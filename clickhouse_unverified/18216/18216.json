{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 18216,
  "instance_id": "ClickHouse__ClickHouse-18216",
  "issue_numbers": [
    "18137"
  ],
  "base_commit": "0d9519a0a2ca464e752b2593f7b061cb63eca4a4",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeReadPool.cpp b/src/Storages/MergeTree/MergeTreeReadPool.cpp\nindex e44ff500c88a..d9a250e3f7ac 100644\n--- a/src/Storages/MergeTree/MergeTreeReadPool.cpp\n+++ b/src/Storages/MergeTree/MergeTreeReadPool.cpp\n@@ -71,6 +71,7 @@ MergeTreeReadTaskPtr MergeTreeReadPool::getTask(const size_t min_marks_to_read,\n         {\n             threads_tasks[thread] = std::move(threads_tasks[*it]);\n             remaining_thread_tasks.erase(it);\n+            remaining_thread_tasks.insert(thread);\n         }\n         else // Try steal tasks from the next thread\n         {\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01603_read_with_backoff_bug.reference b/tests/queries/0_stateless/01603_read_with_backoff_bug.reference\nnew file mode 100644\nindex 000000000000..c7075162d9c5\n--- /dev/null\n+++ b/tests/queries/0_stateless/01603_read_with_backoff_bug.reference\n@@ -0,0 +1,3 @@\n+24972288\t1522399120\n+24972288\t1522399120\n+24972288\t1522399120\ndiff --git a/tests/queries/0_stateless/01603_read_with_backoff_bug.sql b/tests/queries/0_stateless/01603_read_with_backoff_bug.sql\nnew file mode 100644\nindex 000000000000..e80d657fdb42\n--- /dev/null\n+++ b/tests/queries/0_stateless/01603_read_with_backoff_bug.sql\n@@ -0,0 +1,15 @@\n+drop table if exists t;\n+\n+create table t (x UInt64, s String) engine = MergeTree order by x;\n+INSERT INTO t SELECT\n+    number,\n+    if(number < (8129 * 1024), arrayStringConcat(arrayMap(x -> toString(x), range(number % 128)), ' '), '')\n+FROM numbers_mt((8129 * 1024) * 3) settings max_insert_threads=8;\n+\n+-- optimize table t final;\n+\n+select count(), sum(length(s)) from t settings max_threads = 3, read_backoff_min_latency_ms = 1, read_backoff_max_throughput = 1000000000, read_backoff_min_interval_between_events_ms = 1, read_backoff_min_events = 1, read_backoff_min_concurrency = 1;\n+select count(), sum(length(s)) from t settings max_threads = 3, read_backoff_min_latency_ms = 1, read_backoff_max_throughput = 1000000000, read_backoff_min_interval_between_events_ms = 1, read_backoff_min_events = 1, read_backoff_min_concurrency = 1;\n+select count(), sum(length(s)) from t settings max_threads = 3, read_backoff_min_latency_ms = 1, read_backoff_max_throughput = 1000000000, read_backoff_min_interval_between_events_ms = 1, read_backoff_min_events = 1, read_backoff_min_concurrency = 1;\n+\n+drop table if exists t;\n",
  "problem_statement": "20.12.3.3 Less amount of data is returned if \"read backoff\" is in effect.\nConsider following: \r\n\r\n1 master server with Distributed table (```tracking_distributed```), 2 shards, previously was 4 shards, but during chat discussion i've reduced them to 2 for easier debugging (including master server each having 1 replica with 1 MergeTree table ```tracking_shard```). Also a ```tracking``` table - which is an old table that i want to re-distribute and aggregate while doing inserts from it into ```tracking_distributed``` which is connected to MV on the same server, by doing following insert:\r\n\r\n```\r\ninsert into tracking_distributed (date, datetime, col1, col2, col3, col4, col5,\r\n                                  col6, col7, col8, col9,\r\n                                  col10, col11, col12, col13, col14, col15, col16,\r\n                                  col17, col18, col19,\r\n                                  col20, col21, col22, col23,\r\n                                  col24, col25,\r\n                                  col26, col27, col28, col29, col30, col31)\r\nselect date,\r\n          datetime,\r\n          1     as raw1,\r\n          0     as raw2,\r\n          col3,\r\n             col4,\r\n             col5,\r\n             col6,\r\n             col7,\r\n             col8,\r\n             col9,\r\n             col10,\r\n             col11,\r\n             col12,\r\n             col13,\r\n             col14,\r\n             col15,\r\n             col16,\r\n             col17,\r\n             col18,\r\n             col19,\r\n             col20,\r\n             col21,\r\n             col22,\r\n             col23,\r\n             col24,\r\n             col25,\r\n             [[]]  as raw3,\r\n             0     as raw4,\r\n             'RUB' as raw5,\r\n             []    as raw6,\r\n             0     as raw7,\r\n             []    as raw8\r\n      from tracking\r\n      where date > '2010-01-01'\r\n        and date <= '2019-07-01'\r\n```\r\n\r\nData inside ```tracking``` are starting from 2019-01-08. After this insert i am checking that all rows are inserted correctly by doing following two queries:\r\n\r\n```\r\nselect count(), concat(toString(toMonth(date)), '.', toString(toYear(date))) as dt\r\nfrom tracking_distributed\r\nwhere (date >= '2000-02-01')\r\n  AND (date < '2019-07-01')\r\ngroup by dt\r\norder by dt;\r\n\r\nselect count(), concat(toString(toMonth(date)), '.', toString(toYear(date))) as dt\r\nfrom tracking\r\nwhere (date >= '2000-02-01')\r\n  AND (date < '2019-07-01')\r\ngroup by dt\r\norder by dt;\r\n```\r\n\r\nAnd getting very strange results:\r\n\r\ntracking_distributed:\r\n```\r\n78238,1.2019\r\n8406510,2.2019\r\n7700480,3.2019\r\n47273866,4.2019\r\n86705743,5.2019\r\n69612803,6.2019\r\n```\r\n\r\ntracking:\r\n```\r\n78238,1.2019\r\n8406510,2.2019\r\n21402619,3.2019\r\n47759435,4.2019\r\n89318991,5.2019\r\n76633611,6.2019\r\n```\r\n\r\n```tracking``` (csv, no column names) - [schema](https://pastebin.com/G5m6taU7) \r\n```tracking_dsitributed``` (csv, no column names) - [schema](https://pastebin.com/RPXXn4w2)\r\n\r\n0) Before inserting on every shard is executed ```truncate table tracking_shard``` and additionally executed ```truncate table tracking_distributed``` \r\n1) Logs does not have any errors on shards and on master\r\n2) If i am doing 6 separate queries for 6 month - i am getting CORRECT data inside ```tracking_distributed``` e.g. ```where date >= 2019-01-01 and date < 2019-02-01``` ```where date >= 2019-02-01 and date < 2019-03-01```\r\n3) I've tried stop distributed flushes, do insert then flush in one operation - same result\r\n4) Tried using insert_distributed_sync=1, same result but slower\r\n5) Tried wraping initial select with subselect e.g. select * from (select date, datetime ...), same results\r\n6) Servers and clickhouse-server on every shard have UTC datetime\r\n7) ```/var/lib/clickhouse/data/<db>/<distributed_table>``` location empty after insert is finished\r\n8) Trace log - https://pastebin.com/UThwL0XV\r\n9) Also tried removing default toDate(datetime) in distributed table - but no luck\r\n\r\n\r\n\r\n\n",
  "hints_text": "UP:\r\n\r\nProblem also occurs when doing inserts like:\r\n```insert into tracking_shard select ... from remote(server,'tracking') where cityHash64(date) % 2 == 1``` \r\n\r\nand local query on server1 like:\r\n```insert into tracking_shard select ... from tracking where cityHash64(date) % 2 == 0```\nUP:\r\n\r\nProblem FOUND! If i set max_threads=1 (from default 8) everything is working! All data are in place!\r\nAlso there are some strange messages in logs:\r\n\r\n```\r\n<Debug> MergeTreeReadPool: Slow read, event \u21161: read 1048576 bytes in 1.104 sec\r\n<Debug> MergeTreeReadPool: Will lower number of threads to 7\r\n```\r\n\r\nI assume after this some data are lost silently without any errors\nUP:\r\n\r\nSetting this:\r\n\r\nread_backoff_min_latency_ms=100000 (so number of threads never lowers)\r\nmax_threads=5\r\nmax_insert_threads=5\r\n\r\nWorks PERFECTLY. So this is data loss every time when number of threads for MergeTreeReadPool lowers due to backoff mechanics...\n@den-crane What versions are affected?\r\nCould you please make a draft PR with failing test?\nRepro:\r\n```\r\ncreate table t (x UInt64, s String) engine = MergeTree order by x;\r\nINSERT INTO t SELECT\r\n    number,\r\n    if(number < (8129 * 1024), arrayStringConcat(arrayMap(x -> toString(x), range(number % 128)), ' '), '')\r\nFROM numbers((8129 * 1024) * 3);\r\n\r\nselect count(), sum(length(s)) from t settings max_threads = 3, read_backoff_min_latency_ms = 1, read_backoff_max_throughput = 1000000000, read_backoff_min_interval_between_events_ms = 1, read_backoff_min_events = 1, read_backoff_min_concurrency = 1;\r\n```\r\n\r\n```\r\n:) select count(), sum(length(s)) from t settings max_threads = 3, read_backoff_min_latency_ms = 1, read_backoff_max_throughput = 1000000000, read_backoff_min_interval_between_events_ms = 1, read_backoff_min_events = 1, read_backoff_min_concurrency = 1\r\n\r\nSELECT\r\n    count(),\r\n    sum(length(s))\r\nFROM t\r\nSETTINGS max_threads = 3, read_backoff_min_latency_ms = 1, read_backoff_max_throughput = 1000000000, read_backoff_min_interval_between_events_ms = 1, read_backoff_min_events = 1, read_backoff_min_concurrency = 1\r\n\r\nQuery id: 5605ae8e-3ce4-4b06-92eb-e314d4f81bba\r\n\r\n\u250c\u2500\u2500count()\u2500\u252c\u2500sum(length(s))\u2500\u2510\r\n\u2502 20000116 \u2502      983073009 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 0.169 sec. Processed 20.00 million rows, 1.16 GB (118.51 million rows/s., 6.89 GB/s.) \r\n\r\n:) select count(), sum(length(s)) from t settings max_threads = 3, read_backoff_min_latency_ms = 1, read_backoff_max_throughput = 1000000000, read_backoff_min_interval_between_events_ms = 1, read_backoff_min_events = 1, read_backoff_min_concurrency = 1\r\n\r\nSELECT\r\n    count(),\r\n    sum(length(s))\r\nFROM t\r\nSETTINGS max_threads = 3, read_backoff_min_latency_ms = 1, read_backoff_max_throughput = 1000000000, read_backoff_min_interval_between_events_ms = 1, read_backoff_min_events = 1, read_backoff_min_concurrency = 1\r\n\r\nQuery id: c0f5f964-3db0-4bf1-ae9c-3f50d4af558f\r\n\r\n\u250c\u2500\u2500count()\u2500\u252c\u2500sum(length(s))\u2500\u2510\r\n\u2502 18607290 \u2502     1510185631 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 0.416 sec. Processed 18.61 million rows, 1.68 GB (44.72 million rows/s., 4.03 GB/s.) \r\n\r\n```\r\n",
  "created_at": "2020-12-18T08:41:33Z"
}