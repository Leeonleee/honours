{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 68291,
  "instance_id": "ClickHouse__ClickHouse-68291",
  "issue_numbers": [
    "63979"
  ],
  "base_commit": "d1b3bf31039d94bbd385a7287b9c51569bc34fc5",
  "patch": "diff --git a/src/Processors/Executors/ExecutingGraph.cpp b/src/Processors/Executors/ExecutingGraph.cpp\nindex 6d5b60d81591..10470325bb80 100644\n--- a/src/Processors/Executors/ExecutingGraph.cpp\n+++ b/src/Processors/Executors/ExecutingGraph.cpp\n@@ -96,7 +96,7 @@ bool ExecutingGraph::addEdges(uint64_t node)\n     return was_edge_added;\n }\n \n-bool ExecutingGraph::expandPipeline(std::stack<uint64_t> & stack, uint64_t pid)\n+ExecutingGraph::UpdateNodeStatus ExecutingGraph::expandPipeline(std::stack<uint64_t> & stack, uint64_t pid)\n {\n     auto & cur_node = *nodes[pid];\n     Processors new_processors;\n@@ -108,7 +108,7 @@ bool ExecutingGraph::expandPipeline(std::stack<uint64_t> & stack, uint64_t pid)\n     catch (...)\n     {\n         cur_node.exception = std::current_exception();\n-        return false;\n+        return UpdateNodeStatus::Exception;\n     }\n \n     {\n@@ -118,7 +118,7 @@ bool ExecutingGraph::expandPipeline(std::stack<uint64_t> & stack, uint64_t pid)\n         {\n             for (auto & processor : new_processors)\n                 processor->cancel();\n-            return false;\n+            return UpdateNodeStatus::Cancelled;\n         }\n         processors->insert(processors->end(), new_processors.begin(), new_processors.end());\n \n@@ -178,7 +178,7 @@ bool ExecutingGraph::expandPipeline(std::stack<uint64_t> & stack, uint64_t pid)\n         }\n     }\n \n-    return true;\n+    return UpdateNodeStatus::Done;\n }\n \n void ExecutingGraph::initializeExecution(Queue & queue)\n@@ -213,7 +213,7 @@ void ExecutingGraph::initializeExecution(Queue & queue)\n }\n \n \n-bool ExecutingGraph::updateNode(uint64_t pid, Queue & queue, Queue & async_queue)\n+ExecutingGraph::UpdateNodeStatus ExecutingGraph::updateNode(uint64_t pid, Queue & queue, Queue & async_queue)\n {\n     std::stack<Edge *> updated_edges;\n     std::stack<uint64_t> updated_processors;\n@@ -309,7 +309,7 @@ bool ExecutingGraph::updateNode(uint64_t pid, Queue & queue, Queue & async_queue\n                 catch (...)\n                 {\n                     node.exception = std::current_exception();\n-                    return false;\n+                    return UpdateNodeStatus::Exception;\n                 }\n \n #ifndef NDEBUG\n@@ -386,8 +386,9 @@ bool ExecutingGraph::updateNode(uint64_t pid, Queue & queue, Queue & async_queue\n                 read_lock.unlock();\n                 {\n                     std::unique_lock lock(nodes_mutex);\n-                    if (!expandPipeline(updated_processors, pid))\n-                        return false;\n+                    auto status = expandPipeline(updated_processors, pid);\n+                    if (status != UpdateNodeStatus::Done)\n+                        return status;\n                 }\n                 read_lock.lock();\n \n@@ -397,7 +398,7 @@ bool ExecutingGraph::updateNode(uint64_t pid, Queue & queue, Queue & async_queue\n         }\n     }\n \n-    return true;\n+    return UpdateNodeStatus::Done;\n }\n \n void ExecutingGraph::cancel(bool cancel_all_processors)\ndiff --git a/src/Processors/Executors/ExecutingGraph.h b/src/Processors/Executors/ExecutingGraph.h\nindex 71dcd360a2c0..e1a6ac962034 100644\n--- a/src/Processors/Executors/ExecutingGraph.h\n+++ b/src/Processors/Executors/ExecutingGraph.h\n@@ -138,10 +138,17 @@ class ExecutingGraph\n     /// Traverse graph the first time to update all the childless nodes.\n     void initializeExecution(Queue & queue);\n \n+    enum class UpdateNodeStatus\n+    {\n+        Done,\n+        Exception,\n+        Cancelled,\n+    };\n+\n     /// Update processor with pid number (call IProcessor::prepare).\n     /// Check parents and children of current processor and push them to stacks if they also need to be updated.\n     /// If processor wants to be expanded, lock will be upgraded to get write access to pipeline.\n-    bool updateNode(uint64_t pid, Queue & queue, Queue & async_queue);\n+    UpdateNodeStatus updateNode(uint64_t pid, Queue & queue, Queue & async_queue);\n \n     void cancel(bool cancel_all_processors = true);\n \n@@ -155,7 +162,7 @@ class ExecutingGraph\n \n     /// Update graph after processor (pid) returned ExpandPipeline status.\n     /// All new nodes and nodes with updated ports are pushed into stack.\n-    bool expandPipeline(std::stack<uint64_t> & stack, uint64_t pid);\n+    UpdateNodeStatus expandPipeline(std::stack<uint64_t> & stack, uint64_t pid);\n \n     std::shared_ptr<Processors> processors;\n     std::vector<bool> source_processors;\ndiff --git a/src/Processors/Executors/PipelineExecutor.cpp b/src/Processors/Executors/PipelineExecutor.cpp\nindex 82cad471a29d..23b3a6d9f5f9 100644\n--- a/src/Processors/Executors/PipelineExecutor.cpp\n+++ b/src/Processors/Executors/PipelineExecutor.cpp\n@@ -77,9 +77,9 @@ const Processors & PipelineExecutor::getProcessors() const\n     return graph->getProcessors();\n }\n \n-void PipelineExecutor::cancel()\n+void PipelineExecutor::cancel(ExecutionStatus reason)\n {\n-    cancelled = true;\n+    tryUpdateExecutionStatus(ExecutionStatus::Executing, reason);\n     finish();\n     graph->cancel();\n }\n@@ -98,6 +98,11 @@ void PipelineExecutor::finish()\n     tasks.finish();\n }\n \n+bool PipelineExecutor::tryUpdateExecutionStatus(ExecutionStatus expected, ExecutionStatus desired)\n+{\n+    return execution_status.compare_exchange_strong(expected, desired);\n+}\n+\n void PipelineExecutor::execute(size_t num_threads, bool concurrency_control)\n {\n     checkTimeLimit();\n@@ -120,7 +125,7 @@ void PipelineExecutor::execute(size_t num_threads, bool concurrency_control)\n     }\n     catch (...)\n     {\n-        span.addAttribute(ExecutionStatus::fromCurrentException());\n+        span.addAttribute(DB::ExecutionStatus::fromCurrentException());\n \n #ifndef NDEBUG\n         LOG_TRACE(log, \"Exception while executing query. Current state:\\n{}\", dumpPipeline());\n@@ -169,7 +174,7 @@ bool PipelineExecutor::checkTimeLimitSoft()\n         // We call cancel here so that all processors are notified and tasks waken up\n         // so that the \"break\" is faster and doesn't wait for long events\n         if (!continuing)\n-            cancel();\n+            cancel(ExecutionStatus::CancelledByTimeout);\n \n         return continuing;\n     }\n@@ -195,7 +200,8 @@ void PipelineExecutor::finalizeExecution()\n {\n     checkTimeLimit();\n \n-    if (cancelled)\n+    auto status = execution_status.load();\n+    if (status == ExecutionStatus::CancelledByTimeout || status == ExecutionStatus::CancelledByUser)\n         return;\n \n     bool all_processors_finished = true;\n@@ -271,7 +277,7 @@ void PipelineExecutor::executeStepImpl(size_t thread_num, std::atomic_bool * yie\n                 break;\n \n             if (!context.executeTask())\n-                cancel();\n+                cancel(ExecutionStatus::Exception);\n \n             if (tasks.isFinished())\n                 break;\n@@ -289,11 +295,13 @@ void PipelineExecutor::executeStepImpl(size_t thread_num, std::atomic_bool * yie\n                 Queue async_queue;\n \n                 /// Prepare processor after execution.\n-                if (!graph->updateNode(context.getProcessorID(), queue, async_queue))\n-                    cancel();\n+                auto status = graph->updateNode(context.getProcessorID(), queue, async_queue);\n+                if (status == ExecutingGraph::UpdateNodeStatus::Exception)\n+                    cancel(ExecutionStatus::Exception);\n \n                 /// Push other tasks to global queue.\n-                tasks.pushTasks(queue, async_queue, context);\n+                if (status == ExecutingGraph::UpdateNodeStatus::Done)\n+                    tasks.pushTasks(queue, async_queue, context);\n             }\n \n #ifndef NDEBUG\n@@ -309,7 +317,7 @@ void PipelineExecutor::executeStepImpl(size_t thread_num, std::atomic_bool * yie\n             {\n                 /// spawnThreads can throw an exception, for example CANNOT_SCHEDULE_TASK.\n                 /// We should cancel execution properly before rethrow.\n-                cancel();\n+                cancel(ExecutionStatus::Exception);\n                 throw;\n             }\n \n@@ -328,6 +336,7 @@ void PipelineExecutor::executeStepImpl(size_t thread_num, std::atomic_bool * yie\n void PipelineExecutor::initializeExecution(size_t num_threads, bool concurrency_control)\n {\n     is_execution_initialized = true;\n+    tryUpdateExecutionStatus(ExecutionStatus::NotStarted, ExecutionStatus::Executing);\n \n     size_t use_threads = num_threads;\n \n@@ -393,7 +402,7 @@ void PipelineExecutor::executeImpl(size_t num_threads, bool concurrency_control)\n         {\n             /// If finished_flag is not set, there was an exception.\n             /// Cancel execution in this case.\n-            cancel();\n+            cancel(ExecutionStatus::Exception);\n             if (pool)\n                 pool->wait();\n         }\ndiff --git a/src/Processors/Executors/PipelineExecutor.h b/src/Processors/Executors/PipelineExecutor.h\nindex ae119355cb5a..79d0a29d4e1d 100644\n--- a/src/Processors/Executors/PipelineExecutor.h\n+++ b/src/Processors/Executors/PipelineExecutor.h\n@@ -48,8 +48,20 @@ class PipelineExecutor\n \n     const Processors & getProcessors() const;\n \n+    enum class ExecutionStatus\n+    {\n+        NotStarted,\n+        Executing,\n+        Finished,\n+        Exception,\n+        CancelledByUser,\n+        CancelledByTimeout,\n+    };\n+\n     /// Cancel execution. May be called from another thread.\n-    void cancel();\n+    void cancel() { cancel(ExecutionStatus::CancelledByUser); }\n+\n+    ExecutionStatus getExecutionStatus() const { return execution_status.load(); }\n \n     /// Cancel processors which only read data from source. May be called from another thread.\n     void cancelReading();\n@@ -81,7 +93,7 @@ class PipelineExecutor\n     /// system.opentelemetry_span_log\n     bool trace_processors = false;\n \n-    std::atomic_bool cancelled = false;\n+    std::atomic<ExecutionStatus> execution_status = ExecutionStatus::NotStarted;\n     std::atomic_bool cancelled_reading = false;\n \n     LoggerPtr log = getLogger(\"PipelineExecutor\");\n@@ -105,6 +117,10 @@ class PipelineExecutor\n     void executeStepImpl(size_t thread_num, std::atomic_bool * yield_flag = nullptr);\n     void executeSingleThread(size_t thread_num);\n     void finish();\n+    void cancel(ExecutionStatus reason);\n+\n+    /// If execution_status == from, change it to desired.\n+    bool tryUpdateExecutionStatus(ExecutionStatus expected, ExecutionStatus desired);\n \n     String dumpPipeline() const;\n };\ndiff --git a/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp b/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp\nindex 830a96533edf..866d224a08d0 100644\n--- a/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp\n+++ b/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp\n@@ -15,6 +15,7 @@ namespace DB\n namespace ErrorCodes\n {\n     extern const int LOGICAL_ERROR;\n+    extern const int QUERY_WAS_CANCELLED;\n }\n \n class PushingAsyncSource : public ISource\n@@ -176,6 +177,16 @@ void PushingAsyncPipelineExecutor::start()\n     data->thread = ThreadFromGlobalPool(std::move(func));\n }\n \n+[[noreturn]] static void throwOnExecutionStatus(PipelineExecutor::ExecutionStatus status)\n+{\n+    if (status == PipelineExecutor::ExecutionStatus::CancelledByTimeout\n+        || status == PipelineExecutor::ExecutionStatus::CancelledByUser)\n+        throw Exception(ErrorCodes::QUERY_WAS_CANCELLED, \"Query was cancelled\");\n+\n+    throw Exception(ErrorCodes::LOGICAL_ERROR,\n+        \"Pipeline for PushingPipelineExecutor was finished before all data was inserted\");\n+}\n+\n void PushingAsyncPipelineExecutor::push(Chunk chunk)\n {\n     if (!started)\n@@ -185,8 +196,7 @@ void PushingAsyncPipelineExecutor::push(Chunk chunk)\n     data->rethrowExceptionIfHas();\n \n     if (!is_pushed)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR,\n-                        \"Pipeline for PushingAsyncPipelineExecutor was finished before all data was inserted\");\n+        throwOnExecutionStatus(data->executor->getExecutionStatus());\n }\n \n void PushingAsyncPipelineExecutor::push(Block block)\ndiff --git a/src/Processors/Executors/PushingPipelineExecutor.cpp b/src/Processors/Executors/PushingPipelineExecutor.cpp\nindex 696932932df5..7a1c0111a3a6 100644\n--- a/src/Processors/Executors/PushingPipelineExecutor.cpp\n+++ b/src/Processors/Executors/PushingPipelineExecutor.cpp\n@@ -11,6 +11,7 @@ namespace DB\n namespace ErrorCodes\n {\n     extern const int LOGICAL_ERROR;\n+    extern const int QUERY_WAS_CANCELLED;\n }\n \n class PushingSource : public ISource\n@@ -80,6 +81,15 @@ const Block & PushingPipelineExecutor::getHeader() const\n     return pushing_source->getPort().getHeader();\n }\n \n+[[noreturn]] static void throwOnExecutionStatus(PipelineExecutor::ExecutionStatus status)\n+{\n+    if (status == PipelineExecutor::ExecutionStatus::CancelledByTimeout\n+        || status == PipelineExecutor::ExecutionStatus::CancelledByUser)\n+        throw Exception(ErrorCodes::QUERY_WAS_CANCELLED, \"Query was cancelled\");\n+\n+    throw Exception(ErrorCodes::LOGICAL_ERROR,\n+        \"Pipeline for PushingPipelineExecutor was finished before all data was inserted\");\n+}\n \n void PushingPipelineExecutor::start()\n {\n@@ -91,8 +101,7 @@ void PushingPipelineExecutor::start()\n     executor->setReadProgressCallback(pipeline.getReadProgressCallback());\n \n     if (!executor->executeStep(&input_wait_flag))\n-        throw Exception(ErrorCodes::LOGICAL_ERROR,\n-                        \"Pipeline for PushingPipelineExecutor was finished before all data was inserted\");\n+        throwOnExecutionStatus(executor->getExecutionStatus());\n }\n \n void PushingPipelineExecutor::push(Chunk chunk)\n@@ -103,8 +112,7 @@ void PushingPipelineExecutor::push(Chunk chunk)\n     pushing_source->setData(std::move(chunk));\n \n     if (!executor->executeStep(&input_wait_flag))\n-        throw Exception(ErrorCodes::LOGICAL_ERROR,\n-                        \"Pipeline for PushingPipelineExecutor was finished before all data was inserted\");\n+        throwOnExecutionStatus(executor->getExecutionStatus());\n }\n \n void PushingPipelineExecutor::push(Block block)\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03221_insert_timeout_overflow_mode.reference b/tests/queries/0_stateless/03221_insert_timeout_overflow_mode.reference\nnew file mode 100644\nindex 000000000000..68538c3f75b5\n--- /dev/null\n+++ b/tests/queries/0_stateless/03221_insert_timeout_overflow_mode.reference\n@@ -0,0 +1,2 @@\n+QUERY_WAS_CANCELLED\n+QUERY_WAS_CANCELLED\ndiff --git a/tests/queries/0_stateless/03221_insert_timeout_overflow_mode.sh b/tests/queries/0_stateless/03221_insert_timeout_overflow_mode.sh\nnew file mode 100755\nindex 000000000000..db943a665cbf\n--- /dev/null\n+++ b/tests/queries/0_stateless/03221_insert_timeout_overflow_mode.sh\n@@ -0,0 +1,8 @@\n+#!/usr/bin/env bash\n+\n+CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CUR_DIR\"/../shell_config.sh\n+\n+${CLICKHOUSE_CLIENT} --query \"create table null_t (number UInt64) engine = Null;\"\n+${CLICKHOUSE_CLIENT} --query \"select sleep(0.1) from system.numbers settings max_block_size = 1 format Native\" 2>/dev/null | ${CLICKHOUSE_CLIENT} --max_execution_time 0.3 --timeout_overflow_mode break --query \"insert into null_t format Native\" 2>&1 | grep -o \"QUERY_WAS_CANCELLED\"\n",
  "problem_statement": "LOGICAL_ERROR Pipeline for PushingPipelineExecutor was finished before all data was inserted\nI'm able to reproduce smth similar with the following:\r\n\r\n``` sh\r\ndiff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp\r\nindex ae2f150c4a1..d0911804063 100644\r\n--- a/src/Server/TCPHandler.cpp\r\n+++ b/src/Server/TCPHandler.cpp\r\n@@ -910,6 +910,8 @@ void TCPHandler::processInsertQuery()\r\n\r\n     auto run_executor = [&](auto & executor, Block processed_data)\r\n     {\r\n+        std::this_thread::sleep_for(std::chrono::seconds(1));\r\n+\r\n         /// Made above the rest of the lines,\r\n         /// so that in case of `start` function throws an exception,\r\n         /// client receive exception before sending data.\r\n```\r\n\r\n``` sh\r\n\u276f cat repro.sql\r\ndrop table if exists mv_table_1;\r\ndrop table if exists mv_table;\r\ndrop table if exists null_table;\r\n\r\nset max_execution_time = 0.1, timeout_overflow_mode = 'break';\r\n\r\nCREATE TABLE null_table (str String) ENGINE = Null;\r\nCREATE MATERIALIZED VIEW mv_table (str String) ENGINE = MergeTree ORDER BY str AS SELECT str AS str FROM null_table;\r\nCREATE MATERIALIZED VIEW mv_table_1 (str Decimal(38, 7)) ENGINE = MergeTree ORDER BY str AS SELECT str AS str FROM null_table;\r\n\r\nINSERT INTO null_table VALUES ('test');\r\n```\r\n\r\n```\r\nCode: 49. DB::Exception: Received from localhost:9000. DB::Exception: Pipeline for PushingPipelineExecutor was finished before all data was inserted. (LOGICAL_ERROR)\r\n```\r\n\r\n---\r\n\r\nStepped on this while trying to reproduce https://s3.amazonaws.com/clickhouse-test-reports/63861/af84e3e1a9c8c3b62f738f231e457efc8ea301ea/ast_fuzzer__tsan_/fatal.log\r\n\r\nNot sure if it is connected anyhow with https://github.com/ClickHouse/ClickHouse/issues/52234 or not. Probably yes, since it requires `max_execution_time = 0.1, timeout_overflow_mode = 'break'`.\n",
  "hints_text": "another interesting behaviour is this:\r\n\r\n```\r\n\u276f gd | cat\r\ndiff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp\r\nindex ae2f150c4a1..dfc18bd90bb 100644\r\n--- a/src/Server/TCPHandler.cpp\r\n+++ b/src/Server/TCPHandler.cpp\r\n@@ -923,6 +923,8 @@ void TCPHandler::processInsertQuery()\r\n         while (readDataNext())\r\n             executor.push(std::move(state.block_for_insert));\r\n\r\n+        std::this_thread::sleep_for(std::chrono::seconds(1));\r\n+\r\n         if (state.cancellation_status == CancellationStatus::FULLY_CANCELLED)\r\n             executor.cancel();\r\n         else\r\n```\r\n\r\nproduces no error, while without any sleep we will obviously get an error:\r\n\r\n```\r\n\u276f clickhouse client --queries-file repro.sql\r\nReceived exception from server (version 24.5.1):\r\nCode: 6. DB::Exception: Received from localhost:9000. DB::Exception: Cannot parse string 'test' as Decimal(38, 7): syntax error at begin of string: while converting source column str to destination column str: while executing 'FUNCTION _CAST(str :: 0, Decimal(38, 7) :: 1) -> _CAST(str, Decimal(38, 7)) Decimal(38, 7) : 2': while pushing to view default.mv_table_1 (318bed11-79cd-4168-b3ac-b8341f8fd678). (CANNOT_PARSE_TEXT)\r\n(query: INSERT INTO null_table VALUES ('test');)\r\n```\r\n\r\nso, we effectively loosing data: https://pastila.nl/?008ee639/0bb65a2827875c58b98c62a4cf731a59#C/nUnY22Jtcrb4U9dUv/tA==\nhttps://s3.amazonaws.com/clickhouse-test-reports/52503/1e15574a25b2eaa4d08c1a14a005ba0b3ebcfc23/ast_fuzzer__ubsan_.html\nWell,\r\nIn my opinion, when the combination of settings `set max_execution_time = 0.1, timeout_overflow_mode = 'break';` is set, noninserting any data is not an error. We can sleep in any place for 0.1 sec, insert nothing after that, and return OK.\r\n\r\nMaybe we can ignore the `timeout_overflow_mode = break` for the `INSERT` query. I am not sure about that, because for `INSERT SELECT`, the setting should be applied for the `SELECT` part, and data insertion won't be guaranteed. And `INSERT` vs. `INSERT SELECT` is not so different (probably, `timeout_overflow_mode` makes sense for some slow inserting scenarios).\r\n\r\n`Pipeline for PushingPipelineExecutor was finished before all data was inserted. (LOGICAL_ERROR)` should be fixed.",
  "created_at": "2024-08-13T14:46:51Z",
  "modified_files": [
    "src/Processors/Executors/ExecutingGraph.cpp",
    "src/Processors/Executors/ExecutingGraph.h",
    "src/Processors/Executors/PipelineExecutor.cpp",
    "src/Processors/Executors/PipelineExecutor.h",
    "src/Processors/Executors/PushingAsyncPipelineExecutor.cpp",
    "src/Processors/Executors/PushingPipelineExecutor.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/03221_insert_timeout_overflow_mode.reference",
    "b/tests/queries/0_stateless/03221_insert_timeout_overflow_mode.sh"
  ]
}