{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 26410,
  "instance_id": "ClickHouse__ClickHouse-26410",
  "issue_numbers": [
    "23682"
  ],
  "base_commit": "6ae40317239bd8da459da6f8fb6475cf9e53e30f",
  "patch": "diff --git a/src/Functions/initialQueryID.cpp b/src/Functions/initialQueryID.cpp\nnew file mode 100644\nindex 000000000000..118339a8fb60\n--- /dev/null\n+++ b/src/Functions/initialQueryID.cpp\n@@ -0,0 +1,44 @@\n+#include <Functions/IFunction.h>\n+#include <Functions/FunctionFactory.h>\n+#include <Interpreters/Context.h>\n+#include <DataTypes/DataTypeString.h>\n+#include <Core/Field.h>\n+\n+namespace DB\n+{\n+class FunctionInitialQueryID : public IFunction\n+{\n+    const String initial_query_id;\n+\n+public:\n+    static constexpr auto name = \"initialQueryID\";\n+    static FunctionPtr create(ContextPtr context)\n+    {\n+        return std::make_shared<FunctionInitialQueryID>(context->getClientInfo().initial_query_id);\n+    }\n+\n+    explicit FunctionInitialQueryID(const String & initial_query_id_) : initial_query_id(initial_query_id_) {}\n+\n+    inline String getName() const override { return name; }\n+\n+    inline size_t getNumberOfArguments() const override { return 0; }\n+\n+    DataTypePtr getReturnTypeImpl(const DataTypes & /*arguments*/) const override\n+    {\n+        return std::make_shared<DataTypeString>();\n+    }\n+\n+    inline bool isDeterministic() const override { return false; }\n+\n+    ColumnPtr executeImpl(const ColumnsWithTypeAndName &, const DataTypePtr &, size_t input_rows_count) const override\n+    {\n+        return DataTypeString().createColumnConst(input_rows_count, initial_query_id);\n+    }\n+};\n+\n+void registerFunctionInitialQueryID(FunctionFactory & factory)\n+{\n+    factory.registerFunction<FunctionInitialQueryID>();\n+    factory.registerAlias(\"initial_query_id\", FunctionInitialQueryID::name, FunctionFactory::CaseInsensitive);\n+}\n+}\ndiff --git a/src/Functions/queryID.cpp b/src/Functions/queryID.cpp\nnew file mode 100644\nindex 000000000000..b55d3fa03266\n--- /dev/null\n+++ b/src/Functions/queryID.cpp\n@@ -0,0 +1,44 @@\n+#include <Functions/IFunction.h>\n+#include <Functions/FunctionFactory.h>\n+#include <Interpreters/Context.h>\n+#include <DataTypes/DataTypeString.h>\n+#include <Core/Field.h>\n+\n+namespace DB\n+{\n+class FunctionQueryID : public IFunction\n+{\n+    const String query_id;\n+\n+public:\n+    static constexpr auto name = \"queryID\";\n+    static FunctionPtr create(ContextPtr context)\n+    {\n+        return std::make_shared<FunctionQueryID>(context->getClientInfo().current_query_id);\n+    }\n+\n+    explicit FunctionQueryID(const String & query_id_) : query_id(query_id_) {}\n+\n+    inline String getName() const override { return name; }\n+\n+    inline size_t getNumberOfArguments() const override { return 0; }\n+\n+    DataTypePtr getReturnTypeImpl(const DataTypes & /*arguments*/) const override\n+    {\n+        return std::make_shared<DataTypeString>();\n+    }\n+\n+    inline bool isDeterministic() const override { return false; }\n+\n+    ColumnPtr executeImpl(const ColumnsWithTypeAndName &, const DataTypePtr &, size_t input_rows_count) const override\n+    {\n+        return DataTypeString().createColumnConst(input_rows_count, query_id)->convertToFullColumnIfConst();\n+    }\n+};\n+\n+void registerFunctionQueryID(FunctionFactory & factory)\n+{\n+    factory.registerFunction<FunctionQueryID>();\n+    factory.registerAlias(\"query_id\", FunctionQueryID::name, FunctionFactory::CaseInsensitive);\n+}\n+}\ndiff --git a/src/Functions/registerFunctionsMiscellaneous.cpp b/src/Functions/registerFunctionsMiscellaneous.cpp\nindex 3403390ea72c..ed9b642738b3 100644\n--- a/src/Functions/registerFunctionsMiscellaneous.cpp\n+++ b/src/Functions/registerFunctionsMiscellaneous.cpp\n@@ -74,6 +74,8 @@ void registerFunctionFile(FunctionFactory & factory);\n void registerFunctionConnectionId(FunctionFactory & factory);\n void registerFunctionPartitionId(FunctionFactory & factory);\n void registerFunctionIsIPAddressContainedIn(FunctionFactory &);\n+void registerFunctionQueryID(FunctionFactory & factory);\n+void registerFunctionInitialQueryID(FunctionFactory & factory);\n \n #if USE_ICU\n void registerFunctionConvertCharset(FunctionFactory &);\n@@ -148,6 +150,8 @@ void registerFunctionsMiscellaneous(FunctionFactory & factory)\n     registerFunctionConnectionId(factory);\n     registerFunctionPartitionId(factory);\n     registerFunctionIsIPAddressContainedIn(factory);\n+    registerFunctionQueryID(factory);\n+    registerFunctionInitialQueryID(factory);\n \n #if USE_ICU\n     registerFunctionConvertCharset(factory);\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01943_query_id_check.reference b/tests/queries/0_stateless/01943_query_id_check.reference\nnew file mode 100644\nindex 000000000000..324d49f89074\n--- /dev/null\n+++ b/tests/queries/0_stateless/01943_query_id_check.reference\n@@ -0,0 +1,7 @@\n+CREATE TABLE tmp ENGINE = TinyLog AS SELECT queryID();\n+CREATE TABLE tmp ENGINE = TinyLog AS SELECT initialQueryID();\n+3\n+3\n+1\n+1\n+3\ndiff --git a/tests/queries/0_stateless/01943_query_id_check.sql b/tests/queries/0_stateless/01943_query_id_check.sql\nnew file mode 100644\nindex 000000000000..6e3d281386d5\n--- /dev/null\n+++ b/tests/queries/0_stateless/01943_query_id_check.sql\n@@ -0,0 +1,21 @@\n+DROP TABLE IF EXISTS tmp;\n+\n+CREATE TABLE tmp ENGINE = TinyLog AS SELECT queryID();\n+SYSTEM FLUSH LOGS;\n+SELECT query FROM system.query_log WHERE query_id = (SELECT * FROM tmp) AND current_database = currentDatabase() LIMIT 1;\n+DROP TABLE tmp;\n+\n+CREATE TABLE tmp ENGINE = TinyLog AS SELECT initialQueryID();\n+SYSTEM FLUSH LOGS;\n+SELECT query FROM system.query_log WHERE initial_query_id = (SELECT * FROM tmp) AND current_database = currentDatabase() LIMIT 1;\n+DROP TABLE tmp;\n+\n+CREATE TABLE tmp (str String) ENGINE = Log;\n+INSERT INTO tmp (*) VALUES ('a')\n+SELECT count() FROM (SELECT initialQueryID() FROM remote('127.0.0.{1..3}', currentDatabase(), 'tmp') GROUP BY queryID());\n+SELECT count() FROM (SELECT queryID() FROM remote('127.0.0.{1..3}', currentDatabase(), 'tmp') GROUP BY queryID());\n+SELECT count() FROM (SELECT queryID() AS t FROM remote('127.0.0.{1..3}', currentDatabase(), 'tmp') GROUP BY queryID() HAVING t == initialQueryID());\n+SELECT count(DISTINCT t) FROM (SELECT initialQueryID() AS t FROM remote('127.0.0.{1..3}', currentDatabase(), 'tmp') GROUP BY queryID());\n+SELECT count(DISTINCT t) FROM (SELECT queryID() AS t FROM remote('127.0.0.{1..3}', currentDatabase(), 'tmp') GROUP BY queryID());\n+DROP TABLE tmp;\n+\ndiff --git a/tests/queries/skip_list.json b/tests/queries/skip_list.json\nindex 6cf9c65cfe94..f2bdd8ae52dc 100644\n--- a/tests/queries/skip_list.json\n+++ b/tests/queries/skip_list.json\n@@ -176,6 +176,7 @@\n         /// Requires investigation\n         \"00953_zookeeper_suetin_deduplication_bug\",\n         \"01783_http_chunk_size\",\n+        \"01943_query_id_check\",\n         \"00166_explain_estimate\"\n     ],\n     \"polymorphic-parts\": [\n",
  "problem_statement": "Create functions queryID and initialQueryID\nGoal is to find out (initial_)query_id of INSERT query that triggered this (current) Materialized View execution, in order to register this initial_query_id in statistics table.\r\nWhy? It would enrich statistics/monitoring/troubleshooting and provide significant information both about origins of insert to ClickHouse and about propagation of insert through ClickHouse derived objects (e.g. in-ClickHouse latency).\r\n\r\nThe point is that system.query_log with all its useful information knows nothing about data.\r\nAt the same time manual statistics table(s) that are filled by adjacent MV potentially know everything about incoming data, but lack information about initial IP's, queries etc.\r\nThese two statistic's sources are crying to be linked together.\r\n\r\nThis use case and this desire look general enough, so there is probably some general solution.\r\n\r\n+++++++++++++++++++++++++++\r\nDetails\r\n+++++++++++++++++++++++++++\r\n\r\nInput data stream enters my ClickHouse cluster through input Null table (on every node). \r\nSeveral Materialized Views over this Null table are performing some processing and propagating data further (there are distributed tables and more MV's there). \r\nIn order to reduce in-ClickHouse latency: parallel_view_processing=1\r\n\r\nOne of derived tables (stat2.inserts_v02) contains statistics about input flow  (count(), quantiles, delays) over some data-related dimensions.\r\nIt is basic ReplicatedMergeTree that is filled via MV from inserts to initial Null table data2.input_null like:\r\n`CREATE MATERIALIZED VIEW data2.inserts_v02_MVst2 ON CLUSTER ch_sNr1 TO stat2.inserts_v02\r\nAS SELECT\r\n  <data dimensions>,\r\n  hostName(),\r\n  count(), median(), etc\r\n  FROM data2.input_null GROUP BY ... ORDER BY ...`\r\n\r\nI'm trying to somehow find out/evaluate (initial_)query_id of parent's insert inside Materialized View's query.\r\nIt would be very helpful for monitoring/troubleshooting/statistics. \r\nIf query_id or initial_query_id were known, it would have been possible to obtain a lot of additional information from system.query_log tables - both about origins of ETL data flow (IP addresses, http_user_agent) and about further destiny of this insert (whole picture of latencies within ClickHouse, additional checks that everything works as intended).\r\n\r\nBut all my attempts failed.\r\nThere are seemingly no inherent functions to receive initial_query_id that triggered MV during MV execution (however modern ClickHouse versions do display query's query_id in clickhouse-client).\r\nI tried to fill initial_query_id via lookup into system.processes table, but the problem is that these are large inserts (500k-1M events) that are executed several seconds, and there are usually many simultaneous inserts of such kind. \r\nSo Materialized View (when it is executed) can't find out which of existsing system.processes INSERT queries is its parent. \r\n`(SELECT arrayStringConcat(groupArray(initial_query_id), ',') FROM system.processes WHERE substr(query,1,37)='INSERT INTO data2.stage2_null_events') AS possible_query_ids,`\n",
  "hints_text": "In other words you want to make things like query_id and initial_query_id available as functions, and use them inside your materialized views? \r\n\r\n\r\nSomething like: \r\n\r\n```\r\nCREATE MATERIALIZED VIEW foo AS SELECT hostName(), count(), median(), queryID(), initialQueryID() from bar;\r\n```\r\n\r\n? \nIf there were direct functions like this it would be a perfect outcome !\r\n\r\nActually I didn't intend this Issue to be a feature request, but rather hoped that there is already some workaround to enrich inserts-related statistics (counted within derived MV) with audit data from system.query_log. \r\nIf it was a function - even better!\r\n\r\nWhat is more important is that I assume it is not my personal issue, but rather a feature that would meet certain demand from ClickHouse users in a whole. \r\nIt looks like an implementation of final \"Load\" phase of non-trivial ETL processes on the side of ClickHouse not in some particular table, but rather in a small tree of several tables (linked by Materialized Views) is quite a mainstream approach. \r\nAnd additional MV (to main data flow) that evaluates insert's statistics for monitoring looks very natural solution here. An opportunity to link to system.query_log would make this pattern more useful.\n> workaround to enrich inserts-related statistics (counted within derived MV) with audit data from system.query_log.\r\n\r\nYou can try joins (of course later, it is not possible at insert / MV time) . But it would be quite painful, non reliable  and and non efficient.\r\n\r\nAddind such function should be trivial. ",
  "created_at": "2021-07-16T12:37:16Z",
  "modified_files": [
    "b/src/Functions/initialQueryID.cpp",
    "b/src/Functions/queryID.cpp",
    "src/Functions/registerFunctionsMiscellaneous.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/01943_query_id_check.reference",
    "b/tests/queries/0_stateless/01943_query_id_check.sql",
    "tests/queries/skip_list.json"
  ]
}