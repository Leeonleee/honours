{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 38614,
  "instance_id": "ClickHouse__ClickHouse-38614",
  "issue_numbers": [
    "10316"
  ],
  "base_commit": "539cb6f3c1a84967b7bdd463405a04664667a3ce",
  "patch": "diff --git a/src/Common/CurrentThread.cpp b/src/Common/CurrentThread.cpp\nindex e54b2c8abe4e..a176a19673b4 100644\n--- a/src/Common/CurrentThread.cpp\n+++ b/src/Common/CurrentThread.cpp\n@@ -40,7 +40,7 @@ ThreadStatus & CurrentThread::get()\n \n ProfileEvents::Counters & CurrentThread::getProfileEvents()\n {\n-    return current_thread ? current_thread->performance_counters : ProfileEvents::global_counters;\n+    return current_thread ? *current_thread->current_performance_counters : ProfileEvents::global_counters;\n }\n \n void CurrentThread::updateProgressIn(const Progress & value)\ndiff --git a/src/Common/CurrentThread.h b/src/Common/CurrentThread.h\nindex cbe60365798d..c07b34acae3a 100644\n--- a/src/Common/CurrentThread.h\n+++ b/src/Common/CurrentThread.h\n@@ -92,7 +92,7 @@ class CurrentThread\n     static void detachQueryIfNotDetached();\n \n     /// Initializes query with current thread as master thread in constructor, and detaches it in destructor\n-    struct QueryScope\n+    struct QueryScope : private boost::noncopyable\n     {\n         explicit QueryScope(ContextMutablePtr query_context);\n         explicit QueryScope(ContextPtr query_context);\ndiff --git a/src/Common/ProfileEventsScope.cpp b/src/Common/ProfileEventsScope.cpp\nnew file mode 100644\nindex 000000000000..92f75f4f5b0f\n--- /dev/null\n+++ b/src/Common/ProfileEventsScope.cpp\n@@ -0,0 +1,32 @@\n+#include <Common/ProfileEventsScope.h>\n+\n+namespace DB\n+{\n+\n+\n+ProfileEventsScope::ProfileEventsScope()\n+    : performance_counters_holder(std::make_unique<ProfileEvents::Counters>())\n+    , performance_counters_scope(performance_counters_holder.get())\n+    , previous_counters_scope(CurrentThread::get().attachProfileCountersScope(performance_counters_scope))\n+{\n+}\n+\n+ProfileEventsScope::ProfileEventsScope(ProfileEvents::Counters * performance_counters_scope_)\n+    : performance_counters_scope(performance_counters_scope_)\n+    , previous_counters_scope(CurrentThread::get().attachProfileCountersScope(performance_counters_scope))\n+{\n+}\n+\n+std::shared_ptr<ProfileEvents::Counters::Snapshot> ProfileEventsScope::getSnapshot()\n+{\n+    return std::make_shared<ProfileEvents::Counters::Snapshot>(performance_counters_scope->getPartiallyAtomicSnapshot());\n+}\n+\n+ProfileEventsScope::~ProfileEventsScope()\n+{\n+    /// Restore previous performance counters\n+    CurrentThread::get().attachProfileCountersScope(previous_counters_scope);\n+}\n+\n+\n+}\ndiff --git a/src/Common/ProfileEventsScope.h b/src/Common/ProfileEventsScope.h\nnew file mode 100644\nindex 000000000000..0444531d02b0\n--- /dev/null\n+++ b/src/Common/ProfileEventsScope.h\n@@ -0,0 +1,35 @@\n+#pragma once\n+\n+#include <Common/ProfileEvents.h>\n+#include <Common/CurrentThread.h>\n+\n+namespace DB\n+{\n+\n+/// Use specific performance counters for current thread in the current scope.\n+class ProfileEventsScope : private boost::noncopyable\n+{\n+public:\n+    /// Counters are owned by this object.\n+    ProfileEventsScope();\n+\n+    /// Shared counters are stored outside.\n+    /// Useful when we calculate metrics entering into some scope several times.\n+    explicit ProfileEventsScope(ProfileEvents::Counters * performance_counters_scope_);\n+\n+    std::shared_ptr<ProfileEvents::Counters::Snapshot> getSnapshot();\n+\n+    ~ProfileEventsScope();\n+\n+private:\n+    /// If set, then performance_counters_scope is owned by this object.\n+    /// Otherwise, counters are passed to the constructor from outside.\n+    std::unique_ptr<ProfileEvents::Counters> performance_counters_holder;\n+\n+    ProfileEvents::Counters * performance_counters_scope;\n+    ProfileEvents::Counters * previous_counters_scope;\n+};\n+\n+\n+}\n+\ndiff --git a/src/Common/ThreadStatus.h b/src/Common/ThreadStatus.h\nindex 69c5732ddb6e..20550a633121 100644\n--- a/src/Common/ThreadStatus.h\n+++ b/src/Common/ThreadStatus.h\n@@ -124,6 +124,10 @@ class ThreadStatus : public boost::noncopyable\n \n     /// TODO: merge them into common entity\n     ProfileEvents::Counters performance_counters{VariableContext::Thread};\n+\n+    /// Points to performance_counters by default.\n+    /// Could be changed to point to another object to calculate performance counters for some narrow scope.\n+    ProfileEvents::Counters * current_performance_counters{&performance_counters};\n     MemoryTracker memory_tracker{VariableContext::Thread};\n \n     /// Small amount of untracked memory (per thread atomic-less counter)\n@@ -139,6 +143,7 @@ class ThreadStatus : public boost::noncopyable\n     Deleter deleter;\n \n protected:\n+    /// Group of threads, to which this thread attached\n     ThreadGroupStatusPtr thread_group;\n \n     std::atomic<int> thread_state{ThreadState::DetachedFromQuery};\n@@ -244,6 +249,10 @@ class ThreadStatus : public boost::noncopyable\n     /// Attaches slave thread to existing thread group\n     void attachQuery(const ThreadGroupStatusPtr & thread_group_, bool check_detached = true);\n \n+    /// Returns pointer to the current profile counters to restore them back.\n+    /// Note: consequent call with new scope will detach previous scope.\n+    ProfileEvents::Counters * attachProfileCountersScope(ProfileEvents::Counters * performance_counters_scope);\n+\n     InternalTextLogsQueuePtr getInternalTextLogsQueue() const\n     {\n         return thread_state == Died ? nullptr : logs_queue_ptr.lock();\ndiff --git a/src/Interpreters/PartLog.cpp b/src/Interpreters/PartLog.cpp\nindex 4a1349680fd8..376501967839 100644\n--- a/src/Interpreters/PartLog.cpp\n+++ b/src/Interpreters/PartLog.cpp\n@@ -11,6 +11,9 @@\n #include <Storages/MergeTree/MergeTreeData.h>\n #include <Interpreters/PartLog.h>\n #include <Interpreters/Context.h>\n+#include <Interpreters/ProfileEventsExt.h>\n+#include <Common/ProfileEvents.h>\n+#include <DataTypes/DataTypeMap.h>\n \n #include <Common/CurrentThread.h>\n \n@@ -121,6 +124,17 @@ NamesAndTypesList PartLogElement::getNamesAndTypes()\n         /// Is there an error during the execution or commit\n         {\"error\", std::make_shared<DataTypeUInt16>()},\n         {\"exception\", std::make_shared<DataTypeString>()},\n+\n+        {\"ProfileEvents\", std::make_shared<DataTypeMap>(std::make_shared<DataTypeString>(), std::make_shared<DataTypeUInt64>())},\n+    };\n+}\n+\n+NamesAndAliases PartLogElement::getNamesAndAliases()\n+{\n+    return\n+    {\n+        {\"ProfileEvents.Names\", {std::make_shared<DataTypeArray>(std::make_shared<DataTypeString>())}, \"mapKeys(ProfileEvents)\"},\n+        {\"ProfileEvents.Values\", {std::make_shared<DataTypeArray>(std::make_shared<DataTypeUInt64>())}, \"mapValues(ProfileEvents)\"},\n     };\n }\n \n@@ -163,18 +177,20 @@ void PartLogElement::appendToBlock(MutableColumns & columns) const\n \n     columns[i++]->insert(error);\n     columns[i++]->insert(exception);\n-}\n \n-\n-bool PartLog::addNewPart(\n-    ContextPtr current_context, const MutableDataPartPtr & part, UInt64 elapsed_ns, const ExecutionStatus & execution_status)\n-{\n-    return addNewParts(current_context, {part}, elapsed_ns, execution_status);\n+    if (profile_counters)\n+    {\n+        auto * column = columns[i++].get();\n+        ProfileEvents::dumpToMapColumn(*profile_counters, column, true);\n+    }\n+    else\n+    {\n+        columns[i++]->insertDefault();\n+    }\n }\n \n-\n bool PartLog::addNewParts(\n-    ContextPtr current_context, const PartLog::MutableDataPartsVector & parts, UInt64 elapsed_ns, const ExecutionStatus & execution_status)\n+    ContextPtr current_context, const PartLog::PartLogEntries & parts, const ExecutionStatus & execution_status)\n {\n     if (parts.empty())\n         return true;\n@@ -183,15 +199,17 @@ bool PartLog::addNewParts(\n \n     try\n     {\n-        auto table_id = parts.front()->storage.getStorageID();\n+        auto table_id = parts.front().part->storage.getStorageID();\n         part_log = current_context->getPartLog(table_id.database_name); // assume parts belong to the same table\n         if (!part_log)\n             return false;\n \n         auto query_id = CurrentThread::getQueryId();\n \n-        for (const auto & part : parts)\n+        for (const auto & part_log_entry : parts)\n         {\n+            const auto & part = part_log_entry.part;\n+\n             PartLogElement elem;\n \n             if (!query_id.empty())\n@@ -204,7 +222,7 @@ bool PartLog::addNewParts(\n             const auto time_now = std::chrono::system_clock::now();\n             elem.event_time = timeInSeconds(time_now);\n             elem.event_time_microseconds = timeInMicroseconds(time_now);\n-            elem.duration_ms = elapsed_ns / 1000000;\n+            elem.duration_ms = part_log_entry.elapsed_ns / 1000000;\n \n             elem.database_name = table_id.database_name;\n             elem.table_name = table_id.table_name;\n@@ -221,6 +239,8 @@ bool PartLog::addNewParts(\n             elem.error = static_cast<UInt16>(execution_status.code);\n             elem.exception = execution_status.message;\n \n+            elem.profile_counters = part_log_entry.profile_counters;\n+\n             part_log->add(elem);\n         }\n     }\n@@ -233,4 +253,21 @@ bool PartLog::addNewParts(\n     return true;\n }\n \n+bool PartLog::addNewPart(ContextPtr context, const PartLog::PartLogEntry & part, const ExecutionStatus & execution_status)\n+{\n+    return addNewParts(context, {part}, execution_status);\n+}\n+\n+\n+PartLog::PartLogEntries PartLog::createPartLogEntries(const MutableDataPartsVector & parts, UInt64 elapsed_ns, ProfileCountersSnapshotPtr profile_counters)\n+{\n+    PartLogEntries part_log_entries;\n+    part_log_entries.reserve(parts.size());\n+\n+    for (const auto & part : parts)\n+        part_log_entries.emplace_back(part, elapsed_ns, profile_counters);\n+\n+    return part_log_entries;\n+}\n+\n }\ndiff --git a/src/Interpreters/PartLog.h b/src/Interpreters/PartLog.h\nindex 392e76d85d12..843792d03a9a 100644\n--- a/src/Interpreters/PartLog.h\n+++ b/src/Interpreters/PartLog.h\n@@ -8,6 +8,10 @@\n #include <Storages/MergeTree/MergeType.h>\n #include <Storages/MergeTree/MergeAlgorithm.h>\n \n+namespace ProfileEvents\n+{\n+    class Counters;\n+}\n \n namespace DB\n {\n@@ -81,13 +85,15 @@ struct PartLogElement\n     UInt16 error = 0;\n     String exception;\n \n+    std::shared_ptr<ProfileEvents::Counters::Snapshot> profile_counters;\n+\n     static std::string name() { return \"PartLog\"; }\n \n     static MergeReasonType getMergeReasonType(MergeType merge_type);\n     static PartMergeAlgorithm getMergeAlgorithm(MergeAlgorithm merge_algorithm_);\n \n     static NamesAndTypesList getNamesAndTypes();\n-    static NamesAndAliases getNamesAndAliases() { return {}; }\n+    static NamesAndAliases getNamesAndAliases();\n     void appendToBlock(MutableColumns & columns) const;\n     static const char * getCustomColumnList() { return nullptr; }\n };\n@@ -103,11 +109,37 @@ class PartLog : public SystemLog<PartLogElement>\n     using MutableDataPartPtr = std::shared_ptr<IMergeTreeDataPart>;\n     using MutableDataPartsVector = std::vector<MutableDataPartPtr>;\n \n+    using ProfileCountersSnapshotPtr = std::shared_ptr<ProfileEvents::Counters::Snapshot>;\n+\n public:\n+    struct PartLogEntry\n+    {\n+        std::shared_ptr<IMergeTreeDataPart> part;\n+        ProfileCountersSnapshotPtr profile_counters;\n+        UInt64 elapsed_ns;\n+\n+        PartLogEntry(std::shared_ptr<IMergeTreeDataPart> part_, UInt64 elapsed_ns_)\n+            : part(std::move(part_)), elapsed_ns(elapsed_ns_)\n+        {\n+        }\n+\n+        PartLogEntry(std::shared_ptr<IMergeTreeDataPart> part_, UInt64 elapsed_ns_, ProfileCountersSnapshotPtr profile_counters_)\n+            : part(std::move(part_))\n+            , profile_counters(std::move(profile_counters_))\n+            , elapsed_ns(elapsed_ns_)\n+        {\n+        }\n+    };\n+\n+    using PartLogEntries = std::vector<PartLogEntry>;\n+\n+    static PartLogEntries createPartLogEntries(const MutableDataPartsVector & parts, UInt64 elapsed_ns, ProfileCountersSnapshotPtr profile_counters = {});\n+\n     /// Add a record about creation of new part.\n-    static bool addNewPart(ContextPtr context, const MutableDataPartPtr & part, UInt64 elapsed_ns,\n+    static bool addNewPart(ContextPtr context, const PartLogEntry & part,\n                            const ExecutionStatus & execution_status = {});\n-    static bool addNewParts(ContextPtr context, const MutableDataPartsVector & parts, UInt64 elapsed_ns,\n+\n+    static bool addNewParts(ContextPtr context, const PartLogEntries & parts,\n                             const ExecutionStatus & execution_status = {});\n };\n \ndiff --git a/src/Interpreters/ThreadStatusExt.cpp b/src/Interpreters/ThreadStatusExt.cpp\nindex 816b03f3a0e0..84400fc37118 100644\n--- a/src/Interpreters/ThreadStatusExt.cpp\n+++ b/src/Interpreters/ThreadStatusExt.cpp\n@@ -161,6 +161,23 @@ void ThreadStatus::attachQuery(const ThreadGroupStatusPtr & thread_group_, bool\n     setupState(thread_group_);\n }\n \n+ProfileEvents::Counters * ThreadStatus::attachProfileCountersScope(ProfileEvents::Counters * performance_counters_scope)\n+{\n+    ProfileEvents::Counters * prev_counters = current_performance_counters;\n+\n+    if (current_performance_counters == performance_counters_scope)\n+        /// Allow to attach the same scope multiple times\n+        return prev_counters;\n+\n+    /// Avoid cycles when exiting local scope and attaching back to current thread counters\n+    if (performance_counters_scope != &performance_counters)\n+        performance_counters_scope->setParent(&performance_counters);\n+\n+    current_performance_counters = performance_counters_scope;\n+\n+    return prev_counters;\n+}\n+\n void ThreadStatus::initPerformanceCounters()\n {\n     performance_counters_finalized = false;\ndiff --git a/src/Storages/MergeTree/MergeFromLogEntryTask.cpp b/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\nindex 2d2013bd6485..a4e5b1f05751 100644\n--- a/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\n+++ b/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\n@@ -2,6 +2,7 @@\n \n #include <Common/logger_useful.h>\n #include <Common/ProfileEvents.h>\n+#include <Common/ProfileEventsScope.h>\n #include <Storages/StorageReplicatedMergeTree.h>\n \n namespace ProfileEvents\n@@ -289,9 +290,10 @@ ReplicatedMergeMutateTaskBase::PrepareResult MergeFromLogEntryTask::prepare()\n \n     return {true, true, [this, stopwatch = *stopwatch_ptr] (const ExecutionStatus & execution_status)\n     {\n+        auto profile_counters_snapshot = std::make_shared<ProfileEvents::Counters::Snapshot>(profile_counters.getPartiallyAtomicSnapshot());\n         storage.writePartLog(\n             PartLogElement::MERGE_PARTS, execution_status, stopwatch.elapsed(),\n-            entry.new_part_name, part, parts, merge_mutate_entry.get());\n+            entry.new_part_name, part, parts, merge_mutate_entry.get(), std::move(profile_counters_snapshot));\n     }};\n }\n \ndiff --git a/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp b/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp\nindex 9f24839f1e16..855b93dc90ee 100644\n--- a/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp\n+++ b/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp\n@@ -3,6 +3,7 @@\n #include <Storages/MergeTree/MergeTreeData.h>\n #include <Storages/StorageMergeTree.h>\n #include <Storages/MergeTree/MergeTreeDataMergerMutator.h>\n+#include <Common/ProfileEventsScope.h>\n \n namespace DB\n {\n@@ -27,6 +28,9 @@ void MergePlainMergeTreeTask::onCompleted()\n \n bool MergePlainMergeTreeTask::executeStep()\n {\n+    /// Metrics will be saved in the thread_group.\n+    ProfileEventsScope profile_events_scope(&profile_counters);\n+\n     /// Make out memory tracker a parent of current thread memory tracker\n     MemoryTrackerThreadSwitcherPtr switcher;\n     if (merge_list_entry)\n@@ -85,6 +89,7 @@ void MergePlainMergeTreeTask::prepare()\n \n     write_part_log = [this] (const ExecutionStatus & execution_status)\n     {\n+        auto profile_counters_snapshot = std::make_shared<ProfileEvents::Counters::Snapshot>(profile_counters.getPartiallyAtomicSnapshot());\n         merge_task.reset();\n         storage.writePartLog(\n             PartLogElement::MERGE_PARTS,\n@@ -93,7 +98,8 @@ void MergePlainMergeTreeTask::prepare()\n             future_part->name,\n             new_part,\n             future_part->parts,\n-            merge_list_entry.get());\n+            merge_list_entry.get(),\n+            std::move(profile_counters_snapshot));\n     };\n \n     merge_task = storage.merger_mutator.mergePartsToTemporaryPart(\ndiff --git a/src/Storages/MergeTree/MergePlainMergeTreeTask.h b/src/Storages/MergeTree/MergePlainMergeTreeTask.h\nindex d84db36bac2a..eb659bf38ec8 100644\n--- a/src/Storages/MergeTree/MergePlainMergeTreeTask.h\n+++ b/src/Storages/MergeTree/MergePlainMergeTreeTask.h\n@@ -6,6 +6,7 @@\n #include <Storages/MergeTree/MergeMutateSelectedEntry.h>\n #include <Interpreters/MergeTreeTransactionHolder.h>\n \n+\n namespace DB\n {\n \n@@ -46,7 +47,6 @@ class MergePlainMergeTreeTask : public IExecutableTask\n     }\n \n private:\n-\n     void prepare();\n     void finish();\n \n@@ -82,6 +82,8 @@ class MergePlainMergeTreeTask : public IExecutableTask\n \n     MergeTreeTransactionHolder txn_holder;\n     MergeTreeTransactionPtr txn;\n+\n+    ProfileEvents::Counters profile_counters;\n };\n \n \ndiff --git a/src/Storages/MergeTree/MergeTreeBackgroundExecutor.h b/src/Storages/MergeTree/MergeTreeBackgroundExecutor.h\nindex 5c1178a1bc1d..cf4d4b08c4d5 100644\n--- a/src/Storages/MergeTree/MergeTreeBackgroundExecutor.h\n+++ b/src/Storages/MergeTree/MergeTreeBackgroundExecutor.h\n@@ -17,6 +17,7 @@\n #include <base/defines.h>\n #include <Storages/MergeTree/IExecutableTask.h>\n \n+\n namespace DB\n {\n namespace ErrorCodes\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex c3c4cd3082de..d13452c291ea 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -10,6 +10,7 @@\n #include <Common/escapeForFileName.h>\n #include <Common/Increment.h>\n #include <Common/noexcept_scope.h>\n+#include <Common/ProfileEventsScope.h>\n #include <Common/quoteString.h>\n #include <Common/scope_guard_safe.h>\n #include <Common/SimpleIncrement.h>\n@@ -7280,7 +7281,8 @@ void MergeTreeData::writePartLog(\n     const String & new_part_name,\n     const DataPartPtr & result_part,\n     const DataPartsVector & source_parts,\n-    const MergeListEntry * merge_entry)\n+    const MergeListEntry * merge_entry,\n+    std::shared_ptr<ProfileEvents::Counters::Snapshot> profile_counters)\n try\n {\n     auto table_id = getStorageID();\n@@ -7342,6 +7344,15 @@ try\n         part_log_elem.peak_memory_usage = (*merge_entry)->memory_tracker.getPeak();\n     }\n \n+    if (profile_counters)\n+    {\n+        part_log_elem.profile_counters = profile_counters;\n+    }\n+    else\n+    {\n+        LOG_WARNING(log, \"Profile counters are not set\");\n+    }\n+\n     part_log->add(part_log_elem);\n }\n catch (...)\n@@ -7477,6 +7488,7 @@ bool MergeTreeData::moveParts(const CurrentlyMovingPartsTaggerPtr & moving_tagge\n     {\n         Stopwatch stopwatch;\n         MutableDataPartPtr cloned_part;\n+        ProfileEventsScope profile_events_scope;\n \n         auto write_part_log = [&](const ExecutionStatus & execution_status)\n         {\n@@ -7487,7 +7499,8 @@ bool MergeTreeData::moveParts(const CurrentlyMovingPartsTaggerPtr & moving_tagge\n                 moving_part.part->name,\n                 cloned_part,\n                 {moving_part.part},\n-                nullptr);\n+                nullptr,\n+                profile_events_scope.getSnapshot());\n         };\n \n         // Register in global moves list (StorageSystemMoves)\ndiff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h\nindex 34bc3d24d663..10ba0045826b 100644\n--- a/src/Storages/MergeTree/MergeTreeData.h\n+++ b/src/Storages/MergeTree/MergeTreeData.h\n@@ -1298,7 +1298,8 @@ class MergeTreeData : public IStorage, public WithMutableContext\n         const String & new_part_name,\n         const DataPartPtr & result_part,\n         const DataPartsVector & source_parts,\n-        const MergeListEntry * merge_entry);\n+        const MergeListEntry * merge_entry,\n+        std::shared_ptr<ProfileEvents::Counters::Snapshot> profile_counters);\n \n     /// If part is assigned to merge or mutation (possibly replicated)\n     /// Should be overridden by children, because they can have different\ndiff --git a/src/Storages/MergeTree/MergeTreeSink.cpp b/src/Storages/MergeTree/MergeTreeSink.cpp\nindex 99f6b1855e44..1e607767f867 100644\n--- a/src/Storages/MergeTree/MergeTreeSink.cpp\n+++ b/src/Storages/MergeTree/MergeTreeSink.cpp\n@@ -3,6 +3,7 @@\n #include <Storages/StorageMergeTree.h>\n #include <Interpreters/PartLog.h>\n #include <DataTypes/ObjectUtils.h>\n+#include <Common/ProfileEventsScope.h>\n \n namespace ProfileEvents\n {\n@@ -47,6 +48,7 @@ struct MergeTreeSink::DelayedChunk\n         MergeTreeDataWriter::TemporaryPart temp_part;\n         UInt64 elapsed_ns;\n         String block_dedup_token;\n+        ProfileEvents::Counters part_counters;\n     };\n \n     std::vector<Partition> partitions;\n@@ -70,12 +72,18 @@ void MergeTreeSink::consume(Chunk chunk)\n \n     for (auto & current_block : part_blocks)\n     {\n-        Stopwatch watch;\n-        String block_dedup_token;\n+        ProfileEvents::Counters part_counters;\n \n-        auto temp_part = storage.writer.writeTempPart(current_block, metadata_snapshot, context);\n+        UInt64 elapsed_ns = 0;\n+        MergeTreeDataWriter::TemporaryPart temp_part;\n \n-        UInt64 elapsed_ns = watch.elapsed();\n+        {\n+            ProfileEventsScope scoped_attach(&part_counters);\n+\n+            Stopwatch watch;\n+            temp_part = storage.writer.writeTempPart(current_block, metadata_snapshot, context);\n+            elapsed_ns = watch.elapsed();\n+        }\n \n         /// If optimize_on_insert setting is true, current_block could become empty after merge\n         /// and we didn't create part.\n@@ -85,6 +93,7 @@ void MergeTreeSink::consume(Chunk chunk)\n         if (!support_parallel_write && temp_part.part->getDataPartStorage().supportParallelWrite())\n             support_parallel_write = true;\n \n+        String block_dedup_token;\n         if (storage.getDeduplicationLog())\n         {\n             const String & dedup_token = settings.insert_deduplication_token;\n@@ -119,7 +128,8 @@ void MergeTreeSink::consume(Chunk chunk)\n         {\n             .temp_part = std::move(temp_part),\n             .elapsed_ns = elapsed_ns,\n-            .block_dedup_token = std::move(block_dedup_token)\n+            .block_dedup_token = std::move(block_dedup_token),\n+            .part_counters = std::move(part_counters),\n         });\n     }\n \n@@ -135,6 +145,8 @@ void MergeTreeSink::finishDelayedChunk()\n \n     for (auto & partition : delayed_chunk->partitions)\n     {\n+        ProfileEventsScope scoped_attach(&partition.part_counters);\n+\n         partition.temp_part.finalize();\n \n         auto & part = partition.temp_part.part;\n@@ -168,7 +180,8 @@ void MergeTreeSink::finishDelayedChunk()\n         /// Part can be deduplicated, so increment counters and add to part log only if it's really added\n         if (added)\n         {\n-            PartLog::addNewPart(storage.getContext(), part, partition.elapsed_ns);\n+            auto counters_snapshot = std::make_shared<ProfileEvents::Counters::Snapshot>(partition.part_counters.getPartiallyAtomicSnapshot());\n+            PartLog::addNewPart(storage.getContext(), PartLog::PartLogEntry(part, partition.elapsed_ns, counters_snapshot));\n             storage.incrementInsertedPartsProfileEvent(part->getType());\n \n             /// Initiate async merge - it will be done if it's good time for merge and if there are space in 'background_pool'.\ndiff --git a/src/Storages/MergeTree/MutateFromLogEntryTask.cpp b/src/Storages/MergeTree/MutateFromLogEntryTask.cpp\nindex b83c058f7fd3..4428f6c2bced 100644\n--- a/src/Storages/MergeTree/MutateFromLogEntryTask.cpp\n+++ b/src/Storages/MergeTree/MutateFromLogEntryTask.cpp\n@@ -184,9 +184,10 @@ ReplicatedMergeMutateTaskBase::PrepareResult MutateFromLogEntryTask::prepare()\n \n     return {true, true, [this] (const ExecutionStatus & execution_status)\n     {\n+        auto profile_counters_snapshot = std::make_shared<ProfileEvents::Counters::Snapshot>(profile_counters.getPartiallyAtomicSnapshot());\n         storage.writePartLog(\n             PartLogElement::MUTATE_PART, execution_status, stopwatch_ptr->elapsed(),\n-            entry.new_part_name, new_part, future_mutated_part->parts, merge_mutate_entry.get());\n+            entry.new_part_name, new_part, future_mutated_part->parts, merge_mutate_entry.get(), std::move(profile_counters_snapshot));\n     }};\n }\n \ndiff --git a/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp b/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp\nindex 76ba921b705b..9bd0f148d6cd 100644\n--- a/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp\n+++ b/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp\n@@ -2,6 +2,7 @@\n \n #include <Storages/StorageMergeTree.h>\n #include <Interpreters/TransactionLog.h>\n+#include <Common/ProfileEventsScope.h>\n \n namespace DB\n {\n@@ -38,6 +39,7 @@ void MutatePlainMergeTreeTask::prepare()\n \n     write_part_log = [this] (const ExecutionStatus & execution_status)\n     {\n+        auto profile_counters_snapshot = std::make_shared<ProfileEvents::Counters::Snapshot>(profile_counters.getPartiallyAtomicSnapshot());\n         mutate_task.reset();\n         storage.writePartLog(\n             PartLogElement::MUTATE_PART,\n@@ -46,7 +48,8 @@ void MutatePlainMergeTreeTask::prepare()\n             future_part->name,\n             new_part,\n             future_part->parts,\n-            merge_list_entry.get());\n+            merge_list_entry.get(),\n+            std::move(profile_counters_snapshot));\n     };\n \n     fake_query_context = Context::createCopy(storage.getContext());\n@@ -58,8 +61,12 @@ void MutatePlainMergeTreeTask::prepare()\n             time(nullptr), fake_query_context, merge_mutate_entry->txn, merge_mutate_entry->tagger->reserved_space, table_lock_holder);\n }\n \n+\n bool MutatePlainMergeTreeTask::executeStep()\n {\n+    /// Metrics will be saved in the local profile_counters.\n+    ProfileEventsScope profile_events_scope(&profile_counters);\n+\n     /// Make out memory tracker a parent of current thread memory tracker\n     MemoryTrackerThreadSwitcherPtr switcher;\n     if (merge_list_entry)\n@@ -123,5 +130,4 @@ bool MutatePlainMergeTreeTask::executeStep()\n     return false;\n }\n \n-\n }\ndiff --git a/src/Storages/MergeTree/MutatePlainMergeTreeTask.h b/src/Storages/MergeTree/MutatePlainMergeTreeTask.h\nindex e2b019c08ce5..ae2ac039543e 100644\n--- a/src/Storages/MergeTree/MutatePlainMergeTreeTask.h\n+++ b/src/Storages/MergeTree/MutatePlainMergeTreeTask.h\n@@ -9,6 +9,7 @@\n #include <Storages/MutationCommands.h>\n #include <Storages/MergeTree/MergeMutateSelectedEntry.h>\n \n+\n namespace DB\n {\n \n@@ -76,6 +77,8 @@ class MutatePlainMergeTreeTask : public IExecutableTask\n \n     ContextMutablePtr fake_query_context;\n     MutateTaskPtr mutate_task;\n+\n+    ProfileEvents::Counters profile_counters;\n };\n \n \ndiff --git a/src/Storages/MergeTree/MutateTask.cpp b/src/Storages/MergeTree/MutateTask.cpp\nindex 4a7224b0722b..43cf3d950b2b 100644\n--- a/src/Storages/MergeTree/MutateTask.cpp\n+++ b/src/Storages/MergeTree/MutateTask.cpp\n@@ -20,6 +20,7 @@\n #include <Storages/MutationCommands.h>\n #include <Storages/MergeTree/MergeTreeDataMergerMutator.h>\n #include <boost/algorithm/string/replace.hpp>\n+#include <Common/ProfileEventsScope.h>\n \n \n namespace CurrentMetrics\n@@ -898,6 +899,7 @@ class MergeProjectionPartsTask : public IExecutableTask\n         /// Need execute again\n         return true;\n     }\n+\n private:\n     String name;\n     MergeTreeData::MutableDataPartsVector parts;\n@@ -1253,6 +1255,7 @@ class MutateAllPartColumnsTask : public IExecutableTask\n     std::unique_ptr<PartMergerWriter> part_merger_writer_task;\n };\n \n+\n class MutateSomePartColumnsTask : public IExecutableTask\n {\n public:\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.cpp b/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.cpp\nindex a22aab8d6cef..9ce7eb426668 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.cpp\n@@ -2,6 +2,7 @@\n \n #include <Storages/StorageReplicatedMergeTree.h>\n #include <Storages/MergeTree/ReplicatedMergeTreeQueue.h>\n+#include <Common/ProfileEventsScope.h>\n \n \n namespace DB\n@@ -29,6 +30,9 @@ void ReplicatedMergeMutateTaskBase::onCompleted()\n \n bool ReplicatedMergeMutateTaskBase::executeStep()\n {\n+    /// Metrics will be saved in the local profile_counters.\n+    ProfileEventsScope profile_events_scope(&profile_counters);\n+\n     std::exception_ptr saved_exception;\n \n     bool retryable_error = false;\n@@ -83,7 +87,6 @@ bool ReplicatedMergeMutateTaskBase::executeStep()\n         saved_exception = std::current_exception();\n     }\n \n-\n     if (!retryable_error && saved_exception)\n     {\n         std::lock_guard lock(storage.queue.state_mutex);\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.h b/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.h\nindex d8495d35d90e..d9a1cbff166b 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.h\n+++ b/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.h\n@@ -5,6 +5,7 @@\n #include <Storages/MergeTree/IExecutableTask.h>\n #include <Storages/MergeTree/ReplicatedMergeTreeQueue.h>\n \n+\n namespace DB\n {\n \n@@ -59,9 +60,10 @@ class ReplicatedMergeMutateTaskBase : public IExecutableTask\n     MergeList::EntryPtr merge_mutate_entry{nullptr};\n     Poco::Logger * log;\n     StorageReplicatedMergeTree & storage;\n+    /// ProfileEvents for current part will be stored here\n+    ProfileEvents::Counters profile_counters;\n \n private:\n-\n     enum class CheckExistingPartResult\n     {\n         PART_EXISTS,\n@@ -69,7 +71,7 @@ class ReplicatedMergeMutateTaskBase : public IExecutableTask\n     };\n \n     CheckExistingPartResult checkExistingPart();\n-    bool executeImpl() ;\n+    bool executeImpl();\n \n     enum class State\n     {\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp\nindex ee192966758a..31fd99f0aa1b 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp\n@@ -2,6 +2,7 @@\n #include <Storages/MergeTree/ReplicatedMergeTreeQuorumEntry.h>\n #include <Storages/MergeTree/ReplicatedMergeTreeSink.h>\n #include <Interpreters/PartLog.h>\n+#include <Common/ProfileEventsScope.h>\n #include <Common/SipHash.h>\n #include <Common/ZooKeeper/KeeperException.h>\n #include <Common/ThreadFuzzer.h>\n@@ -48,14 +49,21 @@ struct ReplicatedMergeTreeSinkImpl<async_insert>::DelayedChunk\n         BlockIDsType block_id;\n         BlockWithPartition block_with_partition;\n         std::unordered_map<String, std::vector<size_t>> block_id_to_offset_idx;\n+        ProfileEvents::Counters part_counters;\n \n         Partition() = default;\n-        Partition(Poco::Logger * log_, MergeTreeDataWriter::TemporaryPart && temp_part_, UInt64 elapsed_ns_, BlockIDsType && block_id_, BlockWithPartition && block_)\n+        Partition(Poco::Logger * log_,\n+                  MergeTreeDataWriter::TemporaryPart && temp_part_,\n+                  UInt64 elapsed_ns_,\n+                  BlockIDsType && block_id_,\n+                  BlockWithPartition && block_,\n+                  ProfileEvents::Counters && part_counters_)\n             : log(log_),\n               temp_part(std::move(temp_part_)),\n               elapsed_ns(elapsed_ns_),\n               block_id(std::move(block_id_)),\n-              block_with_partition(std::move(block_))\n+              block_with_partition(std::move(block_)),\n+              part_counters(std::move(part_counters_))\n         {\n                 initBlockIDMap();\n         }\n@@ -186,8 +194,9 @@ std::vector<Int64> testSelfDeduplicate(std::vector<Int64> data, std::vector<size\n     Block block({ColumnWithTypeAndName(std::move(column), DataTypePtr(new DataTypeInt64()), \"a\")});\n \n     BlockWithPartition block1(std::move(block), Row(), std::move(offsets));\n+    ProfileEvents::Counters profile_counters;\n     ReplicatedMergeTreeSinkImpl<true>::DelayedChunk::Partition part(\n-        &Poco::Logger::get(\"testSelfDeduplicate\"), MergeTreeDataWriter::TemporaryPart(), 0, std::move(hashes), std::move(block1));\n+        &Poco::Logger::get(\"testSelfDeduplicate\"), MergeTreeDataWriter::TemporaryPart(), 0, std::move(hashes), std::move(block1), std::move(profile_counters));\n \n     part.filterSelfDuplicate();\n \n@@ -411,6 +420,9 @@ void ReplicatedMergeTreeSinkImpl<async_insert>::consume(Chunk chunk)\n     {\n         Stopwatch watch;\n \n+        ProfileEvents::Counters part_counters;\n+        auto profile_events_scope = std::make_unique<ProfileEventsScope>(&part_counters);\n+\n         /// Write part to the filesystem under temporary name. Calculate a checksum.\n \n         auto temp_part = storage.writer.writeTempPart(current_block, metadata_snapshot, context);\n@@ -452,6 +464,7 @@ void ReplicatedMergeTreeSinkImpl<async_insert>::consume(Chunk chunk)\n             LOG_DEBUG(log, \"Wrote block with {} rows{}\", current_block.block.rows(), quorumLogMessage(replicas_num));\n         }\n \n+        profile_events_scope.reset();\n         UInt64 elapsed_ns = watch.elapsed();\n \n         size_t max_insert_delayed_streams_for_parallel_write = DEFAULT_DELAYED_STREAMS_FOR_PARALLEL_WRITE;\n@@ -472,12 +485,14 @@ void ReplicatedMergeTreeSinkImpl<async_insert>::consume(Chunk chunk)\n             partitions = DelayedPartitions{};\n         }\n \n+\n         partitions.emplace_back(DelayedPartition(\n             log,\n             std::move(temp_part),\n             elapsed_ns,\n             std::move(block_id),\n-            std::move(current_block)\n+            std::move(current_block),\n+            std::move(part_counters) /// profile_events_scope must be reset here.\n         ));\n     }\n \n@@ -503,6 +518,8 @@ void ReplicatedMergeTreeSinkImpl<false>::finishDelayedChunk(const ZooKeeperWithF\n \n     for (auto & partition : delayed_chunk->partitions)\n     {\n+        ProfileEventsScope scoped_attach(&partition.part_counters);\n+\n         partition.temp_part.finalize();\n \n         auto & part = partition.temp_part.part;\n@@ -515,12 +532,14 @@ void ReplicatedMergeTreeSinkImpl<false>::finishDelayedChunk(const ZooKeeperWithF\n \n             /// Set a special error code if the block is duplicate\n             int error = (deduplicate && part->is_duplicate) ? ErrorCodes::INSERT_WAS_DEDUPLICATED : 0;\n-            PartLog::addNewPart(storage.getContext(), part, partition.elapsed_ns, ExecutionStatus(error));\n+            auto counters_snapshot = std::make_shared<ProfileEvents::Counters::Snapshot>(partition.part_counters.getPartiallyAtomicSnapshot());\n+            PartLog::addNewPart(storage.getContext(), PartLog::PartLogEntry(part, partition.elapsed_ns, counters_snapshot), ExecutionStatus(error));\n             storage.incrementInsertedPartsProfileEvent(part->getType());\n         }\n         catch (...)\n         {\n-            PartLog::addNewPart(storage.getContext(), part, partition.elapsed_ns, ExecutionStatus::fromCurrentException(\"\", true));\n+            auto counters_snapshot = std::make_shared<ProfileEvents::Counters::Snapshot>(partition.part_counters.getPartiallyAtomicSnapshot());\n+            PartLog::addNewPart(storage.getContext(), PartLog::PartLogEntry(part, partition.elapsed_ns, counters_snapshot), ExecutionStatus::fromCurrentException(\"\", true));\n             throw;\n         }\n     }\n@@ -579,16 +598,17 @@ void ReplicatedMergeTreeSinkImpl<async_insert>::writeExistingPart(MergeTreeData:\n     size_t replicas_num = checkQuorumPrecondition(zookeeper);\n \n     Stopwatch watch;\n+    ProfileEventsScope profile_events_scope;\n \n     try\n     {\n         part->version.setCreationTID(Tx::PrehistoricTID, nullptr);\n         commitPart(zookeeper, part, BlockIDsType(), replicas_num, true);\n-        PartLog::addNewPart(storage.getContext(), part, watch.elapsed());\n+        PartLog::addNewPart(storage.getContext(), PartLog::PartLogEntry(part, watch.elapsed(), profile_events_scope.getSnapshot()));\n     }\n     catch (...)\n     {\n-        PartLog::addNewPart(storage.getContext(), part, watch.elapsed(), ExecutionStatus::fromCurrentException(\"\", true));\n+        PartLog::addNewPart(storage.getContext(), PartLog::PartLogEntry(part, watch.elapsed(), profile_events_scope.getSnapshot()), ExecutionStatus::fromCurrentException(\"\", true));\n         throw;\n     }\n }\ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex 125322281d00..9e98946baebc 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -8,6 +8,7 @@\n #include <Backups/BackupEntriesCollector.h>\n #include <Databases/IDatabase.h>\n #include <Common/escapeForFileName.h>\n+#include <Common/ProfileEventsScope.h>\n #include <Common/typeid_cast.h>\n #include <Common/ThreadPool.h>\n #include <Interpreters/InterpreterAlterQuery.h>\n@@ -1608,6 +1609,7 @@ void StorageMergeTree::truncate(const ASTPtr &, const StorageMetadataPtr &, Cont\n         waitForOutdatedPartsToBeLoaded();\n \n         Stopwatch watch;\n+        ProfileEventsScope profile_events_scope;\n \n         auto txn = query_context->getCurrentTransaction();\n         MergeTreeData::Transaction transaction(*this, txn.get());\n@@ -1628,7 +1630,7 @@ void StorageMergeTree::truncate(const ASTPtr &, const StorageMetadataPtr &, Cont\n             auto new_data_parts = createEmptyDataParts(*this, future_parts, txn);\n             renameAndCommitEmptyParts(new_data_parts, transaction);\n \n-            PartLog::addNewParts(query_context, new_data_parts, watch.elapsed());\n+            PartLog::addNewParts(query_context, PartLog::createPartLogEntries(new_data_parts, watch.elapsed(), profile_events_scope.getSnapshot()));\n \n             LOG_INFO(log, \"Truncated table with {} parts by replacing them with new empty {} parts. With txn {}\",\n                      parts.size(), future_parts.size(),\n@@ -1650,6 +1652,7 @@ void StorageMergeTree::dropPart(const String & part_name, bool detach, ContextPt\n         auto merge_blocker = stopMergesAndWait();\n \n         Stopwatch watch;\n+        ProfileEventsScope profile_events_scope;\n \n         /// It's important to create it outside of lock scope because\n         /// otherwise it can lock parts in destructor and deadlock is possible.\n@@ -1681,7 +1684,7 @@ void StorageMergeTree::dropPart(const String & part_name, bool detach, ContextPt\n                 auto new_data_parts = createEmptyDataParts(*this, future_parts, txn);\n                 renameAndCommitEmptyParts(new_data_parts, transaction);\n \n-                PartLog::addNewParts(query_context, new_data_parts, watch.elapsed());\n+                PartLog::addNewParts(query_context, PartLog::createPartLogEntries(new_data_parts, watch.elapsed(), profile_events_scope.getSnapshot()));\n \n                 const auto * op = detach ? \"Detached\" : \"Dropped\";\n                 LOG_INFO(log, \"{} {} part by replacing it with new empty {} part. With txn {}\",\n@@ -1707,6 +1710,7 @@ void StorageMergeTree::dropPartition(const ASTPtr & partition, bool detach, Cont\n         auto merge_blocker = stopMergesAndWait();\n \n         Stopwatch watch;\n+        ProfileEventsScope profile_events_scope;\n \n         /// It's important to create it outside of lock scope because\n         /// otherwise it can lock parts in destructor and deadlock is possible.\n@@ -1746,7 +1750,7 @@ void StorageMergeTree::dropPartition(const ASTPtr & partition, bool detach, Cont\n             auto new_data_parts = createEmptyDataParts(*this, future_parts, txn);\n             renameAndCommitEmptyParts(new_data_parts, transaction);\n \n-            PartLog::addNewParts(query_context, new_data_parts, watch.elapsed());\n+            PartLog::addNewParts(query_context, PartLog::createPartLogEntries(new_data_parts, watch.elapsed(), profile_events_scope.getSnapshot()));\n \n             const auto * op = detach ? \"Detached\" : \"Dropped\";\n             LOG_INFO(log, \"{} partition with {} parts by replacing them with new empty {} parts. With txn {}\",\n@@ -1814,6 +1818,8 @@ void StorageMergeTree::replacePartitionFrom(const StoragePtr & source_table, con\n     auto my_metadata_snapshot = getInMemoryMetadataPtr();\n \n     Stopwatch watch;\n+    ProfileEventsScope profile_events_scope;\n+\n     MergeTreeData & src_data = checkStructureAndGetMergeTreeData(source_table, source_metadata_snapshot, my_metadata_snapshot);\n     String partition_id = getPartitionIDFromQuery(partition, local_context);\n \n@@ -1878,11 +1884,12 @@ void StorageMergeTree::replacePartitionFrom(const StoragePtr & source_table, con\n                 removePartsInRangeFromWorkingSet(local_context->getCurrentTransaction().get(), drop_range, data_parts_lock);\n         }\n \n-        PartLog::addNewParts(getContext(), dst_parts, watch.elapsed());\n+        /// Note: same elapsed time and profile events for all parts is used\n+        PartLog::addNewParts(getContext(), PartLog::createPartLogEntries(dst_parts, watch.elapsed(), profile_events_scope.getSnapshot()));\n     }\n     catch (...)\n     {\n-        PartLog::addNewParts(getContext(), dst_parts, watch.elapsed(), ExecutionStatus::fromCurrentException(\"\", true));\n+        PartLog::addNewParts(getContext(), PartLog::createPartLogEntries(dst_parts, watch.elapsed()), ExecutionStatus::fromCurrentException(\"\", true));\n         throw;\n     }\n }\n@@ -1909,6 +1916,7 @@ void StorageMergeTree::movePartitionToTable(const StoragePtr & dest_table, const\n     auto dest_metadata_snapshot = dest_table->getInMemoryMetadataPtr();\n     auto metadata_snapshot = getInMemoryMetadataPtr();\n     Stopwatch watch;\n+    ProfileEventsScope profile_events_scope;\n \n     MergeTreeData & src_data = dest_table_storage->checkStructureAndGetMergeTreeData(*this, metadata_snapshot, dest_metadata_snapshot);\n     String partition_id = getPartitionIDFromQuery(partition, local_context);\n@@ -1961,11 +1969,12 @@ void StorageMergeTree::movePartitionToTable(const StoragePtr & dest_table, const\n \n         clearOldPartsFromFilesystem();\n \n-        PartLog::addNewParts(getContext(), dst_parts, watch.elapsed());\n+        /// Note: same elapsed time and profile events for all parts is used\n+        PartLog::addNewParts(getContext(), PartLog::createPartLogEntries(dst_parts, watch.elapsed(), profile_events_scope.getSnapshot()));\n     }\n     catch (...)\n     {\n-        PartLog::addNewParts(getContext(), dst_parts, watch.elapsed(), ExecutionStatus::fromCurrentException(\"\", true));\n+        PartLog::addNewParts(getContext(), PartLog::createPartLogEntries(dst_parts, watch.elapsed()), ExecutionStatus::fromCurrentException(\"\", true));\n         throw;\n     }\n }\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 0fb3e25ee85b..e2844431e342 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -2,8 +2,10 @@\n \n #include <cstddef>\n #include <ranges>\n-#include \"Common/hex.h\"\n+\n+#include <Common/hex.h>\n #include <Common/Macros.h>\n+#include <Common/ProfileEventsScope.h>\n #include <Common/StringUtils/StringUtils.h>\n #include <Common/ZooKeeper/KeeperException.h>\n #include <Common/ZooKeeper/Types.h>\n@@ -1592,6 +1594,8 @@ bool StorageReplicatedMergeTree::executeLogEntry(LogEntry & entry)\n \n     if (entry.type == LogEntry::ATTACH_PART)\n     {\n+        ProfileEventsScope profile_events_scope;\n+\n         if (MutableDataPartPtr part = attachPartHelperFoundValidPart(entry))\n         {\n             LOG_TRACE(log, \"Found valid local part for {}, preparing the transaction\", part->name);\n@@ -1603,7 +1607,8 @@ bool StorageReplicatedMergeTree::executeLogEntry(LogEntry & entry)\n             checkPartChecksumsAndCommit(transaction, part);\n \n             writePartLog(PartLogElement::Type::NEW_PART, {}, 0 /** log entry is fake so we don't measure the time */,\n-                part->name, part, {} /** log entry is fake so there are no initial parts */, nullptr);\n+                part->name, part, {} /** log entry is fake so there are no initial parts */, nullptr,\n+                profile_events_scope.getSnapshot());\n \n             return true;\n         }\n@@ -1947,6 +1952,8 @@ void StorageReplicatedMergeTree::executeDropRange(const LogEntry & entry)\n bool StorageReplicatedMergeTree::executeReplaceRange(const LogEntry & entry)\n {\n     Stopwatch watch;\n+    ProfileEventsScope profile_events_scope;\n+\n     auto & entry_replace = *entry.replace_range_entry;\n     LOG_DEBUG(log, \"Executing log entry {} to replace parts range {} with {} parts from {}.{}\",\n               entry.znode_name, entry_replace.drop_range_part_name, entry_replace.new_part_names.size(),\n@@ -2339,11 +2346,11 @@ bool StorageReplicatedMergeTree::executeReplaceRange(const LogEntry & entry)\n             }\n         }\n \n-        PartLog::addNewParts(getContext(), res_parts, watch.elapsed());\n+        PartLog::addNewParts(getContext(), PartLog::createPartLogEntries(res_parts, watch.elapsed(), profile_events_scope.getSnapshot()));\n     }\n     catch (...)\n     {\n-        PartLog::addNewParts(getContext(), res_parts, watch.elapsed(), ExecutionStatus::fromCurrentException(\"\", true));\n+        PartLog::addNewParts(getContext(), PartLog::createPartLogEntries(res_parts, watch.elapsed()), ExecutionStatus::fromCurrentException(\"\", true));\n \n         for (const auto & res_part : res_parts)\n             unlockSharedData(*res_part);\n@@ -4004,12 +4011,14 @@ bool StorageReplicatedMergeTree::fetchPart(\n     Stopwatch stopwatch;\n     MutableDataPartPtr part;\n     DataPartsVector replaced_parts;\n+    ProfileEventsScope profile_events_scope;\n \n     auto write_part_log = [&] (const ExecutionStatus & execution_status)\n     {\n         writePartLog(\n             PartLogElement::DOWNLOAD_PART, execution_status, stopwatch.elapsed(),\n-            part_name, part, replaced_parts, nullptr);\n+            part_name, part, replaced_parts, nullptr,\n+            profile_events_scope.getSnapshot());\n     };\n \n     DataPartPtr part_to_clone;\n@@ -4240,12 +4249,14 @@ MutableDataPartStoragePtr StorageReplicatedMergeTree::fetchExistsPart(\n     Stopwatch stopwatch;\n     MutableDataPartPtr part;\n     DataPartsVector replaced_parts;\n+    ProfileEventsScope profile_events_scope;\n \n     auto write_part_log = [&] (const ExecutionStatus & execution_status)\n     {\n         writePartLog(\n             PartLogElement::DOWNLOAD_PART, execution_status, stopwatch.elapsed(),\n-            part_name, part, replaced_parts, nullptr);\n+            part_name, part, replaced_parts, nullptr,\n+            profile_events_scope.getSnapshot());\n     };\n \n     std::function<MutableDataPartPtr()> get_part;\n@@ -6878,6 +6889,8 @@ void StorageReplicatedMergeTree::replacePartitionFrom(\n     auto metadata_snapshot = getInMemoryMetadataPtr();\n \n     Stopwatch watch;\n+    ProfileEventsScope profile_events_scope;\n+\n     MergeTreeData & src_data = checkStructureAndGetMergeTreeData(source_table, source_metadata_snapshot, metadata_snapshot);\n     String partition_id = getPartitionIDFromQuery(partition, query_context);\n \n@@ -7054,11 +7067,11 @@ void StorageReplicatedMergeTree::replacePartitionFrom(\n                     parts_to_remove = removePartsInRangeFromWorkingSetAndGetPartsToRemoveFromZooKeeper(NO_TRANSACTION_RAW, drop_range, data_parts_lock);\n             }\n \n-            PartLog::addNewParts(getContext(), dst_parts, watch.elapsed());\n+            PartLog::addNewParts(getContext(), PartLog::createPartLogEntries(dst_parts, watch.elapsed(), profile_events_scope.getSnapshot()));\n         }\n         catch (...)\n         {\n-            PartLog::addNewParts(getContext(), dst_parts, watch.elapsed(), ExecutionStatus::fromCurrentException(\"\", true));\n+            PartLog::addNewParts(getContext(), PartLog::createPartLogEntries(dst_parts, watch.elapsed()), ExecutionStatus::fromCurrentException(\"\", true));\n             for (const auto & dst_part : dst_parts)\n                 unlockSharedData(*dst_part);\n \n@@ -7113,6 +7126,8 @@ void StorageReplicatedMergeTree::movePartitionToTable(const StoragePtr & dest_ta\n     auto metadata_snapshot = getInMemoryMetadataPtr();\n \n     Stopwatch watch;\n+    ProfileEventsScope profile_events_scope;\n+\n     MergeTreeData & src_data = dest_table_storage->checkStructureAndGetMergeTreeData(*this, metadata_snapshot, dest_metadata_snapshot);\n     auto src_data_id = src_data.getStorageID();\n     String partition_id = getPartitionIDFromQuery(partition, query_context);\n@@ -7283,11 +7298,11 @@ void StorageReplicatedMergeTree::movePartitionToTable(const StoragePtr & dest_ta\n                 transaction.commit(&src_data_parts_lock);\n             }\n \n-            PartLog::addNewParts(getContext(), dst_parts, watch.elapsed());\n+            PartLog::addNewParts(getContext(), PartLog::createPartLogEntries(dst_parts, watch.elapsed(), profile_events_scope.getSnapshot()));\n         }\n         catch (...)\n         {\n-            PartLog::addNewParts(getContext(), dst_parts, watch.elapsed(), ExecutionStatus::fromCurrentException(\"\", true));\n+            PartLog::addNewParts(getContext(), PartLog::createPartLogEntries(dst_parts, watch.elapsed()), ExecutionStatus::fromCurrentException(\"\", true));\n \n             for (const auto & dst_part : dst_parts)\n                 dest_table_storage->unlockSharedData(*dst_part);\n",
  "test_patch": "diff --git a/src/Storages/MergeTree/tests/gtest_executor.cpp b/src/Storages/MergeTree/tests/gtest_executor.cpp\nindex b89692869fdf..601492206430 100644\n--- a/src/Storages/MergeTree/tests/gtest_executor.cpp\n+++ b/src/Storages/MergeTree/tests/gtest_executor.cpp\n@@ -75,8 +75,7 @@ TEST(Executor, RemoveTasks)\n     for (size_t i = 0; i < batch; ++i)\n         for (size_t j = 0; j < tasks_kinds; ++j)\n             ASSERT_TRUE(\n-                executor->trySchedule(std::make_shared<FakeExecutableTask>(std::to_string(j)))\n-            );\n+                executor->trySchedule(std::make_shared<FakeExecutableTask>(std::to_string(j))));\n \n     std::vector<std::thread> threads(batch);\n \ndiff --git a/tests/queries/0_stateless/02378_part_log_profile_events.reference b/tests/queries/0_stateless/02378_part_log_profile_events.reference\nnew file mode 100644\nindex 000000000000..c09e6c997c50\n--- /dev/null\n+++ b/tests/queries/0_stateless/02378_part_log_profile_events.reference\n@@ -0,0 +1,3 @@\n+Ok\tOk\tOk\tOk\tOk\tOk\n+Ok\tOk\n+Ok\tOk\tOk\ndiff --git a/tests/queries/0_stateless/02378_part_log_profile_events.sql b/tests/queries/0_stateless/02378_part_log_profile_events.sql\nnew file mode 100644\nindex 000000000000..38d3f8b4c057\n--- /dev/null\n+++ b/tests/queries/0_stateless/02378_part_log_profile_events.sql\n@@ -0,0 +1,50 @@\n+DROP TABLE IF EXISTS test;\n+\n+CREATE TABLE test (key UInt64, val UInt64) engine = MergeTree Order by key PARTITION BY key >= 128;\n+\n+SET max_block_size = 64, max_insert_block_size = 64, min_insert_block_size_rows = 64;\n+\n+INSERT INTO test SELECT number AS key, sipHash64(number) AS val FROM numbers(512);\n+\n+SYSTEM FLUSH LOGS;\n+\n+SELECT\n+    if(count(DISTINCT query_id) == 1, 'Ok', 'Error: ' || toString(count(DISTINCT query_id))),\n+    if(count() == 512 / 64, 'Ok', 'Error: ' || toString(count())), -- 512 rows inserted, 64 rows per block\n+    if(SUM(ProfileEvents['MergeTreeDataWriterRows']) == 512, 'Ok', 'Error: ' || toString(SUM(ProfileEvents['MergeTreeDataWriterRows']))),\n+    if(SUM(ProfileEvents['MergeTreeDataWriterUncompressedBytes']) >= 1024, 'Ok', 'Error: ' || toString(SUM(ProfileEvents['MergeTreeDataWriterUncompressedBytes']))),\n+    if(SUM(ProfileEvents['MergeTreeDataWriterCompressedBytes']) >= 1024, 'Ok', 'Error: ' || toString(SUM(ProfileEvents['MergeTreeDataWriterCompressedBytes']))),\n+    if(SUM(ProfileEvents['MergeTreeDataWriterBlocks']) >= 8, 'Ok', 'Error: ' || toString(SUM(ProfileEvents['MergeTreeDataWriterBlocks'])))\n+FROM system.part_log\n+WHERE event_time > now() - INTERVAL 10 MINUTE\n+    AND database == currentDatabase() AND table == 'test'\n+    AND event_type == 'NewPart'\n+;\n+\n+OPTIMIZE TABLE test FINAL;\n+\n+SYSTEM FLUSH LOGS;\n+SELECT\n+    if(count() > 2, 'Ok', 'Error: ' || toString(count())),\n+    if(SUM(ProfileEvents['MergedRows']) >= 512, 'Ok', 'Error: ' || toString(SUM(ProfileEvents['MergedRows'])))\n+FROM system.part_log\n+WHERE event_time > now() - INTERVAL 10 MINUTE\n+    AND database == currentDatabase() AND table == 'test'\n+    AND event_type == 'MergeParts'\n+;\n+\n+ALTER TABLE test UPDATE val = 0 WHERE key % 2 == 0 SETTINGS mutations_sync = 2;\n+\n+SYSTEM FLUSH LOGS;\n+\n+SELECT\n+    if(count() == 2, 'Ok', 'Error: ' || toString(count())),\n+    if(SUM(ProfileEvents['MergedRows']) == 512, 'Ok', 'Error: ' || toString(SUM(ProfileEvents['MergedRows']))),\n+    if(SUM(ProfileEvents['FileOpen']) > 1, 'Ok', 'Error: ' || toString(SUM(ProfileEvents['FileOpen'])))\n+FROM system.part_log\n+WHERE event_time > now() - INTERVAL 10 MINUTE\n+    AND database == currentDatabase() AND table == 'test'\n+    AND event_type == 'MutatePart'\n+;\n+\n+DROP TABLE test;\ndiff --git a/tests/queries/0_stateless/02378_part_log_profile_events_replicated.reference b/tests/queries/0_stateless/02378_part_log_profile_events_replicated.reference\nnew file mode 100644\nindex 000000000000..d00491fd7e5b\n--- /dev/null\n+++ b/tests/queries/0_stateless/02378_part_log_profile_events_replicated.reference\n@@ -0,0 +1,1 @@\n+1\ndiff --git a/tests/queries/0_stateless/02378_part_log_profile_events_replicated.sql b/tests/queries/0_stateless/02378_part_log_profile_events_replicated.sql\nnew file mode 100644\nindex 000000000000..d61b680bb878\n--- /dev/null\n+++ b/tests/queries/0_stateless/02378_part_log_profile_events_replicated.sql\n@@ -0,0 +1,40 @@\n+\n+-- Tags: long, replica, no-replicated-database, no-parallel\n+\n+DROP TABLE IF EXISTS part_log_profile_events_r1 NO DELAY;\n+DROP TABLE IF EXISTS part_log_profile_events_r2 NO DELAY;\n+\n+CREATE TABLE part_log_profile_events_r1 (x UInt64)\n+ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/test_02378/part_log_profile_events', 'r1')\n+ORDER BY x\n+PARTITION BY x >= 128\n+;\n+\n+CREATE TABLE part_log_profile_events_r2 (x UInt64)\n+ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/test_02378/part_log_profile_events', 'r2')\n+ORDER BY x\n+PARTITION BY x >= 128\n+;\n+\n+-- SYSTEM STOP MERGES part_log_profile_events_r1;\n+-- SYSTEM STOP MERGES part_log_profile_events_r2;\n+\n+SET max_block_size = 64, max_insert_block_size = 64, min_insert_block_size_rows = 64;\n+\n+INSERT INTO part_log_profile_events_r1 SELECT number FROM numbers(1000);\n+\n+SYSTEM SYNC REPLICA part_log_profile_events_r2;\n+\n+SYSTEM FLUSH LOGS;\n+\n+SELECT\n+    count() > 1\n+    AND SUM(ProfileEvents['ZooKeeperTransactions']) >= 4\n+FROM system.part_log\n+WHERE event_time > now() - INTERVAL 10 MINUTE\n+    AND database == currentDatabase() AND table == 'part_log_profile_events_r2'\n+    AND event_type == 'DownloadPart'\n+;\n+\n+DROP TABLE part_log_profile_events_r1 NO DELAY;\n+DROP TABLE part_log_profile_events_r2 NO DELAY;\n",
  "problem_statement": "metrics in system.part_log\nAdd columns ProfileEvents.Names, ProfileEvents.Values for system.part_log.\r\nThis will help to track resource usage for merges.\r\n\r\nThis task is needed for Yandex Morda.\n",
  "hints_text": "i think this issue is familar with https://github.com/ClickHouse/ClickHouse/issues/26255 \r\n",
  "created_at": "2022-06-30T03:54:38Z"
}