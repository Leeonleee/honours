{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 62366,
  "instance_id": "ClickHouse__ClickHouse-62366",
  "issue_numbers": [
    "59597"
  ],
  "base_commit": "633aeaaa765ae5de46451659391d62b48ec3b1f3",
  "patch": "diff --git a/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.cpp b/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.cpp\nindex b083c5400839..d874612ad04a 100644\n--- a/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.cpp\n+++ b/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.cpp\n@@ -56,7 +56,6 @@ UserDefinedSQLObjectsDiskStorage::UserDefinedSQLObjectsDiskStorage(const Context\n     , dir_path{makeDirectoryPathCanonical(dir_path_)}\n     , log{getLogger(\"UserDefinedSQLObjectsLoaderFromDisk\")}\n {\n-    createDirectory();\n }\n \n \n@@ -122,7 +121,12 @@ void UserDefinedSQLObjectsDiskStorage::reloadObjects()\n void UserDefinedSQLObjectsDiskStorage::loadObjectsImpl()\n {\n     LOG_INFO(log, \"Loading user defined objects from {}\", dir_path);\n-    createDirectory();\n+\n+    if (!std::filesystem::exists(dir_path))\n+    {\n+        LOG_DEBUG(log, \"The directory for user defined objects ({}) does not exist: nothing to load\", dir_path);\n+        return;\n+    }\n \n     std::vector<std::pair<String, ASTPtr>> function_names_and_queries;\n \n@@ -157,7 +161,6 @@ void UserDefinedSQLObjectsDiskStorage::loadObjectsImpl()\n \n void UserDefinedSQLObjectsDiskStorage::reloadObject(UserDefinedSQLObjectType object_type, const String & object_name)\n {\n-    createDirectory();\n     auto ast = tryLoadObject(object_type, object_name);\n     if (ast)\n         setObject(object_name, *ast);\n@@ -185,6 +188,7 @@ bool UserDefinedSQLObjectsDiskStorage::storeObjectImpl(\n     bool replace_if_exists,\n     const Settings & settings)\n {\n+    createDirectory();\n     String file_path = getFilePath(object_type, object_name);\n     LOG_DEBUG(log, \"Storing user-defined object {} to file {}\", backQuote(object_name), file_path);\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03033_analyzer_query_parameters.sh b/tests/queries/0_stateless/03033_analyzer_query_parameters.sh\nindex c821791e4378..cf46067df993 100755\n--- a/tests/queries/0_stateless/03033_analyzer_query_parameters.sh\n+++ b/tests/queries/0_stateless/03033_analyzer_query_parameters.sh\n@@ -4,5 +4,5 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n . \"$CURDIR\"/../shell_config.sh\n \n-clickhouse-local --param_rounding 1 --query \"SELECT 1 AS x ORDER BY x WITH FILL STEP {rounding:UInt32} SETTINGS allow_experimental_analyzer = 1\"\n-clickhouse-local --param_rounding 1 --query \"SELECT 1 AS x ORDER BY x WITH FILL STEP {rounding:UInt32} SETTINGS allow_experimental_analyzer = 0\"\n+${CLICKHOUSE_LOCAL} --param_rounding 1 --query \"SELECT 1 AS x ORDER BY x WITH FILL STEP {rounding:UInt32} SETTINGS allow_experimental_analyzer = 1\"\n+${CLICKHOUSE_LOCAL} --param_rounding 1 --query \"SELECT 1 AS x ORDER BY x WITH FILL STEP {rounding:UInt32} SETTINGS allow_experimental_analyzer = 0\"\ndiff --git a/tests/queries/0_stateless/03036_udf_user_defined_directory_in_client.reference b/tests/queries/0_stateless/03036_udf_user_defined_directory_in_client.reference\nnew file mode 100644\nindex 000000000000..251d054748a5\n--- /dev/null\n+++ b/tests/queries/0_stateless/03036_udf_user_defined_directory_in_client.reference\n@@ -0,0 +1,1 @@\n+Unknown function\ndiff --git a/tests/queries/0_stateless/03036_udf_user_defined_directory_in_client.sh b/tests/queries/0_stateless/03036_udf_user_defined_directory_in_client.sh\nnew file mode 100755\nindex 000000000000..e0a145d84566\n--- /dev/null\n+++ b/tests/queries/0_stateless/03036_udf_user_defined_directory_in_client.sh\n@@ -0,0 +1,15 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+${CLICKHOUSE_CLIENT} --query \"DROP TABLE IF EXISTS test\"\n+${CLICKHOUSE_CLIENT} --query \"CREATE TABLE test (s String) ENGINE = Memory\"\n+\n+# Calling an unknown function should not lead to creation of a 'user_defined' directory in the current directory\n+${CLICKHOUSE_CLIENT} --query \"INSERT INTO test VALUES (xyz('abc'))\" 2>&1 | grep -o -F 'Unknown function'\n+\n+ls -ld user_defined 2> /dev/null\n+\n+${CLICKHOUSE_CLIENT} --query \"DROP TABLE test\"\n",
  "problem_statement": "user_defined directory is getting created in my user home directory\n\r\nI updated our clickhouse-server container a few weeks ago. I use clickhouse-client on a physical server through some scripts, and It started complaining about not having permission somewhere, but I wasn't able to determine where it was having a problem, as the message was pretty cryptic.  I ran clickhouse-client in the script as sudo, and it worked as expected.  I was now able to run this anytime afterward without using sudo.  The problem is now clickhouse-client (I think) is creating the directory, user_defined, in my home directory.  If I delete the directory, it is recreated the next time the scripts run.  Is this some sort of configuration issue?  I'm not sure if this is the result of updating the clickhouse-server container, or if clickhouse-client is the problem (which is on a physical server and updates regularly via apt upgrade).\r\n\r\nThis is now occurring in both our dev and production environments.\r\n\r\nWe are running on Ubuntu 20.04:\r\nClickHouse client version 24.1.2.5 (official build)\r\nClickHouse server version 23.9.2\r\n\r\nThe error that was being thrown (less the record) before running clickhouse-client as sudo:\r\n\r\nCode: 83. DB::Exception: Couldn't create directory /user_defined/ reason: 'Permission denied': While executing ValuesBlockInputFormat: data for INSERT was parsed from query: (in query: insert into XXX values(XXX). (DIRECTORY_DOESNT_EXIST)\r\n\r\nWe aren't using any user_defined things, so I'm not quite sure how to fix this.\r\nthanks,\r\n          david\r\n\n",
  "hints_text": ">  Is this some sort of configuration issue? \r\n\r\nYes, please check `path` in the config\nWe're been running the same config for over two years, so not sure how that could have changed, unless the update changes something. We're not doing any user defined things, as I mentioned, so there is not a function.xml\r\nThe path in the config, should be default, is:  \r\n<path>/var/lib/clickhouse/</path>  \r\n<tmp_path>/var/lib/clickhouse/tmp/</tmp_path>\r\n<user_files_path>/var/lib/clickhouse/user_files/</user_files_path>\r\nI don't see anything else, especially anything related to \"user_defined\".\r\nI'm going to run through the process again this morning to see if I can get any more incite into what's going on, but I'm certainly open to suggestions.\r\n\n> The path in the config, should be default, is:\r\n> /var/lib/clickhouse/\r\n\r\nIs it explicitly specified in the config? Like `<path>/var/lib/clickhouse/</path>`? I guess `path` is not configured, so it uses current directory\nYes, I showed that /var/lib/clickhouse was the default setting\r\n<!-- Path to data directory, with trailing slash. -->\r\n<path>/var/lib/clickhouse/</path>\r\nBut are you saying that entry should be in the clickhouse-client config.xml?\r\nI don't modify that from install, but that directive does not exist in that file.\r\n\r\nI ran through my process again, and isolated it to an insert.  This is the command:\r\n clickhouse-client --database=My_DB --query=\"insert into My_Table values(XXX)\"\r\nIt does this every time I do an insert.\n> But are you saying that entry should be in the clickhouse-client config.xml?\r\n\r\nYes. \r\n\r\nHowever, it should use `/var/lib/clickhouse/` if `path` is not specified in the config. And it does, except for a few places, including loading of executable UDFs: https://github.com/ClickHouse/ClickHouse/pull/59654\nI'm sorry, I'm a little confused.  That path doesn't exist on my physical server, which clickhouse-client is running, it only exists in the clickhouse-server container.  And you're also stating that clickhouse-client \"should\" be using that path, /var/lib/clickhouse, if one is not specified in the clickhouse-client config.xml file... correct?\r\n\r\nShould I add that to the clickhouse-client config.xml file then??\r\nAnd if yes, then should it look like this?:\r\n\\<path>/var/lib/clickhouse/\\</path>\"\nAh, sorry, no, I've mistakenly read \"clickhouse-client config.xml\" as \"clickhouse-server config.xml\". No, clickhouse-client should not create any directories at all. You should add `<path>/var/lib/clickhouse/</path>` to the server's config\nOkay good.  As I stated above, that path **does** exist in my clickhouse-server config.xml file.\nThen there's no way it could create the directory at another location. Are you sure you run clickhouse-server with the same config.xml that does contain `path`? Do you have some overrides in config.d? Or do you have `<user_defined_path>` in the config or overrides? It makes sense to check `preprocessed_configs/config.xml` as well\nAs I mentioned above, I've not changed any of my configurations, only updated the programs.\r\nAll of my configs reside in the config.d directory.\r\n\r\nI don't see any configs for anything called user_defined*\r\ngrep -R \"user_defined\" *\r\nconfig.d/config.xml:    <user_defined_executable_functions_config>*_function.xml</user_defined_executable_functions_config>\r\nconfig.xml:    <user_defined_executable_functions_config>*_function.*ml</user_defined_executable_functions_config>\r\nconfig.xml:    <!-- <user_defined_zookeeper_path>/clickhouse/user_defined</user_defined_zookeeper_path> -->\r\n\r\nI don't have anything called \"preprocessed_config\" that I can find.\r\n\r\nIf it helps, I could rollback my clickhouse-server container and see if that makes a difference... since clickhouse-client doesn't create directories.\r\n\n> I don't have anything called \"preprocessed_config\"\r\n\r\nIt's impossible. It must be in `/var/lib/clickhouse/` (or where `path` is set to)\nSorry, I misunderstood you as that being under config.d.\r\ngrep \"user_defined\" /var/lib/clickhouse/preprocessed_configs/config.xml \r\n    <user_defined_executable_functions_config>*_function.xml</user_defined_executable_functions_config>\r\n    <!-- <user_defined_zookeeper_path>/clickhouse/user_defined</user_defined_zookeeper_path> -->\r\n\r\nI also tried to rollback to the previous version, and it now refuses to run with this error below.  Going back to the initial version starts up and runs okay again.  I don't know if this could be of any help:\r\n\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]:  (version 22.8.16.32 (official build))\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 2024.02.06 16:56:45.266835 [ 130 ] {} <Error> My_DB.My_Table (39c86b2e-55f5-49ac-a3d7-4210835ad9d5): Detaching broken part /var/lib/clickhouse/store/39c/39c86b2e-55f5-49ac-a3d7-4210835ad9d5/2024_7792_8260_146 (size: 225.32 KiB). If it happened after update, it is likely because of backward incompatibility. You need to resolve this manually\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 2024.02.06 16:56:45.270444 [ 1 ] {} <Error> Application: Caught exception while loading metadata: Code: 231. DB::Exception: Suspiciously many (15 parts, 5.10 MiB in total) broken parts to remove while maximum allowed broken parts count is 10. You can change the maximum value with merge tree setting 'max_suspicious_broken_parts' in <merge_tree> configuration section or in table settings in .sql file (don't forget to return setting back to default value): Cannot attach table `MY_DB`.`My_Table` from metadata file /var/lib/clickhouse/store/8ee/8ee1b480-209b-4f75-9022-9d70000d60bc/My_Table.sql from query ATTACH TABLE My_DB.My_Table UUID '39c86b2e-55f5-49ac-a3d7-4210835ad9d5' (`entity` String CODEC(ZSTD(1)), `host` String CODEC(ZSTD(1)), `item` String CODEC(ZSTD(1)), `measurement` String CODEC(ZSTD(1)), `m_interval` UInt32 CODEC(ZSTD(1)), `m_timestamp` DateTime CODEC(Delta(4), ZSTD(1)), `val1` Nullable(Float64) CODEC(Delta(8), ZSTD(6)), `val2` Nullable(Float64) CODEC(Delta(8), ZSTD(6)), `val3` Nullable(Float64) CODEC(Delta(8), ZSTD(6)), `val4` Nullable(Float64) CODEC(Delta(8), ZSTD(6))) ENGINE = MergeTree PARTITION BY toYear(m_timestamp) ORDER BY (measurement, item, host, m_timestamp) SETTINGS index_granularity = 32768, min_merge_bytes_to_use_direct_io = 999999999999999999. (TOO_MANY_UNEXPECTED_DATA_PARTS), Stack trace (when copying this message, always include the lines below):\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xa40285a in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 1. DB::Exception::Exception<unsigned long&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, DB::SettingFieldNumber<unsigned long> const&>(int, fmt::v8::basic_format_string<char, fmt::v8::type_identity<unsigned long&>::type, fmt::v8::type_identity<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >::type, fmt::v8::type_identity<DB::SettingFieldNumber<unsigned long> const&>::type>, unsigned long&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >&&, DB::SettingFieldNumber<unsigned long> const&) @ 0x1588e310 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 2. DB::MergeTreeData::loadDataPartsFromDisk(std::__1::vector<std::__1::shared_ptr<DB::IMergeTreeDataPart const>, std::__1::allocator<std::__1::shared_ptr<DB::IMergeTreeDataPart const> > >&, std::__1::vector<std::__1::shared_ptr<DB::IMergeTreeDataPart const>, std::__1::allocator<std::__1::shared_ptr<DB::IMergeTreeDataPart const> > >&, ThreadPoolImpl<ThreadFromGlobalPool>&, unsigned long, std::__1::queue<std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> > > >, std::__1::deque<std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> > > >, std::__1::allocator<std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> > > > > > >&, bool, std::__1::shared_ptr<DB::MergeTreeSettings const> const&) @ 0x1588d629 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 3. DB::MergeTreeData::loadDataParts(bool) @ 0x15890623 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 4. DB::StorageMergeTree::StorageMergeTree(DB::StorageID const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::StorageInMemoryMetadata const&, bool, std::__1::shared_ptr<DB::Context>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::MergeTreeData::MergingParams const&, std::__1::unique_ptr<DB::MergeTreeSettings, std::__1::default_delete<DB::MergeTreeSettings> >, bool) @ 0x156278a8 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 5. ? @ 0x15b21f20 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 6. DB::StorageFactory::get(DB::ASTCreateQuery const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::Context>, std::__1::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, bool) const @ 0x15455703 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 7. DB::createTableFromAST(DB::ASTCreateQuery, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::Context>, bool) @ 0x14288e95 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 8. DB::DatabaseOrdinary::loadTableFromMetadata(std::__1::shared_ptr<DB::Context>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::QualifiedTableName const&, std::__1::shared_ptr<DB::IAST> const&, DB::LoadingStrictnessLevel) @ 0x14336e89 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 9. ? @ 0x14566eea in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 10. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0xa4c6ae6 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 11. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>(void&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0xa4c8437 in /usr/bin/clickhouseFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]:  (version 22.8.16.32 (official build))\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 2024.02.06 16:56:45.266835 [ 130 ] {} <Error> My_DB.My_Table (39c86b2e-55f5-49ac-a3d7-4210835ad9d5): Detaching broken part /var/lib/clickhouse/store/39c/39c86b2e-55f5-49ac-a3d7-4210835ad9d5/2024_7792_8260_146 (size: 225.32 KiB). If it happened after update, it is likely because of backward incompatibility. You need to resolve this manually\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 2024.02.06 16:56:45.270444 [ 1 ] {} <Error> Application: Caught exception while loading metadata: Code: 231. DB::Exception: Suspiciously many (15 parts, 5.10 MiB in total) broken parts to remove while maximum allowed broken parts count is 10. You can change the maximum value with merge tree setting 'max_suspicious_broken_parts' in <merge_tree> configuration section or in table settings in .sql file (don't forget to return setting back to default value): Cannot attach table `MY_DB`.`My_Table` from metadata file /var/lib/clickhouse/store/8ee/8ee1b480-209b-4f75-9022-9d70000d60bc/My_Table.sql from query ATTACH TABLE My_DB.My_Table UUID '39c86b2e-55f5-49ac-a3d7-4210835ad9d5' (`entity` String CODEC(ZSTD(1)), `host` String CODEC(ZSTD(1)), `item` String CODEC(ZSTD(1)), `measurement` String CODEC(ZSTD(1)), `m_interval` UInt32 CODEC(ZSTD(1)), `m_timestamp` DateTime CODEC(Delta(4), ZSTD(1)), `val1` Nullable(Float64) CODEC(Delta(8), ZSTD(6)), `val2` Nullable(Float64) CODEC(Delta(8), ZSTD(6)), `val3` Nullable(Float64) CODEC(Delta(8), ZSTD(6)), `val4` Nullable(Float64) CODEC(Delta(8), ZSTD(6))) ENGINE = MergeTree PARTITION BY toYear(m_timestamp) ORDER BY (measurement, item, host, m_timestamp) SETTINGS index_granularity = 32768, min_merge_bytes_to_use_direct_io = 999999999999999999. (TOO_MANY_UNEXPECTED_DATA_PARTS), Stack trace (when copying this message, always include the lines below):\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xa40285a in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 1. DB::Exception::Exception<unsigned long&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, DB::SettingFieldNumber<unsigned long> const&>(int, fmt::v8::basic_format_string<char, fmt::v8::type_identity<unsigned long&>::type, fmt::v8::type_identity<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >::type, fmt::v8::type_identity<DB::SettingFieldNumber<unsigned long> const&>::type>, unsigned long&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >&&, DB::SettingFieldNumber<unsigned long> const&) @ 0x1588e310 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 2. DB::MergeTreeData::loadDataPartsFromDisk(std::__1::vector<std::__1::shared_ptr<DB::IMergeTreeDataPart const>, std::__1::allocator<std::__1::shared_ptr<DB::IMergeTreeDataPart const> > >&, std::__1::vector<std::__1::shared_ptr<DB::IMergeTreeDataPart const>, std::__1::allocator<std::__1::shared_ptr<DB::IMergeTreeDataPart const> > >&, ThreadPoolImpl<ThreadFromGlobalPool>&, unsigned long, std::__1::queue<std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> > > >, std::__1::deque<std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> > > >, std::__1::allocator<std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::shared_ptr<DB::IDisk> > > > > > >&, bool, std::__1::shared_ptr<DB::MergeTreeSettings const> const&) @ 0x1588d629 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 3. DB::MergeTreeData::loadDataParts(bool) @ 0x15890623 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 4. DB::StorageMergeTree::StorageMergeTree(DB::StorageID const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::StorageInMemoryMetadata const&, bool, std::__1::shared_ptr<DB::Context>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::MergeTreeData::MergingParams const&, std::__1::unique_ptr<DB::MergeTreeSettings, std::__1::default_delete<DB::MergeTreeSettings> >, bool) @ 0x156278a8 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 5. ? @ 0x15b21f20 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 6. DB::StorageFactory::get(DB::ASTCreateQuery const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::Context>, std::__1::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, bool) const @ 0x15455703 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 7. DB::createTableFromAST(DB::ASTCreateQuery, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::Context>, bool) @ 0x14288e95 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 8. DB::DatabaseOrdinary::loadTableFromMetadata(std::__1::shared_ptr<DB::Context>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::QualifiedTableName const&, std::__1::shared_ptr<DB::IAST> const&, DB::LoadingStrictnessLevel) @ 0x14336e89 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 9. ? @ 0x14566eea in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 10. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0xa4c6ae6 in /usr/bin/clickhouse\r\nFeb  6 08:56:45 3 3 server 313281e4d8e0[3746799]: 11. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>(void&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0xa4c8437 in /usr/bin/clickhouse\r\n\r\n\nI see these are unrelated issues.  I fixed the issue above, and was able to rollback successfully now.\r\nI again attempted the insert and the directory is again created.\nwell, I guess I didn't fix the problem.  When I rolled back to the previous configuration, it errors out.  When I go back to the initial container version, it runs, but it wipes out the table completely.  I restored the table and tried it again, and it again wipes out the entire table.  What would one do in this situation?\r\nRestoring the data in the current container works okay... all the data returns.\r\n\r\nI keep 30 days of data on the server and i've been working backwards, and so far all do the same thing.\r\nWhen restoring the data in the older version container, none of the data return and this error gets posted:\r\n\r\n2024/02/06 10:51:02.766991 error can't attach partitions for table 'My_DB.My_Table': code: 226, message: Marks file '/var/lib/clickhouse/store/250/25048407-e89b-4386-bc52-9e7365bbb029/detached/attaching_2023_1_12_3_134/data.mrk3' doesn't exist.\r\n\r\nLooking through all my backups, this file never existed.  Is this something that was recently created?  The previous version of clickhouse-server we were running was: 23.9.2.56, vs the most recent version: 23.12.2.59\r\n\r\nI'm at a loss of what to do next?  Do I just restore to the most recent version and leave it alone or is there some corrective action I should be taking?\r\n\r\nI found an article by Denny Crane suggesting that the broken directory be removed as a way of solving this problem.\r\nWe did that and it cleared up the broken parts issue.  We are now back to normal it appears.  Is this the right process\r\nto follow?\r\nI now rolled back to the previous container, and now we have 22 broken parts again.  Is this behavior expected for containers?  These probably get shutdown without stopping clickhouse i'd guess.\r\n\r\nBTW - the original problems of writing the directory user_defined still exists :)\r\nI also tried deleting the user_defined and user_files directories from the /var/lib/clickhouse, and these do not get recreated on the insert.  Only the user_defined does get created in my home directory, not the user_files directory.\r\n\r\n\nno further responses?\nI reset the environment and when through my process again.  The original issue is now back, where clickhouse doesn't think it has permission to write the directory.  If I run my script with sudo, it will pass, but will start writing the \"user_defined\" directory in my home directory.\r\n\r\nWe updated clickhouse-server in dev to the latest, with the same results.\r\nWe are running on Ubuntu 20.04:\r\nClickHouse client version 24.1.2.5 (official build)\r\nClickHouse server version 24.1.2.5 \r\n\r\nCode: 83. DB::Exception: Couldn't create directory /user_defined/ reason: 'Permission denied': While executing ValuesBlockInputFormat: data for INSERT was parsed from query: (in query: insert into My_Table values(X). (DIRECTORY_DOESNT_EXIST)\r\n\r\nAny ideas how to fix this??\r\n\r\nHere are all the path setting from preprocessed_configs/config.xml\r\n        <ssl_cert_file>/path/to/ssl_cert_file</ssl_cert_file>\r\n        <ssl_key_file>/path/to/ssl_key_file</ssl_key_file>\r\n        <ssl_ca_cert_file>/path/to/ssl_ca_cert_file</ssl_ca_cert_file>\r\n    <!-- Cache path for custom (created from SQL) cached disks -->\r\n    <!-- Path to data directory, with trailing slash. -->\r\n    \\<path>/var/lib/clickhouse/\\</path>\r\n                \\<path>/data/\\</path>\r\n                \\<endpoint>http://path/to/endpoint \\</endpoint>\r\n                \\<metadata_path>/var/lib/clickhouse/disks/blob_storage_disk/\\</metadata_path>\r\n    <!-- Path to temporary data for processing hard queries. -->\r\n    \\<tmp_path>/var/lib/clickhouse/tmp/\\</tmp_path>\r\n         If not set <tmp_path> is used, otherwise <tmp_path> is ignored.\r\n    \\<user_files_path>/var/lib/clickhouse/user_files/\\</user_files_path>\r\n                tls_cert_file - path to certificate file.\r\n                tls_key_file - path to certificate key file.\r\n                tls_ca_cert_file - path to CA certificate file.\r\n                tls_ca_cert_dir - path to the directory containing CA certificates.\r\n                    <tls_cert_file>/path/to/tls_cert_file</tls_cert_file>\r\n                    <tls_key_file>/path/to/tls_key_file</tls_key_file>\r\n                    <tls_ca_cert_file>/path/to/tls_ca_cert_file</tls_ca_cert_file>\r\n                    <tls_ca_cert_dir>/path/to/tls_ca_cert_dir</tls_ca_cert_dir>\r\n                tls_cert_file - path to certificate file.\r\n                tls_key_file - path to certificate key file.\r\n                tls_ca_cert_file - path to CA certificate file.\r\n                tls_ca_cert_dir - path to the directory containing CA certificates.\r\n                    <tls_cert_file>/path/to/tls_cert_file</tls_cert_file>\r\n                    <tls_key_file>/path/to/tls_key_file</tls_key_file>\r\n                    <tls_ca_cert_file>/path/to/tls_ca_cert_file</tls_ca_cert_file>\r\n                    <tls_ca_cert_dir>/path/to/tls_ca_cert_dir</tls_ca_cert_dir>\r\n            <!-- Path to configuration file with predefined users. -->\r\n            \\<path>users.xml\\</path>\r\n            <!-- Path to configuration file with predefined users. -->\r\n            <!-- Path to folder where users created by SQL commands are stored. -->\r\n           \\<path>/var/lib/clickhouse/access/\\</path>\r\n            <!-- Path to folder where users created by SQL commands are stored. -->\r\n         By default, path to file with substitutions is /etc/metrika.xml. It could be changed in config in 'include_from' element.\r\n        root_path - prefix for keys\r\n        hostname_in_path - append hostname to root_path (default = true)\r\n        \\<root_path>one_min\\</root_path>\r\n        \\<hostname_in_path>true\\</hostname_in_path>\r\n        \\<root_path>one_sec\\</root_path>\r\n        endpoint - mertics path (relative to root, statring with \"/\")\r\n    <!-- <top_level_domains_path>/var/lib/clickhouse/top_level_domains/</top_level_domains_path> -->\r\n         Format: <name>/path/to/file</name>\r\n         Path to the list is under top_level_domains_path (see above).\r\n        \\<public_suffix_list>/path/to/public_suffix_list.dat\\</public_suffix_list>\r\n        \\<public_suffix_list>/path/to/public_suffix_list.dat\\</public_suffix_list>\r\n    <!-- Path in ZooKeeper to store user-defined SQL functions created by the command CREATE FUNCTION.\r\n    <!-- <user_defined_zookeeper_path>/clickhouse/user_defined</user_defined_zookeeper_path> -->\r\n        <!-- Path in ZooKeeper to queue with DDL queries -->\r\n        \\<path>/clickhouse/jeda_cluster/task_queue/ddl\\</path>\r\n        <!-- Path in ZooKeeper to queue with DDL queries -->\r\n         If you want do delete one table and don't want to change clickhouse-server config\r\n\\<details>\\<summary>Details\\</summary>\r\n\\</details> , you could create special file <clickhouse-path>/flags/force_drop_table and make DROP once.\r\n    <!-- Directory in <clickhouse-path> containing schema files for various input formats.\r\n    \\<format_schema_path>/var/lib/clickhouse/format_schemas/\\</format_schema_path>\r\n    \\<google_protos_path>/usr/share/clickhouse/protos/\\</google_protos_path>\r\n        \\<allowed_path>backups\\</allowed_path>\r\n    <!-- Path to data directory, with trailing slash. -->\r\n    <!-- Path to temporary data for processing hard queries. -->\r\n         If not set <tmp_path> is used, otherwise <tmp_path> is ignored.\r\n         By default, path to file with substitutions is /etc/metrika.xml. It could be changed in config in 'include_from' element.\r\n        root_path - prefix for keys\r\n        hostname_in_path - append hostname to root_path (default = true)\r\n        \\<root_path>one_min\\</root_path>\r\n        \\<hostname_in_path>true\\</hostname_in_path>\r\n        \\<root_path>one_sec\\</root_path>\r\n        endpoint - mertics path (relative to root, statring with \"/\")\r\n    <!-- Path to file with region hierarchy. -->\r\n    <!-- <path_to_regions_hierarchy_file>/opt/geo/regions_hierarchy.txt</path_to_regions_hierarchy_file> -->\r\n    <!-- Path to directory with files containing names of regions -->\r\n    <!-- <path_to_regions_names_files>/opt/geo/</path_to_regions_names_files> -->\r\n    <!-- <top_level_domains_path>/var/lib/clickhouse/top_level_domains/</top_level_domains_path> -->\r\n         Format: <name>/path/to/file</name>\r\n         Path to the list is under top_level_domains_path (see above).\r\n         If you want do delete one table and don't want to change clickhouse-server config, you could create special file <clickhouse-path>/flags/force_drop_table and make DROP once.\r\n    <!-- Directory in <clickhouse-path> containing schema files for various input formats.\r\n\nNot sure if this helps or not. I turned on trace for logging.  It looks like it's showing that the clickhouse-client is terminating the query.  Would clickhouse-client be looking for the user_defined directory?\r\n\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.455339 [ 48 ] {} <Debug> TCPHandler: Connected ClickHouse client version 24.1.0, revision: 54466, database: My_DB, user: default.\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.456360 [ 48 ] {} <Debug> TCP-Session: 5f524ff4-36ac-4f24-86b5-8872ed7a35bc Authenticating user 'default' from 10.0.0.6:38342\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.457097 [ 48 ] {} <Debug> TCP-Session: 5f524ff4-36ac-4f24-86b5-8872ed7a35bc Authenticated with global context as user 94309d50-4f52-5250-31bd-74fecac179db\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.457621 [ 48 ] {} <Debug> TCP-Session: 5f524ff4-36ac-4f24-86b5-8872ed7a35bc Creating session context with user_id: 94309d50-4f52-5250-31bd-74fecac179db\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.494296 [ 48 ] {} <Trace> TCP-Session: 5f524ff4-36ac-4f24-86b5-8872ed7a35bc Creating query context from session context, user_id: 94309d50-4f52-5250-31bd-74fecac179db, parent context user: default\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.496465 [ 48 ] {5d2440e8-e4c8-4bcf-bb23-9a817cfa1626} <Debug> executeQuery: (from 10.0.0.6:38342) insert into My_Table values (stage: Complete)\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.497281 [ 48 ] {5d2440e8-e4c8-4bcf-bb23-9a817cfa1626} <Trace> ContextAccess (default): Access granted: INSERT(MY_DATA) ON My_DB.My_Table\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.505539 [ 48 ] {5d2440e8-e4c8-4bcf-bb23-9a817cfa1626} <Information> TCPHandler: Change cancellation status from NOT_CANCELLED to FULLY_CANCELLED. Log message: Received 'Cancel' packet from the client, canceling the query.\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.521520 [ 48 ] {5d2440e8-e4c8-4bcf-bb23-9a817cfa1626} <Information> executeQuery: Code: 394. DB::Exception: Query was cancelled or a client has unexpectedly dropped the connection. (**QUERY_WAS_CANCELLED**) (version 23.12.2.59 (official build)) (from 10.0.0.6:38342) (in query: insert into My_Table values)\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.522424 [ 48 ] {5d2440e8-e4c8-4bcf-bb23-9a817cfa1626} <Debug> TCPHandler: Processed in 0.029306216 sec.\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.524586 [ 48 ] {} <Debug> TCPHandler: Done processing connection.\r\nFeb 12 09:28:32 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:32.524954 [ 48 ] {} <Debug> TCP-Session: 5f524ff4-36ac-4f24-86b5-8872ed7a35bc Logout, user_id: 94309d50-4f52-5250-31bd-74fecac179db\r\nFeb 12 09:28:33 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:33.721600 [ 731 ] {} <Trace> SystemLog (system.metric_log): Flushing system log, 7 entries to flush up to offset 447\r\nFeb 12 09:28:33 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:33.748358 [ 731 ] {} <Trace> system.metric_log (71864658-8943-47a6-adf5-35ade28b33ba): Trying to reserve 1.00 MiB using storage policy from min volume index 0\r\nFeb 12 09:28:33 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:33.748511 [ 731 ] {} <Trace> DiskLocal: Reserved 1.00 MiB on local disk `default`, having unreserved 16.02 GiB.\r\nFeb 12 09:28:33 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:33.763067 [ 731 ] {} <Trace> MergedBlockOutputStream: filled checksums 202402_59_59_0 (state Temporary)\r\nFeb 12 09:28:33 3 3 node4 2ae9822fa3d7[1150]: 2024.02.12 17:28:33.774339 [ 731 ] {} <Trace> system.metric_log (71864658-8943-47a6-adf5-35ade28b33ba): Renaming temporary part tmp_insert_202402_59_59_0 to 202402_59_59_0 with tid (1, 1, 00000000-0000-0000-0000-000000000000).\r\n\nI don't think this closes this.  My configuration always had the correct path in the configuration file.\nIt seems to me that if there is no `user_defined_path` in config.xml then ClickHouse uses the current directory\r\nhttps://github.com/ClickHouse/ClickHouse/blob/master/src/Functions/UserDefined/createUserDefinedSQLObjectsStorage.cpp#L40\r\n\r\nThe default value is supposed to be `<user_defined_path>/var/lib/clickhouse/user_defined/</user_defined_path>` but it is NOT present in the default config.xml.\r\n\r\nAs a workaround you could put this parameter into an override file in config.d\nThis PR might be related https://github.com/ClickHouse/ClickHouse/pull/57752\n@SaltTan Thanks for your response!  I run all my config's from config.d.  I have the general file config.xml located there, as well as macros.xml, docker_related_config.xml, and then depending on which servers we're talking about, there may also be clusters.xml as well.  I was told (above) that the path has to be present in the config.xml, but I validated the preprocessed_configs/config.xml (see above) and the line for clickhouse is there, as well as in my config.d/config.xml.  \r\nI'm happy to test an alternate override file. To which override file can I add the path <user_defined_path>/var/lib/clickhouse/user_defined/</user_defined_path> ?\nYou can put it to any file.\r\nJust check that it got merged into `/var/lib/clickhouse/preprocessed_configs/config.xml`\nThe problem still exists.\r\nI added it to the clusters.xml file like below:\r\n\r\n```\r\n<yandex>\r\n    <remote_servers>\r\n        ....removed....\r\n    </remote_servers>\r\n    <!-- Path to data directory, with trailing slash. -->\r\n    <path>/var/lib/clickhouse/</path>\r\n</yandex>\r\n```\r\n\r\nI only see it listed once in the /var/lib/clickhouse/preprocessed_configs/config.xml\r\naround line 572.\r\n\r\n```\r\n   <validate_tcp_client_information>false</validate_tcp_client_information>\r\n\r\n    <!-- Path to data directory, with trailing slash. -->\r\n    <path>/var/lib/clickhouse/</path>\r\n\r\n    <!-- Multi-disk configuration example: -->\r\n   \r\n    <storage_configuration>\r\n```\r\n\nYou need to add this: `<user_defined_path>/var/lib/clickhouse/user_defined/</user_defined_path> `\nThis may not matter, but just to remind you, these are in a containers. The path in the container is valid (/var/lib/clickhouse), and it's mapped outside the container to /var/lib/docker/volumes/clickhouse/_data.  The data looks consistent from both locations.\r\n\r\nContainer: drwxrwxrwx 18 clickhouse clickhouse 4096 Feb 27 11:34 /var/lib/clickhouse/\r\n        Host: drwx-----x      3 root           root            4096 Feb  8  09:11 /var/lib/docker/volumes/clickhouse\r\n\nOh crap... that path does **NOT** exist in my config.xml.  Let me add it and get back.\nAdded it to the config.xml file, and it does now show up in /var/lib/clickhouse/preprocessed_configs/config.xml.\r\naround line 2757:\r\n`    <user_defined_path>/var/lib/clickhouse/user_defined/</user_defined_path>`\r\n\r\nIt still creates the directory, user_defined, in my home directory when doing an insert.\r\n\r\nAlso tried adding it to the cluster.xml file, with the same results.\r\n\nSeeing the same problem, is there a workaround for this?\nNo, there's not been any work-around provided, or actually much activity.\nIt reproduces:\r\n\r\n```\r\nmilovidov@milovidov-pc:~$ clickhouse-client \r\nClickHouse client version 24.4.1.1.\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 24.4.1.\r\n\r\nmilovidov-pc :) CREATE TABLE test (x String) ENGINE = Memory\r\n\r\nCREATE TABLE test\r\n(\r\n    `x` String\r\n)\r\nENGINE = Memory\r\n\r\nQuery id: b440b6aa-0d8d-4529-9e65-d2bd3f007648\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.006 sec. \r\n\r\nmilovidov-pc :) Bye.\r\n\r\nmilovidov@milovidov-pc:~$ clickhouse-client --query \"INSERT INTO test VALUES (xyz('abc'))\"\r\nCode: 46. DB::Exception: Unknown function xyz: While processing xyz('abc'): While executing ValuesBlockInputFormat: data for INSERT was parsed from query: (in query: INSERT INTO test VALUES (xyz('abc'))). (UNKNOWN_FUNCTION)\r\n\r\nmilovidov@milovidov-pc:~$ ls -ld user_defined\r\ndrwxrwxr-x 2 milovidov milovidov 4096 apr  6 21:34 user_defined\r\n```",
  "created_at": "2024-04-06T19:47:38Z"
}