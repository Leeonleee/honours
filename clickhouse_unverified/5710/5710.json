{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 5710,
  "instance_id": "ClickHouse__ClickHouse-5710",
  "issue_numbers": [
    "5527"
  ],
  "base_commit": "4f7d472cb7329bcbf0659fc8c3abaf0ca26cc439",
  "patch": "diff --git a/dbms/CMakeLists.txt b/dbms/CMakeLists.txt\nindex e7cc084237fc..63a454d0ea64 100644\n--- a/dbms/CMakeLists.txt\n+++ b/dbms/CMakeLists.txt\n@@ -410,6 +410,6 @@ if (ENABLE_TESTS AND USE_GTEST)\n     # gtest framework has substandard code\n     target_compile_options(unit_tests_dbms PRIVATE -Wno-zero-as-null-pointer-constant -Wno-undef -Wno-sign-compare -Wno-used-but-marked-unused -Wno-missing-noreturn)\n \n-    target_link_libraries(unit_tests_dbms PRIVATE ${GTEST_BOTH_LIBRARIES} clickhouse_functions clickhouse_parsers dbms clickhouse_common_zookeeper)\n+    target_link_libraries(unit_tests_dbms PRIVATE ${GTEST_BOTH_LIBRARIES} clickhouse_functions clickhouse_parsers dbms clickhouse_common_zookeeper string_utils)\n     add_check(unit_tests_dbms)\n endif ()\ndiff --git a/dbms/programs/client/Client.cpp b/dbms/programs/client/Client.cpp\nindex 8874eeac6c70..df5e8568d21c 100644\n--- a/dbms/programs/client/Client.cpp\n+++ b/dbms/programs/client/Client.cpp\n@@ -608,6 +608,7 @@ class Client : public Poco::Util::Application\n \n             if (!ends_with_backslash && (ends_with_semicolon || has_vertical_output_suffix || (!config().has(\"multiline\") && !hasDataInSTDIN())))\n             {\n+                // TODO: should we do sensitive data masking on client too? History file can be source of secret leaks.\n                 if (input != prev_input)\n                 {\n                     /// Replace line breaks with spaces to prevent the following problem.\ndiff --git a/dbms/programs/local/LocalServer.cpp b/dbms/programs/local/LocalServer.cpp\nindex 1844c0377845..f4eac1baec2c 100644\n--- a/dbms/programs/local/LocalServer.cpp\n+++ b/dbms/programs/local/LocalServer.cpp\n@@ -74,6 +74,7 @@ void LocalServer::initialize(Poco::Util::Application & self)\n \n     if (config().has(\"logger\") || config().has(\"logger.level\") || config().has(\"logger.log\"))\n     {\n+        // sensitive data rules are not used here\n         buildLoggers(config(), logger());\n     }\n     else\ndiff --git a/dbms/programs/odbc-bridge/ODBCBridge.cpp b/dbms/programs/odbc-bridge/ODBCBridge.cpp\nindex cf265eb6abb0..214d9f75328f 100644\n--- a/dbms/programs/odbc-bridge/ODBCBridge.cpp\n+++ b/dbms/programs/odbc-bridge/ODBCBridge.cpp\n@@ -124,6 +124,7 @@ void ODBCBridge::initialize(Application & self)\n     config().setString(\"logger\", \"ODBCBridge\");\n \n     buildLoggers(config(), logger());\n+\n     log = &logger();\n     hostname = config().getString(\"listen-host\", \"localhost\");\n     port = config().getUInt(\"http-port\");\n@@ -162,6 +163,12 @@ int ODBCBridge::main(const std::vector<std::string> & /*args*/)\n     context = std::make_shared<Context>(Context::createGlobal());\n     context->makeGlobalContext();\n \n+    if (config().has(\"query_masking_rules\"))\n+    {\n+        context->setSensitiveDataMasker(std::make_unique<SensitiveDataMasker>(config(), \"query_masking_rules\"));\n+        setLoggerSensitiveDataMasker(logger(), context->getSensitiveDataMasker());\n+    }\n+\n     auto server = Poco::Net::HTTPServer(\n         new HandlerFactory(\"ODBCRequestHandlerFactory-factory\", keep_alive_timeout, context), server_pool, socket, http_params);\n     server.start();\ndiff --git a/dbms/programs/server/Server.cpp b/dbms/programs/server/Server.cpp\nindex f10dc07ab56a..82f50f265692 100644\n--- a/dbms/programs/server/Server.cpp\n+++ b/dbms/programs/server/Server.cpp\n@@ -278,7 +278,11 @@ int Server::main(const std::vector<std::string> & /*args*/)\n           *  table engines could use Context on destroy.\n           */\n         LOG_INFO(log, \"Shutting down storages.\");\n+\n+        // global_context is the owner of sensitive_data_masker, which will be destoyed after global_context->shutdown() call\n+        setLoggerSensitiveDataMasker(logger(), nullptr);\n         global_context->shutdown();\n+\n         LOG_DEBUG(log, \"Shutted down storages.\");\n \n         /** Explicitly destroy Context. It is more convenient than in destructor of Server, because logger is still available.\n@@ -407,6 +411,12 @@ int Server::main(const std::vector<std::string> & /*args*/)\n \n     /// Initialize main config reloader.\n     std::string include_from_path = config().getString(\"include_from\", \"/etc/metrika.xml\");\n+\n+    if (config().has(\"query_masking_rules\"))\n+    {\n+        global_context->setSensitiveDataMasker(std::make_unique<SensitiveDataMasker>(config(), \"query_masking_rules\"));\n+    }\n+\n     auto main_config_reloader = std::make_unique<ConfigReloader>(config_path,\n         include_from_path,\n         config().getString(\"path\", \"\"),\n@@ -416,6 +426,10 @@ int Server::main(const std::vector<std::string> & /*args*/)\n         {\n             setTextLog(global_context->getTextLog());\n             buildLoggers(*config, logger());\n+            if (auto masker = global_context->getSensitiveDataMasker())\n+            {\n+                setLoggerSensitiveDataMasker(logger(), masker);\n+            }\n             global_context->setClustersConfig(config);\n             global_context->setMacros(std::make_unique<Macros>(*config, \"macros\"));\n         },\ndiff --git a/dbms/programs/server/config.xml b/dbms/programs/server/config.xml\nindex 814b7dded3c3..d8fcd9b0c9ee 100644\n--- a/dbms/programs/server/config.xml\n+++ b/dbms/programs/server/config.xml\n@@ -439,6 +439,20 @@\n       -->\n     <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>\n \n+\n+    <!-- Uncomment to use query masking rules.\n+        name - name for the rule (optional)\n+        regexp - RE2 compatible regular expression (mandatory)\n+        replace - substitution string for sensitive data (optional, by default - six asterisks)\n+    <query_masking_rules>\n+        <rule>\n+            <name>hide SSN</name>\n+            <regexp>(^|\\D)\\d{3}-\\d{2}-\\d{4}($|\\D)</regexp>\n+            <replace>000-00-0000</replace>\n+        </rule>\n+    </query_masking_rules>\n+    -->\n+\n     <!-- Uncomment to disable ClickHouse internal DNS caching. -->\n     <!-- <disable_internal_dns_cache>1</disable_internal_dns_cache> -->\n </yandex>\ndiff --git a/dbms/src/Common/ProfileEvents.cpp b/dbms/src/Common/ProfileEvents.cpp\nindex 67303b085f44..947e3890078a 100644\n--- a/dbms/src/Common/ProfileEvents.cpp\n+++ b/dbms/src/Common/ProfileEvents.cpp\n@@ -46,6 +46,8 @@\n     M(NetworkSendElapsedMicroseconds, \"\") \\\n     M(ThrottlerSleepMicroseconds, \"Total time a query was sleeping to conform the 'max_network_bandwidth' setting.\") \\\n     \\\n+    M(QueryMaskingRulesMatch, \"Number of times query masking rules was successfully matched.\") \\\n+    \\\n     M(ReplicatedPartFetches, \"Number of times a data part was downloaded from replica of a ReplicatedMergeTree table.\") \\\n     M(ReplicatedPartFailedFetches, \"\") \\\n     M(ObsoleteReplicatedParts, \"\") \\\ndiff --git a/dbms/src/Common/SensitiveDataMasker.cpp b/dbms/src/Common/SensitiveDataMasker.cpp\nnew file mode 100644\nindex 000000000000..488c0be42459\n--- /dev/null\n+++ b/dbms/src/Common/SensitiveDataMasker.cpp\n@@ -0,0 +1,166 @@\n+#include \"SensitiveDataMasker.h\"\n+\n+#include <set>\n+#include <string>\n+#include <atomic>\n+\n+#include <re2/re2.h>\n+#include <re2/stringpiece.h>\n+\n+#include <Poco/Util/AbstractConfiguration.h>\n+\n+#include <common/logger_useful.h>\n+\n+#include <Common/Exception.h>\n+#include <Common/StringUtils/StringUtils.h>\n+\n+#ifndef NDEBUG\n+#    include <iostream>\n+#endif\n+\n+namespace DB\n+{\n+namespace ErrorCodes\n+{\n+    extern const int CANNOT_COMPILE_REGEXP;\n+    extern const int NO_ELEMENTS_IN_CONFIG;\n+    extern const int INVALID_CONFIG_PARAMETER;\n+}\n+\n+class SensitiveDataMasker::MaskingRule\n+{\n+private:\n+    const std::string name;\n+    const std::string replacement_string;\n+    const std::string regexp_string;\n+\n+    const RE2 regexp;\n+    const re2::StringPiece replacement;\n+\n+    mutable std::atomic<std::uint64_t> matches_count = 0;\n+\n+public:\n+    //* TODO: option with hyperscan? https://software.intel.com/en-us/articles/why-and-how-to-replace-pcre-with-hyperscan\n+    // re2::set should also work quite fast, but it doesn't return the match position, only which regexp was matched\n+\n+    MaskingRule(const std::string & name, const std::string & _regexp_string, const std::string & _replacement_string)\n+        : name(name)\n+        , replacement_string(_replacement_string)\n+        , regexp_string(_regexp_string)\n+        , regexp(regexp_string, RE2::Quiet)\n+        , replacement(replacement_string)\n+    {\n+        if (!regexp.ok())\n+            throw DB::Exception(\n+                \"SensitiveDataMasker: cannot compile re2: \" + _regexp_string + \", error: \" + regexp.error()\n+                    + \". Look at https://github.com/google/re2/wiki/Syntax for reference.\",\n+                DB::ErrorCodes::CANNOT_COMPILE_REGEXP);\n+    }\n+    int apply(std::string & data) const\n+    {\n+        auto m = RE2::GlobalReplace(&data, regexp, replacement);\n+        matches_count += m;\n+        return m;\n+    }\n+\n+    const std::string & getName() const { return name; }\n+    const std::string & getReplacementString() const { return replacement_string; }\n+    uint64_t getMatchesCount() const { return matches_count; }\n+};\n+\n+SensitiveDataMasker::SensitiveDataMasker(const Poco::Util::AbstractConfiguration & config, const std::string & config_prefix)\n+{\n+    Poco::Util::AbstractConfiguration::Keys keys;\n+    config.keys(config_prefix, keys);\n+    Logger * logger = &Logger::get(\"SensitiveDataMaskerConfigRead\");\n+\n+    std::set<std::string> used_names;\n+\n+    for (const auto & rule : keys)\n+    {\n+        if (startsWith(rule, \"rule\"))\n+        {\n+            auto rule_config_prefix = config_prefix + \".\" + rule;\n+\n+            auto rule_name = config.getString(rule_config_prefix + \".name\", rule_config_prefix);\n+\n+            if (used_names.count(rule_name) == 0)\n+            {\n+                used_names.insert(rule_name);\n+            }\n+            else\n+            {\n+                throw Exception(\n+                    \"query_masking_rules configuration contains more than one rule named '\" + rule_name + \"'.\",\n+                    ErrorCodes::INVALID_CONFIG_PARAMETER);\n+            }\n+\n+            auto regexp = config.getString(rule_config_prefix + \".regexp\", \"\");\n+\n+            if (regexp == \"\")\n+            {\n+                throw Exception(\n+                    \"query_masking_rules configuration, rule '\" + rule_name + \"' has no <regexp> node or <regexp> is empty.\",\n+                    ErrorCodes::NO_ELEMENTS_IN_CONFIG);\n+            }\n+\n+            auto replace = config.getString(rule_config_prefix + \".replace\", \"******\");\n+\n+            try\n+            {\n+                addMaskingRule(rule_name, regexp, replace);\n+            }\n+            catch (DB::Exception & e)\n+            {\n+                e.addMessage(\"while adding query masking rule '\" + rule_name + \"'.\");\n+                throw;\n+            }\n+        }\n+        else\n+        {\n+            LOG_WARNING(logger, \"Unused param \" << config_prefix << '.' << rule);\n+        }\n+    }\n+    auto rules_count = this->rulesCount();\n+    if (rules_count > 0)\n+    {\n+        LOG_INFO(logger, rules_count << \" query masking rules loaded.\");\n+    }\n+}\n+\n+SensitiveDataMasker::~SensitiveDataMasker() {}\n+\n+void SensitiveDataMasker::addMaskingRule(\n+    const std::string & name, const std::string & regexp_string, const std::string & replacement_string)\n+{\n+    all_masking_rules.push_back(std::make_unique<MaskingRule>(name, regexp_string, replacement_string));\n+}\n+\n+\n+int SensitiveDataMasker::wipeSensitiveData(std::string & data) const\n+{\n+    int matches = 0;\n+    for (auto & rule : all_masking_rules)\n+    {\n+        matches += rule->apply(data);\n+    }\n+    return matches;\n+}\n+\n+#ifndef NDEBUG\n+void SensitiveDataMasker::printStats()\n+{\n+    for (auto & rule : all_masking_rules)\n+    {\n+        std::cout << rule->getName() << \" (replacement to \" << rule->getReplacementString() << \") matched \" << rule->getMatchesCount()\n+                  << \" times\" << std::endl;\n+    }\n+}\n+#endif\n+\n+unsigned long SensitiveDataMasker::rulesCount() const\n+{\n+    return all_masking_rules.size();\n+}\n+\n+}\ndiff --git a/dbms/src/Common/SensitiveDataMasker.h b/dbms/src/Common/SensitiveDataMasker.h\nnew file mode 100644\nindex 000000000000..02e86976d028\n--- /dev/null\n+++ b/dbms/src/Common/SensitiveDataMasker.h\n@@ -0,0 +1,35 @@\n+#pragma once\n+\n+#include <memory>\n+#include <vector>\n+\n+namespace Poco\n+{\n+namespace Util\n+{\n+    class AbstractConfiguration;\n+}\n+}\n+\n+namespace DB\n+{\n+class SensitiveDataMasker\n+{\n+private:\n+    class MaskingRule;\n+    std::vector<std::unique_ptr<MaskingRule>> all_masking_rules;\n+\n+public:\n+    SensitiveDataMasker(const Poco::Util::AbstractConfiguration & config, const std::string & config_prefix);\n+    ~SensitiveDataMasker();\n+    void addMaskingRule(const std::string & name, const std::string & regexp_string, const std::string & replacement_string);\n+    int wipeSensitiveData(std::string & data) const;\n+\n+#ifndef NDEBUG\n+    void printStats();\n+#endif\n+\n+    unsigned long rulesCount() const;\n+};\n+\n+};\ndiff --git a/dbms/src/Interpreters/Context.cpp b/dbms/src/Interpreters/Context.cpp\nindex fb8487154523..cb05b0e4fc87 100644\n--- a/dbms/src/Interpreters/Context.cpp\n+++ b/dbms/src/Interpreters/Context.cpp\n@@ -86,6 +86,7 @@ namespace ErrorCodes\n     extern const int SESSION_NOT_FOUND;\n     extern const int SESSION_IS_LOCKED;\n     extern const int CANNOT_GET_CREATE_TABLE_QUERY;\n+    extern const int LOGICAL_ERROR;\n }\n \n \n@@ -142,6 +143,8 @@ struct ContextShared\n     std::unique_ptr<DDLWorker> ddl_worker;                  /// Process ddl commands from zk.\n     /// Rules for selecting the compression settings, depending on the size of the part.\n     mutable std::unique_ptr<CompressionCodecSelector> compression_codec_selector;\n+    /// Allows to remove sensitive data from queries using set of regexp-based rules\n+    std::unique_ptr<SensitiveDataMasker> sensitive_data_masker;\n     std::optional<MergeTreeSettings> merge_tree_settings; /// Settings of MergeTree* engines.\n     size_t max_table_size_to_drop = 50000000000lu;          /// Protects MergeTree tables from accidental DROP (50GB by default)\n     size_t max_partition_size_to_drop = 50000000000lu;      /// Protects MergeTree partitions from accidental DROP (50GB by default)\n@@ -284,6 +287,8 @@ struct ContextShared\n \n         /// Stop trace collector if any\n         trace_collector.reset();\n+\n+        sensitive_data_masker.reset();\n     }\n \n     bool hasTraceCollector()\n@@ -533,6 +538,23 @@ String Context::getUserFilesPath() const\n     return shared->user_files_path;\n }\n \n+void Context::setSensitiveDataMasker(std::unique_ptr<SensitiveDataMasker> sensitive_data_masker)\n+{\n+    if (!sensitive_data_masker)\n+        throw Exception(\"Logical error: the 'sensitive_data_masker' is not set\", ErrorCodes::LOGICAL_ERROR);\n+    \n+    if (sensitive_data_masker->rulesCount() > 0)\n+    {\n+        auto lock = getLock();\n+        shared->sensitive_data_masker = std::move(sensitive_data_masker);\n+    }\n+}\n+\n+SensitiveDataMasker * Context::getSensitiveDataMasker() const\n+{\n+    return shared->sensitive_data_masker.get();\n+}\n+\n void Context::setPath(const String & path)\n {\n     auto lock = getLock();\ndiff --git a/dbms/src/Interpreters/Context.h b/dbms/src/Interpreters/Context.h\nindex f7ba0a7dbaa4..d8e4748ddad6 100644\n--- a/dbms/src/Interpreters/Context.h\n+++ b/dbms/src/Interpreters/Context.h\n@@ -12,6 +12,7 @@\n #include <Common/MultiVersion.h>\n #include <Common/ThreadPool.h>\n #include \"config_core.h\"\n+#include <Common/SensitiveDataMasker.h>\n #include <Storages/IStorage_fwd.h>\n #include <atomic>\n #include <chrono>\n@@ -177,6 +178,9 @@ class Context\n     String getFlagsPath() const;\n     String getUserFilesPath() const;\n \n+    void setSensitiveDataMasker(std::unique_ptr<SensitiveDataMasker> sensitive_data_masker);\n+    SensitiveDataMasker * getSensitiveDataMasker() const;\n+\n     void setPath(const String & path);\n     void setTemporaryPath(const String & path);\n     void setFlagsPath(const String & path);\ndiff --git a/dbms/src/Interpreters/executeQuery.cpp b/dbms/src/Interpreters/executeQuery.cpp\nindex 07445aac646e..3793f2f79c9b 100644\n--- a/dbms/src/Interpreters/executeQuery.cpp\n+++ b/dbms/src/Interpreters/executeQuery.cpp\n@@ -28,12 +28,19 @@\n #include <Interpreters/InterpreterSetQuery.h>\n #include <Interpreters/ReplaceQueryParameterVisitor.h>\n #include <Interpreters/executeQuery.h>\n+#include <Common/ProfileEvents.h>\n+\n #include <Interpreters/DNSCacheUpdater.h>\n \n #include <Processors/Transforms/LimitsCheckingTransform.h>\n #include <Processors/Transforms/MaterializingTransform.h>\n #include <Processors/Formats/IOutputFormat.h>\n \n+namespace ProfileEvents\n+{\n+    extern const Event QueryMaskingRulesMatch;\n+}\n+\n namespace DB\n {\n \n@@ -54,7 +61,6 @@ static void checkASTSizeLimits(const IAST & ast, const Settings & settings)\n         ast.checkSize(settings.max_ast_elements);\n }\n \n-\n /// NOTE This is wrong in case of single-line comments and in case of multiline string literals.\n static String joinLines(const String & query)\n {\n@@ -64,6 +70,27 @@ static String joinLines(const String & query)\n }\n \n \n+static String prepareQueryForLogging(const String & query, Context & context)\n+{\n+    String res = query;\n+\n+    // wiping sensitive data before cropping query by log_queries_cut_to_length,\n+    // otherwise something like credit card without last digit can go to log\n+    if (auto masker = context.getSensitiveDataMasker())\n+    {\n+        auto matches = masker->wipeSensitiveData(res);\n+        if (matches > 0)\n+        {\n+            ProfileEvents::increment(ProfileEvents::QueryMaskingRulesMatch, matches);\n+        }\n+    }\n+\n+    res = res.substr(0, context.getSettingsRef().log_queries_cut_to_length);\n+\n+    return res;\n+}\n+\n+\n /// Log query into text log (not into system table).\n static void logQuery(const String & query, const Context & context, bool internal)\n {\n@@ -111,7 +138,7 @@ static void logException(Context & context, QueryLogElement & elem)\n }\n \n \n-static void onExceptionBeforeStart(const String & query, Context & context, time_t current_time)\n+static void onExceptionBeforeStart(const String & query_for_logging, Context & context, time_t current_time)\n {\n     /// Exception before the query execution.\n     context.getQuota().addError();\n@@ -126,7 +153,7 @@ static void onExceptionBeforeStart(const String & query, Context & context, time\n     elem.event_time = current_time;\n     elem.query_start_time = current_time;\n \n-    elem.query = query.substr(0, settings.log_queries_cut_to_length);\n+    elem.query = query_for_logging;\n     elem.exception = getCurrentExceptionMessage(false);\n \n     elem.client_info = context.getClientInfo();\n@@ -192,10 +219,12 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n     {\n         /// Anyway log the query.\n         String query = String(begin, begin + std::min(end - begin, static_cast<ptrdiff_t>(max_query_size)));\n-        logQuery(query.substr(0, settings.log_queries_cut_to_length), context, internal);\n+\n+        auto query_for_logging = prepareQueryForLogging(query, context);\n+        logQuery(query_for_logging, context, internal);\n \n         if (!internal)\n-            onExceptionBeforeStart(query, context, current_time);\n+            onExceptionBeforeStart(query_for_logging, context, current_time);\n \n         throw;\n     }\n@@ -205,6 +234,8 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n     BlockIO res;\n     QueryPipeline & pipeline = res.pipeline;\n \n+    String query_for_logging = \"\";\n+\n     try\n     {\n         /// Replace ASTQueryParameter with ASTLiteral for prepared statements.\n@@ -217,7 +248,9 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n             query = serializeAST(*ast);\n         }\n \n-        logQuery(query.substr(0, settings.log_queries_cut_to_length), context, internal);\n+        query_for_logging = prepareQueryForLogging(query, context);\n+\n+        logQuery(query_for_logging, context, internal);\n \n         /// Check the limits.\n         checkASTSizeLimits(*ast, settings);\n@@ -231,7 +264,8 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n         ProcessList::EntryPtr process_list_entry;\n         if (!internal && !ast->as<ASTShowProcesslistQuery>())\n         {\n-            process_list_entry = context.getProcessList().insert(query, ast.get(), context);\n+            /// processlist also has query masked now, to avoid secrets leaks though SHOW PROCESSLIST by other users.\n+            process_list_entry = context.getProcessList().insert(query_for_logging, ast.get(), context);\n             context.setProcessListElement(&process_list_entry->get());\n         }\n \n@@ -323,7 +357,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n             elem.event_time = current_time;\n             elem.query_start_time = current_time;\n \n-            elem.query = query.substr(0, settings.log_queries_cut_to_length);\n+            elem.query = query_for_logging;\n \n             elem.client_info = context.getClientInfo();\n \n@@ -469,7 +503,12 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n     catch (...)\n     {\n         if (!internal)\n-            onExceptionBeforeStart(query, context, current_time);\n+        {\n+            if (query_for_logging.empty())\n+                query_for_logging = prepareQueryForLogging(query, context);\n+\n+            onExceptionBeforeStart(query_for_logging, context, current_time);\n+        }\n \n         throw;\n     }\ndiff --git a/docs/en/operations/server_settings/settings.md b/docs/en/operations/server_settings/settings.md\nindex 2be36a6e0c64..3da0dd7d8d2c 100644\n--- a/docs/en/operations/server_settings/settings.md\n+++ b/docs/en/operations/server_settings/settings.md\n@@ -554,6 +554,36 @@ If the table doesn't exist, ClickHouse will create it. If the structure of the q\n </query_log>\n ```\n \n+## query_masking_rules\n+\n+Regexp-based rules, which will be applied to queries as well as all log messages before storing them in server logs,\n+`system.query_log`, `system.text_log`, `system.processes` table, and in logs sent to client. That allows preventing\n+sensitive data leakage from SQL queries (like names / emails / personal\n+identifiers / credit card numbers etc) to logs.\n+\n+**Example**\n+\n+```xml\n+<query_masking_rules>\n+    <rule>\n+        <name>hide SSN</name>\n+        <regexp>(^|\\D)\\d{3}-\\d{2}-\\d{4}($|\\D)</regexp>\n+        <replace>000-00-0000</replace>\n+    </rule>\n+</query_masking_rules>\n+```\n+\n+Config fields:\n+- `name` - name for the rule (optional)\n+- `regexp` - RE2 compatible regular expression (mandatory)\n+- `replace` - substitution string for sensitive data (optional, by default - six asterisks)\n+\n+The masking rules are applied on whole query (to prevent leaks of sensitive data from malformed / non parsable queries).\n+\n+`system.events` table have counter `QueryMaskingRulesMatch` which have overall number of query masking rules matches.\n+\n+For distributed queries each server have to be configured separately, otherwise subquries passed to other\n+nodes will be stored without masking.\n \n ## remote_servers {#server_settings_remote_servers}\n \ndiff --git a/libs/libdaemon/src/BaseDaemon.cpp b/libs/libdaemon/src/BaseDaemon.cpp\nindex 807506775aee..931d91bd8b52 100644\n--- a/libs/libdaemon/src/BaseDaemon.cpp\n+++ b/libs/libdaemon/src/BaseDaemon.cpp\n@@ -648,6 +648,7 @@ void BaseDaemon::initialize(Application & self)\n             throw Poco::Exception(\"Cannot change directory to /tmp\");\n     }\n \n+    // sensitive data masking rules are not used here\n     buildLoggers(config(), logger());\n \n     if (is_daemon)\ndiff --git a/libs/libloggers/loggers/Loggers.cpp b/libs/libloggers/loggers/Loggers.cpp\nindex ebdc3e375713..eab541dd2ee2 100644\n--- a/libs/libloggers/loggers/Loggers.cpp\n+++ b/libs/libloggers/loggers/Loggers.cpp\n@@ -11,6 +11,11 @@\n #include <Poco/Net/RemoteSyslogChannel.h>\n #include <Poco/Path.h>\n \n+namespace DB\n+{\n+    class SensitiveDataMasker;\n+}\n+\n \n // TODO: move to libcommon\n static std::string createDirectory(const std::string & file)\n@@ -162,12 +167,21 @@ void Loggers::buildLoggers(Poco::Util::AbstractConfiguration & config, Poco::Log\n             logger.root().get(level).setLevel(config.getString(\"logger.levels.\" + level, \"trace\"));\n }\n \n+void Loggers::setLoggerSensitiveDataMasker(Poco::Logger & logger, DB::SensitiveDataMasker * sensitive_data_masker)\n+{\n+    if (auto split = dynamic_cast<DB::OwnSplitChannel *>(logger.getChannel()))\n+    {\n+        split->setMasker(sensitive_data_masker);\n+    }\n+}\n+\n void Loggers::closeLogs(Poco::Logger & logger)\n {\n     if (log_file)\n         log_file->close();\n     if (error_log_file)\n         error_log_file->close();\n+    // Shouldn't syslog_channel be closed here too?\n \n     if (!log_file)\n         logger.warning(\"Logging to console but received signal to close log file (ignoring).\");\ndiff --git a/libs/libloggers/loggers/Loggers.h b/libs/libloggers/loggers/Loggers.h\nindex 4cc3df3757a0..49135afadc61 100644\n--- a/libs/libloggers/loggers/Loggers.h\n+++ b/libs/libloggers/loggers/Loggers.h\n@@ -8,7 +8,12 @@\n \n namespace Poco::Util\n {\n-class AbstractConfiguration;\n+    class AbstractConfiguration;\n+}\n+\n+namespace DB\n+{\n+    class SensitiveDataMasker;\n }\n \n \n@@ -16,6 +21,8 @@ class Loggers\n {\n public:\n     void buildLoggers(Poco::Util::AbstractConfiguration & config, Poco::Logger & logger, const std::string & cmd_name = \"\");\n+    void setLoggerSensitiveDataMasker(Poco::Logger & logger, DB::SensitiveDataMasker * sensitive_data_masker);\n+\n \n     /// Close log files. On next log write files will be reopened.\n     void closeLogs(Poco::Logger & logger);\n@@ -31,10 +38,10 @@ class Loggers\n     std::optional<size_t> layer;\n \n private:\n-    /// \u0424\u0430\u0439\u043b\u044b \u0441 \u043b\u043e\u0433\u0430\u043c\u0438.\n     Poco::AutoPtr<Poco::FileChannel> log_file;\n     Poco::AutoPtr<Poco::FileChannel> error_log_file;\n     Poco::AutoPtr<Poco::Channel> syslog_channel;\n+\n     /// Previous value of logger element in config. It is used to reinitialize loggers whenever the value changed.\n     std::string config_logger;\n \ndiff --git a/libs/libloggers/loggers/OwnPatternFormatter.h b/libs/libloggers/loggers/OwnPatternFormatter.h\nindex 0e100aa6f33b..dc1254cba294 100644\n--- a/libs/libloggers/loggers/OwnPatternFormatter.h\n+++ b/libs/libloggers/loggers/OwnPatternFormatter.h\n@@ -5,18 +5,18 @@\n #include \"ExtendedLogChannel.h\"\n \n \n-/** \u0424\u043e\u0440\u043c\u0430\u0442\u0438\u0440\u0443\u0435\u0442 \u043f\u043e \u0441\u0432\u043e\u0435\u043c\u0443.\n-  * \u041d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0434\u0435\u0442\u0430\u043b\u0438 \u043d\u0435\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u0442\u043e\u043b\u044c\u043a\u043e Poco::PatternFormatter.\n+/** Format log messages own way.\n+  * We can't obtain some details using Poco::PatternFormatter.\n   *\n-  * \u0412\u043e-\u043f\u0435\u0440\u0432\u044b\u0445, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u043d\u043e\u043c\u0435\u0440 \u043f\u043e\u0442\u043e\u043a\u0430 \u043d\u0435 \u0441\u0440\u0435\u0434\u0438 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 Poco::Thread,\n-  *  \u0430 \u0441\u0440\u0435\u0434\u0438 \u0432\u0441\u0435\u0445 \u043f\u043e\u0442\u043e\u043a\u043e\u0432, \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0431\u044b\u043b \u043f\u043e\u043b\u0443\u0447\u0435\u043d \u043d\u043e\u043c\u0435\u0440 (\u0441\u043c. ThreadNumber.h)\n+  * Firstly, the thread number here is peaked not from Poco::Thread\n+  * threads only, but from all threads with number assigned (see ThreadNumber.h)\n   *\n-  * \u0412\u043e-\u0432\u0442\u043e\u0440\u044b\u0445, \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u0430\u044f \u0434\u0430\u0442\u0430 \u0438 \u0432\u0440\u0435\u043c\u044f.\n-  * Poco::PatternFormatter \u043f\u043b\u043e\u0445\u043e \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0441 \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u044b\u043c \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c,\n-  *  \u0432 \u0441\u0438\u0442\u0443\u0430\u0446\u0438\u044f\u0445, \u043a\u043e\u0433\u0434\u0430 \u0432 \u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0435\u043c \u0431\u0443\u0434\u0443\u0449\u0435\u043c \u043d\u0430\u043c\u0435\u0447\u0430\u0435\u0442\u0441\u044f \u043e\u0442\u043c\u0435\u043d\u0430 \u0438\u043b\u0438 \u0432\u0432\u0435\u0434\u0435\u043d\u0438\u0435 daylight saving time.\n-  *  - \u0441\u043c. \u0438\u0441\u0445\u043e\u0434\u043d\u0438\u043a\u0438 Poco \u0438 http://thread.gmane.org/gmane.comp.time.tz/8883\n+  * Secondly, the local date and time are correctly displayed.\n+  * Poco::PatternFormatter does not work well with local time,\n+  * when timestamps are close to DST timeshift moments.\n+  * - see Poco sources and http://thread.gmane.org/gmane.comp.time.tz/8883\n   *\n-  * \u0422\u0430\u043a\u0436\u0435 \u0441\u0434\u0435\u043b\u0430\u043d \u0447\u0443\u0442\u044c \u0431\u043e\u043b\u0435\u0435 \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u044b\u043c (\u0447\u0442\u043e \u0438\u043c\u0435\u0435\u0442 \u043c\u0430\u043b\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f).\n+  * Also it's made a bit more efficient (unimportant).\n   */\n \n class Loggers;\ndiff --git a/libs/libloggers/loggers/OwnSplitChannel.cpp b/libs/libloggers/loggers/OwnSplitChannel.cpp\nindex e4f0c7e473a1..69e540e1d210 100644\n--- a/libs/libloggers/loggers/OwnSplitChannel.cpp\n+++ b/libs/libloggers/loggers/OwnSplitChannel.cpp\n@@ -20,6 +20,23 @@ void OwnSplitChannel::log(const Poco::Message & msg)\n     if (channels.empty() && (logs_queue == nullptr || msg.getPriority() > logs_queue->max_priority))\n         return;\n \n+    if (auto masker = sensitive_data_masker.load())\n+    {\n+        auto message_text = msg.getText();\n+        auto matches = masker->wipeSensitiveData(message_text);\n+        if (matches > 0)\n+        {\n+            logSplit({msg, message_text}); // we will continue with the copy of original message with text modified\n+            return;\n+        }\n+\n+    }\n+    logSplit(msg);\n+}\n+\n+\n+void OwnSplitChannel::logSplit(const Poco::Message & msg)\n+{\n     ExtendedLogMessage msg_ext = ExtendedLogMessage::getFrom(msg);\n \n     /// Log data to child channels\n@@ -31,6 +48,8 @@ void OwnSplitChannel::log(const Poco::Message & msg)\n             channel.first->log(msg); // ordinary child\n     }\n \n+    auto logs_queue = CurrentThread::getInternalTextLogsQueue();\n+\n     /// Log to \"TCP queue\" if message is not too noisy\n     if (logs_queue && msg.getPriority() <= logs_queue->max_priority)\n     {\n@@ -80,6 +99,12 @@ void OwnSplitChannel::log(const Poco::Message & msg)\n         log->add(elem);\n }\n \n+\n+void OwnSplitChannel::setMasker(DB::SensitiveDataMasker * _sensitive_data_masker)\n+{\n+    sensitive_data_masker.store(_sensitive_data_masker);\n+}\n+\n void OwnSplitChannel::addChannel(Poco::AutoPtr<Poco::Channel> channel)\n {\n     channels.emplace_back(std::move(channel), dynamic_cast<ExtendedLogChannel *>(channel.get()));\ndiff --git a/libs/libloggers/loggers/OwnSplitChannel.h b/libs/libloggers/loggers/OwnSplitChannel.h\nindex ee190124c664..4b4da639b979 100644\n--- a/libs/libloggers/loggers/OwnSplitChannel.h\n+++ b/libs/libloggers/loggers/OwnSplitChannel.h\n@@ -1,8 +1,10 @@\n #pragma once\n+#include <atomic>\n #include <vector>\n #include <Poco/AutoPtr.h>\n #include <Poco/Channel.h>\n #include \"ExtendedLogChannel.h\"\n+#include <Common/SensitiveDataMasker.h>\n #include <Interpreters/TextLog.h>\n \n \n@@ -17,16 +19,21 @@ class OwnSplitChannel : public Poco::Channel\n     /// Makes an extended message from msg and passes it to the client logs queue and child (if possible)\n     void log(const Poco::Message & msg) override;\n \n+    void setMasker(DB::SensitiveDataMasker * _sensitive_data_masker);\n+\n     /// Adds a child channel\n     void addChannel(Poco::AutoPtr<Poco::Channel> channel);\n \n     void addTextLog(std::shared_ptr<DB::TextLog> log);\n \n private:\n+    void logSplit(const Poco::Message & msg);\n+\n     using ChannelPtr = Poco::AutoPtr<Poco::Channel>;\n     /// Handler and its pointer casted to extended interface\n     using ExtendedChannelPtrPair = std::pair<ChannelPtr, ExtendedLogChannel *>;\n     std::vector<ExtendedChannelPtrPair> channels;\n+    std::atomic<DB::SensitiveDataMasker *> sensitive_data_masker = nullptr; // global context owns that object, pointer should be reset before context destroying.\n \n     std::mutex text_log_mutex;\n     std::weak_ptr<DB::TextLog> text_log;\n",
  "test_patch": "diff --git a/dbms/src/Common/tests/gtest_sensitive_data_masker.cpp b/dbms/src/Common/tests/gtest_sensitive_data_masker.cpp\nnew file mode 100644\nindex 000000000000..d79b7b9932ca\n--- /dev/null\n+++ b/dbms/src/Common/tests/gtest_sensitive_data_masker.cpp\n@@ -0,0 +1,228 @@\n+#include <Common/Exception.h>\n+#include <Common/SensitiveDataMasker.h>\n+#include <Poco/AutoPtr.h>\n+#include <Poco/Util/XMLConfiguration.h>\n+#include <Poco/XML/XMLException.h>\n+\n+#pragma GCC diagnostic ignored \"-Wsign-compare\"\n+#ifdef __clang__\n+#    pragma clang diagnostic ignored \"-Wzero-as-null-pointer-constant\"\n+#    pragma clang diagnostic ignored \"-Wundef\"\n+#endif\n+\n+#include <gtest/gtest.h>\n+\n+\n+namespace DB\n+{\n+namespace ErrorCodes\n+{\n+extern const int CANNOT_COMPILE_REGEXP;\n+extern const int NO_ELEMENTS_IN_CONFIG;\n+extern const int INVALID_CONFIG_PARAMETER;\n+}\n+};\n+\n+\n+TEST(Common, SensitiveDataMasker)\n+{\n+\n+    Poco::AutoPtr<Poco::Util::XMLConfiguration> empty_xml_config = new Poco::Util::XMLConfiguration();\n+    DB::SensitiveDataMasker masker(*empty_xml_config , \"\");\n+    masker.addMaskingRule(\"all a letters\", \"a+\", \"--a--\");\n+    masker.addMaskingRule(\"all b letters\", \"b+\", \"--b--\");\n+    masker.addMaskingRule(\"all d letters\", \"d+\", \"--d--\");\n+    masker.addMaskingRule(\"all x letters\", \"x+\", \"--x--\");\n+    masker.addMaskingRule(\"rule \\\"d\\\" result\", \"--d--\", \"*****\"); // RE2 regexps are applied one-by-one in order\n+    std::string x = \"aaaaaaaaaaaaa   bbbbbbbbbb cccc aaaaaaaaaaaa d \";\n+    EXPECT_EQ(masker.wipeSensitiveData(x), 5);\n+    EXPECT_EQ(x, \"--a--   --b-- cccc --a-- ***** \");\n+#ifndef NDEBUG\n+    masker.printStats();\n+#endif\n+    EXPECT_EQ(masker.wipeSensitiveData(x), 3);\n+    EXPECT_EQ(x, \"----a----   ----b---- cccc ----a---- ***** \");\n+#ifndef NDEBUG\n+    masker.printStats();\n+#endif\n+\n+    DB::SensitiveDataMasker masker2(*empty_xml_config , \"\");\n+    masker2.addMaskingRule(\"hide root password\", \"qwerty123\", \"******\");\n+    masker2.addMaskingRule(\"hide SSN\", \"[0-9]{3}-[0-9]{2}-[0-9]{4}\", \"000-00-0000\");\n+    masker2.addMaskingRule(\"hide email\", \"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}\", \"hidden@hidden.test\");\n+\n+    std::string query = \"SELECT id FROM mysql('localhost:3308', 'database', 'table', 'root', 'qwerty123') WHERE ssn='123-45-6789' or \"\n+                        \"email='JonhSmith@secret.domain.test'\";\n+    EXPECT_EQ(masker2.wipeSensitiveData(query), 3);\n+    EXPECT_EQ(\n+        query,\n+        \"SELECT id FROM mysql('localhost:3308', 'database', 'table', 'root', '******') WHERE \"\n+        \"ssn='000-00-0000' or email='hidden@hidden.test'\");\n+\n+\n+#ifndef NDEBUG\n+    // simple benchmark\n+    auto start = std::chrono::high_resolution_clock::now();\n+    constexpr unsigned long int iterations = 200000;\n+    for (int i = 0; i < iterations; ++i)\n+    {\n+        std::string query2 = \"SELECT id FROM mysql('localhost:3308', 'database', 'table', 'root', 'qwerty123') WHERE ssn='123-45-6789' or \"\n+                             \"email='JonhSmith@secret.domain.test'\";\n+        masker2.wipeSensitiveData(query2);\n+    }\n+    auto finish = std::chrono::high_resolution_clock::now();\n+    std::chrono::duration<double> elapsed = finish - start;\n+    std::cout << \"Elapsed time: \" << elapsed.count() << \"s per \" << iterations <<\" calls (\" << elapsed.count() * 1000000 / iterations << \"\u00b5s per call)\"\n+              << std::endl;\n+    // I have: \"Elapsed time: 3.44022s per 200000 calls (17.2011\u00b5s per call)\"\n+    masker2.printStats();\n+#endif\n+\n+    DB::SensitiveDataMasker maskerbad(*empty_xml_config , \"\");\n+\n+    // gtest has not good way to check exception content, so just do it manually (see https://github.com/google/googletest/issues/952 )\n+    try\n+    {\n+        maskerbad.addMaskingRule(\"bad regexp\", \"**\", \"\");\n+        ADD_FAILURE() << \"addMaskingRule() should throw an error\" << std::endl;\n+    }\n+    catch (DB::Exception & e)\n+    {\n+        EXPECT_EQ(\n+            std::string(e.what()),\n+            \"SensitiveDataMasker: cannot compile re2: **, error: no argument for repetition operator: *. Look at \"\n+            \"https://github.com/google/re2/wiki/Syntax for reference.\");\n+        EXPECT_EQ(e.code(), DB::ErrorCodes::CANNOT_COMPILE_REGEXP);\n+    }\n+    /* catch (...) { // not needed, gtest will react unhandled exception\n+        FAIL() << \"ERROR: Unexpected exception thrown: \" << std::current_exception << std::endl; // std::current_exception is part of C++11x\n+    } */\n+\n+    EXPECT_EQ(maskerbad.rulesCount(), 0);\n+    EXPECT_EQ(maskerbad.wipeSensitiveData(x), 0);\n+\n+    {\n+        std::istringstream xml_isteam(R\"END(<?xml version=\"1.0\"?>\n+<clickhouse>\n+    <query_masking_rules>\n+        <rule>\n+            <name>hide SSN</name><!-- by default: it will use xml path, like query_masking_rules.rule[1] -->\n+            <regexp>[0-9]{3}-[0-9]{2}-[0-9]{4}</regexp><!-- mandatory -->\n+            <replace>000-00-0000</replace><!-- by default - six asterisks (******) -->\n+        </rule>\n+        <rule>\n+            <name>hide root password</name>\n+            <regexp>qwerty123</regexp>\n+        </rule>\n+        <rule>\n+            <regexp>(?i)Ivan</regexp>\n+            <replace>John</replace>\n+        </rule>\n+        <rule>\n+            <regexp>(?i)Petrov</regexp>\n+            <replace>Doe</replace>\n+        </rule>\n+        <rule>\n+            <name>hide email</name>\n+            <regexp>(?i)[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}</regexp>\n+            <replace>hidden@hidden.test</replace>\n+        </rule>\n+        <rule>\n+            <name>remove selects to bad_words table</name>\n+            <regexp>^.*bad_words.*$</regexp>\n+            <replace>[QUERY IS CENSORED]</replace>\n+        </rule>\n+    </query_masking_rules>\n+</clickhouse>)END\");\n+\n+        Poco::AutoPtr<Poco::Util::XMLConfiguration> xml_config = new Poco::Util::XMLConfiguration(xml_isteam);\n+        DB::SensitiveDataMasker masker_xml_based(*xml_config, \"query_masking_rules\");\n+        std::string top_secret = \"The e-mail of IVAN PETROV is kotik1902@sdsdf.test, and the password is qwerty123\";\n+        EXPECT_EQ(masker_xml_based.wipeSensitiveData(top_secret), 4);\n+        EXPECT_EQ(top_secret, \"The e-mail of John Doe is hidden@hidden.test, and the password is ******\");\n+\n+        top_secret = \"SELECT * FROM bad_words\";\n+        EXPECT_EQ(masker_xml_based.wipeSensitiveData(top_secret), 1);\n+        EXPECT_EQ(top_secret, \"[QUERY IS CENSORED]\");\n+\n+#ifndef NDEBUG\n+        masker_xml_based.printStats();\n+#endif\n+    }\n+\n+    try\n+    {\n+        std::istringstream xml_isteam_bad(R\"END(<?xml version=\"1.0\"?>\n+<clickhouse>\n+    <query_masking_rules>\n+        <rule>\n+            <name>test</name>\n+            <regexp>abc</regexp>\n+        </rule>\n+        <rule>\n+            <name>test</name>\n+            <regexp>abc</regexp>\n+        </rule>\n+    </query_masking_rules>\n+</clickhouse>)END\");\n+        Poco::AutoPtr<Poco::Util::XMLConfiguration> xml_config = new Poco::Util::XMLConfiguration(xml_isteam_bad);\n+        DB::SensitiveDataMasker masker_xml_based_exception_check(*xml_config, \"query_masking_rules\");\n+\n+        ADD_FAILURE() << \"XML should throw an error on bad XML\" << std::endl;\n+    }\n+    catch (DB::Exception & e)\n+    {\n+        EXPECT_EQ(\n+            std::string(e.what()),\n+            \"query_masking_rules configuration contains more than one rule named 'test'.\");\n+        EXPECT_EQ(e.code(), DB::ErrorCodes::INVALID_CONFIG_PARAMETER);\n+    }\n+\n+\n+    try\n+    {\n+        std::istringstream xml_isteam_bad(R\"END(<?xml version=\"1.0\"?>\n+<clickhouse>\n+    <query_masking_rules>\n+        <rule><name>test</name></rule>\n+    </query_masking_rules>\n+</clickhouse>)END\");\n+\n+        Poco::AutoPtr<Poco::Util::XMLConfiguration> xml_config = new Poco::Util::XMLConfiguration(xml_isteam_bad);\n+        DB::SensitiveDataMasker masker_xml_based_exception_check(*xml_config, \"query_masking_rules\");\n+\n+        ADD_FAILURE() << \"XML should throw an error on bad XML\" << std::endl;\n+    }\n+    catch (DB::Exception & e)\n+    {\n+        EXPECT_EQ(\n+            std::string(e.what()),\n+            \"query_masking_rules configuration, rule 'test' has no <regexp> node or <regexp> is empty.\");\n+        EXPECT_EQ(e.code(), DB::ErrorCodes::NO_ELEMENTS_IN_CONFIG);\n+    }\n+\n+\n+    try\n+    {\n+        std::istringstream xml_isteam_bad(R\"END(<?xml version=\"1.0\"?>\n+<clickhouse>\n+    <query_masking_rules>\n+        <rule><name>test</name><regexp>())(</regexp></rule>\n+    </query_masking_rules>\n+</clickhouse>)END\");\n+\n+        Poco::AutoPtr<Poco::Util::XMLConfiguration> xml_config = new Poco::Util::XMLConfiguration(xml_isteam_bad);\n+        DB::SensitiveDataMasker masker_xml_based_exception_check(*xml_config, \"query_masking_rules\");\n+\n+        ADD_FAILURE() << \"XML should throw an error on bad XML\" << std::endl;\n+    }\n+    catch (DB::Exception & e)\n+    {\n+        EXPECT_EQ(\n+            std::string(e.message()),\n+            \"SensitiveDataMasker: cannot compile re2: ())(, error: missing ): ())(. Look at https://github.com/google/re2/wiki/Syntax for reference.: while adding query masking rule 'test'.\"\n+        );\n+        EXPECT_EQ(e.code(), DB::ErrorCodes::CANNOT_COMPILE_REGEXP);\n+    }\n+\n+}\ndiff --git a/dbms/tests/queries/0_stateless/00956_sensitive_data_masking.reference b/dbms/tests/queries/0_stateless/00956_sensitive_data_masking.reference\nnew file mode 100644\nindex 000000000000..10856627eace\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00956_sensitive_data_masking.reference\n@@ -0,0 +1,10 @@\n+1\n+2\n+3\n+4\n+5\n+5.1\n+6\n+7\n+8\n+finish\ndiff --git a/dbms/tests/queries/0_stateless/00956_sensitive_data_masking.sh b/dbms/tests/queries/0_stateless/00956_sensitive_data_masking.sh\nnew file mode 100755\nindex 000000000000..cca4b363b105\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00956_sensitive_data_masking.sh\n@@ -0,0 +1,110 @@\n+#!/usr/bin/env bash\n+\n+# Get all server logs\n+export CLICKHOUSE_CLIENT_SERVER_LOGS_LEVEL=\"trace\"\n+#export CLICKHOUSE_BINARY='../../../../build-vscode/Debug/dbms/programs/clickhouse'\n+#export CLICKHOUSE_PORT_TCP=59000\n+#export CLICKHOUSE_CLIENT_BINARY='../../../../cmake-build-debug/dbms/programs/clickhouse client'\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+cur_name=$(basename \"${BASH_SOURCE[0]}\")\n+tmp_file=${CLICKHOUSE_TMP}/$cur_name\"_server.logs\"\n+\n+rm -f $tmp_file >/dev/null 2>&1\n+echo 1\n+# normal execution\n+$CLICKHOUSE_CLIENT \\\n+  --query=\"SELECT 'find_me_TOPSECRET=TOPSECRET' FROM numbers(1) FORMAT Null\" \\\n+  --log_queries=1 --ignore-error --multiquery >$tmp_file 2>&1\n+\n+grep 'find_me_\\[hidden\\]' $tmp_file >/dev/null || echo 'fail 1a'\n+grep 'TOPSECRET' $tmp_file && echo 'fail 1b'\n+\n+rm -f $tmp_file >/dev/null 2>&1\n+echo 2\n+# failure at parsing stage\n+echo \"SELECT 'find_me_TOPSECRET=TOPSECRET' FRRRROM numbers\" | ${CLICKHOUSE_CURL} -sSg ${CLICKHOUSE_URL} -d @- >$tmp_file 2>&1\n+\n+#cat $tmp_file\n+\n+## can't be checked on client side!\n+# grep 'find_me_\\[hidden\\]' $tmp_file >/dev/null || echo 'fail 2a'\n+grep 'TOPSECRET' $tmp_file && echo 'fail 2b'\n+\n+rm -f $tmp_file >/dev/null 2>&1\n+echo 3\n+# failure at before query start\n+$CLICKHOUSE_CLIENT \\\n+  --query=\"SELECT 'find_me_TOPSECRET=TOPSECRET' FROM non_existing_table FORMAT Null\" \\\n+  --log_queries=1 --ignore-error --multiquery >$tmp_file 2>&1\n+\n+grep 'find_me_\\[hidden\\]' $tmp_file >/dev/null || echo 'fail 3a'\n+grep 'TOPSECRET' $tmp_file && echo 'fail 3b'\n+\n+rm -f $tmp_file >/dev/null 2>&1\n+echo 4\n+# failure at the end of query\n+$CLICKHOUSE_CLIENT \\\n+  --query=\"SELECT 'find_me_TOPSECRET=TOPSECRET', intDiv( 100, number - 10) FROM numbers(11) FORMAT Null\" \\\n+  --log_queries=1 --ignore-error --max_block_size=2 --multiquery >$tmp_file 2>&1\n+\n+grep 'find_me_\\[hidden\\]' $tmp_file >/dev/null || echo 'fail 4a'\n+grep 'TOPSECRET' $tmp_file && echo 'fail 4b'\n+\n+echo 5\n+# run in background\n+bash -c \"$CLICKHOUSE_CLIENT \\\n+  --query=\\\"select sleepEachRow(0.5) from numbers(4) where ignore('find_me_TOPSECRET=TOPSECRET')=0 and ignore('fwerkh_that_magic_string_make_me_unique') = 0 FORMAT Null\\\" \\\n+  --log_queries=1 --ignore-error --multiquery 2>&1 | grep TOPSECRET\" &\n+\n+sleep 0.1\n+\n+# $CLICKHOUSE_CLIENT --query='SHOW PROCESSLIST'\n+\n+rm -f $tmp_file >/dev/null 2>&1\n+echo '5.1'\n+# check that executing query doesn't expose secrets in processlist\n+$CLICKHOUSE_CLIENT --query=\"SHOW PROCESSLIST\" --log_queries=0 >$tmp_file 2>&1\n+\n+grep 'fwerkh_that_magic_string_make_me_unique' $tmp_file >/dev/null || echo 'fail 5a'\n+( grep 'fwerkh_that_magic_string_make_me_unique' $tmp_file | grep 'find_me_\\[hidden\\]' $tmp_file >/dev/null ) || echo 'fail 5b'\n+grep 'TOPSECRET' $tmp_file && echo 'fail 5c'\n+\n+wait\n+\n+\n+# instead of disabling send_logs_level=trace (enabled globally for that test) - redir it's output to /dev/null\n+$CLICKHOUSE_CLIENT \\\n+  --server_logs_file=/dev/null \\\n+  --query=\"system flush logs\"\n+\n+\n+echo 6\n+# check events count properly increments\n+$CLICKHOUSE_CLIENT \\\n+  --server_logs_file=/dev/null \\\n+  --query=\"select * from (select sum(value) as matches from system.events where event='QueryMaskingRulesMatch') where matches < 5\"\n+\n+echo 7\n+# and finally querylog\n+$CLICKHOUSE_CLIENT \\\n+  --server_logs_file=/dev/null \\\n+  --query=\"select * from system.query_log where event_time>now() - 10 and query like '%TOPSECRET%';\"\n+\n+\n+rm -f $tmp_file >/dev/null 2>&1\n+echo 8\n+$CLICKHOUSE_CLIENT \\\n+   --query=\"drop table if exists sensetive; create table sensitive ( id UInt64, date Date, value1 String, value2 UInt64) Engine=MergeTree ORDER BY id PARTITION BY date;\n+insert into sensitive select number as id, toDate('2019-01-01') as date, 'abcd' as value1, rand() as valuer from numbers(10000);\n+insert into sensitive select number as id, toDate('2019-01-01') as date, 'find_me_TOPSECRET=TOPSECRET' as value1, rand() as valuer from numbers(10);\n+insert into sensitive select number as id, toDate('2019-01-01') as date, 'abcd' as value1, rand() as valuer from numbers(10000);\n+select * from sensitive WHERE value1 = 'find_me_TOPSECRET=TOPSECRET' FORMAT Null;\n+drop table sensitive;\" --log_queries=1 --ignore-error --multiquery >$tmp_file 2>&1\n+\n+grep 'find_me_\\[hidden\\]' $tmp_file >/dev/null || echo 'fail 8a'\n+grep 'TOPSECRET' $tmp_file && echo 'fail 8b'\n+\n+echo 'finish'\n\\ No newline at end of file\n",
  "problem_statement": "Add cleansing rules to prevent SQL queries from leaking sensitive data into log\n**Use case**\r\nUsers who want to protect sensitive data in ClickHouse need a way to prevent data from accidentally leaking through logs.  One way that this can happen is through queries logged in the clickhouse-system.log or system.query_log table.  If messages from either of these are extracted to Splunk or similar systems, sensitive data like credit card numbers use in query expressions may leak out and be exposed to people who should not see them. \r\n\r\n**Describe the solution you'd like**\r\nI would like to add a feature to apply apply cleansing rules to any query that ClickHouse logs.  It would work as follows. \r\n1. Add a new property in /etc/clickhouse-server.xml to define regular expressions to seek in queries when logging.  Here's an example to match US social security numbers.\r\n```\r\n<query_cleansing_rules>\r\n  <regexp>[0-9]{3}-[0-9]{2}-[0-9]{4}</regexp>\r\n</query_cleansing_rules>\r\n```\r\n2. Whenever a query is logged, run the foregoing regular expressions on the query string.  Any matching strings would be replaced by a standard value like '********'. \r\n\r\nThis requires simple changes in just a couple of locations to implement (notably executeQuery.cpp and perhaps BaseDaemon.cpp)\r\n\r\n**Describe alternatives you've considered**\r\nI looked for a more general way to do this, for example by making setting changes in Poco log configuration.  However there does not appear to be a centralized way to do this, and Poco anyway is not used for logging to system.query_log.  Also running regexp on large numbers of messages would impact server performance.  \r\n\r\n**Additional context**\r\nThis feature is very useful for achieving PCI-DSS compliance (standard for handling credit card data). \r\n\r\n**Outstanding Questions**\r\nAre there other ways data can leak out into the logs?\n",
  "hints_text": "About implementation - if it will be done on log level only - then query_log (for example) or error messages will still contain the unsafe strings.  Probably for error messages, it's acceptable (?), but for query_log it sounds like it should be done too.\r\n\r\nSo it should be either filter added in two places, either special getter function to 'safe variant' of the query (both original or that reconstructed from AST).\r\n\r\nBoth options don't sound complicated.\r\n\r\nOf course for distributed queried all servers in the cluster should be configured the same.\r\n\r\nBTW: For query_log maybe it would be cool to store constants separately from query to make it easy to group queries with the same pattern (is there a task/feature request for that somewhere?)\r\n",
  "created_at": "2019-06-21T12:50:35Z"
}