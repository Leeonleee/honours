{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 15007,
  "instance_id": "ClickHouse__ClickHouse-15007",
  "issue_numbers": [
    "14886"
  ],
  "base_commit": "c0d1416bbd564fa1e9b3ae5e58b1a5785b5d891a",
  "patch": "diff --git a/benchmark/greenplum/result_parser.py b/benchmark/greenplum/result_parser.py\nindex ea178cf77a42..8af20d265a02 100755\n--- a/benchmark/greenplum/result_parser.py\n+++ b/benchmark/greenplum/result_parser.py\n@@ -1,6 +1,6 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n+\n \n-from __future__ import print_function\n import sys\n import json\n \n@@ -99,7 +99,7 @@ def gen_html_json(options, arguments):\n     tuples = read_stats_file(options, arguments[1])\n     print('{')\n     print('\"system:       GreenPlum(x2),')\n-    print('\"version\":      \"%s\",' % '4.3.9.1')\n+    print(('\"version\":      \"%s\",' % '4.3.9.1'))\n     print('\"data_size\":    10000000,')\n     print('\"time\":         \"\",')\n     print('\"comments\":     \"\",')\ndiff --git a/debian/control b/debian/control\nindex 1014b8b0a3c0..12d69d9fff6b 100644\n--- a/debian/control\n+++ b/debian/control\n@@ -62,5 +62,5 @@ Description: debugging symbols for clickhouse-common-static\n Package: clickhouse-test\n Priority: optional\n Architecture: all\n-Depends: ${shlibs:Depends}, ${misc:Depends}, clickhouse-client, bash, expect, python, python-lxml, python-termcolor, python-requests, curl, perl, sudo, openssl, netcat-openbsd, telnet, brotli, bsdutils\n+Depends: ${shlibs:Depends}, ${misc:Depends}, clickhouse-client, bash, expect, python3, python3-lxml, python3-termcolor, python3-requests, curl, perl, sudo, openssl, netcat-openbsd, telnet, brotli, bsdutils\n Description: ClickHouse tests\ndiff --git a/docker/builder/Dockerfile b/docker/builder/Dockerfile\nindex d4a121d13eb3..68245a92c58a 100644\n--- a/docker/builder/Dockerfile\n+++ b/docker/builder/Dockerfile\n@@ -25,10 +25,10 @@ RUN apt-get update \\\n         ninja-build \\\n         perl \\\n         pkg-config \\\n-        python \\\n-        python-lxml \\\n-        python-requests \\\n-        python-termcolor \\\n+        python3 \\\n+        python3-lxml \\\n+        python3-requests \\\n+        python3-termcolor \\\n         tzdata \\\n         llvm-${LLVM_VERSION} \\\n         clang-${LLVM_VERSION} \\\ndiff --git a/docker/packager/packager b/docker/packager/packager\nindex 0a14102ec04c..6d0751950034 100755\n--- a/docker/packager/packager\n+++ b/docker/packager/packager\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n #-*- coding: utf-8 -*-\n import subprocess\n import os\ndiff --git a/docs/en/development/build.md b/docs/en/development/build.md\nindex 1c84342baf99..145dd99e8de2 100644\n--- a/docs/en/development/build.md\n+++ b/docs/en/development/build.md\n@@ -116,7 +116,7 @@ ninja\n Example for Fedora Rawhide:\n ``` bash\n sudo yum update\n-yum --nogpg install git cmake make gcc-c++ python2\n+yum --nogpg install git cmake make gcc-c++ python3\n git clone --recursive https://github.com/ClickHouse/ClickHouse.git\n mkdir build && cd build\n cmake ../ClickHouse\ndiff --git a/docs/es/development/build.md b/docs/es/development/build.md\nindex 861ceb53e515..0b190242f8cf 100644\n--- a/docs/es/development/build.md\n+++ b/docs/es/development/build.md\n@@ -102,7 +102,7 @@ Ejemplo de OpenSUSE Tumbleweed:\n Ejemplo de Fedora Rawhide:\n \n     sudo yum update\n-    yum --nogpg install git cmake make gcc-c++ python2\n+    yum --nogpg install git cmake make gcc-c++ python3\n     git clone --recursive https://github.com/ClickHouse/ClickHouse.git\n     mkdir build && cd build\n     cmake ../ClickHouse\ndiff --git a/docs/fa/development/build.md b/docs/fa/development/build.md\nindex 8b9d8bba8223..7ba21c0fa933 100644\n--- a/docs/fa/development/build.md\n+++ b/docs/fa/development/build.md\n@@ -103,7 +103,7 @@ $ cd ..\n \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0645\u062b\u0627\u0644 \u0628\u0631\u0627\u06cc \u0641\u062f\u0648\u0631\u0627 \u067e\u0648\u0633\u062a \u062f\u0628\u0627\u063a\u06cc \u0646\u0634\u062f\u0647:\n \n     sudo yum update\n-    yum --nogpg install git cmake make gcc-c++ python2\n+    yum --nogpg install git cmake make gcc-c++ python3\n     git clone --recursive https://github.com/ClickHouse/ClickHouse.git\n     mkdir build && cd build\n     cmake ../ClickHouse\ndiff --git a/docs/fr/development/build.md b/docs/fr/development/build.md\nindex a57e0f203372..d05f09997205 100644\n--- a/docs/fr/development/build.md\n+++ b/docs/fr/development/build.md\n@@ -102,7 +102,7 @@ Exemple Pour openSUSE Tumbleweed:\n Exemple Pour Fedora Rawhide:\n \n     sudo yum update\n-    yum --nogpg install git cmake make gcc-c++ python2\n+    yum --nogpg install git cmake make gcc-c++ python3\n     git clone --recursive https://github.com/ClickHouse/ClickHouse.git\n     mkdir build && cd build\n     cmake ../ClickHouse\ndiff --git a/docs/ja/development/build.md b/docs/ja/development/build.md\nindex c1e92efd4412..035d5e7efb1d 100644\n--- a/docs/ja/development/build.md\n+++ b/docs/ja/development/build.md\n@@ -102,7 +102,7 @@ OpenSUSE\u30bf\u30f3\u30d6\u30eb\u30a6\u30a3\u30fc\u30c9\u306e\u4f8b:\n Fedora Rawhide\u306e\u4f8b:\n \n     sudo yum update\n-    yum --nogpg install git cmake make gcc-c++ python2\n+    yum --nogpg install git cmake make gcc-c++ python3\n     git clone --recursive https://github.com/ClickHouse/ClickHouse.git\n     mkdir build && cd build\n     cmake ../ClickHouse\ndiff --git a/docs/tools/easy_diff.py b/docs/tools/easy_diff.py\nindex e4b5b6755252..22d305d3da3f 100755\n--- a/docs/tools/easy_diff.py\n+++ b/docs/tools/easy_diff.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # -*- coding: utf-8 -*-\n \n import os, sys\ndiff --git a/docs/tools/github.py b/docs/tools/github.py\nindex d007752dca9a..29184f5e5679 100644\n--- a/docs/tools/github.py\n+++ b/docs/tools/github.py\n@@ -71,8 +71,8 @@ def choose_latest_releases(args):\n             logging.fatal('Unexpected GitHub response: %s', str(candidates))\n             sys.exit(1)\n \n-    logging.info('Found LTS releases: %s', ', '.join(seen_lts.keys()))\n-    logging.info('Found stable releases: %s', ', '.join(seen_stable.keys()))\n+    logging.info('Found LTS releases: %s', ', '.join(list(seen_lts.keys())))\n+    logging.info('Found stable releases: %s', ', '.join(list(seen_stable.keys())))\n     return sorted(list(seen_lts.items()) + list(seen_stable.items()))\n \n \ndiff --git a/docs/tools/mdx_clickhouse.py b/docs/tools/mdx_clickhouse.py\nindex 80ecf8293418..b4c255066ffa 100755\n--- a/docs/tools/mdx_clickhouse.py\n+++ b/docs/tools/mdx_clickhouse.py\n@@ -1,6 +1,6 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # -*- coding: utf-8 -*-\n-from __future__ import unicode_literals\n+\n \n import datetime\n import os\ndiff --git a/docs/tools/nav.py b/docs/tools/nav.py\nindex d14791a5b9b3..291797a16339 100644\n--- a/docs/tools/nav.py\n+++ b/docs/tools/nav.py\n@@ -59,7 +59,7 @@ def build_docs_nav(lang, args):\n     _, _, nav = build_nav_entry(docs_dir, args)\n     result = []\n     index_key = None\n-    for key, value in nav.items():\n+    for key, value in list(nav.items()):\n         if key and value:\n             if value == 'index.md':\n                 index_key = key\ndiff --git a/docs/tools/purge_cache_for_changed_files.py b/docs/tools/purge_cache_for_changed_files.py\nindex 761697770b7e..6cfc9d18a575 100644\n--- a/docs/tools/purge_cache_for_changed_files.py\n+++ b/docs/tools/purge_cache_for_changed_files.py\n@@ -59,7 +59,7 @@ def convert_to_dicts(changed_files, batch_size):\n def post_data(prepared_batches, token):\n     headers = {\"Authorization\": \"Bearer {}\".format(token)}\n     for batch in prepared_batches:\n-        print(\"Pugring cache for\", \", \".join(batch[\"files\"]))\n+        print((\"Pugring cache for\", \", \".join(batch[\"files\"])))\n         response = requests.post(CLOUDFLARE_URL, json=batch, headers=headers)\n         response.raise_for_status()\n         time.sleep(3)\n@@ -71,8 +71,8 @@ def post_data(prepared_batches, token):\n         raise Exception(\"Env variable CLOUDFLARE_TOKEN is empty\")\n     base_domain = os.getenv(\"BASE_DOMAIN\", \"https://content.clickhouse.tech/\")\n     changed_files = collect_changed_files()\n-    print(\"Found\", len(changed_files), \"changed files\")\n+    print((\"Found\", len(changed_files), \"changed files\"))\n     filtered_files = filter_and_transform_changed_files(changed_files, base_domain)\n-    print(\"Files rest after filtering\", len(filtered_files))\n+    print((\"Files rest after filtering\", len(filtered_files)))\n     prepared_batches = convert_to_dicts(filtered_files, 25)\n     post_data(prepared_batches, token)\ndiff --git a/docs/tools/single_page.py b/docs/tools/single_page.py\nindex b074cd42329b..004409fe281c 100644\n--- a/docs/tools/single_page.py\n+++ b/docs/tools/single_page.py\n@@ -15,7 +15,7 @@\n \n def recursive_values(item):\n     if isinstance(item, dict):\n-        for _, value in item.items():\n+        for _, value in list(item.items()):\n             yield from recursive_values(value)\n     elif isinstance(item, list):\n         for value in item:\ndiff --git a/docs/tools/translate/typograph_ru.py b/docs/tools/translate/typograph_ru.py\nindex db20109efffc..2d970cf2a2e4 100644\n--- a/docs/tools/translate/typograph_ru.py\n+++ b/docs/tools/translate/typograph_ru.py\n@@ -42,4 +42,4 @@ def typograph(text):\n \n if __name__ == '__main__':\n     import sys\n-    print(typograph(sys.stdin.read()))\n+    print((typograph(sys.stdin.read())))\ndiff --git a/docs/tr/development/build.md b/docs/tr/development/build.md\nindex 18ef2cd66aef..90cb166094d4 100644\n--- a/docs/tr/development/build.md\n+++ b/docs/tr/development/build.md\n@@ -102,7 +102,7 @@ OpenSUSE Tumbleweed i\u00e7in \u00f6rnek:\n Fedora Rawhide i\u00e7in \u00f6rnek:\n \n     sudo yum update\n-    yum --nogpg install git cmake make gcc-c++ python2\n+    yum --nogpg install git cmake make gcc-c++ python3\n     git clone --recursive https://github.com/ClickHouse/ClickHouse.git\n     mkdir build && cd build\n     cmake ../ClickHouse\ndiff --git a/release b/release\nindex b446ceca0d5c..f2052840cb04 100755\n--- a/release\n+++ b/release\n@@ -66,7 +66,7 @@ do\n         shift\n     elif [[ $1 == '--fast' ]]; then\n         # Wrong but fast pbuilder mode: create base package with all depends\n-        EXTRAPACKAGES=\"$EXTRAPACKAGES debhelper cmake ninja-build gcc-8 g++-8 libc6-dev libicu-dev libreadline-dev psmisc bash expect python python-lxml python-termcolor python-requests curl perl sudo openssl netcat-openbsd\"\n+        EXTRAPACKAGES=\"$EXTRAPACKAGES debhelper cmake ninja-build gcc-8 g++-8 libc6-dev libicu-dev libreadline-dev psmisc bash expect python3 python3-lxml python3-termcolor python3-requests curl perl sudo openssl netcat-openbsd\"\n         shift\n     elif [[ $1 == '--rpm' ]]; then\n         MAKE_RPM=1\ndiff --git a/utils/build/build_debian.sh b/utils/build/build_debian.sh\nindex 4ae54b0d29fd..c6cfe6ce4b89 100755\n--- a/utils/build/build_debian.sh\n+++ b/utils/build/build_debian.sh\n@@ -11,7 +11,7 @@ sudo apt install -y git bash cmake ninja-build gcc-8 g++-8 libicu-dev libreadlin\n #sudo apt install -y libboost-program-options-dev libboost-system-dev libboost-filesystem-dev libboost-thread-dev libboost-regex-dev libboost-iostreams-dev zlib1g-dev liblz4-dev libdouble-conversion-dev libzstd-dev libre2-dev librdkafka-dev libcapnp-dev libpoco-dev libgoogle-perftools-dev libunwind-dev googletest libcctz-dev\n \n # install testing only stuff if you want:\n-sudo apt install -y expect python python-lxml python-termcolor python-requests curl perl sudo openssl netcat-openbsd telnet\n+sudo apt install -y expect python3 python3-lxml python3-termcolor python3-requests curl perl sudo openssl netcat-openbsd telnet\n \n BASE_DIR=$(dirname $0) && [ -f \"$BASE_DIR/../../CMakeLists.txt\" ] && ROOT_DIR=$BASE_DIR/../.. && cd $ROOT_DIR\n \ndiff --git a/utils/github-hook/hook.py b/utils/github-hook/hook.py\nindex 22eb85867c32..1ea65f3c3abc 100644\n--- a/utils/github-hook/hook.py\n+++ b/utils/github-hook/hook.py\n@@ -12,7 +12,7 @@\n \n def _reverse_dict_with_list(source):\n     result = {}\n-    for key, value in source.items():\n+    for key, value in list(source.items()):\n         for elem in value:\n             result[elem] = key\n     return result\n@@ -48,14 +48,14 @@ def set_labels_for_pr(pull_request_number, labels, headers):\n             response.raise_for_status()\n             break\n         except Exception as ex:\n-            print(\"Exception\", ex)\n+            print((\"Exception\", ex))\n             time.sleep(0.2)\n \n \n def get_required_labels_from_desc(description, current_labels):\n     result = set([])\n     # find first matching category\n-    for marker, labels in MARKER_TO_LABEL.items():\n+    for marker, labels in list(MARKER_TO_LABEL.items()):\n         if marker in description:\n             if not any(label in current_labels for label in labels):\n                 result.add(labels[0])\n@@ -282,9 +282,9 @@ def _insert_json_str_info(self, db, table, json_str):\n                 response.raise_for_status()\n                 break\n             except Exception as ex:\n-                print(\"Cannot insert with exception %s\", str(ex))\n+                print((\"Cannot insert with exception %s\", str(ex)))\n                 if response:\n-                    print(\"Response text %s\", response.text)\n+                    print((\"Response text %s\", response.text))\n                 time.sleep(0.1)\n         else:\n             raise Exception(\"Cannot insert data into clickhouse\")\ndiff --git a/utils/github/backport.py b/utils/github/backport.py\nindex 3a33c3a563f1..f303be23ac40 100644\n--- a/utils/github/backport.py\n+++ b/utils/github/backport.py\n@@ -78,14 +78,14 @@ def execute(self, repo, until_commit, number, run_cherrypick):\n                     backport_map[pr['number']].remove(matched_backported.group(1))\n                     logging.info('\\tskipping %s because it\\'s already backported manually', matched_backported.group(1))\n \n-        for pr, branches in backport_map.items():\n+        for pr, branches in list(backport_map.items()):\n             logging.info('PR #%s needs to be backported to:', pr)\n             for branch in branches:\n                 logging.info('\\t%s, and the status is: %s', branch, run_cherrypick(self._token, pr, branch))\n \n         # print API costs\n         logging.info('\\nGitHub API total costs per query:')\n-        for name, value in self._gh.api_costs.items():\n+        for name, value in list(self._gh.api_costs.items()):\n             logging.info('%s : %s', name, value)\n \n \ndiff --git a/utils/github/parser.py b/utils/github/parser.py\nindex 2f00cac9bb4a..570410ba23d4 100644\n--- a/utils/github/parser.py\n+++ b/utils/github/parser.py\n@@ -57,4 +57,4 @@ def _parse(self, text):\n             if not category:\n                 print('Cannot find category in pr description')\n             else:\n-                print('Unknown category: ' + category)\n+                print(('Unknown category: ' + category))\ndiff --git a/utils/github/query.py b/utils/github/query.py\nindex 9182b001dfe0..ac3ce5bffa96 100644\n--- a/utils/github/query.py\n+++ b/utils/github/query.py\n@@ -517,7 +517,7 @@ def requests_retry_session(\n                 if not is_mutation:\n                     import inspect\n                     caller = inspect.getouterframes(inspect.currentframe(), 2)[1][3]\n-                    if caller not in self.api_costs.keys():\n+                    if caller not in list(self.api_costs.keys()):\n                         self.api_costs[caller] = 0\n                     self.api_costs[caller] += result['data']['rateLimit']['cost']\n \ndiff --git a/utils/junit_to_html/junit_to_html b/utils/junit_to_html/junit_to_html\nindex cf50e7df00ac..132763c7d4ce 100755\n--- a/utils/junit_to_html/junit_to_html\n+++ b/utils/junit_to_html/junit_to_html\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # -*- coding: utf-8 -*-\n import os\n import lxml.etree as etree\n@@ -82,5 +82,5 @@ if __name__ == \"__main__\":\n         result_path = args.result_dir\n     else:\n         result_path = os.path.dirname(junit_path)\n-    print \"junit_path: {}, result_path: {}, export cases:{}, export suites: {}\".format(junit_path, result_path, args.export_cases, args.export_suites)\n+    print(\"junit_path: {}, result_path: {}, export cases:{}, export suites: {}\".format(junit_path, result_path, args.export_cases, args.export_suites))\n     _convert_junit_to_html(junit_path, result_path, args.export_cases, args.export_suites)\ndiff --git a/utils/kafka/manage.py b/utils/kafka/manage.py\nindex 01847c7675b2..7458bdceb74b 100755\n--- a/utils/kafka/manage.py\n+++ b/utils/kafka/manage.py\n@@ -30,9 +30,9 @@ def main():\n \n     client = kafka.KafkaAdminClient(**config)\n     if args.create:\n-        print(client.create_topics(args.create))\n+        print((client.create_topics(args.create)))\n     elif args.delete:\n-        print(client.delete_topics(args.delete))\n+        print((client.delete_topics(args.delete)))\n \n     client.close()\n     return 0\ndiff --git a/utils/make_changelog.py b/utils/make_changelog.py\nindex fb8fa037001d..5a5c82e5ab66 100755\n--- a/utils/make_changelog.py\n+++ b/utils/make_changelog.py\n@@ -1,6 +1,6 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # Note: should work with python 2 and 3\n-from __future__ import print_function\n+\n \n import requests\n import json\n@@ -201,10 +201,10 @@ def update_user(user):\n             resp = github_api_get_json(query, token, max_retries, retry_timeout)\n             users[user] = resp\n \n-    for pull_request in pull_requests.values():\n+    for pull_request in list(pull_requests.values()):\n         update_user(pull_request['user'])\n \n-    for commit_info in commits_info.values():\n+    for commit_info in list(commits_info.values()):\n         if 'committer' in commit_info and commit_info['committer'] is not None and 'login' in commit_info['committer']:\n             update_user(commit_info['committer']['login'])\n         else:\n@@ -216,7 +216,7 @@ def update_user(user):\n # List of unknown commits -> text description.\n def process_unknown_commits(commits, commits_info, users):\n \n-    pattern = u'Commit: [{}]({})\\nAuthor: {}\\nMessage: {}'\n+    pattern = 'Commit: [{}]({})\\nAuthor: {}\\nMessage: {}'\n \n     texts = []\n \n@@ -262,7 +262,7 @@ def process_unknown_commits(commits, commits_info, users):\n # Returns False if the PR should not be mentioned changelog.\n def parse_one_pull_request(item):\n     description = item['description']\n-    lines = [line for line in map(lambda x: x.strip(), description.split('\\n') if description else []) if line]\n+    lines = [line for line in [x.strip() for x in description.split('\\n') if description else []] if line]\n     lines = [re.sub(r'\\s+', ' ', l) for l in lines]\n \n     cat_pos = None\n@@ -310,17 +310,17 @@ def parse_one_pull_request(item):\n def process_pull_requests(pull_requests, users, repo):\n     groups = {}\n \n-    for id, item in pull_requests.items():\n+    for id, item in list(pull_requests.items()):\n         if not parse_one_pull_request(item):\n             continue\n \n-        pattern = u\"{} [#{}]({}) ({})\"\n+        pattern = \"{} [#{}]({}) ({})\"\n         link = 'https://github.com/{}/pull/{}'.format(repo, id)\n         author = 'author not found'\n         if item['user'] in users:\n             # TODO get user from any commit if no user name on github\n             user = users[item['user']]\n-            author = u'[{}]({})'.format(user['name'] or user['login'], user['html_url'])\n+            author = '[{}]({})'.format(user['name'] or user['login'], user['html_url'])\n \n         cat = item['category']\n         if cat not in groups:\n@@ -336,9 +336,9 @@ def categories_sort_key(name):\n             return name.lower()\n \n     texts = []\n-    for group, text in sorted(groups.items(), key = lambda kv: categories_sort_key(kv[0])):\n-        items = [u'* {}'.format(pr) for pr in text]\n-        texts.append(u'### {}\\n{}'.format(group if group else u'[No category]', '\\n'.join(items)))\n+    for group, text in sorted(list(groups.items()), key = lambda kv: categories_sort_key(kv[0])):\n+        items = ['* {}'.format(pr) for pr in text]\n+        texts.append('### {}\\n{}'.format(group if group else '[No category]', '\\n'.join(items)))\n \n     return '\\n\\n'.join(texts)\n \n@@ -456,7 +456,7 @@ def make_changelog(new_tag, prev_tag, pull_requests_nums, repo, repo_folder, sta\n     logging.info('Found %d users.', len(users))\n     save_state(state_file, state)\n \n-    changelog = u'{}\\n\\n{}'.format(process_pull_requests(pull_requests, users, repo), process_unknown_commits(unknown_commits, commits_info, users))\n+    changelog = '{}\\n\\n{}'.format(process_pull_requests(pull_requests, users, repo), process_unknown_commits(unknown_commits, commits_info, users))\n \n     # Substitute links to issues\n     changelog = re.sub(r'(?<!\\[)#(\\d{4,})(?!\\])', r'[#\\1](https://github.com/{}/issues/\\1)'.format(repo), changelog)\ndiff --git a/utils/release/push_packages b/utils/release/push_packages\nindex 43e75a723da7..e25cb325c711 100755\n--- a/utils/release/push_packages\n+++ b/utils/release/push_packages\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # -*- coding: utf-8 -*-\n import argparse\n import subprocess\n@@ -54,7 +54,7 @@ class DebRelease(object):\n \n     def __init__(self, dupload_config, login, ssh_key_path):\n         self.__config = {}\n-        for repo, conf in dupload_config.iteritems():\n+        for repo, conf in dupload_config.items():\n             d = {\n                 \"fqdn\": conf[\"fqdn\"],\n                 \"method\": \"scpb\",\n@@ -65,7 +65,7 @@ class DebRelease(object):\n             }\n             d.update(conf)\n             self.__config[repo] = d\n-        print self.__config\n+        print(self.__config)\n         self.ssh_key_path = ssh_key_path\n \n     def __enter__(self):\n@@ -74,7 +74,7 @@ class DebRelease(object):\n         self.__dupload_conf = open(self.DUPLOAD_CONF_PATH, 'w')\n         self.__dupload_conf.write('package config;\\n\\n$default_host = undef;\\n\\n' + '\\n\\n'.join([\n             self.DUPLOAD_CONF_TEMPLATE.format(title=title, **values)\n-            for title, values in self.__config.iteritems()]))\n+            for title, values in self.__config.items()]))\n         self.__dupload_conf.write('\\n')\n         self.__dupload_conf.close()\n         if self.ssh_key_path:\ndiff --git a/utils/release/release_lib.sh b/utils/release/release_lib.sh\nindex 569e1dfb9f23..c4dd177b931b 100644\n--- a/utils/release/release_lib.sh\n+++ b/utils/release/release_lib.sh\n@@ -253,8 +253,8 @@ function make_rpm {\n     TARGET=noarch\n     deb_unpack\n     mv ${PACKAGE}-$VERSION_FULL-2.spec ${PACKAGE}-$VERSION_FULL-2.spec_tmp\n-    echo \"Requires: python2\" >> ${PACKAGE}-$VERSION_FULL-2.spec\n-    #echo \"Requires: python2-termcolor\" >> ${PACKAGE}-$VERSION-2.spec\n+    echo \"Requires: python3\" >> ${PACKAGE}-$VERSION_FULL-2.spec\n+    #echo \"Requires: python3-termcolor\" >> ${PACKAGE}-$VERSION-2.spec\n     cat ${PACKAGE}-$VERSION_FULL-2.spec_tmp >> ${PACKAGE}-$VERSION_FULL-2.spec\n     rpm_pack\n \ndiff --git a/utils/s3tools/s3uploader b/utils/s3tools/s3uploader\nindex 4e8722e08517..a21263c1094f 100755\n--- a/utils/s3tools/s3uploader\n+++ b/utils/s3tools/s3uploader\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python2\n+#!/usr/bin/env python3\n # -*- coding: utf-8 -*-\n import os\n import logging\n@@ -32,7 +32,7 @@ class S3API(object):\n         chunkcount = int(math.ceil(filesize / chunksize))\n \n         def call_back(x, y):\n-            print \"Uploaded {}/{} bytes\".format(x, y)\n+            print(\"Uploaded {}/{} bytes\".format(x, y))\n         try:\n             for i in range(chunkcount + 1):\n                 logging.info(\"Uploading chunk %s of %s\", i, chunkcount + 1)\ndiff --git a/utils/simple-backport/format-changelog.py b/utils/simple-backport/format-changelog.py\nindex 5dff4f1c5e88..e0fe4912d5dc 100755\n--- a/utils/simple-backport/format-changelog.py\n+++ b/utils/simple-backport/format-changelog.py\n@@ -18,7 +18,7 @@\n def parse_one_pull_request(item):\n     description = item['body']\n     # Don't skip empty lines because they delimit parts of description\n-    lines = [line for line in map(lambda x: x.strip(), description.split('\\n') if description else [])]\n+    lines = [line for line in [x.strip() for x in description.split('\\n') if description else []]]\n     lines = [re.sub(r'\\s+', ' ', l) for l in lines]\n \n     category = ''\n@@ -102,7 +102,7 @@ def parse_one_pull_request(item):\n     users[user_id] = json.loads(open(f'user{user_id}.json').read())\n \n def print_category(category):\n-    print(\"#### \" + category)\n+    print((\"#### \" + category))\n     print()\n     for pr in category_to_pr[category]:\n         user = users[pr[\"user\"][\"id\"]]\n",
  "test_patch": "diff --git a/docker/test/fasttest/Dockerfile b/docker/test/fasttest/Dockerfile\nindex 9b4bb574f8f9..65ec078d3cac 100644\n--- a/docker/test/fasttest/Dockerfile\n+++ b/docker/test/fasttest/Dockerfile\n@@ -52,10 +52,10 @@ RUN apt-get update \\\n         moreutils \\\n         ninja-build \\\n         psmisc \\\n-        python \\\n-        python-lxml \\\n-        python-requests \\\n-        python-termcolor \\\n+        python3 \\\n+        python3-lxml \\\n+        python3-requests \\\n+        python3-termcolor \\\n         qemu-user-static \\\n         rename \\\n         software-properties-common \\\ndiff --git a/docker/test/integration/base/Dockerfile b/docker/test/integration/base/Dockerfile\nindex 3e4e88965e0f..b6a46f6d934e 100644\n--- a/docker/test/integration/base/Dockerfile\n+++ b/docker/test/integration/base/Dockerfile\n@@ -4,7 +4,7 @@ FROM yandex/clickhouse-test-base\n RUN apt-get update \\\n     && env DEBIAN_FRONTEND=noninteractive apt-get -y install \\\n         tzdata \\\n-        python \\\n+        python3 \\\n         libreadline-dev \\\n         libicu-dev \\\n         bsdutils \\\ndiff --git a/docker/test/integration/runner/Dockerfile b/docker/test/integration/runner/Dockerfile\nindex bfbe8da816f4..795d0d371f63 100644\n--- a/docker/test/integration/runner/Dockerfile\n+++ b/docker/test/integration/runner/Dockerfile\n@@ -16,13 +16,13 @@ RUN apt-get update \\\n     iproute2 \\\n     module-init-tools \\\n     cgroupfs-mount \\\n-    python-pip \\\n+    python3-pip \\\n     tzdata \\\n     libreadline-dev \\\n     libicu-dev \\\n     bsdutils \\\n     curl \\\n-    python-pika \\\n+    python3-pika \\\n     liblua5.1-dev \\\n     luajit \\\n     libssl-dev \\\n@@ -37,7 +37,7 @@ RUN apt-get update \\\n ENV TZ=Europe/Moscow\n RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\n \n-RUN pip install urllib3==1.23 pytest docker-compose==1.22.0 docker dicttoxml kazoo PyMySQL psycopg2==2.7.5 pymongo tzlocal kafka-python protobuf redis aerospike pytest-timeout minio rpm-confluent-schemaregistry grpcio grpcio-tools cassandra-driver\n+RUN python3 -m pip install urllib3==1.23 pytest docker-compose==1.22.0 docker dicttoxml kazoo PyMySQL psycopg2==2.7.5 pymongo tzlocal kafka-python protobuf redis aerospike pytest-timeout minio grpcio grpcio-tools cassandra-driver confluent-kafka avro\n \n ENV DOCKER_CHANNEL stable\n ENV DOCKER_VERSION 17.09.1-ce\ndiff --git a/docker/test/performance-comparison/report.py b/docker/test/performance-comparison/report.py\nindex 69015c2ce1ad..1f55300661b4 100755\n--- a/docker/test/performance-comparison/report.py\n+++ b/docker/test/performance-comparison/report.py\n@@ -312,7 +312,7 @@ def add_errors_explained():\n \n \n if args.report == 'main':\n-    print(header_template.format())\n+    print((header_template.format()))\n \n     add_tested_commits()\n \n@@ -571,14 +571,14 @@ def add_test_times():\n         status = 'failure'\n         message = 'Errors while building the report.'\n \n-    print(\"\"\"\n+    print((\"\"\"\n     <!--status: {status}-->\n     <!--message: {message}-->\n-    \"\"\".format(status=status, message=message))\n+    \"\"\".format(status=status, message=message)))\n \n elif args.report == 'all-queries':\n \n-    print(header_template.format())\n+    print((header_template.format()))\n \n     add_tested_commits()\n \ndiff --git a/docker/test/stateful/Dockerfile b/docker/test/stateful/Dockerfile\nindex 8a7aca80653f..07aad75a2eae 100644\n--- a/docker/test/stateful/Dockerfile\n+++ b/docker/test/stateful/Dockerfile\n@@ -4,7 +4,7 @@ FROM yandex/clickhouse-stateless-test\n RUN apt-get update -y \\\n     && env DEBIAN_FRONTEND=noninteractive \\\n         apt-get install --yes --no-install-recommends \\\n-        python-requests \\\n+        python3-requests \\\n         llvm-9\n \n COPY s3downloader /s3downloader\ndiff --git a/docker/test/stateful/s3downloader b/docker/test/stateful/s3downloader\nindex fb49931f022b..363ece8dac66 100755\n--- a/docker/test/stateful/s3downloader\n+++ b/docker/test/stateful/s3downloader\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # -*- coding: utf-8 -*-\n import os\n import sys\n@@ -29,7 +29,7 @@ def dowload_with_progress(url, path):\n     logging.info(\"Downloading from %s to temp path %s\", url, path)\n     for i in range(RETRIES_COUNT):\n         try:\n-            with open(path, 'w') as f:\n+            with open(path, 'wb') as f:\n                 response = requests.get(url, stream=True)\n                 response.raise_for_status()\n                 total_length = response.headers.get('content-length')\n@@ -74,7 +74,7 @@ if __name__ == \"__main__\":\n     parser = argparse.ArgumentParser(\n         description=\"Simple tool for dowloading datasets for clickhouse from S3\")\n \n-    parser.add_argument('--dataset-names', required=True, nargs='+', choices=AVAILABLE_DATASETS.keys())\n+    parser.add_argument('--dataset-names', required=True, nargs='+', choices=list(AVAILABLE_DATASETS.keys()))\n     parser.add_argument('--url-prefix', default=DEFAULT_URL)\n     parser.add_argument('--clickhouse-data-path', default='/var/lib/clickhouse/')\n \ndiff --git a/docker/test/stateful_with_coverage/Dockerfile b/docker/test/stateful_with_coverage/Dockerfile\nindex 839eea5cdc18..f5d66ed50136 100644\n--- a/docker/test/stateful_with_coverage/Dockerfile\n+++ b/docker/test/stateful_with_coverage/Dockerfile\n@@ -6,7 +6,7 @@ RUN echo \"deb [trusted=yes] http://apt.llvm.org/bionic/ llvm-toolchain-bionic-9\n RUN apt-get update -y \\\n     && env DEBIAN_FRONTEND=noninteractive \\\n         apt-get install --yes --no-install-recommends \\\n-        python-requests\n+        python3-requests\n \n COPY s3downloader /s3downloader\n COPY run.sh /run.sh\ndiff --git a/docker/test/stateful_with_coverage/s3downloader b/docker/test/stateful_with_coverage/s3downloader\nindex fb49931f022b..a27c03a70f0d 100755\n--- a/docker/test/stateful_with_coverage/s3downloader\n+++ b/docker/test/stateful_with_coverage/s3downloader\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # -*- coding: utf-8 -*-\n import os\n import sys\n@@ -74,7 +74,7 @@ if __name__ == \"__main__\":\n     parser = argparse.ArgumentParser(\n         description=\"Simple tool for dowloading datasets for clickhouse from S3\")\n \n-    parser.add_argument('--dataset-names', required=True, nargs='+', choices=AVAILABLE_DATASETS.keys())\n+    parser.add_argument('--dataset-names', required=True, nargs='+', choices=list(AVAILABLE_DATASETS.keys()))\n     parser.add_argument('--url-prefix', default=DEFAULT_URL)\n     parser.add_argument('--clickhouse-data-path', default='/var/lib/clickhouse/')\n \ndiff --git a/docker/test/stateless/Dockerfile b/docker/test/stateless/Dockerfile\nindex 516d8d5842b0..33eb1c291030 100644\n--- a/docker/test/stateless/Dockerfile\n+++ b/docker/test/stateless/Dockerfile\n@@ -12,10 +12,10 @@ RUN apt-get update -y \\\n             ncdu \\\n             netcat-openbsd \\\n             openssl \\\n-            python \\\n-            python-lxml \\\n-            python-requests \\\n-            python-termcolor \\\n+            python3 \\\n+            python3-lxml \\\n+            python3-requests \\\n+            python3-termcolor \\\n             qemu-user-static \\\n             sudo \\\n             telnet \\\ndiff --git a/docker/test/stateless_pytest/Dockerfile b/docker/test/stateless_pytest/Dockerfile\nindex 596e2686f495..674a60031878 100644\n--- a/docker/test/stateless_pytest/Dockerfile\n+++ b/docker/test/stateless_pytest/Dockerfile\n@@ -3,10 +3,10 @@ FROM yandex/clickhouse-test-base\n \n RUN apt-get update -y && \\\n     apt-get install -y --no-install-recommends \\\n-        python-pip \\\n-        python-setuptools\n+        python3-pip \\\n+        python3-setuptools\n \n-RUN pip install \\\n+RUN python3 -m pip install \\\n     pytest \\\n     pytest-html \\\n     pytest-timeout \\\n@@ -17,4 +17,4 @@ CMD dpkg -i package_folder/clickhouse-common-static_*.deb; \\\n     dpkg -i package_folder/clickhouse-server_*.deb;  \\\n     dpkg -i package_folder/clickhouse-client_*.deb; \\\n     dpkg -i package_folder/clickhouse-test_*.deb; \\\n-    python -m pytest /usr/share/clickhouse-test/queries -n $(nproc) --html=test_output/report.html --self-contained-html\n+    python3 -m pytest /usr/share/clickhouse-test/queries -n $(nproc) --html=test_output/report.html --self-contained-html\ndiff --git a/docker/test/stateless_unbundled/Dockerfile b/docker/test/stateless_unbundled/Dockerfile\nindex cb8cd158e5f5..f2fd28e40788 100644\n--- a/docker/test/stateless_unbundled/Dockerfile\n+++ b/docker/test/stateless_unbundled/Dockerfile\n@@ -54,10 +54,10 @@ RUN apt-get --allow-unauthenticated update -y \\\n             perl \\\n             pigz \\\n             pkg-config \\\n-            python \\\n-            python-lxml \\\n-            python-requests \\\n-            python-termcolor \\\n+            python3 \\\n+            python3-lxml \\\n+            python3-requests \\\n+            python3-termcolor \\\n             qemu-user-static \\\n             sudo \\\n             telnet \\\ndiff --git a/docker/test/stateless_with_coverage/Dockerfile b/docker/test/stateless_with_coverage/Dockerfile\nindex b76989de1cfe..1d6a85adf9e5 100644\n--- a/docker/test/stateless_with_coverage/Dockerfile\n+++ b/docker/test/stateless_with_coverage/Dockerfile\n@@ -12,10 +12,10 @@ RUN apt-get update -y \\\n             fakeroot \\\n             debhelper \\\n             expect \\\n-            python \\\n-            python-lxml \\\n-            python-termcolor \\\n-            python-requests \\\n+            python3 \\\n+            python3-lxml \\\n+            python3-termcolor \\\n+            python3-requests \\\n             sudo \\\n             openssl \\\n             ncdu \\\ndiff --git a/docker/test/stress/Dockerfile b/docker/test/stress/Dockerfile\nindex 6855a632df47..e1df32ec3d72 100644\n--- a/docker/test/stress/Dockerfile\n+++ b/docker/test/stress/Dockerfile\n@@ -10,10 +10,10 @@ RUN apt-get update -y \\\n             debhelper \\\n             parallel \\\n             expect \\\n-            python \\\n-            python-lxml \\\n-            python-termcolor \\\n-            python-requests \\\n+            python3 \\\n+            python3-lxml \\\n+            python3-termcolor \\\n+            python3-requests \\\n             curl \\\n             sudo \\\n             openssl \\\ndiff --git a/docker/test/stress/stress b/docker/test/stress/stress\nindex a36adda3aad9..a81391d56a73 100755\n--- a/docker/test/stress/stress\n+++ b/docker/test/stress/stress\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # -*- coding: utf-8 -*-\n from multiprocessing import cpu_count\n from subprocess import Popen, check_call\ndiff --git a/docs/tools/test.py b/docs/tools/test.py\nindex d963d34df087..7d11157c986e 100755\n--- a/docs/tools/test.py\n+++ b/docs/tools/test.py\n@@ -1,6 +1,5 @@\n #!/usr/bin/env python3\n-# -*- coding: utf-8 -*-\n-from __future__ import unicode_literals\n+\n import logging\n import os\n import sys\ndiff --git a/src/Storages/tests/active_parts.py b/src/Storages/tests/active_parts.py\nindex 6872baf63684..a818a76017db 100644\n--- a/src/Storages/tests/active_parts.py\n+++ b/src/Storages/tests/active_parts.py\n@@ -24,16 +24,16 @@\n     parts[m1].append((i1, i2, l, s))\n \n for m, ps in sorted(parts.items()):\n-    ps.sort(key=lambda (i1, i2, l, s): (i1, -i2, -l))\n+    ps.sort(key=lambda i1_i2_l_s: (i1_i2_l_s[0], -i1_i2_l_s[1], -i1_i2_l_s[2]))\n     (x2, y2, l2, s2) = (-1, -1, -1, -1)\n     for x1, y1, l1, s1 in ps:\n         if x1 >= x2 and y1 <= y2 and l1 < l2 and (x1, y1) != (x2, y2): # 2 contains 1\n             pass\n         elif x1 > y2: # 1 is to the right of 2\n             if x1 != y2 + 1 and y2 != -1:\n-                print # to see the missing numbers\n+                print() # to see the missing numbers\n             (x2, y2, l2, s2) = (x1, y1, l1, s1)\n-            print s1\n+            print(s1)\n         else:\n             raise Exception('invalid parts intersection: ' + s1 + ' and ' + s2)\n-    print\n+    print()\ndiff --git a/tests/clickhouse-test b/tests/clickhouse-test\nindex 2a9c95eb8305..348df2f93be5 100755\n--- a/tests/clickhouse-test\n+++ b/tests/clickhouse-test\n@@ -1,5 +1,5 @@\n-#!/usr/bin/env python2\n-from __future__ import print_function\n+#!/usr/bin/env python3\n+\n import sys\n import os\n import os.path\n@@ -23,7 +23,7 @@ try:\n except ImportError:\n     termcolor = None\n from random import random\n-import commands\n+import subprocess\n import multiprocessing\n from contextlib import closing\n \n@@ -99,7 +99,7 @@ def remove_control_characters(s):\n     \"\"\"\n     def str_to_int(s, default, base=10):\n         if int(s, base) < 0x10000:\n-            return unichr(int(s, base))\n+            return chr(int(s, base))\n         return default\n     s = re.sub(r\"&#(\\d+);?\", lambda c: str_to_int(c.group(1), c.group(0)), s)\n     s = re.sub(r\"&#[xX]([0-9a-fA-F]+);?\", lambda c: str_to_int(c.group(1), c.group(0), base=16), s)\n@@ -129,8 +129,8 @@ def run_single_test(args, ext, server_logs_level, client_options, case_file, std\n             return ''.join(random.choice(alphabet) for _ in range(length))\n         database = 'test_{suffix}'.format(suffix=random_str())\n \n-        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-        clickhouse_proc_create.communicate(\"CREATE DATABASE \" + database + get_db_engine(args))\n+        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n+        clickhouse_proc_create.communicate((\"CREATE DATABASE \" + database + get_db_engine(args)))\n \n         os.environ[\"CLICKHOUSE_DATABASE\"] = database\n \n@@ -157,8 +157,8 @@ def run_single_test(args, ext, server_logs_level, client_options, case_file, std\n         sleep(0.01)\n \n     if not args.database:\n-        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-        clickhouse_proc_create.communicate(\"DROP DATABASE \" + database)\n+        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n+        clickhouse_proc_create.communicate((\"DROP DATABASE \" + database))\n \n     total_time = (datetime.now() - start_time).total_seconds()\n \n@@ -166,10 +166,10 @@ def run_single_test(args, ext, server_logs_level, client_options, case_file, std\n     os.system(\"LC_ALL=C sed -i -e 's/{test_db}/default/g' {file}\".format(test_db=database, file=stdout_file))\n     os.system(\"LC_ALL=C sed -i -e 's/{test_db}/default/g' {file}\".format(test_db=database, file=stderr_file))\n \n-    stdout = open(stdout_file, 'r').read() if os.path.exists(stdout_file) else ''\n-    stdout = unicode(stdout, errors='replace', encoding='utf-8')\n-    stderr = open(stderr_file, 'r').read() if os.path.exists(stderr_file) else ''\n-    stderr = unicode(stderr, errors='replace', encoding='utf-8')\n+    stdout = open(stdout_file, 'rb').read() if os.path.exists(stdout_file) else b''\n+    stdout = str(stdout, errors='replace', encoding='utf-8')\n+    stderr = open(stderr_file, 'rb').read() if os.path.exists(stderr_file) else b''\n+    stderr = str(stderr, errors='replace', encoding='utf-8')\n \n     return proc, stdout, stderr, total_time\n \n@@ -300,8 +300,8 @@ def run_tests_array(all_tests_with_params):\n                 else:\n \n                     if args.testname:\n-                        clickhouse_proc = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-                        clickhouse_proc.communicate(\"SELECT 'Running test {suite}/{case} from pid={pid}';\".format(pid = os.getpid(), case = case, suite = suite))\n+                        clickhouse_proc = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n+                        clickhouse_proc.communicate((\"SELECT 'Running test {suite}/{case} from pid={pid}';\".format(pid = os.getpid(), case = case, suite = suite)))\n \n                         if clickhouse_proc.returncode != 0:\n                             failures += 1\n@@ -342,7 +342,7 @@ def run_tests_array(all_tests_with_params):\n                             print(\" - return code {}\".format(proc.returncode))\n \n                             if stderr:\n-                                print(stderr.encode('utf-8'))\n+                                print(stderr)\n \n                             # Stop on fatal errors like segmentation fault. They are send to client via logs.\n                             if ' <Fatal> ' in stderr:\n@@ -360,22 +360,22 @@ def run_tests_array(all_tests_with_params):\n                             failures_chain += 1\n                             print(MSG_FAIL, end='')\n                             print_test_time(total_time)\n-                            print(\" - having stderror:\\n{}\".format(stderr.encode('utf-8')))\n+                            print(\" - having stderror:\\n{}\".format(stderr))\n                         elif 'Exception' in stdout:\n                             failures += 1\n                             failures_chain += 1\n                             print(MSG_FAIL, end='')\n                             print_test_time(total_time)\n-                            print(\" - having exception:\\n{}\".format(stdout.encode('utf-8')))\n+                            print(\" - having exception:\\n{}\".format(stdout))\n                         elif not os.path.isfile(reference_file):\n                             print(MSG_UNKNOWN, end='')\n                             print_test_time(total_time)\n                             print(\" - no reference file\")\n                         else:\n-                            result_is_different = subprocess.call(['diff', '-q', reference_file, stdout_file], stdout = PIPE)\n+                            result_is_different = subprocess.call(['diff', '-q', reference_file, stdout_file], stdout=PIPE)\n \n                             if result_is_different:\n-                                diff = Popen(['diff', '-U', str(args.unified), reference_file, stdout_file], stdout = PIPE).communicate()[0]\n+                                diff = Popen(['diff', '-U', str(args.unified), reference_file, stdout_file], stdout=PIPE, universal_newlines=True).communicate()[0]\n                                 failures += 1\n                                 print(MSG_FAIL, end='')\n                                 print_test_time(total_time)\n@@ -419,9 +419,9 @@ def check_server_started(client, retry_count):\n     sys.stdout.flush()\n     while retry_count > 0:\n         clickhouse_proc = Popen(shlex.split(client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-        (stdout, stderr) = clickhouse_proc.communicate(\"SELECT 1\")\n+        (stdout, stderr) = clickhouse_proc.communicate(b\"SELECT 1\")\n \n-        if clickhouse_proc.returncode == 0 and stdout.startswith(\"1\"):\n+        if clickhouse_proc.returncode == 0 and stdout.startswith(b\"1\"):\n             print(\" OK\")\n             sys.stdout.flush()\n             return True\n@@ -468,46 +468,46 @@ class BuildFlags(object):\n \n def collect_build_flags(client):\n     clickhouse_proc = Popen(shlex.split(client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-    (stdout, stderr) = clickhouse_proc.communicate(\"SELECT value FROM system.build_options WHERE name = 'CXX_FLAGS'\")\n+    (stdout, stderr) = clickhouse_proc.communicate(b\"SELECT value FROM system.build_options WHERE name = 'CXX_FLAGS'\")\n     result = []\n \n     if clickhouse_proc.returncode == 0:\n-        if '-fsanitize=thread' in stdout:\n+        if b'-fsanitize=thread' in stdout:\n             result.append(BuildFlags.THREAD)\n-        elif '-fsanitize=address' in stdout:\n+        elif b'-fsanitize=address' in stdout:\n             result.append(BuildFlags.ADDRESS)\n-        elif '-fsanitize=undefined' in stdout:\n+        elif b'-fsanitize=undefined' in stdout:\n             result.append(BuildFlags.UNDEFINED)\n-        elif '-fsanitize=memory' in stdout:\n+        elif b'-fsanitize=memory' in stdout:\n             result.append(BuildFlags.MEMORY)\n     else:\n         raise Exception(\"Cannot get inforamtion about build from server errorcode {}, stderr {}\".format(clickhouse_proc.returncode, stderr))\n \n     clickhouse_proc = Popen(shlex.split(client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-    (stdout, stderr) = clickhouse_proc.communicate(\"SELECT value FROM system.build_options WHERE name = 'BUILD_TYPE'\")\n+    (stdout, stderr) = clickhouse_proc.communicate(b\"SELECT value FROM system.build_options WHERE name = 'BUILD_TYPE'\")\n \n     if clickhouse_proc.returncode == 0:\n-        if 'Debug' in stdout:\n+        if b'Debug' in stdout:\n             result.append(BuildFlags.DEBUG)\n-        elif 'RelWithDebInfo' in stdout or 'Release' in stdout:\n+        elif b'RelWithDebInfo' in stdout or b'Release' in stdout:\n             result.append(BuildFlags.RELEASE)\n     else:\n         raise Exception(\"Cannot get inforamtion about build from server errorcode {}, stderr {}\".format(clickhouse_proc.returncode, stderr))\n \n     clickhouse_proc = Popen(shlex.split(client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-    (stdout, stderr) = clickhouse_proc.communicate(\"SELECT value FROM system.build_options WHERE name = 'UNBUNDLED'\")\n+    (stdout, stderr) = clickhouse_proc.communicate(b\"SELECT value FROM system.build_options WHERE name = 'UNBUNDLED'\")\n \n     if clickhouse_proc.returncode == 0:\n-        if 'ON' in stdout or '1' in stdout:\n+        if b'ON' in stdout or b'1' in stdout:\n             result.append(BuildFlags.UNBUNDLED)\n     else:\n         raise Exception(\"Cannot get inforamtion about build from server errorcode {}, stderr {}\".format(clickhouse_proc.returncode, stderr))\n \n     clickhouse_proc = Popen(shlex.split(client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-    (stdout, stderr) = clickhouse_proc.communicate(\"SELECT value FROM system.settings WHERE name = 'default_database_engine'\")\n+    (stdout, stderr) = clickhouse_proc.communicate(b\"SELECT value FROM system.settings WHERE name = 'default_database_engine'\")\n \n     if clickhouse_proc.returncode == 0:\n-        if 'Ordinary' in stdout:\n+        if b'Ordinary' in stdout:\n             result.append(BuildFlags.DATABASE_ORDINARY)\n     else:\n         raise Exception(\"Cannot get inforamtion about build from server errorcode {}, stderr {}\".format(clickhouse_proc.returncode, stderr))\n@@ -523,11 +523,11 @@ def main(args):\n \n     def is_data_present():\n         clickhouse_proc = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-        (stdout, stderr) = clickhouse_proc.communicate(\"EXISTS TABLE test.hits\")\n+        (stdout, stderr) = clickhouse_proc.communicate(b\"EXISTS TABLE test.hits\")\n         if clickhouse_proc.returncode != 0:\n             raise CalledProcessError(clickhouse_proc.returncode, args.client, stderr)\n \n-        return stdout.startswith('1')\n+        return stdout.startswith(b'1')\n \n     if not check_server_started(args.client, args.server_check_retries):\n         raise Exception(\"clickhouse-server is not responding. Cannot execute 'SELECT 1' query.\")\n@@ -562,7 +562,7 @@ def main(args):\n         stop_time = time() + args.global_time_limit\n \n     if args.zookeeper is None:\n-        code, out = commands.getstatusoutput(args.extract_from_config + \" --try --config \" + args.configserver + ' --key zookeeper | grep . | wc -l')\n+        code, out = subprocess.getstatusoutput(args.extract_from_config + \" --try --config \" + args.configserver + ' --key zookeeper | grep . | wc -l')\n         try:\n             if int(out) > 0:\n                 args.zookeeper = True\n@@ -572,18 +572,18 @@ def main(args):\n             args.zookeeper = False\n \n     if args.shard is None:\n-        code, out = commands.getstatusoutput(args.extract_from_config + \" --try --config \" + args.configserver + ' --key listen_host | grep -E \"127.0.0.2|::\"')\n+        code, out = subprocess.getstatusoutput(args.extract_from_config + \" --try --config \" + args.configserver + ' --key listen_host | grep -E \"127.0.0.2|::\"')\n         if out:\n             args.shard = True\n         else:\n             args.shard = False\n \n     if args.database and args.database != \"test\":\n-        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-        clickhouse_proc_create.communicate(\"CREATE DATABASE IF NOT EXISTS \" + args.database + get_db_engine(args))\n+        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n+        clickhouse_proc_create.communicate((\"CREATE DATABASE IF NOT EXISTS \" + args.database + get_db_engine(args)))\n \n-    clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)\n-    clickhouse_proc_create.communicate(\"CREATE DATABASE IF NOT EXISTS test\" + get_db_engine(args))\n+    clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n+    clickhouse_proc_create.communicate((\"CREATE DATABASE IF NOT EXISTS test\" + get_db_engine(args)))\n \n     def is_test_from_dir(suite_dir, case):\n         case_file = os.path.join(suite_dir, case)\n@@ -595,14 +595,14 @@ def main(args):\n              return random()\n \n        if -1 == item.find('_'):\n-           return 99998\n+           return 99998, ''\n \n        prefix, suffix = item.split('_', 1)\n \n        try:\n            return int(prefix), suffix\n        except ValueError:\n-           return 99997\n+           return 99997, ''\n \n     total_tests_run = 0\n     for suite in sorted(os.listdir(base_dir), key=sute_key_func):\n@@ -650,7 +650,7 @@ def main(args):\n                     return 99997\n \n             all_tests = os.listdir(suite_dir)\n-            all_tests = filter(lambda case: is_test_from_dir(suite_dir, case), all_tests)\n+            all_tests = [case for case in all_tests if is_test_from_dir(suite_dir, case)]\n             if args.test:\n                 all_tests = [t for t in all_tests if any([re.search(r, t) for r in args.test])]\n             all_tests.sort(key=key_func)\n@@ -670,7 +670,7 @@ def main(args):\n             if jobs > run_total:\n                 run_total = jobs\n \n-            batch_size = len(all_tests) / jobs\n+            batch_size = len(all_tests) // jobs\n             all_tests_array = []\n             for i in range(0, len(all_tests), batch_size):\n                 all_tests_array.append((all_tests[i:i+batch_size], suite, suite_dir, suite_tmp_dir, run_total))\ndiff --git a/tests/external_models/catboost/helpers/server.py b/tests/external_models/catboost/helpers/server.py\nindex 265898d8d415..8248b16e6df8 100644\n--- a/tests/external_models/catboost/helpers/server.py\n+++ b/tests/external_models/catboost/helpers/server.py\n@@ -37,7 +37,7 @@ def wait_for_request(self, port, timeout=1):\n \n             s.connect(('localhost', port))\n         except socket.error as socketerror:\n-            print \"Error: \", socketerror\n+            print(\"Error: \", socketerror)\n             raise\n \n     def shutdown(self, timeout=10):\ndiff --git a/tests/external_models/catboost/helpers/server_with_models.py b/tests/external_models/catboost/helpers/server_with_models.py\nindex ad9feea99fe3..e00da7b70279 100644\n--- a/tests/external_models/catboost/helpers/server_with_models.py\n+++ b/tests/external_models/catboost/helpers/server_with_models.py\n@@ -1,6 +1,6 @@\n-from server import ClickHouseServer\n-from client import ClickHouseClient\n-from table import ClickHouseTable\n+from .server import ClickHouseServer\n+from .client import ClickHouseClient\n+from .table import ClickHouseTable\n import os\n import errno\n from shutil import rmtree\n@@ -140,7 +140,7 @@ def _save_models(self):\n         if not os.path.exists(self.models_dir):\n             os.makedirs(self.models_dir)\n \n-        for name, model in self.models.items():\n+        for name, model in list(self.models.items()):\n             model_path = os.path.join(self.models_dir, name + '.cbm')\n             config_path = os.path.join(self.models_dir, name + '_model.xml')\n             params = {\ndiff --git a/tests/external_models/catboost/helpers/table.py b/tests/external_models/catboost/helpers/table.py\nindex e6b05ac7b7b1..5f9b828c9f3d 100644\n--- a/tests/external_models/catboost/helpers/table.py\n+++ b/tests/external_models/catboost/helpers/table.py\n@@ -1,5 +1,5 @@\n-from server import ClickHouseServer\n-from client import ClickHouseClient\n+from .server import ClickHouseServer\n+from .client import ClickHouseClient\n from pandas import DataFrame\n import os\n import threading\n@@ -40,7 +40,7 @@ def _create_table_from_df(self):\n         column_types = list(self.df.dtypes)\n         column_names = list(self.df)\n         schema = ', '.join((name + ' ' + self._convert(str(t)) for name, t in zip(column_names, column_types)))\n-        print 'schema:', schema\n+        print('schema:', schema)\n \n         create_query = 'create table test.{} (date Date DEFAULT today(), {}) engine = MergeTree(date, (date), 8192)'\n         self.client.query(create_query.format(self.table_name, schema))\n@@ -58,10 +58,10 @@ def apply_model(self, model_name, float_columns, cat_columns):\n         result = self.client.query(query.format(model_name, columns, self.table_name))\n \n         def parse_row(row):\n-            values = tuple(map(float, filter(len, map(str.strip, row.replace('(', '').replace(')', '').split(',')))))\n+            values = tuple(map(float, list(filter(len, list(map(str.strip, row.replace('(', '').replace(')', '').split(',')))))))\n             return values if len(values) != 1 else values[0]\n \n-        return tuple(map(parse_row, filter(len, map(str.strip, result.split('\\n')))))\n+        return tuple(map(parse_row, list(filter(len, list(map(str.strip, result.split('\\n')))))))\n \n     def _drop_table(self):\n         self.client.query('drop table test.{}'.format(self.table_name))\ndiff --git a/tests/external_models/catboost/helpers/train.py b/tests/external_models/catboost/helpers/train.py\nindex df81d7195535..34a6f8e958bb 100644\n--- a/tests/external_models/catboost/helpers/train.py\n+++ b/tests/external_models/catboost/helpers/train.py\n@@ -19,10 +19,10 @@ def train_catboost_model(df, target, cat_features, params, verbose=True):\n     if not isinstance(df, DataFrame):\n         raise Exception('DataFrame object expected, but got ' + repr(df))\n \n-    print 'features:', df.columns.tolist()\n+    print('features:', df.columns.tolist())\n \n     cat_features_index = list(df.columns.get_loc(feature) for feature in cat_features)\n-    print 'cat features:', cat_features_index\n+    print('cat features:', cat_features_index)\n     model = CatBoostClassifier(**params)\n     model.fit(df, target, cat_features=cat_features_index, verbose=verbose)\n     return model\ndiff --git a/tests/external_models/catboost/test_apply_catboost_model/test.py b/tests/external_models/catboost/test_apply_catboost_model/test.py\nindex 00b9fe0dce1a..d266393bf48d 100644\n--- a/tests/external_models/catboost/test_apply_catboost_model/test.py\n+++ b/tests/external_models/catboost/test_apply_catboost_model/test.py\n@@ -23,7 +23,7 @@ def check_predictions(test_name, target, pred_python, pred_ch, acc_threshold):\n \n     acc = 1 - np.sum(np.abs(ch_class - np.array(target))) / (len(target) + .0)\n     assert acc >= acc_threshold\n-    print test_name, 'accuracy: {:.10f}'.format(acc)\n+    print(test_name, 'accuracy: {:.10f}'.format(acc))\n \n \n def test_apply_float_features_only():\n@@ -52,9 +52,9 @@ def target_filter(row):\n     train_target = get_target(train_df)\n     test_target = get_target(test_df)\n \n-    print\n-    print 'train target', train_target\n-    print 'test target', test_target\n+    print()\n+    print('train target', train_target)\n+    print('test target', test_target)\n \n     params = {\n         'iterations': 4,\n@@ -71,8 +71,8 @@ def target_filter(row):\n     with server:\n         pred_ch = (np.array(server.apply_model(name, test_df, [])) > 0).astype(int)\n \n-    print 'python predictions', pred_python\n-    print 'clickhouse predictions', pred_ch\n+    print('python predictions', pred_python)\n+    print('clickhouse predictions', pred_ch)\n \n     check_predictions(name, test_target, pred_python, pred_ch, 0.9)\n \n@@ -105,9 +105,9 @@ def target_filter(row):\n     train_target = get_target(train_df)\n     test_target = get_target(test_df)\n \n-    print\n-    print 'train target', train_target\n-    print 'test target', test_target\n+    print()\n+    print('train target', train_target)\n+    print('test target', test_target)\n \n     params = {\n         'iterations': 6,\n@@ -124,8 +124,8 @@ def target_filter(row):\n     with server:\n         pred_ch = (np.array(server.apply_model(name, test_df, [])) > 0).astype(int)\n \n-    print 'python predictions', pred_python\n-    print 'clickhouse predictions', pred_ch\n+    print('python predictions', pred_python)\n+    print('clickhouse predictions', pred_ch)\n \n     check_predictions(name, test_target, pred_python, pred_ch, 0.9)\n \n@@ -158,9 +158,9 @@ def target_filter(row):\n     train_target = get_target(train_df)\n     test_target = get_target(test_df)\n \n-    print\n-    print 'train target', train_target\n-    print 'test target', test_target\n+    print()\n+    print('train target', train_target)\n+    print('test target', test_target)\n \n     params = {\n         'iterations': 6,\n@@ -177,8 +177,8 @@ def target_filter(row):\n     with server:\n         pred_ch = (np.array(server.apply_model(name, test_df, [])) > 0).astype(int)\n \n-    print 'python predictions', pred_python\n-    print 'clickhouse predictions', pred_ch\n+    print('python predictions', pred_python)\n+    print('clickhouse predictions', pred_ch)\n \n     check_predictions(name, test_target, pred_python, pred_ch, 0.9)\n \n@@ -211,9 +211,9 @@ def target_filter(row):\n     train_target = get_target(train_df)\n     test_target = get_target(test_df)\n \n-    print\n-    print 'train target', train_target\n-    print 'test target', test_target\n+    print()\n+    print('train target', train_target)\n+    print('test target', test_target)\n \n     params = {\n         'iterations': 6,\n@@ -230,8 +230,8 @@ def target_filter(row):\n     with server:\n         pred_ch = (np.array(server.apply_model(name, test_df, [])) > 0).astype(int)\n \n-    print 'python predictions', pred_python\n-    print 'clickhouse predictions', pred_ch\n+    print('python predictions', pred_python)\n+    print('clickhouse predictions', pred_ch)\n \n     check_predictions(name, test_target, pred_python, pred_ch, 0.9)\n \n@@ -269,9 +269,9 @@ def target_filter(row):\n     train_target = get_target(train_df)\n     test_target = get_target(test_df)\n \n-    print\n-    print 'train target', train_target\n-    print 'test target', test_target\n+    print()\n+    print('train target', train_target)\n+    print('test target', test_target)\n \n     params = {\n         'iterations': 10,\n@@ -288,7 +288,7 @@ def target_filter(row):\n     with server:\n         pred_ch = np.argmax(np.array(server.apply_model(name, test_df, [])), axis=1)\n \n-    print 'python predictions', pred_python\n-    print 'clickhouse predictions', pred_ch\n+    print('python predictions', pred_python)\n+    print('clickhouse predictions', pred_ch)\n \n     check_predictions(name, test_target, pred_python, pred_ch, 0.9)\ndiff --git a/tests/integration/README.md b/tests/integration/README.md\nindex a3eb577d609d..94a6000d707b 100644\n--- a/tests/integration/README.md\n+++ b/tests/integration/README.md\n@@ -12,11 +12,11 @@ You must install latest Docker from\n https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#set-up-the-repository\n Don't use Docker from your system repository.\n \n-* [pip](https://pypi.python.org/pypi/pip) and `libpq-dev`. To install: `sudo apt-get install python-pip libpq-dev zlib1g-dev libcrypto++-dev libssl-dev`\n+* [pip](https://pypi.python.org/pypi/pip) and `libpq-dev`. To install: `sudo apt-get install python3-pip libpq-dev zlib1g-dev libcrypto++-dev libssl-dev`\n * [py.test](https://docs.pytest.org/) testing framework. To install: `sudo -H pip install pytest`\n-* [docker-compose](https://docs.docker.com/compose/) and additional python libraries. To install: `sudo -H pip install urllib3==1.23 pytest docker-compose==1.22.0 docker dicttoxml kazoo PyMySQL psycopg2==2.7.5 pymongo tzlocal kafka-python protobuf redis aerospike pytest-timeout minio rpm-confluent-schemaregistry`\n+* [docker-compose](https://docs.docker.com/compose/) and additional python libraries. To install: `sudo -H pip install urllib3==1.23 pytest docker-compose==1.22.0 docker dicttoxml kazoo PyMySQL psycopg2==2.7.5 pymongo tzlocal kafka-python protobuf redis aerospike pytest-timeout minio confluent-kafka avro\n \n-(highly not recommended) If you really want to use OS packages on modern debian/ubuntu instead of \"pip\": `sudo apt install -y docker docker-compose python-pytest python-dicttoxml python-docker python-pymysql python-pymongo python-tzlocal python-kazoo python-psycopg2 python-kafka python-pytest-timeout python-minio`\n+(highly not recommended) If you really want to use OS packages on modern debian/ubuntu instead of \"pip\": `sudo apt install -y docker docker-compose python3-pytest python3-dicttoxml python3-docker python3-pymysql python3-pymongo python3-tzlocal python3-kazoo python3-psycopg2 kafka-python python3-pytest-timeout python3-minio`\n \n If you want to run the tests under a non-privileged user, you must add this user to `docker` group: `sudo usermod -aG docker $USER` and re-login.\n (You must close all your sessions (for example, restart your computer))\ndiff --git a/tests/integration/helpers/client.py b/tests/integration/helpers/client.py\nindex deffa20753f8..a43440e41f74 100644\n--- a/tests/integration/helpers/client.py\n+++ b/tests/integration/helpers/client.py\n@@ -31,7 +31,7 @@ def get_query_request(self, sql, stdin=None, timeout=None, settings=None, user=N\n             command += ['--query', sql]\n \n         if settings is not None:\n-            for setting, value in settings.iteritems():\n+            for setting, value in settings.items():\n                 command += ['--' + setting, str(value)]\n \n         if user is not None:\n@@ -67,7 +67,7 @@ class QueryRuntimeException(Exception):\n class CommandRequest:\n     def __init__(self, command, stdin=None, timeout=None, ignore_error=False):\n         # Write data to tmp file to avoid PIPEs and execution blocking\n-        stdin_file = tempfile.TemporaryFile()\n+        stdin_file = tempfile.TemporaryFile(mode='w+')\n         stdin_file.write(stdin)\n         stdin_file.seek(0)\n         self.stdout_file = tempfile.TemporaryFile()\n@@ -80,7 +80,7 @@ def __init__(self, command, stdin=None, timeout=None, ignore_error=False):\n         # can print some debug information there\n         env = {}\n         env[\"TSAN_OPTIONS\"] = \"verbosity=0\"\n-        self.process = sp.Popen(command, stdin=stdin_file, stdout=self.stdout_file, stderr=self.stderr_file, env=env)\n+        self.process = sp.Popen(command, stdin=stdin_file, stdout=self.stdout_file, stderr=self.stderr_file, env=env, universal_newlines=True)\n \n         self.timer = None\n         self.process_finished_before_timeout = True\n@@ -98,8 +98,8 @@ def get_answer(self):\n         self.stdout_file.seek(0)\n         self.stderr_file.seek(0)\n \n-        stdout = self.stdout_file.read()\n-        stderr = self.stderr_file.read()\n+        stdout = self.stdout_file.read().decode()\n+        stderr = self.stderr_file.read().decode()\n \n         if self.timer is not None and not self.process_finished_before_timeout and not self.ignore_error:\n             raise QueryTimeoutExceedException('Client timed out!')\n@@ -115,8 +115,8 @@ def get_error(self):\n         self.stdout_file.seek(0)\n         self.stderr_file.seek(0)\n \n-        stdout = self.stdout_file.read()\n-        stderr = self.stderr_file.read()\n+        stdout = self.stdout_file.read().decode()\n+        stderr = self.stderr_file.read().decode()\n \n         if self.timer is not None and not self.process_finished_before_timeout and not self.ignore_error:\n             raise QueryTimeoutExceedException('Client timed out!')\n@@ -131,8 +131,8 @@ def get_answer_and_error(self):\n         self.stdout_file.seek(0)\n         self.stderr_file.seek(0)\n \n-        stdout = self.stdout_file.read()\n-        stderr = self.stderr_file.read()\n+        stdout = self.stdout_file.read().decode()\n+        stderr = self.stderr_file.read().decode()\n \n         if self.timer is not None and not self.process_finished_before_timeout and not self.ignore_error:\n             raise QueryTimeoutExceedException('Client timed out!')\ndiff --git a/tests/integration/helpers/cluster.py b/tests/integration/helpers/cluster.py\nindex d99d8a17844d..6b24bc30460d 100644\n--- a/tests/integration/helpers/cluster.py\n+++ b/tests/integration/helpers/cluster.py\n@@ -1,6 +1,6 @@\n import base64\n import errno\n-import httplib\n+import http.client\n import logging\n import os\n import os.path as p\n@@ -12,7 +12,7 @@\n import subprocess\n import time\n import traceback\n-import urllib\n+import urllib.parse\n \n import cassandra.cluster\n import docker\n@@ -21,7 +21,7 @@\n import pymysql\n import requests\n import xml.dom.minidom\n-from confluent.schemaregistry.client import CachedSchemaRegistryClient\n+from confluent_kafka.avro.cached_schema_registry_client import CachedSchemaRegistryClient\n from dicttoxml import dicttoxml\n from kazoo.client import KazooClient\n from kazoo.exceptions import KazooException\n@@ -41,7 +41,7 @@\n def _create_env_file(path, variables, fname=DEFAULT_ENV_NAME):\n     full_path = os.path.join(path, fname)\n     with open(full_path, 'w') as f:\n-        for var, value in variables.items():\n+        for var, value in list(variables.items()):\n             f.write(\"=\".join([var, value]) + \"\\n\")\n     return full_path\n \n@@ -76,7 +76,7 @@ def get_docker_compose_path():\n         if os.path.exists(os.path.dirname('/compose/')):\n             return os.path.dirname('/compose/')  # default in docker runner container\n         else:\n-            print(\"Fallback docker_compose_path to LOCAL_DOCKER_COMPOSE_DIR: {}\".format(LOCAL_DOCKER_COMPOSE_DIR))\n+            print((\"Fallback docker_compose_path to LOCAL_DOCKER_COMPOSE_DIR: {}\".format(LOCAL_DOCKER_COMPOSE_DIR)))\n             return LOCAL_DOCKER_COMPOSE_DIR\n \n \n@@ -91,8 +91,8 @@ class ClickHouseCluster:\n \n     def __init__(self, base_path, name=None, base_config_dir=None, server_bin_path=None, client_bin_path=None,\n                  odbc_bridge_bin_path=None, zookeeper_config_path=None, custom_dockerd_host=None):\n-        for param in os.environ.keys():\n-            print \"ENV %40s %s\" % (param, os.environ[param])\n+        for param in list(os.environ.keys()):\n+            print(\"ENV %40s %s\" % (param, os.environ[param]))\n         self.base_dir = p.dirname(base_path)\n         self.name = name if name is not None else ''\n \n@@ -160,7 +160,7 @@ def __init__(self, base_path, name=None, base_config_dir=None, server_bin_path=N\n \n         self.docker_client = None\n         self.is_up = False\n-        print \"CLUSTER INIT base_config_dir:{}\".format(self.base_config_dir)\n+        print(\"CLUSTER INIT base_config_dir:{}\".format(self.base_config_dir))\n \n     def get_client_cmd(self):\n         cmd = self.client_bin_path\n@@ -386,7 +386,7 @@ def restart_instance_with_ip_change(self, node, new_ip):\n     def get_instance_ip(self, instance_name):\n         docker_id = self.get_instance_docker_id(instance_name)\n         handle = self.docker_client.containers.get(docker_id)\n-        return handle.attrs['NetworkSettings']['Networks'].values()[0]['IPAddress']\n+        return list(handle.attrs['NetworkSettings']['Networks'].values())[0]['IPAddress']\n \n     def get_container_id(self, instance_name):\n         docker_id = self.get_instance_docker_id(instance_name)\n@@ -395,22 +395,21 @@ def get_container_id(self, instance_name):\n \n     def get_container_logs(self, instance_name):\n         container_id = self.get_container_id(instance_name)\n-        return self.docker_client.api.logs(container_id)\n+        return self.docker_client.api.logs(container_id).decode()\n \n     def exec_in_container(self, container_id, cmd, detach=False, nothrow=False, **kwargs):\n         exec_id = self.docker_client.api.exec_create(container_id, cmd, **kwargs)\n         output = self.docker_client.api.exec_start(exec_id, detach=detach)\n \n-        output = output.decode('utf8')\n         exit_code = self.docker_client.api.exec_inspect(exec_id)['ExitCode']\n         if exit_code:\n             container_info = self.docker_client.api.inspect_container(container_id)\n             image_id = container_info.get('Image')\n             image_info = self.docker_client.api.inspect_image(image_id)\n-            print(\"Command failed in container {}: \".format(container_id))\n+            print((\"Command failed in container {}: \".format(container_id)))\n             pprint.pprint(container_info)\n             print(\"\")\n-            print(\"Container {} uses image {}: \".format(container_id, image_id))\n+            print((\"Container {} uses image {}: \".format(container_id, image_id)))\n             pprint.pprint(image_info)\n             print(\"\")\n             message = 'Cmd \"{}\" failed in container {}. Return code {}. Output: {}'.format(' '.join(cmd), container_id,\n@@ -419,14 +418,17 @@ def exec_in_container(self, container_id, cmd, detach=False, nothrow=False, **kw\n                 print(message)\n             else:\n                 raise Exception(message)\n+        if not detach:\n+            return output.decode()\n         return output\n \n     def copy_file_to_container(self, container_id, local_path, dest_path):\n-        with open(local_path, 'r') as fdata:\n+        with open(local_path, \"r\") as fdata:\n             data = fdata.read()\n-            encoded_data = base64.b64encode(data)\n+            encodedBytes = base64.b64encode(data.encode(\"utf-8\"))\n+            encodedStr = str(encodedBytes, \"utf-8\")\n             self.exec_in_container(container_id,\n-                                   [\"bash\", \"-c\", \"echo {} | base64 --decode > {}\".format(encoded_data, dest_path)],\n+                                   [\"bash\", \"-c\", \"echo {} | base64 --decode > {}\".format(encodedStr, dest_path)],\n                                    user='root')\n \n     def wait_mysql_to_start(self, timeout=60):\n@@ -435,10 +437,10 @@ def wait_mysql_to_start(self, timeout=60):\n             try:\n                 conn = pymysql.connect(user='root', password='clickhouse', host='127.0.0.1', port=3308)\n                 conn.close()\n-                print \"Mysql Started\"\n+                print(\"Mysql Started\")\n                 return\n             except Exception as ex:\n-                print \"Can't connect to MySQL \" + str(ex)\n+                print(\"Can't connect to MySQL \" + str(ex))\n                 time.sleep(0.5)\n \n         subprocess_call(['docker-compose', 'ps', '--services', '--all'])\n@@ -451,10 +453,10 @@ def wait_postgres_to_start(self, timeout=60):\n                 conn_string = \"host='localhost' user='postgres' password='mysecretpassword'\"\n                 conn = psycopg2.connect(conn_string)\n                 conn.close()\n-                print \"Postgres Started\"\n+                print(\"Postgres Started\")\n                 return\n             except Exception as ex:\n-                print \"Can't connect to Postgres \" + str(ex)\n+                print(\"Can't connect to Postgres \" + str(ex))\n                 time.sleep(0.5)\n \n         raise Exception(\"Cannot wait Postgres container\")\n@@ -466,10 +468,10 @@ def wait_zookeeper_to_start(self, timeout=60):\n                 for instance in ['zoo1', 'zoo2', 'zoo3']:\n                     conn = self.get_kazoo_client(instance)\n                     conn.get_children('/')\n-                print \"All instances of ZooKeeper started\"\n+                print(\"All instances of ZooKeeper started\")\n                 return\n             except Exception as ex:\n-                print \"Can't connect to ZooKeeper \" + str(ex)\n+                print(\"Can't connect to ZooKeeper \" + str(ex))\n                 time.sleep(0.5)\n \n         raise Exception(\"Cannot wait ZooKeeper container\")\n@@ -480,10 +482,10 @@ def wait_hdfs_to_start(self, timeout=60):\n         while time.time() - start < timeout:\n             try:\n                 hdfs_api.write_data(\"/somefilewithrandomname222\", \"1\")\n-                print \"Connected to HDFS and SafeMode disabled! \"\n+                print(\"Connected to HDFS and SafeMode disabled! \")\n                 return\n             except Exception as ex:\n-                print \"Can't connect to HDFS \" + str(ex)\n+                print(\"Can't connect to HDFS \" + str(ex))\n                 time.sleep(1)\n \n         raise Exception(\"Can't wait HDFS to start\")\n@@ -496,10 +498,10 @@ def wait_mongo_to_start(self, timeout=30):\n         while time.time() - start < timeout:\n             try:\n                 connection.list_database_names()\n-                print \"Connected to Mongo dbs:\", connection.list_database_names()\n+                print(\"Connected to Mongo dbs:\", connection.database_names())\n                 return\n             except Exception as ex:\n-                print \"Can't connect to Mongo \" + str(ex)\n+                print(\"Can't connect to Mongo \" + str(ex))\n                 time.sleep(1)\n \n     def wait_minio_to_start(self, timeout=30, secure=False):\n@@ -519,12 +521,12 @@ def wait_minio_to_start(self, timeout=30, secure=False):\n \n                 minio_client.make_bucket(self.minio_bucket)\n \n-                print(\"S3 bucket '%s' created\", self.minio_bucket)\n+                print((\"S3 bucket '%s' created\", self.minio_bucket))\n \n                 self.minio_client = minio_client\n                 return\n             except Exception as ex:\n-                print(\"Can't connect to Minio: %s\", str(ex))\n+                print((\"Can't connect to Minio: %s\", str(ex)))\n                 time.sleep(1)\n \n         raise Exception(\"Can't wait Minio to start\")\n@@ -539,7 +541,7 @@ def wait_schema_registry_to_start(self, timeout=10):\n                 print(\"Connected to SchemaRegistry\")\n                 return\n             except Exception as ex:\n-                print(\"Can't connect to SchemaRegistry: %s\", str(ex))\n+                print((\"Can't connect to SchemaRegistry: %s\", str(ex)))\n                 time.sleep(1)\n \n     def wait_cassandra_to_start(self, timeout=30):\n@@ -555,7 +557,7 @@ def wait_cassandra_to_start(self, timeout=30):\n                 time.sleep(1)\n \n     def start(self, destroy_dirs=True):\n-        print \"Cluster start called. is_up={}, destroy_dirs={}\".format(self.is_up, destroy_dirs)\n+        print(\"Cluster start called. is_up={}, destroy_dirs={}\".format(self.is_up, destroy_dirs))\n         if self.is_up:\n             return\n \n@@ -571,11 +573,11 @@ def start(self, destroy_dirs=True):\n \n         try:\n             if destroy_dirs and p.exists(self.instances_dir):\n-                print(\"Removing instances dir %s\", self.instances_dir)\n+                print((\"Removing instances dir %s\", self.instances_dir))\n                 shutil.rmtree(self.instances_dir)\n \n-            for instance in self.instances.values():\n-                print('Setup directory for instance: {} destroy_dirs: {}'.format(instance.name, destroy_dirs))\n+            for instance in list(self.instances.values()):\n+                print(('Setup directory for instance: {} destroy_dirs: {}'.format(instance.name, destroy_dirs)))\n                 instance.create_dir(destroy_dir=destroy_dirs)\n \n             self.docker_client = docker.from_env(version=self.docker_api_version)\n@@ -676,12 +678,12 @@ def start(self, destroy_dirs=True):\n                 self.wait_cassandra_to_start()\n \n             clickhouse_start_cmd = self.base_cmd + ['up', '-d', '--no-recreate']\n-            print(\"Trying to create ClickHouse instance by command %s\", ' '.join(map(str, clickhouse_start_cmd)))\n+            print((\"Trying to create ClickHouse instance by command %s\", ' '.join(map(str, clickhouse_start_cmd))))\n             subprocess_check_call(clickhouse_start_cmd)\n             print(\"ClickHouse instance created\")\n \n             start_deadline = time.time() + 20.0  # seconds\n-            for instance in self.instances.itervalues():\n+            for instance in self.instances.values():\n                 instance.docker_client = self.docker_client\n                 instance.ip_address = self.get_instance_ip(instance.name)\n \n@@ -693,10 +695,10 @@ def start(self, destroy_dirs=True):\n \n             self.is_up = True\n \n-        except BaseException, e:\n-            print \"Failed to start cluster: \"\n-            print str(e)\n-            print traceback.print_exc()\n+        except BaseException as e:\n+            print(\"Failed to start cluster: \")\n+            print(str(e))\n+            print(traceback.print_exc())\n             raise\n \n     def shutdown(self, kill=True):\n@@ -705,7 +707,7 @@ def shutdown(self, kill=True):\n             try:\n                 subprocess.check_call(self.base_cmd + ['logs'], stdout=f)\n             except Exception as e:\n-                print \"Unable to get logs from docker.\"\n+                print(\"Unable to get logs from docker.\")\n             f.seek(0)\n             for line in f:\n                 if SANITIZER_SIGN in line:\n@@ -716,18 +718,18 @@ def shutdown(self, kill=True):\n             try:\n                 subprocess_check_call(self.base_cmd + ['kill'])\n             except Exception as e:\n-                print \"Kill command failed durung shutdown. {}\".format(repr(e))\n+                print(\"Kill command failed durung shutdown. {}\".format(repr(e)))\n \n         try:\n             subprocess_check_call(self.base_cmd + ['down', '--volumes', '--remove-orphans'])\n         except Exception as e:\n-            print \"Down + remove orphans failed durung shutdown. {}\".format(repr(e))\n+            print(\"Down + remove orphans failed durung shutdown. {}\".format(repr(e)))\n \n         self.is_up = False\n \n         self.docker_client = None\n \n-        for instance in self.instances.values():\n+        for instance in list(self.instances.values()):\n             instance.docker_client = None\n             instance.ip_address = None\n             instance.client = None\n@@ -769,7 +771,7 @@ def run_kazoo_commands_with_retries(self, kazoo_callback, zoo_instance_name='zoo\n                 kazoo_callback(self.get_kazoo_client(zoo_instance_name))\n                 return\n             except KazooException as e:\n-                print repr(e)\n+                print(repr(e))\n                 time.sleep(sleep_for)\n \n         kazoo_callback(self.get_kazoo_client(zoo_instance_name))\n@@ -922,7 +924,7 @@ def query_with_retry(self, sql, stdin=None, timeout=None, settings=None, user=No\n                     return result\n                 time.sleep(sleep_time)\n             except Exception as ex:\n-                print \"Retry {} got exception {}\".format(i + 1, ex)\n+                print(\"Retry {} got exception {}\".format(i + 1, ex))\n                 time.sleep(sleep_time)\n \n         if result is not None:\n@@ -954,28 +956,30 @@ def http_query(self, sql, data=None, params=None, user=None, password=None, expe\n \n         params[\"query\"] = sql\n \n-        auth = \"\"\n+        auth = None\n         if user and password:\n-            auth = \"{}:{}@\".format(user, password)\n+            auth = requests.auth.HTTPBasicAuth(user, password)\n         elif user:\n-            auth = \"{}@\".format(user)\n+            auth = requests.auth.HTTPBasicAuth(user, '')\n+        url = \"http://\" + self.ip_address + \":8123/?\" + urllib.parse.urlencode(params)\n \n-        url = \"http://\" + auth + self.ip_address + \":8123/?\" + urllib.urlencode(params)\n-\n-        open_result = urllib.urlopen(url, data)\n+        if data:\n+            r = requests.post(url, data, auth=auth)\n+        else:\n+            r = requests.get(url, auth=auth)\n \n         def http_code_and_message():\n-            return str(open_result.getcode()) + \" \" + httplib.responses[\n-                open_result.getcode()] + \": \" + open_result.read()\n+            code = r.status_code\n+            return str(code) + \" \" + http.client.responses[code] + \": \" + r.text\n \n         if expect_fail_and_get_error:\n-            if open_result.getcode() == 200:\n-                raise Exception(\"ClickHouse HTTP server is expected to fail, but succeeded: \" + open_result.read())\n+            if r.ok:\n+                raise Exception(\"ClickHouse HTTP server is expected to fail, but succeeded: \" + r.text)\n             return http_code_and_message()\n         else:\n-            if open_result.getcode() != 200:\n+            if not r.ok:\n                 raise Exception(\"ClickHouse HTTP server returned \" + http_code_and_message())\n-            return open_result.read()\n+            return r.text\n \n     # Connects to the instance via HTTP interface, sends a query and returns the answer\n     def http_request(self, url, method='GET', params=None, data=None, headers=None):\n@@ -1161,9 +1165,9 @@ def odbc_drivers(self):\n \n     def _create_odbc_config_file(self):\n         with open(self.odbc_ini_path.split(':')[0], 'w') as f:\n-            for driver_setup in self.odbc_drivers.values():\n+            for driver_setup in list(self.odbc_drivers.values()):\n                 f.write(\"[{}]\\n\".format(driver_setup[\"DSN\"]))\n-                for key, value in driver_setup.items():\n+                for key, value in list(driver_setup.items()):\n                     if key != \"DSN\":\n                         f.write(key + \"=\" + value + \"\\n\")\n \n@@ -1183,16 +1187,16 @@ def create_dir(self, destroy_dir=True):\n         instance_config_dir = p.abspath(p.join(self.path, 'configs'))\n         os.makedirs(instance_config_dir)\n \n-        print \"Copy common default production configuration from {}\".format(self.base_config_dir)\n+        print(\"Copy common default production configuration from {}\".format(self.base_config_dir))\n         shutil.copyfile(p.join(self.base_config_dir, 'config.xml'), p.join(instance_config_dir, 'config.xml'))\n         shutil.copyfile(p.join(self.base_config_dir, 'users.xml'), p.join(instance_config_dir, 'users.xml'))\n \n-        print \"Create directory for configuration generated in this helper\"\n+        print(\"Create directory for configuration generated in this helper\")\n         # used by all utils with any config\n         conf_d_dir = p.abspath(p.join(instance_config_dir, 'conf.d'))\n         os.mkdir(conf_d_dir)\n \n-        print \"Create directory for common tests configuration\"\n+        print(\"Create directory for common tests configuration\")\n         # used by server with main config.xml\n         self.config_d_dir = p.abspath(p.join(instance_config_dir, 'config.d'))\n         os.mkdir(self.config_d_dir)\n@@ -1201,14 +1205,14 @@ def create_dir(self, destroy_dir=True):\n         dictionaries_dir = p.abspath(p.join(instance_config_dir, 'dictionaries'))\n         os.mkdir(dictionaries_dir)\n \n-        print \"Copy common configuration from helpers\"\n+        print(\"Copy common configuration from helpers\")\n         # The file is named with 0_ prefix to be processed before other configuration overloads.\n         shutil.copy(p.join(HELPERS_DIR, '0_common_instance_config.xml'), self.config_d_dir)\n         shutil.copy(p.join(HELPERS_DIR, '0_common_instance_users.xml'), users_d_dir)\n         if len(self.custom_dictionaries_paths):\n             shutil.copy(p.join(HELPERS_DIR, '0_common_enable_dictionaries.xml'), self.config_d_dir)\n \n-        print \"Generate and write macros file\"\n+        print(\"Generate and write macros file\")\n         macros = self.macros.copy()\n         macros['instance'] = self.name\n         with open(p.join(conf_d_dir, 'macros.xml'), 'w') as macros_config:\n@@ -1222,7 +1226,7 @@ def create_dir(self, destroy_dir=True):\n             shutil.copytree(self.kerberos_secrets_dir, p.abspath(p.join(self.path, 'secrets')))\n \n         # Copy config.d configs\n-        print \"Copy custom test config files {} to {}\".format(self.custom_main_config_paths, self.config_d_dir)\n+        print(\"Copy custom test config files {} to {}\".format(self.custom_main_config_paths, self.config_d_dir))\n         for path in self.custom_main_config_paths:\n             shutil.copy(path, self.config_d_dir)\n \n@@ -1235,16 +1239,16 @@ def create_dir(self, destroy_dir=True):\n             shutil.copy(path, dictionaries_dir)\n \n         db_dir = p.abspath(p.join(self.path, 'database'))\n-        print \"Setup database dir {}\".format(db_dir)\n+        print(\"Setup database dir {}\".format(db_dir))\n         if self.clickhouse_path_dir is not None:\n-            print \"Database files taken from {}\".format(self.clickhouse_path_dir)\n+            print(\"Database files taken from {}\".format(self.clickhouse_path_dir))\n             shutil.copytree(self.clickhouse_path_dir, db_dir)\n-            print \"Database copied from {} to {}\".format(self.clickhouse_path_dir, db_dir)\n+            print(\"Database copied from {} to {}\".format(self.clickhouse_path_dir, db_dir))\n         else:\n             os.mkdir(db_dir)\n \n         logs_dir = p.abspath(p.join(self.path, 'logs'))\n-        print \"Setup logs dir {}\".format(logs_dir)\n+        print(\"Setup logs dir {}\".format(logs_dir))\n         os.mkdir(logs_dir)\n \n         depends_on = []\n@@ -1272,7 +1276,7 @@ def create_dir(self, destroy_dir=True):\n \n         env_file = _create_env_file(os.path.dirname(self.docker_compose_path), self.env_variables)\n \n-        print \"Env {} stored in {}\".format(self.env_variables, env_file)\n+        print(\"Env {} stored in {}\".format(self.env_variables, env_file))\n \n         odbc_ini_path = \"\"\n         if self.odbc_ini_path:\n@@ -1284,7 +1288,7 @@ def create_dir(self, destroy_dir=True):\n         if self.stay_alive:\n             entrypoint_cmd = CLICKHOUSE_STAY_ALIVE_COMMAND\n \n-        print \"Entrypoint cmd: {}\".format(entrypoint_cmd)\n+        print(\"Entrypoint cmd: {}\".format(entrypoint_cmd))\n \n         networks = app_net = ipv4_address = ipv6_address = net_aliases = net_alias1 = \"\"\n         if self.ipv4_address is not None or self.ipv6_address is not None or self.hostname != self.name:\ndiff --git a/tests/integration/helpers/external_sources.py b/tests/integration/helpers/external_sources.py\nindex a52cf7a02d80..47de9dd0caf1 100644\n--- a/tests/integration/helpers/external_sources.py\n+++ b/tests/integration/helpers/external_sources.py\n@@ -176,7 +176,7 @@ def load_data(self, data, table_name):\n         to_insert = []\n         for row in data:\n             row_dict = {}\n-            for cell_name, cell_value in row.data.items():\n+            for cell_name, cell_value in list(row.data.items()):\n                 row_dict[cell_name] = self.converters[cell_name](cell_value)\n             to_insert.append(row_dict)\n \n@@ -387,7 +387,7 @@ def prepare(self, structure, table_name, cluster):\n         self.node.exec_in_container([\n             \"bash\",\n             \"-c\",\n-            \"python2 /http_server.py --data-path={tbl} --schema={schema} --host={host} --port={port} --cert-path=/fake_cert.pem\".format(\n+            \"python3 /http_server.py --data-path={tbl} --schema={schema} --host={host} --port={port} --cert-path=/fake_cert.pem\".format(\n                 tbl=path, schema=self._get_schema(), host=self.docker_hostname, port=self.http_port)\n         ], detach=True)\n         self.ordered_names = structure.get_ordered_names()\n@@ -573,12 +573,14 @@ def compatible_with_layout(self, layout):\n     def _flush_aerospike_db(self):\n         keys = []\n \n-        def handle_record((key, metadata, record)):\n-            print(\"Handle record {} {}\".format(key, record))\n+        def handle_record(xxx_todo_changeme):\n+            (key, metadata, record) = xxx_todo_changeme\n+            print((\"Handle record {} {}\".format(key, record)))\n             keys.append(key)\n \n-        def print_record((key, metadata, record)):\n-            print(\"Print record {} {}\".format(key, record))\n+        def print_record(xxx_todo_changeme1):\n+            (key, metadata, record) = xxx_todo_changeme1\n+            print((\"Print record {} {}\".format(key, record)))\n \n         scan = self.client.scan(self.namespace, self.set)\n         scan.foreach(handle_record)\ndiff --git a/tests/integration/helpers/hdfs_api.py b/tests/integration/helpers/hdfs_api.py\nindex 70111045ad21..d3afa9be8371 100644\n--- a/tests/integration/helpers/hdfs_api.py\n+++ b/tests/integration/helpers/hdfs_api.py\n@@ -1,5 +1,5 @@\n # -*- coding: utf-8 -*-\n-import StringIO\n+import io\n import gzip\n import subprocess\n from tempfile import NamedTemporaryFile\n@@ -14,7 +14,7 @@ def __init__(self, user):\n         self.http_data_port = \"50075\"\n         self.user = user\n \n-    def read_data(self, path):\n+    def read_data(self, path, universal_newlines=True):\n         response = requests.get(\n             \"http://{host}:{port}/webhdfs/v1{path}?op=OPEN\".format(host=self.host, port=self.http_proxy_port,\n                                                                    path=path), allow_redirects=False)\n@@ -27,7 +27,10 @@ def read_data(self, path):\n         if response_data.status_code != 200:\n             response_data.raise_for_status()\n \n-        return response_data.content\n+        if universal_newlines:\n+            return response_data.text\n+        else:\n+            return response_data.content\n \n     # Requests can't put file\n     def _curl_to_put(self, filename, path, params):\n@@ -35,12 +38,14 @@ def _curl_to_put(self, filename, path, params):\n                                                                                 port=self.http_data_port, path=path,\n                                                                                 params=params)\n         cmd = \"curl -s -i -X PUT -T {fname} '{url}'\".format(fname=filename, url=url)\n-        output = subprocess.check_output(cmd, shell=True)\n+        output = subprocess.check_output(cmd, shell=True, universal_newlines=True)\n         return output\n \n     def write_data(self, path, content):\n-        named_file = NamedTemporaryFile()\n+        named_file = NamedTemporaryFile(mode='wb+')\n         fpath = named_file.name\n+        if isinstance(content, str):\n+            content = content.encode()\n         named_file.write(content)\n         named_file.flush()\n         response = requests.put(\n@@ -58,10 +63,12 @@ def write_data(self, path, content):\n             raise Exception(\"Can't create file on hdfs:\\n {}\".format(output))\n \n     def write_gzip_data(self, path, content):\n-        out = StringIO.StringIO()\n-        with gzip.GzipFile(fileobj=out, mode=\"w\") as f:\n+        if isinstance(content, str):\n+            content = content.encode()\n+        out = io.BytesIO()\n+        with gzip.GzipFile(fileobj=out, mode=\"wb\") as f:\n             f.write(content)\n         self.write_data(path, out.getvalue())\n \n     def read_gzip_data(self, path):\n-        return gzip.GzipFile(fileobj=StringIO.StringIO(self.read_data(path))).read()\n+        return gzip.GzipFile(fileobj=io.BytesIO(self.read_data(path, universal_newlines=False))).read().decode()\ndiff --git a/tests/integration/helpers/http_server.py b/tests/integration/helpers/http_server.py\nindex 83e134606e3f..e62096dd33f4 100644\n--- a/tests/integration/helpers/http_server.py\n+++ b/tests/integration/helpers/http_server.py\n@@ -3,7 +3,7 @@\n import csv\n import socket\n import ssl\n-from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer\n+from http.server import BaseHTTPRequestHandler, HTTPServer\n \n \n # Decorator used to see if authentication works for external dictionary who use a HTTP source.\n@@ -29,7 +29,7 @@ def do_GET(self):\n         @check_auth\n         def do_POST(self):\n             ids = self.__read_and_decode_post_ids()\n-            print \"ids=\", ids\n+            print(\"ids=\", ids)\n             self.__send_headers()\n             self.__send_data(ids)\n \n@@ -43,26 +43,26 @@ def __send_data(self, only_ids=None):\n                 reader = csv.reader(fl, delimiter='\\t')\n                 for row in reader:\n                     if not only_ids or (row[0] in only_ids):\n-                        self.wfile.write('\\t'.join(row) + '\\n')\n+                        self.wfile.write(('\\t'.join(row) + '\\n').encode())\n \n         def __read_and_decode_post_ids(self):\n             data = self.__read_and_decode_post_data()\n-            return filter(None, data.split())\n+            return [_f for _f in data.split() if _f]\n \n         def __read_and_decode_post_data(self):\n             transfer_encoding = self.headers.get(\"Transfer-encoding\")\n             decoded = \"\";\n             if transfer_encoding == \"chunked\":\n                 while True:\n-                    s = self.rfile.readline()\n+                    s = self.rfile.readline().decode()\n                     chunk_length = int(s, 16)\n                     if not chunk_length:\n                         break\n-                    decoded += self.rfile.read(chunk_length)\n-                    self.rfile.readline()\n+                    decoded += self.rfile.read(chunk_length).decode()\n+                    self.rfile.readline().decode()\n             else:\n                 content_length = int(self.headers.get(\"Content-Length\", 0))\n-                decoded = self.rfile.read(content_length)\n+                decoded = self.rfile.read(content_length).decode()\n             return decoded\n \n     if address_family == \"ipv6\":\ndiff --git a/tests/integration/helpers/network.py b/tests/integration/helpers/network.py\nindex f6505e81c910..a237f7d3cc7c 100644\n--- a/tests/integration/helpers/network.py\n+++ b/tests/integration/helpers/network.py\n@@ -183,7 +183,7 @@ def _exec_run(self, cmd, **kwargs):\n         exit_code = self._docker_client.api.exec_inspect(handle)['ExitCode']\n \n         if exit_code != 0:\n-            print output\n+            print(output)\n             raise subprocess.CalledProcessError(exit_code, cmd)\n \n         return output\ndiff --git a/tests/integration/helpers/test_tools.py b/tests/integration/helpers/test_tools.py\nindex 9fbffe418199..75ae8f67f7a9 100644\n--- a/tests/integration/helpers/test_tools.py\n+++ b/tests/integration/helpers/test_tools.py\n@@ -1,14 +1,15 @@\n import difflib\n import time\n+from io import IOBase\n \n \n class TSV:\n     \"\"\"Helper to get pretty diffs between expected and actual tab-separated value files\"\"\"\n \n     def __init__(self, contents):\n-        if isinstance(contents, file):\n+        if isinstance(contents, IOBase):\n             raw_lines = contents.readlines()\n-        elif isinstance(contents, str) or isinstance(contents, unicode):\n+        elif isinstance(contents, str) or isinstance(contents, str):\n             raw_lines = contents.splitlines(True)\n         elif isinstance(contents, list):\n             raw_lines = ['\\t'.join(map(str, l)) if isinstance(l, list) else str(l) for l in contents]\n@@ -29,7 +30,7 @@ def __ne__(self, other):\n             return self != TSV(other)\n         return self.lines != other.lines\n \n-    def diff(self, other, n1=None, n2=None):\n+    def diff(self, other, n1='', n2=''):\n         if not isinstance(other, TSV):\n             return self.diff(TSV(other), n1=n1, n2=n2)\n         return list(line.rstrip() for line in difflib.unified_diff(self.lines, other.lines, fromfile=n1, tofile=n2))[2:]\n@@ -45,14 +46,14 @@ def toMat(contents):\n def assert_eq_with_retry(instance, query, expectation, retry_count=20, sleep_time=0.5, stdin=None, timeout=None,\n                          settings=None, user=None, ignore_error=False):\n     expectation_tsv = TSV(expectation)\n-    for i in xrange(retry_count):\n+    for i in range(retry_count):\n         try:\n             if TSV(instance.query(query, user=user, stdin=stdin, timeout=timeout, settings=settings,\n                                   ignore_error=ignore_error)) == expectation_tsv:\n                 break\n             time.sleep(sleep_time)\n         except Exception as ex:\n-            print \"assert_eq_with_retry retry {} exception {}\".format(i + 1, ex)\n+            print((\"assert_eq_with_retry retry {} exception {}\".format(i + 1, ex)))\n             time.sleep(sleep_time)\n     else:\n         val = TSV(instance.query(query, user=user, stdin=stdin, timeout=timeout, settings=settings,\n@@ -66,13 +67,13 @@ def assert_logs_contain(instance, substring):\n         raise AssertionError(\"'{}' not found in logs\".format(substring))\n \n def assert_logs_contain_with_retry(instance, substring, retry_count=20, sleep_time=0.5):\n-    for i in xrange(retry_count):\n+    for i in range(retry_count):\n         try:\n             if instance.contains_in_log(substring):\n                 break\n             time.sleep(sleep_time)\n         except Exception as ex:\n-            print \"contains_in_log_with_retry retry {} exception {}\".format(i + 1, ex)\n+            print(\"contains_in_log_with_retry retry {} exception {}\".format(i + 1, ex))\n             time.sleep(sleep_time)\n     else:\n         raise AssertionError(\"'{}' not found in logs\".format(substring))\ndiff --git a/tests/integration/helpers/uclient.py b/tests/integration/helpers/uclient.py\nindex 098e17a38dab..538722580af5 100644\n--- a/tests/integration/helpers/uclient.py\n+++ b/tests/integration/helpers/uclient.py\n@@ -6,7 +6,7 @@\n \n sys.path.insert(0, os.path.join(CURDIR))\n \n-import uexpect\n+from . import uexpect\n \n prompt = ':\\) '\n end_of_block = r'.*\\r\\n.*\\r\\n'\ndiff --git a/tests/integration/helpers/uexpect.py b/tests/integration/helpers/uexpect.py\nindex 873d9a749e0f..cd26e3ddbd3d 100644\n--- a/tests/integration/helpers/uexpect.py\n+++ b/tests/integration/helpers/uexpect.py\n@@ -15,7 +15,7 @@\n import pty\n import re\n import time\n-from Queue import Queue, Empty\n+from queue import Queue, Empty\n from subprocess import Popen\n from threading import Thread, Event\n \n@@ -118,7 +118,7 @@ def send(self, data, eol=None):\n         return self.write(data + eol)\n \n     def write(self, data):\n-        return os.write(self.master, data)\n+        return os.write(self.master, data.encode())\n \n     def expect(self, pattern, timeout=None, escape=False):\n         self.match = None\n@@ -201,7 +201,8 @@ def spawn(command):\n def reader(process, out, queue, kill_event):\n     while True:\n         try:\n-            data = os.read(out, 65536)\n+            # TODO: there are some issues with 1<<16 buffer size\n+            data = os.read(out, 1<<17).decode(errors='replace')\n             queue.put(data)\n         except:\n             if kill_event.is_set():\ndiff --git a/tests/integration/runner b/tests/integration/runner\nindex 78d93af2929f..dbcb6f21732d 100755\n--- a/tests/integration/runner\n+++ b/tests/integration/runner\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n #-*- coding: utf-8 -*-\n import subprocess\n import os\n@@ -188,5 +188,5 @@ if __name__ == \"__main__\":\n         command=args.command\n     )\n \n-    print(\"Running pytest container as: '\" + cmd + \"'.\")\n+    print((\"Running pytest container as: '\" + cmd + \"'.\"))\n     subprocess.check_call(cmd, shell=True)\ndiff --git a/tests/integration/test_adaptive_granularity/test.py b/tests/integration/test_adaptive_granularity/test.py\nindex ec3169bb9955..12bfc22d7d94 100644\n--- a/tests/integration/test_adaptive_granularity/test.py\n+++ b/tests/integration/test_adaptive_granularity/test.py\n@@ -371,7 +371,7 @@ def callback(n):\n             node12.query(\"SYSTEM SYNC REPLICA table_with_default_granularity_new\", timeout=120)\n             break\n         except Exception as ex:\n-            print(\"Exception during replica sync\", ex)\n+            print((\"Exception during replica sync\", ex))\n             node11.query(\"SYSTEM RESTART REPLICA table_with_default_granularity_new\")\n             node12.query(\"SYSTEM RESTART REPLICA table_with_default_granularity_new\")\n             time.sleep(2 * i)\n@@ -386,7 +386,7 @@ def callback(n):\n             node12.query(\"SYSTEM SYNC REPLICA table_with_default_granularity\", timeout=120)\n             break\n         except Exception as ex:\n-            print(\"Exception during replica sync\", ex)\n+            print((\"Exception during replica sync\", ex))\n             node11.query(\"SYSTEM RESTART REPLICA table_with_default_granularity\")\n             node12.query(\"SYSTEM RESTART REPLICA table_with_default_granularity\")\n             time.sleep(2 * i)\ndiff --git a/tests/integration/test_cluster_copier/test.py b/tests/integration/test_cluster_copier/test.py\nindex 88dac06f1582..6a922dbfca72 100644\n--- a/tests/integration/test_cluster_copier/test.py\n+++ b/tests/integration/test_cluster_copier/test.py\n@@ -50,8 +50,8 @@ def started_cluster():\n             }\n         }\n \n-        for cluster_name, shards in clusters_schema.iteritems():\n-            for shard_name, replicas in shards.iteritems():\n+        for cluster_name, shards in clusters_schema.items():\n+            for shard_name, replicas in shards.items():\n                 for replica_name in replicas:\n                     name = \"s{}_{}_{}\".format(cluster_name, shard_name, replica_name)\n                     cluster.add_instance(name,\n@@ -235,16 +235,16 @@ def execute_task(task, cmd_options):\n     task.start()\n \n     zk = cluster.get_kazoo_client('zoo1')\n-    print \"Use ZooKeeper server: {}:{}\".format(zk.hosts[0][0], zk.hosts[0][1])\n+    print(\"Use ZooKeeper server: {}:{}\".format(zk.hosts[0][0], zk.hosts[0][1]))\n \n     try:\n         zk.delete(\"/clickhouse-copier\", recursive=True)\n     except kazoo.exceptions.NoNodeError:\n-        print \"No node /clickhouse-copier. It is Ok in first test.\"\n+        print(\"No node /clickhouse-copier. It is Ok in first test.\")\n \n     zk_task_path = task.zk_task_path\n     zk.ensure_path(zk_task_path)\n-    zk.create(zk_task_path + \"/description\", task.copier_task_config)\n+    zk.create(zk_task_path + \"/description\", task.copier_task_config.encode())\n \n     # Run cluster-copier processes on each node\n     docker_api = docker.from_env().api\n@@ -256,19 +256,19 @@ def execute_task(task, cmd_options):\n            '--base-dir', '/var/log/clickhouse-server/copier']\n     cmd += cmd_options\n \n-    copiers = random.sample(cluster.instances.keys(), 3)\n+    copiers = random.sample(list(cluster.instances.keys()), 3)\n \n     for instance_name in copiers:\n         instance = cluster.instances[instance_name]\n         container = instance.get_docker_handle()\n         instance.copy_file_to_container(os.path.join(CURRENT_TEST_DIR, \"configs/config-copier.xml\"),\n                                         \"/etc/clickhouse-server/config-copier.xml\")\n-        print \"Copied copier config to {}\".format(instance.name)\n+        print(\"Copied copier config to {}\".format(instance.name))\n         exec_id = docker_api.exec_create(container.id, cmd, stderr=True)\n         output = docker_api.exec_start(exec_id).decode('utf8')\n         print(output)\n         copiers_exec_ids.append(exec_id)\n-        print \"Copier for {} ({}) has started\".format(instance.name, instance.ip_address)\n+        print(\"Copier for {} ({}) has started\".format(instance.name, instance.ip_address))\n \n     # Wait for copiers stopping and check their return codes\n     for exec_id, instance_name in zip(copiers_exec_ids, copiers):\n@@ -362,6 +362,6 @@ def test_no_arg(started_cluster):\n \n if __name__ == '__main__':\n     with contextmanager(started_cluster)() as cluster:\n-        for name, instance in cluster.instances.items():\n-            print name, instance.ip_address\n-        raw_input(\"Cluster created, press any key to destroy...\")\n+        for name, instance in list(cluster.instances.items()):\n+            print(name, instance.ip_address)\n+        input(\"Cluster created, press any key to destroy...\")\ndiff --git a/tests/integration/test_cluster_copier/trivial_test.py b/tests/integration/test_cluster_copier/trivial_test.py\nindex 035faf0bb9fa..8a43440ac90c 100644\n--- a/tests/integration/test_cluster_copier/trivial_test.py\n+++ b/tests/integration/test_cluster_copier/trivial_test.py\n@@ -27,8 +27,8 @@ def started_cluster():\n \n         cluster = ClickHouseCluster(__file__)\n \n-        for cluster_name, shards in clusters_schema.iteritems():\n-            for shard_name, replicas in shards.iteritems():\n+        for cluster_name, shards in clusters_schema.items():\n+            for shard_name, replicas in shards.items():\n                 for replica_name in replicas:\n                     name = \"s{}_{}_{}\".format(cluster_name, shard_name, replica_name)\n                     cluster.add_instance(name,\n@@ -83,7 +83,7 @@ def execute_task(task, cmd_options):\n     task.start()\n \n     zk = cluster.get_kazoo_client('zoo1')\n-    print \"Use ZooKeeper server: {}:{}\".format(zk.hosts[0][0], zk.hosts[0][1])\n+    print(\"Use ZooKeeper server: {}:{}\".format(zk.hosts[0][0], zk.hosts[0][1]))\n \n     zk_task_path = task.zk_task_path\n     zk.ensure_path(zk_task_path)\n@@ -101,16 +101,16 @@ def execute_task(task, cmd_options):\n \n     print(cmd)\n \n-    for instance_name, instance in cluster.instances.iteritems():\n+    for instance_name, instance in cluster.instances.items():\n         container = instance.get_docker_handle()\n         exec_id = docker_api.exec_create(container.id, cmd, stderr=True)\n         docker_api.exec_start(exec_id, detach=True)\n \n         copiers_exec_ids.append(exec_id)\n-        print \"Copier for {} ({}) has started\".format(instance.name, instance.ip_address)\n+        print(\"Copier for {} ({}) has started\".format(instance.name, instance.ip_address))\n \n     # Wait for copiers stopping and check their return codes\n-    for exec_id, instance in zip(copiers_exec_ids, cluster.instances.itervalues()):\n+    for exec_id, instance in zip(copiers_exec_ids, iter(cluster.instances.values())):\n         while True:\n             res = docker_api.exec_inspect(exec_id)\n             if not res['Running']:\n@@ -175,6 +175,6 @@ def test_trivial_copy_with_move_fault(started_cluster, use_sample_offset):\n \n if __name__ == '__main__':\n     with contextmanager(started_cluster)() as cluster:\n-        for name, instance in cluster.instances.items():\n-            print name, instance.ip_address\n-        raw_input(\"Cluster created, press any key to destroy...\")\n+        for name, instance in list(cluster.instances.items()):\n+            print(name, instance.ip_address)\n+        input(\"Cluster created, press any key to destroy...\")\ndiff --git a/tests/integration/test_concurrent_queries_for_user_restriction/test.py b/tests/integration/test_concurrent_queries_for_user_restriction/test.py\nindex e287eb763ced..279e0dfe4398 100644\n--- a/tests/integration/test_concurrent_queries_for_user_restriction/test.py\n+++ b/tests/integration/test_concurrent_queries_for_user_restriction/test.py\n@@ -26,14 +26,14 @@ def test_exception_message(started_cluster):\n     assert node1.query(\"select number from nums order by number\") == \"0\\n1\\n\"\n \n     def node_busy(_):\n-        for i in xrange(10):\n+        for i in range(10):\n             node1.query(\"select sleep(2)\", user='default')\n \n     busy_pool = Pool(3)\n-    busy_pool.map_async(node_busy, xrange(3))\n+    busy_pool.map_async(node_busy, range(3))\n     time.sleep(1)  # wait a little until polling starts\n     try:\n         assert node2.query(\"select number from remote('node1', 'default', 'nums')\", user='good') == \"0\\n1\\n\"\n     except Exception as ex:\n-        print ex.message\n+        print(ex.message)\n         assert False, \"Exception thrown while max_concurrent_queries_for_user is not exceeded\"\ndiff --git a/tests/integration/test_concurrent_ttl_merges/test.py b/tests/integration/test_concurrent_ttl_merges/test.py\nindex f77ae5996d17..f067e65f58aa 100644\n--- a/tests/integration/test_concurrent_ttl_merges/test.py\n+++ b/tests/integration/test_concurrent_ttl_merges/test.py\n@@ -66,7 +66,7 @@ def test_no_ttl_merges_in_busy_pool(started_cluster):\n     node1.query(\"ALTER TABLE test_ttl UPDATE data = data + 1 WHERE sleepEachRow(1) = 0\")\n \n     while count_running_mutations(node1, \"test_ttl\") < 6:\n-        print \"Mutations count\", count_running_mutations(node1, \"test_ttl\")\n+        print(\"Mutations count\", count_running_mutations(node1, \"test_ttl\"))\n         assert count_ttl_merges_in_background_pool(node1, \"test_ttl\") == 0\n         time.sleep(0.5)\n \n@@ -74,7 +74,7 @@ def test_no_ttl_merges_in_busy_pool(started_cluster):\n \n     rows_count = []\n     while count_running_mutations(node1, \"test_ttl\") == 6:\n-        print \"Mutations count after start TTL\", count_running_mutations(node1, \"test_ttl\")\n+        print(\"Mutations count after start TTL\", count_running_mutations(node1, \"test_ttl\"))\n         rows_count.append(int(node1.query(\"SELECT count() FROM test_ttl\").strip()))\n         time.sleep(0.5)\n \ndiff --git a/tests/integration/test_config_substitutions/test.py b/tests/integration/test_config_substitutions/test.py\nindex 3a2d0d982810..565cd1c0e977 100644\n--- a/tests/integration/test_config_substitutions/test.py\n+++ b/tests/integration/test_config_substitutions/test.py\n@@ -19,7 +19,7 @@\n def start_cluster():\n     try:\n         def create_zk_roots(zk):\n-            zk.create(path=\"/setting/max_query_size\", value=\"77777\", makepath=True)\n+            zk.create(path=\"/setting/max_query_size\", value=b\"77777\", makepath=True)\n \n         cluster.add_zookeeper_startup_command(create_zk_roots)\n \ndiff --git a/tests/integration/test_consistant_parts_after_move_partition/test.py b/tests/integration/test_consistant_parts_after_move_partition/test.py\nindex 05e721ee5ea6..2070c8cb3f8a 100644\n--- a/tests/integration/test_consistant_parts_after_move_partition/test.py\n+++ b/tests/integration/test_consistant_parts_after_move_partition/test.py\n@@ -33,7 +33,7 @@ def start_cluster():\n         initialize_database([node1, node2], 1)\n         yield cluster\n     except Exception as ex:\n-        print ex\n+        print(ex)\n     finally:\n         cluster.shutdown()\n \ndiff --git a/tests/integration/test_consistent_parts_after_clone_replica/test.py b/tests/integration/test_consistent_parts_after_clone_replica/test.py\nindex 60b91bcb282d..784f94397af7 100644\n--- a/tests/integration/test_consistent_parts_after_clone_replica/test.py\n+++ b/tests/integration/test_consistent_parts_after_clone_replica/test.py\n@@ -29,7 +29,7 @@ def start_cluster():\n         fill_nodes([node1, node2], 1)\n         yield cluster\n     except Exception as ex:\n-        print ex\n+        print(ex)\n     finally:\n         cluster.shutdown()\n \ndiff --git a/tests/integration/test_cross_replication/test.py b/tests/integration/test_cross_replication/test.py\nindex 9171fea5547d..8a118934c938 100644\n--- a/tests/integration/test_cross_replication/test.py\n+++ b/tests/integration/test_cross_replication/test.py\n@@ -83,11 +83,11 @@ def test(started_cluster):\n         assert_eq_with_retry(node2, \"SELECT * FROM distributed ORDER BY id\", expected_from_distributed)\n \n         with pytest.raises(Exception):\n-            print node3.query_with_retry(\"SELECT * FROM distributed ORDER BY id\", retry_count=5)\n+            print(node3.query_with_retry(\"SELECT * FROM distributed ORDER BY id\", retry_count=5))\n \n \n if __name__ == '__main__':\n     with contextmanager(started_cluster)() as cluster:\n-        for name, instance in cluster.instances.items():\n-            print name, instance.ip_address\n-        raw_input(\"Cluster created, press any key to destroy...\")\n+        for name, instance in list(cluster.instances.items()):\n+            print(name, instance.ip_address)\n+        input(\"Cluster created, press any key to destroy...\")\ndiff --git a/tests/integration/test_delayed_replica_failover/test.py b/tests/integration/test_delayed_replica_failover/test.py\nindex f657edae6fb0..18184c3304d3 100644\n--- a/tests/integration/test_delayed_replica_failover/test.py\n+++ b/tests/integration/test_delayed_replica_failover/test.py\n@@ -98,12 +98,12 @@ def test(started_cluster):\n \n         # If we forbid stale replicas, the query must fail.\n         with pytest.raises(Exception):\n-            print instance_with_dist_table.query('''\n+            print(instance_with_dist_table.query('''\n SELECT count() FROM distributed SETTINGS\n     load_balancing='in_order',\n     max_replica_delay_for_distributed_queries=1,\n     fallback_to_stale_replicas_for_distributed_queries=0\n-''')\n+'''))\n \n         # Now partition off the remote replica of the local shard and test that failover still works.\n         pm.partition_instances(node_1_1, node_1_2, port=9000)\ndiff --git a/tests/integration/test_dictionaries_all_layouts_separate_sources/common.py b/tests/integration/test_dictionaries_all_layouts_separate_sources/common.py\nindex 0411b5d94758..ef6d133893ac 100644\n--- a/tests/integration/test_dictionaries_all_layouts_separate_sources/common.py\n+++ b/tests/integration/test_dictionaries_all_layouts_separate_sources/common.py\n@@ -113,12 +113,12 @@ def create_dictionaries(self, source_):\n                 self.layout_to_dictionary[layout] = get_dict(source_, Layout(layout), self.fields)\n \n     def prepare(self, cluster_):\n-        for _, dictionary in self.layout_to_dictionary.items():\n+        for _, dictionary in list(self.layout_to_dictionary.items()):\n             dictionary.prepare_source(cluster_)\n             dictionary.load_data(self.data)\n \n     def execute(self, layout_name, node):\n-        if not self.layout_to_dictionary.has_key(layout_name):\n+        if layout_name not in self.layout_to_dictionary:\n             raise RuntimeError(\"Source doesn't support layout: {}\".format(layout_name))\n \n         dct = self.layout_to_dictionary[layout_name]\n@@ -170,12 +170,12 @@ def create_dictionaries(self, source_):\n                 self.layout_to_dictionary[layout] = get_dict(source_, Layout(layout), self.fields)\n \n     def prepare(self, cluster_):\n-        for _, dictionary in self.layout_to_dictionary.items():\n+        for _, dictionary in list(self.layout_to_dictionary.items()):\n             dictionary.prepare_source(cluster_)\n             dictionary.load_data(self.data)\n \n     def execute(self, layout_name, node):\n-        if not self.layout_to_dictionary.has_key(layout_name):\n+        if layout_name not in self.layout_to_dictionary:\n             raise RuntimeError(\"Source doesn't support layout: {}\".format(layout_name))\n \n         dct = self.layout_to_dictionary[layout_name]\n@@ -213,13 +213,13 @@ def create_dictionaries(self, source_):\n                 self.layout_to_dictionary[layout] = get_dict(source_, Layout(layout), self.fields)\n \n     def prepare(self, cluster_):\n-        for _, dictionary in self.layout_to_dictionary.items():\n+        for _, dictionary in list(self.layout_to_dictionary.items()):\n             dictionary.prepare_source(cluster_)\n             dictionary.load_data(self.data)\n \n     def execute(self, layout_name, node):\n \n-        if not self.layout_to_dictionary.has_key(layout_name):\n+        if layout_name not in self.layout_to_dictionary:\n             raise RuntimeError(\"Source doesn't support layout: {}\".format(layout_name))\n \n         dct = self.layout_to_dictionary[layout_name]\ndiff --git a/tests/integration/test_dictionaries_complex_key_cache_string/test.py b/tests/integration/test_dictionaries_complex_key_cache_string/test.py\nindex c8969aee63e0..a01e60af47d0 100644\n--- a/tests/integration/test_dictionaries_complex_key_cache_string/test.py\n+++ b/tests/integration/test_dictionaries_complex_key_cache_string/test.py\n@@ -42,7 +42,7 @@ def test_memory_consumption(cluster):\n     allocated_first = int(node.query(\"select bytes_allocated from system.dictionaries where name = 'radars'\").strip())\n \n     alloc_array = []\n-    for i in xrange(5):\n+    for i in range(5):\n         node.query(\"select dictGetString('radars', 'client_id', tuple(toString(number))) from numbers(0, 5000)\")\n \n         allocated = int(node.query(\"select bytes_allocated from system.dictionaries where name = 'radars'\").strip())\n@@ -51,7 +51,7 @@ def test_memory_consumption(cluster):\n     # size doesn't grow\n     assert all(allocated_first >= a for a in alloc_array)\n \n-    for i in xrange(5):\n+    for i in range(5):\n         node.query(\"select dictGetString('radars', 'client_id', tuple(toString(number))) from numbers(0, 5000)\")\n \n         allocated = int(node.query(\"select bytes_allocated from system.dictionaries where name = 'radars'\").strip())\ndiff --git a/tests/integration/test_dictionaries_redis/test.py b/tests/integration/test_dictionaries_redis/test.py\nindex 385580816e0a..d08734af5470 100644\n--- a/tests/integration/test_dictionaries_redis/test.py\n+++ b/tests/integration/test_dictionaries_redis/test.py\n@@ -106,7 +106,7 @@ def setup_module(module):\n         for source in sources:\n             for layout in LAYOUTS:\n                 if not source.compatible_with_layout(layout):\n-                    print \"Source\", source.name, \"incompatible with layout\", layout.name\n+                    print(\"Source\", source.name, \"incompatible with layout\", layout.name)\n                     continue\n \n                 fields = KEY_FIELDS[layout.layout_type] + [field]\n@@ -128,9 +128,9 @@ def started_cluster():\n         assert len(FIELDS) == len(VALUES)\n         for dicts in DICTIONARIES:\n             for dictionary in dicts:\n-                print \"Preparing\", dictionary.name\n+                print(\"Preparing\", dictionary.name)\n                 dictionary.prepare_source(cluster)\n-                print \"Prepared\"\n+                print(\"Prepared\")\n \n         yield cluster\n \n@@ -138,9 +138,9 @@ def started_cluster():\n         cluster.shutdown()\n \n \n-@pytest.mark.parametrize(\"id\", range(len(FIELDS)))\n+@pytest.mark.parametrize(\"id\", list(range(len(FIELDS))))\n def test_redis_dictionaries(started_cluster, id):\n-    print 'id:', id\n+    print('id:', id)\n \n     dicts = DICTIONARIES[id]\n     values = VALUES[id]\n@@ -173,7 +173,7 @@ def test_redis_dictionaries(started_cluster, id):\n         node.query(\"system reload dictionary {}\".format(dct.name))\n \n         for query, answer in queries_with_answers:\n-            print query\n+            print(query)\n             assert node.query(query) == str(answer) + '\\n'\n \n     # Checks, that dictionaries can be reloaded.\ndiff --git a/tests/integration/test_dictionaries_select_all/generate_dictionaries.py b/tests/integration/test_dictionaries_select_all/generate_dictionaries.py\nindex 5c92d0d67e86..109ecea438e7 100644\n--- a/tests/integration/test_dictionaries_select_all/generate_dictionaries.py\n+++ b/tests/integration/test_dictionaries_select_all/generate_dictionaries.py\n@@ -1,5 +1,6 @@\n import difflib\n import os\n+from functools import reduce\n \n files = ['key_simple.tsv', 'key_complex_integers.tsv', 'key_complex_mixed.tsv']\n \n@@ -78,8 +79,9 @@ def generate_dictionaries(path, structure):\n     '''\n \n     dictionary_skeleton = \\\n-        dictionary_skeleton % reduce(lambda xml, (type, default): xml + attribute_skeleton % (type, type, default),\n-                                     zip(types, implicit_defaults), '')\n+        dictionary_skeleton % reduce(\n+            lambda xml, type_default: xml + attribute_skeleton % (type_default[0], type_default[0], type_default[1]),\n+            list(zip(types, implicit_defaults)), '')\n \n     source_clickhouse = '''\n     <clickhouse>\n@@ -195,7 +197,7 @@ def __init__(self, source_file_name):\n                     String_ String,\n                     Date_ Date, DateTime_ DateTime, Parent UInt64'''\n \n-        self.names_and_types = map(str.split, self.structure.split(','))\n+        self.names_and_types = list(map(str.split, self.structure.split(',')))\n         self.keys_names_and_types = self.names_and_types[:6]\n         self.values_names_and_types = self.names_and_types[6:]\n         self.source_file_name = source_file_name\n@@ -223,10 +225,10 @@ def wrap_value(pair):\n         def make_tuple(line):\n             row = tuple(line.split('\\t'))\n             self.rows.append(row)\n-            return '(' + ','.join(map(wrap_value, zip(row, types))) + ')'\n+            return '(' + ','.join(map(wrap_value, list(zip(row, types)))) + ')'\n \n         values = ','.join(map(make_tuple, lines))\n-        print query % (self.structure, values)\n+        print(query % (self.structure, values))\n         instance.query(query % (self.structure, values))\n \n     def get_structure_for_keys(self, keys, enable_parent=True):\n@@ -245,7 +247,7 @@ def compare_rows_by_keys(self, keys, values, lines, add_not_found_rows=True):\n         for row in rows:\n             key = '\\t'.join(row[:len(keys)])\n             value = '\\t'.join(row[len(keys):])\n-            if key in lines_map.keys():\n+            if key in list(lines_map.keys()):\n                 pattern_value = lines_map[key]\n                 del lines_map[key]\n                 if not value == pattern_value:\n@@ -256,7 +258,7 @@ def compare_rows_by_keys(self, keys, values, lines, add_not_found_rows=True):\n                 diff.append((key + '\\t' + value, ''))\n \n         if add_not_found_rows:\n-            for key, value in lines_map.items():\n+            for key, value in list(lines_map.items()):\n                 diff.append(('', key + '\\t' + value))\n \n         if not diff:\ndiff --git a/tests/integration/test_dictionaries_select_all/test.py b/tests/integration/test_dictionaries_select_all/test.py\nindex 5b8d39a7a631..5331f51f4c7d 100644\n--- a/tests/integration/test_dictionaries_select_all/test.py\n+++ b/tests/integration/test_dictionaries_select_all/test.py\n@@ -4,7 +4,7 @@\n from helpers.cluster import ClickHouseCluster\n from helpers.test_tools import TSV\n \n-from generate_dictionaries import generate_structure, generate_dictionaries, DictionaryTestTable\n+from .generate_dictionaries import generate_structure, generate_dictionaries, DictionaryTestTable\n \n SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))\n \n@@ -32,7 +32,7 @@ def started_cluster():\n         cluster.start()\n         test_table.create_clickhouse_source(instance)\n         for line in TSV(instance.query('select name from system.dictionaries')).lines:\n-            print line,\n+            print(line, end=' ')\n \n         yield cluster\n \n@@ -72,7 +72,7 @@ def test_select_all(dictionary_structure):\n     result = TSV(query('select * from test.{0}'.format(name)))\n \n     diff = test_table.compare_by_keys(keys, result.lines, use_parent, add_not_found_rows=True)\n-    print test_table.process_diff(diff)\n+    print(test_table.process_diff(diff))\n     assert not diff\n \n \n@@ -103,7 +103,7 @@ def test_select_all_from_cached(cached_dictionary_structure):\n     for i in range(4):\n         result = TSV(query('select * from test.{0}'.format(name)))\n         diff = test_table.compare_by_keys(keys, result.lines, use_parent, add_not_found_rows=False)\n-        print test_table.process_diff(diff)\n+        print(test_table.process_diff(diff))\n         assert not diff\n \n         key = []\n@@ -120,5 +120,5 @@ def test_select_all_from_cached(cached_dictionary_structure):\n \n     result = TSV(query('select * from test.{0}'.format(name)))\n     diff = test_table.compare_by_keys(keys, result.lines, use_parent, add_not_found_rows=True)\n-    print test_table.process_diff(diff)\n+    print(test_table.process_diff(diff))\n     assert not diff\ndiff --git a/tests/integration/test_dictionary_allow_read_expired_keys/test_default_reading.py b/tests/integration/test_dictionary_allow_read_expired_keys/test_default_reading.py\nindex 1266c37dcd37..416bbe089aa4 100644\n--- a/tests/integration/test_dictionary_allow_read_expired_keys/test_default_reading.py\n+++ b/tests/integration/test_dictionary_allow_read_expired_keys/test_default_reading.py\n@@ -1,4 +1,4 @@\n-from __future__ import print_function\n+\n \n import time\n \ndiff --git a/tests/integration/test_dictionary_allow_read_expired_keys/test_default_string.py b/tests/integration/test_dictionary_allow_read_expired_keys/test_default_string.py\nindex 2aa6fb448cad..caabdf12c665 100644\n--- a/tests/integration/test_dictionary_allow_read_expired_keys/test_default_string.py\n+++ b/tests/integration/test_dictionary_allow_read_expired_keys/test_default_string.py\n@@ -1,4 +1,4 @@\n-from __future__ import print_function\n+\n \n import os\n import random\ndiff --git a/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get.py b/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get.py\nindex 9de0b3be4eb8..7097bd15bb7b 100644\n--- a/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get.py\n+++ b/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get.py\n@@ -1,4 +1,4 @@\n-from __future__ import print_function\n+\n \n import time\n \ndiff --git a/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get_or_default.py b/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get_or_default.py\nindex 31f0e469555d..2aecb8691fbb 100644\n--- a/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get_or_default.py\n+++ b/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get_or_default.py\n@@ -1,4 +1,4 @@\n-from __future__ import print_function\n+\n \n import time\n \ndiff --git a/tests/integration/test_dictionary_custom_settings/http_server.py b/tests/integration/test_dictionary_custom_settings/http_server.py\nindex 20487ccf4475..bd5ce22dbac7 100644\n--- a/tests/integration/test_dictionary_custom_settings/http_server.py\n+++ b/tests/integration/test_dictionary_custom_settings/http_server.py\n@@ -3,7 +3,7 @@\n import csv\n import socket\n import ssl\n-from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer\n+from http.server import BaseHTTPRequestHandler, HTTPServer\n \n \n # Decorator used to see if authentication works for external dictionary who use a HTTP source.\n@@ -29,7 +29,7 @@ def do_GET(self):\n         @check_auth\n         def do_POST(self):\n             ids = self.__read_and_decode_post_ids()\n-            print \"ids=\", ids\n+            print(\"ids=\", ids)\n             self.__send_headers()\n             self.__send_data(ids)\n \n@@ -43,11 +43,11 @@ def __send_data(self, only_ids=None):\n                 reader = csv.reader(fl, delimiter='\\t')\n                 for row in reader:\n                     if not only_ids or (row[0] in only_ids):\n-                        self.wfile.write('\\t'.join(row) + '\\n')\n+                        self.wfile.write(('\\t'.join(row) + '\\n').encode())\n \n         def __read_and_decode_post_ids(self):\n             data = self.__read_and_decode_post_data()\n-            return filter(None, data.split())\n+            return [_f for _f in data.split() if _f]\n \n         def __read_and_decode_post_data(self):\n             transfer_encoding = self.headers.get(\"Transfer-encoding\")\n@@ -58,11 +58,11 @@ def __read_and_decode_post_data(self):\n                     chunk_length = int(s, 16)\n                     if not chunk_length:\n                         break\n-                    decoded += self.rfile.read(chunk_length)\n+                    decoded += self.rfile.read(chunk_length).decode()\n                     self.rfile.readline()\n             else:\n                 content_length = int(self.headers.get(\"Content-Length\", 0))\n-                decoded = self.rfile.read(content_length)\n+                decoded = self.rfile.read(content_length).decode()\n             return decoded\n \n     if address_family == \"ipv6\":\ndiff --git a/tests/integration/test_dictionary_custom_settings/test.py b/tests/integration/test_dictionary_custom_settings/test.py\nindex 022822c8a806..aa6a16afb519 100644\n--- a/tests/integration/test_dictionary_custom_settings/test.py\n+++ b/tests/integration/test_dictionary_custom_settings/test.py\n@@ -26,7 +26,7 @@ def prepare():\n     node.exec_in_container([\n         \"bash\",\n         \"-c\",\n-        \"python2 /http_server.py --data-path={tbl} --schema=http --host=localhost --port=5555\".format(\n+        \"python3 /http_server.py --data-path={tbl} --schema=http --host=localhost --port=5555\".format(\n             tbl=path)\n     ], detach=True)\n \ndiff --git a/tests/integration/test_disk_types/test.py b/tests/integration/test_disk_types/test.py\nindex a97b90af27da..c748653bc827 100644\n--- a/tests/integration/test_disk_types/test.py\n+++ b/tests/integration/test_disk_types/test.py\n@@ -33,5 +33,5 @@ def test_different_types(cluster):\n \n def test_select_by_type(cluster):\n     node = cluster.instances[\"node\"]\n-    for name, disk_type in disk_types.items():\n+    for name, disk_type in list(disk_types.items()):\n         assert node.query(\"SELECT name FROM system.disks WHERE type='\" + disk_type + \"'\") == name + \"\\n\"\ndiff --git a/tests/integration/test_distributed_ddl/cluster.py b/tests/integration/test_distributed_ddl/cluster.py\nindex efd6ce7e65cf..811eb94bad43 100644\n--- a/tests/integration/test_distributed_ddl/cluster.py\n+++ b/tests/integration/test_distributed_ddl/cluster.py\n@@ -26,12 +26,12 @@ def prepare(self, replace_hostnames_with_ips=True):\n                 main_configs += [os.path.join(self.test_config_dir, f) for f in\n                                  [\"server.crt\", \"server.key\", \"dhparam.pem\", \"config.d/ssl_conf.xml\"]]\n \n-            for i in xrange(4):\n+            for i in range(4):\n                 self.add_instance(\n                     'ch{}'.format(i + 1),\n                     main_configs=main_configs,\n                     user_configs=user_configs,\n-                    macros={\"layer\": 0, \"shard\": i / 2 + 1, \"replica\": i % 2 + 1},\n+                    macros={\"layer\": 0, \"shard\": i // 2 + 1, \"replica\": i % 2 + 1},\n                     with_zookeeper=True)\n \n             self.start()\n@@ -62,11 +62,11 @@ def prepare(self, replace_hostnames_with_ips=True):\n             self.ddl_check_query(instance, \"CREATE DATABASE IF NOT EXISTS test ON CLUSTER 'cluster'\")\n \n         except Exception as e:\n-            print e\n+            print(e)\n             raise\n \n     def sync_replicas(self, table, timeout=5):\n-        for instance in self.instances.values():\n+        for instance in list(self.instances.values()):\n             instance.query(\"SYSTEM SYNC REPLICA {}\".format(table), timeout=timeout)\n \n     def check_all_hosts_successfully_executed(self, tsv_content, num_hosts=None):\n@@ -90,7 +90,7 @@ def ddl_check_query(self, instance, query, num_hosts=None, settings=None):\n     def replace_domains_to_ip_addresses_in_cluster_config(self, instances_to_replace):\n         clusters_config = open(p.join(self.base_dir, '{}/config.d/clusters.xml'.format(self.test_config_dir))).read()\n \n-        for inst_name, inst in self.instances.items():\n+        for inst_name, inst in list(self.instances.items()):\n             clusters_config = clusters_config.replace(inst_name, str(inst.ip_address))\n \n         for inst_name in instances_to_replace:\n@@ -113,7 +113,7 @@ def insert_reliable(instance, query_insert):\n         Make retries in case of UNKNOWN_STATUS_OF_INSERT or zkutil::KeeperException errors\n         \"\"\"\n \n-        for i in xrange(100):\n+        for i in range(100):\n             try:\n                 instance.query(query_insert)\n                 return\ndiff --git a/tests/integration/test_distributed_ddl/test.py b/tests/integration/test_distributed_ddl/test.py\nindex 9f01fa7ed5b1..f0e78dfec414 100755\n--- a/tests/integration/test_distributed_ddl/test.py\n+++ b/tests/integration/test_distributed_ddl/test.py\n@@ -27,7 +27,7 @@ def test_cluster(request):\n \n         # Check query log to ensure that DDL queries are not executed twice\n         time.sleep(1.5)\n-        for instance in cluster.instances.values():\n+        for instance in list(cluster.instances.values()):\n             cluster.ddl_check_there_are_no_dublicates(instance)\n \n         cluster.pm_random_drops.heal_all()\n@@ -133,12 +133,12 @@ def test_simple_alters(test_cluster):\n ENGINE = Distributed('{cluster}', default, merge, i)\n \"\"\")\n \n-    for i in xrange(0, 4, 2):\n+    for i in range(0, 4, 2):\n         k = (i / 2) * 2\n         test_cluster.instances['ch{}'.format(i + 1)].query(\"INSERT INTO merge (i) VALUES ({})({})\".format(k, k + 1))\n \n     assert TSV(instance.query(\"SELECT i FROM all_merge_32 ORDER BY i\")) == TSV(\n-        ''.join(['{}\\n'.format(x) for x in xrange(4)]))\n+        ''.join(['{}\\n'.format(x) for x in range(4)]))\n \n     time.sleep(5)\n     test_cluster.ddl_check_query(instance, \"ALTER TABLE merge ON CLUSTER '{cluster}' MODIFY COLUMN i Int64\")\n@@ -147,19 +147,19 @@ def test_simple_alters(test_cluster):\n                                  \"ALTER TABLE merge ON CLUSTER '{cluster}' ADD COLUMN s String DEFAULT toString(i) FORMAT TSV\")\n \n     assert TSV(instance.query(\"SELECT i, s FROM all_merge_64 ORDER BY i\")) == TSV(\n-        ''.join(['{}\\t{}\\n'.format(x, x) for x in xrange(4)]))\n+        ''.join(['{}\\t{}\\n'.format(x, x) for x in range(4)]))\n \n-    for i in xrange(0, 4, 2):\n+    for i in range(0, 4, 2):\n         k = (i / 2) * 2 + 4\n         test_cluster.instances['ch{}'.format(i + 1)].query(\n             \"INSERT INTO merge (p, i) VALUES (31, {})(31, {})\".format(k, k + 1))\n \n     assert TSV(instance.query(\"SELECT i, s FROM all_merge_64 ORDER BY i\")) == TSV(\n-        ''.join(['{}\\t{}\\n'.format(x, x) for x in xrange(8)]))\n+        ''.join(['{}\\t{}\\n'.format(x, x) for x in range(8)]))\n \n     test_cluster.ddl_check_query(instance, \"ALTER TABLE merge ON CLUSTER '{cluster}' DETACH PARTITION 197002\")\n     assert TSV(instance.query(\"SELECT i, s FROM all_merge_64 ORDER BY i\")) == TSV(\n-        ''.join(['{}\\t{}\\n'.format(x, x) for x in xrange(4)]))\n+        ''.join(['{}\\t{}\\n'.format(x, x) for x in range(4)]))\n \n     test_cluster.ddl_check_query(instance, \"DROP TABLE merge ON CLUSTER '{cluster}'\")\n     test_cluster.ddl_check_query(instance, \"DROP TABLE all_merge_32 ON CLUSTER '{cluster}'\")\n@@ -170,7 +170,7 @@ def test_macro(test_cluster):\n     instance = test_cluster.instances['ch2']\n     test_cluster.ddl_check_query(instance, \"CREATE TABLE tab ON CLUSTER '{cluster}' (value UInt8) ENGINE = Memory\")\n \n-    for i in xrange(4):\n+    for i in range(4):\n         test_cluster.insert_reliable(test_cluster.instances['ch{}'.format(i + 1)],\n                                      \"INSERT INTO tab VALUES ({})\".format(i))\n \n@@ -359,6 +359,6 @@ def test_replicated_without_arguments(test_cluster):\n \n if __name__ == '__main__':\n     with contextmanager(test_cluster)() as ctx_cluster:\n-        for name, instance in ctx_cluster.instances.items():\n-            print name, instance.ip_address\n-        raw_input(\"Cluster created, press any key to destroy...\")\n+        for name, instance in list(ctx_cluster.instances.items()):\n+            print(name, instance.ip_address)\n+        input(\"Cluster created, press any key to destroy...\")\ndiff --git a/tests/integration/test_distributed_ddl/test_replicated_alter.py b/tests/integration/test_distributed_ddl/test_replicated_alter.py\nindex 840803f61efe..bd95f5660b75 100644\n--- a/tests/integration/test_distributed_ddl/test_replicated_alter.py\n+++ b/tests/integration/test_distributed_ddl/test_replicated_alter.py\n@@ -26,7 +26,7 @@ def test_cluster(request):\n \n         # Check query log to ensure that DDL queries are not executed twice\n         time.sleep(1.5)\n-        for instance in cluster.instances.values():\n+        for instance in list(cluster.instances.values()):\n             cluster.ddl_check_there_are_no_dublicates(instance)\n \n         cluster.pm_random_drops.heal_all()\n@@ -59,36 +59,36 @@ def test_replicated_alters(test_cluster):\n ENGINE = Distributed(cluster, default, merge_for_alter, i)\n \"\"\")\n \n-    for i in xrange(4):\n-        k = (i / 2) * 2\n+    for i in range(4):\n+        k = (i // 2) * 2\n         test_cluster.insert_reliable(test_cluster.instances['ch{}'.format(i + 1)],\n                                      \"INSERT INTO merge_for_alter (i) VALUES ({})({})\".format(k, k + 1))\n \n     test_cluster.sync_replicas(\"merge_for_alter\")\n \n     assert TSV(instance.query(\"SELECT i FROM all_merge_32 ORDER BY i\")) == TSV(\n-        ''.join(['{}\\n'.format(x) for x in xrange(4)]))\n+        ''.join(['{}\\n'.format(x) for x in range(4)]))\n \n     test_cluster.ddl_check_query(instance, \"ALTER TABLE merge_for_alter ON CLUSTER cluster MODIFY COLUMN i Int64\")\n     test_cluster.ddl_check_query(instance,\n                                  \"ALTER TABLE merge_for_alter ON CLUSTER cluster ADD COLUMN s String DEFAULT toString(i)\")\n \n     assert TSV(instance.query(\"SELECT i, s FROM all_merge_64 ORDER BY i\")) == TSV(\n-        ''.join(['{}\\t{}\\n'.format(x, x) for x in xrange(4)]))\n+        ''.join(['{}\\t{}\\n'.format(x, x) for x in range(4)]))\n \n-    for i in xrange(4):\n-        k = (i / 2) * 2 + 4\n+    for i in range(4):\n+        k = (i // 2) * 2 + 4\n         test_cluster.insert_reliable(test_cluster.instances['ch{}'.format(i + 1)],\n                                      \"INSERT INTO merge_for_alter (p, i) VALUES (31, {})(31, {})\".format(k, k + 1))\n \n     test_cluster.sync_replicas(\"merge_for_alter\")\n \n     assert TSV(instance.query(\"SELECT i, s FROM all_merge_64 ORDER BY i\")) == TSV(\n-        ''.join(['{}\\t{}\\n'.format(x, x) for x in xrange(8)]))\n+        ''.join(['{}\\t{}\\n'.format(x, x) for x in range(8)]))\n \n     test_cluster.ddl_check_query(instance, \"ALTER TABLE merge_for_alter ON CLUSTER cluster DETACH PARTITION 197002\")\n     assert TSV(instance.query(\"SELECT i, s FROM all_merge_64 ORDER BY i\")) == TSV(\n-        ''.join(['{}\\t{}\\n'.format(x, x) for x in xrange(4)]))\n+        ''.join(['{}\\t{}\\n'.format(x, x) for x in range(4)]))\n \n     test_cluster.ddl_check_query(instance, \"DROP TABLE merge_for_alter ON CLUSTER cluster\")\n \ndiff --git a/tests/integration/test_distributed_inter_server_secret/test.py b/tests/integration/test_distributed_inter_server_secret/test.py\nindex b39f9dec8612..bd9e6d111ca1 100644\n--- a/tests/integration/test_distributed_inter_server_secret/test.py\n+++ b/tests/integration/test_distributed_inter_server_secret/test.py\n@@ -25,7 +25,7 @@ def make_instance(name, cfg):\n ])\n \n def bootstrap():\n-    for n in cluster.instances.values():\n+    for n in list(cluster.instances.values()):\n         n.query('DROP TABLE IF EXISTS data')\n         n.query('DROP TABLE IF EXISTS dist')\n         n.query('CREATE TABLE data (key Int) Engine=Memory()')\ndiff --git a/tests/integration/test_distributed_load_balancing/test.py b/tests/integration/test_distributed_load_balancing/test.py\nindex b227c57fb04e..e7b86a210bdb 100644\n--- a/tests/integration/test_distributed_load_balancing/test.py\n+++ b/tests/integration/test_distributed_load_balancing/test.py\n@@ -18,7 +18,7 @@\n \n \n def bootstrap():\n-    for n in cluster.instances.values():\n+    for n in list(cluster.instances.values()):\n         # At startup, server loads configuration files.\n         #\n         # However ConfigReloader does not know about already loaded files\n@@ -90,7 +90,7 @@ def get_node(query_node, table='dist', *args, **kwargs):\n \n     query_node.query('SELECT * FROM ' + table, *args, **kwargs)\n \n-    for n in cluster.instances.values():\n+    for n in list(cluster.instances.values()):\n         n.query('SYSTEM FLUSH LOGS')\n \n     rows = query_node.query(\"\"\"\ndiff --git a/tests/integration/test_distributed_over_distributed/test.py b/tests/integration/test_distributed_over_distributed/test.py\nindex 716bc66d629c..410a03a6af11 100644\n--- a/tests/integration/test_distributed_over_distributed/test.py\n+++ b/tests/integration/test_distributed_over_distributed/test.py\n@@ -1,7 +1,7 @@\n # This test is a subset of the 01223_dist_on_dist.\n # (just in case, with real separate instances).\n \n-from __future__ import print_function\n+\n \n import pytest\n from helpers.cluster import ClickHouseCluster\n@@ -51,7 +51,7 @@ def started_cluster():\n         cluster.shutdown()\n \n \n-@pytest.mark.parametrize(\"node\", NODES.values())\n+@pytest.mark.parametrize(\"node\", list(NODES.values()))\n @pytest.mark.parametrize(\"source\",\n                          [\"distributed_over_distributed_table\", \"cluster('test_cluster', default, distributed_table)\"])\n class TestDistributedOverDistributedSuite:\ndiff --git a/tests/integration/test_distributed_over_live_view/test.py b/tests/integration/test_distributed_over_live_view/test.py\nindex 9e62aaad9820..78b90024ebf8 100644\n--- a/tests/integration/test_distributed_over_live_view/test.py\n+++ b/tests/integration/test_distributed_over_live_view/test.py\n@@ -1,4 +1,4 @@\n-from __future__ import print_function\n+\n \n import sys\n import time\n@@ -9,6 +9,9 @@\n \n cluster = ClickHouseCluster(__file__)\n \n+# log = sys.stdout\n+log = None\n+\n NODES = {'node' + str(i): cluster.add_instance(\n     'node' + str(i),\n     main_configs=['configs/remote_servers.xml'],\n@@ -63,12 +66,11 @@ def poll_query(node, query, expected, timeout):\n         pass\n     assert node.query(query) == expected\n \n-@pytest.mark.parametrize(\"node\", NODES.values()[:1])\n+@pytest.mark.parametrize(\"node\", list(NODES.values())[:1])\n @pytest.mark.parametrize(\"source\", [\"lv_over_distributed_table\"])\n class TestLiveViewOverDistributedSuite:\n     def test_distributed_over_live_view_order_by_node(self, started_cluster, node, source):\n-        log = sys.stdout\n-        node0, node1 = NODES.values()\n+        node0, node1 = list(NODES.values())\n \n         select_query = \"SELECT * FROM distributed_over_lv ORDER BY node, key FORMAT CSV\"\n         select_query_dist_table = \"SELECT * FROM distributed_table ORDER BY node, key FORMAT CSV\"\n@@ -118,8 +120,7 @@ def test_distributed_over_live_view_order_by_node(self, started_cluster, node, s\n             client1.expect(prompt)\n \n     def test_distributed_over_live_view_order_by_key(self, started_cluster, node, source):\n-        log = sys.stdout\n-        node0, node1 = NODES.values()\n+        node0, node1 = list(NODES.values())\n \n         select_query = \"SELECT * FROM distributed_over_lv ORDER BY key, node FORMAT CSV\"\n         select_count_query = \"SELECT count() FROM distributed_over_lv\"\n@@ -160,8 +161,7 @@ def test_distributed_over_live_view_order_by_key(self, started_cluster, node, so\n             client1.expect(prompt)\n \n     def test_distributed_over_live_view_group_by_node(self, started_cluster, node, source):\n-        log = sys.stdout\n-        node0, node1 = NODES.values()\n+        node0, node1 = list(NODES.values())\n \n         select_query = \"SELECT node, SUM(value) FROM distributed_over_lv GROUP BY node ORDER BY node FORMAT CSV\"\n \n@@ -204,8 +204,7 @@ def test_distributed_over_live_view_group_by_node(self, started_cluster, node, s\n             client1.expect(prompt)\n \n     def test_distributed_over_live_view_group_by_key(self, started_cluster, node, source):\n-        log = sys.stdout\n-        node0, node1 = NODES.values()\n+        node0, node1 = list(NODES.values())\n \n         select_query = \"SELECT key, SUM(value) FROM distributed_over_lv GROUP BY key ORDER BY key FORMAT CSV\"\n \n@@ -249,8 +248,7 @@ def test_distributed_over_live_view_group_by_key(self, started_cluster, node, so\n             client1.expect(prompt)\n \n     def test_distributed_over_live_view_sum(self, started_cluster, node, source):\n-        log = sys.stdout\n-        node0, node1 = NODES.values()\n+        node0, node1 = list(NODES.values())\n \n         with client(name=\"client1> \", log=log, command=\" \".join(node0.client.command)) as client1, \\\n                 client(name=\"client2> \", log=log, command=\" \".join(node1.client.command)) as client2:\ndiff --git a/tests/integration/test_distributed_respect_user_timeouts/test.py b/tests/integration/test_distributed_respect_user_timeouts/test.py\nindex e5d9d0c1857d..c19323b20497 100644\n--- a/tests/integration/test_distributed_respect_user_timeouts/test.py\n+++ b/tests/integration/test_distributed_respect_user_timeouts/test.py\n@@ -103,7 +103,7 @@ def started_cluster(request):\n     try:\n         cluster.start()\n \n-        for node_id, node in NODES.items():\n+        for node_id, node in list(NODES.items()):\n             node.query(CREATE_TABLES_SQL)\n             node.query(INSERT_SQL_TEMPLATE.format(node_id=node_id))\n \n@@ -155,7 +155,7 @@ def test_reconnect(started_cluster, node_name, first_user, query_base):\n \n     with PartitionManager() as pm:\n         # Break the connection.\n-        pm.partition_instances(*NODES.values())\n+        pm.partition_instances(*list(NODES.values()))\n \n         # Now it shouldn't:\n         _check_timeout_and_exception(node, first_user, query_base, query)\ndiff --git a/tests/integration/test_drop_replica/test.py b/tests/integration/test_drop_replica/test.py\nindex fac8802b2f93..f3af9dcb9807 100644\n--- a/tests/integration/test_drop_replica/test.py\n+++ b/tests/integration/test_drop_replica/test.py\n@@ -65,7 +65,7 @@ def start_cluster():\n         yield cluster\n \n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     finally:\n         cluster.shutdown()\ndiff --git a/tests/integration/test_fetch_partition_from_auxiliary_zookeeper/test.py b/tests/integration/test_fetch_partition_from_auxiliary_zookeeper/test.py\nindex 9ad56d4fb17c..f9c10d68fe3e 100644\n--- a/tests/integration/test_fetch_partition_from_auxiliary_zookeeper/test.py\n+++ b/tests/integration/test_fetch_partition_from_auxiliary_zookeeper/test.py\n@@ -1,4 +1,4 @@\n-from __future__ import print_function\n+\n \n import pytest\n from helpers.client import QueryRuntimeException\ndiff --git a/tests/integration/test_format_avro_confluent/test.py b/tests/integration/test_format_avro_confluent/test.py\nindex 67d153053333..cc0068017358 100644\n--- a/tests/integration/test_format_avro_confluent/test.py\n+++ b/tests/integration/test_format_avro_confluent/test.py\n@@ -3,7 +3,7 @@\n \n import avro.schema\n import pytest\n-from confluent.schemaregistry.serializers import MessageSerializer\n+from confluent_kafka.avro.serializer.message_serializer import MessageSerializer\n from helpers.cluster import ClickHouseCluster, ClickHouseInstance\n \n logging.getLogger().setLevel(logging.INFO)\ndiff --git a/tests/integration/test_grant_and_revoke/test.py b/tests/integration/test_grant_and_revoke/test.py\nindex 073578edaa5e..0404120907d5 100644\n--- a/tests/integration/test_grant_and_revoke/test.py\n+++ b/tests/integration/test_grant_and_revoke/test.py\n@@ -226,8 +226,8 @@ def test_introspection():\n \n     assert instance.query(\n         \"SELECT * from system.grants WHERE user_name IN ('A', 'B') ORDER BY user_name, access_type, grant_option\") == \\\n-           TSV([[\"A\", \"\\N\", \"SELECT\", \"test\", \"table\", \"\\N\", 0, 0],\n-                [\"B\", \"\\N\", \"CREATE\", \"\\N\", \"\\N\", \"\\N\", 0, 1]])\n+           TSV([[\"A\", \"\\\\N\", \"SELECT\", \"test\", \"table\", \"\\\\N\", 0, 0],\n+                [\"B\", \"\\\\N\", \"CREATE\", \"\\\\N\", \"\\\\N\", \"\\\\N\", 0, 1]])\n \n \n def test_current_database():\ndiff --git a/tests/integration/test_graphite_merge_tree/test.py b/tests/integration/test_graphite_merge_tree/test.py\nindex 319fdb816ff5..502004d2dfea 100644\n--- a/tests/integration/test_graphite_merge_tree/test.py\n+++ b/tests/integration/test_graphite_merge_tree/test.py\n@@ -301,7 +301,7 @@ def test_path_dangling_pointer(graphite_table):\n                       \"AND table='graphite2'\"))\n         if parts == 1:\n             break\n-        print('Parts', parts)\n+        print(('Parts', parts))\n \n     assert TSV(\n         q(\"SELECT value, timestamp, date, updated FROM test.graphite2\")\ndiff --git a/tests/integration/test_host_ip_change/test.py b/tests/integration/test_host_ip_change/test.py\nindex 951af699a5f8..7525914e8038 100644\n--- a/tests/integration/test_host_ip_change/test.py\n+++ b/tests/integration/test_host_ip_change/test.py\n@@ -35,7 +35,7 @@ def cluster_without_dns_cache_update():\n         yield cluster\n \n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     finally:\n         cluster.shutdown()\n@@ -90,7 +90,7 @@ def cluster_with_dns_cache_update():\n         yield cluster\n \n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     finally:\n         cluster.shutdown()\n@@ -117,7 +117,7 @@ def test_ip_change_update_dns_cache(cluster_with_dns_cache_update):\n     curl_result = node4.exec_in_container([\"bash\", \"-c\", \"curl -s 'node3:8123'\"])\n     assert curl_result == 'Ok.\\n'\n     cat_resolv = node4.exec_in_container([\"bash\", \"-c\", \"cat /etc/resolv.conf\"])\n-    print(\"RESOLV {}\".format(cat_resolv))\n+    print((\"RESOLV {}\".format(cat_resolv)))\n \n     assert_eq_with_retry(node4, \"SELECT * FROM remote('node3', 'system', 'one')\", \"0\", sleep_time=0.5)\n \ndiff --git a/tests/integration/test_http_handlers_config/test.py b/tests/integration/test_http_handlers_config/test.py\nindex 06602ba3ca32..818a1e54640c 100644\n--- a/tests/integration/test_http_handlers_config/test.py\n+++ b/tests/integration/test_http_handlers_config/test.py\n@@ -1,6 +1,6 @@\n import contextlib\n import os\n-import urllib\n+import urllib.request, urllib.parse, urllib.error\n \n from helpers.cluster import ClickHouseCluster\n \n@@ -22,7 +22,7 @@ def add_instance(self, name, config_dir):\n def test_dynamic_query_handler():\n     with contextlib.closing(\n             SimpleCluster(ClickHouseCluster(__file__), \"dynamic_handler\", \"test_dynamic_handler\")) as cluster:\n-        test_query = urllib.quote_plus('SELECT * FROM system.settings WHERE name = \\'max_threads\\'')\n+        test_query = urllib.parse.quote_plus('SELECT * FROM system.settings WHERE name = \\'max_threads\\'')\n \n         assert 404 == cluster.instance.http_request('?max_threads=1', method='GET', headers={'XXX': 'xxx'}).status_code\n \n@@ -54,11 +54,11 @@ def test_predefined_query_handler():\n         assert 500 == cluster.instance.http_request('test_predefined_handler_get?max_threads=1', method='GET',\n                                                     headers={'XXX': 'xxx'}).status_code\n \n-        assert 'max_threads\\t1\\n' == cluster.instance.http_request(\n+        assert b'max_threads\\t1\\n' == cluster.instance.http_request(\n             'test_predefined_handler_get?max_threads=1&setting_name=max_threads', method='GET',\n             headers={'XXX': 'xxx'}).content\n \n-        assert 'max_threads\\t1\\nmax_alter_threads\\t1\\n' == cluster.instance.http_request(\n+        assert b'max_threads\\t1\\nmax_alter_threads\\t1\\n' == cluster.instance.http_request(\n             'query_param_with_url/max_threads?max_threads=1&max_alter_threads=1',\n             headers={'XXX': 'max_alter_threads'}).content\n \n@@ -79,7 +79,7 @@ def test_fixed_static_handler():\n         assert 'text/html; charset=UTF-8' == \\\n                cluster.instance.http_request('test_get_fixed_static_handler', method='GET',\n                                              headers={'XXX': 'xxx'}).headers['Content-Type']\n-        assert 'Test get static handler and fix content' == cluster.instance.http_request(\n+        assert b'Test get static handler and fix content' == cluster.instance.http_request(\n             'test_get_fixed_static_handler', method='GET', headers={'XXX': 'xxx'}).content\n \n \n@@ -100,7 +100,7 @@ def test_config_static_handler():\n         assert 'text/plain; charset=UTF-8' == \\\n                cluster.instance.http_request('test_get_config_static_handler', method='GET',\n                                              headers={'XXX': 'xxx'}).headers['Content-Type']\n-        assert 'Test get static handler and config content' == cluster.instance.http_request(\n+        assert b'Test get static handler and config content' == cluster.instance.http_request(\n             'test_get_config_static_handler', method='GET', headers={'XXX': 'xxx'}).content\n \n \n@@ -126,7 +126,7 @@ def test_absolute_path_static_handler():\n         assert 'text/html; charset=UTF-8' == \\\n                cluster.instance.http_request('test_get_absolute_path_static_handler', method='GET',\n                                              headers={'XXX': 'xxx'}).headers['Content-Type']\n-        assert '<html><body>Absolute Path File</body></html>\\n' == cluster.instance.http_request(\n+        assert b'<html><body>Absolute Path File</body></html>\\n' == cluster.instance.http_request(\n             'test_get_absolute_path_static_handler', method='GET', headers={'XXX': 'xxx'}).content\n \n \n@@ -152,7 +152,7 @@ def test_relative_path_static_handler():\n         assert 'text/html; charset=UTF-8' == \\\n                cluster.instance.http_request('test_get_relative_path_static_handler', method='GET',\n                                              headers={'XXX': 'xxx'}).headers['Content-Type']\n-        assert '<html><body>Relative Path File</body></html>\\n' == cluster.instance.http_request(\n+        assert b'<html><body>Relative Path File</body></html>\\n' == cluster.instance.http_request(\n             'test_get_relative_path_static_handler', method='GET', headers={'XXX': 'xxx'}).content\n \n \n@@ -160,19 +160,19 @@ def test_defaults_http_handlers():\n     with contextlib.closing(\n             SimpleCluster(ClickHouseCluster(__file__), \"defaults_handlers\", \"test_defaults_handlers\")) as cluster:\n         assert 200 == cluster.instance.http_request('', method='GET').status_code\n-        assert 'Default server response' == cluster.instance.http_request('', method='GET').content\n+        assert b'Default server response' == cluster.instance.http_request('', method='GET').content\n \n         assert 200 == cluster.instance.http_request('ping', method='GET').status_code\n-        assert 'Ok.\\n' == cluster.instance.http_request('ping', method='GET').content\n+        assert b'Ok.\\n' == cluster.instance.http_request('ping', method='GET').content\n \n         assert 200 == cluster.instance.http_request('replicas_status', method='get').status_code\n-        assert 'Ok.\\n' == cluster.instance.http_request('replicas_status', method='get').content\n+        assert b'Ok.\\n' == cluster.instance.http_request('replicas_status', method='get').content\n \n         assert 200 == cluster.instance.http_request('replicas_status?verbose=1', method='get').status_code\n-        assert '' == cluster.instance.http_request('replicas_status?verbose=1', method='get').content\n+        assert b'' == cluster.instance.http_request('replicas_status?verbose=1', method='get').content\n \n         assert 200 == cluster.instance.http_request('?query=SELECT+1', method='GET').status_code\n-        assert '1\\n' == cluster.instance.http_request('?query=SELECT+1', method='GET').content\n+        assert b'1\\n' == cluster.instance.http_request('?query=SELECT+1', method='GET').content\n \n \n def test_prometheus_handler():\n@@ -186,7 +186,7 @@ def test_prometheus_handler():\n                                                     headers={'XXX': 'xxx'}).status_code\n \n         assert 200 == cluster.instance.http_request('test_prometheus', method='GET', headers={'XXX': 'xxx'}).status_code\n-        assert 'ClickHouseProfileEvents_Query' in cluster.instance.http_request('test_prometheus', method='GET',\n+        assert b'ClickHouseProfileEvents_Query' in cluster.instance.http_request('test_prometheus', method='GET',\n                                                                                 headers={'XXX': 'xxx'}).content\n \n \n@@ -203,5 +203,5 @@ def test_replicas_status_handler():\n \n         assert 200 == cluster.instance.http_request('test_replicas_status', method='GET',\n                                                     headers={'XXX': 'xxx'}).status_code\n-        assert 'Ok.\\n' == cluster.instance.http_request('test_replicas_status', method='GET',\n+        assert b'Ok.\\n' == cluster.instance.http_request('test_replicas_status', method='GET',\n                                                         headers={'XXX': 'xxx'}).content\ndiff --git a/tests/integration/test_https_replication/test.py b/tests/integration/test_https_replication/test.py\nindex 84c2744923d6..dbb6874718ca 100644\n--- a/tests/integration/test_https_replication/test.py\n+++ b/tests/integration/test_https_replication/test.py\n@@ -75,7 +75,7 @@ def insert_data_and_check(num):\n     closing_pool = Pool(1)\n     inserting_pool = Pool(5)\n     cres = closing_pool.map_async(close, [random.randint(1, 3) for _ in range(10)])\n-    ires = inserting_pool.map_async(insert_data_and_check, range(100))\n+    ires = inserting_pool.map_async(insert_data_and_check, list(range(100)))\n \n     cres.wait()\n     ires.wait()\ndiff --git a/tests/integration/test_insert_into_distributed_sync_async/test.py b/tests/integration/test_insert_into_distributed_sync_async/test.py\nindex 30c80e50c438..372ed04cd2c9 100755\n--- a/tests/integration/test_insert_into_distributed_sync_async/test.py\n+++ b/tests/integration/test_insert_into_distributed_sync_async/test.py\n@@ -1,4 +1,3 @@\n-#!/usr/bin/env python2\n import os\n import sys\n from contextlib import contextmanager\n@@ -119,6 +118,6 @@ def test_async_inserts_into_local_shard(started_cluster):\n \n if __name__ == '__main__':\n     with contextmanager(started_cluster)() as cluster:\n-        for name, instance in cluster.instances.items():\n-            print name, instance.ip_address\n-        raw_input(\"Cluster created, press any key to destroy...\")\n+        for name, instance in list(cluster.instances.items()):\n+            print(name, instance.ip_address)\n+        input(\"Cluster created, press any key to destroy...\")\ndiff --git a/tests/integration/test_live_view_over_distributed/test.py b/tests/integration/test_live_view_over_distributed/test.py\nindex 67ff4d8dfe7c..a21eeb772e55 100644\n--- a/tests/integration/test_live_view_over_distributed/test.py\n+++ b/tests/integration/test_live_view_over_distributed/test.py\n@@ -1,4 +1,4 @@\n-from __future__ import print_function\n+\n \n import sys\n \n@@ -7,6 +7,8 @@\n from helpers.uclient import client, prompt, end_of_block\n \n cluster = ClickHouseCluster(__file__)\n+# log = sys.stdout\n+log = None\n \n NODES = {'node' + str(i): cluster.add_instance(\n     'node' + str(i),\n@@ -55,7 +57,7 @@ def started_cluster():\n         cluster.shutdown()\n \n \n-@pytest.mark.parametrize(\"node\", NODES.values()[:1])\n+@pytest.mark.parametrize(\"node\", list(NODES.values())[:1])\n @pytest.mark.parametrize(\"source\", [\"lv_over_distributed_table\"])\n class TestLiveViewOverDistributedSuite:\n     def test_select_with_order_by_node(self, started_cluster, node, source):\n@@ -87,7 +89,6 @@ def test_select_sum(self, started_cluster, node, source):\n                == \"22\\n\"\n \n     def test_watch_live_view_order_by_node(self, started_cluster, node, source):\n-        log = sys.stdout\n         command = \" \".join(node.client.command)\n         args = dict(log=log, command=command)\n \n@@ -130,7 +131,6 @@ def test_watch_live_view_order_by_node(self, started_cluster, node, source):\n             client1.expect('\"node3\",3,3,3')\n \n     def test_watch_live_view_order_by_key(self, started_cluster, node, source):\n-        log = sys.stdout\n         command = \" \".join(node.client.command)\n         args = dict(log=log, command=command)\n \n@@ -173,7 +173,6 @@ def test_watch_live_view_order_by_key(self, started_cluster, node, source):\n             client1.expect('\"node3\",3,3,3')\n \n     def test_watch_live_view_group_by_node(self, started_cluster, node, source):\n-        log = sys.stdout\n         command = \" \".join(node.client.command)\n         args = dict(log=log, command=command)\n \n@@ -208,7 +207,6 @@ def test_watch_live_view_group_by_node(self, started_cluster, node, source):\n             client1.expect('\"node3\",3,3')\n \n     def test_watch_live_view_group_by_key(self, started_cluster, node, source):\n-        log = sys.stdout\n         command = \" \".join(node.client.command)\n         args = dict(log=log, command=command)\n         sep = ' \\xe2\\x94\\x82'\n@@ -245,7 +243,6 @@ def test_watch_live_view_group_by_key(self, started_cluster, node, source):\n             client1.expect('3,3,3')\n \n     def test_watch_live_view_sum(self, started_cluster, node, source):\n-        log = sys.stdout\n         command = \" \".join(node.client.command)\n         args = dict(log=log, command=command)\n \ndiff --git a/tests/integration/test_materialize_mysql_database/materialize_with_ddl.py b/tests/integration/test_materialize_mysql_database/materialize_with_ddl.py\nindex 813e72fe7a7e..3990f7dbd333 100644\n--- a/tests/integration/test_materialize_mysql_database/materialize_with_ddl.py\n+++ b/tests/integration/test_materialize_mysql_database/materialize_with_ddl.py\n@@ -11,7 +11,7 @@ def check_query(clickhouse_node, query, result_set, retry_count=3, interval_seco\n         if result_set == lastest_result:\n             return\n \n-        print lastest_result\n+        print(lastest_result)\n         time.sleep(interval_seconds)\n \n     assert lastest_result == result_set\ndiff --git a/tests/integration/test_materialize_mysql_database/test.py b/tests/integration/test_materialize_mysql_database/test.py\nindex 81a69dd7c543..237df999c62a 100644\n--- a/tests/integration/test_materialize_mysql_database/test.py\n+++ b/tests/integration/test_materialize_mysql_database/test.py\n@@ -6,7 +6,7 @@\n import pytest\n from helpers.cluster import ClickHouseCluster, get_docker_compose_path\n \n-import materialize_with_ddl\n+from . import materialize_with_ddl\n \n DOCKER_COMPOSE_PATH = get_docker_compose_path()\n \n@@ -50,10 +50,10 @@ def wait_mysql_to_start(self, timeout=60):\n         while time.time() - start < timeout:\n             try:\n                 self.alloc_connection()\n-                print \"Mysql Started\"\n+                print(\"Mysql Started\")\n                 return\n             except Exception as ex:\n-                print \"Can't connect to MySQL \" + str(ex)\n+                print(\"Can't connect to MySQL \" + str(ex))\n                 time.sleep(0.5)\n \n         subprocess.check_call(['docker-compose', 'ps', '--services', 'all'])\n@@ -119,8 +119,8 @@ def test_materialize_database_ddl_with_mysql_5_7(started_cluster, started_mysql_\n         materialize_with_ddl.alter_modify_column_with_materialize_mysql_database(clickhouse_node, started_mysql_5_7,\n                                                                                  \"mysql1\")\n     except:\n-        print(clickhouse_node.query(\n-            \"select '\\n', thread_id, query_id, arrayStringConcat(arrayMap(x -> concat(demangle(addressToSymbol(x)), '\\n    ', addressToLine(x)), trace), '\\n') AS sym from system.stack_trace format TSVRaw\"))\n+        print((clickhouse_node.query(\n+            \"select '\\n', thread_id, query_id, arrayStringConcat(arrayMap(x -> concat(demangle(addressToSymbol(x)), '\\n    ', addressToLine(x)), trace), '\\n') AS sym from system.stack_trace format TSVRaw\")))\n         raise\n \n \ndiff --git a/tests/integration/test_max_http_connections_for_replication/test.py b/tests/integration/test_max_http_connections_for_replication/test.py\nindex 5ef45c2a893a..2dc4e2a8810c 100644\n--- a/tests/integration/test_max_http_connections_for_replication/test.py\n+++ b/tests/integration/test_max_http_connections_for_replication/test.py\n@@ -44,12 +44,12 @@ def start_small_cluster():\n \n def test_single_endpoint_connections_count(start_small_cluster):\n     def task(count):\n-        print(\"Inserting ten times from {}\".format(count))\n-        for i in xrange(count, count + 10):\n+        print((\"Inserting ten times from {}\".format(count)))\n+        for i in range(count, count + 10):\n             node1.query(\"insert into test_table values ('2017-06-16', {}, 0)\".format(i))\n \n     p = Pool(10)\n-    p.map(task, xrange(0, 100, 10))\n+    p.map(task, range(0, 100, 10))\n \n     assert_eq_with_retry(node1, \"select count() from test_table\", \"100\")\n     assert_eq_with_retry(node2, \"select count() from test_table\", \"100\")\n@@ -97,17 +97,17 @@ def start_big_cluster():\n \n def test_multiple_endpoint_connections_count(start_big_cluster):\n     def task(count):\n-        print(\"Inserting ten times from {}\".format(count))\n+        print((\"Inserting ten times from {}\".format(count)))\n         if (count / 10) % 2 == 1:\n             node = node3\n         else:\n             node = node4\n \n-        for i in xrange(count, count + 10):\n+        for i in range(count, count + 10):\n             node.query(\"insert into test_table values ('2017-06-16', {}, 0)\".format(i))\n \n     p = Pool(10)\n-    p.map(task, xrange(0, 100, 10))\n+    p.map(task, range(0, 100, 10))\n \n     assert_eq_with_retry(node3, \"select count() from test_table\", \"100\")\n     assert_eq_with_retry(node4, \"select count() from test_table\", \"100\")\ndiff --git a/tests/integration/test_merge_table_over_distributed/test.py b/tests/integration/test_merge_table_over_distributed/test.py\nindex 2e73bd09ded2..ab2948671266 100644\n--- a/tests/integration/test_merge_table_over_distributed/test.py\n+++ b/tests/integration/test_merge_table_over_distributed/test.py\n@@ -68,6 +68,6 @@ def test_select_table_name_from_merge_over_distributed(started_cluster):\n \n if __name__ == '__main__':\n     with contextmanager(started_cluster)() as cluster:\n-        for name, instance in cluster.instances.items():\n-            print name, instance.ip_address\n-        raw_input(\"Cluster created, press any key to destroy...\")\n+        for name, instance in list(cluster.instances.items()):\n+            print(name, instance.ip_address)\n+        input(\"Cluster created, press any key to destroy...\")\ndiff --git a/tests/integration/test_multiple_disks/test.py b/tests/integration/test_multiple_disks/test.py\nindex d12c7f7b3575..5058bcf368ed 100644\n--- a/tests/integration/test_multiple_disks/test.py\n+++ b/tests/integration/test_multiple_disks/test.py\n@@ -954,7 +954,7 @@ def test_mutate_to_another_disk(start_cluster, name, engine):\n         if node1.query(\"SELECT latest_fail_reason FROM system.mutations WHERE table = '{}'\".format(name)) == \"\":\n             assert node1.query(\"SELECT sum(endsWith(s1, 'x')) FROM {}\".format(name)) == \"25\\n\"\n         else:  # mutation failed, let's try on another disk\n-            print \"Mutation failed\"\n+            print(\"Mutation failed\")\n             node1.query(\"OPTIMIZE TABLE {} FINAL\".format(name))\n             node1.query(\"ALTER TABLE {} UPDATE s1 = concat(s1, 'x') WHERE 1\".format(name))\n             retry = 20\n@@ -1114,7 +1114,7 @@ def test_download_appropriate_disk(start_cluster):\n \n         for _ in range(10):\n             try:\n-                print \"Syncing replica\"\n+                print(\"Syncing replica\")\n                 node2.query(\"SYSTEM SYNC REPLICA replicated_table_for_download\")\n                 break\n             except:\ndiff --git a/tests/integration/test_mutations_hardlinks/test.py b/tests/integration/test_mutations_hardlinks/test.py\nindex b1e538b123b1..7ac7fe12108b 100644\n--- a/tests/integration/test_mutations_hardlinks/test.py\n+++ b/tests/integration/test_mutations_hardlinks/test.py\n@@ -122,7 +122,7 @@ def mutate():\n             if int(result.strip()) == 2:\n                 break\n         except:\n-            print \"Result\", result\n+            print(\"Result\", result)\n             pass\n \n         time.sleep(0.5)\ndiff --git a/tests/integration/test_mutations_with_merge_tree/test.py b/tests/integration/test_mutations_with_merge_tree/test.py\nindex 25bc0df8e7cf..65eaee215777 100644\n--- a/tests/integration/test_mutations_with_merge_tree/test.py\n+++ b/tests/integration/test_mutations_with_merge_tree/test.py\n@@ -44,8 +44,8 @@ def get_done_mutations(instance):\n             all_done = True\n             break\n \n-    print instance_test_mutations.query(\n-        \"SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations_with_ast_elements' SETTINGS force_index_by_date = 0, force_primary_key = 0 FORMAT TSVWithNames\")\n+    print(instance_test_mutations.query(\n+        \"SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations_with_ast_elements' SETTINGS force_index_by_date = 0, force_primary_key = 0 FORMAT TSVWithNames\"))\n     assert all_done\n \n \ndiff --git a/tests/integration/test_mysql_database_engine/test.py b/tests/integration/test_mysql_database_engine/test.py\nindex a8824b383abc..23424c550b20 100644\n--- a/tests/integration/test_mysql_database_engine/test.py\n+++ b/tests/integration/test_mysql_database_engine/test.py\n@@ -44,7 +44,7 @@ def execute(query):\n                     res = \"\\n\".join(rows)\n                 return res\n \n-            if isinstance(execution_query, (str, bytes, unicode)):\n+            if isinstance(execution_query, (str, bytes)):\n                 return execute(execution_query)\n             else:\n                 return [execute(q) for q in execution_query]\n@@ -256,7 +256,7 @@ def do_execute(query):\n             res = node.query(query, **kwargs)\n             return res if isinstance(res, int) else res.rstrip('\\n\\r')\n \n-        if isinstance(query, (str, bytes, unicode)):\n+        if isinstance(query, (str, bytes)):\n             return do_execute(query)\n         else:\n             return [do_execute(q) for q in query]\ndiff --git a/tests/integration/test_mysql_protocol/test.py b/tests/integration/test_mysql_protocol/test.py\nindex 3e737dc26447..04cbef59af7a 100644\n--- a/tests/integration/test_mysql_protocol/test.py\n+++ b/tests/integration/test_mysql_protocol/test.py\n@@ -98,7 +98,7 @@ def test_mysql_client(mysql_client, server_address):\n         -e \"SELECT 1;\"\n     '''.format(host=server_address, port=server_port), demux=True)\n \n-    assert stdout == '\\n'.join(['1', '1', ''])\n+    assert stdout.decode() == '\\n'.join(['1', '1', ''])\n \n     code, (stdout, stderr) = mysql_client.exec_run('''\n         mysql --protocol tcp -h {host} -P {port} default -u default --password=123\n@@ -106,13 +106,13 @@ def test_mysql_client(mysql_client, server_address):\n         -e \"SELECT '\u0442\u0435\u0441\u0442' as b;\"\n     '''.format(host=server_address, port=server_port), demux=True)\n \n-    assert stdout == '\\n'.join(['a', '1', 'b', '\u0442\u0435\u0441\u0442', ''])\n+    assert stdout.decode() == '\\n'.join(['a', '1', 'b', '\u0442\u0435\u0441\u0442', ''])\n \n     code, (stdout, stderr) = mysql_client.exec_run('''\n         mysql --protocol tcp -h {host} -P {port} default -u default --password=abc -e \"select 1 as a;\"\n     '''.format(host=server_address, port=server_port), demux=True)\n \n-    assert stderr == 'mysql: [Warning] Using a password on the command line interface can be insecure.\\n' \\\n+    assert stderr.decode() == 'mysql: [Warning] Using a password on the command line interface can be insecure.\\n' \\\n                      'ERROR 516 (00000): default: Authentication failed: password is incorrect or there is no user with such name\\n'\n \n     code, (stdout, stderr) = mysql_client.exec_run('''\n@@ -122,8 +122,8 @@ def test_mysql_client(mysql_client, server_address):\n         -e \"use system2;\"\n     '''.format(host=server_address, port=server_port), demux=True)\n \n-    assert stdout == 'count()\\n1\\n'\n-    assert stderr[0:182] == \"mysql: [Warning] Using a password on the command line interface can be insecure.\\n\" \\\n+    assert stdout.decode() == 'count()\\n1\\n'\n+    assert stderr[0:182].decode() == \"mysql: [Warning] Using a password on the command line interface can be insecure.\\n\" \\\n                             \"ERROR 81 (00000) at line 1: Code: 81, e.displayText() = DB::Exception: Database system2 doesn't exist\"\n \n     code, (stdout, stderr) = mysql_client.exec_run('''\n@@ -140,7 +140,7 @@ def test_mysql_client(mysql_client, server_address):\n         -e \"SELECT * FROM tmp ORDER BY tmp_column;\"\n     '''.format(host=server_address, port=server_port), demux=True)\n \n-    assert stdout == '\\n'.join(['column', '0', '0', '1', '1', '5', '5', 'tmp_column', '0', '1', ''])\n+    assert stdout.decode() == '\\n'.join(['column', '0', '0', '1', '1', '5', '5', 'tmp_column', '0', '1', ''])\n \n \n def test_mysql_client_exception(mysql_client, server_address):\n@@ -150,7 +150,7 @@ def test_mysql_client_exception(mysql_client, server_address):\n         -e \"CREATE TABLE default.t1_remote_mysql AS mysql('127.0.0.1:10086','default','t1_local','default','');\"\n     '''.format(host=server_address, port=server_port), demux=True)\n \n-    assert stderr[0:266] == \"mysql: [Warning] Using a password on the command line interface can be insecure.\\n\" \\\n+    assert stderr[0:266].decode() == \"mysql: [Warning] Using a password on the command line interface can be insecure.\\n\" \\\n                             \"ERROR 1000 (00000) at line 1: Poco::Exception. Code: 1000, e.code() = 2002, e.displayText() = mysqlxx::ConnectionFailed: Can't connect to MySQL server on '127.0.0.1' (115) ((nullptr):0)\"\n \n \n@@ -188,14 +188,14 @@ def test_mysql_replacement_query(mysql_client, server_address):\n         --password=123 -e \"select database();\"\n     '''.format(host=server_address, port=server_port), demux=True)\n     assert code == 0\n-    assert stdout == 'database()\\ndefault\\n'\n+    assert stdout.decode() == 'database()\\ndefault\\n'\n \n     code, (stdout, stderr) = mysql_client.exec_run('''\n         mysql --protocol tcp -h {host} -P {port} default -u default\n         --password=123 -e \"select DATABASE();\"\n     '''.format(host=server_address, port=server_port), demux=True)\n     assert code == 0\n-    assert stdout == 'DATABASE()\\ndefault\\n'\n+    assert stdout.decode() == 'DATABASE()\\ndefault\\n'\n \n \n def test_mysql_explain(mysql_client, server_address):\n@@ -238,6 +238,7 @@ def test_mysql_federated(mysql_server, server_address):\n         node.query('''INSERT INTO mysql_federated.test VALUES (0), (1), (5)''', settings={\"password\": \"123\"})\n \n         def check_retryable_error_in_stderr(stderr):\n+            stderr = stderr.decode()\n             return (\"Can't connect to local MySQL server through socket\" in stderr\n                     or \"MySQL server has gone away\" in stderr\n                     or \"Server shutdown in progress\" in stderr)\n@@ -252,8 +253,8 @@ def check_retryable_error_in_stderr(stderr):\n         '''.format(host=server_address, port=server_port), demux=True)\n \n         if code != 0:\n-            print(\"stdout\", stdout)\n-            print(\"stderr\", stderr)\n+            print((\"stdout\", stdout))\n+            print((\"stderr\", stderr))\n             if try_num + 1 < retries and check_retryable_error_in_stderr(stderr):\n                 time.sleep(1)\n                 continue\n@@ -266,14 +267,14 @@ def check_retryable_error_in_stderr(stderr):\n         '''.format(host=server_address, port=server_port), demux=True)\n \n         if code != 0:\n-            print(\"stdout\", stdout)\n-            print(\"stderr\", stderr)\n+            print((\"stdout\", stdout))\n+            print((\"stderr\", stderr))\n             if try_num + 1 < retries and check_retryable_error_in_stderr(stderr):\n                 time.sleep(1)\n                 continue\n         assert code == 0\n \n-        assert stdout == '\\n'.join(['col', '0', '1', '5', ''])\n+        assert stdout.decode() == '\\n'.join(['col', '0', '1', '5', ''])\n \n         code, (stdout, stderr) = mysql_server.exec_run('''\n             mysql\n@@ -282,14 +283,14 @@ def check_retryable_error_in_stderr(stderr):\n         '''.format(host=server_address, port=server_port), demux=True)\n \n         if code != 0:\n-            print(\"stdout\", stdout)\n-            print(\"stderr\", stderr)\n+            print((\"stdout\", stdout))\n+            print((\"stderr\", stderr))\n             if try_num + 1 < retries and check_retryable_error_in_stderr(stderr):\n                 time.sleep(1)\n                 continue\n         assert code == 0\n \n-        assert stdout == '\\n'.join(['col', '0', '0', '1', '1', '5', '5', ''])\n+        assert stdout.decode() == '\\n'.join(['col', '0', '0', '1', '1', '5', '5', ''])\n \n \n def test_mysql_set_variables(mysql_client, server_address):\n@@ -362,7 +363,7 @@ def test_python_client(server_address):\n \n def test_golang_client(server_address, golang_container):\n     # type: (str, Container) -> None\n-    with open(os.path.join(SCRIPT_DIR, 'golang.reference')) as fp:\n+    with open(os.path.join(SCRIPT_DIR, 'golang.reference'), 'rb') as fp:\n         reference = fp.read()\n \n     code, (stdout, stderr) = golang_container.exec_run(\n@@ -370,7 +371,7 @@ def test_golang_client(server_address, golang_container):\n         'abc'.format(host=server_address, port=server_port), demux=True)\n \n     assert code == 1\n-    assert stderr == \"Error 81: Database abc doesn't exist\\n\"\n+    assert stderr.decode() == \"Error 81: Database abc doesn't exist\\n\"\n \n     code, (stdout, stderr) = golang_container.exec_run(\n         './main --host {host} --port {port} --user default --password 123 --database '\n@@ -391,31 +392,31 @@ def test_php_client(server_address, php_container):\n     code, (stdout, stderr) = php_container.exec_run(\n         'php -f test.php {host} {port} default 123'.format(host=server_address, port=server_port), demux=True)\n     assert code == 0\n-    assert stdout == 'tables\\n'\n+    assert stdout.decode() == 'tables\\n'\n \n     code, (stdout, stderr) = php_container.exec_run(\n         'php -f test_ssl.php {host} {port} default 123'.format(host=server_address, port=server_port), demux=True)\n     assert code == 0\n-    assert stdout == 'tables\\n'\n+    assert stdout.decode() == 'tables\\n'\n \n     code, (stdout, stderr) = php_container.exec_run(\n         'php -f test.php {host} {port} user_with_double_sha1 abacaba'.format(host=server_address, port=server_port),\n         demux=True)\n     assert code == 0\n-    assert stdout == 'tables\\n'\n+    assert stdout.decode() == 'tables\\n'\n \n     code, (stdout, stderr) = php_container.exec_run(\n         'php -f test_ssl.php {host} {port} user_with_double_sha1 abacaba'.format(host=server_address, port=server_port),\n         demux=True)\n     assert code == 0\n-    assert stdout == 'tables\\n'\n+    assert stdout.decode() == 'tables\\n'\n \n \n def test_mysqljs_client(server_address, nodejs_container):\n     code, (_, stderr) = nodejs_container.exec_run(\n         'node test.js {host} {port} user_with_sha256 abacaba'.format(host=server_address, port=server_port), demux=True)\n     assert code == 1\n-    assert 'MySQL is requesting the sha256_password authentication method, which is not supported.' in stderr\n+    assert 'MySQL is requesting the sha256_password authentication method, which is not supported.' in stderr.decode()\n \n     code, (_, stderr) = nodejs_container.exec_run(\n         'node test.js {host} {port} user_with_empty_password \"\"'.format(host=server_address, port=server_port),\n@@ -449,21 +450,21 @@ def test_java_client(server_address, java_container):\n         'java JavaConnectorTest --host {host} --port {port} --user user_with_empty_password --database '\n         'default'.format(host=server_address, port=server_port), demux=True)\n     assert code == 0\n-    assert stdout == reference\n+    assert stdout.decode() == reference\n \n     # non-empty password passed.\n     code, (stdout, stderr) = java_container.exec_run(\n         'java JavaConnectorTest --host {host} --port {port} --user default --password 123 --database '\n         'default'.format(host=server_address, port=server_port), demux=True)\n     assert code == 0\n-    assert stdout == reference\n+    assert stdout.decode() == reference\n \n     # double-sha1 password passed.\n     code, (stdout, stderr) = java_container.exec_run(\n         'java JavaConnectorTest --host {host} --port {port} --user user_with_double_sha1 --password abacaba  --database '\n         'default'.format(host=server_address, port=server_port), demux=True)\n     assert code == 0\n-    assert stdout == reference\n+    assert stdout.decode() == reference\n \n \n def test_types(server_address):\ndiff --git a/tests/integration/test_no_local_metadata_node/test.py b/tests/integration/test_no_local_metadata_node/test.py\nindex ae69f5e1384b..f976cc005bd9 100644\n--- a/tests/integration/test_no_local_metadata_node/test.py\n+++ b/tests/integration/test_no_local_metadata_node/test.py\n@@ -47,7 +47,7 @@ def test_table_start_without_metadata(start_cluster):\n \n     node1.query(\"DETACH TABLE test\")\n \n-    zk_cli.set(\"/clickhouse/table/test_table/replicas/1/metadata\", \"\")\n+    zk_cli.set(\"/clickhouse/table/test_table/replicas/1/metadata\", b\"\")\n \n     node1.query(\"ATTACH TABLE test\")\n \ndiff --git a/tests/integration/test_non_default_compression/test.py b/tests/integration/test_non_default_compression/test.py\nindex 4706d8efbdde..03210e47081a 100644\n--- a/tests/integration/test_non_default_compression/test.py\n+++ b/tests/integration/test_non_default_compression/test.py\n@@ -82,7 +82,7 @@ def test_preconfigured_custom_codec(start_cluster):\n     assert node3.query(\n         \"SELECT max(length(data)) from compression_codec_multiple_with_key GROUP BY data ORDER BY max(length(data)) DESC LIMIT 1\") == \"10000\\n\"\n \n-    for i in xrange(10):\n+    for i in range(10):\n         node3.query(\n             \"INSERT INTO compression_codec_multiple_with_key VALUES(toDate('2018-10-12'), {}, '{}', 88.88)\".format(i,\n                                                                                                                    ''.join(\ndiff --git a/tests/integration/test_odbc_interaction/test.py b/tests/integration/test_odbc_interaction/test.py\nindex f527b4cc66e2..028137cef125 100644\n--- a/tests/integration/test_odbc_interaction/test.py\n+++ b/tests/integration/test_odbc_interaction/test.py\n@@ -60,7 +60,7 @@ def started_cluster():\n         cluster.start()\n         sqlite_db = node1.odbc_drivers[\"SQLite3\"][\"Database\"]\n \n-        print \"sqlite data received\"\n+        print(\"sqlite data received\")\n         node1.exec_in_container(\n             [\"bash\", \"-c\", \"echo 'CREATE TABLE t1(x INTEGER PRIMARY KEY ASC, y, z);' | sqlite3 {}\".format(sqlite_db)],\n             privileged=True, user='root')\n@@ -73,18 +73,18 @@ def started_cluster():\n         node1.exec_in_container(\n             [\"bash\", \"-c\", \"echo 'CREATE TABLE t4(X INTEGER PRIMARY KEY ASC, Y, Z);' | sqlite3 {}\".format(sqlite_db)],\n             privileged=True, user='root')\n-        print \"sqlite tables created\"\n+        print(\"sqlite tables created\")\n         mysql_conn = get_mysql_conn()\n-        print \"mysql connection received\"\n+        print(\"mysql connection received\")\n         ## create mysql db and table\n         create_mysql_db(mysql_conn, 'clickhouse')\n-        print \"mysql database created\"\n+        print(\"mysql database created\")\n \n         postgres_conn = get_postgres_conn()\n-        print \"postgres connection received\"\n+        print(\"postgres connection received\")\n \n         create_postgres_db(postgres_conn, 'clickhouse')\n-        print \"postgres db created\"\n+        print(\"postgres db created\")\n \n         cursor = postgres_conn.cursor()\n         cursor.execute(\n@@ -259,7 +259,7 @@ def test_postgres_odbc_hached_dictionary_no_tty_pipe_overflow(started_cluster):\n     conn = get_postgres_conn()\n     cursor = conn.cursor()\n     cursor.execute(\"insert into clickhouse.test_table values(3, 'xxx')\")\n-    for i in xrange(100):\n+    for i in range(100):\n         try:\n             node1.query(\"system reload dictionary postgres_odbc_hashed\", timeout=5)\n         except Exception as ex:\ndiff --git a/tests/integration/test_partition/test.py b/tests/integration/test_partition/test.py\nindex 679c6fb8c5b5..b5facb5f4b2b 100644\n--- a/tests/integration/test_partition/test.py\n+++ b/tests/integration/test_partition/test.py\n@@ -52,7 +52,7 @@ def partition_complex_assert_columns_txt():\n     for part_name in parts.lines:\n         path_to_columns = path_to_parts + part_name + '/columns.txt'\n         # 2 header lines + 3 columns\n-        assert exec_bash('cat {} | wc -l'.format(path_to_columns)) == u'5\\n'\n+        assert exec_bash('cat {} | wc -l'.format(path_to_columns)) == '5\\n'\n \n \n def partition_complex_assert_checksums():\n@@ -145,7 +145,7 @@ def cannot_attach_active_part_table(started_cluster):\n \n def test_cannot_attach_active_part(cannot_attach_active_part_table):\n     error = instance.client.query_and_get_error(\"ALTER TABLE test.attach_active ATTACH PART '../1_2_2_0'\")\n-    print error\n+    print(error)\n     assert 0 <= error.find('Invalid part name')\n \n     res = q(\"SElECT name FROM system.parts WHERE table='attach_active' AND database='test' ORDER BY name\")\ndiff --git a/tests/integration/test_parts_delete_zookeeper/test.py b/tests/integration/test_parts_delete_zookeeper/test.py\nindex 7489b2411f93..8a4aafaa55ca 100644\n--- a/tests/integration/test_parts_delete_zookeeper/test.py\n+++ b/tests/integration/test_parts_delete_zookeeper/test.py\n@@ -26,7 +26,7 @@ def start_cluster():\n         yield cluster\n \n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     finally:\n         cluster.shutdown()\ndiff --git a/tests/integration/test_postgresql_protocol/test.py b/tests/integration/test_postgresql_protocol/test.py\nindex 513bb75fcab1..52c911cb9391 100644\n--- a/tests/integration/test_postgresql_protocol/test.py\n+++ b/tests/integration/test_postgresql_protocol/test.py\n@@ -1,6 +1,6 @@\n # -*- coding: utf-8 -*-\n \n-from __future__ import print_function\n+\n \n import datetime\n import decimal\n@@ -81,10 +81,10 @@ def test_psql_client(psql_client, server_address):\n     cmd_prefix += \"--no-align --field-separator=' ' \"\n \n     code, (stdout, stderr) = psql_client.exec_run(cmd_prefix + '-c \"SELECT 1 as a\"', demux=True)\n-    assert stdout == '\\n'.join(['a', '1', '(1 row)', ''])\n+    assert stdout.decode() == '\\n'.join(['a', '1', '(1 row)', ''])\n \n     code, (stdout, stderr) = psql_client.exec_run(cmd_prefix + '''-c \"SELECT '\u043a\u043e\u043b\u043e\u043d\u043a\u0430' as a\"''', demux=True)\n-    assert stdout == '\\n'.join(['a', '\u043a\u043e\u043b\u043e\u043d\u043a\u0430', '(1 row)', ''])\n+    assert stdout.decode() == '\\n'.join(['a', '\u043a\u043e\u043b\u043e\u043d\u043a\u0430', '(1 row)', ''])\n \n     code, (stdout, stderr) = psql_client.exec_run(\n         cmd_prefix + '-c ' +\n@@ -98,7 +98,7 @@ def test_psql_client(psql_client, server_address):\n         ''',\n         demux=True\n     )\n-    assert stdout == '\\n'.join(['column', '0', '0', '1', '1', '5', '5', '(6 rows)', ''])\n+    assert stdout.decode() == '\\n'.join(['column', '0', '0', '1', '1', '5', '5', '(6 rows)', ''])\n \n     code, (stdout, stderr) = psql_client.exec_run(\n         cmd_prefix + '-c ' +\n@@ -110,7 +110,7 @@ def test_psql_client(psql_client, server_address):\n         ''',\n         demux=True\n     )\n-    assert stdout == '\\n'.join(['tmp_column', '0', '1', '(2 rows)', ''])\n+    assert stdout.decode() == '\\n'.join(['tmp_column', '0', '1', '(2 rows)', ''])\n \n \n def test_python_client(server_address):\n@@ -157,4 +157,4 @@ def test_java_client(server_address, java_container):\n         'default'.format(host=server_address, port=server_port), demux=True)\n     print(stdout, stderr, file=sys.stderr)\n     assert code == 0\n-    assert stdout == reference\n+    assert stdout.decode() == reference\ndiff --git a/tests/integration/test_prometheus_endpoint/test.py b/tests/integration/test_prometheus_endpoint/test.py\nindex 909dbf139b98..06276803c3d0 100644\n--- a/tests/integration/test_prometheus_endpoint/test.py\n+++ b/tests/integration/test_prometheus_endpoint/test.py\n@@ -1,4 +1,4 @@\n-from __future__ import print_function\n+\n \n import re\n import time\ndiff --git a/tests/integration/test_quota/test.py b/tests/integration/test_quota/test.py\nindex 5d2a4acffe6b..0614150ee071 100644\n--- a/tests/integration/test_quota/test.py\n+++ b/tests/integration/test_quota/test.py\n@@ -15,14 +15,14 @@\n def check_system_quotas(canonical):\n     canonical_tsv = TSV(canonical)\n     r = TSV(instance.query(\"SELECT * FROM system.quotas ORDER BY name\"))\n-    print(\"system_quotas: {},\\ncanonical: {}\".format(r, TSV(canonical_tsv)))\n+    print((\"system_quotas: {},\\ncanonical: {}\".format(r, TSV(canonical_tsv))))\n     assert r == canonical_tsv\n \n \n def system_quota_limits(canonical):\n     canonical_tsv = TSV(canonical)\n     r = TSV(instance.query(\"SELECT * FROM system.quota_limits ORDER BY quota_name, duration\"))\n-    print(\"system_quota_limits: {},\\ncanonical: {}\".format(r, TSV(canonical_tsv)))\n+    print((\"system_quota_limits: {},\\ncanonical: {}\".format(r, TSV(canonical_tsv))))\n     assert r == canonical_tsv\n \n \n@@ -32,7 +32,7 @@ def system_quota_usage(canonical):\n             \"result_bytes, max_result_bytes, read_rows, max_read_rows, read_bytes, max_read_bytes, max_execution_time \" \\\n             \"FROM system.quota_usage ORDER BY duration\"\n     r = TSV(instance.query(query))\n-    print(\"system_quota_usage: {},\\ncanonical: {}\".format(r, TSV(canonical_tsv)))\n+    print((\"system_quota_usage: {},\\ncanonical: {}\".format(r, TSV(canonical_tsv))))\n     assert r == canonical_tsv\n \n \n@@ -42,7 +42,7 @@ def system_quotas_usage(canonical):\n             \"result_bytes, max_result_bytes, read_rows, max_read_rows, read_bytes, max_read_bytes, max_execution_time \" \\\n             \"FROM system.quotas_usage ORDER BY quota_name, quota_key, duration\"\n     r = TSV(instance.query(query))\n-    print(\"system_quotas_usage: {},\\ncanonical: {}\".format(r, TSV(canonical_tsv)))\n+    print((\"system_quotas_usage: {},\\ncanonical: {}\".format(r, TSV(canonical_tsv))))\n     assert r == canonical_tsv\n \n \n@@ -81,18 +81,18 @@ def reset_quotas_and_usage_info():\n def test_quota_from_users_xml():\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", [31556952],\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"]])\n-    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, 1000, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, 1000, 0, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"]])\n+    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, 1000, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, 1000, 0, \"\\\\N\", \"\\\\N\"]])\n     system_quotas_usage(\n-        [[\"myQuota\", \"default\", 1, 31556952, 0, 1000, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, 1000, 0, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 1, 31556952, 0, 1000, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, 1000, 0, \"\\\\N\", \"\\\\N\"]])\n \n     instance.query(\"SELECT * from test_table\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", 31556952, 1, 1000, 0, \"\\N\", 50, \"\\N\", 200, \"\\N\", 50, 1000, 200, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 31556952, 1, 1000, 0, \"\\\\N\", 50, \"\\\\N\", 200, \"\\\\N\", 50, 1000, 200, \"\\\\N\", \"\\\\N\"]])\n \n     instance.query(\"SELECT COUNT() from test_table\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", 31556952, 2, 1000, 0, \"\\N\", 51, \"\\N\", 208, \"\\N\", 50, 1000, 200, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 31556952, 2, 1000, 0, \"\\\\N\", 51, \"\\\\N\", 208, \"\\\\N\", 50, 1000, 200, \"\\\\N\", \"\\\\N\"]])\n \n \n def test_simpliest_quota():\n@@ -102,11 +102,11 @@ def test_simpliest_quota():\n                           \"['default']\", \"[]\"]])\n     system_quota_limits(\"\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\"]])\n \n     instance.query(\"SELECT * from test_table\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\"]])\n \n \n def test_tracking_quota():\n@@ -114,16 +114,16 @@ def test_tracking_quota():\n     copy_quota_xml('tracking.xml')\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", \"[31556952]\",\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\"]])\n-    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\"]])\n+    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", \"\\\\N\"]])\n \n     instance.query(\"SELECT * from test_table\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", 31556952, 1, \"\\N\", 0, \"\\N\", 50, \"\\N\", 200, \"\\N\", 50, \"\\N\", 200, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 31556952, 1, \"\\\\N\", 0, \"\\\\N\", 50, \"\\\\N\", 200, \"\\\\N\", 50, \"\\\\N\", 200, \"\\\\N\", \"\\\\N\"]])\n \n     instance.query(\"SELECT COUNT() from test_table\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", 31556952, 2, \"\\N\", 0, \"\\N\", 51, \"\\N\", 208, \"\\N\", 50, \"\\N\", 200, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 31556952, 2, \"\\\\N\", 0, \"\\\\N\", 51, \"\\\\N\", 208, \"\\\\N\", 50, \"\\\\N\", 200, \"\\\\N\", \"\\\\N\"]])\n \n \n def test_exceed_quota():\n@@ -131,55 +131,55 @@ def test_exceed_quota():\n     copy_quota_xml('tiny_limits.xml')\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", \"[31556952]\",\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1, 1, 1, \"\\N\", 1, \"\\N\", \"\\N\"]])\n-    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, 1, 0, 1, 0, 1, 0, \"\\N\", 0, 1, 0, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1, 1, 1, \"\\\\N\", 1, \"\\\\N\", \"\\\\N\"]])\n+    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, 1, 0, 1, 0, 1, 0, \"\\\\N\", 0, 1, 0, \"\\\\N\", \"\\\\N\"]])\n \n     assert re.search(\"Quota.*has\\ been\\ exceeded\", instance.query_and_get_error(\"SELECT * from test_table\"))\n-    system_quota_usage([[\"myQuota\", \"default\", 31556952, 1, 1, 1, 1, 0, 1, 0, \"\\N\", 50, 1, 0, \"\\N\", \"\\N\"]])\n+    system_quota_usage([[\"myQuota\", \"default\", 31556952, 1, 1, 1, 1, 0, 1, 0, \"\\\\N\", 50, 1, 0, \"\\\\N\", \"\\\\N\"]])\n \n     # Change quota, now the limits are enough to execute queries.\n     copy_quota_xml('normal_limits.xml')\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", \"[31556952]\",\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"]])\n-    system_quota_usage([[\"myQuota\", \"default\", 31556952, 1, 1000, 1, \"\\N\", 0, \"\\N\", 0, \"\\N\", 50, 1000, 0, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"]])\n+    system_quota_usage([[\"myQuota\", \"default\", 31556952, 1, 1000, 1, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 50, 1000, 0, \"\\\\N\", \"\\\\N\"]])\n \n     instance.query(\"SELECT * from test_table\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", 31556952, 2, 1000, 1, \"\\N\", 50, \"\\N\", 200, \"\\N\", 100, 1000, 200, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 31556952, 2, 1000, 1, \"\\\\N\", 50, \"\\\\N\", 200, \"\\\\N\", 100, 1000, 200, \"\\\\N\", \"\\\\N\"]])\n \n \n def test_add_remove_interval():\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", [31556952],\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"]])\n-    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, 1000, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, 1000, 0, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"]])\n+    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, 1000, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, 1000, 0, \"\\\\N\", \"\\\\N\"]])\n \n     # Add interval.\n     copy_quota_xml('two_intervals.xml')\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\",\n                           \"[31556952,63113904]\", 0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"],\n-                         [\"myQuota\", 63113904, 1, \"\\N\", \"\\N\", \"\\N\", 30000, \"\\N\", 20000, 120]])\n-    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, 1000, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, 1000, 0, \"\\N\", \"\\N\"],\n-                        [\"myQuota\", \"default\", 63113904, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, 30000, 0, \"\\N\", 0, 20000, 120]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"],\n+                         [\"myQuota\", 63113904, 1, \"\\\\N\", \"\\\\N\", \"\\\\N\", 30000, \"\\\\N\", 20000, 120]])\n+    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, 1000, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, 1000, 0, \"\\\\N\", \"\\\\N\"],\n+                        [\"myQuota\", \"default\", 63113904, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, 30000, 0, \"\\\\N\", 0, 20000, 120]])\n \n     instance.query(\"SELECT * from test_table\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", 31556952, 1, 1000, 0, \"\\N\", 50, \"\\N\", 200, \"\\N\", 50, 1000, 200, \"\\N\", \"\\N\"],\n-         [\"myQuota\", \"default\", 63113904, 1, \"\\N\", 0, \"\\N\", 50, \"\\N\", 200, 30000, 50, \"\\N\", 200, 20000, 120]])\n+        [[\"myQuota\", \"default\", 31556952, 1, 1000, 0, \"\\\\N\", 50, \"\\\\N\", 200, \"\\\\N\", 50, 1000, 200, \"\\\\N\", \"\\\\N\"],\n+         [\"myQuota\", \"default\", 63113904, 1, \"\\\\N\", 0, \"\\\\N\", 50, \"\\\\N\", 200, 30000, 50, \"\\\\N\", 200, 20000, 120]])\n \n     # Remove interval.\n     copy_quota_xml('normal_limits.xml')\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", [31556952],\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"]])\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", 31556952, 1, 1000, 0, \"\\N\", 50, \"\\N\", 200, \"\\N\", 50, 1000, 200, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 31556952, 1, 1000, 0, \"\\\\N\", 50, \"\\\\N\", 200, \"\\\\N\", 50, 1000, 200, \"\\\\N\", \"\\\\N\"]])\n \n     instance.query(\"SELECT * from test_table\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", 31556952, 2, 1000, 0, \"\\N\", 100, \"\\N\", 400, \"\\N\", 100, 1000, 400, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 31556952, 2, 1000, 0, \"\\\\N\", 100, \"\\\\N\", 400, \"\\\\N\", 100, 1000, 400, \"\\\\N\", \"\\\\N\"]])\n \n     # Remove all intervals.\n     copy_quota_xml('simpliest.xml')\n@@ -187,26 +187,26 @@ def test_add_remove_interval():\n                           \"['default']\", \"[]\"]])\n     system_quota_limits(\"\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\"]])\n \n     instance.query(\"SELECT * from test_table\")\n     system_quota_usage(\n-        [[\"myQuota\", \"default\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\"]])\n \n     # Add one interval back.\n     copy_quota_xml('normal_limits.xml')\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", [31556952],\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"]])\n-    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, 1000, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, 1000, 0, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"]])\n+    system_quota_usage([[\"myQuota\", \"default\", 31556952, 0, 1000, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, 1000, 0, \"\\\\N\", \"\\\\N\"]])\n \n \n def test_add_remove_quota():\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", [31556952],\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"]])\n     system_quotas_usage(\n-        [[\"myQuota\", \"default\", 1, 31556952, 0, 1000, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, 1000, 0, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 1, 31556952, 0, 1000, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, 1000, 0, \"\\\\N\", \"\\\\N\"]])\n \n     # Add quota.\n     copy_quota_xml('two_quotas.xml')\n@@ -214,19 +214,19 @@ def test_add_remove_quota():\n                           0, \"['default']\", \"[]\"],\n                          [\"myQuota2\", \"4590510c-4d13-bf21-ec8a-c2187b092e73\", \"users.xml\", \"['client_key','user_name']\",\n                           \"[3600,2629746]\", 0, \"[]\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"],\n-                         [\"myQuota2\", 3600, 1, \"\\N\", \"\\N\", 4000, 400000, 4000, 400000, 60],\n-                         [\"myQuota2\", 2629746, 0, \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", 1800]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"],\n+                         [\"myQuota2\", 3600, 1, \"\\\\N\", \"\\\\N\", 4000, 400000, 4000, 400000, 60],\n+                         [\"myQuota2\", 2629746, 0, \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", 1800]])\n     system_quotas_usage(\n-        [[\"myQuota\", \"default\", 1, 31556952, 0, 1000, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, 1000, 0, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 1, 31556952, 0, 1000, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, 1000, 0, \"\\\\N\", \"\\\\N\"]])\n \n     # Drop quota.\n     copy_quota_xml('normal_limits.xml')\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", \"[31556952]\",\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"]])\n     system_quotas_usage(\n-        [[\"myQuota\", \"default\", 1, 31556952, 0, 1000, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, 1000, 0, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 1, 31556952, 0, 1000, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, 1000, 0, \"\\\\N\", \"\\\\N\"]])\n \n     # Drop all quotas.\n     copy_quota_xml('no_quotas.xml')\n@@ -238,15 +238,15 @@ def test_add_remove_quota():\n     copy_quota_xml('normal_limits.xml')\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", \"[31556952]\",\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"]])\n     system_quotas_usage(\n-        [[\"myQuota\", \"default\", 1, 31556952, 0, 1000, 0, \"\\N\", 0, \"\\N\", 0, \"\\N\", 0, 1000, 0, \"\\N\", \"\\N\"]])\n+        [[\"myQuota\", \"default\", 1, 31556952, 0, 1000, 0, \"\\\\N\", 0, \"\\\\N\", 0, \"\\\\N\", 0, 1000, 0, \"\\\\N\", \"\\\\N\"]])\n \n \n def test_reload_users_xml_by_timer():\n     check_system_quotas([[\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", \"['user_name']\", \"[31556952]\",\n                           0, \"['default']\", \"[]\"]])\n-    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\N\", \"\\N\", \"\\N\", 1000, \"\\N\", \"\\N\"]])\n+    system_quota_limits([[\"myQuota\", 31556952, 0, 1000, \"\\\\N\", \"\\\\N\", \"\\\\N\", 1000, \"\\\\N\", \"\\\\N\"]])\n \n     time.sleep(1)  # The modification time of the 'quota.xml' file should be different,\n     # because config files are reload by timer only when the modification time is changed.\n@@ -255,7 +255,7 @@ def test_reload_users_xml_by_timer():\n         [\"myQuota\", \"e651da9c-a748-8703-061a-7e5e5096dae7\", \"users.xml\", ['user_name'], \"[31556952]\", 0, \"['default']\",\n          \"[]\"]])\n     assert_eq_with_retry(instance, \"SELECT * FROM system.quota_limits\",\n-                         [[\"myQuota\", 31556952, 0, 1, 1, 1, \"\\N\", 1, \"\\N\", \"\\N\"]])\n+                         [[\"myQuota\", 31556952, 0, 1, 1, 1, \"\\\\N\", 1, \"\\\\N\", \"\\\\N\"]])\n \n \n def test_dcl_introspection():\ndiff --git a/tests/integration/test_random_inserts/test.py b/tests/integration/test_random_inserts/test.py\nindex f43581b64828..a06649dba525 100644\n--- a/tests/integration/test_random_inserts/test.py\n+++ b/tests/integration/test_random_inserts/test.py\n@@ -55,7 +55,7 @@ def test_random_inserts(started_cluster):\n             cmd = ['/bin/bash', bash_script, node.ip_address, str(min_timestamp), str(max_timestamp),\n                    str(cluster.get_client_cmd())]\n             inserters.append(CommandRequest(cmd, timeout=DURATION_SECONDS * 2, stdin=''))\n-            print node.name, node.ip_address\n+            print(node.name, node.ip_address)\n \n         for inserter in inserters:\n             inserter.get_answer()\n@@ -105,8 +105,8 @@ def do_insert(self, thread_num):\n                     self.total_inserted += 2 * x + 1\n                 self.mtx.release()\n \n-            except Exception, e:\n-                print 'Exception:', e\n+            except Exception as e:\n+                print('Exception:', e)\n \n             x += 2\n             self.stop_ev.wait(0.1 + random.random() / 10)\ndiff --git a/tests/integration/test_recompression_ttl/test.py b/tests/integration/test_recompression_ttl/test.py\nindex 9a96151d04a5..e74ae928b51a 100644\n--- a/tests/integration/test_recompression_ttl/test.py\n+++ b/tests/integration/test_recompression_ttl/test.py\n@@ -16,7 +16,7 @@ def started_cluster():\n         yield cluster\n \n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     finally:\n         cluster.shutdown()\ndiff --git a/tests/integration/test_recovery_replica/test.py b/tests/integration/test_recovery_replica/test.py\nindex 74e773cfb835..9320a176f1ea 100644\n--- a/tests/integration/test_recovery_replica/test.py\n+++ b/tests/integration/test_recovery_replica/test.py\n@@ -31,7 +31,7 @@ def start_cluster():\n         yield cluster\n \n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     finally:\n         cluster.shutdown()\ndiff --git a/tests/integration/test_reload_max_table_size_to_drop/test.py b/tests/integration/test_reload_max_table_size_to_drop/test.py\nindex d6bdcc839455..5f2083d742ec 100644\n--- a/tests/integration/test_reload_max_table_size_to_drop/test.py\n+++ b/tests/integration/test_reload_max_table_size_to_drop/test.py\n@@ -34,8 +34,7 @@ def test_reload_max_table_size_to_drop(start_cluster):\n     config = open(CONFIG_PATH, 'r')\n     config_lines = config.readlines()\n     config.close()\n-    config_lines = map(lambda line: line.replace(\"<max_table_size_to_drop>1\", \"<max_table_size_to_drop>1000000\"),\n-                       config_lines)\n+    config_lines = [line.replace(\"<max_table_size_to_drop>1\", \"<max_table_size_to_drop>1000000\") for line in config_lines]\n     config = open(CONFIG_PATH, 'w')\n     config.writelines(config_lines)\n     config.close()\ndiff --git a/tests/integration/test_reload_zookeeper/test.py b/tests/integration/test_reload_zookeeper/test.py\nindex 66df5a1a1267..35958c954172 100644\n--- a/tests/integration/test_reload_zookeeper/test.py\n+++ b/tests/integration/test_reload_zookeeper/test.py\n@@ -65,7 +65,7 @@ def wait_zookeeper_node_to_start(zk_nodes, timeout=60):\n                 print(\"All instances of ZooKeeper started\")\n                 return\n             except Exception as ex:\n-                print(\"Can't connect to ZooKeeper \" + str(ex))\n+                print((\"Can't connect to ZooKeeper \" + str(ex)))\n                 time.sleep(0.5)\n \n     node.query(\"INSERT INTO test_table(date, id) select today(), number FROM numbers(1000)\")\ndiff --git a/tests/integration/test_reloading_storage_configuration/test.py b/tests/integration/test_reloading_storage_configuration/test.py\nindex 0c3139c7fddc..edcba4e8a604 100644\n--- a/tests/integration/test_reloading_storage_configuration/test.py\n+++ b/tests/integration/test_reloading_storage_configuration/test.py\n@@ -82,7 +82,7 @@ def add_policy(node, name, volumes):\n     root = tree.getroot()\n     new_policy = ET.Element(name)\n     new_volumes = ET.Element(\"volumes\")\n-    for volume, disks in volumes.items():\n+    for volume, disks in list(volumes.items()):\n         new_volume = ET.Element(volume)\n         for disk in disks:\n             new_disk = ET.Element(\"disk\")\ndiff --git a/tests/integration/test_rename_column/test.py b/tests/integration/test_rename_column/test.py\nindex b7ab8a75ba5d..0e5cc9f5d9d3 100644\n--- a/tests/integration/test_rename_column/test.py\n+++ b/tests/integration/test_rename_column/test.py\n@@ -1,4 +1,4 @@\n-from __future__ import print_function\n+\n \n import random\n import time\ndiff --git a/tests/integration/test_replicated_merge_tree_s3/test.py b/tests/integration/test_replicated_merge_tree_s3/test.py\nindex 4d19793d0b20..3b3540ef1b89 100644\n--- a/tests/integration/test_replicated_merge_tree_s3/test.py\n+++ b/tests/integration/test_replicated_merge_tree_s3/test.py\n@@ -63,13 +63,13 @@ def create_table(cluster, additional_settings=None):\n         create_table_statement += \",\"\n         create_table_statement += additional_settings\n \n-    cluster.instances.values()[0].query(create_table_statement)\n+    list(cluster.instances.values())[0].query(create_table_statement)\n \n \n @pytest.fixture(autouse=True)\n def drop_table(cluster):\n     yield\n-    for node in cluster.instances.values():\n+    for node in list(cluster.instances.values()):\n         node.query(\"DROP TABLE IF EXISTS s3_test\")\n \n     minio = cluster.minio_client\ndiff --git a/tests/integration/test_replicated_mutations/test.py b/tests/integration/test_replicated_mutations/test.py\nindex cf3cef3a9e61..40a2b15ffaff 100644\n--- a/tests/integration/test_replicated_mutations/test.py\n+++ b/tests/integration/test_replicated_mutations/test.py\n@@ -90,7 +90,7 @@ def do_insert(self, thread_num, partitions_num):\n                 i += 1\n \n             try:\n-                print 'thread {}: insert for {}: {}'.format(thread_num, date_str, ','.join(str(x) for x in xs))\n+                print('thread {}: insert for {}: {}'.format(thread_num, date_str, ','.join(str(x) for x in xs)))\n                 random.choice(self.nodes).query(\"INSERT INTO test_mutations FORMAT TSV\", payload)\n \n                 with self.mtx:\n@@ -99,8 +99,8 @@ def do_insert(self, thread_num, partitions_num):\n                     self.total_inserted_xs += sum(xs)\n                     self.total_inserted_rows += len(xs)\n \n-            except Exception, e:\n-                print 'Exception while inserting,', e\n+            except Exception as e:\n+                print('Exception while inserting,', e)\n                 self.exceptions.append(e)\n             finally:\n                 with self.mtx:\n@@ -128,7 +128,7 @@ def do_delete(self, thread_num):\n                 continue\n \n             try:\n-                print 'thread {}: delete {} * {}'.format(thread_num, to_delete_count, x)\n+                print('thread {}: delete {} * {}'.format(thread_num, to_delete_count, x))\n                 random.choice(self.nodes).query(\"ALTER TABLE test_mutations DELETE WHERE x = {}\".format(x))\n \n                 with self.mtx:\n@@ -137,8 +137,8 @@ def do_delete(self, thread_num):\n                     self.total_deleted_xs += to_delete_count * x\n                     self.total_deleted_rows += to_delete_count\n \n-            except Exception, e:\n-                print 'Exception while deleting,', e\n+            except Exception as e:\n+                print('Exception while deleting,', e)\n             finally:\n                 with self.mtx:\n                     self.currently_deleting_xs.remove(x)\n@@ -186,10 +186,10 @@ def test_mutations(started_cluster):\n \n     all_done = wait_for_mutations(nodes, runner.total_mutations)\n \n-    print \"Total mutations: \", runner.total_mutations\n+    print(\"Total mutations: \", runner.total_mutations)\n     for node in nodes:\n-        print node.query(\n-            \"SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames\")\n+        print(node.query(\n+            \"SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames\"))\n     assert all_done\n \n     expected_sum = runner.total_inserted_xs - runner.total_deleted_xs\n@@ -233,10 +233,10 @@ def test_mutations_dont_prevent_merges(started_cluster, nodes):\n         t.join()\n \n     for node in nodes:\n-        print node.query(\n-            \"SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames\")\n-        print node.query(\n-            \"SELECT partition, count(name), sum(active), sum(active*rows) FROM system.parts WHERE table ='test_mutations' GROUP BY partition FORMAT TSVWithNames\")\n+        print(node.query(\n+            \"SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames\"))\n+        print(node.query(\n+            \"SELECT partition, count(name), sum(active), sum(active*rows) FROM system.parts WHERE table ='test_mutations' GROUP BY partition FORMAT TSVWithNames\"))\n \n     assert all_done\n     assert all([str(e).find(\"Too many parts\") < 0 for e in runner.exceptions])\ndiff --git a/tests/integration/test_replicated_parse_zk_metadata/test.py b/tests/integration/test_replicated_parse_zk_metadata/test.py\nindex 4bdd77393b38..d8b6685ddcda 100644\n--- a/tests/integration/test_replicated_parse_zk_metadata/test.py\n+++ b/tests/integration/test_replicated_parse_zk_metadata/test.py\n@@ -33,7 +33,7 @@ def test_replicated_engine_parse_metadata_on_attach():\n     # and successfully accepted by the server.\n     #\n     # This metadata was obtain from the server without #11325\n-    zk.set('/ch/tables/default/data/replicas/node/metadata', \"\"\"\n+    zk.set('/ch/tables/default/data/replicas/node/metadata', b\"\"\"\n metadata format version: 1\n date column: \n sampling expression: \ndiff --git a/tests/integration/test_replication_without_zookeeper/test.py b/tests/integration/test_replication_without_zookeeper/test.py\nindex 90f060d991a6..26347b47d365 100644\n--- a/tests/integration/test_replication_without_zookeeper/test.py\n+++ b/tests/integration/test_replication_without_zookeeper/test.py\n@@ -23,7 +23,7 @@ def start_cluster():\n         yield cluster\n \n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     finally:\n         cluster.shutdown()\ndiff --git a/tests/integration/test_role/test.py b/tests/integration/test_role/test.py\nindex 31fddd3df8ce..ccd3477ed722 100644\n--- a/tests/integration/test_role/test.py\n+++ b/tests/integration/test_role/test.py\n@@ -184,15 +184,15 @@ def test_introspection():\n \n     assert instance.query(\n         \"SELECT * from system.grants WHERE user_name IN ('A', 'B') OR role_name IN ('R1', 'R2') ORDER BY user_name, role_name, access_type, grant_option\") == \\\n-           TSV([[\"A\", \"\\N\", \"SELECT\", \"test\", \"table\", \"\\N\", 0, 0],\n-                [\"B\", \"\\N\", \"CREATE\", \"\\N\", \"\\N\", \"\\N\", 0, 1],\n-                [\"\\N\", \"R2\", \"SELECT\", \"test\", \"table\", \"\\N\", 0, 0],\n-                [\"\\N\", \"R2\", \"SELECT\", \"test\", \"table\", \"x\", 1, 0]])\n+           TSV([[\"A\", \"\\\\N\", \"SELECT\", \"test\", \"table\", \"\\\\N\", 0, 0],\n+                [\"B\", \"\\\\N\", \"CREATE\", \"\\\\N\", \"\\\\N\", \"\\\\N\", 0, 1],\n+                [\"\\\\N\", \"R2\", \"SELECT\", \"test\", \"table\", \"\\\\N\", 0, 0],\n+                [\"\\\\N\", \"R2\", \"SELECT\", \"test\", \"table\", \"x\", 1, 0]])\n \n     assert instance.query(\n         \"SELECT * from system.role_grants WHERE user_name IN ('A', 'B') OR role_name IN ('R1', 'R2') ORDER BY user_name, role_name, granted_role_name\") == \\\n-           TSV([[\"A\", \"\\N\", \"R1\", 1, 0],\n-                [\"B\", \"\\N\", \"R2\", 1, 1]])\n+           TSV([[\"A\", \"\\\\N\", \"R1\", 1, 0],\n+                [\"B\", \"\\\\N\", \"R2\", 1, 1]])\n \n     assert instance.query(\"SELECT * from system.current_roles ORDER BY role_name\", user='A') == TSV([[\"R1\", 0, 1]])\n     assert instance.query(\"SELECT * from system.current_roles ORDER BY role_name\", user='B') == TSV([[\"R2\", 1, 1]])\ndiff --git a/tests/integration/test_send_crash_reports/fake_sentry_server.py b/tests/integration/test_send_crash_reports/fake_sentry_server.py\nindex 49463bdb1332..fa40f642e417 100644\n--- a/tests/integration/test_send_crash_reports/fake_sentry_server.py\n+++ b/tests/integration/test_send_crash_reports/fake_sentry_server.py\n@@ -1,17 +1,18 @@\n-import BaseHTTPServer\n+import http.server\n \n RESULT_PATH = '/result.txt'\n \n \n-class SentryHandler(BaseHTTPServer.BaseHTTPRequestHandler):\n+class SentryHandler(http.server.BaseHTTPRequestHandler):\n     def do_POST(self):\n         post_data = self.__read_and_decode_post_data()\n         with open(RESULT_PATH, 'w') as f:\n+            content_length = self.headers.get(\"content-length\")\n             if self.headers.get(\"content-type\") != \"application/x-sentry-envelope\":\n                 f.write(\"INCORRECT_CONTENT_TYPE\")\n-            elif self.headers.get(\"content-length\") < 3000:\n-                f.write(\"INCORRECT_CONTENT_LENGTH\")\n-            elif '\"http://6f33034cfe684dd7a3ab9875e57b1c8d@localhost:9500/5226277\"' not in post_data:\n+            elif int(content_length) < 200:\n+                f.write(\"INCORRECT_CONTENT_LENGTH:\" + content_length + '\\n' + post_data.decode())\n+            elif b'\"http://6f33034cfe684dd7a3ab9875e57b1c8d@localhost:9500/5226277\"' not in post_data:\n                 f.write('INCORRECT_POST_DATA')\n             else:\n                 f.write(\"OK\")\n@@ -19,7 +20,7 @@ def do_POST(self):\n \n     def __read_and_decode_post_data(self):\n         transfer_encoding = self.headers.get(\"transfer-Encoding\")\n-        decoded = \"\"\n+        decoded = b\"\"\n         if transfer_encoding == \"chunked\":\n             while True:\n                 s = self.rfile.readline()\n@@ -37,7 +38,7 @@ def __read_and_decode_post_data(self):\n if __name__ == \"__main__\":\n     with open(RESULT_PATH, 'w') as f:\n         f.write(\"INITIAL_STATE\")\n-    httpd = BaseHTTPServer.HTTPServer((\"localhost\", 9500,), SentryHandler)\n+    httpd = http.server.HTTPServer((\"localhost\", 9500,), SentryHandler)\n     try:\n         httpd.serve_forever()\n     finally:\ndiff --git a/tests/integration/test_send_crash_reports/test.py b/tests/integration/test_send_crash_reports/test.py\nindex 4c832d9d67c1..a3c35ca1537c 100644\n--- a/tests/integration/test_send_crash_reports/test.py\n+++ b/tests/integration/test_send_crash_reports/test.py\n@@ -5,7 +5,7 @@\n import helpers.test_tools\n import pytest\n \n-import fake_sentry_server\n+from . import fake_sentry_server\n \n SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))\n \n@@ -25,7 +25,7 @@ def started_node():\n \n def test_send_segfault(started_node, ):\n     started_node.copy_file_to_container(os.path.join(SCRIPT_DIR, \"fake_sentry_server.py\"), \"/fake_sentry_server.py\")\n-    started_node.exec_in_container([\"bash\", \"-c\", \"python2 /fake_sentry_server.py\"], detach=True, user=\"root\")\n+    started_node.exec_in_container([\"bash\", \"-c\", \"python3 /fake_sentry_server.py > /fake_sentry_server.log 2>&1\"], detach=True, user=\"root\")\n     time.sleep(0.5)\n     started_node.exec_in_container([\"bash\", \"-c\", \"pkill -11 clickhouse\"], user=\"root\")\n \ndiff --git a/tests/integration/test_settings_constraints/test.py b/tests/integration/test_settings_constraints/test.py\nindex 90e639685f03..18c80d9c1da2 100644\n--- a/tests/integration/test_settings_constraints/test.py\n+++ b/tests/integration/test_settings_constraints/test.py\n@@ -116,7 +116,7 @@ def assert_query_settings(instance, query, settings, result=None, exception=None\n     # session level settings\n     queries = \"\"\n \n-    for k, v in settings.items():\n+    for k, v in list(settings.items()):\n         queries += \"SET {}={};\\n\".format(k, v)\n \n     queries += query\ndiff --git a/tests/integration/test_settings_profile/test.py b/tests/integration/test_settings_profile/test.py\nindex f7901dc1fe6c..5345ef9a4746 100644\n--- a/tests/integration/test_settings_profile/test.py\n+++ b/tests/integration/test_settings_profile/test.py\n@@ -59,7 +59,7 @@ def test_smoke():\n         \"SET max_memory_usage = 120000000\", user=\"robin\")\n     assert system_settings_profile(\"xyz\") == [[\"xyz\", \"local directory\", 1, 0, \"['robin']\", \"[]\"]]\n     assert system_settings_profile_elements(profile_name=\"xyz\") == [\n-        [\"xyz\", \"\\N\", \"\\N\", 0, \"max_memory_usage\", 100000001, 90000000, 110000000, \"\\N\", \"\\N\"]]\n+        [\"xyz\", \"\\\\N\", \"\\\\N\", 0, \"max_memory_usage\", 100000001, 90000000, 110000000, \"\\\\N\", \"\\\\N\"]]\n \n     instance.query(\"ALTER SETTINGS PROFILE xyz TO NONE\")\n     assert instance.query(\n@@ -81,7 +81,7 @@ def test_smoke():\n     assert \"Setting max_memory_usage shouldn't be greater than 110000000\" in instance.query_and_get_error(\n         \"SET max_memory_usage = 120000000\", user=\"robin\")\n     assert system_settings_profile_elements(user_name=\"robin\") == [\n-        [\"\\N\", \"robin\", \"\\N\", 0, \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"xyz\"]]\n+        [\"\\\\N\", \"robin\", \"\\\\N\", 0, \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"xyz\"]]\n \n     instance.query(\"ALTER USER robin SETTINGS NONE\")\n     assert instance.query(\"SHOW CREATE USER robin\") == \"CREATE USER robin\\n\"\n@@ -108,10 +108,10 @@ def test_settings_from_granted_role():\n         \"SET max_memory_usage = 120000000\", user=\"robin\")\n     assert system_settings_profile(\"xyz\") == [[\"xyz\", \"local directory\", 2, 0, \"[]\", \"[]\"]]\n     assert system_settings_profile_elements(profile_name=\"xyz\") == [\n-        [\"xyz\", \"\\N\", \"\\N\", 0, \"max_memory_usage\", 100000001, \"\\N\", 110000000, \"\\N\", \"\\N\"],\n-        [\"xyz\", \"\\N\", \"\\N\", 1, \"max_ast_depth\", 2000, \"\\N\", \"\\N\", \"\\N\", \"\\N\"]]\n+        [\"xyz\", \"\\\\N\", \"\\\\N\", 0, \"max_memory_usage\", 100000001, \"\\\\N\", 110000000, \"\\\\N\", \"\\\\N\"],\n+        [\"xyz\", \"\\\\N\", \"\\\\N\", 1, \"max_ast_depth\", 2000, \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\"]]\n     assert system_settings_profile_elements(role_name=\"worker\") == [\n-        [\"\\N\", \"\\N\", \"worker\", 0, \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"xyz\"]]\n+        [\"\\\\N\", \"\\\\N\", \"worker\", 0, \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"xyz\"]]\n \n     instance.query(\"REVOKE worker FROM robin\")\n     assert instance.query(\"SELECT value FROM system.settings WHERE name = 'max_memory_usage'\",\n@@ -159,10 +159,10 @@ def test_inheritance():\n \n     assert system_settings_profile(\"xyz\") == [[\"xyz\", \"local directory\", 1, 0, \"[]\", \"[]\"]]\n     assert system_settings_profile_elements(profile_name=\"xyz\") == [\n-        [\"xyz\", \"\\N\", \"\\N\", 0, \"max_memory_usage\", 100000002, \"\\N\", \"\\N\", 1, \"\\N\"]]\n+        [\"xyz\", \"\\\\N\", \"\\\\N\", 0, \"max_memory_usage\", 100000002, \"\\\\N\", \"\\\\N\", 1, \"\\\\N\"]]\n     assert system_settings_profile(\"alpha\") == [[\"alpha\", \"local directory\", 1, 0, \"['robin']\", \"[]\"]]\n     assert system_settings_profile_elements(profile_name=\"alpha\") == [\n-        [\"alpha\", \"\\N\", \"\\N\", 0, \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"\\N\", \"xyz\"]]\n+        [\"alpha\", \"\\\\N\", \"\\\\N\", 0, \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"xyz\"]]\n     assert system_settings_profile_elements(user_name=\"robin\") == []\n \n \ndiff --git a/tests/integration/test_storage_hdfs/test.py b/tests/integration/test_storage_hdfs/test.py\nindex ed2a4e0140d0..996df28ac810 100644\n--- a/tests/integration/test_storage_hdfs/test.py\n+++ b/tests/integration/test_storage_hdfs/test.py\n@@ -58,21 +58,21 @@ def test_read_write_storage_with_globs(started_cluster):\n         node1.query(\"insert into HDFSStorageWithEnum values (1, 'NEW', 4.2)\")\n         assert False, \"Exception have to be thrown\"\n     except Exception as ex:\n-        print ex\n+        print(ex)\n         assert \"in readonly mode\" in str(ex)\n \n     try:\n         node1.query(\"insert into HDFSStorageWithQuestionMark values (1, 'NEW', 4.2)\")\n         assert False, \"Exception have to be thrown\"\n     except Exception as ex:\n-        print ex\n+        print(ex)\n         assert \"in readonly mode\" in str(ex)\n \n     try:\n         node1.query(\"insert into HDFSStorageWithAsterisk values (1, 'NEW', 4.2)\")\n         assert False, \"Exception have to be thrown\"\n     except Exception as ex:\n-        print ex\n+        print(ex)\n         assert \"in readonly mode\" in str(ex)\n \n \n@@ -104,20 +104,20 @@ def test_bad_hdfs_uri(started_cluster):\n         node1.query(\n             \"create table BadStorage1 (id UInt32, name String, weight Float64) ENGINE = HDFS('hads:hgsdfs100500:9000/other_storage', 'TSV')\")\n     except Exception as ex:\n-        print ex\n+        print(ex)\n         assert \"Illegal HDFS URI\" in str(ex)\n     try:\n         node1.query(\n             \"create table BadStorage2 (id UInt32, name String, weight Float64) ENGINE = HDFS('hdfs://hdfs100500:9000/other_storage', 'TSV')\")\n     except Exception as ex:\n-        print ex\n+        print(ex)\n         assert \"Unable to create builder to connect to HDFS\" in str(ex)\n \n     try:\n         node1.query(\n             \"create table BadStorage3 (id UInt32, name String, weight Float64) ENGINE = HDFS('hdfs://hdfs1:9000/<>', 'TSV')\")\n     except Exception as ex:\n-        print ex\n+        print(ex)\n         assert \"Unable to open HDFS file\" in str(ex)\n \n \ndiff --git a/tests/integration/test_storage_kafka/test.py b/tests/integration/test_storage_kafka/test.py\nindex 90422bf98e9b..ae7eed555323 100644\n--- a/tests/integration/test_storage_kafka/test.py\n+++ b/tests/integration/test_storage_kafka/test.py\n@@ -7,10 +7,11 @@\n import time\n \n import avro.schema\n+from confluent_kafka.avro.cached_schema_registry_client import CachedSchemaRegistryClient\n+from confluent_kafka.avro.serializer.message_serializer import MessageSerializer\n+\n import kafka.errors\n import pytest\n-from confluent.schemaregistry.client import CachedSchemaRegistryClient\n-from confluent.schemaregistry.serializers.MessageSerializer import MessageSerializer\n from google.protobuf.internal.encoder import _VarintBytes\n from helpers.client import QueryRuntimeException\n from helpers.cluster import ClickHouseCluster\n@@ -28,7 +29,7 @@\n # to create kafka_pb2.py\n protoc --python_out=. kafka.proto\n \"\"\"\n-import kafka_pb2\n+from . import kafka_pb2\n \n # TODO: add test for run-time offset update in CH, if we manually update it on Kafka side.\n # TODO: add test for SELECT LIMIT is working.\n@@ -69,40 +70,38 @@ def wait_kafka_is_available(max_retries=50):\n             print(\"Waiting for Kafka to start up\")\n             time.sleep(1)\n \n+def producer_serializer(x):\n+    return x.encode() if isinstance(x, str) else x\n \n def kafka_produce(topic, messages, timestamp=None):\n-    producer = KafkaProducer(bootstrap_servers=\"localhost:9092\")\n+    producer = KafkaProducer(bootstrap_servers=\"localhost:9092\", value_serializer=producer_serializer)\n     for message in messages:\n         producer.send(topic=topic, value=message, timestamp_ms=timestamp)\n         producer.flush()\n \n-\n-#    print (\"Produced {} messages for topic {}\".format(len(messages), topic))\n-\n-\n def kafka_consume(topic):\n     consumer = KafkaConsumer(bootstrap_servers=\"localhost:9092\", auto_offset_reset=\"earliest\")\n     consumer.subscribe(topics=(topic))\n-    for toppar, messages in consumer.poll(5000).items():\n+    for toppar, messages in list(consumer.poll(5000).items()):\n         if toppar.topic == topic:\n             for message in messages:\n-                yield message.value\n+                yield message.value.decode()\n     consumer.unsubscribe()\n     consumer.close()\n \n \n def kafka_produce_protobuf_messages(topic, start_index, num_messages):\n-    data = ''\n+    data = b''\n     for i in range(start_index, start_index + num_messages):\n         msg = kafka_pb2.KeyValuePair()\n         msg.key = i\n         msg.value = str(i)\n         serialized_msg = msg.SerializeToString()\n         data = data + _VarintBytes(len(serialized_msg)) + serialized_msg\n-    producer = KafkaProducer(bootstrap_servers=\"localhost:9092\")\n+    producer = KafkaProducer(bootstrap_servers=\"localhost:9092\", value_serializer=producer_serializer)\n     producer.send(topic=topic, value=data)\n     producer.flush()\n-    print(\"Produced {} messages for topic {}\".format(num_messages, topic))\n+    print((\"Produced {} messages for topic {}\".format(num_messages, topic)))\n \n \n def avro_confluent_message(schema_registry_client, value):\n@@ -285,9 +284,9 @@ def test_kafka_formats(kafka_cluster):\n         # clickhouse-client ... | xxd -ps -c 200 | tr -d '\\n' | sed 's/\\(..\\)/\\\\x\\1/g'\n         'Native': {\n             'data_sample': [\n-                '\\x05\\x01\\x02\\x69\\x64\\x05\\x49\\x6e\\x74\\x36\\x34\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x00\\x00\\x04\\x76\\x61\\x6c\\x31\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x02\\x41\\x4d\\x04\\x76\\x61\\x6c\\x32\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x00\\x00\\x00\\x3f\\x04\\x76\\x61\\x6c\\x33\\x05\\x55\\x49\\x6e\\x74\\x38\\x01',\n-                '\\x05\\x0f\\x02\\x69\\x64\\x05\\x49\\x6e\\x74\\x36\\x34\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x09\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x76\\x61\\x6c\\x31\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x04\\x76\\x61\\x6c\\x32\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x04\\x76\\x61\\x6c\\x33\\x05\\x55\\x49\\x6e\\x74\\x38\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01',\n-                '\\x05\\x01\\x02\\x69\\x64\\x05\\x49\\x6e\\x74\\x36\\x34\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x00\\x00\\x04\\x76\\x61\\x6c\\x31\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x02\\x41\\x4d\\x04\\x76\\x61\\x6c\\x32\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x00\\x00\\x00\\x3f\\x04\\x76\\x61\\x6c\\x33\\x05\\x55\\x49\\x6e\\x74\\x38\\x01',\n+                b'\\x05\\x01\\x02\\x69\\x64\\x05\\x49\\x6e\\x74\\x36\\x34\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x00\\x00\\x04\\x76\\x61\\x6c\\x31\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x02\\x41\\x4d\\x04\\x76\\x61\\x6c\\x32\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x00\\x00\\x00\\x3f\\x04\\x76\\x61\\x6c\\x33\\x05\\x55\\x49\\x6e\\x74\\x38\\x01',\n+                b'\\x05\\x0f\\x02\\x69\\x64\\x05\\x49\\x6e\\x74\\x36\\x34\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x09\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x76\\x61\\x6c\\x31\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x02\\x41\\x4d\\x04\\x76\\x61\\x6c\\x32\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x3f\\x04\\x76\\x61\\x6c\\x33\\x05\\x55\\x49\\x6e\\x74\\x38\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01',\n+                b'\\x05\\x01\\x02\\x69\\x64\\x05\\x49\\x6e\\x74\\x36\\x34\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x00\\x00\\x04\\x76\\x61\\x6c\\x31\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x02\\x41\\x4d\\x04\\x76\\x61\\x6c\\x32\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x00\\x00\\x00\\x3f\\x04\\x76\\x61\\x6c\\x33\\x05\\x55\\x49\\x6e\\x74\\x38\\x01',\n                 # ''\n                 # On empty message exception happens: DB::Exception: Attempt to read after eof\n                 # /src/IO/VarInt.h:122: DB::throwReadAfterEOF() @ 0x15c34487 in /usr/bin/clickhouse\n@@ -301,9 +300,9 @@ def test_kafka_formats(kafka_cluster):\n         },\n         'MsgPack': {\n             'data_sample': [\n-                '\\x00\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01',\n-                '\\x01\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x02\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x03\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x04\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x05\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x06\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x07\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x08\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x09\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0a\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0b\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0c\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0d\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0e\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0f\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01',\n-                '\\x00\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01',\n+                b'\\x00\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01',\n+                b'\\x01\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x02\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x03\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x04\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x05\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x06\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x07\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x08\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x09\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0a\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0b\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0c\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0d\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0e\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01\\x0f\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01',\n+                b'\\x00\\x00\\xa2\\x41\\x4d\\xca\\x3f\\x00\\x00\\x00\\x01',\n                 # ''\n                 # On empty message exception happens: Unexpected end of file while parsing msgpack object.: (at row 1)\n                 # coming from Processors/Formats/Impl/MsgPackRowInputFormat.cpp:170\n@@ -311,9 +310,9 @@ def test_kafka_formats(kafka_cluster):\n         },\n         'RowBinary': {\n             'data_sample': [\n-                '\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n-                '\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x09\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n-                '\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n+                b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n+                b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x09\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n+                b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n                 # ''\n                 # On empty message exception happens: DB::Exception: Cannot read all data. Bytes read: 0. Bytes expected: 8.\n                 # /src/IO/ReadBuffer.h:157: DB::ReadBuffer::readStrict(char*, unsigned long) @ 0x15c6894d in /usr/bin/clickhouse\n@@ -325,9 +324,9 @@ def test_kafka_formats(kafka_cluster):\n         },\n         'RowBinaryWithNamesAndTypes': {\n             'data_sample': [\n-                '\\x05\\x02\\x69\\x64\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x04\\x76\\x61\\x6c\\x31\\x04\\x76\\x61\\x6c\\x32\\x04\\x76\\x61\\x6c\\x33\\x05\\x49\\x6e\\x74\\x36\\x34\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x05\\x55\\x49\\x6e\\x74\\x38\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n-                '\\x05\\x02\\x69\\x64\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x04\\x76\\x61\\x6c\\x31\\x04\\x76\\x61\\x6c\\x32\\x04\\x76\\x61\\x6c\\x33\\x05\\x49\\x6e\\x74\\x36\\x34\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x05\\x55\\x49\\x6e\\x74\\x38\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x09\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n-                '\\x05\\x02\\x69\\x64\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x04\\x76\\x61\\x6c\\x31\\x04\\x76\\x61\\x6c\\x32\\x04\\x76\\x61\\x6c\\x33\\x05\\x49\\x6e\\x74\\x36\\x34\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x05\\x55\\x49\\x6e\\x74\\x38\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n+                b'\\x05\\x02\\x69\\x64\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x04\\x76\\x61\\x6c\\x31\\x04\\x76\\x61\\x6c\\x32\\x04\\x76\\x61\\x6c\\x33\\x05\\x49\\x6e\\x74\\x36\\x34\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x05\\x55\\x49\\x6e\\x74\\x38\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n+                b'\\x05\\x02\\x69\\x64\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x04\\x76\\x61\\x6c\\x31\\x04\\x76\\x61\\x6c\\x32\\x04\\x76\\x61\\x6c\\x33\\x05\\x49\\x6e\\x74\\x36\\x34\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x05\\x55\\x49\\x6e\\x74\\x38\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x09\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n+                b'\\x05\\x02\\x69\\x64\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x04\\x76\\x61\\x6c\\x31\\x04\\x76\\x61\\x6c\\x32\\x04\\x76\\x61\\x6c\\x33\\x05\\x49\\x6e\\x74\\x36\\x34\\x06\\x55\\x49\\x6e\\x74\\x31\\x36\\x06\\x53\\x74\\x72\\x69\\x6e\\x67\\x07\\x46\\x6c\\x6f\\x61\\x74\\x33\\x32\\x05\\x55\\x49\\x6e\\x74\\x38\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x41\\x4d\\x00\\x00\\x00\\x3f\\x01',\n                 # ''\n                 # !!! On empty message segfault: Address not mapped to object\n                 # /contrib/FastMemcpy/FastMemcpy.h:666: memcpy_fast @ 0x21742d65 in /usr/bin/clickhouse\n@@ -340,9 +339,9 @@ def test_kafka_formats(kafka_cluster):\n         },\n         'Protobuf': {\n             'data_sample': [\n-                '\\x0b\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01',\n-                '\\x0d\\x08\\x01\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x02\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x03\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x04\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x05\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x06\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x07\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x08\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x09\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0a\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0b\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0c\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0d\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0e\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0f\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01',\n-                '\\x0b\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01',\n+                b'\\x0b\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01',\n+                b'\\x0d\\x08\\x01\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x02\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x03\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x04\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x05\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x06\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x07\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x08\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x09\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0a\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0b\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0c\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0d\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0e\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01\\x0d\\x08\\x0f\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01',\n+                b'\\x0b\\x1a\\x02\\x41\\x4d\\x25\\x00\\x00\\x00\\x3f\\x28\\x01',\n                 # ''\n                 # On empty message exception: Attempt to read after eof\n                 # /src/IO/ReadBuffer.h:184: DB::ReadBuffer::throwReadAfterEOF() @ 0x15c9699b in /usr/bin/clickhouse\n@@ -355,9 +354,9 @@ def test_kafka_formats(kafka_cluster):\n         },\n         'ORC': {\n             'data_sample': [\n-                '\\x4f\\x52\\x43\\x11\\x00\\x00\\x0a\\x06\\x12\\x04\\x08\\x01\\x50\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x01\\x12\\x06\\x08\\x00\\x10\\x00\\x18\\x00\\x50\\x00\\x30\\x00\\x00\\xe3\\x12\\xe7\\x62\\x65\\x00\\x01\\x21\\x3e\\x0e\\x46\\x25\\x0e\\x2e\\x46\\x03\\x21\\x46\\x03\\x09\\xa6\\x00\\x06\\x00\\x32\\x00\\x00\\xe3\\x92\\xe4\\x62\\x65\\x00\\x01\\x21\\x01\\x0e\\x46\\x25\\x2e\\x2e\\x26\\x47\\x5f\\x21\\x20\\x96\\x60\\x09\\x60\\x00\\x00\\x36\\x00\\x00\\xe3\\x92\\xe1\\x62\\x65\\x00\\x01\\x21\\x61\\x0e\\x46\\x23\\x5e\\x2e\\x46\\x03\\x21\\x66\\x03\\x3d\\x53\\x29\\x10\\x11\\xc0\\x00\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x01\\x12\\x06\\x08\\x02\\x10\\x02\\x18\\x02\\x50\\x00\\x05\\x00\\x00\\xff\\x00\\x03\\x00\\x00\\x30\\x07\\x00\\x00\\x40\\x00\\x80\\x05\\x00\\x00\\x41\\x4d\\x07\\x00\\x00\\x42\\x00\\x80\\x03\\x00\\x00\\x0a\\x07\\x00\\x00\\x42\\x00\\x80\\x05\\x00\\x00\\xff\\x01\\x88\\x00\\x00\\x4d\\xca\\xc1\\x0a\\x80\\x30\\x0c\\x03\\xd0\\x2e\\x6b\\xcb\\x98\\x17\\xf1\\x14\\x50\\xfc\\xff\\xcf\\xb4\\x66\\x1e\\x3c\\x84\\x47\\x9a\\xce\\x1c\\xb9\\x1b\\xb7\\xf9\\xda\\x48\\x09\\x9e\\xb2\\xf3\\x92\\xce\\x5b\\x86\\xf6\\x56\\x7f\\x21\\x41\\x2f\\x51\\xa6\\x7a\\xd7\\x1d\\xe5\\xea\\xae\\x3d\\xca\\xd5\\x83\\x71\\x60\\xd8\\x17\\xfc\\x62\\x0f\\xa8\\x00\\x00\\xe3\\x4a\\xe6\\x62\\xe1\\x60\\x0c\\x60\\xe0\\xe2\\xe3\\x60\\x14\\x62\\xe3\\x60\\x10\\x60\\x90\\x60\\x08\\x60\\x88\\x60\\xe5\\x12\\xe0\\x60\\x54\\xe2\\xe0\\x62\\x34\\x10\\x62\\x34\\x90\\x60\\x02\\x8a\\x70\\x71\\x09\\x01\\x45\\xb8\\xb8\\x98\\x1c\\x7d\\x85\\x80\\x58\\x82\\x05\\x28\\xc6\\xcd\\x25\\xca\\xc1\\x68\\xc4\\x0b\\x52\\xc5\\x6c\\xa0\\x67\\x2a\\x05\\x22\\xc0\\x4a\\x21\\x86\\x31\\x09\\x30\\x81\\xb5\\xb2\\x02\\x00\\x36\\x01\\x00\\x25\\x8c\\xbd\\x0a\\xc2\\x30\\x14\\x85\\x73\\x6f\\x92\\xf6\\x92\\x6a\\x09\\x01\\x21\\x64\\x92\\x4e\\x75\\x91\\x58\\x71\\xc9\\x64\\x27\\x5d\\x2c\\x1d\\x5d\\xfd\\x59\\xc4\\x42\\x37\\x5f\\xc0\\x17\\xe8\\x23\\x9b\\xc6\\xe1\\x3b\\x70\\x0f\\xdf\\xb9\\xc4\\xf5\\x17\\x5d\\x41\\x5c\\x4f\\x60\\x37\\xeb\\x53\\x0d\\x55\\x4d\\x0b\\x23\\x01\\xb9\\x90\\x2e\\xbf\\x0f\\xe3\\xe3\\xdd\\x8d\\x0e\\x5f\\x4f\\x27\\x3e\\xb7\\x61\\x97\\xb2\\x49\\xb9\\xaf\\x90\\x20\\x92\\x27\\x32\\x2a\\x6b\\xf4\\xf3\\x0d\\x1e\\x82\\x20\\xe8\\x59\\x28\\x09\\x4c\\x46\\x4c\\x33\\xcb\\x7a\\x76\\x95\\x41\\x47\\x9f\\x14\\x78\\x03\\xde\\x62\\x6c\\x54\\x30\\xb1\\x51\\x0a\\xdb\\x8b\\x89\\x58\\x11\\xbb\\x22\\xac\\x08\\x9a\\xe5\\x6c\\x71\\xbf\\x3d\\xb8\\x39\\x92\\xfa\\x7f\\x86\\x1a\\xd3\\x54\\x1e\\xa7\\xee\\xcc\\x7e\\x08\\x9e\\x01\\x10\\x01\\x18\\x80\\x80\\x10\\x22\\x02\\x00\\x0c\\x28\\x57\\x30\\x06\\x82\\xf4\\x03\\x03\\x4f\\x52\\x43\\x18',\n-                '\\x4f\\x52\\x43\\x11\\x00\\x00\\x0a\\x06\\x12\\x04\\x08\\x0f\\x50\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x0f\\x12\\x06\\x08\\x00\\x10\\x00\\x18\\x00\\x50\\x00\\x30\\x00\\x00\\xe3\\x12\\xe7\\x62\\x65\\x00\\x01\\x21\\x3e\\x0e\\x7e\\x25\\x0e\\x2e\\x46\\x43\\x21\\x46\\x4b\\x09\\xad\\x00\\x06\\x00\\x33\\x00\\x00\\x0a\\x17\\x0a\\x03\\x00\\x00\\x00\\x12\\x10\\x08\\x0f\\x22\\x0a\\x0a\\x02\\x41\\x4d\\x12\\x02\\x41\\x4d\\x18\\x3c\\x50\\x00\\x3a\\x00\\x00\\xe3\\x92\\xe1\\x62\\x65\\x00\\x01\\x21\\x61\\x0e\\x7e\\x23\\x5e\\x2e\\x46\\x03\\x21\\x66\\x03\\x3d\\x53\\x29\\x66\\x73\\x3d\\xd3\\x00\\x06\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x0f\\x12\\x06\\x08\\x02\\x10\\x02\\x18\\x1e\\x50\\x00\\x05\\x00\\x00\\x0c\\x00\\x2b\\x00\\x00\\x31\\x32\\x33\\x34\\x35\\x36\\x37\\x38\\x39\\x31\\x30\\x31\\x31\\x31\\x32\\x31\\x33\\x31\\x34\\x31\\x35\\x09\\x00\\x00\\x06\\x01\\x03\\x02\\x09\\x00\\x00\\xc0\\x0e\\x00\\x00\\x07\\x00\\x00\\x42\\x00\\x80\\x05\\x00\\x00\\x41\\x4d\\x0a\\x00\\x00\\xe3\\xe2\\x42\\x01\\x00\\x09\\x00\\x00\\xc0\\x0e\\x02\\x00\\x05\\x00\\x00\\x0c\\x01\\x94\\x00\\x00\\x2d\\xca\\xc1\\x0e\\x80\\x30\\x08\\x03\\xd0\\xc1\\x60\\x2e\\xf3\\x62\\x76\\x6a\\xe2\\x0e\\xfe\\xff\\x57\\x5a\\x3b\\x0f\\xe4\\x51\\xe8\\x68\\xbd\\x5d\\x05\\xe7\\xf8\\x34\\x40\\x3a\\x6e\\x59\\xb1\\x64\\xe0\\x91\\xa9\\xbf\\xb1\\x97\\xd2\\x95\\x9d\\x1e\\xca\\x55\\x3a\\x6d\\xb4\\xd2\\xdd\\x0b\\x74\\x9a\\x74\\xf7\\x12\\x39\\xbd\\x97\\x7f\\x7c\\x06\\xbb\\xa6\\x8d\\x97\\x17\\xb4\\x00\\x00\\xe3\\x4a\\xe6\\x62\\xe1\\xe0\\x0f\\x60\\xe0\\xe2\\xe3\\xe0\\x17\\x62\\xe3\\x60\\x10\\x60\\x90\\x60\\x08\\x60\\x88\\x60\\xe5\\x12\\xe0\\xe0\\x57\\xe2\\xe0\\x62\\x34\\x14\\x62\\xb4\\x94\\xd0\\x02\\x8a\\xc8\\x73\\x09\\x01\\x45\\xb8\\xb8\\x98\\x1c\\x7d\\x85\\x80\\x58\\xc2\\x06\\x28\\x26\\xc4\\x25\\xca\\xc1\\x6f\\xc4\\xcb\\xc5\\x68\\x20\\xc4\\x6c\\xa0\\x67\\x2a\\xc5\\x6c\\xae\\x67\\x0a\\x14\\xe6\\x87\\x1a\\xc6\\x24\\xc0\\x24\\x21\\x07\\x32\\x0c\\x00\\x4a\\x01\\x00\\xe3\\x60\\x16\\x58\\xc3\\x24\\xc5\\xcd\\xc1\\x2c\\x30\\x89\\x51\\xc2\\x4b\\xc1\\x57\\x83\\x5f\\x49\\x83\\x83\\x47\\x88\\x95\\x91\\x89\\x99\\x85\\x55\\x8a\\x3d\\x29\\x27\\x3f\\x39\\xdb\\x2f\\x5f\\x8a\\x29\\x33\\x45\\x8a\\xa5\\x2c\\x31\\xc7\\x10\\x4c\\x1a\\x81\\x49\\x63\\x25\\x26\\x0e\\x46\\x20\\x66\\x07\\x63\\x36\\x0e\\x3e\\x0d\\x26\\x03\\x10\\x9f\\xd1\\x80\\xdf\\x8a\\x85\\x83\\x3f\\x80\\xc1\\x8a\\x8f\\x83\\x5f\\x88\\x8d\\x83\\x41\\x80\\x41\\x82\\x21\\x80\\x21\\x82\\xd5\\x4a\\x80\\x83\\x5f\\x89\\x83\\x8b\\xd1\\x50\\x88\\xd1\\x52\\x42\\x0b\\x28\\x22\\x6f\\x25\\x04\\x14\\xe1\\xe2\\x62\\x72\\xf4\\x15\\x02\\x62\\x09\\x1b\\xa0\\x98\\x90\\x95\\x28\\x07\\xbf\\x11\\x2f\\x17\\xa3\\x81\\x10\\xb3\\x81\\x9e\\xa9\\x14\\xb3\\xb9\\x9e\\x29\\x50\\x98\\x1f\\x6a\\x18\\x93\\x00\\x93\\x84\\x1c\\xc8\\x30\\x87\\x09\\x7e\\x1e\\x0c\\x00\\x08\\xa8\\x01\\x10\\x01\\x18\\x80\\x80\\x10\\x22\\x02\\x00\\x0c\\x28\\x5d\\x30\\x06\\x82\\xf4\\x03\\x03\\x4f\\x52\\x43\\x18',\n-                '\\x4f\\x52\\x43\\x11\\x00\\x00\\x0a\\x06\\x12\\x04\\x08\\x01\\x50\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x01\\x12\\x06\\x08\\x00\\x10\\x00\\x18\\x00\\x50\\x00\\x30\\x00\\x00\\xe3\\x12\\xe7\\x62\\x65\\x00\\x01\\x21\\x3e\\x0e\\x46\\x25\\x0e\\x2e\\x46\\x03\\x21\\x46\\x03\\x09\\xa6\\x00\\x06\\x00\\x32\\x00\\x00\\xe3\\x92\\xe4\\x62\\x65\\x00\\x01\\x21\\x01\\x0e\\x46\\x25\\x2e\\x2e\\x26\\x47\\x5f\\x21\\x20\\x96\\x60\\x09\\x60\\x00\\x00\\x36\\x00\\x00\\xe3\\x92\\xe1\\x62\\x65\\x00\\x01\\x21\\x61\\x0e\\x46\\x23\\x5e\\x2e\\x46\\x03\\x21\\x66\\x03\\x3d\\x53\\x29\\x10\\x11\\xc0\\x00\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x01\\x12\\x06\\x08\\x02\\x10\\x02\\x18\\x02\\x50\\x00\\x05\\x00\\x00\\xff\\x00\\x03\\x00\\x00\\x30\\x07\\x00\\x00\\x40\\x00\\x80\\x05\\x00\\x00\\x41\\x4d\\x07\\x00\\x00\\x42\\x00\\x80\\x03\\x00\\x00\\x0a\\x07\\x00\\x00\\x42\\x00\\x80\\x05\\x00\\x00\\xff\\x01\\x88\\x00\\x00\\x4d\\xca\\xc1\\x0a\\x80\\x30\\x0c\\x03\\xd0\\x2e\\x6b\\xcb\\x98\\x17\\xf1\\x14\\x50\\xfc\\xff\\xcf\\xb4\\x66\\x1e\\x3c\\x84\\x47\\x9a\\xce\\x1c\\xb9\\x1b\\xb7\\xf9\\xda\\x48\\x09\\x9e\\xb2\\xf3\\x92\\xce\\x5b\\x86\\xf6\\x56\\x7f\\x21\\x41\\x2f\\x51\\xa6\\x7a\\xd7\\x1d\\xe5\\xea\\xae\\x3d\\xca\\xd5\\x83\\x71\\x60\\xd8\\x17\\xfc\\x62\\x0f\\xa8\\x00\\x00\\xe3\\x4a\\xe6\\x62\\xe1\\x60\\x0c\\x60\\xe0\\xe2\\xe3\\x60\\x14\\x62\\xe3\\x60\\x10\\x60\\x90\\x60\\x08\\x60\\x88\\x60\\xe5\\x12\\xe0\\x60\\x54\\xe2\\xe0\\x62\\x34\\x10\\x62\\x34\\x90\\x60\\x02\\x8a\\x70\\x71\\x09\\x01\\x45\\xb8\\xb8\\x98\\x1c\\x7d\\x85\\x80\\x58\\x82\\x05\\x28\\xc6\\xcd\\x25\\xca\\xc1\\x68\\xc4\\x0b\\x52\\xc5\\x6c\\xa0\\x67\\x2a\\x05\\x22\\xc0\\x4a\\x21\\x86\\x31\\x09\\x30\\x81\\xb5\\xb2\\x02\\x00\\x36\\x01\\x00\\x25\\x8c\\xbd\\x0a\\xc2\\x30\\x14\\x85\\x73\\x6f\\x92\\xf6\\x92\\x6a\\x09\\x01\\x21\\x64\\x92\\x4e\\x75\\x91\\x58\\x71\\xc9\\x64\\x27\\x5d\\x2c\\x1d\\x5d\\xfd\\x59\\xc4\\x42\\x37\\x5f\\xc0\\x17\\xe8\\x23\\x9b\\xc6\\xe1\\x3b\\x70\\x0f\\xdf\\xb9\\xc4\\xf5\\x17\\x5d\\x41\\x5c\\x4f\\x60\\x37\\xeb\\x53\\x0d\\x55\\x4d\\x0b\\x23\\x01\\xb9\\x90\\x2e\\xbf\\x0f\\xe3\\xe3\\xdd\\x8d\\x0e\\x5f\\x4f\\x27\\x3e\\xb7\\x61\\x97\\xb2\\x49\\xb9\\xaf\\x90\\x20\\x92\\x27\\x32\\x2a\\x6b\\xf4\\xf3\\x0d\\x1e\\x82\\x20\\xe8\\x59\\x28\\x09\\x4c\\x46\\x4c\\x33\\xcb\\x7a\\x76\\x95\\x41\\x47\\x9f\\x14\\x78\\x03\\xde\\x62\\x6c\\x54\\x30\\xb1\\x51\\x0a\\xdb\\x8b\\x89\\x58\\x11\\xbb\\x22\\xac\\x08\\x9a\\xe5\\x6c\\x71\\xbf\\x3d\\xb8\\x39\\x92\\xfa\\x7f\\x86\\x1a\\xd3\\x54\\x1e\\xa7\\xee\\xcc\\x7e\\x08\\x9e\\x01\\x10\\x01\\x18\\x80\\x80\\x10\\x22\\x02\\x00\\x0c\\x28\\x57\\x30\\x06\\x82\\xf4\\x03\\x03\\x4f\\x52\\x43\\x18',\n+                b'\\x4f\\x52\\x43\\x11\\x00\\x00\\x0a\\x06\\x12\\x04\\x08\\x01\\x50\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x01\\x12\\x06\\x08\\x00\\x10\\x00\\x18\\x00\\x50\\x00\\x30\\x00\\x00\\xe3\\x12\\xe7\\x62\\x65\\x00\\x01\\x21\\x3e\\x0e\\x46\\x25\\x0e\\x2e\\x46\\x03\\x21\\x46\\x03\\x09\\xa6\\x00\\x06\\x00\\x32\\x00\\x00\\xe3\\x92\\xe4\\x62\\x65\\x00\\x01\\x21\\x01\\x0e\\x46\\x25\\x2e\\x2e\\x26\\x47\\x5f\\x21\\x20\\x96\\x60\\x09\\x60\\x00\\x00\\x36\\x00\\x00\\xe3\\x92\\xe1\\x62\\x65\\x00\\x01\\x21\\x61\\x0e\\x46\\x23\\x5e\\x2e\\x46\\x03\\x21\\x66\\x03\\x3d\\x53\\x29\\x10\\x11\\xc0\\x00\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x01\\x12\\x06\\x08\\x02\\x10\\x02\\x18\\x02\\x50\\x00\\x05\\x00\\x00\\xff\\x00\\x03\\x00\\x00\\x30\\x07\\x00\\x00\\x40\\x00\\x80\\x05\\x00\\x00\\x41\\x4d\\x07\\x00\\x00\\x42\\x00\\x80\\x03\\x00\\x00\\x0a\\x07\\x00\\x00\\x42\\x00\\x80\\x05\\x00\\x00\\xff\\x01\\x88\\x00\\x00\\x4d\\xca\\xc1\\x0a\\x80\\x30\\x0c\\x03\\xd0\\x2e\\x6b\\xcb\\x98\\x17\\xf1\\x14\\x50\\xfc\\xff\\xcf\\xb4\\x66\\x1e\\x3c\\x84\\x47\\x9a\\xce\\x1c\\xb9\\x1b\\xb7\\xf9\\xda\\x48\\x09\\x9e\\xb2\\xf3\\x92\\xce\\x5b\\x86\\xf6\\x56\\x7f\\x21\\x41\\x2f\\x51\\xa6\\x7a\\xd7\\x1d\\xe5\\xea\\xae\\x3d\\xca\\xd5\\x83\\x71\\x60\\xd8\\x17\\xfc\\x62\\x0f\\xa8\\x00\\x00\\xe3\\x4a\\xe6\\x62\\xe1\\x60\\x0c\\x60\\xe0\\xe2\\xe3\\x60\\x14\\x62\\xe3\\x60\\x10\\x60\\x90\\x60\\x08\\x60\\x88\\x60\\xe5\\x12\\xe0\\x60\\x54\\xe2\\xe0\\x62\\x34\\x10\\x62\\x34\\x90\\x60\\x02\\x8a\\x70\\x71\\x09\\x01\\x45\\xb8\\xb8\\x98\\x1c\\x7d\\x85\\x80\\x58\\x82\\x05\\x28\\xc6\\xcd\\x25\\xca\\xc1\\x68\\xc4\\x0b\\x52\\xc5\\x6c\\xa0\\x67\\x2a\\x05\\x22\\xc0\\x4a\\x21\\x86\\x31\\x09\\x30\\x81\\xb5\\xb2\\x02\\x00\\x36\\x01\\x00\\x25\\x8c\\xbd\\x0a\\xc2\\x30\\x14\\x85\\x73\\x6f\\x92\\xf6\\x92\\x6a\\x09\\x01\\x21\\x64\\x92\\x4e\\x75\\x91\\x58\\x71\\xc9\\x64\\x27\\x5d\\x2c\\x1d\\x5d\\xfd\\x59\\xc4\\x42\\x37\\x5f\\xc0\\x17\\xe8\\x23\\x9b\\xc6\\xe1\\x3b\\x70\\x0f\\xdf\\xb9\\xc4\\xf5\\x17\\x5d\\x41\\x5c\\x4f\\x60\\x37\\xeb\\x53\\x0d\\x55\\x4d\\x0b\\x23\\x01\\xb9\\x90\\x2e\\xbf\\x0f\\xe3\\xe3\\xdd\\x8d\\x0e\\x5f\\x4f\\x27\\x3e\\xb7\\x61\\x97\\xb2\\x49\\xb9\\xaf\\x90\\x20\\x92\\x27\\x32\\x2a\\x6b\\xf4\\xf3\\x0d\\x1e\\x82\\x20\\xe8\\x59\\x28\\x09\\x4c\\x46\\x4c\\x33\\xcb\\x7a\\x76\\x95\\x41\\x47\\x9f\\x14\\x78\\x03\\xde\\x62\\x6c\\x54\\x30\\xb1\\x51\\x0a\\xdb\\x8b\\x89\\x58\\x11\\xbb\\x22\\xac\\x08\\x9a\\xe5\\x6c\\x71\\xbf\\x3d\\xb8\\x39\\x92\\xfa\\x7f\\x86\\x1a\\xd3\\x54\\x1e\\xa7\\xee\\xcc\\x7e\\x08\\x9e\\x01\\x10\\x01\\x18\\x80\\x80\\x10\\x22\\x02\\x00\\x0c\\x28\\x57\\x30\\x06\\x82\\xf4\\x03\\x03\\x4f\\x52\\x43\\x18',\n+                b'\\x4f\\x52\\x43\\x11\\x00\\x00\\x0a\\x06\\x12\\x04\\x08\\x0f\\x50\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x0f\\x12\\x06\\x08\\x00\\x10\\x00\\x18\\x00\\x50\\x00\\x30\\x00\\x00\\xe3\\x12\\xe7\\x62\\x65\\x00\\x01\\x21\\x3e\\x0e\\x7e\\x25\\x0e\\x2e\\x46\\x43\\x21\\x46\\x4b\\x09\\xad\\x00\\x06\\x00\\x33\\x00\\x00\\x0a\\x17\\x0a\\x03\\x00\\x00\\x00\\x12\\x10\\x08\\x0f\\x22\\x0a\\x0a\\x02\\x41\\x4d\\x12\\x02\\x41\\x4d\\x18\\x3c\\x50\\x00\\x3a\\x00\\x00\\xe3\\x92\\xe1\\x62\\x65\\x00\\x01\\x21\\x61\\x0e\\x7e\\x23\\x5e\\x2e\\x46\\x03\\x21\\x66\\x03\\x3d\\x53\\x29\\x66\\x73\\x3d\\xd3\\x00\\x06\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x0f\\x12\\x06\\x08\\x02\\x10\\x02\\x18\\x1e\\x50\\x00\\x05\\x00\\x00\\x0c\\x00\\x2b\\x00\\x00\\x31\\x32\\x33\\x34\\x35\\x36\\x37\\x38\\x39\\x31\\x30\\x31\\x31\\x31\\x32\\x31\\x33\\x31\\x34\\x31\\x35\\x09\\x00\\x00\\x06\\x01\\x03\\x02\\x09\\x00\\x00\\xc0\\x0e\\x00\\x00\\x07\\x00\\x00\\x42\\x00\\x80\\x05\\x00\\x00\\x41\\x4d\\x0a\\x00\\x00\\xe3\\xe2\\x42\\x01\\x00\\x09\\x00\\x00\\xc0\\x0e\\x02\\x00\\x05\\x00\\x00\\x0c\\x01\\x94\\x00\\x00\\x2d\\xca\\xc1\\x0e\\x80\\x30\\x08\\x03\\xd0\\xc1\\x60\\x2e\\xf3\\x62\\x76\\x6a\\xe2\\x0e\\xfe\\xff\\x57\\x5a\\x3b\\x0f\\xe4\\x51\\xe8\\x68\\xbd\\x5d\\x05\\xe7\\xf8\\x34\\x40\\x3a\\x6e\\x59\\xb1\\x64\\xe0\\x91\\xa9\\xbf\\xb1\\x97\\xd2\\x95\\x9d\\x1e\\xca\\x55\\x3a\\x6d\\xb4\\xd2\\xdd\\x0b\\x74\\x9a\\x74\\xf7\\x12\\x39\\xbd\\x97\\x7f\\x7c\\x06\\xbb\\xa6\\x8d\\x97\\x17\\xb4\\x00\\x00\\xe3\\x4a\\xe6\\x62\\xe1\\xe0\\x0f\\x60\\xe0\\xe2\\xe3\\xe0\\x17\\x62\\xe3\\x60\\x10\\x60\\x90\\x60\\x08\\x60\\x88\\x60\\xe5\\x12\\xe0\\xe0\\x57\\xe2\\xe0\\x62\\x34\\x14\\x62\\xb4\\x94\\xd0\\x02\\x8a\\xc8\\x73\\x09\\x01\\x45\\xb8\\xb8\\x98\\x1c\\x7d\\x85\\x80\\x58\\xc2\\x06\\x28\\x26\\xc4\\x25\\xca\\xc1\\x6f\\xc4\\xcb\\xc5\\x68\\x20\\xc4\\x6c\\xa0\\x67\\x2a\\xc5\\x6c\\xae\\x67\\x0a\\x14\\xe6\\x87\\x1a\\xc6\\x24\\xc0\\x24\\x21\\x07\\x32\\x0c\\x00\\x4a\\x01\\x00\\xe3\\x60\\x16\\x58\\xc3\\x24\\xc5\\xcd\\xc1\\x2c\\x30\\x89\\x51\\xc2\\x4b\\xc1\\x57\\x83\\x5f\\x49\\x83\\x83\\x47\\x88\\x95\\x91\\x89\\x99\\x85\\x55\\x8a\\x3d\\x29\\x27\\x3f\\x39\\xdb\\x2f\\x5f\\x8a\\x29\\x33\\x45\\x8a\\xa5\\x2c\\x31\\xc7\\x10\\x4c\\x1a\\x81\\x49\\x63\\x25\\x26\\x0e\\x46\\x20\\x66\\x07\\x63\\x36\\x0e\\x3e\\x0d\\x26\\x03\\x10\\x9f\\xd1\\x80\\xdf\\x8a\\x85\\x83\\x3f\\x80\\xc1\\x8a\\x8f\\x83\\x5f\\x88\\x8d\\x83\\x41\\x80\\x41\\x82\\x21\\x80\\x21\\x82\\xd5\\x4a\\x80\\x83\\x5f\\x89\\x83\\x8b\\xd1\\x50\\x88\\xd1\\x52\\x42\\x0b\\x28\\x22\\x6f\\x25\\x04\\x14\\xe1\\xe2\\x62\\x72\\xf4\\x15\\x02\\x62\\x09\\x1b\\xa0\\x98\\x90\\x95\\x28\\x07\\xbf\\x11\\x2f\\x17\\xa3\\x81\\x10\\xb3\\x81\\x9e\\xa9\\x14\\xb3\\xb9\\x9e\\x29\\x50\\x98\\x1f\\x6a\\x18\\x93\\x00\\x93\\x84\\x1c\\xc8\\x30\\x87\\x09\\x7e\\x1e\\x0c\\x00\\x08\\xa8\\x01\\x10\\x01\\x18\\x80\\x80\\x10\\x22\\x02\\x00\\x0c\\x28\\x5d\\x30\\x06\\x82\\xf4\\x03\\x03\\x4f\\x52\\x43\\x18',\n+                b'\\x4f\\x52\\x43\\x11\\x00\\x00\\x0a\\x06\\x12\\x04\\x08\\x01\\x50\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x01\\x12\\x06\\x08\\x00\\x10\\x00\\x18\\x00\\x50\\x00\\x30\\x00\\x00\\xe3\\x12\\xe7\\x62\\x65\\x00\\x01\\x21\\x3e\\x0e\\x46\\x25\\x0e\\x2e\\x46\\x03\\x21\\x46\\x03\\x09\\xa6\\x00\\x06\\x00\\x32\\x00\\x00\\xe3\\x92\\xe4\\x62\\x65\\x00\\x01\\x21\\x01\\x0e\\x46\\x25\\x2e\\x2e\\x26\\x47\\x5f\\x21\\x20\\x96\\x60\\x09\\x60\\x00\\x00\\x36\\x00\\x00\\xe3\\x92\\xe1\\x62\\x65\\x00\\x01\\x21\\x61\\x0e\\x46\\x23\\x5e\\x2e\\x46\\x03\\x21\\x66\\x03\\x3d\\x53\\x29\\x10\\x11\\xc0\\x00\\x00\\x2b\\x00\\x00\\x0a\\x13\\x0a\\x03\\x00\\x00\\x00\\x12\\x0c\\x08\\x01\\x12\\x06\\x08\\x02\\x10\\x02\\x18\\x02\\x50\\x00\\x05\\x00\\x00\\xff\\x00\\x03\\x00\\x00\\x30\\x07\\x00\\x00\\x40\\x00\\x80\\x05\\x00\\x00\\x41\\x4d\\x07\\x00\\x00\\x42\\x00\\x80\\x03\\x00\\x00\\x0a\\x07\\x00\\x00\\x42\\x00\\x80\\x05\\x00\\x00\\xff\\x01\\x88\\x00\\x00\\x4d\\xca\\xc1\\x0a\\x80\\x30\\x0c\\x03\\xd0\\x2e\\x6b\\xcb\\x98\\x17\\xf1\\x14\\x50\\xfc\\xff\\xcf\\xb4\\x66\\x1e\\x3c\\x84\\x47\\x9a\\xce\\x1c\\xb9\\x1b\\xb7\\xf9\\xda\\x48\\x09\\x9e\\xb2\\xf3\\x92\\xce\\x5b\\x86\\xf6\\x56\\x7f\\x21\\x41\\x2f\\x51\\xa6\\x7a\\xd7\\x1d\\xe5\\xea\\xae\\x3d\\xca\\xd5\\x83\\x71\\x60\\xd8\\x17\\xfc\\x62\\x0f\\xa8\\x00\\x00\\xe3\\x4a\\xe6\\x62\\xe1\\x60\\x0c\\x60\\xe0\\xe2\\xe3\\x60\\x14\\x62\\xe3\\x60\\x10\\x60\\x90\\x60\\x08\\x60\\x88\\x60\\xe5\\x12\\xe0\\x60\\x54\\xe2\\xe0\\x62\\x34\\x10\\x62\\x34\\x90\\x60\\x02\\x8a\\x70\\x71\\x09\\x01\\x45\\xb8\\xb8\\x98\\x1c\\x7d\\x85\\x80\\x58\\x82\\x05\\x28\\xc6\\xcd\\x25\\xca\\xc1\\x68\\xc4\\x0b\\x52\\xc5\\x6c\\xa0\\x67\\x2a\\x05\\x22\\xc0\\x4a\\x21\\x86\\x31\\x09\\x30\\x81\\xb5\\xb2\\x02\\x00\\x36\\x01\\x00\\x25\\x8c\\xbd\\x0a\\xc2\\x30\\x14\\x85\\x73\\x6f\\x92\\xf6\\x92\\x6a\\x09\\x01\\x21\\x64\\x92\\x4e\\x75\\x91\\x58\\x71\\xc9\\x64\\x27\\x5d\\x2c\\x1d\\x5d\\xfd\\x59\\xc4\\x42\\x37\\x5f\\xc0\\x17\\xe8\\x23\\x9b\\xc6\\xe1\\x3b\\x70\\x0f\\xdf\\xb9\\xc4\\xf5\\x17\\x5d\\x41\\x5c\\x4f\\x60\\x37\\xeb\\x53\\x0d\\x55\\x4d\\x0b\\x23\\x01\\xb9\\x90\\x2e\\xbf\\x0f\\xe3\\xe3\\xdd\\x8d\\x0e\\x5f\\x4f\\x27\\x3e\\xb7\\x61\\x97\\xb2\\x49\\xb9\\xaf\\x90\\x20\\x92\\x27\\x32\\x2a\\x6b\\xf4\\xf3\\x0d\\x1e\\x82\\x20\\xe8\\x59\\x28\\x09\\x4c\\x46\\x4c\\x33\\xcb\\x7a\\x76\\x95\\x41\\x47\\x9f\\x14\\x78\\x03\\xde\\x62\\x6c\\x54\\x30\\xb1\\x51\\x0a\\xdb\\x8b\\x89\\x58\\x11\\xbb\\x22\\xac\\x08\\x9a\\xe5\\x6c\\x71\\xbf\\x3d\\xb8\\x39\\x92\\xfa\\x7f\\x86\\x1a\\xd3\\x54\\x1e\\xa7\\xee\\xcc\\x7e\\x08\\x9e\\x01\\x10\\x01\\x18\\x80\\x80\\x10\\x22\\x02\\x00\\x0c\\x28\\x57\\x30\\x06\\x82\\xf4\\x03\\x03\\x4f\\x52\\x43\\x18',\n                 # ''\n                 # On empty message exception:  IOError: File size too small, Stack trace (when copying this message, always include the lines below):\n                 # /src/Processors/Formats/Impl/ORCBlockInputFormat.cpp:36: DB::ORCBlockInputFormat::generate() @ 0x1df282a6 in /usr/bin/clickhouse\n@@ -366,9 +365,9 @@ def test_kafka_formats(kafka_cluster):\n         },\n         'CapnProto': {\n             'data_sample': [\n-                '\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00',\n-                '\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x09\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00',\n-                '\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00',\n+                b'\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00',\n+                b'\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x09\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00',\n+                b'\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x3f\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x41\\x4d\\x00\\x00\\x00\\x00\\x00\\x00',\n                 # ''\n                 # On empty message exception: Cannot read all data. Bytes read: 0. Bytes expected: 4.\n                 # /src/IO/ReadBuffer.h:157: DB::ReadBuffer::readStrict(char*, unsigned long) @ 0x15c6894d in /usr/bin/clickhouse\n@@ -404,30 +403,30 @@ def test_kafka_formats(kafka_cluster):\n         # /src/DataStreams/copyData.cpp:63: DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::__1::atomic<bool>*) @ 0x1c9e9fc7 in /usr/bin/clickhouse\n         # /src/Storages/Kafka/StorageKafka.cpp:565: DB::StorageKafka::streamToViews() @ 0x1d8cc3fa in /usr/bin/clickhouse\n         #     # 'data_sample' : [\n-        #     #     '\\x50\\x41\\x52\\x31\\x15\\x04\\x15\\x10\\x15\\x14\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x08\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xbc\\x01\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x02\\x16\\xac\\x01\\x16\\xb4\\x01\\x26\\x38\\x26\\x08\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xc8\\x03\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xfc\\x02\\x26\\xd4\\x02\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x0c\\x15\\x10\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x06\\x14\\x02\\x00\\x00\\x00\\x41\\x4d\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xa2\\x05\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x02\\x16\\x68\\x16\\x70\\x26\\xde\\x04\\x26\\xb2\\x04\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x3f\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\x8a\\x07\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x02\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xa6\\x06\\x26\\xfe\\x05\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x01\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xfe\\x08\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xb2\\x08\\x26\\x8a\\x08\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x02\\x19\\x6c\\x35\\x00\\x18\\x06\\x73\\x63\\x68\\x65\\x6d\\x61\\x15\\x0a\\x00\\x15\\x04\\x25\\x00\\x18\\x02\\x69\\x64\\x00\\x15\\x02\\x25\\x00\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x25\\x18\\x4c\\xac\\x13\\x10\\x12\\x00\\x00\\x00\\x15\\x0c\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x31\\x25\\x00\\x4c\\x1c\\x00\\x00\\x00\\x15\\x08\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x32\\x00\\x15\\x02\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x33\\x25\\x16\\x4c\\xac\\x13\\x08\\x12\\x00\\x00\\x00\\x16\\x02\\x19\\x1c\\x19\\x5c\\x26\\xbc\\x01\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x02\\x16\\xac\\x01\\x16\\xb4\\x01\\x26\\x38\\x26\\x08\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xc8\\x03\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xfc\\x02\\x26\\xd4\\x02\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xa2\\x05\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x02\\x16\\x68\\x16\\x70\\x26\\xde\\x04\\x26\\xb2\\x04\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x26\\x8a\\x07\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x02\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xa6\\x06\\x26\\xfe\\x05\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x26\\xfe\\x08\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xb2\\x08\\x26\\x8a\\x08\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x98\\x05\\x16\\x02\\x00\\x28\\x22\\x70\\x61\\x72\\x71\\x75\\x65\\x74\\x2d\\x63\\x70\\x70\\x20\\x76\\x65\\x72\\x73\\x69\\x6f\\x6e\\x20\\x31\\x2e\\x35\\x2e\\x31\\x2d\\x53\\x4e\\x41\\x50\\x53\\x48\\x4f\\x54\\x19\\x5c\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x00\\xc4\\x01\\x00\\x00\\x50\\x41\\x52\\x31',\n-        #     #     '\\x50\\x41\\x52\\x31\\x15\\x04\\x15\\xf0\\x01\\x15\\x90\\x01\\x4c\\x15\\x1e\\x15\\x04\\x12\\x00\\x00\\x78\\x04\\x01\\x00\\x09\\x01\\x00\\x02\\x09\\x07\\x04\\x00\\x03\\x0d\\x08\\x00\\x04\\x0d\\x08\\x00\\x05\\x0d\\x08\\x00\\x06\\x0d\\x08\\x00\\x07\\x0d\\x08\\x00\\x08\\x0d\\x08\\x00\\x09\\x0d\\x08\\x00\\x0a\\x0d\\x08\\x00\\x0b\\x0d\\x08\\x00\\x0c\\x0d\\x08\\x00\\x0d\\x0d\\x08\\x3c\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x14\\x15\\x18\\x2c\\x15\\x1e\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0a\\x24\\x04\\x05\\x10\\x32\\x54\\x76\\x98\\xba\\xdc\\x0e\\x26\\xca\\x02\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x1e\\x16\\x9e\\x03\\x16\\xc2\\x02\\x26\\xb8\\x01\\x26\\x08\\x1c\\x18\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x1e\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x1e\\x00\\x26\\xd8\\x04\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x1e\\x16\\x6c\\x16\\x74\\x26\\x8c\\x04\\x26\\xe4\\x03\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x0c\\x15\\x10\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x06\\x14\\x02\\x00\\x00\\x00\\x41\\x4d\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x1e\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x03\\x08\\x01\\x1e\\x00\\x26\\xb2\\x06\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x1e\\x16\\x68\\x16\\x70\\x26\\xee\\x05\\x26\\xc2\\x05\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x3f\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x1e\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x03\\x08\\x01\\x1e\\x00\\x26\\x9a\\x08\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x1e\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xb6\\x07\\x26\\x8e\\x07\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x01\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x1e\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x1e\\x00\\x26\\x8e\\x0a\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x1e\\x16\\x6c\\x16\\x74\\x26\\xc2\\x09\\x26\\x9a\\x09\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x02\\x19\\x6c\\x35\\x00\\x18\\x06\\x73\\x63\\x68\\x65\\x6d\\x61\\x15\\x0a\\x00\\x15\\x04\\x25\\x00\\x18\\x02\\x69\\x64\\x00\\x15\\x02\\x25\\x00\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x25\\x18\\x4c\\xac\\x13\\x10\\x12\\x00\\x00\\x00\\x15\\x0c\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x31\\x25\\x00\\x4c\\x1c\\x00\\x00\\x00\\x15\\x08\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x32\\x00\\x15\\x02\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x33\\x25\\x16\\x4c\\xac\\x13\\x08\\x12\\x00\\x00\\x00\\x16\\x1e\\x19\\x1c\\x19\\x5c\\x26\\xca\\x02\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x1e\\x16\\x9e\\x03\\x16\\xc2\\x02\\x26\\xb8\\x01\\x26\\x08\\x1c\\x18\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xd8\\x04\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x1e\\x16\\x6c\\x16\\x74\\x26\\x8c\\x04\\x26\\xe4\\x03\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xb2\\x06\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x1e\\x16\\x68\\x16\\x70\\x26\\xee\\x05\\x26\\xc2\\x05\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x26\\x9a\\x08\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x1e\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xb6\\x07\\x26\\x8e\\x07\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x26\\x8e\\x0a\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x1e\\x16\\x6c\\x16\\x74\\x26\\xc2\\x09\\x26\\x9a\\x09\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\xa6\\x06\\x16\\x1e\\x00\\x28\\x22\\x70\\x61\\x72\\x71\\x75\\x65\\x74\\x2d\\x63\\x70\\x70\\x20\\x76\\x65\\x72\\x73\\x69\\x6f\\x6e\\x20\\x31\\x2e\\x35\\x2e\\x31\\x2d\\x53\\x4e\\x41\\x50\\x53\\x48\\x4f\\x54\\x19\\x5c\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x00\\xc5\\x01\\x00\\x00\\x50\\x41\\x52\\x31',\n-        #     #     '\\x50\\x41\\x52\\x31\\x15\\x04\\x15\\x10\\x15\\x14\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x08\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xbc\\x01\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x02\\x16\\xac\\x01\\x16\\xb4\\x01\\x26\\x38\\x26\\x08\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xc8\\x03\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xfc\\x02\\x26\\xd4\\x02\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x0c\\x15\\x10\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x06\\x14\\x02\\x00\\x00\\x00\\x41\\x4d\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xa2\\x05\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x02\\x16\\x68\\x16\\x70\\x26\\xde\\x04\\x26\\xb2\\x04\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x3f\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\x8a\\x07\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x02\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xa6\\x06\\x26\\xfe\\x05\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x01\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xfe\\x08\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xb2\\x08\\x26\\x8a\\x08\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x02\\x19\\x6c\\x35\\x00\\x18\\x06\\x73\\x63\\x68\\x65\\x6d\\x61\\x15\\x0a\\x00\\x15\\x04\\x25\\x00\\x18\\x02\\x69\\x64\\x00\\x15\\x02\\x25\\x00\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x25\\x18\\x4c\\xac\\x13\\x10\\x12\\x00\\x00\\x00\\x15\\x0c\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x31\\x25\\x00\\x4c\\x1c\\x00\\x00\\x00\\x15\\x08\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x32\\x00\\x15\\x02\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x33\\x25\\x16\\x4c\\xac\\x13\\x08\\x12\\x00\\x00\\x00\\x16\\x02\\x19\\x1c\\x19\\x5c\\x26\\xbc\\x01\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x02\\x16\\xac\\x01\\x16\\xb4\\x01\\x26\\x38\\x26\\x08\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xc8\\x03\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xfc\\x02\\x26\\xd4\\x02\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xa2\\x05\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x02\\x16\\x68\\x16\\x70\\x26\\xde\\x04\\x26\\xb2\\x04\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x26\\x8a\\x07\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x02\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xa6\\x06\\x26\\xfe\\x05\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x26\\xfe\\x08\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xb2\\x08\\x26\\x8a\\x08\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x98\\x05\\x16\\x02\\x00\\x28\\x22\\x70\\x61\\x72\\x71\\x75\\x65\\x74\\x2d\\x63\\x70\\x70\\x20\\x76\\x65\\x72\\x73\\x69\\x6f\\x6e\\x20\\x31\\x2e\\x35\\x2e\\x31\\x2d\\x53\\x4e\\x41\\x50\\x53\\x48\\x4f\\x54\\x19\\x5c\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x00\\xc4\\x01\\x00\\x00\\x50\\x41\\x52\\x31',\n+        #     #     b'\\x50\\x41\\x52\\x31\\x15\\x04\\x15\\x10\\x15\\x14\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x08\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xbc\\x01\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x02\\x16\\xac\\x01\\x16\\xb4\\x01\\x26\\x38\\x26\\x08\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xc8\\x03\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xfc\\x02\\x26\\xd4\\x02\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x0c\\x15\\x10\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x06\\x14\\x02\\x00\\x00\\x00\\x41\\x4d\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xa2\\x05\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x02\\x16\\x68\\x16\\x70\\x26\\xde\\x04\\x26\\xb2\\x04\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x3f\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\x8a\\x07\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x02\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xa6\\x06\\x26\\xfe\\x05\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x01\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xfe\\x08\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xb2\\x08\\x26\\x8a\\x08\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x02\\x19\\x6c\\x35\\x00\\x18\\x06\\x73\\x63\\x68\\x65\\x6d\\x61\\x15\\x0a\\x00\\x15\\x04\\x25\\x00\\x18\\x02\\x69\\x64\\x00\\x15\\x02\\x25\\x00\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x25\\x18\\x4c\\xac\\x13\\x10\\x12\\x00\\x00\\x00\\x15\\x0c\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x31\\x25\\x00\\x4c\\x1c\\x00\\x00\\x00\\x15\\x08\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x32\\x00\\x15\\x02\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x33\\x25\\x16\\x4c\\xac\\x13\\x08\\x12\\x00\\x00\\x00\\x16\\x02\\x19\\x1c\\x19\\x5c\\x26\\xbc\\x01\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x02\\x16\\xac\\x01\\x16\\xb4\\x01\\x26\\x38\\x26\\x08\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xc8\\x03\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xfc\\x02\\x26\\xd4\\x02\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xa2\\x05\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x02\\x16\\x68\\x16\\x70\\x26\\xde\\x04\\x26\\xb2\\x04\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x26\\x8a\\x07\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x02\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xa6\\x06\\x26\\xfe\\x05\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x26\\xfe\\x08\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xb2\\x08\\x26\\x8a\\x08\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x98\\x05\\x16\\x02\\x00\\x28\\x22\\x70\\x61\\x72\\x71\\x75\\x65\\x74\\x2d\\x63\\x70\\x70\\x20\\x76\\x65\\x72\\x73\\x69\\x6f\\x6e\\x20\\x31\\x2e\\x35\\x2e\\x31\\x2d\\x53\\x4e\\x41\\x50\\x53\\x48\\x4f\\x54\\x19\\x5c\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x00\\xc4\\x01\\x00\\x00\\x50\\x41\\x52\\x31',\n+        #     #     b'\\x50\\x41\\x52\\x31\\x15\\x04\\x15\\xf0\\x01\\x15\\x90\\x01\\x4c\\x15\\x1e\\x15\\x04\\x12\\x00\\x00\\x78\\x04\\x01\\x00\\x09\\x01\\x00\\x02\\x09\\x07\\x04\\x00\\x03\\x0d\\x08\\x00\\x04\\x0d\\x08\\x00\\x05\\x0d\\x08\\x00\\x06\\x0d\\x08\\x00\\x07\\x0d\\x08\\x00\\x08\\x0d\\x08\\x00\\x09\\x0d\\x08\\x00\\x0a\\x0d\\x08\\x00\\x0b\\x0d\\x08\\x00\\x0c\\x0d\\x08\\x00\\x0d\\x0d\\x08\\x3c\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x14\\x15\\x18\\x2c\\x15\\x1e\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0a\\x24\\x04\\x05\\x10\\x32\\x54\\x76\\x98\\xba\\xdc\\x0e\\x26\\xca\\x02\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x1e\\x16\\x9e\\x03\\x16\\xc2\\x02\\x26\\xb8\\x01\\x26\\x08\\x1c\\x18\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x1e\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x1e\\x00\\x26\\xd8\\x04\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x1e\\x16\\x6c\\x16\\x74\\x26\\x8c\\x04\\x26\\xe4\\x03\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x0c\\x15\\x10\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x06\\x14\\x02\\x00\\x00\\x00\\x41\\x4d\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x1e\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x03\\x08\\x01\\x1e\\x00\\x26\\xb2\\x06\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x1e\\x16\\x68\\x16\\x70\\x26\\xee\\x05\\x26\\xc2\\x05\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x3f\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x1e\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x03\\x08\\x01\\x1e\\x00\\x26\\x9a\\x08\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x1e\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xb6\\x07\\x26\\x8e\\x07\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x01\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x1e\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x1e\\x00\\x26\\x8e\\x0a\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x1e\\x16\\x6c\\x16\\x74\\x26\\xc2\\x09\\x26\\x9a\\x09\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x02\\x19\\x6c\\x35\\x00\\x18\\x06\\x73\\x63\\x68\\x65\\x6d\\x61\\x15\\x0a\\x00\\x15\\x04\\x25\\x00\\x18\\x02\\x69\\x64\\x00\\x15\\x02\\x25\\x00\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x25\\x18\\x4c\\xac\\x13\\x10\\x12\\x00\\x00\\x00\\x15\\x0c\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x31\\x25\\x00\\x4c\\x1c\\x00\\x00\\x00\\x15\\x08\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x32\\x00\\x15\\x02\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x33\\x25\\x16\\x4c\\xac\\x13\\x08\\x12\\x00\\x00\\x00\\x16\\x1e\\x19\\x1c\\x19\\x5c\\x26\\xca\\x02\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x1e\\x16\\x9e\\x03\\x16\\xc2\\x02\\x26\\xb8\\x01\\x26\\x08\\x1c\\x18\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xd8\\x04\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x1e\\x16\\x6c\\x16\\x74\\x26\\x8c\\x04\\x26\\xe4\\x03\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xb2\\x06\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x1e\\x16\\x68\\x16\\x70\\x26\\xee\\x05\\x26\\xc2\\x05\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x26\\x9a\\x08\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x1e\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xb6\\x07\\x26\\x8e\\x07\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x26\\x8e\\x0a\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x1e\\x16\\x6c\\x16\\x74\\x26\\xc2\\x09\\x26\\x9a\\x09\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\xa6\\x06\\x16\\x1e\\x00\\x28\\x22\\x70\\x61\\x72\\x71\\x75\\x65\\x74\\x2d\\x63\\x70\\x70\\x20\\x76\\x65\\x72\\x73\\x69\\x6f\\x6e\\x20\\x31\\x2e\\x35\\x2e\\x31\\x2d\\x53\\x4e\\x41\\x50\\x53\\x48\\x4f\\x54\\x19\\x5c\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x00\\xc5\\x01\\x00\\x00\\x50\\x41\\x52\\x31',\n+        #     #     b'\\x50\\x41\\x52\\x31\\x15\\x04\\x15\\x10\\x15\\x14\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x08\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xbc\\x01\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x02\\x16\\xac\\x01\\x16\\xb4\\x01\\x26\\x38\\x26\\x08\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xc8\\x03\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xfc\\x02\\x26\\xd4\\x02\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x04\\x15\\x0c\\x15\\x10\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x06\\x14\\x02\\x00\\x00\\x00\\x41\\x4d\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xa2\\x05\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x02\\x16\\x68\\x16\\x70\\x26\\xde\\x04\\x26\\xb2\\x04\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x00\\x00\\x00\\x3f\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\x8a\\x07\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x02\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xa6\\x06\\x26\\xfe\\x05\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x15\\x04\\x15\\x08\\x15\\x0c\\x4c\\x15\\x02\\x15\\x04\\x12\\x00\\x00\\x04\\x0c\\x01\\x00\\x00\\x00\\x15\\x00\\x15\\x06\\x15\\x0a\\x2c\\x15\\x02\\x15\\x04\\x15\\x06\\x15\\x06\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x08\\x01\\x02\\x00\\x26\\xfe\\x08\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xb2\\x08\\x26\\x8a\\x08\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x02\\x19\\x6c\\x35\\x00\\x18\\x06\\x73\\x63\\x68\\x65\\x6d\\x61\\x15\\x0a\\x00\\x15\\x04\\x25\\x00\\x18\\x02\\x69\\x64\\x00\\x15\\x02\\x25\\x00\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x25\\x18\\x4c\\xac\\x13\\x10\\x12\\x00\\x00\\x00\\x15\\x0c\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x31\\x25\\x00\\x4c\\x1c\\x00\\x00\\x00\\x15\\x08\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x32\\x00\\x15\\x02\\x25\\x00\\x18\\x04\\x76\\x61\\x6c\\x33\\x25\\x16\\x4c\\xac\\x13\\x08\\x12\\x00\\x00\\x00\\x16\\x02\\x19\\x1c\\x19\\x5c\\x26\\xbc\\x01\\x1c\\x15\\x04\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x02\\x69\\x64\\x15\\x02\\x16\\x02\\x16\\xac\\x01\\x16\\xb4\\x01\\x26\\x38\\x26\\x08\\x1c\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x28\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xc8\\x03\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x07\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xfc\\x02\\x26\\xd4\\x02\\x1c\\x36\\x00\\x28\\x04\\x00\\x00\\x00\\x00\\x18\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x26\\xa2\\x05\\x1c\\x15\\x0c\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x31\\x15\\x02\\x16\\x02\\x16\\x68\\x16\\x70\\x26\\xde\\x04\\x26\\xb2\\x04\\x1c\\x36\\x00\\x28\\x02\\x41\\x4d\\x18\\x02\\x41\\x4d\\x00\\x00\\x00\\x26\\x8a\\x07\\x1c\\x15\\x08\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x32\\x15\\x02\\x16\\x02\\x16\\x84\\x01\\x16\\x8c\\x01\\x26\\xa6\\x06\\x26\\xfe\\x05\\x1c\\x18\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x16\\x00\\x28\\x04\\x00\\x00\\x00\\x3f\\x18\\x04\\x00\\x00\\x00\\x3f\\x00\\x00\\x00\\x26\\xfe\\x08\\x1c\\x15\\x02\\x19\\x35\\x04\\x00\\x06\\x19\\x18\\x04\\x76\\x61\\x6c\\x33\\x15\\x02\\x16\\x02\\x16\\x6c\\x16\\x74\\x26\\xb2\\x08\\x26\\x8a\\x08\\x1c\\x36\\x00\\x28\\x04\\x01\\x00\\x00\\x00\\x18\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x98\\x05\\x16\\x02\\x00\\x28\\x22\\x70\\x61\\x72\\x71\\x75\\x65\\x74\\x2d\\x63\\x70\\x70\\x20\\x76\\x65\\x72\\x73\\x69\\x6f\\x6e\\x20\\x31\\x2e\\x35\\x2e\\x31\\x2d\\x53\\x4e\\x41\\x50\\x53\\x48\\x4f\\x54\\x19\\x5c\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x1c\\x00\\x00\\x00\\xc4\\x01\\x00\\x00\\x50\\x41\\x52\\x31',\n         #     #     ''\n         #     # ],\n         # },\n         # 'Avro' : {\n         #     'data_sample' : [\n-        #         '\\x4f\\x62\\x6a\\x01\\x04\\x16\\x61\\x76\\x72\\x6f\\x2e\\x73\\x63\\x68\\x65\\x6d\\x61\\x82\\x03\\x7b\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x72\\x65\\x63\\x6f\\x72\\x64\\x22\\x2c\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x72\\x6f\\x77\\x22\\x2c\\x22\\x66\\x69\\x65\\x6c\\x64\\x73\\x22\\x3a\\x5b\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x69\\x64\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x6c\\x6f\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x31\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x73\\x74\\x72\\x69\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x32\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x66\\x6c\\x6f\\x61\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x33\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x5d\\x7d\\x14\\x61\\x76\\x72\\x6f\\x2e\\x63\\x6f\\x64\\x65\\x63\\x08\\x6e\\x75\\x6c\\x6c\\x00\\x8d\\x1f\\xf2\\x17\\x71\\xa4\\x2e\\xe4\\xc9\\x0a\\x23\\x67\\x12\\xaa\\xc6\\xc0\\x02\\x14\\x00\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x8d\\x1f\\xf2\\x17\\x71\\xa4\\x2e\\xe4\\xc9\\x0a\\x23\\x67\\x12\\xaa\\xc6\\xc0',\n-        #         '\\x4f\\x62\\x6a\\x01\\x04\\x16\\x61\\x76\\x72\\x6f\\x2e\\x73\\x63\\x68\\x65\\x6d\\x61\\x82\\x03\\x7b\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x72\\x65\\x63\\x6f\\x72\\x64\\x22\\x2c\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x72\\x6f\\x77\\x22\\x2c\\x22\\x66\\x69\\x65\\x6c\\x64\\x73\\x22\\x3a\\x5b\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x69\\x64\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x6c\\x6f\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x31\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x73\\x74\\x72\\x69\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x32\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x66\\x6c\\x6f\\x61\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x33\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x5d\\x7d\\x14\\x61\\x76\\x72\\x6f\\x2e\\x63\\x6f\\x64\\x65\\x63\\x08\\x6e\\x75\\x6c\\x6c\\x00\\xeb\\x9d\\x51\\x82\\xf2\\x11\\x3d\\x0b\\xc5\\x92\\x97\\xb2\\x07\\x6d\\x72\\x5a\\x1e\\xac\\x02\\x02\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x04\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x06\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x08\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x0a\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x0c\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x0e\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x10\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x12\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x14\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x16\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x18\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x1a\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x1c\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x1e\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\xeb\\x9d\\x51\\x82\\xf2\\x11\\x3d\\x0b\\xc5\\x92\\x97\\xb2\\x07\\x6d\\x72\\x5a',\n-        #         '\\x4f\\x62\\x6a\\x01\\x04\\x16\\x61\\x76\\x72\\x6f\\x2e\\x73\\x63\\x68\\x65\\x6d\\x61\\x82\\x03\\x7b\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x72\\x65\\x63\\x6f\\x72\\x64\\x22\\x2c\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x72\\x6f\\x77\\x22\\x2c\\x22\\x66\\x69\\x65\\x6c\\x64\\x73\\x22\\x3a\\x5b\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x69\\x64\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x6c\\x6f\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x31\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x73\\x74\\x72\\x69\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x32\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x66\\x6c\\x6f\\x61\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x33\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x5d\\x7d\\x14\\x61\\x76\\x72\\x6f\\x2e\\x63\\x6f\\x64\\x65\\x63\\x08\\x6e\\x75\\x6c\\x6c\\x00\\x73\\x65\\x4f\\x7c\\xd9\\x33\\xe1\\x18\\xdd\\x30\\xe8\\x22\\x2a\\x58\\x20\\x6f\\x02\\x14\\x00\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x73\\x65\\x4f\\x7c\\xd9\\x33\\xe1\\x18\\xdd\\x30\\xe8\\x22\\x2a\\x58\\x20\\x6f',\n+        #         b'\\x4f\\x62\\x6a\\x01\\x04\\x16\\x61\\x76\\x72\\x6f\\x2e\\x73\\x63\\x68\\x65\\x6d\\x61\\x82\\x03\\x7b\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x72\\x65\\x63\\x6f\\x72\\x64\\x22\\x2c\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x72\\x6f\\x77\\x22\\x2c\\x22\\x66\\x69\\x65\\x6c\\x64\\x73\\x22\\x3a\\x5b\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x69\\x64\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x6c\\x6f\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x31\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x73\\x74\\x72\\x69\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x32\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x66\\x6c\\x6f\\x61\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x33\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x5d\\x7d\\x14\\x61\\x76\\x72\\x6f\\x2e\\x63\\x6f\\x64\\x65\\x63\\x08\\x6e\\x75\\x6c\\x6c\\x00\\x8d\\x1f\\xf2\\x17\\x71\\xa4\\x2e\\xe4\\xc9\\x0a\\x23\\x67\\x12\\xaa\\xc6\\xc0\\x02\\x14\\x00\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x8d\\x1f\\xf2\\x17\\x71\\xa4\\x2e\\xe4\\xc9\\x0a\\x23\\x67\\x12\\xaa\\xc6\\xc0',\n+        #         b'\\x4f\\x62\\x6a\\x01\\x04\\x16\\x61\\x76\\x72\\x6f\\x2e\\x73\\x63\\x68\\x65\\x6d\\x61\\x82\\x03\\x7b\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x72\\x65\\x63\\x6f\\x72\\x64\\x22\\x2c\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x72\\x6f\\x77\\x22\\x2c\\x22\\x66\\x69\\x65\\x6c\\x64\\x73\\x22\\x3a\\x5b\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x69\\x64\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x6c\\x6f\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x31\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x73\\x74\\x72\\x69\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x32\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x66\\x6c\\x6f\\x61\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x33\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x5d\\x7d\\x14\\x61\\x76\\x72\\x6f\\x2e\\x63\\x6f\\x64\\x65\\x63\\x08\\x6e\\x75\\x6c\\x6c\\x00\\xeb\\x9d\\x51\\x82\\xf2\\x11\\x3d\\x0b\\xc5\\x92\\x97\\xb2\\x07\\x6d\\x72\\x5a\\x1e\\xac\\x02\\x02\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x04\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x06\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x08\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x0a\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x0c\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x0e\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x10\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x12\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x14\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x16\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x18\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x1a\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x1c\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x1e\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\xeb\\x9d\\x51\\x82\\xf2\\x11\\x3d\\x0b\\xc5\\x92\\x97\\xb2\\x07\\x6d\\x72\\x5a',\n+        #         b'\\x4f\\x62\\x6a\\x01\\x04\\x16\\x61\\x76\\x72\\x6f\\x2e\\x73\\x63\\x68\\x65\\x6d\\x61\\x82\\x03\\x7b\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x72\\x65\\x63\\x6f\\x72\\x64\\x22\\x2c\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x72\\x6f\\x77\\x22\\x2c\\x22\\x66\\x69\\x65\\x6c\\x64\\x73\\x22\\x3a\\x5b\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x69\\x64\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x6c\\x6f\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x31\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x73\\x74\\x72\\x69\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x32\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x66\\x6c\\x6f\\x61\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x33\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x5d\\x7d\\x14\\x61\\x76\\x72\\x6f\\x2e\\x63\\x6f\\x64\\x65\\x63\\x08\\x6e\\x75\\x6c\\x6c\\x00\\x73\\x65\\x4f\\x7c\\xd9\\x33\\xe1\\x18\\xdd\\x30\\xe8\\x22\\x2a\\x58\\x20\\x6f\\x02\\x14\\x00\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x73\\x65\\x4f\\x7c\\xd9\\x33\\xe1\\x18\\xdd\\x30\\xe8\\x22\\x2a\\x58\\x20\\x6f',\n         #     ],\n         # },\n         'AvroConfluent': {\n             'data_sample': [\n                 avro_confluent_message(cluster.schema_registry_client,\n-                                       {'id': 0L, 'blockNo': 0, 'val1': unicode('AM'), 'val2': 0.5, \"val3\": 1}),\n+                                       {'id': 0, 'blockNo': 0, 'val1': str('AM'), 'val2': 0.5, \"val3\": 1}),\n \n-                ''.join(map(lambda id: avro_confluent_message(cluster.schema_registry_client,\n-                                                              {'id': id, 'blockNo': 0, 'val1': unicode('AM'),\n-                                                               'val2': 0.5, \"val3\": 1}), range(1, 16))),\n+                b''.join([avro_confluent_message(cluster.schema_registry_client,\n+                                                              {'id': id, 'blockNo': 0, 'val1': str('AM'),\n+                                                               'val2': 0.5, \"val3\": 1}) for id in range(1, 16)]),\n \n                 avro_confluent_message(cluster.schema_registry_client,\n-                                       {'id': 0L, 'blockNo': 0, 'val1': unicode('AM'), 'val2': 0.5, \"val3\": 1}),\n+                                       {'id': 0, 'blockNo': 0, 'val1': str('AM'), 'val2': 0.5, \"val3\": 1}),\n             ],\n             'extra_settings': \", format_avro_schema_registry_url='http://{}:{}'\".format(\n                 cluster.schema_registry_host,\n@@ -479,8 +478,8 @@ def test_kafka_formats(kafka_cluster):\n         # },\n     }\n \n-    for format_name, format_opts in all_formats.items():\n-        print('Set up {}'.format(format_name))\n+    for format_name, format_opts in list(all_formats.items()):\n+        print(('Set up {}'.format(format_name)))\n         topic_name = 'format_tests_{}'.format(format_name)\n         data_sample = format_opts['data_sample']\n         data_prefix = []\n@@ -513,8 +512,8 @@ def test_kafka_formats(kafka_cluster):\n \n     time.sleep(12)\n \n-    for format_name, format_opts in all_formats.items():\n-        print('Checking {}'.format(format_name))\n+    for format_name, format_opts in list(all_formats.items()):\n+        print(('Checking {}'.format(format_name)))\n         topic_name = 'format_tests_{}'.format(format_name)\n         # shift offsets by 1 if format supports empty value\n         offsets = [1, 2, 3] if format_opts.get('supports_empty_value', False) else [0, 1, 2]\n@@ -588,7 +587,7 @@ def kafka_cluster():\n         global kafka_id\n         cluster.start()\n         kafka_id = instance.cluster.kafka_docker_id\n-        print(\"kafka_id is {}\".format(kafka_id))\n+        print((\"kafka_id is {}\".format(kafka_id)))\n         yield cluster\n \n     finally:\n@@ -638,7 +637,7 @@ def test_kafka_settings_old_syntax(kafka_cluster):\n     kafka_check_result(result, True)\n \n     members = describe_consumer_group('old')\n-    assert members[0]['client_id'] == u'ClickHouse-instance-test-kafka'\n+    assert members[0]['client_id'] == 'ClickHouse-instance-test-kafka'\n     # text_desc = kafka_cluster.exec_in_container(kafka_cluster.get_container_id('kafka1'),\"kafka-consumer-groups --bootstrap-server localhost:9092 --describe --members --group old --verbose\"))\n \n \n@@ -679,7 +678,7 @@ def test_kafka_settings_new_syntax(kafka_cluster):\n     kafka_check_result(result, True)\n \n     members = describe_consumer_group('new')\n-    assert members[0]['client_id'] == u'instance test 1234'\n+    assert members[0]['client_id'] == 'instance test 1234'\n \n \n @pytest.mark.timeout(180)\n@@ -1124,7 +1123,7 @@ def test_kafka_flush_on_big_message(kafka_cluster):\n     while not received:\n         try:\n             offsets = client.list_consumer_group_offsets('flush')\n-            for topic, offset in offsets.items():\n+            for topic, offset in list(offsets.items()):\n                 if topic.topic == 'flush' and offset.offset == kafka_messages:\n                     received = True\n                     break\n@@ -1407,19 +1406,19 @@ def test_kafka_virtual_columns2(kafka_cluster):\n         SELECT value, _key, _topic, _partition, _offset, toUnixTimestamp(_timestamp), toUnixTimestamp64Milli(_timestamp_ms), _headers.name, _headers.value FROM test.kafka;\n         ''')\n \n-    producer = KafkaProducer(bootstrap_servers=\"localhost:9092\")\n+    producer = KafkaProducer(bootstrap_servers=\"localhost:9092\", value_serializer=producer_serializer, key_serializer=producer_serializer)\n \n     producer.send(topic='virt2_0', value=json.dumps({'value': 1}), partition=0, key='k1', timestamp_ms=1577836801001,\n                   headers=[('content-encoding', b'base64')])\n     producer.send(topic='virt2_0', value=json.dumps({'value': 2}), partition=0, key='k2', timestamp_ms=1577836802002,\n-                  headers=[('empty_value', ''), ('', 'empty name'), ('', ''), ('repetition', '1'), ('repetition', '2')])\n+                  headers=[('empty_value', b''), ('', b'empty name'), ('', b''), ('repetition', b'1'), ('repetition', b'2')])\n     producer.flush()\n     time.sleep(1)\n \n     producer.send(topic='virt2_0', value=json.dumps({'value': 3}), partition=1, key='k3', timestamp_ms=1577836803003,\n-                  headers=[('b', 'b'), ('a', 'a')])\n+                  headers=[('b', b'b'), ('a', b'a')])\n     producer.send(topic='virt2_0', value=json.dumps({'value': 4}), partition=1, key='k4', timestamp_ms=1577836804004,\n-                  headers=[('a', 'a'), ('b', 'b')])\n+                  headers=[('a', b'a'), ('b', b'b')])\n     producer.flush()\n     time.sleep(1)\n \n@@ -1436,8 +1435,8 @@ def test_kafka_virtual_columns2(kafka_cluster):\n \n     members = describe_consumer_group('virt2')\n     # pprint.pprint(members)\n-    members[0]['client_id'] = u'ClickHouse-instance-test-kafka-0'\n-    members[1]['client_id'] = u'ClickHouse-instance-test-kafka-1'\n+    members[0]['client_id'] = 'ClickHouse-instance-test-kafka-0'\n+    members[1]['client_id'] = 'ClickHouse-instance-test-kafka-1'\n \n     result = instance.query(\"SELECT * FROM test.view ORDER BY value\", ignore_error=True)\n \n@@ -1717,7 +1716,7 @@ def produce():\n \n     for consumer_index in range(NUMBER_OF_CONSURRENT_CONSUMERS):\n         table_name = 'kafka_consumer{}'.format(consumer_index)\n-        print(\"Setting up {}\".format(table_name))\n+        print((\"Setting up {}\".format(table_name)))\n \n         instance.query('''\n             DROP TABLE IF EXISTS test.{0};\n@@ -1744,14 +1743,14 @@ def produce():\n         # kafka_cluster.open_bash_shell('instance')\n         while int(\n                 instance.query(\"SELECT count() FROM test.destination WHERE _consumed_by='{}'\".format(table_name))) == 0:\n-            print(\"Waiting for test.kafka_consumer{} to start consume\".format(consumer_index))\n+            print((\"Waiting for test.kafka_consumer{} to start consume\".format(consumer_index)))\n             time.sleep(1)\n \n     cancel.set()\n \n     # I leave last one working by intent (to finish consuming after all rebalances)\n     for consumer_index in range(NUMBER_OF_CONSURRENT_CONSUMERS - 1):\n-        print(\"Dropping test.kafka_consumer{}\".format(consumer_index))\n+        print((\"Dropping test.kafka_consumer{}\".format(consumer_index)))\n         instance.query('DROP TABLE IF EXISTS test.kafka_consumer{}'.format(consumer_index))\n         while int(instance.query(\n                 \"SELECT count() FROM system.tables WHERE database='test' AND name='kafka_consumer{}'\".format(\n@@ -1766,9 +1765,9 @@ def produce():\n         if messages_consumed >= msg_index[0]:\n             break\n         time.sleep(1)\n-        print(\"Waiting for finishing consuming (have {}, should be {})\".format(messages_consumed, msg_index[0]))\n+        print((\"Waiting for finishing consuming (have {}, should be {})\".format(messages_consumed, msg_index[0])))\n \n-    print(instance.query('SELECT count(), uniqExact(key), max(key) + 1 FROM test.destination'))\n+    print((instance.query('SELECT count(), uniqExact(key), max(key) + 1 FROM test.destination')))\n \n     # Some queries to debug...\n     # SELECT * FROM test.destination where key in (SELECT key FROM test.destination group by key having count() <> 1)\n@@ -1793,7 +1792,7 @@ def produce():\n     result = int(instance.query('SELECT count() == uniqExact(key) FROM test.destination'))\n \n     for consumer_index in range(NUMBER_OF_CONSURRENT_CONSUMERS):\n-        print(\"kafka_consumer{}\".format(consumer_index))\n+        print((\"kafka_consumer{}\".format(consumer_index)))\n         table_name = 'kafka_consumer{}'.format(consumer_index)\n         instance.query('''\n             DROP TABLE IF EXISTS test.{0};\n@@ -2253,5 +2252,5 @@ def test_kafka_csv_with_thread_per_consumer(kafka_cluster):\n \n if __name__ == '__main__':\n     cluster.start()\n-    raw_input(\"Cluster created, press any key to destroy...\")\n+    input(\"Cluster created, press any key to destroy...\")\n     cluster.shutdown()\ndiff --git a/tests/integration/test_storage_kerberized_kafka/test.py b/tests/integration/test_storage_kerberized_kafka/test.py\nindex ec23d3409779..59fb043b5468 100644\n--- a/tests/integration/test_storage_kerberized_kafka/test.py\n+++ b/tests/integration/test_storage_kerberized_kafka/test.py\n@@ -56,8 +56,10 @@ def wait_kafka_is_available(max_retries=50):\n             time.sleep(1)\n \n \n+def producer_serializer(x):\n+    return x.encode() if isinstance(x, str) else x\n def kafka_produce(topic, messages, timestamp=None):\n-    producer = KafkaProducer(bootstrap_servers=\"localhost:9093\")\n+    producer = KafkaProducer(bootstrap_servers=\"localhost:9093\", value_serializer=producer_serializer)\n     for message in messages:\n         producer.send(topic=topic, value=message, timestamp_ms=timestamp)\n         producer.flush()\n@@ -142,5 +144,5 @@ def test_kafka_json_as_string_no_kdc(kafka_cluster):\n \n if __name__ == '__main__':\n     cluster.start()\n-    raw_input(\"Cluster created, press any key to destroy...\")\n+    input(\"Cluster created, press any key to destroy...\")\n     cluster.shutdown()\ndiff --git a/tests/integration/test_storage_mysql/test.py b/tests/integration/test_storage_mysql/test.py\nindex 83ef1e6c86a2..87033381e2cb 100644\n--- a/tests/integration/test_storage_mysql/test.py\n+++ b/tests/integration/test_storage_mysql/test.py\n@@ -179,6 +179,6 @@ def create_mysql_table(conn, tableName):\n \n if __name__ == '__main__':\n     with contextmanager(started_cluster)() as cluster:\n-        for name, instance in cluster.instances.items():\n-            print name, instance.ip_address\n-        raw_input(\"Cluster created, press any key to destroy...\")\n+        for name, instance in list(cluster.instances.items()):\n+            print(name, instance.ip_address)\n+        input(\"Cluster created, press any key to destroy...\")\ndiff --git a/tests/integration/test_storage_rabbitmq/test.py b/tests/integration/test_storage_rabbitmq/test.py\nindex 4d892eaa72c1..ab44d0ebea0c 100644\n--- a/tests/integration/test_storage_rabbitmq/test.py\n+++ b/tests/integration/test_storage_rabbitmq/test.py\n@@ -13,7 +13,7 @@\n from helpers.cluster import ClickHouseCluster\n from helpers.test_tools import TSV\n \n-import rabbitmq_pb2\n+from . import rabbitmq_pb2\n \n cluster = ClickHouseCluster(__file__)\n instance = cluster.add_instance('instance',\n@@ -103,7 +103,7 @@ def rabbitmq_cluster():\n         global rabbitmq_id\n         cluster.start()\n         rabbitmq_id = instance.cluster.rabbitmq_docker_id\n-        print(\"rabbitmq_id is {}\".format(rabbitmq_id))\n+        print((\"rabbitmq_id is {}\".format(rabbitmq_id)))\n         instance.query('CREATE DATABASE test')\n \n         yield cluster\n@@ -957,7 +957,7 @@ def test_rabbitmq_direct_exchange(rabbitmq_cluster):\n \n     num_tables = 5\n     for consumer_id in range(num_tables):\n-        print(\"Setting up table {}\".format(consumer_id))\n+        print((\"Setting up table {}\".format(consumer_id)))\n         instance.query('''\n             DROP TABLE IF EXISTS test.direct_exchange_{0};\n             DROP TABLE IF EXISTS test.direct_exchange_{0}_mv;\n@@ -1030,7 +1030,7 @@ def test_rabbitmq_fanout_exchange(rabbitmq_cluster):\n \n     num_tables = 5\n     for consumer_id in range(num_tables):\n-        print(\"Setting up table {}\".format(consumer_id))\n+        print((\"Setting up table {}\".format(consumer_id)))\n         instance.query('''\n             DROP TABLE IF EXISTS test.fanout_exchange_{0};\n             DROP TABLE IF EXISTS test.fanout_exchange_{0}_mv;\n@@ -1097,7 +1097,7 @@ def test_rabbitmq_topic_exchange(rabbitmq_cluster):\n \n     num_tables = 5\n     for consumer_id in range(num_tables):\n-        print(\"Setting up table {}\".format(consumer_id))\n+        print((\"Setting up table {}\".format(consumer_id)))\n         instance.query('''\n             DROP TABLE IF EXISTS test.topic_exchange_{0};\n             DROP TABLE IF EXISTS test.topic_exchange_{0}_mv;\n@@ -1116,7 +1116,7 @@ def test_rabbitmq_topic_exchange(rabbitmq_cluster):\n         '''.format(consumer_id))\n \n     for consumer_id in range(num_tables):\n-        print(\"Setting up table {}\".format(num_tables + consumer_id))\n+        print((\"Setting up table {}\".format(num_tables + consumer_id)))\n         instance.query('''\n             DROP TABLE IF EXISTS test.topic_exchange_{0};\n             DROP TABLE IF EXISTS test.topic_exchange_{0}_mv;\n@@ -1195,7 +1195,7 @@ def test_rabbitmq_hash_exchange(rabbitmq_cluster):\n     num_tables = 4\n     for consumer_id in range(num_tables):\n         table_name = 'rabbitmq_consumer{}'.format(consumer_id)\n-        print(\"Setting up {}\".format(table_name))\n+        print((\"Setting up {}\".format(table_name)))\n         instance.query('''\n             DROP TABLE IF EXISTS test.{0};\n             DROP TABLE IF EXISTS test.{0}_mv;\n@@ -1353,7 +1353,7 @@ def test_rabbitmq_headers_exchange(rabbitmq_cluster):\n \n     num_tables_to_receive = 2\n     for consumer_id in range(num_tables_to_receive):\n-        print(\"Setting up table {}\".format(consumer_id))\n+        print((\"Setting up table {}\".format(consumer_id)))\n         instance.query('''\n             DROP TABLE IF EXISTS test.headers_exchange_{0};\n             DROP TABLE IF EXISTS test.headers_exchange_{0}_mv;\n@@ -1372,7 +1372,7 @@ def test_rabbitmq_headers_exchange(rabbitmq_cluster):\n \n     num_tables_to_ignore = 2\n     for consumer_id in range(num_tables_to_ignore):\n-        print(\"Setting up table {}\".format(consumer_id + num_tables_to_receive))\n+        print((\"Setting up table {}\".format(consumer_id + num_tables_to_receive)))\n         instance.query('''\n             DROP TABLE IF EXISTS test.headers_exchange_{0};\n             DROP TABLE IF EXISTS test.headers_exchange_{0}_mv;\n@@ -1570,7 +1570,7 @@ def test_rabbitmq_many_consumers_to_each_queue(rabbitmq_cluster):\n \n     num_tables = 4\n     for table_id in range(num_tables):\n-        print(\"Setting up table {}\".format(table_id))\n+        print((\"Setting up table {}\".format(table_id)))\n         instance.query('''\n             DROP TABLE IF EXISTS test.many_consumers_{0};\n             DROP TABLE IF EXISTS test.many_consumers_{0}_mv;\n@@ -1864,5 +1864,5 @@ def produce():\n \n if __name__ == '__main__':\n     cluster.start()\n-    raw_input(\"Cluster created, press any key to destroy...\")\n+    input(\"Cluster created, press any key to destroy...\")\n     cluster.shutdown()\ndiff --git a/tests/integration/test_storage_s3/s3_mock/mock_s3.py b/tests/integration/test_storage_s3/s3_mock/mock_s3.py\nindex 5b422f6a73a5..d76fe4ac36df 100644\n--- a/tests/integration/test_storage_s3/s3_mock/mock_s3.py\n+++ b/tests/integration/test_storage_s3/s3_mock/mock_s3.py\n@@ -11,7 +11,7 @@ def infinite_redirect(_path):\n @route('/<_bucket>/<_path>')\n def server(_bucket, _path):\n     for name in request.headers:\n-        if name == 'Authorization' and request.headers[name] == u'Bearer TOKEN':\n+        if name == 'Authorization' and request.headers[name] == 'Bearer TOKEN':\n             return '1, 2, 3'\n     abort(403)\n \ndiff --git a/tests/integration/test_storage_s3/test.py b/tests/integration/test_storage_s3/test.py\nindex f752e72c6779..42dbeda47170 100644\n--- a/tests/integration/test_storage_s3/test.py\n+++ b/tests/integration/test_storage_s3/test.py\n@@ -2,8 +2,8 @@\n import json\n import logging\n import os\n+import io\n import random\n-import StringIO\n import threading\n import time\n \n@@ -61,18 +61,20 @@ def prepare_s3_bucket(cluster):\n \n \n def put_s3_file_content(cluster, bucket, filename, data):\n-    buf = StringIO.StringIO(data)\n+    buf = io.BytesIO(data)\n     cluster.minio_client.put_object(bucket, filename, buf, len(data))\n \n \n # Returns content of given S3 file as string.\n-def get_s3_file_content(cluster, bucket, filename):\n+def get_s3_file_content(cluster, bucket, filename, decode=True):\n     # type: (ClickHouseCluster, str) -> str\n \n     data = cluster.minio_client.get_object(bucket, filename)\n-    data_str = \"\"\n+    data_str = b\"\"\n     for chunk in data.stream():\n         data_str += chunk\n+    if decode:\n+        return data_str.decode()\n     return data_str\n \n \n@@ -231,7 +233,7 @@ def test_multipart_put(cluster, maybe_auth, positive):\n     one_line_length = 6  # 3 digits, 2 commas, 1 line separator.\n \n     # Generate data having size more than one part\n-    int_data = [[1, 2, 3] for i in range(csv_size_bytes / one_line_length)]\n+    int_data = [[1, 2, 3] for i in range(csv_size_bytes // one_line_length)]\n     csv_data = \"\".join([\"{},{},{}\\n\".format(x, y, z) for x, y, z in int_data])\n \n     assert len(csv_data) > min_part_size_bytes\n@@ -377,9 +379,9 @@ def test_storage_s3_get_gzip(cluster):\n         \"Norman Ortega,33\",\n         \"\"\n     ]\n-    buf = StringIO.StringIO()\n+    buf = io.BytesIO()\n     compressed = gzip.GzipFile(fileobj=buf, mode=\"wb\")\n-    compressed.write(\"\\n\".join(data))\n+    compressed.write((\"\\n\".join(data)).encode())\n     compressed.close()\n     put_s3_file_content(cluster, bucket, filename, buf.getvalue())\n \n@@ -459,9 +461,9 @@ def test_storage_s3_put_gzip(cluster):\n \n         run_query(instance, \"SELECT sum(id) FROM {}\".format(name)).splitlines() == [\"708\"]\n \n-        buf = StringIO.StringIO(get_s3_file_content(cluster, bucket, filename))\n+        buf = io.BytesIO(get_s3_file_content(cluster, bucket, filename, decode=False))\n         f = gzip.GzipFile(fileobj=buf, mode=\"rb\")\n-        uncompressed_content = f.read()\n+        uncompressed_content = f.read().decode()\n         assert sum([ int(i.split(',')[1]) for i in uncompressed_content.splitlines() ]) == 708\n     finally:\n         run_query(instance, \"DROP TABLE {}\".format(name))\ndiff --git a/tests/integration/test_system_queries/test.py b/tests/integration/test_system_queries/test.py\nindex 18a164da805d..7f5bce97805f 100644\n--- a/tests/integration/test_system_queries/test.py\n+++ b/tests/integration/test_system_queries/test.py\n@@ -26,9 +26,6 @@ def started_cluster():\n         instance = cluster.instances['ch1']\n         instance.query('CREATE DATABASE dictionaries ENGINE = Dictionary')\n         instance.query('CREATE TABLE dictionary_source (id UInt64, value UInt8) ENGINE = Memory')\n-        print instance.query('SELECT * FROM system.dictionaries FORMAT Vertical')\n-        print \"Started \", instance.ip_address\n-\n         yield cluster\n \n     finally:\n@@ -136,6 +133,6 @@ def test_SYSTEM_FLUSH_LOGS(started_cluster):\n \n if __name__ == '__main__':\n     with contextmanager(started_cluster)() as cluster:\n-        for name, instance in cluster.instances.items():\n-            print name, instance.ip_address\n-        raw_input(\"Cluster created, press any key to destroy...\")\n+        for name, instance in list(cluster.instances.items()):\n+            print(name, instance.ip_address)\n+        input(\"Cluster created, press any key to destroy...\")\ndiff --git a/tests/integration/test_ttl_move/test.py b/tests/integration/test_ttl_move/test.py\nindex 377ee0e5d754..751d15b8313c 100644\n--- a/tests/integration/test_ttl_move/test.py\n+++ b/tests/integration/test_ttl_move/test.py\n@@ -37,14 +37,6 @@ def started_cluster():\n         cluster.shutdown()\n \n \n-def get_random_string(length):\n-    symbols = bytes(string.ascii_uppercase + string.digits)\n-    result_list = bytearray([0]) * length\n-    for i in range(length):\n-        result_list[i] = random.choice(symbols)\n-    return str(result_list)\n-\n-\n def get_used_disks_for_table(node, table_name, partition=None):\n     if partition is None:\n         suffix = \"\"\n@@ -150,8 +142,8 @@ def test_inserts_to_disk_work(started_cluster, name, engine, positive):\n \n         data = []  # 10MB in total\n         for i in range(10):\n-            data.append((\"'{}'\".format(get_random_string(1024 * 1024)), \"toDateTime({})\".format(\n-                time.time() - 1 if i > 0 or positive else time.time() + 300)))  # 1MB row\n+            data.append((\"randomPrintableASCII(1024*1024)\", \"toDateTime({})\".format(\n+                time.time() - 1 if i > 0 or positive else time.time() + 300)))\n \n         node1.query(\"INSERT INTO {} (s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n         used_disks = get_used_disks_for_table(node1, name)\n@@ -199,7 +191,7 @@ def test_moves_work_after_storage_policy_change(started_cluster, name, engine):\n \n         data = []  # 10MB in total\n         for i in range(10):\n-            data.append((\"'{}'\".format(get_random_string(1024 * 1024)), \"toDateTime({})\".format(time_1)))  # 1MB row\n+            data.append((\"randomPrintableASCII(1024*1024)\", \"toDateTime({})\".format(time_1)))\n \n         node1.query(\"INSERT INTO {} (s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n         used_disks = get_used_disks_for_table(node1, name)\n@@ -247,8 +239,8 @@ def test_moves_to_disk_work(started_cluster, name, engine, positive):\n \n         data = []  # 10MB in total\n         for i in range(10):\n-            data.append((\"'{}'\".format(get_random_string(1024 * 1024)),\n-                         \"toDateTime({})\".format(time_1 if i > 0 or positive else time_2)))  # 1MB row\n+            data.append((\"randomPrintableASCII(1024*1024)\",\n+                         \"toDateTime({})\".format(time_1 if i > 0 or positive else time_2)))\n \n         node1.query(\"INSERT INTO {} (s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n         used_disks = get_used_disks_for_table(node1, name)\n@@ -295,7 +287,7 @@ def test_moves_to_volume_work(started_cluster, name, engine):\n             data = []  # 10MB in total\n             for i in range(5):\n                 data.append(\n-                    (str(p), \"'{}'\".format(get_random_string(1024 * 1024)), \"toDateTime({})\".format(time_1)))  # 1MB row\n+                    (str(p), \"randomPrintableASCII(1024*1024)\", \"toDateTime({})\".format(time_1)))\n \n             node1.query(\n                 \"INSERT INTO {} (p1, s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n@@ -342,8 +334,8 @@ def test_inserts_to_volume_work(started_cluster, name, engine, positive):\n         for p in range(2):\n             data = []  # 20MB in total\n             for i in range(10):\n-                data.append((str(p), \"'{}'\".format(get_random_string(1024 * 1024)), \"toDateTime({})\".format(\n-                    time.time() - 1 if i > 0 or positive else time.time() + 300)))  # 1MB row\n+                data.append((str(p), \"randomPrintableASCII(1024*1024)\", \"toDateTime({})\".format(\n+                    time.time() - 1 if i > 0 or positive else time.time() + 300)))\n \n             node1.query(\n                 \"INSERT INTO {} (p1, s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n@@ -376,9 +368,9 @@ def test_moves_to_disk_eventually_work(started_cluster, name, engine):\n \n         data = []  # 35MB in total\n         for i in range(35):\n-            data.append(get_random_string(1024 * 1024))  # 1MB row\n+            data.append(\"randomPrintableASCII(1024*1024)\")\n \n-        node1.query(\"INSERT INTO {} VALUES {}\".format(name_temp, \",\".join([\"('\" + x + \"')\" for x in data])))\n+        node1.query(\"INSERT INTO {} VALUES {}\".format(name_temp, \",\".join([\"(\" + x + \")\" for x in data])))\n         used_disks = get_used_disks_for_table(node1, name_temp)\n         assert set(used_disks) == {\"jbod2\"}\n \n@@ -395,7 +387,7 @@ def test_moves_to_disk_eventually_work(started_cluster, name, engine):\n         data = []  # 10MB in total\n         for i in range(10):\n             data.append(\n-                (\"'{}'\".format(get_random_string(1024 * 1024)), \"toDateTime({})\".format(time.time() - 1)))  # 1MB row\n+                (\"randomPrintableASCII(1024*1024)\", \"toDateTime({})\".format(time.time() - 1)))\n \n         node1.query(\"INSERT INTO {} (s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n         used_disks = get_used_disks_for_table(node1, name)\n@@ -431,8 +423,7 @@ def test_replicated_download_ttl_info(started_cluster):\n \n         node1.query(\"SYSTEM STOP MOVES {}\".format(name))\n \n-        node2.query(\"INSERT INTO {} (s1, d1) VALUES ('{}', toDateTime({}))\".format(name, get_random_string(1024 * 1024),\n-                                                                                   time.time() - 100))\n+        node2.query(\"INSERT INTO {} (s1, d1) VALUES (randomPrintableASCII(1024*1024), toDateTime({}))\".format(name, time.time() - 100))\n \n         assert set(get_used_disks_for_table(node2, name)) == {\"external\"}\n         time.sleep(1)\n@@ -482,8 +473,8 @@ def test_merges_to_disk_work(started_cluster, name, engine, positive):\n         for _ in range(2):\n             data = []  # 16MB in total\n             for i in range(8):\n-                data.append((\"'{}'\".format(get_random_string(1024 * 1024)),\n-                             \"toDateTime({})\".format(time_1 if i > 0 or positive else time_2)))  # 1MB row\n+                data.append((\"randomPrintableASCII(1024*1024)\",\n+                             \"toDateTime({})\".format(time_1 if i > 0 or positive else time_2)))\n \n             node1.query(\n                 \"INSERT INTO {} (s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n@@ -530,9 +521,9 @@ def test_merges_with_full_disk_work(started_cluster, name, engine):\n \n         data = []  # 35MB in total\n         for i in range(35):\n-            data.append(get_random_string(1024 * 1024))  # 1MB row\n+            data.append(\"randomPrintableASCII(1024*1024)\")\n \n-        node1.query(\"INSERT INTO {} VALUES {}\".format(name_temp, \",\".join([\"('\" + x + \"')\" for x in data])))\n+        node1.query(\"INSERT INTO {} VALUES {}\".format(name_temp, \",\".join([\"(\" + x + \")\" for x in data])))\n         used_disks = get_used_disks_for_table(node1, name_temp)\n         assert set(used_disks) == {\"jbod2\"}\n \n@@ -555,7 +546,7 @@ def test_merges_with_full_disk_work(started_cluster, name, engine):\n         for _ in range(2):\n             data = []  # 12MB in total\n             for i in range(6):\n-                data.append((\"'{}'\".format(get_random_string(1024 * 1024)), \"toDateTime({})\".format(time_1)))  # 1MB row\n+                data.append((\"randomPrintableASCII(1024*1024)\", \"toDateTime({})\".format(time_1)))  # 1MB row\n             node1.query(\n                 \"INSERT INTO {} (s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n \n@@ -612,7 +603,7 @@ def test_moves_after_merges_work(started_cluster, name, engine, positive):\n         for _ in range(2):\n             data = []  # 14MB in total\n             for i in range(7):\n-                data.append((\"'{}'\".format(get_random_string(1024 * 1024)),\n+                data.append((\"randomPrintableASCII(1024*1024)\",\n                              \"toDateTime({})\".format(time_1 if i > 0 or positive else time_2)))  # 1MB row\n \n             node1.query(\n@@ -674,7 +665,7 @@ def test_ttls_do_not_work_after_alter(started_cluster, name, engine, positive, b\n         data = []  # 10MB in total\n         for i in range(10):\n             data.append(\n-                (\"'{}'\".format(get_random_string(1024 * 1024)), \"toDateTime({})\".format(time.time() - 1)))  # 1MB row\n+                (\"randomPrintableASCII(1024*1024)\", \"toDateTime({})\".format(time.time() - 1)))  # 1MB row\n         node1.query(\"INSERT INTO {} (s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n \n         used_disks = get_used_disks_for_table(node1, name)\n@@ -706,7 +697,7 @@ def test_materialize_ttl_in_partition(started_cluster, name, engine):\n \n         data = []  # 5MB in total\n         for i in range(5):\n-            data.append((str(i), \"'{}'\".format(get_random_string(1024 * 1024)),\n+            data.append((str(i), \"randomPrintableASCII(1024*1024)\",\n                          \"toDateTime({})\".format(time.time() - 1)))  # 1MB row\n         node1.query(\n             \"INSERT INTO {} (p1, s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n@@ -808,9 +799,8 @@ def test_alter_multiple_ttls(started_cluster, name, engine, positive):\n             now = time.time()\n             for i in range(2):\n                 p1 = p\n-                s1 = get_random_string(1024 * 1024)  # 1MB\n                 d1 = now - 1 if i > 0 or positive else now + 300\n-                data.append(\"({}, '{}', toDateTime({}))\".format(p1, s1, d1))\n+                data.append(\"({}, randomPrintableASCII(1024*1024), toDateTime({}))\".format(p1, d1))\n             node1.query(\"INSERT INTO {name} (p1, s1, d1) VALUES {values}\".format(name=name, values=\",\".join(data)))\n \n         used_disks = get_used_disks_for_table(node1, name)\n@@ -970,7 +960,7 @@ def test_double_move_while_select(started_cluster, name, positive):\n         \"\"\".format(name=name))\n \n         node1.query(\n-            \"INSERT INTO {name} VALUES (1, '{string}')\".format(name=name, string=get_random_string(10 * 1024 * 1024)))\n+            \"INSERT INTO {name} VALUES (1, randomPrintableASCII(10*1024*1024))\".format(name=name))\n \n         parts = node1.query(\n             \"SELECT name FROM system.parts WHERE table = '{name}' AND active = 1\".format(name=name)).splitlines()\n@@ -991,11 +981,11 @@ def long_select():\n \n         # Fill jbod1 to force ClickHouse to make move of partition 1 to external.\n         node1.query(\n-            \"INSERT INTO {name} VALUES (2, '{string}')\".format(name=name, string=get_random_string(9 * 1024 * 1024)))\n+            \"INSERT INTO {name} VALUES (2, randomPrintableASCII(9*1024*1024))\".format(name=name))\n         node1.query(\n-            \"INSERT INTO {name} VALUES (3, '{string}')\".format(name=name, string=get_random_string(9 * 1024 * 1024)))\n+            \"INSERT INTO {name} VALUES (3, randomPrintableASCII(9*1024*1024))\".format(name=name))\n         node1.query(\n-            \"INSERT INTO {name} VALUES (4, '{string}')\".format(name=name, string=get_random_string(9 * 1024 * 1024)))\n+            \"INSERT INTO {name} VALUES (4, randomPrintableASCII(9*1024*1024))\".format(name=name))\n \n         time.sleep(1)\n \n@@ -1059,9 +1049,8 @@ def optimize_table(num):\n             data = []  # 6MB in total\n             now = time.time()\n             for i in range(2):\n-                s1 = get_random_string(1024 * 1024)  # 1MB\n                 d1 = now - 1 if positive else now + 300\n-                data.append(\"('{}', toDateTime({}))\".format(s1, d1))\n+                data.append(\"(randomPrintableASCII(1024*1024), toDateTime({}))\".format(d1))\n             values = \",\".join(data)\n             node1.query(\"INSERT INTO {name} (s1, d1) VALUES {values}\".format(name=name, values=values))\n \n@@ -1126,8 +1115,7 @@ def test_disabled_ttl_move_on_insert(started_cluster, name, dest_type, engine):\n \n         data = []  # 10MB in total\n         for i in range(10):\n-            data.append((\"'{}'\".format(get_random_string(1024 * 1024)), \"toDateTime({})\".format(\n-                time.time() - 1)))  # 1MB row\n+            data.append((\"randomPrintableASCII(1024*1024)\", \"toDateTime({})\".format(time.time() - 1)))\n \n         node1.query(\"INSERT INTO {} (s1, d1) VALUES {}\".format(name, \",\".join([\"(\" + \",\".join(x) + \")\" for x in data])))\n \ndiff --git a/tests/integration/test_ttl_replicated/test.py b/tests/integration/test_ttl_replicated/test.py\nindex 13fb779a6e69..cbf13c202209 100644\n--- a/tests/integration/test_ttl_replicated/test.py\n+++ b/tests/integration/test_ttl_replicated/test.py\n@@ -18,7 +18,7 @@ def started_cluster():\n         yield cluster\n \n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     finally:\n         cluster.shutdown()\ndiff --git a/tests/integration/test_user_ip_restrictions/test.py b/tests/integration/test_user_ip_restrictions/test.py\nindex 1f28fbde069f..a7344fd1a450 100644\n--- a/tests/integration/test_user_ip_restrictions/test.py\n+++ b/tests/integration/test_user_ip_restrictions/test.py\n@@ -63,7 +63,7 @@ def test_ipv4(setup_cluster):\n     except AssertionError:\n         raise\n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n \n def test_ipv6(setup_cluster):\n@@ -72,7 +72,7 @@ def test_ipv6(setup_cluster):\n             [\"bash\", \"-c\", \"/usr/bin/clickhouse client --host 2001:3984:3989::1:1000 --query 'select 1'\"],\n             privileged=True, user='root')\n     except Exception as ex:\n-        print ex\n+        print(ex)\n         assert False, \"allowed client with 2001:3984:3989:0:0:0:1:1111 cannot connect to server with allowed mask '2001:3984:3989:0:0:0:0:0/112'\"\n \n     try:\n@@ -90,4 +90,4 @@ def test_ipv6(setup_cluster):\n     except AssertionError:\n         raise\n     except Exception as ex:\n-        print ex\n+        print(ex)\ndiff --git a/tests/integration/test_user_zero_database_access/test_user_zero_database_access.py b/tests/integration/test_user_zero_database_access/test_user_zero_database_access.py\nindex c5ea7ed60a0b..dd3789cde571 100644\n--- a/tests/integration/test_user_zero_database_access/test_user_zero_database_access.py\n+++ b/tests/integration/test_user_zero_database_access/test_user_zero_database_access.py\n@@ -24,7 +24,7 @@ def test_user_zero_database_access(start_cluster):\n     except AssertionError:\n         raise\n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     try:\n         node.exec_in_container(\n@@ -47,7 +47,7 @@ def test_user_zero_database_access(start_cluster):\n     except AssertionError:\n         raise\n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     try:\n         node.exec_in_container(\n@@ -57,7 +57,7 @@ def test_user_zero_database_access(start_cluster):\n     except AssertionError:\n         raise\n     except Exception as ex:\n-        print ex\n+        print(ex)\n \n     try:\n         node.exec_in_container(\ndiff --git a/tests/integration/test_zookeeper_config/test.py b/tests/integration/test_zookeeper_config/test.py\nindex 9bc206d8da49..eb5ab2da98f3 100644\n--- a/tests/integration/test_zookeeper_config/test.py\n+++ b/tests/integration/test_zookeeper_config/test.py\n@@ -1,4 +1,4 @@\n-from __future__ import print_function\n+\n \n import time\n from os import path as p, unlink\n@@ -147,7 +147,7 @@ def test_secure_connection():\n \n     cluster = ClickHouseCluster(__file__, zookeeper_config_path='configs/zookeeper_config_with_ssl.xml')\n \n-    docker_compose = NamedTemporaryFile(delete=False)\n+    docker_compose = NamedTemporaryFile(mode='w+', delete=False)\n \n     docker_compose.write(\n         \"version: '2.3'\\nservices:\\n\" +\ndiff --git a/tests/perf_drafts/accurate_comparisons/accurate_comparisons.sh b/tests/perf_drafts/accurate_comparisons/accurate_comparisons.sh\nindex 2cd040cec632..cfd73b5b942e 100755\n--- a/tests/perf_drafts/accurate_comparisons/accurate_comparisons.sh\n+++ b/tests/perf_drafts/accurate_comparisons/accurate_comparisons.sh\n@@ -8,7 +8,7 @@ clickhouse-client -q \"INSERT INTO test.comparisons SELECT toInt64(rand64()) + nu\n function test_cmp {\n     echo -n \"$1 : \"\n     echo \"SELECT count() FROM test.comparisons WHERE ($1)\" | clickhouse-benchmark --max_threads=1 -i 20 -d 0 --json test.json 1>&2 2>/dev/null\n-    python2 -c \"import json; print '%.3f' % float(json.load(open('test.json'))['query_time_percentiles']['0'])\"\n+    python3 -c \"import json; print '%.3f' % float(json.load(open('test.json'))['query_time_percentiles']['0'])\"\n     rm test.json\n }\n \ndiff --git a/tests/queries/0_stateless/00386_long_in_pk.python b/tests/queries/0_stateless/00386_long_in_pk.python\nindex f189233d2997..ab5fc50d8e34 100644\n--- a/tests/queries/0_stateless/00386_long_in_pk.python\n+++ b/tests/queries/0_stateless/00386_long_in_pk.python\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n \n def gen_queries():\n     create_template = 'create table tab_00386 (a Int8, b String, c Tuple(Int8), d Tuple(Tuple(Int8)), e Tuple(Int8, String), f Tuple(Tuple(Int8, String))) engine = MergeTree order by ({}) partition by {}'\n@@ -45,9 +45,9 @@ def main():\n     for q in gen_queries():\n         resp = requests.post(url, data=q)\n         if resp.status_code != 200 or resp.text.strip() not in ('1', ''):\n-            print 'Query:', q\n-            print 'Code:', resp.status_code\n-            print resp.text\n+            print('Query:', q)\n+            print('Code:', resp.status_code)\n+            print(resp.text)\n             break\n \n if __name__ == \"__main__\":\ndiff --git a/tests/queries/0_stateless/00386_long_in_pk.sh b/tests/queries/0_stateless/00386_long_in_pk.sh\nindex 414a3dce32d3..8cad8f93a13d 100755\n--- a/tests/queries/0_stateless/00386_long_in_pk.sh\n+++ b/tests/queries/0_stateless/00386_long_in_pk.sh\n@@ -5,5 +5,5 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n # We should have correct env vars from shell_config.sh to run this test\n \n-python \"$CURDIR\"/00386_long_in_pk.python\n+python3 \"$CURDIR\"/00386_long_in_pk.python\n \ndiff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison.python b/tests/queries/0_stateless/00411_long_accurate_number_comparison.python\nindex 47c5d7f3d5b8..3c8a8f2ea25d 100644\n--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison.python\n+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison.python\n@@ -1,9 +1,9 @@\n-#!/usr/bin/env python\n-from __future__ import print_function\n-import os, itertools, urllib, urllib2, sys\n+#!/usr/bin/env python3\n+\n+import os, itertools, urllib.request, urllib.parse, urllib.error, urllib.request, urllib.error, urllib.parse, sys\n \n def get_ch_answer(query):\n-    return urllib.urlopen(os.environ.get('CLICKHOUSE_URL', 'http://localhost:' + os.environ.get('CLICKHOUSE_PORT_HTTP', '8123') ), data=query).read()\n+    return urllib.request.urlopen(os.environ.get('CLICKHOUSE_URL', 'http://localhost:' + os.environ.get('CLICKHOUSE_PORT_HTTP', '8123') ), data=query.encode()).read().decode()\n \n def check_answers(query, answer):\n     ch_answer = get_ch_answer(query)\n@@ -83,9 +83,9 @@ def test_pair(v1, v2):\n     answers += a\n \n     if TEST_WITH_CASTING:\n-        for t1 in TYPES.iterkeys():\n+        for t1 in TYPES.keys():\n             if inside_range(v1, t1):\n-                for t2 in TYPES.iterkeys():\n+                for t2 in TYPES.keys():\n                     if inside_range(v2, t2):\n                         q, a = test_operators(v1, v2, 'to{}({})'.format(t1, v1), 'to{}({})'.format(t2, v2))\n                         query += ', ' + q\n@@ -108,7 +108,7 @@ def test_float_pair(i, f):\n     answers += a\n \n     if TEST_WITH_CASTING:\n-        for t1 in TYPES.iterkeys():\n+        for t1 in TYPES.keys():\n             if inside_range(i, t1):\n                 q, a = test_operators(i, f, 'to{}({})'.format(t1, i), f_str)\n                 query += ', ' + q\n@@ -127,9 +127,9 @@ def main():\n     num_int_tests = len(list(itertools.combinations(VALUES, 2)))\n \n     num_parts = 4\n-    for part in xrange(0, num_parts):\n+    for part in range(0, num_parts):\n         if 'int' + str(part + 1) in sys.argv[1:]:\n-            for (v1, v2) in itertools.islice(itertools.combinations(VALUES, 2), part * num_int_tests / num_parts, (part + 1) * num_int_tests / num_parts):\n+            for (v1, v2) in itertools.islice(itertools.combinations(VALUES, 2), part * num_int_tests // num_parts, (part + 1) * num_int_tests // num_parts):\n                 q, a = test_pair(v1, v2)\n                 if GENERATE_TEST_FILES:\n                     sql_file.write(q + \";\\n\")\ndiff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison_float.sh b/tests/queries/0_stateless/00411_long_accurate_number_comparison_float.sh\nindex 50a6cd386aee..17d0c7564e36 100755\n--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison_float.sh\n+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison_float.sh\n@@ -5,4 +5,4 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n # We should have correct env vars from shell_config.sh to run this test\n \n-python \"$CURDIR\"/00411_long_accurate_number_comparison.python float\n+python3 \"$CURDIR\"/00411_long_accurate_number_comparison.python float\ndiff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int1.sh b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int1.sh\nindex 8aba65d89116..43d9d550ddf8 100755\n--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int1.sh\n+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int1.sh\n@@ -5,4 +5,4 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n # We should have correct env vars from shell_config.sh to run this test\n \n-python \"$CURDIR\"/00411_long_accurate_number_comparison.python int1\n+python3 \"$CURDIR\"/00411_long_accurate_number_comparison.python int1\ndiff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int2.sh b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int2.sh\nindex 93001184144d..34aaf9ef7edf 100755\n--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int2.sh\n+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int2.sh\n@@ -5,4 +5,4 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n # We should have correct env vars from shell_config.sh to run this test\n \n-python \"$CURDIR\"/00411_long_accurate_number_comparison.python int2\n+python3 \"$CURDIR\"/00411_long_accurate_number_comparison.python int2\ndiff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int3.sh b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int3.sh\nindex 08ef31863b51..139792944ee6 100755\n--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int3.sh\n+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int3.sh\n@@ -5,4 +5,4 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n # We should have correct env vars from shell_config.sh to run this test\n \n-python \"$CURDIR\"/00411_long_accurate_number_comparison.python int3\n+python3 \"$CURDIR\"/00411_long_accurate_number_comparison.python int3\ndiff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int4.sh b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int4.sh\nindex a268066725b3..f57099e77cab 100755\n--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int4.sh\n+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int4.sh\n@@ -5,4 +5,4 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n # We should have correct env vars from shell_config.sh to run this test\n \n-python \"$CURDIR\"/00411_long_accurate_number_comparison.python int4\n+python3 \"$CURDIR\"/00411_long_accurate_number_comparison.python int4\ndiff --git a/tests/queries/0_stateless/00565_enum_order.sh b/tests/queries/0_stateless/00565_enum_order.sh\nindex d7d06b49108e..2851bcaaca26 100755\n--- a/tests/queries/0_stateless/00565_enum_order.sh\n+++ b/tests/queries/0_stateless/00565_enum_order.sh\n@@ -42,7 +42,7 @@ QUERY='INSERT INTO \"test_log\"(\"date\", \"datetime\", \"path\", \"gtid\", \"query_serial\"\n     \"new_fields\".\"is_null\", \"record_source_type\", \"record_source_timestamp\", \"deleted\") FORMAT TabSeparated'\n QUERY=\"$(tr -d '\\n' <<<\"$QUERY\")\"\n echo \"$QUERY\"\n-URL=$(python -c 'print \"'\"${CLICKHOUSE_URL}\"'&query=\" + __import__(\"urllib\").quote('\"'''$QUERY'''\"')')\n+URL=$(python3 -c 'import urllib.parse; print(\"'\"${CLICKHOUSE_URL}\"'&query=\" + urllib.parse.quote('\"'''$QUERY'''\"'))')\n \n set +e\n for _ in 1 2 3; do\ndiff --git a/tests/queries/0_stateless/00612_http_max_query_size.sh b/tests/queries/0_stateless/00612_http_max_query_size.sh\nindex a50155edab05..78ae4eba1dc5 100755\n--- a/tests/queries/0_stateless/00612_http_max_query_size.sh\n+++ b/tests/queries/0_stateless/00612_http_max_query_size.sh\n@@ -28,20 +28,20 @@ if not url.startswith('http'):\n q = 'select sum(number) from (select * from system.numbers limit 10000000) where number = 0'\n \n def gen_data(q):\n-    yield q\n-    yield ''.join([' '] * (1024 - len(q)))\n+    yield q.encode()\n+    yield (''.join([' '] * (1024 - len(q)))).encode()\n \n     pattern = ''' or toString(number) = '{}'\\n'''\n \n     for i in range(1, 4 * 1024):\n-        yield pattern.format(str(i).zfill(1024 - len(pattern) + 2))\n+        yield pattern.format(str(i).zfill(1024 - len(pattern) + 2)).encode()\n \n s = requests.Session()\n resp = s.post(url + '&max_query_size={}'.format(1 << 21), timeout=1, data=gen_data(q), stream=True,\n               headers = {'Connection': 'close'})\n \n for line in resp.iter_lines():\n-    print line\n-\" | python | grep -o \"Max query size exceeded\"\n+    print(line)\n+\" | python3 | grep -o \"Max query size exceeded\"\n echo -\n \ndiff --git a/tests/queries/0_stateless/00646_url_engine.python b/tests/queries/0_stateless/00646_url_engine.python\nindex c03ce51c9a9f..6a70fac21f30 100644\n--- a/tests/queries/0_stateless/00646_url_engine.python\n+++ b/tests/queries/0_stateless/00646_url_engine.python\n@@ -1,14 +1,21 @@\n-#!/usr/bin/env python\n-from __future__ import print_function\n+#!/usr/bin/env python3\n+\n+import socket\n import csv\n import sys\n-import time\n import tempfile\n import threading\n-import os, urllib\n+import os\n+import traceback\n+import urllib.request\n import subprocess\n from io import StringIO\n-from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer\n+from http.server import BaseHTTPRequestHandler, HTTPServer\n+\n+def get_local_port(host):\n+    with socket.socket() as fd:\n+        fd.bind((host, 0))\n+        return fd.getsockname()[1]\n \n CLICKHOUSE_HOST = os.environ.get('CLICKHOUSE_HOST', '127.0.0.1')\n CLICKHOUSE_PORT_HTTP = os.environ.get('CLICKHOUSE_PORT_HTTP', '8123')\n@@ -21,7 +28,7 @@ CLICKHOUSE_PORT_HTTP = os.environ.get('CLICKHOUSE_PORT_HTTP', '8123')\n \n # IP-address of this host accessible from outside world.\n HTTP_SERVER_HOST = subprocess.check_output(['hostname', '-i']).decode('utf-8').strip()\n-HTTP_SERVER_PORT = 55123\n+HTTP_SERVER_PORT = get_local_port(HTTP_SERVER_HOST)\n \n # IP address and port of the HTTP server started from this script.\n HTTP_SERVER_ADDRESS = (HTTP_SERVER_HOST, HTTP_SERVER_PORT)\n@@ -30,7 +37,7 @@ CSV_DATA = os.path.join(tempfile._get_default_tempdir(), next(tempfile._get_cand\n \n def get_ch_answer(query):\n     url = os.environ.get('CLICKHOUSE_URL', 'http://{host}:{port}'.format(host=CLICKHOUSE_HOST, port=CLICKHOUSE_PORT_HTTP))\n-    return urllib.urlopen(url, data=query).read()\n+    return urllib.request.urlopen(url, data=query.encode()).read().decode()\n \n def check_answers(query, answer):\n     ch_answer = get_ch_answer(query)\n@@ -51,7 +58,7 @@ class CSVHTTPServer(BaseHTTPRequestHandler):\n         with open(CSV_DATA, 'r') as fl:\n             reader = csv.reader(fl, delimiter=',')\n             for row in reader:\n-                self.wfile.write(', '.join(row) + '\\n')\n+                self.wfile.write((', '.join(row) + '\\n').encode())\n         return\n \n     def read_chunk(self):\n@@ -77,14 +84,13 @@ class CSVHTTPServer(BaseHTTPRequestHandler):\n             if not chunk:\n                 break\n             data += chunk\n-        text = \"\"\n         with StringIO(data) as fl:\n             reader = csv.reader(fl, delimiter=',')\n             with open(CSV_DATA, 'a') as d:\n                 for row in reader:\n                     d.write(','.join(row) + '\\n')\n         self._set_headers()\n-        self.wfile.write(\"ok\")\n+        self.wfile.write(b\"ok\")\n \n     def log_message(self, format, *args):\n         return\n@@ -93,7 +99,7 @@ def start_server(requests_amount):\n     httpd = HTTPServer(HTTP_SERVER_ADDRESS, CSVHTTPServer)\n \n     def real_func():\n-        for i in xrange(requests_amount):\n+        for i in range(requests_amount):\n             httpd.handle_request()\n \n     t = threading.Thread(target=real_func)\n@@ -113,7 +119,7 @@ def test_select(table_name=\"\", schema=\"str String,numuint UInt32,numint Int32,do\n         get_ch_answer(\"drop table if exists {}\".format(table_name))\n         get_ch_answer(\"create table {} ({}) engine=URL('{}', 'CSV')\".format(table_name, schema, HTTP_SERVER_URL_STR))\n \n-    for i in xrange(len(requests)):\n+    for i in range(len(requests)):\n         tbl = table_name\n         if not tbl:\n             tbl = \"url('{addr}', 'CSV', '{schema}')\".format(addr=HTTP_SERVER_URL_STR, schema=schema)\n@@ -137,7 +143,7 @@ def test_insert(table_name=\"\", schema=\"str String,numuint UInt32,numint Int32,do\n         get_ch_answer(req.format(tbl=tbl))\n \n \n-    for i in xrange(len(requests_select)):\n+    for i in range(len(requests_select)):\n         tbl = table_name\n         if not tbl:\n             tbl = \"url('{addr}', 'CSV', '{schema}')\".format(addr=HTTP_SERVER_URL_STR, schema=schema)\n@@ -161,7 +167,7 @@ def main():\n     ]\n \n     select_requests = {\n-        \"select distinct numuint from {tbl} order by numuint\": '\\n'.join([str(i) for i in xrange(11)]),\n+        \"select distinct numuint from {tbl} order by numuint\": '\\n'.join([str(i) for i in range(11)]),\n         \"select count(*) from {tbl}\": '12',\n         'select double, count(*) from {tbl} group by double': \"7.7\\t2\\n9.9\\t10\"\n     }\n@@ -169,27 +175,24 @@ def main():\n     t = start_server(len(select_only_requests) * 2 + (len(insert_requests) + len(select_requests)) * 2)\n     t.start()\n     # test table with url engine\n-    test_select(table_name=\"test_table_select\", requests=select_only_requests.keys(), answers=select_only_requests.values(), test_data=test_data)\n+    test_select(table_name=\"test_table_select\", requests=list(select_only_requests.keys()), answers=list(select_only_requests.values()), test_data=test_data)\n     # test table function url\n-    test_select(requests=select_only_requests.keys(), answers=select_only_requests.values(), test_data=test_data)\n+    test_select(requests=list(select_only_requests.keys()), answers=list(select_only_requests.values()), test_data=test_data)\n     #test insert into table with url engine\n-    test_insert(table_name=\"test_table_insert\", requests_insert=insert_requests, requests_select=select_requests.keys(), answers=select_requests.values())\n+    test_insert(table_name=\"test_table_insert\", requests_insert=insert_requests, requests_select=list(select_requests.keys()), answers=list(select_requests.values()))\n     #test insert into table function url\n-    test_insert(requests_insert=insert_requests, requests_select=select_requests.keys(), answers=select_requests.values())\n+    test_insert(requests_insert=insert_requests, requests_select=list(select_requests.keys()), answers=list(select_requests.values()))\n     t.join()\n     print(\"PASSED\")\n \n \n if __name__ == \"__main__\":\n-    exception_text = ''\n-    for i in range(1, 5):\n-        try:\n-            main()\n-            break\n-        except Exception as ex:\n-            exception_text = str(ex)\n-            time.sleep(0.1)\n-\n-    if exception_text:\n-        print(\"Exception: {}\".format(exception_text), file=sys.stderr)\n+    try:\n+        main()\n+    except Exception as ex:\n+        exc_type, exc_value, exc_traceback = sys.exc_info()\n+        traceback.print_tb(exc_traceback, file=sys.stderr)\n+        print(ex, file=sys.stderr)\n+        sys.stderr.flush()\n+\n         os._exit(1)\ndiff --git a/tests/queries/0_stateless/00646_url_engine.sh b/tests/queries/0_stateless/00646_url_engine.sh\nindex ee2e2521cf8d..bf20e0c1222d 100755\n--- a/tests/queries/0_stateless/00646_url_engine.sh\n+++ b/tests/queries/0_stateless/00646_url_engine.sh\n@@ -5,4 +5,4 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n # We should have correct env vars from shell_config.sh to run this test\n \n-python \"$CURDIR\"/00646_url_engine.python\n+python3 \"$CURDIR\"/00646_url_engine.python\ndiff --git a/tests/queries/0_stateless/00921_datetime64_compatibility.python b/tests/queries/0_stateless/00921_datetime64_compatibility.python\nindex 54630755f055..bf0ae8a72ac6 100755\n--- a/tests/queries/0_stateless/00921_datetime64_compatibility.python\n+++ b/tests/queries/0_stateless/00921_datetime64_compatibility.python\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # encoding: utf-8\n \n import re\n@@ -88,8 +88,7 @@ formatDateTime(N, '%C %d %D %e %F %H %I %j %m %M %p %R %S %T %u %V %w %y %Y %%')\n \n # Expanded later to cartesian product of all arguments.\n # NOTE: {N} to be turned into N after str.format() for keys (format string), but not for list of values!\n-extra_ops =\\\n-[\n+extra_ops = [\n     # With same type:\n     (\n         ['N {op} N'],\n@@ -161,37 +160,35 @@ extra_ops =\\\n \n # Expand extra_ops here\n for funcs, args in extra_ops:\n-    args_keys = args.keys()\n-    for args_vals in itertools.product(*args.values()):\n+    args_keys = list(args.keys())\n+    for args_vals in itertools.product(*list(args.values())):\n         for func in funcs:\n-            result_func = func.format(**dict(zip(args_keys, args_vals)))\n+            result_func = func.format(**dict(list(zip(args_keys, args_vals))))\n             FUNCTIONS.append(result_func)\n \n # filter out empty lines and commented out lines\n COMMENTED_OUT_LINE_RE = re.compile(r\"^\\s*#\")\n-FUNCTIONS = list(filter(lambda f: len(f) != 0 and COMMENTED_OUT_LINE_RE.match(f) == None, FUNCTIONS))\n+FUNCTIONS = list([f for f in FUNCTIONS if len(f) != 0 and COMMENTED_OUT_LINE_RE.match(f) == None])\n TYPES = ['D', 'DT', 'DT64']\n \n-if sys.version_info[0] > 2:\n-    escape_string_codec = 'unicode_escape'\n-else:\n-    escape_string_codec = 'string-escape'\n-\n def escape_string(s):\n-    return s.encode(escape_string_codec).decode('utf-8')\n+    if sys.version_info[0] > 2:\n+        return s.encode('unicode_escape').decode('utf-8').replace(\"'\", \"\\\\'\")\n+    else:\n+        return s.encode('string-escape').decode('utf-8')\n \n \n def execute_functions_for_types(functions, types):\n     # TODO: use string.Template here to allow lines that do not contain type, like: SELECT CAST(toDateTime64(1234567890), 'DateTime64')\n     for func in functions:\n-        print(\"\"\"SELECT 'SELECT {func}';\"\"\".format(func=escape_string(func)))\n+        print((\"\"\"SELECT 'SELECT {func}';\"\"\".format(func=escape_string(func))))\n         for dt in types:\n             prologue = \"\\\n WITH \\\n toDateTime64('2019-09-16 19:20:11.234', 3, 'Europe/Minsk') as DT64, \\\n toDateTime('2019-09-16 19:20:11', 'Europe/Minsk') as DT, \\\n toDate('2019-09-16') as D, {X} as N\".format(X=dt)\n-            print(\"\"\"{prologue} SELECT toTypeName(r), {func} as r FORMAT CSV;\"\"\".format(prologue=prologue, func=func))\n+            print((\"\"\"{prologue} SELECT toTypeName(r), {func} as r FORMAT CSV;\"\"\".format(prologue=prologue, func=func)))\n         print(\"\"\"SELECT '------------------------------------------';\"\"\")\n \n def main():\n@@ -210,22 +207,22 @@ def main():\n     types = TYPES\n \n     if args.functions_re:\n-        functions = list(filter(lambda f : args.functions_re.search(f), functions))\n+        functions = list([f for f in functions if args.functions_re.search(f)])\n         if len(functions) == 0:\n             print(\"functions list is empty\")\n             return -1\n \n     if args.types_re:\n-        types = list(filter(lambda t : args.types_re.match(t), types))\n+        types = list([t for t in types if args.types_re.match(t)])\n         if len(types) == 0:\n             print(\"types list is empty\")\n             return -1\n \n     if args.list_functions:\n-        print(\"\\n\".join(functions))\n+        print((\"\\n\".join(functions)))\n         return 0\n \n     execute_functions_for_types(functions, types)\n \n if __name__ == '__main__':\n-    exit(main())\n\\ No newline at end of file\n+    exit(main())\ndiff --git a/tests/queries/0_stateless/00921_datetime64_compatibility.reference b/tests/queries/0_stateless/00921_datetime64_compatibility.reference\nindex 079469c8c2d8..1a909c8c754d 100644\n--- a/tests/queries/0_stateless/00921_datetime64_compatibility.reference\n+++ b/tests/queries/0_stateless/00921_datetime64_compatibility.reference\n@@ -430,6 +430,36 @@ Code: 43: Illegal types DateTime('Europe/Minsk') and Date of arguments of functi\n \n Code: 43: Illegal types DateTime('Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n ------------------------------------------\n+SELECT N - D\n+\"Int32\",0\n+\n+Code: 43: Illegal types DateTime('Europe/Minsk') and Date of arguments of function minus.\n+\n+Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and Date of arguments of function minus.\n+------------------------------------------\n+SELECT D - N\n+\"Int32\",0\n+\n+Code: 43: Illegal types Date and DateTime('Europe/Minsk') of arguments of function minus.\n+\n+Code: 43: Illegal types Date and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n+------------------------------------------\n+SELECT N - DT64\n+\n+Code: 43: Illegal types Date and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n+\n+Code: 43: Illegal types DateTime('Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n+\n+Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n+------------------------------------------\n+SELECT DT64 - N\n+\n+Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and Date of arguments of function minus.\n+\n+Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime('Europe/Minsk') of arguments of function minus.\n+\n+Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n+------------------------------------------\n SELECT N != DT\n \"UInt8\",1\n \"UInt8\",0\n@@ -440,89 +470,65 @@ SELECT DT != N\n \"UInt8\",0\n \"UInt8\",1\n ------------------------------------------\n-SELECT N == DT\n+SELECT N != D\n \"UInt8\",0\n \"UInt8\",1\n-\"UInt8\",0\n+\"UInt8\",1\n ------------------------------------------\n-SELECT DT == N\n+SELECT D != N\n \"UInt8\",0\n \"UInt8\",1\n-\"UInt8\",0\n-------------------------------------------\n-SELECT N <  DT\n \"UInt8\",1\n-\"UInt8\",0\n-\"UInt8\",0\n ------------------------------------------\n-SELECT DT <  N\n-\"UInt8\",0\n-\"UInt8\",0\n+SELECT N != DT64\n+\"UInt8\",1\n \"UInt8\",1\n+\"UInt8\",0\n ------------------------------------------\n-SELECT N <= DT\n+SELECT DT64 != N\n \"UInt8\",1\n \"UInt8\",1\n \"UInt8\",0\n ------------------------------------------\n-SELECT DT <= N\n+SELECT N == DT\n \"UInt8\",0\n \"UInt8\",1\n-\"UInt8\",1\n-------------------------------------------\n-SELECT N >  DT\n \"UInt8\",0\n+------------------------------------------\n+SELECT DT == N\n \"UInt8\",0\n \"UInt8\",1\n+\"UInt8\",0\n ------------------------------------------\n-SELECT DT >  N\n+SELECT N == D\n \"UInt8\",1\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N >= DT\n-\"UInt8\",0\n-\"UInt8\",1\n-\"UInt8\",1\n-------------------------------------------\n-SELECT DT >= N\n-\"UInt8\",1\n+SELECT D == N\n \"UInt8\",1\n \"UInt8\",0\n+\"UInt8\",0\n ------------------------------------------\n-SELECT N - D\n-\"Int32\",0\n-\n-Code: 43: Illegal types DateTime('Europe/Minsk') and Date of arguments of function minus.\n-\n-Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and Date of arguments of function minus.\n-------------------------------------------\n-SELECT D - N\n-\"Int32\",0\n-\n-Code: 43: Illegal types Date and DateTime('Europe/Minsk') of arguments of function minus.\n-\n-Code: 43: Illegal types Date and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n-------------------------------------------\n-SELECT N != D\n+SELECT N == DT64\n+\"UInt8\",0\n \"UInt8\",0\n-\"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT D != N\n+SELECT DT64 == N\n+\"UInt8\",0\n \"UInt8\",0\n-\"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N == D\n+SELECT N <  DT\n \"UInt8\",1\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT D == N\n-\"UInt8\",1\n+SELECT DT <  N\n \"UInt8\",0\n \"UInt8\",0\n+\"UInt8\",1\n ------------------------------------------\n SELECT N <  D\n \"UInt8\",0\n@@ -534,100 +540,94 @@ SELECT D <  N\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <= D\n+SELECT N <  DT64\n \"UInt8\",1\n+\"UInt8\",1\n+\"UInt8\",0\n+------------------------------------------\n+SELECT DT64 <  N\n+\"UInt8\",0\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT D <= N\n-\"UInt8\",1\n+SELECT N <= DT\n \"UInt8\",1\n \"UInt8\",1\n+\"UInt8\",0\n ------------------------------------------\n-SELECT N >  D\n+SELECT DT <= N\n \"UInt8\",0\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT D >  N\n-\"UInt8\",0\n+SELECT N <= D\n+\"UInt8\",1\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N >= D\n+SELECT D <= N\n \"UInt8\",1\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT D >= N\n+SELECT N <= DT64\n \"UInt8\",1\n-\"UInt8\",0\n-\"UInt8\",0\n-------------------------------------------\n-SELECT N - DT64\n-\n-Code: 43: Illegal types Date and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n-\n-Code: 43: Illegal types DateTime('Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n-\n-Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n-------------------------------------------\n-SELECT DT64 - N\n-\n-Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and Date of arguments of function minus.\n-\n-Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime('Europe/Minsk') of arguments of function minus.\n-\n-Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.\n-------------------------------------------\n-SELECT N != DT64\n \"UInt8\",1\n \"UInt8\",1\n-\"UInt8\",0\n ------------------------------------------\n-SELECT DT64 != N\n-\"UInt8\",1\n-\"UInt8\",1\n+SELECT DT64 <= N\n \"UInt8\",0\n+\"UInt8\",0\n+\"UInt8\",1\n ------------------------------------------\n-SELECT N == DT64\n+SELECT N >  DT\n \"UInt8\",0\n \"UInt8\",0\n \"UInt8\",1\n ------------------------------------------\n-SELECT DT64 == N\n+SELECT DT >  N\n+\"UInt8\",1\n \"UInt8\",0\n \"UInt8\",0\n-\"UInt8\",1\n ------------------------------------------\n-SELECT N <  DT64\n+SELECT N >  D\n+\"UInt8\",0\n \"UInt8\",1\n \"UInt8\",1\n+------------------------------------------\n+SELECT D >  N\n+\"UInt8\",0\n+\"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT DT64 <  N\n+SELECT N >  DT64\n \"UInt8\",0\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N <= DT64\n-\"UInt8\",1\n+SELECT DT64 >  N\n \"UInt8\",1\n \"UInt8\",1\n-------------------------------------------\n-SELECT DT64 <= N\n \"UInt8\",0\n+------------------------------------------\n+SELECT N >= DT\n \"UInt8\",0\n \"UInt8\",1\n+\"UInt8\",1\n ------------------------------------------\n-SELECT N >  DT64\n-\"UInt8\",0\n-\"UInt8\",0\n+SELECT DT >= N\n+\"UInt8\",1\n+\"UInt8\",1\n \"UInt8\",0\n ------------------------------------------\n-SELECT DT64 >  N\n+SELECT N >= D\n+\"UInt8\",1\n \"UInt8\",1\n \"UInt8\",1\n+------------------------------------------\n+SELECT D >= N\n+\"UInt8\",1\n+\"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n SELECT N >= DT64\n@@ -650,6 +650,76 @@ SELECT toUInt8(1) +  N\n \"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n \"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n ------------------------------------------\n+SELECT N +  toInt8(-1)\n+\"Date\",\"2019-09-15\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n+------------------------------------------\n+SELECT toInt8(-1) +  N\n+\"Date\",\"2019-09-15\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n+------------------------------------------\n+SELECT N +  toUInt16(1)\n+\"Date\",\"2019-09-17\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n+------------------------------------------\n+SELECT toUInt16(1) +  N\n+\"Date\",\"2019-09-17\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n+------------------------------------------\n+SELECT N +  toInt16(-1)\n+\"Date\",\"2019-09-15\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n+------------------------------------------\n+SELECT toInt16(-1) +  N\n+\"Date\",\"2019-09-15\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n+------------------------------------------\n+SELECT N +  toUInt32(1)\n+\"Date\",\"2019-09-17\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n+------------------------------------------\n+SELECT toUInt32(1) +  N\n+\"Date\",\"2019-09-17\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n+------------------------------------------\n+SELECT N +  toInt32(-1)\n+\"Date\",\"2019-09-15\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n+------------------------------------------\n+SELECT toInt32(-1) +  N\n+\"Date\",\"2019-09-15\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n+------------------------------------------\n+SELECT N +  toUInt64(1)\n+\"Date\",\"2019-09-17\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n+------------------------------------------\n+SELECT toUInt64(1) +  N\n+\"Date\",\"2019-09-17\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n+------------------------------------------\n+SELECT N +  toInt64(-1)\n+\"Date\",\"2019-09-15\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n+------------------------------------------\n+SELECT toInt64(-1) +  N\n+\"Date\",\"2019-09-15\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n+------------------------------------------\n SELECT N -  toUInt8(1)\n \"Date\",\"2019-09-15\"\n \"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n@@ -663,94 +733,90 @@ Code: 43: Wrong order of arguments for function minus: argument of type Interval\n \n Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n ------------------------------------------\n-SELECT N == toUInt8(1)\n-\n-Code: 43: Illegal types of arguments (Date, UInt8) of function equals.\n-\"UInt8\",0\n-\"UInt8\",0\n-------------------------------------------\n-SELECT toUInt8(1) == N\n-\n-Code: 43: Illegal types of arguments (UInt8, Date) of function equals.\n-\"UInt8\",0\n-\"UInt8\",0\n+SELECT N -  toInt8(-1)\n+\"Date\",\"2019-09-17\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n ------------------------------------------\n-SELECT N != toUInt8(1)\n+SELECT toInt8(-1) -  N\n \n-Code: 43: Illegal types of arguments (Date, UInt8) of function notEquals.\n-\"UInt8\",1\n-\"UInt8\",1\n-------------------------------------------\n-SELECT toUInt8(1) != N\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n \n-Code: 43: Illegal types of arguments (UInt8, Date) of function notEquals.\n-\"UInt8\",1\n-\"UInt8\",1\n-------------------------------------------\n-SELECT N <  toUInt8(1)\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n \n-Code: 43: Illegal types of arguments (Date, UInt8) of function less.\n-\"UInt8\",0\n-\"UInt8\",0\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n ------------------------------------------\n-SELECT toUInt8(1) <  N\n-\n-Code: 43: Illegal types of arguments (UInt8, Date) of function less.\n-\"UInt8\",1\n-\"UInt8\",1\n+SELECT N -  toUInt16(1)\n+\"Date\",\"2019-09-15\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n ------------------------------------------\n-SELECT N <= toUInt8(1)\n+SELECT toUInt16(1) -  N\n \n-Code: 43: Illegal types of arguments (Date, UInt8) of function lessOrEquals.\n-\"UInt8\",0\n-\"UInt8\",0\n-------------------------------------------\n-SELECT toUInt8(1) <= N\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n \n-Code: 43: Illegal types of arguments (UInt8, Date) of function lessOrEquals.\n-\"UInt8\",1\n-\"UInt8\",1\n-------------------------------------------\n-SELECT N >  toUInt8(1)\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n \n-Code: 43: Illegal types of arguments (Date, UInt8) of function greater.\n-\"UInt8\",1\n-\"UInt8\",1\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n ------------------------------------------\n-SELECT toUInt8(1) >  N\n-\n-Code: 43: Illegal types of arguments (UInt8, Date) of function greater.\n-\"UInt8\",0\n-\"UInt8\",0\n+SELECT N -  toInt16(-1)\n+\"Date\",\"2019-09-17\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n ------------------------------------------\n-SELECT N >= toUInt8(1)\n+SELECT toInt16(-1) -  N\n \n-Code: 43: Illegal types of arguments (Date, UInt8) of function greaterOrEquals.\n-\"UInt8\",1\n-\"UInt8\",1\n-------------------------------------------\n-SELECT toUInt8(1) >= N\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n \n-Code: 43: Illegal types of arguments (UInt8, Date) of function greaterOrEquals.\n-\"UInt8\",0\n-\"UInt8\",0\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n ------------------------------------------\n-SELECT N +  toInt8(-1)\n+SELECT N -  toUInt32(1)\n \"Date\",\"2019-09-15\"\n \"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n \"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n ------------------------------------------\n-SELECT toInt8(-1) +  N\n+SELECT toUInt32(1) -  N\n+\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+------------------------------------------\n+SELECT N -  toInt32(-1)\n+\"Date\",\"2019-09-17\"\n+\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n+\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n+------------------------------------------\n+SELECT toInt32(-1) -  N\n+\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+------------------------------------------\n+SELECT N -  toUInt64(1)\n \"Date\",\"2019-09-15\"\n \"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n \"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n ------------------------------------------\n-SELECT N -  toInt8(-1)\n+SELECT toUInt64(1) -  N\n+\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+\n+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+------------------------------------------\n+SELECT N -  toInt64(-1)\n \"Date\",\"2019-09-17\"\n \"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n \"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n ------------------------------------------\n-SELECT toInt8(-1) -  N\n+SELECT toInt64(-1) -  N\n \n Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n \n@@ -758,6 +824,18 @@ Code: 43: Wrong order of arguments for function minus: argument of type Interval\n \n Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n ------------------------------------------\n+SELECT N == toUInt8(1)\n+\n+Code: 43: Illegal types of arguments (Date, UInt8) of function equals.\n+\"UInt8\",0\n+\"UInt8\",0\n+------------------------------------------\n+SELECT toUInt8(1) == N\n+\n+Code: 43: Illegal types of arguments (UInt8, Date) of function equals.\n+\"UInt8\",0\n+\"UInt8\",0\n+------------------------------------------\n SELECT N == toInt8(-1)\n \n Code: 43: Illegal types of arguments (Date, Int8) of function equals.\n@@ -770,196 +848,114 @@ Code: 43: Illegal types of arguments (Int8, Date) of function equals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N != toInt8(-1)\n-\n-Code: 43: Illegal types of arguments (Date, Int8) of function notEquals.\n-\"UInt8\",1\n-\"UInt8\",1\n-------------------------------------------\n-SELECT toInt8(-1) != N\n+SELECT N == toUInt16(1)\n \n-Code: 43: Illegal types of arguments (Int8, Date) of function notEquals.\n-\"UInt8\",1\n-\"UInt8\",1\n+Code: 43: Illegal types of arguments (Date, UInt16) of function equals.\n+\"UInt8\",0\n+\"UInt8\",0\n ------------------------------------------\n-SELECT N <  toInt8(-1)\n+SELECT toUInt16(1) == N\n \n-Code: 43: Illegal types of arguments (Date, Int8) of function less.\n+Code: 43: Illegal types of arguments (UInt16, Date) of function equals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toInt8(-1) <  N\n+SELECT N == toInt16(-1)\n \n-Code: 43: Illegal types of arguments (Int8, Date) of function less.\n-\"UInt8\",1\n-\"UInt8\",1\n+Code: 43: Illegal types of arguments (Date, Int16) of function equals.\n+\"UInt8\",0\n+\"UInt8\",0\n ------------------------------------------\n-SELECT N <= toInt8(-1)\n+SELECT toInt16(-1) == N\n \n-Code: 43: Illegal types of arguments (Date, Int8) of function lessOrEquals.\n+Code: 43: Illegal types of arguments (Int16, Date) of function equals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toInt8(-1) <= N\n+SELECT N == toUInt32(1)\n \n-Code: 43: Illegal types of arguments (Int8, Date) of function lessOrEquals.\n-\"UInt8\",1\n-\"UInt8\",1\n+Code: 43: Illegal types of arguments (Date, UInt32) of function equals.\n+\"UInt8\",0\n+\"UInt8\",0\n ------------------------------------------\n-SELECT N >  toInt8(-1)\n+SELECT toUInt32(1) == N\n \n-Code: 43: Illegal types of arguments (Date, Int8) of function greater.\n-\"UInt8\",1\n-\"UInt8\",1\n+Code: 43: Illegal types of arguments (UInt32, Date) of function equals.\n+\"UInt8\",0\n+\"UInt8\",0\n ------------------------------------------\n-SELECT toInt8(-1) >  N\n+SELECT N == toInt32(-1)\n \n-Code: 43: Illegal types of arguments (Int8, Date) of function greater.\n+Code: 43: Illegal types of arguments (Date, Int32) of function equals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N >= toInt8(-1)\n+SELECT toInt32(-1) == N\n \n-Code: 43: Illegal types of arguments (Date, Int8) of function greaterOrEquals.\n-\"UInt8\",1\n-\"UInt8\",1\n+Code: 43: Illegal types of arguments (Int32, Date) of function equals.\n+\"UInt8\",0\n+\"UInt8\",0\n ------------------------------------------\n-SELECT toInt8(-1) >= N\n+SELECT N == toUInt64(1)\n \n-Code: 43: Illegal types of arguments (Int8, Date) of function greaterOrEquals.\n+Code: 43: Illegal types of arguments (Date, UInt64) of function equals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N +  toUInt16(1)\n-\"Date\",\"2019-09-17\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n-------------------------------------------\n-SELECT toUInt16(1) +  N\n-\"Date\",\"2019-09-17\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n-------------------------------------------\n-SELECT N -  toUInt16(1)\n-\"Date\",\"2019-09-15\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n-------------------------------------------\n-SELECT toUInt16(1) -  N\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+SELECT toUInt64(1) == N\n \n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+Code: 43: Illegal types of arguments (UInt64, Date) of function equals.\n+\"UInt8\",0\n+\"UInt8\",0\n ------------------------------------------\n-SELECT N == toUInt16(1)\n+SELECT N == toInt64(-1)\n \n-Code: 43: Illegal types of arguments (Date, UInt16) of function equals.\n+Code: 43: Illegal types of arguments (Date, Int64) of function equals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toUInt16(1) == N\n+SELECT toInt64(-1) == N\n \n-Code: 43: Illegal types of arguments (UInt16, Date) of function equals.\n+Code: 43: Illegal types of arguments (Int64, Date) of function equals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N != toUInt16(1)\n+SELECT N != toUInt8(1)\n \n-Code: 43: Illegal types of arguments (Date, UInt16) of function notEquals.\n+Code: 43: Illegal types of arguments (Date, UInt8) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toUInt16(1) != N\n+SELECT toUInt8(1) != N\n \n-Code: 43: Illegal types of arguments (UInt16, Date) of function notEquals.\n+Code: 43: Illegal types of arguments (UInt8, Date) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <  toUInt16(1)\n-\n-Code: 43: Illegal types of arguments (Date, UInt16) of function less.\n-\"UInt8\",0\n-\"UInt8\",0\n-------------------------------------------\n-SELECT toUInt16(1) <  N\n+SELECT N != toInt8(-1)\n \n-Code: 43: Illegal types of arguments (UInt16, Date) of function less.\n+Code: 43: Illegal types of arguments (Date, Int8) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <= toUInt16(1)\n-\n-Code: 43: Illegal types of arguments (Date, UInt16) of function lessOrEquals.\n-\"UInt8\",0\n-\"UInt8\",0\n-------------------------------------------\n-SELECT toUInt16(1) <= N\n+SELECT toInt8(-1) != N\n \n-Code: 43: Illegal types of arguments (UInt16, Date) of function lessOrEquals.\n+Code: 43: Illegal types of arguments (Int8, Date) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N >  toUInt16(1)\n+SELECT N != toUInt16(1)\n \n-Code: 43: Illegal types of arguments (Date, UInt16) of function greater.\n+Code: 43: Illegal types of arguments (Date, UInt16) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toUInt16(1) >  N\n-\n-Code: 43: Illegal types of arguments (UInt16, Date) of function greater.\n-\"UInt8\",0\n-\"UInt8\",0\n-------------------------------------------\n-SELECT N >= toUInt16(1)\n+SELECT toUInt16(1) != N\n \n-Code: 43: Illegal types of arguments (Date, UInt16) of function greaterOrEquals.\n+Code: 43: Illegal types of arguments (UInt16, Date) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toUInt16(1) >= N\n-\n-Code: 43: Illegal types of arguments (UInt16, Date) of function greaterOrEquals.\n-\"UInt8\",0\n-\"UInt8\",0\n-------------------------------------------\n-SELECT N +  toInt16(-1)\n-\"Date\",\"2019-09-15\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n-------------------------------------------\n-SELECT toInt16(-1) +  N\n-\"Date\",\"2019-09-15\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n-------------------------------------------\n-SELECT N -  toInt16(-1)\n-\"Date\",\"2019-09-17\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n-------------------------------------------\n-SELECT toInt16(-1) -  N\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n-------------------------------------------\n-SELECT N == toInt16(-1)\n-\n-Code: 43: Illegal types of arguments (Date, Int16) of function equals.\n-\"UInt8\",0\n-\"UInt8\",0\n-------------------------------------------\n-SELECT toInt16(-1) == N\n-\n-Code: 43: Illegal types of arguments (Int16, Date) of function equals.\n-\"UInt8\",0\n-\"UInt8\",0\n-------------------------------------------\n SELECT N != toInt16(-1)\n \n Code: 43: Illegal types of arguments (Date, Int16) of function notEquals.\n@@ -972,98 +968,99 @@ Code: 43: Illegal types of arguments (Int16, Date) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <  toInt16(-1)\n+SELECT N != toUInt32(1)\n \n-Code: 43: Illegal types of arguments (Date, Int16) of function less.\n-\"UInt8\",0\n-\"UInt8\",0\n+Code: 43: Illegal types of arguments (Date, UInt32) of function notEquals.\n+\"UInt8\",1\n+\"UInt8\",1\n ------------------------------------------\n-SELECT toInt16(-1) <  N\n+SELECT toUInt32(1) != N\n \n-Code: 43: Illegal types of arguments (Int16, Date) of function less.\n+Code: 43: Illegal types of arguments (UInt32, Date) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <= toInt16(-1)\n+SELECT N != toInt32(-1)\n \n-Code: 43: Illegal types of arguments (Date, Int16) of function lessOrEquals.\n-\"UInt8\",0\n-\"UInt8\",0\n+Code: 43: Illegal types of arguments (Date, Int32) of function notEquals.\n+\"UInt8\",1\n+\"UInt8\",1\n ------------------------------------------\n-SELECT toInt16(-1) <= N\n+SELECT toInt32(-1) != N\n \n-Code: 43: Illegal types of arguments (Int16, Date) of function lessOrEquals.\n+Code: 43: Illegal types of arguments (Int32, Date) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N >  toInt16(-1)\n+SELECT N != toUInt64(1)\n \n-Code: 43: Illegal types of arguments (Date, Int16) of function greater.\n+Code: 43: Illegal types of arguments (Date, UInt64) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toInt16(-1) >  N\n+SELECT toUInt64(1) != N\n \n-Code: 43: Illegal types of arguments (Int16, Date) of function greater.\n-\"UInt8\",0\n-\"UInt8\",0\n+Code: 43: Illegal types of arguments (UInt64, Date) of function notEquals.\n+\"UInt8\",1\n+\"UInt8\",1\n ------------------------------------------\n-SELECT N >= toInt16(-1)\n+SELECT N != toInt64(-1)\n \n-Code: 43: Illegal types of arguments (Date, Int16) of function greaterOrEquals.\n+Code: 43: Illegal types of arguments (Date, Int64) of function notEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toInt16(-1) >= N\n+SELECT toInt64(-1) != N\n \n-Code: 43: Illegal types of arguments (Int16, Date) of function greaterOrEquals.\n+Code: 43: Illegal types of arguments (Int64, Date) of function notEquals.\n+\"UInt8\",1\n+\"UInt8\",1\n+------------------------------------------\n+SELECT N <  toUInt8(1)\n+\n+Code: 43: Illegal types of arguments (Date, UInt8) of function less.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N +  toUInt32(1)\n-\"Date\",\"2019-09-17\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n-------------------------------------------\n-SELECT toUInt32(1) +  N\n-\"Date\",\"2019-09-17\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n-------------------------------------------\n-SELECT N -  toUInt32(1)\n-\"Date\",\"2019-09-15\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n-------------------------------------------\n-SELECT toUInt32(1) -  N\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+SELECT toUInt8(1) <  N\n \n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+Code: 43: Illegal types of arguments (UInt8, Date) of function less.\n+\"UInt8\",1\n+\"UInt8\",1\n ------------------------------------------\n-SELECT N == toUInt32(1)\n+SELECT N <  toInt8(-1)\n \n-Code: 43: Illegal types of arguments (Date, UInt32) of function equals.\n+Code: 43: Illegal types of arguments (Date, Int8) of function less.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toUInt32(1) == N\n+SELECT toInt8(-1) <  N\n \n-Code: 43: Illegal types of arguments (UInt32, Date) of function equals.\n+Code: 43: Illegal types of arguments (Int8, Date) of function less.\n+\"UInt8\",1\n+\"UInt8\",1\n+------------------------------------------\n+SELECT N <  toUInt16(1)\n+\n+Code: 43: Illegal types of arguments (Date, UInt16) of function less.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N != toUInt32(1)\n+SELECT toUInt16(1) <  N\n \n-Code: 43: Illegal types of arguments (Date, UInt32) of function notEquals.\n+Code: 43: Illegal types of arguments (UInt16, Date) of function less.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toUInt32(1) != N\n+SELECT N <  toInt16(-1)\n \n-Code: 43: Illegal types of arguments (UInt32, Date) of function notEquals.\n+Code: 43: Illegal types of arguments (Date, Int16) of function less.\n+\"UInt8\",0\n+\"UInt8\",0\n+------------------------------------------\n+SELECT toInt16(-1) <  N\n+\n+Code: 43: Illegal types of arguments (Int16, Date) of function less.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n@@ -1079,98 +1076,99 @@ Code: 43: Illegal types of arguments (UInt32, Date) of function less.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <= toUInt32(1)\n+SELECT N <  toInt32(-1)\n \n-Code: 43: Illegal types of arguments (Date, UInt32) of function lessOrEquals.\n+Code: 43: Illegal types of arguments (Date, Int32) of function less.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toUInt32(1) <= N\n+SELECT toInt32(-1) <  N\n \n-Code: 43: Illegal types of arguments (UInt32, Date) of function lessOrEquals.\n+Code: 43: Illegal types of arguments (Int32, Date) of function less.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N >  toUInt32(1)\n+SELECT N <  toUInt64(1)\n \n-Code: 43: Illegal types of arguments (Date, UInt32) of function greater.\n+Code: 43: Illegal types of arguments (Date, UInt64) of function less.\n+\"UInt8\",0\n+\"UInt8\",0\n+------------------------------------------\n+SELECT toUInt64(1) <  N\n+\n+Code: 43: Illegal types of arguments (UInt64, Date) of function less.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toUInt32(1) >  N\n+SELECT N <  toInt64(-1)\n \n-Code: 43: Illegal types of arguments (UInt32, Date) of function greater.\n+Code: 43: Illegal types of arguments (Date, Int64) of function less.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N >= toUInt32(1)\n+SELECT toInt64(-1) <  N\n \n-Code: 43: Illegal types of arguments (Date, UInt32) of function greaterOrEquals.\n+Code: 43: Illegal types of arguments (Int64, Date) of function less.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toUInt32(1) >= N\n+SELECT N <= toUInt8(1)\n \n-Code: 43: Illegal types of arguments (UInt32, Date) of function greaterOrEquals.\n+Code: 43: Illegal types of arguments (Date, UInt8) of function lessOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N +  toInt32(-1)\n-\"Date\",\"2019-09-15\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n-------------------------------------------\n-SELECT toInt32(-1) +  N\n-\"Date\",\"2019-09-15\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n-------------------------------------------\n-SELECT N -  toInt32(-1)\n-\"Date\",\"2019-09-17\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n-------------------------------------------\n-SELECT toInt32(-1) -  N\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+SELECT toUInt8(1) <= N\n \n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+Code: 43: Illegal types of arguments (UInt8, Date) of function lessOrEquals.\n+\"UInt8\",1\n+\"UInt8\",1\n ------------------------------------------\n-SELECT N == toInt32(-1)\n+SELECT N <= toInt8(-1)\n \n-Code: 43: Illegal types of arguments (Date, Int32) of function equals.\n+Code: 43: Illegal types of arguments (Date, Int8) of function lessOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toInt32(-1) == N\n+SELECT toInt8(-1) <= N\n \n-Code: 43: Illegal types of arguments (Int32, Date) of function equals.\n+Code: 43: Illegal types of arguments (Int8, Date) of function lessOrEquals.\n+\"UInt8\",1\n+\"UInt8\",1\n+------------------------------------------\n+SELECT N <= toUInt16(1)\n+\n+Code: 43: Illegal types of arguments (Date, UInt16) of function lessOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N != toInt32(-1)\n+SELECT toUInt16(1) <= N\n \n-Code: 43: Illegal types of arguments (Date, Int32) of function notEquals.\n+Code: 43: Illegal types of arguments (UInt16, Date) of function lessOrEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toInt32(-1) != N\n+SELECT N <= toInt16(-1)\n \n-Code: 43: Illegal types of arguments (Int32, Date) of function notEquals.\n+Code: 43: Illegal types of arguments (Date, Int16) of function lessOrEquals.\n+\"UInt8\",0\n+\"UInt8\",0\n+------------------------------------------\n+SELECT toInt16(-1) <= N\n+\n+Code: 43: Illegal types of arguments (Int16, Date) of function lessOrEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <  toInt32(-1)\n+SELECT N <= toUInt32(1)\n \n-Code: 43: Illegal types of arguments (Date, Int32) of function less.\n+Code: 43: Illegal types of arguments (Date, UInt32) of function lessOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toInt32(-1) <  N\n+SELECT toUInt32(1) <= N\n \n-Code: 43: Illegal types of arguments (Int32, Date) of function less.\n+Code: 43: Illegal types of arguments (UInt32, Date) of function lessOrEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n@@ -1186,101 +1184,102 @@ Code: 43: Illegal types of arguments (Int32, Date) of function lessOrEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N >  toInt32(-1)\n-\n-Code: 43: Illegal types of arguments (Date, Int32) of function greater.\n-\"UInt8\",1\n-\"UInt8\",1\n-------------------------------------------\n-SELECT toInt32(-1) >  N\n+SELECT N <= toUInt64(1)\n \n-Code: 43: Illegal types of arguments (Int32, Date) of function greater.\n+Code: 43: Illegal types of arguments (Date, UInt64) of function lessOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N >= toInt32(-1)\n+SELECT toUInt64(1) <= N\n \n-Code: 43: Illegal types of arguments (Date, Int32) of function greaterOrEquals.\n+Code: 43: Illegal types of arguments (UInt64, Date) of function lessOrEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toInt32(-1) >= N\n+SELECT N <= toInt64(-1)\n \n-Code: 43: Illegal types of arguments (Int32, Date) of function greaterOrEquals.\n+Code: 43: Illegal types of arguments (Date, Int64) of function lessOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N +  toUInt64(1)\n-\"Date\",\"2019-09-17\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n-------------------------------------------\n-SELECT toUInt64(1) +  N\n-\"Date\",\"2019-09-17\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n-------------------------------------------\n-SELECT N -  toUInt64(1)\n-\"Date\",\"2019-09-15\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n-------------------------------------------\n-SELECT toUInt64(1) -  N\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+SELECT toInt64(-1) <= N\n \n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+Code: 43: Illegal types of arguments (Int64, Date) of function lessOrEquals.\n+\"UInt8\",1\n+\"UInt8\",1\n+------------------------------------------\n+SELECT N >  toUInt8(1)\n \n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+Code: 43: Illegal types of arguments (Date, UInt8) of function greater.\n+\"UInt8\",1\n+\"UInt8\",1\n ------------------------------------------\n-SELECT N == toUInt64(1)\n+SELECT toUInt8(1) >  N\n \n-Code: 43: Illegal types of arguments (Date, UInt64) of function equals.\n+Code: 43: Illegal types of arguments (UInt8, Date) of function greater.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toUInt64(1) == N\n+SELECT N >  toInt8(-1)\n \n-Code: 43: Illegal types of arguments (UInt64, Date) of function equals.\n+Code: 43: Illegal types of arguments (Date, Int8) of function greater.\n+\"UInt8\",1\n+\"UInt8\",1\n+------------------------------------------\n+SELECT toInt8(-1) >  N\n+\n+Code: 43: Illegal types of arguments (Int8, Date) of function greater.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N != toUInt64(1)\n+SELECT N >  toUInt16(1)\n \n-Code: 43: Illegal types of arguments (Date, UInt64) of function notEquals.\n+Code: 43: Illegal types of arguments (Date, UInt16) of function greater.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toUInt64(1) != N\n+SELECT toUInt16(1) >  N\n \n-Code: 43: Illegal types of arguments (UInt64, Date) of function notEquals.\n+Code: 43: Illegal types of arguments (UInt16, Date) of function greater.\n+\"UInt8\",0\n+\"UInt8\",0\n+------------------------------------------\n+SELECT N >  toInt16(-1)\n+\n+Code: 43: Illegal types of arguments (Date, Int16) of function greater.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <  toUInt64(1)\n+SELECT toInt16(-1) >  N\n \n-Code: 43: Illegal types of arguments (Date, UInt64) of function less.\n+Code: 43: Illegal types of arguments (Int16, Date) of function greater.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toUInt64(1) <  N\n+SELECT N >  toUInt32(1)\n \n-Code: 43: Illegal types of arguments (UInt64, Date) of function less.\n+Code: 43: Illegal types of arguments (Date, UInt32) of function greater.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <= toUInt64(1)\n+SELECT toUInt32(1) >  N\n \n-Code: 43: Illegal types of arguments (Date, UInt64) of function lessOrEquals.\n+Code: 43: Illegal types of arguments (UInt32, Date) of function greater.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toUInt64(1) <= N\n+SELECT N >  toInt32(-1)\n \n-Code: 43: Illegal types of arguments (UInt64, Date) of function lessOrEquals.\n+Code: 43: Illegal types of arguments (Date, Int32) of function greater.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n+SELECT toInt32(-1) >  N\n+\n+Code: 43: Illegal types of arguments (Int32, Date) of function greater.\n+\"UInt8\",0\n+\"UInt8\",0\n+------------------------------------------\n SELECT N >  toUInt64(1)\n \n Code: 43: Illegal types of arguments (Date, UInt64) of function greater.\n@@ -1293,98 +1292,99 @@ Code: 43: Illegal types of arguments (UInt64, Date) of function greater.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N >= toUInt64(1)\n+SELECT N >  toInt64(-1)\n \n-Code: 43: Illegal types of arguments (Date, UInt64) of function greaterOrEquals.\n+Code: 43: Illegal types of arguments (Date, Int64) of function greater.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toUInt64(1) >= N\n+SELECT toInt64(-1) >  N\n \n-Code: 43: Illegal types of arguments (UInt64, Date) of function greaterOrEquals.\n+Code: 43: Illegal types of arguments (Int64, Date) of function greater.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N +  toInt64(-1)\n-\"Date\",\"2019-09-15\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n-------------------------------------------\n-SELECT toInt64(-1) +  N\n-\"Date\",\"2019-09-15\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:10\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:10.234\"\n-------------------------------------------\n-SELECT N -  toInt64(-1)\n-\"Date\",\"2019-09-17\"\n-\"DateTime('Europe/Minsk')\",\"2019-09-16 19:20:12\"\n-\"DateTime64(3, 'Europe/Minsk')\",\"2019-09-16 19:20:12.234\"\n-------------------------------------------\n-SELECT toInt64(-1) -  N\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n-\n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+SELECT N >= toUInt8(1)\n \n-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..\n+Code: 43: Illegal types of arguments (Date, UInt8) of function greaterOrEquals.\n+\"UInt8\",1\n+\"UInt8\",1\n ------------------------------------------\n-SELECT N == toInt64(-1)\n+SELECT toUInt8(1) >= N\n \n-Code: 43: Illegal types of arguments (Date, Int64) of function equals.\n+Code: 43: Illegal types of arguments (UInt8, Date) of function greaterOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toInt64(-1) == N\n+SELECT N >= toInt8(-1)\n \n-Code: 43: Illegal types of arguments (Int64, Date) of function equals.\n+Code: 43: Illegal types of arguments (Date, Int8) of function greaterOrEquals.\n+\"UInt8\",1\n+\"UInt8\",1\n+------------------------------------------\n+SELECT toInt8(-1) >= N\n+\n+Code: 43: Illegal types of arguments (Int8, Date) of function greaterOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT N != toInt64(-1)\n+SELECT N >= toUInt16(1)\n \n-Code: 43: Illegal types of arguments (Date, Int64) of function notEquals.\n+Code: 43: Illegal types of arguments (Date, UInt16) of function greaterOrEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toInt64(-1) != N\n+SELECT toUInt16(1) >= N\n \n-Code: 43: Illegal types of arguments (Int64, Date) of function notEquals.\n+Code: 43: Illegal types of arguments (UInt16, Date) of function greaterOrEquals.\n+\"UInt8\",0\n+\"UInt8\",0\n+------------------------------------------\n+SELECT N >= toInt16(-1)\n+\n+Code: 43: Illegal types of arguments (Date, Int16) of function greaterOrEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <  toInt64(-1)\n+SELECT toInt16(-1) >= N\n \n-Code: 43: Illegal types of arguments (Date, Int64) of function less.\n+Code: 43: Illegal types of arguments (Int16, Date) of function greaterOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toInt64(-1) <  N\n+SELECT N >= toUInt32(1)\n \n-Code: 43: Illegal types of arguments (Int64, Date) of function less.\n+Code: 43: Illegal types of arguments (Date, UInt32) of function greaterOrEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N <= toInt64(-1)\n+SELECT toUInt32(1) >= N\n \n-Code: 43: Illegal types of arguments (Date, Int64) of function lessOrEquals.\n+Code: 43: Illegal types of arguments (UInt32, Date) of function greaterOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\n-SELECT toInt64(-1) <= N\n+SELECT N >= toInt32(-1)\n \n-Code: 43: Illegal types of arguments (Int64, Date) of function lessOrEquals.\n+Code: 43: Illegal types of arguments (Date, Int32) of function greaterOrEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT N >  toInt64(-1)\n+SELECT toInt32(-1) >= N\n \n-Code: 43: Illegal types of arguments (Date, Int64) of function greater.\n+Code: 43: Illegal types of arguments (Int32, Date) of function greaterOrEquals.\n+\"UInt8\",0\n+\"UInt8\",0\n+------------------------------------------\n+SELECT N >= toUInt64(1)\n+\n+Code: 43: Illegal types of arguments (Date, UInt64) of function greaterOrEquals.\n \"UInt8\",1\n \"UInt8\",1\n ------------------------------------------\n-SELECT toInt64(-1) >  N\n+SELECT toUInt64(1) >= N\n \n-Code: 43: Illegal types of arguments (Int64, Date) of function greater.\n+Code: 43: Illegal types of arguments (UInt64, Date) of function greaterOrEquals.\n \"UInt8\",0\n \"UInt8\",0\n ------------------------------------------\ndiff --git a/tests/queries/0_stateless/00960_live_view_watch_events_live.py b/tests/queries/0_stateless/00960_live_view_watch_events_live.py\nindex 3349175dee8b..780c31f20cad 100755\n--- a/tests/queries/0_stateless/00960_live_view_watch_events_live.py\n+++ b/tests/queries/0_stateless/00960_live_view_watch_events_live.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00962_temporary_live_view_watch_live.py b/tests/queries/0_stateless/00962_temporary_live_view_watch_live.py\nindex c6a5251fbeeb..073c8c88e2be 100755\n--- a/tests/queries/0_stateless/00962_temporary_live_view_watch_live.py\n+++ b/tests/queries/0_stateless/00962_temporary_live_view_watch_live.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00963_temporary_live_view_watch_live_timeout.py.disabled b/tests/queries/0_stateless/00963_temporary_live_view_watch_live_timeout.py.disabled\nindex 525e70221564..cfd218d5983b 100755\n--- a/tests/queries/0_stateless/00963_temporary_live_view_watch_live_timeout.py.disabled\n+++ b/tests/queries/0_stateless/00963_temporary_live_view_watch_live_timeout.py.disabled\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00964_live_view_watch_events_heartbeat.py b/tests/queries/0_stateless/00964_live_view_watch_events_heartbeat.py\nindex 794d04a429cc..03b598fe46f4 100755\n--- a/tests/queries/0_stateless/00964_live_view_watch_events_heartbeat.py\n+++ b/tests/queries/0_stateless/00964_live_view_watch_events_heartbeat.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00965_live_view_watch_heartbeat.py b/tests/queries/0_stateless/00965_live_view_watch_heartbeat.py\nindex 1d557f09f4d6..15c4e7636344 100755\n--- a/tests/queries/0_stateless/00965_live_view_watch_heartbeat.py\n+++ b/tests/queries/0_stateless/00965_live_view_watch_heartbeat.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00966_live_view_watch_events_http.py b/tests/queries/0_stateless/00966_live_view_watch_events_http.py\nindex 72ab3ea88181..3d407ec56026 100755\n--- a/tests/queries/0_stateless/00966_live_view_watch_events_http.py\n+++ b/tests/queries/0_stateless/00966_live_view_watch_events_http.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n \ndiff --git a/tests/queries/0_stateless/00967_live_view_watch_http.py b/tests/queries/0_stateless/00967_live_view_watch_http.py\nindex e2f33971c3d9..d26bb5402e76 100755\n--- a/tests/queries/0_stateless/00967_live_view_watch_http.py\n+++ b/tests/queries/0_stateless/00967_live_view_watch_http.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n \ndiff --git a/tests/queries/0_stateless/00970_live_view_watch_events_http_heartbeat.py b/tests/queries/0_stateless/00970_live_view_watch_events_http_heartbeat.py\nindex 8435cdc147a9..76e5cdbe88de 100755\n--- a/tests/queries/0_stateless/00970_live_view_watch_events_http_heartbeat.py\n+++ b/tests/queries/0_stateless/00970_live_view_watch_events_http_heartbeat.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n \ndiff --git a/tests/queries/0_stateless/00971_live_view_watch_http_heartbeat.py b/tests/queries/0_stateless/00971_live_view_watch_http_heartbeat.py\nindex 2317d705efed..5da36ab2d5f6 100755\n--- a/tests/queries/0_stateless/00971_live_view_watch_http_heartbeat.py\n+++ b/tests/queries/0_stateless/00971_live_view_watch_http_heartbeat.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n \ndiff --git a/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py b/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py\nindex 3a67226da80a..7924aa15d0ca 100755\n--- a/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py\n+++ b/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00979_live_view_watch_live.py b/tests/queries/0_stateless/00979_live_view_watch_live.py\nindex 04ca070c9699..2fc70352dbfd 100755\n--- a/tests/queries/0_stateless/00979_live_view_watch_live.py\n+++ b/tests/queries/0_stateless/00979_live_view_watch_live.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00979_live_view_watch_live_moving_avg.py b/tests/queries/0_stateless/00979_live_view_watch_live_moving_avg.py\nindex ccc824c4d208..54f9ef694d6e 100755\n--- a/tests/queries/0_stateless/00979_live_view_watch_live_moving_avg.py\n+++ b/tests/queries/0_stateless/00979_live_view_watch_live_moving_avg.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00979_live_view_watch_live_with_subquery.py b/tests/queries/0_stateless/00979_live_view_watch_live_with_subquery.py\nindex 809b8b0342ad..2918bed82e81 100755\n--- a/tests/queries/0_stateless/00979_live_view_watch_live_with_subquery.py\n+++ b/tests/queries/0_stateless/00979_live_view_watch_live_with_subquery.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00990_hasToken.python b/tests/queries/0_stateless/00990_hasToken.python\nindex cd2a284655f8..7d3775adc9da 100755\n--- a/tests/queries/0_stateless/00990_hasToken.python\n+++ b/tests/queries/0_stateless/00990_hasToken.python\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # encoding: utf-8\n \n import re\n@@ -126,7 +126,7 @@ def create_cases(case_sensitive_func, case_insensitive_func, table_row_template,\n def main():\n \n     def query(x):\n-        print x\n+        print(x)\n \n     CONST_QUERY = Template(\"\"\"SELECT ${func}('${haystack}', '${needle}'), ' expecting ', ${match};\"\"\")\n     TABLE_QUERY = Template(\"\"\"WITH '${needle}' as n\ndiff --git a/tests/queries/0_stateless/00990_hasToken.sh b/tests/queries/0_stateless/00990_hasToken.sh\nindex 0b88ac0007f0..4b42a570e994 100755\n--- a/tests/queries/0_stateless/00990_hasToken.sh\n+++ b/tests/queries/0_stateless/00990_hasToken.sh\n@@ -5,4 +5,4 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n # We should have correct env vars from shell_config.sh to run this test\n \n-python \"$CURDIR\"/00990_hasToken.python | ${CLICKHOUSE_CLIENT} --max_query_size 1048576 -nm\n+python3 \"$CURDIR\"/00990_hasToken.python | ${CLICKHOUSE_CLIENT} --max_query_size 1048576 -nm\ndiff --git a/tests/queries/0_stateless/00991_live_view_watch_event_live.python b/tests/queries/0_stateless/00991_live_view_watch_event_live.python\nindex 782671cdfaf7..901d388ec011 100644\n--- a/tests/queries/0_stateless/00991_live_view_watch_event_live.python\n+++ b/tests/queries/0_stateless/00991_live_view_watch_event_live.python\n@@ -1,8 +1,8 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n \n import subprocess\n import threading\n-import Queue as queue\n+import queue as queue\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00991_live_view_watch_event_live.sh.disabled b/tests/queries/0_stateless/00991_live_view_watch_event_live.sh.disabled\nindex 10e4e98b2e36..0548d24a80b4 100755\n--- a/tests/queries/0_stateless/00991_live_view_watch_event_live.sh.disabled\n+++ b/tests/queries/0_stateless/00991_live_view_watch_event_live.sh.disabled\n@@ -3,4 +3,4 @@\n CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n . $CURDIR/../shell_config.sh\n \n-python $CURDIR/00991_live_view_watch_event_live.python\n+python3 $CURDIR/00991_live_view_watch_event_live.python\ndiff --git a/tests/queries/0_stateless/00991_live_view_watch_http.python b/tests/queries/0_stateless/00991_live_view_watch_http.python\nindex 938547ca0cb1..d5a1e6e8ed99 100755\n--- a/tests/queries/0_stateless/00991_live_view_watch_http.python\n+++ b/tests/queries/0_stateless/00991_live_view_watch_http.python\n@@ -1,8 +1,8 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n \n import subprocess\n import threading\n-import Queue as queue\n+import queue as queue\n import os\n import sys\n \ndiff --git a/tests/queries/0_stateless/00991_live_view_watch_http.sh.disabled b/tests/queries/0_stateless/00991_live_view_watch_http.sh.disabled\nindex 88cce77f5954..d441ab94473f 100755\n--- a/tests/queries/0_stateless/00991_live_view_watch_http.sh.disabled\n+++ b/tests/queries/0_stateless/00991_live_view_watch_http.sh.disabled\n@@ -3,4 +3,4 @@\n CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n . $CURDIR/../shell_config.sh\n \n-python $CURDIR/00991_live_view_watch_http.python\n+python3 $CURDIR/00991_live_view_watch_http.python\ndiff --git a/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.python b/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.python\nindex 3fd3b38be16f..8ddb1a1ea81a 100644\n--- a/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.python\n+++ b/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.python\n@@ -1,8 +1,8 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n \n import subprocess\n import threading\n-import Queue as queue\n+import queue as queue\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.sh.disabled b/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.sh.disabled\nindex f7aa13d52b33..ebe492fafcef 100755\n--- a/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.sh.disabled\n+++ b/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.sh.disabled\n@@ -3,4 +3,4 @@\n CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n . $CURDIR/../shell_config.sh\n \n-python $CURDIR/00991_temporary_live_view_watch_events_heartbeat.python\n+python3 $CURDIR/00991_temporary_live_view_watch_events_heartbeat.python\ndiff --git a/tests/queries/0_stateless/00991_temporary_live_view_watch_live.python b/tests/queries/0_stateless/00991_temporary_live_view_watch_live.python\nindex a0a1fae0188c..a417cdf29376 100644\n--- a/tests/queries/0_stateless/00991_temporary_live_view_watch_live.python\n+++ b/tests/queries/0_stateless/00991_temporary_live_view_watch_live.python\n@@ -1,8 +1,8 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n \n import subprocess\n import threading\n-import Queue as queue\n+import queue as queue\n import os\n import sys\n import signal\ndiff --git a/tests/queries/0_stateless/00991_temporary_live_view_watch_live.sh.disabled b/tests/queries/0_stateless/00991_temporary_live_view_watch_live.sh.disabled\nindex 4d01d1c3a8e9..91efff53abec 100755\n--- a/tests/queries/0_stateless/00991_temporary_live_view_watch_live.sh.disabled\n+++ b/tests/queries/0_stateless/00991_temporary_live_view_watch_live.sh.disabled\n@@ -3,4 +3,4 @@\n CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n . $CURDIR/../shell_config.sh\n \n-python $CURDIR/00991_temporary_live_view_watch_live.python\n+python3 $CURDIR/00991_temporary_live_view_watch_live.python\ndiff --git a/tests/queries/0_stateless/01246_insert_into_watch_live_view.py b/tests/queries/0_stateless/01246_insert_into_watch_live_view.py\nindex 7f65a7135d55..0f7c6965b7b8 100755\n--- a/tests/queries/0_stateless/01246_insert_into_watch_live_view.py\n+++ b/tests/queries/0_stateless/01246_insert_into_watch_live_view.py\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import os\n import sys\n import time\ndiff --git a/tests/queries/0_stateless/helpers/httpclient.py b/tests/queries/0_stateless/helpers/httpclient.py\nindex a42fad2cbc34..6fb6edff1422 100644\n--- a/tests/queries/0_stateless/helpers/httpclient.py\n+++ b/tests/queries/0_stateless/helpers/httpclient.py\n@@ -8,7 +8,7 @@\n import httpexpect\n \n def client(request, name='', log=None):\n-    client = httpexpect.spawn({'host':'localhost','port':8123}, request)\n+    client = httpexpect.spawn({'host':'localhost','port':8123,'timeout':1}, request)\n     client.logger(log, prefix=name)\n     client.timeout(20)\n     return client\ndiff --git a/tests/queries/0_stateless/helpers/httpechoserver.py b/tests/queries/0_stateless/helpers/httpechoserver.py\nindex 94f94d07f67b..a1176c5e72d5 100644\n--- a/tests/queries/0_stateless/helpers/httpechoserver.py\n+++ b/tests/queries/0_stateless/helpers/httpechoserver.py\n@@ -1,12 +1,12 @@\n-#!/usr/bin/env python\n-from __future__ import print_function\n+#!/usr/bin/env python3\n+\n import sys\n import os\n import time\n import subprocess\n import threading\n from io import StringIO, SEEK_END\n-from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer\n+from http.server import BaseHTTPRequestHandler, HTTPServer\n \n CLICKHOUSE_HOST = os.environ.get('CLICKHOUSE_HOST', '127.0.0.1')\n CLICKHOUSE_PORT_HTTP = os.environ.get('CLICKHOUSE_PORT_HTTP', '8123')\n@@ -72,7 +72,7 @@ def start_server(requests_amount, test_data=\"Hello,2,-2,7.7\\nWorld,2,-5,8.8\"):\n     httpd = HTTPServer(HTTP_SERVER_ADDRESS, EchoCSVHTTPServer)\n \n     def real_func():\n-        for i in xrange(requests_amount):\n+        for i in range(requests_amount):\n             httpd.handle_request()\n \n     t = threading.Thread(target=real_func)\ndiff --git a/tests/queries/0_stateless/helpers/httpexpect.py b/tests/queries/0_stateless/helpers/httpexpect.py\nindex e440dafce4e5..788e57499a87 100644\n--- a/tests/queries/0_stateless/helpers/httpexpect.py\n+++ b/tests/queries/0_stateless/helpers/httpexpect.py\n@@ -13,7 +13,7 @@\n # limitations under the License.\n import os\n import sys\n-import httplib\n+import http.client\n \n CURDIR = os.path.dirname(os.path.realpath(__file__))\n sys.path.insert(0, CURDIR)\n@@ -21,7 +21,7 @@\n import uexpect\n \n from threading import Thread, Event\n-from Queue import Queue, Empty\n+from queue import Queue, Empty\n \n class IO(uexpect.IO):\n     def __init__(self, connection, response, queue, reader):\n@@ -45,15 +45,15 @@ def reader(response, queue, kill_event):\n         try:\n             if kill_event.is_set():\n                 break\n-            data = response.read(1)\n+            data = response.read(1).decode()\n             queue.put(data)\n-        except Exception, e:\n+        except Exception as e:\n             if kill_event.is_set():\n                 break\n             raise\n \n def spawn(connection, request):\n-    connection = httplib.HTTPConnection(**connection)\n+    connection = http.client.HTTPConnection(**connection)\n     connection.request(**request)\n     response = connection.getresponse()\n \n@@ -66,8 +66,8 @@ def spawn(connection, request):\n     return IO(connection, response, queue, reader={'thread':thread, 'kill_event':reader_kill_event})\n \n if __name__ == '__main__':\n-    with http({'host':'localhost','port':8123},{'method':'GET', 'url':'?query=SELECT%201'}) as client:\n+    with spawn({'host':'localhost','port':8123},{'method':'GET', 'url':'?query=SELECT%201'}) as client:\n         client.logger(sys.stdout)\n         client.timeout(2)\n-        print client.response.status, client.response.reason\n+        print(client.response.status, client.response.reason)\n         client.expect('1\\n')\ndiff --git a/tests/queries/0_stateless/helpers/uexpect.py b/tests/queries/0_stateless/helpers/uexpect.py\nindex b71dd2f81a0d..7a633facc95f 100644\n--- a/tests/queries/0_stateless/helpers/uexpect.py\n+++ b/tests/queries/0_stateless/helpers/uexpect.py\n@@ -19,7 +19,7 @@\n \n from threading import Thread, Event\n from subprocess import Popen\n-from Queue import Queue, Empty\n+from queue import Queue, Empty\n \n class TimeoutError(Exception):\n     def __init__(self, timeout):\n@@ -117,7 +117,7 @@ def send(self, data, eol=None):\n         return self.write(data + eol)\n \n     def write(self, data):\n-        return os.write(self.master, data)\n+        return os.write(self.master, data.encode())\n \n     def expect(self, pattern, timeout=None, escape=False):\n         self.match = None\n@@ -198,7 +198,7 @@ def spawn(command):\n def reader(process, out, queue, kill_event):\n     while True:\n         try:\n-            data = os.read(out, 65536)\n+            data = os.read(out, 65536).decode(errors='replace')\n             queue.put(data)\n         except:\n             if kill_event.is_set():\ndiff --git a/tests/queries/conftest.py b/tests/queries/conftest.py\nindex e0f47f63451d..85b7250af0c3 100644\n--- a/tests/queries/conftest.py\n+++ b/tests/queries/conftest.py\n@@ -4,7 +4,7 @@\n import sys\n import tempfile\n \n-from server import ServerThread\n+from .server import ServerThread\n \n \n def pytest_addoption(parser):\n@@ -44,9 +44,9 @@ def standalone_server(bin_prefix, tmp_path):\n \n     if wait_result is not None:\n         with open(os.path.join(server.log_dir, 'server', 'stdout.txt'), 'r') as f:\n-            print >> sys.stderr, f.read()\n+            print(f.read(), file=sys.stderr)\n         with open(os.path.join(server.log_dir, 'server', 'stderr.txt'), 'r') as f:\n-            print >> sys.stderr, f.read()\n+            print(f.read(), file=sys.stderr)\n         pytest.fail('Server died unexpectedly with code {code}'.format(code=server._proc.returncode), pytrace=False)\n \n     yield server\ndiff --git a/tests/queries/query_test.py b/tests/queries/query_test.py\nindex e31a8ded2652..bac38d0334e0 100644\n--- a/tests/queries/query_test.py\n+++ b/tests/queries/query_test.py\n@@ -14,11 +14,11 @@ def run_client(bin_prefix, port, query, reference, replace_map={}):\n     result, error = client.communicate(query)\n     assert client.returncode is not None, \"Client should exit after processing all queries\"\n \n-    for old, new in replace_map.iteritems():\n+    for old, new in replace_map.items():\n         result = result.replace(old, new)\n \n     if client.returncode != 0:\n-        print >> sys.stderr, error\n+        print(error, file=sys.stderr)\n         pytest.fail('Client died unexpectedly with code {code}'.format(code=client.returncode), pytrace=False)\n     elif result != reference:\n         pytest.fail(\"Query output doesn't match reference:{eol}{diff}\".format(\ndiff --git a/tests/queries/server.py b/tests/queries/server.py\nindex 31f92281f973..cb0755db6aec 100644\n--- a/tests/queries/server.py\n+++ b/tests/queries/server.py\n@@ -56,7 +56,7 @@ def run(self):\n \n         while retries:\n             self._choose_ports_and_args()\n-            print 'Start clickhouse-server with args:', self._args\n+            print('Start clickhouse-server with args:', self._args)\n             self._proc = subprocess.Popen([self._bin] + self._args, shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n \n             while self._proc.poll() is None:\n@@ -64,11 +64,11 @@ def run(self):\n                     time.sleep(ServerThread.DEFAULT_SERVER_DELAY)\n                     s = socket.create_connection(('localhost', self.tcp_port), ServerThread.DEFAULT_CONNECTION_TIMEOUT)\n                     s.sendall('G')  # trigger expected \"bad\" HELLO response\n-                    print 'Successful server response:', s.recv(1024)  # FIXME: read whole buffered response\n+                    print('Successful server response:', s.recv(1024))  # FIXME: read whole buffered response\n                     s.shutdown(socket.SHUT_RDWR)\n                     s.close()\n                 except Exception as e:\n-                    print >> sys.stderr, 'Failed to connect to server:', e\n+                    print('Failed to connect to server:', e, file=sys.stderr)\n                     continue\n                 else:\n                     break\n@@ -76,8 +76,8 @@ def run(self):\n             # If process has died then try to fetch output before releasing lock\n             if self._proc.returncode is not None:\n                 stdout, stderr = self._proc.communicate()\n-                print >> sys.stderr, stdout\n-                print >> sys.stderr, stderr\n+                print(stdout, file=sys.stderr)\n+                print(stderr, file=sys.stderr)\n \n             if self._proc.returncode == 70:  # Address already in use\n                 retries -= 1\n@@ -101,7 +101,7 @@ def stop(self):\n         if self._proc.returncode is None:\n             self._proc.terminate()\n         self.join()\n-        print 'Stop clickhouse-server'\n+        print('Stop clickhouse-server')\n \n \n ServerThread.DEFAULT_SERVER_CONFIG = \\\ndiff --git a/tests/queries/shell_config.sh b/tests/queries/shell_config.sh\nindex 8c66d79b5b1a..1fe199be48f1 100644\n--- a/tests/queries/shell_config.sh\n+++ b/tests/queries/shell_config.sh\n@@ -73,5 +73,5 @@ function clickhouse_client_removed_host_parameter()\n {\n     # removing only `--host=value` and `--host value` (removing '-hvalue' feels to dangerous) with python regex.\n     # bash regex magic is arcane, but version dependant and weak; sed or awk are not really portable.\n-    $(echo \"$CLICKHOUSE_CLIENT\"  | python -c \"import sys, re; print re.sub('--host(\\s+|=)[^\\s]+', '', sys.stdin.read())\") \"$@\"\n+    $(echo \"$CLICKHOUSE_CLIENT\"  | python3 -c \"import sys, re; print(re.sub('--host(\\s+|=)[^\\s]+', '', sys.stdin.read()))\") \"$@\"\n }\ndiff --git a/tests/testflows/helpers/cluster.py b/tests/testflows/helpers/cluster.py\nindex 8288e700e3b5..8fda8ac43d87 100644\n--- a/tests/testflows/helpers/cluster.py\n+++ b/tests/testflows/helpers/cluster.py\n@@ -210,7 +210,7 @@ def __exit__(self, type, value, traceback):\n                 self.down()\n         finally:\n             with self.lock:\n-                for shell in self._bash.values():\n+                for shell in list(self._bash.values()):\n                     shell.__exit__(type, value, traceback)\n \n     def node(self, name):\ndiff --git a/tests/testflows/ldap/tests/common.py b/tests/testflows/ldap/tests/common.py\nindex eb21923e9309..c065576c9d44 100644\n--- a/tests/testflows/ldap/tests/common.py\n+++ b/tests/testflows/ldap/tests/common.py\n@@ -129,9 +129,9 @@ def create_ldap_servers_config_content(servers, config_d_dir=\"/etc/clickhouse-se\n     xml_servers = root.find(\"ldap_servers\")\n     xml_servers.append(xmltree.Comment(text=f\"LDAP servers {uid}\"))\n \n-    for _name, server in servers.items():\n+    for _name, server in list(servers.items()):\n         xml_server = xmltree.Element(_name)\n-        for key, value in server.items():\n+        for key, value in list(server.items()):\n             xml_append(xml_server, key, value)\n         xml_servers.append(xml_server)\n \n@@ -288,7 +288,7 @@ def add_user_to_ldap(cn, userpassword, givenname=None, homedirectory=None, sn=No\n     }\n \n     lines = []\n-    for key, value in user.items():\n+    for key, value in list(user.items()):\n         if key.startswith(\"_\"):\n             continue\n         elif key == \"objectclass\":\ndiff --git a/tests/testflows/rbac/tests/privileges/insert.py b/tests/testflows/rbac/tests/privileges/insert.py\nindex 5cb78c6a8a57..ad0ba90c8e35 100755\n--- a/tests/testflows/rbac/tests/privileges/insert.py\n+++ b/tests/testflows/rbac/tests/privileges/insert.py\n@@ -65,9 +65,9 @@ def role(node, role):\n \n def input_output_equality_check(node, input_columns, input_data):\n     data_list = [x.strip(\"'\") for x in input_data.split(\",\")]\n-    input_dict = dict(zip(input_columns.split(\",\"), data_list))\n+    input_dict = dict(list(zip(input_columns.split(\",\"), data_list)))\n     output_dict = json.loads(node.query(f\"select {input_columns} from merge_tree format JSONEachRow\").output)\n-    output_dict = {k:str(v) for (k,v) in output_dict.items()}\n+    output_dict = {k:str(v) for (k,v) in list(output_dict.items())}\n     return input_dict == output_dict\n \n @TestScenario\n@@ -509,7 +509,7 @@ def revoke_privilege_from_role_via_role_with_grant_option(self, table_type, node\n     RQ_SRS_006_RBAC_Privileges_Insert(\"1.0\"),\n )\n @Examples(\"table_type\", [\n-    (table_type, Requirements(requirement)) for table_type, requirement in table_requirements.items()\n+    (table_type, Requirements(requirement)) for table_type, requirement in list(table_requirements.items())\n ])\n @Name(\"insert\")\n def feature(self, table_type, node=\"clickhouse1\"):\ndiff --git a/tests/testflows/rbac/tests/privileges/select.py b/tests/testflows/rbac/tests/privileges/select.py\nindex e74a63614d59..a2d3092f1c3c 100644\n--- a/tests/testflows/rbac/tests/privileges/select.py\n+++ b/tests/testflows/rbac/tests/privileges/select.py\n@@ -477,7 +477,7 @@ def revoke_privilege_from_role_via_role_with_grant_option(self, table_type, node\n     RQ_SRS_006_RBAC_Privileges_Select(\"1.0\"),\n )\n @Examples(\"table_type\", [\n-    (table_type, Requirements(requirement)) for table_type, requirement in table_requirements.items()\n+    (table_type, Requirements(requirement)) for table_type, requirement in list(table_requirements.items())\n ])\n @Name(\"select\")\n def feature(self, table_type, node=\"clickhouse1\"):\ndiff --git a/tests/testflows/runner b/tests/testflows/runner\nindex 6522c8f47f73..0acc3a25945f 100755\n--- a/tests/testflows/runner\n+++ b/tests/testflows/runner\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n #-*- coding: utf-8 -*-\n import subprocess\n import os\n@@ -117,6 +117,6 @@ if __name__ == \"__main__\":\n         command=args.command\n     )\n \n-    print(\"Running testflows container as: '\" + cmd + \"'.\")\n+    print((\"Running testflows container as: '\" + cmd + \"'.\"))\n     # testflows return non zero error code on failed tests\n     subprocess.call(cmd, shell=True)\ndiff --git a/utils/test_history/test-history b/utils/test_history/test-history\nindex dca62625c9f3..fdd6c36e9dc4 100755\n--- a/utils/test_history/test-history\n+++ b/utils/test_history/test-history\n@@ -1,8 +1,8 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n # -*- coding: utf-8 -*-\n \n # Note: should work with python 2 and 3\n-from __future__ import print_function\n+\n from github import Github\n import datetime\n import tabulate\n@@ -31,7 +31,7 @@ def _filter_statuses(statuses):\n     filt = {}\n     for status in sorted(statuses, key=lambda x: x.updated_at):\n         filt[status.context] = status\n-    return filt.values()\n+    return list(filt.values())\n \n \n def get_filtered_statuses(commit):\n@@ -76,7 +76,7 @@ if __name__ == \"__main__\":\n     all_data = []\n     for num, commit in enumerate(commits):\n         commit_sha, commit_modified, check_results = process_one_commit(commit)\n-        mapped_keys = [key for key in check_results.keys() if args.substr in key]\n+        mapped_keys = [key for key in list(check_results.keys()) if args.substr in key]\n         if len(mapped_keys) > len(longest_header):\n             longest_header = mapped_keys\n         all_data.append((commit_modified, commit_sha, check_results))\ndiff --git a/utils/upload_test_results/upload_test_results b/utils/upload_test_results/upload_test_results\nindex 058a73d80812..5916d0d85e86 100755\n--- a/utils/upload_test_results/upload_test_results\n+++ b/utils/upload_test_results/upload_test_results\n@@ -1,4 +1,4 @@\n-#!/usr/bin/env python\n+#!/usr/bin/env python3\n import requests\n import argparse\n \n@@ -96,7 +96,7 @@ def upload_request(sha, pr, file, q_type, user, password, ca_cert, host, db):\n             'X-ClickHouse-Key': password,\n         }\n \n-        print query;\n+        print(query);\n \n         res = requests.post(\n             url,\n@@ -121,7 +121,7 @@ if __name__ == \"__main__\":\n \n     args = parser.parse_args()\n \n-    print(upload_request(args.sha, args.pr, args.file, args.type, args.user, args.password, args.ca_cert, args.host, args.db))\n+    print((upload_request(args.sha, args.pr, args.file, args.type, args.user, args.password, args.ca_cert, args.host, args.db)))\n \n \n \n",
  "problem_statement": "Rewrite integration tests and clickhouse-test script to python 3.\n\n",
  "hints_text": "@alexey-milovidov I think I can take a stab at this (probably assign to me?)",
  "created_at": "2020-09-18T22:51:40Z"
}