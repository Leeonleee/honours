You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
S3 table function and storage engine.
To allow import and export to S3 compatible storage.

Use case and implementation is mostly like `file` table function and `File` storage:
https://clickhouse.yandex/docs/en/query_language/table_functions/file/

With the difference: s3 URL is specified instead of table path<s> and there is possibility to pass token or another auth info</s>authentication will be implemented under #6923.

(Please note that a possibility to pass credentials in other way is out of scope of this task and will be solved further: #3311)

(Also note that we can extend `url` storage and table function to support `s3`, `file` and `hdfs` schemas. This can be addressed further as easy task.)

https://en.wikipedia.org/wiki/Amazon_S3
https://github.com/aws/aws-sdk-cpp

There is a chance that we can simply use REST API instead of this heavy library. But it's unclear.

PS. You can test manually with evaluation account in Yandex.Cloud if you like.
And for automated test choose something that you like:
https://stackoverflow.com/questions/6615988/how-to-mock-amazon-s3-in-an-integration-test
https://stackoverflow.com/questions/23991694/aws-s3-local-server-for-integration-testing/35812932

PS. Please do not be confused with another feature request - to add support to use S3 for cold storage (multiple storage volumes + virtual filesystem) #1394 #1052 #3605. This task is just for import/export of table dumps.
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
