{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 10910,
  "instance_id": "ClickHouse__ClickHouse-10910",
  "issue_numbers": [
    "7260"
  ],
  "base_commit": "f65305878b59f97296b1cecea0ee72ed6c24aae6",
  "patch": "diff --git a/src/Storages/Kafka/ReadBufferFromKafkaConsumer.cpp b/src/Storages/Kafka/ReadBufferFromKafkaConsumer.cpp\nindex 62feea8fe349..eff4161ffb63 100644\n--- a/src/Storages/Kafka/ReadBufferFromKafkaConsumer.cpp\n+++ b/src/Storages/Kafka/ReadBufferFromKafkaConsumer.cpp\n@@ -80,22 +80,9 @@ ReadBufferFromKafkaConsumer::ReadBufferFromKafkaConsumer(\n     });\n }\n \n-ReadBufferFromKafkaConsumer::~ReadBufferFromKafkaConsumer()\n-{\n-    /// NOTE: see https://github.com/edenhill/librdkafka/issues/2077\n-    try\n-    {\n-        if (!consumer->get_subscription().empty())\n-            consumer->unsubscribe();\n-        if (!assignment.empty())\n-            consumer->unassign();\n-        while (consumer->get_consumer_queue().next_event(100ms));\n-    }\n-    catch (const cppkafka::HandleException & e)\n-    {\n-        LOG_ERROR(log, \"Exception from ReadBufferFromKafkaConsumer destructor: \" << e.what());\n-    }\n-}\n+// NOTE on removed desctuctor: There is no need to unsubscribe prior to calling rd_kafka_consumer_close().\n+// check: https://github.com/edenhill/librdkafka/blob/master/INTRODUCTION.md#termination\n+// manual destruction was source of weird errors (hangs during droping kafka table, etc.)\n \n void ReadBufferFromKafkaConsumer::commit()\n {\n@@ -226,8 +213,13 @@ void ReadBufferFromKafkaConsumer::unsubscribe()\n     // it should not raise exception as used in destructor\n     try\n     {\n-        if (!consumer->get_subscription().empty())\n-            consumer->unsubscribe();\n+        // From docs: Any previous subscription will be unassigned and unsubscribed first.\n+        consumer->subscribe(topics);\n+\n+        // I wanted to avoid explicit unsubscribe as it requires draining the messages\n+        // to close the consumer safely after unsubscribe\n+        // see https://github.com/edenhill/librdkafka/issues/2077\n+        //     https://github.com/confluentinc/confluent-kafka-go/issues/189 etc.\n     }\n     catch (const cppkafka::HandleException & e)\n     {\ndiff --git a/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h b/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h\nindex 700a69cf49bc..c5b72ed6d7c6 100644\n--- a/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h\n+++ b/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h\n@@ -28,7 +28,6 @@ class ReadBufferFromKafkaConsumer : public ReadBuffer\n         const std::atomic<bool> & stopped_,\n         const Names & _topics\n     );\n-    ~ReadBufferFromKafkaConsumer() override;\n \n     void allowNext() { allowed = true; } // Allow to read next message.\n     void commit(); // Commit all processed messages.\n@@ -64,10 +63,13 @@ class ReadBufferFromKafkaConsumer : public ReadBuffer\n \n     const std::atomic<bool> & stopped;\n \n+    // order is important, need to be destructed before consumer\n     Messages messages;\n     Messages::const_iterator current;\n \n     bool rebalance_happened = false;\n+\n+    // order is important, need to be destructed before consumer\n     cppkafka::TopicPartitionList assignment;\n     const Names topics;\n \ndiff --git a/src/Storages/Kafka/StorageKafka.cpp b/src/Storages/Kafka/StorageKafka.cpp\nindex e3e285639064..2e2797983b67 100644\n--- a/src/Storages/Kafka/StorageKafka.cpp\n+++ b/src/Storages/Kafka/StorageKafka.cpp\n@@ -235,14 +235,19 @@ ProducerBufferPtr StorageKafka::createWriteBuffer(const Block & header)\n ConsumerBufferPtr StorageKafka::createReadBuffer()\n {\n     cppkafka::Configuration conf;\n+\n     conf.set(\"metadata.broker.list\", brokers);\n     conf.set(\"group.id\", group);\n     conf.set(\"client.id\", VERSION_FULL);\n+\n     conf.set(\"auto.offset.reset\", \"smallest\");     // If no offset stored for this group, read all messages from the start\n+\n+    updateConfiguration(conf);\n+\n+    // those settings should not be changed by users.\n     conf.set(\"enable.auto.commit\", \"false\");       // We manually commit offsets after a stream successfully finished\n     conf.set(\"enable.auto.offset.store\", \"false\"); // Update offset automatically - to commit them all at once.\n     conf.set(\"enable.partition.eof\", \"false\");     // Ignore EOF messages\n-    updateConfiguration(conf);\n \n     // Create a consumer and subscribe to topics\n     auto consumer = std::make_shared<cppkafka::Consumer>(conf);\n",
  "test_patch": "diff --git a/tests/integration/test_storage_kafka/test.py b/tests/integration/test_storage_kafka/test.py\nindex 92fa06c262e8..cbe96df3c293 100644\n--- a/tests/integration/test_storage_kafka/test.py\n+++ b/tests/integration/test_storage_kafka/test.py\n@@ -198,7 +198,6 @@ def test_kafka_settings_new_syntax(kafka_cluster):\n     kafka_check_result(result, True)\n \n \n-@pytest.mark.skip(reason=\"https://github.com/edenhill/librdkafka/issues/2077\")\n @pytest.mark.timeout(180)\n def test_kafka_consumer_hang(kafka_cluster):\n \n@@ -219,7 +218,7 @@ def test_kafka_consumer_hang(kafka_cluster):\n         CREATE MATERIALIZED VIEW test.consumer TO test.view AS SELECT * FROM test.kafka;\n         ''')\n \n-    time.sleep(12)\n+    time.sleep(10)\n     instance.query('SELECT * FROM test.view')\n \n     # This should trigger heartbeat fail,\n@@ -229,19 +228,23 @@ def test_kafka_consumer_hang(kafka_cluster):\n     time.sleep(0.5)\n     kafka_cluster.unpause_container('kafka1')\n \n+    # print(\"Attempt to drop\")\n     instance.query('DROP TABLE test.kafka')\n \n+    #kafka_cluster.open_bash_shell('instance')\n+\n     instance.query('''\n         DROP TABLE test.consumer;\n         DROP TABLE test.view;\n     ''')\n \n-    log = '/var/log/clickhouse-server/stderr.log'\n-    instance.exec_in_container(['grep', '-q', 'BROKERFAIL', log])\n-    instance.exec_in_container(['grep', '-q', '|ASSIGN|', log])\n-    instance.exec_in_container(['grep', '-q', 'Heartbeat failed: REBALANCE_IN_PROGRESS: group is rebalancing', log])\n-    instance.exec_in_container(['grep', '-q', 'Group \"consumer_hang\": waiting for rebalance_cb', log])\n+    # original problem appearance was a sequence of the following messages in librdkafka logs:\n+    # BROKERFAIL -> |ASSIGN| -> REBALANCE_IN_PROGRESS -> \"waiting for rebalance_cb\" (repeated forever)\n+    # so it was waiting forever while the application will execute queued rebalance callback\n \n+    # from a user perspective: we expect no hanging 'drop' queries\n+    # 'dr'||'op' to avoid self matching\n+    assert int(instance.query(\"select count() from system.processes where position(lower(query),'dr'||'op')>0\")) == 0\n \n @pytest.mark.timeout(180)\n def test_kafka_csv_with_delimiter(kafka_cluster):\n@@ -1234,7 +1237,7 @@ def test_exception_from_destructor(kafka_cluster):\n         DROP TABLE test.kafka;\n     ''')\n \n-    kafka_cluster.open_bash_shell('instance')\n+    #kafka_cluster.open_bash_shell('instance')\n     assert TSV(instance.query('SELECT 1')) == TSV('1')\n \n \n",
  "problem_statement": "Kafka: drop Kafka table sometimes hangs\nstacktrace at the moment of hang.\r\nhttps://gist.github.com/filimonov/c51e77f50b4eebb43a133c6cfc4d9066\n",
  "hints_text": "According to stacktrace it's a known internal rdkafka problem, but it should be very rare - so more details about repro scenario are required.",
  "created_at": "2020-05-14T08:45:08Z"
}