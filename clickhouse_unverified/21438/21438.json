{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 21438,
  "instance_id": "ClickHouse__ClickHouse-21438",
  "issue_numbers": [
    "21437"
  ],
  "base_commit": "134eaa55e5e49eed937980a7eeef16f805c6ed9c",
  "patch": "diff --git a/src/Processors/Formats/Impl/AvroRowInputFormat.cpp b/src/Processors/Formats/Impl/AvroRowInputFormat.cpp\nindex a8d71790f415..95ee42b4d098 100644\n--- a/src/Processors/Formats/Impl/AvroRowInputFormat.cpp\n+++ b/src/Processors/Formats/Impl/AvroRowInputFormat.cpp\n@@ -554,7 +554,7 @@ AvroDeserializer::Action AvroDeserializer::createAction(const Block & header, co\n     }\n }\n \n-AvroDeserializer::AvroDeserializer(const Block & header, avro::ValidSchema schema, const FormatSettings & format_settings)\n+AvroDeserializer::AvroDeserializer(const Block & header, avro::ValidSchema schema, bool allow_missing_fields)\n {\n     const auto & schema_root = schema.root();\n     if (schema_root->type() != avro::AVRO_RECORD)\n@@ -565,7 +565,7 @@ AvroDeserializer::AvroDeserializer(const Block & header, avro::ValidSchema schem\n     column_found.resize(header.columns());\n     row_action = createAction(header, schema_root);\n     // fail on missing fields when allow_missing_fields = false\n-    if (!format_settings.avro.allow_missing_fields)\n+    if (!allow_missing_fields)\n     {\n         for (size_t i = 0; i < header.columns(); ++i)\n         {\n@@ -592,19 +592,24 @@ void AvroDeserializer::deserializeRow(MutableColumns & columns, avro::Decoder &\n \n \n AvroRowInputFormat::AvroRowInputFormat(const Block & header_, ReadBuffer & in_, Params params_, const FormatSettings & format_settings_)\n-    : IRowInputFormat(header_, in_, params_)\n-    , file_reader(std::make_unique<InputStreamReadBufferAdapter>(in_))\n-    , deserializer(output.getHeader(), file_reader.dataSchema(), format_settings_)\n+    : IRowInputFormat(header_, in_, params_),\n+      allow_missing_fields(format_settings_.avro.allow_missing_fields)\n+{\n+}\n+\n+void AvroRowInputFormat::readPrefix()\n {\n-    file_reader.init();\n+    file_reader_ptr = std::make_unique<avro::DataFileReaderBase>(std::make_unique<InputStreamReadBufferAdapter>(in));\n+    deserializer_ptr = std::make_unique<AvroDeserializer>(output.getHeader(), file_reader_ptr->dataSchema(), allow_missing_fields);\n+    file_reader_ptr->init();\n }\n \n bool AvroRowInputFormat::readRow(MutableColumns & columns, RowReadExtension &ext)\n {\n-    if (file_reader.hasMore())\n+    if (file_reader_ptr->hasMore())\n     {\n-        file_reader.decr();\n-        deserializer.deserializeRow(columns, file_reader.decoder(), ext);\n+        file_reader_ptr->decr();\n+        deserializer_ptr->deserializeRow(columns, file_reader_ptr->decoder(), ext);\n         return true;\n     }\n     return false;\n@@ -781,7 +786,7 @@ const AvroDeserializer & AvroConfluentRowInputFormat::getOrCreateDeserializer(Sc\n     if (it == deserializer_cache.end())\n     {\n         auto schema = schema_registry->getSchema(schema_id);\n-        AvroDeserializer deserializer(output.getHeader(), schema, format_settings);\n+        AvroDeserializer deserializer(output.getHeader(), schema, format_settings.avro.allow_missing_fields);\n         it = deserializer_cache.emplace(schema_id, deserializer).first;\n     }\n     return it->second;\ndiff --git a/src/Processors/Formats/Impl/AvroRowInputFormat.h b/src/Processors/Formats/Impl/AvroRowInputFormat.h\nindex e3de3bf59a7b..5617b4a7661e 100644\n--- a/src/Processors/Formats/Impl/AvroRowInputFormat.h\n+++ b/src/Processors/Formats/Impl/AvroRowInputFormat.h\n@@ -25,7 +25,7 @@ namespace DB\n class AvroDeserializer\n {\n public:\n-    AvroDeserializer(const Block & header, avro::ValidSchema schema, const FormatSettings & format_settings);\n+    AvroDeserializer(const Block & header, avro::ValidSchema schema, bool allow_missing_fields);\n     void deserializeRow(MutableColumns & columns, avro::Decoder & decoder, RowReadExtension & ext) const;\n \n private:\n@@ -107,12 +107,15 @@ class AvroRowInputFormat : public IRowInputFormat\n {\n public:\n     AvroRowInputFormat(const Block & header_, ReadBuffer & in_, Params params_, const FormatSettings & format_settings_);\n-    virtual bool readRow(MutableColumns & columns, RowReadExtension & ext) override;\n+    bool readRow(MutableColumns & columns, RowReadExtension & ext) override;\n+    void readPrefix() override;\n+\n     String getName() const override { return \"AvroRowInputFormat\"; }\n \n private:\n-    avro::DataFileReaderBase file_reader;\n-    AvroDeserializer deserializer;\n+    std::unique_ptr<avro::DataFileReaderBase> file_reader_ptr;\n+    std::unique_ptr<AvroDeserializer> deserializer_ptr;\n+    bool allow_missing_fields;\n };\n \n /// Confluent framing + Avro binary datum encoding. Mainly used for Kafka.\n",
  "test_patch": "diff --git a/tests/integration/test_storage_kafka/test.py b/tests/integration/test_storage_kafka/test.py\nindex 2a73375c5eae..3c9fb8f3f058 100644\n--- a/tests/integration/test_storage_kafka/test.py\n+++ b/tests/integration/test_storage_kafka/test.py\n@@ -5,8 +5,11 @@\n import subprocess\n import threading\n import time\n+import io\n \n import avro.schema\n+import avro.io\n+import avro.datafile\n from confluent_kafka.avro.cached_schema_registry_client import CachedSchemaRegistryClient\n from confluent_kafka.avro.serializer.message_serializer import MessageSerializer\n from confluent_kafka import admin\n@@ -140,6 +143,37 @@ def kafka_produce_protobuf_social(topic, start_index, num_messages):\n     producer.flush()\n     print((\"Produced {} messages for topic {}\".format(num_messages, topic)))\n \n+def avro_message(value):\n+    schema = avro.schema.make_avsc_object({\n+        'name': 'row',\n+        'type': 'record',\n+        'fields': [\n+            {'name': 'id', 'type': 'long'},\n+            {'name': 'blockNo', 'type': 'int'},\n+            {'name': 'val1', 'type': 'string'},\n+            {'name': 'val2', 'type': 'float'},\n+            {'name': 'val3', 'type': 'int'}\n+        ]\n+    })\n+    bytes_writer = io.BytesIO()\n+    # writer = avro.io.DatumWriter(schema)\n+    # encoder = avro.io.BinaryEncoder(bytes_writer)\n+    # writer.write(value, encoder)\n+\n+\n+    # DataFileWrite seems to be mandatory to get schema encoded\n+    writer = avro.datafile.DataFileWriter(bytes_writer, avro.io.DatumWriter(), schema)\n+    if isinstance(value, list):\n+        for v in value:\n+            writer.append(v)\n+    else:\n+        writer.append(value)\n+    writer.flush()\n+    raw_bytes = bytes_writer.getvalue()\n+\n+    writer.close()\n+    bytes_writer.close()\n+    return raw_bytes\n \n def avro_confluent_message(schema_registry_client, value):\n     # type: (CachedSchemaRegistryClient, dict) -> str\n@@ -572,13 +606,6 @@ def test_kafka_formats(kafka_cluster):\n         #     #     ''\n         #     # ],\n         # },\n-        # 'Avro' : {\n-        #     'data_sample' : [\n-        #         b'\\x4f\\x62\\x6a\\x01\\x04\\x16\\x61\\x76\\x72\\x6f\\x2e\\x73\\x63\\x68\\x65\\x6d\\x61\\x82\\x03\\x7b\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x72\\x65\\x63\\x6f\\x72\\x64\\x22\\x2c\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x72\\x6f\\x77\\x22\\x2c\\x22\\x66\\x69\\x65\\x6c\\x64\\x73\\x22\\x3a\\x5b\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x69\\x64\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x6c\\x6f\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x31\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x73\\x74\\x72\\x69\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x32\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x66\\x6c\\x6f\\x61\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x33\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x5d\\x7d\\x14\\x61\\x76\\x72\\x6f\\x2e\\x63\\x6f\\x64\\x65\\x63\\x08\\x6e\\x75\\x6c\\x6c\\x00\\x8d\\x1f\\xf2\\x17\\x71\\xa4\\x2e\\xe4\\xc9\\x0a\\x23\\x67\\x12\\xaa\\xc6\\xc0\\x02\\x14\\x00\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x8d\\x1f\\xf2\\x17\\x71\\xa4\\x2e\\xe4\\xc9\\x0a\\x23\\x67\\x12\\xaa\\xc6\\xc0',\n-        #         b'\\x4f\\x62\\x6a\\x01\\x04\\x16\\x61\\x76\\x72\\x6f\\x2e\\x73\\x63\\x68\\x65\\x6d\\x61\\x82\\x03\\x7b\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x72\\x65\\x63\\x6f\\x72\\x64\\x22\\x2c\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x72\\x6f\\x77\\x22\\x2c\\x22\\x66\\x69\\x65\\x6c\\x64\\x73\\x22\\x3a\\x5b\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x69\\x64\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x6c\\x6f\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x31\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x73\\x74\\x72\\x69\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x32\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x66\\x6c\\x6f\\x61\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x33\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x5d\\x7d\\x14\\x61\\x76\\x72\\x6f\\x2e\\x63\\x6f\\x64\\x65\\x63\\x08\\x6e\\x75\\x6c\\x6c\\x00\\xeb\\x9d\\x51\\x82\\xf2\\x11\\x3d\\x0b\\xc5\\x92\\x97\\xb2\\x07\\x6d\\x72\\x5a\\x1e\\xac\\x02\\x02\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x04\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x06\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x08\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x0a\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x0c\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x0e\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x10\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x12\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x14\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x16\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x18\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x1a\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x1c\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x1e\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\xeb\\x9d\\x51\\x82\\xf2\\x11\\x3d\\x0b\\xc5\\x92\\x97\\xb2\\x07\\x6d\\x72\\x5a',\n-        #         b'\\x4f\\x62\\x6a\\x01\\x04\\x16\\x61\\x76\\x72\\x6f\\x2e\\x73\\x63\\x68\\x65\\x6d\\x61\\x82\\x03\\x7b\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x72\\x65\\x63\\x6f\\x72\\x64\\x22\\x2c\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x72\\x6f\\x77\\x22\\x2c\\x22\\x66\\x69\\x65\\x6c\\x64\\x73\\x22\\x3a\\x5b\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x69\\x64\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x6c\\x6f\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x62\\x6c\\x6f\\x63\\x6b\\x4e\\x6f\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x31\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x73\\x74\\x72\\x69\\x6e\\x67\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x32\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x66\\x6c\\x6f\\x61\\x74\\x22\\x7d\\x2c\\x7b\\x22\\x6e\\x61\\x6d\\x65\\x22\\x3a\\x22\\x76\\x61\\x6c\\x33\\x22\\x2c\\x22\\x74\\x79\\x70\\x65\\x22\\x3a\\x22\\x69\\x6e\\x74\\x22\\x7d\\x5d\\x7d\\x14\\x61\\x76\\x72\\x6f\\x2e\\x63\\x6f\\x64\\x65\\x63\\x08\\x6e\\x75\\x6c\\x6c\\x00\\x73\\x65\\x4f\\x7c\\xd9\\x33\\xe1\\x18\\xdd\\x30\\xe8\\x22\\x2a\\x58\\x20\\x6f\\x02\\x14\\x00\\x00\\x04\\x41\\x4d\\x00\\x00\\x00\\x3f\\x02\\x73\\x65\\x4f\\x7c\\xd9\\x33\\xe1\\x18\\xdd\\x30\\xe8\\x22\\x2a\\x58\\x20\\x6f',\n-        #     ],\n-        # },\n         'AvroConfluent': {\n             'data_sample': [\n                 avro_confluent_message(cluster.schema_registry_client,\n@@ -596,6 +623,19 @@ def test_kafka_formats(kafka_cluster):\n                 cluster.schema_registry_port\n             ),\n             'supports_empty_value': True,\n+        },\n+        'Avro': {\n+            # It seems impossible to send more than one avro file per a message\n+            #   because of nature of Avro: blocks go one after another\n+            'data_sample': [\n+                avro_message({'id': 0, 'blockNo': 0, 'val1': str('AM'), 'val2': 0.5, \"val3\": 1}),\n+\n+                avro_message([{'id': id, 'blockNo': 0, 'val1': str('AM'),\n+                                                               'val2': 0.5, \"val3\": 1} for id in range(1, 16)]),\n+\n+                avro_message({'id': 0, 'blockNo': 0, 'val1': str('AM'), 'val2': 0.5, \"val3\": 1}),\n+            ],\n+            'supports_empty_value': False,\n         }\n         # 'Arrow' : {\n         #     # Not working at all: DB::Exception: Error while opening a table: Invalid: File is too small: 0, Stack trace (when copying this message, always include the lines below):\n",
  "problem_statement": "loading more than one Avro formatted message from kafka does not work\nIn recent ClickHouse versions (21.3) Avro format for kafka does not work at all.\r\nIn ClickHouse 20.3 one Avro formatted kafka message can read, than stall forever.\r\nReportedly in ClickHouse prior 20.3 Avro formatted kafka messages work Ok while contain only single record\n",
  "hints_text": "",
  "created_at": "2021-03-04T08:25:34Z"
}