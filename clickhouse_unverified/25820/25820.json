{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 25820,
  "instance_id": "ClickHouse__ClickHouse-25820",
  "issue_numbers": [
    "10368"
  ],
  "base_commit": "081695fd05998161cf6150c22c4399ee53d87dea",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex dc09a783a29a..a4dbb5c59011 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -1013,7 +1013,7 @@ void MergeTreeData::loadDataParts(bool skip_sanity_checks)\n             ErrorCodes::TOO_MANY_UNEXPECTED_DATA_PARTS);\n \n     for (auto & part : broken_parts_to_detach)\n-        part->renameToDetached(\"broken_on_start\");\n+        part->renameToDetached(\"broken-on-start\"); /// detached parts must not have '_' in prefixes\n \n \n     /// Delete from the set of current parts those parts that are covered by another part (those parts that\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp b/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp\nindex d170ba835cb2..35a011a4a588 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp\n@@ -190,18 +190,36 @@ void ReplicatedMergeTreePartCheckThread::searchForMissingPartAndFetchIfPossible(\n \n     if (missing_part_search_result == MissingPartSearchResult::LostForever)\n     {\n-        /// Is it in the replication queue? If there is - delete, because the task can not be processed.\n-        if (!storage.queue.remove(zookeeper, part_name))\n+        auto lost_part_info = MergeTreePartInfo::fromPartName(part_name, storage.format_version);\n+        if (lost_part_info.level != 0)\n         {\n-            /// The part was not in our queue.\n-            LOG_WARNING(log, \"Missing part {} is not in our queue, this can happen rarely.\", part_name);\n+            Strings source_parts;\n+            bool part_in_queue = storage.queue.checkPartInQueueAndGetSourceParts(part_name, source_parts);\n+\n+            /// If it's MERGE/MUTATION etc. we shouldn't replace result part with empty part\n+            /// because some source parts can be lost, but some of them can exist.\n+            if (part_in_queue && !source_parts.empty())\n+            {\n+                LOG_ERROR(log, \"Part {} found in queue and some source parts for it was lost. Will check all source parts.\", part_name);\n+                for (const String & source_part_name : source_parts)\n+                    enqueuePart(source_part_name);\n+\n+                return;\n+            }\n         }\n \n-        /** This situation is possible if on all the replicas where the part was, it deteriorated.\n-            * For example, a replica that has just written it has power turned off and the data has not been written from cache to disk.\n-            */\n-        LOG_ERROR(log, \"Part {} is lost forever.\", part_name);\n-        ProfileEvents::increment(ProfileEvents::ReplicatedDataLoss);\n+        if (storage.createEmptyPartInsteadOfLost(zookeeper, part_name))\n+        {\n+            /** This situation is possible if on all the replicas where the part was, it deteriorated.\n+                * For example, a replica that has just written it has power turned off and the data has not been written from cache to disk.\n+                */\n+            LOG_ERROR(log, \"Part {} is lost forever.\", part_name);\n+            ProfileEvents::increment(ProfileEvents::ReplicatedDataLoss);\n+        }\n+        else\n+        {\n+            LOG_WARNING(log, \"Cannot create empty part {} instead of lost. Will retry later\", part_name);\n+        }\n     }\n }\n \n@@ -307,11 +325,12 @@ CheckResult ReplicatedMergeTreePartCheckThread::checkPart(const String & part_na\n                 String message = \"Part \" + part_name + \" looks broken. Removing it and will try to fetch.\";\n                 LOG_ERROR(log, message);\n \n+                /// Delete part locally.\n+                storage.forgetPartAndMoveToDetached(part, \"broken\");\n+\n                 /// Part is broken, let's try to find it and fetch.\n                 searchForMissingPartAndFetchIfPossible(part_name, exists_in_zookeeper);\n \n-                /// Delete part locally.\n-                storage.forgetPartAndMoveToDetached(part, \"broken\");\n                 return {part_name, false, message};\n             }\n         }\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\nindex a14b6119f38a..bb4d0888c56b 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\n@@ -64,6 +64,24 @@ bool ReplicatedMergeTreeQueue::isVirtualPart(const MergeTreeData::DataPartPtr &\n     return !virtual_part_name.empty() && virtual_part_name != data_part->name;\n }\n \n+bool ReplicatedMergeTreeQueue::checkPartInQueueAndGetSourceParts(const String & part_name, Strings & source_parts) const\n+{\n+    std::lock_guard lock(state_mutex);\n+\n+    bool found = false;\n+    for (const auto & entry : queue)\n+    {\n+        if (entry->new_part_name == part_name && entry->source_parts.size() > source_parts.size())\n+        {\n+            source_parts.clear();\n+            source_parts.insert(source_parts.end(), entry->source_parts.begin(), entry->source_parts.end());\n+            found = true;\n+        }\n+    }\n+\n+    return found;\n+}\n+\n \n bool ReplicatedMergeTreeQueue::load(zkutil::ZooKeeperPtr zookeeper)\n {\n@@ -410,62 +428,6 @@ void ReplicatedMergeTreeQueue::removeProcessedEntry(zkutil::ZooKeeperPtr zookeep\n     updateTimesInZooKeeper(zookeeper, min_unprocessed_insert_time_changed, max_processed_insert_time_changed);\n }\n \n-\n-bool ReplicatedMergeTreeQueue::remove(zkutil::ZooKeeperPtr zookeeper, const String & part_name)\n-{\n-    LogEntryPtr found;\n-    size_t queue_size = 0;\n-\n-    std::optional<time_t> min_unprocessed_insert_time_changed;\n-    std::optional<time_t> max_processed_insert_time_changed;\n-\n-    {\n-        std::unique_lock lock(state_mutex);\n-\n-        bool removed = virtual_parts.remove(part_name);\n-\n-        for (Queue::iterator it = queue.begin(); it != queue.end();)\n-        {\n-            if ((*it)->new_part_name == part_name)\n-            {\n-                found = *it;\n-                if (removed)\n-                {\n-                    /// Preserve invariant `virtual_parts` = `current_parts` + `queue`.\n-                    /// We remove new_part from virtual parts and add all source parts\n-                    /// which present in current_parts.\n-                    for (const auto & source_part : found->source_parts)\n-                    {\n-                        auto part_in_current_parts = current_parts.getContainingPart(source_part);\n-                        if (part_in_current_parts == source_part)\n-                            virtual_parts.add(source_part, nullptr, log);\n-                    }\n-                }\n-\n-                updateStateOnQueueEntryRemoval(\n-                    found, /* is_successful = */ false,\n-                    min_unprocessed_insert_time_changed, max_processed_insert_time_changed, lock);\n-                queue.erase(it++);\n-                queue_size = queue.size();\n-                break;\n-            }\n-            else\n-                ++it;\n-        }\n-    }\n-\n-    if (!found)\n-        return false;\n-\n-    notifySubscribers(queue_size);\n-\n-    zookeeper->tryRemove(fs::path(replica_path) / \"queue\" / found->znode_name);\n-    updateTimesInZooKeeper(zookeeper, min_unprocessed_insert_time_changed, max_processed_insert_time_changed);\n-\n-    return true;\n-}\n-\n-\n bool ReplicatedMergeTreeQueue::removeFailedQuorumPart(const MergeTreePartInfo & part_info)\n {\n     assert(part_info.level == 0);\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h\nindex 078795472bfe..820d2794a31a 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h\n@@ -281,11 +281,6 @@ class ReplicatedMergeTreeQueue\n       */\n     void insert(zkutil::ZooKeeperPtr zookeeper, LogEntryPtr & entry);\n \n-    /** Delete the action with the specified part (as new_part_name) from the queue.\n-      * Called for unreachable actions in the queue - old lost parts.\n-      */\n-    bool remove(zkutil::ZooKeeperPtr zookeeper, const String & part_name);\n-\n     /** Load (initialize) a queue from ZooKeeper (/replicas/me/queue/).\n       * If queue was not empty load() would not load duplicate records.\n       * return true, if we update queue.\n@@ -378,6 +373,11 @@ class ReplicatedMergeTreeQueue\n     /// Checks that part is already in virtual parts\n     bool isVirtualPart(const MergeTreeData::DataPartPtr & data_part) const;\n \n+    /// Check that part produced by some entry in queue and get source parts for it.\n+    /// If there are several entries return largest source_parts set. This rarely possible\n+    /// for example after replica clone.\n+    bool checkPartInQueueAndGetSourceParts(const String & part_name, Strings & source_parts) const;\n+\n     /// Check that part isn't in currently generating parts and isn't covered by them and add it to future_parts.\n     /// Locks queue's mutex.\n     bool addFuturePartIfNotCoveredByThem(const String & part_name, LogEntry & entry, String & reject_reason);\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex ce2e2bf0774f..b51b39f7d68b 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -17,6 +17,7 @@\n #include <Storages/StorageReplicatedMergeTree.h>\n #include <Storages/MergeTree/IMergeTreeDataPart.h>\n #include <Storages/MergeTree/MergeList.h>\n+#include <Storages/MergeTree/MergedBlockOutputStream.h>\n #include <Storages/MergeTree/PinnedPartUUIDs.h>\n #include <Storages/MergeTree/PartitionPruner.h>\n #include <Storages/MergeTree/ReplicatedMergeTreeTableMetadata.h>\n@@ -1215,29 +1216,37 @@ void StorageReplicatedMergeTree::checkParts(bool skip_sanity_checks)\n     for (size_t i = 0; i < parts_to_fetch.size(); ++i)\n     {\n         const String & part_name = parts_to_fetch[i];\n-        LOG_ERROR(log, \"Removing locally missing part from ZooKeeper and queueing a fetch: {}\", part_name);\n \n         Coordination::Requests ops;\n \n-        time_t part_create_time = 0;\n-        Coordination::ExistsResponse exists_resp = exists_futures[i].get();\n-        if (exists_resp.error == Coordination::Error::ZOK)\n+        String has_replica = findReplicaHavingPart(part_name, true);\n+        if (!has_replica.empty())\n         {\n-            part_create_time = exists_resp.stat.ctime / 1000;\n-            removePartFromZooKeeper(part_name, ops, exists_resp.stat.numChildren > 0);\n-        }\n-\n-        LogEntry log_entry;\n-        log_entry.type = LogEntry::GET_PART;\n-        log_entry.source_replica = \"\";\n-        log_entry.new_part_name = part_name;\n-        log_entry.create_time = part_create_time;\n+            LOG_ERROR(log, \"Removing locally missing part from ZooKeeper and queueing a fetch: {}\", part_name);\n+            time_t part_create_time = 0;\n+            Coordination::ExistsResponse exists_resp = exists_futures[i].get();\n+            if (exists_resp.error == Coordination::Error::ZOK)\n+            {\n+                part_create_time = exists_resp.stat.ctime / 1000;\n+                removePartFromZooKeeper(part_name, ops, exists_resp.stat.numChildren > 0);\n+            }\n+            LogEntry log_entry;\n+            log_entry.type = LogEntry::GET_PART;\n+            log_entry.source_replica = \"\";\n+            log_entry.new_part_name = part_name;\n+            log_entry.create_time = part_create_time;\n \n-        /// We assume that this occurs before the queue is loaded (queue.initialize).\n-        ops.emplace_back(zkutil::makeCreateRequest(\n-            fs::path(replica_path) / \"queue/queue-\", log_entry.toString(), zkutil::CreateMode::PersistentSequential));\n+            /// We assume that this occurs before the queue is loaded (queue.initialize).\n+            ops.emplace_back(zkutil::makeCreateRequest(\n+                fs::path(replica_path) / \"queue/queue-\", log_entry.toString(), zkutil::CreateMode::PersistentSequential));\n+            enqueue_futures.emplace_back(zookeeper->asyncMulti(ops));\n+        }\n+        else\n+        {\n+            LOG_ERROR(log, \"Not found active replica having part {}\", part_name);\n+            enqueuePartForCheck(part_name);\n+        }\n \n-        enqueue_futures.emplace_back(zookeeper->asyncMulti(ops));\n     }\n \n     for (auto & future : enqueue_futures)\n@@ -1272,7 +1281,6 @@ void StorageReplicatedMergeTree::syncPinnedPartUUIDs()\n     }\n }\n \n-\n void StorageReplicatedMergeTree::checkPartChecksumsAndAddCommitOps(const zkutil::ZooKeeperPtr & zookeeper,\n     const DataPartPtr & part, Coordination::Requests & ops, String part_name, NameSet * absent_replicas_paths)\n {\n@@ -7393,4 +7401,164 @@ bool StorageReplicatedMergeTree::checkIfDetachedPartitionExists(const String & p\n     }\n     return false;\n }\n+\n+\n+bool StorageReplicatedMergeTree::createEmptyPartInsteadOfLost(zkutil::ZooKeeperPtr zookeeper, const String & lost_part_name)\n+{\n+    LOG_INFO(log, \"Going to replace lost part {} with empty part\", lost_part_name);\n+    auto metadata_snapshot = getInMemoryMetadataPtr();\n+    auto settings = getSettings();\n+\n+    constexpr static auto TMP_PREFIX = \"tmp_empty_\";\n+\n+    auto new_part_info = MergeTreePartInfo::fromPartName(lost_part_name, format_version);\n+    auto block = metadata_snapshot->getSampleBlock();\n+\n+    DB::IMergeTreeDataPart::TTLInfos move_ttl_infos;\n+\n+    NamesAndTypesList columns = metadata_snapshot->getColumns().getAllPhysical().filter(block.getNames());\n+    ReservationPtr reservation = reserveSpacePreferringTTLRules(metadata_snapshot, 0, move_ttl_infos, time(nullptr), 0, true);\n+    VolumePtr volume = getStoragePolicy()->getVolume(0);\n+\n+    IMergeTreeDataPart::MinMaxIndex minmax_idx;\n+    minmax_idx.update(block, getMinMaxColumnsNames(metadata_snapshot->getPartitionKey()));\n+\n+    auto new_data_part = createPart(\n+        lost_part_name,\n+        choosePartType(0, block.rows()),\n+        new_part_info,\n+        createVolumeFromReservation(reservation, volume),\n+        TMP_PREFIX + lost_part_name);\n+\n+    if (settings->assign_part_uuids)\n+        new_data_part->uuid = UUIDHelpers::generateV4();\n+\n+    new_data_part->setColumns(columns);\n+    new_data_part->rows_count = block.rows();\n+\n+    {\n+        auto lock = lockParts();\n+        auto parts_in_partition = getDataPartsPartitionRange(new_part_info.partition_id);\n+        if (parts_in_partition.empty())\n+        {\n+            LOG_WARNING(log, \"Empty part {} is not created instead of lost part because there are no parts in partition {} (it's empty), resolve this manually using DROP PARTITION.\", lost_part_name, new_part_info.partition_id);\n+            return false;\n+        }\n+\n+        new_data_part->partition = (*parts_in_partition.begin())->partition;\n+    }\n+\n+    new_data_part->minmax_idx = std::move(minmax_idx);\n+    new_data_part->is_temp = true;\n+\n+\n+    SyncGuardPtr sync_guard;\n+    if (new_data_part->isStoredOnDisk())\n+    {\n+        /// The name could be non-unique in case of stale files from previous runs.\n+        String full_path = new_data_part->getFullRelativePath();\n+\n+        if (new_data_part->volume->getDisk()->exists(full_path))\n+        {\n+            LOG_WARNING(log, \"Removing old temporary directory {}\", fullPath(new_data_part->volume->getDisk(), full_path));\n+            new_data_part->volume->getDisk()->removeRecursive(full_path);\n+        }\n+\n+        const auto disk = new_data_part->volume->getDisk();\n+        disk->createDirectories(full_path);\n+\n+        if (getSettings()->fsync_part_directory)\n+            sync_guard = disk->getDirectorySyncGuard(full_path);\n+    }\n+\n+    /// This effectively chooses minimal compression method:\n+    ///  either default lz4 or compression method with zero thresholds on absolute and relative part size.\n+    auto compression_codec = getContext()->chooseCompressionCodec(0, 0);\n+\n+    const auto & index_factory = MergeTreeIndexFactory::instance();\n+    MergedBlockOutputStream out(new_data_part, metadata_snapshot, columns, index_factory.getMany(metadata_snapshot->getSecondaryIndices()), compression_codec);\n+    bool sync_on_insert = settings->fsync_after_insert;\n+\n+    out.writePrefix();\n+    out.write(block);\n+    out.writeSuffixAndFinalizePart(new_data_part, sync_on_insert);\n+\n+    try\n+    {\n+        MergeTreeData::Transaction transaction(*this);\n+        auto replaced_parts = renameTempPartAndReplace(new_data_part, nullptr, &transaction);\n+\n+        if (!replaced_parts.empty())\n+        {\n+            Strings part_names;\n+            for (const auto & part : replaced_parts)\n+                part_names.emplace_back(part->name);\n+\n+            /// Why this exception is not a LOGICAL_ERROR? Because it's possible\n+            /// to have some source parts for the lost part if replica currently\n+            /// cloning from another replica, but source replica lost covering\n+            /// part and finished MERGE_PARTS before clone. It's an extremely\n+            /// rare case and it's unclear how to resolve it better. Eventually\n+            /// source replica will replace lost part with empty part and we\n+            /// will fetch this empty part instead of our source parts. This\n+            /// will make replicas consistent, but some data will be lost.\n+            throw Exception(ErrorCodes::INCORRECT_DATA, \"Tried to create empty part {}, but it replaces existing parts {}.\", lost_part_name, fmt::join(part_names, \", \"));\n+        }\n+\n+        while (true)\n+        {\n+\n+            Coordination::Requests ops;\n+            Coordination::Stat replicas_stat;\n+            auto replicas_path = fs::path(zookeeper_path) / \"replicas\";\n+            Strings replicas = zookeeper->getChildren(replicas_path, &replicas_stat);\n+\n+            /// In rare cases new replica can appear during check\n+            ops.emplace_back(zkutil::makeCheckRequest(replicas_path, replicas_stat.version));\n+\n+            for (const String & replica : replicas)\n+            {\n+                String current_part_path = fs::path(zookeeper_path) / \"replicas\" / replica / \"parts\" / lost_part_name;\n+\n+                /// We must be sure that this part doesn't exist on other replicas\n+                if (!zookeeper->exists(current_part_path))\n+                {\n+                    ops.emplace_back(zkutil::makeCreateRequest(current_part_path, \"\", zkutil::CreateMode::Persistent));\n+                    ops.emplace_back(zkutil::makeRemoveRequest(current_part_path, -1));\n+                }\n+                else\n+                {\n+                    throw Exception(ErrorCodes::DUPLICATE_DATA_PART, \"Part {} already exists on replica {} on path {}\", lost_part_name, replica, current_part_path);\n+                }\n+            }\n+\n+            getCommitPartOps(ops, new_data_part);\n+\n+            Coordination::Responses responses;\n+            if (auto code = zookeeper->tryMulti(ops, responses); code == Coordination::Error::ZOK)\n+            {\n+                transaction.commit();\n+                break;\n+            }\n+            else if (code == Coordination::Error::ZBADVERSION)\n+            {\n+                LOG_INFO(log, \"Looks like new replica appearead while creating new empty part, will retry\");\n+            }\n+            else\n+            {\n+                zkutil::KeeperMultiException::check(code, ops, responses);\n+            }\n+        }\n+    }\n+    catch (const Exception & ex)\n+    {\n+        LOG_WARNING(log, \"Cannot commit empty part {} with error {}\", lost_part_name, ex.displayText());\n+        return false;\n+    }\n+\n+    LOG_INFO(log, \"Created empty part {} instead of lost part\", lost_part_name);\n+\n+    return true;\n+}\n+\n }\ndiff --git a/src/Storages/StorageReplicatedMergeTree.h b/src/Storages/StorageReplicatedMergeTree.h\nindex 205dc9687c72..6f717b7c450d 100644\n--- a/src/Storages/StorageReplicatedMergeTree.h\n+++ b/src/Storages/StorageReplicatedMergeTree.h\n@@ -258,6 +258,8 @@ class StorageReplicatedMergeTree final : public shared_ptr_helper<StorageReplica\n         return replicated_sends_throttler;\n     }\n \n+    bool createEmptyPartInsteadOfLost(zkutil::ZooKeeperPtr zookeeper, const String & lost_part_name);\n+\n private:\n     std::atomic_bool are_restoring_replica {false};\n \n",
  "test_patch": "diff --git a/tests/integration/test_lost_part/__init__.py b/tests/integration/test_lost_part/__init__.py\nnew file mode 100644\nindex 000000000000..e5a0d9b4834e\n--- /dev/null\n+++ b/tests/integration/test_lost_part/__init__.py\n@@ -0,0 +1,1 @@\n+#!/usr/bin/env python3\ndiff --git a/tests/integration/test_lost_part/test.py b/tests/integration/test_lost_part/test.py\nnew file mode 100644\nindex 000000000000..614df52063f2\n--- /dev/null\n+++ b/tests/integration/test_lost_part/test.py\n@@ -0,0 +1,211 @@\n+#!/usr/bin/env python3\n+\n+import pytest\n+import time\n+import ast\n+import random\n+\n+from helpers.cluster import ClickHouseCluster\n+from helpers.test_tools import assert_eq_with_retry\n+\n+cluster = ClickHouseCluster(__file__)\n+\n+node1 = cluster.add_instance('node1', with_zookeeper=True)\n+node2 = cluster.add_instance('node2', with_zookeeper=True)\n+\n+@pytest.fixture(scope=\"module\")\n+def start_cluster():\n+    try:\n+        cluster.start()\n+\n+        yield cluster\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def remove_part_from_disk(node, table, part_name):\n+    part_path = node.query(\n+        \"SELECT path FROM system.parts WHERE table = '{}' and name = '{}'\".format(table, part_name)).strip()\n+    if not part_path:\n+        raise Exception(\"Part \" + part_name + \"doesn't exist\")\n+    node.exec_in_container(['bash', '-c', 'rm -r {p}/*'.format(p=part_path)], privileged=True)\n+\n+\n+def test_lost_part_same_replica(start_cluster):\n+    for node in [node1, node2]:\n+        node.query(\n+            \"CREATE TABLE mt0 (id UInt64, date Date) ENGINE ReplicatedMergeTree('/clickhouse/tables/t', '{}') ORDER BY tuple() PARTITION BY date\".format(node.name))\n+\n+    node1.query(\"SYSTEM STOP MERGES mt0\")\n+    node2.query(\"SYSTEM STOP REPLICATION QUEUES\")\n+\n+    for i in range(5):\n+        node1.query(\"INSERT INTO mt0 VALUES ({}, toDate('2020-10-01'))\".format(i))\n+\n+    for i in range(20):\n+        parts_to_merge = node1.query(\"SELECT parts_to_merge FROM system.replication_queue\")\n+        if parts_to_merge:\n+            parts_list = list(sorted(ast.literal_eval(parts_to_merge)))\n+            print(\"Got parts list\", parts_list)\n+            if len(parts_list) < 3:\n+                raise Exception(\"Got too small parts list {}\".format(parts_list))\n+            break\n+        time.sleep(1)\n+\n+    victim_part_from_the_middle = random.choice(parts_list[1:-1])\n+    print(\"Will corrupt part\", victim_part_from_the_middle)\n+\n+    remove_part_from_disk(node1, 'mt0', victim_part_from_the_middle)\n+\n+    node1.query(\"DETACH TABLE mt0\")\n+\n+    node1.query(\"ATTACH TABLE mt0\")\n+\n+    node1.query(\"SYSTEM START MERGES mt0\")\n+\n+    for i in range(10):\n+        result = node1.query(\"SELECT count() FROM system.replication_queue\")\n+        if int(result) == 0:\n+            break\n+        time.sleep(1)\n+    else:\n+        assert False, \"Still have something in replication queue:\\n\" + node1.query(\"SELECT count() FROM system.replication_queue FORMAT Vertical\")\n+\n+    assert node1.contains_in_log(\"Created empty part\"), \"Seems like empty part {} is not created or log message changed\".format(victim_part_from_the_middle)\n+\n+    assert node1.query(\"SELECT COUNT() FROM mt0\") == \"4\\n\"\n+\n+    node2.query(\"SYSTEM START REPLICATION QUEUES\")\n+\n+    assert_eq_with_retry(node2, \"SELECT COUNT() FROM mt0\", \"4\")\n+    assert_eq_with_retry(node2, \"SELECT COUNT() FROM system.replication_queue\", \"0\")\n+\n+def test_lost_part_other_replica(start_cluster):\n+    for node in [node1, node2]:\n+        node.query(\n+            \"CREATE TABLE mt1 (id UInt64) ENGINE ReplicatedMergeTree('/clickhouse/tables/t1', '{}') ORDER BY tuple()\".format(node.name))\n+\n+    node1.query(\"SYSTEM STOP MERGES mt1\")\n+    node2.query(\"SYSTEM STOP REPLICATION QUEUES\")\n+\n+    for i in range(5):\n+        node1.query(\"INSERT INTO mt1 VALUES ({})\".format(i))\n+\n+    for i in range(20):\n+        parts_to_merge = node1.query(\"SELECT parts_to_merge FROM system.replication_queue\")\n+        if parts_to_merge:\n+            parts_list = list(sorted(ast.literal_eval(parts_to_merge)))\n+            print(\"Got parts list\", parts_list)\n+            if len(parts_list) < 3:\n+                raise Exception(\"Got too small parts list {}\".format(parts_list))\n+            break\n+        time.sleep(1)\n+\n+    victim_part_from_the_middle = random.choice(parts_list[1:-1])\n+    print(\"Will corrupt part\", victim_part_from_the_middle)\n+\n+    remove_part_from_disk(node1, 'mt1', victim_part_from_the_middle)\n+\n+    # other way to detect broken parts\n+    node1.query(\"CHECK TABLE mt1\")\n+\n+    node2.query(\"SYSTEM START REPLICATION QUEUES\")\n+\n+    for i in range(10):\n+        result = node2.query(\"SELECT count() FROM system.replication_queue\")\n+        if int(result) == 0:\n+            break\n+        time.sleep(1)\n+    else:\n+        assert False, \"Still have something in replication queue:\\n\" + node2.query(\"SELECT * FROM system.replication_queue FORMAT Vertical\")\n+\n+    assert node1.contains_in_log(\"Created empty part\"), \"Seems like empty part {} is not created or log message changed\".format(victim_part_from_the_middle)\n+\n+    assert_eq_with_retry(node2, \"SELECT COUNT() FROM mt1\", \"4\")\n+    assert_eq_with_retry(node2, \"SELECT COUNT() FROM system.replication_queue\", \"0\")\n+\n+    node1.query(\"SYSTEM START MERGES mt1\")\n+\n+    assert_eq_with_retry(node1, \"SELECT COUNT() FROM mt1\", \"4\")\n+    assert_eq_with_retry(node1, \"SELECT COUNT() FROM system.replication_queue\", \"0\")\n+\n+def test_lost_part_mutation(start_cluster):\n+    for node in [node1, node2]:\n+        node.query(\n+            \"CREATE TABLE mt2 (id UInt64) ENGINE ReplicatedMergeTree('/clickhouse/tables/t2', '{}') ORDER BY tuple()\".format(node.name))\n+\n+    node1.query(\"SYSTEM STOP MERGES mt2\")\n+    node2.query(\"SYSTEM STOP REPLICATION QUEUES\")\n+\n+    for i in range(2):\n+        node1.query(\"INSERT INTO mt2 VALUES ({})\".format(i))\n+\n+    node1.query(\"ALTER TABLE mt2 UPDATE id = 777 WHERE 1\", settings={\"mutations_sync\": \"0\"})\n+\n+    for i in range(20):\n+        parts_to_mutate = node1.query(\"SELECT count() FROM system.replication_queue\")\n+        # two mutations for both replicas\n+        if int(parts_to_mutate) == 4:\n+            break\n+        time.sleep(1)\n+\n+    remove_part_from_disk(node1, 'mt2', 'all_1_1_0')\n+\n+    # other way to detect broken parts\n+    node1.query(\"CHECK TABLE mt2\")\n+\n+    node1.query(\"SYSTEM START MERGES mt2\")\n+\n+    for i in range(10):\n+        result = node1.query(\"SELECT count() FROM system.replication_queue\")\n+        if int(result) == 0:\n+            break\n+        time.sleep(1)\n+    else:\n+        assert False, \"Still have something in replication queue:\\n\" + node1.query(\"SELECT * FROM system.replication_queue FORMAT Vertical\")\n+\n+    assert_eq_with_retry(node1, \"SELECT COUNT() FROM mt2\", \"1\")\n+    assert_eq_with_retry(node1, \"SELECT SUM(id) FROM mt2\", \"777\")\n+    assert_eq_with_retry(node1, \"SELECT COUNT() FROM system.replication_queue\", \"0\")\n+\n+    node2.query(\"SYSTEM START REPLICATION QUEUES\")\n+\n+    assert_eq_with_retry(node2, \"SELECT COUNT() FROM mt2\", \"1\")\n+    assert_eq_with_retry(node2, \"SELECT SUM(id) FROM mt2\", \"777\")\n+    assert_eq_with_retry(node2, \"SELECT COUNT() FROM system.replication_queue\", \"0\")\n+\n+\n+def test_lost_last_part(start_cluster):\n+    for node in [node1, node2]:\n+        node.query(\n+            \"CREATE TABLE mt3 (id UInt64) ENGINE ReplicatedMergeTree('/clickhouse/tables/t3', '{}') ORDER BY tuple()\".format(node.name))\n+\n+    node1.query(\"SYSTEM STOP MERGES mt3\")\n+    node2.query(\"SYSTEM STOP REPLICATION QUEUES\")\n+\n+    for i in range(1):\n+        node1.query(\"INSERT INTO mt3 VALUES ({})\".format(i))\n+\n+    # actually not important\n+    node1.query(\"ALTER TABLE mt3 UPDATE id = 777 WHERE 1\", settings={\"mutations_sync\": \"0\"})\n+\n+    remove_part_from_disk(node1, 'mt3', 'all_0_0_0')\n+\n+    # other way to detect broken parts\n+    node1.query(\"CHECK TABLE mt3\")\n+\n+    node1.query(\"SYSTEM START MERGES mt3\")\n+\n+    for i in range(10):\n+        result = node1.query(\"SELECT count() FROM system.replication_queue\")\n+        assert int(result) <= 1, \"Have a lot of entries in queue {}\".format(node1.query(\"SELECT * FROM system.replication_queue FORMAT Vertical\"))\n+        if node1.contains_in_log(\"Cannot create empty part\") and node1.contains_in_log(\"DROP PARTITION\"):\n+            break\n+        time.sleep(1)\n+    else:\n+        assert False, \"Don't have required messages in node1 log\"\n+\n+    node1.query(\"ALTER TABLE mt3 DROP PARTITION ID 'all'\")\n+\n+    assert_eq_with_retry(node1, \"SELECT COUNT() FROM mt3\", \"0\")\n+    assert_eq_with_retry(node1, \"SELECT COUNT() FROM system.replication_queue\", \"0\")\n",
  "problem_statement": "Some merges may stuck\nThis bug is discovered on Yandex.Metrica servers.\r\n\r\nIf there is assigned merge but some parts in between of the range of parts to merge get lost on all replicas, the merge cannot proceed and the following messages will be printed in log:\r\n\r\n```\r\nExecuting log entry to merge parts ...\r\nDon't have all parts for merge ...; will try to fetch it instead\r\nNo active replica has part ...\r\nChecking part ...\r\nChecking if anyone has a part covering ...\r\nFound parts with the same min block and with the same max block as the missing part ... Hoping that it will eventually appear as a result of a merge.\r\n```\r\n\r\nAnd in system.replication_log you will see the following entries:\r\n```\r\nNot executing log entry for part ... because it is covered by part ... that is currently executing\r\nNo active replica has part ... or covering part\r\n```\r\n\r\nActually this logic exists as a safety measure when automated action is not possible: https://github.com/ClickHouse/ClickHouse/pull/1251\r\n\r\nAnd it's unclear how to fix it in code.\n",
  "hints_text": "Maybe simply check all parts participating in merge?\nHow to fix it manually:\r\n\r\n1. `SELECT * FROM system.replication_queue WHERE create_time < now() - INTERVAL 1 DAY AND type = 'MERGE_PARTS' AND last_exception LIKE '%No active replica has part%' \\G`\r\n2. `SELECT replica_path || '/queue/' || node_name FROM system.replication_queue JOIN system.replicas USING (database, table) WHERE create_time < now() - INTERVAL 1 DAY AND type = 'MERGE_PARTS' AND last_exception LIKE '%No active replica has part%'`\r\n3. Delete these nodes from ZooKeeper.\r\nExample:\r\n```\r\nclickhouse-client --query \"SELECT replica_path || '/queue/' || node_name FROM system.replication_queue JOIN system.replicas USING (database, table) WHERE create_time < now() - INTERVAL 1 DAY AND type = 'MERGE_PARTS' AND last_exception LIKE '%No active replica has part%'\" | while read i; do zk-cli.py --host ... -n $i rm; done\r\n```\r\n4. `SYSTEM RESTART REPLICAS`\r\n\r\nDo all these steps on all replicas.\r\nRepeat until the issue disappear.\n>will try to fetch it instead -> No active replica has part\r\n\r\na) Introduce some counter `fetch_try_no_active` and give up after 10 (100 ( configurable)) tries?\r\nb) Without automation: `alter table drop part xxx force` / `optimize table partition yyyy force`\nrelated #2755\nI've encountered similar issue twice. In both cases it happened when all replicas were restarting while there were many active inserts. Then some table in some shard failed to merge anymore with bloated replication_queue (> 1000 entries)\nRelated #25168 (posting here to have cross-references between these related issues)",
  "created_at": "2021-06-29T15:18:07Z",
  "modified_files": [
    "src/Storages/MergeTree/MergeTreeData.cpp",
    "src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp",
    "src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp",
    "src/Storages/MergeTree/ReplicatedMergeTreeQueue.h",
    "src/Storages/StorageReplicatedMergeTree.cpp",
    "src/Storages/StorageReplicatedMergeTree.h"
  ],
  "modified_test_files": [
    "b/tests/integration/test_lost_part/__init__.py",
    "b/tests/integration/test_lost_part/test.py"
  ]
}