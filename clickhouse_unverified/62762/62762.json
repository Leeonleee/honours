{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 62762,
  "instance_id": "ClickHouse__ClickHouse-62762",
  "issue_numbers": [
    "62686"
  ],
  "base_commit": "7525b2acf438d52c9768565ccbe4c03cb8d030d9",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeReaderCompact.cpp b/src/Storages/MergeTree/MergeTreeReaderCompact.cpp\nindex a22bff6b8d22..53acfd539fb1 100644\n--- a/src/Storages/MergeTree/MergeTreeReaderCompact.cpp\n+++ b/src/Storages/MergeTree/MergeTreeReaderCompact.cpp\n@@ -204,7 +204,6 @@ void MergeTreeReaderCompact::readPrefix(\n         else\n             serialization = getSerializationInPart(name_and_type);\n \n-\n         deserialize_settings.getter = buffer_getter;\n         serialization->deserializeBinaryBulkStatePrefix(deserialize_settings, deserialize_binary_bulk_state_map[name_and_type.name]);\n     }\ndiff --git a/src/Storages/StorageMergeTreeIndex.cpp b/src/Storages/StorageMergeTreeIndex.cpp\nindex 329275f46054..9ecefc5a3dcb 100644\n--- a/src/Storages/StorageMergeTreeIndex.cpp\n+++ b/src/Storages/StorageMergeTreeIndex.cpp\n@@ -68,8 +68,8 @@ class MergeTreeIndexSource : public ISource, WithContext\n         const auto & part_name_column = StorageMergeTreeIndex::part_name_column;\n         const auto & mark_number_column = StorageMergeTreeIndex::mark_number_column;\n         const auto & rows_in_granule_column = StorageMergeTreeIndex::rows_in_granule_column;\n-\n         const auto & index = part->getIndex();\n+\n         Columns result_columns(num_columns);\n         for (size_t pos = 0; pos < num_columns; ++pos)\n         {\n@@ -79,7 +79,19 @@ class MergeTreeIndexSource : public ISource, WithContext\n             if (index_header.has(column_name))\n             {\n                 size_t index_position = index_header.getPositionByName(column_name);\n-                result_columns[pos] = index[index_position];\n+\n+                /// Some of the columns from suffix of primary index may be not loaded\n+                /// according to setting 'primary_key_ratio_of_unique_prefix_values_to_skip_suffix_columns'.\n+                if (index_position < index.size())\n+                {\n+                    result_columns[pos] = index[index_position];\n+                }\n+                else\n+                {\n+                    const auto & index_type = index_header.getByPosition(index_position).type;\n+                    auto index_column = index_type->createColumnConstWithDefaultValue(num_rows);\n+                    result_columns[pos] = index_column->convertToFullColumnIfConst();\n+                }\n             }\n             else if (column_name == part_name_column.name)\n             {\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03128_merge_tree_index_lazy_load.reference b/tests/queries/0_stateless/03128_merge_tree_index_lazy_load.reference\nnew file mode 100644\nindex 000000000000..022457178ec0\n--- /dev/null\n+++ b/tests/queries/0_stateless/03128_merge_tree_index_lazy_load.reference\n@@ -0,0 +1,8 @@\n+0\t0\t0\n+1\t4\t4\n+2\t8\t8\n+3\t9\t9\n+0\t0\t0\n+1\t4\t0\n+2\t8\t0\n+3\t9\t0\ndiff --git a/tests/queries/0_stateless/03128_merge_tree_index_lazy_load.sql b/tests/queries/0_stateless/03128_merge_tree_index_lazy_load.sql\nnew file mode 100644\nindex 000000000000..19f00e7dcad7\n--- /dev/null\n+++ b/tests/queries/0_stateless/03128_merge_tree_index_lazy_load.sql\n@@ -0,0 +1,16 @@\n+DROP TABLE IF EXISTS t_index_lazy_load;\n+\n+CREATE TABLE t_index_lazy_load (a UInt64, b UInt64)\n+ENGINE = MergeTree ORDER BY (a, b)\n+SETTINGS index_granularity = 4, primary_key_ratio_of_unique_prefix_values_to_skip_suffix_columns = 0.5;\n+\n+INSERT INTO t_index_lazy_load SELECT number, number FROM numbers(10);\n+\n+SELECT mark_number, a, b FROM mergeTreeIndex(currentDatabase(), t_index_lazy_load) ORDER BY mark_number;\n+\n+DETACH TABLE t_index_lazy_load;\n+ATTACH TABLE t_index_lazy_load;\n+\n+SELECT mark_number, a, b FROM mergeTreeIndex(currentDatabase(), t_index_lazy_load) ORDER BY mark_number;\n+\n+DROP TABLE t_index_lazy_load;\n",
  "problem_statement": "The mergeTreeIndex table function causes the server crash\nThe following two queries cause the server crash.\r\n\r\n```\r\n select * from mergeTreeIndex(test, ram_log_local_token)\r\n select * from mergeTreeIndex(test, ram_log_local_token, with_marks = false)\r\n```\r\n\r\n```\r\n2024.04.16 17:58:03.356456 [ 46544 ] {} <Fatal> BaseDaemon: ########################################\r\n2024.04.16 17:58:03.356484 [ 46544 ] {} <Fatal> BaseDaemon: (version 24.3.2.23 (official build), build id: DA47C8C3B6BA55C4A326D4DD33ACED2DFEA5DA96, git hash: 8b7d910960cc2c6a0db07991fe2576a67fe98146) (from thread 46302) (query_id: ce5e28b0e041789ca5cc80febfd6e5bd) (query: select * from mergeTreeIndex(test, ram_log_local_token)) Received signal Segmentation fault (11)\r\n2024.04.16 17:58:03.356527 [ 46544 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Unknown si_code.\r\n2024.04.16 17:58:03.356546 [ 46544 ] {} <Fatal> BaseDaemon: Stack trace: 0x00000000123a6217 0x00000000117e174f 0x00000000123b5835 0x00000000123b52c2 0x00000000123d04fa 0x00000000123c4a50 0x00000000123c3ec1 0x00000000123c2652 0x000000001127623b 0x00000000122f3295 0x00000000122f7d54 0x00000000123772fa 0x0000000014c9bef2 0x0000000014c9cd39 0x0000000014d954a1 0x0000000014d93a3d 0x00007fc9215f5ea5 0x00007fc92131eb0d\r\n2024.04.16 17:58:03.356667 [ 46544 ] {} <Fatal> BaseDaemon: 2. DB::Chunk::checkNumRowsIsConsistent() @ 0x00000000123a6217\r\n2024.04.16 17:58:03.356731 [ 46544 ] {} <Fatal> BaseDaemon: 3. DB::MergeTreeIndexSource::generate() @ 0x00000000117e174f\r\n2024.04.16 17:58:03.356762 [ 46544 ] {} <Fatal> BaseDaemon: 4. DB::ISource::tryGenerate() @ 0x00000000123b5835\r\n2024.04.16 17:58:03.356803 [ 46544 ] {} <Fatal> BaseDaemon: 5. DB::ISource::work() @ 0x00000000123b52c2\r\n2024.04.16 17:58:03.356850 [ 46544 ] {} <Fatal> BaseDaemon: 6. DB::ExecutionThreadContext::executeTask() @ 0x00000000123d04fa\r\n2024.04.16 17:58:03.356904 [ 46544 ] {} <Fatal> BaseDaemon: 7. DB::PipelineExecutor::executeStepImpl(unsigned long, std::atomic<bool>*) @ 0x00000000123c4a50\r\n2024.04.16 17:58:03.356953 [ 46544 ] {} <Fatal> BaseDaemon: 8. DB::PipelineExecutor::execute(unsigned long, bool) @ 0x00000000123c3ec1\r\n2024.04.16 17:58:03.356981 [ 46544 ] {} <Fatal> BaseDaemon: 9. DB::CompletedPipelineExecutor::execute() @ 0x00000000123c2652\r\n2024.04.16 17:58:03.357038 [ 46544 ] {} <Fatal> BaseDaemon: 10. DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, std::shared_ptr<DB::Context>, std::function<void (DB::QueryResultDetails const&)>, DB::QueryFlags, std::optional<DB::FormatSettings> const&, std::function<void (DB::IOutputFormat&)>) @ 0x000000001127623b\r\n2024.04.16 17:58:03.357082 [ 46544 ] {} <Fatal> BaseDaemon: 11. DB::HTTPHandler::processQuery(DB::HTTPServerRequest&, DB::HTMLForm&, DB::HTTPServerResponse&, DB::HTTPHandler::Output&, std::optional<DB::CurrentThread::QueryScope>&, StrongTypedef<unsigned long, ProfileEvents::EventTag> const&) @ 0x00000000122f3295\r\n2024.04.16 17:58:03.357117 [ 46544 ] {} <Fatal> BaseDaemon: 12. DB::HTTPHandler::handleRequest(DB::HTTPServerRequest&, DB::HTTPServerResponse&, StrongTypedef<unsigned long, ProfileEvents::EventTag> const&) @ 0x00000000122f7d54\r\n2024.04.16 17:58:03.357153 [ 46544 ] {} <Fatal> BaseDaemon: 13. DB::HTTPServerConnection::run() @ 0x00000000123772fa\r\n2024.04.16 17:58:03.357191 [ 46544 ] {} <Fatal> BaseDaemon: 14. Poco::Net::TCPServerConnection::start() @ 0x0000000014c9bef2\r\n2024.04.16 17:58:03.357251 [ 46544 ] {} <Fatal> BaseDaemon: 15. Poco::Net::TCPServerDispatcher::run() @ 0x0000000014c9cd39\r\n2024.04.16 17:58:03.357279 [ 46544 ] {} <Fatal> BaseDaemon: 16. Poco::PooledThread::run() @ 0x0000000014d954a1\r\n2024.04.16 17:58:03.357306 [ 46544 ] {} <Fatal> BaseDaemon: 17. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000014d93a3d\r\n2024.04.16 17:58:03.357386 [ 46544 ] {} <Fatal> BaseDaemon: 18. start_thread @ 0x0000000000007ea5\r\n2024.04.16 17:58:03.357469 [ 46544 ] {} <Fatal> BaseDaemon: 19. clone @ 0x00000000000feb0d\r\n2024.04.16 17:58:03.560076 [ 46544 ] {} <Fatal> BaseDaemon: Integrity check of the executable successfully passed (checksum: 3D80E1F632C131451BEFC024AB379208)\r\n```\r\n\r\nThe table has a schema as follows and 508.78 million rows in the table.\r\n\r\n```\r\nCREATE TABLE test.ram_log_local_token\r\n(\r\n    `timestamp` DateTime64(3) CODEC(Delta(8), ZSTD(1)),\r\n    `idc` LowCardinality(String),\r\n    `az` LowCardinality(String),\r\n    `env` LowCardinality(String),\r\n    `service` LowCardinality(String),\r\n    `cid` LowCardinality(String),\r\n    `host` LowCardinality(String),\r\n    `source` String CODEC(ZSTD(1)),\r\n    `module` String CODEC(ZSTD(1)),\r\n    `level` LowCardinality(String),\r\n    `logger` String CODEC(ZSTD(1)),\r\n    `thread` String CODEC(ZSTD(1)),\r\n    `file` String CODEC(ZSTD(1)),\r\n    `line` Int32 CODEC(ZSTD(1)),\r\n    `traceId` String CODEC(ZSTD(1)),\r\n    `message` String CODEC(ZSTD(1)),\r\n    `message_length` Int32 DEFAULT length(message) CODEC(ZSTD(1)),\r\n    INDEX idx_message message TYPE tokenbf_v1(32768, 3, 2) GRANULARITY 1\r\n)\r\nENGINE = ReplicatedMergeTree\r\nPARTITION BY toYYYYMM(timestamp)\r\nORDER BY (idc, env, service, toStartOfMinute(timestamp), level, logger, thread, host)\r\n```\r\n\r\nHave not yet checked the code, report first.\n",
  "hints_text": "there is at least one problem: when some of the index columns are not loaded we can crash on trying to accessing them",
  "created_at": "2024-04-18T14:47:45Z"
}