{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 40017,
  "instance_id": "ClickHouse__ClickHouse-40017",
  "issue_numbers": [
    "34755"
  ],
  "base_commit": "b827f3bccf9f0d5a7efb2493942362ca989d8f3c",
  "patch": "diff --git a/docker/packager/binary/build.sh b/docker/packager/binary/build.sh\nindex fb2b08a26335..c2de0e33d82b 100755\n--- a/docker/packager/binary/build.sh\n+++ b/docker/packager/binary/build.sh\n@@ -104,6 +104,7 @@ if [ -n \"$MAKE_DEB\" ]; then\n fi\n \n mv ./programs/clickhouse* /output\n+[ -x ./programs/self-extracting/clickhouse ] && mv ./programs/self-extracting/clickhouse /output\n mv ./src/unit_tests_dbms /output ||: # may not exist for some binary builds\n find . -name '*.so' -print -exec mv '{}' /output \\;\n find . -name '*.so.*' -print -exec mv '{}' /output \\;\n",
  "test_patch": "diff --git a/docker/test/fuzzer/run-fuzzer.sh b/docker/test/fuzzer/run-fuzzer.sh\nindex f74760e33394..392d81105764 100755\n--- a/docker/test/fuzzer/run-fuzzer.sh\n+++ b/docker/test/fuzzer/run-fuzzer.sh\n@@ -69,6 +69,8 @@ function download\n     wget_with_retry \"$BINARY_URL_TO_DOWNLOAD\"\n \n     chmod +x clickhouse\n+    # clickhouse may be compressed - run once to decompress\n+    ./clickhouse ||:\n     ln -s ./clickhouse ./clickhouse-server\n     ln -s ./clickhouse ./clickhouse-client\n \n",
  "problem_statement": "Make `clickhouse` binary a self extracting executable.\n**Use case**\r\n\r\n1. More quick downloads but without the need of unpacking or installing any separate tools.\r\n2. Include `odbc-bridge` and `library-bridge` in single-binary ClickHouse downloads despite the fact that they are separate binaries.\r\n3. Maybe the size will be ok to always include debug info, even in .deb/.rpm packages.\r\n4. It will also speed up cold start in the cloud.\r\n5. #29378\r\n\r\n**Describe the solution you'd like**\r\n\r\nCompile a tool that can compress and decompress with ZSTD. It can use the official zstd framing format but not necessarily. It should support compression by blocks of size around 10..100 MiB (to avoid too high memory usage) and checksums. It should not depend on glibc version, and even better if it will be statically linked. Maybe two tools - one for compression and another for decompression.\r\n\r\nPost-build rule will compress `clickhouse` (and possibly `clickhouse-odbc-bridge` and `clickhouse-jdbc-bridge`) binary into blob and then include it into the decompressor with `llvm-objcopy` as a custom ELF section (alternatively - maybe we can concatenate it after the decompressor binary).\r\n\r\nDecompressor should check the free space in the current directory, decompress the content into temporary file with a similar name (like `clickhouse.tmp`), perform `fsync`, rename the current binary to a file with similar name (like `.compressed`), rename the decompressed binary to the original name, delete the compressed binary and run the decompressed binary with the same arguments.\r\n\r\nIf `clickhouse-odbc-bridge` and `clickhouse-odbc-bridge` binaries are present, they should be extracted into current directory and `clickhouse install` script should check if they are present.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nThere are existing specialized tools for compressing executables (like UPX). But zstd will do it better.\r\n\r\n**Additional context**\r\n\r\nA shortcut for `clickhouse install` in the decompressor can be implemented to avoid extra file copies (first into current directory then to the install destination like `/usr/bin`).\r\n\r\nIt makes sense to parallelize decompression.\n",
  "hints_text": "@yakov-olkhovskiy AFAICS this issue is still not resolved, since #38447 only generates such binary, but it is not used anywhere. Am I missing something? Or the initial plan had been changed?\n@azat \r\noh, missed PR was marked as closing this issue\r\nreopening\r\nI will change deployment script tomorrow since it will depend on having this executable ready\nnot finished yet\nAnother idea is just to compress debug-symbols. Found an interesting [article](https://interrupt.memfault.com/blog/dealing-with-large-symbol-files). It says that the best option is to use `dwz` (DWARF table optimiser) +  `llvm-objcopy --compress-debug-sections`.  For ClickHouse this approach reduces around 50% binary. I just downloaded 2.1G release binary with symbols from CI. After using `dwz` it became 1.9G and when I compressed debug-symbols it because 883Mb which more or less Ok. Note, that stripped binary is around 450Mb. Here is `bloaty` output for clickhouse \r\n```\r\nubuntu@ip-10-1-13-116:~/trash$ bloaty clickhouse\r\n    FILE SIZE        VM SIZE\r\n --------------  --------------\r\n  30.2%   640Mi   0.0%       0    .debug_info\r\n  20.1%   426Mi   0.0%       0    .debug_loc\r\n  13.6%   287Mi  63.6%   287Mi    .text\r\n  11.8%   250Mi   0.0%       0    .debug_str\r\n   5.5%   116Mi   0.0%       0    .debug_ranges\r\n   5.3%   113Mi   0.0%       0    .debug_line\r\n   4.5%  94.6Mi   0.0%       0    .strtab\r\n   2.5%  52.8Mi  11.7%  52.8Mi    .rodata\r\n   2.4%  51.8Mi  11.4%  51.8Mi    .dynstr\r\n   1.3%  27.0Mi   6.0%  27.0Mi    .eh_frame\r\n   0.9%  19.7Mi   0.0%       0    .symtab\r\n   0.6%  11.8Mi   0.0%       0    .debug_abbrev\r\n   0.5%  9.78Mi   2.2%  9.78Mi    .dynsym\r\n   0.4%  9.54Mi   2.1%  9.54Mi    .gcc_except_table\r\n   0.0%       0   0.9%  4.25Mi    .bss\r\n   0.2%  3.99Mi   0.9%  3.99Mi    .eh_frame_hdr\r\n   0.1%  3.03Mi   0.7%  3.03Mi    .gnu.hash\r\n   0.1%  1.69Mi   0.4%  1.68Mi    .data\r\n   0.0%   834Ki   0.2%   834Ki    .gnu.version\r\n   0.0%  53.7Ki   0.0%  36.1Ki    [25 Others]\r\n   0.0%       0   0.0%  25.1Ki    .tbss\r\n 100.0%  2.07Gi 100.0%   452Mi    TOTAL\r\n```\r\n\r\nand for binary with compressed debug symbols \r\n```\r\nubuntu@ip-10-1-13-116:~/trash$ bloaty clickhouse.dwz.compressed\r\n    FILE SIZE        VM SIZE\r\n --------------  --------------\r\n  32.6%   287Mi  63.6%   287Mi    .text\r\n  22.3%   196Mi   0.0%       0    .debug_info\r\n  10.7%  94.6Mi   0.0%       0    .strtab\r\n   6.0%  52.9Mi   0.0%       0    .debug_loc\r\n   6.0%  52.8Mi  11.7%  52.8Mi    .rodata\r\n   5.9%  51.8Mi  11.4%  51.8Mi    .dynstr\r\n   3.4%  30.1Mi   0.0%       0    .debug_str\r\n   3.1%  27.0Mi   6.0%  27.0Mi    .eh_frame\r\n   2.8%  24.5Mi   0.0%       0    .debug_line\r\n   2.2%  19.7Mi   0.0%       0    .symtab\r\n   1.5%  13.4Mi   0.0%       0    .debug_ranges\r\n   1.1%  9.78Mi   2.2%  9.78Mi    .dynsym\r\n   1.1%  9.54Mi   2.1%  9.54Mi    .gcc_except_table\r\n   0.0%       0   0.9%  4.25Mi    .bss\r\n   0.5%  3.99Mi   0.9%  3.99Mi    .eh_frame_hdr\r\n   0.3%  3.03Mi   0.7%  3.03Mi    .gnu.hash\r\n   0.2%  1.80Mi   0.0%       0    .debug_abbrev\r\n   0.2%  1.69Mi   0.4%  1.68Mi    .data\r\n   0.1%   834Ki   0.2%   834Ki    .gnu.version\r\n   0.0%  52.8Ki   0.0%  36.1Ki    [25 Others]\r\n   0.0%       0   0.0%  25.1Ki    .tbss\r\n 100.0%   882Mi 100.0%   452Mi    TOTAL\r\n```\r\n\r\nWe can then even use `upx` to reduce the binary size more dramatically. But for me it did't work out the box and after executing this the upx'ed ClickHouse binary started to produce `Code: 464. DB::Exception: The ELF is truncated (section header points after end of file). (CANNOT_PARSE_ELF), Stack trace (when copying this message, always include the lines below):` error. Didn't dig deeper into it. But this is some output of bloaty and file. \r\n\r\n```\r\nubuntu@ip-10-1-13-116:~/trash$ bloaty clickhouse.stripped\r\n    FILE SIZE        VM SIZE\r\n --------------  --------------\r\n   0.0%       0  74.4%   336Mi    [LOAD #1 [RW]]\r\n 100.0%   115Mi  25.6%   115Mi    [LOAD #0 [RX]]\r\n   0.0%  1.09Ki   0.0%       0    [Unmapped]\r\n 100.0%   115Mi 100.0%   452Mi    TOTAL\r\nubuntu@ip-10-1-13-116:~/trash$ file clickhouse.stripped\r\nclickhouse.stripped: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, no section header\r\n```\r\n\r\nThis is much more simpler than writing our own compressor / decompressor and dealing with tons of CMake code and arguments escaping. And it will simplify debugging a lot without installing additional `dbg` package.\r\nWe can even put `upx`'ed binary to Alpine-based imaged and binary with compressed debug-info to Ubuntu-based images. And name them `clickhouse-server` and `clickhouse-server-slim` for example.  WDYT @alexey-milovidov ?\n@nikitamikhaylov There was already an attempt to do so, by seems that internal DWARF interpreter cannot handle compressed debug symbols - https://github.com/ClickHouse/ClickHouse/pull/18952#issuecomment-758112335\r\n\r\nAnd adding this support may make it slower and this will increase random latencies when the stack will be unwinded from non-cached locations, while extracting it each time at start may take some extra time, which also not a good way to go for me.\r\n\r\nSo, not sure that it will be better, plus right now, the major problem I guess is the artifacts size not the official packages size, since later does not created too often, unlike artifacts.\n@azat I saw problem with Dwarf parser only when using `upx`. When just compress debug symbols, everything works correctly but seems these symbols are not being used...  For example when I just send 11 signal to running server \r\n```\r\n2022.08.04 12:38:49.480834 [ 710212 ] {} <Trace> BaseDaemon: Received signal 11\r\n2022.08.04 12:38:49.481026 [ 710509 ] {} <Fatal> BaseDaemon: ########################################\r\n2022.08.04 12:38:49.481068 [ 710509 ] {} <Fatal> BaseDaemon: (version 22.8.1.825 (official build), build id: 7E15CA8E88D65698) (from thread 710211) (no query) Received signal Segmentation fault (11)\r\n2022.08.04 12:38:49.481083 [ 710509 ] {} <Fatal> BaseDaemon:  Access: read. Unknown si_code.\r\n2022.08.04 12:38:49.481098 [ 710509 ] {} <Fatal> BaseDaemon: Stack trace: 0x7f80b570b376 0xa579bdb 0xa3c790e 0x19130646 0xa3b26de 0xa3afaa8 0xa311519 0x7f80b552e083 0xa0d262e\r\n2022.08.04 12:38:49.481120 [ 710509 ] {} <Fatal> BaseDaemon: 2. pthread_cond_wait in ?\r\n2022.08.04 12:38:49.481144 [ 710509 ] {} <Fatal> BaseDaemon: 3. BaseDaemon::waitForTerminationRequest() in /home/ubuntu/trash/clickhouse.dwz.compressed\r\n2022.08.04 12:38:49.481162 [ 710509 ] {} <Fatal> BaseDaemon: 4. DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) in /home/ubuntu/trash/clickhouse.dwz.compressed\r\n2022.08.04 12:38:49.481177 [ 710509 ] {} <Fatal> BaseDaemon: 5. Poco::Util::Application::run() in /home/ubuntu/trash/clickhouse.dwz.compressed\r\n2022.08.04 12:38:49.481189 [ 710509 ] {} <Fatal> BaseDaemon: 6. DB::Server::run() in /home/ubuntu/trash/clickhouse.dwz.compressed\r\n2022.08.04 12:38:49.481200 [ 710509 ] {} <Fatal> BaseDaemon: 7. mainEntryClickHouseServer(int, char**) in /home/ubuntu/trash/clickhouse.dwz.compressed\r\n2022.08.04 12:38:49.481213 [ 710509 ] {} <Fatal> BaseDaemon: 8. main in /home/ubuntu/trash/clickhouse.dwz.compressed\r\n2022.08.04 12:38:49.481222 [ 710509 ] {} <Fatal> BaseDaemon: 9. __libc_start_main in ?\r\n2022.08.04 12:38:49.481236 [ 710509 ] {} <Fatal> BaseDaemon: 10. _start in /home/ubuntu/trash/clickhouse.dwz.compressed\r\n2022.08.04 12:38:49.634426 [ 710509 ] {} <Fatal> BaseDaemon: Integrity check of the executable successfully passed (checksum: FEFEA47369F0FA0C30683975BF8DC041)\r\n```\r\nAnd `add2line` started to work extremely slow...",
  "created_at": "2022-08-09T06:46:54Z"
}