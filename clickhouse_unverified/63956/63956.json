{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 63956,
  "instance_id": "ClickHouse__ClickHouse-63956",
  "issue_numbers": [
    "63863",
    "63859"
  ],
  "base_commit": "e1389c16266b3d995d6ebb512d2742b5dfc3e5de",
  "patch": "diff --git a/src/DataTypes/Serializations/SerializationLowCardinality.cpp b/src/DataTypes/Serializations/SerializationLowCardinality.cpp\nindex 2d2be195098a..18d6e48623b1 100644\n--- a/src/DataTypes/Serializations/SerializationLowCardinality.cpp\n+++ b/src/DataTypes/Serializations/SerializationLowCardinality.cpp\n@@ -515,8 +515,14 @@ void SerializationLowCardinality::deserializeBinaryBulkWithMultipleStreams(\n     size_t limit,\n     DeserializeBinaryBulkSettings & settings,\n     DeserializeBinaryBulkStatePtr & state,\n-    SubstreamsCache * /* cache */) const\n+    SubstreamsCache * cache) const\n {\n+    if (auto cached_column = getFromSubstreamsCache(cache, settings.path))\n+    {\n+        column = cached_column;\n+        return;\n+    }\n+\n     auto mutable_column = column->assumeMutable();\n     ColumnLowCardinality & low_cardinality_column = typeid_cast<ColumnLowCardinality &>(*mutable_column);\n \n@@ -670,6 +676,7 @@ void SerializationLowCardinality::deserializeBinaryBulkWithMultipleStreams(\n     }\n \n     column = std::move(mutable_column);\n+    addToSubstreamsCache(cache, settings.path, column);\n }\n \n void SerializationLowCardinality::serializeBinary(const Field & field, WriteBuffer & ostr, const FormatSettings & settings) const\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03156_tuple_map_low_cardinality.reference b/tests/queries/0_stateless/03156_tuple_map_low_cardinality.reference\nnew file mode 100644\nindex 000000000000..5b2a36927ee5\n--- /dev/null\n+++ b/tests/queries/0_stateless/03156_tuple_map_low_cardinality.reference\n@@ -0,0 +1,6 @@\n+100000\n+100000\n+100000\n+100000\n+100000\n+100000\ndiff --git a/tests/queries/0_stateless/03156_tuple_map_low_cardinality.sql b/tests/queries/0_stateless/03156_tuple_map_low_cardinality.sql\nnew file mode 100644\nindex 000000000000..836b426a9a93\n--- /dev/null\n+++ b/tests/queries/0_stateless/03156_tuple_map_low_cardinality.sql\n@@ -0,0 +1,33 @@\n+DROP TABLE IF EXISTS t_map_lc;\n+\n+CREATE TABLE t_map_lc\n+(\n+    id UInt64,\n+    t Tuple(m Map(LowCardinality(String), LowCardinality(String)))\n+)\n+ENGINE = MergeTree ORDER BY id SETTINGS min_bytes_for_wide_part = 0;\n+\n+INSERT INTO t_map_lc SELECT * FROM generateRandom('id UInt64, t Tuple(m Map(LowCardinality(String), LowCardinality(String)))') LIMIT 100000;\n+\n+SELECT count(), FROM t_map_lc WHERE NOT ignore(*,  mapKeys(t.m));\n+SELECT count(), FROM t_map_lc WHERE NOT ignore(*,  t.m.keys);\n+SELECT count(), FROM t_map_lc WHERE NOT ignore(*,  t.m.values);\n+SELECT * FROM t_map_lc WHERE mapContains(t.m, 'not_existing_key_1337');\n+\n+DROP TABLE t_map_lc;\n+\n+CREATE TABLE t_map_lc\n+(\n+    id UInt64,\n+    t Tuple(m Map(LowCardinality(String), LowCardinality(String)))\n+)\n+ENGINE = MergeTree ORDER BY id SETTINGS min_bytes_for_wide_part = '10G';\n+\n+INSERT INTO t_map_lc SELECT * FROM generateRandom('id UInt64, t Tuple(m Map(LowCardinality(String), LowCardinality(String)))') LIMIT 100000;\n+\n+SELECT count(), FROM t_map_lc WHERE NOT ignore(*,  mapKeys(t.m));\n+SELECT count(), FROM t_map_lc WHERE NOT ignore(*,  t.m.keys);\n+SELECT count(), FROM t_map_lc WHERE NOT ignore(*,  t.m.values);\n+SELECT * FROM t_map_lc WHERE mapContains(t.m, 'not_existing_key_1337');\n+\n+DROP TABLE t_map_lc;\n",
  "problem_statement": "Locally querying a Map(LowCardinality(String), String)) inside a Tuple leads to segfault in clickhouse server\n**Describe what's wrong**\r\n\r\nLocally querying a Map(LowCardinality(String, String)) containing more than 254 keys leads to segmentation fault in the server when the table contains around 4000 rows or more.\r\n\r\n**Does it reproduce on the most recent release?**\r\n\r\n- `head (24.5.1.1106)`: https://fiddle.clickhouse.com/6d680e44-3828-42d3-8ad2-fff8209dce4c\r\n- `24.4.1.2088`: https://fiddle.clickhouse.com/65d0fb52-ce1c-4e41-8c5f-2fabfcf70337\r\n- `26.8.14.6`: https://fiddle.clickhouse.com/c6f7c8ab-660e-4c4f-b95e-39d8407dc950\r\n\r\n\r\n**How to reproduce**\r\n\r\n`clickhouse client --stacktrace --queries-file poc.sql`\r\n```sql\r\nCREATE OR REPLACE TABLE crash_poc\r\n(\r\n    id UInt64,\r\n    crash Tuple\r\n    (\r\n        data Map(LowCardinality(String), String)\r\n    ) \r\n)\r\nENGINE = MergeTree\r\nORDER BY id;\r\nINSERT INTO crash_poc\r\nSELECT * FROM url('https://gist.githubusercontent.com/3ster/e499d1cfd53966ab5498fb6881f44e84/raw/52521c733d0bcf649cc44419b23f4b93ae3a5f73/crash_data.parquet');\r\nSELECT * FROM crash_poc WHERE mapContains(crash.data, 'not_existent_123') LIMIT 1;\r\n```\r\n\r\nBoth changing event_data to Map(String, String) and moving event_data out of the winlog Tuple prevent the error from happening. The ingested URL contains 4K rows of random data and is publicly accessible.\r\n\r\n**Expected behavior**\r\n\r\nServer should not segfault.\r\n\r\n**Error message and/or stacktrace**\r\n\r\n```\r\n[406cc05e9261] 2024.05.15 16:00:38.126305 [ 52492 ] <Fatal> BaseDaemon: ########################################\r\n[406cc05e9261] 2024.05.15 16:00:38.126367 [ 52492 ] <Fatal> BaseDaemon: (version 24.4.1.2088 (official build), build id: 8474BE9DB7BA90A8E303C2F4B836BA6EC5A57A63, git hash: 6d4b31322d168356c8b10c43b4cef157c82337ff) (from thread 52415) (query_id: abc7242c-2252-496b-a8d1-65628f4ca147) (query: SELECT * FROM crash_poc WHERE mapContains(crash.data, 'not_existent_123') LIMIT 1;) Received signal Segmentation fault (11)\r\n[406cc05e9261] 2024.05.15 16:00:38.126395 [ 52492 ] <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Unknown si_code.\r\n[406cc05e9261] 2024.05.15 16:00:38.126424 [ 52492 ] <Fatal> BaseDaemon: Stack trace: 0x000000000c017905 0x000000000bfe90e8 0x000000000bfe1f13 0x000000000bfdf626 0x000000000bfdecca 0x0000000007913eee 0x000000000f69433e 0x000000000f694ebe 0x000000000f69645b 0x0000000010411d99 0x00000000125a1283 0x00000000125a1034 0x000000000e3c1ef0 0x0000000012307792 0x00000000123257a8 0x0000000012319a90 0x0000000012318f01 0x00000000123290c2 0x000000000ca5e62d 0x00007f0ed3235609 0x00007f0ed3150353\r\n[406cc05e9261] 2024.05.15 16:00:38.126523 [ 52492 ] <Fatal> BaseDaemon: 2. void DB::Impl::String<DB::HasAction>::processImpl<true, false, false>(DB::PODArray<char8_t, 4096ul, Allocator<false, false>, 63ul, 64ul> const&, DB::PODArray<unsigned long, 4096ul, Allocator<false, false>, 63ul, 64ul> const&, DB::PODArray<unsigned long, 4096ul, Allocator<false, false>, 63ul, 64ul> const&, DB::PODArray<char8_t, 4096ul, Allocator<false, false>, 63ul, 64ul> const&, std::conditional<true, unsigned long, DB::PODArray<unsigned long, 4096ul, Allocator<false, false>, 63ul, 64ul> const&>::type, DB::PODArray<char8_t, 4096ul, Allocator<false, false>, 63ul, 64ul>&, DB::PODArray<char8_t, 4096ul, Allocator<false, false>, 63ul, 64ul> const*, DB::PODArray<char8_t, 4096ul, Allocator<false, false>, 63ul, 64ul> const*) @ 0x000000000c017905\r\n[406cc05e9261] 2024.05.15 16:00:38.126589 [ 52492 ] <Fatal> BaseDaemon: 3. DB::FunctionArrayIndex<DB::HasAction, DB::NameMapContains>::executeStringImpl(DB::FunctionArrayIndex<DB::HasAction, DB::NameMapContains>::ExecutionData&) @ 0x000000000bfe90e8\r\n[406cc05e9261] 2024.05.15 16:00:38.126623 [ 52492 ] <Fatal> BaseDaemon: 4. DB::FunctionArrayIndex<DB::HasAction, DB::NameMapContains>::executeOnNonNullable(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, std::shared_ptr<DB::IDataType const> const&) const @ 0x000000000bfe1f13\r\n[406cc05e9261] 2024.05.15 16:00:38.126655 [ 52492 ] <Fatal> BaseDaemon: 5. DB::FunctionArrayIndex<DB::HasAction, DB::NameMapContains>::executeImpl(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, std::shared_ptr<DB::IDataType const> const&, unsigned long) const @ 0x000000000bfdf626\r\n[406cc05e9261] 2024.05.15 16:00:38.126688 [ 52492 ] <Fatal> BaseDaemon: 6. DB::FunctionMapToArrayAdapter<DB::FunctionArrayIndex<DB::HasAction, DB::NameMapContains>, DB::MapToSubcolumnAdapter<DB::NameMapKeys, 0ul>, DB::NameMapContains>::executeImpl(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, std::shared_ptr<DB::IDataType const> const&, unsigned long) const @ 0x000000000bfdecca\r\n[406cc05e9261] 2024.05.15 16:00:38.126723 [ 52492 ] <Fatal> BaseDaemon: 7. DB::FunctionToExecutableFunctionAdaptor::executeImpl(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, std::shared_ptr<DB::IDataType const> const&, unsigned long) const @ 0x0000000007913eee\r\n[406cc05e9261] 2024.05.15 16:00:38.126790 [ 52492 ] <Fatal> BaseDaemon: 8. DB::IExecutableFunction::executeWithoutLowCardinalityColumns(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, std::shared_ptr<DB::IDataType const> const&, unsigned long, bool) const @ 0x000000000f69433e\r\n[406cc05e9261] 2024.05.15 16:00:38.126817 [ 52492 ] <Fatal> BaseDaemon: 9. DB::IExecutableFunction::executeWithoutSparseColumns(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, std::shared_ptr<DB::IDataType const> const&, unsigned long, bool) const @ 0x000000000f694ebe\r\n[406cc05e9261] 2024.05.15 16:00:38.126853 [ 52492 ] <Fatal> BaseDaemon: 10. DB::IExecutableFunction::execute(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, std::shared_ptr<DB::IDataType const> const&, unsigned long, bool) const @ 0x000000000f69645b\r\n[406cc05e9261] 2024.05.15 16:00:38.126887 [ 52492 ] <Fatal> BaseDaemon: 11. DB::ExpressionActions::execute(DB::Block&, unsigned long&, bool, bool) const @ 0x0000000010411d99\r\n[406cc05e9261] 2024.05.15 16:00:38.126944 [ 52492 ] <Fatal> BaseDaemon: 12. DB::FilterTransform::doTransform(DB::Chunk&) @ 0x00000000125a1283\r\n[406cc05e9261] 2024.05.15 16:00:38.126975 [ 52492 ] <Fatal> BaseDaemon: 13. DB::FilterTransform::transform(DB::Chunk&) @ 0x00000000125a1034\r\n[406cc05e9261] 2024.05.15 16:00:38.127006 [ 52492 ] <Fatal> BaseDaemon: 14. DB::ISimpleTransform::transform(DB::Chunk&, DB::Chunk&) @ 0x000000000e3c1ef0\r\n[406cc05e9261] 2024.05.15 16:00:38.127037 [ 52492 ] <Fatal> BaseDaemon: 15. DB::ISimpleTransform::work() @ 0x0000000012307792\r\n[406cc05e9261] 2024.05.15 16:00:38.127067 [ 52492 ] <Fatal> BaseDaemon: 16. DB::ExecutionThreadContext::executeTask() @ 0x00000000123257a8\r\n[406cc05e9261] 2024.05.15 16:00:38.127110 [ 52492 ] <Fatal> BaseDaemon: 17. DB::PipelineExecutor::executeStepImpl(unsigned long, std::atomic<bool>*) @ 0x0000000012319a90\r\n[406cc05e9261] 2024.05.15 16:00:38.127138 [ 52492 ] <Fatal> BaseDaemon: 18. DB::PipelineExecutor::execute(unsigned long, bool) @ 0x0000000012318f01\r\n[406cc05e9261] 2024.05.15 16:00:38.127188 [ 52492 ] <Fatal> BaseDaemon: 19. void std::__function::__policy_invoker<void ()>::__call_impl<std::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true, true>::ThreadFromGlobalPoolImpl<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&&)::'lambda'(), void ()>>(std::__function::__policy_storage const*) @ 0x00000000123290c2\r\n[406cc05e9261] 2024.05.15 16:00:38.127259 [ 52492 ] <Fatal> BaseDaemon: 20. void* std::__thread_proxy[abi:v15000]<std::tuple<std::unique_ptr<std::__thread_struct, std::default_delete<std::__thread_struct>>, void ThreadPoolImpl<std::thread>::scheduleImpl<void>(std::function<void ()>, Priority, std::optional<unsigned long>, bool)::'lambda0'()>>(void*) @ 0x000000000ca5e62d\r\n[406cc05e9261] 2024.05.15 16:00:38.127286 [ 52492 ] <Fatal> BaseDaemon: 21. ? @ 0x00007f0ed3235609\r\n[406cc05e9261] 2024.05.15 16:00:38.127304 [ 52492 ] <Fatal> BaseDaemon: 22. ? @ 0x00007f0ed3150353\r\n[406cc05e9261] 2024.05.15 16:00:38.296964 [ 52492 ] <Fatal> BaseDaemon: Integrity check of the executable successfully passed (checksum: 1B4AB729A4BACA7860A3C947777632AD)\r\n[406cc05e9261] 2024.05.15 16:00:38.297618 [ 52492 ] <Fatal> BaseDaemon: Report this error to https://github.com/ClickHouse/ClickHouse/issues\r\n[406cc05e9261] 2024.05.15 16:00:38.297752 [ 52492 ] <Fatal> BaseDaemon: Changed settings: log_comment = '/workspaces/clickhouse-ingest-feat-materialized/crash.sql'\r\nError on processing query: Code: 32. DB::Exception: Attempt to read after eof: while receiving packet from localhost:9000. (ATTEMPT_TO_READ_AFTER_EOF), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000c9a449b\r\n1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000780b9ac\r\n2. DB::Exception::Exception<>(int, FormatStringHelperImpl<>) @ 0x0000000007819d8b\r\n3. DB::throwReadAfterEOF() @ 0x000000000ca28198\r\n4. DB::Connection::receivePacket() @ 0x00000000121a2828\r\n5. DB::ClientBase::receiveAndProcessPacket(std::shared_ptr<DB::IAST>, bool) @ 0x0000000012172d65\r\n6. DB::ClientBase::processParsedSingleQuery(String const&, String const&, std::shared_ptr<DB::IAST>, std::optional<bool>, bool) @ 0x0000000012170ea1\r\n7. DB::ClientBase::executeMultiQuery(String const&) @ 0x000000001217b4ce\r\n8. DB::ClientBase::processMultiQueryFromFile(String const&) @ 0x000000001217ca5c\r\n9. DB::ClientBase::runNonInteractive() @ 0x0000000012180e5c\r\n10. DB::Client::main(std::vector<String, std::allocator<String>> const&) @ 0x000000000cbbc715\r\n11. Poco::Util::Application::run() @ 0x0000000014c1d166\r\n12. mainEntryClickHouseClient(int, char**) @ 0x000000000cbcecc1\r\n13. main @ 0x0000000007807fb8\r\n14. ? @ 0x00007f2b84c70083\r\n15. _start @ 0x0000000005ea702e\r\n (version 24.4.1.2088 (official build))\r\n(query: SELECT * FROM crash_poc WHERE mapContains(crash.data, 'not_existent_123') LIMIT 1;)\r\n```\r\n\r\n\r\n**Additional context**\r\n\r\nData was generated with the following script:\r\n```python\r\nimport json\r\n\r\ndata = {\"id\": 1337, \"crash\": {\"data\": {}}}\r\nnumkeys = 255\r\nfor key in [f\"param_{i}\" for i in range(0, numkeys)]:\r\n    data[\"crash\"][\"data\"][key] = \"crashcrash\"\r\n\r\nnum_rows = 4000\r\nwith open(\"crash_data.jsonl\", \"w\") as f:\r\n    out = []\r\n    for i in range(num_rows):\r\n        out.append(json.dumps(data))\r\n    f.write(\"\\n\".join(out))\r\n```\r\n\r\nPossibly related to #63859 as it shares the same table schema.\nDB::Exception: Invalid type for SerializationLowCardinality index column \n**Describe what's wrong**\r\nLocally querying a Map(LowCardinality(String), String) inside a Tuple throws a `DB::Exception: Invalid type for SerializationLowCardinality index column` exception. (`INCORRECT_DATA`)\r\n\r\n**Does it reproduce on the most recent release?**\r\nReproducible in `24.5.1.1099`, `24.4.1.2088`, `23.8.14.6`\r\n- `24.5.1.1099`: https://fiddle.clickhouse.com/0634d11d-c185-42db-b0eb-47558dcf14ce\r\n- `24.4.1.2088`: https://fiddle.clickhouse.com/d503ebe3-cccf-46d2-8ff1-4626e941cb95\r\n- `23.8.14.6`: https://fiddle.clickhouse.com/4cb34d41-9e09-4c82-b13d-643bd6134481\r\n\r\n**How to reproduce**\r\n\r\n`clickhouse client --stacktrace --queries-file poc.sql`\r\n```sql\r\nCREATE OR REPLACE TABLE win_logs_poc\r\n(\r\n    event_id UInt32,\r\n    winlog Tuple\r\n    (\r\n        event_data Map(LowCardinality(String), String)\r\n    ) \r\n)\r\nENGINE = MergeTree\r\nORDER BY event_id;\r\n\r\nINSERT INTO win_logs_poc\r\nSELECT * FROM url('https://gist.githubusercontent.com/zu3st/6a559ac3b7a3b7a0c02cd86ddcccfbd2/raw/5396d06184a794c248eaa6140cb67ca990461b25/win_logs_poc.parquet');\r\n\r\n\r\nSELECT * FROM win_logs_poc WHERE mapContains(winlog.event_data, 'not_existent_123') LIMIT 1;\r\n```\r\n\r\nBoth changing `event_data` to `Map(String, String)` and moving `event_data` out of the `winlog Tuple` prevent the error from happening. The ingested URL contains 200K rows of random data and is publicly accessible.\r\n\r\n\r\n**Expected behavior**\r\nNo exception should occur.\r\n\r\n**Error message and/or stacktrace**\r\n\r\n```\r\nReceived exception from server (version 24.5.1):\r\nCode: 117. DB::Exception: Received from localhost:9000. DB::Exception: Invalid type for SerializationLowCardinality index column.: (while reading column winlog): (while reading from part ./store/176/1767a123-fe51-4ce8-9be3-c9ed49937b1a/all_1_1_0/ in table default.win_logs_poc (1767a123-fe51-4ce8-9be3-c9ed49937b1a) located on disk default of type local, from mark 0 with max_rows_to_read = 8192): While executing MergeTreeSelect(pool: ReadPool, algorithm: Thread). Stack trace:\r\n\r\n0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000c7eec3b\r\n1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000007751a6c\r\n2. DB::Exception::Exception<>(int, FormatStringHelperImpl<>) @ 0x000000000775f80b\r\n3. DB::SerializationLowCardinality::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::unordered_map<String, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::hash<String>, std::equal_to<String>, std::allocator<std::pair<String const, COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>>*) const @ 0x000000000fcd0e96\r\n4. DB::SerializationTuple::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::unordered_map<String, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::hash<String>, std::equal_to<String>, std::allocator<std::pair<String const, COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>>*) const @ 0x000000000fcfa9da\r\n5. DB::SerializationArray::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::unordered_map<String, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::hash<String>, std::equal_to<String>, std::allocator<std::pair<String const, COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>>*) const @ 0x000000000fcb1b48\r\n6. DB::SerializationTuple::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::unordered_map<String, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::hash<String>, std::equal_to<String>, std::allocator<std::pair<String const, COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>>*) const @ 0x000000000fcfa9da\r\n7. DB::MergeTreeReaderWide::readRows(unsigned long, unsigned long, bool, unsigned long, std::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>&) @ 0x00000000119fa629\r\n8. DB::MergeTreeRangeReader::DelayedStream::finalize(std::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>&) @ 0x00000000119e2c82\r\n9. DB::MergeTreeRangeReader::read(unsigned long, DB::MarkRanges&) @ 0x00000000119eb8ee\r\n10. DB::MergeTreeReadTask::read(DB::MergeTreeReadTask::BlockSizeParams const&) @ 0x0000000011a0ada8\r\n11. DB::MergeTreeThreadSelectAlgorithm::readFromTask(DB::MergeTreeReadTask&, DB::MergeTreeReadTask::BlockSizeParams const&) @ 0x00000000122afdaf\r\n12. DB::MergeTreeSelectProcessor::read() @ 0x0000000011a080ee\r\n13. DB::MergeTreeSource::tryGenerate() @ 0x00000000122e3e58\r\n14. DB::ISource::work() @ 0x0000000011e60142\r\n15. DB::ExecutionThreadContext::executeTask() @ 0x0000000011e79fc7\r\n16. DB::PipelineExecutor::executeStepImpl(unsigned long, std::atomic<bool>*) @ 0x0000000011e6e8b0\r\n17. void std::__function::__policy_invoker<void ()>::__call_impl<std::__function::__default_alloc_func<DB::PipelineExecutor::spawnThreads()::$_0, void ()>>(std::__function::__policy_storage const*) @ 0x0000000011e6ff2e\r\n18. ThreadPoolImpl<ThreadFromGlobalPoolImpl<false, true>>::worker(std::__list_iterator<ThreadFromGlobalPoolImpl<false, true>, void*>) @ 0x000000000c89ce39\r\n19. void std::__function::__policy_invoker<void ()>::__call_impl<std::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<false, true>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false, true>>::scheduleImpl<void>(std::function<void ()>, Priority, std::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'(), void ()>>(std::__function::__policy_storage const*) @ 0x000000000c8a0d51\r\n20. void* std::__thread_proxy[abi:v15000]<std::tuple<std::unique_ptr<std::__thread_struct, std::default_delete<std::__thread_struct>>, void ThreadPoolImpl<std::thread>::scheduleImpl<void>(std::function<void ()>, Priority, std::optional<unsigned long>, bool)::'lambda0'()>>(void*) @ 0x000000000c89fb3e\r\n21. ? @ 0x00007ff4597e2134\r\n22. ? @ 0x00007ff4598627dc\r\n. (INCORRECT_DATA)\r\n(query: SELECT * FROM win_logs_poc WHERE mapContains(winlog.event_data, 'not_existent_123') LIMIT 1;)\r\n```\r\n\r\n```\r\nReceived exception from server (version 24.4.1):\r\nCode: 117. DB::Exception: Received from localhost:9000. DB::Exception: Invalid type for SerializationLowCardinality index column.: (while reading column winlog): (while reading from part ./store/627/6272a39a-34b6-4873-a29a-7a6fa1eb0cd7/all_1_1_0/ in table default.win_logs_poc (6272a39a-34b6-4873-a29a-7a6fa1eb0cd7) located on disk default of type local, from mark 0 with max_rows_to_read = 8192): While executing MergeTreeSelect(pool: ReadPool, algorithm: Thread). Stack trace:\r\n\r\n0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000c9a449b\r\n1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000780b9ac\r\n2. DB::Exception::Exception<>(int, FormatStringHelperImpl<>) @ 0x0000000007819d8b\r\n3. DB::SerializationLowCardinality::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::unordered_map<String, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::hash<String>, std::equal_to<String>, std::allocator<std::pair<String const, COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>>*) const @ 0x000000000ff88056\r\n4. DB::SerializationTuple::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::unordered_map<String, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::hash<String>, std::equal_to<String>, std::allocator<std::pair<String const, COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>>*) const @ 0x000000000ffb323a\r\n5. DB::SerializationArray::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::unordered_map<String, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::hash<String>, std::equal_to<String>, std::allocator<std::pair<String const, COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>>*) const @ 0x000000000ff684e8\r\n6. DB::SerializationTuple::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::unordered_map<String, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::hash<String>, std::equal_to<String>, std::allocator<std::pair<String const, COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>>*) const @ 0x000000000ffb323a\r\n7. DB::MergeTreeReaderWide::readRows(unsigned long, unsigned long, bool, unsigned long, std::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>&) @ 0x0000000011dd55f4\r\n8. DB::MergeTreeRangeReader::DelayedStream::finalize(std::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>&) @ 0x0000000011dbc482\r\n9. DB::MergeTreeRangeReader::read(unsigned long, DB::MarkRanges&) @ 0x0000000011dc50e8\r\n10. DB::MergeTreeReadTask::read(DB::MergeTreeReadTask::BlockSizeParams const&) @ 0x0000000011de7976\r\n11. DB::MergeTreeThreadSelectAlgorithm::readFromTask(DB::MergeTreeReadTask&, DB::MergeTreeReadTask::BlockSizeParams const&) @ 0x0000000012787e8f\r\n12. DB::MergeTreeSelectProcessor::read() @ 0x0000000011de4b2b\r\n13. DB::MergeTreeSource::tryGenerate() @ 0x00000000127bd358\r\n14. DB::ISource::work() @ 0x000000001230a2a2\r\n15. DB::ExecutionThreadContext::executeTask() @ 0x00000000123257a8\r\n16. DB::PipelineExecutor::executeStepImpl(unsigned long, std::atomic<bool>*) @ 0x0000000012319a90\r\n17. void std::__function::__policy_invoker<void ()>::__call_impl<std::__function::__default_alloc_func<DB::PipelineExecutor::spawnThreads()::$_0, void ()>>(std::__function::__policy_storage const*) @ 0x000000001231b1b8\r\n18. ThreadPoolImpl<ThreadFromGlobalPoolImpl<false, true>>::worker(std::__list_iterator<ThreadFromGlobalPoolImpl<false, true>, void*>) @ 0x000000000ca5bab9\r\n19. void std::__function::__policy_invoker<void ()>::__call_impl<std::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<false, true>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false, true>>::scheduleImpl<void>(std::function<void ()>, Priority, std::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'(), void ()>>(std::__function::__policy_storage const*) @ 0x000000000ca5f82a\r\n20. void* std::__thread_proxy[abi:v15000]<std::tuple<std::unique_ptr<std::__thread_struct, std::default_delete<std::__thread_struct>>, void ThreadPoolImpl<std::thread>::scheduleImpl<void>(std::function<void ()>, Priority, std::optional<unsigned long>, bool)::'lambda0'()>>(void*) @ 0x000000000ca5e62d\r\n21. ? @ 0x00007f09d9082134\r\n22. ? @ 0x00007f09d91027dc\r\n. (INCORRECT_DATA)\r\n(query: SELECT * FROM win_logs_poc WHERE mapContains(winlog.event_data, 'not_existent_123') LIMIT 1;)\r\n```\r\n\n",
  "hints_text": "\n",
  "created_at": "2024-05-16T12:45:54Z"
}