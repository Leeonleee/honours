{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 1922,
  "instance_id": "ClickHouse__ClickHouse-1922",
  "issue_numbers": [
    "51"
  ],
  "base_commit": "d73080640d615e599d6a70ea944f1591a00159dc",
  "patch": "diff --git a/dbms/src/DataStreams/FilterBlockInputStream.cpp b/dbms/src/DataStreams/FilterBlockInputStream.cpp\nindex 5bfff19b7a78..d9f0c9142a77 100644\n--- a/dbms/src/DataStreams/FilterBlockInputStream.cpp\n+++ b/dbms/src/DataStreams/FilterBlockInputStream.cpp\n@@ -37,12 +37,8 @@ FilterBlockInputStream::FilterBlockInputStream(const BlockInputStreamPtr & input\n     /// Isn't the filter already constant?\n     ColumnPtr column = header.safeGetByPosition(filter_column).column;\n \n-    if (!have_constant_filter_description)\n-    {\n-        have_constant_filter_description = true;\n-        if (column)\n-            constant_filter_description = ConstantFilterDescription(*column);\n-    }\n+    if (column)\n+        constant_filter_description = ConstantFilterDescription(*column);\n \n     if (!constant_filter_description.always_false\n         && !constant_filter_description.always_true)\n@@ -79,12 +75,8 @@ Block FilterBlockInputStream::readImpl()\n {\n     Block res;\n \n-    if (!have_constant_filter_description)\n-    {\n-        getHeader();\n-        if (constant_filter_description.always_false)\n-            return res;\n-    }\n+    if (constant_filter_description.always_false)\n+        return res;\n \n     /// Until non-empty block after filtering or end of stream.\n     while (1)\ndiff --git a/dbms/src/DataStreams/FilterBlockInputStream.h b/dbms/src/DataStreams/FilterBlockInputStream.h\nindex 9cb27d6b1f08..c78e4c0919f5 100644\n--- a/dbms/src/DataStreams/FilterBlockInputStream.h\n+++ b/dbms/src/DataStreams/FilterBlockInputStream.h\n@@ -37,7 +37,6 @@ class FilterBlockInputStream : public IProfilingBlockInputStream\n     ssize_t filter_column;\n \n     ConstantFilterDescription constant_filter_description;\n-    bool have_constant_filter_description = false;\n };\n \n }\ndiff --git a/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.cpp b/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.cpp\nindex c29481671ddf..8476f3020af6 100644\n--- a/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.cpp\n+++ b/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.cpp\n@@ -197,6 +197,13 @@ void ParallelAggregatingBlockInputStream::execute()\n         << \"Total aggregated. \" << total_src_rows << \" rows (from \" << total_src_bytes / 1048576.0 << \" MiB)\"\n         << \" in \" << elapsed_seconds << \" sec.\"\n         << \" (\" << total_src_rows / elapsed_seconds << \" rows/sec., \" << total_src_bytes / elapsed_seconds / 1048576.0 << \" MiB/sec.)\");\n+\n+    /// If there was no data, and we aggregate without keys, we must return single row with the result of empty aggregation.\n+    /// To do this, we pass a block with zero rows to aggregate.\n+    if (total_src_rows == 0 && params.keys_size == 0 && !params.empty_result_for_aggregation_by_empty_set)\n+        aggregator.executeOnBlock(children.at(0)->getHeader(), *many_data[0],\n+            threads_data[0].key_columns, threads_data[0].aggregate_columns,\n+            threads_data[0].key, no_more_keys);\n }\n \n }\ndiff --git a/dbms/src/Interpreters/Aggregator.cpp b/dbms/src/Interpreters/Aggregator.cpp\nindex b2816c752027..df1fb72584cc 100644\n--- a/dbms/src/Interpreters/Aggregator.cpp\n+++ b/dbms/src/Interpreters/Aggregator.cpp\n@@ -648,7 +648,7 @@ void NO_INLINE Aggregator::executeWithoutKeyImpl(\n }\n \n \n-bool Aggregator::executeOnBlock(Block & block, AggregatedDataVariants & result,\n+bool Aggregator::executeOnBlock(const Block & block, AggregatedDataVariants & result,\n     ColumnRawPtrs & key_columns, AggregateColumns & aggregate_columns, StringRefs & key,\n     bool & no_more_keys)\n {\n@@ -1023,6 +1023,11 @@ void Aggregator::execute(const BlockInputStreamPtr & stream, AggregatedDataVaria\n             break;\n     }\n \n+    /// If there was no data, and we aggregate without keys, and we must return single row with the result of empty aggregation.\n+    /// To do this, we pass a block with zero rows to aggregate.\n+    if (result.empty() && params.keys_size == 0 && !params.empty_result_for_aggregation_by_empty_set)\n+        executeOnBlock(stream->getHeader(), result, key_columns, aggregate_columns, key, no_more_keys);\n+\n     double elapsed_seconds = watch.elapsedSeconds();\n     size_t rows = result.sizeWithoutOverflowRow();\n     LOG_TRACE(log, std::fixed << std::setprecision(3)\ndiff --git a/dbms/src/Interpreters/Aggregator.h b/dbms/src/Interpreters/Aggregator.h\nindex 08027fe6ae66..a498acf4c741 100644\n--- a/dbms/src/Interpreters/Aggregator.h\n+++ b/dbms/src/Interpreters/Aggregator.h\n@@ -1009,6 +1009,10 @@ class Aggregator\n \n         /// Settings to flush temporary data to the filesystem (external aggregation).\n         const size_t max_bytes_before_external_group_by;        /// 0 - do not use external aggregation.\n+\n+        /// Return empty result when aggregating without keys on empty set.\n+        bool empty_result_for_aggregation_by_empty_set;\n+\n         const std::string tmp_path;\n \n         Params(\n@@ -1017,20 +1021,24 @@ class Aggregator\n             bool overflow_row_, size_t max_rows_to_group_by_, OverflowMode group_by_overflow_mode_,\n             Compiler * compiler_, UInt32 min_count_to_compile_,\n             size_t group_by_two_level_threshold_, size_t group_by_two_level_threshold_bytes_,\n-            size_t max_bytes_before_external_group_by_, const std::string & tmp_path_)\n+            size_t max_bytes_before_external_group_by_,\n+            bool empty_result_for_aggregation_by_empty_set_,\n+            const std::string & tmp_path_)\n             : src_header(src_header_),\n             keys(keys_), aggregates(aggregates_), keys_size(keys.size()), aggregates_size(aggregates.size()),\n             overflow_row(overflow_row_), max_rows_to_group_by(max_rows_to_group_by_), group_by_overflow_mode(group_by_overflow_mode_),\n             compiler(compiler_), min_count_to_compile(min_count_to_compile_),\n             group_by_two_level_threshold(group_by_two_level_threshold_), group_by_two_level_threshold_bytes(group_by_two_level_threshold_bytes_),\n-            max_bytes_before_external_group_by(max_bytes_before_external_group_by_), tmp_path(tmp_path_)\n+            max_bytes_before_external_group_by(max_bytes_before_external_group_by_),\n+            empty_result_for_aggregation_by_empty_set(empty_result_for_aggregation_by_empty_set_),\n+            tmp_path(tmp_path_)\n         {\n         }\n \n         /// Only parameters that matter during merge.\n         Params(const Block & intermediate_header_,\n             const ColumnNumbers & keys_, const AggregateDescriptions & aggregates_, bool overflow_row_)\n-            : Params(Block(), keys_, aggregates_, overflow_row_, 0, OverflowMode::THROW, nullptr, 0, 0, 0, 0, \"\")\n+            : Params(Block(), keys_, aggregates_, overflow_row_, 0, OverflowMode::THROW, nullptr, 0, 0, 0, 0, false, \"\")\n         {\n             intermediate_header = intermediate_header_;\n         }\n@@ -1050,7 +1058,7 @@ class Aggregator\n     using AggregateFunctionsPlainPtrs = std::vector<IAggregateFunction *>;\n \n     /// Process one block. Return false if the processing should be aborted (with group_by_overflow_mode = 'break').\n-    bool executeOnBlock(Block & block, AggregatedDataVariants & result,\n+    bool executeOnBlock(const Block & block, AggregatedDataVariants & result,\n         ColumnRawPtrs & key_columns, AggregateColumns & aggregate_columns,    /// Passed to not create them anew for each block\n         StringRefs & keys,                                        /// - pass the corresponding objects that are initially empty.\n         bool & no_more_keys);\ndiff --git a/dbms/src/Interpreters/InterpreterSelectQuery.cpp b/dbms/src/Interpreters/InterpreterSelectQuery.cpp\nindex b0579452e6fc..be916e0b7b06 100644\n--- a/dbms/src/Interpreters/InterpreterSelectQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterSelectQuery.cpp\n@@ -21,7 +21,6 @@\n #include <DataStreams/CreatingSetsBlockInputStream.h>\n #include <DataStreams/MaterializingBlockInputStream.h>\n #include <DataStreams/ConcatBlockInputStream.h>\n-#include <DataStreams/OneBlockInputStream.h>\n \n #include <Parsers/ASTSelectQuery.h>\n #include <Parsers/ASTIdentifier.h>\n@@ -462,7 +461,7 @@ void InterpreterSelectQuery::executeSingleQuery()\n \n     union_within_single_query = false;\n \n-    /** Take out the data from Storage. from_stage - to what stage the request was completed in Storage. */\n+    /** Read the data from Storage. from_stage - to what stage the request was completed in Storage. */\n     QueryProcessingStage::Enum from_stage = executeFetchColumns();\n \n     LOG_TRACE(log, QueryProcessingStage::toString(from_stage) << \" -> \" << QueryProcessingStage::toString(to_stage));\n@@ -864,18 +863,8 @@ QueryProcessingStage::Enum InterpreterSelectQuery::executeFetchColumns()\n         if (streams.empty())\n             streams = storage->read(required_columns, query_info, context, from_stage, max_block_size, max_streams);\n \n-        /// The storage has no data for this query.\n         if (streams.empty())\n-        {\n-            from_stage = QueryProcessingStage::FetchColumns;\n-            Block header;\n-            for (const auto & name : required_columns)\n-            {\n-                auto type = storage->getDataTypeByName(name);\n-                header.insert({ type->createColumn(), type, name });\n-            }\n-            streams.emplace_back(std::make_shared<OneBlockInputStream>(header));\n-        }\n+            streams.emplace_back(std::make_shared<NullBlockInputStream>(storage->getSampleBlockForColumns(required_columns)));\n \n         if (alias_actions)\n         {\n@@ -971,7 +960,8 @@ void InterpreterSelectQuery::executeAggregation(const ExpressionActionsPtr & exp\n         settings.compile ? &context.getCompiler() : nullptr, settings.min_count_to_compile,\n         allow_to_use_two_level_group_by ? settings.group_by_two_level_threshold : SettingUInt64(0),\n         allow_to_use_two_level_group_by ? settings.group_by_two_level_threshold_bytes : SettingUInt64(0),\n-        settings.limits.max_bytes_before_external_group_by, context.getTemporaryPath());\n+        settings.limits.max_bytes_before_external_group_by, settings.empty_result_for_aggregation_by_empty_set,\n+        context.getTemporaryPath());\n \n     /// If there are several sources, then we perform parallel aggregation\n     if (streams.size() > 1)\ndiff --git a/dbms/src/Interpreters/Settings.h b/dbms/src/Interpreters/Settings.h\nindex 5244ebb5c9b2..4946be8acb67 100644\n--- a/dbms/src/Interpreters/Settings.h\n+++ b/dbms/src/Interpreters/Settings.h\n@@ -180,7 +180,9 @@ struct Settings\n     M(SettingSeconds, http_send_timeout, DEFAULT_HTTP_READ_BUFFER_TIMEOUT, \"HTTP send timeout\") \\\n     M(SettingSeconds, http_receive_timeout, DEFAULT_HTTP_READ_BUFFER_TIMEOUT, \"HTTP receive timeout\") \\\n     M(SettingBool, optimize_throw_if_noop, false, \"If setting is enabled and OPTIMIZE query didn't actually assign a merge then an explanatory exception is thrown\") \\\n-    M(SettingBool, use_index_for_in_with_subqueries, true, \"Try using an index if there is a subquery or a table expression on the right side of the IN operator.\")\n+    M(SettingBool, use_index_for_in_with_subqueries, true, \"Try using an index if there is a subquery or a table expression on the right side of the IN operator.\") \\\n+    \\\n+    M(SettingBool, empty_result_for_aggregation_by_empty_set, false, \"Return empty result when aggregating without keys on empty set.\")\n \n \n     /// Possible limits for query execution.\n",
  "test_patch": "diff --git a/dbms/src/Interpreters/tests/aggregate.cpp b/dbms/src/Interpreters/tests/aggregate.cpp\nindex 046dbf58d9e7..65db982dbd10 100644\n--- a/dbms/src/Interpreters/tests/aggregate.cpp\n+++ b/dbms/src/Interpreters/tests/aggregate.cpp\n@@ -79,7 +79,7 @@ int main(int argc, char ** argv)\n \n         Aggregator::Params params(\n             stream->getHeader(), {0, 1}, aggregate_descriptions,\n-            false, 0, OverflowMode::THROW, nullptr, 0, 0, 0, 0, \"\");\n+            false, 0, OverflowMode::THROW, nullptr, 0, 0, 0, 0, false, \"\");\n \n         Aggregator aggregator(params);\n \ndiff --git a/dbms/tests/queries/0_stateless/00017_in_subquery_with_empty_result.reference b/dbms/tests/queries/0_stateless/00017_in_subquery_with_empty_result.reference\nindex e25c5780b65e..d4d0e64e94c4 100644\n--- a/dbms/tests/queries/0_stateless/00017_in_subquery_with_empty_result.reference\n+++ b/dbms/tests/queries/0_stateless/00017_in_subquery_with_empty_result.reference\n@@ -9,10 +9,12 @@\n \n \t\"data\":\n \t[\n-\n+\t\t{\n+\t\t\t\"count()\": \"0\"\n+\t\t}\n \t],\n \n-\t\"rows\": 0,\n+\t\"rows\": 1,\n \n \t\"rows_before_limit_at_least\": 1000\n }\ndiff --git a/dbms/tests/queries/0_stateless/00181_aggregate_functions_statistics.reference b/dbms/tests/queries/0_stateless/00181_aggregate_functions_statistics.reference\nindex 80cedd761917..4338ddbb0436 100644\n--- a/dbms/tests/queries/0_stateless/00181_aggregate_functions_statistics.reference\n+++ b/dbms/tests/queries/0_stateless/00181_aggregate_functions_statistics.reference\n@@ -1,14 +1,21 @@\n nan\n+nan\n 0\n nan\n+nan\n 0\n+nan\n 0\n 0\n+nan\n 0\n 0\n nan\n+nan\n 0\n+nan\n 0\n 0\n nan\n+nan\n 0\ndiff --git a/dbms/tests/queries/0_stateless/00181_aggregate_functions_statistics_stable.reference b/dbms/tests/queries/0_stateless/00181_aggregate_functions_statistics_stable.reference\nindex ce706690f1ad..9e875346c026 100644\n--- a/dbms/tests/queries/0_stateless/00181_aggregate_functions_statistics_stable.reference\n+++ b/dbms/tests/queries/0_stateless/00181_aggregate_functions_statistics_stable.reference\n@@ -1,14 +1,21 @@\n inf\n+inf\n 0\n inf\n+inf\n 0\n+inf\n 0\n 0\n+inf\n 0\n 0\n inf\n+inf\n 0\n+inf\n 0\n 0\n inf\n+inf\n 0\ndiff --git a/dbms/tests/queries/0_stateless/00321_pk_set.reference b/dbms/tests/queries/0_stateless/00321_pk_set.reference\nindex d00491fd7e5b..2b0a5dc3946c 100644\n--- a/dbms/tests/queries/0_stateless/00321_pk_set.reference\n+++ b/dbms/tests/queries/0_stateless/00321_pk_set.reference\n@@ -1,1 +1,7 @@\n+0\n+0\n+0\n+0\n+0\n+0\n 1\ndiff --git a/dbms/tests/queries/0_stateless/00572_aggregation_by_empty_set.reference b/dbms/tests/queries/0_stateless/00572_aggregation_by_empty_set.reference\nnew file mode 100644\nindex 000000000000..5c89ff2983aa\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00572_aggregation_by_empty_set.reference\n@@ -0,0 +1,6 @@\n+0\n+0\n+1\n+0\t0\tnan\t\\N\t[]\t[]\n+0\t0\tnan\t\\N\t[]\t[]\n+1\ndiff --git a/dbms/tests/queries/0_stateless/00572_aggregation_by_empty_set.sql b/dbms/tests/queries/0_stateless/00572_aggregation_by_empty_set.sql\nnew file mode 100644\nindex 000000000000..8058605a7155\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00572_aggregation_by_empty_set.sql\n@@ -0,0 +1,21 @@\n+CREATE TEMPORARY TABLE t (x UInt8);\n+\n+SET empty_result_for_aggregation_by_empty_set = 0;\n+\n+SELECT count() FROM system.one WHERE 0;\n+SELECT count() FROM system.one WHERE rand() < 0;\n+SELECT count() FROM system.one WHERE 1;\n+\n+SELECT count(), uniq(x), avg(x), avg(toNullable(x)), groupArray(x), groupUniqArray(x) FROM t;\n+SELECT count(), uniq(x), avg(x), avg(toNullable(x)), groupArray(x), groupUniqArray(x) FROM (SELECT * FROM t UNION ALL SELECT * FROM t);\n+SELECT x, count(), uniq(x), avg(x), avg(toNullable(x)), groupArray(x), groupUniqArray(x) FROM t GROUP BY x;\n+\n+SET empty_result_for_aggregation_by_empty_set = 1;\n+\n+SELECT count() FROM system.one WHERE 0;\n+SELECT count() FROM system.one WHERE rand() < 0;\n+SELECT count() FROM system.one WHERE 1;\n+\n+SELECT count(), uniq(x), avg(x), avg(toNullable(x)), groupArray(x), groupUniqArray(x) FROM t;\n+SELECT count(), uniq(x), avg(x), avg(toNullable(x)), groupArray(x), groupUniqArray(x) FROM (SELECT * FROM t UNION ALL SELECT * FROM t);\n+SELECT x, count(), uniq(x), avg(x), avg(toNullable(x)), groupArray(x), groupUniqArray(x) FROM t GROUP BY x;\ndiff --git a/dbms/tests/queries/0_stateless/00573_shard_aggregation_by_empty_set.reference b/dbms/tests/queries/0_stateless/00573_shard_aggregation_by_empty_set.reference\nnew file mode 100644\nindex 000000000000..dadb1e081703\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00573_shard_aggregation_by_empty_set.reference\n@@ -0,0 +1,1 @@\n+0\t0\tnan\t\\N\t[]\t[]\ndiff --git a/dbms/tests/queries/0_stateless/00573_shard_aggregation_by_empty_set.sql b/dbms/tests/queries/0_stateless/00573_shard_aggregation_by_empty_set.sql\nnew file mode 100644\nindex 000000000000..8270b1eef441\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00573_shard_aggregation_by_empty_set.sql\n@@ -0,0 +1,9 @@\n+CREATE TEMPORARY TABLE t (x UInt8);\n+\n+SET empty_result_for_aggregation_by_empty_set = 0;\n+SELECT count(), uniq(x), avg(x), avg(toNullable(x)), groupArray(x), groupUniqArray(x) FROM remote('127.0.0.{1..10}', system.one) WHERE (rand() AS x) < 0;\n+SELECT count(), uniq(x), avg(x), avg(toNullable(x)), groupArray(x), groupUniqArray(x) FROM remote('127.0.0.{1..10}', system.one) WHERE (rand() AS x) < 0 GROUP BY x;\n+\n+SET empty_result_for_aggregation_by_empty_set = 1;\n+SELECT count(), uniq(x), avg(x), avg(toNullable(x)), groupArray(x), groupUniqArray(x) FROM remote('127.0.0.{1..10}', system.one) WHERE (rand() AS x) < 0;\n+SELECT count(), uniq(x), avg(x), avg(toNullable(x)), groupArray(x), groupUniqArray(x) FROM remote('127.0.0.{1..10}', system.one) WHERE (rand() AS x) < 0 GROUP BY x;\n",
  "problem_statement": "Option for returning result instead of empty\nNeed to add option(setting) to return result from one of the rows containing the initial values of aggregate functions instead of returning no result (as we discussed it here: https://groups.google.com/forum/#!topic/clickhouse/2JS_yzvYAHM)\nThis described in documentation: \n\"However, in contrast to standard SQL, if the table doesn't have any rows (either there aren't any at all, or there aren't any after using WHERE to filter), an empty result is returned, and not the result from one of the rows containing the initial values of aggregate functions.\"\n\nIt will be very useful.\nThanks!\n\n",
  "hints_text": "For now working with aggregate functions in sub-queries is uncomfortable(I would even say impossible). \nBecause for \"count\" we can do union with one, OK. But for example for \"avg\" union will be much more complicate and we can't  easy do sub-queries with aggregate functions. \n@alexey-milovidov Can you, please, tell when the option for this can be added?\n\nI hope, it is about few weeks.\n\nHello @rasmus93,\r\nThe following workaround will also work for AVG, SUM and other aggregate functions.\r\n\r\n```\r\nSELECT *\r\nFROM \r\n(\r\n    SELECT count(*) AS count\r\n    FROM mytable\r\n    UNION ALL \r\n    SELECT toUInt64 (0)\r\n) \r\nLIMIT 1\r\n```\nMay I know if this option is implemented?",
  "created_at": "2018-02-18T06:07:48Z",
  "modified_files": [
    "dbms/src/DataStreams/FilterBlockInputStream.cpp",
    "dbms/src/DataStreams/FilterBlockInputStream.h",
    "dbms/src/DataStreams/ParallelAggregatingBlockInputStream.cpp",
    "dbms/src/Interpreters/Aggregator.cpp",
    "dbms/src/Interpreters/Aggregator.h",
    "dbms/src/Interpreters/InterpreterSelectQuery.cpp",
    "dbms/src/Interpreters/Settings.h"
  ],
  "modified_test_files": [
    "dbms/src/Interpreters/tests/aggregate.cpp",
    "dbms/tests/queries/0_stateless/00017_in_subquery_with_empty_result.reference",
    "dbms/tests/queries/0_stateless/00181_aggregate_functions_statistics.reference",
    "dbms/tests/queries/0_stateless/00181_aggregate_functions_statistics_stable.reference",
    "dbms/tests/queries/0_stateless/00321_pk_set.reference",
    "b/dbms/tests/queries/0_stateless/00572_aggregation_by_empty_set.reference",
    "b/dbms/tests/queries/0_stateless/00572_aggregation_by_empty_set.sql",
    "b/dbms/tests/queries/0_stateless/00573_shard_aggregation_by_empty_set.reference",
    "b/dbms/tests/queries/0_stateless/00573_shard_aggregation_by_empty_set.sql"
  ]
}