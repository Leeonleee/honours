{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 12085,
  "instance_id": "ClickHouse__ClickHouse-12085",
  "issue_numbers": [
    "11937"
  ],
  "base_commit": "4d01fb3cbce2971f19a66ac97e85092523487125",
  "patch": "diff --git a/src/Processors/QueryPipeline.h b/src/Processors/QueryPipeline.h\nindex 7dddb2526e54..adab155d2014 100644\n--- a/src/Processors/QueryPipeline.h\n+++ b/src/Processors/QueryPipeline.h\n@@ -167,6 +167,13 @@ class QueryPipeline\n     /// Set upper limit for the recommend number of threads\n     void setMaxThreads(size_t max_threads_) { max_threads = max_threads_; }\n \n+    /// Update upper limit for the recommend number of threads\n+    void limitMaxThreads(size_t max_threads_)\n+    {\n+        if (max_threads == 0 || max_threads_ < max_threads)\n+            max_threads = max_threads_;\n+    }\n+\n     /// Convert query pipeline to single or several pipes.\n     Pipe getPipe() &&;\n     Pipes getPipes() &&;\ndiff --git a/src/Processors/QueryPlan/QueryPlan.cpp b/src/Processors/QueryPlan/QueryPlan.cpp\nindex 25983c25c7e2..cd8c442a3db7 100644\n--- a/src/Processors/QueryPlan/QueryPlan.cpp\n+++ b/src/Processors/QueryPlan/QueryPlan.cpp\n@@ -153,8 +153,8 @@ QueryPipelinePtr QueryPlan::buildQueryPipeline()\n             bool limit_max_threads = frame.pipelines.empty();\n             last_pipeline = frame.node->step->updatePipeline(std::move(frame.pipelines));\n \n-            if (limit_max_threads)\n-                last_pipeline->setMaxThreads(max_threads);\n+            if (limit_max_threads && max_threads)\n+                last_pipeline->limitMaxThreads(max_threads);\n \n             stack.pop();\n         }\ndiff --git a/src/Processors/QueryPlan/ReadFromStorageStep.cpp b/src/Processors/QueryPlan/ReadFromStorageStep.cpp\nindex e0781c24f7f5..7e8d44abed87 100644\n--- a/src/Processors/QueryPlan/ReadFromStorageStep.cpp\n+++ b/src/Processors/QueryPlan/ReadFromStorageStep.cpp\n@@ -113,7 +113,7 @@ ReadFromStorageStep::ReadFromStorageStep(\n         }\n     }\n \n-    if (pipes.size() == 1)\n+    if (pipes.size() == 1 && !storage->isView())\n         pipeline->setMaxThreads(1);\n \n     for (auto & pipe : pipes)\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01356_view_threads.reference b/tests/queries/0_stateless/01356_view_threads.reference\nnew file mode 100644\nindex 000000000000..4e9079198d52\n--- /dev/null\n+++ b/tests/queries/0_stateless/01356_view_threads.reference\n@@ -0,0 +1,3 @@\n+0\t249999500000\n+1\t250000000000\n+1\ndiff --git a/tests/queries/0_stateless/01356_view_threads.sql b/tests/queries/0_stateless/01356_view_threads.sql\nnew file mode 100644\nindex 000000000000..5290ec555aff\n--- /dev/null\n+++ b/tests/queries/0_stateless/01356_view_threads.sql\n@@ -0,0 +1,12 @@\n+drop table if exists table_01356_view_threads;\n+\n+create view table_01356_view_threads as select number % 10 as g, sum(number) as s from numbers_mt(1000000) group by g;\n+\n+set log_queries = 1;\n+set max_threads = 16;\n+select g % 2 as gg, sum(s) from table_01356_view_threads group by gg order by gg;\n+\n+system flush logs;\n+select length(thread_ids) >= 16 from system.query_log where event_date >= today() - 1 and lower(query) like '%select g % 2 as gg, sum(s) from table_01356_view_threads group by gg order by gg%' and type = 'QueryFinish' order by query_start_time desc limit 1;\n+\n+drop table if exists table_01356_view_threads;\n",
  "problem_statement": "View of MV slower than querying directly?\n```sql\r\n\r\nCREATE MATERIALIZED VIEW player_champ_counts_mv\r\nENGINE = AggregatingMergeTree() ORDER BY (patch_num, my_account_id, champ_id)\r\nas select patch_num, my_account_id, champ_id, countState() as c_state\r\nfrom full_info\r\ngroup by patch_num, my_account_id, champ_id;\r\n\r\ncreate view player_champ_counts as\r\nselect patch_num, my_account_id, champ_id, countMerge(c_state) as c\r\nfrom player_champ_counts_mv\r\ngroup by patch_num, my_account_id, champ_id;\r\n```\r\n\r\n2.4s:\r\n`select * from player_champ_counts`\r\n\r\n900ms:\r\n```\r\nselect patch_num, my_account_id, champ_id, countMerge(c_state) as c\r\nfrom player_champ_counts_mv\r\ngroup by patch_num, my_account_id, champ_id;\r\n```\r\n\r\nIn other words, just inlining the definition of the view is doing something different than querying the view itself.\n",
  "hints_text": "It needs clarification and reproduction.\r\n\r\n1. CH version.\r\n2. show create table full_info\r\n3. data sample for full_info\r\n4. select name,value from system.settings where changed;\n@den-crane \r\n\r\n`ClickHouse server version 20.4.5.36 (official build).`\r\n\r\n```sql\r\nCREATE TABLE full_info (\r\n\t`my_game_id` UInt64,\r\n\t`game_id` UInt64,\r\n\t`region` String,\r\n\t`game_tier` UInt8,\r\n\t`patch_full` String,\r\n\t`patch_num` UInt16,\r\n\t`game_start_time` DateTime64(3),\r\n\t`my_account_id` UInt64,\r\n\t`champ_id` UInt8,\r\n\t`canonical_role` UInt8,\r\n\t`won` UInt8,\r\n\t`highest_rank_in_game` UInt8\r\n)\r\nENGINE = MergeTree()\r\nORDER BY tuple()\r\n```\r\n\r\n`SELECT * FROM full_info LIMIT 20;`\r\n```\r\nmy_game_id|game_id   |region|game_tier|patch_full    |patch_num|game_start_time        |my_account_id|champ_id|canonical_role|won|highest_rank_in_game|\r\n----------|----------|------|---------|--------------|---------|-----------------------|-------------|--------|--------------|---|--------------------|\r\n       114|1978239875|BR1   |       60|10.12.325.3360|     1012|2014-08-06   :09:29.000|       703916|      82|             1|  0|                   0|\r\n       114|1978239875|BR1   |       60|10.12.325.3360|     1012|2014-08-06   :09:29.000|       663109|     238|             3|  0|                   0|\r\n       114|1978239875|BR1   |       60|10.12.325.3360|     1012|2014-08-06   :09:29.000|       617173|     145|             4|  0|                   0|\r\n       114|1978239875|BR1   |       60|10.12.325.3360|     1012|2014-08-06   :09:29.000|       702115|     107|             5|  0|                   1|\r\n       114|1978239875|BR1   |       60|10.12.325.3360|     1012|2014-08-06   :09:29.000|       918117|      60|             2|  0|                   0|\r\n       114|1978239875|BR1   |       60|10.12.325.3360|     1012|2014-08-06   :09:29.000|       765669|      58|             1|  1|                   1|\r\n       114|1978239875|BR1   |       60|10.12.325.3360|     1012|2014-08-06   :09:29.000|       672571|     236|             3|  1|                   1|\r\n       114|1978239875|BR1   |       60|10.12.325.3360|     1012|2014-08-06   :09:29.000|       595553|     173|             4|  1|                   0|\r\n       114|1978239875|BR1   |       60|10.12.325.3360|     1012|2014-08-06   :09:29.000|       919079|     241|             5|  1|                   1|\r\n       114|1978239875|BR1   |       60|10.12.325.3360|     1012|2014-08-06   :09:29.000|      1136555|      20|             2|  1|                   0|\r\n       290| 235855467|JP1   |       50|10.12.325.3360|     1012|2014-06-06 p\ufffd:51:12.000|       355828|     145|             4|  1|                   0|\r\n       290| 235855467|JP1   |       50|10.12.325.3360|     1012|2014-06-06 p\ufffd:51:12.000|      1579000|       8|             1|  1|                   0|\r\n       290| 235855467|JP1   |       50|10.12.325.3360|     1012|2014-06-06 p\ufffd:51:12.000|      1563001|      81|             3|  1|                   0|\r\n       290| 235855467|JP1   |       50|10.12.325.3360|     1012|2014-06-06 p\ufffd:51:12.000|       563780|      48|             2|  1|                   0|\r\n       290| 235855467|JP1   |       50|10.12.325.3360|     1012|2014-06-06 p\ufffd:51:12.000|        38667|      26|             5|  1|                   1|\r\n       290| 235855467|JP1   |       50|10.12.325.3360|     1012|2014-06-06 p\ufffd:51:12.000|       252279|     122|             1|  0|                   0|\r\n       290| 235855467|JP1   |       50|10.12.325.3360|     1012|2014-06-06 p\ufffd:51:12.000|       356250|      90|             3|  0|                   0|\r\n       290| 235855467|JP1   |       50|10.12.325.3360|     1012|2014-06-06 p\ufffd:51:12.000|       102144|     111|             5|  0|                   0|\r\n       290| 235855467|JP1   |       50|10.12.325.3360|     1012|2014-06-06 p\ufffd:51:12.000|       102231|      11|             4|  0|                   0|\r\n       290| 235855467|JP1   |       50|10.12.325.3360|     1012|2014-06-06 p\ufffd:51:12.000|       395535|     121|             2|  0|                   0|\r\n```\r\n\r\n```\r\nname                  |value      |\r\n----------------------|-----------|\r\nextremes              |0          |\r\nuse_uncompressed_cache|0          |\r\nload_balancing        |random     |\r\nmax_result_rows       |200        |\r\nresult_overflow_mode  |break      |\r\nmax_memory_usage      |10000000000|\r\n```\r\n\nWA: set experimental_use_processors=0\r\n\r\n\r\n20.3.12.112, 20.4.5.36, 20.4.6.53 affected. \r\n20.6.1.3853 is not affected.\r\n\r\nrepro:\r\n\r\n\r\n```\r\n\r\nCREATE TABLE player_champ_counts\r\n(   patch_num UInt64,\r\n    c_state AggregateFunction(count))\r\nENGINE = AggregatingMergeTree()\r\nORDER BY (patch_num);\r\n\r\ninsert into player_champ_counts\r\nselect number, countState() from numbers(10000000) group by number;\r\n\r\ncreate view player_champ_counts_v as\r\nselect patch_num, countMerge(c_state) as c\r\nfrom player_champ_counts\r\ngroup by patch_num;\r\n\r\nselect patch_num, countMerge(c_state) as c from player_champ_counts group by patch_num format Null;\r\n0 rows in set. Elapsed: 0.447 sec. Processed 10.00 million rows, 303.59 MB (22.36 million rows/s., 678.71 MB/s.)\r\n\r\nset experimental_use_processors=1\r\nselect * from player_champ_counts_v format Null;\r\n0 rows in set. Elapsed: 1.399 sec. Processed 10.00 million rows, 303.59 MB (7.15 million rows/s., 216.98 MB/s.)\r\n0 rows in set. Elapsed: 1.400 sec. Processed 10.00 million rows, 303.59 MB (7.14 million rows/s., 216.84 MB/s.)\r\n\r\nset experimental_use_processors=0\r\nselect * from player_champ_counts_v format Null;\r\n0 rows in set. Elapsed: 0.430 sec. Processed 10.00 million rows, 303.59 MB (23.23 million rows/s., 705.32 MB/s.)\r\n0 rows in set. Elapsed: 0.396 sec. Processed 10.00 million rows, 303.59 MB (25.26 million rows/s., 766.84 MB/s.)\r\n```\nThanks for the quick follow-up.\r\n\r\nI can confirm the issue is fixed with `20.6.1.3853`",
  "created_at": "2020-07-02T13:07:36Z"
}