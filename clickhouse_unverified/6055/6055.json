{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 6055,
  "instance_id": "ClickHouse__ClickHouse-6055",
  "issue_numbers": [
    "5990"
  ],
  "base_commit": "aef0e2c0a387e26645fca340e6ec7fc332562149",
  "patch": "diff --git a/dbms/src/Core/Settings.h b/dbms/src/Core/Settings.h\nindex 27e06ffec10e..b789f4c7286f 100644\n--- a/dbms/src/Core/Settings.h\n+++ b/dbms/src/Core/Settings.h\n@@ -171,6 +171,7 @@ struct Settings : public SettingsCollection<Settings>\n     M(SettingBool, input_format_with_names_use_header, false, \"For TSVWithNames and CSVWithNames input formats this controls whether format parser is to assume that column data appear in the input exactly as they are specified in the header.\") \\\n     M(SettingBool, input_format_import_nested_json, false, \"Map nested JSON data to nested tables (it works for JSONEachRow format).\") \\\n     M(SettingBool, input_format_defaults_for_omitted_fields, true, \"For input data calculate default expressions for omitted fields (it works for JSONEachRow format).\") \\\n+    M(SettingBool, input_format_null_as_default, false, \"For CSV format initialize null fields with default values if data type of this field is not nullable\") \\\n     \\\n     M(SettingBool, input_format_values_interpret_expressions, true, \"For Values format: if field could not be parsed by streaming parser, run SQL parser and try to interpret it as SQL expression.\") \\\n     \\\n@@ -300,6 +301,7 @@ struct Settings : public SettingsCollection<Settings>\n     M(SettingChar, format_csv_delimiter, ',', \"The character to be considered as a delimiter in CSV data. If setting with a string, a string has to have a length of 1.\") \\\n     M(SettingBool, format_csv_allow_single_quotes, 1, \"If it is set to true, allow strings in single quotes.\") \\\n     M(SettingBool, format_csv_allow_double_quotes, 1, \"If it is set to true, allow strings in double quotes.\") \\\n+    M(SettingBool, input_format_csv_unquoted_null_literal_as_null, false, \"Consider unquoted NULL literal as \\N\") \\\n     \\\n     M(SettingDateTimeInputFormat, date_time_input_format, FormatSettings::DateTimeInputFormat::Basic, \"Method to read DateTime from text input formats. Possible values: 'basic' and 'best_effort'.\") \\\n     M(SettingBool, log_profile_events, true, \"Log query performance statistics into the query_log and query_thread_log.\") \\\ndiff --git a/dbms/src/DataTypes/DataTypeNullable.cpp b/dbms/src/DataTypes/DataTypeNullable.cpp\nindex c56d8616be23..44df56b3d3ac 100644\n--- a/dbms/src/DataTypes/DataTypeNullable.cpp\n+++ b/dbms/src/DataTypes/DataTypeNullable.cpp\n@@ -272,9 +272,72 @@ void DataTypeNullable::serializeTextCSV(const IColumn & column, size_t row_num,\n \n void DataTypeNullable::deserializeTextCSV(IColumn & column, ReadBuffer & istr, const FormatSettings & settings) const\n {\n-    safeDeserialize(column,\n-        [&istr] { return checkStringByFirstCharacterAndAssertTheRest(\"\\\\N\", istr); },\n-        [this, &settings, &istr] (IColumn & nested) { nested_data_type->deserializeAsTextCSV(nested, istr, settings); });\n+    constexpr char const * null_literal = \"NULL\";\n+    constexpr size_t len = 4;\n+    size_t null_prefix_len = 0;\n+\n+    auto check_for_null = [&istr, &settings, &null_prefix_len]\n+    {\n+        if (checkStringByFirstCharacterAndAssertTheRest(\"\\\\N\", istr))\n+            return true;\n+        if (!settings.csv.unquoted_null_literal_as_null)\n+            return false;\n+\n+        /// Check for unquoted NULL\n+        while (!istr.eof() && null_prefix_len < len && null_literal[null_prefix_len] == *istr.position())\n+        {\n+            ++null_prefix_len;\n+            ++istr.position();\n+        }\n+        if (null_prefix_len == len)\n+            return true;\n+\n+        /// Value and \"NULL\" have common prefix, but value is not \"NULL\".\n+        /// Restore previous buffer position if possible.\n+        if (null_prefix_len <= istr.offset())\n+        {\n+            istr.position() -= null_prefix_len;\n+            null_prefix_len = 0;\n+        }\n+        return false;\n+    };\n+\n+    auto deserialize_nested = [this, &settings, &istr, &null_prefix_len] (IColumn & nested)\n+    {\n+        if (likely(!null_prefix_len))\n+            nested_data_type->deserializeAsTextCSV(nested, istr, settings);\n+        else\n+        {\n+            /// Previous buffer position was not restored,\n+            /// so we need to prepend extracted characters (rare case)\n+            ReadBufferFromMemory prepend(null_literal, null_prefix_len);\n+            ConcatReadBuffer buf(prepend, istr);\n+            nested_data_type->deserializeAsTextCSV(nested, buf, settings);\n+\n+            /// Check if all extracted characters were read by nested parser and update buffer position\n+            if (null_prefix_len < buf.count())\n+                istr.position() = buf.position();\n+            else if (null_prefix_len > buf.count())\n+            {\n+                /// It can happen only if there is an unquoted string instead of a number\n+                /// or if someone uses 'U' or 'L' as delimiter in CSV.\n+                /// In the first case we cannot continue reading anyway. The second case seems to be unlikely.\n+                if (settings.csv.delimiter == 'U' || settings.csv.delimiter == 'L')\n+                    throw DB::Exception(\"Enabled setting input_format_csv_unquoted_null_literal_as_null may not work correctly \"\n+                                        \"with format_csv_delimiter = 'U' or 'L' for large input.\", ErrorCodes::CANNOT_READ_ALL_DATA);\n+                WriteBufferFromOwnString parsed_value;\n+                nested_data_type->serializeAsTextCSV(nested, nested.size() - 1, parsed_value, settings);\n+                throw DB::Exception(\"Error while parsing \\\"\" + std::string(null_literal, null_prefix_len)\n+                                    + std::string(istr.position(), std::min(size_t{10}, istr.available())) + \"\\\" as \" + getName()\n+                                    + \" at position \" + std::to_string(istr.count()) + \": expected \\\"NULL\\\" or \" + nested_data_type->getName()\n+                                    + \", got \\\"\" + std::string(null_literal, buf.count()) + \"\\\", which was deserialized as \\\"\"\n+                                    + parsed_value.str() + \"\\\". It seems that input data is ill-formatted.\",\n+                                    ErrorCodes::CANNOT_READ_ALL_DATA);\n+            }\n+        }\n+    };\n+\n+    safeDeserialize(column, check_for_null, deserialize_nested);\n }\n \n void DataTypeNullable::serializeText(const IColumn & column, size_t row_num, WriteBuffer & ostr, const FormatSettings & settings) const\ndiff --git a/dbms/src/DataTypes/DataTypeNullable.h b/dbms/src/DataTypes/DataTypeNullable.h\nindex 2b098ea0476d..5bacdb39ff4a 100644\n--- a/dbms/src/DataTypes/DataTypeNullable.h\n+++ b/dbms/src/DataTypes/DataTypeNullable.h\n@@ -61,7 +61,8 @@ class DataTypeNullable final : public IDataType\n       * 1. \\N\n       * 2. empty string (without quotes)\n       * 3. NULL\n-      * Now we support only first.\n+      * We support all of them (however, second variant is supported by CSVRowInputStream, not by deserializeTextCSV).\n+      * (see also input_format_defaults_for_omitted_fields and input_format_csv_unquoted_null_literal_as_null settings)\n       * In CSV, non-NULL string value, starting with \\N characters, must be placed in quotes, to avoid ambiguity.\n       */\n     void deserializeTextCSV(IColumn & column, ReadBuffer & istr, const FormatSettings & settings) const override;\ndiff --git a/dbms/src/Formats/CSVRowInputStream.cpp b/dbms/src/Formats/CSVRowInputStream.cpp\nindex 07cfd4826dfa..635fef82cd0b 100644\n--- a/dbms/src/Formats/CSVRowInputStream.cpp\n+++ b/dbms/src/Formats/CSVRowInputStream.cpp\n@@ -1,5 +1,6 @@\n #include <Core/Defines.h>\n \n+#include <IO/ConcatReadBuffer.h>\n #include <IO/ReadHelpers.h>\n #include <IO/Operators.h>\n \n@@ -8,6 +9,8 @@\n #include <Formats/FormatFactory.h>\n #include <Formats/BlockInputStreamFromRowInputStream.h>\n \n+#include <DataTypes/DataTypeNullable.h>\n+\n \n namespace DB\n {\n@@ -96,6 +99,7 @@ CSVRowInputStream::CSVRowInputStream(ReadBuffer & istr_, const Block & header_,\n \n     data_types.resize(num_columns);\n     column_indexes_by_names.reserve(num_columns);\n+    column_idx_to_nullable_column_idx.resize(num_columns);\n \n     for (size_t i = 0; i < num_columns; ++i)\n     {\n@@ -103,6 +107,16 @@ CSVRowInputStream::CSVRowInputStream(ReadBuffer & istr_, const Block & header_,\n \n         data_types[i] = column_info.type;\n         column_indexes_by_names.emplace(column_info.name, i);\n+\n+        /// If input_format_null_as_default=1 we need ColumnNullable of type DataTypeNullable(nested_type)\n+        /// to parse value as nullable before inserting it in corresponding column of not-nullable type.\n+        /// Constructing temporary column for each row is slow, so we prepare it here\n+        if (format_settings.csv.null_as_default && !column_info.type->isNullable() && column_info.type->canBeInsideNullable())\n+        {\n+            column_idx_to_nullable_column_idx[i] = nullable_columns.size();\n+            nullable_types.emplace_back(std::make_shared<DataTypeNullable>(column_info.type));\n+            nullable_columns.emplace_back(nullable_types.back()->createColumn());\n+        }\n     }\n }\n \n@@ -210,38 +224,16 @@ bool CSVRowInputStream::read(MutableColumns & columns, RowReadExtension & ext)\n     for (size_t file_column = 0; file_column < column_indexes_for_input_fields.size(); ++file_column)\n     {\n         const auto & table_column = column_indexes_for_input_fields[file_column];\n-        const bool is_last_file_column =\n-                file_column + 1 == column_indexes_for_input_fields.size();\n+        const bool is_last_file_column = file_column + 1 == column_indexes_for_input_fields.size();\n \n         if (table_column)\n         {\n-            const auto & type = data_types[*table_column];\n-            const bool at_delimiter = *istr.position() == delimiter;\n-            const bool at_last_column_line_end = is_last_file_column\n-                    && (*istr.position() == '\\n' || *istr.position() == '\\r'\n-                        || istr.eof());\n-\n-            if (format_settings.csv.empty_as_default\n-                    && (at_delimiter || at_last_column_line_end))\n-            {\n-                /// Treat empty unquoted column value as default value, if\n-                /// specified in the settings. Tuple columns might seem\n-                /// problematic, because they are never quoted but still contain\n-                /// commas, which might be also used as delimiters. However,\n-                /// they do not contain empty unquoted fields, so this check\n-                /// works for tuples as well.\n-                read_columns[*table_column] = false;\n+            skipWhitespacesAndTabs(istr);\n+            read_columns[*table_column] = readField(*columns[*table_column], data_types[*table_column],\n+                                                    is_last_file_column, *table_column);\n+            if (!read_columns[*table_column])\n                 have_default_columns = true;\n-            }\n-            else\n-            {\n-                /// Read the column normally.\n-                read_columns[*table_column] = true;\n-                skipWhitespacesAndTabs(istr);\n-                type->deserializeAsTextCSV(*columns[*table_column], istr,\n-                    format_settings);\n-                skipWhitespacesAndTabs(istr);\n-            }\n+            skipWhitespacesAndTabs(istr);\n         }\n         else\n         {\n@@ -380,7 +372,7 @@ bool OPTIMIZE(1) CSVRowInputStream::parseRowAndPrintDiagnosticInfo(MutableColumn\n                 {\n                     skipWhitespacesAndTabs(istr);\n                     prev_position = istr.position();\n-                    current_column_type->deserializeAsTextCSV(*columns[table_column], istr, format_settings);\n+                    readField(*columns[table_column], current_column_type, is_last_file_column, table_column);\n                     curr_position = istr.position();\n                     skipWhitespacesAndTabs(istr);\n                 }\n@@ -520,6 +512,45 @@ void CSVRowInputStream::updateDiagnosticInfo()\n     pos_of_current_row = istr.position();\n }\n \n+bool CSVRowInputStream::readField(IColumn & column, const DataTypePtr & type, bool is_last_file_column, size_t column_idx)\n+{\n+    const bool at_delimiter = *istr.position() == format_settings.csv.delimiter;\n+    const bool at_last_column_line_end = is_last_file_column\n+                                         && (*istr.position() == '\\n' || *istr.position() == '\\r'\n+                                             || istr.eof());\n+\n+    if (format_settings.csv.empty_as_default\n+        && (at_delimiter || at_last_column_line_end))\n+    {\n+        /// Treat empty unquoted column value as default value, if\n+        /// specified in the settings. Tuple columns might seem\n+        /// problematic, because they are never quoted but still contain\n+        /// commas, which might be also used as delimiters. However,\n+        /// they do not contain empty unquoted fields, so this check\n+        /// works for tuples as well.\n+        return false;\n+    }\n+    else if (column_idx_to_nullable_column_idx[column_idx])\n+    {\n+        /// If value is null but type is not nullable then use default value instead.\n+        const size_t nullable_idx = *column_idx_to_nullable_column_idx[column_idx];\n+        auto & tmp_col = *nullable_columns[nullable_idx];\n+        nullable_types[nullable_idx]->deserializeAsTextCSV(tmp_col, istr, format_settings);\n+        Field value = tmp_col[0];\n+        tmp_col.popBack(1);     /// do not store copy of values in memory\n+        if (value.isNull())\n+            return false;\n+        column.insert(value);\n+        return true;\n+    }\n+    else\n+    {\n+        /// Read the column normally.\n+        type->deserializeAsTextCSV(column, istr, format_settings);\n+        return true;\n+    }\n+}\n+\n \n void registerInputFormatCSV(FormatFactory & factory)\n {\ndiff --git a/dbms/src/Formats/CSVRowInputStream.h b/dbms/src/Formats/CSVRowInputStream.h\nindex b282b22570e2..6cb0fe8e82fb 100644\n--- a/dbms/src/Formats/CSVRowInputStream.h\n+++ b/dbms/src/Formats/CSVRowInputStream.h\n@@ -67,10 +67,17 @@ class CSVRowInputStream : public IRowInputStream\n     char * pos_of_current_row = nullptr;\n     char * pos_of_prev_row = nullptr;\n \n+    /// For setting input_format_null_as_default\n+    DataTypes nullable_types;\n+    MutableColumns nullable_columns;\n+    OptionalIndexes column_idx_to_nullable_column_idx;\n+\n     void updateDiagnosticInfo();\n \n     bool parseRowAndPrintDiagnosticInfo(MutableColumns & columns,\n         WriteBuffer & out, size_t max_length_of_column_name, size_t max_length_of_data_type_name);\n+\n+    bool readField(IColumn & column, const DataTypePtr & type, bool is_last_file_column, size_t column_idx);\n };\n \n }\ndiff --git a/dbms/src/Formats/FormatFactory.cpp b/dbms/src/Formats/FormatFactory.cpp\nindex 4fae140abee9..3dfcc84eb4d3 100644\n--- a/dbms/src/Formats/FormatFactory.cpp\n+++ b/dbms/src/Formats/FormatFactory.cpp\n@@ -41,7 +41,9 @@ static FormatSettings getInputFormatSetting(const Settings & settings)\n     format_settings.csv.delimiter = settings.format_csv_delimiter;\n     format_settings.csv.allow_single_quotes = settings.format_csv_allow_single_quotes;\n     format_settings.csv.allow_double_quotes = settings.format_csv_allow_double_quotes;\n+    format_settings.csv.unquoted_null_literal_as_null = settings.input_format_csv_unquoted_null_literal_as_null;\n     format_settings.csv.empty_as_default = settings.input_format_defaults_for_omitted_fields;\n+    format_settings.csv.null_as_default = settings.input_format_null_as_default;\n     format_settings.values.interpret_expressions = settings.input_format_values_interpret_expressions;\n     format_settings.with_names_use_header = settings.input_format_with_names_use_header;\n     format_settings.skip_unknown_fields = settings.input_format_skip_unknown_fields;\ndiff --git a/dbms/src/Formats/FormatSettings.h b/dbms/src/Formats/FormatSettings.h\nindex 0bb71e6e50ec..f4dd8e6cb8a7 100644\n--- a/dbms/src/Formats/FormatSettings.h\n+++ b/dbms/src/Formats/FormatSettings.h\n@@ -27,7 +27,9 @@ struct FormatSettings\n         char delimiter = ',';\n         bool allow_single_quotes = true;\n         bool allow_double_quotes = true;\n+        bool unquoted_null_literal_as_null = false;\n         bool empty_as_default = false;\n+        bool null_as_default = false;\n     };\n \n     CSV csv;\ndiff --git a/docs/en/interfaces/formats.md b/docs/en/interfaces/formats.md\nindex 71f282632703..8c9badaa02fa 100644\n--- a/docs/en/interfaces/formats.md\n+++ b/docs/en/interfaces/formats.md\n@@ -173,7 +173,7 @@ Empty unquoted input values are replaced with default values for the respective\n [input_format_defaults_for_omitted_fields](../operations/settings/settings.md#session_settings-input_format_defaults_for_omitted_fields)\n is enabled.\n \n-`NULL` is formatted as `\\N`.\n+`NULL` is formatted as `\\N` or `NULL` or an empty unquoted string (see settings [input_format_csv_unquoted_null_literal_as_null](../operations/settings/settings.md#settings-input_format_csv_unquoted_null_literal_as_null) and [input_format_defaults_for_omitted_fields](../operations/settings/settings.md#settings-input_format_defaults_for_omitted_fields)).\n \n The CSV format supports the output of totals and extremes the same way as `TabSeparated`.\n \ndiff --git a/docs/en/operations/settings/settings.md b/docs/en/operations/settings/settings.md\nindex 63648d95b779..b4247d17de90 100644\n--- a/docs/en/operations/settings/settings.md\n+++ b/docs/en/operations/settings/settings.md\n@@ -211,6 +211,11 @@ Possible values:\n \n Default value: 0.\n \n+## input_format_null_as_default {#settings-input_format_null_as_default}\n+\n+Enables or disables using default values if input data contain `NULL`, but data type of corresponding column in not `Nullable(T)` (for CSV format).\n+\n+\n ## input_format_skip_unknown_fields {#settings-input_format_skip_unknown_fields}\n \n Enables or disables skipping insertion of extra data.\n@@ -689,6 +694,10 @@ If the value is true, integers appear in quotes when using JSON\\* Int64 and UInt\n \n The character interpreted as a delimiter in the CSV data. By default, the delimiter is `,`.\n \n+## input_format_csv_unquoted_null_literal_as_null {#settings-input_format_csv_unquoted_null_literal_as_null}\n+\n+For CSV input format enables or disables parsing of unquoted `NULL` as literal (synonym for `\\N`).\n+\n ## insert_quorum {#settings-insert_quorum}\n \n Enables quorum writes.\ndiff --git a/docs/ru/interfaces/formats.md b/docs/ru/interfaces/formats.md\nindex bc685443b0dd..14d6408b7e75 100644\n--- a/docs/ru/interfaces/formats.md\n+++ b/docs/ru/interfaces/formats.md\n@@ -165,9 +165,9 @@ clickhouse-client --format_csv_delimiter=\"|\" --query=\"INSERT INTO test.csv FORMA\n \n \u041f\u0440\u0438 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0435, \u0432\u0441\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0433\u0443\u0442 \u043f\u0430\u0440\u0441\u0438\u0442\u044c\u0441\u044f \u043a\u0430\u043a \u0432 \u043a\u0430\u0432\u044b\u0447\u043a\u0430\u0445, \u0442\u0430\u043a \u0438 \u0431\u0435\u0437 \u043a\u0430\u0432\u044b\u0447\u0435\u043a. \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0432\u0430\u044e\u0442\u0441\u044f \u043a\u0430\u043a \u0434\u0432\u043e\u0439\u043d\u044b\u0435, \u0442\u0430\u043a \u0438 \u043e\u0434\u0438\u043d\u0430\u0440\u043d\u044b\u0435 \u043a\u0430\u0432\u044b\u0447\u043a\u0438. \u0421\u0442\u0440\u043e\u043a\u0438 \u0442\u0430\u043a\u0436\u0435 \u043c\u043e\u0433\u0443\u0442 \u0431\u044b\u0442\u044c \u0431\u0435\u0437 \u043a\u0430\u0432\u044b\u0447\u0435\u043a. \u0412 \u044d\u0442\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435 \u043e\u043d\u0438 \u043f\u0430\u0440\u0441\u044f\u0442\u0441\u044f \u0434\u043e \u0441\u0438\u043c\u0432\u043e\u043b\u0430-\u0440\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u0435\u043b\u044f \u0438\u043b\u0438 \u043f\u0435\u0440\u0435\u0432\u043e\u0434\u0430 \u0441\u0442\u0440\u043e\u043a\u0438 (CR \u0438\u043b\u0438 LF). \u0412 \u043d\u0430\u0440\u0443\u0448\u0435\u043d\u0438\u0435 RFC, \u0432 \u0441\u043b\u0443\u0447\u0430\u0435 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u0441\u0442\u0440\u043e\u043a \u043d\u0435 \u0432 \u043a\u0430\u0432\u044b\u0447\u043a\u0430\u0445, \u043d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0435 \u0438 \u043a\u043e\u043d\u0435\u0447\u043d\u044b\u0435 \u043f\u0440\u043e\u0431\u0435\u043b\u044b \u0438 \u0442\u0430\u0431\u044b \u0438\u0433\u043d\u043e\u0440\u0438\u0440\u0443\u044e\u0442\u0441\u044f. \u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043f\u0435\u0440\u0435\u0432\u043e\u0434\u0430 \u0441\u0442\u0440\u043e\u043a\u0438, \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0432\u0430\u044e\u0442\u0441\u044f \u043a\u0430\u043a Unix (LF), \u0442\u0430\u043a \u0438 Windows (CR LF) \u0438 Mac OS Classic (LF CR) \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b.\n \n-\u0415\u0441\u043b\u0438 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u0430 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 [input_format_defaults_for_omitted_fields = 1](../operations/settings/settings.md#session_settings-input_format_defaults_for_omitted_fields), \u0442\u043e \u043f\u0443\u0441\u0442\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0431\u0435\u0437 \u043a\u0430\u0432\u044b\u0447\u0435\u043a \u0437\u0430\u043c\u0435\u043d\u044f\u044e\u0442\u0441\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438 \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u0434\u043b\u044f \u0442\u0438\u043f\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441\u0442\u043e\u043b\u0431\u0446\u0430.\n+`NULL` \u0444\u043e\u0440\u043c\u0430\u0442\u0438\u0440\u0443\u0435\u0442\u0441\u044f \u0432 \u0432\u0438\u0434\u0435 `\\N` \u0438\u043b\u0438 `NULL` \u0438\u043b\u0438 \u043f\u0443\u0441\u0442\u043e\u0439 \u043d\u0435\u044d\u043a\u0440\u0430\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0438 (\u0441\u043c. \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 [input_format_csv_unquoted_null_literal_as_null](../operations/settings/settings.md#settings-input_format_csv_unquoted_null_literal_as_null) \u0438 [input_format_defaults_for_omitted_fields](../operations/settings/settings.md#settings-input_format_defaults_for_omitted_fields)).\n \n-`NULL` \u0444\u043e\u0440\u043c\u0430\u0442\u0438\u0440\u0443\u0435\u0442\u0441\u044f \u0432 \u0432\u0438\u0434\u0435 `\\N`.\n+\u0415\u0441\u043b\u0438 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u0430 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 [input_format_defaults_for_omitted_fields = 1](../operations/settings/settings.md#session_settings-input_format_defaults_for_omitted_fields) \u0438 \u0442\u0438\u043f \u0441\u0442\u043e\u043b\u0431\u0446\u0430 \u043d\u0435 `Nullable(T)`, \u0442\u043e \u043f\u0443\u0441\u0442\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0431\u0435\u0437 \u043a\u0430\u0432\u044b\u0447\u0435\u043a \u0437\u0430\u043c\u0435\u043d\u044f\u044e\u0442\u0441\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438 \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u0434\u043b\u044f \u0442\u0438\u043f\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441\u0442\u043e\u043b\u0431\u0446\u0430.\n \n \u0424\u043e\u0440\u043c\u0430\u0442 CSV \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0432\u0430\u0435\u0442 \u0432\u044b\u0432\u043e\u0434 totals \u0438 extremes \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u043e `TabSeparated`.\n \ndiff --git a/docs/ru/operations/settings/settings.md b/docs/ru/operations/settings/settings.md\nindex e5e4bad1fa66..03a16b098fd3 100644\n--- a/docs/ru/operations/settings/settings.md\n+++ b/docs/ru/operations/settings/settings.md\n@@ -211,6 +211,10 @@ Ok.\n \n \u0417\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e: 0.\n \n+## input_format_null_as_default {#settings-input_format_null_as_default}\n+\n+\u0412\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u0438\u043b\u0438 \u043e\u0442\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043f\u043e-\u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u0432 \u0441\u043b\u0443\u0447\u0430\u044f\u0445, \u043a\u043e\u0433\u0434\u0430 \u0432\u043e \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442\u0441\u044f `NULL`, \u043d\u043e \u0442\u0438\u043f \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0435\u0433\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430 \u043d\u0435 `Nullable(T)` (\u0434\u043b\u044f \u0444\u043e\u043c\u0430\u0442\u0430 CSV).\n+\n ## input_format_skip_unknown_fields {#settings-input_format_skip_unknown_fields}\n \n \u0412\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u0438\u043b\u0438 \u043e\u0442\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u043d\u0438\u0435 \u0432\u0441\u0442\u0430\u0432\u043a\u0438 \u043d\u0435\u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445.\n@@ -617,6 +621,10 @@ load_balancing = first_or_random\n \n \u0421\u0438\u043c\u0432\u043e\u043b, \u0438\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0438\u0440\u0443\u0435\u043c\u044b\u0439 \u043a\u0430\u043a \u0440\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u0435\u043b\u044c \u0432 \u0434\u0430\u043d\u043d\u044b\u0445 \u0444\u043e\u0440\u043c\u0430\u0442\u0430 CSV. \u041f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u2014 `,`.\n \n+## input_format_csv_unquoted_null_literal_as_null {#settings-input_format_csv_unquoted_null_literal_as_null}\n+\n+\u0414\u043b\u044f \u0444\u043e\u0440\u043c\u0430\u0442\u0430 CSV \u0432\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u0438\u043b\u0438 \u0432\u044b\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u043f\u0430\u0440\u0441\u0438\u043d\u0433 \u043d\u0435\u044d\u043a\u0440\u0430\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0438 `NULL` \u043a\u0430\u043a \u043b\u0438\u0442\u0435\u0440\u0430\u043b\u0430 (\u0441\u0438\u043d\u043e\u043d\u0438\u043c \u0434\u043b\u044f `\\N`)\n+\n ## insert_quorum {#settings-insert_quorum}\n \n \u0412\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u043a\u0432\u043e\u0440\u0443\u043c\u043d\u0443\u044e \u0437\u0430\u043f\u0438\u0441\u044c.\n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/00301_csv.reference b/dbms/tests/queries/0_stateless/00301_csv.reference\nindex 69debccade9a..92cb50c0727b 100644\n--- a/dbms/tests/queries/0_stateless/00301_csv.reference\n+++ b/dbms/tests/queries/0_stateless/00301_csv.reference\n@@ -4,7 +4,14 @@ Hello \"world\"\t789\t2016-01-03\n Hello\\n world\t100\t2016-01-04\n default\t1\t2019-06-19\n default-eof\t1\t2019-06-19\n+0\t1\t42\t2019-07-22\n+1\tworld\t3\t2019-07-23\n+2\tHello\t123\t2019-06-19\n+3\tHello\t42\t2019-06-19\n 2016-01-01 01:02:03\t1\n 2016-01-02 01:02:03\t2\n 2017-08-15 13:15:01\t3\n 1970-01-02 06:46:39\t4\n+2016-01-01 01:02:03\tNUL\n+2016-01-02 01:02:03\tNhello\n+\\N\t\\N\ndiff --git a/dbms/tests/queries/0_stateless/00301_csv.sh b/dbms/tests/queries/0_stateless/00301_csv.sh\nindex c7ee476ab406..3ecc87e5bc1a 100755\n--- a/dbms/tests/queries/0_stateless/00301_csv.sh\n+++ b/dbms/tests/queries/0_stateless/00301_csv.sh\n@@ -17,6 +17,17 @@ Hello \"world\", 789 ,2016-01-03\n $CLICKHOUSE_CLIENT --query=\"SELECT * FROM csv ORDER BY d\";\n $CLICKHOUSE_CLIENT --query=\"DROP TABLE csv\";\n \n+\n+$CLICKHOUSE_CLIENT --query=\"CREATE TABLE csv (i Int8, s String DEFAULT 'Hello', n UInt64 DEFAULT 42, d Date DEFAULT '2019-06-19') ENGINE = Memory\";\n+echo '\\N, 1, \\N, \"2019-07-22\"\n+1, world, 3, \"2019-07-23\"\n+2, \\N, 123, \\N\n+3, \\N, \\N, \\N' | $CLICKHOUSE_CLIENT --input_format_null_as_default=1 --query=\"INSERT INTO csv FORMAT CSV\";\n+\n+$CLICKHOUSE_CLIENT --query=\"SELECT * FROM csv ORDER BY i\";\n+$CLICKHOUSE_CLIENT --query=\"DROP TABLE csv\";\n+\n+\n $CLICKHOUSE_CLIENT --query=\"CREATE TABLE csv (t DateTime('Europe/Moscow'), s String) ENGINE = Memory\";\n \n echo '\"2016-01-01 01:02:03\",\"1\"\n@@ -26,3 +37,13 @@ echo '\"2016-01-01 01:02:03\",\"1\"\n \n $CLICKHOUSE_CLIENT --query=\"SELECT * FROM csv ORDER BY s\";\n $CLICKHOUSE_CLIENT --query=\"DROP TABLE csv\";\n+\n+\n+$CLICKHOUSE_CLIENT --query=\"CREATE TABLE csv (t Nullable(DateTime('Europe/Moscow')), s Nullable(String)) ENGINE = Memory\";\n+\n+echo 'NULL, NULL\n+\"2016-01-01 01:02:03\",NUL\n+\"2016-01-02 01:02:03\",Nhello' | $CLICKHOUSE_CLIENT --input_format_csv_unquoted_null_literal_as_null=1 --query=\"INSERT INTO csv FORMAT CSV\";\n+\n+$CLICKHOUSE_CLIENT --query=\"SELECT * FROM csv ORDER BY s NULLS LAST\";\n+$CLICKHOUSE_CLIENT --query=\"DROP TABLE csv\";\n",
  "problem_statement": "load data with CSVWithNames or TabSeparatedWithNames got error when two columns  continuous  null\nI'm using clickhouse 19.9.2.4 , my csv file data like : \r\nbusiness_id,dates,goods_id,tbill_code,membership_card_id,fact_new_card_id,atc1_new,atc2_new,atc3_new,atc4_new,goods_name,sex,age,birthdays,is_subscribe_wx,subscribe_time,subscribe_store,activate_time,activate_store,first_buy_date,paid_in_amt,profit\r\n12501,2018-02-21,1062069,hnhys_PZ1A2500351654,801159913,801159913,OTC,\u513f\u79d1\u7528\u836f,\u513f\u7ae5\u80c3\u80a0\u9053\u7528\u836f,\u513f\u7ae5\u6d88\u5316\u4e0d\u826f/\u538c\u98df,\u5065\u513f\u6e05\u89e3\u6db2,2,NULL,NULL,0,NULL,A10U,NULL,A10U,2017-11-27,19.800000,8.300000\r\n\r\nwhen I try to load data with CSVWithNames , I got error :  \r\nColumn 0,   name: business_id,        type: String,         parsed text: \"12501\"\r\nColumn 1,   name: dates,              type: String,         parsed text: \"2018-02-21\"\r\nColumn 2,   name: goods_id,           type: String,         parsed text: \"1062069\"\r\nColumn 3,   name: tbill_code,         type: String,         parsed text: \"hnhys_PZ1A2500351654\"\r\nColumn 4,   name: membership_card_id, type: String,         parsed text: \"801159913\"\r\nColumn 5,   name: fact_new_card_id,   type: String,         parsed text: \"801159913\"\r\nColumn 6,   name: atc1_new,           type: String,         parsed text: \"OTC\"\r\nColumn 7,   name: atc2_new,           type: String,         parsed text: \"\u513f\u79d1\u7528\u836f\"\r\nColumn 8,   name: atc3_new,           type: String,         parsed text: \"\u513f\u7ae5\u80c3\u80a0\u9053\u7528\u836f\"\r\nColumn 9,   name: atc4_new,           type: String,         parsed text: \"\u513f\u7ae5\u6d88\u5316\u4e0d\u826f/\u538c\u98df\"\r\nColumn 10,  name: goods_name,         type: String,         parsed text: \"\u5065\u513f\u6e05\u89e3\u6db2\"\r\nColumn 11,  name: sex,                type: UInt32,         parsed text: \"2\"\r\nColumn 12,  name: age,                type: UInt32,         ERROR: text \"NULL,NULL,\" is not like UInt32\r\n\r\nwhat should I do ?\r\n\n",
  "hints_text": "if I data is like this : \r\n12501,2018-02-21,1062069,hnhys_PZ1A2500351654,801159913,801159913,OTC,\u513f\u79d1\u7528\u836f,\u513f\u7ae5\u80c3\u80a0\u9053\u7528\u836f,\u513f\u7ae5\u6d88\u5316\u4e0d\u826f/\u538c\u98df,\u5065\u513f\u6e05\u89e3\u6db2,2,,,0,,A10U,,A10U,2017-11-27,19.800000,8.300000 \r\n\r\nColumn 0,   name: business_id,        type: String,         parsed text: \"12501\"\r\nColumn 1,   name: dates,              type: String,         parsed text: \"2018-02-21\"\r\nColumn 2,   name: goods_id,           type: String,         parsed text: \"1062069\"\r\nColumn 3,   name: tbill_code,         type: String,         parsed text: \"hnhys_PZ1A2500351654\"\r\nColumn 4,   name: membership_card_id, type: String,         parsed text: \"801159913\"\r\nColumn 5,   name: fact_new_card_id,   type: String,         parsed text: \"801159913\"\r\nColumn 6,   name: atc1_new,           type: String,         parsed text: \"OTC\"\r\nColumn 7,   name: atc2_new,           type: String,         parsed text: \"\u513f\u79d1\u7528\u836f\"\r\nColumn 8,   name: atc3_new,           type: String,         parsed text: \"\u513f\u7ae5\u80c3\u80a0\u9053\u7528\u836f\"\r\nColumn 9,   name: atc4_new,           type: String,         parsed text: \"\u513f\u7ae5\u6d88\u5316\u4e0d\u826f/\u538c\u98df\"\r\nColumn 10,  name: goods_name,         type: String,         parsed text: \"\u5065\u513f\u6e05\u89e3\u6db2\"\r\nColumn 11,  name: sex,                type: UInt32,         parsed text: \"2\"\r\nColumn 12,  name: age,                type: UInt32,         ERROR: text \",,0,,A10U,\" is not like UInt32\nFirst, please make sure that the type of column is Nullable(Int32), or else it won't be able to store nulls. Then, use '\\N' for null values, not 'NULL'. Alternatively, you can set `input_format_defaults_for_omitted_fields = 1`, and then empty values like in your second example will be treated as nulls.",
  "created_at": "2019-07-18T16:13:34Z"
}