{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 33804,
  "instance_id": "ClickHouse__ClickHouse-33804",
  "issue_numbers": [
    "27784"
  ],
  "base_commit": "e3de3889e3cf0c6c0373446b2a2a69d69a16e36e",
  "patch": "diff --git a/src/Dictionaries/RedisDictionarySource.cpp b/src/Dictionaries/RedisDictionarySource.cpp\nindex 24a14d8cc800..a1b406b3424c 100644\n--- a/src/Dictionaries/RedisDictionarySource.cpp\n+++ b/src/Dictionaries/RedisDictionarySource.cpp\n@@ -3,26 +3,6 @@\n #include \"DictionaryStructure.h\"\n #include \"registerDictionaries.h\"\n \n-namespace DB\n-{\n-\n-void registerDictionarySourceRedis(DictionarySourceFactory & factory)\n-{\n-    auto create_table_source = [=](const DictionaryStructure & dict_struct,\n-                                   const Poco::Util::AbstractConfiguration & config,\n-                                   const String & config_prefix,\n-                                   Block & sample_block,\n-                                   ContextPtr /* global_context */,\n-                                   const std::string & /* default_database */,\n-                                   bool /* created_from_ddl */) -> DictionarySourcePtr {\n-        return std::make_unique<RedisDictionarySource>(dict_struct, config, config_prefix + \".redis\", sample_block);\n-    };\n-    factory.registerSource(\"redis\", create_table_source);\n-}\n-\n-}\n-\n-\n #include <Poco/Redis/Array.h>\n #include <Poco/Redis/Client.h>\n #include <Poco/Redis/Command.h>\n@@ -33,7 +13,6 @@ void registerDictionarySourceRedis(DictionarySourceFactory & factory)\n \n #include \"RedisSource.h\"\n \n-\n namespace DB\n {\n     namespace ErrorCodes\n@@ -42,34 +21,64 @@ namespace DB\n         extern const int INVALID_CONFIG_PARAMETER;\n         extern const int INTERNAL_REDIS_ERROR;\n         extern const int LOGICAL_ERROR;\n+        extern const int TIMEOUT_EXCEEDED;\n     }\n \n+    static RedisStorageType parseStorageType(const String & storage_type_str)\n+    {\n+        if (storage_type_str == \"hash_map\")\n+            return RedisStorageType::HASH_MAP;\n+        else if (!storage_type_str.empty() && storage_type_str != \"simple\")\n+            throw Exception(ErrorCodes::INVALID_CONFIG_PARAMETER, \"Unknown storage type {} for Redis dictionary\", storage_type_str);\n \n-    static const size_t max_block_size = 8192;\n+        return RedisStorageType::SIMPLE;\n+    }\n+\n+    void registerDictionarySourceRedis(DictionarySourceFactory & factory)\n+    {\n+        auto create_table_source = [=](const DictionaryStructure & dict_struct,\n+                                    const Poco::Util::AbstractConfiguration & config,\n+                                    const String & config_prefix,\n+                                    Block & sample_block,\n+                                    ContextPtr /* global_context */,\n+                                    const std::string & /* default_database */,\n+                                    bool /* created_from_ddl */) -> DictionarySourcePtr {\n+\n+            auto redis_config_prefix = config_prefix + \".redis\";\n+            RedisDictionarySource::Configuration configuration =\n+            {\n+                .host = config.getString(redis_config_prefix + \".host\"),\n+                .port = static_cast<UInt16>(config.getUInt(redis_config_prefix + \".port\")),\n+                .db_index = config.getUInt(redis_config_prefix + \".db_index\", 0),\n+                .password = config.getString(redis_config_prefix + \".password\", \"\"),\n+                .storage_type = parseStorageType(config.getString(redis_config_prefix + \".storage_type\", \"\")),\n+                .pool_size = config.getUInt(redis_config_prefix + \".pool_size\", 16),\n+            };\n+\n+            return std::make_unique<RedisDictionarySource>(dict_struct, configuration, sample_block);\n+        };\n+\n+        factory.registerSource(\"redis\", create_table_source);\n+    }\n+\n+    static constexpr size_t REDIS_MAX_BLOCK_SIZE = DEFAULT_BLOCK_SIZE;\n+    static constexpr size_t REDIS_LOCK_ACQUIRE_TIMEOUT_MS = 5000;\n \n     RedisDictionarySource::RedisDictionarySource(\n-            const DictionaryStructure & dict_struct_,\n-            const String & host_,\n-            UInt16 port_,\n-            UInt8 db_index_,\n-            const String & password_,\n-            RedisStorageType storage_type_,\n-            const Block & sample_block_)\n-            : dict_struct{dict_struct_}\n-            , host{host_}\n-            , port{port_}\n-            , db_index{db_index_}\n-            , password{password_}\n-            , storage_type{storage_type_}\n-            , sample_block{sample_block_}\n-            , client{std::make_shared<Poco::Redis::Client>(host, port)}\n+        const DictionaryStructure & dict_struct_,\n+        const Configuration & configuration_,\n+        const Block & sample_block_)\n+        : dict_struct{dict_struct_}\n+        , configuration(configuration_)\n+        , pool(std::make_shared<Pool>(configuration.pool_size))\n+        , sample_block{sample_block_}\n     {\n         if (dict_struct.attributes.size() != 1)\n             throw Exception(ErrorCodes::INVALID_CONFIG_PARAMETER,\n                 \"Invalid number of non key columns for Redis source: {}, expected 1\",\n                 DB::toString(dict_struct.attributes.size()));\n \n-        if (storage_type == RedisStorageType::HASH_MAP)\n+        if (configuration.storage_type == RedisStorageType::HASH_MAP)\n         {\n             if (!dict_struct.key)\n                 throw Exception(ErrorCodes::INVALID_CONFIG_PARAMETER,\n@@ -87,61 +96,13 @@ namespace DB\n                         key.name,\n                         key.type->getName());\n         }\n-\n-        if (!password.empty())\n-        {\n-            RedisCommand command(\"AUTH\");\n-            command << password;\n-            String reply = client->execute<String>(command);\n-            if (reply != \"OK\")\n-                throw Exception(ErrorCodes::INTERNAL_REDIS_ERROR,\n-                    \"Authentication failed with reason {}\",\n-                    reply);\n-        }\n-\n-        if (db_index != 0)\n-        {\n-            RedisCommand command(\"SELECT\");\n-            command << std::to_string(db_index);\n-            String reply = client->execute<String>(command);\n-            if (reply != \"OK\")\n-                throw Exception(ErrorCodes::INTERNAL_REDIS_ERROR,\n-                    \"Selecting database with index {} failed with reason {}\",\n-                    DB::toString(db_index),\n-                    reply);\n-        }\n     }\n \n-\n-    RedisDictionarySource::RedisDictionarySource(\n-            const DictionaryStructure & dict_struct_,\n-            const Poco::Util::AbstractConfiguration & config_,\n-            const String & config_prefix_,\n-            Block & sample_block_)\n-            : RedisDictionarySource(\n-            dict_struct_,\n-            config_.getString(config_prefix_ + \".host\"),\n-            config_.getUInt(config_prefix_ + \".port\"),\n-            config_.getUInt(config_prefix_ + \".db_index\", 0),\n-            config_.getString(config_prefix_ + \".password\",\"\"),\n-            parseStorageType(config_.getString(config_prefix_ + \".storage_type\", \"\")),\n-            sample_block_)\n-    {\n-    }\n-\n-\n     RedisDictionarySource::RedisDictionarySource(const RedisDictionarySource & other)\n-            : RedisDictionarySource{other.dict_struct,\n-                                    other.host,\n-                                    other.port,\n-                                    other.db_index,\n-                                    other.password,\n-                                    other.storage_type,\n-                                    other.sample_block}\n+        : RedisDictionarySource(other.dict_struct, other.configuration, other.sample_block)\n     {\n     }\n \n-\n     RedisDictionarySource::~RedisDictionarySource() = default;\n \n     static String storageTypeToKeyType(RedisStorageType type)\n@@ -161,24 +122,25 @@ namespace DB\n \n     Pipe RedisDictionarySource::loadAll()\n     {\n-        if (!client->isConnected())\n-            client->connect(host, port);\n+        auto connection = getConnection();\n \n         RedisCommand command_for_keys(\"KEYS\");\n         command_for_keys << \"*\";\n \n         /// Get only keys for specified storage type.\n-        auto all_keys = client->execute<RedisArray>(command_for_keys);\n+        auto all_keys = connection->client->execute<RedisArray>(command_for_keys);\n         if (all_keys.isNull())\n-            return Pipe(std::make_shared<RedisSource>(client, RedisArray{}, storage_type, sample_block, max_block_size));\n+            return Pipe(std::make_shared<RedisSource>(\n+                std::move(connection), RedisArray{},\n+                configuration.storage_type, sample_block, REDIS_MAX_BLOCK_SIZE));\n \n         RedisArray keys;\n-        auto key_type = storageTypeToKeyType(storage_type);\n+        auto key_type = storageTypeToKeyType(configuration.storage_type);\n         for (const auto & key : all_keys)\n-            if (key_type == client->execute<String>(RedisCommand(\"TYPE\").addRedisType(key)))\n+            if (key_type == connection->client->execute<String>(RedisCommand(\"TYPE\").addRedisType(key)))\n                 keys.addRedisType(std::move(key));\n \n-        if (storage_type == RedisStorageType::HASH_MAP)\n+        if (configuration.storage_type == RedisStorageType::HASH_MAP)\n         {\n             RedisArray hkeys;\n             for (const auto & key : keys)\n@@ -186,7 +148,7 @@ namespace DB\n                 RedisCommand command_for_secondary_keys(\"HKEYS\");\n                 command_for_secondary_keys.addRedisType(key);\n \n-                auto secondary_keys = client->execute<RedisArray>(command_for_secondary_keys);\n+                auto secondary_keys = connection->client->execute<RedisArray>(command_for_secondary_keys);\n \n                 RedisArray primary_with_secondary;\n                 primary_with_secondary.addRedisType(key);\n@@ -194,7 +156,7 @@ namespace DB\n                 {\n                     primary_with_secondary.addRedisType(secondary_key);\n                     /// Do not store more than max_block_size values for one request.\n-                    if (primary_with_secondary.size() == max_block_size + 1)\n+                    if (primary_with_secondary.size() == REDIS_MAX_BLOCK_SIZE + 1)\n                     {\n                         hkeys.add(primary_with_secondary);\n                         primary_with_secondary.clear();\n@@ -209,16 +171,16 @@ namespace DB\n             keys = std::move(hkeys);\n         }\n \n-        return Pipe(std::make_shared<RedisSource>(client, std::move(keys), storage_type, sample_block, max_block_size));\n+        return Pipe(std::make_shared<RedisSource>(\n+            std::move(connection), std::move(keys),\n+            configuration.storage_type, sample_block, REDIS_MAX_BLOCK_SIZE));\n     }\n \n-\n     Pipe RedisDictionarySource::loadIds(const std::vector<UInt64> & ids)\n     {\n-        if (!client->isConnected())\n-            client->connect(host, port);\n+        auto connection = getConnection();\n \n-        if (storage_type == RedisStorageType::HASH_MAP)\n+        if (configuration.storage_type == RedisStorageType::HASH_MAP)\n             throw Exception(ErrorCodes::UNSUPPORTED_METHOD, \"Cannot use loadIds with 'hash_map' storage type\");\n \n         if (!dict_struct.id)\n@@ -229,13 +191,14 @@ namespace DB\n         for (UInt64 id : ids)\n             keys << DB::toString(id);\n \n-        return Pipe(std::make_shared<RedisSource>(client, std::move(keys), storage_type, sample_block, max_block_size));\n+        return Pipe(std::make_shared<RedisSource>(\n+            std::move(connection), std::move(keys),\n+            configuration.storage_type, sample_block, REDIS_MAX_BLOCK_SIZE));\n     }\n \n     Pipe RedisDictionarySource::loadKeys(const Columns & key_columns, const std::vector<size_t> & requested_rows)\n     {\n-        if (!client->isConnected())\n-            client->connect(host, port);\n+        auto connection = getConnection();\n \n         if (key_columns.size() != dict_struct.key->size())\n             throw Exception(ErrorCodes::LOGICAL_ERROR, \"The size of key_columns does not equal to the size of dictionary key\");\n@@ -250,7 +213,7 @@ namespace DB\n                 if (isInteger(type))\n                     key << DB::toString(key_columns[i]->get64(row));\n                 else if (isString(type))\n-                    key << get<String>((*key_columns[i])[row]);\n+                    key << get<const String &>((*key_columns[i])[row]);\n                 else\n                     throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unexpected type of key in Redis dictionary\");\n             }\n@@ -258,22 +221,65 @@ namespace DB\n             keys.add(key);\n         }\n \n-        return Pipe(std::make_shared<RedisSource>(client, std::move(keys), storage_type, sample_block, max_block_size));\n+        return Pipe(std::make_shared<RedisSource>(\n+            std::move(connection), std::move(keys),\n+            configuration.storage_type, sample_block, REDIS_MAX_BLOCK_SIZE));\n     }\n \n-\n     String RedisDictionarySource::toString() const\n     {\n-        return \"Redis: \" + host + ':' + DB::toString(port);\n+        return \"Redis: \" + configuration.host + ':' + DB::toString(configuration.port);\n     }\n \n-    RedisStorageType RedisDictionarySource::parseStorageType(const String & storage_type_str)\n+    RedisDictionarySource::ConnectionPtr RedisDictionarySource::getConnection() const\n     {\n-        if (storage_type_str == \"hash_map\")\n-            return RedisStorageType::HASH_MAP;\n-        else if (!storage_type_str.empty() && storage_type_str != \"simple\")\n-            throw Exception(ErrorCodes::INVALID_CONFIG_PARAMETER, \"Unknown storage type {} for Redis dictionary\", storage_type_str);\n+        ClientPtr client;\n+        bool ok = pool->tryBorrowObject(client,\n+            [] { return std::make_unique<Poco::Redis::Client>(); },\n+            REDIS_LOCK_ACQUIRE_TIMEOUT_MS);\n \n-        return RedisStorageType::SIMPLE;\n+        if (!ok)\n+            throw Exception(ErrorCodes::TIMEOUT_EXCEEDED,\n+                \"Could not get connection from pool, timeout exceeded {} seconds\",\n+                REDIS_LOCK_ACQUIRE_TIMEOUT_MS);\n+\n+        if (!client->isConnected())\n+        {\n+            try\n+            {\n+                client->connect(configuration.host, configuration.port);\n+\n+                if (!configuration.password.empty())\n+                {\n+                    RedisCommand command(\"AUTH\");\n+                    command << configuration.password;\n+                    String reply = client->execute<String>(command);\n+                    if (reply != \"OK\")\n+                        throw Exception(ErrorCodes::INTERNAL_REDIS_ERROR,\n+                            \"Authentication failed with reason {}\", reply);\n+                }\n+\n+                if (configuration.db_index != 0)\n+                {\n+                    RedisCommand command(\"SELECT\");\n+                    command << std::to_string(configuration.db_index);\n+                    String reply = client->execute<String>(command);\n+                    if (reply != \"OK\")\n+                        throw Exception(ErrorCodes::INTERNAL_REDIS_ERROR,\n+                            \"Selecting database with index {} failed with reason {}\",\n+                            configuration.db_index, reply);\n+                }\n+            }\n+            catch (...)\n+            {\n+                if (client->isConnected())\n+                    client->disconnect();\n+\n+                pool->returnObject(std::move(client));\n+                throw;\n+            }\n+        }\n+\n+        return std::make_unique<Connection>(pool, std::move(client));\n     }\n }\ndiff --git a/src/Dictionaries/RedisDictionarySource.h b/src/Dictionaries/RedisDictionarySource.h\nindex eff97dede0c7..af12981f348d 100644\n--- a/src/Dictionaries/RedisDictionarySource.h\n+++ b/src/Dictionaries/RedisDictionarySource.h\n@@ -1,6 +1,7 @@\n #pragma once\n \n #include <Core/Block.h>\n+#include <base/BorrowedObjectPool.h>\n \n #include \"DictionaryStructure.h\"\n #include \"IDictionarySource.h\"\n@@ -20,13 +21,13 @@ namespace Poco\n     }\n }\n \n-\n namespace DB\n {\n-namespace ErrorCodes\n-{\n-    extern const int NOT_IMPLEMENTED;\n-}\n+    namespace ErrorCodes\n+    {\n+        extern const int NOT_IMPLEMENTED;\n+    }\n+\n     enum class RedisStorageType\n     {\n             SIMPLE,\n@@ -36,24 +37,46 @@ namespace ErrorCodes\n \n     class RedisDictionarySource final : public IDictionarySource\n     {\n-        RedisDictionarySource(\n-                const DictionaryStructure & dict_struct,\n-                const std::string & host,\n-                UInt16 port,\n-                UInt8 db_index,\n-                const std::string & password,\n-                RedisStorageType storage_type,\n-                const Block & sample_block);\n-\n     public:\n         using RedisArray = Poco::Redis::Array;\n         using RedisCommand = Poco::Redis::Command;\n \n+        using ClientPtr = std::unique_ptr<Poco::Redis::Client>;\n+        using Pool = BorrowedObjectPool<ClientPtr>;\n+        using PoolPtr = std::shared_ptr<Pool>;\n+\n+        struct Configuration\n+        {\n+            const std::string host;\n+            const UInt16 port;\n+            const UInt32 db_index;\n+            const std::string password;\n+            const RedisStorageType storage_type;\n+            const size_t pool_size;\n+        };\n+\n+        struct Connection\n+        {\n+            Connection(PoolPtr pool_, ClientPtr client_)\n+                : pool(std::move(pool_)), client(std::move(client_))\n+            {\n+            }\n+\n+            ~Connection()\n+            {\n+                pool->returnObject(std::move(client));\n+            }\n+\n+            PoolPtr pool;\n+            ClientPtr client;\n+        };\n+\n+        using ConnectionPtr = std::unique_ptr<Connection>;\n+\n         RedisDictionarySource(\n-                const DictionaryStructure & dict_struct,\n-                const Poco::Util::AbstractConfiguration & config,\n-                const std::string & config_prefix,\n-                Block & sample_block);\n+            const DictionaryStructure & dict_struct_,\n+            const Configuration & configuration_,\n+            const Block & sample_block_);\n \n         RedisDictionarySource(const RedisDictionarySource & other);\n \n@@ -81,17 +104,12 @@ namespace ErrorCodes\n         std::string toString() const override;\n \n     private:\n-        static RedisStorageType parseStorageType(const std::string& storage_type);\n+        ConnectionPtr getConnection() const;\n \n         const DictionaryStructure dict_struct;\n-        const std::string host;\n-        const UInt16 port;\n-        const UInt8 db_index;\n-        const std::string password;\n-        const RedisStorageType storage_type;\n-        Block sample_block;\n+        const Configuration configuration;\n \n-        std::shared_ptr<Poco::Redis::Client> client;\n+        PoolPtr pool;\n+        Block sample_block;\n     };\n-\n }\ndiff --git a/src/Dictionaries/RedisSource.cpp b/src/Dictionaries/RedisSource.cpp\nindex ad5cf8a0977b..6089b836d98b 100644\n--- a/src/Dictionaries/RedisSource.cpp\n+++ b/src/Dictionaries/RedisSource.cpp\n@@ -30,20 +30,22 @@ namespace DB\n \n \n     RedisSource::RedisSource(\n-            const std::shared_ptr<Poco::Redis::Client> & client_,\n-            const RedisArray & keys_,\n-            const RedisStorageType & storage_type_,\n-            const DB::Block & sample_block,\n-            const size_t max_block_size_)\n-            : SourceWithProgress(sample_block)\n-            , client(client_), keys(keys_), storage_type(storage_type_), max_block_size{max_block_size_}\n+        ConnectionPtr connection_,\n+        const RedisArray & keys_,\n+        const RedisStorageType & storage_type_,\n+        const DB::Block & sample_block,\n+        size_t max_block_size_)\n+        : SourceWithProgress(sample_block)\n+        , connection(std::move(connection_))\n+        , keys(keys_)\n+        , storage_type(storage_type_)\n+        , max_block_size{max_block_size_}\n     {\n         description.init(sample_block);\n     }\n \n     RedisSource::~RedisSource() = default;\n \n-\n     namespace\n     {\n         using ValueType = ExternalResultDescription::ValueType;\n@@ -121,7 +123,6 @@ namespace DB\n         }\n     }\n \n-\n     Chunk RedisSource::generate()\n     {\n         if (keys.isNull() || description.sample_block.rows() == 0 || cursor >= keys.size())\n@@ -168,7 +169,7 @@ namespace DB\n                 for (const auto & elem : keys_array)\n                     command_for_values.addRedisType(elem);\n \n-                auto values = client->execute<RedisArray>(command_for_values);\n+                auto values = connection->client->execute<RedisArray>(command_for_values);\n \n                 if (keys_array.size() != values.size() + 1) // 'HMGET' primary_key secondary_keys\n                     throw Exception(ErrorCodes::NUMBER_OF_COLUMNS_DOESNT_MATCH,\n@@ -199,7 +200,7 @@ namespace DB\n             for (size_t i = 0; i < need_values; ++i)\n                 command_for_values.add(keys.get<RedisBulkString>(cursor + i));\n \n-            auto values = client->execute<RedisArray>(command_for_values);\n+            auto values = connection->client->execute<RedisArray>(command_for_values);\n             if (values.size() != need_values)\n                 throw Exception(ErrorCodes::INTERNAL_REDIS_ERROR,\n                     \"Inconsistent sizes of keys and values in Redis request\");\ndiff --git a/src/Dictionaries/RedisSource.h b/src/Dictionaries/RedisSource.h\nindex db2e643eb4e2..24507998f581 100644\n--- a/src/Dictionaries/RedisSource.h\n+++ b/src/Dictionaries/RedisSource.h\n@@ -24,13 +24,14 @@ namespace DB\n     public:\n         using RedisArray = Poco::Redis::Array;\n         using RedisBulkString = Poco::Redis::BulkString;\n+        using ConnectionPtr = RedisDictionarySource::ConnectionPtr;\n \n         RedisSource(\n-                const std::shared_ptr<Poco::Redis::Client> & client_,\n-                const Poco::Redis::Array & keys_,\n-                const RedisStorageType & storage_type_,\n-                const Block & sample_block,\n-                const size_t max_block_size);\n+            ConnectionPtr connection_,\n+            const Poco::Redis::Array & keys_,\n+            const RedisStorageType & storage_type_,\n+            const Block & sample_block,\n+            size_t max_block_size);\n \n         ~RedisSource() override;\n \n@@ -39,7 +40,7 @@ namespace DB\n     private:\n         Chunk generate() override;\n \n-        std::shared_ptr<Poco::Redis::Client> client;\n+        ConnectionPtr connection;\n         Poco::Redis::Array keys;\n         RedisStorageType storage_type;\n         const size_t max_block_size;\n",
  "test_patch": "diff --git a/tests/integration/test_dictionaries_redis/test_long.py b/tests/integration/test_dictionaries_redis/test_long.py\nnew file mode 100644\nindex 000000000000..3f29403df627\n--- /dev/null\n+++ b/tests/integration/test_dictionaries_redis/test_long.py\n@@ -0,0 +1,51 @@\n+import pytest\n+from helpers.cluster import ClickHouseCluster\n+import redis\n+\n+cluster = ClickHouseCluster(__file__)\n+\n+node = cluster.add_instance('node', with_redis=True)\n+\n+@pytest.fixture(scope=\"module\")\n+def start_cluster():\n+    try:\n+        cluster.start()\n+\n+        N = 1000\n+        client = redis.Redis(host='localhost', port=cluster.redis_port, password='clickhouse', db=0)\n+        client.flushdb()\n+        for i in range(N):\n+            client.hset('2020-10-10', i, i)\n+\n+        node.query(\"\"\"\n+            CREATE DICTIONARY redis_dict\n+            (\n+                date String,\n+                id UInt64,\n+                value UInt64\n+            )\n+            PRIMARY KEY date, id\n+            SOURCE(REDIS(HOST '{}' PORT 6379 STORAGE_TYPE 'hash_map' DB_INDEX 0 PASSWORD 'clickhouse'))\n+            LAYOUT(COMPLEX_KEY_DIRECT())\n+            \"\"\".format(cluster.redis_host)\n+        )\n+\n+        node.query(\"\"\"\n+            CREATE TABLE redis_dictionary_test\n+            (\n+                date Date,\n+                id UInt64\n+            )\n+            ENGINE = MergeTree ORDER BY id\"\"\"\n+        )\n+\n+        node.query(\"INSERT INTO default.redis_dictionary_test SELECT '2020-10-10', number FROM numbers(1000000)\")\n+\n+        yield cluster\n+\n+    finally:\n+        cluster.shutdown()\n+\n+def test_redis_dict_long(start_cluster):\n+    assert node.query(\"SELECT count(), uniqExact(date), uniqExact(id) FROM redis_dict\") == \"1000\\t1\\t1000\\n\"\n+    assert node.query(\"SELECT count(DISTINCT dictGet('redis_dict', 'value', tuple(date, id % 1000))) FROM redis_dictionary_test\") == \"1000\\n\"\n",
  "problem_statement": "ClickHouse is stuck when using a dictionary with Redis as the data source\nI have a table with one million rows of data. And It's schema is like:\r\n```\r\ncreate table redis_dictionary_test\r\n(\r\n\tdate String,\r\n\tid String,\r\n\tvalue Int64\r\n)\r\nengine = MergeTree()\r\npartition by date\r\norder by id\r\nsettings index_granularity = 8192;\r\n```\r\n\r\nI also inserted one million key-value pairs into Redis.\r\nThe dictionary is like:\r\n```\r\ncreate dictionary redis_dict\r\n(\r\n\tdate String,\r\n\tid String,\r\n\tvalue Int64\r\n)\r\nPRIMARY KEY date, id\r\nSOURCE(REDIS(\r\n\thost '127.0.0.1'\r\n\tport 6379\r\n\tstorage_type 'hash_map'\r\n\tdb_index 0\r\n))\r\nLAYOUT(COMPLEX_KEY_DIRECT())\r\n```\r\nWhen I execute this query: `SELECT COUNT(DISTINCT dictGet('redis_dict', 'value', tuple(date, id))) FROM redis_dictionary_test;`, ClickHouse seems stuck. Progress was in this state: 122.88 thousand rows, 5.84 MB (1.20 million rows/s., 56.83 MB/s.)  12% about five minutes. Finally, I canceled query.\r\n\r\nI am sure Redis is fine. Because I monitored Redis and it could accept read and write commands.\r\n\r\nI also executed this query on 1000, 10000 and 100000 rows of data. They can return data normally.\r\n\r\nWhat happened to ClickHouse? Where can I find out the reason?\n",
  "hints_text": "I executed this query on data similar to the production environment, and ClickHouse threw an exception: \r\n```\r\n2021.08.17 10:51:59.555363 [ 34481 ] <Fatal> BaseDaemon: ########################################\r\n2021.08.17 10:51:59.555443 [ 34481 ] <Fatal> BaseDaemon: (version 21.7.4.18 (official build), build id: 697A9902DCE7A291C0E5CA723B17481126142A81) (from thread 35955) (query_id: 8e054b93-bceb-4821-89b1-adca2867618a) Received signal Segmentation fault (11)\r\n2021.08.17 10:51:59.555478 [ 34481 ] <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Unknown si_code.\r\n2021.08.17 10:51:59.555508 [ 34481 ] <Fatal> BaseDaemon: Stack trace: 0xdbfacd8 0xdbfb71d 0x8dfe3e7 0xdf4daf7 0xdf4e0db 0xadff28b 0xadfcb47 0xa94d66e 0xf1fbdde 0xf1fc2d2 0xf8181b5 0x1085c3bc 0x1085c750 0x1085f627 0x10712a3d 0x1070f5d1 0x10714076 0x8d6b91f 0x8d6f203 0x7f3635df86db 0x7f363571588f\r\n2021.08.17 10:51:59.555595 [ 34481 ] <Fatal> BaseDaemon: 1. Poco::Redis::Type<Poco::Redis::Array>::~Type() @ 0xdbfacd8 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555621 [ 34481 ] <Fatal> BaseDaemon: 2. DB::RedisBlockInputStream::~RedisBlockInputStream() @ 0xdbfb71d in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555643 [ 34481 ] <Fatal> BaseDaemon: 3. std::__1::shared_ptr<DB::IBlockInputStream>::~shared_ptr() @ 0x8dfe3e7 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555683 [ 34481 ] <Fatal> BaseDaemon: 4. DB::DirectDictionary<(DB::DictionaryKeyType)1>::getColumns(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::shared_ptr<DB::IDataType const>, std::__1::allocator<std::__1::shared_ptr<DB::IDataType const> > > const&, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > const&, std::__1::vector<std::__1::shared_ptr<DB::IDataType const>, std::__1::allocator<std::__1::shared_ptr<DB::IDataType const> > > const&, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > const&) const @ 0xdf4daf7 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555723 [ 34481 ] <Fatal> BaseDaemon: 5. DB::DirectDictionary<(DB::DictionaryKeyType)1>::getColumn(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::IDataType const> const&, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > const&, std::__1::vector<std::__1::shared_ptr<DB::IDataType const>, std::__1::allocator<std::__1::shared_ptr<DB::IDataType const> > > const&, COW<DB::IColumn>::immutable_ptr<DB::IColumn> const&) const @ 0xdf4e0db in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555754 [ 34481 ] <Fatal> BaseDaemon: 6. DB::FunctionDictGetNoType<(DB::DictionaryGetFunctionType)0>::executeDictionaryRequest(std::__1::shared_ptr<DB::IDictionary const>&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > const&, std::__1::vector<std::__1::shared_ptr<DB::IDataType const>, std::__1::allocator<std::__1::shared_ptr<DB::IDataType const> > > const&, std::__1::shared_ptr<DB::IDataType const> const&, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > const&) const @ 0xadff28b in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555782 [ 34481 ] <Fatal> BaseDaemon: 7. DB::FunctionDictGetNoType<(DB::DictionaryGetFunctionType)0>::executeImpl(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&, std::__1::shared_ptr<DB::IDataType const> const&, unsigned long) const @ 0xadfcb47 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555804 [ 34481 ] <Fatal> BaseDaemon: 8. DB::FunctionToExecutableFunctionAdaptor::executeImpl(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&, std::__1::shared_ptr<DB::IDataType const> const&, unsigned long) const @ 0xa94d66e in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555832 [ 34481 ] <Fatal> BaseDaemon: 9. DB::IExecutableFunction::executeWithoutLowCardinalityColumns(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&, std::__1::shared_ptr<DB::IDataType const> const&, unsigned long, bool) const @ 0xf1fbdde in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555861 [ 34481 ] <Fatal> BaseDaemon: 10. DB::IExecutableFunction::execute(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&, std::__1::shared_ptr<DB::IDataType const> const&, unsigned long, bool) const @ 0xf1fc2d2 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555889 [ 34481 ] <Fatal> BaseDaemon: 11. DB::ExpressionActions::execute(DB::Block&, unsigned long&, bool) const @ 0xf8181b5 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555915 [ 34481 ] <Fatal> BaseDaemon: 12. DB::ExpressionTransform::transform(DB::Chunk&) @ 0x1085c3bc in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555934 [ 34481 ] <Fatal> BaseDaemon: 13. DB::ISimpleTransform::transform(DB::Chunk&, DB::Chunk&) @ 0x1085c750 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555959 [ 34481 ] <Fatal> BaseDaemon: 14. DB::ISimpleTransform::work() @ 0x1085f627 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.555987 [ 34481 ] <Fatal> BaseDaemon: 15. ? @ 0x10712a3d in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.556013 [ 34481 ] <Fatal> BaseDaemon: 16. DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) @ 0x1070f5d1 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.556036 [ 34481 ] <Fatal> BaseDaemon: 17. ? @ 0x10714076 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.556058 [ 34481 ] <Fatal> BaseDaemon: 18. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8d6b91f in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.556081 [ 34481 ] <Fatal> BaseDaemon: 19. ? @ 0x8d6f203 in /usr/bin/clickhouse\r\n2021.08.17 10:51:59.556112 [ 34481 ] <Fatal> BaseDaemon: 20. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n2021.08.17 10:51:59.556142 [ 34481 ] <Fatal> BaseDaemon: 21. clone @ 0x12188f in /lib/x86_64-linux-gnu/libc-2.27.so\r\n2021.08.17 10:51:59.675348 [ 34481 ] <Fatal> BaseDaemon: Checksum of the binary: 29FC72CB092D5C4B8F07929DE59AD4B8, integrity check passed.\r\n\r\nException on client:\r\nCode: 32. DB::Exception: Attempt to read after eof: while receiving packet from localhost:9000\r\n\r\nConnecting to localhost:9000 as user default.\r\nCode: 210. DB::NetException: Connection refused (localhost:9000)\r\n```",
  "created_at": "2022-01-20T00:06:10Z"
}