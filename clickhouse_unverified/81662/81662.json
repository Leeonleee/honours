{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 81662,
  "instance_id": "ClickHouse__ClickHouse-81662",
  "issue_numbers": [
    "71430"
  ],
  "base_commit": "dee9cf6468082ce4d71fcee02bdc77af0650327f",
  "patch": "diff --git a/src/Storages/Kafka/KafkaConsumer2.cpp b/src/Storages/Kafka/KafkaConsumer2.cpp\nindex d3b0dc89ee21..67014932757c 100644\n--- a/src/Storages/Kafka/KafkaConsumer2.cpp\n+++ b/src/Storages/Kafka/KafkaConsumer2.cpp\n@@ -115,7 +115,7 @@ void KafkaConsumer2::initializeQueues(const cppkafka::TopicPartitionList & topic\n             consumer->get_partition_queue(topic_partition));\n }\n \n-// it do the poll when needed\n+// it does the poll when needed\n ReadBufferPtr KafkaConsumer2::consume(const TopicPartition & topic_partition, const std::optional<int64_t> & message_count)\n {\n     resetIfStopped();\ndiff --git a/src/Storages/Kafka/StorageKafka2.cpp b/src/Storages/Kafka/StorageKafka2.cpp\nindex a154dd85dd1b..8e968a670567 100644\n--- a/src/Storages/Kafka/StorageKafka2.cpp\n+++ b/src/Storages/Kafka/StorageKafka2.cpp\n@@ -837,11 +837,13 @@ std::optional<StorageKafka2::LockedTopicPartitionInfo> StorageKafka2::createLock\n \n         LOG_TRACE(\n             log,\n-            \"Locked topic partition: {}:{} at offset {} with intent size {}\",\n+            \"Locked topic partition: {}:{} at offset {} with intent size {}, offset present: {}, intent size present: {}\",\n             partition_to_lock.topic,\n             partition_to_lock.partition_id,\n             lock_info.committed_offset.value_or(0),\n-            lock_info.intent_size.value_or(0));\n+            lock_info.intent_size.value_or(0),\n+            lock_info.committed_offset.has_value(),\n+            lock_info.intent_size.has_value());\n \n         return lock_info;\n     }\n@@ -983,6 +985,14 @@ void StorageKafka2::saveCommittedOffset(zkutil::ZooKeeper & keeper_to_use, const\n \n void StorageKafka2::saveIntent(zkutil::ZooKeeper & keeper_to_use, const TopicPartition & topic_partition, int64_t intent)\n {\n+    if (intent <= 0)\n+        throw Exception(\n+            ErrorCodes::LOGICAL_ERROR,\n+            \"Intent for topic-partition [{}:{}] must be greater than 0, but got {}\",\n+            topic_partition.topic,\n+            topic_partition.partition_id,\n+            intent);\n+\n     LOG_TEST(\n         log,\n         \"Saving intent of {} for topic-partition [{}:{}] at offset {}\",\n@@ -1022,6 +1032,7 @@ StorageKafka2::PolledBatchInfo StorageKafka2::pollConsumer(\n \n     std::optional<std::string> exception_message;\n     size_t total_rows = 0;\n+    size_t intent_size = 0;\n     size_t failed_poll_attempts = 0;\n \n     auto on_error = [&](const MutableColumns & result_columns, const ColumnCheckpoints & checkpoints, Exception & e)\n@@ -1077,6 +1088,7 @@ StorageKafka2::PolledBatchInfo StorageKafka2::pollConsumer(\n         exception_message.reset();\n         if (auto buf = consumer.consume(topic_partition, message_count))\n         {\n+            ++intent_size;\n             ProfileEvents::increment(ProfileEvents::KafkaMessagesRead);\n             new_rows = executor.execute(*buf);\n         }\n@@ -1188,6 +1200,7 @@ StorageKafka2::PolledBatchInfo StorageKafka2::pollConsumer(\n         result_block.insert(column);\n \n     batch_info.blocks.emplace_back(std::move(result_block));\n+    batch_info.intent_size = intent_size;\n     return batch_info;\n }\n \n@@ -1392,7 +1405,7 @@ std::optional<size_t> StorageKafka2::streamFromConsumer(ConsumerAndAssignmentInf\n     ++consumer_info.poll_count;\n \n     auto * lock_info = consumer_info.findTopicPartitionLock(topic_partition);\n-    auto [blocks, last_read_offset] = pollConsumer(\n+    auto [blocks, intent_size, last_read_offset] = pollConsumer(\n         *consumer_info.consumer, topic_partition, lock_info->intent_size, consumer_info.watch, kafka_context);\n \n     if (blocks.empty())\n@@ -1415,7 +1428,7 @@ std::optional<size_t> StorageKafka2::streamFromConsumer(ConsumerAndAssignmentInf\n \n     // We can't cancel during copyData, as it's not aware of commits and other kafka-related stuff.\n     // It will be cancelled on underlying layer (kafka buffer)\n-    lock_info->intent_size = last_read_offset - lock_info->committed_offset.value_or(0);\n+    lock_info->intent_size = intent_size;\n     saveIntent(keeper_to_use, topic_partition, *lock_info->intent_size);\n     std::atomic_size_t rows = 0;\n     {\ndiff --git a/src/Storages/Kafka/StorageKafka2.h b/src/Storages/Kafka/StorageKafka2.h\nindex 65142810d268..07b079b42757 100644\n--- a/src/Storages/Kafka/StorageKafka2.h\n+++ b/src/Storages/Kafka/StorageKafka2.h\n@@ -55,6 +55,9 @@ using KafkaConsumer2Ptr = std::shared_ptr<KafkaConsumer2>;\n /// manipulating the queues of librdkafka. By pulling from multiple topic-partitions\n /// the order of messages are not guaranteed, therefore they would have different\n /// hashes for deduplication.\n+///\n+/// For the committed offsets we try to mimic the same behavior as Kafka does: if the last\n+/// read offset is `n`, then we save the offset `n + 1`, same as Kafka does.\n class StorageKafka2 final : public IStorage, WithContext\n {\n     using KafkaInterceptors = KafkaInterceptors<StorageKafka2>;\n@@ -160,6 +163,7 @@ class StorageKafka2 final : public IStorage, WithContext\n     struct PolledBatchInfo\n     {\n         BlocksList blocks;\n+        int64_t intent_size;\n         int64_t last_offset;\n     };\n \n",
  "test_patch": "diff --git a/tests/integration/test_storage_kafka/test_intent_sizes.py b/tests/integration/test_storage_kafka/test_intent_sizes.py\nnew file mode 100644\nindex 000000000000..6face5c59162\n--- /dev/null\n+++ b/tests/integration/test_storage_kafka/test_intent_sizes.py\n@@ -0,0 +1,157 @@\n+import logging\n+\n+from helpers.kafka.common_direct import *\n+from helpers.kafka.common_direct import _VarintBytes\n+import helpers.kafka.common as k\n+\n+\n+# protoc --version\n+# libprotoc 3.0.0\n+# # to create kafka_pb2.py\n+# protoc --python_out=. kafka.proto\n+\n+\n+# TODO: add test for run-time offset update in CH, if we manually update it on Kafka side.\n+# TODO: add test for SELECT LIMIT is working.\n+\n+\n+cluster = ClickHouseCluster(__file__)\n+instance = cluster.add_instance(\n+    \"instance\",\n+    main_configs=[\"configs/kafka.xml\", \"configs/named_collection.xml\"],\n+    user_configs=[\"configs/users.xml\"],\n+    with_kafka=True,\n+    with_zookeeper=True,  # For Replicated Table\n+    macros={\n+        \"kafka_broker\": \"kafka1\",\n+        \"kafka_topic_old\": k.KAFKA_TOPIC_OLD,\n+        \"kafka_group_name_old\": k.KAFKA_CONSUMER_GROUP_OLD,\n+        \"kafka_topic_new\": k.KAFKA_TOPIC_NEW,\n+        \"kafka_group_name_new\": k.KAFKA_CONSUMER_GROUP_NEW,\n+        \"kafka_client_id\": \"instance\",\n+        \"kafka_format_json_each_row\": \"JSONEachRow\",\n+    },\n+    clickhouse_path_dir=\"clickhouse_path\",\n+)\n+\n+\n+# Fixtures\n+@pytest.fixture(scope=\"module\")\n+def kafka_cluster():\n+    try:\n+        cluster.start()\n+        kafka_id = instance.cluster.kafka_docker_id\n+        print((\"kafka_id is {}\".format(kafka_id)))\n+        yield cluster\n+    finally:\n+        cluster.shutdown()\n+\n+\n+@pytest.fixture(autouse=True)\n+def kafka_setup_teardown():\n+    instance.query(\"DROP DATABASE IF EXISTS test SYNC; CREATE DATABASE test;\")\n+    admin_client = k.get_admin_client(cluster)\n+\n+    def get_topics_to_delete():\n+        return [t for t in admin_client.list_topics() if not t.startswith(\"_\")]\n+\n+    topics = get_topics_to_delete()\n+    logging.debug(f\"Deleting topics: {topics}\")\n+    result = admin_client.delete_topics(topics)\n+    for topic, error in result.topic_error_codes:\n+        if error != 0:\n+            logging.warning(f\"Received error {error} while deleting topic {topic}\")\n+        else:\n+            logging.info(f\"Deleted topic {topic}\")\n+\n+    retries = 0\n+    topics = get_topics_to_delete()\n+    while len(topics) != 0:\n+        logging.info(f\"Existing topics: {topics}\")\n+        if retries >= 5:\n+            raise Exception(f\"Failed to delete topics {topics}\")\n+        retries += 1\n+        time.sleep(0.5)\n+    yield  # run test\n+\n+\n+def test_good_intent_size(kafka_cluster):\n+    instance.rotate_logs()\n+\n+    topic_name = \"topic_intent_size\"\n+\n+    def produce_message(index):\n+        k.kafka_produce(\n+            kafka_cluster,\n+            topic_name,\n+            [f\"message_{index}\"]\n+        )\n+\n+    produce_message(1)\n+\n+    create_kafka_query = k.generate_new_create_table_query(\"kafka\", \"a String\", topic_list=topic_name, format=\"LineAsString\", settings={\"kafka_flush_interval_ms\": 500})\n+\n+    with k.existing_kafka_topic(k.get_admin_client(kafka_cluster), topic_name):\n+        instance.query(\n+            f\"\"\"\n+            CREATE TABLE test.dst (\n+                a String,\n+            )\n+            ENGINE = MergeTree()\n+            ORDER BY a;\n+\n+            {create_kafka_query};\n+\n+            CREATE MATERIALIZED VIEW test.kafka_mv TO test.dst AS\n+            SELECT\n+                a\n+            FROM test.kafka;\n+            \"\"\"\n+        )\n+\n+        def check_intent_size(num_messages, offset):\n+            consumed_messages = instance.query_with_retry(\"SELECT * FROM test.dst\", retry_count =30, sleep_time=1, check_callback=lambda x: len(TSV(x)) == num_messages)\n+            logging.debug(f\"Consumed messages: {consumed_messages}\")\n+            instance.wait_for_log_line(f\"Saving intent of 1 for topic-partition \\\\[{topic_name}:0\\\\] at offset {offset}\", look_behind_lines=500)\n+\n+        INVALID_KAFKA_OFFSET = -1001\n+        check_intent_size(1, INVALID_KAFKA_OFFSET)\n+\n+        produce_message(2)\n+        check_intent_size(2, 1)\n+\n+        result = instance.query(\"SELECT * FROM test.dst ORDER BY a\")\n+        assert TSV(result) == TSV(\"message_1\\nmessage_2\\n\")\n+\n+        instance.query(\n+            \"\"\"\n+            DROP TABLE test.kafka SYNC;\n+            TRUNCATE TABLE test.dst SETTINGS alter_sync=1;\n+            \"\"\")\n+        instance.query(create_kafka_query)\n+\n+        # Check that intent size is also correct when we have no saved committed offset\n+        produce_message(3)\n+        check_intent_size(1, INVALID_KAFKA_OFFSET)\n+        # Do an extra check to make sure wait_for_log_line in `check_intent_size` didn't caught the wrong line\n+        assert instance.wait_for_log_line(f\"Saving intent of 1 for topic-partition \\\\[{topic_name}:0\\\\] at offset {INVALID_KAFKA_OFFSET}\", look_behind_lines=10000, repetitions=2)\n+\n+        # Check that intent size is correct with multiple messages\n+        k.kafka_produce(\n+            kafka_cluster,\n+            topic_name,\n+            [f\"message_4\", \"message_5\"]\n+        )\n+\n+        consumed_messages = instance.query_with_retry(\"SELECT * FROM test.dst\", retry_count = 30, sleep_time = 1, check_callback=lambda x: len(TSV(x)) == 3)\n+        logging.debug(f\"Consumed messages: {consumed_messages}\")\n+        instance.wait_for_log_line(f\"Saving intent of 2 for topic-partition \\\\[{topic_name}:0\\\\] at offset 3\", look_behind_lines=500)\n+\n+        result = instance.query(\"SELECT * FROM test.dst ORDER BY a\")\n+        assert TSV(result) == TSV(\"message_3\\nmessage_4\\nmessage_5\")\n+\n+\n+if __name__ == \"__main__\":\n+    cluster.start()\n+    input(\"Cluster created, press any key to destroy...\")\n+    cluster.shutdown()\n",
  "problem_statement": "StorageKafka2 could not continue reading from one partition after a ZK session loss\nI have a StorageKafka2 table with two replicas.\r\nWhen a connection loss happened the table stopped reading from one of the partitions and never recovered.\r\nI had to delete a znode to fix the table.\r\n\r\nHere is what happened:\r\n\r\n1. StorageKafka2 was reading from partition 4 when ZooKeeper session expired:\r\n```\r\n2024.10.30 21:51:20.790423 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Will fetch topic1:4 (consume_from_topic_partition_index is 4)\r\n2024.10.30 21:51:20.790462 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:21.290594 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:51:21.290620 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:21.790763 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:51:21.790809 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:22.291136 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Polled batch of 1 messages. Offsets position: [topic1[0:5259773], topic1[1:5262769], topic1[2:5261993], topic1[3:5261874], topic1[4:5264992], topic1[5:5264874], topic1[6:5266124], topic1[7:5261532]]\r\n2024.10.30 21:51:22.291185 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:22.791322 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:51:22.791367 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:23.291512 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:51:23.291533 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:23.791906 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:51:23.791935 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:24.292236 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:51:24.292264 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:24.792375 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:51:24.792402 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:25.292735 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:51:25.292763 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:25.793019 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:51:25.793048 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264991\r\n2024.10.30 21:51:26.293325 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:51:26.293353 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stopped collecting message for current batch. There are 10 failed polled attempts, 1 total rows and consumer needs offset update is false\r\n2024.10.30 21:52:19.436993 [ 1550229 ] {} <Information> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Cleaning up topic-partitions locks because of exception: Coordination::Exception: Coordination error: Connection loss, path /clickhouse/kafka_topic1/topics/topic1/partitions/4/committed\r\n2024.10.30 21:52:19.437039 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stream stalled.\r\n2024.10.30 21:52:19.437047 [ 1550229 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Execution took 73040 ms.\r\n2024.10.30 21:52:19.437089 [ 1550134 ] {} <Warning> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): ZooKeeper session has expired. Switching to a new session\r\n2024.10.30 21:52:19.437106 [ 1550134 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Cancelling streams\r\n2024.10.30 21:52:19.437110 [ 1550134 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Waiting for cleanup\r\n```\r\n\r\n2. The table was re-activated and started reading from its partitions:\r\n```\r\n2024.10.30 21:52:32.052930 [ 1550134 ] {} <Debug> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Table activated successfully\r\n2024.10.30 21:52:32.052956 [ 1550134 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490))(activating task): Execution took 12616 ms.\r\n2024.10.30 21:52:32.052971 [ 1550230 ] {} <Debug> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Started streaming to 1 attached views\r\n2024.10.30 21:52:32.053011 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Polling consumer 0 for events\r\n2024.10.30 21:52:32.103330 [ 1550230 ] {} <Information> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Consumer has assignment: false\r\n2024.10.30 21:52:32.103354 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Consumer needs update offset\r\n2024.10.30 21:52:32.103367 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Creating locking ops for: /clickhouse/kafka_topic1/topics/topic1/partitions/0/lock\r\n2024.10.30 21:52:32.103372 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Creating locking ops for: /clickhouse/kafka_topic1/topics/topic1/partitions/1/lock\r\n2024.10.30 21:52:32.103376 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Creating locking ops for: /clickhouse/kafka_topic1/topics/topic1/partitions/2/lock\r\n2024.10.30 21:52:32.103380 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Creating locking ops for: /clickhouse/kafka_topic1/topics/topic1/partitions/3/lock\r\n2024.10.30 21:52:32.103384 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Creating locking ops for: /clickhouse/kafka_topic1/topics/topic1/partitions/4/lock\r\n2024.10.30 21:52:32.103388 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Creating locking ops for: /clickhouse/kafka_topic1/topics/topic1/partitions/5/lock\r\n2024.10.30 21:52:32.103392 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Creating locking ops for: /clickhouse/kafka_topic1/topics/topic1/partitions/6/lock\r\n2024.10.30 21:52:32.103396 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Creating locking ops for: /clickhouse/kafka_topic1/topics/topic1/partitions/7/lock\r\n2024.10.30 21:52:33.160252 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Locked topic partition: topic1:0 at offset 5259773 with intent size 0\r\n2024.10.30 21:52:33.717420 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Locked topic partition: topic1:1 at offset 5262769 with intent size 0\r\n2024.10.30 21:52:34.065687 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Locked topic partition: topic1:2 at offset 5261993 with intent size 0\r\n2024.10.30 21:52:34.068870 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Locked topic partition: topic1:3 at offset 5261874 with intent size 0\r\n2024.10.30 21:52:34.072089 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Locked topic partition: topic1:4 at offset 5264992 with intent size 0\r\n2024.10.30 21:52:34.177013 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Locked topic partition: topic1:5 at offset 5264874 with intent size 0\r\n2024.10.30 21:52:35.561763 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Locked topic partition: topic1:6 at offset 5266124 with intent size 0\r\n2024.10.30 21:52:35.873622 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Locked topic partition: topic1:7 at offset 5261532 with intent size 0\r\n2024.10.30 21:52:35.873822 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Trying to consume from consumer 0\r\n2024.10.30 21:52:35.876790 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Will fetch topic1:0 (consume_from_topic_partition_index is 0)\r\n2024.10.30 21:52:35.876818 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5259773\r\n2024.10.30 21:52:36.377228 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:36.377271 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5259773\r\n2024.10.30 21:52:36.877704 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:36.877762 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5259773\r\n2024.10.30 21:52:37.378108 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:37.378138 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5259773\r\n2024.10.30 21:52:37.878487 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:37.878515 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5259773\r\n2024.10.30 21:52:38.379017 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:38.379044 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5259773\r\n2024.10.30 21:52:38.879203 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:38.879229 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5259773\r\n2024.10.30 21:52:39.379578 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:39.379606 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5259773\r\n2024.10.30 21:52:39.879980 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:39.880007 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stopped collecting message for current batch. There are 8 failed polled attempts, 0 total rows and consumer needs offset update is false\r\n2024.10.30 21:52:39.880029 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Didn't get any messages\r\n2024.10.30 21:52:39.880272 [ 1550230 ] {} <Debug> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Couldn't stream any messages\r\n2024.10.30 21:52:39.880280 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stream stalled.\r\n2024.10.30 21:52:39.880288 [ 1550230 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Execution took 7827 ms.\r\n```\r\n\r\n3.  The reading from partition 4 was not successful it seems (there was no 'Execution took N ms' message):\r\n```\r\n2024.10.30 21:52:57.899968 [ 1550232 ] {} <Debug> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Started streaming to 1 attached views\r\n2024.10.30 21:52:57.899988 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Polling consumer 0 for events\r\n2024.10.30 21:52:57.950086 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Trying to consume from consumer 0\r\n2024.10.30 21:52:57.952277 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Will fetch topic1:4 (consume_from_topic_partition_index is 4)\r\n2024.10.30 21:52:57.952303 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264992\r\n2024.10.30 21:52:57.952309 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:57.952313 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264992\r\n2024.10.30 21:52:57.952316 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:57.952320 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264992\r\n2024.10.30 21:52:57.952323 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:57.952326 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264992\r\n2024.10.30 21:52:57.952329 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:57.952332 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264992\r\n2024.10.30 21:52:57.952335 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:57.952338 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264992\r\n2024.10.30 21:52:57.952341 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:57.952344 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264992\r\n2024.10.30 21:52:57.952347 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:57.952350 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264992\r\n2024.10.30 21:52:57.952353 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:57.952356 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264992\r\n2024.10.30 21:52:57.952366 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:57.952369 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Batch size 65409, offset 5264992\r\n2024.10.30 21:52:57.952372 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stalled\r\n2024.10.30 21:52:57.952376 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stopped collecting message for current batch. There are 10 failed polled attempts, 0 total rows and consumer needs offset update is false\r\n2024.10.30 21:52:57.952383 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Didn't get any messages\r\n2024.10.30 21:52:57.952446 [ 1550232 ] {} <Debug> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Couldn't stream any messages\r\n2024.10.30 21:52:57.952451 [ 1550232 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Stream stalled.\r\n```\r\n\r\n5. The other partitions recovered, and for several days ClickHouse was reporting new offsets for all partitions except the broken partition 4:\r\n```\r\n2024.10.30 21:55:51.056479 [ 1550174 ] {} <Trace> StorageKafka2 (kafka.kafka_topic1 (b17a71c3-eb35-44e5-8242-43d54b458490)): Polled batch of 93 messages. Offsets position: [topic1[0:5259854], topic1[1:5262838], topic1[2:5262076], topic1[3:5261943], topic1[4:#], topic1[5:5264968], topic1[6:5266198], topic1[7:5261613]]\r\n```\r\n\r\n6. I detached the Kafka2 table, removed the `/clickhouse/kafka_topic1/topics/topic1/partitions/4/intention` znode, attached the table back and it pulled missing messages from the partition 4.\r\n\r\nI would like ClickHouse to recover automatically from a failure like this.\n",
  "hints_text": "This happened to me again.\r\nCould you help to investigate this issue @antaljanosbenjamin? How does KafkaEngine suppose to recover from a connection loss? Last time I deleted the 'intention' node manually I got duplicates in the target table.\nIt should recover from errors like this. To be honest I am not sure what went wrong:\r\n\r\n```\r\nLocked topic partition: topic1:4 at offset 5264992 with intent size 0\r\n```\r\n\r\nThis seems to show the correct offset, and the intent is either somehow ended up with `0`, or it was not existing. Next time before deleting the intent file, maybe get the content of it.\r\n\r\nIf you are using ClickHouse in a not production environment, you can try to lover the log level for `TEST`, in this case you can a lot more logs and `StorageKafka2` will log much more information.\r\n\r\n> Last time I deleted the 'intention' node manually I got duplicates in the target table.\r\n\r\nThat means the content of the intent file was probably not `0`. \n> If you are using ClickHouse in a not production environment, you can try to lover the log level for `TEST`, in this case you can a lot more logs and `StorageKafka2` will log much more information.\r\n\r\nI did that. Let's wait :) \r\n\r\n> > Last time I deleted the 'intention' node manually I got duplicates in the target table.\r\n> \r\n> That means the content of the intent file was probably not `0`.\r\n\r\nIt happened again. I checked ZK and the value of the 'intention' node was 0. I removed it, the table recovered and there were no duplicates.\r\nWhat should I do if the value of the 'intention' node is not 0?\nHm, okay, then I guess the logic for writing the intent file goes wrong somewhere, because it shouldn't contain 0. I am not aware of any cases when a message doesn't have to contain at least 1 row. Does that might happen with you?\nYou are talking about 'the intent file', and I'm not sure what that is. Is it stored in the table's directory?\r\nI'm looking into Keeper's data and this is what I see now:\r\n```\r\nselect path, name, value, ctime, mtime from system.zookeeper where path = '/clickhouse/kafka_cost/topics/cost/partitions/0' \r\n\r\npath                                             | name       | value      | ctime               | mtime              \r\n-------------------------------------------------+------------+------------+---------------------+--------------------\r\n/clickhouse/kafka_cost/topics/cost/partitions/0  | lock       | replica1   | 2024-12-03 22:02:15 | 2024-12-03 22:02:15\r\n/clickhouse/kafka_cost/topics/cost/partitions/0  | committed  | 5668948    | 2024-10-24 18:49:06 | 2024-12-04 09:45:06\r\n```\r\nWhen the table stops reading from a partition there would be another node called 'intention'. The value of that 'intention' node was 0. And I am not sure what it was when I got duplicates.\r\nI delete this node in Keeper and reattach the Kafka table and it starts reading the partition again.\nYes, sorry I meant that intention node, but misphrased it as a file. That `intention` node is strange to have 0. Unfortunately as this is an experimental feature and I have other priorities right now, I cannot allocate time to debug this issue further. If you would like to fix it, feel free to open a PR.\nThis happened again on 25.3.\nUnfortunately I do not have logs at the time when the Kafka table stopped reading from one of the partitions. It happened after a connection loss with ZooKeeper.\nBTW I didn't see any log messages on the Test level for StorageKafka2. The only difference in logs between the working partitions and the broken partition is the absence of the 'Execution took N ms' message when StorageKafka2 is reading from the broken partition.\n> the absence of the 'Execution took N ms' message\n\nThe message seems to be coming from BackgroundSchedulePool https://github.com/ClickHouse/ClickHouse/blob/master/src/Core/BackgroundSchedulePool.cpp#L120",
  "created_at": "2025-06-11T14:49:02Z"
}