diff --git a/docker/test/stateful/run.sh b/docker/test/stateful/run.sh
index e69a85c0fca4..80a437999145 100755
--- a/docker/test/stateful/run.sh
+++ b/docker/test/stateful/run.sh
@@ -126,13 +126,16 @@ function run_tests()
     fi
 
     set +e
-    clickhouse-test -j 2 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \
-        --skip 00168_parallel_processing_on_replicas "${ADDITIONAL_OPTIONS[@]}" \
-        "$SKIP_TESTS_OPTION" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee test_output/test_result.txt
-
-    clickhouse-test --timeout 1200 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \
-    00168_parallel_processing_on_replicas "${ADDITIONAL_OPTIONS[@]}" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a test_output/test_result.txt
 
+    if [[ -n "$USE_PARALLEL_REPLICAS" ]] && [[ "$USE_PARALLEL_REPLICAS" -eq 1 ]]; then
+        clickhouse-test --client="clickhouse-client --use_hedged_requests=0  --allow_experimental_parallel_reading_from_replicas=1 \
+            --max_parallel_replicas=100 --cluster_for_parallel_replicas='parallel_replicas'" \
+            -j 2 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --no-parallel-replicas --hung-check --print-time "${ADDITIONAL_OPTIONS[@]}" \
+        "$SKIP_TESTS_OPTION" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee test_output/test_result.txt
+    else
+        clickhouse-test -j 2 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time "${ADDITIONAL_OPTIONS[@]}" \
+        "$SKIP_TESTS_OPTION" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee test_output/test_result.txt
+    fi
     set -e
 }
 
diff --git a/docker/test/stateless/run.sh b/docker/test/stateless/run.sh
index fef3fc4d2288..8e7d0ef55b96 100755
--- a/docker/test/stateless/run.sh
+++ b/docker/test/stateless/run.sh
@@ -134,9 +134,9 @@ function run_tests()
 
     set +e
     clickhouse-test --testname --shard --zookeeper --check-zookeeper-session --hung-check --print-time \
-            --test-runs "$NUM_TRIES" "${ADDITIONAL_OPTIONS[@]}" 2>&1 \
-        | ts '%Y-%m-%d %H:%M:%S' \
-        | tee -a test_output/test_result.txt
+        --test-runs "$NUM_TRIES" "${ADDITIONAL_OPTIONS[@]}" 2>&1 \
+    | ts '%Y-%m-%d %H:%M:%S' \
+    | tee -a test_output/test_result.txt
     set -e
 }
 
diff --git a/src/Storages/MergeTree/tests/gtest_coordinator.cpp b/src/Storages/MergeTree/tests/gtest_coordinator.cpp
deleted file mode 100644
index 7bcf3304c2b0..000000000000
--- a/src/Storages/MergeTree/tests/gtest_coordinator.cpp
+++ /dev/null
@@ -1,240 +0,0 @@
-#include <gtest/gtest.h>
-
-#include <utility>
-#include <limits>
-#include <set>
-
-#include <Storages/MergeTree/IntersectionsIndexes.h>
-
-#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>
-
-using namespace DB;
-
-
-TEST(HalfIntervals, Simple)
-{
-    ASSERT_TRUE((
-        HalfIntervals{{{1, 2}, {3, 4}}}.negate() ==
-        HalfIntervals{{{0, 1}, {2, 3}, {4, 18446744073709551615UL}}}
-    ));
-
-    {
-        auto left = HalfIntervals{{{0, 2}, {4, 6}}}.negate();
-        ASSERT_TRUE((
-            left ==
-            HalfIntervals{{{2, 4}, {6, 18446744073709551615UL}}}
-        ));
-    }
-
-    {
-        auto left = HalfIntervals{{{0, 2}, {4, 6}}};
-        auto right = HalfIntervals{{{1, 5}}}.negate();
-        auto intersection = left.intersect(right);
-
-        ASSERT_TRUE((
-            intersection ==
-            HalfIntervals{{{0, 1}, {5, 6}}}
-        ));
-    }
-
-    {
-        auto left = HalfIntervals{{{1, 2}, {2, 3}}};
-        auto right = HalfIntervals::initializeWithEntireSpace();
-        auto intersection = right.intersect(left.negate());
-
-        ASSERT_TRUE((
-            intersection ==
-            HalfIntervals{{{0, 1}, {3, 18446744073709551615UL}}}
-        ));
-    }
-
-    {
-        auto left = HalfIntervals{{{1, 2}, {2, 3}, {3, 4}, {4, 5}}};
-
-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 4}}}).convertToMarkRangesFinal().size(), 3);
-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 5}}}).convertToMarkRangesFinal().size(), 4);
-    }
-
-    {
-        auto left = HalfIntervals{{{1, 3}, {3, 5}, {5, 7}}};
-
-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 5}}}).convertToMarkRangesFinal().size(), 1);
-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 7}}}).convertToMarkRangesFinal().size(), 2);
-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{4, 6}}}).convertToMarkRangesFinal().size(), 2);
-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 7}}}).convertToMarkRangesFinal().size(), 3);
-    }
-
-    {
-        auto left = HalfIntervals{{{1, 3}}};
-
-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 4}}}).convertToMarkRangesFinal().size(), 0);
-    }
-
-    {
-        auto left = HalfIntervals{{{1, 2}, {3, 4}, {5, 6}}};
-
-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{2, 3}}}).convertToMarkRangesFinal().size(), 0);
-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{4, 5}}}).convertToMarkRangesFinal().size(), 0);
-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 6}}}).convertToMarkRangesFinal().size(), 3);
-    }
-}
-
-TEST(HalfIntervals, TwoRequests)
-{
-    auto left = HalfIntervals{{{1, 2}, {2, 3}}};
-    auto right = HalfIntervals{{{2, 3}, {3, 4}}};
-    auto intersection = left.intersect(right);
-
-    ASSERT_TRUE((
-        intersection ==
-        HalfIntervals{{{2, 3}}}
-    ));
-
-    /// With negation
-    left = HalfIntervals{{{1, 2}, {2, 3}}}.negate();
-    right = HalfIntervals{{{2, 3}, {3, 4}}};
-    intersection = left.intersect(right);
-
-
-    ASSERT_TRUE((
-        intersection ==
-        HalfIntervals{{{3, 4}}}
-    ));
-}
-
-TEST(HalfIntervals, SelfIntersection)
-{
-    auto left = HalfIntervals{{{1, 2}, {2, 3}, {4, 5}}};
-    auto right = left;
-    auto intersection = left.intersect(right);
-
-    ASSERT_TRUE((
-        intersection == right
-    ));
-
-    left = HalfIntervals{{{1, 2}, {2, 3}, {4, 5}}};
-    right = left;
-    right.negate();
-    intersection = left.intersect(right);
-
-    ASSERT_TRUE((
-        intersection == HalfIntervals{}
-    ));
-}
-
-
-TEST(Coordinator, Simple)
-{
-    PartitionReadRequest request;
-    request.partition_id = "a";
-    request.part_name = "b";
-    request.projection_name = "c";
-    request.block_range = PartBlockRange{1, 2};
-    request.mark_ranges = MarkRanges{{1, 2}, {3, 4}};
-
-    ParallelReplicasReadingCoordinator coordinator;
-    auto response = coordinator.handleRequest(request);
-
-    ASSERT_FALSE(response.denied) << "Process request at first has to be accepted";
-
-    ASSERT_EQ(response.mark_ranges.size(), request.mark_ranges.size());
-
-    for (int i = 0; i < response.mark_ranges.size(); ++i)
-        EXPECT_EQ(response.mark_ranges[i], request.mark_ranges[i]);
-
-    response = coordinator.handleRequest(request);
-    ASSERT_TRUE(response.denied) << "Process the same request second time";
-}
-
-
-TEST(Coordinator, TwoRequests)
-{
-    PartitionReadRequest first;
-    first.partition_id = "a";
-    first.part_name = "b";
-    first.projection_name = "c";
-    first.block_range = PartBlockRange{0, 0};
-    first.mark_ranges = MarkRanges{{1, 2}, {2, 3}};
-
-    auto second = first;
-    second.mark_ranges = MarkRanges{{2, 3}, {3, 4}};
-
-    ParallelReplicasReadingCoordinator coordinator;
-    auto response = coordinator.handleRequest(first);
-
-    ASSERT_FALSE(response.denied) << "First request must me accepted";
-
-    ASSERT_EQ(response.mark_ranges.size(), first.mark_ranges.size());
-    for (int i = 0; i < response.mark_ranges.size(); ++i)
-        EXPECT_EQ(response.mark_ranges[i], first.mark_ranges[i]);
-
-    response = coordinator.handleRequest(second);
-    ASSERT_FALSE(response.denied);
-    ASSERT_EQ(response.mark_ranges.size(), 1);
-    ASSERT_EQ(response.mark_ranges.front(), (MarkRange{3, 4}));
-}
-
-
-TEST(Coordinator, PartIntersections)
-{
-    {
-        PartSegments boundaries;
-
-        boundaries.addPart(PartToRead{{1, 1}, {"TestPart", "TestProjection"}});
-        boundaries.addPart(PartToRead{{2, 2}, {"TestPart", "TestProjection"}});
-        boundaries.addPart(PartToRead{{3, 3}, {"TestPart", "TestProjection"}});
-        boundaries.addPart(PartToRead{{4, 4}, {"TestPart", "TestProjection"}});
-
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 4}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-        ASSERT_EQ(boundaries.getIntersectionResult({{0, 5}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"ClickHouse", "AnotherProjection"}}), PartSegments::IntersectionResult::REJECT);
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 2}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-
-        boundaries.addPart(PartToRead{{5, 5}, {"TestPart", "TestProjection"}});
-        boundaries.addPart(PartToRead{{0, 0}, {"TestPart", "TestProjection"}});
-
-        ASSERT_EQ(boundaries.getIntersectionResult({{0, 5}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"ClickHouse", "AnotherProjection"}}), PartSegments::IntersectionResult::REJECT);
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 2}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-        ASSERT_EQ(boundaries.getIntersectionResult({{0, 3}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-    }
-
-    {
-        PartSegments boundaries;
-        boundaries.addPart(PartToRead{{1, 3}, {"TestPart", "TestProjection"}});
-        boundaries.addPart(PartToRead{{4, 5}, {"TestPart", "TestProjection"}});
-
-        ASSERT_EQ(boundaries.getIntersectionResult({{2, 4}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-        ASSERT_EQ(boundaries.getIntersectionResult({{0, 6}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-    }
-
-    {
-        PartSegments boundaries;
-        boundaries.addPart(PartToRead{{1, 3}, {"TestPart", "TestProjection"}});
-        boundaries.addPart(PartToRead{{4, 6}, {"TestPart", "TestProjection"}});
-        boundaries.addPart(PartToRead{{7, 9}, {"TestPart", "TestProjection"}});
-
-        ASSERT_EQ(boundaries.getIntersectionResult({{2, 8}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-        ASSERT_EQ(boundaries.getIntersectionResult({{4, 6}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);
-        ASSERT_EQ(boundaries.getIntersectionResult({{3, 7}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-        ASSERT_EQ(boundaries.getIntersectionResult({{5, 7}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-    }
-
-    {
-        PartSegments boundaries;
-
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::NO_INTERSECTION);
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 3}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::NO_INTERSECTION);
-        ASSERT_EQ(boundaries.getIntersectionResult({{0, 100500}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::NO_INTERSECTION);
-
-        boundaries.addPart(PartToRead{{1, 1}, {"TestPart", "TestProjection"}});
-        boundaries.addPart(PartToRead{{2, 2}, {"TestPart", "TestProjection"}});
-        boundaries.addPart(PartToRead{{3, 3}, {"TestPart", "TestProjection"}});
-
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);
-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 3}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
-        ASSERT_EQ(boundaries.getIntersectionResult({{100, 100500}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::NO_INTERSECTION);
-    }
-}
diff --git a/tests/ci/ci_config.py b/tests/ci/ci_config.py
index c77acfb679f4..b671b8683d7f 100644
--- a/tests/ci/ci_config.py
+++ b/tests/ci/ci_config.py
@@ -209,6 +209,26 @@
         "Stateful tests (release, DatabaseReplicated)": {
             "required_build": "package_release",
         },
+        # Stateful tests for parallel replicas
+        "Stateful tests (release, ParallelReplicas)": {
+            "required_build": "package_release",
+        },
+        "Stateful tests (debug, ParallelReplicas)": {
+            "required_build": "package_debug",
+        },
+        "Stateful tests (asan, ParallelReplicas)": {
+            "required_build": "package_asan",
+        },
+        "Stateful tests (msan, ParallelReplicas)": {
+            "required_build": "package_msan",
+        },
+        "Stateful tests (ubsan, ParallelReplicas)": {
+            "required_build": "package_ubsan",
+        },
+        "Stateful tests (tsan, ParallelReplicas)": {
+            "required_build": "package_tsan",
+        },
+        # End stateful tests for parallel replicas
         "Stateless tests (asan)": {
             "required_build": "package_asan",
         },
diff --git a/tests/ci/functional_test_check.py b/tests/ci/functional_test_check.py
index cf5f53afbf98..c33454d1d904 100644
--- a/tests/ci/functional_test_check.py
+++ b/tests/ci/functional_test_check.py
@@ -48,7 +48,8 @@ def get_additional_envs(check_name, run_by_hash_num, run_by_hash_total):
         result.append("USE_DATABASE_ORDINARY=1")
     if "wide parts enabled" in check_name:
         result.append("USE_POLYMORPHIC_PARTS=1")
-
+    if "ParallelReplicas" in check_name:
+        result.append("USE_PARALLEL_REPLICAS=1")
     if "s3 storage" in check_name:
         result.append("USE_S3_STORAGE_FOR_MERGE_TREE=1")
 
@@ -355,16 +356,34 @@ def main():
 
     print(f"::notice:: {check_name} Report url: {report_url}")
     if args.post_commit_status == "commit_status":
-        post_commit_status(
-            gh, pr_info.sha, check_name_with_group, description, state, report_url
-        )
+        if "parallelreplicas" in check_name.lower():
+            post_commit_status(
+                gh,
+                pr_info.sha,
+                check_name_with_group,
+                description,
+                "success",
+                report_url,
+            )
+        else:
+            post_commit_status(
+                gh, pr_info.sha, check_name_with_group, description, state, report_url
+            )
     elif args.post_commit_status == "file":
-        post_commit_status_to_file(
-            post_commit_path,
-            description,
-            state,
-            report_url,
-        )
+        if "parallelreplicas" in check_name.lower():
+            post_commit_status_to_file(
+                post_commit_path,
+                description,
+                "success",
+                report_url,
+            )
+        else:
+            post_commit_status_to_file(
+                post_commit_path,
+                description,
+                state,
+                report_url,
+            )
     else:
         raise Exception(
             f'Unknown post_commit_status option "{args.post_commit_status}"'
@@ -382,7 +401,11 @@ def main():
     ch_helper.insert_events_into(db="default", table="checks", events=prepared_events)
 
     if state != "success":
-        if FORCE_TESTS_LABEL in pr_info.labels:
+        # Parallel replicas are always green for now
+        if (
+            FORCE_TESTS_LABEL in pr_info.labels
+            or "parallelreplicas" in check_name.lower()
+        ):
             print(f"'{FORCE_TESTS_LABEL}' enabled, will report success")
         else:
             sys.exit(1)
diff --git a/tests/clickhouse-test b/tests/clickhouse-test
index 50d940bc23ce..366197cfd037 100755
--- a/tests/clickhouse-test
+++ b/tests/clickhouse-test
@@ -442,6 +442,7 @@ class FailureReason(enum.Enum):
     STRESS = "stress"
     BUILD = "not running for current build"
     BACKWARD_INCOMPATIBLE = "test is backward incompatible"
+    NO_PARALLEL_REPLICAS = "smth in not supported with parallel replicas"
 
     # UNKNOWN reasons
     NO_REFERENCE = "no reference file"
@@ -729,6 +730,9 @@ class TestCase:
         ):
             return FailureReason.DISABLED
 
+        elif "no-parallel-replicas" in tags and args.no_parallel_replicas:
+            return FailureReason.NO_PARALLEL_REPLICAS
+
         elif args.skip and any(s in self.name for s in args.skip):
             return FailureReason.SKIP
 
@@ -2399,6 +2403,13 @@ if __name__ == "__main__":
         default=False,
         help="Report statistics about log messages",
     )
+    parser.add_argument(
+        "--no-parallel-replicas",
+        action="store_true",
+        default=False,
+        help="Do not include tests that are not supported with parallel replicas feature",
+    )
+
     args = parser.parse_args()
 
     if args.queries and not os.path.isdir(args.queries):
diff --git a/tests/performance/memory_bound_merging.xml b/tests/performance/memory_bound_merging.xml
index 3b13400151c8..15dc1b29fba0 100644
--- a/tests/performance/memory_bound_merging.xml
+++ b/tests/performance/memory_bound_merging.xml
@@ -11,7 +11,5 @@
 
   <query>select avg(a) from remote('127.0.0.{{1,2}}', default, t_mbm) group by a format Null</query>
 
-  <query>select * from remote('127.0.0.{{1,2}}', default, t_mbm) group by a format Null settings allow_experimental_parallel_reading_from_replicas = 1, max_parallel_replicas = 2, use_hedged_requests = 0</query>
-
   <drop_query>drop table t_mbm</drop_query>
 </test>
diff --git a/tests/queries/0_stateless/02404_memory_bound_merging.reference b/tests/queries/0_stateless/02404_memory_bound_merging.reference
index 47d3470ef6ed..98e53cd50abb 100644
--- a/tests/queries/0_stateless/02404_memory_bound_merging.reference
+++ b/tests/queries/0_stateless/02404_memory_bound_merging.reference
@@ -98,8 +98,9 @@ select a, count() from dist_t_different_dbs group by a, b order by a limit 5 off
 502	2000
 503	2000
 504	2000
+1000000
 -- { echoOn } --
-explain pipeline select a from dist_pr_t group by a order by a limit 5 offset 500;
+explain pipeline select a from pr_t group by a order by a limit 5 offset 500;
 (Expression)
 ExpressionTransform
   (Limit)
@@ -112,28 +113,29 @@ ExpressionTransform
             (Expression)
             ExpressionTransform × 4
               (MergingAggregated)
-              MergingAggregatedBucketTransform × 4
-                Resize 1 → 4
-                  FinishAggregatingInOrderTransform 3 → 1
-                    (Union)
-                      (Aggregating)
-                      SortingAggregatedForMemoryBoundMergingTransform 4 → 1
-                        MergingAggregatedBucketTransform × 4
-                          Resize 1 → 4
-                            FinishAggregatingInOrderTransform 4 → 1
-                              AggregatingInOrderTransform × 4
-                                (Expression)
-                                ExpressionTransform × 4
-                                  (ReadFromMergeTree)
-                                  MergeTreeInOrder × 4 0 → 1
-                      (ReadFromRemoteParallelReplicas)
-select a, count() from dist_pr_t group by a order by a limit 5 offset 500;
+              Resize 1 → 4
+                SortingAggregatedTransform 4 → 1
+                  MergingAggregatedBucketTransform × 4
+                    Resize 1 → 4
+                      GroupingAggregatedTransform 6 → 1
+                        (Union)
+                          (Aggregating)
+                          MergingAggregatedBucketTransform × 4
+                            Resize 1 → 4
+                              FinishAggregatingInOrderTransform 4 → 1
+                                AggregatingInOrderTransform × 4
+                                  (Expression)
+                                  ExpressionTransform × 4
+                                    (ReadFromMergeTree)
+                                    MergeTreeInOrder × 4 0 → 1
+                          (ReadFromRemoteParallelReplicas)
+select a, count() from pr_t group by a order by a limit 5 offset 500;
 500	1000
 501	1000
 502	1000
 503	1000
 504	1000
-select a, count() from dist_pr_t group by a, b order by a limit 5 offset 500;
+select a, count() from pr_t group by a, b order by a limit 5 offset 500;
 500	1000
 501	1000
 502	1000
diff --git a/tests/queries/0_stateless/02404_memory_bound_merging.sql b/tests/queries/0_stateless/02404_memory_bound_merging.sql
index f4a1e75e3983..a38e4c5ec6b4 100644
--- a/tests/queries/0_stateless/02404_memory_bound_merging.sql
+++ b/tests/queries/0_stateless/02404_memory_bound_merging.sql
@@ -1,13 +1,13 @@
 -- Tags: no-parallel
 
 drop table if exists pr_t;
-drop table if exists dist_pr_t;
 drop table if exists dist_t_different_dbs;
 drop table if exists shard_1.t_different_dbs;
 drop table if exists t_different_dbs;
 drop table if exists dist_t;
 drop table if exists t;
 
+
 create table t(a UInt64, b UInt64) engine=MergeTree order by a;
 system stop merges t;
 insert into t select number, number from numbers_mt(1e6);
@@ -15,6 +15,7 @@ insert into t select number, number from numbers_mt(1e6);
 set enable_memory_bound_merging_of_aggregation_results = 1;
 set max_threads = 4;
 set optimize_aggregation_in_order = 1;
+set optimize_read_in_order = 1;
 set prefer_localhost_replica = 1;
 
 -- slightly different transforms will be generated by reading steps if we let settings randomisation to change this setting value --
@@ -56,26 +57,28 @@ select a, count() from dist_t_different_dbs group by a, b order by a limit 5 off
 
 -- { echoOff } --
 
+create table pr_t(a UInt64, b UInt64) engine=MergeTree order by a;
+insert into pr_t select number % 1000, number % 1000 from numbers_mt(1e6);
+
 set allow_experimental_parallel_reading_from_replicas = 1;
 set max_parallel_replicas = 3;
 set use_hedged_requests = 0;
+set cluster_for_parallel_replicas = 'test_cluster_one_shard_three_replicas_localhost';
+set distributed_aggregation_memory_efficient=1;
 
-create table pr_t(a UInt64, b UInt64) engine=MergeTree order by a;
-insert into pr_t select number % 1000, number % 1000 from numbers_mt(1e6);
-create table dist_pr_t as pr_t engine = Distributed(test_cluster_one_shard_three_replicas_localhost, currentDatabase(), pr_t);
+select count() from pr_t;
 
 -- { echoOn } --
-explain pipeline select a from dist_pr_t group by a order by a limit 5 offset 500;
+explain pipeline select a from pr_t group by a order by a limit 5 offset 500;
 
-select a, count() from dist_pr_t group by a order by a limit 5 offset 500;
-select a, count() from dist_pr_t group by a, b order by a limit 5 offset 500;
+select a, count() from pr_t group by a order by a limit 5 offset 500;
+select a, count() from pr_t group by a, b order by a limit 5 offset 500;
 
 -- { echoOff } --
 
-drop table pr_t;
-drop table dist_pr_t;
-drop table dist_t_different_dbs;
-drop table shard_1.t_different_dbs;
-drop table t_different_dbs;
-drop table dist_t;
-drop table t;
+drop table if exists pr_t;
+drop table if exists dist_t_different_dbs;
+drop table if exists shard_1.t_different_dbs;
+drop table if exists t_different_dbs;
+drop table if exists dist_t;
+drop table if exists t;
diff --git a/tests/queries/1_stateful/00009_uniq_distributed.sql b/tests/queries/1_stateful/00009_uniq_distributed.sql
index f78604fd401c..352514cd059c 100644
--- a/tests/queries/1_stateful/00009_uniq_distributed.sql
+++ b/tests/queries/1_stateful/00009_uniq_distributed.sql
@@ -1,3 +1,4 @@
 -- Tags: distributed
 
+
 SELECT uniq(UserID), uniqIf(UserID, CounterID = 800784), uniqIf(FUniqID, RegionID = 213) FROM remote('127.0.0.{1,2}', test, hits)
diff --git a/tests/queries/1_stateful/00012_sorting_distributed.sql b/tests/queries/1_stateful/00012_sorting_distributed.sql
index 2f852af1dba3..afbaf89d9ae8 100644
--- a/tests/queries/1_stateful/00012_sorting_distributed.sql
+++ b/tests/queries/1_stateful/00012_sorting_distributed.sql
@@ -1,3 +1,4 @@
 -- Tags: distributed
 
+
 SELECT EventTime::DateTime('Asia/Dubai') FROM remote('127.0.0.{1,2}', test, hits) ORDER BY EventTime DESC LIMIT 10
diff --git a/tests/queries/1_stateful/00013_sorting_of_nested.sql b/tests/queries/1_stateful/00013_sorting_of_nested.sql
index 44f7684d7469..f97120e2b981 100644
--- a/tests/queries/1_stateful/00013_sorting_of_nested.sql
+++ b/tests/queries/1_stateful/00013_sorting_of_nested.sql
@@ -1,2 +1,4 @@
+-- Tags: no-parallel-replicas
+
 SELECT ParsedParams.Key1 FROM test.visits FINAL WHERE VisitID != 0 AND notEmpty(ParsedParams.Key1) ORDER BY VisitID LIMIT 10
 
diff --git a/tests/queries/1_stateful/00016_any_if_distributed_cond_always_false.sql b/tests/queries/1_stateful/00016_any_if_distributed_cond_always_false.sql
index 2afe28639f26..50a3402244e8 100644
--- a/tests/queries/1_stateful/00016_any_if_distributed_cond_always_false.sql
+++ b/tests/queries/1_stateful/00016_any_if_distributed_cond_always_false.sql
@@ -1,3 +1,4 @@
 -- Tags: distributed
 
+
 SELECT anyIf(SearchPhrase, CounterID = -1) FROM remote('127.0.0.{1,2}:9000', test, hits)
diff --git a/tests/queries/1_stateful/00022_merge_prewhere.sql b/tests/queries/1_stateful/00022_merge_prewhere.sql
index 74a3677b68eb..400a896d5a87 100644
--- a/tests/queries/1_stateful/00022_merge_prewhere.sql
+++ b/tests/queries/1_stateful/00022_merge_prewhere.sql
@@ -1,3 +1,5 @@
+-- Tags: no-parallel-replicas
+
 DROP TABLE IF EXISTS test.merge_hits;
 CREATE TABLE IF NOT EXISTS test.merge_hits AS test.hits ENGINE = Merge(test, '^hits$');
 SELECT count() FROM test.merge_hits WHERE AdvEngineID = 2;
diff --git a/tests/queries/1_stateful/00042_any_left_join.sql b/tests/queries/1_stateful/00042_any_left_join.sql
index b87cf88f0071..c7c0f0f987a6 100644
--- a/tests/queries/1_stateful/00042_any_left_join.sql
+++ b/tests/queries/1_stateful/00042_any_left_join.sql
@@ -1,3 +1,5 @@
+-- Tags: no-parallel-replicas
+
 SELECT
     EventDate,
     hits,
diff --git a/tests/queries/1_stateful/00043_any_left_join.sql b/tests/queries/1_stateful/00043_any_left_join.sql
index 704d38f727a8..6b8cce540515 100644
--- a/tests/queries/1_stateful/00043_any_left_join.sql
+++ b/tests/queries/1_stateful/00043_any_left_join.sql
@@ -1,3 +1,5 @@
+-- Tags: no-parallel-replicas
+
 SELECT
     EventDate,
     count() AS hits,
diff --git a/tests/queries/1_stateful/00044_any_left_join_string.sql b/tests/queries/1_stateful/00044_any_left_join_string.sql
index a4f2e9e1b964..ceb7a1c1783f 100644
--- a/tests/queries/1_stateful/00044_any_left_join_string.sql
+++ b/tests/queries/1_stateful/00044_any_left_join_string.sql
@@ -1,3 +1,5 @@
+-- Tags: no-parallel-replicas
+
 SELECT
     domain,
     hits,
diff --git a/tests/queries/1_stateful/00063_loyalty_joins.sql b/tests/queries/1_stateful/00063_loyalty_joins.sql
index 1e7011ea9099..44f0767a87a0 100644
--- a/tests/queries/1_stateful/00063_loyalty_joins.sql
+++ b/tests/queries/1_stateful/00063_loyalty_joins.sql
@@ -1,15 +1,17 @@
+-- Tags: no-parallel-replicas
+
 SET any_join_distinct_right_table_keys = 1;
 SET joined_subquery_requires_alias = 0;
 
 SELECT
-    loyalty, 
+    loyalty,
     count()
-FROM test.hits ANY LEFT JOIN 
+FROM test.hits ANY LEFT JOIN
 (
     SELECT
-        UserID, 
-        sum(SearchEngineID = 2) AS yandex, 
-        sum(SearchEngineID = 3) AS google, 
+        UserID,
+        sum(SearchEngineID = 2) AS yandex,
+        sum(SearchEngineID = 3) AS google,
         toInt8(if(yandex > google, yandex / (yandex + google), -google / (yandex + google)) * 10) AS loyalty
     FROM test.hits
     WHERE (SearchEngineID = 2) OR (SearchEngineID = 3)
@@ -21,18 +23,18 @@ ORDER BY loyalty ASC;
 
 
 SELECT
-    loyalty, 
+    loyalty,
     count()
 FROM
 (
     SELECT UserID
     FROM test.hits
-) ANY LEFT JOIN 
+) ANY LEFT JOIN
 (
     SELECT
-        UserID, 
-        sum(SearchEngineID = 2) AS yandex, 
-        sum(SearchEngineID = 3) AS google, 
+        UserID,
+        sum(SearchEngineID = 2) AS yandex,
+        sum(SearchEngineID = 3) AS google,
         toInt8(if(yandex > google, yandex / (yandex + google), -google / (yandex + google)) * 10) AS loyalty
     FROM test.hits
     WHERE (SearchEngineID = 2) OR (SearchEngineID = 3)
@@ -44,23 +46,23 @@ ORDER BY loyalty ASC;
 
 
 SELECT
-    loyalty, 
+    loyalty,
     count()
 FROM
 (
     SELECT
-        loyalty, 
+        loyalty,
         UserID
     FROM
     (
         SELECT UserID
         FROM test.hits
-    ) ANY LEFT JOIN 
+    ) ANY LEFT JOIN
     (
         SELECT
-            UserID, 
-            sum(SearchEngineID = 2) AS yandex, 
-            sum(SearchEngineID = 3) AS google, 
+            UserID,
+            sum(SearchEngineID = 2) AS yandex,
+            sum(SearchEngineID = 3) AS google,
             toInt8(if(yandex > google, yandex / (yandex + google), -google / (yandex + google)) * 10) AS loyalty
         FROM test.hits
         WHERE (SearchEngineID = 2) OR (SearchEngineID = 3)
@@ -73,19 +75,19 @@ ORDER BY loyalty ASC;
 
 
 SELECT
-    loyalty, 
-    count() AS c, 
+    loyalty,
+    count() AS c,
     bar(log(c + 1) * 1000, 0, log(3000000) * 1000, 80)
-FROM test.hits ANY INNER JOIN 
+FROM test.hits ANY INNER JOIN
 (
     SELECT
-        UserID, 
+        UserID,
         toInt8(if(yandex > google, yandex / (yandex + google), -google / (yandex + google)) * 10) AS loyalty
     FROM
     (
         SELECT
-            UserID, 
-            sum(SearchEngineID = 2) AS yandex, 
+            UserID,
+            sum(SearchEngineID = 2) AS yandex,
             sum(SearchEngineID = 3) AS google
         FROM test.hits
         WHERE (SearchEngineID = 2) OR (SearchEngineID = 3)
diff --git a/tests/queries/1_stateful/00065_loyalty_with_storage_join.sql b/tests/queries/1_stateful/00065_loyalty_with_storage_join.sql
index 515a24105830..35f0c7b60b94 100644
--- a/tests/queries/1_stateful/00065_loyalty_with_storage_join.sql
+++ b/tests/queries/1_stateful/00065_loyalty_with_storage_join.sql
@@ -1,3 +1,5 @@
+-- Tags: no-parallel-replicas
+
 USE test;
 
 DROP TABLE IF EXISTS join;
@@ -7,7 +9,7 @@ INSERT INTO join
 SELECT
     UserID,
     toInt8(if((sum(SearchEngineID = 2) AS yandex) > (sum(SearchEngineID = 3) AS google),
-    yandex / (yandex + google), 
+    yandex / (yandex + google),
     -google / (yandex + google)) * 10) AS loyalty
 FROM hits
 WHERE (SearchEngineID = 2) OR (SearchEngineID = 3)
diff --git a/tests/queries/1_stateful/00066_sorting_distributed_many_replicas.sql b/tests/queries/1_stateful/00066_sorting_distributed_many_replicas.sql
index c7a34c493c9d..c60e342dd414 100644
--- a/tests/queries/1_stateful/00066_sorting_distributed_many_replicas.sql
+++ b/tests/queries/1_stateful/00066_sorting_distributed_many_replicas.sql
@@ -1,4 +1,5 @@
 -- Tags: replica, distributed, no-random-settings
 
+
 SET max_parallel_replicas = 2;
 SELECT EventTime::DateTime('Asia/Dubai') FROM remote('127.0.0.{1|2}', test, hits) ORDER BY EventTime DESC LIMIT 10
diff --git a/tests/queries/1_stateful/00074_full_join.sql b/tests/queries/1_stateful/00074_full_join.sql
index f049be2a74d4..c1d9e4be1a4f 100644
--- a/tests/queries/1_stateful/00074_full_join.sql
+++ b/tests/queries/1_stateful/00074_full_join.sql
@@ -1,3 +1,5 @@
+-- Tags: no-parallel-replicas
+
 set any_join_distinct_right_table_keys = 1;
 set joined_subquery_requires_alias = 0;
 
diff --git a/tests/queries/1_stateful/00075_left_array_join.sql b/tests/queries/1_stateful/00075_left_array_join.sql
index 1fd045a26bf6..3540d7911573 100644
--- a/tests/queries/1_stateful/00075_left_array_join.sql
+++ b/tests/queries/1_stateful/00075_left_array_join.sql
@@ -1,2 +1,4 @@
+-- Tags: no-parallel-replicas
+
 SELECT UserID, EventTime::DateTime('Asia/Dubai'), pp.Key1, pp.Key2, ParsedParams.Key1 FROM test.hits ARRAY JOIN ParsedParams AS pp WHERE CounterID = 1704509 ORDER BY UserID, EventTime, pp.Key1, pp.Key2 LIMIT 100;
 SELECT UserID, EventTime::DateTime('Asia/Dubai'), pp.Key1, pp.Key2, ParsedParams.Key1 FROM test.hits LEFT ARRAY JOIN ParsedParams AS pp WHERE CounterID = 1704509 ORDER BY UserID, EventTime, pp.Key1, pp.Key2 LIMIT 100;
diff --git a/tests/queries/1_stateful/00079_array_join_not_used_joined_column.sql b/tests/queries/1_stateful/00079_array_join_not_used_joined_column.sql
index 8e6742bb1e17..9431e1cf5963 100644
--- a/tests/queries/1_stateful/00079_array_join_not_used_joined_column.sql
+++ b/tests/queries/1_stateful/00079_array_join_not_used_joined_column.sql
@@ -1,3 +1,5 @@
+-- Tags: no-parallel-replicas
+
 SELECT PP.Key1 AS `ym:s:paramsLevel1`, sum(arrayAll(`x_1` -> `x_1`= '', ParsedParams.Key2)) AS `ym:s:visits` FROM test.hits ARRAY JOIN ParsedParams AS `PP`  WHERE CounterID = 1704509 GROUP BY `ym:s:paramsLevel1` ORDER BY PP.Key1, `ym:s:visits` LIMIT 0, 100;
 SELECT PP.Key1 AS x1, ParsedParams.Key2 AS x2 FROM test.hits ARRAY JOIN ParsedParams AS PP WHERE CounterID = 1704509 ORDER BY x1, x2 LIMIT 10;
 SELECT ParsedParams.Key2 AS x FROM test.hits ARRAY JOIN ParsedParams AS PP ORDER BY x DESC LIMIT 10;
diff --git a/tests/queries/1_stateful/00080_array_join_and_union.sql b/tests/queries/1_stateful/00080_array_join_and_union.sql
index d9aa1cc17cc4..2f2e5e9324fa 100644
--- a/tests/queries/1_stateful/00080_array_join_and_union.sql
+++ b/tests/queries/1_stateful/00080_array_join_and_union.sql
@@ -1,1 +1,3 @@
+-- Tags: no-parallel-replicas
+
 SELECT count() FROM (SELECT Goals.ID FROM test.visits ARRAY JOIN Goals WHERE CounterID = 842440 LIMIT 10 UNION ALL SELECT Goals.ID FROM test.visits ARRAY JOIN Goals WHERE CounterID = 842440 LIMIT 10);
diff --git a/tests/queries/1_stateful/00084_external_aggregation.sql b/tests/queries/1_stateful/00084_external_aggregation.sql
index 816d95f4b8b3..330aa158cf75 100644
--- a/tests/queries/1_stateful/00084_external_aggregation.sql
+++ b/tests/queries/1_stateful/00084_external_aggregation.sql
@@ -1,4 +1,4 @@
--- Tags: no-random-settings
+-- Tags: no-random-settings, no-parallel-replicas
 
 SET max_bytes_before_external_group_by = 200000000;
 
diff --git a/tests/queries/1_stateful/00091_prewhere_two_conditions.sql b/tests/queries/1_stateful/00091_prewhere_two_conditions.sql
index 1e476d3a27dc..745bb125c2bd 100644
--- a/tests/queries/1_stateful/00091_prewhere_two_conditions.sql
+++ b/tests/queries/1_stateful/00091_prewhere_two_conditions.sql
@@ -1,3 +1,6 @@
+-- Tags: no-parallel-replicas
+-- Requires investigation (max_bytes_to_read is not respected)
+
 SET max_bytes_to_read = 600000000;
 
 SET optimize_move_to_prewhere = 1;
diff --git a/tests/queries/1_stateful/00092_obfuscator.sh b/tests/queries/1_stateful/00092_obfuscator.sh
index 85f476c6ae5c..f19473f01ac1 100755
--- a/tests/queries/1_stateful/00092_obfuscator.sh
+++ b/tests/queries/1_stateful/00092_obfuscator.sh
@@ -1,4 +1,6 @@
 #!/usr/bin/env bash
+# Tags: no-parallel-replicas
+# clickhouse-local may not work with parallel replicas
 
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # shellcheck source=../shell_config.sh
diff --git a/tests/queries/1_stateful/00096_obfuscator_save_load.sh b/tests/queries/1_stateful/00096_obfuscator_save_load.sh
index a88dfcdb9b9a..1bb212e1bbae 100755
--- a/tests/queries/1_stateful/00096_obfuscator_save_load.sh
+++ b/tests/queries/1_stateful/00096_obfuscator_save_load.sh
@@ -1,4 +1,6 @@
 #!/usr/bin/env bash
+# Tags: no-parallel-replicas
+# clickhouse-local may not work with parallel replicas
 
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # shellcheck source=../shell_config.sh
diff --git a/tests/queries/1_stateful/00146_aggregate_function_uniq.sql b/tests/queries/1_stateful/00146_aggregate_function_uniq.sql
index fd3fde7636d8..2cab6e70d22a 100644
--- a/tests/queries/1_stateful/00146_aggregate_function_uniq.sql
+++ b/tests/queries/1_stateful/00146_aggregate_function_uniq.sql
@@ -1,3 +1,5 @@
+-- Tags: no-parallel-replicas
+
 SELECT RegionID, uniqHLL12(WatchID) AS X FROM remote('127.0.0.{1,2}', test, hits) GROUP BY RegionID HAVING X > 100000 ORDER BY RegionID ASC;
 SELECT RegionID, uniqCombined(WatchID) AS X FROM remote('127.0.0.{1,2}', test, hits) GROUP BY RegionID HAVING X > 100000 ORDER BY RegionID ASC;
 SELECT abs(uniq(WatchID) - uniqExact(WatchID)) FROM test.hits;
diff --git a/tests/queries/1_stateful/00149_quantiles_timing_distributed.sql b/tests/queries/1_stateful/00149_quantiles_timing_distributed.sql
index 6f910646fb7b..5d2476226bae 100644
--- a/tests/queries/1_stateful/00149_quantiles_timing_distributed.sql
+++ b/tests/queries/1_stateful/00149_quantiles_timing_distributed.sql
@@ -1,4 +1,4 @@
--- Tags: distributed
+-- Tags: distributed, no-parallel-replicas
 
 SELECT sum(cityHash64(*)) FROM (SELECT CounterID, quantileTiming(0.5)(SendTiming), count() FROM remote('127.0.0.{1,2,3,4,5,6,7,8,9,10}', test.hits) WHERE SendTiming != -1 GROUP BY CounterID);
 SELECT sum(cityHash64(*)) FROM (SELECT CounterID, quantileTiming(0.5)(SendTiming), count() FROM remote('127.0.0.{1,2,3,4,5,6,7,8,9,10}', test.hits) WHERE SendTiming != -1 GROUP BY CounterID) SETTINGS optimize_aggregation_in_order = 1;
diff --git a/tests/queries/1_stateful/00152_insert_different_granularity.sql b/tests/queries/1_stateful/00152_insert_different_granularity.sql
index 294d71b384ba..354831494983 100644
--- a/tests/queries/1_stateful/00152_insert_different_granularity.sql
+++ b/tests/queries/1_stateful/00152_insert_different_granularity.sql
@@ -1,4 +1,4 @@
--- Tags: no-tsan, no-replicated-database, no-parallel
+-- Tags: no-tsan, no-replicated-database, no-parallel, no-parallel-replicas
 -- Tag no-replicated-database: Fails due to additional replicas or shards
 
 DROP TABLE IF EXISTS fixed_granularity_table;
diff --git a/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql b/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql
index e325c18200b5..32079111f6ce 100644
--- a/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql
+++ b/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql
@@ -1,3 +1,6 @@
+-- Tags: no-parallel-replicas
+-- Merge tables doesn't work with parallel replicas currently
+
 SET max_execution_speed = 4000000, timeout_before_checking_execution_speed = 0;
 
 CREATE TEMPORARY TABLE times (t DateTime);
diff --git a/tests/queries/1_stateful/00166_explain_estimate.sql b/tests/queries/1_stateful/00166_explain_estimate.sql
index c40712717363..abac92ecb2e2 100644
--- a/tests/queries/1_stateful/00166_explain_estimate.sql
+++ b/tests/queries/1_stateful/00166_explain_estimate.sql
@@ -1,4 +1,4 @@
--- Tags: no-replicated-database
+-- Tags: no-replicated-database, no-parallel-replicas
 -- Tag no-replicated-database: Requires investigation
 
 EXPLAIN ESTIMATE SELECT count() FROM test.hits WHERE CounterID = 29103473;
diff --git a/tests/queries/1_stateful/00170_s3_cache.sql b/tests/queries/1_stateful/00170_s3_cache.sql
index b03b2a16bf09..815922554287 100644
--- a/tests/queries/1_stateful/00170_s3_cache.sql
+++ b/tests/queries/1_stateful/00170_s3_cache.sql
@@ -1,4 +1,4 @@
--- Tags: no-parallel, no-random-settings
+-- Tags: no-parallel, no-random-settings, no-parallel-replicas
 
 -- { echo }
 
diff --git a/tests/queries/1_stateful/00171_grouping_aggregated_transform_bug.sql b/tests/queries/1_stateful/00171_grouping_aggregated_transform_bug.sql
index 7068780a1b1c..07788af927e0 100644
--- a/tests/queries/1_stateful/00171_grouping_aggregated_transform_bug.sql
+++ b/tests/queries/1_stateful/00171_grouping_aggregated_transform_bug.sql
@@ -1,4 +1,4 @@
--- Tags: distributed
+-- Tags: distributed, no-parallel-replicas
 
 SELECT sum(cityHash64(*)) FROM (SELECT CounterID, quantileTiming(0.5)(SendTiming), count() FROM remote('127.0.0.{1,2,3,4,5,6,7,8,9,10}', test.hits) WHERE SendTiming != -1 GROUP BY CounterID) SETTINGS max_block_size = 63169;
 SELECT sum(cityHash64(*)) FROM (SELECT CounterID, quantileTiming(0.5)(SendTiming), count() FROM remote('127.0.0.{1,2,3,4,5,6,7,8,9,10}', test.hits) WHERE SendTiming != -1 GROUP BY CounterID) SETTINGS optimize_aggregation_in_order = 1, max_block_size = 63169;
diff --git a/tests/queries/1_stateful/00172_early_constant_folding.sql b/tests/queries/1_stateful/00172_early_constant_folding.sql
index cc3d2274ecde..b31e418b4926 100644
--- a/tests/queries/1_stateful/00172_early_constant_folding.sql
+++ b/tests/queries/1_stateful/00172_early_constant_folding.sql
@@ -1,1 +1,3 @@
+-- Tags: no-parallel-replicas
+
 EXPLAIN PIPELINE SELECT count(JavaEnable) FROM test.hits WHERE WatchID = 1 OR Title = 'next' OR URL = 'prev' OR URL = '???' OR 1;
diff --git a/tests/queries/1_stateful/00172_hits_joins.sql.j2 b/tests/queries/1_stateful/00172_hits_joins.sql.j2
index 4599d1d5a5d1..4617fe5aef84 100644
--- a/tests/queries/1_stateful/00172_hits_joins.sql.j2
+++ b/tests/queries/1_stateful/00172_hits_joins.sql.j2
@@ -1,3 +1,4 @@
+-- Tags: no-parallel-replicas
 {% for join_algorithm in ['hash', 'parallel_hash', 'full_sorting_merge', 'grace_hash'] -%}
 
 SET max_rows_in_join = '{% if join_algorithm == 'grace_hash' %}10K{% else %}0{% endif %}';
diff --git a/tests/queries/1_stateful/00175_obfuscator_schema_inference.sh b/tests/queries/1_stateful/00175_obfuscator_schema_inference.sh
index 771c7ab54361..0b308c650610 100755
--- a/tests/queries/1_stateful/00175_obfuscator_schema_inference.sh
+++ b/tests/queries/1_stateful/00175_obfuscator_schema_inference.sh
@@ -1,4 +1,5 @@
 #!/usr/bin/env bash
+# Tags: no-parallel-replicas
 
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # shellcheck source=../shell_config.sh
