{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 31826,
  "instance_id": "ClickHouse__ClickHouse-31826",
  "issue_numbers": [
    "31449"
  ],
  "base_commit": "55b9724fe7d78e0bd6ddcb334b2609f93227d2af",
  "patch": "diff --git a/src/Compression/CachedCompressedReadBuffer.cpp b/src/Compression/CachedCompressedReadBuffer.cpp\nindex c19e854dd454..f942f81f5e92 100644\n--- a/src/Compression/CachedCompressedReadBuffer.cpp\n+++ b/src/Compression/CachedCompressedReadBuffer.cpp\n@@ -87,7 +87,7 @@ CachedCompressedReadBuffer::CachedCompressedReadBuffer(\n void CachedCompressedReadBuffer::seek(size_t offset_in_compressed_file, size_t offset_in_decompressed_block)\n {\n     /// Nothing to do if we already at required position\n-    if (file_pos == offset_in_compressed_file\n+    if (!owned_cell && file_pos == offset_in_compressed_file\n         && (offset() == offset_in_decompressed_block ||\n             nextimpl_working_buffer_offset == offset_in_decompressed_block))\n         return;\n@@ -106,6 +106,8 @@ void CachedCompressedReadBuffer::seek(size_t offset_in_compressed_file, size_t o\n         bytes += offset();\n         /// No data, everything discarded\n         pos = working_buffer.end();\n+        owned_cell.reset();\n+\n         /// Remember required offset in decompressed block which will be set in\n         /// the next ReadBuffer::next() call\n         nextimpl_working_buffer_offset = offset_in_decompressed_block;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02124_uncompressed_cache.reference b/tests/queries/0_stateless/02124_uncompressed_cache.reference\nnew file mode 100644\nindex 000000000000..79957a23f0b8\n--- /dev/null\n+++ b/tests/queries/0_stateless/02124_uncompressed_cache.reference\n@@ -0,0 +1,2 @@\n+105\t3\n+105\t3\ndiff --git a/tests/queries/0_stateless/02124_uncompressed_cache.sql b/tests/queries/0_stateless/02124_uncompressed_cache.sql\nnew file mode 100644\nindex 000000000000..60b616b456a1\n--- /dev/null\n+++ b/tests/queries/0_stateless/02124_uncompressed_cache.sql\n@@ -0,0 +1,16 @@\n+DROP TABLE IF EXISTS t_uncompressed_cache;\n+\n+CREATE TABLE t_uncompressed_cache(id UInt32, n UInt32)\n+ENGINE = MergeTree ORDER BY tuple()\n+SETTINGS min_bytes_for_wide_part = 0,\n+min_compress_block_size = 12, max_compress_block_size = 12,\n+index_granularity = 4;\n+\n+INSERT INTO t_uncompressed_cache SELECT number, number FROM numbers(200);\n+\n+SET max_threads = 1;\n+\n+SELECT sum(n), count() FROM t_uncompressed_cache PREWHERE id = 0 OR id = 5 OR id = 100 SETTINGS use_uncompressed_cache = 0;\n+SELECT sum(n), count() FROM t_uncompressed_cache PREWHERE id = 0 OR id = 5 OR id = 100 SETTINGS use_uncompressed_cache = 1;\n+\n+DROP TABLE t_uncompressed_cache;\n",
  "problem_statement": "query does not return the expected results but mixing columns\n### Context\r\nA computed W2V dataset is created and inserted into ClickHouse using these operations and to reproduce this issue included a copy of the dataset\r\n```SQL\r\n-- cat vectors/part* | clickhouse-client -h localhost --query=\"insert into ot.ml_w2v_log format JSONEachRow \"\r\ncreate database if not exists ot;\r\ncreate table if not exists ot.ml_w2v_log\r\n(\r\n    category String,\r\n    word   String,\r\n    norm    Float64,\r\n    vector Array(Float64)\r\n) engine = Log;\r\n\r\ncreate table if not exists ot.ml_w2v\r\n    engine = MergeTree()\r\n        order by (word)\r\n        primary key (word)\r\nas\r\nselect category,\r\n       word,\r\n       norm,\r\n       vector\r\nfrom (select category, word, norm, vector from ot.ml_w2v_log);\r\n```\r\nThe used query to get the top words from some category is\r\n```SQL\r\nWITH (\r\n    SELECT sumForEach(vector)\r\n    FROM ot.ml_w2v\r\n    PREWHERE (in(word,('CHEMBL1737')))\r\n    ) AS vv,\r\n     sqrt(arraySum(x -> x*x,vv)) AS vvnorm,\r\n     if(and(notEquals(vvnorm,0.0),notEquals(norm,0.0)),divide(arraySum(x -> x.1 * x.2,arrayZip(vv,vector)),multiply(norm,vvnorm)),0.0) AS similarity\r\nSELECT category, word, similarity\r\nFROM ot.ml_w2v\r\n    PREWHERE (in(category,('disease')))\r\nWHERE (greaterOrEquals(similarity,0.1))\r\nORDER BY similarity DESC\r\nLIMIT 10 OFFSET 0;\r\n```\r\nThe expected output is a list of `>= 0` elements coming just from category `disease`. In the last release, it gets words from a category that does not belong to.\r\n\r\noutput with versions\r\n```\r\nClickHouse client version 21.9.4.35 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 21.9.4 revision 54449.\r\n```\r\n```SQL\r\nWITH\r\n    (\r\n        SELECT sumForEach(vector)\r\n        FROM ot.ml_w2v\r\n        PREWHERE word IN ('CHEMBL1737')\r\n    ) AS vv,\r\n    sqrt(arraySum(x -> (x * x), vv)) AS vvnorm,\r\n    if((vvnorm != 0.) AND (norm != 0.), arraySum(x -> ((x.1) * (x.2)), arrayZip(vv, vector)) / (norm * vvnorm), 0.) AS similarity\r\nSELECT\r\n    category,\r\n    word,\r\n    similarity\r\nFROM ot.ml_w2v\r\nPREWHERE category IN ('disease')\r\nWHERE similarity >= 0.1\r\nORDER BY similarity DESC\r\nLIMIT 0, 10\r\n\r\nQuery id: a4fbcdab-0bd7-4cdd-816f-fc5508154f25\r\n\r\n\u250c\u2500category\u2500\u252c\u2500word\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500similarity\u2500\u2510\r\n\u2502 disease  \u2502 EFO_0004234     \u2502 0.7696740602266341 \u2502\r\n\u2502 disease  \u2502 EFO_1000466     \u2502 0.6860139858343028 \u2502\r\n\u2502 disease  \u2502 MONDO_0001999   \u2502 0.6183489436097988 \u2502\r\n\u2502 disease  \u2502 HP_0001667      \u2502 0.6032877790181791 \u2502\r\n\u2502 disease  \u2502 EFO_0009085     \u2502 0.5989707188199231 \u2502\r\n\u2502 disease  \u2502 Orphanet_156629 \u2502 0.5800397436624738 \u2502\r\n\u2502 disease  \u2502 EFO_0009196     \u2502  0.579683404421804 \u2502\r\n\u2502 disease  \u2502 EFO_0001361     \u2502   0.56757779832079 \u2502\r\n\u2502 disease  \u2502 HP_0200023      \u2502  0.565599936638102 \u2502\r\n\u2502 disease  \u2502 MONDO_0001574   \u2502 0.5552950663929026 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n10 rows in set. Elapsed: 0.029 sec. Processed 47.47 thousand rows, 19.90 MB (1.66 million rows/s., 694.93 MB/s.)\r\n```\r\nand this output is expected. But when the same query is executed against the latest version\r\n```\r\nClickHouse client version 21.11.3.6 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 21.11.3 revision 54450.\r\n```\r\n```SQL\r\n\r\nWITH\r\n    (\r\n        SELECT sumForEach(vector)\r\n        FROM ot.ml_w2v\r\n        PREWHERE word IN ('CHEMBL1737')\r\n    ) AS vv,\r\n    sqrt(arraySum(x -> (x * x), vv)) AS vvnorm,\r\n    if((vvnorm != 0.) AND (norm != 0.), arraySum(x -> ((x.1) * (x.2)), arrayZip(vv, vector)) / (norm * vvnorm), 0.) AS similarity\r\nSELECT\r\n    category,\r\n    word,\r\n    similarity\r\nFROM ot.ml_w2v\r\nPREWHERE category IN ('disease')\r\nWHERE similarity >= 0.1\r\nORDER BY similarity DESC\r\nLIMIT 0, 10\r\n\r\nQuery id: 707cefb6-1c3b-427f-85ac-44a813020bab\r\n\r\n\u250c\u2500category\u2500\u252c\u2500word\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500similarity\u2500\u2510\r\n\u2502 disease  \u2502 CHEMBL2110641 \u2502 12.066153256687638 \u2502\r\n\u2502 disease  \u2502 CHEMBL1887891 \u2502  8.441367361572434 \u2502\r\n\u2502 disease  \u2502 CHEMBL219376  \u2502   8.42932989841403 \u2502\r\n\u2502 disease  \u2502 CHEMBL2108401 \u2502  6.813855928884503 \u2502\r\n\u2502 disease  \u2502 CHEMBL1927030 \u2502   5.82952056420569 \u2502\r\n\u2502 disease  \u2502 CHEMBL1464    \u2502  5.501304739078533 \u2502\r\n\u2502 disease  \u2502 CHEMBL2107880 \u2502  5.351481348458378 \u2502\r\n\u2502 disease  \u2502 CHEMBL2103836 \u2502  5.082651728915573 \u2502\r\n\u2502 disease  \u2502 CHEMBL2219640 \u2502  4.849979327914108 \u2502\r\n\u2502 disease  \u2502 CHEMBL1644695 \u2502 4.6276729651167345 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n10 rows in set. Elapsed: 0.027 sec. Processed 47.13 thousand rows, 19.61 MB (1.75 million rows/s., 728.89 MB/s.)\r\n```\r\nthis output is not expected as there is no word starting with `CHEMBL` in the category `disease`. I guess the way the similarity comes is by not computing it correctly. Might it be the way to take the vector from the query in the WITH section either?\r\n\r\n\n",
  "hints_text": "Please [find here the link](http://ftp.ebi.ac.uk/pub/databases/opentargets/platform/latest/output/literature/parquet/vectors/) to the dataset to reproduce the issue.\nI've downloaded the dataset by your link and couldn't reproduce this bug on 21.11.3 and on master. Do you have any non-default settings set? You can check it by queries: \r\n```sql \r\nSELECT name, value FROM system.settings WHERE changed;\r\n\r\nSELECT name, value FROM system.merge_tree_settings WHERE changed;\r\n```\n@CurtizJ thank you for giving a closer look at it. Here is the result of your suggested queries\r\n\r\n```SQL\r\nSELECT\r\n    name,\r\n    value\r\nFROM system.settings\r\nWHERE changed\r\n\r\nQuery id: 89268c01-1be7-4994-a446-08b65bd4a5a5\r\n\r\n\u250c\u2500name\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500value\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 max_query_size                     \u2502 1048576     \u2502\r\n\u2502 use_uncompressed_cache             \u2502 1           \u2502\r\n\u2502 load_balancing                     \u2502 random      \u2502\r\n\u2502 max_bytes_before_external_group_by \u2502 20000000000 \u2502\r\n\u2502 max_bytes_before_external_sort     \u2502 20000000000 \u2502\r\n\u2502 max_memory_usage                   \u2502 30000000000 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\nAnd for the second one\r\n```SQL\r\nSELECT\r\n    name,\r\n    value\r\nFROM system.merge_tree_settings\r\nWHERE changed\r\n\r\nQuery id: cf1bfee7-1241-42b1-aa49-8c0fa2cea658\r\n\r\nOk.\r\n```\nThanks. I found that issue is in uncompressed cache. You can disable `use_uncompressed_cache` until fix will be ready.\n@CurtizJ thank you very much! We will do it (@cmalangone).",
  "created_at": "2021-11-25T18:22:10Z",
  "modified_files": [
    "src/Compression/CachedCompressedReadBuffer.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02124_uncompressed_cache.reference",
    "b/tests/queries/0_stateless/02124_uncompressed_cache.sql"
  ]
}