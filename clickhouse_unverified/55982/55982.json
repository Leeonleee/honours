{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 55982,
  "instance_id": "ClickHouse__ClickHouse-55982",
  "issue_numbers": [
    "49293"
  ],
  "base_commit": "010cc6918acb81bfaa9b2839fa022f14c05e549b",
  "patch": "diff --git a/docs/en/interfaces/formats.md b/docs/en/interfaces/formats.md\nindex e98f19b2a65d..0e7bbcf4b1be 100644\n--- a/docs/en/interfaces/formats.md\n+++ b/docs/en/interfaces/formats.md\n@@ -74,6 +74,7 @@ The supported formats are:\n | [ArrowStream](#data-format-arrow-stream)                                                  | \u2714    | \u2714     |\n | [ORC](#data-format-orc)                                                                   | \u2714    | \u2714     |\n | [One](#data-format-one)                                                                   | \u2714    | \u2717     |\n+| [Npy](#data-format-npy)                                                                   | \u2714    | \u2717     |\n | [RowBinary](#rowbinary)                                                                   | \u2714    | \u2714     |\n | [RowBinaryWithNames](#rowbinarywithnamesandtypes)                                         | \u2714    | \u2714     |\n | [RowBinaryWithNamesAndTypes](#rowbinarywithnamesandtypes)                                 | \u2714    | \u2714     |\n@@ -2445,6 +2446,50 @@ Result:\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n ```\n \n+## Npy {#data-format-npy}\n+\n+This function is designed to load a NumPy array from a .npy file into ClickHouse. The NumPy file format is a binary format used for efficiently storing arrays of numerical data. During import, ClickHouse treats top level dimension as an array of rows with single column. Supported Npy data types and their corresponding type in ClickHouse: \n+| Npy type | ClickHouse type |\n+|:--------:|:---------------:|\n+| b1       |    UInt8        |\n+| i1       |    Int8         |\n+| i2       |    Int16        |\n+| i4       |    Int32        |\n+| i8       |    Int64        |\n+| u1       |    UInt8        |\n+| u2       |    UInt16       |\n+| u4       |    UInt32       |\n+| u8       |    UInt64       |\n+| f4       |    Float32      |\n+| f8       |    Float64      |\n+| S        |    String       |\n+| U        |    String       |\n+\n+**Example of saving an array in .npy format using Python**\n+\n+\n+```Python\n+import numpy as np\n+arr = np.array([[[1],[2],[3]],[[4],[5],[6]]])\n+np.save('example_array.npy', arr)\n+```\n+\n+**Example of reading a NumPy file in ClickHouse**\n+\n+Query:\n+```sql\n+SELECT *\n+FROM file('example_array.npy', Npy)\n+```\n+\n+Result:\n+```\n+\u250c\u2500array\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n+\u2502 [[1],[2],[3]] \u2502\n+\u2502 [[4],[5],[6]] \u2502\n+\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n+```\n+\n ## LineAsString {#lineasstring}\n \n In this format, every line of input data is interpreted as a single string value. This format can only be parsed for table with a single field of type [String](/docs/en/sql-reference/data-types/string.md). The remaining columns must be set to [DEFAULT](/docs/en/sql-reference/statements/create/table.md/#default) or [MATERIALIZED](/docs/en/sql-reference/statements/create/table.md/#materialized), or omitted.\ndiff --git a/src/Formats/NumpyDataTypes.h b/src/Formats/NumpyDataTypes.h\nnew file mode 100644\nindex 000000000000..43fd9064daea\n--- /dev/null\n+++ b/src/Formats/NumpyDataTypes.h\n@@ -0,0 +1,123 @@\n+#pragma once\n+#include <cstddef>\n+#include <Storages/NamedCollectionsHelpers.h>\n+\n+namespace ErrorCodes\n+{\n+    extern const int BAD_ARGUMENTS;\n+}\n+\n+enum class NumpyDataTypeIndex\n+{\n+    Int8,\n+    Int16,\n+    Int32,\n+    Int64,\n+    UInt8,\n+    UInt16,\n+    UInt32,\n+    UInt64,\n+    Float32,\n+    Float64,\n+    String,\n+    Unicode,\n+};\n+\n+class NumpyDataType\n+{\n+public:\n+    enum Endianness\n+    {\n+        LITTLE,\n+        BIG,\n+        NONE,\n+    };\n+    NumpyDataTypeIndex type_index;\n+\n+    explicit NumpyDataType(Endianness endianness_) : endianness(endianness_) {}\n+    virtual ~NumpyDataType() = default;\n+\n+    Endianness getEndianness() const { return endianness; }\n+\n+    virtual NumpyDataTypeIndex getTypeIndex() const = 0;\n+\n+private:\n+    Endianness endianness;\n+};\n+\n+class NumpyDataTypeInt : public NumpyDataType\n+{\n+public:\n+    NumpyDataTypeInt(Endianness endianness, size_t size_, bool is_signed_) : NumpyDataType(endianness), size(size_), is_signed(is_signed_)\n+    {\n+        switch (size)\n+        {\n+            case 1: type_index = is_signed ? NumpyDataTypeIndex::Int8 : NumpyDataTypeIndex::UInt8; break;\n+            case 2: type_index = is_signed ? NumpyDataTypeIndex::Int16 : NumpyDataTypeIndex::UInt16; break;\n+            case 4: type_index = is_signed ? NumpyDataTypeIndex::Int32 : NumpyDataTypeIndex::UInt32; break;\n+            case 8: type_index = is_signed ? NumpyDataTypeIndex::Int64 : NumpyDataTypeIndex::UInt64; break;\n+            default:\n+                throw DB::Exception(DB::ErrorCodes::BAD_ARGUMENTS, \"Incorrect int type with size {}\", size);\n+        }\n+    }\n+\n+    NumpyDataTypeIndex getTypeIndex() const override\n+    {\n+        return type_index;\n+    }\n+    bool isSigned() const { return is_signed; }\n+\n+private:\n+    size_t size;\n+    bool is_signed;\n+};\n+\n+class NumpyDataTypeFloat : public NumpyDataType\n+{\n+public:\n+    NumpyDataTypeFloat(Endianness endianness, size_t size_) : NumpyDataType(endianness), size(size_)\n+    {\n+        switch (size)\n+        {\n+            case 4: type_index = NumpyDataTypeIndex::Float32; break;\n+            case 8: type_index = NumpyDataTypeIndex::Float64; break;\n+            default:\n+                throw DB::Exception(DB::ErrorCodes::BAD_ARGUMENTS, \"Numpy float type with size {} is not supported\", size);\n+        }\n+    }\n+\n+    NumpyDataTypeIndex getTypeIndex() const override\n+    {\n+        return type_index;\n+    }\n+private:\n+    size_t size;\n+};\n+\n+class NumpyDataTypeString : public NumpyDataType\n+{\n+public:\n+    NumpyDataTypeString(Endianness endianness, size_t size_) : NumpyDataType(endianness), size(size_)\n+    {\n+        type_index = NumpyDataTypeIndex::String;\n+    }\n+\n+    NumpyDataTypeIndex getTypeIndex() const override { return type_index; }\n+    size_t getSize() const { return size; }\n+private:\n+    size_t size;\n+};\n+\n+class NumpyDataTypeUnicode : public NumpyDataType\n+{\n+public:\n+    NumpyDataTypeUnicode(Endianness endianness, size_t size_) : NumpyDataType(endianness), size(size_)\n+    {\n+        type_index = NumpyDataTypeIndex::Unicode;\n+    }\n+\n+    NumpyDataTypeIndex getTypeIndex() const override { return type_index; }\n+    size_t getSize() const { return size * 4; }\n+private:\n+    size_t size;\n+};\ndiff --git a/src/Formats/registerFormats.cpp b/src/Formats/registerFormats.cpp\nindex 580db61edde4..ba03390cbd51 100644\n--- a/src/Formats/registerFormats.cpp\n+++ b/src/Formats/registerFormats.cpp\n@@ -102,6 +102,7 @@ void registerInputFormatLineAsString(FormatFactory & factory);\n void registerInputFormatMySQLDump(FormatFactory & factory);\n void registerInputFormatParquetMetadata(FormatFactory & factory);\n void registerInputFormatOne(FormatFactory & factory);\n+void registerInputFormatNpy(FormatFactory & factory);\n \n #if USE_HIVE\n void registerInputFormatHiveText(FormatFactory & factory);\n@@ -144,6 +145,7 @@ void registerMySQLSchemaReader(FormatFactory & factory);\n void registerBSONEachRowSchemaReader(FormatFactory & factory);\n void registerParquetMetadataSchemaReader(FormatFactory & factory);\n void registerOneSchemaReader(FormatFactory & factory);\n+void registerNpySchemaReader(FormatFactory & factory);\n \n void registerFileExtensions(FormatFactory & factory);\n \n@@ -246,6 +248,7 @@ void registerFormats()\n \n     registerInputFormatParquetMetadata(factory);\n     registerInputFormatOne(factory);\n+    registerInputFormatNpy(factory);\n \n     registerNonTrivialPrefixAndSuffixCheckerJSONEachRow(factory);\n     registerNonTrivialPrefixAndSuffixCheckerJSONAsString(factory);\n@@ -283,6 +286,7 @@ void registerFormats()\n     registerBSONEachRowSchemaReader(factory);\n     registerParquetMetadataSchemaReader(factory);\n     registerOneSchemaReader(factory);\n+    registerNpySchemaReader(factory);\n }\n \n }\ndiff --git a/src/Processors/Formats/Impl/NpyRowInputFormat.cpp b/src/Processors/Formats/Impl/NpyRowInputFormat.cpp\nnew file mode 100644\nindex 000000000000..9acb2909626d\n--- /dev/null\n+++ b/src/Processors/Formats/Impl/NpyRowInputFormat.cpp\n@@ -0,0 +1,426 @@\n+#include <string>\n+#include <vector>\n+#include <Processors/Formats/Impl/NpyRowInputFormat.h>\n+#include <DataTypes/DataTypeString.h>\n+#include <Common/assert_cast.h>\n+#include <Common/Exception.h>\n+#include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <Formats/FormatFactory.h>\n+#include <Formats/NumpyDataTypes.h>\n+#include <Columns/ColumnFixedString.h>\n+#include <Columns/ColumnString.h>\n+#include <Columns/ColumnArray.h>\n+#include <Columns/ColumnsNumber.h>\n+#include <DataTypes/IDataType.h>\n+#include <IO/ReadBuffer.h>\n+#include <Processors/Formats/IRowInputFormat.h>\n+#include <boost/algorithm/string/split.hpp>\n+#include <IO/ReadBufferFromString.h>\n+\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int INCORRECT_DATA;\n+    extern const int BAD_ARGUMENTS;\n+    extern const int TOO_LARGE_STRING_SIZE;\n+    extern const int UNKNOWN_TYPE;\n+    extern const int ILLEGAL_COLUMN;\n+}\n+\n+namespace\n+{\n+\n+DataTypePtr getDataTypeFromNumpyType(const std::shared_ptr<NumpyDataType> & numpy_type)\n+{\n+    switch (numpy_type->getTypeIndex())\n+    {\n+        case NumpyDataTypeIndex::Int8:\n+            return std::make_shared<DataTypeInt8>();\n+        case NumpyDataTypeIndex::Int16:\n+            return std::make_shared<DataTypeInt16>();\n+        case NumpyDataTypeIndex::Int32:\n+            return std::make_shared<DataTypeInt32>();\n+        case NumpyDataTypeIndex::Int64:\n+            return std::make_shared<DataTypeInt64>();\n+        case NumpyDataTypeIndex::UInt8:\n+            return std::make_shared<DataTypeUInt8>();\n+        case NumpyDataTypeIndex::UInt16:\n+            return std::make_shared<DataTypeUInt16>();\n+        case NumpyDataTypeIndex::UInt32:\n+            return std::make_shared<DataTypeUInt32>();\n+        case NumpyDataTypeIndex::UInt64:\n+            return std::make_shared<DataTypeUInt64>();\n+        case NumpyDataTypeIndex::Float32:\n+            return std::make_shared<DataTypeFloat32>();\n+        case NumpyDataTypeIndex::Float64:\n+            return std::make_shared<DataTypeFloat64>();\n+        case NumpyDataTypeIndex::String:\n+            return std::make_shared<DataTypeString>();\n+        case NumpyDataTypeIndex::Unicode:\n+            return std::make_shared<DataTypeString>();\n+    }\n+    throw Exception(ErrorCodes::UNKNOWN_TYPE, \"Numpy type {} is not supported\", magic_enum::enum_name(numpy_type->getTypeIndex()));\n+}\n+\n+DataTypePtr createNestedArrayType(const DataTypePtr & nested_type, size_t depth)\n+{\n+    DataTypePtr result_type = nested_type;\n+    assert(depth > 0);\n+    if (depth > 1)\n+    {\n+        for (size_t i = 0; i < depth - 1; ++i)\n+            result_type = std::make_shared<DataTypeArray>(std::move(result_type));\n+    }\n+    return result_type;\n+}\n+\n+size_t parseTypeSize(const std::string & size_str)\n+{\n+    ReadBufferFromString buf(size_str);\n+    size_t size;\n+    if (!tryReadIntText(size, buf))\n+        throw Exception(ErrorCodes::INCORRECT_DATA, \"Invalid data type size: {}\", size_str);\n+    return size;\n+}\n+\n+std::shared_ptr<NumpyDataType> parseType(String type)\n+{\n+    /// Parse endianness\n+    NumpyDataType::Endianness endianness;\n+    if (type[0] == '<')\n+        endianness = NumpyDataType::Endianness::LITTLE;\n+    else if (type[1] == '>')\n+        endianness = NumpyDataType::Endianness::BIG;\n+    else if (type[0] == '|')\n+        endianness = NumpyDataType::Endianness::NONE;\n+    else\n+      throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Wrong header data\");\n+\n+    /// Parse type\n+    if (type[1] == 'i')\n+        return std::make_shared<NumpyDataTypeInt>(endianness, parseTypeSize(type.substr(2)), true);\n+    else if (type[1] == 'b')\n+        return std::make_shared<NumpyDataTypeInt>(endianness, parseTypeSize(type.substr(2)), false);\n+    else if (type[1] == 'u')\n+        return std::make_shared<NumpyDataTypeInt>(endianness, parseTypeSize(type.substr(2)), false);\n+    else if (type[1] == 'f')\n+        return std::make_shared<NumpyDataTypeFloat>(endianness, parseTypeSize(type.substr(2)));\n+    else if (type[1] == 'S')\n+        return std::make_shared<NumpyDataTypeString>(endianness, parseTypeSize(type.substr(2)));\n+    else if (type[1] == 'U')\n+        return std::make_shared<NumpyDataTypeUnicode>(endianness, parseTypeSize(type.substr(2)));\n+    else if (type[1] == 'c')\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"ClickHouse doesn't support complex numeric type\");\n+    else if (type[1] == 'O')\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"ClickHouse doesn't support object types\");\n+    else\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"ClickHouse doesn't support numpy type '{}'\", type);\n+}\n+\n+std::vector<int> parseShape(String shape_string)\n+{\n+    if (!shape_string.starts_with('(') || !shape_string.ends_with(')'))\n+        throw Exception(ErrorCodes::INCORRECT_DATA, \"Incorrect shape format: {}\", shape_string);\n+    std::vector<std::string> result_str;\n+    boost::split(result_str, std::string_view(shape_string.data() + 1, shape_string.size() - 2), boost::is_any_of(\",\"));\n+\n+    std::vector<int> shape;\n+    if (result_str[result_str.size()-1].empty())\n+        result_str.pop_back();\n+    shape.reserve(result_str.size());\n+    for (const String & item : result_str)\n+    {\n+        int value;\n+        ReadBufferFromString buf(item);\n+        skipWhitespaceIfAny(buf);\n+        if (!tryReadIntText(value, buf))\n+            throw Exception(ErrorCodes::INCORRECT_DATA, \"Invalid shape format: {}\", shape_string);\n+        shape.push_back(value);\n+    }\n+    return shape;\n+}\n+\n+NumpyHeader parseHeader(ReadBuffer &buf)\n+{\n+    /// Check magic bytes\n+    const char * magic_string = \"\\x93NUMPY\";\n+    assertString(magic_string, buf);\n+\n+    /// Read npy version.\n+    UInt8 version_major;\n+    UInt8 version_minor;\n+    readBinary(version_major, buf);\n+    readBinary(version_minor, buf);\n+\n+    /// Read header length.\n+    UInt32 header_length;\n+    /// In v1 header length is 2 bytes, in v2 - 4 bytes.\n+    if (version_major == 1)\n+    {\n+        UInt16 header_length_u16;\n+        readBinaryLittleEndian(header_length_u16, buf);\n+        header_length = header_length_u16;\n+    }\n+    else\n+    {\n+        readBinaryLittleEndian(header_length, buf);\n+    }\n+\n+    /// Remember current count of read bytes to skip remaining\n+    /// bytes in header when we find all required fields.\n+    size_t header_start = buf.count();\n+\n+    /// Start parsing header.\n+    String shape;\n+    String descr;\n+\n+    assertChar('{', buf);\n+    skipWhitespaceIfAny(buf);\n+    bool first = true;\n+    while (!checkChar('}', buf))\n+    {\n+        /// Skip delimiter between key-value pairs.\n+        if (!first)\n+        {\n+            skipWhitespaceIfAny(buf);\n+        }\n+        else\n+        {\n+            first = false;\n+        }\n+\n+        /// Read map key.\n+        String key;\n+        readQuotedString(key, buf);\n+        assertChar(':', buf);\n+        skipWhitespaceIfAny(buf);\n+        /// Read map value.\n+        String value;\n+        readQuotedField(value, buf);\n+        assertChar(',', buf);\n+        skipWhitespaceIfAny(buf);\n+\n+        if (key == \"descr\")\n+            descr = value;\n+        else if (key == \"fortran_order\")\n+        {\n+            if (value != \"false\")\n+                throw Exception(ErrorCodes::INCORRECT_DATA, \"Fortran order is not supported\");\n+        }\n+        else if (key == \"shape\")\n+            shape = value;\n+    }\n+\n+    if (shape.empty() || descr.empty())\n+        throw Exception(ErrorCodes::INCORRECT_DATA, \"npy file header doesn't contain required field 'shape' or 'descr'\");\n+\n+    size_t read_bytes = buf.count() - header_start;\n+    if (read_bytes > header_length)\n+        throw Exception(ErrorCodes::INCORRECT_DATA, \"Header size is incorrect\");\n+\n+    /// Ignore remaining header data.\n+    buf.ignore(header_length - read_bytes);\n+\n+    if (descr[0] == '\\'')\n+        descr = descr.substr(1, descr.length() - 1);\n+    if (descr[descr.length() - 1] == '\\'')\n+        descr = descr.substr(0, descr.length() - 1);\n+\n+    if (shape[0] == '\\'')\n+        shape = shape.substr(1, shape.length() - 1);\n+    if (shape[shape.length() - 1] == '\\'')\n+        shape = shape.substr(0, shape.length() - 1);\n+\n+    NumpyHeader res;\n+    res.shape = parseShape(shape);\n+    res.numpy_type = parseType(descr);\n+\n+    return res;\n+}\n+\n+DataTypePtr getNestedType(DataTypePtr type)\n+{\n+    while (const auto * temp_type = typeid_cast<const DataTypeArray *>(type.get()))\n+        type = temp_type->getNestedType();\n+\n+    return type;\n+}\n+}\n+\n+void NpyRowInputFormat::readPrefix()\n+{\n+    header = parseHeader(*in);\n+}\n+\n+NpyRowInputFormat::NpyRowInputFormat(ReadBuffer & in_, Block header_, Params params_)\n+    : IRowInputFormat(std::move(header_), in_, std::move(params_))\n+{\n+    auto types = getPort().getHeader().getDataTypes();\n+    if (types.size() != 1)\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unexpected number of columns for Npy input format, expected one column, got {} columns\", types.size());\n+    nested_type = getNestedType(types[0]);\n+}\n+\n+template <typename ColumnValue, typename DataValue>\n+void NpyRowInputFormat::readBinaryValueAndInsert(MutableColumnPtr column, NumpyDataType::Endianness endianness)\n+{\n+    DataValue value;\n+    if (endianness == NumpyDataType::Endianness::BIG)\n+        readBinaryBigEndian(value, *in);\n+    else\n+        readBinaryLittleEndian(value, *in);\n+    assert_cast<ColumnVector<ColumnValue> &>(*column).insertValue(static_cast<ColumnValue>(value));\n+}\n+\n+template <typename T>\n+void NpyRowInputFormat::readAndInsertInteger(IColumn * column, const DataTypePtr & data_type, const NumpyDataType & npy_type)\n+{\n+    switch (npy_type.getTypeIndex())\n+    {\n+        case NumpyDataTypeIndex::Int8: readBinaryValueAndInsert<T, UInt8>(column->getPtr(), npy_type.getEndianness()); break;\n+        case NumpyDataTypeIndex::Int16: readBinaryValueAndInsert<T, UInt16>(column->getPtr(), npy_type.getEndianness()); break;\n+        case NumpyDataTypeIndex::Int32: readBinaryValueAndInsert<T, UInt32>(column->getPtr(), npy_type.getEndianness()); break;\n+        case NumpyDataTypeIndex::Int64: readBinaryValueAndInsert<T, UInt64>(column->getPtr(), npy_type.getEndianness()); break;\n+        case NumpyDataTypeIndex::UInt8: readBinaryValueAndInsert<T, UInt8>(column->getPtr(), npy_type.getEndianness()); break;\n+        case NumpyDataTypeIndex::UInt16: readBinaryValueAndInsert<T, UInt16>(column->getPtr(), npy_type.getEndianness()); break;\n+        case NumpyDataTypeIndex::UInt32: readBinaryValueAndInsert<T, UInt32>(column->getPtr(), npy_type.getEndianness()); break;\n+        case NumpyDataTypeIndex::UInt64: readBinaryValueAndInsert<T, UInt64>(column->getPtr(), npy_type.getEndianness()); break;\n+        default:\n+            throw Exception(ErrorCodes::ILLEGAL_COLUMN, \"Cannot insert Numpy value with type {} into column with type {}\",\n+                        magic_enum::enum_name(npy_type.getTypeIndex()), data_type->getName());\n+    }\n+}\n+\n+template <typename T>\n+void NpyRowInputFormat::readAndInsertFloat(IColumn * column, const DataTypePtr & data_type, const NumpyDataType & npy_type)\n+{\n+    switch (npy_type.getTypeIndex())\n+    {\n+        case NumpyDataTypeIndex::Float32: readBinaryValueAndInsert<T, Float32>(column->getPtr(), npy_type.getEndianness()); break;\n+        case NumpyDataTypeIndex::Float64: readBinaryValueAndInsert<T, Float64>(column->getPtr(), npy_type.getEndianness()); break;\n+        default:\n+            throw Exception(ErrorCodes::ILLEGAL_COLUMN, \"Cannot insert Numpy value with type {} into column with type {}\",\n+                        magic_enum::enum_name(npy_type.getTypeIndex()), data_type->getName());\n+    }\n+}\n+\n+template <typename T>\n+void NpyRowInputFormat::readAndInsertString(MutableColumnPtr column, const DataTypePtr & data_type, const NumpyDataType & npy_type, bool is_fixed)\n+{\n+    size_t size;\n+    if (npy_type.getTypeIndex() == NumpyDataTypeIndex::String)\n+        size = assert_cast<const NumpyDataTypeString &>(npy_type).getSize();\n+    else if (npy_type.getTypeIndex() == NumpyDataTypeIndex::Unicode)\n+        size = assert_cast<const NumpyDataTypeUnicode &>(npy_type).getSize();\n+    else\n+        throw Exception(ErrorCodes::ILLEGAL_COLUMN, \"Cannot insert Numpy value with type {} into column with type {}\",\n+                        magic_enum::enum_name(npy_type.getTypeIndex()), data_type->getName());\n+\n+    if (is_fixed)\n+    {\n+        auto & fixed_string_column = assert_cast<ColumnFixedString &>(*column);\n+        size_t n = fixed_string_column.getN();\n+        if (size > n)\n+            throw Exception(ErrorCodes::TOO_LARGE_STRING_SIZE, \"Too large string for FixedString column\");\n+        auto & chars = fixed_string_column.getChars();\n+        size_t prev_size = chars.size();\n+        chars.resize_fill(prev_size + n);\n+        in->readStrict(reinterpret_cast<char *>(chars.data() + prev_size), size);\n+    }\n+    else\n+    {\n+        auto & column_string = assert_cast<ColumnString &>(*column);\n+        String tmp;\n+\n+        tmp.resize(size);\n+        in->readStrict(tmp.data(), size);\n+        tmp.erase(std::remove(tmp.begin(), tmp.end(), '\\0'), tmp.end());\n+        column_string.insertData(tmp.c_str(), tmp.size());\n+    }\n+}\n+\n+void NpyRowInputFormat::readValue(IColumn * column)\n+{\n+    switch (nested_type->getTypeId())\n+    {\n+        case TypeIndex::UInt8: readAndInsertInteger<UInt8>(column, nested_type, *header.numpy_type); break;\n+        case TypeIndex::UInt16: readAndInsertInteger<UInt16>(column, nested_type, *header.numpy_type); break;\n+        case TypeIndex::UInt32: readAndInsertInteger<UInt32>(column, nested_type, *header.numpy_type); break;\n+        case TypeIndex::UInt64: readAndInsertInteger<UInt64>(column, nested_type, *header.numpy_type); break;\n+        case TypeIndex::Int8: readAndInsertInteger<Int8>(column, nested_type, *header.numpy_type); break;\n+        case TypeIndex::Int16: readAndInsertInteger<Int16>(column, nested_type, *header.numpy_type); break;\n+        case TypeIndex::Int32: readAndInsertInteger<Int32>(column, nested_type, *header.numpy_type); break;\n+        case TypeIndex::Int64: readAndInsertInteger<Int64>(column, nested_type, *header.numpy_type); break;\n+        case TypeIndex::Float32: readAndInsertFloat<Float32>(column, nested_type, *header.numpy_type); break;\n+        case TypeIndex::Float64: readAndInsertFloat<Float64>(column, nested_type, *header.numpy_type); break;\n+        case TypeIndex::String: readAndInsertString<String>(column->getPtr(), nested_type, *header.numpy_type, false); break;\n+        case TypeIndex::FixedString: readAndInsertString<String>(column->getPtr(), nested_type, *header.numpy_type, true); break;\n+        default:\n+            throw Exception(ErrorCodes::UNKNOWN_TYPE, \"ClickHouse type {} is not supported for import from Npy format\", nested_type->getName());\n+    }\n+}\n+\n+bool NpyRowInputFormat::readRow(MutableColumns & columns, RowReadExtension &  /*ext*/)\n+{\n+    if (in->eof())\n+        return false;\n+\n+    auto & column = columns[0];\n+    IColumn * current_column = column.get();\n+    size_t elements_in_current_column = 1;\n+    for (size_t i = 1; i != header.shape.size(); ++i)\n+    {\n+        auto * array_column = typeid_cast<ColumnArray *>(current_column);\n+        if (!array_column)\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unexpected nesting level of column '{}', expected {}, got {}\", column->getName(), header.shape.size() - 1, i - 1);\n+        /// Fill offsets of array columns.\n+        for (size_t j = 0; j != elements_in_current_column; ++j)\n+            array_column->getOffsets().push_back(array_column->getOffsets().back() + header.shape[i]);\n+        current_column = &array_column->getData();\n+        elements_in_current_column *= header.shape[i];\n+    }\n+\n+    for (size_t i = 0; i != elements_in_current_column; ++i)\n+        readValue(current_column);\n+\n+    return true;\n+}\n+\n+NpySchemaReader::NpySchemaReader(ReadBuffer & in_)\n+    : ISchemaReader(in_) {}\n+\n+NamesAndTypesList NpySchemaReader::readSchema()\n+{\n+    NumpyHeader header = parseHeader(in);\n+    DataTypePtr nested_type = getDataTypeFromNumpyType(header.numpy_type);\n+    DataTypePtr result_type = createNestedArrayType(nested_type, header.shape.size());\n+\n+    return {{\"array\", result_type}};\n+}\n+\n+void registerInputFormatNpy(FormatFactory & factory)\n+{\n+    factory.registerInputFormat(\"Npy\", [](\n+        ReadBuffer & buf,\n+        const Block & sample,\n+        IRowInputFormat::Params params,\n+        const FormatSettings &)\n+    {\n+        return std::make_shared<NpyRowInputFormat>(buf, sample, std::move(params));\n+    });\n+\n+    factory.markFormatSupportsSubsetOfColumns(\"Npy\");\n+}\n+void registerNpySchemaReader(FormatFactory & factory)\n+{\n+    factory.registerSchemaReader(\"Npy\", [](ReadBuffer & buf, const FormatSettings &)\n+    {\n+        return std::make_shared<NpySchemaReader>(buf);\n+    });\n+}\n+\n+}\ndiff --git a/src/Processors/Formats/Impl/NpyRowInputFormat.h b/src/Processors/Formats/Impl/NpyRowInputFormat.h\nnew file mode 100644\nindex 000000000000..ad32bdba3bf2\n--- /dev/null\n+++ b/src/Processors/Formats/Impl/NpyRowInputFormat.h\n@@ -0,0 +1,65 @@\n+#pragma once\n+\n+#include <vector>\n+#include <Processors/Formats/IRowInputFormat.h>\n+#include <Processors/Formats/ISchemaReader.h>\n+#include <Formats/FormatSettings.h>\n+#include <Columns/IColumn.h>\n+#include <Core/Field.h>\n+#include <Core/NamesAndTypes.h>\n+#include <Core/Types.h>\n+#include <Formats/NumpyDataTypes.h>\n+\n+namespace DB\n+{\n+\n+class ReadBuffer;\n+\n+struct NumpyHeader\n+{\n+    std::vector<int> shape;\n+    std::shared_ptr<NumpyDataType> numpy_type;\n+};\n+\n+class NpyRowInputFormat final : public IRowInputFormat\n+{\n+public:\n+    NpyRowInputFormat(ReadBuffer & in_, Block header_, Params params_);\n+\n+    String getName() const override { return \"NpyRowInputFormat\"; }\n+\n+private:\n+    void readPrefix() override;\n+    bool readRow(MutableColumns & columns, RowReadExtension &) override;\n+    void readData(MutableColumns & columns);\n+\n+    template <typename T>\n+    void readAndInsertInteger(IColumn * column, const DataTypePtr & data_type, const NumpyDataType & npy_type);\n+\n+    template <typename T>\n+    void readAndInsertFloat(IColumn * column, const DataTypePtr & data_type, const NumpyDataType & npy_type);\n+\n+    template <typename T>\n+    void readAndInsertString(MutableColumnPtr column, const DataTypePtr & data_type, const NumpyDataType & npy_type, bool is_fixed);\n+\n+    template <typename ColumnValue, typename DataValue>\n+    void readBinaryValueAndInsert(MutableColumnPtr column, NumpyDataType::Endianness endianness);\n+\n+    void readRows(MutableColumns & columns);\n+\n+    void readValue(IColumn * column);\n+\n+    DataTypePtr nested_type;\n+    NumpyHeader header;\n+};\n+\n+class NpySchemaReader : public ISchemaReader\n+{\n+public:\n+    explicit NpySchemaReader(ReadBuffer & in_);\n+\n+private:\n+    NamesAndTypesList readSchema() override;\n+};\n+\n+}\ndiff --git a/utils/check-style/aspell-ignore/en/aspell-dict.txt b/utils/check-style/aspell-ignore/en/aspell-dict.txt\nindex b43f9cab0f19..f772f58c2ba4 100644\n--- a/utils/check-style/aspell-ignore/en/aspell-dict.txt\n+++ b/utils/check-style/aspell-ignore/en/aspell-dict.txt\n@@ -568,6 +568,7 @@ NumberOfDatabases\n NumberOfDetachedByUserParts\n NumberOfDetachedParts\n NumberOfTables\n+NumPy\n OFNS\n OLAP\n OLTP\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02895_npy_format.reference b/tests/queries/0_stateless/02895_npy_format.reference\nnew file mode 100644\nindex 000000000000..0c90fbfd418f\n--- /dev/null\n+++ b/tests/queries/0_stateless/02895_npy_format.reference\n@@ -0,0 +1,86 @@\n+1\n+2\n+3\n+1.1\n+2.2\n+3.3\n+1\n+a\n+c\n+1\n+a\n+c\n+[1,2,3]\n+[4,5,6]\n+[1.1,2.22,3.33]\n+[4.4,5.5,6.6]\n+['a','b','c']\n+['e','f','g']\n+['a','b','c']\n+['e','f','g']\n+[1]\n+[0]\n+[1]\n+[0]\n+[0,0,0]\n+[0,0,0]\n+[[1,2],[3,4]]\n+[[5,6],[7,8]]\n+array\tInt64\t\t\t\t\t\n+array\tFloat64\t\t\t\t\t\n+array\tString\t\t\t\t\t\n+array\tString\t\t\t\t\t\n+array\tArray(Int64)\t\t\t\t\t\n+array\tArray(Float64)\t\t\t\t\t\n+array\tArray(String)\t\t\t\t\t\n+array\tArray(String)\t\t\t\t\t\n+array\tArray(UInt8)\t\t\t\t\t\n+array\tArray(Int64)\t\t\t\t\t\n+array\tArray(Array(Int64))\t\t\t\t\t\n+1\n+2\n+3\n+1\n+2\n+3\n+1\n+2\n+3\n+1\n+2\n+3\n+1\n+2\n+3\n+1\n+2\n+3\n+1\n+2\n+3\n+1\n+2\n+3\n+1.1\n+2.2\n+3.3\n+1.1\n+2.2\n+3.3\n+1\n+a\n+c\n+1\n+a\n+c\n+[1,2,3]\n+[4,5,6]\n+[[1,2],[3,4]]\n+[[5,6],[7,8]]\n+0\n+0\n+0\n+0\n+0\n+0\n+1\ndiff --git a/tests/queries/0_stateless/02895_npy_format.sh b/tests/queries/0_stateless/02895_npy_format.sh\nnew file mode 100755\nindex 000000000000..1dbf62ceaa23\n--- /dev/null\n+++ b/tests/queries/0_stateless/02895_npy_format.sh\n@@ -0,0 +1,58 @@\n+#!/usr/bin/env bash\n+# Tags: no-fasttest\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim.npy')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_float.npy')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_str.npy')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_unicode.npy')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/two_dim.npy')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/two_dim_float.npy')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/two_dim_str.npy')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/two_dim_unicode.npy')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/two_dim_bool.npy')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/two_dim_null.npy')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/three_dim.npy')\"\n+\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/one_dim.npy')\"\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/one_dim_float.npy')\"\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/one_dim_str.npy')\"\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/one_dim_unicode.npy')\"\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/two_dim.npy')\"\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/two_dim_float.npy')\"\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/two_dim_str.npy')\"\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/two_dim_unicode.npy')\"\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/two_dim_bool.npy')\"\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/two_dim_null.npy')\"\n+$CLICKHOUSE_LOCAL -q \"describe file('$CURDIR/data_npy/three_dim.npy')\"\n+\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim.npy', Npy, 'value UInt8')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim.npy', Npy, 'value UInt16')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim.npy', Npy, 'value UInt32')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim.npy', Npy, 'value UInt64')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim.npy', Npy, 'value Int8')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim.npy', Npy, 'value Int16')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim.npy', Npy, 'value Int32')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim.npy', Npy, 'value Int64')\"\n+\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_float.npy', Npy, 'value Float32')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_float.npy', Npy, 'value Float64')\"\n+\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_str.npy', Npy, 'value FixedString(1)')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_str.npy', Npy, 'value String')\"\n+\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/two_dim.npy', Npy, 'value Array(Int8)')\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/three_dim.npy', Npy, 'value Array(Array(Int8))')\"\n+\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_float.npy', Npy, 'value Array(Float32)')\" 2>&1 | grep -c \"BAD_ARGUMENTS\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_float.npy', Npy, 'value UUID')\" 2>&1 | grep -c \"BAD_ARGUMENTS\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_float.npy', Npy, 'value Tuple(UInt8)')\" 2>&1 | grep -c \"BAD_ARGUMENTS\"\n+\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_float.npy', Npy, 'value Int8')\" 2>&1 | grep -c \"BAD_ARGUMENTS\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_str.npy', Npy, 'value Int8')\" 2>&1 | grep -c \"BAD_ARGUMENTS\"\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/one_dim_unicode.npy', Npy, 'value Float32')\" 2>&1 | grep -c \"BAD_ARGUMENTS\"\n+\n+$CLICKHOUSE_LOCAL -q \"select * from file('$CURDIR/data_npy/complex.npy')\" 2>&1 | grep -c \"BAD_ARGUMENTS\"\ndiff --git a/tests/queries/0_stateless/data_npy/complex.npy b/tests/queries/0_stateless/data_npy/complex.npy\nnew file mode 100644\nindex 000000000000..5777d593a7dd\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/complex.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/one_dim.npy b/tests/queries/0_stateless/data_npy/one_dim.npy\nnew file mode 100644\nindex 000000000000..80c6ff86eba9\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/one_dim.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/one_dim_float.npy b/tests/queries/0_stateless/data_npy/one_dim_float.npy\nnew file mode 100644\nindex 000000000000..0e7fc14e59e0\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/one_dim_float.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/one_dim_str.npy b/tests/queries/0_stateless/data_npy/one_dim_str.npy\nnew file mode 100644\nindex 000000000000..010cb52787e8\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/one_dim_str.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/one_dim_unicode.npy b/tests/queries/0_stateless/data_npy/one_dim_unicode.npy\nnew file mode 100644\nindex 000000000000..d0245df237cb\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/one_dim_unicode.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/three_dim.npy b/tests/queries/0_stateless/data_npy/three_dim.npy\nnew file mode 100644\nindex 000000000000..07a6b2bec4ab\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/three_dim.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/two_dim.npy b/tests/queries/0_stateless/data_npy/two_dim.npy\nnew file mode 100644\nindex 000000000000..70f4ed9ec170\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/two_dim.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/two_dim_bool.npy b/tests/queries/0_stateless/data_npy/two_dim_bool.npy\nnew file mode 100644\nindex 000000000000..d2f28ce6fa37\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/two_dim_bool.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/two_dim_float.npy b/tests/queries/0_stateless/data_npy/two_dim_float.npy\nnew file mode 100644\nindex 000000000000..2e2b58513cd9\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/two_dim_float.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/two_dim_null.npy b/tests/queries/0_stateless/data_npy/two_dim_null.npy\nnew file mode 100644\nindex 000000000000..b78b95af03ea\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/two_dim_null.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/two_dim_str.npy b/tests/queries/0_stateless/data_npy/two_dim_str.npy\nnew file mode 100644\nindex 000000000000..bda150c5f462\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/two_dim_str.npy differ\ndiff --git a/tests/queries/0_stateless/data_npy/two_dim_unicode.npy b/tests/queries/0_stateless/data_npy/two_dim_unicode.npy\nnew file mode 100644\nindex 000000000000..f8558d810c57\nBinary files /dev/null and b/tests/queries/0_stateless/data_npy/two_dim_unicode.npy differ\n",
  "problem_statement": "Support npy as input format\nnpy is often used to encode numpy data including embeddings as a arrays. Large embedding datasets are often distributed in this format. Propose we support as an input format.\r\nA mapping to clickhouse rows needs to be discussed, but possibly first level is mapped to row and nested arrays become `Array(Array`.\n",
  "hints_text": "https://numpy.org/devdocs/reference/generated/numpy.lib.format.html\r\n\r\nThis is a really good quote :)\r\n\r\n> Is straightforward to reverse engineer. Datasets often live longer than the programs that created them. A competent developer should be able to create a solution in their preferred programming language to read most .npy files that they have been given without much documentation.\nThe format is really simple and contains just one array. It will be easy to implement this format for reading.\r\n\r\nBut implementing this format for writing is not easy because it does not support streaming output - the number of rows should be known in advance. Therefore, we will only support reading.",
  "created_at": "2023-10-24T15:09:35Z"
}