diff --git a/docs/en/interfaces/formats.md b/docs/en/interfaces/formats.md
index e98f19b2a65d..0e7bbcf4b1be 100644
--- a/docs/en/interfaces/formats.md
+++ b/docs/en/interfaces/formats.md
@@ -74,6 +74,7 @@ The supported formats are:
 | [ArrowStream](#data-format-arrow-stream)                                                  | ✔    | ✔     |
 | [ORC](#data-format-orc)                                                                   | ✔    | ✔     |
 | [One](#data-format-one)                                                                   | ✔    | ✗     |
+| [Npy](#data-format-npy)                                                                   | ✔    | ✗     |
 | [RowBinary](#rowbinary)                                                                   | ✔    | ✔     |
 | [RowBinaryWithNames](#rowbinarywithnamesandtypes)                                         | ✔    | ✔     |
 | [RowBinaryWithNamesAndTypes](#rowbinarywithnamesandtypes)                                 | ✔    | ✔     |
@@ -2445,6 +2446,50 @@ Result:
 └──────────────┘
 ```
 
+## Npy {#data-format-npy}
+
+This function is designed to load a NumPy array from a .npy file into ClickHouse. The NumPy file format is a binary format used for efficiently storing arrays of numerical data. During import, ClickHouse treats top level dimension as an array of rows with single column. Supported Npy data types and their corresponding type in ClickHouse: 
+| Npy type | ClickHouse type |
+|:--------:|:---------------:|
+| b1       |    UInt8        |
+| i1       |    Int8         |
+| i2       |    Int16        |
+| i4       |    Int32        |
+| i8       |    Int64        |
+| u1       |    UInt8        |
+| u2       |    UInt16       |
+| u4       |    UInt32       |
+| u8       |    UInt64       |
+| f4       |    Float32      |
+| f8       |    Float64      |
+| S        |    String       |
+| U        |    String       |
+
+**Example of saving an array in .npy format using Python**
+
+
+```Python
+import numpy as np
+arr = np.array([[[1],[2],[3]],[[4],[5],[6]]])
+np.save('example_array.npy', arr)
+```
+
+**Example of reading a NumPy file in ClickHouse**
+
+Query:
+```sql
+SELECT *
+FROM file('example_array.npy', Npy)
+```
+
+Result:
+```
+┌─array─────────┐
+│ [[1],[2],[3]] │
+│ [[4],[5],[6]] │
+└───────────────┘
+```
+
 ## LineAsString {#lineasstring}
 
 In this format, every line of input data is interpreted as a single string value. This format can only be parsed for table with a single field of type [String](/docs/en/sql-reference/data-types/string.md). The remaining columns must be set to [DEFAULT](/docs/en/sql-reference/statements/create/table.md/#default) or [MATERIALIZED](/docs/en/sql-reference/statements/create/table.md/#materialized), or omitted.
diff --git a/src/Formats/NumpyDataTypes.h b/src/Formats/NumpyDataTypes.h
new file mode 100644
index 000000000000..43fd9064daea
--- /dev/null
+++ b/src/Formats/NumpyDataTypes.h
@@ -0,0 +1,123 @@
+#pragma once
+#include <cstddef>
+#include <Storages/NamedCollectionsHelpers.h>
+
+namespace ErrorCodes
+{
+    extern const int BAD_ARGUMENTS;
+}
+
+enum class NumpyDataTypeIndex
+{
+    Int8,
+    Int16,
+    Int32,
+    Int64,
+    UInt8,
+    UInt16,
+    UInt32,
+    UInt64,
+    Float32,
+    Float64,
+    String,
+    Unicode,
+};
+
+class NumpyDataType
+{
+public:
+    enum Endianness
+    {
+        LITTLE,
+        BIG,
+        NONE,
+    };
+    NumpyDataTypeIndex type_index;
+
+    explicit NumpyDataType(Endianness endianness_) : endianness(endianness_) {}
+    virtual ~NumpyDataType() = default;
+
+    Endianness getEndianness() const { return endianness; }
+
+    virtual NumpyDataTypeIndex getTypeIndex() const = 0;
+
+private:
+    Endianness endianness;
+};
+
+class NumpyDataTypeInt : public NumpyDataType
+{
+public:
+    NumpyDataTypeInt(Endianness endianness, size_t size_, bool is_signed_) : NumpyDataType(endianness), size(size_), is_signed(is_signed_)
+    {
+        switch (size)
+        {
+            case 1: type_index = is_signed ? NumpyDataTypeIndex::Int8 : NumpyDataTypeIndex::UInt8; break;
+            case 2: type_index = is_signed ? NumpyDataTypeIndex::Int16 : NumpyDataTypeIndex::UInt16; break;
+            case 4: type_index = is_signed ? NumpyDataTypeIndex::Int32 : NumpyDataTypeIndex::UInt32; break;
+            case 8: type_index = is_signed ? NumpyDataTypeIndex::Int64 : NumpyDataTypeIndex::UInt64; break;
+            default:
+                throw DB::Exception(DB::ErrorCodes::BAD_ARGUMENTS, "Incorrect int type with size {}", size);
+        }
+    }
+
+    NumpyDataTypeIndex getTypeIndex() const override
+    {
+        return type_index;
+    }
+    bool isSigned() const { return is_signed; }
+
+private:
+    size_t size;
+    bool is_signed;
+};
+
+class NumpyDataTypeFloat : public NumpyDataType
+{
+public:
+    NumpyDataTypeFloat(Endianness endianness, size_t size_) : NumpyDataType(endianness), size(size_)
+    {
+        switch (size)
+        {
+            case 4: type_index = NumpyDataTypeIndex::Float32; break;
+            case 8: type_index = NumpyDataTypeIndex::Float64; break;
+            default:
+                throw DB::Exception(DB::ErrorCodes::BAD_ARGUMENTS, "Numpy float type with size {} is not supported", size);
+        }
+    }
+
+    NumpyDataTypeIndex getTypeIndex() const override
+    {
+        return type_index;
+    }
+private:
+    size_t size;
+};
+
+class NumpyDataTypeString : public NumpyDataType
+{
+public:
+    NumpyDataTypeString(Endianness endianness, size_t size_) : NumpyDataType(endianness), size(size_)
+    {
+        type_index = NumpyDataTypeIndex::String;
+    }
+
+    NumpyDataTypeIndex getTypeIndex() const override { return type_index; }
+    size_t getSize() const { return size; }
+private:
+    size_t size;
+};
+
+class NumpyDataTypeUnicode : public NumpyDataType
+{
+public:
+    NumpyDataTypeUnicode(Endianness endianness, size_t size_) : NumpyDataType(endianness), size(size_)
+    {
+        type_index = NumpyDataTypeIndex::Unicode;
+    }
+
+    NumpyDataTypeIndex getTypeIndex() const override { return type_index; }
+    size_t getSize() const { return size * 4; }
+private:
+    size_t size;
+};
diff --git a/src/Formats/registerFormats.cpp b/src/Formats/registerFormats.cpp
index 580db61edde4..ba03390cbd51 100644
--- a/src/Formats/registerFormats.cpp
+++ b/src/Formats/registerFormats.cpp
@@ -102,6 +102,7 @@ void registerInputFormatLineAsString(FormatFactory & factory);
 void registerInputFormatMySQLDump(FormatFactory & factory);
 void registerInputFormatParquetMetadata(FormatFactory & factory);
 void registerInputFormatOne(FormatFactory & factory);
+void registerInputFormatNpy(FormatFactory & factory);
 
 #if USE_HIVE
 void registerInputFormatHiveText(FormatFactory & factory);
@@ -144,6 +145,7 @@ void registerMySQLSchemaReader(FormatFactory & factory);
 void registerBSONEachRowSchemaReader(FormatFactory & factory);
 void registerParquetMetadataSchemaReader(FormatFactory & factory);
 void registerOneSchemaReader(FormatFactory & factory);
+void registerNpySchemaReader(FormatFactory & factory);
 
 void registerFileExtensions(FormatFactory & factory);
 
@@ -246,6 +248,7 @@ void registerFormats()
 
     registerInputFormatParquetMetadata(factory);
     registerInputFormatOne(factory);
+    registerInputFormatNpy(factory);
 
     registerNonTrivialPrefixAndSuffixCheckerJSONEachRow(factory);
     registerNonTrivialPrefixAndSuffixCheckerJSONAsString(factory);
@@ -283,6 +286,7 @@ void registerFormats()
     registerBSONEachRowSchemaReader(factory);
     registerParquetMetadataSchemaReader(factory);
     registerOneSchemaReader(factory);
+    registerNpySchemaReader(factory);
 }
 
 }
diff --git a/src/Processors/Formats/Impl/NpyRowInputFormat.cpp b/src/Processors/Formats/Impl/NpyRowInputFormat.cpp
new file mode 100644
index 000000000000..9acb2909626d
--- /dev/null
+++ b/src/Processors/Formats/Impl/NpyRowInputFormat.cpp
@@ -0,0 +1,426 @@
+#include <string>
+#include <vector>
+#include <Processors/Formats/Impl/NpyRowInputFormat.h>
+#include <DataTypes/DataTypeString.h>
+#include <Common/assert_cast.h>
+#include <Common/Exception.h>
+#include <DataTypes/DataTypeArray.h>
+#include <DataTypes/DataTypesNumber.h>
+#include <Formats/FormatFactory.h>
+#include <Formats/NumpyDataTypes.h>
+#include <Columns/ColumnFixedString.h>
+#include <Columns/ColumnString.h>
+#include <Columns/ColumnArray.h>
+#include <Columns/ColumnsNumber.h>
+#include <DataTypes/IDataType.h>
+#include <IO/ReadBuffer.h>
+#include <Processors/Formats/IRowInputFormat.h>
+#include <boost/algorithm/string/split.hpp>
+#include <IO/ReadBufferFromString.h>
+
+
+namespace DB
+{
+
+namespace ErrorCodes
+{
+    extern const int INCORRECT_DATA;
+    extern const int BAD_ARGUMENTS;
+    extern const int TOO_LARGE_STRING_SIZE;
+    extern const int UNKNOWN_TYPE;
+    extern const int ILLEGAL_COLUMN;
+}
+
+namespace
+{
+
+DataTypePtr getDataTypeFromNumpyType(const std::shared_ptr<NumpyDataType> & numpy_type)
+{
+    switch (numpy_type->getTypeIndex())
+    {
+        case NumpyDataTypeIndex::Int8:
+            return std::make_shared<DataTypeInt8>();
+        case NumpyDataTypeIndex::Int16:
+            return std::make_shared<DataTypeInt16>();
+        case NumpyDataTypeIndex::Int32:
+            return std::make_shared<DataTypeInt32>();
+        case NumpyDataTypeIndex::Int64:
+            return std::make_shared<DataTypeInt64>();
+        case NumpyDataTypeIndex::UInt8:
+            return std::make_shared<DataTypeUInt8>();
+        case NumpyDataTypeIndex::UInt16:
+            return std::make_shared<DataTypeUInt16>();
+        case NumpyDataTypeIndex::UInt32:
+            return std::make_shared<DataTypeUInt32>();
+        case NumpyDataTypeIndex::UInt64:
+            return std::make_shared<DataTypeUInt64>();
+        case NumpyDataTypeIndex::Float32:
+            return std::make_shared<DataTypeFloat32>();
+        case NumpyDataTypeIndex::Float64:
+            return std::make_shared<DataTypeFloat64>();
+        case NumpyDataTypeIndex::String:
+            return std::make_shared<DataTypeString>();
+        case NumpyDataTypeIndex::Unicode:
+            return std::make_shared<DataTypeString>();
+    }
+    throw Exception(ErrorCodes::UNKNOWN_TYPE, "Numpy type {} is not supported", magic_enum::enum_name(numpy_type->getTypeIndex()));
+}
+
+DataTypePtr createNestedArrayType(const DataTypePtr & nested_type, size_t depth)
+{
+    DataTypePtr result_type = nested_type;
+    assert(depth > 0);
+    if (depth > 1)
+    {
+        for (size_t i = 0; i < depth - 1; ++i)
+            result_type = std::make_shared<DataTypeArray>(std::move(result_type));
+    }
+    return result_type;
+}
+
+size_t parseTypeSize(const std::string & size_str)
+{
+    ReadBufferFromString buf(size_str);
+    size_t size;
+    if (!tryReadIntText(size, buf))
+        throw Exception(ErrorCodes::INCORRECT_DATA, "Invalid data type size: {}", size_str);
+    return size;
+}
+
+std::shared_ptr<NumpyDataType> parseType(String type)
+{
+    /// Parse endianness
+    NumpyDataType::Endianness endianness;
+    if (type[0] == '<')
+        endianness = NumpyDataType::Endianness::LITTLE;
+    else if (type[1] == '>')
+        endianness = NumpyDataType::Endianness::BIG;
+    else if (type[0] == '|')
+        endianness = NumpyDataType::Endianness::NONE;
+    else
+      throw Exception(ErrorCodes::BAD_ARGUMENTS, "Wrong header data");
+
+    /// Parse type
+    if (type[1] == 'i')
+        return std::make_shared<NumpyDataTypeInt>(endianness, parseTypeSize(type.substr(2)), true);
+    else if (type[1] == 'b')
+        return std::make_shared<NumpyDataTypeInt>(endianness, parseTypeSize(type.substr(2)), false);
+    else if (type[1] == 'u')
+        return std::make_shared<NumpyDataTypeInt>(endianness, parseTypeSize(type.substr(2)), false);
+    else if (type[1] == 'f')
+        return std::make_shared<NumpyDataTypeFloat>(endianness, parseTypeSize(type.substr(2)));
+    else if (type[1] == 'S')
+        return std::make_shared<NumpyDataTypeString>(endianness, parseTypeSize(type.substr(2)));
+    else if (type[1] == 'U')
+        return std::make_shared<NumpyDataTypeUnicode>(endianness, parseTypeSize(type.substr(2)));
+    else if (type[1] == 'c')
+        throw Exception(ErrorCodes::BAD_ARGUMENTS, "ClickHouse doesn't support complex numeric type");
+    else if (type[1] == 'O')
+        throw Exception(ErrorCodes::BAD_ARGUMENTS, "ClickHouse doesn't support object types");
+    else
+        throw Exception(ErrorCodes::BAD_ARGUMENTS, "ClickHouse doesn't support numpy type '{}'", type);
+}
+
+std::vector<int> parseShape(String shape_string)
+{
+    if (!shape_string.starts_with('(') || !shape_string.ends_with(')'))
+        throw Exception(ErrorCodes::INCORRECT_DATA, "Incorrect shape format: {}", shape_string);
+    std::vector<std::string> result_str;
+    boost::split(result_str, std::string_view(shape_string.data() + 1, shape_string.size() - 2), boost::is_any_of(","));
+
+    std::vector<int> shape;
+    if (result_str[result_str.size()-1].empty())
+        result_str.pop_back();
+    shape.reserve(result_str.size());
+    for (const String & item : result_str)
+    {
+        int value;
+        ReadBufferFromString buf(item);
+        skipWhitespaceIfAny(buf);
+        if (!tryReadIntText(value, buf))
+            throw Exception(ErrorCodes::INCORRECT_DATA, "Invalid shape format: {}", shape_string);
+        shape.push_back(value);
+    }
+    return shape;
+}
+
+NumpyHeader parseHeader(ReadBuffer &buf)
+{
+    /// Check magic bytes
+    const char * magic_string = "\x93NUMPY";
+    assertString(magic_string, buf);
+
+    /// Read npy version.
+    UInt8 version_major;
+    UInt8 version_minor;
+    readBinary(version_major, buf);
+    readBinary(version_minor, buf);
+
+    /// Read header length.
+    UInt32 header_length;
+    /// In v1 header length is 2 bytes, in v2 - 4 bytes.
+    if (version_major == 1)
+    {
+        UInt16 header_length_u16;
+        readBinaryLittleEndian(header_length_u16, buf);
+        header_length = header_length_u16;
+    }
+    else
+    {
+        readBinaryLittleEndian(header_length, buf);
+    }
+
+    /// Remember current count of read bytes to skip remaining
+    /// bytes in header when we find all required fields.
+    size_t header_start = buf.count();
+
+    /// Start parsing header.
+    String shape;
+    String descr;
+
+    assertChar('{', buf);
+    skipWhitespaceIfAny(buf);
+    bool first = true;
+    while (!checkChar('}', buf))
+    {
+        /// Skip delimiter between key-value pairs.
+        if (!first)
+        {
+            skipWhitespaceIfAny(buf);
+        }
+        else
+        {
+            first = false;
+        }
+
+        /// Read map key.
+        String key;
+        readQuotedString(key, buf);
+        assertChar(':', buf);
+        skipWhitespaceIfAny(buf);
+        /// Read map value.
+        String value;
+        readQuotedField(value, buf);
+        assertChar(',', buf);
+        skipWhitespaceIfAny(buf);
+
+        if (key == "descr")
+            descr = value;
+        else if (key == "fortran_order")
+        {
+            if (value != "false")
+                throw Exception(ErrorCodes::INCORRECT_DATA, "Fortran order is not supported");
+        }
+        else if (key == "shape")
+            shape = value;
+    }
+
+    if (shape.empty() || descr.empty())
+        throw Exception(ErrorCodes::INCORRECT_DATA, "npy file header doesn't contain required field 'shape' or 'descr'");
+
+    size_t read_bytes = buf.count() - header_start;
+    if (read_bytes > header_length)
+        throw Exception(ErrorCodes::INCORRECT_DATA, "Header size is incorrect");
+
+    /// Ignore remaining header data.
+    buf.ignore(header_length - read_bytes);
+
+    if (descr[0] == '\'')
+        descr = descr.substr(1, descr.length() - 1);
+    if (descr[descr.length() - 1] == '\'')
+        descr = descr.substr(0, descr.length() - 1);
+
+    if (shape[0] == '\'')
+        shape = shape.substr(1, shape.length() - 1);
+    if (shape[shape.length() - 1] == '\'')
+        shape = shape.substr(0, shape.length() - 1);
+
+    NumpyHeader res;
+    res.shape = parseShape(shape);
+    res.numpy_type = parseType(descr);
+
+    return res;
+}
+
+DataTypePtr getNestedType(DataTypePtr type)
+{
+    while (const auto * temp_type = typeid_cast<const DataTypeArray *>(type.get()))
+        type = temp_type->getNestedType();
+
+    return type;
+}
+}
+
+void NpyRowInputFormat::readPrefix()
+{
+    header = parseHeader(*in);
+}
+
+NpyRowInputFormat::NpyRowInputFormat(ReadBuffer & in_, Block header_, Params params_)
+    : IRowInputFormat(std::move(header_), in_, std::move(params_))
+{
+    auto types = getPort().getHeader().getDataTypes();
+    if (types.size() != 1)
+        throw Exception(ErrorCodes::BAD_ARGUMENTS, "Unexpected number of columns for Npy input format, expected one column, got {} columns", types.size());
+    nested_type = getNestedType(types[0]);
+}
+
+template <typename ColumnValue, typename DataValue>
+void NpyRowInputFormat::readBinaryValueAndInsert(MutableColumnPtr column, NumpyDataType::Endianness endianness)
+{
+    DataValue value;
+    if (endianness == NumpyDataType::Endianness::BIG)
+        readBinaryBigEndian(value, *in);
+    else
+        readBinaryLittleEndian(value, *in);
+    assert_cast<ColumnVector<ColumnValue> &>(*column).insertValue(static_cast<ColumnValue>(value));
+}
+
+template <typename T>
+void NpyRowInputFormat::readAndInsertInteger(IColumn * column, const DataTypePtr & data_type, const NumpyDataType & npy_type)
+{
+    switch (npy_type.getTypeIndex())
+    {
+        case NumpyDataTypeIndex::Int8: readBinaryValueAndInsert<T, UInt8>(column->getPtr(), npy_type.getEndianness()); break;
+        case NumpyDataTypeIndex::Int16: readBinaryValueAndInsert<T, UInt16>(column->getPtr(), npy_type.getEndianness()); break;
+        case NumpyDataTypeIndex::Int32: readBinaryValueAndInsert<T, UInt32>(column->getPtr(), npy_type.getEndianness()); break;
+        case NumpyDataTypeIndex::Int64: readBinaryValueAndInsert<T, UInt64>(column->getPtr(), npy_type.getEndianness()); break;
+        case NumpyDataTypeIndex::UInt8: readBinaryValueAndInsert<T, UInt8>(column->getPtr(), npy_type.getEndianness()); break;
+        case NumpyDataTypeIndex::UInt16: readBinaryValueAndInsert<T, UInt16>(column->getPtr(), npy_type.getEndianness()); break;
+        case NumpyDataTypeIndex::UInt32: readBinaryValueAndInsert<T, UInt32>(column->getPtr(), npy_type.getEndianness()); break;
+        case NumpyDataTypeIndex::UInt64: readBinaryValueAndInsert<T, UInt64>(column->getPtr(), npy_type.getEndianness()); break;
+        default:
+            throw Exception(ErrorCodes::ILLEGAL_COLUMN, "Cannot insert Numpy value with type {} into column with type {}",
+                        magic_enum::enum_name(npy_type.getTypeIndex()), data_type->getName());
+    }
+}
+
+template <typename T>
+void NpyRowInputFormat::readAndInsertFloat(IColumn * column, const DataTypePtr & data_type, const NumpyDataType & npy_type)
+{
+    switch (npy_type.getTypeIndex())
+    {
+        case NumpyDataTypeIndex::Float32: readBinaryValueAndInsert<T, Float32>(column->getPtr(), npy_type.getEndianness()); break;
+        case NumpyDataTypeIndex::Float64: readBinaryValueAndInsert<T, Float64>(column->getPtr(), npy_type.getEndianness()); break;
+        default:
+            throw Exception(ErrorCodes::ILLEGAL_COLUMN, "Cannot insert Numpy value with type {} into column with type {}",
+                        magic_enum::enum_name(npy_type.getTypeIndex()), data_type->getName());
+    }
+}
+
+template <typename T>
+void NpyRowInputFormat::readAndInsertString(MutableColumnPtr column, const DataTypePtr & data_type, const NumpyDataType & npy_type, bool is_fixed)
+{
+    size_t size;
+    if (npy_type.getTypeIndex() == NumpyDataTypeIndex::String)
+        size = assert_cast<const NumpyDataTypeString &>(npy_type).getSize();
+    else if (npy_type.getTypeIndex() == NumpyDataTypeIndex::Unicode)
+        size = assert_cast<const NumpyDataTypeUnicode &>(npy_type).getSize();
+    else
+        throw Exception(ErrorCodes::ILLEGAL_COLUMN, "Cannot insert Numpy value with type {} into column with type {}",
+                        magic_enum::enum_name(npy_type.getTypeIndex()), data_type->getName());
+
+    if (is_fixed)
+    {
+        auto & fixed_string_column = assert_cast<ColumnFixedString &>(*column);
+        size_t n = fixed_string_column.getN();
+        if (size > n)
+            throw Exception(ErrorCodes::TOO_LARGE_STRING_SIZE, "Too large string for FixedString column");
+        auto & chars = fixed_string_column.getChars();
+        size_t prev_size = chars.size();
+        chars.resize_fill(prev_size + n);
+        in->readStrict(reinterpret_cast<char *>(chars.data() + prev_size), size);
+    }
+    else
+    {
+        auto & column_string = assert_cast<ColumnString &>(*column);
+        String tmp;
+
+        tmp.resize(size);
+        in->readStrict(tmp.data(), size);
+        tmp.erase(std::remove(tmp.begin(), tmp.end(), '\0'), tmp.end());
+        column_string.insertData(tmp.c_str(), tmp.size());
+    }
+}
+
+void NpyRowInputFormat::readValue(IColumn * column)
+{
+    switch (nested_type->getTypeId())
+    {
+        case TypeIndex::UInt8: readAndInsertInteger<UInt8>(column, nested_type, *header.numpy_type); break;
+        case TypeIndex::UInt16: readAndInsertInteger<UInt16>(column, nested_type, *header.numpy_type); break;
+        case TypeIndex::UInt32: readAndInsertInteger<UInt32>(column, nested_type, *header.numpy_type); break;
+        case TypeIndex::UInt64: readAndInsertInteger<UInt64>(column, nested_type, *header.numpy_type); break;
+        case TypeIndex::Int8: readAndInsertInteger<Int8>(column, nested_type, *header.numpy_type); break;
+        case TypeIndex::Int16: readAndInsertInteger<Int16>(column, nested_type, *header.numpy_type); break;
+        case TypeIndex::Int32: readAndInsertInteger<Int32>(column, nested_type, *header.numpy_type); break;
+        case TypeIndex::Int64: readAndInsertInteger<Int64>(column, nested_type, *header.numpy_type); break;
+        case TypeIndex::Float32: readAndInsertFloat<Float32>(column, nested_type, *header.numpy_type); break;
+        case TypeIndex::Float64: readAndInsertFloat<Float64>(column, nested_type, *header.numpy_type); break;
+        case TypeIndex::String: readAndInsertString<String>(column->getPtr(), nested_type, *header.numpy_type, false); break;
+        case TypeIndex::FixedString: readAndInsertString<String>(column->getPtr(), nested_type, *header.numpy_type, true); break;
+        default:
+            throw Exception(ErrorCodes::UNKNOWN_TYPE, "ClickHouse type {} is not supported for import from Npy format", nested_type->getName());
+    }
+}
+
+bool NpyRowInputFormat::readRow(MutableColumns & columns, RowReadExtension &  /*ext*/)
+{
+    if (in->eof())
+        return false;
+
+    auto & column = columns[0];
+    IColumn * current_column = column.get();
+    size_t elements_in_current_column = 1;
+    for (size_t i = 1; i != header.shape.size(); ++i)
+    {
+        auto * array_column = typeid_cast<ColumnArray *>(current_column);
+        if (!array_column)
+            throw Exception(ErrorCodes::BAD_ARGUMENTS, "Unexpected nesting level of column '{}', expected {}, got {}", column->getName(), header.shape.size() - 1, i - 1);
+        /// Fill offsets of array columns.
+        for (size_t j = 0; j != elements_in_current_column; ++j)
+            array_column->getOffsets().push_back(array_column->getOffsets().back() + header.shape[i]);
+        current_column = &array_column->getData();
+        elements_in_current_column *= header.shape[i];
+    }
+
+    for (size_t i = 0; i != elements_in_current_column; ++i)
+        readValue(current_column);
+
+    return true;
+}
+
+NpySchemaReader::NpySchemaReader(ReadBuffer & in_)
+    : ISchemaReader(in_) {}
+
+NamesAndTypesList NpySchemaReader::readSchema()
+{
+    NumpyHeader header = parseHeader(in);
+    DataTypePtr nested_type = getDataTypeFromNumpyType(header.numpy_type);
+    DataTypePtr result_type = createNestedArrayType(nested_type, header.shape.size());
+
+    return {{"array", result_type}};
+}
+
+void registerInputFormatNpy(FormatFactory & factory)
+{
+    factory.registerInputFormat("Npy", [](
+        ReadBuffer & buf,
+        const Block & sample,
+        IRowInputFormat::Params params,
+        const FormatSettings &)
+    {
+        return std::make_shared<NpyRowInputFormat>(buf, sample, std::move(params));
+    });
+
+    factory.markFormatSupportsSubsetOfColumns("Npy");
+}
+void registerNpySchemaReader(FormatFactory & factory)
+{
+    factory.registerSchemaReader("Npy", [](ReadBuffer & buf, const FormatSettings &)
+    {
+        return std::make_shared<NpySchemaReader>(buf);
+    });
+}
+
+}
diff --git a/src/Processors/Formats/Impl/NpyRowInputFormat.h b/src/Processors/Formats/Impl/NpyRowInputFormat.h
new file mode 100644
index 000000000000..ad32bdba3bf2
--- /dev/null
+++ b/src/Processors/Formats/Impl/NpyRowInputFormat.h
@@ -0,0 +1,65 @@
+#pragma once
+
+#include <vector>
+#include <Processors/Formats/IRowInputFormat.h>
+#include <Processors/Formats/ISchemaReader.h>
+#include <Formats/FormatSettings.h>
+#include <Columns/IColumn.h>
+#include <Core/Field.h>
+#include <Core/NamesAndTypes.h>
+#include <Core/Types.h>
+#include <Formats/NumpyDataTypes.h>
+
+namespace DB
+{
+
+class ReadBuffer;
+
+struct NumpyHeader
+{
+    std::vector<int> shape;
+    std::shared_ptr<NumpyDataType> numpy_type;
+};
+
+class NpyRowInputFormat final : public IRowInputFormat
+{
+public:
+    NpyRowInputFormat(ReadBuffer & in_, Block header_, Params params_);
+
+    String getName() const override { return "NpyRowInputFormat"; }
+
+private:
+    void readPrefix() override;
+    bool readRow(MutableColumns & columns, RowReadExtension &) override;
+    void readData(MutableColumns & columns);
+
+    template <typename T>
+    void readAndInsertInteger(IColumn * column, const DataTypePtr & data_type, const NumpyDataType & npy_type);
+
+    template <typename T>
+    void readAndInsertFloat(IColumn * column, const DataTypePtr & data_type, const NumpyDataType & npy_type);
+
+    template <typename T>
+    void readAndInsertString(MutableColumnPtr column, const DataTypePtr & data_type, const NumpyDataType & npy_type, bool is_fixed);
+
+    template <typename ColumnValue, typename DataValue>
+    void readBinaryValueAndInsert(MutableColumnPtr column, NumpyDataType::Endianness endianness);
+
+    void readRows(MutableColumns & columns);
+
+    void readValue(IColumn * column);
+
+    DataTypePtr nested_type;
+    NumpyHeader header;
+};
+
+class NpySchemaReader : public ISchemaReader
+{
+public:
+    explicit NpySchemaReader(ReadBuffer & in_);
+
+private:
+    NamesAndTypesList readSchema() override;
+};
+
+}
diff --git a/utils/check-style/aspell-ignore/en/aspell-dict.txt b/utils/check-style/aspell-ignore/en/aspell-dict.txt
index b43f9cab0f19..f772f58c2ba4 100644
--- a/utils/check-style/aspell-ignore/en/aspell-dict.txt
+++ b/utils/check-style/aspell-ignore/en/aspell-dict.txt
@@ -568,6 +568,7 @@ NumberOfDatabases
 NumberOfDetachedByUserParts
 NumberOfDetachedParts
 NumberOfTables
+NumPy
 OFNS
 OLAP
 OLTP
