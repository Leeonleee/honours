{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 14397,
  "instance_id": "ClickHouse__ClickHouse-14397",
  "issue_numbers": [
    "14114"
  ],
  "base_commit": "adf50fd7748fba30b0494040f886bffe780fffde",
  "patch": "diff --git a/src/Interpreters/MySQL/InterpretersMySQLDDLQuery.cpp b/src/Interpreters/MySQL/InterpretersMySQLDDLQuery.cpp\nindex 461dd997cd15..70916fe386df 100644\n--- a/src/Interpreters/MySQL/InterpretersMySQLDDLQuery.cpp\n+++ b/src/Interpreters/MySQL/InterpretersMySQLDDLQuery.cpp\n@@ -18,6 +18,7 @@\n #include <DataTypes/DataTypeNullable.h>\n #include <Parsers/MySQL/ASTDeclareIndex.h>\n #include <Common/quoteString.h>\n+#include <Common/assert_cast.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/InterpreterCreateQuery.h>\n #include <Storages/IStorage.h>\n@@ -124,8 +125,37 @@ static NamesAndTypesList getNames(const ASTFunction & expr, const Context & cont\n     return expression->getRequiredColumnsWithTypes();\n }\n \n+static NamesAndTypesList modifyPrimaryKeysToNonNullable(const NamesAndTypesList & primary_keys, NamesAndTypesList & columns)\n+{\n+    /// https://dev.mysql.com/doc/refman/5.7/en/create-table.html#create-table-indexes-keys\n+    /// PRIMARY KEY:\n+    /// A unique index where all key columns must be defined as NOT NULL.\n+    /// If they are not explicitly declared as NOT NULL, MySQL declares them so implicitly (and silently).\n+    /// A table can have only one PRIMARY KEY. The name of a PRIMARY KEY is always PRIMARY,\n+    /// which thus cannot be used as the name for any other kind of index.\n+    NamesAndTypesList non_nullable_primary_keys;\n+    for (const auto & primary_key : primary_keys)\n+    {\n+        if (!primary_key.type->isNullable())\n+            non_nullable_primary_keys.emplace_back(primary_key);\n+        else\n+        {\n+            non_nullable_primary_keys.emplace_back(\n+                NameAndTypePair(primary_key.name, assert_cast<const DataTypeNullable *>(primary_key.type.get())->getNestedType()));\n+\n+            for (auto & column : columns)\n+            {\n+                if (column.name == primary_key.name)\n+                    column.type = assert_cast<const DataTypeNullable *>(column.type.get())->getNestedType();\n+            }\n+        }\n+    }\n+\n+    return non_nullable_primary_keys;\n+}\n+\n static inline std::tuple<NamesAndTypesList, NamesAndTypesList, NamesAndTypesList, NameSet> getKeys(\n-    ASTExpressionList * columns_define, ASTExpressionList * indices_define, const Context & context, const NamesAndTypesList & columns)\n+    ASTExpressionList * columns_define, ASTExpressionList * indices_define, const Context & context, NamesAndTypesList & columns)\n {\n     NameSet increment_columns;\n     auto keys = makeASTFunction(\"tuple\");\n@@ -171,8 +201,9 @@ static inline std::tuple<NamesAndTypesList, NamesAndTypesList, NamesAndTypesList\n         }\n     }\n \n-    return std::make_tuple(\n-        getNames(*primary_keys, context, columns), getNames(*unique_keys, context, columns), getNames(*keys, context, columns), increment_columns);\n+    const auto & primary_keys_names_and_types = getNames(*primary_keys, context, columns);\n+    const auto & non_nullable_primary_keys_names_and_types = modifyPrimaryKeysToNonNullable(primary_keys_names_and_types, columns);\n+    return std::make_tuple(non_nullable_primary_keys_names_and_types, getNames(*unique_keys, context, columns), getNames(*keys, context, columns), increment_columns);\n }\n \n static String getUniqueColumnName(NamesAndTypesList columns_name_and_type, const String & prefix)\n@@ -201,14 +232,13 @@ static String getUniqueColumnName(NamesAndTypesList columns_name_and_type, const\n \n static ASTPtr getPartitionPolicy(const NamesAndTypesList & primary_keys)\n {\n-    const auto & numbers_partition = [&](const String & column_name, bool is_nullable, size_t type_max_size)\n+    const auto & numbers_partition = [&](const String & column_name, size_t type_max_size) -> ASTPtr\n     {\n-        ASTPtr column = std::make_shared<ASTIdentifier>(column_name);\n+        if (type_max_size <= 1000)\n+            return std::make_shared<ASTIdentifier>(column_name);\n \n-        if (is_nullable)\n-            column = makeASTFunction(\"assumeNotNull\", column);\n-\n-        return makeASTFunction(\"intDiv\", column, std::make_shared<ASTLiteral>(UInt64(type_max_size / 1000)));\n+        return makeASTFunction(\"intDiv\", std::make_shared<ASTIdentifier>(column_name),\n+           std::make_shared<ASTLiteral>(UInt64(type_max_size / 1000)));\n     };\n \n     ASTPtr best_partition;\n@@ -219,16 +249,12 @@ static ASTPtr getPartitionPolicy(const NamesAndTypesList & primary_keys)\n         WhichDataType which(type);\n \n         if (which.isNullable())\n-        {\n-            type = (static_cast<const DataTypeNullable &>(*type)).getNestedType();\n-            which = WhichDataType(type);\n-        }\n+            throw Exception(\"LOGICAL ERROR: MySQL primary key must be not null, it is a bug.\", ErrorCodes::LOGICAL_ERROR);\n \n         if (which.isDateOrDateTime())\n         {\n             /// In any case, date or datetime is always the best partitioning key\n-            ASTPtr res = std::make_shared<ASTIdentifier>(primary_key.name);\n-            return makeASTFunction(\"toYYYYMM\", primary_key.type->isNullable() ? makeASTFunction(\"assumeNotNull\", res) : res);\n+            return makeASTFunction(\"toYYYYMM\", std::make_shared<ASTIdentifier>(primary_key.name));\n         }\n \n         if (type->haveMaximumSizeOfValue() && (!best_size || type->getSizeOfValueInMemory() < best_size))\n@@ -236,25 +262,22 @@ static ASTPtr getPartitionPolicy(const NamesAndTypesList & primary_keys)\n             if (which.isInt8() || which.isUInt8())\n             {\n                 best_size = type->getSizeOfValueInMemory();\n-                best_partition = std::make_shared<ASTIdentifier>(primary_key.name);\n-\n-                if (primary_key.type->isNullable())\n-                    best_partition = makeASTFunction(\"assumeNotNull\", best_partition);\n+                best_partition = numbers_partition(primary_key.name, std::numeric_limits<UInt8>::max());\n             }\n             else if (which.isInt16() || which.isUInt16())\n             {\n                 best_size = type->getSizeOfValueInMemory();\n-                best_partition = numbers_partition(primary_key.name, primary_key.type->isNullable(), std::numeric_limits<UInt16>::max());\n+                best_partition = numbers_partition(primary_key.name, std::numeric_limits<UInt16>::max());\n             }\n             else if (which.isInt32() || which.isUInt32())\n             {\n                 best_size = type->getSizeOfValueInMemory();\n-                best_partition = numbers_partition(primary_key.name, primary_key.type->isNullable(), std::numeric_limits<UInt32>::max());\n+                best_partition = numbers_partition(primary_key.name, std::numeric_limits<UInt32>::max());\n             }\n             else if (which.isInt64() || which.isUInt64())\n             {\n                 best_size = type->getSizeOfValueInMemory();\n-                best_partition = numbers_partition(primary_key.name, primary_key.type->isNullable(), std::numeric_limits<UInt64>::max());\n+                best_partition = numbers_partition(primary_key.name, std::numeric_limits<UInt64>::max());\n             }\n         }\n     }\n@@ -266,12 +289,12 @@ static ASTPtr getOrderByPolicy(\n     const NamesAndTypesList & primary_keys, const NamesAndTypesList & unique_keys, const NamesAndTypesList & keys, const NameSet & increment_columns)\n {\n     NameSet order_by_columns_set;\n-    std::deque<std::vector<String>> order_by_columns_list;\n+    std::deque<NamesAndTypesList> order_by_columns_list;\n \n     const auto & add_order_by_expression = [&](const NamesAndTypesList & names_and_types)\n     {\n-        std::vector<String> increment_keys;\n-        std::vector<String> non_increment_keys;\n+        NamesAndTypesList increment_keys;\n+        NamesAndTypesList non_increment_keys;\n \n         for (const auto & [name, type] : names_and_types)\n         {\n@@ -280,13 +303,13 @@ static ASTPtr getOrderByPolicy(\n \n             if (increment_columns.count(name))\n             {\n-                increment_keys.emplace_back(name);\n                 order_by_columns_set.emplace(name);\n+                increment_keys.emplace_back(NameAndTypePair(name, type));\n             }\n             else\n             {\n                 order_by_columns_set.emplace(name);\n-                non_increment_keys.emplace_back(name);\n+                non_increment_keys.emplace_back(NameAndTypePair(name, type));\n             }\n         }\n \n@@ -305,8 +328,13 @@ static ASTPtr getOrderByPolicy(\n \n     for (const auto & order_by_columns : order_by_columns_list)\n     {\n-        for (const auto & order_by_column : order_by_columns)\n-            order_by_expression->arguments->children.emplace_back(std::make_shared<ASTIdentifier>(order_by_column));\n+        for (const auto & [name, type] : order_by_columns)\n+        {\n+            order_by_expression->arguments->children.emplace_back(std::make_shared<ASTIdentifier>(name));\n+\n+            if (type->isNullable())\n+                order_by_expression->arguments->children.back() = makeASTFunction(\"assumeNotNull\", order_by_expression->arguments->children.back());\n+        }\n     }\n \n     return order_by_expression;\ndiff --git a/src/Parsers/MySQL/ASTDeclareColumn.cpp b/src/Parsers/MySQL/ASTDeclareColumn.cpp\nindex 56a92291f061..6d21f9348587 100644\n--- a/src/Parsers/MySQL/ASTDeclareColumn.cpp\n+++ b/src/Parsers/MySQL/ASTDeclareColumn.cpp\n@@ -46,10 +46,10 @@ static inline bool parseColumnDeclareOptions(IParser::Pos & pos, ASTPtr & node,\n             OptionDescribe(\"DEFAULT\", \"default\", std::make_unique<ParserExpression>()),\n             OptionDescribe(\"ON UPDATE\", \"on_update\", std::make_unique<ParserExpression>()),\n             OptionDescribe(\"AUTO_INCREMENT\", \"auto_increment\", std::make_unique<ParserAlwaysTrue>()),\n-            OptionDescribe(\"UNIQUE\", \"unique_key\", std::make_unique<ParserAlwaysTrue>()),\n             OptionDescribe(\"UNIQUE KEY\", \"unique_key\", std::make_unique<ParserAlwaysTrue>()),\n-            OptionDescribe(\"KEY\", \"primary_key\", std::make_unique<ParserAlwaysTrue>()),\n             OptionDescribe(\"PRIMARY KEY\", \"primary_key\", std::make_unique<ParserAlwaysTrue>()),\n+            OptionDescribe(\"UNIQUE\", \"unique_key\", std::make_unique<ParserAlwaysTrue>()),\n+            OptionDescribe(\"KEY\", \"primary_key\", std::make_unique<ParserAlwaysTrue>()),\n             OptionDescribe(\"COMMENT\", \"comment\", std::make_unique<ParserStringLiteral>()),\n             OptionDescribe(\"CHARACTER SET\", \"charset_name\", std::make_unique<ParserCharsetName>()),\n             OptionDescribe(\"COLLATE\", \"collate\", std::make_unique<ParserCharsetName>()),\n",
  "test_patch": "diff --git a/src/Interpreters/MySQL/tests/gtest_create_rewritten.cpp b/src/Interpreters/MySQL/tests/gtest_create_rewritten.cpp\nindex b9bfe28ea1b4..b940e4e0c951 100644\n--- a/src/Interpreters/MySQL/tests/gtest_create_rewritten.cpp\n+++ b/src/Interpreters/MySQL/tests/gtest_create_rewritten.cpp\n@@ -103,26 +103,56 @@ TEST(MySQLCreateRewritten, PartitionPolicy)\n         {\"TIMESTAMP\", \"DateTime\", \" PARTITION BY toYYYYMM(key)\"}, {\"BOOLEAN\", \"Int8\", \" PARTITION BY key\"}\n     };\n \n-    const auto & replace_string = [](const String & str, const String & old_str, const String & new_str)\n+    for (const auto & [test_type, mapped_type, partition_policy] : test_types)\n     {\n-        String new_string = str;\n-        size_t pos = new_string.find(old_str);\n-        if (pos != std::string::npos)\n-            new_string = new_string.replace(pos, old_str.size(), new_str);\n-        return new_string;\n+        EXPECT_EQ(queryToString(tryRewrittenCreateQuery(\n+            \"CREATE TABLE `test_database`.`test_table_1` (`key` \" + test_type + \" PRIMARY KEY)\", context_holder.context)),\n+            \"CREATE TABLE test_database.test_table_1 (`key` \" + mapped_type + \", `_sign` Int8() MATERIALIZED 1, \"\n+            \"`_version` UInt64() MATERIALIZED 1) ENGINE = ReplacingMergeTree(_version)\" + partition_policy + \" ORDER BY tuple(key)\");\n+\n+        EXPECT_EQ(queryToString(tryRewrittenCreateQuery(\n+            \"CREATE TABLE `test_database`.`test_table_1` (`key` \" + test_type + \" NOT NULL PRIMARY KEY)\", context_holder.context)),\n+            \"CREATE TABLE test_database.test_table_1 (`key` \" + mapped_type + \", `_sign` Int8() MATERIALIZED 1, \"\n+            \"`_version` UInt64() MATERIALIZED 1) ENGINE = ReplacingMergeTree(_version)\" + partition_policy + \" ORDER BY tuple(key)\");\n+    }\n+}\n+\n+TEST(MySQLCreateRewritten, OrderbyPolicy)\n+{\n+    tryRegisterFunctions();\n+    const auto & context_holder = getContext();\n+\n+    std::vector<std::tuple<String, String, String>> test_types\n+    {\n+        {\"TINYINT\", \"Int8\", \" PARTITION BY key\"}, {\"SMALLINT\", \"Int16\", \" PARTITION BY intDiv(key, 65)\"},\n+        {\"MEDIUMINT\", \"Int32\", \" PARTITION BY intDiv(key, 4294967)\"}, {\"INT\", \"Int32\", \" PARTITION BY intDiv(key, 4294967)\"},\n+        {\"INTEGER\", \"Int32\", \" PARTITION BY intDiv(key, 4294967)\"}, {\"BIGINT\", \"Int64\", \" PARTITION BY intDiv(key, 18446744073709551)\"},\n+        {\"FLOAT\", \"Float32\", \"\"}, {\"DOUBLE\", \"Float64\", \"\"}, {\"VARCHAR(10)\", \"String\", \"\"}, {\"CHAR(10)\", \"String\", \"\"},\n+        {\"Date\", \"Date\", \" PARTITION BY toYYYYMM(key)\"}, {\"DateTime\", \"DateTime\", \" PARTITION BY toYYYYMM(key)\"},\n+        {\"TIMESTAMP\", \"DateTime\", \" PARTITION BY toYYYYMM(key)\"}, {\"BOOLEAN\", \"Int8\", \" PARTITION BY key\"}\n     };\n \n     for (const auto & [test_type, mapped_type, partition_policy] : test_types)\n     {\n         EXPECT_EQ(queryToString(tryRewrittenCreateQuery(\n-            \"CREATE TABLE `test_database`.`test_table_1` (`key` \" + test_type + \" PRIMARY KEY)\", context_holder.context)),\n-            \"CREATE TABLE test_database.test_table_1 (`key` Nullable(\" + mapped_type + \"), `_sign` Int8() MATERIALIZED 1, \"\n-            \"`_version` UInt64() MATERIALIZED 1) ENGINE = ReplacingMergeTree(_version)\" + replace_string(partition_policy, \"key\", \"assumeNotNull(key)\") + \" ORDER BY tuple(key)\");\n+            \"CREATE TABLE `test_database`.`test_table_1` (`key` \" + test_type + \" PRIMARY KEY, `key2` \" + test_type + \" UNIQUE KEY)\", context_holder.context)),\n+            \"CREATE TABLE test_database.test_table_1 (`key` \" + mapped_type + \", `key2` Nullable(\" + mapped_type + \"), `_sign` Int8() MATERIALIZED 1, \"\n+            \"`_version` UInt64() MATERIALIZED 1) ENGINE = ReplacingMergeTree(_version)\" + partition_policy + \" ORDER BY (key, assumeNotNull(key2))\");\n \n         EXPECT_EQ(queryToString(tryRewrittenCreateQuery(\n-            \"CREATE TABLE `test_database`.`test_table_1` (`key` \" + test_type + \" NOT NULL PRIMARY KEY)\", context_holder.context)),\n+            \"CREATE TABLE `test_database`.`test_table_1` (`key` \" + test_type + \" NOT NULL PRIMARY KEY, `key2` \" + test_type + \" NOT NULL UNIQUE KEY)\", context_holder.context)),\n+            \"CREATE TABLE test_database.test_table_1 (`key` \" + mapped_type + \", `key2` \" + mapped_type + \", `_sign` Int8() MATERIALIZED 1, \"\n+            \"`_version` UInt64() MATERIALIZED 1) ENGINE = ReplacingMergeTree(_version)\" + partition_policy + \" ORDER BY (key, key2)\");\n+\n+        EXPECT_EQ(queryToString(tryRewrittenCreateQuery(\n+            \"CREATE TABLE `test_database`.`test_table_1` (`key` \" + test_type + \" KEY UNIQUE KEY)\", context_holder.context)),\n             \"CREATE TABLE test_database.test_table_1 (`key` \" + mapped_type + \", `_sign` Int8() MATERIALIZED 1, \"\n             \"`_version` UInt64() MATERIALIZED 1) ENGINE = ReplacingMergeTree(_version)\" + partition_policy + \" ORDER BY tuple(key)\");\n+\n+        EXPECT_EQ(queryToString(tryRewrittenCreateQuery(\n+            \"CREATE TABLE `test_database`.`test_table_1` (`key` \" + test_type + \", `key2` \" + test_type + \" UNIQUE KEY, PRIMARY KEY(`key`, `key2`))\", context_holder.context)),\n+            \"CREATE TABLE test_database.test_table_1 (`key` \" + mapped_type + \", `key2` \" + mapped_type + \", `_sign` Int8() MATERIALIZED 1, \"\n+            \"`_version` UInt64() MATERIALIZED 1) ENGINE = ReplacingMergeTree(_version)\" + partition_policy + \" ORDER BY (key, key2)\");\n     }\n }\n \n",
  "problem_statement": "experimental MaterializeMySQL in 20.8 cannot synchronize \"create table\" commands\ni use\r\nmy steps\r\n1. create a new database ckdb on mysql, then  create table t1(a int, primary key(a)); and insert some rows\r\n2. SET allow_experimental_database_materialize_mysql=1; at clickhouse, \r\n3. CREATE DATABASE ckdb ENGINE = MaterializeMySQL('127.0.0.1:3306', 'ckdb', 'root', 'A123b_456');\r\n4. use ckdb and select * from t1 ok\r\n5. create table dzm as select * from others in mysql ----> cannot see dzm in clickhouse, but if select * from t1, reports\r\n```\r\nCode: 48. DB::Exception: Received from localhost:9000. DB::Exception: The ckdb.dzm cannot be materialized, because there is no primary keys..\r\n```\r\n6. create table t2(a int,b int primary a);----> cannot see t2 in clickhouse, , but if select * from t1, reports\r\n```\r\nCode: 44. DB::Exception: Received from localhost:9000. DB::Exception: Sorting key cannot contain nullable columns.\r\n```\r\n<del>7. if i drop ckdb and recreate it, all tables can be selected </del>\r\n7.if there are some 'bad' tables in a database, all tables in that database cannot be selected\r\n\r\nMake sure to check documentation https://clickhouse.yandex/docs/en/ first. If the question is concise and probably has a short answer, asking it in Telegram chat https://telegram.me/clickhouse_en is probably the fastest way to find the answer. For more complicated questions, consider asking them on StackOverflow with \"clickhouse\" tag https://stackoverflow.com/questions/tagged/clickhouse \r\n\r\nIf you still prefer GitHub issues, remove all this text and ask your question here.\r\n\n",
  "hints_text": "if there is no 'bad' tables,drop ckdb and recreate it, all tables can be selected.\r\n```\r\nmysql> create database ckdb3;\r\nQuery OK, 1 row affected (0.02 sec)\r\n\r\nmysql> use ckdb3;\r\nDatabase changed\r\n```\r\ncreate db in clickhouse now\r\n```\r\nCREATE DATABASE ckdb3\r\nENGINE = MaterializeMySQL('127.0.0.1:3306', 'ckdb3', 'root', 'A123b_456')\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.028 sec.\r\n\r\n```\r\ncreate a table in mysql's db\r\n```\r\nmysql> create table ta(a int,primary key(a));\r\nQuery OK, 0 rows affected (0.14 sec)\r\n\r\nmysql> insert into ta values(1),(2);\r\nQuery OK, 2 rows affected (0.00 sec)\r\nRecords: 2  Duplicates: 0  Warnings: 0\r\n\r\nmysql> commit;\r\nQuery OK, 0 rows affected (0.03 sec)\r\n```\r\ncannot see ta in clickhouse\r\n```\r\nUSE ckdb3\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.013 sec.\r\n\r\nSHOW TABLES\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.018 sec.\r\n\r\nSELECT *\r\nFROM ta\r\n\r\nReceived exception from server (version 20.8.1):\r\nCode: 60. DB::Exception: Received from localhost:9000. DB::Exception: Table ckdb3.ta doesn't exist..\r\n\r\n0 rows in set. Elapsed: 0.012 sec.\r\n```\r\ndrop and recreate db, ok\r\n```\r\nDROP DATABASE ckdb3\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.008 sec.\r\n\r\nCREATE DATABASE ckdb3\r\nENGINE = MaterializeMySQL('127.0.0.1:3306', 'ckdb3', 'root', 'A123b_456')\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.043 sec.\r\n\r\nSHOW TABLES\r\n\r\n\u250c\u2500name\u2500\u2510\r\n\u2502 t1   \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 0.016 sec.\r\n\r\nUSE ckdb3\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.007 sec.\r\n\r\nSHOW TABLES\r\n\r\n\u250c\u2500name\u2500\u2510\r\n\u2502 ta   \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 0.023 sec.\r\n\r\nSELECT *\r\nFROM ta\r\n\r\n\u250c\u2500a\u2500\u2510\r\n\u2502 1 \u2502\r\n\u2514\u2500\u2500\u2500\u2518\r\n\u250c\u2500a\u2500\u2510\r\n\u2502 2 \u2502\r\n\u2514\u2500\u2500\u2500\u2518\r\n\r\n2 rows in set. Elapsed: 0.031 sec.\r\n\r\n```\n1. Bad 'table' will break the MaterializeMySQL replciation thread, you should drop and re-create it.\r\n2.  CREATE TABLE ... SELECT statements are not allowed when using GTID-based replication(and the new version MaterializeMySQL ONLY support GTID mode), it's not safe or you will get:\r\n```\r\nERROR 1786 (HY000): Statement violates GTID consistency: CREATE TABLE ... SELECT.\r\n```\r\n\r\nsee [16.1.3.6 Restrictions on Replication with GTIDs](https://dev.mysql.com/doc/refman/5.7/en/replication-gtids-restrictions.html)\r\n\n> if there is no 'bad' tables,drop ckdb and recreate it, all tables can be selected.\r\n> \r\n> ```\r\n> mysql> create database ckdb3;\r\n> Query OK, 1 row affected (0.02 sec)\r\n> \r\n> mysql> use ckdb3;\r\n> Database changed\r\n> ```\r\n> \r\n> create db in clickhouse now\r\n> \r\n> ```\r\n> CREATE DATABASE ckdb3\r\n> ENGINE = MaterializeMySQL('127.0.0.1:3306', 'ckdb3', 'root', 'A123b_456')\r\n> \r\n> Ok.\r\n> \r\n> 0 rows in set. Elapsed: 0.028 sec.\r\n> ```\r\n> \r\n> create a table in mysql's db\r\n> \r\n> ```\r\n> mysql> create table ta(a int,primary key(a));\r\n> Query OK, 0 rows affected (0.14 sec)\r\n> \r\n> mysql> insert into ta values(1),(2);\r\n> Query OK, 2 rows affected (0.00 sec)\r\n> Records: 2  Duplicates: 0  Warnings: 0\r\n> \r\n> mysql> commit;\r\n> Query OK, 0 rows affected (0.03 sec)\r\n> ```\r\n> \r\n> cannot see ta in clickhouse\r\n> \r\n> ```\r\n> USE ckdb3\r\n> \r\n> Ok.\r\n> \r\n> 0 rows in set. Elapsed: 0.013 sec.\r\n> \r\n> SHOW TABLES\r\n> \r\n> Ok.\r\n> \r\n> 0 rows in set. Elapsed: 0.018 sec.\r\n> \r\n> SELECT *\r\n> FROM ta\r\n> \r\n> Received exception from server (version 20.8.1):\r\n> Code: 60. DB::Exception: Received from localhost:9000. DB::Exception: Table ckdb3.ta doesn't exist..\r\n> \r\n> 0 rows in set. Elapsed: 0.012 sec.\r\n> ```\r\n> \r\n> drop and recreate db, ok\r\n> \r\n> ```\r\n> DROP DATABASE ckdb3\r\n> \r\n> Ok.\r\n> \r\n> 0 rows in set. Elapsed: 0.008 sec.\r\n> \r\n> CREATE DATABASE ckdb3\r\n> ENGINE = MaterializeMySQL('127.0.0.1:3306', 'ckdb3', 'root', 'A123b_456')\r\n> \r\n> Ok.\r\n> \r\n> 0 rows in set. Elapsed: 0.043 sec.\r\n> \r\n> SHOW TABLES\r\n> \r\n> \u250c\u2500name\u2500\u2510\r\n> \u2502 t1   \u2502\r\n> \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n> \r\n> 1 rows in set. Elapsed: 0.016 sec.\r\n> \r\n> USE ckdb3\r\n> \r\n> Ok.\r\n> \r\n> 0 rows in set. Elapsed: 0.007 sec.\r\n> \r\n> SHOW TABLES\r\n> \r\n> \u250c\u2500name\u2500\u2510\r\n> \u2502 ta   \u2502\r\n> \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n> \r\n> 1 rows in set. Elapsed: 0.023 sec.\r\n> \r\n> SELECT *\r\n> FROM ta\r\n> \r\n> \u250c\u2500a\u2500\u2510\r\n> \u2502 1 \u2502\r\n> \u2514\u2500\u2500\u2500\u2518\r\n> \u250c\u2500a\u2500\u2510\r\n> \u2502 2 \u2502\r\n> \u2514\u2500\u2500\u2500\u2518\r\n> \r\n> 2 rows in set. Elapsed: 0.031 sec.\r\n> ```\r\nMaterializeMySQL has 2 steps for datas replication:\r\nStep1: full dumping with `select ... from ...` in transaction\r\nStep2: incremental dumping by binlog events\r\n\r\nHere it works because it's Step1, not Step2.",
  "created_at": "2020-09-02T05:07:44Z",
  "modified_files": [
    "src/Interpreters/MySQL/InterpretersMySQLDDLQuery.cpp",
    "src/Parsers/MySQL/ASTDeclareColumn.cpp"
  ],
  "modified_test_files": [
    "src/Interpreters/MySQL/tests/gtest_create_rewritten.cpp"
  ]
}