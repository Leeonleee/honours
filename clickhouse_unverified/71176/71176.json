{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 71176,
  "instance_id": "ClickHouse__ClickHouse-71176",
  "issue_numbers": [
    "70600"
  ],
  "base_commit": "8f7fc5e49fd683c4aad0d883a1f430a9b081dfdb",
  "patch": "diff --git a/src/Storages/StorageExternalDistributed.cpp b/src/Storages/StorageExternalDistributed.cpp\ndeleted file mode 100644\nindex ac560b58962e..000000000000\n--- a/src/Storages/StorageExternalDistributed.cpp\n+++ /dev/null\n@@ -1,233 +0,0 @@\n-#include <Storages/StorageExternalDistributed.h>\n-\n-#include <Core/Settings.h>\n-#include <Storages/StorageFactory.h>\n-#include <Interpreters/evaluateConstantExpression.h>\n-#include <Interpreters/InterpreterSelectQuery.h>\n-#include <Core/PostgreSQL/PoolWithFailover.h>\n-#include <Parsers/ASTLiteral.h>\n-#include <Parsers/ASTFunction.h>\n-#include <Parsers/ASTIdentifier.h>\n-#include <Common/parseAddress.h>\n-#include <Processors/QueryPlan/QueryPlan.h>\n-#include <Common/parseRemoteDescription.h>\n-#include <Storages/StorageMySQL.h>\n-#include <Storages/MySQL/MySQLSettings.h>\n-#include <Storages/StoragePostgreSQL.h>\n-#include <Storages/StorageURL.h>\n-#include <Storages/MySQL/MySQLHelpers.h>\n-#include <Storages/NamedCollectionsHelpers.h>\n-#include <Storages/checkAndGetLiteralArgument.h>\n-#include <Common/logger_useful.h>\n-#include <Processors/QueryPlan/UnionStep.h>\n-\n-\n-namespace DB\n-{\n-namespace Setting\n-{\n-    extern const SettingsUInt64 glob_expansion_max_elements;\n-    extern const SettingsUInt64 postgresql_connection_attempt_timeout;\n-    extern const SettingsBool postgresql_connection_pool_auto_close_connection;\n-    extern const SettingsUInt64 postgresql_connection_pool_retries;\n-    extern const SettingsUInt64 postgresql_connection_pool_size;\n-    extern const SettingsUInt64 postgresql_connection_pool_wait_timeout;\n-}\n-\n-namespace ErrorCodes\n-{\n-    extern const int BAD_ARGUMENTS;\n-}\n-\n-StorageExternalDistributed::StorageExternalDistributed(\n-    const StorageID & table_id_,\n-    std::unordered_set<StoragePtr> && shards_,\n-    const ColumnsDescription & columns_,\n-    const ConstraintsDescription & constraints_,\n-    const String & comment)\n-    : IStorage(table_id_)\n-    , shards(shards_)\n-{\n-    StorageInMemoryMetadata storage_metadata;\n-    storage_metadata.setColumns(columns_);\n-    storage_metadata.setConstraints(constraints_);\n-    storage_metadata.setComment(comment);\n-    setInMemoryMetadata(storage_metadata);\n-}\n-\n-void StorageExternalDistributed::read(\n-    QueryPlan & query_plan,\n-    const Names & column_names,\n-    const StorageSnapshotPtr & storage_snapshot,\n-    SelectQueryInfo & query_info,\n-    ContextPtr context,\n-    QueryProcessingStage::Enum processed_stage,\n-    size_t max_block_size,\n-    size_t num_streams)\n-{\n-    std::vector<std::unique_ptr<QueryPlan>> plans;\n-    for (const auto & shard : shards)\n-    {\n-        plans.emplace_back(std::make_unique<QueryPlan>());\n-        shard->read(\n-            *plans.back(),\n-            column_names,\n-            storage_snapshot,\n-            query_info,\n-            context,\n-            processed_stage,\n-            max_block_size,\n-            num_streams\n-        );\n-    }\n-\n-    if (plans.empty())\n-    {\n-        auto header = storage_snapshot->getSampleBlockForColumns(column_names);\n-        InterpreterSelectQuery::addEmptySourceToQueryPlan(query_plan, header, query_info);\n-    }\n-\n-    if (plans.size() == 1)\n-    {\n-        query_plan = std::move(*plans.front());\n-        return;\n-    }\n-\n-    Headers input_headers;\n-    input_headers.reserve(plans.size());\n-    for (auto & plan : plans)\n-        input_headers.emplace_back(plan->getCurrentHeader());\n-\n-    auto union_step = std::make_unique<UnionStep>(std::move(input_headers));\n-    query_plan.unitePlans(std::move(union_step), std::move(plans));\n-}\n-\n-void registerStorageExternalDistributed(StorageFactory & factory)\n-{\n-    factory.registerStorage(\"ExternalDistributed\", [](const StorageFactory::Arguments & args)\n-    {\n-        ASTs & engine_args = args.engine_args;\n-        if (engine_args.size() < 2)\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS,\n-                            \"Engine ExternalDistributed must have at least 2 arguments: \"\n-                            \"engine_name, named_collection and/or description\");\n-\n-        auto context = args.getLocalContext();\n-        const auto & settings = context->getSettingsRef();\n-        size_t max_addresses = settings[Setting::glob_expansion_max_elements];\n-        auto get_addresses = [&](const std::string addresses_expr)\n-        {\n-            return parseRemoteDescription(addresses_expr, 0, addresses_expr.size(), ',', max_addresses);\n-        };\n-\n-        std::unordered_set<StoragePtr> shards;\n-        ASTs inner_engine_args(engine_args.begin() + 1, engine_args.end());\n-\n-        ASTPtr * address_arg = nullptr;\n-\n-        /// If there is a named collection argument, named `addresses_expr`\n-        for (auto & node : inner_engine_args)\n-        {\n-            if (ASTFunction * func = node->as<ASTFunction>(); func && func->name == \"equals\" && func->arguments)\n-            {\n-                if (ASTExpressionList * func_args = func->arguments->as<ASTExpressionList>(); func_args && func_args->children.size() == 2)\n-                {\n-                    if (ASTIdentifier * arg_name = func_args->children[0]->as<ASTIdentifier>(); arg_name && arg_name->name() == \"addresses_expr\")\n-                    {\n-                        address_arg = &func_args->children[1];\n-                        break;\n-                    }\n-                }\n-            }\n-        }\n-\n-        /// Otherwise it is the first argument.\n-        if (!address_arg)\n-            address_arg = &inner_engine_args.at(0);\n-\n-        String addresses_expr = checkAndGetLiteralArgument<String>(*address_arg, \"addresses\");\n-        Strings shards_addresses = get_addresses(addresses_expr);\n-\n-        auto engine_name = checkAndGetLiteralArgument<String>(engine_args[0], \"engine_name\");\n-        if (engine_name == \"URL\")\n-        {\n-            auto format_settings = StorageURL::getFormatSettingsFromArgs(args);\n-            for (const auto & shard_address : shards_addresses)\n-            {\n-                *address_arg = std::make_shared<ASTLiteral>(shard_address);\n-                auto configuration = StorageURL::getConfiguration(inner_engine_args, context);\n-                auto uri_options = parseRemoteDescription(shard_address, 0, shard_address.size(), '|', max_addresses);\n-                if (uri_options.size() > 1)\n-                {\n-                    shards.insert(\n-                        std::make_shared<StorageURLWithFailover>(\n-                            uri_options, args.table_id, configuration.format, format_settings,\n-                            args.columns, args.constraints, context, configuration.compression_method));\n-                }\n-                else\n-                {\n-                    shards.insert(std::make_shared<StorageURL>(\n-                        shard_address, args.table_id, configuration.format, format_settings,\n-                        args.columns, args.constraints, String{}, context, configuration.compression_method));\n-                }\n-            }\n-        }\n-#if USE_MYSQL\n-        else if (engine_name == \"MySQL\")\n-        {\n-            MySQLSettings mysql_settings;\n-            for (const auto & shard_address : shards_addresses)\n-            {\n-                *address_arg = std::make_shared<ASTLiteral>(shard_address);\n-                auto configuration = StorageMySQL::getConfiguration(inner_engine_args, context, mysql_settings);\n-                configuration.addresses = parseRemoteDescriptionForExternalDatabase(shard_address, max_addresses, 3306);\n-                auto pool = createMySQLPoolWithFailover(configuration, mysql_settings);\n-                shards.insert(std::make_shared<StorageMySQL>(\n-                    args.table_id, std::move(pool), configuration.database, configuration.table,\n-                    /* replace_query = */ false, /* on_duplicate_clause = */ \"\",\n-                    args.columns, args.constraints, String{}, context, mysql_settings));\n-            }\n-        }\n-#endif\n-#if USE_LIBPQXX\n-        else if (engine_name == \"PostgreSQL\")\n-        {\n-            for (const auto & shard_address : shards_addresses)\n-            {\n-                *address_arg = std::make_shared<ASTLiteral>(shard_address);\n-                auto configuration = StoragePostgreSQL::getConfiguration(inner_engine_args, context);\n-                configuration.addresses = parseRemoteDescriptionForExternalDatabase(shard_address, max_addresses, 5432);\n-                auto pool = std::make_shared<postgres::PoolWithFailover>(\n-                    configuration,\n-                    settings[Setting::postgresql_connection_pool_size],\n-                    settings[Setting::postgresql_connection_pool_wait_timeout],\n-                    settings[Setting::postgresql_connection_pool_retries],\n-                    settings[Setting::postgresql_connection_pool_auto_close_connection],\n-                    settings[Setting::postgresql_connection_attempt_timeout]);\n-                shards.insert(std::make_shared<StoragePostgreSQL>(\n-                    args.table_id, std::move(pool), configuration.table, args.columns, args.constraints, String{}, context));\n-            }\n-        }\n-#endif\n-        else\n-        {\n-            throw Exception(\n-                ErrorCodes::BAD_ARGUMENTS,\n-                \"External storage engine {} is not supported for StorageExternalDistributed. \"\n-                \"Supported engines are: MySQL, PostgreSQL, URL\",\n-                engine_name);\n-        }\n-\n-        return std::make_shared<StorageExternalDistributed>(\n-            args.table_id,\n-            std::move(shards),\n-            args.columns,\n-            args.constraints,\n-            args.comment);\n-    },\n-    {\n-        .source_access_type = AccessType::SOURCES,\n-    });\n-}\n-\n-}\ndiff --git a/src/Storages/StorageExternalDistributed.h b/src/Storages/StorageExternalDistributed.h\ndeleted file mode 100644\nindex 56c7fe86f34f..000000000000\n--- a/src/Storages/StorageExternalDistributed.h\n+++ /dev/null\n@@ -1,43 +0,0 @@\n-#pragma once\n-\n-#include \"config.h\"\n-\n-#include <Storages/IStorage.h>\n-\n-\n-namespace DB\n-{\n-\n-/// Storages MySQL and PostgreSQL use ConnectionPoolWithFailover and support multiple replicas.\n-/// This class unites multiple storages with replicas into multiple shards with replicas.\n-/// A query to external database is passed to one replica on each shard, the result is united.\n-/// Replicas on each shard have the same priority, traversed replicas are moved to the end of the queue.\n-/// Similar approach is used for URL storage.\n-class StorageExternalDistributed final : public DB::IStorage\n-{\n-public:\n-    StorageExternalDistributed(\n-        const StorageID & table_id_,\n-        std::unordered_set<StoragePtr> && shards_,\n-        const ColumnsDescription & columns_,\n-        const ConstraintsDescription & constraints_,\n-        const String & comment);\n-\n-    std::string getName() const override { return \"ExternalDistributed\"; }\n-\n-    void read(\n-        QueryPlan & query_plan,\n-        const Names & column_names,\n-        const StorageSnapshotPtr & storage_snapshot,\n-        SelectQueryInfo & query_info,\n-        ContextPtr context,\n-        QueryProcessingStage::Enum processed_stage,\n-        size_t max_block_size,\n-        size_t num_streams) override;\n-\n-private:\n-    using Shards = std::unordered_set<StoragePtr>;\n-    Shards shards;\n-};\n-\n-}\ndiff --git a/src/Storages/registerStorages.cpp b/src/Storages/registerStorages.cpp\nindex cfd406ccbe26..d2c445c87068 100644\n--- a/src/Storages/registerStorages.cpp\n+++ b/src/Storages/registerStorages.cpp\n@@ -93,10 +93,6 @@ void registerStoragePostgreSQL(StorageFactory & factory);\n void registerStorageMaterializedPostgreSQL(StorageFactory & factory);\n #endif\n \n-#if USE_MYSQL || USE_LIBPQXX\n-void registerStorageExternalDistributed(StorageFactory & factory);\n-#endif\n-\n #if USE_FILELOG\n void registerStorageFileLog(StorageFactory & factory);\n #endif\n@@ -205,10 +201,6 @@ void registerStorages(bool use_legacy_mongodb_integration [[maybe_unused]])\n     registerStorageMaterializedPostgreSQL(factory);\n     #endif\n \n-    #if USE_MYSQL || USE_LIBPQXX\n-    registerStorageExternalDistributed(factory);\n-    #endif\n-\n     #if USE_SQLITE\n     registerStorageSQLite(factory);\n     #endif\ndiff --git a/src/TableFunctions/TableFunctionURL.cpp b/src/TableFunctions/TableFunctionURL.cpp\nindex 2bdc0b449e0d..8f4841a992b1 100644\n--- a/src/TableFunctions/TableFunctionURL.cpp\n+++ b/src/TableFunctions/TableFunctionURL.cpp\n@@ -6,7 +6,6 @@\n #include <Parsers/ASTFunction.h>\n #include <Parsers/ASTIdentifier.h>\n #include <Storages/ColumnsDescription.h>\n-#include <Storages/StorageExternalDistributed.h>\n #include <Storages/NamedCollectionsHelpers.h>\n #include <TableFunctions/TableFunctionFactory.h>\n #include <Analyzer/FunctionNode.h>\n",
  "test_patch": "diff --git a/tests/integration/test_storage_mysql/test.py b/tests/integration/test_storage_mysql/test.py\nindex 2fc62d7f5116..2d34a52c17bc 100644\n--- a/tests/integration/test_storage_mysql/test.py\n+++ b/tests/integration/test_storage_mysql/test.py\n@@ -386,100 +386,6 @@ def test_enum_type(started_cluster):\n     conn.close()\n \n \n-def test_mysql_distributed(started_cluster):\n-    table_name = \"test_replicas\"\n-\n-    conn1 = get_mysql_conn(started_cluster, started_cluster.mysql8_ip)\n-    conn2 = get_mysql_conn(started_cluster, started_cluster.mysql2_ip)\n-    conn3 = get_mysql_conn(started_cluster, started_cluster.mysql3_ip)\n-    conn4 = get_mysql_conn(started_cluster, started_cluster.mysql4_ip)\n-\n-    create_mysql_db(conn1, \"clickhouse\")\n-    create_mysql_db(conn2, \"clickhouse\")\n-    create_mysql_db(conn3, \"clickhouse\")\n-    create_mysql_db(conn4, \"clickhouse\")\n-\n-    create_mysql_table(conn1, table_name)\n-    create_mysql_table(conn2, table_name)\n-    create_mysql_table(conn3, table_name)\n-    create_mysql_table(conn4, table_name)\n-\n-    node2.query(\"DROP TABLE IF EXISTS test_replicas\")\n-\n-    # Storage with with 3 replicas\n-    node2.query(\n-        \"\"\"\n-        CREATE TABLE test_replicas\n-        (id UInt32, name String, age UInt32, money UInt32)\n-        ENGINE = MySQL('mysql{2|3|4}:3306', 'clickhouse', 'test_replicas', 'root', 'clickhouse'); \"\"\"\n-    )\n-\n-    # Fill remote tables with different data to be able to check\n-    nodes = [node1, node2, node2, node2]\n-    for i in range(1, 5):\n-        nodes[i - 1].query(\"DROP TABLE IF EXISTS test_replica{}\".format(i))\n-        nodes[i - 1].query(\n-            \"\"\"\n-            CREATE TABLE test_replica{}\n-            (id UInt32, name String, age UInt32, money UInt32)\n-            ENGINE = MySQL('mysql{}:3306', 'clickhouse', 'test_replicas', 'root', 'clickhouse');\"\"\".format(\n-                i, 80 if i == 1 else i\n-            )\n-        )\n-        nodes[i - 1].query(\n-            \"INSERT INTO test_replica{} (id, name) SELECT number, 'host{}' from numbers(10) \".format(\n-                i, i\n-            )\n-        )\n-\n-    # test multiple ports parsing\n-    result = node2.query(\n-        \"\"\"SELECT DISTINCT(name) FROM mysql('mysql{80|2|3}:3306', 'clickhouse', 'test_replicas', 'root', 'clickhouse'); \"\"\"\n-    )\n-    assert result == \"host1\\n\" or result == \"host2\\n\" or result == \"host3\\n\"\n-    result = node2.query(\n-        \"\"\"SELECT DISTINCT(name) FROM mysql('mysql80:3306|mysql2:3306|mysql3:3306', 'clickhouse', 'test_replicas', 'root', 'clickhouse'); \"\"\"\n-    )\n-    assert result == \"host1\\n\" or result == \"host2\\n\" or result == \"host3\\n\"\n-\n-    # check all replicas are traversed\n-    query = \"SELECT * FROM (\"\n-    for i in range(3):\n-        query += \"SELECT name FROM test_replicas UNION DISTINCT \"\n-    query += \"SELECT name FROM test_replicas) ORDER BY name\"\n-\n-    result = node2.query(query)\n-    assert result == \"host2\\nhost3\\nhost4\\n\"\n-\n-    # Storage with with two shards, each has 2 replicas\n-    node2.query(\"DROP TABLE IF EXISTS test_shards\")\n-\n-    node2.query(\n-        \"\"\"\n-        CREATE TABLE test_shards\n-        (id UInt32, name String, age UInt32, money UInt32)\n-        ENGINE = ExternalDistributed('MySQL', 'mysql{80|2}:3306,mysql{3|4}:3306', 'clickhouse', 'test_replicas', 'root', 'clickhouse'); \"\"\"\n-    )\n-\n-    # Check only one replica in each shard is used\n-    result = node2.query(\"SELECT DISTINCT(name) FROM test_shards ORDER BY name\")\n-    assert result == \"host1\\nhost3\\n\"\n-\n-    # check all replicas are traversed\n-    query = \"SELECT name FROM (\"\n-    for i in range(3):\n-        query += \"SELECT name FROM test_shards UNION DISTINCT \"\n-    query += \"SELECT name FROM test_shards) ORDER BY name\"\n-    result = node2.query(query)\n-    assert result == \"host1\\nhost2\\nhost3\\nhost4\\n\"\n-\n-    # disconnect mysql\n-    started_cluster.pause_container(\"mysql80\")\n-    result = node2.query(\"SELECT DISTINCT(name) FROM test_shards ORDER BY name\")\n-    started_cluster.unpause_container(\"mysql80\")\n-    assert result == \"host2\\nhost4\\n\" or result == \"host3\\nhost4\\n\"\n-\n-\n def test_external_settings(started_cluster):\n     table_name = \"test_external_settings\"\n     node1.query(f\"DROP TABLE IF EXISTS {table_name}\")\ndiff --git a/tests/integration/test_storage_postgresql/test.py b/tests/integration/test_storage_postgresql/test.py\nindex aaecc7537cfd..78bb1167d79b 100644\n--- a/tests/integration/test_storage_postgresql/test.py\n+++ b/tests/integration/test_storage_postgresql/test.py\n@@ -449,89 +449,6 @@ def node_insert_select(_):\n     node1.query(\"DROP TABLE test.stat;\")\n \n \n-def test_postgres_distributed(started_cluster):\n-    cursor0 = started_cluster.postgres_conn.cursor()\n-    cursor1 = started_cluster.postgres2_conn.cursor()\n-    cursor2 = started_cluster.postgres3_conn.cursor()\n-    cursor3 = started_cluster.postgres4_conn.cursor()\n-    cursors = [cursor0, cursor1, cursor2, cursor3]\n-\n-    for i in range(4):\n-        cursors[i].execute(\"DROP TABLE IF EXISTS test_replicas\")\n-        cursors[i].execute(\"CREATE TABLE test_replicas (id Integer, name Text)\")\n-        cursors[i].execute(\n-            f\"\"\"INSERT INTO test_replicas select i, 'host{i+1}' from generate_series(0, 99) as t(i);\"\"\"\n-        )\n-\n-    # test multiple ports parsing\n-    result = node2.query(\n-        \"\"\"SELECT DISTINCT(name) FROM postgresql('postgres{1|2|3}:5432', 'postgres', 'test_replicas', 'postgres', 'mysecretpassword'); \"\"\"\n-    )\n-    assert result == \"host1\\n\" or result == \"host2\\n\" or result == \"host3\\n\"\n-    result = node2.query(\n-        \"\"\"SELECT DISTINCT(name) FROM postgresql('postgres2:5431|postgres3:5432', 'postgres', 'test_replicas', 'postgres', 'mysecretpassword'); \"\"\"\n-    )\n-    assert result == \"host3\\n\" or result == \"host2\\n\"\n-\n-    # Create storage with with 3 replicas\n-    node2.query(\"DROP TABLE IF EXISTS test_replicas\")\n-    node2.query(\n-        \"\"\"\n-        CREATE TABLE test_replicas\n-        (id UInt32, name String)\n-        ENGINE = PostgreSQL('postgres{2|3|4}:5432', 'postgres', 'test_replicas', 'postgres', 'mysecretpassword'); \"\"\"\n-    )\n-\n-    # Check all replicas are traversed\n-    query = \"SELECT name FROM (\"\n-    for i in range(3):\n-        query += \"SELECT name FROM test_replicas UNION DISTINCT \"\n-    query += \"SELECT name FROM test_replicas) ORDER BY name\"\n-    result = node2.query(query)\n-    assert result == \"host2\\nhost3\\nhost4\\n\"\n-\n-    # Create storage with with two two shards, each has 2 replicas\n-    node2.query(\"DROP TABLE IF EXISTS test_shards\")\n-\n-    node2.query(\n-        \"\"\"\n-        CREATE TABLE test_shards\n-        (id UInt32, name String, age UInt32, money UInt32)\n-        ENGINE = ExternalDistributed('PostgreSQL', 'postgres{1|2}:5432,postgres{3|4}:5432', 'postgres', 'test_replicas', 'postgres', 'mysecretpassword'); \"\"\"\n-    )\n-\n-    # Check only one replica in each shard is used\n-    result = node2.query(\"SELECT DISTINCT(name) FROM test_shards ORDER BY name\")\n-    assert result == \"host1\\nhost3\\n\"\n-\n-    node2.query(\n-        \"\"\"\n-        CREATE TABLE test_shards2\n-        (id UInt32, name String, age UInt32, money UInt32)\n-        ENGINE = ExternalDistributed('PostgreSQL', postgres4, addresses_expr='postgres{1|2}:5432,postgres{3|4}:5432'); \"\"\"\n-    )\n-\n-    result = node2.query(\"SELECT DISTINCT(name) FROM test_shards2 ORDER BY name\")\n-    assert result == \"host1\\nhost3\\n\"\n-\n-    # Check all replicas are traversed\n-    query = \"SELECT name FROM (\"\n-    for i in range(3):\n-        query += \"SELECT name FROM test_shards UNION DISTINCT \"\n-    query += \"SELECT name FROM test_shards) ORDER BY name\"\n-    result = node2.query(query)\n-    assert result == \"host1\\nhost2\\nhost3\\nhost4\\n\"\n-\n-    # Disconnect postgres1\n-    started_cluster.pause_container(\"postgres1\")\n-    result = node2.query(\"SELECT DISTINCT(name) FROM test_shards ORDER BY name\")\n-    started_cluster.unpause_container(\"postgres1\")\n-    assert result == \"host2\\nhost4\\n\" or result == \"host3\\nhost4\\n\"\n-    node2.query(\"DROP TABLE test_shards2\")\n-    node2.query(\"DROP TABLE test_shards\")\n-    node2.query(\"DROP TABLE test_replicas\")\n-\n-\n def test_datetime_with_timezone(started_cluster):\n     cursor = started_cluster.postgres_conn.cursor()\n     cursor.execute(\"DROP TABLE IF EXISTS test_timezone\")\n@@ -850,6 +767,7 @@ def test_filter_pushdown(started_cluster):\n         \"INSERT INTO test_filter_pushdown.test_table VALUES (1, 10), (1, 110), (2, 0), (3, 33), (4, 0)\"\n     )\n \n+    node1.query(\"DROP TABLE IF EXISTS test_filter_pushdown_pg_table\")\n     node1.query(\n         \"\"\"\n         CREATE TABLE test_filter_pushdown_pg_table (id UInt32, value UInt32)\n@@ -857,12 +775,14 @@ def test_filter_pushdown(started_cluster):\n     \"\"\"\n     )\n \n+    node1.query(\"DROP TABLE IF EXISTS test_filter_pushdown_local_table\")\n     node1.query(\n         \"\"\"\n         CREATE TABLE test_filter_pushdown_local_table (id UInt32, value UInt32) ENGINE Memory AS SELECT * FROM test_filter_pushdown_pg_table\n     \"\"\"\n     )\n \n+    node1.query(\"DROP TABLE IF EXISTS ch_table\")\n     node1.query(\n         \"CREATE TABLE ch_table (id UInt32, pg_id UInt32) ENGINE MergeTree ORDER BY id\"\n     )\n",
  "problem_statement": "Remove `ExternalDistributed` engine\nIts logic is not generic enough, and its existence bothers me.\n",
  "hints_text": "",
  "created_at": "2024-10-29T08:58:46Z",
  "modified_files": [
    "src/Storages/StorageExternalDistributed.cpp",
    "src/Storages/StorageExternalDistributed.h",
    "src/Storages/registerStorages.cpp",
    "src/TableFunctions/TableFunctionURL.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_storage_mysql/test.py",
    "tests/integration/test_storage_postgresql/test.py"
  ]
}