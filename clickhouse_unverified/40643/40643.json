{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 40643,
  "instance_id": "ClickHouse__ClickHouse-40643",
  "issue_numbers": [
    "40637"
  ],
  "base_commit": "91ec3793dbb99731250ae75b32703cdb0a567f54",
  "patch": "diff --git a/src/Interpreters/DatabaseCatalog.cpp b/src/Interpreters/DatabaseCatalog.cpp\nindex 1ad3d0057cda..67fb256b1c9b 100644\n--- a/src/Interpreters/DatabaseCatalog.cpp\n+++ b/src/Interpreters/DatabaseCatalog.cpp\n@@ -19,6 +19,7 @@\n #include <Poco/Util/AbstractConfiguration.h>\n #include <Common/filesystemHelpers.h>\n #include <Common/noexcept_scope.h>\n+#include <Common/checkStackSize.h>\n \n #include \"config_core.h\"\n \n@@ -32,6 +33,7 @@\n #    include <Storages/PostgreSQL/StorageMaterializedPostgreSQL.h>\n #endif\n \n+\n namespace CurrentMetrics\n {\n     extern const Metric TablesToDropQueueSize;\n@@ -255,6 +257,8 @@ DatabaseAndTable DatabaseCatalog::getTableImpl(\n     ContextPtr context_,\n     std::optional<Exception> * exception) const\n {\n+    checkStackSize();\n+\n     if (!table_id)\n     {\n         if (exception)\ndiff --git a/src/Storages/StorageBuffer.cpp b/src/Storages/StorageBuffer.cpp\nindex c14584a382b7..3fc00a79bbe3 100644\n--- a/src/Storages/StorageBuffer.cpp\n+++ b/src/Storages/StorageBuffer.cpp\n@@ -102,6 +102,19 @@ std::unique_lock<std::mutex> StorageBuffer::Buffer::lockImpl(bool read) const\n }\n \n \n+StoragePtr StorageBuffer::getDestinationTable() const\n+{\n+    if (!destination_id)\n+        return {};\n+\n+    auto destination = DatabaseCatalog::instance().tryGetTable(destination_id, getContext());\n+    if (destination.get() == this)\n+        throw Exception(\"Destination table is myself. Will lead to infinite loop.\", ErrorCodes::INFINITE_LOOP);\n+\n+    return destination;\n+}\n+\n+\n StorageBuffer::StorageBuffer(\n     const StorageID & table_id_,\n     const ColumnsDescription & columns_,\n@@ -134,6 +147,7 @@ StorageBuffer::StorageBuffer(\n     }\n     else\n         storage_metadata.setColumns(columns_);\n+\n     storage_metadata.setConstraints(constraints_);\n     storage_metadata.setComment(comment);\n     setInMemoryMetadata(storage_metadata);\n@@ -193,13 +207,8 @@ QueryProcessingStage::Enum StorageBuffer::getQueryProcessingStage(\n     const StorageSnapshotPtr &,\n     SelectQueryInfo & query_info) const\n {\n-    if (destination_id)\n+    if (auto destination = getDestinationTable())\n     {\n-        auto destination = DatabaseCatalog::instance().getTable(destination_id, local_context);\n-\n-        if (destination.get() == this)\n-            throw Exception(\"Destination table is myself. Read will cause infinite loop.\", ErrorCodes::INFINITE_LOOP);\n-\n         /// TODO: Find a way to support projections for StorageBuffer\n         query_info.ignore_projections = true;\n         const auto & destination_metadata = destination->getInMemoryMetadataPtr();\n@@ -221,13 +230,8 @@ void StorageBuffer::read(\n {\n     const auto & metadata_snapshot = storage_snapshot->metadata;\n \n-    if (destination_id)\n+    if (auto destination = getDestinationTable())\n     {\n-        auto destination = DatabaseCatalog::instance().getTable(destination_id, local_context);\n-\n-        if (destination.get() == this)\n-            throw Exception(\"Destination table is myself. Read will cause infinite loop.\", ErrorCodes::INFINITE_LOOP);\n-\n         auto destination_lock = destination->lockForShare(local_context->getCurrentQueryId(), local_context->getSettingsRef().lock_acquire_timeout);\n \n         auto destination_metadata_snapshot = destination->getInMemoryMetadataPtr();\n@@ -521,8 +525,8 @@ class BufferSink : public SinkToStorage\n \n         auto block = getHeader().cloneWithColumns(chunk.getColumns());\n \n-        StoragePtr destination;\n-        if (storage.destination_id)\n+        StoragePtr destination = storage.getDestinationTable();\n+        if (destination)\n         {\n             destination = DatabaseCatalog::instance().tryGetTable(storage.destination_id, storage.getContext());\n             if (destination.get() == &storage)\n@@ -537,7 +541,7 @@ class BufferSink : public SinkToStorage\n         /// If the block already exceeds the maximum limit, then we skip the buffer.\n         if (rows > storage.max_thresholds.rows || bytes > storage.max_thresholds.bytes)\n         {\n-            if (storage.destination_id)\n+            if (destination)\n             {\n                 LOG_DEBUG(storage.log, \"Writing block with {} rows, {} bytes directly.\", rows, bytes);\n                 storage.writeBlockToDestination(block, destination);\n@@ -628,15 +632,9 @@ SinkToStoragePtr StorageBuffer::write(const ASTPtr & /*query*/, const StorageMet\n bool StorageBuffer::mayBenefitFromIndexForIn(\n     const ASTPtr & left_in_operand, ContextPtr query_context, const StorageMetadataPtr & /*metadata_snapshot*/) const\n {\n-    if (!destination_id)\n-        return false;\n-\n-    auto destination = DatabaseCatalog::instance().getTable(destination_id, query_context);\n-\n-    if (destination.get() == this)\n-        throw Exception(\"Destination table is myself. Read will cause infinite loop.\", ErrorCodes::INFINITE_LOOP);\n-\n-    return destination->mayBenefitFromIndexForIn(left_in_operand, query_context, destination->getInMemoryMetadataPtr());\n+    if (auto destination = getDestinationTable())\n+        return destination->mayBenefitFromIndexForIn(left_in_operand, query_context, destination->getInMemoryMetadataPtr());\n+    return false;\n }\n \n \n@@ -703,11 +701,8 @@ bool StorageBuffer::optimize(\n \n bool StorageBuffer::supportsPrewhere() const\n {\n-    if (!destination_id)\n-        return false;\n-    auto dest = DatabaseCatalog::instance().tryGetTable(destination_id, getContext());\n-    if (dest && dest.get() != this)\n-        return dest->supportsPrewhere();\n+    if (auto destination = getDestinationTable())\n+        return destination->supportsPrewhere();\n     return false;\n }\n \n@@ -834,7 +829,7 @@ bool StorageBuffer::flushBuffer(Buffer & buffer, bool check_thresholds, bool loc\n     Stopwatch watch;\n     try\n     {\n-        writeBlockToDestination(block_to_write, DatabaseCatalog::instance().tryGetTable(destination_id, getContext()));\n+        writeBlockToDestination(block_to_write, getDestinationTable());\n     }\n     catch (...)\n     {\n@@ -1010,14 +1005,10 @@ void StorageBuffer::checkAlterIsPossible(const AlterCommands & commands, Context\n std::optional<UInt64> StorageBuffer::totalRows(const Settings & settings) const\n {\n     std::optional<UInt64> underlying_rows;\n-    auto underlying = DatabaseCatalog::instance().tryGetTable(destination_id, getContext());\n-\n-    if (underlying)\n-        underlying_rows = underlying->totalRows(settings);\n-    if (!underlying_rows)\n-        return underlying_rows;\n+    if (auto destination = getDestinationTable())\n+        underlying_rows = destination->totalRows(settings);\n \n-    return total_writes.rows + *underlying_rows;\n+    return total_writes.rows + underlying_rows.value_or(0);\n }\n \n std::optional<UInt64> StorageBuffer::totalBytes(const Settings & /*settings*/) const\ndiff --git a/src/Storages/StorageBuffer.h b/src/Storages/StorageBuffer.h\nindex 200b3fc1838e..580742c0c846 100644\n--- a/src/Storages/StorageBuffer.h\n+++ b/src/Storages/StorageBuffer.h\n@@ -169,6 +169,8 @@ friend class BufferSink;\n     void backgroundFlush();\n     void reschedule();\n \n+    StoragePtr getDestinationTable() const;\n+\n     BackgroundSchedulePool & bg_pool;\n     BackgroundSchedulePoolTaskHolder flush_handle;\n };\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02391_recursive_buffer.reference b/tests/queries/0_stateless/02391_recursive_buffer.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/02391_recursive_buffer.sql b/tests/queries/0_stateless/02391_recursive_buffer.sql\nnew file mode 100644\nindex 000000000000..c0954ed834b6\n--- /dev/null\n+++ b/tests/queries/0_stateless/02391_recursive_buffer.sql\n@@ -0,0 +1,18 @@\n+-- Tags: no-parallel\n+-- because of system.tables poisoning\n+\n+DROP TABLE IF EXISTS test;\n+CREATE TABLE test (key UInt32) Engine = Buffer(currentDatabase(), test, 16, 10, 100, 10000, 1000000, 10000000, 100000000);\n+SELECT * FROM test; -- { serverError 269 }\n+SELECT * FROM system.tables WHERE table = 'test' AND database = currentDatabase() FORMAT Null; -- { serverError 269 }\n+DROP TABLE test;\n+\n+DROP TABLE IF EXISTS test1;\n+DROP TABLE IF EXISTS test2;\n+CREATE TABLE test1 (key UInt32) Engine = Buffer(currentDatabase(), test2, 16, 10, 100, 10000, 1000000, 10000000, 100000000);\n+CREATE TABLE test2 (key UInt32) Engine = Buffer(currentDatabase(), test1, 16, 10, 100, 10000, 1000000, 10000000, 100000000);\n+SELECT * FROM test1; -- { serverError 306 }\n+SELECT * FROM test2; -- { serverError 306 }\n+SELECT * FROM system.tables WHERE table IN ('test1', 'test2') AND database = currentDatabase(); -- { serverError 306 }\n+DROP TABLE test1;\n+DROP TABLE test2;\n",
  "problem_statement": "SegFault with \"recursive\" buffer table\nClickHouse crushed on request to system.tables if has an incorrect \"self-flushing\" buffer table.\r\n\r\n```\r\nxxxx :) CREATE TABLE test (key UInt32) Engine=Buffer(default, test, 16, 10, 100, 10000, 1000000, 10000000, 100000000);\r\n\r\n\r\nCREATE TABLE test\r\n(\r\n    `key` UInt32\r\n)\r\nENGINE = Buffer(default, test, 16, 10, 100, 10000, 1000000, 10000000, 100000000)\r\n\r\nQuery id: a90ea965-ac7c-420f-a947-f900b6b0d014\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.005 sec. \r\n\r\nxxxx :) select * from system.tables\r\n\r\nSELECT *\r\nFROM system.tables\r\n\r\nQuery id: bbb7d7eb-b782-4527-9803-ddc4f8703d5c\r\n\r\n[xxxx] 2022.08.25 21:44:05.507879 [ 841325 ] <Fatal> BaseDaemon: ########################################\r\n[xxxx] 2022.08.25 21:44:05.508036 [ 841325 ] <Fatal> BaseDaemon: (version 22.8.2.11 (official build), build id: F509FE73D83F8136) (from thread 841253) (query_id: bbb7d7eb-b782-4527-9803-ddc4f8703d5c) (query: select * from system.tables) Received signal Segmentation fault (11)\r\n[xxxx] 2022.08.25 21:44:05.508105 [ 841325 ] <Fatal> BaseDaemon: Address: 0x7f06c12f7ff8 Access: write. Attempted access has violated the permissions assigned to the memory area.\r\n[xxxx] 2022.08.25 21:44:05.508141 [ 841325 ] <Fatal> BaseDaemon: Stack trace: 0xa480065\r\n[xxxx] 2022.08.25 21:44:05.508200 [ 841325 ] <Fatal> BaseDaemon: 2. ? @ 0xa480065 in /usr/bin/clickhouse\r\n[xxxx] 2022.08.25 21:44:05.697982 [ 841325 ] <Fatal> BaseDaemon: Integrity check of the executable successfully passed (checksum: 26BBB329434F6C45E2D0312BCEE49FC1)\r\n\u2198 Progress: 0.00 rows, 0.00 B (0.00 rows/s., 0.00 B/s.)                                                                                                                                                   Exception on client:\r\nCode: 32. DB::Exception: Attempt to read after eof: while receiving packet from localhost:9000. (ATTEMPT_TO_READ_AFTER_EOF)\r\n\r\nConnecting to localhost:9000 as user default.\r\nCode: 210. DB::NetException: Connection reset by peer, while writing to socket ([::1]:9000). (NETWORK_ERROR)\r\n\r\n```\r\n\r\nFound on version 22.3.9.19, reproduced also on 22.8.2.11\r\n\n",
  "hints_text": "The bug is introduced in #9919.",
  "created_at": "2022-08-25T20:41:28Z",
  "modified_files": [
    "src/Interpreters/DatabaseCatalog.cpp",
    "src/Storages/StorageBuffer.cpp",
    "src/Storages/StorageBuffer.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02391_recursive_buffer.sql"
  ]
}