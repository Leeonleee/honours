{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 19572,
  "instance_id": "ClickHouse__ClickHouse-19572",
  "issue_numbers": [
    "19568"
  ],
  "base_commit": "813b2bcc7334672889bda8c148c324a28a126c98",
  "patch": "diff --git a/src/Interpreters/DDLWorker.cpp b/src/Interpreters/DDLWorker.cpp\nindex 6dab60f57d14..b1d9f872daa1 100644\n--- a/src/Interpreters/DDLWorker.cpp\n+++ b/src/Interpreters/DDLWorker.cpp\n@@ -727,9 +727,15 @@ void DDLWorker::processTask(DDLTask & task)\n                 }\n \n                 if (storage && taskShouldBeExecutedOnLeader(rewritten_ast, storage)  && !task.is_circular_replicated)\n+                {\n                     tryExecuteQueryOnLeaderReplica(task, storage, rewritten_query, task.entry_path, zookeeper);\n+                }\n                 else\n+                {\n+                    /// StoragePtr may cause DROP TABLE to hang\n+                    storage.reset();\n                     tryExecuteQuery(rewritten_query, task, task.execution_status);\n+                }\n             }\n             else\n                 tryExecuteQuery(rewritten_query, task, task.execution_status);\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01181_db_atomic_drop_on_cluster.reference b/tests/queries/0_stateless/01181_db_atomic_drop_on_cluster.reference\nnew file mode 100644\nindex 000000000000..5e2366c8a419\n--- /dev/null\n+++ b/tests/queries/0_stateless/01181_db_atomic_drop_on_cluster.reference\n@@ -0,0 +1,5 @@\n+localhost\t9000\t0\t\t0\t0\n+localhost\t9000\t0\t\t0\t0\n+localhost\t9000\t0\t\t0\t0\n+localhost\t9000\t0\t\t0\t0\n+localhost\t9000\t0\t\t0\t0\ndiff --git a/tests/queries/0_stateless/01181_db_atomic_drop_on_cluster.sql b/tests/queries/0_stateless/01181_db_atomic_drop_on_cluster.sql\nnew file mode 100644\nindex 000000000000..ca393c366171\n--- /dev/null\n+++ b/tests/queries/0_stateless/01181_db_atomic_drop_on_cluster.sql\n@@ -0,0 +1,6 @@\n+DROP TABLE IF EXISTS test_repl ON CLUSTER test_shard_localhost SYNC;\n+\n+CREATE TABLE test_repl ON CLUSTER test_shard_localhost (n UInt64) ENGINE ReplicatedMergeTree('/clickhouse/test_01181/{database}/test_repl','r1') ORDER BY tuple();\n+DETACH TABLE test_repl ON CLUSTER test_shard_localhost SYNC;\n+ATTACH TABLE test_repl ON CLUSTER test_shard_localhost;\n+DROP TABLE test_repl ON CLUSTER test_shard_localhost SYNC;\ndiff --git a/tests/queries/0_stateless/arcadia_skip_list.txt b/tests/queries/0_stateless/arcadia_skip_list.txt\nindex f2bac038e38f..98e33c21887f 100644\n--- a/tests/queries/0_stateless/arcadia_skip_list.txt\n+++ b/tests/queries/0_stateless/arcadia_skip_list.txt\n@@ -193,3 +193,4 @@\n 01660_sum_ubsan\n 01669_columns_declaration_serde\n 01666_blns\n+01181_db_atomic_drop_on_cluster\n",
  "problem_statement": "DROP TABLE default.test_repl ON CLUSTER 'default' SYNC failed for Atomic\n**Describe the bug**\r\nFor DATABASE ENGINE Atomic (used by Default for all databases from 20.10) \r\nwhen try to `DROP TALBE replicatedmergetree table ON CLUSTER ... SYNC`, query failed after `distributed_ddl_task_timeout` seconds\r\n`decrease `database_atomic_delay_before_drop_table_sec=1` and setup `database_atomic_wait_for_drop_and_detach_synchronously=1` for default user profile didn't help\r\n\r\n**How to reproduce**\r\njust look to https://gist.github.com/Slach/a7f2946a108883f6b1d5585b1b5b6b0d\r\n```\r\nbash -x ./reproduce.sh\r\n```\r\n\r\n* Which ClickHouse server version to use\r\nLatest official docker build\r\n\r\n* Non-default settings, if any\r\n```\r\n<yandex>\r\n    <database_atomic_delay_before_drop_table_sec>1</database_atomic_delay_before_drop_table_sec>\r\n    <profile>\r\n        <default>\r\n            <database_atomic_wait_for_drop_and_detach_synchronously>1</database_atomic_wait_for_drop_and_detach_synchronously>\r\n            <distributed_ddl_task_timeout>20</distributed_ddl_task_timeout>\r\n        </default>\r\n    </profile>\r\n</yandex>\r\n\r\n```\r\n\r\n**Expected behavior**\r\nSuccessfull DROP TABLE on cluster\r\n\r\n**Error message and/or stacktrace**\r\nCode: 159. DB::Exception: Received from localhost:9000. DB::Exception: Watching task /clickhouse/task_queue/ddl/query-0000000001 is executing longer than distributed_ddl_task_timeout (=20) seconds. There are 2 unfinished hosts (0 of them are currently active), they are going to execute the query in background.\r\n\r\n**Additional context**\r\ntable physically deleted, but Atomic engine doesn't return \"finished\" flag to Zookeeper `distributed_ddl` queue\r\n\r\n```\r\ndocker-compose exec clickhouse-0-0-0 clickhouse-client -q \"SELECT * FROM system.zookeeper WHERE path='/clickhouse/task_queue/ddl/query-0000000001/finished' FORMAT\r\nVertical\"\r\n```\r\n\r\nreturns empty result\r\n\r\n\n",
  "hints_text": "",
  "created_at": "2021-01-25T12:48:03Z"
}