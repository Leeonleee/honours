{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 48787,
  "instance_id": "ClickHouse__ClickHouse-48787",
  "issue_numbers": [
    "48774"
  ],
  "base_commit": "8989f3a2430a7378f04a5ee5f5e28e61676a850f",
  "patch": "diff --git a/docs/en/operations/server-configuration-parameters/settings.md b/docs/en/operations/server-configuration-parameters/settings.md\nindex 7c97d0ab6409..a9f0cc276ff5 100644\n--- a/docs/en/operations/server-configuration-parameters/settings.md\n+++ b/docs/en/operations/server-configuration-parameters/settings.md\n@@ -1045,7 +1045,7 @@ Default value: `0`.\n \n ## background_pool_size {#background_pool_size}\n \n-Sets the number of threads performing background merges and mutations for tables with MergeTree engines. This setting is also could be applied  at server startup from the `default` profile configuration for backward compatibility at the ClickHouse server start. You can only increase the number of threads at runtime. To lower the number of threads you have to restart the server. By adjusting this setting, you manage CPU and disk load. Smaller pool size utilizes less CPU and disk resources, but background processes advance slower which might eventually impact query performance.\n+Sets the number of threads performing background merges and mutations for tables with MergeTree engines. This setting is also could be applied at server startup from the `default` profile configuration for backward compatibility at the ClickHouse server start. You can only increase the number of threads at runtime. To lower the number of threads you have to restart the server. By adjusting this setting, you manage CPU and disk load. Smaller pool size utilizes less CPU and disk resources, but background processes advance slower which might eventually impact query performance.\n \n Before changing it, please also take a look at related MergeTree settings, such as [number_of_free_entries_in_pool_to_lower_max_size_of_merge](../../operations/settings/merge-tree-settings.md#number-of-free-entries-in-pool-to-lower-max-size-of-merge) and [number_of_free_entries_in_pool_to_execute_mutation](../../operations/settings/merge-tree-settings.md#number-of-free-entries-in-pool-to-execute-mutation).\n \n@@ -1063,8 +1063,8 @@ Default value: 16.\n \n ## background_merges_mutations_concurrency_ratio {#background_merges_mutations_concurrency_ratio}\n \n-Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently. For example if the ratio equals to 2 and\n-`background_pool_size` is set to 16 then ClickHouse can execute 32 background merges concurrently. This is possible, because background operation could be suspended and postponed. This is needed to give small merges more execution priority. You can only increase this ratio at runtime. To lower it you have to restart the server.\n+Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently. For example, if the ratio equals to 2 and\n+`background_pool_size` is set to 16 then ClickHouse can execute 32 background merges concurrently. This is possible, because background operations could be suspended and postponed. This is needed to give small merges more execution priority. You can only increase this ratio at runtime. To lower it you have to restart the server.\n The same as for `background_pool_size` setting `background_merges_mutations_concurrency_ratio` could be applied from the `default` profile for backward compatibility.\n \n Possible values:\n@@ -1079,6 +1079,33 @@ Default value: 2.\n <background_merges_mutations_concurrency_ratio>3</background_merges_mutations_concurrency_ratio>\n ```\n \n+## merges_mutations_memory_usage_soft_limit {#merges_mutations_memory_usage_soft_limit}\n+\n+Sets the limit on how much RAM is allowed to use for performing merge and mutation operations.\n+Zero means unlimited.\n+If ClickHouse reaches this limit, it won't schedule any new background merge or mutation operations but will continue to execute already scheduled tasks.\n+\n+Possible values:\n+\n+-   Any positive integer.\n+\n+**Example**\n+\n+```xml\n+<merges_mutations_memory_usage_soft_limit>0</merges_mutations_memory_usage_soft_limit>\n+```\n+\n+## merges_mutations_memory_usage_to_ram_ratio {#merges_mutations_memory_usage_to_ram_ratio}\n+\n+The default `merges_mutations_memory_usage_soft_limit` value is calculated as `memory_amount * merges_mutations_memory_usage_to_ram_ratio`.\n+\n+Default value: `0.5`.\n+\n+**See also**\n+\n+-   [max_memory_usage](../../operations/settings/query-complexity.md#settings_max_memory_usage)\n+-   [merges_mutations_memory_usage_soft_limit](#merges_mutations_memory_usage_soft_limit)\n+\n ## background_merges_mutations_scheduling_policy {#background_merges_mutations_scheduling_policy}\n \n Algorithm used to select next merge or mutation to be executed by background thread pool. Policy may be changed at runtime without server restart.\ndiff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex 8c0d50bae55c..cba7a4c47788 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -135,6 +135,7 @@ namespace CurrentMetrics\n     extern const Metric Revision;\n     extern const Metric VersionInteger;\n     extern const Metric MemoryTracking;\n+    extern const Metric MergesMutationsMemoryTracking;\n     extern const Metric MaxDDLEntryID;\n     extern const Metric MaxPushedDDLEntryID;\n }\n@@ -1225,6 +1226,25 @@ try\n             total_memory_tracker.setDescription(\"(total)\");\n             total_memory_tracker.setMetric(CurrentMetrics::MemoryTracking);\n \n+            size_t merges_mutations_memory_usage_soft_limit = server_settings_.merges_mutations_memory_usage_soft_limit;\n+\n+            size_t default_merges_mutations_server_memory_usage = static_cast<size_t>(memory_amount * server_settings_.merges_mutations_memory_usage_to_ram_ratio);\n+            if (merges_mutations_memory_usage_soft_limit == 0 || merges_mutations_memory_usage_soft_limit > default_merges_mutations_server_memory_usage)\n+            {\n+                merges_mutations_memory_usage_soft_limit = default_merges_mutations_server_memory_usage;\n+                LOG_WARNING(log, \"Setting merges_mutations_memory_usage_soft_limit was set to {}\"\n+                    \" ({} available * {:.2f} merges_mutations_memory_usage_to_ram_ratio)\",\n+                    formatReadableSizeWithBinarySuffix(merges_mutations_memory_usage_soft_limit),\n+                    formatReadableSizeWithBinarySuffix(memory_amount),\n+                    server_settings_.merges_mutations_memory_usage_to_ram_ratio);\n+            }\n+\n+            LOG_INFO(log, \"Merges and mutations memory limit is set to {}\",\n+                formatReadableSizeWithBinarySuffix(merges_mutations_memory_usage_soft_limit));\n+            background_memory_tracker.setSoftLimit(merges_mutations_memory_usage_soft_limit);\n+            background_memory_tracker.setDescription(\"(background)\");\n+            background_memory_tracker.setMetric(CurrentMetrics::MergesMutationsMemoryTracking);\n+\n             total_memory_tracker.setAllowUseJemallocMemory(server_settings_.allow_use_jemalloc_memory);\n \n             auto * global_overcommit_tracker = global_context->getGlobalOvercommitTracker();\ndiff --git a/src/Common/CurrentMetrics.cpp b/src/Common/CurrentMetrics.cpp\nindex 81c1481e2de6..ea248d996a78 100644\n--- a/src/Common/CurrentMetrics.cpp\n+++ b/src/Common/CurrentMetrics.cpp\n@@ -53,6 +53,7 @@\n     M(QueryThread, \"Number of query processing threads\") \\\n     M(ReadonlyReplica, \"Number of Replicated tables that are currently in readonly state due to re-initialization after ZooKeeper session loss or due to startup without ZooKeeper configured.\") \\\n     M(MemoryTracking, \"Total amount of memory (bytes) allocated by the server.\") \\\n+    M(MergesMutationsMemoryTracking, \"Total amount of memory (bytes) allocated by background tasks (merges and mutations).\") \\\n     M(EphemeralNode, \"Number of ephemeral nodes hold in ZooKeeper.\") \\\n     M(ZooKeeperSession, \"Number of sessions (connections) to ZooKeeper. Should be no more than one, because using more than one connection to ZooKeeper may lead to bugs due to lack of linearizability (stale reads) that ZooKeeper consistency model allows.\") \\\n     M(ZooKeeperWatch, \"Number of watches (event subscriptions) in ZooKeeper.\") \\\ndiff --git a/src/Common/MemoryTracker.cpp b/src/Common/MemoryTracker.cpp\nindex 674d8d469af4..81cac2617c54 100644\n--- a/src/Common/MemoryTracker.cpp\n+++ b/src/Common/MemoryTracker.cpp\n@@ -96,12 +96,17 @@ using namespace std::chrono_literals;\n static constexpr size_t log_peak_memory_usage_every = 1ULL << 30;\n \n MemoryTracker total_memory_tracker(nullptr, VariableContext::Global);\n+MemoryTracker background_memory_tracker(&total_memory_tracker, VariableContext::User, false);\n \n std::atomic<Int64> MemoryTracker::free_memory_in_allocator_arenas;\n \n MemoryTracker::MemoryTracker(VariableContext level_) : parent(&total_memory_tracker), level(level_) {}\n MemoryTracker::MemoryTracker(MemoryTracker * parent_, VariableContext level_) : parent(parent_), level(level_) {}\n-\n+MemoryTracker::MemoryTracker(MemoryTracker * parent_, VariableContext level_, bool log_peak_memory_usage_in_destructor_)\n+    : parent(parent_)\n+    , log_peak_memory_usage_in_destructor(log_peak_memory_usage_in_destructor_)\n+    , level(level_)\n+{}\n \n MemoryTracker::~MemoryTracker()\n {\n@@ -528,3 +533,10 @@ void MemoryTracker::setOrRaiseProfilerLimit(Int64 value)\n     while ((value == 0 || old_value < value) && !profiler_limit.compare_exchange_weak(old_value, value))\n         ;\n }\n+\n+bool canEnqueueBackgroundTask()\n+{\n+    auto limit = background_memory_tracker.getSoftLimit();\n+    auto amount = background_memory_tracker.get();\n+    return limit == 0 || amount < limit;\n+}\ndiff --git a/src/Common/MemoryTracker.h b/src/Common/MemoryTracker.h\nindex 0d7748856bd7..4e29d40c953d 100644\n--- a/src/Common/MemoryTracker.h\n+++ b/src/Common/MemoryTracker.h\n@@ -98,6 +98,7 @@ class MemoryTracker\n \n     explicit MemoryTracker(VariableContext level_ = VariableContext::Thread);\n     explicit MemoryTracker(MemoryTracker * parent_, VariableContext level_ = VariableContext::Thread);\n+    MemoryTracker(MemoryTracker * parent_, VariableContext level_, bool log_peak_memory_usage_in_destructor_);\n \n     ~MemoryTracker();\n \n@@ -110,6 +111,22 @@ class MemoryTracker\n         return amount.load(std::memory_order_relaxed);\n     }\n \n+    // Merges and mutations may pass memory ownership to other threads thus in the end of execution\n+    // MemoryTracker for background task may have a non-zero counter.\n+    // This method is intended to fix the counter inside of background_memory_tracker.\n+    // NOTE: We can't use alloc/free methods to do it, because they also will change the value inside\n+    // of total_memory_tracker.\n+    void adjustOnBackgroundTaskEnd(const MemoryTracker * child)\n+    {\n+        auto background_memory_consumption = child->amount.load(std::memory_order_relaxed);\n+        amount.fetch_sub(background_memory_consumption, std::memory_order_relaxed);\n+\n+        // Also fix CurrentMetrics::MergesMutationsMemoryTracking\n+        auto metric_loaded = metric.load(std::memory_order_relaxed);\n+        if (metric_loaded != CurrentMetrics::end())\n+            CurrentMetrics::sub(metric_loaded, background_memory_consumption);\n+    }\n+\n     Int64 getPeak() const\n     {\n         return peak.load(std::memory_order_relaxed);\n@@ -220,3 +237,6 @@ class MemoryTracker\n };\n \n extern MemoryTracker total_memory_tracker;\n+extern MemoryTracker background_memory_tracker;\n+\n+bool canEnqueueBackgroundTask();\ndiff --git a/src/Core/ServerSettings.h b/src/Core/ServerSettings.h\nindex aabc89cc6d75..2d8c37783db8 100644\n--- a/src/Core/ServerSettings.h\n+++ b/src/Core/ServerSettings.h\n@@ -40,6 +40,8 @@ namespace DB\n     M(String, temporary_data_in_cache, \"\", \"Cache disk name for temporary data.\", 0) \\\n     M(UInt64, max_server_memory_usage, 0, \"Limit on total memory usage. Zero means Unlimited.\", 0) \\\n     M(Double, max_server_memory_usage_to_ram_ratio, 0.9, \"Same as max_server_memory_usage but in to ram ratio. Allows to lower max memory on low-memory systems.\", 0) \\\n+    M(UInt64, merges_mutations_memory_usage_soft_limit, 0, \"Limit on total memory usage for merges and mutations. Zero means Unlimited.\", 0) \\\n+    M(Double, merges_mutations_memory_usage_to_ram_ratio, 0.5, \"Same as merges_mutations_memory_usage_soft_limit but in to ram ratio. Allows to lower memory limit on low-memory systems.\", 0) \\\n     M(Bool, allow_use_jemalloc_memory, true, \"Allows to use jemalloc memory.\", 0) \\\n     \\\n     M(UInt64, max_concurrent_queries, 0, \"Limit on total number of concurrently executed queries. Zero means Unlimited.\", 0) \\\ndiff --git a/src/Interpreters/ThreadStatusExt.cpp b/src/Interpreters/ThreadStatusExt.cpp\nindex fd4a6b5e9966..559652fe56c0 100644\n--- a/src/Interpreters/ThreadStatusExt.cpp\n+++ b/src/Interpreters/ThreadStatusExt.cpp\n@@ -84,6 +84,7 @@ ThreadGroupPtr ThreadGroup::createForBackgroundProcess(ContextPtr storage_contex\n     group->memory_tracker.setProfilerStep(settings.memory_profiler_step);\n     group->memory_tracker.setSampleProbability(settings.memory_profiler_sample_probability);\n     group->memory_tracker.setSoftLimit(settings.memory_overcommit_ratio_denominator);\n+    group->memory_tracker.setParent(&background_memory_tracker);\n     if (settings.memory_tracker_fault_probability > 0.0)\n         group->memory_tracker.setFaultProbability(settings.memory_tracker_fault_probability);\n \ndiff --git a/src/Storages/MergeTree/MergeList.cpp b/src/Storages/MergeTree/MergeList.cpp\nindex 0bf662921ad3..d54079bc7a53 100644\n--- a/src/Storages/MergeTree/MergeList.cpp\n+++ b/src/Storages/MergeTree/MergeList.cpp\n@@ -78,4 +78,9 @@ MergeInfo MergeListElement::getInfo() const\n     return res;\n }\n \n+MergeListElement::~MergeListElement()\n+{\n+    background_memory_tracker.adjustOnBackgroundTaskEnd(&getMemoryTracker());\n+}\n+\n }\ndiff --git a/src/Storages/MergeTree/MergeList.h b/src/Storages/MergeTree/MergeList.h\nindex 9c8c2ebd1e4e..d8271a66b45b 100644\n--- a/src/Storages/MergeTree/MergeList.h\n+++ b/src/Storages/MergeTree/MergeList.h\n@@ -113,6 +113,8 @@ struct MergeListElement : boost::noncopyable\n     MergeListElement * ptr() { return this; }\n \n     MergeListElement & ref() { return *this; }\n+\n+    ~MergeListElement();\n };\n \n /** Maintains a list of currently running merges.\ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex 34bf5d55270e..6cb3ce35e5b7 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -7,6 +7,7 @@\n #include <base/sort.h>\n #include <Backups/BackupEntriesCollector.h>\n #include <Databases/IDatabase.h>\n+#include <Common/MemoryTracker.h>\n #include <Common/escapeForFileName.h>\n #include <Common/ProfileEventsScope.h>\n #include <Common/typeid_cast.h>\n@@ -41,6 +42,7 @@\n #include <Processors/QueryPlan/QueryPlan.h>\n #include <Processors/QueryPlan/BuildQueryPipelineSettings.h>\n #include <Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h>\n+#include <fmt/core.h>\n \n namespace DB\n {\n@@ -918,7 +920,14 @@ MergeMutateSelectedEntryPtr StorageMergeTree::selectPartsToMerge(\n \n     SelectPartsDecision select_decision = SelectPartsDecision::CANNOT_SELECT;\n \n-    if (partition_id.empty())\n+    if (!canEnqueueBackgroundTask())\n+    {\n+        if (out_disable_reason)\n+            *out_disable_reason = fmt::format(\"Current background tasks memory usage ({}) is more than the limit ({})\",\n+                formatReadableSizeWithBinarySuffix(background_memory_tracker.get()),\n+                formatReadableSizeWithBinarySuffix(background_memory_tracker.getSoftLimit()));\n+    }\n+    else if (partition_id.empty())\n     {\n         UInt64 max_source_parts_size = merger_mutator.getMaxSourcePartsSizeForMerge();\n         bool merge_with_ttl_allowed = getTotalMergesWithTTLInMergeList() < data_settings->max_number_of_merges_with_ttl_in_pool;\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 5cd02c33d554..4a36cf03c2aa 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -5,6 +5,7 @@\n \n #include <base/hex.h>\n #include <Common/Macros.h>\n+#include <Common/MemoryTracker.h>\n #include <Common/ProfileEventsScope.h>\n #include <Common/StringUtils/StringUtils.h>\n #include <Common/ZooKeeper/KeeperException.h>\n@@ -3223,7 +3224,14 @@ void StorageReplicatedMergeTree::mergeSelectingTask()\n \n         auto merges_and_mutations_queued = queue.countMergesAndPartMutations();\n         size_t merges_and_mutations_sum = merges_and_mutations_queued.merges + merges_and_mutations_queued.mutations;\n-        if (merges_and_mutations_sum >= storage_settings_ptr->max_replicated_merges_in_queue)\n+        if (!canEnqueueBackgroundTask())\n+        {\n+            LOG_TRACE(log, \"Reached memory limit for the background tasks ({}), so won't select new parts to merge or mutate.\"\n+                \"Current background tasks memory usage: {}.\",\n+                formatReadableSizeWithBinarySuffix(background_memory_tracker.getSoftLimit()),\n+                formatReadableSizeWithBinarySuffix(background_memory_tracker.get()));\n+        }\n+        else if (merges_and_mutations_sum >= storage_settings_ptr->max_replicated_merges_in_queue)\n         {\n             LOG_TRACE(log, \"Number of queued merges ({}) and part mutations ({})\"\n                 \" is greater than max_replicated_merges_in_queue ({}), so won't select new parts to merge or mutate.\",\n",
  "test_patch": "diff --git a/tests/integration/test_merges_memory_limit/__init__.py b/tests/integration/test_merges_memory_limit/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_merges_memory_limit/test.py b/tests/integration/test_merges_memory_limit/test.py\nnew file mode 100644\nindex 000000000000..e663f3280cc7\n--- /dev/null\n+++ b/tests/integration/test_merges_memory_limit/test.py\n@@ -0,0 +1,39 @@\n+import pytest\n+\n+from helpers.cluster import ClickHouseCluster\n+\n+cluster = ClickHouseCluster(__file__)\n+\n+node = cluster.add_instance(\"node\")\n+\n+\n+@pytest.fixture(scope=\"module\", autouse=True)\n+def start_cluster():\n+    try:\n+        cluster.start()\n+        yield cluster\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def test_memory_limit_success():\n+    node.query(\n+        \"CREATE TABLE test_merge_oom ENGINE=AggregatingMergeTree ORDER BY id EMPTY AS SELECT number%1024 AS id, arrayReduce( 'groupArrayState', arrayMap( x-> randomPrintableASCII(100), range(8192))) fat_state FROM numbers(20000)\"\n+    )\n+    node.query(\"SYSTEM STOP MERGES test_merge_oom\")\n+    node.query(\n+        \"INSERT INTO test_merge_oom SELECT number%1024 AS id, arrayReduce( 'groupArrayState', arrayMap( x-> randomPrintableASCII(100), range(8192))) fat_state FROM numbers(3000)\"\n+    )\n+    node.query(\n+        \"INSERT INTO test_merge_oom SELECT number%1024 AS id, arrayReduce( 'groupArrayState', arrayMap( x-> randomPrintableASCII(100), range(8192))) fat_state FROM numbers(3000)\"\n+    )\n+    node.query(\n+        \"INSERT INTO test_merge_oom SELECT number%1024 AS id, arrayReduce( 'groupArrayState', arrayMap( x-> randomPrintableASCII(100), range(8192))) fat_state FROM numbers(3000)\"\n+    )\n+\n+    _, error = node.query_and_get_answer_with_error(\n+        \"SYSTEM START MERGES test_merge_oom;SET optimize_throw_if_noop=1;OPTIMIZE TABLE test_merge_oom FINAL\"\n+    )\n+\n+    assert not error\n+    node.query(\"DROP TABLE test_merge_oom\")\n",
  "problem_statement": "ThreadSanitizer: use of an invalid mutex (e.g. uninitialized or destroyed)\nhttps://s3.amazonaws.com/clickhouse-test-reports/45819/d17abc9e89990dc36594a178d4cff6fbff2bf414/stress_test__tsan_.html\r\n\r\n```\r\nWARNING: ThreadSanitizer: use of an invalid mutex (e.g. uninitialized or destroyed) (pid=38762)\r\n    #0 pthread_mutex_lock <null> (clickhouse+0xce2be9a) (BuildId: eeeb4b8c47df3a26a45b773beefba242cb57015a)\r\n    #1 Poco::MutexImpl::lockImpl() build_docker/./base/poco/Foundation/include/Poco/Mutex_POSIX.h:60:9 (clickhouse+0x1cd08050) (BuildId: eeeb4b8c47df3a26a45b773beefba242cb57015a)\r\n    #2 Poco::Mutex::lock() build_docker/./base/poco/Foundation/include/Poco/Mutex.h:198:5 (clickhouse+0x1cd08050)\r\n    #3 Poco::ScopedLock<Poco::Mutex>::ScopedLock(Poco::Mutex&) build_docker/./base/poco/Foundation/include/Poco/ScopedLock.h:37:61 (clickhouse+0x1cd08050)\r\n    #4 Poco::Logger::get(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) build_docker/./base/poco/Foundation/src/Logger.cpp:285:20 (clickhouse+0x23fa129f) (BuildId: eeeb4b8c47df3a26a45b773beefba242cb57015a)\r\n    #5 MemoryTracker::logPeakMemoryUsage() build_docker/./src/Common/MemoryTracker.cpp:126:5 (clickhouse+0x14f5d59e) (BuildId: eeeb4b8c47df3a26a45b773beefba242cb57015a)\r\n    #6 MemoryTracker::~MemoryTracker() build_docker/./src/Common/MemoryTracker.cpp:113:13 (clickhouse+0x14f5d4f2) (BuildId: eeeb4b8c47df3a26a45b773beefba242cb57015a)\r\n    #7 cxa_at_exit_callback_installed_at(void*) crtstuff.c (clickhouse+0xce4b1ca) (BuildId: eeeb4b8c47df3a26a45b773beefba242cb57015a)\r\n    #8 __cxx_global_var_init.3 build_docker/./src/Common/MemoryTracker.cpp (clickhouse+0x14f61a3f) (BuildId: eeeb4b8c47df3a26a45b773beefba242cb57015a)\r\n    #9 _GLOBAL__sub_I_MemoryTracker.cpp build_docker/./src/Common/MemoryTracker.cpp (clickhouse+0x14f61a3f)\r\n\r\n  Location is global 'Poco::Logger::_mapMtx' of size 40 at 0x00002949c9d0 (clickhouse+0x2949c9d0)\r\n\r\n  Mutex M0 (0x00002949c9d0) created at:\r\n    [failed to restore the stack]\r\n\r\nSUMMARY: ThreadSanitizer: use of an invalid mutex (e.g. uninitialized or destroyed) (/usr/bin/clickhouse+0xce2be9a) (BuildId: eeeb4b8c47df3a26a45b773beefba242cb57015a) in pthread_mutex_lock\r\n```\n",
  "hints_text": "https://s3.amazonaws.com/clickhouse-test-reports/45819/d17abc9e89990dc36594a178d4cff6fbff2bf414/stateless_tests__tsan__s3_storage__[5/5].html",
  "created_at": "2023-04-14T14:52:05Z",
  "modified_files": [
    "docs/en/operations/server-configuration-parameters/settings.md",
    "programs/server/Server.cpp",
    "src/Common/CurrentMetrics.cpp",
    "src/Common/MemoryTracker.cpp",
    "src/Common/MemoryTracker.h",
    "src/Core/ServerSettings.h",
    "src/Interpreters/ThreadStatusExt.cpp",
    "src/Storages/MergeTree/MergeList.cpp",
    "src/Storages/MergeTree/MergeList.h",
    "src/Storages/StorageMergeTree.cpp",
    "src/Storages/StorageReplicatedMergeTree.cpp"
  ],
  "modified_test_files": [
    "b/tests/integration/test_merges_memory_limit/test.py"
  ]
}