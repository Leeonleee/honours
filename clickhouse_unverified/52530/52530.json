{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 52530,
  "instance_id": "ClickHouse__ClickHouse-52530",
  "issue_numbers": [
    "52433"
  ],
  "base_commit": "40f53c46591df74ce300f06d8df8558cb1a9e86e",
  "patch": "diff --git a/src/Interpreters/MutationsInterpreter.cpp b/src/Interpreters/MutationsInterpreter.cpp\nindex 25c52ad89257..e50f8488cac4 100644\n--- a/src/Interpreters/MutationsInterpreter.cpp\n+++ b/src/Interpreters/MutationsInterpreter.cpp\n@@ -113,13 +113,14 @@ QueryTreeNodePtr prepareQueryAffectedQueryTree(const std::vector<MutationCommand\n ColumnDependencies getAllColumnDependencies(\n     const StorageMetadataPtr & metadata_snapshot,\n     const NameSet & updated_columns,\n-    const std::function<bool(const String & file_name)> & has_index_or_projection)\n+    const StorageInMemoryMetadata::HasDependencyCallback & has_dependency)\n {\n     NameSet new_updated_columns = updated_columns;\n     ColumnDependencies dependencies;\n+\n     while (!new_updated_columns.empty())\n     {\n-        auto new_dependencies = metadata_snapshot->getColumnDependencies(new_updated_columns, true, has_index_or_projection);\n+        auto new_dependencies = metadata_snapshot->getColumnDependencies(new_updated_columns, true, has_dependency);\n         new_updated_columns.clear();\n         for (const auto & dependency : new_dependencies)\n         {\n@@ -292,9 +293,14 @@ bool MutationsInterpreter::Source::materializeTTLRecalculateOnly() const\n     return data && data->getSettings()->materialize_ttl_recalculate_only;\n }\n \n-bool MutationsInterpreter::Source::hasIndexOrProjection(const String & file_name) const\n+bool MutationsInterpreter::Source::hasSecondaryIndex(const String & name) const\n {\n-    return part && part->checksums.has(file_name);\n+    return part && part->hasSecondaryIndex(name);\n+}\n+\n+bool MutationsInterpreter::Source::hasProjection(const String & name) const\n+{\n+    return part && part->hasProjection(name);\n }\n \n static Names getAvailableColumnsWithVirtuals(StorageMetadataPtr metadata_snapshot, const IStorage & storage)\n@@ -533,13 +539,24 @@ void MutationsInterpreter::prepare(bool dry_run)\n         validateUpdateColumns(source, metadata_snapshot, updated_columns, column_to_affected_materialized);\n     }\n \n-    std::function<bool(const String & file_name)> has_index_or_projection\n-        = [&](const String & file_name) { return source.hasIndexOrProjection(file_name); };\n+    StorageInMemoryMetadata::HasDependencyCallback has_dependency =\n+        [&](const String & name, ColumnDependency::Kind kind)\n+    {\n+        if (kind == ColumnDependency::PROJECTION)\n+            return source.hasProjection(name);\n+\n+        if (kind == ColumnDependency::SKIP_INDEX)\n+            return source.hasSecondaryIndex(name);\n+\n+        return true;\n+    };\n \n     if (settings.recalculate_dependencies_of_updated_columns)\n-        dependencies = getAllColumnDependencies(metadata_snapshot, updated_columns, has_index_or_projection);\n+        dependencies = getAllColumnDependencies(metadata_snapshot, updated_columns, has_dependency);\n \n+    bool has_alter_delete = false;\n     std::vector<String> read_columns;\n+\n     /// First, break a sequence of commands into stages.\n     for (auto & command : commands)\n     {\n@@ -558,6 +575,7 @@ void MutationsInterpreter::prepare(bool dry_run)\n                 predicate = makeASTFunction(\"isZeroOrNull\", predicate);\n \n             stages.back().filters.push_back(predicate);\n+            has_alter_delete = true;\n         }\n         else if (command.type == MutationCommand::UPDATE)\n         {\n@@ -692,8 +710,7 @@ void MutationsInterpreter::prepare(bool dry_run)\n             if (it == std::cend(indices_desc))\n                 throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unknown index: {}\", command.index_name);\n \n-            if (!source.hasIndexOrProjection(\"skp_idx_\" + it->name + \".idx\")\n-                && !source.hasIndexOrProjection(\"skp_idx_\" + it->name + \".idx2\"))\n+            if (!source.hasSecondaryIndex(it->name))\n             {\n                 auto query = (*it).expression_list_ast->clone();\n                 auto syntax_result = TreeRewriter(context).analyze(query, all_columns);\n@@ -707,7 +724,7 @@ void MutationsInterpreter::prepare(bool dry_run)\n         {\n             mutation_kind.set(MutationKind::MUTATE_INDEX_PROJECTION);\n             const auto & projection = projections_desc.get(command.projection_name);\n-            if (!source.hasIndexOrProjection(projection.getDirectoryName()))\n+            if (!source.hasProjection(projection.name))\n             {\n                 for (const auto & column : projection.required_columns)\n                     dependencies.emplace(column, ColumnDependency::PROJECTION);\n@@ -731,8 +748,9 @@ void MutationsInterpreter::prepare(bool dry_run)\n             {\n                 // just recalculate ttl_infos without remove expired data\n                 auto all_columns_vec = all_columns.getNames();\n-                auto new_dependencies = metadata_snapshot->getColumnDependencies(\n-                    NameSet(all_columns_vec.begin(), all_columns_vec.end()), false, has_index_or_projection);\n+                auto all_columns_set = NameSet(all_columns_vec.begin(), all_columns_vec.end());\n+                auto new_dependencies = metadata_snapshot->getColumnDependencies(all_columns_set, false, has_dependency);\n+\n                 for (const auto & dependency : new_dependencies)\n                 {\n                     if (dependency.kind == ColumnDependency::TTL_EXPRESSION)\n@@ -757,8 +775,8 @@ void MutationsInterpreter::prepare(bool dry_run)\n                 }\n \n                 auto all_columns_vec = all_columns.getNames();\n-                auto all_dependencies = getAllColumnDependencies(\n-                    metadata_snapshot, NameSet(all_columns_vec.begin(), all_columns_vec.end()), has_index_or_projection);\n+                auto all_columns_set = NameSet(all_columns_vec.begin(), all_columns_vec.end());\n+                auto all_dependencies = getAllColumnDependencies(metadata_snapshot, all_columns_set, has_dependency);\n \n                 for (const auto & dependency : all_dependencies)\n                 {\n@@ -767,7 +785,7 @@ void MutationsInterpreter::prepare(bool dry_run)\n                 }\n \n                 /// Recalc only skip indices and projections of columns which could be updated by TTL.\n-                auto new_dependencies = metadata_snapshot->getColumnDependencies(new_updated_columns, true, has_index_or_projection);\n+                auto new_dependencies = metadata_snapshot->getColumnDependencies(new_updated_columns, true, has_dependency);\n                 for (const auto & dependency : new_dependencies)\n                 {\n                     if (dependency.kind == ColumnDependency::SKIP_INDEX || dependency.kind == ColumnDependency::PROJECTION)\n@@ -861,30 +879,44 @@ void MutationsInterpreter::prepare(bool dry_run)\n \n     for (const auto & index : metadata_snapshot->getSecondaryIndices())\n     {\n-        if (source.hasIndexOrProjection(\"skp_idx_\" + index.name + \".idx\") || source.hasIndexOrProjection(\"skp_idx_\" + index.name + \".idx2\"))\n+        if (!source.hasSecondaryIndex(index.name))\n+            continue;\n+\n+        if (has_alter_delete)\n         {\n-            const auto & index_cols = index.expression->getRequiredColumns();\n-            bool changed = std::any_of(\n-                index_cols.begin(),\n-                index_cols.end(),\n-                [&](const auto & col) { return updated_columns.contains(col) || changed_columns.contains(col); });\n-            if (changed)\n-                materialized_indices.insert(index.name);\n+            materialized_indices.insert(index.name);\n+            continue;\n         }\n+\n+        const auto & index_cols = index.expression->getRequiredColumns();\n+        bool changed = std::any_of(\n+            index_cols.begin(),\n+            index_cols.end(),\n+            [&](const auto & col) { return updated_columns.contains(col) || changed_columns.contains(col); });\n+\n+        if (changed)\n+            materialized_indices.insert(index.name);\n     }\n \n     for (const auto & projection : metadata_snapshot->getProjections())\n     {\n-        if (source.hasIndexOrProjection(projection.getDirectoryName()))\n+        if (!source.hasProjection(projection.name))\n+            continue;\n+\n+        if (has_alter_delete)\n         {\n-            const auto & projection_cols = projection.required_columns;\n-            bool changed = std::any_of(\n-                projection_cols.begin(),\n-                projection_cols.end(),\n-                [&](const auto & col) { return updated_columns.contains(col) || changed_columns.contains(col); });\n-            if (changed)\n-                materialized_projections.insert(projection.name);\n+            materialized_projections.insert(projection.name);\n+            continue;\n         }\n+\n+        const auto & projection_cols = projection.required_columns;\n+        bool changed = std::any_of(\n+            projection_cols.begin(),\n+            projection_cols.end(),\n+            [&](const auto & col) { return updated_columns.contains(col) || changed_columns.contains(col); });\n+\n+        if (changed)\n+            materialized_projections.insert(projection.name);\n     }\n \n     /// Stages might be empty when we materialize skip indices or projections which don't add any\ndiff --git a/src/Interpreters/MutationsInterpreter.h b/src/Interpreters/MutationsInterpreter.h\nindex d783b503531c..9b4caaae2313 100644\n--- a/src/Interpreters/MutationsInterpreter.h\n+++ b/src/Interpreters/MutationsInterpreter.h\n@@ -120,7 +120,8 @@ class MutationsInterpreter\n         bool supportsLightweightDelete() const;\n         bool hasLightweightDeleteMask() const;\n         bool materializeTTLRecalculateOnly() const;\n-        bool hasIndexOrProjection(const String & file_name) const;\n+        bool hasSecondaryIndex(const String & name) const;\n+        bool hasProjection(const String & name) const;\n \n         void read(\n             Stage & first_stage,\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\nindex 7050a98a4bc0..1ab8dc7fb053 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n@@ -1983,6 +1983,12 @@ IndexSize IMergeTreeDataPart::getSecondaryIndexSize(const String & secondary_ind\n     return ColumnSize{};\n }\n \n+bool IMergeTreeDataPart::hasSecondaryIndex(const String & index_name) const\n+{\n+    auto file_name = INDEX_FILE_PREFIX + index_name;\n+    return checksums.has(file_name + \".idx\") || checksums.has(file_name + \".idx2\");\n+}\n+\n void IMergeTreeDataPart::accumulateColumnSizes(ColumnToSize & column_to_size) const\n {\n     for (const auto & [column_name, size] : columns_sizes)\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.h b/src/Storages/MergeTree/IMergeTreeDataPart.h\nindex af6906e004da..bfb472ca50dc 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.h\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.h\n@@ -122,6 +122,9 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     /// Otherwise return information about secondary index size on disk.\n     IndexSize getSecondaryIndexSize(const String & secondary_index_name) const;\n \n+    /// Returns true if there is materialized index with specified name in part.\n+    bool hasSecondaryIndex(const String & index_name) const;\n+\n     /// Return information about column size on disk for all columns in part\n     ColumnSize getTotalColumnsSize() const { return total_columns_size; }\n \ndiff --git a/src/Storages/MergeTree/MutateTask.cpp b/src/Storages/MergeTree/MutateTask.cpp\nindex 491c36433cab..5143d9d5bb8e 100644\n--- a/src/Storages/MergeTree/MutateTask.cpp\n+++ b/src/Storages/MergeTree/MutateTask.cpp\n@@ -453,6 +453,7 @@ static ExecuteTTLType shouldExecuteTTL(const StorageMetadataPtr & metadata_snaps\n /// Return set of indices which should be recalculated during mutation also\n /// wraps input stream into additional expression stream\n static std::set<MergeTreeIndexPtr> getIndicesToRecalculate(\n+    const MergeTreeDataPartPtr & source_part,\n     QueryPipelineBuilder & builder,\n     const StorageMetadataPtr & metadata_snapshot,\n     ContextPtr context,\n@@ -463,10 +464,15 @@ static std::set<MergeTreeIndexPtr> getIndicesToRecalculate(\n     std::set<MergeTreeIndexPtr> indices_to_recalc;\n     ASTPtr indices_recalc_expr_list = std::make_shared<ASTExpressionList>();\n     const auto & indices = metadata_snapshot->getSecondaryIndices();\n+    bool is_full_part_storage = isFullPartStorage(source_part->getDataPartStorage());\n \n     for (const auto & index : indices)\n     {\n-        if (materialized_indices.contains(index.name))\n+        bool need_recalculate =\n+            materialized_indices.contains(index.name)\n+            || (!is_full_part_storage && source_part->hasSecondaryIndex(index.name));\n+\n+        if (need_recalculate)\n         {\n             if (indices_to_recalc.insert(index_factory.get(index)).second)\n             {\n@@ -496,15 +502,23 @@ static std::set<MergeTreeIndexPtr> getIndicesToRecalculate(\n }\n \n static std::set<ProjectionDescriptionRawPtr> getProjectionsToRecalculate(\n+    const MergeTreeDataPartPtr & source_part,\n     const StorageMetadataPtr & metadata_snapshot,\n     const NameSet & materialized_projections)\n {\n     std::set<ProjectionDescriptionRawPtr> projections_to_recalc;\n+    bool is_full_part_storage = isFullPartStorage(source_part->getDataPartStorage());\n+\n     for (const auto & projection : metadata_snapshot->getProjections())\n     {\n-        if (materialized_projections.contains(projection.name))\n+        bool need_recalculate =\n+            materialized_projections.contains(projection.name)\n+            || (!is_full_part_storage && source_part->hasProjection(projection.name));\n+\n+        if (need_recalculate)\n             projections_to_recalc.insert(&projection);\n     }\n+\n     return projections_to_recalc;\n }\n \n@@ -1279,14 +1293,20 @@ class MutateAllPartColumnsTask : public IExecutableTask\n                 removed_indices.insert(command.column_name);\n         }\n \n+        bool is_full_part_storage = isFullPartStorage(ctx->new_data_part->getDataPartStorage());\n         const auto & indices = ctx->metadata_snapshot->getSecondaryIndices();\n+\n         MergeTreeIndices skip_indices;\n         for (const auto & idx : indices)\n         {\n             if (removed_indices.contains(idx.name))\n                 continue;\n \n-            if (ctx->materialized_indices.contains(idx.name))\n+            bool need_recalculate =\n+                ctx->materialized_indices.contains(idx.name)\n+                || (!is_full_part_storage && ctx->source_part->hasSecondaryIndex(idx.name));\n+\n+            if (need_recalculate)\n             {\n                 skip_indices.push_back(MergeTreeIndexFactory::instance().get(idx));\n             }\n@@ -1319,7 +1339,11 @@ class MutateAllPartColumnsTask : public IExecutableTask\n             if (removed_projections.contains(projection.name))\n                 continue;\n \n-            if (ctx->materialized_projections.contains(projection.name))\n+            bool need_recalculate =\n+                ctx->materialized_projections.contains(projection.name)\n+                || (!is_full_part_storage && ctx->source_part->hasProjection(projection.name));\n+\n+            if (need_recalculate)\n             {\n                 ctx->projections_to_build.push_back(&projection);\n             }\n@@ -1920,9 +1944,16 @@ bool MutateTask::prepare()\n     else /// TODO: check that we modify only non-key columns in this case.\n     {\n         ctx->indices_to_recalc = MutationHelpers::getIndicesToRecalculate(\n-            ctx->mutating_pipeline_builder, ctx->metadata_snapshot, ctx->context, ctx->materialized_indices);\n+            ctx->source_part,\n+            ctx->mutating_pipeline_builder,\n+            ctx->metadata_snapshot,\n+            ctx->context,\n+            ctx->materialized_indices);\n \n-        ctx->projections_to_recalc = MutationHelpers::getProjectionsToRecalculate(ctx->metadata_snapshot, ctx->materialized_projections);\n+        ctx->projections_to_recalc = MutationHelpers::getProjectionsToRecalculate(\n+            ctx->source_part,\n+            ctx->metadata_snapshot,\n+            ctx->materialized_projections);\n \n         ctx->files_to_skip = MutationHelpers::collectFilesToSkip(\n             ctx->source_part,\ndiff --git a/src/Storages/StorageInMemoryMetadata.cpp b/src/Storages/StorageInMemoryMetadata.cpp\nindex afe753498644..af285a953dc6 100644\n--- a/src/Storages/StorageInMemoryMetadata.cpp\n+++ b/src/Storages/StorageInMemoryMetadata.cpp\n@@ -239,7 +239,7 @@ bool StorageInMemoryMetadata::hasAnyGroupByTTL() const\n ColumnDependencies StorageInMemoryMetadata::getColumnDependencies(\n     const NameSet & updated_columns,\n     bool include_ttl_target,\n-    const std::function<bool(const String & file_name)> & has_indice_or_projection) const\n+    const HasDependencyCallback & has_dependency) const\n {\n     if (updated_columns.empty())\n         return {};\n@@ -268,13 +268,13 @@ ColumnDependencies StorageInMemoryMetadata::getColumnDependencies(\n \n     for (const auto & index : getSecondaryIndices())\n     {\n-        if (has_indice_or_projection(\"skp_idx_\" + index.name + \".idx\") || has_indice_or_projection(\"skp_idx_\" + index.name + \".idx2\"))\n+        if (has_dependency(index.name, ColumnDependency::SKIP_INDEX))\n             add_dependent_columns(index.expression, indices_columns);\n     }\n \n     for (const auto & projection : getProjections())\n     {\n-        if (has_indice_or_projection(projection.getDirectoryName()))\n+        if (has_dependency(projection.name, ColumnDependency::PROJECTION))\n             add_dependent_columns(&projection, projections_columns);\n     }\n \ndiff --git a/src/Storages/StorageInMemoryMetadata.h b/src/Storages/StorageInMemoryMetadata.h\nindex 4ed7eb8bf295..30b2b303492a 100644\n--- a/src/Storages/StorageInMemoryMetadata.h\n+++ b/src/Storages/StorageInMemoryMetadata.h\n@@ -147,12 +147,14 @@ struct StorageInMemoryMetadata\n     TTLDescriptions getGroupByTTLs() const;\n     bool hasAnyGroupByTTL() const;\n \n+    using HasDependencyCallback = std::function<bool(const String &, ColumnDependency::Kind)>;\n+\n     /// Returns columns, which will be needed to calculate dependencies (skip indices, projections,\n     /// TTL expressions) if we update @updated_columns set of columns.\n     ColumnDependencies getColumnDependencies(\n         const NameSet & updated_columns,\n         bool include_ttl_target,\n-        const std::function<bool(const String & file_name)> & has_indice_or_projection) const;\n+        const HasDependencyCallback & has_dependency) const;\n \n     /// Block with ordinary + materialized columns.\n     Block getSampleBlock() const;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02832_alter_delete_indexes_projections.reference b/tests/queries/0_stateless/02832_alter_delete_indexes_projections.reference\nnew file mode 100644\nindex 000000000000..f14acdf9e6dd\n--- /dev/null\n+++ b/tests/queries/0_stateless/02832_alter_delete_indexes_projections.reference\n@@ -0,0 +1,6 @@\n+2\n+0\n+3355402240\n+3355402240\n+3321851904\n+3321851904\ndiff --git a/tests/queries/0_stateless/02832_alter_delete_indexes_projections.sql b/tests/queries/0_stateless/02832_alter_delete_indexes_projections.sql\nnew file mode 100644\nindex 000000000000..b87230e57d1d\n--- /dev/null\n+++ b/tests/queries/0_stateless/02832_alter_delete_indexes_projections.sql\n@@ -0,0 +1,26 @@\n+set mutations_sync = 2;\n+\n+drop table if exists t_delete_skip_index;\n+\n+create table t_delete_skip_index (x UInt32, y String, index i y type minmax granularity 3) engine = MergeTree order by tuple();\n+insert into t_delete_skip_index select number, toString(number) from numbers(8192 * 10);\n+\n+select count() from t_delete_skip_index where y in (4, 5);\n+alter table t_delete_skip_index delete where x < 8192;\n+select count() from t_delete_skip_index where y in (4, 5);\n+\n+drop table if exists t_delete_skip_index;\n+drop table if exists t_delete_projection;\n+\n+create table t_delete_projection (x UInt32, y UInt64, projection p (select sum(y))) engine = MergeTree order by tuple();\n+insert into t_delete_projection select number, toString(number) from numbers(8192 * 10);\n+\n+select sum(y) from t_delete_projection settings optimize_use_projections = 0;\n+select sum(y) from t_delete_projection settings optimize_use_projections = 0, force_optimize_projection = 1;\n+\n+alter table t_delete_projection delete where x < 8192;\n+\n+select sum(y) from t_delete_projection settings optimize_use_projections = 0;\n+select sum(y) from t_delete_projection settings optimize_use_projections = 0, force_optimize_projection = 1;\n+\n+drop table if exists t_delete_projection;\n",
  "problem_statement": "Skip index is not affected by alter delete. Too many marks in file.\nmaster\r\n\r\n```\r\ncreate table tab (x UInt32, y String, Index i y type minmax granularity 3) engine = MergeTree order by tuple();\r\ninsert into tab select number, toString(number) from numbers(8192 * 10);\r\nalter table tab delete where x < 8192;\r\nselect x from tab where y in (4, 5);\r\n```\r\n\r\n```\r\nSELECT x\r\nFROM tab\r\nWHERE y IN (4, 5)\r\n\r\nQuery id: 81971d0e-73f5-4b03-a0ab-dce83c252a04\r\n\r\n\r\n0 rows in set. Elapsed: 0.002 sec. \r\n\r\nReceived exception from server (version 23.7.1):\r\nCode: 33. DB::Exception: Received from localhost:9000. DB::Exception: Too many marks in file skp_idx_i.cmrk3, marks expected 3 (bytes size 72). (CANNOT_READ_ALL_DATA)\r\n```\r\n\r\nIndex is just hard-linked.\r\n\r\n```\r\n$ hexdump /home/ubuntu/test/clickhouse/store/085/085ca165-85ef-4671-9233-d81dd6a0c727/all_1_1_0_2/skp_idx_i.idx2 \r\n0000000 2c5f fce7 d50c 7003 ddfc 5ff7 bab9 9bed\r\n0000010 3282 0000 2b00 0000 f100 0104 0430 3939\r\n0000020 3939 3205 3534 3637 3405 3139 3135 0006\r\n0000030 3271 3705 3733 3732 0006 3870 3805 3931\r\n0000040 3931                                   \r\n0000042\r\n$ hexdump /home/ubuntu/test/clickhouse/store/085/085ca165-85ef-4671-9233-d81dd6a0c727/all_1_1_0/skp_idx_i.idx2 \r\n0000000 2c5f fce7 d50c 7003 ddfc 5ff7 bab9 9bed\r\n0000010 3282 0000 2b00 0000 f100 0104 0430 3939\r\n0000020 3939 3205 3534 3637 3405 3139 3135 0006\r\n0000030 3271 3705 3733 3732 0006 3870 3805 3931\r\n0000040 3931                                   \r\n0000042\r\n$ stat /home/ubuntu/test/clickhouse/store/085/085ca165-85ef-4671-9233-d81dd6a0c727/all_1_1_0/skp_idx_i.idx2 \r\n  File: /home/ubuntu/test/clickhouse/store/085/085ca165-85ef-4671-9233-d81dd6a0c727/all_1_1_0/skp_idx_i.idx2\r\n  Size: 66        \tBlocks: 8          IO Block: 4096   regular file\r\nDevice: 10301h/66305d\tInode: 529521      Links: 3\r\nAccess: (0640/-rw-r-----)  Uid: ( 1000/  ubuntu)   Gid: ( 1000/  ubuntu)\r\nAccess: 2023-07-21 14:56:21.679980867 +0000\r\nModify: 2023-07-21 14:52:53.161683317 +0000\r\nChange: 2023-07-21 14:55:03.580622408 +0000\r\n Birth: -\r\n```\n",
  "hints_text": "Hmm, might be related to https://github.com/ClickHouse/ClickHouse/pull/50104",
  "created_at": "2023-07-24T14:15:36Z",
  "modified_files": [
    "src/Interpreters/MutationsInterpreter.cpp",
    "src/Interpreters/MutationsInterpreter.h",
    "src/Storages/MergeTree/IMergeTreeDataPart.cpp",
    "src/Storages/MergeTree/IMergeTreeDataPart.h",
    "src/Storages/MergeTree/MutateTask.cpp",
    "src/Storages/StorageInMemoryMetadata.cpp",
    "src/Storages/StorageInMemoryMetadata.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02832_alter_delete_indexes_projections.reference",
    "b/tests/queries/0_stateless/02832_alter_delete_indexes_projections.sql"
  ]
}