{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 68082,
  "instance_id": "ClickHouse__ClickHouse-68082",
  "issue_numbers": [
    "52771"
  ],
  "base_commit": "008d02880bdf99fa659d34790d5ed1e9b884b6d8",
  "patch": "diff --git a/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp b/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp\nindex 7205b5b3294f..8de809712384 100644\n--- a/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp\n+++ b/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp\n@@ -63,7 +63,7 @@ void throwIfError(const Aws::Utils::Outcome<Result, Error> & response)\n     {\n         const auto & err = response.GetError();\n         throw S3Exception(\n-            fmt::format(\"{} (Code: {}, s3 exception: {})\",\n+            fmt::format(\"{} (Code: {}, S3 exception: '{}')\",\n                         err.GetMessage(), static_cast<size_t>(err.GetErrorType()), err.GetExceptionName()),\n             err.GetErrorType());\n     }\ndiff --git a/src/IO/S3/Credentials.cpp b/src/IO/S3/Credentials.cpp\nindex dfb7727fca43..d6f7542da6b3 100644\n--- a/src/IO/S3/Credentials.cpp\n+++ b/src/IO/S3/Credentials.cpp\n@@ -145,12 +145,16 @@ Aws::String AWSEC2MetadataClient::getDefaultCredentialsSecurely() const\n {\n     String user_agent_string = awsComputeUserAgentString();\n     auto [new_token, response_code] = getEC2MetadataToken(user_agent_string);\n-    if (response_code == Aws::Http::HttpResponseCode::BAD_REQUEST)\n+    if (response_code == Aws::Http::HttpResponseCode::BAD_REQUEST\n+        || response_code == Aws::Http::HttpResponseCode::REQUEST_NOT_MADE)\n+    {\n+        /// At least the host should be available and reply, otherwise neither IMDSv2 nor IMDSv1 are usable.\n         return {};\n+    }\n     else if (response_code != Aws::Http::HttpResponseCode::OK || new_token.empty())\n     {\n         LOG_TRACE(logger, \"Calling EC2MetadataService to get token failed, \"\n-                  \"falling back to less secure way. HTTP response code: {}\", response_code);\n+                  \"falling back to a less secure way. HTTP response code: {}\", response_code);\n         return getDefaultCredentials();\n     }\n \n@@ -247,7 +251,7 @@ static Aws::String getAWSMetadataEndpoint()\n     return ec2_metadata_service_endpoint;\n }\n \n-std::shared_ptr<AWSEC2MetadataClient> InitEC2MetadataClient(const Aws::Client::ClientConfiguration & client_configuration)\n+std::shared_ptr<AWSEC2MetadataClient> createEC2MetadataClient(const Aws::Client::ClientConfiguration & client_configuration)\n {\n     auto endpoint = getAWSMetadataEndpoint();\n     return std::make_shared<AWSEC2MetadataClient>(client_configuration, endpoint.c_str());\n@@ -781,11 +785,13 @@ S3CredentialsProviderChain::S3CredentialsProviderChain(\n \n             /// EC2MetadataService throttles by delaying the response so the service client should set a large read timeout.\n             /// EC2MetadataService delay is in order of seconds so it only make sense to retry after a couple of seconds.\n-            aws_client_configuration.connectTimeoutMs = 1000;\n+            /// But the connection timeout should be small because there is the case when there is no IMDS at all,\n+            /// like outside of the cloud, on your own machines.\n+            aws_client_configuration.connectTimeoutMs = 10;\n             aws_client_configuration.requestTimeoutMs = 1000;\n \n             aws_client_configuration.retryStrategy = std::make_shared<Aws::Client::DefaultRetryStrategy>(1, 1000);\n-            auto ec2_metadata_client = InitEC2MetadataClient(aws_client_configuration);\n+            auto ec2_metadata_client = createEC2MetadataClient(aws_client_configuration);\n             auto config_loader = std::make_shared<AWSEC2InstanceProfileConfigLoader>(ec2_metadata_client, !credentials_configuration.use_insecure_imds_request);\n \n             AddProvider(std::make_shared<AWSInstanceProfileCredentialsProvider>(config_loader));\ndiff --git a/src/IO/S3/Credentials.h b/src/IO/S3/Credentials.h\nindex 95297ab0538c..042c48ec15a1 100644\n--- a/src/IO/S3/Credentials.h\n+++ b/src/IO/S3/Credentials.h\n@@ -70,7 +70,7 @@ class AWSEC2MetadataClient : public Aws::Internal::AWSHttpResourceClient\n     LoggerPtr logger;\n };\n \n-std::shared_ptr<AWSEC2MetadataClient> InitEC2MetadataClient(const Aws::Client::ClientConfiguration & client_configuration);\n+std::shared_ptr<AWSEC2MetadataClient> createEC2MetadataClient(const Aws::Client::ClientConfiguration & client_configuration);\n \n class AWSEC2InstanceProfileConfigLoader : public Aws::Config::AWSProfileConfigLoader\n {\ndiff --git a/src/IO/S3/PocoHTTPClient.cpp b/src/IO/S3/PocoHTTPClient.cpp\nindex aab7a39534dd..de43f34d8386 100644\n--- a/src/IO/S3/PocoHTTPClient.cpp\n+++ b/src/IO/S3/PocoHTTPClient.cpp\n@@ -128,7 +128,7 @@ void PocoHTTPClientConfiguration::updateSchemeAndRegion()\n             }\n             else\n             {\n-                /// In global mode AWS C++ SDK send `us-east-1` but accept switching to another one if being suggested.\n+                /// In global mode AWS C++ SDK sends `us-east-1` but accepts switching to another one if being suggested.\n                 region = Aws::Region::AWS_GLOBAL;\n             }\n         }\ndiff --git a/src/IO/S3/URI.cpp b/src/IO/S3/URI.cpp\nindex fead18315d84..9c80b377661b 100644\n--- a/src/IO/S3/URI.cpp\n+++ b/src/IO/S3/URI.cpp\n@@ -1,8 +1,8 @@\n #include <IO/S3/URI.h>\n-#include <Interpreters/Context.h>\n-#include <Storages/NamedCollectionsHelpers.h>\n-#include \"Common/Macros.h\"\n+\n #if USE_AWS_S3\n+#include <Interpreters/Context.h>\n+#include <Common/Macros.h>\n #include <Common/Exception.h>\n #include <Common/quoteString.h>\n #include <Common/re2.h>\n@@ -10,6 +10,7 @@\n \n #include <boost/algorithm/string/case_conv.hpp>\n \n+\n namespace DB\n {\n \n@@ -40,21 +41,13 @@ URI::URI(const std::string & uri_, bool allow_archive_path_syntax)\n     /// Case when AWS Private Link Interface is being used\n     /// E.g. (bucket.vpce-07a1cd78f1bd55c5f-j3a3vg6w.s3.us-east-1.vpce.amazonaws.com/bucket-name/key)\n     /// https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html\n-    static const RE2 aws_private_link_style_pattern(R\"(bucket\\.vpce\\-([a-z0-9\\-.]+)\\.vpce.amazonaws.com(:\\d{1,5})?)\");\n+    static const RE2 aws_private_link_style_pattern(R\"(bucket\\.vpce\\-([a-z0-9\\-.]+)\\.vpce\\.amazonaws\\.com(:\\d{1,5})?)\");\n \n-    /// Case when bucket name and key represented in path of S3 URL.\n+    /// Case when bucket name and key represented in the path of S3 URL.\n     /// E.g. (https://s3.region.amazonaws.com/bucket-name/key)\n     /// https://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html#path-style-access\n     static const RE2 path_style_pattern(\"^/([^/]*)/(.*)\");\n \n-    static constexpr auto S3 = \"S3\";\n-    static constexpr auto S3EXPRESS = \"S3EXPRESS\";\n-    static constexpr auto COSN = \"COSN\";\n-    static constexpr auto COS = \"COS\";\n-    static constexpr auto OBS = \"OBS\";\n-    static constexpr auto OSS = \"OSS\";\n-    static constexpr auto EOS = \"EOS\";\n-\n     if (allow_archive_path_syntax)\n         std::tie(uri_str, archive_pattern) = getURIAndArchivePattern(uri_);\n     else\n@@ -85,7 +78,7 @@ URI::URI(const std::string & uri_, bool allow_archive_path_syntax)\n             URIConverter::modifyURI(uri, mapper);\n     }\n \n-    storage_name = S3;\n+    storage_name = \"S3\";\n \n     if (uri.getHost().empty())\n         throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Host is empty in S3 URI.\");\n@@ -93,11 +86,13 @@ URI::URI(const std::string & uri_, bool allow_archive_path_syntax)\n     /// Extract object version ID from query string.\n     bool has_version_id = false;\n     for (const auto & [query_key, query_value] : uri.getQueryParameters())\n+    {\n         if (query_key == \"versionId\")\n         {\n             version_id = query_value;\n             has_version_id = true;\n         }\n+    }\n \n     /// Poco::URI will ignore '?' when parsing the path, but if there is a versionId in the http parameter,\n     /// '?' can not be used as a wildcard, otherwise it will be ambiguous.\n@@ -129,15 +124,8 @@ URI::URI(const std::string & uri_, bool allow_archive_path_syntax)\n         }\n \n         boost::to_upper(name);\n-        /// For S3Express it will look like s3express-eun1-az1, i.e. contain region and AZ info\n-        if (name != S3 && !name.starts_with(S3EXPRESS) && name != COS && name != OBS && name != OSS && name != EOS)\n-            throw Exception(\n-                ErrorCodes::BAD_ARGUMENTS,\n-                \"Object storage system name is unrecognized in virtual hosted style S3 URI: {}\",\n-                quoteString(name));\n-\n-        if (name == COS)\n-            storage_name = COSN;\n+        if (name == \"COS\")\n+            storage_name = \"COSN\";\n         else\n             storage_name = name;\n     }\n@@ -148,13 +136,22 @@ URI::URI(const std::string & uri_, bool allow_archive_path_syntax)\n         validateBucket(bucket, uri);\n     }\n     else\n-        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Bucket or key name are invalid in S3 URI.\");\n+    {\n+        /// Custom endpoint, e.g. a public domain of Cloudflare R2,\n+        /// which could be served by a custom server-side code.\n+        storage_name = \"S3\";\n+        bucket = \"default\";\n+        is_virtual_hosted_style = false;\n+        endpoint = uri.getScheme() + \"://\" + uri.getAuthority();\n+        if (!uri.getPath().empty())\n+            key = uri.getPath().substr(1);\n+    }\n }\n \n void URI::addRegionToURI(const std::string &region)\n {\n-    if (auto pos = endpoint.find(\"amazonaws.com\"); pos != std::string::npos)\n-        endpoint = endpoint.substr(0, pos) + region + \".\" + endpoint.substr(pos);\n+    if (auto pos = endpoint.find(\".amazonaws.com\"); pos != std::string::npos)\n+        endpoint = endpoint.substr(0, pos) + \".\" + region + endpoint.substr(pos);\n }\n \n void URI::validateBucket(const String & bucket, const Poco::URI & uri)\ndiff --git a/src/IO/S3/URI.h b/src/IO/S3/URI.h\nindex 80e2da96cd4d..c8d0b28cd150 100644\n--- a/src/IO/S3/URI.h\n+++ b/src/IO/S3/URI.h\n@@ -1,14 +1,14 @@\n #pragma once\n \n-#include <optional>\n-#include <string>\n-\n #include \"config.h\"\n \n #if USE_AWS_S3\n \n+#include <optional>\n+#include <string>\n #include <Poco/URI.h>\n \n+\n namespace DB::S3\n {\n \n@@ -23,7 +23,7 @@ namespace DB::S3\n struct URI\n {\n     Poco::URI uri;\n-    // Custom endpoint if URI scheme is not S3.\n+    // Custom endpoint if URI scheme, if not S3.\n     std::string endpoint;\n     std::string bucket;\n     std::string key;\ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex 78dbb72c199c..f7701a2aab80 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -895,7 +895,7 @@ void StorageMergeTree::loadDeduplicationLog()\n     std::string path = fs::path(relative_data_path) / \"deduplication_logs\";\n \n     /// If either there is already a deduplication log, or we will be able to use it.\n-    if (disk->exists(path) || !disk->isReadOnly())\n+    if (!disk->isReadOnly() || disk->exists(path))\n     {\n         deduplication_log = std::make_unique<MergeTreeDeduplicationLog>(path, settings->non_replicated_deduplication_window, format_version, disk);\n         deduplication_log->load();\n",
  "test_patch": "diff --git a/src/IO/tests/gtest_s3_uri.cpp b/src/IO/tests/gtest_s3_uri.cpp\nindex 0ec28f800727..c0bf7fcb28a1 100644\n--- a/src/IO/tests/gtest_s3_uri.cpp\n+++ b/src/IO/tests/gtest_s3_uri.cpp\n@@ -206,11 +206,6 @@ TEST(S3UriTest, validPatterns)\n     }\n }\n \n-TEST_P(S3UriTest, invalidPatterns)\n-{\n-    ASSERT_ANY_THROW(S3::URI new_uri(GetParam()));\n-}\n-\n TEST(S3UriTest, versionIdChecks)\n {\n     for (const auto& test_case : TestCases)\n@@ -223,19 +218,5 @@ TEST(S3UriTest, versionIdChecks)\n     }\n }\n \n-INSTANTIATE_TEST_SUITE_P(\n-    S3,\n-    S3UriTest,\n-    testing::Values(\n-        \"https:///\",\n-        \"https://.s3.amazonaws.com/key\",\n-        \"https://s3.amazonaws.com/key\",\n-        \"https://jokserfn.s3amazonaws.com/key\",\n-        \"https://s3.amazonaws.com//\",\n-        \"https://amazonaws.com/\",\n-        \"https://amazonaws.com//\",\n-        \"https://amazonaws.com//key\"));\n-\n }\n-\n #endif\ndiff --git a/tests/integration/test_odbc_interaction/test.py b/tests/integration/test_odbc_interaction/test.py\nindex 0d0d7a0afb17..9d4ca5ad49f0 100644\n--- a/tests/integration/test_odbc_interaction/test.py\n+++ b/tests/integration/test_odbc_interaction/test.py\n@@ -51,9 +51,9 @@\n     \"\"\"\n \n \n-def skip_test_msan(instance):\n-    if instance.is_built_with_memory_sanitizer():\n-        pytest.skip(\"Memory Sanitizer cannot work with third-party shared libraries\")\n+def skip_test_sanitizers(instance):\n+    if instance.is_built_with_sanitizer():\n+        pytest.skip(\"Sanitizers cannot work with third-party shared libraries\")\n \n \n def get_mysql_conn():\n@@ -208,7 +208,7 @@ def started_cluster():\n \n \n def test_mysql_odbc_select_nullable(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n     mysql_setup = node1.odbc_drivers[\"MySQL\"]\n \n     table_name = \"test_insert_nullable_select\"\n@@ -248,7 +248,7 @@ def test_mysql_odbc_select_nullable(started_cluster):\n \n \n def test_mysql_simple_select_works(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     mysql_setup = node1.odbc_drivers[\"MySQL\"]\n \n@@ -331,7 +331,7 @@ def test_mysql_simple_select_works(started_cluster):\n \n \n def test_mysql_insert(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     mysql_setup = node1.odbc_drivers[\"MySQL\"]\n     table_name = \"test_insert\"\n@@ -374,7 +374,7 @@ def test_mysql_insert(started_cluster):\n \n \n def test_sqlite_simple_select_function_works(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     sqlite_setup = node1.odbc_drivers[\"SQLite3\"]\n     sqlite_db = sqlite_setup[\"Database\"]\n@@ -438,7 +438,7 @@ def test_sqlite_simple_select_function_works(started_cluster):\n \n \n def test_sqlite_table_function(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     sqlite_setup = node1.odbc_drivers[\"SQLite3\"]\n     sqlite_db = sqlite_setup[\"Database\"]\n@@ -470,7 +470,7 @@ def test_sqlite_table_function(started_cluster):\n \n \n def test_sqlite_simple_select_storage_works(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     sqlite_setup = node1.odbc_drivers[\"SQLite3\"]\n     sqlite_db = sqlite_setup[\"Database\"]\n@@ -503,7 +503,7 @@ def test_sqlite_simple_select_storage_works(started_cluster):\n \n \n def test_sqlite_odbc_hashed_dictionary(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     sqlite_db = node1.odbc_drivers[\"SQLite3\"][\"Database\"]\n     node1.exec_in_container(\n@@ -586,7 +586,7 @@ def test_sqlite_odbc_hashed_dictionary(started_cluster):\n \n \n def test_sqlite_odbc_cached_dictionary(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     sqlite_db = node1.odbc_drivers[\"SQLite3\"][\"Database\"]\n     node1.exec_in_container(\n@@ -635,7 +635,7 @@ def test_sqlite_odbc_cached_dictionary(started_cluster):\n \n \n def test_postgres_odbc_hashed_dictionary_with_schema(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     try:\n         conn = get_postgres_conn(started_cluster)\n@@ -663,7 +663,7 @@ def test_postgres_odbc_hashed_dictionary_with_schema(started_cluster):\n \n \n def test_postgres_odbc_hashed_dictionary_no_tty_pipe_overflow(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     try:\n         conn = get_postgres_conn(started_cluster)\n@@ -685,7 +685,7 @@ def test_postgres_odbc_hashed_dictionary_no_tty_pipe_overflow(started_cluster):\n \n \n def test_no_connection_pooling(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     try:\n         conn = get_postgres_conn(started_cluster)\n@@ -717,7 +717,7 @@ def test_no_connection_pooling(started_cluster):\n \n \n def test_postgres_insert(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     conn = get_postgres_conn(started_cluster)\n \n@@ -754,7 +754,7 @@ def test_postgres_insert(started_cluster):\n \n \n def test_odbc_postgres_date_data_type(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     try:\n         conn = get_postgres_conn(started_cluster)\n@@ -783,7 +783,7 @@ def test_odbc_postgres_date_data_type(started_cluster):\n \n \n def test_odbc_postgres_conversions(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     try:\n         conn = get_postgres_conn(started_cluster)\n@@ -841,7 +841,7 @@ def test_odbc_postgres_conversions(started_cluster):\n \n \n def test_odbc_cyrillic_with_varchar(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     conn = get_postgres_conn(started_cluster)\n     cursor = conn.cursor()\n@@ -868,7 +868,7 @@ def test_odbc_cyrillic_with_varchar(started_cluster):\n \n \n def test_many_connections(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     conn = get_postgres_conn(started_cluster)\n     cursor = conn.cursor()\n@@ -894,7 +894,7 @@ def test_many_connections(started_cluster):\n \n \n def test_concurrent_queries(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     conn = get_postgres_conn(started_cluster)\n     cursor = conn.cursor()\n@@ -948,7 +948,7 @@ def node_insert_select(_):\n \n \n def test_odbc_long_column_names(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     conn = get_postgres_conn(started_cluster)\n     cursor = conn.cursor()\n@@ -986,7 +986,7 @@ def test_odbc_long_column_names(started_cluster):\n \n \n def test_odbc_long_text(started_cluster):\n-    skip_test_msan(node1)\n+    skip_test_sanitizers(node1)\n \n     conn = get_postgres_conn(started_cluster)\n     cursor = conn.cursor()\ndiff --git a/tests/integration/test_s3_imds/test_simple.py b/tests/integration/test_s3_imds/test_simple.py\nindex 0dacac2b0b96..4884c824f998 100644\n--- a/tests/integration/test_s3_imds/test_simple.py\n+++ b/tests/integration/test_s3_imds/test_simple.py\n@@ -56,7 +56,7 @@ def test_credentials_from_metadata():\n     )\n \n     expected_logs = [\n-        \"Calling EC2MetadataService to get token failed, falling back to less secure way\",\n+        \"Calling EC2MetadataService to get token failed, falling back to a less secure way\",\n         \"Getting default credentials for ec2 instance from resolver:8080\",\n         \"Calling EC2MetadataService resource, /latest/meta-data/iam/security-credentials returned credential string myrole\",\n         \"Calling EC2MetadataService resource /latest/meta-data/iam/security-credentials/myrole\",\ndiff --git a/tests/queries/0_stateless/02490_benchmark_max_consecutive_errors.sh b/tests/queries/0_stateless/02490_benchmark_max_consecutive_errors.sh\nindex f747b3156a57..df7e93866627 100755\n--- a/tests/queries/0_stateless/02490_benchmark_max_consecutive_errors.sh\n+++ b/tests/queries/0_stateless/02490_benchmark_max_consecutive_errors.sh\n@@ -11,5 +11,6 @@ if [ \"$RES\" -eq 10 ]\n then\n     echo \"$RES\"\n else\n+    echo \"$RES\"\n     cat \"${CLICKHOUSE_TMP}/${CLICKHOUSE_DATABASE}.log\"\n fi\ndiff --git a/tests/queries/0_stateless/03221_s3_imds_decent_timeout.reference b/tests/queries/0_stateless/03221_s3_imds_decent_timeout.reference\nnew file mode 100644\nindex 000000000000..d00491fd7e5b\n--- /dev/null\n+++ b/tests/queries/0_stateless/03221_s3_imds_decent_timeout.reference\n@@ -0,0 +1,1 @@\n+1\ndiff --git a/tests/queries/0_stateless/03221_s3_imds_decent_timeout.sh b/tests/queries/0_stateless/03221_s3_imds_decent_timeout.sh\nnew file mode 100755\nindex 000000000000..021278955cd6\n--- /dev/null\n+++ b/tests/queries/0_stateless/03221_s3_imds_decent_timeout.sh\n@@ -0,0 +1,16 @@\n+#!/usr/bin/env bash\n+# Tags: no-fasttest, no-asan, no-msan, no-tsan\n+# ^ requires S3\n+\n+CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CUR_DIR\"/../shell_config.sh\n+\n+# Inaccessible IMDS should not introduce large delays, so this query should reply quickly at least sometimes:\n+while true\n+do\n+    # This host (likely) drops packets sent to it (does not reply), so it is good for testing timeouts.\n+    # At the same time, we expect that the clickhouse host does not drop packets and quickly replies with 4xx, which is a non-retriable error for S3.\n+    AWS_EC2_METADATA_SERVICE_ENDPOINT='https://10.255.255.255/' ${CLICKHOUSE_LOCAL} --time --query \"SELECT * FROM s3('${CLICKHOUSE_PORT_HTTP_PROTO}://${CLICKHOUSE_HOST}:${CLICKHOUSE_PORT_HTTP}/nonexistent')\" |& grep -v -F 404 |\n+        ${CLICKHOUSE_LOCAL} --input-format TSV \"SELECT c1::Float64 < 1 FROM table\" | grep 1 && break\n+done\n",
  "problem_statement": "Creating view on S3 glob pattern takes unexpectedly long time\n**Describe the unexpected behaviour**\r\n\r\nWhen creating a view, I am observing 4 seconds from my laptop in us east to data in us west, when I'd expect it to be instant.\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use\r\n\r\n`ClickHouse server version 23.7.1 revision 54464`\r\n\r\n* Queries to run that lead to unexpected result\r\n\r\n```\r\nCREATE VIEW s3_parquet AS\r\nSELECT *\r\nFROM s3('https://s3.us-west-2.amazonaws.com/ookla-open-data/parquet/performance/type=*/year=*/quarter=*/*.parquet', 'Parquet', 'quadkey Nullable(String), tile Nullable(String), avg_d_kbps Nullable(Int64), avg_u_kbps Nullable(Int64), avg_lat_ms Nullable(Int64), tests Nullable(Int64), devices Nullable(Int64)')\r\n\r\nQuery id: 7eaf74c7-25ba-4748-8dff-6f4accdcdabb\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 4.021 sec.\r\n\r\nd2e52eb1a093 :) select count() from s3_parquet\r\n\r\nSELECT count()\r\nFROM s3_parquet\r\n\r\nQuery id: a703f818-ac38-40ea-a1fa-8736c28f5bd3\r\n\r\n\u250c\u2500\u2500\u2500count()\u2500\u2510\r\n\u2502 185832935 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 row in set. Elapsed: 40.022 sec. Processed 185.83 million rows, 7.17 GB (4.64 million rows/s., 179.10 MB/s.)\r\n```\r\n\r\nWithout View (killed to reset cache):\r\n```\r\nSELECT count()\r\nFROM s3('https://s3.us-west-2.amazonaws.com/ookla-open-data/parquet/performance/type=*/year=*/quarter=*/*.parquet', 'Parquet', 'quadkey Nullable(String), tile Nullable(String), avg_d_kbps Nullable(Int64), avg_u_kbps Nullable(Int64), avg_lat_ms Nullable(Int64), tests Nullable(Int64), devices Nullable(Int64)')\r\n\r\nQuery id: 2f8b2625-9e89-418e-8d58-e5cff0d2e7e2\r\n\r\n\u250c\u2500\u2500\u2500count()\u2500\u2510\r\n\u2502 185832935 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 row in set. Elapsed: 40.336 sec. Processed 185.83 million rows, 7.17 GB (4.61 million rows/s., 177.71 MB/s.)\r\n```\r\n\r\nI've specified the schema to remove the possibility that it needs to scan files to determine schema. As you can see creating the view takes 4 seconds, but the count of both queries takes nearly identical time. I am not sure what it is doing when creating the view but from at least this query it does not seem to be helpful.\n",
  "hints_text": "Based on query time it also seems to be doing more than just listing, otherwise I'd expect the s3 function to take an extra 3-4 seconds.\r\n\r\nFor example in duckdb:\r\n\r\n```\r\ncreate view test as SELECT * FROM read_parquet('s3://ookla-open-data/parquet/performance/type=*/year=*/quarter=*/*.parquet');\r\n\r\nCompleted in 933ms\r\n```\nThis was first observed in https://github.com/ClickHouse/ClickHouse/issues/44246#issue-1497564465",
  "created_at": "2024-08-09T01:46:21Z"
}