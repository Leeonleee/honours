{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 72102,
  "instance_id": "ClickHouse__ClickHouse-72102",
  "issue_numbers": [
    "71992"
  ],
  "base_commit": "26de44703910c41f173f8651990a6ad689633922",
  "patch": "diff --git a/programs/local/LocalServer.cpp b/programs/local/LocalServer.cpp\nindex 3ecc6ecf24d9..69f363789d18 100644\n--- a/programs/local/LocalServer.cpp\n+++ b/programs/local/LocalServer.cpp\n@@ -111,6 +111,9 @@ namespace ServerSetting\n     extern const ServerSettingsString uncompressed_cache_policy;\n     extern const ServerSettingsUInt64 uncompressed_cache_size;\n     extern const ServerSettingsDouble uncompressed_cache_size_ratio;\n+    extern const ServerSettingsString primary_index_cache_policy;\n+    extern const ServerSettingsUInt64 primary_index_cache_size;\n+    extern const ServerSettingsDouble primary_index_cache_size_ratio;\n     extern const ServerSettingsBool use_legacy_mongodb_integration;\n }\n \n@@ -779,6 +782,16 @@ void LocalServer::processConfig()\n     }\n     global_context->setIndexMarkCache(index_mark_cache_policy, index_mark_cache_size, index_mark_cache_size_ratio);\n \n+    String primary_index_cache_policy = server_settings[ServerSetting::primary_index_cache_policy];\n+    size_t primary_index_cache_size = server_settings[ServerSetting::primary_index_cache_size];\n+    double primary_index_cache_size_ratio = server_settings[ServerSetting::primary_index_cache_size_ratio];\n+    if (primary_index_cache_size > max_cache_size)\n+    {\n+        primary_index_cache_size = max_cache_size;\n+        LOG_INFO(log, \"Lowered primary index cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(primary_index_cache_size));\n+    }\n+    global_context->setPrimaryIndexCache(primary_index_cache_policy, primary_index_cache_size, primary_index_cache_size_ratio);\n+\n     size_t mmap_cache_size = server_settings[ServerSetting::mmap_cache_size];\n     if (mmap_cache_size > max_cache_size)\n     {\ndiff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex af383334128c..278433b5507e 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -280,6 +280,9 @@ namespace ServerSetting\n     extern const ServerSettingsString uncompressed_cache_policy;\n     extern const ServerSettingsUInt64 uncompressed_cache_size;\n     extern const ServerSettingsDouble uncompressed_cache_size_ratio;\n+    extern const ServerSettingsString primary_index_cache_policy;\n+    extern const ServerSettingsUInt64 primary_index_cache_size;\n+    extern const ServerSettingsDouble primary_index_cache_size_ratio;\n     extern const ServerSettingsBool use_legacy_mongodb_integration;\n }\n \n@@ -1563,6 +1566,16 @@ try\n     }\n     global_context->setMarkCache(mark_cache_policy, mark_cache_size, mark_cache_size_ratio);\n \n+    String primary_index_cache_policy = server_settings[ServerSetting::primary_index_cache_policy];\n+    size_t primary_index_cache_size = server_settings[ServerSetting::primary_index_cache_size];\n+    double primary_index_cache_size_ratio = server_settings[ServerSetting::primary_index_cache_size_ratio];\n+    if (primary_index_cache_size > max_cache_size)\n+    {\n+        primary_index_cache_size = max_cache_size;\n+        LOG_INFO(log, \"Lowered primary index cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(primary_index_cache_size));\n+    }\n+    global_context->setPrimaryIndexCache(primary_index_cache_policy, primary_index_cache_size, primary_index_cache_size_ratio);\n+\n     size_t page_cache_size = server_settings[ServerSetting::page_cache_size];\n     if (page_cache_size != 0)\n         global_context->setPageCache(\n@@ -1897,6 +1910,7 @@ try\n \n             global_context->updateUncompressedCacheConfiguration(*config);\n             global_context->updateMarkCacheConfiguration(*config);\n+            global_context->updatePrimaryIndexCacheConfiguration(*config);\n             global_context->updateIndexUncompressedCacheConfiguration(*config);\n             global_context->updateIndexMarkCacheConfiguration(*config);\n             global_context->updateMMappedFileCacheConfiguration(*config);\ndiff --git a/src/Access/Common/AccessType.h b/src/Access/Common/AccessType.h\nindex ec543104167f..1027567a753f 100644\n--- a/src/Access/Common/AccessType.h\n+++ b/src/Access/Common/AccessType.h\n@@ -165,6 +165,8 @@ enum class AccessType : uint8_t\n     M(SYSTEM_DROP_CONNECTIONS_CACHE, \"SYSTEM DROP CONNECTIONS CACHE, DROP CONNECTIONS CACHE\", GLOBAL, SYSTEM_DROP_CACHE)  \\\n     M(SYSTEM_PREWARM_MARK_CACHE, \"SYSTEM PREWARM MARK, PREWARM MARK CACHE, PREWARM MARKS\", GLOBAL, SYSTEM_DROP_CACHE) \\\n     M(SYSTEM_DROP_MARK_CACHE, \"SYSTEM DROP MARK, DROP MARK CACHE, DROP MARKS\", GLOBAL, SYSTEM_DROP_CACHE) \\\n+    M(SYSTEM_PREWARM_PRIMARY_INDEX_CACHE, \"SYSTEM PREWARM PRIMARY INDEX, PREWARM PRIMARY INDEX CACHE, PREWARM PRIMARY INDEX\", GLOBAL, SYSTEM_DROP_CACHE) \\\n+    M(SYSTEM_DROP_PRIMARY_INDEX_CACHE, \"SYSTEM DROP PRIMARY INDEX, DROP PRIMARY INDEX CACHE, DROP PRIMARY INDEX\", GLOBAL, SYSTEM_DROP_CACHE) \\\n     M(SYSTEM_DROP_UNCOMPRESSED_CACHE, \"SYSTEM DROP UNCOMPRESSED, DROP UNCOMPRESSED CACHE, DROP UNCOMPRESSED\", GLOBAL, SYSTEM_DROP_CACHE) \\\n     M(SYSTEM_DROP_MMAP_CACHE, \"SYSTEM DROP MMAP, DROP MMAP CACHE, DROP MMAP\", GLOBAL, SYSTEM_DROP_CACHE) \\\n     M(SYSTEM_DROP_QUERY_CACHE, \"SYSTEM DROP QUERY, DROP QUERY CACHE, DROP QUERY\", GLOBAL, SYSTEM_DROP_CACHE) \\\ndiff --git a/src/Common/ProfileEvents.cpp b/src/Common/ProfileEvents.cpp\nindex bdacf03d3bbd..69a4cd6d31b9 100644\n--- a/src/Common/ProfileEvents.cpp\n+++ b/src/Common/ProfileEvents.cpp\n@@ -63,6 +63,8 @@\n     M(TableFunctionExecute, \"Number of table function calls.\", ValueType::Number) \\\n     M(MarkCacheHits, \"Number of times an entry has been found in the mark cache, so we didn't have to load a mark file.\", ValueType::Number) \\\n     M(MarkCacheMisses, \"Number of times an entry has not been found in the mark cache, so we had to load a mark file in memory, which is a costly operation, adding to query latency.\", ValueType::Number) \\\n+    M(PrimaryIndexCacheHits, \"Number of times an entry has been found in the primary index cache, so we didn't have to load a index file.\", ValueType::Number) \\\n+    M(PrimaryIndexCacheMisses, \"Number of times an entry has not been found in the primary index cache, so we had to load a index file in memory, which is a costly operation, adding to query latency.\", ValueType::Number) \\\n     M(QueryCacheHits, \"Number of times a query result has been found in the query cache (and query computation was avoided). Only updated for SELECT queries with SETTING use_query_cache = 1.\", ValueType::Number) \\\n     M(QueryCacheMisses, \"Number of times a query result has not been found in the query cache (and required query computation). Only updated for SELECT queries with SETTING use_query_cache = 1.\", ValueType::Number) \\\n     /* Each page cache chunk access increments exactly one of the following 5 PageCacheChunk* counters. */ \\\n@@ -229,6 +231,9 @@\n     M(BackgroundLoadingMarksTasks, \"Number of background tasks for loading marks\", ValueType::Number) \\\n     M(LoadedMarksCount, \"Number of marks loaded (total across columns).\", ValueType::Number) \\\n     M(LoadedMarksMemoryBytes, \"Size of in-memory representations of loaded marks.\", ValueType::Bytes) \\\n+    M(LoadedPrimaryIndexFiles, \"Number of primary index files loaded.\", ValueType::Number) \\\n+    M(LoadedPrimaryIndexRows, \"Number of rows of primary key loaded.\", ValueType::Number) \\\n+    M(LoadedPrimaryIndexBytes, \"Number of rows of primary key loaded.\", ValueType::Bytes) \\\n     \\\n     M(Merge, \"Number of launched background merges.\", ValueType::Number) \\\n     M(MergeSourceParts, \"Number of source parts scheduled for merges.\", ValueType::Number) \\\ndiff --git a/src/Core/Defines.h b/src/Core/Defines.h\nindex c6e65f34e909..faa5dc3a3fed 100644\n--- a/src/Core/Defines.h\n+++ b/src/Core/Defines.h\n@@ -95,6 +95,9 @@ static constexpr auto DEFAULT_UNCOMPRESSED_CACHE_SIZE_RATIO = 0.5l;\n static constexpr auto DEFAULT_MARK_CACHE_POLICY = \"SLRU\";\n static constexpr auto DEFAULT_MARK_CACHE_MAX_SIZE = 5_GiB;\n static constexpr auto DEFAULT_MARK_CACHE_SIZE_RATIO = 0.5l;\n+static constexpr auto DEFAULT_PRIMARY_INDEX_CACHE_POLICY = \"SLRU\";\n+static constexpr auto DEFAULT_PRIMARY_INDEX_CACHE_MAX_SIZE = 5_GiB;\n+static constexpr auto DEFAULT_PRIMARY_INDEX_CACHE_SIZE_RATIO = 0.5l;\n static constexpr auto DEFAULT_INDEX_UNCOMPRESSED_CACHE_POLICY = \"SLRU\";\n static constexpr auto DEFAULT_INDEX_UNCOMPRESSED_CACHE_MAX_SIZE = 0;\n static constexpr auto DEFAULT_INDEX_UNCOMPRESSED_CACHE_SIZE_RATIO = 0.5;\ndiff --git a/src/Core/ServerSettings.cpp b/src/Core/ServerSettings.cpp\nindex 4bea23d4e900..3870619d7d1e 100644\n--- a/src/Core/ServerSettings.cpp\n+++ b/src/Core/ServerSettings.cpp\n@@ -104,6 +104,10 @@ namespace DB\n     DECLARE(UInt64, mark_cache_size, DEFAULT_MARK_CACHE_MAX_SIZE, \"Size of cache for marks (index of MergeTree family of tables).\", 0) \\\n     DECLARE(Double, mark_cache_size_ratio, DEFAULT_MARK_CACHE_SIZE_RATIO, \"The size of the protected queue in the mark cache relative to the cache's total size.\", 0) \\\n     DECLARE(Double, mark_cache_prewarm_ratio, 0.95, \"The ratio of total size of mark cache to fill during prewarm.\", 0) \\\n+    DECLARE(String, primary_index_cache_policy, DEFAULT_PRIMARY_INDEX_CACHE_POLICY, \"Primary index cache policy name.\", 0) \\\n+    DECLARE(UInt64, primary_index_cache_size, DEFAULT_PRIMARY_INDEX_CACHE_MAX_SIZE, \"Size of cache for primary index (index of MergeTree family of tables).\", 0) \\\n+    DECLARE(Double, primary_index_cache_size_ratio, DEFAULT_PRIMARY_INDEX_CACHE_SIZE_RATIO, \"The size of the protected queue in the primary index cache relative to the cache's total size.\", 0) \\\n+    DECLARE(Double, primary_index_cache_prewarm_ratio, 0.95, \"The ratio of total size of mark cache to fill during prewarm.\", 0) \\\n     DECLARE(String, index_uncompressed_cache_policy, DEFAULT_INDEX_UNCOMPRESSED_CACHE_POLICY, \"Secondary index uncompressed cache policy name.\", 0) \\\n     DECLARE(UInt64, index_uncompressed_cache_size, DEFAULT_INDEX_UNCOMPRESSED_CACHE_MAX_SIZE, \"Size of cache for uncompressed blocks of secondary indices. Zero means disabled.\", 0) \\\n     DECLARE(Double, index_uncompressed_cache_size_ratio, DEFAULT_INDEX_UNCOMPRESSED_CACHE_SIZE_RATIO, \"The size of the protected queue in the secondary index uncompressed cache relative to the cache's total size.\", 0) \\\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex 7f0ad013c1de..b123847c9498 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -34,6 +34,7 @@\n #include <Storages/MergeTree/ReplicatedFetchList.h>\n #include <Storages/MergeTree/MergeTreeData.h>\n #include <Storages/MergeTree/MergeTreeSettings.h>\n+#include <Storages/MergeTree/PrimaryIndexCache.h>\n #include <Storages/Distributed/DistributedSettings.h>\n #include <Storages/CompressionCodecSelector.h>\n #include <IO/S3Settings.h>\n@@ -408,6 +409,7 @@ struct ContextSharedPart : boost::noncopyable\n     mutable ResourceManagerPtr resource_manager;\n     mutable UncompressedCachePtr uncompressed_cache TSA_GUARDED_BY(mutex);            /// The cache of decompressed blocks.\n     mutable MarkCachePtr mark_cache TSA_GUARDED_BY(mutex);                            /// Cache of marks in compressed files.\n+    mutable PrimaryIndexCachePtr primary_index_cache TSA_GUARDED_BY(mutex);\n     mutable OnceFlag load_marks_threadpool_initialized;\n     mutable std::unique_ptr<ThreadPool> load_marks_threadpool;  /// Threadpool for loading marks cache.\n     mutable OnceFlag prefetch_threadpool_initialized;\n@@ -3254,6 +3256,41 @@ ThreadPool & Context::getLoadMarksThreadpool() const\n     return *shared->load_marks_threadpool;\n }\n \n+void Context::setPrimaryIndexCache(const String & cache_policy, size_t max_cache_size_in_bytes, double size_ratio)\n+{\n+    std::lock_guard lock(shared->mutex);\n+\n+    if (shared->primary_index_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Primary index cache has been already created.\");\n+\n+    shared->primary_index_cache = std::make_shared<PrimaryIndexCache>(cache_policy, max_cache_size_in_bytes, size_ratio);\n+}\n+\n+void Context::updatePrimaryIndexCacheConfiguration(const Poco::Util::AbstractConfiguration & config)\n+{\n+    std::lock_guard lock(shared->mutex);\n+\n+    if (!shared->primary_index_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Primary index cache was not created yet.\");\n+\n+    size_t max_size_in_bytes = config.getUInt64(\"primary_index_cache_size\", DEFAULT_PRIMARY_INDEX_CACHE_MAX_SIZE);\n+    shared->primary_index_cache->setMaxSizeInBytes(max_size_in_bytes);\n+}\n+\n+PrimaryIndexCachePtr Context::getPrimaryIndexCache() const\n+{\n+    SharedLockGuard lock(shared->mutex);\n+    return shared->primary_index_cache;\n+}\n+\n+void Context::clearPrimaryIndexCache() const\n+{\n+    std::lock_guard lock(shared->mutex);\n+\n+    if (shared->primary_index_cache)\n+        shared->primary_index_cache->clear();\n+}\n+\n void Context::setIndexUncompressedCache(const String & cache_policy, size_t max_size_in_bytes, double size_ratio)\n {\n     std::lock_guard lock(shared->mutex);\n@@ -3409,6 +3446,10 @@ void Context::clearCaches() const\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Mark cache was not created yet.\");\n     shared->mark_cache->clear();\n \n+    if (!shared->primary_index_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Primary index cache was not created yet.\");\n+    shared->primary_index_cache->clear();\n+\n     if (!shared->index_uncompressed_cache)\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Index uncompressed cache was not created yet.\");\n     shared->index_uncompressed_cache->clear();\ndiff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h\nindex 327ac0af5fd3..1c5b3d80e93b 100644\n--- a/src/Interpreters/Context.h\n+++ b/src/Interpreters/Context.h\n@@ -89,6 +89,7 @@ class RefreshSet;\n class Cluster;\n class Compiler;\n class MarkCache;\n+class PrimaryIndexCache;\n class PageCache;\n class MMappedFileCache;\n class UncompressedCache;\n@@ -1076,6 +1077,11 @@ class Context: public ContextData, public std::enable_shared_from_this<Context>\n     void clearMarkCache() const;\n     ThreadPool & getLoadMarksThreadpool() const;\n \n+    void setPrimaryIndexCache(const String & cache_policy, size_t max_cache_size_in_bytes, double size_ratio);\n+    void updatePrimaryIndexCacheConfiguration(const Poco::Util::AbstractConfiguration & config);\n+    std::shared_ptr<PrimaryIndexCache> getPrimaryIndexCache() const;\n+    void clearPrimaryIndexCache() const;\n+\n     void setIndexUncompressedCache(const String & cache_policy, size_t max_size_in_bytes, double size_ratio);\n     void updateIndexUncompressedCacheConfiguration(const Poco::Util::AbstractConfiguration & config);\n     std::shared_ptr<UncompressedCache> getIndexUncompressedCache() const;\ndiff --git a/src/Interpreters/InterpreterSystemQuery.cpp b/src/Interpreters/InterpreterSystemQuery.cpp\nindex 21b8be93f925..63e5fe1a3bd5 100644\n--- a/src/Interpreters/InterpreterSystemQuery.cpp\n+++ b/src/Interpreters/InterpreterSystemQuery.cpp\n@@ -371,10 +371,19 @@ BlockIO InterpreterSystemQuery::execute()\n             prewarmMarkCache();\n             break;\n         }\n+        case Type::PREWARM_PRIMARY_INDEX_CACHE:\n+        {\n+            prewarmPrimaryIndexCache();\n+            break;\n+        }\n         case Type::DROP_MARK_CACHE:\n             getContext()->checkAccess(AccessType::SYSTEM_DROP_MARK_CACHE);\n             system_context->clearMarkCache();\n             break;\n+        case Type::DROP_PRIMARY_INDEX_CACHE:\n+            getContext()->checkAccess(AccessType::SYSTEM_DROP_PRIMARY_INDEX_CACHE);\n+            system_context->clearPrimaryIndexCache();\n+            break;\n         case Type::DROP_UNCOMPRESSED_CACHE:\n             getContext()->checkAccess(AccessType::SYSTEM_DROP_UNCOMPRESSED_CACHE);\n             system_context->clearUncompressedCache();\n@@ -1319,17 +1328,45 @@ void InterpreterSystemQuery::prewarmMarkCache()\n \n     auto table_ptr = DatabaseCatalog::instance().getTable(table_id, getContext());\n     auto * merge_tree = dynamic_cast<MergeTreeData *>(table_ptr.get());\n-\n     if (!merge_tree)\n         throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Command PREWARM MARK CACHE is supported only for MergeTree table, but got: {}\", table_ptr->getName());\n \n+    auto mark_cache = getContext()->getMarkCache();\n+    if (!mark_cache)\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Mark cache is not configured\");\n+\n     ThreadPool pool(\n         CurrentMetrics::MergeTreePartsLoaderThreads,\n         CurrentMetrics::MergeTreePartsLoaderThreadsActive,\n         CurrentMetrics::MergeTreePartsLoaderThreadsScheduled,\n         getContext()->getSettingsRef()[Setting::max_threads]);\n \n-    merge_tree->prewarmMarkCache(pool);\n+    merge_tree->prewarmCaches(pool, std::move(mark_cache), nullptr);\n+}\n+\n+void InterpreterSystemQuery::prewarmPrimaryIndexCache()\n+{\n+    if (table_id.empty())\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Table is not specified for PREWARM PRIMARY INDEX CACHE command\");\n+\n+    getContext()->checkAccess(AccessType::SYSTEM_PREWARM_PRIMARY_INDEX_CACHE, table_id);\n+\n+    auto table_ptr = DatabaseCatalog::instance().getTable(table_id, getContext());\n+    auto * merge_tree = dynamic_cast<MergeTreeData *>(table_ptr.get());\n+    if (!merge_tree)\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Command PREWARM PRIMARY INDEX CACHE is supported only for MergeTree table, but got: {}\", table_ptr->getName());\n+\n+    auto index_cache = merge_tree->getPrimaryIndexCache();\n+    if (!index_cache)\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Primary index cache is not configured or is not enabled for table {}\", table_id.getFullTableName());\n+\n+    ThreadPool pool(\n+        CurrentMetrics::MergeTreePartsLoaderThreads,\n+        CurrentMetrics::MergeTreePartsLoaderThreadsActive,\n+        CurrentMetrics::MergeTreePartsLoaderThreadsScheduled,\n+        getContext()->getSettingsRef()[Setting::max_threads]);\n+\n+    merge_tree->prewarmCaches(pool, nullptr, std::move(index_cache));\n }\n \n \n@@ -1351,6 +1388,7 @@ AccessRightsElements InterpreterSystemQuery::getRequiredAccessForDDLOnCluster()\n         case Type::DROP_DNS_CACHE:\n         case Type::DROP_CONNECTIONS_CACHE:\n         case Type::DROP_MARK_CACHE:\n+        case Type::DROP_PRIMARY_INDEX_CACHE:\n         case Type::DROP_MMAP_CACHE:\n         case Type::DROP_QUERY_CACHE:\n         case Type::DROP_COMPILED_EXPRESSION_CACHE:\n@@ -1538,6 +1576,11 @@ AccessRightsElements InterpreterSystemQuery::getRequiredAccessForDDLOnCluster()\n             required_access.emplace_back(AccessType::SYSTEM_PREWARM_MARK_CACHE, query.getDatabase(), query.getTable());\n             break;\n         }\n+        case Type::PREWARM_PRIMARY_INDEX_CACHE:\n+        {\n+            required_access.emplace_back(AccessType::SYSTEM_PREWARM_MARK_CACHE, query.getDatabase(), query.getTable());\n+            break;\n+        }\n         case Type::SYNC_DATABASE_REPLICA:\n         {\n             required_access.emplace_back(AccessType::SYSTEM_SYNC_DATABASE_REPLICA, query.getDatabase());\ndiff --git a/src/Interpreters/InterpreterSystemQuery.h b/src/Interpreters/InterpreterSystemQuery.h\nindex e31c6cd739b4..09cdeb720939 100644\n--- a/src/Interpreters/InterpreterSystemQuery.h\n+++ b/src/Interpreters/InterpreterSystemQuery.h\n@@ -82,7 +82,9 @@ class InterpreterSystemQuery : public IInterpreter, WithMutableContext\n \n     AccessRightsElements getRequiredAccessForDDLOnCluster() const;\n     void startStopAction(StorageActionBlockType action_type, bool start);\n+\n     void prewarmMarkCache();\n+    void prewarmPrimaryIndexCache();\n \n     void stopReplicatedDDLQueries();\n     void startReplicatedDDLQueries();\ndiff --git a/src/Interpreters/ServerAsynchronousMetrics.cpp b/src/Interpreters/ServerAsynchronousMetrics.cpp\nindex 46a811822c2d..dfaebec03a8d 100644\n--- a/src/Interpreters/ServerAsynchronousMetrics.cpp\n+++ b/src/Interpreters/ServerAsynchronousMetrics.cpp\n@@ -83,6 +83,12 @@ void ServerAsynchronousMetrics::updateImpl(TimePoint update_time, TimePoint curr\n         new_values[\"MarkCacheFiles\"] = { mark_cache->count(), \"Total number of mark files cached in the mark cache\" };\n     }\n \n+    if (auto primary_index_cache = getContext()->getPrimaryIndexCache())\n+    {\n+        new_values[\"PrimaryIndexCacheBytes\"] = { primary_index_cache->sizeInBytes(), \"Total size of primary index cache in bytes\" };\n+        new_values[\"PrimaryIndexCacheFiles\"] = { primary_index_cache->count(), \"Total number of index files cached in the primary index cache\" };\n+    }\n+\n     if (auto page_cache = getContext()->getPageCache())\n     {\n         auto rss = page_cache->getResidentSetSize();\ndiff --git a/src/Parsers/ASTSystemQuery.cpp b/src/Parsers/ASTSystemQuery.cpp\nindex d76d33ce7083..ec908b02e7b7 100644\n--- a/src/Parsers/ASTSystemQuery.cpp\n+++ b/src/Parsers/ASTSystemQuery.cpp\n@@ -192,6 +192,7 @@ void ASTSystemQuery::formatImpl(const FormatSettings & settings, FormatState & s\n         case Type::WAIT_LOADING_PARTS:\n         case Type::FLUSH_DISTRIBUTED:\n         case Type::PREWARM_MARK_CACHE:\n+        case Type::PREWARM_PRIMARY_INDEX_CACHE:\n         {\n             if (table)\n             {\n@@ -408,6 +409,7 @@ void ASTSystemQuery::formatImpl(const FormatSettings & settings, FormatState & s\n         case Type::DROP_MMAP_CACHE:\n         case Type::DROP_QUERY_CACHE:\n         case Type::DROP_MARK_CACHE:\n+        case Type::DROP_PRIMARY_INDEX_CACHE:\n         case Type::DROP_INDEX_MARK_CACHE:\n         case Type::DROP_UNCOMPRESSED_CACHE:\n         case Type::DROP_INDEX_UNCOMPRESSED_CACHE:\ndiff --git a/src/Parsers/ASTSystemQuery.h b/src/Parsers/ASTSystemQuery.h\nindex d9ee4d8aa22b..78852cd9fac0 100644\n--- a/src/Parsers/ASTSystemQuery.h\n+++ b/src/Parsers/ASTSystemQuery.h\n@@ -24,7 +24,9 @@ class ASTSystemQuery : public IAST, public ASTQueryWithOnCluster\n         DROP_DNS_CACHE,\n         DROP_CONNECTIONS_CACHE,\n         PREWARM_MARK_CACHE,\n+        PREWARM_PRIMARY_INDEX_CACHE,\n         DROP_MARK_CACHE,\n+        DROP_PRIMARY_INDEX_CACHE,\n         DROP_UNCOMPRESSED_CACHE,\n         DROP_INDEX_MARK_CACHE,\n         DROP_INDEX_UNCOMPRESSED_CACHE,\ndiff --git a/src/Parsers/ParserSystemQuery.cpp b/src/Parsers/ParserSystemQuery.cpp\nindex 453ae0b50324..c1f33dc74a35 100644\n--- a/src/Parsers/ParserSystemQuery.cpp\n+++ b/src/Parsers/ParserSystemQuery.cpp\n@@ -277,6 +277,7 @@ bool ParserSystemQuery::parseImpl(IParser::Pos & pos, ASTPtr & node, Expected &\n         case Type::SYNC_REPLICA:\n         case Type::WAIT_LOADING_PARTS:\n         case Type::PREWARM_MARK_CACHE:\n+        case Type::PREWARM_PRIMARY_INDEX_CACHE:\n         {\n             if (!parseQueryWithOnCluster(res, pos, expected))\n                 return false;\ndiff --git a/src/Processors/QueryPlan/PartsSplitter.cpp b/src/Processors/QueryPlan/PartsSplitter.cpp\nindex 2b860f452198..bac910364091 100644\n--- a/src/Processors/QueryPlan/PartsSplitter.cpp\n+++ b/src/Processors/QueryPlan/PartsSplitter.cpp\n@@ -205,7 +205,7 @@ class IndexAccess\n     }\n private:\n     const RangesInDataParts & parts;\n-    std::vector<IMergeTreeDataPart::Index> indices;\n+    std::vector<IMergeTreeDataPart::IndexPtr> indices;\n     size_t loaded_columns = std::numeric_limits<size_t>::max();\n };\n \ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\nindex 229c33897538..1e3ea593f2aa 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n@@ -58,6 +58,13 @@ namespace CurrentMetrics\n     extern const Metric PartsCompact;\n }\n \n+namespace ProfileEvents\n+{\n+    extern const Event LoadedPrimaryIndexFiles;\n+    extern const Event LoadedPrimaryIndexRows;\n+    extern const Event LoadedPrimaryIndexBytes;\n+}\n+\n namespace DB\n {\n \n@@ -352,7 +359,6 @@ IMergeTreeDataPart::IMergeTreeDataPart(\n     incrementStateMetric(state);\n     incrementTypeMetric(part_type);\n \n-    index = std::make_shared<Columns>();\n     minmax_idx = std::make_shared<MinMaxIndex>();\n \n     initializeIndexGranularityInfo();\n@@ -365,46 +371,61 @@ IMergeTreeDataPart::~IMergeTreeDataPart()\n     decrementTypeMetric(part_type);\n }\n \n-\n-IMergeTreeDataPart::Index IMergeTreeDataPart::getIndex() const\n+IMergeTreeDataPart::IndexPtr IMergeTreeDataPart::getIndex() const\n {\n     std::scoped_lock lock(index_mutex);\n-    if (!index_loaded)\n-        loadIndex();\n-    index_loaded = true;\n+\n+    if (index)\n+        return index;\n+\n+    if (auto index_cache = storage.getPrimaryIndexCache())\n+        return loadIndexToCache(*index_cache);\n+\n+    index = loadIndex();\n     return index;\n }\n \n+IMergeTreeDataPart::IndexPtr IMergeTreeDataPart::loadIndexToCache(PrimaryIndexCache & index_cache) const\n+{\n+    auto key = PrimaryIndexCache::hash(getDataPartStorage().getFullPath());\n+    auto callback = [this] { return loadIndex(); };\n+    return index_cache.getOrSet(key, callback);\n+}\n \n-void IMergeTreeDataPart::setIndex(const Columns & cols_)\n+void IMergeTreeDataPart::moveIndexToCache(PrimaryIndexCache & index_cache)\n {\n     std::scoped_lock lock(index_mutex);\n-    if (!index->empty())\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"The index of data part can be set only once\");\n-    index = std::make_shared<const Columns>(cols_);\n-    index_loaded = true;\n+    if (!index)\n+        return;\n+\n+    auto key = PrimaryIndexCache::hash(getDataPartStorage().getFullPath());\n+    index_cache.set(key, std::const_pointer_cast<Index>(index));\n+    index.reset();\n+\n+    for (const auto & [_, projection] : projection_parts)\n+        projection->moveIndexToCache(index_cache);\n }\n \n-void IMergeTreeDataPart::setIndex(Columns && cols_)\n+void IMergeTreeDataPart::setIndex(Columns index_columns)\n {\n     std::scoped_lock lock(index_mutex);\n-    if (!index->empty())\n+    if (index)\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"The index of data part can be set only once\");\n-    index = std::make_shared<const Columns>(std::move(cols_));\n-    index_loaded = true;\n+\n+    optimizeIndexColumns(index_granularity->getMarksCount(), index_columns);\n+    index = std::make_shared<Index>(std::move(index_columns));\n }\n \n void IMergeTreeDataPart::unloadIndex()\n {\n     std::scoped_lock lock(index_mutex);\n-    index = std::make_shared<Columns>();\n-    index_loaded = false;\n+    index.reset();\n }\n \n bool IMergeTreeDataPart::isIndexLoaded() const\n {\n     std::scoped_lock lock(index_mutex);\n-    return index_loaded;\n+    return index != nullptr;\n }\n \n void IMergeTreeDataPart::setName(const String & new_name)\n@@ -615,8 +636,11 @@ void IMergeTreeDataPart::removeIfNeeded() noexcept\n UInt64 IMergeTreeDataPart::getIndexSizeInBytes() const\n {\n     std::scoped_lock lock(index_mutex);\n+    if (!index)\n+        return 0;\n+\n     UInt64 res = 0;\n-    for (const ColumnPtr & column : *index)\n+    for (const auto & column : *index)\n         res += column->byteSize();\n     return res;\n }\n@@ -624,8 +648,11 @@ UInt64 IMergeTreeDataPart::getIndexSizeInBytes() const\n UInt64 IMergeTreeDataPart::getIndexSizeInAllocatedBytes() const\n {\n     std::scoped_lock lock(index_mutex);\n+    if (!index)\n+        return 0;\n+\n     UInt64 res = 0;\n-    for (const ColumnPtr & column : *index)\n+    for (const auto & column : *index)\n         res += column->allocatedBytes();\n     return res;\n }\n@@ -755,7 +782,7 @@ void IMergeTreeDataPart::loadColumnsChecksumsIndexes(bool require_columns_checks\n         loadIndexGranularity();\n \n         if (!(*storage.getSettings())[MergeTreeSetting::primary_key_lazy_load])\n-            getIndex();\n+            index = loadIndex();\n \n         calculateColumnsAndSecondaryIndicesSizesOnDisk();\n         loadRowsCount(); /// Must be called after loadIndexGranularity() as it uses the value of `index_granularity`.\n@@ -929,7 +956,38 @@ void IMergeTreeDataPart::appendFilesOfIndexGranularity(Strings & /* files */) co\n {\n }\n \n-void IMergeTreeDataPart::loadIndex() const\n+template <typename Columns>\n+void IMergeTreeDataPart::optimizeIndexColumns(size_t marks_count, Columns & index_columns) const\n+{\n+    size_t key_size = index_columns.size();\n+    Float64 ratio_to_drop_suffix_columns = (*storage.getSettings())[MergeTreeSetting::primary_key_ratio_of_unique_prefix_values_to_skip_suffix_columns];\n+\n+    /// Cut useless suffix columns, if necessary.\n+    if (key_size > 1 && ratio_to_drop_suffix_columns > 0 && ratio_to_drop_suffix_columns < 1)\n+    {\n+        chassert(marks_count > 0);\n+        for (size_t j = 0; j < key_size - 1; ++j)\n+        {\n+            size_t num_changes = 0;\n+            for (size_t i = 1; i < marks_count; ++i)\n+            {\n+                if (0 != index_columns[j]->compareAt(i, i - 1, *index_columns[j], 0))\n+                    ++num_changes;\n+            }\n+\n+            if (static_cast<Float64>(num_changes) / marks_count >= ratio_to_drop_suffix_columns)\n+            {\n+                key_size = j + 1;\n+                index_columns.resize(key_size);\n+                break;\n+            }\n+        }\n+\n+        LOG_TEST(storage.log, \"Loaded primary key index for part {}, {} columns are kept in memory\", name, key_size);\n+    }\n+}\n+\n+std::shared_ptr<IMergeTreeDataPart::Index> IMergeTreeDataPart::loadIndex() const\n {\n     /// Memory for index must not be accounted as memory usage for query, because it belongs to a table.\n     MemoryTrackerBlockerInThread temporarily_disable_memory_tracker;\n@@ -937,70 +995,59 @@ void IMergeTreeDataPart::loadIndex() const\n     auto metadata_snapshot = storage.getInMemoryMetadataPtr();\n     if (parent_part)\n         metadata_snapshot = metadata_snapshot->projections.get(name).metadata;\n+\n     const auto & primary_key = metadata_snapshot->getPrimaryKey();\n     size_t key_size = primary_key.column_names.size();\n \n-    if (key_size)\n+    if (!key_size)\n+        return std::make_shared<Index>();\n+\n+    MutableColumns loaded_index;\n+    loaded_index.resize(key_size);\n+\n+    for (size_t i = 0; i < key_size; ++i)\n     {\n-        MutableColumns loaded_index;\n-        loaded_index.resize(key_size);\n+        loaded_index[i] = primary_key.data_types[i]->createColumn();\n+        loaded_index[i]->reserve(index_granularity->getMarksCount());\n+    }\n \n-        for (size_t i = 0; i < key_size; ++i)\n-        {\n-            loaded_index[i] = primary_key.data_types[i]->createColumn();\n-            loaded_index[i]->reserve(index_granularity->getMarksCount());\n-        }\n+    String index_name = \"primary\" + getIndexExtensionFromFilesystem(getDataPartStorage());\n+    String index_path = fs::path(getDataPartStorage().getRelativePath()) / index_name;\n+    auto index_file = metadata_manager->read(index_name);\n+    size_t marks_count = index_granularity->getMarksCount();\n \n-        String index_name = \"primary\" + getIndexExtensionFromFilesystem(getDataPartStorage());\n-        String index_path = fs::path(getDataPartStorage().getRelativePath()) / index_name;\n-        auto index_file = metadata_manager->read(index_name);\n-        size_t marks_count = index_granularity->getMarksCount();\n+    Serializations key_serializations(key_size);\n+    for (size_t j = 0; j < key_size; ++j)\n+        key_serializations[j] = primary_key.data_types[j]->getDefaultSerialization();\n \n-        Serializations key_serializations(key_size);\n+    for (size_t i = 0; i < marks_count; ++i)\n+    {\n         for (size_t j = 0; j < key_size; ++j)\n-            key_serializations[j] = primary_key.data_types[j]->getDefaultSerialization();\n-\n-        for (size_t i = 0; i < marks_count; ++i)\n-            for (size_t j = 0; j < key_size; ++j)\n-                key_serializations[j]->deserializeBinary(*loaded_index[j], *index_file, {});\n+            key_serializations[j]->deserializeBinary(*loaded_index[j], *index_file, {});\n+    }\n \n-        /// Cut useless suffix columns, if necessary.\n-        Float64 ratio_to_drop_suffix_columns = (*storage.getSettings())[MergeTreeSetting::primary_key_ratio_of_unique_prefix_values_to_skip_suffix_columns];\n-        if (key_size > 1 && ratio_to_drop_suffix_columns > 0 && ratio_to_drop_suffix_columns < 1)\n-        {\n-            chassert(marks_count > 0);\n-            for (size_t j = 0; j < key_size - 1; ++j)\n-            {\n-                size_t num_changes = 0;\n-                for (size_t i = 1; i < marks_count; ++i)\n-                    if (0 != loaded_index[j]->compareAt(i, i - 1, *loaded_index[j], 0))\n-                        ++num_changes;\n+    optimizeIndexColumns(marks_count, loaded_index);\n+    size_t total_bytes = 0;\n \n-                if (static_cast<Float64>(num_changes) / marks_count >= ratio_to_drop_suffix_columns)\n-                {\n-                    key_size = j + 1;\n-                    loaded_index.resize(key_size);\n-                    break;\n-                }\n-            }\n-        }\n+    for (const auto & column : loaded_index)\n+    {\n+        column->shrinkToFit();\n+        column->protect();\n+        total_bytes += column->byteSize();\n \n-        for (size_t i = 0; i < key_size; ++i)\n-        {\n-            loaded_index[i]->shrinkToFit();\n-            loaded_index[i]->protect();\n-            if (loaded_index[i]->size() != marks_count)\n-                throw Exception(ErrorCodes::CANNOT_READ_ALL_DATA, \"Cannot read all data from index file {}(expected size: \"\n-                    \"{}, read: {})\", index_path, marks_count, loaded_index[i]->size());\n-        }\n+        if (column->size() != marks_count)\n+            throw Exception(ErrorCodes::CANNOT_READ_ALL_DATA, \"Cannot read all data from index file {}(expected size: \"\n+                \"{}, read: {})\", index_path, marks_count, column->size());\n+    }\n \n-        LOG_TEST(storage.log, \"Loaded primary key index for part {}, {} columns are kept in memory\", name, key_size);\n+    if (!index_file->eof())\n+        throw Exception(ErrorCodes::EXPECTED_END_OF_FILE, \"Index file {} is unexpectedly long\", index_path);\n \n-        if (!index_file->eof())\n-            throw Exception(ErrorCodes::EXPECTED_END_OF_FILE, \"Index file {} is unexpectedly long\", index_path);\n+    ProfileEvents::increment(ProfileEvents::LoadedPrimaryIndexFiles);\n+    ProfileEvents::increment(ProfileEvents::LoadedPrimaryIndexRows, marks_count);\n+    ProfileEvents::increment(ProfileEvents::LoadedPrimaryIndexBytes, total_bytes);\n \n-        index = std::make_shared<Columns>(std::make_move_iterator(loaded_index.begin()), std::make_move_iterator(loaded_index.end()));\n-    }\n+    return std::make_shared<Index>(std::make_move_iterator(loaded_index.begin()), std::make_move_iterator(loaded_index.end()));\n }\n \n void IMergeTreeDataPart::appendFilesOfIndex(Strings & files) const\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.h b/src/Storages/MergeTree/IMergeTreeDataPart.h\nindex 1623290ecfac..013d024aaa81 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.h\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.h\n@@ -25,6 +25,7 @@\n #include <Interpreters/TransactionVersionMetadata.h>\n #include <DataTypes/Serializations/SerializationInfo.h>\n #include <Storages/MergeTree/IPartMetadataManager.h>\n+#include <Storages/MergeTree/PrimaryIndexCache.h>\n \n \n namespace zkutil\n@@ -77,7 +78,8 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     using ColumnSizeByName = std::unordered_map<std::string, ColumnSize>;\n     using NameToNumber = std::unordered_map<std::string, size_t>;\n \n-    using Index = std::shared_ptr<const Columns>;\n+    using Index = Columns;\n+    using IndexPtr = std::shared_ptr<const Index>;\n     using IndexSizeByName = std::unordered_map<std::string, ColumnSize>;\n \n     using Type = MergeTreeDataPartType;\n@@ -371,9 +373,11 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     /// Version of part metadata (columns, pk and so on). Managed properly only for replicated merge tree.\n     int32_t metadata_version;\n \n-    Index getIndex() const;\n-    void setIndex(const Columns & cols_);\n-    void setIndex(Columns && cols_);\n+    IndexPtr getIndex() const;\n+    IndexPtr loadIndexToCache(PrimaryIndexCache & index_cache) const;\n+    void moveIndexToCache(PrimaryIndexCache & index_cache);\n+\n+    void setIndex(Columns index_columns);\n     void unloadIndex();\n     bool isIndexLoaded() const;\n \n@@ -601,8 +605,7 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     /// Lazily loaded in RAM. Contains each index_granularity-th value of primary key tuple.\n     /// Note that marks (also correspond to primary key) are not always in RAM, but cached. See MarkCache.h.\n     mutable std::mutex index_mutex;\n-    mutable Index index TSA_GUARDED_BY(index_mutex);\n-    mutable bool index_loaded TSA_GUARDED_BY(index_mutex) = false;\n+    mutable IndexPtr index;\n \n     /// Total size of all columns, calculated once in calcuateColumnSizesOnDisk\n     ColumnSize total_columns_size;\n@@ -697,7 +700,11 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     virtual void appendFilesOfIndexGranularity(Strings & files) const;\n \n     /// Loads the index file.\n-    void loadIndex() const TSA_REQUIRES(index_mutex);\n+    std::shared_ptr<Index> loadIndex() const;\n+\n+    /// Optimize index. Drop useless columns from suffix of primary key.\n+    template <typename Columns>\n+    void optimizeIndexColumns(size_t marks_count, Columns & index_columns) const;\n \n     void appendFilesOfIndex(Strings & files) const;\n \ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPartWriter.cpp b/src/Storages/MergeTree/IMergeTreeDataPartWriter.cpp\nindex e0070dc23498..37a9cbffa4c6 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPartWriter.cpp\n+++ b/src/Storages/MergeTree/IMergeTreeDataPartWriter.cpp\n@@ -72,8 +72,11 @@ IMergeTreeDataPartWriter::IMergeTreeDataPartWriter(\n {\n }\n \n-Columns IMergeTreeDataPartWriter::releaseIndexColumns()\n+std::optional<Columns> IMergeTreeDataPartWriter::releaseIndexColumns()\n {\n+    if (!settings.save_primary_index_in_memory)\n+        return {};\n+\n     /// The memory for index was allocated without thread memory tracker.\n     /// We need to deallocate it in shrinkToFit without memory tracker as well.\n     MemoryTrackerBlockerInThread temporarily_disable_memory_tracker;\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPartWriter.h b/src/Storages/MergeTree/IMergeTreeDataPartWriter.h\nindex d6d8cbd115b2..e8129eeefb28 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPartWriter.h\n+++ b/src/Storages/MergeTree/IMergeTreeDataPartWriter.h\n@@ -49,7 +49,7 @@ class IMergeTreeDataPartWriter : private boost::noncopyable\n \n     virtual size_t getNumberOfOpenStreams() const = 0;\n \n-    Columns releaseIndexColumns();\n+    std::optional<Columns> releaseIndexColumns();\n \n     PlainMarksByName releaseCachedMarks();\n \ndiff --git a/src/Storages/MergeTree/MergeFromLogEntryTask.cpp b/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\nindex d7e807c689fc..fa03b3f63fb5 100644\n--- a/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\n+++ b/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\n@@ -445,8 +445,13 @@ bool MergeFromLogEntryTask::finalize(ReplicatedMergeMutateTaskBase::PartLogWrite\n     finish_callback = [storage_ptr = &storage]() { storage_ptr->merge_selecting_task->schedule(); };\n     ProfileEvents::increment(ProfileEvents::ReplicatedPartMerges);\n \n-    if (auto * mark_cache = storage.getContext()->getMarkCache().get())\n-        addMarksToCache(*part, cached_marks, mark_cache);\n+    if (auto mark_cache = storage.getMarkCacheToPrewarm())\n+        addMarksToCache(*part, cached_marks, mark_cache.get());\n+\n+    /// Move index to cache and reset it here because we need\n+    /// a correct part name after rename for a key of cache entry.\n+    if (auto index_cache = storage.getPrimaryIndexCacheToPrewarm())\n+        part->moveIndexToCache(*index_cache);\n \n     write_part_log({});\n     StorageReplicatedMergeTree::incrementMergedPartsProfileEvent(part->getType());\ndiff --git a/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp b/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp\nindex 5b3d410a493b..54fc58d60561 100644\n--- a/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp\n+++ b/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp\n@@ -152,10 +152,17 @@ void MergePlainMergeTreeTask::finish()\n     ThreadFuzzer::maybeInjectSleep();\n     ThreadFuzzer::maybeInjectMemoryLimitException();\n \n-    if (auto * mark_cache = storage.getContext()->getMarkCache().get())\n+    if (auto mark_cache = storage.getMarkCacheToPrewarm())\n     {\n         auto marks = merge_task->releaseCachedMarks();\n-        addMarksToCache(*new_part, marks, mark_cache);\n+        addMarksToCache(*new_part, marks, mark_cache.get());\n+    }\n+\n+    if (auto index_cache = storage.getPrimaryIndexCacheToPrewarm())\n+    {\n+        /// Move index to cache and reset it here because we need\n+        /// a correct part name after rename for a key of cache entry.\n+        new_part->moveIndexToCache(*index_cache);\n     }\n \n     write_part_log({});\ndiff --git a/src/Storages/MergeTree/MergeTask.cpp b/src/Storages/MergeTree/MergeTask.cpp\nindex b978beae14bb..8ce950f66ba5 100644\n--- a/src/Storages/MergeTree/MergeTask.cpp\n+++ b/src/Storages/MergeTree/MergeTask.cpp\n@@ -569,8 +569,6 @@ bool MergeTask::ExecuteAndFinalizeHorizontalPart::prepare() const\n         global_ctx->new_data_part->index_granularity_info,\n         ctx->blocks_are_granules_size);\n \n-    bool save_marks_in_cache = (*storage_settings)[MergeTreeSetting::prewarm_mark_cache] && global_ctx->context->getMarkCache();\n-\n     global_ctx->to = std::make_shared<MergedBlockOutputStream>(\n         global_ctx->new_data_part,\n         global_ctx->metadata_snapshot,\n@@ -581,7 +579,6 @@ bool MergeTask::ExecuteAndFinalizeHorizontalPart::prepare() const\n         std::move(index_granularity_ptr),\n         global_ctx->txn ? global_ctx->txn->tid : Tx::PrehistoricTID,\n         /*reset_columns=*/ true,\n-        save_marks_in_cache,\n         ctx->blocks_are_granules_size,\n         global_ctx->context->getWriteSettings());\n \n@@ -1120,8 +1117,6 @@ void MergeTask::VerticalMergeStage::prepareVerticalMergeForOneColumn() const\n     ctx->executor = std::make_unique<PullingPipelineExecutor>(ctx->column_parts_pipeline);\n     NamesAndTypesList columns_list = {*ctx->it_name_and_type};\n \n-    bool save_marks_in_cache = (*global_ctx->data->getSettings())[MergeTreeSetting::prewarm_mark_cache] && global_ctx->context->getMarkCache();\n-\n     ctx->column_to = std::make_unique<MergedColumnOnlyOutputStream>(\n         global_ctx->new_data_part,\n         global_ctx->metadata_snapshot,\n@@ -1130,8 +1125,7 @@ void MergeTask::VerticalMergeStage::prepareVerticalMergeForOneColumn() const\n         getStatisticsForColumns(columns_list, global_ctx->metadata_snapshot),\n         ctx->compression_codec,\n         global_ctx->to->getIndexGranularity(),\n-        &global_ctx->written_offset_columns,\n-        save_marks_in_cache);\n+        &global_ctx->written_offset_columns);\n \n     ctx->column_elems_written = 0;\n }\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex 907fa0bc4188..7b4385f49a50 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -233,13 +233,17 @@ namespace MergeTreeSetting\n     extern const MergeTreeSettingsString storage_policy;\n     extern const MergeTreeSettingsFloat zero_copy_concurrent_part_removal_max_postpone_ratio;\n     extern const MergeTreeSettingsUInt64 zero_copy_concurrent_part_removal_max_split_times;\n-    extern const MergeTreeSettingsBool enforce_index_structure_match_on_partition_manipulation;\n+    extern const MergeTreeSettingsBool use_primary_key_cache;\n+    extern const MergeTreeSettingsBool prewarm_primary_key_cache;\n     extern const MergeTreeSettingsBool prewarm_mark_cache;\n+    extern const MergeTreeSettingsBool primary_key_lazy_load;\n+    extern const MergeTreeSettingsBool enforce_index_structure_match_on_partition_manipulation;\n }\n \n namespace ServerSetting\n {\n     extern const ServerSettingsDouble mark_cache_prewarm_ratio;\n+    extern const ServerSettingsDouble primary_index_cache_prewarm_ratio;\n }\n \n namespace ErrorCodes\n@@ -2351,32 +2355,44 @@ void MergeTreeData::stopOutdatedAndUnexpectedDataPartsLoadingTask()\n     }\n }\n \n-void MergeTreeData::prewarmMarkCacheIfNeeded(ThreadPool & pool)\n+PrimaryIndexCachePtr MergeTreeData::getPrimaryIndexCache() const\n {\n-    if (!(*getSettings())[MergeTreeSetting::prewarm_mark_cache])\n-        return;\n+    bool use_primary_key_cache = (*getSettings())[MergeTreeSetting::use_primary_key_cache];\n+    bool primary_key_lazy_load = (*getSettings())[MergeTreeSetting::primary_key_lazy_load];\n \n-    prewarmMarkCache(pool);\n+    if (!use_primary_key_cache || !primary_key_lazy_load)\n+        return nullptr;\n+\n+    return getContext()->getPrimaryIndexCache();\n }\n \n-void MergeTreeData::prewarmMarkCache(ThreadPool & pool)\n+PrimaryIndexCachePtr MergeTreeData::getPrimaryIndexCacheToPrewarm() const\n {\n-    auto * mark_cache = getContext()->getMarkCache().get();\n-    if (!mark_cache)\n-        return;\n+    if (!(*getSettings())[MergeTreeSetting::prewarm_primary_key_cache])\n+        return nullptr;\n \n-    auto metadata_snaphost = getInMemoryMetadataPtr();\n-    auto column_names = getColumnsToPrewarmMarks(*getSettings(), metadata_snaphost->getColumns().getAllPhysical());\n+    return getPrimaryIndexCache();\n+}\n+\n+MarkCachePtr MergeTreeData::getMarkCacheToPrewarm() const\n+{\n+    if (!(*getSettings())[MergeTreeSetting::prewarm_mark_cache])\n+        return nullptr;\n+\n+    return getContext()->getMarkCache();\n+}\n \n-    if (column_names.empty())\n+void MergeTreeData::prewarmCaches(ThreadPool & pool, MarkCachePtr mark_cache, PrimaryIndexCachePtr index_cache)\n+{\n+    if (!mark_cache && !index_cache)\n         return;\n \n     Stopwatch watch;\n-    LOG_TRACE(log, \"Prewarming mark cache\");\n+    LOG_TRACE(log, \"Prewarming mark and/or primary index caches\");\n \n     auto data_parts = getDataPartsVectorForInternalUsage();\n \n-    /// Prewarm mark cache firstly for the most fresh parts according\n+    /// Prewarm caches firstly for the most fresh parts according\n     /// to time columns in partition key (if exists) and by modification time.\n \n     auto to_tuple = [](const auto & part)\n@@ -2389,20 +2405,41 @@ void MergeTreeData::prewarmMarkCache(ThreadPool & pool)\n         return to_tuple(lhs) > to_tuple(rhs);\n     });\n \n-    ThreadPoolCallbackRunnerLocal<void> runner(pool, \"PrewarmMarks\");\n-    double ratio_to_prewarm = getContext()->getServerSettings()[ServerSetting::mark_cache_prewarm_ratio];\n+    ThreadPoolCallbackRunnerLocal<void> runner(pool, \"PrewarmCaches\");\n+\n+    double marks_ratio_to_prewarm = getContext()->getServerSettings()[ServerSetting::mark_cache_prewarm_ratio];\n+    double index_ratio_to_prewarm = getContext()->getServerSettings()[ServerSetting::primary_index_cache_prewarm_ratio];\n+\n+    Names columns_to_prewarm_marks;\n+\n+    if (mark_cache)\n+    {\n+        auto metadata_snaphost = getInMemoryMetadataPtr();\n+        columns_to_prewarm_marks = getColumnsToPrewarmMarks(*getSettings(), metadata_snaphost->getColumns().getAllPhysical());\n+    }\n \n     for (const auto & part : data_parts)\n     {\n-        if (mark_cache->sizeInBytes() >= mark_cache->maxSizeInBytes() * ratio_to_prewarm)\n-            break;\n+        bool added_task = false;\n \n-        runner([&] { part->loadMarksToCache(column_names, mark_cache); });\n+        if (index_cache && !part->isIndexLoaded() && index_cache->sizeInBytes() < index_cache->maxSizeInBytes() * index_ratio_to_prewarm)\n+        {\n+            added_task = true;\n+            runner([&] { part->loadIndexToCache(*index_cache); });\n+        }\n+\n+        if (mark_cache && mark_cache->sizeInBytes() < mark_cache->maxSizeInBytes() * marks_ratio_to_prewarm)\n+        {\n+            added_task = true;\n+            runner([&] { part->loadMarksToCache(columns_to_prewarm_marks, mark_cache.get()); });\n+        }\n+\n+        if (!added_task)\n+            break;\n     }\n \n     runner.waitForAllToFinishAndRethrowFirstError();\n-    watch.stop();\n-    LOG_TRACE(log, \"Prewarmed mark cache in {} seconds\", watch.elapsedSeconds());\n+    LOG_TRACE(log, \"Prewarmed mark and/or primary index caches in {} seconds\", watch.elapsedSeconds());\n }\n \n /// Is the part directory old.\ndiff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h\nindex fe3609078752..240cfa717487 100644\n--- a/src/Storages/MergeTree/MergeTreeData.h\n+++ b/src/Storages/MergeTree/MergeTreeData.h\n@@ -31,6 +31,8 @@\n #include <Storages/DataDestinationType.h>\n #include <Storages/extractKeyExpressionList.h>\n #include <Storages/PartitionCommands.h>\n+#include <Storages/MarkCache.h>\n+#include <Storages/MergeTree/PrimaryIndexCache.h>\n #include <Interpreters/PartLog.h>\n #include <Poco/Timestamp.h>\n #include <Common/threadPoolCallbackRunner.h>\n@@ -506,9 +508,15 @@ class MergeTreeData : public IStorage, public WithMutableContext\n     /// Load the set of data parts from disk. Call once - immediately after the object is created.\n     void loadDataParts(bool skip_sanity_checks, std::optional<std::unordered_set<std::string>> expected_parts);\n \n-    /// Prewarm mark cache for the most recent data parts.\n-    void prewarmMarkCache(ThreadPool & pool);\n-    void prewarmMarkCacheIfNeeded(ThreadPool & pool);\n+    /// Returns a pointer to primary index cache if it is enabled.\n+    PrimaryIndexCachePtr getPrimaryIndexCache() const;\n+    /// Returns a pointer to primary index cache if it is enabled and required to be prewarmed.\n+    PrimaryIndexCachePtr getPrimaryIndexCacheToPrewarm() const;\n+    /// Returns a pointer to primary mark cache if it is required to be prewarmed.\n+    MarkCachePtr getMarkCacheToPrewarm() const;\n+\n+    /// Prewarm mark cache and primary index cache for the most recent data parts.\n+    void prewarmCaches(ThreadPool & pool, MarkCachePtr mark_cache, PrimaryIndexCachePtr index_cache);\n \n     String getLogName() const { return log.loadName(); }\n \ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp b/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\nindex 391b7be64e26..bd6feb993295 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\n@@ -317,9 +317,10 @@ void MergeTreeDataPartWriterOnDisk::calculateAndSerializePrimaryIndexRow(const B\n     for (size_t i = 0; i < index_block.columns(); ++i)\n     {\n         const auto & column = index_block.getByPosition(i).column;\n-\n-        index_columns[i]->insertFrom(*column, row);\n         index_serializations[i]->serializeBinary(*column, row, index_stream, {});\n+\n+        if (settings.save_primary_index_in_memory)\n+            index_columns[i]->insertFrom(*column, row);\n     }\n }\n \n@@ -337,8 +338,10 @@ void MergeTreeDataPartWriterOnDisk::calculateAndSerializePrimaryIndex(const Bloc\n          */\n         MemoryTrackerBlockerInThread temporarily_disable_memory_tracker;\n \n-        if (index_columns.empty())\n+        if (settings.save_primary_index_in_memory && index_columns.empty())\n+        {\n             index_columns = primary_index_block.cloneEmptyColumns();\n+        }\n \n         /// Write index. The index contains Primary Key value for each `index_granularity` row.\n         for (const auto & granule : granules_to_write)\ndiff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\nindex 52ea6db787d2..56b9eaff2615 100644\n--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\n@@ -1074,7 +1074,7 @@ MarkRanges MergeTreeDataSelectExecutor::markRangesFromPKRange(\n     DataTypes key_types;\n     if (!key_indices.empty())\n     {\n-        const auto & index = part->getIndex();\n+        const auto index = part->getIndex();\n \n         for (size_t i : key_indices)\n         {\ndiff --git a/src/Storages/MergeTree/MergeTreeDataWriter.cpp b/src/Storages/MergeTree/MergeTreeDataWriter.cpp\nindex 5e78ab49010d..a0e1de24cf14 100644\n--- a/src/Storages/MergeTree/MergeTreeDataWriter.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataWriter.cpp\n@@ -14,7 +14,7 @@\n #include <Storages/MergeTree/MergedBlockOutputStream.h>\n #include <Storages/MergeTree/MergeTreeSettings.h>\n #include <Storages/MergeTree/RowOrderOptimizer.h>\n-#include \"Common/logger_useful.h\"\n+#include <Storages/MergeTree/MergeTreeMarksLoader.h>\n #include <Common/ElapsedTimeProfileEventIncrement.h>\n #include <Common/Exception.h>\n #include <Common/HashTable/HashMap.h>\n@@ -74,7 +74,6 @@ namespace MergeTreeSetting\n     extern const MergeTreeSettingsFloat min_free_disk_ratio_to_perform_insert;\n     extern const MergeTreeSettingsBool optimize_row_order;\n     extern const MergeTreeSettingsFloat ratio_of_defaults_for_sparse_serialization;\n-    extern const MergeTreeSettingsBool prewarm_mark_cache;\n }\n \n namespace ErrorCodes\n@@ -226,6 +225,27 @@ void MergeTreeDataWriter::TemporaryPart::finalize()\n         projection->getDataPartStorage().precommitTransaction();\n }\n \n+void MergeTreeDataWriter::TemporaryPart::prewarmCaches()\n+{\n+    /// This method must be called after rename and commit of part\n+    /// because a correct path is required for the keys of caches.\n+\n+    if (auto mark_cache = part->storage.getMarkCacheToPrewarm())\n+    {\n+        for (const auto & stream : streams)\n+        {\n+            auto marks = stream.stream->releaseCachedMarks();\n+            addMarksToCache(*part, marks, mark_cache.get());\n+        }\n+    }\n+\n+    if (auto index_cache = part->storage.getPrimaryIndexCacheToPrewarm())\n+    {\n+        /// Index was already set during writing. Now move it to cache.\n+        part->moveIndexToCache(*index_cache);\n+    }\n+}\n+\n std::vector<AsyncInsertInfoPtr> scatterAsyncInsertInfoBySelector(AsyncInsertInfoPtr async_insert_info, const IColumn::Selector & selector, size_t partition_num)\n {\n     if (nullptr == async_insert_info)\n@@ -684,7 +704,6 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeTempPartImpl(\n     /// This effectively chooses minimal compression method:\n     ///  either default lz4 or compression method with zero thresholds on absolute and relative part size.\n     auto compression_codec = data.getContext()->chooseCompressionCodec(0, 0);\n-    bool save_marks_in_cache = (*data_settings)[MergeTreeSetting::prewarm_mark_cache] && data.getContext()->getMarkCache();\n \n     auto index_granularity_ptr = createMergeTreeIndexGranularity(\n         block.rows(),\n@@ -703,7 +722,6 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeTempPartImpl(\n         std::move(index_granularity_ptr),\n         context->getCurrentTransaction() ? context->getCurrentTransaction()->tid : Tx::PrehistoricTID,\n         /*reset_columns=*/ false,\n-        save_marks_in_cache,\n         /*blocks_are_granules_size=*/ false,\n         context->getWriteSettings());\n \n@@ -839,7 +857,6 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeProjectionPartImpl(\n     /// This effectively chooses minimal compression method:\n     ///  either default lz4 or compression method with zero thresholds on absolute and relative part size.\n     auto compression_codec = data.getContext()->chooseCompressionCodec(0, 0);\n-    bool save_marks_in_cache = (*data.getSettings())[MergeTreeSetting::prewarm_mark_cache] && data.getContext()->getMarkCache();\n \n     auto index_granularity_ptr = createMergeTreeIndexGranularity(\n         block.rows(),\n@@ -859,7 +876,6 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeProjectionPartImpl(\n         std::move(index_granularity_ptr),\n         Tx::PrehistoricTID,\n         /*reset_columns=*/ false,\n-        save_marks_in_cache,\n         /*blocks_are_granules_size=*/ false,\n         data.getContext()->getWriteSettings());\n \ndiff --git a/src/Storages/MergeTree/MergeTreeDataWriter.h b/src/Storages/MergeTree/MergeTreeDataWriter.h\nindex 863c951d9575..c2224a72683f 100644\n--- a/src/Storages/MergeTree/MergeTreeDataWriter.h\n+++ b/src/Storages/MergeTree/MergeTreeDataWriter.h\n@@ -75,6 +75,7 @@ class MergeTreeDataWriter\n \n         void cancel();\n         void finalize();\n+        void prewarmCaches();\n     };\n \n     /** All rows must correspond to same partition.\ndiff --git a/src/Storages/MergeTree/MergeTreeIOSettings.cpp b/src/Storages/MergeTree/MergeTreeIOSettings.cpp\nindex dd6d0fea6027..5d4c9eb72407 100644\n--- a/src/Storages/MergeTree/MergeTreeIOSettings.cpp\n+++ b/src/Storages/MergeTree/MergeTreeIOSettings.cpp\n@@ -36,6 +36,7 @@ MergeTreeWriterSettings::MergeTreeWriterSettings(\n     bool can_use_adaptive_granularity_,\n     bool rewrite_primary_key_,\n     bool save_marks_in_cache_,\n+    bool save_primary_index_in_memory_,\n     bool blocks_are_granules_size_)\n     : min_compress_block_size(\n           (*storage_settings)[MergeTreeSetting::min_compress_block_size] ? (*storage_settings)[MergeTreeSetting::min_compress_block_size] : global_settings[Setting::min_compress_block_size])\n@@ -49,6 +50,7 @@ MergeTreeWriterSettings::MergeTreeWriterSettings(\n     , can_use_adaptive_granularity(can_use_adaptive_granularity_)\n     , rewrite_primary_key(rewrite_primary_key_)\n     , save_marks_in_cache(save_marks_in_cache_)\n+    , save_primary_index_in_memory(save_primary_index_in_memory_)\n     , blocks_are_granules_size(blocks_are_granules_size_)\n     , query_write_settings(query_write_settings_)\n     , low_cardinality_max_dictionary_size(global_settings[Setting::low_cardinality_max_dictionary_size])\ndiff --git a/src/Storages/MergeTree/MergeTreeIOSettings.h b/src/Storages/MergeTree/MergeTreeIOSettings.h\nindex 697d110d2684..b2300209fe12 100644\n--- a/src/Storages/MergeTree/MergeTreeIOSettings.h\n+++ b/src/Storages/MergeTree/MergeTreeIOSettings.h\n@@ -64,6 +64,7 @@ struct MergeTreeWriterSettings\n         bool can_use_adaptive_granularity_,\n         bool rewrite_primary_key_,\n         bool save_marks_in_cache_,\n+        bool save_primary_index_in_memory_,\n         bool blocks_are_granules_size_);\n \n     size_t min_compress_block_size;\n@@ -79,6 +80,7 @@ struct MergeTreeWriterSettings\n     bool can_use_adaptive_granularity;\n     bool rewrite_primary_key;\n     bool save_marks_in_cache;\n+    bool save_primary_index_in_memory;\n     bool blocks_are_granules_size;\n     WriteSettings query_write_settings;\n \ndiff --git a/src/Storages/MergeTree/MergeTreeSettings.cpp b/src/Storages/MergeTree/MergeTreeSettings.cpp\nindex 097c5b7036db..ae8baf1dae5e 100644\n--- a/src/Storages/MergeTree/MergeTreeSettings.cpp\n+++ b/src/Storages/MergeTree/MergeTreeSettings.cpp\n@@ -240,6 +240,8 @@ namespace ErrorCodes\n     DECLARE(UInt64, primary_key_compress_block_size, 65536, \"Primary compress block size, the actual size of the block to compress.\", 0) \\\n     DECLARE(Bool, primary_key_lazy_load, true, \"Load primary key in memory on first use instead of on table initialization. This can save memory in the presence of a large number of tables.\", 0) \\\n     DECLARE(Float, primary_key_ratio_of_unique_prefix_values_to_skip_suffix_columns, 0.9f, \"If the value of a column of the primary key in data part changes at least in this ratio of times, skip loading next columns in memory. This allows to save memory usage by not loading useless columns of the primary key.\", 0) \\\n+    DECLARE(Bool, use_primary_key_cache, false, \"Use cache for primary index instead of saving all indexes in memory. Can be useful for very large tables\", 0) \\\n+    DECLARE(Bool, prewarm_primary_key_cache, false, \"If true primary index cache will be prewarmed by saving marks to mark cache on inserts, merges, fetches and on startup of server\", 0) \\\n     DECLARE(Bool, prewarm_mark_cache, false, \"If true mark cache will be prewarmed by saving marks to mark cache on inserts, merges, fetches and on startup of server\", 0) \\\n     DECLARE(String, columns_to_prewarm_mark_cache, \"\", \"List of columns to prewarm mark cache for (if enabled). Empty means all columns\", 0) \\\n     /** Projection settings. */ \\\ndiff --git a/src/Storages/MergeTree/MergeTreeSink.cpp b/src/Storages/MergeTree/MergeTreeSink.cpp\nindex 99852309c774..d65d1f3212f0 100644\n--- a/src/Storages/MergeTree/MergeTreeSink.cpp\n+++ b/src/Storages/MergeTree/MergeTreeSink.cpp\n@@ -247,14 +247,7 @@ void MergeTreeSink::finishDelayedChunk()\n         /// Part can be deduplicated, so increment counters and add to part log only if it's really added\n         if (added)\n         {\n-            if (auto * mark_cache = storage.getContext()->getMarkCache().get())\n-            {\n-                for (const auto & stream : partition.temp_part.streams)\n-                {\n-                    auto marks = stream.stream->releaseCachedMarks();\n-                    addMarksToCache(*part, marks, mark_cache);\n-                }\n-            }\n+            partition.temp_part.prewarmCaches();\n \n             auto counters_snapshot = std::make_shared<ProfileEvents::Counters::Snapshot>(partition.part_counters.getPartiallyAtomicSnapshot());\n             PartLog::addNewPart(storage.getContext(), PartLog::PartLogEntry(part, partition.elapsed_ns, counters_snapshot));\ndiff --git a/src/Storages/MergeTree/MergedBlockOutputStream.cpp b/src/Storages/MergeTree/MergedBlockOutputStream.cpp\nindex 979b46987381..db162bd82cbf 100644\n--- a/src/Storages/MergeTree/MergedBlockOutputStream.cpp\n+++ b/src/Storages/MergeTree/MergedBlockOutputStream.cpp\n@@ -30,7 +30,6 @@ MergedBlockOutputStream::MergedBlockOutputStream(\n     MergeTreeIndexGranularityPtr index_granularity_ptr,\n     TransactionID tid,\n     bool reset_columns_,\n-    bool save_marks_in_cache,\n     bool blocks_are_granules_size,\n     const WriteSettings & write_settings_)\n     : IMergedBlockOutputStream(data_part->storage.getSettings(), data_part->getDataPartStoragePtr(), metadata_snapshot_, columns_list_, reset_columns_)\n@@ -38,6 +37,11 @@ MergedBlockOutputStream::MergedBlockOutputStream(\n     , default_codec(default_codec_)\n     , write_settings(write_settings_)\n {\n+    /// Save marks in memory if prewarm is enabled to avoid re-reading marks file.\n+    bool save_marks_in_cache = data_part->storage.getMarkCacheToPrewarm() != nullptr;\n+    /// Save primary index in memory if cache is disabled or is enabled with prewarm to avoid re-reading primary index file.\n+    bool save_primary_index_in_memory = !data_part->storage.getPrimaryIndexCache() || data_part->storage.getPrimaryIndexCacheToPrewarm();\n+\n     MergeTreeWriterSettings writer_settings(\n         data_part->storage.getContext()->getSettingsRef(),\n         write_settings,\n@@ -45,6 +49,7 @@ MergedBlockOutputStream::MergedBlockOutputStream(\n         data_part->index_granularity_info.mark_type.adaptive,\n         /* rewrite_primary_key = */ true,\n         save_marks_in_cache,\n+        save_primary_index_in_memory,\n         blocks_are_granules_size);\n \n     /// TODO: looks like isStoredOnDisk() is always true for MergeTreeDataPart\n@@ -243,7 +248,7 @@ MergedBlockOutputStream::Finalizer MergedBlockOutputStream::finalizePartAsync(\n \n     new_part->rows_count = rows_count;\n     new_part->modification_time = time(nullptr);\n-    new_part->setIndex(writer->releaseIndexColumns());\n+\n     new_part->checksums = checksums;\n     new_part->setBytesOnDisk(checksums.getTotalSizeOnDisk());\n     new_part->setBytesUncompressedOnDisk(checksums.getTotalSizeUncompressedOnDisk());\n@@ -256,6 +261,9 @@ MergedBlockOutputStream::Finalizer MergedBlockOutputStream::finalizePartAsync(\n             new_part->index_granularity = std::move(new_index_granularity);\n     }\n \n+    if (auto computed_index = writer->releaseIndexColumns())\n+        new_part->setIndex(std::move(*computed_index));\n+\n     /// In mutation, existing_rows_count is already calculated in PartMergerWriter\n     /// In merge situation, lightweight deleted rows was physically deleted, existing_rows_count equals rows_count\n     if (!new_part->existing_rows_count.has_value())\ndiff --git a/src/Storages/MergeTree/MergedBlockOutputStream.h b/src/Storages/MergeTree/MergedBlockOutputStream.h\nindex afa2eaf18ec0..4be9f17d7001 100644\n--- a/src/Storages/MergeTree/MergedBlockOutputStream.h\n+++ b/src/Storages/MergeTree/MergedBlockOutputStream.h\n@@ -25,7 +25,6 @@ class MergedBlockOutputStream final : public IMergedBlockOutputStream\n         MergeTreeIndexGranularityPtr index_granularity_ptr,\n         TransactionID tid,\n         bool reset_columns_ = false,\n-        bool save_marks_in_cache = false,\n         bool blocks_are_granules_size = false,\n         const WriteSettings & write_settings = {});\n \ndiff --git a/src/Storages/MergeTree/MergedColumnOnlyOutputStream.cpp b/src/Storages/MergeTree/MergedColumnOnlyOutputStream.cpp\nindex c6fd992bbf6e..9f6ab952bc30 100644\n--- a/src/Storages/MergeTree/MergedColumnOnlyOutputStream.cpp\n+++ b/src/Storages/MergeTree/MergedColumnOnlyOutputStream.cpp\n@@ -1,11 +1,13 @@\n #include <Storages/MergeTree/MergedColumnOnlyOutputStream.h>\n #include <Storages/MergeTree/MergeTreeDataPartWriterOnDisk.h>\n+#include <Storages/MergeTree/MergeTreeSettings.h>\n #include <Core/Settings.h>\n #include <Interpreters/Context.h>\n #include <IO/WriteSettings.h>\n \n namespace DB\n {\n+\n namespace ErrorCodes\n {\n     extern const int NOT_IMPLEMENTED;\n@@ -19,20 +21,23 @@ MergedColumnOnlyOutputStream::MergedColumnOnlyOutputStream(\n     const ColumnsStatistics & stats_to_recalc,\n     CompressionCodecPtr default_codec,\n     MergeTreeIndexGranularityPtr index_granularity_ptr,\n-    WrittenOffsetColumns * offset_columns,\n-    bool save_marks_in_cache)\n+    WrittenOffsetColumns * offset_columns)\n     : IMergedBlockOutputStream(data_part->storage.getSettings(), data_part->getDataPartStoragePtr(), metadata_snapshot_, columns_list_, /*reset_columns=*/ true)\n {\n-    const auto & global_settings = data_part->storage.getContext()->getSettingsRef();\n+    /// Save marks in memory if prewarm is enabled to avoid re-reading marks file.\n+    bool save_marks_in_cache = data_part->storage.getMarkCacheToPrewarm() != nullptr;\n+    /// Save primary index in memory if cache is disabled or is enabled with prewarm to avoid re-reading priamry index file.\n+    bool save_primary_index_in_memory = !data_part->storage.getPrimaryIndexCache() || data_part->storage.getPrimaryIndexCacheToPrewarm();\n \n     /// Granularity is never recomputed while writing only columns.\n     MergeTreeWriterSettings writer_settings(\n-        global_settings,\n+        data_part->storage.getContext()->getSettingsRef(),\n         data_part->storage.getContext()->getWriteSettings(),\n         storage_settings,\n         data_part->index_granularity_info.mark_type.adaptive,\n         /*rewrite_primary_key=*/ false,\n         save_marks_in_cache,\n+        save_primary_index_in_memory,\n         /*blocks_are_granules_size=*/ false);\n \n     writer = createMergeTreeDataPartWriter(\ndiff --git a/src/Storages/MergeTree/MergedColumnOnlyOutputStream.h b/src/Storages/MergeTree/MergedColumnOnlyOutputStream.h\nindex f2f2f10d6ff9..2e4bf7c69578 100644\n--- a/src/Storages/MergeTree/MergedColumnOnlyOutputStream.h\n+++ b/src/Storages/MergeTree/MergedColumnOnlyOutputStream.h\n@@ -22,8 +22,7 @@ class MergedColumnOnlyOutputStream final : public IMergedBlockOutputStream\n         const ColumnsStatistics & stats_to_recalc,\n         CompressionCodecPtr default_codec,\n         MergeTreeIndexGranularityPtr index_granularity_ptr,\n-        WrittenOffsetColumns * offset_columns = nullptr,\n-        bool save_marks_in_cache = false);\n+        WrittenOffsetColumns * offset_columns = nullptr);\n \n     void write(const Block & block) override;\n \ndiff --git a/src/Storages/MergeTree/MutateTask.cpp b/src/Storages/MergeTree/MutateTask.cpp\nindex 0510f51b4ffd..8c8c07fa266d 100644\n--- a/src/Storages/MergeTree/MutateTask.cpp\n+++ b/src/Storages/MergeTree/MutateTask.cpp\n@@ -985,7 +985,6 @@ void finalizeMutatedPart(\n \n     new_data_part->rows_count = source_part->rows_count;\n     new_data_part->index_granularity = source_part->index_granularity;\n-    new_data_part->setIndex(*source_part->getIndex());\n     new_data_part->minmax_idx = source_part->minmax_idx;\n     new_data_part->modification_time = time(nullptr);\n \n@@ -995,6 +994,9 @@ void finalizeMutatedPart(\n             new_data_part->index_granularity = std::move(new_index_granularity);\n     }\n \n+    if (!new_data_part->storage.getPrimaryIndexCache())\n+        new_data_part->setIndex(*source_part->getIndex());\n+\n     /// Load rest projections which are hardlinked\n     bool noop;\n     new_data_part->loadProjections(false, false, noop, true /* if_not_loaded */);\n@@ -1650,7 +1652,6 @@ class MutateAllPartColumnsTask : public IExecutableTask\n             std::move(index_granularity_ptr),\n             ctx->txn ? ctx->txn->tid : Tx::PrehistoricTID,\n             /*reset_columns=*/ true,\n-            /*save_marks_in_cache=*/ false,\n             /*blocks_are_granules_size=*/ false,\n             ctx->context->getWriteSettings());\n \ndiff --git a/src/Storages/MergeTree/PrimaryIndexCache.cpp b/src/Storages/MergeTree/PrimaryIndexCache.cpp\nnew file mode 100644\nindex 000000000000..aeb9969f5787\n--- /dev/null\n+++ b/src/Storages/MergeTree/PrimaryIndexCache.cpp\n@@ -0,0 +1,8 @@\n+#include <Storages/MergeTree/PrimaryIndexCache.h>\n+\n+namespace DB\n+{\n+\n+template class CacheBase<UInt128, PrimaryIndex, UInt128TrivialHash, PrimaryIndexWeightFunction>;\n+\n+}\ndiff --git a/src/Storages/MergeTree/PrimaryIndexCache.h b/src/Storages/MergeTree/PrimaryIndexCache.h\nnew file mode 100644\nindex 000000000000..5ec185dcf58c\n--- /dev/null\n+++ b/src/Storages/MergeTree/PrimaryIndexCache.h\n@@ -0,0 +1,74 @@\n+#pragma once\n+#include <Common/CacheBase.h>\n+#include <Common/ProfileEvents.h>\n+#include <Common/SipHash.h>\n+#include <Common/HashTable/Hash.h>\n+#include <Columns/IColumn.h>\n+\n+namespace ProfileEvents\n+{\n+    extern const Event PrimaryIndexCacheHits;\n+    extern const Event PrimaryIndexCacheMisses;\n+}\n+\n+namespace DB\n+{\n+\n+using PrimaryIndex = std::vector<ColumnPtr>;\n+\n+/// Estimate of number of bytes in cache for primary index.\n+struct PrimaryIndexWeightFunction\n+{\n+    /// We spent additional bytes on key in hashmap, linked lists, shared pointers, etc ...\n+    static constexpr size_t PRIMARY_INDEX_CACHE_OVERHEAD = 128;\n+\n+    size_t operator()(const PrimaryIndex & index) const\n+    {\n+        size_t res = 0;\n+        for (const auto & column : index)\n+            res += column->byteSize();\n+        return res;\n+    }\n+};\n+\n+extern template class CacheBase<UInt128, PrimaryIndex, UInt128TrivialHash, PrimaryIndexWeightFunction>;\n+\n+/** Cache of primary index for MergeTree tables.\n+  * Primary index is a list of columns from primary key\n+  * that store first row for each granule of data part.\n+  */\n+class PrimaryIndexCache : public CacheBase<UInt128, PrimaryIndex, UInt128TrivialHash, PrimaryIndexWeightFunction>\n+{\n+private:\n+    using Base = CacheBase<UInt128, PrimaryIndex, UInt128TrivialHash, PrimaryIndexWeightFunction>;\n+\n+public:\n+    PrimaryIndexCache(const String & cache_policy, size_t max_size_in_bytes, double size_ratio)\n+        : Base(cache_policy, max_size_in_bytes, 0, size_ratio)\n+    {\n+    }\n+\n+    /// Calculate key from path to file and offset.\n+    static UInt128 hash(const String & part_path)\n+    {\n+        SipHash hash;\n+        hash.update(part_path.data(), part_path.size() + 1);\n+        return hash.get128();\n+    }\n+\n+    template <typename LoadFunc>\n+    MappedPtr getOrSet(const Key & key, LoadFunc && load)\n+    {\n+        auto result = Base::getOrSet(key, load);\n+        if (result.second)\n+            ProfileEvents::increment(ProfileEvents::PrimaryIndexCacheMisses);\n+        else\n+            ProfileEvents::increment(ProfileEvents::PrimaryIndexCacheHits);\n+\n+        return result.first;\n+    }\n+};\n+\n+using PrimaryIndexCachePtr = std::shared_ptr<PrimaryIndexCache>;\n+\n+}\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp\nindex bb168893a837..19a69eb46be0 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp\n@@ -490,16 +490,9 @@ void ReplicatedMergeTreeSinkImpl<false>::finishDelayedChunk(const ZooKeeperWithF\n \n             /// Set a special error code if the block is duplicate\n             int error = (deduplicate && deduplicated) ? ErrorCodes::INSERT_WAS_DEDUPLICATED : 0;\n-            auto * mark_cache = storage.getContext()->getMarkCache().get();\n \n-            if (!error && mark_cache)\n-            {\n-                for (const auto & stream : partition.temp_part.streams)\n-                {\n-                    auto marks = stream.stream->releaseCachedMarks();\n-                    addMarksToCache(*part, marks, mark_cache);\n-                }\n-            }\n+            if (!error)\n+                partition.temp_part.prewarmCaches();\n \n             auto counters_snapshot = std::make_shared<ProfileEvents::Counters::Snapshot>(partition.part_counters.getPartiallyAtomicSnapshot());\n             PartLog::addNewPart(storage.getContext(), PartLog::PartLogEntry(part, partition.elapsed_ns, counters_snapshot), ExecutionStatus(error));\n@@ -544,14 +537,7 @@ void ReplicatedMergeTreeSinkImpl<true>::finishDelayedChunk(const ZooKeeperWithFa\n \n             if (conflict_block_ids.empty())\n             {\n-                if (auto * mark_cache = storage.getContext()->getMarkCache().get())\n-                {\n-                    for (const auto & stream : partition.temp_part.streams)\n-                    {\n-                        auto marks = stream.stream->releaseCachedMarks();\n-                        addMarksToCache(*partition.temp_part.part, marks, mark_cache);\n-                    }\n-                }\n+                partition.temp_part.prewarmCaches();\n \n                 auto counters_snapshot = std::make_shared<ProfileEvents::Counters::Snapshot>(partition.part_counters.getPartiallyAtomicSnapshot());\n                 PartLog::addNewPart(\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeSink.h b/src/Storages/MergeTree/ReplicatedMergeTreeSink.h\nindex 7d0253617170..b467cc167f80 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeSink.h\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeSink.h\n@@ -5,6 +5,7 @@\n #include <base/types.h>\n #include <Common/ZooKeeper/ZooKeeperRetries.h>\n #include <Common/ZooKeeper/ZooKeeperWithFaultInjection.h>\n+#include <Storages/MergeTree/MergeTreeDataWriter.h>\n #include <Storages/MergeTree/AsyncBlockIDsCache.h>\n \n \n@@ -129,6 +130,7 @@ class ReplicatedMergeTreeSinkImpl : public SinkToStorage\n     std::unique_ptr<DelayedChunk> delayed_chunk;\n \n     void finishDelayedChunk(const ZooKeeperWithFaultInjectionPtr & zookeeper);\n+    void prewarmCaches(const MergeTreeDataWriter::TemporaryPart & temp_part) const;\n };\n \n using ReplicatedMergeTreeSinkWithAsyncDeduplicate = ReplicatedMergeTreeSinkImpl<true>;\ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex 5b18bcf47071..166305e89106 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -155,7 +155,11 @@ StorageMergeTree::StorageMergeTree(\n \n     loadMutations();\n     loadDeduplicationLog();\n-    prewarmMarkCacheIfNeeded(getActivePartsLoadingThreadPool().get());\n+\n+    prewarmCaches(\n+        getActivePartsLoadingThreadPool().get(),\n+        getMarkCacheToPrewarm(),\n+        getPrimaryIndexCacheToPrewarm());\n }\n \n \ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 264644ffd28b..80914f78b4ca 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -208,7 +208,6 @@ namespace MergeTreeSetting\n     extern const MergeTreeSettingsBool use_minimalistic_checksums_in_zookeeper;\n     extern const MergeTreeSettingsBool use_minimalistic_part_header_in_zookeeper;\n     extern const MergeTreeSettingsMilliseconds wait_for_unique_parts_send_before_shutdown_ms;\n-    extern const MergeTreeSettingsBool prewarm_mark_cache;\n }\n \n namespace FailPoints\n@@ -511,7 +510,11 @@ StorageReplicatedMergeTree::StorageReplicatedMergeTree(\n     }\n \n     loadDataParts(skip_sanity_checks, expected_parts_on_this_replica);\n-    prewarmMarkCacheIfNeeded(getActivePartsLoadingThreadPool().get());\n+\n+    prewarmCaches(\n+        getActivePartsLoadingThreadPool().get(),\n+        getMarkCacheToPrewarm(),\n+        getPrimaryIndexCacheToPrewarm());\n \n     if (LoadingStrictnessLevel::ATTACH <= mode)\n     {\n@@ -5084,10 +5087,15 @@ bool StorageReplicatedMergeTree::fetchPart(\n                 ProfileEvents::increment(ProfileEvents::ObsoleteReplicatedParts);\n             }\n \n-            if ((*getSettings())[MergeTreeSetting::prewarm_mark_cache] && getContext()->getMarkCache())\n+            if (auto mark_cache = getMarkCacheToPrewarm())\n             {\n                 auto column_names = getColumnsToPrewarmMarks(*getSettings(), part->getColumns());\n-                part->loadMarksToCache(column_names, getContext()->getMarkCache().get());\n+                part->loadMarksToCache(column_names, mark_cache.get());\n+            }\n+\n+            if (auto index_cache = getPrimaryIndexCacheToPrewarm())\n+            {\n+                part->loadIndexToCache(*index_cache);\n             }\n \n             write_part_log({});\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01271_show_privileges.reference b/tests/queries/0_stateless/01271_show_privileges.reference\nindex de6df7ac021a..dddedb25f5a7 100644\n--- a/tests/queries/0_stateless/01271_show_privileges.reference\n+++ b/tests/queries/0_stateless/01271_show_privileges.reference\n@@ -114,6 +114,8 @@ SYSTEM DROP DNS CACHE\t['SYSTEM DROP DNS','DROP DNS CACHE','DROP DNS']\tGLOBAL\tSYS\n SYSTEM DROP CONNECTIONS CACHE\t['SYSTEM DROP CONNECTIONS CACHE','DROP CONNECTIONS CACHE']\tGLOBAL\tSYSTEM DROP CACHE\n SYSTEM PREWARM MARK CACHE\t['SYSTEM PREWARM MARK','PREWARM MARK CACHE','PREWARM MARKS']\tGLOBAL\tSYSTEM DROP CACHE\n SYSTEM DROP MARK CACHE\t['SYSTEM DROP MARK','DROP MARK CACHE','DROP MARKS']\tGLOBAL\tSYSTEM DROP CACHE\n+SYSTEM PREWARM PRIMARY INDEX CACHE\t['SYSTEM PREWARM PRIMARY INDEX','PREWARM PRIMARY INDEX CACHE','PREWARM PRIMARY INDEX']\tGLOBAL\tSYSTEM DROP CACHE\n+SYSTEM DROP PRIMARY INDEX CACHE\t['SYSTEM DROP PRIMARY INDEX','DROP PRIMARY INDEX CACHE','DROP PRIMARY INDEX']\tGLOBAL\tSYSTEM DROP CACHE\n SYSTEM DROP UNCOMPRESSED CACHE\t['SYSTEM DROP UNCOMPRESSED','DROP UNCOMPRESSED CACHE','DROP UNCOMPRESSED']\tGLOBAL\tSYSTEM DROP CACHE\n SYSTEM DROP MMAP CACHE\t['SYSTEM DROP MMAP','DROP MMAP CACHE','DROP MMAP']\tGLOBAL\tSYSTEM DROP CACHE\n SYSTEM DROP QUERY CACHE\t['SYSTEM DROP QUERY','DROP QUERY CACHE','DROP QUERY']\tGLOBAL\tSYSTEM DROP CACHE\ndiff --git a/tests/queries/0_stateless/03128_merge_tree_index_lazy_load.reference b/tests/queries/0_stateless/03128_merge_tree_index_lazy_load.reference\nindex 022457178ec0..5022e543cd24 100644\n--- a/tests/queries/0_stateless/03128_merge_tree_index_lazy_load.reference\n+++ b/tests/queries/0_stateless/03128_merge_tree_index_lazy_load.reference\n@@ -1,7 +1,7 @@\n 0\t0\t0\n-1\t4\t4\n-2\t8\t8\n-3\t9\t9\n+1\t4\t0\n+2\t8\t0\n+3\t9\t0\n 0\t0\t0\n 1\t4\t0\n 2\t8\t0\ndiff --git a/tests/queries/0_stateless/03273_primary_index_cache.reference b/tests/queries/0_stateless/03273_primary_index_cache.reference\nnew file mode 100644\nindex 000000000000..611787366ee8\n--- /dev/null\n+++ b/tests/queries/0_stateless/03273_primary_index_cache.reference\n@@ -0,0 +1,16 @@\n+0\n+PrimaryIndexCacheBytes\t0\n+PrimaryIndexCacheFiles\t0\n+99\n+0\n+PrimaryIndexCacheBytes\t1280\n+PrimaryIndexCacheFiles\t2\n+0\n+PrimaryIndexCacheBytes\t0\n+PrimaryIndexCacheFiles\t0\n+49\n+0\n+PrimaryIndexCacheBytes\t640\n+PrimaryIndexCacheFiles\t1\n+2\t160\t1280\n+1\t80\t640\ndiff --git a/tests/queries/0_stateless/03273_primary_index_cache.sql b/tests/queries/0_stateless/03273_primary_index_cache.sql\nnew file mode 100644\nindex 000000000000..04a03797bcbe\n--- /dev/null\n+++ b/tests/queries/0_stateless/03273_primary_index_cache.sql\n@@ -0,0 +1,45 @@\n+-- Tags: no-parallel\n+\n+DROP TABLE IF EXISTS t_primary_index_cache;\n+\n+CREATE TABLE t_primary_index_cache (a UInt64, b UInt64)\n+ENGINE = MergeTree ORDER BY a PARTITION BY a % 2\n+SETTINGS use_primary_key_cache = 1, prewarm_primary_key_cache = 0, index_granularity = 64, index_granularity_bytes = '10M', min_bytes_for_wide_part = 0;\n+\n+SYSTEM DROP PRIMARY INDEX CACHE;\n+\n+INSERT INTO t_primary_index_cache SELECT number, number FROM numbers(10000);\n+\n+SYSTEM RELOAD ASYNCHRONOUS METRICS;\n+SELECT sum(primary_key_bytes_in_memory) FROM system.parts WHERE table = 't_primary_index_cache' AND active;\n+SELECT metric, value FROM system.asynchronous_metrics WHERE metric IN ('PrimaryIndexCacheFiles', 'PrimaryIndexCacheBytes') ORDER BY metric;\n+\n+SELECT count() FROM t_primary_index_cache WHERE a > 100 AND a < 200;\n+\n+SYSTEM RELOAD ASYNCHRONOUS METRICS;\n+SELECT sum(primary_key_bytes_in_memory) FROM system.parts WHERE table = 't_primary_index_cache' AND active;\n+SELECT metric, value FROM system.asynchronous_metrics WHERE metric IN ('PrimaryIndexCacheFiles', 'PrimaryIndexCacheBytes') ORDER BY metric;\n+\n+SYSTEM DROP PRIMARY INDEX CACHE;\n+\n+SYSTEM RELOAD ASYNCHRONOUS METRICS;\n+SELECT sum(primary_key_bytes_in_memory) FROM system.parts WHERE table = 't_primary_index_cache' AND active;\n+SELECT metric, value FROM system.asynchronous_metrics WHERE metric IN ('PrimaryIndexCacheFiles', 'PrimaryIndexCacheBytes') ORDER BY metric;\n+\n+SELECT count() FROM t_primary_index_cache WHERE a > 100 AND a < 200 AND a % 2 = 0;\n+\n+SYSTEM RELOAD ASYNCHRONOUS METRICS;\n+SELECT sum(primary_key_bytes_in_memory) FROM system.parts WHERE table = 't_primary_index_cache' AND active;\n+SELECT metric, value FROM system.asynchronous_metrics WHERE metric IN ('PrimaryIndexCacheFiles', 'PrimaryIndexCacheBytes') ORDER BY metric;\n+\n+SYSTEM FLUSH LOGS;\n+\n+SELECT\n+    ProfileEvents['LoadedPrimaryIndexFiles'],\n+    ProfileEvents['LoadedPrimaryIndexRows'],\n+    ProfileEvents['LoadedPrimaryIndexBytes']\n+FROM system.query_log\n+WHERE query LIKE 'SELECT count() FROM t_primary_index_cache%' AND current_database = currentDatabase() AND type = 'QueryFinish'\n+ORDER BY event_time_microseconds;\n+\n+DROP TABLE t_primary_index_cache;\ndiff --git a/tests/queries/0_stateless/03274_prewarm_primary_index_cache.reference b/tests/queries/0_stateless/03274_prewarm_primary_index_cache.reference\nnew file mode 100644\nindex 000000000000..1a9e1167eb4a\n--- /dev/null\n+++ b/tests/queries/0_stateless/03274_prewarm_primary_index_cache.reference\n@@ -0,0 +1,22 @@\n+449\n+0\n+449\n+0\n+898\n+898\n+0\n+898\n+898\n+0\n+898\n+0\n+898\n+0\n+0\n+0\n+0\n+0\n+0\n+0\n+1\n+0\ndiff --git a/tests/queries/0_stateless/03274_prewarm_primary_index_cache.sql b/tests/queries/0_stateless/03274_prewarm_primary_index_cache.sql\nnew file mode 100644\nindex 000000000000..16e895a7798c\n--- /dev/null\n+++ b/tests/queries/0_stateless/03274_prewarm_primary_index_cache.sql\n@@ -0,0 +1,74 @@\n+-- Tags: no-parallel, no-shared-merge-tree\n+\n+DROP TABLE IF EXISTS t_prewarm_cache_rmt_1;\n+DROP TABLE IF EXISTS t_prewarm_cache_rmt_2;\n+\n+CREATE TABLE t_prewarm_cache_rmt_1 (a UInt64, b UInt64, c UInt64)\n+ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/03274_prewarm_mark_cache_smt/t_prewarm_cache', '1')\n+ORDER BY a PARTITION BY a % 2\n+SETTINGS prewarm_primary_key_cache = 1, use_primary_key_cache = 1;\n+\n+CREATE TABLE t_prewarm_cache_rmt_2 (a UInt64, b UInt64, c UInt64)\n+ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/03274_prewarm_mark_cache_smt/t_prewarm_cache', '2')\n+ORDER BY a PARTITION BY a % 2\n+SETTINGS prewarm_primary_key_cache = 1, use_primary_key_cache = 1;\n+\n+SYSTEM DROP PRIMARY INDEX CACHE;\n+SYSTEM STOP FETCHES t_prewarm_cache_rmt_2;\n+\n+-- Check that prewarm works on insert.\n+INSERT INTO t_prewarm_cache_rmt_1 SELECT number, rand(), rand() FROM numbers(20000);\n+\n+SELECT count() FROM t_prewarm_cache_rmt_1 WHERE a % 2 = 0 AND a > 100 AND a < 1000;\n+SELECT sum(primary_key_bytes_in_memory) FROM system.parts WHERE database = currentDatabase() AND table IN ('t_prewarm_cache_rmt_1', 't_prewarm_cache_rmt_2');\n+\n+-- Check that prewarm works on fetch.\n+SYSTEM DROP PRIMARY INDEX CACHE;\n+SYSTEM START FETCHES t_prewarm_cache_rmt_2;\n+SYSTEM SYNC REPLICA t_prewarm_cache_rmt_2;\n+\n+SELECT count() FROM t_prewarm_cache_rmt_2 WHERE a % 2 = 0 AND a > 100 AND a < 1000;\n+SELECT sum(primary_key_bytes_in_memory) FROM system.parts WHERE database = currentDatabase() AND table IN ('t_prewarm_cache_rmt_1', 't_prewarm_cache_rmt_2');\n+\n+-- Check that prewarm works on merge.\n+INSERT INTO t_prewarm_cache_rmt_1 SELECT number, rand(), rand() FROM numbers(20000);\n+OPTIMIZE TABLE t_prewarm_cache_rmt_1 FINAL;\n+\n+SYSTEM SYNC REPLICA t_prewarm_cache_rmt_2;\n+\n+SELECT count() FROM t_prewarm_cache_rmt_1 WHERE a % 2 = 0 AND a > 100 AND a < 1000;\n+SELECT count() FROM t_prewarm_cache_rmt_2 WHERE a % 2 = 0 AND a > 100 AND a < 1000;\n+SELECT sum(primary_key_bytes_in_memory) FROM system.parts WHERE database = currentDatabase() AND table IN ('t_prewarm_cache_rmt_1', 't_prewarm_cache_rmt_2');\n+\n+-- Check that prewarm works on restart.\n+SYSTEM DROP PRIMARY INDEX CACHE;\n+\n+DETACH TABLE t_prewarm_cache_rmt_1;\n+DETACH TABLE t_prewarm_cache_rmt_2;\n+\n+ATTACH TABLE t_prewarm_cache_rmt_1;\n+ATTACH TABLE t_prewarm_cache_rmt_2;\n+\n+SELECT count() FROM t_prewarm_cache_rmt_1 WHERE a % 2 = 0 AND a > 100 AND a < 1000;\n+SELECT count() FROM t_prewarm_cache_rmt_2 WHERE a % 2 = 0 AND a > 100 AND a < 1000;\n+SELECT sum(primary_key_bytes_in_memory) FROM system.parts WHERE database = currentDatabase() AND table IN ('t_prewarm_cache_rmt_1', 't_prewarm_cache_rmt_2');\n+\n+SYSTEM DROP PRIMARY INDEX CACHE;\n+\n+SELECT count() FROM t_prewarm_cache_rmt_1 WHERE a % 2 = 0 AND a > 100 AND a < 1000;\n+SELECT sum(primary_key_bytes_in_memory) FROM system.parts WHERE database = currentDatabase() AND table IN ('t_prewarm_cache_rmt_1', 't_prewarm_cache_rmt_2');\n+\n+--- Check that system query works.\n+SYSTEM PREWARM PRIMARY INDEX CACHE t_prewarm_cache_rmt_1;\n+\n+SELECT count() FROM t_prewarm_cache_rmt_1 WHERE a % 2 = 0 AND a > 100 AND a < 1000;\n+SELECT sum(primary_key_bytes_in_memory) FROM system.parts WHERE database = currentDatabase() AND table IN ('t_prewarm_cache_rmt_1', 't_prewarm_cache_rmt_2');\n+\n+SYSTEM FLUSH LOGS;\n+\n+SELECT ProfileEvents['LoadedPrimaryIndexFiles'] FROM system.query_log\n+WHERE current_database = currentDatabase() AND type = 'QueryFinish' AND query LIKE 'SELECT count() FROM t_prewarm_cache%'\n+ORDER BY event_time_microseconds;\n+\n+DROP TABLE IF EXISTS t_prewarm_cache_rmt_1;\n+DROP TABLE IF EXISTS t_prewarm_cache_rmt_2;\n",
  "problem_statement": "Cache for primary index\n**Use case**\r\n\r\nIn some extremely large workloads (trillions of rows) primary index may take significant amount of memory: tens or hundreds of GBs. Instead we can use cache for primary similar to mark cache instead of always storing index for parts.\r\n\r\n**Describe the solution you'd like**\r\n\r\nUse a cache similar to mark cache. If lazy load and primary index cache are enabled store index in that cache instead of storing it in data part.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nLazy load of index, but the problem is that index is never evicted and once primary index was analyzed for some query the index will be stored in memory until restart or `SYSTEM UNLOAD PRIMARY KEY` query.\n",
  "hints_text": "> In some extremely large workloads (trillions of rows) primary index may take significant amount of memory: tens or hundreds of GBs. Instead we can use cache for primary similar to mark cache instead of always storing index for parts.\r\n\r\nCan CH just load not every mark, but every X mark instead? \nYes, it's one possible solution. Basically it's the same as increasing `index_granularity` but more flexible because it can be easily changed. I'm afraid that it may affect performance significantly when you want to thin out index a lot. Maybe it's a good idea to make it adaptive and load every X mark, but start from X=1 for hot parts and increase X for colder ones.\n> Maybe it's a good idea to make it adaptive and load every X mark, but start from X=1 for hot parts and increase X for colder ones.\r\n\r\nRight, it can depend on part size or just frequency of part access by queries.\r\n\r\n> I'm afraid that it may affect performance significantly when you want to thin out index a lot. \r\n\r\nDon't think that it will be much worse than load uncached PK in memory on query. As you at least will read bigger range granules for PK columns (on PREWHERE step), but not read whole PK index (which is also expected to be big) \nI agree that it is maybe a questionable feature (it will be disabled by default). It works in case when queries read mostly from fresh parts and other parts are filtered by `minmax` index of partition key columns (or by `minmax` index/statistic of any column in the future) or partition pruning. In that case performance won't be affectedby bigger ranges selected by PK analysis on a regular workload. Primary index cache works here as a safety measure in a complement to the lazy load of index, because now there may be a case when server works well on a regular workload but one inaccurate query may read indexes of all parts and consume a lot of memory and server will required manual intervention.",
  "created_at": "2024-11-19T16:25:31Z",
  "modified_files": [
    "programs/local/LocalServer.cpp",
    "programs/server/Server.cpp",
    "src/Access/Common/AccessType.h",
    "src/Common/ProfileEvents.cpp",
    "src/Core/Defines.h",
    "src/Core/ServerSettings.cpp",
    "src/Interpreters/Context.cpp",
    "src/Interpreters/Context.h",
    "src/Interpreters/InterpreterSystemQuery.cpp",
    "src/Interpreters/InterpreterSystemQuery.h",
    "src/Interpreters/ServerAsynchronousMetrics.cpp",
    "src/Parsers/ASTSystemQuery.cpp",
    "src/Parsers/ASTSystemQuery.h",
    "src/Parsers/ParserSystemQuery.cpp",
    "src/Processors/QueryPlan/PartsSplitter.cpp",
    "src/Storages/MergeTree/IMergeTreeDataPart.cpp",
    "src/Storages/MergeTree/IMergeTreeDataPart.h",
    "src/Storages/MergeTree/IMergeTreeDataPartWriter.cpp",
    "src/Storages/MergeTree/IMergeTreeDataPartWriter.h",
    "src/Storages/MergeTree/MergeFromLogEntryTask.cpp",
    "src/Storages/MergeTree/MergePlainMergeTreeTask.cpp",
    "src/Storages/MergeTree/MergeTask.cpp",
    "src/Storages/MergeTree/MergeTreeData.cpp",
    "src/Storages/MergeTree/MergeTreeData.h",
    "src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp",
    "src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp",
    "src/Storages/MergeTree/MergeTreeDataWriter.cpp",
    "src/Storages/MergeTree/MergeTreeDataWriter.h",
    "src/Storages/MergeTree/MergeTreeIOSettings.cpp",
    "src/Storages/MergeTree/MergeTreeIOSettings.h",
    "src/Storages/MergeTree/MergeTreeSettings.cpp",
    "src/Storages/MergeTree/MergeTreeSink.cpp",
    "src/Storages/MergeTree/MergedBlockOutputStream.cpp",
    "src/Storages/MergeTree/MergedBlockOutputStream.h",
    "src/Storages/MergeTree/MergedColumnOnlyOutputStream.cpp",
    "src/Storages/MergeTree/MergedColumnOnlyOutputStream.h",
    "src/Storages/MergeTree/MutateTask.cpp",
    "b/src/Storages/MergeTree/PrimaryIndexCache.cpp",
    "b/src/Storages/MergeTree/PrimaryIndexCache.h",
    "src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp",
    "src/Storages/MergeTree/ReplicatedMergeTreeSink.h",
    "src/Storages/StorageMergeTree.cpp",
    "src/Storages/StorageReplicatedMergeTree.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/01271_show_privileges.reference",
    "tests/queries/0_stateless/03128_merge_tree_index_lazy_load.reference",
    "b/tests/queries/0_stateless/03273_primary_index_cache.reference",
    "b/tests/queries/0_stateless/03273_primary_index_cache.sql",
    "b/tests/queries/0_stateless/03274_prewarm_primary_index_cache.reference",
    "b/tests/queries/0_stateless/03274_prewarm_primary_index_cache.sql"
  ]
}