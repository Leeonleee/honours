You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Fatal error occurs when reusing the LRUResource Cache
Hello, I am currently working on secondary development based on ClickHouse. During the development process, I reused the LRUResource Cache. Unexpectedly, I encountered a Fatal error during usage.

```Bash
[ 272 ] {} <Error> LRUResourceCache: LRUResourceCache became inconsistent. There must be a bug in it.
[ 552 ] {} <Fatal> BaseDaemon: ########################################
[ 552 ] {} <Fatal> BaseDaemon: (version 23.3.2.1, build id: 52E0E50941B9FC4B3DD14160980076B127C3AB6E) (from thread 272) (no query) Received signal Aborted (6)
[ 552 ] {} <Fatal> BaseDaemon: 
[ 552 ] {} <Fatal> BaseDaemon: Stack trace: 0x7fe924d3e00b 0x7fe924d1d859 0x18343b0a 0x183404df 0x17bdb16d 0x17b9f4a3 0x17b9d94d 0x17d390df 0x179bfd9b 0x179bfa0a 0x1191286e 0x1191247c 0x1190ebed 0x1190e76e 0x7fe924ef5609 0x7fe924e1a133
[ 552 ] {} <Fatal> BaseDaemon: 3. raise @ 0x7fe924d3e00b in ?
[ 552 ] {} <Fatal> BaseDaemon: 4. abort @ 0x7fe924d1d859 in ?
[ 552 ] {} <Fatal> BaseDaemon: 5.1. inlined from ./build/./contrib/llvm-project/libcxx/include/string:1624: String::__zero[abi:v15000]()
[ 552 ] {} <Fatal> BaseDaemon: 5.2. inlined from ./build/./contrib/llvm-project/libcxx/include/string:1515: String::__default_init[abi:v15000]()
[ 552 ] {} <Fatal> BaseDaemon: 5.3. inlined from ./build/./contrib/llvm-project/libcxx/include/string:1902: basic_string
[ 552 ] {} <Fatal> BaseDaemon: 5. ./build/./src/Common/LRUResourceCache.h:367: DB::LRUResourceCache<VectorIndex::CacheKey, VectorIndex::IndexWithMeta, VectorIndex::IndexWithMetaWeightFunc, VectorIndex::IndexWithMetaReleaseFunction, std::hash<VectorIndex::CacheKey>>::set(VectorIndex::CacheKey const&, std::shared_ptr<VectorIndex::IndexWithMeta>) @ 0x18343b0a in /usr/bin/clickhouse
[ 552 ] {} <Fatal> BaseDaemon: 6.1. inlined from ./build/./src/Common/LRUResourceCache.h:0: std::shared_ptr<VectorIndex::IndexWithMeta> DB::LRUResourceCache<VectorIndex::CacheKey, VectorIndex::IndexWithMeta, VectorIndex::IndexWithMetaWeightFunc, VectorIndex::IndexWithMetaReleaseFunction, std::hash<VectorIndex::CacheKey>>::getImpl<VectorIndex::CacheManager::put(VectorIndex::CacheKey const&, std::shared_ptr<VectorIndex::IndexWithMeta>)::$_0&>(VectorIndex::CacheKey const&, VectorIndex::CacheManager::put(VectorIndex::CacheKey const&, std::shared_ptr<VectorIndex::IndexWithMeta>)::$_0&)
[ 552 ] {} <Fatal> BaseDaemon: 6.2. inlined from ./build/./src/Common/LRUResourceCache.h:83: std::unique_ptr<DB::LRUResourceCache<VectorIndex::CacheKey, VectorIndex::IndexWithMeta, VectorIndex::IndexWithMetaWeightFunc, VectorIndex::IndexWithMetaReleaseFunction, std::hash<VectorIndex::CacheKey>>::MappedHolder, std::default_delete<DB::LRUResourceCache<VectorIndex::CacheKey, VectorIndex::IndexWithMeta, VectorIndex::IndexWithMetaWeightFunc, VectorIndex::IndexWithMetaReleaseFunction, std::hash<VectorIndex::CacheKey>>::MappedHolder>> DB::LRUResourceCache<VectorIndex::CacheKey, VectorIndex::IndexWithMeta, VectorIndex::IndexWithMetaWeightFunc, VectorIndex::IndexWithMetaReleaseFunction, std::hash<VectorIndex::CacheKey>>::getOrSet<VectorIndex::CacheManager::put(VectorIndex::CacheKey const&, std::shared_ptr<VectorIndex::IndexWithMeta>)::$_0>(VectorIndex::CacheKey const&, VectorIndex::CacheManager::put(VectorIndex::CacheKey const&, std::shared_ptr<VectorIndex::IndexWithMeta>)::$_0&&)
```

The corresponding code is as follows:

```c++
// key mustn't be in the cache
Cell * set(const Key & insert_key, MappedPtr value)
{

    ...

    while (is_overflow() && queue_size > 1 && key_it != queue.end())
    {
        const Key & key = *key_it;

        auto cell_it = cells.find(key);
        if (cell_it == cells.end())
        {
            LOG_ERROR(&Poco::Logger::get("LRUResourceCache"), "LRUResourceCache became inconsistent. There must be a bug in it.");
            abort();
        }

        auto & cell = cell_it->second;
        if (cell.reference_count == 0)
        {
            loss_weight += cell.weight;
            queue_size--;
            to_release_keys.insert(key);
        }

        ++key_it;
    }

    ...
}
```

After investigation, I found that a cache key exists in the queue but not in the cells. Upon further investigation, I discovered that in my code, I mistakenly executed the tryRemove operation on this cache key, causing the corresponding cache to become expired. Subsequently, I reloaded the cache item corresponding to this cache key using the getOrSet operation. At this point, the expired cache item still existed in the cells. When the LRUResourceCache::set method was eventually executed:

```c++
Cell * set(const Key & insert_key, MappedPtr value)
{
	...

	current_weight = current_weight + weight - loss_weight;
		
	auto & new_cell = cells[insert_key];
	new_cell.value = value;
	new_cell.weight = weight;
	new_cell.queue_iterator = queue.insert(queue.end(), insert_key);
	return &new_cell;
}
```

The expired cache item corresponding to the insert_key in `auto & new_cell = cells[insert_key]` still existed. This resulted in the insertion of duplicate cache keys into the queue, ultimately leading to the problem of not finding the corresponding item when cleaning up items in cells based on cache keys in the queue (because the corresponding cache item had already been cleaned up by the previous duplicate cache key).

Currently, this behavior is caused by my incorrect use of the tryRemove operation. However, I believe that this behavior should not result in an abort. If this behavior is indeed abnormal, I am willing to submit a PR to fix it.
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
