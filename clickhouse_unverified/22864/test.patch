diff --git a/tests/integration/test_s3_zero_copy_replication/configs/config.d/s3.xml b/tests/integration/test_s3_zero_copy_replication/configs/config.d/s3.xml
index ec28840054a3..db639cabb63d 100644
--- a/tests/integration/test_s3_zero_copy_replication/configs/config.d/s3.xml
+++ b/tests/integration/test_s3_zero_copy_replication/configs/config.d/s3.xml
@@ -8,6 +8,18 @@
                 <access_key_id>minio</access_key_id>
                 <secret_access_key>minio123</secret_access_key>
             </s31>
+            <s31_again>
+                <type>s3</type>
+                <endpoint>http://minio1:9001/root/data/</endpoint>
+                <access_key_id>minio</access_key_id>
+                <secret_access_key>minio123</secret_access_key>
+            </s31_again>
+            <s32>
+                <type>s3</type>
+                <endpoint>http://minio1:9001/root/data2/</endpoint>
+                <access_key_id>minio</access_key_id>
+                <secret_access_key>minio123</secret_access_key>
+            </s32>
         </disks>
         <policies>
             <s3>
@@ -28,11 +40,31 @@
                 </volumes>
                 <move_factor>0.0</move_factor>
             </hybrid>
+            <tiered>
+                <volumes>
+                    <main>
+                        <disk>s31</disk>
+                    </main>
+                    <external>
+                        <disk>s32</disk>
+                    </external>
+                </volumes>
+            </tiered>
+            <tiered_copy>
+                <volumes>
+                    <main>
+                        <disk>s31</disk>
+                    </main>
+                    <external>
+                        <disk>s31_again</disk>
+                    </external>
+                </volumes>
+            </tiered_copy>
         </policies>
     </storage_configuration>
 
     <merge_tree>
-        <min_bytes_for_wide_part>0</min_bytes_for_wide_part>
+        <min_bytes_for_wide_part>1024</min_bytes_for_wide_part>
         <old_parts_lifetime>1</old_parts_lifetime>
         <allow_s3_zero_copy_replication>1</allow_s3_zero_copy_replication>
     </merge_tree>
diff --git a/tests/integration/test_s3_zero_copy_replication/test.py b/tests/integration/test_s3_zero_copy_replication/test.py
index f7078d55c330..d9f7cca4a3a7 100644
--- a/tests/integration/test_s3_zero_copy_replication/test.py
+++ b/tests/integration/test_s3_zero_copy_replication/test.py
@@ -1,3 +1,4 @@
+import datetime
 import logging
 import time
 
@@ -27,10 +28,10 @@ def cluster():
         cluster.shutdown()
 
 
-def get_large_objects_count(cluster, size=100):
+def get_large_objects_count(cluster, size=100, folder='data'):
     minio = cluster.minio_client
     counter = 0
-    for obj in minio.list_objects(cluster.minio_bucket, 'data/'):
+    for obj in minio.list_objects(cluster.minio_bucket, '{}/'.format(folder)):
         if obj.size >= size:
             counter = counter + 1
     return counter
@@ -38,11 +39,11 @@ def get_large_objects_count(cluster, size=100):
 
 def wait_for_large_objects_count(cluster, expected, size=100, timeout=30):
     while timeout > 0:
-        if get_large_objects_count(cluster, size) == expected:
+        if get_large_objects_count(cluster, size=size) == expected:
             return
         timeout -= 1
         time.sleep(1)
-    assert get_large_objects_count(cluster, size) == expected
+    assert get_large_objects_count(cluster, size=size) == expected
 
 
 @pytest.mark.parametrize(
@@ -63,7 +64,7 @@ def test_s3_zero_copy_replication(cluster, policy):
     )
 
     node1.query("INSERT INTO s3_test VALUES (0,'data'),(1,'data')")
-    time.sleep(1)
+    node2.query("SYSTEM SYNC REPLICA s3_test")
     assert node1.query("SELECT * FROM s3_test order by id FORMAT Values") == "(0,'data'),(1,'data')"
     assert node2.query("SELECT * FROM s3_test order by id FORMAT Values") == "(0,'data'),(1,'data')"
 
@@ -71,14 +72,15 @@ def test_s3_zero_copy_replication(cluster, policy):
     assert get_large_objects_count(cluster) == 1
 
     node2.query("INSERT INTO s3_test VALUES (2,'data'),(3,'data')")
-    time.sleep(1)
+    node1.query("SYSTEM SYNC REPLICA s3_test")
+
     assert node2.query("SELECT * FROM s3_test order by id FORMAT Values") == "(0,'data'),(1,'data'),(2,'data'),(3,'data')"
     assert node1.query("SELECT * FROM s3_test order by id FORMAT Values") == "(0,'data'),(1,'data'),(2,'data'),(3,'data')"
 
     # Based on version 20.x - two parts
     wait_for_large_objects_count(cluster, 2)
 
-    node1.query("OPTIMIZE TABLE s3_test")
+    node1.query("OPTIMIZE TABLE s3_test FINAL")
 
     # Based on version 20.x - after merge, two old parts and one merged
     wait_for_large_objects_count(cluster, 3)
@@ -105,8 +107,7 @@ def test_s3_zero_copy_on_hybrid_storage(cluster):
     )
 
     node1.query("INSERT INTO hybrid_test VALUES (0,'data'),(1,'data')")
-
-    time.sleep(1)
+    node2.query("SYSTEM SYNC REPLICA hybrid_test")
 
     assert node1.query("SELECT * FROM hybrid_test ORDER BY id FORMAT Values") == "(0,'data'),(1,'data')"
     assert node2.query("SELECT * FROM hybrid_test ORDER BY id FORMAT Values") == "(0,'data'),(1,'data')"
@@ -120,7 +121,7 @@ def test_s3_zero_copy_on_hybrid_storage(cluster):
     assert node2.query("SELECT partition_id,disk_name FROM system.parts WHERE table='hybrid_test' FORMAT Values") == "('all','default')"
 
     # Total objects in S3
-    s3_objects = get_large_objects_count(cluster, 0)
+    s3_objects = get_large_objects_count(cluster, size=0)
 
     node2.query("ALTER TABLE hybrid_test MOVE PARTITION ID 'all' TO DISK 's31'")
 
@@ -135,3 +136,115 @@ def test_s3_zero_copy_on_hybrid_storage(cluster):
 
     node1.query("DROP TABLE IF EXISTS hybrid_test NO DELAY")
     node2.query("DROP TABLE IF EXISTS hybrid_test NO DELAY")
+
+
+def insert_data_time(node, table, number_of_mb, time, start=0):
+    values = ','.join(f"({x},{time})" for x in range(start, int((1024 * 1024 * number_of_mb) / 8) + start + 1))
+    node.query(f"INSERT INTO {table} VALUES {values}")
+
+
+def insert_large_data(node, table):
+    tm = time.mktime((datetime.date.today() - datetime.timedelta(days=7)).timetuple())
+    insert_data_time(node, table, 1, tm, 0)
+    tm = time.mktime((datetime.date.today() - datetime.timedelta(days=3)).timetuple())
+    insert_data_time(node, table, 1, tm, 1024*1024)
+    tm = time.mktime(datetime.date.today().timetuple())
+    insert_data_time(node, table, 10, tm, 1024*1024*2)
+
+
+@pytest.mark.parametrize(
+    ("storage_policy", "large_data", "iterations"),
+    [
+        ("tiered", False, 10),
+        ("tiered_copy", False, 10),
+        ("tiered", True, 3),
+        ("tiered_copy", True, 3),
+    ]
+)
+def test_s3_zero_copy_with_ttl_move(cluster, storage_policy, large_data, iterations):
+    node1 = cluster.instances["node1"]
+    node2 = cluster.instances["node2"]
+
+    node1.query("DROP TABLE IF EXISTS ttl_move_test NO DELAY")
+    node2.query("DROP TABLE IF EXISTS ttl_move_test NO DELAY")
+
+    for i in range(iterations):
+        node1.query(
+            """
+            CREATE TABLE ttl_move_test ON CLUSTER test_cluster (d UInt64, d1 DateTime)
+            ENGINE=ReplicatedMergeTree('/clickhouse/tables/ttl_move_test', '{}')
+            ORDER BY d
+            TTL d1 + INTERVAL 2 DAY TO VOLUME 'external'
+            SETTINGS storage_policy='{}'
+            """
+                .format('{replica}', storage_policy)
+        )
+
+        if large_data:
+            insert_large_data(node1, 'ttl_move_test')
+        else:
+            node1.query("INSERT INTO ttl_move_test VALUES (10, now() - INTERVAL 3 DAY)")
+            node1.query("INSERT INTO ttl_move_test VALUES (11, now() - INTERVAL 1 DAY)")
+
+        node1.query("OPTIMIZE TABLE ttl_move_test FINAL")
+        node2.query("SYSTEM SYNC REPLICA ttl_move_test")
+
+        if large_data:
+            assert node1.query("SELECT count() FROM ttl_move_test FORMAT Values") == "(1572867)"
+            assert node2.query("SELECT count() FROM ttl_move_test FORMAT Values") == "(1572867)"
+        else:
+            assert node1.query("SELECT count() FROM ttl_move_test FORMAT Values") == "(2)"
+            assert node2.query("SELECT count() FROM ttl_move_test FORMAT Values") == "(2)"
+            assert node1.query("SELECT d FROM ttl_move_test ORDER BY d FORMAT Values") == "(10),(11)"
+            assert node2.query("SELECT d FROM ttl_move_test ORDER BY d FORMAT Values") == "(10),(11)"
+
+        node1.query("DROP TABLE IF EXISTS ttl_move_test NO DELAY")
+        node2.query("DROP TABLE IF EXISTS ttl_move_test NO DELAY")
+
+
+@pytest.mark.parametrize(
+    ("large_data", "iterations"),
+    [
+        (False, 10),
+        (True, 3),
+    ]
+)
+def test_s3_zero_copy_with_ttl_delete(cluster, large_data, iterations):
+    node1 = cluster.instances["node1"]
+    node2 = cluster.instances["node2"]
+
+    node1.query("DROP TABLE IF EXISTS ttl_delete_test NO DELAY")
+    node2.query("DROP TABLE IF EXISTS ttl_delete_test NO DELAY")
+
+    for i in range(iterations):
+        node1.query(
+            """
+            CREATE TABLE ttl_delete_test ON CLUSTER test_cluster (d UInt64, d1 DateTime)
+            ENGINE=ReplicatedMergeTree('/clickhouse/tables/ttl_delete_test', '{}')
+            ORDER BY d
+            TTL d1 + INTERVAL 2 DAY
+            SETTINGS storage_policy='tiered'
+            """
+                .format('{replica}')
+        )
+
+        if large_data:
+            insert_large_data(node1, 'ttl_delete_test')
+        else:
+            node1.query("INSERT INTO ttl_delete_test VALUES (10, now() - INTERVAL 3 DAY)")
+            node1.query("INSERT INTO ttl_delete_test VALUES (11, now() - INTERVAL 1 DAY)")
+
+        node1.query("OPTIMIZE TABLE ttl_delete_test FINAL")
+        node2.query("SYSTEM SYNC REPLICA ttl_delete_test")
+
+        if large_data:
+            assert node1.query("SELECT count() FROM ttl_delete_test FORMAT Values") == "(1310721)"
+            assert node2.query("SELECT count() FROM ttl_delete_test FORMAT Values") == "(1310721)"
+        else:
+            assert node1.query("SELECT count() FROM ttl_delete_test FORMAT Values") == "(1)"
+            assert node2.query("SELECT count() FROM ttl_delete_test FORMAT Values") == "(1)"
+            assert node1.query("SELECT d FROM ttl_delete_test ORDER BY d FORMAT Values") == "(11)"
+            assert node2.query("SELECT d FROM ttl_delete_test ORDER BY d FORMAT Values") == "(11)"
+
+        node1.query("DROP TABLE IF EXISTS ttl_delete_test NO DELAY")
+        node2.query("DROP TABLE IF EXISTS ttl_delete_test NO DELAY")
