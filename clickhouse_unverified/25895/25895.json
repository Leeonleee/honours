{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 25895,
  "instance_id": "ClickHouse__ClickHouse-25895",
  "issue_numbers": [
    "24566",
    "23175"
  ],
  "base_commit": "b52250bc0d820eb375ff29eb87456dd986987558",
  "patch": "diff --git a/src/Databases/DatabaseReplicated.cpp b/src/Databases/DatabaseReplicated.cpp\nindex ac6c525af68f..26dd8763c400 100644\n--- a/src/Databases/DatabaseReplicated.cpp\n+++ b/src/Databases/DatabaseReplicated.cpp\n@@ -525,7 +525,7 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n         query_context->getClientInfo().is_replicated_database_internal = true;\n         query_context->setCurrentDatabase(database_name);\n         query_context->setCurrentQueryId(\"\");\n-        auto txn = std::make_shared<ZooKeeperMetadataTransaction>(current_zookeeper, zookeeper_path, false);\n+        auto txn = std::make_shared<ZooKeeperMetadataTransaction>(current_zookeeper, zookeeper_path, false, \"\");\n         query_context->initZooKeeperMetadataTransaction(txn);\n         return query_context;\n     };\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex 69c986d88c3a..635af6f3cb70 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -2796,6 +2796,13 @@ ZooKeeperMetadataTransactionPtr Context::getZooKeeperMetadataTransaction() const\n     return metadata_transaction;\n }\n \n+void Context::resetZooKeeperMetadataTransaction()\n+{\n+    assert(metadata_transaction);\n+    assert(hasQueryContext());\n+    metadata_transaction = nullptr;\n+}\n+\n PartUUIDsPtr Context::getPartUUIDs() const\n {\n     auto lock = getLock();\ndiff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h\nindex f72427d2a7a1..66fac7e6e70b 100644\n--- a/src/Interpreters/Context.h\n+++ b/src/Interpreters/Context.h\n@@ -819,6 +819,8 @@ class Context: public std::enable_shared_from_this<Context>\n     void initZooKeeperMetadataTransaction(ZooKeeperMetadataTransactionPtr txn, bool attach_existing = false);\n     /// Returns context of current distributed DDL query or nullptr.\n     ZooKeeperMetadataTransactionPtr getZooKeeperMetadataTransaction() const;\n+    /// Removes context of current distributed DDL.\n+    void resetZooKeeperMetadataTransaction();\n \n     PartUUIDsPtr getPartUUIDs() const;\n     PartUUIDsPtr getIgnoredPartUUIDs() const;\ndiff --git a/src/Interpreters/DDLTask.cpp b/src/Interpreters/DDLTask.cpp\nindex 8bebc2fb442b..0391e76e7634 100644\n--- a/src/Interpreters/DDLTask.cpp\n+++ b/src/Interpreters/DDLTask.cpp\n@@ -22,6 +22,7 @@ namespace ErrorCodes\n     extern const int UNKNOWN_FORMAT_VERSION;\n     extern const int UNKNOWN_TYPE_OF_QUERY;\n     extern const int INCONSISTENT_CLUSTER_DEFINITION;\n+    extern const int LOGICAL_ERROR;\n }\n \n HostID HostID::fromString(const String & host_port_str)\n@@ -362,7 +363,7 @@ ContextMutablePtr DatabaseReplicatedTask::makeQueryContext(ContextPtr from_conte\n     query_context->getClientInfo().is_replicated_database_internal = true;\n     query_context->setCurrentDatabase(database->getDatabaseName());\n \n-    auto txn = std::make_shared<ZooKeeperMetadataTransaction>(zookeeper, database->zookeeper_path, is_initial_query);\n+    auto txn = std::make_shared<ZooKeeperMetadataTransaction>(zookeeper, database->zookeeper_path, is_initial_query, entry_path);\n     query_context->initZooKeeperMetadataTransaction(txn);\n \n     if (is_initial_query)\n@@ -402,7 +403,8 @@ UInt32 DDLTaskBase::getLogEntryNumber(const String & log_entry_name)\n \n void ZooKeeperMetadataTransaction::commit()\n {\n-    assert(state == CREATED);\n+    if (state != CREATED)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Incorrect state ({}), it's a bug\", state);\n     state = FAILED;\n     current_zookeeper->multi(ops);\n     state = COMMITTED;\ndiff --git a/src/Interpreters/DDLTask.h b/src/Interpreters/DDLTask.h\nindex 41ab9ec80584..ee49274707a8 100644\n--- a/src/Interpreters/DDLTask.h\n+++ b/src/Interpreters/DDLTask.h\n@@ -20,6 +20,11 @@ namespace fs = std::filesystem;\n namespace DB\n {\n \n+namespace ErrorCodes\n+{\n+    extern const int LOGICAL_ERROR;\n+}\n+\n class ASTQueryWithOnCluster;\n using ZooKeeperPtr = std::shared_ptr<zkutil::ZooKeeper>;\n using ClusterPtr = std::shared_ptr<Cluster>;\n@@ -164,13 +169,15 @@ class ZooKeeperMetadataTransaction\n     ZooKeeperPtr current_zookeeper;\n     String zookeeper_path;\n     bool is_initial_query;\n+    String task_path;\n     Coordination::Requests ops;\n \n public:\n-    ZooKeeperMetadataTransaction(const ZooKeeperPtr & current_zookeeper_, const String & zookeeper_path_, bool is_initial_query_)\n+    ZooKeeperMetadataTransaction(const ZooKeeperPtr & current_zookeeper_, const String & zookeeper_path_, bool is_initial_query_, const String & task_path_)\n     : current_zookeeper(current_zookeeper_)\n     , zookeeper_path(zookeeper_path_)\n     , is_initial_query(is_initial_query_)\n+    , task_path(task_path_)\n     {\n     }\n \n@@ -180,15 +187,21 @@ class ZooKeeperMetadataTransaction\n \n     String getDatabaseZooKeeperPath() const { return zookeeper_path; }\n \n+    String getTaskZooKeeperPath() const { return task_path; }\n+\n+    ZooKeeperPtr getZooKeeper() const { return current_zookeeper; }\n+\n     void addOp(Coordination::RequestPtr && op)\n     {\n-        assert(!isExecuted());\n+        if (isExecuted())\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Cannot add ZooKeeper operation because query is executed. It's a bug.\");\n         ops.emplace_back(op);\n     }\n \n     void moveOpsTo(Coordination::Requests & other_ops)\n     {\n-        assert(!isExecuted());\n+        if (isExecuted())\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Cannot add ZooKeeper operation because query is executed. It's a bug.\");\n         std::move(ops.begin(), ops.end(), std::back_inserter(other_ops));\n         ops.clear();\n         state = COMMITTED;\ndiff --git a/src/Interpreters/InterpreterCreateQuery.cpp b/src/Interpreters/InterpreterCreateQuery.cpp\nindex b3cbfdcd035c..bf2cf6338aa9 100644\n--- a/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -8,6 +8,7 @@\n #include <Common/Macros.h>\n #include <Common/randomSeed.h>\n #include <Common/renameat2.h>\n+#include <Common/hex.h>\n \n #include <Core/Defines.h>\n #include <Core/Settings.h>\n@@ -31,7 +32,9 @@\n \n #include <Interpreters/Context.h>\n #include <Interpreters/executeDDLQueryOnCluster.h>\n+#include <Interpreters/executeQuery.h>\n #include <Interpreters/Cluster.h>\n+#include <Interpreters/DDLTask.h>\n #include <Interpreters/ExpressionAnalyzer.h>\n #include <Interpreters/InterpreterCreateQuery.h>\n #include <Interpreters/InterpreterSelectWithUnionQuery.h>\n@@ -84,7 +87,6 @@ namespace ErrorCodes\n     extern const int UNKNOWN_DATABASE;\n     extern const int PATH_ACCESS_DENIED;\n     extern const int NOT_IMPLEMENTED;\n-    extern const int UNKNOWN_TABLE;\n }\n \n namespace fs = std::filesystem;\n@@ -803,36 +805,6 @@ void InterpreterCreateQuery::assertOrSetUUID(ASTCreateQuery & create, const Data\n         create.uuid = UUIDHelpers::Nil;\n         create.to_inner_uuid = UUIDHelpers::Nil;\n     }\n-\n-    if (create.replace_table)\n-    {\n-        if (database->getUUID() == UUIDHelpers::Nil)\n-            throw Exception(ErrorCodes::INCORRECT_QUERY,\n-                            \"{} query is supported only for Atomic databases\",\n-                            create.create_or_replace ? \"CREATE OR REPLACE TABLE\" : \"REPLACE TABLE\");\n-\n-        UUID uuid_of_table_to_replace;\n-        if (create.create_or_replace)\n-        {\n-            uuid_of_table_to_replace = getContext()->tryResolveStorageID(StorageID(create.database, create.table)).uuid;\n-            if (uuid_of_table_to_replace == UUIDHelpers::Nil)\n-            {\n-                /// Convert to usual CREATE\n-                create.replace_table = false;\n-                assert(!database->isTableExist(create.table, getContext()));\n-            }\n-            else\n-                create.table = \"_tmp_replace_\" + toString(uuid_of_table_to_replace);\n-        }\n-        else\n-        {\n-            uuid_of_table_to_replace = getContext()->resolveStorageID(StorageID(create.database, create.table)).uuid;\n-            if (uuid_of_table_to_replace == UUIDHelpers::Nil)\n-                throw Exception(ErrorCodes::UNKNOWN_TABLE, \"Table {}.{} doesn't exist\",\n-                                backQuoteIfNeed(create.database), backQuoteIfNeed(create.table));\n-            create.table = \"_tmp_replace_\" + toString(uuid_of_table_to_replace);\n-        }\n-    }\n }\n \n \n@@ -1110,23 +1082,72 @@ bool InterpreterCreateQuery::doCreateTable(ASTCreateQuery & create,\n BlockIO InterpreterCreateQuery::doCreateOrReplaceTable(ASTCreateQuery & create,\n                                                        const InterpreterCreateQuery::TableProperties & properties)\n {\n+    /// Replicated database requires separate contexts for each DDL query\n+    ContextPtr current_context = getContext();\n+    ContextMutablePtr create_context = Context::createCopy(current_context);\n+    create_context->setQueryContext(std::const_pointer_cast<Context>(current_context));\n+\n+    auto make_drop_context = [&](bool on_error) -> ContextMutablePtr\n+    {\n+        ContextMutablePtr drop_context = Context::createCopy(current_context);\n+        drop_context->makeQueryContext();\n+        if (on_error)\n+            return drop_context;\n+\n+        if (auto txn = current_context->getZooKeeperMetadataTransaction())\n+        {\n+            /// Execute drop as separate query, because [CREATE OR] REPLACE query can be considered as\n+            /// successfully executed after RENAME/EXCHANGE query.\n+            drop_context->resetZooKeeperMetadataTransaction();\n+            auto drop_txn = std::make_shared<ZooKeeperMetadataTransaction>(txn->getZooKeeper(), txn->getDatabaseZooKeeperPath(),\n+                                                                           txn->isInitialQuery(), txn->getTaskZooKeeperPath());\n+            drop_context->initZooKeeperMetadataTransaction(drop_txn);\n+        }\n+        return drop_context;\n+    };\n+\n     auto ast_drop = std::make_shared<ASTDropQuery>();\n     String table_to_replace_name = create.table;\n-    bool created = false;\n-    bool replaced = false;\n \n-    try\n     {\n-        [[maybe_unused]] bool done = doCreateTable(create, properties);\n-        assert(done);\n+        auto database = DatabaseCatalog::instance().getDatabase(create.database);\n+        if (database->getUUID() == UUIDHelpers::Nil)\n+            throw Exception(ErrorCodes::INCORRECT_QUERY,\n+                            \"{} query is supported only for Atomic databases\",\n+                            create.create_or_replace ? \"CREATE OR REPLACE TABLE\" : \"REPLACE TABLE\");\n+\n+\n+        UInt64 name_hash = sipHash64(create.database + create.table);\n+        UInt16 random_suffix = thread_local_rng();\n+        if (auto txn = current_context->getZooKeeperMetadataTransaction())\n+        {\n+            /// Avoid different table name on database replicas\n+            random_suffix = sipHash64(txn->getTaskZooKeeperPath());\n+        }\n+        create.table = fmt::format(\"_tmp_replace_{}_{}\",\n+                                   getHexUIntLowercase(name_hash),\n+                                   getHexUIntLowercase(random_suffix));\n+\n         ast_drop->table = create.table;\n         ast_drop->is_dictionary = create.is_dictionary;\n         ast_drop->database = create.database;\n         ast_drop->kind = ASTDropQuery::Drop;\n+    }\n+\n+    bool created = false;\n+    bool renamed = false;\n+    try\n+    {\n+        /// Create temporary table (random name will be generated)\n+        [[maybe_unused]] bool done = InterpreterCreateQuery(query_ptr, create_context).doCreateTable(create, properties);\n+        assert(done);\n         created = true;\n-        if (!create.replace_table)\n-            return fillTableIfNeeded(create);\n \n+        /// Try fill temporary table\n+        BlockIO fill_io = fillTableIfNeeded(create);\n+        executeTrivialBlockIO(fill_io, getContext());\n+\n+        /// Replace target table with created one\n         auto ast_rename = std::make_shared<ASTRenameQuery>();\n         ASTRenameQuery::Element elem\n         {\n@@ -1135,22 +1156,44 @@ BlockIO InterpreterCreateQuery::doCreateOrReplaceTable(ASTCreateQuery & create,\n         };\n \n         ast_rename->elements.push_back(std::move(elem));\n-        ast_rename->exchange = true;\n         ast_rename->dictionary = create.is_dictionary;\n+        if (create.create_or_replace)\n+        {\n+            /// CREATE OR REPLACE TABLE\n+            /// Will execute ordinary RENAME instead of EXCHANGE if the target table does not exist\n+            ast_rename->rename_if_cannot_exchange = true;\n+            ast_rename->exchange = false;\n+        }\n+        else\n+        {\n+            /// REPLACE TABLE\n+            /// Will execute EXCHANGE query and fail if the target table does not exist\n+            ast_rename->exchange = true;\n+        }\n \n-        InterpreterRenameQuery(ast_rename, getContext()).execute();\n-        replaced = true;\n+        InterpreterRenameQuery interpreter_rename{ast_rename, current_context};\n+        interpreter_rename.execute();\n+        renamed = true;\n \n-        InterpreterDropQuery(ast_drop, getContext()).execute();\n+        if (!interpreter_rename.renamedInsteadOfExchange())\n+        {\n+            /// Target table was replaced with new one, drop old table\n+            auto drop_context = make_drop_context(false);\n+            InterpreterDropQuery(ast_drop, drop_context).execute();\n+        }\n \n         create.table = table_to_replace_name;\n \n-        return fillTableIfNeeded(create);\n+        return {};\n     }\n     catch (...)\n     {\n-        if (created && create.replace_table && !replaced)\n-            InterpreterDropQuery(ast_drop, getContext()).execute();\n+        /// Drop temporary table if it was successfully created, but was not renamed to target name\n+        if (created && !renamed)\n+        {\n+            auto drop_context = make_drop_context(true);\n+            InterpreterDropQuery(ast_drop, drop_context).execute();\n+        }\n         throw;\n     }\n }\ndiff --git a/src/Interpreters/InterpreterRenameQuery.cpp b/src/Interpreters/InterpreterRenameQuery.cpp\nindex 373953e75308..e3d52487a52d 100644\n--- a/src/Interpreters/InterpreterRenameQuery.cpp\n+++ b/src/Interpreters/InterpreterRenameQuery.cpp\n@@ -72,12 +72,27 @@ BlockIO InterpreterRenameQuery::execute()\n \n BlockIO InterpreterRenameQuery::executeToTables(const ASTRenameQuery & rename, const RenameDescriptions & descriptions, TableGuards & ddl_guards)\n {\n+    assert(!rename.rename_if_cannot_exchange || descriptions.size() == 1);\n+    assert(!(rename.rename_if_cannot_exchange && rename.exchange));\n     auto & database_catalog = DatabaseCatalog::instance();\n \n     for (const auto & elem : descriptions)\n     {\n-        if (!rename.exchange)\n+        bool exchange_tables;\n+        if (rename.exchange)\n+        {\n+            exchange_tables = true;\n+        }\n+        else if (rename.rename_if_cannot_exchange)\n+        {\n+            exchange_tables = database_catalog.isTableExist(StorageID(elem.to_database_name, elem.to_table_name), getContext());\n+            renamed_instead_of_exchange = !exchange_tables;\n+        }\n+        else\n+        {\n+            exchange_tables = false;\n             database_catalog.assertTableDoesntExist(StorageID(elem.to_database_name, elem.to_table_name), getContext());\n+        }\n \n         DatabasePtr database = database_catalog.getDatabase(elem.from_database_name);\n         if (typeid_cast<DatabaseReplicated *>(database.get())\n@@ -100,7 +115,7 @@ BlockIO InterpreterRenameQuery::executeToTables(const ASTRenameQuery & rename, c\n                 elem.from_table_name,\n                 *database_catalog.getDatabase(elem.to_database_name),\n                 elem.to_table_name,\n-                rename.exchange,\n+                exchange_tables,\n                 rename.dictionary);\n         }\n     }\ndiff --git a/src/Interpreters/InterpreterRenameQuery.h b/src/Interpreters/InterpreterRenameQuery.h\nindex 49fdd50f52dd..dfcd741754ea 100644\n--- a/src/Interpreters/InterpreterRenameQuery.h\n+++ b/src/Interpreters/InterpreterRenameQuery.h\n@@ -55,6 +55,8 @@ class InterpreterRenameQuery : public IInterpreter, WithContext\n     BlockIO execute() override;\n     void extendQueryLogElemImpl(QueryLogElement & elem, const ASTPtr & ast, ContextPtr) const override;\n \n+    bool renamedInsteadOfExchange() const { return renamed_instead_of_exchange; }\n+\n private:\n     BlockIO executeToTables(const ASTRenameQuery & rename, const RenameDescriptions & descriptions, TableGuards & ddl_guards);\n     static BlockIO executeToDatabase(const ASTRenameQuery & rename, const RenameDescriptions & descriptions);\n@@ -62,6 +64,7 @@ class InterpreterRenameQuery : public IInterpreter, WithContext\n     AccessRightsElements getRequiredAccess() const;\n \n     ASTPtr query_ptr;\n+    bool renamed_instead_of_exchange{false};\n };\n \n }\ndiff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp\nindex 75b895548201..9f4af34f39ef 100644\n--- a/src/Interpreters/executeQuery.cpp\n+++ b/src/Interpreters/executeQuery.cpp\n@@ -74,6 +74,7 @@ namespace ErrorCodes\n {\n     extern const int INTO_OUTFILE_NOT_ALLOWED;\n     extern const int QUERY_WAS_CANCELLED;\n+    extern const int LOGICAL_ERROR;\n }\n \n \n@@ -1113,4 +1114,32 @@ void executeQuery(\n     streams.onFinish();\n }\n \n+void executeTrivialBlockIO(BlockIO & streams, ContextPtr context)\n+{\n+    try\n+    {\n+        if (streams.out)\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Query stream requires input, but no input buffer provided, it's a bug\");\n+        if (streams.in)\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Query stream requires output, but no output buffer provided, it's a bug\");\n+\n+        if (!streams.pipeline.initialized())\n+            return;\n+\n+        if (!streams.pipeline.isCompleted())\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Query pipeline requires output, but no output buffer provided, it's a bug\");\n+\n+        streams.pipeline.setProgressCallback(context->getProgressCallback());\n+        auto executor = streams.pipeline.execute();\n+        executor->execute(streams.pipeline.getNumThreads());\n+    }\n+    catch (...)\n+    {\n+        streams.onException();\n+        throw;\n+    }\n+\n+    streams.onFinish();\n+}\n+\n }\ndiff --git a/src/Interpreters/executeQuery.h b/src/Interpreters/executeQuery.h\nindex 179016e85239..9672c4e7517a 100644\n--- a/src/Interpreters/executeQuery.h\n+++ b/src/Interpreters/executeQuery.h\n@@ -55,4 +55,8 @@ BlockIO executeQuery(\n     bool allow_processors /// If can use processors pipeline\n );\n \n+/// Executes BlockIO returned from executeQuery(...)\n+/// if built pipeline does not require any input and does not produce any output.\n+void executeTrivialBlockIO(BlockIO & streams, ContextPtr context);\n+\n }\ndiff --git a/src/Parsers/ASTRenameQuery.h b/src/Parsers/ASTRenameQuery.h\nindex 611f81dc9e9a..e0c58e3462e3 100644\n--- a/src/Parsers/ASTRenameQuery.h\n+++ b/src/Parsers/ASTRenameQuery.h\n@@ -34,6 +34,9 @@ class ASTRenameQuery : public ASTQueryWithOutput, public ASTQueryWithOnCluster\n     bool database{false};   /// For RENAME DATABASE\n     bool dictionary{false};   /// For RENAME DICTIONARY\n \n+    /// Special flag for CREATE OR REPLACE. Do not throw if the second table does not exist.\n+    bool rename_if_cannot_exchange{false};\n+\n     /** Get the text that identifies this element. */\n     String getID(char) const override { return \"Rename\"; }\n \ndiff --git a/src/Storages/StorageDistributed.cpp b/src/Storages/StorageDistributed.cpp\nindex 5173abeb9f92..9aaa6692560c 100644\n--- a/src/Storages/StorageDistributed.cpp\n+++ b/src/Storages/StorageDistributed.cpp\n@@ -1139,6 +1139,18 @@ ActionLock StorageDistributed::getActionLock(StorageActionBlockType type)\n     return {};\n }\n \n+void StorageDistributed::flush()\n+{\n+    try\n+    {\n+        flushClusterNodesAllData(getContext());\n+    }\n+    catch (...)\n+    {\n+        tryLogCurrentException(log, \"Cannot flush\");\n+    }\n+}\n+\n void StorageDistributed::flushClusterNodesAllData(ContextPtr local_context)\n {\n     /// Sync SYSTEM FLUSH DISTRIBUTED with TRUNCATE\ndiff --git a/src/Storages/StorageDistributed.h b/src/Storages/StorageDistributed.h\nindex bf48e814ae28..4331817386e7 100644\n--- a/src/Storages/StorageDistributed.h\n+++ b/src/Storages/StorageDistributed.h\n@@ -98,6 +98,7 @@ class StorageDistributed final : public shared_ptr_helper<StorageDistributed>, p\n \n     void startup() override;\n     void shutdown() override;\n+    void flush() override;\n     void drop() override;\n \n     bool storesDataOnDisk() const override { return true; }\ndiff --git a/utils/antlr/ClickHouseParser.g4 b/utils/antlr/ClickHouseParser.g4\nindex 28e5b1217ab8..eb1908ed0737 100644\n--- a/utils/antlr/ClickHouseParser.g4\n+++ b/utils/antlr/ClickHouseParser.g4\n@@ -91,10 +91,10 @@ checkStmt: CHECK TABLE tableIdentifier partitionClause?;\n \n createStmt\n     : (ATTACH | CREATE) DATABASE (IF NOT EXISTS)? databaseIdentifier clusterClause? engineExpr?                                                                                       # CreateDatabaseStmt\n-    | (ATTACH | CREATE) DICTIONARY (IF NOT EXISTS)? tableIdentifier uuidClause? clusterClause? dictionarySchemaClause dictionaryEngineClause                                          # CreateDictionaryStmt\n+    | (ATTACH | CREATE (OR REPLACE)? | REPLACE) DICTIONARY (IF NOT EXISTS)? tableIdentifier uuidClause? clusterClause? dictionarySchemaClause dictionaryEngineClause                                          # CreateDictionaryStmt\n     | (ATTACH | CREATE) LIVE VIEW (IF NOT EXISTS)? tableIdentifier uuidClause? clusterClause? (WITH TIMEOUT DECIMAL_LITERAL?)? destinationClause? tableSchemaClause? subqueryClause   # CreateLiveViewStmt\n     | (ATTACH | CREATE) MATERIALIZED VIEW (IF NOT EXISTS)? tableIdentifier uuidClause? clusterClause? tableSchemaClause? (destinationClause | engineClause POPULATE?) subqueryClause  # CreateMaterializedViewStmt\n-    | (ATTACH | CREATE) TEMPORARY? TABLE (IF NOT EXISTS)? tableIdentifier uuidClause? clusterClause? tableSchemaClause? engineClause? subqueryClause?                                 # CreateTableStmt\n+    | (ATTACH | CREATE (OR REPLACE)? | REPLACE) TEMPORARY? TABLE (IF NOT EXISTS)? tableIdentifier uuidClause? clusterClause? tableSchemaClause? engineClause? subqueryClause?                                 # CreateTableStmt\n     | (ATTACH | CREATE) (OR REPLACE)? VIEW (IF NOT EXISTS)? tableIdentifier uuidClause? clusterClause? tableSchemaClause? subqueryClause                                              # CreateViewStmt\n     ;\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01157_replace_table.reference b/tests/queries/0_stateless/01157_replace_table.reference\nnew file mode 100644\nindex 000000000000..9fddaf99847f\n--- /dev/null\n+++ b/tests/queries/0_stateless/01157_replace_table.reference\n@@ -0,0 +1,20 @@\n+test flush on replace\n+1\ts1\n+2\ts2\n+3\ts3\n+exception on create and fill\n+0\n+1\t1\ts1\n+2\t2\ts2\n+3\t3\ts3\n+1\t1\ts1\n+2\t2\ts2\n+3\t3\ts3\n+1\t1\ts1\n+2\t2\ts2\n+3\t3\ts3\n+4\t4\ts4\n+buf\n+dist\n+join\n+t\ndiff --git a/tests/queries/0_stateless/01157_replace_table.sql b/tests/queries/0_stateless/01157_replace_table.sql\nnew file mode 100644\nindex 000000000000..a29b381a5226\n--- /dev/null\n+++ b/tests/queries/0_stateless/01157_replace_table.sql\n@@ -0,0 +1,51 @@\n+drop table if exists t;\n+drop table if exists dist;\n+drop table if exists buf;\n+drop table if exists join;\n+\n+select 'test flush on replace';\n+create table t (n UInt64, s String default 's' || toString(n)) engine=Memory;\n+create table dist (n int) engine=Distributed(test_shard_localhost, currentDatabase(), t);\n+create table buf (n int) engine=Buffer(currentDatabase(), dist, 1, 10, 100, 10, 100, 1000, 1000);\n+\n+system stop distributed sends dist;\n+insert into buf values (1);\n+replace table buf (n int) engine=Distributed(test_shard_localhost, currentDatabase(), dist);\n+replace table dist (n int) engine=Buffer(currentDatabase(), t, 1, 10, 100, 10, 100, 1000, 1000);\n+\n+system stop distributed sends buf;\n+insert into buf values (2);\n+replace table buf (n int) engine=Buffer(currentDatabase(), dist, 1, 10, 100, 10, 100, 1000, 1000);\n+replace table dist (n int) engine=Distributed(test_shard_localhost, currentDatabase(), t);\n+\n+system stop distributed sends dist;\n+insert into buf values (3);\n+replace table buf (n int) engine=Null;\n+replace table dist (n int) engine=Null;\n+\n+select * from t order by n;\n+\n+select 'exception on create and fill';\n+-- table is not created if select fails\n+create or replace table join engine=Join(ANY, INNER, n) as select * from t where throwIf(n); -- { serverError 395 }\n+select count() from system.tables where database=currentDatabase() and name='join';\n+\n+-- table is created and filled\n+create or replace table join engine=Join(ANY, INNER, n) as select * from t;\n+select * from numbers(10) as t any join join on t.number=join.n order by n;\n+\n+-- table is not replaced if select fails\n+insert into t(n) values (4);\n+replace table join engine=Join(ANY, INNER, n) as select * from t where throwIf(n); -- { serverError 395 }\n+select * from numbers(10) as t any join join on t.number=join.n order by n;\n+\n+-- table is replaced\n+replace table join engine=Join(ANY, INNER, n) as select * from t;\n+select * from numbers(10) as t any join join on t.number=join.n order by n;\n+\n+select name from system.tables where database=currentDatabase() order by name;\n+\n+drop table t;\n+drop table dist;\n+drop table buf;\n+drop table join;\ndiff --git a/tests/queries/0_stateless/01185_create_or_replace_table.reference b/tests/queries/0_stateless/01185_create_or_replace_table.reference\nindex 84df5f0f5b5b..be187d9dcd47 100644\n--- a/tests/queries/0_stateless/01185_create_or_replace_table.reference\n+++ b/tests/queries/0_stateless/01185_create_or_replace_table.reference\n@@ -1,8 +1,8 @@\n t1\n-CREATE TABLE test_01185.t1\\n(\\n    `n` UInt64,\\n    `s` String\\n)\\nENGINE = MergeTree\\nORDER BY n\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.t1\\n(\\n    `n` UInt64,\\n    `s` String\\n)\\nENGINE = MergeTree\\nORDER BY n\\nSETTINGS index_granularity = 8192\n t1\n-CREATE TABLE test_01185.t1\\n(\\n    `n` UInt64,\\n    `s` Nullable(String)\\n)\\nENGINE = MergeTree\\nORDER BY n\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.t1\\n(\\n    `n` UInt64,\\n    `s` Nullable(String)\\n)\\nENGINE = MergeTree\\nORDER BY n\\nSETTINGS index_granularity = 8192\n 2\t\\N\n t1\n-CREATE TABLE test_01185.t1\\n(\\n    `n` UInt64\\n)\\nENGINE = MergeTree\\nORDER BY n\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.t1\\n(\\n    `n` UInt64\\n)\\nENGINE = MergeTree\\nORDER BY n\\nSETTINGS index_granularity = 8192\n 3\ndiff --git a/tests/queries/0_stateless/01185_create_or_replace_table.sql b/tests/queries/0_stateless/01185_create_or_replace_table.sql\nindex fe408cc7ac62..45900329b2ca 100644\n--- a/tests/queries/0_stateless/01185_create_or_replace_table.sql\n+++ b/tests/queries/0_stateless/01185_create_or_replace_table.sql\n@@ -1,23 +1,22 @@\n-drop database if exists test_01185;\n-create database test_01185 engine=Atomic;\n+drop table if exists t1;\n \n-replace table test_01185.t1 (n UInt64, s String) engine=MergeTree order by n; -- { serverError 60 }\n-show tables from test_01185;\n-create or replace table test_01185.t1 (n UInt64, s String) engine=MergeTree order by n;\n-show tables from test_01185;\n-show create table test_01185.t1;\n+replace table t1 (n UInt64, s String) engine=MergeTree order by n; -- { serverError 60 }\n+show tables;\n+create or replace table t1 (n UInt64, s String) engine=MergeTree order by n;\n+show tables;\n+show create table t1;\n \n-insert into test_01185.t1 values (1, 'test');\n-create or replace table test_01185.t1 (n UInt64, s Nullable(String)) engine=MergeTree order by n;\n-insert into test_01185.t1 values (2, null);\n-show tables from test_01185;\n-show create table test_01185.t1;\n-select * from test_01185.t1;\n+insert into t1 values (1, 'test');\n+create or replace table t1 (n UInt64, s Nullable(String)) engine=MergeTree order by n;\n+insert into t1 values (2, null);\n+show tables;\n+show create table t1;\n+select * from t1;\n \n-replace table test_01185.t1 (n UInt64) engine=MergeTree order by n;\n-insert into test_01185.t1 values (3);\n-show tables from test_01185;\n-show create table test_01185.t1;\n-select * from test_01185.t1;\n+replace table t1 (n UInt64) engine=MergeTree order by n;\n+insert into t1 values (3);\n+show tables;\n+show create table t1;\n+select * from t1;\n \n-drop database test_01185;\n+drop table t1;\ndiff --git a/tests/queries/0_stateless/01915_create_or_replace_dictionary.sql b/tests/queries/0_stateless/01915_create_or_replace_dictionary.sql\nindex c9df6114ec9a..1520dd419735 100644\n--- a/tests/queries/0_stateless/01915_create_or_replace_dictionary.sql\n+++ b/tests/queries/0_stateless/01915_create_or_replace_dictionary.sql\n@@ -1,51 +1,51 @@\n-DROP DATABASE IF EXISTS 01915_db;\n-CREATE DATABASE 01915_db ENGINE=Atomic;\n+DROP DATABASE IF EXISTS test_01915_db;\n+CREATE DATABASE test_01915_db ENGINE=Atomic;\n \n-DROP TABLE IF EXISTS 01915_db.test_source_table_1;\n-CREATE TABLE 01915_db.test_source_table_1\n+DROP TABLE IF EXISTS test_01915_db.test_source_table_1;\n+CREATE TABLE test_01915_db.test_source_table_1\n (\n     id UInt64,\n     value String\n ) ENGINE=TinyLog;\n \n-INSERT INTO 01915_db.test_source_table_1 VALUES (0, 'Value0');\n+INSERT INTO test_01915_db.test_source_table_1 VALUES (0, 'Value0');\n \n-DROP DICTIONARY IF EXISTS 01915_db.test_dictionary;\n-CREATE OR REPLACE DICTIONARY 01915_db.test_dictionary\n+DROP DICTIONARY IF EXISTS test_01915_db.test_dictionary;\n+CREATE OR REPLACE DICTIONARY test_01915_db.test_dictionary\n (\n     id UInt64,\n     value String\n )\n PRIMARY KEY id\n LAYOUT(DIRECT())\n-SOURCE(CLICKHOUSE(DB '01915_db' TABLE 'test_source_table_1'));\n+SOURCE(CLICKHOUSE(DB 'test_01915_db' TABLE 'test_source_table_1'));\n \n-SELECT * FROM 01915_db.test_dictionary;\n+SELECT * FROM test_01915_db.test_dictionary;\n \n-DROP TABLE IF EXISTS 01915_db.test_source_table_2;\n-CREATE TABLE 01915_db.test_source_table_2\n+DROP TABLE IF EXISTS test_01915_db.test_source_table_2;\n+CREATE TABLE test_01915_db.test_source_table_2\n (\n     id UInt64,\n     value_1 String\n ) ENGINE=TinyLog;\n \n-INSERT INTO 01915_db.test_source_table_2 VALUES (0, 'Value1');\n+INSERT INTO test_01915_db.test_source_table_2 VALUES (0, 'Value1');\n \n-CREATE OR REPLACE DICTIONARY 01915_db.test_dictionary\n+CREATE OR REPLACE DICTIONARY test_01915_db.test_dictionary\n (\n     id UInt64,\n     value_1 String\n )\n PRIMARY KEY id\n LAYOUT(HASHED())\n-SOURCE(CLICKHOUSE(DB '01915_db' TABLE 'test_source_table_2'))\n+SOURCE(CLICKHOUSE(DB 'test_01915_db' TABLE 'test_source_table_2'))\n LIFETIME(0);\n \n-SELECT * FROM 01915_db.test_dictionary;\n+SELECT * FROM test_01915_db.test_dictionary;\n \n-DROP DICTIONARY 01915_db.test_dictionary;\n+DROP DICTIONARY test_01915_db.test_dictionary;\n \n-DROP TABLE 01915_db.test_source_table_1;\n-DROP TABLE 01915_db.test_source_table_2;\n+DROP TABLE test_01915_db.test_source_table_1;\n+DROP TABLE test_01915_db.test_source_table_2;\n \n-DROP DATABASE 01915_db;\n+DROP DATABASE test_01915_db;\ndiff --git a/tests/queries/0_stateless/arcadia_skip_list.txt b/tests/queries/0_stateless/arcadia_skip_list.txt\nindex d7581cc4e070..606015c369ff 100644\n--- a/tests/queries/0_stateless/arcadia_skip_list.txt\n+++ b/tests/queries/0_stateless/arcadia_skip_list.txt\n@@ -93,6 +93,8 @@\n 01138_join_on_distributed_and_tmp\n 01153_attach_mv_uuid\n 01155_rename_move_materialized_view\n+01157_replace_table\n+01185_create_or_replace_table\n 01191_rename_dictionary\n 01200_mutations_memory_consumption\n 01211_optimize_skip_unused_shards_type_mismatch\ndiff --git a/tests/queries/skip_list.json b/tests/queries/skip_list.json\nindex d40d9a940d0b..579a2636ad5f 100644\n--- a/tests/queries/skip_list.json\n+++ b/tests/queries/skip_list.json\n@@ -110,6 +110,8 @@\n         \"00510_materizlized_view_and_deduplication_zookeeper\",\n         \"00738_lock_for_inner_table\",\n         \"01153_attach_mv_uuid\",\n+        \"01157_replace_table\",\n+        \"01185_create_or_replace_table\",\n         /// Sometimes cannot lock file most likely due to concurrent or adjacent tests, but we don't care how it works in Ordinary database.\n         \"rocksdb\",\n         \"01914_exchange_dictionaries\" /// Requires Atomic database\n",
  "problem_statement": "CREATE OR REPLACE TABLE on a DISTRIBUTED table while performing writes\nHi everyone, \r\n\r\nClickHouse server version 21.5.5.12 (official build). (docker image)\r\n\r\n**Some notes:**\r\nHave 2 servers `ch1`, `ch2`, each has 2 tables `t1` and `t2` and another table `distributed_t1`\r\n\r\nI tried to use `CREATE OR REPLACE TABLE` on table `distributed_t1` while performing writes+read from that table\r\n\r\nWhile performing writes, RECREATed distributed_t1 and pointed it to t2 instead of t1\r\n\r\nBut some of the data was missing from t1, how do i know?\r\nI have used insert bulks of 100 inserts, and after recreating, count() returned a number that doesn't divide by 100, meaning some of it was missing.\r\n\r\nTo be precise, the data that should have been on the _other_ server is missing.\r\n\r\n**Example:**\r\n```\r\nCREATE TABLE t1 ON CLUSTER my_cluster (a UInt64, b UInt64) ENGINE=MergeTree()\r\nCREATE TABLE t2 ON CLUSTER my_cluster (a UInt64, b UInt64) ENGINE=MergeTree()\r\nCREATE TABLE IF NOT EXISTS distributed_t1 ON CLUSTER my_cluster ( a UInt64, b UInt64 ) ENGINE = Distributed('my_cluster', 'default', 't1', b) SETTINGS fsync_after_insert = 0, fsync_directories = 0\r\n```\r\nRecreate:\r\n```\r\nCREATE OR REPLACE TABLE distributed_t1 ON CLUSTER my_cluster ( a UInt64, b UInt64 ) ENGINE = Distributed('my_cluster', 'default', 't2', b) SETTINGS fsync_after_insert = 0, fsync_directories = 0\r\n```\r\nWrites are sequential number of column `b`, all writes are written to `ch1`, when recreating, sometimes half (because there are 2 servers) of the data is missing from `t1` and `t2` on both server servers\r\n\r\nNot sure if related, but same things can also happen while reading from Merge() engine and recreating it\r\n\r\nMy question is, how far ATOMIC are those commands over an atomic database?\r\nI was expecting the server to flush writes to a certain point, do the command, and then continue with the same pointer to the same table in that point of time\r\n\r\nWhat am I missing? Am I missing something?\r\n\r\nThanks.\nREPLACE TABLE replaces table even in case the insertion fails\n**Describe the unexpected behaviour**\r\n1. `CREATE TABLE t1 (...) ENGINE ReplicatedReplacingMergeTree(...) ...`\r\n2. insert data into t1.\r\n3. `CREATE TABLE t2 (...) ENGINE Join(ANY, LEFT, ...)`.\r\n4. `REPLACE TABLE t2 ENGINE Join(ANY, LEFT, ...) AS SELECT ... FROM t1`\r\n5. the insertion fails with `exception: Code: 241, e.displayText() = DB::Exception: Memory limit (total) exceeded: would use 704.69 GiB (attempt to allocate chunk of 132317568 bytes), maximum: 704.68 GiB: While executing CreatingSetsTransform (version 21.3.2.5)`\r\n6. `t2` is replaced with a subset of data from `t1`.\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use\r\n21.3.2.5\r\n\r\n* Which interface to use, if matters\r\nclickhouse-client\r\n\r\n**Expected behavior**\r\nIf the query fails, the replacement should not happen.\n",
  "hints_text": "`REPLACE TABLE t ...` query is a kind of syntax sugar, it works like the following queries:\r\n ```\r\nCREATE TABLE tmp_replace_xxxxxx ...\r\nEXCHANGE TABLES t AND tmp_replace_xxxxxx -- it's atomic\r\nDROP TABLE tmp_replace_xxxxxx\r\n```\r\n\r\nIf table engine is `Distributed` and `insert_distributed_sync=0` then it's possible that some data were inserted into Distributed table before `EXCHANGE`, but it were not flushed into destination tables before `DROP`.\r\n\r\nProbably we can fix it on ClickHouse side by forcefully flushing Distributed table after `EXCHANGE`\nAwesome.\r\nIt will make things much easier for us, we don't mind which table it will be flushed into, but we do mind to not lose the data of course.\n@tavplubix \r\n\r\nThat's a good idea.\r\nWe can also make `CREATE TABLE ... AS SELECT` atomic if database is `Atomic`.\r\n(table won't be created in case of insertion error)",
  "created_at": "2021-07-01T13:28:26Z"
}