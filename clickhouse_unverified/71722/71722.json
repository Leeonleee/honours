{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 71722,
  "instance_id": "ClickHouse__ClickHouse-71722",
  "issue_numbers": [
    "50647",
    "49947"
  ],
  "base_commit": "f9f8f8a8861b7a395c2f831ef28e211381f39a0d",
  "patch": "diff --git a/docs/en/operations/system-tables/overview.md b/docs/en/operations/system-tables/overview.md\nindex 4270f02c6d7b..2acea79cf5d0 100644\n--- a/docs/en/operations/system-tables/overview.md\n+++ b/docs/en/operations/system-tables/overview.md\n@@ -152,7 +152,7 @@ We can query across these tables using the [`merge`](/sql-reference/table-functi\n SELECT\n     _table,\n     max(event_time) AS most_recent\n-FROM merge('system', '^query_log.*')\n+FROM merge('system', '^query_log')\n GROUP BY _table\n ORDER BY most_recent DESC\n \n@@ -230,7 +230,7 @@ Due to system table versioning this still does not represent the full data in th\n SELECT\n     hostname() AS host,\n     count()\n-FROM clusterAllReplicas('default', merge('system', '^query_log.*'))\n+FROM clusterAllReplicas('default', merge('system', '^query_log'))\n WHERE (event_time >= '2025-04-01 00:00:00') AND (event_time <= '2025-04-12 00:00:00')\n GROUP BY host SETTINGS skip_unavailable_shards = 1\n \n@@ -248,4 +248,3 @@ GROUP BY host SETTINGS skip_unavailable_shards = 1\n - Blog: [System Tables and a window into the internals of ClickHouse](https://clickhouse.com/blog/clickhouse-debugging-issues-with-system-tables)\n - Blog: [Essential monitoring queries - part 1 - INSERT queries](https://clickhouse.com/blog/monitoring-troubleshooting-insert-queries-clickhouse)\n - Blog: [Essential monitoring queries - part 2 - SELECT queries](https://clickhouse.com/blog/monitoring-troubleshooting-select-queries-clickhouse)\n-\ndiff --git a/programs/local/LocalServer.cpp b/programs/local/LocalServer.cpp\nindex 1ddd05809b2f..e81b4e62ab9d 100644\n--- a/programs/local/LocalServer.cpp\n+++ b/programs/local/LocalServer.cpp\n@@ -52,6 +52,7 @@\n #include <boost/program_options/options_description.hpp>\n #include <base/argsToConfig.h>\n #include <filesystem>\n+#include <Common/filesystemHelpers.h>\n \n #include \"config.h\"\n \n@@ -280,7 +281,19 @@ static DatabasePtr createMemoryDatabaseIfNotExists(ContextPtr context, const Str\n static DatabasePtr createClickHouseLocalDatabaseOverlay(const String & name_, ContextPtr context)\n {\n     auto overlay = std::make_shared<DatabasesOverlay>(name_, context);\n-    overlay->registerNextDatabase(std::make_shared<DatabaseAtomic>(name_, fs::weakly_canonical(context->getPath()), UUIDHelpers::generateV4(), context));\n+\n+    UUID default_database_uuid;\n+\n+    fs::path existing_path_symlink = fs::weakly_canonical(context->getPath()) / \"metadata\" / \"default\";\n+    if (FS::isSymlinkNoThrow(existing_path_symlink))\n+        default_database_uuid = parse<UUID>(FS::readSymlink(existing_path_symlink).filename());\n+    else\n+        default_database_uuid = UUIDHelpers::generateV4();\n+\n+    fs::path default_database_metadata_path = fs::weakly_canonical(context->getPath()) / \"store\"\n+        / DatabaseCatalog::getPathForUUID(default_database_uuid);\n+\n+    overlay->registerNextDatabase(std::make_shared<DatabaseAtomic>(name_, default_database_metadata_path, default_database_uuid, context));\n     overlay->registerNextDatabase(std::make_shared<DatabaseFilesystem>(name_, \"\", context));\n     return overlay;\n }\n@@ -292,7 +305,7 @@ void LocalServer::tryInitPath()\n \n     if (getClientConfiguration().has(\"path\"))\n     {\n-        // User-supplied path.\n+        /// User-supplied path.\n         path = getClientConfiguration().getString(\"path\");\n         Poco::trimInPlace(path);\n \n@@ -306,15 +319,15 @@ void LocalServer::tryInitPath()\n     }\n     else\n     {\n-        // The path is not provided explicitly - use a unique path in the system temporary directory\n-        // (or in the current dir if a temporary doesn't exist)\n+        /// The user requested to use a temporary path - use a unique path in the system temporary directory\n+        /// (or in the current dir if a temporary doesn't exist)\n         LoggerRawPtr log = &logger();\n         std::filesystem::path parent_folder;\n         std::filesystem::path default_path;\n \n         try\n         {\n-            // try to guess a tmp folder name, and check if it's a directory (throw exception otherwise)\n+            /// Try to guess a tmp folder name, and check if it's a directory (throw an exception otherwise).\n             parent_folder = std::filesystem::temp_directory_path();\n \n         }\n@@ -342,7 +355,7 @@ void LocalServer::tryInitPath()\n         temporary_directory_to_delete = default_path;\n \n         path = default_path.string();\n-        LOG_DEBUG(log, \"Working directory created: {}\", path);\n+        LOG_DEBUG(log, \"Working directory will be created as needed: {}\", path);\n     }\n \n     global_context->setPath(fs::path(path) / \"\");\n@@ -883,30 +896,38 @@ void LocalServer::processConfig()\n \n     if (getClientConfiguration().has(\"path\"))\n     {\n+        attachSystemTablesServer(global_context, *createMemoryDatabaseIfNotExists(global_context, DatabaseCatalog::SYSTEM_DATABASE), false);\n+        attachInformationSchema(global_context, *createMemoryDatabaseIfNotExists(global_context, DatabaseCatalog::INFORMATION_SCHEMA));\n+        attachInformationSchema(global_context, *createMemoryDatabaseIfNotExists(global_context, DatabaseCatalog::INFORMATION_SCHEMA_UPPERCASE));\n+\n         String path = global_context->getPath();\n-        fs::create_directories(fs::path(path));\n \n         /// Lock path directory before read\n+        fs::create_directories(fs::path(path));\n         status.emplace(fs::path(path) / \"status\", StatusFile::write_full_info);\n \n-        LOG_DEBUG(log, \"Loading metadata from {}\", path);\n-        auto load_system_metadata_tasks = loadMetadataSystem(global_context);\n-        attachSystemTablesServer(global_context, *createMemoryDatabaseIfNotExists(global_context, DatabaseCatalog::SYSTEM_DATABASE), false);\n-        attachInformationSchema(global_context, *createMemoryDatabaseIfNotExists(global_context, DatabaseCatalog::INFORMATION_SCHEMA));\n-        attachInformationSchema(global_context, *createMemoryDatabaseIfNotExists(global_context, DatabaseCatalog::INFORMATION_SCHEMA_UPPERCASE));\n-        waitLoad(TablesLoaderForegroundPoolId, load_system_metadata_tasks);\n-\n-        if (!getClientConfiguration().has(\"only-system-tables\"))\n+        if (fs::exists(fs::path(path) / \"metadata\"))\n         {\n-            DatabaseCatalog::instance().createBackgroundTasks();\n-            waitLoad(loadMetadata(global_context));\n-            DatabaseCatalog::instance().startupBackgroundTasks();\n-        }\n+            LOG_DEBUG(log, \"Loading metadata from {}\", path);\n \n-        /// For ClickHouse local if path is not set the loader will be disabled.\n-        global_context->getUserDefinedSQLObjectsStorage().loadObjects();\n+            if (fs::exists(std::filesystem::path(path) / \"metadata\" / \"system.sql\"))\n+            {\n+                LoadTaskPtrs load_system_metadata_tasks = loadMetadataSystem(global_context);\n+                waitLoad(TablesLoaderForegroundPoolId, load_system_metadata_tasks);\n+            }\n \n-        LOG_DEBUG(log, \"Loaded metadata.\");\n+            if (!getClientConfiguration().has(\"only-system-tables\"))\n+            {\n+                DatabaseCatalog::instance().createBackgroundTasks();\n+                waitLoad(loadMetadata(global_context));\n+                DatabaseCatalog::instance().startupBackgroundTasks();\n+            }\n+\n+            /// For ClickHouse local if path is not set the loader will be disabled.\n+            global_context->getUserDefinedSQLObjectsStorage().loadObjects();\n+\n+            LOG_DEBUG(log, \"Loaded metadata.\");\n+        }\n     }\n     else if (!getClientConfiguration().has(\"no-system-tables\"))\n     {\n@@ -981,7 +1002,7 @@ void LocalServer::addExtraOptions(OptionsDescription & options_description)\n         (\"logger.level\", po::value<std::string>(), \"Log level\")\n \n         (\"no-system-tables\", \"do not attach system tables (better startup time)\")\n-        (\"path\", po::value<std::string>(), \"Storage path\")\n+        (\"path\", po::value<std::string>(), \"Storage path. If it was not specified, we will use a temporary directory, that is cleaned up on exit.\")\n         (\"only-system-tables\", \"attach only system tables from specified path\")\n         (\"top_level_domains_path\", po::value<std::string>(), \"Path to lists with custom TLDs\")\n         ;\n@@ -1023,8 +1044,6 @@ void LocalServer::processOptions(const OptionsDescription &, const CommandLineOp\n         getClientConfiguration().setBool(\"no-system-tables\", true);\n     if (options.count(\"only-system-tables\"))\n         getClientConfiguration().setBool(\"only-system-tables\", true);\n-    if (options.count(\"database\"))\n-        getClientConfiguration().setString(\"default_database\", options[\"database\"].as<std::string>());\n \n     if (options.count(\"input-format\"))\n         getClientConfiguration().setString(\"table-data-format\", options[\"input-format\"].as<std::string>());\ndiff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex f2083a261911..cf8f8683a990 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -2400,7 +2400,7 @@ try\n \n     /// Set current database name before loading tables and databases because\n     /// system logs may copy global context.\n-    std::string default_database = server_settings[ServerSetting::default_database].toString();\n+    std::string default_database = server_settings[ServerSetting::default_database];\n     if (default_database.empty())\n         throw Exception(ErrorCodes::BAD_ARGUMENTS, \"default_database cannot be empty\");\n     global_context->setCurrentDatabaseNameInGlobalContext(default_database);\ndiff --git a/src/Access/IAccessStorage.cpp b/src/Access/IAccessStorage.cpp\nindex fca30f588ee6..27ff6728d0a2 100644\n--- a/src/Access/IAccessStorage.cpp\n+++ b/src/Access/IAccessStorage.cpp\n@@ -308,7 +308,7 @@ bool IAccessStorage::insertImpl(const UUID &, const AccessEntityPtr & entity, bo\n {\n     if (isReadOnly())\n         throwReadonlyCannotInsert(entity->getType(), entity->getName());\n-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"insertImpl() is not implemented in {}\", getStorageType());\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"insertImpl is not implemented in {}\", getStorageType());\n }\n \n \n@@ -404,7 +404,7 @@ bool IAccessStorage::removeImpl(const UUID & id, bool throw_if_not_exists)\n             return false;\n         throwReadonlyCannotRemove(entity->getType(), entity->getName());\n     }\n-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"removeImpl() is not implemented in {}\", getStorageType());\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"removeImpl is not implemented in {}\", getStorageType());\n }\n \n \n@@ -500,7 +500,7 @@ bool IAccessStorage::updateImpl(const UUID & id, const UpdateFunc &, bool throw_\n             return false;\n         throwReadonlyCannotUpdate(entity->getType(), entity->getName());\n     }\n-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"updateImpl() is not implemented in {}\", getStorageType());\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"updateImpl is not implemented in {}\", getStorageType());\n }\n \n \ndiff --git a/src/Access/RowPolicy.cpp b/src/Access/RowPolicy.cpp\nindex 5b9d8521d9a8..ef03d7c582d2 100644\n--- a/src/Access/RowPolicy.cpp\n+++ b/src/Access/RowPolicy.cpp\n@@ -45,7 +45,7 @@ void RowPolicy::setFullName(const RowPolicyName & full_name_)\n \n void RowPolicy::setName(const String &)\n {\n-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"RowPolicy::setName() is not implemented\");\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"RowPolicy::setName is not implemented\");\n }\n \n \ndiff --git a/src/Client/LocalConnection.cpp b/src/Client/LocalConnection.cpp\nindex bf29d44e17d1..926fed4c1d59 100644\n--- a/src/Client/LocalConnection.cpp\n+++ b/src/Client/LocalConnection.cpp\n@@ -616,7 +616,7 @@ bool LocalConnection::pollImpl()\n \n UInt64 LocalConnection::receivePacketType()\n {\n-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"receivePacketType() is not implemented for LocalConnection\");\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"receivePacketType is not implemented for LocalConnection\");\n }\n \n Packet LocalConnection::receivePacket()\ndiff --git a/src/DataTypes/DataTypeObjectDeprecated.h b/src/DataTypes/DataTypeObjectDeprecated.h\nindex e1f81caaa4fb..2975f48e6aba 100644\n--- a/src/DataTypes/DataTypeObjectDeprecated.h\n+++ b/src/DataTypes/DataTypeObjectDeprecated.h\n@@ -30,7 +30,7 @@ class DataTypeObjectDeprecated : public IDataType\n \n     Field getDefault() const override\n     {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getDefault() is not implemented for data type {}\", getName());\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getDefault is not implemented for data type {}\", getName());\n     }\n \n     bool haveSubtypes() const override { return false; }\ndiff --git a/src/DataTypes/IDataType.h b/src/DataTypes/IDataType.h\nindex ab6e31da30a4..9d201dab6377 100644\n--- a/src/DataTypes/IDataType.h\n+++ b/src/DataTypes/IDataType.h\n@@ -362,7 +362,7 @@ class IDataType : private boost::noncopyable, public std::enable_shared_from_thi\n         bool throw_if_null) const\n     {\n         if (throw_if_null)\n-            throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getDynamicSubcolumnData() is not implemented for type {}\", getName());\n+            throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getDynamicSubcolumnData is not implemented for type {}\", getName());\n         return nullptr;\n     }\n };\ndiff --git a/src/DataTypes/IDataTypeDummy.h b/src/DataTypes/IDataTypeDummy.h\nindex fcfcbe43375f..912d5c501a32 100644\n--- a/src/DataTypes/IDataTypeDummy.h\n+++ b/src/DataTypes/IDataTypeDummy.h\n@@ -28,17 +28,17 @@ class IDataTypeDummy : public IDataType\n public:\n     MutableColumnPtr createColumn() const override\n     {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method createColumn() is not implemented for data type {}\", getName());\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method createColumn is not implemented for data type {}\", getName());\n     }\n \n     Field getDefault() const override\n     {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getDefault() is not implemented for data type {}\", getName());\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getDefault is not implemented for data type {}\", getName());\n     }\n \n     void insertDefaultInto(IColumn &) const override\n     {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method insertDefaultInto() is not implemented for data type {}\", getName());\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method insertDefaultInto is not implemented for data type {}\", getName());\n     }\n \n     bool haveSubtypes() const override { return false; }\ndiff --git a/src/Databases/DatabaseAtomic.cpp b/src/Databases/DatabaseAtomic.cpp\nindex a9f10ff1b856..2dfcef80dc3b 100644\n--- a/src/Databases/DatabaseAtomic.cpp\n+++ b/src/Databases/DatabaseAtomic.cpp\n@@ -4,9 +4,6 @@\n #include <Databases/DatabaseFactory.h>\n #include <Databases/DatabaseOnDisk.h>\n #include <Databases/DatabaseReplicated.h>\n-#include <IO/ReadBufferFromFile.h>\n-#include <IO/ReadHelpers.h>\n-#include <Interpreters/Context.h>\n #include <Interpreters/DDLTask.h>\n #include <Interpreters/DatabaseCatalog.h>\n #include <Interpreters/ExternalDictionariesLoader.h>\n@@ -14,7 +11,6 @@\n #include <Common/logger_useful.h>\n #include <Common/PoolId.h>\n #include <Common/atomicRename.h>\n-#include <Common/filesystemHelpers.h>\n #include <Core/Settings.h>\n \n \n@@ -54,8 +50,9 @@ class AtomicDatabaseTablesSnapshotIterator final : public DatabaseTablesSnapshot\n \n DatabaseAtomic::DatabaseAtomic(String name_, String metadata_path_, UUID uuid, const String & logger_name, ContextPtr context_)\n     : DatabaseOrdinary(name_, metadata_path_, \"store/\", logger_name, context_)\n-    , path_to_table_symlinks(fs::path(\"data\") / escapeForFileName(name_) / \"\")\n-    , path_to_metadata_symlink(fs::path(\"metadata\") / escapeForFileName(name_))\n+    , root_path(fs::weakly_canonical(context_->getPath()))\n+    , path_to_table_symlinks(root_path / \"data\" / escapeForFileName(name_) / \"\")\n+    , path_to_metadata_symlink(root_path / \"metadata\" / escapeForFileName(name_))\n     , db_uuid(uuid)\n {\n     assert(db_uuid != UUIDHelpers::Nil);\n@@ -436,6 +433,8 @@ void DatabaseAtomic::setDetachedTableNotInUseForce(const UUID & uuid)\n DatabaseAtomic::DetachedTables DatabaseAtomic::cleanupDetachedTables()\n {\n     DetachedTables not_in_use;\n+    if (detached_tables.empty())\n+        return not_in_use;\n     auto it = detached_tables.begin();\n     LOG_DEBUG(log, \"There are {} detached tables. Start searching non used tables.\", detached_tables.size());\n     while (it != detached_tables.end())\n@@ -573,6 +572,7 @@ void DatabaseAtomic::tryCreateSymlink(const StoragePtr & table, bool if_data_pat\n {\n     if (!db_disk->isSymlinkSupported())\n         return;\n+\n     try\n     {\n         String table_name = table->getStorageID().getTableName();\n@@ -580,8 +580,8 @@ void DatabaseAtomic::tryCreateSymlink(const StoragePtr & table, bool if_data_pat\n         if (!table->storesDataOnDisk())\n             throw Exception(ErrorCodes::LOGICAL_ERROR, \"Table {} doesn't have data path to create symlink\", table_name);\n \n-        String link = path_to_table_symlinks + escapeForFileName(table_name);\n-        fs::path data = fs::weakly_canonical(table->getDataPaths()[0]);\n+        String link = path_to_table_symlinks / escapeForFileName(table_name);\n+        fs::path data = fs::proximate(table->getDataPaths()[0], path_to_table_symlinks);\n \n         /// If it already points where needed.\n         if (db_disk->equivalentNoThrow(data, link))\n@@ -590,7 +590,7 @@ void DatabaseAtomic::tryCreateSymlink(const StoragePtr & table, bool if_data_pat\n         if (if_data_path_exist && !db_disk->existsFileOrDirectory(data))\n             return;\n \n-        db_disk->createDirectoriesSymlink(data, link);\n+        db_disk->createDirectorySymlink(data, link);\n     }\n     catch (...)\n     {\n@@ -605,7 +605,7 @@ void DatabaseAtomic::tryRemoveSymlink(const String & table_name)\n \n     try\n     {\n-        String path = path_to_table_symlinks + escapeForFileName(table_name);\n+        String path = path_to_table_symlinks / escapeForFileName(table_name);\n         db_disk->removeFileIfExists(path);\n     }\n     catch (...)\n@@ -621,21 +621,24 @@ void DatabaseAtomic::tryCreateMetadataSymlink()\n \n     /// Symlinks in data/db_name/ directory and metadata/db_name/ are not used by ClickHouse,\n     /// it's needed only for convenient introspection.\n-    assert(path_to_metadata_symlink != metadata_path);\n-    fs::path metadata_symlink(path_to_metadata_symlink);\n-    if (db_disk->existsFileOrDirectory(metadata_symlink))\n+    chassert(path_to_metadata_symlink != metadata_path);\n+    if (db_disk->existsFileOrDirectory(path_to_metadata_symlink))\n     {\n-        if (!db_disk->isSymlink(metadata_symlink))\n-            throw Exception(ErrorCodes::FILE_ALREADY_EXISTS, \"Directory {} exists\", path_to_metadata_symlink);\n+        if (!db_disk->isSymlink(path_to_metadata_symlink))\n+            throw Exception(ErrorCodes::FILE_ALREADY_EXISTS, \"Directory {} already exists\", path_to_metadata_symlink);\n     }\n     else\n     {\n         try\n         {\n             /// fs::exists could return false for broken symlink\n-            if (db_disk->isSymlinkNoThrow(metadata_symlink))\n-                db_disk->removeFileIfExists(metadata_symlink);\n-            db_disk->createDirectoriesSymlink(metadata_path, path_to_metadata_symlink);\n+            if (db_disk->isSymlinkNoThrow(path_to_metadata_symlink))\n+                db_disk->removeFileIfExists(path_to_metadata_symlink);\n+\n+            String symlink = fs::proximate(root_path / metadata_path, path_to_metadata_symlink.parent_path());\n+\n+            LOG_TEST(log, \"Creating directory symlink, path_to_metadata_symlink: {}, metadata_path: {}, symlink content: {}\", path_to_metadata_symlink, metadata_path, symlink);\n+            db_disk->createDirectorySymlink(symlink, path_to_metadata_symlink);\n         }\n         catch (...)\n         {\n@@ -670,8 +673,8 @@ void DatabaseAtomic::renameDatabase(ContextPtr query_context, const String & new\n     }\n \n     auto new_name_escaped = escapeForFileName(new_name);\n-    auto old_database_metadata_path = fs::path(\"metadata\") / (escapeForFileName(getDatabaseName()) + \".sql\");\n-    auto new_database_metadata_path = fs::path(\"metadata\") / (new_name_escaped + \".sql\");\n+    auto old_database_metadata_path = root_path / \"metadata\" / (escapeForFileName(getDatabaseName()) + \".sql\");\n+    auto new_database_metadata_path = root_path / \"metadata\" / (new_name_escaped + \".sql\");\n     db_disk->moveFile(old_database_metadata_path, new_database_metadata_path);\n \n     String old_path_to_table_symlinks;\n@@ -699,9 +702,9 @@ void DatabaseAtomic::renameDatabase(ContextPtr query_context, const String & new\n             snapshot.database = database_name;\n         }\n \n-        path_to_metadata_symlink = fs::path(\"metadata\") / new_name_escaped;\n+        path_to_metadata_symlink = root_path / \"metadata\" / new_name_escaped;\n         old_path_to_table_symlinks = path_to_table_symlinks;\n-        path_to_table_symlinks = fs::path(\"data\") / new_name_escaped / \"\";\n+        path_to_table_symlinks = root_path / \"data\" / new_name_escaped / \"\";\n     }\n \n     if (db_disk->isSymlinkSupported())\ndiff --git a/src/Databases/DatabaseAtomic.h b/src/Databases/DatabaseAtomic.h\nindex 7e9091286355..b63451757109 100644\n--- a/src/Databases/DatabaseAtomic.h\n+++ b/src/Databases/DatabaseAtomic.h\n@@ -88,8 +88,9 @@ class DatabaseAtomic : public DatabaseOrdinary\n     NameToPathMap table_name_to_path TSA_GUARDED_BY(mutex);\n \n     DetachedTables detached_tables TSA_GUARDED_BY(mutex);\n-    String path_to_table_symlinks;\n-    String path_to_metadata_symlink;\n+    std::filesystem::path root_path;\n+    std::filesystem::path path_to_table_symlinks;\n+    std::filesystem::path path_to_metadata_symlink;\n     const UUID db_uuid;\n \n     LoadTaskPtr startup_atomic_database_task TSA_GUARDED_BY(mutex);\ndiff --git a/src/Databases/DatabasesOverlay.cpp b/src/Databases/DatabasesOverlay.cpp\nindex e5acc48b7dbf..a0c8549b30e1 100644\n--- a/src/Databases/DatabasesOverlay.cpp\n+++ b/src/Databases/DatabasesOverlay.cpp\n@@ -64,7 +64,7 @@ void DatabasesOverlay::createTable(ContextPtr context_, const String & table_nam\n     }\n     throw Exception(\n         ErrorCodes::LOGICAL_ERROR,\n-        \"There is no databases for CREATE TABLE `{}` query in database `{}` (engine {})\",\n+        \"There are no databases for CREATE TABLE `{}` query in database `{}` (engine {})\",\n         table_name,\n         getDatabaseName(),\n         getEngineName());\n@@ -82,7 +82,7 @@ void DatabasesOverlay::dropTable(ContextPtr context_, const String & table_name,\n     }\n     throw Exception(\n         ErrorCodes::LOGICAL_ERROR,\n-        \"There is no databases for DROP TABLE `{}` query in database `{}` (engine {})\",\n+        \"There are no databases for DROP TABLE `{}` query in database `{}` (engine {})\",\n         table_name,\n         getDatabaseName(),\n         getEngineName());\n@@ -105,7 +105,7 @@ void DatabasesOverlay::attachTable(\n     }\n     throw Exception(\n         ErrorCodes::LOGICAL_ERROR,\n-        \"There is no databases for ATTACH TABLE `{}` query in database `{}` (engine {})\",\n+        \"There are no databases for ATTACH TABLE `{}` query in database `{}` (engine {})\",\n         table_name,\n         getDatabaseName(),\n         getEngineName());\n@@ -121,7 +121,7 @@ StoragePtr DatabasesOverlay::detachTable(ContextPtr context_, const String & tab\n     }\n     throw Exception(\n         ErrorCodes::LOGICAL_ERROR,\n-        \"There is no databases for DETACH TABLE `{}` query in database `{}` (engine {})\",\n+        \"There are no databases for DETACH TABLE `{}` query in database `{}` (engine {})\",\n         table_name,\n         getDatabaseName(),\n         getEngineName());\n@@ -256,7 +256,7 @@ void DatabasesOverlay::alterTable(ContextPtr local_context, const StorageID & ta\n     }\n     throw Exception(\n         ErrorCodes::LOGICAL_ERROR,\n-        \"There is no databases for ALTER TABLE `{}` query in database `{}` (engine {})\",\n+        \"There are no databases for ALTER TABLE `{}` query in database `{}` (engine {})\",\n         table_id.table_name,\n         getDatabaseName(),\n         getEngineName());\n@@ -314,4 +314,251 @@ DatabaseTablesIteratorPtr DatabasesOverlay::getTablesIterator(ContextPtr context\n     return std::make_unique<DatabaseTablesSnapshotIterator>(std::move(tables), getDatabaseName());\n }\n \n+bool DatabasesOverlay::canContainMergeTreeTables() const\n+{\n+    for (const auto & db : databases)\n+        if (db->canContainMergeTreeTables())\n+            return true;\n+    return false;\n+}\n+\n+bool DatabasesOverlay::canContainDistributedTables() const\n+{\n+    for (const auto & db : databases)\n+        if (db->canContainDistributedTables())\n+            return true;\n+    return false;\n+}\n+\n+void DatabasesOverlay::loadStoredObjects(ContextMutablePtr local_context, LoadingStrictnessLevel mode)\n+{\n+    for (auto & db : databases)\n+        if (!db->isReadOnly())\n+            db->loadStoredObjects(local_context, mode);\n+}\n+\n+bool DatabasesOverlay::supportsLoadingInTopologicalOrder() const\n+{\n+    for (const auto & db : databases)\n+        if (db->supportsLoadingInTopologicalOrder())\n+            return true;\n+    return false;\n+}\n+\n+void DatabasesOverlay::beforeLoadingMetadata(ContextMutablePtr local_context, LoadingStrictnessLevel mode)\n+{\n+    for (auto & db : databases)\n+        if (!db->isReadOnly())\n+            db->beforeLoadingMetadata(local_context, mode);\n+}\n+\n+void DatabasesOverlay::loadTablesMetadata(ContextPtr local_context, ParsedTablesMetadata & metadata, bool is_startup)\n+{\n+    for (auto & db : databases)\n+        if (!db->isReadOnly())\n+            db->loadTablesMetadata(local_context, metadata, is_startup);\n+}\n+\n+void DatabasesOverlay::loadTableFromMetadata(\n+    ContextMutablePtr local_context,\n+    const String & file_path,\n+    const QualifiedTableName & name,\n+    const ASTPtr & ast,\n+    LoadingStrictnessLevel mode)\n+{\n+    for (auto & db : databases)\n+    {\n+        if (db->isReadOnly())\n+            continue;\n+\n+        try\n+        {\n+            db->loadTableFromMetadata(local_context, file_path, name, ast, mode);\n+            return;\n+        }\n+        catch (...)\n+        {\n+            continue;\n+        }\n+    }\n+    throw Exception(\n+        ErrorCodes::LOGICAL_ERROR,\n+        \"There are no databases capable of loading table `{}` from path `{}` in database `{}` (engine {})\",\n+        name.table,\n+        file_path,\n+        getDatabaseName(),\n+        getEngineName());\n+}\n+\n+LoadTaskPtr DatabasesOverlay::loadTableFromMetadataAsync(\n+    AsyncLoader & async_loader,\n+    LoadJobSet load_after,\n+    ContextMutablePtr local_context,\n+    const String & file_path,\n+    const QualifiedTableName & name,\n+    const ASTPtr & ast,\n+    LoadingStrictnessLevel mode)\n+{\n+    for (auto & db : databases)\n+    {\n+        if (db->isReadOnly())\n+            continue;\n+\n+        try\n+        {\n+            return db->loadTableFromMetadataAsync(async_loader, load_after, local_context, file_path, name, ast, mode);\n+        }\n+        catch (...)\n+        {\n+            continue;\n+        }\n+    }\n+    throw Exception(\n+        ErrorCodes::LOGICAL_ERROR,\n+        \"There are no databases capable of loading table `{}` from path `{}` in database `{}` (engine {})\",\n+        name.table,\n+        file_path,\n+        getDatabaseName(),\n+        getEngineName());\n+}\n+\n+LoadTaskPtr DatabasesOverlay::startupTableAsync(\n+    AsyncLoader & async_loader,\n+    LoadJobSet startup_after,\n+    const QualifiedTableName & name,\n+    LoadingStrictnessLevel mode)\n+{\n+    for (auto & db : databases)\n+    {\n+        if (db->isReadOnly())\n+            continue;\n+\n+        try\n+        {\n+            return db->startupTableAsync(async_loader, startup_after, name, mode);\n+        }\n+        catch (...)\n+        {\n+            continue;\n+        }\n+    }\n+    throw Exception(\n+        ErrorCodes::LOGICAL_ERROR,\n+        \"There are no databases capable of starting up table `{}` in database `{}` (engine {})\",\n+        name.table,\n+        getDatabaseName(),\n+        getEngineName());\n+}\n+\n+LoadTaskPtr DatabasesOverlay::startupDatabaseAsync(\n+    AsyncLoader & async_loader,\n+    LoadJobSet startup_after,\n+    LoadingStrictnessLevel mode)\n+{\n+    for (auto & db : databases)\n+    {\n+        if (db->isReadOnly())\n+            continue;\n+\n+        try\n+        {\n+            return db->startupDatabaseAsync(async_loader, startup_after, mode);\n+        }\n+        catch (...)\n+        {\n+            continue;\n+        }\n+    }\n+    throw Exception(\n+        ErrorCodes::LOGICAL_ERROR,\n+        \"There are no databases capable of starting up asynchronously in database `{}` (engine {})\",\n+        getDatabaseName(),\n+        getEngineName());\n+}\n+\n+void DatabasesOverlay::waitTableStarted(const String & name) const\n+{\n+    for (const auto & db : databases)\n+    {\n+        if (db->isReadOnly())\n+            continue;\n+\n+        try\n+        {\n+            db->waitTableStarted(name);\n+            return;\n+        }\n+        catch (...)\n+        {\n+            continue;\n+        }\n+    }\n+    throw Exception(\n+        ErrorCodes::LOGICAL_ERROR,\n+        \"There are no databases capable of waiting for table startup `{}` in database `{}` (engine {})\",\n+        name,\n+        getDatabaseName(),\n+        getEngineName());\n+}\n+\n+void DatabasesOverlay::waitDatabaseStarted() const\n+{\n+    for (const auto & db : databases)\n+    {\n+        if (db->isReadOnly())\n+            continue;\n+\n+        try\n+        {\n+            db->waitDatabaseStarted();\n+            return;\n+        }\n+        catch (...)\n+        {\n+            continue;\n+        }\n+    }\n+    throw Exception(\n+        ErrorCodes::LOGICAL_ERROR,\n+        \"There are no databases capable of waiting for startup in database `{}` (engine {})\",\n+        getDatabaseName(),\n+        getEngineName());\n+}\n+\n+void DatabasesOverlay::stopLoading()\n+{\n+    for (auto & db : databases)\n+    {\n+        if (db->isReadOnly())\n+            continue;\n+\n+        try\n+        {\n+            db->stopLoading();\n+            return;\n+        }\n+        catch (...)\n+        {\n+            continue;\n+        }\n+    }\n+    throw Exception(\n+        ErrorCodes::LOGICAL_ERROR,\n+        \"There are no databases capable of stop loading in database `{}` (engine {})\",\n+        getDatabaseName(),\n+        getEngineName());\n+}\n+\n+void DatabasesOverlay::checkMetadataFilenameAvailability(const String & table_name) const\n+{\n+    for (const auto & db : databases)\n+    {\n+        if (db->isReadOnly())\n+            continue;\n+        db->checkMetadataFilenameAvailability(table_name);\n+        return;\n+    }\n+}\n+\n+\n }\ndiff --git a/src/Databases/DatabasesOverlay.h b/src/Databases/DatabasesOverlay.h\nindex 40c653e5cb50..2883844106c7 100644\n--- a/src/Databases/DatabasesOverlay.h\n+++ b/src/Databases/DatabasesOverlay.h\n@@ -66,6 +66,40 @@ class DatabasesOverlay : public IDatabase, protected WithContext\n \n     void shutdown() override;\n \n+    bool canContainMergeTreeTables() const override;\n+    bool canContainDistributedTables() const override;\n+    void loadStoredObjects(ContextMutablePtr local_context, LoadingStrictnessLevel mode) override;\n+    bool supportsLoadingInTopologicalOrder() const override;\n+    void beforeLoadingMetadata(ContextMutablePtr local_context, LoadingStrictnessLevel mode) override;\n+    void loadTablesMetadata(ContextPtr local_context, ParsedTablesMetadata & metadata, bool is_startup) override;\n+    void loadTableFromMetadata(\n+        ContextMutablePtr local_context,\n+        const String & file_path,\n+        const QualifiedTableName & name,\n+        const ASTPtr & ast,\n+        LoadingStrictnessLevel mode) override;\n+    LoadTaskPtr loadTableFromMetadataAsync(\n+        AsyncLoader & async_loader,\n+        LoadJobSet load_after,\n+        ContextMutablePtr local_context,\n+        const String & file_path,\n+        const QualifiedTableName & name,\n+        const ASTPtr & ast,\n+        LoadingStrictnessLevel mode) override;\n+    [[nodiscard]] LoadTaskPtr startupTableAsync(\n+        AsyncLoader & async_loader,\n+        LoadJobSet startup_after,\n+        const QualifiedTableName & name,\n+        LoadingStrictnessLevel mode) override;\n+    [[nodiscard]] LoadTaskPtr startupDatabaseAsync(\n+        AsyncLoader & async_loader,\n+        LoadJobSet startup_after,\n+        LoadingStrictnessLevel mode) override;\n+    void waitTableStarted(const String & name) const override;\n+    void waitDatabaseStarted() const override;\n+    void stopLoading() override;\n+    void checkMetadataFilenameAvailability(const String & table_name) const override;\n+\n protected:\n     std::vector<DatabasePtr> databases;\n     LoggerPtr log;\ndiff --git a/src/Disks/DiskLocal.cpp b/src/Disks/DiskLocal.cpp\nindex bc5181133f56..ea637bd62f3f 100644\n--- a/src/Disks/DiskLocal.cpp\n+++ b/src/Disks/DiskLocal.cpp\n@@ -445,9 +445,11 @@ bool DiskLocal::isSymlinkNoThrow(const String & path) const\n     return FS::isSymlinkNoThrow(fs::path(disk_path) / path);\n }\n \n-void DiskLocal::createDirectoriesSymlink(const String & target, const String & link)\n+void DiskLocal::createDirectorySymlink(const String & target, const String & link)\n {\n-    fs::create_directory_symlink(fs::path(disk_path) / target, fs::path(disk_path) / link);\n+    auto link_path_inside_disk = fs::path(disk_path) / link;\n+    /// Symlinks will be relative.\n+    fs::create_directory_symlink(fs::proximate(link_path_inside_disk.parent_path() / target, link_path_inside_disk.parent_path()), link_path_inside_disk);\n }\n \n String DiskLocal::readSymlink(const fs::path & path) const\ndiff --git a/src/Disks/DiskLocal.h b/src/Disks/DiskLocal.h\nindex 0ae633221270..79147eac6210 100644\n--- a/src/Disks/DiskLocal.h\n+++ b/src/Disks/DiskLocal.h\n@@ -116,7 +116,7 @@ class DiskLocal : public IDisk\n \n     bool isSymlinkNoThrow(const String & path) const override;\n \n-    void createDirectoriesSymlink(const String & target, const String & link) override;\n+    void createDirectorySymlink(const String & target, const String & link) override;\n \n     String readSymlink(const fs::path & path) const override;\n \ndiff --git a/src/Disks/IDisk.h b/src/Disks/IDisk.h\nindex c9c598bc062e..a52c307cd8ed 100644\n--- a/src/Disks/IDisk.h\n+++ b/src/Disks/IDisk.h\n@@ -384,22 +384,22 @@ class IDisk : public Space\n     virtual bool isSymlink(const String &) const\n     {\n         throw Exception(\n-            ErrorCodes::NOT_IMPLEMENTED, \"Method isSymlink() is not implemented for disk type: {}\", getDataSourceDescription().toString());\n+            ErrorCodes::NOT_IMPLEMENTED, \"Method isSymlink is not implemented for disk type: {}\", getDataSourceDescription().toString());\n     }\n \n     virtual bool isSymlinkNoThrow(const String &) const\n     {\n         throw Exception(\n             ErrorCodes::NOT_IMPLEMENTED,\n-            \"Method isSymlinkNothrow() is not implemented for disk type: {}\",\n+            \"Method isSymlinkNothrow is not implemented for disk type: {}\",\n             getDataSourceDescription().toString());\n     }\n \n-    virtual void createDirectoriesSymlink(const String &, const String &)\n+    virtual void createDirectorySymlink(const String &, const String &)\n     {\n         throw Exception(\n             ErrorCodes::NOT_IMPLEMENTED,\n-            \"Method createDirectoriesSymlink() is not implemented for disk type: {}\",\n+            \"Method createDirectorySymlink is not implemented for disk type: {}\",\n             getDataSourceDescription().toString());\n     }\n \n@@ -407,20 +407,20 @@ class IDisk : public Space\n     {\n         throw Exception(\n             ErrorCodes::NOT_IMPLEMENTED,\n-            \"Method readSymlink() is not implemented for disk type: {}\",\n+            \"Method readSymlink is not implemented for disk type: {}\",\n             getDataSourceDescription().toString());\n     }\n \n     virtual bool equivalent(const String &, const String &) const\n     {\n         throw Exception(\n-            ErrorCodes::NOT_IMPLEMENTED, \"Method equivalent() is not implemented for disk type: {}\", getDataSourceDescription().toString());\n+            ErrorCodes::NOT_IMPLEMENTED, \"Method equivalent is not implemented for disk type: {}\", getDataSourceDescription().toString());\n     }\n \n     virtual bool equivalentNoThrow(const String &, const String &) const\n     {\n         throw Exception(\n-            ErrorCodes::NOT_IMPLEMENTED, \"Method equivalent() is not implemented for disk type: {}\", getDataSourceDescription().toString());\n+            ErrorCodes::NOT_IMPLEMENTED, \"Method equivalent is not implemented for disk type: {}\", getDataSourceDescription().toString());\n     }\n \n     /// Truncate file to specified size.\n@@ -498,7 +498,7 @@ class IDisk : public Space\n     {\n         throw Exception(\n             ErrorCodes::NOT_IMPLEMENTED,\n-            \"Method getMetadataStorage() is not implemented for disk type: {}\",\n+            \"Method getMetadataStorage is not implemented for disk type: {}\",\n             getDataSourceDescription().toString());\n     }\n \n@@ -532,7 +532,7 @@ class IDisk : public Space\n     {\n         throw Exception(\n             ErrorCodes::NOT_IMPLEMENTED,\n-            \"Method getObjectStorage() is not implemented for disk type: {}\",\n+            \"Method getObjectStorage is not implemented for disk type: {}\",\n             getDataSourceDescription().toString());\n     }\n \n@@ -543,7 +543,7 @@ class IDisk : public Space\n     {\n         throw Exception(\n             ErrorCodes::NOT_IMPLEMENTED,\n-            \"Method createDiskObjectStorage() is not implemented for disk type: {}\",\n+            \"Method createDiskObjectStorage is not implemented for disk type: {}\",\n             getDataSourceDescription().toString());\n     }\n \n@@ -565,7 +565,7 @@ class IDisk : public Space\n     {\n         throw Exception(\n             ErrorCodes::NOT_IMPLEMENTED,\n-            \"Method getS3StorageClient() is not implemented for disk type: {}\",\n+            \"Method getS3StorageClient is not implemented for disk type: {}\",\n             getDataSourceDescription().toString());\n     }\n \ndiff --git a/src/Disks/ObjectStorages/IObjectStorage.cpp b/src/Disks/ObjectStorages/IObjectStorage.cpp\nindex ce5f06e8f25f..da10528bbedf 100644\n--- a/src/Disks/ObjectStorages/IObjectStorage.cpp\n+++ b/src/Disks/ObjectStorages/IObjectStorage.cpp\n@@ -84,7 +84,7 @@ void IObjectStorage::copyObjectToAnotherObjectStorage( // NOLINT\n \n const std::string & IObjectStorage::getCacheName() const\n {\n-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"getCacheName() is not implemented for object storage\");\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"getCacheName is not implemented for object storage\");\n }\n \n ReadSettings IObjectStorage::patchSettings(const ReadSettings & read_settings) const\ndiff --git a/src/Disks/ObjectStorages/Local/LocalObjectStorage.cpp b/src/Disks/ObjectStorages/Local/LocalObjectStorage.cpp\nindex ea09f29b428d..e24732bee8c7 100644\n--- a/src/Disks/ObjectStorages/Local/LocalObjectStorage.cpp\n+++ b/src/Disks/ObjectStorages/Local/LocalObjectStorage.cpp\n@@ -209,7 +209,7 @@ std::unique_ptr<IObjectStorage> LocalObjectStorage::cloneObjectStorage(\n     const Poco::Util::AbstractConfiguration & /* config */,\n     const std::string & /* config_prefix */, ContextPtr /* context */)\n {\n-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"cloneObjectStorage() is not implemented for LocalObjectStorage\");\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"cloneObjectStorage is not implemented for LocalObjectStorage\");\n }\n \n ObjectStorageKey\ndiff --git a/src/Disks/ObjectStorages/Web/WebObjectStorage.cpp b/src/Disks/ObjectStorages/Web/WebObjectStorage.cpp\nindex 35abc0ed0dfa..e5d47a54cebc 100644\n--- a/src/Disks/ObjectStorages/Web/WebObjectStorage.cpp\n+++ b/src/Disks/ObjectStorages/Web/WebObjectStorage.cpp\n@@ -287,7 +287,7 @@ std::unique_ptr<IObjectStorage> WebObjectStorage::cloneObjectStorage(\n     const Poco::Util::AbstractConfiguration & /* config */,\n     const std::string & /* config_prefix */, ContextPtr /* context */)\n {\n-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"cloneObjectStorage() is not implemented for WebObjectStorage\");\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"cloneObjectStorage is not implemented for WebObjectStorage\");\n }\n \n }\ndiff --git a/src/Formats/NumpyDataTypes.h b/src/Formats/NumpyDataTypes.h\nindex 6ccdf65f4576..fbb0a11c5593 100644\n--- a/src/Formats/NumpyDataTypes.h\n+++ b/src/Formats/NumpyDataTypes.h\n@@ -44,9 +44,9 @@ class NumpyDataType\n     Endianness getEndianness() const { return endianness; }\n \n     virtual NumpyDataTypeIndex getTypeIndex() const = 0;\n-    virtual size_t getSize() const { throw DB::Exception(DB::ErrorCodes::NOT_IMPLEMENTED, \"Function getSize() is not implemented\"); }\n-    virtual void setSize(size_t) { throw DB::Exception(DB::ErrorCodes::NOT_IMPLEMENTED, \"Function setSize() is not implemented\"); }\n-    virtual String str() const { throw DB::Exception(DB::ErrorCodes::NOT_IMPLEMENTED, \"Function str() is not implemented\"); }\n+    virtual size_t getSize() const { throw DB::Exception(DB::ErrorCodes::NOT_IMPLEMENTED, \"Function getSize is not implemented\"); }\n+    virtual void setSize(size_t) { throw DB::Exception(DB::ErrorCodes::NOT_IMPLEMENTED, \"Function setSize is not implemented\"); }\n+    virtual String str() const { throw DB::Exception(DB::ErrorCodes::NOT_IMPLEMENTED, \"Function str is not implemented\"); }\n \n protected:\n     Endianness endianness;\ndiff --git a/src/Functions/byteSwap.cpp b/src/Functions/byteSwap.cpp\nindex 9594e583f89b..d9c76aada0fb 100644\n--- a/src/Functions/byteSwap.cpp\n+++ b/src/Functions/byteSwap.cpp\n@@ -30,7 +30,7 @@ T byteSwap(T x)\n template <typename T>\n T byteSwap(T)\n {\n-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"byteSwap() is not implemented for {} datatype\", demangle(typeid(T).name()));\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"byteSwap is not implemented for {} datatype\", demangle(typeid(T).name()));\n }\n \n template <typename T>\ndiff --git a/src/IO/Archives/ZipArchiveWriter.cpp b/src/IO/Archives/ZipArchiveWriter.cpp\nindex df263ceb29bf..ac72c3ded02e 100644\n--- a/src/IO/Archives/ZipArchiveWriter.cpp\n+++ b/src/IO/Archives/ZipArchiveWriter.cpp\n@@ -207,12 +207,12 @@ class ZipArchiveWriter::StreamInfo\n \n     static long seekFunc(void *, void *, ZPOS64_T, int) // NOLINT(google-runtime-int)\n     {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"StreamInfo::seek() is not implemented\");\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"StreamInfo::seek is not implemented\");\n     }\n \n     static unsigned long readFileFunc(void *, void *, void *, unsigned long) // NOLINT(google-runtime-int)\n     {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"StreamInfo::readFile() is not implemented\");\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"StreamInfo::readFile is not implemented\");\n     }\n \n     std::unique_ptr<WriteBuffer> write_buffer;\ndiff --git a/src/Interpreters/DatabaseCatalog.cpp b/src/Interpreters/DatabaseCatalog.cpp\nindex e546271bbc6f..2d902b3c36ca 100644\n--- a/src/Interpreters/DatabaseCatalog.cpp\n+++ b/src/Interpreters/DatabaseCatalog.cpp\n@@ -1094,6 +1094,9 @@ void DatabaseCatalog::loadMarkedAsDroppedTables()\n         dropped_metadata.emplace(std::move(full_path), std::move(dropped_id));\n     }\n \n+    if (dropped_metadata.empty())\n+        return;\n+\n     LOG_INFO(log, \"Found {} partially dropped tables. Will load them and retry removal.\", dropped_metadata.size());\n \n     ThreadPoolCallbackRunnerLocal<void> runner(getDatabaseCatalogDropTablesThreadPool().get(), \"DropTables\");\ndiff --git a/src/Interpreters/loadMetadata.cpp b/src/Interpreters/loadMetadata.cpp\nindex 2be58620b3f4..7ade5c6031ab 100644\n--- a/src/Interpreters/loadMetadata.cpp\n+++ b/src/Interpreters/loadMetadata.cpp\n@@ -1,5 +1,4 @@\n #include <Common/PoolId.h>\n-#include <Common/ThreadPool.h>\n #include <Common/thread_local_rng.h>\n \n #include <Parsers/ParserCreateQuery.h>\n@@ -18,7 +17,6 @@\n #include <Storages/StorageMaterializedView.h>\n \n #include <IO/ReadBufferFromFile.h>\n-#include <IO/ReadHelpers.h>\n \n #include <Core/Settings.h>\n #include <Common/CurrentMetrics.h>\n@@ -33,6 +31,7 @@\n \n #define ORDINARY_TO_ATOMIC_PREFIX \".tmp_convert.\"\n \n+\n namespace fs = std::filesystem;\n \n namespace DB\n@@ -104,6 +103,10 @@ static void loadDatabase(\n     const String & database_path,\n     bool force_restore_data)\n {\n+    /// If it is already loaded.\n+    if (DatabaseCatalog::instance().isDatabaseExist(database))\n+        return;\n+\n     String database_attach_query;\n     String database_metadata_file = database_path + \".sql\";\n \n@@ -198,11 +201,14 @@ LoadTaskPtrs loadMetadata(ContextMutablePtr context, const String & default_data\n         }\n     }\n \n-\n     auto metadata_dir_path = fs::path(\"metadata\");\n \n     /// Loop over databases.\n     std::map<String, String> databases;\n+\n+    /// Some databases don't have an .sql metadata file.\n+    std::map<String, String> orphan_directories_and_symlinks;\n+\n     for (const auto it = db_disk->iterateDirectory(metadata_dir_path); it->isValid(); it->next())\n     {\n         auto sub_path = fs::path(it->path());\n@@ -210,17 +216,22 @@ LoadTaskPtrs loadMetadata(ContextMutablePtr context, const String & default_data\n             sub_path = sub_path.parent_path();\n \n         if (db_disk->isSymlinkSupported() && db_disk->isSymlink(sub_path))\n+        {\n+            String db_name = sub_path.filename().string();\n+            if (!isSystemOrInformationSchema(db_name))\n+                orphan_directories_and_symlinks.emplace(unescapeForFileName(db_name), sub_path);\n             continue;\n+        }\n \n         if (db_disk->existsDirectory(sub_path))\n             continue;\n \n         const auto current_file = sub_path.filename().string();\n \n-        /// TODO: DETACH DATABASE PERMANENTLY ?\n         if (fs::path(current_file).extension() == \".sql\")\n         {\n             String db_name = fs::path(current_file).stem();\n+            orphan_directories_and_symlinks.erase(db_name);\n             if (!isSystemOrInformationSchema(db_name))\n                 databases.emplace(unescapeForFileName(db_name), metadata_dir_path / db_name);\n         }\n@@ -260,7 +271,13 @@ LoadTaskPtrs loadMetadata(ContextMutablePtr context, const String & default_data\n         loaded_databases.insert({name, DatabaseCatalog::instance().getDatabase(name)});\n     }\n \n-    auto mode = getLoadingStrictnessLevel(/* attach */ true, /* force_attach */ true, has_force_restore_data_flag, /*secondary*/ false);\n+    for (const auto & [name, db_path] : orphan_directories_and_symlinks)\n+    {\n+        loadDatabase(context, name, db_path, has_force_restore_data_flag);\n+        loaded_databases.insert({name, DatabaseCatalog::instance().getDatabase(name)});\n+    }\n+\n+    auto mode = getLoadingStrictnessLevel(/* attach */ true, /* force_attach */ true, has_force_restore_data_flag, /* secondary */ false);\n     TablesLoader loader{context, std::move(loaded_databases), mode};\n     auto load_tasks = loader.loadTablesAsync();\n     auto startup_tasks = loader.startupTablesAsync();\n@@ -292,6 +309,10 @@ LoadTaskPtrs loadMetadata(ContextMutablePtr context, const String & default_data\n \n static void loadSystemDatabaseImpl(ContextMutablePtr context, const String & database_name, const String & default_engine)\n {\n+    /// If it is already loaded.\n+    if (DatabaseCatalog::instance().isDatabaseExist(database_name))\n+        return;\n+\n     auto db_disk = Context::getGlobalContextInstance()->getDatabaseDisk();\n \n     String database_name_escaped = escapeForFileName(database_name);\n@@ -522,7 +543,8 @@ void convertDatabasesEnginesIfNeed(const LoadTaskPtrs & load_metadata, ContextMu\n \n LoadTaskPtrs loadMetadataSystem(ContextMutablePtr context, bool async_load_system_database)\n {\n-    loadSystemDatabaseImpl(context, DatabaseCatalog::SYSTEM_DATABASE, \"Atomic\");\n+    loadSystemDatabaseImpl(context, DatabaseCatalog::SYSTEM_DATABASE,\n+        context->getApplicationType() == Context::ApplicationType::SERVER ? \"Atomic\" : \"Memory\");\n     loadSystemDatabaseImpl(context, DatabaseCatalog::INFORMATION_SCHEMA, \"Memory\");\n     loadSystemDatabaseImpl(context, DatabaseCatalog::INFORMATION_SCHEMA_UPPERCASE, \"Memory\");\n \ndiff --git a/src/Processors/Transforms/WindowTransform.cpp b/src/Processors/Transforms/WindowTransform.cpp\nindex c64e817ffae3..98c21a341fdb 100644\n--- a/src/Processors/Transforms/WindowTransform.cpp\n+++ b/src/Processors/Transforms/WindowTransform.cpp\n@@ -1532,7 +1532,7 @@ namespace recurrent_detail\n {\n     template<typename T> T getValue(const WindowTransform * /*transform*/, size_t /*function_index*/, size_t /*column_index*/, RowNumber /*row*/)\n     {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"recurrent_detail::getValue() is not implemented for {} type\", typeid(T).name());\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"recurrent_detail::getValue is not implemented for {} type\", typeid(T).name());\n     }\n \n     template<> Float64 getValue<Float64>(const WindowTransform * transform, size_t function_index, size_t column_index, RowNumber row)\n@@ -1545,7 +1545,7 @@ namespace recurrent_detail\n     template<typename T> void setValueToOutputColumn(const WindowTransform * /*transform*/, size_t /*function_index*/, T /*value*/)\n     {\n         throw Exception(ErrorCodes::NOT_IMPLEMENTED,\n-                        \"recurrent_detail::setValueToOutputColumn() is not implemented for {} type\", typeid(T).name());\n+                        \"recurrent_detail::setValueToOutputColumn is not implemented for {} type\", typeid(T).name());\n     }\n \n     template<> void setValueToOutputColumn<Float64>(const WindowTransform * transform, size_t function_index, Float64 value)\ndiff --git a/src/Storages/ObjectStorageQueue/ObjectStorageQueueIFileMetadata.h b/src/Storages/ObjectStorageQueue/ObjectStorageQueueIFileMetadata.h\nindex a970e1422b60..28a97694f2c2 100644\n--- a/src/Storages/ObjectStorageQueue/ObjectStorageQueueIFileMetadata.h\n+++ b/src/Storages/ObjectStorageQueue/ObjectStorageQueueIFileMetadata.h\n@@ -132,7 +132,7 @@ class ObjectStorageQueueIFileMetadata\n \n     virtual SetProcessingResponseIndexes prepareProcessingRequestsImpl(Coordination::Requests &)\n     {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method prepareProcesingRequestsImpl() is not implemented\");\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method prepareProcesingRequestsImpl is not implemented\");\n     }\n     void prepareFailedRequestsImpl(Coordination::Requests & requests, bool retriable);\n \ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 9e427aed1367..9f956c43d98c 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -6650,7 +6650,7 @@ void StorageReplicatedMergeTree::alter(\n         if (auto txn = query_context->getZooKeeperMetadataTransaction())\n         {\n             /// It would be better to clone ops instead of moving, so we could retry on ZBADVERSION,\n-            /// but clone() is not implemented for Coordination::Request.\n+            /// but clone is not implemented for Coordination::Request.\n             txn->moveOpsTo(ops);\n             /// NOTE: IDatabase::alterTable(...) is called when executing ALTER_METADATA queue entry without query context,\n             /// so we have to update metadata of DatabaseReplicated here.\ndiff --git a/src/Storages/System/StorageSystemProjections.h b/src/Storages/System/StorageSystemProjections.h\nindex 46e73cec6cd3..c81ac22cd7cb 100644\n--- a/src/Storages/System/StorageSystemProjections.h\n+++ b/src/Storages/System/StorageSystemProjections.h\n@@ -12,7 +12,7 @@ class StorageSystemProjections : public IStorage\n public:\n     explicit StorageSystemProjections(const StorageID & table_id_);\n \n-    std::string getName() const override { return \"StorageSystemProjections\"; }\n+    std::string getName() const override { return \"SystemProjections\"; }\n \n     void read(\n         QueryPlan & query_plan,\n",
  "test_patch": "diff --git a/tests/integration/test_filesystem_layout/test.py b/tests/integration/test_filesystem_layout/test.py\nindex 02eb355e0326..e5775ba8a620 100644\n--- a/tests/integration/test_filesystem_layout/test.py\n+++ b/tests/integration/test_filesystem_layout/test.py\n@@ -139,35 +139,22 @@ def test_data_directory_symlinks(started_cluster):\n     s3_symlink = database_dir / \"s3\"\n     jbod_symlink = database_dir / \"jbod\"\n \n-    default_data = (\n-        clickhouse_dir / \"store\" / \"876\" / \"87654321-1000-4000-8000-000000000001\"\n-    )\n-    s3_data = (\n-        clickhouse_dir\n-        / \"disks\"\n-        / \"s3\"\n-        / \"store\"\n-        / \"876\"\n-        / \"87654321-1000-4000-8000-000000000002\"\n-    )\n-    jbod_data = Path(\"jbod1\") / \"store\" / \"876\" / \"87654321-1000-4000-8000-000000000003\"\n-\n     node.restart_clickhouse()\n \n     assert (\n         node.exec_in_container([\"bash\", \"-c\", f\"ls -l {default_symlink}\"])\n         .strip()\n-        .endswith(f\"{default_symlink} -> {default_data}\")\n+        .endswith(f\"{default_symlink} -> ../../store/876/87654321-1000-4000-8000-000000000001\")\n     )\n     assert (\n         node.exec_in_container([\"bash\", \"-c\", f\"ls -l {s3_symlink}\"])\n         .strip()\n-        .endswith(f\"{s3_symlink} -> {s3_data}\")\n+        .endswith(f\"{s3_symlink} -> ../../disks/s3/store/876/87654321-1000-4000-8000-000000000002\")\n     )\n     assert (\n         node.exec_in_container([\"bash\", \"-c\", f\"ls -l {jbod_symlink}\"])\n         .strip()\n-        .endswith(f\"{jbod_symlink} -> /{jbod_data}\")\n+        .endswith(f\"{jbod_symlink} -> ../../../../../jbod1/store/876/87654321-1000-4000-8000-000000000003\")\n     )\n \n     node.query(\"DROP TABLE test_symlinks.default SYNC\")\ndiff --git a/tests/queries/0_stateless/03271_clickhouse_local_persistency.reference b/tests/queries/0_stateless/03271_clickhouse_local_persistency.reference\nnew file mode 100644\nindex 000000000000..7abc1ea60b43\n--- /dev/null\n+++ b/tests/queries/0_stateless/03271_clickhouse_local_persistency.reference\n@@ -0,0 +1,35 @@\n+1\n+0\tHello0\n+1\tHello1\n+2\tHello2\n+3\tHello3\n+4\tHello4\n+5\tHello5\n+6\tHello6\n+7\tHello7\n+8\tHello8\n+9\tHello9\n+default\tOverlay\n+World0\n+World1\n+World2\n+World3\n+World4\n+World5\n+World6\n+World7\n+World8\n+World9\n+\n+World0\n+World1\n+World2\n+World3\n+World4\n+World5\n+World6\n+World7\n+World8\n+World9\n+Hello\n+World\ndiff --git a/tests/queries/0_stateless/03271_clickhouse_local_persistency.sh b/tests/queries/0_stateless/03271_clickhouse_local_persistency.sh\nnew file mode 100755\nindex 000000000000..71be0a13af2e\n--- /dev/null\n+++ b/tests/queries/0_stateless/03271_clickhouse_local_persistency.sh\n@@ -0,0 +1,37 @@\n+#!/usr/bin/env bash\n+\n+CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CUR_DIR\"/../shell_config.sh\n+\n+cd \"${CLICKHOUSE_TMP}\" || exit\n+rm -rf \"clickhouse.local\"\n+rm -f test\n+\n+# You can specify the path explicitly.\n+$CLICKHOUSE_LOCAL --path \"clickhouse.local\" --query \"SELECT 1\"\n+\n+# You can create tables.\n+$CLICKHOUSE_LOCAL --path \"clickhouse.local\" --query \"CREATE TABLE test (x UInt64, s String) ENGINE = MergeTree ORDER BY x\"\n+\n+# The data is persisted between restarts\n+$CLICKHOUSE_LOCAL --path \"clickhouse.local\" --query \"INSERT INTO test SELECT number, 'Hello' || number FROM numbers(10)\"\n+$CLICKHOUSE_LOCAL --path \"clickhouse.local\" --query \"SELECT * FROM test ORDER BY x\"\n+\n+# The default database is an Overlay on top of Atomic, which lets you exchange tables.\n+$CLICKHOUSE_LOCAL --path \"clickhouse.local\" --query \"SELECT name, engine FROM system.databases WHERE name = 'default'\"\n+$CLICKHOUSE_LOCAL --path \"clickhouse.local\" --query \"CREATE OR REPLACE TABLE test (s String) ENGINE = MergeTree ORDER BY ()\"\n+$CLICKHOUSE_LOCAL --path \"clickhouse.local\" --query \"SELECT * FROM test\"\n+$CLICKHOUSE_LOCAL --path \"clickhouse.local\" --query \"INSERT INTO test SELECT 'World' || number FROM numbers(10)\"\n+$CLICKHOUSE_LOCAL --path \"clickhouse.local\" --query \"SELECT * FROM test\"\n+\n+# It is an overlay database. If you don't have a table with the same name, it will look for a file with that name.\n+# Files are searched relative to the current working directory.\n+echo '\"Hello\"\n+\"World\"' > \"test\"\n+\n+echo\n+$CLICKHOUSE_LOCAL --path \"clickhouse.local\" --query \"SELECT * FROM test; DROP TABLE test; SELECT * FROM test;\"\n+\n+rm -rf \"clickhouse.local\"\n+rm test\ndiff --git a/tests/queries/0_stateless/03381_clickhouse_local_empty_default_database.reference b/tests/queries/0_stateless/03381_clickhouse_local_empty_default_database.reference\nindex 7018cf3dfa01..fdc00bed1e10 100644\n--- a/tests/queries/0_stateless/03381_clickhouse_local_empty_default_database.reference\n+++ b/tests/queries/0_stateless/03381_clickhouse_local_empty_default_database.reference\n@@ -1,2 +1,1 @@\n default_database cannot be empty. (BAD_ARGUMENTS)\n-default_database cannot be empty. (BAD_ARGUMENTS)\ndiff --git a/tests/queries/0_stateless/03381_clickhouse_local_empty_default_database.sh b/tests/queries/0_stateless/03381_clickhouse_local_empty_default_database.sh\nindex ea4d17d63509..b45948ce2e3f 100755\n--- a/tests/queries/0_stateless/03381_clickhouse_local_empty_default_database.sh\n+++ b/tests/queries/0_stateless/03381_clickhouse_local_empty_default_database.sh\n@@ -4,5 +4,4 @@ CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n . \"$CUR_DIR\"/../shell_config.sh\n \n-$CLICKHOUSE_LOCAL --database '' |& grep -o \"default_database cannot be empty. (BAD_ARGUMENTS)\"\n $CLICKHOUSE_LOCAL -- --default_database='' |& grep -o \"default_database cannot be empty. (BAD_ARGUMENTS)\"\n",
  "problem_statement": "Slightly better persistency in clickhouse-local\n\u2714\ufe0f 1. It should use Atomic database engine instead of Memory for the default database, so the metadata will be preserved across runs.\r\n\r\n\u2714\ufe0f 2. The default database should be named `default` instead of `_local`.\r\n\r\n\\3. It should use `./clickhouse.local` directory as the working directory instead of a random directory in `/tmp`\r\n\r\n\\4. Nevertheless, if the directory cannot be created, it should continue working.\r\n\r\n\u2714\ufe0f 5. Temporary tables for File IO should use the mechanism of the temporary tables.\r\n\r\n\u2714\ufe0f 6. Ideally, it should not create any directories if the queries are purely stateless like `SELECT 1`.\nHow to load the data stored in '_local' by ClickHouse-local on a previous run?\n\r\nI extracted the github archive files into a ClickHouse table using the instructions at https://ghe.clickhouse.tech/ using a custom '--path' attribute to make sure the files persisted. However, I closed that specific instance and have started a new instance of clickhouse-local and would like to load that table.\r\n\r\nWhen I run SHOW DATABASE I see the '_local' one in which my files are persisted, but when I run SHOW TABLES I dont see anything. How do I import those persisted files into a table?\n",
  "hints_text": "I use clickhouse-local all the time to test temporary things that I want to go away on exit (things like https://github.com/ClickHouse/ClickHouse/issues/50628#issuecomment-1578833490 for example). So it'd be great to keep the temporary behaviour as an option if possible (`clickhouse local --temp` / `clickhouse local --persist` ?)\r\n\r\nNo strong opinion about the other things\nOne idea for clickhouse-local:\r\n- use default database as default;\r\n- make it Atomic instead of Memory;\r\n- but avoid creating any files unless the first table is created;\r\n- when we create tables implicitly for the inputs, instead of normal tables, create them as temporary tables with an engine - in this way, we will avoid creating the database files in most cases.\r\n\r\nBonus: the support for EXCHANGE, CREATE OR REPLACE, etc.\nThis comment is implemented here: https://github.com/ClickHouse/ClickHouse/pull/65860\n`create database` / `use database`\r\n\r\n```sql\r\n$ clickhouse-local --path mydb\r\n\r\ncreate database A;\r\ncreate table A.A Engine =Log as select 1 a;\r\nexit;\r\n\r\n$ clickhouse-local --path mydb\r\n\r\nselect * from A.A;\r\n\u250c\u2500a\u2500\u2510\r\n\u2502 1 \u2502\r\n\u2514\u2500\u2500\u2500\u2518\r\n```\nWhen I run ```SELECT * from _local.<my_db_name>;``` it just says ```_local.<my_db_name>``` doesn't exist, even though the files are there.\nUnfortunately no way to persist ` _local` database. No such feature.\r\n\r\n@alexey-milovidov What do you think about the mode when clickhouse-local persists data for the default `_local` database? `clickhouse-local --path mydb`. I guess duckdb works like this?",
  "created_at": "2024-11-11T03:56:54Z"
}