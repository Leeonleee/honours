{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 71539,
  "instance_id": "ClickHouse__ClickHouse-71539",
  "issue_numbers": [
    "71408"
  ],
  "base_commit": "095f7ab591aa023d87f8f281f6d0226d1d447476",
  "patch": "diff --git a/src/Core/Settings.cpp b/src/Core/Settings.cpp\nindex f3ada33cb377..eaac7271ccef 100644\n--- a/src/Core/Settings.cpp\n+++ b/src/Core/Settings.cpp\n@@ -4557,7 +4557,7 @@ Possible values:\n - 0 - Disable\n - 1 - Enable\n )\", 0) \\\n-    DECLARE(Bool, query_plan_merge_filters, false, R\"(\n+    DECLARE(Bool, query_plan_merge_filters, true, R\"(\n Allow to merge filters in the query plan\n )\", 0) \\\n     DECLARE(Bool, query_plan_filter_push_down, true, R\"(\ndiff --git a/src/Core/SettingsChangesHistory.cpp b/src/Core/SettingsChangesHistory.cpp\nindex edf4e60706bd..8f01bacf254d 100644\n--- a/src/Core/SettingsChangesHistory.cpp\n+++ b/src/Core/SettingsChangesHistory.cpp\n@@ -75,6 +75,7 @@ static std::initializer_list<std::pair<ClickHouseVersion, SettingsChangesHistory\n             {\"backup_restore_keeper_max_retries_while_initializing\", 0, 20, \"New setting.\"},\n             {\"backup_restore_keeper_max_retries_while_handling_error\", 0, 20, \"New setting.\"},\n             {\"backup_restore_finish_timeout_after_error_sec\", 0, 180, \"New setting.\"},\n+            {\"query_plan_merge_filters\", false, true, \"Allow to merge filters in the query plan. This is required to properly support filter-push-down with a new analyzer.\"},\n             {\"parallel_replicas_local_plan\", false, true, \"Use local plan for local replica in a query with parallel replicas\"},\n         }\n     },\ndiff --git a/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp b/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp\nindex fb3ed7f80fc8..1832cc2ad429 100644\n--- a/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp\n+++ b/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp\n@@ -6,12 +6,23 @@\n namespace DB\n {\n \n+namespace Setting\n+{\n+    extern const SettingsBool query_plan_merge_filters;\n+}\n+\n BuildQueryPipelineSettings BuildQueryPipelineSettings::fromContext(ContextPtr from)\n {\n+    const auto & query_settings = from->getSettingsRef();\n     BuildQueryPipelineSettings settings;\n-    settings.actions_settings = ExpressionActionsSettings::fromSettings(from->getSettingsRef(), CompileExpressions::yes);\n+    settings.actions_settings = ExpressionActionsSettings::fromSettings(query_settings, CompileExpressions::yes);\n     settings.process_list_element = from->getProcessListElement();\n     settings.progress_callback = from->getProgressCallback();\n+\n+    /// Setting query_plan_merge_filters is enabled by default.\n+    /// But it can brake short-circuit without splitting filter step into smaller steps.\n+    /// So, enable and disable this optimizations together.\n+    settings.enable_multiple_filters_transforms_for_and_chain = query_settings[Setting::query_plan_merge_filters];\n     return settings;\n }\n \ndiff --git a/src/Processors/QueryPlan/BuildQueryPipelineSettings.h b/src/Processors/QueryPlan/BuildQueryPipelineSettings.h\nindex d99f9a7d1f12..6219e37db588 100644\n--- a/src/Processors/QueryPlan/BuildQueryPipelineSettings.h\n+++ b/src/Processors/QueryPlan/BuildQueryPipelineSettings.h\n@@ -17,6 +17,8 @@ using TemporaryFileLookupPtr = std::shared_ptr<ITemporaryFileLookup>;\n \n struct BuildQueryPipelineSettings\n {\n+    bool enable_multiple_filters_transforms_for_and_chain = true;\n+\n     ExpressionActionsSettings actions_settings;\n     QueryStatusPtr process_list_element;\n     ProgressCallback progress_callback = nullptr;\ndiff --git a/src/Processors/QueryPlan/FilterStep.cpp b/src/Processors/QueryPlan/FilterStep.cpp\nindex 862e03d74f20..af9e3f0c5155 100644\n--- a/src/Processors/QueryPlan/FilterStep.cpp\n+++ b/src/Processors/QueryPlan/FilterStep.cpp\n@@ -5,6 +5,11 @@\n #include <Interpreters/ExpressionActions.h>\n #include <IO/Operators.h>\n #include <Common/JSONBuilder.h>\n+#include <DataTypes/DataTypeLowCardinality.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <Functions/IFunction.h>\n+#include <stack>\n+#include <ranges>\n \n namespace DB\n {\n@@ -24,6 +29,92 @@ static ITransformingStep::Traits getTraits()\n     };\n }\n \n+static bool isTrivialSubtree(const ActionsDAG::Node * node)\n+{\n+    while (node->type == ActionsDAG::ActionType::ALIAS)\n+        node = node->children.at(0);\n+\n+    return node->type != ActionsDAG::ActionType::FUNCTION && node->type != ActionsDAG::ActionType::ARRAY_JOIN;\n+}\n+\n+struct ActionsAndName\n+{\n+    ActionsDAG dag;\n+    std::string name;\n+};\n+\n+static ActionsAndName splitSingleAndFilter(ActionsDAG & dag, const ActionsDAG::Node * filter_node)\n+{\n+    auto split_result = dag.split({filter_node}, true);\n+    dag = std::move(split_result.second);\n+\n+    const auto * split_filter_node = split_result.split_nodes_mapping[filter_node];\n+    auto filter_type = removeLowCardinality(split_filter_node->result_type);\n+    if (!filter_type->onlyNull() && !isUInt8(removeNullable(filter_type)))\n+    {\n+        DataTypePtr cast_type = std::make_shared<DataTypeUInt8>();\n+        if (filter_type->isNullable())\n+            cast_type = std::make_shared<DataTypeNullable>(std::move(cast_type));\n+\n+        split_filter_node = &split_result.first.addCast(*split_filter_node, cast_type, {});\n+    }\n+\n+    split_result.first.getOutputs().emplace(split_result.first.getOutputs().begin(), split_filter_node);\n+    auto name = split_filter_node->result_name;\n+    return ActionsAndName{std::move(split_result.first), std::move(name)};\n+}\n+\n+/// Try to split the left most AND atom to a separate DAG.\n+static std::optional<ActionsAndName> trySplitSingleAndFilter(ActionsDAG & dag, const std::string & filter_name)\n+{\n+    const auto * filter = &dag.findInOutputs(filter_name);\n+    while (filter->type == ActionsDAG::ActionType::ALIAS)\n+        filter = filter->children.at(0);\n+\n+    if (filter->type != ActionsDAG::ActionType::FUNCTION || filter->function_base->getName() != \"and\")\n+        return {};\n+\n+    const ActionsDAG::Node * condition_to_split = nullptr;\n+    std::stack<const ActionsDAG::Node *> nodes;\n+    nodes.push(filter);\n+    while (!nodes.empty())\n+    {\n+        const auto * node = nodes.top();\n+        nodes.pop();\n+\n+        if (node->type == ActionsDAG::ActionType::FUNCTION && node->function_base->getName() == \"and\")\n+        {\n+            /// The order is important. We should take the left-most atom, so put conditions on stack in reverse order.\n+            for (const auto * child : node->children | std::ranges::views::reverse)\n+                nodes.push(child);\n+\n+            continue;\n+        }\n+\n+        if (isTrivialSubtree(node))\n+            continue;\n+\n+        /// Do not split subtree if it's the last non-trivial one.\n+        /// So, split the first found condition only when there is a another one found.\n+        if (condition_to_split)\n+            return splitSingleAndFilter(dag, condition_to_split);\n+\n+        condition_to_split = node;\n+    }\n+\n+    return {};\n+}\n+\n+std::vector<ActionsAndName> splitAndChainIntoMultipleFilters(ActionsDAG & dag, const std::string & filter_name)\n+{\n+    std::vector<ActionsAndName> res;\n+\n+    while (auto condition = trySplitSingleAndFilter(dag, filter_name))\n+        res.push_back(std::move(*condition));\n+\n+    return res;\n+}\n+\n FilterStep::FilterStep(\n     const Header & input_header_,\n     ActionsDAG actions_dag_,\n@@ -50,6 +141,23 @@ FilterStep::FilterStep(\n \n void FilterStep::transformPipeline(QueryPipelineBuilder & pipeline, const BuildQueryPipelineSettings & settings)\n {\n+    std::vector<ActionsAndName> and_atoms;\n+\n+    /// Splitting AND filter condition to steps under the setting, which is enabled with merge_filters optimization.\n+    /// This is needed to support short-circuit properly.\n+    if (settings.enable_multiple_filters_transforms_for_and_chain && !actions_dag.hasStatefulFunctions())\n+        and_atoms = splitAndChainIntoMultipleFilters(actions_dag, filter_column_name);\n+\n+    for (auto & and_atom : and_atoms)\n+    {\n+        auto expression = std::make_shared<ExpressionActions>(std::move(and_atom.dag), settings.getActionsSettings());\n+        pipeline.addSimpleTransform([&](const Block & header, QueryPipelineBuilder::StreamType stream_type)\n+        {\n+            bool on_totals = stream_type == QueryPipelineBuilder::StreamType::Totals;\n+            return std::make_shared<FilterTransform>(header, expression, and_atom.name, true, on_totals);\n+        });\n+    }\n+\n     auto expression = std::make_shared<ExpressionActions>(std::move(actions_dag), settings.getActionsSettings());\n \n     pipeline.addSimpleTransform([&](const Block & header, QueryPipelineBuilder::StreamType stream_type)\n@@ -76,18 +184,45 @@ void FilterStep::transformPipeline(QueryPipelineBuilder & pipeline, const BuildQ\n void FilterStep::describeActions(FormatSettings & settings) const\n {\n     String prefix(settings.offset, settings.indent_char);\n+\n+    auto cloned_dag = actions_dag.clone();\n+\n+    std::vector<ActionsAndName> and_atoms;\n+    if (!actions_dag.hasStatefulFunctions())\n+        and_atoms = splitAndChainIntoMultipleFilters(cloned_dag, filter_column_name);\n+\n+    for (auto & and_atom : and_atoms)\n+    {\n+        auto expression = std::make_shared<ExpressionActions>(std::move(and_atom.dag));\n+        settings.out << prefix << \"AND column: \" << and_atom.name << '\\n';\n+        expression->describeActions(settings.out, prefix);\n+    }\n+\n     settings.out << prefix << \"Filter column: \" << filter_column_name;\n \n     if (remove_filter_column)\n         settings.out << \" (removed)\";\n     settings.out << '\\n';\n \n-    auto expression = std::make_shared<ExpressionActions>(actions_dag.clone());\n+    auto expression = std::make_shared<ExpressionActions>(std::move(cloned_dag));\n     expression->describeActions(settings.out, prefix);\n }\n \n void FilterStep::describeActions(JSONBuilder::JSONMap & map) const\n {\n+    auto cloned_dag = actions_dag.clone();\n+\n+    std::vector<ActionsAndName> and_atoms;\n+    if (!actions_dag.hasStatefulFunctions())\n+        and_atoms = splitAndChainIntoMultipleFilters(cloned_dag, filter_column_name);\n+\n+    for (auto & and_atom : and_atoms)\n+    {\n+        auto expression = std::make_shared<ExpressionActions>(std::move(and_atom.dag));\n+        map.add(\"AND column\", and_atom.name);\n+        map.add(\"Expression\", expression->toTree());\n+    }\n+\n     map.add(\"Filter Column\", filter_column_name);\n     map.add(\"Removes Filter\", remove_filter_column);\n \ndiff --git a/src/Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h b/src/Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h\nindex 6232fc7f54f0..55a9d18f063e 100644\n--- a/src/Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h\n+++ b/src/Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h\n@@ -32,7 +32,7 @@ struct QueryPlanOptimizationSettings\n     bool merge_expressions = true;\n \n     /// If merge-filters optimization is enabled.\n-    bool merge_filters = false;\n+    bool merge_filters = true;\n \n     /// If filter push down optimization is enabled.\n     bool filter_push_down = true;\ndiff --git a/src/Processors/QueryPlan/ReadFromMergeTree.cpp b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\nindex 3186df6a6b3e..6a9ca93fd853 100644\n--- a/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n+++ b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n@@ -175,6 +175,7 @@ namespace Setting\n     extern const SettingsBool use_skip_indexes;\n     extern const SettingsBool use_skip_indexes_if_final;\n     extern const SettingsBool use_uncompressed_cache;\n+    extern const SettingsBool query_plan_merge_filters;\n     extern const SettingsUInt64 merge_tree_min_read_task_size;\n }\n \n@@ -206,6 +207,7 @@ static MergeTreeReaderSettings getMergeTreeReaderSettings(\n         .use_asynchronous_read_from_pool = settings[Setting::allow_asynchronous_read_from_io_pool_for_merge_tree]\n             && (settings[Setting::max_streams_to_max_threads_ratio] > 1 || settings[Setting::max_streams_for_merge_tree_reading] > 1),\n         .enable_multiple_prewhere_read_steps = settings[Setting::enable_multiple_prewhere_read_steps],\n+        .force_short_circuit_execution = settings[Setting::query_plan_merge_filters]\n     };\n }\n \ndiff --git a/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp b/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\nindex 7ba358d2d352..4a7e02a7a519 100644\n--- a/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\n+++ b/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\n@@ -330,7 +330,7 @@ MergeTreeReadTaskColumns getReadTaskColumns(\n         auto prewhere_actions = MergeTreeSelectProcessor::getPrewhereActions(\n             prewhere_info,\n             actions_settings,\n-            reader_settings.enable_multiple_prewhere_read_steps);\n+            reader_settings.enable_multiple_prewhere_read_steps, reader_settings.force_short_circuit_execution);\n \n         for (const auto & step : prewhere_actions.steps)\n             add_step(*step);\ndiff --git a/src/Storages/MergeTree/MergeTreeIOSettings.h b/src/Storages/MergeTree/MergeTreeIOSettings.h\nindex 4d1d25337295..7506c726bc4f 100644\n--- a/src/Storages/MergeTree/MergeTreeIOSettings.h\n+++ b/src/Storages/MergeTree/MergeTreeIOSettings.h\n@@ -45,6 +45,8 @@ struct MergeTreeReaderSettings\n     bool use_asynchronous_read_from_pool = false;\n     /// If PREWHERE has multiple conditions combined with AND, execute them in separate read/filtering steps.\n     bool enable_multiple_prewhere_read_steps = false;\n+    /// In case of multiple prewhere steps, execute filtering earlier to support short-circuit properly.\n+    bool force_short_circuit_execution = false;\n     /// If true, try to lower size of read buffer according to granule size and compressed block size.\n     bool adjust_read_buffer_size = true;\n     /// If true, it's allowed to read the whole part without reading marks.\ndiff --git a/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp\nindex 5efd33ce09a5..242f9c6504fa 100644\n--- a/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp\n@@ -91,7 +91,7 @@ MergeTreeSelectProcessor::MergeTreeSelectProcessor(\n     , algorithm(std::move(algorithm_))\n     , prewhere_info(prewhere_info_)\n     , actions_settings(actions_settings_)\n-    , prewhere_actions(getPrewhereActions(prewhere_info, actions_settings, reader_settings_.enable_multiple_prewhere_read_steps))\n+    , prewhere_actions(getPrewhereActions(prewhere_info, actions_settings, reader_settings_.enable_multiple_prewhere_read_steps, reader_settings_.force_short_circuit_execution))\n     , reader_settings(reader_settings_)\n     , result_header(transformHeader(pool->getHeader(), prewhere_info))\n {\n@@ -124,9 +124,9 @@ String MergeTreeSelectProcessor::getName() const\n     return fmt::format(\"MergeTreeSelect(pool: {}, algorithm: {})\", pool->getName(), algorithm->getName());\n }\n \n-bool tryBuildPrewhereSteps(PrewhereInfoPtr prewhere_info, const ExpressionActionsSettings & actions_settings, PrewhereExprInfo & prewhere);\n+bool tryBuildPrewhereSteps(PrewhereInfoPtr prewhere_info, const ExpressionActionsSettings & actions_settings, PrewhereExprInfo & prewhere, bool force_short_circuit_execution);\n \n-PrewhereExprInfo MergeTreeSelectProcessor::getPrewhereActions(PrewhereInfoPtr prewhere_info, const ExpressionActionsSettings & actions_settings, bool enable_multiple_prewhere_read_steps)\n+PrewhereExprInfo MergeTreeSelectProcessor::getPrewhereActions(PrewhereInfoPtr prewhere_info, const ExpressionActionsSettings & actions_settings, bool enable_multiple_prewhere_read_steps, bool force_short_circuit_execution)\n {\n     PrewhereExprInfo prewhere_actions;\n     if (prewhere_info)\n@@ -147,7 +147,7 @@ PrewhereExprInfo MergeTreeSelectProcessor::getPrewhereActions(PrewhereInfoPtr pr\n         }\n \n         if (!enable_multiple_prewhere_read_steps ||\n-            !tryBuildPrewhereSteps(prewhere_info, actions_settings, prewhere_actions))\n+            !tryBuildPrewhereSteps(prewhere_info, actions_settings, prewhere_actions, force_short_circuit_execution))\n         {\n             PrewhereExprStep prewhere_step\n             {\ndiff --git a/src/Storages/MergeTree/MergeTreeSelectProcessor.h b/src/Storages/MergeTree/MergeTreeSelectProcessor.h\nindex 33069a78e331..32a761cefb7a 100644\n--- a/src/Storages/MergeTree/MergeTreeSelectProcessor.h\n+++ b/src/Storages/MergeTree/MergeTreeSelectProcessor.h\n@@ -73,7 +73,8 @@ class MergeTreeSelectProcessor : private boost::noncopyable\n     static PrewhereExprInfo getPrewhereActions(\n         PrewhereInfoPtr prewhere_info,\n         const ExpressionActionsSettings & actions_settings,\n-        bool enable_multiple_prewhere_read_steps);\n+        bool enable_multiple_prewhere_read_steps,\n+        bool force_short_circuit_execution);\n \n     void addPartLevelToChunk(bool add_part_level_) { add_part_level = add_part_level_; }\n \ndiff --git a/src/Storages/MergeTree/MergeTreeSplitPrewhereIntoReadSteps.cpp b/src/Storages/MergeTree/MergeTreeSplitPrewhereIntoReadSteps.cpp\nindex 9c82817e8cb6..1cc4006a285c 100644\n--- a/src/Storages/MergeTree/MergeTreeSplitPrewhereIntoReadSteps.cpp\n+++ b/src/Storages/MergeTree/MergeTreeSplitPrewhereIntoReadSteps.cpp\n@@ -4,6 +4,7 @@\n #include <Storages/SelectQueryInfo.h>\n #include <Storages/MergeTree/MergeTreeRangeReader.h>\n #include <DataTypes/DataTypeString.h>\n+#include <DataTypes/DataTypeLowCardinality.h>\n #include <Interpreters/ExpressionActions.h>\n \n \n@@ -57,9 +58,9 @@ struct DAGNodeRef\n     const ActionsDAG::Node * node;\n };\n \n-/// Result name -> DAGNodeRef\n-using OriginalToNewNodeMap = std::unordered_map<String, DAGNodeRef>;\n-using NodeNameToLastUsedStepMap = std::unordered_map<String, size_t>;\n+/// ResultNode -> DAGNodeRef\n+using OriginalToNewNodeMap = std::unordered_map<const ActionsDAG::Node *, DAGNodeRef>;\n+using NodeNameToLastUsedStepMap = std::unordered_map<const ActionsDAG::Node *, size_t>;\n \n /// Clones the part of original DAG responsible for computing the original_dag_node and adds it to the new DAG.\n const ActionsDAG::Node & addClonedDAGToDAG(\n@@ -69,25 +70,28 @@ const ActionsDAG::Node & addClonedDAGToDAG(\n     OriginalToNewNodeMap & node_remap,\n     NodeNameToLastUsedStepMap & node_to_step_map)\n {\n-    const String & node_name = original_dag_node->result_name;\n     /// Look for the node in the map of already known nodes\n-    if (node_remap.contains(node_name))\n+    if (node_remap.contains(original_dag_node))\n     {\n         /// If the node is already in the new DAG, return it\n-        const auto & node_ref = node_remap.at(node_name);\n+        const auto & node_ref = node_remap.at(original_dag_node);\n         if (node_ref.dag == new_dag.get())\n             return *node_ref.node;\n \n         /// If the node is known from the previous steps, add it as an input, except for constants\n         if (original_dag_node->type != ActionsDAG::ActionType::COLUMN)\n         {\n-            node_ref.dag->addOrReplaceInOutputs(*node_ref.node);\n+            /// If the node was found in node_remap, it was not added to outputs yet.\n+            /// The only exception is the filter node, which is always the first one.\n+            if (node_ref.dag->getOutputs().at(0) != node_ref.node)\n+                node_ref.dag->getOutputs().push_back(node_ref.node);\n+\n             const auto & new_node = new_dag->addInput(node_ref.node->result_name, node_ref.node->result_type);\n-            node_remap[node_name] = {new_dag.get(), &new_node}; /// TODO: here we update the node reference. Is it always correct?\n+            node_remap[original_dag_node] = {new_dag.get(), &new_node};\n \n             /// Remember the index of the last step which reuses this node.\n             /// We cannot remove this node from the outputs before that step.\n-            node_to_step_map[node_name] = step;\n+            node_to_step_map[original_dag_node] = step;\n             return new_node;\n         }\n     }\n@@ -96,7 +100,7 @@ const ActionsDAG::Node & addClonedDAGToDAG(\n     if (original_dag_node->type == ActionsDAG::ActionType::INPUT)\n     {\n         const auto & new_node = new_dag->addInput(original_dag_node->result_name, original_dag_node->result_type);\n-        node_remap[node_name] = {new_dag.get(), &new_node};\n+        node_remap[original_dag_node] = {new_dag.get(), &new_node};\n         return new_node;\n     }\n \n@@ -105,7 +109,7 @@ const ActionsDAG::Node & addClonedDAGToDAG(\n     {\n         const auto & new_node = new_dag->addColumn(\n             ColumnWithTypeAndName(original_dag_node->column, original_dag_node->result_type, original_dag_node->result_name));\n-        node_remap[node_name] = {new_dag.get(), &new_node};\n+        node_remap[original_dag_node] = {new_dag.get(), &new_node};\n         return new_node;\n     }\n \n@@ -113,7 +117,7 @@ const ActionsDAG::Node & addClonedDAGToDAG(\n     {\n         const auto & alias_child = addClonedDAGToDAG(step, original_dag_node->children[0], new_dag, node_remap, node_to_step_map);\n         const auto & new_node = new_dag->addAlias(alias_child, original_dag_node->result_name);\n-        node_remap[node_name] = {new_dag.get(), &new_node};\n+        node_remap[original_dag_node] = {new_dag.get(), &new_node};\n         return new_node;\n     }\n \n@@ -128,7 +132,7 @@ const ActionsDAG::Node & addClonedDAGToDAG(\n         }\n \n         const auto & new_node = new_dag->addFunction(original_dag_node->function_base, new_children, original_dag_node->result_name);\n-        node_remap[node_name] = {new_dag.get(), &new_node};\n+        node_remap[original_dag_node] = {new_dag.get(), &new_node};\n         return new_node;\n     }\n \n@@ -138,11 +142,9 @@ const ActionsDAG::Node & addClonedDAGToDAG(\n const ActionsDAG::Node & addFunction(\n         const ActionsDAGPtr & new_dag,\n         const FunctionOverloadResolverPtr & function,\n-        ActionsDAG::NodeRawConstPtrs children,\n-        OriginalToNewNodeMap & node_remap)\n+        ActionsDAG::NodeRawConstPtrs children)\n {\n     const auto & new_node = new_dag->addFunction(function, children, \"\");\n-    node_remap[new_node.result_name] = {new_dag.get(), &new_node};\n     return new_node;\n }\n \n@@ -152,14 +154,12 @@ const ActionsDAG::Node & addFunction(\n const ActionsDAG::Node & addCast(\n         const ActionsDAGPtr & dag,\n         const ActionsDAG::Node & node_to_cast,\n-        const DataTypePtr & to_type,\n-        OriginalToNewNodeMap & node_remap)\n+        const DataTypePtr & to_type)\n {\n     if (!node_to_cast.result_type->equals(*to_type))\n         return node_to_cast;\n \n     const auto & new_node = dag->addCast(node_to_cast, to_type, {});\n-    node_remap[new_node.result_name] = {dag.get(), &new_node};\n     return new_node;\n }\n \n@@ -169,8 +169,7 @@ const ActionsDAG::Node & addCast(\n /// 2. makes sure that the result contains only 0 or 1 values even if the source column contains non-boolean values.\n const ActionsDAG::Node & addAndTrue(\n     const ActionsDAGPtr & dag,\n-    const ActionsDAG::Node & filter_node_to_normalize,\n-    OriginalToNewNodeMap & node_remap)\n+    const ActionsDAG::Node & filter_node_to_normalize)\n {\n     Field const_true_value(true);\n \n@@ -181,7 +180,7 @@ const ActionsDAG::Node & addAndTrue(\n     const auto * const_true_node = &dag->addColumn(std::move(const_true_column));\n     ActionsDAG::NodeRawConstPtrs children = {&filter_node_to_normalize, const_true_node};\n     FunctionOverloadResolverPtr func_builder_and = std::make_unique<FunctionToOverloadResolverAdaptor>(std::make_shared<FunctionAnd>());\n-    return addFunction(dag, func_builder_and, children, node_remap);\n+    return addFunction(dag, func_builder_and, children);\n }\n \n }\n@@ -206,7 +205,11 @@ const ActionsDAG::Node & addAndTrue(\n /// 6. Find all outputs of the original DAG\n /// 7. Find all outputs that were computed in the already built DAGs, mark these nodes as outputs in the steps where they were computed\n /// 8. Add computation of the remaining outputs to the last step with the procedure similar to 4\n-bool tryBuildPrewhereSteps(PrewhereInfoPtr prewhere_info, const ExpressionActionsSettings & actions_settings, PrewhereExprInfo & prewhere)\n+bool tryBuildPrewhereSteps(\n+    PrewhereInfoPtr prewhere_info,\n+    const ExpressionActionsSettings & actions_settings,\n+    PrewhereExprInfo & prewhere,\n+    bool force_short_circuit_execution)\n {\n     if (!prewhere_info)\n         return true;\n@@ -243,7 +246,10 @@ bool tryBuildPrewhereSteps(PrewhereInfoPtr prewhere_info, const ExpressionAction\n     struct Step\n     {\n         ActionsDAGPtr actions;\n-        String column_name;\n+        /// Original condition, in case if we have only one condition, and it was not casted\n+        const ActionsDAG::Node * original_node;\n+        /// Result condition node\n+        const ActionsDAG::Node * result_node;\n     };\n     std::vector<Step> steps;\n \n@@ -254,7 +260,8 @@ bool tryBuildPrewhereSteps(PrewhereInfoPtr prewhere_info, const ExpressionAction\n     {\n         const auto & condition_group = condition_groups[step_index];\n         ActionsDAGPtr step_dag = std::make_unique<ActionsDAG>();\n-        String result_name;\n+        const ActionsDAG::Node * original_node = nullptr;\n+         const ActionsDAG::Node * result_node;\n \n         std::vector<const ActionsDAG::Node *> new_condition_nodes;\n         for (const auto * node : condition_group)\n@@ -267,48 +274,37 @@ bool tryBuildPrewhereSteps(PrewhereInfoPtr prewhere_info, const ExpressionAction\n         {\n             /// Add AND function to combine the conditions\n             FunctionOverloadResolverPtr func_builder_and = std::make_unique<FunctionToOverloadResolverAdaptor>(std::make_shared<FunctionAnd>());\n-            const auto & and_function_node = addFunction(step_dag, func_builder_and, new_condition_nodes, node_remap);\n-            step_dag->addOrReplaceInOutputs(and_function_node);\n-            result_name = and_function_node.result_name;\n+            const auto & and_function_node = addFunction(step_dag, func_builder_and, new_condition_nodes);\n+            result_node = &and_function_node;\n         }\n         else\n         {\n-            const auto & result_node = *new_condition_nodes.front();\n+            result_node = new_condition_nodes.front();\n             /// Check if explicit cast is needed for the condition to serve as a filter.\n-            const auto result_type_name = result_node.result_type->getName();\n-            if (result_type_name == \"UInt8\" ||\n-                result_type_name == \"Nullable(UInt8)\" ||\n-                result_type_name == \"LowCardinality(UInt8)\" ||\n-                result_type_name == \"LowCardinality(Nullable(UInt8))\")\n-            {\n-                /// No need to cast\n-                step_dag->addOrReplaceInOutputs(result_node);\n-                result_name = result_node.result_name;\n-            }\n-            else\n+            if (!isUInt8(removeNullable(removeLowCardinality(result_node->result_type))))\n             {\n                 /// Build \"condition AND True\" expression to \"cast\" the condition to UInt8 or Nullable(UInt8) depending on its type.\n-                const auto & cast_node = addAndTrue(step_dag, result_node, node_remap);\n-                step_dag->addOrReplaceInOutputs(cast_node);\n-                result_name = cast_node.result_name;\n+                result_node = &addAndTrue(step_dag, *result_node);\n             }\n         }\n \n-        steps.push_back({std::move(step_dag), result_name});\n+        step_dag->getOutputs().insert(step_dag->getOutputs().begin(), result_node);\n+        steps.push_back({std::move(step_dag), original_node, result_node});\n     }\n \n     /// 6. Find all outputs of the original DAG\n     auto original_outputs = prewhere_info->prewhere_actions.getOutputs();\n+    steps.back().actions->getOutputs().clear();\n     /// 7. Find all outputs that were computed in the already built DAGs, mark these nodes as outputs in the steps where they were computed\n     /// 8. Add computation of the remaining outputs to the last step with the procedure similar to 4\n-    NameSet all_output_names;\n+    std::unordered_set<const ActionsDAG::Node *> all_outputs;\n     for (const auto * output : original_outputs)\n     {\n-        all_output_names.insert(output->result_name);\n-        if (node_remap.contains(output->result_name))\n+        all_outputs.insert(output);\n+        if (node_remap.contains(output))\n         {\n-            const auto & new_node_info = node_remap[output->result_name];\n-            new_node_info.dag->addOrReplaceInOutputs(*new_node_info.node);\n+            const auto & new_node_info = node_remap[output];\n+            new_node_info.dag->getOutputs().push_back(new_node_info.node);\n         }\n         else if (output->result_name == prewhere_info->prewhere_column_name)\n         {\n@@ -319,20 +315,21 @@ bool tryBuildPrewhereSteps(PrewhereInfoPtr prewhere_info, const ExpressionAction\n             /// 1. AND the last condition with constant True. This is needed to make sure that in the last step filter has UInt8 type\n             ///    but contains values other than 0 and 1 (e.g. if it is (number%5) it contains 2,3,4)\n             /// 2. CAST the result to the exact type of the PREWHERE column from the original DAG\n-            const auto & last_step_result_node_info = node_remap[steps.back().column_name];\n             auto & last_step_dag = steps.back().actions;\n+            auto & last_step_result_node = steps.back().result_node;\n             /// Build AND(last_step_result_node, true)\n-            const auto & and_node = addAndTrue(last_step_dag, *last_step_result_node_info.node, node_remap);\n+            const auto & and_node = addAndTrue(last_step_dag, *last_step_result_node);\n             /// Build CAST(and_node, type of PREWHERE column)\n-            const auto & cast_node = addCast(last_step_dag, and_node, output->result_type, node_remap);\n+            const auto & cast_node = addCast(last_step_dag, and_node, output->result_type);\n             /// Add alias for the result with the name of the PREWHERE column\n             const auto & prewhere_result_node = last_step_dag->addAlias(cast_node, output->result_name);\n-            last_step_dag->addOrReplaceInOutputs(prewhere_result_node);\n+            last_step_dag->getOutputs().push_back(&prewhere_result_node);\n+            steps.back().result_node = &prewhere_result_node;\n         }\n         else\n         {\n             const auto & node_in_new_dag = addClonedDAGToDAG(steps.size() - 1, output, steps.back().actions, node_remap, node_to_step);\n-            steps.back().actions->addOrReplaceInOutputs(node_in_new_dag);\n+            steps.back().actions->getOutputs().push_back(&node_in_new_dag);\n         }\n     }\n \n@@ -345,17 +342,18 @@ bool tryBuildPrewhereSteps(PrewhereInfoPtr prewhere_info, const ExpressionAction\n             {\n                 .type = PrewhereExprStep::Filter,\n                 .actions = std::make_shared<ExpressionActions>(std::move(*step.actions), actions_settings),\n-                .filter_column_name = step.column_name,\n+                .filter_column_name = step.result_node->result_name,\n                 /// Don't remove if it's in the list of original outputs\n                 .remove_filter_column =\n-                    !all_output_names.contains(step.column_name) && node_to_step[step.column_name] <= step_index,\n-                .need_filter = false,\n+                    step.original_node && !all_outputs.contains(step.original_node) && node_to_step[step.original_node] <= step_index,\n+                .need_filter = force_short_circuit_execution,\n                 .perform_alter_conversions = true,\n             };\n \n             prewhere.steps.push_back(std::make_shared<PrewhereExprStep>(std::move(new_step)));\n         }\n \n+        prewhere.steps.back()->remove_filter_column = prewhere_info->remove_prewhere_column;\n         prewhere.steps.back()->need_filter = prewhere_info->need_filter;\n     }\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01655_plan_optimizations.reference b/tests/queries/0_stateless/01655_plan_optimizations.reference\nindex edf93b4b39f7..7fc7556e85b0 100644\n--- a/tests/queries/0_stateless/01655_plan_optimizations.reference\n+++ b/tests/queries/0_stateless/01655_plan_optimizations.reference\n@@ -82,12 +82,12 @@ Filter column: notEquals(__table1.y, 0_UInt8)\n 9\t10\n > one condition of filter should be pushed down after aggregating, other two conditions are ANDed\n Filter column\n-FUNCTION and(minus(s, 8) :: 5, minus(s, 4) :: 2) -> and(notEquals(y, 0), minus(s, 8), minus(s, 4))\n+FUNCTION and(minus(s, 8) :: 3, minus(s, 4) :: 5) -> and(notEquals(y, 0), minus(s, 8), minus(s, 4))\n Aggregating\n Filter column: notEquals(y, 0)\n > (analyzer) one condition of filter should be pushed down after aggregating, other two conditions are ANDed\n Filter column\n-FUNCTION and(minus(__table1.s, 8_UInt8) :: 1, minus(__table1.s, 4_UInt8) :: 2) -> and(notEquals(__table1.y, 0_UInt8), minus(__table1.s, 8_UInt8), minus(__table1.s, 4_UInt8))\n+FUNCTION and(minus(__table1.s, 8_UInt8) :: 3, minus(__table1.s, 4_UInt8) :: 5) -> and(notEquals(__table1.y, 0_UInt8), minus(__table1.s, 8_UInt8), minus(__table1.s, 4_UInt8))\n Aggregating\n Filter column: notEquals(__table1.y, 0_UInt8)\n 0\t1\n@@ -163,7 +163,6 @@ Filter column: notEquals(__table1.y, 2_UInt8)\n > filter is pushed down before CreatingSets\n CreatingSets\n Filter\n-Filter\n 1\n 3\n > one condition of filter is pushed down before LEFT JOIN\ndiff --git a/tests/queries/0_stateless/01655_plan_optimizations.sh b/tests/queries/0_stateless/01655_plan_optimizations.sh\nindex 42cdac8c01fa..04ab9bbd11ca 100755\n--- a/tests/queries/0_stateless/01655_plan_optimizations.sh\n+++ b/tests/queries/0_stateless/01655_plan_optimizations.sh\n@@ -89,14 +89,14 @@ $CLICKHOUSE_CLIENT --enable_analyzer=0 --convert_query_to_cnf=0 -q \"\n         select sum(x) as s, y from (select number as x, number + 1 as y from numbers(10)) group by y\n     ) where y != 0 and s - 8 and s - 4\n     settings enable_optimize_predicate_expression=0\" |\n-    grep -o \"Aggregating\\|Filter column\\|Filter column: notEquals(y, 0)\\|FUNCTION and(minus(s, 8) :: 5, minus(s, 4) :: 2) -> and(notEquals(y, 0), minus(s, 8), minus(s, 4))\"\n+    grep -o \"Aggregating\\|Filter column\\|Filter column: notEquals(y, 0)\\|FUNCTION and(minus(s, 8) :: 3, minus(s, 4) :: 5) -> and(notEquals(y, 0), minus(s, 8), minus(s, 4))\"\n echo \"> (analyzer) one condition of filter should be pushed down after aggregating, other two conditions are ANDed\"\n $CLICKHOUSE_CLIENT --enable_analyzer=1 --convert_query_to_cnf=0 -q \"\n     explain actions = 1 select s, y from (\n         select sum(x) as s, y from (select number as x, number + 1 as y from numbers(10)) group by y\n     ) where y != 0 and s - 8 and s - 4\n     settings enable_optimize_predicate_expression=0\" |\n-        grep -o \"Aggregating\\|Filter column\\|Filter column: notEquals(__table1.y, 0_UInt8)\\|FUNCTION and(minus(__table1.s, 8_UInt8) :: 1, minus(__table1.s, 4_UInt8) :: 2) -> and(notEquals(__table1.y, 0_UInt8), minus(__table1.s, 8_UInt8), minus(__table1.s, 4_UInt8))\"\n+        grep -o \"Aggregating\\|Filter column\\|Filter column: notEquals(__table1.y, 0_UInt8)\\|FUNCTION and(minus(__table1.s, 8_UInt8) :: 3, minus(__table1.s, 4_UInt8) :: 5) -> and(notEquals(__table1.y, 0_UInt8), minus(__table1.s, 8_UInt8), minus(__table1.s, 4_UInt8))\"\n $CLICKHOUSE_CLIENT -q \"\n     select s, y from (\n         select sum(x) as s, y from (select number as x, number + 1 as y from numbers(10)) group by y\ndiff --git a/tests/queries/0_stateless/02496_remove_redundant_sorting.reference b/tests/queries/0_stateless/02496_remove_redundant_sorting.reference\nindex 7824fd8cba9e..00db41e8ac57 100644\n--- a/tests/queries/0_stateless/02496_remove_redundant_sorting.reference\n+++ b/tests/queries/0_stateless/02496_remove_redundant_sorting.reference\n@@ -332,13 +332,12 @@ SETTINGS optimize_aggregators_of_group_by_keys=0 -- avoid removing any() as it d\n Expression (Projection)\n   Sorting (Sorting for ORDER BY)\n     Expression (Before ORDER BY)\n-      Filter ((WHERE + (Projection + Before ORDER BY)))\n-        Filter (HAVING)\n-          Aggregating\n-            Expression ((Before GROUP BY + Projection))\n-              Sorting (Sorting for ORDER BY)\n-                Expression ((Before ORDER BY + (Projection + Before ORDER BY)))\n-                  ReadFromSystemNumbers\n+      Filter (((WHERE + (Projection + Before ORDER BY)) + HAVING))\n+        Aggregating\n+          Expression ((Before GROUP BY + Projection))\n+            Sorting (Sorting for ORDER BY)\n+              Expression ((Before ORDER BY + (Projection + Before ORDER BY)))\n+                ReadFromSystemNumbers\n -- execute\n 1\n 2\ndiff --git a/tests/queries/0_stateless/02554_fix_grouping_sets_predicate_push_down.reference b/tests/queries/0_stateless/02554_fix_grouping_sets_predicate_push_down.reference\nindex 9bb0c022752b..a382e14ce035 100644\n--- a/tests/queries/0_stateless/02554_fix_grouping_sets_predicate_push_down.reference\n+++ b/tests/queries/0_stateless/02554_fix_grouping_sets_predicate_push_down.reference\n@@ -28,21 +28,17 @@ WHERE type_1 = \\'all\\'\n (Expression)\n ExpressionTransform \u00d7 2\n   (Filter)\n-  FilterTransform \u00d7 2\n-    (Filter)\n-    FilterTransform \u00d7 2\n-      (Filter)\n-      FilterTransform \u00d7 2\n-        (Aggregating)\n-        ExpressionTransform \u00d7 2\n-          AggregatingTransform \u00d7 2\n-            Copy 1 \u2192 2\n-              (Expression)\n-              ExpressionTransform\n-                (Expression)\n-                ExpressionTransform\n-                  (ReadFromMergeTree)\n-                  MergeTreeSelect(pool: ReadPoolInOrder, algorithm: InOrder) 0 \u2192 1\n+  FilterTransform \u00d7 6\n+    (Aggregating)\n+    ExpressionTransform \u00d7 2\n+      AggregatingTransform \u00d7 2\n+        Copy 1 \u2192 2\n+          (Expression)\n+          ExpressionTransform\n+            (Expression)\n+            ExpressionTransform\n+              (ReadFromMergeTree)\n+              MergeTreeSelect(pool: ReadPoolInOrder, algorithm: InOrder) 0 \u2192 1\n (Expression)\n ExpressionTransform \u00d7 2\n   (Filter)\n@@ -68,14 +64,10 @@ ExpressionTransform \u00d7 2\n   ExpressionTransform \u00d7 2\n     AggregatingTransform \u00d7 2\n       Copy 1 \u2192 2\n-        (Filter)\n-        FilterTransform\n-          (Filter)\n-          FilterTransform\n-            (Expression)\n-            ExpressionTransform\n-              (ReadFromMergeTree)\n-              MergeTreeSelect(pool: ReadPoolInOrder, algorithm: InOrder) 0 \u2192 1\n+        (Expression)\n+        ExpressionTransform\n+          (ReadFromMergeTree)\n+          MergeTreeSelect(pool: ReadPoolInOrder, algorithm: InOrder) 0 \u2192 1\n (Expression)\n ExpressionTransform \u00d7 2\n   (Aggregating)\ndiff --git a/tests/queries/0_stateless/03036_join_filter_push_down_equivalent_sets.reference b/tests/queries/0_stateless/03036_join_filter_push_down_equivalent_sets.reference\nindex 80f4e3095057..d0a3e7b02aed 100644\n--- a/tests/queries/0_stateless/03036_join_filter_push_down_equivalent_sets.reference\n+++ b/tests/queries/0_stateless/03036_join_filter_push_down_equivalent_sets.reference\n@@ -163,17 +163,21 @@ Positions: 4 2 0 1\n     Filter (( + (JOIN actions + Change column names to column identifiers)))\n     Header: __table1.id UInt64\n             __table1.value String\n-    Filter column: and(equals(__table1.id, 5_UInt8), equals(__table1.id, 6_UInt8)) (removed)\n+    AND column: equals(__table1.id, 5_UInt8)\n     Actions: INPUT : 0 -> id UInt64 : 0\n-             INPUT : 1 -> value String : 1\n+             COLUMN Const(UInt8) -> 5_UInt8 UInt8 : 1\n+             FUNCTION equals(id : 0, 5_UInt8 :: 1) -> equals(__table1.id, 5_UInt8) UInt8 : 2\n+    Positions: 2 0 2\n+    Filter column: and(equals(__table1.id, 5_UInt8), equals(__table1.id, 6_UInt8)) (removed)\n+    Actions: INPUT : 2 -> value String : 0\n+             INPUT : 1 -> id UInt64 : 1\n              COLUMN Const(UInt8) -> 6_UInt8 UInt8 : 2\n-             COLUMN Const(UInt8) -> 5_UInt8 UInt8 : 3\n-             ALIAS id : 0 -> __table1.id UInt64 : 4\n-             ALIAS value :: 1 -> __table1.value String : 5\n-             FUNCTION equals(id : 0, 6_UInt8 :: 2) -> equals(__table1.id, 6_UInt8) UInt8 : 1\n-             FUNCTION equals(id :: 0, 5_UInt8 :: 3) -> equals(__table1.id, 5_UInt8) UInt8 : 2\n-             FUNCTION and(equals(__table1.id, 5_UInt8) :: 2, equals(__table1.id, 6_UInt8) :: 1) -> and(equals(__table1.id, 5_UInt8), equals(__table1.id, 6_UInt8)) UInt8 : 3\n-    Positions: 3 4 5\n+             INPUT : 0 -> equals(__table1.id, 5_UInt8) UInt8 : 3\n+             ALIAS value :: 0 -> __table1.value String : 4\n+             ALIAS id : 1 -> __table1.id UInt64 : 0\n+             FUNCTION equals(id :: 1, 6_UInt8 :: 2) -> equals(__table1.id, 6_UInt8) UInt8 : 5\n+             FUNCTION and(equals(__table1.id, 5_UInt8) :: 3, equals(__table1.id, 6_UInt8) :: 5) -> and(equals(__table1.id, 5_UInt8), equals(__table1.id, 6_UInt8)) UInt8 : 2\n+    Positions: 2 0 4\n       ReadFromMergeTree (default.test_table_1)\n       Header: id UInt64\n               value String\n@@ -183,17 +187,21 @@ Positions: 4 2 0 1\n     Filter (( + (JOIN actions + Change column names to column identifiers)))\n     Header: __table2.id UInt64\n             __table2.value String\n-    Filter column: and(equals(__table2.id, 6_UInt8), equals(__table2.id, 5_UInt8)) (removed)\n+    AND column: equals(__table2.id, 6_UInt8)\n     Actions: INPUT : 0 -> id UInt64 : 0\n-             INPUT : 1 -> value String : 1\n+             COLUMN Const(UInt8) -> 6_UInt8 UInt8 : 1\n+             FUNCTION equals(id : 0, 6_UInt8 :: 1) -> equals(__table2.id, 6_UInt8) UInt8 : 2\n+    Positions: 2 0 2\n+    Filter column: and(equals(__table2.id, 6_UInt8), equals(__table2.id, 5_UInt8)) (removed)\n+    Actions: INPUT : 2 -> value String : 0\n+             INPUT : 1 -> id UInt64 : 1\n              COLUMN Const(UInt8) -> 5_UInt8 UInt8 : 2\n-             COLUMN Const(UInt8) -> 6_UInt8 UInt8 : 3\n-             ALIAS id : 0 -> __table2.id UInt64 : 4\n-             ALIAS value :: 1 -> __table2.value String : 5\n-             FUNCTION equals(id : 0, 5_UInt8 :: 2) -> equals(__table2.id, 5_UInt8) UInt8 : 1\n-             FUNCTION equals(id :: 0, 6_UInt8 :: 3) -> equals(__table2.id, 6_UInt8) UInt8 : 2\n-             FUNCTION and(equals(__table2.id, 6_UInt8) :: 2, equals(__table2.id, 5_UInt8) :: 1) -> and(equals(__table2.id, 6_UInt8), equals(__table2.id, 5_UInt8)) UInt8 : 3\n-    Positions: 3 4 5\n+             INPUT : 0 -> equals(__table2.id, 6_UInt8) UInt8 : 3\n+             ALIAS value :: 0 -> __table2.value String : 4\n+             ALIAS id : 1 -> __table2.id UInt64 : 0\n+             FUNCTION equals(id :: 1, 5_UInt8 :: 2) -> equals(__table2.id, 5_UInt8) UInt8 : 5\n+             FUNCTION and(equals(__table2.id, 6_UInt8) :: 3, equals(__table2.id, 5_UInt8) :: 5) -> and(equals(__table2.id, 6_UInt8), equals(__table2.id, 5_UInt8)) UInt8 : 2\n+    Positions: 2 0 4\n       ReadFromMergeTree (default.test_table_2)\n       Header: id UInt64\n               value String\n@@ -656,17 +664,21 @@ Positions: 4 2 0 1\n           __table1.value String\n           __table2.value String\n           __table2.id UInt64\n-  Filter column: and(equals(__table1.id, 5_UInt8), equals(__table2.id, 6_UInt8)) (removed)\n+  AND column: equals(__table1.id, 5_UInt8)\n   Actions: INPUT : 0 -> __table1.id UInt64 : 0\n-           INPUT :: 1 -> __table1.value String : 1\n-           INPUT :: 2 -> __table2.value String : 2\n-           INPUT : 3 -> __table2.id UInt64 : 3\n-           COLUMN Const(UInt8) -> 5_UInt8 UInt8 : 4\n-           COLUMN Const(UInt8) -> 6_UInt8 UInt8 : 5\n-           FUNCTION equals(__table1.id : 0, 5_UInt8 :: 4) -> equals(__table1.id, 5_UInt8) UInt8 : 6\n-           FUNCTION equals(__table2.id : 3, 6_UInt8 :: 5) -> equals(__table2.id, 6_UInt8) UInt8 : 4\n-           FUNCTION and(equals(__table1.id, 5_UInt8) :: 6, equals(__table2.id, 6_UInt8) :: 4) -> and(equals(__table1.id, 5_UInt8), equals(__table2.id, 6_UInt8)) UInt8 : 5\n-  Positions: 5 0 1 2 3\n+           COLUMN Const(UInt8) -> 5_UInt8 UInt8 : 1\n+           FUNCTION equals(__table1.id : 0, 5_UInt8 :: 1) -> equals(__table1.id, 5_UInt8) UInt8 : 2\n+  Positions: 2 0 2\n+  Filter column: and(equals(__table1.id, 5_UInt8), equals(__table2.id, 6_UInt8)) (removed)\n+  Actions: INPUT :: 1 -> __table1.id UInt64 : 0\n+           INPUT :: 2 -> __table1.value String : 1\n+           INPUT :: 3 -> __table2.value String : 2\n+           INPUT : 4 -> __table2.id UInt64 : 3\n+           COLUMN Const(UInt8) -> 6_UInt8 UInt8 : 4\n+           INPUT : 0 -> equals(__table1.id, 5_UInt8) UInt8 : 5\n+           FUNCTION equals(__table2.id : 3, 6_UInt8 :: 4) -> equals(__table2.id, 6_UInt8) UInt8 : 6\n+           FUNCTION and(equals(__table1.id, 5_UInt8) :: 5, equals(__table2.id, 6_UInt8) :: 6) -> and(equals(__table1.id, 5_UInt8), equals(__table2.id, 6_UInt8)) UInt8 : 4\n+  Positions: 4 0 1 2 3\n     Join (JOIN FillRightFirst)\n     Header: __table1.id UInt64\n             __table1.value String\ndiff --git a/tests/queries/0_stateless/03199_merge_filters_bug.sql b/tests/queries/0_stateless/03199_merge_filters_bug.sql\nindex ed2ec2ea2176..696856c91212 100644\n--- a/tests/queries/0_stateless/03199_merge_filters_bug.sql\n+++ b/tests/queries/0_stateless/03199_merge_filters_bug.sql\n@@ -1,3 +1,5 @@\n+set allow_reorder_prewhere_conditions=0;\n+\n drop table if exists t1;\n drop table if exists t2;\n \n@@ -49,7 +51,23 @@ tmp1 AS\n         fs1\n     FROM t2\n     LEFT JOIN tmp1 USING (fs1)\n-    WHERE (fs1 IN ('test')) SETTINGS enable_multiple_prewhere_read_steps = 0;\n+    WHERE (fs1 IN ('test')) SETTINGS enable_multiple_prewhere_read_steps = 0, query_plan_merge_filters=0;\n+\n+WITH\n+tmp1 AS\n+(\n+    SELECT\n+        CAST(s1, 'FixedString(10)') AS fs1,\n+        s2 AS sector,\n+        s3\n+    FROM t1\n+    WHERE  (s3 != 'test')\n+)\n+    SELECT\n+        fs1\n+    FROM t2\n+    LEFT JOIN tmp1 USING (fs1)\n+    WHERE (fs1 IN ('test')) SETTINGS enable_multiple_prewhere_read_steps = 1, query_plan_merge_filters=1;\n \n optimize table t1 final;\n \n@@ -67,4 +85,20 @@ tmp1 AS\n         fs1\n     FROM t2\n     LEFT JOIN tmp1 USING (fs1)\n-    WHERE (fs1 IN ('test'));\n+    WHERE (fs1 IN ('test')) SETTINGS enable_multiple_prewhere_read_steps = 0, query_plan_merge_filters=0;\n+\n+WITH\n+tmp1 AS\n+(\n+    SELECT\n+        CAST(s1, 'FixedString(10)') AS fs1,\n+        s2 AS sector,\n+        s3\n+    FROM t1\n+    WHERE  (s3 != 'test')\n+)\n+    SELECT\n+        fs1\n+    FROM t2\n+    LEFT JOIN tmp1 USING (fs1)\n+    WHERE (fs1 IN ('test')) SETTINGS enable_multiple_prewhere_read_steps = 1, query_plan_merge_filters=1;\ndiff --git a/tests/queries/0_stateless/03262_filter_push_down_view.reference b/tests/queries/0_stateless/03262_filter_push_down_view.reference\nnew file mode 100644\nindex 000000000000..275ff18f73be\n--- /dev/null\n+++ b/tests/queries/0_stateless/03262_filter_push_down_view.reference\n@@ -0,0 +1,2 @@\n+Condition: and((materialize(auid) in [1, 1]), (_CAST(toDate(ts)) in (-Inf, 1703980800]))\n+Granules: 1/3\ndiff --git a/tests/queries/0_stateless/03262_filter_push_down_view.sql b/tests/queries/0_stateless/03262_filter_push_down_view.sql\nnew file mode 100644\nindex 000000000000..8492d8c8ebdc\n--- /dev/null\n+++ b/tests/queries/0_stateless/03262_filter_push_down_view.sql\n@@ -0,0 +1,36 @@\n+DROP TABLE IF EXISTS alpha;\n+DROP TABLE IF EXISTS alpha__day;\n+\n+SET session_timezone = 'Etc/UTC';\n+\n+CREATE TABLE alpha\n+(\n+    `ts` DateTime64(6),\n+    `auid` Int64,\n+)\n+ENGINE = MergeTree\n+ORDER BY (auid, ts)\n+SETTINGS index_granularity = 1;\n+\n+CREATE VIEW alpha__day\n+(\n+    `ts_date` Date,\n+    `auid` Int64,\n+)\n+AS SELECT\n+    ts_date,\n+    auid,\n+FROM\n+(\n+    SELECT\n+        toDate(ts) AS ts_date,\n+        auid\n+    FROM alpha\n+)\n+WHERE ts_date <= toDateTime('2024-01-01 00:00:00') - INTERVAL 1 DAY;\n+\n+INSERT INTO alpha VALUES (toDateTime64('2024-01-01 00:00:00.000', 3) - INTERVAL 3 DAY, 1);\n+INSERT INTO alpha VALUES (toDateTime64('2024-01-01 00:00:00.000', 3) - INTERVAL 3 DAY, 2);\n+INSERT INTO alpha VALUES (toDateTime64('2024-01-01 00:00:00.000', 3) - INTERVAL 3 DAY, 3);\n+\n+select trimLeft(explain) from (EXPLAIN indexes = 1 SELECT auid FROM alpha__day WHERE auid = 1) where explain like '%Condition:%' or explain like '%Granules:%' settings allow_experimental_analyzer = 1;\n",
  "problem_statement": "Analyzer does not push down filter condition and use index in View with subquery\n**Describe the unexpected behaviour**\r\nWhen using a View with subquery, the Analyzer does not push down the filtering condition. \r\n\r\n**How to reproduce**\r\n- Reproduced on 24.8 LTS and 24.10 latest release\r\n\r\n- https://fiddle.clickhouse.com/2be02245-eb36-4fa0-8dfe-62b8236bbfd7\r\n```\r\nDROP TABLE IF EXISTS alpha;\r\nDROP TABLE IF EXISTS alpha__day;\r\n\r\nCREATE TABLE alpha\r\n(\r\n    `ts` DateTime64(6),\r\n    `auid` Int64,\r\n)\r\nENGINE = MergeTree\r\nORDER BY (auid, ts)\r\nSETTINGS index_granularity = 1;\r\n\r\nCREATE VIEW alpha__day\r\n(\r\n    `ts_date` Date,\r\n    `auid` Int64,\r\n)\r\nAS SELECT\r\n    ts_date,\r\n    auid,\r\nFROM\r\n(\r\n    SELECT\r\n        toDate(ts) AS ts_date,\r\n        auid\r\n    FROM alpha\r\n)\r\nWHERE ts_date <= now() - INTERVAL 1 DAY;\r\n\r\nINSERT INTO alpha VALUES (now64() - INTERVAL 3 DAY, 1);\r\nINSERT INTO alpha VALUES (now64() - INTERVAL 3 DAY, 2);\r\nINSERT INTO alpha VALUES (now64() - INTERVAL 3 DAY, 3);\r\n\r\nEXPLAIN indexes = 1 SELECT auid FROM alpha__day WHERE auid = 1 settings allow_experimental_analyzer = 1;\r\nEXPLAIN indexes = 1 SELECT auid FROM alpha__day WHERE auid = 1 settings allow_experimental_analyzer = 0;\r\n```\r\n\r\nGranules are not filtered when using analyzer (`Granules: 3/3`)\r\n```\r\n-- allow_experimental_analyzer = 1\r\nExpression ((Project names + Projection))\r\n  Filter ((WHERE + (Change column names to column identifiers + (Convert VIEW subquery result to VIEW table structure + (Materialize constants after VIEW subquery + (Project names + (Projection + (Change column names to column identifiers + (Project names + Projection)))))))))\r\n    Expression\r\n      ReadFromMergeTree (default.alpha)\r\n      Indexes:\r\n        PrimaryKey\r\n          Keys: \r\n            ts\r\n          Condition: (_CAST(toDate(ts)) in (-Inf, 1730600442])\r\n          Parts: 3/3\r\n          Granules: 3/3\r\n-- allow_experimental_analyzer = 0\r\nExpression ((Projection + Before ORDER BY))\r\n  Filter ((WHERE + (Convert VIEW subquery result to VIEW table structure + (Materialize constants after VIEW subquery + (Projection + Before ORDER BY)))))\r\n    Filter ((WHERE + (Projection + Before ORDER BY)))\r\n      Expression\r\n        ReadFromMergeTree (default.alpha)\r\n        Indexes:\r\n          PrimaryKey\r\n            Keys: \r\n              auid\r\n              ts\r\n            Condition: and((materialize(auid) in [1, 1]), and((auid in [1, 1]), and((_CAST(toDate(ts)) in (-Inf, 1730600442]), (auid in [1, 1]))))\r\n            Parts: 1/3\r\n            Granules: 1/3\r\n```\r\n\r\nWorking as expected when not using subquery in View.\r\n\r\n- https://fiddle.clickhouse.com/37304f26-a736-4505-a3a4-04f3bf4a75e3\r\n```\r\n...\r\nCREATE VIEW alpha__day\r\n(\r\n    `ts_date` Date,\r\n    `auid` Int64,\r\n)\r\nAS SELECT\r\n    toDate(ts) AS ts_date,\r\n    auid\r\nFROM alpha\r\nWHERE ts_date <= now() - INTERVAL 1 DAY;\r\n...\r\nEXPLAIN indexes = 1 SELECT auid FROM alpha__day WHERE auid = 1 settings allow_experimental_analyzer = 1;\r\n```\r\n\r\n```\r\nExpression ((Project names + Projection))\r\n  Filter ((WHERE + (Change column names to column identifiers + (Convert VIEW subquery result to VIEW table structure + (Materialize constants after VIEW subquery + (Project names + (Projection + (Change column names to column identifiers + (Project names + Projection)))))))))\r\n    Expression\r\n      ReadFromMergeTree (default.alpha)\r\n      Indexes:\r\n        PrimaryKey\r\n          Keys: \r\n            auid\r\n            ts\r\n          Condition: and((materialize(auid) in [1, 1]), (_CAST(toDate(ts)) in (-Inf, 1730597277]))\r\n          Parts: 1/3\r\n          Granules: 1/3\r\n```\r\n\r\n**Expected behavior**\r\nAnalyzer should pushdown condition for View with subquery. \n",
  "hints_text": "Related https://github.com/ClickHouse/ClickHouse/issues/67668 https://github.com/ClickHouse/ClickHouse/issues/69373",
  "created_at": "2024-11-06T17:34:11Z",
  "modified_files": [
    "src/Core/Settings.cpp",
    "src/Core/SettingsChangesHistory.cpp",
    "src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp",
    "src/Processors/QueryPlan/BuildQueryPipelineSettings.h",
    "src/Processors/QueryPlan/FilterStep.cpp",
    "src/Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h",
    "src/Processors/QueryPlan/ReadFromMergeTree.cpp",
    "src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp",
    "src/Storages/MergeTree/MergeTreeIOSettings.h",
    "src/Storages/MergeTree/MergeTreeSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreeSelectProcessor.h",
    "src/Storages/MergeTree/MergeTreeSplitPrewhereIntoReadSteps.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/01655_plan_optimizations.reference",
    "tests/queries/0_stateless/01655_plan_optimizations.sh",
    "tests/queries/0_stateless/02496_remove_redundant_sorting.reference",
    "tests/queries/0_stateless/02554_fix_grouping_sets_predicate_push_down.reference",
    "tests/queries/0_stateless/03036_join_filter_push_down_equivalent_sets.reference",
    "tests/queries/0_stateless/03199_merge_filters_bug.sql",
    "b/tests/queries/0_stateless/03262_filter_push_down_view.reference",
    "b/tests/queries/0_stateless/03262_filter_push_down_view.sql"
  ]
}