{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 2235,
  "instance_id": "ClickHouse__ClickHouse-2235",
  "issue_numbers": [
    "2189"
  ],
  "base_commit": "c9c09a9d13f9fa6b961ceb4fef6c9fc9c9affca3",
  "patch": "diff --git a/dbms/src/DataStreams/IBlockInputStream.h b/dbms/src/DataStreams/IBlockInputStream.h\nindex 988f15bffb7e..b66fe70e2c78 100644\n--- a/dbms/src/DataStreams/IBlockInputStream.h\n+++ b/dbms/src/DataStreams/IBlockInputStream.h\n@@ -3,6 +3,7 @@\n #include <vector>\n #include <memory>\n #include <mutex>\n+#include <shared_mutex>\n #include <functional>\n #include <boost/noncopyable.hpp>\n #include <Core/Block.h>\n@@ -108,7 +109,9 @@ class IBlockInputStream : private boost::noncopyable\n     template <typename F>\n     void forEachChild(F && f)\n     {\n-        std::lock_guard lock(children_mutex);\n+        /// NOTE: Acquire a read lock, therefore f() should be thread safe\n+        std::shared_lock lock(children_mutex);\n+\n         for (auto & child : children)\n             if (f(*child))\n                 return;\n@@ -116,7 +119,7 @@ class IBlockInputStream : private boost::noncopyable\n \n protected:\n     BlockInputStreams children;\n-    std::mutex children_mutex;\n+    std::shared_mutex children_mutex;\n \n private:\n     TableStructureReadLocks table_locks;\ndiff --git a/dbms/src/DataStreams/IProfilingBlockInputStream.h b/dbms/src/DataStreams/IProfilingBlockInputStream.h\nindex a9601d5c265f..5febcb18c56b 100644\n--- a/dbms/src/DataStreams/IProfilingBlockInputStream.h\n+++ b/dbms/src/DataStreams/IProfilingBlockInputStream.h\n@@ -190,7 +190,7 @@ class IProfilingBlockInputStream : public IBlockInputStream\n \n     void addChild(BlockInputStreamPtr & child)\n     {\n-        std::lock_guard lock(children_mutex);\n+        std::unique_lock lock(children_mutex);\n         children.push_back(child);\n     }\n \n@@ -231,7 +231,9 @@ class IProfilingBlockInputStream : public IBlockInputStream\n     template <typename F>\n     void forEachProfilingChild(F && f)\n     {\n-        std::lock_guard lock(children_mutex);\n+        /// NOTE: Acquire a read lock, therefore f() should be thread safe\n+        std::shared_lock lock(children_mutex);\n+\n         for (auto & child : children)\n             if (IProfilingBlockInputStream * p_child = dynamic_cast<IProfilingBlockInputStream *>(child.get()))\n                 if (f(*p_child))\ndiff --git a/dbms/src/Interpreters/Context.cpp b/dbms/src/Interpreters/Context.cpp\nindex b0bf8f6f441b..2e10acf4c735 100644\n--- a/dbms/src/Interpreters/Context.cpp\n+++ b/dbms/src/Interpreters/Context.cpp\n@@ -588,6 +588,12 @@ QuotaForIntervals & Context::getQuota()\n }\n \n void Context::checkDatabaseAccessRights(const std::string & database_name) const\n+{\n+    auto lock = getLock();\n+    checkDatabaseAccessRightsImpl(database_name);\n+}\n+\n+void Context::checkDatabaseAccessRightsImpl(const std::string & database_name) const\n {\n     if (client_info.current_user.empty() || (database_name == \"system\"))\n     {\n@@ -602,8 +608,8 @@ void Context::checkDatabaseAccessRights(const std::string & database_name) const\n void Context::addDependency(const DatabaseAndTableName & from, const DatabaseAndTableName & where)\n {\n     auto lock = getLock();\n-    checkDatabaseAccessRights(from.first);\n-    checkDatabaseAccessRights(where.first);\n+    checkDatabaseAccessRightsImpl(from.first);\n+    checkDatabaseAccessRightsImpl(where.first);\n     shared->view_dependencies[from].insert(where);\n \n     // Notify table of dependencies change\n@@ -615,8 +621,8 @@ void Context::addDependency(const DatabaseAndTableName & from, const DatabaseAnd\n void Context::removeDependency(const DatabaseAndTableName & from, const DatabaseAndTableName & where)\n {\n     auto lock = getLock();\n-    checkDatabaseAccessRights(from.first);\n-    checkDatabaseAccessRights(where.first);\n+    checkDatabaseAccessRightsImpl(from.first);\n+    checkDatabaseAccessRightsImpl(where.first);\n     shared->view_dependencies[from].erase(where);\n \n     // Notify table of dependencies change\n@@ -637,7 +643,7 @@ Dependencies Context::getDependencies(const String & database_name, const String\n     }\n     else\n     {\n-        checkDatabaseAccessRights(db);\n+        checkDatabaseAccessRightsImpl(db);\n     }\n \n     ViewDependencies::const_iterator iter = shared->view_dependencies.find(DatabaseAndTableName(db, table_name));\n@@ -652,7 +658,7 @@ bool Context::isTableExist(const String & database_name, const String & table_na\n     auto lock = getLock();\n \n     String db = resolveDatabase(database_name, current_database);\n-    checkDatabaseAccessRights(db);\n+    checkDatabaseAccessRightsImpl(db);\n \n     Databases::const_iterator it = shared->databases.find(db);\n     return shared->databases.end() != it\n@@ -664,7 +670,7 @@ bool Context::isDatabaseExist(const String & database_name) const\n {\n     auto lock = getLock();\n     String db = resolveDatabase(database_name, current_database);\n-    checkDatabaseAccessRights(db);\n+    checkDatabaseAccessRightsImpl(db);\n     return shared->databases.end() != shared->databases.find(db);\n }\n \n@@ -679,7 +685,7 @@ void Context::assertTableExists(const String & database_name, const String & tab\n     auto lock = getLock();\n \n     String db = resolveDatabase(database_name, current_database);\n-    checkDatabaseAccessRights(db);\n+    checkDatabaseAccessRightsImpl(db);\n \n     Databases::const_iterator it = shared->databases.find(db);\n     if (shared->databases.end() == it)\n@@ -696,7 +702,7 @@ void Context::assertTableDoesntExist(const String & database_name, const String\n \n     String db = resolveDatabase(database_name, current_database);\n     if (check_database_access_rights)\n-        checkDatabaseAccessRights(db);\n+        checkDatabaseAccessRightsImpl(db);\n \n     Databases::const_iterator it = shared->databases.find(db);\n     if (shared->databases.end() != it && it->second->isTableExist(*this, table_name))\n@@ -710,7 +716,7 @@ void Context::assertDatabaseExists(const String & database_name, bool check_data\n \n     String db = resolveDatabase(database_name, current_database);\n     if (check_database_access_rights)\n-        checkDatabaseAccessRights(db);\n+        checkDatabaseAccessRightsImpl(db);\n \n     if (shared->databases.end() == shared->databases.find(db))\n         throw Exception(\"Database \" + backQuoteIfNeed(db) + \" doesn't exist\", ErrorCodes::UNKNOWN_DATABASE);\n@@ -722,7 +728,7 @@ void Context::assertDatabaseDoesntExist(const String & database_name) const\n     auto lock = getLock();\n \n     String db = resolveDatabase(database_name, current_database);\n-    checkDatabaseAccessRights(db);\n+    checkDatabaseAccessRightsImpl(db);\n \n     if (shared->databases.end() != shared->databases.find(db))\n         throw Exception(\"Database \" + backQuoteIfNeed(db) + \" already exists.\", ErrorCodes::DATABASE_ALREADY_EXISTS);\n@@ -789,7 +795,7 @@ StoragePtr Context::getTableImpl(const String & database_name, const String & ta\n     }\n \n     String db = resolveDatabase(database_name, current_database);\n-    checkDatabaseAccessRights(db);\n+    checkDatabaseAccessRightsImpl(db);\n \n     Databases::const_iterator it = shared->databases.find(db);\n     if (shared->databases.end() == it)\ndiff --git a/dbms/src/Interpreters/Context.h b/dbms/src/Interpreters/Context.h\nindex 670bda401bfb..69f18c913b02 100644\n--- a/dbms/src/Interpreters/Context.h\n+++ b/dbms/src/Interpreters/Context.h\n@@ -178,6 +178,7 @@ class Context\n     void assertDatabaseExists(const String & database_name, bool check_database_acccess_rights = true) const;\n \n     void assertDatabaseDoesntExist(const String & database_name) const;\n+    void checkDatabaseAccessRights(const std::string & database_name) const;\n \n     Tables getExternalTables() const;\n     StoragePtr tryGetExternalTable(const String & table_name) const;\n@@ -392,7 +393,7 @@ class Context\n       * If access is denied, throw an exception.\n       * NOTE: This method should always be called when the `shared->mutex` mutex is acquired.\n       */\n-    void checkDatabaseAccessRights(const std::string & database_name) const;\n+    void checkDatabaseAccessRightsImpl(const std::string & database_name) const;\n \n     EmbeddedDictionaries & getEmbeddedDictionariesImpl(bool throw_on_error) const;\n     ExternalDictionaries & getExternalDictionariesImpl(bool throw_on_error) const;\ndiff --git a/dbms/src/Interpreters/DDLWorker.cpp b/dbms/src/Interpreters/DDLWorker.cpp\nindex 5a820ff73340..c8bdd67ce2a8 100644\n--- a/dbms/src/Interpreters/DDLWorker.cpp\n+++ b/dbms/src/Interpreters/DDLWorker.cpp\n@@ -960,15 +960,25 @@ class DDLQueryStatusInputSream : public IProfilingBlockInputStream\n     {\n         Block res;\n         if (num_hosts_finished >= waiting_hosts.size())\n+        {\n+            if (first_exception)\n+                throw Exception(*first_exception);\n+\n             return res;\n+        }\n \n         auto zookeeper = context.getZooKeeper();\n         size_t try_number = 0;\n \n-        while(res.rows() == 0)\n+        while (res.rows() == 0)\n         {\n             if (isCancelled())\n+            {\n+                if (first_exception)\n+                    throw Exception(*first_exception);\n+\n                 return res;\n+            }\n \n             if (timeout_seconds >= 0 && watch.elapsedSeconds() > timeout_seconds)\n             {\n@@ -1020,6 +1030,9 @@ class DDLQueryStatusInputSream : public IProfilingBlockInputStream\n                 UInt16 port;\n                 Cluster::Address::fromString(host_id, host, port);\n \n+                if (status.code != 0 && first_exception == nullptr)\n+                    first_exception = std::make_unique<Exception>(\"There was an error on \" + host + \": \" + status.message, status.code);\n+\n                 ++num_hosts_finished;\n \n                 columns[0]->insert(host);\n@@ -1092,11 +1105,14 @@ class DDLQueryStatusInputSream : public IProfilingBlockInputStream\n     Strings current_active_hosts; /// Hosts that were in active state at the last check\n     size_t num_hosts_finished = 0;\n \n+    /// Save the first detected error and throw it at the end of excecution\n+    std::unique_ptr<Exception> first_exception;\n+\n     Int64 timeout_seconds = 120;\n };\n \n \n-BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr_, const Context & context)\n+BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr_, const Context & context, const NameSet & query_databases)\n {\n     /// Remove FORMAT <fmt> and INTO OUTFILE <file> if exists\n     ASTPtr query_ptr = query_ptr_->clone();\n@@ -1128,13 +1144,26 @@ BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr_, const Context & cont\n     entry.query = queryToString(query_ptr);\n     entry.initiator = ddl_worker.getCommonHostID();\n \n+    /// Check database access rights, assume that all servers have the same users config\n+    NameSet databases_to_check_access_rights;\n+\n     Cluster::AddressesWithFailover shards = cluster->getShardsAddresses();\n+\n     for (const auto & shard : shards)\n     {\n         for (const auto & addr : shard)\n+        {\n             entry.hosts.emplace_back(addr);\n+\n+            /// Expand empty database name to shards' default database name\n+            for (const String & database : query_databases)\n+                databases_to_check_access_rights.emplace(database.empty() ? addr.default_database : database);\n+        }\n     }\n \n+    for (const String & database : databases_to_check_access_rights)\n+        context.checkDatabaseAccessRights(database.empty() ? context.getCurrentDatabase() : database);\n+\n     String node_path = ddl_worker.enqueueQuery(entry);\n \n     BlockIO io;\ndiff --git a/dbms/src/Interpreters/DDLWorker.h b/dbms/src/Interpreters/DDLWorker.h\nindex f9c296d373ad..d640b6d0bc8e 100644\n--- a/dbms/src/Interpreters/DDLWorker.h\n+++ b/dbms/src/Interpreters/DDLWorker.h\n@@ -18,7 +18,8 @@ struct DDLLogEntry;\n struct DDLTask;\n \n \n-BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr, const Context & context);\n+/// Pushes distributed DDL query to the queue\n+BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr, const Context & context, const NameSet & query_databases);\n \n \n class DDLWorker\ndiff --git a/dbms/src/Interpreters/InterpreterAlterQuery.cpp b/dbms/src/Interpreters/InterpreterAlterQuery.cpp\nindex f4708a67c3d5..bc7861ad41c6 100644\n--- a/dbms/src/Interpreters/InterpreterAlterQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterAlterQuery.cpp\n@@ -42,7 +42,7 @@ BlockIO InterpreterAlterQuery::execute()\n     auto & alter = typeid_cast<ASTAlterQuery &>(*query_ptr);\n \n     if (!alter.cluster.empty())\n-        return executeDDLQueryOnCluster(query_ptr, context);\n+        return executeDDLQueryOnCluster(query_ptr, context, {alter.table});\n \n     const String & table_name = alter.table;\n     String database_name = alter.database.empty() ? context.getCurrentDatabase() : alter.database;\ndiff --git a/dbms/src/Interpreters/InterpreterCreateQuery.cpp b/dbms/src/Interpreters/InterpreterCreateQuery.cpp\nindex 455217a5e40d..99f0efc10c99 100644\n--- a/dbms/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -66,7 +66,7 @@ InterpreterCreateQuery::InterpreterCreateQuery(const ASTPtr & query_ptr_, Contex\n BlockIO InterpreterCreateQuery::createDatabase(ASTCreateQuery & create)\n {\n     if (!create.cluster.empty())\n-        return executeDDLQueryOnCluster(query_ptr, context);\n+        return executeDDLQueryOnCluster(query_ptr, context, {create.database});\n \n     String database_name = create.database;\n \n@@ -439,7 +439,13 @@ void InterpreterCreateQuery::setEngine(ASTCreateQuery & create) const\n BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)\n {\n     if (!create.cluster.empty())\n-        return executeDDLQueryOnCluster(query_ptr, context);\n+    {\n+        NameSet databases{create.database};\n+        if (!create.to_table.empty())\n+            databases.emplace(create.to_database);\n+\n+        return executeDDLQueryOnCluster(query_ptr, context, databases);\n+    }\n \n     String path = context.getPath();\n     String current_database = context.getCurrentDatabase();\ndiff --git a/dbms/src/Interpreters/InterpreterDropQuery.cpp b/dbms/src/Interpreters/InterpreterDropQuery.cpp\nindex 0fdf2b1ccf4a..839b714a4994 100644\n--- a/dbms/src/Interpreters/InterpreterDropQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterDropQuery.cpp\n@@ -32,7 +32,7 @@ BlockIO InterpreterDropQuery::execute()\n     checkAccess(drop);\n \n     if (!drop.cluster.empty())\n-        return executeDDLQueryOnCluster(query_ptr, context);\n+        return executeDDLQueryOnCluster(query_ptr, context, {drop.database});\n \n     String path = context.getPath();\n     String current_database = context.getCurrentDatabase();\ndiff --git a/dbms/src/Interpreters/InterpreterKillQueryQuery.cpp b/dbms/src/Interpreters/InterpreterKillQueryQuery.cpp\nindex 1710f881fe40..bddd74432f33 100644\n--- a/dbms/src/Interpreters/InterpreterKillQueryQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterKillQueryQuery.cpp\n@@ -147,7 +147,6 @@ class SyncKillQueryInputStream : public IProfilingBlockInputStream\n             }\n \n             /// KILL QUERY could be killed also\n-            /// Probably interpreting KILL QUERIES as complete (not internal) queries is extra functionality\n             if (isCancelled())\n                 break;\n \ndiff --git a/dbms/src/Interpreters/InterpreterRenameQuery.cpp b/dbms/src/Interpreters/InterpreterRenameQuery.cpp\nindex 00aa95ee6fb5..d241e620455a 100644\n--- a/dbms/src/Interpreters/InterpreterRenameQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterRenameQuery.cpp\n@@ -39,7 +39,16 @@ BlockIO InterpreterRenameQuery::execute()\n     ASTRenameQuery & rename = typeid_cast<ASTRenameQuery &>(*query_ptr);\n \n     if (!rename.cluster.empty())\n-        return executeDDLQueryOnCluster(query_ptr, context);\n+    {\n+        NameSet databases;\n+        for (const auto & elem : rename.elements)\n+        {\n+            databases.emplace(elem.from.database);\n+            databases.emplace(elem.to.database);\n+        }\n+\n+        return executeDDLQueryOnCluster(query_ptr, context, databases);\n+    }\n \n     String path = context.getPath();\n     String current_database = context.getCurrentDatabase();\ndiff --git a/dbms/src/Interpreters/ProcessList.cpp b/dbms/src/Interpreters/ProcessList.cpp\nindex 59c481e6e3ae..8f8053a401c8 100644\n--- a/dbms/src/Interpreters/ProcessList.cpp\n+++ b/dbms/src/Interpreters/ProcessList.cpp\n@@ -1,6 +1,9 @@\n #include <Interpreters/ProcessList.h>\n #include <Interpreters/Settings.h>\n+#include <Parsers/ASTSelectWithUnionQuery.h>\n+#include <Parsers/ASTSelectQuery.h>\n #include <Parsers/ASTKillQueryQuery.h>\n+#include <Parsers/ASTIdentifier.h>\n #include <Common/Exception.h>\n #include <IO/WriteHelpers.h>\n #include <DataStreams/IProfilingBlockInputStream.h>\n@@ -19,21 +22,70 @@ namespace ErrorCodes\n }\n \n \n+/// Should we execute the query even if max_concurrent_queries limit is exhausted\n+static bool isUnlimitedQuery(const IAST * ast)\n+{\n+    if (!ast)\n+        return false;\n+\n+    /// It is KILL QUERY\n+    if (typeid_cast<const ASTKillQueryQuery *>(ast))\n+        return true;\n+\n+    /// It is SELECT FROM system.processes\n+    if (auto ast_selects = typeid_cast<const ASTSelectWithUnionQuery *>(ast))\n+    {\n+        if (!ast_selects->list_of_selects || ast_selects->list_of_selects->children.empty())\n+            return false;\n+\n+        auto ast_select = typeid_cast<ASTSelectQuery *>(ast_selects->list_of_selects->children[0].get());\n+\n+        if (!ast_select)\n+            return false;\n+\n+        auto ast_database = ast_select->database();\n+        if (!ast_database)\n+            return false;\n+\n+        auto ast_table = ast_select->table();\n+        if (!ast_table)\n+            return false;\n+\n+        auto ast_database_id = typeid_cast<const ASTIdentifier *>(ast_database.get());\n+        if (!ast_database_id)\n+            return false;\n+\n+        auto ast_table_id = typeid_cast<const ASTIdentifier *>(ast_table.get());\n+        if (!ast_table_id)\n+            return false;\n+\n+        return ast_database_id->name == \"system\" && ast_table_id->name == \"processes\";\n+    }\n+\n+    return false;\n+}\n+\n+\n ProcessList::EntryPtr ProcessList::insert(\n     const String & query_, const IAST * ast, const ClientInfo & client_info, const Settings & settings)\n {\n     EntryPtr res;\n-    bool is_kill_query = ast && typeid_cast<const ASTKillQueryQuery *>(ast);\n \n     if (client_info.current_query_id.empty())\n         throw Exception(\"Query id cannot be empty\", ErrorCodes::LOGICAL_ERROR);\n \n+    bool is_unlimited_query = isUnlimitedQuery(ast);\n+\n     {\n         std::lock_guard<std::mutex> lock(mutex);\n \n-        if (!is_kill_query && max_size && cur_size >= max_size\n-            && (!settings.queue_max_wait_ms.totalMilliseconds() || !have_space.tryWait(mutex, settings.queue_max_wait_ms.totalMilliseconds())))\n-            throw Exception(\"Too many simultaneous queries. Maximum: \" + toString(max_size), ErrorCodes::TOO_MANY_SIMULTANEOUS_QUERIES);\n+        if (!is_unlimited_query && max_size && cur_size >= max_size)\n+        {\n+            if (!settings.queue_max_wait_ms.totalMilliseconds() || !have_space.tryWait(mutex, settings.queue_max_wait_ms.totalMilliseconds()))\n+            {\n+                throw Exception(\"Too many simultaneous queries. Maximum: \" + toString(max_size), ErrorCodes::TOO_MANY_SIMULTANEOUS_QUERIES);\n+            }\n+        }\n \n         /** Why we use current user?\n           * Because initial one is passed by client and credentials for it is not verified,\n@@ -50,7 +102,7 @@ ProcessList::EntryPtr ProcessList::insert(\n \n             if (user_process_list != user_to_queries.end())\n             {\n-                if (!is_kill_query && settings.max_concurrent_queries_for_user\n+                if (!is_unlimited_query && settings.max_concurrent_queries_for_user\n                     && user_process_list->second.queries.size() >= settings.max_concurrent_queries_for_user)\n                     throw Exception(\"Too many simultaneous queries for user \" + client_info.current_user\n                         + \". Current: \" + toString(user_process_list->second.queries.size())\n@@ -191,31 +243,37 @@ void ProcessListElement::setQueryStreams(const BlockIO & io)\n \n     query_stream_in = io.in;\n     query_stream_out = io.out;\n-    query_streams_initialized = true;\n+    query_streams_status = QueryStreamsStatus::Initialized;\n }\n \n void ProcessListElement::releaseQueryStreams()\n {\n-    std::lock_guard<std::mutex> lock(query_streams_mutex);\n+    BlockInputStreamPtr in;\n+    BlockOutputStreamPtr out;\n+\n+    {\n+        std::lock_guard<std::mutex> lock(query_streams_mutex);\n+\n+        query_streams_status = QueryStreamsStatus::Released;\n+        in = std::move(query_stream_in);\n+        out = std::move(query_stream_out);\n+    }\n \n-    query_streams_initialized = false;\n-    query_streams_released = true;\n-    query_stream_in.reset();\n-    query_stream_out.reset();\n+    /// Destroy streams outside the mutex lock\n }\n \n bool ProcessListElement::streamsAreReleased()\n {\n     std::lock_guard<std::mutex> lock(query_streams_mutex);\n \n-    return query_streams_released;\n+    return query_streams_status == QueryStreamsStatus::Released;\n }\n \n bool ProcessListElement::tryGetQueryStreams(BlockInputStreamPtr & in, BlockOutputStreamPtr & out) const\n {\n     std::lock_guard<std::mutex> lock(query_streams_mutex);\n \n-    if (!query_streams_initialized)\n+    if (query_streams_status != QueryStreamsStatus::Initialized)\n         return false;\n \n     in = query_stream_in;\ndiff --git a/dbms/src/Interpreters/ProcessList.h b/dbms/src/Interpreters/ProcessList.h\nindex ecc29d671fee..2d7d3227eb7a 100644\n--- a/dbms/src/Interpreters/ProcessList.h\n+++ b/dbms/src/Interpreters/ProcessList.h\n@@ -91,8 +91,14 @@ class ProcessListElement\n     BlockInputStreamPtr query_stream_in;\n     BlockOutputStreamPtr query_stream_out;\n \n-    bool query_streams_initialized{false};\n-    bool query_streams_released{false};\n+    enum QueryStreamsStatus\n+    {\n+        NotInitialized,\n+        Initialized,\n+        Released\n+    };\n+\n+    QueryStreamsStatus query_streams_status{NotInitialized};\n \n public:\n     ProcessListElement(\ndiff --git a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAddress.cpp b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAddress.cpp\nnew file mode 100644\nindex 000000000000..16a84b4b2f61\n--- /dev/null\n+++ b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAddress.cpp\n@@ -0,0 +1,42 @@\n+#include \"ReplicatedMergeTreeAddress.h\"\n+#include <IO/ReadBufferFromString.h>\n+#include <IO/WriteBufferFromString.h>\n+#include <IO/Operators.h>\n+\n+namespace DB\n+{\n+\n+\n+void ReplicatedMergeTreeAddress::writeText(WriteBuffer & out) const\n+{\n+    out\n+        << \"host: \" << escape << host << '\\n'\n+        << \"port: \" << replication_port << '\\n'\n+        << \"tcp_port: \" << queries_port << '\\n'\n+        << \"database: \" << escape << database << '\\n'\n+        << \"table: \" << escape << table << '\\n';\n+}\n+\n+void ReplicatedMergeTreeAddress::readText(ReadBuffer & in)\n+{\n+    in\n+        >> \"host: \" >> escape >> host >> \"\\n\"\n+        >> \"port: \" >> replication_port >> \"\\n\"\n+        >> \"tcp_port: \" >> queries_port >> \"\\n\"\n+        >> \"database: \" >> escape >> database >> \"\\n\"\n+        >> \"table: \" >> escape >> table >> \"\\n\";\n+}\n+\n+String ReplicatedMergeTreeAddress::toString() const\n+{\n+    WriteBufferFromOwnString out;\n+    writeText(out);\n+    return out.str();\n+}\n+\n+void ReplicatedMergeTreeAddress::fromString(const String & str)\n+{\n+    ReadBufferFromString in(str);\n+    readText(in);\n+}\n+}\ndiff --git a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAddress.h b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAddress.h\nindex 325b2dc617bd..b50ec72f3a5a 100644\n--- a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAddress.h\n+++ b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAddress.h\n@@ -1,8 +1,7 @@\n+#pragma once\n+#include <Core/Types.h>\n #include <IO/ReadBuffer.h>\n-#include <IO/ReadBufferFromString.h>\n #include <IO/WriteBuffer.h>\n-#include <IO/WriteBufferFromString.h>\n-#include <IO/Operators.h>\n \n \n namespace DB\n@@ -18,44 +17,19 @@ struct ReplicatedMergeTreeAddress\n     String database;\n     String table;\n \n-    ReplicatedMergeTreeAddress() {}\n-    ReplicatedMergeTreeAddress(const String & str)\n+    ReplicatedMergeTreeAddress() = default;\n+    explicit ReplicatedMergeTreeAddress(const String & str)\n     {\n         fromString(str);\n     }\n \n-    void writeText(WriteBuffer & out) const\n-    {\n-        out\n-            << \"host: \" << escape << host << '\\n'\n-            << \"port: \" << replication_port << '\\n'\n-            << \"tcp_port: \" << queries_port << '\\n'\n-            << \"database: \" << escape << database << '\\n'\n-            << \"table: \" << escape << table << '\\n';\n-    }\n+    void writeText(WriteBuffer & out) const;\n \n-    void readText(ReadBuffer & in)\n-    {\n-        in\n-            >> \"host: \" >> escape >> host >> \"\\n\"\n-            >> \"port: \" >> replication_port >> \"\\n\"\n-            >> \"tcp_port: \" >> queries_port >> \"\\n\"\n-            >> \"database: \" >> escape >> database >> \"\\n\"\n-            >> \"table: \" >> escape >> table >> \"\\n\";\n-    }\n+    void readText(ReadBuffer & in);\n \n-    String toString() const\n-    {\n-        WriteBufferFromOwnString out;\n-        writeText(out);\n-        return out.str();\n-    }\n+    String toString() const;\n \n-    void fromString(const String & str)\n-    {\n-        ReadBufferFromString in(str);\n-        readText(in);\n-    }\n+    void fromString(const String & str);\n };\n \n }\ndiff --git a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.cpp b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.cpp\nindex 5affd77ac7b4..37ef004dd559 100644\n--- a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.cpp\n+++ b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.cpp\n@@ -292,16 +292,10 @@ void ReplicatedMergeTreeRestartingThread::updateQuorumIfWeHavePart()\n \n void ReplicatedMergeTreeRestartingThread::activateReplica()\n {\n-    auto host_port = storage.context.getInterserverIOAddress();\n     auto zookeeper = storage.getZooKeeper();\n \n-    /// How other replicas can access this.\n-    ReplicatedMergeTreeAddress address;\n-    address.host = host_port.first;\n-    address.replication_port = host_port.second;\n-    address.queries_port = storage.context.getTCPPort();\n-    address.database = storage.database_name;\n-    address.table = storage.table_name;\n+    /// How other replicas can access this one.\n+    ReplicatedMergeTreeAddress address = storage.getReplicatedMergeTreeAddress();\n \n     String is_active_path = storage.replica_path + \"/is_active\";\n \ndiff --git a/dbms/src/Storages/StorageReplicatedMergeTree.cpp b/dbms/src/Storages/StorageReplicatedMergeTree.cpp\nindex 3e371816533b..2ee8770f77f3 100644\n--- a/dbms/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/dbms/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -3004,6 +3004,10 @@ void StorageReplicatedMergeTree::rename(const String & new_path_to_db, const Str\n     table_name = new_table_name;\n     full_path = new_full_path;\n \n+    /// Update table name in zookeeper\n+    auto zookeeper = getZooKeeper();\n+    zookeeper->set(replica_path + \"/host\", getReplicatedMergeTreeAddress().toString());\n+\n     /// TODO: You can update names of loggers.\n }\n \n@@ -3766,4 +3770,17 @@ void StorageReplicatedMergeTree::clearBlocksInPartition(\n     LOG_TRACE(log, \"Deleted \" << to_delete_futures.size() << \" deduplication block IDs in partition ID \" << partition_id);\n }\n \n+ReplicatedMergeTreeAddress StorageReplicatedMergeTree::getReplicatedMergeTreeAddress() const\n+{\n+    auto host_port = context.getInterserverIOAddress();\n+\n+    ReplicatedMergeTreeAddress res;\n+    res.host = host_port.first;\n+    res.replication_port = host_port.second;\n+    res.queries_port = context.getTCPPort();\n+    res.database = database_name;\n+    res.table = table_name;\n+    return res;\n+}\n+\n }\ndiff --git a/dbms/src/Storages/StorageReplicatedMergeTree.h b/dbms/src/Storages/StorageReplicatedMergeTree.h\nindex 457e834ea1cb..0cb6dbb004ce 100644\n--- a/dbms/src/Storages/StorageReplicatedMergeTree.h\n+++ b/dbms/src/Storages/StorageReplicatedMergeTree.h\n@@ -17,6 +17,7 @@\n #include <Storages/MergeTree/AbandonableLockInZooKeeper.h>\n #include <Storages/MergeTree/BackgroundProcessingPool.h>\n #include <Storages/MergeTree/DataPartsExchange.h>\n+#include <Storages/MergeTree/ReplicatedMergeTreeAddress.h>\n #include <DataTypes/DataTypesNumber.h>\n #include <Common/randomSeed.h>\n #include <Common/ZooKeeper/ZooKeeper.h>\n@@ -451,6 +452,9 @@ class StorageReplicatedMergeTree : public ext::shared_ptr_helper<StorageReplicat\n     void clearBlocksInPartition(\n         zkutil::ZooKeeper & zookeeper, const String & partition_id, Int64 min_block_num, Int64 max_block_num);\n \n+    /// Info about how other replicas can access this one.\n+    ReplicatedMergeTreeAddress getReplicatedMergeTreeAddress() const;\n+\n protected:\n     /** If not 'attach', either creates a new table in ZK, or adds a replica to an existing table.\n       */\n",
  "test_patch": "diff --git a/dbms/tests/integration/test_distributed_ddl/configs/users.d/restricted_user.xml b/dbms/tests/integration/test_distributed_ddl/configs/users.d/restricted_user.xml\nnew file mode 100644\nindex 000000000000..5b6084eea7b2\n--- /dev/null\n+++ b/dbms/tests/integration/test_distributed_ddl/configs/users.d/restricted_user.xml\n@@ -0,0 +1,16 @@\n+<yandex>\n+    <users>\n+    \t<restricted_user>\n+    \t\t<password></password>\n+\t        <profile>default</profile>\n+\t        <quota>default</quota>\n+            <networks>\n+                    <ip>::/0</ip>\n+            </networks>\n+\n+\t        <allow_databases>\n+\t           <database>db1</database>\n+\t        </allow_databases>\n+    \t</restricted_user>\n+    </users>\n+</yandex>\ndiff --git a/dbms/tests/integration/test_distributed_ddl/test.py b/dbms/tests/integration/test_distributed_ddl/test.py\nindex 8b7e46443d55..8621f723ac12 100755\n--- a/dbms/tests/integration/test_distributed_ddl/test.py\n+++ b/dbms/tests/integration/test_distributed_ddl/test.py\n@@ -315,6 +315,24 @@ def test_macro(started_cluster):\n     ddl_check_query(instance, \"DROP TABLE IF EXISTS distr ON CLUSTER '{cluster}'\")\n     ddl_check_query(instance, \"DROP TABLE IF EXISTS tab ON CLUSTER '{cluster}'\")\n \n+\n+def test_allowed_databases(started_cluster):\n+    instance = cluster.instances['ch2']\n+    instance.query(\"CREATE DATABASE IF NOT EXISTS db1 ON CLUSTER cluster\")\n+    instance.query(\"CREATE DATABASE IF NOT EXISTS db2 ON CLUSTER cluster\")\n+\n+    instance.query(\"CREATE TABLE db1.t1 ON CLUSTER cluster (i Int8) ENGINE = Memory\", settings={\"user\" : \"restricted_user\"})\n+    \n+    with pytest.raises(Exception):\n+        instance.query(\"CREATE TABLE db2.t2 ON CLUSTER cluster (i Int8) ENGINE = Memory\", settings={\"user\" : \"restricted_user\"})\n+    with pytest.raises(Exception):\n+        instance.query(\"CREATE TABLE t3 ON CLUSTER cluster (i Int8) ENGINE = Memory\", settings={\"user\" : \"restricted_user\"})\n+    with pytest.raises(Exception):\n+        instance.query(\"DROP DATABASE db2 ON CLUSTER cluster\", settings={\"user\" : \"restricted_user\"})\n+\n+    instance.query(\"DROP DATABASE db1 ON CLUSTER cluster\", settings={\"user\" : \"restricted_user\"})\n+\n+\n if __name__ == '__main__':\n     with contextmanager(started_cluster)() as cluster:\n        for name, instance in cluster.instances.items():\ndiff --git a/dbms/tests/queries/0_stateless/00446_clear_column_in_partition_zookeeper.sql b/dbms/tests/queries/0_stateless/00446_clear_column_in_partition_zookeeper.sql\nindex 0ace86c2e5e9..7625c6e01b1f 100644\n--- a/dbms/tests/queries/0_stateless/00446_clear_column_in_partition_zookeeper.sql\n+++ b/dbms/tests/queries/0_stateless/00446_clear_column_in_partition_zookeeper.sql\n@@ -61,11 +61,3 @@ ALTER TABLE test.clear_column1 CLEAR COLUMN s IN PARTITION '200002';\n ALTER TABLE test.clear_column1 CLEAR COLUMN s IN PARTITION '200012', CLEAR COLUMN i IN PARTITION '200012';\n -- Drop empty partition also Ok\n ALTER TABLE test.clear_column1 DROP PARTITION '200012', DROP PARTITION '200011';\n-\n-\n--- check optimize for non-leader replica (it is not related with CLEAR COLUMN)\n-OPTIMIZE TABLE test.clear_column1;\n-OPTIMIZE TABLE test.clear_column2;\n-\n-DROP TABLE IF EXISTS test.clear_column1;\n-DROP TABLE IF EXISTS test.clear_column2;\ndiff --git a/dbms/tests/queries/0_stateless/00620_optimize_on_nonleader_replica_zookeeper.reference b/dbms/tests/queries/0_stateless/00620_optimize_on_nonleader_replica_zookeeper.reference\nnew file mode 100644\nindex 000000000000..087a2f3b9d70\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00620_optimize_on_nonleader_replica_zookeeper.reference\n@@ -0,0 +1,2 @@\n+0\t1\t1\n+0\t1\t2\ndiff --git a/dbms/tests/queries/0_stateless/00620_optimize_on_nonleader_replica_zookeeper.sql b/dbms/tests/queries/0_stateless/00620_optimize_on_nonleader_replica_zookeeper.sql\nnew file mode 100644\nindex 000000000000..f66ab550bd4b\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00620_optimize_on_nonleader_replica_zookeeper.sql\n@@ -0,0 +1,20 @@\n+DROP TABLE IF EXISTS test.clear_column1;\n+DROP TABLE IF EXISTS test.clear_column2;\n+CREATE TABLE test.clear_column1 (p Int64, i Int64, v UInt64) ENGINE = ReplicatedReplacingMergeTree('/clickhouse/tables/test/clear_column', '1', v) PARTITION BY p ORDER BY i;\n+CREATE TABLE test.clear_column2 (p Int64, i Int64, v UInt64) ENGINE = ReplicatedReplacingMergeTree('/clickhouse/tables/test/clear_column', '2', v) PARTITION BY p ORDER BY i;\n+\n+INSERT INTO test.clear_column1 VALUES (0, 1, 0);\n+INSERT INTO test.clear_column1 VALUES (0, 1, 1);\n+\n+OPTIMIZE TABLE test.clear_column1;\n+OPTIMIZE TABLE test.clear_column2;\n+SELECT * FROM test.clear_column1;\n+\n+RENAME TABLE test.clear_column2 TO test.clear_column3;\n+\n+INSERT INTO test.clear_column1 VALUES (0, 1, 2);\n+OPTIMIZE TABLE test.clear_column3;\n+SELECT * FROM test.clear_column1;\n+\n+DROP TABLE IF EXISTS test.clear_column1;\n+DROP TABLE IF EXISTS test.clear_column2;\n\\ No newline at end of file\n",
  "problem_statement": "allow_databases restriction still allows distributed DDL access\n(version 1.1.54358)\r\n\r\nI have a user restricted to a single database, but distributed queries like `CREATE database x on cluster large` still work, as it seems that it skips the permissions checks and uses the permissions of user defined in the `<remote_servers>`, which according to [the docs](http://clickhouse-docs.readthedocs.io/en/latest/access_rights.html) \"must not have substantial restrictions\" so the user and password provided in \"remote_servers\" has full access.\r\n\r\nhave I configured something incorrectly or is this a bug?\r\n\r\n```xml\r\n<testuser>\r\n    <password_sha256_hex>b848c5a3fe10b63b864c7f10c1efbbcd03cb50580ff3534817b5add512b3c7a8</password_sha256_hex>\r\n    <networks>\r\n        <ip>127.0.0.1</ip>\r\n    </networks>\r\n    <profile>default</profile>\r\n    <quota>default</quota>\r\n    <allow_databases>\r\n       <database>testuser</database>\r\n    </allow_databases>\r\n</testuser>\r\n```\r\n\r\nMy cluster is configured thus:\r\n\r\n```xml\r\n<remote_servers>\r\n    <large>\r\n        <shard>\r\n            <replica>\r\n                <host>xxxx</host>\r\n                <port>9000</port>\r\n                <user>cluster</user>\r\n                <password>{{CLUSTER_PASSWORD}}</password>\r\n            </replica>\r\n            <replica>\r\n                <host>xxxxm</host>\r\n                <port>9000</port>\r\n                <user>cluster</user>\r\n                <password>{{CLUSTER_PASSWORD}}</password>\r\n            </replica>\r\n        </shard>\r\n```\n",
  "hints_text": "",
  "created_at": "2018-04-17T19:37:53Z",
  "modified_files": [
    "dbms/src/DataStreams/IBlockInputStream.h",
    "dbms/src/DataStreams/IProfilingBlockInputStream.h",
    "dbms/src/Interpreters/Context.cpp",
    "dbms/src/Interpreters/Context.h",
    "dbms/src/Interpreters/DDLWorker.cpp",
    "dbms/src/Interpreters/DDLWorker.h",
    "dbms/src/Interpreters/InterpreterAlterQuery.cpp",
    "dbms/src/Interpreters/InterpreterCreateQuery.cpp",
    "dbms/src/Interpreters/InterpreterDropQuery.cpp",
    "dbms/src/Interpreters/InterpreterKillQueryQuery.cpp",
    "dbms/src/Interpreters/InterpreterRenameQuery.cpp",
    "dbms/src/Interpreters/ProcessList.cpp",
    "dbms/src/Interpreters/ProcessList.h",
    "b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAddress.cpp",
    "dbms/src/Storages/MergeTree/ReplicatedMergeTreeAddress.h",
    "dbms/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.cpp",
    "dbms/src/Storages/StorageReplicatedMergeTree.cpp",
    "dbms/src/Storages/StorageReplicatedMergeTree.h"
  ],
  "modified_test_files": [
    "b/dbms/tests/integration/test_distributed_ddl/configs/users.d/restricted_user.xml",
    "dbms/tests/integration/test_distributed_ddl/test.py",
    "dbms/tests/queries/0_stateless/00446_clear_column_in_partition_zookeeper.sql",
    "b/dbms/tests/queries/0_stateless/00620_optimize_on_nonleader_replica_zookeeper.reference",
    "b/dbms/tests/queries/0_stateless/00620_optimize_on_nonleader_replica_zookeeper.sql"
  ]
}