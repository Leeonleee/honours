{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 36215,
  "instance_id": "ClickHouse__ClickHouse-36215",
  "issue_numbers": [
    "34647",
    "34953"
  ],
  "base_commit": "6e89fc4542bc08e269e6fe3fcc082da83b48b5ed",
  "patch": "diff --git a/src/Compression/CompressedReadBufferFromFile.cpp b/src/Compression/CompressedReadBufferFromFile.cpp\nindex 9efb3c92cde1..a959da2c3ae4 100644\n--- a/src/Compression/CompressedReadBufferFromFile.cpp\n+++ b/src/Compression/CompressedReadBufferFromFile.cpp\n@@ -62,7 +62,7 @@ void CompressedReadBufferFromFile::seek(size_t offset_in_compressed_file, size_t\n {\n     /// Nothing to do if we already at required position\n     if (!size_compressed && static_cast<size_t>(file_in.getPosition()) == offset_in_compressed_file && /// correct position in compressed file\n-        (offset() == offset_in_decompressed_block /// correct position in buffer or\n+        ((!buffer().empty() && offset() == offset_in_decompressed_block)     /// correct position in buffer or\n          || nextimpl_working_buffer_offset == offset_in_decompressed_block)) /// we will move our position to correct one\n         return;\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02267_empty_arrays_read_reverse.reference b/tests/queries/0_stateless/02267_empty_arrays_read_reverse.reference\nnew file mode 100644\nindex 000000000000..cc0cc5714d91\n--- /dev/null\n+++ b/tests/queries/0_stateless/02267_empty_arrays_read_reverse.reference\n@@ -0,0 +1,1 @@\n+['x']\t0\t['1','2','3','4','5','6']\ndiff --git a/tests/queries/0_stateless/02267_empty_arrays_read_reverse.sql b/tests/queries/0_stateless/02267_empty_arrays_read_reverse.sql\nnew file mode 100644\nindex 000000000000..7c1cf47c5408\n--- /dev/null\n+++ b/tests/queries/0_stateless/02267_empty_arrays_read_reverse.sql\n@@ -0,0 +1,22 @@\n+DROP TABLE IF EXISTS t_02267;\n+\n+CREATE TABLE t_02267\n+(\n+    a Array(String),\n+    b UInt32,\n+    c Array(String)\n+)\n+ENGINE = MergeTree\n+ORDER BY b\n+SETTINGS index_granularity = 500;\n+\n+INSERT INTO t_02267 (b, a, c) SELECT 0, ['x'],  ['1','2','3','4','5','6'] FROM numbers(1) ;\n+INSERT INTO t_02267 (b, a, c) SELECT 1, [],     ['1','2','3','4','5','6'] FROM numbers(300000);\n+\n+OPTIMIZE TABLE t_02267 FINAL;\n+\n+SELECT * FROM t_02267 WHERE hasAll(a, ['x'])\n+ORDER BY b DESC\n+SETTINGS max_threads=1, max_block_size=1000;\n+\n+DROP TABLE IF EXISTS t_02267;\n",
  "problem_statement": "Column compression broken few minutes after data inserted\nClickhouse version: 22.1.3.\r\n\r\nI'm creating and importing data to the new table based on join from two tables like this:\r\n`insert into my_database_{country_iso}.fulltext_new select keyword, stems, search_volumes.search_volume, difficulty, cpc, monthly_sv, peak_month, yoy_change, serp_features from my_database_{country_iso}.search_volumes as search_volumes final left any join my_database_{country_iso}.keyword_data using (keyword) SETTINGS join_use_nulls=1, join_any_take_last_row=1`\r\n\r\nStructure of the output table is 1:1 with selected columns:\r\n```\r\n  `keyword` String,\r\n  `stems` Array(String),\r\n  `search_volume` Int32,\r\n  `difficulty` Int8 Default -100,\r\n  `cpc` Float32,\r\n  `monthly_sv` String,\r\n  `peak_month` Date,\r\n  `yoy_change` Float32,\r\n  `serp_features` Array(String),\r\n```\r\n\r\nAfter importing those data everything works fine around 1 minute and after that (using the same select queries) I'm getting this error for some queries:\r\n```\r\nReceived exception from server (version 22.1.3):\r\nCode: 271. DB::Exception: Received from localhost:9000. DB::Exception: Data compressed with different methods, given method byte 0x1b, previous method byte 0x82: (while reading column serp_features): (while reading from part /var/lib/clickhouse/store/f3d/f3d3328c-24b4-4f71-b40e-b2650ac5229e/all_1_34_2/ from mark 64722 with max_rows_to_read = 195): While executing MergeTreeReverse. (CANNOT_DECOMPRESS)\r\n```\r\n\r\nThe SELECT is for example following:\r\n`select * from my_database_us.fulltext where hasAll(stems, ['something']) order by search_volume desc`\r\n\r\nWhat is stranger - the query seems to be working until I use ordering using the column search_volume but I totally don't know why because from the error log it seems like it has some problem with column serp_features. But what is strangest for me is that it works after importing. But just for few seconds/minutes and then start showing this error (even for the same queries like before).\r\n\r\nFull log:\r\n```\r\n2022.02.16 12:57:26.870809 [ 334594 ] {55202cee-124e-4626-a3b4-e31d5388e410} <Error> TCPHandler: Code: 271. DB::Exception: Data compressed with different methods, given method byte 0x1b, previous method byte 0x82: (while reading column serp_features): (while reading from part /var/lib/clickhouse/store/f3d/f3d3328c-24b4-4f71-b40e-b2650ac5229e/all_1_34_2/ from mark 64722 with max_rows_to_read = 195): While executing MergeTreeReverse. (CANNOT_DECOMPRESS), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xa82d07a in /usr/bin/clickhouse\r\n1. DB::CompressedReadBufferBase::readCompressedData(unsigned long&, unsigned long&, bool) @ 0x130929f8 in /usr/bin/clickhouse\r\n2. DB::CompressedReadBufferFromFile::nextImpl() @ 0x130940d5 in /usr/bin/clickhouse\r\n3. ? @ 0x1328c4c2 in /usr/bin/clickhouse\r\n4. DB::ISerialization::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::__1::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >*) const @ 0x132536f5 in /usr/bin/clickhouse\r\n5. DB::SerializationArray::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::__1::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >*) const @ 0x1325f4d1 in /usr/bin/clickhouse\r\n6. DB::MergeTreeReaderWide::readData(DB::NameAndTypePair const&, COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, bool, unsigned long, unsigned long, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >&, bool) @ 0x143a5f0f in /usr/bin/clickhouse\r\n7. DB::MergeTreeReaderWide::readRows(unsigned long, unsigned long, bool, unsigned long, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0x143a4e8b in /usr/bin/clickhouse\r\n8. DB::MergeTreeRangeReader::DelayedStream::finalize(std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0x14b1fb8e in /usr/bin/clickhouse\r\n9. DB::MergeTreeRangeReader::continueReadingChain(DB::MergeTreeRangeReader::ReadResult&, unsigned long&) @ 0x14b23c79 in /usr/bin/clickhouse\r\n10. DB::MergeTreeRangeReader::read(unsigned long, std::__1::deque<DB::MarkRange, std::__1::allocator<DB::MarkRange> >&) @ 0x14b22cd3 in /usr/bin/clickhouse\r\n11. DB::MergeTreeBaseSelectProcessor::readFromPartImpl() @ 0x14b18c08 in /usr/bin/clickhouse\r\n12. DB::MergeTreeReverseSelectProcessor::readFromPart() @ 0x14b37485 in /usr/bin/clickhouse\r\n13. DB::MergeTreeBaseSelectProcessor::generate() @ 0x14b18480 in /usr/bin/clickhouse\r\n14. DB::ISource::tryGenerate() @ 0x148414b5 in /usr/bin/clickhouse\r\n15. DB::ISource::work() @ 0x1484107a in /usr/bin/clickhouse\r\n16. DB::SourceWithProgress::work() @ 0x14a8c662 in /usr/bin/clickhouse\r\n17. DB::ExecutionThreadContext::executeTask() @ 0x14860b23 in /usr/bin/clickhouse\r\n18. DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) @ 0x1485539e in /usr/bin/clickhouse\r\n19. ? @ 0x14856b22 in /usr/bin/clickhouse\r\n20. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xa86f4b7 in /usr/bin/clickhouse\r\n21. ? @ 0xa872ebd in /usr/bin/clickhouse\r\n22. ? @ 0x7fef318ec609 in ?\r\n23. __clone @ 0x7fef31813293 in ?\r\n```\r\n\r\nIt seems like some problem with column compression. But both tables use native compression (nothing special). Two input tables were created in different CH versions so if CH changed compression then it could be something with that but I don't think so.\nAttempt to read after eof\n DB::Exception: Attempt to read after eof: (while reading column http_user): (while reading from part /xxxxx/01/store/b4f/b4f7cad2-943c-49b4-b8e1-44399bcc45a6/457190_82_107_4/ from mark 0 with max_rows_to_read = 8192): While executing MergeTreeReverse. (ATTEMPT_TO_READ_AFTER_EOF), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xa82d07a in /home/clickhouse/bin/clickhouse-server\r\n1. DB::throwReadAfterEOF() @ 0xa83e4db in /home/clickhouse/bin/clickhouse-server\r\n2. ? @ 0xa87c16b in /home/clickhouse/bin/clickhouse-server\r\n3. ? @ 0x1328c4fc in /home/clickhouse/bin/clickhouse-server\r\n4. DB::ISerialization::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::__1::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >*) const @ 0x132536f5 in /home/clickhouse/bin/clickhouse-server\r\n5. DB::SerializationArray::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::__1::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >*) const @ 0x1325f4d1 in /home/clickhouse/bin/clickhouse-server\r\n6. DB::MergeTreeReaderWide::readData(DB::NameAndTypePair const&, COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, bool, unsigned long, unsigned long, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >&, bool) @ 0x143a5f0f in /home/clickhouse/bin/clickhouse-server\r\n7. DB::MergeTreeReaderWide::readRows(unsigned long, unsigned long, bool, unsigned long, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0x143a4e8b in /home/clickhouse/bin/clickhouse-server\r\n8. DB::MergeTreeRangeReader::DelayedStream::finalize(std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0x14b1fb8e in /home/clickhouse/bin/clickhouse-server\r\n9. DB::MergeTreeRangeReader::continueReadingChain(DB::MergeTreeRangeReader::ReadResult&, unsigned long&) @ 0x14b23c79 in /home/clickhouse/bin/clickhouse-server\r\n10. DB::MergeTreeRangeReader::read(unsigned long, std::__1::deque<DB::MarkRange, std::__1::allocator<DB::MarkRange> >&) @ 0x14b22cd3 in /home/clickhouse/bin/clickhouse-server\r\n11. DB::MergeTreeBaseSelectProcessor::readFromPartImpl() @ 0x14b18c08 in /home/clickhouse/bin/clickhouse-server\r\n12. DB::MergeTreeReverseSelectProcessor::readFromPart() @ 0x14b37485 in /home/clickhouse/bin/clickhouse-server\r\n13. DB::MergeTreeBaseSelectProcessor::generate() @ 0x14b18480 in /home/clickhouse/bin/clickhouse-server\r\n14. DB::ISource::tryGenerate() @ 0x148414b5 in /home/clickhouse/bin/clickhouse-server\r\n15. DB::ISource::work() @ 0x1484107a in /home/clickhouse/bin/clickhouse-server\r\n16. DB::SourceWithProgress::work() @ 0x14a8c662 in /home/clickhouse/bin/clickhouse-server\r\n17. DB::ExecutionThreadContext::executeTask() @ 0x14860b23 in /home/clickhouse/bin/clickhouse-server\r\n18. DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) @ 0x1485539e in /home/clickhouse/bin/clickhouse-server\r\n19. ? @ 0x14856b22 in /home/clickhouse/bin/clickhouse-server\r\n20. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xa86f4b7 in /home/clickhouse/bin/clickhouse-server\r\n21. ? @ 0xa872ebd in /home/clickhouse/bin/clickhouse-server\r\n22. start_thread @ 0x7dd5 in /usr/lib64/libpthread-2.17.so\r\n23. __clone @ 0xfdead in /usr/lib64/libc-2.17.so\r\n (version 22.1.3.7 (official build))\n",
  "hints_text": ">After importing those data everything works fine around 1 minute and after that (using the same select queries)\r\n\r\nmore likely when you insert data it creates compact parts, after some time they merged into wide parts.\r\n\r\nCan you please share `show create table my_database_us.fulltext` probably it's related to table ordeby\r\n\r\nAnd please share `select * from system.parts where table = 'fulltext'`\r\n\nAlso try to execute your query with  settings `.... order by search_volume desc settings optimize_read_in_order=0`\n@den-crane With optimize_read_in_order=0 it works. Create table here:\r\n\r\n```\r\nCREATE TABLE my_database_us.fulltext\r\n(\r\n    `keyword` String,\r\n    `stems` Array(String),\r\n    `search_volume` UInt32,\r\n    `difficulty` Int8 DEFAULT -100,\r\n    `cpc` Float32,\r\n    `monthly_sv` String,\r\n    `peak_month` Date,\r\n    `yoy_change` Float32,\r\n    `serp_features` Array(String),\r\n    INDEX stems_filter stems TYPE bloom_filter(0.01) GRANULARITY 1\r\n)\r\nENGINE = MergeTree\r\nORDER BY search_volume\r\nSETTINGS index_granularity = 500 \r\n```\r\n\r\nSELECT from system parts -> if you need it, can I send you that in DM please?\r\n\n>SELECT from system parts -> if you need it, can I send you that in DM please?\r\n\r\nYes. Please.\nAlso please share `select name, value from from system.settings where changed`\nrepro:\r\n\r\n```\r\n$ cat x.sql\r\ndrop table if exists f;\r\n\r\nCREATE TABLE f\r\n(\r\n    a Array(String),\r\n    b UInt32,\r\n    c Array(String)\r\n)\r\nENGINE = MergeTree\r\nORDER BY b\r\nSETTINGS index_granularity = 500;\r\n\r\ninsert into f(b,a,c) select 0,  ['x'],  ['1','2','3','4','5','6'] from numbers(1) ;\r\ninsert into f(b,a,c) select 1,  [],     ['1','2','3','4','5','6'] from numbers(300000);\r\n\r\noptimize table f ;\r\n\r\nSELECT * FROM f where  hasAll(a, ['x']) order by b desc settings max_threads=1, max_block_size=1000;\r\n\r\n\r\n$ clickhouse-client -mn < x.sql\r\nReceived exception from server (version 22.1.3):\r\nCode: 32. DB::Exception: Received from localhost:9000. DB::Exception:\r\n Attempt to read after eof: (while reading column a): \r\n(while reading from part /var/lib/clickhouse/store/31d/31d10c23-c7a9-43a5-a315-b6b7192e08db/all_1_2_1/ from mark 0 with max_rows_to_read = 1000): While executing MergeTreeReverse. (ATTEMPT_TO_READ_AFTER_EOF)\r\n(query: SELECT * FROM f where  hasAll(a, ['x']) order by b desc settings max_threads=1, max_block_size=1000;)\r\n```\ndoes not reproduce with 22.3\r\n\r\ndoes not reproduce with optimize_read_in_order=0\r\n\r\n```\r\ncl --optimize_read_in_order=0 < x.sql\r\n['x']\t0\t['1','2','3','4','5','6']\r\n```\n@CurtizJ is it fixed in https://github.com/ClickHouse/ClickHouse/pull/34327 ?\nYes, it has been fixed in #34327.\nI've reproduced it on 22.3 and on master.\nddl\r\nCREATE TABLE if not exists default.session_local on CLUSTER tfs\r\n(\r\n    `last_packet` DateTime CODEC(DoubleDelta),\r\n    `first_packet` DateTime CODEC(DoubleDelta),\r\n    `length` UInt32 ,\r\n    `node` String,\r\n    `uid` String,\r\n    `src_ip` String,\r\n    `src_port` UInt16 ,\r\n    `dst_ip` String,\r\n    `dst_port` UInt16 ,\r\n    `ip_protocol` UInt8 ,\r\n    `tot_packets` UInt32 ,\r\n    `src_packets` UInt32 ,\r\n    `dst_packets` UInt32 ,\r\n    `tot_bytes` UInt32 ,\r\n    `src_bytes` UInt32 ,\r\n    `dst_bytes` UInt32 ,\r\n    `tot_data_bytes` UInt32 ,\r\n    `src_data_bytes` UInt32 ,\r\n    `dst_data_bytes` UInt32 ,\r\n    `source` String,\r\n    `eth_type` String,\r\n    `frag_pkts` UInt32 ,\r\n    `vxlan` UInt32 ,\r\n    `seq_num` Int16 ,\r\n    `community_id` String,\r\n    `conn_state` String,\r\n    `packet_pos` Array(Int64) ,\r\n    `src_mac` String,\r\n    `dst_mac` String,\r\n    `vlan` Array(Int64) ,\r\n    `gre_ip` Array(String),\r\n    `tags` Array(String),\r\n    `protocols` Array(String),\r\n    `src_geo` String,\r\n    `dst_geo` String,\r\n    `dst_asn` String,\r\n    `src_asn` String,\r\n    `tcpflags_syn` Array(UInt32) ,\r\n    `tcpflags_fin` Array(UInt32) ,\r\n    `tcpflags_psh` Array(UInt32) ,\r\n    `tcpflags_ack` Array(UInt32) ,\r\n    `tcpflags_syn_ack` Array(UInt32) ,\r\n    `tcpflags_rst_ts` Array(UInt32) ,\r\n    `tcpflags_rst_tc` Array(UInt32) ,\r\n    `tcpflags_gapnum` Array(UInt32) ,\r\n    `tcpflags_retrans` Array(UInt32) ,\r\n    `tcpflags_zerowin_tc` Array(UInt32) ,\r\n    `tcpflags_zerowin_ts` Array(UInt32) ,\r\n    `tcpflags_initwin_tc` Array(UInt32) ,\r\n    `tcpflags_initwin_ts` Array(UInt32) ,\r\n    `tcpflags_retrans_syn` Array(UInt32) ,\r\n    `tcpflags_retrans_synack` Array(UInt32) ,\r\n    `tcpflags_urg` Array(UInt32) ,\r\n    `http_user` Array(String),\r\n    `http_status_code` Array(UInt16) ,\r\n    `http_method` Array(String),\r\n    `http_host` Array(String),\r\n    `http_uri` Array(String),\r\n    `http_authtype` Array(String),\r\n    `http_cookiekey` Array(String),\r\n    `http_response_header` Array(String),\r\n    `http_request_header` Array(String),\r\n    `http_xff_ip` Array(String),\r\n    `http_request_header_value` Array(String),\r\n    `http_referer` Array(String),\r\n    `http_response_header_value` Array(String),\r\n    `http_key` Array(String),\r\n    `http_value` Array(String),\r\n    `snmp_community` Array(String),\r\n    `snmp_version` Array(String),\r\n    `snmp_trap_address` Array(String),\r\n    `file_infos_magic` Array(String),\r\n    `file_infos_filename` Array(String),\r\n    `file_infos_md5` Array(String),\r\n    `email_cc` Array(String),\r\n    `email_bcc` Array(String),\r\n    `email_src` Array(String),\r\n    `email_md5` Array(String),\r\n    `email_dst` Array(String),\r\n    `email_ip` Array(String),\r\n    `email_file_name` Array(String),\r\n    `email_subject` Array(String),\r\n    `smb_version` Array(String),\r\n    `smb_host` Array(String),\r\n    `smb_domain` Array(String),\r\n    `smb_file_name` Array(String),\r\n    `ssh_hassh` Array(String),\r\n    `ssh_key` Array(String),\r\n    `ssh_version` Array(String),\r\n    `ssh_hassh_server` Array(String),\r\n    `cert_remaining_days` Array(Int64),\r\n    `cert_subject_on` Array(String),\r\n    `cert_hash` Array(String),\r\n    `cert_not_after` Array(Int64),\r\n    `cert_issuer_cn` Array(String),\r\n    `cert_issuer_on` Array(String),\r\n    `cert_valid_days` Array(Int64),\r\n    `cert_not_before` Array(Int64),\r\n    `cert_alt` Array(String),\r\n    `cert_subject_cn` Array(String),\r\n    `cert_serial` Array(String),\r\n    `socks_port` Array(UInt16),\r\n    `socks_host` Array(String),\r\n    `socks_user` Array(String),\r\n    `socks_ip` Array(String),\r\n    `tls_server_name` Array(String),\r\n    `tls_cipher` Array(String),\r\n    `tls_ja3_client_str` Array(String),\r\n    `tls_ja3` Array(String),\r\n    `tls_ja3s` Array(String),\r\n    `tls_ja3_server_str` Array(String),\r\n    `icmp_code` Array(String),\r\n    `icmp_type` Array(String),\r\n    `dns_host` Array(String),\r\n    `dns_qt` Array(String),\r\n    `dns_ttl` Array(String),\r\n    `dns_status` Array(String),\r\n    `dns_qc` Array(String),\r\n    `dns_opcode` Array(String),\r\n    `dhcp_host_name` Array(String),\r\n    `dhcp_trans_id` Array(String),\r\n    `dhcp_mac` Array(String),\r\n    `dhcp_type` Array(String),\r\n    `krb5_cname` Array(String),\r\n    `krb5_realm` Array(String),\r\n    `krb5_sname` Array(String),\r\n    `ldap_authtype` Array(String),\r\n    `ldap_bindname` Array(String),\r\n    `mysql_user` Array(String),\r\n    `oracle_user` Array(String),\r\n    `postgresql_user` Array(String),\r\n    INDEX idx_uid uid TYPE minmax GRANULARITY 1,\r\n    INDEX idx_srcip src_ip TYPE bloom_filter(0.025) GRANULARITY 1,\r\n    INDEX idx_dstip dst_ip TYPE bloom_filter(0.025) GRANULARITY 1\r\n)\r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{layer}-{shard}/session_local', '{replica}')\r\nPARTITION BY toRelativeHourNum(last_packet)\r\nPRIMARY KEY last_packet\r\nORDER BY last_packet\r\nSETTINGS index_granularity = 8192;\r\n\r\nCREATE TABLE if not exists default.session on CLUSTER tfs AS default.session_local\r\nENGINE = Distributed('tfs','default','session_local', intHash64(last_packet));\nsql  \r\nSELECT uid,last_packet,ip_protocol,first_packet,src_ip,src_port,dst_ip,dst_port,tot_packets,http_xff_ip,http_user,http_status_code,http_method,http_referer FROM session WHERE (last_packet BETWEEN '2022-02-22 09:20:50' AND '2022-03-01 09:20:50') and has(protocols,'http') order by last_packet desc LIMIT 10 FORMAT TabSeparatedWithNamesAndTypes;\n2022.03.01 09:57:37.993015 [ 41257 ] {} <Warning> default.session_local (ReplicatedMergeTreePartCheckThread): Checking part 457190_82_107_4\r\n2022.03.01 09:57:37.993857 [ 41257 ] {} <Warning> default.session_local (ReplicatedMergeTreePartCheckThread): Checking data of part 457190_82_107_4.\r\n2022.03.01 09:57:38.005506 [ 41129 ] {4bf28373-2aaf-4fae-96e5-aab662e46de7} <Error> executeQuery: Code: 32. DB::Exception: Attempt to read after eof: (while reading column http_user): (while reading from part /data0/clickhouse/01/store/b4f/b4f7cad2-943c-49b4-b8e1-44399bcc45a6/457190_82_107_4/ from mark 0 with max_rows_to_read = 8192): While executing MergeTreeReverse. (ATTEMPT_TO_READ_AFTER_EOF) (version 22.1.3.7 (official build)) (from [::1]:33412) (in query: SELECT uid,last_packet,ip_protocol,first_packet,src_ip,src_port,dst_ip,dst_port,tot_packets,http_xff_ip,http_user,http_status_code,http_method,http_referer FROM session WHERE (last_packet BETWEEN '2022-02-22 09:20:50' AND '2022-03-01 09:20:50') and has(protocols,'http') order by last_packet desc LIMIT 10 FORMAT TabSeparatedWithNamesAndTypes;), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xa82d07a in /home/clickhouse/bin/clickhouse-server\r\n1. DB::throwReadAfterEOF() @ 0xa83e4db in /home/clickhouse/bin/clickhouse-server\r\n2. ? @ 0xa87c16b in /home/clickhouse/bin/clickhouse-server\r\n3. ? @ 0x1328c4fc in /home/clickhouse/bin/clickhouse-server\r\n4. DB::ISerialization::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::__1::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >*) const @ 0x132536f5 in /home/clickhouse/bin/clickhouse-server\r\n5. DB::SerializationArray::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::__1::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >*) const @ 0x1325f4d1 in /home/clickhouse/bin/clickhouse-server\r\n6. DB::MergeTreeReaderWide::readData(DB::NameAndTypePair const&, COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, bool, unsigned long, unsigned long, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >&, bool) @ 0x143a5f0f in /home/clickhouse/bin/clickhouse-server\r\n7. DB::MergeTreeReaderWide::readRows(unsigned long, unsigned long, bool, unsigned long, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0x143a4e8b in /home/clickhouse/bin/clickhouse-server\r\n8. DB::MergeTreeRangeReader::DelayedStream::finalize(std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0x14b1fb8e in /home/clickhouse/bin/clickhouse-server\r\n9. DB::MergeTreeRangeReader::continueReadingChain(DB::MergeTreeRangeReader::ReadResult&, unsigned long&) @ 0x14b23c79 in /home/clickhouse/bin/clickhouse-server\r\n10. DB::MergeTreeRangeReader::read(unsigned long, std::__1::deque<DB::MarkRange, std::__1::allocator<DB::MarkRange> >&) @ 0x14b22cd3 in /home/clickhouse/bin/clickhouse-server\r\n11. DB::MergeTreeBaseSelectProcessor::readFromPartImpl() @ 0x14b18c08 in /home/clickhouse/bin/clickhouse-server\r\n12. DB::MergeTreeReverseSelectProcessor::readFromPart() @ 0x14b37485 in /home/clickhouse/bin/clickhouse-server\r\n13. DB::MergeTreeBaseSelectProcessor::generate() @ 0x14b18480 in /home/clickhouse/bin/clickhouse-server\r\n14. DB::ISource::tryGenerate() @ 0x148414b5 in /home/clickhouse/bin/clickhouse-server\r\n15. DB::ISource::work() @ 0x1484107a in /home/clickhouse/bin/clickhouse-server\r\n16. DB::SourceWithProgress::work() @ 0x14a8c662 in /home/clickhouse/bin/clickhouse-server\r\n17. DB::ExecutionThreadContext::executeTask() @ 0x14860b23 in /home/clickhouse/bin/clickhouse-server\r\n18. DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) @ 0x1485539e in /home/clickhouse/bin/clickhouse-server\r\n19. ? @ 0x14856b22 in /home/clickhouse/bin/clickhouse-server\r\n20. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xa86f4b7 in /home/clickhouse/bin/clickhouse-server\r\n21. ? @ 0xa872ebd in /home/clickhouse/bin/clickhouse-server\r\n22. start_thread @ 0x7dd5 in /usr/lib64/libpthread-2.17.so\r\n23. __clone @ 0xfdead in /usr/lib64/libc-2.17.so\n![image](https://user-images.githubusercontent.com/77827496/156090947-3fea1cf6-5bba-4340-b9d5-ddc6c33a5ed9.png)\r\n\nversion = 22.1.3.7\nIt is likely the part is broken for some reason. An exception was thrown for Array column which we start reading from the very beginning. Would it be possible to send this broken part somehow to investigate the issue?\nThe part is `/data0/clickhouse/01/store/b4f/b4f7cad2-943c-49b4-b8e1-44399bcc45a6/457190_82_107_4/`. Probably, just `http_user.*` column would be enough\n[http_user.zip](https://github.com/ClickHouse/ClickHouse/files/8161138/http_user.zip)\r\n\n@KochetovNicolai \r\nhelp me\nI have attached the file and it seem to be correct, at least I can read from it.\r\n```\r\nSELECT\r\n    http_user,\r\n    count()\r\nFROM http_user\r\nGROUP BY http_user\r\n\r\nQuery id: d30e28d8-8896-4a54-9740-58d3f67c4d83\r\n\r\n\u250c\u2500http_user\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500count()\u2500\u2510\r\n\u2502 []              \u2502  239999 \u2502\r\n\u2502 ['itworkzhang'] \u2502       1 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nProbably there was some bug during reading. By now, the only thing I can suggest is to update ClickHouse.\nI'm hitting an issue that seems to be the same as this one, both with `22.3.3.44` and `22.3.2.2`. When reverting to the previous LTS release (`21.8.15.7`), I don't hit this issue anymore.\r\nThe error message looks like this:\r\n```\r\ncode: 32, message: Attempt to read after eof: (while reading column foo): (while reading from part /var/lib/clickhouse/store/a4d/a4db5c3c-6ffd-4071-b101-205eee45d10a/20220408_1835_1851_2/ from mark 13 with max_rows_to_read = 8192): While executing MergeTreeReverse\r\n```\r\nThe table is using the `ReplacingMergeTree` engine and I hit this issue with queries that lookup a certain amount of data. Unfortunately, I don't have clear steps to reproduce but I hope the information I provided could help the investigation.\nI'm hitting this issue as well with 22.3.2.1. Never observed this on 21.x.\r\n\r\nThis **unstable** error may happen during MergeTreeReverse execution when I try to select most recent data which is constantly inserted (logs) using DESC ordering by Timestamp field (PK). In my case this error is also always related to a column X of type **Array(String)**, which is the only array field in a table.\r\n\r\nQuery is very simple, looks like that:\r\n\r\n**SELECT * FROM $distributed_table WHERE Timestamp >= $from AND Timestamp <= $now ORDER BY Timestamp DESC;**\r\n\r\nIf I use ASC ordering - query performs without errors.\r\nIf I don't use SELECT * or exclude column X from projection and WHERE clause - query performs without errors.\r\nIf I stop data insertion - I can read already inserted data without issues, so data parts are not broken.\r\n\r\nMy only guess is that Clickhouse tries to read column's data file at some offset which is already present in index (or .mrk file), but actual length of a file **at that moment** is less than expected. \nduplicate ? https://github.com/ClickHouse/ClickHouse/issues/34647#issuecomment-1088215628\r\nhttps://github.com/ClickHouse/ClickHouse/pull/34327\n> duplicate ? [#34647 (comment)](https://github.com/ClickHouse/ClickHouse/issues/34647#issuecomment-1088215628) #34327\r\n\r\nDon't think so. #34327 was merged into master on Feb 7, but this issue is related to recent builds.\n@tephrocactus \r\n\r\n>If I stop data insertion - I can read already inserted data without issues, so data parts are not broken.\r\n\r\nCH does not expose not finished inserts to queries.\r\nProbably the issue is related either compact parts (for test you can disable them for this table temporary) or the issue disappears after data merge (for example you insert data with empty arrays and the issue reproduce because all rows have empty array in a part, but after a merge these rows are mixed with rows other parts and the issue stops to reproduce. \r\n",
  "created_at": "2022-04-13T22:18:48Z"
}