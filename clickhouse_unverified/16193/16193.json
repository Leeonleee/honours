{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 16193,
  "instance_id": "ClickHouse__ClickHouse-16193",
  "issue_numbers": [
    "6496"
  ],
  "base_commit": "45119fce4f77dc96bc3edfd3b74948efb532f493",
  "patch": "diff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex a96cb2b89735..cda7833a127e 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -102,6 +102,7 @@ namespace CurrentMetrics\n     extern const Metric Revision;\n     extern const Metric VersionInteger;\n     extern const Metric MemoryTracking;\n+    extern const Metric MaxDDLEntryID;\n }\n \n \n@@ -1011,7 +1012,8 @@ int Server::main(const std::vector<std::string> & /*args*/)\n         int pool_size = config().getInt(\"distributed_ddl.pool_size\", 1);\n         if (pool_size < 1)\n             throw Exception(\"distributed_ddl.pool_size should be greater then 0\", ErrorCodes::ARGUMENT_OUT_OF_BOUND);\n-        global_context->setDDLWorker(std::make_unique<DDLWorker>(pool_size, ddl_zookeeper_path, *global_context, &config(), \"distributed_ddl\"));\n+        global_context->setDDLWorker(std::make_unique<DDLWorker>(pool_size, ddl_zookeeper_path, *global_context, &config(),\n+                                                                 \"distributed_ddl\", \"DDLWorker\", &CurrentMetrics::MaxDDLEntryID));\n     }\n \n     std::unique_ptr<DNSCacheUpdater> dns_cache_updater;\ndiff --git a/src/Common/ErrorCodes.cpp b/src/Common/ErrorCodes.cpp\nindex 52c22c2e371f..ba8741efae70 100644\n--- a/src/Common/ErrorCodes.cpp\n+++ b/src/Common/ErrorCodes.cpp\n@@ -537,6 +537,7 @@\n     M(568, RAFT_ERROR) \\\n     M(569, MULTIPLE_COLUMNS_SERIALIZED_TO_SAME_PROTOBUF_FIELD) \\\n     M(570, DATA_TYPE_INCOMPATIBLE_WITH_PROTOBUF_FIELD) \\\n+    M(571, DATABASE_REPLICATION_FAILED) \\\n     \\\n     M(999, KEEPER_EXCEPTION) \\\n     M(1000, POCO_EXCEPTION) \\\ndiff --git a/src/Common/ZooKeeper/IKeeper.cpp b/src/Common/ZooKeeper/IKeeper.cpp\nindex ad18fdd992aa..94fd291bd123 100644\n--- a/src/Common/ZooKeeper/IKeeper.cpp\n+++ b/src/Common/ZooKeeper/IKeeper.cpp\n@@ -59,7 +59,7 @@ static void addRootPath(String & path, const String & root_path)\n         throw Exception(\"Path cannot be empty\", Error::ZBADARGUMENTS);\n \n     if (path[0] != '/')\n-        throw Exception(\"Path must begin with /\", Error::ZBADARGUMENTS);\n+        throw Exception(\"Path must begin with /, got \" + path, Error::ZBADARGUMENTS);\n \n     if (root_path.empty())\n         return;\ndiff --git a/src/Common/ZooKeeper/ZooKeeper.h b/src/Common/ZooKeeper/ZooKeeper.h\nindex 90d15e2ac4ac..5b37e4d60245 100644\n--- a/src/Common/ZooKeeper/ZooKeeper.h\n+++ b/src/Common/ZooKeeper/ZooKeeper.h\n@@ -194,6 +194,7 @@ class ZooKeeper\n     void removeChildren(const std::string & path);\n \n     using WaitCondition = std::function<bool()>;\n+\n     /// Wait for the node to disappear or return immediately if it doesn't exist.\n     /// If condition is specified, it is used to return early (when condition returns false)\n     /// The function returns true if waited and false if waiting was interrupted by condition.\n@@ -314,8 +315,15 @@ class EphemeralNodeHolder\n         return std::make_shared<EphemeralNodeHolder>(path, zookeeper, false, false, \"\");\n     }\n \n+    void setAlreadyRemoved()\n+    {\n+        need_remove = false;\n+    }\n+\n     ~EphemeralNodeHolder()\n     {\n+        if (!need_remove)\n+            return;\n         try\n         {\n             zookeeper.tryRemove(path);\n@@ -331,6 +339,7 @@ class EphemeralNodeHolder\n     std::string path;\n     ZooKeeper & zookeeper;\n     CurrentMetrics::Increment metric_increment{CurrentMetrics::EphemeralNode};\n+    bool need_remove = true;\n };\n \n using EphemeralNodeHolderPtr = EphemeralNodeHolder::Ptr;\ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex 9bb9ad30f15e..8a96ad88b650 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -421,6 +421,9 @@ class IColumn;\n     M(Bool, optimize_rewrite_sum_if_to_count_if, true, \"Rewrite sumIf() and sum(if()) function countIf() function when logically equivalent\", 0) \\\n     M(UInt64, insert_shard_id, 0, \"If non zero, when insert into a distributed table, the data will be inserted into the shard `insert_shard_id` synchronously. Possible values range from 1 to `shards_number` of corresponding distributed table\", 0) \\\n     M(Bool, allow_experimental_query_deduplication, false, \"Allow sending parts' UUIDs for a query in order to deduplicate data parts if any\", 0) \\\n+    M(Bool, allow_experimental_database_replicated, false, \"Allow to create databases with Replicated engine\", 0) \\\n+    M(UInt64, database_replicated_initial_query_timeout_sec, 300, \"How long initial DDL query should wait for Replicated database to precess previous DDL queue entries\", 0) \\\n+    M(Bool, database_replicated_ddl_output, true, \"Return table with query execution status as a result of DDL query\", 0) \\\n     \\\n     /** Obsolete settings that do nothing but left for compatibility reasons. Remove each one after half a year of obsolescence. */ \\\n     \\\ndiff --git a/src/Databases/DatabaseAtomic.cpp b/src/Databases/DatabaseAtomic.cpp\nindex 17a91a1fff97..71e0effb2d2f 100644\n--- a/src/Databases/DatabaseAtomic.cpp\n+++ b/src/Databases/DatabaseAtomic.cpp\n@@ -4,13 +4,14 @@\n #include <Poco/Path.h>\n #include <IO/ReadHelpers.h>\n #include <IO/WriteHelpers.h>\n+#include <IO/ReadBufferFromFile.h>\n #include <Parsers/formatAST.h>\n #include <Common/renameat2.h>\n #include <Storages/StorageMaterializedView.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/ExternalDictionariesLoader.h>\n #include <filesystem>\n-\n+#include <Interpreters/DDLTask.h>\n \n namespace DB\n {\n@@ -34,7 +35,6 @@ class AtomicDatabaseTablesSnapshotIterator final : public DatabaseTablesSnapshot\n     UUID uuid() const override { return table()->getStorageID().uuid; }\n };\n \n-\n DatabaseAtomic::DatabaseAtomic(String name_, String metadata_path_, UUID uuid, const String & logger_name, const Context & context_)\n     : DatabaseOrdinary(name_, std::move(metadata_path_), \"store/\", logger_name, context_)\n     , path_to_table_symlinks(global_context.getPath() + \"data/\" + escapeForFileName(name_) + \"/\")\n@@ -106,7 +106,7 @@ StoragePtr DatabaseAtomic::detachTable(const String & name)\n     return table;\n }\n \n-void DatabaseAtomic::dropTable(const Context &, const String & table_name, bool no_delay)\n+void DatabaseAtomic::dropTable(const Context & context, const String & table_name, bool no_delay)\n {\n     String table_metadata_path = getObjectMetadataPath(table_name);\n     String table_metadata_path_drop;\n@@ -115,6 +115,16 @@ void DatabaseAtomic::dropTable(const Context &, const String & table_name, bool\n         std::unique_lock lock(mutex);\n         table = getTableUnlocked(table_name, lock);\n         table_metadata_path_drop = DatabaseCatalog::instance().getPathForDroppedMetadata(table->getStorageID());\n+        auto txn = context.getZooKeeperMetadataTransaction();\n+        if (txn && !context.isInternalSubquery())\n+            txn->commit();      /// Commit point (a sort of) for Replicated database\n+\n+        /// NOTE: replica will be lost if server crashes before the following rename\n+        /// We apply changes in ZooKeeper before applying changes in local metadata file\n+        /// to reduce probability of failures between these operations\n+        /// (it's more likely to lost connection, than to fail before applying local changes).\n+        /// TODO better detection and recovery\n+\n         Poco::File(table_metadata_path).renameTo(table_metadata_path_drop);    /// Mark table as dropped\n         DatabaseWithDictionaries::detachTableUnlocked(table_name, lock);       /// Should never throw\n         table_name_to_path.erase(table_name);\n@@ -124,7 +134,7 @@ void DatabaseAtomic::dropTable(const Context &, const String & table_name, bool\n     /// Remove the inner table (if any) to avoid deadlock\n     /// (due to attempt to execute DROP from the worker thread)\n     if (auto * mv = dynamic_cast<StorageMaterializedView *>(table.get()))\n-        mv->dropInnerTable(no_delay);\n+        mv->dropInnerTable(no_delay, context);\n     /// Notify DatabaseCatalog that table was dropped. It will remove table data in background.\n     /// Cleanup is performed outside of database to allow easily DROP DATABASE without waiting for cleanup to complete.\n     DatabaseCatalog::instance().enqueueDroppedTableCleanup(table->getStorageID(), table, table_metadata_path_drop, no_delay);\n@@ -144,6 +154,8 @@ void DatabaseAtomic::renameTable(const Context & context, const String & table_n\n \n     if (exchange && dictionary)\n         throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Cannot exchange dictionaries\");\n+    if (exchange && !supportsRenameat2())\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"RENAME EXCHANGE is not supported\");\n \n     auto & other_db = dynamic_cast<DatabaseAtomic &>(to_database);\n     bool inside_database = this == &other_db;\n@@ -232,6 +244,13 @@ void DatabaseAtomic::renameTable(const Context & context, const String & table_n\n     }\n \n     /// Table renaming actually begins here\n+    auto txn = context.getZooKeeperMetadataTransaction();\n+    if (txn && !context.isInternalSubquery())\n+        txn->commit();     /// Commit point (a sort of) for Replicated database\n+\n+    /// NOTE: replica will be lost if server crashes before the following rename\n+    /// TODO better detection and recovery\n+\n     if (exchange)\n         renameExchange(old_metadata_path, new_metadata_path);\n     else\n@@ -267,7 +286,8 @@ void DatabaseAtomic::renameTable(const Context & context, const String & table_n\n }\n \n void DatabaseAtomic::commitCreateTable(const ASTCreateQuery & query, const StoragePtr & table,\n-                                       const String & table_metadata_tmp_path, const String & table_metadata_path)\n+                                       const String & table_metadata_tmp_path, const String & table_metadata_path,\n+                                       const Context & query_context)\n {\n     DetachedTables not_in_use;\n     auto table_data_path = getTableDataPath(query);\n@@ -284,6 +304,14 @@ void DatabaseAtomic::commitCreateTable(const ASTCreateQuery & query, const Stora\n         /// We will get en exception if some table with the same UUID exists (even if it's detached table or table from another database)\n         DatabaseCatalog::instance().addUUIDMapping(query.uuid);\n         locked_uuid = true;\n+\n+        auto txn = query_context.getZooKeeperMetadataTransaction();\n+        if (txn && !query_context.isInternalSubquery())\n+            txn->commit();     /// Commit point (a sort of) for Replicated database\n+\n+        /// NOTE: replica will be lost if server crashes before the following renameNoReplace(...)\n+        /// TODO better detection and recovery\n+\n         /// It throws if `table_metadata_path` already exists (it's possible if table was detached)\n         renameNoReplace(table_metadata_tmp_path, table_metadata_path);  /// Commit point (a sort of)\n         attachTableUnlocked(query.table, table, lock);   /// Should never throw\n@@ -300,7 +328,8 @@ void DatabaseAtomic::commitCreateTable(const ASTCreateQuery & query, const Stora\n         tryCreateSymlink(query.table, table_data_path);\n }\n \n-void DatabaseAtomic::commitAlterTable(const StorageID & table_id, const String & table_metadata_tmp_path, const String & table_metadata_path)\n+void DatabaseAtomic::commitAlterTable(const StorageID & table_id, const String & table_metadata_tmp_path, const String & table_metadata_path,\n+                                      const String & /*statement*/, const Context & query_context)\n {\n     bool check_file_exists = true;\n     SCOPE_EXIT({ std::error_code code; if (check_file_exists) std::filesystem::remove(table_metadata_tmp_path, code); });\n@@ -311,6 +340,13 @@ void DatabaseAtomic::commitAlterTable(const StorageID & table_id, const String &\n     if (table_id.uuid != actual_table_id.uuid)\n         throw Exception(\"Cannot alter table because it was renamed\", ErrorCodes::CANNOT_ASSIGN_ALTER);\n \n+    auto txn = query_context.getZooKeeperMetadataTransaction();\n+    if (txn && !query_context.isInternalSubquery())\n+        txn->commit();      /// Commit point (a sort of) for Replicated database\n+\n+    /// NOTE: replica will be lost if server crashes before the following rename\n+    /// TODO better detection and recovery\n+\n     check_file_exists = renameExchangeIfSupported(table_metadata_tmp_path, table_metadata_path);\n     if (!check_file_exists)\n         std::filesystem::rename(table_metadata_tmp_path, table_metadata_path);\n@@ -329,6 +365,12 @@ void DatabaseAtomic::assertDetachedTableNotInUse(const UUID & uuid)\n               \", because it was detached but still used by some query. Retry later.\", ErrorCodes::TABLE_ALREADY_EXISTS);\n }\n \n+void DatabaseAtomic::setDetachedTableNotInUseForce(const UUID & uuid)\n+{\n+    std::unique_lock lock{mutex};\n+    detached_tables.erase(uuid);\n+}\n+\n DatabaseAtomic::DetachedTables DatabaseAtomic::cleanupDetachedTables()\n {\n     DetachedTables not_in_use;\ndiff --git a/src/Databases/DatabaseAtomic.h b/src/Databases/DatabaseAtomic.h\nindex 006d0e114345..09cdf269b356 100644\n--- a/src/Databases/DatabaseAtomic.h\n+++ b/src/Databases/DatabaseAtomic.h\n@@ -58,11 +58,12 @@ class DatabaseAtomic : public DatabaseOrdinary\n     void tryRemoveSymlink(const String & table_name);\n \n     void waitDetachedTableNotInUse(const UUID & uuid) override;\n+    void setDetachedTableNotInUseForce(const UUID & uuid);\n \n-private:\n-    void commitAlterTable(const StorageID & table_id, const String & table_metadata_tmp_path, const String & table_metadata_path) override;\n+protected:\n+    void commitAlterTable(const StorageID & table_id, const String & table_metadata_tmp_path, const String & table_metadata_path, const String & statement, const Context & query_context) override;\n     void commitCreateTable(const ASTCreateQuery & query, const StoragePtr & table,\n-                           const String & table_metadata_tmp_path, const String & table_metadata_path) override;\n+                           const String & table_metadata_tmp_path, const String & table_metadata_path, const Context & query_context) override;\n \n     void assertDetachedTableNotInUse(const UUID & uuid);\n     typedef std::unordered_map<UUID, StoragePtr> DetachedTables;\ndiff --git a/src/Databases/DatabaseFactory.cpp b/src/Databases/DatabaseFactory.cpp\nindex 5166e15b7b42..cd0143556c9a 100644\n--- a/src/Databases/DatabaseFactory.cpp\n+++ b/src/Databases/DatabaseFactory.cpp\n@@ -1,6 +1,7 @@\n #include <Databases/DatabaseFactory.h>\n \n #include <Databases/DatabaseAtomic.h>\n+#include <Databases/DatabaseReplicated.h>\n #include <Databases/DatabaseDictionary.h>\n #include <Databases/DatabaseLazy.h>\n #include <Databases/DatabaseMemory.h>\n@@ -13,6 +14,7 @@\n #include <Poco/File.h>\n #include <Poco/Path.h>\n #include <Interpreters/Context.h>\n+#include <Common/Macros.h>\n \n #if !defined(ARCADIA_BUILD)\n #    include \"config_core.h\"\n@@ -96,11 +98,16 @@ DatabasePtr DatabaseFactory::getImpl(const ASTCreateQuery & create, const String\n     const String & engine_name = engine_define->engine->name;\n     const UUID & uuid = create.uuid;\n \n-    if (engine_name != \"MySQL\" && engine_name != \"MaterializeMySQL\" && engine_name != \"Lazy\" && engine_name != \"PostgreSQL\" && engine_define->engine->arguments)\n+    bool engine_may_have_arguments = engine_name == \"MySQL\" || engine_name == \"MaterializeMySQL\" || engine_name == \"Lazy\" ||\n+                                     engine_name == \"Replicated\" || engine_name == \"PostgreSQL\";\n+    if (engine_define->engine->arguments && !engine_may_have_arguments)\n         throw Exception(\"Database engine \" + engine_name + \" cannot have arguments\", ErrorCodes::BAD_ARGUMENTS);\n \n-    if (engine_define->engine->parameters || engine_define->partition_by || engine_define->primary_key || engine_define->order_by ||\n-        engine_define->sample_by || (!endsWith(engine_name, \"MySQL\") && engine_define->settings))\n+    bool has_unexpected_element = engine_define->engine->parameters || engine_define->partition_by ||\n+                                  engine_define->primary_key || engine_define->order_by ||\n+                                  engine_define->sample_by;\n+    bool may_have_settings = endsWith(engine_name, \"MySQL\") || engine_name == \"Replicated\";\n+    if (has_unexpected_element || (!may_have_settings && engine_define->settings))\n         throw Exception(\"Database engine \" + engine_name + \" cannot have parameters, primary_key, order_by, sample_by, settings\",\n                         ErrorCodes::UNKNOWN_ELEMENT_IN_AST);\n \n@@ -184,6 +191,32 @@ DatabasePtr DatabaseFactory::getImpl(const ASTCreateQuery & create, const String\n         return std::make_shared<DatabaseLazy>(database_name, metadata_path, cache_expiration_time_seconds, context);\n     }\n \n+    else if (engine_name == \"Replicated\")\n+    {\n+        const ASTFunction * engine = engine_define->engine;\n+\n+        if (!engine->arguments || engine->arguments->children.size() != 3)\n+            throw Exception(\"Replicated database requires 3 arguments: zookeeper path, shard name and replica name\", ErrorCodes::BAD_ARGUMENTS);\n+\n+        const auto & arguments = engine->arguments->children;\n+\n+        String zookeeper_path = safeGetLiteralValue<String>(arguments[0], \"Replicated\");\n+        String shard_name = safeGetLiteralValue<String>(arguments[1], \"Replicated\");\n+        String replica_name  = safeGetLiteralValue<String>(arguments[2], \"Replicated\");\n+\n+        zookeeper_path = context.getMacros()->expand(zookeeper_path);\n+        shard_name = context.getMacros()->expand(shard_name);\n+        replica_name = context.getMacros()->expand(replica_name);\n+\n+        DatabaseReplicatedSettings database_replicated_settings{};\n+        if (engine_define->settings)\n+            database_replicated_settings.loadFromQuery(*engine_define);\n+\n+        return std::make_shared<DatabaseReplicated>(database_name, metadata_path, uuid,\n+                                                    zookeeper_path, shard_name, replica_name,\n+                                                    std::move(database_replicated_settings), context);\n+    }\n+\n #if USE_LIBPQXX\n \n     else if (engine_name == \"PostgreSQL\")\ndiff --git a/src/Databases/DatabaseOnDisk.cpp b/src/Databases/DatabaseOnDisk.cpp\nindex bf89fcdf4ee4..e5d2b23ace03 100644\n--- a/src/Databases/DatabaseOnDisk.cpp\n+++ b/src/Databases/DatabaseOnDisk.cpp\n@@ -129,6 +129,60 @@ String getObjectDefinitionFromCreateQuery(const ASTPtr & query)\n     return statement_buf.str();\n }\n \n+void applyMetadataChangesToCreateQuery(const ASTPtr & query, const StorageInMemoryMetadata & metadata)\n+{\n+    auto & ast_create_query = query->as<ASTCreateQuery &>();\n+\n+    bool has_structure = ast_create_query.columns_list && ast_create_query.columns_list->columns;\n+    if (ast_create_query.as_table_function && !has_structure)\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Cannot alter table {} because it was created AS table function\"\n+                                                     \" and doesn't have structure in metadata\", backQuote(ast_create_query.table));\n+\n+    assert(has_structure);\n+    ASTPtr new_columns = InterpreterCreateQuery::formatColumns(metadata.columns);\n+    ASTPtr new_indices = InterpreterCreateQuery::formatIndices(metadata.secondary_indices);\n+    ASTPtr new_constraints = InterpreterCreateQuery::formatConstraints(metadata.constraints);\n+\n+    ast_create_query.columns_list->replace(ast_create_query.columns_list->columns, new_columns);\n+    ast_create_query.columns_list->setOrReplace(ast_create_query.columns_list->indices, new_indices);\n+    ast_create_query.columns_list->setOrReplace(ast_create_query.columns_list->constraints, new_constraints);\n+\n+    if (metadata.select.select_query)\n+    {\n+        query->replace(ast_create_query.select, metadata.select.select_query);\n+    }\n+\n+    /// MaterializedView is one type of CREATE query without storage.\n+    if (ast_create_query.storage)\n+    {\n+        ASTStorage & storage_ast = *ast_create_query.storage;\n+\n+        bool is_extended_storage_def\n+            = storage_ast.partition_by || storage_ast.primary_key || storage_ast.order_by || storage_ast.sample_by || storage_ast.settings;\n+\n+        if (is_extended_storage_def)\n+        {\n+            if (metadata.sorting_key.definition_ast)\n+                storage_ast.set(storage_ast.order_by, metadata.sorting_key.definition_ast);\n+\n+            if (metadata.primary_key.definition_ast)\n+                storage_ast.set(storage_ast.primary_key, metadata.primary_key.definition_ast);\n+\n+            if (metadata.sampling_key.definition_ast)\n+                storage_ast.set(storage_ast.sample_by, metadata.sampling_key.definition_ast);\n+\n+            if (metadata.table_ttl.definition_ast)\n+                storage_ast.set(storage_ast.ttl_table, metadata.table_ttl.definition_ast);\n+            else if (storage_ast.ttl_table != nullptr) /// TTL was removed\n+                storage_ast.ttl_table = nullptr;\n+\n+            if (metadata.settings_changes)\n+                storage_ast.set(storage_ast.settings, metadata.settings_changes);\n+        }\n+    }\n+}\n+\n+\n DatabaseOnDisk::DatabaseOnDisk(\n     const String & name,\n     const String & metadata_path_,\n@@ -214,7 +268,7 @@ void DatabaseOnDisk::createTable(\n         out.close();\n     }\n \n-    commitCreateTable(create, table, table_metadata_tmp_path, table_metadata_path);\n+    commitCreateTable(create, table, table_metadata_tmp_path, table_metadata_path, context);\n \n     removeDetachedPermanentlyFlag(table_name, table_metadata_path);\n }\n@@ -238,7 +292,8 @@ void DatabaseOnDisk::removeDetachedPermanentlyFlag(const String & table_name, co\n }\n \n void DatabaseOnDisk::commitCreateTable(const ASTCreateQuery & query, const StoragePtr & table,\n-                                       const String & table_metadata_tmp_path, const String & table_metadata_path)\n+                                       const String & table_metadata_tmp_path, const String & table_metadata_path,\n+                                       const Context & /*query_context*/)\n {\n     try\n     {\n@@ -256,7 +311,7 @@ void DatabaseOnDisk::commitCreateTable(const ASTCreateQuery & query, const Stora\n     }\n }\n \n-void DatabaseOnDisk::detachTablePermanently(const String & table_name)\n+void DatabaseOnDisk::detachTablePermanently(const Context &, const String & table_name)\n {\n     auto table = detachTable(table_name);\n \n@@ -352,6 +407,8 @@ void DatabaseOnDisk::renameTable(\n             from_ordinary_to_atomic = true;\n         else if (typeid_cast<DatabaseAtomic *>(this) && typeid_cast<DatabaseOrdinary *>(&to_database))\n             from_atomic_to_ordinary = true;\n+        else if (dynamic_cast<DatabaseAtomic *>(this) && typeid_cast<DatabaseOrdinary *>(&to_database) && getEngineName() == \"Replicated\")\n+            from_atomic_to_ordinary = true;\n         else\n             throw Exception(\"Moving tables between databases of different engines is not supported\", ErrorCodes::NOT_IMPLEMENTED);\n     }\n@@ -363,6 +420,7 @@ void DatabaseOnDisk::renameTable(\n     /// DatabaseLazy::detachTable may return nullptr even if table exists, so we need tryGetTable for this case.\n     StoragePtr table = tryGetTable(table_name, global_context);\n     detachTable(table_name);\n+    UUID prev_uuid = UUIDHelpers::Nil;\n     try\n     {\n         table_lock = table->lockExclusively(context.getCurrentQueryId(), context.getSettingsRef().lock_acquire_timeout);\n@@ -375,7 +433,7 @@ void DatabaseOnDisk::renameTable(\n         if (from_ordinary_to_atomic)\n             create.uuid = UUIDHelpers::generateV4();\n         if (from_atomic_to_ordinary)\n-            create.uuid = UUIDHelpers::Nil;\n+            std::swap(create.uuid, prev_uuid);\n \n         if (auto * target_db = dynamic_cast<DatabaseOnDisk *>(&to_database))\n             target_db->checkMetadataFilenameAvailability(to_table_name);\n@@ -400,12 +458,16 @@ void DatabaseOnDisk::renameTable(\n \n     Poco::File(table_metadata_path).remove();\n \n-    /// Special case: usually no actions with symlinks are required when detaching/attaching table,\n-    /// but not when moving from Atomic database to Ordinary\n-    if (from_atomic_to_ordinary && table->storesDataOnDisk())\n+    if (from_atomic_to_ordinary)\n     {\n-        auto & atomic_db = assert_cast<DatabaseAtomic &>(*this);\n-        atomic_db.tryRemoveSymlink(table_name);\n+        auto & atomic_db = dynamic_cast<DatabaseAtomic &>(*this);\n+        /// Special case: usually no actions with symlinks are required when detaching/attaching table,\n+        /// but not when moving from Atomic database to Ordinary\n+        if (table->storesDataOnDisk())\n+            atomic_db.tryRemoveSymlink(table_name);\n+        /// Forget about UUID, now it's possible to reuse it for new table\n+        DatabaseCatalog::instance().removeUUIDMappingFinally(prev_uuid);\n+        atomic_db.setDetachedTableNotInUseForce(prev_uuid);\n     }\n }\n \ndiff --git a/src/Databases/DatabaseOnDisk.h b/src/Databases/DatabaseOnDisk.h\nindex fff2a259911b..fefe6e916062 100644\n--- a/src/Databases/DatabaseOnDisk.h\n+++ b/src/Databases/DatabaseOnDisk.h\n@@ -25,6 +25,8 @@ std::pair<String, StoragePtr> createTableFromAST(\n   */\n String getObjectDefinitionFromCreateQuery(const ASTPtr & query);\n \n+void applyMetadataChangesToCreateQuery(const ASTPtr & query, const StorageInMemoryMetadata & metadata);\n+\n \n /* Class to provide basic operations with tables when metadata is stored on disk in .sql files.\n  */\n@@ -39,7 +41,7 @@ class DatabaseOnDisk : public DatabaseWithOwnTablesBase\n         const StoragePtr & table,\n         const ASTPtr & query) override;\n \n-    void detachTablePermanently(const String & table_name) override;\n+    void detachTablePermanently(const Context & context, const String & table_name) override;\n \n     void dropTable(\n         const Context & context,\n@@ -90,7 +92,7 @@ class DatabaseOnDisk : public DatabaseWithOwnTablesBase\n     ASTPtr getCreateQueryFromMetadata(const String & metadata_path, bool throw_on_error) const;\n \n     virtual void commitCreateTable(const ASTCreateQuery & query, const StoragePtr & table,\n-                                   const String & table_metadata_tmp_path, const String & table_metadata_path);\n+                                   const String & table_metadata_tmp_path, const String & table_metadata_path, const Context & query_context);\n \n     const String metadata_path;\n     const String data_path;\ndiff --git a/src/Databases/DatabaseOrdinary.cpp b/src/Databases/DatabaseOrdinary.cpp\nindex df30f9e6306c..a94668dacf79 100644\n--- a/src/Databases/DatabaseOrdinary.cpp\n+++ b/src/Databases/DatabaseOrdinary.cpp\n@@ -33,11 +33,6 @@ static constexpr size_t PRINT_MESSAGE_EACH_N_OBJECTS = 256;\n static constexpr size_t PRINT_MESSAGE_EACH_N_SECONDS = 5;\n static constexpr size_t METADATA_FILE_BUFFER_SIZE = 32768;\n \n-namespace ErrorCodes\n-{\n-    extern const int NOT_IMPLEMENTED;\n-}\n-\n namespace\n {\n     void tryAttachTable(\n@@ -272,55 +267,7 @@ void DatabaseOrdinary::alterTable(const Context & context, const StorageID & tab\n         0,\n         context.getSettingsRef().max_parser_depth);\n \n-    auto & ast_create_query = ast->as<ASTCreateQuery &>();\n-\n-    bool has_structure = ast_create_query.columns_list && ast_create_query.columns_list->columns;\n-    if (ast_create_query.as_table_function && !has_structure)\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Cannot alter table {} because it was created AS table function\"\n-                                                     \" and doesn't have structure in metadata\", backQuote(table_name));\n-\n-    assert(has_structure);\n-    ASTPtr new_columns = InterpreterCreateQuery::formatColumns(metadata.columns);\n-    ASTPtr new_indices = InterpreterCreateQuery::formatIndices(metadata.secondary_indices);\n-    ASTPtr new_constraints = InterpreterCreateQuery::formatConstraints(metadata.constraints);\n-\n-    ast_create_query.columns_list->replace(ast_create_query.columns_list->columns, new_columns);\n-    ast_create_query.columns_list->setOrReplace(ast_create_query.columns_list->indices, new_indices);\n-    ast_create_query.columns_list->setOrReplace(ast_create_query.columns_list->constraints, new_constraints);\n-\n-    if (metadata.select.select_query)\n-    {\n-        ast->replace(ast_create_query.select, metadata.select.select_query);\n-    }\n-\n-    /// MaterializedView is one type of CREATE query without storage.\n-    if (ast_create_query.storage)\n-    {\n-        ASTStorage & storage_ast = *ast_create_query.storage;\n-\n-        bool is_extended_storage_def\n-            = storage_ast.partition_by || storage_ast.primary_key || storage_ast.order_by || storage_ast.sample_by || storage_ast.settings;\n-\n-        if (is_extended_storage_def)\n-        {\n-            if (metadata.sorting_key.definition_ast)\n-                storage_ast.set(storage_ast.order_by, metadata.sorting_key.definition_ast);\n-\n-            if (metadata.primary_key.definition_ast)\n-                storage_ast.set(storage_ast.primary_key, metadata.primary_key.definition_ast);\n-\n-            if (metadata.sampling_key.definition_ast)\n-                storage_ast.set(storage_ast.sample_by, metadata.sampling_key.definition_ast);\n-\n-            if (metadata.table_ttl.definition_ast)\n-                storage_ast.set(storage_ast.ttl_table, metadata.table_ttl.definition_ast);\n-            else if (storage_ast.ttl_table != nullptr) /// TTL was removed\n-                storage_ast.ttl_table = nullptr;\n-\n-            if (metadata.settings_changes)\n-                storage_ast.set(storage_ast.settings, metadata.settings_changes);\n-        }\n-    }\n+    applyMetadataChangesToCreateQuery(ast, metadata);\n \n     statement = getObjectDefinitionFromCreateQuery(ast);\n     {\n@@ -332,10 +279,10 @@ void DatabaseOrdinary::alterTable(const Context & context, const StorageID & tab\n         out.close();\n     }\n \n-    commitAlterTable(table_id, table_metadata_tmp_path, table_metadata_path);\n+    commitAlterTable(table_id, table_metadata_tmp_path, table_metadata_path, statement, context);\n }\n \n-void DatabaseOrdinary::commitAlterTable(const StorageID &, const String & table_metadata_tmp_path, const String & table_metadata_path)\n+void DatabaseOrdinary::commitAlterTable(const StorageID &, const String & table_metadata_tmp_path, const String & table_metadata_path, const String & /*statement*/, const Context & /*query_context*/)\n {\n     try\n     {\ndiff --git a/src/Databases/DatabaseOrdinary.h b/src/Databases/DatabaseOrdinary.h\nindex 077833134132..c1ad32345f68 100644\n--- a/src/Databases/DatabaseOrdinary.h\n+++ b/src/Databases/DatabaseOrdinary.h\n@@ -30,7 +30,7 @@ class DatabaseOrdinary : public DatabaseWithDictionaries\n         const StorageInMemoryMetadata & metadata) override;\n \n protected:\n-    virtual void commitAlterTable(const StorageID & table_id, const String & table_metadata_tmp_path, const String & table_metadata_path);\n+    virtual void commitAlterTable(const StorageID & table_id, const String & table_metadata_tmp_path, const String & table_metadata_path, const String & statement, const Context & query_context);\n \n     void startupTables(ThreadPool & thread_pool);\n };\ndiff --git a/src/Databases/DatabaseReplicated.cpp b/src/Databases/DatabaseReplicated.cpp\nnew file mode 100644\nindex 000000000000..12cff3407d3c\n--- /dev/null\n+++ b/src/Databases/DatabaseReplicated.cpp\n@@ -0,0 +1,719 @@\n+#include <DataTypes/DataTypeString.h>\n+#include <Databases/DatabaseReplicated.h>\n+#include <IO/ReadBufferFromFile.h>\n+#include <IO/ReadBufferFromString.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+#include <Interpreters/Context.h>\n+#include <Interpreters/executeQuery.h>\n+#include <Parsers/queryToString.h>\n+#include <Common/Exception.h>\n+#include <Common/Stopwatch.h>\n+#include <Common/ZooKeeper/KeeperException.h>\n+#include <Common/ZooKeeper/Types.h>\n+#include <Common/ZooKeeper/ZooKeeper.h>\n+#include <Databases/DatabaseReplicatedWorker.h>\n+#include <Interpreters/DDLTask.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n+#include <Interpreters/Cluster.h>\n+#include <common/getFQDNOrHostName.h>\n+#include <Parsers/ASTAlterQuery.h>\n+#include <Parsers/ParserCreateQuery.h>\n+#include <Parsers/parseQuery.h>\n+#include <Interpreters/InterpreterCreateQuery.h>\n+#include <Parsers/formatAST.h>\n+\n+namespace DB\n+{\n+namespace ErrorCodes\n+{\n+    extern const int NO_ZOOKEEPER;\n+    extern const int LOGICAL_ERROR;\n+    extern const int BAD_ARGUMENTS;\n+    extern const int REPLICA_IS_ALREADY_EXIST;\n+    extern const int DATABASE_REPLICATION_FAILED;\n+    extern const int UNKNOWN_DATABASE;\n+    extern const int UNKNOWN_TABLE;\n+    extern const int NOT_IMPLEMENTED;\n+    extern const int INCORRECT_QUERY;\n+    extern const int ALL_CONNECTION_TRIES_FAILED;\n+}\n+\n+static constexpr const char * DROPPED_MARK = \"DROPPED\";\n+static constexpr const char * BROKEN_TABLES_SUFFIX = \"_broken_tables\";\n+\n+\n+zkutil::ZooKeeperPtr DatabaseReplicated::getZooKeeper() const\n+{\n+    return global_context.getZooKeeper();\n+}\n+\n+static inline String getHostID(const Context & global_context, const UUID & db_uuid)\n+{\n+    return Cluster::Address::toString(getFQDNOrHostName(), global_context.getTCPPort()) + ':' + toString(db_uuid);\n+}\n+\n+\n+DatabaseReplicated::~DatabaseReplicated() = default;\n+\n+DatabaseReplicated::DatabaseReplicated(\n+    const String & name_,\n+    const String & metadata_path_,\n+    UUID uuid,\n+    const String & zookeeper_path_,\n+    const String & shard_name_,\n+    const String & replica_name_,\n+    DatabaseReplicatedSettings db_settings_,\n+    const Context & context_)\n+    : DatabaseAtomic(name_, metadata_path_, uuid, \"DatabaseReplicated (\" + name_ + \")\", context_)\n+    , zookeeper_path(zookeeper_path_)\n+    , shard_name(shard_name_)\n+    , replica_name(replica_name_)\n+    , db_settings(std::move(db_settings_))\n+{\n+    if (zookeeper_path.empty() || shard_name.empty() || replica_name.empty())\n+        throw Exception(\"ZooKeeper path, shard and replica names must be non-empty\", ErrorCodes::BAD_ARGUMENTS);\n+    if (shard_name.find('/') != std::string::npos || replica_name.find('/') != std::string::npos)\n+        throw Exception(\"Shard and replica names should not contain '/'\", ErrorCodes::BAD_ARGUMENTS);\n+    if (shard_name.find('|') != std::string::npos || replica_name.find('|') != std::string::npos)\n+        throw Exception(\"Shard and replica names should not contain '|'\", ErrorCodes::BAD_ARGUMENTS);\n+\n+    if (zookeeper_path.back() == '/')\n+        zookeeper_path.resize(zookeeper_path.size() - 1);\n+\n+    /// If zookeeper chroot prefix is used, path should start with '/', because chroot concatenates without it.\n+    if (zookeeper_path.front() != '/')\n+        zookeeper_path = \"/\" + zookeeper_path;\n+}\n+\n+String DatabaseReplicated::getFullReplicaName() const\n+{\n+    return shard_name + '|' + replica_name;\n+}\n+\n+std::pair<String, String> DatabaseReplicated::parseFullReplicaName(const String & name)\n+{\n+    String shard;\n+    String replica;\n+    auto pos = name.find('|');\n+    if (pos == std::string::npos || name.find('|', pos + 1) != std::string::npos)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Incorrect replica identifier: {}\", name);\n+    shard = name.substr(0, pos);\n+    replica = name.substr(pos + 1);\n+    return {shard, replica};\n+}\n+\n+ClusterPtr DatabaseReplicated::getCluster() const\n+{\n+    /// TODO Maintain up-to-date Cluster and allow to use it in Distributed tables\n+    Strings hosts;\n+    Strings host_ids;\n+\n+    auto zookeeper = global_context.getZooKeeper();\n+    constexpr int max_retries = 10;\n+    int iteration = 0;\n+    bool success = false;\n+    while (++iteration <= max_retries)\n+    {\n+        host_ids.resize(0);\n+        Coordination::Stat stat;\n+        hosts = zookeeper->getChildren(zookeeper_path + \"/replicas\", &stat);\n+        if (hosts.empty())\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"No hosts found\");\n+        Int32 cver = stat.cversion;\n+        std::sort(hosts.begin(), hosts.end());\n+\n+        std::vector<zkutil::ZooKeeper::FutureGet> futures;\n+        futures.reserve(hosts.size());\n+        host_ids.reserve(hosts.size());\n+        for (const auto & host : hosts)\n+            futures.emplace_back(zookeeper->asyncTryGet(zookeeper_path + \"/replicas/\" + host));\n+\n+        success = true;\n+        for (auto & future : futures)\n+        {\n+            auto res = future.get();\n+            if (res.error != Coordination::Error::ZOK)\n+                success = false;\n+            host_ids.emplace_back(res.data);\n+        }\n+\n+        zookeeper->get(zookeeper_path + \"/replicas\", &stat);\n+        if (success && cver == stat.version)\n+            break;\n+    }\n+    if (!success)\n+        throw Exception(ErrorCodes::ALL_CONNECTION_TRIES_FAILED, \"Cannot get consistent cluster snapshot,\"\n+                                                                 \"because replicas are created or removed concurrently\");\n+\n+    assert(!hosts.empty());\n+    assert(hosts.size() == host_ids.size());\n+    String current_shard = parseFullReplicaName(hosts.front()).first;\n+    std::vector<Strings> shards;\n+    shards.emplace_back();\n+    for (size_t i = 0; i < hosts.size(); ++i)\n+    {\n+        const auto & id = host_ids[i];\n+        if (id == DROPPED_MARK)\n+            continue;\n+        auto [shard, replica] = parseFullReplicaName(hosts[i]);\n+        auto pos = id.find(':');\n+        String host = id.substr(0, pos);\n+        if (shard != current_shard)\n+        {\n+            current_shard = shard;\n+            if (!shards.back().empty())\n+                shards.emplace_back();\n+        }\n+        shards.back().emplace_back(unescapeForFileName(host));\n+    }\n+\n+    /// TODO make it configurable\n+    String username = \"default\";\n+    String password;\n+\n+    return std::make_shared<Cluster>(global_context.getSettingsRef(), shards, username, password, global_context.getTCPPort(), false);\n+}\n+\n+void DatabaseReplicated::tryConnectToZooKeeperAndInitDatabase(bool force_attach)\n+{\n+    try\n+    {\n+        if (!global_context.hasZooKeeper())\n+        {\n+            throw Exception(\"Can't create replicated database without ZooKeeper\", ErrorCodes::NO_ZOOKEEPER);\n+        }\n+\n+        auto current_zookeeper = global_context.getZooKeeper();\n+\n+        if (!current_zookeeper->exists(zookeeper_path))\n+        {\n+            /// Create new database, multiple nodes can execute it concurrently\n+            createDatabaseNodesInZooKeeper(current_zookeeper);\n+        }\n+\n+        replica_path = zookeeper_path + \"/replicas/\" + getFullReplicaName();\n+\n+        String replica_host_id;\n+        if (current_zookeeper->tryGet(replica_path, replica_host_id))\n+        {\n+            String host_id = getHostID(global_context, db_uuid);\n+            if (replica_host_id != host_id)\n+                throw Exception(ErrorCodes::REPLICA_IS_ALREADY_EXIST,\n+                                \"Replica {} of shard {} of replicated database at {} already exists. Replica host ID: '{}', current host ID: '{}'\",\n+                                replica_name, shard_name, zookeeper_path, replica_host_id, host_id);\n+        }\n+        else\n+        {\n+            /// Throws if replica with the same name already exists\n+            createReplicaNodesInZooKeeper(current_zookeeper);\n+        }\n+\n+        is_readonly = false;\n+    }\n+    catch (...)\n+    {\n+        if (!force_attach)\n+            throw;\n+\n+        /// It's server startup, ignore error.\n+        /// Worker thread will try to setup ZooKeeper connection\n+        tryLogCurrentException(log);\n+    }\n+}\n+\n+bool DatabaseReplicated::createDatabaseNodesInZooKeeper(const zkutil::ZooKeeperPtr & current_zookeeper)\n+{\n+    current_zookeeper->createAncestors(zookeeper_path);\n+\n+    Coordination::Requests ops;\n+    ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path, \"\", zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/log\", \"\", zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/replicas\", \"\", zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/counter\", \"\", zkutil::CreateMode::Persistent));\n+    /// We create and remove counter/cnt- node to increment sequential number of counter/ node and make log entry numbers start from 1.\n+    /// New replicas are created with log pointer equal to 0 and log pointer is a number of the last executed entry.\n+    /// It means that we cannot have log entry with number 0.\n+    ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/counter/cnt-\", \"\", zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeRemoveRequest(zookeeper_path + \"/counter/cnt-\", -1));\n+    ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/metadata\", \"\", zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/max_log_ptr\", \"1\", zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/logs_to_keep\", \"1000\", zkutil::CreateMode::Persistent));\n+\n+    Coordination::Responses responses;\n+    auto res = current_zookeeper->tryMulti(ops, responses);\n+    if (res == Coordination::Error::ZOK)\n+        return true;    /// Created new database (it's the first replica)\n+    if (res == Coordination::Error::ZNODEEXISTS)\n+        return false;   /// Database exists, we will add new replica\n+\n+    /// Other codes are unexpected, will throw\n+    zkutil::KeeperMultiException::check(res, ops, responses);\n+    assert(false);\n+    __builtin_unreachable();\n+}\n+\n+void DatabaseReplicated::createReplicaNodesInZooKeeper(const zkutil::ZooKeeperPtr & current_zookeeper)\n+{\n+    /// Write host name to replica_path, it will protect from multiple replicas with the same name\n+    auto host_id = getHostID(global_context, db_uuid);\n+\n+    /// On replica creation add empty entry to log. Can be used to trigger some actions on other replicas (e.g. update cluster info).\n+    DDLLogEntry entry{};\n+\n+    String query_path_prefix = zookeeper_path + \"/log/query-\";\n+    String counter_prefix = zookeeper_path + \"/counter/cnt-\";\n+    String counter_path = current_zookeeper->create(counter_prefix, \"\", zkutil::CreateMode::EphemeralSequential);\n+    String query_path = query_path_prefix + counter_path.substr(counter_prefix.size());\n+\n+    Coordination::Requests ops;\n+    ops.emplace_back(zkutil::makeCreateRequest(replica_path, host_id, zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeCreateRequest(replica_path + \"/log_ptr\", \"0\", zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeCreateRequest(query_path, entry.toString(), zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeRemoveRequest(counter_path, -1));\n+    current_zookeeper->multi(ops);\n+}\n+\n+void DatabaseReplicated::loadStoredObjects(Context & context, bool has_force_restore_data_flag, bool force_attach)\n+{\n+    tryConnectToZooKeeperAndInitDatabase(force_attach);\n+\n+    DatabaseAtomic::loadStoredObjects(context, has_force_restore_data_flag, force_attach);\n+\n+    ddl_worker = std::make_unique<DatabaseReplicatedDDLWorker>(this, global_context);\n+    ddl_worker->startup();\n+}\n+\n+BlockIO DatabaseReplicated::tryEnqueueReplicatedDDL(const ASTPtr & query, const Context & query_context)\n+{\n+    if (is_readonly)\n+        throw Exception(ErrorCodes::NO_ZOOKEEPER, \"Database is in readonly mode, because it cannot connect to ZooKeeper\");\n+\n+    if (query_context.getClientInfo().query_kind != ClientInfo::QueryKind::INITIAL_QUERY)\n+        throw Exception(ErrorCodes::INCORRECT_QUERY, \"It's not initial query. ON CLUSTER is not allowed for Replicated database.\");\n+\n+    /// Replicas will set correct name of current database in query context (database name can be different on replicas)\n+    if (auto * ddl_query = query->as<ASTQueryWithTableAndOutput>())\n+        ddl_query->database.clear();\n+\n+    if (const auto * query_alter = query->as<ASTAlterQuery>())\n+    {\n+        for (const auto & command : query_alter->command_list->children)\n+        {\n+            if (!isSupportedAlterType(command->as<ASTAlterCommand&>().type))\n+                throw Exception(\"Unsupported type of ALTER query\", ErrorCodes::NOT_IMPLEMENTED);\n+        }\n+    }\n+\n+    LOG_DEBUG(log, \"Proposing query: {}\", queryToString(query));\n+\n+    /// TODO maybe write current settings to log entry?\n+    DDLLogEntry entry;\n+    entry.query = queryToString(query);\n+    entry.initiator = ddl_worker->getCommonHostID();\n+    String node_path = ddl_worker->tryEnqueueAndExecuteEntry(entry, query_context);\n+\n+    BlockIO io;\n+    if (query_context.getSettingsRef().distributed_ddl_task_timeout == 0)\n+        return io;\n+\n+    Strings hosts_to_wait = getZooKeeper()->getChildren(zookeeper_path + \"/replicas\");\n+    auto stream = std::make_shared<DDLQueryStatusInputStream>(node_path, entry, query_context, hosts_to_wait);\n+    if (query_context.getSettingsRef().database_replicated_ddl_output)\n+        io.in = std::move(stream);\n+    return io;\n+}\n+\n+static UUID getTableUUIDIfReplicated(const String & metadata, const Context & context)\n+{\n+    bool looks_like_replicated = metadata.find(\"ReplicatedMergeTree\") != std::string::npos;\n+    if (!looks_like_replicated)\n+        return UUIDHelpers::Nil;\n+\n+    ParserCreateQuery parser;\n+    auto size = context.getSettingsRef().max_query_size;\n+    auto depth = context.getSettingsRef().max_parser_depth;\n+    ASTPtr query = parseQuery(parser, metadata, size, depth);\n+    const ASTCreateQuery & create = query->as<const ASTCreateQuery &>();\n+    if (!create.storage || !create.storage->engine)\n+        return UUIDHelpers::Nil;\n+    if (!startsWith(create.storage->engine->name, \"Replicated\") || !endsWith(create.storage->engine->name, \"MergeTree\"))\n+        return UUIDHelpers::Nil;\n+    assert(create.uuid != UUIDHelpers::Nil);\n+    return create.uuid;\n+}\n+\n+void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeeper, UInt32 our_log_ptr, UInt32 max_log_ptr)\n+{\n+    /// Let's compare local (possibly outdated) metadata with (most actual) metadata stored in ZooKeeper\n+    /// and try to update the set of local tables.\n+    /// We could drop all local tables and create the new ones just like it's new replica.\n+    /// But it will cause all ReplicatedMergeTree tables to fetch all data parts again and data in other tables will be lost.\n+\n+    bool new_replica = our_log_ptr == 0;\n+    if (new_replica)\n+        LOG_INFO(log, \"Will create new replica from log pointer {}\", max_log_ptr);\n+    else\n+        LOG_WARNING(log, \"Will recover replica with staled log pointer {} from log pointer {}\", our_log_ptr, max_log_ptr);\n+\n+    if (new_replica && !empty())\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"It's new replica, but database is not empty\");\n+\n+    auto table_name_to_metadata = tryGetConsistentMetadataSnapshot(current_zookeeper, max_log_ptr);\n+\n+    /// For ReplicatedMergeTree tables we can compare only UUIDs to ensure that it's the same table.\n+    /// Metadata can be different, it's handled on table replication level.\n+    /// We need to handle renamed tables only.\n+    /// TODO maybe we should also update MergeTree SETTINGS if required?\n+    std::unordered_map<UUID, String> zk_replicated_id_to_name;\n+    for (const auto & zk_table : table_name_to_metadata)\n+    {\n+        UUID zk_replicated_id = getTableUUIDIfReplicated(zk_table.second, global_context);\n+        if (zk_replicated_id != UUIDHelpers::Nil)\n+            zk_replicated_id_to_name.emplace(zk_replicated_id, zk_table.first);\n+    }\n+\n+    /// We will drop or move tables which exist only in local metadata\n+    Strings tables_to_detach;\n+    std::vector<std::pair<String, String>> replicated_tables_to_rename;\n+    size_t total_tables = 0;\n+    std::vector<UUID> replicated_ids;\n+    for (auto existing_tables_it = getTablesIterator(global_context, {}); existing_tables_it->isValid(); existing_tables_it->next(), ++total_tables)\n+    {\n+        String name = existing_tables_it->name();\n+        UUID local_replicated_id = UUIDHelpers::Nil;\n+        if (existing_tables_it->table()->supportsReplication())\n+        {\n+            /// Check if replicated tables have the same UUID\n+            local_replicated_id = existing_tables_it->table()->getStorageID().uuid;\n+            auto it = zk_replicated_id_to_name.find(local_replicated_id);\n+            if (it != zk_replicated_id_to_name.end())\n+            {\n+                if (name != it->second)\n+                {\n+                    /// Need just update table name\n+                    replicated_tables_to_rename.emplace_back(name, it->second);\n+                }\n+                continue;\n+            }\n+        }\n+\n+        auto in_zk = table_name_to_metadata.find(name);\n+        if (in_zk == table_name_to_metadata.end() || in_zk->second != readMetadataFile(name))\n+        {\n+            /// Local table does not exits in ZooKeeper or has different metadata\n+            tables_to_detach.emplace_back(std::move(name));\n+        }\n+    }\n+\n+    String db_name = getDatabaseName();\n+    String to_db_name = getDatabaseName() + BROKEN_TABLES_SUFFIX;\n+    if (total_tables * db_settings.max_broken_tables_ratio < tables_to_detach.size())\n+        throw Exception(ErrorCodes::DATABASE_REPLICATION_FAILED, \"Too many tables to recreate: {} of {}\", tables_to_detach.size(), total_tables);\n+    else if (!tables_to_detach.empty())\n+    {\n+        LOG_WARNING(log, \"Will recreate {} broken tables to recover replica\", tables_to_detach.size());\n+        /// It's too dangerous to automatically drop tables, so we will move them to special database.\n+        /// We use Ordinary engine for destination database, because it's the only way to discard table UUID\n+        /// and make possible creation of new table with the same UUID.\n+        String query = fmt::format(\"CREATE DATABASE IF NOT EXISTS {} ENGINE=Ordinary\", backQuoteIfNeed(to_db_name));\n+        Context query_context = global_context;\n+        executeQuery(query, query_context, true);\n+    }\n+\n+    size_t dropped_dicts = 0;\n+    size_t moved_tables = 0;\n+    std::vector<UUID> dropped_tables;\n+    for (const auto & table_name : tables_to_detach)\n+    {\n+        DDLGuardPtr table_guard = DatabaseCatalog::instance().getDDLGuard(db_name, table_name);\n+        if (getDatabaseName() != db_name)\n+            throw Exception(ErrorCodes::UNKNOWN_DATABASE, \"Database was renamed, will retry\");\n+\n+        auto table = tryGetTable(table_name, global_context);\n+        if (isDictionaryExist(table_name))\n+        {\n+            /// We can safely drop any dictionaries because they do not store data\n+            LOG_DEBUG(log, \"Will DROP DICTIONARY {}\", backQuoteIfNeed(table_name));\n+            DatabaseAtomic::removeDictionary(global_context, table_name);\n+            ++dropped_dicts;\n+        }\n+        else if (!table->storesDataOnDisk())\n+        {\n+            LOG_DEBUG(log, \"Will DROP TABLE {}, because it does not store data on disk and can be safely dropped\", backQuoteIfNeed(table_name));\n+            dropped_tables.push_back(tryGetTableUUID(table_name));\n+            table->shutdown();\n+            DatabaseAtomic::dropTable(global_context, table_name, true);\n+        }\n+        else\n+        {\n+            /// Table probably stores some data. Let's move it to another database.\n+            String to_name = fmt::format(\"{}_{}_{}\", table_name, max_log_ptr, thread_local_rng() % 1000);\n+            LOG_DEBUG(log, \"Will RENAME TABLE {} TO {}.{}\", backQuoteIfNeed(table_name), backQuoteIfNeed(to_db_name), backQuoteIfNeed(to_name));\n+            assert(db_name < to_db_name);\n+            DDLGuardPtr to_table_guard = DatabaseCatalog::instance().getDDLGuard(to_db_name, to_name);\n+            auto to_db_ptr = DatabaseCatalog::instance().getDatabase(to_db_name);\n+            DatabaseAtomic::renameTable(global_context, table_name, *to_db_ptr, to_name, false, false);\n+            ++moved_tables;\n+        }\n+    }\n+\n+    if (!tables_to_detach.empty())\n+        LOG_WARNING(log, \"Cleaned {} outdated objects: dropped {} dictionaries and {} tables, moved {} tables\",\n+                    tables_to_detach.size(), dropped_dicts, dropped_tables.size(), moved_tables);\n+\n+    /// Now database is cleared from outdated tables, let's rename ReplicatedMergeTree tables to actual names\n+    for (const auto & old_to_new : replicated_tables_to_rename)\n+    {\n+        const String & from = old_to_new.first;\n+        const String & to = old_to_new.second;\n+\n+        LOG_DEBUG(log, \"Will RENAME TABLE {} TO {}\", backQuoteIfNeed(from), backQuoteIfNeed(to));\n+        /// TODO Maybe we should do it in two steps: rename all tables to temporary names and then rename them to actual names?\n+        DDLGuardPtr table_guard = DatabaseCatalog::instance().getDDLGuard(db_name, std::min(from, to));\n+        DDLGuardPtr to_table_guard = DatabaseCatalog::instance().getDDLGuard(db_name, std::max(from, to));\n+        DatabaseAtomic::renameTable(global_context, from, *this, to, false, false);\n+    }\n+\n+    for (const auto & id : dropped_tables)\n+        DatabaseCatalog::instance().waitTableFinallyDropped(id);\n+\n+    for (const auto & name_and_meta : table_name_to_metadata)\n+    {\n+        if (isTableExist(name_and_meta.first, global_context))\n+        {\n+            assert(name_and_meta.second == readMetadataFile(name_and_meta.first));\n+            continue;\n+        }\n+\n+        auto query_ast = parseQueryFromMetadataInZooKeeper(name_and_meta.first, name_and_meta.second);\n+\n+        Context query_context = global_context;\n+        query_context.makeQueryContext();\n+        query_context.getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n+        query_context.setCurrentDatabase(database_name);\n+        query_context.setCurrentQueryId(\"\"); // generate random query_id\n+\n+        LOG_INFO(log, \"Executing {}\", serializeAST(*query_ast));\n+        InterpreterCreateQuery(query_ast, query_context).execute();\n+    }\n+\n+    current_zookeeper->set(replica_path + \"/log_ptr\", toString(max_log_ptr));\n+}\n+\n+std::map<String, String> DatabaseReplicated::tryGetConsistentMetadataSnapshot(const ZooKeeperPtr & zookeeper, UInt32 & max_log_ptr)\n+{\n+    std::map<String, String> table_name_to_metadata;\n+    constexpr int max_retries = 10;\n+    int iteration = 0;\n+    while (++iteration <= max_retries)\n+    {\n+        table_name_to_metadata.clear();\n+        LOG_DEBUG(log, \"Trying to get consistent metadata snapshot for log pointer {}\", max_log_ptr);\n+        Strings table_names = zookeeper->getChildren(zookeeper_path + \"/metadata\");\n+\n+        std::vector<zkutil::ZooKeeper::FutureGet> futures;\n+        futures.reserve(table_names.size());\n+        for (const auto & table : table_names)\n+            futures.emplace_back(zookeeper->asyncTryGet(zookeeper_path + \"/metadata/\" + table));\n+\n+        for (size_t i = 0; i < table_names.size(); ++i)\n+        {\n+            auto res = futures[i].get();\n+            if (res.error != Coordination::Error::ZOK)\n+                break;\n+            table_name_to_metadata.emplace(unescapeForFileName(table_names[i]), res.data);\n+        }\n+\n+        UInt32 new_max_log_ptr = parse<UInt32>(zookeeper->get(zookeeper_path + \"/max_log_ptr\"));\n+        if (new_max_log_ptr == max_log_ptr && table_names.size() == table_name_to_metadata.size())\n+            break;\n+\n+        if (max_log_ptr < new_max_log_ptr)\n+        {\n+            LOG_DEBUG(log, \"Log pointer moved from {} to {}, will retry\", max_log_ptr, new_max_log_ptr);\n+            max_log_ptr = new_max_log_ptr;\n+        }\n+        else\n+        {\n+            assert(max_log_ptr == new_max_log_ptr);\n+            assert(table_names.size() != table_name_to_metadata.size());\n+            LOG_DEBUG(log, \"Cannot get metadata of some tables due to ZooKeeper error, will retry\");\n+        }\n+    }\n+\n+    if (max_retries < iteration)\n+        throw Exception(ErrorCodes::DATABASE_REPLICATION_FAILED, \"Cannot get consistent metadata snapshot\");\n+\n+    LOG_DEBUG(log, \"Got consistent metadata snapshot for log pointer {}\", max_log_ptr);\n+\n+    return table_name_to_metadata;\n+}\n+\n+ASTPtr DatabaseReplicated::parseQueryFromMetadataInZooKeeper(const String & node_name, const String & query)\n+{\n+    ParserCreateQuery parser;\n+    String description = \"in ZooKeeper \" + zookeeper_path + \"/metadata/\" + node_name;\n+    auto ast = parseQuery(parser, query, description, 0, global_context.getSettingsRef().max_parser_depth);\n+\n+    auto & create = ast->as<ASTCreateQuery &>();\n+    if (create.uuid == UUIDHelpers::Nil || create.table != TABLE_WITH_UUID_NAME_PLACEHOLDER || ! create.database.empty())\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Got unexpected query from {}: {}\", node_name, query);\n+\n+    create.database = getDatabaseName();\n+    create.table = unescapeForFileName(node_name);\n+    create.attach = false;\n+\n+    return ast;\n+}\n+\n+void DatabaseReplicated::drop(const Context & context_)\n+{\n+    auto current_zookeeper = getZooKeeper();\n+    current_zookeeper->set(replica_path, DROPPED_MARK);\n+    DatabaseAtomic::drop(context_);\n+    current_zookeeper->tryRemoveRecursive(replica_path);\n+    /// TODO it may leave garbage in ZooKeeper if the last node lost connection here\n+    if (current_zookeeper->tryRemove(zookeeper_path + \"/replicas\") == Coordination::Error::ZOK)\n+    {\n+        /// It was the last replica, remove all metadata\n+        current_zookeeper->tryRemoveRecursive(zookeeper_path);\n+    }\n+}\n+\n+void DatabaseReplicated::stopReplication()\n+{\n+    if (ddl_worker)\n+        ddl_worker->shutdown();\n+}\n+\n+void DatabaseReplicated::shutdown()\n+{\n+    stopReplication();\n+    ddl_worker = nullptr;\n+    DatabaseAtomic::shutdown();\n+}\n+\n+\n+void DatabaseReplicated::dropTable(const Context & context, const String & table_name, bool no_delay)\n+{\n+    auto txn = context.getZooKeeperMetadataTransaction();\n+    assert(!ddl_worker->isCurrentlyActive() || txn);\n+    if (txn && txn->isInitialQuery())\n+    {\n+        String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(table_name);\n+        txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path, -1));\n+    }\n+    DatabaseAtomic::dropTable(context, table_name, no_delay);\n+}\n+\n+void DatabaseReplicated::renameTable(const Context & context, const String & table_name, IDatabase & to_database,\n+                                     const String & to_table_name, bool exchange, bool dictionary)\n+{\n+    auto txn = context.getZooKeeperMetadataTransaction();\n+    assert(txn);\n+\n+    if (txn->isInitialQuery())\n+    {\n+        if (this != &to_database)\n+            throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Moving tables between databases is not supported for Replicated engine\");\n+        if (table_name == to_table_name)\n+            throw Exception(ErrorCodes::INCORRECT_QUERY, \"Cannot rename table to itself\");\n+        if (!isTableExist(table_name, context))\n+            throw Exception(ErrorCodes::UNKNOWN_TABLE, \"Table {} does not exist\", table_name);\n+        if (exchange && !to_database.isTableExist(to_table_name, context))\n+            throw Exception(ErrorCodes::UNKNOWN_TABLE, \"Table {} does not exist\", to_table_name);\n+\n+        String statement = readMetadataFile(table_name);\n+        String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(table_name);\n+        String metadata_zk_path_to = zookeeper_path + \"/metadata/\" + escapeForFileName(to_table_name);\n+        txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path, -1));\n+        if (exchange)\n+        {\n+            String statement_to = readMetadataFile(to_table_name);\n+            txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path_to, -1));\n+            txn->addOp(zkutil::makeCreateRequest(metadata_zk_path, statement_to, zkutil::CreateMode::Persistent));\n+        }\n+        txn->addOp(zkutil::makeCreateRequest(metadata_zk_path_to, statement, zkutil::CreateMode::Persistent));\n+    }\n+\n+    DatabaseAtomic::renameTable(context, table_name, to_database, to_table_name, exchange, dictionary);\n+}\n+\n+void DatabaseReplicated::commitCreateTable(const ASTCreateQuery & query, const StoragePtr & table,\n+                       const String & table_metadata_tmp_path, const String & table_metadata_path,\n+                       const Context & query_context)\n+{\n+    auto txn = query_context.getZooKeeperMetadataTransaction();\n+    assert(!ddl_worker->isCurrentlyActive() || txn);\n+    if (txn && txn->isInitialQuery())\n+    {\n+        String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(query.table);\n+        String statement = getObjectDefinitionFromCreateQuery(query.clone());\n+        /// zk::multi(...) will throw if `metadata_zk_path` exists\n+        txn->addOp(zkutil::makeCreateRequest(metadata_zk_path, statement, zkutil::CreateMode::Persistent));\n+    }\n+    DatabaseAtomic::commitCreateTable(query, table, table_metadata_tmp_path, table_metadata_path, query_context);\n+}\n+\n+void DatabaseReplicated::commitAlterTable(const StorageID & table_id,\n+                                          const String & table_metadata_tmp_path, const String & table_metadata_path,\n+                                          const String & statement, const Context & query_context)\n+{\n+    auto txn = query_context.getZooKeeperMetadataTransaction();\n+    if (txn && txn->isInitialQuery())\n+    {\n+        String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(table_id.table_name);\n+        txn->addOp(zkutil::makeSetRequest(metadata_zk_path, statement, -1));\n+    }\n+    DatabaseAtomic::commitAlterTable(table_id, table_metadata_tmp_path, table_metadata_path, statement, query_context);\n+}\n+\n+void DatabaseReplicated::createDictionary(const Context & context,\n+                                          const String & dictionary_name,\n+                                          const ASTPtr & query)\n+{\n+    auto txn = context.getZooKeeperMetadataTransaction();\n+    assert(!ddl_worker->isCurrentlyActive() || txn);\n+    if (txn && txn->isInitialQuery())\n+    {\n+        String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(dictionary_name);\n+        String statement = getObjectDefinitionFromCreateQuery(query->clone());\n+        txn->addOp(zkutil::makeCreateRequest(metadata_zk_path, statement, zkutil::CreateMode::Persistent));\n+    }\n+    DatabaseAtomic::createDictionary(context, dictionary_name, query);\n+}\n+\n+void DatabaseReplicated::removeDictionary(const Context & context, const String & dictionary_name)\n+{\n+    auto txn = context.getZooKeeperMetadataTransaction();\n+    assert(!ddl_worker->isCurrentlyActive() || txn);\n+    if (txn && txn->isInitialQuery())\n+    {\n+        String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(dictionary_name);\n+        txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path, -1));\n+    }\n+    DatabaseAtomic::removeDictionary(context, dictionary_name);\n+}\n+\n+void DatabaseReplicated::detachTablePermanently(const Context & context, const String & table_name)\n+{\n+    auto txn = context.getZooKeeperMetadataTransaction();\n+    assert(!ddl_worker->isCurrentlyActive() || txn);\n+    if (txn && txn->isInitialQuery())\n+    {\n+        String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(table_name);\n+        txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path, -1));\n+    }\n+    DatabaseAtomic::detachTablePermanently(context, table_name);\n+}\n+\n+String DatabaseReplicated::readMetadataFile(const String & table_name) const\n+{\n+    String statement;\n+    ReadBufferFromFile in(getObjectMetadataPath(table_name), 4096);\n+    readStringUntilEOF(statement, in);\n+    return statement;\n+}\n+\n+}\ndiff --git a/src/Databases/DatabaseReplicated.h b/src/Databases/DatabaseReplicated.h\nnew file mode 100644\nindex 000000000000..fde53cf2c294\n--- /dev/null\n+++ b/src/Databases/DatabaseReplicated.h\n@@ -0,0 +1,91 @@\n+#pragma once\n+\n+#include <Databases/DatabaseAtomic.h>\n+#include <Databases/DatabaseReplicatedSettings.h>\n+#include <Common/ZooKeeper/ZooKeeper.h>\n+#include <Core/BackgroundSchedulePool.h>\n+#include <DataStreams/BlockIO.h>\n+#include <DataStreams/OneBlockInputStream.h>\n+#include <Interpreters/Context.h>\n+\n+\n+namespace DB\n+{\n+\n+class DatabaseReplicatedDDLWorker;\n+using ZooKeeperPtr = std::shared_ptr<zkutil::ZooKeeper>;\n+\n+class Cluster;\n+using ClusterPtr = std::shared_ptr<Cluster>;\n+\n+class DatabaseReplicated : public DatabaseAtomic\n+{\n+public:\n+    DatabaseReplicated(const String & name_, const String & metadata_path_, UUID uuid,\n+                       const String & zookeeper_path_, const String & shard_name_, const String & replica_name_,\n+                       DatabaseReplicatedSettings db_settings_,\n+                       const Context & context);\n+\n+    ~DatabaseReplicated() override;\n+\n+    String getEngineName() const override { return \"Replicated\"; }\n+\n+    /// If current query is initial, then the following methods add metadata updating ZooKeeper operations to current ZooKeeperMetadataTransaction.\n+    void dropTable(const Context &, const String & table_name, bool no_delay) override;\n+    void renameTable(const Context & context, const String & table_name, IDatabase & to_database,\n+                     const String & to_table_name, bool exchange, bool dictionary) override;\n+    void commitCreateTable(const ASTCreateQuery & query, const StoragePtr & table,\n+                           const String & table_metadata_tmp_path, const String & table_metadata_path,\n+                           const Context & query_context) override;\n+    void commitAlterTable(const StorageID & table_id,\n+                          const String & table_metadata_tmp_path, const String & table_metadata_path,\n+                          const String & statement, const Context & query_context) override;\n+    void createDictionary(const Context & context,\n+                          const String & dictionary_name,\n+                          const ASTPtr & query) override;\n+    void removeDictionary(const Context & context, const String & dictionary_name) override;\n+    void detachTablePermanently(const Context & context, const String & table_name) override;\n+\n+    /// Try to execute DLL query on current host as initial query. If query is succeed,\n+    /// then it will be executed on all replicas.\n+    BlockIO tryEnqueueReplicatedDDL(const ASTPtr & query, const Context & query_context);\n+\n+    void stopReplication();\n+\n+    String getFullReplicaName() const;\n+    static std::pair<String, String> parseFullReplicaName(const String & name);\n+\n+    /// Returns cluster consisting of database replicas\n+    ClusterPtr getCluster() const;\n+\n+    void drop(const Context & /*context*/) override;\n+\n+    void loadStoredObjects(Context & context, bool has_force_restore_data_flag, bool force_attach) override;\n+    void shutdown() override;\n+\n+    friend struct DatabaseReplicatedTask;\n+    friend class DatabaseReplicatedDDLWorker;\n+private:\n+    void tryConnectToZooKeeperAndInitDatabase(bool force_attach);\n+    bool createDatabaseNodesInZooKeeper(const ZooKeeperPtr & current_zookeeper);\n+    void createReplicaNodesInZooKeeper(const ZooKeeperPtr & current_zookeeper);\n+\n+    void recoverLostReplica(const ZooKeeperPtr & current_zookeeper, UInt32 our_log_ptr, UInt32 max_log_ptr);\n+    std::map<String, String> tryGetConsistentMetadataSnapshot(const ZooKeeperPtr & zookeeper, UInt32 & max_log_ptr);\n+\n+    ASTPtr parseQueryFromMetadataInZooKeeper(const String & node_name, const String & query);\n+    String readMetadataFile(const String & table_name) const;\n+\n+    String zookeeper_path;\n+    String shard_name;\n+    String replica_name;\n+    String replica_path;\n+    DatabaseReplicatedSettings db_settings;\n+\n+    zkutil::ZooKeeperPtr getZooKeeper() const;\n+\n+    std::atomic_bool is_readonly = true;\n+    std::unique_ptr<DatabaseReplicatedDDLWorker> ddl_worker;\n+};\n+\n+}\ndiff --git a/src/Databases/DatabaseReplicatedSettings.cpp b/src/Databases/DatabaseReplicatedSettings.cpp\nnew file mode 100644\nindex 000000000000..61febcf28100\n--- /dev/null\n+++ b/src/Databases/DatabaseReplicatedSettings.cpp\n@@ -0,0 +1,23 @@\n+#include <Databases/DatabaseReplicatedSettings.h>\n+#include <Parsers/ASTFunction.h>\n+#include <Parsers/ASTCreateQuery.h>\n+\n+namespace DB\n+{\n+\n+IMPLEMENT_SETTINGS_TRAITS(DatabaseReplicatedSettingsTraits, LIST_OF_DATABASE_REPLICATED_SETTINGS)\n+\n+void DatabaseReplicatedSettings::loadFromQuery(ASTStorage & storage_def)\n+{\n+    if (storage_def.settings)\n+    {\n+        applyChanges(storage_def.settings->changes);\n+        return;\n+    }\n+\n+    auto settings_ast = std::make_shared<ASTSetQuery>();\n+    settings_ast->is_standalone = false;\n+    storage_def.set(storage_def.settings, settings_ast);\n+}\n+\n+}\ndiff --git a/src/Databases/DatabaseReplicatedSettings.h b/src/Databases/DatabaseReplicatedSettings.h\nnew file mode 100644\nindex 000000000000..11d5b3820e43\n--- /dev/null\n+++ b/src/Databases/DatabaseReplicatedSettings.h\n@@ -0,0 +1,26 @@\n+#pragma once\n+#include <Core/Defines.h>\n+#include <Core/BaseSettings.h>\n+\n+namespace DB\n+{\n+\n+class ASTStorage;\n+\n+#define LIST_OF_DATABASE_REPLICATED_SETTINGS(M) \\\n+    M(Float, max_broken_tables_ratio, 0.5, \"Do not recover replica automatically if the ratio of staled tables to all tables is greater\", 0) \\\n+    M(UInt64, max_replication_lag_to_enqueue, 10, \"Replica will throw exception on attempt to execute query if its replication lag greater\", 0) \\\n+    M(UInt64, wait_entry_commited_timeout_sec, 3600, \"Replicas will try to cancel query if timeout exceed, but initiator host has not executed it yet\", 0) \\\n+\n+DECLARE_SETTINGS_TRAITS(DatabaseReplicatedSettingsTraits, LIST_OF_DATABASE_REPLICATED_SETTINGS)\n+\n+\n+/** Settings for the MaterializeMySQL database engine.\n+  * Could be loaded from a CREATE DATABASE query (SETTINGS clause).\n+  */\n+struct DatabaseReplicatedSettings : public BaseSettings<DatabaseReplicatedSettingsTraits>\n+{\n+    void loadFromQuery(ASTStorage & storage_def);\n+};\n+\n+}\ndiff --git a/src/Databases/DatabaseReplicatedWorker.cpp b/src/Databases/DatabaseReplicatedWorker.cpp\nnew file mode 100644\nindex 000000000000..e0c5717711ce\n--- /dev/null\n+++ b/src/Databases/DatabaseReplicatedWorker.cpp\n@@ -0,0 +1,260 @@\n+#include <Databases/DatabaseReplicatedWorker.h>\n+#include <Databases/DatabaseReplicated.h>\n+#include <Interpreters/DDLTask.h>\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int LOGICAL_ERROR;\n+    extern const int DATABASE_REPLICATION_FAILED;\n+    extern const int NOT_A_LEADER;\n+    extern const int UNFINISHED;\n+}\n+\n+DatabaseReplicatedDDLWorker::DatabaseReplicatedDDLWorker(DatabaseReplicated * db, const Context & context_)\n+    : DDLWorker(/* pool_size */ 1, db->zookeeper_path + \"/log\", context_, nullptr, {}, fmt::format(\"DDLWorker({})\", db->getDatabaseName()))\n+    , database(db)\n+{\n+    /// Pool size must be 1 to avoid reordering of log entries.\n+    /// TODO Make a dependency graph of DDL queries. It will allow to execute independent entries in parallel.\n+    /// We also need similar graph to load tables on server startup in order of topsort.\n+}\n+\n+void DatabaseReplicatedDDLWorker::initializeMainThread()\n+{\n+    while (!stop_flag)\n+    {\n+        try\n+        {\n+            auto zookeeper = getAndSetZooKeeper();\n+            if (database->is_readonly)\n+                database->tryConnectToZooKeeperAndInitDatabase(false);\n+            initializeReplication();\n+            initialized = true;\n+            return;\n+        }\n+        catch (...)\n+        {\n+            tryLogCurrentException(log, fmt::format(\"Error on initialization of {}\", database->getDatabaseName()));\n+            sleepForSeconds(5);\n+        }\n+    }\n+}\n+\n+void DatabaseReplicatedDDLWorker::shutdown()\n+{\n+    DDLWorker::shutdown();\n+    wait_current_task_change.notify_all();\n+}\n+\n+void DatabaseReplicatedDDLWorker::initializeReplication()\n+{\n+    /// Check if we need to recover replica.\n+    /// Invariant: replica is lost if it's log_ptr value is less then max_log_ptr - logs_to_keep.\n+\n+    String log_ptr_str = current_zookeeper->get(database->replica_path + \"/log_ptr\");\n+    UInt32 our_log_ptr = parse<UInt32>(log_ptr_str);\n+    UInt32 max_log_ptr = parse<UInt32>(current_zookeeper->get(database->zookeeper_path + \"/max_log_ptr\"));\n+    logs_to_keep = parse<UInt32>(current_zookeeper->get(database->zookeeper_path + \"/logs_to_keep\"));\n+    if (our_log_ptr == 0 || our_log_ptr + logs_to_keep < max_log_ptr)\n+        database->recoverLostReplica(current_zookeeper, our_log_ptr, max_log_ptr);\n+    else\n+        last_skipped_entry_name.emplace(log_ptr_str);\n+}\n+\n+String DatabaseReplicatedDDLWorker::enqueueQuery(DDLLogEntry & entry)\n+{\n+    auto zookeeper = getAndSetZooKeeper();\n+    const String query_path_prefix = queue_dir + \"/query-\";\n+\n+    /// We cannot create sequential node and it's ephemeral child in a single transaction, so allocate sequential number another way\n+    String counter_prefix = database->zookeeper_path + \"/counter/cnt-\";\n+    String counter_path = zookeeper->create(counter_prefix, \"\", zkutil::CreateMode::EphemeralSequential);\n+    String node_path = query_path_prefix + counter_path.substr(counter_prefix.size());\n+\n+    Coordination::Requests ops;\n+    /// Query is not committed yet, but we have to write it into log to avoid reordering\n+    ops.emplace_back(zkutil::makeCreateRequest(node_path, entry.toString(), zkutil::CreateMode::Persistent));\n+    /// '/try' will be replaced with '/committed' or will be removed due to expired session or other error\n+    ops.emplace_back(zkutil::makeCreateRequest(node_path + \"/try\", database->getFullReplicaName(), zkutil::CreateMode::Ephemeral));\n+    /// We don't need it anymore\n+    ops.emplace_back(zkutil::makeRemoveRequest(counter_path, -1));\n+    /// Create status dirs\n+    ops.emplace_back(zkutil::makeCreateRequest(node_path + \"/active\", \"\", zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeCreateRequest(node_path + \"/finished\", \"\", zkutil::CreateMode::Persistent));\n+    zookeeper->multi(ops);\n+\n+    return node_path;\n+}\n+\n+String DatabaseReplicatedDDLWorker::tryEnqueueAndExecuteEntry(DDLLogEntry & entry, const Context & query_context)\n+{\n+    /// NOTE Possibly it would be better to execute initial query on the most up-to-date node,\n+    /// but it requires more complex logic around /try node.\n+\n+    auto zookeeper = getAndSetZooKeeper();\n+    UInt32 our_log_ptr = parse<UInt32>(zookeeper->get(database->replica_path + \"/log_ptr\"));\n+    UInt32 max_log_ptr = parse<UInt32>(zookeeper->get(database->zookeeper_path + \"/max_log_ptr\"));\n+    assert(our_log_ptr <= max_log_ptr);\n+    if (database->db_settings.max_replication_lag_to_enqueue < max_log_ptr - our_log_ptr)\n+        throw Exception(ErrorCodes::NOT_A_LEADER, \"Cannot enqueue query on this replica, \"\n+                        \"because it has replication lag of {} queries. Try other replica.\", max_log_ptr - our_log_ptr);\n+\n+    String entry_path = enqueueQuery(entry);\n+    auto try_node = zkutil::EphemeralNodeHolder::existing(entry_path + \"/try\", *zookeeper);\n+    String entry_name = entry_path.substr(entry_path.rfind('/') + 1);\n+    auto task = std::make_unique<DatabaseReplicatedTask>(entry_name, entry_path, database);\n+    task->entry = entry;\n+    task->parseQueryFromEntry(context);\n+    assert(!task->entry.query.empty());\n+    assert(!zookeeper->exists(task->getFinishedNodePath()));\n+    task->is_initial_query = true;\n+\n+    LOG_DEBUG(log, \"Waiting for worker thread to process all entries before {}\", entry_name);\n+    UInt64 timeout = query_context.getSettingsRef().database_replicated_initial_query_timeout_sec;\n+    {\n+        std::unique_lock lock{mutex};\n+        bool processed = wait_current_task_change.wait_for(lock, std::chrono::seconds(timeout), [&]()\n+        {\n+            assert(zookeeper->expired() || current_task <= entry_name);\n+            return zookeeper->expired() || current_task == entry_name || stop_flag;\n+        });\n+\n+        if (!processed)\n+            throw Exception(ErrorCodes::UNFINISHED, \"Timeout: Cannot enqueue query on this replica,\"\n+                            \"most likely because replica is busy with previous queue entries\");\n+    }\n+\n+    if (zookeeper->expired() || stop_flag)\n+        throw Exception(ErrorCodes::DATABASE_REPLICATION_FAILED, \"ZooKeeper session expired or replication stopped, try again\");\n+\n+    processTask(*task, zookeeper);\n+\n+    if (!task->was_executed)\n+    {\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Entry {} was executed, but was not committed: code {}: {}\",\n+                        task->execution_status.code, task->execution_status.message);\n+    }\n+\n+    try_node->setAlreadyRemoved();\n+\n+    return entry_path;\n+}\n+\n+DDLTaskPtr DatabaseReplicatedDDLWorker::initAndCheckTask(const String & entry_name, String & out_reason, const ZooKeeperPtr & zookeeper)\n+{\n+    {\n+        std::lock_guard lock{mutex};\n+        if (current_task < entry_name)\n+        {\n+            current_task = entry_name;\n+            wait_current_task_change.notify_all();\n+        }\n+    }\n+\n+    UInt32 our_log_ptr = parse<UInt32>(current_zookeeper->get(database->replica_path + \"/log_ptr\"));\n+    UInt32 entry_num = DatabaseReplicatedTask::getLogEntryNumber(entry_name);\n+\n+    if (entry_num <= our_log_ptr)\n+    {\n+        out_reason = fmt::format(\"Task {} already executed according to log pointer {}\", entry_name, our_log_ptr);\n+        return {};\n+    }\n+\n+    String entry_path = queue_dir + \"/\" + entry_name;\n+    auto task = std::make_unique<DatabaseReplicatedTask>(entry_name, entry_path, database);\n+\n+    String initiator_name;\n+    zkutil::EventPtr wait_committed_or_failed = std::make_shared<Poco::Event>();\n+\n+    String try_node_path = entry_path + \"/try\";\n+    if (zookeeper->tryGet(try_node_path, initiator_name, nullptr, wait_committed_or_failed))\n+    {\n+        task->is_initial_query = initiator_name == task->host_id_str;\n+\n+        /// Query is not committed yet. We cannot just skip it and execute next one, because reordering may break replication.\n+        LOG_TRACE(log, \"Waiting for initiator {} to commit or rollback entry {}\", initiator_name, entry_path);\n+        constexpr size_t wait_time_ms = 1000;\n+        size_t max_iterations = database->db_settings.wait_entry_commited_timeout_sec;\n+        size_t iteration = 0;\n+\n+        while (!wait_committed_or_failed->tryWait(wait_time_ms))\n+        {\n+            if (stop_flag)\n+            {\n+                /// We cannot return task to process and we cannot return nullptr too,\n+                /// because nullptr means \"task should not be executed\".\n+                /// We can only exit by exception.\n+                throw Exception(ErrorCodes::UNFINISHED, \"Replication was stopped\");\n+            }\n+\n+            if (max_iterations <= ++iteration)\n+            {\n+                /// What can we do if initiator hangs for some reason? Seems like we can remove /try node.\n+                /// Initiator will fail to commit ZooKeeperMetadataTransaction (including ops for replicated table) if /try does not exist.\n+                /// But it's questionable.\n+\n+                /// We use tryRemove(...) because multiple hosts (including initiator) may try to do it concurrently.\n+                auto code = zookeeper->tryRemove(try_node_path);\n+                if (code != Coordination::Error::ZOK && code != Coordination::Error::ZNONODE)\n+                    throw Coordination::Exception(code, try_node_path);\n+\n+                if (!zookeeper->exists(entry_path + \"/committed\"))\n+                {\n+                    out_reason = fmt::format(\"Entry {} was forcefully cancelled due to timeout\", entry_name);\n+                    return {};\n+                }\n+            }\n+        }\n+    }\n+\n+    if (!zookeeper->exists(entry_path + \"/committed\"))\n+    {\n+        out_reason = fmt::format(\"Entry {} hasn't been committed\", entry_name);\n+        return {};\n+    }\n+\n+    if (task->is_initial_query)\n+    {\n+        assert(!zookeeper->exists(entry_path + \"/try\"));\n+        assert(zookeeper->exists(entry_path + \"/committed\") == (zookeeper->get(task->getFinishedNodePath()) == ExecutionStatus(0).serializeText()));\n+        out_reason = fmt::format(\"Entry {} has been executed as initial query\", entry_name);\n+        return {};\n+    }\n+\n+    String node_data;\n+    if (!zookeeper->tryGet(entry_path, node_data))\n+    {\n+        LOG_ERROR(log, \"Cannot get log entry {}\", entry_path);\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"should be unreachable\");\n+    }\n+\n+    task->entry.parse(node_data);\n+\n+    if (task->entry.query.empty())\n+    {\n+        out_reason = fmt::format(\"Entry {} is a dummy task\", entry_name);\n+        return {};\n+    }\n+\n+    task->parseQueryFromEntry(context);\n+\n+    if (zookeeper->exists(task->getFinishedNodePath()))\n+    {\n+        out_reason = fmt::format(\"Task {} has been already processed\", entry_name);\n+        return {};\n+    }\n+\n+    return task;\n+}\n+\n+bool DatabaseReplicatedDDLWorker::canRemoveQueueEntry(const String & entry_name, const Coordination::Stat &)\n+{\n+    UInt32 entry_number = DDLTaskBase::getLogEntryNumber(entry_name);\n+    UInt32 max_log_ptr = parse<UInt32>(getAndSetZooKeeper()->get(database->zookeeper_path + \"/max_log_ptr\"));\n+    return entry_number + logs_to_keep < max_log_ptr;\n+}\n+\n+}\ndiff --git a/src/Databases/DatabaseReplicatedWorker.h b/src/Databases/DatabaseReplicatedWorker.h\nnew file mode 100644\nindex 000000000000..6ba46a98bca4\n--- /dev/null\n+++ b/src/Databases/DatabaseReplicatedWorker.h\n@@ -0,0 +1,46 @@\n+#pragma once\n+#include <Interpreters/DDLWorker.h>\n+\n+namespace DB\n+{\n+\n+class DatabaseReplicated;\n+\n+/// It's similar to DDLWorker, but has the following differences:\n+/// 1. DDL queue in ZooKeeper is not shared between multiple clusters and databases,\n+///    each DatabaseReplicated has its own queue in ZooKeeper and DatabaseReplicatedDDLWorker object.\n+/// 2. Shards and replicas are identified by shard_name and replica_name arguments of database engine,\n+///    not by address:port pairs. Cluster (of multiple database replicas) is identified by its zookeeper_path.\n+/// 3. After creation of an entry in DDL queue initiator tries to execute the entry locally\n+///    and other hosts wait for query to finish on initiator host.\n+///    If query succeed on initiator, then all hosts must execute it, so they will retry until query succeed.\n+///    We assume that cluster is homogeneous, so if replicas are in consistent state and query succeed on one host,\n+///    then all hosts can execute it (maybe after several retries).\n+/// 4. Each database replica stores its log pointer in ZooKeeper. Cleanup thread removes old entry\n+///    if its number < max_log_ptr - logs_to_keep.\n+class DatabaseReplicatedDDLWorker : public DDLWorker\n+{\n+public:\n+    DatabaseReplicatedDDLWorker(DatabaseReplicated * db, const Context & context_);\n+\n+    String enqueueQuery(DDLLogEntry & entry) override;\n+\n+    String tryEnqueueAndExecuteEntry(DDLLogEntry & entry, const Context & query_context);\n+\n+    void shutdown() override;\n+\n+private:\n+    void initializeMainThread() override;\n+    void initializeReplication();\n+\n+    DDLTaskPtr initAndCheckTask(const String & entry_name, String & out_reason, const ZooKeeperPtr & zookeeper) override;\n+    bool canRemoveQueueEntry(const String & entry_name, const Coordination::Stat & stat) override;\n+\n+    DatabaseReplicated * const database;\n+    mutable std::mutex mutex;\n+    std::condition_variable wait_current_task_change;\n+    String current_task;\n+    UInt32 logs_to_keep = std::numeric_limits<UInt32>::max();\n+};\n+\n+}\ndiff --git a/src/Databases/DatabaseWithDictionaries.cpp b/src/Databases/DatabaseWithDictionaries.cpp\nindex ee16f4ae15e6..d92f0f1897e6 100644\n--- a/src/Databases/DatabaseWithDictionaries.cpp\n+++ b/src/Databases/DatabaseWithDictionaries.cpp\n@@ -4,6 +4,7 @@\n #include <Interpreters/ExternalDictionariesLoader.h>\n #include <Interpreters/ExternalLoaderTempConfigRepository.h>\n #include <Interpreters/ExternalLoaderDatabaseConfigRepository.h>\n+#include <Interpreters/DDLTask.h>\n #include <Dictionaries/getDictionaryConfigurationFromAST.h>\n #include <Dictionaries/DictionaryStructure.h>\n #include <Parsers/ASTCreateQuery.h>\n@@ -193,6 +194,10 @@ void DatabaseWithDictionaries::createDictionary(const Context & context, const S\n             detachDictionary(dictionary_name);\n     });\n \n+    auto txn = context.getZooKeeperMetadataTransaction();\n+    if (txn && !context.isInternalSubquery())\n+        txn->commit();      /// Commit point (a sort of) for Replicated database\n+\n     /// If it was ATTACH query and file with dictionary metadata already exist\n     /// (so, ATTACH is done after DETACH), then rename atomically replaces old file with new one.\n     Poco::File(dictionary_metadata_tmp_path).renameTo(dictionary_metadata_path);\n@@ -205,7 +210,7 @@ void DatabaseWithDictionaries::createDictionary(const Context & context, const S\n     succeeded = true;\n }\n \n-void DatabaseWithDictionaries::removeDictionary(const Context &, const String & dictionary_name)\n+void DatabaseWithDictionaries::removeDictionary(const Context & context, const String & dictionary_name)\n {\n     DictionaryAttachInfo attach_info;\n     detachDictionaryImpl(dictionary_name, attach_info);\n@@ -213,6 +218,11 @@ void DatabaseWithDictionaries::removeDictionary(const Context &, const String &\n     try\n     {\n         String dictionary_metadata_path = getObjectMetadataPath(dictionary_name);\n+\n+        auto txn = context.getZooKeeperMetadataTransaction();\n+        if (txn && !context.isInternalSubquery())\n+            txn->commit();      /// Commit point (a sort of) for Replicated database\n+\n         Poco::File(dictionary_metadata_path).remove();\n         CurrentStatusInfo::unset(CurrentStatusInfo::DictionaryStatus,\n                                  StorageID(attach_info.create_query).getInternalDictionaryName());\ndiff --git a/src/Databases/IDatabase.h b/src/Databases/IDatabase.h\nindex fc821fcab30f..3a196f827b71 100644\n--- a/src/Databases/IDatabase.h\n+++ b/src/Databases/IDatabase.h\n@@ -249,7 +249,7 @@ class IDatabase : public std::enable_shared_from_this<IDatabase>\n \n     /// Forget about the table without deleting it's data, but rename metadata file to prevent reloading it\n     /// with next restart. The database may not support this method.\n-    virtual void detachTablePermanently(const String & /*name*/)\n+    virtual void detachTablePermanently(const Context & /*context*/, const String & /*name*/)\n     {\n         throw Exception(\"There is no DETACH TABLE PERMANENTLY query for Database\" + getEngineName(), ErrorCodes::NOT_IMPLEMENTED);\n     }\ndiff --git a/src/Databases/MySQL/DatabaseConnectionMySQL.cpp b/src/Databases/MySQL/DatabaseConnectionMySQL.cpp\nindex 35b016f255b9..eeea12ae8f35 100644\n--- a/src/Databases/MySQL/DatabaseConnectionMySQL.cpp\n+++ b/src/Databases/MySQL/DatabaseConnectionMySQL.cpp\n@@ -395,7 +395,7 @@ void DatabaseConnectionMySQL::loadStoredObjects(Context &, bool, bool /*force_at\n     }\n }\n \n-void DatabaseConnectionMySQL::detachTablePermanently(const String & table_name)\n+void DatabaseConnectionMySQL::detachTablePermanently(const Context &, const String & table_name)\n {\n     std::lock_guard<std::mutex> lock{mutex};\n \n@@ -429,9 +429,9 @@ void DatabaseConnectionMySQL::detachTablePermanently(const String & table_name)\n     table_iter->second.second->is_dropped = true;\n }\n \n-void DatabaseConnectionMySQL::dropTable(const Context &, const String & table_name, bool /*no_delay*/)\n+void DatabaseConnectionMySQL::dropTable(const Context & context, const String & table_name, bool /*no_delay*/)\n {\n-    detachTablePermanently(table_name);\n+    detachTablePermanently(context, table_name);\n }\n \n DatabaseConnectionMySQL::~DatabaseConnectionMySQL()\ndiff --git a/src/Databases/MySQL/DatabaseConnectionMySQL.h b/src/Databases/MySQL/DatabaseConnectionMySQL.h\nindex 3e305fcb20df..d0a5c041d7b5 100644\n--- a/src/Databases/MySQL/DatabaseConnectionMySQL.h\n+++ b/src/Databases/MySQL/DatabaseConnectionMySQL.h\n@@ -72,9 +72,9 @@ class DatabaseConnectionMySQL final : public IDatabase\n \n     StoragePtr detachTable(const String & table_name) override;\n \n-    void detachTablePermanently(const String & table_name) override;\n+    void detachTablePermanently(const Context & context, const String & table_name) override;\n \n-    void dropTable(const Context &, const String & table_name, bool no_delay) override;\n+    void dropTable(const Context & context, const String & table_name, bool no_delay) override;\n \n     void attachTable(const String & table_name, const StoragePtr & storage, const String & relative_table_path) override;\n \ndiff --git a/src/Databases/ya.make b/src/Databases/ya.make\nindex 0dc44386088e..8bd3f291a649 100644\n--- a/src/Databases/ya.make\n+++ b/src/Databases/ya.make\n@@ -16,6 +16,9 @@ SRCS(\n     DatabaseMemory.cpp\n     DatabaseOnDisk.cpp\n     DatabaseOrdinary.cpp\n+    DatabaseReplicated.cpp\n+    DatabaseReplicatedSettings.cpp\n+    DatabaseReplicatedWorker.cpp\n     DatabaseWithDictionaries.cpp\n     DatabasesCommon.cpp\n     MySQL/ConnectionMySQLSettings.cpp\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex 5e8d80adee90..98e4a87fba3c 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -342,6 +342,7 @@ struct ContextShared\n     ReplicatedFetchList replicated_fetch_list;\n     ConfigurationPtr users_config;                          /// Config with the users, profiles and quotas sections.\n     InterserverIOHandler interserver_io_handler;            /// Handler for interserver communication.\n+\n     mutable std::optional<BackgroundSchedulePool> buffer_flush_schedule_pool; /// A thread pool that can do background flush for Buffer tables.\n     mutable std::optional<BackgroundSchedulePool> schedule_pool;    /// A thread pool that can run different jobs in background (used in replicated tables)\n     mutable std::optional<BackgroundSchedulePool> distributed_schedule_pool; /// A thread pool that can run different jobs in background (used for distributed sends)\n@@ -1552,6 +1553,7 @@ void Context::setDDLWorker(std::unique_ptr<DDLWorker> ddl_worker)\n     auto lock = getLock();\n     if (shared->ddl_worker)\n         throw Exception(\"DDL background thread has already been initialized\", ErrorCodes::LOGICAL_ERROR);\n+    ddl_worker->startup();\n     shared->ddl_worker = std::move(ddl_worker);\n }\n \n@@ -2551,6 +2553,19 @@ StorageID Context::resolveStorageIDImpl(StorageID storage_id, StorageNamespace w\n     return StorageID::createEmpty();\n }\n \n+void Context::initZooKeeperMetadataTransaction(ZooKeeperMetadataTransactionPtr txn, [[maybe_unused]] bool attach_existing)\n+{\n+    assert(!metadata_transaction);\n+    assert(attach_existing || query_context == this);\n+    metadata_transaction = std::move(txn);\n+}\n+\n+ZooKeeperMetadataTransactionPtr Context::getZooKeeperMetadataTransaction() const\n+{\n+    assert(!metadata_transaction || hasQueryContext());\n+    return metadata_transaction;\n+}\n+\n PartUUIDsPtr Context::getPartUUIDs()\n {\n     auto lock = getLock();\ndiff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h\nindex be53a4364e0a..563fb1724885 100644\n--- a/src/Interpreters/Context.h\n+++ b/src/Interpreters/Context.h\n@@ -117,6 +117,8 @@ using VolumePtr = std::shared_ptr<IVolume>;\n struct NamedSession;\n struct BackgroundTaskSchedulingSettings;\n \n+class ZooKeeperMetadataTransaction;\n+using ZooKeeperMetadataTransactionPtr = std::shared_ptr<ZooKeeperMetadataTransaction>;\n \n #if USE_EMBEDDED_COMPILER\n class CompiledExpressionCache;\n@@ -279,6 +281,12 @@ class Context\n                                    /// to be customized in HTTP and TCP servers by overloading the customizeContext(DB::Context&)\n                                    /// methods.\n \n+    ZooKeeperMetadataTransactionPtr metadata_transaction;    /// Distributed DDL context. I'm not sure if it's a suitable place for this,\n+                                                    /// but it's the easiest way to pass this through the whole stack from executeQuery(...)\n+                                                    /// to DatabaseOnDisk::commitCreateTable(...) or IStorage::alter(...) without changing\n+                                                    /// thousands of signatures.\n+                                                    /// And I hope it will be replaced with more common Transaction sometime.\n+\n     /// Use copy constructor or createGlobal() instead\n     Context();\n \n@@ -534,6 +542,7 @@ class Context\n     const Context & getQueryContext() const;\n     Context & getQueryContext();\n     bool hasQueryContext() const { return query_context != nullptr; }\n+    bool isInternalSubquery() const { return hasQueryContext() && query_context != this; }\n \n     const Context & getSessionContext() const;\n     Context & getSessionContext();\n@@ -737,6 +746,11 @@ class Context\n     IHostContextPtr & getHostContext();\n     const IHostContextPtr & getHostContext() const;\n \n+    /// Initialize context of distributed DDL query with Replicated database.\n+    void initZooKeeperMetadataTransaction(ZooKeeperMetadataTransactionPtr txn, bool attach_existing = false);\n+    /// Returns context of current distributed DDL query or nullptr.\n+    ZooKeeperMetadataTransactionPtr getZooKeeperMetadataTransaction() const;\n+\n     struct MySQLWireContext\n     {\n         uint8_t sequence_id = 0;\ndiff --git a/src/Interpreters/DDLTask.cpp b/src/Interpreters/DDLTask.cpp\nnew file mode 100644\nindex 000000000000..4be465d3de47\n--- /dev/null\n+++ b/src/Interpreters/DDLTask.cpp\n@@ -0,0 +1,344 @@\n+#include <Interpreters/DDLTask.h>\n+#include <Common/DNSResolver.h>\n+#include <Common/isLocalAddress.h>\n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/Operators.h>\n+#include <IO/ReadBufferFromString.h>\n+#include <Poco/Net/NetException.h>\n+#include <common/logger_useful.h>\n+#include <Parsers/ParserQuery.h>\n+#include <Parsers/parseQuery.h>\n+#include <Parsers/ASTQueryWithOnCluster.h>\n+#include <Parsers/ASTQueryWithTableAndOutput.h>\n+#include <Databases/DatabaseReplicated.h>\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int UNKNOWN_FORMAT_VERSION;\n+    extern const int UNKNOWN_TYPE_OF_QUERY;\n+    extern const int INCONSISTENT_CLUSTER_DEFINITION;\n+}\n+\n+HostID HostID::fromString(const String & host_port_str)\n+{\n+    HostID res;\n+    std::tie(res.host_name, res.port) = Cluster::Address::fromString(host_port_str);\n+    return res;\n+}\n+\n+bool HostID::isLocalAddress(UInt16 clickhouse_port) const\n+{\n+    try\n+    {\n+        return DB::isLocalAddress(DNSResolver::instance().resolveAddress(host_name, port), clickhouse_port);\n+    }\n+    catch (const Poco::Net::NetException &)\n+    {\n+        /// Avoid \"Host not found\" exceptions\n+        return false;\n+    }\n+}\n+\n+\n+String DDLLogEntry::toString() const\n+{\n+    WriteBufferFromOwnString wb;\n+\n+    Strings host_id_strings(hosts.size());\n+    std::transform(hosts.begin(), hosts.end(), host_id_strings.begin(), HostID::applyToString);\n+\n+    auto version = CURRENT_VERSION;\n+    wb << \"version: \" << version << \"\\n\";\n+    wb << \"query: \" << escape << query << \"\\n\";\n+    wb << \"hosts: \" << host_id_strings << \"\\n\";\n+    wb << \"initiator: \" << initiator << \"\\n\";\n+\n+    return wb.str();\n+}\n+\n+void DDLLogEntry::parse(const String & data)\n+{\n+    ReadBufferFromString rb(data);\n+\n+    int version;\n+    rb >> \"version: \" >> version >> \"\\n\";\n+\n+    if (version != CURRENT_VERSION)\n+        throw Exception(ErrorCodes::UNKNOWN_FORMAT_VERSION, \"Unknown DDLLogEntry format version: {}\", version);\n+\n+    Strings host_id_strings;\n+    rb >> \"query: \" >> escape >> query >> \"\\n\";\n+    rb >> \"hosts: \" >> host_id_strings >> \"\\n\";\n+\n+    if (!rb.eof())\n+        rb >> \"initiator: \" >> initiator >> \"\\n\";\n+    else\n+        initiator.clear();\n+\n+    assertEOF(rb);\n+\n+    hosts.resize(host_id_strings.size());\n+    std::transform(host_id_strings.begin(), host_id_strings.end(), hosts.begin(), HostID::fromString);\n+}\n+\n+\n+void DDLTaskBase::parseQueryFromEntry(const Context & context)\n+{\n+    const char * begin = entry.query.data();\n+    const char * end = begin + entry.query.size();\n+\n+    ParserQuery parser_query(end);\n+    String description;\n+    query = parseQuery(parser_query, begin, end, description, 0, context.getSettingsRef().max_parser_depth);\n+}\n+\n+std::unique_ptr<Context> DDLTaskBase::makeQueryContext(Context & from_context, const ZooKeeperPtr & /*zookeeper*/)\n+{\n+    auto query_context = std::make_unique<Context>(from_context);\n+    query_context->makeQueryContext();\n+    query_context->setCurrentQueryId(\"\"); // generate random query_id\n+    query_context->getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n+    return query_context;\n+}\n+\n+\n+bool DDLTask::findCurrentHostID(const Context & global_context, Poco::Logger * log)\n+{\n+    bool host_in_hostlist = false;\n+\n+    for (const HostID & host : entry.hosts)\n+    {\n+        auto maybe_secure_port = global_context.getTCPPortSecure();\n+\n+        /// The port is considered local if it matches TCP or TCP secure port that the server is listening.\n+        bool is_local_port = (maybe_secure_port && host.isLocalAddress(*maybe_secure_port))\n+                             || host.isLocalAddress(global_context.getTCPPort());\n+\n+        if (!is_local_port)\n+            continue;\n+\n+        if (host_in_hostlist)\n+        {\n+            /// This check could be slow a little bit\n+            LOG_WARNING(log, \"There are two the same ClickHouse instances in task {}: {} and {}. Will use the first one only.\",\n+                             entry_name, host_id.readableString(), host.readableString());\n+        }\n+        else\n+        {\n+            host_in_hostlist = true;\n+            host_id = host;\n+            host_id_str = host.toString();\n+        }\n+    }\n+\n+    return host_in_hostlist;\n+}\n+\n+void DDLTask::setClusterInfo(const Context & context, Poco::Logger * log)\n+{\n+    auto * query_on_cluster = dynamic_cast<ASTQueryWithOnCluster *>(query.get());\n+    if (!query_on_cluster)\n+        throw Exception(\"Received unknown DDL query\", ErrorCodes::UNKNOWN_TYPE_OF_QUERY);\n+\n+    cluster_name = query_on_cluster->cluster;\n+    cluster = context.tryGetCluster(cluster_name);\n+\n+    if (!cluster)\n+        throw Exception(ErrorCodes::INCONSISTENT_CLUSTER_DEFINITION,\n+                        \"DDL task {} contains current host {} in cluster {}, but there are no such cluster here.\",\n+                        entry_name, host_id.readableString(), cluster_name);\n+\n+    /// Try to find host from task host list in cluster\n+    /// At the first, try find exact match (host name and ports should be literally equal)\n+    /// If the attempt fails, try find it resolving host name of each instance\n+\n+    if (!tryFindHostInCluster())\n+    {\n+        LOG_WARNING(log, \"Not found the exact match of host {} from task {} in cluster {} definition. Will try to find it using host name resolving.\",\n+                         host_id.readableString(), entry_name, cluster_name);\n+\n+        if (!tryFindHostInClusterViaResolving(context))\n+            throw Exception(ErrorCodes::INCONSISTENT_CLUSTER_DEFINITION, \"Not found host {} in definition of cluster {}\",\n+                                                                 host_id.readableString(), cluster_name);\n+\n+        LOG_INFO(log, \"Resolved host {} from task {} as host {} in definition of cluster {}\",\n+                 host_id.readableString(), entry_name, address_in_cluster.readableString(), cluster_name);\n+    }\n+\n+    query = query_on_cluster->getRewrittenASTWithoutOnCluster(address_in_cluster.default_database);\n+    query_on_cluster = nullptr;\n+}\n+\n+bool DDLTask::tryFindHostInCluster()\n+{\n+    const auto & shards = cluster->getShardsAddresses();\n+    bool found_exact_match = false;\n+    String default_database;\n+\n+    for (size_t shard_num = 0; shard_num < shards.size(); ++shard_num)\n+    {\n+        for (size_t replica_num = 0; replica_num < shards[shard_num].size(); ++replica_num)\n+        {\n+            const Cluster::Address & address = shards[shard_num][replica_num];\n+\n+            if (address.host_name == host_id.host_name && address.port == host_id.port)\n+            {\n+                if (found_exact_match)\n+                {\n+                    if (default_database == address.default_database)\n+                    {\n+                        throw Exception(ErrorCodes::INCONSISTENT_CLUSTER_DEFINITION,\n+                                        \"There are two exactly the same ClickHouse instances {} in cluster {}\",\n+                                        address.readableString(), cluster_name);\n+                    }\n+                    else\n+                    {\n+                        /* Circular replication is used.\n+                         * It is when every physical node contains\n+                         * replicas of different shards of the same table.\n+                         * To distinguish one replica from another on the same node,\n+                         * every shard is placed into separate database.\n+                         * */\n+                        is_circular_replicated = true;\n+                        auto * query_with_table = dynamic_cast<ASTQueryWithTableAndOutput *>(query.get());\n+                        if (!query_with_table || query_with_table->database.empty())\n+                        {\n+                            throw Exception(ErrorCodes::INCONSISTENT_CLUSTER_DEFINITION,\n+                                            \"For a distributed DDL on circular replicated cluster its table name must be qualified by database name.\");\n+                        }\n+                        if (default_database == query_with_table->database)\n+                            return true;\n+                    }\n+                }\n+                found_exact_match = true;\n+                host_shard_num = shard_num;\n+                host_replica_num = replica_num;\n+                address_in_cluster = address;\n+                default_database = address.default_database;\n+            }\n+        }\n+    }\n+\n+    return found_exact_match;\n+}\n+\n+bool DDLTask::tryFindHostInClusterViaResolving(const Context & context)\n+{\n+    const auto & shards = cluster->getShardsAddresses();\n+    bool found_via_resolving = false;\n+\n+    for (size_t shard_num = 0; shard_num < shards.size(); ++shard_num)\n+    {\n+        for (size_t replica_num = 0; replica_num < shards[shard_num].size(); ++replica_num)\n+        {\n+            const Cluster::Address & address = shards[shard_num][replica_num];\n+\n+            if (auto resolved = address.getResolvedAddress();\n+                resolved && (isLocalAddress(*resolved, context.getTCPPort())\n+                             || (context.getTCPPortSecure() && isLocalAddress(*resolved, *context.getTCPPortSecure()))))\n+            {\n+                if (found_via_resolving)\n+                {\n+                    throw Exception(ErrorCodes::INCONSISTENT_CLUSTER_DEFINITION,\n+                                    \"There are two the same ClickHouse instances in cluster {} : {} and {}\",\n+                                    cluster_name, address_in_cluster.readableString(), address.readableString());\n+                }\n+                else\n+                {\n+                    found_via_resolving = true;\n+                    host_shard_num = shard_num;\n+                    host_replica_num = replica_num;\n+                    address_in_cluster = address;\n+                }\n+            }\n+        }\n+    }\n+\n+    return found_via_resolving;\n+}\n+\n+String DDLTask::getShardID() const\n+{\n+    /// Generate unique name for shard node, it will be used to execute the query by only single host\n+    /// Shard node name has format 'replica_name1,replica_name2,...,replica_nameN'\n+    /// Where replica_name is 'replica_config_host_name:replica_port'\n+\n+    auto shard_addresses = cluster->getShardsAddresses().at(host_shard_num);\n+\n+    Strings replica_names;\n+    for (const Cluster::Address & address : shard_addresses)\n+        replica_names.emplace_back(address.readableString());\n+    std::sort(replica_names.begin(), replica_names.end());\n+\n+    String res;\n+    for (auto it = replica_names.begin(); it != replica_names.end(); ++it)\n+        res += *it + (std::next(it) != replica_names.end() ? \",\" : \"\");\n+\n+    return res;\n+}\n+\n+DatabaseReplicatedTask::DatabaseReplicatedTask(const String & name, const String & path, DatabaseReplicated * database_)\n+    : DDLTaskBase(name, path)\n+    , database(database_)\n+{\n+    host_id_str = database->getFullReplicaName();\n+}\n+\n+String DatabaseReplicatedTask::getShardID() const\n+{\n+    return database->shard_name;\n+}\n+\n+std::unique_ptr<Context> DatabaseReplicatedTask::makeQueryContext(Context & from_context, const ZooKeeperPtr & zookeeper)\n+{\n+    auto query_context = DDLTaskBase::makeQueryContext(from_context, zookeeper);\n+    query_context->getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n+    query_context->setCurrentDatabase(database->getDatabaseName());\n+\n+    auto txn = std::make_shared<ZooKeeperMetadataTransaction>(zookeeper, database->zookeeper_path, is_initial_query);\n+    query_context->initZooKeeperMetadataTransaction(txn);\n+\n+    if (is_initial_query)\n+    {\n+        txn->addOp(zkutil::makeRemoveRequest(entry_path + \"/try\", -1));\n+        txn->addOp(zkutil::makeCreateRequest(entry_path + \"/committed\", host_id_str, zkutil::CreateMode::Persistent));\n+        txn->addOp(zkutil::makeSetRequest(database->zookeeper_path + \"/max_log_ptr\", toString(getLogEntryNumber(entry_name)), -1));\n+    }\n+\n+    txn->addOp(zkutil::makeSetRequest(database->replica_path + \"/log_ptr\", toString(getLogEntryNumber(entry_name)), -1));\n+\n+    for (auto & op : ops)\n+        txn->addOp(std::move(op));\n+    ops.clear();\n+\n+    return query_context;\n+}\n+\n+String DDLTaskBase::getLogEntryName(UInt32 log_entry_number)\n+{\n+    constexpr size_t seq_node_digits = 10;\n+    String number = toString(log_entry_number);\n+    String name = \"query-\" + String(seq_node_digits - number.size(), '0') + number;\n+    return name;\n+}\n+\n+UInt32 DDLTaskBase::getLogEntryNumber(const String & log_entry_name)\n+{\n+    constexpr const char * name = \"query-\";\n+    assert(startsWith(log_entry_name, name));\n+    return parse<UInt32>(log_entry_name.substr(strlen(name)));\n+}\n+\n+void ZooKeeperMetadataTransaction::commit()\n+{\n+    assert(state == CREATED);\n+    state = FAILED;\n+    current_zookeeper->multi(ops);\n+    state = COMMITTED;\n+}\n+\n+}\ndiff --git a/src/Interpreters/DDLTask.h b/src/Interpreters/DDLTask.h\nnew file mode 100644\nindex 000000000000..18c1f4c80cd7\n--- /dev/null\n+++ b/src/Interpreters/DDLTask.h\n@@ -0,0 +1,195 @@\n+#pragma once\n+#include <Core/Types.h>\n+#include <Interpreters/Cluster.h>\n+#include <Common/ZooKeeper/Types.h>\n+\n+namespace Poco\n+{\n+class Logger;\n+}\n+\n+namespace zkutil\n+{\n+class ZooKeeper;\n+}\n+\n+namespace DB\n+{\n+\n+class ASTQueryWithOnCluster;\n+using ZooKeeperPtr = std::shared_ptr<zkutil::ZooKeeper>;\n+class DatabaseReplicated;\n+\n+class ZooKeeperMetadataTransaction;\n+using ZooKeeperMetadataTransactionPtr = std::shared_ptr<ZooKeeperMetadataTransaction>;\n+\n+struct HostID\n+{\n+    String host_name;\n+    UInt16 port;\n+\n+    HostID() = default;\n+\n+    explicit HostID(const Cluster::Address & address)\n+        : host_name(address.host_name), port(address.port) {}\n+\n+    static HostID fromString(const String & host_port_str);\n+\n+    String toString() const\n+    {\n+        return Cluster::Address::toString(host_name, port);\n+    }\n+\n+    String readableString() const\n+    {\n+        return host_name + \":\" + DB::toString(port);\n+    }\n+\n+    bool isLocalAddress(UInt16 clickhouse_port) const;\n+\n+    static String applyToString(const HostID & host_id)\n+    {\n+        return host_id.toString();\n+    }\n+};\n+\n+\n+struct DDLLogEntry\n+{\n+    String query;\n+    std::vector<HostID> hosts;\n+    String initiator; // optional\n+\n+    static constexpr int CURRENT_VERSION = 1;\n+\n+    String toString() const;\n+\n+    void parse(const String & data);\n+};\n+\n+struct DDLTaskBase\n+{\n+    const String entry_name;\n+    const String entry_path;\n+\n+    DDLLogEntry entry;\n+\n+    String host_id_str;\n+    ASTPtr query;\n+\n+    bool is_initial_query = false;\n+    bool is_circular_replicated = false;\n+    bool execute_on_leader = false;\n+\n+    Coordination::Requests ops;\n+    ExecutionStatus execution_status;\n+    bool was_executed = false;\n+\n+    std::atomic_bool completely_processed = false;\n+\n+    DDLTaskBase(const String & name, const String & path) : entry_name(name), entry_path(path) {}\n+    DDLTaskBase(const DDLTaskBase &) = delete;\n+    virtual ~DDLTaskBase() = default;\n+\n+    void parseQueryFromEntry(const Context & context);\n+\n+    virtual String getShardID() const = 0;\n+\n+    virtual std::unique_ptr<Context> makeQueryContext(Context & from_context, const ZooKeeperPtr & zookeeper);\n+\n+    inline String getActiveNodePath() const { return entry_path + \"/active/\" + host_id_str; }\n+    inline String getFinishedNodePath() const { return entry_path + \"/finished/\" + host_id_str; }\n+    inline String getShardNodePath() const { return entry_path + \"/shards/\" + getShardID(); }\n+\n+    static String getLogEntryName(UInt32 log_entry_number);\n+    static UInt32 getLogEntryNumber(const String & log_entry_name);\n+};\n+\n+struct DDLTask : public DDLTaskBase\n+{\n+    DDLTask(const String & name, const String & path) : DDLTaskBase(name, path) {}\n+\n+    bool findCurrentHostID(const Context & global_context, Poco::Logger * log);\n+\n+    void setClusterInfo(const Context & context, Poco::Logger * log);\n+\n+    String getShardID() const override;\n+\n+private:\n+    bool tryFindHostInCluster();\n+    bool tryFindHostInClusterViaResolving(const Context & context);\n+\n+    HostID host_id;\n+    String cluster_name;\n+    ClusterPtr cluster;\n+    Cluster::Address address_in_cluster;\n+    size_t host_shard_num;\n+    size_t host_replica_num;\n+};\n+\n+struct DatabaseReplicatedTask : public DDLTaskBase\n+{\n+    DatabaseReplicatedTask(const String & name, const String & path, DatabaseReplicated * database_);\n+\n+    String getShardID() const override;\n+    std::unique_ptr<Context> makeQueryContext(Context & from_context, const ZooKeeperPtr & zookeeper) override;\n+\n+    DatabaseReplicated * database;\n+};\n+\n+/// The main purpose of ZooKeeperMetadataTransaction is to execute all zookeeper operation related to query\n+/// in a single transaction when we performed all required checks and ready to \"commit\" changes.\n+/// For example, create ALTER_METADATA entry in ReplicatedMergeTree log,\n+/// create path/to/entry/finished/host_id node in distributed DDL queue to mark query as executed and\n+/// update metadata in path/to/replicated_database/metadata/table_name\n+/// It's used for DatabaseReplicated.\n+/// TODO we can also use it for ordinary ON CLUSTER queries\n+class ZooKeeperMetadataTransaction\n+{\n+    enum State\n+    {\n+        CREATED,\n+        COMMITTED,\n+        FAILED\n+    };\n+\n+    State state = CREATED;\n+    ZooKeeperPtr current_zookeeper;\n+    String zookeeper_path;\n+    bool is_initial_query;\n+    Coordination::Requests ops;\n+\n+public:\n+    ZooKeeperMetadataTransaction(const ZooKeeperPtr & current_zookeeper_, const String & zookeeper_path_, bool is_initial_query_)\n+    : current_zookeeper(current_zookeeper_)\n+    , zookeeper_path(zookeeper_path_)\n+    , is_initial_query(is_initial_query_)\n+    {\n+    }\n+\n+    bool isInitialQuery() const { return is_initial_query; }\n+\n+    bool isExecuted() const { return state != CREATED; }\n+\n+    String getDatabaseZooKeeperPath() const { return zookeeper_path; }\n+\n+    void addOp(Coordination::RequestPtr && op)\n+    {\n+        assert(!isExecuted());\n+        ops.emplace_back(op);\n+    }\n+\n+    void moveOpsTo(Coordination::Requests & other_ops)\n+    {\n+        assert(!isExecuted());\n+        std::move(ops.begin(), ops.end(), std::back_inserter(other_ops));\n+        ops.clear();\n+        state = COMMITTED;\n+    }\n+\n+    void commit();\n+\n+    ~ZooKeeperMetadataTransaction() { assert(isExecuted() || std::uncaught_exception()); }\n+};\n+\n+}\ndiff --git a/src/Interpreters/DDLWorker.cpp b/src/Interpreters/DDLWorker.cpp\nindex fc460a5584c6..67f716c235cc 100644\n--- a/src/Interpreters/DDLWorker.cpp\n+++ b/src/Interpreters/DDLWorker.cpp\n@@ -1,6 +1,7 @@\n #include <filesystem>\n \n #include <Interpreters/DDLWorker.h>\n+#include <Interpreters/DDLTask.h>\n #include <Parsers/ASTAlterQuery.h>\n #include <Parsers/ASTDropQuery.h>\n #include <Parsers/ASTOptimizeQuery.h>\n@@ -11,129 +12,43 @@\n #include <Parsers/queryToString.h>\n #include <IO/WriteHelpers.h>\n #include <IO/ReadHelpers.h>\n-#include <IO/Operators.h>\n #include <IO/ReadBufferFromString.h>\n-#include <DataStreams/IBlockInputStream.h>\n+#include <Storages/IStorage.h>\n #include <Interpreters/executeQuery.h>\n #include <Interpreters/Cluster.h>\n-#include <Interpreters/AddDefaultDatabaseVisitor.h>\n #include <Interpreters/Context.h>\n-#include <Access/AccessRightsElement.h>\n-#include <Access/ContextAccess.h>\n-#include <Common/Macros.h>\n #include <Common/setThreadName.h>\n-#include <Common/Stopwatch.h>\n #include <Common/randomSeed.h>\n #include <Common/ZooKeeper/ZooKeeper.h>\n #include <Common/ZooKeeper/KeeperException.h>\n #include <Common/isLocalAddress.h>\n-#include <Common/quoteString.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeString.h>\n #include <Storages/StorageReplicatedMergeTree.h>\n #include <Poco/Timestamp.h>\n #include <common/sleep.h>\n #include <common/getFQDNOrHostName.h>\n+#include <common/logger_useful.h>\n+#include <random>\n #include <pcg_random.hpp>\n \n namespace fs = std::filesystem;\n \n-namespace CurrentMetrics\n-{\n-    extern const Metric MaxDDLEntryID;\n-}\n \n namespace DB\n {\n \n namespace ErrorCodes\n {\n-    extern const int NOT_IMPLEMENTED;\n     extern const int LOGICAL_ERROR;\n-    extern const int UNKNOWN_FORMAT_VERSION;\n-    extern const int INCONSISTENT_CLUSTER_DEFINITION;\n     extern const int TIMEOUT_EXCEEDED;\n-    extern const int UNKNOWN_TYPE_OF_QUERY;\n     extern const int UNFINISHED;\n-    extern const int QUERY_IS_PROHIBITED;\n+    extern const int NOT_A_LEADER;\n+    extern const int KEEPER_EXCEPTION;\n+    extern const int CANNOT_ASSIGN_ALTER;\n+    extern const int CANNOT_ALLOCATE_MEMORY;\n+    extern const int MEMORY_LIMIT_EXCEEDED;\n }\n \n \n-String DDLLogEntry::toString()\n-{\n-    WriteBufferFromOwnString wb;\n-\n-    Strings host_id_strings(hosts.size());\n-    std::transform(hosts.begin(), hosts.end(), host_id_strings.begin(), HostID::applyToString);\n-\n-    auto version = CURRENT_VERSION;\n-    wb << \"version: \" << version << \"\\n\";\n-    wb << \"query: \" << escape << query << \"\\n\";\n-    wb << \"hosts: \" << host_id_strings << \"\\n\";\n-    wb << \"initiator: \" << initiator << \"\\n\";\n-\n-    return wb.str();\n-}\n-\n-void DDLLogEntry::parse(const String & data)\n-{\n-    ReadBufferFromString rb(data);\n-\n-    int version;\n-    rb >> \"version: \" >> version >> \"\\n\";\n-\n-    if (version != CURRENT_VERSION)\n-        throw Exception(ErrorCodes::UNKNOWN_FORMAT_VERSION, \"Unknown DDLLogEntry format version: {}\", version);\n-\n-    Strings host_id_strings;\n-    rb >> \"query: \" >> escape >> query >> \"\\n\";\n-    rb >> \"hosts: \" >> host_id_strings >> \"\\n\";\n-\n-    if (!rb.eof())\n-        rb >> \"initiator: \" >> initiator >> \"\\n\";\n-    else\n-        initiator.clear();\n-\n-    assertEOF(rb);\n-\n-    hosts.resize(host_id_strings.size());\n-    std::transform(host_id_strings.begin(), host_id_strings.end(), hosts.begin(), HostID::fromString);\n-}\n-\n-\n-struct DDLTask\n-{\n-    /// Stages of task lifetime correspond ordering of these data fields:\n-\n-    /// Stage 1: parse entry\n-    String entry_name;\n-    String entry_path;\n-    DDLLogEntry entry;\n-\n-    /// Stage 2: resolve host_id and check that\n-    HostID host_id;\n-    String host_id_str;\n-\n-    /// Stage 3.1: parse query\n-    ASTPtr query;\n-    ASTQueryWithOnCluster * query_on_cluster = nullptr;\n-\n-    /// Stage 3.2: check cluster and find the host in cluster\n-    String cluster_name;\n-    ClusterPtr cluster;\n-    Cluster::Address address_in_cluster;\n-    size_t host_shard_num;\n-    size_t host_replica_num;\n-    bool is_circular_replicated = false;\n-\n-    /// Stage 3.3: execute query\n-    ExecutionStatus execution_status;\n-    bool was_executed = false;\n-\n-    /// Stage 4: commit results to ZooKeeper\n-};\n-\n-\n namespace\n {\n \n@@ -232,29 +147,22 @@ std::unique_ptr<ZooKeeperLock> createSimpleZooKeeperLock(\n }\n \n \n-static bool isSupportedAlterType(int type)\n-{\n-    static const std::unordered_set<int> unsupported_alter_types{\n-        ASTAlterCommand::ATTACH_PARTITION,\n-        ASTAlterCommand::REPLACE_PARTITION,\n-        ASTAlterCommand::FETCH_PARTITION,\n-        ASTAlterCommand::FREEZE_PARTITION,\n-        ASTAlterCommand::FREEZE_ALL,\n-        ASTAlterCommand::NO_TYPE,\n-    };\n-\n-    return unsupported_alter_types.count(type) == 0;\n-}\n-\n-\n-DDLWorker::DDLWorker(int pool_size_, const std::string & zk_root_dir, Context & context_, const Poco::Util::AbstractConfiguration * config, const String & prefix)\n+DDLWorker::DDLWorker(int pool_size_, const std::string & zk_root_dir, const Context & context_, const Poco::Util::AbstractConfiguration * config, const String & prefix,\n+                     const String & logger_name, const CurrentMetrics::Metric * max_entry_metric_)\n     : context(context_)\n-    , log(&Poco::Logger::get(\"DDLWorker\"))\n+    , log(&Poco::Logger::get(logger_name))\n     , pool_size(pool_size_)\n-    , worker_pool(std::make_unique<ThreadPool>(pool_size))\n+    , max_entry_metric(max_entry_metric_)\n {\n-    CurrentMetrics::set(CurrentMetrics::MaxDDLEntryID, 0);\n-    last_tasks.reserve(pool_size);\n+    if (max_entry_metric)\n+        CurrentMetrics::set(*max_entry_metric, 0);\n+\n+    if (1 < pool_size)\n+    {\n+        LOG_WARNING(log, \"DDLWorker is configured to use multiple threads. \"\n+                         \"It's not recommended because queries can be reordered. Also it may cause some unknown issues to appear.\");\n+        worker_pool = std::make_unique<ThreadPool>(pool_size);\n+    }\n \n     queue_dir = zk_root_dir;\n     if (queue_dir.back() == '/')\n@@ -277,30 +185,40 @@ DDLWorker::DDLWorker(int pool_size_, const std::string & zk_root_dir, Context &\n \n     host_fqdn = getFQDNOrHostName();\n     host_fqdn_id = Cluster::Address::toString(host_fqdn, context.getTCPPort());\n+}\n \n+void DDLWorker::startup()\n+{\n     main_thread = ThreadFromGlobalPool(&DDLWorker::runMainThread, this);\n     cleanup_thread = ThreadFromGlobalPool(&DDLWorker::runCleanupThread, this);\n }\n \n+void DDLWorker::shutdown()\n+{\n+    bool prev_stop_flag = stop_flag.exchange(true);\n+    if (!prev_stop_flag)\n+    {\n+        queue_updated_event->set();\n+        cleanup_event->set();\n+        main_thread.join();\n+        cleanup_thread.join();\n+        worker_pool.reset();\n+    }\n+}\n \n DDLWorker::~DDLWorker()\n {\n-    stop_flag = true;\n-    queue_updated_event->set();\n-    cleanup_event->set();\n-    worker_pool.reset();\n-    main_thread.join();\n-    cleanup_thread.join();\n+    DDLWorker::shutdown();\n }\n \n \n-DDLWorker::ZooKeeperPtr DDLWorker::tryGetZooKeeper() const\n+ZooKeeperPtr DDLWorker::tryGetZooKeeper() const\n {\n     std::lock_guard lock(zookeeper_mutex);\n     return current_zookeeper;\n }\n \n-DDLWorker::ZooKeeperPtr DDLWorker::getAndSetZooKeeper()\n+ZooKeeperPtr DDLWorker::getAndSetZooKeeper()\n {\n     std::lock_guard lock(zookeeper_mutex);\n \n@@ -310,31 +228,14 @@ DDLWorker::ZooKeeperPtr DDLWorker::getAndSetZooKeeper()\n     return current_zookeeper;\n }\n \n-void DDLWorker::recoverZooKeeper()\n-{\n-    LOG_DEBUG(log, \"Recovering ZooKeeper session after: {}\", getCurrentExceptionMessage(false));\n-\n-    while (!stop_flag)\n-    {\n-        try\n-        {\n-            getAndSetZooKeeper();\n-            break;\n-        }\n-        catch (...)\n-        {\n-            tryLogCurrentException(__PRETTY_FUNCTION__);\n-            sleepForSeconds(5);\n-        }\n-    }\n-}\n-\n \n DDLTaskPtr DDLWorker::initAndCheckTask(const String & entry_name, String & out_reason, const ZooKeeperPtr & zookeeper)\n {\n     String node_data;\n     String entry_path = fs::path(queue_dir) / entry_name;\n \n+    auto task = std::make_unique<DDLTask>(entry_name, entry_path);\n+\n     if (!zookeeper->tryGet(entry_path, node_data))\n     {\n         /// It is Ok that node could be deleted just now. It means that there are no current host in node's host list.\n@@ -342,12 +243,16 @@ DDLTaskPtr DDLWorker::initAndCheckTask(const String & entry_name, String & out_r\n         return {};\n     }\n \n-    auto task = std::make_unique<DDLTask>();\n-    task->entry_name = entry_name;\n-    task->entry_path = entry_path;\n+    auto write_error_status = [&](const String & host_id, const String & error_message, const String & reason)\n+    {\n+        LOG_ERROR(log, \"Cannot parse DDL task {}: {}. Will try to send error status: {}\", entry_name, reason, error_message);\n+        createStatusDirs(entry_path, zookeeper);\n+        zookeeper->tryCreate(fs::path(entry_path) / \"finished\" / host_id, error_message, zkutil::CreateMode::Persistent);\n+    };\n \n     try\n     {\n+        /// Stage 1: parse entry\n         task->entry.parse(node_data);\n     }\n     catch (...)\n@@ -355,55 +260,41 @@ DDLTaskPtr DDLWorker::initAndCheckTask(const String & entry_name, String & out_r\n         /// What should we do if we even cannot parse host name and therefore cannot properly submit execution status?\n         /// We can try to create fail node using FQDN if it equal to host name in cluster config attempt will be successful.\n         /// Otherwise, that node will be ignored by DDLQueryStatusInputStream.\n-\n-        tryLogCurrentException(log, \"Cannot parse DDL task \" + entry_name + \", will try to send error status\");\n-\n-        String status = ExecutionStatus::fromCurrentException().serializeText();\n-        try\n-        {\n-            createStatusDirs(entry_path, zookeeper);\n-            zookeeper->tryCreate(fs::path(entry_path) / \"finished\" / host_fqdn_id, status, zkutil::CreateMode::Persistent);\n-        }\n-        catch (...)\n-        {\n-            tryLogCurrentException(log, \"Can't report the task has invalid format\");\n-        }\n-\n         out_reason = \"Incorrect task format\";\n+        write_error_status(host_fqdn_id, ExecutionStatus::fromCurrentException().serializeText(), out_reason);\n         return {};\n     }\n \n-    bool host_in_hostlist = false;\n-    for (const HostID & host : task->entry.hosts)\n+    /// Stage 2: resolve host_id and check if we should execute query or not\n+    /// Multiple clusters can use single DDL queue path in ZooKeeper,\n+    /// So we should skip task if we cannot find current host in cluster hosts list.\n+    if (!task->findCurrentHostID(context, log))\n     {\n-        auto maybe_secure_port = context.getTCPPortSecure();\n-\n-        /// The port is considered local if it matches TCP or TCP secure port that the server is listening.\n-        bool is_local_port = (maybe_secure_port && host.isLocalAddress(*maybe_secure_port))\n-            || host.isLocalAddress(context.getTCPPort());\n-\n-        if (!is_local_port)\n-            continue;\n+        out_reason = \"There is no a local address in host list\";\n+        return {};\n+    }\n \n-        if (host_in_hostlist)\n-        {\n-            /// This check could be slow a little bit\n-            LOG_WARNING(log, \"There are two the same ClickHouse instances in task {}: {} and {}. Will use the first one only.\", entry_name, task->host_id.readableString(), host.readableString());\n-        }\n-        else\n-        {\n-            host_in_hostlist = true;\n-            task->host_id = host;\n-            task->host_id_str = host.toString();\n-        }\n+    try\n+    {\n+        /// Stage 3.1: parse query\n+        task->parseQueryFromEntry(context);\n+        /// Stage 3.2: check cluster and find the host in cluster\n+        task->setClusterInfo(context, log);\n+    }\n+    catch (...)\n+    {\n+        out_reason = \"Cannot parse query or obtain cluster info\";\n+        write_error_status(task->host_id_str, ExecutionStatus::fromCurrentException().serializeText(), out_reason);\n+        return {};\n     }\n \n-    if (!host_in_hostlist)\n+    if (zookeeper->exists(task->getFinishedNodePath()))\n     {\n-        out_reason = \"There is no a local address in host list\";\n+        out_reason = \"Task has been already processed\";\n         return {};\n     }\n \n+    /// Now task is ready for execution\n     return task;\n }\n \n@@ -419,189 +310,83 @@ void DDLWorker::scheduleTasks()\n     LOG_DEBUG(log, \"Scheduling tasks\");\n     auto zookeeper = tryGetZooKeeper();\n \n+    for (auto & task : current_tasks)\n+    {\n+        /// Main thread of DDLWorker was restarted, probably due to lost connection with ZooKeeper.\n+        /// We have some unfinished tasks. To avoid duplication of some queries, try to write execution status.\n+        bool task_still_exists = zookeeper->exists(task->entry_path);\n+        bool status_written = zookeeper->exists(task->getFinishedNodePath());\n+        if (task->was_executed && !status_written && task_still_exists)\n+        {\n+            processTask(*task, zookeeper);\n+        }\n+    }\n+\n     Strings queue_nodes = zookeeper->getChildren(queue_dir, nullptr, queue_updated_event);\n     filterAndSortQueueNodes(queue_nodes);\n     if (queue_nodes.empty())\n+    {\n+        LOG_TRACE(log, \"No tasks to schedule\");\n         return;\n+    }\n+    else if (max_tasks_in_queue < queue_nodes.size())\n+        cleanup_event->set();\n \n-    bool server_startup = last_tasks.empty();\n+    bool server_startup = current_tasks.empty();\n+    auto begin_node = queue_nodes.begin();\n+\n+    if (!server_startup)\n+    {\n+        /// We will recheck status of last executed tasks. It's useful if main thread was just restarted.\n+        auto & min_task = *std::min_element(current_tasks.begin(), current_tasks.end());\n+        String min_entry_name = last_skipped_entry_name ? std::min(min_task->entry_name, *last_skipped_entry_name) : min_task->entry_name;\n+        begin_node = std::upper_bound(queue_nodes.begin(), queue_nodes.end(), min_entry_name);\n+        current_tasks.clear();\n+    }\n \n-    auto begin_node = server_startup\n-        ? queue_nodes.begin()\n-        : std::upper_bound(queue_nodes.begin(), queue_nodes.end(), last_tasks.back());\n+    assert(current_tasks.empty());\n \n-    for (auto it = begin_node; it != queue_nodes.end(); ++it)\n+    for (auto it = begin_node; it != queue_nodes.end() && !stop_flag; ++it)\n     {\n         String entry_name = *it;\n+        LOG_TRACE(log, \"Checking task {}\", entry_name);\n \n         String reason;\n         auto task = initAndCheckTask(entry_name, reason, zookeeper);\n         if (!task)\n         {\n             LOG_DEBUG(log, \"Will not execute task {}: {}\", entry_name, reason);\n-            saveTask(entry_name);\n+            updateMaxDDLEntryID(entry_name);\n+            last_skipped_entry_name.emplace(entry_name);\n             continue;\n         }\n \n-        bool already_processed = zookeeper->exists(fs::path(task->entry_path)  / \"finished\" / task->host_id_str);\n-        if (!server_startup && !task->was_executed && already_processed)\n-        {\n-            throw Exception(ErrorCodes::LOGICAL_ERROR,\n-                \"Server expects that DDL task {} should be processed, but it was already processed according to ZK\",\n-                entry_name);\n-        }\n+        auto & saved_task = saveTask(std::move(task));\n \n-        if (!already_processed)\n+        if (worker_pool)\n         {\n-            worker_pool->scheduleOrThrowOnError([this, task_ptr = task.release()]()\n+            worker_pool->scheduleOrThrowOnError([this, &saved_task, &zookeeper]()\n             {\n                 setThreadName(\"DDLWorkerExec\");\n-                enqueueTask(DDLTaskPtr(task_ptr));\n+                processTask(saved_task, zookeeper);\n             });\n         }\n         else\n         {\n-            LOG_DEBUG(log, \"Task {} ({}) has been already processed\", entry_name, task->entry.query);\n-            updateMaxDDLEntryID(*task);\n+            processTask(saved_task, zookeeper);\n         }\n-\n-        saveTask(entry_name);\n-\n-        if (stop_flag)\n-            break;\n     }\n }\n \n-void DDLWorker::saveTask(const String & entry_name)\n+DDLTaskBase & DDLWorker::saveTask(DDLTaskPtr && task)\n {\n-    if (last_tasks.size() == pool_size)\n-    {\n-        last_tasks.erase(last_tasks.begin());\n-    }\n-    last_tasks.emplace_back(entry_name);\n+    current_tasks.remove_if([](const DDLTaskPtr & t) { return t->completely_processed.load(); });\n+    assert(current_tasks.size() <= pool_size);\n+    current_tasks.emplace_back(std::move(task));\n+    return *current_tasks.back();\n }\n \n-/// Parses query and resolves cluster and host in cluster\n-void DDLWorker::parseQueryAndResolveHost(DDLTask & task)\n-{\n-    {\n-        const char * begin = task.entry.query.data();\n-        const char * end = begin + task.entry.query.size();\n-\n-        ParserQuery parser_query(end);\n-        String description;\n-        task.query = parseQuery(parser_query, begin, end, description, 0, context.getSettingsRef().max_parser_depth);\n-    }\n-\n-    // XXX: serious design flaw since `ASTQueryWithOnCluster` is not inherited from `IAST`!\n-    if (!task.query || !(task.query_on_cluster = dynamic_cast<ASTQueryWithOnCluster *>(task.query.get())))\n-        throw Exception(\"Received unknown DDL query\", ErrorCodes::UNKNOWN_TYPE_OF_QUERY);\n-\n-    task.cluster_name = task.query_on_cluster->cluster;\n-    task.cluster = context.tryGetCluster(task.cluster_name);\n-    if (!task.cluster)\n-        throw Exception(ErrorCodes::INCONSISTENT_CLUSTER_DEFINITION,\n-            \"DDL task {} contains current host {} in cluster {}, but there are no such cluster here.\",\n-            task.entry_name, task.host_id.readableString(), task.cluster_name);\n-\n-    /// Try to find host from task host list in cluster\n-    /// At the first, try find exact match (host name and ports should be literally equal)\n-    /// If the attempt fails, try find it resolving host name of each instance\n-    const auto & shards = task.cluster->getShardsAddresses();\n-\n-    bool found_exact_match = false;\n-    String default_database;\n-    for (size_t shard_num = 0; shard_num < shards.size(); ++shard_num)\n-    {\n-        for (size_t replica_num = 0; replica_num < shards[shard_num].size(); ++replica_num)\n-        {\n-            const Cluster::Address & address = shards[shard_num][replica_num];\n-\n-            if (address.host_name == task.host_id.host_name && address.port == task.host_id.port)\n-            {\n-                if (found_exact_match)\n-                {\n-                    if (default_database == address.default_database)\n-                    {\n-                        throw Exception(ErrorCodes::INCONSISTENT_CLUSTER_DEFINITION,\n-                            \"There are two exactly the same ClickHouse instances {} in cluster {}\",\n-                            address.readableString(), task.cluster_name);\n-                    }\n-                    else\n-                    {\n-                        /* Circular replication is used.\n-                         * It is when every physical node contains\n-                         * replicas of different shards of the same table.\n-                         * To distinguish one replica from another on the same node,\n-                         * every shard is placed into separate database.\n-                         * */\n-                        task.is_circular_replicated = true;\n-                        auto * query_with_table = dynamic_cast<ASTQueryWithTableAndOutput *>(task.query.get());\n-                        if (!query_with_table || query_with_table->database.empty())\n-                        {\n-                            throw Exception(ErrorCodes::INCONSISTENT_CLUSTER_DEFINITION,\n-                                \"For a distributed DDL on circular replicated cluster its table name must be qualified by database name.\");\n-                        }\n-                        if (default_database == query_with_table->database)\n-                            return;\n-                    }\n-                }\n-                found_exact_match = true;\n-                task.host_shard_num = shard_num;\n-                task.host_replica_num = replica_num;\n-                task.address_in_cluster = address;\n-                default_database = address.default_database;\n-            }\n-        }\n-    }\n-\n-    if (found_exact_match)\n-        return;\n-\n-    LOG_WARNING(log, \"Not found the exact match of host {} from task {} in cluster {} definition. Will try to find it using host name resolving.\", task.host_id.readableString(), task.entry_name, task.cluster_name);\n-\n-    bool found_via_resolving = false;\n-    for (size_t shard_num = 0; shard_num < shards.size(); ++shard_num)\n-    {\n-        for (size_t replica_num = 0; replica_num < shards[shard_num].size(); ++replica_num)\n-        {\n-            const Cluster::Address & address = shards[shard_num][replica_num];\n-\n-            if (auto resolved = address.getResolvedAddress();\n-                resolved && (isLocalAddress(*resolved, context.getTCPPort())\n-                    || (context.getTCPPortSecure() && isLocalAddress(*resolved, *context.getTCPPortSecure()))))\n-            {\n-                if (found_via_resolving)\n-                {\n-                    throw Exception(ErrorCodes::INCONSISTENT_CLUSTER_DEFINITION,\n-                        \"There are two the same ClickHouse instances in cluster {} : {} and {}\",\n-                        task.cluster_name, task.address_in_cluster.readableString(), address.readableString());\n-                }\n-                else\n-                {\n-                    found_via_resolving = true;\n-                    task.host_shard_num = shard_num;\n-                    task.host_replica_num = replica_num;\n-                    task.address_in_cluster = address;\n-                }\n-            }\n-        }\n-    }\n-\n-    if (!found_via_resolving)\n-    {\n-        throw Exception(ErrorCodes::INCONSISTENT_CLUSTER_DEFINITION,\n-            \"Not found host {} in definition of cluster {}\",\n-            task.host_id.readableString(), task.cluster_name);\n-    }\n-    else\n-    {\n-        LOG_INFO(log, \"Resolved host {} from task {} as host {} in definition of cluster {}\", task.host_id.readableString(), task.entry_name, task.address_in_cluster.readableString(), task.cluster_name);\n-    }\n-}\n-\n-\n-bool DDLWorker::tryExecuteQuery(const String & query, const DDLTask & task, ExecutionStatus & status)\n+bool DDLWorker::tryExecuteQuery(const String & query, DDLTaskBase & task, const ZooKeeperPtr & zookeeper)\n {\n     /// Add special comment at the start of query to easily identify DDL-produced queries in query_log\n     String query_prefix = \"/* ddl_entry=\" + task.entry_name + \" */ \";\n@@ -614,84 +399,79 @@ bool DDLWorker::tryExecuteQuery(const String & query, const DDLTask & task, Exec\n \n     try\n     {\n-        auto current_context = std::make_unique<Context>(context);\n-        current_context->getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n-        current_context->setCurrentQueryId(\"\"); // generate random query_id\n-        query_scope.emplace(*current_context);\n-        executeQuery(istr, ostr, false, *current_context, {});\n+        auto query_context = task.makeQueryContext(context, zookeeper);\n+        if (!task.is_initial_query)\n+            query_scope.emplace(*query_context);\n+        executeQuery(istr, ostr, !task.is_initial_query, *query_context, {});\n+\n+        if (auto txn = query_context->getZooKeeperMetadataTransaction())\n+        {\n+            /// Most queries commit changes to ZooKeeper right before applying local changes,\n+            /// but some queries does not support it, so we have to do it here.\n+            if (!txn->isExecuted())\n+                txn->commit();\n+        }\n+    }\n+    catch (const DB::Exception & e)\n+    {\n+        if (task.is_initial_query)\n+            throw;\n+\n+        task.execution_status = ExecutionStatus::fromCurrentException();\n+        tryLogCurrentException(log, \"Query \" + query + \" wasn't finished successfully\");\n+\n+        /// We use return value of tryExecuteQuery(...) in tryExecuteQueryOnLeaderReplica(...) to determine\n+        /// if replica has stopped being leader and we should retry query.\n+        /// However, for the majority of exceptions there is no sense to retry, because most likely we will just\n+        /// get the same exception again. So we return false only for several special exception codes,\n+        /// and consider query as executed with status \"failed\" and return true in other cases.\n+        bool no_sense_to_retry = e.code() != ErrorCodes::KEEPER_EXCEPTION &&\n+                                 e.code() != ErrorCodes::NOT_A_LEADER &&\n+                                 e.code() != ErrorCodes::CANNOT_ASSIGN_ALTER &&\n+                                 e.code() != ErrorCodes::CANNOT_ALLOCATE_MEMORY &&\n+                                 e.code() != ErrorCodes::MEMORY_LIMIT_EXCEEDED;\n+        return no_sense_to_retry;\n     }\n     catch (...)\n     {\n-        status = ExecutionStatus::fromCurrentException();\n+        if (task.is_initial_query)\n+            throw;\n+\n+        task.execution_status = ExecutionStatus::fromCurrentException();\n         tryLogCurrentException(log, \"Query \" + query + \" wasn't finished successfully\");\n \n+        /// We don't know what exactly happened, but maybe it's Poco::NetException or std::bad_alloc,\n+        /// so we consider unknown exception as retryable error.\n         return false;\n     }\n \n-    status = ExecutionStatus(0);\n+    task.execution_status = ExecutionStatus(0);\n     LOG_DEBUG(log, \"Executed query: {}\", query);\n \n     return true;\n }\n \n-\n-void DDLWorker::enqueueTask(DDLTaskPtr task_ptr)\n+void DDLWorker::updateMaxDDLEntryID(const String & entry_name)\n {\n-    auto & task = *task_ptr;\n-\n-    while (!stop_flag)\n-    {\n-        try\n-        {\n-            processTask(task);\n-            return;\n-        }\n-        catch (const Coordination::Exception & e)\n-        {\n-            if (Coordination::isHardwareError(e.code))\n-            {\n-                recoverZooKeeper();\n-            }\n-            else\n-            {\n-                LOG_ERROR(log, \"Unexpected ZooKeeper error: {}.\", getCurrentExceptionMessage(true));\n-                throw;\n-            }\n-        }\n-        catch (...)\n-        {\n-            LOG_WARNING(log, \"An error occurred while processing task {} ({}) : {}\", task.entry_name, task.entry.query, getCurrentExceptionMessage(true));\n-        }\n-    }\n-}\n-\n-\n-void DDLWorker::updateMaxDDLEntryID(const DDLTask & task)\n-{\n-    DB::ReadBufferFromString in(task.entry_name);\n-    DB::assertString(\"query-\", in);\n-    UInt64 id;\n-    readText(id, in);\n+    UInt64 id = DDLTaskBase::getLogEntryNumber(entry_name);\n     auto prev_id = max_id.load(std::memory_order_relaxed);\n     while (prev_id < id)\n     {\n         if (max_id.compare_exchange_weak(prev_id, id))\n         {\n-            CurrentMetrics::set(CurrentMetrics::MaxDDLEntryID, id);\n+            if (max_entry_metric)\n+                CurrentMetrics::set(*max_entry_metric, id);\n             break;\n         }\n     }\n }\n \n-\n-void DDLWorker::processTask(DDLTask & task)\n+void DDLWorker::processTask(DDLTaskBase & task, const ZooKeeperPtr & zookeeper)\n {\n-    auto zookeeper = tryGetZooKeeper();\n-\n     LOG_DEBUG(log, \"Processing task {} ({})\", task.entry_name, task.entry.query);\n \n-    String active_node_path = task.entry_path + \"/active/\" + task.host_id_str;\n-    String finished_node_path = task.entry_path + \"/finished/\" + task.host_id_str;\n+    String active_node_path = task.getActiveNodePath();\n+    String finished_node_path = task.getFinishedNodePath();\n \n     /// It will tryRemove(...) on exception\n     auto active_node = zkutil::EphemeralNodeHolder::existing(active_node_path, *zookeeper);\n@@ -712,9 +492,8 @@ void DDLWorker::processTask(DDLTask & task)\n \n         if (create_active_res == Coordination::Error::ZNODEEXISTS)\n         {\n-            /// Connection has been lost and now we are retrying to write query status,\n+            /// Connection has been lost and now we are retrying,\n             /// but our previous ephemeral node still exists.\n-            assert(task.was_executed);\n             zkutil::EventPtr eph_node_disappeared = std::make_shared<Poco::Event>();\n             String dummy;\n             if (zookeeper->tryGet(active_node_path, dummy, nullptr, eph_node_disappeared))\n@@ -731,17 +510,21 @@ void DDLWorker::processTask(DDLTask & task)\n \n     if (!task.was_executed)\n     {\n+        /// If table and database engine supports it, they will execute task.ops by their own in a single transaction\n+        /// with other zk operations (such as appending something to ReplicatedMergeTree log, or\n+        /// updating metadata in Replicated database), so we make create request for finished_node_path with status \"0\",\n+        /// which means that query executed successfully.\n+        task.ops.emplace_back(zkutil::makeRemoveRequest(active_node_path, -1));\n+        task.ops.emplace_back(zkutil::makeCreateRequest(finished_node_path, ExecutionStatus(0).serializeText(), zkutil::CreateMode::Persistent));\n+\n         try\n         {\n-            parseQueryAndResolveHost(task);\n-\n-            ASTPtr rewritten_ast = task.query_on_cluster->getRewrittenASTWithoutOnCluster(task.address_in_cluster.default_database);\n-            String rewritten_query = queryToString(rewritten_ast);\n+            String rewritten_query = queryToString(task.query);\n             LOG_DEBUG(log, \"Executing query: {}\", rewritten_query);\n \n-            if (auto * query_with_table = dynamic_cast<ASTQueryWithTableAndOutput *>(rewritten_ast.get()); query_with_table)\n+            StoragePtr storage;\n+            if (auto * query_with_table = dynamic_cast<ASTQueryWithTableAndOutput *>(task.query.get()); query_with_table)\n             {\n-                StoragePtr storage;\n                 if (!query_with_table->table.empty())\n                 {\n                     /// It's not CREATE DATABASE\n@@ -749,19 +532,18 @@ void DDLWorker::processTask(DDLTask & task)\n                     storage = DatabaseCatalog::instance().tryGetTable(table_id, context);\n                 }\n \n-                if (storage && taskShouldBeExecutedOnLeader(rewritten_ast, storage)  && !task.is_circular_replicated)\n-                {\n-                    tryExecuteQueryOnLeaderReplica(task, storage, rewritten_query, task.entry_path, zookeeper);\n-                }\n-                else\n-                {\n-                    /// StoragePtr may cause DROP TABLE to hang\n-                    storage.reset();\n-                    tryExecuteQuery(rewritten_query, task, task.execution_status);\n-                }\n+                task.execute_on_leader = storage && taskShouldBeExecutedOnLeader(task.query, storage) && !task.is_circular_replicated;\n+            }\n+\n+            if (task.execute_on_leader)\n+            {\n+                tryExecuteQueryOnLeaderReplica(task, storage, rewritten_query, task.entry_path, zookeeper);\n             }\n             else\n-                tryExecuteQuery(rewritten_query, task, task.execution_status);\n+            {\n+                storage.reset();\n+                tryExecuteQuery(rewritten_query, task, zookeeper);\n+            }\n         }\n         catch (const Coordination::Exception &)\n         {\n@@ -769,27 +551,52 @@ void DDLWorker::processTask(DDLTask & task)\n         }\n         catch (...)\n         {\n+            if (task.is_initial_query)\n+                throw;\n             tryLogCurrentException(log, \"An error occurred before execution of DDL task: \");\n             task.execution_status = ExecutionStatus::fromCurrentException(\"An error occurred before execution\");\n         }\n \n+        if (task.execution_status.code != 0)\n+        {\n+            bool status_written_by_table_or_db = task.ops.empty();\n+            if (status_written_by_table_or_db)\n+            {\n+                throw Exception(ErrorCodes::UNFINISHED, \"Unexpected error: {}\", task.execution_status.serializeText());\n+            }\n+            else\n+            {\n+                /// task.ops where not executed by table or database engine, so DDLWorker is responsible for\n+                /// writing query execution status into ZooKeeper.\n+                task.ops.emplace_back(zkutil::makeSetRequest(finished_node_path, task.execution_status.serializeText(), -1));\n+            }\n+        }\n+\n         /// We need to distinguish ZK errors occurred before and after query executing\n         task.was_executed = true;\n     }\n \n-    updateMaxDDLEntryID(task);\n+    updateMaxDDLEntryID(task.entry_name);\n \n     /// FIXME: if server fails right here, the task will be executed twice. We need WAL here.\n+    /// NOTE: If ZooKeeper connection is lost here, we will try again to write query status.\n+    /// NOTE: If both table and database are replicated, task is executed in single ZK transaction.\n \n-    /// Delete active flag and create finish flag\n-    Coordination::Requests ops;\n-    ops.emplace_back(zkutil::makeRemoveRequest(active_node_path, -1));\n-    ops.emplace_back(zkutil::makeCreateRequest(finished_node_path, task.execution_status.serializeText(), zkutil::CreateMode::Persistent));\n-    zookeeper->multi(ops);\n+    bool status_written = task.ops.empty();\n+    if (!status_written)\n+    {\n+        zookeeper->multi(task.ops);\n+        task.ops.clear();\n+    }\n+\n+    /// Active node was removed in multi ops\n+    active_node->setAlreadyRemoved();\n+\n+    task.completely_processed = true;\n }\n \n \n-bool DDLWorker::taskShouldBeExecutedOnLeader(const ASTPtr ast_ddl, const StoragePtr storage)\n+bool DDLWorker::taskShouldBeExecutedOnLeader(const ASTPtr & ast_ddl, const StoragePtr storage)\n {\n     /// Pure DROP queries have to be executed on each node separately\n     if (auto * query = ast_ddl->as<ASTDropQuery>(); query && query->kind != ASTDropQuery::Kind::Truncate)\n@@ -803,47 +610,36 @@ bool DDLWorker::taskShouldBeExecutedOnLeader(const ASTPtr ast_ddl, const Storage\n         // Setting alters should be executed on all replicas\n         if (alter->isSettingsAlter())\n             return false;\n+\n+        if (alter->isFreezeAlter())\n+            return false;\n     }\n \n     return storage->supportsReplication();\n }\n \n bool DDLWorker::tryExecuteQueryOnLeaderReplica(\n-    DDLTask & task,\n+    DDLTaskBase & task,\n     StoragePtr storage,\n     const String & rewritten_query,\n-    const String & node_path,\n+    const String & /*node_path*/,\n     const ZooKeeperPtr & zookeeper)\n {\n     StorageReplicatedMergeTree * replicated_storage = dynamic_cast<StorageReplicatedMergeTree *>(storage.get());\n \n     /// If we will develop new replicated storage\n     if (!replicated_storage)\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Storage type '{}' is not supported by distributed DDL\", storage->getName());\n-\n-    /// Generate unique name for shard node, it will be used to execute the query by only single host\n-    /// Shard node name has format 'replica_name1,replica_name2,...,replica_nameN'\n-    /// Where replica_name is 'replica_config_host_name:replica_port'\n-    auto get_shard_name = [] (const Cluster::Addresses & shard_addresses)\n-    {\n-        Strings replica_names;\n-        for (const Cluster::Address & address : shard_addresses)\n-            replica_names.emplace_back(address.readableString());\n-        std::sort(replica_names.begin(), replica_names.end());\n-\n-        String res;\n-        for (auto it = replica_names.begin(); it != replica_names.end(); ++it)\n-            res += *it + (std::next(it) != replica_names.end() ? \",\" : \"\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Storage type '{}' is not supported by distributed DDL\", storage->getName());\n \n-        return res;\n-    };\n-\n-    String shard_node_name = get_shard_name(task.cluster->getShardsAddresses().at(task.host_shard_num));\n-    String shard_path = fs::path(node_path) / \"shards\" / shard_node_name;\n+    String shard_path = task.getShardNodePath();\n     String is_executed_path = fs::path(shard_path) / \"executed\";\n     String tries_to_execute_path = fs::path(shard_path) / \"tries_to_execute\";\n     zookeeper->createAncestors(fs::path(shard_path) / \"\"); /* appends \"/\" at the end of shard_path */\n \n+    /// Leader replica creates is_executed_path node on successful query execution.\n+    /// We will remove create_shard_flag from zk operations list, if current replica is just waiting for leader to execute the query.\n+    auto create_shard_flag = zkutil::makeCreateRequest(is_executed_path, task.host_id_str, zkutil::CreateMode::Persistent);\n+\n     /// Node exists, or we will create or we will get an exception\n     zookeeper->tryCreate(tries_to_execute_path, \"0\", zkutil::CreateMode::Persistent);\n \n@@ -867,7 +663,9 @@ bool DDLWorker::tryExecuteQueryOnLeaderReplica(\n \n     Stopwatch stopwatch;\n \n-    bool executed_by_leader = false;\n+    bool executed_by_us = false;\n+    bool executed_by_other_leader = false;\n+\n     /// Defensive programming. One hour is more than enough to execute almost all DDL queries.\n     /// If it will be very long query like ALTER DELETE for a huge table it's still will be executed,\n     /// but DDL worker can continue processing other queries.\n@@ -887,6 +685,9 @@ bool DDLWorker::tryExecuteQueryOnLeaderReplica(\n             return false;\n         }\n \n+        if (task.is_initial_query && !status.is_leader)\n+            throw Exception(ErrorCodes::NOT_A_LEADER, \"Cannot execute initial query on non-leader replica\");\n+\n         /// Any replica which is leader tries to take lock\n         if (status.is_leader && lock->tryLock())\n         {\n@@ -896,7 +697,7 @@ bool DDLWorker::tryExecuteQueryOnLeaderReplica(\n             if (zookeeper->tryGet(is_executed_path, executed_by))\n             {\n                 LOG_DEBUG(log, \"Task {} has already been executed by replica ({}) of the same shard.\", task.entry_name, executed_by);\n-                executed_by_leader = true;\n+                executed_by_other_leader = true;\n                 break;\n             }\n \n@@ -907,12 +708,14 @@ bool DDLWorker::tryExecuteQueryOnLeaderReplica(\n \n             zookeeper->set(tries_to_execute_path, toString(counter + 1));\n \n+            task.ops.push_back(create_shard_flag);\n+            SCOPE_EXIT({ if (!executed_by_us && !task.ops.empty()) task.ops.pop_back(); });\n+\n             /// If the leader will unexpectedly changed this method will return false\n             /// and on the next iteration new leader will take lock\n-            if (tryExecuteQuery(rewritten_query, task, task.execution_status))\n+            if (tryExecuteQuery(rewritten_query, task, zookeeper))\n             {\n-                zookeeper->create(is_executed_path, task.host_id_str, zkutil::CreateMode::Persistent);\n-                executed_by_leader = true;\n+                executed_by_us = true;\n                 break;\n             }\n \n@@ -923,7 +726,7 @@ bool DDLWorker::tryExecuteQueryOnLeaderReplica(\n         if (event->tryWait(std::uniform_int_distribution<int>(0, 1000)(rng)))\n         {\n             LOG_DEBUG(log, \"Task {} has already been executed by replica ({}) of the same shard.\", task.entry_name, zookeeper->get(is_executed_path));\n-            executed_by_leader = true;\n+            executed_by_other_leader = true;\n             break;\n         }\n         else\n@@ -944,8 +747,10 @@ bool DDLWorker::tryExecuteQueryOnLeaderReplica(\n         }\n     }\n \n+    assert(!(executed_by_us && executed_by_other_leader));\n+\n     /// Not executed by leader so was not executed at all\n-    if (!executed_by_leader)\n+    if (!executed_by_us && !executed_by_other_leader)\n     {\n         /// If we failed with timeout\n         if (stopwatch.elapsedSeconds() >= MAX_EXECUTION_TIMEOUT_SEC)\n@@ -961,21 +766,22 @@ bool DDLWorker::tryExecuteQueryOnLeaderReplica(\n         return false;\n     }\n \n-    LOG_DEBUG(log, \"Task {} has already been executed by replica ({}) of the same shard.\", task.entry_name, zookeeper->get(is_executed_path));\n+    if (executed_by_us)\n+        LOG_DEBUG(log, \"Task {} executed by current replica\", task.entry_name);\n+    else // if (executed_by_other_leader)\n+        LOG_DEBUG(log, \"Task {} has already been executed by replica ({}) of the same shard.\", task.entry_name, zookeeper->get(is_executed_path));\n+\n     return true;\n }\n \n \n-void DDLWorker::cleanupQueue(Int64 current_time_seconds, const ZooKeeperPtr & zookeeper)\n+void DDLWorker::cleanupQueue(Int64, const ZooKeeperPtr & zookeeper)\n {\n     LOG_DEBUG(log, \"Cleaning queue\");\n \n     Strings queue_nodes = zookeeper->getChildren(queue_dir);\n     filterAndSortQueueNodes(queue_nodes);\n \n-    size_t num_outdated_nodes = (queue_nodes.size() > max_tasks_in_queue) ? queue_nodes.size() - max_tasks_in_queue : 0;\n-    auto first_non_outdated_node = queue_nodes.begin() + num_outdated_nodes;\n-\n     for (auto it = queue_nodes.cbegin(); it < queue_nodes.cend(); ++it)\n     {\n         if (stop_flag)\n@@ -993,15 +799,7 @@ void DDLWorker::cleanupQueue(Int64 current_time_seconds, const ZooKeeperPtr & zo\n             if (!zookeeper->exists(node_path, &stat))\n                 continue;\n \n-            /// Delete node if its lifetime is expired (according to task_max_lifetime parameter)\n-            constexpr UInt64 zookeeper_time_resolution = 1000;\n-            Int64 zookeeper_time_seconds = stat.ctime / zookeeper_time_resolution;\n-            bool node_lifetime_is_expired = zookeeper_time_seconds + task_max_lifetime < current_time_seconds;\n-\n-            /// If too many nodes in task queue (> max_tasks_in_queue), delete oldest one\n-            bool node_is_outside_max_window = it < first_non_outdated_node;\n-\n-            if (!node_lifetime_is_expired && !node_is_outside_max_window)\n+            if (!canRemoveQueueEntry(node_name, stat))\n                 continue;\n \n             /// At first we remove entry/active node to prevent staled hosts from executing entry concurrently\n@@ -1015,10 +813,8 @@ void DDLWorker::cleanupQueue(Int64 current_time_seconds, const ZooKeeperPtr & zo\n                 continue;\n             }\n \n-            if (node_lifetime_is_expired)\n-                LOG_INFO(log, \"Lifetime of task {} is expired, deleting it\", node_name);\n-            else if (node_is_outside_max_window)\n-                LOG_INFO(log, \"Task {} is outdated, deleting it\", node_name);\n+            /// Now we can safely delete entry\n+            LOG_INFO(log, \"Task {} is outdated, deleting it\", node_name);\n \n             /// We recursively delete all nodes except node_path/finished to prevent staled hosts from\n             /// creating node_path/active node (see createStatusDirs(...))\n@@ -1031,6 +827,7 @@ void DDLWorker::cleanupQueue(Int64 current_time_seconds, const ZooKeeperPtr & zo\n             ops.emplace_back(zkutil::makeRemoveRequest(fs::path(node_path) / \"finished\", -1));\n             ops.emplace_back(zkutil::makeRemoveRequest(node_path, -1));\n             auto rm_entry_res = zookeeper->tryMulti(ops, res);\n+\n             if (rm_entry_res == Coordination::Error::ZNONODE)\n             {\n                 /// Most likely both node_path/finished and node_path were removed concurrently.\n@@ -1055,6 +852,19 @@ void DDLWorker::cleanupQueue(Int64 current_time_seconds, const ZooKeeperPtr & zo\n     }\n }\n \n+bool DDLWorker::canRemoveQueueEntry(const String & entry_name, const Coordination::Stat & stat)\n+{\n+    /// Delete node if its lifetime is expired (according to task_max_lifetime parameter)\n+    constexpr UInt64 zookeeper_time_resolution = 1000;\n+    Int64 zookeeper_time_seconds = stat.ctime / zookeeper_time_resolution;\n+    bool node_lifetime_is_expired = zookeeper_time_seconds + task_max_lifetime < Poco::Timestamp().epochTime();\n+\n+    /// If too many nodes in task queue (> max_tasks_in_queue), delete oldest one\n+    UInt32 entry_number = DDLTaskBase::getLogEntryNumber(entry_name);\n+    bool node_is_outside_max_window = entry_number + max_tasks_in_queue < max_id.load(std::memory_order_relaxed);\n+\n+    return node_lifetime_is_expired || node_is_outside_max_window;\n+}\n \n /// Try to create nonexisting \"status\" dirs for a node\n void DDLWorker::createStatusDirs(const std::string & node_path, const ZooKeeperPtr & zookeeper)\n@@ -1080,8 +890,11 @@ void DDLWorker::createStatusDirs(const std::string & node_path, const ZooKeeperP\n         return;\n \n     if (is_currently_deleting)\n+    {\n+        cleanup_event->set();\n         throw Exception(ErrorCodes::UNFINISHED, \"Cannot create status dirs for {}, \"\n                         \"most likely because someone is deleting it concurrently\", node_path);\n+    }\n \n     /// Connection lost or entry was removed\n     assert(Coordination::isHardwareError(code) || code == Coordination::Error::ZNONODE);\n@@ -1101,7 +914,9 @@ String DDLWorker::enqueueQuery(DDLLogEntry & entry)\n \n     String node_path = zookeeper->create(query_path_prefix, entry.toString(), zkutil::CreateMode::PersistentSequential);\n \n-    /// Optional step\n+    /// We cannot create status dirs in a single transaction with previous request,\n+    /// because we don't know node_path until previous request is executed.\n+    /// Se we try to create status dirs here or later when we will execute entry.\n     try\n     {\n         createStatusDirs(node_path, zookeeper);\n@@ -1115,30 +930,20 @@ String DDLWorker::enqueueQuery(DDLLogEntry & entry)\n }\n \n \n-void DDLWorker::runMainThread()\n+void DDLWorker::initializeMainThread()\n {\n-    auto reset_state = [&](bool reset_pool = true)\n-    {\n-        /// It will wait for all threads in pool to finish and will not rethrow exceptions (if any).\n-        /// We create new thread pool to forget previous exceptions.\n-        if (reset_pool)\n-            worker_pool = std::make_unique<ThreadPool>(pool_size);\n-        /// Clear other in-memory state, like server just started.\n-        last_tasks.clear();\n-        max_id = 0;\n-    };\n-\n+    assert(!initialized);\n     setThreadName(\"DDLWorker\");\n     LOG_DEBUG(log, \"Started DDLWorker thread\");\n \n-    bool initialized = false;\n-    do\n+    while (!stop_flag)\n     {\n         try\n         {\n             auto zookeeper = getAndSetZooKeeper();\n             zookeeper->createAncestors(fs::path(queue_dir) / \"\");\n             initialized = true;\n+            return;\n         }\n         catch (const Coordination::Exception & e)\n         {\n@@ -1146,53 +951,76 @@ void DDLWorker::runMainThread()\n             {\n                 /// A logical error.\n                 LOG_ERROR(log, \"ZooKeeper error: {}. Failed to start DDLWorker.\", getCurrentExceptionMessage(true));\n-                reset_state(false);\n                 assert(false);  /// Catch such failures in tests with debug build\n             }\n \n             tryLogCurrentException(__PRETTY_FUNCTION__);\n-\n-            /// Avoid busy loop when ZooKeeper is not available.\n-            sleepForSeconds(1);\n         }\n         catch (...)\n         {\n             tryLogCurrentException(log, \"Cannot initialize DDL queue.\");\n-            reset_state(false);\n         }\n+\n+        /// Avoid busy loop when ZooKeeper is not available.\n+        sleepForSeconds(5);\n     }\n-    while (!initialized && !stop_flag);\n+}\n+\n+void DDLWorker::runMainThread()\n+{\n+    auto reset_state = [&]()\n+    {\n+        initialized = false;\n+        /// It will wait for all threads in pool to finish and will not rethrow exceptions (if any).\n+        /// We create new thread pool to forget previous exceptions.\n+        if (1 < pool_size)\n+            worker_pool = std::make_unique<ThreadPool>(pool_size);\n+        /// Clear other in-memory state, like server just started.\n+        current_tasks.clear();\n+        last_skipped_entry_name.reset();\n+        max_id = 0;\n+        LOG_INFO(log, \"Cleaned DDLWorker state\");\n+    };\n+\n+    setThreadName(\"DDLWorker\");\n+    LOG_DEBUG(log, \"Starting DDLWorker thread\");\n \n     while (!stop_flag)\n     {\n         try\n         {\n+            /// Reinitialize DDLWorker state (including ZooKeeper connection) if required\n+            if (!initialized)\n+            {\n+                initializeMainThread();\n+                LOG_DEBUG(log, \"Initialized DDLWorker thread\");\n+            }\n+\n             cleanup_event->set();\n             scheduleTasks();\n \n-            LOG_DEBUG(log, \"Waiting a watch\");\n+            LOG_DEBUG(log, \"Waiting for queue updates\");\n             queue_updated_event->wait();\n         }\n         catch (const Coordination::Exception & e)\n         {\n             if (Coordination::isHardwareError(e.code))\n             {\n-                recoverZooKeeper();\n-            }\n-            else if (e.code == Coordination::Error::ZNONODE)\n-            {\n-                LOG_ERROR(log, \"ZooKeeper error: {}\", getCurrentExceptionMessage(true));\n+                initialized = false;\n+                LOG_INFO(log, \"Lost ZooKeeper connection, will try to connect again: {}\", getCurrentExceptionMessage(true));\n             }\n             else\n             {\n-                LOG_ERROR(log, \"Unexpected ZooKeeper error: {}\", getCurrentExceptionMessage(true));\n+                LOG_ERROR(log, \"Unexpected ZooKeeper error, will try to restart main thread: {}\", getCurrentExceptionMessage(true));\n                 reset_state();\n             }\n+            sleepForSeconds(1);\n         }\n         catch (...)\n         {\n-            tryLogCurrentException(log, \"Unexpected error:\");\n+            tryLogCurrentException(log, \"Unexpected error, will try to restart main thread:\");\n             reset_state();\n+            sleepForSeconds(5);\n         }\n     }\n }\n@@ -1219,6 +1047,7 @@ void DDLWorker::runCleanupThread()\n                 continue;\n             }\n \n+            /// ZooKeeper connection is recovered by main thread. We will wait for it on cleanup_event.\n             auto zookeeper = tryGetZooKeeper();\n             if (zookeeper->expired())\n                 continue;\n@@ -1233,313 +1062,4 @@ void DDLWorker::runCleanupThread()\n     }\n }\n \n-\n-class DDLQueryStatusInputStream final : public IBlockInputStream\n-{\n-public:\n-\n-    DDLQueryStatusInputStream(const String & zk_node_path, const DDLLogEntry & entry, const Context & context_)\n-        : node_path(zk_node_path), context(context_), watch(CLOCK_MONOTONIC_COARSE), log(&Poco::Logger::get(\"DDLQueryStatusInputStream\"))\n-    {\n-        sample = Block{\n-            {std::make_shared<DataTypeString>(),    \"host\"},\n-            {std::make_shared<DataTypeUInt16>(),    \"port\"},\n-            {std::make_shared<DataTypeInt64>(),     \"status\"},\n-            {std::make_shared<DataTypeString>(),    \"error\"},\n-            {std::make_shared<DataTypeUInt64>(),    \"num_hosts_remaining\"},\n-            {std::make_shared<DataTypeUInt64>(),    \"num_hosts_active\"},\n-        };\n-\n-        for (const HostID & host: entry.hosts)\n-            waiting_hosts.emplace(host.toString());\n-\n-        addTotalRowsApprox(entry.hosts.size());\n-\n-        timeout_seconds = context.getSettingsRef().distributed_ddl_task_timeout;\n-    }\n-\n-    String getName() const override\n-    {\n-        return \"DDLQueryStatusInputStream\";\n-    }\n-\n-    Block getHeader() const override { return sample; }\n-\n-    Block readImpl() override\n-    {\n-        Block res;\n-        if (num_hosts_finished >= waiting_hosts.size())\n-        {\n-            if (first_exception)\n-                throw Exception(*first_exception);\n-\n-            return res;\n-        }\n-\n-        auto zookeeper = context.getZooKeeper();\n-        size_t try_number = 0;\n-\n-        while (res.rows() == 0)\n-        {\n-            if (isCancelled())\n-            {\n-                if (first_exception)\n-                    throw Exception(*first_exception);\n-\n-                return res;\n-            }\n-\n-            if (timeout_seconds >= 0 && watch.elapsedSeconds() > timeout_seconds)\n-            {\n-                size_t num_unfinished_hosts = waiting_hosts.size() - num_hosts_finished;\n-                size_t num_active_hosts = current_active_hosts.size();\n-\n-                throw Exception(ErrorCodes::TIMEOUT_EXCEEDED,\n-                    \"Watching task {} is executing longer than distributed_ddl_task_timeout (={}) seconds. \"\n-                    \"There are {} unfinished hosts ({} of them are currently active), they are going to execute the query in background\",\n-                    node_path, timeout_seconds, num_unfinished_hosts, num_active_hosts);\n-            }\n-\n-            if (num_hosts_finished != 0 || try_number != 0)\n-            {\n-                sleepForMilliseconds(std::min<size_t>(1000, 50 * (try_number + 1)));\n-            }\n-\n-            /// TODO: add shared lock\n-            if (!zookeeper->exists(node_path))\n-            {\n-                throw Exception(ErrorCodes::UNFINISHED,\n-                    \"Cannot provide query execution status. The query's node {} has been deleted by the cleaner since it was finished (or its lifetime is expired)\",\n-                    node_path);\n-            }\n-\n-            Strings new_hosts = getNewAndUpdate(getChildrenAllowNoNode(zookeeper, fs::path(node_path) / \"finished\"));\n-            ++try_number;\n-            if (new_hosts.empty())\n-                continue;\n-\n-            current_active_hosts = getChildrenAllowNoNode(zookeeper, fs::path(node_path) / \"active\");\n-\n-            MutableColumns columns = sample.cloneEmptyColumns();\n-            for (const String & host_id : new_hosts)\n-            {\n-                ExecutionStatus status(-1, \"Cannot obtain error message\");\n-                {\n-                    String status_data;\n-                    if (zookeeper->tryGet(fs::path(node_path) / \"finished\" / host_id, status_data))\n-                        status.tryDeserializeText(status_data);\n-                }\n-\n-                auto [host, port] = Cluster::Address::fromString(host_id);\n-\n-                if (status.code != 0 && first_exception == nullptr)\n-                    first_exception = std::make_unique<Exception>(status.code, \"There was an error on [{}:{}]: {}\", host, port, status.message);\n-\n-                ++num_hosts_finished;\n-\n-                columns[0]->insert(host);\n-                columns[1]->insert(port);\n-                columns[2]->insert(status.code);\n-                columns[3]->insert(status.message);\n-                columns[4]->insert(waiting_hosts.size() - num_hosts_finished);\n-                columns[5]->insert(current_active_hosts.size());\n-            }\n-            res = sample.cloneWithColumns(std::move(columns));\n-        }\n-\n-        return res;\n-    }\n-\n-    Block getSampleBlock() const\n-    {\n-        return sample.cloneEmpty();\n-    }\n-\n-    ~DDLQueryStatusInputStream() override = default;\n-\n-private:\n-\n-    static Strings getChildrenAllowNoNode(const std::shared_ptr<zkutil::ZooKeeper> & zookeeper, const String & node_path)\n-    {\n-        Strings res;\n-        Coordination::Error code = zookeeper->tryGetChildren(node_path, res);\n-        if (code != Coordination::Error::ZOK && code != Coordination::Error::ZNONODE)\n-            throw Coordination::Exception(code, node_path);\n-        return res;\n-    }\n-\n-    Strings getNewAndUpdate(const Strings & current_list_of_finished_hosts)\n-    {\n-        Strings diff;\n-        for (const String & host : current_list_of_finished_hosts)\n-        {\n-            if (!waiting_hosts.count(host))\n-            {\n-                if (!ignoring_hosts.count(host))\n-                {\n-                    ignoring_hosts.emplace(host);\n-                    LOG_INFO(log, \"Unexpected host {} appeared  in task {}\", host, node_path);\n-                }\n-                continue;\n-            }\n-\n-            if (!finished_hosts.count(host))\n-            {\n-                diff.emplace_back(host);\n-                finished_hosts.emplace(host);\n-            }\n-        }\n-\n-        return diff;\n-    }\n-\n-    String node_path;\n-    const Context & context;\n-    Stopwatch watch;\n-    Poco::Logger * log;\n-\n-    Block sample;\n-\n-    NameSet waiting_hosts;  /// hosts from task host list\n-    NameSet finished_hosts; /// finished hosts from host list\n-    NameSet ignoring_hosts; /// appeared hosts that are not in hosts list\n-    Strings current_active_hosts; /// Hosts that were in active state at the last check\n-    size_t num_hosts_finished = 0;\n-\n-    /// Save the first detected error and throw it at the end of execution\n-    std::unique_ptr<Exception> first_exception;\n-\n-    Int64 timeout_seconds = 120;\n-};\n-\n-\n-BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr_, const Context & context, AccessRightsElements && query_requires_access, bool query_requires_grant_option)\n-{\n-    /// Remove FORMAT <fmt> and INTO OUTFILE <file> if exists\n-    ASTPtr query_ptr = query_ptr_->clone();\n-    ASTQueryWithOutput::resetOutputASTIfExist(*query_ptr);\n-\n-    // XXX: serious design flaw since `ASTQueryWithOnCluster` is not inherited from `IAST`!\n-    auto * query = dynamic_cast<ASTQueryWithOnCluster *>(query_ptr.get());\n-    if (!query)\n-    {\n-        throw Exception(\"Distributed execution is not supported for such DDL queries\", ErrorCodes::NOT_IMPLEMENTED);\n-    }\n-\n-    if (!context.getSettingsRef().allow_distributed_ddl)\n-        throw Exception(\"Distributed DDL queries are prohibited for the user\", ErrorCodes::QUERY_IS_PROHIBITED);\n-\n-    if (const auto * query_alter = query_ptr->as<ASTAlterQuery>())\n-    {\n-        for (const auto & command : query_alter->command_list->children)\n-        {\n-            if (!isSupportedAlterType(command->as<ASTAlterCommand&>().type))\n-                throw Exception(\"Unsupported type of ALTER query\", ErrorCodes::NOT_IMPLEMENTED);\n-        }\n-    }\n-\n-    query->cluster = context.getMacros()->expand(query->cluster);\n-    ClusterPtr cluster = context.getCluster(query->cluster);\n-    DDLWorker & ddl_worker = context.getDDLWorker();\n-\n-    /// Enumerate hosts which will be used to send query.\n-    Cluster::AddressesWithFailover shards = cluster->getShardsAddresses();\n-    std::vector<HostID> hosts;\n-    for (const auto & shard : shards)\n-    {\n-        for (const auto & addr : shard)\n-            hosts.emplace_back(addr);\n-    }\n-\n-    if (hosts.empty())\n-        throw Exception(\"No hosts defined to execute distributed DDL query\", ErrorCodes::LOGICAL_ERROR);\n-\n-    /// The current database in a distributed query need to be replaced with either\n-    /// the local current database or a shard's default database.\n-    bool need_replace_current_database\n-        = (std::find_if(\n-               query_requires_access.begin(),\n-               query_requires_access.end(),\n-               [](const AccessRightsElement & elem) { return elem.isEmptyDatabase(); })\n-           != query_requires_access.end());\n-\n-    bool use_local_default_database = false;\n-    const String & current_database = context.getCurrentDatabase();\n-\n-    if (need_replace_current_database)\n-    {\n-        Strings shard_default_databases;\n-        for (const auto & shard : shards)\n-        {\n-            for (const auto & addr : shard)\n-            {\n-                if (!addr.default_database.empty())\n-                    shard_default_databases.push_back(addr.default_database);\n-                else\n-                    use_local_default_database = true;\n-            }\n-        }\n-        std::sort(shard_default_databases.begin(), shard_default_databases.end());\n-        shard_default_databases.erase(std::unique(shard_default_databases.begin(), shard_default_databases.end()), shard_default_databases.end());\n-        assert(use_local_default_database || !shard_default_databases.empty());\n-\n-        if (use_local_default_database && !shard_default_databases.empty())\n-            throw Exception(\"Mixed local default DB and shard default DB in DDL query\", ErrorCodes::NOT_IMPLEMENTED);\n-\n-        if (use_local_default_database)\n-        {\n-            query_requires_access.replaceEmptyDatabase(current_database);\n-        }\n-        else\n-        {\n-            for (size_t i = 0; i != query_requires_access.size();)\n-            {\n-                auto & element = query_requires_access[i];\n-                if (element.isEmptyDatabase())\n-                {\n-                    query_requires_access.insert(query_requires_access.begin() + i + 1, shard_default_databases.size() - 1, element);\n-                    for (size_t j = 0; j != shard_default_databases.size(); ++j)\n-                        query_requires_access[i + j].replaceEmptyDatabase(shard_default_databases[j]);\n-                    i += shard_default_databases.size();\n-                }\n-                else\n-                    ++i;\n-            }\n-        }\n-    }\n-\n-    AddDefaultDatabaseVisitor visitor(current_database, !use_local_default_database);\n-    visitor.visitDDL(query_ptr);\n-\n-    /// Check access rights, assume that all servers have the same users config\n-    if (query_requires_grant_option)\n-        context.getAccess()->checkGrantOption(query_requires_access);\n-    else\n-        context.checkAccess(query_requires_access);\n-\n-    DDLLogEntry entry;\n-    entry.hosts = std::move(hosts);\n-    entry.query = queryToString(query_ptr);\n-    entry.initiator = ddl_worker.getCommonHostID();\n-    String node_path = ddl_worker.enqueueQuery(entry);\n-\n-    BlockIO io;\n-    if (context.getSettingsRef().distributed_ddl_task_timeout == 0)\n-        return io;\n-\n-    auto stream = std::make_shared<DDLQueryStatusInputStream>(node_path, entry, context);\n-    io.in = std::move(stream);\n-    return io;\n-}\n-\n-BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr, const Context & context, const AccessRightsElements & query_requires_access, bool query_requires_grant_option)\n-{\n-    return executeDDLQueryOnCluster(query_ptr, context, AccessRightsElements{query_requires_access}, query_requires_grant_option);\n-}\n-\n-BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr_, const Context & context)\n-{\n-    return executeDDLQueryOnCluster(query_ptr_, context, {});\n-}\n-\n }\ndiff --git a/src/Interpreters/DDLWorker.h b/src/Interpreters/DDLWorker.h\nindex 0a8fa6923ae9..8b0a8f038a01 100644\n--- a/src/Interpreters/DDLWorker.h\n+++ b/src/Interpreters/DDLWorker.h\n@@ -1,15 +1,11 @@\n #pragma once\n \n-#include <DataStreams/BlockIO.h>\n-#include <Interpreters/Cluster.h>\n-#include <Interpreters/Context.h>\n-#include <Storages/IStorage_fwd.h>\n-#include <Poco/Net/NetException.h>\n #include <Common/CurrentThread.h>\n #include <Common/DNSResolver.h>\n #include <Common/ThreadPool.h>\n-#include <Common/isLocalAddress.h>\n-#include <common/logger_useful.h>\n+#include <Storages/IStorage_fwd.h>\n+#include <Parsers/IAST_fwd.h>\n+#include <Interpreters/Context.h>\n \n #include <atomic>\n #include <chrono>\n@@ -19,90 +15,39 @@\n \n namespace zkutil\n {\n-class ZooKeeper;\n+    class ZooKeeper;\n }\n \n-namespace DB\n+namespace Poco\n {\n-class Context;\n-class ASTAlterQuery;\n-class AccessRightsElements;\n+    class Logger;\n+    namespace Util { class AbstractConfiguration; }\n+}\n \n-struct HostID\n+namespace Coordination\n {\n-    String host_name;\n-    UInt16 port;\n-\n-    HostID() = default;\n-\n-    explicit HostID(const Cluster::Address & address) : host_name(address.host_name), port(address.port) { }\n-\n-    static HostID fromString(const String & host_port_str)\n-    {\n-        HostID res;\n-        std::tie(res.host_name, res.port) = Cluster::Address::fromString(host_port_str);\n-        return res;\n-    }\n-\n-    String toString() const { return Cluster::Address::toString(host_name, port); }\n-\n-    String readableString() const { return host_name + \":\" + DB::toString(port); }\n-\n-    bool isLocalAddress(UInt16 clickhouse_port) const\n-    {\n-        try\n-        {\n-            return DB::isLocalAddress(DNSResolver::instance().resolveAddress(host_name, port), clickhouse_port);\n-        }\n-        catch (const Poco::Net::NetException &)\n-        {\n-            /// Avoid \"Host not found\" exceptions\n-            return false;\n-        }\n-    }\n-\n-    static String applyToString(const HostID & host_id) { return host_id.toString(); }\n-};\n+    struct Stat;\n+}\n \n-struct DDLLogEntry\n+namespace DB\n {\n-    String query;\n-    std::vector<HostID> hosts;\n-    String initiator; // optional\n-\n-    static constexpr int CURRENT_VERSION = 1;\n-\n-public:\n-    String toString();\n-    void parse(const String & data);\n-};\n-\n-struct DDLTask;\n-using DDLTaskPtr = std::unique_ptr<DDLTask>;\n-\n-\n-/// Pushes distributed DDL query to the queue\n-BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr, const Context & context);\n-BlockIO executeDDLQueryOnCluster(\n-    const ASTPtr & query_ptr,\n-    const Context & context,\n-    const AccessRightsElements & query_requires_access,\n-    bool query_requires_grant_option = false);\n-BlockIO executeDDLQueryOnCluster(\n-    const ASTPtr & query_ptr,\n-    const Context & context,\n-    AccessRightsElements && query_requires_access,\n-    bool query_requires_grant_option = false);\n+class ASTAlterQuery;\n+struct DDLLogEntry;\n+struct DDLTaskBase;\n+using DDLTaskPtr = std::unique_ptr<DDLTaskBase>;\n+using ZooKeeperPtr = std::shared_ptr<zkutil::ZooKeeper>;\n+class AccessRightsElements;\n \n \n class DDLWorker\n {\n public:\n-    DDLWorker(int pool_size_, const std::string & zk_root_dir, Context & context_, const Poco::Util::AbstractConfiguration * config, const String & prefix);\n-    ~DDLWorker();\n+    DDLWorker(int pool_size_, const std::string & zk_root_dir, const Context & context_, const Poco::Util::AbstractConfiguration * config, const String & prefix,\n+              const String & logger_name = \"DDLWorker\", const CurrentMetrics::Metric * max_entry_metric_ = nullptr);\n+    virtual ~DDLWorker();\n \n     /// Pushes query into DDL queue, returns path to created node\n-    String enqueueQuery(DDLLogEntry & entry);\n+    virtual String enqueueQuery(DDLLogEntry & entry);\n \n     /// Host ID (name:port) for logging purposes\n     /// Note that in each task hosts are identified individually by name:port from initiator server cluster config\n@@ -111,30 +56,32 @@ class DDLWorker\n         return host_fqdn_id;\n     }\n \n-private:\n-    using ZooKeeperPtr = std::shared_ptr<zkutil::ZooKeeper>;\n+    void startup();\n+    virtual void shutdown();\n+\n+    bool isCurrentlyActive() const { return initialized && !stop_flag; }\n+\n+protected:\n \n     /// Returns cached ZooKeeper session (possibly expired).\n     ZooKeeperPtr tryGetZooKeeper() const;\n     /// If necessary, creates a new session and caches it.\n     ZooKeeperPtr getAndSetZooKeeper();\n-    /// ZooKeeper recover loop (while not stopped).\n-    void recoverZooKeeper();\n \n-    void checkCurrentTasks();\n+    /// Iterates through queue tasks in ZooKeeper, runs execution of new tasks\n     void scheduleTasks();\n-    void saveTask(const String & entry_name);\n+\n+    DDLTaskBase & saveTask(DDLTaskPtr && task);\n \n     /// Reads entry and check that the host belongs to host list of the task\n     /// Returns non-empty DDLTaskPtr if entry parsed and the check is passed\n-    DDLTaskPtr initAndCheckTask(const String & entry_name, String & out_reason, const ZooKeeperPtr & zookeeper);\n+    virtual DDLTaskPtr initAndCheckTask(const String & entry_name, String & out_reason, const ZooKeeperPtr & zookeeper);\n \n-    void updateMaxDDLEntryID(const DDLTask & task);\n-    void enqueueTask(DDLTaskPtr task);\n-    void processTask(DDLTask & task);\n+    void processTask(DDLTaskBase & task, const ZooKeeperPtr & zookeeper);\n+    void updateMaxDDLEntryID(const String & entry_name);\n \n     /// Check that query should be executed on leader replica only\n-    static bool taskShouldBeExecutedOnLeader(const ASTPtr ast_ddl, StoragePtr storage);\n+    static bool taskShouldBeExecutedOnLeader(const ASTPtr & ast_ddl, StoragePtr storage);\n \n     /// Executes query only on leader replica in case of replicated table.\n     /// Queries like TRUNCATE/ALTER .../OPTIMIZE have to be executed only on one node of shard.\n@@ -142,27 +89,27 @@ class DDLWorker\n     /// query via RemoteBlockOutputStream to leader, so to avoid such \"2-phase\" query execution we\n     /// execute query directly on leader.\n     bool tryExecuteQueryOnLeaderReplica(\n-        DDLTask & task,\n+        DDLTaskBase & task,\n         StoragePtr storage,\n         const String & rewritten_query,\n         const String & node_path,\n         const ZooKeeperPtr & zookeeper);\n \n-    void parseQueryAndResolveHost(DDLTask & task);\n-\n-    bool tryExecuteQuery(const String & query, const DDLTask & task, ExecutionStatus & status);\n+    bool tryExecuteQuery(const String & query, DDLTaskBase & task, const ZooKeeperPtr & zookeeper);\n \n     /// Checks and cleanups queue's nodes\n     void cleanupQueue(Int64 current_time_seconds, const ZooKeeperPtr & zookeeper);\n+    virtual bool canRemoveQueueEntry(const String & entry_name, const Coordination::Stat & stat);\n \n     /// Init task node\n-    static void createStatusDirs(const std::string & node_path, const ZooKeeperPtr & zookeeper);\n+    void createStatusDirs(const std::string & node_path, const ZooKeeperPtr & zookeeper);\n \n+    virtual void initializeMainThread();\n \n     void runMainThread();\n     void runCleanupThread();\n \n-private:\n+protected:\n     Context context;\n     Poco::Logger * log;\n \n@@ -174,10 +121,12 @@ class DDLWorker\n     ZooKeeperPtr current_zookeeper;\n \n     /// Save state of executed task to avoid duplicate execution on ZK error\n-    std::vector<std::string> last_tasks;\n+    std::optional<String> last_skipped_entry_name;\n+    std::list<DDLTaskPtr> current_tasks;\n \n     std::shared_ptr<Poco::Event> queue_updated_event = std::make_shared<Poco::Event>();\n     std::shared_ptr<Poco::Event> cleanup_event = std::make_shared<Poco::Event>();\n+    std::atomic<bool> initialized = false;\n     std::atomic<bool> stop_flag = false;\n \n     ThreadFromGlobalPool main_thread;\n@@ -195,9 +144,7 @@ class DDLWorker\n     size_t max_tasks_in_queue = 1000;\n \n     std::atomic<UInt64> max_id = 0;\n-\n-    friend class DDLQueryStatusInputStream;\n-    friend struct DDLTask;\n+    const CurrentMetrics::Metric * max_entry_metric;\n };\n \n \ndiff --git a/src/Interpreters/DatabaseCatalog.cpp b/src/Interpreters/DatabaseCatalog.cpp\nindex 18cf69675bae..f27fb93b2d41 100644\n--- a/src/Interpreters/DatabaseCatalog.cpp\n+++ b/src/Interpreters/DatabaseCatalog.cpp\n@@ -609,7 +609,7 @@ DatabaseCatalog::updateDependency(const StorageID & old_from, const StorageID &\n         view_dependencies[{new_from.getDatabaseName(), new_from.getTableName()}].insert(new_where);\n }\n \n-std::unique_ptr<DDLGuard> DatabaseCatalog::getDDLGuard(const String & database, const String & table)\n+DDLGuardPtr DatabaseCatalog::getDDLGuard(const String & database, const String & table)\n {\n     std::unique_lock lock(ddl_guards_mutex);\n     auto db_guard_iter = ddl_guards.try_emplace(database).first;\n@@ -956,36 +956,38 @@ DDLGuard::DDLGuard(Map & map_, std::shared_mutex & db_mutex_, std::unique_lock<s\n     ++it->second.counter;\n     guards_lock.unlock();\n     table_lock = std::unique_lock(*it->second.mutex);\n-    bool is_database = elem.empty();\n-    if (!is_database)\n+    is_database_guard = elem.empty();\n+    if (!is_database_guard)\n     {\n \n         bool locked_database_for_read = db_mutex.try_lock_shared();\n         if (!locked_database_for_read)\n         {\n-            removeTableLock();\n+            releaseTableLock();\n             throw Exception(ErrorCodes::UNKNOWN_DATABASE, \"Database {} is currently dropped or renamed\", database_name);\n         }\n     }\n }\n \n-void DDLGuard::removeTableLock()\n+void DDLGuard::releaseTableLock() noexcept\n {\n+    if (table_lock_removed)\n+        return;\n+\n+    table_lock_removed = true;\n     guards_lock.lock();\n-    --it->second.counter;\n-    if (!it->second.counter)\n-    {\n-        table_lock.unlock();\n+    UInt32 counter = --it->second.counter;\n+    table_lock.unlock();\n+    if (counter == 0)\n         map.erase(it);\n-    }\n+    guards_lock.unlock();\n }\n \n DDLGuard::~DDLGuard()\n {\n-    bool is_database = it->first.empty();\n-    if (!is_database)\n+    if (!is_database_guard)\n         db_mutex.unlock_shared();\n-    removeTableLock();\n+    releaseTableLock();\n }\n \n }\ndiff --git a/src/Interpreters/DatabaseCatalog.h b/src/Interpreters/DatabaseCatalog.h\nindex 5146c786f642..bb82dbfc4407 100644\n--- a/src/Interpreters/DatabaseCatalog.h\n+++ b/src/Interpreters/DatabaseCatalog.h\n@@ -54,16 +54,21 @@ class DDLGuard\n     DDLGuard(Map & map_, std::shared_mutex & db_mutex_, std::unique_lock<std::mutex> guards_lock_, const String & elem, const String & database_name);\n     ~DDLGuard();\n \n+    /// Unlocks table name, keeps holding read lock for database name\n+    void releaseTableLock() noexcept;\n+\n private:\n     Map & map;\n     std::shared_mutex & db_mutex;\n     Map::iterator it;\n     std::unique_lock<std::mutex> guards_lock;\n     std::unique_lock<std::mutex> table_lock;\n-\n-    void removeTableLock();\n+    bool table_lock_removed = false;\n+    bool is_database_guard = false;\n };\n \n+using DDLGuardPtr = std::unique_ptr<DDLGuard>;\n+\n \n /// Creates temporary table in `_temporary_and_external_tables` with randomly generated unique StorageID.\n /// Such table can be accessed from everywhere by its ID.\n@@ -117,7 +122,7 @@ class DatabaseCatalog : boost::noncopyable\n     void loadDatabases();\n \n     /// Get an object that protects the table from concurrently executing multiple DDL operations.\n-    std::unique_ptr<DDLGuard> getDDLGuard(const String & database, const String & table);\n+    DDLGuardPtr getDDLGuard(const String & database, const String & table);\n     /// Get an object that protects the database from concurrent DDL queries all tables in the database\n     std::unique_lock<std::shared_mutex> getExclusiveDDLGuardForDatabase(const String & database);\n \ndiff --git a/src/Interpreters/InterpreterAlterQuery.cpp b/src/Interpreters/InterpreterAlterQuery.cpp\nindex bb457b65f4d8..bf624507574b 100644\n--- a/src/Interpreters/InterpreterAlterQuery.cpp\n+++ b/src/Interpreters/InterpreterAlterQuery.cpp\n@@ -1,5 +1,5 @@\n #include <Interpreters/InterpreterAlterQuery.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Interpreters/MutationsInterpreter.h>\n #include <Interpreters/AddDefaultDatabaseVisitor.h>\n #include <Interpreters/Context.h>\n@@ -16,6 +16,9 @@\n #include <Common/typeid_cast.h>\n #include <boost/range/algorithm_ext/push_back.hpp>\n #include <algorithm>\n+#include <Databases/IDatabase.h>\n+#include <Databases/DatabaseReplicated.h>\n+#include <Databases/DatabaseFactory.h>\n \n \n namespace DB\n@@ -25,6 +28,7 @@ namespace ErrorCodes\n {\n     extern const int LOGICAL_ERROR;\n     extern const int INCORRECT_QUERY;\n+    extern const int NOT_IMPLEMENTED;\n }\n \n \n@@ -38,11 +42,21 @@ BlockIO InterpreterAlterQuery::execute()\n     BlockIO res;\n     const auto & alter = query_ptr->as<ASTAlterQuery &>();\n \n+\n     if (!alter.cluster.empty())\n         return executeDDLQueryOnCluster(query_ptr, context, getRequiredAccess());\n \n     context.checkAccess(getRequiredAccess());\n     auto table_id = context.resolveStorageID(alter, Context::ResolveOrdinary);\n+\n+    DatabasePtr database = DatabaseCatalog::instance().getDatabase(table_id.database_name);\n+    if (typeid_cast<DatabaseReplicated *>(database.get()) && context.getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY)\n+    {\n+        auto guard = DatabaseCatalog::instance().getDDLGuard(table_id.database_name, table_id.table_name);\n+        guard->releaseTableLock();\n+        return typeid_cast<DatabaseReplicated *>(database.get())->tryEnqueueReplicatedDDL(query_ptr, context);\n+    }\n+\n     StoragePtr table = DatabaseCatalog::instance().getTable(table_id, context);\n     auto alter_lock = table->lockForAlter(context.getCurrentQueryId(), context.getSettingsRef().lock_acquire_timeout);\n     auto metadata_snapshot = table->getInMemoryMetadataPtr();\n@@ -80,6 +94,14 @@ BlockIO InterpreterAlterQuery::execute()\n             throw Exception(\"Wrong parameter type in ALTER query\", ErrorCodes::LOGICAL_ERROR);\n     }\n \n+    if (typeid_cast<DatabaseReplicated *>(database.get()))\n+    {\n+        int command_types_count = !mutation_commands.empty() + !partition_commands.empty() + !live_view_commands.empty() + !alter_commands.empty();\n+        if (1 < command_types_count)\n+            throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"For Replicated databases it's not allowed \"\n+                                                         \"to execute ALTERs of different types in single query\");\n+    }\n+\n     if (!mutation_commands.empty())\n     {\n         MutationsInterpreter(table, metadata_snapshot, mutation_commands, context, false).validate();\ndiff --git a/src/Interpreters/InterpreterCreateQuery.cpp b/src/Interpreters/InterpreterCreateQuery.cpp\nindex e9a11b9eb0df..2b1dddde78cf 100644\n--- a/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -30,7 +30,8 @@\n #include <Storages/StorageInMemoryMetadata.h>\n \n #include <Interpreters/Context.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n+#include <Interpreters/Cluster.h>\n #include <Interpreters/ExpressionAnalyzer.h>\n #include <Interpreters/InterpreterCreateQuery.h>\n #include <Interpreters/InterpreterSelectWithUnionQuery.h>\n@@ -46,6 +47,7 @@\n #include <DataTypes/DataTypeNullable.h>\n \n #include <Databases/DatabaseFactory.h>\n+#include <Databases/DatabaseReplicated.h>\n #include <Databases/IDatabase.h>\n #include <Databases/DatabaseOnDisk.h>\n \n@@ -79,6 +81,7 @@ namespace ErrorCodes\n     extern const int ILLEGAL_SYNTAX_FOR_DATA_TYPE;\n     extern const int ILLEGAL_COLUMN;\n     extern const int LOGICAL_ERROR;\n+    extern const int UNKNOWN_DATABASE;\n     extern const int PATH_ACCESS_DENIED;\n     extern const int NOT_IMPLEMENTED;\n     extern const int UNKNOWN_TABLE;\n@@ -146,7 +149,7 @@ BlockIO InterpreterCreateQuery::createDatabase(ASTCreateQuery & create)\n         throw Exception(ErrorCodes::UNKNOWN_DATABASE_ENGINE, \"Unknown database engine: {}\", serializeAST(*create.storage));\n     }\n \n-    if (create.storage->engine->name == \"Atomic\")\n+    if (create.storage->engine->name == \"Atomic\" || create.storage->engine->name == \"Replicated\")\n     {\n         if (create.attach && create.uuid == UUIDHelpers::Nil)\n             throw Exception(ErrorCodes::INCORRECT_QUERY, \"UUID must be specified for ATTACH. \"\n@@ -205,6 +208,12 @@ BlockIO InterpreterCreateQuery::createDatabase(ASTCreateQuery & create)\n                         \"Enable allow_experimental_database_materialize_mysql to use it.\", ErrorCodes::UNKNOWN_DATABASE_ENGINE);\n     }\n \n+    if (create.storage->engine->name == \"Replicated\" && !context.getSettingsRef().allow_experimental_database_replicated && !internal)\n+    {\n+        throw Exception(\"Replicated is an experimental database engine. \"\n+                        \"Enable allow_experimental_database_replicated to use it.\", ErrorCodes::UNKNOWN_DATABASE_ENGINE);\n+    }\n+\n     DatabasePtr database = DatabaseFactory::get(create, metadata_path / \"\", context);\n \n     if (create.uuid != UUIDHelpers::Nil)\n@@ -556,6 +565,11 @@ InterpreterCreateQuery::TableProperties InterpreterCreateQuery::setProperties(AS\n     validateTableStructure(create, properties);\n     /// Set the table engine if it was not specified explicitly.\n     setEngine(create);\n+\n+    assert(as_database_saved.empty() && as_table_saved.empty());\n+    std::swap(create.as_database, as_database_saved);\n+    std::swap(create.as_table, as_table_saved);\n+\n     return properties;\n }\n \n@@ -702,6 +716,12 @@ void InterpreterCreateQuery::assertOrSetUUID(ASTCreateQuery & create, const Data\n     const auto * kind = create.is_dictionary ? \"Dictionary\" : \"Table\";\n     const auto * kind_upper = create.is_dictionary ? \"DICTIONARY\" : \"TABLE\";\n \n+    if (database->getEngineName() == \"Replicated\" && context.getClientInfo().query_kind == ClientInfo::QueryKind::SECONDARY_QUERY && !internal)\n+    {\n+        if (create.uuid == UUIDHelpers::Nil)\n+            throw Exception(\"Table UUID is not specified in DDL log\", ErrorCodes::LOGICAL_ERROR);\n+    }\n+\n     bool from_path = create.attach_from_path.has_value();\n \n     if (database->getUUID() != UUIDHelpers::Nil)\n@@ -776,11 +796,11 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)\n             ErrorCodes::BAD_DATABASE_FOR_TEMPORARY_TABLE);\n \n     String current_database = context.getCurrentDatabase();\n+    auto database_name = create.database.empty() ? current_database : create.database;\n \n     // If this is a stub ATTACH query, read the query definition from the database\n     if (create.attach && !create.storage && !create.columns_list)\n     {\n-        auto database_name = create.database.empty() ? current_database : create.database;\n         auto database = DatabaseCatalog::instance().getDatabase(database_name);\n         bool if_not_exists = create.if_not_exists;\n \n@@ -800,19 +820,30 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)\n \n     if (create.attach_from_path)\n     {\n-        fs::path data_path = fs::path(*create.attach_from_path).lexically_normal();\n         fs::path user_files = fs::path(context.getUserFilesPath()).lexically_normal();\n-        if (data_path.is_relative())\n-            data_path = (user_files / data_path).lexically_normal();\n-        if (!startsWith(data_path, user_files))\n-            throw Exception(ErrorCodes::PATH_ACCESS_DENIED,\n-                            \"Data directory {} must be inside {} to attach it\", String(data_path), String(user_files));\n-\n         fs::path root_path = fs::path(context.getPath()).lexically_normal();\n-        /// Data path must be relative to root_path\n-        create.attach_from_path = fs::relative(data_path, root_path) / \"\";\n+\n+        if (context.getClientInfo().query_kind == ClientInfo::QueryKind::INITIAL_QUERY)\n+        {\n+            fs::path data_path = fs::path(*create.attach_from_path).lexically_normal();\n+            if (data_path.is_relative())\n+                data_path = (user_files / data_path).lexically_normal();\n+            if (!startsWith(data_path, user_files))\n+                throw Exception(ErrorCodes::PATH_ACCESS_DENIED,\n+                                \"Data directory {} must be inside {} to attach it\", String(data_path), String(user_files));\n+\n+            /// Data path must be relative to root_path\n+            create.attach_from_path = fs::relative(data_path, root_path) / \"\";\n+        }\n+        else\n+        {\n+            fs::path data_path = (root_path / *create.attach_from_path).lexically_normal();\n+            if (!startsWith(data_path, user_files))\n+                throw Exception(ErrorCodes::PATH_ACCESS_DENIED,\n+                                \"Data directory {} must be inside {} to attach it\", String(data_path), String(user_files));\n+        }\n     }\n-    else if (create.attach && !create.attach_short_syntax)\n+    else if (create.attach && !create.attach_short_syntax && context.getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY)\n     {\n         auto * log = &Poco::Logger::get(\"InterpreterCreateQuery\");\n         LOG_WARNING(log, \"ATTACH TABLE query with full table definition is not recommended: \"\n@@ -836,11 +867,29 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)\n     /// Set and retrieve list of columns, indices and constraints. Set table engine if needed. Rewrite query in canonical way.\n     TableProperties properties = setProperties(create);\n \n+    DatabasePtr database;\n+    bool need_add_to_database = !create.temporary;\n+    if (need_add_to_database)\n+        database = DatabaseCatalog::instance().getDatabase(database_name);\n+\n+    if (need_add_to_database && database->getEngineName() == \"Replicated\")\n+    {\n+        auto guard = DatabaseCatalog::instance().getDDLGuard(create.database, create.table);\n+        database = DatabaseCatalog::instance().getDatabase(create.database);\n+        if (typeid_cast<DatabaseReplicated *>(database.get()) && context.getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY)\n+        {\n+            assertOrSetUUID(create, database);\n+            guard->releaseTableLock();\n+            return typeid_cast<DatabaseReplicated *>(database.get())->tryEnqueueReplicatedDDL(query_ptr, context);\n+        }\n+    }\n+\n     if (create.replace_table)\n         return doCreateOrReplaceTable(create, properties);\n \n     /// Actually creates table\n     bool created = doCreateTable(create, properties);\n+\n     if (!created)   /// Table already exists\n         return {};\n \n@@ -880,7 +929,8 @@ bool InterpreterCreateQuery::doCreateTable(ASTCreateQuery & create,\n                 drop_ast->table = create.table;\n                 drop_ast->no_ddl_lock = true;\n \n-                InterpreterDropQuery interpreter(drop_ast, context);\n+                Context drop_context = context;\n+                InterpreterDropQuery interpreter(drop_ast, drop_context);\n                 interpreter.execute();\n             }\n             else\n@@ -1037,6 +1087,14 @@ BlockIO InterpreterCreateQuery::createDictionary(ASTCreateQuery & create)\n     auto guard = DatabaseCatalog::instance().getDDLGuard(database_name, dictionary_name);\n     DatabasePtr database = DatabaseCatalog::instance().getDatabase(database_name);\n \n+    if (typeid_cast<DatabaseReplicated *>(database.get()) && context.getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY)\n+    {\n+        if (!create.attach)\n+            assertOrSetUUID(create, database);\n+        guard->releaseTableLock();\n+        return typeid_cast<DatabaseReplicated *>(database.get())->tryEnqueueReplicatedDDL(query_ptr, context);\n+    }\n+\n     if (database->isDictionaryExist(dictionary_name))\n     {\n         /// TODO Check structure of dictionary\n@@ -1189,15 +1247,14 @@ AccessRightsElements InterpreterCreateQuery::getRequiredAccess() const\n     return required_access;\n }\n \n-void InterpreterCreateQuery::extendQueryLogElemImpl(QueryLogElement & elem, const ASTPtr & ast, const Context &) const\n+void InterpreterCreateQuery::extendQueryLogElemImpl(QueryLogElement & elem, const ASTPtr &, const Context &) const\n {\n-    const auto & create = ast->as<const ASTCreateQuery &>();\n     elem.query_kind = \"Create\";\n-    if (!create.as_table.empty())\n+    if (!as_table_saved.empty())\n     {\n-        String database = backQuoteIfNeed(create.as_database.empty() ? context.getCurrentDatabase() : create.as_database);\n+        String database = backQuoteIfNeed(as_database_saved.empty() ? context.getCurrentDatabase() : as_database_saved);\n         elem.query_databases.insert(database);\n-        elem.query_tables.insert(database + \".\" + backQuoteIfNeed(create.as_table));\n+        elem.query_tables.insert(database + \".\" + backQuoteIfNeed(as_table_saved));\n     }\n }\n \ndiff --git a/src/Interpreters/InterpreterCreateQuery.h b/src/Interpreters/InterpreterCreateQuery.h\nindex c109b0b7760f..d88357fe4123 100644\n--- a/src/Interpreters/InterpreterCreateQuery.h\n+++ b/src/Interpreters/InterpreterCreateQuery.h\n@@ -95,5 +95,8 @@ class InterpreterCreateQuery : public IInterpreter\n     /// Is this an internal query - not from the user.\n     bool internal = false;\n     bool force_attach = false;\n+\n+    mutable String as_database_saved;\n+    mutable String as_table_saved;\n };\n }\ndiff --git a/src/Interpreters/InterpreterCreateQuotaQuery.cpp b/src/Interpreters/InterpreterCreateQuotaQuery.cpp\nindex f45c2c9709d1..ff30a2fff479 100644\n--- a/src/Interpreters/InterpreterCreateQuotaQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateQuotaQuery.cpp\n@@ -2,7 +2,7 @@\n #include <Parsers/ASTCreateQuotaQuery.h>\n #include <Parsers/ASTRolesOrUsersSet.h>\n #include <Interpreters/Context.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Access/AccessControlManager.h>\n #include <Access/AccessFlags.h>\n #include <ext/range.h>\ndiff --git a/src/Interpreters/InterpreterCreateRoleQuery.cpp b/src/Interpreters/InterpreterCreateRoleQuery.cpp\nindex 2fa04eebae1b..72ad3234b956 100644\n--- a/src/Interpreters/InterpreterCreateRoleQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateRoleQuery.cpp\n@@ -1,7 +1,7 @@\n #include <Interpreters/InterpreterCreateRoleQuery.h>\n #include <Parsers/ASTCreateRoleQuery.h>\n #include <Interpreters/Context.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Access/AccessControlManager.h>\n #include <Access/Role.h>\n \ndiff --git a/src/Interpreters/InterpreterCreateRowPolicyQuery.cpp b/src/Interpreters/InterpreterCreateRowPolicyQuery.cpp\nindex 9dacc9d1bf42..8f1c5b061e08 100644\n--- a/src/Interpreters/InterpreterCreateRowPolicyQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateRowPolicyQuery.cpp\n@@ -4,7 +4,7 @@\n #include <Parsers/ASTRolesOrUsersSet.h>\n #include <Parsers/formatAST.h>\n #include <Interpreters/Context.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Access/AccessControlManager.h>\n #include <Access/AccessFlags.h>\n #include <boost/range/algorithm/sort.hpp>\ndiff --git a/src/Interpreters/InterpreterCreateSettingsProfileQuery.cpp b/src/Interpreters/InterpreterCreateSettingsProfileQuery.cpp\nindex 2d5f4d499b7f..b65225db16c6 100644\n--- a/src/Interpreters/InterpreterCreateSettingsProfileQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateSettingsProfileQuery.cpp\n@@ -2,7 +2,7 @@\n #include <Parsers/ASTCreateSettingsProfileQuery.h>\n #include <Parsers/ASTRolesOrUsersSet.h>\n #include <Interpreters/Context.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Access/AccessControlManager.h>\n #include <Access/SettingsProfile.h>\n #include <Access/AccessFlags.h>\ndiff --git a/src/Interpreters/InterpreterCreateUserQuery.cpp b/src/Interpreters/InterpreterCreateUserQuery.cpp\nindex 111f698beb9d..c9b087de5b4e 100644\n--- a/src/Interpreters/InterpreterCreateUserQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateUserQuery.cpp\n@@ -1,7 +1,7 @@\n #include <Interpreters/InterpreterCreateUserQuery.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/InterpreterSetRoleQuery.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Parsers/ASTCreateUserQuery.h>\n #include <Parsers/ASTUserNameWithHost.h>\n #include <Parsers/ASTRolesOrUsersSet.h>\ndiff --git a/src/Interpreters/InterpreterDropAccessEntityQuery.cpp b/src/Interpreters/InterpreterDropAccessEntityQuery.cpp\nindex d79d239ee12f..e86f8361100f 100644\n--- a/src/Interpreters/InterpreterDropAccessEntityQuery.cpp\n+++ b/src/Interpreters/InterpreterDropAccessEntityQuery.cpp\n@@ -2,7 +2,7 @@\n #include <Parsers/ASTDropAccessEntityQuery.h>\n #include <Parsers/ASTRowPolicyName.h>\n #include <Interpreters/Context.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Access/AccessControlManager.h>\n #include <Access/AccessFlags.h>\n #include <Access/User.h>\ndiff --git a/src/Interpreters/InterpreterDropQuery.cpp b/src/Interpreters/InterpreterDropQuery.cpp\nindex be4908582a5d..33e93a79c418 100644\n--- a/src/Interpreters/InterpreterDropQuery.cpp\n+++ b/src/Interpreters/InterpreterDropQuery.cpp\n@@ -2,7 +2,7 @@\n \n #include <Databases/IDatabase.h>\n #include <Interpreters/Context.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Interpreters/InterpreterDropQuery.h>\n #include <Interpreters/ExternalDictionariesLoader.h>\n #include <Interpreters/QueryLog.h>\n@@ -12,6 +12,7 @@\n #include <Common/escapeForFileName.h>\n #include <Common/quoteString.h>\n #include <Common/typeid_cast.h>\n+#include <Databases/DatabaseReplicated.h>\n \n #if !defined(ARCADIA_BUILD)\n #    include \"config_core.h\"\n@@ -32,6 +33,7 @@ namespace ErrorCodes\n     extern const int UNKNOWN_TABLE;\n     extern const int UNKNOWN_DICTIONARY;\n     extern const int NOT_IMPLEMENTED;\n+    extern const int INCORRECT_QUERY;\n }\n \n \n@@ -118,32 +120,55 @@ BlockIO InterpreterDropQuery::executeToTableImpl(const ASTDropQuery & query, Dat\n \n     if (database && table)\n     {\n-        if (query_ptr->as<ASTDropQuery &>().is_view && !table->isView())\n+        if (query.as<ASTDropQuery &>().is_view && !table->isView())\n             throw Exception(\"Table \" + table_id.getNameForLogs() + \" is not a View\", ErrorCodes::LOGICAL_ERROR);\n \n         /// Now get UUID, so we can wait for table data to be finally dropped\n         table_id.uuid = database->tryGetTableUUID(table_id.table_name);\n \n+        /// Prevents recursive drop from drop database query. The original query must specify a table.\n+        bool is_drop_or_detach_database = query_ptr->as<ASTDropQuery>()->table.empty();\n+        bool is_replicated_ddl_query = typeid_cast<DatabaseReplicated *>(database.get()) &&\n+                                       context.getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY &&\n+                                       !is_drop_or_detach_database;\n+        if (is_replicated_ddl_query)\n+        {\n+            if (query.kind == ASTDropQuery::Kind::Detach && !query.permanently)\n+                throw Exception(ErrorCodes::INCORRECT_QUERY, \"DETACH TABLE is not allowed for Replicated databases. \"\n+                                                             \"Use DETACH TABLE PERMANENTLY or SYSTEM RESTART REPLICA\");\n+\n+            if (query.kind == ASTDropQuery::Kind::Detach)\n+                context.checkAccess(table->isView() ? AccessType::DROP_VIEW : AccessType::DROP_TABLE, table_id);\n+            else if (query.kind == ASTDropQuery::Kind::Truncate)\n+                context.checkAccess(AccessType::TRUNCATE, table_id);\n+            else if (query.kind == ASTDropQuery::Kind::Drop)\n+                context.checkAccess(table->isView() ? AccessType::DROP_VIEW : AccessType::DROP_TABLE, table_id);\n+\n+            ddl_guard->releaseTableLock();\n+            table.reset();\n+            return typeid_cast<DatabaseReplicated *>(database.get())->tryEnqueueReplicatedDDL(query.clone(), context);\n+        }\n+\n         if (query.kind == ASTDropQuery::Kind::Detach)\n         {\n             context.checkAccess(table->isView() ? AccessType::DROP_VIEW : AccessType::DROP_TABLE, table_id);\n             table->checkTableCanBeDetached();\n             table->shutdown();\n             TableExclusiveLockHolder table_lock;\n+\n             if (database->getUUID() == UUIDHelpers::Nil)\n                 table_lock = table->lockExclusively(context.getCurrentQueryId(), context.getSettingsRef().lock_acquire_timeout);\n \n             if (query.permanently)\n             {\n                 /// Drop table from memory, don't touch data, metadata file renamed and will be skipped during server restart\n-                database->detachTablePermanently(table_id.table_name);\n+                database->detachTablePermanently(context, table_id.table_name);\n             }\n             else\n             {\n                 /// Drop table from memory, don't touch data and metadata\n                 database->detachTable(table_id.table_name);\n             }\n-\n         }\n         else if (query.kind == ASTDropQuery::Kind::Truncate)\n         {\n@@ -194,6 +219,21 @@ BlockIO InterpreterDropQuery::executeToDictionary(\n \n     DatabasePtr database = tryGetDatabase(database_name, if_exists);\n \n+    bool is_drop_or_detach_database = query_ptr->as<ASTDropQuery>()->table.empty();\n+    bool is_replicated_ddl_query = typeid_cast<DatabaseReplicated *>(database.get()) &&\n+                                   context.getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY &&\n+                                   !is_drop_or_detach_database;\n+    if (is_replicated_ddl_query)\n+    {\n+        if (kind == ASTDropQuery::Kind::Detach)\n+            throw Exception(ErrorCodes::INCORRECT_QUERY, \"DETACH DICTIONARY is not allowed for Replicated databases.\");\n+\n+        context.checkAccess(AccessType::DROP_DICTIONARY, database_name, dictionary_name);\n+\n+        ddl_guard->releaseTableLock();\n+        return typeid_cast<DatabaseReplicated *>(database.get())->tryEnqueueReplicatedDDL(query_ptr, context);\n+    }\n+\n     if (!database || !database->isDictionaryExist(dictionary_name))\n     {\n         if (!if_exists)\n@@ -307,6 +347,8 @@ BlockIO InterpreterDropQuery::executeToDatabaseImpl(const ASTDropQuery & query,\n             if (database->getEngineName() == \"MaterializeMySQL\")\n                 stopDatabaseSynchronization(database);\n #endif\n+            if (auto * replicated = typeid_cast<DatabaseReplicated *>(database.get()))\n+                replicated->stopReplication();\n \n             if (database->shouldBeEmptyOnDetach())\n             {\ndiff --git a/src/Interpreters/InterpreterGrantQuery.cpp b/src/Interpreters/InterpreterGrantQuery.cpp\nindex 6f45687a4e1f..dafe4d2e18c8 100644\n--- a/src/Interpreters/InterpreterGrantQuery.cpp\n+++ b/src/Interpreters/InterpreterGrantQuery.cpp\n@@ -2,7 +2,7 @@\n #include <Parsers/ASTGrantQuery.h>\n #include <Parsers/ASTRolesOrUsersSet.h>\n #include <Interpreters/Context.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Access/AccessControlManager.h>\n #include <Access/ContextAccess.h>\n #include <Access/RolesOrUsersSet.h>\ndiff --git a/src/Interpreters/InterpreterKillQueryQuery.cpp b/src/Interpreters/InterpreterKillQueryQuery.cpp\nindex 0f7da8f1f587..c50659c6c45d 100644\n--- a/src/Interpreters/InterpreterKillQueryQuery.cpp\n+++ b/src/Interpreters/InterpreterKillQueryQuery.cpp\n@@ -2,7 +2,7 @@\n #include <Parsers/ASTKillQueryQuery.h>\n #include <Parsers/queryToString.h>\n #include <Interpreters/Context.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Interpreters/ProcessList.h>\n #include <Interpreters/executeQuery.h>\n #include <Interpreters/CancellationCode.h>\ndiff --git a/src/Interpreters/InterpreterOptimizeQuery.cpp b/src/Interpreters/InterpreterOptimizeQuery.cpp\nindex cda8471c32ef..d8e9013e3972 100644\n--- a/src/Interpreters/InterpreterOptimizeQuery.cpp\n+++ b/src/Interpreters/InterpreterOptimizeQuery.cpp\n@@ -1,7 +1,7 @@\n #include <Storages/IStorage.h>\n #include <Parsers/ASTOptimizeQuery.h>\n #include <Interpreters/Context.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Interpreters/InterpreterOptimizeQuery.h>\n #include <Access/AccessRightsElement.h>\n #include <Common/typeid_cast.h>\ndiff --git a/src/Interpreters/InterpreterRenameQuery.cpp b/src/Interpreters/InterpreterRenameQuery.cpp\nindex f3b01a6a42c4..923a342d9ea2 100644\n--- a/src/Interpreters/InterpreterRenameQuery.cpp\n+++ b/src/Interpreters/InterpreterRenameQuery.cpp\n@@ -3,14 +3,20 @@\n #include <Interpreters/Context.h>\n #include <Interpreters/InterpreterRenameQuery.h>\n #include <Storages/IStorage.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Interpreters/QueryLog.h>\n #include <Access/AccessRightsElement.h>\n+#include <Common/typeid_cast.h>\n+#include <Databases/DatabaseReplicated.h>\n \n \n namespace DB\n {\n \n+namespace ErrorCodes\n+{\n+    extern const int NOT_IMPLEMENTED;\n+}\n \n InterpreterRenameQuery::InterpreterRenameQuery(const ASTPtr & query_ptr_, Context & context_)\n     : query_ptr(query_ptr_), context(context_)\n@@ -61,10 +67,10 @@ BlockIO InterpreterRenameQuery::execute()\n     if (rename.database)\n         return executeToDatabase(rename, descriptions);\n     else\n-        return executeToTables(rename, descriptions);\n+        return executeToTables(rename, descriptions, table_guards);\n }\n \n-BlockIO InterpreterRenameQuery::executeToTables(const ASTRenameQuery & rename, const RenameDescriptions & descriptions)\n+BlockIO InterpreterRenameQuery::executeToTables(const ASTRenameQuery & rename, const RenameDescriptions & descriptions, TableGuards & ddl_guards)\n {\n     auto & database_catalog = DatabaseCatalog::instance();\n \n@@ -73,13 +79,29 @@ BlockIO InterpreterRenameQuery::executeToTables(const ASTRenameQuery & rename, c\n         if (!rename.exchange)\n             database_catalog.assertTableDoesntExist(StorageID(elem.to_database_name, elem.to_table_name), context);\n \n-        database_catalog.getDatabase(elem.from_database_name)->renameTable(\n+        DatabasePtr database = database_catalog.getDatabase(elem.from_database_name);\n+        if (typeid_cast<DatabaseReplicated *>(database.get()) && context.getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY)\n+        {\n+            if (1 < descriptions.size())\n+                throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Database {} is Replicated, \"\n+                                \"it does not support renaming of multiple tables in single query.\", elem.from_database_name);\n+\n+            UniqueTableName from(elem.from_database_name, elem.from_table_name);\n+            UniqueTableName to(elem.to_database_name, elem.to_table_name);\n+            ddl_guards[from]->releaseTableLock();\n+            ddl_guards[to]->releaseTableLock();\n+            return typeid_cast<DatabaseReplicated *>(database.get())->tryEnqueueReplicatedDDL(query_ptr, context);\n+        }\n+        else\n+        {\n+            database->renameTable(\n                 context,\n                 elem.from_table_name,\n                 *database_catalog.getDatabase(elem.to_database_name),\n                 elem.to_table_name,\n                 rename.exchange,\n                 rename.dictionary);\n+        }\n     }\n \n     return {};\ndiff --git a/src/Interpreters/InterpreterRenameQuery.h b/src/Interpreters/InterpreterRenameQuery.h\nindex 055c15181c1a..0da25f63e8dc 100644\n--- a/src/Interpreters/InterpreterRenameQuery.h\n+++ b/src/Interpreters/InterpreterRenameQuery.h\n@@ -57,7 +57,7 @@ class InterpreterRenameQuery : public IInterpreter\n     void extendQueryLogElemImpl(QueryLogElement & elem, const ASTPtr & ast, const Context &) const override;\n \n private:\n-    BlockIO executeToTables(const ASTRenameQuery & rename, const RenameDescriptions & descriptions);\n+    BlockIO executeToTables(const ASTRenameQuery & rename, const RenameDescriptions & descriptions, TableGuards & ddl_guards);\n     static BlockIO executeToDatabase(const ASTRenameQuery & rename, const RenameDescriptions & descriptions);\n \n     AccessRightsElements getRequiredAccess() const;\ndiff --git a/src/Interpreters/InterpreterSystemQuery.cpp b/src/Interpreters/InterpreterSystemQuery.cpp\nindex 0e9683de95f1..ece3209621b8 100644\n--- a/src/Interpreters/InterpreterSystemQuery.cpp\n+++ b/src/Interpreters/InterpreterSystemQuery.cpp\n@@ -16,7 +16,7 @@\n #include <Interpreters/InterpreterCreateQuery.h>\n #include <Interpreters/InterpreterRenameQuery.h>\n #include <Interpreters/QueryLog.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n #include <Interpreters/PartLog.h>\n #include <Interpreters/QueryThreadLog.h>\n #include <Interpreters/TraceLog.h>\ndiff --git a/src/Interpreters/SystemLog.h b/src/Interpreters/SystemLog.h\nindex 84a2c075355a..aa3dc113e444 100644\n--- a/src/Interpreters/SystemLog.h\n+++ b/src/Interpreters/SystemLog.h\n@@ -515,7 +515,9 @@ void SystemLog<LogElement>::prepareTable()\n \n             LOG_DEBUG(log, \"Existing table {} for system log has obsolete or different structure. Renaming it to {}\", description, backQuoteIfNeed(to.table));\n \n-            InterpreterRenameQuery(rename, context).execute();\n+            Context query_context = context;\n+            query_context.makeQueryContext();\n+            InterpreterRenameQuery(rename, query_context).execute();\n \n             /// The required table will be created.\n             table = nullptr;\n@@ -531,7 +533,10 @@ void SystemLog<LogElement>::prepareTable()\n \n         auto create = getCreateTableQuery();\n \n-        InterpreterCreateQuery interpreter(create, context);\n+\n+        Context query_context = context;\n+        query_context.makeQueryContext();\n+        InterpreterCreateQuery interpreter(create, query_context);\n         interpreter.setInternal(true);\n         interpreter.execute();\n \ndiff --git a/src/Interpreters/executeDDLQueryOnCluster.cpp b/src/Interpreters/executeDDLQueryOnCluster.cpp\nnew file mode 100644\nindex 000000000000..1937fbaf9054\n--- /dev/null\n+++ b/src/Interpreters/executeDDLQueryOnCluster.cpp\n@@ -0,0 +1,337 @@\n+#include <Interpreters/executeDDLQueryOnCluster.h>\n+#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/DDLTask.h>\n+#include <Interpreters/AddDefaultDatabaseVisitor.h>\n+#include <Interpreters/Context.h>\n+#include <Parsers/ASTQueryWithOutput.h>\n+#include <Parsers/ASTQueryWithOnCluster.h>\n+#include <Parsers/ASTAlterQuery.h>\n+#include <Parsers/queryToString.h>\n+#include <Access/AccessRightsElement.h>\n+#include <Access/ContextAccess.h>\n+#include <Common/Macros.h>\n+#include <Common/ZooKeeper/ZooKeeper.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeString.h>\n+#include <filesystem>\n+\n+namespace fs = std::filesystem;\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int NOT_IMPLEMENTED;\n+    extern const int TIMEOUT_EXCEEDED;\n+    extern const int UNFINISHED;\n+    extern const int QUERY_IS_PROHIBITED;\n+    extern const int LOGICAL_ERROR;\n+}\n+\n+bool isSupportedAlterType(int type)\n+{\n+    assert(type != ASTAlterCommand::NO_TYPE);\n+    static const std::unordered_set<int> unsupported_alter_types{\n+        /// It's dangerous, because it may duplicate data if executed on multiple replicas. We can allow it after #18978\n+        ASTAlterCommand::ATTACH_PARTITION,\n+        /// Usually followed by ATTACH PARTITION\n+        ASTAlterCommand::FETCH_PARTITION,\n+        /// Logical error\n+        ASTAlterCommand::NO_TYPE,\n+    };\n+\n+    return unsupported_alter_types.count(type) == 0;\n+}\n+\n+\n+BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr_, const Context & context)\n+{\n+    return executeDDLQueryOnCluster(query_ptr_, context, {});\n+}\n+\n+BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr, const Context & context, const AccessRightsElements & query_requires_access, bool query_requires_grant_option)\n+{\n+    return executeDDLQueryOnCluster(query_ptr, context, AccessRightsElements{query_requires_access}, query_requires_grant_option);\n+}\n+\n+BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr_, const Context & context, AccessRightsElements && query_requires_access, bool query_requires_grant_option)\n+{\n+    /// Remove FORMAT <fmt> and INTO OUTFILE <file> if exists\n+    ASTPtr query_ptr = query_ptr_->clone();\n+    ASTQueryWithOutput::resetOutputASTIfExist(*query_ptr);\n+\n+    // XXX: serious design flaw since `ASTQueryWithOnCluster` is not inherited from `IAST`!\n+    auto * query = dynamic_cast<ASTQueryWithOnCluster *>(query_ptr.get());\n+    if (!query)\n+    {\n+        throw Exception(\"Distributed execution is not supported for such DDL queries\", ErrorCodes::NOT_IMPLEMENTED);\n+    }\n+\n+    if (!context.getSettingsRef().allow_distributed_ddl)\n+        throw Exception(\"Distributed DDL queries are prohibited for the user\", ErrorCodes::QUERY_IS_PROHIBITED);\n+\n+    if (const auto * query_alter = query_ptr->as<ASTAlterQuery>())\n+    {\n+        for (const auto & command : query_alter->command_list->children)\n+        {\n+            if (!isSupportedAlterType(command->as<ASTAlterCommand&>().type))\n+                throw Exception(\"Unsupported type of ALTER query\", ErrorCodes::NOT_IMPLEMENTED);\n+        }\n+    }\n+\n+    query->cluster = context.getMacros()->expand(query->cluster);\n+    ClusterPtr cluster = context.getCluster(query->cluster);\n+    DDLWorker & ddl_worker = context.getDDLWorker();\n+\n+    /// Enumerate hosts which will be used to send query.\n+    Cluster::AddressesWithFailover shards = cluster->getShardsAddresses();\n+    std::vector<HostID> hosts;\n+    for (const auto & shard : shards)\n+    {\n+        for (const auto & addr : shard)\n+            hosts.emplace_back(addr);\n+    }\n+\n+    if (hosts.empty())\n+        throw Exception(\"No hosts defined to execute distributed DDL query\", ErrorCodes::LOGICAL_ERROR);\n+\n+    /// The current database in a distributed query need to be replaced with either\n+    /// the local current database or a shard's default database.\n+    bool need_replace_current_database\n+        = (std::find_if(\n+            query_requires_access.begin(),\n+            query_requires_access.end(),\n+            [](const AccessRightsElement & elem) { return elem.isEmptyDatabase(); })\n+           != query_requires_access.end());\n+\n+    bool use_local_default_database = false;\n+    const String & current_database = context.getCurrentDatabase();\n+\n+    if (need_replace_current_database)\n+    {\n+        Strings shard_default_databases;\n+        for (const auto & shard : shards)\n+        {\n+            for (const auto & addr : shard)\n+            {\n+                if (!addr.default_database.empty())\n+                    shard_default_databases.push_back(addr.default_database);\n+                else\n+                    use_local_default_database = true;\n+            }\n+        }\n+        std::sort(shard_default_databases.begin(), shard_default_databases.end());\n+        shard_default_databases.erase(std::unique(shard_default_databases.begin(), shard_default_databases.end()), shard_default_databases.end());\n+        assert(use_local_default_database || !shard_default_databases.empty());\n+\n+        if (use_local_default_database && !shard_default_databases.empty())\n+            throw Exception(\"Mixed local default DB and shard default DB in DDL query\", ErrorCodes::NOT_IMPLEMENTED);\n+\n+        if (use_local_default_database)\n+        {\n+            query_requires_access.replaceEmptyDatabase(current_database);\n+        }\n+        else\n+        {\n+            for (size_t i = 0; i != query_requires_access.size();)\n+            {\n+                auto & element = query_requires_access[i];\n+                if (element.isEmptyDatabase())\n+                {\n+                    query_requires_access.insert(query_requires_access.begin() + i + 1, shard_default_databases.size() - 1, element);\n+                    for (size_t j = 0; j != shard_default_databases.size(); ++j)\n+                        query_requires_access[i + j].replaceEmptyDatabase(shard_default_databases[j]);\n+                    i += shard_default_databases.size();\n+                }\n+                else\n+                    ++i;\n+            }\n+        }\n+    }\n+\n+    AddDefaultDatabaseVisitor visitor(current_database, !use_local_default_database);\n+    visitor.visitDDL(query_ptr);\n+\n+    /// Check access rights, assume that all servers have the same users config\n+    if (query_requires_grant_option)\n+        context.getAccess()->checkGrantOption(query_requires_access);\n+    else\n+        context.checkAccess(query_requires_access);\n+\n+    DDLLogEntry entry;\n+    entry.hosts = std::move(hosts);\n+    entry.query = queryToString(query_ptr);\n+    entry.initiator = ddl_worker.getCommonHostID();\n+    String node_path = ddl_worker.enqueueQuery(entry);\n+\n+    BlockIO io;\n+    if (context.getSettingsRef().distributed_ddl_task_timeout == 0)\n+        return io;\n+\n+    auto stream = std::make_shared<DDLQueryStatusInputStream>(node_path, entry, context);\n+    io.in = std::move(stream);\n+    return io;\n+}\n+\n+\n+DDLQueryStatusInputStream::DDLQueryStatusInputStream(const String & zk_node_path, const DDLLogEntry & entry, const Context & context_,\n+                                                     const std::optional<Strings> & hosts_to_wait)\n+    : node_path(zk_node_path)\n+    , context(context_)\n+    , watch(CLOCK_MONOTONIC_COARSE)\n+    , log(&Poco::Logger::get(\"DDLQueryStatusInputStream\"))\n+{\n+    sample = Block{\n+        {std::make_shared<DataTypeString>(),    \"host\"},\n+        {std::make_shared<DataTypeUInt16>(),    \"port\"},\n+        {std::make_shared<DataTypeInt64>(),     \"status\"},\n+        {std::make_shared<DataTypeString>(),    \"error\"},\n+        {std::make_shared<DataTypeUInt64>(),    \"num_hosts_remaining\"},\n+        {std::make_shared<DataTypeUInt64>(),    \"num_hosts_active\"},\n+    };\n+\n+    if (hosts_to_wait)\n+    {\n+        waiting_hosts = NameSet(hosts_to_wait->begin(), hosts_to_wait->end());\n+        by_hostname = false;\n+    }\n+    else\n+    {\n+        for (const HostID & host : entry.hosts)\n+            waiting_hosts.emplace(host.toString());\n+    }\n+\n+    addTotalRowsApprox(waiting_hosts.size());\n+\n+    timeout_seconds = context.getSettingsRef().distributed_ddl_task_timeout;\n+}\n+\n+Block DDLQueryStatusInputStream::readImpl()\n+{\n+    Block res;\n+    if (num_hosts_finished >= waiting_hosts.size())\n+    {\n+        if (first_exception)\n+            throw Exception(*first_exception);\n+\n+        return res;\n+    }\n+\n+    auto zookeeper = context.getZooKeeper();\n+    size_t try_number = 0;\n+\n+    while (res.rows() == 0)\n+    {\n+        if (isCancelled())\n+        {\n+            if (first_exception)\n+                throw Exception(*first_exception);\n+\n+            return res;\n+        }\n+\n+        if (timeout_seconds >= 0 && watch.elapsedSeconds() > timeout_seconds)\n+        {\n+            size_t num_unfinished_hosts = waiting_hosts.size() - num_hosts_finished;\n+            size_t num_active_hosts = current_active_hosts.size();\n+\n+\n+            throw Exception(ErrorCodes::TIMEOUT_EXCEEDED,\n+                            \"Watching task {} is executing longer than distributed_ddl_task_timeout (={}) seconds. \"\n+                            \"There are {} unfinished hosts ({} of them are currently active), they are going to execute the query in background\",\n+                            node_path, timeout_seconds, num_unfinished_hosts, num_active_hosts);\n+        }\n+\n+        if (num_hosts_finished != 0 || try_number != 0)\n+        {\n+            sleepForMilliseconds(std::min<size_t>(1000, 50 * (try_number + 1)));\n+        }\n+\n+        if (!zookeeper->exists(node_path))\n+        {\n+            throw Exception(ErrorCodes::UNFINISHED,\n+                            \"Cannot provide query execution status. The query's node {} has been deleted by the cleaner since it was finished (or its lifetime is expired)\",\n+                            node_path);\n+        }\n+\n+        Strings new_hosts = getNewAndUpdate(getChildrenAllowNoNode(zookeeper, fs::path(node_path) / \"finished\"));\n+        ++try_number;\n+        if (new_hosts.empty())\n+            continue;\n+\n+        current_active_hosts = getChildrenAllowNoNode(zookeeper, fs::path(node_path) / \"active\");\n+\n+        MutableColumns columns = sample.cloneEmptyColumns();\n+        for (const String & host_id : new_hosts)\n+        {\n+            ExecutionStatus status(-1, \"Cannot obtain error message\");\n+            {\n+                String status_data;\n+                if (zookeeper->tryGet(fs::path(node_path) / \"finished\" / host_id, status_data))\n+                    status.tryDeserializeText(status_data);\n+            }\n+\n+            String host = host_id;\n+            UInt16 port = 0;\n+            if (by_hostname)\n+            {\n+                auto host_and_port = Cluster::Address::fromString(host_id);\n+                host = host_and_port.first;\n+                port = host_and_port.second;\n+            }\n+\n+            if (status.code != 0 && first_exception == nullptr)\n+                first_exception = std::make_unique<Exception>(status.code, \"There was an error on [{}:{}]: {}\", host, port, status.message);\n+\n+            ++num_hosts_finished;\n+\n+            columns[0]->insert(host);\n+            columns[1]->insert(port);\n+            columns[2]->insert(status.code);\n+            columns[3]->insert(status.message);\n+            columns[4]->insert(waiting_hosts.size() - num_hosts_finished);\n+            columns[5]->insert(current_active_hosts.size());\n+        }\n+        res = sample.cloneWithColumns(std::move(columns));\n+    }\n+\n+    return res;\n+}\n+\n+Strings DDLQueryStatusInputStream::getChildrenAllowNoNode(const std::shared_ptr<zkutil::ZooKeeper> & zookeeper, const String & node_path)\n+{\n+    Strings res;\n+    Coordination::Error code = zookeeper->tryGetChildren(node_path, res);\n+    if (code != Coordination::Error::ZOK && code != Coordination::Error::ZNONODE)\n+        throw Coordination::Exception(code, node_path);\n+    return res;\n+}\n+\n+Strings DDLQueryStatusInputStream::getNewAndUpdate(const Strings & current_list_of_finished_hosts)\n+{\n+    Strings diff;\n+    for (const String & host : current_list_of_finished_hosts)\n+    {\n+        if (!waiting_hosts.count(host))\n+        {\n+            if (!ignoring_hosts.count(host))\n+            {\n+                ignoring_hosts.emplace(host);\n+                LOG_INFO(log, \"Unexpected host {} appeared  in task {}\", host, node_path);\n+            }\n+            continue;\n+        }\n+\n+        if (!finished_hosts.count(host))\n+        {\n+            diff.emplace_back(host);\n+            finished_hosts.emplace(host);\n+        }\n+    }\n+\n+    return diff;\n+}\n+\n+\n+}\ndiff --git a/src/Interpreters/executeDDLQueryOnCluster.h b/src/Interpreters/executeDDLQueryOnCluster.h\nnew file mode 100644\nindex 000000000000..2b272d3b0da9\n--- /dev/null\n+++ b/src/Interpreters/executeDDLQueryOnCluster.h\n@@ -0,0 +1,67 @@\n+#pragma once\n+#include <DataStreams/BlockIO.h>\n+#include <Parsers/IAST_fwd.h>\n+\n+namespace zkutil\n+{\n+    class ZooKeeper;\n+}\n+\n+namespace DB\n+{\n+\n+class Context;\n+class AccessRightsElements;\n+struct DDLLogEntry;\n+\n+\n+/// Returns true if provided ALTER type can be executed ON CLUSTER\n+bool isSupportedAlterType(int type);\n+\n+/// Pushes distributed DDL query to the queue.\n+/// Returns DDLQueryStatusInputStream, which reads results of query execution on each host in the cluster.\n+BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr, const Context & context);\n+BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr, const Context & context, const AccessRightsElements & query_requires_access, bool query_requires_grant_option = false);\n+BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr, const Context & context, AccessRightsElements && query_requires_access, bool query_requires_grant_option = false);\n+\n+\n+class DDLQueryStatusInputStream final : public IBlockInputStream\n+{\n+public:\n+    DDLQueryStatusInputStream(const String & zk_node_path, const DDLLogEntry & entry, const Context & context_, const std::optional<Strings> & hosts_to_wait = {});\n+\n+    String getName() const override { return \"DDLQueryStatusInputStream\"; }\n+\n+    Block getHeader() const override { return sample; }\n+\n+    Block getSampleBlock() const { return sample.cloneEmpty(); }\n+\n+    Block readImpl() override;\n+\n+private:\n+\n+    static Strings getChildrenAllowNoNode(const std::shared_ptr<zkutil::ZooKeeper> & zookeeper, const String & node_path);\n+\n+    Strings getNewAndUpdate(const Strings & current_list_of_finished_hosts);\n+\n+    String node_path;\n+    const Context & context;\n+    Stopwatch watch;\n+    Poco::Logger * log;\n+\n+    Block sample;\n+\n+    NameSet waiting_hosts;  /// hosts from task host list\n+    NameSet finished_hosts; /// finished hosts from host list\n+    NameSet ignoring_hosts; /// appeared hosts that are not in hosts list\n+    Strings current_active_hosts; /// Hosts that were in active state at the last check\n+    size_t num_hosts_finished = 0;\n+\n+    /// Save the first detected error and throw it at the end of execution\n+    std::unique_ptr<Exception> first_exception;\n+\n+    Int64 timeout_seconds = 120;\n+    bool by_hostname = true;\n+};\n+\n+}\ndiff --git a/src/Interpreters/ya.make b/src/Interpreters/ya.make\nindex cd4980927e4e..bfd70447beee 100644\n--- a/src/Interpreters/ya.make\n+++ b/src/Interpreters/ya.make\n@@ -41,6 +41,7 @@ SRCS(\n     Context.cpp\n     CrashLog.cpp\n     CrossToInnerJoinVisitor.cpp\n+    DDLTask.cpp\n     DDLWorker.cpp\n     DNSCacheUpdater.cpp\n     DatabaseAndTableWithAlias.cpp\n@@ -153,6 +154,7 @@ SRCS(\n     convertFieldToType.cpp\n     createBlockSelector.cpp\n     evaluateConstantExpression.cpp\n+    executeDDLQueryOnCluster.cpp\n     executeQuery.cpp\n     getClusterName.cpp\n     getHeaderForProcessingStage.cpp\ndiff --git a/src/Parsers/ASTAlterQuery.cpp b/src/Parsers/ASTAlterQuery.cpp\nindex 8a44dcc7c3b3..f24b26d5b548 100644\n--- a/src/Parsers/ASTAlterQuery.cpp\n+++ b/src/Parsers/ASTAlterQuery.cpp\n@@ -344,7 +344,7 @@ void ASTAlterCommand::formatImpl(\n         throw Exception(\"Unexpected type of ALTER\", ErrorCodes::UNEXPECTED_AST_STRUCTURE);\n }\n \n-bool ASTAlterQuery::isSettingsAlter() const\n+bool ASTAlterQuery::isOneCommandTypeOnly(const ASTAlterCommand::Type & type) const\n {\n     if (command_list)\n     {\n@@ -353,7 +353,7 @@ bool ASTAlterQuery::isSettingsAlter() const\n         for (const auto & child : command_list->children)\n         {\n             const auto & command = child->as<const ASTAlterCommand &>();\n-            if (command.type != ASTAlterCommand::MODIFY_SETTING)\n+            if (command.type != type)\n                 return false;\n         }\n         return true;\n@@ -361,6 +361,16 @@ bool ASTAlterQuery::isSettingsAlter() const\n     return false;\n }\n \n+bool ASTAlterQuery::isSettingsAlter() const\n+{\n+    return isOneCommandTypeOnly(ASTAlterCommand::MODIFY_SETTING);\n+}\n+\n+bool ASTAlterQuery::isFreezeAlter() const\n+{\n+    return isOneCommandTypeOnly(ASTAlterCommand::FREEZE_PARTITION) || isOneCommandTypeOnly(ASTAlterCommand::FREEZE_ALL);\n+}\n+\n /** Get the text that identifies this element. */\n String ASTAlterQuery::getID(char delim) const\n {\ndiff --git a/src/Parsers/ASTAlterQuery.h b/src/Parsers/ASTAlterQuery.h\nindex f53a987905eb..4cc01aa889e4 100644\n--- a/src/Parsers/ASTAlterQuery.h\n+++ b/src/Parsers/ASTAlterQuery.h\n@@ -189,6 +189,8 @@ class ASTAlterQuery : public ASTQueryWithTableAndOutput, public ASTQueryWithOnCl\n \n     bool isSettingsAlter() const;\n \n+    bool isFreezeAlter() const;\n+\n     String getID(char) const override;\n \n     ASTPtr clone() const override;\n@@ -200,6 +202,8 @@ class ASTAlterQuery : public ASTQueryWithTableAndOutput, public ASTQueryWithOnCl\n \n protected:\n     void formatQueryImpl(const FormatSettings & settings, FormatState & state, FormatStateStacked frame) const override;\n+\n+    bool isOneCommandTypeOnly(const ASTAlterCommand::Type & type) const;\n };\n \n }\ndiff --git a/src/Storages/MergeTree/registerStorageMergeTree.cpp b/src/Storages/MergeTree/registerStorageMergeTree.cpp\nindex ec016c912a66..10ebfa5ce1d2 100644\n--- a/src/Storages/MergeTree/registerStorageMergeTree.cpp\n+++ b/src/Storages/MergeTree/registerStorageMergeTree.cpp\n@@ -450,16 +450,21 @@ static StoragePtr create(const StorageFactory::Arguments & args)\n             arg_cnt += 2;\n         }\n         else\n-            throw Exception(\"Expected two string literal arguments: zookeper_path and replica_name\", ErrorCodes::BAD_ARGUMENTS);\n+            throw Exception(\"Expected two string literal arguments: zookeeper_path and replica_name\", ErrorCodes::BAD_ARGUMENTS);\n \n         /// Allow implicit {uuid} macros only for zookeeper_path in ON CLUSTER queries\n         bool is_on_cluster = args.local_context.getClientInfo().query_kind == ClientInfo::QueryKind::SECONDARY_QUERY;\n-        bool allow_uuid_macro = is_on_cluster || args.query.attach;\n+        bool is_replicated_database = args.local_context.getClientInfo().query_kind == ClientInfo::QueryKind::SECONDARY_QUERY &&\n+                                      DatabaseCatalog::instance().getDatabase(args.table_id.database_name)->getEngineName() == \"Replicated\";\n+        bool allow_uuid_macro = is_on_cluster || is_replicated_database || args.query.attach;\n \n         /// Unfold {database} and {table} macro on table creation, so table can be renamed.\n         /// We also unfold {uuid} macro, so path will not be broken after moving table from Atomic to Ordinary database.\n         if (!args.attach)\n         {\n+            if (is_replicated_database && !is_extended_storage_def)\n+                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Old syntax is not allowed for ReplicatedMergeTree tables in Replicated databases\");\n+\n             Macros::MacroExpansionInfo info;\n             /// NOTE: it's not recursive\n             info.expand_special_macros_only = true;\ndiff --git a/src/Storages/StorageMaterializedView.cpp b/src/Storages/StorageMaterializedView.cpp\nindex af00b37b1d5a..325bf3d2f742 100644\n--- a/src/Storages/StorageMaterializedView.cpp\n+++ b/src/Storages/StorageMaterializedView.cpp\n@@ -89,6 +89,7 @@ StorageMaterializedView::StorageMaterializedView(\n     else\n     {\n         /// We will create a query to create an internal table.\n+        auto create_context = Context(local_context);\n         auto manual_create_query = std::make_shared<ASTCreateQuery>();\n         manual_create_query->database = getStorageID().database_name;\n         manual_create_query->table = generateInnerTableName(getStorageID());\n@@ -99,7 +100,7 @@ StorageMaterializedView::StorageMaterializedView(\n         manual_create_query->set(manual_create_query->columns_list, new_columns_list);\n         manual_create_query->set(manual_create_query->storage, query.storage->ptr());\n \n-        InterpreterCreateQuery create_interpreter(manual_create_query, local_context);\n+        InterpreterCreateQuery create_interpreter(manual_create_query, create_context);\n         create_interpreter.setInternal(true);\n         create_interpreter.execute();\n \n@@ -193,9 +194,9 @@ BlockOutputStreamPtr StorageMaterializedView::write(const ASTPtr & query, const\n }\n \n \n-static void executeDropQuery(ASTDropQuery::Kind kind, Context & global_context, const StorageID & target_table_id, bool no_delay)\n+static void executeDropQuery(ASTDropQuery::Kind kind, const Context & global_context, const Context & current_context, const StorageID & target_table_id, bool no_delay)\n {\n-    if (DatabaseCatalog::instance().tryGetTable(target_table_id, global_context))\n+    if (DatabaseCatalog::instance().tryGetTable(target_table_id, current_context))\n     {\n         /// We create and execute `drop` query for internal table.\n         auto drop_query = std::make_shared<ASTDropQuery>();\n@@ -205,7 +206,19 @@ static void executeDropQuery(ASTDropQuery::Kind kind, Context & global_context,\n         drop_query->no_delay = no_delay;\n         drop_query->if_exists = true;\n         ASTPtr ast_drop_query = drop_query;\n-        InterpreterDropQuery drop_interpreter(ast_drop_query, global_context);\n+        /// FIXME We have to use global context to execute DROP query for inner table\n+        /// to avoid \"Not enough privileges\" error if current user has only DROP VIEW ON mat_view_name privilege\n+        /// and not allowed to drop inner table explicitly. Allowing to drop inner table without explicit grant\n+        /// looks like expected behaviour and we have tests for it.\n+        auto drop_context = Context(global_context);\n+        drop_context.getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n+        if (auto txn = current_context.getZooKeeperMetadataTransaction())\n+        {\n+            /// For Replicated database\n+            drop_context.setQueryContext(const_cast<Context &>(current_context));\n+            drop_context.initZooKeeperMetadataTransaction(txn, true);\n+        }\n+        InterpreterDropQuery drop_interpreter(ast_drop_query, drop_context);\n         drop_interpreter.execute();\n     }\n }\n@@ -218,19 +231,19 @@ void StorageMaterializedView::drop()\n     if (!select_query.select_table_id.empty())\n         DatabaseCatalog::instance().removeDependency(select_query.select_table_id, table_id);\n \n-    dropInnerTable(true);\n+    dropInnerTable(true, global_context);\n }\n \n-void StorageMaterializedView::dropInnerTable(bool no_delay)\n+void StorageMaterializedView::dropInnerTable(bool no_delay, const Context & context)\n {\n     if (has_inner_table && tryGetTargetTable())\n-        executeDropQuery(ASTDropQuery::Kind::Drop, global_context, target_table_id, no_delay);\n+        executeDropQuery(ASTDropQuery::Kind::Drop, global_context, context, target_table_id, no_delay);\n }\n \n-void StorageMaterializedView::truncate(const ASTPtr &, const StorageMetadataPtr &, const Context &, TableExclusiveLockHolder &)\n+void StorageMaterializedView::truncate(const ASTPtr &, const StorageMetadataPtr &, const Context & context, TableExclusiveLockHolder &)\n {\n     if (has_inner_table)\n-        executeDropQuery(ASTDropQuery::Kind::Truncate, global_context, target_table_id, true);\n+        executeDropQuery(ASTDropQuery::Kind::Truncate, global_context, context, target_table_id, true);\n }\n \n void StorageMaterializedView::checkStatementCanBeForwarded() const\ndiff --git a/src/Storages/StorageMaterializedView.h b/src/Storages/StorageMaterializedView.h\nindex fab9e28afe34..94e4295cd343 100644\n--- a/src/Storages/StorageMaterializedView.h\n+++ b/src/Storages/StorageMaterializedView.h\n@@ -37,7 +37,7 @@ class StorageMaterializedView final : public ext::shared_ptr_helper<StorageMater\n     BlockOutputStreamPtr write(const ASTPtr & query, const StorageMetadataPtr & /*metadata_snapshot*/, const Context & context) override;\n \n     void drop() override;\n-    void dropInnerTable(bool no_delay);\n+    void dropInnerTable(bool no_delay, const Context & context);\n \n     void truncate(const ASTPtr &, const StorageMetadataPtr &, const Context &, TableExclusiveLockHolder &) override;\n \ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 518577c473c4..f2c88cdedd93 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -29,6 +29,7 @@\n \n \n #include <Databases/IDatabase.h>\n+#include <Databases/DatabaseOnDisk.h>\n \n #include <Parsers/formatAST.h>\n #include <Parsers/ASTDropQuery.h>\n@@ -46,6 +47,7 @@\n #include <Interpreters/InterpreterAlterQuery.h>\n #include <Interpreters/PartLog.h>\n #include <Interpreters/Context.h>\n+#include <Interpreters/DDLTask.h>\n \n #include <DataStreams/RemoteBlockInputStream.h>\n #include <DataStreams/copyData.h>\n@@ -4218,6 +4220,8 @@ void StorageReplicatedMergeTree::alter(\n             future_metadata_in_zk.constraints = new_constraints_str;\n \n         Coordination::Requests ops;\n+        size_t alter_path_idx = std::numeric_limits<size_t>::max();\n+        size_t mutation_path_idx = std::numeric_limits<size_t>::max();\n \n         String new_metadata_str = future_metadata_in_zk.toString();\n         ops.emplace_back(zkutil::makeSetRequest(zookeeper_path + \"/metadata\", new_metadata_str, metadata_version));\n@@ -4249,6 +4253,7 @@ void StorageReplicatedMergeTree::alter(\n             *current_metadata, query_context.getSettingsRef().materialize_ttl_after_modify, query_context);\n         alter_entry->have_mutation = !maybe_mutation_commands.empty();\n \n+        alter_path_idx = ops.size();\n         ops.emplace_back(zkutil::makeCreateRequest(\n             zookeeper_path + \"/log/log-\", alter_entry->toString(), zkutil::CreateMode::PersistentSequential));\n \n@@ -4272,10 +4277,22 @@ void StorageReplicatedMergeTree::alter(\n             mutation_entry.create_time = time(nullptr);\n \n             ops.emplace_back(zkutil::makeSetRequest(mutations_path, String(), mutations_stat.version));\n+            mutation_path_idx = ops.size();\n             ops.emplace_back(\n                 zkutil::makeCreateRequest(mutations_path + \"/\", mutation_entry.toString(), zkutil::CreateMode::PersistentSequential));\n         }\n \n+        if (auto txn = query_context.getZooKeeperMetadataTransaction())\n+        {\n+            txn->moveOpsTo(ops);\n+            /// NOTE: IDatabase::alterTable(...) is called when executing ALTER_METADATA queue entry without query context,\n+            /// so we have to update metadata of DatabaseReplicated here.\n+            String metadata_zk_path = txn->getDatabaseZooKeeperPath() + \"/metadata/\" + escapeForFileName(table_id.table_name);\n+            auto ast = DatabaseCatalog::instance().getDatabase(table_id.database_name)->getCreateTableQuery(table_id.table_name, query_context);\n+            applyMetadataChangesToCreateQuery(ast, future_metadata);\n+            ops.emplace_back(zkutil::makeSetRequest(metadata_zk_path, getObjectDefinitionFromCreateQuery(ast), -1));\n+        }\n+\n         Coordination::Responses results;\n         Coordination::Error rc = zookeeper->tryMulti(ops, results);\n \n@@ -4289,17 +4306,17 @@ void StorageReplicatedMergeTree::alter(\n             if (alter_entry->have_mutation)\n             {\n                 /// ALTER_METADATA record in replication /log\n-                String alter_path = dynamic_cast<const Coordination::CreateResponse &>(*results[2]).path_created;\n+                String alter_path = dynamic_cast<const Coordination::CreateResponse &>(*results[alter_path_idx]).path_created;\n                 alter_entry->znode_name = alter_path.substr(alter_path.find_last_of('/') + 1);\n \n                 /// ReplicatedMergeTreeMutationEntry record in /mutations\n-                String mutation_path = dynamic_cast<const Coordination::CreateResponse &>(*results.back()).path_created;\n+                String mutation_path = dynamic_cast<const Coordination::CreateResponse &>(*results[mutation_path_idx]).path_created;\n                 mutation_znode = mutation_path.substr(mutation_path.find_last_of('/') + 1);\n             }\n             else\n             {\n                 /// ALTER_METADATA record in replication /log\n-                String alter_path = dynamic_cast<const Coordination::CreateResponse &>(*results.back()).path_created;\n+                String alter_path = dynamic_cast<const Coordination::CreateResponse &>(*results[alter_path_idx]).path_created;\n                 alter_entry->znode_name = alter_path.substr(alter_path.find_last_of('/') + 1);\n             }\n             break;\n@@ -4421,7 +4438,7 @@ void StorageReplicatedMergeTree::dropPartition(const ASTPtr & partition, bool de\n     else\n     {\n         String partition_id = getPartitionIDFromQuery(partition, query_context);\n-        did_drop = dropAllPartsInPartition(*zookeeper, partition_id, entry, detach);\n+        did_drop = dropAllPartsInPartition(*zookeeper, partition_id, entry, query_context, detach);\n     }\n \n     if (did_drop)\n@@ -4445,7 +4462,7 @@ void StorageReplicatedMergeTree::dropPartition(const ASTPtr & partition, bool de\n \n \n void StorageReplicatedMergeTree::truncate(\n-    const ASTPtr &, const StorageMetadataPtr &, const Context &, TableExclusiveLockHolder & table_lock)\n+    const ASTPtr &, const StorageMetadataPtr &, const Context & query_context, TableExclusiveLockHolder & table_lock)\n {\n     table_lock.release();   /// Truncate is done asynchronously.\n \n@@ -4461,7 +4478,7 @@ void StorageReplicatedMergeTree::truncate(\n     {\n         LogEntry entry;\n \n-        if (dropAllPartsInPartition(*zookeeper, partition_id, entry, false))\n+        if (dropAllPartsInPartition(*zookeeper, partition_id, entry, query_context, false))\n             waitForAllReplicasToProcessLogEntry(entry);\n     }\n }\n@@ -5245,6 +5262,9 @@ void StorageReplicatedMergeTree::mutate(const MutationCommands & commands, const\n         requests.emplace_back(zkutil::makeCreateRequest(\n             mutations_path + \"/\", mutation_entry.toString(), zkutil::CreateMode::PersistentSequential));\n \n+        if (auto txn = query_context.getZooKeeperMetadataTransaction())\n+            txn->moveOpsTo(requests);\n+\n         Coordination::Responses responses;\n         Coordination::Error rc = zookeeper->tryMulti(requests, responses);\n \n@@ -5746,6 +5766,9 @@ void StorageReplicatedMergeTree::replacePartitionFrom(\n             }\n         }\n \n+        if (auto txn = context.getZooKeeperMetadataTransaction())\n+            txn->moveOpsTo(ops);\n+\n         ops.emplace_back(zkutil::makeSetRequest(zookeeper_path + \"/log\", \"\", -1));  /// Just update version\n         ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/log/log-\", entry.toString(), zkutil::CreateMode::PersistentSequential));\n \n@@ -6214,7 +6237,7 @@ bool StorageReplicatedMergeTree::dropPart(\n }\n \n bool StorageReplicatedMergeTree::dropAllPartsInPartition(\n-    zkutil::ZooKeeper & zookeeper, String & partition_id, LogEntry & entry, bool detach)\n+    zkutil::ZooKeeper & zookeeper, String & partition_id, LogEntry & entry, const Context & query_context, bool detach)\n {\n     MergeTreePartInfo drop_range_info;\n     if (!getFakePartCoveringAllPartsInPartition(partition_id, drop_range_info))\n@@ -6246,6 +6269,8 @@ bool StorageReplicatedMergeTree::dropAllPartsInPartition(\n     Coordination::Requests ops;\n     ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/log/log-\", entry.toString(), zkutil::CreateMode::PersistentSequential));\n     ops.emplace_back(zkutil::makeSetRequest(zookeeper_path + \"/log\", \"\", -1));  /// Just update version.\n+    if (auto txn = query_context.getZooKeeperMetadataTransaction())\n+        txn->moveOpsTo(ops);\n     Coordination::Responses responses = zookeeper.multi(ops);\n \n     String log_znode_path = dynamic_cast<const Coordination::CreateResponse &>(*responses.front()).path_created;\ndiff --git a/src/Storages/StorageReplicatedMergeTree.h b/src/Storages/StorageReplicatedMergeTree.h\nindex 6db05294b635..a1a70ada9b23 100644\n--- a/src/Storages/StorageReplicatedMergeTree.h\n+++ b/src/Storages/StorageReplicatedMergeTree.h\n@@ -134,7 +134,7 @@ class StorageReplicatedMergeTree final : public ext::shared_ptr_helper<StorageRe\n       */\n     void drop() override;\n \n-    void truncate(const ASTPtr &, const StorageMetadataPtr &, const Context &, TableExclusiveLockHolder &) override;\n+    void truncate(const ASTPtr &, const StorageMetadataPtr &, const Context & query_context, TableExclusiveLockHolder &) override;\n \n     void checkTableCanBeRenamed() const override;\n \n@@ -577,7 +577,7 @@ class StorageReplicatedMergeTree final : public ext::shared_ptr_helper<StorageRe\n \n     bool dropPart(zkutil::ZooKeeperPtr & zookeeper, String part_name, LogEntry & entry, bool detach, bool throw_if_noop);\n     bool dropAllPartsInPartition(\n-        zkutil::ZooKeeper & zookeeper, String & partition_id, LogEntry & entry, bool detach);\n+        zkutil::ZooKeeper & zookeeper, String & partition_id, LogEntry & entry, const Context & query_context, bool detach);\n \n     // Partition helpers\n     void dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & query_context, bool throw_if_noop) override;\ndiff --git a/src/Storages/System/StorageSystemClusters.cpp b/src/Storages/System/StorageSystemClusters.cpp\nindex ae8bcca28049..7e16deb6d22f 100644\n--- a/src/Storages/System/StorageSystemClusters.cpp\n+++ b/src/Storages/System/StorageSystemClusters.cpp\n@@ -3,6 +3,7 @@\n #include <Interpreters/Cluster.h>\n #include <Interpreters/Context.h>\n #include <Storages/System/StorageSystemClusters.h>\n+#include <Databases/DatabaseReplicated.h>\n \n namespace DB\n {\n@@ -26,40 +27,51 @@ NamesAndTypesList StorageSystemClusters::getNamesAndTypes()\n     };\n }\n \n+\n void StorageSystemClusters::fillData(MutableColumns & res_columns, const Context & context, const SelectQueryInfo &) const\n {\n     for (const auto & name_and_cluster : context.getClusters().getContainer())\n+        writeCluster(res_columns, name_and_cluster);\n+\n+    const auto databases = DatabaseCatalog::instance().getDatabases();\n+    for (const auto & name_and_database : databases)\n     {\n-        const String & cluster_name = name_and_cluster.first;\n-        const ClusterPtr & cluster = name_and_cluster.second;\n-        const auto & shards_info = cluster->getShardsInfo();\n-        const auto & addresses_with_failover = cluster->getShardsAddresses();\n+        if (const auto * replicated = typeid_cast<const DatabaseReplicated *>(name_and_database.second.get()))\n+            writeCluster(res_columns, {name_and_database.first, replicated->getCluster()});\n+    }\n+}\n \n-        for (size_t shard_index = 0; shard_index < shards_info.size(); ++shard_index)\n-        {\n-            const auto & shard_info = shards_info[shard_index];\n-            const auto & shard_addresses = addresses_with_failover[shard_index];\n-            const auto pool_status = shard_info.pool->getStatus();\n+void StorageSystemClusters::writeCluster(MutableColumns & res_columns, const NameAndCluster & name_and_cluster)\n+{\n+    const String & cluster_name = name_and_cluster.first;\n+    const ClusterPtr & cluster = name_and_cluster.second;\n+    const auto & shards_info = cluster->getShardsInfo();\n+    const auto & addresses_with_failover = cluster->getShardsAddresses();\n+\n+    for (size_t shard_index = 0; shard_index < shards_info.size(); ++shard_index)\n+    {\n+        const auto & shard_info = shards_info[shard_index];\n+        const auto & shard_addresses = addresses_with_failover[shard_index];\n+        const auto pool_status = shard_info.pool->getStatus();\n \n-            for (size_t replica_index = 0; replica_index < shard_addresses.size(); ++replica_index)\n-            {\n-                size_t i = 0;\n-                const auto & address = shard_addresses[replica_index];\n+        for (size_t replica_index = 0; replica_index < shard_addresses.size(); ++replica_index)\n+        {\n+            size_t i = 0;\n+            const auto & address = shard_addresses[replica_index];\n \n-                res_columns[i++]->insert(cluster_name);\n-                res_columns[i++]->insert(shard_info.shard_num);\n-                res_columns[i++]->insert(shard_info.weight);\n-                res_columns[i++]->insert(replica_index + 1);\n-                res_columns[i++]->insert(address.host_name);\n-                auto resolved = address.getResolvedAddress();\n-                res_columns[i++]->insert(resolved ? resolved->host().toString() : String());\n-                res_columns[i++]->insert(address.port);\n-                res_columns[i++]->insert(address.is_local);\n-                res_columns[i++]->insert(address.user);\n-                res_columns[i++]->insert(address.default_database);\n-                res_columns[i++]->insert(pool_status[replica_index].error_count);\n-                res_columns[i++]->insert(pool_status[replica_index].estimated_recovery_time.count());\n-            }\n+            res_columns[i++]->insert(cluster_name);\n+            res_columns[i++]->insert(shard_info.shard_num);\n+            res_columns[i++]->insert(shard_info.weight);\n+            res_columns[i++]->insert(replica_index + 1);\n+            res_columns[i++]->insert(address.host_name);\n+            auto resolved = address.getResolvedAddress();\n+            res_columns[i++]->insert(resolved ? resolved->host().toString() : String());\n+            res_columns[i++]->insert(address.port);\n+            res_columns[i++]->insert(address.is_local);\n+            res_columns[i++]->insert(address.user);\n+            res_columns[i++]->insert(address.default_database);\n+            res_columns[i++]->insert(pool_status[replica_index].error_count);\n+            res_columns[i++]->insert(pool_status[replica_index].estimated_recovery_time.count());\n         }\n     }\n }\ndiff --git a/src/Storages/System/StorageSystemClusters.h b/src/Storages/System/StorageSystemClusters.h\nindex 4cda7c372b21..4f2a843999f8 100644\n--- a/src/Storages/System/StorageSystemClusters.h\n+++ b/src/Storages/System/StorageSystemClusters.h\n@@ -10,6 +10,7 @@ namespace DB\n {\n \n class Context;\n+class Cluster;\n \n /** Implements system table 'clusters'\n   *  that allows to obtain information about available clusters\n@@ -25,8 +26,10 @@ class StorageSystemClusters final : public ext::shared_ptr_helper<StorageSystemC\n \n protected:\n     using IStorageSystemOneBlock::IStorageSystemOneBlock;\n+    using NameAndCluster = std::pair<String, std::shared_ptr<Cluster>>;\n \n     void fillData(MutableColumns & res_columns, const Context & context, const SelectQueryInfo & query_info) const override;\n+    static void writeCluster(MutableColumns & res_columns, const NameAndCluster & name_and_cluster);\n };\n \n }\ndiff --git a/src/Storages/System/StorageSystemDDLWorkerQueue.cpp b/src/Storages/System/StorageSystemDDLWorkerQueue.cpp\nindex 229325313e2e..04321544f5d4 100644\n--- a/src/Storages/System/StorageSystemDDLWorkerQueue.cpp\n+++ b/src/Storages/System/StorageSystemDDLWorkerQueue.cpp\n@@ -4,7 +4,7 @@\n #include \"StorageSystemDDLWorkerQueue.h\"\n \n #include <Columns/ColumnArray.h>\n-#include <Interpreters/DDLWorker.h>\n+#include <Interpreters/DDLTask.h>\n \n #include <DataTypes/DataTypeArray.h>\n #include <DataTypes/DataTypeDateTime.h>\n",
  "test_patch": "diff --git a/docker/test/fasttest/run.sh b/docker/test/fasttest/run.sh\nindex 1c5f62a9e467..c9c8cb1382d9 100755\n--- a/docker/test/fasttest/run.sh\n+++ b/docker/test/fasttest/run.sh\n@@ -326,7 +326,7 @@ function run_tests\n         # Look at DistributedFilesToInsert, so cannot run in parallel.\n         01460_DistributedFilesToInsert\n \n-        01541_max_memory_usage_for_user\n+        01541_max_memory_usage_for_user_long\n \n         # Require python libraries like scipy, pandas and numpy\n         01322_ttest_scipy\ndiff --git a/docker/test/stateful/run.sh b/docker/test/stateful/run.sh\nindex f2fcefd604f1..7779f0e9dc20 100755\n--- a/docker/test/stateful/run.sh\n+++ b/docker/test/stateful/run.sh\n@@ -60,4 +60,8 @@ fi\n # more idiologically correct.\n read -ra ADDITIONAL_OPTIONS <<< \"${ADDITIONAL_OPTIONS:-}\"\n \n+if [[ -n \"$USE_DATABASE_REPLICATED\" ]] && [[ \"$USE_DATABASE_REPLICATED\" -eq 1 ]]; then\n+    ADDITIONAL_OPTIONS+=('--replicated-database')\n+fi\n+\n clickhouse-test --testname --shard --zookeeper --no-stateless --hung-check --print-time \"$SKIP_LIST_OPT\" \"${ADDITIONAL_OPTIONS[@]}\" \"$SKIP_TESTS_OPTION\" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee test_output/test_result.txt\ndiff --git a/docker/test/stateless/run.sh b/docker/test/stateless/run.sh\nindex 575be721a544..d078f3739fdf 100755\n--- a/docker/test/stateless/run.sh\n+++ b/docker/test/stateless/run.sh\n@@ -57,6 +57,10 @@ function run_tests()\n         ADDITIONAL_OPTIONS+=('4')\n     fi\n \n+    if [[ -n \"$USE_DATABASE_REPLICATED\" ]] && [[ \"$USE_DATABASE_REPLICATED\" -eq 1 ]]; then\n+        ADDITIONAL_OPTIONS+=('--replicated-database')\n+    fi\n+\n     clickhouse-test --testname --shard --zookeeper --hung-check --print-time \\\n             --test-runs \"$NUM_TRIES\" \\\n             \"$SKIP_LIST_OPT\" \"${ADDITIONAL_OPTIONS[@]}\" 2>&1 \\\ndiff --git a/docker/test/stress/stress b/docker/test/stress/stress\nindex d2ec86b4421d..841556cf090d 100755\n--- a/docker/test/stress/stress\n+++ b/docker/test/stress/stress\n@@ -23,12 +23,15 @@ def get_options(i):\n     if 0 < i:\n         options += \" --order=random\"\n \n-    if i % 2 == 1:\n+    if i % 3 == 1:\n         options += \" --db-engine=Ordinary\"\n \n+    if i % 3 == 2:\n+        options += ''' --db-engine=\"Replicated('/test/db/test_{}', 's1', 'r1')\"'''.format(i)\n+\n     # If database name is not specified, new database is created for each functional test.\n     # Run some threads with one database for all tests.\n-    if i % 3 == 1:\n+    if i % 2 == 1:\n         options += \" --database=test_{}\".format(i)\n \n     if i == 13:\ndiff --git a/tests/ci/ci_config.json b/tests/ci/ci_config.json\nindex 44b35d61601d..0e4673192854 100644\n--- a/tests/ci/ci_config.json\n+++ b/tests/ci/ci_config.json\n@@ -261,6 +261,18 @@\n                 \"with_coverage\": false\n             }\n         },\n+        \"Functional stateful tests (release, DatabaseReplicated)\": {\n+            \"required_build_properties\": {\n+                \"compiler\": \"clang-11\",\n+                \"package_type\": \"deb\",\n+                \"build_type\": \"relwithdebuginfo\",\n+                \"sanitizer\": \"none\",\n+                \"bundled\": \"bundled\",\n+                \"splitted\": \"unsplitted\",\n+                \"clang-tidy\": \"disable\",\n+                \"with_coverage\": false\n+            }\n+        },\n         \"Functional stateless tests (address)\": {\n             \"required_build_properties\": {\n                 \"compiler\": \"clang-11\",\n@@ -381,6 +393,18 @@\n                 \"with_coverage\": false\n             }\n         },\n+        \"Functional stateless tests (release, DatabaseReplicated)\": {\n+            \"required_build_properties\": {\n+                \"compiler\": \"clang-11\",\n+                \"package_type\": \"deb\",\n+                \"build_type\": \"relwithdebuginfo\",\n+                \"sanitizer\": \"none\",\n+                \"bundled\": \"bundled\",\n+                \"splitted\": \"unsplitted\",\n+                \"clang-tidy\": \"disable\",\n+                \"with_coverage\": false\n+            }\n+        },\n         \"Stress test (address)\": {\n             \"required_build_properties\": {\n                 \"compiler\": \"clang-11\",\ndiff --git a/tests/clickhouse-test b/tests/clickhouse-test\nindex 74f5f07eb9dd..64a93416c41b 100755\n--- a/tests/clickhouse-test\n+++ b/tests/clickhouse-test\n@@ -105,7 +105,9 @@ def remove_control_characters(s):\n     s = re.sub(r\"[\\x00-\\x08\\x0b\\x0e-\\x1f\\x7f]\", \"\", s)\n     return s\n \n-def get_db_engine(args):\n+def get_db_engine(args, database_name):\n+    if args.replicated_database:\n+        return \" ENGINE=Replicated('/test/clickhouse/db/{}', 's1', 'r1')\".format(database_name)\n     if args.db_engine:\n         return \" ENGINE=\" + args.db_engine\n     return \"\"   # Will use default engine\n@@ -128,7 +130,7 @@ def run_single_test(args, ext, server_logs_level, client_options, case_file, std\n \n         clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n         try:\n-            clickhouse_proc_create.communicate((\"CREATE DATABASE \" + database + get_db_engine(args)), timeout=args.timeout)\n+            clickhouse_proc_create.communicate((\"CREATE DATABASE \" + database + get_db_engine(args, database)), timeout=args.timeout)\n         except TimeoutExpired:\n             total_time = (datetime.now() - start_time).total_seconds()\n             return clickhouse_proc_create, \"\", \"Timeout creating database {} before test\".format(database), total_time\n@@ -161,7 +163,12 @@ def run_single_test(args, ext, server_logs_level, client_options, case_file, std\n     while (datetime.now() - start_time).total_seconds() < args.timeout and proc.poll() is None:\n         sleep(0.01)\n \n-    if not args.database:\n+    need_drop_database = not args.database\n+    if need_drop_database and args.no_drop_if_fail:\n+        maybe_passed = (proc.returncode == 0) and (proc.stderr is None) and (proc.stdout is None or 'Exception' not in proc.stdout)\n+        need_drop_database = not maybe_passed\n+\n+    if need_drop_database:\n         clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n         seconds_left = max(args.timeout - (datetime.now() - start_time).total_seconds(), 10)\n         try:\n@@ -182,7 +189,8 @@ def run_single_test(args, ext, server_logs_level, client_options, case_file, std\n \n     # Normalize randomized database names in stdout, stderr files.\n     os.system(\"LC_ALL=C sed -i -e 's/{test_db}/default/g' {file}\".format(test_db=database, file=stdout_file))\n-    os.system(\"LC_ALL=C sed -i -e 's/{test_db}/default/g' {file}\".format(test_db=database, file=stderr_file))\n+    if not args.show_db_name:\n+        os.system(\"LC_ALL=C sed -i -e 's/{test_db}/default/g' {file}\".format(test_db=database, file=stderr_file))\n \n     stdout = open(stdout_file, 'rb').read() if os.path.exists(stdout_file) else b''\n     stdout = str(stdout, errors='replace', encoding='utf-8')\n@@ -526,6 +534,8 @@ class BuildFlags():\n     RELEASE = 'release-build'\n     DATABASE_ORDINARY = 'database-ordinary'\n     POLYMORPHIC_PARTS = 'polymorphic-parts'\n+    ANTLR = 'antlr'\n+    DATABASE_REPLICATED = 'database-replicated'\n \n \n def collect_build_flags(client):\n@@ -607,7 +617,9 @@ def main(args):\n \n     build_flags = collect_build_flags(args.client)\n     if args.antlr:\n-        build_flags.append('antlr')\n+        build_flags.append(BuildFlags.ANTLR)\n+    if args.replicated_database:\n+        build_flags.append(BuildFlags.DATABASE_REPLICATED)\n \n     if args.use_skip_list:\n         tests_to_skip_from_list = collect_tests_to_skip(args.skip_list_path, build_flags)\n@@ -660,10 +672,10 @@ def main(args):\n \n     if args.database and args.database != \"test\":\n         clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n-        clickhouse_proc_create.communicate((\"CREATE DATABASE IF NOT EXISTS \" + args.database + get_db_engine(args)))\n+        clickhouse_proc_create.communicate((\"CREATE DATABASE IF NOT EXISTS \" + args.database + get_db_engine(args, args.database)))\n \n     clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n-    clickhouse_proc_create.communicate((\"CREATE DATABASE IF NOT EXISTS test\" + get_db_engine(args)))\n+    clickhouse_proc_create.communicate((\"CREATE DATABASE IF NOT EXISTS test\" + get_db_engine(args, 'test')))\n \n     def is_test_from_dir(suite_dir, case):\n         case_file = os.path.join(suite_dir, case)\n@@ -907,6 +919,8 @@ if __name__ == '__main__':\n     parser.add_argument('--hung-check', action='store_true', default=False)\n     parser.add_argument('--force-color', action='store_true', default=False)\n     parser.add_argument('--database', help='Database for tests (random name test_XXXXXX by default)')\n+    parser.add_argument('--no-drop-if-fail', action='store_true', help='Do not drop database for test if test has failed')\n+    parser.add_argument('--show-db-name', action='store_true', help='Do not replace random database name with \"default\"')\n     parser.add_argument('--parallel', default='1/1', help='One parallel test run number/total')\n     parser.add_argument('-j', '--jobs', default=1, nargs='?', type=int, help='Run all tests in parallel')\n     parser.add_argument('--test-runs', default=1, nargs='?', type=int, help='Run each test many times (useful for e.g. flaky check)')\n@@ -915,6 +929,7 @@ if __name__ == '__main__':\n     parser.add_argument('--skip-list-path', help=\"Path to skip-list file\")\n     parser.add_argument('--use-skip-list', action='store_true', default=False, help=\"Use skip list to skip tests if found\")\n     parser.add_argument('--db-engine', help='Database engine name')\n+    parser.add_argument('--replicated-database', action='store_true', default=False, help='Run tests with Replicated database engine')\n \n     parser.add_argument('--antlr', action='store_true', default=False, dest='antlr', help='Use new ANTLR parser in tests')\n     parser.add_argument('--no-stateless', action='store_true', help='Disable all stateless tests')\ndiff --git a/tests/config/install.sh b/tests/config/install.sh\nindex 9965e1fb1ad4..de6ba2a7a091 100755\n--- a/tests/config/install.sh\n+++ b/tests/config/install.sh\n@@ -61,5 +61,8 @@ fi\n if [[ -n \"$USE_DATABASE_ORDINARY\" ]] && [[ \"$USE_DATABASE_ORDINARY\" -eq 1 ]]; then\n     ln -sf $SRC_PATH/users.d/database_ordinary.xml $DEST_SERVER_PATH/users.d/\n fi\n+if [[ -n \"$USE_DATABASE_REPLICATED\" ]] && [[ \"$USE_DATABASE_REPLICATED\" -eq 1 ]]; then\n+    ln -sf $SRC_PATH/users.d/database_replicated.xml $DEST_SERVER_PATH/users.d/\n+fi\n \n ln -sf $SRC_PATH/client_config.xml $DEST_CLIENT_PATH/config.xml\ndiff --git a/tests/config/users.d/database_replicated.xml b/tests/config/users.d/database_replicated.xml\nnew file mode 100644\nindex 000000000000..23801d001548\n--- /dev/null\n+++ b/tests/config/users.d/database_replicated.xml\n@@ -0,0 +1,10 @@\n+<yandex>\n+    <profiles>\n+        <default>\n+            <allow_experimental_database_replicated>1</allow_experimental_database_replicated>\n+            <database_replicated_ddl_output>0</database_replicated_ddl_output>\n+            <database_replicated_initial_query_timeout_sec>30</database_replicated_initial_query_timeout_sec>\n+            <distributed_ddl_task_timeout>30</distributed_ddl_task_timeout>\n+        </default>\n+    </profiles>\n+</yandex>\ndiff --git a/tests/integration/helpers/test_tools.py b/tests/integration/helpers/test_tools.py\nindex bbab12e55d47..5fedadd3380b 100644\n--- a/tests/integration/helpers/test_tools.py\n+++ b/tests/integration/helpers/test_tools.py\n@@ -47,20 +47,20 @@ def toMat(contents):\n \n \n def assert_eq_with_retry(instance, query, expectation, retry_count=20, sleep_time=0.5, stdin=None, timeout=None,\n-                         settings=None, user=None, ignore_error=False):\n+                         settings=None, user=None, ignore_error=False, get_result=lambda x: x):\n     expectation_tsv = TSV(expectation)\n     for i in range(retry_count):\n         try:\n-            if TSV(instance.query(query, user=user, stdin=stdin, timeout=timeout, settings=settings,\n-                                  ignore_error=ignore_error)) == expectation_tsv:\n+            if TSV(get_result(instance.query(query, user=user, stdin=stdin, timeout=timeout, settings=settings,\n+                                  ignore_error=ignore_error))) == expectation_tsv:\n                 break\n             time.sleep(sleep_time)\n         except Exception as ex:\n             print((\"assert_eq_with_retry retry {} exception {}\".format(i + 1, ex)))\n             time.sleep(sleep_time)\n     else:\n-        val = TSV(instance.query(query, user=user, stdin=stdin, timeout=timeout, settings=settings,\n-                                 ignore_error=ignore_error))\n+        val = TSV(get_result(instance.query(query, user=user, stdin=stdin, timeout=timeout, settings=settings,\n+                                 ignore_error=ignore_error)))\n         if expectation_tsv != val:\n             raise AssertionError(\"'{}' != '{}'\\n{}\".format(expectation_tsv, val, '\\n'.join(\n                 expectation_tsv.diff(val, n1=\"expectation\", n2=\"query\"))))\ndiff --git a/tests/integration/test_replicated_database/__init__.py b/tests/integration/test_replicated_database/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_replicated_database/configs/config.xml b/tests/integration/test_replicated_database/configs/config.xml\nnew file mode 100644\nindex 000000000000..ebceee3aa5c8\n--- /dev/null\n+++ b/tests/integration/test_replicated_database/configs/config.xml\n@@ -0,0 +1,34 @@\n+<yandex>\n+    <database_atomic_delay_before_drop_table_sec>10</database_atomic_delay_before_drop_table_sec>\n+\n+    <remote_servers>\n+        <cluster>\n+            <shard>\n+                <internal_replication>true</internal_replication>\n+                <replica>\n+                    <host>main_node</host>\n+                    <port>9000</port>\n+                </replica>\n+                <replica>\n+                    <host>dummy_node</host>\n+                    <port>9000</port>\n+                </replica>\n+                <replica>\n+                    <host>competing_node</host>\n+                    <port>9000</port>\n+                </replica>\n+            </shard>\n+            <shard>\n+                <internal_replication>true</internal_replication>\n+                <replica>\n+                    <host>snapshotting_node</host>\n+                    <port>9000</port>\n+                </replica>\n+                <replica>\n+                    <host>snapshot_recovering_node</host>\n+                    <port>9000</port>\n+                </replica>\n+            </shard>\n+        </cluster>\n+    </remote_servers>\n+</yandex>\ndiff --git a/tests/integration/test_replicated_database/configs/settings.xml b/tests/integration/test_replicated_database/configs/settings.xml\nnew file mode 100644\nindex 000000000000..e0f7e8691e66\n--- /dev/null\n+++ b/tests/integration/test_replicated_database/configs/settings.xml\n@@ -0,0 +1,12 @@\n+<yandex>\n+    <profiles>\n+        <default>\n+            <allow_experimental_database_replicated>1</allow_experimental_database_replicated>\n+        </default>\n+    </profiles>\n+    <users>\n+        <default>\n+            <profile>default</profile>\n+        </default>\n+    </users>\n+</yandex>\ndiff --git a/tests/integration/test_replicated_database/test.py b/tests/integration/test_replicated_database/test.py\nnew file mode 100644\nindex 000000000000..99e7d6077f82\n--- /dev/null\n+++ b/tests/integration/test_replicated_database/test.py\n@@ -0,0 +1,278 @@\n+import time\n+import re\n+import pytest\n+\n+from helpers.cluster import ClickHouseCluster\n+from helpers.test_tools import assert_eq_with_retry, assert_logs_contain\n+from helpers.network import PartitionManager\n+\n+cluster = ClickHouseCluster(__file__)\n+\n+main_node = cluster.add_instance('main_node', main_configs=['configs/config.xml'], user_configs=['configs/settings.xml'], with_zookeeper=True, stay_alive=True, macros={\"shard\": 1, \"replica\": 1})\n+dummy_node = cluster.add_instance('dummy_node', main_configs=['configs/config.xml'], user_configs=['configs/settings.xml'], with_zookeeper=True, stay_alive=True, macros={\"shard\": 1, \"replica\": 2})\n+competing_node = cluster.add_instance('competing_node', main_configs=['configs/config.xml'], user_configs=['configs/settings.xml'], with_zookeeper=True, macros={\"shard\": 1, \"replica\": 3})\n+snapshotting_node = cluster.add_instance('snapshotting_node', main_configs=['configs/config.xml'], user_configs=['configs/settings.xml'], with_zookeeper=True, macros={\"shard\": 2, \"replica\": 1})\n+snapshot_recovering_node = cluster.add_instance('snapshot_recovering_node', main_configs=['configs/config.xml'], user_configs=['configs/settings.xml'], with_zookeeper=True, macros={\"shard\": 2, \"replica\": 2})\n+\n+all_nodes = [main_node, dummy_node, competing_node, snapshotting_node, snapshot_recovering_node]\n+\n+uuid_regex = re.compile(\"[0-9a-f]{8}\\-[0-9a-f]{4}\\-[0-9a-f]{4}\\-[0-9a-f]{4}\\-[0-9a-f]{12}\")\n+def assert_create_query(nodes, table_name, expected):\n+    replace_uuid = lambda x: re.sub(uuid_regex, \"uuid\", x)\n+    query = \"show create table {}\".format(table_name)\n+    for node in nodes:\n+        assert_eq_with_retry(node, query, expected, get_result=replace_uuid)\n+\n+@pytest.fixture(scope=\"module\")\n+def started_cluster():\n+    try:\n+        cluster.start()\n+        main_node.query(\"CREATE DATABASE testdb ENGINE = Replicated('/clickhouse/databases/test1', 'shard1', 'replica1');\")\n+        dummy_node.query(\"CREATE DATABASE testdb ENGINE = Replicated('/clickhouse/databases/test1', 'shard1', 'replica2');\")\n+        yield cluster\n+\n+    finally:\n+        cluster.shutdown()\n+\n+def test_create_replicated_table(started_cluster):\n+    assert \"Old syntax is not allowed\" in \\\n+           main_node.query_and_get_error(\"CREATE TABLE testdb.replicated_table (d Date, k UInt64, i32 Int32) ENGINE=ReplicatedMergeTree('/test/tmp', 'r', d, k, 8192);\")\n+\n+    main_node.query(\"CREATE TABLE testdb.replicated_table (d Date, k UInt64, i32 Int32) ENGINE=ReplicatedMergeTree ORDER BY k PARTITION BY toYYYYMM(d);\")\n+\n+    expected = \"CREATE TABLE testdb.replicated_table\\\\n(\\\\n    `d` Date,\\\\n    `k` UInt64,\\\\n    `i32` Int32\\\\n)\\\\n\" \\\n+               \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\\\\n\" \\\n+               \"PARTITION BY toYYYYMM(d)\\\\nORDER BY k\\\\nSETTINGS index_granularity = 8192\"\n+    assert_create_query([main_node, dummy_node], \"testdb.replicated_table\", expected)\n+    # assert without replacing uuid\n+    assert main_node.query(\"show create testdb.replicated_table\") == dummy_node.query(\"show create testdb.replicated_table\")\n+\n+@pytest.mark.parametrize(\"engine\", ['MergeTree', 'ReplicatedMergeTree'])\n+def test_simple_alter_table(started_cluster, engine):\n+    # test_simple_alter_table\n+    name  = \"testdb.alter_test_{}\".format(engine)\n+    main_node.query(\"CREATE TABLE {} \"\n+                    \"(CounterID UInt32, StartDate Date, UserID UInt32, VisitID UInt32, NestedColumn Nested(A UInt8, S String), ToDrop UInt32) \"\n+                    \"ENGINE = {} PARTITION BY StartDate ORDER BY (CounterID, StartDate, intHash32(UserID), VisitID);\".format(name, engine))\n+    main_node.query(\"ALTER TABLE {} ADD COLUMN Added0 UInt32;\".format(name))\n+    main_node.query(\"ALTER TABLE {} ADD COLUMN Added2 UInt32;\".format(name))\n+    main_node.query(\"ALTER TABLE {} ADD COLUMN Added1 UInt32 AFTER Added0;\".format(name))\n+    main_node.query(\"ALTER TABLE {} ADD COLUMN AddedNested1 Nested(A UInt32, B UInt64) AFTER Added2;\".format(name))\n+    main_node.query(\"ALTER TABLE {} ADD COLUMN AddedNested1.C Array(String) AFTER AddedNested1.B;\".format(name))\n+    main_node.query(\"ALTER TABLE {} ADD COLUMN AddedNested2 Nested(A UInt32, B UInt64) AFTER AddedNested1;\".format(name))\n+\n+    full_engine = engine if not \"Replicated\" in engine else engine + \"(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\"\n+    expected = \"CREATE TABLE {}\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\" \\\n+               \"    `VisitID` UInt32,\\\\n    `NestedColumn.A` Array(UInt8),\\\\n    `NestedColumn.S` Array(String),\\\\n\" \\\n+               \"    `ToDrop` UInt32,\\\\n    `Added0` UInt32,\\\\n    `Added1` UInt32,\\\\n    `Added2` UInt32,\\\\n\" \\\n+               \"    `AddedNested1.A` Array(UInt32),\\\\n    `AddedNested1.B` Array(UInt64),\\\\n    `AddedNested1.C` Array(String),\\\\n\" \\\n+               \"    `AddedNested2.A` Array(UInt32),\\\\n    `AddedNested2.B` Array(UInt64)\\\\n)\\\\n\" \\\n+               \"ENGINE = {}\\\\nPARTITION BY StartDate\\\\nORDER BY (CounterID, StartDate, intHash32(UserID), VisitID)\\\\n\" \\\n+               \"SETTINGS index_granularity = 8192\".format(name, full_engine)\n+\n+    assert_create_query([main_node, dummy_node], name, expected)\n+\n+    # test_create_replica_after_delay\n+    competing_node.query(\"CREATE DATABASE IF NOT EXISTS testdb ENGINE = Replicated('/clickhouse/databases/test1', 'shard1', 'replica3');\")\n+\n+    name  = \"testdb.alter_test_{}\".format(engine)\n+    main_node.query(\"ALTER TABLE {} ADD COLUMN Added3 UInt32;\".format(name))\n+    main_node.query(\"ALTER TABLE {} DROP COLUMN AddedNested1;\".format(name))\n+    main_node.query(\"ALTER TABLE {} RENAME COLUMN Added1 TO AddedNested1;\".format(name))\n+\n+    full_engine = engine if not \"Replicated\" in engine else engine + \"(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\"\n+    expected = \"CREATE TABLE {}\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\" \\\n+               \"    `VisitID` UInt32,\\\\n    `NestedColumn.A` Array(UInt8),\\\\n    `NestedColumn.S` Array(String),\\\\n\" \\\n+               \"    `ToDrop` UInt32,\\\\n    `Added0` UInt32,\\\\n    `AddedNested1` UInt32,\\\\n    `Added2` UInt32,\\\\n\" \\\n+               \"    `AddedNested2.A` Array(UInt32),\\\\n    `AddedNested2.B` Array(UInt64),\\\\n    `Added3` UInt32\\\\n)\\\\n\" \\\n+               \"ENGINE = {}\\\\nPARTITION BY StartDate\\\\nORDER BY (CounterID, StartDate, intHash32(UserID), VisitID)\\\\n\" \\\n+               \"SETTINGS index_granularity = 8192\".format(name, full_engine)\n+\n+    assert_create_query([main_node, dummy_node, competing_node], name, expected)\n+\n+\n+def test_alters_from_different_replicas(started_cluster):\n+    # test_alters_from_different_replicas\n+    competing_node.query(\"CREATE DATABASE IF NOT EXISTS testdb ENGINE = Replicated('/clickhouse/databases/test1', 'shard1', 'replica3');\")\n+\n+    main_node.query(\"CREATE TABLE testdb.concurrent_test \"\n+                    \"(CounterID UInt32, StartDate Date, UserID UInt32, VisitID UInt32, NestedColumn Nested(A UInt8, S String), ToDrop UInt32) \"\n+                    \"ENGINE = MergeTree(StartDate, intHash32(UserID), (CounterID, StartDate, intHash32(UserID), VisitID), 8192);\")\n+\n+    main_node.query(\"CREATE TABLE testdb.dist AS testdb.concurrent_test ENGINE = Distributed(cluster, testdb, concurrent_test, CounterID)\")\n+\n+    dummy_node.stop_clickhouse(kill=True)\n+\n+    settings = {\"distributed_ddl_task_timeout\": 10}\n+    assert \"There are 1 unfinished hosts (0 of them are currently active)\" in \\\n+        competing_node.query_and_get_error(\"ALTER TABLE testdb.concurrent_test ADD COLUMN Added0 UInt32;\", settings=settings)\n+    dummy_node.start_clickhouse()\n+    main_node.query(\"ALTER TABLE testdb.concurrent_test ADD COLUMN Added2 UInt32;\")\n+    competing_node.query(\"ALTER TABLE testdb.concurrent_test ADD COLUMN Added1 UInt32 AFTER Added0;\")\n+    main_node.query(\"ALTER TABLE testdb.concurrent_test ADD COLUMN AddedNested1 Nested(A UInt32, B UInt64) AFTER Added2;\")\n+    competing_node.query(\"ALTER TABLE testdb.concurrent_test ADD COLUMN AddedNested1.C Array(String) AFTER AddedNested1.B;\")\n+    main_node.query(\"ALTER TABLE testdb.concurrent_test ADD COLUMN AddedNested2 Nested(A UInt32, B UInt64) AFTER AddedNested1;\")\n+\n+    expected = \"CREATE TABLE testdb.concurrent_test\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\" \\\n+               \"    `VisitID` UInt32,\\\\n    `NestedColumn.A` Array(UInt8),\\\\n    `NestedColumn.S` Array(String),\\\\n    `ToDrop` UInt32,\\\\n\" \\\n+               \"    `Added0` UInt32,\\\\n    `Added1` UInt32,\\\\n    `Added2` UInt32,\\\\n    `AddedNested1.A` Array(UInt32),\\\\n\" \\\n+               \"    `AddedNested1.B` Array(UInt64),\\\\n    `AddedNested1.C` Array(String),\\\\n    `AddedNested2.A` Array(UInt32),\\\\n\" \\\n+               \"    `AddedNested2.B` Array(UInt64)\\\\n)\\\\n\" \\\n+               \"ENGINE = MergeTree(StartDate, intHash32(UserID), (CounterID, StartDate, intHash32(UserID), VisitID), 8192)\"\n+\n+    assert_create_query([main_node, competing_node], \"testdb.concurrent_test\", expected)\n+\n+    # test_create_replica_after_delay\n+    main_node.query(\"DROP TABLE testdb.concurrent_test\")\n+    main_node.query(\"CREATE TABLE testdb.concurrent_test \"\n+                    \"(CounterID UInt32, StartDate Date, UserID UInt32, VisitID UInt32, NestedColumn Nested(A UInt8, S String), ToDrop UInt32) \"\n+                    \"ENGINE = ReplicatedMergeTree ORDER BY CounterID;\")\n+\n+    expected = \"CREATE TABLE testdb.concurrent_test\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\" \\\n+               \"    `VisitID` UInt32,\\\\n    `NestedColumn.A` Array(UInt8),\\\\n    `NestedColumn.S` Array(String),\\\\n    `ToDrop` UInt32\\\\n)\\\\n\" \\\n+               \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\\\\nORDER BY CounterID\\\\nSETTINGS index_granularity = 8192\"\n+\n+    assert_create_query([main_node, competing_node], \"testdb.concurrent_test\", expected)\n+\n+    main_node.query(\"INSERT INTO testdb.dist (CounterID, StartDate, UserID) SELECT number, addDays(toDate('2020-02-02'), number), intHash32(number) FROM numbers(10)\")\n+\n+    # test_replica_restart\n+    main_node.restart_clickhouse()\n+\n+    expected = \"CREATE TABLE testdb.concurrent_test\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\" \\\n+               \"    `VisitID` UInt32,\\\\n    `NestedColumn.A` Array(UInt8),\\\\n    `NestedColumn.S` Array(String),\\\\n    `ToDrop` UInt32\\\\n)\\\\n\" \\\n+               \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\\\\nORDER BY CounterID\\\\nSETTINGS index_granularity = 8192\"\n+\n+\n+    # test_snapshot_and_snapshot_recover\n+    snapshotting_node.query(\"CREATE DATABASE testdb ENGINE = Replicated('/clickhouse/databases/test1', 'shard2', 'replica1');\")\n+    snapshot_recovering_node.query(\"CREATE DATABASE testdb ENGINE = Replicated('/clickhouse/databases/test1', 'shard2', 'replica2');\")\n+    assert_create_query(all_nodes, \"testdb.concurrent_test\", expected)\n+\n+    main_node.query(\"SYSTEM FLUSH DISTRIBUTED testdb.dist\")\n+    main_node.query(\"ALTER TABLE testdb.concurrent_test UPDATE StartDate = addYears(StartDate, 1) WHERE 1\")\n+    res = main_node.query(\"ALTER TABLE testdb.concurrent_test DELETE WHERE UserID % 2\")\n+    assert \"shard1|replica1\" in res and \"shard1|replica2\" in res and \"shard1|replica3\" in res\n+    assert \"shard2|replica1\" in res and \"shard2|replica2\" in res\n+\n+    expected = \"1\\t1\\tmain_node\\n\" \\\n+               \"1\\t2\\tdummy_node\\n\" \\\n+               \"1\\t3\\tcompeting_node\\n\" \\\n+               \"2\\t1\\tsnapshotting_node\\n\" \\\n+               \"2\\t2\\tsnapshot_recovering_node\\n\"\n+    assert main_node.query(\"SELECT shard_num, replica_num, host_name FROM system.clusters WHERE cluster='testdb'\") == expected\n+\n+    # test_drop_and_create_replica\n+    main_node.query(\"DROP DATABASE testdb SYNC\")\n+    main_node.query(\"CREATE DATABASE testdb ENGINE = Replicated('/clickhouse/databases/test1', 'shard1', 'replica1');\")\n+\n+    expected = \"CREATE TABLE testdb.concurrent_test\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\" \\\n+               \"    `VisitID` UInt32,\\\\n    `NestedColumn.A` Array(UInt8),\\\\n    `NestedColumn.S` Array(String),\\\\n    `ToDrop` UInt32\\\\n)\\\\n\" \\\n+               \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\\\\nORDER BY CounterID\\\\nSETTINGS index_granularity = 8192\"\n+\n+    assert_create_query([main_node, competing_node], \"testdb.concurrent_test\", expected)\n+    assert_create_query(all_nodes, \"testdb.concurrent_test\", expected)\n+\n+    for node in all_nodes:\n+        node.query(\"SYSTEM SYNC REPLICA testdb.concurrent_test\")\n+\n+    expected = \"0\\t2021-02-02\\t4249604106\\n\" \\\n+               \"1\\t2021-02-03\\t1343103100\\n\" \\\n+               \"4\\t2021-02-06\\t3902320246\\n\" \\\n+               \"7\\t2021-02-09\\t3844986530\\n\" \\\n+               \"9\\t2021-02-11\\t1241149650\\n\"\n+\n+    assert_eq_with_retry(dummy_node, \"SELECT CounterID, StartDate, UserID FROM testdb.dist ORDER BY CounterID\", expected)\n+\n+def test_recover_staled_replica(started_cluster):\n+    main_node.query(\"CREATE DATABASE recover ENGINE = Replicated('/clickhouse/databases/recover', 'shard1', 'replica1');\")\n+    started_cluster.get_kazoo_client('zoo1').set('/clickhouse/databases/recover/logs_to_keep', b'10')\n+    dummy_node.query(\"CREATE DATABASE recover ENGINE = Replicated('/clickhouse/databases/recover', 'shard1', 'replica2');\")\n+\n+    settings = {\"distributed_ddl_task_timeout\": 0}\n+    main_node.query(\"CREATE TABLE recover.t1 (n int) ENGINE=Memory\", settings=settings)\n+    dummy_node.query(\"CREATE TABLE recover.t2 (s String) ENGINE=Memory\", settings=settings)\n+    main_node.query(\"CREATE TABLE recover.mt1 (n int) ENGINE=MergeTree order by n\", settings=settings)\n+    dummy_node.query(\"CREATE TABLE recover.mt2 (n int) ENGINE=MergeTree order by n\", settings=settings)\n+    main_node.query(\"CREATE TABLE recover.rmt1 (n int) ENGINE=ReplicatedMergeTree order by n\", settings=settings)\n+    dummy_node.query(\"CREATE TABLE recover.rmt2 (n int) ENGINE=ReplicatedMergeTree order by n\", settings=settings)\n+    main_node.query(\"CREATE TABLE recover.rmt3 (n int) ENGINE=ReplicatedMergeTree order by n\", settings=settings)\n+    dummy_node.query(\"CREATE TABLE recover.rmt5 (n int) ENGINE=ReplicatedMergeTree order by n\", settings=settings)\n+    main_node.query(\"CREATE DICTIONARY recover.d1 (n int DEFAULT 0, m int DEFAULT 1) PRIMARY KEY n SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'rmt1' PASSWORD '' DB 'recover')) LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT())\")\n+    dummy_node.query(\"CREATE DICTIONARY recover.d2 (n int DEFAULT 0, m int DEFAULT 1) PRIMARY KEY n SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'rmt2' PASSWORD '' DB 'recover')) LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT())\")\n+\n+    for table in ['t1', 't2', 'mt1', 'mt2', 'rmt1', 'rmt2', 'rmt3', 'rmt5']:\n+        main_node.query(\"INSERT INTO recover.{} VALUES (42)\".format(table))\n+    for table in ['t1', 't2', 'mt1', 'mt2']:\n+        dummy_node.query(\"INSERT INTO recover.{} VALUES (42)\".format(table))\n+    for table in ['rmt1', 'rmt2', 'rmt3', 'rmt5']:\n+        main_node.query(\"SYSTEM SYNC REPLICA recover.{}\".format(table))\n+\n+    with PartitionManager() as pm:\n+        pm.drop_instance_zk_connections(dummy_node)\n+        dummy_node.query_and_get_error(\"RENAME TABLE recover.t1 TO recover.m1\")\n+        main_node.query(\"RENAME TABLE recover.t1 TO recover.m1\", settings=settings)\n+        main_node.query(\"ALTER TABLE recover.mt1  ADD COLUMN m int\", settings=settings)\n+        main_node.query(\"ALTER TABLE recover.rmt1 ADD COLUMN m int\", settings=settings)\n+        main_node.query(\"RENAME TABLE recover.rmt3 TO recover.rmt4\", settings=settings)\n+        main_node.query(\"DROP TABLE recover.rmt5\", settings=settings)\n+        main_node.query(\"DROP DICTIONARY recover.d2\", settings=settings)\n+        main_node.query(\"CREATE DICTIONARY recover.d2 (n int DEFAULT 0, m int DEFAULT 1) PRIMARY KEY n SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'rmt1' PASSWORD '' DB 'recover')) LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT());\", settings=settings)\n+\n+        main_node.query(\"CREATE TABLE recover.tmp AS recover.m1\", settings=settings)\n+        main_node.query(\"DROP TABLE recover.tmp\", settings=settings)\n+        main_node.query(\"CREATE TABLE recover.tmp AS recover.m1\", settings=settings)\n+        main_node.query(\"DROP TABLE recover.tmp\", settings=settings)\n+        main_node.query(\"CREATE TABLE recover.tmp AS recover.m1\", settings=settings)\n+        main_node.query(\"DROP TABLE recover.tmp\", settings=settings)\n+        main_node.query(\"CREATE TABLE recover.tmp AS recover.m1\", settings=settings)\n+\n+    assert main_node.query(\"SELECT name FROM system.tables WHERE database='recover' ORDER BY name\") == \"d1\\nd2\\nm1\\nmt1\\nmt2\\nrmt1\\nrmt2\\nrmt4\\nt2\\ntmp\\n\"\n+    query = \"SELECT name, uuid, create_table_query FROM system.tables WHERE database='recover' ORDER BY name\"\n+    expected = main_node.query(query)\n+    assert_eq_with_retry(dummy_node, query, expected)\n+\n+    for table in ['m1', 't2', 'mt1', 'mt2', 'rmt1', 'rmt2', 'rmt4', 'd1', 'd2']:\n+        assert main_node.query(\"SELECT (*,).1 FROM recover.{}\".format(table)) == \"42\\n\"\n+    for table in ['t2', 'rmt1', 'rmt2', 'rmt4', 'd1', 'd2', 'mt2']:\n+        assert dummy_node.query(\"SELECT (*,).1 FROM recover.{}\".format(table)) == \"42\\n\"\n+    for table in ['m1', 'mt1']:\n+        assert dummy_node.query(\"SELECT count() FROM recover.{}\".format(table)) == \"0\\n\"\n+\n+    assert dummy_node.query(\"SELECT count() FROM system.tables WHERE database='recover_broken_tables'\") == \"2\\n\"\n+    table = dummy_node.query(\"SHOW TABLES FROM recover_broken_tables LIKE 'mt1_26_%'\").strip()\n+    assert dummy_node.query(\"SELECT (*,).1 FROM recover_broken_tables.{}\".format(table)) == \"42\\n\"\n+    table = dummy_node.query(\"SHOW TABLES FROM recover_broken_tables LIKE 'rmt5_26_%'\").strip()\n+    assert dummy_node.query(\"SELECT (*,).1 FROM recover_broken_tables.{}\".format(table)) == \"42\\n\"\n+\n+    expected = \"Cleaned 4 outdated objects: dropped 1 dictionaries and 1 tables, moved 2 tables\"\n+    assert_logs_contain(dummy_node, expected)\n+\n+    dummy_node.query(\"DROP TABLE recover.tmp\")\n+    assert_eq_with_retry(main_node, \"SELECT count() FROM system.tables WHERE database='recover' AND name='tmp'\", \"0\\n\")\n+\n+def test_startup_without_zk(started_cluster):\n+    main_node.query(\"DROP DATABASE IF EXISTS testdb SYNC\")\n+    main_node.query(\"DROP DATABASE IF EXISTS recover SYNC\")\n+    with PartitionManager() as pm:\n+        pm.drop_instance_zk_connections(main_node)\n+        err = main_node.query_and_get_error(\"CREATE DATABASE startup ENGINE = Replicated('/clickhouse/databases/startup', 'shard1', 'replica1');\")\n+        assert \"ZooKeeper\" in err\n+    main_node.query(\"CREATE DATABASE startup ENGINE = Replicated('/clickhouse/databases/startup', 'shard1', 'replica1');\")\n+    #main_node.query(\"CREATE TABLE startup.rmt (n int) ENGINE=ReplicatedMergeTree order by n\")\n+    main_node.query(\"CREATE TABLE startup.rmt (n int) ENGINE=MergeTree order by n\")\n+    main_node.query(\"INSERT INTO startup.rmt VALUES (42)\")\n+    with PartitionManager() as pm:\n+        pm.drop_instance_zk_connections(main_node)\n+        main_node.restart_clickhouse(stop_start_wait_sec=30)\n+        assert main_node.query(\"SELECT (*,).1 FROM startup.rmt\") == \"42\\n\"\n+\n+    for _ in range(10):\n+        try:\n+            main_node.query(\"CREATE TABLE startup.m (n int) ENGINE=Memory\")\n+            break\n+        except:\n+            time.sleep(1)\n+\n+    main_node.query(\"EXCHANGE TABLES startup.rmt AND startup.m\")\n+    assert main_node.query(\"SELECT (*,).1 FROM startup.m\") == \"42\\n\"\ndiff --git a/tests/queries/0_stateless/01018_ddl_dictionaries_concurrent_requrests.sh b/tests/queries/0_stateless/01018_ddl_dictionaries_concurrent_requrests.sh\nindex bc13e44934a8..025fe51e2a9c 100755\n--- a/tests/queries/0_stateless/01018_ddl_dictionaries_concurrent_requrests.sh\n+++ b/tests/queries/0_stateless/01018_ddl_dictionaries_concurrent_requrests.sh\n@@ -113,8 +113,8 @@ timeout $TIMEOUT bash -c thread7 2> /dev/null &\n wait\n $CLICKHOUSE_CLIENT -q \"SELECT 'Still alive'\"\n \n-$CLICKHOUSE_CLIENT -q \"ATTACH DICTIONARY database_for_dict.dict1\"\n-$CLICKHOUSE_CLIENT -q \"ATTACH DICTIONARY database_for_dict.dict2\"\n+$CLICKHOUSE_CLIENT -q \"ATTACH DICTIONARY IF NOT EXISTS database_for_dict.dict1\"\n+$CLICKHOUSE_CLIENT -q \"ATTACH DICTIONARY IF NOT EXISTS database_for_dict.dict2\"\n \n $CLICKHOUSE_CLIENT -n -q \"\n     DROP TABLE table_for_dict1;\ndiff --git a/tests/queries/0_stateless/01238_http_memory_tracking.sh b/tests/queries/0_stateless/01238_http_memory_tracking.sh\nindex 90a7611c7c79..8c900e4c2088 100755\n--- a/tests/queries/0_stateless/01238_http_memory_tracking.sh\n+++ b/tests/queries/0_stateless/01238_http_memory_tracking.sh\n@@ -18,3 +18,6 @@ yes 'SELECT 1' 2>/dev/null | {\n } | grep -x -c 1\n \n wait\n+\n+# Reset max_memory_usage_for_user, so it will not affect other tests\n+${CLICKHOUSE_CLIENT} --max_memory_usage_for_user=0 -q \"SELECT 1 FORMAT Null\"\ndiff --git a/tests/queries/0_stateless/01281_group_by_limit_memory_tracking.sh b/tests/queries/0_stateless/01281_group_by_limit_memory_tracking.sh\nindex 9909d9b566d7..4667c76cb607 100755\n--- a/tests/queries/0_stateless/01281_group_by_limit_memory_tracking.sh\n+++ b/tests/queries/0_stateless/01281_group_by_limit_memory_tracking.sh\n@@ -42,3 +42,6 @@ execute_group_by\n # if memory accounting will be incorrect, the second query will be failed with MEMORY_LIMIT_EXCEEDED\n execute_group_by\n wait\n+\n+# Reset max_memory_usage_for_user, so it will not affect other tests\n+${CLICKHOUSE_CLIENT} --max_memory_usage_for_user=0 -q \"SELECT 1 FORMAT Null\"\ndiff --git a/tests/queries/0_stateless/01541_max_memory_usage_for_user.reference b/tests/queries/0_stateless/01541_max_memory_usage_for_user_long.reference\nsimilarity index 100%\nrename from tests/queries/0_stateless/01541_max_memory_usage_for_user.reference\nrename to tests/queries/0_stateless/01541_max_memory_usage_for_user_long.reference\ndiff --git a/tests/queries/0_stateless/01541_max_memory_usage_for_user.sh b/tests/queries/0_stateless/01541_max_memory_usage_for_user_long.sh\nsimilarity index 94%\nrename from tests/queries/0_stateless/01541_max_memory_usage_for_user.sh\nrename to tests/queries/0_stateless/01541_max_memory_usage_for_user_long.sh\nindex c81bd1a6ce4b..32877bfd0fe6 100755\n--- a/tests/queries/0_stateless/01541_max_memory_usage_for_user.sh\n+++ b/tests/queries/0_stateless/01541_max_memory_usage_for_user_long.sh\n@@ -66,4 +66,7 @@ echo 'OK'\n \n ${CLICKHOUSE_CLIENT} --query \"DROP USER test_01541\";\n \n+# Reset max_memory_usage_for_user, so it will not affect other tests\n+${CLICKHOUSE_CLIENT} --max_memory_usage_for_user=0 -q \"SELECT 1 FORMAT Null\"\n+\n exit 0\ndiff --git a/tests/queries/skip_list.json b/tests/queries/skip_list.json\nindex fdb845b7e723..77c4d4870822 100644\n--- a/tests/queries/skip_list.json\n+++ b/tests/queries/skip_list.json\n@@ -102,6 +102,158 @@\n         \"00510_materizlized_view_and_deduplication_zookeeper\",\n         \"00738_lock_for_inner_table\"\n     ],\n+    \"database-replicated\": [\n+        /// Tests with DETACH TABLE (it's not allowed)\n+        /// and tests with SET (session and query settings are not supported)\n+        \"memory_tracking\",\n+        \"memory_usage\",\n+        \"live_view\",\n+        \"00825_protobuf_format_map\",\n+        \"00152_insert_different_granularity\",\n+        \"01715_background_checker_blather_zookeeper\",\n+        \"01714_alter_drop_version\",\n+        \"01114_materialize_clear_index_compact_parts\",\n+        \"00814_replicated_minimalistic_part_header_zookeeper\",\n+        \"01188_attach_table_from_pat\",\n+        \"01415_sticking_mutations\",\n+        \"01130_in_memory_parts\",\n+        \"01110_dictionary_layout_without_arguments\",\n+        \"01018_ddl_dictionaries_create\",\n+        \"01018_ddl_dictionaries_select\",\n+        \"01414_freeze_does_not_prevent_alters\",\n+        \"01018_ddl_dictionaries_bad_queries\",\n+        \"01686_rocksdb\",\n+        \"01550_mutation_subquery\",\n+        \"01070_mutations_with_dependencies\",\n+        \"01070_materialize_ttl\",\n+        \"01055_compact_parts\",\n+        \"01017_mutations_with_nondeterministic_functions_zookeeper\",\n+        \"00926_adaptive_index_granularity_pk\",\n+        \"00910_zookeeper_test_alter_compression_codecs\",\n+        \"00908_bloom_filter_index\",\n+        \"00616_final_single_part\",\n+        \"00446_clear_column_in_partition_zookeeper\",\n+        \"01533_multiple_nested\",\n+        \"01213_alter_rename_column_zookeeper\",\n+        \"01575_disable_detach_table_of_dictionary\",\n+        \"01457_create_as_table_function_structure\",\n+        \"01415_inconsistent_merge_tree_settings\",\n+        \"01413_allow_non_metadata_alters\",\n+        \"01378_alter_rename_with_ttl_zookeeper\",\n+        \"01349_mutation_datetime_key\",\n+        \"01325_freeze_mutation_stuck\",\n+        \"01272_suspicious_codecs\",\n+        \"01181_db_atomic_drop_on_cluster\",\n+        \"00957_delta_diff_bug\",\n+        \"00910_zookeeper_custom_compression_codecs_replicated\",\n+        \"00899_long_attach_memory_limit\",\n+        \"00804_test_custom_compression_codes_log_storages\",\n+        \"00804_test_alter_compression_codecs\",\n+        \"00804_test_delta_codec_no_type_alter\",\n+        \"00804_test_custom_compression_codecs\",\n+        \"00753_alter_attach\",\n+        \"00715_fetch_merged_or_mutated_part_zookeeper\",\n+        \"00688_low_cardinality_serialization\",\n+        \"01575_disable_detach_table_of_dictionary\",\n+        \"00738_lock_for_inner_table\",\n+        \"01666_blns\",\n+        \"01652_ignore_and_low_cardinality\",\n+        \"01651_map_functions\",\n+        \"01650_fetch_patition_with_macro_in_zk_path\",\n+        \"01648_mutations_and_escaping\",\n+        \"01640_marks_corruption_regression\",\n+        \"01622_byte_size\",\n+        \"01611_string_to_low_cardinality_key_alter\",\n+        \"01602_show_create_view\",\n+        \"01600_log_queries_with_extensive_info\",\n+        \"01560_ttl_remove_empty_parts\",\n+        \"01554_bloom_filter_index_big_integer_uuid\",\n+        \"01550_type_map_formats_input\",\n+        \"01550_type_map_formats\",\n+        \"01550_create_map_type\",\n+        \"01532_primary_key_without_order_by_zookeeper\",\n+        \"01511_alter_version_versioned_collapsing_merge_tree_zookeeper\",\n+        \"01509_parallel_quorum_insert_no_replicas\",\n+        \"01504_compression_multiple_streams\",\n+        \"01494_storage_join_persistency\",\n+        \"01493_storage_set_persistency\",\n+        \"01493_alter_remove_properties_zookeeper\",\n+        \"01475_read_subcolumns_storages\",\n+        \"01475_read_subcolumns\",\n+        \"01451_replicated_detach_drop_part\",\n+        \"01451_detach_drop_part\",\n+        \"01440_big_int_exotic_casts\",\n+        \"01430_modify_sample_by_zookeeper\",\n+        \"01417_freeze_partition_verbose_zookeeper\",\n+        \"01417_freeze_partition_verbose\",\n+        \"01396_inactive_replica_cleanup_nodes_zookeeper\",\n+        \"01375_compact_parts_codecs\",\n+        \"01357_version_collapsing_attach_detach_zookeeper\",\n+        \"01355_alter_column_with_order\",\n+        \"01291_geo_types\",\n+        \"01270_optimize_skip_unused_shards_low_cardinality\",\n+        \"01182_materialized_view_different_structure\",\n+        \"01150_ddl_guard_rwr\",\n+        \"01148_zookeeper_path_macros_unfolding\",\n+        \"01135_default_and_alter_zookeeper\",\n+        \"01130_in_memory_parts_partitons\",\n+        \"01127_month_partitioning_consistency_select\",\n+        \"01114_database_atomic\",\n+        \"01083_expressions_in_engine_arguments\",\n+        \"01073_attach_if_not_exists\",\n+        \"01072_optimize_skip_unused_shards_const_expr_eval\",\n+        \"01071_prohibition_secondary_index_with_old_format_merge_tree\",\n+        \"01062_alter_on_mutataion_zookeeper\",\n+        \"01060_shutdown_table_after_detach\",\n+        \"01056_create_table_as\",\n+        \"01035_avg\",\n+        \"01021_only_tuple_columns\",\n+        \"01019_alter_materialized_view_query\",\n+        \"01019_alter_materialized_view_consistent\",\n+        \"01019_alter_materialized_view_atomic\",\n+        \"01015_attach_part\",\n+        \"00989_parallel_parts_loading\",\n+        \"00980_zookeeper_merge_tree_alter_settings\",\n+        \"00980_merge_alter_settings\",\n+        \"00955_test_final_mark\",\n+        \"00933_reserved_word\",\n+        \"00926_zookeeper_adaptive_index_granularity_replicated_merge_tree\",\n+        \"00926_adaptive_index_granularity_replacing_merge_tree\",\n+        \"00926_adaptive_index_granularity_merge_tree\",\n+        \"00925_zookeeper_empty_replicated_merge_tree_optimize_final\",\n+        \"00800_low_cardinality_distinct_numeric\",\n+        \"00754_alter_modify_order_by_replicated_zookeeper\",\n+        \"00751_low_cardinality_nullable_group_by\",\n+        \"00751_default_databasename_for_view\",\n+        \"00719_parallel_ddl_table\",\n+        \"00718_low_cardinaliry_alter\",\n+        \"00717_low_cardinaliry_distributed_group_by\",\n+        \"00688_low_cardinality_syntax\",\n+        \"00688_low_cardinality_nullable_cast\",\n+        \"00688_low_cardinality_in\",\n+        \"00652_replicated_mutations_zookeeper\",\n+        \"00634_rename_view\",\n+        \"00626_replace_partition_from_table\",\n+        \"00625_arrays_in_nested\",\n+        \"00623_replicated_truncate_table_zookeeper\",\n+        \"00619_union_highlite\",\n+        \"00599_create_view_with_subquery\",\n+        \"00571_non_exist_database_when_create_materializ_view\",\n+        \"00553_buff_exists_materlized_column\",\n+        \"00516_deduplication_after_drop_partition_zookeeper\",\n+        \"00508_materialized_view_to\",\n+        \"00446_clear_column_in_partition_concurrent_zookeeper\",\n+        \"00423_storage_log_single_thread\",\n+        \"00311_array_primary_key\",\n+        \"00236_replicated_drop_on_non_leader_zookeeper\",\n+        \"00226_zookeeper_deduplication_and_unexpected_parts\",\n+        \"00215_primary_key_order_zookeeper\",\n+        \"00180_attach_materialized_view\",\n+        \"00121_drop_column_zookeeper\",\n+        \"00116_storage_set\",\n+        \"00083_create_merge_tree_zookeeper\",\n+        \"00062_replicated_merge_tree_alter_zookeeper\"\n+    ],\n     \"polymorphic-parts\": [\n         \"01508_partition_pruning_long\", /// bug, shoud be fixed\n         \"01482_move_to_prewhere_and_cast\" /// bug, shoud be fixed\n@@ -158,6 +310,7 @@\n         \"01015_attach_part\",\n         \"01015_database_bad_tables\",\n         \"01017_uniqCombined_memory_usage\",\n+        \"01018_ddl_dictionaries_concurrent_requrests\",  /// Cannot parse ATTACH DICTIONARY IF NOT EXISTS\n         \"01019_alter_materialized_view_atomic\",\n         \"01019_alter_materialized_view_consistent\",\n         \"01019_alter_materialized_view_query\",\n@@ -287,7 +440,7 @@\n         \"01530_drop_database_atomic_sync\",\n         \"01532_execute_merges_on_single_replica\",\n         \"01532_primary_key_without_order_by_zookeeper\",\n-        \"01541_max_memory_usage_for_user\",\n+        \"01541_max_memory_usage_for_user_long\",\n         \"01551_mergetree_read_in_order_spread\",\n         \"01552_dict_fixedstring\",\n         \"01554_bloom_filter_index_big_integer_uuid\",\n@@ -564,7 +717,7 @@\n         \"01527_clickhouse_local_optimize\",\n         \"01527_dist_sharding_key_dictGet_reload\",\n         \"01530_drop_database_atomic_sync\",\n-        \"01541_max_memory_usage_for_user\",\n+        \"01541_max_memory_usage_for_user_long\",\n         \"01542_dictionary_load_exception_race\",\n         \"01575_disable_detach_table_of_dictionary\",\n         \"01593_concurrent_alter_mutations_kill\",\n",
  "problem_statement": "DatabaseReplicated\nDatabase engine that stores tables metadata (.sql files) and modification log (DDL operations) in ZooKeeper. Replicas will replicate changes in metadata.\r\n\r\nQuestionable.\n",
  "hints_text": "@ValBaturin",
  "created_at": "2020-10-20T16:20:07Z",
  "modified_files": [
    "programs/server/Server.cpp",
    "src/Common/ErrorCodes.cpp",
    "src/Common/ZooKeeper/IKeeper.cpp",
    "src/Common/ZooKeeper/ZooKeeper.h",
    "src/Core/Settings.h",
    "src/Databases/DatabaseAtomic.cpp",
    "src/Databases/DatabaseAtomic.h",
    "src/Databases/DatabaseFactory.cpp",
    "src/Databases/DatabaseOnDisk.cpp",
    "src/Databases/DatabaseOnDisk.h",
    "src/Databases/DatabaseOrdinary.cpp",
    "src/Databases/DatabaseOrdinary.h",
    "b/src/Databases/DatabaseReplicated.cpp",
    "b/src/Databases/DatabaseReplicated.h",
    "b/src/Databases/DatabaseReplicatedSettings.cpp",
    "b/src/Databases/DatabaseReplicatedSettings.h",
    "b/src/Databases/DatabaseReplicatedWorker.cpp",
    "b/src/Databases/DatabaseReplicatedWorker.h",
    "src/Databases/DatabaseWithDictionaries.cpp",
    "src/Databases/IDatabase.h",
    "src/Databases/MySQL/DatabaseConnectionMySQL.cpp",
    "src/Databases/MySQL/DatabaseConnectionMySQL.h",
    "src/Databases/ya.make",
    "src/Interpreters/Context.cpp",
    "src/Interpreters/Context.h",
    "b/src/Interpreters/DDLTask.cpp",
    "b/src/Interpreters/DDLTask.h",
    "src/Interpreters/DDLWorker.cpp",
    "src/Interpreters/DDLWorker.h",
    "src/Interpreters/DatabaseCatalog.cpp",
    "src/Interpreters/DatabaseCatalog.h",
    "src/Interpreters/InterpreterAlterQuery.cpp",
    "src/Interpreters/InterpreterCreateQuery.cpp",
    "src/Interpreters/InterpreterCreateQuery.h",
    "src/Interpreters/InterpreterCreateQuotaQuery.cpp",
    "src/Interpreters/InterpreterCreateRoleQuery.cpp",
    "src/Interpreters/InterpreterCreateRowPolicyQuery.cpp",
    "src/Interpreters/InterpreterCreateSettingsProfileQuery.cpp",
    "src/Interpreters/InterpreterCreateUserQuery.cpp",
    "src/Interpreters/InterpreterDropAccessEntityQuery.cpp",
    "src/Interpreters/InterpreterDropQuery.cpp",
    "src/Interpreters/InterpreterGrantQuery.cpp",
    "src/Interpreters/InterpreterKillQueryQuery.cpp",
    "src/Interpreters/InterpreterOptimizeQuery.cpp",
    "src/Interpreters/InterpreterRenameQuery.cpp",
    "src/Interpreters/InterpreterRenameQuery.h",
    "src/Interpreters/InterpreterSystemQuery.cpp",
    "src/Interpreters/SystemLog.h",
    "b/src/Interpreters/executeDDLQueryOnCluster.cpp",
    "b/src/Interpreters/executeDDLQueryOnCluster.h",
    "src/Interpreters/ya.make",
    "src/Parsers/ASTAlterQuery.cpp",
    "src/Parsers/ASTAlterQuery.h",
    "src/Storages/MergeTree/registerStorageMergeTree.cpp",
    "src/Storages/StorageMaterializedView.cpp",
    "src/Storages/StorageMaterializedView.h",
    "src/Storages/StorageReplicatedMergeTree.cpp",
    "src/Storages/StorageReplicatedMergeTree.h",
    "src/Storages/System/StorageSystemClusters.cpp",
    "src/Storages/System/StorageSystemClusters.h",
    "src/Storages/System/StorageSystemDDLWorkerQueue.cpp"
  ],
  "modified_test_files": [
    "docker/test/fasttest/run.sh",
    "docker/test/stateful/run.sh",
    "docker/test/stateless/run.sh",
    "docker/test/stress/stress",
    "tests/ci/ci_config.json",
    "tests/clickhouse-test",
    "tests/config/install.sh",
    "b/tests/config/users.d/database_replicated.xml",
    "tests/integration/helpers/test_tools.py",
    "b/tests/integration/test_replicated_database/configs/config.xml",
    "b/tests/integration/test_replicated_database/configs/settings.xml",
    "b/tests/integration/test_replicated_database/test.py",
    "tests/queries/0_stateless/01018_ddl_dictionaries_concurrent_requrests.sh",
    "tests/queries/0_stateless/01238_http_memory_tracking.sh",
    "tests/queries/0_stateless/01281_group_by_limit_memory_tracking.sh",
    "tests/queries/0_stateless/01541_max_memory_usage_for_user.sh",
    "tests/queries/skip_list.json"
  ]
}