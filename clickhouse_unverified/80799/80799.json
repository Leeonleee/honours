{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 80799,
  "instance_id": "ClickHouse__ClickHouse-80799",
  "issue_numbers": [
    "60989"
  ],
  "base_commit": "efe34be9a2d8c1ad85429161beb28aa7f18f4145",
  "patch": "diff --git a/src/Common/CacheBase.h b/src/Common/CacheBase.h\nindex 27b6a190c7f4..de1df4940e64 100644\n--- a/src/Common/CacheBase.h\n+++ b/src/Common/CacheBase.h\n@@ -64,7 +64,10 @@ class CacheBase\n         size_t max_count,\n         double size_ratio)\n     {\n-        auto on_weight_loss_function = [&](size_t weight_loss) { onRemoveOverflowWeightLoss(weight_loss); };\n+        auto on_remove_entry_function = [this](size_t weight_loss, const MappedPtr & mapped_ptr)\n+        {\n+            onEntryRemoval(weight_loss, mapped_ptr);\n+        };\n \n         if (cache_policy_name.empty())\n         {\n@@ -75,12 +78,12 @@ class CacheBase\n         if (cache_policy_name == \"LRU\")\n         {\n             using LRUPolicy = LRUCachePolicy<TKey, TMapped, HashFunction, WeightFunction>;\n-            cache_policy = std::make_unique<LRUPolicy>(size_in_bytes_metric, count_metric, max_size_in_bytes, max_count, on_weight_loss_function);\n+            cache_policy = std::make_unique<LRUPolicy>(size_in_bytes_metric, count_metric, max_size_in_bytes, max_count, on_remove_entry_function);\n         }\n         else if (cache_policy_name == \"SLRU\")\n         {\n             using SLRUPolicy = SLRUCachePolicy<TKey, TMapped, HashFunction, WeightFunction>;\n-            cache_policy = std::make_unique<SLRUPolicy>(size_in_bytes_metric, count_metric, max_size_in_bytes, max_count, size_ratio, on_weight_loss_function);\n+            cache_policy = std::make_unique<SLRUPolicy>(size_in_bytes_metric, count_metric, max_size_in_bytes, max_count, size_ratio, on_remove_entry_function);\n         }\n         else\n             throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unknown cache policy name: {}\", cache_policy_name);\n@@ -335,8 +338,9 @@ class CacheBase\n \n     InsertTokenById insert_tokens TSA_GUARDED_BY(mutex);\n \n-    /// Override this method if you want to track how much weight was lost in removeOverflow method.\n-    virtual void onRemoveOverflowWeightLoss(size_t /*weight_loss*/) {}\n+    /// This is called when an entry is being evicted from the cache.\n+    /// Override this method if you want to handle individual entry removals from cache\n+    virtual void onEntryRemoval(size_t /*weight_loss*/, const MappedPtr &) { }\n };\n \n \ndiff --git a/src/Common/ICachePolicy.h b/src/Common/ICachePolicy.h\nindex f764f15b4f6b..990321a8b4a4 100644\n--- a/src/Common/ICachePolicy.h\n+++ b/src/Common/ICachePolicy.h\n@@ -26,7 +26,7 @@ class ICachePolicy\n     using Key = TKey;\n     using Mapped = TMapped;\n     using MappedPtr = std::shared_ptr<Mapped>;\n-    using OnWeightLossFunction = std::function<void(size_t)>;\n+    using OnRemoveEntryFunction = std::function<void(size_t, const MappedPtr &)>;  /// For per-item callback\n \n     struct KeyMapped\n     {\ndiff --git a/src/Common/LRUCachePolicy.h b/src/Common/LRUCachePolicy.h\nindex ea87272d835e..124eca84d7e2 100644\n--- a/src/Common/LRUCachePolicy.h\n+++ b/src/Common/LRUCachePolicy.h\n@@ -21,7 +21,7 @@ class LRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n     using Base = ICachePolicy<Key, Mapped, HashFunction, WeightFunction>;\n     using typename Base::MappedPtr;\n     using typename Base::KeyMapped;\n-    using typename Base::OnWeightLossFunction;\n+    using typename Base::OnRemoveEntryFunction;\n \n     /** Initialize LRUCachePolicy with max_size_in_bytes and max_count.\n      *  max_size_in_bytes == 0 means the cache accepts no entries.\n@@ -32,13 +32,13 @@ class LRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n         CurrentMetrics::Metric count_metric_,\n         size_t max_size_in_bytes_,\n         size_t max_count_,\n-        OnWeightLossFunction on_weight_loss_function_)\n+        OnRemoveEntryFunction on_remove_entry_function_)\n         : Base(std::make_unique<NoCachePolicyUserQuota>())\n         , max_size_in_bytes(max_size_in_bytes_)\n         , max_count(max_count_)\n         , current_size_in_bytes_metric(size_in_bytes_metric_)\n         , count_metric(count_metric_)\n-        , on_weight_loss_function(on_weight_loss_function_)\n+        , on_remove_entry_function(on_remove_entry_function_)\n     {\n     }\n \n@@ -221,7 +221,7 @@ class LRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n     CurrentMetrics::Metric count_metric;\n \n     WeightFunction weight_function;\n-    OnWeightLossFunction on_weight_loss_function;\n+    OnRemoveEntryFunction on_remove_entry_function;\n \n     void removeOverflow()\n     {\n@@ -243,14 +243,13 @@ class LRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n \n             current_size_in_bytes -= cell.size;\n             current_weight_lost += cell.size;\n+            on_remove_entry_function(cell.size, cell.value);\n \n             cells.erase(it);\n             queue.pop_front();\n             --queue_size;\n         }\n \n-        on_weight_loss_function(current_weight_lost);\n-\n         if (current_size_in_bytes > (1ull << 63))\n             std::terminate(); // Queue became inconsistent\n \ndiff --git a/src/Common/PageCache.cpp b/src/Common/PageCache.cpp\nindex f74652c10f22..01cd629b89ec 100644\n--- a/src/Common/PageCache.cpp\n+++ b/src/Common/PageCache.cpp\n@@ -145,9 +145,10 @@ bool PageCache::contains(const PageCacheKey & key, bool inject_eviction) const\n     return shard.contains(key_hash);\n }\n \n-void PageCache::Shard::onRemoveOverflowWeightLoss(size_t weight_loss)\n+void PageCache::Shard::onEntryRemoval(const size_t weight_loss, const MappedPtr & mapped_ptr)\n {\n     ProfileEvents::increment(ProfileEvents::PageCacheWeightLost, weight_loss);\n+    UNUSED(mapped_ptr);\n }\n \n void PageCache::autoResize(Int64 memory_usage_signed, size_t memory_limit)\ndiff --git a/src/Common/PageCache.h b/src/Common/PageCache.h\nindex 3bb27bcd8bce..13addd84c742 100644\n--- a/src/Common/PageCache.h\n+++ b/src/Common/PageCache.h\n@@ -98,7 +98,7 @@ class PageCache\n     public:\n         using Base::Base;\n \n-        void onRemoveOverflowWeightLoss(size_t /*weight_loss*/) override;\n+        void onEntryRemoval(size_t weight_loss, const MappedPtr & mapped_ptr) override;\n     };\n \n public:\ndiff --git a/src/Common/ProfileEvents.cpp b/src/Common/ProfileEvents.cpp\nindex 3407d76e7659..f8239ecb4ffd 100644\n--- a/src/Common/ProfileEvents.cpp\n+++ b/src/Common/ProfileEvents.cpp\n@@ -274,6 +274,9 @@\n     M(LoadedMarksFiles, \"Number of mark files loaded.\", ValueType::Number) \\\n     M(LoadedMarksCount, \"Number of marks loaded (total across columns).\", ValueType::Number) \\\n     M(LoadedMarksMemoryBytes, \"Size of in-memory representations of loaded marks.\", ValueType::Bytes) \\\n+    M(MarkCacheEvictedBytes, \"Number of bytes evicted from the mark cache.\", ValueType::Bytes) \\\n+    M(MarkCacheEvictedMarks, \"Number of marks evicted from the mark cache.\", ValueType::Number) \\\n+    M(MarkCacheEvictedFiles, \"Number of mark files evicted from the mark cache.\", ValueType::Number) \\\n     M(LoadedPrimaryIndexFiles, \"Number of primary index files loaded.\", ValueType::Number) \\\n     M(LoadedPrimaryIndexRows, \"Number of rows of primary key loaded.\", ValueType::Number) \\\n     M(LoadedPrimaryIndexBytes, \"Number of rows of primary key loaded.\", ValueType::Bytes) \\\ndiff --git a/src/Common/SLRUCachePolicy.h b/src/Common/SLRUCachePolicy.h\nindex e08a64c6bb22..e63690da83d4 100644\n--- a/src/Common/SLRUCachePolicy.h\n+++ b/src/Common/SLRUCachePolicy.h\n@@ -23,7 +23,7 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n     using Base = ICachePolicy<Key, Mapped, HashFunction, WeightFunction>;\n     using typename Base::MappedPtr;\n     using typename Base::KeyMapped;\n-    using typename Base::OnWeightLossFunction;\n+    using typename Base::OnRemoveEntryFunction;\n \n     /** Initialize SLRUCachePolicy with max_size_in_bytes and max_protected_size.\n       * max_protected_size shows how many of the most frequently used entries will not be evicted after a sequential scan.\n@@ -36,7 +36,7 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n         size_t max_size_in_bytes_,\n         size_t max_count_,\n         double size_ratio_,\n-        OnWeightLossFunction on_weight_loss_function_)\n+        OnRemoveEntryFunction on_remove_entry_function_)\n         : Base(std::make_unique<NoCachePolicyUserQuota>())\n         , max_size_in_bytes(max_size_in_bytes_)\n         , max_protected_size(calculateMaxProtectedSize(max_size_in_bytes_, size_ratio_))\n@@ -44,7 +44,7 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n         , size_ratio(size_ratio_)\n         , current_size_in_bytes_metric(size_in_bytes_metric_)\n         , count_metric(count_metric_)\n-        , on_weight_loss_function(on_weight_loss_function_)\n+        , on_remove_entry_function(on_remove_entry_function_)\n     {\n     }\n \n@@ -270,7 +270,7 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n     CurrentMetrics::Metric count_metric;\n \n     WeightFunction weight_function;\n-    OnWeightLossFunction on_weight_loss_function;\n+    OnRemoveEntryFunction on_remove_entry_function;\n \n     static size_t calculateMaxProtectedSize(size_t max_size_in_bytes, double size_ratio)\n     {\n@@ -326,6 +326,11 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n             else\n             {\n                 current_weight_lost += cell.size;\n+\n+                /// We cannot have protected cells in non-protected queue\n+                chassert(!is_protected);\n+                on_remove_entry_function(cell.size, cell.value);\n+\n                 cells.erase(it);\n                 queue.pop_front();\n             }\n@@ -333,9 +338,6 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n             --queue_size;\n         }\n \n-        if (!is_protected)\n-            on_weight_loss_function(current_weight_lost);\n-\n         if (current_size_in_bytes > (1ull << 63))\n             std::terminate(); // Queue became inconsistent\n \ndiff --git a/src/Common/TTLCachePolicy.h b/src/Common/TTLCachePolicy.h\nindex 2070718c87c8..79e34dc2ebd5 100644\n--- a/src/Common/TTLCachePolicy.h\n+++ b/src/Common/TTLCachePolicy.h\n@@ -93,7 +93,7 @@ class TTLCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n     using Base = ICachePolicy<Key, Mapped, HashFunction, WeightFunction>;\n     using typename Base::MappedPtr;\n     using typename Base::KeyMapped;\n-    using typename Base::OnWeightLossFunction;\n+    using typename Base::OnRemoveEntryFunction;\n \n     explicit TTLCachePolicy(CurrentMetrics::Metric size_in_bytes_metric_, CurrentMetrics::Metric count_metric_, CachePolicyUserQuotaPtr quotas_)\n         : Base(std::move(quotas_))\n@@ -288,7 +288,7 @@ class TTLCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n \n     WeightFunction weight_function;\n     IsStaleFunction is_stale_function;\n-    /// TODO support OnWeightLossFunction callback\n+    /// TODO support OnRemoveEntryFunction callback\n \n     void clearImpl()\n     {\n@@ -300,6 +300,7 @@ class TTLCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n \n         size_in_bytes = 0;\n     }\n+\n };\n \n }\ndiff --git a/src/Formats/MarkInCompressedFile.h b/src/Formats/MarkInCompressedFile.h\nindex 12acb1d1333e..801987751c34 100644\n--- a/src/Formats/MarkInCompressedFile.h\n+++ b/src/Formats/MarkInCompressedFile.h\n@@ -50,6 +50,8 @@ class MarksInCompressedFile\n \n     size_t approximateMemoryUsage() const;\n \n+    size_t getNumberOfMarks() const { return num_marks; }\n+\n private:\n     /** Throughout this class:\n      *   * \"x\" stands for offset_in_compressed_file,\ndiff --git a/src/IO/UncompressedCache.h b/src/IO/UncompressedCache.h\nindex 125d58e2eee3..ba8081ba962c 100644\n--- a/src/IO/UncompressedCache.h\n+++ b/src/IO/UncompressedCache.h\n@@ -61,9 +61,11 @@ class UncompressedCache : public CacheBase<UInt128, UncompressedCacheCell, UInt1\n     }\n \n private:\n-    void onRemoveOverflowWeightLoss(size_t weight_loss) override\n+    /// Called for each individual entry being evicted from cache\n+    void onEntryRemoval(const size_t weight_loss, const MappedPtr & mapped_ptr) override\n     {\n         ProfileEvents::increment(ProfileEvents::UncompressedCacheWeightLost, weight_loss);\n+        UNUSED(mapped_ptr);\n     }\n };\n \ndiff --git a/src/Storages/MarkCache.h b/src/Storages/MarkCache.h\nindex 9d9acabf68e6..81af2dd1c6dd 100644\n--- a/src/Storages/MarkCache.h\n+++ b/src/Storages/MarkCache.h\n@@ -12,6 +12,9 @@ namespace ProfileEvents\n {\n     extern const Event MarkCacheHits;\n     extern const Event MarkCacheMisses;\n+    extern const Event MarkCacheEvictedBytes;\n+    extern const Event MarkCacheEvictedMarks;\n+    extern const Event MarkCacheEvictedFiles;\n }\n \n namespace DB\n@@ -41,7 +44,7 @@ class MarkCache : public CacheBase<UInt128, MarksInCompressedFile, UInt128Trivia\n public:\n     MarkCache(const String & cache_policy, size_t max_size_in_bytes, double size_ratio);\n \n-    /// Calculate key from path to file and offset.\n+    /// Calculate key from path to file.\n     static UInt128 hash(const String & path_to_file);\n \n     template <typename LoadFunc>\n@@ -55,6 +58,19 @@ class MarkCache : public CacheBase<UInt128, MarksInCompressedFile, UInt128Trivia\n \n         return result.first;\n     }\n+\n+private:\n+    /// Called for each individual entry being evicted from cache\n+    void onEntryRemoval(const size_t weight_loss, const MappedPtr & mapped_ptr) override\n+    {\n+        /// File is the key of MarkCache, each removal means eviction of 1 file from the cache.\n+        ProfileEvents::increment(ProfileEvents::MarkCacheEvictedFiles);\n+        ProfileEvents::increment(ProfileEvents::MarkCacheEvictedBytes, weight_loss);\n+\n+        const auto * marks_in_compressed_file = static_cast<const MarksInCompressedFile *>(mapped_ptr.get());\n+        ProfileEvents::increment(ProfileEvents::MarkCacheEvictedMarks, marks_in_compressed_file->getNumberOfMarks());\n+    }\n+\n };\n \n using MarkCachePtr = std::shared_ptr<MarkCache>;\ndiff --git a/src/Storages/MergeTree/VectorSimilarityIndexCache.h b/src/Storages/MergeTree/VectorSimilarityIndexCache.h\nindex afde1a01dfeb..85063d233047 100644\n--- a/src/Storages/MergeTree/VectorSimilarityIndexCache.h\n+++ b/src/Storages/MergeTree/VectorSimilarityIndexCache.h\n@@ -89,9 +89,11 @@ class VectorSimilarityIndexCache : public CacheBase<UInt128, VectorSimilarityInd\n     }\n \n private:\n-    void onRemoveOverflowWeightLoss(size_t weight_loss) override\n+    /// Called for each individual entry being evicted from cache\n+    void onEntryRemoval(const size_t weight_loss, const MappedPtr & mapped_ptr) override\n     {\n         ProfileEvents::increment(ProfileEvents::VectorSimilarityIndexCacheWeightLost, weight_loss);\n+        UNUSED(mapped_ptr);\n     }\n };\n \ndiff --git a/src/Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadataFilesCache.h b/src/Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadataFilesCache.h\nindex 2ad276d6e38d..fd57458cd170 100644\n--- a/src/Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadataFilesCache.h\n+++ b/src/Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadataFilesCache.h\n@@ -149,9 +149,11 @@ class IcebergMetadataFilesCache : public CacheBase<String, IcebergMetadataFilesC\n     }\n \n private:\n-    void onRemoveOverflowWeightLoss(size_t weight_loss) override\n+    /// Called for each individual entry being evicted from cache\n+    void onEntryRemoval(const size_t weight_loss, const MappedPtr & mapped_ptr) override\n     {\n         ProfileEvents::increment(ProfileEvents::IcebergMetadataFilesCacheWeightLost, weight_loss);\n+        UNUSED(mapped_ptr);\n     }\n };\n \n",
  "test_patch": "diff --git a/tests/integration/test_mark_cache_profile_events/__init__.py b/tests/integration/test_mark_cache_profile_events/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_mark_cache_profile_events/configs/mark_cache_config.xml b/tests/integration/test_mark_cache_profile_events/configs/mark_cache_config.xml\nnew file mode 100644\nindex 000000000000..97d47ae33843\n--- /dev/null\n+++ b/tests/integration/test_mark_cache_profile_events/configs/mark_cache_config.xml\n@@ -0,0 +1,14 @@\n+<clickhouse>\n+\n+    <mark_cache_size>124</mark_cache_size>\n+    <merge_tree>\n+        <min_bytes_for_wide_part>0</min_bytes_for_wide_part>\n+    </merge_tree>\n+\n+    <query_log>\n+        <database>system</database>\n+        <table>query_log</table>\n+        <flush_interval_milliseconds>1000</flush_interval_milliseconds>\n+    </query_log>\n+\n+</clickhouse>\ndiff --git a/tests/integration/test_mark_cache_profile_events/test.py b/tests/integration/test_mark_cache_profile_events/test.py\nnew file mode 100644\nindex 000000000000..420ce9682e27\n--- /dev/null\n+++ b/tests/integration/test_mark_cache_profile_events/test.py\n@@ -0,0 +1,291 @@\n+import os\n+import time\n+import pytest\n+import logging\n+from helpers.cluster import ClickHouseCluster\n+\n+# Setup logging\n+logger = logging.getLogger(__name__)\n+\n+cluster = ClickHouseCluster(__file__)\n+# Use a smaller mark cache to force evictions more reliably\n+node = cluster.add_instance(\n+    \"node\",\n+    main_configs=[\"configs/mark_cache_config.xml\"],\n+    stay_alive=True,\n+)\n+\n+@pytest.fixture(scope=\"module\")\n+def start_cluster():\n+    try:\n+        cluster.start()\n+        yield cluster\n+    finally:\n+        cluster.shutdown()\n+\n+def get_current_cache_metrics():\n+    \"\"\"Get current cache metrics from system.events to establish baseline\"\"\"\n+    result = node.query(\"\"\"\n+                        SELECT event, value\n+                        FROM system.events\n+                        WHERE event IN ('MarkCacheEvictedBytes', 'MarkCacheEvictedMarks', 'MarkCacheEvictedFiles')\n+                        ORDER BY event\n+                        \"\"\").strip()\n+\n+    metrics = {}\n+    if result:\n+        for line in result.splitlines():\n+            event, value = line.split('\\t')\n+            metrics[event] = int(value)\n+\n+    logger.info(f\"Current cache metrics: {metrics}\")\n+    return metrics\n+\n+def wait_for_cache_eviction(initial_metrics, timeout=30):\n+    \"\"\"Wait for cache eviction to occur by monitoring metrics change\"\"\"\n+    start_time = time.time()\n+\n+    while time.time() - start_time < timeout:\n+        current_metrics = get_current_cache_metrics()\n+\n+        # Check if any eviction metric has increased\n+        eviction_occurred = False\n+        for metric in ['MarkCacheEvictedBytes', 'MarkCacheEvictedMarks', 'MarkCacheEvictedFiles']:\n+            initial_value = initial_metrics.get(metric, 0)\n+            current_value = current_metrics.get(metric, 0)\n+            if current_value > initial_value:\n+                eviction_occurred = True\n+                logger.info(f\"Eviction detected: {metric} increased from {initial_value} to {current_value}\")\n+                break\n+\n+        if eviction_occurred:\n+            return current_metrics\n+\n+        time.sleep(0.5)\n+\n+    raise TimeoutError(f\"Cache eviction not detected within {timeout} seconds\")\n+\n+@pytest.fixture()\n+def setup_cache_test_environment():\n+    \"\"\"Setup environment with controlled cache size and data that will force evictions\"\"\"\n+    table_name = \"mark_cache_eviction_test\"\n+    logger.info(f\"Setting up test environment with table: {table_name}\")\n+\n+    try:\n+        # Clean up any existing table\n+        node.query(f\"DROP TABLE IF EXISTS {table_name}\")\n+\n+        # Set a small mark cache size to force evictions\n+        # This ensures our test is deterministic\n+        node.query(\"SYSTEM DROP MARK CACHE\")\n+\n+        # Create table with specific settings to control mark file size\n+        node.query(f\"\"\"\n+            CREATE TABLE {table_name} (\n+                id UInt64, \n+                data String,\n+                padding String\n+            )\n+            ENGINE = MergeTree()\n+            ORDER BY id\n+            SETTINGS \n+                index_granularity = 1024,  -- Smaller granularity = more marks\n+                index_granularity_bytes = 0  -- Disable adaptive granularity\n+        \"\"\")\n+\n+        # Insert data in multiple parts to create multiple mark files\n+        # Each insert creates a separate part with its own mark file\n+        batch_size = 5000\n+        num_batches = 20\n+\n+        logger.info(f\"Inserting {num_batches} batches of {batch_size} rows each\")\n+        for batch in range(num_batches):\n+            offset = batch * batch_size\n+            node.query(f\"\"\"\n+                INSERT INTO {table_name}\n+                SELECT \n+                    number + {offset} as id,\n+                    'data_' || toString(number) as data,\n+                    repeat('x', 100) as padding  -- Add padding to increase mark file size\n+                FROM numbers({batch_size})\n+            \"\"\")\n+\n+        # Optimize to ensure we have the expected number of parts\n+        # But don't merge everything into one part\n+        node.query(f\"OPTIMIZE TABLE {table_name}\")\n+\n+        # Verify table structure\n+        parts_info = node.query(f\"\"\"\n+            SELECT count() as part_count, sum(rows) as total_rows \n+            FROM system.parts \n+            WHERE table = '{table_name}' AND active\n+        \"\"\").strip().split('\\t')\n+\n+        logger.info(f\"Created table with {parts_info[0]} parts and {parts_info[1]} total rows\")\n+\n+        yield table_name\n+\n+    finally:\n+        logger.info(f\"Cleaning up table: {table_name}\")\n+        try:\n+            node.query(f\"DROP TABLE IF EXISTS {table_name}\")\n+        except Exception as e:\n+            logger.warning(f\"Error during cleanup: {e}\")\n+\n+def test_mark_cache_eviction_functionality(start_cluster, setup_cache_test_environment):\n+    \"\"\"\n+    Test that mark cache eviction metrics are properly tracked when cache overflows.\n+\n+    This test:\n+    1. Records baseline metrics\n+    2. Performs operations that will fill and overflow the mark cache\n+    3. Verifies that eviction metrics are incremented appropriately\n+    \"\"\"\n+    table_name = setup_cache_test_environment\n+\n+    # Get baseline metrics before starting the test\n+    initial_metrics = get_current_cache_metrics()\n+    logger.info(f\"Starting test with baseline metrics: {initial_metrics}\")\n+\n+    # Clear the mark cache to start fresh\n+    node.query(\"SYSTEM DROP MARK CACHE\")\n+\n+    # Perform queries that will load many mark files into cache\n+    # Query different ranges to load different parts and their mark files\n+    logger.info(\"Executing queries to fill mark cache...\")\n+\n+    # First, do some queries to populate the cache\n+    for i in range(0, 50000, 2500):  # Query every 2500 records\n+        end_range = i + 2500\n+        result = node.query(f\"\"\"\n+            SELECT count(*), avg(length(data)) \n+            FROM {table_name} \n+            WHERE id BETWEEN {i} AND {end_range}\n+        \"\"\")\n+        logger.debug(f\"Query range {i}-{end_range}: {result.strip()}\")\n+\n+    # Now do more intensive queries that should trigger evictions\n+    logger.info(\"Executing queries to trigger cache evictions...\")\n+\n+    # Perform random access patterns to force cache pressure\n+    import random\n+    ranges = [(i, i + 1000) for i in range(0, 90000, 3000)]\n+    random.shuffle(ranges)  # Random access pattern increases cache pressure\n+\n+    for start, end in ranges:\n+        node.query(f\"\"\"\n+            SELECT count(*), sum(length(padding))\n+            FROM {table_name} \n+            WHERE id BETWEEN {start} AND {end}\n+        \"\"\")\n+\n+    # Wait for evictions to be reflected in metrics\n+    logger.info(\"Waiting for cache evictions to be recorded...\")\n+    try:\n+        final_metrics = wait_for_cache_eviction(initial_metrics, timeout=30)\n+    except TimeoutError:\n+        # If no eviction detected, try one more aggressive approach\n+        logger.warning(\"No eviction detected, trying more aggressive cache pressure...\")\n+\n+        # Force more cache pressure by querying with PREWHERE (loads more marks)\n+        for i in range(0, 100000, 1000):\n+            node.query(f\"\"\"\n+                SELECT count() \n+                FROM {table_name} \n+                PREWHERE id % 100 = 0 \n+                WHERE id >= {i} AND id < {i + 1000}\n+            \"\"\")\n+\n+        final_metrics = wait_for_cache_eviction(initial_metrics, timeout=15)\n+\n+    # Verify that eviction metrics have increased\n+    expected_metrics = ['MarkCacheEvictedBytes', 'MarkCacheEvictedMarks', 'MarkCacheEvictedFiles']\n+\n+    for metric in expected_metrics:\n+        initial_value = initial_metrics.get(metric, 0)\n+        final_value = final_metrics.get(metric, 0)\n+\n+        assert final_value > initial_value, \\\n+            f\"{metric} should have increased: initial={initial_value}, final={final_value}\"\n+\n+        logger.info(f\"\u2713 {metric}: {initial_value} \u2192 {final_value} (delta: {final_value - initial_value})\")\n+\n+    # Verify logical relationships between metrics\n+    bytes_evicted = final_metrics.get('MarkCacheEvictedBytes', 0) - initial_metrics.get('MarkCacheEvictedBytes', 0)\n+    marks_evicted = final_metrics.get('MarkCacheEvictedMarks', 0) - initial_metrics.get('MarkCacheEvictedMarks', 0)\n+    files_evicted = final_metrics.get('MarkCacheEvictedFiles', 0) - initial_metrics.get('MarkCacheEvictedFiles', 0)\n+\n+    # Sanity checks for metric relationships\n+    assert bytes_evicted > 0, \"Should have evicted some bytes\"\n+    assert marks_evicted > 0, \"Should have evicted some marks\"\n+    assert files_evicted > 0, \"Should have evicted some files\"\n+\n+    # Marks should be >= files (each file contains at least 1 mark)\n+    assert marks_evicted >= files_evicted, \\\n+        f\"Marks evicted ({marks_evicted}) should be >= files evicted ({files_evicted})\"\n+\n+    logger.info(f\"\u2713 Test passed - Cache eviction metrics working correctly\")\n+\n+def test_mark_cache_query_log_integration(start_cluster, setup_cache_test_environment):\n+    \"\"\"\n+    Test that eviction metrics appear in query logs when evictions occur during queries\n+    \"\"\"\n+    table_name = setup_cache_test_environment\n+\n+    # Enable query log\n+    node.query(\"SYSTEM FLUSH LOGS\")\n+\n+    # Clear cache and perform operation that should trigger evictions\n+    node.query(\"SYSTEM DROP MARK CACHE\")\n+\n+    # Get initial metrics\n+    initial_metrics = get_current_cache_metrics()\n+\n+    # Perform a query that should trigger cache evictions\n+    node.query(f\"\"\"\n+        SELECT count(*), avg(length(data)), sum(length(padding))\n+        FROM {table_name}\n+        WHERE id % 17 = 0  -- Sparse access pattern to stress cache\n+    \"\"\")\n+\n+    # More cache pressure\n+    for i in range(10):\n+        node.query(f\"\"\"\n+            SELECT count() FROM {table_name} \n+            WHERE id >= {i * 10000} AND id < {(i + 1) * 10000}\n+            AND data LIKE '%{i}%'\n+        \"\"\")\n+\n+    # Wait for metrics to update\n+    time.sleep(2)\n+    node.query(\"SYSTEM FLUSH LOGS\")\n+\n+    # Check if eviction metrics appear in query log\n+    eviction_queries = node.query(\"\"\"\n+                                  SELECT\n+                                      query,\n+                                      ProfileEvents['MarkCacheEvictedBytes'] as bytes,\n+                                      ProfileEvents['MarkCacheEvictedMarks'] as marks,\n+                                      ProfileEvents['MarkCacheEvictedFiles'] as files\n+                                  FROM system.query_log\n+                                  WHERE\n+                                      type = 'QueryFinish'\n+                                    AND (\n+                                      ProfileEvents['MarkCacheEvictedBytes'] > 0 OR\n+                                      ProfileEvents['MarkCacheEvictedMarks'] > 0 OR\n+                                      ProfileEvents['MarkCacheEvictedFiles'] > 0\n+                                      )\n+                                    AND query NOT LIKE 'SYSTEM%'\n+                                  ORDER BY event_time_microseconds DESC\n+                                      LIMIT 5\n+                                  \"\"\").strip()\n+\n+    logger.info(f\"Queries with eviction metrics:\\n{eviction_queries}\")\n+\n+    # We should have at least some queries with eviction metrics\n+    # (This might be empty if evictions didn't occur during these specific queries,\n+    #  which is why we also test system.events separately)\n+    if eviction_queries:\n+        logger.info(\"\u2713 Found eviction metrics in query log\")\n+    else:\n+        logger.info(\"\u2139 No eviction metrics in query log (evictions may have occurred between queries)\")\n\\ No newline at end of file\n",
  "problem_statement": "Need more metrics about Mark Cache eviction.\nMarkCacheEvictedFiles\r\nMarkCacheEvictedMarks\r\nMarkCacheEvictedBytes\n",
  "hints_text": "I would rather say mark loading has to be reworked. I have wrote it somewhere in issues comments, but I have not created designated issue yet.\r\n\r\nThis has to be improved:\r\n- even in good-green path marks loading puts a task to the thread pool for only check if the marks in the cache\r\n- in that case tasks in pool which _have_ data in cache are waiting other tasks which really load new marks, that eliminates all advantages of using cache\r\n- there is no cancelation point, canceled query waits  until all its marks loading tasks are executed.",
  "created_at": "2025-05-25T23:34:50Z",
  "modified_files": [
    "src/Common/CacheBase.h",
    "src/Common/ICachePolicy.h",
    "src/Common/LRUCachePolicy.h",
    "src/Common/PageCache.cpp",
    "src/Common/PageCache.h",
    "src/Common/ProfileEvents.cpp",
    "src/Common/SLRUCachePolicy.h",
    "src/Common/TTLCachePolicy.h",
    "src/Formats/MarkInCompressedFile.h",
    "src/IO/UncompressedCache.h",
    "src/Storages/MarkCache.h",
    "src/Storages/MergeTree/VectorSimilarityIndexCache.h",
    "src/Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadataFilesCache.h"
  ],
  "modified_test_files": [
    "b/tests/integration/test_mark_cache_profile_events/configs/mark_cache_config.xml",
    "b/tests/integration/test_mark_cache_profile_events/test.py"
  ]
}