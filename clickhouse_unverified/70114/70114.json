{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 70114,
  "instance_id": "ClickHouse__ClickHouse-70114",
  "issue_numbers": [
    "69092"
  ],
  "base_commit": "f0f9224d6aa9528222dac51afb9d109141656ee7",
  "patch": "diff --git a/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.cpp b/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.cpp\nindex 2fe1fb5905ad..9ccd0ee778aa 100644\n--- a/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.cpp\n+++ b/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.cpp\n@@ -723,16 +723,21 @@ Strings PostgreSQLReplicationHandler::getTableAllowedColumns(const std::string &\n     if (tables_list.empty())\n         return result;\n \n-    size_t table_pos = tables_list.find(table_name);\n-    if (table_pos == std::string::npos)\n+    size_t table_pos = 0;\n+    while (true)\n     {\n-        return result;\n+        table_pos = tables_list.find(table_name, table_pos + 1);\n+        if (table_pos == std::string::npos)\n+            return result;\n+        if (table_pos + table_name.length() + 1 > tables_list.length())\n+            return result;\n+        if (tables_list[table_pos + table_name.length() + 1] == '(' ||\n+            tables_list[table_pos + table_name.length() + 1] == ',' ||\n+            tables_list[table_pos + table_name.length() + 1] == ' '\n+        )\n+            break;\n     }\n \n-    if (table_pos + table_name.length() + 1 > tables_list.length())\n-    {\n-        return result;\n-    }\n     String column_list = tables_list.substr(table_pos + table_name.length() + 1);\n     column_list.erase(std::remove(column_list.begin(), column_list.end(), '\"'), column_list.end());\n     boost::trim(column_list);\n",
  "test_patch": "diff --git a/tests/integration/test_postgresql_replica_database_engine_2/test.py b/tests/integration/test_postgresql_replica_database_engine_2/test.py\nindex e64c9eb9d1ec..140250508beb 100644\n--- a/tests/integration/test_postgresql_replica_database_engine_2/test.py\n+++ b/tests/integration/test_postgresql_replica_database_engine_2/test.py\n@@ -1184,64 +1184,97 @@ def test_partial_table(started_cluster):\n     )\n \n \n-def test_partial_and_full_table(started_cluster):\n+# it is important to check case when table name, with subset of columns, is substring of table with full set of columns\n+@pytest.mark.parametrize(\n+    \"table_list\",\n+    [\n+        \"{}(key, x, z), {}_full, {}_full1\",\n+        \"{}_full, {}(key, x, z), {}_full1\",\n+        \"{}_full,{}(key, x, z),{}_full1\",\n+        \"{}_full,{}_full1,{}(key, x, z)\",\n+    ],\n+)\n+def test_partial_and_full_table(started_cluster, table_list):\n     table = \"test_partial_and_full_table\"\n+    table_list = table_list.format(table, table, table)\n+    print(table_list)\n \n     pg_manager.create_postgres_table(\n         table,\n         \"\",\n-        f\"\"\"CREATE TABLE {table}1 (\n+        f\"\"\"CREATE TABLE {table} (\n              key integer PRIMARY KEY,\n              x integer DEFAULT 0,\n              y integer,\n              z text DEFAULT 'z');\n          \"\"\",\n     )\n-    pg_manager.execute(f\"insert into {table}1 (key, x, y, z) values (1,1,1,'1');\")\n-    pg_manager.execute(f\"insert into {table}1 (key, x, y, z) values (2,2,2,'2');\")\n+    pg_manager.execute(f\"insert into {table} (key, x, y, z) values (1,1,1,'1');\")\n+    pg_manager.execute(f\"insert into {table} (key, x, y, z) values (2,2,2,'2');\")\n+\n     pg_manager.create_postgres_table(\n-        table,\n+        table + \"_full\",\n         \"\",\n-        f\"\"\"CREATE TABLE {table}2 (\n+        f\"\"\"CREATE TABLE {table}_full (\n              key integer PRIMARY KEY,\n              x integer DEFAULT 0,\n              y integer,\n              z text DEFAULT 'z');\n          \"\"\",\n     )\n-    pg_manager.execute(f\"insert into {table}2 (key, x, y, z) values (3,3,3,'3');\")\n-    pg_manager.execute(f\"insert into {table}2 (key, x, y, z) values (4,4,4,'4');\")\n+    pg_manager.execute(f\"insert into {table}_full (key, x, y, z) values (3,3,3,'3');\")\n+    pg_manager.execute(f\"insert into {table}_full (key, x, y, z) values (4,4,4,'4');\")\n+\n+    pg_manager.create_postgres_table(\n+        table + \"_full1\",\n+        \"\",\n+        f\"\"\"CREATE TABLE {table}_full1 (\n+             key integer PRIMARY KEY,\n+             x integer DEFAULT 0,\n+             y integer,\n+             z text DEFAULT 'z');\n+         \"\"\",\n+    )\n+    pg_manager.execute(f\"insert into {table}_full1 (key, x, y, z) values (5,5,5,'5');\")\n+    pg_manager.execute(f\"insert into {table}_full1 (key, x, y, z) values (6,6,6,'6');\")\n \n     pg_manager.create_materialized_db(\n         ip=started_cluster.postgres_ip,\n         port=started_cluster.postgres_port,\n         settings=[\n-            f\"materialized_postgresql_tables_list = '{table}1(key, x, z), {table}2'\",\n+            f\"materialized_postgresql_tables_list = '{table_list}'\",\n             \"materialized_postgresql_backoff_min_ms = 100\",\n             \"materialized_postgresql_backoff_max_ms = 100\",\n         ],\n     )\n     check_tables_are_synchronized(\n         instance,\n-        f\"{table}1\",\n+        f\"{table}\",\n         postgres_database=pg_manager.get_default_database(),\n         columns=[\"key\", \"x\", \"z\"],\n     )\n     check_tables_are_synchronized(\n-        instance, f\"{table}2\", postgres_database=pg_manager.get_default_database()\n+        instance, f\"{table}_full\", postgres_database=pg_manager.get_default_database()\n+    )\n+    check_tables_are_synchronized(\n+        instance, f\"{table}_full1\", postgres_database=pg_manager.get_default_database()\n     )\n \n-    pg_manager.execute(f\"insert into {table}1 (key, x, z) values (3,3,'3');\")\n-    pg_manager.execute(f\"insert into {table}2 (key, x, z) values (5,5,'5');\")\n+    pg_manager.execute(f\"insert into {table} (key, x, z) values (7,7,'7');\")\n+    pg_manager.execute(f\"insert into {table}_full (key, x, z) values (8,8,'8');\")\n+    pg_manager.execute(f\"insert into {table}_full1 (key, x, z) values (9,9,'9');\")\n \n     check_tables_are_synchronized(\n         instance,\n-        f\"{table}1\",\n+        f\"{table}\",\n         postgres_database=pg_manager.get_default_database(),\n         columns=[\"key\", \"x\", \"z\"],\n     )\n     check_tables_are_synchronized(\n-        instance, f\"{table}2\", postgres_database=pg_manager.get_default_database()\n+        instance, f\"{table}_full\", postgres_database=pg_manager.get_default_database()\n+    )\n+    check_tables_are_synchronized(\n+        instance, f\"{table}_full1\", postgres_database=pg_manager.get_default_database()\n     )\n \n \n",
  "problem_statement": "Ability to limit columns for tables in MaterializedPostgreSQL\n### Changelog category (leave one):\r\n- Improvement\r\n\r\n\r\n### Changelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\nReplication of subset of columns is now available  through MaterializedPostgreSQL. Closes #33748 \r\n\r\n### Documentation entry for user-facing changes\r\n\r\nEach table in `materialized_postgresql_tables_list` setting can have subset of replicated columns in brackets. If subset of columns is omitted, then all columns for table will be replicated.\r\n\r\n`    materialized_postgresql_tables_list = 'table1(co1, col2),table2,table3(co3, col5, col7)`\r\n\r\n> Information about CI checks: https://clickhouse.com/docs/en/development/continuous-integration/\r\n\r\n#### CI Settings (Only check the boxes if you know what you are doing):\r\n- [ ] <!---ci_set_required--> Allow: All Required Checks\r\n- [ ] <!---ci_include_stateless--> Allow: Stateless tests\r\n- [ ] <!---ci_include_stateful--> Allow: Stateful tests\r\n- [x] <!---ci_include_integration--> Allow: Integration Tests\r\n- [ ] <!---ci_include_performance--> Allow: Performance tests\r\n- [ ] <!---ci_set_builds--> Allow: All Builds\r\n- [ ] <!---batch_0_1--> Allow: batch 1, 2 for multi-batch jobs\r\n- [ ] <!---batch_2_3--> Allow: batch 3, 4, 5, 6 for multi-batch jobs\r\n---\r\n- [ ] <!---ci_exclude_style--> Exclude: Style check\r\n- [ ] <!---ci_exclude_fast--> Exclude: Fast test\r\n- [ ] <!---ci_exclude_asan--> Exclude: All with ASAN\r\n- [ ] <!---ci_exclude_tsan|msan|ubsan|coverage--> Exclude: All with TSAN, MSAN, UBSAN, Coverage\r\n- [ ] <!---ci_exclude_aarch64|release|debug--> Exclude: All with aarch64, release, debug\r\n---\r\n- [ ] <!---ci_include_fuzzer--> Run only fuzzers related jobs (libFuzzer fuzzers, AST fuzzers, etc.)\r\n- [ ] <!---ci_exclude_ast--> Exclude: AST fuzzers\r\n---\r\n- [ ] <!---do_not_test--> Do not test\r\n- [ ] <!---woolen_wolfdog--> Woolen Wolfdog\r\n- [ ] <!---upload_all--> Upload binaries for special builds\r\n- [ ] <!---no_merge_commit--> Disable merge-commit\r\n- [ ] <!---no_ci_cache--> Disable CI cache\r\n\n",
  "hints_text": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/ClickHouse/ClickHouse?pullRequest=69092) <br/>All committers have signed the CLA.\nHey @kssenii ! Can you please look at this PR?\n<!-- automatic status comment for PR #69092 from 1on/ClickHouse:master -->\n*This is an automated comment for commit 51d770fa7aeacbe0a10e7f48c86fdeec8ab214e1 with description of existing statuses. It's updated for the latest CI running*\n\n[\u274c Click here](https://s3.amazonaws.com/clickhouse-test-reports/69092/51d770fa7aeacbe0a10e7f48c86fdeec8ab214e1/ci_running.html) to open a full report in a separate page\n\n<table>\n<thead><tr><th>Check name</th><th>Description</th><th>Status</th></tr></thead>\n<tbody>\n<tr><td>Integration tests</td><td>The integration tests report. In parenthesis the package type is given, and in square brackets are the optional part/total tests</td><td><a href=\"https://s3.amazonaws.com/clickhouse-test-reports/69092/51d770fa7aeacbe0a10e7f48c86fdeec8ab214e1/integration_tests__release__[2_4].html\">\u274c failure</a></td></tr>\n<tbody>\n</table>\n<details><summary>Successful checks</summary>\n<table>\n<thead><tr><th>Check name</th><th>Description</th><th>Status</th></tr></thead>\n<tbody>\n<tr><td>Flaky tests</td><td>Checks if new added or modified tests are flaky by running them repeatedly, in parallel, with more randomization. Functional tests are run 100 times with address sanitizer, and additional randomization of thread scheduling. Integration tests are run up to 10 times. If at least once a new test has failed, or was too long, this check will be red. We don't allow flaky tests, read <a href=\"https://clickhouse.com/blog/decorating-a-christmas-tree-with-the-help-of-flaky-tests/\">the doc</a></td><td><a href=\"https://s3.amazonaws.com/clickhouse-test-reports/69092/51d770fa7aeacbe0a10e7f48c86fdeec8ab214e1/integration_tests_flaky_check__asan_.html\">\u2705 success</a></td></tr>\n<tr><td>Style check</td><td>Runs a set of checks to keep the code style clean. If some of tests failed, see the related log from the report</td><td><a href=\"https://s3.amazonaws.com/clickhouse-test-reports/69092/51d770fa7aeacbe0a10e7f48c86fdeec8ab214e1/style_check.html\">\u2705 success</a></td></tr>\n<tbody>\n</table>\n</details>\n\nLooks like failures (in kafka tests) are not connected with changes in PR?\n> Looks like failures (in kafka tests) are not connected with changes in PR?\r\n\r\nyes, not related",
  "created_at": "2024-09-30T07:09:26Z",
  "modified_files": [
    "src/Storages/PostgreSQL/PostgreSQLReplicationHandler.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_postgresql_replica_database_engine_2/test.py"
  ]
}