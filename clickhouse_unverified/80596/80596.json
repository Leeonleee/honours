{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 80596,
  "instance_id": "ClickHouse__ClickHouse-80596",
  "issue_numbers": [
    "80012",
    "74343"
  ],
  "base_commit": "81dce1e8f330d30a7f8e6c7ea1fa69b2eff93493",
  "patch": "diff --git a/src/Analyzer/ConstantNode.cpp b/src/Analyzer/ConstantNode.cpp\nindex fed21a2721bd..62ef2c2341ad 100644\n--- a/src/Analyzer/ConstantNode.cpp\n+++ b/src/Analyzer/ConstantNode.cpp\n@@ -55,58 +55,10 @@ String ConstantNode::getValueStringRepresentation() const\n     return applyVisitor(FieldVisitorToString(), getValue());\n }\n \n-bool ConstantNode::requiresCastCall(Field::Types::Which type, const DataTypePtr & field_type, const DataTypePtr & data_type)\n-{\n-    bool need_to_add_cast_function = false;\n-    WhichDataType constant_value_type(data_type);\n-\n-    switch (type)\n-    {\n-        case Field::Types::String:\n-        {\n-            need_to_add_cast_function = !constant_value_type.isString();\n-            break;\n-        }\n-        case Field::Types::UInt64:\n-        case Field::Types::Int64:\n-        case Field::Types::Float64:\n-        {\n-            WhichDataType constant_value_field_type(field_type);\n-            need_to_add_cast_function = constant_value_field_type.idx != constant_value_type.idx;\n-            break;\n-        }\n-        case Field::Types::Int128:\n-        case Field::Types::UInt128:\n-        case Field::Types::Int256:\n-        case Field::Types::UInt256:\n-        case Field::Types::Decimal32:\n-        case Field::Types::Decimal64:\n-        case Field::Types::Decimal128:\n-        case Field::Types::Decimal256:\n-        case Field::Types::AggregateFunctionState:\n-        case Field::Types::Array:\n-        case Field::Types::Tuple:\n-        case Field::Types::Map:\n-        case Field::Types::UUID:\n-        case Field::Types::Bool:\n-        case Field::Types::Object:\n-        case Field::Types::IPv4:\n-        case Field::Types::IPv6:\n-        case Field::Types::Null:\n-        case Field::Types::CustomType:\n-        {\n-            need_to_add_cast_function = true;\n-            break;\n-        }\n-    }\n-\n-    return need_to_add_cast_function;\n-}\n-\n bool ConstantNode::requiresCastCall(const DataTypePtr & field_type, const DataTypePtr & data_type)\n {\n     WhichDataType which_field_type(field_type);\n-    if (which_field_type.isNullable() || which_field_type.isArray())\n+    if (which_field_type.isNullable() || which_field_type.isArray() || which_field_type.isTuple())\n         return true;\n \n     return field_type->getTypeId() != data_type->getTypeId();\n@@ -203,21 +155,29 @@ ASTPtr ConstantNode::toASTImpl(const ConvertToASTOptions & options) const\n         return std::make_shared<ASTLiteral>(getFieldFromColumnForASTLiteral(constant_value.getColumn(), 0, constant_value.getType()));\n \n     const auto & constant_value_type = constant_value.getType();\n-    auto constant_value_ast = std::make_shared<ASTLiteral>(getValue());\n \n     // Add cast if constant was created as a result of constant folding.\n     // Constant folding may lead to type transformation and literal on shard\n     // may have a different type.\n-    if (source_expression != nullptr || requiresCastCall(constant_value_ast->value.getType(), applyVisitor(FieldToDataType(), constant_value_ast->value), getResultType()))\n+\n+    auto requires_cast = [this]()\n+    {\n+        const auto & [_, type] = getValueNameAndType();\n+        return requiresCastCall(type, getResultType());\n+    };\n+\n+    if (source_expression != nullptr || requires_cast())\n     {\n         /// For some types we cannot just get a field from a column, because it can loose type information during serialization/deserialization of the literal.\n         /// For example, DateTime64 will return Field with Decimal64 and we won't be able to parse it to DateTine64 back in some cases.\n         /// Also for Dynamic and Object types we can loose types information, so we need to create a Field carefully.\n-        constant_value_ast = std::make_shared<ASTLiteral>(getFieldFromColumnForASTLiteral(constant_value.getColumn(), 0, constant_value.getType()));\n+        auto constant_value_ast = std::make_shared<ASTLiteral>(getFieldFromColumnForASTLiteral(constant_value.getColumn(), 0, constant_value.getType()));\n         auto constant_type_name_ast = std::make_shared<ASTLiteral>(constant_value_type->getName());\n         return makeASTFunction(\"_CAST\", std::move(constant_value_ast), std::move(constant_type_name_ast));\n     }\n \n+    auto constant_value_ast = std::make_shared<ASTLiteral>(getValue());\n+\n     if (isBool(constant_value_type))\n         constant_value_ast->custom_type = constant_value_type;\n \ndiff --git a/src/Analyzer/ConstantNode.h b/src/Analyzer/ConstantNode.h\nindex e91e97c34792..e97063427ec2 100644\n--- a/src/Analyzer/ConstantNode.h\n+++ b/src/Analyzer/ConstantNode.h\n@@ -91,7 +91,6 @@ class ConstantNode final : public IQueryTreeNode\n     }\n \n     /// Check if conversion to AST requires wrapping with _CAST function.\n-    static bool requiresCastCall(Field::Types::Which type, const DataTypePtr & field_type, const DataTypePtr & data_type);\n     static bool requiresCastCall(const DataTypePtr & field_type, const DataTypePtr & data_type);\n \n     /// Check if constant is a result of _CAST function constant folding.\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03519_analyzer_tuple_cast.reference b/tests/queries/0_stateless/03519_analyzer_tuple_cast.reference\nnew file mode 100644\nindex 000000000000..04b968820166\n--- /dev/null\n+++ b/tests/queries/0_stateless/03519_analyzer_tuple_cast.reference\n@@ -0,0 +1,9 @@\n+2\t(-9,0)\n+2\t(-8,1)\n+2\t{1:1}\n+2\t{1:2}\n+(1,2)\n+(3,4)\n+(1,2)\n+(1,2)\n+1\t('dete','ok')\t('dete','ok')\ndiff --git a/tests/queries/0_stateless/03519_analyzer_tuple_cast.sql b/tests/queries/0_stateless/03519_analyzer_tuple_cast.sql\nnew file mode 100644\nindex 000000000000..33dd02184e9d\n--- /dev/null\n+++ b/tests/queries/0_stateless/03519_analyzer_tuple_cast.sql\n@@ -0,0 +1,17 @@\n+set enable_analyzer=1;\n+\n+DROP TABLE IF EXISTS test, src;\n+\n+SELECT count(), plus((-9, 0), (number,  number)) AS k FROM remote('127.0.0.{3,2}', numbers(2)) GROUP BY k ORDER BY k;\n+SELECT count(), mapAdd(map(1::UInt128, 1), map(1::UInt128 ,number)) AS k FROM remote('127.0.0.{3,2}', numbers(2)) GROUP BY k ORDER BY k;\n+\n+CREATE TABLE test (s String) ORDER BY ();\n+INSERT INTO test VALUES ('a'), ('b');\n+SELECT transform(s, ['a', 'b'], [(1, 2), (3, 4)], (0, 0)) AS k FROM test ORDER BY k;\n+SELECT s != '' ? (1,2) : (0,0) AS k FROM test ORDER BY k;\n+\n+CREATE TABLE src (id UInt32, type String, data String) ENGINE=MergeTree ORDER BY tuple();\n+INSERT INTO src VALUES (1, 'ok', 'data');\n+SELECT id, tuple(replaceAll(data, 'a', 'e') AS col_a, type) AS a, tuple(replaceAll(data, 'a', 'e') AS col_b, type) AS b FROM src;\n+\n+DROP TABLE IF EXISTS test, src;\n",
  "problem_statement": "`Cannot find column` with constant tuple in distributed query (analyzer)\n```\n:) SELECT (-9, 0) + (number,  number)  from remote('127.0.0.{1,2}', numbers(2)) order by number\n\nSELECT (-9, 0) + (number, number)\nFROM remote('127.0.0.{1,2}', numbers(2))\nORDER BY number ASC\n\nQuery id: 21f422c6-6962-4069-90b6-d2400ed6b335\n\n\nElapsed: 0.004 sec. \n\nReceived exception from server (version 25.5.1):\nCode: 8. DB::Exception: Received from localhost:9000. DB::Exception: Cannot find column `plus((-9, 0)_Tuple(Int8, UInt8), tuple(__table1.number, __table1.number))` in source stream, there are only columns: [__table1.number, plus(_CAST((-9, 0)_Tuple(Int8, UInt8), 'Tuple(Int8, UInt8)'_String), tuple(__table1.number, __table1.number))]. (THERE_IS_NO_COLUMN)\n\n```\nCannot find column `tuple` in source stream. Parallel replicas\nNot reproduced with `enable_named_columns_in_function_tuple = 0`\r\n\r\nRepro:\r\n```\r\nSET enable_analyzer = 1;\r\nSET enable_named_columns_in_function_tuple = 1;\r\n\r\nDROP TABLE IF EXISTS src;\r\nDROP TABLE IF EXISTS dst;\r\n\r\nCREATE TABLE src (id UInt32, type String, data String) ENGINE=MergeTree ORDER BY tuple();\r\nCREATE TABLE dst (id UInt32, a Tuple (col_a Nullable(String), type String), b Tuple (col_b Nullable(String), type String)) ENGINE = MergeTree ORDER BY id;\r\n\r\nINSERT INTO src VALUES (1, 'ok', 'data');\r\nSELECT id, tuple(replaceAll(data, 'a', 'e') AS col_a, type) AS a, tuple(replaceAll(data, 'a', 'e') AS col_b, type) AS b FROM src;\r\n\r\nDROP TABLE src;\r\n```\r\n\r\n```\r\n03240_insert_select_named_tuple:                                        [ FAIL ]\r\nReason: return code:  8\r\n[nikpc] 2025.01.08 22:59:45.517145 [ 49046 ] {7a4b11c7-621f-46dd-b144-438a525490dd} <Error> executeQuery: Code: 8. DB::Exception: Cannot find column `tuple(col_a, type)` in source stream, there are only columns: [__table1.id, tuple(replaceAll(__table1.data, 'a'_String, 'e'_String), __table1.type), tuple(replaceAll(__table1.data, 'a'_String, 'e'_String), __table1.type)]. (THERE_IS_NO_COLUMN) (version 25.1.1.1921 (official build)) (from [::ffff:127.0.0.1]:42160) (comment: 03240_insert_select_named_tuple.sql) (in query: SELECT id, tuple(replaceAll(data, 'a', 'e') AS col_a, type) AS a, tuple(replaceAll(data, 'a', 'e') AS col_b, type) AS b FROM src;), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. ./build_docker/./src/Common/Exception.cpp:107: DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000d87b63b\r\n1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x00000000086ff62c\r\n2. DB::Exception::Exception<String const&, String>(int, FormatStringHelperImpl<std::type_identity<String const&>::type, std::type_identity<String>::type>, String const&, String&&) @ 0x0000000008d7030b\r\n3. ./build_docker/./src/Interpreters/ActionsDAG.cpp:1518: DB::ActionsDAG::makeConvertingActions(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, DB::ActionsDAG::MatchColumnsMode, bool, bool, std::unordered_map<String, String, std::hash<String>, std::equal_to<String>, std::allocator<std::pair<String const, String>>>*) @ 0x00000000117ae51a\r\n4. ./build_docker/./src/Processors/QueryPlan/ConvertingActions.cpp:20: DB::addConvertingActions(DB::QueryPlan&, DB::Block const&, bool) @ 0x0000000013bcf9bd\r\n5. ./build_docker/./src/Processors/QueryPlan/ParallelReplicasLocalPlan.cpp:102: DB::createLocalPlanForParallelReplicas(std::shared_ptr<DB::IAST> const&, DB::Block const&, std::shared_ptr<DB::Context const>, DB::QueryProcessingStage::Enum, std::shared_ptr<DB::ParallelReplicasReadingCoordinator>, std::unique_ptr<DB::IQueryPlanStep, std::default_delete<DB::IQueryPlanStep>>, unsigned long) @ 0x0000000013c07460\r\n6. ./build_docker/./src/Interpreters/ClusterProxy/executeQuery.cpp:625: DB::ClusterProxy::executeQueryWithParallelReplicas(DB::QueryPlan&, DB::StorageID const&, DB::Block const&, DB::QueryProcessingStage::Enum, std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const>, std::shared_ptr<std::list<DB::StorageLimits, std::allocator<DB::StorageLimits>> const>, std::unique_ptr<DB::IQueryPlanStep, std::default_delete<DB::IQueryPlanStep>>) @ 0x00000000126ad8e7\r\n7. ./build_docker/./src/Interpreters/ClusterProxy/executeQuery.cpp:719: DB::ClusterProxy::executeQueryWithParallelReplicas(DB::QueryPlan&, DB::StorageID const&, DB::QueryProcessingStage::Enum, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::PlannerContext> const&, std::shared_ptr<DB::Context const>, std::shared_ptr<std::list<DB::StorageLimits, std::allocator<DB::StorageLimits>> const>, std::unique_ptr<DB::IQueryPlanStep, std::default_delete<DB::IQueryPlanStep>>) @ 0x00000000126b0a27\r\n8. ./build_docker/./src/Planner/PlannerJoinTree.cpp:1076: DB::(anonymous namespace)::buildQueryPlanForTableExpression(std::shared_ptr<DB::IQueryTreeNode>, std::shared_ptr<DB::IQueryTreeNode> const&, DB::SelectQueryInfo const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::PlannerContext>&, bool, bool) @ 0x0000000012130aab\r\n9. ./build_docker/./src/Planner/PlannerJoinTree.cpp:2150: DB::buildJoinTreeQueryPlan(std::shared_ptr<DB::IQueryTreeNode> const&, DB::SelectQueryInfo const&, DB::SelectQueryOptions&, std::unordered_set<String, std::hash<String>, std::equal_to<String>, std::allocator<String>> const&, std::shared_ptr<DB::PlannerContext>&) @ 0x0000000012121ab7\r\n10. ./build_docker/./src/Planner/Planner.cpp:1546: DB::Planner::buildPlanForQueryNode() @ 0x000000001210d7e6\r\n11. ./build_docker/./src/Planner/Planner.cpp:1300: DB::Planner::buildQueryPlanIfNeeded() @ 0x0000000012108a3e\r\n12. ./src/Interpreters/InterpreterSelectQueryAnalyzer.cpp:241: DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*) @ 0x0000000012484ebd\r\n13. ./build_docker/./src/Interpreters/executeQuery.cpp:1602: DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x000000001248029c\r\n14. ./build_docker/./src/Server/TCPHandler.cpp:658: DB::TCPHandler::runImpl() @ 0x000000001372856c\r\n15. ./build_docker/./src/Server/TCPHandler.cpp:2625: DB::TCPHandler::run() @ 0x00000000137433b9\r\n16. ./build_docker/./base/poco/Net/src/TCPServerConnection.cpp:40: Poco::Net::TCPServerConnection::start() @ 0x0000000016c568a7\r\n17. ./build_docker/./base/poco/Net/src/TCPServerDispatcher.cpp:115: Poco::Net::TCPServerDispatcher::run() @ 0x0000000016c56cf9\r\n18. ./build_docker/./base/poco/Foundation/src/ThreadPool.cpp:205: Poco::PooledThread::run() @ 0x0000000016c2329b\r\n19. ./base/poco/Foundation/src/Thread_POSIX.cpp:335: Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000016c2177d\r\n20. ? @ 0x00007fe59de9ca94\r\n21. ? @ 0x00007fe59df29c3c\r\n\r\n```\r\n\r\nAffected tests:\r\n```\r\n03240_insert_select_named_tuple.sql\r\n```\r\n\r\nVersion 25.1.1.1921\n",
  "hints_text": "Is broken after 25.1\nhttps://fiddle.clickhouse.com/9b27238d-f7bc-441f-8210-502ad296abdd\n@KochetovNicolai, check https://github.com/ClickHouse/ClickHouse/issues/65587\nSame problem https://github.com/ClickHouse/ClickHouse/issues/74343\nLooks similar to https://github.com/ClickHouse/ClickHouse/issues/74367",
  "created_at": "2025-05-21T01:43:00Z"
}