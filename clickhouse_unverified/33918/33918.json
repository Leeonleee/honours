{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 33918,
  "instance_id": "ClickHouse__ClickHouse-33918",
  "issue_numbers": [
    "33820"
  ],
  "base_commit": "edc8568b2f186b5a77114619a0898349cede2e92",
  "patch": "diff --git a/src/Dictionaries/CacheDictionary.cpp b/src/Dictionaries/CacheDictionary.cpp\nindex 4b242ee7fd9d..cad3e3b8799c 100644\n--- a/src/Dictionaries/CacheDictionary.cpp\n+++ b/src/Dictionaries/CacheDictionary.cpp\n@@ -271,7 +271,6 @@ ColumnUInt8::Ptr CacheDictionary<dictionary_key_type>::hasKeys(const Columns & k\n     if (dictionary_key_type == DictionaryKeyType::Complex)\n         dict_struct.validateKeyTypes(key_types);\n \n-\n     DictionaryKeysArenaHolder<dictionary_key_type> arena_holder;\n     DictionaryKeysExtractor<dictionary_key_type> extractor(key_columns, arena_holder.getComplexKeyArena());\n     const auto keys = extractor.extractAllKeys();\ndiff --git a/src/Dictionaries/FlatDictionary.cpp b/src/Dictionaries/FlatDictionary.cpp\nindex e99503b881ba..40cc735557c4 100644\n--- a/src/Dictionaries/FlatDictionary.cpp\n+++ b/src/Dictionaries/FlatDictionary.cpp\n@@ -294,7 +294,36 @@ void FlatDictionary::blockToAttributes(const Block & block)\n     size_t keys_size = keys_extractor.getKeysSize();\n \n     static constexpr size_t key_offset = 1;\n-    for (size_t attribute_index = 0; attribute_index < attributes.size(); ++attribute_index)\n+\n+    size_t attributes_size = attributes.size();\n+\n+    if (unlikely(attributes_size == 0))\n+    {\n+        for (size_t i = 0; i < keys_size; ++i)\n+        {\n+            auto key = keys_extractor.extractCurrentKey();\n+\n+            if (unlikely(key >= configuration.max_array_size))\n+                throw Exception(ErrorCodes::ARGUMENT_OUT_OF_BOUND,\n+                    \"{}: identifier should be less than {}\",\n+                    getFullName(),\n+                    toString(configuration.max_array_size));\n+\n+            if (key >= loaded_keys.size())\n+            {\n+                const size_t elements_count = key + 1;\n+                loaded_keys.resize(elements_count, false);\n+            }\n+\n+            loaded_keys[key] = true;\n+\n+            keys_extractor.rollbackCurrentKey();\n+        }\n+\n+        return;\n+    }\n+\n+    for (size_t attribute_index = 0; attribute_index < attributes_size; ++attribute_index)\n     {\n         const IColumn & attribute_column = *block.safeGetByPosition(attribute_index + key_offset).column;\n         Attribute & attribute = attributes[attribute_index];\n@@ -494,21 +523,6 @@ void FlatDictionary::resize(Attribute & attribute, UInt64 key)\n     }\n }\n \n-template <typename T>\n-void FlatDictionary::setAttributeValueImpl(Attribute & attribute, UInt64 key, const T & value)\n-{\n-    auto & array = std::get<ContainerType<T>>(attribute.container);\n-    array[key] = value;\n-    loaded_keys[key] = true;\n-}\n-\n-template <>\n-void FlatDictionary::setAttributeValueImpl<String>(Attribute & attribute, UInt64 key, const String & value)\n-{\n-    auto arena_value = copyStringInArena(string_arena, value);\n-    setAttributeValueImpl(attribute, key, arena_value);\n-}\n-\n void FlatDictionary::setAttributeValue(Attribute & attribute, const UInt64 key, const Field & value)\n {\n     auto type_call = [&](const auto & dictionary_attribute_type)\n@@ -526,7 +540,20 @@ void FlatDictionary::setAttributeValue(Attribute & attribute, const UInt64 key,\n             return;\n         }\n \n-        setAttributeValueImpl<AttributeType>(attribute, key, value.get<AttributeType>());\n+        auto & attribute_value = value.get<AttributeType>();\n+\n+        auto & container = std::get<ContainerType<ValueType>>(attribute.container);\n+        loaded_keys[key] = true;\n+\n+        if constexpr (std::is_same_v<ValueType, StringRef>)\n+        {\n+            auto arena_value = copyStringInArena(string_arena, attribute_value);\n+            container[key] = arena_value;\n+        }\n+        else\n+        {\n+            container[key] = attribute_value;\n+        }\n     };\n \n     callOnDictionaryAttributeType(attribute.type, type_call);\ndiff --git a/src/Dictionaries/FlatDictionary.h b/src/Dictionaries/FlatDictionary.h\nindex e8f40ea1d662..55898a0d1792 100644\n--- a/src/Dictionaries/FlatDictionary.h\n+++ b/src/Dictionaries/FlatDictionary.h\n@@ -154,9 +154,6 @@ class FlatDictionary final : public IDictionary\n     template <typename T>\n     void resize(Attribute & attribute, UInt64 key);\n \n-    template <typename T>\n-    void setAttributeValueImpl(Attribute & attribute, UInt64 key, const T & value);\n-\n     void setAttributeValue(Attribute & attribute, UInt64 key, const Field & value);\n \n     const DictionaryStructure dict_struct;\ndiff --git a/src/Dictionaries/HashedArrayDictionary.cpp b/src/Dictionaries/HashedArrayDictionary.cpp\nindex 55a3adc32ae4..e35340c76189 100644\n--- a/src/Dictionaries/HashedArrayDictionary.cpp\n+++ b/src/Dictionaries/HashedArrayDictionary.cpp\n@@ -158,12 +158,6 @@ ColumnUInt8::Ptr HashedArrayDictionary<dictionary_key_type>::hasKeys(const Colum\n     auto result = ColumnUInt8::create(keys_size, false);\n     auto & out = result->getData();\n \n-    if (attributes.empty())\n-    {\n-        query_count.fetch_add(keys_size, std::memory_order_relaxed);\n-        return result;\n-    }\n-\n     size_t keys_found = 0;\n \n     for (size_t requested_key_index = 0; requested_key_index < keys_size; ++requested_key_index)\ndiff --git a/src/Dictionaries/HashedDictionary.cpp b/src/Dictionaries/HashedDictionary.cpp\nindex 8417455087e0..c83735a63303 100644\n--- a/src/Dictionaries/HashedDictionary.cpp\n+++ b/src/Dictionaries/HashedDictionary.cpp\n@@ -177,15 +177,25 @@ ColumnUInt8::Ptr HashedDictionary<dictionary_key_type, sparse>::hasKeys(const Co\n     auto result = ColumnUInt8::create(keys_size, false);\n     auto & out = result->getData();\n \n-    if (attributes.empty())\n+    size_t keys_found = 0;\n+\n+    if (unlikely(attributes.empty()))\n     {\n+        for (size_t requested_key_index = 0; requested_key_index < keys_size; ++requested_key_index)\n+        {\n+            auto requested_key = extractor.extractCurrentKey();\n+            out[requested_key_index] = no_attributes_container.find(requested_key) != no_attributes_container.end();\n+            keys_found += out[requested_key_index];\n+            extractor.rollbackCurrentKey();\n+        }\n+\n         query_count.fetch_add(keys_size, std::memory_order_relaxed);\n+        found_count.fetch_add(keys_found, std::memory_order_relaxed);\n         return result;\n     }\n \n     const auto & attribute = attributes.front();\n     bool is_attribute_nullable = attribute.is_nullable_set.has_value();\n-    size_t keys_found = 0;\n \n     getAttributeContainer(0, [&](const auto & container)\n     {\n@@ -423,7 +433,25 @@ void HashedDictionary<dictionary_key_type, sparse>::blockToAttributes(const Bloc\n \n     Field column_value_to_insert;\n \n-    for (size_t attribute_index = 0; attribute_index < attributes.size(); ++attribute_index)\n+    size_t attributes_size = attributes.size();\n+\n+    if (unlikely(attributes_size == 0))\n+    {\n+        for (size_t key_index = 0; key_index < keys_size; ++key_index)\n+        {\n+            auto key = keys_extractor.extractCurrentKey();\n+\n+            if constexpr (std::is_same_v<KeyType, StringRef>)\n+                key = copyStringInArena(string_arena, key);\n+\n+            no_attributes_container.insert(key);\n+            keys_extractor.rollbackCurrentKey();\n+        }\n+\n+        return;\n+    }\n+\n+    for (size_t attribute_index = 0; attribute_index < attributes_size; ++attribute_index)\n     {\n         const IColumn & attribute_column = *block.safeGetByPosition(skip_keys_size_offset + attribute_index).column;\n         auto & attribute = attributes[attribute_index];\n@@ -487,7 +515,21 @@ void HashedDictionary<dictionary_key_type, sparse>::resize(size_t added_rows)\n     if (unlikely(!added_rows))\n         return;\n \n-    for (size_t attribute_index = 0; attribute_index < attributes.size(); ++attribute_index)\n+    size_t attributes_size = attributes.size();\n+\n+    if (unlikely(attributes_size == 0))\n+    {\n+        size_t reserve_size = added_rows + no_attributes_container.size();\n+\n+        if constexpr (sparse)\n+            no_attributes_container.resize(reserve_size);\n+        else\n+            no_attributes_container.reserve(reserve_size);\n+\n+        return;\n+    }\n+\n+    for (size_t attribute_index = 0; attribute_index < attributes_size; ++attribute_index)\n     {\n         getAttributeContainer(attribute_index, [added_rows](auto & attribute_map)\n         {\n@@ -570,7 +612,9 @@ void HashedDictionary<dictionary_key_type, sparse>::loadData()\n                 }\n             }\n             else\n+            {\n                 resize(block.rows());\n+            }\n \n             blockToAttributes(block);\n         }\n@@ -589,9 +633,10 @@ void HashedDictionary<dictionary_key_type, sparse>::loadData()\n template <DictionaryKeyType dictionary_key_type, bool sparse>\n void HashedDictionary<dictionary_key_type, sparse>::calculateBytesAllocated()\n {\n-    bytes_allocated += attributes.size() * sizeof(attributes.front());\n+    size_t attributes_size = attributes.size();\n+    bytes_allocated += attributes_size * sizeof(attributes.front());\n \n-    for (size_t i = 0; i < attributes.size(); ++i)\n+    for (size_t i = 0; i < attributes_size; ++i)\n     {\n         getAttributeContainer(i, [&](const auto & container)\n         {\n@@ -622,6 +667,22 @@ void HashedDictionary<dictionary_key_type, sparse>::calculateBytesAllocated()\n             bytes_allocated = attributes[i].is_nullable_set->getBufferSizeInBytes();\n     }\n \n+    if (unlikely(attributes_size == 0))\n+    {\n+        bytes_allocated += sizeof(no_attributes_container);\n+\n+        if constexpr (sparse)\n+        {\n+            bytes_allocated += no_attributes_container.size() * (sizeof(KeyType));\n+            bucket_count = no_attributes_container.bucket_count();\n+        }\n+        else\n+        {\n+            bytes_allocated += no_attributes_container.getBufferSizeInBytes();\n+            bucket_count = no_attributes_container.getBufferSizeInCells();\n+        }\n+    }\n+\n     bytes_allocated += string_arena.size();\n \n     if (update_field_loaded_block)\n@@ -657,6 +718,18 @@ Pipe HashedDictionary<dictionary_key_type, sparse>::read(const Names & column_na\n             }\n         });\n     }\n+    else\n+    {\n+        keys.reserve(no_attributes_container.size());\n+\n+        for (const auto & key : no_attributes_container)\n+        {\n+            if constexpr (sparse)\n+                keys.emplace_back(key);\n+            else\n+                keys.emplace_back(key.getKey());\n+        }\n+    }\n \n     ColumnsWithTypeAndName key_columns;\n \ndiff --git a/src/Dictionaries/HashedDictionary.h b/src/Dictionaries/HashedDictionary.h\nindex c1761944b14b..605477efc78f 100644\n--- a/src/Dictionaries/HashedDictionary.h\n+++ b/src/Dictionaries/HashedDictionary.h\n@@ -5,6 +5,7 @@\n #include <variant>\n #include <optional>\n #include <sparsehash/sparse_hash_map>\n+#include <sparsehash/sparse_hash_set>\n \n #include <Common/HashTable/HashMap.h>\n #include <Common/HashTable/HashSet.h>\n@@ -120,9 +121,14 @@ class HashedDictionary final : public IDictionary\n     template <typename Value>\n     using CollectionTypeNonSparse = std::conditional_t<\n         dictionary_key_type == DictionaryKeyType::Simple,\n-        HashMap<UInt64, Value>,\n+        HashMap<UInt64, Value, DefaultHash<UInt64>>,\n         HashMapWithSavedHash<StringRef, Value, DefaultHash<StringRef>>>;\n \n+    using NoAttributesCollectionTypeNonSparse = std::conditional_t<\n+        dictionary_key_type == DictionaryKeyType::Simple,\n+        HashSet<UInt64, DefaultHash<UInt64>>,\n+        HashSetWithSavedHash<StringRef, DefaultHash<StringRef>>>;\n+\n     /// Here we use sparse_hash_map with DefaultHash<> for the following reasons:\n     ///\n     /// - DefaultHash<> is used for HashMap\n@@ -140,9 +146,13 @@ class HashedDictionary final : public IDictionary\n         google::sparse_hash_map<UInt64, Value, DefaultHash<KeyType>>,\n         google::sparse_hash_map<StringRef, Value, DefaultHash<KeyType>>>;\n \n+    using NoAttributesCollectionTypeSparse = google::sparse_hash_set<KeyType, DefaultHash<KeyType>>;\n+\n     template <typename Value>\n     using CollectionType = std::conditional_t<sparse, CollectionTypeSparse<Value>, CollectionTypeNonSparse<Value>>;\n \n+    using NoAttributesCollectionType = std::conditional_t<sparse, NoAttributesCollectionTypeSparse, NoAttributesCollectionTypeNonSparse>;\n+\n     using NullableSet = HashSet<KeyType, DefaultHash<KeyType>>;\n \n     struct Attribute final\n@@ -214,6 +224,7 @@ class HashedDictionary final : public IDictionary\n \n     BlockPtr update_field_loaded_block;\n     Arena string_arena;\n+    NoAttributesCollectionType no_attributes_container;\n };\n \n extern template class HashedDictionary<DictionaryKeyType::Simple, false>;\ndiff --git a/src/Dictionaries/RangeHashedDictionary.cpp b/src/Dictionaries/RangeHashedDictionary.cpp\nindex e5c08b52881f..979cfce6ce22 100644\n--- a/src/Dictionaries/RangeHashedDictionary.cpp\n+++ b/src/Dictionaries/RangeHashedDictionary.cpp\n@@ -780,6 +780,9 @@ void registerDictionaryRangeHashed(DictionaryFactory & factory)\n                 \"{}: dictionary of layout 'range_hashed' requires .structure.range_min and .structure.range_max\",\n                 full_name);\n \n+        if (dict_struct.attributes.empty())\n+            throw Exception(ErrorCodes::UNSUPPORTED_METHOD, \"Empty attributes are not supported for dictionary of layout 'range_hashed'\");\n+\n         const auto dict_id = StorageID::fromDictionaryConfig(config, config_prefix);\n         const DictionaryLifetime dict_lifetime{config, config_prefix + \".lifetime\"};\n         const bool require_nonempty = config.getBool(config_prefix + \".require_nonempty\", false);\n@@ -803,6 +806,9 @@ void registerDictionaryRangeHashed(DictionaryFactory & factory)\n                 \"{}: dictionary of layout 'complex_key_range_hashed' requires .structure.range_min and .structure.range_max\",\n                 full_name);\n \n+        if (dict_struct.attributes.empty())\n+            throw Exception(ErrorCodes::UNSUPPORTED_METHOD, \"Empty attributes are not supported for dictionary of layout 'complex_key_range_hashed'\");\n+\n         const auto dict_id = StorageID::fromDictionaryConfig(config, config_prefix);\n         const DictionaryLifetime dict_lifetime{config, config_prefix + \".lifetime\"};\n         const bool require_nonempty = config.getBool(config_prefix + \".require_nonempty\", false);\ndiff --git a/src/Dictionaries/RangeHashedDictionary.h b/src/Dictionaries/RangeHashedDictionary.h\nindex f31d6415dc80..f7859d304269 100644\n--- a/src/Dictionaries/RangeHashedDictionary.h\n+++ b/src/Dictionaries/RangeHashedDictionary.h\n@@ -96,9 +96,14 @@ class RangeHashedDictionary final : public IDictionary\n     template <typename Value>\n     using CollectionType = std::conditional_t<\n         dictionary_key_type == DictionaryKeyType::Simple,\n-        HashMap<UInt64, Values<Value>>,\n+        HashMap<UInt64, Values<Value>, DefaultHash<UInt64>>,\n         HashMapWithSavedHash<StringRef, Values<Value>, DefaultHash<StringRef>>>;\n \n+    using NoAttributesCollectionType = std::conditional_t<\n+        dictionary_key_type == DictionaryKeyType::Simple,\n+        HashMap<UInt64, IntervalSet<RangeInterval>>,\n+        HashMapWithSavedHash<StringRef, IntervalSet<RangeInterval>>>;\n+\n     struct Attribute final\n     {\n     public:\n@@ -189,6 +194,7 @@ class RangeHashedDictionary final : public IDictionary\n     mutable std::atomic<size_t> query_count{0};\n     mutable std::atomic<size_t> found_count{0};\n     Arena string_arena;\n+    NoAttributesCollectionType no_attributes_container;\n };\n \n }\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02183_dictionary_no_attributes.reference b/tests/queries/0_stateless/02183_dictionary_no_attributes.reference\nnew file mode 100644\nindex 000000000000..972b0c7c671b\n--- /dev/null\n+++ b/tests/queries/0_stateless/02183_dictionary_no_attributes.reference\n@@ -0,0 +1,40 @@\n+0\n+1\n+FlatDictionary\n+1\n+1\n+0\n+0\n+1\n+HashedDictionary\n+1\n+1\n+0\n+0\n+1\n+HashedArrayDictionary\n+1\n+1\n+0\n+0\n+1\n+CacheDictionary\n+1\n+1\n+0\n+0\n+1\n+DirectDictionary\n+1\n+1\n+0\n+0\n+1\n+IPTrieDictionary\n+1\n+0\n+127.0.0.0/32\n+PolygonDictionary\n+1\n+0\n+[[[(0,0),(0,1),(1,1),(1,0)]]]\ndiff --git a/tests/queries/0_stateless/02183_dictionary_no_attributes.sql b/tests/queries/0_stateless/02183_dictionary_no_attributes.sql\nnew file mode 100644\nindex 000000000000..193b8dc2cdc5\n--- /dev/null\n+++ b/tests/queries/0_stateless/02183_dictionary_no_attributes.sql\n@@ -0,0 +1,191 @@\n+DROP TABLE IF EXISTS 02183_dictionary_test_table;\n+CREATE TABLE 02183_dictionary_test_table (id UInt64) ENGINE=TinyLog;\n+INSERT INTO 02183_dictionary_test_table VALUES (0), (1);\n+\n+SELECT * FROM 02183_dictionary_test_table;\n+\n+DROP DICTIONARY IF EXISTS 02183_flat_dictionary;\n+CREATE DICTIONARY 02183_flat_dictionary\n+(\n+    id UInt64\n+)\n+PRIMARY KEY id\n+LAYOUT(FLAT())\n+SOURCE(CLICKHOUSE(TABLE '02183_dictionary_test_table'))\n+LIFETIME(0);\n+\n+SELECT 'FlatDictionary';\n+\n+SELECT dictGet('02183_flat_dictionary', 'value', 0); -- {serverError 36}\n+SELECT dictHas('02183_flat_dictionary', 0);\n+SELECT dictHas('02183_flat_dictionary', 1);\n+SELECT dictHas('02183_flat_dictionary', 2);\n+\n+SELECT * FROM 02183_flat_dictionary;\n+\n+DROP DICTIONARY 02183_flat_dictionary;\n+\n+DROP DICTIONARY IF EXISTS 02183_hashed_dictionary;\n+CREATE DICTIONARY 02183_hashed_dictionary\n+(\n+    id UInt64\n+)\n+PRIMARY KEY id\n+LAYOUT(HASHED())\n+SOURCE(CLICKHOUSE(TABLE '02183_dictionary_test_table'))\n+LIFETIME(0);\n+\n+SELECT 'HashedDictionary';\n+\n+SELECT dictHas('02183_hashed_dictionary', 0);\n+SELECT dictHas('02183_hashed_dictionary', 1);\n+SELECT dictHas('02183_hashed_dictionary', 2);\n+\n+SELECT * FROM 02183_hashed_dictionary;\n+\n+DROP DICTIONARY 02183_hashed_dictionary;\n+\n+DROP DICTIONARY IF EXISTS 02183_hashed_array_dictionary;\n+CREATE DICTIONARY 02183_hashed_array_dictionary\n+(\n+    id UInt64\n+)\n+PRIMARY KEY id\n+LAYOUT(HASHED_ARRAY())\n+SOURCE(CLICKHOUSE(TABLE '02183_dictionary_test_table'))\n+LIFETIME(0);\n+\n+SELECT 'HashedArrayDictionary';\n+\n+SELECT dictHas('02183_hashed_array_dictionary', 0);\n+SELECT dictHas('02183_hashed_array_dictionary', 1);\n+SELECT dictHas('02183_hashed_array_dictionary', 2);\n+\n+SELECT * FROM 02183_hashed_array_dictionary;\n+\n+DROP DICTIONARY 02183_hashed_array_dictionary;\n+\n+DROP DICTIONARY IF EXISTS 02183_cache_dictionary;\n+CREATE DICTIONARY 02183_cache_dictionary\n+(\n+    id UInt64\n+)\n+PRIMARY KEY id\n+LAYOUT(CACHE(SIZE_IN_CELLS 10))\n+SOURCE(CLICKHOUSE(TABLE '02183_dictionary_test_table'))\n+LIFETIME(0);\n+\n+SELECT 'CacheDictionary';\n+\n+SELECT dictHas('02183_cache_dictionary', 0);\n+SELECT dictHas('02183_cache_dictionary', 1);\n+SELECT dictHas('02183_cache_dictionary', 2);\n+\n+SELECT * FROM 02183_cache_dictionary;\n+\n+DROP DICTIONARY 02183_cache_dictionary;\n+\n+DROP DICTIONARY IF EXISTS 02183_direct_dictionary;\n+CREATE DICTIONARY 02183_direct_dictionary\n+(\n+    id UInt64\n+)\n+PRIMARY KEY id\n+LAYOUT(HASHED())\n+SOURCE(CLICKHOUSE(TABLE '02183_dictionary_test_table'))\n+LIFETIME(0);\n+\n+SELECT 'DirectDictionary';\n+\n+SELECT dictHas('02183_direct_dictionary', 0);\n+SELECT dictHas('02183_direct_dictionary', 1);\n+SELECT dictHas('02183_direct_dictionary', 2);\n+\n+SELECT * FROM 02183_direct_dictionary;\n+\n+DROP DICTIONARY 02183_direct_dictionary;\n+\n+DROP TABLE 02183_dictionary_test_table;\n+\n+DROP TABLE IF EXISTS ip_trie_dictionary_source_table;\n+CREATE TABLE ip_trie_dictionary_source_table\n+(\n+    prefix String\n+) ENGINE = TinyLog;\n+\n+INSERT INTO ip_trie_dictionary_source_table VALUES ('127.0.0.0');\n+\n+DROP DICTIONARY IF EXISTS 02183_ip_trie_dictionary;\n+CREATE DICTIONARY 02183_ip_trie_dictionary\n+(\n+    prefix String\n+)\n+PRIMARY KEY prefix\n+SOURCE(CLICKHOUSE(TABLE 'ip_trie_dictionary_source_table'))\n+LAYOUT(IP_TRIE())\n+LIFETIME(0);\n+\n+SELECT 'IPTrieDictionary';\n+\n+SELECT dictHas('02183_ip_trie_dictionary', tuple(IPv4StringToNum('127.0.0.0')));\n+SELECT dictHas('02183_ip_trie_dictionary', tuple(IPv4StringToNum('127.0.0.1')));\n+SELECT * FROM 02183_ip_trie_dictionary;\n+\n+DROP DICTIONARY 02183_ip_trie_dictionary;\n+DROP TABLE ip_trie_dictionary_source_table;\n+\n+DROP TABLE IF EXISTS 02183_polygon_dictionary_source_table;\n+CREATE TABLE 02183_polygon_dictionary_source_table\n+(\n+    key Array(Array(Array(Tuple(Float64, Float64))))\n+) ENGINE = TinyLog;\n+\n+INSERT INTO 02183_polygon_dictionary_source_table VALUES ([[[(0, 0), (0, 1), (1, 1), (1, 0)]]]);\n+\n+DROP DICTIONARY IF EXISTS 02183_polygon_dictionary;\n+CREATE DICTIONARY 02183_polygon_dictionary\n+(\n+    key Array(Array(Array(Tuple(Float64, Float64))))\n+)\n+PRIMARY KEY key\n+SOURCE(CLICKHOUSE(TABLE '02183_polygon_dictionary_source_table'))\n+LAYOUT(POLYGON(store_polygon_key_column 1))\n+LIFETIME(0);\n+\n+SELECT 'PolygonDictionary';\n+\n+SELECT dictHas('02183_polygon_dictionary', tuple(0.5, 0.5));\n+SELECT dictHas('02183_polygon_dictionary', tuple(1.5, 1.5));\n+SELECT * FROM 02183_polygon_dictionary;\n+\n+DROP DICTIONARY 02183_polygon_dictionary;\n+DROP TABLE 02183_polygon_dictionary_source_table;\n+\n+DROP TABLE IF EXISTS 02183_range_dictionary_source_table;\n+CREATE TABLE 02183_range_dictionary_source_table\n+(\n+  key UInt64,\n+  start UInt64,\n+  end UInt64\n+)\n+ENGINE = TinyLog;\n+\n+INSERT INTO 02183_range_dictionary_source_table VALUES(1, 0, 1);\n+\n+DROP DICTIONARY IF EXISTS 02183_range_dictionary;\n+CREATE DICTIONARY 02183_range_dictionary\n+(\n+  key UInt64,\n+  start UInt64,\n+  end UInt64\n+)\n+PRIMARY KEY key\n+SOURCE(CLICKHOUSE(TABLE '02183_range_dictionary_source_table'))\n+LAYOUT(RANGE_HASHED())\n+RANGE(MIN start MAX end)\n+LIFETIME(0);\n+\n+SELECT * FROM 02183_range_dictionary; -- {serverError 1}\n+\n+DROP DICTIONARY 02183_range_dictionary;\n+DROP TABLE 02183_range_dictionary_source_table;\n",
  "problem_statement": "Server crash when accessing a dictionary without attributes\nWhen creating a dictionary without attributes in the database with the Ordinary engine and querying the dictionary, the clickhouse server crashes\r\n\r\n```\r\nSELECT version()\r\n\r\n\u250c\u2500version()\u2500\u2500\u2510\r\n\u2502 21.12.3.32 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nCREATE DATABASE test ENGINE = Ordinary;\r\n\r\nCREATE TABLE test.dict_src_test\r\n(\r\n    `StartDate` Date,\r\n    `EndDate` Date,\r\n    `ColumnString` String,\r\n    `Columnone` String,\r\n    `Columntwo` String,\r\n    `Columnthree` String,\r\n    `Value` Int64,\r\n    `Columnsix` String\r\n)\r\nENGINE = ReplacingMergeTree()\r\nPARTITION BY toYear(StartDate)\r\nPRIMARY KEY StartDate\r\nORDER BY (StartDate,\r\n EndDate,\r\n ColumnString,\r\n Columnone,\r\n Columntwo,\r\n Columnthree,\r\n Value,\r\n Columnsix)\r\nSETTINGS index_granularity = 8192;\r\n\r\nCREATE DICTIONARY test.dict_test\r\n(\r\n    `ColumnString` String,\r\n    `Columnone` String,\r\n    `Columntwo` String,\r\n    `Value` UInt64,\r\n    `Columnsix` String,\r\n    `StartDate` DATE,\r\n    `EndDate` DATE\r\n)\r\nPRIMARY KEY ColumnString,\r\n Columnone,\r\n Columntwo,\r\n Value,\r\n Columnsix\r\nSOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' PASSWORD '' DB 'test' TABLE 'dict_src_test'))\r\nLIFETIME(MIN 82800 MAX 86400)\r\nLAYOUT(COMPLEX_KEY_RANGE_HASHED())\r\nRANGE(MIN StartDate MAX EndDate);\r\n\r\nINSERT INTO test.dict_src_test (ColumnString) VALUES ('Three');\r\nINSERT INTO test.dict_src_test (Columnone) VALUES ('Apple');\r\nINSERT INTO test.dict_src_test (Columntwo) VALUES ('333333');\r\nINSERT INTO test.dict_src_test (Columnthree) VALUES ('Pen');\r\nINSERT INTO test.dict_src_test (Value) VALUES ('6666');\r\nINSERT INTO test.dict_src_test (Columnsix) VALUES ('Time');\r\n\r\nselect * from test.dict_test;\r\n\r\n2022.01.19 13:32:10.458512 [ 814 ] <Fatal> BaseDaemon: ########################################\r\n2022.01.19 13:32:10.458562 [ 814 ] <Fatal> BaseDaemon: (version 21.12.3.32 (official build), build id: FA4A7F489F3FF6E3) (from thread 589) (query_id: 4022beaa-4bd1-4e0d-a921-63ebf9fa12ad) Received signal Segmentation fault (11)\r\n2022.01.19 13:32:10.458582 [ 814 ] <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Address not mapped to object.\r\n2022.01.19 13:32:10.458605 [ 814 ] <Fatal> BaseDaemon: Stack trace: 0x10f0ce58 0x10f03822 0x10ea6fb3 0x136aee8c 0x13686412 0x1329076e 0x132888d4 0x132883b6 0x132d7ea5 0x132d8fb6 0x135289f0 0x135267d5 0x13fd8c51 0x13fec4b9 0x16f3d6af 0x16f3fb01 0x1704e889 0x1704bf80 0x7f91cc9f6609 0x7f91cc912293\r\n2022.01.19 13:32:10.458663 [ 814 ] <Fatal> BaseDaemon: 2. bool DB::RangeHashedDictionary<(DB::DictionaryKeyType)1>::read(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, unsigned long, unsigned long) const::'lambda'(auto const&)::operator()<DB::TypePair<DB::DataTypeDate, void> >(auto const&) @ 0x10f0ce58 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.458702 [ 814 ] <Fatal> BaseDaemon: 3. bool DB::callOnIndexAndDataType<void, DB::RangeHashedDictionary<(DB::DictionaryKeyType)1>::read(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, unsigned long, unsigned long) const::'lambda'(auto const&)&>(DB::TypeIndex, DB::RangeHashedDictionary<(DB::DictionaryKeyType)1>::read(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, unsigned long, unsigned long) const::'lambda'(auto const&)&) @ 0x10f03822 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.458732 [ 814 ] <Fatal> BaseDaemon: 4. DB::RangeHashedDictionary<(DB::DictionaryKeyType)1>::read(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, unsigned long, unsigned long) const @ 0x10ea6fb3 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.458765 [ 814 ] <Fatal> BaseDaemon: 5. DB::StorageDictionary::read(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::SelectQueryInfo&, std::__1::shared_ptr<DB::Context const>, DB::QueryProcessingStage::Enum, unsigned long, unsigned int) @ 0x136aee8c in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.458797 [ 814 ] <Fatal> BaseDaemon: 6. DB::IStorage::read(DB::QueryPlan&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::SelectQueryInfo&, std::__1::shared_ptr<DB::Context const>, DB::QueryProcessingStage::Enum, unsigned long, unsigned int) @ 0x13686412 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.458835 [ 814 ] <Fatal> BaseDaemon: 7. DB::InterpreterSelectQuery::executeFetchColumns(DB::QueryProcessingStage::Enum, DB::QueryPlan&) @ 0x1329076e in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.458876 [ 814 ] <Fatal> BaseDaemon: 8. DB::InterpreterSelectQuery::executeImpl(DB::QueryPlan&, std::__1::optional<DB::Pipe>) @ 0x132888d4 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.458898 [ 814 ] <Fatal> BaseDaemon: 9. DB::InterpreterSelectQuery::buildQueryPlan(DB::QueryPlan&) @ 0x132883b6 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.458924 [ 814 ] <Fatal> BaseDaemon: 10. DB::InterpreterSelectWithUnionQuery::buildQueryPlan(DB::QueryPlan&) @ 0x132d7ea5 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.458949 [ 814 ] <Fatal> BaseDaemon: 11. DB::InterpreterSelectWithUnionQuery::execute() @ 0x132d8fb6 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.458974 [ 814 ] <Fatal> BaseDaemon: 12. ? @ 0x135289f0 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.459001 [ 814 ] <Fatal> BaseDaemon: 13. DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::Context>, bool, DB::QueryProcessingStage::Enum) @ 0x135267d5 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.459023 [ 814 ] <Fatal> BaseDaemon: 14. DB::TCPHandler::runImpl() @ 0x13fd8c51 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.459048 [ 814 ] <Fatal> BaseDaemon: 15. DB::TCPHandler::run() @ 0x13fec4b9 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.459079 [ 814 ] <Fatal> BaseDaemon: 16. Poco::Net::TCPServerConnection::start() @ 0x16f3d6af in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.459107 [ 814 ] <Fatal> BaseDaemon: 17. Poco::Net::TCPServerDispatcher::run() @ 0x16f3fb01 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.459141 [ 814 ] <Fatal> BaseDaemon: 18. Poco::PooledThread::run() @ 0x1704e889 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.459164 [ 814 ] <Fatal> BaseDaemon: 19. Poco::ThreadImpl::runnableEntry(void*) @ 0x1704bf80 in /usr/bin/clickhouse\r\n2022.01.19 13:32:10.459187 [ 814 ] <Fatal> BaseDaemon: 20. ? @ 0x7f91cc9f6609 in ?\r\n2022.01.19 13:32:10.459207 [ 814 ] <Fatal> BaseDaemon: 21. clone @ 0x7f91cc912293 in ?\r\n2022.01.19 13:32:10.561139 [ 814 ] <Fatal> BaseDaemon: Calculated checksum of the binary: 5BEBF5792A40F7E345921EDA3698245B.\r\n```\n",
  "hints_text": "",
  "created_at": "2022-01-22T20:03:38Z",
  "modified_files": [
    "src/Dictionaries/CacheDictionary.cpp",
    "src/Dictionaries/FlatDictionary.cpp",
    "src/Dictionaries/FlatDictionary.h",
    "src/Dictionaries/HashedArrayDictionary.cpp",
    "src/Dictionaries/HashedDictionary.cpp",
    "src/Dictionaries/HashedDictionary.h",
    "src/Dictionaries/RangeHashedDictionary.cpp",
    "src/Dictionaries/RangeHashedDictionary.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02183_dictionary_no_attributes.reference",
    "b/tests/queries/0_stateless/02183_dictionary_no_attributes.sql"
  ]
}