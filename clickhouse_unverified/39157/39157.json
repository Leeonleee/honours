{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 39157,
  "instance_id": "ClickHouse__ClickHouse-39157",
  "issue_numbers": [
    "36043",
    "37381"
  ],
  "base_commit": "812143c76ba0ef50041f16c98c5c5c05c6fd4292",
  "patch": "diff --git a/src/Interpreters/ExpressionAnalyzer.cpp b/src/Interpreters/ExpressionAnalyzer.cpp\nindex 483ffad67b72..23258c600991 100644\n--- a/src/Interpreters/ExpressionAnalyzer.cpp\n+++ b/src/Interpreters/ExpressionAnalyzer.cpp\n@@ -1253,7 +1253,7 @@ JoinPtr SelectQueryExpressionAnalyzer::makeJoin(\n }\n \n ActionsDAGPtr SelectQueryExpressionAnalyzer::appendPrewhere(\n-    ExpressionActionsChain & chain, bool only_types, const Names & additional_required_columns)\n+    ExpressionActionsChain & chain, bool only_types)\n {\n     const auto * select_query = getSelectQuery();\n     if (!select_query->prewhere())\n@@ -1290,14 +1290,6 @@ ActionsDAGPtr SelectQueryExpressionAnalyzer::appendPrewhere(\n         NameSet required_source_columns(required_columns.begin(), required_columns.end());\n         required_source_columns.insert(first_action_names.begin(), first_action_names.end());\n \n-        /// Add required columns to required output in order not to remove them after prewhere execution.\n-        /// TODO: add sampling and final execution to common chain.\n-        for (const auto & column : additional_required_columns)\n-        {\n-            if (required_source_columns.contains(column))\n-                step.addRequiredOutput(column);\n-        }\n-\n         auto names = step.actions()->getNames();\n         NameSet name_set(names.begin(), names.end());\n \n@@ -1844,12 +1836,28 @@ ExpressionAnalysisResult::ExpressionAnalysisResult(\n     const Settings & settings = context->getSettingsRef();\n     const ConstStoragePtr & storage = query_analyzer.storage();\n \n+    Names additional_required_columns_after_prewhere;\n     ssize_t prewhere_step_num = -1;\n     ssize_t where_step_num = -1;\n     ssize_t having_step_num = -1;\n \n     auto finalize_chain = [&](ExpressionActionsChain & chain)\n     {\n+        if (prewhere_step_num >= 0)\n+        {\n+            ExpressionActionsChain::Step & step = *chain.steps.at(prewhere_step_num);\n+\n+            auto required_columns = prewhere_info->prewhere_actions->getRequiredColumnsNames();\n+            NameSet required_source_columns(required_columns.begin(), required_columns.end());\n+            /// Add required columns to required output in order not to remove them after prewhere execution.\n+            /// TODO: add sampling and final execution to common chain.\n+            for (const auto & column : additional_required_columns_after_prewhere)\n+            {\n+                if (required_source_columns.contains(column))\n+                    step.addRequiredOutput(column);\n+            }\n+        }\n+\n         chain.finalize();\n \n         finalize(chain, prewhere_step_num, where_step_num, having_step_num, query);\n@@ -1859,7 +1867,6 @@ ExpressionAnalysisResult::ExpressionAnalysisResult(\n \n     {\n         ExpressionActionsChain chain(context);\n-        Names additional_required_columns_after_prewhere;\n \n         if (storage && (query.sampleSize() || settings.parallel_replicas_count > 1))\n         {\n@@ -1881,7 +1888,7 @@ ExpressionAnalysisResult::ExpressionAnalysisResult(\n             filter_info->do_remove_column = true;\n         }\n \n-        if (auto actions = query_analyzer.appendPrewhere(chain, !first_stage, additional_required_columns_after_prewhere))\n+        if (auto actions = query_analyzer.appendPrewhere(chain, !first_stage))\n         {\n             /// Prewhere is always the first one.\n             prewhere_step_num = 0;\n@@ -1976,6 +1983,13 @@ ExpressionAnalysisResult::ExpressionAnalysisResult(\n             && !query.final()\n             && join_allow_read_in_order;\n \n+        if (storage && optimize_read_in_order)\n+        {\n+            Names columns_for_sorting_key = metadata_snapshot->getColumnsRequiredForSortingKey();\n+            additional_required_columns_after_prewhere.insert(additional_required_columns_after_prewhere.end(),\n+                columns_for_sorting_key.begin(), columns_for_sorting_key.end());\n+        }\n+\n         /// If there is aggregation, we execute expressions in SELECT and ORDER BY on the initiating server, otherwise on the source servers.\n         query_analyzer.appendSelect(chain, only_types || (need_aggregate ? !second_stage : !first_stage));\n \ndiff --git a/src/Interpreters/ExpressionAnalyzer.h b/src/Interpreters/ExpressionAnalyzer.h\nindex aae45482a977..019cda8b924a 100644\n--- a/src/Interpreters/ExpressionAnalyzer.h\n+++ b/src/Interpreters/ExpressionAnalyzer.h\n@@ -403,7 +403,7 @@ class SelectQueryExpressionAnalyzer : public ExpressionAnalyzer\n \n     /// remove_filter is set in ExpressionActionsChain::finalize();\n     /// Columns in `additional_required_columns` will not be removed (they can be used for e.g. sampling or FINAL modifier).\n-    ActionsDAGPtr appendPrewhere(ExpressionActionsChain & chain, bool only_types, const Names & additional_required_columns);\n+    ActionsDAGPtr appendPrewhere(ExpressionActionsChain & chain, bool only_types);\n     bool appendWhere(ExpressionActionsChain & chain, bool only_types);\n     bool appendGroupBy(ExpressionActionsChain & chain, bool only_types, bool optimize_aggregation_in_order, ManyExpressionActions &);\n     void appendAggregateFunctionsArguments(ExpressionActionsChain & chain, bool only_types);\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02354_read_in_order_prewhere.reference b/tests/queries/0_stateless/02354_read_in_order_prewhere.reference\nnew file mode 100644\nindex 000000000000..7d5543bf9cca\n--- /dev/null\n+++ b/tests/queries/0_stateless/02354_read_in_order_prewhere.reference\n@@ -0,0 +1,10 @@\n+1\n+1\n+1\n+2001\n+2001\n+1\n+1\n+1\n+2001\n+2001\ndiff --git a/tests/queries/0_stateless/02354_read_in_order_prewhere.sql b/tests/queries/0_stateless/02354_read_in_order_prewhere.sql\nnew file mode 100644\nindex 000000000000..c5abd5945f32\n--- /dev/null\n+++ b/tests/queries/0_stateless/02354_read_in_order_prewhere.sql\n@@ -0,0 +1,30 @@\n+drop table if exists order;\n+\n+CREATE TABLE order\n+(\n+    ID Int64,\n+    Type Int64,\n+    Num UInt64,\n+    t DateTime\n+)\n+ENGINE = MergeTree()\n+PARTITION BY toYYYYMMDD(t)\n+ORDER BY (ID, Type, Num);\n+\n+system stop merges order;\n+\n+insert into order select number%2000, 1, number, (1656700561 - intDiv(intHash32(number), 1000)) from numbers(100000);\n+insert into order select number%2000, 1, number, (1656700561 - intDiv(intHash32(number), 1000)) from numbers(100000);\n+insert into order select number%2000, 1, number, (1656700561 - intDiv(intHash32(number), 1000)) from numbers(100000);\n+\n+SELECT Num\n+FROM order\n+WHERE Type = 1 AND ID = 1\n+ORDER BY Num ASC limit 5;\n+\n+SELECT Num\n+FROM order\n+PREWHERE Type = 1\n+WHERE ID = 1\n+ORDER BY Num ASC limit 5;\n+\n",
  "problem_statement": " Not found column in block exception\nHello,\r\n\r\nWe upgraded our Clickhouse version to 22.3.3.44. After ugrade, we get strange exception in the queries. If I include 'n' word to where query, it gives an exception. \r\n\r\nI have a sample query like below:\r\n\r\n```\r\nSELECT ts FROM event WHERE ((appkey='n') AND (ecode = 'n')) ORDER BY ts ASC limit 1;\r\n```\r\n\r\nIt gives below exception:\r\n\r\n```\r\nReceived exception from server (version 22.3.3):\r\nCode: 10. DB::Exception: Received from localhost:9000. DB::Exception: Not found column ecode in block. There are only columns: appkey, ts, equals(ecode, 'n'). (NOT_FOUND_COLUMN_IN_BLOCK)\r\n```\r\n\r\nIf I change 'n' with 'a' in the where query, it doesn't give the exception:\r\n```\r\nSELECT ts FROM event WHERE ((appkey='a') AND (ecode = 'a')) ORDER BY ts ASC limit 1;\r\n```\r\n\r\nResult:\r\n\r\n```\r\n0 rows in set. Elapsed: 0.047 sec.\r\n```\r\n\r\n**Affected Version**\r\n22.3.3.44\r\n\r\n**show create table event**\r\n\r\n```\r\nCREATE TABLE event\r\n(\r\n    `appkey` String,\r\n    `ecode` String,\r\n    `userid` String,\r\n    `iid` String,\r\n    `exid` String,\r\n    `did` String,\r\n    `sid` String,\r\n    `pid` Int32,\r\n    `fid` String,\r\n    `appVersion` String,\r\n    `platform` UInt8,\r\n    `revenue` Float64,\r\n    `ts` DateTime,\r\n    `ea` String,\r\n    `eb` String,\r\n    `ec` Int32,\r\n    `ed` Int32,\r\n    `ee` String,\r\n    `ef` String,\r\n    `eg` String,\r\n    `eh` String,\r\n    `ei` String,\r\n    `ej` String,\r\n    `ek` String,\r\n    `el` Float64,\r\n    `em` String,\r\n    `en` String,\r\n    `eo` Int32,\r\n    `ep` Float64,\r\n    `eq` Float64,\r\n    `er` Float64,\r\n    `es` Float64,\r\n    `et` String,\r\n    `eu` String,\r\n    `ev` String,\r\n    `fc` Float64,\r\n    `fd` Float64,\r\n    `fe` Int32,\r\n    `ff` Int32,\r\n    `fg` UInt8,\r\n    `fh` UInt8,\r\n    `fi` DateTime,\r\n    `fj` DateTime,\r\n    `fk` String,\r\n    `fl` String,\r\n    `fm` Int32,\r\n    `fn` Int32,\r\n    `fo` String,\r\n    `fp` String,\r\n    `fq` Int64,\r\n    `fr` Int64,\r\n    `fs` String,\r\n    `ft` Float64,\r\n    `fu` Int64,\r\n    `fv` String,\r\n    `fw` Float64,\r\n    `fx` String,\r\n    `fy` Int32,\r\n    `fz` Int32,\r\n    `ga` String,\r\n    `gb` Int64,\r\n    `gc` Int64,\r\n    `data` String,\r\n    `txt` String,\r\n    `cmp` String,\r\n    `piid` String,\r\n    `uid` String,\r\n    `gd` String,\r\n    `ge` String,\r\n    `rv` Float64\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY toYYYYMMDD(ts)\r\nORDER BY (appkey, ecode, ts)\r\nSETTINGS index_granularity = 8192\r\n```\nException with optimize_move_to_prewhere = 1\n```\r\nselect version();\r\n\u250c\u2500version()\u2500\u2500\u2500\u2510\r\n\u2502 22.5.1.2079 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nCREATE TABLE order\r\n(\r\n    `ID` String,\r\n    `Type` Enum8('TYPE_0' = 0, 'TYPE_1' = 1, 'TYPE_2' = 2),\r\n    `Num` UInt64,\r\n    `Data` String,\r\n    `RowCreatedAt` DateTime DEFAULT now()\r\n)\r\nENGINE = ReplacingMergeTree()\r\nPARTITION BY toYYYYMMDD(RowCreatedAt)\r\nPRIMARY KEY ID\r\nORDER BY (ID, Type, Num)\r\nTTL RowCreatedAt + toIntervalWeek(6)\r\nSETTINGS index_granularity = 8192;\r\n\r\ninsert into order (ID, Type, Num, Data, RowCreatedAt) select toString(cityHash64(ID)%2000), case cityHash64(ID)%3 when 0 then 'TYPE_0' when 1 then 'TYPE_1' when 2 then 'TYPE_2' ELSE 'TYPE_0' END, cityHash64(ID), ID, toDateTime(toUInt32(now()) - round(rand32() / 4294967295 * 4100000, 0))  from generateRandom('ID String ', 1, 1000) limit 100000;\r\ninsert into order (ID, Type, Num, Data, RowCreatedAt) select toString(cityHash64(ID)%2000), case cityHash64(ID)%3 when 0 then 'TYPE_0' when 1 then 'TYPE_1' when 2 then 'TYPE_2' ELSE 'TYPE_0' END, cityHash64(ID), ID, toDateTime(toUInt32(now()) - round(rand32() / 4294967295 * 4100000, 0))  from generateRandom('ID String ', 1, 1000) limit 100000;\r\ninsert into order (ID, Type, Num, Data, RowCreatedAt) select toString(cityHash64(ID)%2000), case cityHash64(ID)%3 when 0 then 'TYPE_0' when 1 then 'TYPE_1' when 2 then 'TYPE_2' ELSE 'TYPE_0' END, cityHash64(ID), ID, toDateTime(toUInt32(now()) - round(rand32() / 4294967295 * 4100000, 0))  from generateRandom('ID String ', 1, 1000) limit 100000;\r\ninsert into order (ID, Type, Num, Data, RowCreatedAt) select toString(cityHash64(ID)%2000), case cityHash64(ID)%3 when 0 then 'TYPE_0' when 1 then 'TYPE_1' when 2 then 'TYPE_2' ELSE 'TYPE_0' END, cityHash64(ID), ID, toDateTime(toUInt32(now()) - round(rand32() / 4294967295 * 4100000, 0))  from generateRandom('ID String ', 1, 1000) limit 100000;\r\ninsert into order (ID, Type, Num, Data, RowCreatedAt) select toString(cityHash64(ID)%2000), case cityHash64(ID)%3 when 0 then 'TYPE_0' when 1 then 'TYPE_1' when 2 then 'TYPE_2' ELSE 'TYPE_0' END, cityHash64(ID), ID, toDateTime(toUInt32(now()) - round(rand32() / 4294967295 * 4100000, 0))  from generateRandom('ID String ', 1, 1000) limit 100000;\r\ninsert into order (ID, Type, Num, Data, RowCreatedAt) select toString(cityHash64(ID)%2000), case cityHash64(ID)%3 when 0 then 'TYPE_0' when 1 then 'TYPE_1' when 2 then 'TYPE_2' ELSE 'TYPE_0' END, cityHash64(ID), ID, toDateTime(toUInt32(now()) - round(rand32() / 4294967295 * 4100000, 0))  from generateRandom('ID String ', 1, 1000) limit 100000;\r\ninsert into order (ID, Type, Num, Data, RowCreatedAt) select toString(cityHash64(ID)%2000), case cityHash64(ID)%3 when 0 then 'TYPE_0' when 1 then 'TYPE_1' when 2 then 'TYPE_2' ELSE 'TYPE_0' END, cityHash64(ID), ID, toDateTime(toUInt32(now()) - round(rand32() / 4294967295 * 4100000, 0))  from generateRandom('ID String ', 1, 1000) limit 100000;\r\ninsert into order (ID, Type, Num, Data, RowCreatedAt) select toString(cityHash64(ID)%2000), case cityHash64(ID)%3 when 0 then 'TYPE_0' when 1 then 'TYPE_1' when 2 then 'TYPE_2' ELSE 'TYPE_0' END, cityHash64(ID), ID, toDateTime(toUInt32(now()) - round(rand32() / 4294967295 * 4100000, 0))  from generateRandom('ID String ', 1, 1000) limit 100000;\r\ninsert into order (ID, Type, Num, Data, RowCreatedAt) select toString(cityHash64(ID)%2000), case cityHash64(ID)%3 when 0 then 'TYPE_0' when 1 then 'TYPE_1' when 2 then 'TYPE_2' ELSE 'TYPE_0' END, cityHash64(ID), ID, toDateTime(toUInt32(now()) - round(rand32() / 4294967295 * 4100000, 0))  from generateRandom('ID String ', 1, 1000) limit 100000;\r\n\r\nselect count(*) from order;\r\n\u250c\u2500count()\u2500\u2510\r\n\u2502  892441 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nset optimize_move_to_prewhere = 0;\r\nSELECT Data\r\nFROM order\r\nWHERE (ID = '1') AND (Type = 'TYPE_1')\r\nORDER BY Num ASC\r\nFORMAT `Null`\r\n\r\nOk.\r\n\r\nset optimize_move_to_prewhere = 1;\r\nSELECT Data\r\nFROM order\r\nWHERE (ID = '1') AND (Type = 'TYPE_1')\r\nORDER BY Num ASC\r\nFORMAT `Null`\r\n\r\nReceived exception from server (version 22.5.1):\r\nCode: 10. DB::Exception: Received from localhost:9000. DB::Exception: Not found column Type in block. There are only columns: ID, Num, equals(Type, 'TYPE_1'), Data. (NOT_FOUND_COLUMN_IN_BLOCK)\r\n\r\n```\n",
  "hints_text": "Provide `show create table event`\n> Provide `show create table event`\r\n\r\nOk I added to the description.\n@talhakum it will quite complicated to reproduce without sample data. Can you share data from your table (privately) ?\n> @talhakum it will quite complicated to reproduce without sample data. Can you share data from your table (privately) ?\r\n\r\nI added to gist as csv: https://gist.github.com/talhakum/73742b81b1de0298bf309c37699bd78b\r\n\r\nAlso I share the error log: https://gist.github.com/talhakum/45547cb6757269d04b107d076adef66e\ntry to execute your query with `set optimize_move_to_prewhere=0`\n@den-crane I saw a similar issue.\r\n\r\n```\r\nSELECT\r\n    time,\r\n    env,\r\n    request_id,\r\n    trace_id,\r\n    message,\r\n    rest\r\nFROM logs.logs_shard\r\nWHERE ((time >= '2022-06-01 10:38:07') AND (time <= '2022-06-02 16:38:07')) AND ((project = 'market-checkouter') AND (service = 'market-checkouter') AND (message LIKE '%myhellsing%'))\r\nORDER BY time DESC\r\nLIMIT 100\r\n\r\nQuery id: 54e3f991-ffc0-48e2-b914-ebe75fe202d2\r\n\r\n\r\n0 rows in set. Elapsed: 0.519 sec.\r\n\r\nReceived exception from server (version 22.3.6):\r\nCode: 10. DB::Exception: Received from db_host:9440. DB::Exception: Not found column service in block. There are only columns: time, project, and(equals(service, 'market-checkouter'), greaterOrEquals(time, '2022-06-01 10:38:07'), lessOrEquals(time, '2022-06-02 16:38:07')), message, env, request_id, trace_id, rest. (NOT_FOUND_COLUMN_IN_BLOCK)\r\n```\r\n\r\n```\r\nSET optimize_move_to_prewhere = 0\r\n\r\nSELECT\r\n    time,\r\n    env,\r\n    request_id,\r\n    trace_id,\r\n    message,\r\n    rest\r\nFROM logs.logs_shard\r\nWHERE ((time >= '2022-06-01 10:38:07') AND (time <= '2022-06-02 16:38:07')) AND ((project = 'market-checkouter') AND (service = 'market-checkouter') AND (message LIKE '%myhellsing%'))\r\nORDER BY time DESC\r\nLIMIT 100\r\n\r\nQuery id: 9bc31850-e523-46ea-8e8a-b850a292d5bf\r\n\r\nOk.\r\n\r\n```\r\n\r\n\r\n```\r\nCREATE TABLE logs.logs_shard\r\n(\r\n    `time` DateTime64(9) DEFAULT fromUnixTimestamp64Nano(toUInt64(toUnixTimestamp(_time) * 1000000000.) + _time_nano) CODEC(Delta(8), ZSTD(1)),\r\n    `project` LowCardinality(String) CODEC(ZSTD(7)),\r\n    `service` LowCardinality(String) CODEC(ZSTD(7)),\r\n    `message` String CODEC(ZSTD(7)),\r\n    `env` LowCardinality(String) CODEC(ZSTD(1)),\r\n    `cluster` LowCardinality(String) CODEC(ZSTD(1)),\r\n    `level` Enum8('UNKNOWN' = 0, 'FATAL' = 1, 'ERROR' = 2, 'WARN' = 3, 'INFO' = 4, 'DEBUG' = 5, 'TRACE' = 6),\r\n    `hostname` LowCardinality(String) CODEC(ZSTD(7)),\r\n    `version` LowCardinality(String) CODEC(ZSTD(7)),\r\n    `dc` LowCardinality(String) CODEC(ZSTD(1)),\r\n    `request_id` String CODEC(ZSTD(7)),\r\n    `trace_id` String CODEC(ZSTD(7)),\r\n    `span_id` String CODEC(ZSTD(7)),\r\n    `component` String CODEC(ZSTD(7)),\r\n    `record_id` UUID CODEC(NONE),\r\n    `validation_err` String CODEC(ZSTD(7)),\r\n    `rest` String CODEC(ZSTD(7)),\r\n    `date` Date EPHEMERAL toDate(now()),\r\n    `timestamp` UInt32 EPHEMERAL toUnixTimestamp(now()),\r\n    `_time` DateTime EPHEMERAL now(),\r\n    `_time_nano` UInt64 EPHEMERAL 0,\r\n    INDEX idx_message message TYPE ngrambf_v1(3, 512, 2, 0) GRANULARITY 3,\r\n    INDEX idx_request_id request_id TYPE bloom_filter(0.01) GRANULARITY 3,\r\n    INDEX idx_trace_id trace_id TYPE bloom_filter(0.01) GRANULARITY 3,\r\n    INDEX idx_span_id span_id TYPE bloom_filter(0.01) GRANULARITY 3,\r\n    INDEX idx_level level TYPE bloom_filter(0.01) GRANULARITY 3\r\n)\r\nENGINE = ReplicatedReplacingMergeTree('/clickhouse/tables/9439ab61-2151-4ee6-8abe-0b0190ed3228/{shard}', '{replica}')\r\nPARTITION BY toStartOfHour(time)\r\nPRIMARY KEY (project, service, time)\r\nORDER BY (project, service, time, record_id)\r\nTTL toDateTime(time) + toIntervalDay(1) TO DISK 'object_storage', toDateTime(time) + toIntervalDay(30)\r\nSETTINGS index_granularity = 1024, ttl_only_drop_parts = 1\r\n```\nit is not reproducible without specific data distribution \n@orloffv can you share your dataset ? \nI can, but it's about 100TB\nI believe this is the same as https://github.com/ClickHouse/ClickHouse/issues/37381\r\n\r\nThe second column of table ORDER BY is moved to prewhere and this column has low cardinality and select ORDER BY high_cardinal_column\nThe same but minimized and without `rand`.\r\n\r\n```sql\r\ndrop table order;\r\n\r\nCREATE TABLE order\r\n(\r\n    ID Int64,\r\n    Type Int64,\r\n    Num UInt64,\r\n    t DateTime  \r\n)\r\nENGINE = MergeTree()\r\nPARTITION BY toYYYYMMDD(t)\r\nORDER BY (ID, Type, Num);\r\n\r\nsystem stop merges order;\r\n\r\ninsert into order select number%2000, 1, number, (1656700561 - intDiv(intHash32(number), 1000)) from numbers(100000);\r\ninsert into order select number%2000, 1, number, (1656700561 - intDiv(intHash32(number), 1000)) from numbers(100000);\r\ninsert into order select number%2000, 1, number, (1656700561 - intDiv(intHash32(number), 1000)) from numbers(100000);\r\n\r\nSELECT Num\r\nFROM order\r\nPREWHERE Type = 1\r\nWHERE ID = 1\r\nORDER BY Num ASC limit 5;\r\n\r\nReceived exception from server (version 22.6.1):\r\nCode: 10. DB::Exception: Received from localhost:9000. DB::Exception: \r\nNot found column Type in block. There are only columns: ID, Num, equals(Type, 1).\r\n (NOT_FOUND_COLUMN_IN_BLOCK)\r\n\r\n\r\nSELECT Num\r\nFROM order\r\nWHERE (ID = 1) AND (Type = 1)\r\nORDER BY Num ASC\r\nLIMIT 5\r\nSETTINGS optimize_move_to_prewhere = 0;\r\n\u250c\u2500\u2500Num\u2500\u2510\r\n\u2502    1 \u2502\r\n\u2502    1 \u2502\r\n\u2502    1 \u2502\r\n\u2502 2001 \u2502\r\n\u2502 2001 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nSELECT Num\r\nFROM order\r\nWHERE (ID = 1) AND (Type = 1)\r\nORDER BY Num ASC\r\nLIMIT 5\r\nSETTINGS optimize_move_to_prewhere = 1;\r\n\r\nReceived exception from server (version 22.6.1):\r\nCode: 10. DB::Exception: Received from localhost:9000. \r\nDB::Exception: Not found column Type in block. There are only columns: ID, Num, equals(Type, 1). \r\n(NOT_FOUND_COLUMN_IN_BLOCK)\r\n```\r\n\r\nbroken since 22.2\nExcellent, thanks ! \ni don't know how to reproduce(many data in table)\r\n\r\n```\r\nSELECT timestamp \r\nFROM table \r\nWHERE status = 200 AND date = '2022-07-06' AND bucket = 'probki'\r\nORDER BY timestamp DESC\r\nLIMIT 30\r\n```\r\n\r\n```\r\nClickhouse error: code 10\r\nNot found column status in block. There are only columns: timestamp, bucket, equals(status, 200), date: While processing timestamp. (NOT_FOUND_COLUMN_IN_BLOCK)\r\n```\r\n\r\n\n@orloffv share `order by` section from your table.\n@den-crane\r\n```\r\nORDER BY (bucket, status, timestamp)\r\n```\n@orloffv yes, it's the same issue. \r\nIt's already reproduced, see the first messages in the current issue.",
  "created_at": "2022-07-13T07:08:18Z"
}