{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 11276,
  "instance_id": "ClickHouse__ClickHouse-11276",
  "issue_numbers": [
    "11275",
    "11273",
    "11274"
  ],
  "base_commit": "04bdffd9d73f3f82fbbfeaae194fbd0bc45ea826",
  "patch": "diff --git a/src/Core/ExternalTable.cpp b/src/Core/ExternalTable.cpp\nindex 62a99cea97ed..5ec6980dbfa4 100644\n--- a/src/Core/ExternalTable.cpp\n+++ b/src/Core/ExternalTable.cpp\n@@ -164,7 +164,7 @@ void ExternalTablesHandler::handlePart(const Poco::Net::MessageHeader & header,\n \n     /// Create table\n     NamesAndTypesList columns = sample_block.getNamesAndTypesList();\n-    auto temporary_table = TemporaryTableHolder(context, ColumnsDescription{columns});\n+    auto temporary_table = TemporaryTableHolder(context, ColumnsDescription{columns}, {});\n     auto storage = temporary_table.getTable();\n     context.addExternalTable(data->table_name, std::move(temporary_table));\n     BlockOutputStreamPtr output = storage->write(ASTPtr(), context);\ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex 142e0872d721..8cf90fa146a1 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -126,7 +126,7 @@ struct Settings : public SettingsCollection<Settings>\n     M(SettingBool, force_optimize_skip_unused_shards_no_nested, false, \"Do not apply force_optimize_skip_unused_shards for nested Distributed tables.\", 0) \\\n     \\\n     M(SettingBool, input_format_parallel_parsing, true, \"Enable parallel parsing for some data formats.\", 0) \\\n-    M(SettingUInt64, min_chunk_bytes_for_parallel_parsing, (1024 * 1024), \"The minimum chunk size in bytes, which each thread will parse in parallel.\", 0) \\\n+    M(SettingUInt64, min_chunk_bytes_for_parallel_parsing, (10 * 1024 * 1024), \"The minimum chunk size in bytes, which each thread will parse in parallel.\", 0) \\\n     \\\n     M(SettingUInt64, merge_tree_min_rows_for_concurrent_read, (20 * 8192), \"If at least as many lines are read from one file, the reading can be parallelized.\", 0) \\\n     M(SettingUInt64, merge_tree_min_bytes_for_concurrent_read, (24 * 10 * 1024 * 1024), \"If at least as many bytes are read from one file, the reading can be parallelized.\", 0) \\\ndiff --git a/src/Interpreters/DatabaseCatalog.cpp b/src/Interpreters/DatabaseCatalog.cpp\nindex 7606fdb255a0..c55e60898b96 100644\n--- a/src/Interpreters/DatabaseCatalog.cpp\n+++ b/src/Interpreters/DatabaseCatalog.cpp\n@@ -58,13 +58,17 @@ TemporaryTableHolder::TemporaryTableHolder(const Context & context_,\n }\n \n \n-TemporaryTableHolder::TemporaryTableHolder(const Context & context_, const ColumnsDescription & columns, const ASTPtr & query)\n+TemporaryTableHolder::TemporaryTableHolder(\n+    const Context & context_,\n+    const ColumnsDescription & columns,\n+    const ConstraintsDescription & constraints,\n+    const ASTPtr & query)\n     : TemporaryTableHolder\n       (\n           context_,\n           [&](const StorageID & table_id)\n           {\n-              return StorageMemory::create(table_id, ColumnsDescription{columns}, ConstraintsDescription{});\n+              return StorageMemory::create(table_id, ColumnsDescription{columns}, ConstraintsDescription{constraints});\n           },\n           query\n       )\ndiff --git a/src/Interpreters/DatabaseCatalog.h b/src/Interpreters/DatabaseCatalog.h\nindex a481e3d7e5e8..a274d294af05 100644\n--- a/src/Interpreters/DatabaseCatalog.h\n+++ b/src/Interpreters/DatabaseCatalog.h\n@@ -21,6 +21,7 @@ class Context;\n class IDatabase;\n class Exception;\n class ColumnsDescription;\n+struct ConstraintsDescription;\n \n using DatabasePtr = std::shared_ptr<IDatabase>;\n using DatabaseAndTable = std::pair<DatabasePtr, StoragePtr>;\n@@ -71,7 +72,11 @@ struct TemporaryTableHolder : boost::noncopyable\n     TemporaryTableHolder(const Context & context, const Creator & creator, const ASTPtr & query = {});\n \n     /// Creates temporary table with Engine=Memory\n-    TemporaryTableHolder(const Context & context, const ColumnsDescription & columns, const ASTPtr & query = {});\n+    TemporaryTableHolder(\n+        const Context & context,\n+        const ColumnsDescription & columns,\n+        const ConstraintsDescription & constraints,\n+        const ASTPtr & query = {});\n \n     TemporaryTableHolder(TemporaryTableHolder && rhs);\n     TemporaryTableHolder & operator = (TemporaryTableHolder && rhs);\ndiff --git a/src/Interpreters/GlobalSubqueriesVisitor.h b/src/Interpreters/GlobalSubqueriesVisitor.h\nindex 37a358c3d28c..9e616b04dab6 100644\n--- a/src/Interpreters/GlobalSubqueriesVisitor.h\n+++ b/src/Interpreters/GlobalSubqueriesVisitor.h\n@@ -103,7 +103,7 @@ class GlobalSubqueriesMatcher\n             Block sample = interpreter->getSampleBlock();\n             NamesAndTypesList columns = sample.getNamesAndTypesList();\n \n-            auto external_storage_holder = std::make_shared<TemporaryTableHolder>(context, ColumnsDescription{columns});\n+            auto external_storage_holder = std::make_shared<TemporaryTableHolder>(context, ColumnsDescription{columns}, ConstraintsDescription{});\n             StoragePtr external_storage = external_storage_holder->getTable();\n \n             /** We replace the subquery with the name of the temporary table.\ndiff --git a/src/Interpreters/InterpreterCreateQuery.cpp b/src/Interpreters/InterpreterCreateQuery.cpp\nindex 147ef7d739b3..6d35e25ba444 100644\n--- a/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -637,7 +637,7 @@ bool InterpreterCreateQuery::doCreateTable(ASTCreateQuery & create,\n         if (create.if_not_exists && context.tryResolveStorageID({\"\", table_name}, Context::ResolveExternal))\n             return false;\n \n-        auto temporary_table = TemporaryTableHolder(context, properties.columns, query_ptr);\n+        auto temporary_table = TemporaryTableHolder(context, properties.columns, properties.constraints, query_ptr);\n         context.getSessionContext().addExternalTable(table_name, std::move(temporary_table));\n         return true;\n     }\ndiff --git a/src/Interpreters/InterpreterInsertQuery.cpp b/src/Interpreters/InterpreterInsertQuery.cpp\nindex b6efa5d6d462..149a78c38035 100644\n--- a/src/Interpreters/InterpreterInsertQuery.cpp\n+++ b/src/Interpreters/InterpreterInsertQuery.cpp\n@@ -233,6 +233,21 @@ BlockIO InterpreterInsertQuery::execute()\n             else\n                 out = std::make_shared<PushingToViewsBlockOutputStream>(table, context, query_ptr, no_destination);\n \n+            /// Note that we wrap transforms one on top of another, so we write them in reverse of data processing order.\n+\n+            /// Checking constraints. It must be done after calculation of all defaults, so we can check them on calculated columns.\n+            if (const auto & constraints = table->getConstraints(); !constraints.empty())\n+                out = std::make_shared<CheckConstraintsBlockOutputStream>(\n+                    query.table_id, out, out->getHeader(), table->getConstraints(), context);\n+\n+            /// Actually we don't know structure of input blocks from query/table,\n+            /// because some clients break insertion protocol (columns != header)\n+            out = std::make_shared<AddingDefaultBlockOutputStream>(\n+                out, query_sample_block, out->getHeader(), table->getColumns().getDefaults(), context);\n+\n+            /// It's important to squash blocks as early as possible (before other transforms),\n+            ///  because other transforms may work inefficient if block size is small.\n+\n             /// Do not squash blocks if it is a sync INSERT into Distributed, since it lead to double bufferization on client and server side.\n             /// Client-side bufferization might cause excessive timeouts (especially in case of big blocks).\n             if (!(context.getSettingsRef().insert_distributed_sync && table->isRemote()) && !no_squash && !query.watch)\n@@ -244,15 +259,6 @@ BlockIO InterpreterInsertQuery::execute()\n                     context.getSettingsRef().min_insert_block_size_bytes);\n             }\n \n-            /// Actually we don't know structure of input blocks from query/table,\n-            /// because some clients break insertion protocol (columns != header)\n-            out = std::make_shared<AddingDefaultBlockOutputStream>(\n-                out, query_sample_block, out->getHeader(), table->getColumns().getDefaults(), context);\n-\n-            if (const auto & constraints = table->getConstraints(); !constraints.empty())\n-                out = std::make_shared<CheckConstraintsBlockOutputStream>(\n-                    query.table_id, out, query_sample_block, table->getConstraints(), context);\n-\n             auto out_wrapper = std::make_shared<CountingBlockOutputStream>(out);\n             out_wrapper->setProcessListElement(context.getProcessListElement());\n             out = std::move(out_wrapper);\ndiff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp\nindex b8f3660179d5..65ed1f5eb902 100644\n--- a/src/Server/TCPHandler.cpp\n+++ b/src/Server/TCPHandler.cpp\n@@ -948,7 +948,7 @@ bool TCPHandler::receiveData(bool scalar)\n                 else\n                 {\n                     NamesAndTypesList columns = block.getNamesAndTypesList();\n-                    auto temporary_table = TemporaryTableHolder(*query_context, ColumnsDescription{columns});\n+                    auto temporary_table = TemporaryTableHolder(*query_context, ColumnsDescription{columns}, {});\n                     storage = temporary_table.getTable();\n                     query_context->addExternalTable(temporary_id.table_name, std::move(temporary_table));\n                 }\n",
  "test_patch": "diff --git a/tests/performance/insert_select_default_small_block.xml b/tests/performance/insert_select_default_small_block.xml\nnew file mode 100644\nindex 000000000000..12e67b09d2f2\n--- /dev/null\n+++ b/tests/performance/insert_select_default_small_block.xml\n@@ -0,0 +1,38 @@\n+<test>\n+    <settings><max_block_size>1</max_block_size></settings>\n+\n+    <create_query>\n+CREATE TABLE insert_small_block_performance\n+(\n+    `x` String, \n+    `a` DEFAULT SHA256(x), \n+    `b` DEFAULT SHA256(toString(a)), \n+    `c` DEFAULT SHA256(toString(b)), \n+    `d` DEFAULT SHA256(toString(c)), \n+    `e` DEFAULT SHA256(toString(d)), \n+    `f` DEFAULT SHA256(toString(e)), \n+    `g` DEFAULT SHA256(toString(f)), \n+    `h` DEFAULT SHA256(toString(g)), \n+    `i` DEFAULT SHA256(toString(h)), \n+    `j` DEFAULT SHA256(toString(i)), \n+    `k` DEFAULT SHA256(toString(j)), \n+    `l` DEFAULT SHA256(toString(k)), \n+    `m` DEFAULT SHA256(toString(l)), \n+    `n` DEFAULT SHA256(toString(m)), \n+    `o` DEFAULT SHA256(toString(n)), \n+    `p` DEFAULT SHA256(toString(o)), \n+    `q` DEFAULT SHA256(toString(p)), \n+    `r` DEFAULT SHA256(toString(q)), \n+    `s` DEFAULT SHA256(toString(r)), \n+    `t` DEFAULT SHA256(toString(s)), \n+    `u` DEFAULT SHA256(toString(t)), \n+    `v` DEFAULT SHA256(toString(u)), \n+    `w` DEFAULT SHA256(toString(v))\n+)\n+ENGINE = Null;\n+    </create_query>\n+\n+    <query>INSERT INTO insert_small_block_performance (x) SELECT toString(number) FROM numbers(10000);</query>\n+\n+    <drop_query>DROP TABLE IF EXISTS insert_small_block_performance</drop_query>\n+</test>\ndiff --git a/tests/queries/0_stateless/01286_constraints_on_default.reference b/tests/queries/0_stateless/01286_constraints_on_default.reference\nnew file mode 100644\nindex 000000000000..aa47d0d46d47\n--- /dev/null\n+++ b/tests/queries/0_stateless/01286_constraints_on_default.reference\n@@ -0,0 +1,2 @@\n+0\n+0\ndiff --git a/tests/queries/0_stateless/01286_constraints_on_default.sql b/tests/queries/0_stateless/01286_constraints_on_default.sql\nnew file mode 100644\nindex 000000000000..d150bac15b51\n--- /dev/null\n+++ b/tests/queries/0_stateless/01286_constraints_on_default.sql\n@@ -0,0 +1,29 @@\n+DROP TABLE IF EXISTS default_constraints;\n+CREATE TABLE default_constraints\n+(\n+    x UInt8,\n+    y UInt8 DEFAULT x + 1,\n+    CONSTRAINT c CHECK y < 5\n+) ENGINE = Memory;\n+\n+INSERT INTO default_constraints (x) SELECT number FROM system.numbers LIMIT 5; -- { serverError 469 }\n+INSERT INTO default_constraints (x) VALUES (0),(1),(2),(3),(4); -- { serverError 469 }\n+\n+SELECT y, throwIf(NOT y < 5) FROM default_constraints;\n+SELECT count() FROM default_constraints;\n+\n+DROP TABLE default_constraints;\n+\n+\n+CREATE TEMPORARY TABLE default_constraints\n+(\n+    x UInt8,\n+    y UInt8 DEFAULT x + 1,\n+    CONSTRAINT c CHECK y < 5\n+);\n+\n+INSERT INTO default_constraints (x) SELECT number FROM system.numbers LIMIT 5; -- { serverError 469 }\n+INSERT INTO default_constraints (x) VALUES (0),(1),(2),(3),(4); -- { serverError 469 }\n+\n+SELECT y, throwIf(NOT y < 5) FROM default_constraints;\n+SELECT count() FROM default_constraints;\n",
  "problem_statement": "Suboptimal calculation of DEFAULT expressions if INSERT is done with small blocks via native protocol\n\nConstraints don't apply to DEFAULT columns\n\nConstraints are ignored for temporary tables\n\n",
  "hints_text": "\n\n",
  "created_at": "2020-05-29T02:11:16Z",
  "modified_files": [
    "src/Core/ExternalTable.cpp",
    "src/Core/Settings.h",
    "src/Interpreters/DatabaseCatalog.cpp",
    "src/Interpreters/DatabaseCatalog.h",
    "src/Interpreters/GlobalSubqueriesVisitor.h",
    "src/Interpreters/InterpreterCreateQuery.cpp",
    "src/Interpreters/InterpreterInsertQuery.cpp",
    "src/Server/TCPHandler.cpp"
  ],
  "modified_test_files": [
    "b/tests/performance/insert_select_default_small_block.xml",
    "b/tests/queries/0_stateless/01286_constraints_on_default.reference",
    "b/tests/queries/0_stateless/01286_constraints_on_default.sql"
  ]
}