diff --git a/tests/integration/test_database_disk_setting/configs/database_disk.xml b/tests/integration/test_database_disk_setting/configs/database_disk.xml
index 49a80c7b4900..1b19076ea2ce 100644
--- a/tests/integration/test_database_disk_setting/configs/database_disk.xml
+++ b/tests/integration/test_database_disk_setting/configs/database_disk.xml
@@ -19,6 +19,14 @@
                 <access_key_id>minio</access_key_id>
                 <secret_access_key>ClickHouse_Minio_P@ssw0rd</secret_access_key>
             </s3>
+            <s3_plain_rewritable>
+                <type>object_storage</type>
+                <object_storage_type>s3</object_storage_type>
+                <metadata_type>plain_rewritable</metadata_type>
+                <endpoint>http://minio1:9001/root/data/disks/disk_s3_plain_rewritable/</endpoint>
+                <access_key_id>minio</access_key_id>
+                <secret_access_key>ClickHouse_Minio_P@ssw0rd</secret_access_key>
+            </s3_plain_rewritable>
         </disks>
     </storage_configuration>
 </clickhouse>
diff --git a/tests/integration/test_database_disk_setting/configs/disk_app_config.xml b/tests/integration/test_database_disk_setting/configs/disk_app_config.xml
index b1cefc64733d..e1ee90251da8 100644
--- a/tests/integration/test_database_disk_setting/configs/disk_app_config.xml
+++ b/tests/integration/test_database_disk_setting/configs/disk_app_config.xml
@@ -20,6 +20,14 @@
                 <secret_access_key>ClickHouse_Minio_P@ssw0rd</secret_access_key>
                 <readonly>true</readonly>
             </s3>
+            <s3_plain_rewritable>
+                <type>object_storage</type>
+                <object_storage_type>s3</object_storage_type>
+                <metadata_type>plain_rewritable</metadata_type>
+                <endpoint>http://minio1:9001/root/data/disks/disk_s3_plain_rewritable/</endpoint>
+                <access_key_id>minio</access_key_id>
+                <secret_access_key>ClickHouse_Minio_P@ssw0rd</secret_access_key>
+            </s3_plain_rewritable>
         </disks>
     </storage_configuration>
 </clickhouse>
diff --git a/tests/integration/test_database_disk_setting/test.py b/tests/integration/test_database_disk_setting/test.py
index be7262d3d5c2..4b9b35d2b762 100644
--- a/tests/integration/test_database_disk_setting/test.py
+++ b/tests/integration/test_database_disk_setting/test.py
@@ -19,6 +19,16 @@
     stay_alive=True,
 )
 
+node2 = cluster.add_instance(
+    "node2",
+    main_configs=[
+        "configs/database_disk.xml",
+    ],
+    with_remote_database_disk=False,
+    with_minio=True,
+    stay_alive=True,
+)
+
 disk_config_file_path =  "/tmp/disk_app_config.xml"
 
 @pytest.fixture(scope="module")
@@ -29,6 +39,10 @@ def start_cluster():
             os.path.join(SCRIPT_DIR, "configs/disk_app_config.xml"),
             disk_config_file_path,
         )
+        node2.copy_file_to_container(
+            os.path.join(SCRIPT_DIR, "configs/disk_app_config.xml"),
+            disk_config_file_path,
+        )
         yield cluster
     finally:
         cluster.shutdown()
@@ -54,7 +68,7 @@ def validate_table_metadata_path(node, disk_name : str, db : str, table: str):
     assert directory_exists(node, disk_name, table_metadata_path)
     if(disk_name != "global_db_disk"):
         assert not directory_exists(node1, "global_db_disk", table_metadata_path)
-        
+
 def validate_db_path(node, disk_name : str, db : str, support_symlink: bool = True):
     db_data_path = node.query(
         f"SELECT metadata_path FROM system.databases WHERE database='{db}'"
@@ -64,15 +78,15 @@ def validate_db_path(node, disk_name : str, db : str, support_symlink: bool = Tr
     if support_symlink:
         assert directory_exists(node, disk_name, os.path.join("metadata", db))
         assert directory_exists(node, disk_name, os.path.join( "data", db))
-        
+
 @pytest.mark.parametrize("engine", ["Atomic", "Ordinary"])
 @pytest.mark.parametrize("db_disk_name", ["db_disk", "global_db_disk", ""])
 def test_db_disk_setting(start_cluster, engine: str, db_disk_name: str):
     db_name = f"db_{db_disk_name}_{engine.lower()}"
-    
+
     node1.query(f"DROP DATABASE IF EXISTS {db_name} SYNC")
     node1.query(f"DROP DATABASE IF EXISTS {db_name}_rename SYNC")
-    
+
     disk_setting = f"disk='{db_disk_name}'"
     if len(db_disk_name) == 0:
         disk_setting = "disk=disk(type='local', path='/var/lib/clickhouse/disks/custom_db_disk/')"
@@ -86,21 +100,20 @@ def test_db_disk_setting(start_cluster, engine: str, db_disk_name: str):
 
     validate_db_path(node1, db_disk_name, db_name)
     validate_table_metadata_path(node1, db_disk_name, db_name, 'test')
-    
+
     # Ordinay DB doesn't support renaming
     if(engine != "Ordinary"):
         node1.query(f"RENAME DATABASE {db_name} TO {db_name}_rename")
         validate_db_path(node1, db_disk_name, f"{db_name}_rename")
         validate_table_metadata_path(node1, db_disk_name, f"{db_name}_rename", 'test')
-        
+
         node1.query(f"RENAME DATABASE {db_name}_rename TO {db_name}")
         validate_db_path(node1, db_disk_name, db_name)
         validate_table_metadata_path(node1, db_disk_name, db_name, 'test')
-    
+
     node1.query(f"RENAME TABLE {db_name}.test TO {db_name}.test_rename")
     validate_db_path(node1, db_disk_name, db_name)
     validate_table_metadata_path(node1, db_disk_name, db_name, 'test_rename')
-    
 
     node1.query(f"DROP DATABASE IF EXISTS {db_name} SYNC")
     node1.query(f"DROP DATABASE IF EXISTS {db_name}_rename SYNC")
@@ -121,7 +134,7 @@ def read_file(node, disk_name: str, metadata_path: str):
     return node.exec_in_container(
         ["bash", "-c", f"{disk_cmd_prefix} 'read --path-from {metadata_path}'"]
     )
-    
+
 def write_to_file(node, disk_name: str, file_path: str, content: str):
     # Escape backticks to avoid command substitution
     escaped_content = content.replace('"', r"\"").replace("`", r"\`")
@@ -133,7 +146,7 @@ def write_to_file(node, disk_name: str, file_path: str, content: str):
             f"""printf "%s" "{escaped_content}" | {disk_cmd_prefix} 'w --path-to {file_path}'""",
         ]
     )
-        
+
 def remove_file(node, disk_name: str, file_path: str):
     # Escape backticks to avoid command substitution
     disk_cmd_prefix = f"/usr/bin/clickhouse disks -C {disk_config_file_path} --save-logs --disk {disk_name} --query "
@@ -141,41 +154,49 @@ def remove_file(node, disk_name: str, file_path: str):
         ["bash", "-c", f"{disk_cmd_prefix} 'remove {file_path}'"]
     )
 
-@pytest.mark.skip(reason="'s3' disk doesn't support moveFile, so the DB with 's3' disk cannot be dropped.")
-def test_db_disk_setting_with_s3(start_cluster):
+
+def test_attach_db_from_readonly_remote_disk(start_cluster):
     db_name = f"db_test"
-    
+
     node1.query(f"DROP DATABASE IF EXISTS {db_name} SYNC")
-    
-    node1.query(f"CREATE DATABASE {db_name} ENGINE= Atomic SETTINGS disk='db_disk'")
-    node1.query(f"CREATE TABLE {db_name}.test (x INT) ENGINE=MergeTree ORDER BY x")
-    
-    table_metadata_path = node1.query(
-        f"SELECT metadata_path FROM system.tables WHERE database='{db_name}' AND table='test'"
+
+    node1.query(
+        f"CREATE DATABASE {db_name} ENGINE=Atomic SETTINGS disk='s3_plain_rewritable'"
+    )
+    db_uuid = node1.query(
+        f"SELECT uuid FROM system.databases WHERE database='{db_name}'"
     ).strip()
-    
-     
-    print(f"table_metadata_path: {table_metadata_path}")
-    
-    node1.stop_clickhouse()
-    
-    # Update disk of the DB to 's3'
-    replace_text_in_metadata(node1, "global_db_disk", f"metadata/{db_name}.sql", "db_disk", "s3")
-    
-    # Copy the table metadata file into 's3' disk
-    table_metadata_content = read_file(node1, "db_disk", table_metadata_path)
-    print(f"table_metadata_content: {table_metadata_content}")
-    write_to_file(node1, 's3', table_metadata_path, table_metadata_content)
-    
-    # Remove metadata file on the DB disk
-    remove_file(node1, "db_disk", table_metadata_path)
-    
-    node1.start_clickhouse()
-    
-    validate_db_path(node1, "s3", db_name, False)
-    assert directory_exists(node1, "s3", table_metadata_path)
-    
-    assert node1.query("SELECT count() FROM system.tables WHERE table='test'").strip() == "1"
-    
+    table_disk_setting = 'disk(type = "s3_plain_rewritable", endpoint = "http://minio1:9001/root/data/disks/disk_s3_plain_rewritable/", access_key_id="minio", secret_access_key = "ClickHouse_Minio_P@ssw0rd")'
+    node1.query(
+        f"CREATE TABLE {db_name}.test (x INT, y INT) ENGINE=MergeTree ORDER BY x SETTINGS disk={table_disk_setting}"
+    )
+    node1.query(f"INSERT INTO {db_name}.test VALUES (1, 1)")
+
+    assert node1.query(f"SELECT * FROM {db_name}.test") == "1\t1
"
+    assert (
+        node1.query("SELECT count() FROM system.tables WHERE table='test'").strip()
+        == "1"
+    )
+
+    node2.restart_clickhouse()
+    readonly_disk_setting = 'disk(readonly = 1, type = "s3_plain_rewritable", endpoint = "http://minio1:9001/root/data/disks/disk_s3_plain_rewritable/", access_key_id="minio", secret_access_key = "ClickHouse_Minio_P@ssw0rd")'
+    node2.query(
+        f"ATTACH DATABASE {db_name} UUID '{db_uuid}' ENGINE=Atomic SETTINGS disk={readonly_disk_setting}"
+    )
+    assert (
+        node2.query("SELECT count() FROM system.tables WHERE table='test'").strip()
+        == "1"
+    )
+    assert node2.query(f"SELECT * FROM {db_name}.test") == "1\t1
"
+
+    node2.query(f"DETACH DATABASE {db_name}")
+    assert node1.query(f"SELECT * FROM {db_name}.test") == "1\t1
"
+
+    node2.query(f"ATTACH DATABASE {db_name}")
+    assert node1.query(f"SELECT * FROM {db_name}.test") == "1\t1
"
+    assert node2.query(f"SELECT * FROM {db_name}.test") == "1\t1
"
+
+    node2.query(f"DROP DATABASE {db_name} SYNC")
+    assert node1.query(f"SELECT * FROM {db_name}.test") == "1\t1
"
+
     node1.query(f"DROP DATABASE IF EXISTS {db_name} SYNC")
-    
\ No newline at end of file
