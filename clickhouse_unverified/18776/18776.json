{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 18776,
  "instance_id": "ClickHouse__ClickHouse-18776",
  "issue_numbers": [
    "18741"
  ],
  "base_commit": "176358f0b4bfcafa12887b2b6cd8e7fb397a56e3",
  "patch": "diff --git a/src/Compression/CompressedReadBuffer.h b/src/Compression/CompressedReadBuffer.h\nindex 1e8ea4784c77..3fa7347507c0 100644\n--- a/src/Compression/CompressedReadBuffer.h\n+++ b/src/Compression/CompressedReadBuffer.h\n@@ -16,8 +16,8 @@ class CompressedReadBuffer : public CompressedReadBufferBase, public BufferWithO\n     bool nextImpl() override;\n \n public:\n-    CompressedReadBuffer(ReadBuffer & in_)\n-        : CompressedReadBufferBase(&in_), BufferWithOwnMemory<ReadBuffer>(0)\n+    CompressedReadBuffer(ReadBuffer & in_, bool allow_different_codecs_ = false)\n+        : CompressedReadBufferBase(&in_, allow_different_codecs_), BufferWithOwnMemory<ReadBuffer>(0)\n     {\n     }\n \ndiff --git a/src/Compression/CompressionFactory.cpp b/src/Compression/CompressionFactory.cpp\nindex 46d7d7dfcc4b..aacf95b19501 100644\n--- a/src/Compression/CompressionFactory.cpp\n+++ b/src/Compression/CompressionFactory.cpp\n@@ -46,6 +46,9 @@ CompressionCodecPtr CompressionCodecFactory::get(const String & family_name, std\n \n void CompressionCodecFactory::validateCodec(const String & family_name, std::optional<int> level, bool sanity_check) const\n {\n+    if (family_name.empty())\n+        throw Exception(\"Compression codec name cannot be empty\", ErrorCodes::BAD_ARGUMENTS);\n+\n     if (level)\n     {\n         auto literal = std::make_shared<ASTLiteral>(static_cast<UInt64>(*level));\ndiff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp\nindex 6493302a8078..12d1a0249b7b 100644\n--- a/src/Server/TCPHandler.cpp\n+++ b/src/Server/TCPHandler.cpp\n@@ -1181,7 +1181,7 @@ void TCPHandler::receiveUnexpectedData()\n     std::shared_ptr<ReadBuffer> maybe_compressed_in;\n \n     if (last_block_in.compression == Protocol::Compression::Enable)\n-        maybe_compressed_in = std::make_shared<CompressedReadBuffer>(*in);\n+        maybe_compressed_in = std::make_shared<CompressedReadBuffer>(*in, /* allow_different_codecs */ true);\n     else\n         maybe_compressed_in = in;\n \n@@ -1198,8 +1198,11 @@ void TCPHandler::initBlockInput()\n {\n     if (!state.block_in)\n     {\n+        /// 'allow_different_codecs' is set to true, because some parts of compressed data can be precompressed in advance\n+        /// with another codec that the rest of the data. Example: data sent by Distributed tables.\n+\n         if (state.compression == Protocol::Compression::Enable)\n-            state.maybe_compressed_in = std::make_shared<CompressedReadBuffer>(*in);\n+            state.maybe_compressed_in = std::make_shared<CompressedReadBuffer>(*in, /* allow_different_codecs */ true);\n         else\n             state.maybe_compressed_in = in;\n \ndiff --git a/src/Storages/Distributed/DistributedBlockOutputStream.cpp b/src/Storages/Distributed/DistributedBlockOutputStream.cpp\nindex 040f33ea02ee..32908a00660a 100644\n--- a/src/Storages/Distributed/DistributedBlockOutputStream.cpp\n+++ b/src/Storages/Distributed/DistributedBlockOutputStream.cpp\n@@ -582,6 +582,17 @@ void DistributedBlockOutputStream::writeToLocal(const Block & block, const size_\n \n void DistributedBlockOutputStream::writeToShard(const Block & block, const std::vector<std::string> & dir_names)\n {\n+    const auto & settings = context.getSettingsRef();\n+\n+    std::string compression_method = Poco::toUpper(settings.network_compression_method.toString());\n+    std::optional<int> compression_level;\n+\n+    if (compression_method == \"ZSTD\")\n+        compression_level = settings.network_zstd_compression_level;\n+\n+    CompressionCodecFactory::instance().validateCodec(compression_method, compression_level, !settings.allow_suspicious_codecs);\n+    CompressionCodecPtr compression_codec = CompressionCodecFactory::instance().get(compression_method, compression_level);\n+\n     /// tmp directory is used to ensure atomicity of transactions\n     /// and keep monitor thread out from reading incomplete data\n     std::string first_file_tmp_path{};\n@@ -607,7 +618,7 @@ void DistributedBlockOutputStream::writeToShard(const Block & block, const std::\n         /// Write batch to temporary location\n         {\n             WriteBufferFromFile out{first_file_tmp_path};\n-            CompressedWriteBuffer compress{out};\n+            CompressedWriteBuffer compress{out, compression_codec};\n             NativeBlockOutputStream stream{compress, DBMS_TCP_PROTOCOL_VERSION, block.cloneEmpty()};\n \n             /// Prepare the header.\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01640_distributed_async_insert_compression.reference b/tests/queries/0_stateless/01640_distributed_async_insert_compression.reference\nnew file mode 100644\nindex 000000000000..fef47999e2e2\n--- /dev/null\n+++ b/tests/queries/0_stateless/01640_distributed_async_insert_compression.reference\n@@ -0,0 +1,2 @@\n+256\n+512\ndiff --git a/tests/queries/0_stateless/01640_distributed_async_insert_compression.sql b/tests/queries/0_stateless/01640_distributed_async_insert_compression.sql\nnew file mode 100644\nindex 000000000000..b0a674b83894\n--- /dev/null\n+++ b/tests/queries/0_stateless/01640_distributed_async_insert_compression.sql\n@@ -0,0 +1,16 @@\n+DROP TABLE IF EXISTS local;\n+DROP TABLE IF EXISTS distributed;\n+\n+CREATE TABLE local (x UInt8) ENGINE = Memory;\n+CREATE TABLE distributed AS local ENGINE = Distributed(test_cluster_two_shards, currentDatabase(), local, x);\n+\n+SET insert_distributed_sync = 0, network_compression_method = 'zstd';\n+\n+INSERT INTO distributed SELECT number FROM numbers(256);\n+SYSTEM FLUSH DISTRIBUTED distributed;\n+\n+SELECT count() FROM local;\n+SELECT count() FROM distributed;\n+\n+DROP TABLE local;\n+DROP TABLE distributed;\n",
  "problem_statement": "Data rejected by server when clickhouse-client uses zstd network compression \nHello guys,\r\n\r\n**Description**\r\nWhen inserting data into a replicated+distributed table, I've noticed that not all data reaches all shards, only shard where client connects.\r\n\r\nTLDR; version of command which fails:\r\ncat payload.json | clickhouse client --input_format_skip_unknown_fields 1 --host 192.168.121.201 --query \"INSERT INTO test_db.tbl_distributed FORMAT JSONEachRow\" --max_insert_block_size=1000000\r\n\r\nClickhouse version: 20.12.5 revision 54442\r\n\r\n**How to reproduce**\r\nFor a 4 node cluster splited into two shards (with 2 replicas), \r\n- shard01r1\r\n- shard01r2\r\n- shard02r1\r\n- shard02r2\r\n\r\nwhen connecting to the shard01r1 node, data is inserted into shard01r1 (and replica in shard01r2).\r\nIf I drop `--network_compression_method` all goes fine.\r\n\r\n***ClickHouse remote_servers***\r\n```\r\n<yandex>\r\n<remote_servers>\r\n    <test_cluster>\r\n        <shard>\r\n            <internal_replication>true</internal_replication>\r\n            <replica>\r\n                <host>192.168.121.201</host>\r\n                <port>9000</port>\r\n             </replica>\r\n            <replica>\r\n                <host>192.168.121.202</host>\r\n                <port>9000</port>\r\n             </replica>\r\n        </shard>\r\n        <shard>\r\n            <internal_replication>true</internal_replication>\r\n            <replica>\r\n                <host>192.168.121.203</host>\r\n                <port>9000</port>\r\n             </replica>\r\n            <replica>\r\n                <host>192.168.121.204</host>\r\n                <port>9000</port>\r\n             </replica>\r\n        </shard>\r\n    </test_cluster>\r\n</remote_servers>\r\n</yandex>\r\n```\r\n\r\n***SQL DDL***\r\n```\r\nCREATE DATABASE IF NOT EXISTS test_db ON CLUSTER test_cluster;\r\n\r\nCREATE TABLE IF NOT EXISTS test_db.tbl_local ON CLUSTER test_cluster\r\n(\r\n    timestamp DateTime64,\r\n    data String\r\n)\r\nENGINE = ReplicatedMergeTree()\r\nPARTITION BY toYYYYMMDD(timestamp)\r\nORDER BY (timestamp)\r\nSETTINGS index_granularity = 8192;\r\n\r\nCREATE TABLE IF NOT EXISTS test_db.tbl_distributed ON CLUSTER test_cluster AS test_db.tbl_local ENGINE = Distributed(test_cluster, test_db, tbl_local, rand());\r\n```\r\n***Payload***\r\n```json\r\n{\"timestamp\":\"2021-01-01T01:00:00.000\",\"data\": \"Hello World #1\"}\r\n{\"timestamp\":\"2021-01-01T02:00:00.000\",\"data\": \"Hello World #2\"}\r\n{\"timestamp\":\"2021-01-01T03:00:00.000\",\"data\": \"Hello World #3\"}\r\n{\"timestamp\":\"2021-01-01T04:00:00.000\",\"data\": \"Hello World #4\"}\r\n```\r\nUpon insert, only two rows will be saved in the database.\r\n\r\n\r\n**Error message**\r\n```\r\n (version 20.12.5.14 (official build))\r\n2021.01.04 18:20:56.489979 [ 6860 ] {} <Error> test_db.tbl_distributed.DirectoryMonitor: Renamed `/var/lib/clickhouse/store/dfa/dfaa92a5-34d4-4269-af39-a739fed1541a/shard2_replica1,shard2_replica2/1.bin` to `/var/lib/clickhouse/store/dfa/dfaa92a5-34d4-4269-af39-a739fed1541a/shard2_replica1,shard2_replica2/broken/1.bin`\r\n2021.01.04 18:20:56.490303 [ 6860 ] {} <Error> test_db.tbl_distributed.DirectoryMonitor: Code: 271, e.displayText() = DB::Exception: Received from 192.168.121.204:9000. DB::Exception: Data compressed with different methods, given method byte 0x90, previous method byte 0x82. Stack trace:\r\n\r\n0. DB::CompressedReadBufferBase::readCompressedData(unsigned long&, unsigned long&) @ 0xd7d654e in /usr/bin/clickhouse\r\n1. DB::CompressedReadBuffer::nextImpl() @ 0xd7d4b20 in /usr/bin/clickhouse\r\n2. DB::NativeBlockInputStream::readImpl() @ 0xdf40dd6 in /usr/bin/clickhouse\r\n3. DB::IBlockInputStream::read() @ 0xd8a0715 in /usr/bin/clickhouse\r\n4. DB::TCPHandler::receiveData(bool) @ 0xe7408f1 in /usr/bin/clickhouse\r\n5. DB::TCPHandler::receivePacket() @ 0xe739ddc in /usr/bin/clickhouse\r\n6. DB::TCPHandler::readDataNext(unsigned long const&, int const&) @ 0xe73b56f in /usr/bin/clickhouse\r\n7. DB::TCPHandler::processInsertQuery(DB::Settings const&) @ 0xe73a31e in /usr/bin/clickhouse\r\n8. DB::TCPHandler::runImpl() @ 0xe735929 in /usr/bin/clickhouse\r\n9. DB::TCPHandler::run() @ 0xe741c47 in /usr/bin/clickhouse\r\n10. Poco::Net::TCPServerConnection::start() @ 0x10eebb1f in /usr/bin/clickhouse\r\n11. Poco::Net::TCPServerDispatcher::run() @ 0x10eed531 in /usr/bin/clickhouse\r\n12. Poco::PooledThread::run() @ 0x1101ab09 in /usr/bin/clickhouse\r\n13. Poco::ThreadImpl::runnableEntry(void*) @ 0x11016a9a in /usr/bin/clickhouse\r\n14. start_thread @ 0x7fa3 in /usr/lib/x86_64-linux-gnu/libpthread-2.28.so\r\n15. clone @ 0xf94cf in /usr/lib/x86_64-linux-gnu/libc-2.28.so\r\n```\r\n\r\nWe can observe `broken` directory in store with missing data in *.bin files.\r\n`/var/lib/clickhouse/store/dfa/dfaa92a5-34d4-4269-af39-a739fed1541a/shard2_replica1,shard2_replica2/broken`\r\n\r\n`clickhouse-compressor` also complains when opening bin file:\r\n\r\n```\r\nclickhouse-compressor --decompress < /var/lib/clickhouse/store/dfa/dfaa92a5-34d4-4269-af39-a739fed1541a/shard2_replica1,shard2_replica2/broken/1.bin > 1.txt\r\nCode: 432, e.displayText() = DB::Exception: Unknown codec family code: 84, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::CompressionCodecFactory::get(unsigned char) const @ 0xd7dbe38 in /usr/bin/clickhouse\r\n1. DB::CompressedReadBufferBase::readCompressedData(unsigned long&, unsigned long&) @ 0xd7d514f in /usr/bin/clickhouse\r\n2. DB::CompressedReadBuffer::nextImpl() @ 0xd7d4b20 in /usr/bin/clickhouse\r\n3. mainEntryClickHouseCompressor(int, char**) @ 0x7ee721e in /usr/bin/clickhouse\r\n4. main @ 0x7d8acbd in /usr/bin/clickhouse\r\n5. __libc_start_main @ 0x2409b in /usr/lib/x86_64-linux-gnu/libc-2.28.so\r\n6. _start @ 0x7d3b02e in /usr/bin/clickhouse\r\n```\r\n\r\n**Additional context**\r\n\r\nFor what it's worth, we use `zstd` compression everywhere, aside from that I don't think there is nothing exotic in the conf.\r\n\r\n```\r\n<yandex>\r\n    <compression>\r\n        <case>\r\n            <method>zstd</method>\r\n        </case>\r\n    </compression>\r\n</yandex>\r\n```\r\n\r\nLast, but not the least, I've attached Vagrant setup (with Ansible provisioner), which can be used to reproduce the bug.\r\n[clickhouse_bug.tar.gz](https://github.com/ClickHouse/ClickHouse/files/5766355/clickhouse_bug.tar.gz)\r\n\n",
  "hints_text": "",
  "created_at": "2021-01-06T00:26:01Z"
}