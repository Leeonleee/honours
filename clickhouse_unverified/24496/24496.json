{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 24496,
  "instance_id": "ClickHouse__ClickHouse-24496",
  "issue_numbers": [
    "1820"
  ],
  "base_commit": "4309e230f056775d6e2815ed52ad80ba53d664a9",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp b/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\nindex 4e151bfdb91e..f5edde014780 100644\n--- a/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\n@@ -343,6 +343,9 @@ SelectPartsDecision MergeTreeDataMergerMutator::selectPartsToMerge(\n     if (parts_to_merge.empty())\n     {\n         SimpleMergeSelector::Settings merge_settings;\n+        /// Override value from table settings\n+        merge_settings.max_parts_to_merge_at_once = data_settings->max_parts_to_merge_at_once;\n+\n         if (aggressive)\n             merge_settings.base = 1;\n \ndiff --git a/src/Storages/MergeTree/MergeTreeSettings.h b/src/Storages/MergeTree/MergeTreeSettings.h\nindex 6e43d0fad77d..673105b3ed46 100644\n--- a/src/Storages/MergeTree/MergeTreeSettings.h\n+++ b/src/Storages/MergeTree/MergeTreeSettings.h\n@@ -56,6 +56,7 @@ struct Settings;\n     M(UInt64, write_ahead_log_interval_ms_to_fsync, 100, \"Interval in milliseconds after which fsync for WAL is being done.\", 0) \\\n     M(Bool, in_memory_parts_insert_sync, false, \"If true insert of part with in-memory format will wait for fsync of WAL\", 0) \\\n     M(UInt64, non_replicated_deduplication_window, 0, \"How many last blocks of hashes should be kept on disk (0 - disabled).\", 0) \\\n+    M(UInt64, max_parts_to_merge_at_once, 100, \"Max amount of parts which can be merged at once (0 - disabled). Doesn't affect OPTIMIZE FINAL query.\", 0) \\\n     \\\n     /** Inserts settings. */ \\\n     M(UInt64, parts_to_delay_insert, 150, \"If table contains at least that many active parts in single partition, artificially slow down insert into table.\", 0) \\\ndiff --git a/src/Storages/MergeTree/SimpleMergeSelector.h b/src/Storages/MergeTree/SimpleMergeSelector.h\nindex 4f277ad74cd7..af339dbfa24b 100644\n--- a/src/Storages/MergeTree/SimpleMergeSelector.h\n+++ b/src/Storages/MergeTree/SimpleMergeSelector.h\n@@ -88,7 +88,7 @@ class SimpleMergeSelector final : public IMergeSelector\n public:\n     struct Settings\n     {\n-        /// Zero means unlimited.\n+        /// Zero means unlimited. Can be overridden by the same merge tree setting.\n         size_t max_parts_to_merge_at_once = 100;\n \n         /** Minimum ratio of size of one part to all parts in set of parts to merge (for usual cases).\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01882_check_max_parts_to_merge_at_once.reference b/tests/queries/0_stateless/01882_check_max_parts_to_merge_at_once.reference\nnew file mode 100644\nindex 000000000000..30a4d52afe1f\n--- /dev/null\n+++ b/tests/queries/0_stateless/01882_check_max_parts_to_merge_at_once.reference\n@@ -0,0 +1,2 @@\n+100\n+1\ndiff --git a/tests/queries/0_stateless/01882_check_max_parts_to_merge_at_once.sql b/tests/queries/0_stateless/01882_check_max_parts_to_merge_at_once.sql\nnew file mode 100644\nindex 000000000000..d6cde1ef7a81\n--- /dev/null\n+++ b/tests/queries/0_stateless/01882_check_max_parts_to_merge_at_once.sql\n@@ -0,0 +1,32 @@\n+DROP TABLE IF EXISTS limited_merge_table;\n+\n+SET max_threads = 1;\n+SET max_block_size = 1;\n+SET min_insert_block_size_rows = 1;\n+\n+CREATE TABLE limited_merge_table\n+(\n+    key UInt64\n+)\n+ENGINE = MergeTree()\n+ORDER BY key\n+SETTINGS max_parts_to_merge_at_once = 3;\n+\n+SYSTEM STOP MERGES limited_merge_table;\n+\n+INSERT INTO limited_merge_table SELECT number FROM numbers(100);\n+\n+SYSTEM START MERGES limited_merge_table;\n+\n+OPTIMIZE TABLE limited_merge_table FINAL;\n+\n+SYSTEM FLUSH LOGS;\n+\n+SELECT COUNT() FROM limited_merge_table;\n+\n+-- final optimize FINAL will merge all parts, but all previous merges must merge <= 3 parts.\n+-- During concurrent run only one final merge can happen, thats why we have this `if`.\n+SELECT if(length(topK(2)(length(merged_from))) == 2, arrayMin(topK(2)(length(merged_from))) <= 3, 1)\n+FROM system.part_log WHERE table = 'limited_merge_table' and database = currentDatabase() and event_type = 'MergeParts';\n+\n+DROP TABLE IF EXISTS limited_merge_table;\n",
  "problem_statement": "Lowering the default for maximum of parts to be merged at once, or make it configurable\nWe have this case recently\r\n\r\n```\r\n:) select num_parts, formatReadableSize(total_size_bytes_compressed) from system.merges where num_parts > 100;\r\n\r\nSELECT\r\n    num_parts,\r\n    formatReadableSize(total_size_bytes_compressed)\r\nFROM system.merges\r\nWHERE num_parts > 100\r\n\r\n\u250c\u2500num_parts\u2500\u252c\u2500formatReadableSize(total_size_bytes_compressed)\u2500\u2510\r\n\u2502      1001 \u2502 49.31 GiB                                       \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nwhere we hits the hard-coded limit of number of parts being merged at once. Merging 1000 parts at once is rarely a good idea though. Can we lower this, or make it configurable somehow ?\n",
  "hints_text": "Memory usage of merges on 3 machines that decided to do this:\r\n\r\n![image](https://user-images.githubusercontent.com/89186/35348446-f3499344-00ec-11e8-98e5-7070be0887f1.png)\r\n\nThis may be related to #1821, as it happened not long after.\nJust add to `MergeTreeSettings` and pass into `SimpleMergeSelector`.",
  "created_at": "2021-05-25T13:23:21Z"
}