{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 13816,
  "instance_id": "ClickHouse__ClickHouse-13816",
  "issue_numbers": [
    "11271"
  ],
  "base_commit": "7a8b1f064b0105084e84a5ba74f47192adf7caf8",
  "patch": "diff --git a/src/Functions/CMakeLists.txt b/src/Functions/CMakeLists.txt\nindex a37fb386d4c6..8d1fff23347f 100644\n--- a/src/Functions/CMakeLists.txt\n+++ b/src/Functions/CMakeLists.txt\n@@ -34,6 +34,7 @@ target_link_libraries(clickhouse_functions\n         ${FASTOPS_LIBRARY}\n         clickhouse_dictionaries\n         clickhouse_dictionaries_embedded\n+        clickhouse_parsers\n         consistent-hashing\n         consistent-hashing-sumbur\n         dbms\ndiff --git a/src/Functions/normalizeQuery.cpp b/src/Functions/normalizeQuery.cpp\nnew file mode 100644\nindex 000000000000..91c5b9d16804\n--- /dev/null\n+++ b/src/Functions/normalizeQuery.cpp\n@@ -0,0 +1,171 @@\n+#include <DataTypes/DataTypeString.h>\n+#include <Columns/ColumnString.h>\n+#include <Functions/FunctionFactory.h>\n+#include <Functions/FunctionStringToString.h>\n+#include <Parsers/Lexer.h>\n+#include <common/find_symbols.h>\n+#include <Common/StringUtils/StringUtils.h>\n+\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int ILLEGAL_COLUMN;\n+}\n+\n+namespace\n+{\n+\n+struct Impl\n+{\n+    static void vector(const ColumnString::Chars & data,\n+        const ColumnString::Offsets & offsets,\n+        ColumnString::Chars & res_data,\n+        ColumnString::Offsets & res_offsets)\n+    {\n+        size_t size = offsets.size();\n+        res_offsets.resize(size);\n+        res_data.reserve(data.size());\n+\n+        ColumnString::Offset prev_src_offset = 0;\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            ColumnString::Offset curr_src_offset = offsets[i];\n+            Lexer lexer(reinterpret_cast<const char *>(&data[prev_src_offset]), reinterpret_cast<const char *>(&data[curr_src_offset - 1]));\n+            prev_src_offset = offsets[i];\n+\n+            /// Coalesce whitespace characters and comments to a single whitespace.\n+            bool prev_insignificant = false;\n+\n+            /// Coalesce a list of comma separated literals to a single '?..' sequence.\n+            size_t num_literals_in_sequence = 0;\n+            bool prev_comma = false;\n+            bool prev_whitespace = false;\n+\n+            while (true)\n+            {\n+                Token token = lexer.nextToken();\n+\n+                if (!token.isSignificant())\n+                {\n+                    /// Replace a sequence of insignificant tokens with single whitespace.\n+                    if (!prev_insignificant)\n+                    {\n+                        if (0 == num_literals_in_sequence)\n+                            res_data.push_back(' ');\n+                        else\n+                            prev_whitespace = true;\n+                    }\n+                    prev_insignificant = true;\n+                    continue;\n+                }\n+\n+                prev_insignificant = false;\n+\n+                /// Literals.\n+                if (token.type == TokenType::Number || token.type == TokenType::StringLiteral)\n+                {\n+                    if (0 == num_literals_in_sequence)\n+                        res_data.push_back('?');\n+                    ++num_literals_in_sequence;\n+                    prev_whitespace = false;\n+                    prev_comma = false;\n+                    continue;\n+                }\n+                else if (token.type == TokenType::Comma)\n+                {\n+                    if (num_literals_in_sequence)\n+                    {\n+                        prev_comma = true;\n+                        continue;\n+                    }\n+                }\n+                else\n+                {\n+                    if (num_literals_in_sequence > 1)\n+                    {\n+                        res_data.push_back('.');\n+                        res_data.push_back('.');\n+                    }\n+\n+                    if (prev_comma)\n+                        res_data.push_back(',');\n+\n+                    if (prev_whitespace)\n+                        res_data.push_back(' ');\n+\n+                    num_literals_in_sequence = 0;\n+                    prev_comma = false;\n+                    prev_whitespace = false;\n+                }\n+\n+                /// Slightly normalize something that look like aliases - if they are complex, replace them to `?` placeholders.\n+                if (token.type == TokenType::QuotedIdentifier\n+                    /// Differentiate identifier from function (example: SHA224(x)).\n+                    /// By the way, there is padding in columns and pointer dereference is Ok.\n+                    || (token.type == TokenType::BareWord && *token.end != '('))\n+                {\n+                    /// Identifier is complex if it contains whitespace or more than two digits.\n+                    size_t num_digits = 0;\n+\n+                    const char * pos = token.begin;\n+                    for (; pos != token.end; ++pos)\n+                    {\n+                        if (isWhitespaceASCII(*pos))\n+                            break;\n+\n+                        if (isNumericASCII(*pos))\n+                        {\n+                            ++num_digits;\n+                            if (num_digits > 2)\n+                                break;\n+                        }\n+                    }\n+\n+                    if (pos == token.end)\n+                    {\n+                        res_data.insert(token.begin, token.end);\n+                    }\n+                    else\n+                    {\n+                        res_data.push_back('`');\n+                        res_data.push_back('?');\n+                        res_data.push_back('`');\n+                    }\n+\n+                    continue;\n+                }\n+\n+                if (token.isEnd() || token.isError())\n+                    break;\n+\n+                res_data.insert(token.begin, token.end);\n+            }\n+\n+            res_data.push_back(0);\n+            res_offsets[i] = res_data.size();\n+        }\n+    }\n+\n+    [[noreturn]] static void vectorFixed(const ColumnString::Chars &, size_t, ColumnString::Chars &)\n+    {\n+        throw Exception(\"Cannot apply function normalizeQuery to fixed string.\", ErrorCodes::ILLEGAL_COLUMN);\n+    }\n+};\n+\n+struct Name\n+{\n+    static constexpr auto name = \"normalizeQuery\";\n+};\n+\n+}\n+\n+void registerFunctionNormalizeQuery(FunctionFactory & factory)\n+{\n+    factory.registerFunction<FunctionStringToString<Impl, Name>>();\n+}\n+\n+}\n+\ndiff --git a/src/Functions/normalizedQueryHash.cpp b/src/Functions/normalizedQueryHash.cpp\nnew file mode 100644\nindex 000000000000..ca5ab7886e75\n--- /dev/null\n+++ b/src/Functions/normalizedQueryHash.cpp\n@@ -0,0 +1,183 @@\n+#include <DataTypes/DataTypeString.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <Columns/ColumnString.h>\n+#include <Columns/ColumnsNumber.h>\n+#include <Functions/FunctionFactory.h>\n+#include <Parsers/Lexer.h>\n+#include <common/find_symbols.h>\n+#include <Common/StringUtils/StringUtils.h>\n+#include <Common/SipHash.h>\n+\n+\n+/** The function returns 64bit hash value that is identical for similar queries.\n+  * See also 'normalizeQuery'. This function is only slightly more efficient.\n+  */\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int ILLEGAL_COLUMN;\n+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+}\n+\n+namespace\n+{\n+\n+struct Impl\n+{\n+    static void vector(\n+        const ColumnString::Chars & data,\n+        const ColumnString::Offsets & offsets,\n+        PaddedPODArray<UInt64> & res_data)\n+    {\n+        size_t size = offsets.size();\n+        res_data.resize(size);\n+\n+        ColumnString::Offset prev_src_offset = 0;\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            SipHash hash;\n+\n+            ColumnString::Offset curr_src_offset = offsets[i];\n+            Lexer lexer(reinterpret_cast<const char *>(&data[prev_src_offset]), reinterpret_cast<const char *>(&data[curr_src_offset - 1]));\n+            prev_src_offset = offsets[i];\n+\n+            /// Coalesce a list of comma separated literals.\n+            size_t num_literals_in_sequence = 0;\n+            bool prev_comma = false;\n+\n+            while (true)\n+            {\n+                Token token = lexer.nextToken();\n+\n+                if (!token.isSignificant())\n+                    continue;\n+\n+                /// Literals.\n+                if (token.type == TokenType::Number || token.type == TokenType::StringLiteral)\n+                {\n+                    if (0 == num_literals_in_sequence)\n+                        hash.update(\"\\x00\", 1);\n+                    ++num_literals_in_sequence;\n+                    prev_comma = false;\n+                    continue;\n+                }\n+                else if (token.type == TokenType::Comma)\n+                {\n+                    if (num_literals_in_sequence)\n+                    {\n+                        prev_comma = true;\n+                        continue;\n+                    }\n+                }\n+                else\n+                {\n+                    if (num_literals_in_sequence > 1)\n+                        hash.update(\"\\x00\", 1);\n+\n+                    if (prev_comma)\n+                        hash.update(\",\", 1);\n+\n+                    num_literals_in_sequence = 0;\n+                    prev_comma = false;\n+                }\n+\n+                /// Slightly normalize something that look like aliases - if they are complex, replace them to `?` placeholders.\n+                if (token.type == TokenType::QuotedIdentifier\n+                    /// Differentiate identifier from function (example: SHA224(x)).\n+                    /// By the way, there is padding in columns and pointer dereference is Ok.\n+                    || (token.type == TokenType::BareWord && *token.end != '('))\n+                {\n+                    /// Identifier is complex if it contains whitespace or more than two digits.\n+                    size_t num_digits = 0;\n+\n+                    const char * pos = token.begin;\n+                    for (; pos != token.end; ++pos)\n+                    {\n+                        if (isWhitespaceASCII(*pos))\n+                            break;\n+\n+                        if (isNumericASCII(*pos))\n+                        {\n+                            ++num_digits;\n+                            if (num_digits > 2)\n+                                break;\n+                        }\n+                    }\n+\n+                    if (pos == token.end)\n+                        hash.update(token.begin, token.size());\n+                    else\n+                        hash.update(\"\\x01\", 1);\n+\n+                    continue;\n+                }\n+\n+                if (token.isEnd() || token.isError())\n+                    break;\n+\n+                hash.update(token.begin, token.size());\n+            }\n+\n+            res_data[i] = hash.get64();\n+        }\n+    }\n+};\n+\n+class FunctionNormalizedQueryHash : public IFunction\n+{\n+public:\n+    static constexpr auto name = \"normalizedQueryHash\";\n+    static FunctionPtr create(const Context &)\n+    {\n+        return std::make_shared<FunctionNormalizedQueryHash>();\n+    }\n+\n+    String getName() const override\n+    {\n+        return name;\n+    }\n+\n+    size_t getNumberOfArguments() const override\n+    {\n+        return 1;\n+    }\n+\n+    DataTypePtr getReturnTypeImpl(const DataTypes & arguments) const override\n+    {\n+        if (!isString(arguments[0]))\n+            throw Exception(\"Illegal type \" + arguments[0]->getName() + \" of argument of function \" + getName(), ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT);\n+\n+        return std::make_shared<DataTypeUInt64>();\n+    }\n+\n+    bool useDefaultImplementationForConstants() const override { return true; }\n+\n+    void executeImpl(Block & block, const ColumnNumbers & arguments, size_t result, size_t /*input_rows_count*/) const override\n+    {\n+        const ColumnPtr column = block.getByPosition(arguments[0]).column;\n+        if (const ColumnString * col = checkAndGetColumn<ColumnString>(column.get()))\n+        {\n+            auto col_res = ColumnUInt64::create();\n+            typename ColumnUInt64::Container & vec_res = col_res->getData();\n+            vec_res.resize(col->size());\n+            Impl::vector(col->getChars(), col->getOffsets(), vec_res);\n+            block.getByPosition(result).column = std::move(col_res);\n+        }\n+        else\n+            throw Exception(\"Illegal column \" + block.getByPosition(arguments[0]).column->getName() + \" of argument of function \" + getName(),\n+                ErrorCodes::ILLEGAL_COLUMN);\n+    }\n+};\n+\n+}\n+\n+void registerFunctionNormalizedQueryHash(FunctionFactory & factory)\n+{\n+    factory.registerFunction<FunctionNormalizedQueryHash>();\n+}\n+\n+}\n+\ndiff --git a/src/Functions/registerFunctionsString.cpp b/src/Functions/registerFunctionsString.cpp\nindex ae09498ee99f..5d4c165e1e3d 100644\n--- a/src/Functions/registerFunctionsString.cpp\n+++ b/src/Functions/registerFunctionsString.cpp\n@@ -30,6 +30,8 @@ void registerFunctionStartsWith(FunctionFactory &);\n void registerFunctionEndsWith(FunctionFactory &);\n void registerFunctionTrim(FunctionFactory &);\n void registerFunctionRegexpQuoteMeta(FunctionFactory &);\n+void registerFunctionNormalizeQuery(FunctionFactory &);\n+void registerFunctionNormalizedQueryHash(FunctionFactory &);\n \n #if USE_BASE64\n void registerFunctionBase64Encode(FunctionFactory &);\n@@ -62,6 +64,8 @@ void registerFunctionsString(FunctionFactory & factory)\n     registerFunctionEndsWith(factory);\n     registerFunctionTrim(factory);\n     registerFunctionRegexpQuoteMeta(factory);\n+    registerFunctionNormalizeQuery(factory);\n+    registerFunctionNormalizedQueryHash(factory);\n #if USE_BASE64\n     registerFunctionBase64Encode(factory);\n     registerFunctionBase64Decode(factory);\ndiff --git a/src/Functions/ya.make.in b/src/Functions/ya.make.in\nindex 72d9cf9476a5..4c097e2c4bbf 100644\n--- a/src/Functions/ya.make.in\n+++ b/src/Functions/ya.make.in\n@@ -17,6 +17,7 @@ ADDINCL(\n \n PEERDIR(\n     clickhouse/src/Common\n+    clickhouse/src/Parsers\n     clickhouse/src/Dictionaries\n     contrib/libs/farmhash\n     contrib/libs/fastops/fastops\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01451_normalize_query.reference b/tests/queries/0_stateless/01451_normalize_query.reference\nnew file mode 100644\nindex 000000000000..67aa3a97998c\n--- /dev/null\n+++ b/tests/queries/0_stateless/01451_normalize_query.reference\n@@ -0,0 +1,22 @@\n+SELECT ?\n+SELECT ?\n+SELECT ?..\n+SELECT ?.., \n+SELECT ?.., \n+SELECT ?..\n+SELECT ?.. WHERE ?\n+SELECT ?.. WHERE ? = ?\n+SELECT ?.. WHERE ? = ? AND (x, y)\n+SELECT ?.. WHERE ? = ? AND (?, y)\n+[?..]\n+[?.., x]\n+SELECT ?.. WHERE ? = ? AND (?, y) LIMIT ?..\n+SELECT ? AS `xyz`\n+SELECT ? AS `xyz1`\n+SELECT ? AS `xyz11`\n+SELECT ? AS `?`\n+SELECT ? AS xyz1\n+SELECT ? AS xyz11\n+SELECT ? xyz11\n+SELECT ?, xyz11\n+SELECT ?..\ndiff --git a/tests/queries/0_stateless/01451_normalize_query.sql b/tests/queries/0_stateless/01451_normalize_query.sql\nnew file mode 100644\nindex 000000000000..d1e45dea967b\n--- /dev/null\n+++ b/tests/queries/0_stateless/01451_normalize_query.sql\n@@ -0,0 +1,22 @@\n+SELECT normalizeQuery('SELECT 1');\n+SELECT normalizeQuery('SELECT  1');\n+SELECT normalizeQuery('SELECT  1, 1, 1');\n+SELECT normalizeQuery('SELECT 1, 1, 1, /* Hwllo */');\n+SELECT normalizeQuery('SELECT 1, 1, 1, /* Hello */');\n+SELECT normalizeQuery('SELECT 1, 1, 1, /* Hello */ \\'abc\\'');\n+SELECT normalizeQuery('SELECT 1, 1, 1, /* Hello */ \\'abc\\' WHERE 1');\n+SELECT normalizeQuery('SELECT 1, 1, 1, /* Hello */ \\'abc\\' WHERE 1 = 1');\n+SELECT normalizeQuery('SELECT 1, 1, 1, /* Hello */ \\'abc\\' WHERE 1 = 1 AND (x, y)');\n+SELECT normalizeQuery('SELECT 1, 1, 1, /* Hello */ \\'abc\\' WHERE 1 = 1 AND (1, y)');\n+SELECT normalizeQuery('[1, 2, 3]');\n+SELECT normalizeQuery('[1, 2, 3, x]');\n+SELECT normalizeQuery('SELECT 1, 1, 1, /* Hello */ \\'abc\\' WHERE 1 = 1 AND (1, y) LIMIT 1, 1');\n+SELECT normalizeQuery('SELECT 1 AS `xyz`');\n+SELECT normalizeQuery('SELECT 1 AS `xyz1`');\n+SELECT normalizeQuery('SELECT 1 AS `xyz11`');\n+SELECT normalizeQuery('SELECT 1 AS xyz111');\n+SELECT normalizeQuery('SELECT 1 AS xyz1');\n+SELECT normalizeQuery('SELECT 1 AS xyz11');\n+SELECT normalizeQuery('SELECT 1 xyz11');\n+SELECT normalizeQuery('SELECT 1, xyz11');\n+SELECT normalizeQuery('SELECT 1, ''xyz11''');\ndiff --git a/tests/queries/0_stateless/01452_normalized_query_hash.reference b/tests/queries/0_stateless/01452_normalized_query_hash.reference\nnew file mode 100644\nindex 000000000000..fcb49fa99454\n--- /dev/null\n+++ b/tests/queries/0_stateless/01452_normalized_query_hash.reference\n@@ -0,0 +1,7 @@\n+1\n+1\n+1\n+1\n+1\n+1\n+1\ndiff --git a/tests/queries/0_stateless/01452_normalized_query_hash.sql b/tests/queries/0_stateless/01452_normalized_query_hash.sql\nnew file mode 100644\nindex 000000000000..a888d2b87b5b\n--- /dev/null\n+++ b/tests/queries/0_stateless/01452_normalized_query_hash.sql\n@@ -0,0 +1,7 @@\n+SELECT normalizedQueryHash('SELECT 1') = normalizedQueryHash('SELECT 2');\n+SELECT normalizedQueryHash('SELECT  1') != normalizedQueryHash('SELECT  1, 1, 1');\n+SELECT normalizedQueryHash('SELECT 1, 1, 1, /* Hello */ \\'abc\\'') = normalizedQueryHash('SELECT 2, 3');\n+SELECT normalizedQueryHash('[1, 2, 3]') = normalizedQueryHash('[1, ''x'']');\n+SELECT normalizedQueryHash('[1, 2, 3, x]') != normalizedQueryHash('[1, x]');\n+SELECT normalizedQueryHash('SELECT 1 AS `xyz`') != normalizedQueryHash('SELECT 1 AS `abc`');\n+SELECT normalizedQueryHash('SELECT 1 AS xyz111') = normalizedQueryHash('SELECT 2 AS xyz234');\n",
  "problem_statement": "Query normalization and hashing functions.\nProvide a function to replace literals and lists of literals in SQL query to question marks.\r\nProvide a function to calculate a hash of query structure without the values of literals.\r\n\r\nExample:\r\n`SELECT count(*) FROM table WHERE date = '2020-01-02' AND id IN (1, 2, 3) LIMIT 10, 10`\r\nshould be replaced to\r\n`SELECT count(*) FROM table WHERE date = ? AND id IN (?) LIMIT ?`\r\n\r\nThe function should be database agnostic: it should work for ClickHouse queries as well as MySQL queries.\r\n\r\nWhy do we need this feature.\r\n1. We will extract all unique queries from our production machines for testing.\r\n2. These functions will be useful for various monitoring and performance tools*.\r\n\r\n\\* ClickHouse is already used as main database in multiple popular tools to analyze performance of SQL queries in MySQL, Postgres.\n",
  "hints_text": "Proposed names:\r\n`queryNormalize`\r\n`queryHash`",
  "created_at": "2020-08-16T18:19:00Z"
}