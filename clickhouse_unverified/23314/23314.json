{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 23314,
  "instance_id": "ClickHouse__ClickHouse-23314",
  "issue_numbers": [
    "22408"
  ],
  "base_commit": "fc2e2848bffbafae18adf177333396716a92f3be",
  "patch": "diff --git a/src/AggregateFunctions/QuantileTDigest.h b/src/AggregateFunctions/QuantileTDigest.h\nindex 490abd5d1342..76d2f608d59b 100644\n--- a/src/AggregateFunctions/QuantileTDigest.h\n+++ b/src/AggregateFunctions/QuantileTDigest.h\n@@ -132,6 +132,7 @@ class QuantileTDigest\n         if (unmerged > params.max_unmerged)\n             compress();\n     }\n+\n     void compressBrute()\n     {\n         if (centroids.size() <= params.max_centroids)\n@@ -195,14 +196,12 @@ class QuantileTDigest\n             BetterFloat l_count = l->count;\n             while (r != centroids.end())\n             {\n-                if (l->mean == r->mean) // Perfect aggregation (fast). We compare l->mean, not l_mean, to avoid identical elements after compress\n-                {\n-                    l_count += r->count;\n-                    l->count = l_count;\n-                    ++r;\n-                    continue;\n-                }\n-                // we use quantile which gives us the smallest error\n+                /// N.B. Piece of logic which compresses the same singleton centroids into one centroid is removed\n+                /// because: 1) singleton centroids are being processed in unusual way in recent version of algorithm\n+                /// and such compression would break this logic;\n+                /// 2) we shall not compress centroids further than `max_centroids` parameter requires because\n+                /// this will lead to uneven compression.\n+                /// For more information see: https://arxiv.org/abs/1902.04023\n \n                 /// The ratio of the part of the histogram to l, including the half l to the entire histogram. That is, what level quantile in position l.\n                 BetterFloat ql = (sum + l_count * 0.5) / count;\n@@ -320,16 +319,29 @@ class QuantileTDigest\n         Float64 prev_x = 0;\n         Count sum = 0;\n         Value prev_mean = centroids.front().mean;\n+        Count prev_count = centroids.front().count;\n \n         for (const auto & c : centroids)\n         {\n             Float64 current_x = sum + c.count * 0.5;\n \n             if (current_x >= x)\n-                return interpolate(x, prev_x, prev_mean, current_x, c.mean);\n+            {\n+                /// Special handling of singletons.\n+                Float64 left = prev_x + 0.5 * (prev_count == 1);\n+                Float64 right = current_x - 0.5 * (c.count == 1);\n+\n+                if (x <= left)\n+                    return prev_mean;\n+                else if (x >= right)\n+                    return c.mean;\n+                else\n+                    return interpolate(x, left, prev_mean, right, c.mean);\n+            }\n \n             sum += c.count;\n             prev_mean = c.mean;\n+            prev_count = c.count;\n             prev_x = current_x;\n         }\n \n@@ -364,25 +376,40 @@ class QuantileTDigest\n         Float64 prev_x = 0;\n         Count sum = 0;\n         Value prev_mean = centroids.front().mean;\n+        Count prev_count = centroids.front().count;\n \n         size_t result_num = 0;\n         for (const auto & c : centroids)\n         {\n             Float64 current_x = sum + c.count * 0.5;\n \n-            while (current_x >= x)\n+            if (current_x >= x)\n             {\n-                result[levels_permutation[result_num]] = interpolate(x, prev_x, prev_mean, current_x, c.mean);\n+                /// Special handling of singletons.\n+                Float64 left = prev_x + 0.5 * (prev_count == 1);\n+                Float64 right = current_x - 0.5 * (c.count == 1);\n+\n+                while (current_x >= x)\n+                {\n+\n+                    if (x <= left)\n+                        result[levels_permutation[result_num]] = prev_mean;\n+                    else if (x >= right)\n+                        result[levels_permutation[result_num]] = c.mean;\n+                    else\n+                        result[levels_permutation[result_num]] = interpolate(x, left, prev_mean, right, c.mean);\n \n-                ++result_num;\n-                if (result_num >= size)\n-                    return;\n+                    ++result_num;\n+                    if (result_num >= size)\n+                        return;\n \n-                x = levels[levels_permutation[result_num]] * count;\n+                    x = levels[levels_permutation[result_num]] * count;\n+                }\n             }\n \n             sum += c.count;\n             prev_mean = c.mean;\n+            prev_count = c.count;\n             prev_x = current_x;\n         }\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/00273_quantiles.reference b/tests/queries/0_stateless/00273_quantiles.reference\nindex 616e06841e4f..aefb00846486 100644\n--- a/tests/queries/0_stateless/00273_quantiles.reference\n+++ b/tests/queries/0_stateless/00273_quantiles.reference\n@@ -4,7 +4,7 @@\n [500]\n [0,1,10,50,100,200,300,400,500,600,700,800,900,950,990,999,1000]\n [0,1,10,50,100,200,300,400,500,600,700,800,900,950,990,999,1000]\n-[0,0.50100005,9.51,49.55,99.6,199.7,299.8,399.9,500,600.1,700.2,800.3,900.4,950.45,990.49,999.499,1000]\n+[0,1,10,50,99.6,199.7,299.8,399.9,500,600.1,700.2,800.3,900.4,950,990,999,1000]\n [0,1,10,50,100,200,300,400,500,600,700,800,900,950,990,999,1000]\n 1\t333334\t[699144.2,835663,967429.2]\t[699999,833333,966666]\n 2\t266667\t[426549.5,536255.5,638957.6]\t[426665,533332,639999]\ndiff --git a/tests/queries/0_stateless/00725_quantiles_shard.reference b/tests/queries/0_stateless/00725_quantiles_shard.reference\nindex 6974bee97355..ec404bb89a19 100644\n--- a/tests/queries/0_stateless/00725_quantiles_shard.reference\n+++ b/tests/queries/0_stateless/00725_quantiles_shard.reference\n@@ -1,4 +1,4 @@\n [4.5,8.100000000000001]\n [5,9]\n-[4.5,8.5]\n+[4,8]\n [4.5,8.100000000000001]\n",
  "problem_statement": "quantileTDigest inaccuracy with extreme quanties.\n**Use case**\r\nClickhouse version 21.4\r\n```\r\nSELECT\r\n    quantileTiming(0.95)(key) AS timing,\r\n    quantileExact(0.95)(key) AS exact,\r\n    quantileTDigest(0.95)(key) AS tdigest\r\nFROM\r\n(\r\n    SELECT\r\n        9000 AS key,\r\n        2 AS count\r\n    UNION ALL\r\n    SELECT\r\n        3000,\r\n        11\r\n    UNION ALL\r\n    SELECT\r\n        1000,\r\n        26\r\n)\r\nARRAY JOIN range(count) AS s\r\n\r\nQuery id: addce63f-0b75-46e2-b896-712d66711fb0\r\n\r\n\u250c\u2500timing\u2500\u252c\u2500exact\u2500\u252c\u2500\u2500tdigest\u2500\u2510\r\n\u2502   9000 \u2502  9000 \u2502 8123.076 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n\r\nSELECT\r\n    quantileTiming(0.9)(key) AS timing,\r\n    quantileExact(0.9)(key) AS exact,\r\n    quantileTDigest(0.9)(key) AS tdigest\r\nFROM\r\n(\r\n    SELECT key\r\n    FROM\r\n    (\r\n        SELECT\r\n            9000 AS key,\r\n            2 AS count\r\n        UNION ALL\r\n        SELECT\r\n            3000,\r\n            11\r\n        UNION ALL\r\n        SELECT\r\n            1000,\r\n            26\r\n    )\r\n    ARRAY JOIN range(count) AS s\r\n    ORDER BY key ASC\r\n)\r\n\r\nQuery id: e92e3d07-3b97-4155-aa10-9a15544d9312\r\n\r\n\u250c\u2500timing\u2500\u252c\u2500exact\u2500\u252c\u2500\u2500\u2500tdigest\u2500\u2510\r\n\u2502   3000 \u2502  3000 \u2502 6323.0757 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n```\r\n\r\nProbably related: https://github.com/tdunning/t-digest/issues/154\n",
  "hints_text": "https://github.com/ClickHouse/ClickHouse/issues/1158 ? \nOne more test - here also the error of quantile is drastic:\r\n```\r\nSELECT\r\n    quantile(0.95)(v) AS quantile,\r\n    quantileTiming(0.95)(v) AS timing,\r\n    quantileExact(0.95)(v) AS exact,\r\n    quantileTDigest(0.95)(v) AS tdigest\r\nFROM \r\n(\r\n    SELECT\r\n        multiIf(number < 15, 1, 2) AS k,\r\n        multiIf(number < 10, 1000, number < 15, 3000, number < 31, 1000, number < 37, 3000, number <= 38, 9000, 0) AS v\r\n    FROM numbers(39)\r\n)\r\n\r\nQuery id: 2773592f-870e-4251-b0dd-95b90f64b060\r\n\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500quantile\u2500\u252c\u2500timing\u2500\u252c\u2500exact\u2500\u252c\u2500\u2500tdigest\u2500\u2510\r\n\u2502 3600.0000000000086 \u2502   9000 \u2502  9000 \u2502 8123.076 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\nCould you please provide some reasoning - how comes that the T-Digest algorithm should return a better answer?\r\nYour example looks like the natural behaviour of the underlying approximate algorithm.\r\n\r\nBut I cannot quickly quantify if it's as inacurrate as it should be or it can be better.\nDid you check tdunning/t-digest#154 ? \nNo.\n@filimonov I checked it:\r\n> Instead of fancy sorting by weight, I changed the sort to be stable.\r\n\r\nWe are already using stable sort (Radix LSD), so the fix is irrelevant for us.\n@UnamedRus Clarification needed.\nI compiled library from github (v3.3) \r\n\r\ncreateAvlTreeDigest(20)\r\n\r\n/opt/test/build/.\r\n0.05 1000.0\r\n0.95 5799.999999999993\r\n\r\ncreateMergingDigest(20)\r\n\r\n/opt/test/build/.\r\n0.05 1000.0\r\n0.95 9000.0\r\n\r\nAnd MergingDigest provides correct result. \r\n But currect release 3.2 provides inaccurate result.\nhttps://github.com/tdunning/t-digest/commit/72a1d6fc85523b046246fd16bcd3f3df5c689d3b\r\n\r\nBefore this commit: 7199.999999999989\r\nAfter this commit: 9000.0\r\n",
  "created_at": "2021-04-19T17:16:15Z",
  "modified_files": [
    "src/AggregateFunctions/QuantileTDigest.h"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/00273_quantiles.reference",
    "tests/queries/0_stateless/00725_quantiles_shard.reference"
  ]
}