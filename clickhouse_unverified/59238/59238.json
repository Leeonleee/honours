{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 59238,
  "instance_id": "ClickHouse__ClickHouse-59238",
  "issue_numbers": [
    "59165"
  ],
  "base_commit": "875efc54b86c46f7ecb1d373627b6806da1873ef",
  "patch": "diff --git a/docs/en/operations/settings/settings.md b/docs/en/operations/settings/settings.md\nindex 75d05d553663..5f197990f4db 100644\n--- a/docs/en/operations/settings/settings.md\n+++ b/docs/en/operations/settings/settings.md\n@@ -2040,6 +2040,32 @@ SELECT * FROM test_table\n \u2514\u2500\u2500\u2500\u2518\n ```\n \n+## update_insert_deduplication_token_in_dependent_materialized_views {#update-insert-deduplication-token-in-dependent-materialized-views}\n+\n+Allows to update `insert_deduplication_token` with table identifier during insert in dependent materialized views, if setting `deduplicate_blocks_in_dependent_materialized_views` is enabled and `insert_deduplication_token` is set.\n+\n+Possible values:\n+\n+      0 \u2014 Disabled.\n+      1 \u2014 Enabled.\n+\n+Default value: 0.\n+\n+Usage:\n+\n+If setting `deduplicate_blocks_in_dependent_materialized_views` is enabled, `insert_deduplication_token` is passed to dependent materialized views. But in complex INSERT flows it is possible that we want to avoid deduplication for dependent materialized views.\n+\n+Example:\n+```\n+landing -\u252c--> mv_1_1 ---> ds_1_1 ---> mv_2_1 --\u252c-> ds_2_1 ---> mv_3_1 ---> ds_3_1\n+         |                                     |\n+         \u2514--> mv_1_2 ---> ds_1_2 ---> mv_2_2 --\u2518\n+```\n+\n+In this example we want to avoid deduplication for two different blocks generated from `mv_2_1` and `mv_2_2` that will be inserted into `ds_2_1`. Without `update_insert_deduplication_token_in_dependent_materialized_views` setting enabled, those two different blocks will be deduplicated, because different blocks from `mv_2_1` and `mv_2_2` will have the same `insert_deduplication_token`.\n+\n+If setting `update_insert_deduplication_token_in_dependent_materialized_views` is enabled, during each insert into dependent materialized views `insert_deduplication_token` is updated with table identifier, so block from `mv_2_1` and block from `mv_2_2` will have different `insert_deduplication_token` and will not be deduplicated.\n+\n ## insert_keeper_max_retries\n \n The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree. Only Keeper requests which failed due to network error, Keeper session timeout, or request timeout are considered for retries.\n@@ -5165,7 +5191,7 @@ SETTINGS(dictionary_use_async_executor=1, max_threads=8);\n ## storage_metadata_write_full_object_key {#storage_metadata_write_full_object_key}\n \n When set to `true` the metadata files are written with `VERSION_FULL_OBJECT_KEY` format version. With that format full object storage key names are written to the metadata files.\n-When set to `false` the metadata files are written with the previous format version, `VERSION_INLINE_DATA`. With that format only suffixes of object storage key names are are written to the metadata files. The prefix for all of object storage key names is set in configurations files at `storage_configuration.disks` section. \n+When set to `false` the metadata files are written with the previous format version, `VERSION_INLINE_DATA`. With that format only suffixes of object storage key names are are written to the metadata files. The prefix for all of object storage key names is set in configurations files at `storage_configuration.disks` section.\n \n Default value: `false`.\n \ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex e0b3ca39899f..a09f2d2331df 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -588,6 +588,7 @@ class IColumn;\n     M(Bool, normalize_function_names, true, \"Normalize function names to their canonical names\", 0) \\\n     M(Bool, enable_early_constant_folding, true, \"Enable query optimization where we analyze function and subqueries results and rewrite query if there're constants there\", 0) \\\n     M(Bool, deduplicate_blocks_in_dependent_materialized_views, false, \"Should deduplicate blocks for materialized views if the block is not a duplicate for the table. Use true to always deduplicate in dependent tables.\", 0) \\\n+    M(Bool, update_insert_deduplication_token_in_dependent_materialized_views, false, \"Should update insert deduplication token with table identifier during insert in dependent materialized views.\", 0) \\\n     M(Bool, materialized_views_ignore_errors, false, \"Allows to ignore errors for MATERIALIZED VIEW, and deliver original block to the table regardless of MVs\", 0) \\\n     M(Bool, ignore_materialized_views_with_dropped_target_table, false, \"Ignore MVs with dropped taraget table during pushing to views\", 0) \\\n     M(Bool, allow_experimental_refreshable_materialized_view, false, \"Allow refreshable materialized views (CREATE MATERIALIZED VIEW <name> REFRESH ...).\", 0) \\\ndiff --git a/src/Processors/Transforms/buildPushingToViewsChain.cpp b/src/Processors/Transforms/buildPushingToViewsChain.cpp\nindex 960cc0190015..8ddc3ab0c61f 100644\n--- a/src/Processors/Transforms/buildPushingToViewsChain.cpp\n+++ b/src/Processors/Transforms/buildPushingToViewsChain.cpp\n@@ -244,7 +244,33 @@ Chain buildPushingToViewsChain(\n \n         // Do not deduplicate insertions into MV if the main insertion is Ok\n         if (disable_deduplication_for_children)\n+        {\n             insert_context->setSetting(\"insert_deduplicate\", Field{false});\n+        }\n+        else if (insert_settings.update_insert_deduplication_token_in_dependent_materialized_views &&\n+            !insert_settings.insert_deduplication_token.value.empty())\n+        {\n+            /** Update deduplication token passed to dependent MV with current table id. So it is possible to properly handle\n+              * deduplication in complex INSERT flows.\n+              *\n+              * Example:\n+              *\n+              * landing -\u252c--> mv_1_1 ---> ds_1_1 ---> mv_2_1 --\u252c-> ds_2_1 ---> mv_3_1 ---> ds_3_1\n+              *          |                                     |\n+              *          \u2514--> mv_1_2 ---> ds_1_2 ---> mv_2_2 --\u2518\n+              *\n+              * Here we want to avoid deduplication for two different blocks generated from `mv_2_1` and `mv_2_2` that will\n+              * be inserted into `ds_2_1`.\n+              */\n+            auto insert_deduplication_token = insert_settings.insert_deduplication_token.value;\n+\n+            if (table_id.hasUUID())\n+                insert_deduplication_token += \"_\" + toString(table_id.uuid);\n+            else\n+                insert_deduplication_token += \"_\" + table_id.getFullNameNotQuoted();\n+\n+            insert_context->setSetting(\"insert_deduplication_token\", insert_deduplication_token);\n+        }\n \n         // Processing of blocks for MVs is done block by block, and there will\n         // be no parallel reading after (plus it is not a costless operation)\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02972_insert_deduplication_token_hierarchical_inserts.reference b/tests/queries/0_stateless/02972_insert_deduplication_token_hierarchical_inserts.reference\nnew file mode 100644\nindex 000000000000..71c9053d644a\n--- /dev/null\n+++ b/tests/queries/0_stateless/02972_insert_deduplication_token_hierarchical_inserts.reference\n@@ -0,0 +1,9 @@\n+0\n+ds_1_1\tall_1_1_0\t0\n+ds_1_2\tall_1_1_0\t0\n+ds_2_1\tall_1_1_0\t0\n+ds_2_1\tall_2_2_0\t0\n+ds_3_1\tall_1_1_0\t0\n+ds_3_1\tall_2_2_0\t0\n+landing\tall_1_1_0\t0\n+10\ndiff --git a/tests/queries/0_stateless/02972_insert_deduplication_token_hierarchical_inserts.sql b/tests/queries/0_stateless/02972_insert_deduplication_token_hierarchical_inserts.sql\nnew file mode 100644\nindex 000000000000..242133e9122d\n--- /dev/null\n+++ b/tests/queries/0_stateless/02972_insert_deduplication_token_hierarchical_inserts.sql\n@@ -0,0 +1,103 @@\n+SET insert_deduplicate = 1;\n+SET deduplicate_blocks_in_dependent_materialized_views = 1;\n+SET update_insert_deduplication_token_in_dependent_materialized_views = 1;\n+SET insert_deduplication_token = 'test';\n+\n+DROP TABLE IF EXISTS landing;\n+CREATE TABLE landing\n+(\n+    timestamp UInt64,\n+    value UInt64\n+)\n+ENGINE = MergeTree ORDER BY tuple() SETTINGS non_replicated_deduplication_window = 1000;\n+\n+DROP TABLE IF EXISTS ds_1_1;\n+CREATE TABLE ds_1_1\n+(\n+    t UInt64,\n+    v UInt64\n+)\n+ENGINE = MergeTree ORDER BY tuple() SETTINGS non_replicated_deduplication_window = 1000;\n+\n+DROP VIEW IF EXISTS mv_1_1;\n+CREATE MATERIALIZED VIEW mv_1_1 TO ds_1_1 as\n+SELECT\n+    timestamp t, sum(value) v\n+FROM landing\n+GROUP BY t;\n+\n+DROP TABLE IF EXISTS ds_1_2;\n+CREATE TABLE ds_1_2\n+(\n+    t UInt64,\n+    v UInt64\n+)\n+ENGINE = MergeTree ORDER BY tuple() SETTINGS non_replicated_deduplication_window = 1000;\n+\n+DROP VIEW IF EXISTS mv_1_2;\n+CREATE MATERIALIZED VIEW mv_1_2 TO ds_1_2 as\n+SELECT\n+    timestamp t, sum(value) v\n+FROM landing\n+GROUP BY t;\n+\n+DROP TABLE IF EXISTS ds_2_1;\n+CREATE TABLE ds_2_1\n+(\n+    l String,\n+    t DateTime,\n+    v UInt64\n+)\n+ENGINE = MergeTree ORDER BY tuple() SETTINGS non_replicated_deduplication_window = 1000;\n+\n+DROP VIEW IF EXISTS mv_2_1;\n+CREATE MATERIALIZED VIEW mv_2_1 TO ds_2_1 as\n+SELECT '2_1' l, t, v\n+FROM ds_1_1;\n+\n+DROP VIEW IF EXISTS mv_2_2;\n+CREATE MATERIALIZED VIEW mv_2_2 TO ds_2_1 as\n+SELECT '2_2' l, t, v\n+FROM ds_1_2;\n+\n+DROP TABLE IF EXISTS ds_3_1;\n+CREATE TABLE ds_3_1\n+(\n+    l String,\n+    t DateTime,\n+    v UInt64\n+)\n+ENGINE = MergeTree ORDER BY tuple() SETTINGS non_replicated_deduplication_window = 1000;\n+\n+DROP VIEW IF EXISTS mv_3_1;\n+CREATE MATERIALIZED VIEW mv_3_1 TO ds_3_1 as\n+SELECT '3_1' l, t, v\n+FROM ds_2_1;\n+\n+INSERT INTO landing SELECT 1 as timestamp, 1 AS value FROM numbers(10);\n+\n+SELECT sleep(3);\n+\n+INSERT INTO landing SELECT 1 as timestamp, 1 AS value FROM numbers(10);\n+\n+SYSTEM FLUSH LOGS;\n+SELECT table, name, error FROM system.part_log\n+WHERE database = currentDatabase()\n+ORDER BY table, name;\n+\n+SELECT count() FROM landing;\n+\n+DROP TABLE landing;\n+\n+DROP TABLE ds_1_1;\n+DROP VIEW mv_1_1;\n+\n+DROP TABLE ds_1_2;\n+DROP VIEW mv_1_2;\n+\n+DROP TABLE ds_2_1;\n+DROP VIEW mv_2_1;\n+DROP VIEW mv_2_2;\n+\n+DROP TABLE ds_3_1;\n+DROP VIEW mv_3_1;\n",
  "problem_statement": "MV deduplication not working as expected when passing `insert_deduplication_token` \nWe are trying to emulate transactions (or to be able to have idempotent inserts) by using deduplication so we can safely retry inserts on failure. We can generate a static block of rows and assign a `$insertion_id` to each one. Having that set up and passing the following settings, we can retry inserts that have partially written data in any table in the data flow.\r\n\r\n- insert_deduplicate = 1\r\n- deduplicate_blocks_in_dependent_materialized_views = 1\r\n- insert_deduplication_token = $insertion_id (automatically generated for each block of rows we ingest)\r\n\r\nThis has been working fine but we have encountered a corner case. Note that the following setup is a bit special since a landing table gets split into various MVs and reunited again into another table.\r\n\r\nThis is the schematics of the setup:\r\n\r\n```\r\nlanding -\u252c--> mv_1_1 ---> ds_1_1 ---> mv_2_1 --\u252c-> ds_2_1 ---> mv_2_2 ---> ds_3_1\r\n         |                                     |  \r\n         \u2514--> mv_1_2 ---> ds_1_2 ---> mv_2_2 --\u2518 \r\n\r\n```\r\n\r\nAnd here is a script to reproduce the setup and the issue we are seeing: https://pastila.nl/?003e3b86/1785bacbca04dd3ef0c91f4e115b1e6f#e9/2/RQDxlV+QARpP3tw8g==\r\n\r\nIf you run the script you can see the following output from `system.part_log`:\r\n\r\n```sql\r\n\u250c\u2500query_id\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500event_time\u2500\u252c\u2500database\u2500\u252c\u2500table\u2500\u2500\u2500\u252c\u2500name\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500error\u2500\u2510\r\n\u2502 first_insert  \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 landing \u2502 all_0_0_0 \u2502     0 \u2502\r\n\u2502 first_insert  \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 landing \u2502 all_1_1_0 \u2502     0 \u2502\r\n\u2502 first_insert  \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_1_2  \u2502 all_0_0_0 \u2502     0 \u2502\r\n\u2502 first_insert  \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_1_1  \u2502 all_0_0_0 \u2502     0 \u2502\r\n\u2502 first_insert  \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_2_1  \u2502 all_0_0_0 \u2502     0 \u2502\r\n\u2502 first_insert  \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_2_1  \u2502 all_2_2_0 \u2502   389 \u2502  # <= Shouldn't be deduplicated\r\n\u2502 first_insert  \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_3_1  \u2502 all_0_0_0 \u2502     0 \u2502\r\n\u2502 first_insert  \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_3_1  \u2502 all_2_2_0 \u2502   389 \u2502  # <= Shouldn't be deduplicated\r\n\u2502 second_insert \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 landing \u2502 all_3_3_0 \u2502   389 \u2502\r\n\u2502 second_insert \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 landing \u2502 all_4_4_0 \u2502   389 \u2502\r\n\u2502 second_insert \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_1_2  \u2502 all_2_2_0 \u2502   389 \u2502\r\n\u2502 second_insert \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_1_1  \u2502 all_2_2_0 \u2502   389 \u2502\r\n\u2502 second_insert \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_2_1  \u2502 all_3_3_0 \u2502   389 \u2502\r\n\u2502 second_insert \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_2_1  \u2502 all_4_4_0 \u2502   389 \u2502\r\n\u2502 second_insert \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_3_1  \u2502 all_3_3_0 \u2502   389 \u2502\r\n\u2502 second_insert \u2502 2024-01-24 12:10:06 \u2502 dedup    \u2502 ds_3_1  \u2502 all_4_4_0 \u2502   389 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n1. first insert: We set a custom deduplication token and all inserts until `ds_2_1` are properly ingested (no deduplication). The issue starts at `ds_2_1` since it's receiving the \"same block\" in two different inserts (through `mv_2_1` and `mv_2_2`) , and the second one gets deduplicated. The deduplication then propagates to `ds_3_1` and any other DS downstream.\r\n2. second insert: Everything gets correctly deduplicated. Something expected\r\n\r\nI'd expect ClickHouse to handle this despite technically being the same ingested block. **Could this be considered a bug, or is it expected behavior?** How is the internal deduplication being executed? Is it not considering that they are two different parts coming from different MVs?\r\n\r\nA possible solution could be to stop sending our custom token and rely on ClickHouse generated hashes using the data, but we see two possible drawbacks:\r\n* If a MV is not deterministic (e.g. it's using `now()`) it will always generate different output, and retries are not going to get deduplicated\r\n* If a MV generates the same output for two different inserts (e.g. MV doing only a `count()` and two inserts ingesting 1k different rows), the second one is going to be deduplicated when it shouldn't\r\n\r\nWe are aware of initiatives like microtransactions (https://github.com/ClickHouse/ClickHouse/issues/57815) but we wonder if there is something we can do meanwhile to fix this situation.\n",
  "hints_text": "ds_2_1 skips inserts because both parents ds_1_1, ds_1_2 produce the same dedup token: `original_token`+`_1`\r\n\r\nanother approach which can be implemented for dedup checksums\r\n* https://github.com/ClickHouse/ClickHouse/issues/30240#issuecomment-944636538",
  "created_at": "2024-01-25T18:06:47Z",
  "modified_files": [
    "docs/en/operations/settings/settings.md",
    "src/Core/Settings.h",
    "src/Processors/Transforms/buildPushingToViewsChain.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02972_insert_deduplication_token_hierarchical_inserts.reference",
    "b/tests/queries/0_stateless/02972_insert_deduplication_token_hierarchical_inserts.sql"
  ]
}