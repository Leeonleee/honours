{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 11296,
  "instance_id": "ClickHouse__ClickHouse-11296",
  "issue_numbers": [
    "6228",
    "11297",
    "5732"
  ],
  "base_commit": "6468d7af8c6d54a7bcf0cfd4ad481d11446222d6",
  "patch": "diff --git a/programs/client/Client.cpp b/programs/client/Client.cpp\nindex afc8f9a72b14..878eaede2fec 100644\n--- a/programs/client/Client.cpp\n+++ b/programs/client/Client.cpp\n@@ -1583,6 +1583,11 @@ class Client : public Poco::Util::Application\n         if (std::string::npos != embedded_stack_trace_pos && !config().getBool(\"stacktrace\", false))\n             text.resize(embedded_stack_trace_pos);\n \n+        /// If we probably have progress bar, we should add additional newline,\n+        /// otherwise exception may display concatenated with the progress bar.\n+        if (need_render_progress)\n+            std::cerr << '\\n';\n+\n         std::cerr << \"Received exception from server (version \" << server_version << \"):\" << std::endl\n             << \"Code: \" << e.code() << \". \" << text << std::endl;\n     }\ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex 0bfd4530c124..25f6497f9a1f 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -310,7 +310,7 @@ struct Settings : public SettingsCollection<Settings>\n     M(SettingUInt64, max_execution_speed, 0, \"Maximum number of execution rows per second.\", 0) \\\n     M(SettingUInt64, min_execution_speed_bytes, 0, \"Minimum number of execution bytes per second.\", 0) \\\n     M(SettingUInt64, max_execution_speed_bytes, 0, \"Maximum number of execution bytes per second.\", 0) \\\n-    M(SettingSeconds, timeout_before_checking_execution_speed, 0, \"Check that the speed is not too low after the specified time has elapsed.\", 0) \\\n+    M(SettingSeconds, timeout_before_checking_execution_speed, 10, \"Check that the speed is not too low after the specified time has elapsed.\", 0) \\\n     \\\n     M(SettingUInt64, max_columns_to_read, 0, \"\", 0) \\\n     M(SettingUInt64, max_temporary_columns, 0, \"\", 0) \\\ndiff --git a/src/DataStreams/ExecutionSpeedLimits.cpp b/src/DataStreams/ExecutionSpeedLimits.cpp\nindex 28a8cd949946..6cc1b9006bf7 100644\n--- a/src/DataStreams/ExecutionSpeedLimits.cpp\n+++ b/src/DataStreams/ExecutionSpeedLimits.cpp\n@@ -30,7 +30,8 @@ static void limitProgressingSpeed(size_t total_progress_size, size_t max_speed_i\n     {\n         UInt64 sleep_microseconds = desired_microseconds - total_elapsed_microseconds;\n \n-        /// Never sleep more than one second (it should be enough to limit speed for a reasonable amount, and otherwise it's too easy to make query hang).\n+        /// Never sleep more than one second (it should be enough to limit speed for a reasonable amount,\n+        /// and otherwise it's too easy to make query hang).\n         sleep_microseconds = std::min(UInt64(1000000), sleep_microseconds);\n \n         sleepForMicroseconds(sleep_microseconds);\n@@ -45,14 +46,14 @@ void ExecutionSpeedLimits::throttle(\n {\n     if ((min_execution_rps != 0 || max_execution_rps != 0\n          || min_execution_bps != 0 || max_execution_bps != 0\n-         || (total_rows_to_read != 0 && timeout_before_checking_execution_speed != 0)) &&\n-        (static_cast<Int64>(total_elapsed_microseconds) > timeout_before_checking_execution_speed.totalMicroseconds()))\n+         || (total_rows_to_read != 0 && timeout_before_checking_execution_speed != 0))\n+        && (static_cast<Int64>(total_elapsed_microseconds) > timeout_before_checking_execution_speed.totalMicroseconds()))\n     {\n         /// Do not count sleeps in throttlers\n         UInt64 throttler_sleep_microseconds = CurrentThread::getProfileEvents()[ProfileEvents::ThrottlerSleepMicroseconds];\n \n         double elapsed_seconds = 0;\n-        if (throttler_sleep_microseconds > total_elapsed_microseconds)\n+        if (total_elapsed_microseconds > throttler_sleep_microseconds)\n             elapsed_seconds = static_cast<double>(total_elapsed_microseconds - throttler_sleep_microseconds) / 1000000.0;\n \n         if (elapsed_seconds > 0)\ndiff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp\nindex 4f717eda706c..5fa1bfcdc6a1 100644\n--- a/src/Interpreters/InterpreterSelectQuery.cpp\n+++ b/src/Interpreters/InterpreterSelectQuery.cpp\n@@ -1498,16 +1498,19 @@ void InterpreterSelectQuery::executeFetchColumns(\n               * But limits on data size to read and maximum execution time are reasonable to check both on initiator and\n               *  additionally on each remote server, because these limits are checked per block of data processed,\n               *  and remote servers may process way more blocks of data than are received by initiator.\n+              *\n+              * The limits to throttle maximum execution speed is also checked on all servers.\n               */\n             if (options.to_stage == QueryProcessingStage::Complete)\n             {\n                 limits.speed_limits.min_execution_rps = settings.min_execution_speed;\n-                limits.speed_limits.max_execution_rps = settings.max_execution_speed;\n                 limits.speed_limits.min_execution_bps = settings.min_execution_speed_bytes;\n-                limits.speed_limits.max_execution_bps = settings.max_execution_speed_bytes;\n-                limits.speed_limits.timeout_before_checking_execution_speed = settings.timeout_before_checking_execution_speed;\n             }\n \n+            limits.speed_limits.max_execution_rps = settings.max_execution_speed;\n+            limits.speed_limits.max_execution_bps = settings.max_execution_speed_bytes;\n+            limits.speed_limits.timeout_before_checking_execution_speed = settings.timeout_before_checking_execution_speed;\n+\n             auto quota = context->getQuota();\n \n             for (auto & stream : streams)\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01287_max_execution_speed.reference b/tests/queries/0_stateless/01287_max_execution_speed.reference\nnew file mode 100644\nindex 000000000000..2e85f1f53355\n--- /dev/null\n+++ b/tests/queries/0_stateless/01287_max_execution_speed.reference\n@@ -0,0 +1,8 @@\n+Ok (1)\n+Ok (2)\n+2000000\n+1\n+Ok (3)\n+2000000\n+1\n+Ok (4)\ndiff --git a/tests/queries/0_stateless/01287_max_execution_speed.sql b/tests/queries/0_stateless/01287_max_execution_speed.sql\nnew file mode 100644\nindex 000000000000..7e8f6681c84f\n--- /dev/null\n+++ b/tests/queries/0_stateless/01287_max_execution_speed.sql\n@@ -0,0 +1,44 @@\n+SET min_execution_speed = 100000000000, timeout_before_checking_execution_speed = 0.1;\n+SELECT count() FROM system.numbers; -- { serverError 160 }\n+SELECT 'Ok (1)';\n+SET min_execution_speed = 0;\n+\n+SET min_execution_speed_bytes = 800000000000, timeout_before_checking_execution_speed = 0.1;\n+SELECT count() FROM system.numbers; -- { serverError 160 }\n+SELECT 'Ok (2)';\n+SET min_execution_speed_bytes = 0;\n+\n+SET max_execution_speed = 1000000;\n+SET max_block_size = 100;\n+\n+CREATE TEMPORARY TABLE times (t DateTime);\n+\n+INSERT INTO times SELECT now();\n+SELECT count() FROM numbers(2000000);\n+INSERT INTO times SELECT now();\n+\n+SELECT max(t) - min(t) >= 1 FROM times;\n+SELECT 'Ok (3)';\n+SET max_execution_speed = 0;\n+\n+SET max_execution_speed_bytes = 8000000;\n+TRUNCATE TABLE times;\n+\n+INSERT INTO times SELECT now();\n+SELECT count() FROM numbers(2000000);\n+INSERT INTO times SELECT now();\n+\n+SELECT max(t) - min(t) >= 1 FROM times;\n+SELECT 'Ok (4)';\n+SET max_execution_speed_bytes = 0;\n+\n+-- Note that 'min_execution_speed' does not count sleeping due to throttling\n+-- with 'max_execution_speed' and similar limits like 'priority' and 'max_network_bandwidth'\n+\n+-- Note: I have to disable this part of the test because it actually can work slower under sanitizers,\n+-- with debug builds and in presense of random system hickups in our CI environment.\n+\n+--SET max_execution_speed = 1000000, min_execution_speed = 2000000;\n+-- And this query will work despite the fact that the above settings look contradictory.\n+--SELECT count() FROM numbers(1000000);\n+--SELECT 'Ok (5)';\ndiff --git a/tests/queries/0_stateless/01288_shard_max_network_bandwidth.reference b/tests/queries/0_stateless/01288_shard_max_network_bandwidth.reference\nnew file mode 100644\nindex 000000000000..0d66ea1aee95\n--- /dev/null\n+++ b/tests/queries/0_stateless/01288_shard_max_network_bandwidth.reference\n@@ -0,0 +1,2 @@\n+0\n+1\ndiff --git a/tests/queries/0_stateless/01288_shard_max_network_bandwidth.sql b/tests/queries/0_stateless/01288_shard_max_network_bandwidth.sql\nnew file mode 100644\nindex 000000000000..09c043784bbb\n--- /dev/null\n+++ b/tests/queries/0_stateless/01288_shard_max_network_bandwidth.sql\n@@ -0,0 +1,15 @@\n+-- Limit to 10 MB/sec\n+SET max_network_bandwidth = 10000000;\n+\n+-- Lower max_block_size, so we can start throttling sooner. Otherwise query will be executed too quickly.\n+SET max_block_size = 100;\n+\n+CREATE TEMPORARY TABLE times (t DateTime);\n+\n+-- rand64 is uncompressable data. Each number will take 8 bytes of bandwidth.\n+-- This query should execute in no less than 1.6 seconds if throttled.\n+INSERT INTO times SELECT now();\n+SELECT sum(ignore(*)) FROM (SELECT rand64() FROM remote('127.0.0.{2,3}', numbers(2000000)));\n+INSERT INTO times SELECT now();\n+\n+SELECT max(t) - min(t) >= 1 FROM times;\ndiff --git a/tests/queries/0_stateless/01289_min_execution_speed_not_too_early.reference b/tests/queries/0_stateless/01289_min_execution_speed_not_too_early.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/01289_min_execution_speed_not_too_early.sql b/tests/queries/0_stateless/01289_min_execution_speed_not_too_early.sql\nnew file mode 100644\nindex 000000000000..e3a18d0c5157\n--- /dev/null\n+++ b/tests/queries/0_stateless/01289_min_execution_speed_not_too_early.sql\n@@ -0,0 +1,19 @@\n+DROP TABLE IF EXISTS ES;\n+\n+create table ES(A String) Engine=MergeTree order by tuple();\n+insert into ES select toString(number) from numbers(10000000);\n+\n+SET max_execution_time = 100, max_execution_speed = 1000000;\n+SET max_threads = 1;\n+SET max_block_size = 1000000;\n+\n+-- Exception about execution speed is not thrown from these queries.\n+SELECT * FROM ES LIMIT 1 format Null;\n+SELECT * FROM ES LIMIT 10 format Null;\n+SELECT * FROM ES LIMIT 100 format Null;\n+SELECT * FROM ES LIMIT 1000 format Null;\n+SELECT * FROM ES LIMIT 10000 format Null;\n+SELECT * FROM ES LIMIT 100000 format Null;\n+SELECT * FROM ES LIMIT 1000000 format Null;\n+\n+DROP TABLE ES;\ndiff --git a/tests/queries/0_stateless/01290_max_execution_speed_distributed.reference b/tests/queries/0_stateless/01290_max_execution_speed_distributed.reference\nnew file mode 100644\nindex 000000000000..ad0e80d8e690\n--- /dev/null\n+++ b/tests/queries/0_stateless/01290_max_execution_speed_distributed.reference\n@@ -0,0 +1,3 @@\n+2000000\n+1\n+1\ndiff --git a/tests/queries/0_stateless/01290_max_execution_speed_distributed.sql b/tests/queries/0_stateless/01290_max_execution_speed_distributed.sql\nnew file mode 100644\nindex 000000000000..8282390ca90b\n--- /dev/null\n+++ b/tests/queries/0_stateless/01290_max_execution_speed_distributed.sql\n@@ -0,0 +1,13 @@\n+SET max_execution_speed = 1000000, timeout_before_checking_execution_speed = 0.001, max_block_size = 100;\n+\n+CREATE TEMPORARY TABLE times (t DateTime);\n+\n+INSERT INTO times SELECT now();\n+SELECT count('special query for 01290_max_execution_speed_distributed') FROM remote('127.0.0.{2,3}', numbers(1000000));\n+INSERT INTO times SELECT now();\n+\n+SELECT max(t) - min(t) >= 1 FROM times;\n+\n+-- Check that the query was also throttled on \"remote\" servers.\n+SYSTEM FLUSH LOGS;\n+SELECT DISTINCT query_duration_ms >= 500 FROM system.query_log WHERE event_date >= yesterday() AND query LIKE '%special query for 01290_max_execution_speed_distributed%' AND type = 2;\ndiff --git a/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.reference b/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.reference\nnew file mode 100644\nindex 000000000000..53bb58224b96\n--- /dev/null\n+++ b/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.reference\n@@ -0,0 +1,4 @@\n+4392010\n+1\n+4392010\n+1\ndiff --git a/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql b/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql\nnew file mode 100644\nindex 000000000000..37e91296f14c\n--- /dev/null\n+++ b/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql\n@@ -0,0 +1,16 @@\n+SET max_execution_speed = 4000000, timeout_before_checking_execution_speed = 0.001;\n+\n+CREATE TEMPORARY TABLE times (t DateTime);\n+\n+INSERT INTO times SELECT now();\n+SELECT count() FROM test.hits SAMPLE 1 / 2;\n+INSERT INTO times SELECT now();\n+\n+SELECT max(t) - min(t) >= 1 FROM times;\n+TRUNCATE TABLE times;\n+\n+INSERT INTO times SELECT now();\n+SELECT count() FROM merge(test, '^hits$') SAMPLE 1 / 2;\n+INSERT INTO times SELECT now();\n+\n+SELECT max(t) - min(t) >= 1 FROM times;\n",
  "problem_statement": "max_execution_speed setting does not work if SAMPLE is used\nCC @zhang2014 \r\n\r\n```\r\nexample.yandex.ru :) SET max_execution_speed = 1000000\r\n\r\nSET max_execution_speed = 1000000\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.001 sec. \r\n\r\nexample.yandex.ru :) SELECT ...\r\n\r\n1 rows in set. Elapsed: 10.360 sec. Processed 318.26 million rows, 57.65 GB (30.72 million rows/s., 5.56 GB/s.)\r\n```\nThe setting max_execution_speed does not work at all.\n**Describe the bug**\r\n\r\n```\r\nSET max_execution_speed = 1000000;\r\nSELECT count() FROM system.numbers;\r\n```\nmax_execution_speed doesn't seem to work as expected\n#4430 introduced two new settings:\r\n* max_execution_speed \r\n* max_execution_speed_bytes\r\n\r\nBoth of which should be very useful in a multi tenant environment, especially as a poor's man non-conserving query prioritization.\r\n\r\nWhen progressImpl is called it checks current execution speed and if it higher than set in settings it sleeps, thus introducing back-pressure to executing threads. (?)\r\n\r\nIt doesn't seem to work when running aggregations (`SELECT count()...`) over a cluster (a distributed table). These limits are checked only on the executor node on a progress packet arrival, even though the thread that checked the limit sleeps, the back-pressure is not propagated to leaf nodes as these have no data to push to executor until the whole query is finished.\r\n\r\ncc @zhang2014\n",
  "hints_text": "Though it works perfectly for system.numbers.\r\nBut I have complex Merge table of MergeTree tables.\nIt doesn't work if SAMPLE is specified.\nThere is no upper bound on sleep time. I think it should be no more than one second.\r\nOtherwise it's too easy to hang a query with `SET max_execution_speed = 1`.\r\n\r\n\nOn first look this almost the same as #5732, speed is throttled only for queries that read QueryProcessingStage::Complete.\r\n\r\nI have a branch somewhere which defines new setting `leaf_max ...`. However I'd propose to change the meaning of current settings and apply them always.\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/2133492598d46650937c706f90204d7ef57dc9b2/dbms/src/Interpreters/InterpreterSelectQuery.cpp#L1781-L1788\r\n\r\nAnother idiosyncrasy is that behaviour also changes when distributed_group_by_no_merge is set, \ud83e\udd26\u200d\u2642 .\n\nI see the ClickHouse team has a similar plan.  Maybe we can look forward to that:\r\nhttps://github.com/yandex/clickhouse-presentations/blob/master/percona2019/index.html#L567\r\nhttps://gist.github.com/alexey-milovidov/d62d73222d83b9319dc519cbb13aeff6\r\n\r\ncc @alexey-milovidov \r\n\r\nBTW: max_execution_speed and max_execution_speed_bytes are commonly used in our scenario to limit migration task of `insert...select...` \r\n",
  "created_at": "2020-05-29T18:27:19Z"
}