{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 44173,
  "instance_id": "ClickHouse__ClickHouse-44173",
  "issue_numbers": [
    "44054"
  ],
  "base_commit": "ad91cb3eb14b86a52e92018ce1e6b4be607b20d1",
  "patch": "diff --git a/src/Storages/MergeTree/DataPartsExchange.cpp b/src/Storages/MergeTree/DataPartsExchange.cpp\nindex 4f9c9ffd5961..66f91aa6cd2f 100644\n--- a/src/Storages/MergeTree/DataPartsExchange.cpp\n+++ b/src/Storages/MergeTree/DataPartsExchange.cpp\n@@ -794,8 +794,6 @@ void Fetcher::downloadBasePartOrProjectionPartToDiskRemoteMeta(\n                 /// NOTE The is_cancelled flag also makes sense to check every time you read over the network,\n                 /// performing a poll with a not very large timeout.\n                 /// And now we check it only between read chunks (in the `copyData` function).\n-                data_part_storage->removeSharedRecursive(true);\n-                data_part_storage->commitTransaction();\n                 throw Exception(\"Fetching of part was cancelled\", ErrorCodes::ABORTED);\n             }\n \n@@ -855,7 +853,6 @@ void Fetcher::downloadBaseOrProjectionPartToDisk(\n             /// NOTE The is_cancelled flag also makes sense to check every time you read over the network,\n             /// performing a poll with a not very large timeout.\n             /// And now we check it only between read chunks (in the `copyData` function).\n-            data_part_storage->removeRecursive();\n             throw Exception(\"Fetching of part was cancelled\", ErrorCodes::ABORTED);\n         }\n \n@@ -934,22 +931,36 @@ MergeTreeData::MutableDataPartPtr Fetcher::downloadPartToDisk(\n \n     CurrentMetrics::Increment metric_increment{CurrentMetrics::ReplicatedFetch};\n \n-    for (size_t i = 0; i < projections; ++i)\n+    try\n     {\n-        String projection_name;\n-        readStringBinary(projection_name, in);\n-        MergeTreeData::DataPart::Checksums projection_checksum;\n+        for (size_t i = 0; i < projections; ++i)\n+        {\n+            String projection_name;\n+            readStringBinary(projection_name, in);\n+            MergeTreeData::DataPart::Checksums projection_checksum;\n+\n+            auto projection_part_storage = data_part_storage->getProjection(projection_name + \".proj\");\n+            projection_part_storage->createDirectories();\n+            downloadBaseOrProjectionPartToDisk(\n+                replica_path, projection_part_storage, sync, in, projection_checksum, throttler);\n+            checksums.addFile(\n+                projection_name + \".proj\", projection_checksum.getTotalSizeOnDisk(), projection_checksum.getTotalChecksumUInt128());\n+        }\n \n-        auto projection_part_storage = data_part_storage->getProjection(projection_name + \".proj\");\n-        projection_part_storage->createDirectories();\n-        downloadBaseOrProjectionPartToDisk(\n-            replica_path, projection_part_storage, sync, in, projection_checksum, throttler);\n-        checksums.addFile(\n-            projection_name + \".proj\", projection_checksum.getTotalSizeOnDisk(), projection_checksum.getTotalChecksumUInt128());\n+        // Download the base part\n+        downloadBaseOrProjectionPartToDisk(replica_path, data_part_storage, sync, in, checksums, throttler);\n+    }\n+    catch (const Exception & e)\n+    {\n+        /// Remove the whole part directory if fetch of base\n+        /// part or fetch of any projection was stopped.\n+        if (e.code() == ErrorCodes::ABORTED)\n+        {\n+            data_part_storage->removeRecursive();\n+            data_part_storage->commitTransaction();\n+        }\n+        throw;\n     }\n-\n-    // Download the base part\n-    downloadBaseOrProjectionPartToDisk(replica_path, data_part_storage, sync, in, checksums, throttler);\n \n     assertEOF(in);\n     data_part_storage->commitTransaction();\n@@ -1007,23 +1018,37 @@ MergeTreeData::MutableDataPartPtr Fetcher::downloadPartToDiskRemoteMeta(\n \n     data_part_storage->createDirectories();\n \n-    for (size_t i = 0; i < projections; ++i)\n+    try\n     {\n-        String projection_name;\n-        readStringBinary(projection_name, in);\n-        MergeTreeData::DataPart::Checksums projection_checksum;\n+        for (size_t i = 0; i < projections; ++i)\n+        {\n+            String projection_name;\n+            readStringBinary(projection_name, in);\n+            MergeTreeData::DataPart::Checksums projection_checksum;\n \n-        auto projection_part_storage = data_part_storage->getProjection(projection_name + \".proj\");\n-        projection_part_storage->createDirectories();\n-        downloadBasePartOrProjectionPartToDiskRemoteMeta(\n-            replica_path, projection_part_storage, in, projection_checksum, throttler);\n+            auto projection_part_storage = data_part_storage->getProjection(projection_name + \".proj\");\n+            projection_part_storage->createDirectories();\n+            downloadBasePartOrProjectionPartToDiskRemoteMeta(\n+                replica_path, projection_part_storage, in, projection_checksum, throttler);\n \n-        checksums.addFile(\n-            projection_name + \".proj\", projection_checksum.getTotalSizeOnDisk(), projection_checksum.getTotalChecksumUInt128());\n-    }\n+            checksums.addFile(\n+                projection_name + \".proj\", projection_checksum.getTotalSizeOnDisk(), projection_checksum.getTotalChecksumUInt128());\n+        }\n \n-    downloadBasePartOrProjectionPartToDiskRemoteMeta(\n-        replica_path, data_part_storage, in, checksums, throttler);\n+        downloadBasePartOrProjectionPartToDiskRemoteMeta(\n+            replica_path, data_part_storage, in, checksums, throttler);\n+    }\n+    catch (const Exception & e)\n+    {\n+        if (e.code() == ErrorCodes::ABORTED)\n+        {\n+            /// Remove the whole part directory if fetch of base\n+            /// part or fetch of any projection was stopped.\n+            data_part_storage->removeSharedRecursive(true);\n+            data_part_storage->commitTransaction();\n+        }\n+        throw;\n+    }\n \n     assertEOF(in);\n     MergeTreeData::MutableDataPartPtr new_data_part;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02344_describe_cache.sql b/tests/queries/0_stateless/02344_describe_cache.sql\nindex 8b3831bcaa83..fef004cb27f1 100644\n--- a/tests/queries/0_stateless/02344_describe_cache.sql\n+++ b/tests/queries/0_stateless/02344_describe_cache.sql\n@@ -1,4 +1,7 @@\n--- Tags: no-fasttest\n+-- Tags: no-fasttest, no-parallel\n+\n+SYSTEM DROP FILESYSTEM CACHE 's3_cache/';\n+SYSTEM DROP FILESYSTEM CACHE 's3_cache_2/';\n \n DESCRIBE FILESYSTEM CACHE 's3_cache';\n DESCRIBE FILESYSTEM CACHE 's3_cache_2';\ndiff --git a/tests/queries/0_stateless/02494_zero_copy_projection_cancel_fetch.reference b/tests/queries/0_stateless/02494_zero_copy_projection_cancel_fetch.reference\nnew file mode 100644\nindex 000000000000..5878ba472255\n--- /dev/null\n+++ b/tests/queries/0_stateless/02494_zero_copy_projection_cancel_fetch.reference\n@@ -0,0 +1,2 @@\n+1000\n+1000\ndiff --git a/tests/queries/0_stateless/02494_zero_copy_projection_cancel_fetch.sh b/tests/queries/0_stateless/02494_zero_copy_projection_cancel_fetch.sh\nnew file mode 100755\nindex 000000000000..b72c3eb56c72\n--- /dev/null\n+++ b/tests/queries/0_stateless/02494_zero_copy_projection_cancel_fetch.sh\n@@ -0,0 +1,66 @@\n+#!/usr/bin/env bash\n+# Tags: no-fasttest\n+\n+CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CUR_DIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT -n --query \"\n+DROP TABLE IF EXISTS wikistat1 SYNC;\n+DROP TABLE IF EXISTS wikistat2 SYNC;\n+\"\n+\n+for i in {1..2}; do\n+    $CLICKHOUSE_CLIENT --query \"\n+    CREATE TABLE wikistat$i\n+    (\n+        time DateTime,\n+        project LowCardinality(String),\n+        subproject LowCardinality(String),\n+        path String,\n+        hits UInt64,\n+        PROJECTION total\n+        (\n+            SELECT\n+                project,\n+                subproject,\n+                path,\n+                sum(hits),\n+                count()\n+            GROUP BY\n+                project,\n+                subproject,\n+                path\n+        )\n+    )\n+    ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/02494_zero_copy_projection_cancel_fetch', '$i')\n+    ORDER BY (path, time)\n+    SETTINGS min_bytes_for_wide_part = 0, storage_policy = 's3_cache',\n+    allow_remote_fs_zero_copy_replication = 1,\n+    max_replicated_fetches_network_bandwidth = 100\n+    \"\n+done\n+\n+$CLICKHOUSE_CLIENT --query \"SYSTEM STOP FETCHES wikistat2\"\n+$CLICKHOUSE_CLIENT --query \"INSERT INTO wikistat1 SELECT toDateTime('2020-10-01 00:00:00'), 'hello', 'world', '/data/path', 10 from numbers(1000)\"\n+\n+$CLICKHOUSE_CLIENT --query \"SYSTEM START FETCHES wikistat2\"\n+$CLICKHOUSE_CLIENT --query \"SYSTEM SYNC REPLICA wikistat2\" &\n+\n+# With previous versions LOGICAL_ERROR will be thrown\n+# and server will be crashed in debug mode.\n+sleep 1.5\n+$CLICKHOUSE_CLIENT --query \"SYSTEM STOP FETCHES wikistat2\"\n+sleep 1.5\n+\n+$CLICKHOUSE_CLIENT --query \"ALTER TABLE wikistat2 MODIFY SETTING max_replicated_fetches_network_bandwidth = 0\"\n+$CLICKHOUSE_CLIENT --query \"SYSTEM START FETCHES wikistat2\"\n+wait\n+\n+$CLICKHOUSE_CLIENT --query \"SELECT count() FROM wikistat1 WHERE NOT ignore(*)\"\n+$CLICKHOUSE_CLIENT --query \"SELECT count() FROM wikistat2 WHERE NOT ignore(*)\"\n+\n+$CLICKHOUSE_CLIENT -n --query \"\n+DROP TABLE IF EXISTS wikistat1 SYNC;\n+DROP TABLE IF EXISTS wikistat2 SYNC;\n+\"\n",
  "problem_statement": "Logical error: 'Cannot commit shared transaction'\nhttps://s3.amazonaws.com/clickhouse-test-reports/43986/7249ad407a0824d8c7651d8e03d4e68e1dea0813/stress_test__msan_.html\n",
  "hints_text": "https://s3.amazonaws.com/clickhouse-test-reports/43999/048aecf54008bed51fd2abe24c387e2306235db4/stress_test__msan_.html",
  "created_at": "2022-12-12T17:32:15Z"
}