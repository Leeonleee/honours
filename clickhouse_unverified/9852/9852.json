{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 9852,
  "instance_id": "ClickHouse__ClickHouse-9852",
  "issue_numbers": [
    "9447"
  ],
  "base_commit": "25f08e83c7de5dffffc2e2cdef878df29e30ee46",
  "patch": "diff --git a/dbms/src/DataStreams/RemoteBlockOutputStream.cpp b/dbms/src/DataStreams/RemoteBlockOutputStream.cpp\nindex 400ed42fdcbd..5200500cd002 100644\n--- a/dbms/src/DataStreams/RemoteBlockOutputStream.cpp\n+++ b/dbms/src/DataStreams/RemoteBlockOutputStream.cpp\n@@ -21,13 +21,14 @@ namespace ErrorCodes\n RemoteBlockOutputStream::RemoteBlockOutputStream(Connection & connection_,\n                                                  const ConnectionTimeouts & timeouts,\n                                                  const String & query_,\n-                                                 const Settings * settings_)\n-    : connection(connection_), query(query_), settings(settings_)\n+                                                 const Settings * settings_,\n+                                                 const ClientInfo * client_info_)\n+    : connection(connection_), query(query_), settings(settings_), client_info(client_info_)\n {\n     /** Send query and receive \"header\", that describe table structure.\n       * Header is needed to know, what structure is required for blocks to be passed to 'write' method.\n       */\n-    connection.sendQuery(timeouts, query, \"\", QueryProcessingStage::Complete, settings, nullptr);\n+    connection.sendQuery(timeouts, query, \"\", QueryProcessingStage::Complete, settings, client_info);\n \n     while (true)\n     {\ndiff --git a/dbms/src/DataStreams/RemoteBlockOutputStream.h b/dbms/src/DataStreams/RemoteBlockOutputStream.h\nindex 8887277c657a..f7f1ab468065 100644\n--- a/dbms/src/DataStreams/RemoteBlockOutputStream.h\n+++ b/dbms/src/DataStreams/RemoteBlockOutputStream.h\n@@ -22,7 +22,8 @@ class RemoteBlockOutputStream : public IBlockOutputStream\n     RemoteBlockOutputStream(Connection & connection_,\n                             const ConnectionTimeouts & timeouts,\n                             const String & query_,\n-                            const Settings * settings_ = nullptr);\n+                            const Settings * settings_ = nullptr,\n+                            const ClientInfo * client_info_ = nullptr);\n \n     Block getHeader() const override { return header; }\n \n@@ -38,6 +39,7 @@ class RemoteBlockOutputStream : public IBlockOutputStream\n     Connection & connection;\n     String query;\n     const Settings * settings;\n+    const ClientInfo * client_info;\n     Block header;\n     bool finished = false;\n };\ndiff --git a/dbms/src/Storages/Distributed/DirectoryMonitor.cpp b/dbms/src/Storages/Distributed/DirectoryMonitor.cpp\nindex 098a06e43fc5..01bf0798a638 100644\n--- a/dbms/src/Storages/Distributed/DirectoryMonitor.cpp\n+++ b/dbms/src/Storages/Distributed/DirectoryMonitor.cpp\n@@ -279,9 +279,10 @@ void StorageDistributedDirectoryMonitor::processFile(const std::string & file_pa\n \n         Settings insert_settings;\n         std::string insert_query;\n-        readHeader(in, insert_settings, insert_query, log);\n+        ClientInfo client_info;\n+        readHeader(in, insert_settings, insert_query, client_info, log);\n \n-        RemoteBlockOutputStream remote{*connection, timeouts, insert_query, &insert_settings};\n+        RemoteBlockOutputStream remote{*connection, timeouts, insert_query, &insert_settings, &client_info};\n \n         remote.writePrefix();\n         remote.writePrepared(in);\n@@ -299,7 +300,7 @@ void StorageDistributedDirectoryMonitor::processFile(const std::string & file_pa\n }\n \n void StorageDistributedDirectoryMonitor::readHeader(\n-    ReadBuffer & in, Settings & insert_settings, std::string & insert_query, Logger * log)\n+    ReadBuffer & in, Settings & insert_settings, std::string & insert_query, ClientInfo & client_info, Logger * log)\n {\n     UInt64 query_size;\n     readVarUInt(query_size, in);\n@@ -331,8 +332,11 @@ void StorageDistributedDirectoryMonitor::readHeader(\n         readStringBinary(insert_query, header_buf);\n         insert_settings.deserialize(header_buf);\n \n+        if (header_buf.hasPendingData())\n+            client_info.read(header_buf, initiator_revision);\n+\n         /// Add handling new data here, for example:\n-        /// if (initiator_revision >= DBMS_MIN_REVISION_WITH_MY_NEW_DATA)\n+        /// if (header_buf.hasPendingData())\n         ///    readVarUInt(my_new_data, header_buf);\n \n         return;\n@@ -353,19 +357,21 @@ struct StorageDistributedDirectoryMonitor::BatchHeader\n {\n     Settings settings;\n     String query;\n+    ClientInfo client_info;\n     Block sample_block;\n \n-    BatchHeader(Settings settings_, String query_, Block sample_block_)\n+    BatchHeader(Settings settings_, String query_, ClientInfo client_info_, Block sample_block_)\n         : settings(std::move(settings_))\n         , query(std::move(query_))\n+        , client_info(std::move(client_info_))\n         , sample_block(std::move(sample_block_))\n     {\n     }\n \n     bool operator==(const BatchHeader & other) const\n     {\n-        return settings == other.settings && query == other.query &&\n-               blocksHaveEqualStructure(sample_block, other.sample_block);\n+        return settings == other.settings && query == other.query && client_info.query_kind == other.client_info.query_kind\n+            && blocksHaveEqualStructure(sample_block, other.sample_block);\n     }\n \n     struct Hash\n@@ -445,6 +451,7 @@ struct StorageDistributedDirectoryMonitor::Batch\n         {\n             Settings insert_settings;\n             String insert_query;\n+            ClientInfo client_info;\n             std::unique_ptr<RemoteBlockOutputStream> remote;\n             bool first = true;\n \n@@ -459,12 +466,12 @@ struct StorageDistributedDirectoryMonitor::Batch\n                 }\n \n                 ReadBufferFromFile in(file_path->second);\n-                parent.readHeader(in, insert_settings, insert_query, parent.log);\n+                parent.readHeader(in, insert_settings, insert_query, client_info, parent.log);\n \n                 if (first)\n                 {\n                     first = false;\n-                    remote = std::make_unique<RemoteBlockOutputStream>(*connection, timeouts, insert_query, &insert_settings);\n+                    remote = std::make_unique<RemoteBlockOutputStream>(*connection, timeouts, insert_query, &insert_settings, &client_info);\n                     remote->writePrefix();\n                 }\n \n@@ -541,7 +548,8 @@ class DirectoryMonitorBlockInputStream : public IBlockInputStream\n     {\n         Settings insert_settings;\n         String insert_query;\n-        StorageDistributedDirectoryMonitor::readHeader(in, insert_settings, insert_query, log);\n+        ClientInfo client_info;\n+        StorageDistributedDirectoryMonitor::readHeader(in, insert_settings, insert_query, client_info, log);\n \n         block_in.readPrefix();\n         first_block = block_in.read();\n@@ -610,11 +618,12 @@ void StorageDistributedDirectoryMonitor::processFilesWithBatching(const std::map\n         Block sample_block;\n         Settings insert_settings;\n         String insert_query;\n+        ClientInfo client_info;\n         try\n         {\n             /// Determine metadata of the current file and check if it is not broken.\n             ReadBufferFromFile in{file_path};\n-            readHeader(in, insert_settings, insert_query, log);\n+            readHeader(in, insert_settings, insert_query, client_info, log);\n \n             CompressedReadBuffer decompressing_in(in);\n             NativeBlockInputStream block_in(decompressing_in, ClickHouseRevision::get());\n@@ -641,7 +650,7 @@ void StorageDistributedDirectoryMonitor::processFilesWithBatching(const std::map\n                 throw;\n         }\n \n-        BatchHeader batch_header(std::move(insert_settings), std::move(insert_query), std::move(sample_block));\n+        BatchHeader batch_header(std::move(insert_settings), std::move(insert_query), std::move(client_info), std::move(sample_block));\n         Batch & batch = header_to_batch.try_emplace(batch_header, *this, files).first->second;\n \n         batch.file_indices.push_back(file_idx);\ndiff --git a/dbms/src/Storages/Distributed/DirectoryMonitor.h b/dbms/src/Storages/Distributed/DirectoryMonitor.h\nindex de7dcffa92e7..475a3bc7bc6c 100644\n--- a/dbms/src/Storages/Distributed/DirectoryMonitor.h\n+++ b/dbms/src/Storages/Distributed/DirectoryMonitor.h\n@@ -70,7 +70,7 @@ class StorageDistributedDirectoryMonitor\n     ThreadFromGlobalPool thread{&StorageDistributedDirectoryMonitor::run, this};\n \n     /// Read insert query and insert settings for backward compatible.\n-    static void readHeader(ReadBuffer & in, Settings & insert_settings, std::string & insert_query, Logger * log);\n+    static void readHeader(ReadBuffer & in, Settings & insert_settings, std::string & insert_query, ClientInfo & client_info, Logger * log);\n \n     friend class DirectoryMonitorBlockInputStream;\n };\ndiff --git a/dbms/src/Storages/Distributed/DistributedBlockOutputStream.cpp b/dbms/src/Storages/Distributed/DistributedBlockOutputStream.cpp\nindex 85fcb3c2766d..2aba27dfc67d 100644\n--- a/dbms/src/Storages/Distributed/DistributedBlockOutputStream.cpp\n+++ b/dbms/src/Storages/Distributed/DistributedBlockOutputStream.cpp\n@@ -290,7 +290,7 @@ ThreadPool::Job DistributedBlockOutputStream::runWritingJob(DistributedBlockOutp\n                 if (throttler)\n                     job.connection_entry->setThrottler(throttler);\n \n-                job.stream = std::make_shared<RemoteBlockOutputStream>(*job.connection_entry, timeouts, query_string, &settings);\n+                job.stream = std::make_shared<RemoteBlockOutputStream>(*job.connection_entry, timeouts, query_string, &settings, &context.getClientInfo());\n                 job.stream->writePrefix();\n             }\n \n@@ -598,6 +598,7 @@ void DistributedBlockOutputStream::writeToShard(const Block & block, const std::\n             writeVarUInt(ClickHouseRevision::get(), header_buf);\n             writeStringBinary(query_string, header_buf);\n             context.getSettingsRef().serialize(header_buf);\n+            context.getClientInfo().write(header_buf, ClickHouseRevision::get());\n \n             /// Add new fields here, for example:\n             /// writeVarUInt(my_new_data, header_buf);\n",
  "test_patch": "diff --git a/dbms/tests/integration/test_settings_constraints_distributed/configs/remote_servers.xml b/dbms/tests/integration/test_settings_constraints_distributed/configs/remote_servers.xml\nindex faa56e0b6dc4..2417ad81aec2 100644\n--- a/dbms/tests/integration/test_settings_constraints_distributed/configs/remote_servers.xml\n+++ b/dbms/tests/integration/test_settings_constraints_distributed/configs/remote_servers.xml\n@@ -5,14 +5,14 @@\n                 <replica>\n                     <host>node1</host>\n                     <port>9000</port>\n-                    <user>normal</user>\n+                    <user>shard</user>\n                 </replica>\n             </shard>\n             <shard>\n                 <replica>\n                     <host>node2</host>\n                     <port>9000</port>\n-                    <user>readonly</user>\n+                    <user>shard</user>\n                 </replica>\n             </shard>\n         </test_cluster>\ndiff --git a/dbms/tests/integration/test_settings_constraints_distributed/configs/users_on_cluster.xml b/dbms/tests/integration/test_settings_constraints_distributed/configs/users_on_cluster.xml\ndeleted file mode 100644\nindex 11ba40ac50de..000000000000\n--- a/dbms/tests/integration/test_settings_constraints_distributed/configs/users_on_cluster.xml\n+++ /dev/null\n@@ -1,33 +0,0 @@\n-<yandex>\n-    <profiles>\n-        <default>\n-        </default>\n-        <normal>\n-            <max_memory_usage>50000000</max_memory_usage>\n-            <constraints>\n-                <max_memory_usage>\n-                    <min>11111111</min>\n-                    <max>99999999</max>\n-                </max_memory_usage>\n-            </constraints>\n-        </normal>\n-        <readonly>\n-            <readonly>1</readonly>\n-        </readonly>\n-    </profiles>\n-\n-    <users>\n-        <default>\n-            <profile>default</profile>\n-            <password></password>\n-        </default>\n-        <normal>\n-            <profile>normal</profile>\n-            <password></password>\n-        </normal>\n-        <readonly>\n-            <profile>readonly</profile>\n-            <password></password>\n-        </readonly>\n-    </users>\n-</yandex>\ndiff --git a/dbms/tests/integration/test_settings_constraints_distributed/configs/users_on_distributed.xml b/dbms/tests/integration/test_settings_constraints_distributed/configs/users_on_distributed.xml\ndeleted file mode 100644\nindex 371a6de26a3b..000000000000\n--- a/dbms/tests/integration/test_settings_constraints_distributed/configs/users_on_distributed.xml\n+++ /dev/null\n@@ -1,36 +0,0 @@\n-<yandex>\n-    <profiles>\n-        <default>\n-        </default>\n-        <normal>\n-            <max_memory_usage>80000000</max_memory_usage>\n-            <use_uncompressed_cache>0</use_uncompressed_cache>\n-            <load_balancing>random</load_balancing>\n-        </normal>\n-        <wasteful>\n-            <max_memory_usage>2000000000</max_memory_usage>\n-        </wasteful>\n-        <readonly>\n-            <readonly>1</readonly>\n-        </readonly>\n-    </profiles>\n-   \n-    <users>\n-        <default>\n-            <profile>default</profile>\n-            <password></password>\n-        </default>\n-        <normal>\n-            <profile>normal</profile>\n-            <password></password>\n-        </normal>\n-        <wasteful>\n-            <profile>wasteful</profile>\n-            <password></password>\n-        </wasteful>\n-        <readonly>\n-            <profile>readonly</profile>\n-            <password></password>\n-        </readonly>\n-    </users>\n-</yandex>\ndiff --git a/dbms/tests/integration/test_settings_constraints_distributed/test.py b/dbms/tests/integration/test_settings_constraints_distributed/test.py\nindex b9dfb7619cba..b23b130b2700 100644\n--- a/dbms/tests/integration/test_settings_constraints_distributed/test.py\n+++ b/dbms/tests/integration/test_settings_constraints_distributed/test.py\n@@ -8,10 +8,9 @@\n \n cluster = ClickHouseCluster(__file__)\n \n-node1 = cluster.add_instance('node1', user_configs=['configs/users_on_cluster.xml'])\n-node2 = cluster.add_instance('node2', user_configs=['configs/users_on_cluster.xml'])\n-\n-distributed = cluster.add_instance('distributed', main_configs=['configs/remote_servers.xml'], user_configs=['configs/users_on_distributed.xml'])\n+node1 = cluster.add_instance('node1')\n+node2 = cluster.add_instance('node2')\n+distributed = cluster.add_instance('distributed', main_configs=['configs/remote_servers.xml'])\n \n \n @pytest.fixture(scope=\"module\")\n@@ -20,11 +19,15 @@ def started_cluster():\n         cluster.start()\n \n         for node in [node1, node2]:\n-            node.query(\"CREATE TABLE sometable(date Date, id UInt32, value Int32) ENGINE = MergeTree() ORDER BY id;\")\n-            node.query(\"INSERT INTO sometable VALUES (toDate('2020-01-20'), 1, 1)\")\n+            node.query(\"CREATE TABLE sometable (date Date, id UInt32, value Int32) ENGINE = MergeTree() ORDER BY id;\")\n+            node.query(\"INSERT INTO sometable VALUES (toDate('2010-01-10'), 1, 1)\")\n+            node.query(\"CREATE USER shard\")\n+            node.query(\"GRANT ALL ON *.* TO shard\")\n \n-        distributed.query(\"CREATE TABLE proxy (date Date, id UInt32, value Int32) ENGINE = Distributed(test_cluster, default, sometable);\")\n-        distributed.query(\"CREATE TABLE sysproxy (name String, value String) ENGINE = Distributed(test_cluster, system, settings);\")\n+        distributed.query(\"CREATE TABLE proxy (date Date, id UInt32, value Int32) ENGINE = Distributed(test_cluster, default, sometable, toUInt64(date));\")\n+        distributed.query(\"CREATE TABLE shard_settings (name String, value String) ENGINE = Distributed(test_cluster, system, settings);\")\n+        distributed.query(\"CREATE ROLE admin\")\n+        distributed.query(\"GRANT ALL ON *.* TO admin\")\n \n         yield cluster\n \n@@ -32,7 +35,14 @@ def started_cluster():\n         cluster.shutdown()\n \n \n-def test_shard_doesnt_throw_on_constraint_violation(started_cluster):\n+def test_select_clamps_settings(started_cluster):\n+    distributed.query(\"CREATE USER normal DEFAULT ROLE admin SETTINGS max_memory_usage = 80000000\")\n+    distributed.query(\"CREATE USER wasteful DEFAULT ROLE admin SETTINGS max_memory_usage = 2000000000\")\n+    distributed.query(\"CREATE USER readonly DEFAULT ROLE admin SETTINGS readonly = 1\")\n+    node1.query(\"ALTER USER shard SETTINGS max_memory_usage = 50000000 MIN 11111111 MAX 99999999\")\n+    node2.query(\"ALTER USER shard SETTINGS readonly = 1\")\n+\n+    # Check that shards doesn't throw exceptions on constraints violation\n     query = \"SELECT COUNT() FROM proxy\"\n     assert distributed.query(query) == '2\\n'\n     assert distributed.query(query, user = 'normal') == '2\\n'\n@@ -47,9 +57,8 @@ def test_shard_doesnt_throw_on_constraint_violation(started_cluster):\n     assert distributed.query(query, user = 'normal') == '2\\n'\n     assert distributed.query(query, user = 'wasteful') == '2\\n'\n \n-\n-def test_shard_clamps_settings(started_cluster):\n-    query = \"SELECT hostName() as host, name, value FROM sysproxy WHERE name = 'max_memory_usage' OR name = 'readonly' ORDER BY host, name, value\"\n+    # Check that shards clamp passed settings.\n+    query = \"SELECT hostName() as host, name, value FROM shard_settings WHERE name = 'max_memory_usage' OR name = 'readonly' ORDER BY host, name, value\"\n     assert distributed.query(query) == 'node1\\tmax_memory_usage\\t99999999\\n'\\\n                                        'node1\\treadonly\\t0\\n'\\\n                                        'node2\\tmax_memory_usage\\t10000000000\\n'\\\n@@ -79,3 +88,11 @@ def test_shard_clamps_settings(started_cluster):\n                                                                                                  'node1\\treadonly\\t2\\n'\\\n                                                                                                  'node2\\tmax_memory_usage\\t10000000000\\n'\\\n                                                                                                  'node2\\treadonly\\t1\\n'\n+\n+def test_insert_clamps_settings(started_cluster):\n+    node1.query(\"ALTER USER shard SETTINGS max_memory_usage = 50000000 MIN 11111111 MAX 99999999\")\n+    node2.query(\"ALTER USER shard SETTINGS max_memory_usage = 50000000 MIN 11111111 MAX 99999999\")\n+\n+    distributed.query(\"INSERT INTO proxy VALUES (toDate('2020-02-20'), 2, 2)\")\n+    distributed.query(\"INSERT INTO proxy VALUES (toDate('2020-02-21'), 2, 2)\", settings={\"max_memory_usage\": 5000000})\n+    assert distributed.query(\"SELECT COUNT() FROM proxy\") == \"4\\n\"\n",
  "problem_statement": "Shard now clamps the settings from the initiator.\nI hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category:\r\n- Bug Fix\r\n\r\nChangelog entry:\r\nShard now clamps the settings got from the initiator to the shard's constaints instead of throwing an exception. This fix allows to send queries to a shard with another constraints.\n",
  "hints_text": "Integration tests are to be updated?",
  "created_at": "2020-03-25T07:20:51Z",
  "modified_files": [
    "dbms/src/DataStreams/RemoteBlockOutputStream.cpp",
    "dbms/src/DataStreams/RemoteBlockOutputStream.h",
    "dbms/src/Storages/Distributed/DirectoryMonitor.cpp",
    "dbms/src/Storages/Distributed/DirectoryMonitor.h",
    "dbms/src/Storages/Distributed/DistributedBlockOutputStream.cpp"
  ],
  "modified_test_files": [
    "dbms/tests/integration/test_settings_constraints_distributed/configs/remote_servers.xml",
    "dbms/tests/integration/test_settings_constraints_distributed/configs/users_on_cluster.xml",
    "dbms/tests/integration/test_settings_constraints_distributed/configs/users_on_distributed.xml",
    "dbms/tests/integration/test_settings_constraints_distributed/test.py"
  ]
}