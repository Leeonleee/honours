{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 72891,
  "instance_id": "ClickHouse__ClickHouse-72891",
  "issue_numbers": [
    "72868"
  ],
  "base_commit": "348b7393a5bbb1b3d7e9484eddb0534884f55603",
  "patch": "diff --git a/src/Core/Block.cpp b/src/Core/Block.cpp\nindex 02176a6b77a0..7d58c25a3723 100644\n--- a/src/Core/Block.cpp\n+++ b/src/Core/Block.cpp\n@@ -449,6 +449,14 @@ MutableColumns Block::cloneEmptyColumns() const\n     return columns;\n }\n \n+MutableColumns Block::cloneEmptyColumns(const Serializations & serializations) const\n+{\n+    size_t num_columns = data.size();\n+    MutableColumns columns(num_columns);\n+    for (size_t i = 0; i < num_columns; ++i)\n+        columns[i] = data[i].type->createColumn(*serializations[i]);\n+    return columns;\n+}\n \n Columns Block::getColumns() const\n {\ndiff --git a/src/Core/Block.h b/src/Core/Block.h\nindex 841fb3fb6639..a045e2acdf07 100644\n--- a/src/Core/Block.h\n+++ b/src/Core/Block.h\n@@ -141,6 +141,9 @@ class Block\n     /** Get empty columns with the same types as in block. */\n     MutableColumns cloneEmptyColumns() const;\n \n+    /** Get empty columns with the same types as in block and given serializations. */\n+    MutableColumns cloneEmptyColumns(const Serializations & serializations) const;\n+\n     /** Get columns from block for mutation. Columns in block will be nullptr. */\n     MutableColumns mutateColumns();\n \ndiff --git a/src/Processors/Formats/IRowInputFormat.cpp b/src/Processors/Formats/IRowInputFormat.cpp\nindex ea316f97521d..928be5d7c394 100644\n--- a/src/Processors/Formats/IRowInputFormat.cpp\n+++ b/src/Processors/Formats/IRowInputFormat.cpp\n@@ -104,12 +104,8 @@ Chunk IRowInputFormat::read()\n     }\n \n     const Block & header = getPort().getHeader();\n-\n     size_t num_columns = header.columns();\n-    MutableColumns columns(num_columns);\n-\n-    for (size_t i = 0; i < num_columns; ++i)\n-        columns[i] = header.getByPosition(i).type->createColumn(*serializations[i]);\n+    MutableColumns columns = header.cloneEmptyColumns(serializations);\n \n     ColumnCheckpoints checkpoints(columns.size());\n     for (size_t column_idx = 0; column_idx < columns.size(); ++column_idx)\ndiff --git a/src/Processors/Formats/RowInputFormatWithDiagnosticInfo.cpp b/src/Processors/Formats/RowInputFormatWithDiagnosticInfo.cpp\nindex c1dd77aecaf3..12e9b650acd2 100644\n--- a/src/Processors/Formats/RowInputFormatWithDiagnosticInfo.cpp\n+++ b/src/Processors/Formats/RowInputFormatWithDiagnosticInfo.cpp\n@@ -44,7 +44,7 @@ std::pair<String, String> RowInputFormatWithDiagnosticInfo::getDiagnosticAndRawD\n             \"Buffer has gone, cannot extract information about what has been parsed.\");\n \n     const auto & header = getPort().getHeader();\n-    MutableColumns columns = header.cloneEmptyColumns();\n+    MutableColumns columns = header.cloneEmptyColumns(serializations);\n \n     /// It is possible to display detailed diagnostics only if the last and next to last rows are still in the read buffer.\n     size_t bytes_read_at_start_of_buffer = in->count() - in->offset();\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03279_insert_sparse_parsing_error.reference b/tests/queries/0_stateless/03279_insert_sparse_parsing_error.reference\nnew file mode 100644\nindex 000000000000..07d1b660d363\n--- /dev/null\n+++ b/tests/queries/0_stateless/03279_insert_sparse_parsing_error.reference\n@@ -0,0 +1,6 @@\n+Code: 27\n+1\t0\t0\n+2\t0\t0\n+a\tDefault\n+b\tSparse\n+c\tSparse\ndiff --git a/tests/queries/0_stateless/03279_insert_sparse_parsing_error.sh b/tests/queries/0_stateless/03279_insert_sparse_parsing_error.sh\nnew file mode 100755\nindex 000000000000..1d46c084c693\n--- /dev/null\n+++ b/tests/queries/0_stateless/03279_insert_sparse_parsing_error.sh\n@@ -0,0 +1,31 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT --query \"\n+    DROP TABLE IF EXISTS t_insert_sparse_columns;\n+\n+    CREATE TABLE t_insert_sparse_columns (a UInt64, b UInt64, c UInt64)\n+    ENGINE = MergeTree ORDER BY a\n+    SETTINGS ratio_of_defaults_for_sparse_serialization = 0.5, enable_block_number_column = 0, enable_block_offset_column = 0;\n+\n+    SYSTEM STOP MERGES t_insert_sparse_columns;\n+\"\n+\n+${CLICKHOUSE_CURL} -sS \"${CLICKHOUSE_URL}&query=INSERT+INTO+t_insert_sparse_columns+FORMAT+CSV\" --data-binary @- <<EOF\n+1, 0, 0\n+2, 0, 0\n+EOF\n+\n+${CLICKHOUSE_CURL} -sS \"${CLICKHOUSE_URL}&query=INSERT+INTO+t_insert_sparse_columns+FORMAT+CSV\" --data-binary @- <<EOF 2>&1 | grep -o \"Code: 27\"\n+3, 0\n+4, 0\n+EOF\n+\n+$CLICKHOUSE_CLIENT --query \"\n+    SELECT * FROM t_insert_sparse_columns;\n+    SELECT column, serialization_kind FROM system.parts_columns WHERE database = currentDatabase() AND table = 't_insert_sparse_columns' AND active ORDER BY column, serialization_kind;\n+    DROP TABLE IF EXISTS t_insert_sparse_columns;\n+\"\n",
  "problem_statement": "Segmentation fault on CSV inserts after upgrading to v24.x\n**Describe what's wrong**\r\n\r\nAfter upgrading from 23.5.3.24 to 24.x (e.g., 24.10.1.2812), ClickHouse crashes on the following query:\r\n```bash\r\ncurl 'http://localhost:8123/?query=INSERT%20INTO%20table(a,b,c)%20FORMAT%20CSV' --data-binary @data.csv\r\n```\r\n**How to reproduce**\r\n\r\n* Which ClickHouse server version to use: `any v24.10`\r\n* Which interface to use, if it matters: `HTTP (8123/tcp) only`\r\n* Non-default settings, if any: `vanilla configuration`\r\n* `CREATE TABLE` statements for all tables involved: [table definition](https://fiddle.clickhouse.com/23d772cf-4f9c-4b63-94b8-a95594bf2119)\r\n* Sample data for all these tables (success via native):\r\n```bash\r\nclickhouse-client -q \"INSERT INTO t2 FORMAT CSV\" <<EOF\r\nc1,c2,c3,c4,c5,c7,c8,c9,c10,c11,c12,c13,c14,c15,c16,c17,c18,c19,c20,c36,c37,c38,c39,c40,c41,c42,c43,c45,c47,c59,c60,c61,c62,c63,c64,c65,c66,c67,c69,c70\r\n2024-11-28,2024-11-28 12:07:27,num2,a,c,\"\",8729573116184671696,37515450,RU,2023468,2023469,\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) WebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 YaBrowser/24.10.0.0 Safari/537.36\",86da5280-8903-4a30-95c8-8be5ed74afc9,3,1,windows,10,yandex-browser,24.10,287,0,262162957,82d21e644968b94ada30bb807b1838a3,23530971,,,0,14,16938683,mid,\"\",\"\",\"\",0,0,\"\",0,0,\"\",\"\"\r\n2024-11-28,2024-11-28 12:00:38,num2,a,c,\"\",4787695949136185212,37515450,RU,2023468,2023469,Android,bd8eafe6-8b29-4054-b35c-15dcde4b3ac5,2,0,android,\"\",\"\",\"\",25867133,0,282136854,40bc4823456e3d47c3fe2ace56929cd3,40643490,,,0,15,16938683,pre,\"\",\"\",\"\",0,0,\"\",0,0,\"\",\"\"\r\nEOF\r\n```\r\n* Queries to run that lead to an unexpected result (same data without CSV header, HTTP interface):\r\n```bash\r\ncurl 'http://localhost:8123/?query=INSERT%20INTO%20t2%20FORMAT%20CSV' --data-binary @- <<EOF\r\n2024-11-28,2024-11-28 12:07:27,num2,a,c,\"\",8729573116184671696,37515450,RU,2023468,2023469,\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) WebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 YaBrowser/24.10.0.0 Safari/537.36\",86da5280-8903-4a30-95c8-8be5ed74afc9,3,1,windows,10,yandex-browser,24.10,287,0,262162957,82d21e644968b94ada30bb807b1838a3,23530971,,,0,14,16938683,mid,\"\",\"\",\"\",0,0,\"\",0,0,\"\",\"\"\r\n2024-11-28,2024-11-28 12:00:38,num2,a,c,\"\",4787695949136185212,37515450,RU,2023468,2023469,Android,bd8eafe6-8b29-4054-b35c-15dcde4b3ac5,2,0,android,\"\",\"\",\"\",25867133,0,282136854,40bc4823456e3d47c3fe2ace56929cd3,40643490,,,0,15,16938683,pre,\"\",\"\",\"\",0,0,\"\",0,0,\"\",\"\"\r\nEOF\r\n```\r\n\r\n**Expected behavior**\r\n\r\nNo segfaults, successful inserts with valid CSV. Otherwise: `DB::Exception: Cannot parse input`\r\n\r\n**Error message and/or stacktrace**\r\n```\r\n2024.12.05 20:59:03.884057 [ 18667 ] {} <Fatal> BaseDaemon: ########## Short fault info ############\r\n2024.12.05 20:59:03.884104 [ 18667 ] {} <Fatal> BaseDaemon: (version 24.10.1.2812 (official build), build id: 012A16C8538DB153D53D2A7FF95661825CF0C33C, git hash: 9cd0a3738d5c067197557100b6862bd43c2b0233, architecture: x86_64) (from thread 15253) Received signal 11\r\n2024.12.05 20:59:03.884116 [ 18667 ] {} <Fatal> BaseDaemon: Signal description: Segmentation fault\r\n2024.12.05 20:59:03.884128 [ 18667 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Unknown si_code.\r\n2024.12.05 20:59:03.884139 [ 18667 ] {} <Fatal> BaseDaemon: Stack trace: 0x000000000d26b861 0x00007fabab790d20 0x0000000007a561b3 0x000000001080302b 0x0000000012a7166f 0x0000000012a4cf19 0x0000000012a43396 0x0000000012a4c9cb 0x0000000012a4cbdd 0x0000000012a1c879 0x00000000129bd116 0x000000001299985b 0x0000000012999567 0x0000000012b24421 0x000000000d04452b 0x000000000d04ad42 0x000000000d041a5f 0x000000000d0488fa 0x00007fabab7861ca 0x00007fabab3e18d3\r\n2024.12.05 20:59:03.884147 [ 18667 ] {} <Fatal> BaseDaemon: ########################################\r\n2024.12.05 20:59:03.884154 [ 18667 ] {} <Fatal> BaseDaemon: (version 24.10.1.2812 (official build), build id: 012A16C8538DB153D53D2A7FF95661825CF0C33C, git hash: 9cd0a3738d5c067197557100b6862bd43c2b0233) (from thread 15253) (query_id: f1ba9b16-c7f4-4b06-8bbe-a92bafb130e4) (query: INSERT INTO t2 FORMAT CSV\r\n2024.12.05 20:59:03.884160 [ 18667 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Unknown si_code.\r\n2024.12.05 20:59:03.884164 [ 18667 ] {} <Fatal> BaseDaemon: Stack trace: 0x000000000d26b861 0x00007fabab790d20 0x0000000007a561b3 0x000000001080302b 0x0000000012a7166f 0x0000000012a4cf19 0x0000000012a43396 0x0000000012a4c9cb 0x0000000012a4cbdd 0x0000000012a1c879 0x00000000129bd116 0x000000001299985b 0x0000000012999567 0x0000000012b24421 0x000000000d04452b 0x000000000d04ad42 0x000000000d041a5f 0x000000000d0488fa 0x00007fabab7861ca 0x00007fabab3e18d3\r\n2024.12.05 20:59:03.884200 [ 18667 ] {} <Fatal> BaseDaemon: 0. signalHandler(int, siginfo_t*, void*) @ 0x000000000d26b861\r\n2024.12.05 20:59:03.884213 [ 18667 ] {} <Fatal> BaseDaemon: 1. ? @ 0x0000000000012d20\r\n2024.12.05 20:59:03.884234 [ 18667 ] {} <Fatal> BaseDaemon: 2. DB::SerializationNumber<unsigned short>::deserializeTextCSV(DB::IColumn&, DB::ReadBuffer&, DB::FormatSettings const&) const @ 0x0000000007a561b3\r\n2024.12.05 20:59:03.884244 [ 18667 ] {} <Fatal> BaseDaemon: 3. DB::SerializationSparse::deserializeTextCSV(DB::IColumn&, DB::ReadBuffer&, DB::FormatSettings const&) const @ 0x000000001080302b\r\n2024.12.05 20:59:03.884283 [ 18667 ] {} <Fatal> BaseDaemon: 4. DB::CSVFormatReader::readField(DB::IColumn&, std::shared_ptr<DB::IDataType const> const&, std::shared_ptr<DB::ISerialization const> const&, bool, String const&) @ 0x0000000012a7166f\r\n2024.12.05 20:59:03.884306 [ 18667 ] {} <Fatal> BaseDaemon: 5. DB::RowInputFormatWithDiagnosticInfo::deserializeFieldAndPrintDiagnosticInfo(String const&, std::shared_ptr<DB::IDataType const> const&, DB::IColumn&, DB::WriteBuffer&, unsigned long) @ 0x0000000012a4cf19\r\n2024.12.05 20:59:03.884319 [ 18667 ] {} <Fatal> BaseDaemon: 6. DB::RowInputFormatWithNamesAndTypes<DB::CSVFormatReader>::parseRowAndPrintDiagnosticInfo(std::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn>>>&, DB::WriteBuffer&) @ 0x0000000012a43396\r\n2024.12.05 20:59:03.884335 [ 18667 ] {} <Fatal> BaseDaemon: 7. DB::RowInputFormatWithDiagnosticInfo::getDiagnosticAndRawDataImpl(bool) @ 0x0000000012a4c9cb\r\n2024.12.05 20:59:03.884345 [ 18667 ] {} <Fatal> BaseDaemon: 8. DB::RowInputFormatWithDiagnosticInfo::getDiagnosticInfo() @ 0x0000000012a4cbdd\r\n2024.12.05 20:59:03.884357 [ 18667 ] {} <Fatal> BaseDaemon: 9. DB::IRowInputFormat::read() @ 0x0000000012a1c879\r\n2024.12.05 20:59:03.884368 [ 18667 ] {} <Fatal> BaseDaemon: 10. DB::IInputFormat::generate() @ 0x00000000129bd116\r\n2024.12.05 20:59:03.884374 [ 18667 ] {} <Fatal> BaseDaemon: 11. DB::ISource::tryGenerate() @ 0x000000001299985b\r\n2024.12.05 20:59:03.884382 [ 18667 ] {} <Fatal> BaseDaemon: 12. DB::ISource::work() @ 0x0000000012999567\r\n2024.12.05 20:59:03.884401 [ 18667 ] {} <Fatal> BaseDaemon: 13. void std::__function::__policy_invoker<void ()>::__call_impl<std::__function::__default_alloc_func<DB::ParallelParsingInputFormat::scheduleParserThreadForUnitWithNumber(unsigned long)::'lambda'(), void ()>>(std::__function::__policy_storage const*) @ 0x0000000012b24421\r\n2024.12.05 20:59:03.884414 [ 18667 ] {} <Fatal> BaseDaemon: 14. ThreadPoolImpl<ThreadFromGlobalPoolImpl<false, true>>::ThreadFromThreadPool::worker() @ 0x000000000d04452b\r\n2024.12.05 20:59:03.884430 [ 18667 ] {} <Fatal> BaseDaemon: 15. void std::__function::__policy_invoker<void ()>::__call_impl<std::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<false, true>::ThreadFromGlobalPoolImpl<void (ThreadPoolImpl<ThreadFromGlobalPoolImpl<false, true>>::ThreadFromThreadPool::*)(), ThreadPoolImpl<ThreadFromGlobalPoolImpl<false, true>>::ThreadFromThreadPool*>(void (ThreadPoolImpl<ThreadFromGlobalPoolImpl<false, true>>::ThreadFromThreadPool::*&&)(), ThreadPoolImpl<ThreadFromGlobalPoolImpl<false, true>>::ThreadFromThreadPool*&&)::'lambda'(), void ()>>(std::__function::__policy_storage const*) @ 0x000000000d04ad42\r\n2024.12.05 20:59:03.884438 [ 18667 ] {} <Fatal> BaseDaemon: 16. ThreadPoolImpl<std::thread>::ThreadFromThreadPool::worker() @ 0x000000000d041a5f\r\n2024.12.05 20:59:03.884453 [ 18667 ] {} <Fatal> BaseDaemon: 17. void* std::__thread_proxy[abi:v15007]<std::tuple<std::unique_ptr<std::__thread_struct, std::default_delete<std::__thread_struct>>, void (ThreadPoolImpl<std::thread>::ThreadFromThreadPool::*)(), ThreadPoolImpl<std::thread>::ThreadFromThreadPool*>>(void*) @ 0x000000000d0488fa\r\n2024.12.05 20:59:03.884460 [ 18667 ] {} <Fatal> BaseDaemon: 18. start_thread @ 0x00000000000081ca\r\n2024.12.05 20:59:03.884476 [ 18667 ] {} <Fatal> BaseDaemon: 19. clone @ 0x00000000000398d3\r\n2024.12.05 20:59:04.057539 [ 18667 ] {} <Fatal> BaseDaemon: Integrity check of the executable successfully passed (checksum: 8E1CF31706649FB3F1049E398ADB6A33)\r\n2024.12.05 20:59:04.057731 [ 18667 ] {} <Information> SentryWriter: Not sending crash report\r\n2024.12.05 20:59:04.057735 [ 18667 ] {} <Fatal> BaseDaemon: Report this error to https://github.com/ClickHouse/ClickHouse/issues\r\n2024.12.05 20:59:04.057838 [ 18667 ] {} <Fatal> BaseDaemon: No settings were changed\r\n```\r\n\n",
  "hints_text": "",
  "created_at": "2024-12-06T13:36:43Z"
}