diff --git a/tests/integration/test_storage_kafka/test.py b/tests/integration/test_storage_kafka/test.py
index 2176b0151ffb..1c7814435dbb 100644
--- a/tests/integration/test_storage_kafka/test.py
+++ b/tests/integration/test_storage_kafka/test.py
@@ -892,12 +892,14 @@ def test_kafka_formats(kafka_cluster):
 """
 
     expected_rows_count = raw_expected.count("
")
-    instance.query_with_retry(
+    result_checker = lambda res: res.count("
") == expected_rows_count
+    res = instance.query_with_retry(
         f"SELECT * FROM test.kafka_{list(all_formats.keys())[-1]}_mv;",
         retry_count=30,
         sleep_time=1,
-        check_callback=lambda res: res.count("
") == expected_rows_count,
+        check_callback=result_checker,
     )
+    assert result_checker(res)
 
     for format_name, format_opts in list(all_formats.items()):
         logging.debug(("Checking {}".format(format_name)))
@@ -3808,12 +3810,14 @@ def test_kafka_formats_with_broken_message(kafka_cluster):
 """
 
     expected_rows_count = raw_expected.count("
")
-    instance.query_with_retry(
+    result_checker = lambda res: res.count("
") == expected_rows_count
+    res = instance.query_with_retry(
         f"SELECT * FROM test.kafka_data_{list(all_formats.keys())[-1]}_mv;",
         retry_count=30,
         sleep_time=1,
-        check_callback=lambda res: res.count("
") == expected_rows_count,
+        check_callback=result_checker,
     )
+    assert result_checker(res)
 
     for format_name, format_opts in list(all_formats.items()):
         logging.debug(f"Checking {format_name}")
@@ -4931,6 +4935,80 @@ def test_formats_errors(kafka_cluster):
         instance.query("DROP TABLE test.view")
 
 
+def test_multiple_read_in_materialized_views(kafka_cluster, max_retries=15):
+    admin_client = KafkaAdminClient(
+        bootstrap_servers="localhost:{}".format(kafka_cluster.kafka_port)
+    )
+
+    topic = "multiple_read_from_mv"
+    kafka_create_topic(admin_client, topic)
+
+    instance.query(
+        f"""
+        DROP TABLE IF EXISTS test.kafka_multiple_read_input;
+        DROP TABLE IF EXISTS test.kafka_multiple_read_table;
+        DROP TABLE IF EXISTS test.kafka_multiple_read_mv;
+
+        CREATE TABLE test.kafka_multiple_read_input (id Int64)
+        ENGINE = Kafka
+        SETTINGS
+            kafka_broker_list = 'kafka1:19092',
+            kafka_topic_list = '{topic}',
+            kafka_group_name = '{topic}',
+            kafka_format = 'JSONEachRow';
+
+        CREATE TABLE test.kafka_multiple_read_table (id Int64)
+        ENGINE = MergeTree
+        ORDER BY id;
+
+
+        CREATE MATERIALIZED VIEW IF NOT EXISTS test.kafka_multiple_read_mv TO test.kafka_multiple_read_table AS
+        SELECT id
+        FROM test.kafka_multiple_read_input
+        WHERE id NOT IN (
+            SELECT id
+            FROM test.kafka_multiple_read_table
+            WHERE id IN (
+                SELECT id
+                FROM test.kafka_multiple_read_input
+            )
+        );
+        """
+    )
+
+    kafka_produce(
+        kafka_cluster, topic, [json.dumps({"id": 42}), json.dumps({"id": 43})]
+    )
+
+    expected_result = "42
43
"
+    res = instance.query_with_retry(
+        f"SELECT id FROM test.kafka_multiple_read_table ORDER BY id",
+        retry_count=30,
+        sleep_time=0.5,
+        check_callback=lambda res: res == expected_result,
+    )
+    assert res == expected_result
+
+    # Verify that the query deduplicates the records as it meant to be
+    messages = []
+    for i in range(0, 10):
+        messages.append(json.dumps({"id": 42}))
+        messages.append(json.dumps({"id": 43}))
+
+    messages.append(json.dumps({"id": 44}))
+
+    kafka_produce(kafka_cluster, topic, messages)
+
+    expected_result = "42
43
44
"
+    res = instance.query_with_retry(
+        f"SELECT id FROM test.kafka_multiple_read_table ORDER BY id",
+        retry_count=30,
+        sleep_time=0.5,
+        check_callback=lambda res: res == expected_result,
+    )
+    assert res == expected_result
+
+
 if __name__ == "__main__":
     cluster.start()
     input("Cluster created, press any key to destroy...")
