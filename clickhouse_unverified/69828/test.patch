diff --git a/tests/performance/insert_sparse_column.xml b/tests/performance/insert_sparse_column.xml
new file mode 100644
index 000000000000..0f6cdcec332c
--- /dev/null
+++ b/tests/performance/insert_sparse_column.xml
@@ -0,0 +1,17 @@
+<test>
+    <create_query>CREATE TABLE t_insert_sparse (id UInt64, c0 String, c1 String, c2 String, c3 String, c4 String, c5 String, c6 String, c7 String, c8 String, c9 String, c10 String, c11 String, c12 String, c13 String, c14 String, c15 String, c16 String, c17 String, c18 String, c19 String, c20 String, c21 String, c22 String, c23 String, c24 String, c25 String, c26 String, c27 String, c28 String, c29 String, c30 String, c31 String, c32 String, c33 String, c34 String, c35 String, c36 String, c37 String, c38 String, c39 String, c40 String, c41 String, c42 String, c43 String, c44 String, c45 String, c46 String, c47 String, c48 String, c49 String, c50 String, c51 String, c52 String, c53 String, c54 String, c55 String, c56 String, c57 String, c58 String, c59 String, c60 String, c61 String, c62 String, c63 String, c64 String, c65 String, c66 String, c67 String, c68 String, c69 String, c70 String, c71 String, c72 String, c73 String, c74 String, c75 String, c76 String, c77 String, c78 String, c79 String, c80 String, c81 String, c82 String, c83 String, c84 String, c85 String, c86 String, c87 String, c88 String, c89 String, c90 String, c91 String, c92 String, c93 String, c94 String, c95 String, c96 String, c97 String, c98 String, c99 String) ENGINE = MergeTree ORDER BY id</create_query>
+    <!-- Prepare JSON data -->
+    <fill_query>SYSTEM STOP MERGES t_insert_sparse</fill_query>
+    <!-- Prepare JSON data -->
+    <fill_query>
+        INSERT INTO FUNCTION file('test_data_sparse.json', LineAsString)
+        SELECT '{{"id": ' || number || ', "c' || number % 50 || '": "' || hex(rand()) || '"}}'
+        FROM numbers(100000) SETTINGS engine_file_truncate_on_insert = 1
+    </fill_query>
+    <!-- Insert one batch to create statistics about serializations -->
+    <fill_query>INSERT INTO t_insert_sparse SELECT * FROM file('test_data_sparse.json', JSONEachRow)</fill_query>
+
+    <query>INSERT INTO t_insert_sparse SELECT * FROM file('test_data_sparse.json', JSONEachRow)</query>
+
+    <drop_query>DROP TABLE IF EXISTS t_insert_sparse</drop_query>
+</test>
diff --git a/tests/queries/0_stateless/02423_insert_stats_behaviour.sh b/tests/queries/0_stateless/02423_insert_stats_behaviour.sh
index b85ca3111016..5680af7da718 100755
--- a/tests/queries/0_stateless/02423_insert_stats_behaviour.sh
+++ b/tests/queries/0_stateless/02423_insert_stats_behaviour.sh
@@ -4,9 +4,9 @@ CUR_DIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # shellcheck source=../shell_config.sh
 . "$CUR_DIR"/../shell_config.sh
 
-$CLICKHOUSE_CLIENT -q "CREATE TABLE floats (v Float64) Engine=MergeTree() ORDER BY tuple();"
-$CLICKHOUSE_CLIENT -q "CREATE TABLE target_1 (v Float64) Engine=MergeTree() ORDER BY tuple();"
-$CLICKHOUSE_CLIENT -q "CREATE TABLE target_2 (v Float64) Engine=MergeTree() ORDER BY tuple();"
+$CLICKHOUSE_CLIENT -q "CREATE TABLE floats (v Float64) Engine=MergeTree() ORDER BY tuple() SETTINGS ratio_of_defaults_for_sparse_serialization = 1.0"
+$CLICKHOUSE_CLIENT -q "CREATE TABLE target_1 (v Float64) Engine=MergeTree() ORDER BY tuple() SETTINGS ratio_of_defaults_for_sparse_serialization = 1.0;"
+$CLICKHOUSE_CLIENT -q "CREATE TABLE target_2 (v Float64) Engine=MergeTree() ORDER BY tuple() SETTINGS ratio_of_defaults_for_sparse_serialization = 1.0;"
 $CLICKHOUSE_CLIENT -q "CREATE MATERIALIZED VIEW floats_to_target TO target_1 AS SELECT * FROM floats"
 $CLICKHOUSE_CLIENT -q "CREATE MATERIALIZED VIEW floats_to_target_2 TO target_2 AS SELECT * FROM floats, numbers(2) n"
 
diff --git a/tests/queries/0_stateless/02423_insert_summary_behaviour.sh b/tests/queries/0_stateless/02423_insert_summary_behaviour.sh
index b184d9ccf47f..cb28724ab58e 100755
--- a/tests/queries/0_stateless/02423_insert_summary_behaviour.sh
+++ b/tests/queries/0_stateless/02423_insert_summary_behaviour.sh
@@ -4,9 +4,9 @@ CUR_DIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # shellcheck source=../shell_config.sh
 . "$CUR_DIR"/../shell_config.sh
 
-$CLICKHOUSE_CLIENT -q "CREATE TABLE floats (v Float64) Engine=MergeTree() ORDER BY tuple();"
-$CLICKHOUSE_CLIENT -q "CREATE TABLE target_1 (v Float64) Engine=MergeTree() ORDER BY tuple();"
-$CLICKHOUSE_CLIENT -q "CREATE TABLE target_2 (v Float64) Engine=MergeTree() ORDER BY tuple();"
+$CLICKHOUSE_CLIENT -q "CREATE TABLE floats (v Float64) Engine=MergeTree() ORDER BY tuple() SETTINGS ratio_of_defaults_for_sparse_serialization = 1.0;"
+$CLICKHOUSE_CLIENT -q "CREATE TABLE target_1 (v Float64) Engine=MergeTree() ORDER BY tuple() SETTINGS ratio_of_defaults_for_sparse_serialization = 1.0;"
+$CLICKHOUSE_CLIENT -q "CREATE TABLE target_2 (v Float64) Engine=MergeTree() ORDER BY tuple() SETTINGS ratio_of_defaults_for_sparse_serialization = 1.0;"
 $CLICKHOUSE_CLIENT -q "CREATE MATERIALIZED VIEW floats_to_target TO target_1 AS SELECT * FROM floats"
 $CLICKHOUSE_CLIENT -q "CREATE MATERIALIZED VIEW floats_to_target_2 TO target_2 AS SELECT * FROM floats, numbers(2) n"
 
diff --git a/tests/queries/0_stateless/03237_insert_sparse_columns.reference b/tests/queries/0_stateless/03237_insert_sparse_columns.reference
new file mode 100644
index 000000000000..592fcff9b258
--- /dev/null
+++ b/tests/queries/0_stateless/03237_insert_sparse_columns.reference
@@ -0,0 +1,21 @@
+1	0
+2	0
+3	0
+4	0
+5	0
+6	0
+7	0
+8	0
+9	0
+10	0
+11	100
+12	200
+13	300
+14	400
+15	500
+all_1_1_0	id	Default
+all_1_1_0	v	Sparse
+all_2_2_0	id	Default
+all_2_2_0	v	Sparse
+all_3_3_0	id	Default
+all_3_3_0	v	Default
diff --git a/tests/queries/0_stateless/03237_insert_sparse_columns.sh b/tests/queries/0_stateless/03237_insert_sparse_columns.sh
new file mode 100755
index 000000000000..a4d53a36b87e
--- /dev/null
+++ b/tests/queries/0_stateless/03237_insert_sparse_columns.sh
@@ -0,0 +1,25 @@
+#!/usr/bin/env bash
+
+CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
+# shellcheck source=../shell_config.sh
+. "$CURDIR"/../shell_config.sh
+
+$CLICKHOUSE_CLIENT --query "
+    DROP TABLE IF EXISTS t_insert_sparse_columns;
+    CREATE TABLE t_insert_sparse_columns (id UInt64, v UInt64) ENGINE = MergeTree ORDER BY id SETTINGS ratio_of_defaults_for_sparse_serialization = 0.5;
+    SYSTEM STOP MERGES t_insert_sparse_columns;
+"
+
+${CLICKHOUSE_CURL} -sS ${CLICKHOUSE_URL} -d 'INSERT INTO t_insert_sparse_columns FORMAT JSONEachRow {"id": 1} {"id": 2} {"id": 3} {"id": 4} {"id": 5}'
+${CLICKHOUSE_CURL} -sS ${CLICKHOUSE_URL} -d 'INSERT INTO t_insert_sparse_columns FORMAT JSONEachRow {"id": 6} {"id": 7} {"id": 8} {"id": 9} {"id": 10}'
+${CLICKHOUSE_CURL} -sS ${CLICKHOUSE_URL} -d 'INSERT INTO t_insert_sparse_columns FORMAT JSONEachRow {"id": 11, "v": 100} {"id": 12, "v": 200} {"id": 13, "v": 300} {"id": 14, "v": 400} {"id": 15, "v": 500}'
+
+$CLICKHOUSE_CLIENT --query "
+    SELECT * FROM t_insert_sparse_columns ORDER BY id;
+
+    SELECT name, column, serialization_kind FROM system.parts_columns
+    WHERE table = 't_insert_sparse_columns' AND database = currentDatabase() AND active
+    ORDER BY name, column;
+
+    DROP TABLE t_insert_sparse_columns;
+"
diff --git a/tests/queries/0_stateless/03237_insert_sparse_columns_mem.reference b/tests/queries/0_stateless/03237_insert_sparse_columns_mem.reference
new file mode 100644
index 000000000000..09ef3399bad7
--- /dev/null
+++ b/tests/queries/0_stateless/03237_insert_sparse_columns_mem.reference
@@ -0,0 +1,9 @@
+120000
+435170936075214220
+435170936075214220
+Default	4
+Sparse	1000
+0
+1
+1
+1
diff --git a/tests/queries/0_stateless/03237_insert_sparse_columns_mem.sh b/tests/queries/0_stateless/03237_insert_sparse_columns_mem.sh
new file mode 100755
index 000000000000..ac682a0f574b
--- /dev/null
+++ b/tests/queries/0_stateless/03237_insert_sparse_columns_mem.sh
@@ -0,0 +1,62 @@
+#!/usr/bin/env bash
+# Tags: no-fasttest, long
+
+CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
+# shellcheck source=../shell_config.sh
+. "$CURDIR"/../shell_config.sh
+
+table_structure="id UInt64"
+
+for i in {1..250}; do
+    table_structure+=", c$i String"
+done
+
+$CLICKHOUSE_CLIENT --query "
+    DROP TABLE IF EXISTS t_insert_mem;
+    DROP TABLE IF EXISTS t_reference;
+
+    CREATE TABLE t_insert_mem ($table_structure) ENGINE = MergeTree ORDER BY id SETTINGS ratio_of_defaults_for_sparse_serialization = 0.9;
+    CREATE TABLE t_reference ($table_structure) ENGINE = Log;
+
+    SYSTEM STOP MERGES t_insert_mem;
+"
+
+filename="test_data_sparse_$CLICKHOUSE_DATABASE.json"
+
+$CLICKHOUSE_CLIENT --query "
+    INSERT INTO FUNCTION file('$filename', LineAsString)
+    SELECT format('{{ \"id\": {}, \"c{}\": \"{}\" }}', number, number % 250, hex(number * 1000000)) FROM numbers(30000)
+    SETTINGS engine_file_truncate_on_insert = 1;
+
+    INSERT INTO FUNCTION s3(s3_conn, filename='$filename', format='LineAsString')
+    SELECT * FROM file('$filename', LineAsString)
+    SETTINGS s3_truncate_on_insert = 1;
+"
+
+for _ in {1..4}; do
+    $CLICKHOUSE_CLIENT --query "INSERT INTO t_reference SELECT * FROM file('$filename', JSONEachRow)"
+done;
+
+$CLICKHOUSE_CLIENT --enable_parsing_to_custom_serialization 1 --query "INSERT INTO t_insert_mem SELECT * FROM file('$filename', JSONEachRow)"
+$CLICKHOUSE_CLIENT --enable_parsing_to_custom_serialization 1 --query "INSERT INTO t_insert_mem SELECT * FROM file('$filename', JSONEachRow)"
+$CLICKHOUSE_CLIENT --enable_parsing_to_custom_serialization 1 --query "INSERT INTO t_insert_mem SELECT * FROM s3(s3_conn, filename='$filename', format='JSONEachRow')"
+$CLICKHOUSE_CLIENT --query "SELECT * FROM file('$filename', LineAsString) FORMAT LineAsString" | ${CLICKHOUSE_CURL} -sS "${CLICKHOUSE_URL}&query=INSERT+INTO+t_insert_mem+FORMAT+JSONEachRow&enable_parsing_to_custom_serialization=1" --data-binary @-
+
+$CLICKHOUSE_CLIENT --query "
+    SELECT count() FROM t_insert_mem;
+    SELECT sum(sipHash64(*)) FROM t_insert_mem;
+    SELECT sum(sipHash64(*)) FROM t_reference;
+
+    SELECT serialization_kind, count() FROM system.parts_columns
+    WHERE table = 't_insert_mem' AND database = '$CLICKHOUSE_DATABASE'
+    GROUP BY serialization_kind ORDER BY serialization_kind;
+
+    SYSTEM FLUSH LOGS;
+
+    SELECT written_bytes <= 3000000 FROM system.query_log
+    WHERE query LIKE 'INSERT INTO t_insert_mem%' AND current_database = '$CLICKHOUSE_DATABASE' AND type = 'QueryFinish'
+    ORDER BY event_time_microseconds;
+
+    DROP TABLE IF EXISTS t_insert_mem;
+    DROP TABLE IF EXISTS t_reference;
+"
