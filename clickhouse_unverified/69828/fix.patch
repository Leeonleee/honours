diff --git a/src/Core/Block.cpp b/src/Core/Block.cpp
index d560cb2c1053..c7e0e9b7b377 100644
--- a/src/Core/Block.cpp
+++ b/src/Core/Block.cpp
@@ -818,6 +818,23 @@ Serializations Block::getSerializations() const
     return res;
 }
 
+Serializations Block::getSerializations(const SerializationInfoByName & hints) const
+{
+    Serializations res;
+    res.reserve(data.size());
+
+    for (const auto & column : data)
+    {
+        auto it = hints.find(column.name);
+        if (it == hints.end())
+            res.push_back(column.type->getDefaultSerialization());
+        else
+            res.push_back(column.type->getSerialization(*it->second));
+    }
+
+    return res;
+}
+
 void convertToFullIfSparse(Block & block)
 {
     for (auto & column : block)
diff --git a/src/Core/Block.h b/src/Core/Block.h
index d998581a50fe..841fb3fb6639 100644
--- a/src/Core/Block.h
+++ b/src/Core/Block.h
@@ -10,6 +10,7 @@
 #include <set>
 #include <vector>
 #include <sparsehash/dense_hash_map>
+#include <DataTypes/Serializations/SerializationInfo.h>
 
 
 namespace DB
@@ -99,6 +100,7 @@ class Block
     NameMap getNamesToIndexesMap() const;
 
     Serializations getSerializations() const;
+    Serializations getSerializations(const SerializationInfoByName & hints) const;
 
     /// Returns number of rows from first column in block, not equal to nullptr. If no columns, returns 0.
     size_t rows() const;
diff --git a/src/Core/Settings.cpp b/src/Core/Settings.cpp
index a09a0b8375fe..35579a520f63 100644
--- a/src/Core/Settings.cpp
+++ b/src/Core/Settings.cpp
@@ -242,6 +242,7 @@ namespace ErrorCodes
     M(Bool, output_format_parallel_formatting, true, "Enable parallel formatting for some data formats.", 0) \
     M(UInt64, output_format_compression_level, 3, "Default compression level if query output is compressed. The setting is applied when `SELECT` query has `INTO OUTFILE` or when inserting to table function `file`, `url`, `hdfs`, `s3`, and `azureBlobStorage`.", 0) \
     M(UInt64, output_format_compression_zstd_window_log, 0, "Can be used when the output compression method is `zstd`. If greater than `0`, this setting explicitly sets compression window size (power of `2`) and enables a long-range mode for zstd compression.", 0) \
+    M(Bool, enable_parsing_to_custom_serialization, true, "If true then data can be parsed directly to columns with custom serialization (e.g. Sparse) according to hints for serialization got from the table.", 0) \
     \
     M(UInt64, merge_tree_min_rows_for_concurrent_read, (20 * 8192), "If at least as many lines are read from one file, the reading can be parallelized.", 0) \
     M(UInt64, merge_tree_min_bytes_for_concurrent_read, (24 * 10 * 1024 * 1024), "If at least as many bytes are read from one file, the reading can be parallelized.", 0) \
diff --git a/src/Core/SettingsChangesHistory.cpp b/src/Core/SettingsChangesHistory.cpp
index 8b9dfc91e3e6..6408a989ee14 100644
--- a/src/Core/SettingsChangesHistory.cpp
+++ b/src/Core/SettingsChangesHistory.cpp
@@ -67,6 +67,7 @@ static std::initializer_list<std::pair<ClickHouseVersion, SettingsChangesHistory
     },
     {"24.10",
         {
+            {"enable_parsing_to_custom_serialization", false, true, "New setting"},
             {"mongodb_throw_on_unsupported_query", false, true, "New setting."},
         }
     },
diff --git a/src/DataTypes/Serializations/SerializationInfo.cpp b/src/DataTypes/Serializations/SerializationInfo.cpp
index 7d5c456af7f3..df9d27d4ca28 100644
--- a/src/DataTypes/Serializations/SerializationInfo.cpp
+++ b/src/DataTypes/Serializations/SerializationInfo.cpp
@@ -47,6 +47,12 @@ void SerializationInfo::Data::add(const Data & other)
     num_defaults += other.num_defaults;
 }
 
+void SerializationInfo::Data::remove(const Data & other)
+{
+    num_rows -= other.num_rows;
+    num_defaults -= other.num_defaults;
+}
+
 void SerializationInfo::Data::addDefaults(size_t length)
 {
     num_rows += length;
@@ -80,6 +86,14 @@ void SerializationInfo::add(const SerializationInfo & other)
         kind = chooseKind(data, settings);
 }
 
+void SerializationInfo::remove(const SerializationInfo & other)
+{
+    data.remove(other.data);
+    if (settings.choose_kind)
+        kind = chooseKind(data, settings);
+}
+
+
 void SerializationInfo::addDefaults(size_t length)
 {
     data.addDefaults(length);
@@ -202,13 +216,37 @@ void SerializationInfoByName::add(const Block & block)
 void SerializationInfoByName::add(const SerializationInfoByName & other)
 {
     for (const auto & [name, info] : other)
-    {
-        auto it = find(name);
-        if (it == end())
-            continue;
+        add(name, *info);
+}
 
-        it->second->add(*info);
-    }
+void SerializationInfoByName::add(const String & name, const SerializationInfo & info)
+{
+    if (auto it = find(name); it != end())
+        it->second->add(info);
+}
+
+void SerializationInfoByName::remove(const SerializationInfoByName & other)
+{
+    for (const auto & [name, info] : other)
+        remove(name, *info);
+}
+
+void SerializationInfoByName::remove(const String & name, const SerializationInfo & info)
+{
+    if (auto it = find(name); it != end())
+        it->second->remove(info);
+}
+
+SerializationInfoPtr SerializationInfoByName::tryGet(const String & name) const
+{
+    auto it = find(name);
+    return it == end() ? nullptr : it->second;
+}
+
+MutableSerializationInfoPtr SerializationInfoByName::tryGet(const String & name)
+{
+    auto it = find(name);
+    return it == end() ? nullptr : it->second;
 }
 
 void SerializationInfoByName::replaceData(const SerializationInfoByName & other)
@@ -224,6 +262,12 @@ void SerializationInfoByName::replaceData(const SerializationInfoByName & other)
     }
 }
 
+ISerialization::Kind SerializationInfoByName::getKind(const String & column_name) const
+{
+    auto it = find(column_name);
+    return it != end() ? it->second->getKind() : ISerialization::Kind::DEFAULT;
+}
+
 void SerializationInfoByName::writeJSON(WriteBuffer & out) const
 {
     Poco::JSON::Object object;
diff --git a/src/DataTypes/Serializations/SerializationInfo.h b/src/DataTypes/Serializations/SerializationInfo.h
index 5a900a5521cd..c30e50ab12c8 100644
--- a/src/DataTypes/Serializations/SerializationInfo.h
+++ b/src/DataTypes/Serializations/SerializationInfo.h
@@ -39,6 +39,7 @@ class SerializationInfo
 
         void add(const IColumn & column);
         void add(const Data & other);
+        void remove(const Data & other);
         void addDefaults(size_t length);
     };
 
@@ -52,6 +53,7 @@ class SerializationInfo
 
     virtual void add(const IColumn & column);
     virtual void add(const SerializationInfo & other);
+    virtual void remove(const SerializationInfo & other);
     virtual void addDefaults(size_t length);
     virtual void replaceData(const SerializationInfo & other);
 
@@ -99,6 +101,14 @@ class SerializationInfoByName : public std::map<String, MutableSerializationInfo
 
     void add(const Block & block);
     void add(const SerializationInfoByName & other);
+    void add(const String & name, const SerializationInfo & info);
+
+    void remove(const SerializationInfoByName & other);
+    void remove(const String & name, const SerializationInfo & info);
+
+    SerializationInfoPtr tryGet(const String & name) const;
+    MutableSerializationInfoPtr tryGet(const String & name);
+    ISerialization::Kind getKind(const String & column_name) const;
 
     /// Takes data from @other, but keeps current serialization kinds.
     /// If column exists in @other infos, but not in current infos,
diff --git a/src/DataTypes/Serializations/SerializationInfoTuple.cpp b/src/DataTypes/Serializations/SerializationInfoTuple.cpp
index cd65b865248a..b7449be3cc53 100644
--- a/src/DataTypes/Serializations/SerializationInfoTuple.cpp
+++ b/src/DataTypes/Serializations/SerializationInfoTuple.cpp
@@ -10,6 +10,7 @@ namespace ErrorCodes
 {
     extern const int CORRUPTED_DATA;
     extern const int THERE_IS_NO_COLUMN;
+    extern const int NOT_IMPLEMENTED;
 }
 
 SerializationInfoTuple::SerializationInfoTuple(
@@ -68,6 +69,19 @@ void SerializationInfoTuple::add(const SerializationInfo & other)
     }
 }
 
+void SerializationInfoTuple::remove(const SerializationInfo & other)
+{
+    if (!structureEquals(other))
+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Cannot remove from serialization info different structure");
+
+    SerializationInfo::remove(other);
+    const auto & other_elems = assert_cast<const SerializationInfoTuple &>(other).elems;
+    chassert(elems.size() == other_elems.size());
+
+    for (size_t i = 0; i < elems.size(); ++i)
+        elems[i]->remove(*other_elems[i]);
+}
+
 void SerializationInfoTuple::addDefaults(size_t length)
 {
     SerializationInfo::addDefaults(length);
diff --git a/src/DataTypes/Serializations/SerializationInfoTuple.h b/src/DataTypes/Serializations/SerializationInfoTuple.h
index a9f3bdb6c6e7..a6b9c89166fb 100644
--- a/src/DataTypes/Serializations/SerializationInfoTuple.h
+++ b/src/DataTypes/Serializations/SerializationInfoTuple.h
@@ -15,6 +15,7 @@ class SerializationInfoTuple : public SerializationInfo
 
     void add(const IColumn & column) override;
     void add(const SerializationInfo & other) override;
+    void remove(const SerializationInfo & other) override;
     void addDefaults(size_t length) override;
     void replaceData(const SerializationInfo & other) override;
 
diff --git a/src/DataTypes/Serializations/SerializationSparse.cpp b/src/DataTypes/Serializations/SerializationSparse.cpp
index 73488d308bb3..327d1f23ccaf 100644
--- a/src/DataTypes/Serializations/SerializationSparse.cpp
+++ b/src/DataTypes/Serializations/SerializationSparse.cpp
@@ -13,7 +13,6 @@ namespace DB
 
 namespace ErrorCodes
 {
-    extern const int NOT_IMPLEMENTED;
     extern const int LOGICAL_ERROR;
 }
 
@@ -313,15 +312,35 @@ void SerializationSparse::deserializeBinary(Field & field, ReadBuffer & istr, co
     nested->deserializeBinary(field, istr, settings);
 }
 
+template <typename Reader>
+void SerializationSparse::deserialize(IColumn & column, Reader && reader) const
+{
+    auto & column_sparse = assert_cast<ColumnSparse &>(column);
+    auto & values = column_sparse.getValuesColumn();
+    size_t old_size = column_sparse.size();
+
+    /// It just increments the size of column.
+    column_sparse.insertDefault();
+    reader(column_sparse.getValuesColumn());
+
+    if (values.isDefaultAt(values.size() - 1))
+        values.popBack(1);
+    else
+        column_sparse.getOffsetsData().push_back(old_size);
+}
+
 void SerializationSparse::serializeBinary(const IColumn & column, size_t row_num, WriteBuffer & ostr, const FormatSettings & settings) const
 {
     const auto & column_sparse = assert_cast<const ColumnSparse &>(column);
     nested->serializeBinary(column_sparse.getValuesColumn(), column_sparse.getValueIndex(row_num), ostr, settings);
 }
 
-void SerializationSparse::deserializeBinary(IColumn &, ReadBuffer &, const FormatSettings &) const
+void SerializationSparse::deserializeBinary(IColumn & column, ReadBuffer & istr, const FormatSettings & settings) const
 {
-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Method 'deserializeBinary' is not implemented for SerializationSparse");
+    deserialize(column, [&](auto & nested_column)
+    {
+        nested->deserializeBinary(nested_column, istr, settings);
+    });
 }
 
 void SerializationSparse::serializeTextEscaped(const IColumn & column, size_t row_num, WriteBuffer & ostr, const FormatSettings & settings) const
@@ -330,9 +349,12 @@ void SerializationSparse::serializeTextEscaped(const IColumn & column, size_t ro
     nested->serializeTextEscaped(column_sparse.getValuesColumn(), column_sparse.getValueIndex(row_num), ostr, settings);
 }
 
-void SerializationSparse::deserializeTextEscaped(IColumn &, ReadBuffer &, const FormatSettings &) const
+void SerializationSparse::deserializeTextEscaped(IColumn & column, ReadBuffer & istr, const FormatSettings & settings) const
 {
-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Method 'deserializeTextEscaped' is not implemented for SerializationSparse");
+    deserialize(column, [&](auto & nested_column)
+    {
+        nested->deserializeTextEscaped(nested_column, istr, settings);
+    });
 }
 
 void SerializationSparse::serializeTextQuoted(const IColumn & column, size_t row_num, WriteBuffer & ostr, const FormatSettings & settings) const
@@ -341,9 +363,12 @@ void SerializationSparse::serializeTextQuoted(const IColumn & column, size_t row
     nested->serializeTextQuoted(column_sparse.getValuesColumn(), column_sparse.getValueIndex(row_num), ostr, settings);
 }
 
-void SerializationSparse::deserializeTextQuoted(IColumn &, ReadBuffer &, const FormatSettings &) const
+void SerializationSparse::deserializeTextQuoted(IColumn & column, ReadBuffer & istr, const FormatSettings & settings) const
 {
-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Method 'deserializeTextQuoted' is not implemented for SerializationSparse");
+    deserialize(column, [&](auto & nested_column)
+    {
+        nested->deserializeTextQuoted(nested_column, istr, settings);
+    });
 }
 
 void SerializationSparse::serializeTextCSV(const IColumn & column, size_t row_num, WriteBuffer & ostr, const FormatSettings & settings) const
@@ -352,9 +377,12 @@ void SerializationSparse::serializeTextCSV(const IColumn & column, size_t row_nu
     nested->serializeTextCSV(column_sparse.getValuesColumn(), column_sparse.getValueIndex(row_num), ostr, settings);
 }
 
-void SerializationSparse::deserializeTextCSV(IColumn &, ReadBuffer &, const FormatSettings &) const
+void SerializationSparse::deserializeTextCSV(IColumn & column, ReadBuffer & istr, const FormatSettings & settings) const
 {
-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Method 'deserializeTextCSV' is not implemented for SerializationSparse");
+    deserialize(column, [&](auto & nested_column)
+    {
+        nested->deserializeTextCSV(nested_column, istr, settings);
+    });
 }
 
 void SerializationSparse::serializeText(const IColumn & column, size_t row_num, WriteBuffer & ostr, const FormatSettings & settings) const
@@ -363,9 +391,12 @@ void SerializationSparse::serializeText(const IColumn & column, size_t row_num,
     nested->serializeText(column_sparse.getValuesColumn(), column_sparse.getValueIndex(row_num), ostr, settings);
 }
 
-void SerializationSparse::deserializeWholeText(IColumn &, ReadBuffer &, const FormatSettings &) const
+void SerializationSparse::deserializeWholeText(IColumn & column, ReadBuffer & istr, const FormatSettings & settings) const
 {
-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Method 'deserializeWholeText' is not implemented for SerializationSparse");
+    deserialize(column, [&](auto & nested_column)
+    {
+        nested->deserializeWholeText(nested_column, istr, settings);
+    });
 }
 
 void SerializationSparse::serializeTextJSON(const IColumn & column, size_t row_num, WriteBuffer & ostr, const FormatSettings & settings) const
@@ -374,9 +405,12 @@ void SerializationSparse::serializeTextJSON(const IColumn & column, size_t row_n
     nested->serializeTextJSON(column_sparse.getValuesColumn(), column_sparse.getValueIndex(row_num), ostr, settings);
 }
 
-void SerializationSparse::deserializeTextJSON(IColumn &, ReadBuffer &, const FormatSettings &) const
+void SerializationSparse::deserializeTextJSON(IColumn & column, ReadBuffer & istr, const FormatSettings & settings) const
 {
-    throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Method 'deserializeTextJSON' is not implemented for SerializationSparse");
+    deserialize(column, [&](auto & nested_column)
+    {
+        nested->deserializeTextJSON(nested_column, istr, settings);
+    });
 }
 
 void SerializationSparse::serializeTextXML(const IColumn & column, size_t row_num, WriteBuffer & ostr, const FormatSettings & settings) const
diff --git a/src/DataTypes/Serializations/SerializationSparse.h b/src/DataTypes/Serializations/SerializationSparse.h
index a55856bacf0e..b31a006639b8 100644
--- a/src/DataTypes/Serializations/SerializationSparse.h
+++ b/src/DataTypes/Serializations/SerializationSparse.h
@@ -99,6 +99,9 @@ class SerializationSparse final : public ISerialization
         ColumnPtr create(const ColumnPtr & prev) const override;
     };
 
+    template <typename Reader>
+    void deserialize(IColumn & column, Reader && reader) const;
+
     SerializationPtr nested;
 };
 
diff --git a/src/Functions/materialize.cpp b/src/Functions/materialize.cpp
index 5cef610b60ab..e8a43dfc820f 100644
--- a/src/Functions/materialize.cpp
+++ b/src/Functions/materialize.cpp
@@ -7,7 +7,7 @@ namespace DB
 
 REGISTER_FUNCTION(Materialize)
 {
-    factory.registerFunction<FunctionMaterialize>();
+    factory.registerFunction<FunctionMaterialize<true>>();
 }
 
 }
diff --git a/src/Functions/materialize.h b/src/Functions/materialize.h
index 571391faba79..ac4a01d875e4 100644
--- a/src/Functions/materialize.h
+++ b/src/Functions/materialize.h
@@ -9,13 +9,14 @@ namespace DB
 
 /** materialize(x) - materialize the constant
   */
+template <bool remove_sparse>
 class FunctionMaterialize : public IFunction
 {
 public:
     static constexpr auto name = "materialize";
     static FunctionPtr create(ContextPtr)
     {
-        return std::make_shared<FunctionMaterialize>();
+        return std::make_shared<FunctionMaterialize<remove_sparse>>();
     }
 
     /// Get the function name.
@@ -55,7 +56,10 @@ class FunctionMaterialize : public IFunction
 
     ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t /*input_rows_count*/) const override
     {
-        return recursiveRemoveSparse(arguments[0].column->convertToFullColumnIfConst());
+        auto res = arguments[0].column->convertToFullColumnIfConst();
+        if constexpr (remove_sparse)
+            res = recursiveRemoveSparse(res);
+        return res;
     }
 
     bool hasInformationAboutMonotonicity() const override { return true; }
diff --git a/src/Interpreters/ActionsDAG.cpp b/src/Interpreters/ActionsDAG.cpp
index 44862344df00..5d99a63e2c4a 100644
--- a/src/Interpreters/ActionsDAG.cpp
+++ b/src/Interpreters/ActionsDAG.cpp
@@ -1433,16 +1433,21 @@ bool ActionsDAG::hasNonDeterministic() const
     return false;
 }
 
-void ActionsDAG::addMaterializingOutputActions()
+void ActionsDAG::addMaterializingOutputActions(bool materialize_sparse)
 {
     for (auto & output_node : outputs)
-        output_node = &materializeNode(*output_node);
+        output_node = &materializeNode(*output_node, materialize_sparse);
 }
 
-const ActionsDAG::Node & ActionsDAG::materializeNode(const Node & node)
+const ActionsDAG::Node & ActionsDAG::materializeNode(const Node & node, bool materialize_sparse)
 {
-    FunctionOverloadResolverPtr func_builder_materialize
-        = std::make_unique<FunctionToOverloadResolverAdaptor>(std::make_shared<FunctionMaterialize>());
+    FunctionPtr func_materialize;
+    if (materialize_sparse)
+        func_materialize = std::make_shared<FunctionMaterialize<true>>();
+    else
+        func_materialize = std::make_shared<FunctionMaterialize<false>>();
+
+    FunctionOverloadResolverPtr func_builder_materialize = std::make_unique<FunctionToOverloadResolverAdaptor>(std::move(func_materialize));
 
     const auto & name = node.result_name;
     const auto * func = &addFunction(func_builder_materialize, {&node}, {});
@@ -1469,7 +1474,7 @@ ActionsDAG ActionsDAG::makeConvertingActions(
     ActionsDAG actions_dag(source);
     NodeRawConstPtrs projection(num_result_columns);
 
-    FunctionOverloadResolverPtr func_builder_materialize = std::make_unique<FunctionToOverloadResolverAdaptor>(std::make_shared<FunctionMaterialize>());
+    FunctionOverloadResolverPtr func_builder_materialize = std::make_unique<FunctionToOverloadResolverAdaptor>(std::make_shared<FunctionMaterialize<false>>());
 
     std::unordered_map<std::string_view, std::list<size_t>> inputs;
     if (mode == MatchColumnsMode::Name)
@@ -1596,7 +1601,7 @@ ActionsDAG ActionsDAG::makeAddingColumnActions(ColumnWithTypeAndName column)
 {
     ActionsDAG adding_column_action;
     FunctionOverloadResolverPtr func_builder_materialize
-        = std::make_unique<FunctionToOverloadResolverAdaptor>(std::make_shared<FunctionMaterialize>());
+        = std::make_unique<FunctionToOverloadResolverAdaptor>(std::make_shared<FunctionMaterialize<true>>());
 
     auto column_name = column.name;
     const auto * column_node = &adding_column_action.addColumn(std::move(column));
diff --git a/src/Interpreters/ActionsDAG.h b/src/Interpreters/ActionsDAG.h
index 0d6b1ce0e047..746d12f6884b 100644
--- a/src/Interpreters/ActionsDAG.h
+++ b/src/Interpreters/ActionsDAG.h
@@ -282,14 +282,13 @@ class ActionsDAG
 
     /// For apply materialize() function for every output.
     /// Also add aliases so the result names remain unchanged.
-    void addMaterializingOutputActions();
+    void addMaterializingOutputActions(bool materialize_sparse);
 
     /// Apply materialize() function to node. Result node has the same name.
-    const Node & materializeNode(const Node & node);
+    const Node & materializeNode(const Node & node, bool materialize_sparse = true);
 
     enum class MatchColumnsMode : uint8_t
     {
-        /// Require same number of columns in source and result. Match columns by corresponding positions, regardless to names.
         Position,
         /// Find columns in source by their names. Allow excessive columns in source.
         Name,
diff --git a/src/Interpreters/BloomFilterHash.h b/src/Interpreters/BloomFilterHash.h
index 8248e9e44694..49450b5932b2 100644
--- a/src/Interpreters/BloomFilterHash.h
+++ b/src/Interpreters/BloomFilterHash.h
@@ -171,7 +171,7 @@ struct BloomFilterHash
         const auto * index_column = typeid_cast<const ColumnVector<Type> *>(column);
 
         if (unlikely(!index_column))
-            throw Exception(ErrorCodes::ILLEGAL_COLUMN, "Illegal column type was passed to the bloom filter index.");
+            throw Exception(ErrorCodes::ILLEGAL_COLUMN, "Illegal column {} was passed to the bloom filter index", column->getName());
 
         const typename ColumnVector<Type>::Container & vec_from = index_column->getData();
 
diff --git a/src/Interpreters/InterpreterInsertQuery.cpp b/src/Interpreters/InterpreterInsertQuery.cpp
index d7f9c338ab1c..1a2213bf4640 100644
--- a/src/Interpreters/InterpreterInsertQuery.cpp
+++ b/src/Interpreters/InterpreterInsertQuery.cpp
@@ -71,6 +71,7 @@ namespace Setting
     extern const SettingsBool use_concurrency_control;
     extern const SettingsSeconds lock_acquire_timeout;
     extern const SettingsUInt64 parallel_distributed_insert_select;
+    extern const SettingsBool enable_parsing_to_custom_serialization;
 }
 
 namespace ErrorCodes
@@ -563,11 +564,10 @@ QueryPipeline InterpreterInsertQuery::buildInsertSelectPipeline(ASTInsertQuery &
         return std::make_shared<ExpressionTransform>(in_header, actions);
     });
 
-    /// We need to convert Sparse columns to full, because it's destination storage
-    /// may not support it or may have different settings for applying Sparse serialization.
+    /// We need to convert Sparse columns to full if the destination storage doesn't support them.
     pipeline.addSimpleTransform([&](const Block & in_header) -> ProcessorPtr
     {
-        return std::make_shared<MaterializingTransform>(in_header);
+        return std::make_shared<MaterializingTransform>(in_header, !table->supportsSparseSerialization());
     });
 
     pipeline.addSimpleTransform([&](const Block & in_header) -> ProcessorPtr
@@ -737,11 +737,14 @@ QueryPipeline InterpreterInsertQuery::buildInsertPipeline(ASTInsertQuery & query
 
     if (query.hasInlinedData() && !async_insert)
     {
-        /// can execute without additional data
         auto format = getInputFormatFromASTInsertQuery(query_ptr, true, query_sample_block, getContext(), nullptr);
-        for (auto && buffer : owned_buffers)
+
+        for (auto & buffer : owned_buffers)
             format->addBuffer(std::move(buffer));
 
+        if (settings[Setting::enable_parsing_to_custom_serialization])
+            format->setSerializationHints(table->getSerializationHints());
+
         auto pipe = getSourceFromInputFormat(query_ptr, std::move(format), getContext(), nullptr);
         pipeline.complete(std::move(pipe));
     }
diff --git a/src/Interpreters/Squashing.cpp b/src/Interpreters/Squashing.cpp
index c656a1a797b0..8122800f882f 100644
--- a/src/Interpreters/Squashing.cpp
+++ b/src/Interpreters/Squashing.cpp
@@ -1,8 +1,9 @@
 #include <vector>
 #include <Interpreters/Squashing.h>
-#include "Common/Logger.h"
-#include "Common/logger_useful.h"
 #include <Common/CurrentThread.h>
+#include <Common/Logger.h>
+#include <Common/logger_useful.h>
+#include <Columns/ColumnSparse.h>
 #include <base/defines.h>
 
 namespace DB
@@ -116,7 +117,7 @@ Chunk Squashing::squash(std::vector<Chunk> && input_chunks, Chunk::ChunkInfoColl
         return result;
     }
 
-    std::vector<IColumn::MutablePtr> mutable_columns = {};
+    std::vector<IColumn::MutablePtr> mutable_columns;
     size_t rows = 0;
     for (const Chunk & chunk : input_chunks)
         rows += chunk.getNumRows();
@@ -130,8 +131,11 @@ Chunk Squashing::squash(std::vector<Chunk> && input_chunks, Chunk::ChunkInfoColl
     }
 
     size_t num_columns = mutable_columns.size();
+
     /// Collect the list of source columns for each column.
-    std::vector<Columns> source_columns_list(num_columns, Columns{});
+    std::vector<Columns> source_columns_list(num_columns);
+    std::vector<UInt8> have_same_serialization(num_columns, true);
+
     for (size_t i = 0; i != num_columns; ++i)
         source_columns_list[i].reserve(input_chunks.size() - 1);
 
@@ -139,11 +143,21 @@ Chunk Squashing::squash(std::vector<Chunk> && input_chunks, Chunk::ChunkInfoColl
     {
         auto columns = input_chunks[i].detachColumns();
         for (size_t j = 0; j != num_columns; ++j)
+        {
+            have_same_serialization[j] &= ISerialization::getKind(*columns[j]) == ISerialization::getKind(*mutable_columns[j]);
             source_columns_list[j].emplace_back(std::move(columns[j]));
+        }
     }
 
     for (size_t i = 0; i != num_columns; ++i)
     {
+        if (!have_same_serialization[i])
+        {
+            mutable_columns[i] = recursiveRemoveSparse(std::move(mutable_columns[i]))->assumeMutable();
+            for (auto & column : source_columns_list[i])
+                column = recursiveRemoveSparse(column);
+        }
+
         /// We know all the data we will insert in advance and can make all necessary pre-allocations.
         mutable_columns[i]->prepareForSquashing(source_columns_list[i]);
         for (auto & source_column : source_columns_list[i])
diff --git a/src/Interpreters/addMissingDefaults.cpp b/src/Interpreters/addMissingDefaults.cpp
index 27d79e86622f..173478332f3d 100644
--- a/src/Interpreters/addMissingDefaults.cpp
+++ b/src/Interpreters/addMissingDefaults.cpp
@@ -85,7 +85,7 @@ ActionsDAG addMissingDefaults(
 
     /// Removes unused columns and reorders result.
     actions.removeUnusedActions(required_columns.getNames(), false);
-    actions.addMaterializingOutputActions();
+    actions.addMaterializingOutputActions(/*materialize_sparse=*/ false);
 
     return actions;
 }
diff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp
index a96350c7ca34..14a67521a100 100644
--- a/src/Interpreters/executeQuery.cpp
+++ b/src/Interpreters/executeQuery.cpp
@@ -1247,7 +1247,6 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
                 {
                     if (!interpreter->supportsTransactions())
                         throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Transactions are not supported for this type of query ({})", ast->getID());
-
                 }
 
                 // InterpreterSelectQueryAnalyzer does not build QueryPlan in the constructor.
diff --git a/src/Processors/Formats/IInputFormat.h b/src/Processors/Formats/IInputFormat.h
index 713c1089d289..64b289170d2d 100644
--- a/src/Processors/Formats/IInputFormat.h
+++ b/src/Processors/Formats/IInputFormat.h
@@ -58,6 +58,10 @@ class IInputFormat : public SourceWithKeyCondition
     /// parallel parsing before creating this parser.
     virtual void setRowsReadBefore(size_t /*rows*/) {}
 
+    /// Sets the serialization hints for the columns. It allows to create columns
+    /// in custom serializations (e.g. Sparse) for parsing and avoid extra conversion.
+    virtual void setSerializationHints(const SerializationInfoByName & /*hints*/) {}
+
     void addBuffer(std::unique_ptr<ReadBuffer> buffer) { owned_buffers.emplace_back(std::move(buffer)); }
 
     void setErrorsLogger(const InputFormatErrorsLoggerPtr & errors_logger_) { errors_logger = errors_logger_; }
diff --git a/src/Processors/Formats/IRowInputFormat.cpp b/src/Processors/Formats/IRowInputFormat.cpp
index 0b6c81923dbe..b8e8822e6485 100644
--- a/src/Processors/Formats/IRowInputFormat.cpp
+++ b/src/Processors/Formats/IRowInputFormat.cpp
@@ -103,7 +103,10 @@ Chunk IRowInputFormat::read()
     const Block & header = getPort().getHeader();
 
     size_t num_columns = header.columns();
-    MutableColumns columns = header.cloneEmptyColumns();
+    MutableColumns columns(num_columns);
+
+    for (size_t i = 0; i < num_columns; ++i)
+        columns[i] = header.getByPosition(i).type->createColumn(*serializations[i]);
 
     block_missing_values.clear();
 
@@ -266,5 +269,10 @@ size_t IRowInputFormat::countRows(size_t)
     throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Method countRows is not implemented for input format {}", getName());
 }
 
+void IRowInputFormat::setSerializationHints(const SerializationInfoByName & hints)
+{
+    serializations = getPort().getHeader().getSerializations(hints);
+}
+
 
 }
diff --git a/src/Processors/Formats/IRowInputFormat.h b/src/Processors/Formats/IRowInputFormat.h
index f8796df86049..c6786f45ecb2 100644
--- a/src/Processors/Formats/IRowInputFormat.h
+++ b/src/Processors/Formats/IRowInputFormat.h
@@ -5,6 +5,7 @@
 #include <Processors/Formats/IInputFormat.h>
 #include <QueryPipeline/SizeLimits.h>
 #include <Poco/Timespan.h>
+#include <DataTypes/Serializations/SerializationInfo.h>
 
 class Stopwatch;
 
@@ -84,6 +85,7 @@ class IRowInputFormat : public IInputFormat
     size_t getApproxBytesReadForChunk() const override { return approx_bytes_read_for_chunk; }
 
     void setRowsReadBefore(size_t rows) override { total_rows = rows; }
+    void setSerializationHints(const SerializationInfoByName & hints) override;
 
     Serializations serializations;
 
diff --git a/src/Processors/Formats/Impl/ParallelParsingInputFormat.cpp b/src/Processors/Formats/Impl/ParallelParsingInputFormat.cpp
index 447adb1ed48f..faf6bf81869b 100644
--- a/src/Processors/Formats/Impl/ParallelParsingInputFormat.cpp
+++ b/src/Processors/Formats/Impl/ParallelParsingInputFormat.cpp
@@ -92,6 +92,7 @@ void ParallelParsingInputFormat::parserThreadFunction(ThreadGroupPtr thread_grou
         InputFormatPtr input_format = internal_parser_creator(read_buffer);
         input_format->setRowsReadBefore(unit.offset);
         input_format->setErrorsLogger(errors_logger);
+        input_format->setSerializationHints(serialization_hints);
         InternalParser parser(input_format);
 
         unit.chunk_ext.chunk.clear();
diff --git a/src/Processors/Formats/Impl/ParallelParsingInputFormat.h b/src/Processors/Formats/Impl/ParallelParsingInputFormat.h
index b97bf5213e60..e3753385ae8b 100644
--- a/src/Processors/Formats/Impl/ParallelParsingInputFormat.h
+++ b/src/Processors/Formats/Impl/ParallelParsingInputFormat.h
@@ -129,6 +129,11 @@ class ParallelParsingInputFormat : public IInputFormat
         return last_block_missing_values;
     }
 
+    void setSerializationHints(const SerializationInfoByName & hints) override
+    {
+        serialization_hints = hints;
+    }
+
     size_t getApproxBytesReadForChunk() const override { return last_approx_bytes_read_for_chunk; }
 
     String getName() const final { return "ParallelParsingBlockInputFormat"; }
@@ -207,6 +212,7 @@ class ParallelParsingInputFormat : public IInputFormat
 
     BlockMissingValues last_block_missing_values;
     size_t last_approx_bytes_read_for_chunk = 0;
+    SerializationInfoByName serialization_hints;
 
     /// Non-atomic because it is used in one thread.
     std::optional<size_t> next_block_in_current_unit;
diff --git a/src/Processors/Transforms/MaterializingTransform.cpp b/src/Processors/Transforms/MaterializingTransform.cpp
index 9ae80e21a686..771718e5cede 100644
--- a/src/Processors/Transforms/MaterializingTransform.cpp
+++ b/src/Processors/Transforms/MaterializingTransform.cpp
@@ -5,8 +5,11 @@
 namespace DB
 {
 
-MaterializingTransform::MaterializingTransform(const Block & header)
-    : ISimpleTransform(header, materializeBlock(header), false) {}
+MaterializingTransform::MaterializingTransform(const Block & header, bool remove_sparse_)
+    : ISimpleTransform(header, materializeBlock(header), false)
+    , remove_sparse(remove_sparse_)
+{
+}
 
 void MaterializingTransform::transform(Chunk & chunk)
 {
@@ -14,7 +17,11 @@ void MaterializingTransform::transform(Chunk & chunk)
     auto columns = chunk.detachColumns();
 
     for (auto & col : columns)
-        col = recursiveRemoveSparse(col->convertToFullColumnIfConst());
+    {
+        col = col->convertToFullColumnIfConst();
+        if (remove_sparse)
+            col = recursiveRemoveSparse(col);
+    }
 
     chunk.setColumns(std::move(columns), num_rows);
 }
diff --git a/src/Processors/Transforms/MaterializingTransform.h b/src/Processors/Transforms/MaterializingTransform.h
index 5ecd85224268..d384083a50d5 100644
--- a/src/Processors/Transforms/MaterializingTransform.h
+++ b/src/Processors/Transforms/MaterializingTransform.h
@@ -8,12 +8,13 @@ namespace DB
 class MaterializingTransform : public ISimpleTransform
 {
 public:
-    explicit MaterializingTransform(const Block & header);
+    explicit MaterializingTransform(const Block & header, bool remove_sparse_ = true);
 
     String getName() const override { return "MaterializingTransform"; }
 
 protected:
     void transform(Chunk & chunk) override;
+    bool remove_sparse;
 };
 
 }
diff --git a/src/Processors/Transforms/getSourceFromASTInsertQuery.cpp b/src/Processors/Transforms/getSourceFromASTInsertQuery.cpp
index 4bb3b88886e2..1f6474da7d00 100644
--- a/src/Processors/Transforms/getSourceFromASTInsertQuery.cpp
+++ b/src/Processors/Transforms/getSourceFromASTInsertQuery.cpp
@@ -66,8 +66,7 @@ InputFormatPtr getInputFormatFromASTInsertQuery(
         : std::make_unique<EmptyReadBuffer>();
 
     /// Create a source from input buffer using format from query
-    auto source
-        = context->getInputFormat(ast_insert_query->format, *input_buffer, header, context->getSettingsRef()[Setting::max_insert_block_size]);
+    auto source = context->getInputFormat(ast_insert_query->format, *input_buffer, header, context->getSettingsRef()[Setting::max_insert_block_size]);
     source->addBuffer(std::move(input_buffer));
     return source;
 }
diff --git a/src/Storages/IStorage.h b/src/Storages/IStorage.h
index 07058dfb5dff..0dc486342821 100644
--- a/src/Storages/IStorage.h
+++ b/src/Storages/IStorage.h
@@ -18,6 +18,7 @@
 #include <Common/Exception.h>
 #include <Common/RWLock.h>
 #include <Common/TypePromotion.h>
+#include <DataTypes/Serializations/SerializationInfo.h>
 
 #include <optional>
 
@@ -269,6 +270,9 @@ class IStorage : public std::enable_shared_from_this<IStorage>, public TypePromo
     /// because those are internally translated into 'ALTER UDPATE' mutations.
     virtual bool supportsDelete() const { return false; }
 
+    /// Returns true if storage can store columns in sparse serialization.
+    virtual bool supportsSparseSerialization() const { return false; }
+
     /// Return true if the trivial count query could be optimized without reading the data at all
     /// in totalRows() or totalRowsByPartitionPredicate() methods or with optimized reading in read() method.
     /// 'storage_snapshot' may be nullptr.
@@ -277,6 +281,9 @@ class IStorage : public std::enable_shared_from_this<IStorage>, public TypePromo
         return false;
     }
 
+    /// Returns hints for serialization of columns accorsing to statistics accumulated by storage.
+    virtual SerializationInfoByName getSerializationHints() const { return {}; }
+
 private:
     StorageID storage_id;
 
diff --git a/src/Storages/MergeTree/IMergeTreeDataPartWriter.cpp b/src/Storages/MergeTree/IMergeTreeDataPartWriter.cpp
index c87f66b64f33..4f42a7e91226 100644
--- a/src/Storages/MergeTree/IMergeTreeDataPartWriter.cpp
+++ b/src/Storages/MergeTree/IMergeTreeDataPartWriter.cpp
@@ -1,5 +1,6 @@
 #include <Storages/MergeTree/IMergeTreeDataPartWriter.h>
 #include <Common/MemoryTrackerBlockerInThread.h>
+#include <Columns/ColumnSparse.h>
 
 namespace DB
 {
@@ -11,13 +12,14 @@ namespace ErrorCodes
 }
 
 
-Block getBlockAndPermute(const Block & block, const Names & names, const IColumn::Permutation * permutation)
+Block getIndexBlockAndPermute(const Block & block, const Names & names, const IColumn::Permutation * permutation)
 {
     Block result;
     for (size_t i = 0, size = names.size(); i < size; ++i)
     {
-        const auto & name = names[i];
-        result.insert(i, block.getByName(name));
+        auto src_column = block.getByName(names[i]);
+        src_column.column = recursiveRemoveSparse(src_column.column);
+        result.insert(i, src_column);
 
         /// Reorder primary key columns in advance and add them to `primary_key_columns`.
         if (permutation)
diff --git a/src/Storages/MergeTree/IMergeTreeDataPartWriter.h b/src/Storages/MergeTree/IMergeTreeDataPartWriter.h
index 2fdb0794789a..eb51a1b29224 100644
--- a/src/Storages/MergeTree/IMergeTreeDataPartWriter.h
+++ b/src/Storages/MergeTree/IMergeTreeDataPartWriter.h
@@ -16,7 +16,7 @@ namespace DB
 struct MergeTreeSettings;
 using MergeTreeSettingsPtr = std::shared_ptr<const MergeTreeSettings>;
 
-Block getBlockAndPermute(const Block & block, const Names & names, const IColumn::Permutation * permutation);
+Block getIndexBlockAndPermute(const Block & block, const Names & names, const IColumn::Permutation * permutation);
 
 Block permuteBlockIfNeeded(const Block & block, const IColumn::Permutation * permutation);
 
diff --git a/src/Storages/MergeTree/IMergeTreeReader.cpp b/src/Storages/MergeTree/IMergeTreeReader.cpp
index 1f46d6b8e1b2..b2f18f08f416 100644
--- a/src/Storages/MergeTree/IMergeTreeReader.cpp
+++ b/src/Storages/MergeTree/IMergeTreeReader.cpp
@@ -172,7 +172,7 @@ void IMergeTreeReader::evaluateMissingDefaults(Block additional_columns, Columns
 
         if (dag)
         {
-            dag->addMaterializingOutputActions();
+            dag->addMaterializingOutputActions(/*materialize_sparse=*/ false);
             auto actions = std::make_shared<ExpressionActions>(
                 std::move(*dag),
                 ExpressionActionsSettings::fromSettings(data_part_info_for_read->getContext()->getSettingsRef()));
diff --git a/src/Storages/MergeTree/MergeTask.cpp b/src/Storages/MergeTree/MergeTask.cpp
index 4dd8400ec962..0be1e5087032 100644
--- a/src/Storages/MergeTree/MergeTask.cpp
+++ b/src/Storages/MergeTree/MergeTask.cpp
@@ -995,7 +995,7 @@ MergeTask::VerticalMergeRuntimeContext::PreparedColumnPipeline MergeTask::Vertic
             indexes_to_recalc = MergeTreeIndexFactory::instance().getMany(indexes_it->second);
 
             auto indices_expression_dag = indexes_it->second.getSingleExpressionForIndices(global_ctx->metadata_snapshot->getColumns(), global_ctx->data->getContext())->getActionsDAG().clone();
-            indices_expression_dag.addMaterializingOutputActions(); /// Const columns cannot be written without materialization.
+            indices_expression_dag.addMaterializingOutputActions(/*materialize_sparse=*/ true); /// Const columns cannot be written without materialization.
             auto calculate_indices_expression_step = std::make_unique<ExpressionStep>(
                 merge_column_query_plan.getCurrentDataStream(),
                 std::move(indices_expression_dag));
@@ -1719,7 +1719,7 @@ void MergeTask::ExecuteAndFinalizeHorizontalPart::createMergedStream() const
     if (!global_ctx->merging_skip_indexes.empty())
     {
         auto indices_expression_dag = global_ctx->merging_skip_indexes.getSingleExpressionForIndices(global_ctx->metadata_snapshot->getColumns(), global_ctx->data->getContext())->getActionsDAG().clone();
-        indices_expression_dag.addMaterializingOutputActions(); /// Const columns cannot be written without materialization.
+        indices_expression_dag.addMaterializingOutputActions(/*materialize_sparse=*/ true); /// Const columns cannot be written without materialization.
         auto calculate_indices_expression_step = std::make_unique<ExpressionStep>(
             merge_parts_query_plan.getCurrentDataStream(),
             std::move(indices_expression_dag));
diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp
index c728ffd63d49..040b696af296 100644
--- a/src/Storages/MergeTree/MergeTreeData.cpp
+++ b/src/Storages/MergeTree/MergeTreeData.cpp
@@ -1904,6 +1904,7 @@ void MergeTreeData::loadDataParts(bool skip_sanity_checks, std::optional<std::un
     if (num_parts == 0 && unexpected_parts_to_load.empty())
     {
         resetObjectColumnsFromActiveParts(part_lock);
+        resetSerializationHints(part_lock);
         LOG_DEBUG(log, "There are no data parts");
         return;
     }
@@ -1950,6 +1951,7 @@ void MergeTreeData::loadDataParts(bool skip_sanity_checks, std::optional<std::un
             part->renameToDetached("broken-on-start"); /// detached parts must not have '_' in prefixes
 
     resetObjectColumnsFromActiveParts(part_lock);
+    resetSerializationHints(part_lock);
     calculateColumnAndSecondaryIndexSizesImpl();
 
     PartLoadingTreeNodes unloaded_parts;
@@ -6908,6 +6910,8 @@ MergeTreeData::DataPartsVector MergeTreeData::Transaction::commit(DataPartsLock
                 }
             }
 
+            data.updateSerializationHints(precommitted_parts, total_covered_parts, parts_lock);
+
             if (reduce_parts == 0)
             {
                 for (const auto & part : precommitted_parts)
@@ -8571,6 +8575,66 @@ void MergeTreeData::updateObjectColumns(const DataPartPtr & part, const DataPart
     DB::updateObjectColumns(object_columns, columns, part->getColumns());
 }
 
+template <typename DataPartPtr>
+static void updateSerializationHintsForPart(const DataPartPtr & part, const ColumnsDescription & storage_columns, SerializationInfoByName & hints, bool remove)
+{
+    const auto & part_columns = part->getColumnsDescription();
+    for (const auto & [name, info] : part->getSerializationInfos())
+    {
+        auto new_hint = hints.tryGet(name);
+        if (!new_hint)
+            continue;
+
+        /// Structure may change after alter. Do not add info for such items.
+        /// Instead it will be updated on commit of the result part of alter.
+        if (part_columns.tryGetPhysical(name) != storage_columns.tryGetPhysical(name))
+            continue;
+
+        chassert(new_hint->structureEquals(*info));
+        if (remove)
+            new_hint->remove(*info);
+        else
+            new_hint->add(*info);
+    }
+}
+
+void MergeTreeData::resetSerializationHints(const DataPartsLock & /*lock*/)
+{
+    SerializationInfo::Settings settings =
+    {
+        .ratio_of_defaults_for_sparse = getSettings()->ratio_of_defaults_for_sparse_serialization,
+        .choose_kind = true,
+    };
+
+    const auto & storage_columns = getInMemoryMetadataPtr()->getColumns();
+    serialization_hints = SerializationInfoByName(storage_columns.getAllPhysical(), settings);
+    auto range = getDataPartsStateRange(DataPartState::Active);
+
+    for (const auto & part : range)
+        updateSerializationHintsForPart(part, storage_columns, serialization_hints, false);
+}
+
+template <typename AddedParts, typename RemovedParts>
+void MergeTreeData::updateSerializationHints(const AddedParts & added_parts, const RemovedParts & removed_parts, const DataPartsLock & /*lock*/)
+{
+    const auto & storage_columns = getInMemoryMetadataPtr()->getColumns();
+
+    for (const auto & part : added_parts)
+        updateSerializationHintsForPart(part, storage_columns, serialization_hints, false);
+
+    for (const auto & part : removed_parts)
+        updateSerializationHintsForPart(part, storage_columns, serialization_hints, true);
+}
+
+SerializationInfoByName MergeTreeData::getSerializationHints() const
+{
+    auto lock = lockParts();
+    SerializationInfoByName res;
+    for (const auto & [name, info] : serialization_hints)
+        res.emplace(name, info->clone());
+    return res;
+}
+
 bool MergeTreeData::supportsTrivialCountOptimization(const StorageSnapshotPtr & storage_snapshot, ContextPtr query_context) const
 {
     if (hasLightweightDeletedMask())
diff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h
index 5edd24db40d5..7a9730e8627c 100644
--- a/src/Storages/MergeTree/MergeTreeData.h
+++ b/src/Storages/MergeTree/MergeTreeData.h
@@ -441,6 +441,7 @@ class MergeTreeData : public IStorage, public WithMutableContext
 
     bool supportsDynamicSubcolumnsDeprecated() const override { return true; }
     bool supportsDynamicSubcolumns() const override { return true; }
+    bool supportsSparseSerialization() const override { return true; }
 
     bool supportsLightweightDelete() const override;
 
@@ -1242,6 +1243,11 @@ class MergeTreeData : public IStorage, public WithMutableContext
     /// protected by @data_parts_mutex.
     ColumnsDescription object_columns;
 
+    /// Serialization info accumulated among all active parts.
+    /// It changes only when set of parts is changed and is
+    /// protected by @data_parts_mutex.
+    SerializationInfoByName serialization_hints;
+
     MergeTreePartsMover parts_mover;
 
     /// Executors are common for both ReplicatedMergeTree and plain MergeTree
@@ -1530,6 +1536,13 @@ class MergeTreeData : public IStorage, public WithMutableContext
     void resetObjectColumnsFromActiveParts(const DataPartsLock & lock);
     void updateObjectColumns(const DataPartPtr & part, const DataPartsLock & lock);
 
+    void resetSerializationHints(const DataPartsLock & lock);
+
+    template <typename AddedParts, typename RemovedParts>
+    void updateSerializationHints(const AddedParts & added_parts, const RemovedParts & removed_parts, const DataPartsLock & lock);
+
+    SerializationInfoByName getSerializationHints() const override;
+
     /** A structure that explicitly represents a "merge tree" of parts
      *  which is implicitly presented by min-max block numbers and levels of parts.
      *  The children of node are parts which are covered by parent part.
diff --git a/src/Storages/MergeTree/MergeTreeDataPartWriterCompact.cpp b/src/Storages/MergeTree/MergeTreeDataPartWriterCompact.cpp
index f4be7619fc83..a859172023fa 100644
--- a/src/Storages/MergeTree/MergeTreeDataPartWriterCompact.cpp
+++ b/src/Storages/MergeTree/MergeTreeDataPartWriterCompact.cpp
@@ -213,11 +213,11 @@ void MergeTreeDataPartWriterCompact::writeDataBlockPrimaryIndexAndSkipIndices(co
 
     if (settings.rewrite_primary_key)
     {
-        Block primary_key_block = getBlockAndPermute(block, metadata_snapshot->getPrimaryKeyColumns(), nullptr);
+        Block primary_key_block = getIndexBlockAndPermute(block, metadata_snapshot->getPrimaryKeyColumns(), nullptr);
         calculateAndSerializePrimaryIndex(primary_key_block, granules_to_write);
     }
 
-    Block skip_indices_block = getBlockAndPermute(block, getSkipIndicesColumns(), nullptr);
+    Block skip_indices_block = getIndexBlockAndPermute(block, getSkipIndicesColumns(), nullptr);
     calculateAndSerializeSkipIndices(skip_indices_block, granules_to_write);
 }
 
diff --git a/src/Storages/MergeTree/MergeTreeDataPartWriterWide.cpp b/src/Storages/MergeTree/MergeTreeDataPartWriterWide.cpp
index f050accd7a1f..04e07a0588a7 100644
--- a/src/Storages/MergeTree/MergeTreeDataPartWriterWide.cpp
+++ b/src/Storages/MergeTree/MergeTreeDataPartWriterWide.cpp
@@ -296,9 +296,9 @@ void MergeTreeDataPartWriterWide::write(const Block & block, const IColumn::Perm
     auto offset_columns = written_offset_columns ? *written_offset_columns : WrittenOffsetColumns{};
     Block primary_key_block;
     if (settings.rewrite_primary_key)
-        primary_key_block = getBlockAndPermute(block, metadata_snapshot->getPrimaryKeyColumns(), permutation);
+        primary_key_block = getIndexBlockAndPermute(block, metadata_snapshot->getPrimaryKeyColumns(), permutation);
 
-    Block skip_indexes_block = getBlockAndPermute(block, getSkipIndicesColumns(), permutation);
+    Block skip_indexes_block = getIndexBlockAndPermute(block, getSkipIndicesColumns(), permutation);
 
     auto it = columns_list.begin();
     for (size_t i = 0; i < columns_list.size(); ++i, ++it)
diff --git a/src/Storages/MergeTree/MergeTreeDataWriter.cpp b/src/Storages/MergeTree/MergeTreeDataWriter.cpp
index ed68200041bf..130d9ca8f6a2 100644
--- a/src/Storages/MergeTree/MergeTreeDataWriter.cpp
+++ b/src/Storages/MergeTree/MergeTreeDataWriter.cpp
@@ -577,6 +577,13 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeTempPartImpl(
     SerializationInfoByName infos(columns, settings);
     infos.add(block);
 
+    for (const auto & [column_name, _] : columns)
+    {
+        auto & column = block.getByName(column_name);
+        if (column.column->isSparse() && infos.getKind(column_name) != ISerialization::Kind::SPARSE)
+            column.column = recursiveRemoveSparse(column.column);
+    }
+
     new_data_part->setColumns(columns, infos, metadata_snapshot->getMetadataVersion());
     new_data_part->rows_count = block.rows();
     new_data_part->existing_rows_count = block.rows();
diff --git a/src/Storages/MergeTree/MergeTreeReadTask.h b/src/Storages/MergeTree/MergeTreeReadTask.h
index e90a07e0b558..748babb5b4c7 100644
--- a/src/Storages/MergeTree/MergeTreeReadTask.h
+++ b/src/Storages/MergeTree/MergeTreeReadTask.h
@@ -66,7 +66,7 @@ struct MergeTreeReadTaskInfo
     MergeTreeReadTaskColumns task_columns;
     /// Shared initialized size predictor. It is copied for each new task.
     MergeTreeBlockSizePredictorPtr shared_size_predictor;
-    /// TODO: comment
+    /// Shared constant fields for virtual columns.
     VirtualFields const_virtual_fields;
     /// The amount of data to read per task based on size of the queried columns.
     size_t min_marks_per_task = 0;
diff --git a/src/Storages/ObjectStorage/DataLakes/IStorageDataLake.h b/src/Storages/ObjectStorage/DataLakes/IStorageDataLake.h
index a17fd1632536..6dff60aeaa9c 100644
--- a/src/Storages/ObjectStorage/DataLakes/IStorageDataLake.h
+++ b/src/Storages/ObjectStorage/DataLakes/IStorageDataLake.h
@@ -144,7 +144,7 @@ class IStorageDataLake final : public StorageObjectStorage
         bool supports_subset_of_columns,
         ContextPtr local_context) override
     {
-        auto info = DB::prepareReadingFromFormat(requested_columns, storage_snapshot, supports_subset_of_columns);
+        auto info = DB::prepareReadingFromFormat(requested_columns, storage_snapshot, local_context, supports_subset_of_columns);
         if (!current_metadata)
         {
             Storage::updateConfiguration(local_context);
diff --git a/src/Storages/ObjectStorage/StorageObjectStorage.cpp b/src/Storages/ObjectStorage/StorageObjectStorage.cpp
index bc27820707cc..040ce8db51de 100644
--- a/src/Storages/ObjectStorage/StorageObjectStorage.cpp
+++ b/src/Storages/ObjectStorage/StorageObjectStorage.cpp
@@ -247,9 +247,9 @@ ReadFromFormatInfo StorageObjectStorage::prepareReadingFromFormat(
     const Strings & requested_columns,
     const StorageSnapshotPtr & storage_snapshot,
     bool supports_subset_of_columns,
-    ContextPtr /* local_context */)
+    ContextPtr local_context)
 {
-    return DB::prepareReadingFromFormat(requested_columns, storage_snapshot, supports_subset_of_columns);
+    return DB::prepareReadingFromFormat(requested_columns, storage_snapshot, local_context, supports_subset_of_columns);
 }
 
 void StorageObjectStorage::read(
diff --git a/src/Storages/ObjectStorage/StorageObjectStorageSource.cpp b/src/Storages/ObjectStorage/StorageObjectStorageSource.cpp
index 641b43e57d6d..0b7106de9498 100644
--- a/src/Storages/ObjectStorage/StorageObjectStorageSource.cpp
+++ b/src/Storages/ObjectStorage/StorageObjectStorageSource.cpp
@@ -377,6 +377,8 @@ StorageObjectStorageSource::ReaderHolder StorageObjectStorageSource::createReade
             compression_method,
             need_only_count);
 
+        input_format->setSerializationHints(read_from_format_info.serialization_hints);
+
         if (key_condition_)
             input_format->setKeyCondition(key_condition_);
 
diff --git a/src/Storages/ObjectStorageQueue/StorageObjectStorageQueue.cpp b/src/Storages/ObjectStorageQueue/StorageObjectStorageQueue.cpp
index 250a0deec4fe..94ca07eec166 100644
--- a/src/Storages/ObjectStorageQueue/StorageObjectStorageQueue.cpp
+++ b/src/Storages/ObjectStorageQueue/StorageObjectStorageQueue.cpp
@@ -299,7 +299,7 @@ void StorageObjectStorageQueue::read(
     }
 
     auto this_ptr = std::static_pointer_cast<StorageObjectStorageQueue>(shared_from_this());
-    auto read_from_format_info = prepareReadingFromFormat(column_names, storage_snapshot, supportsSubsetOfColumns(local_context));
+    auto read_from_format_info = prepareReadingFromFormat(column_names, storage_snapshot, local_context, supportsSubsetOfColumns(local_context));
 
     auto reading = std::make_unique<ReadFromObjectStorageQueue>(
         column_names,
@@ -460,6 +460,7 @@ bool StorageObjectStorageQueue::streamToViews()
         auto read_from_format_info = prepareReadingFromFormat(
             block_io.pipeline.getHeader().getNames(),
             storage_snapshot,
+            queue_context,
             supportsSubsetOfColumns(queue_context));
 
         Pipes pipes;
diff --git a/src/Storages/StorageFile.cpp b/src/Storages/StorageFile.cpp
index 1d846b6bb0f5..46f4800b4977 100644
--- a/src/Storages/StorageFile.cpp
+++ b/src/Storages/StorageFile.cpp
@@ -99,6 +99,7 @@ namespace Setting
     extern const SettingsLocalFSReadMethod storage_file_read_method;
     extern const SettingsBool use_cache_for_count_from_files;
     extern const SettingsInt64 zstd_window_log_max;
+    extern const SettingsBool enable_parsing_to_custom_serialization;
 }
 
 namespace ErrorCodes
@@ -1136,7 +1137,6 @@ void StorageFile::setStorageMetadata(CommonArguments args)
     setInMemoryMetadata(storage_metadata);
 }
 
-
 static std::chrono::seconds getLockTimeout(const ContextPtr & context)
 {
     const Settings & settings = context->getSettingsRef();
@@ -1209,6 +1209,7 @@ StorageFileSource::StorageFileSource(
     , requested_columns(info.requested_columns)
     , requested_virtual_columns(info.requested_virtual_columns)
     , block_for_format(info.format_header)
+    , serialization_hints(info.serialization_hints)
     , max_block_size(max_block_size_)
     , need_only_count(need_only_count_)
 {
@@ -1439,6 +1440,8 @@ Chunk StorageFileSource::generate()
                 storage->format_name, *read_buf, block_for_format, getContext(), max_block_size, storage->format_settings,
                 max_parsing_threads, std::nullopt, /*is_remote_fs*/ false, CompressionMethod::None, need_only_count);
 
+            input_format->setSerializationHints(serialization_hints);
+
             if (key_condition)
                 input_format->setKeyCondition(key_condition);
 
@@ -1630,7 +1633,7 @@ void StorageFile::read(
 
     auto this_ptr = std::static_pointer_cast<StorageFile>(shared_from_this());
 
-    auto read_from_format_info = prepareReadingFromFormat(column_names, storage_snapshot, supportsSubsetOfColumns(context));
+    auto read_from_format_info = prepareReadingFromFormat(column_names, storage_snapshot, context, supportsSubsetOfColumns(context));
     bool need_only_count = (query_info.optimize_trivial_count || read_from_format_info.requested_columns.empty())
         && context->getSettingsRef()[Setting::optimize_count_from_files];
 
diff --git a/src/Storages/StorageFile.h b/src/Storages/StorageFile.h
index bb969c1877c8..6b21353f1614 100644
--- a/src/Storages/StorageFile.h
+++ b/src/Storages/StorageFile.h
@@ -296,6 +296,7 @@ class StorageFileSource : public SourceWithKeyCondition, WithContext
     NamesAndTypesList requested_columns;
     NamesAndTypesList requested_virtual_columns;
     Block block_for_format;
+    SerializationInfoByName serialization_hints;
 
     UInt64 max_block_size;
 
diff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp
index c921adaf2fd7..e5fc8e1a3b94 100644
--- a/src/Storages/StorageMergeTree.cpp
+++ b/src/Storages/StorageMergeTree.cpp
@@ -400,17 +400,18 @@ void StorageMergeTree::alter(
 
             DatabaseCatalog::instance().getDatabase(table_id.database_name)->alterTable(local_context, table_id, new_metadata);
 
+            {
+                /// Reset Object columns, because column of type
+                /// Object may be added or dropped by alter.
+                auto parts_lock = lockParts();
+                resetObjectColumnsFromActiveParts(parts_lock);
+                resetSerializationHints(parts_lock);
+            }
+
             if (!maybe_mutation_commands.empty())
                 mutation_version = startMutation(maybe_mutation_commands, local_context);
         }
 
-        {
-            /// Reset Object columns, because column of type
-            /// Object may be added or dropped by alter.
-            auto parts_lock = lockParts();
-            resetObjectColumnsFromActiveParts(parts_lock);
-        }
-
         if (!maybe_mutation_commands.empty() && query_settings[Setting::alter_sync] > 0)
             waitForMutation(mutation_version, false);
     }
diff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp
index 67924fb29130..093ba2b97a34 100644
--- a/src/Storages/StorageReplicatedMergeTree.cpp
+++ b/src/Storages/StorageReplicatedMergeTree.cpp
@@ -6072,6 +6072,7 @@ bool StorageReplicatedMergeTree::executeMetadataAlter(const StorageReplicatedMer
         /// Object may be added or dropped by alter.
         auto parts_lock = lockParts();
         resetObjectColumnsFromActiveParts(parts_lock);
+        resetSerializationHints(parts_lock);
     }
 
     return true;
diff --git a/src/Storages/StorageURL.cpp b/src/Storages/StorageURL.cpp
index 42648ad73e65..80c07658055f 100644
--- a/src/Storages/StorageURL.cpp
+++ b/src/Storages/StorageURL.cpp
@@ -408,6 +408,8 @@ StorageURLSource::StorageURLSource(
                 compression_method,
                 need_only_count);
 
+            input_format->setSerializationHints(info.serialization_hints);
+
             if (key_condition)
                 input_format->setKeyCondition(key_condition);
 
@@ -1127,7 +1129,7 @@ void IStorageURLBase::read(
     size_t num_streams)
 {
     auto params = getReadURIParams(column_names, storage_snapshot, query_info, local_context, processed_stage, max_block_size);
-    auto read_from_format_info = prepareReadingFromFormat(column_names, storage_snapshot, supportsSubsetOfColumns(local_context));
+    auto read_from_format_info = prepareReadingFromFormat(column_names, storage_snapshot, local_context, supportsSubsetOfColumns(local_context));
 
     bool need_only_count = (query_info.optimize_trivial_count || read_from_format_info.requested_columns.empty())
         && local_context->getSettingsRef()[Setting::optimize_count_from_files];
@@ -1297,7 +1299,7 @@ void StorageURLWithFailover::read(
     size_t num_streams)
 {
     auto params = getReadURIParams(column_names, storage_snapshot, query_info, local_context, processed_stage, max_block_size);
-    auto read_from_format_info = prepareReadingFromFormat(column_names, storage_snapshot, supportsSubsetOfColumns(local_context));
+    auto read_from_format_info = prepareReadingFromFormat(column_names, storage_snapshot, local_context, supportsSubsetOfColumns(local_context));
 
     bool need_only_count = (query_info.optimize_trivial_count || read_from_format_info.requested_columns.empty())
         && local_context->getSettingsRef()[Setting::optimize_count_from_files];
diff --git a/src/Storages/StorageView.cpp b/src/Storages/StorageView.cpp
index cb438e0efa68..bcbcd4f66c8e 100644
--- a/src/Storages/StorageView.cpp
+++ b/src/Storages/StorageView.cpp
@@ -187,7 +187,7 @@ void StorageView::read(
     /// It's expected that the columns read from storage are not constant.
     /// Because method 'getSampleBlockForColumns' is used to obtain a structure of result in InterpreterSelectQuery.
     ActionsDAG materializing_actions(query_plan.getCurrentDataStream().header.getColumnsWithTypeAndName());
-    materializing_actions.addMaterializingOutputActions();
+    materializing_actions.addMaterializingOutputActions(/*materialize_sparse=*/ true);
 
     auto materializing = std::make_unique<ExpressionStep>(query_plan.getCurrentDataStream(), std::move(materializing_actions));
     materializing->setStepDescription("Materialize constants after VIEW subquery");
diff --git a/src/Storages/prepareReadingFromFormat.cpp b/src/Storages/prepareReadingFromFormat.cpp
index 406b7f379f90..b87af449dc50 100644
--- a/src/Storages/prepareReadingFromFormat.cpp
+++ b/src/Storages/prepareReadingFromFormat.cpp
@@ -1,10 +1,19 @@
 #include <Storages/prepareReadingFromFormat.h>
 #include <Formats/FormatFactory.h>
+#include <Core/Settings.h>
+#include <Interpreters/Context.h>
+#include <Interpreters/DatabaseCatalog.h>
+#include <Storages/IStorage.h>
 
 namespace DB
 {
 
-ReadFromFormatInfo prepareReadingFromFormat(const Strings & requested_columns, const StorageSnapshotPtr & storage_snapshot, bool supports_subset_of_columns)
+namespace Setting
+{
+    extern const SettingsBool enable_parsing_to_custom_serialization;
+}
+
+ReadFromFormatInfo prepareReadingFromFormat(const Strings & requested_columns, const StorageSnapshotPtr & storage_snapshot, const ContextPtr & context, bool supports_subset_of_columns)
 {
     ReadFromFormatInfo info;
     /// Collect requested virtual columns and remove them from requested columns.
@@ -72,7 +81,35 @@ ReadFromFormatInfo prepareReadingFromFormat(const Strings & requested_columns, c
 
     /// Create header for InputFormat with columns that will be read from the data.
     info.format_header = storage_snapshot->getSampleBlockForColumns(info.columns_description.getNamesOfPhysical());
+    info.serialization_hints = getSerializationHintsForFileLikeStorage(storage_snapshot->metadata, context);
     return info;
 }
 
+SerializationInfoByName getSerializationHintsForFileLikeStorage(const StorageMetadataPtr & metadata_snapshot, const ContextPtr & context)
+{
+    if (!context->getSettingsRef()[Setting::enable_parsing_to_custom_serialization])
+        return {};
+
+    auto insertion_table = context->getInsertionTable();
+    if (!insertion_table)
+        return {};
+
+    auto storage_ptr = DatabaseCatalog::instance().tryGetTable(insertion_table, context);
+    if (!storage_ptr)
+        return {};
+
+    const auto & our_columns = metadata_snapshot->getColumns();
+    const auto & storage_columns = storage_ptr->getInMemoryMetadataPtr()->getColumns();
+    auto storage_hints = storage_ptr->getSerializationHints();
+    SerializationInfoByName res;
+
+    for (const auto & hint : storage_hints)
+    {
+        if (our_columns.tryGetPhysical(hint.first) == storage_columns.tryGetPhysical(hint.first))
+            res.insert(hint);
+    }
+
+    return res;
+}
+
 }
diff --git a/src/Storages/prepareReadingFromFormat.h b/src/Storages/prepareReadingFromFormat.h
index e4d62c29ec6d..02e42056d0cc 100644
--- a/src/Storages/prepareReadingFromFormat.h
+++ b/src/Storages/prepareReadingFromFormat.h
@@ -1,6 +1,8 @@
 #pragma once
 #include <Core/Block.h>
 #include <Storages/StorageSnapshot.h>
+#include <DataTypes/Serializations/SerializationInfo.h>
+#include <Interpreters/Context_fwd.h>
 
 namespace DB
 {
@@ -19,8 +21,14 @@ namespace DB
         NamesAndTypesList requested_columns;
         /// The list of requested virtual columns.
         NamesAndTypesList requested_virtual_columns;
+        /// Hints for the serialization of columns.
+        /// For example can be retrieved from the destination table in INSERT SELECT query.
+        SerializationInfoByName serialization_hints;
     };
 
     /// Get all needed information for reading from data in some input format.
-    ReadFromFormatInfo prepareReadingFromFormat(const Strings & requested_columns, const StorageSnapshotPtr & storage_snapshot, bool supports_subset_of_columns);
+    ReadFromFormatInfo prepareReadingFromFormat(const Strings & requested_columns, const StorageSnapshotPtr & storage_snapshot, const ContextPtr & context, bool supports_subset_of_columns);
+
+    /// Returns the serialization hints from the insertion table (if it's set in the Context).
+    SerializationInfoByName getSerializationHintsForFileLikeStorage(const StorageMetadataPtr & metadata_snapshot, const ContextPtr & context);
 }
