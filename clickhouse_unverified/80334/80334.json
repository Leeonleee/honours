{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 80334,
  "instance_id": "ClickHouse__ClickHouse-80334",
  "issue_numbers": [
    "36020",
    "78583"
  ],
  "base_commit": "65888e9e70116106c9ae5952669af93f5fcc9ba1",
  "patch": "diff --git a/docs/en/engines/table-engines/integrations/jdbc.md b/docs/en/engines/table-engines/integrations/jdbc.md\nindex 2712870865e8..b2383bc51bf4 100644\n--- a/docs/en/engines/table-engines/integrations/jdbc.md\n+++ b/docs/en/engines/table-engines/integrations/jdbc.md\n@@ -45,6 +45,8 @@ ENGINE = JDBC(datasource_uri, external_database, external_table)\n \n - `external_table` \u2014 Name of the table in `external_database` or a select query like `select * from table1 where column1=1`.\n \n+- These parameters can also be passed using [named collections](operations/named-collections.md).\n+\n ## Usage Example {#usage-example}\n \n Creating a table in MySQL server by connecting directly with it's console client:\ndiff --git a/docs/en/engines/table-engines/integrations/odbc.md b/docs/en/engines/table-engines/integrations/odbc.md\nindex c739fdd42b42..8137697dc477 100644\n--- a/docs/en/engines/table-engines/integrations/odbc.md\n+++ b/docs/en/engines/table-engines/integrations/odbc.md\n@@ -44,6 +44,8 @@ The table structure can differ from the source table structure:\n - `external_database` \u2014 Name of a database in an external DBMS.\n - `external_table` \u2014 Name of a table in the `external_database`.\n \n+These parameters can also be passed using [named collections](operations/named-collections.md).\n+\n ## Usage Example {#usage-example}\n \n **Retrieving data from the local MySQL installation via ODBC**\ndiff --git a/docs/en/sql-reference/table-functions/jdbc.md b/docs/en/sql-reference/table-functions/jdbc.md\nindex 23a90462a9e4..533cb5468927 100644\n--- a/docs/en/sql-reference/table-functions/jdbc.md\n+++ b/docs/en/sql-reference/table-functions/jdbc.md\n@@ -13,11 +13,19 @@ clickhouse-jdbc-bridge contains experimental codes and is no longer supported. I\n ClickHouse recommend using built-in table functions in ClickHouse which provide a better alternative for ad-hoc querying scenarios (Postgres, MySQL, MongoDB, etc).\n :::\n \n-`jdbc(datasource, schema, table)` - returns table that is connected via JDBC driver.\n+JDBC table function returns table that is connected via JDBC driver.\n \n This table function requires separate [clickhouse-jdbc-bridge](https://github.com/ClickHouse/clickhouse-jdbc-bridge) program to be running.\n It supports Nullable types (based on DDL of remote table that is queried).\n \n+## Syntax {#syntax}\n+\n+```sql\n+jdbc(datasource, schema, table)\n+jdbc(datasource, table)\n+jdbc(named_collection)\n+```\n+\n ## Examples {#examples}\n \n ```sql\ndiff --git a/docs/en/sql-reference/table-functions/odbc.md b/docs/en/sql-reference/table-functions/odbc.md\nindex 703dc49eb790..7fa5126ef1be 100644\n--- a/docs/en/sql-reference/table-functions/odbc.md\n+++ b/docs/en/sql-reference/table-functions/odbc.md\n@@ -14,6 +14,8 @@ Returns table that is connected via [ODBC](https://en.wikipedia.org/wiki/Open_Da\n \n ```sql\n odbc(connection_settings, external_database, external_table)\n+odbc(connection_settings, external_table)\n+odbc(named_collection)\n ```\n \n ## Arguments {#arguments}\n@@ -24,6 +26,8 @@ odbc(connection_settings, external_database, external_table)\n | `external_database` | Name of a database in an external DBMS.                                |\n | `external_table`    | Name of a table in the `external_database`.                            |\n \n+These parameters can also be passed using [named collections](operations/named-collections.md).\n+\n To safely implement ODBC connections, ClickHouse uses a separate program `clickhouse-odbc-bridge`. If the ODBC driver is loaded directly from `clickhouse-server`, driver problems can crash the ClickHouse server. ClickHouse automatically starts `clickhouse-odbc-bridge` when it is required. The ODBC bridge program is installed from the same package as the `clickhouse-server`.\n \n The fields with the `NULL` values from the external table are converted into the default values for the base data type. For example, if a remote MySQL table field has the `INT NULL` type it is converted to 0 (the default value for ClickHouse `Int32` data type).\ndiff --git a/src/Storages/StorageXDBC.cpp b/src/Storages/StorageXDBC.cpp\nindex a80bb610e1b4..58dd83a32ea0 100644\n--- a/src/Storages/StorageXDBC.cpp\n+++ b/src/Storages/StorageXDBC.cpp\n@@ -3,6 +3,7 @@\n #include <Storages/StorageURL.h>\n #include <Storages/transformQueryForExternalDatabase.h>\n #include <Storages/checkAndGetLiteralArgument.h>\n+#include <Storages/NamedCollectionsHelpers.h>\n \n #include <Core/ServerSettings.h>\n #include <Core/Settings.h>\n@@ -184,22 +185,53 @@ namespace\n         {\n             ASTs & engine_args = args.engine_args;\n \n-            if (engine_args.size() != 3)\n-                throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n-                    \"Storage {} requires exactly 3 parameters: {}('DSN', database or schema, table)\", name, name);\n+            String connection_string;\n+            String database_or_schema;\n+            String table;\n \n-            for (size_t i = 0; i < 3; ++i)\n-                engine_args[i] = evaluateConstantExpressionOrIdentifierAsLiteral(engine_args[i], args.getLocalContext());\n+            if (auto named_collection = tryGetNamedCollectionWithOverrides(engine_args, args.getLocalContext()))\n+            {\n+                if (name == \"JDBC\")\n+                {\n+                    validateNamedCollection<>(*named_collection, {\"datasource\", \"schema\", \"table\"}, {});\n+                    connection_string = named_collection->get<String>(\"datasource\");\n+                    database_or_schema = named_collection->get<String>(\"schema\");\n+                    table = named_collection->get<String>(\"table\");\n+                }\n+                else\n+                {\n+                    validateNamedCollection<>(*named_collection, {\"connection_settings\", \"external_database\", \"external_table\"}, {});\n+                    connection_string = named_collection->get<String>(\"connection_settings\");\n+                    database_or_schema = named_collection->get<String>(\"external_database\");\n+                    table = named_collection->get<String>(\"external_table\");\n+                }\n+            }\n+            else\n+            {\n+                if (engine_args.size() != 3)\n+                    throw Exception(\n+                        ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n+                        \"Storage {} requires exactly 3 parameters: {}('DSN', database or schema, table)\",\n+                        name,\n+                        name);\n+\n+                for (size_t i = 0; i < 3; ++i)\n+                    engine_args[i] = evaluateConstantExpressionOrIdentifierAsLiteral(engine_args[i], args.getLocalContext());\n+\n+                connection_string = checkAndGetLiteralArgument<String>(engine_args[0], \"connection_string\");\n+                database_or_schema = checkAndGetLiteralArgument<String>(engine_args[1], \"database_name\");\n+                table = checkAndGetLiteralArgument<String>(engine_args[2], \"table_name\");\n+            }\n \n             BridgeHelperPtr bridge_helper = std::make_shared<XDBCBridgeHelper<BridgeHelperMixin>>(\n                 args.getContext(),\n                 args.getContext()->getSettingsRef()[Setting::http_receive_timeout].value,\n-                checkAndGetLiteralArgument<String>(engine_args[0], \"connection_string\"),\n+                connection_string,\n                 args.getContext()->getSettingsRef()[Setting::odbc_bridge_use_connection_pooling].value);\n             return std::make_shared<StorageXDBC>(\n                 args.table_id,\n-                checkAndGetLiteralArgument<String>(engine_args[1], \"database_name\"),\n-                checkAndGetLiteralArgument<String>(engine_args[2], \"table_name\"),\n+                database_or_schema,\n+                table,\n                 args.columns,\n                 args.constraints,\n                 args.comment,\ndiff --git a/src/TableFunctions/ITableFunctionXDBC.cpp b/src/TableFunctions/ITableFunctionXDBC.cpp\nindex b2f3ce084450..491eb78b84de 100644\n--- a/src/TableFunctions/ITableFunctionXDBC.cpp\n+++ b/src/TableFunctions/ITableFunctionXDBC.cpp\n@@ -10,6 +10,7 @@\n #include <Parsers/ASTLiteral.h>\n #include <Parsers/parseQuery.h>\n #include <Storages/StorageXDBC.h>\n+#include <Storages/NamedCollectionsHelpers.h>\n #include <TableFunctions/ITableFunction.h>\n #include <TableFunctions/TableFunctionFactory.h>\n #include <Poco/Net/HTTPRequest.h>\n@@ -35,6 +36,7 @@ namespace ErrorCodes\n {\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n     extern const int LOGICAL_ERROR;\n+    extern const int BAD_ARGUMENTS;\n }\n \n namespace\n@@ -118,23 +120,54 @@ void ITableFunctionXDBC::parseArguments(const ASTPtr & ast_function, ContextPtr\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Table function '{}' must have arguments.\", getName());\n \n     ASTs & args = args_func.arguments->children;\n-    if (args.size() != 2 && args.size() != 3)\n-        throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n-            \"Table function '{0}' requires 2 or 3 arguments: {0}('DSN', table) or {0}('DSN', schema, table)\", getName());\n \n-    for (auto & arg : args)\n-        arg = evaluateConstantExpressionOrIdentifierAsLiteral(arg, context);\n+    if (args.empty() || args.size() > 3)\n+        throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n+            \"Table function '{0}' requires 1, 2 or 3 arguments: {0}(named_collection) or {0}('DSN', table) or {0}('DSN', schema, table)\", getName());\n \n-    if (args.size() == 3)\n+    if (args.size() == 1)\n     {\n-        connection_string = args[0]->as<ASTLiteral &>().value.safeGet<String>();\n-        schema_name = args[1]->as<ASTLiteral &>().value.safeGet<String>();\n-        remote_table_name = args[2]->as<ASTLiteral &>().value.safeGet<String>();\n+        if (auto named_collection = tryGetNamedCollectionWithOverrides(ast_function->children.at(0)->children, context))\n+        {\n+            if (getName() == \"JDBC\")\n+            {\n+                validateNamedCollection<>(*named_collection, {\"datasource\"}, {\"schema\", \"table\"});\n+                connection_string = named_collection->get<String>(\"datasource\");\n+                schema_name = named_collection->getOrDefault<String>(\"schema\", \"\");\n+                remote_table_name = named_collection->getOrDefault<String>(\"table\", \"\");\n+            }\n+            else\n+            {\n+                validateNamedCollection<>(*named_collection, {\"connection_settings\"}, {\"external_database\", \"external_table\"});\n+\n+                connection_string = named_collection->get<String>(\"connection_settings\");\n+                schema_name = named_collection->getOrDefault<String>(\"external_database\", \"\");\n+                remote_table_name = named_collection->getOrDefault<String>(\"external_table\", \"\");\n+\n+            }\n+        }\n+        else\n+        {\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS,\n+                            \"Table function '{0}' has 1 argument, it is expected to be named collection\", getName());\n+        }\n     }\n-    else if (args.size() == 2)\n+    else\n     {\n-        connection_string = args[0]->as<ASTLiteral &>().value.safeGet<String>();\n-        remote_table_name = args[1]->as<ASTLiteral &>().value.safeGet<String>();\n+        for (auto & arg : args)\n+            arg = evaluateConstantExpressionOrIdentifierAsLiteral(arg, context);\n+\n+        if (args.size() == 3)\n+        {\n+            connection_string = args[0]->as<ASTLiteral &>().value.safeGet<String>();\n+            schema_name = args[1]->as<ASTLiteral &>().value.safeGet<String>();\n+            remote_table_name = args[2]->as<ASTLiteral &>().value.safeGet<String>();\n+        }\n+        else if (args.size() == 2)\n+        {\n+            connection_string = args[0]->as<ASTLiteral &>().value.safeGet<String>();\n+            remote_table_name = args[1]->as<ASTLiteral &>().value.safeGet<String>();\n+        }\n     }\n }\n \n",
  "test_patch": "diff --git a/tests/integration/test_odbc_interaction/configs/users.xml b/tests/integration/test_odbc_interaction/configs/users.xml\nindex 4555a2ed4945..0ca4b117c9a1 100644\n--- a/tests/integration/test_odbc_interaction/configs/users.xml\n+++ b/tests/integration/test_odbc_interaction/configs/users.xml\n@@ -12,6 +12,8 @@\n             </networks>\n             <profile>default</profile>\n             <quota>default</quota>\n+            <named_collection_control>1</named_collection_control>\n+            <use_named_collections>1</use_named_collections>\n         </default>\n     </users>\n \ndiff --git a/tests/integration/test_odbc_interaction/test.py b/tests/integration/test_odbc_interaction/test.py\nindex f8bc6c7cb7d2..daf72505274e 100644\n--- a/tests/integration/test_odbc_interaction/test.py\n+++ b/tests/integration/test_odbc_interaction/test.py\n@@ -170,6 +170,15 @@ def started_cluster():\n             privileged=True,\n             user=\"root\",\n         )\n+        node1.exec_in_container(\n+            [\n+                \"sqlite3\",\n+                sqlite_db,\n+                \"CREATE TABLE t5(id INTEGER PRIMARY KEY ASC, X INTEGER, Y, Z);\",\n+            ],\n+            privileged=True,\n+            user=\"root\",\n+        )\n         node1.exec_in_container(\n             [\n                 \"sqlite3\",\n@@ -326,6 +335,37 @@ def test_mysql_simple_select_works(started_cluster):\n     conn.close()\n \n \n+def test_table_function_odbc_with_named_collection(started_cluster):\n+    skip_test_sanitizers(node1)\n+\n+    mysql_setup = node1.odbc_drivers[\"MySQL\"]\n+\n+    table_name = \"test_mysql_with_named_collection\"\n+    conn = get_mysql_conn()\n+    create_mysql_table(conn, table_name)\n+\n+    # Check that NULL-values are handled correctly by the ODBC-bridge\n+    with conn.cursor() as cursor:\n+        cursor.execute(\n+            \"INSERT INTO clickhouse.{} VALUES(50, 'name1', 127, 255, 512), (100, 'name2', 127, 255, 511);\".format(\n+                table_name\n+            )\n+        )\n+        conn.commit()\n+\n+    node1.query(f\"\"\"\n+    DROP NAMED COLLECTION IF EXISTS odbc_collection;\n+    CREATE NAMED COLLECTION odbc_collection AS\n+    connection_settings = 'DSN={mysql_setup[\"DSN\"]}',\n+    external_table = '{table_name}';\n+    \"\"\")\n+    assert node1.query(\"SELECT name FROM odbc(odbc_collection)\") == \"name1\\nname2\\n\"\n+\n+    node1.query(f\"DROP TABLE IF EXISTS {table_name}\")\n+    drop_mysql_table(conn, table_name)\n+    conn.close()\n+\n+\n def test_mysql_insert(started_cluster):\n     skip_test_sanitizers(node1)\n \n@@ -498,6 +538,37 @@ def test_sqlite_simple_select_storage_works(started_cluster):\n     )\n \n \n+def test_table_engine_odbc_named_collection(started_cluster):\n+    skip_test_sanitizers(node1)\n+\n+    sqlite_setup = node1.odbc_drivers[\"SQLite3\"]\n+    sqlite_db = sqlite_setup[\"Database\"]\n+\n+    node1.exec_in_container(\n+        [\"sqlite3\", sqlite_db, \"INSERT INTO t5 values(1, 1, 2, 3);\"],\n+        privileged=True,\n+        user=\"root\",\n+    )\n+\n+    node1.query(f\"\"\"\n+    DROP NAMED COLLECTION IF EXISTS engine_odbc_collection;\n+    CREATE NAMED COLLECTION engine_odbc_collection AS\n+    connection_settings = 'DSN={sqlite_setup[\"DSN\"]}',\n+    external_database = '',\n+    external_table = 't5';\n+    \"\"\")\n+    node1.query(\"CREATE TABLE SqliteODBCNamedCol (x Int32, y String, z String) ENGINE = ODBC(engine_odbc_collection)\")\n+\n+    assert node1.query(\"SELECT * FROM SqliteODBCNamedCol\") == \"1\\t2\\t3\\n\"\n+    node1.query(\"DROP TABLE IF EXISTS SqliteODBCNamedCol\")\n+\n+    node1.exec_in_container(\n+        [\"sqlite3\", sqlite_db, \"DELETE FROM t5;\"],\n+        privileged=True,\n+        user=\"root\",\n+    )\n+\n+\n def test_sqlite_odbc_hashed_dictionary(started_cluster):\n     skip_test_sanitizers(node1)\n \n",
  "problem_statement": "Support named collections for jdbc table function\nNamed collections are implemented for MySQL, PostgreSQL, MongoDB, URL, S3 and Kafka connections, but not for generic JDBC. \nSupport Named Collections for ODBC/JDBC Connections in ClickHouse\n### Company or project name\n\n_No response_\n\n### Use case\n\nImplement support for **named collections** for ODBC/JDBC connections in ClickHouse. This feature is currently missing for ODBC/JDBC, making it inconsistent with existing named collection support for MySQL, PostgreSQL, MongoDB, URL, S3, and Kafka.\n\n### **Current Behavior**\nI have a working dictionary using an MSSQL ODBC connection in XML format:\n```xml\n<dictionary>\n    <name>test_dict</name>\n    <layout>\n        <complex_key_hashed/>\n    </layout>\n    <lifetime>\n        <min>500</min>\n        <max>600</max>\n    </lifetime>\n    <source>\n        <odbc>\n            <connection_string>DSN=MSSQL;Server=X;Database=Y;Uid=ch;Pwd=Z;</connection_string>\n            <table>test_table</table>\n        </odbc>\n    </source>\n    <structure>\n        <key>\n            <attribute>\n                <name>table_id</name>\n                <type>String</type>\n            </attribute>\n        </key>\n    </structure>\n</dictionary>\n```\n\nBy following the existing named collection structure, I created:\n```xml\n<clickhouse>\n    <named_collections>\n        <nc_mssql>\n            <connection_string>DSN=MSSQL;Server=X;Database=Y;Uid=ch;Pwd=Z;</connection_string>\n            <table> test_table </table>\n        </nc_mssql>\n    </named_collections>\n</clickhouse>\n```\n\nHowever, when trying to query from this named collection, the following errors occur:\n\n#### **Attempt 1**\n```sql\nSELECT * FROM odbc(nc_mssql);\n```\n**Error:**\n```\nCode: 42. DB::Exception: Table function 'odbc' requires 2 or 3 arguments: odbc('DSN', table) or odbc('DSN', schema, table). (NUMBER_OF_ARGUMENTS_DOESNT_MATCH)\n```\n\n#### **Attempt 2**\n```sql\nSELECT * FROM odbc('nc_mssql', test_table);\n```\n**Error:**\n```\nCode: 86. DB::Exception: Received from localhost:9000. DB::HTTPException. DB::HTTPException: Received error from remote server http://127.0.0.1:9018/columns_info?use_connection_pooling=1&version=1&connection_string=nc_mssql&table=test_table&external_table_functions_use_nulls=1. HTTP status code: 500 Internal Server Error, body: Error getting columns from ODBC 'Code: 404. DB::Exception: ODBC connection string parameter doesn't have value. (BAD_ODBC_CONNECTION_STRING) '\n. (RECEIVED_ERROR_FROM_REMOTE_IO_SERVER)\n```\n\n\n### Describe the solution you'd like\n\n### **Proposed Solution**\n- Extend named collection support to ODBC/JDBC connections.\n- Ensure the implementation is consistent with the approach used for MySQL, PostgreSQL, and other existing named collection implementations.\n\n### **Benefit**\n- Improves consistency across ClickHouse connection mechanisms.\n- Simplifies configuration by allowing reuse of named collections for ODBC/JDBC connections.\n- Reduces potential errors caused by manually handling connection strings.\n\n### **References**\n- Named collections are already implemented for MySQL, PostgreSQL, MongoDB, URL, S3, and Kafka.\n- This feature would enhance ODBC/JDBC usability in ClickHouse environments.\n\n**Would appreciate consideration for adding this feature!** \n\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n_No response_\n",
  "hints_text": "\nrelated https://github.com/ClickHouse/ClickHouse/issues/36020",
  "created_at": "2025-05-16T11:57:28Z",
  "modified_files": [
    "docs/en/engines/table-engines/integrations/jdbc.md",
    "docs/en/engines/table-engines/integrations/odbc.md",
    "docs/en/sql-reference/table-functions/jdbc.md",
    "docs/en/sql-reference/table-functions/odbc.md",
    "src/Storages/StorageXDBC.cpp",
    "src/TableFunctions/ITableFunctionXDBC.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_odbc_interaction/configs/users.xml",
    "tests/integration/test_odbc_interaction/test.py"
  ]
}