{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 9507,
  "instance_id": "ClickHouse__ClickHouse-9507",
  "issue_numbers": [
    "9378"
  ],
  "base_commit": "26c74d679f350c482c4e69a0992b323f2f954e94",
  "patch": "diff --git a/dbms/src/Storages/Kafka/KafkaBlockInputStream.cpp b/dbms/src/Storages/Kafka/KafkaBlockInputStream.cpp\nindex 80efc9f49965..c1252086b1de 100644\n--- a/dbms/src/Storages/Kafka/KafkaBlockInputStream.cpp\n+++ b/dbms/src/Storages/Kafka/KafkaBlockInputStream.cpp\n@@ -199,8 +199,6 @@ Block KafkaBlockInputStream::readImpl()\n \n void KafkaBlockInputStream::readSuffixImpl()\n {\n-    broken = false;\n-\n     if (commit_in_suffix)\n         commit();\n }\n@@ -211,6 +209,8 @@ void KafkaBlockInputStream::commit()\n         return;\n \n     buffer->commit();\n+\n+    broken = false;\n }\n \n }\n",
  "test_patch": "diff --git a/dbms/tests/integration/test_storage_kafka/test.py b/dbms/tests/integration/test_storage_kafka/test.py\nindex 8c4f2fbc9ef5..cf9f32e52b82 100644\n--- a/dbms/tests/integration/test_storage_kafka/test.py\n+++ b/dbms/tests/integration/test_storage_kafka/test.py\n@@ -7,6 +7,7 @@\n from helpers.cluster import ClickHouseCluster\n from helpers.test_tools import TSV\n from helpers.client import QueryRuntimeException\n+from helpers.network import PartitionManager\n \n import json\n import subprocess\n@@ -34,6 +35,7 @@\n                                 config_dir='configs',\n                                 main_configs=['configs/kafka.xml', 'configs/log_conf.xml' ],\n                                 with_kafka=True,\n+                                with_zookeeper=True,\n                                 clickhouse_path_dir='clickhouse_path')\n kafka_id = ''\n \n@@ -1106,6 +1108,58 @@ def produce():\n \n     assert result == 1, 'Messages from kafka get duplicated!'\n \n+@pytest.mark.timeout(1200)\n+def test_kafka_no_holes_when_write_suffix_failed(kafka_cluster):\n+    messages = [json.dumps({'key': j+1, 'value': 'x' * 300}) for j in range(22)]\n+    kafka_produce('no_holes_when_write_suffix_failed', messages)\n+\n+    instance.query('''\n+        DROP TABLE IF EXISTS test.view;\n+        DROP TABLE IF EXISTS test.consumer;\n+\n+        CREATE TABLE test.kafka (key UInt64, value String)\n+            ENGINE = Kafka\n+            SETTINGS kafka_broker_list = 'kafka1:19092',\n+                     kafka_topic_list = 'no_holes_when_write_suffix_failed',\n+                     kafka_group_name = 'no_holes_when_write_suffix_failed',\n+                     kafka_format = 'JSONEachRow',\n+                     kafka_max_block_size = 20;\n+\n+        CREATE TABLE test.view (key UInt64, value String)\n+            ENGINE = ReplicatedMergeTree('/clickhouse/kafkatest/tables/no_holes_when_write_suffix_failed', 'node1')\n+            ORDER BY key;\n+\n+        CREATE MATERIALIZED VIEW test.consumer TO test.view AS\n+            SELECT * FROM test.kafka\n+            WHERE NOT sleepEachRow(1);\n+    ''')\n+    # the tricky part here is that disconnect should happen after write prefix, but before write suffix\n+    # so i use sleepEachRow\n+    with PartitionManager() as pm:\n+        time.sleep(12)\n+        pm.drop_instance_zk_connections(instance)\n+        time.sleep(20)\n+        pm.heal_all\n+\n+    # connection restored and it will take a while until next block will be flushed\n+    # it takes years on CI :\\\n+    time.sleep(90)\n+\n+    # as it's a bit tricky to hit the proper moment - let's check in logs if we did it correctly\n+    assert instance.contains_in_log(\"ZooKeeper session has been expired.: while write prefix to view\")\n+\n+    result = instance.query('SELECT count(), uniqExact(key), max(key) FROM test.view')\n+    print(result)\n+\n+    # kafka_cluster.open_bash_shell('instance')\n+\n+    instance.query('''\n+        DROP TABLE test.consumer;\n+        DROP TABLE test.view;\n+    ''')\n+\n+    assert TSV(result) == TSV('22\\t22\\t22')\n+\n \n \n if __name__ == '__main__':\n",
  "problem_statement": "Kafka engine can lose data with replicated table and zookeeper issue\n**Describe the bug or unexpected behaviour**\r\nI have the following pipeline: KafkaEngine => MV => replicated table. If Zookeeper service is unavailable for a moment, some Kafka messages may be lost when Zookeeper recovers.  \r\n\r\n**How to reproduce**\r\n- tested with Clickhouse 19.16.13.54 (official Docker image)\r\n- execute this script which starts Zookeeper, Kafka, Clickhouse and a data generator:\r\n[start.txt](https://github.com/ClickHouse/ClickHouse/files/4254809/start.txt)\r\n\r\n- simulate Zookeeper issues:\r\n`while true; do docker kill zk; sleep 5; docker start zk; sleep 10; done`\r\n\r\n- watch insertion result:\r\n`while true; do docker exec ch clickhouse-client -q \"select max(key1),uniq(key1) from store\"; sleep 10; done`\r\n\r\nyou get something like this:\r\n```\r\n0       0\r\n0       0\r\n3       3\r\n4       4\r\n6       6\r\n9       8\r\n9       8\r\n12      11\r\n14      13\r\n15      14\r\n18      17\r\n```\r\nThis shows that at some point messages are lost (sometimes after a long moment).\r\n\r\n**Expected behavior**\r\nNo message should be lost. When messages cannot be inserted, Kafka messages should not be committed. This also means that messages could be inserted twice but this is expected.\r\n\r\n**Error message and/or stacktrace**\r\nReplicated table switches to readonly mode because of lost of Zookeeper connection and this triggers an error in StorageKafka::streamToViews but for some reason, messages are still committed in some case:\r\n\r\n`2020.02.26 10:05:26.393221 [ 20 ] {} <Error> void DB::StorageKafka::threadFunc(): Code: 242, e.displayText() = DB::Exception: Table is in readonly mode, Stack trace:\r\n\r\n0. 0x55fdbcd226a0 StackTrace::StackTrace() /usr/bin/clickhouse\r\n1. 0x55fdbcd22475 DB::Exception::Exception(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int) /usr/bin/clickhouse\r\n2. 0x55fdbca8ce13 ? /usr/bin/clickhouse\r\n3. 0x55fdc02ffd59 DB::StorageReplicatedMergeTree::write(std::shared_ptr<DB::IAST> const&, DB::Context const&) /usr/bin/clickhouse\r\n4. 0x55fdc06ad27e DB::PushingToViewsBlockOutputStream::PushingToViewsBlockOutputStream(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::shared_ptr<DB::IStorage> const&, DB::Context const&, std::shared_ptr<DB::IAST> const&, bool) /usr/bin/clickhouse\r\n5. 0x55fdc0081e01 DB::InterpreterInsertQuery::execute() /usr/bin/clickhouse\r\n6. 0x55fdc06adea4 DB::PushingToViewsBlockOutputStream::PushingToViewsBlockOutputStream(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::shared_ptr<DB::IStorage> const&, DB::Context const&, std::shared_ptr<DB::IAST> const&, bool) /usr/bin/clickhouse\r\n7. 0x55fdc0081e01 DB::InterpreterInsertQuery::execute() /usr/bin/clickhouse\r\n8. 0x55fdc05ef8c2 DB::StorageKafka::streamToViews() /usr/bin/clickhouse\r\n9. 0x55fdc05f0481 DB::StorageKafka::threadFunc() /usr/bin/clickhouse\r\n`\n",
  "hints_text": "Perfect report, thanks. \r\nI will try to reproduce the problem, and check what's going on. \r\nWe may expect duplicates, but not holes in that usecase.\nThe test case here is simplified because on my real platform, I have several MV behind the same Kafka Engine and each MV inserts in a distributed table on top of a replicated table. I don't know if it makes a difference on how to detect that insertion failed or was partial (only some of the MV).\n1) When several MV are attached then inserts are not atomic. One table may get data, the other one - failed.\r\n2) The expected behavior in that case: then ANY of MV was failed, the whole block should be inserted once again (so if 9 of 10 MV was successful the first time, they will have that block duplicated, and the tenth will get it once). \r\n3) atomic inserts to MV chain are in the roadmap, there are some (uncertain) chances to have it in the summer of 2020\r\n\r\n\nThe problem reproduces using your tests case. \r\n\r\nMissing blocks correlate well with those exceptions:\r\n```\r\n2020.03.03 11:29:15.628156 [ 20 ] {} <Error> void DB::StorageKafka::threadFunc(): Code: 225, e.displayText() = DB::Exception: ZooKeeper session has been expired.: while write prefix to view default.mv, Stack trace:\r\n\r\n0. 0x559020d3b6a0 StackTrace::StackTrace() /usr/bin/clickhouse\r\n1. 0x559020d3b475 DB::Exception::Exception(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int) /usr/bin/clickhouse\r\n2. 0x559020ae0145 ? /usr/bin/clickhouse\r\n3. 0x559024461459 DB::ReplicatedMergeTreeBlockOutputStream::write(DB::Block const&) /usr/bin/clickhouse\r\n4. 0x5590246c8291 DB::PushingToViewsBlockOutputStream::write(DB::Block const&) /usr/bin/clickhouse\r\n5. 0x5590246d2193 DB::SquashingBlockOutputStream::finalize() /usr/bin/clickhouse\r\n6. 0x5590246d23c1 DB::SquashingBlockOutputStream::writeSuffix() /usr/bin/clickhouse\r\n7. 0x5590246c5c5a DB::PushingToViewsBlockOutputStream::writeSuffix() /usr/bin/clickhouse\r\n8. 0x559023f723c7 DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::atomic<bool>*) /usr/bin/clickhouse\r\n9. 0x559024608d0e DB::StorageKafka::streamToViews() /usr/bin/clickhouse\r\n10. 0x559024609481 DB::StorageKafka::threadFunc() /usr/bin/clickhouse\r\n11. 0x55902461b5b9 DB::BackgroundSchedulePoolTaskInfo::execute() /usr/bin/clickhouse\r\n12. 0x55902461befa DB::BackgroundSchedulePool::threadFunction() /usr/bin/clickhouse\r\n13. 0x55902461bf7a ? /usr/bin/clickhouse\r\n14. 0x559020d85b0c ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>) /usr/bin/clickhouse\r\n15. 0x559026aaf120 ? /usr/bin/clickhouse\r\n16. 0x7f52914206db start_thread /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n17. 0x7f5290d3d88f __clone /lib/x86_64-linux-gnu/libc-2.27.so\r\n (version 19.16.13.54 (official build))\r\n```\r\n\r\nI see the issue. ",
  "created_at": "2020-03-04T07:04:01Z"
}