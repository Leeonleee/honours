{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 39527,
  "instance_id": "ClickHouse__ClickHouse-39527",
  "issue_numbers": [
    "39525"
  ],
  "base_commit": "e583345987f43dd74a158488d048676e7ef356db",
  "patch": "diff --git a/contrib/nats-io-cmake/CMakeLists.txt b/contrib/nats-io-cmake/CMakeLists.txt\nindex 5588d5750c47..579bf6f8ae48 100644\n--- a/contrib/nats-io-cmake/CMakeLists.txt\n+++ b/contrib/nats-io-cmake/CMakeLists.txt\n@@ -18,6 +18,8 @@ elseif(WIN32)\n     set(NATS_PLATFORM_INCLUDE \"apple\")\n endif()\n \n+add_definitions(-DNATS_HAS_TLS)\n+\n file(GLOB PS_SOURCES \"${NATS_IO_SOURCE_DIR}/${NATS_PLATFORM_INCLUDE}/*.c\")\n set(SRCS\n     \"${NATS_IO_SOURCE_DIR}/asynccb.c\"\ndiff --git a/src/Storages/NATS/NATSConnection.cpp b/src/Storages/NATS/NATSConnection.cpp\nindex 359754bb1440..64beb9f2dffb 100644\n--- a/src/Storages/NATS/NATSConnection.cpp\n+++ b/src/Storages/NATS/NATSConnection.cpp\n@@ -9,7 +9,6 @@\n namespace DB\n {\n \n-//static const auto CONNECT_SLEEP = 200;\n static const auto RETRIES_MAX = 20;\n static const auto CONNECTED_TO_BUFFER_SIZE = 256;\n \n@@ -19,6 +18,10 @@ NATSConnectionManager::NATSConnectionManager(const NATSConfiguration & configura\n     , log(log_)\n     , event_handler(loop.getLoop(), log)\n {\n+    const char * val = std::getenv(\"CLICKHOUSE_NATS_TLS_SECURE\");\n+    std::string tls_secure = val == nullptr ? std::string(\"1\") : std::string(val);\n+    if (tls_secure == \"0\")\n+        skip_verification = true;\n }\n \n \n@@ -92,6 +95,9 @@ void NATSConnectionManager::connectImpl()\n     if (configuration.secure)\n     {\n         natsOptions_SetSecure(options, true);\n+    }\n+    if (skip_verification)\n+    {\n         natsOptions_SkipServerVerification(options, true);\n     }\n     if (!configuration.url.empty())\ndiff --git a/src/Storages/NATS/NATSConnection.h b/src/Storages/NATS/NATSConnection.h\nindex 78a273164db4..c699f859446a 100644\n--- a/src/Storages/NATS/NATSConnection.h\n+++ b/src/Storages/NATS/NATSConnection.h\n@@ -65,6 +65,9 @@ class NATSConnectionManager\n     // true if at any point successfully connected to NATS\n     bool has_connection = false;\n \n+    // use CLICKHOUSE_NATS_TLS_SECURE=0 env var to skip TLS verification of server cert\n+    bool skip_verification = false;\n+\n     std::mutex mutex;\n };\n \n",
  "test_patch": "diff --git a/docker/test/integration/runner/compose/docker_compose_nats.yml b/docker/test/integration/runner/compose/docker_compose_nats.yml\nindex 19ae4c162b1f..2122f0f639f8 100644\n--- a/docker/test/integration/runner/compose/docker_compose_nats.yml\n+++ b/docker/test/integration/runner/compose/docker_compose_nats.yml\n@@ -4,4 +4,8 @@ services:\n     image: nats\n     ports:\n       - \"${NATS_EXTERNAL_PORT}:${NATS_INTERNAL_PORT}\"\n-    command: \"-p 4444 --user click --pass house\"\n\\ No newline at end of file\n+    command: \"-p 4444 --user click --pass house --tls --tlscert=/etc/certs/server-cert.pem --tlskey=/etc/certs/server-key.pem\"\n+    volumes:\n+      - type: bind\n+        source: \"${NATS_CERT_DIR}/nats\"\n+        target: /etc/certs\ndiff --git a/tests/integration/helpers/cluster.py b/tests/integration/helpers/cluster.py\nindex 7700fc2dffdc..43b08883ae5a 100644\n--- a/tests/integration/helpers/cluster.py\n+++ b/tests/integration/helpers/cluster.py\n@@ -30,6 +30,7 @@\n     import pymongo\n     import pymysql\n     import nats\n+    import ssl\n     import meilisearch\n     from confluent_kafka.avro.cached_schema_registry_client import (\n         CachedSchemaRegistryClient,\n@@ -215,9 +216,27 @@ def check_rabbitmq_is_available(rabbitmq_id):\n     return p.returncode == 0\n \n \n-async def check_nats_is_available(nats_ip):\n-    nc = await nats.connect(\"{}:4444\".format(nats_ip), user=\"click\", password=\"house\")\n-    return nc.is_connected\n+async def check_nats_is_available(nats_port, ssl_ctx=None):\n+    nc = await nats_connect_ssl(\n+        nats_port, user=\"click\", password=\"house\", ssl_ctx=ssl_ctx\n+    )\n+    available = nc.is_connected\n+    await nc.close()\n+    return available\n+\n+\n+async def nats_connect_ssl(nats_port, user, password, ssl_ctx=None):\n+    if not ssl_ctx:\n+        ssl_ctx = ssl.create_default_context()\n+        ssl_ctx.check_hostname = False\n+        ssl_ctx.verify_mode = ssl.CERT_NONE\n+    nc = await nats.connect(\n+        \"tls://localhost:{}\".format(nats_port),\n+        user=user,\n+        password=password,\n+        tls=ssl_ctx,\n+    )\n+    return nc\n \n \n def enable_consistent_hash_plugin(rabbitmq_id):\n@@ -336,6 +355,7 @@ def __init__(\n         self.env_variables = {}\n         self.env_variables[\"TSAN_OPTIONS\"] = \"second_deadlock_stack=1\"\n         self.env_variables[\"CLICKHOUSE_WATCHDOG_ENABLE\"] = \"0\"\n+        self.env_variables[\"CLICKHOUSE_NATS_TLS_SECURE\"] = \"0\"\n         self.up_called = False\n \n         custom_dockerd_host = custom_dockerd_host or os.environ.get(\n@@ -464,9 +484,11 @@ def __init__(\n         self.rabbitmq_logs_dir = os.path.join(self.rabbitmq_dir, \"logs\")\n \n         self.nats_host = \"nats1\"\n-        self.nats_ip = None\n         self.nats_port = 4444\n         self.nats_docker_id = None\n+        self.nats_dir = p.abspath(p.join(self.instances_dir, \"nats\"))\n+        self.nats_cert_dir = os.path.join(self.nats_dir, \"cert\")\n+        self.nats_ssl_context = None\n \n         # available when with_nginx == True\n         self.nginx_host = \"nginx\"\n@@ -1046,6 +1068,7 @@ def setup_nats_cmd(self, instance, env_variables, docker_compose_yml_dir):\n         env_variables[\"NATS_HOST\"] = self.nats_host\n         env_variables[\"NATS_INTERNAL_PORT\"] = \"4444\"\n         env_variables[\"NATS_EXTERNAL_PORT\"] = str(self.nats_port)\n+        env_variables[\"NATS_CERT_DIR\"] = self.nats_cert_dir\n \n         self.base_cmd.extend(\n             [\"--file\", p.join(docker_compose_yml_dir, \"docker_compose_nats.yml\")]\n@@ -1967,10 +1990,12 @@ def wait_rabbitmq_to_start(self, timeout=180, throw=True):\n             raise Exception(\"Cannot wait RabbitMQ container\")\n         return False\n \n-    def wait_nats_is_available(self, nats_ip, max_retries=5):\n+    def wait_nats_is_available(self, max_retries=5):\n         retries = 0\n         while True:\n-            if asyncio.run(check_nats_is_available(nats_ip)):\n+            if asyncio.run(\n+                check_nats_is_available(self.nats_port, ssl_ctx=self.nats_ssl_context)\n+            ):\n                 break\n             else:\n                 retries += 1\n@@ -2453,11 +2478,24 @@ def start(self, destroy_dirs=True):\n \n             if self.with_nats and self.base_nats_cmd:\n                 logging.debug(\"Setup NATS\")\n+                os.makedirs(self.nats_cert_dir)\n+                env = os.environ.copy()\n+                env[\"NATS_CERT_DIR\"] = self.nats_cert_dir\n+                run_and_check(\n+                    p.join(self.base_dir, \"nats_certs.sh\"),\n+                    env=env,\n+                    detach=False,\n+                    nothrow=False,\n+                )\n+\n+                self.nats_ssl_context = ssl.create_default_context()\n+                self.nats_ssl_context.load_verify_locations(\n+                    p.join(self.nats_cert_dir, \"ca\", \"ca-cert.pem\")\n+                )\n                 subprocess_check_call(self.base_nats_cmd + common_opts)\n                 self.nats_docker_id = self.get_instance_docker_id(\"nats1\")\n                 self.up_called = True\n-                self.nats_ip = self.get_instance_ip(\"nats1\")\n-                self.wait_nats_is_available(self.nats_ip)\n+                self.wait_nats_is_available()\n \n             if self.with_hdfs and self.base_hdfs_cmd:\n                 logging.debug(\"Setup HDFS\")\ndiff --git a/tests/integration/test_storage_nats/nats_certs.sh b/tests/integration/test_storage_nats/nats_certs.sh\nnew file mode 100755\nindex 000000000000..689221c39e4b\n--- /dev/null\n+++ b/tests/integration/test_storage_nats/nats_certs.sh\n@@ -0,0 +1,13 @@\n+#!/bin/bash\n+set -euxo pipefail\n+\n+mkdir -p \"${NATS_CERT_DIR}/ca\"\n+mkdir -p \"${NATS_CERT_DIR}/nats\"\n+openssl req -newkey rsa:4096 -x509 -days 365 -nodes -batch -keyout \"${NATS_CERT_DIR}/ca/ca-key.pem\" -out \"${NATS_CERT_DIR}/ca/ca-cert.pem\" -subj \"/C=RU/ST=Some-State/O=Internet Widgits Pty Ltd/CN=ca\"\n+openssl req -newkey rsa:4096 -nodes -batch -keyout \"${NATS_CERT_DIR}/nats/server-key.pem\" -out \"${NATS_CERT_DIR}/nats/server-req.pem\" -subj \"/C=RU/ST=Some-State/O=Internet Widgits Pty Ltd/CN=server\"\n+openssl x509 -req -days 365 -in \"${NATS_CERT_DIR}/nats/server-req.pem\" -CA \"${NATS_CERT_DIR}/ca/ca-cert.pem\" -CAkey \"${NATS_CERT_DIR}/ca/ca-key.pem\" -CAcreateserial -out \"${NATS_CERT_DIR}/nats/server-cert.pem\" -extfile <(\n+cat <<-EOF\n+subjectAltName = DNS:localhost, DNS:nats1\n+EOF\n+)\n+rm -f \"${NATS_CERT_DIR}/nats/server-req.pem\"\ndiff --git a/tests/integration/test_storage_nats/test.py b/tests/integration/test_storage_nats/test.py\nindex a952f4b78a60..63dde8922a68 100644\n--- a/tests/integration/test_storage_nats/test.py\n+++ b/tests/integration/test_storage_nats/test.py\n@@ -9,11 +9,10 @@\n import math\n \n import asyncio\n-import nats\n import pytest\n from google.protobuf.internal.encoder import _VarintBytes\n from helpers.client import QueryRuntimeException\n-from helpers.cluster import ClickHouseCluster, check_nats_is_available\n+from helpers.cluster import ClickHouseCluster, check_nats_is_available, nats_connect_ssl\n from helpers.test_tools import TSV\n \n from . import nats_pb2\n@@ -35,11 +34,11 @@\n # Helpers\n \n \n-def wait_nats_to_start(nats_ip, timeout=180):\n+def wait_nats_to_start(nats_port, ssl_ctx=None, timeout=180):\n     start = time.time()\n     while time.time() - start < timeout:\n         try:\n-            if asyncio.run(check_nats_is_available(nats_ip)):\n+            if asyncio.run(check_nats_is_available(nats_port, ssl_ctx=ssl_ctx)):\n                 logging.debug(\"NATS is available\")\n                 return\n             time.sleep(0.5)\n@@ -63,10 +62,10 @@ def kill_nats(nats_id):\n     return p.returncode == 0\n \n \n-def revive_nats(nats_id, nats_ip):\n+def revive_nats(nats_id, nats_port):\n     p = subprocess.Popen((\"docker\", \"start\", nats_id), stdout=subprocess.PIPE)\n     p.communicate()\n-    wait_nats_to_start(nats_ip)\n+    wait_nats_to_start(nats_port)\n \n \n # Fixtures\n@@ -96,8 +95,13 @@ def nats_setup_teardown():\n # Tests\n \n \n-async def nats_produce_messages(ip, subject, messages=(), bytes=None):\n-    nc = await nats.connect(\"{}:4444\".format(ip), user=\"click\", password=\"house\")\n+async def nats_produce_messages(cluster_inst, subject, messages=(), bytes=None):\n+    nc = await nats_connect_ssl(\n+        cluster_inst.nats_port,\n+        user=\"click\",\n+        password=\"house\",\n+        ssl_ctx=cluster_inst.nats_ssl_context,\n+    )\n     logging.debug(\"NATS connection status: \" + str(nc.is_connected))\n \n     for message in messages:\n@@ -136,7 +140,7 @@ def test_nats_select(nats_cluster):\n     messages = []\n     for i in range(50):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"select\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"select\", messages))\n \n     # The order of messages in select * from test.nats is not guaranteed, so sleep to collect everything in one select\n     time.sleep(1)\n@@ -186,13 +190,13 @@ def test_nats_json_without_delimiter(nats_cluster):\n         messages += json.dumps({\"key\": i, \"value\": i}) + \"\\n\"\n \n     all_messages = [messages]\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"json\", all_messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"json\", all_messages))\n \n     messages = \"\"\n     for i in range(25, 50):\n         messages += json.dumps({\"key\": i, \"value\": i}) + \"\\n\"\n     all_messages = [messages]\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"json\", all_messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"json\", all_messages))\n \n     time.sleep(1)\n \n@@ -229,7 +233,7 @@ def test_nats_csv_with_delimiter(nats_cluster):\n     for i in range(50):\n         messages.append(\"{i}, {i}\".format(i=i))\n \n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"csv\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"csv\", messages))\n \n     time.sleep(1)\n \n@@ -268,7 +272,7 @@ def test_nats_tsv_with_delimiter(nats_cluster):\n     for i in range(50):\n         messages.append(\"{i}\\t{i}\".format(i=i))\n \n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"tsv\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"tsv\", messages))\n \n     result = \"\"\n     for _ in range(60):\n@@ -299,7 +303,7 @@ def test_nats_macros(nats_cluster):\n     message = \"\"\n     for i in range(50):\n         message += json.dumps({\"key\": i, \"value\": i}) + \"\\n\"\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"macro\", [message]))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"macro\", [message]))\n \n     time.sleep(1)\n \n@@ -344,7 +348,7 @@ def test_nats_materialized_view(nats_cluster):\n     for i in range(50):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n \n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"mv\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"mv\", messages))\n \n     time_limit_sec = 60\n     deadline = time.monotonic() + time_limit_sec\n@@ -389,7 +393,7 @@ def test_nats_materialized_view_with_subquery(nats_cluster):\n     messages = []\n     for i in range(50):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"mvsq\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"mvsq\", messages))\n \n     time_limit_sec = 60\n     deadline = time.monotonic() + time_limit_sec\n@@ -434,7 +438,7 @@ def test_nats_many_materialized_views(nats_cluster):\n     messages = []\n     for i in range(50):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"mmv\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"mmv\", messages))\n \n     time_limit_sec = 60\n     deadline = time.monotonic() + time_limit_sec\n@@ -485,7 +489,7 @@ def test_nats_protobuf(nats_cluster):\n         msg.value = str(i)\n         serialized_msg = msg.SerializeToString()\n         data = data + _VarintBytes(len(serialized_msg)) + serialized_msg\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"pb\", bytes=data))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"pb\", bytes=data))\n     data = b\"\"\n     for i in range(20, 21):\n         msg = nats_pb2.ProtoKeyValue()\n@@ -493,7 +497,7 @@ def test_nats_protobuf(nats_cluster):\n         msg.value = str(i)\n         serialized_msg = msg.SerializeToString()\n         data = data + _VarintBytes(len(serialized_msg)) + serialized_msg\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"pb\", bytes=data))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"pb\", bytes=data))\n     data = b\"\"\n     for i in range(21, 50):\n         msg = nats_pb2.ProtoKeyValue()\n@@ -501,7 +505,7 @@ def test_nats_protobuf(nats_cluster):\n         msg.value = str(i)\n         serialized_msg = msg.SerializeToString()\n         data = data + _VarintBytes(len(serialized_msg)) + serialized_msg\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"pb\", bytes=data))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"pb\", bytes=data))\n \n     result = \"\"\n     time_limit_sec = 60\n@@ -542,7 +546,7 @@ def test_nats_big_message(nats_cluster):\n         logging.debug(\"Table test.nats is not yet ready\")\n         time.sleep(0.5)\n \n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"big\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"big\", messages))\n \n     while True:\n         result = instance.query(\"SELECT count() FROM test.view\")\n@@ -600,7 +604,7 @@ def produce():\n         for _ in range(messages_num):\n             messages.append(json.dumps({\"key\": i[0], \"value\": i[0]}))\n             i[0] += 1\n-        asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"combo\", messages))\n+        asyncio.run(nats_produce_messages(nats_cluster, \"combo\", messages))\n \n     threads = []\n     threads_num = 20\n@@ -662,8 +666,11 @@ def test_nats_insert(nats_cluster):\n     insert_messages = []\n \n     async def sub_to_nats():\n-        nc = await nats.connect(\n-            \"{}:4444\".format(nats_cluster.nats_ip), user=\"click\", password=\"house\"\n+        nc = await nats_connect_ssl(\n+            nats_cluster.nats_port,\n+            user=\"click\",\n+            password=\"house\",\n+            ssl_ctx=nats_cluster.nats_ssl_context,\n         )\n         sub = await nc.subscribe(\"insert\")\n         await sub.unsubscribe(50)\n@@ -771,8 +778,11 @@ def test_nats_many_subjects_insert_right(nats_cluster):\n     insert_messages = []\n \n     async def sub_to_nats():\n-        nc = await nats.connect(\n-            \"{}:4444\".format(nats_cluster.nats_ip), user=\"click\", password=\"house\"\n+        nc = await nats_connect_ssl(\n+            nats_cluster.nats_port,\n+            user=\"click\",\n+            password=\"house\",\n+            ssl_ctx=nats_cluster.nats_ssl_context,\n         )\n         sub = await nc.subscribe(\"right_insert1\")\n         await sub.unsubscribe(50)\n@@ -1003,7 +1013,7 @@ def test_nats_virtual_column(nats_cluster):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n         i += 1\n \n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"virtuals\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"virtuals\", messages))\n \n     while True:\n         result = instance.query(\"SELECT count() FROM test.view\")\n@@ -1067,7 +1077,7 @@ def test_nats_virtual_column_with_materialized_view(nats_cluster):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n         i += 1\n \n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"virtuals_mv\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"virtuals_mv\", messages))\n \n     while True:\n         result = instance.query(\"SELECT count() FROM test.view\")\n@@ -1147,9 +1157,7 @@ def produce():\n         for _ in range(messages_num):\n             messages.append(json.dumps({\"key\": i[0], \"value\": i[0]}))\n             i[0] += 1\n-        asyncio.run(\n-            nats_produce_messages(nats_cluster.nats_ip, \"many_consumers\", messages)\n-        )\n+        asyncio.run(nats_produce_messages(nats_cluster, \"many_consumers\", messages))\n \n     threads = []\n     threads_num = 20\n@@ -1243,7 +1251,7 @@ def test_nats_restore_failed_connection_without_losses_on_write(nats_cluster):\n \n     kill_nats(nats_cluster.nats_docker_id)\n     time.sleep(4)\n-    revive_nats(nats_cluster.nats_docker_id, nats_cluster.nats_ip)\n+    revive_nats(nats_cluster.nats_docker_id, nats_cluster.nats_port)\n \n     while True:\n         result = instance.query(\"SELECT count(DISTINCT key) FROM test.view\")\n@@ -1310,7 +1318,7 @@ def test_nats_no_connection_at_startup_2(nats_cluster):\n     messages = []\n     for i in range(messages_num):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"cs\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"cs\", messages))\n \n     for _ in range(20):\n         result = instance.query(\"SELECT count() FROM test.view\")\n@@ -1353,9 +1361,7 @@ def test_nats_format_factory_settings(nats_cluster):\n         \"\"\"SELECT parseDateTimeBestEffort(CAST('2021-01-19T14:42:33.1829214Z', 'String'))\"\"\"\n     )\n \n-    asyncio.run(\n-        nats_produce_messages(nats_cluster.nats_ip, \"format_settings\", [message])\n-    )\n+    asyncio.run(nats_produce_messages(nats_cluster, \"format_settings\", [message]))\n \n     while True:\n         result = instance.query(\"SELECT date FROM test.format_settings\")\n@@ -1372,9 +1378,7 @@ def test_nats_format_factory_settings(nats_cluster):\n         \"\"\"\n     )\n \n-    asyncio.run(\n-        nats_produce_messages(nats_cluster.nats_ip, \"format_settings\", [message])\n-    )\n+    asyncio.run(nats_produce_messages(nats_cluster, \"format_settings\", [message]))\n     while True:\n         result = instance.query(\"SELECT date FROM test.view\")\n         if result == expected:\n@@ -1424,13 +1428,13 @@ def test_nats_drop_mv(nats_cluster):\n     messages = []\n     for i in range(20):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"mv\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"mv\", messages))\n \n     instance.query(\"DROP VIEW test.consumer\")\n     messages = []\n     for i in range(20, 40):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"mv\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"mv\", messages))\n \n     instance.query(\n         \"\"\"\n@@ -1441,7 +1445,7 @@ def test_nats_drop_mv(nats_cluster):\n     messages = []\n     for i in range(40, 50):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"mv\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"mv\", messages))\n \n     while True:\n         result = instance.query(\"SELECT * FROM test.view ORDER BY key\")\n@@ -1454,7 +1458,7 @@ def test_nats_drop_mv(nats_cluster):\n     messages = []\n     for i in range(50, 60):\n         messages.append(json.dumps({\"key\": i, \"value\": i}))\n-    asyncio.run(nats_produce_messages(nats_cluster.nats_ip, \"mv\", messages))\n+    asyncio.run(nats_produce_messages(nats_cluster, \"mv\", messages))\n \n     count = 0\n     while True:\n@@ -1477,7 +1481,7 @@ def test_nats_predefined_configuration(nats_cluster):\n \n     asyncio.run(\n         nats_produce_messages(\n-            nats_cluster.nats_ip, \"named\", [json.dumps({\"key\": 1, \"value\": 2})]\n+            nats_cluster, \"named\", [json.dumps({\"key\": 1, \"value\": 2})]\n         )\n     )\n     while True:\n",
  "problem_statement": "NATS is built with no TLS support\nI.e. \r\n```sql\r\n  CREATE TABLE queue (\r\n    key UInt64,\r\n    value UInt64\r\n  ) ENGINE = NATS \r\n    SETTINGS nats_url = 'demo.nats.io',\r\n             nats_subjects = 'subject1',\r\n             nats_format = 'JSONEachRow',\r\n             date_time_input_format = 'best_effort';\r\n```\r\nWill fail with \"compiled without TLS\"\r\nWill add patch that fixes it.\n",
  "hints_text": "",
  "created_at": "2022-07-24T14:15:25Z",
  "modified_files": [
    "contrib/nats-io-cmake/CMakeLists.txt",
    "src/Storages/NATS/NATSConnection.cpp",
    "src/Storages/NATS/NATSConnection.h"
  ],
  "modified_test_files": [
    "docker/test/integration/runner/compose/docker_compose_nats.yml",
    "tests/integration/helpers/cluster.py",
    "b/tests/integration/test_storage_nats/nats_certs.sh",
    "tests/integration/test_storage_nats/test.py"
  ]
}