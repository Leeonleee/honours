{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 6596,
  "instance_id": "ClickHouse__ClickHouse-6596",
  "issue_numbers": [
    "5296"
  ],
  "base_commit": "83104b3d5ed9786b9704b7623ec689f0917a9200",
  "patch": "diff --git a/dbms/src/Common/StringSearcher.h b/dbms/src/Common/StringSearcher.h\nindex 5e78ff23df19..25287db11f5d 100644\n--- a/dbms/src/Common/StringSearcher.h\n+++ b/dbms/src/Common/StringSearcher.h\n@@ -1,5 +1,7 @@\n #pragma once\n \n+#include <Common/Exception.h>\n+#include <Common/StringUtils/StringUtils.h>\n #include <Common/UTF8Helpers.h>\n #include <Core/Defines.h>\n #include <ext/range.h>\n@@ -23,6 +25,7 @@ namespace DB\n namespace ErrorCodes\n {\n     extern const int UNSUPPORTED_PARAMETER;\n+    extern const int BAD_ARGUMENTS;\n }\n \n \n@@ -157,7 +160,7 @@ class StringSearcher<false, false> : private StringSearcherBase\n #endif\n     }\n \n-    ALWAYS_INLINE bool compare(const UInt8 * pos) const\n+    ALWAYS_INLINE bool compare(const UInt8 * /*haystack*/, const UInt8 * /*haystack_end*/, const UInt8 * pos) const\n     {\n         static const Poco::UTF8Encoding utf8;\n \n@@ -374,7 +377,7 @@ class StringSearcher<false, true> : private StringSearcherBase\n #endif\n     }\n \n-    ALWAYS_INLINE bool compare(const UInt8 * pos) const\n+    ALWAYS_INLINE bool compare(const UInt8 * /*haystack*/, const UInt8 * /*haystack_end*/, const UInt8 * pos) const\n     {\n #ifdef __SSE4_1__\n         if (pageSafe(pos))\n@@ -567,7 +570,7 @@ class StringSearcher<true, ASCII> : private StringSearcherBase\n #endif\n     }\n \n-    ALWAYS_INLINE bool compare(const UInt8 * pos) const\n+    ALWAYS_INLINE bool compare(const UInt8 * /*haystack*/, const UInt8 * /*haystack_end*/, const UInt8 * pos) const\n     {\n #ifdef __SSE4_1__\n         if (pageSafe(pos))\n@@ -697,11 +700,81 @@ class StringSearcher<true, ASCII> : private StringSearcherBase\n     }\n };\n \n+// Searches for needle surrounded by token-separators.\n+// Separators are anything inside ASCII (0-128) and not alphanum.\n+// Any value outside of basic ASCII (>=128) is considered a non-separator symbol, hence UTF-8 strings\n+// should work just fine. But any Unicode whitespace is not considered a token separtor.\n+template <typename StringSearcher>\n+class TokenSearcher\n+{\n+    StringSearcher searcher;\n+    size_t needle_size;\n+\n+public:\n+    TokenSearcher(const char * const needle_, const size_t needle_size_)\n+        : searcher{needle_, needle_size_},\n+          needle_size(needle_size_)\n+    {\n+        if (std::any_of(reinterpret_cast<const UInt8 *>(needle_), reinterpret_cast<const UInt8 *>(needle_) + needle_size_, isTokenSeparator))\n+        {\n+            throw Exception{\"Needle must not contain whitespace or separator characters\", ErrorCodes::BAD_ARGUMENTS};\n+        }\n+\n+    }\n+\n+    ALWAYS_INLINE bool compare(const UInt8 * haystack, const UInt8 * haystack_end, const UInt8 * pos) const\n+    {\n+        // use searcher only if pos is in the beginning of token and pos + searcher.needle_size is end of token.\n+        if (isToken(haystack, haystack_end, pos))\n+            return searcher.compare(haystack, haystack_end, pos);\n+\n+        return false;\n+    }\n+\n+    const UInt8 * search(const UInt8 * haystack, const UInt8 * const haystack_end) const\n+    {\n+        // use searcher.search(), then verify that returned value is a token\n+        // if it is not, skip it and re-run\n+\n+        const UInt8 * pos = haystack;\n+        while (pos < haystack_end)\n+        {\n+            pos = searcher.search(pos, haystack_end);\n+            if (pos == haystack_end || isToken(haystack, haystack_end, pos))\n+                return pos;\n+\n+            // assuming that heendle does not contain any token separators.\n+            pos += needle_size;\n+        }\n+        return haystack_end;\n+    }\n+\n+    const UInt8 * search(const UInt8 * haystack, const size_t haystack_size) const\n+    {\n+        return search(haystack, haystack + haystack_size);\n+    }\n+\n+    ALWAYS_INLINE bool isToken(const UInt8 * haystack, const UInt8 * const haystack_end, const UInt8* p) const\n+    {\n+        return (p == haystack || isTokenSeparator(*(p - 1)))\n+             && (p + needle_size >= haystack_end || isTokenSeparator(*(p + needle_size)));\n+    }\n+\n+    ALWAYS_INLINE static bool isTokenSeparator(const UInt8 c)\n+    {\n+        if (isAlphaNumericASCII(c) || !isASCII(c))\n+            return false;\n+\n+        return true;\n+    }\n+};\n+\n \n using ASCIICaseSensitiveStringSearcher = StringSearcher<true, true>;\n using ASCIICaseInsensitiveStringSearcher = StringSearcher<false, true>;\n using UTF8CaseSensitiveStringSearcher = StringSearcher<true, false>;\n using UTF8CaseInsensitiveStringSearcher = StringSearcher<false, false>;\n+using ASCIICaseSensitiveTokenSearcher = TokenSearcher<ASCIICaseSensitiveStringSearcher>;\n \n \n /** Uses functions from libc.\ndiff --git a/dbms/src/Common/Volnitsky.h b/dbms/src/Common/Volnitsky.h\nindex 748cbe091386..c87bdd79dab2 100644\n--- a/dbms/src/Common/Volnitsky.h\n+++ b/dbms/src/Common/Volnitsky.h\n@@ -327,6 +327,8 @@ class VolnitskyBase\n     FallbackSearcher fallback_searcher;\n \n public:\n+    using Searcher = FallbackSearcher;\n+\n     /** haystack_size_hint - the expected total size of the haystack for `search` calls. Optional (zero means unspecified).\n       * If you specify it small enough, the fallback algorithm will be used,\n       *  since it is considered that it's useless to waste time initializing the hash table.\n@@ -373,7 +375,7 @@ class VolnitskyBase\n                 const auto res = pos - (hash[cell_num] - 1);\n \n                 /// pointer in the code is always padded array so we can use pagesafe semantics\n-                if (fallback_searcher.compare(res))\n+                if (fallback_searcher.compare(haystack, haystack_end, res))\n                     return res;\n             }\n         }\n@@ -520,7 +522,7 @@ class MultiVolnitskyBase\n                     {\n                         const auto res = pos - (hash[cell_num].off - 1);\n                         const size_t ind = hash[cell_num].id;\n-                        if (res + needles[ind].size <= haystack_end && fallback_searchers[ind].compare(res))\n+                        if (res + needles[ind].size <= haystack_end && fallback_searchers[ind].compare(haystack, haystack_end, res))\n                             return true;\n                     }\n                 }\n@@ -552,7 +554,7 @@ class MultiVolnitskyBase\n                     {\n                         const auto res = pos - (hash[cell_num].off - 1);\n                         const size_t ind = hash[cell_num].id;\n-                        if (res + needles[ind].size <= haystack_end && fallback_searchers[ind].compare(res))\n+                        if (res + needles[ind].size <= haystack_end && fallback_searchers[ind].compare(haystack, haystack_end, res))\n                             ans = std::min(ans, ind);\n                     }\n                 }\n@@ -590,7 +592,7 @@ class MultiVolnitskyBase\n                     {\n                         const auto res = pos - (hash[cell_num].off - 1);\n                         const size_t ind = hash[cell_num].id;\n-                        if (res + needles[ind].size <= haystack_end && fallback_searchers[ind].compare(res))\n+                        if (res + needles[ind].size <= haystack_end && fallback_searchers[ind].compare(haystack, haystack_end, res))\n                             ans = std::min<UInt64>(ans, res - haystack);\n                     }\n                 }\n@@ -625,7 +627,7 @@ class MultiVolnitskyBase\n                     {\n                         const auto * res = pos - (hash[cell_num].off - 1);\n                         const size_t ind = hash[cell_num].id;\n-                        if (ans[ind] == 0 && res + needles[ind].size <= haystack_end && fallback_searchers[ind].compare(res))\n+                        if (ans[ind] == 0 && res + needles[ind].size <= haystack_end && fallback_searchers[ind].compare(haystack, haystack_end, res))\n                             ans[ind] = count_chars(haystack, res);\n                     }\n                 }\n@@ -650,6 +652,8 @@ using VolnitskyUTF8 = VolnitskyBase<true, false, ASCIICaseSensitiveStringSearche\n using VolnitskyCaseInsensitive = VolnitskyBase<false, true, ASCIICaseInsensitiveStringSearcher>; /// ignores non-ASCII bytes\n using VolnitskyCaseInsensitiveUTF8 = VolnitskyBase<false, false, UTF8CaseInsensitiveStringSearcher>;\n \n+using VolnitskyToken = VolnitskyBase<true, true, ASCIICaseSensitiveTokenSearcher>;\n+\n using MultiVolnitsky = MultiVolnitskyBase<true, true, ASCIICaseSensitiveStringSearcher>;\n using MultiVolnitskyUTF8 = MultiVolnitskyBase<true, false, ASCIICaseSensitiveStringSearcher>;\n using MultiVolnitskyCaseInsensitive = MultiVolnitskyBase<false, true, ASCIICaseInsensitiveStringSearcher>;\ndiff --git a/dbms/src/Functions/FunctionsStringSearch.cpp b/dbms/src/Functions/FunctionsStringSearch.cpp\nindex 726eb8738afb..5d688232bd48 100644\n--- a/dbms/src/Functions/FunctionsStringSearch.cpp\n+++ b/dbms/src/Functions/FunctionsStringSearch.cpp\n@@ -434,6 +434,74 @@ struct MultiSearchFirstIndexImpl\n     }\n };\n \n+/** Token search the string, means that needle must be surrounded by some separator chars, like whitespace or puctuation.\n+  */\n+template <bool negate_result = false>\n+struct HasTokenImpl\n+{\n+    using ResultType = UInt8;\n+\n+    static void vector_constant(\n+        const ColumnString::Chars & data, const ColumnString::Offsets & offsets, const std::string & pattern, PaddedPODArray<UInt8> & res)\n+    {\n+        if (offsets.empty())\n+            return;\n+\n+        const UInt8 * begin = data.data();\n+        const UInt8 * pos = begin;\n+        const UInt8 * end = pos + data.size();\n+\n+        /// The current index in the array of strings.\n+        size_t i = 0;\n+\n+        VolnitskyToken searcher(pattern.data(), pattern.size(), end - pos);\n+\n+        /// We will search for the next occurrence in all rows at once.\n+        while (pos < end && end != (pos = searcher.search(pos, end - pos)))\n+        {\n+            /// Let's determine which index it refers to.\n+            while (begin + offsets[i] <= pos)\n+            {\n+                res[i] = negate_result;\n+                ++i;\n+            }\n+\n+            /// We check that the entry does not pass through the boundaries of strings.\n+            if (pos + pattern.size() < begin + offsets[i])\n+                res[i] = !negate_result;\n+            else\n+                res[i] = negate_result;\n+\n+            pos = begin + offsets[i];\n+            ++i;\n+        }\n+\n+        /// Tail, in which there can be no substring.\n+        if (i < res.size())\n+            memset(&res[i], negate_result, (res.size() - i) * sizeof(res[0]));\n+    }\n+\n+    static void constant_constant(const std::string & data, const std::string & pattern, UInt8 & res)\n+    {\n+        VolnitskyToken searcher(pattern.data(), pattern.size(), data.size());\n+        const auto found = searcher.search(data.c_str(), data.size()) != data.end().base();\n+        res = negate_result ^ found;\n+    }\n+\n+    template <typename... Args>\n+    static void vector_vector(Args &&...)\n+    {\n+        throw Exception(\"Function 'hasToken' does not support non-constant needle argument\", ErrorCodes::ILLEGAL_COLUMN);\n+    }\n+\n+    /// Search different needles in single haystack.\n+    template <typename... Args>\n+    static void constant_vector(Args &&...)\n+    {\n+        throw Exception(\"Function 'hasToken' does not support non-constant needle argument\", ErrorCodes::ILLEGAL_COLUMN);\n+    }\n+};\n+\n \n struct NamePosition\n {\n@@ -516,6 +584,11 @@ struct NameMultiSearchFirstPositionCaseInsensitiveUTF8\n     static constexpr auto name = \"multiSearchFirstPositionCaseInsensitiveUTF8\";\n };\n \n+struct NameHasToken\n+{\n+    static constexpr auto name = \"hasToken\";\n+};\n+\n \n using FunctionPosition = FunctionsStringSearch<PositionImpl<PositionCaseSensitiveASCII>, NamePosition>;\n using FunctionPositionUTF8 = FunctionsStringSearch<PositionImpl<PositionCaseSensitiveUTF8>, NamePositionUTF8>;\n@@ -542,6 +615,7 @@ using FunctionMultiSearchFirstPositionUTF8 = FunctionsMultiStringSearch<MultiSea\n using FunctionMultiSearchFirstPositionCaseInsensitive = FunctionsMultiStringSearch<MultiSearchFirstPositionImpl<PositionCaseInsensitiveASCII>, NameMultiSearchFirstPositionCaseInsensitive>;\n using FunctionMultiSearchFirstPositionCaseInsensitiveUTF8 = FunctionsMultiStringSearch<MultiSearchFirstPositionImpl<PositionCaseInsensitiveUTF8>, NameMultiSearchFirstPositionCaseInsensitiveUTF8>;\n \n+using FunctionHasToken = FunctionsStringSearch<HasTokenImpl<false>, NameHasToken>;\n \n void registerFunctionsStringSearch(FunctionFactory & factory)\n {\n@@ -570,6 +644,8 @@ void registerFunctionsStringSearch(FunctionFactory & factory)\n     factory.registerFunction<FunctionMultiSearchFirstPositionCaseInsensitive>();\n     factory.registerFunction<FunctionMultiSearchFirstPositionCaseInsensitiveUTF8>();\n \n+    factory.registerFunction<FunctionHasToken>();\n+\n     factory.registerAlias(\"locate\", NamePosition::name, FunctionFactory::CaseInsensitive);\n }\n }\ndiff --git a/dbms/src/Storages/MergeTree/MergeTreeIndexFullText.cpp b/dbms/src/Storages/MergeTree/MergeTreeIndexFullText.cpp\nindex 3625c6f1aa55..246ad6784b26 100644\n--- a/dbms/src/Storages/MergeTree/MergeTreeIndexFullText.cpp\n+++ b/dbms/src/Storages/MergeTree/MergeTreeIndexFullText.cpp\n@@ -168,6 +168,19 @@ const MergeTreeConditionFullText::AtomMap MergeTreeConditionFullText::atom_map\n                     return true;\n                 }\n         },\n+        {\n+                \"hasToken\",\n+                [] (RPNElement & out, const Field & value, const MergeTreeIndexFullText & idx)\n+                {\n+                    out.function = RPNElement::FUNCTION_EQUALS;\n+                    out.bloom_filter = std::make_unique<BloomFilter>(\n+                            idx.bloom_filter_size, idx.bloom_filter_hashes, idx.seed);\n+\n+                    const auto & str = value.get<String>();\n+                    stringToBloomFilter(str.c_str(), str.size(), idx.token_extractor_func, *out.bloom_filter);\n+                    return true;\n+                }\n+        },\n         {\n                 \"startsWith\",\n                 [] (RPNElement & out, const Field & value, const MergeTreeIndexFullText & idx)\n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/00990_hasToken.python b/dbms/tests/queries/0_stateless/00990_hasToken.python\nnew file mode 100755\nindex 000000000000..217d96dfe52f\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00990_hasToken.python\n@@ -0,0 +1,124 @@\n+#!/usr/bin/env python\n+# encoding: utf-8\n+\n+import re\n+\n+HAYSTACKS = [\n+    \"hay hay hay hay hay hay hay hay hay hay hay hay hay hay hay hay hay hay needle\",\n+    \"needle hay hay hay hay hay hay hay hay hay hay hay hay hay hay hay hay hay hay\",\n+    \"hay hay hay hay hay hay hay hay hay needle hay hay hay hay hay hay hay hay hay\",\n+]\n+\n+NEEDLE = \"needle\"\n+\n+HAY_RE = re.compile(r'\\bhay\\b', re.IGNORECASE)\n+NEEDLE_RE = re.compile(r'\\bneedle\\b', re.IGNORECASE)\n+\n+def replace_follow_case(replacement):\n+    def func(match):\n+        g = match.group()\n+        if g.islower(): return replacement.lower()\n+        if g.istitle(): return replacement.title()\n+        if g.isupper(): return replacement.upper()\n+        return replacement\n+    return func\n+\n+def replace_separators(query, new_sep):\n+    SEP_RE = re.compile('\\\\s+')\n+    result = SEP_RE.sub(new_sep, query)\n+    return result\n+\n+def enlarge_haystack(query, times, separator=''):\n+    return HAY_RE.sub(replace_follow_case(('hay' + separator) * times), query)\n+\n+def small_needle(query):\n+    return NEEDLE_RE.sub(replace_follow_case('n'), query)\n+\n+def remove_needle(query):\n+    return NEEDLE_RE.sub('', query)\n+\n+def replace_needle(query, new_needle):\n+    return NEEDLE_RE.sub(new_needle, query)\n+\n+# with str.lower, str.uppert, str.title and such\n+def transform_needle(query, string_transformation_func):\n+    def replace_with_transformation(match):\n+        g = match.group()\n+        return string_transformation_func(g)\n+\n+    return NEEDLE_RE.sub(replace_with_transformation, query)\n+\n+\n+def create_cases(table_row_template, table_query_template, const_query_template):\n+    const_queries = []\n+    table_rows = []\n+    table_queries = set()\n+\n+    def add_case(haystack, needle, match):\n+        match = int(match)\n+        const_queries.append(const_query_template.format(haystack=haystack, needle=needle, match=match))\n+        table_queries.add(table_query_template.format(haystack=haystack, needle=needle, match=match))\n+        table_rows.append(table_row_template.format(haystack=haystack, needle=needle, match=match))\n+\n+    # Negative cases\n+    add_case(remove_needle(HAYSTACKS[0]), NEEDLE, False)\n+    for haystack in HAYSTACKS:\n+        add_case(transform_needle(haystack, str.title), NEEDLE, False)\n+        sep = ''\n+        h = replace_separators(haystack, sep)\n+        add_case(h, NEEDLE, False)\n+        add_case(small_needle(h), small_needle(NEEDLE), False)\n+        add_case(enlarge_haystack(h, 10, sep), NEEDLE, False)\n+\n+    # positive cases\n+    for haystack in HAYSTACKS:\n+        add_case(transform_needle(haystack, str.title), transform_needle(NEEDLE, str.title), True)\n+        add_case(transform_needle(haystack, str.upper), transform_needle(NEEDLE, str.upper), True)\n+\n+        # Not checking all separators since some (like ' and \\n) cause issues when coupled with\n+        # re-based replacement and quoting in query\n+        # other are rare in practice and checking all separators makes this test too lengthy.\n+\n+        # r'\\\\\\\\' turns into a single '\\' in query\n+        #separators = list(''' \\t`~!@#$%^&*()-=+|]}[{\";:/?.>,<''') + [r'\\\\\\\\']\n+        separators = list(''' \\t;:?.,''') + [r'\\\\\\\\']\n+        for sep in separators:\n+            h = replace_separators(haystack, sep)\n+            add_case(h, NEEDLE, True)\n+            add_case(small_needle(h), small_needle(NEEDLE), True)\n+            add_case(enlarge_haystack(h, 200, sep), NEEDLE, True)\n+            add_case(replace_needle(h, '\u0438\u0433\u043e\u043b\u043a\u0430'), replace_needle(NEEDLE, '\u0438\u0433\u043e\u043b\u043a\u0430'), True)\n+            add_case(replace_needle(h, '\u6307\u9488'), replace_needle(NEEDLE, '\u6307\u9488'), True)\n+\n+    return table_rows, table_queries, const_queries\n+\n+def main():\n+\n+    def query(x):\n+        print x\n+\n+    CONST_QUERY = \"\"\"SELECT hasToken('{haystack}', '{needle}'), ' expecting ', {match};\"\"\"\n+    #SELECT hasToken(haystack, '{needle}') FROM ht WHERE needle = '{needle}' AND match = {match};\"\"\"\n+    TABLE_QUERY = \"\"\"WITH '{needle}' as n SELECT haystack, needle, hasToken(haystack, n) as result FROM ht WHERE needle = n AND result != match;\"\"\"\n+    TABLE_ROW = \"\"\"('{haystack}', '{needle}', {match})\"\"\"\n+\n+    rows, table_queries, const_queries = create_cases(TABLE_ROW, TABLE_QUERY, CONST_QUERY)\n+    for q in const_queries:\n+        query(q)\n+\n+    query(\"\"\"DROP TABLE IF EXISTS ht;\n+    CREATE TABLE IF NOT EXISTS\n+    ht\n+(\n+    haystack String,\n+    needle String,\n+    match UInt8\n+)\n+ENGINE MergeTree()\n+ORDER BY haystack;\n+INSERT INTO ht VALUES {values};\"\"\".format(values=\", \".join(rows)))\n+    for q in sorted(table_queries):\n+        query(q)\n+\n+if __name__ == '__main__':\n+    main()\ndiff --git a/dbms/tests/queries/0_stateless/00990_hasToken.reference b/dbms/tests/queries/0_stateless/00990_hasToken.reference\nnew file mode 100644\nindex 000000000000..867c0c1c691f\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00990_hasToken.reference\n@@ -0,0 +1,139 @@\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+0\t expecting \t0\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\n+1\t expecting \t1\ndiff --git a/dbms/tests/queries/0_stateless/00990_hasToken.sh b/dbms/tests/queries/0_stateless/00990_hasToken.sh\nnew file mode 100755\nindex 000000000000..4ccb77b8ecc9\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00990_hasToken.sh\n@@ -0,0 +1,8 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+# We should have correct env vars from shell_config.sh to run this test\n+\n+python $CURDIR/00990_hasToken.python | ${CLICKHOUSE_CLIENT} -nm\ndiff --git a/dbms/tests/queries/0_stateless/00990_hasToken_and_tokenbf.reference b/dbms/tests/queries/0_stateless/00990_hasToken_and_tokenbf.reference\nnew file mode 100644\nindex 000000000000..10e8f0d2c592\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00990_hasToken_and_tokenbf.reference\n@@ -0,0 +1,3 @@\n+2007\n+2007\n+2007\ndiff --git a/dbms/tests/queries/0_stateless/00990_hasToken_and_tokenbf.sql b/dbms/tests/queries/0_stateless/00990_hasToken_and_tokenbf.sql\nnew file mode 100644\nindex 000000000000..60e4d959417c\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00990_hasToken_and_tokenbf.sql\n@@ -0,0 +1,33 @@\n+SET allow_experimental_data_skipping_indices = 1;\n+\n+DROP TABLE IF EXISTS bloom_filter;\n+\n+CREATE TABLE bloom_filter\n+(\n+    id UInt64,\n+    s String,\n+    INDEX tok_bf (s, lower(s)) TYPE tokenbf_v1(512, 3, 0) GRANULARITY 1\n+) ENGINE = MergeTree() ORDER BY id SETTINGS index_granularity = 8;\n+\n+insert into bloom_filter select number, 'yyy,uuu' from numbers(1024);\n+insert into bloom_filter select number+2000, 'abc,def,zzz' from numbers(8);\n+insert into bloom_filter select number+3000, 'yyy,uuu' from numbers(1024);\n+insert into bloom_filter select number+3000, 'abcdefzzz' from numbers(1024);\n+\n+set max_rows_to_read = 16;\n+\n+SELECT max(id) FROM bloom_filter WHERE hasToken(s, 'abc');\n+SELECT max(id) FROM bloom_filter WHERE hasToken(s, 'def');\n+SELECT max(id) FROM bloom_filter WHERE hasToken(s, 'zzz');\n+\n+-- invert result\n+-- this does not work as expected, reading more rows that it should\n+-- SELECT max(id) FROM bloom_filter WHERE NOT hasToken(s, 'yyy');\n+\n+-- accessing to many rows\n+SELECT max(id) FROM bloom_filter WHERE hasToken(s, 'yyy'); -- { serverError 158 }\n+\n+-- this syntax is not supported by tokenbf\n+SELECT max(id) FROM bloom_filter WHERE hasToken(s, 'zzz') == 1; -- { serverError 158 }\n+\n+DROP TABLE bloom_filter;\n\\ No newline at end of file\n",
  "problem_statement": "hasToken function (tokenbf_v1 related)\n## Use case.\r\n\r\nLet's imagine that we have a field with tokens, for example, comma-separated list of tags, and a tokenbf_v1 skip index on that field.\r\n\r\nWhen searching with `LIKE` in that field skip index can only be used if the whole token is appeared in like expression (i.e. with some separators around): i.e. `WHERE field LIKE '%,tag,%'`.\r\n\r\nWhen you search with the expression `WHERE field LIKE '%tag%'` bloom filter cannot be used (because otherwise partial matches tagA, tagB will be skipped).\r\n\r\nFrom the other hand when looking with that expression - `WHERE field LIKE '%,tag,%'` skip index fill find the needed blocks, but after that real `LIKE` will be applied to the real column content it will throw away the values when the tag appears on last/first position (and don't have 2 commas around). \r\n\r\nSo current solution with token searches is not really usable - as a workaround you can always add delimiters at the beginning and the end of the string, but it doesn't sound great. \r\n\r\n## proposed solution\r\n\r\nIntroduce the special function `hasToken` which will allow searching by tokens, and will support bloom filter as well.\r\n\r\n1) implement string function `hasToken(haystack, needle)` similar to `position` / `like`\r\nhttps://github.com/yandex/ClickHouse/blob/295a4a8684bd6819e01abccf47e29dd676f9fa50/dbms/src/Functions/FunctionsStringSearch.h\r\n\r\nwhich will check if token `needle` appears in string `haystack`. For spiting `heystack` to tokens - try to use that: \r\nhttps://github.com/yandex/ClickHouse/blob/45b7588ab1e8a8df2e27ae95177f3d0850b1088e/dbms/src/Storages/MergeTree/MergeTreeIndexFullText.cpp#L618\r\n\r\n2) after p. 1 will be working properly and tested - add support for `hasToken` in token_bf filter - see https://github.com/yandex/ClickHouse/blob/45b7588ab1e8a8df2e27ae95177f3d0850b1088e/dbms/src/Storages/MergeTree/MergeTreeIndexFullText.cpp#L123 \r\n\r\n\r\n\r\n\r\nSee also: #5262\r\n\r\n/cc @nikvas0 \n",
  "hints_text": "",
  "created_at": "2019-08-21T14:43:03Z"
}