diff --git a/docker/test/fasttest/run.sh b/docker/test/fasttest/run.sh
index 43c1add74ccf..c4493de477c8 100755
--- a/docker/test/fasttest/run.sh
+++ b/docker/test/fasttest/run.sh
@@ -393,6 +393,9 @@ function run_tests
         01853_s2_cells_intersect
         01854_s2_cap_contains
         01854_s2_cap_union
+
+        # needs s3
+        01944_insert_partition_by
     )
 
     time clickhouse-test --hung-check -j 8 --order=random --use-skip-list \
diff --git a/tests/integration/test_storage_s3/test.py b/tests/integration/test_storage_s3/test.py
index 5908def82979..87f9fec57b59 100644
--- a/tests/integration/test_storage_s3/test.py
+++ b/tests/integration/test_storage_s3/test.py
@@ -146,6 +146,59 @@ def test_put(started_cluster, maybe_auth, positive, compression):
         assert values_csv == get_s3_file_content(started_cluster, bucket, filename)
 
 
+def test_partition_by(started_cluster):
+    bucket = started_cluster.minio_bucket
+    instance = started_cluster.instances["dummy"]  # type: ClickHouseInstance
+    table_format = "column1 UInt32, column2 UInt32, column3 UInt32"
+    partition_by = "column3"
+    values = "(1, 2, 3), (3, 2, 1), (78, 43, 45)"
+    filename = "test_{_partition_id}.csv"
+    put_query = f"""INSERT INTO TABLE FUNCTION
+        s3('http://{started_cluster.minio_host}:{started_cluster.minio_port}/{bucket}/{filename}', 'CSV', '{table_format}')
+        PARTITION BY {partition_by} VALUES {values}"""
+
+    run_query(instance, put_query)
+
+    assert "1,2,3
" == get_s3_file_content(started_cluster, bucket, "test_3.csv")
+    assert "3,2,1
" == get_s3_file_content(started_cluster, bucket, "test_1.csv")
+    assert "78,43,45
" == get_s3_file_content(started_cluster, bucket, "test_45.csv")
+
+
+def test_partition_by_string_column(started_cluster):
+    bucket = started_cluster.minio_bucket
+    instance = started_cluster.instances["dummy"]  # type: ClickHouseInstance
+    table_format = "col_num UInt32, col_str String"
+    partition_by = "col_str"
+    values = "(1, 'foo/bar'), (3, 'йцук'), (78, '你好')"
+    filename = "test_{_partition_id}.csv"
+    put_query = f"""INSERT INTO TABLE FUNCTION
+        s3('http://{started_cluster.minio_host}:{started_cluster.minio_port}/{bucket}/{filename}', 'CSV', '{table_format}')
+        PARTITION BY {partition_by} VALUES {values}"""
+
+    run_query(instance, put_query)
+
+    assert '1,"foo/bar"
' == get_s3_file_content(started_cluster, bucket, "test_foo/bar.csv")
+    assert '3,"йцук"
' == get_s3_file_content(started_cluster, bucket, "test_йцук.csv")
+    assert '78,"你好"
' == get_s3_file_content(started_cluster, bucket, "test_你好.csv")
+
+
+def test_partition_by_const_column(started_cluster):
+    bucket = started_cluster.minio_bucket
+    instance = started_cluster.instances["dummy"]  # type: ClickHouseInstance
+    table_format = "column1 UInt32, column2 UInt32, column3 UInt32"
+    values = "(1, 2, 3), (3, 2, 1), (78, 43, 45)"
+    partition_by = "'88'"
+    values_csv = "1,2,3
3,2,1
78,43,45
"
+    filename = "test_{_partition_id}.csv"
+    put_query = f"""INSERT INTO TABLE FUNCTION
+        s3('http://{started_cluster.minio_host}:{started_cluster.minio_port}/{bucket}/{filename}', 'CSV', '{table_format}')
+        PARTITION BY {partition_by} VALUES {values}"""
+
+    run_query(instance, put_query)
+
+    assert values_csv == get_s3_file_content(started_cluster, bucket, "test_88.csv")
+
+
 @pytest.mark.parametrize("special", [
     "space",
     "plus"
diff --git a/tests/queries/0_stateless/01944_insert_partition_by.reference b/tests/queries/0_stateless/01944_insert_partition_by.reference
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tests/queries/0_stateless/01944_insert_partition_by.sql b/tests/queries/0_stateless/01944_insert_partition_by.sql
new file mode 100644
index 000000000000..1c7d96d77620
--- /dev/null
+++ b/tests/queries/0_stateless/01944_insert_partition_by.sql
@@ -0,0 +1,9 @@
+INSERT INTO TABLE FUNCTION file('foo.csv', 'CSV', 'id Int32, val Int32') PARTITION BY val VALUES (1, 1), (2, 2); -- { serverError NOT_IMPLEMENTED }
+INSERT INTO TABLE FUNCTION s3('http://localhost:9001/foo/test_{_partition_id}.csv', 'admin', 'admin', 'CSV', 'id Int32, val String') PARTITION BY val VALUES (1, '\r
'); -- { serverError CANNOT_PARSE_TEXT }
+INSERT INTO TABLE FUNCTION s3('http://localhost:9001/foo/test_{_partition_id}.csv', 'admin', 'admin', 'CSV', 'id Int32, val String') PARTITION BY val VALUES (1, 'abc\x00abc'); -- { serverError CANNOT_PARSE_TEXT }
+INSERT INTO TABLE FUNCTION s3('http://localhost:9001/foo/test_{_partition_id}.csv', 'admin', 'admin', 'CSV', 'id Int32, val String') PARTITION BY val VALUES (1, 'abc\xc3\x28abc'); -- { serverError CANNOT_PARSE_TEXT }
+INSERT INTO TABLE FUNCTION s3('http://localhost:9001/foo/test_{_partition_id}.csv', 'admin', 'admin', 'CSV', 'id Int32, val String') PARTITION BY val VALUES (1, 'abc}{abc'); -- { serverError CANNOT_PARSE_TEXT }
+INSERT INTO TABLE FUNCTION s3('http://localhost:9001/foo/test_{_partition_id}.csv', 'admin', 'admin', 'CSV', 'id Int32, val String') PARTITION BY val VALUES (1, 'abc*abc'); -- { serverError CANNOT_PARSE_TEXT }
+INSERT INTO TABLE FUNCTION s3('http://localhost:9001/foo/{_partition_id}', 'admin', 'admin', 'CSV', 'id Int32, val String') PARTITION BY val VALUES (1, ''); -- { serverError BAD_ARGUMENTS }
+INSERT INTO TABLE FUNCTION s3('http://localhost:9001/{_partition_id}/key.csv', 'admin', 'admin', 'CSV', 'id Int32, val String') PARTITION BY val VALUES (1, ''); -- { serverError BAD_ARGUMENTS }
+INSERT INTO TABLE FUNCTION s3('http://localhost:9001/{_partition_id}/key.csv', 'admin', 'admin', 'CSV', 'id Int32, val String') PARTITION BY val VALUES (1, 'aa/bb'); -- { serverError CANNOT_PARSE_TEXT }
diff --git a/tests/queries/0_stateless/arcadia_skip_list.txt b/tests/queries/0_stateless/arcadia_skip_list.txt
index 606015c369ff..8b97f4dcfa42 100644
--- a/tests/queries/0_stateless/arcadia_skip_list.txt
+++ b/tests/queries/0_stateless/arcadia_skip_list.txt
@@ -267,3 +267,4 @@
 01428_h3_range_check
 01442_h3kring_range_check
 01906_h3_to_geo
+01944_insert_partition_by
