{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 62120,
  "instance_id": "ClickHouse__ClickHouse-62120",
  "issue_numbers": [
    "53643",
    "49929"
  ],
  "base_commit": "090ef99339bbd977c6ceab2169446b794183c131",
  "patch": "diff --git a/src/Storages/StorageS3.cpp b/src/Storages/StorageS3.cpp\nindex 0371a9de08a9..e65d0cb5be47 100644\n--- a/src/Storages/StorageS3.cpp\n+++ b/src/Storages/StorageS3.cpp\n@@ -191,7 +191,7 @@ class StorageS3Source::DisclosedGlobIterator::Impl : WithContext\n     Impl(\n         const S3::Client & client_,\n         const S3::URI & globbed_uri_,\n-        const ActionsDAG::Node * predicate,\n+        const ActionsDAG::Node * predicate_,\n         const NamesAndTypesList & virtual_columns_,\n         ContextPtr context_,\n         KeysWithInfo * read_keys_,\n@@ -200,6 +200,7 @@ class StorageS3Source::DisclosedGlobIterator::Impl : WithContext\n         : WithContext(context_)\n         , client(client_.clone())\n         , globbed_uri(globbed_uri_)\n+        , predicate(predicate_)\n         , virtual_columns(virtual_columns_)\n         , read_keys(read_keys_)\n         , request_settings(request_settings_)\n@@ -210,32 +211,11 @@ class StorageS3Source::DisclosedGlobIterator::Impl : WithContext\n         if (globbed_uri.bucket.find_first_of(\"*?{\") != std::string::npos)\n             throw Exception(ErrorCodes::UNEXPECTED_EXPRESSION, \"Expression can not have wildcards inside bucket name\");\n \n-        const String key_prefix = globbed_uri.key.substr(0, globbed_uri.key.find_first_of(\"*?{\"));\n+        expanded_keys = expandSelectionGlob(globbed_uri.key);\n+        expanded_keys_iter = expanded_keys.begin();\n \n-        /// We don't have to list bucket, because there is no asterisks.\n-        if (key_prefix.size() == globbed_uri.key.size())\n-        {\n-            buffer.emplace_back(std::make_shared<KeyWithInfo>(globbed_uri.key, std::nullopt));\n-            buffer_iter = buffer.begin();\n-            is_finished = true;\n-            return;\n-        }\n-\n-        request.SetBucket(globbed_uri.bucket);\n-        request.SetPrefix(key_prefix);\n-        request.SetMaxKeys(static_cast<int>(request_settings.list_object_keys_size));\n-\n-        outcome_future = listObjectsAsync();\n-\n-        matcher = std::make_unique<re2::RE2>(makeRegexpPatternFromGlobs(globbed_uri.key));\n-        if (!matcher->ok())\n-            throw Exception(ErrorCodes::CANNOT_COMPILE_REGEXP,\n-                \"Cannot compile regex from glob ({}): {}\", globbed_uri.key, matcher->error());\n-\n-        recursive = globbed_uri.key == \"/**\" ? true : false;\n-\n-        filter_dag = VirtualColumnUtils::createPathAndFileFilterDAG(predicate, virtual_columns);\n-        fillInternalBufferAssumeLocked();\n+        fillBufferForKey(*expanded_keys_iter);\n+        expanded_keys_iter++;\n     }\n \n     KeyWithInfoPtr next(size_t)\n@@ -249,6 +229,14 @@ class StorageS3Source::DisclosedGlobIterator::Impl : WithContext\n         return buffer.size();\n     }\n \n+    bool hasMore()\n+    {\n+        if (buffer.empty())\n+            return !(expanded_keys_iter == expanded_keys.end() && is_finished_for_key);\n+        else\n+            return true;\n+    }\n+\n     ~Impl()\n     {\n         list_objects_pool.wait();\n@@ -257,6 +245,41 @@ class StorageS3Source::DisclosedGlobIterator::Impl : WithContext\n private:\n     using ListObjectsOutcome = Aws::S3::Model::ListObjectsV2Outcome;\n \n+    void fillBufferForKey(const std::string & uri_key)\n+    {\n+        is_finished_for_key = false;\n+        const String key_prefix = uri_key.substr(0, uri_key.find_first_of(\"*?{\"));\n+\n+        /// We don't have to list bucket, because there is no asterisks.\n+        if (key_prefix.size() == uri_key.size())\n+        {\n+            buffer.clear();\n+            buffer.emplace_back(std::make_shared<KeyWithInfo>(uri_key, std::nullopt));\n+            buffer_iter = buffer.begin();\n+            if (read_keys)\n+                read_keys->insert(read_keys->end(), buffer.begin(), buffer.end());\n+            is_finished_for_key = true;\n+            return;\n+        }\n+\n+        request = {};\n+        request.SetBucket(globbed_uri.bucket);\n+        request.SetPrefix(key_prefix);\n+        request.SetMaxKeys(static_cast<int>(request_settings.list_object_keys_size));\n+\n+        outcome_future = listObjectsAsync();\n+\n+        matcher = std::make_unique<re2::RE2>(makeRegexpPatternFromGlobs(uri_key));\n+        if (!matcher->ok())\n+            throw Exception(ErrorCodes::CANNOT_COMPILE_REGEXP,\n+                            \"Cannot compile regex from glob ({}): {}\", uri_key, matcher->error());\n+\n+        recursive = globbed_uri.key == \"/**\";\n+\n+        filter_dag = VirtualColumnUtils::createPathAndFileFilterDAG(predicate, virtual_columns);\n+        fillInternalBufferAssumeLocked();\n+    }\n+\n     KeyWithInfoPtr nextAssumeLocked()\n     {\n         do\n@@ -270,7 +293,18 @@ class StorageS3Source::DisclosedGlobIterator::Impl : WithContext\n                 /// So we get object info lazily here on 'next()' request.\n                 if (!answer->info)\n                 {\n-                    answer->info = S3::getObjectInfo(*client, globbed_uri.bucket, answer->key, globbed_uri.version_id, request_settings);\n+                    try\n+                    {\n+                        answer->info = S3::getObjectInfo(*client, globbed_uri.bucket, answer->key, globbed_uri.version_id, request_settings);\n+                    }\n+                    catch (...)\n+                    {\n+                        /// if no such file AND there was no `{}` glob -- this is an exception\n+                        /// otherwise ignore it, this is acceptable\n+                        if (expanded_keys.size() == 1)\n+                            throw;\n+                        continue;\n+                    }\n                     if (file_progress_callback)\n                         file_progress_callback(FileProgress(0, answer->info->size));\n                 }\n@@ -278,8 +312,17 @@ class StorageS3Source::DisclosedGlobIterator::Impl : WithContext\n                 return answer;\n             }\n \n-            if (is_finished)\n-                return {};\n+            if (is_finished_for_key)\n+            {\n+                if (expanded_keys_iter != expanded_keys.end())\n+                {\n+                    fillBufferForKey(*expanded_keys_iter);\n+                    expanded_keys_iter++;\n+                    continue;\n+                }\n+                else\n+                    return {};\n+            }\n \n             try\n             {\n@@ -293,7 +336,7 @@ class StorageS3Source::DisclosedGlobIterator::Impl : WithContext\n                 /// it may take some time for threads to stop processors and they\n                 /// may still use this iterator after exception is thrown.\n                 /// To avoid this UB, reset the buffer and return defaults for further calls.\n-                is_finished = true;\n+                is_finished_for_key = true;\n                 buffer.clear();\n                 buffer_iter = buffer.begin();\n                 throw;\n@@ -317,9 +360,9 @@ class StorageS3Source::DisclosedGlobIterator::Impl : WithContext\n         const auto & result_batch = outcome.GetResult().GetContents();\n \n         /// It returns false when all objects were returned\n-        is_finished = !outcome.GetResult().GetIsTruncated();\n+        is_finished_for_key = !outcome.GetResult().GetIsTruncated();\n \n-        if (!is_finished)\n+        if (!is_finished_for_key)\n         {\n             /// Even if task is finished the thread may be not freed in pool.\n             /// So wait until it will be freed before scheduling a new task.\n@@ -399,14 +442,18 @@ class StorageS3Source::DisclosedGlobIterator::Impl : WithContext\n     KeysWithInfo buffer;\n     KeysWithInfo::iterator buffer_iter;\n \n+    std::vector<String> expanded_keys;\n+    std::vector<String>::iterator expanded_keys_iter;\n+\n     std::unique_ptr<S3::Client> client;\n     S3::URI globbed_uri;\n+    const ActionsDAG::Node * predicate;\n     ASTPtr query;\n     NamesAndTypesList virtual_columns;\n     ActionsDAGPtr filter_dag;\n     std::unique_ptr<re2::RE2> matcher;\n     bool recursive{false};\n-    bool is_finished{false};\n+    bool is_finished_for_key{false};\n     KeysWithInfo * read_keys;\n \n     S3::ListObjectsV2Request request;\n@@ -438,7 +485,16 @@ StorageS3Source::KeyWithInfoPtr StorageS3Source::DisclosedGlobIterator::next(siz\n \n size_t StorageS3Source::DisclosedGlobIterator::estimatedKeysCount()\n {\n-    return pimpl->objectsCount();\n+    if (pimpl->hasMore())\n+    {\n+        /// 1000 files were listed, and we cannot make any estimation of _how many more_ there are (because we list bucket lazily);\n+        /// If there are more objects in the bucket, limiting the number of streams is the last thing we may want to do\n+        /// as it would lead to serious slow down of the execution, since objects are going\n+        /// to be fetched sequentially rather than in-parallel with up to <max_threads> times.\n+        return std::numeric_limits<size_t>::max();\n+    }\n+    else\n+        return pimpl->objectsCount();\n }\n \n class StorageS3Source::KeysIterator::Impl\n@@ -1236,8 +1292,10 @@ void ReadFromStorageS3Step::initializePipeline(QueryPipelineBuilder & pipeline,\n     if (estimated_keys_count > 1)\n         num_streams = std::min(num_streams, estimated_keys_count);\n     else\n-        /// Disclosed glob iterator can underestimate the amount of keys in some cases. We will keep one stream for this particular case.\n+    {\n+        /// The amount of keys (zero) was probably underestimated. We will keep one stream for this particular case.\n         num_streams = 1;\n+    }\n \n     const size_t max_threads = context->getSettingsRef().max_threads;\n     const size_t max_parsing_threads = num_streams >= max_threads ? 1 : (max_threads / std::max(num_streams, 1ul));\n",
  "test_patch": "diff --git a/tests/integration/test_storage_s3/test.py b/tests/integration/test_storage_s3/test.py\nindex 1e330cc1744f..dc929b7db466 100644\n--- a/tests/integration/test_storage_s3/test.py\n+++ b/tests/integration/test_storage_s3/test.py\n@@ -678,6 +678,54 @@ def add_tales(start, end):\n     assert run_query(instance, query).splitlines() == [\"1001\\t1001\\t1001\\t1001\"]\n \n \n+# a bit simplified version of scheherazade test\n+# checks e.g. `prefix{1,2}/file*.csv`, where there are more than 1000 files under prefix1.\n+def test_s3_glob_many_objects_under_selection(started_cluster):\n+    bucket = started_cluster.minio_bucket\n+    instance = started_cluster.instances[\"dummy\"]  # type: ClickHouseInstance\n+    table_format = \"column1 UInt32, column2 UInt32, column3 UInt32\"\n+    values = \"(1, 1, 1)\"\n+    jobs = []\n+    for thread_num in range(16):\n+\n+        def create_files(thread_num):\n+            for f_num in range(thread_num * 63, thread_num * 63 + 63):\n+                path = f\"folder1/file{f_num}.csv\"\n+                query = \"insert into table function s3('http://{}:{}/{}/{}', 'CSV', '{}') values {}\".format(\n+                    started_cluster.minio_ip,\n+                    MINIO_INTERNAL_PORT,\n+                    bucket,\n+                    path,\n+                    table_format,\n+                    values,\n+                )\n+                run_query(instance, query)\n+\n+        jobs.append(threading.Thread(target=create_files, args=(thread_num,)))\n+        jobs[-1].start()\n+\n+    query = \"insert into table function s3('http://{}:{}/{}/{}', 'CSV', '{}') values {}\".format(\n+        started_cluster.minio_ip,\n+        MINIO_INTERNAL_PORT,\n+        bucket,\n+        f\"folder2/file0.csv\",\n+        table_format,\n+        values,\n+    )\n+    run_query(instance, query)\n+\n+    for job in jobs:\n+        job.join()\n+\n+    query = \"select count(), sum(column1), sum(column2), sum(column3) from s3('http://{}:{}/{}/folder{{1,2}}/file*.csv', 'CSV', '{}')\".format(\n+        started_cluster.minio_redirect_host,\n+        started_cluster.minio_redirect_port,\n+        bucket,\n+        table_format,\n+    )\n+    assert run_query(instance, query).splitlines() == [\"1009\\t1009\\t1009\\t1009\"]\n+\n+\n def run_s3_mocks(started_cluster):\n     script_dir = os.path.join(os.path.dirname(__file__), \"s3_mocks\")\n     start_mock_servers(\n@@ -1768,13 +1816,27 @@ def test(storage_name):\n         check_cache(instance, [])\n \n         run_describe_query(instance, files, storage_name, started_cluster, bucket)\n-        check_cache_misses(instance, files, storage_name, started_cluster, bucket, 4)\n+        check_cache_misses(\n+            instance,\n+            files,\n+            storage_name,\n+            started_cluster,\n+            bucket,\n+            4 if storage_name == \"url\" else 1,\n+        )\n \n         instance.query(\"system drop schema cache\")\n         check_cache(instance, [])\n \n         run_describe_query(instance, files, storage_name, started_cluster, bucket)\n-        check_cache_misses(instance, files, storage_name, started_cluster, bucket, 4)\n+        check_cache_misses(\n+            instance,\n+            files,\n+            storage_name,\n+            started_cluster,\n+            bucket,\n+            4 if storage_name == \"url\" else 1,\n+        )\n \n         instance.query(\"system drop schema cache\")\n \n",
  "problem_statement": "Queries to S3 having glob patterns takes a long time to complete\n**Describe the situation**\r\nThere is a huge difference wrt query response time when querying S3 with or without glob patterns in the S3 URL \r\n\r\n**How to reproduce**\r\nBelow is an example query without glob pattern\r\n> SELECT Column1, Column2, _path\r\nFROM s3('https://test-s3-bucket.s3.us-west-2.amazonaws.com/Partition1/202308210735/*.parquet',  <aws_access_key_id>, <aws_secret_access_key>) LIMIT 2\r\n\r\nBelow is an example query with glob pattern\r\n> SELECT Column1, Column2, _path\r\nFROM s3('https://test-s3-bucket.s3.us-west-2.amazonaws.com/Partition1/{202308210735,DUMMY}/*.parquet',  <aws_access_key_id>, <aws_secret_access_key>) LIMIT 2\r\n\r\nEffectively both the queries should be reading or parsing the same number of files (\"DUMMY\" used the glob pattern is non-existent). \r\nThe resulting response time is approximately **1.5s** for query without glob pattern.\r\nBut the same query with blob pattern is taking around **140s**\r\n\r\n* Which ClickHouse server version to use\r\n**_ClickHouse client version 23.7.3.14 (official build)._**\r\n\r\n**Expected performance**\r\nThe response time in both cases should be more or less the same.\r\n\r\n**Additional context**\r\nData stored in S3 is of parquet format. There are multiple files within `202308210735`. As is obvious from the pattern, the data is time partitioned and there will be multiple folders like `202308210740`, `202308210745` etc..\r\nAdditionally, there are multiple top-level folders as well (eg) `Partition1`, `Partition2` etc..\r\n\r\nI did run query analysis of both the queries and from that its quite clear that the glob pattern based query is leading a substantially higher S3ListObject & S3Reads. Below is a snapshot of the comparision\r\n\r\n<img width=\"561\" alt=\"image\" src=\"https://github.com/ClickHouse/ClickHouse/assets/14892092/e6e27262-274e-4e16-aab8-f46c2596de63\">\r\n\r\n\nS3 Wildcard Issue When Using OR (Not usable)\nThere is an issue with performance when using the S3 Wildcard below.\r\n\r\n**Clickhouse Versions Tested (We have about 20 total servers):** \r\n- clickhouse/clickhouse-server:23.4.2.11 \r\n- clickhouse/clickhouse-server:23.1.3.5\r\n- clickhouse/clickhouse-server:23.2.1.2537\r\n\r\n**_Wildcard Used from Documentation:_** {some_string,another_string,yet_another_one} \u2014 Substitutes any of strings 'some_string', 'another_string', 'yet_another_one'\r\n\r\n_**Without Wildcard:**_ \r\n- **Expected result:** Return all data under presto_data/config/bts_id=555251 folder (5 files, 4MB total)\r\n- **S3 Path:** us-east-1.amazonaws.com/presto_data/config/bts_id=555251/*\r\n- **Speed:** Finishes in about 1 second\r\n\r\n_**With Wildcard:**_\r\n- **Expected result:** Return all data under presto_data/config/bts_id=555251 folder (5 files, 4MB total) AND presto_data/config/bts_id=555256 folder (4 files, 3MB total)\r\n- **S3 Path:** us-east-1.amazonaws.com/presto_data/config/bts_id=_**{555251,555256}**_/*\r\n- **Speed:** Never Finishes; Memory Limit Error after about 150 seconds\r\n\r\nThanks!\n",
  "hints_text": "Probably a duplicate of https://github.com/ClickHouse/ClickHouse/issues/49929 \n@tavplubix Yep, looks like its the same issue. I was just about to post that I was suspecting this is to be a result of highly partitioned bucket. The number of objects in the S3 bucket may be leading to the high number of list operations.\nalso suffered this in a query like\r\n\r\n```sql\r\nSELECT toStartOfHour(eventdate) as ts, max(value) as value\r\n             FROM s3('https://s3.xx.amazonaws.com/xxxx/xxx/xxxxx/xxxxx/day={2023-12-12,2023-12-13,2023-12-14}/*.parquet','key', 'secret')\r\n             GROUP BY ts\r\n             order by ts\r\n             SETTINGS max_threads=24\r\n```\r\n\r\nwithout string globbing, it works great.\r\n\r\n\nOne note. The folder for \"presto_data/config/\" has about 20k-500k folders in it (depending on our customer). It might be trying to list all the folders before applying the {} wildcard. I guess I had expected it to be linear with the choices so it would only check for those 2 paths without a directory list. Hope that helps explain a little more. \n@warleysa  : It lists folder/files with prefix \"presto_data/config/bts_id=\". Do you have 20k-500k folders with the same prefix? If yes, then it does list them all and try to match the glob.\nThe problem is that it lists all `bts_id`s (all keys with `presto_data/config/bts_id=` prefix) and only then tries to apply the regexp and find matching keys:\r\nhttps://github.com/ClickHouse/ClickHouse/blob/7fbf87be176081411918ae35f040f338892d1416/src/Storages/StorageS3.cpp#L165-L182\r\n\r\nHowever, it could only list `presto_data/config/bts_id=555251` and `presto_data/config/bts_id=555256` and it would be much more optimal \n> @warleysa : It lists folder/files with prefix \"presto_data/config/bts_id=\". Do you have 20k-500k folders with the same prefix? If yes, then it does list them all and try to match the glob.\r\n\r\nYes. We have that many folders with the same prefix there. It is partitioning in Parquet. Some of the larger folders have large sets of data. \r\n\r\nThe suggestion from [tavplubix](https://github.com/tavplubix) seems to be the optimal approach that could be taken. \r\n\r\nThanks all!\nAny update on this?\n> Any update on this?\r\nI am wondering about an update on this as well. We have been forced to use PrestoDB for Parquet data with such partitioning and then post process data in Python. This is leading to about 100x as much data being processed overall since we cannot use Clickhouse this to pre filter the data. \n@MaheshGPai @warleysa \r\nUnfortunately no updates, I plan to implement this shortly.\n@SmitaRKulkarni any update on this?\n@MaheshGPai, currently no update, and the task is not in progress.",
  "created_at": "2024-03-31T20:17:31Z"
}