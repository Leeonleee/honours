{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 28150,
  "instance_id": "ClickHouse__ClickHouse-28150",
  "issue_numbers": [
    "26149"
  ],
  "base_commit": "eaa49f56ddc37c3c7c794c7b4d6072b2200ff886",
  "patch": "diff --git a/src/IO/ZlibInflatingReadBuffer.cpp b/src/IO/ZlibInflatingReadBuffer.cpp\nindex bea83c74e219..472399dea3d7 100644\n--- a/src/IO/ZlibInflatingReadBuffer.cpp\n+++ b/src/IO/ZlibInflatingReadBuffer.cpp\n@@ -38,7 +38,7 @@ ZlibInflatingReadBuffer::ZlibInflatingReadBuffer(\n #pragma GCC diagnostic pop\n \n     if (rc != Z_OK)\n-        throw Exception(std::string(\"inflateInit2 failed: \") + zError(rc) + \"; zlib version: \" + ZLIB_VERSION, ErrorCodes::ZLIB_INFLATE_FAILED);\n+        throw Exception(ErrorCodes::ZLIB_INFLATE_FAILED, \"inflateInit2 failed: {}; zlib version: {}.\", zError(rc), ZLIB_VERSION);\n }\n \n ZlibInflatingReadBuffer::~ZlibInflatingReadBuffer()\n@@ -48,41 +48,60 @@ ZlibInflatingReadBuffer::~ZlibInflatingReadBuffer()\n \n bool ZlibInflatingReadBuffer::nextImpl()\n {\n-    if (eof)\n-        return false;\n-\n-    if (!zstr.avail_in)\n+    /// Need do-while loop to prevent situation, when\n+    /// eof was not reached, but working buffer became empty (when nothing was decompressed in current iteration)\n+    /// (this happens with compression algorithms, same idea is implemented in ZstdInflatingReadBuffer)\n+    do\n     {\n-        in->nextIfAtEnd();\n-        zstr.next_in = reinterpret_cast<unsigned char *>(in->position());\n-        zstr.avail_in = in->buffer().end() - in->position();\n-    }\n-    zstr.next_out = reinterpret_cast<unsigned char *>(internal_buffer.begin());\n-    zstr.avail_out = internal_buffer.size();\n-\n-    int rc = inflate(&zstr, Z_NO_FLUSH);\n+        /// if we already found eof, we shouldn't do anything\n+        if (eof)\n+            return false;\n \n-    in->position() = in->buffer().end() - zstr.avail_in;\n-    working_buffer.resize(internal_buffer.size() - zstr.avail_out);\n-\n-    if (rc == Z_STREAM_END)\n-    {\n-        if (in->eof())\n+        /// if there is no available bytes in zstr, move ptr to next available data\n+        if (!zstr.avail_in)\n         {\n-            eof = true;\n-            return !working_buffer.empty();\n+            in->nextIfAtEnd();\n+            zstr.next_in = reinterpret_cast<unsigned char *>(in->position());\n+            zstr.avail_in = in->buffer().end() - in->position();\n         }\n-        else\n+        /// init output bytes (place, where decompressed data will be)\n+        zstr.next_out = reinterpret_cast<unsigned char *>(internal_buffer.begin());\n+        zstr.avail_out = internal_buffer.size();\n+\n+        int rc = inflate(&zstr, Z_NO_FLUSH);\n+\n+        /// move in stream on place, where reading stopped\n+        in->position() = in->buffer().end() - zstr.avail_in;\n+        /// change size of working buffer (it's size equal to internal_buffer size without unused uncompressed values)\n+        working_buffer.resize(internal_buffer.size() - zstr.avail_out);\n+\n+        /// If end was reached, it can be end of file or end of part (for example, chunk)\n+        if (rc == Z_STREAM_END)\n         {\n-            rc = inflateReset(&zstr);\n-            if (rc != Z_OK)\n-                throw Exception(std::string(\"inflateReset failed: \") + zError(rc), ErrorCodes::ZLIB_INFLATE_FAILED);\n-            return true;\n+            /// if it is end of file, remember this and return\n+            /// * true if we can work with working buffer (we still have something to read, so next must return true)\n+            /// * false if there is no data in working buffer\n+            if (in->eof())\n+            {\n+                eof = true;\n+                return !working_buffer.empty();\n+            }\n+            /// If it is not end of file, we need to reset zstr and return true, because we still have some data to read\n+            else\n+            {\n+                rc = inflateReset(&zstr);\n+                if (rc != Z_OK)\n+                    throw Exception(ErrorCodes::ZLIB_INFLATE_FAILED, \"inflateReset failed: {}\", zError(rc));\n+                return true;\n+            }\n         }\n+        /// If it is not end and not OK, something went wrong, throw exception\n+        if (rc != Z_OK)\n+            throw Exception(ErrorCodes::ZLIB_INFLATE_FAILED, \"inflateReset failed: {}\", zError(rc));\n     }\n-    if (rc != Z_OK)\n-        throw Exception(std::string(\"inflate failed: \") + zError(rc), ErrorCodes::ZLIB_INFLATE_FAILED);\n+    while (working_buffer.empty());\n \n+    /// if code reach this section, working buffer is not empty, so we have some data to process\n     return true;\n }\n \n",
  "test_patch": "diff --git a/docker/test/fasttest/run.sh b/docker/test/fasttest/run.sh\nindex c4493de477c8..00af261f6c89 100755\n--- a/docker/test/fasttest/run.sh\n+++ b/docker/test/fasttest/run.sh\n@@ -396,6 +396,9 @@ function run_tests\n \n         # needs s3\n         01944_insert_partition_by\n+\n+        # depends on Go\n+        02013_zlib_read_after_eof\n     )\n \n     time clickhouse-test --hung-check -j 8 --order=random --use-skip-list \\\ndiff --git a/docker/test/stateless/Dockerfile b/docker/test/stateless/Dockerfile\nindex f5fa86a6f339..39c8a2e53580 100644\n--- a/docker/test/stateless/Dockerfile\n+++ b/docker/test/stateless/Dockerfile\n@@ -24,6 +24,8 @@ RUN apt-get update -y \\\n             python3-pip \\\n             qemu-user-static \\\n             sudo \\\n+            # golang version 1.13 on Ubuntu 20 is enough for tests\n+            golang \\\n             telnet \\\n             tree \\\n             unixodbc \\\ndiff --git a/tests/queries/0_stateless/02013_zlib_read_after_eof.go b/tests/queries/0_stateless/02013_zlib_read_after_eof.go\nnew file mode 100644\nindex 000000000000..a97a1438bdff\n--- /dev/null\n+++ b/tests/queries/0_stateless/02013_zlib_read_after_eof.go\n@@ -0,0 +1,61 @@\n+package main\n+\n+import (\n+\t\"compress/gzip\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"io/ioutil\"\n+\t\"net/http\"\n+\t\"net/url\"\n+\t\"os\"\n+)\n+\n+func compress(data io.Reader) io.Reader {\n+\tpr, pw := io.Pipe()\n+\tgw := gzip.NewWriter(pw)\n+\n+\tgo func() {\n+\t\t_, _ = io.Copy(gw, data)\n+\t\tgw.Close()\n+\t\tpw.Close()\n+\t}()\n+\n+\treturn pr\n+}\n+\n+func main() {\n+\tdatabase := os.Getenv(\"CLICKHOUSE_DATABASE\")\n+\tp, err := url.Parse(\"http://localhost:8123/\")\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\tq := p.Query()\n+\n+\tq.Set(\"query\", \"INSERT INTO \"+database+\".graphite FORMAT RowBinary\")\n+\tp.RawQuery = q.Encode()\n+\tqueryUrl := p.String()\n+\n+\tvar req *http.Request\n+\n+\treq, err = http.NewRequest(\"POST\", queryUrl, compress(os.Stdin))\n+\treq.Header.Add(\"Content-Encoding\", \"gzip\")\n+\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\n+\tclient := &http.Client{\n+\t\tTransport: &http.Transport{DisableKeepAlives: true},\n+\t}\n+\tresp, err := client.Do(req)\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\tdefer resp.Body.Close()\n+\n+\tbody, _ := ioutil.ReadAll(resp.Body)\n+\n+\tif resp.StatusCode != 200 {\n+\t\tpanic(fmt.Errorf(\"clickhouse response status %d: %s\", resp.StatusCode, string(body)))\n+\t}\n+}\ndiff --git a/tests/queries/0_stateless/02013_zlib_read_after_eof.reference b/tests/queries/0_stateless/02013_zlib_read_after_eof.reference\nnew file mode 100644\nindex 000000000000..5caff40c4a0c\n--- /dev/null\n+++ b/tests/queries/0_stateless/02013_zlib_read_after_eof.reference\n@@ -0,0 +1,1 @@\n+10000\ndiff --git a/tests/queries/0_stateless/02013_zlib_read_after_eof.sh b/tests/queries/0_stateless/02013_zlib_read_after_eof.sh\nnew file mode 100755\nindex 000000000000..d74dca6cc61c\n--- /dev/null\n+++ b/tests/queries/0_stateless/02013_zlib_read_after_eof.sh\n@@ -0,0 +1,18 @@\n+#!/usr/bin/env bash\n+\n+CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CUR_DIR\"/../shell_config.sh\n+\n+DATA_FILE=$CUR_DIR/data_zlib/02013_zlib_read_after_eof_data\n+\n+$CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS graphite;\"\n+\n+$CLICKHOUSE_CLIENT -q \"CREATE TABLE graphite(\\`Path\\` String, \\`Value\\` Float64, \\`Time\\` UInt32, \\`Date\\` Date, \\`Timestamp\\` UInt32) \\\n+    ENGINE = MergeTree PARTITION BY toYYYYMM(Date) ORDER BY (Path, Time) SETTINGS index_granularity = 8192;\"\n+\n+cat \"$DATA_FILE\" | go run $CUR_DIR/02013_zlib_read_after_eof.go\n+\n+$CLICKHOUSE_CLIENT -q \"SELECT count() FROM graphite;\"\n+\n+$CLICKHOUSE_CLIENT -q \"drop table graphite;\"\ndiff --git a/tests/queries/0_stateless/data_zlib/02013_zlib_read_after_eof_data b/tests/queries/0_stateless/data_zlib/02013_zlib_read_after_eof_data\nnew file mode 100644\nindex 000000000000..3e57c0824627\nBinary files /dev/null and b/tests/queries/0_stateless/data_zlib/02013_zlib_read_after_eof_data differ\n",
  "problem_statement": "Attempt to read after eof with enabled data compression on carbon-clickhouse\n**Describe the bug**\r\n\r\nCH throws an `Attempt to read after eof` exception when `carbon-clickhouse` with enabled gzip compression (`compress-data true` in `carbon-clickhouse` config) tries to insert 5000+ metrics.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nReproduces on 21.6.6.51 (stable) and v21.3.14.1 (LTS).\r\n\r\n**How to reproduce**\r\n\r\n***Prerequisites***\r\n1. `carbon-clickhouse` - `clickhouse` [default scheme](https://github.com/lomik/carbon-clickhouse) inside docker\r\n2. `compress-data` enabled in `carbon-clickhouse` config\r\n\r\n***How it works***\r\n\r\nWhen sending metrics manually by curl, it goes ok.\r\n\r\n[metrics_rowbinary.txt](https://github.com/ClickHouse/ClickHouse/files/6793464/metrics_rowbinary.txt)\r\n\r\n```\r\ncat /tmp/metrics_rowbinary.txt | gzip -c | curl 'http://localhost:8123/?query=INSERT%20INTO%20graphite%20(Path,%20Value,%20Time,%20Date,%20Timestamp)%20FORMAT%20RowBinary' --data-binary @- -H 'Content-Encoding: gzip'\r\n```\r\n\r\n***How it doesn't work***\r\n\r\nWhen sending metrics to `carbon-clickhouse` plaintext port, CH throws an exception.\r\n\r\n[metrics.txt](https://github.com/ClickHouse/ClickHouse/files/6793465/metrics.txt)\r\n\r\n```\r\ncat /tmp/metrics.txt | nc -q0 localhost 2003\r\n```\r\n\r\nWhen `compress-data` is disabled in `carbon-clickhouse`, it goes with no exception too.\r\n\r\n**Error message and/or stacktrace**\r\n\r\n<details>\r\n <summary>Stacktrace</summary>\r\n<pre>\r\nclickhouse_1           | 2021.07.09 18:56:18.756162 [ 100 ] {9d25478d-a23f-44aa-90a6-13bf6984413e} <Error> DynamicQueryHandler: Code: 32, e.displayText() = DB::Exception: Attempt to read after eof, Stack trace (when copying this message, always include the lines below):\r\nclickhouse_1           | \r\nclickhouse_1           | 0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8b770fa in /usr/bin/clickhouse\r\nclickhouse_1           | 1. DB::throwReadAfterEOF() @ 0x8b88a1f in /usr/bin/clickhouse\r\nclickhouse_1           | 2. ? @ 0x8bb26ab in /usr/bin/clickhouse\r\nclickhouse_1           | 3. DB::SerializationString::deserializeBinary(DB::IColumn&, DB::ReadBuffer&) const @ 0xf43c5df in /usr/bin/clickhouse\r\nclickhouse_1           | 4. DB::BinaryRowInputFormat::readRow(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::RowReadExtension&) @ 0x105273cd in /usr/bin/clickhouse\r\nclickhouse_1           | 5. DB::IRowInputFormat::generate() @ 0x1051ccc8 in /usr/bin/clickhouse\r\nclickhouse_1           | 6. DB::ISource::tryGenerate() @ 0x104a97d5 in /usr/bin/clickhouse\r\nclickhouse_1           | 7. DB::ISource::work() @ 0x104a93ba in /usr/bin/clickhouse\r\nclickhouse_1           | 8. DB::InputStreamFromInputFormat::readImpl() @ 0xdb0883f in /usr/bin/clickhouse\r\nclickhouse_1           | 9. DB::IBlockInputStream::read() @ 0xf348eb2 in /usr/bin/clickhouse\r\nclickhouse_1           | 10. DB::InputStreamFromASTInsertQuery::readImpl() @ 0xf8ff690 in /usr/bin/clickhouse\r\nclickhouse_1           | 11. DB::IBlockInputStream::read() @ 0xf348eb2 in /usr/bin/clickhouse\r\nclickhouse_1           | 12. DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::__1::atomic<bool>*) @ 0xf36c66f in /usr/bin/clickhouse\r\nclickhouse_1           | 13. DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, std::__1::shared_ptr<DB::Context>, std::__1::function<void (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>) @ 0xfc48461 in /usr/bin/clickhouse\r\nclickhouse_1           | 14. DB::HTTPHandler::processQuery(std::__1::shared_ptr<DB::Context>, DB::HTTPServerRequest&, DB::HTMLForm&, DB::HTTPServerResponse&, DB::HTTPHandler::Output&, std::__1::optional<DB::CurrentThread::QueryScope>&) @ 0x103fd93f in /usr/bin/clickhouse\r\nclickhouse_1           | 15. DB::HTTPHandler::handleRequest(DB::HTTPServerRequest&, DB::HTTPServerResponse&) @ 0x104010c9 in /usr/bin/clickhouse\r\nclickhouse_1           | 16. DB::HTTPServerConnection::run() @ 0x10484f50 in /usr/bin/clickhouse\r\nclickhouse_1           | 17. Poco::Net::TCPServerConnection::start() @ 0x12a7a50f in /usr/bin/clickhouse\r\nclickhouse_1           | 18. Poco::Net::TCPServerDispatcher::run() @ 0x12a7bf9a in /usr/bin/clickhouse\r\nclickhouse_1           | 19. Poco::PooledThread::run() @ 0x12bb52f9 in /usr/bin/clickhouse\r\nclickhouse_1           | 20. Poco::ThreadImpl::runnableEntry(void*) @ 0x12bb12ea in /usr/bin/clickhouse\r\nclickhouse_1           | 21. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\nclickhouse_1           | 22. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n</pre>\r\n</details>\r\n\r\n[PCAP](https://github.com/ClickHouse/ClickHouse/files/6793478/clickhouse.zip)\r\n\n",
  "hints_text": "Is it related to ClickHouse or to carbon-clickhouse (a third-party software)?\n@alexey-milovidov \r\n\r\nIt works with CH 20.6.8.5 and `carbon-clickhouse` 0.11.1, and broken in CH 21.3.14.1+, so I think it's CH-related.\n[log_500.crash.txt](https://github.com/ClickHouse/ClickHouse/files/6794163/log_500.crash.txt)\r\n[log_segfault.crash.txt](https://github.com/ClickHouse/ClickHouse/files/6794164/log_segfault.crash.txt)\r\n\ncc @Felixoid \n@den-crane @vhsmacabre How to reproduce this issue without installing `carbon-clickhouse`?\r\nOr write step-by-step instruction how to install carbon-clickhouse and reproduce this issue.\n@alexey-milovidov \r\n[carbon-test.tar.gz](https://github.com/ClickHouse/ClickHouse/files/6835530/carbon-test.tar.gz)\r\n\r\n```\r\n20.8.18.32\r\n\r\ncat graphite.sql | clickhouse-client -mn\r\ncat metrics |./test-carbon\r\n\r\nselect count() from graphite\r\n\u250c\u2500count()\u2500\u2510\r\n\u2502   10000 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n\r\n21.8.1.7409\r\n\r\ncat graphite.sql | clickhouse-client -mn\r\ncat metrics| ./test-carbon\r\npanic: clickhouse response status 500: Code: 32, e.displayText() = DB::Exception: Attempt to read after eof (version 21.8.1.7409 (official build))\r\n```\r\n\r\n",
  "created_at": "2021-08-25T17:00:40Z"
}