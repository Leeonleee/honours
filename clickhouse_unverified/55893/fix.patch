diff --git a/docs/en/operations/settings/settings.md b/docs/en/operations/settings/settings.md
index ccbf54843e4b..5c9472600b80 100644
--- a/docs/en/operations/settings/settings.md
+++ b/docs/en/operations/settings/settings.md
@@ -4708,18 +4708,6 @@ SELECT toFloat64('1.7091'), toFloat64('1.5008753E7') SETTINGS precise_float_pars
 └─────────────────────┴──────────────────────────┘
 ```
 
-## partial_result_update_duration_ms
-
-Interval (in milliseconds) for sending updates with partial data about the result table to the client (in interactive mode) during query execution. Setting to 0 disables partial results. Only supported for single-threaded GROUP BY without key, ORDER BY, LIMIT and OFFSET.
-
-:::note
-It's an experimental feature. Enable `allow_experimental_partial_result` setting first to use it.
-:::
-
-## max_rows_in_partial_result
-
-Maximum rows to show in the partial result after every real-time update while the query runs (use partial result limit + OFFSET as a value in case of OFFSET in the query).
-
 ## validate_tcp_client_information {#validate-tcp-client-information}
 
 Determines whether validation of client information enabled when query packet is received from a client using a TCP connection.
diff --git a/src/Client/ClientBase.cpp b/src/Client/ClientBase.cpp
index a350654cdda2..16229c5e44c6 100644
--- a/src/Client/ClientBase.cpp
+++ b/src/Client/ClientBase.cpp
@@ -449,20 +449,7 @@ void ClientBase::onData(Block & block, ASTPtr parsed_query)
     if (!block)
         return;
 
-    if (block.rows() == 0 && partial_result_mode == PartialResultMode::Active)
-    {
-        partial_result_mode = PartialResultMode::Inactive;
-        if (is_interactive)
-        {
-            progress_indication.clearProgressOutput(*tty_buf);
-            std::cout << "Full result:" << std::endl;
-            progress_indication.writeProgress(*tty_buf);
-        }
-    }
-
-    if (partial_result_mode == PartialResultMode::Inactive)
-        processed_rows += block.rows();
-
+    processed_rows += block.rows();
     /// Even if all blocks are empty, we still need to initialize the output stream to write empty resultset.
     initOutputFormat(block, parsed_query);
 
@@ -472,20 +459,13 @@ void ClientBase::onData(Block & block, ASTPtr parsed_query)
     if (block.rows() == 0 || (query_fuzzer_runs != 0 && processed_rows >= 100))
         return;
 
-    if (!is_interactive && partial_result_mode == PartialResultMode::Active)
-        return;
-
     /// If results are written INTO OUTFILE, we can avoid clearing progress to avoid flicker.
     if (need_render_progress && tty_buf && (!select_into_file || select_into_file_and_stdout))
         progress_indication.clearProgressOutput(*tty_buf);
 
     try
     {
-        if (partial_result_mode == PartialResultMode::Active)
-            output_format->writePartialResult(materializeBlock(block));
-        else
-            output_format->write(materializeBlock(block));
-
+        output_format->write(materializeBlock(block));
         written_first_block = true;
     }
     catch (const Exception &)
@@ -549,9 +529,6 @@ void ClientBase::onProfileInfo(const ProfileInfo & profile_info)
 void ClientBase::initOutputFormat(const Block & block, ASTPtr parsed_query)
 try
 {
-    if (partial_result_mode == PartialResultMode::NotInit)
-        partial_result_mode = PartialResultMode::Active;
-
     if (!output_format)
     {
         /// Ignore all results when fuzzing as they can be huge.
@@ -994,14 +971,6 @@ void ClientBase::processOrdinaryQuery(const String & query_to_execute, ASTPtr pa
 
     const auto & settings = global_context->getSettingsRef();
     const Int32 signals_before_stop = settings.partial_result_on_first_cancel ? 2 : 1;
-    bool has_partial_result_setting = settings.partial_result_update_duration_ms.totalMilliseconds() > 0;
-
-    if (has_partial_result_setting)
-    {
-        partial_result_mode = PartialResultMode::NotInit;
-        if (is_interactive)
-            std::cout << "Partial result:" << std::endl;
-    }
 
     int retries_left = 10;
     while (retries_left)
@@ -1828,7 +1797,6 @@ void ClientBase::processParsedSingleQuery(const String & full_query, const Strin
     }
 
     processed_rows = 0;
-    partial_result_mode = PartialResultMode::Inactive;
     written_first_block = false;
     progress_indication.resetProgress();
     profile_events.watch.restart();
diff --git a/src/Client/ClientBase.h b/src/Client/ClientBase.h
index 604c8cf4d5c2..2156aae71817 100644
--- a/src/Client/ClientBase.h
+++ b/src/Client/ClientBase.h
@@ -275,21 +275,6 @@ class ClientBase : public Poco::Util::Application, public IHints<2>
     size_t processed_rows = 0; /// How many rows have been read or written.
     bool print_num_processed_rows = false; /// Whether to print the number of processed rows at
 
-    enum class PartialResultMode: UInt8
-    {
-        /// Query doesn't show partial result before the first block with 0 rows.
-        /// The first block with 0 rows initializes the output table format using its header.
-        NotInit,
-
-        /// Query shows partial result after the first and before the second block with 0 rows.
-        /// The second block with 0 rows indicates that that receiving blocks with partial result has been completed and next blocks will be with the full result.
-        Active,
-
-        /// Query doesn't show partial result at all.
-        Inactive,
-    };
-    PartialResultMode partial_result_mode = PartialResultMode::Inactive;
-
     bool print_stack_trace = false;
     /// The last exception that was received from the server. Is used for the
     /// return code in batch mode.
diff --git a/src/Core/Settings.h b/src/Core/Settings.h
index b58705614d8e..f1b031eaf938 100644
--- a/src/Core/Settings.h
+++ b/src/Core/Settings.h
@@ -314,10 +314,6 @@ class IColumn;
     \
     M(Bool, partial_result_on_first_cancel, false, "Allows query to return a partial result after cancel.", 0) \
     \
-    M(Bool, allow_experimental_partial_result, 0, "Enable experimental feature: partial results for running queries.", 0) \
-    M(Milliseconds, partial_result_update_duration_ms, 0, "Interval (in milliseconds) for sending updates with partial data about the result table to the client (in interactive mode) during query execution. Setting to 0 disables partial results. Only supported for single-threaded GROUP BY without key, ORDER BY, LIMIT and OFFSET.", 0) \
-    M(UInt64, max_rows_in_partial_result, 10, "Maximum rows to show in the partial result after every real-time update while the query runs (use partial result limit + OFFSET as a value in case of OFFSET in the query).", 0) \
-    \
     M(Bool, ignore_on_cluster_for_replicated_udf_queries, false, "Ignore ON CLUSTER clause for replicated UDF management queries.", 0) \
     M(Bool, ignore_on_cluster_for_replicated_access_entities_queries, false, "Ignore ON CLUSTER clause for replicated access entities management queries.", 0) \
     /** Settings for testing hedged requests */ \
diff --git a/src/Interpreters/Aggregator.cpp b/src/Interpreters/Aggregator.cpp
index e16064db713b..ac0ebc44bec1 100644
--- a/src/Interpreters/Aggregator.cpp
+++ b/src/Interpreters/Aggregator.cpp
@@ -2334,29 +2334,6 @@ Block Aggregator::prepareBlockAndFillWithoutKey(AggregatedDataVariants & data_va
     return block;
 }
 
-Block Aggregator::prepareBlockAndFillWithoutKeySnapshot(AggregatedDataVariants & data_variants) const
-{
-    size_t rows = 1;
-    bool final = true;
-
-    auto && out_cols
-        = prepareOutputBlockColumns(params, aggregate_functions, getHeader(final), data_variants.aggregates_pools, final, rows);
-    auto && [key_columns, raw_key_columns, aggregate_columns, final_aggregate_columns, aggregate_columns_data] = out_cols;
-
-    AggregatedDataWithoutKey & data = data_variants.without_key;
-
-    /// Always single-thread. It's safe to pass current arena from 'aggregates_pool'.
-    for (size_t insert_i = 0; insert_i < params.aggregates_size; ++insert_i)
-        aggregate_functions[insert_i]->insertResultInto(
-            data + offsets_of_aggregate_states[insert_i],
-            *final_aggregate_columns[insert_i],
-            data_variants.aggregates_pool);
-
-    Block block = finalizeBlock(params, getHeader(final), std::move(out_cols), final, rows);
-
-    return block;
-}
-
 template <bool return_single_block>
 Aggregator::ConvertToBlockRes<return_single_block>
 Aggregator::prepareBlockAndFillSingleLevel(AggregatedDataVariants & data_variants, bool final) const
diff --git a/src/Interpreters/Aggregator.h b/src/Interpreters/Aggregator.h
index 4acf73ce50fe..ab53f76d2cec 100644
--- a/src/Interpreters/Aggregator.h
+++ b/src/Interpreters/Aggregator.h
@@ -1217,7 +1217,6 @@ class Aggregator final
     friend class ConvertingAggregatedToChunksSource;
     friend class ConvertingAggregatedToChunksWithMergingSource;
     friend class AggregatingInOrderTransform;
-    friend class AggregatingPartialResultTransform;
 
     /// Data structure of source blocks.
     Block header;
@@ -1402,7 +1401,6 @@ class Aggregator final
         std::atomic<bool> * is_cancelled = nullptr) const;
 
     Block prepareBlockAndFillWithoutKey(AggregatedDataVariants & data_variants, bool final, bool is_overflows) const;
-    Block prepareBlockAndFillWithoutKeySnapshot(AggregatedDataVariants & data_variants) const;
     BlocksList prepareBlocksAndFillTwoLevel(AggregatedDataVariants & data_variants, bool final, ThreadPool * thread_pool) const;
 
     template <bool return_single_block>
diff --git a/src/Processors/Chunk.cpp b/src/Processors/Chunk.cpp
index cd442085eca1..3839a8963b24 100644
--- a/src/Processors/Chunk.cpp
+++ b/src/Processors/Chunk.cpp
@@ -14,8 +14,7 @@ namespace ErrorCodes
     extern const int POSITION_OUT_OF_BOUND;
 }
 
-Chunk::Chunk(DB::Columns columns_, UInt64 num_rows_)
-    : columns(std::move(columns_)), num_rows(num_rows_)
+Chunk::Chunk(DB::Columns columns_, UInt64 num_rows_) : columns(std::move(columns_)), num_rows(num_rows_)
 {
     checkNumRowsIsConsistent();
 }
diff --git a/src/Processors/Executors/CompletedPipelineExecutor.cpp b/src/Processors/Executors/CompletedPipelineExecutor.cpp
index c30586e194e6..598a51bf0c75 100644
--- a/src/Processors/Executors/CompletedPipelineExecutor.cpp
+++ b/src/Processors/Executors/CompletedPipelineExecutor.cpp
@@ -75,7 +75,7 @@ void CompletedPipelineExecutor::execute()
     if (interactive_timeout_ms)
     {
         data = std::make_unique<Data>();
-        data->executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element, pipeline.partial_result_duration_ms);
+        data->executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element);
         data->executor->setReadProgressCallback(pipeline.getReadProgressCallback());
 
         /// Avoid passing this to lambda, copy ptr to data instead.
@@ -105,7 +105,7 @@ void CompletedPipelineExecutor::execute()
     }
     else
     {
-        PipelineExecutor executor(pipeline.processors, pipeline.process_list_element, pipeline.partial_result_duration_ms);
+        PipelineExecutor executor(pipeline.processors, pipeline.process_list_element);
         executor.setReadProgressCallback(pipeline.getReadProgressCallback());
         executor.execute(pipeline.getNumThreads(), pipeline.getConcurrencyControl());
     }
diff --git a/src/Processors/Executors/ExecutingGraph.cpp b/src/Processors/Executors/ExecutingGraph.cpp
index 6a946b4a4b9b..27f6a454b244 100644
--- a/src/Processors/Executors/ExecutingGraph.cpp
+++ b/src/Processors/Executors/ExecutingGraph.cpp
@@ -260,6 +260,7 @@ bool ExecutingGraph::updateNode(uint64_t pid, Queue & queue, Queue & async_queue
         {
             pid = updated_processors.top();
             updated_processors.pop();
+
             /// In this method we have ownership on node.
             auto & node = *nodes[pid];
 
diff --git a/src/Processors/Executors/ExecutionThreadContext.h b/src/Processors/Executors/ExecutionThreadContext.h
index 85788a707714..eb048f8ab091 100644
--- a/src/Processors/Executors/ExecutionThreadContext.h
+++ b/src/Processors/Executors/ExecutionThreadContext.h
@@ -30,12 +30,6 @@ class ExecutionThreadContext
     /// Callback for read progress.
     ReadProgressCallback * read_progress_callback = nullptr;
 
-    /// Timer that stops optimization of running local tasks instead of queuing them.
-    /// It provides local progress for each IProcessor task, allowing the partial result of the request to be always sended to the user.
-    Stopwatch watch;
-    /// Time period that limits the maximum allowed duration for optimizing the scheduling of local tasks within the executor
-    const UInt64 partial_result_duration_ms;
-
 public:
 #ifndef NDEBUG
     /// Time for different processing stages.
@@ -68,13 +62,8 @@ class ExecutionThreadContext
     void setException(std::exception_ptr exception_) { exception = exception_; }
     void rethrowExceptionIfHas();
 
-    bool needWatchRestartForPartialResultProgress() { return partial_result_duration_ms != 0 && partial_result_duration_ms < watch.elapsedMilliseconds(); }
-    void restartWatch() { watch.restart(); }
-
-    explicit ExecutionThreadContext(size_t thread_number_, bool profile_processors_, bool trace_processors_, ReadProgressCallback * callback, UInt64 partial_result_duration_ms_)
+    explicit ExecutionThreadContext(size_t thread_number_, bool profile_processors_, bool trace_processors_, ReadProgressCallback * callback)
         : read_progress_callback(callback)
-        , watch(CLOCK_MONOTONIC)
-        , partial_result_duration_ms(partial_result_duration_ms_)
         , thread_number(thread_number_)
         , profile_processors(profile_processors_)
         , trace_processors(trace_processors_)
diff --git a/src/Processors/Executors/ExecutorTasks.cpp b/src/Processors/Executors/ExecutorTasks.cpp
index 089205923911..e61d225a968c 100644
--- a/src/Processors/Executors/ExecutorTasks.cpp
+++ b/src/Processors/Executors/ExecutorTasks.cpp
@@ -108,15 +108,8 @@ void ExecutorTasks::pushTasks(Queue & queue, Queue & async_queue, ExecutionThrea
 {
     context.setTask(nullptr);
 
-    /// If sending partial results is allowed and local tasks scheduling optimization is repeated longer than the limit
-    /// or new task need to send partial result later, skip optimization for this iteration.
-    /// Otherwise take local task from queue if has one.
-    if ((!queue.empty() && queue.front()->processor->isPartialResultProcessor())
-        || context.needWatchRestartForPartialResultProgress())
-    {
-        context.restartWatch();
-    }
-    else if (!queue.empty() && !context.hasAsyncTasks())
+    /// Take local task from queue if has one.
+    if (!queue.empty() && !context.hasAsyncTasks())
     {
         context.setTask(queue.front());
         queue.pop();
@@ -146,7 +139,7 @@ void ExecutorTasks::pushTasks(Queue & queue, Queue & async_queue, ExecutionThrea
     }
 }
 
-void ExecutorTasks::init(size_t num_threads_, size_t use_threads_, bool profile_processors, bool trace_processors, ReadProgressCallback * callback, UInt64 partial_result_duration_ms)
+void ExecutorTasks::init(size_t num_threads_, size_t use_threads_, bool profile_processors, bool trace_processors, ReadProgressCallback * callback)
 {
     num_threads = num_threads_;
     use_threads = use_threads_;
@@ -158,7 +151,7 @@ void ExecutorTasks::init(size_t num_threads_, size_t use_threads_, bool profile_
 
         executor_contexts.reserve(num_threads);
         for (size_t i = 0; i < num_threads; ++i)
-            executor_contexts.emplace_back(std::make_unique<ExecutionThreadContext>(i, profile_processors, trace_processors, callback, partial_result_duration_ms));
+            executor_contexts.emplace_back(std::make_unique<ExecutionThreadContext>(i, profile_processors, trace_processors, callback));
     }
 }
 
diff --git a/src/Processors/Executors/ExecutorTasks.h b/src/Processors/Executors/ExecutorTasks.h
index ab6d5e914119..d35f8de94d15 100644
--- a/src/Processors/Executors/ExecutorTasks.h
+++ b/src/Processors/Executors/ExecutorTasks.h
@@ -58,7 +58,7 @@ class ExecutorTasks
     void tryGetTask(ExecutionThreadContext & context);
     void pushTasks(Queue & queue, Queue & async_queue, ExecutionThreadContext & context);
 
-    void init(size_t num_threads_, size_t use_threads_, bool profile_processors, bool trace_processors, ReadProgressCallback * callback, UInt64 partial_result_duration_ms);
+    void init(size_t num_threads_, size_t use_threads_, bool profile_processors, bool trace_processors, ReadProgressCallback * callback);
     void fill(Queue & queue);
     void upscale(size_t use_threads_);
 
diff --git a/src/Processors/Executors/PipelineExecutor.cpp b/src/Processors/Executors/PipelineExecutor.cpp
index 77779e2cec22..37af391fba31 100644
--- a/src/Processors/Executors/PipelineExecutor.cpp
+++ b/src/Processors/Executors/PipelineExecutor.cpp
@@ -33,9 +33,8 @@ namespace ErrorCodes
 }
 
 
-PipelineExecutor::PipelineExecutor(std::shared_ptr<Processors> & processors, QueryStatusPtr elem, UInt64 partial_result_duration_ms_)
+PipelineExecutor::PipelineExecutor(std::shared_ptr<Processors> & processors, QueryStatusPtr elem)
     : process_list_element(std::move(elem))
-    , partial_result_duration_ms(partial_result_duration_ms_)
 {
     if (process_list_element)
     {
@@ -329,7 +328,7 @@ void PipelineExecutor::initializeExecution(size_t num_threads, bool concurrency_
     Queue queue;
     graph->initializeExecution(queue);
 
-    tasks.init(num_threads, use_threads, profile_processors, trace_processors, read_progress_callback.get(), partial_result_duration_ms);
+    tasks.init(num_threads, use_threads, profile_processors, trace_processors, read_progress_callback.get());
     tasks.fill(queue);
 
     if (num_threads > 1)
diff --git a/src/Processors/Executors/PipelineExecutor.h b/src/Processors/Executors/PipelineExecutor.h
index 6cb0e6c4ac1e..dee12dad2829 100644
--- a/src/Processors/Executors/PipelineExecutor.h
+++ b/src/Processors/Executors/PipelineExecutor.h
@@ -33,7 +33,7 @@ class PipelineExecutor
     /// During pipeline execution new processors can appear. They will be added to existing set.
     ///
     /// Explicit graph representation is built in constructor. Throws if graph is not correct.
-    explicit PipelineExecutor(std::shared_ptr<Processors> & processors, QueryStatusPtr elem, UInt64 partial_result_duration_ms_ = 0);
+    explicit PipelineExecutor(std::shared_ptr<Processors> & processors, QueryStatusPtr elem);
     ~PipelineExecutor();
 
     /// Execute pipeline in multiple threads. Must be called once.
@@ -90,9 +90,6 @@ class PipelineExecutor
 
     ReadProgressCallbackPtr read_progress_callback;
 
-    /// Duration between sending partial result through the pipeline
-    const UInt64 partial_result_duration_ms;
-
     using Queue = std::queue<ExecutingGraph::Node *>;
 
     void initializeExecution(size_t num_threads, bool concurrency_control); /// Initialize executor contexts and task_queue.
diff --git a/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp b/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp
index 95a2022bf936..345bec395b24 100644
--- a/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp
+++ b/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp
@@ -41,13 +41,12 @@ struct PullingAsyncPipelineExecutor::Data
     }
 };
 
-PullingAsyncPipelineExecutor::PullingAsyncPipelineExecutor(QueryPipeline & pipeline_, bool has_partial_result_setting) : pipeline(pipeline_)
+PullingAsyncPipelineExecutor::PullingAsyncPipelineExecutor(QueryPipeline & pipeline_) : pipeline(pipeline_)
 {
     if (!pipeline.pulling())
         throw Exception(ErrorCodes::LOGICAL_ERROR, "Pipeline for PullingAsyncPipelineExecutor must be pulling");
 
-    lazy_format = std::make_shared<LazyOutputFormat>(pipeline.output->getHeader(), /*is_partial_result_protocol_active*/ has_partial_result_setting);
-
+    lazy_format = std::make_shared<LazyOutputFormat>(pipeline.output->getHeader());
     pipeline.complete(lazy_format);
 }
 
@@ -104,7 +103,7 @@ bool PullingAsyncPipelineExecutor::pull(Chunk & chunk, uint64_t milliseconds)
     if (!data)
     {
         data = std::make_unique<Data>();
-        data->executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element, pipeline.partial_result_duration_ms);
+        data->executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element);
         data->executor->setReadProgressCallback(pipeline.getReadProgressCallback());
         data->lazy_format = lazy_format.get();
 
diff --git a/src/Processors/Executors/PullingAsyncPipelineExecutor.h b/src/Processors/Executors/PullingAsyncPipelineExecutor.h
index 202ecbf281b1..361bcc0155c6 100644
--- a/src/Processors/Executors/PullingAsyncPipelineExecutor.h
+++ b/src/Processors/Executors/PullingAsyncPipelineExecutor.h
@@ -21,7 +21,7 @@ struct ProfileInfo;
 class PullingAsyncPipelineExecutor
 {
 public:
-    explicit PullingAsyncPipelineExecutor(QueryPipeline & pipeline_, bool has_partial_result_setting = false);
+    explicit PullingAsyncPipelineExecutor(QueryPipeline & pipeline_);
     ~PullingAsyncPipelineExecutor();
 
     /// Get structure of returned block or chunk.
diff --git a/src/Processors/Executors/PullingPipelineExecutor.cpp b/src/Processors/Executors/PullingPipelineExecutor.cpp
index f79f15c19bfc..cbf73c5cb079 100644
--- a/src/Processors/Executors/PullingPipelineExecutor.cpp
+++ b/src/Processors/Executors/PullingPipelineExecutor.cpp
@@ -44,7 +44,7 @@ bool PullingPipelineExecutor::pull(Chunk & chunk)
 {
     if (!executor)
     {
-        executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element, pipeline.partial_result_duration_ms);
+        executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element);
         executor->setReadProgressCallback(pipeline.getReadProgressCallback());
     }
 
diff --git a/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp b/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp
index f3ed24e7e961..a816ab9ca7f7 100644
--- a/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp
+++ b/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp
@@ -167,7 +167,7 @@ void PushingAsyncPipelineExecutor::start()
     started = true;
 
     data = std::make_unique<Data>();
-    data->executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element, pipeline.partial_result_duration_ms);
+    data->executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element);
     data->executor->setReadProgressCallback(pipeline.getReadProgressCallback());
     data->source = pushing_source.get();
 
diff --git a/src/Processors/Executors/PushingPipelineExecutor.cpp b/src/Processors/Executors/PushingPipelineExecutor.cpp
index f2b018792c7f..696932932df5 100644
--- a/src/Processors/Executors/PushingPipelineExecutor.cpp
+++ b/src/Processors/Executors/PushingPipelineExecutor.cpp
@@ -87,7 +87,7 @@ void PushingPipelineExecutor::start()
         return;
 
     started = true;
-    executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element, pipeline.partial_result_duration_ms);
+    executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element);
     executor->setReadProgressCallback(pipeline.getReadProgressCallback());
 
     if (!executor->executeStep(&input_wait_flag))
diff --git a/src/Processors/Formats/IOutputFormat.cpp b/src/Processors/Formats/IOutputFormat.cpp
index e691e32a7bc8..88a6fb1e92fd 100644
--- a/src/Processors/Formats/IOutputFormat.cpp
+++ b/src/Processors/Formats/IOutputFormat.cpp
@@ -1,90 +1,41 @@
 #include <Processors/Formats/IOutputFormat.h>
 #include <IO/WriteBuffer.h>
-#include <IO/WriteHelpers.h>
 
 
 namespace DB
 {
 
-IOutputFormat::IOutputFormat(const Block & header_, WriteBuffer & out_, bool is_partial_result_protocol_active_)
-    : IProcessor({header_, header_, header_, header_}, {})
-    , out(out_)
-    , is_partial_result_protocol_active(is_partial_result_protocol_active_)
+IOutputFormat::IOutputFormat(const Block & header_, WriteBuffer & out_)
+    : IProcessor({header_, header_, header_}, {}), out(out_)
 {
 }
 
-void IOutputFormat::setCurrentChunk(InputPort & input, PortKind kind)
+IOutputFormat::Status IOutputFormat::prepare()
 {
-    current_chunk = input.pull(true);
-    current_block_kind = kind;
-    has_input = true;
-}
+    if (has_input)
+        return Status::Ready;
 
-IOutputFormat::Status IOutputFormat::prepareMainAndPartialResult()
-{
-    bool need_data = false;
-    for (auto kind : {Main, PartialResult})
+    for (auto kind : {Main, Totals, Extremes})
     {
         auto & input = getPort(kind);
 
-        if (input.isFinished())
+        if (kind != Main && !input.isConnected())
             continue;
 
-        if (kind == PartialResult && main_input_activated)
-        {
-            input.close();
+        if (input.isFinished())
             continue;
-        }
 
         input.setNeeded();
-        need_data = true;
-
-        if (!input.hasData())
-            continue;
-
-        setCurrentChunk(input, kind);
-        return Status::Ready;
-    }
-
-    if (need_data)
-        return Status::NeedData;
-
-    return Status::Finished;
-}
-
-IOutputFormat::Status IOutputFormat::prepareTotalsAndExtremes()
-{
-    for (auto kind : {Totals, Extremes})
-    {
-        auto & input = getPort(kind);
-
-        if (!input.isConnected() || input.isFinished())
-            continue;
 
-        input.setNeeded();
         if (!input.hasData())
             return Status::NeedData;
 
-        setCurrentChunk(input, kind);
+        current_chunk = input.pull(true);
+        current_block_kind = kind;
+        has_input = true;
         return Status::Ready;
     }
 
-    return Status::Finished;
-}
-
-IOutputFormat::Status IOutputFormat::prepare()
-{
-    if (has_input)
-        return Status::Ready;
-
-    auto status = prepareMainAndPartialResult();
-    if (status != Status::Finished)
-        return status;
-
-    status = prepareTotalsAndExtremes();
-    if (status != Status::Finished)
-        return status;
-
     finished = true;
 
     if (!finalized)
@@ -132,18 +83,8 @@ void IOutputFormat::work()
         case Main:
             result_rows += current_chunk.getNumRows();
             result_bytes += current_chunk.allocatedBytes();
-            if (is_partial_result_protocol_active && !main_input_activated && current_chunk.hasRows())
-            {
-                /// Sending an empty block signals to the client that partial results are terminated,
-                /// and only data from the main pipeline will be forwarded.
-                consume(Chunk(current_chunk.cloneEmptyColumns(), 0));
-                main_input_activated = true;
-            }
             consume(std::move(current_chunk));
             break;
-        case PartialResult:
-            consumePartialResult(std::move(current_chunk));
-            break;
         case Totals:
             writeSuffixIfNeeded();
             if (auto totals = prepareTotals(std::move(current_chunk)))
@@ -178,15 +119,6 @@ void IOutputFormat::write(const Block & block)
         flush();
 }
 
-void IOutputFormat::writePartialResult(const Block & block)
-{
-    writePrefixIfNeeded();
-    consumePartialResult(Chunk(block.getColumns(), block.rows()));
-
-    if (auto_flush)
-        flush();
-}
-
 void IOutputFormat::finalize()
 {
     if (finalized)
diff --git a/src/Processors/Formats/IOutputFormat.h b/src/Processors/Formats/IOutputFormat.h
index e642132fb646..cae2ab7691e6 100644
--- a/src/Processors/Formats/IOutputFormat.h
+++ b/src/Processors/Formats/IOutputFormat.h
@@ -23,9 +23,9 @@ class WriteBuffer;
 class IOutputFormat : public IProcessor
 {
 public:
-    enum PortKind { Main = 0, Totals = 1, Extremes = 2, PartialResult = 3 };
+    enum PortKind { Main = 0, Totals = 1, Extremes = 2 };
 
-    IOutputFormat(const Block & header_, WriteBuffer & out_, bool is_partial_result_protocol_active_ = false);
+    IOutputFormat(const Block & header_, WriteBuffer & out_);
 
     Status prepare() override;
     void work() override;
@@ -54,7 +54,6 @@ class IOutputFormat : public IProcessor
     /// TODO: separate formats and processors.
 
     void write(const Block & block);
-    void writePartialResult(const Block & block);
 
     void finalize();
 
@@ -122,7 +121,6 @@ class IOutputFormat : public IProcessor
     virtual void consume(Chunk) = 0;
     virtual void consumeTotals(Chunk) {}
     virtual void consumeExtremes(Chunk) {}
-    virtual void consumePartialResult(Chunk) {}
     virtual void finalizeImpl() {}
     virtual void finalizeBuffers() {}
     virtual void writePrefix() {}
@@ -176,7 +174,6 @@ class IOutputFormat : public IProcessor
 
     Chunk current_chunk;
     PortKind current_block_kind = PortKind::Main;
-    bool main_input_activated = false;
     bool has_input = false;
     bool finished = false;
     bool finalized = false;
@@ -191,15 +188,9 @@ class IOutputFormat : public IProcessor
     Statistics statistics;
 
 private:
-    void setCurrentChunk(InputPort & input, PortKind kind);
-    IOutputFormat::Status prepareMainAndPartialResult();
-    IOutputFormat::Status prepareTotalsAndExtremes();
-
     size_t rows_read_before = 0;
     bool are_totals_written = false;
 
-    bool is_partial_result_protocol_active = false;
-
     /// Counters for consumed chunks. Are used for QueryLog.
     size_t result_rows = 0;
     size_t result_bytes = 0;
diff --git a/src/Processors/Formats/Impl/PrettyBlockOutputFormat.cpp b/src/Processors/Formats/Impl/PrettyBlockOutputFormat.cpp
index 6fa891297f66..14648e68f94a 100644
--- a/src/Processors/Formats/Impl/PrettyBlockOutputFormat.cpp
+++ b/src/Processors/Formats/Impl/PrettyBlockOutputFormat.cpp
@@ -134,8 +134,7 @@ void PrettyBlockOutputFormat::write(Chunk chunk, PortKind port_kind)
 {
     if (total_rows >= format_settings.pretty.max_rows)
     {
-        if (port_kind != PortKind::PartialResult)
-            total_rows += chunk.getNumRows();
+        total_rows += chunk.getNumRows();
         return;
     }
     if (mono_block)
@@ -316,8 +315,7 @@ void PrettyBlockOutputFormat::writeChunk(const Chunk & chunk, PortKind port_kind
     }
     writeString(bottom_separator_s, out);
 
-    if (port_kind != PortKind::PartialResult)
-        total_rows += num_rows;
+    total_rows += num_rows;
 }
 
 
@@ -390,34 +388,6 @@ void PrettyBlockOutputFormat::consumeExtremes(Chunk chunk)
     write(std::move(chunk), PortKind::Extremes);
 }
 
-void PrettyBlockOutputFormat::clearLastLines(size_t lines_number)
-{
-    /// http://en.wikipedia.org/wiki/ANSI_escape_code
-    #define MOVE_TO_PREV_LINE "\033[A"
-    #define CLEAR_TO_END_OF_LINE "\033[K"
-
-    static const char * clear_prev_line = MOVE_TO_PREV_LINE \
-                                          CLEAR_TO_END_OF_LINE;
-
-    /// Move cursor to the beginning of line
-    writeCString("\r", out);
-
-    for (size_t line = 0; line < lines_number; ++line)
-    {
-        writeCString(clear_prev_line, out);
-    }
-}
-
-void PrettyBlockOutputFormat::consumePartialResult(Chunk chunk)
-{
-    if (prev_partial_block_rows > 0)
-        /// number of rows + header line + footer line
-        clearLastLines(prev_partial_block_rows + 2);
-
-    prev_partial_block_rows = chunk.getNumRows();
-    write(std::move(chunk), PortKind::PartialResult);
-}
-
 
 void PrettyBlockOutputFormat::writeMonoChunkIfNeeded()
 {
diff --git a/src/Processors/Formats/Impl/PrettyBlockOutputFormat.h b/src/Processors/Formats/Impl/PrettyBlockOutputFormat.h
index 92466dce3ff4..dfb23ac63f92 100644
--- a/src/Processors/Formats/Impl/PrettyBlockOutputFormat.h
+++ b/src/Processors/Formats/Impl/PrettyBlockOutputFormat.h
@@ -28,12 +28,7 @@ class PrettyBlockOutputFormat : public IOutputFormat
     void consumeTotals(Chunk) override;
     void consumeExtremes(Chunk) override;
 
-    void clearLastLines(size_t lines_number);
-    void consumePartialResult(Chunk) override;
-
     size_t total_rows = 0;
-    size_t prev_partial_block_rows = 0;
-
     size_t row_number_width = 7; // "10000. "
 
     const FormatSettings format_settings;
@@ -60,7 +55,6 @@ class PrettyBlockOutputFormat : public IOutputFormat
     void resetFormatterImpl() override
     {
         total_rows = 0;
-        prev_partial_block_rows = 0;
     }
 
 private:
diff --git a/src/Processors/Formats/Impl/PrettyCompactBlockOutputFormat.cpp b/src/Processors/Formats/Impl/PrettyCompactBlockOutputFormat.cpp
index 3a04d86b1adb..2ba9ec725e24 100644
--- a/src/Processors/Formats/Impl/PrettyCompactBlockOutputFormat.cpp
+++ b/src/Processors/Formats/Impl/PrettyCompactBlockOutputFormat.cpp
@@ -194,8 +194,7 @@ void PrettyCompactBlockOutputFormat::writeChunk(const Chunk & chunk, PortKind po
 
     writeBottom(max_widths);
 
-    if (port_kind != PortKind::PartialResult)
-        total_rows += num_rows;
+    total_rows += num_rows;
 }
 
 
diff --git a/src/Processors/Formats/LazyOutputFormat.h b/src/Processors/Formats/LazyOutputFormat.h
index bbcfdbb7193e..9cf609ed2d7c 100644
--- a/src/Processors/Formats/LazyOutputFormat.h
+++ b/src/Processors/Formats/LazyOutputFormat.h
@@ -14,8 +14,8 @@ class LazyOutputFormat : public IOutputFormat
 {
 
 public:
-    explicit LazyOutputFormat(const Block & header, bool is_partial_result_protocol_active = false)
-        : IOutputFormat(header, out, is_partial_result_protocol_active), queue(2) {}
+    explicit LazyOutputFormat(const Block & header)
+        : IOutputFormat(header, out), queue(2) {}
 
     String getName() const override { return "LazyOutputFormat"; }
 
@@ -49,7 +49,6 @@ class LazyOutputFormat : public IOutputFormat
 
     void consumeTotals(Chunk chunk) override { totals = std::move(chunk); }
     void consumeExtremes(Chunk chunk) override { extremes = std::move(chunk); }
-    void consumePartialResult(Chunk chunk) override { consume(std::move(chunk)); }
 
 private:
 
diff --git a/src/Processors/IProcessor.cpp b/src/Processors/IProcessor.cpp
index 2f294a32531c..8b160153733a 100644
--- a/src/Processors/IProcessor.cpp
+++ b/src/Processors/IProcessor.cpp
@@ -40,10 +40,5 @@ std::string IProcessor::statusToName(Status status)
     UNREACHABLE();
 }
 
-ProcessorPtr IProcessor::getPartialResultProcessorPtr(const ProcessorPtr & current_processor, UInt64 partial_result_limit, UInt64 partial_result_duration_ms)
-{
-    return current_processor->getPartialResultProcessor(current_processor, partial_result_limit, partial_result_duration_ms);
-}
-
 }
 
diff --git a/src/Processors/IProcessor.h b/src/Processors/IProcessor.h
index 51a0bb1c1217..c6bef1868775 100644
--- a/src/Processors/IProcessor.h
+++ b/src/Processors/IProcessor.h
@@ -164,8 +164,6 @@ class IProcessor
 
     static std::string statusToName(Status status);
 
-    static ProcessorPtr getPartialResultProcessorPtr(const ProcessorPtr & current_processor, UInt64 partial_result_limit, UInt64 partial_result_duration_ms);
-
     /** Method 'prepare' is responsible for all cheap ("instantaneous": O(1) of data volume, no wait) calculations.
       *
       * It may access input and output ports,
@@ -237,22 +235,6 @@ class IProcessor
         throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Method 'expandPipeline' is not implemented for {} processor", getName());
     }
 
-    enum class PartialResultStatus
-    {
-        /// Processor currently doesn't support work with the partial result pipeline.
-        NotSupported,
-
-        /// Processor can be skipped in the partial result pipeline.
-        SkipSupported,
-
-        /// Processor creates a light-weight copy of itself in the partial result pipeline.
-        /// The copy can create snapshots of the original processor or transform small blocks of data in the same way as the original processor
-        FullSupported,
-    };
-
-    virtual bool isPartialResultProcessor() const { return false; }
-    virtual PartialResultStatus getPartialResultProcessorSupportStatus() const { return PartialResultStatus::NotSupported; }
-
     /// In case if query was cancelled executor will wait till all processors finish their jobs.
     /// Generally, there is no reason to check this flag. However, it may be reasonable for long operations (e.g. i/o).
     bool isCancelled() const { return is_cancelled.load(std::memory_order_acquire); }
@@ -387,11 +369,6 @@ class IProcessor
 protected:
     virtual void onCancel() {}
 
-    virtual ProcessorPtr getPartialResultProcessor(const ProcessorPtr & /*current_processor*/, UInt64 /*partial_result_limit*/, UInt64 /*partial_result_duration_ms*/)
-    {
-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Method 'getPartialResultProcessor' is not implemented for {} processor", getName());
-    }
-
 private:
     /// For:
     /// - elapsed_us
diff --git a/src/Processors/LimitTransform.cpp b/src/Processors/LimitTransform.cpp
index b2bf3c28eee3..5e24062d67a4 100644
--- a/src/Processors/LimitTransform.cpp
+++ b/src/Processors/LimitTransform.cpp
@@ -1,5 +1,5 @@
 #include <Processors/LimitTransform.h>
-#include <Processors/Transforms/LimitPartialResultTransform.h>
+
 
 namespace DB
 {
@@ -180,6 +180,7 @@ LimitTransform::Status LimitTransform::preparePair(PortsData & data)
         return Status::NeedData;
 
     data.current_chunk = input.pull(true);
+
     auto rows = data.current_chunk.getNumRows();
 
     if (rows_before_limit_at_least && !data.input_port_has_counter)
@@ -366,11 +367,5 @@ bool LimitTransform::sortColumnsEqualAt(const ColumnRawPtrs & current_chunk_sort
     return true;
 }
 
-ProcessorPtr LimitTransform::getPartialResultProcessor(const ProcessorPtr & /*current_processor*/, UInt64 partial_result_limit, UInt64 partial_result_duration_ms)
-{
-    const auto & header = inputs.front().getHeader();
-    return std::make_shared<LimitPartialResultTransform>(header, partial_result_limit, partial_result_duration_ms, limit, offset);
-}
-
 }
 
diff --git a/src/Processors/LimitTransform.h b/src/Processors/LimitTransform.h
index cfacc9634f94..33ff968985f5 100644
--- a/src/Processors/LimitTransform.h
+++ b/src/Processors/LimitTransform.h
@@ -55,8 +55,6 @@ class LimitTransform final : public IProcessor
     ColumnRawPtrs extractSortColumns(const Columns & columns) const;
     bool sortColumnsEqualAt(const ColumnRawPtrs & current_chunk_sort_columns, UInt64 current_chunk_row_num) const;
 
-    ProcessorPtr getPartialResultProcessor(const ProcessorPtr & current_processor, UInt64 partial_result_limit, UInt64 partial_result_duration_ms) override;
-
 public:
     LimitTransform(
         const Block & header_, UInt64 limit_, UInt64 offset_, size_t num_streams = 1,
@@ -75,14 +73,6 @@ class LimitTransform final : public IProcessor
 
     void setRowsBeforeLimitCounter(RowsBeforeLimitCounterPtr counter) override { rows_before_limit_at_least.swap(counter); }
     void setInputPortHasCounter(size_t pos) { ports_data[pos].input_port_has_counter = true; }
-
-    PartialResultStatus getPartialResultProcessorSupportStatus() const override
-    {
-        /// Currently LimitPartialResultTransform support only single-thread work.
-        bool is_partial_result_supported = inputs.size() == 1 && outputs.size() == 1;
-
-        return is_partial_result_supported ? PartialResultStatus::FullSupported : PartialResultStatus::NotSupported;
-    }
 };
 
 }
diff --git a/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp b/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp
index cd911e4cdf4c..fb3ed7f80fc8 100644
--- a/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp
+++ b/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp
@@ -6,24 +6,10 @@
 namespace DB
 {
 
-namespace ErrorCodes
-{
-    extern const int FUNCTION_NOT_ALLOWED;
-}
-
 BuildQueryPipelineSettings BuildQueryPipelineSettings::fromContext(ContextPtr from)
 {
     BuildQueryPipelineSettings settings;
-
-    const auto & context_settings = from->getSettingsRef();
-    settings.partial_result_limit = context_settings.max_rows_in_partial_result;
-    settings.partial_result_duration_ms = context_settings.partial_result_update_duration_ms.totalMilliseconds();
-    if (settings.partial_result_duration_ms && !context_settings.allow_experimental_partial_result)
-        throw Exception(ErrorCodes::FUNCTION_NOT_ALLOWED,
-            "Partial results are not allowed by default, it's an experimental feature. "
-            "Setting 'allow_experimental_partial_result' must be enabled to use 'partial_result_update_duration_ms'");
-
-    settings.actions_settings = ExpressionActionsSettings::fromSettings(context_settings, CompileExpressions::yes);
+    settings.actions_settings = ExpressionActionsSettings::fromSettings(from->getSettingsRef(), CompileExpressions::yes);
     settings.process_list_element = from->getProcessListElement();
     settings.progress_callback = from->getProgressCallback();
     return settings;
diff --git a/src/Processors/QueryPlan/BuildQueryPipelineSettings.h b/src/Processors/QueryPlan/BuildQueryPipelineSettings.h
index 0410bf925d16..3b5e4e06953c 100644
--- a/src/Processors/QueryPlan/BuildQueryPipelineSettings.h
+++ b/src/Processors/QueryPlan/BuildQueryPipelineSettings.h
@@ -19,9 +19,6 @@ struct BuildQueryPipelineSettings
     QueryStatusPtr process_list_element;
     ProgressCallback progress_callback = nullptr;
 
-    UInt64 partial_result_limit = 0;
-    UInt64 partial_result_duration_ms = 0;
-
     const ExpressionActionsSettings & getActionsSettings() const { return actions_settings; }
     static BuildQueryPipelineSettings fromContext(ContextPtr from);
 };
diff --git a/src/Processors/QueryPlan/QueryPlan.cpp b/src/Processors/QueryPlan/QueryPlan.cpp
index ec82c233ce46..2d2dc66a8c99 100644
--- a/src/Processors/QueryPlan/QueryPlan.cpp
+++ b/src/Processors/QueryPlan/QueryPlan.cpp
@@ -168,8 +168,6 @@ QueryPipelineBuilderPtr QueryPlan::buildQueryPipeline(
 
     QueryPipelineBuilderPtr last_pipeline;
 
-    bool has_partial_result_setting = build_pipeline_settings.partial_result_duration_ms > 0;
-
     std::stack<Frame> stack;
     stack.push(Frame{.node = root});
 
@@ -196,9 +194,6 @@ QueryPipelineBuilderPtr QueryPlan::buildQueryPipeline(
         }
         else
             stack.push(Frame{.node = frame.node->children[next_child]});
-
-        if (has_partial_result_setting && last_pipeline && !last_pipeline->isPartialResultActive())
-            last_pipeline->activatePartialResult(build_pipeline_settings.partial_result_limit, build_pipeline_settings.partial_result_duration_ms);
     }
 
     last_pipeline->setProgressCallback(build_pipeline_settings.progress_callback);
diff --git a/src/Processors/QueryPlan/SortingStep.h b/src/Processors/QueryPlan/SortingStep.h
index a72cab05754f..371a24ac6f2d 100644
--- a/src/Processors/QueryPlan/SortingStep.h
+++ b/src/Processors/QueryPlan/SortingStep.h
@@ -27,8 +27,6 @@ class SortingStep : public ITransformingStep
         size_t max_bytes_before_external_sort = 0;
         TemporaryDataOnDiskScopePtr tmp_data = nullptr;
         size_t min_free_disk_space = 0;
-        UInt64 partial_result_limit = 0;
-        UInt64 partial_result_duration_ms = 0;
 
         explicit Settings(const Context & context);
         explicit Settings(size_t max_block_size_);
diff --git a/src/Processors/Transforms/AggregatingPartialResultTransform.cpp b/src/Processors/Transforms/AggregatingPartialResultTransform.cpp
deleted file mode 100644
index cf8ce72e096e..000000000000
--- a/src/Processors/Transforms/AggregatingPartialResultTransform.cpp
+++ /dev/null
@@ -1,47 +0,0 @@
-#include <Processors/Transforms/AggregatingPartialResultTransform.h>
-
-namespace DB
-{
-
-AggregatingPartialResultTransform::AggregatingPartialResultTransform(
-    const Block & input_header, const Block & output_header, AggregatingTransformPtr aggregating_transform_,
-    UInt64 partial_result_limit_, UInt64 partial_result_duration_ms_)
-    : PartialResultTransform(input_header, output_header, partial_result_limit_, partial_result_duration_ms_)
-    , aggregating_transform(std::move(aggregating_transform_))
-    , transform_aggregator(input_header, aggregating_transform->params->params)
-    {}
-
-void AggregatingPartialResultTransform::transformPartialResult(Chunk & chunk)
-{
-    auto & params = aggregating_transform->params->params;
-
-    bool no_more_keys = false;
-    AggregatedDataVariants variants;
-    ColumnRawPtrs key_columns(params.keys_size);
-    Aggregator::AggregateColumns aggregate_columns(params.aggregates_size);
-
-    const UInt64 num_rows = chunk.getNumRows();
-    transform_aggregator.executeOnBlock(chunk.detachColumns(), 0, num_rows, variants, key_columns, aggregate_columns, no_more_keys);
-
-    auto transformed_block = transform_aggregator.convertToBlocks(variants, /*final*/ true, /*max_threads*/ 1).front();
-
-    chunk = convertToChunk(transformed_block);
-}
-
-PartialResultTransform::ShaphotResult AggregatingPartialResultTransform::getRealProcessorSnapshot()
-{
-    std::lock_guard lock(aggregating_transform->snapshot_mutex);
-    if (aggregating_transform->is_generate_initialized)
-        return {{}, SnaphotStatus::Stopped};
-
-    if (aggregating_transform->variants.empty())
-        return {{}, SnaphotStatus::NotReady};
-
-    auto & snapshot_aggregator = aggregating_transform->params->aggregator;
-    auto & snapshot_variants = aggregating_transform->many_data->variants;
-    auto block = snapshot_aggregator.prepareBlockAndFillWithoutKeySnapshot(*snapshot_variants.at(0));
-
-    return {convertToChunk(block), SnaphotStatus::Ready};
-}
-
-}
diff --git a/src/Processors/Transforms/AggregatingPartialResultTransform.h b/src/Processors/Transforms/AggregatingPartialResultTransform.h
deleted file mode 100644
index f7bac3a53943..000000000000
--- a/src/Processors/Transforms/AggregatingPartialResultTransform.h
+++ /dev/null
@@ -1,29 +0,0 @@
-#pragma once
-
-#include <Interpreters/Aggregator.h>
-#include <Processors/Transforms/AggregatingTransform.h>
-#include <Processors/Transforms/PartialResultTransform.h>
-
-namespace DB
-{
-
-class AggregatingPartialResultTransform : public PartialResultTransform
-{
-public:
-    using AggregatingTransformPtr = std::shared_ptr<AggregatingTransform>;
-
-    AggregatingPartialResultTransform(
-        const Block & input_header, const Block & output_header, AggregatingTransformPtr aggregating_transform_,
-        UInt64 partial_result_limit_, UInt64 partial_result_duration_ms_);
-
-    String getName() const override { return "AggregatingPartialResultTransform"; }
-
-    void transformPartialResult(Chunk & chunk) override;
-    ShaphotResult getRealProcessorSnapshot() override;
-
-private:
-    AggregatingTransformPtr aggregating_transform;
-    Aggregator transform_aggregator;
-};
-
-}
diff --git a/src/Processors/Transforms/AggregatingTransform.cpp b/src/Processors/Transforms/AggregatingTransform.cpp
index 9546d3965233..bf475c57d367 100644
--- a/src/Processors/Transforms/AggregatingTransform.cpp
+++ b/src/Processors/Transforms/AggregatingTransform.cpp
@@ -1,4 +1,3 @@
-#include <Processors/Transforms/AggregatingPartialResultTransform.h>
 #include <Processors/Transforms/AggregatingTransform.h>
 
 #include <Formats/NativeReader.h>
@@ -10,6 +9,7 @@
 
 #include <Processors/Transforms/SquashingChunksTransform.h>
 
+
 namespace ProfileEvents
 {
     extern const Event ExternalAggregationMerge;
@@ -660,8 +660,6 @@ void AggregatingTransform::consume(Chunk chunk)
     src_rows += num_rows;
     src_bytes += chunk.bytes();
 
-    std::lock_guard lock(snapshot_mutex);
-
     if (params->params.only_merge)
     {
         auto block = getInputs().front().getHeader().cloneWithColumns(chunk.detachColumns());
@@ -681,10 +679,6 @@ void AggregatingTransform::initGenerate()
     if (is_generate_initialized.load(std::memory_order_acquire))
         return;
 
-    std::lock_guard lock(snapshot_mutex);
-    if (is_generate_initialized.load(std::memory_order_relaxed))
-        return;
-
     is_generate_initialized.store(true, std::memory_order_release);
 
     /// If there was no data, and we aggregate without keys, and we must return single row with the result of empty aggregation.
@@ -815,12 +809,4 @@ void AggregatingTransform::initGenerate()
     }
 }
 
-ProcessorPtr AggregatingTransform::getPartialResultProcessor(const ProcessorPtr & current_processor, UInt64 partial_result_limit, UInt64 partial_result_duration_ms)
-{
-    const auto & input_header = inputs.front().getHeader();
-    const auto & output_header = outputs.front().getHeader();
-    auto aggregating_processor = std::dynamic_pointer_cast<AggregatingTransform>(current_processor);
-    return std::make_shared<AggregatingPartialResultTransform>(input_header, output_header, std::move(aggregating_processor), partial_result_limit, partial_result_duration_ms);
-}
-
 }
diff --git a/src/Processors/Transforms/AggregatingTransform.h b/src/Processors/Transforms/AggregatingTransform.h
index 7b13b1a34f67..3420cdeaa501 100644
--- a/src/Processors/Transforms/AggregatingTransform.h
+++ b/src/Processors/Transforms/AggregatingTransform.h
@@ -170,23 +170,9 @@ class AggregatingTransform : public IProcessor
     void work() override;
     Processors expandPipeline() override;
 
-    PartialResultStatus getPartialResultProcessorSupportStatus() const override
-    {
-        /// Currently AggregatingPartialResultTransform support only single-thread aggregation without key.
-
-        /// TODO: check that insert results from aggregator.prepareBlockAndFillWithoutKey return values without
-        /// changing of the aggregator state when aggregation with keys will be supported in AggregatingPartialResultTransform.
-        bool is_partial_result_supported = params->params.keys_size == 0 /// Aggregation without key.
-                                    && many_data->variants.size() == 1; /// Use only one stream for aggregation.
-
-        return is_partial_result_supported ? PartialResultStatus::FullSupported : PartialResultStatus::NotSupported;
-    }
-
 protected:
     void consume(Chunk chunk);
 
-    ProcessorPtr getPartialResultProcessor(const ProcessorPtr & current_processor, UInt64 partial_result_limit, UInt64 partial_result_duration_ms) override;
-
 private:
     /// To read the data that was flushed into the temporary data file.
     Processors processors;
@@ -226,13 +212,6 @@ class AggregatingTransform : public IProcessor
 
     bool is_consume_started = false;
 
-    friend class AggregatingPartialResultTransform;
-    /// The mutex protects variables that are used for creating a snapshot of the current processor.
-    /// The current implementation of AggregatingPartialResultTransform uses the 'is_generate_initialized' variable to check
-    /// whether the processor has started sending data through the main pipeline, and the corresponding partial result processor should stop creating snapshots.
-    /// Additionally, the mutex protects the 'params->aggregator' and 'many_data->variants' variables, which are used to get data from them for a snapshot.
-    std::mutex snapshot_mutex;
-
     void initGenerate();
 };
 
diff --git a/src/Processors/Transforms/ExpressionTransform.cpp b/src/Processors/Transforms/ExpressionTransform.cpp
index bd92267a7339..0d3341b000c9 100644
--- a/src/Processors/Transforms/ExpressionTransform.cpp
+++ b/src/Processors/Transforms/ExpressionTransform.cpp
@@ -25,14 +25,6 @@ void ExpressionTransform::transform(Chunk & chunk)
     chunk.setColumns(block.getColumns(), num_rows);
 }
 
-ProcessorPtr ExpressionTransform::getPartialResultProcessor(const ProcessorPtr & /*current_processor*/, UInt64 /*partial_result_limit*/, UInt64 /*partial_result_duration_ms*/)
-{
-    const auto & header = getInputPort().getHeader();
-    auto result = std::make_shared<ExpressionTransform>(header, expression);
-    result->setDescription("(Partial result)");
-    return result;
-}
-
 ConvertingTransform::ConvertingTransform(const Block & header_, ExpressionActionsPtr expression_)
     : ExceptionKeepingTransform(header_, ExpressionTransform::transformHeader(header_, expression_->getActionsDAG()))
     , expression(std::move(expression_))
diff --git a/src/Processors/Transforms/ExpressionTransform.h b/src/Processors/Transforms/ExpressionTransform.h
index 8250f25f0f84..791c7d7ba731 100644
--- a/src/Processors/Transforms/ExpressionTransform.h
+++ b/src/Processors/Transforms/ExpressionTransform.h
@@ -26,15 +26,10 @@ class ExpressionTransform final : public ISimpleTransform
 
     static Block transformHeader(Block header, const ActionsDAG & expression);
 
-    PartialResultStatus getPartialResultProcessorSupportStatus() const override { return PartialResultStatus::FullSupported; }
-
 protected:
     void transform(Chunk & chunk) override;
 
-    ProcessorPtr getPartialResultProcessor(const ProcessorPtr & current_processor, UInt64 partial_result_limit, UInt64 partial_result_duration_ms) override;
-
 private:
-
     ExpressionActionsPtr expression;
 };
 
diff --git a/src/Processors/Transforms/LimitPartialResultTransform.cpp b/src/Processors/Transforms/LimitPartialResultTransform.cpp
deleted file mode 100644
index c9eaa9dc7dd9..000000000000
--- a/src/Processors/Transforms/LimitPartialResultTransform.cpp
+++ /dev/null
@@ -1,42 +0,0 @@
-#include <Processors/LimitTransform.h>
-#include <Processors/Transforms/LimitPartialResultTransform.h>
-
-namespace DB
-{
-
-LimitPartialResultTransform::LimitPartialResultTransform(
-    const Block & header,
-    UInt64 partial_result_limit_,
-    UInt64 partial_result_duration_ms_,
-    UInt64 limit_,
-    UInt64 offset_)
-    : PartialResultTransform(header, partial_result_limit_, partial_result_duration_ms_)
-    , limit(limit_)
-    , offset(offset_)
-    {}
-
-void LimitPartialResultTransform::transformPartialResult(Chunk & chunk)
-{
-    UInt64 num_rows = chunk.getNumRows();
-    if (num_rows < offset || limit == 0)
-    {
-        chunk = {};
-        return;
-    }
-
-    UInt64 length = std::min(limit, num_rows - offset);
-
-    /// Check if some rows should be removed
-    if (length < num_rows)
-    {
-        UInt64 num_columns = chunk.getNumColumns();
-        auto columns = chunk.detachColumns();
-
-        for (UInt64 i = 0; i < num_columns; ++i)
-            columns[i] = columns[i]->cut(offset, length);
-
-        chunk.setColumns(std::move(columns), length);
-    }
-}
-
-}
diff --git a/src/Processors/Transforms/LimitPartialResultTransform.h b/src/Processors/Transforms/LimitPartialResultTransform.h
deleted file mode 100644
index 3a0116b624d9..000000000000
--- a/src/Processors/Transforms/LimitPartialResultTransform.h
+++ /dev/null
@@ -1,36 +0,0 @@
-#pragma once
-
-#include <Processors/Transforms/PartialResultTransform.h>
-
-namespace DB
-{
-
-class LimitTransform;
-
-/// Currently support only single thread implementation with one input and one output ports
-class LimitPartialResultTransform : public PartialResultTransform
-{
-public:
-    using LimitTransformPtr = std::shared_ptr<LimitTransform>;
-
-    LimitPartialResultTransform(
-        const Block & header,
-        UInt64 partial_result_limit_,
-        UInt64 partial_result_duration_ms_,
-        UInt64 limit_,
-        UInt64 offset_);
-
-    String getName() const override { return "LimitPartialResultTransform"; }
-
-    void transformPartialResult(Chunk & chunk) override;
-    /// LimitsTransform doesn't have a state which can be snapshoted
-    ShaphotResult getRealProcessorSnapshot() override { return {{}, SnaphotStatus::Stopped}; }
-
-private:
-    UInt64 limit;
-    UInt64 offset;
-
-    LimitTransformPtr limit_transform;
-};
-
-}
diff --git a/src/Processors/Transforms/LimitsCheckingTransform.cpp b/src/Processors/Transforms/LimitsCheckingTransform.cpp
index 0557f3f291ed..02d2fef808ce 100644
--- a/src/Processors/Transforms/LimitsCheckingTransform.cpp
+++ b/src/Processors/Transforms/LimitsCheckingTransform.cpp
@@ -1,5 +1,4 @@
 #include <Processors/Transforms/LimitsCheckingTransform.h>
-#include <Processors/Transforms/PartialResultTransform.h>
 #include <Access/EnabledQuota.h>
 
 namespace DB
diff --git a/src/Processors/Transforms/LimitsCheckingTransform.h b/src/Processors/Transforms/LimitsCheckingTransform.h
index eabb988dab61..2f96a17c17be 100644
--- a/src/Processors/Transforms/LimitsCheckingTransform.h
+++ b/src/Processors/Transforms/LimitsCheckingTransform.h
@@ -33,8 +33,6 @@ class LimitsCheckingTransform : public ISimpleTransform
 
     void setQuota(const std::shared_ptr<const EnabledQuota> & quota_) { quota = quota_; }
 
-    PartialResultStatus getPartialResultProcessorSupportStatus() const override { return PartialResultStatus::SkipSupported; }
-
 protected:
     void transform(Chunk & chunk) override;
 
diff --git a/src/Processors/Transforms/MergeSortingPartialResultTransform.cpp b/src/Processors/Transforms/MergeSortingPartialResultTransform.cpp
deleted file mode 100644
index 44b34ce3f584..000000000000
--- a/src/Processors/Transforms/MergeSortingPartialResultTransform.cpp
+++ /dev/null
@@ -1,54 +0,0 @@
-#include <Processors/Transforms/MergeSortingPartialResultTransform.h>
-
-namespace DB
-{
-
-MergeSortingPartialResultTransform::MergeSortingPartialResultTransform(
-    const Block & header, MergeSortingTransformPtr merge_sorting_transform_,
-    UInt64 partial_result_limit_, UInt64 partial_result_duration_ms_)
-    : PartialResultTransform(header, partial_result_limit_, partial_result_duration_ms_)
-    , merge_sorting_transform(std::move(merge_sorting_transform_))
-    {}
-
-PartialResultTransform::ShaphotResult MergeSortingPartialResultTransform::getRealProcessorSnapshot()
-{
-    std::lock_guard lock(merge_sorting_transform->snapshot_mutex);
-    if (merge_sorting_transform->generated_prefix)
-        return {{}, SnaphotStatus::Stopped};
-
-    if (merge_sorting_transform->chunks.empty())
-        return {{}, SnaphotStatus::NotReady};
-
-    /// Sort all input data
-    merge_sorting_transform->remerge();
-
-    /// It's possible that we had only empty chunks before remerge
-    if (merge_sorting_transform->chunks.empty())
-        return {{}, SnaphotStatus::NotReady};
-
-    /// Add a copy of the first `partial_result_limit` rows to a generated_chunk
-    /// to send it later as a partial result in the next prepare stage of the current processor
-    auto generated_columns = merge_sorting_transform->chunks[0].cloneEmptyColumns();
-
-    size_t total_rows = 0;
-    for (const auto & merged_chunk : merge_sorting_transform->chunks)
-    {
-        size_t rows = std::min(merged_chunk.getNumRows(), partial_result_limit - total_rows);
-        if (rows == 0)
-            break;
-
-        for (size_t position = 0; position < generated_columns.size(); ++position)
-        {
-            auto column = merged_chunk.getColumns()[position];
-            generated_columns[position]->insertRangeFrom(*column, 0, rows);
-        }
-
-        total_rows += rows;
-    }
-
-    auto partial_result = Chunk(std::move(generated_columns), total_rows, merge_sorting_transform->chunks[0].getChunkInfo());
-    merge_sorting_transform->enrichChunkWithConstants(partial_result);
-    return {std::move(partial_result), SnaphotStatus::Ready};
-}
-
-}
diff --git a/src/Processors/Transforms/MergeSortingPartialResultTransform.h b/src/Processors/Transforms/MergeSortingPartialResultTransform.h
deleted file mode 100644
index 781aa8e1265d..000000000000
--- a/src/Processors/Transforms/MergeSortingPartialResultTransform.h
+++ /dev/null
@@ -1,28 +0,0 @@
-#pragma once
-
-#include <Processors/Transforms/MergeSortingTransform.h>
-#include <Processors/Transforms/PartialResultTransform.h>
-
-namespace DB
-{
-
-class MergeSortingPartialResultTransform : public PartialResultTransform
-{
-public:
-    using MergeSortingTransformPtr = std::shared_ptr<MergeSortingTransform>;
-
-    MergeSortingPartialResultTransform(
-        const Block & header, MergeSortingTransformPtr merge_sorting_transform_,
-        UInt64 partial_result_limit_, UInt64 partial_result_duration_ms_);
-
-    String getName() const override { return "MergeSortingPartialResultTransform"; }
-
-    /// MergeSortingTransform always receives chunks in a sorted state, so transformation is not needed
-    void transformPartialResult(Chunk & /*chunk*/) override {}
-    ShaphotResult getRealProcessorSnapshot() override;
-
-private:
-    MergeSortingTransformPtr merge_sorting_transform;
-};
-
-}
diff --git a/src/Processors/Transforms/MergeSortingTransform.cpp b/src/Processors/Transforms/MergeSortingTransform.cpp
index e801e5e16d5f..de77711d1294 100644
--- a/src/Processors/Transforms/MergeSortingTransform.cpp
+++ b/src/Processors/Transforms/MergeSortingTransform.cpp
@@ -1,5 +1,4 @@
 #include <Processors/Transforms/MergeSortingTransform.h>
-#include <Processors/Transforms/MergeSortingPartialResultTransform.h>
 #include <Processors/IAccumulatingTransform.h>
 #include <Processors/Merges/MergingSortedTransform.h>
 #include <Common/ProfileEvents.h>
@@ -137,8 +136,6 @@ void MergeSortingTransform::consume(Chunk chunk)
 
     /// If there were only const columns in sort description, then there is no need to sort.
     /// Return the chunk as is.
-    std::lock_guard lock(snapshot_mutex);
-
     if (description.empty())
     {
         generated_chunk = std::move(chunk);
@@ -216,8 +213,6 @@ void MergeSortingTransform::serialize()
 
 void MergeSortingTransform::generate()
 {
-    std::lock_guard lock(snapshot_mutex);
-
     if (!generated_prefix)
     {
         size_t num_tmp_files = tmp_data ? tmp_data->getStreams().size() : 0;
@@ -278,11 +273,4 @@ void MergeSortingTransform::remerge()
     sum_bytes_in_blocks = new_sum_bytes_in_blocks;
 }
 
-ProcessorPtr MergeSortingTransform::getPartialResultProcessor(const ProcessorPtr & current_processor, UInt64 partial_result_limit, UInt64 partial_result_duration_ms)
-{
-    const auto & header = inputs.front().getHeader();
-    auto merge_sorting_processor = std::dynamic_pointer_cast<MergeSortingTransform>(current_processor);
-    return std::make_shared<MergeSortingPartialResultTransform>(header, std::move(merge_sorting_processor), partial_result_limit, partial_result_duration_ms);
-}
-
 }
diff --git a/src/Processors/Transforms/MergeSortingTransform.h b/src/Processors/Transforms/MergeSortingTransform.h
index 67f098b43624..e8c180b69032 100644
--- a/src/Processors/Transforms/MergeSortingTransform.h
+++ b/src/Processors/Transforms/MergeSortingTransform.h
@@ -33,8 +33,6 @@ class MergeSortingTransform : public SortingTransform
 
     String getName() const override { return "MergeSortingTransform"; }
 
-    PartialResultStatus getPartialResultProcessorSupportStatus() const override { return PartialResultStatus::FullSupported; }
-
 protected:
     void consume(Chunk chunk) override;
     void serialize() override;
@@ -42,8 +40,6 @@ class MergeSortingTransform : public SortingTransform
 
     Processors expandPipeline() override;
 
-    ProcessorPtr getPartialResultProcessor(const ProcessorPtr & current_processor, UInt64 partial_result_limit, UInt64 partial_result_duration_ms) override;
-
 private:
     size_t max_bytes_before_remerge;
     double remerge_lowered_memory_bytes_ratio;
@@ -63,13 +59,6 @@ class MergeSortingTransform : public SortingTransform
     void remerge();
 
     ProcessorPtr external_merging_sorted;
-
-    friend class MergeSortingPartialResultTransform;
-    /// The mutex protects variables that are used for creating a snapshot of the current processor.
-    /// The current implementation of MergeSortingPartialResultTransform uses the 'generated_prefix' variable to check
-    /// whether the processor has started sending data through the main pipeline, and the corresponding partial result processor should stop creating snapshots.
-    /// Additionally, the mutex protects the 'chunks' variable and all variables in the 'remerge' function, which is used to transition 'chunks' to a sorted state.
-    std::mutex snapshot_mutex;
 };
 
 }
diff --git a/src/Processors/Transforms/PartialResultTransform.cpp b/src/Processors/Transforms/PartialResultTransform.cpp
deleted file mode 100644
index 97ff79dee54f..000000000000
--- a/src/Processors/Transforms/PartialResultTransform.cpp
+++ /dev/null
@@ -1,80 +0,0 @@
-#include <Processors/Transforms/PartialResultTransform.h>
-
-namespace DB
-{
-
-
-PartialResultTransform::PartialResultTransform(const Block & header, UInt64 partial_result_limit_, UInt64 partial_result_duration_ms_)
-    : PartialResultTransform(header, header, partial_result_limit_, partial_result_duration_ms_) {}
-
-PartialResultTransform::PartialResultTransform(const Block & input_header, const Block & output_header, UInt64 partial_result_limit_, UInt64 partial_result_duration_ms_)
-    : IProcessor({input_header}, {output_header})
-    , input(inputs.front())
-    , output(outputs.front())
-    , partial_result_limit(partial_result_limit_)
-    , partial_result_duration_ms(partial_result_duration_ms_)
-    , watch(CLOCK_MONOTONIC)
-    {}
-
-IProcessor::Status PartialResultTransform::prepare()
-{
-    if (output.isFinished())
-    {
-        input.close();
-        return Status::Finished;
-    }
-
-    if (finished_getting_snapshots)
-    {
-        output.finish();
-        return Status::Finished;
-    }
-
-    if (!output.canPush())
-    {
-        input.setNotNeeded();
-        return Status::PortFull;
-    }
-
-    /// If input data from previous partial result processor is finished then
-    /// PartialResultTransform ready to create snapshots and send them as a partial result
-    if (input.isFinished())
-    {
-        if (partial_result.snapshot_status == SnaphotStatus::Ready)
-        {
-            partial_result.snapshot_status = SnaphotStatus::NotReady;
-            output.push(std::move(partial_result.chunk));
-            return Status::PortFull;
-        }
-
-        return Status::Ready;
-    }
-
-    input.setNeeded();
-    if (!input.hasData())
-        return Status::NeedData;
-
-    partial_result.chunk = input.pull();
-    transformPartialResult(partial_result.chunk);
-    if (partial_result.chunk.getNumRows() > 0)
-    {
-        output.push(std::move(partial_result.chunk));
-        return Status::PortFull;
-    }
-
-    return Status::NeedData;
-}
-
-void PartialResultTransform::work()
-{
-    if (partial_result_duration_ms < watch.elapsedMilliseconds())
-    {
-        partial_result = getRealProcessorSnapshot();
-        if (partial_result.snapshot_status == SnaphotStatus::Stopped)
-            finished_getting_snapshots = true;
-
-        watch.restart();
-    }
-}
-
-}
diff --git a/src/Processors/Transforms/PartialResultTransform.h b/src/Processors/Transforms/PartialResultTransform.h
deleted file mode 100644
index 4fe87638f38d..000000000000
--- a/src/Processors/Transforms/PartialResultTransform.h
+++ /dev/null
@@ -1,57 +0,0 @@
-#pragma once
-
-#include <Processors/IProcessor.h>
-
-namespace DB
-{
-
-/// Processors of this type are used to construct an auxiliary pipeline with processors corresponding to those in the main pipeline.
-/// These processors work in two modes:
-/// 1) Creating a snapshot of the corresponding processor from the main pipeline once per partial_result_duration_ms (period in milliseconds), and then sending the snapshot through the partial result pipeline.
-/// 2) Transforming small blocks of data in the same way as the original processor and sending the transformed data through the partial result pipeline.
-/// All processors of this type rely on the invariant that a new block from the previous processor of the partial result pipeline overwrites information about the previous block of the same previous processor.
-class PartialResultTransform : public IProcessor
-{
-public:
-    PartialResultTransform(const Block & header, UInt64 partial_result_limit_, UInt64 partial_result_duration_ms_);
-    PartialResultTransform(const Block & input_header, const Block & output_header, UInt64 partial_result_limit_, UInt64 partial_result_duration_ms_);
-
-    String getName() const override { return "PartialResultTransform"; }
-
-    Status prepare() override;
-    void work() override;
-
-    bool isPartialResultProcessor() const override { return true; }
-
-protected:
-    enum class SnaphotStatus
-    {
-        NotReady, // Waiting for data from the previous partial result processor or awaiting a timer before creating the snapshot.
-        Ready,    // Current partial result processor has received a snapshot from the processor in the main pipeline.
-        Stopped,  // The processor from the main pipeline has started sending data, and the pipeline for partial results should use data from the next processors of the main pipeline.
-    };
-
-    struct ShaphotResult
-    {
-        Chunk chunk;
-        SnaphotStatus snapshot_status;
-    };
-
-    InputPort & input;
-    OutputPort & output;
-
-    UInt64 partial_result_limit;
-    UInt64 partial_result_duration_ms;
-
-    ShaphotResult partial_result = {{}, SnaphotStatus::NotReady};
-
-    bool finished_getting_snapshots = false;
-
-    virtual void transformPartialResult(Chunk & /*chunk*/) = 0;
-    virtual ShaphotResult getRealProcessorSnapshot() = 0; // { return {{}, SnaphotStatus::Stopped}; }
-
-private:
-    Stopwatch watch;
-};
-
-}
diff --git a/src/QueryPipeline/Pipe.cpp b/src/QueryPipeline/Pipe.cpp
index b22c135e8650..b1c82d7a7e8a 100644
--- a/src/QueryPipeline/Pipe.cpp
+++ b/src/QueryPipeline/Pipe.cpp
@@ -12,7 +12,6 @@
 #include <Processors/QueryPlan/QueryPlan.h>
 #include <QueryPipeline/ReadProgressCallback.h>
 #include <Columns/ColumnConst.h>
-#include <Common/logger_useful.h>
 
 #include <QueryPipeline/printPipeline.h>
 
@@ -170,9 +169,12 @@ Pipe::Pipe(ProcessorPtr source)
 {
     checkSource(*source);
 
+    if (collected_processors)
+        collected_processors->emplace_back(source);
+
     output_ports.push_back(&source->getOutputs().front());
     header = output_ports.front()->getHeader();
-    addProcessor(std::move(source));
+    processors->emplace_back(std::move(source));
     max_parallel_streams = 1;
 }
 
@@ -313,18 +315,6 @@ Pipe Pipe::unitePipes(Pipes pipes, Processors * collected_processors, bool allow
 
     for (auto & pipe : pipes)
     {
-        if (res.isPartialResultActive() && pipe.isPartialResultActive())
-        {
-            res.partial_result_ports.insert(res.partial_result_ports.end(), pipe.partial_result_ports.begin(), pipe.partial_result_ports.end());
-        }
-        else
-        {
-            if (pipe.isPartialResultActive())
-                pipe.dropPartialResult();
-            if (res.isPartialResultActive())
-                res.dropPartialResult();
-        }
-
         if (!allow_empty_header || pipe.header)
             assertCompatibleHeader(pipe.header, res.header, "Pipe::unitePipes");
 
@@ -364,11 +354,11 @@ void Pipe::addSource(ProcessorPtr source)
     else
         assertBlocksHaveEqualStructure(header, source_header, "Pipes");
 
-    output_ports.push_back(&source->getOutputs().front());
-    if (isPartialResultActive())
-        partial_result_ports.push_back(nullptr);
+    if (collected_processors)
+        collected_processors->emplace_back(source);
 
-    addProcessor(std::move(source));
+    output_ports.push_back(&source->getOutputs().front());
+    processors->emplace_back(std::move(source));
 
     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());
 }
@@ -386,9 +376,11 @@ void Pipe::addTotalsSource(ProcessorPtr source)
 
     assertBlocksHaveEqualStructure(header, source_header, "Pipes");
 
-    totals_port = &source->getOutputs().front();
+    if (collected_processors)
+        collected_processors->emplace_back(source);
 
-    addProcessor(std::move(source));
+    totals_port = &source->getOutputs().front();
+    processors->emplace_back(std::move(source));
 }
 
 void Pipe::addExtremesSource(ProcessorPtr source)
@@ -404,20 +396,11 @@ void Pipe::addExtremesSource(ProcessorPtr source)
 
     assertBlocksHaveEqualStructure(header, source_header, "Pipes");
 
-    extremes_port = &source->getOutputs().front();
-
-    addProcessor(std::move(source));
-}
-
-void Pipe::activatePartialResult(UInt64 partial_result_limit_, UInt64 partial_result_duration_ms_)
-{
-    if (is_partial_result_active)
-        throw Exception(ErrorCodes::LOGICAL_ERROR, "Partial result for Pipe should be initialized only once");
+    if (collected_processors)
+        collected_processors->emplace_back(source);
 
-    is_partial_result_active = true;
-    partial_result_limit = partial_result_limit_;
-    partial_result_duration_ms = partial_result_duration_ms_;
-    partial_result_ports.assign(output_ports.size(), nullptr);
+    extremes_port = &source->getOutputs().front();
+    processors->emplace_back(std::move(source));
 }
 
 static void dropPort(OutputPort *& port, Processors & processors, Processors * collected_processors)
@@ -445,15 +428,6 @@ void Pipe::dropExtremes()
     dropPort(extremes_port, *processors, collected_processors);
 }
 
-void Pipe::dropPartialResult()
-{
-    for (auto & port : partial_result_ports)
-        dropPort(port, *processors, collected_processors);
-
-    is_partial_result_active = false;
-    partial_result_ports.clear();
-}
-
 void Pipe::addTransform(ProcessorPtr transform)
 {
     addTransform(std::move(transform), static_cast<OutputPort *>(nullptr), static_cast<OutputPort *>(nullptr));
@@ -484,8 +458,6 @@ void Pipe::addTransform(ProcessorPtr transform, OutputPort * totals, OutputPort
     if (extremes)
         extremes_port = extremes;
 
-    addPartialResultTransform(transform);
-
     size_t next_output = 0;
     for (auto & input : inputs)
     {
@@ -536,7 +508,10 @@ void Pipe::addTransform(ProcessorPtr transform, OutputPort * totals, OutputPort
     if (extremes_port)
         assertBlocksHaveEqualStructure(header, extremes_port->getHeader(), "Pipes");
 
-    addProcessor(std::move(transform));
+    if (collected_processors)
+        collected_processors->emplace_back(transform);
+
+    processors->emplace_back(std::move(transform));
 
     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());
 }
@@ -573,8 +548,6 @@ void Pipe::addTransform(ProcessorPtr transform, InputPort * totals, InputPort *
         extremes_port = nullptr;
     }
 
-    addPartialResultTransform(transform);
-
     bool found_totals = false;
     bool found_extremes = false;
 
@@ -624,117 +597,12 @@ void Pipe::addTransform(ProcessorPtr transform, InputPort * totals, InputPort *
     if (extremes_port)
         assertBlocksHaveEqualStructure(header, extremes_port->getHeader(), "Pipes");
 
-    addProcessor(std::move(transform));
-
-    max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());
-}
-
-void Pipe::addPartialResultSimpleTransform(const ProcessorPtr & transform, size_t partial_result_port_id)
-{
-    if (isPartialResultActive())
-    {
-        auto & partial_result_port = partial_result_ports[partial_result_port_id];
-        auto partial_result_status = transform->getPartialResultProcessorSupportStatus();
-
-        if (partial_result_status == IProcessor::PartialResultStatus::NotSupported)
-            dropPort(partial_result_port, *processors, collected_processors);
-
-        if (partial_result_status != IProcessor::PartialResultStatus::FullSupported)
-            return;
-
-        auto partial_result_transform = IProcessor::getPartialResultProcessorPtr(transform, partial_result_limit, partial_result_duration_ms);
-
-        connectPartialResultPort(partial_result_port, partial_result_transform->getInputs().front());
-
-        partial_result_port = &partial_result_transform->getOutputs().front();
-
-        addProcessor(std::move(partial_result_transform));
-    }
-}
-
-void Pipe::addPartialResultTransform(const ProcessorPtr & transform)
-{
-    if (isPartialResultActive())
-    {
-        size_t new_outputs_size = 0;
-        for (const auto & output : transform->getOutputs())
-        {
-            /// We do not use totals_port and extremes_port in partial result
-            if ((totals_port && totals_port == &output) || (extremes_port && extremes_port == &output))
-                continue;
-            ++new_outputs_size;
-        }
-
-        auto partial_result_status = transform->getPartialResultProcessorSupportStatus();
-
-        if (partial_result_status == IProcessor::PartialResultStatus::SkipSupported && new_outputs_size != partial_result_ports.size())
-            throw Exception(
-                ErrorCodes::LOGICAL_ERROR,
-                "Cannot skip transform {} in the partial result part of the Pipe because it has {} output ports, but the partial result part expects {} output ports",
-                transform->getName(),
-                new_outputs_size,
-                partial_result_ports.size());
-
-        if (partial_result_status == IProcessor::PartialResultStatus::NotSupported)
-        {
-            for (auto & partial_result_port : partial_result_ports)
-                dropPort(partial_result_port, *processors, collected_processors);
-
-            partial_result_ports.assign(new_outputs_size, nullptr);
-            return;
-        }
-
-        if (partial_result_status != IProcessor::PartialResultStatus::FullSupported)
-            return;
-
-        auto partial_result_transform = IProcessor::getPartialResultProcessorPtr(transform, partial_result_limit, partial_result_duration_ms);
-        auto & inputs = partial_result_transform->getInputs();
-
-        if (inputs.size() != partial_result_ports.size())
-        {
-            WriteBufferFromOwnString out;
-            if (processors && !processors->empty())
-                printPipeline(*processors, out);
-
-            throw Exception(
-                ErrorCodes::LOGICAL_ERROR,
-                "Cannot add partial result transform {} to Pipe because it has {} input ports, but {} expected
{}",
-                partial_result_transform->getName(),
-                inputs.size(),
-                partial_result_ports.size(), out.str());
-        }
-
-        size_t next_port = 0;
-        for (auto & input : inputs)
-        {
-            connectPartialResultPort(partial_result_ports[next_port], input);
-            ++next_port;
-        }
-
-        partial_result_ports.assign(new_outputs_size, nullptr);
-
-        next_port = 0;
-        for (auto & new_partial_result_port : partial_result_transform->getOutputs())
-        {
-            partial_result_ports[next_port] = &new_partial_result_port;
-            ++next_port;
-        }
-
-        addProcessor(std::move(partial_result_transform));
-    }
-}
-
-void Pipe::connectPartialResultPort(OutputPort * partial_result_port, InputPort & partial_result_transform_port)
-{
-    if (partial_result_port == nullptr)
-    {
-        auto source = std::make_shared<NullSource>(getHeader());
-        partial_result_port = &source->getPort();
+    if (collected_processors)
+        collected_processors->emplace_back(transform);
 
-        addProcessor(std::move(source));
-    }
+    processors->emplace_back(std::move(transform));
 
-    connect(*partial_result_port, partial_result_transform_port);
+    max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());
 }
 
 void Pipe::addSimpleTransform(const ProcessorGetterWithStreamKind & getter)
@@ -744,7 +612,7 @@ void Pipe::addSimpleTransform(const ProcessorGetterWithStreamKind & getter)
 
     Block new_header;
 
-    auto add_transform = [&](OutputPort *& port, size_t partial_result_port_id, StreamType stream_type)
+    auto add_transform = [&](OutputPort *& port, StreamType stream_type)
     {
         if (!port)
             return;
@@ -780,22 +648,19 @@ void Pipe::addSimpleTransform(const ProcessorGetterWithStreamKind & getter)
         {
             connect(*port, transform->getInputs().front());
             port = &transform->getOutputs().front();
-            if (stream_type == StreamType::Main)
-                addPartialResultSimpleTransform(transform, partial_result_port_id);
 
-            addProcessor(std::move(transform));
+            if (collected_processors)
+                collected_processors->emplace_back(transform);
+
+            processors->emplace_back(std::move(transform));
         }
     };
 
-    size_t partial_result_port_id = 0;
     for (auto & port : output_ports)
-    {
-        add_transform(port, partial_result_port_id, StreamType::Main);
-        ++partial_result_port_id;
-    }
+        add_transform(port, StreamType::Main);
 
-    add_transform(totals_port, 0, StreamType::Totals);
-    add_transform(extremes_port, 0, StreamType::Extremes);
+    add_transform(totals_port, StreamType::Totals);
+    add_transform(extremes_port, StreamType::Extremes);
 
     header = std::move(new_header);
 }
@@ -816,7 +681,6 @@ void Pipe::addChains(std::vector<Chain> chains)
 
     dropTotals();
     dropExtremes();
-    dropPartialResult();
 
     size_t max_parallel_streams_for_chains = 0;
 
@@ -835,21 +699,18 @@ void Pipe::addChains(std::vector<Chain> chains)
 
         auto added_processors = Chain::getProcessors(std::move(chains[i]));
         for (auto & transform : added_processors)
-            addProcessor(std::move(transform));
+        {
+            if (collected_processors)
+                collected_processors->emplace_back(transform);
+
+            processors->emplace_back(std::move(transform));
+        }
     }
 
     header = std::move(new_header);
     max_parallel_streams = std::max(max_parallel_streams, max_parallel_streams_for_chains);
 }
 
-void Pipe::addProcessor(ProcessorPtr processor)
-{
-    if (collected_processors)
-        collected_processors->emplace_back(processor);
-
-    processors->emplace_back(std::move(processor));
-}
-
 void Pipe::resize(size_t num_streams, bool force, bool strict)
 {
     if (output_ports.empty())
@@ -910,9 +771,6 @@ void Pipe::setSinks(const Pipe::ProcessorGetterWithStreamKind & getter)
     add_transform(totals_port, StreamType::Totals);
     add_transform(extremes_port, StreamType::Extremes);
 
-    for (auto & port : partial_result_ports)
-        add_transform(port, StreamType::PartialResult);
-
     output_ports.clear();
     header.clear();
 }
@@ -922,9 +780,6 @@ void Pipe::transform(const Transformer & transformer, bool check_ports)
     if (output_ports.empty())
         throw Exception(ErrorCodes::LOGICAL_ERROR, "Cannot transform empty Pipe");
 
-    /// TODO: Add functionality to work with partial result ports in transformer.
-    dropPartialResult();
-
     auto new_processors = transformer(output_ports);
 
     /// Create hash table with new processors.
@@ -1014,10 +869,5 @@ void Pipe::transform(const Transformer & transformer, bool check_ports)
     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());
 }
 
-OutputPort * Pipe::getPartialResultPort(size_t pos) const
-{
-    return partial_result_ports.empty() ? nullptr : partial_result_ports[pos];
-}
-
 
 }
diff --git a/src/QueryPipeline/Pipe.h b/src/QueryPipeline/Pipe.h
index a6bd46a325bd..09931e385782 100644
--- a/src/QueryPipeline/Pipe.h
+++ b/src/QueryPipeline/Pipe.h
@@ -48,9 +48,6 @@ class Pipe
     OutputPort * getOutputPort(size_t pos) const { return output_ports[pos]; }
     OutputPort * getTotalsPort() const { return totals_port; }
     OutputPort * getExtremesPort() const { return extremes_port; }
-    OutputPort * getPartialResultPort(size_t pos) const;
-
-    bool isPartialResultActive() { return is_partial_result_active; }
 
     /// Add processor to list, add it output ports to output_ports.
     /// Processor shouldn't have input ports, output ports shouldn't be connected.
@@ -61,13 +58,9 @@ class Pipe
     void addTotalsSource(ProcessorPtr source);
     void addExtremesSource(ProcessorPtr source);
 
-    /// Activate sending partial result during main pipeline execution
-    void activatePartialResult(UInt64 partial_result_limit_, UInt64 partial_result_duration_ms_);
-
-    /// Drop totals, extremes and partial result (create NullSink for them).
+    /// Drop totals and extremes (create NullSink for them).
     void dropTotals();
     void dropExtremes();
-    void dropPartialResult();
 
     /// Add processor to list. It should have size() input ports with compatible header.
     /// Output ports should have same headers.
@@ -76,16 +69,11 @@ class Pipe
     void addTransform(ProcessorPtr transform, OutputPort * totals, OutputPort * extremes);
     void addTransform(ProcessorPtr transform, InputPort * totals, InputPort * extremes);
 
-    void addPartialResultTransform(const ProcessorPtr & transform);
-    void addPartialResultSimpleTransform(const ProcessorPtr & transform, size_t partial_result_port_id);
-    void connectPartialResultPort(OutputPort * partial_result_port, InputPort & partial_result_transform_port);
-
     enum class StreamType
     {
         Main = 0, /// Stream for query data. There may be several streams of this type.
         Totals,  /// Stream for totals. No more than one.
         Extremes, /// Stream for extremes. No more than one.
-        PartialResult, /// Stream for partial result data. There may be several streams of this type.
     };
 
     using ProcessorGetter = std::function<ProcessorPtr(const Block & header)>;
@@ -121,17 +109,10 @@ class Pipe
     Block header;
     std::shared_ptr<Processors> processors;
 
-    /// If the variable is true, then each time a processor is added pipe will try
-    /// to add processor which will send partial result from original processor
-    bool is_partial_result_active = false;
-    UInt64 partial_result_limit = 0;
-    UInt64 partial_result_duration_ms = 0;
-
-    /// Output ports. Totals, extremes and partial results are allowed to be empty.
+    /// Output ports. Totals and extremes are allowed to be empty.
     OutputPortRawPtrs output_ports;
     OutputPort * totals_port = nullptr;
     OutputPort * extremes_port = nullptr;
-    OutputPortRawPtrs partial_result_ports;
 
     /// It is the max number of processors which can be executed in parallel for each step.
     /// Usually, it's the same as the number of output ports.
@@ -147,8 +128,6 @@ class Pipe
     static Pipe unitePipes(Pipes pipes, Processors * collected_processors, bool allow_empty_header);
     void setSinks(const Pipe::ProcessorGetterWithStreamKind & getter);
 
-    void addProcessor(ProcessorPtr processor);
-
     friend class QueryPipelineBuilder;
     friend class QueryPipeline;
 };
diff --git a/src/QueryPipeline/QueryPipeline.cpp b/src/QueryPipeline/QueryPipeline.cpp
index 4ce0aa029bed..935c006c2178 100644
--- a/src/QueryPipeline/QueryPipeline.cpp
+++ b/src/QueryPipeline/QueryPipeline.cpp
@@ -73,8 +73,7 @@ static void checkPulling(
     Processors & processors,
     OutputPort * output,
     OutputPort * totals,
-    OutputPort * extremes,
-    OutputPort * partial_result)
+    OutputPort * extremes)
 {
     if (!output || output->isConnected())
         throw Exception(
@@ -91,15 +90,9 @@ static void checkPulling(
             ErrorCodes::LOGICAL_ERROR,
             "Cannot create pulling QueryPipeline because its extremes port is connected");
 
-    if (partial_result && partial_result->isConnected())
-        throw Exception(
-            ErrorCodes::LOGICAL_ERROR,
-            "Cannot create pulling QueryPipeline because its partial_result port is connected");
-
     bool found_output = false;
     bool found_totals = false;
     bool found_extremes = false;
-    bool found_partial_result = false;
     for (const auto & processor : processors)
     {
         for (const auto & in : processor->getInputs())
@@ -113,8 +106,6 @@ static void checkPulling(
                 found_totals = true;
             else if (extremes && &out == extremes)
                 found_extremes = true;
-            else if (partial_result && &out == partial_result)
-                found_partial_result = true;
             else
                 checkOutput(out, processor, processors);
         }
@@ -132,10 +123,6 @@ static void checkPulling(
         throw Exception(
             ErrorCodes::LOGICAL_ERROR,
             "Cannot create pulling QueryPipeline because its extremes port does not belong to any processor");
-    if (partial_result && !found_partial_result)
-        throw Exception(
-            ErrorCodes::LOGICAL_ERROR,
-            "Cannot create pulling QueryPipeline because its partial result port does not belong to any processor");
 }
 
 static void checkCompleted(Processors & processors)
@@ -338,20 +325,17 @@ QueryPipeline::QueryPipeline(
     std::shared_ptr<Processors> processors_,
     OutputPort * output_,
     OutputPort * totals_,
-    OutputPort * extremes_,
-    OutputPort * partial_result_)
+    OutputPort * extremes_)
     : resources(std::move(resources_))
     , processors(std::move(processors_))
     , output(output_)
     , totals(totals_)
     , extremes(extremes_)
-    , partial_result(partial_result_)
 {
-    checkPulling(*processors, output, totals, extremes, partial_result);
+    checkPulling(*processors, output, totals, extremes);
 }
 
 QueryPipeline::QueryPipeline(Pipe pipe)
-    : partial_result_duration_ms(pipe.partial_result_duration_ms)
 {
     if (pipe.numOutputPorts() > 0)
     {
@@ -359,11 +343,8 @@ QueryPipeline::QueryPipeline(Pipe pipe)
         output = pipe.getOutputPort(0);
         totals = pipe.getTotalsPort();
         extremes = pipe.getExtremesPort();
-        partial_result = pipe.getPartialResultPort(0);
-        num_threads = pipe.max_parallel_streams;
-
         processors = std::move(pipe.processors);
-        checkPulling(*processors, output, totals, extremes, partial_result);
+        checkPulling(*processors, output, totals, extremes);
     }
     else
     {
@@ -395,7 +376,6 @@ QueryPipeline::QueryPipeline(std::shared_ptr<IOutputFormat> format)
     auto & format_main = format->getPort(IOutputFormat::PortKind::Main);
     auto & format_totals = format->getPort(IOutputFormat::PortKind::Totals);
     auto & format_extremes = format->getPort(IOutputFormat::PortKind::Extremes);
-    auto & format_partial_result = format->getPort(IOutputFormat::PortKind::PartialResult);
 
     if (!totals)
     {
@@ -411,21 +391,12 @@ QueryPipeline::QueryPipeline(std::shared_ptr<IOutputFormat> format)
         processors->emplace_back(std::move(source));
     }
 
-    if (!partial_result)
-    {
-        auto source = std::make_shared<NullSource>(format_partial_result.getHeader());
-        partial_result = &source->getPort();
-        processors->emplace_back(std::move(source));
-    }
-
     connect(*totals, format_totals);
     connect(*extremes, format_extremes);
-    connect(*partial_result, format_partial_result);
 
     input = &format_main;
     totals = nullptr;
     extremes = nullptr;
-    partial_result = nullptr;
 
     output_format = format.get();
 
@@ -453,7 +424,6 @@ void QueryPipeline::complete(std::shared_ptr<ISink> sink)
 
     drop(totals, *processors);
     drop(extremes, *processors);
-    drop(partial_result, *processors);
 
     connect(*output, sink->getPort());
     processors->emplace_back(std::move(sink));
@@ -469,7 +439,6 @@ void QueryPipeline::complete(Chain chain)
 
     drop(totals, *processors);
     drop(extremes, *processors);
-    drop(partial_result, *processors);
 
     processors->reserve(processors->size() + chain.getProcessors().size() + 1);
     for (auto processor : chain.getProcessors())
@@ -495,7 +464,6 @@ void QueryPipeline::complete(Pipe pipe)
     pipe.resize(1);
     pipe.dropExtremes();
     pipe.dropTotals();
-    pipe.dropPartialResult();
     connect(*pipe.getOutputPort(0), *input);
     input = nullptr;
 
@@ -524,13 +492,11 @@ void QueryPipeline::complete(std::shared_ptr<IOutputFormat> format)
         addMaterializing(output, *processors);
         addMaterializing(totals, *processors);
         addMaterializing(extremes, *processors);
-        addMaterializing(partial_result, *processors);
     }
 
     auto & format_main = format->getPort(IOutputFormat::PortKind::Main);
     auto & format_totals = format->getPort(IOutputFormat::PortKind::Totals);
     auto & format_extremes = format->getPort(IOutputFormat::PortKind::Extremes);
-    auto & format_partial_result = format->getPort(IOutputFormat::PortKind::PartialResult);
 
     if (!totals)
     {
@@ -546,22 +512,13 @@ void QueryPipeline::complete(std::shared_ptr<IOutputFormat> format)
         processors->emplace_back(std::move(source));
     }
 
-    if (!partial_result)
-    {
-        auto source = std::make_shared<NullSource>(format_partial_result.getHeader());
-        partial_result = &source->getPort();
-        processors->emplace_back(std::move(source));
-    }
-
     connect(*output, format_main);
     connect(*totals, format_totals);
     connect(*extremes, format_extremes);
-    connect(*partial_result, format_partial_result);
 
     output = nullptr;
     totals = nullptr;
     extremes = nullptr;
-    partial_result = nullptr;
 
     initRowsBeforeLimit(format.get());
     output_format = format.get();
@@ -733,7 +690,6 @@ void QueryPipeline::convertStructureTo(const ColumnsWithTypeAndName & columns)
     addExpression(output, actions, *processors);
     addExpression(totals, actions, *processors);
     addExpression(extremes, actions, *processors);
-    addExpression(partial_result, actions, *processors);
 }
 
 std::unique_ptr<ReadProgressCallback> QueryPipeline::getReadProgressCallback() const
diff --git a/src/QueryPipeline/QueryPipeline.h b/src/QueryPipeline/QueryPipeline.h
index 20e58bc0f59f..f14cf61aac24 100644
--- a/src/QueryPipeline/QueryPipeline.h
+++ b/src/QueryPipeline/QueryPipeline.h
@@ -75,8 +75,7 @@ class QueryPipeline
         std::shared_ptr<Processors> processors_,
         OutputPort * output_,
         OutputPort * totals_ = nullptr,
-        OutputPort * extremes_ = nullptr,
-        OutputPort * partial_result_ = nullptr);
+        OutputPort * extremes_ = nullptr);
 
     bool initialized() const { return !processors->empty(); }
     /// When initialized, exactly one of the following is true.
@@ -155,7 +154,6 @@ class QueryPipeline
     OutputPort * output = nullptr;
     OutputPort * totals = nullptr;
     OutputPort * extremes = nullptr;
-    OutputPort * partial_result = nullptr;
 
     QueryStatusPtr process_list_element;
 
@@ -164,9 +162,6 @@ class QueryPipeline
     size_t num_threads = 0;
     bool concurrency_control = false;
 
-    UInt64 partial_result_limit = 0;
-    UInt64 partial_result_duration_ms = 0;
-
     friend class PushingPipelineExecutor;
     friend class PullingPipelineExecutor;
     friend class PushingAsyncPipelineExecutor;
diff --git a/src/QueryPipeline/QueryPipelineBuilder.cpp b/src/QueryPipeline/QueryPipelineBuilder.cpp
index e176e8585f59..f9726339872d 100644
--- a/src/QueryPipeline/QueryPipelineBuilder.cpp
+++ b/src/QueryPipeline/QueryPipelineBuilder.cpp
@@ -110,15 +110,6 @@ void QueryPipelineBuilder::init(QueryPipeline & pipeline)
         pipe.header = {};
     }
 
-    if (pipeline.partial_result)
-    {
-        /// Set partial result ports only after activation because when activated, it is set to nullptr
-        pipe.activatePartialResult(pipeline.partial_result_limit, pipeline.partial_result_duration_ms);
-        pipe.partial_result_ports = {pipeline.partial_result};
-    }
-    else
-        pipe.dropPartialResult();
-
     pipe.totals_port = pipeline.totals;
     pipe.extremes_port = pipeline.extremes;
     pipe.max_parallel_streams = pipeline.num_threads;
@@ -361,10 +352,6 @@ std::unique_ptr<QueryPipelineBuilder> QueryPipelineBuilder::joinPipelinesYShaped
     left->checkInitializedAndNotCompleted();
     right->checkInitializedAndNotCompleted();
 
-    /// TODO: Support joining of partial results from different pipelines.
-    left->pipe.dropPartialResult();
-    right->pipe.dropPartialResult();
-
     left->pipe.dropExtremes();
     right->pipe.dropExtremes();
     if (left->getNumStreams() != 1 || right->getNumStreams() != 1)
@@ -377,7 +364,6 @@ std::unique_ptr<QueryPipelineBuilder> QueryPipelineBuilder::joinPipelinesYShaped
 
     auto joining = std::make_shared<MergeJoinTransform>(join, inputs, out_header, max_block_size);
 
-    /// TODO: Support partial results in merge pipelines after joining support above.
     return mergePipelines(std::move(left), std::move(right), std::move(joining), collected_processors);
 }
 
@@ -398,10 +384,6 @@ std::unique_ptr<QueryPipelineBuilder> QueryPipelineBuilder::joinPipelinesRightLe
     left->pipe.dropExtremes();
     right->pipe.dropExtremes();
 
-    /// TODO: Support joining of partial results from different pipelines.
-    left->pipe.dropPartialResult();
-    right->pipe.dropPartialResult();
-
     left->pipe.collected_processors = collected_processors;
 
     /// Collect the NEW processors for the right pipeline.
@@ -652,7 +634,7 @@ PipelineExecutorPtr QueryPipelineBuilder::execute()
     if (!isCompleted())
         throw Exception(ErrorCodes::LOGICAL_ERROR, "Cannot execute pipeline because it is not completed");
 
-    return std::make_shared<PipelineExecutor>(pipe.processors, process_list_element, pipe.partial_result_duration_ms);
+    return std::make_shared<PipelineExecutor>(pipe.processors, process_list_element);
 }
 
 Pipe QueryPipelineBuilder::getPipe(QueryPipelineBuilder pipeline, QueryPlanResourceHolder & resources)
diff --git a/src/QueryPipeline/QueryPipelineBuilder.h b/src/QueryPipeline/QueryPipelineBuilder.h
index cee545ac29d5..5d273df70686 100644
--- a/src/QueryPipeline/QueryPipelineBuilder.h
+++ b/src/QueryPipeline/QueryPipelineBuilder.h
@@ -85,15 +85,6 @@ class QueryPipelineBuilder
     /// Pipeline will be completed after this transformation.
     void setSinks(const Pipe::ProcessorGetterWithStreamKind & getter);
 
-    /// Activate building separate pipeline for sending partial result.
-    void activatePartialResult(UInt64 partial_result_limit, UInt64 partial_result_duration_ms)
-    {
-        pipe.activatePartialResult(partial_result_limit, partial_result_duration_ms);
-    }
-
-    /// Check if building of a pipeline for sending partial result active.
-    bool isPartialResultActive() { return pipe.isPartialResultActive(); }
-
     /// Add totals which returns one chunk with single row with defaults.
     void addDefaultTotals();
 
diff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp
index 4908bf82b460..871606c62982 100644
--- a/src/Server/TCPHandler.cpp
+++ b/src/Server/TCPHandler.cpp
@@ -10,8 +10,6 @@
 #include <vector>
 #include <string_view>
 #include <cstring>
-#include <base/types.h>
-#include <base/scope_guard.h>
 #include <Poco/Net/NetException.h>
 #include <Poco/Net/SocketAddress.h>
 #include <Poco/Util/LayeredConfiguration.h>
@@ -106,7 +104,6 @@ namespace DB::ErrorCodes
     extern const int TIMEOUT_EXCEEDED;
     extern const int SUPPORT_IS_DISABLED;
     extern const int UNSUPPORTED_METHOD;
-    extern const int FUNCTION_NOT_ALLOWED;
 }
 
 namespace
@@ -965,14 +962,7 @@ void TCPHandler::processOrdinaryQueryWithProcessors()
     std::unique_lock progress_lock(task_callback_mutex, std::defer_lock);
 
     {
-        const auto & settings = query_context->getSettingsRef();
-        bool has_partial_result_setting = settings.partial_result_update_duration_ms.totalMilliseconds() > 0;
-        if (has_partial_result_setting && !settings.allow_experimental_partial_result)
-            throw Exception(ErrorCodes::FUNCTION_NOT_ALLOWED,
-                "Partial results are not allowed by default, it's an experimental feature. "
-                "Setting 'allow_experimental_partial_result' must be enabled to use 'partial_result_update_duration_ms'");
-
-        PullingAsyncPipelineExecutor executor(pipeline, has_partial_result_setting);
+        PullingAsyncPipelineExecutor executor(pipeline);
         CurrentMetrics::Increment query_thread_metric_increment{CurrentMetrics::QueryThread};
 
         Block block;
