{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 10757,
  "instance_id": "ClickHouse__ClickHouse-10757",
  "issue_numbers": [
    "10241"
  ],
  "base_commit": "092f05f8d4059b2eba24a0d1bdea348cefea16c0",
  "patch": "diff --git a/src/DataStreams/PushingToViewsBlockOutputStream.cpp b/src/DataStreams/PushingToViewsBlockOutputStream.cpp\nindex a79cc61bd2d9..ce0922bf282c 100644\n--- a/src/DataStreams/PushingToViewsBlockOutputStream.cpp\n+++ b/src/DataStreams/PushingToViewsBlockOutputStream.cpp\n@@ -90,7 +90,7 @@ PushingToViewsBlockOutputStream::PushingToViewsBlockOutputStream(\n         else\n             out = std::make_shared<PushingToViewsBlockOutputStream>(dependent_table, *views_context, ASTPtr());\n \n-        views.emplace_back(ViewInfo{std::move(query), database_table, std::move(out)});\n+        views.emplace_back(ViewInfo{std::move(query), database_table, std::move(out), nullptr});\n     }\n \n     /// Do not push to destination table if the flag is set\n@@ -162,7 +162,12 @@ void PushingToViewsBlockOutputStream::write(const Block & block)\n     {\n         // Process sequentially\n         for (size_t view_num = 0; view_num < views.size(); ++view_num)\n+        {\n             process(block, view_num);\n+\n+            if (views[view_num].exception)\n+                std::rethrow_exception(views[view_num].exception);\n+        }\n     }\n }\n \n@@ -190,8 +195,18 @@ void PushingToViewsBlockOutputStream::writeSuffix()\n     if (output)\n         output->writeSuffix();\n \n+    std::exception_ptr first_exception;\n+\n     for (auto & view : views)\n     {\n+        if (view.exception)\n+        {\n+            if (!first_exception)\n+                first_exception = view.exception;\n+\n+            continue;\n+        }\n+\n         try\n         {\n             view.out->writeSuffix();\n@@ -202,6 +217,9 @@ void PushingToViewsBlockOutputStream::writeSuffix()\n             throw;\n         }\n     }\n+\n+    if (first_exception)\n+        std::rethrow_exception(first_exception);\n }\n \n void PushingToViewsBlockOutputStream::flush()\n@@ -270,7 +288,11 @@ void PushingToViewsBlockOutputStream::process(const Block & block, size_t view_n\n     catch (Exception & ex)\n     {\n         ex.addMessage(\"while pushing to view \" + view.table_id.getNameForLogs());\n-        throw;\n+        view.exception = std::current_exception();\n+    }\n+    catch (...)\n+    {\n+        view.exception = std::current_exception();\n     }\n }\n \ndiff --git a/src/DataStreams/PushingToViewsBlockOutputStream.h b/src/DataStreams/PushingToViewsBlockOutputStream.h\nindex 162c2e1b4474..a2a1ca5caf55 100644\n--- a/src/DataStreams/PushingToViewsBlockOutputStream.h\n+++ b/src/DataStreams/PushingToViewsBlockOutputStream.h\n@@ -40,6 +40,7 @@ class PushingToViewsBlockOutputStream : public IBlockOutputStream\n         ASTPtr query;\n         StorageID table_id;\n         BlockOutputStreamPtr out;\n+        std::exception_ptr exception;\n     };\n \n     std::vector<ViewInfo> views;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01275_parallel_mv.reference b/tests/queries/0_stateless/01275_parallel_mv.reference\nnew file mode 100644\nindex 000000000000..898d3f7266e1\n--- /dev/null\n+++ b/tests/queries/0_stateless/01275_parallel_mv.reference\n@@ -0,0 +1,4 @@\n+10\n+10\n+0\n+10\ndiff --git a/tests/queries/0_stateless/01275_parallel_mv.sql b/tests/queries/0_stateless/01275_parallel_mv.sql\nnew file mode 100644\nindex 000000000000..b67fbf02f8d4\n--- /dev/null\n+++ b/tests/queries/0_stateless/01275_parallel_mv.sql\n@@ -0,0 +1,18 @@\n+drop table if exists testX;\n+drop table if exists testXA;\n+drop table if exists testXB;\n+drop table if exists testXC;\n+\n+create table testX (A Int64) engine=MergeTree order by tuple();\n+\n+create materialized view testXA engine=MergeTree order by tuple() as select sleep(1) from testX;\n+create materialized view testXB engine=MergeTree order by tuple() as select sleep(2), throwIf(A=1) from testX;\n+create materialized view testXC engine=MergeTree order by tuple() as select sleep(1) from testX;\n+\n+set parallel_view_processing=1;\n+insert into testX select number from numbers(10); -- {serverError 395}\n+\n+select count() from testX;\n+select count() from testXA;\n+select count() from testXB;\n+select count() from testXC;\n",
  "problem_statement": "parallel_view_processing behavior has changed.\nparallel_view_processing=1\r\n\r\n```\r\ndrop table if exists testX;\r\ndrop table if exists testXA;\r\ndrop table if exists testXB;\r\ndrop table if exists testXC;\r\ncreate table testX ( A Int64) engine=MergeTree order by tuple();\r\n\r\ncreate materialized view testXA engine=MergeTree order by tuple() \r\nas select sleep(1) from testX;\r\n\r\ncreate materialized view testXB engine=MergeTree order by tuple() \r\nas select sleep(2),throwIf(A=1) from testX;\r\n\r\ncreate materialized view testXC engine=MergeTree order by tuple() \r\nas select sleep(1) from testX;\r\n\r\ninsert into testX select number from numbers(10);\r\nselect count() from testX;\r\nselect count() from testXA;\r\nselect count() from testXB;\r\nselect count() from testXC; \r\n```\r\n\r\n18.14.18\r\n10\r\n10\r\n0\r\n10\r\n\r\n19.13.7.57\r\n10\r\n0\r\n0\r\n0\r\n\r\n18.14.18\r\n```\r\n26.891574 [ 23 ]  <Debug> executeQuery: (from [::1]:33136) insert into testX select number from numbers(10)\r\n26.891788 [ 23 ]  <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n26.891846 [ 23 ]  <Debug> executeQuery: Query pipeline:\r\n26.892203 [ 208 ]  <Trace> dw.testX (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n26.892487 [ 209 ]  <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n26.892528 [ 211 ]  <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n26.892531 [ 210 ]  <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n27.892829 [ 209 ]  <Trace> dw..inner.testXC (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n27.892862 [ 211 ]  <Trace> dw..inner.testXA (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n28.892788 [ 210 ]  <Trace> ThreadStatus: Thread 210 exited\r\n28.892788 [ 209 ]  <Trace> ThreadStatus: Thread 209 exited\r\n28.892829 [ 211 ]  <Trace> ThreadStatus: Thread 211 exited\r\n28.892956 [ 208 ]  <Trace> ThreadStatus: Thread 208 exited\r\n28.893027 [ 23 ]  <Error> executeQuery: Code: 395, e.displayText() = DB::Exception: Value passed to 'throwIf' \r\n28.893086 [ 23 ]  <Debug> MemoryTracker: Peak memory usage (for query): 4.02 MiB.\r\n```\r\nThreads 209, 211 did insert before Exception\r\n\r\n19.13.7.57\r\n\r\n```\r\n15.756235 [ 8174 ] <Debug> executeQuery: (from [::1]:53622) INSERT INTO testX SELECT number FROM numbers(10)\r\n15.756628 [ 8174 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n15.756696 [ 8174 ] <Debug> executeQuery: Query pipeline:\r\n15.757001 [ 30 ] <Trace> dw.testX: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n15.757196 [ 120 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n15.757196 [ 50 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n15.757314 [ 81 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n17.757825 [ 8174 ] <Error> executeQuery: Code: 395, e.displayText() = DB::Exception: Value passed to 'throwIf' \r\n17.757901 [ 8174 ] <Debug> MemoryTracker: Peak memory usage (for query): 2.30 KiB.\r\n17.757961 [ 8174 ] <Debug> MemoryTracker: Peak memory usage (total): 2.30 KiB.\r\n17.757976 [ 8174 ] <Information> TCPHandler: Processed in 2.002 sec.\r\n```\r\nThreads 120, 81 never inserted\r\n\r\n\r\nWe suspect it impacts performance because INSERTS start after all SELECTS (for 1 block ?) finished.\n",
  "hints_text": "The performance impact is visible with a high number of MVs.\r\n\r\n```\r\ndrop table if exists testX;\r\ndrop table if exists testXA;\r\ndrop table if exists testXB;\r\ndrop table if exists testXC;\r\ndrop table if exists testXD;\r\ndrop table if exists testXE;\r\ndrop table if exists testXF;\r\n\r\ncreate table testX ( A Int64) engine=MergeTree order by tuple();\r\ncreate MATERIALIZED view testXA engine=MergeTree order by tuple() as select * from testX;\r\ncreate MATERIALIZED view testXB engine=MergeTree order by tuple() as select * from testX;\r\ncreate MATERIALIZED view testXC engine=MergeTree order by tuple() as select * from testX;\r\ncreate MATERIALIZED view testXD engine=MergeTree order by tuple() as select * from testX;\r\ncreate MATERIALIZED view testXE engine=MergeTree order by tuple() as select * from testX;\r\ncreate MATERIALIZED view testXF engine=MergeTree order by tuple() as select * from testX;\r\ninsert into testX select number from numbers(100000) settings max_block_size=1000000;\r\n```\r\n\r\n18.14.18 Elapsed: **0.005 sec.** Processed 100.00 thousand rows\r\n```\r\n16.473089 [ 23 ] <Debug> executeQuery: (from [::1]:37306) insert into testX select number from numbers(100000) settings max_block_size=1000000\r\n16.473328 [ 23 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.473386 [ 23 ] <Debug> executeQuery: Query pipeline:\r\n16.474951 [ 224 ] <Trace> dw.testX (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.475310 [ 227 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.475319 [ 226 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.475327 [ 225 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.475349 [ 229 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.475358 [ 228 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.475364 [ 230 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.476860 [ 226 ] <Trace> dw..inner.testXB (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.476925 [ 227 ] <Trace> dw..inner.testXE (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.476999 [ 225 ] <Trace> dw..inner.testXA (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.477016 [ 229 ] <Trace> dw..inner.testXC (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.477453 [ 230 ] <Trace> dw..inner.testXD (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.477453 [ 228 ] <Trace> dw..inner.testXF (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.477524 [ 229 ] <Trace> ThreadStatus: Thread 229 exited\r\n16.477526 [ 227 ] <Trace> ThreadStatus: Thread 227 exited\r\n16.477531 [ 228 ] <Trace> ThreadStatus: Thread 228 exited\r\n16.477533 [ 225 ] <Trace> ThreadStatus: Thread 225 exited\r\n16.477528 [ 226 ] <Trace> ThreadStatus: Thread 226 exited\r\n16.477533 [ 230 ] <Trace> ThreadStatus: Thread 230 exited\r\n16.477651 [ 224 ] <Trace> ThreadStatus: Thread 224 exited\r\n16.477696 [ 23 ] <Information> executeQuery: Read 100000 rows, 781.25 KiB in 0.005 sec., 21904293 rows/sec., 167.12 MiB/sec.\r\n16.477703 [ 23 ] <Debug> MemoryTracker: Peak memory usage (for query): 19.81 MiB.\r\n16.477738 [ 23 ] <Information> TCPHandler: Processed in 0.005 sec.\r\n```\r\n\r\n\r\n19.13.7.57 Elapsed: **0.011 sec.** Processed 100.00 thousand rows,\r\n```\r\n\r\n30.642405 [ 8238 ] <Debug> executeQuery: (from [::1]:37958) INSERT INTO testX SELECT number FROM numbers(100000) SETTINGS max_block_size = 1000000\r\n30.642916 [ 8238 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.642994 [ 8238 ] <Debug> executeQuery: Query pipeline:\r\n30.644472 [ 68 ] <Trace> dw.testX: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.644640 [ 110 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.644643 [ 95 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.644654 [ 86 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.644654 [ 71 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.644713 [ 75 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.644713 [ 92 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.646644 [ 68 ] <Trace> dw..inner.testXA: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.647871 [ 68 ] <Trace> dw..inner.testXB: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.649033 [ 68 ] <Trace> dw..inner.testXC: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.650233 [ 68 ] <Trace> dw..inner.testXD: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.651459 [ 68 ] <Trace> dw..inner.testXE: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.652714 [ 68 ] <Trace> dw..inner.testXF: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.652812 [ 8238 ] <Information> executeQuery: Read 100000 rows, 781.25 KiB in 0.010 sec., 9649717 rows/sec., 73.62 MiB/sec.\r\n30.652824 [ 8238 ] <Debug> MemoryTracker: Peak memory usage (for query): 6.00 MiB.\r\n30.652873 [ 8238 ] <Debug> MemoryTracker: Peak memory usage (total): 6.00 MiB.\r\n30.652880 [ 8238 ] <Information> TCPHandler: Processed in 0.011 sec.\r\n```\r\n\r\nAll inserts are executed by the same thread [ 68 ]\nThe change happened in September 2019\r\n19.11.11.57 -> 19.11.12.69\r\n19.13.4.32 -> 19.13.5.44\n#7195\nBroken in #3796 if I'm not mistaken.",
  "created_at": "2020-05-08T16:26:02Z",
  "modified_files": [
    "src/DataStreams/PushingToViewsBlockOutputStream.cpp",
    "src/DataStreams/PushingToViewsBlockOutputStream.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/01275_parallel_mv.reference",
    "b/tests/queries/0_stateless/01275_parallel_mv.sql"
  ]
}