{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 47114,
  "instance_id": "ClickHouse__ClickHouse-47114",
  "issue_numbers": [
    "13541"
  ],
  "base_commit": "bd5d7f3f81c33ae9d76f15af1888041161f51269",
  "patch": "diff --git a/contrib/arrow-cmake/CMakeLists.txt b/contrib/arrow-cmake/CMakeLists.txt\nindex ae6f270a768f..4181f916d63e 100644\n--- a/contrib/arrow-cmake/CMakeLists.txt\n+++ b/contrib/arrow-cmake/CMakeLists.txt\n@@ -115,6 +115,13 @@ configure_file(\"${ORC_SOURCE_SRC_DIR}/Adaptor.hh.in\" \"${ORC_BUILD_INCLUDE_DIR}/A\n \n # ARROW_ORC + adapters/orc/CMakefiles\n set(ORC_SRCS\n+        \"${CMAKE_CURRENT_BINARY_DIR}/orc_proto.pb.h\"\n+        \"${ORC_SOURCE_SRC_DIR}/sargs/ExpressionTree.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/sargs/Literal.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/sargs/PredicateLeaf.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/sargs/SargsApplier.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/sargs/SearchArgument.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/sargs/TruthValue.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/Exceptions.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/OrcFile.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/Reader.cc\"\n@@ -129,13 +136,20 @@ set(ORC_SRCS\n         \"${ORC_SOURCE_SRC_DIR}/MemoryPool.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/RLE.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/RLEv1.cc\"\n-        \"${ORC_SOURCE_SRC_DIR}/RLEv2.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/RleDecoderV2.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/RleEncoderV2.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/RLEV2Util.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/Statistics.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/StripeStream.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/Timezone.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/TypeImpl.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/Vector.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/Writer.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/Adaptor.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/BloomFilter.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/Murmur3.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/BlockBuffer.cc\"\n+        \"${ORC_SOURCE_SRC_DIR}/wrap/orc-proto-wrapper.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/io/InputStream.cc\"\n         \"${ORC_SOURCE_SRC_DIR}/io/OutputStream.cc\"\n         \"${ORC_ADDITION_SOURCE_DIR}/orc_proto.pb.cc\"\n@@ -358,6 +372,9 @@ SET(ARROW_SRCS \"${LIBRARY_DIR}/util/compression_zlib.cc\" ${ARROW_SRCS})\n add_definitions(-DARROW_WITH_ZSTD)\n SET(ARROW_SRCS \"${LIBRARY_DIR}/util/compression_zstd.cc\" ${ARROW_SRCS})\n \n+add_definitions(-DARROW_WITH_BROTLI)\n+SET(ARROW_SRCS \"${LIBRARY_DIR}/util/compression_brotli.cc\" ${ARROW_SRCS})\n+\n \n add_library(_arrow ${ARROW_SRCS})\n \n@@ -372,6 +389,7 @@ target_link_libraries(_arrow PRIVATE\n     ch_contrib::snappy\n     ch_contrib::zlib\n     ch_contrib::zstd\n+    ch_contrib::brotli\n )\n target_link_libraries(_arrow PUBLIC _orc)\n \ndiff --git a/contrib/orc b/contrib/orc\nindex f9a393ed2433..c5d7755ba0b9 160000\n--- a/contrib/orc\n+++ b/contrib/orc\n@@ -1,1 +1,1 @@\n-Subproject commit f9a393ed2433a60034795284f82d093b348f2102\n+Subproject commit c5d7755ba0b9a95631c8daea4d094101f26ec761\ndiff --git a/docs/en/interfaces/formats.md b/docs/en/interfaces/formats.md\nindex b2b2c6d5b1e5..1b32de9723fe 100644\n--- a/docs/en/interfaces/formats.md\n+++ b/docs/en/interfaces/formats.md\n@@ -1973,6 +1973,7 @@ To exchange data with Hadoop, you can use [HDFS table engine](/docs/en/engines/t\n - [input_format_parquet_skip_columns_with_unsupported_types_in_schema_inference](/docs/en/operations/settings/settings-formats.md/#input_format_parquet_skip_columns_with_unsupported_types_in_schema_inference) - allow skipping columns with unsupported types while schema inference for Parquet format. Default value - `false`.\n - [output_format_parquet_fixed_string_as_fixed_byte_array](/docs/en/operations/settings/settings-formats.md/#output_format_parquet_fixed_string_as_fixed_byte_array) - use Parquet FIXED_LENGTH_BYTE_ARRAY type instead of Binary/String for FixedString columns. Default value - `true`.\n - [output_format_parquet_version](/docs/en/operations/settings/settings-formats.md/#output_format_parquet_version) - The version of Parquet format used in output format. Default value - `2.latest`.\n+- [output_format_parquet_compression_method](/docs/en/operations/settings/settings-formats.md/#output_format_parquet_compression_method) - compression method used in output Parquet format. Default value - `snappy`.\n \n ## Arrow {#data-format-arrow}\n \n@@ -2041,6 +2042,7 @@ $ clickhouse-client --query=\"SELECT * FROM {some_table} FORMAT Arrow\" > {filenam\n - [input_format_arrow_allow_missing_columns](/docs/en/operations/settings/settings-formats.md/#input_format_arrow_allow_missing_columns) - allow missing columns while reading Arrow data. Default value - `false`.\n - [input_format_arrow_skip_columns_with_unsupported_types_in_schema_inference](/docs/en/operations/settings/settings-formats.md/#input_format_arrow_skip_columns_with_unsupported_types_in_schema_inference) - allow skipping columns with unsupported types while schema inference for Arrow format. Default value - `false`.\n - [output_format_arrow_fixed_string_as_fixed_byte_array](/docs/en/operations/settings/settings-formats.md/#output_format_arrow_fixed_string_as_fixed_byte_array) - use Arrow FIXED_SIZE_BINARY type instead of Binary/String for FixedString columns. Default value - `true`.\n+- [output_format_arrow_compression_method](/docs/en/operations/settings/settings-formats.md/#output_format_arrow_compression_method) - compression method used in output Arrow format. Default value - `none`.\n \n ## ArrowStream {#data-format-arrow-stream}\n \n@@ -2096,6 +2098,7 @@ $ clickhouse-client --query=\"SELECT * FROM {some_table} FORMAT ORC\" > {filename.\n ### Arrow format settings {#parquet-format-settings}\n \n - [output_format_arrow_string_as_string](/docs/en/operations/settings/settings-formats.md/#output_format_arrow_string_as_string) - use Arrow String type instead of Binary for String columns. Default value - `false`.\n+- [output_format_orc_compression_method](/docs/en/operations/settings/settings-formats.md/#output_format_orc_compression_method) - compression method used in output ORC format. Default value - `none`.\n - [input_format_arrow_import_nested](/docs/en/operations/settings/settings-formats.md/#input_format_arrow_import_nested) - allow inserting array of structs into Nested table in Arrow input format. Default value - `false`.\n - [input_format_arrow_case_insensitive_column_matching](/docs/en/operations/settings/settings-formats.md/#input_format_arrow_case_insensitive_column_matching) - ignore case when matching Arrow columns with ClickHouse columns. Default value - `false`.\n - [input_format_arrow_allow_missing_columns](/docs/en/operations/settings/settings-formats.md/#input_format_arrow_allow_missing_columns) - allow missing columns while reading Arrow data. Default value - `false`.\ndiff --git a/docs/en/operations/settings/settings-formats.md b/docs/en/operations/settings/settings-formats.md\nindex 3580d83f7049..919ebaf562ff 100644\n--- a/docs/en/operations/settings/settings-formats.md\n+++ b/docs/en/operations/settings/settings-formats.md\n@@ -1014,6 +1014,12 @@ Use Arrow FIXED_SIZE_BINARY type instead of Binary/String for FixedString column\n \n Enabled by default.\n \n+### output_format_arrow_compression_method {#output_format_arrow_compression_method}\n+\n+Compression method used in output Arrow format. Supported codecs: `lz4_frame`, `zstd`, `none` (uncompressed)\n+\n+Default value: `none`.\n+\n ## ORC format settings {#orc-format-settings}\n \n ### input_format_orc_import_nested {#input_format_orc_import_nested}\n@@ -1057,6 +1063,12 @@ Use ORC String type instead of Binary for String columns.\n \n Disabled by default.\n \n+### output_format_orc_compression_method {#output_format_orc_compression_method}\n+\n+Compression method used in output ORC format. Supported codecs: `lz4`, `snappy`, `zlib`, `zstd`, `none` (uncompressed)\n+\n+Default value: `none`.\n+\n ## Parquet format settings {#parquet-format-settings}\n \n ### input_format_parquet_import_nested {#input_format_parquet_import_nested}\n@@ -1112,6 +1124,12 @@ The version of Parquet format used in output format. Supported versions: `1.0`,\n \n Default value: `2.latest`.\n \n+### output_format_parquet_compression_method {#output_format_parquet_compression_method}\n+\n+Compression method used in output Parquet format. Supported codecs: `snappy`, `lz4`, `brotli`, `zstd`, `gzip`, `none` (uncompressed)\n+\n+Default value: `snappy`.\n+\n ## Hive format settings {#hive-format-settings}\n \n ### input_format_hive_text_fields_delimiter {#input_format_hive_text_fields_delimiter}\ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex a65f2ccb60f3..ae5d5326031f 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -858,6 +858,7 @@ class IColumn;\n     M(Bool, output_format_parquet_string_as_string, false, \"Use Parquet String type instead of Binary for String columns.\", 0) \\\n     M(Bool, output_format_parquet_fixed_string_as_fixed_byte_array, true, \"Use Parquet FIXED_LENGTH_BYTE_ARRAY type instead of Binary for FixedString columns.\", 0) \\\n     M(ParquetVersion, output_format_parquet_version, \"2.latest\", \"Parquet format version for output format. Supported versions: 1.0, 2.4, 2.6 and 2.latest (default)\", 0) \\\n+    M(ParquetCompression, output_format_parquet_compression_method, \"lz4\", \"Compression method for Parquet output format. Supported codecs: snappy, lz4, brotli, zstd, gzip, none (uncompressed)\", 0) \\\n     M(String, output_format_avro_codec, \"\", \"Compression codec used for output. Possible values: 'null', 'deflate', 'snappy'.\", 0) \\\n     M(UInt64, output_format_avro_sync_interval, 16 * 1024, \"Sync interval in bytes.\", 0) \\\n     M(String, output_format_avro_string_column_pattern, \"\", \"For Avro format: regexp of String columns to select as AVRO string.\", 0) \\\n@@ -900,8 +901,10 @@ class IColumn;\n     M(Bool, output_format_arrow_low_cardinality_as_dictionary, false, \"Enable output LowCardinality type as Dictionary Arrow type\", 0) \\\n     M(Bool, output_format_arrow_string_as_string, false, \"Use Arrow String type instead of Binary for String columns\", 0) \\\n     M(Bool, output_format_arrow_fixed_string_as_fixed_byte_array, true, \"Use Arrow FIXED_SIZE_BINARY type instead of Binary for FixedString columns.\", 0) \\\n+    M(ArrowCompression, output_format_arrow_compression_method, \"lz4_frame\", \"Compression method for Arrow output format. Supported codecs: lz4_frame, zstd, none (uncompressed)\", 0) \\\n     \\\n     M(Bool, output_format_orc_string_as_string, false, \"Use ORC String type instead of Binary for String columns\", 0) \\\n+    M(ORCCompression, output_format_orc_compression_method, \"lz4\", \"Compression method for ORC output format. Supported codecs: lz4, snappy, zlib, zstd, none (uncompressed)\", 0) \\\n     \\\n     M(EnumComparingMode, format_capn_proto_enum_comparising_mode, FormatSettings::EnumComparingMode::BY_VALUES, \"How to map ClickHouse Enum and CapnProto Enum\", 0) \\\n     \\\ndiff --git a/src/Core/SettingsChangesHistory.h b/src/Core/SettingsChangesHistory.h\nindex 04f328bb6651..91b3dff31416 100644\n--- a/src/Core/SettingsChangesHistory.h\n+++ b/src/Core/SettingsChangesHistory.h\n@@ -81,7 +81,10 @@ namespace SettingsChangesHistory\n static std::map<ClickHouseVersion, SettingsChangesHistory::SettingsChanges> settings_changes_history =\n {\n     {\"23.3\", {{\"output_format_parquet_version\", \"1.0\", \"2.latest\", \"Use latest Parquet format version for output format\"},\n-              {\"input_format_json_ignore_unknown_keys_in_named_tuple\", false, true, \"Improve parsing JSON objects as named tuples\"}}},\n+              {\"input_format_json_ignore_unknown_keys_in_named_tuple\", false, true, \"Improve parsing JSON objects as named tuples\"},\n+              {\"output_format_arrow_compression_method\", \"none\", \"lz4_frame\", \"Use lz4 compression in Arrow output format by default\"},\n+              {\"output_format_parquet_compression_method\", \"snappy\", \"lz4\", \"Use lz4 compression in Parquet output format by default\"},\n+              {\"output_format_orc_compression_method\", \"none\", \"lz4_frame\", \"Use lz4 compression in ORC output format by default\"}}},\n     {\"23.2\", {{\"output_format_parquet_fixed_string_as_fixed_byte_array\", false, true, \"Use Parquet FIXED_LENGTH_BYTE_ARRAY type for FixedString by default\"},\n               {\"output_format_arrow_fixed_string_as_fixed_byte_array\", false, true, \"Use Arrow FIXED_SIZE_BINARY type for FixedString by default\"},\n               {\"query_plan_remove_redundant_distinct\", false, true, \"Remove redundant Distinct step in query plan\"},\ndiff --git a/src/Core/SettingsEnums.cpp b/src/Core/SettingsEnums.cpp\nindex 9e1ab585bb00..91572aa1b3f9 100644\n--- a/src/Core/SettingsEnums.cpp\n+++ b/src/Core/SettingsEnums.cpp\n@@ -158,7 +158,7 @@ IMPLEMENT_SETTING_ENUM(EscapingRule, ErrorCodes::BAD_ARGUMENTS,\n      {\"XML\", FormatSettings::EscapingRule::XML},\n      {\"Raw\", FormatSettings::EscapingRule::Raw}})\n \n-IMPLEMENT_SETTING_ENUM(MsgPackUUIDRepresentation , ErrorCodes::BAD_ARGUMENTS,\n+IMPLEMENT_SETTING_ENUM(MsgPackUUIDRepresentation, ErrorCodes::BAD_ARGUMENTS,\n                        {{\"bin\", FormatSettings::MsgPackUUIDRepresentation::BIN},\n                         {\"str\", FormatSettings::MsgPackUUIDRepresentation::STR},\n                         {\"ext\", FormatSettings::MsgPackUUIDRepresentation::EXT}})\n@@ -172,11 +172,30 @@ IMPLEMENT_SETTING_ENUM(LocalFSReadMethod, ErrorCodes::BAD_ARGUMENTS,\n      {\"pread\", LocalFSReadMethod::pread},\n      {\"read\", LocalFSReadMethod::read}})\n \n-\n IMPLEMENT_SETTING_ENUM_WITH_RENAME(ParquetVersion, ErrorCodes::BAD_ARGUMENTS,\n     {{\"1.0\",       FormatSettings::ParquetVersion::V1_0},\n      {\"2.4\", FormatSettings::ParquetVersion::V2_4},\n      {\"2.6\", FormatSettings::ParquetVersion::V2_6},\n      {\"2.latest\", FormatSettings::ParquetVersion::V2_LATEST}})\n \n+IMPLEMENT_SETTING_ENUM(ParquetCompression, ErrorCodes::BAD_ARGUMENTS,\n+    {{\"none\", FormatSettings::ParquetCompression::NONE},\n+     {\"snappy\", FormatSettings::ParquetCompression::SNAPPY},\n+     {\"zstd\", FormatSettings::ParquetCompression::ZSTD},\n+     {\"gzip\", FormatSettings::ParquetCompression::GZIP},\n+     {\"lz4\", FormatSettings::ParquetCompression::LZ4},\n+     {\"brotli\", FormatSettings::ParquetCompression::BROTLI}})\n+\n+IMPLEMENT_SETTING_ENUM(ArrowCompression, ErrorCodes::BAD_ARGUMENTS,\n+    {{\"none\", FormatSettings::ArrowCompression::NONE},\n+     {\"lz4_frame\", FormatSettings::ArrowCompression::LZ4_FRAME},\n+     {\"zstd\", FormatSettings::ArrowCompression::ZSTD}})\n+\n+IMPLEMENT_SETTING_ENUM(ORCCompression, ErrorCodes::BAD_ARGUMENTS,\n+    {{\"none\", FormatSettings::ORCCompression::NONE},\n+     {\"snappy\", FormatSettings::ORCCompression::SNAPPY},\n+     {\"zstd\", FormatSettings::ORCCompression::ZSTD},\n+     {\"zlib\", FormatSettings::ORCCompression::ZLIB},\n+     {\"lz4\", FormatSettings::ORCCompression::LZ4}})\n+\n }\ndiff --git a/src/Core/SettingsEnums.h b/src/Core/SettingsEnums.h\nindex 139a04f3a5a4..14e952bbd65a 100644\n--- a/src/Core/SettingsEnums.h\n+++ b/src/Core/SettingsEnums.h\n@@ -194,6 +194,12 @@ DECLARE_SETTING_ENUM_WITH_RENAME(EscapingRule, FormatSettings::EscapingRule)\n \n DECLARE_SETTING_ENUM_WITH_RENAME(MsgPackUUIDRepresentation, FormatSettings::MsgPackUUIDRepresentation)\n \n+DECLARE_SETTING_ENUM_WITH_RENAME(ParquetCompression, FormatSettings::ParquetCompression)\n+\n+DECLARE_SETTING_ENUM_WITH_RENAME(ArrowCompression, FormatSettings::ArrowCompression)\n+\n+DECLARE_SETTING_ENUM_WITH_RENAME(ORCCompression, FormatSettings::ORCCompression)\n+\n enum class Dialect\n {\n     clickhouse,\ndiff --git a/src/Formats/FormatFactory.cpp b/src/Formats/FormatFactory.cpp\nindex aca3166a8c42..7f14810b260d 100644\n--- a/src/Formats/FormatFactory.cpp\n+++ b/src/Formats/FormatFactory.cpp\n@@ -118,6 +118,7 @@ FormatSettings getFormatSettings(ContextPtr context, const Settings & settings)\n     format_settings.parquet.output_string_as_string = settings.output_format_parquet_string_as_string;\n     format_settings.parquet.output_fixed_string_as_fixed_byte_array = settings.output_format_parquet_fixed_string_as_fixed_byte_array;\n     format_settings.parquet.max_block_size = settings.input_format_parquet_max_block_size;\n+    format_settings.parquet.output_compression_method = settings.output_format_parquet_compression_method;\n     format_settings.pretty.charset = settings.output_format_pretty_grid_charset.toString() == \"ASCII\" ? FormatSettings::Pretty::Charset::ASCII : FormatSettings::Pretty::Charset::UTF8;\n     format_settings.pretty.color = settings.output_format_pretty_color;\n     format_settings.pretty.max_column_pad_width = settings.output_format_pretty_max_column_pad_width;\n@@ -158,6 +159,7 @@ FormatSettings getFormatSettings(ContextPtr context, const Settings & settings)\n     format_settings.arrow.case_insensitive_column_matching = settings.input_format_arrow_case_insensitive_column_matching;\n     format_settings.arrow.output_string_as_string = settings.output_format_arrow_string_as_string;\n     format_settings.arrow.output_fixed_string_as_fixed_byte_array = settings.output_format_arrow_fixed_string_as_fixed_byte_array;\n+    format_settings.arrow.output_compression_method = settings.output_format_arrow_compression_method;\n     format_settings.orc.import_nested = settings.input_format_orc_import_nested;\n     format_settings.orc.allow_missing_columns = settings.input_format_orc_allow_missing_columns;\n     format_settings.orc.row_batch_size = settings.input_format_orc_row_batch_size;\n@@ -168,6 +170,7 @@ FormatSettings getFormatSettings(ContextPtr context, const Settings & settings)\n     format_settings.orc.skip_columns_with_unsupported_types_in_schema_inference = settings.input_format_orc_skip_columns_with_unsupported_types_in_schema_inference;\n     format_settings.orc.case_insensitive_column_matching = settings.input_format_orc_case_insensitive_column_matching;\n     format_settings.orc.output_string_as_string = settings.output_format_orc_string_as_string;\n+    format_settings.orc.output_compression_method = settings.output_format_orc_compression_method;\n     format_settings.defaults_for_omitted_fields = settings.input_format_defaults_for_omitted_fields;\n     format_settings.capn_proto.enum_comparing_mode = settings.format_capn_proto_enum_comparising_mode;\n     format_settings.capn_proto.skip_fields_with_unsupported_types_in_schema_inference = settings.input_format_capn_proto_skip_fields_with_unsupported_types_in_schema_inference;\ndiff --git a/src/Formats/FormatSettings.h b/src/Formats/FormatSettings.h\nindex d1755a35c5fa..88a5adbc8df2 100644\n--- a/src/Formats/FormatSettings.h\n+++ b/src/Formats/FormatSettings.h\n@@ -86,6 +86,13 @@ struct FormatSettings\n \n     UInt64 max_parser_depth = DBMS_DEFAULT_MAX_PARSER_DEPTH;\n \n+    enum class ArrowCompression\n+    {\n+        NONE,\n+        LZ4_FRAME,\n+        ZSTD\n+    };\n+\n     struct\n     {\n         UInt64 row_group_size = 1000000;\n@@ -96,6 +103,7 @@ struct FormatSettings\n         bool case_insensitive_column_matching = false;\n         bool output_string_as_string = false;\n         bool output_fixed_string_as_fixed_byte_array = true;\n+        ArrowCompression output_compression_method = ArrowCompression::NONE;\n     } arrow;\n \n     struct\n@@ -183,6 +191,16 @@ struct FormatSettings\n         V2_LATEST,\n     };\n \n+    enum class ParquetCompression\n+    {\n+        NONE,\n+        SNAPPY,\n+        ZSTD,\n+        LZ4,\n+        GZIP,\n+        BROTLI,\n+    };\n+\n     struct\n     {\n         UInt64 row_group_size = 1000000;\n@@ -195,6 +213,7 @@ struct FormatSettings\n         bool output_fixed_string_as_fixed_byte_array = true;\n         UInt64 max_block_size = 8192;\n         ParquetVersion output_version;\n+        ParquetCompression output_compression_method = ParquetCompression::SNAPPY;\n     } parquet;\n \n     struct Pretty\n@@ -276,6 +295,15 @@ struct FormatSettings\n         bool accurate_types_of_literals = true;\n     } values;\n \n+    enum class ORCCompression\n+    {\n+        NONE,\n+        LZ4,\n+        SNAPPY,\n+        ZSTD,\n+        ZLIB,\n+    };\n+\n     struct\n     {\n         bool import_nested = false;\n@@ -285,6 +313,7 @@ struct FormatSettings\n         bool case_insensitive_column_matching = false;\n         std::unordered_set<int> skip_stripes = {};\n         bool output_string_as_string = false;\n+        ORCCompression output_compression_method = ORCCompression::NONE;\n     } orc;\n \n     /// For capnProto format we should determine how to\ndiff --git a/src/Processors/Formats/Impl/ArrowBlockOutputFormat.cpp b/src/Processors/Formats/Impl/ArrowBlockOutputFormat.cpp\nindex bf0e2448082f..c85c0342c8c1 100644\n--- a/src/Processors/Formats/Impl/ArrowBlockOutputFormat.cpp\n+++ b/src/Processors/Formats/Impl/ArrowBlockOutputFormat.cpp\n@@ -17,6 +17,24 @@ namespace ErrorCodes\n     extern const int UNKNOWN_EXCEPTION;\n }\n \n+namespace\n+{\n+\n+arrow::Compression::type getArrowCompression(FormatSettings::ArrowCompression method)\n+{\n+    switch (method)\n+    {\n+        case FormatSettings::ArrowCompression::NONE:\n+            return arrow::Compression::type::UNCOMPRESSED;\n+        case FormatSettings::ArrowCompression::ZSTD:\n+            return arrow::Compression::type::ZSTD;\n+        case FormatSettings::ArrowCompression::LZ4_FRAME:\n+            return arrow::Compression::type::LZ4_FRAME;\n+    }\n+}\n+\n+}\n+\n ArrowBlockOutputFormat::ArrowBlockOutputFormat(WriteBuffer & out_, const Block & header_, bool stream_, const FormatSettings & format_settings_)\n     : IOutputFormat(header_, out_)\n     , stream{stream_}\n@@ -78,12 +96,14 @@ void ArrowBlockOutputFormat::prepareWriter(const std::shared_ptr<arrow::Schema>\n {\n     arrow_ostream = std::make_shared<ArrowBufferedOutputStream>(out);\n     arrow::Result<std::shared_ptr<arrow::ipc::RecordBatchWriter>> writer_status;\n+    arrow::ipc::IpcWriteOptions options = arrow::ipc::IpcWriteOptions::Defaults();\n+    options.codec = *arrow::util::Codec::Create(getArrowCompression(format_settings.arrow.output_compression_method));\n \n     // TODO: should we use arrow::ipc::IpcOptions::alignment?\n     if (stream)\n-        writer_status = arrow::ipc::MakeStreamWriter(arrow_ostream.get(), schema);\n+        writer_status = arrow::ipc::MakeStreamWriter(arrow_ostream.get(), schema, options);\n     else\n-        writer_status = arrow::ipc::MakeFileWriter(arrow_ostream.get(), schema);\n+        writer_status = arrow::ipc::MakeFileWriter(arrow_ostream.get(), schema,options);\n \n     if (!writer_status.ok())\n         throw Exception(ErrorCodes::UNKNOWN_EXCEPTION,\ndiff --git a/src/Processors/Formats/Impl/ORCBlockOutputFormat.cpp b/src/Processors/Formats/Impl/ORCBlockOutputFormat.cpp\nindex 42c3e178436e..39cacde94edd 100644\n--- a/src/Processors/Formats/Impl/ORCBlockOutputFormat.cpp\n+++ b/src/Processors/Formats/Impl/ORCBlockOutputFormat.cpp\n@@ -28,6 +28,34 @@ namespace DB\n namespace ErrorCodes\n {\n     extern const int ILLEGAL_COLUMN;\n+    extern const int NOT_IMPLEMENTED;\n+}\n+\n+namespace\n+{\n+\n+orc::CompressionKind getORCCompression(FormatSettings::ORCCompression method)\n+{\n+    if (method == FormatSettings::ORCCompression::NONE)\n+        return orc::CompressionKind::CompressionKind_NONE;\n+\n+#if USE_SNAPPY\n+    if (method == FormatSettings::ORCCompression::SNAPPY)\n+        return orc::CompressionKind::CompressionKind_SNAPPY;\n+#endif\n+\n+    if (method == FormatSettings::ORCCompression::ZSTD)\n+        return orc::CompressionKind::CompressionKind_ZSTD;\n+\n+    if (method == FormatSettings::ORCCompression::LZ4)\n+        return orc::CompressionKind::CompressionKind_LZ4;\n+\n+    if (method == FormatSettings::ORCCompression::ZLIB)\n+        return orc::CompressionKind::CompressionKind_ZLIB;\n+\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Unsupported compression method\");\n+}\n+\n }\n \n ORCOutputStream::ORCOutputStream(WriteBuffer & out_) : out(out_) {}\n@@ -529,7 +557,7 @@ void ORCBlockOutputFormat::prepareWriter()\n {\n     const Block & header = getPort(PortKind::Main).getHeader();\n     schema = orc::createStructType();\n-    options.setCompression(orc::CompressionKind::CompressionKind_NONE);\n+    options.setCompression(getORCCompression(format_settings.orc.output_compression_method));\n     size_t columns_count = header.columns();\n     for (size_t i = 0; i != columns_count; ++i)\n         schema->addStructField(header.safeGetByPosition(i).name, getORCType(recursiveRemoveLowCardinality(data_types[i])));\ndiff --git a/src/Processors/Formats/Impl/ParquetBlockOutputFormat.cpp b/src/Processors/Formats/Impl/ParquetBlockOutputFormat.cpp\nindex 18c81f8fd6ad..759f773a574b 100644\n--- a/src/Processors/Formats/Impl/ParquetBlockOutputFormat.cpp\n+++ b/src/Processors/Formats/Impl/ParquetBlockOutputFormat.cpp\n@@ -14,9 +14,13 @@ namespace DB\n namespace ErrorCodes\n {\n     extern const int UNKNOWN_EXCEPTION;\n+    extern const int NOT_IMPLEMENTED;\n }\n \n-static parquet::ParquetVersion::type getParquetVersion(const FormatSettings & settings)\n+namespace\n+{\n+\n+parquet::ParquetVersion::type getParquetVersion(const FormatSettings & settings)\n {\n     switch (settings.parquet.output_version)\n     {\n@@ -31,6 +35,35 @@ static parquet::ParquetVersion::type getParquetVersion(const FormatSettings & se\n     }\n }\n \n+parquet::Compression::type getParquetCompression(FormatSettings::ParquetCompression method)\n+{\n+    if (method == FormatSettings::ParquetCompression::NONE)\n+        return parquet::Compression::type::UNCOMPRESSED;\n+\n+#if USE_SNAPPY\n+    if (method == FormatSettings::ParquetCompression::SNAPPY)\n+        return parquet::Compression::type::SNAPPY;\n+#endif\n+\n+#if USE_BROTLI\n+    if (method == FormatSettings::ParquetCompression::BROTLI)\n+        return parquet::Compression::type::BROTLI;\n+#endif\n+\n+    if (method == FormatSettings::ParquetCompression::ZSTD)\n+        return parquet::Compression::type::ZSTD;\n+\n+    if (method == FormatSettings::ParquetCompression::LZ4)\n+        return parquet::Compression::type::LZ4;\n+\n+    if (method == FormatSettings::ParquetCompression::GZIP)\n+        return parquet::Compression::type::GZIP;\n+\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Unsupported compression method\");\n+}\n+\n+}\n+\n ParquetBlockOutputFormat::ParquetBlockOutputFormat(WriteBuffer & out_, const Block & header_, const FormatSettings & format_settings_)\n     : IOutputFormat(header_, out_), format_settings{format_settings_}\n {\n@@ -60,9 +93,7 @@ void ParquetBlockOutputFormat::consume(Chunk chunk)\n \n         parquet::WriterProperties::Builder builder;\n         builder.version(getParquetVersion(format_settings));\n-#if USE_SNAPPY\n-        builder.compression(parquet::Compression::SNAPPY);\n-#endif\n+        builder.compression(getParquetCompression(format_settings.parquet.output_compression_method));\n         auto props = builder.build();\n         auto status = parquet::arrow::FileWriter::Open(\n             *arrow_table->schema(),\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01308_orc_output_format_arrays.reference b/tests/queries/0_stateless/01308_orc_output_format_arrays.reference\nindex 1f9646ac1121..7feea7cec356 100644\nBinary files a/tests/queries/0_stateless/01308_orc_output_format_arrays.reference and b/tests/queries/0_stateless/01308_orc_output_format_arrays.reference differ\ndiff --git a/tests/queries/0_stateless/01308_orc_output_format_arrays.sh b/tests/queries/0_stateless/01308_orc_output_format_arrays.sh\nindex 1d9aea353b6a..498854874cf5 100755\n--- a/tests/queries/0_stateless/01308_orc_output_format_arrays.sh\n+++ b/tests/queries/0_stateless/01308_orc_output_format_arrays.sh\n@@ -11,7 +11,7 @@ $CLICKHOUSE_CLIENT --query=\"CREATE TABLE orc (array1 Array(Int32), array2 Array(\n \n $CLICKHOUSE_CLIENT --query=\"INSERT INTO orc VALUES ([1,2,3,4,5], [[1,2], [3,4], [5]]), ([42], [[42, 42], [42]])\";\n \n-$CLICKHOUSE_CLIENT --query=\"SELECT * FROM orc FORMAT ORC\";\n+$CLICKHOUSE_CLIENT --query=\"SELECT * FROM orc FORMAT ORC SETTINGS output_format_orc_compression_method='none'\" | md5sum;\n \n $CLICKHOUSE_CLIENT --query=\"DROP TABLE orc\";\n \ndiff --git a/tests/queries/0_stateless/02426_orc_bug.reference b/tests/queries/0_stateless/02426_orc_bug.reference\nindex e5ad2b492892..baa88da21588 100644\nBinary files a/tests/queries/0_stateless/02426_orc_bug.reference and b/tests/queries/0_stateless/02426_orc_bug.reference differ\ndiff --git a/tests/queries/0_stateless/02426_orc_bug.sh b/tests/queries/0_stateless/02426_orc_bug.sh\nnew file mode 100755\nindex 000000000000..7a7ad9f17838\n--- /dev/null\n+++ b/tests/queries/0_stateless/02426_orc_bug.sh\n@@ -0,0 +1,9 @@\n+#!/usr/bin/env bash\n+# Tags: no-fasttest\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT --query=\"SELECT arrayJoin([[], [1]]) FORMAT ORC SETTINGS output_format_orc_compression_method='none'\" | md5sum;\n+\ndiff --git a/tests/queries/0_stateless/02426_orc_bug.sql b/tests/queries/0_stateless/02426_orc_bug.sql\ndeleted file mode 100644\nindex 7016f1ceb708..000000000000\n--- a/tests/queries/0_stateless/02426_orc_bug.sql\n+++ /dev/null\n@@ -1,3 +0,0 @@\n--- Tags: no-fasttest\n-\n-SELECT arrayJoin([[], [1]]) FORMAT ORC;\ndiff --git a/tests/queries/0_stateless/02581_parquet_arrow_orc_compressions.reference b/tests/queries/0_stateless/02581_parquet_arrow_orc_compressions.reference\nnew file mode 100644\nindex 000000000000..492b12dba563\n--- /dev/null\n+++ b/tests/queries/0_stateless/02581_parquet_arrow_orc_compressions.reference\n@@ -0,0 +1,14 @@\n+10\n+10\n+10\n+10\n+10\n+10\n+10\n+10\n+10\n+10\n+10\n+10\n+10\n+10\ndiff --git a/tests/queries/0_stateless/02581_parquet_arrow_orc_compressions.sh b/tests/queries/0_stateless/02581_parquet_arrow_orc_compressions.sh\nnew file mode 100755\nindex 000000000000..89b5147f026f\n--- /dev/null\n+++ b/tests/queries/0_stateless/02581_parquet_arrow_orc_compressions.sh\n@@ -0,0 +1,25 @@\n+#!/usr/bin/env bash\n+# Tags: no-fasttest\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format Parquet settings output_format_parquet_compression_method='none'\" | $CLICKHOUSE_LOCAL --input-format=Parquet -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format Parquet settings output_format_parquet_compression_method='lz4'\" | $CLICKHOUSE_LOCAL --input-format=Parquet -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format Parquet settings output_format_parquet_compression_method='snappy'\" | $CLICKHOUSE_LOCAL --input-format=Parquet -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format Parquet settings output_format_parquet_compression_method='zstd'\" | $CLICKHOUSE_LOCAL --input-format=Parquet -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format Parquet settings output_format_parquet_compression_method='brotli'\" | $CLICKHOUSE_LOCAL --input-format=Parquet -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format Parquet settings output_format_parquet_compression_method='gzip'\" | $CLICKHOUSE_LOCAL --input-format=Parquet -q \"select count() from table\"\n+\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format ORC settings output_format_orc_compression_method='none'\" | $CLICKHOUSE_LOCAL --input-format=ORC -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format ORC settings output_format_orc_compression_method='lz4'\" | $CLICKHOUSE_LOCAL --input-format=ORC -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format ORC settings output_format_orc_compression_method='zstd'\" | $CLICKHOUSE_LOCAL --input-format=ORC -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format ORC settings output_format_orc_compression_method='zlib'\" | $CLICKHOUSE_LOCAL --input-format=ORC -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format ORC settings output_format_orc_compression_method='snappy'\" | $CLICKHOUSE_LOCAL --input-format=ORC -q \"select count() from table\"\n+\n+\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format Arrow settings output_format_arrow_compression_method='none'\" | $CLICKHOUSE_LOCAL --input-format=Arrow -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format Arrow settings output_format_arrow_compression_method='lz4_frame'\" | $CLICKHOUSE_LOCAL --input-format=Arrow -q \"select count() from table\"\n+$CLICKHOUSE_LOCAL -q \"select * from numbers(10) format Arrow settings output_format_arrow_compression_method='zstd'\" | $CLICKHOUSE_LOCAL --input-format=Arrow -q \"select count() from table\"\n+\n",
  "problem_statement": "Ability to write Parquet with configured compression / codec (snappy, gzip etc) \nIt'd be great to be able to specify the Parquet codec for compression. SNAPPY for example has different properties than GZIP. It's not clear to me what Clickhouse currently uses. \r\n\r\nThanks.\n",
  "hints_text": "Further, it would be great to add Parquet codec compression *levels* e.g. ZSTD(6). ",
  "created_at": "2023-03-01T21:26:40Z",
  "modified_files": [
    "contrib/arrow-cmake/CMakeLists.txt",
    "contrib/orc",
    "docs/en/interfaces/formats.md",
    "docs/en/operations/settings/settings-formats.md",
    "src/Core/Settings.h",
    "src/Core/SettingsChangesHistory.h",
    "src/Core/SettingsEnums.cpp",
    "src/Core/SettingsEnums.h",
    "src/Formats/FormatFactory.cpp",
    "src/Formats/FormatSettings.h",
    "src/Processors/Formats/Impl/ArrowBlockOutputFormat.cpp",
    "src/Processors/Formats/Impl/ORCBlockOutputFormat.cpp",
    "src/Processors/Formats/Impl/ParquetBlockOutputFormat.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/01308_orc_output_format_arrays.sh",
    "b/tests/queries/0_stateless/02426_orc_bug.sh",
    "tests/queries/0_stateless/02426_orc_bug.sql",
    "b/tests/queries/0_stateless/02581_parquet_arrow_orc_compressions.reference",
    "b/tests/queries/0_stateless/02581_parquet_arrow_orc_compressions.sh"
  ]
}