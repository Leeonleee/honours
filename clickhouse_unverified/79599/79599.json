{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 79599,
  "instance_id": "ClickHouse__ClickHouse-79599",
  "issue_numbers": [
    "76177"
  ],
  "base_commit": "4e66e691a280c5d04b9d8e24a36a113ecb00b920",
  "patch": "diff --git a/src/Client/HedgedConnections.cpp b/src/Client/HedgedConnections.cpp\nindex 856e2464f572..a0eb582cdce6 100644\n--- a/src/Client/HedgedConnections.cpp\n+++ b/src/Client/HedgedConnections.cpp\n@@ -18,7 +18,6 @@ namespace Setting\n {\n     extern const SettingsBool allow_changing_replica_until_first_data_packet;\n     extern const SettingsBool allow_experimental_analyzer;\n-    extern const SettingsUInt64 allow_experimental_parallel_reading_from_replicas;\n     extern const SettingsUInt64 connections_with_failover_max_tries;\n     extern const SettingsDialect dialect;\n     extern const SettingsBool fallback_to_stale_replicas_for_distributed_queries;\n@@ -54,9 +53,7 @@ HedgedConnections::HedgedConnections(\n           timeouts_,\n           context_->getSettingsRef()[Setting::connections_with_failover_max_tries].value,\n           context_->getSettingsRef()[Setting::fallback_to_stale_replicas_for_distributed_queries].value,\n-          context_->getSettingsRef()[Setting::allow_experimental_parallel_reading_from_replicas].value > 0\n-            ? context_->getSettingsRef()[Setting::max_parallel_replicas].value\n-            : 1,\n+          context_->getSettingsRef()[Setting::max_parallel_replicas].value,\n           context_->getSettingsRef()[Setting::skip_unavailable_shards].value,\n           table_to_check_,\n           priority_func)\ndiff --git a/src/Processors/QueryPlan/ReadFromRemote.cpp b/src/Processors/QueryPlan/ReadFromRemote.cpp\nindex 192508681782..4f9e425f7143 100644\n--- a/src/Processors/QueryPlan/ReadFromRemote.cpp\n+++ b/src/Processors/QueryPlan/ReadFromRemote.cpp\n@@ -50,6 +50,7 @@ namespace DB\n {\n namespace Setting\n {\n+    extern const SettingsUInt64 allow_experimental_parallel_reading_from_replicas;\n     extern const SettingsBool async_query_sending_for_remote;\n     extern const SettingsBool async_socket_for_remote;\n     extern const SettingsString cluster_for_parallel_replicas;\n@@ -600,6 +601,7 @@ void ReadFromRemote::addPipe(Pipes & pipes, const ClusterProxy::SelectStreamFact\n     bool add_extremes = false;\n     bool async_read = context->getSettingsRef()[Setting::async_socket_for_remote];\n     bool async_query_sending = context->getSettingsRef()[Setting::async_query_sending_for_remote];\n+    bool parallel_replicas_disabled = context->getSettingsRef()[Setting::allow_experimental_parallel_reading_from_replicas] == 0;\n     if (stage == QueryProcessingStage::Complete)\n     {\n         if (const auto * ast_select = shard.query->as<ASTSelectQuery>())\n@@ -690,7 +692,7 @@ void ReadFromRemote::addPipe(Pipes & pipes, const ClusterProxy::SelectStreamFact\n             shard.shard_info.pool, query_string, shard.header, context, throttler, scalars, external_tables, stage_to_use, shard.query_plan);\n         remote_query_executor->setLogger(log);\n \n-        if (context->canUseTaskBasedParallelReplicas())\n+        if (context->canUseTaskBasedParallelReplicas() || parallel_replicas_disabled)\n         {\n             // when doing parallel reading from replicas (ParallelReplicasMode::READ_TASKS) on a shard:\n             // establish a connection to a replica on the shard, the replica will instantiate coordinator to manage parallel reading from replicas on the shard.\n@@ -698,6 +700,8 @@ void ReadFromRemote::addPipe(Pipes & pipes, const ClusterProxy::SelectStreamFact\n             // Only one coordinator per shard is necessary. Therefore using PoolMode::GET_ONE to establish only one connection per shard.\n             // Using PoolMode::GET_MANY for this mode will(can) lead to instantiation of several coordinators (depends on max_parallel_replicas setting)\n             // each will execute parallel reading from replicas, so the query result will be multiplied by the number of created coordinators\n+            //\n+            // In case parallel replicas are disabled, there also should be a single connection to each shard to prevent result duplication\n             remote_query_executor->setPoolMode(PoolMode::GET_ONE);\n         }\n         else\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03444_distributed_wo_hedged_requests.reference b/tests/queries/0_stateless/03444_distributed_wo_hedged_requests.reference\nnew file mode 100644\nindex 000000000000..e8a31f848af6\n--- /dev/null\n+++ b/tests/queries/0_stateless/03444_distributed_wo_hedged_requests.reference\n@@ -0,0 +1,3 @@\n+remote() 1 shard: 100\n+remote() 3 shards: 300\n+Distributed: 100\ndiff --git a/tests/queries/0_stateless/03444_distributed_wo_hedged_requests.sql b/tests/queries/0_stateless/03444_distributed_wo_hedged_requests.sql\nnew file mode 100644\nindex 000000000000..2edc7806bd8a\n--- /dev/null\n+++ b/tests/queries/0_stateless/03444_distributed_wo_hedged_requests.sql\n@@ -0,0 +1,26 @@\n+drop table if exists 03444_local;\n+drop table if exists 03444_distr;\n+\n+create table 03444_local (id UInt32) engine = MergeTree order by id as select * from numbers(100);\n+create table 03444_distr (id UInt32) engine = Distributed(test_cluster_one_shard_two_replicas, currentDatabase(), 03444_local);\n+\n+select 'remote() 1 shard: ' || count()\n+from remote('127.0.0.1|127.0.0.2|127.0.0.3', currentDatabase(), 03444_local)\n+settings prefer_localhost_replica = 0,\n+         use_hedged_requests = 0,\n+         max_parallel_replicas = 100;\n+\n+select 'remote() 3 shards: ' || count()\n+from remote('127.0.0.1|127.0.0.2,127.0.0.3|127.0.0.4,127.0.0.5|127.0.0.6', currentDatabase(), 03444_local)\n+settings prefer_localhost_replica = 0,\n+         use_hedged_requests = 0,\n+         max_parallel_replicas = 100;\n+\n+select 'Distributed: ' || count()\n+from 03444_distr\n+settings prefer_localhost_replica = 0,\n+         use_hedged_requests = 0,\n+         max_parallel_replicas = 100;\n+\n+drop table 03444_local;\n+drop table 03444_distr;\n",
  "problem_statement": "Distributed selects can return incorrect data if use_hedged_requests is disabled\n### Company or project name\n\n_No response_\n\n### Describe the unexpected behaviour\n\nIf `max_parallel_replicas` is > 1 and `use_hedged_requests` is disabled then distributed tables send selects to all replicas of every shard.\n\n\n### How to reproduce\n\n```\nselect name, shard_num, replica_num from system.clusters where name='replicated'\n\nname       | shard_num | replica_num\n-----------+-----------+------------\nreplicated |         1 |           1\nreplicated |         1 |           2\nreplicated |         1 |           3\n\nSELECT dummy FROM cluster(replicated, system.one)\nsettings max_parallel_replicas=1, use_hedged_requests=0\n\ndummy\n-----\n    0\n\nSELECT dummy FROM cluster(replicated, system.one)\nsettings max_parallel_replicas=10, use_hedged_requests=0\n\ndummy\n-----\n    0\n    0\n    0\n```\n\n### Expected behavior\n\nI would expect ClickHouse to return one copy of a dataset even if it sends queries to all replicas.\n\n### Error message and/or stacktrace\n\n_No response_\n\n### Additional context\n\nI ran into this in 25.1 after `max_parallel_replicas` was set to 1000 by default.\n",
  "hints_text": "Actually `prefer_localhost_replica` also needs to be disabled to observe this behavior.\nhttps://fiddle.clickhouse.com/bd7c7569-fa2a-4d20-b39b-4ef8ad5f7d76\nI tried to repeat the same steps, but cannot reproduce:\n\n``` sql\nSELECT\n    name,\n    shard_num,\n    replica_num\nFROM system.clusters\nWHERE name = 'parallel_replicas'\n\n    \u250c\u2500name\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500shard_num\u2500\u252c\u2500replica_num\u2500\u2510\n 1. \u2502 parallel_replicas \u2502         1 \u2502           1 \u2502\n 2. \u2502 parallel_replicas \u2502         1 \u2502           2 \u2502\n 3. \u2502 parallel_replicas \u2502         1 \u2502           3 \u2502\n 4. \u2502 parallel_replicas \u2502         1 \u2502           4 \u2502\n 5. \u2502 parallel_replicas \u2502         1 \u2502           5 \u2502\n 6. \u2502 parallel_replicas \u2502         1 \u2502           6 \u2502\n 7. \u2502 parallel_replicas \u2502         1 \u2502           7 \u2502\n 8. \u2502 parallel_replicas \u2502         1 \u2502           8 \u2502\n 9. \u2502 parallel_replicas \u2502         1 \u2502           9 \u2502\n10. \u2502 parallel_replicas \u2502         1 \u2502          10 \u2502\n11. \u2502 parallel_replicas \u2502         1 \u2502          11 \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n``` sql\nSELECT *\nFROM cluster(parallel_replicas, system.one)\nSETTINGS max_parallel_replicas = 10, use_hedged_requests = 0, enable_parallel_replicas = 1, use_hedged_requests = 0, cluster_for_parallel_replicas = 'parallel_replicas', prefer_localhost_replica = 0, parallel_replicas_for_non_replicated_merge_tree = 1\n\n   \u250c\u2500dummy\u2500\u2510\n1. \u2502     0 \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nEither it is fixed, or I'm doing smth wrong. Could you pls provide an isolated example (when the cluster definition is also available).\nOr, even better, send a PR with a test.\n> Could you pls provide an isolated example\n\nwhat about the fiddle that I provided?\n\nYour test works because `enable_parallel_replicas` is enabled. It is disabled by default and I have not changed it\nhttps://fiddle.clickhouse.com/44cd874c-f60b-4b4f-a57e-4548c814bbc7\nI got slightly different error:\nhttps://d1k2gkhrlfqv31.cloudfront.net/clickhouse-test-reports-private/25412/735ecafe6ab960aea77c7b2d0ff170479303b1d4/unit_tests__asan_/run.log\n24.12\n\nhttps://fiddle.clickhouse.com/a517ad33-ad60-4b84-8210-3eb2a454f81d\n\n```\n1\tprefer_localhost_replica\n1\tuse_hedged_requests\n1\tuse_hedged_requests + prefer_localhost_replica\n```\n\n25.1\n\nhttps://fiddle.clickhouse.com/b31f8ff5-5db9-48f1-bf7d-0c7c2bdb680b\n\n```\n1\tprefer_localhost_replica\n1\tuse_hedged_requests\n3\tuse_hedged_requests + prefer_localhost_replica\n```\n\n3 - because of max_parallel_replicas = 1000\n> I got slightly different error: https://d1k2gkhrlfqv31.cloudfront.net/clickhouse-test-reports-private/25412/735ecafe6ab960aea77c7b2d0ff170479303b1d4/unit_tests__asan_/run.log\n\nI cannot see the file unfortunately.\nHowever I don't get any errors, I get duplicated data in my queries (I have two replicas so everything is multiplied by two).\nI can also replicate the issue in our sharded setup:\n- ClickHouse `v25.1.8.25`\n- cluster with 6 shards x 2 replicas each (12 nodes)\n\nexpected result: `6`\n```sql\nselect count() from cluster(default, system.one)\nsettings use_hedged_requests = 0, prefer_localhost_replica = 0, max_parallel_replicas = 1;\n+-------+\n|count()|\n+-------+\n|6      |\n+-------+\n```\n\n```sql\nselect count() from cluster(default, system.one)\nsettings use_hedged_requests = 0, prefer_localhost_replica = 1, max_parallel_replicas = 1;\n+-------+\n|count()|\n+-------+\n|6      |\n+-------+\n```\n\n```sql\nselect count() from cluster(default, system.one)\nsettings use_hedged_requests = 0, prefer_localhost_replica = 0, max_parallel_replicas = 1000;\n+-------+\n|count()|\n+-------+\n|12     |\n+-------+\n```\n\n```sql\nselect count() from cluster(default, system.one)\nsettings use_hedged_requests = 0, prefer_localhost_replica = 1, max_parallel_replicas = 1000;\n+-------+\n|count()|\n+-------+\n|11     |\n+-------+\n```\n@den-crane should this be tagged as a bug? can we safely disable `use_hedged_requests` when setting `max_parallel_replicas` to 1?",
  "created_at": "2025-04-25T17:26:18Z"
}