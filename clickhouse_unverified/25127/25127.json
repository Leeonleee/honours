{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 25127,
  "instance_id": "ClickHouse__ClickHouse-25127",
  "issue_numbers": [
    "25070"
  ],
  "base_commit": "82b8d45cd71128378b334e0aa4abc756898e688d",
  "patch": "diff --git a/src/Common/FieldVisitors.h b/src/Common/FieldVisitors.h\nindex 0384be39494f..5d3d30369cc0 100644\n--- a/src/Common/FieldVisitors.h\n+++ b/src/Common/FieldVisitors.h\n@@ -269,6 +269,19 @@ class FieldVisitorHash : public StaticVisitor<>\n     void operator() (const AggregateFunctionStateData & x) const;\n };\n \n+/// This is a special visitor which is used to get partition ID.\n+/// Calculate hash for UUID the same way as for UInt128.\n+/// It worked this way until 21.5, and we cannot change it,\n+/// or partition ID will be different in case UUID is used in partition key.\n+/// (It is not recommended to use UUID as partition key).\n+class LegacyFieldVisitorHash : public FieldVisitorHash\n+{\n+public:\n+    using FieldVisitorHash::FieldVisitorHash;\n+    using FieldVisitorHash::operator();\n+    void operator() (const UUID & x) const { FieldVisitorHash::operator()(x.toUnderType()); }\n+};\n+\n \n template <typename T> constexpr bool isDecimalField() { return false; }\n template <> constexpr bool isDecimalField<DecimalField<Decimal32>>() { return true; }\ndiff --git a/src/Storages/MergeTree/MergeTreePartition.cpp b/src/Storages/MergeTree/MergeTreePartition.cpp\nindex a19bd263dbfc..710b259c3ec7 100644\n--- a/src/Storages/MergeTree/MergeTreePartition.cpp\n+++ b/src/Storages/MergeTree/MergeTreePartition.cpp\n@@ -74,7 +74,7 @@ String MergeTreePartition::getID(const Block & partition_key_sample) const\n     }\n \n     SipHash hash;\n-    FieldVisitorHash hashing_visitor(hash);\n+    LegacyFieldVisitorHash hashing_visitor(hash);\n     for (const Field & field : value)\n         applyVisitor(hashing_visitor, field);\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01891_partition_by_uuid.reference b/tests/queries/0_stateless/01891_partition_by_uuid.reference\nnew file mode 100644\nindex 000000000000..1835863e7ff7\n--- /dev/null\n+++ b/tests/queries/0_stateless/01891_partition_by_uuid.reference\n@@ -0,0 +1,1 @@\n+48406fdb38e23228b776558b4edfa795\ndiff --git a/tests/queries/0_stateless/01891_partition_by_uuid.sql b/tests/queries/0_stateless/01891_partition_by_uuid.sql\nnew file mode 100644\nindex 000000000000..19abbb2ebdbb\n--- /dev/null\n+++ b/tests/queries/0_stateless/01891_partition_by_uuid.sql\n@@ -0,0 +1,7 @@\n+drop table if exists tab;\n+create table tab (id UUID, value UInt32) engine = MergeTree PARTITION BY id order by tuple();\n+insert into tab values ('61f0c404-5cb3-11e7-907b-a6006ad3dba0', 1), ('61f0c404-5cb3-11e7-907b-a6006ad3dba0', 2);\n+-- Here we check that partition id for UUID partition key did not change.\n+-- Different result means Backward Incompatible Change. Old partitions will not be accepted by new server.\n+select partition_id from system.parts where table = 'tab' and database = currentDatabase();\n+drop table if exists tab;\ndiff --git a/tests/queries/0_stateless/01891_partition_hash.reference b/tests/queries/0_stateless/01891_partition_hash.reference\nnew file mode 100644\nindex 000000000000..56d11075e503\n--- /dev/null\n+++ b/tests/queries/0_stateless/01891_partition_hash.reference\n@@ -0,0 +1,1 @@\n+6ba51fa36c625adab5d58007c96e32bf\ndiff --git a/tests/queries/0_stateless/01891_partition_hash.sql b/tests/queries/0_stateless/01891_partition_hash.sql\nnew file mode 100644\nindex 000000000000..6e356e799aba\n--- /dev/null\n+++ b/tests/queries/0_stateless/01891_partition_hash.sql\n@@ -0,0 +1,7 @@\n+drop table if exists tab;\n+create table tab (i8 Int8, i16 Int16, i32 Int32, i64 Int64, i128 Int128, i256 Int256, u8 UInt8, u16 UInt16, u32 UInt32, u64 UInt64, u128 UInt128, u256 UInt256, id UUID, s String, fs FixedString(33), a Array(UInt8), t Tuple(UInt16, UInt32), d Date, dt DateTime, dt64 DateTime64, dec128 Decimal128(3), dec256 Decimal256(4), lc LowCardinality(String)) engine = MergeTree PARTITION BY (i8, i16, i32, i64, i128, i256, u8, u16, u32, u64, u128, u256, id, s, fs, a, t, d, dt, dt64, dec128, dec256, lc) order by tuple();\n+insert into tab values (-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, '61f0c404-5cb3-11e7-907b-a6006ad3dba0', 'a', 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', [1, 2, 3], (-1, -2), '2020-01-01', '2020-01-01 01:01:01', '2020-01-01 01:01:01', '123.456', '78.9101', 'a');\n+-- Here we check that partition id did not change.\n+-- Different result means Backward Incompatible Change. Old partitions will not be accepted by new server.\n+select partition_id from system.parts where table = 'tab' and database = currentDatabase();\n+drop table if exists tab;\ndiff --git a/tests/queries/0_stateless/01891_partition_hash_no_long_int.reference b/tests/queries/0_stateless/01891_partition_hash_no_long_int.reference\nnew file mode 100644\nindex 000000000000..061081b28add\n--- /dev/null\n+++ b/tests/queries/0_stateless/01891_partition_hash_no_long_int.reference\n@@ -0,0 +1,1 @@\n+04a875063d3809312ff884e90a5b4dad\ndiff --git a/tests/queries/0_stateless/01891_partition_hash_no_long_int.sql b/tests/queries/0_stateless/01891_partition_hash_no_long_int.sql\nnew file mode 100644\nindex 000000000000..bf5c24579239\n--- /dev/null\n+++ b/tests/queries/0_stateless/01891_partition_hash_no_long_int.sql\n@@ -0,0 +1,7 @@\n+drop table if exists tab;\n+create table tab (i8 Int8, i16 Int16, i32 Int32, i64 Int64, u8 UInt8, u16 UInt16, u32 UInt32, u64 UInt64, id UUID, s String, fs FixedString(33), a Array(UInt8), t Tuple(UInt16, UInt32), d Date, dt DateTime, dt64 DateTime64, dec128 Decimal128(3), lc LowCardinality(String)) engine = MergeTree PARTITION BY (i8, i16, i32, i64, u8, u16, u32, u64, id, s, fs, a, t, d, dt, dt64, dec128, lc) order by tuple();\n+insert into tab values (-1, -1, -1, -1, -1, -1, -1, -1, '61f0c404-5cb3-11e7-907b-a6006ad3dba0', 'a', 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', [1, 2, 3], (-1, -2), '2020-01-01', '2020-01-01 01:01:01', '2020-01-01 01:01:01', '123.456', 'a');\n+-- Here we check that partition id did not change.\n+-- Different result means Backward Incompatible Change. Old partitions will not be accepted by new server.\n+select partition_id from system.parts where table = 'tab' and database = currentDatabase();\n+drop table if exists tab;\n",
  "problem_statement": "Data loss after upgrading\nAfter upgrading clickhouse client and server from version 21.5.6.6 to version 21.6.3.14, I've lost all data stored prior to the update (or at least, access to this data).\r\n\r\nAll my table definitions are intact, but data from before the upgrade is not available. \r\n\r\nThe clickhouse-server.log file has a lot of errors of the type \"While loading part <path> calculated partition ID: <some-id> differs from partition ID in part name: <other-id>\". For example:\r\n\r\n```\r\n2021.06.06 04:35:58.031714 [ 2076 ] {} <Error> auto DB::MergeTreeData::loadDataParts(bool)::(anonymous class)::operator()() const: Code: 246, e.displayText() = DB::Exception: While loading part /datadisk/clickhouse/store/1af/1afedfe1-c1e7-4382-9a39-6b81acd36f2c/7602567da462c2a7f2677c06a783bf1c_234_234_0/: calculated partition ID: 61df88718388867b629412876782fda3 differs from partition ID in part name: 7602567da462c2a7f2677c06a783bf1c, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8b5b17a in /usr/bin/clickhouse\r\n1. DB::IMergeTreeDataPart::loadPartitionAndMinMaxIndex() @ 0x100992a0 in /usr/bin/clickhouse\r\n2. ? @ 0x1011ef1c in /usr/bin/clickhouse\r\n3. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8b9df58 in /usr/bin/clickhouse\r\n4. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() @ 0x8b9f91f in /usr/bin/clickhouse\r\n5. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8b9b49f in /usr/bin/clickhouse\r\n6. ? @ 0x8b9e9c3 in /usr/bin/clickhouse\r\n7. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n8. __clone @ 0x12171f in /lib/x86_64-linux-gnu/libc-2.27.so\r\n (version 21.6.3.14 (official build))\r\n```\r\n\r\nI've noticed I have some data stored in a /detached/ folder. When I try to attach that with the \"alter table X attach partition id 'Y'\" syntax, I get the same error that the calculated partition ID  differs from partition ID in part name.\r\n\r\nWhat can have caused this? Is there anyway to get the data back?\r\n\r\nAdditional information:\r\n- my tables are using the MergeTree engine, while some materialized views use AggregatingMergeTree and SummingMergeTree. All of them have lost older data.\r\n- In the system tables, some tables have data from before the upgrade, while others seem to have been truncated when upgrading (e.g. system.trace_log includes old data, while system.errors only has data from after the upgrade). I don't know if this is by design or not.\r\n- my best guess is that the upgrade caused this, but for all I know it is possible that some corruption happened before this, and the upgrade made it visible\r\n- the partitioning key for all my tables is of type (UUID, UInt32) (e.g PARTITION BY (Id, toYYYYMM(timestamp)) )\r\n\n",
  "hints_text": ">the partitioning key for all my tables is of type (UUID, UInt32) (e.g PARTITION BY (Id, toYYYYMM(timestamp)) )\r\n\r\nCan you share an example of such \"create table\" ?\r\n\r\n>In the system tables, some tables have data from before the upgrade, while others seem to have been truncated\r\n\r\nNo, check `system.trace_log_0, system.trace_log_1`. CH renames (rotates) system tables during upgrade if the table structure is inconsistent.\n> > the partitioning key for all my tables is of type (UUID, UInt32) (e.g PARTITION BY (Id, toYYYYMM(timestamp)) )\r\n> \r\n> Can you share an example of such \"create table\" ?\r\n> \r\n\r\n```sql\r\nCREATE TABLE mydb.counts\r\n(\r\n    `id` UUID,\r\n    `thing` LowCardinality(String),\r\n    `timestamp` DateTime CODEC(DoubleDelta, LZ4),\r\n    `count` UInt32\r\n)\r\nENGINE = SummingMergeTree\r\nPARTITION BY (id, toYYYYMM(timestamp))\r\nPRIMARY KEY (id, thing)\r\nORDER BY (id, thing, toStartOfHour(timestamp))\r\nTTL timestamp + toIntervalDay(92)\r\nSETTINGS index_granularity = 8192\r\n``` \r\n\r\n> > In the system tables, some tables have data from before the upgrade, while others seem to have been truncated\r\n> \r\n> No, check `system.trace_log_0, system.trace_log_1`. CH renames (rotates) system tables during upgrade if the table structure is inconsistent.\r\n\r\nI see such `_0` renaming on `metric_log`, `asynchronous_metric_log` and `query_log`. However `system.errors` does not have errors older than the time I updated, and there is no `system.errors_0`. I definitely made query errors before this. (If it's not by design that this got truncated, I figured it was an interesting symptom.)\r\n\r\n\r\n\nIt may happen if the calculation of partition id has changed between versions.\r\nIt should not change in any valid use cases, but there is one special case that I remember:\r\nIt may change for date times after 2106-02-07 that were invalid in previous versions and are ok in newer versions.\r\n\r\nIt is possible to attach these partitions and restore data back (more details will be provided).\r\n\r\nPS. Partition by UUID is not always a good idea. It only makes sense if you have very small number of UUIDs.\nAll the timestamps were essentially set to `now()`, so the problem shouldn't be that in this case. The lost partitions are from the previous month, and the month before (I've not been using CH very long).\r\n\r\nHere are the other definitions I've used. One table is defined like this: \r\n\r\n```sql\r\nCREATE TABLE mydb.measures\r\n(\r\n    `id` UUID,\r\n    `thing` LowCardinality(String),\r\n    `timestamp` DateTime CODEC(DoubleDelta, LZ4),\r\n    [.. some measures ..]\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY (id, toYYYYMM(timestamp))\r\nORDER BY (id, thing, timestamp)\r\nTTL timestamp + toIntervalDay(92)\r\nSETTINGS index_granularity = 8192\r\n```\r\n\r\nThis has a materialized view, aggregated by week:\r\n\r\n```sql\r\nCREATE MATERIALIZED VIEW mydb.measures_by_week\r\n(\r\n    `id` UUID,\r\n    `thing` LowCardinality(String),\r\n    `week` DateTime('UTC'),\r\n    [.. some aggregations ..]\r\n)\r\nENGINE = AggregatingMergeTree\r\nPARTITION BY (id, toYYYYMM(week))\r\nORDER BY (id, thing, week)\r\nSETTINGS index_granularity = 8192 AS\r\nSELECT\r\n    id, \r\n    thing,  \r\n    toStartOfWeek(timestamp) AS week,  \r\n    [.. some aggregations ..]\r\nFROM mydb.measures\r\nGROUP BY id, thing, week\r\n```\r\n\r\nAnd another aggregated by day\r\n\r\n```sql\r\nCREATE MATERIALIZED VIEW mydb.measures_by_day\r\n(\r\n    `id` UUID,\r\n    `thing` LowCardinality(String),\r\n    `day` DateTime('UTC'),\r\n    [.. some aggregations ..]\r\n)\r\nENGINE = AggregatingMergeTree\r\nPARTITION BY (userid, toYYYYMM(day))\r\nORDER BY (id, thing, day)\r\nSETTINGS index_granularity = 8192 AS\r\nSELECT\r\n    userid,\r\n    url,\r\n    toStartOfDay(timestamp) AS day,\r\n    [.. some aggregations ..]\r\nFROM mydb.measures\r\nGROUP BY userid, url, day\r\n```\r\n\r\n\n> PS. Partition by UUID is not always a good idea. It only makes sense if you have very small number of UUIDs.\r\n\r\nUnderstood. It will be fewer than 1000 in my case.\r\n\r\nThanks for being so responsive here in the github issues. I've been thoroughly impressed by Clickhouse so far, and have seen performance that makes me feel like I've witnessed a magic trick.\nRepro:\r\n\r\n21.5.6.6\r\n```\r\ncreate table tab (id UUID, value UInt32) engine = MergeTree PARTITION BY id order by tuple();\r\ninsert into tab values ('00000000-0000-0000-0000-000000000000', 1), ('00000000-0000-0000-0000-000000000000', 2), ('61f0c404-5cb3-11e7-907b-a6006ad3dba0', 1), ('61f0c404-5cb3-11e7-907b-a6006ad3dba0', 2)\r\nselect * from tab;\r\n\r\nSELECT *\r\nFROM tab\r\n\r\nQuery id: 37881657-dfe1-4d88-a4a3-e1a36ef27180\r\n\r\n\u250c\u2500id\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500value\u2500\u2510\r\n\u2502 00000000-0000-0000-0000-000000000000 \u2502     1 \u2502\r\n\u2502 00000000-0000-0000-0000-000000000000 \u2502     2 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u250c\u2500id\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500value\u2500\u2510\r\n\u2502 61f0c404-5cb3-11e7-907b-a6006ad3dba0 \u2502     1 \u2502\r\n\u2502 61f0c404-5cb3-11e7-907b-a6006ad3dba0 \u2502     2 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n```\r\n\r\nThen, run 21.6.3.14\r\n\r\n```\r\n2021.06.08 20:49:29.715668 [ 7007 ] {} <Error> auto DB::MergeTreeData::loadDataParts(bool)::(anonymous class)::operator()() const: Code: 246, e.displayText() = DB::Exception: While loading part /home/nik-kochetov/test/clickhouse/store/b17/b1798cc5-c1f1-466a-9077-58e7b1a8cce2/406b07f4457f6ffb0fc4e82f9a4301e4_2_2_0/: calculated partition ID: 2ee6f09247edfddb9740a5c807ceaba5 differs from partition ID in part name: 406b07f4457f6ffb0fc4e82f9a4301e4, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8b5b17a in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n1. DB::IMergeTreeDataPart::loadPartitionAndMinMaxIndex() @ 0x100992a0 in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n2. ? @ 0x1011ef1c in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n3. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8b9df58 in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n4. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() @ 0x8b9f91f in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n5. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8b9b49f in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n6. ? @ 0x8b9e9c3 in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n7. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n8. /build/glibc-S9d2JN/glibc-2.27/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:97: __clone @ 0x12171f in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n (version 21.6.3.14 (official build))\r\n2021.06.08 20:49:29.715671 [ 6975 ] {} <Error> auto DB::MergeTreeData::loadDataParts(bool)::(anonymous class)::operator()() const: Code: 246, e.displayText() = DB::Exception: While loading part /home/nik-kochetov/test/clickhouse/store/b17/b1798cc5-c1f1-466a-9077-58e7b1a8cce2/17131ee739ef6ee5a6a5dbcf5fc496fc_1_1_0/: calculated partition ID: 6dedc79d1e7f47ce8dbfdacbe3ace24c differs from partition ID in part name: 17131ee739ef6ee5a6a5dbcf5fc496fc, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8b5b17a in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n1. DB::IMergeTreeDataPart::loadPartitionAndMinMaxIndex() @ 0x100992a0 in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n2. ? @ 0x1011ef1c in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n3. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8b9df58 in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n4. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() @ 0x8b9f91f in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n5. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8b9b49f in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n6. ? @ 0x8b9e9c3 in /home/nik-kochetov/test/21.6.3.14/usr/bin/clickhouse\r\n7. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n8. /build/glibc-S9d2JN/glibc-2.27/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:97: __clone @ 0x12171f in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n (version 21.6.3.14 (official build))\r\n2021.06.08 20:49:29.715770 [ 7007 ] {} <Error> default.tab (b1798cc5-c1f1-466a-9077-58e7b1a8cce2): Considering to remove broken part /home/nik-kochetov/test/clickhouse/store/b17/b1798cc5-c1f1-466a-9077-58e7b1a8cce2/406b07f4457f6ffb0fc4e82f9a4301e4_2_2_0 because it's impossible to repair.\r\n2021.06.08 20:49:29.715844 [ 6975 ] {} <Error> default.tab (b1798cc5-c1f1-466a-9077-58e7b1a8cce2): Considering to remove broken part /home/nik-kochetov/test/clickhouse/store/b17/b1798cc5-c1f1-466a-9077-58e7b1a8cce2/17131ee739ef6ee5a6a5dbcf5fc496fc_1_1_0 because it's impossible to repair.\r\n2021.06.08 20:49:29.716317 [ 7000 ] {} <Debug> default.tab (b1798cc5-c1f1-466a-9077-58e7b1a8cce2): Loaded data parts (0 items)\r\n\r\n```",
  "created_at": "2021-06-09T13:55:17Z"
}