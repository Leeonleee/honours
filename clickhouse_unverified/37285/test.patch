diff --git a/src/Common/tests/gtest_concurrency_control.cpp b/src/Common/tests/gtest_concurrency_control.cpp
new file mode 100644
index 000000000000..2ffb16511f34
--- /dev/null
+++ b/src/Common/tests/gtest_concurrency_control.cpp
@@ -0,0 +1,289 @@
+#include <gtest/gtest.h>
+
+#include <vector>
+#include <thread>
+#include <pcg_random.hpp>
+
+#include <base/types.h>
+#include <base/sleep.h>
+#include <Common/ConcurrencyControl.h>
+#include <Common/randomSeed.h>
+
+struct ConcurrencyControlTest
+{
+    ConcurrencyControl cc;
+
+    explicit ConcurrencyControlTest(ConcurrencyControl::SlotCount limit = ConcurrencyControl::Unlimited)
+    {
+        cc.setMaxConcurrency(limit);
+    }
+};
+
+TEST(ConcurrencyControl, Unlimited)
+{
+    ConcurrencyControlTest t; // unlimited number of slots
+    auto slots = t.cc.allocate(0, 100500);
+    std::vector<ConcurrencyControl::SlotPtr> acquired;
+    while (auto slot = slots->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 100500);
+}
+
+TEST(ConcurrencyControl, Fifo)
+{
+    ConcurrencyControlTest t(1); // use single slot
+    std::vector<ConcurrencyControl::AllocationPtr> allocations;
+    constexpr int count = 42;
+    allocations.reserve(count);
+    for (int i = 0; i < count; i++)
+        allocations.emplace_back(t.cc.allocate(0, 1));
+    for (int i = 0; i < count; i++)
+    {
+        ConcurrencyControl::SlotPtr holder;
+        for (int j = 0; j < count; j++)
+        {
+            auto slot = allocations[j]->tryAcquire();
+            if (i == j) // check fifo order of allocations
+            {
+                ASSERT_TRUE(slot);
+                holder = std::move(slot);
+            }
+            else
+                ASSERT_TRUE(!slot);
+        }
+        holder.reset(); // release slot -- leads to the next allocation
+    }
+}
+
+TEST(ConcurrencyControl, Oversubscription)
+{
+    ConcurrencyControlTest t(10);
+    std::vector<ConcurrencyControl::AllocationPtr> allocations;
+    allocations.reserve(10);
+    for (int i = 0; i < 10; i++)
+        allocations.emplace_back(t.cc.allocate(1, 2));
+    std::vector<ConcurrencyControl::SlotPtr> slots;
+    // Normal allocation using maximum amount of slots
+    for (int i = 0; i < 5; i++)
+    {
+        auto slot1 = allocations[i]->tryAcquire();
+        ASSERT_TRUE(slot1);
+        slots.emplace_back(std::move(slot1));
+        auto slot2 = allocations[i]->tryAcquire();
+        ASSERT_TRUE(slot2);
+        slots.emplace_back(std::move(slot2));
+        ASSERT_TRUE(!allocations[i]->tryAcquire());
+    }
+    // Oversubscription: only minimum amount of slots are allocated
+    for (int i = 5; i < 10; i++)
+    {
+        auto slot1 = allocations[i]->tryAcquire();
+        ASSERT_TRUE(slot1);
+        slots.emplace_back(std::move(slot1));
+        ASSERT_TRUE(!allocations[i]->tryAcquire());
+    }
+}
+
+TEST(ConcurrencyControl, ReleaseUnacquiredSlots)
+{
+    ConcurrencyControlTest t(10);
+    {
+        std::vector<ConcurrencyControl::AllocationPtr> allocations;
+        allocations.reserve(10);
+        for (int i = 0; i < 10; i++)
+            allocations.emplace_back(t.cc.allocate(1, 2));
+        // Do not acquire - just destroy allocations with granted slots
+    }
+    // Check that slots were actually released
+    auto allocation = t.cc.allocate(0, 20);
+    std::vector<ConcurrencyControl::SlotPtr> acquired;
+    while (auto slot = allocation->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 10);
+}
+
+TEST(ConcurrencyControl, DestroyNotFullyAllocatedAllocation)
+{
+    ConcurrencyControlTest t(10);
+    for (int i = 0; i < 3; i++)
+    {
+        auto allocation = t.cc.allocate(5, 20);
+        std::vector<ConcurrencyControl::SlotPtr> acquired;
+        while (auto slot = allocation->tryAcquire())
+            acquired.emplace_back(std::move(slot));
+        ASSERT_TRUE(acquired.size() == 10);
+    }
+}
+
+TEST(ConcurrencyControl, DestroyAllocationBeforeSlots)
+{
+    ConcurrencyControlTest t(10);
+    for (int i = 0; i < 3; i++)
+    {
+        std::vector<ConcurrencyControl::SlotPtr> acquired;
+        auto allocation = t.cc.allocate(5, 20);
+        while (auto slot = allocation->tryAcquire())
+            acquired.emplace_back(std::move(slot));
+        ASSERT_TRUE(acquired.size() == 10);
+        allocation.reset(); // slots are still acquired (they should actually hold allocation)
+    }
+}
+
+TEST(ConcurrencyControl, GrantReleasedToTheSameAllocation)
+{
+    ConcurrencyControlTest t(3);
+    auto allocation = t.cc.allocate(0, 10);
+    std::list<ConcurrencyControl::SlotPtr> acquired;
+    while (auto slot = allocation->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 3); // 0 1 2
+    acquired.clear();
+    while (auto slot = allocation->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 3); // 3 4 5
+    acquired.pop_back();
+    while (auto slot = allocation->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 3); // 3 4 6
+    acquired.pop_front();
+    while (auto slot = allocation->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 3); // 4 6 7
+    acquired.clear();
+    while (auto slot = allocation->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 2); // 8 9
+}
+
+TEST(ConcurrencyControl, FairGranting)
+{
+    ConcurrencyControlTest t(3);
+    auto start_busy_period = t.cc.allocate(3, 3);
+    auto a1 = t.cc.allocate(0, 10);
+    auto a2 = t.cc.allocate(0, 10);
+    auto a3 = t.cc.allocate(0, 10);
+    start_busy_period.reset();
+    for (int i = 0; i < 10; i++)
+    {
+        auto s1 = a1->tryAcquire();
+        ASSERT_TRUE(s1);
+        ASSERT_TRUE(!a1->tryAcquire());
+        auto s2 = a2->tryAcquire();
+        ASSERT_TRUE(s2);
+        ASSERT_TRUE(!a2->tryAcquire());
+        auto s3 = a3->tryAcquire();
+        ASSERT_TRUE(s3);
+        ASSERT_TRUE(!a3->tryAcquire());
+    }
+}
+
+TEST(ConcurrencyControl, SetSlotCount)
+{
+    ConcurrencyControlTest t(10);
+    auto allocation = t.cc.allocate(5, 30);
+    std::vector<ConcurrencyControl::SlotPtr> acquired;
+    while (auto slot = allocation->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 10);
+
+    t.cc.setMaxConcurrency(15);
+    while (auto slot = allocation->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 15);
+
+    t.cc.setMaxConcurrency(5);
+    acquired.clear();
+    while (auto slot = allocation->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 5);
+
+    // Check that newly added slots are equally distributed over waiting allocations
+    std::vector<ConcurrencyControl::SlotPtr> acquired2;
+    auto allocation2 = t.cc.allocate(0, 30);
+    ASSERT_TRUE(!allocation->tryAcquire());
+    t.cc.setMaxConcurrency(15); // 10 slots added: 5 to the first allocation and 5 to the second one
+    while (auto slot = allocation->tryAcquire())
+        acquired.emplace_back(std::move(slot));
+    while (auto slot = allocation2->tryAcquire())
+        acquired2.emplace_back(std::move(slot));
+    ASSERT_TRUE(acquired.size() == 10);
+    ASSERT_TRUE(acquired2.size() == 5);
+}
+
+TEST(ConcurrencyControl, MultipleThreads)
+{
+    constexpr int cfg_total_queries = 1000; // total amount of queries to run
+    constexpr int cfg_work_us = 49; // max microseconds per single work
+    constexpr int cfg_concurrent_queries = 8; // do not run more than specified number of concurrent queries
+    constexpr int cfg_max_threads = 4; // max amount of threads a query is allowed to have
+    constexpr int cfg_max_concurrency = 16; // concurrency control limit (must be >3)
+
+    ConcurrencyControlTest t(cfg_max_concurrency);
+
+    auto run_query = [&] (size_t max_threads)
+    {
+        ConcurrencyControl::AllocationPtr slots = t.cc.allocate(1, max_threads);
+        std::mutex threads_mutex;
+        std::vector<std::thread> threads;
+        threads.reserve(max_threads);
+
+        std::function<void()> spawn_threads = [&] ()
+        {
+            while (auto slot = slots->tryAcquire())
+            {
+                std::unique_lock lock{threads_mutex};
+                threads.emplace_back([&, slot = std::move(slot)]
+                {
+                    pcg64 rng(randomSeed());
+                    std::uniform_int_distribution<size_t> distribution(1, cfg_work_us);
+                    size_t steps = distribution(rng);
+                    for (size_t step = 0; step < steps; step++)
+                    {
+                        sleepForMicroseconds(distribution(rng)); // emulate work
+                        spawn_threads(); // upscale
+                    }
+                });
+            }
+        };
+
+        spawn_threads();
+
+        // graceful shutdown of a query
+        for (size_t thread_num = 0; ; thread_num++)
+        {
+            std::unique_lock lock{threads_mutex};
+            if (thread_num >= threads.size())
+                break;
+            if (threads[thread_num].joinable())
+            {
+                auto & thread = threads[thread_num];
+                lock.unlock(); // to avoid deadlock if thread we are going to join starts spawning threads
+                thread.join();
+            }
+        }
+        // NOTE: No races: all concurrent spawn_threads() calls are done from `threads`, but they're already joined.
+    };
+
+    pcg64 rng(randomSeed());
+    std::uniform_int_distribution<size_t> max_threads_distribution(1, cfg_max_threads);
+    std::vector<std::thread> queries;
+    std::atomic<int> started = 0; // queries started in total
+    std::atomic<int> finished = 0; // queries finished in total
+    while (started < cfg_total_queries)
+    {
+        while (started < finished + cfg_concurrent_queries)
+        {
+            queries.emplace_back([&, max_threads = max_threads_distribution(rng)]
+            {
+                run_query(max_threads);
+                finished++;
+            });
+            started++;
+        }
+        sleepForMicroseconds(5); // wait some queries to finish
+        t.cc.setMaxConcurrency(cfg_max_concurrency - started % 3); // emulate configuration updates
+    }
+
+    for (auto & query : queries)
+        query.join();
+}
diff --git a/tests/integration/test_concurrent_threads_soft_limit/__init__.py b/tests/integration/test_concurrent_threads_soft_limit/__init__.py
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tests/integration/test_concurrent_threads_soft_limit/configs/config_default.xml b/tests/integration/test_concurrent_threads_soft_limit/configs/config_default.xml
new file mode 100644
index 000000000000..6c1f8f33de10
--- /dev/null
+++ b/tests/integration/test_concurrent_threads_soft_limit/configs/config_default.xml
@@ -0,0 +1,7 @@
+<?xml version="1.0"?>
+<clickhouse>
+    <query_log>
+      <database>system</database>
+      <table>query_log</table>
+    </query_log>
+</clickhouse>
diff --git a/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_1.xml b/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_1.xml
new file mode 100644
index 000000000000..026563ecd536
--- /dev/null
+++ b/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_1.xml
@@ -0,0 +1,8 @@
+<?xml version="1.0"?>
+<clickhouse>
+    <concurrent_threads_soft_limit>1</concurrent_threads_soft_limit>
+    <query_log>
+      <database>system</database>
+      <table>query_log</table>
+    </query_log>
+</clickhouse>
diff --git a/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_50.xml b/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_50.xml
new file mode 100644
index 000000000000..55f1bf32bf64
--- /dev/null
+++ b/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_50.xml
@@ -0,0 +1,8 @@
+<?xml version="1.0"?>
+<clickhouse>
+    <concurrent_threads_soft_limit>50</concurrent_threads_soft_limit>
+    <query_log>
+      <database>system</database>
+      <table>query_log</table>
+    </query_log>
+</clickhouse>
diff --git a/tests/integration/test_concurrent_threads_soft_limit/configs/config_limit_reached.xml b/tests/integration/test_concurrent_threads_soft_limit/configs/config_limit_reached.xml
new file mode 100644
index 000000000000..c7d86765212c
--- /dev/null
+++ b/tests/integration/test_concurrent_threads_soft_limit/configs/config_limit_reached.xml
@@ -0,0 +1,8 @@
+<?xml version="1.0"?>
+<clickhouse>
+    <concurrent_threads_soft_limit>10</concurrent_threads_soft_limit>
+    <query_log>
+      <database>system</database>
+      <table>query_log</table>
+    </query_log>
+</clickhouse>
diff --git a/tests/integration/test_concurrent_threads_soft_limit/configs/users.xml b/tests/integration/test_concurrent_threads_soft_limit/configs/users.xml
new file mode 100644
index 000000000000..63fefbb803b3
--- /dev/null
+++ b/tests/integration/test_concurrent_threads_soft_limit/configs/users.xml
@@ -0,0 +1,23 @@
+<?xml version="1.0"?>
+<clickhouse>
+    <profiles>
+        <default>
+            <log_queries>1</log_queries>
+            <max_threads>100</max_threads>
+        </default>
+    </profiles>
+    <users>
+        <default>
+            <password></password>
+            <networks incl="networks" replace="replace">
+                <ip>::/0</ip>
+            </networks>
+            <profile>default</profile>
+            <quota>default</quota>
+        </default>
+    </users>
+    <quotas>
+        <default>
+        </default>
+    </quotas>
+</clickhouse>
diff --git a/tests/integration/test_concurrent_threads_soft_limit/test.py b/tests/integration/test_concurrent_threads_soft_limit/test.py
new file mode 100644
index 000000000000..2f76f44ddc29
--- /dev/null
+++ b/tests/integration/test_concurrent_threads_soft_limit/test.py
@@ -0,0 +1,126 @@
+import pytest
+from helpers.cluster import ClickHouseCluster
+
+import threading
+import time
+from helpers.client import QueryRuntimeException
+
+cluster = ClickHouseCluster(__file__)
+node1 = cluster.add_instance(
+    "node1",
+    main_configs=["configs/config_default.xml"],
+    user_configs=["configs/users.xml"],
+)
+node2 = cluster.add_instance(
+    "node2",
+    main_configs=["configs/config_defined_50.xml"],
+    user_configs=["configs/users.xml"],
+)
+node3 = cluster.add_instance(
+    "node3",
+    main_configs=["configs/config_defined_1.xml"],
+    user_configs=["configs/users.xml"],
+)
+node4 = cluster.add_instance(
+    "node4",
+    main_configs=["configs/config_limit_reached.xml"],
+    user_configs=["configs/users.xml"],
+)
+
+
+@pytest.fixture(scope="module")
+def started_cluster():
+    try:
+        cluster.start()
+        yield cluster
+    finally:
+        cluster.shutdown()
+
+
+def test_concurrent_threads_soft_limit_default(started_cluster):
+    node1.query(
+        "SELECT count(*) FROM numbers_mt(10000000)",
+        query_id="test_concurrent_threads_soft_limit_1",
+    )
+    node1.query("SYSTEM FLUSH LOGS")
+    assert (
+        node1.query(
+            "select length(thread_ids) from system.query_log where current_database = currentDatabase() and type = 'QueryFinish' and query_id = 'test_concurrent_threads_soft_limit_1'"
+        )
+        == "102
"
+    )
+
+
+def test_concurrent_threads_soft_limit_defined_50(started_cluster):
+    node2.query(
+        "SELECT count(*) FROM numbers_mt(10000000)",
+        query_id="test_concurrent_threads_soft_limit_2",
+    )
+    node2.query("SYSTEM FLUSH LOGS")
+    assert (
+        node2.query(
+            "select length(thread_ids) from system.query_log where current_database = currentDatabase() and type = 'QueryFinish' and query_id = 'test_concurrent_threads_soft_limit_2'"
+        )
+        == "52
"
+    )
+
+
+def test_concurrent_threads_soft_limit_defined_1(started_cluster):
+    node3.query(
+        "SELECT count(*) FROM numbers_mt(10000000)",
+        query_id="test_concurrent_threads_soft_limit_3",
+    )
+    node3.query("SYSTEM FLUSH LOGS")
+    assert (
+        node3.query(
+            "select length(thread_ids) from system.query_log where current_database = currentDatabase() and type = 'QueryFinish' and query_id = 'test_concurrent_threads_soft_limit_3'"
+        )
+        == "3
"
+    )
+
+
+# In config_limit_reached.xml there is concurrent_threads_soft_limit=10
+# Background query starts in a separate thread to reach this limit.
+# When this limit is reached the foreground query gets less than 5 queries despite the fact that it has settings max_threads=5
+def test_concurrent_threads_soft_limit_limit_reached(started_cluster):
+    def background_query():
+        try:
+            node4.query(
+                "SELECT count(*) FROM numbers_mt(1e11) settings max_threads=100",
+                query_id="background_query",
+            )
+        except QueryRuntimeException:
+            pass
+
+    background_thread = threading.Thread(target=background_query)
+    background_thread.start()
+
+    def limit_reached():
+        s_count = node4.query(
+            "SELECT sum(length(thread_ids)) FROM system.processes"
+        ).strip()
+        if s_count:
+            count = int(s_count)
+        else:
+            count = 0
+        return count >= 10
+
+    while not limit_reached():
+        time.sleep(0.1)
+
+    node4.query(
+        "SELECT count(*) FROM numbers_mt(10000000) settings max_threads=5",
+        query_id="test_concurrent_threads_soft_limit_4",
+    )
+
+    node4.query("SYSTEM FLUSH LOGS")
+    s_count = node4.query(
+        "select length(thread_ids) from system.query_log where current_database = currentDatabase() and type = 'QueryFinish' and query_id = 'test_concurrent_threads_soft_limit_4'"
+    ).strip()
+    if s_count:
+        count = int(s_count)
+    else:
+        count = 0
+    assert count < 5
+    node4.query("KILL QUERY WHERE query_id = 'background_query' SYNC")
+    background_thread.join()
