{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 37285,
  "instance_id": "ClickHouse__ClickHouse-37285",
  "issue_numbers": [
    "36551"
  ],
  "base_commit": "499818751ef56e7b53bd36ad33fea884b7eb6cea",
  "patch": "diff --git a/docs/en/operations/server-configuration-parameters/settings.md b/docs/en/operations/server-configuration-parameters/settings.md\nindex d3a50969a392..1714251ac929 100644\n--- a/docs/en/operations/server-configuration-parameters/settings.md\n+++ b/docs/en/operations/server-configuration-parameters/settings.md\n@@ -197,7 +197,7 @@ Default value: `480` (8 minute).\n \n Parameter of a task that cleans up garbage from `store/` directory.\n If some subdirectory is not used by clickhouse-server and this directory was not modified for last\n-`database_catalog_unused_dir_hide_timeout_sec` seconds, the task will \"hide\" this directory by \n+`database_catalog_unused_dir_hide_timeout_sec` seconds, the task will \"hide\" this directory by\n removing all access rights. It also works for directories that clickhouse-server does not\n expect to see inside `store/`. Zero means \"immediately\".\n \n@@ -206,10 +206,10 @@ Default value: `3600` (1 hour).\n ## database_catalog_unused_dir_rm_timeout_sec {#database_catalog_unused_dir_rm_timeout_sec}\n \n Parameter of a task that cleans up garbage from `store/` directory.\n-If some subdirectory is not used by clickhouse-server and it was previousely \"hidden\" \n-(see [database_catalog_unused_dir_hide_timeout_sec](../../operations/server-configuration-parameters/settings.md#database_catalog_unused_dir_hide_timeout_sec)) \n+If some subdirectory is not used by clickhouse-server and it was previousely \"hidden\"\n+(see [database_catalog_unused_dir_hide_timeout_sec](../../operations/server-configuration-parameters/settings.md#database_catalog_unused_dir_hide_timeout_sec))\n and this directory was not modified for last\n-`database_catalog_unused_dir_rm_timeout_sec` seconds, the task will remove this directory. \n+`database_catalog_unused_dir_rm_timeout_sec` seconds, the task will remove this directory.\n It also works for directories that clickhouse-server does not\n expect to see inside `store/`. Zero means \"never\".\n \n@@ -731,6 +731,16 @@ On hosts with low RAM and swap, you possibly need setting `max_server_memory_usa\n \n -   [max_server_memory_usage](#max_server_memory_usage)\n \n+## concurrent_threads_soft_limit {#concurrent_threads_soft_limit}\n+The maximum number of query processing threads, excluding threads for retrieving data from remote servers, allowed to run all queries. This is not a hard limit. In case if the limit is reached the query will still get one thread to run.\n+\n+Possible values:\n+-   Positive integer.\n+-   0 \u2014 No limit.\n+-   -1 \u2014 The parameter is initialized by number of logical cores multiplies by 3. Which is a good heuristic for CPU-bound tasks.\n+\n+Default value: `0`.\n+\n ## max_concurrent_queries {#max-concurrent-queries}\n \n The maximum number of simultaneously processed queries.\ndiff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex 621c40c31bf7..9effc23e1076 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -29,6 +29,7 @@\n #include <Common/ClickHouseRevision.h>\n #include <Common/DNSResolver.h>\n #include <Common/CurrentMetrics.h>\n+#include <Common/ConcurrencyControl.h>\n #include <Common/Macros.h>\n #include <Common/ShellCommand.h>\n #include <Common/StringUtils/StringUtils.h>\n@@ -1124,6 +1125,23 @@ int Server::main(const std::vector<std::string> & /*args*/)\n             if (config->has(\"max_partition_size_to_drop\"))\n                 global_context->setMaxPartitionSizeToDrop(config->getUInt64(\"max_partition_size_to_drop\"));\n \n+            if (config->has(\"concurrent_threads_soft_limit\"))\n+            {\n+                auto concurrent_threads_soft_limit = config->getInt(\"concurrent_threads_soft_limit\", 0);\n+                if (concurrent_threads_soft_limit == -1)\n+                {\n+                    // Based on tests concurrent_threads_soft_limit has an optimal value when it's about 3 times of logical CPU cores\n+                    constexpr size_t thread_factor = 3;\n+                    concurrent_threads_soft_limit = std::thread::hardware_concurrency() * thread_factor;\n+                }\n+                if (concurrent_threads_soft_limit)\n+                    ConcurrencyControl::instance().setMaxConcurrency(concurrent_threads_soft_limit);\n+                else\n+                    ConcurrencyControl::instance().setMaxConcurrency(ConcurrencyControl::Unlimited);\n+            }\n+            else\n+                ConcurrencyControl::instance().setMaxConcurrency(ConcurrencyControl::Unlimited);\n+\n             if (config->has(\"max_concurrent_queries\"))\n                 global_context->getProcessList().setMaxSize(config->getInt(\"max_concurrent_queries\", 0));\n \ndiff --git a/programs/server/config.xml b/programs/server/config.xml\nindex 40e561c18806..849302303974 100644\n--- a/programs/server/config.xml\n+++ b/programs/server/config.xml\n@@ -269,6 +269,13 @@\n     <http_server_default_response><![CDATA[<html ng-app=\"SMI2\"><head><base href=\"http://ui.tabix.io/\"></head><body><div ui-view=\"\" class=\"content-ui\"></div><script src=\"http://loader.tabix.io/master.js\"></script></body></html>]]></http_server_default_response>\n     -->\n \n+    <!-- Maximum number of query processing threads to run all queries.\n+         Note that This is not a hard limit. In case if the limit is reached the query will still get one thread to run.\n+         For value equals to -1 this parameter is initialized by number of logical cores multiplies by 3.\n+         Which is a good heuristic for CPU-bound tasks.\n+    -->\n+    <concurrent_threads_soft_limit>0</concurrent_threads_soft_limit>\n+\n     <!-- Maximum number of concurrent queries. -->\n     <max_concurrent_queries>100</max_concurrent_queries>\n \n@@ -604,7 +611,7 @@\n              if this setting is true the user B will see all rows, and if this setting is false the user B will see no rows.\n              By default this setting is false for compatibility with earlier access configurations. -->\n         <users_without_row_policies_can_read_rows>false</users_without_row_policies_can_read_rows>\n-        \n+\n         <!-- By default, for backward compatibility ON CLUSTER queries ignore CLUSTER grant,\n              however you can change this behaviour by setting this to true -->\n         <on_cluster_queries_require_cluster_grant>false</on_cluster_queries_require_cluster_grant>\ndiff --git a/src/Common/ConcurrencyControl.h b/src/Common/ConcurrencyControl.h\nnew file mode 100644\nindex 000000000000..6f37bb45c849\n--- /dev/null\n+++ b/src/Common/ConcurrencyControl.h\n@@ -0,0 +1,266 @@\n+#pragma once\n+\n+#include <base/types.h>\n+#include <boost/core/noncopyable.hpp>\n+#include <mutex>\n+#include <memory>\n+#include <list>\n+#include <condition_variable>\n+\n+#include <Common/Exception.h>\n+\n+namespace DB\n+{\n+namespace ErrorCodes\n+{\n+    extern const int LOGICAL_ERROR;\n+}\n+}\n+\n+/*\n+ * Controls how many threads can be allocated for a query (or another activity).\n+ * There is a limited amount of slots for threads. It can be set with `setMaxConcurrency(limit)`.\n+ *\n+ * Lifecycle of a slot: free -> granted -> acquired -> free.\n+ * free: slot is available to be allocated by any query.\n+ * granted: slot is allocated by specific query, but not yet acquired by any thread.\n+ * acquired: slot is allocated by specific query and acquired by a thread.\n+ *\n+ * USAGE:\n+ *   1. Create an allocation for a query:\n+ *      `auto slots = ConcurrencyControl::instance().allocate(min, max);`\n+ *      It will allocate at least `min` and at most `max` slots.\n+ *      Note that `min` slots are granted immediately, but other `max - min` may be granted later.\n+ *   2. For every thread a slot has to be acquired from that allocation:\n+ *      `while (auto slot = slots->tryAcquire()) createYourThread([slot = std::move(slot)] { ... });`\n+ *      This snippet can be used at query startup and for upscaling later.\n+ * (both functions are non-blocking)\n+ *\n+ * Released slots are distributed between waiting allocations in a round-robin manner to provide fairness.\n+ * Oversubscription is possible: total amount of allocated slots can exceed `setMaxConcurrency(limit)`\n+ * because `min` amount of slots is allocated for each query unconditionally.\n+ */\n+class ConcurrencyControl : boost::noncopyable\n+{\n+public:\n+    struct Allocation;\n+    using AllocationPtr = std::shared_ptr<Allocation>;\n+    using SlotCount = UInt64;\n+    using Waiters = std::list<Allocation *>;\n+\n+    static constexpr SlotCount Unlimited = std::numeric_limits<SlotCount>::max();\n+\n+    // Scoped guard for acquired slot, see Allocation::tryAcquire()\n+    struct Slot : boost::noncopyable\n+    {\n+        ~Slot()\n+        {\n+            allocation->release();\n+        }\n+\n+    private:\n+        friend struct Allocation; // for ctor\n+\n+        explicit Slot(AllocationPtr && allocation_)\n+            : allocation(std::move(allocation_))\n+        {}\n+\n+        AllocationPtr allocation;\n+    };\n+\n+    // FIXME: have to be unique_ptr, but ThreadFromGlobalPool does not support move semantics yet\n+    using SlotPtr = std::shared_ptr<Slot>;\n+\n+    // Manages group of slots for a single query, see ConcurrencyControl::allocate(min, max)\n+    struct Allocation : std::enable_shared_from_this<Allocation>, boost::noncopyable\n+    {\n+        ~Allocation()\n+        {\n+            // We have to lock parent's mutex to avoid race with grant()\n+            // NOTE: shortcut can be added, but it requires Allocation::mutex lock even to check if shortcut is possible\n+            parent.free(this);\n+        }\n+\n+        // Take one already granted slot if available. Lock-free iff there is no granted slot.\n+        [[nodiscard]] SlotPtr tryAcquire()\n+        {\n+            SlotCount value = granted.load();\n+            while (value)\n+            {\n+                if (granted.compare_exchange_strong(value, value - 1))\n+                {\n+                    std::unique_lock lock{mutex};\n+                    return SlotPtr(new Slot(shared_from_this())); // can't use std::make_shared due to private ctor\n+                }\n+            }\n+            return {}; // avoid unnecessary locking\n+        }\n+\n+        SlotCount grantedCount() const\n+        {\n+            return granted;\n+        }\n+\n+    private:\n+        friend struct Slot; // for release()\n+        friend class ConcurrencyControl; // for grant(), free() and ctor\n+\n+        Allocation(ConcurrencyControl & parent_, SlotCount limit_, SlotCount granted_, Waiters::iterator waiter_ = {})\n+            : parent(parent_)\n+            , limit(limit_)\n+            , allocated(granted_)\n+            , granted(granted_)\n+            , waiter(waiter_)\n+        {\n+            if (allocated < limit)\n+                *waiter = this;\n+        }\n+\n+        auto cancel()\n+        {\n+            std::unique_lock lock{mutex};\n+            return std::pair{allocated - released,\n+                allocated < limit ?\n+                    std::optional<Waiters::iterator>(waiter) :\n+                    std::optional<Waiters::iterator>()};\n+        }\n+\n+        // Grant single slot to allocation, returns true iff more slot(s) are required\n+        bool grant()\n+        {\n+            std::unique_lock lock{mutex};\n+            granted++;\n+            allocated++;\n+            return allocated < limit;\n+        }\n+\n+        // Release one slot and grant it to other allocation if required\n+        void release()\n+        {\n+            parent.release(1);\n+            std::unique_lock lock{mutex};\n+            released++;\n+            if (released > allocated)\n+                abort();\n+        }\n+\n+        ConcurrencyControl & parent;\n+        const SlotCount limit;\n+\n+        std::mutex mutex; // the following values must be accessed under this mutex\n+        SlotCount allocated; // allocated total (including already `released`)\n+        SlotCount released = 0;\n+\n+        std::atomic<SlotCount> granted; // allocated, but not yet acquired\n+\n+        const Waiters::iterator waiter; // iterator to itself in Waiters list; valid iff allocated < limit\n+    };\n+\n+public:\n+    ConcurrencyControl()\n+        : cur_waiter(waiters.end())\n+    {}\n+\n+    // WARNING: all Allocation objects MUST be destructed before ConcurrencyControl\n+    // NOTE: Recommended way to achieve this is to use `instance()` and do graceful shutdown of queries\n+    ~ConcurrencyControl()\n+    {\n+        if (!waiters.empty())\n+            abort();\n+    }\n+\n+    // Allocate at least `min` and at most `max` slots.\n+    // If not all `max` slots were successfully allocated, a subscription for later allocation is created\n+    // Use `Allocation::tryAcquire()` to acquire allocated slot, before running a thread.\n+    [[nodiscard]] AllocationPtr allocate(SlotCount min, SlotCount max)\n+    {\n+        if (min > max)\n+            throw DB::Exception(\"ConcurrencyControl: invalid allocation requirements\", DB::ErrorCodes::LOGICAL_ERROR);\n+\n+        std::unique_lock lock{mutex};\n+\n+        // Acquire as much slots as we can, but not lower than `min`\n+        SlotCount granted = std::max(min, std::min(max, available(lock)));\n+        cur_concurrency += granted;\n+\n+        // Create allocation and start waiting if more slots are required\n+        if (granted < max)\n+            return AllocationPtr(new Allocation(*this, max, granted,\n+                waiters.insert(cur_waiter, nullptr /* pointer is set by Allocation ctor */)));\n+        else\n+            return AllocationPtr(new Allocation(*this, max, granted));\n+    }\n+\n+    void setMaxConcurrency(SlotCount value)\n+    {\n+        std::unique_lock lock{mutex};\n+        max_concurrency = std::max<SlotCount>(1, value); // never allow max_concurrency to be zero\n+        schedule(lock);\n+    }\n+\n+    static ConcurrencyControl & instance()\n+    {\n+        static ConcurrencyControl result;\n+        return result;\n+    }\n+\n+private:\n+    friend struct Allocation; // for free() and release()\n+\n+    void free(Allocation * allocation)\n+    {\n+        // Allocation is allowed to be canceled even if there are:\n+        //  - `amount`: granted slots (acquired slots are not possible, because Slot holds AllocationPtr)\n+        //  - `waiter`: active waiting for more slots to be allocated\n+        // Thus Allocation destruction may require the following lock, to avoid race conditions\n+        std::unique_lock lock{mutex};\n+        auto [amount, waiter] = allocation->cancel();\n+\n+        cur_concurrency -= amount;\n+        if (waiter)\n+        {\n+            if (cur_waiter == *waiter)\n+                cur_waiter = waiters.erase(*waiter);\n+            else\n+                waiters.erase(*waiter);\n+        }\n+        schedule(lock);\n+    }\n+\n+    void release(SlotCount amount)\n+    {\n+        std::unique_lock lock{mutex};\n+        cur_concurrency -= amount;\n+        schedule(lock);\n+    }\n+\n+    // Round-robin scheduling of available slots among waiting allocations\n+    void schedule(std::unique_lock<std::mutex> &)\n+    {\n+        while (cur_concurrency < max_concurrency && !waiters.empty())\n+        {\n+            cur_concurrency++;\n+            if (cur_waiter == waiters.end())\n+                cur_waiter = waiters.begin();\n+            Allocation * allocation = *cur_waiter;\n+            if (allocation->grant())\n+                ++cur_waiter;\n+            else\n+                cur_waiter = waiters.erase(cur_waiter); // last required slot has just been granted -- stop waiting\n+        }\n+    }\n+\n+    SlotCount available(std::unique_lock<std::mutex> &)\n+    {\n+        if (cur_concurrency < max_concurrency)\n+            return max_concurrency - cur_concurrency;\n+        else\n+            return 0;\n+    }\n+\n+    std::mutex mutex;\n+    Waiters waiters;\n+    Waiters::iterator cur_waiter; // round-robin pointer\n+    SlotCount max_concurrency = Unlimited;\n+    SlotCount cur_concurrency = 0;\n+};\ndiff --git a/src/Processors/Executors/ExecutorTasks.cpp b/src/Processors/Executors/ExecutorTasks.cpp\nindex 824b4e962d2c..d5c2bfe73992 100644\n--- a/src/Processors/Executors/ExecutorTasks.cpp\n+++ b/src/Processors/Executors/ExecutorTasks.cpp\n@@ -32,7 +32,7 @@ void ExecutorTasks::tryWakeUpAnyOtherThreadWithTasks(ExecutionThreadContext & se\n {\n     if (!task_queue.empty() && !threads_queue.empty() && !finished)\n     {\n-        size_t next_thread = self.thread_number + 1 == num_threads ? 0 : (self.thread_number + 1);\n+        size_t next_thread = self.thread_number + 1 >= use_threads ? 0 : (self.thread_number + 1);\n         auto thread_to_wake = task_queue.getAnyThreadWithTasks(next_thread);\n \n         if (threads_queue.has(thread_to_wake))\n@@ -40,6 +40,9 @@ void ExecutorTasks::tryWakeUpAnyOtherThreadWithTasks(ExecutionThreadContext & se\n         else\n             thread_to_wake = threads_queue.popAny();\n \n+        if (thread_to_wake >= use_threads)\n+            throw Exception(\"Non-empty queue without allocated thread\", ErrorCodes::LOGICAL_ERROR);\n+\n         lock.unlock();\n         executor_contexts[thread_to_wake]->wakeUp();\n     }\n@@ -50,6 +53,7 @@ void ExecutorTasks::tryGetTask(ExecutionThreadContext & context)\n     {\n         std::unique_lock lock(mutex);\n \n+        /// Try get async task assigned to this thread or any other task from queue.\n         if (auto * async_task = context.tryPopAsyncTask())\n         {\n             context.setTask(async_task);\n@@ -58,13 +62,18 @@ void ExecutorTasks::tryGetTask(ExecutionThreadContext & context)\n         else if (!task_queue.empty())\n             context.setTask(task_queue.pop(context.thread_number));\n \n+        /// Task found.\n         if (context.hasTask())\n         {\n+            /// We have to wake up at least one thread if there are pending tasks.\n+            /// That thread will wake up other threads during its `tryGetTask()` call if any.\n             tryWakeUpAnyOtherThreadWithTasks(context, lock);\n             return;\n         }\n \n-        if (threads_queue.size() + 1 == num_threads && async_task_queue.empty() && num_waiting_async_tasks == 0)\n+        /// This thread has no tasks to do and is going to wait.\n+        /// Finish execution if this was the last active thread.\n+        if (threads_queue.size() + 1 == use_threads && async_task_queue.empty() && num_waiting_async_tasks == 0)\n         {\n             lock.unlock();\n             finish();\n@@ -88,6 +97,7 @@ void ExecutorTasks::tryGetTask(ExecutionThreadContext & context)\n         }\n     #endif\n \n+        /// Enqueue thread into stack of waiting threads.\n         threads_queue.push(context.thread_number);\n     }\n \n@@ -124,13 +134,15 @@ void ExecutorTasks::pushTasks(Queue & queue, Queue & async_queue, ExecutionThrea\n             queue.pop();\n         }\n \n+        /// Wake up at least one thread that will wake up other threads if required\n         tryWakeUpAnyOtherThreadWithTasks(context, lock);\n     }\n }\n \n-void ExecutorTasks::init(size_t num_threads_, bool profile_processors, bool trace_processors, ReadProgressCallback * callback)\n+void ExecutorTasks::init(size_t num_threads_, size_t use_threads_, bool profile_processors, bool trace_processors, ReadProgressCallback * callback)\n {\n     num_threads = num_threads_;\n+    use_threads = use_threads_;\n     threads_queue.init(num_threads);\n     task_queue.init(num_threads);\n \n@@ -154,11 +166,21 @@ void ExecutorTasks::fill(Queue & queue)\n         queue.pop();\n \n         ++next_thread;\n-        if (next_thread >= num_threads)\n+\n+        /// It is important to keep queues empty for threads that are not started yet.\n+        /// Otherwise that thread can be selected by `tryWakeUpAnyOtherThreadWithTasks()`, leading to deadlock.\n+        if (next_thread >= use_threads)\n             next_thread = 0;\n     }\n }\n \n+void ExecutorTasks::upscale(size_t use_threads_)\n+{\n+    std::lock_guard lock(mutex);\n+    if (use_threads < use_threads_)\n+        use_threads = use_threads_;\n+}\n+\n void ExecutorTasks::processAsyncTasks()\n {\n #if defined(OS_LINUX)\ndiff --git a/src/Processors/Executors/ExecutorTasks.h b/src/Processors/Executors/ExecutorTasks.h\nindex 668470e7b11d..d35f8de94d15 100644\n--- a/src/Processors/Executors/ExecutorTasks.h\n+++ b/src/Processors/Executors/ExecutorTasks.h\n@@ -32,8 +32,12 @@ class ExecutorTasks\n     /// For single thread, will wait for async tasks only when task_queue is empty.\n     PollingQueue async_task_queue;\n \n+    /// Maximum amount of threads. Constant after initialization, based on `max_threads` setting.\n     size_t num_threads = 0;\n \n+    /// Started thread count (allocated by `ConcurrencyControl`). Can increase during execution up to `num_threads`.\n+    size_t use_threads = 0;\n+\n     /// This is the total number of waited async tasks which are not executed yet.\n     /// sum(executor_contexts[i].async_tasks.size())\n     size_t num_waiting_async_tasks = 0;\n@@ -54,8 +58,9 @@ class ExecutorTasks\n     void tryGetTask(ExecutionThreadContext & context);\n     void pushTasks(Queue & queue, Queue & async_queue, ExecutionThreadContext & context);\n \n-    void init(size_t num_threads_, bool profile_processors, bool trace_processors, ReadProgressCallback * callback);\n+    void init(size_t num_threads_, size_t use_threads_, bool profile_processors, bool trace_processors, ReadProgressCallback * callback);\n     void fill(Queue & queue);\n+    void upscale(size_t use_threads_);\n \n     void processAsyncTasks();\n \ndiff --git a/src/Processors/Executors/PipelineExecutor.cpp b/src/Processors/Executors/PipelineExecutor.cpp\nindex 68225d73ff1e..ae20d97604bf 100644\n--- a/src/Processors/Executors/PipelineExecutor.cpp\n+++ b/src/Processors/Executors/PipelineExecutor.cpp\n@@ -1,4 +1,3 @@\n-#include <queue>\n #include <IO/WriteBufferFromString.h>\n #include <Common/CurrentThread.h>\n #include <Common/setThreadName.h>\n@@ -114,6 +113,11 @@ bool PipelineExecutor::executeStep(std::atomic_bool * yield_flag)\n     {\n         initializeExecution(1);\n \n+        // Acquire slot until we are done\n+        single_thread_slot = slots->tryAcquire();\n+        if (!single_thread_slot)\n+            abort(); // Unable to allocate slot for the first thread, but we just allocated at least one slot\n+\n         if (yield_flag && *yield_flag)\n             return true;\n     }\n@@ -128,6 +132,7 @@ bool PipelineExecutor::executeStep(std::atomic_bool * yield_flag)\n         if (node->exception)\n             std::rethrow_exception(node->exception);\n \n+    single_thread_slot.reset();\n     finalizeExecution();\n \n     return false;\n@@ -205,7 +210,6 @@ void PipelineExecutor::executeStepImpl(size_t thread_num, std::atomic_bool * yie\n     Stopwatch total_time_watch;\n #endif\n \n-    // auto & node = tasks.getNode(thread_num);\n     auto & context = tasks.getThreadContext(thread_num);\n     bool yield = false;\n \n@@ -251,6 +255,9 @@ void PipelineExecutor::executeStepImpl(size_t thread_num, std::atomic_bool * yie\n             context.processing_time_ns += processing_time_watch.elapsed();\n #endif\n \n+            /// Upscale if possible.\n+            spawnThreads();\n+\n             /// We have executed single processor. Check if we need to yield execution.\n             if (yield_flag && *yield_flag)\n                 yield = true;\n@@ -267,70 +274,98 @@ void PipelineExecutor::initializeExecution(size_t num_threads)\n {\n     is_execution_initialized = true;\n \n+    /// Allocate CPU slots from concurrency control\n+    constexpr size_t min_threads = 1;\n+    slots = ConcurrencyControl::instance().allocate(min_threads, num_threads);\n+    size_t use_threads = slots->grantedCount();\n+\n     Queue queue;\n     graph->initializeExecution(queue);\n \n-    tasks.init(num_threads, profile_processors, trace_processors, read_progress_callback.get());\n+    tasks.init(num_threads, use_threads, profile_processors, trace_processors, read_progress_callback.get());\n     tasks.fill(queue);\n+\n+    std::unique_lock lock{threads_mutex};\n+    threads.reserve(num_threads);\n+}\n+\n+void PipelineExecutor::spawnThreads()\n+{\n+    while (auto slot = slots->tryAcquire())\n+    {\n+        std::unique_lock lock{threads_mutex};\n+        size_t thread_num = threads.size();\n+\n+        /// Count of threads in use should be updated for proper finish() condition.\n+        /// NOTE: this will not decrease `use_threads` below initially granted count\n+        tasks.upscale(thread_num + 1);\n+\n+        /// Start new thread\n+        threads.emplace_back([this, thread_num, thread_group = CurrentThread::getGroup(), slot = std::move(slot)]\n+        {\n+            /// ThreadStatus thread_status;\n+\n+            setThreadName(\"QueryPipelineEx\");\n+\n+            if (thread_group)\n+                CurrentThread::attachTo(thread_group);\n+\n+            try\n+            {\n+                executeSingleThread(thread_num);\n+            }\n+            catch (...)\n+            {\n+                /// In case of exception from executor itself, stop other threads.\n+                finish();\n+                tasks.getThreadContext(thread_num).setException(std::current_exception());\n+            }\n+        });\n+    }\n+}\n+\n+void PipelineExecutor::joinThreads()\n+{\n+    for (size_t thread_num = 0; ; thread_num++)\n+    {\n+        std::unique_lock lock{threads_mutex};\n+        if (thread_num >= threads.size())\n+            break;\n+        if (threads[thread_num].joinable())\n+        {\n+            auto & thread = threads[thread_num];\n+            lock.unlock(); // to avoid deadlock if thread we are going to join starts spawning threads\n+            thread.join();\n+        }\n+    }\n+    // NOTE: No races: all concurrent spawnThreads() calls are done from `threads`, but they're already joined.\n }\n \n void PipelineExecutor::executeImpl(size_t num_threads)\n {\n     initializeExecution(num_threads);\n \n-    using ThreadsData = std::vector<ThreadFromGlobalPool>;\n-    ThreadsData threads;\n-    threads.reserve(num_threads);\n-\n     bool finished_flag = false;\n \n     SCOPE_EXIT_SAFE(\n         if (!finished_flag)\n         {\n             finish();\n-\n-            for (auto & thread : threads)\n-                if (thread.joinable())\n-                    thread.join();\n+            joinThreads();\n         }\n     );\n \n     if (num_threads > 1)\n     {\n-        auto thread_group = CurrentThread::getGroup();\n-\n-        for (size_t i = 0; i < num_threads; ++i)\n-        {\n-            threads.emplace_back([this, thread_group, thread_num = i]\n-            {\n-                /// ThreadStatus thread_status;\n-\n-                setThreadName(\"QueryPipelineEx\");\n-\n-                if (thread_group)\n-                    CurrentThread::attachTo(thread_group);\n-\n-                try\n-                {\n-                    executeSingleThread(thread_num);\n-                }\n-                catch (...)\n-                {\n-                    /// In case of exception from executor itself, stop other threads.\n-                    finish();\n-                    tasks.getThreadContext(thread_num).setException(std::current_exception());\n-                }\n-            });\n-        }\n-\n+        spawnThreads(); // start at least one thread\n         tasks.processAsyncTasks();\n-\n-        for (auto & thread : threads)\n-            if (thread.joinable())\n-                thread.join();\n+        joinThreads();\n     }\n     else\n+    {\n+        auto slot = slots->tryAcquire();\n         executeSingleThread(0);\n+    }\n \n     finished_flag = true;\n }\ndiff --git a/src/Processors/Executors/PipelineExecutor.h b/src/Processors/Executors/PipelineExecutor.h\nindex c4d11ef688d9..cea64d309faa 100644\n--- a/src/Processors/Executors/PipelineExecutor.h\n+++ b/src/Processors/Executors/PipelineExecutor.h\n@@ -4,9 +4,10 @@\n #include <Processors/Executors/ExecutorTasks.h>\n #include <Common/EventCounter.h>\n #include <Common/logger_useful.h>\n+#include <Common/ThreadPool.h>\n+#include <Common/ConcurrencyControl.h>\n \n #include <queue>\n-#include <stack>\n #include <mutex>\n \n namespace DB\n@@ -59,7 +60,12 @@ class PipelineExecutor\n     ExecutingGraphPtr graph;\n \n     ExecutorTasks tasks;\n-    using Stack = std::stack<UInt64>;\n+\n+    // Concurrency control related\n+    ConcurrencyControl::AllocationPtr slots;\n+    ConcurrencyControl::SlotPtr single_thread_slot; // slot for single-thread mode to work using executeStep()\n+    std::mutex threads_mutex;\n+    std::vector<ThreadFromGlobalPool> threads;\n \n     /// Flag that checks that initializeExecution was called.\n     bool is_execution_initialized = false;\n@@ -81,6 +87,8 @@ class PipelineExecutor\n \n     void initializeExecution(size_t num_threads); /// Initialize executor contexts and task_queue.\n     void finalizeExecution(); /// Check all processors are finished.\n+    void spawnThreads();\n+    void joinThreads();\n \n     /// Methods connected to execution.\n     void executeImpl(size_t num_threads);\n",
  "test_patch": "diff --git a/src/Common/tests/gtest_concurrency_control.cpp b/src/Common/tests/gtest_concurrency_control.cpp\nnew file mode 100644\nindex 000000000000..2ffb16511f34\n--- /dev/null\n+++ b/src/Common/tests/gtest_concurrency_control.cpp\n@@ -0,0 +1,289 @@\n+#include <gtest/gtest.h>\n+\n+#include <vector>\n+#include <thread>\n+#include <pcg_random.hpp>\n+\n+#include <base/types.h>\n+#include <base/sleep.h>\n+#include <Common/ConcurrencyControl.h>\n+#include <Common/randomSeed.h>\n+\n+struct ConcurrencyControlTest\n+{\n+    ConcurrencyControl cc;\n+\n+    explicit ConcurrencyControlTest(ConcurrencyControl::SlotCount limit = ConcurrencyControl::Unlimited)\n+    {\n+        cc.setMaxConcurrency(limit);\n+    }\n+};\n+\n+TEST(ConcurrencyControl, Unlimited)\n+{\n+    ConcurrencyControlTest t; // unlimited number of slots\n+    auto slots = t.cc.allocate(0, 100500);\n+    std::vector<ConcurrencyControl::SlotPtr> acquired;\n+    while (auto slot = slots->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 100500);\n+}\n+\n+TEST(ConcurrencyControl, Fifo)\n+{\n+    ConcurrencyControlTest t(1); // use single slot\n+    std::vector<ConcurrencyControl::AllocationPtr> allocations;\n+    constexpr int count = 42;\n+    allocations.reserve(count);\n+    for (int i = 0; i < count; i++)\n+        allocations.emplace_back(t.cc.allocate(0, 1));\n+    for (int i = 0; i < count; i++)\n+    {\n+        ConcurrencyControl::SlotPtr holder;\n+        for (int j = 0; j < count; j++)\n+        {\n+            auto slot = allocations[j]->tryAcquire();\n+            if (i == j) // check fifo order of allocations\n+            {\n+                ASSERT_TRUE(slot);\n+                holder = std::move(slot);\n+            }\n+            else\n+                ASSERT_TRUE(!slot);\n+        }\n+        holder.reset(); // release slot -- leads to the next allocation\n+    }\n+}\n+\n+TEST(ConcurrencyControl, Oversubscription)\n+{\n+    ConcurrencyControlTest t(10);\n+    std::vector<ConcurrencyControl::AllocationPtr> allocations;\n+    allocations.reserve(10);\n+    for (int i = 0; i < 10; i++)\n+        allocations.emplace_back(t.cc.allocate(1, 2));\n+    std::vector<ConcurrencyControl::SlotPtr> slots;\n+    // Normal allocation using maximum amount of slots\n+    for (int i = 0; i < 5; i++)\n+    {\n+        auto slot1 = allocations[i]->tryAcquire();\n+        ASSERT_TRUE(slot1);\n+        slots.emplace_back(std::move(slot1));\n+        auto slot2 = allocations[i]->tryAcquire();\n+        ASSERT_TRUE(slot2);\n+        slots.emplace_back(std::move(slot2));\n+        ASSERT_TRUE(!allocations[i]->tryAcquire());\n+    }\n+    // Oversubscription: only minimum amount of slots are allocated\n+    for (int i = 5; i < 10; i++)\n+    {\n+        auto slot1 = allocations[i]->tryAcquire();\n+        ASSERT_TRUE(slot1);\n+        slots.emplace_back(std::move(slot1));\n+        ASSERT_TRUE(!allocations[i]->tryAcquire());\n+    }\n+}\n+\n+TEST(ConcurrencyControl, ReleaseUnacquiredSlots)\n+{\n+    ConcurrencyControlTest t(10);\n+    {\n+        std::vector<ConcurrencyControl::AllocationPtr> allocations;\n+        allocations.reserve(10);\n+        for (int i = 0; i < 10; i++)\n+            allocations.emplace_back(t.cc.allocate(1, 2));\n+        // Do not acquire - just destroy allocations with granted slots\n+    }\n+    // Check that slots were actually released\n+    auto allocation = t.cc.allocate(0, 20);\n+    std::vector<ConcurrencyControl::SlotPtr> acquired;\n+    while (auto slot = allocation->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 10);\n+}\n+\n+TEST(ConcurrencyControl, DestroyNotFullyAllocatedAllocation)\n+{\n+    ConcurrencyControlTest t(10);\n+    for (int i = 0; i < 3; i++)\n+    {\n+        auto allocation = t.cc.allocate(5, 20);\n+        std::vector<ConcurrencyControl::SlotPtr> acquired;\n+        while (auto slot = allocation->tryAcquire())\n+            acquired.emplace_back(std::move(slot));\n+        ASSERT_TRUE(acquired.size() == 10);\n+    }\n+}\n+\n+TEST(ConcurrencyControl, DestroyAllocationBeforeSlots)\n+{\n+    ConcurrencyControlTest t(10);\n+    for (int i = 0; i < 3; i++)\n+    {\n+        std::vector<ConcurrencyControl::SlotPtr> acquired;\n+        auto allocation = t.cc.allocate(5, 20);\n+        while (auto slot = allocation->tryAcquire())\n+            acquired.emplace_back(std::move(slot));\n+        ASSERT_TRUE(acquired.size() == 10);\n+        allocation.reset(); // slots are still acquired (they should actually hold allocation)\n+    }\n+}\n+\n+TEST(ConcurrencyControl, GrantReleasedToTheSameAllocation)\n+{\n+    ConcurrencyControlTest t(3);\n+    auto allocation = t.cc.allocate(0, 10);\n+    std::list<ConcurrencyControl::SlotPtr> acquired;\n+    while (auto slot = allocation->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 3); // 0 1 2\n+    acquired.clear();\n+    while (auto slot = allocation->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 3); // 3 4 5\n+    acquired.pop_back();\n+    while (auto slot = allocation->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 3); // 3 4 6\n+    acquired.pop_front();\n+    while (auto slot = allocation->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 3); // 4 6 7\n+    acquired.clear();\n+    while (auto slot = allocation->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 2); // 8 9\n+}\n+\n+TEST(ConcurrencyControl, FairGranting)\n+{\n+    ConcurrencyControlTest t(3);\n+    auto start_busy_period = t.cc.allocate(3, 3);\n+    auto a1 = t.cc.allocate(0, 10);\n+    auto a2 = t.cc.allocate(0, 10);\n+    auto a3 = t.cc.allocate(0, 10);\n+    start_busy_period.reset();\n+    for (int i = 0; i < 10; i++)\n+    {\n+        auto s1 = a1->tryAcquire();\n+        ASSERT_TRUE(s1);\n+        ASSERT_TRUE(!a1->tryAcquire());\n+        auto s2 = a2->tryAcquire();\n+        ASSERT_TRUE(s2);\n+        ASSERT_TRUE(!a2->tryAcquire());\n+        auto s3 = a3->tryAcquire();\n+        ASSERT_TRUE(s3);\n+        ASSERT_TRUE(!a3->tryAcquire());\n+    }\n+}\n+\n+TEST(ConcurrencyControl, SetSlotCount)\n+{\n+    ConcurrencyControlTest t(10);\n+    auto allocation = t.cc.allocate(5, 30);\n+    std::vector<ConcurrencyControl::SlotPtr> acquired;\n+    while (auto slot = allocation->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 10);\n+\n+    t.cc.setMaxConcurrency(15);\n+    while (auto slot = allocation->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 15);\n+\n+    t.cc.setMaxConcurrency(5);\n+    acquired.clear();\n+    while (auto slot = allocation->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 5);\n+\n+    // Check that newly added slots are equally distributed over waiting allocations\n+    std::vector<ConcurrencyControl::SlotPtr> acquired2;\n+    auto allocation2 = t.cc.allocate(0, 30);\n+    ASSERT_TRUE(!allocation->tryAcquire());\n+    t.cc.setMaxConcurrency(15); // 10 slots added: 5 to the first allocation and 5 to the second one\n+    while (auto slot = allocation->tryAcquire())\n+        acquired.emplace_back(std::move(slot));\n+    while (auto slot = allocation2->tryAcquire())\n+        acquired2.emplace_back(std::move(slot));\n+    ASSERT_TRUE(acquired.size() == 10);\n+    ASSERT_TRUE(acquired2.size() == 5);\n+}\n+\n+TEST(ConcurrencyControl, MultipleThreads)\n+{\n+    constexpr int cfg_total_queries = 1000; // total amount of queries to run\n+    constexpr int cfg_work_us = 49; // max microseconds per single work\n+    constexpr int cfg_concurrent_queries = 8; // do not run more than specified number of concurrent queries\n+    constexpr int cfg_max_threads = 4; // max amount of threads a query is allowed to have\n+    constexpr int cfg_max_concurrency = 16; // concurrency control limit (must be >3)\n+\n+    ConcurrencyControlTest t(cfg_max_concurrency);\n+\n+    auto run_query = [&] (size_t max_threads)\n+    {\n+        ConcurrencyControl::AllocationPtr slots = t.cc.allocate(1, max_threads);\n+        std::mutex threads_mutex;\n+        std::vector<std::thread> threads;\n+        threads.reserve(max_threads);\n+\n+        std::function<void()> spawn_threads = [&] ()\n+        {\n+            while (auto slot = slots->tryAcquire())\n+            {\n+                std::unique_lock lock{threads_mutex};\n+                threads.emplace_back([&, slot = std::move(slot)]\n+                {\n+                    pcg64 rng(randomSeed());\n+                    std::uniform_int_distribution<size_t> distribution(1, cfg_work_us);\n+                    size_t steps = distribution(rng);\n+                    for (size_t step = 0; step < steps; step++)\n+                    {\n+                        sleepForMicroseconds(distribution(rng)); // emulate work\n+                        spawn_threads(); // upscale\n+                    }\n+                });\n+            }\n+        };\n+\n+        spawn_threads();\n+\n+        // graceful shutdown of a query\n+        for (size_t thread_num = 0; ; thread_num++)\n+        {\n+            std::unique_lock lock{threads_mutex};\n+            if (thread_num >= threads.size())\n+                break;\n+            if (threads[thread_num].joinable())\n+            {\n+                auto & thread = threads[thread_num];\n+                lock.unlock(); // to avoid deadlock if thread we are going to join starts spawning threads\n+                thread.join();\n+            }\n+        }\n+        // NOTE: No races: all concurrent spawn_threads() calls are done from `threads`, but they're already joined.\n+    };\n+\n+    pcg64 rng(randomSeed());\n+    std::uniform_int_distribution<size_t> max_threads_distribution(1, cfg_max_threads);\n+    std::vector<std::thread> queries;\n+    std::atomic<int> started = 0; // queries started in total\n+    std::atomic<int> finished = 0; // queries finished in total\n+    while (started < cfg_total_queries)\n+    {\n+        while (started < finished + cfg_concurrent_queries)\n+        {\n+            queries.emplace_back([&, max_threads = max_threads_distribution(rng)]\n+            {\n+                run_query(max_threads);\n+                finished++;\n+            });\n+            started++;\n+        }\n+        sleepForMicroseconds(5); // wait some queries to finish\n+        t.cc.setMaxConcurrency(cfg_max_concurrency - started % 3); // emulate configuration updates\n+    }\n+\n+    for (auto & query : queries)\n+        query.join();\n+}\ndiff --git a/tests/integration/test_concurrent_threads_soft_limit/__init__.py b/tests/integration/test_concurrent_threads_soft_limit/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_concurrent_threads_soft_limit/configs/config_default.xml b/tests/integration/test_concurrent_threads_soft_limit/configs/config_default.xml\nnew file mode 100644\nindex 000000000000..6c1f8f33de10\n--- /dev/null\n+++ b/tests/integration/test_concurrent_threads_soft_limit/configs/config_default.xml\n@@ -0,0 +1,7 @@\n+<?xml version=\"1.0\"?>\n+<clickhouse>\n+    <query_log>\n+      <database>system</database>\n+      <table>query_log</table>\n+    </query_log>\n+</clickhouse>\ndiff --git a/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_1.xml b/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_1.xml\nnew file mode 100644\nindex 000000000000..026563ecd536\n--- /dev/null\n+++ b/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_1.xml\n@@ -0,0 +1,8 @@\n+<?xml version=\"1.0\"?>\n+<clickhouse>\n+    <concurrent_threads_soft_limit>1</concurrent_threads_soft_limit>\n+    <query_log>\n+      <database>system</database>\n+      <table>query_log</table>\n+    </query_log>\n+</clickhouse>\ndiff --git a/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_50.xml b/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_50.xml\nnew file mode 100644\nindex 000000000000..55f1bf32bf64\n--- /dev/null\n+++ b/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_50.xml\n@@ -0,0 +1,8 @@\n+<?xml version=\"1.0\"?>\n+<clickhouse>\n+    <concurrent_threads_soft_limit>50</concurrent_threads_soft_limit>\n+    <query_log>\n+      <database>system</database>\n+      <table>query_log</table>\n+    </query_log>\n+</clickhouse>\ndiff --git a/tests/integration/test_concurrent_threads_soft_limit/configs/config_limit_reached.xml b/tests/integration/test_concurrent_threads_soft_limit/configs/config_limit_reached.xml\nnew file mode 100644\nindex 000000000000..c7d86765212c\n--- /dev/null\n+++ b/tests/integration/test_concurrent_threads_soft_limit/configs/config_limit_reached.xml\n@@ -0,0 +1,8 @@\n+<?xml version=\"1.0\"?>\n+<clickhouse>\n+    <concurrent_threads_soft_limit>10</concurrent_threads_soft_limit>\n+    <query_log>\n+      <database>system</database>\n+      <table>query_log</table>\n+    </query_log>\n+</clickhouse>\ndiff --git a/tests/integration/test_concurrent_threads_soft_limit/configs/users.xml b/tests/integration/test_concurrent_threads_soft_limit/configs/users.xml\nnew file mode 100644\nindex 000000000000..63fefbb803b3\n--- /dev/null\n+++ b/tests/integration/test_concurrent_threads_soft_limit/configs/users.xml\n@@ -0,0 +1,23 @@\n+<?xml version=\"1.0\"?>\n+<clickhouse>\n+    <profiles>\n+        <default>\n+            <log_queries>1</log_queries>\n+            <max_threads>100</max_threads>\n+        </default>\n+    </profiles>\n+    <users>\n+        <default>\n+            <password></password>\n+            <networks incl=\"networks\" replace=\"replace\">\n+                <ip>::/0</ip>\n+            </networks>\n+            <profile>default</profile>\n+            <quota>default</quota>\n+        </default>\n+    </users>\n+    <quotas>\n+        <default>\n+        </default>\n+    </quotas>\n+</clickhouse>\ndiff --git a/tests/integration/test_concurrent_threads_soft_limit/test.py b/tests/integration/test_concurrent_threads_soft_limit/test.py\nnew file mode 100644\nindex 000000000000..2f76f44ddc29\n--- /dev/null\n+++ b/tests/integration/test_concurrent_threads_soft_limit/test.py\n@@ -0,0 +1,126 @@\n+import pytest\n+from helpers.cluster import ClickHouseCluster\n+\n+import threading\n+import time\n+from helpers.client import QueryRuntimeException\n+\n+cluster = ClickHouseCluster(__file__)\n+node1 = cluster.add_instance(\n+    \"node1\",\n+    main_configs=[\"configs/config_default.xml\"],\n+    user_configs=[\"configs/users.xml\"],\n+)\n+node2 = cluster.add_instance(\n+    \"node2\",\n+    main_configs=[\"configs/config_defined_50.xml\"],\n+    user_configs=[\"configs/users.xml\"],\n+)\n+node3 = cluster.add_instance(\n+    \"node3\",\n+    main_configs=[\"configs/config_defined_1.xml\"],\n+    user_configs=[\"configs/users.xml\"],\n+)\n+node4 = cluster.add_instance(\n+    \"node4\",\n+    main_configs=[\"configs/config_limit_reached.xml\"],\n+    user_configs=[\"configs/users.xml\"],\n+)\n+\n+\n+@pytest.fixture(scope=\"module\")\n+def started_cluster():\n+    try:\n+        cluster.start()\n+        yield cluster\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def test_concurrent_threads_soft_limit_default(started_cluster):\n+    node1.query(\n+        \"SELECT count(*) FROM numbers_mt(10000000)\",\n+        query_id=\"test_concurrent_threads_soft_limit_1\",\n+    )\n+    node1.query(\"SYSTEM FLUSH LOGS\")\n+    assert (\n+        node1.query(\n+            \"select length(thread_ids) from system.query_log where current_database = currentDatabase() and type = 'QueryFinish' and query_id = 'test_concurrent_threads_soft_limit_1'\"\n+        )\n+        == \"102\\n\"\n+    )\n+\n+\n+def test_concurrent_threads_soft_limit_defined_50(started_cluster):\n+    node2.query(\n+        \"SELECT count(*) FROM numbers_mt(10000000)\",\n+        query_id=\"test_concurrent_threads_soft_limit_2\",\n+    )\n+    node2.query(\"SYSTEM FLUSH LOGS\")\n+    assert (\n+        node2.query(\n+            \"select length(thread_ids) from system.query_log where current_database = currentDatabase() and type = 'QueryFinish' and query_id = 'test_concurrent_threads_soft_limit_2'\"\n+        )\n+        == \"52\\n\"\n+    )\n+\n+\n+def test_concurrent_threads_soft_limit_defined_1(started_cluster):\n+    node3.query(\n+        \"SELECT count(*) FROM numbers_mt(10000000)\",\n+        query_id=\"test_concurrent_threads_soft_limit_3\",\n+    )\n+    node3.query(\"SYSTEM FLUSH LOGS\")\n+    assert (\n+        node3.query(\n+            \"select length(thread_ids) from system.query_log where current_database = currentDatabase() and type = 'QueryFinish' and query_id = 'test_concurrent_threads_soft_limit_3'\"\n+        )\n+        == \"3\\n\"\n+    )\n+\n+\n+# In config_limit_reached.xml there is concurrent_threads_soft_limit=10\n+# Background query starts in a separate thread to reach this limit.\n+# When this limit is reached the foreground query gets less than 5 queries despite the fact that it has settings max_threads=5\n+def test_concurrent_threads_soft_limit_limit_reached(started_cluster):\n+    def background_query():\n+        try:\n+            node4.query(\n+                \"SELECT count(*) FROM numbers_mt(1e11) settings max_threads=100\",\n+                query_id=\"background_query\",\n+            )\n+        except QueryRuntimeException:\n+            pass\n+\n+    background_thread = threading.Thread(target=background_query)\n+    background_thread.start()\n+\n+    def limit_reached():\n+        s_count = node4.query(\n+            \"SELECT sum(length(thread_ids)) FROM system.processes\"\n+        ).strip()\n+        if s_count:\n+            count = int(s_count)\n+        else:\n+            count = 0\n+        return count >= 10\n+\n+    while not limit_reached():\n+        time.sleep(0.1)\n+\n+    node4.query(\n+        \"SELECT count(*) FROM numbers_mt(10000000) settings max_threads=5\",\n+        query_id=\"test_concurrent_threads_soft_limit_4\",\n+    )\n+\n+    node4.query(\"SYSTEM FLUSH LOGS\")\n+    s_count = node4.query(\n+        \"select length(thread_ids) from system.query_log where current_database = currentDatabase() and type = 'QueryFinish' and query_id = 'test_concurrent_threads_soft_limit_4'\"\n+    ).strip()\n+    if s_count:\n+        count = int(s_count)\n+    else:\n+        count = 0\n+    assert count < 5\n+    node4.query(\"KILL QUERY WHERE query_id = 'background_query' SYNC\")\n+    background_thread.join()\n",
  "problem_statement": "A new option to limit total number of running threads because too many threads used for query processing could significantly decrease server\u2019s performance\n**Use case**\r\n\r\nI had several situations when many clients connect to CH server and they send the many queries. There is max_threads parameter to manage how many threads are used to process a single query. In most cases it was possible to set small number like max_threads = 4 or 8 and to achieve a better server performance. I did many tests by using benchmark tool. In some cases I could achieve about 30% higher QPS by changing max_threads. The problem is that in real situation CH server receives in some cases complex queries requiring 70-100 threads to process each query and in other cases a client sends simple queries requiring 5-10 threads to process a query.\r\n\r\n**Describe the solution you'd like**\r\nThe problem could be solved by having a possibility to set total number of allowed to run in process list. So we need to have a possibility to limit total number of allowed threads. I am thinking about new configuration parameter named like max_threads_for_all_queries. I am planning to implement it\r\n\n",
  "hints_text": "",
  "created_at": "2022-05-17T10:16:57Z",
  "modified_files": [
    "docs/en/operations/server-configuration-parameters/settings.md",
    "programs/server/Server.cpp",
    "programs/server/config.xml",
    "b/src/Common/ConcurrencyControl.h",
    "src/Processors/Executors/ExecutorTasks.cpp",
    "src/Processors/Executors/ExecutorTasks.h",
    "src/Processors/Executors/PipelineExecutor.cpp",
    "src/Processors/Executors/PipelineExecutor.h"
  ],
  "modified_test_files": [
    "b/src/Common/tests/gtest_concurrency_control.cpp",
    "b/tests/integration/test_concurrent_threads_soft_limit/configs/config_default.xml",
    "b/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_1.xml",
    "b/tests/integration/test_concurrent_threads_soft_limit/configs/config_defined_50.xml",
    "b/tests/integration/test_concurrent_threads_soft_limit/configs/config_limit_reached.xml",
    "b/tests/integration/test_concurrent_threads_soft_limit/configs/users.xml",
    "b/tests/integration/test_concurrent_threads_soft_limit/test.py"
  ]
}