{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 67731,
  "instance_id": "ClickHouse__ClickHouse-67731",
  "issue_numbers": [
    "67730",
    "67731"
  ],
  "base_commit": "b97e5b54cae5f5b4332f67869b7e350941270b96",
  "patch": "diff --git a/src/Databases/DatabaseReplicated.cpp b/src/Databases/DatabaseReplicated.cpp\nindex d2dee9b5994d..f127ccbc224f 100644\n--- a/src/Databases/DatabaseReplicated.cpp\n+++ b/src/Databases/DatabaseReplicated.cpp\n@@ -12,7 +12,6 @@\n #include <Common/ZooKeeper/KeeperException.h>\n #include <Common/ZooKeeper/Types.h>\n #include <Common/ZooKeeper/ZooKeeper.h>\n-#include <Common/ZooKeeper/IKeeper.h>\n #include <Common/PoolId.h>\n #include <Core/ServerSettings.h>\n #include <Core/Settings.h>\n@@ -339,12 +338,9 @@ ClusterPtr DatabaseReplicated::getClusterImpl(bool all_groups) const\n     return std::make_shared<Cluster>(getContext()->getSettingsRef(), shards, params);\n }\n \n-ReplicasInfo DatabaseReplicated::tryGetReplicasInfo(const ClusterPtr & cluster_) const\n+std::vector<UInt8> DatabaseReplicated::tryGetAreReplicasActive(const ClusterPtr & cluster_) const\n {\n-    Strings paths_get, paths_exists;\n-\n-    paths_get.emplace_back(fs::path(zookeeper_path) / \"max_log_ptr\");\n-\n+    Strings paths;\n     const auto & addresses_with_failover = cluster_->getShardsAddresses();\n     const auto & shards_info = cluster_->getShardsInfo();\n     for (size_t shard_index = 0; shard_index < shards_info.size(); ++shard_index)\n@@ -352,59 +348,32 @@ ReplicasInfo DatabaseReplicated::tryGetReplicasInfo(const ClusterPtr & cluster_)\n         for (const auto & replica : addresses_with_failover[shard_index])\n         {\n             String full_name = getFullReplicaName(replica.database_shard_name, replica.database_replica_name);\n-            paths_exists.emplace_back(fs::path(zookeeper_path) / \"replicas\" / full_name / \"active\");\n-            paths_get.emplace_back(fs::path(zookeeper_path) / \"replicas\" / full_name / \"log_ptr\");\n+            paths.emplace_back(fs::path(zookeeper_path) / \"replicas\" / full_name / \"active\");\n         }\n     }\n \n     try\n     {\n         auto current_zookeeper = getZooKeeper();\n-        auto get_res = current_zookeeper->get(paths_get);\n-        auto exist_res = current_zookeeper->exists(paths_exists);\n-        chassert(get_res.size() == exist_res.size() + 1);\n-\n-        auto max_log_ptr_zk = get_res[0];\n-        if (max_log_ptr_zk.error != Coordination::Error::ZOK)\n-            throw Coordination::Exception(max_log_ptr_zk.error);\n-\n-        UInt32 max_log_ptr = parse<UInt32>(max_log_ptr_zk.data);\n-\n-        ReplicasInfo replicas_info;\n-        replicas_info.resize(exist_res.size());\n-\n-        size_t global_replica_index = 0;\n-        for (size_t shard_index = 0; shard_index < shards_info.size(); ++shard_index)\n-        {\n-            for (const auto & replica : addresses_with_failover[shard_index])\n-            {\n-                auto replica_active = exist_res[global_replica_index];\n-                auto replica_log_ptr = get_res[global_replica_index + 1];\n+        auto res = current_zookeeper->exists(paths);\n \n-                if (replica_active.error != Coordination::Error::ZOK && replica_active.error != Coordination::Error::ZNONODE)\n-                    throw Coordination::Exception(replica_active.error);\n+        std::vector<UInt8> statuses;\n+        statuses.resize(paths.size());\n \n-                if (replica_log_ptr.error != Coordination::Error::ZOK)\n-                    throw Coordination::Exception(replica_log_ptr.error);\n+        for (size_t i = 0; i < res.size(); ++i)\n+            if (res[i].error == Coordination::Error::ZOK)\n+                statuses[i] = 1;\n \n-                replicas_info[global_replica_index] = ReplicaInfo{\n-                    .is_active = replica_active.error == Coordination::Error::ZOK,\n-                    .replication_lag = max_log_ptr - parse<UInt32>(replica_log_ptr.data),\n-                    .recovery_time = replica.is_local ? ddl_worker->getCurrentInitializationDurationMs() : 0,\n-                };\n-\n-                ++global_replica_index;\n-            }\n-        }\n-\n-        return replicas_info;\n-    } catch (...)\n+        return statuses;\n+    }\n+    catch (...)\n     {\n         tryLogCurrentException(log);\n         return {};\n     }\n }\n \n+\n void DatabaseReplicated::fillClusterAuthInfo(String collection_name, const Poco::Util::AbstractConfiguration & config_ref)\n {\n     const auto & config_prefix = fmt::format(\"named_collections.{}\", collection_name);\ndiff --git a/src/Databases/DatabaseReplicated.h b/src/Databases/DatabaseReplicated.h\nindex 5a1570ae2e2f..27ab262d1f14 100644\n--- a/src/Databases/DatabaseReplicated.h\n+++ b/src/Databases/DatabaseReplicated.h\n@@ -17,14 +17,6 @@ using ZooKeeperPtr = std::shared_ptr<zkutil::ZooKeeper>;\n class Cluster;\n using ClusterPtr = std::shared_ptr<Cluster>;\n \n-struct ReplicaInfo\n-{\n-    bool is_active;\n-    UInt32 replication_lag;\n-    UInt64 recovery_time;\n-};\n-using ReplicasInfo = std::vector<ReplicaInfo>;\n-\n class DatabaseReplicated : public DatabaseAtomic\n {\n public:\n@@ -92,7 +84,7 @@ class DatabaseReplicated : public DatabaseAtomic\n \n     static void dropReplica(DatabaseReplicated * database, const String & database_zookeeper_path, const String & shard, const String & replica, bool throw_if_noop);\n \n-    ReplicasInfo tryGetReplicasInfo(const ClusterPtr & cluster_) const;\n+    std::vector<UInt8> tryGetAreReplicasActive(const ClusterPtr & cluster_) const;\n \n     void renameDatabase(ContextPtr query_context, const String & new_name) override;\n \ndiff --git a/src/Databases/DatabaseReplicatedWorker.cpp b/src/Databases/DatabaseReplicatedWorker.cpp\nindex 4e7408aa96ec..1ef88dc03bc2 100644\n--- a/src/Databases/DatabaseReplicatedWorker.cpp\n+++ b/src/Databases/DatabaseReplicatedWorker.cpp\n@@ -32,12 +32,6 @@ DatabaseReplicatedDDLWorker::DatabaseReplicatedDDLWorker(DatabaseReplicated * db\n \n bool DatabaseReplicatedDDLWorker::initializeMainThread()\n {\n-    {\n-        std::lock_guard lock(initialization_duration_timer_mutex);\n-        initialization_duration_timer.emplace();\n-        initialization_duration_timer->start();\n-    }\n-\n     while (!stop_flag)\n     {\n         try\n@@ -75,10 +69,6 @@ bool DatabaseReplicatedDDLWorker::initializeMainThread()\n \n             initializeReplication();\n             initialized = true;\n-            {\n-                std::lock_guard lock(initialization_duration_timer_mutex);\n-                initialization_duration_timer.reset();\n-            }\n             return true;\n         }\n         catch (...)\n@@ -88,11 +78,6 @@ bool DatabaseReplicatedDDLWorker::initializeMainThread()\n         }\n     }\n \n-    {\n-        std::lock_guard lock(initialization_duration_timer_mutex);\n-        initialization_duration_timer.reset();\n-    }\n-\n     return false;\n }\n \n@@ -474,10 +459,4 @@ UInt32 DatabaseReplicatedDDLWorker::getLogPointer() const\n     return max_id.load();\n }\n \n-UInt64 DatabaseReplicatedDDLWorker::getCurrentInitializationDurationMs() const\n-{\n-    std::lock_guard lock(initialization_duration_timer_mutex);\n-    return initialization_duration_timer ? initialization_duration_timer->elapsedMilliseconds() : 0;\n-}\n-\n }\ndiff --git a/src/Databases/DatabaseReplicatedWorker.h b/src/Databases/DatabaseReplicatedWorker.h\nindex 2309c8318394..41edf2221b8e 100644\n--- a/src/Databases/DatabaseReplicatedWorker.h\n+++ b/src/Databases/DatabaseReplicatedWorker.h\n@@ -36,8 +36,6 @@ class DatabaseReplicatedDDLWorker : public DDLWorker\n                                    DatabaseReplicated * const database, bool committed = false); /// NOLINT\n \n     UInt32 getLogPointer() const;\n-\n-    UInt64 getCurrentInitializationDurationMs() const;\n private:\n     bool initializeMainThread() override;\n     void initializeReplication();\n@@ -58,9 +56,6 @@ class DatabaseReplicatedDDLWorker : public DDLWorker\n     ZooKeeperPtr active_node_holder_zookeeper;\n     /// It will remove \"active\" node when database is detached\n     zkutil::EphemeralNodeHolderPtr active_node_holder;\n-\n-    std::optional<Stopwatch> initialization_duration_timer;\n-    mutable std::mutex initialization_duration_timer_mutex;\n };\n \n }\ndiff --git a/src/Storages/System/StorageSystemClusters.cpp b/src/Storages/System/StorageSystemClusters.cpp\nindex d03b600b6ef6..160c8d6270e4 100644\n--- a/src/Storages/System/StorageSystemClusters.cpp\n+++ b/src/Storages/System/StorageSystemClusters.cpp\n@@ -31,8 +31,6 @@ ColumnsDescription StorageSystemClusters::getColumnsDescription()\n         {\"database_shard_name\", std::make_shared<DataTypeString>(), \"The name of the `Replicated` database shard (for clusters that belong to a `Replicated` database).\"},\n         {\"database_replica_name\", std::make_shared<DataTypeString>(), \"The name of the `Replicated` database replica (for clusters that belong to a `Replicated` database).\"},\n         {\"is_active\", std::make_shared<DataTypeNullable>(std::make_shared<DataTypeUInt8>()), \"The status of the Replicated database replica (for clusters that belong to a Replicated database): 1 means 'replica is online', 0 means 'replica is offline', NULL means 'unknown'.\"},\n-        {\"replication_lag\", std::make_shared<DataTypeNullable>(std::make_shared<DataTypeUInt32>()), \"The replication lag of the `Replicated` database replica (for clusters that belong to a Replicated database).\"},\n-        {\"recovery_time\", std::make_shared<DataTypeNullable>(std::make_shared<DataTypeUInt64>()), \"The recovery time of the `Replicated` database replica (for clusters that belong to a Replicated database), in milliseconds.\"},\n     };\n \n     description.setAliases({\n@@ -48,30 +46,31 @@ void StorageSystemClusters::fillData(MutableColumns & res_columns, ContextPtr co\n         writeCluster(res_columns, name_and_cluster, {});\n \n     const auto databases = DatabaseCatalog::instance().getDatabases();\n-    for (const auto & [database_name, database] : databases)\n+    for (const auto & name_and_database : databases)\n     {\n-        if (const auto * replicated = typeid_cast<const DatabaseReplicated *>(database.get()))\n+        if (const auto * replicated = typeid_cast<const DatabaseReplicated *>(name_and_database.second.get()))\n         {\n+\n             if (auto database_cluster = replicated->tryGetCluster())\n-                writeCluster(res_columns, {database_name, database_cluster},\n-                             replicated->tryGetReplicasInfo(database_cluster));\n+                writeCluster(res_columns, {name_and_database.first, database_cluster},\n+                             replicated->tryGetAreReplicasActive(database_cluster));\n \n             if (auto database_cluster = replicated->tryGetAllGroupsCluster())\n-                writeCluster(res_columns, {DatabaseReplicated::ALL_GROUPS_CLUSTER_PREFIX + database_name, database_cluster},\n-                             replicated->tryGetReplicasInfo(database_cluster));\n+                writeCluster(res_columns, {DatabaseReplicated::ALL_GROUPS_CLUSTER_PREFIX + name_and_database.first, database_cluster},\n+                             replicated->tryGetAreReplicasActive(database_cluster));\n         }\n     }\n }\n \n void StorageSystemClusters::writeCluster(MutableColumns & res_columns, const NameAndCluster & name_and_cluster,\n-                                         const ReplicasInfo & replicas_info)\n+                                         const std::vector<UInt8> & is_active)\n {\n     const String & cluster_name = name_and_cluster.first;\n     const ClusterPtr & cluster = name_and_cluster.second;\n     const auto & shards_info = cluster->getShardsInfo();\n     const auto & addresses_with_failover = cluster->getShardsAddresses();\n \n-    size_t global_replica_idx = 0;\n+    size_t replica_idx = 0;\n     for (size_t shard_index = 0; shard_index < shards_info.size(); ++shard_index)\n     {\n         const auto & shard_info = shards_info[shard_index];\n@@ -100,24 +99,10 @@ void StorageSystemClusters::writeCluster(MutableColumns & res_columns, const Nam\n             res_columns[i++]->insert(pool_status[replica_index].estimated_recovery_time.count());\n             res_columns[i++]->insert(address.database_shard_name);\n             res_columns[i++]->insert(address.database_replica_name);\n-            if (replicas_info.empty())\n-            {\n-                res_columns[i++]->insertDefault();\n+            if (is_active.empty())\n                 res_columns[i++]->insertDefault();\n-                res_columns[i++]->insertDefault();\n-            }\n             else\n-            {\n-                const auto & replica_info = replicas_info[global_replica_idx];\n-                res_columns[i++]->insert(replica_info.is_active);\n-                res_columns[i++]->insert(replica_info.replication_lag);\n-                if (replica_info.recovery_time != 0)\n-                    res_columns[i++]->insert(replica_info.recovery_time);\n-                else\n-                    res_columns[i++]->insertDefault();\n-            }\n-\n-            ++global_replica_idx;\n+                res_columns[i++]->insert(is_active[replica_idx++]);\n         }\n     }\n }\ndiff --git a/src/Storages/System/StorageSystemClusters.h b/src/Storages/System/StorageSystemClusters.h\nindex f6e087348967..0f7c792261d8 100644\n--- a/src/Storages/System/StorageSystemClusters.h\n+++ b/src/Storages/System/StorageSystemClusters.h\n@@ -1,10 +1,10 @@\n #pragma once\n \n-#include <Databases/DatabaseReplicated.h>\n #include <DataTypes/DataTypeString.h>\n #include <DataTypes/DataTypesNumber.h>\n #include <Storages/System/IStorageSystemOneBlock.h>\n \n+\n namespace DB\n {\n \n@@ -27,7 +27,7 @@ class StorageSystemClusters final : public IStorageSystemOneBlock\n     using NameAndCluster = std::pair<String, std::shared_ptr<Cluster>>;\n \n     void fillData(MutableColumns & res_columns, ContextPtr context, const ActionsDAG::Node *, std::vector<UInt8>) const override;\n-    static void writeCluster(MutableColumns & res_columns, const NameAndCluster & name_and_cluster, const ReplicasInfo & replicas_info);\n+    static void writeCluster(MutableColumns & res_columns, const NameAndCluster & name_and_cluster, const std::vector<UInt8> & is_active);\n };\n \n }\n",
  "test_patch": "diff --git a/tests/integration/test_recovery_time_metric/__init__.py b/tests/integration/test_recovery_time_metric/__init__.py\ndeleted file mode 100644\nindex e69de29bb2d1..000000000000\ndiff --git a/tests/integration/test_recovery_time_metric/configs/config.xml b/tests/integration/test_recovery_time_metric/configs/config.xml\ndeleted file mode 100644\nindex bad9b1fa9eae..000000000000\n--- a/tests/integration/test_recovery_time_metric/configs/config.xml\n+++ /dev/null\n@@ -1,41 +0,0 @@\n-<clickhouse>\n-    <tcp_port>9000</tcp_port>\n-\n-    <profiles>\n-        <default>\n-        </default>\n-    </profiles>\n-\n-    <users>\n-        <default>\n-            <profile>default</profile>\n-            <no_password></no_password>\n-        </default>\n-    </users>\n-\n-    <keeper_server>\n-        <tcp_port>2181</tcp_port>\n-        <server_id>1</server_id>\n-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>\n-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>\n-        <coordination_settings>\n-            <session_timeout_ms>20000</session_timeout_ms>\n-        </coordination_settings>\n-        <raft_configuration>\n-            <server>\n-                <id>1</id>\n-                <hostname>localhost</hostname>\n-                <port>9444</port>\n-            </server>\n-        </raft_configuration>\n-    </keeper_server>\n-\n-    <zookeeper>\n-        <node index=\"1\">\n-            <host>localhost</host>\n-            <port>2181</port>\n-        </node>\n-        <session_timeout_ms>20000</session_timeout_ms>\n-    </zookeeper>\n-\n-</clickhouse>\ndiff --git a/tests/integration/test_recovery_time_metric/test.py b/tests/integration/test_recovery_time_metric/test.py\ndeleted file mode 100644\nindex 6fcf2fad423d..000000000000\n--- a/tests/integration/test_recovery_time_metric/test.py\n+++ /dev/null\n@@ -1,61 +0,0 @@\n-import pytest\n-from helpers.cluster import ClickHouseCluster\n-\n-cluster = ClickHouseCluster(__file__)\n-node = cluster.add_instance(\n-    \"node\",\n-    main_configs=[\"configs/config.xml\"],\n-    stay_alive=True,\n-)\n-\n-\n-@pytest.fixture(scope=\"module\")\n-def start_cluster():\n-    try:\n-        cluster.start()\n-        yield cluster\n-    finally:\n-        cluster.shutdown()\n-\n-\n-def test_recovery_time_metric(start_cluster):\n-    node.query(\n-        \"\"\"\n-        DROP DATABASE IF EXISTS rdb;\n-        CREATE DATABASE rdb\n-        ENGINE = Replicated('/test/test_recovery_time_metric', 'shard1', 'replica1')\n-        \"\"\"\n-    )\n-\n-    node.query(\n-        \"\"\"\n-        DROP TABLE IF EXISTS rdb.t;\n-        CREATE TABLE rdb.t\n-        (\n-            `x` UInt32\n-        )\n-        ENGINE = MergeTree\n-        ORDER BY x\n-        \"\"\"\n-    )\n-\n-    node.exec_in_container([\"bash\", \"-c\", \"rm /var/lib/clickhouse/metadata/rdb/t.sql\"])\n-\n-    node.restart_clickhouse()\n-\n-    ret = int(\n-        node.query(\n-            \"\"\"\n-            SELECT recovery_time\n-            FROM system.clusters\n-            WHERE cluster = 'rdb'\n-            \"\"\"\n-        ).strip()\n-    )\n-    assert ret > 0\n-\n-    node.query(\n-        \"\"\"\n-        DROP DATABASE rdb\n-        \"\"\"\n-    )\ndiff --git a/tests/queries/0_stateless/02117_show_create_table_system.reference b/tests/queries/0_stateless/02117_show_create_table_system.reference\nindex 32e8b2f43127..cfae4fee6c21 100644\n--- a/tests/queries/0_stateless/02117_show_create_table_system.reference\n+++ b/tests/queries/0_stateless/02117_show_create_table_system.reference\n@@ -52,8 +52,6 @@ CREATE TABLE system.clusters\n     `database_shard_name` String,\n     `database_replica_name` String,\n     `is_active` Nullable(UInt8),\n-    `replication_lag` Nullable(UInt32),\n-    `recovery_time` Nullable(UInt64),\n     `name` String ALIAS cluster\n )\n ENGINE = SystemClusters\ndiff --git a/tests/queries/0_stateless/03206_replication_lag_metric.reference b/tests/queries/0_stateless/03206_replication_lag_metric.reference\ndeleted file mode 100644\nindex 02f4a7264b1f..000000000000\n--- a/tests/queries/0_stateless/03206_replication_lag_metric.reference\n+++ /dev/null\n@@ -1,4 +0,0 @@\n-0\n-2\n-0\n-2\ndiff --git a/tests/queries/0_stateless/03206_replication_lag_metric.sql b/tests/queries/0_stateless/03206_replication_lag_metric.sql\ndeleted file mode 100644\nindex 998c332a11ce..000000000000\n--- a/tests/queries/0_stateless/03206_replication_lag_metric.sql\n+++ /dev/null\n@@ -1,11 +0,0 @@\n--- Tags: no-parallel\n-\n-CREATE DATABASE rdb1 ENGINE = Replicated('/test/test_replication_lag_metric', 'shard1', 'replica1');\n-CREATE DATABASE rdb2 ENGINE = Replicated('/test/test_replication_lag_metric', 'shard1', 'replica2');\n-\n-SET distributed_ddl_task_timeout = 0;\n-CREATE TABLE rdb1.t (id UInt32) ENGINE = ReplicatedMergeTree ORDER BY id;\n-SELECT replication_lag FROM system.clusters WHERE cluster IN ('rdb1', 'rdb2') ORDER BY cluster ASC, replica_num ASC;\n-\n-DROP DATABASE rdb1;\n-DROP DATABASE rdb2;\n",
  "problem_statement": "DatabaseReplicated: segmentation fault in SHOW CLUSTERS\nhttps://pastila.nl/?00209267/05ce6f4231cadb9daf09f8306a977243#sp3t4kduOj9xKsQU0PYv5w==\r\n\r\nhttps://s3.amazonaws.com/clickhouse-test-reports/67702/d3dcd21dc9b682c48e120126fef37a7112b70ced/stateless_tests__release__old_analyzer__s3__databasereplicated__[4_4].html\nRevert \"Add replication lag and recovery time metrics\"\nReverts ClickHouse/ClickHouse#66703\r\n\r\nCloses #67730\r\nCloses #67731\n",
  "hints_text": "\n",
  "created_at": "2024-08-03T16:41:45Z"
}