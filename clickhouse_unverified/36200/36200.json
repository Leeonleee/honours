{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 36200,
  "instance_id": "ClickHouse__ClickHouse-36200",
  "issue_numbers": [
    "35577"
  ],
  "base_commit": "151399b6a04ebbc8aa0b971f82d23eb5f6ed86f7",
  "patch": "diff --git a/src/Common/Macros.cpp b/src/Common/Macros.cpp\nindex f66e3462e825..ec5a863c0f54 100644\n--- a/src/Common/Macros.cpp\n+++ b/src/Common/Macros.cpp\n@@ -92,7 +92,7 @@ String Macros::expand(const String & s,\n             res += info.table_id.table_name;\n             info.expanded_table = true;\n         }\n-        else if (macro_name == \"uuid\")\n+        else if (macro_name == \"uuid\" && !info.expand_special_macros_only)\n         {\n             if (info.table_id.uuid == UUIDHelpers::Nil)\n                 throw Exception(\"Macro 'uuid' and empty arguments of ReplicatedMergeTree \"\n@@ -109,12 +109,12 @@ String Macros::expand(const String & s,\n         else if (info.shard && macro_name == \"shard\")\n         {\n             res += *info.shard;\n-            info.expanded_uuid = true;\n+            info.expanded_other = true;\n         }\n         else if (info.replica && macro_name == \"replica\")\n         {\n             res += *info.replica;\n-            info.expanded_uuid = true;\n+            info.expanded_other = true;\n         }\n         else if (info.ignore_unknown || info.expand_special_macros_only)\n         {\ndiff --git a/src/Databases/DatabaseAtomic.cpp b/src/Databases/DatabaseAtomic.cpp\nindex adfcd83f5a7a..0bd16a0e722f 100644\n--- a/src/Databases/DatabaseAtomic.cpp\n+++ b/src/Databases/DatabaseAtomic.cpp\n@@ -1,5 +1,6 @@\n #include <Databases/DatabaseAtomic.h>\n #include <Databases/DatabaseOnDisk.h>\n+#include <Databases/DatabaseReplicated.h>\n #include <IO/ReadHelpers.h>\n #include <IO/WriteHelpers.h>\n #include <IO/ReadBufferFromFile.h>\n@@ -151,11 +152,15 @@ void DatabaseAtomic::renameTable(ContextPtr local_context, const String & table_\n {\n     if (typeid(*this) != typeid(to_database))\n     {\n-        if (!typeid_cast<DatabaseOrdinary *>(&to_database))\n+        if (typeid_cast<DatabaseOrdinary *>(&to_database))\n+        {\n+            /// Allow moving tables between Atomic and Ordinary (with table lock)\n+            DatabaseOnDisk::renameTable(local_context, table_name, to_database, to_table_name, exchange, dictionary);\n+            return;\n+        }\n+\n+        if (!allowMoveTableToOtherDatabaseEngine(to_database))\n             throw Exception(\"Moving tables between databases of different engines is not supported\", ErrorCodes::NOT_IMPLEMENTED);\n-        /// Allow moving tables between Atomic and Ordinary (with table lock)\n-        DatabaseOnDisk::renameTable(local_context, table_name, to_database, to_table_name, exchange, dictionary);\n-        return;\n     }\n \n     if (exchange && !supportsRenameat2())\n@@ -230,15 +235,19 @@ void DatabaseAtomic::renameTable(ContextPtr local_context, const String & table_\n     if (dictionary && !table->isDictionary())\n         throw Exception(ErrorCodes::INCORRECT_QUERY, \"Use RENAME/EXCHANGE TABLE (instead of RENAME/EXCHANGE DICTIONARY) for tables\");\n \n-    table->checkTableCanBeRenamed();\n+    StorageID old_table_id = table->getStorageID();\n+    StorageID new_table_id = {other_db.database_name, to_table_name, old_table_id.uuid};\n+    table->checkTableCanBeRenamed({new_table_id});\n     assert_can_move_mat_view(table);\n     StoragePtr other_table;\n+    StorageID other_table_new_id = StorageID::createEmpty();\n     if (exchange)\n     {\n         other_table = other_db.getTableUnlocked(to_table_name, other_db_lock);\n         if (dictionary && !other_table->isDictionary())\n             throw Exception(ErrorCodes::INCORRECT_QUERY, \"Use RENAME/EXCHANGE TABLE (instead of RENAME/EXCHANGE DICTIONARY) for tables\");\n-        other_table->checkTableCanBeRenamed();\n+        other_table_new_id = {database_name, table_name, other_table->getStorageID().uuid};\n+        other_table->checkTableCanBeRenamed(other_table_new_id);\n         assert_can_move_mat_view(other_table);\n     }\n \n@@ -260,11 +269,9 @@ void DatabaseAtomic::renameTable(ContextPtr local_context, const String & table_\n     if (exchange)\n         other_table_data_path = detach(other_db, to_table_name, other_table->storesDataOnDisk());\n \n-    auto old_table_id = table->getStorageID();\n-\n-    table->renameInMemory({other_db.database_name, to_table_name, old_table_id.uuid});\n+    table->renameInMemory(new_table_id);\n     if (exchange)\n-        other_table->renameInMemory({database_name, table_name, other_table->getStorageID().uuid});\n+        other_table->renameInMemory(other_table_new_id);\n \n     if (!inside_database)\n     {\ndiff --git a/src/Databases/DatabaseAtomic.h b/src/Databases/DatabaseAtomic.h\nindex eae700d28c54..b748e53244dd 100644\n--- a/src/Databases/DatabaseAtomic.h\n+++ b/src/Databases/DatabaseAtomic.h\n@@ -63,7 +63,7 @@ class DatabaseAtomic : public DatabaseOrdinary\n \n     void waitDetachedTableNotInUse(const UUID & uuid) override;\n     void checkDetachedTableNotInUse(const UUID & uuid) override;\n-    void setDetachedTableNotInUseForce(const UUID & uuid);\n+    void setDetachedTableNotInUseForce(const UUID & uuid) override;\n \n protected:\n     void commitAlterTable(const StorageID & table_id, const String & table_metadata_tmp_path, const String & table_metadata_path, const String & statement, ContextPtr query_context) override;\n@@ -76,6 +76,8 @@ class DatabaseAtomic : public DatabaseOrdinary\n \n     void tryCreateMetadataSymlink();\n \n+    virtual bool allowMoveTableToOtherDatabaseEngine(IDatabase & /*to_database*/) const { return false; }\n+\n     //TODO store path in DatabaseWithOwnTables::tables\n     using NameToPathMap = std::unordered_map<String, String>;\n     NameToPathMap table_name_to_path;\ndiff --git a/src/Databases/DatabaseOnDisk.cpp b/src/Databases/DatabaseOnDisk.cpp\nindex f12009cef1ae..2b2d1e0ba2c8 100644\n--- a/src/Databases/DatabaseOnDisk.cpp\n+++ b/src/Databases/DatabaseOnDisk.cpp\n@@ -415,11 +415,13 @@ void DatabaseOnDisk::renameTable(\n     }\n     catch (const Exception &)\n     {\n+        setDetachedTableNotInUseForce(prev_uuid);\n         attachTable(local_context, table_name, table, table_data_relative_path);\n         throw;\n     }\n     catch (const Poco::Exception & e)\n     {\n+        setDetachedTableNotInUseForce(prev_uuid);\n         attachTable(local_context, table_name, table, table_data_relative_path);\n         /// Better diagnostics.\n         throw Exception{Exception::CreateFromPocoTag{}, e};\ndiff --git a/src/Databases/DatabaseOnDisk.h b/src/Databases/DatabaseOnDisk.h\nindex 64122ae66e52..a118c8da6782 100644\n--- a/src/Databases/DatabaseOnDisk.h\n+++ b/src/Databases/DatabaseOnDisk.h\n@@ -95,6 +95,7 @@ class DatabaseOnDisk : public DatabaseWithOwnTablesBase\n                                    const String & table_metadata_tmp_path, const String & table_metadata_path, ContextPtr query_context);\n \n     virtual void removeDetachedPermanentlyFlag(ContextPtr context, const String & table_name, const String & table_metadata_path, bool attach) const;\n+    virtual void setDetachedTableNotInUseForce(const UUID & /*uuid*/) {}\n \n     const String metadata_path;\n     const String data_path;\ndiff --git a/src/Databases/DatabaseReplicated.cpp b/src/Databases/DatabaseReplicated.cpp\nindex 2a07ba8375dd..7fea8699d595 100644\n--- a/src/Databases/DatabaseReplicated.cpp\n+++ b/src/Databases/DatabaseReplicated.cpp\n@@ -45,6 +45,7 @@ namespace ErrorCodes\n \n static constexpr const char * DROPPED_MARK = \"DROPPED\";\n static constexpr const char * BROKEN_TABLES_SUFFIX = \"_broken_tables\";\n+static constexpr const char * BROKEN_REPLICATED_TABLES_SUFFIX = \"_broken_replicated_tables\";\n \n \n zkutil::ZooKeeperPtr DatabaseReplicated::getZooKeeper() const\n@@ -410,6 +411,8 @@ void DatabaseReplicated::checkQueryValid(const ASTPtr & query, ContextPtr query_\n \n             Macros::MacroExpansionInfo info;\n             info.table_id = {getDatabaseName(), create->getTable(), create->uuid};\n+            info.shard = getShardName();\n+            info.replica = getReplicaName();\n             query_context->getMacros()->expand(maybe_path, info);\n             bool maybe_shard_macros = info.expanded_other;\n             info.expanded_other = false;\n@@ -505,6 +508,9 @@ static UUID getTableUUIDIfReplicated(const String & metadata, ContextPtr context\n \n void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeeper, UInt32 our_log_ptr, UInt32 max_log_ptr)\n {\n+    is_recovering = true;\n+    SCOPE_EXIT({ is_recovering = false; });\n+\n     /// Let's compare local (possibly outdated) metadata with (most actual) metadata stored in ZooKeeper\n     /// and try to update the set of local tables.\n     /// We could drop all local tables and create the new ones just like it's new replica.\n@@ -582,6 +588,7 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n \n     String db_name = getDatabaseName();\n     String to_db_name = getDatabaseName() + BROKEN_TABLES_SUFFIX;\n+    String to_db_name_replicated = getDatabaseName() + BROKEN_REPLICATED_TABLES_SUFFIX;\n     if (total_tables * db_settings.max_broken_tables_ratio < tables_to_detach.size())\n         throw Exception(ErrorCodes::DATABASE_REPLICATION_FAILED, \"Too many tables to recreate: {} of {}\", tables_to_detach.size(), total_tables);\n     else if (!tables_to_detach.empty())\n@@ -593,6 +600,13 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n         String query = fmt::format(\"CREATE DATABASE IF NOT EXISTS {} ENGINE=Ordinary\", backQuoteIfNeed(to_db_name));\n         auto query_context = Context::createCopy(getContext());\n         executeQuery(query, query_context, true);\n+\n+        /// But we want to avoid discarding UUID of ReplicatedMergeTree tables, because it will not work\n+        /// if zookeeper_path contains {uuid} macro. Replicated database do not recreate replicated tables on recovery,\n+        /// so it's ok to save UUID of replicated table.\n+        query = fmt::format(\"CREATE DATABASE IF NOT EXISTS {} ENGINE=Atomic\", backQuoteIfNeed(to_db_name_replicated));\n+        query_context = Context::createCopy(getContext());\n+        executeQuery(query, query_context, true);\n     }\n \n     size_t moved_tables = 0;\n@@ -607,6 +621,18 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n \n         auto table = tryGetTable(table_name, getContext());\n \n+        auto move_table_to_database = [&](const String & broken_table_name, const String & to_database_name)\n+        {\n+            /// Table probably stores some data. Let's move it to another database.\n+            String to_name = fmt::format(\"{}_{}_{}\", broken_table_name, max_log_ptr, thread_local_rng() % 1000);\n+            LOG_DEBUG(log, \"Will RENAME TABLE {} TO {}.{}\", backQuoteIfNeed(broken_table_name), backQuoteIfNeed(to_database_name), backQuoteIfNeed(to_name));\n+            assert(db_name < to_database_name);\n+            DDLGuardPtr to_table_guard = DatabaseCatalog::instance().getDDLGuard(to_database_name, to_name);\n+            auto to_db_ptr = DatabaseCatalog::instance().getDatabase(to_database_name);\n+            DatabaseAtomic::renameTable(make_query_context(), broken_table_name, *to_db_ptr, to_name, false, false);\n+            ++moved_tables;\n+        };\n+\n         if (!table->storesDataOnDisk())\n         {\n             LOG_DEBUG(log, \"Will DROP TABLE {}, because it does not store data on disk and can be safely dropped\", backQuoteIfNeed(table_name));\n@@ -616,16 +642,13 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n             table->flushAndShutdown();\n             DatabaseAtomic::dropTable(make_query_context(), table_name, true);\n         }\n+        else if (!table->supportsReplication())\n+        {\n+            move_table_to_database(table_name, to_db_name);\n+        }\n         else\n         {\n-            /// Table probably stores some data. Let's move it to another database.\n-            String to_name = fmt::format(\"{}_{}_{}\", table_name, max_log_ptr, thread_local_rng() % 1000);\n-            LOG_DEBUG(log, \"Will RENAME TABLE {} TO {}.{}\", backQuoteIfNeed(table_name), backQuoteIfNeed(to_db_name), backQuoteIfNeed(to_name));\n-            assert(db_name < to_db_name);\n-            DDLGuardPtr to_table_guard = DatabaseCatalog::instance().getDDLGuard(to_db_name, to_name);\n-            auto to_db_ptr = DatabaseCatalog::instance().getDatabase(to_db_name);\n-            DatabaseAtomic::renameTable(make_query_context(), table_name, *to_db_ptr, to_name, false, false);\n-            ++moved_tables;\n+            move_table_to_database(table_name, to_db_name_replicated);\n         }\n     }\n \ndiff --git a/src/Databases/DatabaseReplicated.h b/src/Databases/DatabaseReplicated.h\nindex ac212e168b87..72d19a5340af 100644\n--- a/src/Databases/DatabaseReplicated.h\n+++ b/src/Databases/DatabaseReplicated.h\n@@ -98,6 +98,11 @@ class DatabaseReplicated : public DatabaseAtomic\n \n     void createEmptyLogEntry(const ZooKeeperPtr & current_zookeeper);\n \n+    bool allowMoveTableToOtherDatabaseEngine(IDatabase & to_database) const override\n+    {\n+        return is_recovering && typeid_cast<DatabaseAtomic *>(&to_database);\n+    }\n+\n     String zookeeper_path;\n     String shard_name;\n     String replica_name;\n@@ -107,6 +112,7 @@ class DatabaseReplicated : public DatabaseAtomic\n     zkutil::ZooKeeperPtr getZooKeeper() const;\n \n     std::atomic_bool is_readonly = true;\n+    std::atomic_bool is_recovering = false;\n     std::unique_ptr<DatabaseReplicatedDDLWorker> ddl_worker;\n     UInt32 max_log_ptr_at_creation = 0;\n \ndiff --git a/src/Storages/IStorage.h b/src/Storages/IStorage.h\nindex 013f7e97682b..82fc12eddfbc 100644\n--- a/src/Storages/IStorage.h\n+++ b/src/Storages/IStorage.h\n@@ -416,7 +416,7 @@ class IStorage : public std::enable_shared_from_this<IStorage>, public TypePromo\n         throw Exception(\"Truncate is not supported by storage \" + getName(), ErrorCodes::NOT_IMPLEMENTED);\n     }\n \n-    virtual void checkTableCanBeRenamed() const {}\n+    virtual void checkTableCanBeRenamed(const StorageID & /*new_name*/) const {}\n \n     /** Rename the table.\n       * Renaming a name in a file with metadata, the name in the list of tables in the RAM, is done separately.\ndiff --git a/src/Storages/MergeTree/registerStorageMergeTree.cpp b/src/Storages/MergeTree/registerStorageMergeTree.cpp\nindex 82be9f1708a2..b2c41c7df681 100644\n--- a/src/Storages/MergeTree/registerStorageMergeTree.cpp\n+++ b/src/Storages/MergeTree/registerStorageMergeTree.cpp\n@@ -307,7 +307,7 @@ static StoragePtr create(const StorageFactory::Arguments & args)\n     /// For Replicated.\n     String zookeeper_path;\n     String replica_name;\n-    bool allow_renaming = true;\n+    StorageReplicatedMergeTree::RenamingRestrictions renaming_restrictions = StorageReplicatedMergeTree::RenamingRestrictions::ALLOW_ANY;\n \n     if (replicated)\n     {\n@@ -376,7 +376,6 @@ static StoragePtr create(const StorageFactory::Arguments & args)\n         bool allow_uuid_macro = is_on_cluster || is_replicated_database || args.query.attach;\n \n         /// Unfold {database} and {table} macro on table creation, so table can be renamed.\n-        /// We also unfold {uuid} macro, so path will not be broken after moving table from Atomic to Ordinary database.\n         if (!args.attach)\n         {\n             if (is_replicated_database && !is_extended_storage_def)\n@@ -386,12 +385,13 @@ static StoragePtr create(const StorageFactory::Arguments & args)\n             /// NOTE: it's not recursive\n             info.expand_special_macros_only = true;\n             info.table_id = args.table_id;\n-            if (!allow_uuid_macro)\n-                info.table_id.uuid = UUIDHelpers::Nil;\n+            /// Avoid unfolding {uuid} macro on this step.\n+            /// We did unfold it in previous versions to make moving table from Atomic to Ordinary database work correctly,\n+            /// but now it's not allowed (and it was the only reason to unfold {uuid} macro).\n+            info.table_id.uuid = UUIDHelpers::Nil;\n             zookeeper_path = args.getContext()->getMacros()->expand(zookeeper_path, info);\n \n             info.level = 0;\n-            info.table_id.uuid = UUIDHelpers::Nil;\n             replica_name = args.getContext()->getMacros()->expand(replica_name, info);\n         }\n \n@@ -419,8 +419,11 @@ static StoragePtr create(const StorageFactory::Arguments & args)\n         /// We do not allow renaming table with these macros in metadata, because zookeeper_path will be broken after RENAME TABLE.\n         /// NOTE: it may happen if table was created by older version of ClickHouse (< 20.10) and macros was not unfolded on table creation\n         /// or if one of these macros is recursively expanded from some other macro.\n+        /// Also do not allow to move table from Atomic to Ordinary database if there's {uuid} macro\n         if (info.expanded_database || info.expanded_table)\n-            allow_renaming = false;\n+            renaming_restrictions = StorageReplicatedMergeTree::RenamingRestrictions::DO_NOT_ALLOW;\n+        else if (info.expanded_uuid)\n+            renaming_restrictions = StorageReplicatedMergeTree::RenamingRestrictions::ALLOW_PRESERVING_UUID;\n     }\n \n     /// This merging param maybe used as part of sorting key\n@@ -681,7 +684,7 @@ static StoragePtr create(const StorageFactory::Arguments & args)\n             merging_params,\n             std::move(storage_settings),\n             args.has_force_restore_data_flag,\n-            allow_renaming);\n+            renaming_restrictions);\n     else\n         return StorageMergeTree::create(\n             args.table_id,\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 66a5baf555ba..3688e98629b2 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -237,7 +237,7 @@ StorageReplicatedMergeTree::StorageReplicatedMergeTree(\n     const MergingParams & merging_params_,\n     std::unique_ptr<MergeTreeSettings> settings_,\n     bool has_force_restore_data_flag,\n-    bool allow_renaming_)\n+    RenamingRestrictions renaming_restrictions_)\n     : MergeTreeData(table_id_,\n                     relative_data_path_,\n                     metadata_,\n@@ -264,7 +264,7 @@ StorageReplicatedMergeTree::StorageReplicatedMergeTree(\n     , part_check_thread(*this)\n     , restarting_thread(*this)\n     , part_moves_between_shards_orchestrator(*this)\n-    , allow_renaming(allow_renaming_)\n+    , renaming_restrictions(renaming_restrictions_)\n     , replicated_fetches_pool_size(getContext()->getSettingsRef().background_fetches_pool_size)\n     , replicated_fetches_throttler(std::make_shared<Throttler>(getSettings()->max_replicated_fetches_network_bandwidth, getContext()->getReplicatedFetchesThrottler()))\n     , replicated_sends_throttler(std::make_shared<Throttler>(getSettings()->max_replicated_sends_network_bandwidth, getContext()->getReplicatedSendsThrottler()))\n@@ -5131,17 +5131,26 @@ void StorageReplicatedMergeTree::checkTableCanBeDropped() const\n     getContext()->checkTableCanBeDropped(table_id.database_name, table_id.table_name, getTotalActiveSizeInBytes());\n }\n \n-void StorageReplicatedMergeTree::checkTableCanBeRenamed() const\n+void StorageReplicatedMergeTree::checkTableCanBeRenamed(const StorageID & new_name) const\n {\n-    if (!allow_renaming)\n+    if (renaming_restrictions == RenamingRestrictions::ALLOW_ANY)\n+        return;\n+\n+    if (renaming_restrictions == RenamingRestrictions::DO_NOT_ALLOW)\n         throw Exception(\"Cannot rename Replicated table, because zookeeper_path contains implicit 'database' or 'table' macro. \"\n                         \"We cannot rename path in ZooKeeper, so path may become inconsistent with table name. If you really want to rename table, \"\n                         \"you should edit metadata file first and restart server or reattach the table.\", ErrorCodes::NOT_IMPLEMENTED);\n+\n+    assert(renaming_restrictions == RenamingRestrictions::ALLOW_PRESERVING_UUID);\n+    if (!new_name.hasUUID() && getStorageID().hasUUID())\n+        throw Exception(\"Cannot move Replicated table to Ordinary database, because zookeeper_path contains implicit 'uuid' macro. \"\n+                        \"If you really want to rename table, \"\n+                        \"you should edit metadata file first and restart server or reattach the table.\", ErrorCodes::NOT_IMPLEMENTED);\n }\n \n void StorageReplicatedMergeTree::rename(const String & new_path_to_table_data, const StorageID & new_table_id)\n {\n-    checkTableCanBeRenamed();\n+    checkTableCanBeRenamed(new_table_id);\n     MergeTreeData::rename(new_path_to_table_data, new_table_id);\n \n     /// Update table name in zookeeper\ndiff --git a/src/Storages/StorageReplicatedMergeTree.h b/src/Storages/StorageReplicatedMergeTree.h\nindex 317544c8bb8e..a5291062218f 100644\n--- a/src/Storages/StorageReplicatedMergeTree.h\n+++ b/src/Storages/StorageReplicatedMergeTree.h\n@@ -143,7 +143,14 @@ class StorageReplicatedMergeTree final : public shared_ptr_helper<StorageReplica\n \n     void truncate(const ASTPtr &, const StorageMetadataPtr &, ContextPtr query_context, TableExclusiveLockHolder &) override;\n \n-    void checkTableCanBeRenamed() const override;\n+    enum RenamingRestrictions\n+    {\n+        ALLOW_ANY,\n+        ALLOW_PRESERVING_UUID,\n+        DO_NOT_ALLOW,\n+    };\n+\n+    void checkTableCanBeRenamed(const StorageID & new_name) const override;\n \n     void rename(const String & new_path_to_table_data, const StorageID & new_table_id) override;\n \n@@ -414,7 +421,7 @@ class StorageReplicatedMergeTree final : public shared_ptr_helper<StorageReplica\n     bool other_replicas_fixed_granularity = false;\n \n     /// Do not allow RENAME TABLE if zookeeper_path contains {database} or {table} macro\n-    const bool allow_renaming;\n+    const RenamingRestrictions renaming_restrictions;\n \n     const size_t replicated_fetches_pool_size;\n \n@@ -799,7 +806,7 @@ class StorageReplicatedMergeTree final : public shared_ptr_helper<StorageReplica\n         const MergingParams & merging_params_,\n         std::unique_ptr<MergeTreeSettings> settings_,\n         bool has_force_restore_data_flag,\n-        bool allow_renaming_);\n+        RenamingRestrictions renaming_restrictions_);\n };\n \n String getPartNamePossiblyFake(MergeTreeDataFormatVersion format_version, const MergeTreePartInfo & part_info);\n",
  "test_patch": "diff --git a/tests/integration/test_distributed_ddl/test.py b/tests/integration/test_distributed_ddl/test.py\nindex 9270efdd29b8..74cbcf915d14 100755\n--- a/tests/integration/test_distributed_ddl/test.py\n+++ b/tests/integration/test_distributed_ddl/test.py\n@@ -510,7 +510,7 @@ def test_replicated_without_arguments(test_cluster):\n     )\n     assert (\n         instance.query(\"SHOW CREATE test_atomic.rmt FORMAT TSVRaw\")\n-        == \"CREATE TABLE test_atomic.rmt\\n(\\n    `n` UInt64,\\n    `s` String\\n)\\nENGINE = ReplicatedMergeTree('/clickhouse/tables/12345678-0000-4000-8000-000000000001/{shard}', '{replica}')\\nORDER BY n\\nSETTINGS index_granularity = 8192\\n\"\n+        == \"CREATE TABLE test_atomic.rmt\\n(\\n    `n` UInt64,\\n    `s` String\\n)\\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{uuid}/{shard}', '{replica}')\\nORDER BY n\\nSETTINGS index_granularity = 8192\\n\"\n     )\n     test_cluster.ddl_check_query(\n         instance,\ndiff --git a/tests/integration/test_replicated_database/test.py b/tests/integration/test_replicated_database/test.py\nindex 13e9c225a613..3c39171d8f41 100644\n--- a/tests/integration/test_replicated_database/test.py\n+++ b/tests/integration/test_replicated_database/test.py\n@@ -111,7 +111,7 @@ def test_create_replicated_table(started_cluster):\n \n     expected = (\n         \"CREATE TABLE testdb.replicated_table\\\\n(\\\\n    `d` Date,\\\\n    `k` UInt64,\\\\n    `i32` Int32\\\\n)\\\\n\"\n-        \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\\\\n\"\n+        \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/{uuid}/{shard}\\\\', \\\\'{replica}\\\\')\\\\n\"\n         \"PARTITION BY toYYYYMM(d)\\\\nORDER BY k\\\\nSETTINGS index_granularity = 8192\"\n     )\n     assert_create_query([main_node, dummy_node], \"testdb.replicated_table\", expected)\n@@ -164,7 +164,7 @@ def test_simple_alter_table(started_cluster, engine):\n     full_engine = (\n         engine\n         if not \"Replicated\" in engine\n-        else engine + \"(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\"\n+        else engine + \"(\\\\'/clickhouse/tables/{uuid}/{shard}\\\\', \\\\'{replica}\\\\')\"\n     )\n     expected = (\n         \"CREATE TABLE {}\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\"\n@@ -191,7 +191,7 @@ def test_simple_alter_table(started_cluster, engine):\n     full_engine = (\n         engine\n         if not \"Replicated\" in engine\n-        else engine + \"(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\"\n+        else engine + \"(\\\\'/clickhouse/tables/{uuid}/{shard}\\\\', \\\\'{replica}\\\\')\"\n     )\n     expected = (\n         \"CREATE TABLE {}\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\"\n@@ -459,7 +459,7 @@ def test_alters_from_different_replicas(started_cluster):\n     expected = (\n         \"CREATE TABLE testdb.concurrent_test\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\"\n         \"    `VisitID` UInt32,\\\\n    `NestedColumn.A` Array(UInt8),\\\\n    `NestedColumn.S` Array(String),\\\\n    `ToDrop` UInt32\\\\n)\\\\n\"\n-        \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\\\\nORDER BY CounterID\\\\nSETTINGS index_granularity = 8192\"\n+        \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/{uuid}/{shard}\\\\', \\\\'{replica}\\\\')\\\\nORDER BY CounterID\\\\nSETTINGS index_granularity = 8192\"\n     )\n \n     assert_create_query([main_node, competing_node], \"testdb.concurrent_test\", expected)\n@@ -474,7 +474,7 @@ def test_alters_from_different_replicas(started_cluster):\n     expected = (\n         \"CREATE TABLE testdb.concurrent_test\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\"\n         \"    `VisitID` UInt32,\\\\n    `NestedColumn.A` Array(UInt8),\\\\n    `NestedColumn.S` Array(String),\\\\n    `ToDrop` UInt32\\\\n)\\\\n\"\n-        \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\\\\nORDER BY CounterID\\\\nSETTINGS index_granularity = 8192\"\n+        \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/{uuid}/{shard}\\\\', \\\\'{replica}\\\\')\\\\nORDER BY CounterID\\\\nSETTINGS index_granularity = 8192\"\n     )\n \n     # test_snapshot_and_snapshot_recover\n@@ -521,7 +521,7 @@ def test_alters_from_different_replicas(started_cluster):\n     expected = (\n         \"CREATE TABLE testdb.concurrent_test\\\\n(\\\\n    `CounterID` UInt32,\\\\n    `StartDate` Date,\\\\n    `UserID` UInt32,\\\\n\"\n         \"    `VisitID` UInt32,\\\\n    `NestedColumn.A` Array(UInt8),\\\\n    `NestedColumn.S` Array(String),\\\\n    `ToDrop` UInt32\\\\n)\\\\n\"\n-        \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/uuid/{shard}\\\\', \\\\'{replica}\\\\')\\\\nORDER BY CounterID\\\\nSETTINGS index_granularity = 8192\"\n+        \"ENGINE = ReplicatedMergeTree(\\\\'/clickhouse/tables/{uuid}/{shard}\\\\', \\\\'{replica}\\\\')\\\\nORDER BY CounterID\\\\nSETTINGS index_granularity = 8192\"\n     )\n \n     assert_create_query([main_node, competing_node], \"testdb.concurrent_test\", expected)\n@@ -724,7 +724,13 @@ def test_recover_staled_replica(started_cluster):\n         dummy_node.query(\n             \"SELECT count() FROM system.tables WHERE database='recover_broken_tables'\"\n         )\n-        == f\"{2*test_recover_staled_replica_run}\\n\"\n+        == f\"{test_recover_staled_replica_run}\\n\"\n+    )\n+    assert (\n+        dummy_node.query(\n+            \"SELECT count() FROM system.tables WHERE database='recover_broken_replicated_tables'\"\n+        )\n+        == f\"{test_recover_staled_replica_run}\\n\"\n     )\n     test_recover_staled_replica_run += 1\n     table = dummy_node.query(\n@@ -735,10 +741,12 @@ def test_recover_staled_replica(started_cluster):\n         == \"42\\n\"\n     )\n     table = dummy_node.query(\n-        \"SHOW TABLES FROM recover_broken_tables LIKE 'rmt5_29_%' LIMIT 1\"\n+        \"SHOW TABLES FROM recover_broken_replicated_tables LIKE 'rmt5_29_%' LIMIT 1\"\n     ).strip()\n     assert (\n-        dummy_node.query(\"SELECT (*,).1 FROM recover_broken_tables.{}\".format(table))\n+        dummy_node.query(\n+            \"SELECT (*,).1 FROM recover_broken_replicated_tables.{}\".format(table)\n+        )\n         == \"42\\n\"\n     )\n \ndiff --git a/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.reference b/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.reference\nindex d217855586be..fad3b45a354e 100644\n--- a/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.reference\n+++ b/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.reference\n@@ -2,3 +2,6 @@ CREATE TABLE default.rmt\\n(\\n    `n` UInt64,\\n    `s` String\\n)\\nENGINE = Replic\n CREATE TABLE default.rmt1\\n(\\n    `n` UInt64,\\n    `s` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/test_01148/{shard}/default/rmt\\', \\'{replica}\\')\\nORDER BY n\\nSETTINGS index_granularity = 8192\n CREATE TABLE default.rmt\\n(\\n    `n` UInt64,\\n    `s` String\\n)\\nENGINE = ReplicatedMergeTree(\\'{default_path_test}test_01148\\', \\'{default_name_test}\\')\\nORDER BY n\\nSETTINGS index_granularity = 8192\n CREATE TABLE default.rmt\\n(\\n    `n` UInt64,\\n    `s` String\\n)\\nENGINE = ReplicatedMergeTree(\\'{default_path_test}test_01148\\', \\'{default_name_test}\\')\\nORDER BY n\\nSETTINGS index_granularity = 8192\n+CREATE TABLE test_01148_atomic.rmt2\\n(\\n    `n` Int32\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/{uuid}/{shard}\\', \\'{replica}\\')\\nPRIMARY KEY n\\nORDER BY n\\nSETTINGS index_granularity = 8192\n+CREATE TABLE test_01148_atomic.rmt3\\n(\\n    `n` Int32\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/{uuid}/{shard}\\', \\'{replica}\\')\\nPRIMARY KEY n\\nORDER BY n\\nSETTINGS index_granularity = 8192\n+CREATE TABLE imdb_01148.anything\\n(\\n    `director_id` UInt64,\\n    `movie_id` UInt64\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/{uuid}/{shard}\\', \\'{replica}\\')\\nORDER BY (director_id, movie_id)\\nSETTINGS index_granularity = 8192\ndiff --git a/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.sql b/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.sql\nindex 2fef16c4b0a5..16d3dc741138 100644\n--- a/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.sql\n+++ b/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.sql\n@@ -1,6 +1,9 @@\n--- Tags: zookeeper, no-replicated-database, no-parallel\n+-- Tags: zookeeper, no-replicated-database, no-parallel, no-ordinary-database\n \n DROP TABLE IF EXISTS rmt;\n+DROP TABLE IF EXISTS rmt1;\n+DROP TABLE IF EXISTS rmt2;\n+DROP TABLE IF EXISTS rmt3;\n \n CREATE TABLE rmt (n UInt64, s String) ENGINE = ReplicatedMergeTree('/clickhouse/test_01148/{shard}/{database}/{table}', '{replica}') ORDER BY n;\n SHOW CREATE TABLE rmt;\n@@ -17,5 +20,29 @@ DETACH TABLE rmt;\n ATTACH TABLE rmt;\n SHOW CREATE TABLE rmt;\n \n+SET distributed_ddl_output_mode='none';\n+DROP DATABASE IF EXISTS test_01148_atomic;\n+CREATE DATABASE test_01148_atomic ENGINE=Atomic;\n+CREATE TABLE test_01148_atomic.rmt2 ON CLUSTER test_shard_localhost (n int, PRIMARY KEY n) ENGINE=ReplicatedMergeTree;\n+CREATE TABLE test_01148_atomic.rmt3 AS test_01148_atomic.rmt2; -- { serverError 62 }\n+CREATE TABLE test_01148_atomic.rmt4 ON CLUSTER test_shard_localhost AS test_01148_atomic.rmt2;\n+SHOW CREATE TABLE test_01148_atomic.rmt2;\n+RENAME TABLE test_01148_atomic.rmt4 to test_01148_atomic.rmt3;\n+SHOW CREATE TABLE test_01148_atomic.rmt3;\n+\n+DROP DATABASE IF EXISTS test_01148_ordinary;\n+CREATE DATABASE test_01148_ordinary ENGINE=Ordinary;\n+RENAME TABLE test_01148_atomic.rmt3 to test_01148_ordinary.rmt3; -- { serverError 48 }\n+DROP DATABASE test_01148_ordinary;\n+DROP DATABASE test_01148_atomic;\n+\n DROP TABLE rmt;\n DROP TABLE rmt1;\n+\n+SET allow_experimental_database_replicated=1;\n+DROP DATABASE IF EXISTS imdb_01148;\n+CREATE DATABASE imdb_01148 ENGINE = Replicated('/test/databases/imdb_01148', '{shard}', '{replica}');\n+CREATE TABLE imdb_01148.movie_directors (`director_id` UInt64, `movie_id` UInt64) ENGINE = ReplicatedMergeTree ORDER BY (director_id, movie_id) SETTINGS index_granularity = 8192;\n+CREATE TABLE imdb_01148.anything AS imdb_01148.movie_directors;\n+SHOW CREATE TABLE imdb_01148.anything;\n+DROP DATABASE imdb_01148;\n",
  "problem_statement": "CREATE AS fails on Replicated db\n**Describe what's wrong**\r\n\r\nRenaming a table, followed by a `CREATE AS` (using the renamed table) fails for a replicated database. For example:\r\n\r\n1. Create a database\r\n  ```\r\n  CREATE DATABASE imdb\r\n  ENGINE = Replicated('/clickhouse/databases/{shard}', '{shard}', '{replica}')\r\n  ```\r\n\r\n2. Create replicated table\r\n\r\n```\r\nCREATE TABLE imdb.movie_directors\r\n(\r\n    `director_id` UInt64,\r\n    `movie_id` UInt64\r\n)\r\nENGINE = ReplicatedMergeTree\r\nORDER BY (director_id, movie_id)\r\nSETTINGS index_granularity = 8192;\r\n```\r\n\r\n3. Rename the table\r\n\r\n```\r\nRENAME table movie_directors TO movie_directors_old;\r\n```\r\n\r\n3. Attempt to create a new table using the schema of the old\r\n```\r\nCREATE TABLE default.movie_directors AS default.movie_directors_old;\r\n```\r\n\r\nThrows error\r\n\r\n```\r\nCode: 253. DB::Exception: Replica /clickhouse/tables/56b41aa1-8a01-4958-b56e-61798988d496/default/replicas/c-gracious-morse-39-server-2 already exists. (REPLICA_IS_ALREADY_EXIST) (version 22.3.1.1)\r\ndefault\r\n```\r\n\r\nNote this fails even if the new table is a different name.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nTested on 22.3.1.1\r\n\r\n**How to reproduce**\r\n\r\nSee above\r\n\r\n**Expected behavior**\r\n\r\nI'd expect the 2nd creation to work.\r\n\r\n**Additional context**\r\n\r\nReproducible in ClickHouse Cloud on default db.\r\n\n",
  "hints_text": "This can be distilled down to:\r\n\r\n```\r\nCREATE TABLE imdb.movie_directors\r\n(\r\n    `director_id` UInt64,\r\n    `movie_id` UInt64\r\n)\r\nENGINE = ReplicatedMergeTree\r\nORDER BY (director_id, movie_id)\r\nSETTINGS index_granularity = 8192;\r\n\r\n\r\nCREATE TABLE imdb.anything AS imdb.movie_directors;\r\n```",
  "created_at": "2022-04-13T14:48:01Z"
}