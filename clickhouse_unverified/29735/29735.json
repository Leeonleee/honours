{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 29735,
  "instance_id": "ClickHouse__ClickHouse-29735",
  "issue_numbers": [
    "29580"
  ],
  "base_commit": "4396daeb1f465cf498fb708c25e7b1f9c60a3281",
  "patch": "diff --git a/src/Core/ProtocolDefines.h b/src/Core/ProtocolDefines.h\nindex 6c62b969ff9c..289917f4bdb7 100644\n--- a/src/Core/ProtocolDefines.h\n+++ b/src/Core/ProtocolDefines.h\n@@ -12,7 +12,9 @@\n /// Minimum revision with exactly the same set of aggregation methods and rules to select them.\n /// Two-level (bucketed) aggregation is incompatible if servers are inconsistent in these rules\n /// (keys will be placed in different buckets and result will not be fully aggregated).\n-#define DBMS_MIN_REVISION_WITH_CURRENT_AGGREGATION_VARIANT_SELECTION_METHOD 54431\n+#define DBMS_MIN_REVISION_WITH_CURRENT_AGGREGATION_VARIANT_SELECTION_METHOD 54456\n+#define DBMS_MIN_MAJOR_VERSION_WITH_CURRENT_AGGREGATION_VARIANT_SELECTION_METHOD 21\n+#define DBMS_MIN_MINOR_VERSION_WITH_CURRENT_AGGREGATION_VARIANT_SELECTION_METHOD 4\n #define DBMS_MIN_REVISION_WITH_COLUMN_DEFAULTS_METADATA 54410\n \n #define DBMS_MIN_REVISION_WITH_LOW_CARDINALITY_TYPE 54405\ndiff --git a/src/Interpreters/ClientInfo.h b/src/Interpreters/ClientInfo.h\nindex ed00de6e8034..41bb1f656a78 100644\n--- a/src/Interpreters/ClientInfo.h\n+++ b/src/Interpreters/ClientInfo.h\n@@ -84,6 +84,14 @@ class ClientInfo\n     UInt64 client_version_patch = 0;\n     unsigned client_tcp_protocol_version = 0;\n \n+    /// In case of distributed query, client info for query is actually a client info of client.\n+    /// In order to get a version of server-initiator, use connection_ values.\n+    /// Also for tcp only.\n+    UInt64 connection_client_version_major = 0;\n+    UInt64 connection_client_version_minor = 0;\n+    UInt64 connection_client_version_patch = 0;\n+    unsigned connection_tcp_protocol_version = 0;\n+\n     /// For http\n     HTTPMethod http_method = HTTPMethod::UNKNOWN;\n     String http_user_agent;\ndiff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp\nindex 35c8c32c65b1..202919d66684 100644\n--- a/src/Interpreters/InterpreterSelectQuery.cpp\n+++ b/src/Interpreters/InterpreterSelectQuery.cpp\n@@ -72,6 +72,7 @@\n \n #include <Functions/IFunction.h>\n #include <Core/Field.h>\n+#include <Core/ProtocolDefines.h>\n #include <base/types.h>\n #include <Columns/Collator.h>\n #include <Common/FieldVisitorsAccurateComparison.h>\n@@ -2583,6 +2584,19 @@ void InterpreterSelectQuery::initSettings()\n     auto & query = getSelectQuery();\n     if (query.settings())\n         InterpreterSetQuery(query.settings(), context).executeForCurrentContext();\n+\n+    auto & client_info = context->getClientInfo();\n+    auto min_major = DBMS_MIN_MAJOR_VERSION_WITH_CURRENT_AGGREGATION_VARIANT_SELECTION_METHOD;\n+    auto min_minor = DBMS_MIN_MINOR_VERSION_WITH_CURRENT_AGGREGATION_VARIANT_SELECTION_METHOD;\n+\n+    if (client_info.query_kind == ClientInfo::QueryKind::SECONDARY_QUERY &&\n+        std::forward_as_tuple(client_info.connection_client_version_major, client_info.connection_client_version_minor) < std::forward_as_tuple(min_major, min_minor))\n+    {\n+        /// Disable two-level aggregation due to version incompatibility.\n+        context->setSetting(\"group_by_two_level_threshold\", Field(0));\n+        context->setSetting(\"group_by_two_level_threshold_bytes\", Field(0));\n+\n+    }\n }\n \n }\ndiff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp\nindex 729cb33371af..64f7cc0ae096 100644\n--- a/src/Server/TCPHandler.cpp\n+++ b/src/Server/TCPHandler.cpp\n@@ -1126,6 +1126,11 @@ void TCPHandler::receiveHello()\n     client_info.client_version_patch = client_version_patch;\n     client_info.client_tcp_protocol_version = client_tcp_protocol_version;\n \n+    client_info.connection_client_version_major = client_version_major;\n+    client_info.connection_client_version_minor = client_version_minor;\n+    client_info.connection_client_version_patch = client_version_patch;\n+    client_info.connection_tcp_protocol_version = client_tcp_protocol_version;\n+\n     is_interserver_mode = (user == USER_INTERSERVER_MARKER);\n     if (is_interserver_mode)\n     {\n",
  "test_patch": "diff --git a/tests/integration/test_backward_compatibility/test_aggregate_fixed_key.py b/tests/integration/test_backward_compatibility/test_aggregate_fixed_key.py\nnew file mode 100644\nindex 000000000000..8819be527fd0\n--- /dev/null\n+++ b/tests/integration/test_backward_compatibility/test_aggregate_fixed_key.py\n@@ -0,0 +1,61 @@\n+import pytest\n+\n+from helpers.cluster import ClickHouseCluster\n+\n+cluster = ClickHouseCluster(__file__)\n+node1 = cluster.add_instance('node1', with_zookeeper=True, image='yandex/clickhouse-server', tag='21.3', with_installed_binary=True)\n+node2 = cluster.add_instance('node2', with_zookeeper=True, image='yandex/clickhouse-server')\n+node3 = cluster.add_instance('node3', with_zookeeper=True, image='yandex/clickhouse-server')\n+\n+\n+@pytest.fixture(scope=\"module\")\n+def start_cluster():\n+    try:\n+        cluster.start()\n+        yield cluster\n+\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def test_two_level_merge(start_cluster):\n+    for node in start_cluster.instances.values():\n+        node.query(\n+            \"\"\"\n+            CREATE TABLE IF NOT EXISTS test_two_level_merge(date Date, zone UInt32, number UInt32)\n+            ENGINE = MergeTree() PARTITION BY toUInt64(number / 1000) ORDER BY tuple();\n+\n+            INSERT INTO\n+                test_two_level_merge\n+            SELECT\n+                toDate('2021-09-28') - number / 1000,\n+                249081628,\n+                number\n+            FROM\n+                numbers(15000);\n+            \"\"\"\n+        )\n+\n+    # covers only the keys64 method\n+    for node in start_cluster.instances.values():\n+        print(node.query(\n+            \"\"\"\n+            SELECT\n+                throwIf(uniqExact(date) != count(), 'group by is borked')\n+            FROM (\n+                SELECT\n+                    date\n+                FROM\n+                    remote('node{1,2}', default.test_two_level_merge)\n+                WHERE\n+                    date BETWEEN toDate('2021-09-20') AND toDate('2021-09-28')\n+                    AND zone = 249081628\n+                GROUP by date, zone\n+            )\n+            SETTINGS\n+                group_by_two_level_threshold = 1,\n+                group_by_two_level_threshold_bytes = 1,\n+                max_threads = 2,\n+                prefer_localhost_replica = 0\n+            \"\"\"\n+        ))\n",
  "problem_statement": "Multiple rows returned for the same `GROUP BY` key when mixing different ClickHouse versions (all pre v21.3 LTS and post v21.4, up to latest released 21.10)\nThe following integration test describes the issue more than enough. The test starts 3 nodes to cover all possible cases.\r\n\r\n* _root -> leaf_\r\n* old server -> new server\r\n* new server -> old server\r\n* new server -> new server\r\n\r\ngit bisecting leads to https://github.com/ClickHouse/ClickHouse/commit/64ea1f82989ad45555629759b6f395804b12c864\r\n\r\n<details>\r\n<pre>\r\ngit bisect start\r\n# good: [5bdc57004682a5e0236ec630546d20ad752c2fde] Improve performance of GROUP BY multiple fixed size keys\r\ngit bisect good 5bdc57004682a5e0236ec630546d20ad752c2fde\r\n# bad: [545528917fd7700be0f6c582be970dbd23feeab5] Fix tests.\r\ngit bisect bad 545528917fd7700be0f6c582be970dbd23feeab5\r\n# good: [74a07e406b7199dc5aa7804f5e5c63f6477118de] Even more stable\r\ngit bisect good 74a07e406b7199dc5aa7804f5e5c63f6477118de\r\n# good: [c8da611fcd5c454431b49a407df36fa4ff745b9b] Merge pull request #21023 from ClickHouse/fix-datetime64-formatting\r\ngit bisect good c8da611fcd5c454431b49a407df36fa4ff745b9b\r\n# good: [6dc683dce6af72239793906c633832de2386448e] Merge pull request #19815 from otrazhenia/evgsudarikova-DOCSUP-6149\r\ngit bisect good 6dc683dce6af72239793906c633832de2386448e\r\n# good: [8f81dce32f6eebf448bd8a65ad4192ac746cc66f] Merge pull request #20585 from ClickHouse/persistent_nukeeper_log_storage\r\ngit bisect good 8f81dce32f6eebf448bd8a65ad4192ac746cc66f\r\n# good: [3feded8d0cb562b7d0ed7a8c4bd4939f2524301c] Create type-conversion-functions.md\r\ngit bisect good 3feded8d0cb562b7d0ed7a8c4bd4939f2524301c\r\n# good: [3cda69feaf1295333a1dc2f4030730bd3edbb425] Merge pull request #20632 from ClickHouse/akz/mysqlxx-randomize-replicas\r\ngit bisect good 3cda69feaf1295333a1dc2f4030730bd3edbb425\r\n# good: [994b998df9863e772b438a858a2cdabdb2ce27ea] Update docs/ru/sql-reference/operators/in.md\r\ngit bisect good 994b998df9863e772b438a858a2cdabdb2ce27ea\r\n# good: [802e5e725b744fe608e55aaa6456ea3e8989fe83] Merge pull request #19965 from ka1bi4/romanzhukov-DOCSUP-5822-update-accurateCastOrNull\r\ngit bisect good 802e5e725b744fe608e55aaa6456ea3e8989fe83\r\n# bad: [2bf533630c7a70232b1615e74cca9d8c699c7de0] Fix tests.\r\ngit bisect bad 2bf533630c7a70232b1615e74cca9d8c699c7de0\r\n# bad: [64ea1f82989ad45555629759b6f395804b12c864] Save packet keys.\r\ngit bisect bad 64ea1f82989ad45555629759b6f395804b12c864\r\n# first bad commit: [64ea1f82989ad45555629759b6f395804b12c864] Save packet keys.\r\n</pre>\r\n</details>\r\n\r\nI tried to simplify the test, but even minor changes to the test make it pass again. \r\n\r\n```py\r\nimport pytest\r\n\r\nfrom helpers.cluster import ClickHouseCluster\r\n\r\ncluster = ClickHouseCluster(__file__)\r\nnode1 = cluster.add_instance('node1', with_zookeeper=True, image='yandex/clickhouse-server', tag='20.8', with_installed_binary=True)\r\nnode2 = cluster.add_instance('node2', with_zookeeper=True, image='yandex/clickhouse-server')\r\nnode3 = cluster.add_instance('node3', with_zookeeper=True, image='yandex/clickhouse-server')\r\n\r\n\r\n@pytest.fixture(scope=\"module\")\r\ndef start_cluster():\r\n    try:\r\n        cluster.start()\r\n        yield cluster\r\n\r\n    finally:\r\n        cluster.shutdown()\r\n\r\n\r\ndef test_two_level_merge(start_cluster):\r\n    for node in start_cluster.instances.values():\r\n        node.query(\r\n            \"\"\"\r\n            CREATE TABLE IF NOT EXISTS test_two_level_merge(date Date, zone UInt32, number UInt32)\r\n            ENGINE = MergeTree() PARTITION BY toUInt64(number / 1000) ORDER BY tuple();\r\n\r\n            INSERT INTO\r\n                test_two_level_merge\r\n            SELECT\r\n                toDate('2021-09-28') - number / 1000,\r\n                249081628,\r\n                number\r\n            FROM\r\n                numbers(15000);\r\n            \"\"\"\r\n        )\r\n\r\n    # covers only the keys64 method\r\n    for node in start_cluster.instances.values():\r\n        print(node.query(\r\n            \"\"\"\r\n            SELECT\r\n                throwIf(uniqExact(date) != count(), 'group by is borked')\r\n            FROM (\r\n                SELECT\r\n                    date\r\n                FROM\r\n                    remote('node{1,2}', default.test_two_level_merge)\r\n                WHERE\r\n                    date BETWEEN toDate('2021-09-20') AND toDate('2021-09-28')\r\n                    AND zone = 249081628\r\n                GROUP by date, zone\r\n            )\r\n            SETTINGS\r\n                group_by_two_level_threshold = 1,\r\n                group_by_two_level_threshold_bytes = 1,\r\n                max_threads = 2,\r\n                prefer_localhost_replica = 0\r\n            \"\"\"\r\n        ))\r\n```\r\n\r\ncc @KochetovNicolai \r\n\r\nOne considered fix is to just bump `DBMS_MIN_REVISION_WITH_CURRENT_AGGREGATION_VARIANT_SELECTION_METHOD` and also handle in in TCPHandler. This will introduce some performance degradation during upgrade.\n",
  "hints_text": "",
  "created_at": "2021-10-04T14:34:38Z",
  "modified_files": [
    "src/Core/ProtocolDefines.h",
    "src/Interpreters/ClientInfo.h",
    "src/Interpreters/InterpreterSelectQuery.cpp",
    "src/Server/TCPHandler.cpp"
  ],
  "modified_test_files": [
    "b/tests/integration/test_backward_compatibility/test_aggregate_fixed_key.py"
  ]
}