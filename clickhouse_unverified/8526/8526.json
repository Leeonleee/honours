{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 8526,
  "instance_id": "ClickHouse__ClickHouse-8526",
  "issue_numbers": [
    "8156"
  ],
  "base_commit": "e5dd4d82aeb4b5c8e8d83633ea23ffab4e8e1091",
  "patch": "diff --git a/contrib/zlib-ng b/contrib/zlib-ng\nindex 5673222fbd37..bba56a73be24 160000\n--- a/contrib/zlib-ng\n+++ b/contrib/zlib-ng\n@@ -1,1 +1,1 @@\n-Subproject commit 5673222fbd37ea89afb2ea73096f9bf5ec68ea31\n+Subproject commit bba56a73be249514acfbc7d49aa2a68994dad8ab\ndiff --git a/dbms/programs/server/HTTPHandler.cpp b/dbms/programs/server/HTTPHandler.cpp\nindex 29d186def2d6..b2b3298693ed 100644\n--- a/dbms/programs/server/HTTPHandler.cpp\n+++ b/dbms/programs/server/HTTPHandler.cpp\n@@ -20,8 +20,6 @@\n #include <Compression/CompressedReadBuffer.h>\n #include <Compression/CompressedWriteBuffer.h>\n #include <IO/ReadBufferFromIStream.h>\n-#include <IO/ZlibInflatingReadBuffer.h>\n-#include <IO/BrotliReadBuffer.h>\n #include <IO/ReadBufferFromString.h>\n #include <IO/WriteBufferFromString.h>\n #include <IO/WriteBufferFromHTTPServerResponse.h>\n@@ -300,32 +298,24 @@ void HTTPHandler::processQuery(\n \n     /// The client can pass a HTTP header indicating supported compression method (gzip or deflate).\n     String http_response_compression_methods = request.get(\"Accept-Encoding\", \"\");\n-    bool client_supports_http_compression = false;\n-    CompressionMethod http_response_compression_method {};\n+    CompressionMethod http_response_compression_method = CompressionMethod::None;\n \n     if (!http_response_compression_methods.empty())\n     {\n+        /// If client supports brotli - it's preferred.\n         /// Both gzip and deflate are supported. If the client supports both, gzip is preferred.\n         /// NOTE parsing of the list of methods is slightly incorrect.\n-        if (std::string::npos != http_response_compression_methods.find(\"gzip\"))\n-        {\n-            client_supports_http_compression = true;\n+\n+        if (std::string::npos != http_response_compression_methods.find(\"br\"))\n+            http_response_compression_method = CompressionMethod::Brotli;\n+        else if (std::string::npos != http_response_compression_methods.find(\"gzip\"))\n             http_response_compression_method = CompressionMethod::Gzip;\n-        }\n         else if (std::string::npos != http_response_compression_methods.find(\"deflate\"))\n-        {\n-            client_supports_http_compression = true;\n             http_response_compression_method = CompressionMethod::Zlib;\n-        }\n-#if USE_BROTLI\n-        else if (http_response_compression_methods == \"br\")\n-        {\n-            client_supports_http_compression = true;\n-            http_response_compression_method = CompressionMethod::Brotli;\n-        }\n-#endif\n     }\n \n+    bool client_supports_http_compression = http_response_compression_method != CompressionMethod::None;\n+\n     /// Client can pass a 'compress' flag in the query string. In this case the query result is\n     /// compressed using internal algorithm. This is not reflected in HTTP headers.\n     bool internal_compression = params.getParsed<bool>(\"compress\", false);\n@@ -344,8 +334,8 @@ void HTTPHandler::processQuery(\n     unsigned keep_alive_timeout = config.getUInt(\"keep_alive_timeout\", 10);\n \n     used_output.out = std::make_shared<WriteBufferFromHTTPServerResponse>(\n-        request, response, keep_alive_timeout,\n-        client_supports_http_compression, http_response_compression_method, buffer_size_http);\n+        request, response, keep_alive_timeout, client_supports_http_compression, http_response_compression_method);\n+\n     if (internal_compression)\n         used_output.out_maybe_compressed = std::make_shared<CompressedWriteBuffer>(*used_output.out);\n     else\n@@ -400,32 +390,9 @@ void HTTPHandler::processQuery(\n     std::unique_ptr<ReadBuffer> in_post_raw = std::make_unique<ReadBufferFromIStream>(istr);\n \n     /// Request body can be compressed using algorithm specified in the Content-Encoding header.\n-    std::unique_ptr<ReadBuffer> in_post;\n     String http_request_compression_method_str = request.get(\"Content-Encoding\", \"\");\n-    if (!http_request_compression_method_str.empty())\n-    {\n-        if (http_request_compression_method_str == \"gzip\")\n-        {\n-            in_post = std::make_unique<ZlibInflatingReadBuffer>(std::move(in_post_raw), CompressionMethod::Gzip);\n-        }\n-        else if (http_request_compression_method_str == \"deflate\")\n-        {\n-            in_post = std::make_unique<ZlibInflatingReadBuffer>(std::move(in_post_raw), CompressionMethod::Zlib);\n-        }\n-#if USE_BROTLI\n-        else if (http_request_compression_method_str == \"br\")\n-        {\n-            in_post = std::make_unique<BrotliReadBuffer>(std::move(in_post_raw));\n-        }\n-#endif\n-        else\n-        {\n-            throw Exception(\"Unknown Content-Encoding of HTTP request: \" + http_request_compression_method_str,\n-                    ErrorCodes::UNKNOWN_COMPRESSION_METHOD);\n-        }\n-    }\n-    else\n-        in_post = std::move(in_post_raw);\n+    std::unique_ptr<ReadBuffer> in_post = wrapReadBufferWithCompressionMethod(\n+        std::make_unique<ReadBufferFromIStream>(istr), chooseCompressionMethod({}, http_request_compression_method_str));\n \n     /// The data can also be compressed using incompatible internal algorithm. This is indicated by\n     /// 'decompress' query parameter.\ndiff --git a/dbms/src/IO/BrotliWriteBuffer.cpp b/dbms/src/IO/BrotliWriteBuffer.cpp\nindex 0a0eeb52956d..ac1e2b3c1886 100644\n--- a/dbms/src/IO/BrotliWriteBuffer.cpp\n+++ b/dbms/src/IO/BrotliWriteBuffer.cpp\n@@ -30,14 +30,14 @@ class BrotliWriteBuffer::BrotliStateWrapper\n     BrotliEncoderState * state;\n };\n \n-BrotliWriteBuffer::BrotliWriteBuffer(WriteBuffer & out_, int compression_level, size_t buf_size, char * existing_memory, size_t alignment)\n-        : BufferWithOwnMemory<WriteBuffer>(buf_size, existing_memory, alignment)\n-        , brotli(std::make_unique<BrotliStateWrapper>())\n-        , in_available(0)\n-        , in_data(nullptr)\n-        , out_capacity(0)\n-        , out_data(nullptr)\n-        , out(out_)\n+BrotliWriteBuffer::BrotliWriteBuffer(std::unique_ptr<WriteBuffer> out_, int compression_level, size_t buf_size, char * existing_memory, size_t alignment)\n+    : BufferWithOwnMemory<WriteBuffer>(buf_size, existing_memory, alignment)\n+    , brotli(std::make_unique<BrotliStateWrapper>())\n+    , in_available(0)\n+    , in_data(nullptr)\n+    , out_capacity(0)\n+    , out_data(nullptr)\n+    , out(std::move(out_))\n {\n     BrotliEncoderSetParameter(brotli->state, BROTLI_PARAM_QUALITY, static_cast<uint32_t>(compression_level));\n     // Set LZ77 window size. According to brotli sources default value is 24 (c/tools/brotli.c:81)\n@@ -68,9 +68,9 @@ void BrotliWriteBuffer::nextImpl()\n \n     do\n     {\n-        out.nextIfAtEnd();\n-        out_data = reinterpret_cast<unsigned char *>(out.position());\n-        out_capacity = out.buffer().end() - out.position();\n+        out->nextIfAtEnd();\n+        out_data = reinterpret_cast<unsigned char *>(out->position());\n+        out_capacity = out->buffer().end() - out->position();\n \n         int result = BrotliEncoderCompressStream(\n                 brotli->state,\n@@ -81,7 +81,7 @@ void BrotliWriteBuffer::nextImpl()\n                 &out_data,\n                 nullptr);\n \n-        out.position() = out.buffer().end() - out_capacity;\n+        out->position() = out->buffer().end() - out_capacity;\n \n         if (result == 0)\n         {\n@@ -100,9 +100,9 @@ void BrotliWriteBuffer::finish()\n \n     while (true)\n     {\n-        out.nextIfAtEnd();\n-        out_data = reinterpret_cast<unsigned char *>(out.position());\n-        out_capacity = out.buffer().end() - out.position();\n+        out->nextIfAtEnd();\n+        out_data = reinterpret_cast<unsigned char *>(out->position());\n+        out_capacity = out->buffer().end() - out->position();\n \n         int result = BrotliEncoderCompressStream(\n                 brotli->state,\n@@ -113,7 +113,7 @@ void BrotliWriteBuffer::finish()\n                 &out_data,\n                 nullptr);\n \n-        out.position() = out.buffer().end() - out_capacity;\n+        out->position() = out->buffer().end() - out_capacity;\n \n         if (BrotliEncoderIsFinished(brotli->state))\n         {\ndiff --git a/dbms/src/IO/BrotliWriteBuffer.h b/dbms/src/IO/BrotliWriteBuffer.h\nindex 6cc2a4ec4b73..5a294354f49f 100644\n--- a/dbms/src/IO/BrotliWriteBuffer.h\n+++ b/dbms/src/IO/BrotliWriteBuffer.h\n@@ -10,11 +10,11 @@ class BrotliWriteBuffer : public BufferWithOwnMemory<WriteBuffer>\n {\n public:\n     BrotliWriteBuffer(\n-            WriteBuffer & out_,\n-            int compression_level,\n-            size_t buf_size = DBMS_DEFAULT_BUFFER_SIZE,\n-            char * existing_memory = nullptr,\n-            size_t alignment = 0);\n+        std::unique_ptr<WriteBuffer> out_,\n+        int compression_level,\n+        size_t buf_size = DBMS_DEFAULT_BUFFER_SIZE,\n+        char * existing_memory = nullptr,\n+        size_t alignment = 0);\n \n     ~BrotliWriteBuffer() override;\n \n@@ -30,9 +30,9 @@ class BrotliWriteBuffer : public BufferWithOwnMemory<WriteBuffer>\n     const uint8_t * in_data;\n \n     size_t out_capacity;\n-    uint8_t  * out_data;\n+    uint8_t * out_data;\n \n-    WriteBuffer & out;\n+    std::unique_ptr<WriteBuffer> out;\n \n     bool finished = false;\n };\ndiff --git a/dbms/src/IO/CompressionMethod.cpp b/dbms/src/IO/CompressionMethod.cpp\nnew file mode 100644\nindex 000000000000..20f1ea443011\n--- /dev/null\n+++ b/dbms/src/IO/CompressionMethod.cpp\n@@ -0,0 +1,104 @@\n+#include <IO/CompressionMethod.h>\n+\n+#include <IO/ReadBuffer.h>\n+#include <IO/WriteBuffer.h>\n+#include <IO/ZlibInflatingReadBuffer.h>\n+#include <IO/ZlibDeflatingWriteBuffer.h>\n+#include <IO/BrotliReadBuffer.h>\n+#include <IO/BrotliWriteBuffer.h>\n+\n+#include <Common/config.h>\n+\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int NOT_IMPLEMENTED;\n+}\n+\n+\n+std::string toContentEncodingName(CompressionMethod method)\n+{\n+    switch (method)\n+    {\n+        case CompressionMethod::Gzip:   return \"gzip\";\n+        case CompressionMethod::Zlib:   return \"deflate\";\n+        case CompressionMethod::Brotli: return \"br\";\n+        case CompressionMethod::None:   return \"\";\n+    }\n+    __builtin_unreachable();\n+}\n+\n+\n+CompressionMethod chooseCompressionMethod(const std::string & path, const std::string & hint)\n+{\n+    std::string file_extension;\n+    if (hint.empty() || hint == \"auto\")\n+    {\n+        auto pos = path.find_last_of('.');\n+        if (pos != std::string::npos)\n+            file_extension = path.substr(pos + 1, std::string::npos);\n+    }\n+\n+    const std::string * method_str = file_extension.empty() ? &hint : &file_extension;\n+\n+    if (*method_str == \"gzip\" || *method_str == \"gz\")\n+        return CompressionMethod::Gzip;\n+    if (*method_str == \"deflate\")\n+        return CompressionMethod::Zlib;\n+    if (*method_str == \"brotli\" || *method_str == \"br\")\n+        return CompressionMethod::Brotli;\n+    if (hint.empty() || hint == \"auto\" || hint == \"none\")\n+        return CompressionMethod::None;\n+\n+    throw Exception(\"Unknown compression method \" + hint + \". Only 'auto', 'none', 'gzip', 'br' are supported as compression methods\",\n+        ErrorCodes::NOT_IMPLEMENTED);\n+}\n+\n+\n+std::unique_ptr<ReadBuffer> wrapReadBufferWithCompressionMethod(\n+    std::unique_ptr<ReadBuffer> nested,\n+    CompressionMethod method,\n+    size_t buf_size,\n+    char * existing_memory,\n+    size_t alignment)\n+{\n+    if (method == CompressionMethod::Gzip || method == CompressionMethod::Zlib)\n+        return std::make_unique<ZlibInflatingReadBuffer>(std::move(nested), method, buf_size, existing_memory, alignment);\n+#if USE_BROTLI\n+    if (method == CompressionMethod::Brotli)\n+        return std::make_unique<BrotliReadBuffer>(std::move(nested), buf_size, existing_memory, alignment);\n+#endif\n+\n+    if (method == CompressionMethod::None)\n+        return nested;\n+\n+    throw Exception(\"Unsupported compression method\", ErrorCodes::NOT_IMPLEMENTED);\n+}\n+\n+\n+std::unique_ptr<WriteBuffer> wrapWriteBufferWithCompressionMethod(\n+    std::unique_ptr<WriteBuffer> nested,\n+    CompressionMethod method,\n+    int level,\n+    size_t buf_size,\n+    char * existing_memory,\n+    size_t alignment)\n+{\n+    if (method == DB::CompressionMethod::Gzip || method == CompressionMethod::Zlib)\n+        return std::make_unique<ZlibDeflatingWriteBuffer>(std::move(nested), method, level, buf_size, existing_memory, alignment);\n+\n+#if USE_BROTLI\n+    if (method == DB::CompressionMethod::Brotli)\n+        return std::make_unique<BrotliWriteBuffer>(std::move(nested), level, buf_size, existing_memory, alignment);\n+#endif\n+\n+    if (method == CompressionMethod::None)\n+        return nested;\n+\n+    throw Exception(\"Unsupported compression method\", ErrorCodes::NOT_IMPLEMENTED);\n+}\n+\n+}\ndiff --git a/dbms/src/IO/CompressionMethod.h b/dbms/src/IO/CompressionMethod.h\nindex c54d2b581fd1..64c2ba3341f7 100644\n--- a/dbms/src/IO/CompressionMethod.h\n+++ b/dbms/src/IO/CompressionMethod.h\n@@ -1,18 +1,57 @@\n #pragma once\n \n+#include <string>\n+#include <memory>\n+\n+#include <Core/Defines.h>\n+\n+\n namespace DB\n {\n \n+class ReadBuffer;\n+class WriteBuffer;\n+\n+/** These are \"generally recognizable\" compression methods for data import/export.\n+  * Do not mess with more efficient compression methods used by ClickHouse internally\n+  *  (they use non-standard framing, indexes, checksums...)\n+  */\n+\n enum class CompressionMethod\n {\n+    None,\n     /// DEFLATE compression with gzip header and CRC32 checksum.\n     /// This option corresponds to files produced by gzip(1) or HTTP Content-Encoding: gzip.\n     Gzip,\n     /// DEFLATE compression with zlib header and Adler32 checksum.\n     /// This option corresponds to HTTP Content-Encoding: deflate.\n     Zlib,\n-    Brotli,\n-    None\n+    Brotli\n };\n \n+/// How the compression method is named in HTTP.\n+std::string toContentEncodingName(CompressionMethod method);\n+\n+/** Choose compression method from path and hint.\n+  * if hint is \"auto\" or empty string, then path is analyzed,\n+  *  otherwise path parameter is ignored and hint is used as compression method name.\n+  * path is arbitrary string that will be analyzed for file extension (gz, br...) that determines compression.\n+  */\n+CompressionMethod chooseCompressionMethod(const std::string & path, const std::string & hint);\n+\n+std::unique_ptr<ReadBuffer> wrapReadBufferWithCompressionMethod(\n+    std::unique_ptr<ReadBuffer> nested,\n+    CompressionMethod method,\n+    size_t buf_size = DBMS_DEFAULT_BUFFER_SIZE,\n+    char * existing_memory = nullptr,\n+    size_t alignment = 0);\n+\n+std::unique_ptr<WriteBuffer> wrapWriteBufferWithCompressionMethod(\n+    std::unique_ptr<WriteBuffer> nested,\n+    CompressionMethod method,\n+    int level,\n+    size_t buf_size = DBMS_DEFAULT_BUFFER_SIZE,\n+    char * existing_memory = nullptr,\n+    size_t alignment = 0);\n+\n }\ndiff --git a/dbms/src/IO/ReadHelpers.h b/dbms/src/IO/ReadHelpers.h\nindex 472060394355..7e5b5ce804fa 100644\n--- a/dbms/src/IO/ReadHelpers.h\n+++ b/dbms/src/IO/ReadHelpers.h\n@@ -29,22 +29,13 @@\n #include <IO/CompressionMethod.h>\n #include <IO/ReadBuffer.h>\n #include <IO/ReadBufferFromMemory.h>\n+#include <IO/BufferWithOwnMemory.h>\n #include <IO/VarInt.h>\n-#include <IO/ZlibInflatingReadBuffer.h>\n \n #include <DataTypes/DataTypeDateTime.h>\n \n-#ifdef __clang__\n-#pragma clang diagnostic push\n-#pragma clang diagnostic ignored \"-Wdouble-promotion\"\n-#endif\n-\n #include <double-conversion/double-conversion.h>\n \n-#ifdef __clang__\n-#pragma clang diagnostic pop\n-#endif\n-\n \n /// 1 GiB\n #define DEFAULT_MAX_STRING_SIZE (1ULL << 30)\n@@ -1024,21 +1015,11 @@ void skipToNextLineOrEOF(ReadBuffer & buf);\n /// Skip to next character after next unescaped \\n. If no \\n in stream, skip to end. Does not throw on invalid escape sequences.\n void skipToUnescapedNextLineOrEOF(ReadBuffer & buf);\n \n-template <class TReadBuffer, class... Types>\n-std::unique_ptr<ReadBuffer> getReadBuffer(const DB::CompressionMethod method, Types&&... args)\n-{\n-    if (method == DB::CompressionMethod::Gzip)\n-    {\n-        auto read_buf = std::make_unique<TReadBuffer>(std::forward<Types>(args)...);\n-        return std::make_unique<ZlibInflatingReadBuffer>(std::move(read_buf), method);\n-    }\n-    return std::make_unique<TReadBuffer>(args...);\n-}\n \n /** This function just copies the data from buffer's internal position (in.position())\n   * to current position (from arguments) into memory.\n   */\n-void saveUpToPosition(ReadBuffer & in, DB::Memory<> & memory, char * current);\n+void saveUpToPosition(ReadBuffer & in, Memory<> & memory, char * current);\n \n /** This function is negative to eof().\n   * In fact it returns whether the data was loaded to internal ReadBuffers's buffer or not.\n@@ -1047,6 +1028,6 @@ void saveUpToPosition(ReadBuffer & in, DB::Memory<> & memory, char * current);\n   * of our buffer and the current cursor in the end of the buffer. When we call eof() it calls next().\n   * And this function can fill the buffer with new data, so we will lose the data from previous buffer state.\n   */\n-bool loadAtPosition(ReadBuffer & in, DB::Memory<> & memory, char * & current);\n+bool loadAtPosition(ReadBuffer & in, Memory<> & memory, char * & current);\n \n }\ndiff --git a/dbms/src/IO/WriteBufferFromHTTPServerResponse.cpp b/dbms/src/IO/WriteBufferFromHTTPServerResponse.cpp\nindex f8bd166a4dde..24b7d905dcdf 100644\n--- a/dbms/src/IO/WriteBufferFromHTTPServerResponse.cpp\n+++ b/dbms/src/IO/WriteBufferFromHTTPServerResponse.cpp\n@@ -105,67 +105,41 @@ void WriteBufferFromHTTPServerResponse::nextImpl()\n         {\n             if (compress)\n             {\n-                if (compression_method == CompressionMethod::Gzip)\n-                {\n-#if defined(POCO_CLICKHOUSE_PATCH)\n-                    *response_header_ostr << \"Content-Encoding: gzip\\r\\n\";\n-#else\n-                    response.set(\"Content-Encoding\", \"gzip\");\n-                    response_body_ostr = &(response.send());\n-#endif\n-                    out_raw = std::make_unique<WriteBufferFromOStream>(*response_body_ostr);\n-                    deflating_buf.emplace(std::move(out_raw), compression_method, compression_level, working_buffer.size(), working_buffer.begin());\n-                    out = &*deflating_buf;\n-                }\n-                else if (compression_method == CompressionMethod::Zlib)\n-                {\n-#if defined(POCO_CLICKHOUSE_PATCH)\n-                    *response_header_ostr << \"Content-Encoding: deflate\\r\\n\";\n-#else\n-                    response.set(\"Content-Encoding\", \"deflate\");\n-                    response_body_ostr = &(response.send());\n-#endif\n-                    out_raw = std::make_unique<WriteBufferFromOStream>(*response_body_ostr);\n-                    deflating_buf.emplace(std::move(out_raw), compression_method, compression_level, working_buffer.size(), working_buffer.begin());\n-                    out = &*deflating_buf;\n-                }\n-#if USE_BROTLI\n-                else if (compression_method == CompressionMethod::Brotli)\n-                {\n+                auto content_encoding_name = toContentEncodingName(compression_method);\n+\n #if defined(POCO_CLICKHOUSE_PATCH)\n-                    *response_header_ostr << \"Content-Encoding: br\\r\\n\";\n+                *response_header_ostr << \"Content-Encoding: \" << content_encoding_name << \"\\r\\n\";\n #else\n-                    response.set(\"Content-Encoding\", \"br\");\n-                    response_body_ostr = &(response.send());\n+                response.set(\"Content-Encoding\", content_encoding_name);\n #endif\n-                    out_raw = std::make_unique<WriteBufferFromOStream>(*response_body_ostr);\n-                    brotli_buf.emplace(*out_raw, compression_level, working_buffer.size(), working_buffer.begin());\n-                    out = &*brotli_buf;\n-                }\n-#endif\n-\n-                else\n-                    throw Exception(\"Logical error: unknown compression method passed to WriteBufferFromHTTPServerResponse\",\n-                                    ErrorCodes::LOGICAL_ERROR);\n-                /// Use memory allocated for the outer buffer in the buffer pointed to by out. This avoids extra allocation and copy.\n             }\n-            else\n-            {\n+\n #if !defined(POCO_CLICKHOUSE_PATCH)\n-                response_body_ostr = &(response.send());\n+            response_body_ostr = &(response.send());\n #endif\n \n-                out_raw = std::make_unique<WriteBufferFromOStream>(*response_body_ostr, working_buffer.size(), working_buffer.begin());\n-                out = &*out_raw;\n-            }\n+            /// We reuse our buffer in \"out\" to avoid extra allocations and copies.\n+\n+            if (compress)\n+                out = wrapWriteBufferWithCompressionMethod(\n+                    std::make_unique<WriteBufferFromOStream>(*response_body_ostr),\n+                    compress ? compression_method : CompressionMethod::None,\n+                    compression_level,\n+                    working_buffer.size(),\n+                    working_buffer.begin());\n+            else\n+                out = std::make_unique<WriteBufferFromOStream>(\n+                    *response_body_ostr,\n+                    working_buffer.size(),\n+                    working_buffer.begin());\n         }\n \n         finishSendHeaders();\n-\n     }\n \n     if (out)\n     {\n+        out->buffer() = buffer();\n         out->position() = position();\n         out->next();\n     }\n@@ -177,9 +151,8 @@ WriteBufferFromHTTPServerResponse::WriteBufferFromHTTPServerResponse(\n     Poco::Net::HTTPServerResponse & response_,\n     unsigned keep_alive_timeout_,\n     bool compress_,\n-    CompressionMethod compression_method_,\n-    size_t size)\n-    : BufferWithOwnMemory<WriteBuffer>(size)\n+    CompressionMethod compression_method_)\n+    : BufferWithOwnMemory<WriteBuffer>(DBMS_DEFAULT_BUFFER_SIZE)\n     , request(request_)\n     , response(response_)\n     , keep_alive_timeout(keep_alive_timeout_)\ndiff --git a/dbms/src/IO/WriteBufferFromHTTPServerResponse.h b/dbms/src/IO/WriteBufferFromHTTPServerResponse.h\nindex 642e59e49212..f0b614c74063 100644\n--- a/dbms/src/IO/WriteBufferFromHTTPServerResponse.h\n+++ b/dbms/src/IO/WriteBufferFromHTTPServerResponse.h\n@@ -8,8 +8,6 @@\n #include <IO/WriteBuffer.h>\n #include <IO/BufferWithOwnMemory.h>\n #include <IO/WriteBufferFromOStream.h>\n-#include <IO/ZlibDeflatingWriteBuffer.h>\n-#include <IO/BrotliWriteBuffer.h>\n #include <IO/HTTPCommon.h>\n #include <IO/Progress.h>\n #include <Common/NetException.h>\n@@ -52,7 +50,7 @@ class WriteBufferFromHTTPServerResponse : public BufferWithOwnMemory<WriteBuffer\n     unsigned keep_alive_timeout = 0;\n     bool compress = false;\n     CompressionMethod compression_method;\n-    int compression_level = Z_DEFAULT_COMPRESSION;\n+    int compression_level = 1;\n \n     std::ostream * response_body_ostr = nullptr;\n \n@@ -60,13 +58,7 @@ class WriteBufferFromHTTPServerResponse : public BufferWithOwnMemory<WriteBuffer\n     std::ostream * response_header_ostr = nullptr;\n #endif\n \n-    std::unique_ptr<WriteBufferFromOStream> out_raw;\n-    std::optional<ZlibDeflatingWriteBuffer> deflating_buf;\n-#if USE_BROTLI\n-    std::optional<BrotliWriteBuffer> brotli_buf;\n-#endif\n-\n-    WriteBuffer * out = nullptr;     /// Uncompressed HTTP body is written to this buffer. Points to out_raw or possibly to deflating_buf.\n+    std::unique_ptr<WriteBuffer> out;\n \n     bool headers_started_sending = false;\n     bool headers_finished_sending = false;    /// If true, you could not add any headers.\n@@ -99,8 +91,7 @@ class WriteBufferFromHTTPServerResponse : public BufferWithOwnMemory<WriteBuffer\n         Poco::Net::HTTPServerResponse & response_,\n         unsigned keep_alive_timeout_,\n         bool compress_ = false,        /// If true - set Content-Encoding header and compress the result.\n-        CompressionMethod compression_method_ = CompressionMethod::Gzip,\n-        size_t size = DBMS_DEFAULT_BUFFER_SIZE);\n+        CompressionMethod compression_method_ = CompressionMethod::None);\n \n     /// Writes progess in repeating HTTP headers.\n     void onProgress(const Progress & progress);\ndiff --git a/dbms/src/IO/WriteHelpers.h b/dbms/src/IO/WriteHelpers.h\nindex 082bf63e6b75..328f7b030cce 100644\n--- a/dbms/src/IO/WriteHelpers.h\n+++ b/dbms/src/IO/WriteHelpers.h\n@@ -26,7 +26,6 @@\n #include <IO/VarInt.h>\n #include <IO/DoubleConverter.h>\n #include <IO/WriteBufferFromString.h>\n-#include <IO/ZlibDeflatingWriteBuffer.h>\n \n #include <Formats/FormatSettings.h>\n \n@@ -955,15 +954,4 @@ inline String toString(const T & x)\n     return buf.str();\n }\n \n-template <class TWriteBuffer, class... Types>\n-std::unique_ptr<WriteBuffer> getWriteBuffer(const DB::CompressionMethod method, Types&&... args)\n-{\n-    if (method == DB::CompressionMethod::Gzip)\n-    {\n-        auto write_buf = std::make_unique<TWriteBuffer>(std::forward<Types>(args)...);\n-        return std::make_unique<ZlibDeflatingWriteBuffer>(std::move(write_buf), method, 1 /* compression level */);\n-    }\n-    return std::make_unique<TWriteBuffer>(args...);\n-}\n-\n }\ndiff --git a/dbms/src/IO/ZlibDeflatingWriteBuffer.cpp b/dbms/src/IO/ZlibDeflatingWriteBuffer.cpp\nindex c4d7fac56a6c..8efe96877e43 100644\n--- a/dbms/src/IO/ZlibDeflatingWriteBuffer.cpp\n+++ b/dbms/src/IO/ZlibDeflatingWriteBuffer.cpp\n@@ -5,6 +5,12 @@\n namespace DB\n {\n \n+namespace ErrorCodes\n+{\n+    extern const int ZLIB_DEFLATE_FAILED;\n+}\n+\n+\n ZlibDeflatingWriteBuffer::ZlibDeflatingWriteBuffer(\n         std::unique_ptr<WriteBuffer> out_,\n         CompressionMethod compression_method,\n@@ -84,6 +90,21 @@ void ZlibDeflatingWriteBuffer::finish()\n \n     next();\n \n+    /// https://github.com/zlib-ng/zlib-ng/issues/494\n+    do\n+    {\n+        out->nextIfAtEnd();\n+        zstr.next_out = reinterpret_cast<unsigned char *>(out->position());\n+        zstr.avail_out = out->buffer().end() - out->position();\n+\n+        int rc = deflate(&zstr, Z_FULL_FLUSH);\n+        out->position() = out->buffer().end() - zstr.avail_out;\n+\n+        if (rc != Z_OK)\n+            throw Exception(std::string(\"deflate failed: \") + zError(rc), ErrorCodes::ZLIB_DEFLATE_FAILED);\n+    }\n+    while (zstr.avail_out == 0);\n+\n     while (true)\n     {\n         out->nextIfAtEnd();\ndiff --git a/dbms/src/IO/ZlibDeflatingWriteBuffer.h b/dbms/src/IO/ZlibDeflatingWriteBuffer.h\nindex 86eee1cffe55..f9df8f8157bd 100644\n--- a/dbms/src/IO/ZlibDeflatingWriteBuffer.h\n+++ b/dbms/src/IO/ZlibDeflatingWriteBuffer.h\n@@ -10,11 +10,6 @@\n namespace DB\n {\n \n-namespace ErrorCodes\n-{\n-    extern const int ZLIB_DEFLATE_FAILED;\n-}\n-\n /// Performs compression using zlib library and writes compressed data to out_ WriteBuffer.\n class ZlibDeflatingWriteBuffer : public BufferWithOwnMemory<WriteBuffer>\n {\ndiff --git a/dbms/src/Storages/IStorage.cpp b/dbms/src/Storages/IStorage.cpp\nindex 9dabfe0b604b..e48e98965974 100644\n--- a/dbms/src/Storages/IStorage.cpp\n+++ b/dbms/src/Storages/IStorage.cpp\n@@ -425,21 +425,4 @@ BlockInputStreams IStorage::read(\n     return res;\n }\n \n-DB::CompressionMethod IStorage::chooseCompressionMethod(const String & uri, const String & compression_method)\n-{\n-    if (compression_method == \"auto\" || compression_method == \"\")\n-    {\n-        if (endsWith(uri, \".gz\"))\n-            return DB::CompressionMethod::Gzip;\n-        else\n-            return DB::CompressionMethod::None;\n-    }\n-    else if (compression_method == \"gzip\")\n-        return DB::CompressionMethod::Gzip;\n-    else if (compression_method == \"none\")\n-        return DB::CompressionMethod::None;\n-    else\n-        throw Exception(\"Only auto, none, gzip supported as compression method\", ErrorCodes::NOT_IMPLEMENTED);\n-}\n-\n }\ndiff --git a/dbms/src/Storages/IStorage.h b/dbms/src/Storages/IStorage.h\nindex 8f8a363aec11..69bbca868798 100644\n--- a/dbms/src/Storages/IStorage.h\n+++ b/dbms/src/Storages/IStorage.h\n@@ -5,7 +5,6 @@\n #include <DataStreams/IBlockStream_fwd.h>\n #include <Databases/IDatabase.h>\n #include <Interpreters/CancellationCode.h>\n-#include <IO/CompressionMethod.h>\n #include <Storages/IStorage_fwd.h>\n #include <Storages/SelectQueryInfo.h>\n #include <Storages/TableStructureLockHolder.h>\n@@ -440,8 +439,6 @@ class IStorage : public std::enable_shared_from_this<IStorage>, public TypePromo\n         return {};\n     }\n \n-    static DB::CompressionMethod chooseCompressionMethod(const String & uri, const String & compression_method);\n-\n private:\n     /// You always need to take the next three locks in this order.\n \ndiff --git a/dbms/src/Storages/StorageFile.cpp b/dbms/src/Storages/StorageFile.cpp\nindex 64a603717e24..e640d08beb00 100644\n--- a/dbms/src/Storages/StorageFile.cpp\n+++ b/dbms/src/Storages/StorageFile.cpp\n@@ -23,6 +23,8 @@\n #include <Common/parseGlobs.h>\n \n #include <fcntl.h>\n+#include <unistd.h>\n+#include <sys/types.h>\n \n #include <Poco/Path.h>\n #include <Poco/File.h>\n@@ -39,6 +41,7 @@ namespace ErrorCodes\n {\n     extern const int CANNOT_WRITE_TO_FILE_DESCRIPTOR;\n     extern const int CANNOT_SEEK_THROUGH_FILE;\n+    extern const int CANNOT_TRUNCATE_FILE;\n     extern const int DATABASE_ACCESS_DENIED;\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n     extern const int UNKNOWN_IDENTIFIER;\n@@ -61,11 +64,13 @@ static std::vector<std::string> listFilesWithRegexpMatching(const std::string &\n     const std::string suffix_with_globs = for_match.substr(end_of_path_without_globs);   /// begin with '/'\n \n     const size_t next_slash = suffix_with_globs.find('/', 1);\n-    re2::RE2 matcher(makeRegexpPatternFromGlobs(suffix_with_globs.substr(0, next_slash)));\n+    auto regexp = makeRegexpPatternFromGlobs(suffix_with_globs.substr(0, next_slash));\n+    std::cerr << regexp << \"\\n\";\n+    re2::RE2 matcher(regexp);\n \n     std::vector<std::string> result;\n     const std::string prefix_without_globs = path_for_ls + for_match.substr(1, end_of_path_without_globs);\n-    if (!fs::exists(fs::path(prefix_without_globs.data())))\n+    if (!fs::exists(fs::path(prefix_without_globs)))\n     {\n         return result;\n     }\n@@ -110,11 +115,11 @@ static void checkCreationIsAllowed(const Context & context_global, const std::st\n \n     /// \"/dev/null\" is allowed for perf testing\n     if (!startsWith(table_path, db_dir_path) && table_path != \"/dev/null\")\n-        throw Exception(\"Part path \" + table_path + \" is not inside \" + db_dir_path, ErrorCodes::DATABASE_ACCESS_DENIED);\n+        throw Exception(\"File is not inside \" + db_dir_path, ErrorCodes::DATABASE_ACCESS_DENIED);\n \n     Poco::File table_path_poco_file = Poco::File(table_path);\n     if (table_path_poco_file.exists() && table_path_poco_file.isDirectory())\n-        throw Exception(\"File \" + table_path + \" must not be a directory\", ErrorCodes::INCORRECT_FILE_NAME);\n+        throw Exception(\"File must not be a directory\", ErrorCodes::INCORRECT_FILE_NAME);\n }\n }\n \n@@ -145,11 +150,10 @@ StorageFile::StorageFile(const std::string & table_path_, const std::string & us\n \n     const std::string path = poco_path.absolute().toString();\n     if (path.find_first_of(\"*?{\") == std::string::npos)\n-    {\n         paths.push_back(path);\n-    }\n     else\n         paths = listFilesWithRegexpMatching(\"/\", path);\n+\n     for (const auto & cur_path : paths)\n         checkCreationIsAllowed(args.context, user_files_absolute_path, cur_path);\n }\n@@ -200,12 +204,12 @@ class StorageFileBlockInputStream : public IBlockInputStream\n             }\n \n             storage->table_fd_was_used = true;\n-            read_buf = getReadBuffer<ReadBufferFromFileDescriptor>(compression_method, storage->table_fd);\n+            read_buf = wrapReadBufferWithCompressionMethod(std::make_unique<ReadBufferFromFileDescriptor>(storage->table_fd), compression_method);\n         }\n         else\n         {\n             shared_lock = std::shared_lock(storage->rwlock);\n-            read_buf = getReadBuffer<ReadBufferFromFile>(compression_method, file_path);\n+            read_buf = wrapReadBufferWithCompressionMethod(std::make_unique<ReadBufferFromFile>(file_path), compression_method);\n         }\n \n         reader = FormatFactory::instance().getInput(storage->format_name, *read_buf, storage->getSampleBlock(), context, max_block_size);\n@@ -266,7 +270,7 @@ BlockInputStreams StorageFile::read(\n     for (const auto & file_path : paths)\n     {\n         BlockInputStreamPtr cur_block = std::make_shared<StorageFileBlockInputStream>(\n-                std::static_pointer_cast<StorageFile>(shared_from_this()), context, max_block_size, file_path, IStorage::chooseCompressionMethod(file_path, compression_method));\n+            std::static_pointer_cast<StorageFile>(shared_from_this()), context, max_block_size, file_path, chooseCompressionMethod(file_path, compression_method));\n         blocks_input.push_back(column_defaults.empty() ? cur_block : std::make_shared<AddingDefaultsBlockInputStream>(cur_block, column_defaults, context));\n     }\n     return narrowBlockInputStreams(blocks_input, num_streams);\n@@ -288,13 +292,15 @@ class StorageFileBlockOutputStream : public IBlockOutputStream\n               * INSERT data; SELECT *; last SELECT returns only insert_data\n               */\n             storage.table_fd_was_used = true;\n-            write_buf = getWriteBuffer<WriteBufferFromFileDescriptor>(compression_method, storage.table_fd);\n+            write_buf = wrapWriteBufferWithCompressionMethod(std::make_unique<WriteBufferFromFileDescriptor>(storage.table_fd), compression_method, 3);\n         }\n         else\n         {\n             if (storage.paths.size() != 1)\n                 throw Exception(\"Table '\" + storage.table_name + \"' is in readonly mode because of globs in filepath\", ErrorCodes::DATABASE_ACCESS_DENIED);\n-            write_buf = getWriteBuffer<WriteBufferFromFile>(compression_method, storage.paths[0], DBMS_DEFAULT_BUFFER_SIZE, O_WRONLY | O_APPEND | O_CREAT);\n+            write_buf = wrapWriteBufferWithCompressionMethod(\n+                std::make_unique<WriteBufferFromFile>(storage.paths[0], DBMS_DEFAULT_BUFFER_SIZE, O_WRONLY | O_APPEND | O_CREAT),\n+                compression_method, 3);\n         }\n \n         writer = FormatFactory::instance().getOutput(storage.format_name, *write_buf, storage.getSampleBlock(), context);\n@@ -333,8 +339,7 @@ BlockOutputStreamPtr StorageFile::write(\n     const ASTPtr & /*query*/,\n     const Context & context)\n {\n-    return std::make_shared<StorageFileBlockOutputStream>(*this,\n-        IStorage::chooseCompressionMethod(paths[0], compression_method), context);\n+    return std::make_shared<StorageFileBlockOutputStream>(*this, chooseCompressionMethod(paths[0], compression_method), context);\n }\n \n Strings StorageFile::getDataPaths() const\n@@ -363,6 +368,28 @@ void StorageFile::rename(const String & new_path_to_table_data, const String & n\n     database_name = new_database_name;\n }\n \n+void StorageFile::truncate(const ASTPtr & /*query*/, const Context & /* context */, TableStructureWriteLockHolder &)\n+{\n+    if (paths.size() != 1)\n+        throw Exception(\"Can't truncate table '\" + table_name + \"' in readonly mode\", ErrorCodes::DATABASE_ACCESS_DENIED);\n+\n+    std::unique_lock<std::shared_mutex> lock(rwlock);\n+\n+    if (use_table_fd)\n+    {\n+        if (0 != ::ftruncate(table_fd, 0))\n+            throwFromErrno(\"Cannot truncate file at fd \" + toString(table_fd), ErrorCodes::CANNOT_TRUNCATE_FILE);\n+    }\n+    else\n+    {\n+        if (!Poco::File(paths[0]).exists())\n+            return;\n+\n+        if (0 != ::truncate(paths[0].c_str(), 0))\n+            throwFromErrnoWithPath(\"Cannot truncate file \" + paths[0], paths[0], ErrorCodes::CANNOT_TRUNCATE_FILE);\n+    }\n+}\n+\n \n void registerStorageFile(StorageFactory & factory)\n {\ndiff --git a/dbms/src/Storages/StorageFile.h b/dbms/src/Storages/StorageFile.h\nindex e3871166f03c..23a6d6e7ff5a 100644\n--- a/dbms/src/Storages/StorageFile.h\n+++ b/dbms/src/Storages/StorageFile.h\n@@ -38,6 +38,8 @@ class StorageFile : public ext::shared_ptr_helper<StorageFile>, public IStorage\n         const ASTPtr & query,\n         const Context & context) override;\n \n+    void truncate(const ASTPtr & /*query*/, const Context & /* context */, TableStructureWriteLockHolder &) override;\n+\n     void rename(const String & new_path_to_table_data, const String & new_database_name, const String & new_table_name, TableStructureWriteLockHolder &) override;\n \n     Strings getDataPaths() const override;\ndiff --git a/dbms/src/Storages/StorageHDFS.cpp b/dbms/src/Storages/StorageHDFS.cpp\nindex 3f1386cca5e2..8e5db9100926 100644\n--- a/dbms/src/Storages/StorageHDFS.cpp\n+++ b/dbms/src/Storages/StorageHDFS.cpp\n@@ -67,7 +67,7 @@ class HDFSBlockInputStream : public IBlockInputStream\n         UInt64 max_block_size,\n         const CompressionMethod compression_method)\n     {\n-        auto read_buf = getReadBuffer<ReadBufferFromHDFS>(compression_method, uri);\n+        auto read_buf = wrapReadBufferWithCompressionMethod(std::make_unique<ReadBufferFromHDFS>(uri), compression_method);\n \n         auto input_stream = FormatFactory::instance().getInput(format, *read_buf, sample_block, context, max_block_size);\n         reader = std::make_shared<OwningBlockInputStream<ReadBuffer>>(input_stream, std::move(read_buf));\n@@ -112,7 +112,7 @@ class HDFSBlockOutputStream : public IBlockOutputStream\n         const CompressionMethod compression_method)\n         : sample_block(sample_block_)\n     {\n-        write_buf = getWriteBuffer<WriteBufferFromHDFS>(compression_method, uri);\n+        write_buf = wrapWriteBufferWithCompressionMethod(std::make_unique<WriteBufferFromHDFS>(uri), compression_method, 3);\n         writer = FormatFactory::instance().getOutput(format, *write_buf, sample_block, context);\n     }\n \n@@ -213,7 +213,7 @@ BlockInputStreams StorageHDFS::read(\n     for (const auto & res_path : res_paths)\n     {\n         result.push_back(std::make_shared<HDFSBlockInputStream>(uri_without_path + res_path, format_name, getSampleBlock(), context_,\n-                                                               max_block_size, IStorage::chooseCompressionMethod(res_path, compression_method)));\n+                                                               max_block_size, chooseCompressionMethod(res_path, compression_method)));\n     }\n \n     return narrowBlockInputStreams(result, num_streams);\n@@ -231,7 +231,7 @@ BlockOutputStreamPtr StorageHDFS::write(const ASTPtr & /*query*/, const Context\n         format_name,\n         getSampleBlock(),\n         context,\n-        IStorage::chooseCompressionMethod(uri, compression_method));\n+        chooseCompressionMethod(uri, compression_method));\n }\n \n void registerStorageHDFS(StorageFactory & factory)\ndiff --git a/dbms/src/Storages/StorageS3.cpp b/dbms/src/Storages/StorageS3.cpp\nindex cf0b3df44fd3..14732a291b1d 100644\n--- a/dbms/src/Storages/StorageS3.cpp\n+++ b/dbms/src/Storages/StorageS3.cpp\n@@ -49,7 +49,7 @@ namespace\n             const String & key)\n             : name(name_)\n         {\n-            read_buf = getReadBuffer<ReadBufferFromS3>(compression_method, client, bucket, key);\n+            read_buf = wrapReadBufferWithCompressionMethod(std::make_unique<ReadBufferFromS3>(client, bucket, key), compression_method);\n             reader = FormatFactory::instance().getInput(format, *read_buf, sample_block, context, max_block_size);\n         }\n \n@@ -98,7 +98,8 @@ namespace\n             const String & key)\n             : sample_block(sample_block_)\n         {\n-            write_buf = getWriteBuffer<WriteBufferFromS3>(compression_method, client, bucket, key, min_upload_part_size);\n+            write_buf = wrapWriteBufferWithCompressionMethod(\n+                std::make_unique<WriteBufferFromS3>(client, bucket, key, min_upload_part_size), compression_method, 3);\n             writer = FormatFactory::instance().getOutput(format, *write_buf, sample_block, context);\n         }\n \n@@ -173,7 +174,7 @@ BlockInputStreams StorageS3::read(\n         getHeaderBlock(column_names),\n         context,\n         max_block_size,\n-        IStorage::chooseCompressionMethod(uri.endpoint, compression_method),\n+        chooseCompressionMethod(uri.endpoint, compression_method),\n         client,\n         uri.bucket,\n         uri.key);\n@@ -194,7 +195,7 @@ BlockOutputStreamPtr StorageS3::write(const ASTPtr & /*query*/, const Context &\n {\n     return std::make_shared<StorageS3BlockOutputStream>(\n         format_name, min_upload_part_size, getSampleBlock(), context_global,\n-        IStorage::chooseCompressionMethod(uri.endpoint, compression_method),\n+        chooseCompressionMethod(uri.endpoint, compression_method),\n         client, uri.bucket, uri.key);\n }\n \ndiff --git a/dbms/src/Storages/StorageURL.cpp b/dbms/src/Storages/StorageURL.cpp\nindex 907e18b21cf5..efe15dc19281 100644\n--- a/dbms/src/Storages/StorageURL.cpp\n+++ b/dbms/src/Storages/StorageURL.cpp\n@@ -60,17 +60,18 @@ namespace\n             const CompressionMethod compression_method)\n             : name(name_)\n         {\n-            read_buf = getReadBuffer<ReadWriteBufferFromHTTP>(\n-                compression_method,\n-                uri,\n-                method,\n-                callback,\n-                timeouts,\n-                context.getSettingsRef().max_http_get_redirects,\n-                Poco::Net::HTTPBasicCredentials{},\n-                DBMS_DEFAULT_BUFFER_SIZE,\n-                ReadWriteBufferFromHTTP::HTTPHeaderEntries{},\n-                context.getRemoteHostFilter());\n+            read_buf = wrapReadBufferWithCompressionMethod(\n+                std::make_unique<ReadWriteBufferFromHTTP>(\n+                    uri,\n+                    method,\n+                    callback,\n+                    timeouts,\n+                    context.getSettingsRef().max_http_get_redirects,\n+                    Poco::Net::HTTPBasicCredentials{},\n+                    DBMS_DEFAULT_BUFFER_SIZE,\n+                    ReadWriteBufferFromHTTP::HTTPHeaderEntries{},\n+                    context.getRemoteHostFilter()),\n+                compression_method);\n \n             reader = FormatFactory::instance().getInput(format, *read_buf, sample_block, context, max_block_size);\n         }\n@@ -117,7 +118,9 @@ namespace\n             const CompressionMethod compression_method)\n             : sample_block(sample_block_)\n         {\n-            write_buf = getWriteBuffer<WriteBufferFromHTTP>(compression_method, uri, Poco::Net::HTTPRequest::HTTP_POST, timeouts);\n+            write_buf = wrapWriteBufferWithCompressionMethod(\n+                std::make_unique<WriteBufferFromHTTP>(uri, Poco::Net::HTTPRequest::HTTP_POST, timeouts),\n+                compression_method, 3);\n             writer = FormatFactory::instance().getOutput(format, *write_buf, sample_block, context);\n         }\n \n@@ -196,7 +199,7 @@ BlockInputStreams IStorageURLBase::read(const Names & column_names,\n         context,\n         max_block_size,\n         ConnectionTimeouts::getHTTPTimeouts(context),\n-        IStorage::chooseCompressionMethod(request_uri.getPath(), compression_method));\n+        chooseCompressionMethod(request_uri.getPath(), compression_method));\n \n     auto column_defaults = getColumns().getDefaults();\n     if (column_defaults.empty())\n@@ -215,7 +218,7 @@ BlockOutputStreamPtr IStorageURLBase::write(const ASTPtr & /*query*/, const Cont\n     return std::make_shared<StorageURLBlockOutputStream>(\n         uri, format_name, getSampleBlock(), context_global,\n         ConnectionTimeouts::getHTTPTimeouts(context_global),\n-        IStorage::chooseCompressionMethod(uri.toString(), compression_method));\n+        chooseCompressionMethod(uri.toString(), compression_method));\n }\n \n void registerStorageURL(StorageFactory & factory)\ndiff --git a/dbms/src/Storages/StorageXDBC.cpp b/dbms/src/Storages/StorageXDBC.cpp\nindex 222eebd63771..0dcbf372b28f 100644\n--- a/dbms/src/Storages/StorageXDBC.cpp\n+++ b/dbms/src/Storages/StorageXDBC.cpp\n@@ -7,7 +7,6 @@\n #include <Poco/Util/AbstractConfiguration.h>\n #include <common/logger_useful.h>\n #include <Formats/FormatFactory.h>\n-#include <IO/CompressionMethod.h>\n #include <IO/ReadHelpers.h>\n #include <IO/ReadWriteBufferFromHTTP.h>\n #include <Poco/File.h>\ndiff --git a/dbms/src/TableFunctions/ITableFunctionFileLike.cpp b/dbms/src/TableFunctions/ITableFunctionFileLike.cpp\nindex 3e0ddafaa906..7b1d342a64a6 100644\n--- a/dbms/src/TableFunctions/ITableFunctionFileLike.cpp\n+++ b/dbms/src/TableFunctions/ITableFunctionFileLike.cpp\n@@ -42,12 +42,10 @@ StoragePtr ITableFunctionFileLike::executeImpl(const ASTPtr & ast_function, cons\n     std::string filename = args[0]->as<ASTLiteral &>().value.safeGet<String>();\n     std::string format = args[1]->as<ASTLiteral &>().value.safeGet<String>();\n     std::string structure = args[2]->as<ASTLiteral &>().value.safeGet<String>();\n-    std::string compression_method;\n+    std::string compression_method = \"auto\";\n \n     if (args.size() == 4)\n-    {\n         compression_method = args[3]->as<ASTLiteral &>().value.safeGet<String>();\n-    } else compression_method = \"auto\";\n \n     ColumnsDescription columns = parseColumnsListFromString(structure, context);\n \n",
  "test_patch": "diff --git a/dbms/src/IO/tests/CMakeLists.txt b/dbms/src/IO/tests/CMakeLists.txt\nindex 38802718dd1d..40defb504705 100644\n--- a/dbms/src/IO/tests/CMakeLists.txt\n+++ b/dbms/src/IO/tests/CMakeLists.txt\n@@ -78,7 +78,4 @@ add_executable (parse_date_time_best_effort parse_date_time_best_effort.cpp)\n target_link_libraries (parse_date_time_best_effort PRIVATE clickhouse_common_io)\n \n add_executable (zlib_ng_bug zlib_ng_bug.cpp)\n-target_link_libraries (zlib_ng_bug PRIVATE ${Poco_Foundation_LIBRARY})\n-if(NOT USE_INTERNAL_POCO_LIBRARY)\n-    target_include_directories(zlib_ng_bug SYSTEM BEFORE PRIVATE ${Poco_INCLUDE_DIRS})\n-endif()\n+target_link_libraries (zlib_ng_bug PRIVATE ${Poco_Foundation_LIBRARY} ${ZLIB_LIBRARY})\ndiff --git a/dbms/src/IO/tests/zlib_ng_bug.cpp b/dbms/src/IO/tests/zlib_ng_bug.cpp\nindex 8b94b4e49d26..e9b3c448b888 100644\n--- a/dbms/src/IO/tests/zlib_ng_bug.cpp\n+++ b/dbms/src/IO/tests/zlib_ng_bug.cpp\n@@ -1,32 +1,50 @@\n-#include <Poco/FileStream.h>\n-#include <Poco/NullStream.h>\n-#include <Poco/StreamCopier.h>\n-#include <Poco/DeflatingStream.h>\n-\n-/** This script reproduces the bug in zlib-ng library.\n-  * Put the following content to \"data.bin\" file:\n-abcdefghijklmn!@Aab#AAabcdefghijklmn$%\n-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n-  * There are two lines. First line make sense. Second line contains padding to make file size large enough.\n-  * Compile with\n-  *  cmake -D SANITIZE=address\n-  * and run:\n-\n-./zlib_ng_bug data2.bin\n-=================================================================\n-==204952==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x6310000147ff at pc 0x000000596d7a bp 0x7ffd139edd50 sp 0x7ffd139edd48\n-READ of size 1 at 0x6310000147ff thread T0\n-  */\n-\n-int main(int argc, char ** argv)\n+#include <unistd.h>\n+#include <vector>\n+#include <stdexcept>\n+#include <zlib.h>\n+\n+#pragma GCC diagnostic ignored \"-Wold-style-cast\"\n+\n+\n+/// https://github.com/zlib-ng/zlib-ng/issues/494\n+int main(int, char **)\n {\n-    using namespace Poco;\n+    std::vector<unsigned char> in(1048576);\n+    std::vector<unsigned char> out(1048576);\n+\n+    ssize_t in_size = read(STDIN_FILENO, in.data(), 1048576);\n+    if (in_size < 0)\n+        throw std::runtime_error(\"Cannot read\");\n+    in.resize(in_size);\n+\n+    z_stream zstr{};\n+    if (Z_OK != deflateInit2(&zstr, 1, Z_DEFLATED, 15 + 16, 8, Z_DEFAULT_STRATEGY))\n+        throw std::runtime_error(\"Cannot deflateInit2\");\n+\n+    zstr.next_in = in.data();\n+    zstr.avail_in = in.size();\n+    zstr.next_out = out.data();\n+    zstr.avail_out = out.size();\n+\n+    while (zstr.avail_in > 0)\n+        if (Z_OK != deflate(&zstr, Z_NO_FLUSH))\n+            throw std::runtime_error(\"Cannot deflate\");\n+\n+    while (true)\n+    {\n+        int rc = deflate(&zstr, Z_FINISH);\n+\n+        if (rc == Z_STREAM_END)\n+            break;\n+\n+        if (rc != Z_OK)\n+            throw std::runtime_error(\"Cannot finish deflate\");\n+    }\n+\n+    deflateEnd(&zstr);\n \n-    std::string filename(argc >= 2 ? argv[1] : \"data.bin\");\n-    FileInputStream istr(filename);\n-    NullOutputStream ostr;\n-    DeflatingOutputStream deflater(ostr, DeflatingStreamBuf::STREAM_GZIP);\n-    StreamCopier::copyStream(istr, deflater);\n+    if (ssize_t(zstr.total_out) != write(STDOUT_FILENO, out.data(), zstr.total_out))\n+        throw std::runtime_error(\"Cannot write\");\n \n     return 0;\n }\ndiff --git a/dbms/tests/queries/0_stateless/01057_http_compression_prefer_brotli.reference b/dbms/tests/queries/0_stateless/01057_http_compression_prefer_brotli.reference\nnew file mode 100644\nindex 000000000000..5dd396a38c97\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/01057_http_compression_prefer_brotli.reference\n@@ -0,0 +1,11 @@\n+1\n+1\n+1\n+1\n+1\n+999997\n+999998\n+999999\n+999997\n+999998\n+999999\ndiff --git a/dbms/tests/queries/0_stateless/01057_http_compression_prefer_brotli.sh b/dbms/tests/queries/0_stateless/01057_http_compression_prefer_brotli.sh\nnew file mode 100755\nindex 000000000000..419f774e5020\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/01057_http_compression_prefer_brotli.sh\n@@ -0,0 +1,12 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: br'              \"${CLICKHOUSE_URL}&enable_http_compression=1\" -d 'SELECT 1' | brotli -d\n+${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: br,gzip'         \"${CLICKHOUSE_URL}&enable_http_compression=1\" -d 'SELECT 1' | brotli -d\n+${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: gzip,br'         \"${CLICKHOUSE_URL}&enable_http_compression=1\" -d 'SELECT 1' | brotli -d\n+${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: gzip,deflate,br' \"${CLICKHOUSE_URL}&enable_http_compression=1\" -d 'SELECT 1' | brotli -d\n+${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: gzip,deflate'    \"${CLICKHOUSE_URL}&enable_http_compression=1\" -d 'SELECT 1' | gzip -d\n+${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: gzip'            \"${CLICKHOUSE_URL}&enable_http_compression=1\" -d 'SELECT number FROM numbers(1000000)' | gzip -d | tail -n3\n+${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: br'              \"${CLICKHOUSE_URL}&enable_http_compression=1\" -d 'SELECT number FROM numbers(1000000)' | brotli -d | tail -n3\ndiff --git a/dbms/tests/queries/0_stateless/01058_zlib_ng_level1_bug.reference b/dbms/tests/queries/0_stateless/01058_zlib_ng_level1_bug.reference\nnew file mode 100644\nindex 000000000000..1036eecb9b0d\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/01058_zlib_ng_level1_bug.reference\n@@ -0,0 +1,101 @@\n+34529\n+34530\n+34531\n+34532\n+34533\n+34534\n+34535\n+34536\n+34537\n+34538\n+34539\n+34540\n+34541\n+34542\n+34543\n+34544\n+34545\n+34546\n+34547\n+34548\n+34549\n+34550\n+34551\n+34552\n+34553\n+34554\n+34555\n+34556\n+34557\n+34558\n+34559\n+34560\n+34561\n+34562\n+34563\n+34564\n+34565\n+34566\n+34567\n+34568\n+34569\n+34570\n+34571\n+34572\n+34573\n+34574\n+34575\n+34576\n+34577\n+34578\n+34579\n+34580\n+34581\n+34582\n+34583\n+34584\n+34585\n+34586\n+34587\n+34588\n+34589\n+34590\n+34591\n+34592\n+34593\n+34594\n+34595\n+34596\n+34597\n+34598\n+34599\n+34600\n+34601\n+34602\n+34603\n+34604\n+34605\n+34606\n+34607\n+34608\n+34609\n+34610\n+34611\n+34612\n+34613\n+34614\n+34615\n+34616\n+34617\n+34618\n+34619\n+34620\n+34621\n+34622\n+34623\n+34624\n+34625\n+34626\n+34627\n+34628\n+34629\ndiff --git a/dbms/tests/queries/0_stateless/01058_zlib_ng_level1_bug.sh b/dbms/tests/queries/0_stateless/01058_zlib_ng_level1_bug.sh\nnew file mode 100755\nindex 000000000000..f554aec4fcac\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/01058_zlib_ng_level1_bug.sh\n@@ -0,0 +1,6 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+for i in $(seq 34530 1 34630); do ${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: gzip' \"${CLICKHOUSE_URL}&enable_http_compression=1&http_zlib_compression_level=1\" -d \"SELECT * FROM numbers($i)\" | gzip -d | tail -n1; done\ndiff --git a/dbms/tests/queries/0_stateless/01059_storage_file_brotli.reference b/dbms/tests/queries/0_stateless/01059_storage_file_brotli.reference\nnew file mode 100644\nindex 000000000000..6c545e9faec1\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/01059_storage_file_brotli.reference\n@@ -0,0 +1,5 @@\n+1000000\t999999\n+1000000\t999999\n+2000000\t999999\n+1\t255\n+1\t255\ndiff --git a/dbms/tests/queries/0_stateless/01059_storage_file_brotli.sql b/dbms/tests/queries/0_stateless/01059_storage_file_brotli.sql\nnew file mode 100644\nindex 000000000000..e7d5a87b2aff\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/01059_storage_file_brotli.sql\n@@ -0,0 +1,22 @@\n+DROP TABLE IF EXISTS file;\n+CREATE TABLE file (x UInt64) ENGINE = File(TSV, 'data1.tsv.br');\n+TRUNCATE TABLE file;\n+\n+INSERT INTO file SELECT * FROM numbers(1000000);\n+SELECT count(), max(x) FROM file;\n+\n+DROP TABLE file;\n+\n+CREATE TABLE file (x UInt64) ENGINE = File(TSV, 'data2.tsv.gz');\n+TRUNCATE TABLE file;\n+\n+INSERT INTO file SELECT * FROM numbers(1000000);\n+SELECT count(), max(x) FROM file;\n+\n+DROP TABLE file;\n+\n+SELECT count(), max(x) FROM file('data{1,2}.tsv.{gz,br}', TSV, 'x UInt64');\n+\n+-- check that they are compressed\n+SELECT count() < 1000000, max(x) FROM file('data1.tsv.br', RowBinary, 'x UInt8', 'none');\n+SELECT count() < 3000000, max(x) FROM file('data2.tsv.gz', RowBinary, 'x UInt8', 'none');\n",
  "problem_statement": "Compressed files for external data sources: support for Brotli.\n\n",
  "hints_text": "",
  "created_at": "2020-01-04T07:36:10Z",
  "modified_files": [
    "contrib/zlib-ng",
    "dbms/programs/server/HTTPHandler.cpp",
    "dbms/src/IO/BrotliWriteBuffer.cpp",
    "dbms/src/IO/BrotliWriteBuffer.h",
    "b/dbms/src/IO/CompressionMethod.cpp",
    "dbms/src/IO/CompressionMethod.h",
    "dbms/src/IO/ReadHelpers.h",
    "dbms/src/IO/WriteBufferFromHTTPServerResponse.cpp",
    "dbms/src/IO/WriteBufferFromHTTPServerResponse.h",
    "dbms/src/IO/WriteHelpers.h",
    "dbms/src/IO/ZlibDeflatingWriteBuffer.cpp",
    "dbms/src/IO/ZlibDeflatingWriteBuffer.h",
    "dbms/src/Storages/IStorage.cpp",
    "dbms/src/Storages/IStorage.h",
    "dbms/src/Storages/StorageFile.cpp",
    "dbms/src/Storages/StorageFile.h",
    "dbms/src/Storages/StorageHDFS.cpp",
    "dbms/src/Storages/StorageS3.cpp",
    "dbms/src/Storages/StorageURL.cpp",
    "dbms/src/Storages/StorageXDBC.cpp",
    "dbms/src/TableFunctions/ITableFunctionFileLike.cpp"
  ],
  "modified_test_files": [
    "dbms/src/IO/tests/CMakeLists.txt",
    "dbms/src/IO/tests/zlib_ng_bug.cpp",
    "b/dbms/tests/queries/0_stateless/01057_http_compression_prefer_brotli.reference",
    "b/dbms/tests/queries/0_stateless/01057_http_compression_prefer_brotli.sh",
    "b/dbms/tests/queries/0_stateless/01058_zlib_ng_level1_bug.reference",
    "b/dbms/tests/queries/0_stateless/01058_zlib_ng_level1_bug.sh",
    "b/dbms/tests/queries/0_stateless/01059_storage_file_brotli.reference",
    "b/dbms/tests/queries/0_stateless/01059_storage_file_brotli.sql"
  ]
}