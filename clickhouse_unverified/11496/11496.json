{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 11496,
  "instance_id": "ClickHouse__ClickHouse-11496",
  "issue_numbers": [
    "8995"
  ],
  "base_commit": "0d4725776956d7cac6ca0dd90272c015a3db04b1",
  "patch": "diff --git a/src/Interpreters/Aggregator.cpp b/src/Interpreters/Aggregator.cpp\nindex e7f6f16b91dc..538a24fa9976 100644\n--- a/src/Interpreters/Aggregator.cpp\n+++ b/src/Interpreters/Aggregator.cpp\n@@ -999,6 +999,73 @@ void Aggregator::convertToBlockImpl(\n     data.clearAndShrink();\n }\n \n+\n+template <typename Mapped>\n+inline void Aggregator::insertAggregatesIntoColumns(\n+    Mapped & mapped,\n+    MutableColumns & final_aggregate_columns) const\n+{\n+    /** Final values of aggregate functions are inserted to columns.\n+      * Then states of aggregate functions, that are not longer needed, are destroyed.\n+      *\n+      * We mark already destroyed states with \"nullptr\" in data,\n+      *  so they will not be destroyed in destructor of Aggregator\n+      * (other values will be destroyed in destructor in case of exception).\n+      *\n+      * But it becomes tricky, because we have multiple aggregate states pointed by a single pointer in data.\n+      * So, if exception is thrown in the middle of moving states for different aggregate functions,\n+      *  we have to catch exceptions and destroy all the states that are no longer needed,\n+      *  to keep the data in consistent state.\n+      *\n+      * It is also tricky, because there are aggregate functions with \"-State\" modifier.\n+      * When we call \"insertResultInto\" for them, they insert a pointer to the state to ColumnAggregateFunction\n+      *  and ColumnAggregateFunction will take ownership of this state.\n+      * So, for aggregate functions with \"-State\" modifier, the state must not be destroyed\n+      *  after it has been transferred to ColumnAggregateFunction.\n+      * But we should mark that the data no longer owns these states.\n+      */\n+\n+    size_t insert_i = 0;\n+    std::exception_ptr exception;\n+\n+    try\n+    {\n+        /// Insert final values of aggregate functions into columns.\n+        for (; insert_i < params.aggregates_size; ++insert_i)\n+            aggregate_functions[insert_i]->insertResultInto(\n+                mapped + offsets_of_aggregate_states[insert_i],\n+                *final_aggregate_columns[insert_i]);\n+    }\n+    catch (...)\n+    {\n+        exception = std::current_exception();\n+    }\n+\n+    /** Destroy states that are no longer needed. This loop does not throw.\n+        *\n+        * Don't destroy states for \"-State\" aggregate functions,\n+        *  because the ownership of this state is transferred to ColumnAggregateFunction\n+        *  and ColumnAggregateFunction will take care.\n+        *\n+        * But it's only for states that has been transferred to ColumnAggregateFunction\n+        *  before exception has been thrown;\n+        */\n+    for (size_t destroy_i = 0; destroy_i < params.aggregates_size; ++destroy_i)\n+    {\n+        /// If ownership was not transferred to ColumnAggregateFunction.\n+        if (!(destroy_i < insert_i && aggregate_functions[destroy_i]->isState()))\n+            aggregate_functions[destroy_i]->destroy(\n+                mapped + offsets_of_aggregate_states[destroy_i]);\n+    }\n+\n+    /// Mark the cell as destroyed so it will not be destroyed in destructor.\n+    mapped = nullptr;\n+\n+    if (exception)\n+        std::rethrow_exception(exception);\n+}\n+\n+\n template <typename Method, typename Table>\n void NO_INLINE Aggregator::convertToBlockImplFinal(\n     Method & method,\n@@ -1011,25 +1078,15 @@ void NO_INLINE Aggregator::convertToBlockImplFinal(\n         if (data.hasNullKeyData())\n         {\n             key_columns[0]->insertDefault();\n-\n-            for (size_t i = 0; i < params.aggregates_size; ++i)\n-                aggregate_functions[i]->insertResultInto(\n-                    data.getNullKeyData() + offsets_of_aggregate_states[i],\n-                    *final_aggregate_columns[i]);\n+            insertAggregatesIntoColumns(data.getNullKeyData(), final_aggregate_columns);\n         }\n     }\n \n     data.forEachValue([&](const auto & key, auto & mapped)\n     {\n         method.insertKeyIntoColumns(key, key_columns, key_sizes);\n-\n-        for (size_t i = 0; i < params.aggregates_size; ++i)\n-            aggregate_functions[i]->insertResultInto(\n-                mapped + offsets_of_aggregate_states[i],\n-                *final_aggregate_columns[i]);\n+        insertAggregatesIntoColumns(mapped, final_aggregate_columns);\n     });\n-\n-    destroyImpl<Method>(data);\n }\n \n template <typename Method, typename Table>\n@@ -1047,6 +1104,8 @@ void NO_INLINE Aggregator::convertToBlockImplNotFinal(\n \n             for (size_t i = 0; i < params.aggregates_size; ++i)\n                 aggregate_columns[i]->push_back(data.getNullKeyData() + offsets_of_aggregate_states[i]);\n+\n+            data.getNullKeyData() = nullptr;\n         }\n     }\n \n@@ -1187,16 +1246,16 @@ Block Aggregator::prepareBlockAndFillWithoutKey(AggregatedDataVariants & data_va\n         {\n             AggregatedDataWithoutKey & data = data_variants.without_key;\n \n-            for (size_t i = 0; i < params.aggregates_size; ++i)\n+            if (!final_)\n             {\n-                if (!final_)\n+                for (size_t i = 0; i < params.aggregates_size; ++i)\n                     aggregate_columns[i]->push_back(data + offsets_of_aggregate_states[i]);\n-                else\n-                    aggregate_functions[i]->insertResultInto(data + offsets_of_aggregate_states[i], *final_aggregate_columns[i]);\n-            }\n-\n-            if (!final_)\n                 data = nullptr;\n+            }\n+            else\n+            {\n+                insertAggregatesIntoColumns(data, final_aggregate_columns);\n+            }\n \n             if (params.overflow_row)\n                 for (size_t i = 0; i < params.keys_size; ++i)\n@@ -2387,8 +2446,7 @@ void NO_INLINE Aggregator::destroyImpl(Table & table) const\n             return;\n \n         for (size_t i = 0; i < params.aggregates_size; ++i)\n-            if (!aggregate_functions[i]->isState())\n-                aggregate_functions[i]->destroy(data + offsets_of_aggregate_states[i]);\n+            aggregate_functions[i]->destroy(data + offsets_of_aggregate_states[i]);\n \n         data = nullptr;\n     });\n@@ -2402,8 +2460,7 @@ void Aggregator::destroyWithoutKey(AggregatedDataVariants & result) const\n     if (nullptr != res_data)\n     {\n         for (size_t i = 0; i < params.aggregates_size; ++i)\n-            if (!aggregate_functions[i]->isState())\n-                aggregate_functions[i]->destroy(res_data + offsets_of_aggregate_states[i]);\n+            aggregate_functions[i]->destroy(res_data + offsets_of_aggregate_states[i]);\n \n         res_data = nullptr;\n     }\ndiff --git a/src/Interpreters/Aggregator.h b/src/Interpreters/Aggregator.h\nindex a5d79ce46dcd..6d0eeee90143 100644\n--- a/src/Interpreters/Aggregator.h\n+++ b/src/Interpreters/Aggregator.h\n@@ -1166,6 +1166,11 @@ class Aggregator\n         MutableColumns & final_aggregate_columns,\n         bool final) const;\n \n+    template <typename Mapped>\n+    void insertAggregatesIntoColumns(\n+        Mapped & mapped,\n+        MutableColumns & final_aggregate_columns) const;\n+\n     template <typename Method, typename Table>\n     void convertToBlockImplFinal(\n         Method & method,\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01301_aggregate_state_exception_memory_leak.reference b/tests/queries/0_stateless/01301_aggregate_state_exception_memory_leak.reference\nnew file mode 100644\nindex 000000000000..b20e7415f52d\n--- /dev/null\n+++ b/tests/queries/0_stateless/01301_aggregate_state_exception_memory_leak.reference\n@@ -0,0 +1,2 @@\n+Memory limit (for query) exceeded\n+Ok\ndiff --git a/tests/queries/0_stateless/01301_aggregate_state_exception_memory_leak.sh b/tests/queries/0_stateless/01301_aggregate_state_exception_memory_leak.sh\nnew file mode 100755\nindex 000000000000..633fa5ce315a\n--- /dev/null\n+++ b/tests/queries/0_stateless/01301_aggregate_state_exception_memory_leak.sh\n@@ -0,0 +1,17 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+function test()\n+{\n+    for i in {1..1000}; do\n+        $CLICKHOUSE_CLIENT --max_memory_usage 1G <<< \"SELECT uniqExactState(number) FROM system.numbers_mt GROUP BY number % 10\";\n+    done\n+}\n+\n+export -f test;\n+\n+# If the memory leak exists, it will lead to OOM fairly quickly.\n+timeout 30 bash -c test 2>&1 | grep -o -F 'Memory limit (for query) exceeded' | uniq\n+echo 'Ok'\ndiff --git a/tests/queries/0_stateless/01302_aggregate_state_exception_memory_leak.reference b/tests/queries/0_stateless/01302_aggregate_state_exception_memory_leak.reference\nnew file mode 100644\nindex 000000000000..7326d9603970\n--- /dev/null\n+++ b/tests/queries/0_stateless/01302_aggregate_state_exception_memory_leak.reference\n@@ -0,0 +1,1 @@\n+Ok\ndiff --git a/tests/queries/0_stateless/01302_aggregate_state_exception_memory_leak.sh b/tests/queries/0_stateless/01302_aggregate_state_exception_memory_leak.sh\nnew file mode 100755\nindex 000000000000..cd2fec408abf\n--- /dev/null\n+++ b/tests/queries/0_stateless/01302_aggregate_state_exception_memory_leak.sh\n@@ -0,0 +1,16 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+function test()\n+{\n+    for i in {1..250}; do\n+        $CLICKHOUSE_CLIENT --query \"SELECT groupArrayIfState(('Hello, world' AS s) || s || s || s || s || s || s || s || s || s, NOT throwIf(number > 10000000, 'Ok')) FROM system.numbers_mt GROUP BY number % 10\";\n+    done\n+}\n+\n+export -f test;\n+\n+# If the memory leak exists, it will lead to OOM fairly quickly.\n+timeout 30 bash -c test 2>&1 | grep -o -F 'Ok' | uniq\n",
  "problem_statement": "uniqState memory leak\n**Describe the bug or unexpected behaviour**\r\nPR #4277 states that there is a memory leak in uniqState.\r\n\r\nAt least it was in version\r\nClickHouse: v19.1.6\r\n\r\n**How to reproduce**\r\n\r\n```\r\nfor i in {1..1000}; do clickhouse-client --max_memory_usage 100000000 <<< \"SELECT uniqExactState(number) FROM system.numbers GROUP BY number % 1000\"; done\r\n```\r\n\r\n\r\n**Expected behavior**\r\nMemory usage should be bounded.\r\n\r\n**Additional context**\r\nWe should check if bug is still present and fix it.\n",
  "hints_text": "BTW if we will just create a test showing the memory leak - won't address sanitizer just show the place?\r\nhttps://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer\n@filimonov Yes, it will show memory leak (assuming the process is correctly terminated and assuming that increasing memory usage is attributed to memory leak). Unbounded grow of memory usage can also be attributed to the grow of size of some data structures that are not actually leaked.\n@akuzm just forgot about this task.\n> @akuzm just forgot about this task.\r\n\r\nThankfully we have github so we don't have to remember. The reason I'm not doing anything about this task is that it doesn't seem a particularly high priority to me, and there is always a lot of other things to do.\nCorrect me if I'm wrong, but I guess this is not a leak (i.e. RSS/VIRT is fine) but the memory tracking issue (i.e. `MemoryTracking` from the `asynchronous_metrics`, that also uses for memory limit checks).\r\nIf my assumption is correct then I've already have a fix for it (came to it while I was on #10818).\r\n\r\nP.S. actually 20.4 already has a [quirk](https://github.com/ClickHouse/ClickHouse/blob/1ccd4fb9788e4f40cc774da560bda9bda17ce183/src/Interpreters/AsynchronousMetrics.cpp#L154) to fix this\n>Correct me if I'm wrong, but I guess this is not a leak\r\n\r\nIgnore this message, didn't look carefully, sorry\n@akuzm memory leak is the top priority bug. It just should not exist.",
  "created_at": "2020-06-07T22:49:01Z"
}