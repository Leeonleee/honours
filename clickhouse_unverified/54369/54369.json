{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 54369,
  "instance_id": "ClickHouse__ClickHouse-54369",
  "issue_numbers": [
    "54242"
  ],
  "base_commit": "47701d690af5cf4bfe181868a48ee9d1314b5034",
  "patch": "diff --git a/.github/workflows/backport_branches.yml b/.github/workflows/backport_branches.yml\nindex d69168b01ee5..a9503136b1ae 100644\n--- a/.github/workflows/backport_branches.yml\n+++ b/.github/workflows/backport_branches.yml\n@@ -76,6 +76,7 @@ jobs:\n         uses: ClickHouse/checkout@v1\n         with:\n           clear-repository: true\n+          fetch-depth: 0  # to find ancestor merge commits necessary for finding proper docker tags\n       - name: Download changed aarch64 images\n         uses: actions/download-artifact@v3\n         with:\ndiff --git a/.github/workflows/docs_check.yml b/.github/workflows/docs_check.yml\nindex a0d0e49b95b8..a6be21fb14ae 100644\n--- a/.github/workflows/docs_check.yml\n+++ b/.github/workflows/docs_check.yml\n@@ -73,6 +73,7 @@ jobs:\n         uses: ClickHouse/checkout@v1\n         with:\n           clear-repository: true\n+          fetch-depth: 0  # to find ancestor merge commits necessary for finding proper docker tags\n       - name: Download changed aarch64 images\n         uses: actions/download-artifact@v3\n         with:\ndiff --git a/.github/workflows/master.yml b/.github/workflows/master.yml\nindex 93ef4aa9da3c..0a21fb93beb5 100644\n--- a/.github/workflows/master.yml\n+++ b/.github/workflows/master.yml\n@@ -60,6 +60,7 @@ jobs:\n         uses: ClickHouse/checkout@v1\n         with:\n           clear-repository: true\n+          fetch-depth: 0  # to find ancestor merge commits necessary for finding proper docker tags\n       - name: Download changed aarch64 images\n         uses: actions/download-artifact@v3\n         with:\ndiff --git a/.github/workflows/nightly.yml b/.github/workflows/nightly.yml\nindex 9de0444bd837..8162dc37223e 100644\n--- a/.github/workflows/nightly.yml\n+++ b/.github/workflows/nightly.yml\n@@ -53,6 +53,7 @@ jobs:\n         uses: ClickHouse/checkout@v1\n         with:\n           clear-repository: true\n+          fetch-depth: 0  # to find ancestor merge commits necessary for finding proper docker tags\n       - name: Download changed aarch64 images\n         uses: actions/download-artifact@v3\n         with:\ndiff --git a/.github/workflows/pull_request.yml b/.github/workflows/pull_request.yml\nindex ce135846dd5b..3845ebdcac74 100644\n--- a/.github/workflows/pull_request.yml\n+++ b/.github/workflows/pull_request.yml\n@@ -94,6 +94,7 @@ jobs:\n         uses: ClickHouse/checkout@v1\n         with:\n           clear-repository: true\n+          fetch-depth: 0  # to find ancestor merge commits necessary for finding proper docker tags\n       - name: Download changed aarch64 images\n         uses: actions/download-artifact@v3\n         with:\ndiff --git a/.github/workflows/release_branches.yml b/.github/workflows/release_branches.yml\nindex 212848155831..6d999d1bee76 100644\n--- a/.github/workflows/release_branches.yml\n+++ b/.github/workflows/release_branches.yml\n@@ -52,6 +52,7 @@ jobs:\n         uses: ClickHouse/checkout@v1\n         with:\n           clear-repository: true\n+          fetch-depth: 0  # to find ancestor merge commits necessary for finding proper docker tags\n       - name: Download changed aarch64 images\n         uses: actions/download-artifact@v3\n         with:\n",
  "test_patch": "diff --git a/tests/ci/clickhouse_helper.py b/tests/ci/clickhouse_helper.py\nindex c2304ca7ad34..0d05b811a4fd 100644\n--- a/tests/ci/clickhouse_helper.py\n+++ b/tests/ci/clickhouse_helper.py\n@@ -13,6 +13,10 @@\n from report import TestResults\n \n \n+class CHException(Exception):\n+    pass\n+\n+\n class InsertException(Exception):\n     pass\n \n@@ -131,12 +135,16 @@ def insert_events_into(self, db, table, events, safe=True):\n             if not safe:\n                 raise\n \n-    def _select_and_get_json_each_row(self, db, query):\n+    def _select_and_get_json_each_row(self, db, query, query_params):\n         params = {\n             \"database\": db,\n             \"query\": query,\n             \"default_format\": \"JSONEachRow\",\n         }\n+        if query_params is not None:\n+            for name, value in query_params.items():\n+                params[f\"param_{name}\"] = str(value)\n+\n         for i in range(5):\n             response = None\n             try:\n@@ -144,15 +152,15 @@ def _select_and_get_json_each_row(self, db, query):\n                 response.raise_for_status()\n                 return response.text\n             except Exception as ex:\n-                logging.warning(\"Cannot insert with exception %s\", str(ex))\n+                logging.warning(\"Select query failed with exception %s\", str(ex))\n                 if response:\n-                    logging.warning(\"Reponse text %s\", response.text)\n+                    logging.warning(\"Response text %s\", response.text)\n                 time.sleep(0.1 * i)\n \n-        raise Exception(\"Cannot fetch data from clickhouse\")\n+        raise CHException(\"Cannot fetch data from clickhouse\")\n \n-    def select_json_each_row(self, db, query):\n-        text = self._select_and_get_json_each_row(db, query)\n+    def select_json_each_row(self, db, query, query_params=None):\n+        text = self._select_and_get_json_each_row(db, query, query_params)\n         result = []\n         for line in text.split(\"\\n\"):\n             if line:\ndiff --git a/tests/ci/docker_images_check.py b/tests/ci/docker_images_check.py\nindex 16a58a90dcf6..ab20e7fb9cf5 100644\n--- a/tests/ci/docker_images_check.py\n+++ b/tests/ci/docker_images_check.py\n@@ -9,7 +9,7 @@\n import time\n import sys\n from pathlib import Path\n-from typing import Any, Dict, List, Optional, Set, Tuple, Union\n+from typing import Any, List, Optional, Set, Tuple, Union\n \n from github import Github\n \n@@ -23,13 +23,12 @@\n from stopwatch import Stopwatch\n from tee_popen import TeePopen\n from upload_result_helper import upload_results\n+from docker_images_helper import ImagesDict, IMAGES_FILE_PATH, get_images_dict\n \n NAME = \"Push to Dockerhub\"\n \n TEMP_PATH = os.path.join(RUNNER_TEMP, \"docker_images_check\")\n \n-ImagesDict = Dict[str, dict]\n-\n \n class DockerImage:\n     def __init__(\n@@ -78,21 +77,6 @@ def __repr__(self):\n         return f\"DockerImage(path={self.path},repo={self.repo},parent={self.parent})\"\n \n \n-def get_images_dict(repo_path: str, image_file_path: str) -> ImagesDict:\n-    \"\"\"Return images suppose to build on the current architecture host\"\"\"\n-    images_dict = {}\n-    path_to_images_file = os.path.join(repo_path, image_file_path)\n-    if os.path.exists(path_to_images_file):\n-        with open(path_to_images_file, \"rb\") as dict_file:\n-            images_dict = json.load(dict_file)\n-    else:\n-        logging.info(\n-            \"Image file %s doesn't exist in repo %s\", image_file_path, repo_path\n-        )\n-\n-    return images_dict\n-\n-\n def get_changed_docker_images(\n     pr_info: PRInfo, images_dict: ImagesDict\n ) -> Set[DockerImage]:\n@@ -410,7 +394,7 @@ def main():\n         shutil.rmtree(TEMP_PATH)\n     os.makedirs(TEMP_PATH)\n \n-    images_dict = get_images_dict(GITHUB_WORKSPACE, \"docker/images.json\")\n+    images_dict = get_images_dict(GITHUB_WORKSPACE, IMAGES_FILE_PATH)\n \n     pr_info = PRInfo()\n     if args.all:\ndiff --git a/tests/ci/docker_images_helper.py b/tests/ci/docker_images_helper.py\nnew file mode 100644\nindex 000000000000..6aed6e82ce39\n--- /dev/null\n+++ b/tests/ci/docker_images_helper.py\n@@ -0,0 +1,30 @@\n+#!/usr/bin/env python3\n+\n+import json\n+import logging\n+import os\n+from typing import Dict, List\n+\n+IMAGES_FILE_PATH = \"docker/images.json\"\n+\n+ImagesDict = Dict[str, dict]\n+\n+\n+def get_images_dict(repo_path: str, images_file_path: str) -> ImagesDict:\n+    \"\"\"Return images suppose to build on the current architecture host\"\"\"\n+    images_dict = {}\n+    path_to_images_file = os.path.join(repo_path, images_file_path)\n+    if os.path.exists(path_to_images_file):\n+        with open(path_to_images_file, \"rb\") as dict_file:\n+            images_dict = json.load(dict_file)\n+    else:\n+        logging.info(\n+            \"Image file %s doesn't exist in repo %s\", images_file_path, repo_path\n+        )\n+\n+    return images_dict\n+\n+\n+def get_image_names(repo_path: str, images_file_path: str) -> List[str]:\n+    images_dict = get_images_dict(repo_path, images_file_path)\n+    return [info[\"name\"] for (_, info) in images_dict.items()]\ndiff --git a/tests/ci/docker_manifests_merge.py b/tests/ci/docker_manifests_merge.py\nindex d89708b9277e..56923c5e2d99 100644\n--- a/tests/ci/docker_manifests_merge.py\n+++ b/tests/ci/docker_manifests_merge.py\n@@ -9,10 +9,16 @@\n from typing import List, Dict, Tuple\n from github import Github\n \n-from clickhouse_helper import ClickHouseHelper, prepare_tests_results_for_clickhouse\n+from clickhouse_helper import (\n+    ClickHouseHelper,\n+    prepare_tests_results_for_clickhouse,\n+    CHException,\n+)\n from commit_status_helper import format_description, get_commit, post_commit_status\n-from env_helper import RUNNER_TEMP\n+from docker_images_helper import IMAGES_FILE_PATH, get_image_names\n+from env_helper import RUNNER_TEMP, GITHUB_WORKSPACE\n from get_robot_token import get_best_robot_token, get_parameter_from_ssm\n+from git_helper import Runner\n from pr_info import PRInfo\n from report import TestResults, TestResult\n from s3_helper import S3Helper\n@@ -167,6 +173,74 @@ def create_manifest(image: str, tags: List[str], push: bool) -> Tuple[str, str]:\n     return manifest, \"OK\"\n \n \n+def enrich_images(changed_images: Dict[str, str]) -> None:\n+    all_image_names = get_image_names(GITHUB_WORKSPACE, IMAGES_FILE_PATH)\n+\n+    images_to_find_tags_for = [\n+        image for image in all_image_names if image not in changed_images\n+    ]\n+    images_to_find_tags_for.sort()\n+\n+    logging.info(\n+        \"Trying to find versions for images:\\n %s\", \"\\n \".join(images_to_find_tags_for)\n+    )\n+\n+    COMMIT_SHA_BATCH_SIZE = 100\n+    MAX_COMMIT_BATCHES_TO_CHECK = 10\n+    # Gets the sha of the last COMMIT_SHA_BATCH_SIZE commits after skipping some commits (see below)\n+    LAST_N_ANCESTOR_SHA_COMMAND = f\"git log --format=format:'%H' --max-count={COMMIT_SHA_BATCH_SIZE} --skip={{}} --merges\"\n+    git_runner = Runner()\n+\n+    GET_COMMIT_SHAS_QUERY = \"\"\"\n+        WITH {commit_shas:Array(String)} AS commit_shas,\n+             {images:Array(String)} AS images\n+        SELECT\n+            substring(test_name, 1, position(test_name, ':') -1) AS image_name,\n+            argMax(commit_sha, check_start_time) AS commit_sha\n+        FROM checks\n+            WHERE\n+                check_name == 'Push multi-arch images to Dockerhub'\n+                AND position(test_name, checks.commit_sha)\n+                AND checks.commit_sha IN commit_shas\n+                AND image_name IN images\n+        GROUP BY image_name\n+        \"\"\"\n+\n+    batch_count = 0\n+    ch_helper = ClickHouseHelper()\n+\n+    while (\n+        batch_count <= MAX_COMMIT_BATCHES_TO_CHECK and len(images_to_find_tags_for) != 0\n+    ):\n+        commit_shas = git_runner(\n+            LAST_N_ANCESTOR_SHA_COMMAND.format(batch_count * COMMIT_SHA_BATCH_SIZE)\n+        ).split(\"\\n\")\n+\n+        result = ch_helper.select_json_each_row(\n+            \"default\",\n+            GET_COMMIT_SHAS_QUERY,\n+            {\"commit_shas\": commit_shas, \"images\": images_to_find_tags_for},\n+        )\n+        result.sort(key=lambda x: x[\"image_name\"])\n+\n+        logging.info(\n+            \"Found images for commits %s..%s:\\n %s\",\n+            commit_shas[0],\n+            commit_shas[-1],\n+            \"\\n \".join(f\"{im['image_name']}:{im['commit_sha']}\" for im in result),\n+        )\n+\n+        for row in result:\n+            image_name = row[\"image_name\"]\n+            commit_sha = row[\"commit_sha\"]\n+            # As we only get the SHAs of merge commits from master, the PR number will be always 0\n+            tag = f\"0-{commit_sha}\"\n+            changed_images[image_name] = tag\n+            images_to_find_tags_for.remove(image_name)\n+\n+        batch_count += 1\n+\n+\n def main():\n     logging.basicConfig(level=logging.INFO)\n     stopwatch = Stopwatch()\n@@ -198,6 +272,12 @@ def main():\n             if test_result != \"OK\":\n                 status = \"failure\"\n \n+    try:\n+        # changed_images now contains all the images that are changed in this PR. Let's find the latest tag for the images that are not changed.\n+        enrich_images(changed_images)\n+    except CHException as ex:\n+        logging.warning(\"Couldn't get proper tags for not changed images: %s\", ex)\n+\n     with open(\n         os.path.join(args.path, \"changed_images.json\"), \"w\", encoding=\"utf-8\"\n     ) as ci:\ndiff --git a/tests/ci/docker_test.py b/tests/ci/docker_test.py\nindex 14db348ef36c..ac43069a679d 100644\n--- a/tests/ci/docker_test.py\n+++ b/tests/ci/docker_test.py\n@@ -9,6 +9,7 @@\n from pr_info import PRInfo\n from report import TestResult\n import docker_images_check as di\n+from docker_images_helper import get_images_dict\n \n from version_helper import get_version_from_string\n import docker_server as ds\n@@ -31,7 +32,7 @@ def test_get_changed_docker_images(self):\n         images = sorted(\n             list(\n                 di.get_changed_docker_images(\n-                    pr_info, di.get_images_dict(\"/\", self.docker_images_path)\n+                    pr_info, get_images_dict(\"/\", self.docker_images_path)\n                 )\n             )\n         )\n",
  "problem_statement": "Use not the `:latest` image, but the latest built image in the master ORIGIN_MERGE\n\n",
  "hints_text": "",
  "created_at": "2023-09-06T16:50:29Z",
  "modified_files": [
    ".github/workflows/backport_branches.yml",
    ".github/workflows/docs_check.yml",
    ".github/workflows/master.yml",
    ".github/workflows/nightly.yml",
    ".github/workflows/pull_request.yml",
    ".github/workflows/release_branches.yml"
  ],
  "modified_test_files": [
    "tests/ci/clickhouse_helper.py",
    "tests/ci/docker_images_check.py",
    "b/tests/ci/docker_images_helper.py",
    "tests/ci/docker_manifests_merge.py",
    "tests/ci/docker_test.py"
  ]
}