{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 83088,
  "instance_id": "ClickHouse__ClickHouse-83088",
  "issue_numbers": [
    "49888"
  ],
  "base_commit": "1dba8ed6da52faec3fe2a203507ff85b01a96b18",
  "patch": "diff --git a/.gitmodules b/.gitmodules\nindex 69958ef07cb8..e596765f112e 100644\n--- a/.gitmodules\n+++ b/.gitmodules\n@@ -357,6 +357,9 @@\n [submodule \"contrib/mongo-c-driver\"]\n \tpath = contrib/mongo-c-driver\n \turl = https://github.com/ClickHouse/mongo-c-driver.git\n+[submodule \"contrib/sz3\"]\n+\tpath = contrib/sz3\n+\turl = https://github.com/ClickHouse/SZ3.git\n [submodule \"contrib/numactl\"]\n \tpath = contrib/numactl\n \turl = https://github.com/ClickHouse/numactl.git\ndiff --git a/ci/jobs/scripts/check_style/aspell-ignore/en/aspell-dict.txt b/ci/jobs/scripts/check_style/aspell-ignore/en/aspell-dict.txt\nindex 2e3cc33c19eb..00f6f98bc4eb 100644\n--- a/ci/jobs/scripts/check_style/aspell-ignore/en/aspell-dict.txt\n+++ b/ci/jobs/scripts/check_style/aspell-ignore/en/aspell-dict.txt\n@@ -585,6 +585,7 @@ LogsLevel\n Logstash\n LookML\n LoongArch\n+Lossy\n LowCardinality\n LpDistance\n LpNorm\n@@ -2224,6 +2225,7 @@ loghouse\n london\n lookups\n loongarch\n+lossy\n lowCardinalityIndices\n lowCardinalityKeys\n lowcardinality\ndiff --git a/contrib/CMakeLists.txt b/contrib/CMakeLists.txt\nindex fbf4747f462b..dcbec7a0b9ed 100644\n--- a/contrib/CMakeLists.txt\n+++ b/contrib/CMakeLists.txt\n@@ -250,6 +250,8 @@ add_contrib (sha3iuf-cmake SHA3IUF)\n \n add_contrib (bech32)\n \n+add_contrib (sz3-cmake sz3)\n+\n # Put all targets defined here and in subdirectories under \"contrib/<immediate-subdir>\" folders in GUI-based IDEs.\n # Some of third-party projects may override CMAKE_FOLDER or FOLDER property of their targets, so they would not appear\n # in \"contrib/...\" as originally planned, so we workaround this by fixing FOLDER properties of all targets manually,\ndiff --git a/contrib/sz3 b/contrib/sz3\nnew file mode 160000\nindex 000000000000..346c37af88a9\n--- /dev/null\n+++ b/contrib/sz3\n@@ -0,0 +1,1 @@\n+Subproject commit 346c37af88a9e0201729f4a73da90b6aff3481a7\ndiff --git a/contrib/sz3-cmake/CMakeLists.txt b/contrib/sz3-cmake/CMakeLists.txt\nnew file mode 100644\nindex 000000000000..eac9974a8873\n--- /dev/null\n+++ b/contrib/sz3-cmake/CMakeLists.txt\n@@ -0,0 +1,23 @@\n+option(ENABLE_SZ3 \"Enable SZ3\" ${ENABLE_LIBRARIES})\n+\n+if (NOT ENABLE_SZ3)\n+    message (STATUS \"Not using SZ3\")\n+    return()\n+endif()\n+\n+# SZ3 is still under development, it writes its current version into the serialized compressed data.\n+# Therefore, update SZ3 with care to avoid breaking existing persistencies.\n+\n+# File contrib/sz3-cmake/SZ3/version.hpp was statically generated from version.hpp.in in contrib/sz3.\n+# It must be updated when the library is updated. Refer to contrib/sz3/README.md for that (section #Installation).\n+# Turn off ska hash because ska::unordered_map (this is inner hash map) doesn't work with UB sanitizer.\n+set(SZ3_USE_SKA_HASH OFF)\n+set(SZ3_PROJECT_DIR \"${ClickHouse_SOURCE_DIR}/contrib/sz3\")\n+set(SZ3_SOURCE_DIR \"${SZ3_PROJECT_DIR}/include\")\n+set(SZ3_VERSION_DIR \"${ClickHouse_SOURCE_DIR}/contrib/sz3-cmake\")\n+\n+add_library(_sz3 INTERFACE)\n+target_include_directories(_sz3 SYSTEM INTERFACE ${SZ3_SOURCE_DIR})\n+target_include_directories(_sz3 SYSTEM INTERFACE ${SZ3_VERSION_DIR})\n+\n+add_library(ch_contrib::sz3 ALIAS _sz3)\ndiff --git a/contrib/sz3-cmake/SZ3/version.hpp b/contrib/sz3-cmake/SZ3/version.hpp\nnew file mode 100644\nindex 000000000000..ee571b4d9c11\n--- /dev/null\n+++ b/contrib/sz3-cmake/SZ3/version.hpp\n@@ -0,0 +1,36 @@\n+//\n+// DO NOT MODIFY version.hpp, it is automatically generated by cmake\n+// Change the version numbers in CMakeLists.txt\n+//\n+\n+#ifndef SZ3_VERSION_HPP\n+#define SZ3_VERSION_HPP\n+#include <sstream>\n+\n+#define SZ3_MAGIC_NUMBER 0xF342F310\n+\n+#define SZ3_NAME \"SZ3\"\n+#define SZ3_VER  \"3.2.2\"\n+#define SZ3_VER_MAJOR 3\n+#define SZ3_VER_MINOR 2\n+#define SZ3_VER_PATCH 2\n+#define SZ3_VER_TWEAK 0\n+\n+#define SZ3_DATA_VER \"3.2.2\"\n+\n+inline uint32_t versionInt(const std::string& version) {\n+    uint32_t major = 0, minor = 0, patch = 0;\n+    char dot;\n+    std::stringstream ss(version);\n+    ss >> major >> dot >> minor >> dot >> patch;\n+    return (major << 24) | (minor << 16) | (patch<<8);\n+}\n+\n+inline std::string versionStr(uint32_t version) {\n+    uint32_t major = (version >> 24) & 0xFF;\n+    uint32_t minor = (version >> 16) & 0xFF;\n+    uint32_t patch = (version >> 8) & 0xFF;\n+    return std::to_string(major) + \".\" + std::to_string(minor) + \".\" + std::to_string(patch);\n+}\n+\n+#endif //SZ3_VERSION_HPP\ndiff --git a/docs/en/sql-reference/statements/create/table.md b/docs/en/sql-reference/statements/create/table.md\nindex 931fbc473a5f..d923c4aad9ce 100644\n--- a/docs/en/sql-reference/statements/create/table.md\n+++ b/docs/en/sql-reference/statements/create/table.md\n@@ -465,6 +465,10 @@ These codecs are designed to make compression more effective by exploiting speci\n \n `FPC(level, float_size)` - Repeatedly predicts the next floating point value in the sequence using the better of two predictors, then XORs the actual with the predicted value, and leading-zero compresses the result. Similar to Gorilla, this is efficient when storing a series of floating point values that change slowly. For 64-bit values (double), FPC is faster than Gorilla, for 32-bit values your mileage may vary. Possible `level` values: 1-28, the default value is 12.  Possible `float_size` values: 4, 8, the default value is `sizeof(type)` if type is Float. In all other cases, it's 4. For a detailed description of the algorithm see [High Throughput Compression of Double-Precision Floating-Point Data](https://userweb.cs.txstate.edu/~burtscher/papers/dcc07a.pdf).\n \n+#### SZ3 {#sz3}\n+\n+`SZ3` or `SZ3(algorithm, error_bound_mode, error_bound)` - A lossy but error-bound codec ([SZ3 Lossy Compressor](https://szcompressor.org/)) for columns of type Float32, Float64, Array(Float32), or Array(Float64). If the column type is of array type, then all inserted arrays must have the same length. Supported values for 'algorithm' are `ALGO_LORENZO_REG`, `ALGO_INTERP_LORENZO` and `ALGO_INTERP`. Supported values for 'error_bound_mode' are `ABS`, `REL`, `PSNR` and `ABS_AND_REL`. Argument 'error_bound' is the maximum error and of type Float64.\n+\n #### T64 {#t64}\n \n `T64` \u2014 Compression approach that crops unused high bits of values in integer data types (including `Enum`, `Date` and `DateTime`). At each step of its algorithm, codec takes a block of 64 values, puts them into 64x64 bit matrix, transposes it, crops the unused bits of values and returns the rest as a sequence. Unused bits are the bits, that do not differ between maximum and minimum values in the whole data part for which the compression is used.\ndiff --git a/src/CMakeLists.txt b/src/CMakeLists.txt\nindex 0dd0478630bc..d87b79e38166 100644\n--- a/src/CMakeLists.txt\n+++ b/src/CMakeLists.txt\n@@ -111,6 +111,10 @@ list (REMOVE_ITEM clickhouse_common_io_sources Common/malloc.cpp Common/new_dele\n add_headers_and_sources(clickhouse_compression Compression)\n add_library(clickhouse_compression ${clickhouse_compression_headers} ${clickhouse_compression_sources})\n \n+if (TARGET ch_contrib::sz3)\n+    target_link_libraries (clickhouse_compression PUBLIC ch_contrib::sz3)\n+endif()\n+\n add_headers_and_sources(dbms Disks/IO)\n add_headers_and_sources(dbms Disks/ObjectStorages)\n if (TARGET ch_contrib::sqlite)\ndiff --git a/src/Common/config.h.in b/src/Common/config.h.in\nindex c11e4dc8bcd0..4b3739570009 100644\n--- a/src/Common/config.h.in\n+++ b/src/Common/config.h.in\n@@ -56,6 +56,7 @@\n #cmakedefine01 USE_SQLITE\n #cmakedefine01 USE_NURAFT\n #cmakedefine01 USE_KRB5\n+#cmakedefine01 USE_SZ3\n #cmakedefine01 USE_FILELOG\n #cmakedefine01 USE_BLAKE3\n #cmakedefine01 USE_USEARCH\ndiff --git a/src/Compression/CompressionCodecDeflateQpl.h b/src/Compression/CompressionCodecDeflateQpl.h\nindex 75d3527082f5..b85c52521725 100644\n--- a/src/Compression/CompressionCodecDeflateQpl.h\n+++ b/src/Compression/CompressionCodecDeflateQpl.h\n@@ -110,7 +110,7 @@ class CompressionCodecDeflateQpl final : public ICompressionCodec\n     bool isGenericCompression() const override { return true; }\n     bool isDeflateQpl() const override { return true; }\n \n-    std::string getDescription() const override\n+    String getDescription() const override\n     {\n         return \"Requires hardware support for Intel\u2019s QuickAssist Technology for DEFLATE compression; enhanced performance for specific hardware.\";\n     }\ndiff --git a/src/Compression/CompressionCodecDelta.cpp b/src/Compression/CompressionCodecDelta.cpp\nindex f3ff161eef82..79d7b76f3e28 100644\n--- a/src/Compression/CompressionCodecDelta.cpp\n+++ b/src/Compression/CompressionCodecDelta.cpp\n@@ -29,7 +29,7 @@ class CompressionCodecDelta : public ICompressionCodec\n     bool isGenericCompression() const override { return false; }\n     bool isDeltaCompression() const override { return true; }\n \n-    std::string getDescription() const override\n+    String getDescription() const override\n     {\n         return \"Preprocessor (should be followed by some compression codec). Stores difference between neighboring values; good for monotonically increasing or decreasing data.\";\n     }\ndiff --git a/src/Compression/CompressionCodecDoubleDelta.cpp b/src/Compression/CompressionCodecDoubleDelta.cpp\nindex 15ae8515a8ee..adbacd9d41f2 100644\n--- a/src/Compression/CompressionCodecDoubleDelta.cpp\n+++ b/src/Compression/CompressionCodecDoubleDelta.cpp\n@@ -138,11 +138,7 @@ class CompressionCodecDoubleDelta : public ICompressionCodec\n     bool isCompression() const override { return true; }\n     bool isGenericCompression() const override { return false; }\n     bool isDeltaCompression() const override { return true; }\n-    std::string getDescription() const override\n-    {\n-        return \"Stores difference between neighboring delta values; suitable for time series data.\";\n-    }\n-\n+    String getDescription() const override { return \"Stores difference between neighboring delta values; suitable for time series data.\"; }\n \n private:\n     UInt8 data_bytes_size;\ndiff --git a/src/Compression/CompressionCodecEncrypted.h b/src/Compression/CompressionCodecEncrypted.h\nindex 632294e598ee..229eccf032b9 100644\n--- a/src/Compression/CompressionCodecEncrypted.h\n+++ b/src/Compression/CompressionCodecEncrypted.h\n@@ -110,11 +110,8 @@ class CompressionCodecEncrypted final : public ICompressionCodec\n     bool isCompression() const override { return false; }\n     bool isGenericCompression() const override { return false; }\n     bool isEncryption() const override { return true; }\n+    String getDescription() const override { return \"Encrypts and decrypts blocks with AES-128 in GCM-SIV mode (RFC-8452).\"; }\n \n-    std::string getDescription() const override\n-    {\n-        return \"Encrypts and decrypts blocks with AES-128 in GCM-SIV mode (RFC-8452).\";\n-    }\n protected:\n     UInt32 getMaxCompressedDataSize(UInt32 uncompressed_size) const override;\n \ndiff --git a/src/Compression/CompressionCodecFPC.cpp b/src/Compression/CompressionCodecFPC.cpp\nindex e6ba5c6c7ae2..1b35a0612681 100644\n--- a/src/Compression/CompressionCodecFPC.cpp\n+++ b/src/Compression/CompressionCodecFPC.cpp\n@@ -21,7 +21,7 @@ namespace DB\n class CompressionCodecFPC : public ICompressionCodec\n {\n public:\n-    CompressionCodecFPC(UInt8 float_size, UInt8 compression_level);\n+    CompressionCodecFPC(UInt8 float_width_, UInt8 compression_level_);\n \n     uint8_t getMethodByte() const override;\n \n@@ -40,18 +40,14 @@ class CompressionCodecFPC : public ICompressionCodec\n     bool isCompression() const override { return true; }\n     bool isGenericCompression() const override { return false; }\n     bool isFloatingPointTimeSeriesCodec() const override { return true; }\n-    std::string getDescription() const override\n-    {\n-        return \"High Throughput Compression of Double-Precision Floating-Point Data.\";\n-    }\n-\n+    String getDescription() const override { return \"High Throughput Compression of Double-Precision Floating-Point Data.\"; }\n \n private:\n     static constexpr UInt32 HEADER_SIZE = 2;\n \n     // below members are used by compression, decompression ignores them:\n     const UInt8 float_width; // size of uncompressed float in bytes\n-    const UInt8 level; // compression level, 2^level * float_width is the size of predictors table in bytes\n+    const UInt8 compression_level; // compression level, 2^level * float_width is the size of predictors table in bytes\n };\n \n \n@@ -74,10 +70,11 @@ void CompressionCodecFPC::updateHash(SipHash & hash) const\n     getCodecDesc()->updateTreeHash(hash, /*ignore_aliases=*/ true);\n }\n \n-CompressionCodecFPC::CompressionCodecFPC(UInt8 float_size, UInt8 compression_level)\n-    : float_width{float_size}, level{compression_level}\n+CompressionCodecFPC::CompressionCodecFPC(UInt8 float_width_, UInt8 compression_level_)\n+    : float_width(float_width_)\n+    , compression_level(compression_level_)\n {\n-    setCodecDescription(\"FPC\", {std::make_shared<ASTLiteral>(static_cast<UInt64>(level))});\n+    setCodecDescription(\"FPC\", {std::make_shared<ASTLiteral>(static_cast<UInt64>(compression_level))});\n }\n \n UInt32 CompressionCodecFPC::getMaxCompressedDataSize(UInt32 uncompressed_size) const\n@@ -91,20 +88,15 @@ UInt32 CompressionCodecFPC::getMaxCompressedDataSize(UInt32 uncompressed_size) c\n namespace\n {\n \n-UInt8 getFloatBytesSize(const IDataType & column_type)\n+UInt8 getFloatByteWidth(const IDataType & column_type)\n {\n-    if (!WhichDataType(column_type).isFloat())\n-    {\n-        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"FPC codec is not applicable for {} because the data type is not float\",\n-                        column_type.getName());\n-    }\n+    if (!WhichDataType(column_type).isNativeFloat())\n+        throw Exception(\n+                ErrorCodes::BAD_ARGUMENTS,\n+                \"Codec 'FPC' is not applicable for {} because the data type is not Float*\",\n+                column_type.getName());\n \n-    if (auto float_size = column_type.getSizeOfValueInMemory(); float_size >= 4)\n-    {\n-        return static_cast<UInt8>(float_size);\n-    }\n-    throw Exception(ErrorCodes::BAD_ARGUMENTS, \"FPC codec is not applicable for floats of size less than 4 bytes. Given type {}\",\n-                    column_type.getName());\n+    return column_type.getSizeOfValueInMemory();\n }\n \n }\n@@ -114,38 +106,35 @@ void registerCodecFPC(CompressionCodecFactory & factory)\n     auto method_code = static_cast<UInt8>(CompressionMethodByte::FPC);\n     auto codec_builder = [&](const ASTPtr & arguments, const IDataType * column_type) -> CompressionCodecPtr\n     {\n-        /// Set default float width to 4.\n         UInt8 float_width = 4;\n-        if (column_type != nullptr)\n-            float_width = getFloatBytesSize(*column_type);\n+        if (column_type)\n+            float_width = getFloatByteWidth(*column_type);\n \n         UInt8 level = CompressionCodecFPC::DEFAULT_COMPRESSION_LEVEL;\n         if (arguments && !arguments->children.empty())\n         {\n             if (arguments->children.size() > 2)\n-            {\n                 throw Exception(ErrorCodes::ILLEGAL_SYNTAX_FOR_CODEC_TYPE,\n-                                \"FPC codec must have from 0 to 2 parameters, given {}\", arguments->children.size());\n-            }\n+                                \"Codec 'FPC' must have from 0 to 2 parameters, given {}\", arguments->children.size());\n \n-            const auto * literal = arguments->children.front()->as<ASTLiteral>();\n+            const auto * literal = arguments->children[0]->as<ASTLiteral>();\n             if (!literal || literal->value.getType() != Field::Types::Which::UInt64)\n-                throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"FPC codec argument must be unsigned integer\");\n+                throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"1st argument of codec 'FPC' must be unsigned integer\");\n \n             level = literal->value.safeGet<UInt8>();\n             if (level < 1 || level > CompressionCodecFPC::MAX_COMPRESSION_LEVEL)\n-                throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"FPC codec level must be between {} and {}\",\n+                throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"Codec 'FPC' level must be between {} and {}\",\n                                 1, static_cast<int>(CompressionCodecFPC::MAX_COMPRESSION_LEVEL));\n \n             if (arguments->children.size() == 2)\n             {\n                 literal = arguments->children[1]->as<ASTLiteral>();\n                 if (!literal || !isInt64OrUInt64FieldType(literal->value.getType()))\n-                    throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"FPC codec argument must be unsigned integer\");\n+                    throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"2nd argument of codec 'FPC' must be unsigned integer\");\n \n                 size_t user_float_width = literal->value.safeGet<UInt64>();\n                 if (user_float_width != 4 && user_float_width != 8)\n-                    throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"Float size for FPC codec can be 4 or 8, given {}\", user_float_width);\n+                    throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"Float size for codec 'FPC' can be 4 or 8, given {}\", user_float_width);\n                 float_width = static_cast<UInt8>(user_float_width);\n             }\n         }\n@@ -473,7 +462,7 @@ class FPCOperation\n UInt32 CompressionCodecFPC::doCompressData(const char * source, UInt32 source_size, char * dest) const\n {\n     dest[0] = static_cast<char>(float_width);\n-    dest[1] = static_cast<char>(level);\n+    dest[1] = static_cast<char>(compression_level);\n \n     auto dest_size = getMaxCompressedDataSize(source_size);\n     auto destination = std::as_writable_bytes(std::span(dest, dest_size).subspan(HEADER_SIZE));\n@@ -481,13 +470,13 @@ UInt32 CompressionCodecFPC::doCompressData(const char * source, UInt32 source_si\n     switch (float_width)\n     {\n         case sizeof(Float64):\n-            return static_cast<UInt32>(HEADER_SIZE + FPCOperation<UInt64>(destination, level).encode(src));\n+            return static_cast<UInt32>(HEADER_SIZE + FPCOperation<UInt64>(destination, compression_level).encode(src));\n         case sizeof(Float32):\n-            return static_cast<UInt32>(HEADER_SIZE + FPCOperation<UInt32>(destination, level).encode(src));\n+            return static_cast<UInt32>(HEADER_SIZE + FPCOperation<UInt32>(destination, compression_level).encode(src));\n         default:\n             break;\n     }\n-    throw Exception(ErrorCodes::CANNOT_COMPRESS, \"Cannot compress with FPC codec. File has incorrect float width\");\n+    throw Exception(ErrorCodes::CANNOT_COMPRESS, \"Cannot compress with codec 'FPC'. File has incorrect float width\");\n }\n \n void CompressionCodecFPC::doDecompressData(const char * source, UInt32 source_size, char * dest, UInt32 uncompressed_size) const\ndiff --git a/src/Compression/CompressionCodecGCD.cpp b/src/Compression/CompressionCodecGCD.cpp\nindex 998975e2c554..34065da4d741 100644\n--- a/src/Compression/CompressionCodecGCD.cpp\n+++ b/src/Compression/CompressionCodecGCD.cpp\n@@ -31,12 +31,11 @@ class CompressionCodecGCD : public ICompressionCodec\n \n     bool isCompression() const override { return false; }\n     bool isGenericCompression() const override { return false; }\n-    std::string getDescription() const override\n+    String getDescription() const override\n     {\n         return \"Preprocessor. Greatest common divisor compression; divides values by a common divisor; effective for divisible integer sequences.\";\n     }\n \n-\n private:\n     const UInt8 gcd_bytes_size;\n };\ndiff --git a/src/Compression/CompressionCodecGorilla.cpp b/src/Compression/CompressionCodecGorilla.cpp\nindex 6a22be45e812..5693d2205d44 100644\n--- a/src/Compression/CompressionCodecGorilla.cpp\n+++ b/src/Compression/CompressionCodecGorilla.cpp\n@@ -124,12 +124,11 @@ class CompressionCodecGorilla : public ICompressionCodec\n     bool isGenericCompression() const override { return false; }\n     bool isFloatingPointTimeSeriesCodec() const override { return true; }\n \n-    std::string getDescription() const override\n+    String getDescription() const override\n     {\n         return \"Calculates XOR between current and previous value; suitable for slowly changing numbers.\";\n     }\n \n-\n private:\n     const UInt8 data_bytes_size;\n };\ndiff --git a/src/Compression/CompressionCodecLZ4.cpp b/src/Compression/CompressionCodecLZ4.cpp\nindex 136b7a98c838..4cb424b318cc 100644\n--- a/src/Compression/CompressionCodecLZ4.cpp\n+++ b/src/Compression/CompressionCodecLZ4.cpp\n@@ -35,10 +35,7 @@ class CompressionCodecLZ4 : public ICompressionCodec\n \n     bool isCompression() const override { return true; }\n     bool isGenericCompression() const override { return true; }\n-    std::string getDescription() const override\n-    {\n-        return \"Extremely fast; good compression; balanced speed and efficiency.\";\n-    }\n+    String getDescription() const override { return \"Extremely fast; good compression; balanced speed and efficiency.\"; }\n \n private:\n     void doDecompressData(const char * source, UInt32 source_size, char * dest, UInt32 uncompressed_size) const override;\ndiff --git a/src/Compression/CompressionCodecMultiple.h b/src/Compression/CompressionCodecMultiple.h\nindex 35cb79f3e4d6..2c2573bacf54 100644\n--- a/src/Compression/CompressionCodecMultiple.h\n+++ b/src/Compression/CompressionCodecMultiple.h\n@@ -28,11 +28,7 @@ class CompressionCodecMultiple final : public ICompressionCodec\n     bool isCompression() const override;\n     bool isGenericCompression() const override { return false; }\n \n-    std::string getDescription() const override\n-    {\n-        return \"Apply multiple codecs consecutively defined by user.\";\n-    }\n-\n+    String getDescription() const override { return \"Apply multiple codecs consecutively defined by user.\"; }\n \n private:\n     Codecs codecs;\ndiff --git a/src/Compression/CompressionCodecNone.h b/src/Compression/CompressionCodecNone.h\nindex 9f41a0c6f6cc..89cf12bbe826 100644\n--- a/src/Compression/CompressionCodecNone.h\n+++ b/src/Compression/CompressionCodecNone.h\n@@ -25,11 +25,7 @@ class CompressionCodecNone final : public ICompressionCodec\n     bool isGenericCompression() const override { return false; }\n     bool isNone() const override { return true; }\n \n-    std::string getDescription() const override\n-    {\n-        return \"No compression at all. Can be used on the columns that can not be compressed anyway.\";\n-    }\n-\n+    String getDescription() const override { return \"No compression. Can be used on columns that can not be compressed anyway.\"; }\n };\n \n }\ndiff --git a/src/Compression/CompressionCodecSZ3.cpp b/src/Compression/CompressionCodecSZ3.cpp\nnew file mode 100644\nindex 000000000000..7d8043a763cd\n--- /dev/null\n+++ b/src/Compression/CompressionCodecSZ3.cpp\n@@ -0,0 +1,306 @@\n+#include \"config.h\"\n+\n+#if USE_SZ3\n+#  include \"base/types.h\"\n+#  include \"Common/Exception.h\"\n+#  include <Common/SipHash.h>\n+#  include <Core/TypeId.h>\n+#  include <Compression/CompressionFactory.h>\n+#  include <Compression/CompressionInfo.h>\n+#  include <Compression/ICompressionCodec.h>\n+#  include <DataTypes/IDataType.h>\n+#  include <IO/BufferWithOwnMemory.h>\n+#  include <IO/WriteBuffer.h>\n+#  include <IO/WriteHelpers.h>\n+#  include <Interpreters/Context.h>\n+#  include <Parsers/ASTLiteral.h>\n+#  include <Parsers/IAST.h>\n+\n+#  include <SZ3/api/sz.hpp>\n+#  include <SZ3/utils/Config.hpp>\n+\n+namespace DB\n+{\n+\n+class CompressionCodecSZ3 : public ICompressionCodec\n+{\n+public:\n+    CompressionCodecSZ3(UInt8 float_size_, SZ3::ALGO algorithm_, SZ3::EB error_bound_mode_, double error_value_);\n+\n+    uint8_t getMethodByte() const override;\n+\n+    UInt32 getAdditionalSizeAtTheEndOfBuffer() const override { return 0; }\n+\n+    void updateHash(SipHash & hash) const override;\n+\n+    void setAndCheckVectorDimension(size_t dimension) override;\n+\n+protected:\n+    bool isCompression() const override { return true; }\n+    bool isGenericCompression() const override { return true; }\n+    /// SZ3 is still under development, it writes its current version into the serialized compressed data.\n+    /// Therefore, update SZ3 with care to avoid breaking existing persistencies.\n+    /// We mark it as experimental for now.\n+    bool isLossyCompression() const override { return true; }\n+    bool isExperimental() const override { return true; }\n+    bool needsVectorDimensionUpfront() const override { return true; }\n+    String getDescription() const override { return \"SZ3 is a lossy compressor for floating-point data with error bounds.\"; }\n+\n+private:\n+    UInt32 doCompressData(const char * source, UInt32 source_size, char * dest) const override;\n+    void doDecompressData(const char * source, UInt32 source_size, char * dest, UInt32 uncompressed_size) const override;\n+\n+    UInt32 getMaxCompressedDataSize(UInt32 uncompressed_size) const override;\n+\n+    std::optional<size_t> dimension;\n+    const UInt8 float_width;\n+    const SZ3::ALGO algorithm;\n+    const SZ3::EB error_bound_mode;\n+    const Float64 error_value;\n+};\n+\n+namespace ErrorCodes\n+{\n+    extern const int BAD_ARGUMENTS;\n+    extern const int CORRUPTED_DATA;\n+    extern const int ILLEGAL_CODEC_PARAMETER;\n+    extern const int LOGICAL_ERROR;\n+}\n+\n+String getSZ3AlgorithmString(SZ3::ALGO algorithm)\n+{\n+    for (const auto & [algorithm_string, algorithm_id] : SZ3::ALGO_MAP)\n+    {\n+        if (algorithm_id == algorithm)\n+            return algorithm_string;\n+    }\n+    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Invalid algorithm\");\n+}\n+\n+String getSZ3ErrorBoundModeString(SZ3::EB error_bound_mode)\n+{\n+    for (const auto & [error_bound_string, error_bound_mode_id] : SZ3::EB_MAP)\n+    {\n+        if (error_bound_mode_id == error_bound_mode)\n+            return error_bound_string;\n+    }\n+    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Invalid error bound mode\");\n+}\n+\n+CompressionCodecSZ3::CompressionCodecSZ3(\n+    UInt8 float_size_, SZ3::ALGO algorithm_, SZ3::EB error_bound_mode_, double error_value_)\n+    : float_width(float_size_)\n+    , algorithm(algorithm_)\n+    , error_bound_mode(error_bound_mode_)\n+    , error_value(error_value_)\n+{\n+    setCodecDescription(\n+        \"SZ3\", {std::make_shared<ASTLiteral>(getSZ3AlgorithmString(algorithm)),\n+                std::make_shared<ASTLiteral>(getSZ3ErrorBoundModeString(error_bound_mode)),\n+                std::make_shared<ASTLiteral>(error_value)});\n+}\n+\n+uint8_t CompressionCodecSZ3::getMethodByte() const\n+{\n+    return static_cast<uint8_t>(CompressionMethodByte::SZ3);\n+}\n+\n+void CompressionCodecSZ3::updateHash(SipHash & hash) const\n+{\n+    getCodecDesc()->updateTreeHash(hash, true);\n+    hash.update(float_width);\n+}\n+\n+UInt32 CompressionCodecSZ3::getMaxCompressedDataSize(UInt32 uncompressed_size) const\n+{\n+    return sizeof(UInt8) + sizeof(SZ3::Config) + uncompressed_size;\n+}\n+\n+UInt32 CompressionCodecSZ3::doCompressData(const char * source, UInt32 source_size, char * dest) const\n+{\n+    SZ3::Config config;\n+\n+    std::vector<size_t> result_dimensions;\n+    size_t num_floats = (source_size / float_width) / dimension.value_or(1);\n+\n+    result_dimensions.push_back(num_floats);\n+    result_dimensions.push_back(dimension.value_or(1));\n+\n+    config.setDims(result_dimensions.begin(), result_dimensions.end());\n+\n+    config.cmprAlgo = algorithm;\n+    config.errorBoundMode = error_bound_mode;\n+\n+    switch (error_bound_mode)\n+    {\n+        case SZ3::EB_REL:\n+            config.relErrorBound = error_value;\n+            break;\n+        case SZ3::EB_ABS:\n+            config.absErrorBound = error_value;\n+            break;\n+        case SZ3::EB_PSNR:\n+            config.psnrErrorBound = error_value;\n+            break;\n+        case SZ3::EB_L2NORM:\n+            config.l2normErrorBound = error_value;\n+            break;\n+        default:\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Invalid error bound mode\");\n+    }\n+\n+    std::unique_ptr<char[]> compressed;\n+    size_t compressed_size;\n+    switch (float_width)\n+    {\n+        case 4: {\n+            try\n+            {\n+                compressed.reset(SZ_compress(config, reinterpret_cast<const float *>(source), compressed_size));\n+            }\n+            catch (...)\n+            {\n+                throw Exception(ErrorCodes::CORRUPTED_DATA, \"Unexpected data to compress\");\n+            }\n+            break;\n+        }\n+        case 8: {\n+            try\n+            {\n+                compressed.reset(SZ_compress(config, reinterpret_cast<const double *>(source), compressed_size));\n+            }\n+            catch (...)\n+            {\n+                throw Exception(ErrorCodes::CORRUPTED_DATA, \"Unexpected data to compress\");\n+            }\n+            break;\n+        }\n+        default:\n+            throw Exception(ErrorCodes::CORRUPTED_DATA, \"Unexpected float width in SZ3 compressed data\");\n+    }\n+\n+    size_t offset = 0;\n+    memcpy(dest + offset, &float_width, sizeof(UInt8));\n+    offset += sizeof(UInt8);\n+\n+    memcpy(dest + offset, compressed.get(), compressed_size);\n+    return static_cast<UInt32>(offset + compressed_size);\n+}\n+\n+void CompressionCodecSZ3::setAndCheckVectorDimension(size_t dimension_)\n+{\n+    if (dimension.has_value() && *dimension != dimension_)\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Vector dimensions are not equals: {} and {}\", dimension_, *dimension);\n+    dimension = dimension_;\n+}\n+\n+void CompressionCodecSZ3::doDecompressData(const char * source, UInt32 source_size, char * dest, UInt32 /*uncompressed_size*/) const\n+{\n+    UInt8 width = static_cast<UInt8>(*source);\n+    --source_size;\n+    ++source;\n+\n+    SZ3::Config config;\n+    switch (width)\n+    {\n+        case 4: {\n+            try\n+            {\n+                float * dest_typed = reinterpret_cast<float *>(dest);\n+                SZ_decompress<float>(config, const_cast<char *>(source), source_size, dest_typed);\n+            }\n+            catch (...)\n+            {\n+                throw Exception(ErrorCodes::CORRUPTED_DATA, \"Unexpected data to compress\");\n+            }\n+            break;\n+        }\n+        case 8: {\n+            try\n+            {\n+                double * dest_typed = reinterpret_cast<double *>(dest);\n+                SZ_decompress<double>(config, const_cast<char *>(source), source_size, dest_typed);\n+            }\n+            catch (...)\n+            {\n+                throw Exception(ErrorCodes::CORRUPTED_DATA, \"Unexpected data to compress\");\n+            }\n+            break;\n+        }\n+        default:\n+            throw Exception(ErrorCodes::CORRUPTED_DATA, \"Unexpected float width in SZ3 compressed data\");\n+    }\n+}\n+\n+UInt8 getFloatByteWidth(const IDataType & column_type)\n+{\n+    if (!WhichDataType(column_type).isNativeFloat())\n+        throw Exception(\n+                ErrorCodes::BAD_ARGUMENTS,\n+                \"Codec 'SZ3' is not applicable for {} because the data type is not Float*\",\n+                column_type.getName());\n+\n+    return column_type.getSizeOfValueInMemory();\n+}\n+\n+SZ3::ALGO getSZ3Algorithm(const String & algorithm)\n+{\n+    return SZ3::ALGO_MAP.at(algorithm);\n+}\n+\n+SZ3::EB getSZ3ErrorBoundMode(const String & error_bound_mode)\n+{\n+    return SZ3::EB_MAP.at(error_bound_mode);\n+}\n+\n+void registerCodecSZ3(CompressionCodecFactory & factory)\n+{\n+    auto method_code = static_cast<UInt8>(CompressionMethodByte::SZ3);\n+    auto codec_builder = [&](const ASTPtr & arguments, const IDataType * column_type) -> CompressionCodecPtr\n+    {\n+        UInt8 float_width = 4;\n+        if (column_type)\n+            float_width = getFloatByteWidth(*column_type);\n+\n+        if (!arguments || arguments->children.empty())\n+        {\n+            static constexpr auto default_algorithm = SZ3::ALGO_INTERP_LORENZO;\n+            static constexpr auto default_error_bound_mode = SZ3::EB_REL;\n+            static constexpr auto default_error_bound = 1e-2;\n+\n+            return std::make_shared<CompressionCodecSZ3>(\n+                float_width, default_algorithm, default_error_bound_mode, default_error_bound);\n+        }\n+        else if (arguments->children.size() == 3)\n+        {\n+            const auto & children = arguments->children;\n+            const auto * literal = children[0]->as<ASTLiteral>();\n+            if (!literal || literal->value.getType() != Field::Types::Which::String)\n+                throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"1st argument of codec 'SZ3' must be a String\");\n+            auto algorithm_string = static_cast<String>(literal->value.safeGet<String>());\n+            auto algorithm = getSZ3Algorithm(algorithm_string);\n+\n+            literal = children[1]->as<ASTLiteral>();\n+            if (!literal || literal->value.getType() != Field::Types::Which::String)\n+                throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"2nd argument of codec 'SZ3' be a String\");\n+            auto error_bound_mode_string = static_cast<String>(literal->value.safeGet<String>());\n+            auto error_bound_mode = getSZ3ErrorBoundMode(error_bound_mode_string);\n+\n+            literal = children[2]->as<ASTLiteral>();\n+            if (!literal || literal->value.getType() != Field::Types::Which::Float64)\n+                throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"3rd argument of codec 'SZ3' be a Float64\");\n+            auto error_value = static_cast<double>(literal->value.safeGet<Float64>());\n+\n+            return std::make_shared<CompressionCodecSZ3>(float_width, algorithm, error_bound_mode, error_value);\n+        }\n+        else\n+        {\n+            throw Exception(\n+                ErrorCodes::BAD_ARGUMENTS, \"Codec SZ3 must have 0 or 3 arguments but {} arguments are given\", arguments->children.size());\n+        }\n+    };\n+    factory.registerCompressionCodecWithType(\"SZ3\", method_code, codec_builder);\n+}\n+\n+}\n+#endif\ndiff --git a/src/Compression/CompressionCodecT64.cpp b/src/Compression/CompressionCodecT64.cpp\nindex 5582368863d0..b724e8510b7d 100644\n--- a/src/Compression/CompressionCodecT64.cpp\n+++ b/src/Compression/CompressionCodecT64.cpp\n@@ -53,12 +53,11 @@ class CompressionCodecT64 : public ICompressionCodec\n \n     bool isCompression() const override { return true; }\n     bool isGenericCompression() const override { return false; }\n-    std::string getDescription() const override\n+    String getDescription() const override\n     {\n         return \"Preprocessor. Crops unused high bits; puts them into a 64x64 bit matrix; optimized for 64-bit data types.\";\n     }\n \n-\n private:\n     std::optional<TypeIndex> type_idx;\n     Variant variant;\ndiff --git a/src/Compression/CompressionCodecZSTD.h b/src/Compression/CompressionCodecZSTD.h\nindex 1c985799c98d..f363f1af69e1 100644\n--- a/src/Compression/CompressionCodecZSTD.h\n+++ b/src/Compression/CompressionCodecZSTD.h\n@@ -29,12 +29,11 @@ class CompressionCodecZSTD : public ICompressionCodec\n     bool isCompression() const override { return true; }\n     bool isGenericCompression() const override { return true; }\n \n-    std::string getDescription() const override\n+    String getDescription() const override\n     {\n         return \"Good compression; pretty fast; best for high compression needs. Don\u2019t use levels higher than 3.\";\n     }\n \n-\n private:\n     const int level;\n     const bool enable_long_range;\ndiff --git a/src/Compression/CompressionCodecZSTDQAT.cpp b/src/Compression/CompressionCodecZSTDQAT.cpp\nindex 5da4ba38f8ed..7fdf475d623d 100644\n--- a/src/Compression/CompressionCodecZSTDQAT.cpp\n+++ b/src/Compression/CompressionCodecZSTDQAT.cpp\n@@ -31,12 +31,11 @@ class CompressionCodecZSTDQAT : public CompressionCodecZSTD\n \n     explicit CompressionCodecZSTDQAT(int level_);\n \n-    std::string getDescription() const override\n+    String getDescription() const override\n     {\n         return \"Requires hardware support for QuickAssist Technology (QAT) hardware; provides accelerated compression tasks.\";\n     }\n \n-\n protected:\n     bool isZstdQat() const override { return true; }\n     UInt32 doCompressData(const char * source, UInt32 source_size, char * dest) const override;\ndiff --git a/src/Compression/CompressionFactory.cpp b/src/Compression/CompressionFactory.cpp\nindex 7ab5cb4691f8..f2ea45a70b88 100644\n--- a/src/Compression/CompressionFactory.cpp\n+++ b/src/Compression/CompressionFactory.cpp\n@@ -212,6 +212,9 @@ void registerCodecGorilla(CompressionCodecFactory & factory);\n void registerCodecEncrypted(CompressionCodecFactory & factory);\n void registerCodecFPC(CompressionCodecFactory & factory);\n void registerCodecGCD(CompressionCodecFactory & factory);\n+#if USE_SZ3\n+void registerCodecSZ3(CompressionCodecFactory & factory);\n+#endif\n \n CompressionCodecFactory::CompressionCodecFactory()\n {\n@@ -233,6 +236,9 @@ CompressionCodecFactory::CompressionCodecFactory()\n     registerCodecDeflateQpl(*this);\n #endif\n     registerCodecGCD(*this);\n+#if USE_SZ3\n+    registerCodecSZ3(*this);\n+#endif\n \n     default_codec = get(\"LZ4\", {});\n }\ndiff --git a/src/Compression/CompressionFactoryAdditions.cpp b/src/Compression/CompressionFactoryAdditions.cpp\nindex d897400a171e..d6164b52ee21 100644\n--- a/src/Compression/CompressionFactoryAdditions.cpp\n+++ b/src/Compression/CompressionFactoryAdditions.cpp\n@@ -156,19 +156,19 @@ ASTPtr CompressionCodecFactory::validateCodecAndGetPreprocessedAST(\n                 if (!allow_experimental_codecs && result_codec->isExperimental())\n                     throw Exception(ErrorCodes::BAD_ARGUMENTS,\n                         \"Codec {} is experimental and not meant to be used in production.\"\n-                        \" You can enable it with the 'allow_experimental_codecs' setting.\",\n+                        \" You can enable it with the 'allow_experimental_codecs' setting\",\n                         codec_family_name);\n \n                 if (!enable_deflate_qpl_codec && result_codec->isDeflateQpl())\n                     throw Exception(ErrorCodes::BAD_ARGUMENTS,\n                         \"Codec {} is disabled by default.\"\n-                        \" You can enable it with the 'enable_deflate_qpl_codec' setting.\",\n+                        \" You can enable it with the 'enable_deflate_qpl_codec' setting\",\n                         codec_family_name);\n \n                 if (!enable_zstd_qat_codec && result_codec->isZstdQat())\n                     throw Exception(ErrorCodes::BAD_ARGUMENTS,\n                         \"Codec {} is disabled by default.\"\n-                        \" You can enable it with the 'enable_zstd_qat_codec' setting.\",\n+                        \" You can enable it with the 'enable_zstd_qat_codec' setting\",\n                         codec_family_name);\n \n                 codecs_descriptions->children.emplace_back(result_codec->getCodecDesc());\ndiff --git a/src/Compression/CompressionInfo.h b/src/Compression/CompressionInfo.h\nindex 93ceef156d3a..9079f1412b80 100644\n--- a/src/Compression/CompressionInfo.h\n+++ b/src/Compression/CompressionInfo.h\n@@ -49,6 +49,7 @@ enum class CompressionMethodByte : uint8_t\n     DeflateQpl      = 0x99,\n     GCD             = 0x9a,\n     ZSTD_QPL        = 0x9b,\n+    SZ3             = 0x9c,\n };\n \n }\ndiff --git a/src/Compression/ICompressionCodec.cpp b/src/Compression/ICompressionCodec.cpp\nindex aac0d66dd474..29d217fcc155 100644\n--- a/src/Compression/ICompressionCodec.cpp\n+++ b/src/Compression/ICompressionCodec.cpp\n@@ -22,9 +22,15 @@ namespace DB\n \n namespace ErrorCodes\n {\n+    extern const int BAD_ARGUMENTS;\n     extern const int LOGICAL_ERROR;\n }\n \n+void ICompressionCodec::setAndCheckVectorDimension(size_t /*dimension*/)\n+{\n+    if (!needsVectorDimensionUpfront())\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Can not set dimensions for a non-vector codec\");\n+}\n \n void ICompressionCodec::setCodecDescription(const String & codec_name, const ASTs & arguments)\n {\ndiff --git a/src/Compression/ICompressionCodec.h b/src/Compression/ICompressionCodec.h\nindex f391471f27ab..c64bb8e503df 100644\n--- a/src/Compression/ICompressionCodec.h\n+++ b/src/Compression/ICompressionCodec.h\n@@ -96,6 +96,12 @@ class ICompressionCodec : private boost::noncopyable\n     /// Read size of decompressed block from compressed source\n     UInt32 readDecompressedBlockSize(const char * source) const;\n \n+    /// Does the codec need to know the vector (Array) dimension before compression?\n+    virtual bool needsVectorDimensionUpfront() const { return false; }\n+\n+    /// Setting dimension is useful for vector codecs (only SZ3 codec at the moment).\n+    virtual void setAndCheckVectorDimension(size_t /*dimension*/);\n+\n     /// Read method byte from compressed source\n     static uint8_t readMethod(const char * source);\n \n@@ -114,6 +120,8 @@ class ICompressionCodec : private boost::noncopyable\n     /// If the codec's purpose is to calculate deltas between consecutive values.\n     virtual bool isDeltaCompression() const { return false; }\n \n+    virtual bool isLossyCompression() const { return false; }\n+\n     /// It is a codec available only for evaluation purposes and not meant to be used in production.\n     /// It will not be allowed to use unless the user will turn off the safety switch.\n     virtual bool isExperimental() const { return false; }\n@@ -128,7 +136,7 @@ class ICompressionCodec : private boost::noncopyable\n     virtual bool isNone() const { return false; }\n \n     // Returns a string with a high level codec description.\n-    virtual std::string getDescription() const = 0;\n+    virtual String getDescription() const = 0;\n \n protected:\n     /// This is used for fuzz testing\ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartWriterCompact.cpp b/src/Storages/MergeTree/MergeTreeDataPartWriterCompact.cpp\nindex 12e5f714ba38..cf64e905b4dd 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartWriterCompact.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataPartWriterCompact.cpp\n@@ -73,6 +73,8 @@ MergeTreeDataPartWriterCompact::MergeTreeDataPartWriterCompact(\n \n void MergeTreeDataPartWriterCompact::addStreams(const NameAndTypePair & name_and_type, const ColumnPtr & column, const ASTPtr & effective_codec_desc)\n {\n+    CompressedStreamPtr prev_stream;\n+\n     ISerialization::StreamCallback callback = [&](const auto & substream_path)\n     {\n         assert(!substream_path.empty());\n@@ -91,12 +93,18 @@ void MergeTreeDataPartWriterCompact::addStreams(const NameAndTypePair & name_and\n         else /// otherwise return only generic codecs and don't use info about data_type\n             compression_codec = CompressionCodecFactory::instance().get(effective_codec_desc, nullptr, default_codec, true);\n \n+        /// If previous stream is not null it means it was Array offsets stream.\n+        /// Can't apply lossy compression for offsets.\n+        if (prev_stream && prev_stream->compressed_buf.getCodec()->isLossyCompression())\n+            prev_stream->compressed_buf.setCodec(CompressionCodecFactory::instance().getDefaultCodec());\n+\n         UInt64 codec_id = compression_codec->getHash();\n         auto & stream = streams_by_codec[codec_id];\n         if (!stream)\n             stream = std::make_shared<CompressedStream>(plain_hashing, compression_codec);\n \n         compressed_streams.emplace(stream_name, stream);\n+        prev_stream = stream;\n     };\n \n     ISerialization::EnumerateStreamsSettings enumerate_settings;\n@@ -258,6 +266,13 @@ void MergeTreeDataPartWriterCompact::writeDataBlock(const Block & block, const G\n                 String stream_name = ISerialization::getFileNameForStream(*name_and_type, substream_path);\n \n                 auto & result_stream = compressed_streams[stream_name];\n+\n+                /// Some vector codecs (e.g., SZ3) used for compressing arrays like Array<Float>\n+                /// require specifying the array dimensions before compression starts.\n+                /// For 1D arrays, it's simply the length.\n+                auto compression_codec = result_stream->compressed_buf.getCodec();\n+                setVectorDimensionsIfNeeded(compression_codec, block.getColumnOrSubcolumnByName(name_and_type->name).column.get());\n+\n                 /// Write one compressed block per column in granule for more optimal reading.\n                 if (prev_stream && prev_stream != result_stream)\n                 {\ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp b/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\nindex cfad4fa5f8fc..2f48194dfcc8 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\n@@ -6,6 +6,7 @@\n #include <Common/ElapsedTimeProfileEventIncrement.h>\n #include <Common/MemoryTrackerBlockerInThread.h>\n #include <Common/logger_useful.h>\n+#include <Columns/IColumn.h>\n #include <Compression/CompressionFactory.h>\n \n namespace ProfileEvents\n@@ -603,6 +604,31 @@ void MergeTreeDataPartWriterOnDisk::initOrAdjustDynamicStructureIfNeeded(Block &\n     }\n }\n \n+void MergeTreeDataPartWriterOnDisk::setVectorDimensionsIfNeeded(CompressionCodecPtr codec, const IColumn * column)\n+{\n+    if (codec->needsVectorDimensionUpfront())\n+    {\n+        Field sample_field;\n+        column->get(0, sample_field);\n+        if (sample_field.getType() == Field::Types::Array)\n+        {\n+            for (size_t j = 0; j < column->size(); ++j)\n+            {\n+                column->get(j, sample_field);\n+                codec->setAndCheckVectorDimension(sample_field.safeGet<Array>().size());\n+            }\n+        }\n+        if (sample_field.getType() == Field::Types::Tuple)\n+        {\n+            for (size_t j = 0; j < column->size(); ++j)\n+            {\n+                column->get(j, sample_field);\n+                codec->setAndCheckVectorDimension(sample_field.safeGet<Tuple>().size());\n+            }\n+        }\n+    }\n+}\n+\n template struct MergeTreeDataPartWriterOnDisk::Stream<false>;\n template struct MergeTreeDataPartWriterOnDisk::Stream<true>;\n \ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.h b/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.h\nindex 626215867d4a..86e9b480e670 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.h\n+++ b/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.h\n@@ -10,6 +10,8 @@\n #include <Parsers/parseQuery.h>\n #include <Storages/Statistics/Statistics.h>\n #include <Storages/MarkCache.h>\n+#include <Columns/IColumn_fwd.h>\n+#include <Compression/ICompressionCodec.h>\n \n namespace DB\n {\n@@ -176,6 +178,9 @@ class MergeTreeDataPartWriterOnDisk : public IMergeTreeDataPartWriter\n     /// the structure from the sample.\n     void initOrAdjustDynamicStructureIfNeeded(Block & block);\n \n+    /// This is useful only for vector codecs (like SZ3).\n+    static void setVectorDimensionsIfNeeded(CompressionCodecPtr codec, const IColumn * column);\n+\n     const MergeTreeIndices skip_indices;\n \n     const ColumnsStatistics stats;\ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartWriterWide.cpp b/src/Storages/MergeTree/MergeTreeDataPartWriterWide.cpp\nindex 9caaca8ef676..9c4040744d12 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartWriterWide.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataPartWriterWide.cpp\n@@ -128,6 +128,7 @@ void MergeTreeDataPartWriterWide::addStreams(\n     const ColumnPtr & column,\n     const ASTPtr & effective_codec_desc)\n {\n+    std::optional<String> prev_stream_name;\n     ISerialization::StreamCallback callback = [&](const auto & substream_path)\n     {\n         assert(!substream_path.empty());\n@@ -164,6 +165,12 @@ void MergeTreeDataPartWriterWide::addStreams(\n         else /// otherwise return only generic codecs and don't use info about the` data_type\n             compression_codec = CompressionCodecFactory::instance().get(effective_codec_desc, nullptr, default_codec, true);\n \n+        /// If previous stream is not null it means it was Array offsets stream.\n+        /// Can't apply lossy compression for offsets.\n+        if (prev_stream_name && column_streams[*prev_stream_name]->compressor.getCodec()->isLossyCompression())\n+            column_streams[*prev_stream_name]->compressor.setCodec(CompressionCodecFactory::instance().getDefaultCodec());\n+        prev_stream_name = stream_name;\n+\n         ParserCodec codec_parser;\n         auto ast = parseQuery(codec_parser, \"(\" + Poco::toUpper(settings.marks_compression_codec) + \")\", 0, DBMS_DEFAULT_MAX_PARSER_DEPTH, DBMS_DEFAULT_MAX_PARSER_BACKTRACKS);\n         CompressionCodecPtr marks_compression_codec = CompressionCodecFactory::instance().get(ast, nullptr);\n@@ -227,6 +234,7 @@ ISerialization::OutputStreamGetter MergeTreeDataPartWriterWide::createStreamGett\n         if (is_offsets && offset_columns.contains(stream_name))\n             return nullptr;\n \n+\n         return &column_streams.at(stream_name)->compressed_hashing;\n     };\n }\n@@ -447,6 +455,12 @@ void MergeTreeDataPartWriterWide::writeSingleGranule(\n         if (is_offsets && offset_columns.contains(stream_name))\n             return;\n \n+        /// Some vector codecs (e.g., SZ3) used for compressing arrays like Array<Float>\n+        /// require specifying the array dimensions before compression starts.\n+        /// For 1D arrays, it's simply the length.\n+        auto compression_codec = column_streams.at(stream_name)->compressor.getCodec();\n+        setVectorDimensionsIfNeeded(compression_codec, &column);\n+\n         column_streams.at(stream_name)->compressed_hashing.nextIfAtEnd();\n     }, name_and_type.type, column.getPtr());\n }\ndiff --git a/src/configure_config.cmake b/src/configure_config.cmake\nindex 436c24ac4085..5b8b24d30c35 100644\n--- a/src/configure_config.cmake\n+++ b/src/configure_config.cmake\n@@ -204,4 +204,8 @@ if (TARGET ch_contrib::sha3iuf)\n     set(USE_SHA3IUF 1)\n endif()\n \n+if (TARGET ch_contrib::sz3)\n+    set(USE_SZ3 1)\n+endif()\n+\n set(SOURCE_DIR ${PROJECT_SOURCE_DIR})\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01222_system_codecs.reference b/tests/queries/0_stateless/01222_system_codecs.reference\nindex cb4f6c553d4c..58e6ee595516 100644\n--- a/tests/queries/0_stateless/01222_system_codecs.reference\n+++ b/tests/queries/0_stateless/01222_system_codecs.reference\n@@ -9,11 +9,12 @@ Gorilla\t149\t1\t0\t0\t1\t0\tCalculates XOR between current and previous value; suitabl\n LZ4\t130\t1\t1\t0\t0\t0\tExtremely fast; good compression; balanced speed and efficiency.\n LZ4HC\t130\t1\t1\t0\t0\t0\tLZ4 High Compression algorithm with configurable level; slower but better compression than LZ4, but decompression is still fast.\n Multiple\t145\t0\t0\t0\t0\t0\tApply multiple codecs consecutively defined by user.\n-NONE\t2\t0\t0\t0\t0\t0\tNo compression at all. Can be used on the columns that can not be compressed anyway.\n+NONE\t2\t0\t0\t0\t0\t0\tNo compression. Can be used on columns that can not be compressed anyway.\n+SZ3\t156\t1\t1\t0\t0\t1\tSZ3 is a lossy compressor for floating-point data with error bounds.\n T64\t147\t1\t0\t0\t0\t0\tPreprocessor. Crops unused high bits; puts them into a 64x64 bit matrix; optimized for 64-bit data types.\n ZSTD\t144\t1\t1\t0\t0\t0\tGood compression; pretty fast; best for high compression needs. Don\u2019t use levels higher than 3.\n ZSTD_QAT\t144\t1\t1\t0\t0\t0\tRequires hardware support for QuickAssist Technology (QAT) hardware; provides accelerated compression tasks.\n-15\n+16\n name\n method_byte\n is_compression\ndiff --git a/tests/queries/0_stateless/03202_sz3_codec.reference b/tests/queries/0_stateless/03202_sz3_codec.reference\nnew file mode 100644\nindex 000000000000..beeddbd41e77\n--- /dev/null\n+++ b/tests/queries/0_stateless/03202_sz3_codec.reference\n@@ -0,0 +1,36 @@\n+Negative tests\n+Test wide/compact format\n+0\t[1,0]\n+1\t[1.1,0]\n+2\t[1.2,0]\n+3\t[1.3,0]\n+4\t[1.4,0]\n+5\t[1.5,0]\n+6\t[0,2]\n+7\t[0,2.1]\n+8\t[0,2.2]\n+9\t[0,2.3]\n+10\t[0,2.4]\n+11\t[0,2.5]\n+0\t[1,0]\n+1\t[1.1,0]\n+2\t[1.2,0]\n+3\t[1.3,0]\n+4\t[1.4,0]\n+5\t[1.5,0]\n+6\t[0,2]\n+7\t[0,2.1]\n+8\t[0,2.2]\n+9\t[0,2.3]\n+10\t[0,2.4]\n+11\t[0,2.5]\n+Test with default settings\n+-- Test F64\n+-- Test F32\n+Test with custom settings\n+-- Test F64\n+-- Test F32\n+Test 1d array\n+-- Test F64: summed relative error\n+-- Test F32: summed relative error\n+Simple test 1d tuple\ndiff --git a/tests/queries/0_stateless/03202_sz3_codec.sql b/tests/queries/0_stateless/03202_sz3_codec.sql\nnew file mode 100644\nindex 000000000000..60e7465f6585\n--- /dev/null\n+++ b/tests/queries/0_stateless/03202_sz3_codec.sql\n@@ -0,0 +1,319 @@\n+-- Tags: no-fasttest\n+-- no-fasttest: needs sz3 library\n+\n+SET allow_experimental_codecs = 1;\n+SET cross_to_inner_join_rewrite = 1;\n+SET async_insert = 1;\n+\n+DROP TABLE IF EXISTS tab;\n+\n+SELECT 'Negative tests';\n+\n+-- SZ3 can only be created on Float* and Array(Float*) columns\n+CREATE TABLE tab (compressed String CODEC(SZ3)) Engine = Memory; -- { serverError BAD_ARGUMENTS }\n+CREATE TABLE tab (compressed UInt64 CODEC(SZ3)) Engine = Memory; -- { serverError BAD_ARGUMENTS }\n+CREATE TABLE tab (compressed BFloat16 CODEC(SZ3)) Engine = Memory; -- { serverError BAD_ARGUMENTS }\n+CREATE TABLE tab (compressed Array(UInt64) CODEC(SZ3)) Engine = Memory; -- { serverError BAD_ARGUMENTS }\n+CREATE TABLE tab_map (\n+    compressed_f64   Map(UInt8, Float64) CODEC(SZ3('ALGO_INTERP', 'REL', 0.01)),\n+    compressed_f32   Map(UInt8, Float32) CODEC(SZ3('ALGO_INTERP', 'REL', 0.01))\n+) ENGINE = Memory; -- { serverError BAD_ARGUMENTS }\n+\n+-- SZ3 for array columns requires that all inserted arrays have the same cardinality\n+CREATE TABLE tab (key UInt64, val Array(Float64) CODEC(SZ3)) ENGINE = MergeTree ORDER BY key;\n+INSERT INTO tab VALUES (1, [1.0, 2.0]) (2, [3.0, 4.0, 5.0]); -- { serverError BAD_ARGUMENTS }\n+\n+DROP TABLE IF EXISTS tab;\n+\n+-- SZ3 requires 0 or 3 arguments\n+CREATE TABLE tab (compressed Float64 CODEC(SZ3('ALGO_INTERP'))) Engine = Memory; -- { serverError BAD_ARGUMENTS }\n+CREATE TABLE tab (compressed Float64 CODEC(SZ3('ALGO_INTERP', 'REL', 0.01, 1))) Engine = Memory; -- { serverError BAD_ARGUMENTS }\n+\n+-- The 1st argument must be a string\n+CREATE TABLE tab (compressed Float64 CODEC(SZ3(1, 'REL', 0.01))) Engine = Memory; -- { serverError ILLEGAL_CODEC_PARAMETER }\n+-- The 2nd argument must be a string\n+CREATE TABLE tab (compressed Float64 CODEC(SZ3('ALGO_INTERP', 1, 0.01))) Engine = Memory; -- { serverError ILLEGAL_CODEC_PARAMETER }\n+-- The 3rd argument must be a Float64\n+CREATE TABLE tab (compressed Float64 CODEC(SZ3('ALGO_INTERP', 'REL', 'not_a_f64'))) Engine = Memory; -- { serverError ILLEGAL_CODEC_PARAMETER }\n+\n+SELECT 'Test wide/compact format';\n+-- Very basic test to make sure nothing breaks\n+\n+DROP TABLE IF EXISTS tab_wide;\n+DROP TABLE IF EXISTS tab_compact;\n+\n+CREATE TABLE tab_wide(id Int32, vec Array(Float32) CODEC(SZ3)) ENGINE = MergeTree ORDER BY id SETTINGS min_bytes_for_wide_part = 0, min_rows_for_wide_part = 0;\n+CREATE TABLE tab_compact(id Int32, vec Array(Float32) CODEC(SZ3)) ENGINE = MergeTree ORDER BY id SETTINGS min_bytes_for_wide_part = 1e9, min_rows_for_wide_part = 1e9;\n+\n+INSERT INTO tab_wide VALUES (0, [1.0, 0.0]), (1, [1.1, 0.0]), (2, [1.2, 0.0]), (3, [1.3, 0.0]), (4, [1.4, 0.0]), (5, [1.5, 0.0]), (6, [0.0, 2.0]), (7, [0.0, 2.1]), (8, [0.0, 2.2]), (9, [0.0, 2.3]), (10, [0.0, 2.4]), (11, [0.0, 2.5]);\n+INSERT INTO tab_compact VALUES (0, [1.0, 0.0]), (1, [1.1, 0.0]), (2, [1.2, 0.0]), (3, [1.3, 0.0]), (4, [1.4, 0.0]), (5, [1.5, 0.0]), (6, [0.0, 2.0]), (7, [0.0, 2.1]), (8, [0.0, 2.2]), (9, [0.0, 2.3]), (10, [0.0, 2.4]), (11, [0.0, 2.5]);\n+\n+SELECT * FROM tab_wide ORDER BY ALL;\n+SELECT * FROM tab_compact ORDER BY ALL;\n+\n+DROP TABLE tab_wide;\n+\n+SELECT 'Test with default settings';\n+\n+CREATE TABLE tab (\n+    key                 UInt64,\n+    name                String,\n+    uncompressed_f64    Float64,\n+    uncompressed_f32    Float32,\n+    compressed_f64      Float64  CODEC(SZ3),\n+    compressed_f32      Float32  CODEC(SZ3)\n+) Engine = MergeTree ORDER BY key;\n+\n+-- best case - same value\n+INSERT INTO tab (key, name, uncompressed_f64, uncompressed_f32, compressed_f64, compressed_f32)\n+    SELECT number AS n, 'e()', e() AS v, v, v, v FROM system.numbers LIMIT 1, 100;\n+\n+-- good case - values that grow insignificantly\n+INSERT INTO tab (key, name, uncompressed_f64, uncompressed_f32, compressed_f64, compressed_f32)\n+    SELECT number AS n, 'log2(n)', log2(n) AS v, v, v, v FROM system.numbers LIMIT 101, 100;\n+\n+-- bad case - values differ significantly\n+INSERT INTO tab (key, name, uncompressed_f64, uncompressed_f32, compressed_f64, compressed_f32)\n+    SELECT number AS n, 'n*sqrt(n)', n * sqrt(n) AS v, v, v, v FROM system.numbers LIMIT 201, 100;\n+\n+-- worst case - almost like a random values\n+INSERT INTO tab (key, name, uncompressed_f64, uncompressed_f32, compressed_f64, compressed_f32)\n+    SELECT number AS n, 'sin(n*n*n)*n', sin(n * n * n)*n AS v, v, v, v FROM system.numbers LIMIT 301, 100;\n+\n+SELECT '-- Test F64';\n+SELECT\n+    c1.key, c1.name,\n+    c1.uncompressed_f64, c1.compressed_f64, c1.uncompressed_f64 - c1.compressed_f64 AS diff_f64,\n+    'prev:',\n+    c2.key, c2.uncompressed_f64\n+FROM\n+    tab as c1, tab as c2\n+WHERE\n+    abs(1 - diff_f64 / c1.uncompressed_f64) < 0.01\n+AND\n+    c2.key = c1.key - 1\n+LIMIT 10;\n+\n+SELECT '-- Test F32';\n+SELECT\n+    c1.key, c1.name,\n+    c1.uncompressed_f32, c1.compressed_f32, c1.uncompressed_f32 - c1.compressed_f32 AS diff_f32,\n+    'prev:',\n+    c2.key, c2.uncompressed_f32\n+FROM\n+    tab as c1, tab as c2\n+WHERE\n+    abs(1 - diff_f32 / c1.uncompressed_f32) < 0.01\n+AND\n+    c2.key = c1.key - 1\n+LIMIT 10;\n+\n+DROP TABLE tab;\n+\n+SELECT 'Test with custom settings';\n+\n+CREATE TABLE tab (\n+    key                 UInt64,\n+    name                String,\n+    uncompressed_f64    Float64,\n+    uncompressed_f32    Float32,\n+    compressed_f64      Float64  CODEC(SZ3('ALGO_INTERP', 'REL', 0.01)),\n+    compressed_f32      Float32  CODEC(SZ3('ALGO_INTERP', 'REL', 0.01))\n+) Engine = MergeTree ORDER BY key;\n+\n+-- best case - same value\n+INSERT INTO tab (key, name, uncompressed_f64, uncompressed_f32, compressed_f64, compressed_f32)\n+    SELECT number AS n, 'e()', e() AS v, v, v, v FROM system.numbers LIMIT 1, 100;\n+\n+-- good case - values that grow insignificantly\n+INSERT INTO tab (key, name, uncompressed_f64, uncompressed_f32, compressed_f64, compressed_f32)\n+    SELECT number AS n, 'log2(n)', log2(n) AS v, v, v, v FROM system.numbers LIMIT 101, 100;\n+\n+-- bad case - values differ significantly\n+INSERT INTO tab (key, name, uncompressed_f64, uncompressed_f32, compressed_f64, compressed_f32)\n+    SELECT number AS n, 'n*sqrt(n)', n*sqrt(n) AS v, v, v, v FROM system.numbers LIMIT 201, 100;\n+\n+-- worst case - almost like a random values\n+INSERT INTO tab (key, name, uncompressed_f64, uncompressed_f32, compressed_f64, compressed_f32)\n+    SELECT number AS n, 'sin(n*n*n)*n', sin(n * n * n)*n AS v, v, v, v FROM system.numbers LIMIT 301, 100;\n+\n+SELECT '-- Test F64';\n+SELECT\n+    c1.key, c1.name,\n+    c1.uncompressed_f64, c1.compressed_f64, c1.uncompressed_f64 - c1.compressed_f64 AS diff_f64,\n+    'prev:',\n+    c2.key, c2.uncompressed_f64\n+FROM\n+    tab as c1, tab as c2\n+WHERE\n+    abs(1 - diff_f64 / c1.uncompressed_f64) < 0.01\n+AND\n+    c2.key = c1.key - 1\n+LIMIT 10;\n+\n+\n+SELECT '-- Test F32';\n+SELECT\n+    c1.key, c1.name,\n+    c1.uncompressed_f32, c1.compressed_f32, c1.uncompressed_f32 - c1.compressed_f32 AS diff_f32,\n+    'prev:',\n+    c2.key, c2.uncompressed_f32\n+FROM\n+    tab as c1, tab as c2\n+WHERE\n+    abs(1 - diff_f32 / c1.uncompressed_f32) < 0.01\n+AND\n+    c2.key = c1.key - 1\n+LIMIT 10;\n+\n+SELECT 'Test 1d array';\n+\n+DROP TABLE IF EXISTS tab;\n+\n+CREATE TABLE tab (\n+    key              UInt64,\n+    name             String,\n+    uncompressed_f64 Array(Float64),\n+    uncompressed_f32 Array(Float32),\n+    compressed_f64   Array(Float64) CODEC(SZ3('ALGO_INTERP', 'REL', 0.01)),\n+    compressed_f32   Array(Float32) CODEC(SZ3('ALGO_INTERP', 'REL', 0.01))\n+) ENGINE = MergeTree ORDER BY key;\n+\n+-- best case - all elements equal\n+INSERT INTO tab\n+SELECT\n+    number AS key,\n+    'constant array' AS name,\n+    arrayResize([e()], 10) AS v64,\n+    arrayResize([toFloat32(e())], 10) AS v32,\n+    v64, v32\n+FROM system.numbers LIMIT 10;\n+\n+-- good case - slightly growing values\n+INSERT INTO tab\n+SELECT\n+    number + 100 AS key,\n+    'log(1..10)' AS name,\n+    arrayMap(i -> log(number + i + 1), range(100)) AS v64,\n+    arrayMap(i -> toFloat32(log(number + i + 1)), range(100)) AS v32,\n+    v64, v32\n+FROM system.numbers LIMIT 100;\n+\n+-- bad case - rapidly growing values\n+INSERT INTO tab\n+SELECT\n+    number + 200 AS key,\n+    'i*sqrt(i)' AS name,\n+    arrayMap(i -> i * sqrt(i), range(100)) AS v64,\n+    arrayMap(i -> toFloat32(i * sqrt(i)), range(100)) AS v32,\n+    v64, v32\n+FROM system.numbers LIMIT 100;\n+\n+-- worst case - pseudo-random\n+INSERT INTO tab\n+SELECT\n+    number + 300 AS key,\n+    'sin(i*i*i)*i' AS name,\n+    arrayMap(i -> sin(i * i * i) * i, range(100)) AS v64,\n+    arrayMap(i -> toFloat32(sin(i * i * i) * i), range(100)) AS v32,\n+    v64, v32\n+FROM system.numbers LIMIT 100;\n+\n+-- Comparing F64: sum of absolute errors / sum of original\n+SELECT '-- Test F64: summed relative error';\n+SELECT\n+    name,\n+    sum(arrayReduce('max', arrayMap((r, v) -> abs(r - v), uncompressed_f64, compressed_f64))) AS abs_error,\n+    sum(arrayReduce('max', arrayMap(r -> abs(r), uncompressed_f64))) AS abs_total,\n+    abs_error / abs_total AS rel_error\n+FROM tab\n+GROUP BY name\n+HAVING rel_error > 0.02;\n+\n+-- Comparing F32: sum of absolute errors / sum of original\n+SELECT '-- Test F32: summed relative error';\n+SELECT\n+    name,\n+    sum(arrayReduce('max', arrayMap((r, v) -> abs(r - v), uncompressed_f32, compressed_f32))) AS abs_error,\n+    sum(arrayReduce('max', arrayMap(r -> abs(r), uncompressed_f32))) AS abs_total,\n+    abs_error / abs_total AS rel_error\n+FROM tab\n+GROUP BY name\n+HAVING rel_error > 0.02;\n+\n+DROP TABLE tab;\n+\n+SELECT 'Simple test 1d tuple';\n+\n+DROP TABLE IF EXISTS tab;\n+\n+CREATE TABLE tab (\n+    key              UInt64,\n+    name             String,\n+    uncompressed_f64 Tuple(Float64),\n+    uncompressed_f32 Tuple(Float32),\n+    compressed_f64   Tuple(Float64) CODEC(SZ3('ALGO_INTERP', 'REL', 0.01)),\n+    compressed_f32   Tuple(Float32) CODEC(SZ3('ALGO_INTERP', 'REL', 0.01))\n+) ENGINE = MergeTree ORDER BY key;\n+\n+INSERT INTO tab VALUES\n+(\n+    1,\n+    'alpha',\n+    (123.456),\n+    (12.34),\n+    (123.456),\n+    (12.34)\n+),\n+(\n+    2,\n+    'beta',\n+    (654.321),\n+    (43.21),\n+    (654.321),\n+    (43.21)\n+),\n+(\n+    3,\n+    'gamma',\n+    (111.222),\n+    (22.11),\n+    (111.222),\n+    (22.11)\n+),\n+(\n+    4,\n+    'delta',\n+    (0.001),\n+    (0.002),\n+    (0.001),\n+    (0.002)\n+),\n+(\n+    5,\n+    'epsilon',\n+    (9999.999),\n+    (999.99),\n+    (9999.999),\n+    (999.99)\n+);\n+\n+SELECT\n+    c1.key,\n+    c1.name,\n+    c1.uncompressed_f64,\n+    c1.compressed_f64,\n+    tupleElement(c1.uncompressed_f64, 1) - tupleElement(c1.compressed_f64, 1) AS diff_f64,\n+    'prev:' AS marker,\n+    c2.key AS prev_key,\n+    c2.uncompressed_f64 AS prev_uncompressed_f64\n+FROM\n+    tab AS c1\n+INNER JOIN\n+    tab AS c2\n+    ON c2.key = toUInt64(c1.key - 1)\n+WHERE\n+    abs(1 - (tupleElement(c1.uncompressed_f64, 1) - tupleElement(c1.compressed_f64, 1)) / tupleElement(c1.uncompressed_f64, 1)) < 0.01\n+LIMIT 10;\n+\n+DROP TABLE tab;\n",
  "problem_statement": "Add support for SZ Compression\nAdd support for lossy compression. https://github.com/szcompressor/SZ has shown to perform well and can be bounded. C implementation.\r\n\r\nUseful for vector embeddings.\n",
  "hints_text": "\\+ https://computing.llnl.gov/projects/zfp also comes to mind.\r\n\r\nSZ and ZFP seem both established, popular and stable lossy FP algorithms with C/C++ implementations. The nice thing about them is that one can specify an error threshold (\"compress with at most 5% loss of precision\").\r\n\r\nThey each exist in different versions, so anyone interested in doing this would need to survey what libraries exist.\n@alexey-milovidov is this task still relevant? I'm interested in the part with sz compression\r\n",
  "created_at": "2025-07-02T14:24:49Z",
  "modified_files": [
    ".gitmodules",
    "ci/jobs/scripts/check_style/aspell-ignore/en/aspell-dict.txt",
    "contrib/CMakeLists.txt",
    "b/contrib/sz3",
    "b/contrib/sz3-cmake/CMakeLists.txt",
    "b/contrib/sz3-cmake/SZ3/version.hpp",
    "docs/en/sql-reference/statements/create/table.md",
    "src/CMakeLists.txt",
    "src/Common/config.h.in",
    "src/Compression/CompressionCodecDeflateQpl.h",
    "src/Compression/CompressionCodecDelta.cpp",
    "src/Compression/CompressionCodecDoubleDelta.cpp",
    "src/Compression/CompressionCodecEncrypted.h",
    "src/Compression/CompressionCodecFPC.cpp",
    "src/Compression/CompressionCodecGCD.cpp",
    "src/Compression/CompressionCodecGorilla.cpp",
    "src/Compression/CompressionCodecLZ4.cpp",
    "src/Compression/CompressionCodecMultiple.h",
    "src/Compression/CompressionCodecNone.h",
    "b/src/Compression/CompressionCodecSZ3.cpp",
    "src/Compression/CompressionCodecT64.cpp",
    "src/Compression/CompressionCodecZSTD.h",
    "src/Compression/CompressionCodecZSTDQAT.cpp",
    "src/Compression/CompressionFactory.cpp",
    "src/Compression/CompressionFactoryAdditions.cpp",
    "src/Compression/CompressionInfo.h",
    "src/Compression/ICompressionCodec.cpp",
    "src/Compression/ICompressionCodec.h",
    "src/Storages/MergeTree/MergeTreeDataPartWriterCompact.cpp",
    "src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp",
    "src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.h",
    "src/Storages/MergeTree/MergeTreeDataPartWriterWide.cpp",
    "src/configure_config.cmake"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/01222_system_codecs.reference",
    "b/tests/queries/0_stateless/03202_sz3_codec.reference",
    "b/tests/queries/0_stateless/03202_sz3_codec.sql"
  ]
}