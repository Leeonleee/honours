{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 47490,
  "instance_id": "ClickHouse__ClickHouse-47490",
  "issue_numbers": [
    "43544"
  ],
  "base_commit": "8e228187d5a4b18c669d4f0c95ec8fb09f25b1e1",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex 73007e3f1788..d7cea944689b 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -4121,9 +4121,9 @@ void MergeTreeData::delayInsertOrThrowIfNeeded(Poco::Event * until, const Contex\n         ProfileEvents::increment(ProfileEvents::RejectedInserts);\n         throw Exception(\n             ErrorCodes::TOO_MANY_PARTS,\n-            \"Too many parts ({}) in all partitions in total. This indicates wrong choice of partition key. The threshold can be modified \"\n+            \"Too many parts ({}) in all partitions in total in table '{}'. This indicates wrong choice of partition key. The threshold can be modified \"\n             \"with 'max_parts_in_total' setting in <merge_tree> element in config.xml or with per-table setting.\",\n-            parts_count_in_total);\n+            parts_count_in_total, getLogName());\n     }\n \n     size_t outdated_parts_over_threshold = 0;\n@@ -4137,8 +4137,8 @@ void MergeTreeData::delayInsertOrThrowIfNeeded(Poco::Event * until, const Contex\n             ProfileEvents::increment(ProfileEvents::RejectedInserts);\n             throw Exception(\n                 ErrorCodes::TOO_MANY_PARTS,\n-                \"Too many inactive parts ({}). Parts cleaning are processing significantly slower than inserts\",\n-                outdated_parts_count_in_partition);\n+                \"Too many inactive parts ({}) in table '{}'. Parts cleaning are processing significantly slower than inserts\",\n+                outdated_parts_count_in_partition, getLogName());\n         }\n         if (settings->inactive_parts_to_delay_insert > 0 && outdated_parts_count_in_partition >= settings->inactive_parts_to_delay_insert)\n             outdated_parts_over_threshold = outdated_parts_count_in_partition - settings->inactive_parts_to_delay_insert + 1;\n@@ -4151,6 +4151,7 @@ void MergeTreeData::delayInsertOrThrowIfNeeded(Poco::Event * until, const Contex\n     const auto active_parts_to_throw_insert\n         = query_settings.parts_to_throw_insert ? query_settings.parts_to_throw_insert : settings->parts_to_throw_insert;\n     size_t active_parts_over_threshold = 0;\n+\n     {\n         bool parts_are_large_enough_in_average\n             = settings->max_avg_part_size_for_too_many_parts && average_part_size > settings->max_avg_part_size_for_too_many_parts;\n@@ -4160,9 +4161,10 @@ void MergeTreeData::delayInsertOrThrowIfNeeded(Poco::Event * until, const Contex\n             ProfileEvents::increment(ProfileEvents::RejectedInserts);\n             throw Exception(\n                 ErrorCodes::TOO_MANY_PARTS,\n-                \"Too many parts ({} with average size of {}). Merges are processing significantly slower than inserts\",\n+                \"Too many parts ({} with average size of {}) in table '{}'. Merges are processing significantly slower than inserts\",\n                 parts_count_in_partition,\n-                ReadableSize(average_part_size));\n+                ReadableSize(average_part_size),\n+                getLogName());\n         }\n         if (active_parts_to_delay_insert > 0 && parts_count_in_partition >= active_parts_to_delay_insert\n             && !parts_are_large_enough_in_average)\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/00933_test_fix_extra_seek_on_compressed_cache.reference b/tests/queries/0_stateless/00933_test_fix_extra_seek_on_compressed_cache.reference\nindex f1839bae2594..e142c6c79fef 100644\n--- a/tests/queries/0_stateless/00933_test_fix_extra_seek_on_compressed_cache.reference\n+++ b/tests/queries/0_stateless/00933_test_fix_extra_seek_on_compressed_cache.reference\n@@ -1,1 +1,3 @@\n+99999\n+99999\n 0\t0\t13\ndiff --git a/tests/queries/0_stateless/00933_test_fix_extra_seek_on_compressed_cache.sh b/tests/queries/0_stateless/00933_test_fix_extra_seek_on_compressed_cache.sh\nindex 390d6a70ef10..7bf4a88e972c 100755\n--- a/tests/queries/0_stateless/00933_test_fix_extra_seek_on_compressed_cache.sh\n+++ b/tests/queries/0_stateless/00933_test_fix_extra_seek_on_compressed_cache.sh\n@@ -13,15 +13,24 @@ $CLICKHOUSE_CLIENT --query=\"CREATE TABLE small_table (a UInt64 default 0, n UInt\n $CLICKHOUSE_CLIENT --query=\"INSERT INTO small_table (n) SELECT * from system.numbers limit 100000;\"\n $CLICKHOUSE_CLIENT --query=\"OPTIMIZE TABLE small_table FINAL;\"\n \n-cached_query=\"SELECT count() FROM small_table where n > 0;\"\n+cached_query=\"SELECT count() FROM small_table WHERE n > 0;\"\n \n-$CLICKHOUSE_CLIENT --use_uncompressed_cache=1 --query=\"$cached_query\" &> /dev/null\n-\n-$CLICKHOUSE_CLIENT --use_uncompressed_cache=1 --allow_prefetched_read_pool_for_remote_filesystem=0 --allow_prefetched_read_pool_for_local_filesystem=0 --query_id=\"test-query-uncompressed-cache\" --query=\"$cached_query\" &> /dev/null\n+$CLICKHOUSE_CLIENT --log_queries 1 --use_uncompressed_cache 1 --query=\"$cached_query\"\n+$CLICKHOUSE_CLIENT --log_queries 1 --use_uncompressed_cache 1 --allow_prefetched_read_pool_for_remote_filesystem 0 --allow_prefetched_read_pool_for_local_filesystem 0 --query_id=\"test-query-uncompressed-cache\" --query=\"$cached_query\"\n \n $CLICKHOUSE_CLIENT --query=\"SYSTEM FLUSH LOGS\"\n \n-\n-$CLICKHOUSE_CLIENT --query=\"SELECT ProfileEvents['Seek'], ProfileEvents['ReadCompressedBytes'], ProfileEvents['UncompressedCacheHits'] AS hit FROM system.query_log WHERE (query_id = 'test-query-uncompressed-cache') and current_database = currentDatabase() AND (type = 2) AND event_date >= yesterday() ORDER BY event_time DESC LIMIT 1\"\n+$CLICKHOUSE_CLIENT --query=\"\n+    SELECT\n+        ProfileEvents['Seek'],\n+        ProfileEvents['ReadCompressedBytes'],\n+        ProfileEvents['UncompressedCacheHits'] AS hit\n+    FROM system.query_log\n+    WHERE query_id = 'test-query-uncompressed-cache'\n+        AND current_database = currentDatabase()\n+        AND type = 2\n+        AND event_date >= yesterday()\n+    ORDER BY event_time DESC\n+    LIMIT 1\"\n \n $CLICKHOUSE_CLIENT --query=\"DROP TABLE IF EXISTS small_table\"\ndiff --git a/tests/queries/0_stateless/02286_drop_filesystem_cache.sh b/tests/queries/0_stateless/02286_drop_filesystem_cache.sh\nindex b563c4876465..991622446b8b 100755\n--- a/tests/queries/0_stateless/02286_drop_filesystem_cache.sh\n+++ b/tests/queries/0_stateless/02286_drop_filesystem_cache.sh\n@@ -16,7 +16,7 @@ for STORAGE_POLICY in 's3_cache' 'local_cache'; do\n                                    ORDER BY key\n                                    SETTINGS storage_policy='$STORAGE_POLICY', min_bytes_for_wide_part = 10485760\"\n \n-    $CLICKHOUSE_CLIENT --query \"SYSTEM STOP MERGES\"\n+    $CLICKHOUSE_CLIENT --query \"SYSTEM STOP MERGES test_02286\"\n     $CLICKHOUSE_CLIENT --query \"SYSTEM DROP FILESYSTEM CACHE\"\n \n     $CLICKHOUSE_CLIENT --query \"SELECT count() FROM system.filesystem_cache\"\n",
  "problem_statement": "Test `00933_test_fix_extra_seek_on_compressed_cache` is flaky\nExample: https://s3.amazonaws.com/clickhouse-test-reports/0/481b9face12511b559ef021e1b032427547dabd7/stateless_tests__asan_.html\r\n\r\nhttps://play.clickhouse.com/play?user=play#c2VsZWN0IAp0b1N0YXJ0T2ZEYXkoY2hlY2tfc3RhcnRfdGltZSkgYXMgZCwKY291bnQoKSwgIGdyb3VwVW5pcUFycmF5KHB1bGxfcmVxdWVzdF9udW1iZXIpLCAgYW55KHJlcG9ydF91cmwpCmZyb20gY2hlY2tzIHdoZXJlICcyMDIyLTA2LTAxJyA8PSBjaGVja19zdGFydF90aW1lIGFuZCB0ZXN0X25hbWUgbGlrZSAnJTAwOTMzX3Rlc3RfZml4X2V4dHJhX3NlZWtfb25fY29tcHJlc3NlZF9jYWNoZSUnIGFuZCB0ZXN0X3N0YXR1cyBpbiAoJ0ZBSUwnLCAnRkxBS1knKSBncm91cCBieSBkIG9yZGVyIGJ5IGQgZGVzYw==\r\n\r\nIt's interesting that in release branches and backport PRs it fail much more often than in master and ordinary PRs\n",
  "hints_text": "Repro steps by @Avogar \r\n```\r\n$ export CLICKHOUSE_CLIENT=\"/home/avogar/tmp/master/clickhouse-release client --max_insert_threads=6 --group_by_two_level_threshold=100000 --group_by_two_level_threshold_bytes=1152921504606846976 --distributed_aggregation_memory_efficient=0 --fsync_metadata=0 --output_format_parallel_formatting=0 --input_format_parallel_parsing=0 --min_chunk_bytes_for_parallel_parsing=11673592 --max_read_buffer_size=861682 --prefer_localhost_replica=1 --max_block_size=16859 --max_threads=50 --optimize_or_like_chain=0 --optimize_read_in_order=0 --read_in_order_two_level_merge_threshold=29 --optimize_aggregation_in_order=1 --aggregation_in_order_max_block_bytes=23514619 --use_uncompressed_cache=1 --min_bytes_to_use_direct_io=1041792382 --min_bytes_to_use_mmap_io=34814106 --local_filesystem_read_method=read --remote_filesystem_read_method=threadpool --local_filesystem_read_prefetch=0 --remote_filesystem_read_prefetch=0 --compile_expressions=1 --compile_aggregate_expressions=0 --compile_sort_description=0 --merge_tree_coarse_index_granularity=17 --optimize_distinct_in_order=0 --optimize_sorting_by_input_stream_properties=0\"\r\n$ ./00933_test_fix_extra_seek_on_compressed_cache.sh\r\n$\r\n```\nThese lines \r\n\r\n```\r\n$CLICKHOUSE_CLIENT --use_uncompressed_cache=1 --query=\"$cached_query\" &> /dev/null\r\n\r\n$CLICKHOUSE_CLIENT --use_uncompressed_cache=1 --query_id=\"test-query-uncompressed-cache\" --query=\"$cached_query\" &> /dev/null\r\n```\r\n\r\nwere actually erroring with \"Bad arguments: option '--use_uncompressed_cache' cannot be specified more than once\" but it was hidden by  `&> /dev/null`\nFrom further investigation by @Avogar it looks like the problem is not with duplicate settings in the command line:\r\n \r\nAnd according to server logs all queries from this tests were executed and completed. But we have logs for the last select query that should produce result we expect.\r\nLog from failed test: https://pastila.nl/?03a4d435/ef481658ec8640c3c3b52334af26d5ee\r\nIn the end  `MergingSortedTransform: Merge sorted 1 blocks, 0 rows in 0.12800034 sec., 0 rows/sec., 4.88 KiB/sec . So 0 rows in the result.`\r\nLog from passed test:\r\nhttps://pastila.nl/?02da71a4/fbd5953bc68bc8b02e220f769f0b4c6f\r\nIn the end\r\n`MergingSortedTransform: Merge sorted 1 blocks, 1 rows in 0.004000085 sec., 249.99468761288824 rows/sec., 575.18 KiB/sec `. So 1 expected row in the result.\r\n\r\nCan it be a bug in SelectExecutor ?\r\n\r\nTheory: this test uses query log and in backports we run all stateless test in one run, while in PRs/master we split it into several runs with less tests. Maybe this bug appears when query_log is big enough\r\n",
  "created_at": "2023-03-11T20:45:54Z"
}