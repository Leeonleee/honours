{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 10025,
  "instance_id": "ClickHouse__ClickHouse-10025",
  "issue_numbers": [
    "8636",
    "8925"
  ],
  "base_commit": "e381246bc1bf32b3f1690ad8925933f0ff32a4dd",
  "patch": "diff --git a/dbms/Common/HashTable/StringHashMap.h b/dbms/Common/HashTable/StringHashMap.h\nindex 3ee59c89a369..fe4eab160928 100644\n--- a/dbms/Common/HashTable/StringHashMap.h\n+++ b/dbms/Common/HashTable/StringHashMap.h\n@@ -25,9 +25,13 @@ struct StringHashMapCell<StringKey16, TMapped> : public HashMapCell<StringKey16,\n     using Base::Base;\n     static constexpr bool need_zero_value_storage = false;\n     bool isZero(const HashTableNoState & state) const { return isZero(this->value.first, state); }\n-    // Assuming String does not contain zero bytes. NOTE: Cannot be used in serialized method\n-    static bool isZero(const StringKey16 & key, const HashTableNoState & /*state*/) { return key.low == 0; }\n-    void setZero() { this->value.first.low = 0; }\n+\n+    // Zero means unoccupied cells in hash table. Use key with last word = 0 as\n+    // zero keys, because such keys are unrepresentable (no way to encode length).\n+    static bool isZero(const StringKey16 & key, const HashTableNoState &)\n+    { return key.high == 0; }\n+    void setZero() { this->value.first.high = 0; }\n+\n     // external\n     const StringRef getKey() const { return toStringRef(this->value.first); }\n     // internal\n@@ -42,9 +46,13 @@ struct StringHashMapCell<StringKey24, TMapped> : public HashMapCell<StringKey24,\n     using Base::Base;\n     static constexpr bool need_zero_value_storage = false;\n     bool isZero(const HashTableNoState & state) const { return isZero(this->value.first, state); }\n-    // Assuming String does not contain zero bytes. NOTE: Cannot be used in serialized method\n-    static bool isZero(const StringKey24 & key, const HashTableNoState & /*state*/) { return key.a == 0; }\n-    void setZero() { this->value.first.a = 0; }\n+\n+    // Zero means unoccupied cells in hash table. Use key with last word = 0 as\n+    // zero keys, because such keys are unrepresentable (no way to encode length).\n+    static bool isZero(const StringKey24 & key, const HashTableNoState &)\n+    { return key.c == 0; }\n+    void setZero() { this->value.first.c = 0; }\n+\n     // external\n     const StringRef getKey() const { return toStringRef(this->value.first); }\n     // internal\ndiff --git a/dbms/Common/HashTable/StringHashTable.h b/dbms/Common/HashTable/StringHashTable.h\nindex d80b26c6a7c3..101327ed809c 100644\n--- a/dbms/Common/HashTable/StringHashTable.h\n+++ b/dbms/Common/HashTable/StringHashTable.h\n@@ -18,14 +18,17 @@ struct StringKey24\n \n inline StringRef ALWAYS_INLINE toStringRef(const StringKey8 & n)\n {\n+    assert(n != 0);\n     return {reinterpret_cast<const char *>(&n), 8ul - (__builtin_clzll(n) >> 3)};\n }\n inline StringRef ALWAYS_INLINE toStringRef(const StringKey16 & n)\n {\n+    assert(n.high != 0);\n     return {reinterpret_cast<const char *>(&n), 16ul - (__builtin_clzll(n.high) >> 3)};\n }\n inline StringRef ALWAYS_INLINE toStringRef(const StringKey24 & n)\n {\n+    assert(n.c != 0);\n     return {reinterpret_cast<const char *>(&n), 24ul - (__builtin_clzll(n.c) >> 3)};\n }\n \n@@ -229,6 +232,7 @@ class StringHashTable : private boost::noncopyable\n     template <typename Self, typename KeyHolder, typename Func>\n     static auto ALWAYS_INLINE dispatch(Self & self, KeyHolder && key_holder, Func && func)\n     {\n+        StringHashTableHash hash;\n         const StringRef & x = keyHolderGetKey(key_holder);\n         const size_t sz = x.size;\n         if (sz == 0)\n@@ -237,6 +241,13 @@ class StringHashTable : private boost::noncopyable\n             return func(self.m0, VoidKey{}, 0);\n         }\n \n+        if (x.data[sz - 1] == 0)\n+        {\n+            // Strings with trailing zeros are not representable as fixed-size\n+            // string keys. Put them to the generic table.\n+            return func(self.ms, std::forward<KeyHolder>(key_holder), hash(x));\n+        }\n+\n         const char * p = x.data;\n         // pending bits that needs to be shifted out\n         const char s = (-sz & 7) * 8;\n@@ -247,7 +258,6 @@ class StringHashTable : private boost::noncopyable\n             StringKey24 k24;\n             UInt64 n[3];\n         };\n-        StringHashTableHash hash;\n         switch ((sz - 1) >> 3)\n         {\n             case 0: // 1..8 bytes\ndiff --git a/dbms/Common/HashTable/TwoLevelStringHashTable.h b/dbms/Common/HashTable/TwoLevelStringHashTable.h\nindex 88241c6c5feb..93bbcb2835dc 100644\n--- a/dbms/Common/HashTable/TwoLevelStringHashTable.h\n+++ b/dbms/Common/HashTable/TwoLevelStringHashTable.h\n@@ -77,6 +77,7 @@ class TwoLevelStringHashTable : private boost::noncopyable\n     template <typename Self, typename Func, typename KeyHolder>\n     static auto ALWAYS_INLINE dispatch(Self & self, KeyHolder && key_holder, Func && func)\n     {\n+        StringHashTableHash hash;\n         const StringRef & x = keyHolderGetKey(key_holder);\n         const size_t sz = x.size;\n         if (sz == 0)\n@@ -85,6 +86,16 @@ class TwoLevelStringHashTable : private boost::noncopyable\n             return func(self.impls[0].m0, VoidKey{}, 0);\n         }\n \n+        if (x.data[x.size - 1] == 0)\n+        {\n+            // Strings with trailing zeros are not representable as fixed-size\n+            // string keys. Put them to the generic table.\n+            auto res = hash(x);\n+            auto buck = getBucketFromHash(res);\n+            return func(self.impls[buck].ms, std::forward<KeyHolder>(key_holder),\n+                res);\n+        }\n+\n         const char * p = x.data;\n         // pending bits that needs to be shifted out\n         const char s = (-sz & 7) * 8;\n@@ -95,7 +106,6 @@ class TwoLevelStringHashTable : private boost::noncopyable\n             StringKey24 k24;\n             UInt64 n[3];\n         };\n-        StringHashTableHash hash;\n         switch ((sz - 1) >> 3)\n         {\n             case 0:\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01109_sc0rp10_string_hash_map_zero_bytes.reference b/tests/queries/0_stateless/01109_sc0rp10_string_hash_map_zero_bytes.reference\nnew file mode 100644\nindex 000000000000..d00491fd7e5b\n--- /dev/null\n+++ b/tests/queries/0_stateless/01109_sc0rp10_string_hash_map_zero_bytes.reference\n@@ -0,0 +1,1 @@\n+1\ndiff --git a/tests/queries/0_stateless/01109_sc0rp10_string_hash_map_zero_bytes.sql b/tests/queries/0_stateless/01109_sc0rp10_string_hash_map_zero_bytes.sql\nnew file mode 100644\nindex 000000000000..b7ac6f1641ff\n--- /dev/null\n+++ b/tests/queries/0_stateless/01109_sc0rp10_string_hash_map_zero_bytes.sql\n@@ -0,0 +1,15 @@\n+-- Test that the string hash map works properly with keys containing zero\n+-- bytes.\n+-- Keys with no central '1' are mostly duplicates. The unique keys\n+-- in this group are '', '\\0', ...., '\\0 x 34', to a total of 35. All other\n+-- keys are unique.\n+select count(*) = 18 * 18 * 17 + 35 \n+from (\n+    select key\n+    from (\n+        with 18 as n\n+        select repeat('\\0', number % n)\n+            || repeat('1', intDiv(number, n) % n)\n+            || repeat('\\0', intDiv(number, n * n) % n) key\n+        from numbers(18 * 18 * 18))\n+    group by key);\n",
  "problem_statement": "clickhouse crash \" Received signal Segmentation fault\"\n2020.01.13 23:43:56.376109 [ 969 ] {} <Fatal> BaseDaemon: ########################################\r\n2020.01.13 23:43:56.376119 [ 970 ] {} <Fatal> BaseDaemon: ########################################\r\n2020.01.13 23:43:56.376170 [ 969 ] {} <Fatal> BaseDaemon: (version 19.17.6.36 (official build)) (from thread 348) Received signal Segmentation fault (11).\r\n2020.01.13 23:43:56.376178 [ 970 ] {} <Fatal> BaseDaemon: (version 19.17.6.36 (official build)) (from thread 88) Received signal Segmentation fault (11).\r\n2020.01.13 23:43:56.376200 [ 969 ] {} <Fatal> BaseDaemon: Address: 0x10 Access: read. Address not mapped to object.\r\n2020.01.13 23:43:56.376200 [ 970 ] {} <Fatal> BaseDaemon: Address: 0x10 Access: read. Address not mapped to object.\r\n2020.01.13 23:43:56.377019 [ 970 ] {} <Fatal> BaseDaemon: Stack trace: 0x5624850f3c7c 0x562485166087 0x5624850ddc82 0x5624850de5e8 0x562485079e3f 0x56248507a7ed 0x5624816cc55c 0x562487470780 0x7f43d979fe25 0x7f43d90c134d\r\n2020.01.13 23:43:56.377022 [ 969 ] {} <Fatal> BaseDaemon: Stack trace: 0x5624850f3c7c 0x562485166087 0x5624850ddc82 0x5624850de5e8 0x562485079e3f 0x56248507a7ed 0x5624816cc55c 0x562487470780 0x7f43d979fe25 0x7f43d90c134d\r\n2020.01.13 23:43:56.377989 [ 969 ] {} <Fatal> BaseDaemon: 3. 0x5624850f3c7c void DB::Aggregator::executeImplCase<true, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >::State&, DB::Arena*, unsigned long, DB::Aggregator::AggregateFunctionInstruction*, char*) const ?\r\n2020.01.13 23:43:56.377990 [ 970 ] {} <Fatal> BaseDaemon: 3. 0x5624850f3c7c void DB::Aggregator::executeImplCase<true, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >::State&, DB::Arena*, unsigned long, DB::Aggregator::AggregateFunctionInstruction*, char*) const ?\r\n2020.01.13 23:43:56.378571 [ 970 ] {} <Fatal> BaseDaemon: 4. 0x562485166087 void DB::Aggregator::executeImpl<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, bool, char*) const ?\r\n2020.01.13 23:43:56.378572 [ 969 ] {} <Fatal> BaseDaemon: 4. 0x562485166087 void DB::Aggregator::executeImpl<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, bool, char*) const ?\r\n2020.01.13 23:43:56.379415 [ 970 ] {} <Fatal> BaseDaemon: 5. 0x5624850ddc82 DB::Aggregator::executeOnBlock(std::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >, unsigned long, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, bool&) ?\r\n2020.01.13 23:43:56.379420 [ 969 ] {} <Fatal> BaseDaemon: 5. 0x5624850ddc82 DB::Aggregator::executeOnBlock(std::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >, unsigned long, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, bool&) ?\r\n2020.01.13 23:43:56.379442 [ 970 ] {} <Fatal> BaseDaemon: 6. 0x5624850de5e8 DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, bool&) ?\r\n2020.01.13 23:43:56.379454 [ 969 ] {} <Fatal> BaseDaemon: 6. 0x5624850de5e8 DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, bool&) ?\r\n2020.01.13 23:43:56.379457 [ 970 ] {} <Fatal> BaseDaemon: 7. 0x562485079e3f DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long) ?\r\n2020.01.13 23:43:56.379483 [ 969 ] {} <Fatal> BaseDaemon: 7. 0x562485079e3f DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long) ?\r\n2020.01.13 23:43:56.379514 [ 970 ] {} <Fatal> BaseDaemon: 8. 0x56248507a7ed ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::*)(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long), DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>*, std::shared_ptr<DB::ThreadGroupStatus>, unsigned long&>(void (DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::*&&)(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long), DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>*&&, std::shared_ptr<DB::ThreadGroupStatus>&&, unsigned long&)::{lambda()#1}::operator()() const ?\r\n2020.01.13 23:43:56.379513 [ 969 ] {} <Fatal> BaseDaemon: 8. 0x56248507a7ed ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::*)(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long), DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>*, std::shared_ptr<DB::ThreadGroupStatus>, unsigned long&>(void (DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::*&&)(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long), DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>*&&, std::shared_ptr<DB::ThreadGroupStatus>&&, unsigned long&)::{lambda()#1}::operator()() const ?\r\n2020.01.13 23:43:56.379552 [ 970 ] {} <Fatal> BaseDaemon: 9. 0x5624816cc55c ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>) ?\r\n2020.01.13 23:43:56.379554 [ 969 ] {} <Fatal> BaseDaemon: 9. 0x5624816cc55c ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>) ?\r\n2020.01.13 23:43:56.379572 [ 970 ] {} <Fatal> BaseDaemon: 10. 0x562487470780 ? ?\r\n2020.01.13 23:43:56.379572 [ 969 ] {} <Fatal> BaseDaemon: 10. 0x562487470780 ? ?\r\n2020.01.13 23:43:56.379615 [ 970 ] {} <Fatal> BaseDaemon: 11. 0x7f43d979fe25 start_thread /usr/lib64/libpthread-2.17.so\r\n2020.01.13 23:43:56.379615 [ 969 ] {} <Fatal> BaseDaemon: 11. 0x7f43d979fe25 start_thread /usr/lib64/libpthread-2.17.so\r\n2020.01.13 23:43:56.379639 [ 970 ] {} <Fatal> BaseDaemon: 12. 0x7f43d90c134d clone /usr/lib64/libc-2.17.so\r\n2020.01.13 23:43:56.379639 [ 969 ] {} <Fatal> BaseDaemon: 12. 0x7f43d90c134d clone /usr/lib64/libc-2.17.so\r\n\nrpm 19.17.4.11 (altinity) -> 20.1.2.4 (yandex) = Segmentation fault\nCentOS 7.6.1810.\r\n\r\n\u0420\u0430\u043d\u044c\u0448\u0435 \u0441\u0442\u043e\u044f\u043b\u0430 \u0432\u0435\u0440\u0441\u0438\u044f \u043a\u043b\u0438\u043a\u0445\u0430\u0443\u0441\u0430 19.17.4.11 \u0438\u0437 rpm-\u043f\u0430\u043a\u0435\u0442\u0430 \u043e\u0442 Altinity_clickhouse/x86_64.\r\n\u041f\u043e\u0441\u043b\u0435 \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u044f \u043a\u043b\u0438\u043a\u0445\u0430\u0443\u0441\u0430 \u0438\u0437 rpm-\u043f\u0430\u043a\u0435\u0442\u0430 \u043e\u0442 repo.yandex.ru_clickhouse_rpm_stable_x86_64\r\n\u0441\u0442\u0430\u043b \u043f\u0435\u0440\u0438\u043e\u0434\u0438\u0447\u0435\u0441\u043a\u0438 \u043f\u0430\u0434\u0430\u0442\u044c (\u043f\u0430\u0434\u0430\u0435\u0442 \u0432 \u043f\u043e\u043b\u043d\u043e\u0447\u044c \u0434\u0432\u0430 \u0434\u043d\u044f \u043f\u043e\u0434\u0440\u044f\u0434).\r\n\r\n```\r\n2020.01.31 00:00:06.531882 [ 118 ] {} <Fatal> BaseDaemon: ########################################\r\n2020.01.31 00:00:06.531938 [ 118 ] {} <Fatal> BaseDaemon: (version 20.1.2.4 (official build)) (from thread 51) (query_id: 3b7f94c7-7aae-4fe6-863e-5248cfe97cc3) Received signal Segmentation fault (11).\r\n2020.01.31 00:00:06.531960 [ 118 ] {} <Fatal> BaseDaemon: Address: 0x7fd3e767f000 Access: read. Attempted access has violated the permissions assigned to the memory area.\r\n2020.01.31 00:00:06.531970 [ 118 ] {} <Fatal> BaseDaemon: Stack trace: 0xbc03280 0x5695ad8 0x95c1263 0x95e8b5b 0x95e8f66 0x95e94c5 0x9651341 0x9587e60 0x4fa4657 0x4fa4c84 0x4fa3b77 0x4fa212f 0x7fd4a1aeadd5 0x7fd4a1407ead\r\n2020.01.31 00:00:06.531993 [ 118 ] {} <Fatal> BaseDaemon: 3. 0xbc03280 memcpy  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532015 [ 118 ] {} <Fatal> BaseDaemon: 4. 0x5695ad8 DB::ColumnString::insertData(char const*, unsigned long)  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532041 [ 118 ] {} <Fatal> BaseDaemon: 5. 0x95c1263 void DB::Aggregator::convertToBlockImplFinal<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >, StringHashMap<char*, Allocator<true, true> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, StringHashMap<char*, Allocator<true, true> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&) const  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532074 [ 118 ] {} <Fatal> BaseDaemon: 6. 0x95e8b5b void DB::Aggregator::convertToBlockImpl<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >, StringHashMap<char*, Allocator<true, true> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, StringHashMap<char*, Allocator<true, true> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*, std::__1::allocator<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, bool) const  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532094 [ 118 ] {} <Fatal> BaseDaemon: 7. 0x95e8f66 DB::Block DB::Aggregator::prepareBlockAndFill<DB::Block DB::Aggregator::convertOneBucketToBlock<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregatedDataVariants&, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, bool, unsigned long) const::'lambda'(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*, std::__1::allocator<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, bool)>(DB::AggregatedDataVariants&, bool, unsigned long, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&&) const  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532113 [ 118 ] {} <Fatal> BaseDaemon: 8. 0x95e94c5 DB::Block DB::Aggregator::convertOneBucketToBlock<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregatedDataVariants&, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, bool, unsigned long) const  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532126 [ 118 ] {} <Fatal> BaseDaemon: 9. 0x9651341 DB::MergingAndConvertingBlockInputStream::thread(int, std::__1::shared_ptr<DB::ThreadGroupStatus>)  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532139 [ 118 ] {} <Fatal> BaseDaemon: 10. 0x9587e60 std::__1::__function::__func<std::__1::__bind<void (DB::MergingAndConvertingBlockInputStream::*)(int, std::__1::shared_ptr<DB::ThreadGroupStatus>), DB::MergingAndConvertingBlockInputStream*, int&, std::__1::shared_ptr<DB::ThreadGroupStatus> >, std::__1::allocator<std::__1::__bind<void (DB::MergingAndConvertingBlockInputStream::*)(int, std::__1::shared_ptr<DB::ThreadGroupStatus>), DB::MergingAndConvertingBlockInputStream*, int&, std::__1::shared_ptr<DB::ThreadGroupStatus> > >, void ()>::operator()()  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532151 [ 118 ] {} <Fatal> BaseDaemon: 11. 0x4fa4657 ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>)  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532163 [ 118 ] {} <Fatal> BaseDaemon: 12. 0x4fa4c84 ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532173 [ 118 ] {} <Fatal> BaseDaemon: 13. 0x4fa3b77 ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>)  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532194 [ 118 ] {} <Fatal> BaseDaemon: 14. 0x4fa212f ?  in /usr/bin/clickhouse\r\n2020.01.31 00:00:06.532207 [ 118 ] {} <Fatal> BaseDaemon: 15. 0x7dd5 start_thread  in /usr/lib64/libpthread-2.17.so\r\n2020.01.31 00:00:06.532218 [ 118 ] {} <Fatal> BaseDaemon: 16. 0xfdead clone  in /usr/lib64/libc-2.17.so\r\n\r\n```\r\n\r\n\u041d\u0430 \u0432\u0442\u043e\u0440\u043e\u043c \u0441\u0435\u0440\u0432\u0435\u0440\u0435 (CentOS 7.3.1611) \u0431\u044b\u043b \u0442\u0430\u043a\u0436\u0435 \u043e\u0431\u043d\u043e\u0432\u043b\u0451\u043d \u043a\u043b\u0438\u043a\u0445\u0430\u0443\u0441 c altinity \u043d\u0430 yandex , \u043d\u043e \u043f\u043e\u0434\u043e\u0431\u043d\u043e\u0439 \u043e\u0448\u0438\u0431\u043a\u0438 \u043d\u0435 \u0432\u043e\u0437\u043d\u0438\u043a\u0430\u0435\u0442, \u043f\u0440\u0430\u0432\u0434\u0430 \u0442\u0430\u043c \u0434\u0440\u0443\u0433\u0438\u0435 \u0431\u0434 \u0438 \u0437\u0430\u043f\u0440\u043e\u0441\u044b.\r\n\n",
  "hints_text": "What query do you execute? What is the structure of your tables and configuration of the cluster?\n>2020.01.13 23:43:56.376109 [ 969 ] {} BaseDaemon: \r\n>2020.01.13 23:43:56.376119 [ 970 ] {} BaseDaemon: \r\n\r\nIt's kinda unusual. Two CH servers process?\n@den-crane It's Ok, we output messages from different segfaults in different threads (in recent versions).\n> What query do you execute? What is the structure of your tables and configuration of the cluster?\r\n\r\nwe replayed all the query, no crash happened\n> > What query do you execute? What is the structure of your tables and configuration of the cluster?\r\n> \r\n> we replayed all the query, no crash happened\r\n\r\nIf you're satisfied with the result 'it crashes only sometimes', you can close the issue. \r\n\r\nIf you want to be sure that it is fixed and the problem will not return someday you need to provide more data about circumstances (as requested above). You can obfuscate columns / table names if you prefer to keep details of your schema / usecase in secret. \r\n\r\nMost probably relates to https://github.com/ClickHouse/ClickHouse/pull/6243 and https://github.com/ClickHouse/ClickHouse/commit/a864447802ec451bed6f68af8af66031d48c9ab5#diff-e3a5337aad7de5c6d724c8baff82d0a0 \r\n\r\n/cc  @amosbird @akuzm\n> If you're satisfied with the result 'it crashes only sometimes', you can close the issue.\r\n\r\nI'm not.\n> > If you're satisfied with the result 'it crashes only sometimes', you can close the issue.\r\n> \r\n> I'm not.\r\n\r\nMe neither :) May be @amosbird or @akuzm will be able to deduct what was that looking on the code only, since @kwai-code don't want to help us. \nwe meet the same problem\r\n\r\n> 2020.02.27 23:04:36.749619 [ 1338 ] {} <Fatal> BaseDaemon: \r\n2020.02.27 23:04:36.749734 [ 1338 ] {} <Fatal> BaseDaemon: (version 19.17.6.36 (official build)) (from thread 491) Received signal Segmentation fault (11).\r\n2020.02.27 23:04:36.749846 [ 1338 ] {} <Fatal> BaseDaemon: Address: 0x10 Access: read. Address not mapped to object.\r\n2020.02.27 23:04:36.749963 [ 1338 ] {} <Fatal> BaseDaemon: Stack trace: 0x561af548bc7c 0x561af54fe087 0x561af5475c82 0x561af54765e8 0x561af5411e3f 0x561af54127ed 0x561af1a6455c 0x561af7808780 0x7f788eadde25 0x7f788e3ff34d\r\n2020.02.27 23:04:36.750183 [ 1338 ] {} <Fatal> BaseDaemon: 3. 0x561af548bc7c void DB::Aggregator::executeImplCase<true, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >::State&, DB::Arena*, unsigned long, DB::Aggregator::AggregateFunctionInstruction*, char*) const ?\r\n2020.02.27 23:04:36.750368 [ 1338 ] {} <Fatal> BaseDaemon: 4. 0x561af54fe087 void DB::Aggregator::executeImpl<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, bool, char*) const ?\r\n2020.02.27 23:04:36.750599 [ 1338 ] {} <Fatal> BaseDaemon: 5. 0x561af5475c82 DB::Aggregator::executeOnBlock(std::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >, unsigned long, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, bool&) ?\r\n2020.02.27 23:04:36.750772 [ 1338 ] {} <Fatal> BaseDaemon: 6. 0x561af54765e8 DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, bool&) ?\r\n2020.02.27 23:04:36.750973 [ 1338 ] {} <Fatal> BaseDaemon: 7. 0x561af5411e3f DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long) ?\r\n2020.02.27 23:04:36.751434 [ 1338 ] {} <Fatal> BaseDaemon: 8. 0x561af54127ed ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::*)(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long), DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>*, std::shared_ptr<DB::ThreadGroupStatus>, unsigned long&>(void (DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::*&&)(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long), DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>*&&, std::shared_ptr<DB::ThreadGroupStatus>&&, unsigned long&)::{lambda()#1}::operator()() const ?\r\n2020.02.27 23:04:36.751560 [ 1338 ] {} <Fatal> BaseDaemon: 9. 0x561af1a6455c ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>) ?\r\n2020.02.27 23:04:36.751581 [ 1338 ] {} <Fatal> BaseDaemon: 10. 0x561af7808780 ? ?\r\n2020.02.27 23:04:36.751749 [ 1338 ] {} <Fatal> BaseDaemon: 11. 0x7f788eadde25 start_thread /usr/lib64/libpthread-2.17.so\r\n2020.02.27 23:04:36.751776 [ 1338 ] {} <Fatal> BaseDaemon: 12. 0x7f788e3ff34d clone /usr/lib64/libc-2.17.so\r\n\r\n\r\n\r\nwe have a cluster with 99 server, 33 shards each shard have 3 server. \r\ncluster conf\r\n>\r\n           <shard>\r\n              <weight>2</weight>\r\n              <internal_replication>true</internal_replication>\r\n              <replica>\r\n                  <host>host1</host>\r\n                  <port>9000</port>\r\n                  <user>repl</user>\r\n                  <password>xxx</password>\r\n              </replica>\r\n              <replica>\r\n                  <host>host2</host>\r\n                  <port>9000</port>\r\n                  <user>repl</user>\r\n                  <password>xxx</password>\r\n              </replica>\r\n              <replica>\r\n                  <host>host3</host>\r\n                  <port>9000</port>\r\n                  <user>repl</user>\r\n                  <password>xxx</password>\r\n              </replica>\r\n          </shard>\r\n\r\n during the crash, the server's cpu is very high and with very high network in/out io\r\n\r\ndon't  really know which sql cause the crash, we replayed all the query no crash happen\r\n\nThere should be a query string in the trace log before the crash. \nCan you check / share the query which caused that? Most probably you will be able to find it grepping logs for `3b7f94c7-7aae-4fe6-863e-5248cfe97cc3` (query_id from stacktrace). \n\u0417\u0430\u043f\u0440\u043e\u0441\u0430 \u0432 \u043b\u043e\u0433\u0430\u0445 \u043d\u0435\u0442 \u043f\u043e\u0442\u043e\u043c\u0443 \u0447\u0442\u043e \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u043b\u043e\u0433\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0431\u044b\u043b warning, \u043f\u043e\u043c\u0435\u043d\u044f\u043b \u043d\u0430 trace.\r\n\u0418 \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u043b systemctl enable clickhouse-server.\r\n\r\n\u041f\u043e\u043b\u0443\u0447\u0438\u043b \u043d\u043e\u0432\u0443\u044e \u043e\u0448\u0438\u0431\u043a\u0443 \u0432 \u0442\u043e \u0436\u0435 \u0441\u0430\u043c\u043e\u043c\u0435 \u0432\u0435\u0440\u043c\u044f \u043a\u0430\u043a \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0438\u0435, \u0442\u043e\u043b\u044c\u043a\u043e \u0440\u0430\u043d\u044c\u0448\u0435 \u043a\u043b\u0438\u043a\u0445\u0430\u0443\u0441 \u043f\u0440\u043e\u0441\u0442\u043e \u043f\u0430\u0434\u0430\u043b, \u0430 \u0441\u0435\u0439\u0447\u0430\u0441 \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u0442 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440 \u043d\u0430 100% \u0438 \u043f\u0440\u0438 \u044d\u0442\u043e\u043c \u043d\u0435\u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d\r\n```\r\n2020.02.01 00:00:05.218606 [ 63 ] {9e24c969-e99c-44ef-911c-078f691fcb0c} <Error> executeQuery: Code: 173, e.displayText() = DB::ErrnoException: Allocator: Cannot realloc from 1.00 MiB to 0.00 B., errno: 0, strerror: Success (version 20.1.2.4 (official build)) (from 127.0.0.1:55718) (in query: -- Metabase SELECT `nginx`.`report_by_query`.`query` AS `query` FROM `nginx`.`report_by_query` GROUP BY `nginx`.`report_by_query`.`query` ORDER BY `nginx`.`report_by_query`.`query` ASC LIMIT 5000 FORMAT TabSeparatedWithNamesAndTypes;), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. 0xbc31d9c Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int)  in /usr/bin/clickhouse\r\n1. 0x4f6ee17 DB::ErrnoException::ErrnoException(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, std::__1::optional<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > const&)  in /usr/bin/clickhouse\r\n2. 0x4968044 DB::throwFromErrno(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int)  in /usr/bin/clickhouse\r\n3. 0x4f919ac Allocator<false, false>::realloc(void*, unsigned long, unsigned long, unsigned long)  in /usr/bin/clickhouse\r\n4. 0x5695aa4 DB::ColumnString::insertData(char const*, unsigned long)  in /usr/bin/clickhouse\r\n5. 0x95c1263 void DB::Aggregator::convertToBlockImplFinal<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >, StringHashMap<char*, Allocator<true, true> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, StringHashMap<char*, Allocator<true, true> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&) const  in /usr/bin/clickhouse\r\n6. 0x95e8b5b void DB::Aggregator::convertToBlockImpl<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >, StringHashMap<char*, Allocator<true, true> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, StringHashMap<char*, Allocator<true, true> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*, std::__1::allocator<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, bool) const  in /usr/bin/clickhouse\r\n7. 0x95e8f66 DB::Block DB::Aggregator::prepareBlockAndFill<DB::Block DB::Aggregator::convertOneBucketToBlock<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregatedDataVariants&, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, bool, unsigned long) const::'lambda'(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*, std::__1::allocator<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, bool)>(DB::AggregatedDataVariants&, bool, unsigned long, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&&) const  in /usr/bin/clickhouse\r\n8. 0x95e94c5 DB::Block DB::Aggregator::convertOneBucketToBlock<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregatedDataVariants&, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, bool, unsigned long) const  in /usr/bin/clickhouse\r\n9. 0x9651341 DB::MergingAndConvertingBlockInputStream::thread(int, std::__1::shared_ptr<DB::ThreadGroupStatus>)  in /usr/bin/clickhouse\r\n10. 0x9587e60 std::__1::__function::__func<std::__1::__bind<void (DB::MergingAndConvertingBlockInputStream::*)(int, std::__1::shared_ptr<DB::ThreadGroupStatus>), DB::MergingAndConvertingBlockInputStream*, int&, std::__1::shared_ptr<DB::ThreadGroupStatus> >, std::__1::allocator<std::__1::__bind<void (DB::MergingAndConvertingBlockInputStream::*)(int, std::__1::shared_ptr<DB::ThreadGroupStatus>), DB::MergingAndConvertingBlockInputStream*, int&, std::__1::shared_ptr<DB::ThreadGroupStatus> > >, void ()>::operator()()  in /usr/bin/clickhouse\r\n11. 0x4fa4657 ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>)  in /usr/bin/clickhouse\r\n12. 0x4fa4c84 ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const  in /usr/bin/clickhouse\r\n13. 0x4fa3b77 ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>)  in /usr/bin/clickhouse\r\n14. 0x4fa212f ?  in /usr/bin/clickhouse\r\n15. 0x7dd5 start_thread  in /usr/lib64/libpthread-2.17.so\r\n16. 0xfdead clone  in /usr/lib64/libc-2.17.so\r\n```\r\nsql \u0437\u0430\u043f\u0440\u043e\u0441, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0435\u0451 \u0432\u044b\u0437\u044b\u0432\u0430\u0435\u0442:\r\n> SELECT `nginx`.`report_by_query`.`query` AS `query` FROM `nginx`.`report_by_query` GROUP BY `nginx`.`report_by_query`.`query` ORDER BY `nginx`.`report_by_query`.`query` ASC LIMIT 5000 FORMAT TabSeparatedWithNamesAndTypes;\r\n\r\n\u0412\u0438\u0434\u0438\u043c\u043e [metabase](https://github.com/metabase/metabase) \u0440\u0430\u0437 \u0432 \u0441\u0443\u0442\u043a\u0438 \u043f\u0435\u0440\u0435\u0441\u0442\u0440\u0430\u0438\u0432\u0430\u0435\u0442 \u0441\u0432\u043e\u0438 \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0438\u0435 \u0438\u043d\u0434\u0435\u043a\u0441\u044b \u0438 \u0434\u0435\u043b\u0430\u0435\u0442 \u044d\u0442\u043e\u0442 \u0437\u0430\u043f\u0440\u043e\u0441.\r\n\u0412 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 65\u043a\u043a \u0437\u0430\u043f\u0438\u0441\u0435\u0439 \u0438 \u0432\u0435\u0441\u0438\u0442 \u043e\u043d\u0430 \u043e\u043a\u043e\u043b\u043e 1gb.\r\n\n\u0410 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0430 \u0442\u0430\u0431\u043b\u0438\u0446\u044b? `Show create table nginx.report_by_query`\n```\r\nCREATE TABLE nginx.report_by_query \r\n(`timestamp` DateTime, `country` String, `os` String, `query` String, `n` UInt64) \r\nENGINE = SummingMergeTree \r\nPARTITION BY toYYYYMM(timestamp) \r\nORDER BY (timestamp, country, query) \r\nSETTINGS index_granularity = 8192\r\n```\n\u0412\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430 \u0431\u044b\u043b\u0430 \u0432 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0435 \u0442\u0430\u0431\u043b\u0438\u0446\u044b, \u043e\u043d\u0430 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0442\u0435\u043a\u0441\u0442\u043e\u0432\u043e\u0435 \u043f\u043e\u043b\u0435 query, \u043d\u043e \u043d\u0435 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0435\u0433\u043e \u0432 \"ORDER BY\". \u0412\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0434\u043b\u044f \u0434\u0432\u0438\u0436\u043a\u0430 SummingMergeTree \u0432 \u043d\u043e\u0432\u044b\u0445 \u0432\u0435\u0440\u0441\u0438\u044f\u0445 \u043a\u043b\u0438\u043a\u0445\u0430\u0443\u0441\u0430 \u044d\u0442\u043e \u0432\u044b\u0437\u044b\u0432\u0430\u0435\u0442 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443.\r\n\u0418\u0441\u043f\u0440\u0430\u0432\u0438\u043b \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0443 \u0442\u0430\u0431\u043b\u0438\u0446\u044b, \u043f\u043e\u043a\u0430 \u0447\u0442\u043e \u043e\u0448\u0438\u0431\u043a\u0430 \u043d\u0435 \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0441\u044f.",
  "created_at": "2020-04-02T17:23:38Z"
}