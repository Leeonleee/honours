{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 42040,
  "instance_id": "ClickHouse__ClickHouse-42040",
  "issue_numbers": [
    "41698"
  ],
  "base_commit": "c8c96ecca3b1c59043715a1de87e2c74f5046961",
  "patch": "diff --git a/programs/server/config.xml b/programs/server/config.xml\nindex dcb8ac0804c9..7f3a749b629e 100644\n--- a/programs/server/config.xml\n+++ b/programs/server/config.xml\n@@ -1173,6 +1173,18 @@\n         <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n     </processors_profile_log>\n \n+    <!-- Log of asynchronous inserts. It allows to check status\n+         of insert query in fire-and-forget mode.\n+    -->\n+    <asynchronous_insert_log>\n+        <database>system</database>\n+        <table>asynchronous_insert_log</table>\n+\n+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n+        <partition_by>event_date</partition_by>\n+        <ttl>event_date + INTERVAL 3 DAY</ttl>\n+    </asynchronous_insert_log>\n+\n     <!-- <top_level_domains_path>/var/lib/clickhouse/top_level_domains/</top_level_domains_path> -->\n     <!-- Custom TLD lists.\n          Format: <name>/path/to/file</name>\ndiff --git a/src/Common/DateLUT.h b/src/Common/DateLUT.h\nindex edf09250e6ac..b7ba37c2becc 100644\n--- a/src/Common/DateLUT.h\n+++ b/src/Common/DateLUT.h\n@@ -55,3 +55,23 @@ class DateLUT : private boost::noncopyable\n \n     std::atomic<const DateLUTImpl *> default_impl;\n };\n+\n+inline UInt64 timeInMilliseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n+{\n+    return std::chrono::duration_cast<std::chrono::milliseconds>(timepoint.time_since_epoch()).count();\n+}\n+\n+inline UInt64 timeInMicroseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n+{\n+    return std::chrono::duration_cast<std::chrono::microseconds>(timepoint.time_since_epoch()).count();\n+}\n+\n+inline UInt64 timeInSeconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n+{\n+    return std::chrono::duration_cast<std::chrono::seconds>(timepoint.time_since_epoch()).count();\n+}\n+\n+inline UInt64 timeInNanoseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n+{\n+    return std::chrono::duration_cast<std::chrono::nanoseconds>(timepoint.time_since_epoch()).count();\n+}\ndiff --git a/src/Common/SystemLogBase.cpp b/src/Common/SystemLogBase.cpp\nindex 791f976d5e0d..3e570ac482aa 100644\n--- a/src/Common/SystemLogBase.cpp\n+++ b/src/Common/SystemLogBase.cpp\n@@ -13,6 +13,7 @@\n #include <Interpreters/ProcessorsProfileLog.h>\n #include <Interpreters/ZooKeeperLog.h>\n #include <Interpreters/TransactionsInfoLog.h>\n+#include <Interpreters/AsynchronousInsertLog.h>\n \n #include <Common/MemoryTrackerBlockerInThread.h>\n #include <Common/SystemLogBase.h>\ndiff --git a/src/Common/SystemLogBase.h b/src/Common/SystemLogBase.h\nindex 2f9d58770e6b..8813e5180b06 100644\n--- a/src/Common/SystemLogBase.h\n+++ b/src/Common/SystemLogBase.h\n@@ -27,7 +27,8 @@\n     M(ZooKeeperLogElement) \\\n     M(ProcessorProfileLogElement) \\\n     M(TextLogElement) \\\n-    M(FilesystemCacheLogElement)\n+    M(FilesystemCacheLogElement) \\\n+    M(AsynchronousInsertLogElement)\n \n namespace Poco\n {\ndiff --git a/src/Interpreters/AsynchronousInsertLog.cpp b/src/Interpreters/AsynchronousInsertLog.cpp\nnew file mode 100644\nindex 000000000000..916ec8f3d567\n--- /dev/null\n+++ b/src/Interpreters/AsynchronousInsertLog.cpp\n@@ -0,0 +1,82 @@\n+#include <Interpreters/AsynchronousInsertLog.h>\n+\n+#include <DataTypes/DataTypeDate.h>\n+#include <DataTypes/DataTypeDateTime.h>\n+#include <DataTypes/DataTypeDateTime64.h>\n+#include <DataTypes/DataTypeLowCardinality.h>\n+#include <DataTypes/DataTypeString.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeEnum.h>\n+#include <Parsers/ASTInsertQuery.h>\n+#include <Parsers/queryToString.h>\n+\n+\n+namespace DB\n+{\n+\n+NamesAndTypesList AsynchronousInsertLogElement::getNamesAndTypes()\n+{\n+    auto type_status = std::make_shared<DataTypeEnum8>(\n+        DataTypeEnum8::Values\n+        {\n+            {\"Ok\",           static_cast<Int8>(Status::Ok)},\n+            {\"ParsingError\", static_cast<Int8>(Status::ParsingError)},\n+            {\"FlushError\",   static_cast<Int8>(Status::FlushError)},\n+        });\n+\n+    return\n+    {\n+        {\"event_date\", std::make_shared<DataTypeDate>()},\n+        {\"event_time\", std::make_shared<DataTypeDateTime>()},\n+        {\"event_time_microseconds\", std::make_shared<DataTypeDateTime64>(6)},\n+\n+        {\"query\", std::make_shared<DataTypeString>()},\n+        {\"database\", std::make_shared<DataTypeLowCardinality>(std::make_shared<DataTypeString>())},\n+        {\"table\", std::make_shared<DataTypeLowCardinality>(std::make_shared<DataTypeString>())},\n+        {\"format\", std::make_shared<DataTypeLowCardinality>(std::make_shared<DataTypeString>())},\n+        {\"query_id\", std::make_shared<DataTypeString>()},\n+        {\"bytes\", std::make_shared<DataTypeUInt64>()},\n+        {\"exception\", std::make_shared<DataTypeString>()},\n+        {\"status\", type_status},\n+\n+        {\"flush_time\", std::make_shared<DataTypeDateTime>()},\n+        {\"flush_time_microseconds\", std::make_shared<DataTypeDateTime64>(6)},\n+        {\"flush_query_id\", std::make_shared<DataTypeString>()},\n+    };\n+}\n+\n+void AsynchronousInsertLogElement::appendToBlock(MutableColumns & columns) const\n+{\n+    size_t i = 0;\n+\n+    auto event_date = DateLUT::instance().toDayNum(event_time).toUnderType();\n+    columns[i++]->insert(event_date);\n+    columns[i++]->insert(event_time);\n+    columns[i++]->insert(event_time_microseconds);\n+\n+    const auto & insert_query = assert_cast<const ASTInsertQuery &>(*query);\n+    columns[i++]->insert(queryToString(insert_query));\n+\n+    if (insert_query.table_id)\n+    {\n+        columns[i++]->insert(insert_query.table_id.getDatabaseName());\n+        columns[i++]->insert(insert_query.table_id.getTableName());\n+    }\n+    else\n+    {\n+        columns[i++]->insertDefault();\n+        columns[i++]->insertDefault();\n+    }\n+\n+    columns[i++]->insert(insert_query.format);\n+    columns[i++]->insert(query_id);\n+    columns[i++]->insert(bytes);\n+    columns[i++]->insert(exception);\n+    columns[i++]->insert(status);\n+\n+    columns[i++]->insert(flush_time);\n+    columns[i++]->insert(flush_time_microseconds);\n+    columns[i++]->insert(flush_query_id);\n+}\n+\n+}\ndiff --git a/src/Interpreters/AsynchronousInsertLog.h b/src/Interpreters/AsynchronousInsertLog.h\nnew file mode 100644\nindex 000000000000..e2fdd4c90a05\n--- /dev/null\n+++ b/src/Interpreters/AsynchronousInsertLog.h\n@@ -0,0 +1,50 @@\n+#pragma once\n+\n+#include \"Common/Exception.h\"\n+#include <Interpreters/SystemLog.h>\n+#include <Core/NamesAndTypes.h>\n+#include <Core/NamesAndAliases.h>\n+#include <Parsers/IAST_fwd.h>\n+\n+namespace DB\n+{\n+\n+struct AsynchronousInsertLogElement\n+{\n+    enum Status : Int8\n+    {\n+        Ok = 0,\n+        ParsingError = 1,\n+        FlushError = 2,\n+    };\n+\n+    time_t event_time{};\n+    Decimal64 event_time_microseconds{};\n+\n+    ASTPtr query;\n+    String query_id;\n+    UInt64 bytes{};\n+    String exception;\n+    Status status{};\n+\n+    time_t flush_time{};\n+    Decimal64 flush_time_microseconds{};\n+    String flush_query_id;\n+\n+    static std::string name() { return \"AsynchronousInsertLog\"; }\n+    static NamesAndTypesList getNamesAndTypes();\n+    static NamesAndAliases getNamesAndAliases() { return {}; }\n+    void appendToBlock(MutableColumns & columns) const;\n+    static const char * getCustomColumnList() { return nullptr; }\n+};\n+\n+class AsynchronousInsertLog : public SystemLog<AsynchronousInsertLogElement>\n+{\n+public:\n+    using SystemLog<AsynchronousInsertLogElement>::SystemLog;\n+\n+    /// This table is usually queried for fixed table name.\n+    static const char * getDefaultOrderBy() { return \"(database, table, event_date, event_time)\"; }\n+};\n+\n+}\ndiff --git a/src/Interpreters/AsynchronousInsertQueue.cpp b/src/Interpreters/AsynchronousInsertQueue.cpp\nindex 7f03bc25b62b..3aadea918fba 100644\n--- a/src/Interpreters/AsynchronousInsertQueue.cpp\n+++ b/src/Interpreters/AsynchronousInsertQueue.cpp\n@@ -4,6 +4,7 @@\n #include <QueryPipeline/BlockIO.h>\n #include <Interpreters/InterpreterInsertQuery.h>\n #include <Interpreters/Context.h>\n+#include <Interpreters/AsynchronousInsertLog.h>\n #include <Processors/Transforms/getSourceFromASTInsertQuery.h>\n #include <Processors/Sources/SourceFromSingleChunk.h>\n #include <Processors/Executors/StreamingFormatExecutor.h>\n@@ -18,6 +19,7 @@\n #include <Storages/IStorage.h>\n #include <Common/SipHash.h>\n #include <Common/FieldVisitorHash.h>\n+#include <Common/DateLUT.h>\n #include <Access/Common/AccessFlags.h>\n #include <Access/EnabledQuota.h>\n #include <Formats/FormatFactory.h>\n@@ -89,7 +91,9 @@ bool AsynchronousInsertQueue::InsertQuery::operator==(const InsertQuery & other)\n }\n \n AsynchronousInsertQueue::InsertData::Entry::Entry(String && bytes_, String && query_id_)\n-    : bytes(std::move(bytes_)), query_id(std::move(query_id_))\n+    : bytes(std::move(bytes_))\n+    , query_id(std::move(query_id_))\n+    , create_time(std::chrono::system_clock::now())\n {\n }\n \n@@ -395,6 +399,31 @@ void AsynchronousInsertQueue::cleanup()\n }\n \n \n+static void appendElementsToLogSafe(\n+    AsynchronousInsertLog & log,\n+    std::vector<AsynchronousInsertLogElement> elements,\n+    std::chrono::time_point<std::chrono::system_clock> flush_time,\n+    const String & flush_query_id,\n+    const String & flush_exception)\n+try\n+{\n+    using Status = AsynchronousInsertLogElement::Status;\n+\n+    for (auto & elem : elements)\n+    {\n+        elem.flush_time = timeInSeconds(flush_time);\n+        elem.flush_time_microseconds = timeInMicroseconds(flush_time);\n+        elem.flush_query_id = flush_query_id;\n+        elem.exception = flush_exception;\n+        elem.status = flush_exception.empty() ? Status::Ok : Status::FlushError;\n+        log.add(elem);\n+    }\n+}\n+catch (...)\n+{\n+    tryLogCurrentException(\"AsynchronousInsertQueue\", \"Failed to add elements to AsynchronousInsertLog\");\n+}\n+\n // static\n void AsynchronousInsertQueue::processData(InsertQuery key, InsertDataPtr data, ContextPtr global_context)\n try\n@@ -402,6 +431,8 @@ try\n     if (!data)\n         return;\n \n+    SCOPE_EXIT(CurrentMetrics::sub(CurrentMetrics::PendingAsyncInsert, data->entries.size()));\n+\n     const auto * log = &Poco::Logger::get(\"AsynchronousInsertQueue\");\n     const auto & insert_query = assert_cast<const ASTInsertQuery &>(*key.query);\n     auto insert_context = Context::createCopy(global_context);\n@@ -424,11 +455,13 @@ try\n \n     size_t total_rows = 0;\n     InsertData::EntryPtr current_entry;\n+    String current_exception;\n \n     auto on_error = [&](const MutableColumns & result_columns, Exception & e)\n     {\n+        current_exception = e.displayText();\n         LOG_ERROR(log, \"Failed parsing for query '{}' with query id {}. {}\",\n-            queryToString(key.query), current_entry->query_id, e.displayText());\n+            queryToString(key.query), current_entry->query_id, current_exception);\n \n         for (const auto & column : result_columns)\n             if (column->size() > total_rows)\n@@ -448,6 +481,12 @@ try\n             adding_defaults_transform = std::make_shared<AddingDefaultsTransform>(header, columns, *format, insert_context);\n     }\n \n+    auto insert_log = global_context->getAsynchronousInsertLog();\n+    std::vector<AsynchronousInsertLogElement> log_elements;\n+\n+    if (insert_log)\n+        log_elements.reserve(data->entries.size());\n+\n     StreamingFormatExecutor executor(header, format, std::move(on_error), std::move(adding_defaults_transform));\n     std::unique_ptr<ReadBuffer> last_buffer;\n     for (const auto & entry : data->entries)\n@@ -459,11 +498,40 @@ try\n         /// Keep buffer, because it still can be used\n         /// in destructor, while resetting buffer at next iteration.\n         last_buffer = std::move(buffer);\n+\n+        if (insert_log)\n+        {\n+            AsynchronousInsertLogElement elem;\n+            elem.event_time = timeInSeconds(entry->create_time);\n+            elem.event_time_microseconds = timeInMicroseconds(entry->create_time);\n+            elem.query = key.query;\n+            elem.query_id = entry->query_id;\n+            elem.bytes = entry->bytes.size();\n+            elem.exception = current_exception;\n+            current_exception.clear();\n+\n+            /// If there was a parsing error,\n+            /// the entry won't be flushed anyway,\n+            /// so add the log element immediately.\n+            if (!elem.exception.empty())\n+            {\n+                elem.status = AsynchronousInsertLogElement::ParsingError;\n+                insert_log->add(elem);\n+            }\n+            else\n+            {\n+                log_elements.push_back(elem);\n+            }\n+        }\n     }\n \n     format->addBuffer(std::move(last_buffer));\n+    auto insert_query_id = insert_context->getCurrentQueryId();\n \n-    if (total_rows)\n+    if (total_rows == 0)\n+        return;\n+\n+    try\n     {\n         auto chunk = Chunk(executor.getResultColumns(), total_rows);\n         size_t total_bytes = chunk.bytes();\n@@ -477,12 +545,28 @@ try\n         LOG_INFO(log, \"Flushed {} rows, {} bytes for query '{}'\",\n             total_rows, total_bytes, queryToString(key.query));\n     }\n+    catch (...)\n+    {\n+        if (!log_elements.empty())\n+        {\n+            auto exception = getCurrentExceptionMessage(false);\n+            auto flush_time = std::chrono::system_clock::now();\n+            appendElementsToLogSafe(*insert_log, std::move(log_elements), flush_time, insert_query_id, exception);\n+        }\n+        throw;\n+    }\n \n     for (const auto & entry : data->entries)\n+    {\n         if (!entry->isFinished())\n             entry->finish();\n+    }\n \n-    CurrentMetrics::sub(CurrentMetrics::PendingAsyncInsert, data->entries.size());\n+    if (!log_elements.empty())\n+    {\n+        auto flush_time = std::chrono::system_clock::now();\n+        appendElementsToLogSafe(*insert_log, std::move(log_elements), flush_time, insert_query_id, \"\");\n+    }\n }\n catch (const Exception & e)\n {\n@@ -516,8 +600,6 @@ void AsynchronousInsertQueue::finishWithException(\n             entry->finish(std::make_exception_ptr(exception));\n         }\n     }\n-\n-    CurrentMetrics::sub(CurrentMetrics::PendingAsyncInsert, entries.size());\n }\n \n }\ndiff --git a/src/Interpreters/AsynchronousInsertQueue.h b/src/Interpreters/AsynchronousInsertQueue.h\nindex 93483301ee6a..fcf4e3d98d23 100644\n--- a/src/Interpreters/AsynchronousInsertQueue.h\n+++ b/src/Interpreters/AsynchronousInsertQueue.h\n@@ -47,6 +47,7 @@ class AsynchronousInsertQueue : public WithContext\n         public:\n             const String bytes;\n             const String query_id;\n+            std::chrono::time_point<std::chrono::system_clock> create_time;\n \n             Entry(String && bytes_, String && query_id_);\n \ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex 9604d1796e99..3c406058cb50 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -2665,6 +2665,16 @@ std::shared_ptr<FilesystemCacheLog> Context::getFilesystemCacheLog() const\n     return shared->system_logs->cache_log;\n }\n \n+std::shared_ptr<AsynchronousInsertLog> Context::getAsynchronousInsertLog() const\n+{\n+    auto lock = getLock();\n+\n+    if (!shared->system_logs)\n+        return {};\n+\n+    return shared->system_logs->asynchronous_insert_log;\n+}\n+\n CompressionCodecPtr Context::chooseCompressionCodec(size_t part_size, double part_size_ratio) const\n {\n     auto lock = getLock();\ndiff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h\nindex 635c571b173f..d9a59cb08ae7 100644\n--- a/src/Interpreters/Context.h\n+++ b/src/Interpreters/Context.h\n@@ -86,6 +86,7 @@ class BackupsWorker;\n class TransactionsInfoLog;\n class ProcessorsProfileLog;\n class FilesystemCacheLog;\n+class AsynchronousInsertLog;\n struct MergeTreeSettings;\n class StorageS3Settings;\n class IDatabase;\n@@ -891,8 +892,8 @@ class Context: public std::enable_shared_from_this<Context>\n     std::shared_ptr<SessionLog> getSessionLog() const;\n     std::shared_ptr<TransactionsInfoLog> getTransactionsInfoLog() const;\n     std::shared_ptr<ProcessorsProfileLog> getProcessorsProfileLog() const;\n-\n     std::shared_ptr<FilesystemCacheLog> getFilesystemCacheLog() const;\n+    std::shared_ptr<AsynchronousInsertLog> getAsynchronousInsertLog() const;\n \n     /// Returns an object used to log operations with parts if it possible.\n     /// Provide table name to make required checks.\ndiff --git a/src/Interpreters/InterpreterSystemQuery.cpp b/src/Interpreters/InterpreterSystemQuery.cpp\nindex 56e87d6a4fb9..27d6de6a8df6 100644\n--- a/src/Interpreters/InterpreterSystemQuery.cpp\n+++ b/src/Interpreters/InterpreterSystemQuery.cpp\n@@ -33,6 +33,7 @@\n #include <Interpreters/FilesystemCacheLog.h>\n #include <Interpreters/TransactionsInfoLog.h>\n #include <Interpreters/ProcessorsProfileLog.h>\n+#include <Interpreters/AsynchronousInsertLog.h>\n #include <Interpreters/JIT/CompiledExpressionCache.h>\n #include <Interpreters/TransactionLog.h>\n #include <BridgeHelper/CatBoostLibraryBridgeHelper.h>\n@@ -523,7 +524,8 @@ BlockIO InterpreterSystemQuery::execute()\n                 [&] { if (auto session_log = getContext()->getSessionLog()) session_log->flush(true); },\n                 [&] { if (auto transactions_info_log = getContext()->getTransactionsInfoLog()) transactions_info_log->flush(true); },\n                 [&] { if (auto processors_profile_log = getContext()->getProcessorsProfileLog()) processors_profile_log->flush(true); },\n-                [&] { if (auto cache_log = getContext()->getFilesystemCacheLog()) cache_log->flush(true); }\n+                [&] { if (auto cache_log = getContext()->getFilesystemCacheLog()) cache_log->flush(true); },\n+                [&] { if (auto asynchronous_insert_log = getContext()->getAsynchronousInsertLog()) asynchronous_insert_log->flush(true); }\n             );\n             break;\n         }\ndiff --git a/src/Interpreters/MetricLog.cpp b/src/Interpreters/MetricLog.cpp\nindex 8b28717ff07c..6e98f84bc82f 100644\n--- a/src/Interpreters/MetricLog.cpp\n+++ b/src/Interpreters/MetricLog.cpp\n@@ -78,22 +78,6 @@ void MetricLog::shutdown()\n }\n \n \n-static inline UInt64 time_in_milliseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::milliseconds>(timepoint.time_since_epoch()).count();\n-}\n-\n-static inline UInt64 time_in_microseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::microseconds>(timepoint.time_since_epoch()).count();\n-}\n-\n-static inline UInt64 time_in_seconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::seconds>(timepoint.time_since_epoch()).count();\n-}\n-\n-\n void MetricLog::metricThreadFunction()\n {\n     auto desired_timepoint = std::chrono::system_clock::now();\n@@ -109,8 +93,8 @@ void MetricLog::metricThreadFunction()\n \n             MetricLogElement elem;\n             elem.event_time = std::chrono::system_clock::to_time_t(current_time);\n-            elem.event_time_microseconds = time_in_microseconds(current_time);\n-            elem.milliseconds = time_in_milliseconds(current_time) - time_in_seconds(current_time) * 1000;\n+            elem.event_time_microseconds = timeInMicroseconds(current_time);\n+            elem.milliseconds = timeInMilliseconds(current_time) - timeInSeconds(current_time) * 1000;\n \n             elem.profile_events.resize(ProfileEvents::end());\n             for (size_t i = 0, end = ProfileEvents::end(); i < end; ++i)\ndiff --git a/src/Interpreters/PartLog.cpp b/src/Interpreters/PartLog.cpp\nindex d12eca407d93..75e6d02d6e18 100644\n--- a/src/Interpreters/PartLog.cpp\n+++ b/src/Interpreters/PartLog.cpp\n@@ -169,16 +169,6 @@ bool PartLog::addNewPart(\n     return addNewParts(current_context, {part}, elapsed_ns, execution_status);\n }\n \n-static inline UInt64 time_in_microseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::microseconds>(timepoint.time_since_epoch()).count();\n-}\n-\n-\n-static inline UInt64 time_in_seconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::seconds>(timepoint.time_since_epoch()).count();\n-}\n \n bool PartLog::addNewParts(\n     ContextPtr current_context, const PartLog::MutableDataPartsVector & parts, UInt64 elapsed_ns, const ExecutionStatus & execution_status)\n@@ -209,8 +199,8 @@ bool PartLog::addNewParts(\n             // construct event_time and event_time_microseconds using the same time point\n             // so that the two times will always be equal up to a precision of a second.\n             const auto time_now = std::chrono::system_clock::now();\n-            elem.event_time = time_in_seconds(time_now);\n-            elem.event_time_microseconds = time_in_microseconds(time_now);\n+            elem.event_time = timeInSeconds(time_now);\n+            elem.event_time_microseconds = timeInMicroseconds(time_now);\n             elem.duration_ms = elapsed_ns / 1000000;\n \n             elem.database_name = table_id.database_name;\ndiff --git a/src/Interpreters/SessionLog.cpp b/src/Interpreters/SessionLog.cpp\nindex 29357875488e..3edb84c046d8 100644\n--- a/src/Interpreters/SessionLog.cpp\n+++ b/src/Interpreters/SessionLog.cpp\n@@ -30,21 +30,11 @@ namespace\n {\n using namespace DB;\n \n-inline DateTime64 time_in_microseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::microseconds>(timepoint.time_since_epoch()).count();\n-}\n-\n-inline time_t time_in_seconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::seconds>(timepoint.time_since_epoch()).count();\n-}\n-\n auto eventTime()\n {\n     const auto finish_time = std::chrono::system_clock::now();\n \n-    return std::make_pair(time_in_seconds(finish_time), time_in_microseconds(finish_time));\n+    return std::make_pair(timeInSeconds(finish_time), timeInMicroseconds(finish_time));\n }\n \n using AuthType = AuthenticationType;\ndiff --git a/src/Interpreters/SystemLog.cpp b/src/Interpreters/SystemLog.cpp\nindex 3fc5dda06723..b5e4a0e81c77 100644\n--- a/src/Interpreters/SystemLog.cpp\n+++ b/src/Interpreters/SystemLog.cpp\n@@ -13,6 +13,7 @@\n #include <Interpreters/ZooKeeperLog.h>\n #include <Interpreters/TransactionsInfoLog.h>\n #include <Interpreters/FilesystemCacheLog.h>\n+#include <Interpreters/AsynchronousInsertLog.h>\n #include <Interpreters/InterpreterCreateQuery.h>\n #include <Interpreters/InterpreterRenameQuery.h>\n #include <Interpreters/InterpreterInsertQuery.h>\n@@ -208,6 +209,7 @@ SystemLogs::SystemLogs(ContextPtr global_context, const Poco::Util::AbstractConf\n     transactions_info_log = createSystemLog<TransactionsInfoLog>(\n         global_context, \"system\", \"transactions_info_log\", config, \"transactions_info_log\");\n     processors_profile_log = createSystemLog<ProcessorsProfileLog>(global_context, \"system\", \"processors_profile_log\", config, \"processors_profile_log\");\n+    asynchronous_insert_log = createSystemLog<AsynchronousInsertLog>(global_context, \"system\", \"asynchronous_insert_log\", config, \"asynchronous_insert_log\");\n \n     if (query_log)\n         logs.emplace_back(query_log.get());\n@@ -242,6 +244,8 @@ SystemLogs::SystemLogs(ContextPtr global_context, const Poco::Util::AbstractConf\n         logs.emplace_back(processors_profile_log.get());\n     if (cache_log)\n         logs.emplace_back(cache_log.get());\n+    if (asynchronous_insert_log)\n+        logs.emplace_back(asynchronous_insert_log.get());\n \n     try\n     {\ndiff --git a/src/Interpreters/SystemLog.h b/src/Interpreters/SystemLog.h\nindex 911e316685e4..95292a2b7ced 100644\n--- a/src/Interpreters/SystemLog.h\n+++ b/src/Interpreters/SystemLog.h\n@@ -47,6 +47,7 @@ class SessionLog;\n class TransactionsInfoLog;\n class ProcessorsProfileLog;\n class FilesystemCacheLog;\n+class AsynchronousInsertLog;\n \n /// System logs should be destroyed in destructor of the last Context and before tables,\n ///  because SystemLog destruction makes insert query while flushing data into underlying tables\n@@ -79,6 +80,7 @@ struct SystemLogs\n     std::shared_ptr<TransactionsInfoLog> transactions_info_log;\n     /// Used to log processors profiling\n     std::shared_ptr<ProcessorsProfileLog> processors_profile_log;\n+    std::shared_ptr<AsynchronousInsertLog> asynchronous_insert_log;\n \n     std::vector<ISystemLog *> logs;\n };\ndiff --git a/src/Interpreters/ThreadStatusExt.cpp b/src/Interpreters/ThreadStatusExt.cpp\nindex 9a4152415aff..3e7f08e9d9a3 100644\n--- a/src/Interpreters/ThreadStatusExt.cpp\n+++ b/src/Interpreters/ThreadStatusExt.cpp\n@@ -17,6 +17,7 @@\n #include <Common/ThreadProfileEvents.h>\n #include <Common/setThreadName.h>\n #include <Common/noexcept_scope.h>\n+#include <Common/DateLUT.h>\n #include <base/errnoToString.h>\n \n #if defined(OS_LINUX)\n@@ -154,22 +155,6 @@ void ThreadStatus::attachQuery(const ThreadGroupStatusPtr & thread_group_, bool\n     setupState(thread_group_);\n }\n \n-inline UInt64 time_in_nanoseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::nanoseconds>(timepoint.time_since_epoch()).count();\n-}\n-\n-inline UInt64 time_in_microseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::microseconds>(timepoint.time_since_epoch()).count();\n-}\n-\n-\n-inline UInt64 time_in_seconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::seconds>(timepoint.time_since_epoch()).count();\n-}\n-\n void ThreadStatus::initPerformanceCounters()\n {\n     performance_counters_finalized = false;\n@@ -184,9 +169,9 @@ void ThreadStatus::initPerformanceCounters()\n     // to ensure that they are all equal up to the precision of a second.\n     const auto now = std::chrono::system_clock::now();\n \n-    query_start_time_nanoseconds = time_in_nanoseconds(now);\n-    query_start_time = time_in_seconds(now);\n-    query_start_time_microseconds = time_in_microseconds(now);\n+    query_start_time_nanoseconds = timeInNanoseconds(now);\n+    query_start_time = timeInSeconds(now);\n+    query_start_time_microseconds = timeInMicroseconds(now);\n     ++queries_started;\n \n     // query_start_time_nanoseconds cannot be used here since RUsageCounters expect CLOCK_MONOTONIC\n@@ -261,7 +246,7 @@ void ThreadStatus::finalizePerformanceCounters()\n             if (settings.log_queries && settings.log_query_threads)\n             {\n                 const auto now = std::chrono::system_clock::now();\n-                Int64 query_duration_ms = (time_in_microseconds(now) - query_start_time_microseconds) / 1000;\n+                Int64 query_duration_ms = (timeInMicroseconds(now) - query_start_time_microseconds) / 1000;\n                 if (query_duration_ms >= settings.log_queries_min_query_duration_ms.totalMilliseconds())\n                 {\n                     if (auto thread_log = global_context_ptr->getQueryThreadLog())\n@@ -378,14 +363,14 @@ void ThreadStatus::logToQueryThreadLog(QueryThreadLog & thread_log, const String\n \n     // construct current_time and current_time_microseconds using the same time point\n     // so that the two times will always be equal up to a precision of a second.\n-    auto current_time = time_in_seconds(now);\n-    auto current_time_microseconds = time_in_microseconds(now);\n+    auto current_time = timeInSeconds(now);\n+    auto current_time_microseconds = timeInMicroseconds(now);\n \n     elem.event_time = current_time;\n     elem.event_time_microseconds = current_time_microseconds;\n     elem.query_start_time = query_start_time;\n     elem.query_start_time_microseconds = query_start_time_microseconds;\n-    elem.query_duration_ms = (time_in_nanoseconds(now) - query_start_time_nanoseconds) / 1000000U;\n+    elem.query_duration_ms = (timeInNanoseconds(now) - query_start_time_nanoseconds) / 1000000U;\n \n     elem.read_rows = progress_in.read_rows.load(std::memory_order_relaxed);\n     elem.read_bytes = progress_in.read_bytes.load(std::memory_order_relaxed);\n@@ -447,8 +432,8 @@ void ThreadStatus::logToQueryViewsLog(const ViewRuntimeData & vinfo)\n \n     QueryViewsLogElement element;\n \n-    element.event_time = time_in_seconds(vinfo.runtime_stats->event_time);\n-    element.event_time_microseconds = time_in_microseconds(vinfo.runtime_stats->event_time);\n+    element.event_time = timeInSeconds(vinfo.runtime_stats->event_time);\n+    element.event_time_microseconds = timeInMicroseconds(vinfo.runtime_stats->event_time);\n     element.view_duration_ms = vinfo.runtime_stats->elapsed_ms;\n \n     element.initial_query_id = query_id;\ndiff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp\nindex 6e17e05a7548..35edebb11610 100644\n--- a/src/Interpreters/executeQuery.cpp\n+++ b/src/Interpreters/executeQuery.cpp\n@@ -234,17 +234,6 @@ static void logException(ContextPtr context, QueryLogElement & elem)\n             elem.stack_trace);\n }\n \n-inline UInt64 time_in_microseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::microseconds>(timepoint.time_since_epoch()).count();\n-}\n-\n-\n-inline UInt64 time_in_seconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::seconds>(timepoint.time_since_epoch()).count();\n-}\n-\n static void onExceptionBeforeStart(const String & query_for_logging, ContextPtr context, UInt64 current_time_us, ASTPtr ast, const std::shared_ptr<OpenTelemetry::SpanHolder> & query_span)\n {\n     /// Exception before the query execution.\n@@ -379,8 +368,8 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n     // example, the query is from an initiator that is running an old version of clickhouse.\n     if (!internal && client_info.initial_query_start_time == 0)\n     {\n-        client_info.initial_query_start_time = time_in_seconds(current_time);\n-        client_info.initial_query_start_time_microseconds = time_in_microseconds(current_time);\n+        client_info.initial_query_start_time = timeInSeconds(current_time);\n+        client_info.initial_query_start_time_microseconds = timeInMicroseconds(current_time);\n     }\n \n     assert(internal || CurrentThread::get().getQueryContext());\n@@ -448,7 +437,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n         logQuery(query_for_logging, context, internal, stage);\n \n         if (!internal)\n-            onExceptionBeforeStart(query_for_logging, context, time_in_microseconds(current_time), ast, query_span);\n+            onExceptionBeforeStart(query_for_logging, context, timeInMicroseconds(current_time), ast, query_span);\n         throw;\n     }\n \n@@ -742,10 +731,10 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n \n             elem.type = QueryLogElementType::QUERY_START; //-V1048\n \n-            elem.event_time = time_in_seconds(current_time);\n-            elem.event_time_microseconds = time_in_microseconds(current_time);\n-            elem.query_start_time = time_in_seconds(current_time);\n-            elem.query_start_time_microseconds = time_in_microseconds(current_time);\n+            elem.event_time = timeInSeconds(current_time);\n+            elem.event_time_microseconds = timeInMicroseconds(current_time);\n+            elem.query_start_time = timeInSeconds(current_time);\n+            elem.query_start_time_microseconds = timeInMicroseconds(current_time);\n \n             elem.current_database = context->getCurrentDatabase();\n             elem.query = query_for_logging;\n@@ -874,8 +863,8 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n                     // construct event_time and event_time_microseconds using the same time point\n                     // so that the two times will always be equal up to a precision of a second.\n                     const auto finish_time = std::chrono::system_clock::now();\n-                    elem.event_time = time_in_seconds(finish_time);\n-                    elem.event_time_microseconds = time_in_microseconds(finish_time);\n+                    elem.event_time = timeInSeconds(finish_time);\n+                    elem.event_time_microseconds = timeInMicroseconds(finish_time);\n                     status_info_to_query_log(elem, info, ast, context);\n \n                     if (pulling_pipeline)\n@@ -915,8 +904,8 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n                         if (auto processors_profile_log = context->getProcessorsProfileLog())\n                         {\n                             ProcessorProfileLogElement processor_elem;\n-                            processor_elem.event_time = time_in_seconds(finish_time);\n-                            processor_elem.event_time_microseconds = time_in_microseconds(finish_time);\n+                            processor_elem.event_time = timeInSeconds(finish_time);\n+                            processor_elem.event_time_microseconds = timeInMicroseconds(finish_time);\n                             processor_elem.query_id = elem.client_info.current_query_id;\n \n                             auto get_proc_id = [](const IProcessor & proc) -> UInt64\n@@ -1018,8 +1007,8 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n                 // to ensure that both the times will be equal up to the precision of a second.\n                 const auto time_now = std::chrono::system_clock::now();\n \n-                elem.event_time = time_in_seconds(time_now);\n-                elem.event_time_microseconds = time_in_microseconds(time_now);\n+                elem.event_time = timeInSeconds(time_now);\n+                elem.event_time_microseconds = timeInMicroseconds(time_now);\n                 elem.query_duration_ms = 1000 * (elem.event_time - elem.query_start_time);\n                 elem.exception_code = getCurrentExceptionCode();\n                 elem.exception = getCurrentExceptionMessage(false);\n@@ -1084,7 +1073,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n         }\n \n         if (!internal)\n-            onExceptionBeforeStart(query_for_logging, context, time_in_microseconds(current_time), ast, query_span);\n+            onExceptionBeforeStart(query_for_logging, context, timeInMicroseconds(current_time), ast, query_span);\n \n         throw;\n     }\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex ea7b87a5a582..f519fd75ecb8 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -193,16 +193,6 @@ static void checkSampleExpression(const StorageInMemoryMetadata & metadata, bool\n             ErrorCodes::ILLEGAL_TYPE_OF_COLUMN_FOR_FILTER);\n }\n \n-inline UInt64 time_in_microseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::microseconds>(timepoint.time_since_epoch()).count();\n-}\n-\n-inline UInt64 time_in_seconds(std::chrono::time_point<std::chrono::system_clock> timepoint)\n-{\n-    return std::chrono::duration_cast<std::chrono::seconds>(timepoint.time_since_epoch()).count();\n-}\n-\n MergeTreeData::MergeTreeData(\n     const StorageID & table_id_,\n     const String & relative_data_path_,\n@@ -1817,8 +1807,8 @@ void MergeTreeData::removePartsFinally(const MergeTreeData::DataPartsVector & pa\n         part_log_elem.event_type = PartLogElement::REMOVE_PART;\n \n         const auto time_now = std::chrono::system_clock::now();\n-        part_log_elem.event_time = time_in_seconds(time_now);\n-        part_log_elem.event_time_microseconds = time_in_microseconds(time_now);\n+        part_log_elem.event_time = timeInSeconds(time_now);\n+        part_log_elem.event_time_microseconds = timeInMicroseconds(time_now);\n \n         part_log_elem.duration_ms = 0; //-V1048\n \n@@ -6516,8 +6506,8 @@ try\n     // construct event_time and event_time_microseconds using the same time point\n     // so that the two times will always be equal up to a precision of a second.\n     const auto time_now = std::chrono::system_clock::now();\n-    part_log_elem.event_time = time_in_seconds(time_now);\n-    part_log_elem.event_time_microseconds = time_in_microseconds(time_now);\n+    part_log_elem.event_time = timeInSeconds(time_now);\n+    part_log_elem.event_time_microseconds = timeInMicroseconds(time_now);\n \n     /// TODO: Stop stopwatch in outer code to exclude ZK timings and so on\n     part_log_elem.duration_ms = elapsed_ns / 1000000;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02456_async_inserts_logs.reference b/tests/queries/0_stateless/02456_async_inserts_logs.reference\nnew file mode 100644\nindex 000000000000..efd8a88eca4b\n--- /dev/null\n+++ b/tests/queries/0_stateless/02456_async_inserts_logs.reference\n@@ -0,0 +1,7 @@\n+5\n+\tValues\t21\t1\tOk\t1\n+t_async_inserts_logs\tJSONEachRow\t39\t1\tOk\t1\n+t_async_inserts_logs\tValues\t8\t1\tOk\t1\n+t_async_inserts_logs\tJSONEachRow\t6\t0\tParsingError\t1\n+t_async_inserts_logs\tValues\t6\t0\tParsingError\t1\n+t_async_inserts_logs\tValues\t8\t0\tFlushError\t1\ndiff --git a/tests/queries/0_stateless/02456_async_inserts_logs.sh b/tests/queries/0_stateless/02456_async_inserts_logs.sh\nnew file mode 100755\nindex 000000000000..006455e2d42f\n--- /dev/null\n+++ b/tests/queries/0_stateless/02456_async_inserts_logs.sh\n@@ -0,0 +1,39 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+url=\"${CLICKHOUSE_URL}&async_insert=1&wait_for_async_insert=1\"\n+\n+${CLICKHOUSE_CLIENT} -q \"DROP TABLE IF EXISTS t_async_inserts_logs\"\n+${CLICKHOUSE_CLIENT} -q \"CREATE TABLE t_async_inserts_logs (id UInt32, s String) ENGINE = MergeTree ORDER BY id\"\n+\n+${CLICKHOUSE_CURL} -sS \"$url\" -d 'INSERT INTO t_async_inserts_logs FORMAT JSONEachRow {\"id\": 5, \"s\": \"e\"} {\"id\": 6, \"s\": \"f\"}' &\n+${CLICKHOUSE_CURL} -sS \"$url\" -d \"INSERT INTO t_async_inserts_logs VALUES (1, 'a')\" &\n+\n+${CLICKHOUSE_CURL} -sS \"$url\" -d 'INSERT INTO t_async_inserts_logs FORMAT JSONEachRow qqqqqq' > /dev/null 2>&1 &\n+${CLICKHOUSE_CURL} -sS \"$url\" -d 'INSERT INTO t_async_inserts_logs VALUES qqqqqq' > /dev/null 2>&1 &\n+\n+${CLICKHOUSE_CURL} -sS \"$url\" -d \"INSERT INTO FUNCTION remote('127.0.0.1', currentDatabase(), t_async_inserts_logs) VALUES (1, 'aaa') (2, 'bbb')\" &\n+\n+wait\n+\n+${CLICKHOUSE_CLIENT} -q \"OPTIMIZE TABLE t_async_inserts_logs FINAL\"\n+${CLICKHOUSE_CLIENT} -q \"ALTER TABLE t_async_inserts_logs MODIFY SETTING parts_to_throw_insert = 1\"\n+\n+${CLICKHOUSE_CURL} -sS \"$url\" -d \"INSERT INTO t_async_inserts_logs VALUES (1, 'a')\" > /dev/null 2>&1 &\n+\n+wait\n+\n+${CLICKHOUSE_CLIENT} -q \"SELECT count() FROM t_async_inserts_logs\"\n+\n+${CLICKHOUSE_CLIENT} -q \"SYSTEM FLUSH LOGS\"\n+${CLICKHOUSE_CLIENT} -q \"\n+    SELECT table, format, bytes, empty(exception), status,\n+    status = 'ParsingError' ? flush_time_microseconds = 0 : flush_time_microseconds > event_time_microseconds AS time_ok\n+    FROM system.asynchronous_insert_log\n+    WHERE database = '$CLICKHOUSE_DATABASE' OR query ILIKE 'INSERT INTO FUNCTION%$CLICKHOUSE_DATABASE%'\n+    ORDER BY table, status, format\"\n+\n+${CLICKHOUSE_CLIENT} -q \"DROP TABLE t_async_inserts_logs\"\n",
  "problem_statement": "Async insert should always provide an error indication (outside of  server error log) when a row fails to be inserted \nCurrently, if one insert contains 4 rows and one of the rows is \"faulty\":\r\n\r\nIf `async_insert=1` and `wait_for_async_insert=1` (the default value):\r\n- None of the 4 rows will be inserted\r\n- `ClickHouse will return an error` with the detailed reason about the faulty row\r\n- There will be a detailed error with the detailed reason for the faulty row in the ClickHouse `server error log`, including the query id\r\n- There will be a row in the `system.query_log` table for the query_id with `type='ExceptionWhileProcessing'`, containing the exact error message (there will also be a row with type=QueryStart for the insert)\r\n\r\n\r\nIf `async_insert=1` and `wait_for_async_insert=0`:\r\n- None of the 4 rows will be inserted\r\n- ClickHouse will not return an error (makes sense as we just told ClickHouse \"here are 4 rows, please try to insert them asap, but I have other things to do now\") \r\n- There will be a detailed error with the detailed reason about the faulty row in the ClickHouse `server error log`, including the query id\r\n- The `system.query_log` table does not indicate the error - there will be NO row in the system.query_log table for the query_id with type='ExceptionWhileProcessing', instead there will be two rows, one with type=QueryStart, and one with type=QueryFinish, and none of these two rows is indicating any error \r\n\r\nIt would be useful to always have an indication of an insert error in one of the system tables, especially for scenarios where access to the server error log is not possible.\r\n\r\n\n",
  "hints_text": "",
  "created_at": "2022-10-03T19:34:43Z"
}