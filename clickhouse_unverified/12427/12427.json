{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 12427,
  "instance_id": "ClickHouse__ClickHouse-12427",
  "issue_numbers": [
    "11372",
    "10470"
  ],
  "base_commit": "5ef8d49ebe1512af262fc7dbcb9f37db3e8cc25a",
  "patch": "diff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp\nindex e0abc80b51d5..dad3f82fbc4c 100644\n--- a/src/Interpreters/InterpreterSelectQuery.cpp\n+++ b/src/Interpreters/InterpreterSelectQuery.cpp\n@@ -689,6 +689,9 @@ static UInt64 getLimitForSorting(const ASTSelectQuery & query, const Context & c\n     if (!query.distinct && !query.limitBy() && !query.limit_with_ties && !query.arrayJoinExpressionList() && query.limitLength())\n     {\n         auto [limit_length, limit_offset] = getLimitLengthAndOffset(query, context);\n+        if (limit_length > std::numeric_limits<UInt64>::max() - limit_offset)\n+            return 0;\n+\n         return limit_length + limit_offset;\n     }\n     return 0;\n@@ -1287,6 +1290,7 @@ void InterpreterSelectQuery::executeFetchColumns(\n         && !query.limitBy()\n         && query.limitLength()\n         && !query_analyzer->hasAggregation()\n+        && limit_length <= std::numeric_limits<UInt64>::max() - limit_offset\n         && limit_length + limit_offset < max_block_size)\n     {\n         max_block_size = std::max(UInt64(1), limit_length + limit_offset);\n@@ -1649,8 +1653,9 @@ void InterpreterSelectQuery::executeDistinct(QueryPlan & query_plan, bool before\n         auto [limit_length, limit_offset] = getLimitLengthAndOffset(query, *context);\n         UInt64 limit_for_distinct = 0;\n \n-        /// If after this stage of DISTINCT ORDER BY is not executed, then you can get no more than limit_length + limit_offset of different rows.\n-        if (!query.orderBy() || !before_order)\n+        /// If after this stage of DISTINCT ORDER BY is not executed,\n+        /// then you can get no more than limit_length + limit_offset of different rows.\n+        if ((!query.orderBy() || !before_order) && limit_length <= std::numeric_limits<UInt64>::max() - limit_offset)\n             limit_for_distinct = limit_length + limit_offset;\n \n         SizeLimits limits(settings.max_rows_in_distinct, settings.max_bytes_in_distinct, settings.distinct_overflow_mode);\n@@ -1678,6 +1683,9 @@ void InterpreterSelectQuery::executePreLimit(QueryPlan & query_plan, bool do_not\n \n         if (do_not_skip_offset)\n         {\n+            if (limit_length > std::numeric_limits<UInt64>::max() - limit_offset)\n+                return;\n+\n             limit_length += limit_offset;\n             limit_offset = 0;\n         }\ndiff --git a/src/Processors/LimitTransform.cpp b/src/Processors/LimitTransform.cpp\nindex fe8990f7b0f3..f7043cbfec58 100644\n--- a/src/Processors/LimitTransform.cpp\n+++ b/src/Processors/LimitTransform.cpp\n@@ -10,7 +10,7 @@ namespace ErrorCodes\n }\n \n LimitTransform::LimitTransform(\n-    const Block & header_, size_t limit_, size_t offset_, size_t num_streams,\n+    const Block & header_, UInt64 limit_, UInt64 offset_, size_t num_streams,\n     bool always_read_till_end_, bool with_ties_,\n     SortDescription description_)\n     : IProcessor(InputPorts(num_streams, header_), OutputPorts(num_streams, header_))\n@@ -46,7 +46,7 @@ LimitTransform::LimitTransform(\n     }\n }\n \n-Chunk LimitTransform::makeChunkWithPreviousRow(const Chunk & chunk, size_t row) const\n+Chunk LimitTransform::makeChunkWithPreviousRow(const Chunk & chunk, UInt64 row) const\n {\n     assert(row < chunk.getNumRows());\n     ColumnRawPtrs current_columns = extractSortColumns(chunk.getColumns());\n@@ -93,7 +93,6 @@ IProcessor::Status LimitTransform::prepare(\n                 throw Exception(\n                         \"Unexpected status for LimitTransform::preparePair : \" + IProcessor::statusToName(status),\n                         ErrorCodes::LOGICAL_ERROR);\n-\n         }\n     };\n \n@@ -107,9 +106,12 @@ IProcessor::Status LimitTransform::prepare(\n     if (num_finished_port_pairs == ports_data.size())\n         return Status::Finished;\n \n+    bool limit_is_unreachable = (limit > std::numeric_limits<UInt64>::max() - offset);\n+\n     /// If we reached limit for some port, then close others. Otherwise some sources may infinitely read data.\n     /// Example: SELECT * FROM system.numbers_mt WHERE number = 1000000 LIMIT 1\n-    if ((rows_read >= offset + limit) && !previous_row_chunk && !always_read_till_end)\n+    if ((!limit_is_unreachable && rows_read >= offset + limit)\n+        && !previous_row_chunk && !always_read_till_end)\n     {\n         for (auto & input : inputs)\n             input.close();\n@@ -158,8 +160,10 @@ LimitTransform::Status LimitTransform::preparePair(PortsData & data)\n         return Status::PortFull;\n     }\n \n+    bool limit_is_unreachable = (limit > std::numeric_limits<UInt64>::max() - offset);\n+\n     /// Check if we are done with pushing.\n-    bool is_limit_reached = (rows_read >= offset + limit) && !previous_row_chunk;\n+    bool is_limit_reached = !limit_is_unreachable && rows_read >= offset + limit && !previous_row_chunk;\n     if (is_limit_reached)\n     {\n         if (!always_read_till_end)\n@@ -223,7 +227,8 @@ LimitTransform::Status LimitTransform::preparePair(PortsData & data)\n         return Status::NeedData;\n     }\n \n-    if (rows_read >= offset + rows && rows_read <= offset + limit)\n+    if (rows <= std::numeric_limits<UInt64>::max() - offset && rows_read >= offset + rows\n+        && !limit_is_unreachable && rows_read <= offset + limit)\n     {\n         /// Return the whole chunk.\n \n@@ -237,7 +242,7 @@ LimitTransform::Status LimitTransform::preparePair(PortsData & data)\n \n     bool may_need_more_data_for_ties = previous_row_chunk || rows_read - rows <= offset + limit;\n     /// No more data is needed.\n-    if (!always_read_till_end && (rows_read >= offset + limit) && !may_need_more_data_for_ties)\n+    if (!always_read_till_end && !limit_is_unreachable && rows_read >= offset + limit && !may_need_more_data_for_ties)\n         input.close();\n \n     output.push(std::move(data.current_chunk));\n@@ -249,13 +254,15 @@ LimitTransform::Status LimitTransform::preparePair(PortsData & data)\n void LimitTransform::splitChunk(PortsData & data)\n {\n     auto current_chunk_sort_columns = extractSortColumns(data.current_chunk.getColumns());\n-    size_t num_rows = data.current_chunk.getNumRows();\n-    size_t num_columns = data.current_chunk.getNumColumns();\n+    UInt64 num_rows = data.current_chunk.getNumRows();\n+    UInt64 num_columns = data.current_chunk.getNumColumns();\n+\n+    bool limit_is_unreachable = (limit > std::numeric_limits<UInt64>::max() - offset);\n \n-    if (previous_row_chunk && rows_read >= offset + limit)\n+    if (previous_row_chunk && !limit_is_unreachable && rows_read >= offset + limit)\n     {\n         /// Scan until the first row, which is not equal to previous_row_chunk (for WITH TIES)\n-        size_t current_row_num = 0;\n+        UInt64 current_row_num = 0;\n         for (; current_row_num < num_rows; ++current_row_num)\n         {\n             if (!sortColumnsEqualAt(current_chunk_sort_columns, current_row_num))\n@@ -267,7 +274,7 @@ void LimitTransform::splitChunk(PortsData & data)\n         if (current_row_num < num_rows)\n         {\n             previous_row_chunk = {};\n-            for (size_t i = 0; i < num_columns; ++i)\n+            for (UInt64 i = 0; i < num_columns; ++i)\n                 columns[i] = columns[i]->cut(0, current_row_num);\n         }\n \n@@ -276,19 +283,51 @@ void LimitTransform::splitChunk(PortsData & data)\n     }\n \n     /// return a piece of the block\n-    size_t start = std::max(\n-        static_cast<Int64>(0),\n-        static_cast<Int64>(offset) - static_cast<Int64>(rows_read) + static_cast<Int64>(num_rows));\n+    UInt64 start = 0;\n+\n+    /// ------------[....(...).]\n+    /// <----------------------> rows_read\n+    ///             <----------> num_rows\n+    /// <---------------> offset\n+    ///             <---> start\n+\n+    assert(offset < rows_read);\n+\n+    if (offset + num_rows > rows_read)\n+        start = offset + num_rows - rows_read;\n \n-    size_t length = std::min(\n-        static_cast<Int64>(limit), std::min(\n-        static_cast<Int64>(rows_read) - static_cast<Int64>(offset),\n-        static_cast<Int64>(limit) + static_cast<Int64>(offset) - static_cast<Int64>(rows_read) + static_cast<Int64>(num_rows)));\n+    /// ------------[....(...).]\n+    /// <----------------------> rows_read\n+    ///             <----------> num_rows\n+    /// <---------------> offset\n+    ///                  <---> limit\n+    ///                  <---> length\n+    ///             <---> start\n+\n+    /// Or:\n+\n+    /// -----------------(------[....)....]\n+    /// <---------------------------------> rows_read\n+    ///                         <---------> num_rows\n+    /// <---------------> offset\n+    ///                  <-----------> limit\n+    ///                         <----> length\n+    ///                         0 = start\n+\n+    UInt64 length = num_rows - start;\n+\n+    if (!limit_is_unreachable && offset + limit < rows_read)\n+    {\n+        if (offset + limit < rows_read - num_rows)\n+            length = 0;\n+        else\n+            length = offset + limit - (rows_read - num_rows) - start;\n+    }\n \n     /// check if other rows in current block equals to last one in limit\n     if (with_ties && length)\n     {\n-        size_t current_row_num = start + length;\n+        UInt64 current_row_num = start + length;\n         previous_row_chunk = makeChunkWithPreviousRow(data.current_chunk, current_row_num - 1);\n \n         for (; current_row_num < num_rows; ++current_row_num)\n@@ -308,7 +347,7 @@ void LimitTransform::splitChunk(PortsData & data)\n \n     auto columns = data.current_chunk.detachColumns();\n \n-    for (size_t i = 0; i < num_columns; ++i)\n+    for (UInt64 i = 0; i < num_columns; ++i)\n         columns[i] = columns[i]->cut(start, length);\n \n     data.current_chunk.setColumns(std::move(columns), length);\n@@ -324,7 +363,7 @@ ColumnRawPtrs LimitTransform::extractSortColumns(const Columns & columns) const\n     return res;\n }\n \n-bool LimitTransform::sortColumnsEqualAt(const ColumnRawPtrs & current_chunk_sort_columns, size_t current_chunk_row_num) const\n+bool LimitTransform::sortColumnsEqualAt(const ColumnRawPtrs & current_chunk_sort_columns, UInt64 current_chunk_row_num) const\n {\n     assert(current_chunk_sort_columns.size() == previous_row_chunk.getNumColumns());\n     size_t size = current_chunk_sort_columns.size();\ndiff --git a/src/Processors/LimitTransform.h b/src/Processors/LimitTransform.h\nindex ffa151bc0648..8865eab732ab 100644\n--- a/src/Processors/LimitTransform.h\n+++ b/src/Processors/LimitTransform.h\n@@ -18,9 +18,9 @@ namespace DB\n class LimitTransform : public IProcessor\n {\n private:\n+    UInt64 limit;\n+    UInt64 offset;\n \n-    size_t limit;\n-    size_t offset;\n     bool always_read_till_end;\n \n     bool with_ties;\n@@ -29,7 +29,7 @@ class LimitTransform : public IProcessor\n     Chunk previous_row_chunk;  /// for WITH TIES, contains only sort columns\n     std::vector<size_t> sort_column_positions;\n \n-    size_t rows_read = 0; /// including the last read block\n+    UInt64 rows_read = 0; /// including the last read block\n     RowsBeforeLimitCounterPtr rows_before_limit_at_least;\n \n     /// State of port's pair.\n@@ -46,13 +46,13 @@ class LimitTransform : public IProcessor\n     std::vector<PortsData> ports_data;\n     size_t num_finished_port_pairs = 0;\n \n-    Chunk makeChunkWithPreviousRow(const Chunk & current_chunk, size_t row_num) const;\n+    Chunk makeChunkWithPreviousRow(const Chunk & current_chunk, UInt64 row_num) const;\n     ColumnRawPtrs extractSortColumns(const Columns & columns) const;\n-    bool sortColumnsEqualAt(const ColumnRawPtrs & current_chunk_sort_columns, size_t current_chunk_row_num) const;\n+    bool sortColumnsEqualAt(const ColumnRawPtrs & current_chunk_sort_columns, UInt64 current_chunk_row_num) const;\n \n public:\n     LimitTransform(\n-        const Block & header_, size_t limit_, size_t offset_, size_t num_streams = 1,\n+        const Block & header_, UInt64 limit_, UInt64 offset_, size_t num_streams = 1,\n         bool always_read_till_end_ = false, bool with_ties_ = false,\n         SortDescription description_ = {});\n \ndiff --git a/src/Processors/OffsetTransform.cpp b/src/Processors/OffsetTransform.cpp\nindex f380a5a51596..0ab93d5b6730 100644\n--- a/src/Processors/OffsetTransform.cpp\n+++ b/src/Processors/OffsetTransform.cpp\n@@ -10,7 +10,7 @@ namespace ErrorCodes\n }\n \n OffsetTransform::OffsetTransform(\n-    const Block & header_, size_t offset_, size_t num_streams)\n+    const Block & header_, UInt64 offset_, size_t num_streams)\n     : IProcessor(InputPorts(num_streams, header_), OutputPorts(num_streams, header_))\n     , offset(offset_)\n {\n@@ -135,7 +135,7 @@ OffsetTransform::Status OffsetTransform::preparePair(PortsData & data)\n \n     rows_read += rows;\n \n-    if (rows_read < offset)\n+    if (rows_read <= offset)\n     {\n         data.current_chunk.clear();\n \n@@ -150,7 +150,7 @@ OffsetTransform::Status OffsetTransform::preparePair(PortsData & data)\n         return Status::NeedData;\n     }\n \n-    if (!(rows_read >= offset + rows))\n+    if (!(rows <= std::numeric_limits<UInt64>::max() - offset && rows_read >= offset + rows))\n         splitChunk(data);\n \n     output.push(std::move(data.current_chunk));\n@@ -161,22 +161,30 @@ OffsetTransform::Status OffsetTransform::preparePair(PortsData & data)\n \n void OffsetTransform::splitChunk(PortsData & data) const\n {\n-    size_t num_rows = data.current_chunk.getNumRows();\n-    size_t num_columns = data.current_chunk.getNumColumns();\n+    UInt64 num_rows = data.current_chunk.getNumRows();\n+    UInt64 num_columns = data.current_chunk.getNumColumns();\n \n     /// return a piece of the block\n-    size_t start = std::max(\n-        static_cast<Int64>(0),\n-        static_cast<Int64>(offset) - static_cast<Int64>(rows_read) + static_cast<Int64>(num_rows));\n+    UInt64 start = 0;\n \n-    size_t length = static_cast<Int64>(rows_read) - static_cast<Int64>(offset);\n+    /// ------------[....(.....]\n+    /// <----------------------> rows_read\n+    ///             <----------> num_rows\n+    /// <---------------> offset\n+    ///             <---> start\n \n-    if (length == num_rows)\n+    assert(offset < rows_read);\n+\n+    if (offset + num_rows > rows_read)\n+        start = offset + num_rows - rows_read;\n+    else\n         return;\n \n+    UInt64 length = num_rows - start;\n+\n     auto columns = data.current_chunk.detachColumns();\n \n-    for (size_t i = 0; i < num_columns; ++i)\n+    for (UInt64 i = 0; i < num_columns; ++i)\n         columns[i] = columns[i]->cut(start, length);\n \n     data.current_chunk.setColumns(std::move(columns), length);\ndiff --git a/src/Processors/OffsetTransform.h b/src/Processors/OffsetTransform.h\nindex 905e8298d153..e67685362aa1 100644\n--- a/src/Processors/OffsetTransform.h\n+++ b/src/Processors/OffsetTransform.h\n@@ -13,10 +13,9 @@ namespace DB\n class OffsetTransform : public IProcessor\n {\n private:\n+    UInt64 offset;\n+    UInt64 rows_read = 0; /// including the last read block\n \n-    size_t offset;\n-\n-    size_t rows_read = 0; /// including the last read block\n     RowsBeforeLimitCounterPtr rows_before_limit_at_least;\n \n     /// State of port's pair.\n@@ -34,7 +33,7 @@ class OffsetTransform : public IProcessor\n     size_t num_finished_port_pairs = 0;\n \n public:\n-    OffsetTransform(const Block & header_, size_t offset_, size_t num_streams = 1);\n+    OffsetTransform(const Block & header_, UInt64 offset_, size_t num_streams = 1);\n \n     String getName() const override { return \"Offset\"; }\n \ndiff --git a/src/Processors/Transforms/LimitByTransform.cpp b/src/Processors/Transforms/LimitByTransform.cpp\nindex 8891ae11c035..5c405046a831 100644\n--- a/src/Processors/Transforms/LimitByTransform.cpp\n+++ b/src/Processors/Transforms/LimitByTransform.cpp\n@@ -5,7 +5,7 @@\n namespace DB\n {\n \n-LimitByTransform::LimitByTransform(const Block & header, size_t group_length_, size_t group_offset_, const Names & columns)\n+LimitByTransform::LimitByTransform(const Block & header, UInt64 group_length_, UInt64 group_offset_, const Names & columns)\n     : ISimpleTransform(header, header, true)\n     , group_length(group_length_)\n     , group_offset(group_offset_)\n@@ -25,13 +25,13 @@ LimitByTransform::LimitByTransform(const Block & header, size_t group_length_, s\n \n void LimitByTransform::transform(Chunk & chunk)\n {\n-    size_t num_rows = chunk.getNumRows();\n+    UInt64 num_rows = chunk.getNumRows();\n     auto columns = chunk.detachColumns();\n \n     IColumn::Filter filter(num_rows);\n-    size_t inserted_count = 0;\n+    UInt64 inserted_count = 0;\n \n-    for (size_t row = 0; row < num_rows; ++row)\n+    for (UInt64 row = 0; row < num_rows; ++row)\n     {\n         UInt128 key(0, 0);\n         SipHash hash;\n@@ -42,9 +42,10 @@ void LimitByTransform::transform(Chunk & chunk)\n         hash.get128(key.low, key.high);\n \n         auto count = keys_counts[key]++;\n-        if (count >= group_offset && count < group_length + group_offset)\n+        if (count >= group_offset\n+            && (group_length > std::numeric_limits<UInt64>::max() - group_offset || count < group_length + group_offset))\n         {\n-            inserted_count++;\n+            ++inserted_count;\n             filter[row] = 1;\n         }\n         else\ndiff --git a/src/Processors/Transforms/LimitByTransform.h b/src/Processors/Transforms/LimitByTransform.h\nindex 815114946c8f..9773f637f407 100644\n--- a/src/Processors/Transforms/LimitByTransform.h\n+++ b/src/Processors/Transforms/LimitByTransform.h\n@@ -10,7 +10,7 @@ namespace DB\n class LimitByTransform : public ISimpleTransform\n {\n public:\n-    LimitByTransform(const Block & header, size_t group_length_, size_t group_offset_, const Names & columns);\n+    LimitByTransform(const Block & header, UInt64 group_length_, UInt64 group_offset_, const Names & columns);\n \n     String getName() const override { return \"LimitByTransform\"; }\n \n@@ -22,8 +22,8 @@ class LimitByTransform : public ISimpleTransform\n \n     MapHashed keys_counts;\n     std::vector<size_t> key_positions;\n-    const size_t group_length;\n-    const size_t group_offset;\n+    const UInt64 group_length;\n+    const UInt64 group_offset;\n };\n \n }\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01391_limit_overflow.reference b/tests/queries/0_stateless/01391_limit_overflow.reference\nnew file mode 100644\nindex 000000000000..6fa0a9ec2b92\n--- /dev/null\n+++ b/tests/queries/0_stateless/01391_limit_overflow.reference\n@@ -0,0 +1,14 @@\n+2\n+3\n+4\n+5\n+6\n+7\n+8\n+9\n+---\n+5\n+6\n+7\n+8\n+9\ndiff --git a/tests/queries/0_stateless/01391_limit_overflow.sql b/tests/queries/0_stateless/01391_limit_overflow.sql\nnew file mode 100644\nindex 000000000000..b06622799f78\n--- /dev/null\n+++ b/tests/queries/0_stateless/01391_limit_overflow.sql\n@@ -0,0 +1,12 @@\n+SELECT number FROM numbers(10) ORDER BY number ASC LIMIT 2, 9223372036854775807 WITH TIES;\n+\n+SELECT '---';\n+\n+CREATE TEMPORARY TABLE a (a UInt64);\n+INSERT INTO TABLE a SELECT number FROM system.numbers LIMIT 10;\n+\n+SELECT a\n+FROM a\n+GROUP BY a\n+ORDER BY a ASC\n+LIMIT 5, 18446744073709551615;\ndiff --git a/tests/queries/0_stateless/01395_limit_more_cases.reference b/tests/queries/0_stateless/01395_limit_more_cases.reference\nnew file mode 100644\nindex 000000000000..c9d0dd73ab82\n--- /dev/null\n+++ b/tests/queries/0_stateless/01395_limit_more_cases.reference\n@@ -0,0 +1,257 @@\n+0\t0\t0\t0\t0\t0\t0\t0\n+0\t1\t1\t0\t0\t0\t0\t0\n+0\t2\t2\t0\t1\t0\t0\t0\n+0\t3\t3\t0\t2\t0\t0\t0\n+0\t4\t4\t0\t3\t0\t0\t0\n+0\t5\t5\t0\t4\t0\t0\t0\n+0\t6\t6\t0\t5\t0\t0\t0\n+0\t7\t7\t0\t6\t0\t0\t0\n+0\t8\t8\t0\t7\t0\t0\t0\n+0\t9\t9\t0\t8\t0\t0\t0\n+0\t10\t10\t0\t9\t0\t0\t0\n+0\t11\t11\t0\t10\t0\t0\t0\n+0\t12\t12\t0\t11\t0\t0\t0\n+0\t13\t13\t0\t12\t0\t0\t0\n+0\t14\t13\t0\t12\t0\t0\t0\n+0\t15\t13\t0\t12\t0\t0\t0\n+1\t0\t0\t0\t0\t0\t0\t0\n+1\t1\t1\t1\t1\t0\t0\t0\n+1\t2\t2\t1\t2\t0\t0\t0\n+1\t3\t3\t1\t3\t0\t0\t0\n+1\t4\t4\t1\t4\t0\t0\t0\n+1\t5\t5\t1\t5\t0\t0\t0\n+1\t6\t6\t1\t6\t0\t0\t0\n+1\t7\t7\t1\t7\t0\t0\t0\n+1\t8\t8\t1\t8\t0\t0\t0\n+1\t9\t9\t1\t9\t0\t0\t0\n+1\t10\t10\t1\t10\t0\t0\t0\n+1\t11\t11\t1\t11\t0\t0\t0\n+1\t12\t12\t1\t12\t0\t0\t0\n+1\t13\t12\t1\t12\t0\t0\t0\n+1\t14\t12\t1\t12\t0\t0\t0\n+1\t15\t12\t1\t12\t0\t0\t0\n+2\t0\t0\t0\t0\t0\t0\t0\n+2\t1\t1\t2\t2\t0\t0\t0\n+2\t2\t2\t2\t3\t0\t0\t0\n+2\t3\t3\t2\t4\t0\t0\t0\n+2\t4\t4\t2\t5\t0\t0\t0\n+2\t5\t5\t2\t6\t0\t0\t0\n+2\t6\t6\t2\t7\t0\t0\t0\n+2\t7\t7\t2\t8\t0\t0\t0\n+2\t8\t8\t2\t9\t0\t0\t0\n+2\t9\t9\t2\t10\t0\t0\t0\n+2\t10\t10\t2\t11\t0\t0\t0\n+2\t11\t11\t2\t12\t0\t0\t0\n+2\t12\t11\t2\t12\t0\t0\t0\n+2\t13\t11\t2\t12\t0\t0\t0\n+2\t14\t11\t2\t12\t0\t0\t0\n+2\t15\t11\t2\t12\t0\t0\t0\n+3\t0\t0\t0\t0\t0\t0\t0\n+3\t1\t1\t3\t3\t0\t0\t0\n+3\t2\t2\t3\t4\t0\t0\t0\n+3\t3\t3\t3\t5\t0\t0\t0\n+3\t4\t4\t3\t6\t0\t0\t0\n+3\t5\t5\t3\t7\t0\t0\t0\n+3\t6\t6\t3\t8\t0\t0\t0\n+3\t7\t7\t3\t9\t0\t0\t0\n+3\t8\t8\t3\t10\t0\t0\t0\n+3\t9\t9\t3\t11\t0\t0\t0\n+3\t10\t10\t3\t12\t0\t0\t0\n+3\t11\t10\t3\t12\t0\t0\t0\n+3\t12\t10\t3\t12\t0\t0\t0\n+3\t13\t10\t3\t12\t0\t0\t0\n+3\t14\t10\t3\t12\t0\t0\t0\n+3\t15\t10\t3\t12\t0\t0\t0\n+4\t0\t0\t0\t0\t0\t0\t0\n+4\t1\t1\t4\t4\t0\t0\t0\n+4\t2\t2\t4\t5\t0\t0\t0\n+4\t3\t3\t4\t6\t0\t0\t0\n+4\t4\t4\t4\t7\t0\t0\t0\n+4\t5\t5\t4\t8\t0\t0\t0\n+4\t6\t6\t4\t9\t0\t0\t0\n+4\t7\t7\t4\t10\t0\t0\t0\n+4\t8\t8\t4\t11\t0\t0\t0\n+4\t9\t9\t4\t12\t0\t0\t0\n+4\t10\t9\t4\t12\t0\t0\t0\n+4\t11\t9\t4\t12\t0\t0\t0\n+4\t12\t9\t4\t12\t0\t0\t0\n+4\t13\t9\t4\t12\t0\t0\t0\n+4\t14\t9\t4\t12\t0\t0\t0\n+4\t15\t9\t4\t12\t0\t0\t0\n+5\t0\t0\t0\t0\t0\t0\t0\n+5\t1\t1\t5\t5\t0\t0\t0\n+5\t2\t2\t5\t6\t0\t0\t0\n+5\t3\t3\t5\t7\t0\t0\t0\n+5\t4\t4\t5\t8\t0\t0\t0\n+5\t5\t5\t5\t9\t0\t0\t0\n+5\t6\t6\t5\t10\t0\t0\t0\n+5\t7\t7\t5\t11\t0\t0\t0\n+5\t8\t8\t5\t12\t0\t0\t0\n+5\t9\t8\t5\t12\t0\t0\t0\n+5\t10\t8\t5\t12\t0\t0\t0\n+5\t11\t8\t5\t12\t0\t0\t0\n+5\t12\t8\t5\t12\t0\t0\t0\n+5\t13\t8\t5\t12\t0\t0\t0\n+5\t14\t8\t5\t12\t0\t0\t0\n+5\t15\t8\t5\t12\t0\t0\t0\n+6\t0\t0\t0\t0\t0\t0\t0\n+6\t1\t1\t6\t6\t0\t0\t0\n+6\t2\t2\t6\t7\t0\t0\t0\n+6\t3\t3\t6\t8\t0\t0\t0\n+6\t4\t4\t6\t9\t0\t0\t0\n+6\t5\t5\t6\t10\t0\t0\t0\n+6\t6\t6\t6\t11\t0\t0\t0\n+6\t7\t7\t6\t12\t0\t0\t0\n+6\t8\t7\t6\t12\t0\t0\t0\n+6\t9\t7\t6\t12\t0\t0\t0\n+6\t10\t7\t6\t12\t0\t0\t0\n+6\t11\t7\t6\t12\t0\t0\t0\n+6\t12\t7\t6\t12\t0\t0\t0\n+6\t13\t7\t6\t12\t0\t0\t0\n+6\t14\t7\t6\t12\t0\t0\t0\n+6\t15\t7\t6\t12\t0\t0\t0\n+7\t0\t0\t0\t0\t0\t0\t0\n+7\t1\t1\t7\t7\t0\t0\t0\n+7\t2\t2\t7\t8\t0\t0\t0\n+7\t3\t3\t7\t9\t0\t0\t0\n+7\t4\t4\t7\t10\t0\t0\t0\n+7\t5\t5\t7\t11\t0\t0\t0\n+7\t6\t6\t7\t12\t0\t0\t0\n+7\t7\t6\t7\t12\t0\t0\t0\n+7\t8\t6\t7\t12\t0\t0\t0\n+7\t9\t6\t7\t12\t0\t0\t0\n+7\t10\t6\t7\t12\t0\t0\t0\n+7\t11\t6\t7\t12\t0\t0\t0\n+7\t12\t6\t7\t12\t0\t0\t0\n+7\t13\t6\t7\t12\t0\t0\t0\n+7\t14\t6\t7\t12\t0\t0\t0\n+7\t15\t6\t7\t12\t0\t0\t0\n+8\t0\t0\t0\t0\t0\t0\t0\n+8\t1\t1\t8\t8\t0\t0\t0\n+8\t2\t2\t8\t9\t0\t0\t0\n+8\t3\t3\t8\t10\t0\t0\t0\n+8\t4\t4\t8\t11\t0\t0\t0\n+8\t5\t5\t8\t12\t0\t0\t0\n+8\t6\t5\t8\t12\t0\t0\t0\n+8\t7\t5\t8\t12\t0\t0\t0\n+8\t8\t5\t8\t12\t0\t0\t0\n+8\t9\t5\t8\t12\t0\t0\t0\n+8\t10\t5\t8\t12\t0\t0\t0\n+8\t11\t5\t8\t12\t0\t0\t0\n+8\t12\t5\t8\t12\t0\t0\t0\n+8\t13\t5\t8\t12\t0\t0\t0\n+8\t14\t5\t8\t12\t0\t0\t0\n+8\t15\t5\t8\t12\t0\t0\t0\n+9\t0\t0\t0\t0\t0\t0\t0\n+9\t1\t1\t9\t9\t0\t0\t0\n+9\t2\t2\t9\t10\t0\t0\t0\n+9\t3\t3\t9\t11\t0\t0\t0\n+9\t4\t4\t9\t12\t0\t0\t0\n+9\t5\t4\t9\t12\t0\t0\t0\n+9\t6\t4\t9\t12\t0\t0\t0\n+9\t7\t4\t9\t12\t0\t0\t0\n+9\t8\t4\t9\t12\t0\t0\t0\n+9\t9\t4\t9\t12\t0\t0\t0\n+9\t10\t4\t9\t12\t0\t0\t0\n+9\t11\t4\t9\t12\t0\t0\t0\n+9\t12\t4\t9\t12\t0\t0\t0\n+9\t13\t4\t9\t12\t0\t0\t0\n+9\t14\t4\t9\t12\t0\t0\t0\n+9\t15\t4\t9\t12\t0\t0\t0\n+10\t0\t0\t0\t0\t0\t0\t0\n+10\t1\t1\t10\t10\t0\t0\t0\n+10\t2\t2\t10\t11\t0\t0\t0\n+10\t3\t3\t10\t12\t0\t0\t0\n+10\t4\t3\t10\t12\t0\t0\t0\n+10\t5\t3\t10\t12\t0\t0\t0\n+10\t6\t3\t10\t12\t0\t0\t0\n+10\t7\t3\t10\t12\t0\t0\t0\n+10\t8\t3\t10\t12\t0\t0\t0\n+10\t9\t3\t10\t12\t0\t0\t0\n+10\t10\t3\t10\t12\t0\t0\t0\n+10\t11\t3\t10\t12\t0\t0\t0\n+10\t12\t3\t10\t12\t0\t0\t0\n+10\t13\t3\t10\t12\t0\t0\t0\n+10\t14\t3\t10\t12\t0\t0\t0\n+10\t15\t3\t10\t12\t0\t0\t0\n+11\t0\t0\t0\t0\t0\t0\t0\n+11\t1\t1\t11\t11\t0\t0\t0\n+11\t2\t2\t11\t12\t0\t0\t0\n+11\t3\t2\t11\t12\t0\t0\t0\n+11\t4\t2\t11\t12\t0\t0\t0\n+11\t5\t2\t11\t12\t0\t0\t0\n+11\t6\t2\t11\t12\t0\t0\t0\n+11\t7\t2\t11\t12\t0\t0\t0\n+11\t8\t2\t11\t12\t0\t0\t0\n+11\t9\t2\t11\t12\t0\t0\t0\n+11\t10\t2\t11\t12\t0\t0\t0\n+11\t11\t2\t11\t12\t0\t0\t0\n+11\t12\t2\t11\t12\t0\t0\t0\n+11\t13\t2\t11\t12\t0\t0\t0\n+11\t14\t2\t11\t12\t0\t0\t0\n+11\t15\t2\t11\t12\t0\t0\t0\n+12\t0\t0\t0\t0\t0\t0\t0\n+12\t1\t1\t12\t12\t0\t0\t0\n+12\t2\t1\t12\t12\t0\t0\t0\n+12\t3\t1\t12\t12\t0\t0\t0\n+12\t4\t1\t12\t12\t0\t0\t0\n+12\t5\t1\t12\t12\t0\t0\t0\n+12\t6\t1\t12\t12\t0\t0\t0\n+12\t7\t1\t12\t12\t0\t0\t0\n+12\t8\t1\t12\t12\t0\t0\t0\n+12\t9\t1\t12\t12\t0\t0\t0\n+12\t10\t1\t12\t12\t0\t0\t0\n+12\t11\t1\t12\t12\t0\t0\t0\n+12\t12\t1\t12\t12\t0\t0\t0\n+12\t13\t1\t12\t12\t0\t0\t0\n+12\t14\t1\t12\t12\t0\t0\t0\n+12\t15\t1\t12\t12\t0\t0\t0\n+13\t0\t0\t0\t0\t0\t0\t0\n+13\t1\t0\t0\t0\t0\t0\t0\n+13\t2\t0\t0\t0\t0\t0\t0\n+13\t3\t0\t0\t0\t0\t0\t0\n+13\t4\t0\t0\t0\t0\t0\t0\n+13\t5\t0\t0\t0\t0\t0\t0\n+13\t6\t0\t0\t0\t0\t0\t0\n+13\t7\t0\t0\t0\t0\t0\t0\n+13\t8\t0\t0\t0\t0\t0\t0\n+13\t9\t0\t0\t0\t0\t0\t0\n+13\t10\t0\t0\t0\t0\t0\t0\n+13\t11\t0\t0\t0\t0\t0\t0\n+13\t12\t0\t0\t0\t0\t0\t0\n+13\t13\t0\t0\t0\t0\t0\t0\n+13\t14\t0\t0\t0\t0\t0\t0\n+13\t15\t0\t0\t0\t0\t0\t0\n+14\t0\t0\t0\t0\t0\t0\t0\n+14\t1\t0\t0\t0\t0\t0\t0\n+14\t2\t0\t0\t0\t0\t0\t0\n+14\t3\t0\t0\t0\t0\t0\t0\n+14\t4\t0\t0\t0\t0\t0\t0\n+14\t5\t0\t0\t0\t0\t0\t0\n+14\t6\t0\t0\t0\t0\t0\t0\n+14\t7\t0\t0\t0\t0\t0\t0\n+14\t8\t0\t0\t0\t0\t0\t0\n+14\t9\t0\t0\t0\t0\t0\t0\n+14\t10\t0\t0\t0\t0\t0\t0\n+14\t11\t0\t0\t0\t0\t0\t0\n+14\t12\t0\t0\t0\t0\t0\t0\n+14\t13\t0\t0\t0\t0\t0\t0\n+14\t14\t0\t0\t0\t0\t0\t0\n+14\t15\t0\t0\t0\t0\t0\t0\n+15\t0\t0\t0\t0\t0\t0\t0\n+15\t1\t0\t0\t0\t0\t0\t0\n+15\t2\t0\t0\t0\t0\t0\t0\n+15\t3\t0\t0\t0\t0\t0\t0\n+15\t4\t0\t0\t0\t0\t0\t0\n+15\t5\t0\t0\t0\t0\t0\t0\n+15\t6\t0\t0\t0\t0\t0\t0\n+15\t7\t0\t0\t0\t0\t0\t0\n+15\t8\t0\t0\t0\t0\t0\t0\n+15\t9\t0\t0\t0\t0\t0\t0\n+15\t10\t0\t0\t0\t0\t0\t0\n+15\t11\t0\t0\t0\t0\t0\t0\n+15\t12\t0\t0\t0\t0\t0\t0\n+15\t13\t0\t0\t0\t0\t0\t0\n+15\t14\t0\t0\t0\t0\t0\t0\n+15\t15\t0\t0\t0\t0\t0\t0\n+0\t0\t0\ndiff --git a/tests/queries/0_stateless/01395_limit_more_cases.sh b/tests/queries/0_stateless/01395_limit_more_cases.sh\nnew file mode 100755\nindex 000000000000..1d96d99a4887\n--- /dev/null\n+++ b/tests/queries/0_stateless/01395_limit_more_cases.sh\n@@ -0,0 +1,35 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+SIZE=13\n+for OFFSET in {0..15}; do\n+    for LIMIT in {0..15}; do\n+        echo \"SELECT\n+            $OFFSET, $LIMIT,\n+            count() AS c, min(number) AS first, max(number) AS last,\n+            throwIf(first != ($OFFSET < $SIZE AND $LIMIT > 0 ? $OFFSET : 0)),\n+            throwIf(last != ($OFFSET < $SIZE AND $LIMIT > 0 ? least($SIZE - 1, $OFFSET + $LIMIT - 1) : 0)),\n+            throwIf((c != 0 OR first != 0 OR last != 0) AND (c != last - first + 1))\n+            FROM (SELECT * FROM numbers($SIZE) LIMIT $OFFSET, $LIMIT);\n+        \"\n+    done\n+done | $CLICKHOUSE_CLIENT -n --max_block_size 5\n+\n+# Randomized test\n+\n+ITERATIONS=1000\n+for i in $(seq $ITERATIONS); do\n+    SIZE=$(($RANDOM % 100))\n+    OFFSET=$(($RANDOM % 111))\n+    LIMIT=$(($RANDOM % 111))\n+\n+    echo \"WITH count() AS c, min(number) AS first, max(number) AS last\n+            SELECT\n+                throwIf(first != ($OFFSET < $SIZE AND $LIMIT > 0 ? $OFFSET : 0)),\n+                throwIf(last != ($OFFSET < $SIZE AND $LIMIT > 0 ? least($SIZE - 1, $OFFSET + $LIMIT - 1) : 0)),\n+                throwIf((c != 0 OR first != 0 OR last != 0) AND (c != last - first + 1))\n+            FROM (SELECT * FROM numbers($SIZE) LIMIT $OFFSET, $LIMIT);\n+        \"\n+done | $CLICKHOUSE_CLIENT -n --max_block_size $(($RANDOM % 20)) | uniq\n",
  "problem_statement": "LimitTransform::makeChunkWithPreviousRow(): Assertion `row < chunk.getNumRows()' failed.\n```\r\nSELECT number FROM numbers(100) ORDER BY number ASC LIMIT 2, 9223372036854775807  WITH TIES\r\n```\r\n\r\n@KochetovNicolai The query is similar to https://github.com/ClickHouse/ClickHouse/issues/11359, but the error is different. \nLIMIT n OFFSET m doesn't return rows if n is too large\n**Describe the bug**\r\nWhen we use the clause LIMIT n OFFSET m with a large value using \r\n\r\n**How to reproduce**\r\nI was able to reproduce the bug on `20.3.5` clickhouse server version. (I was able to reproduce on `20.3.7` too)\r\n\r\n```\r\nCREATE TABLE a (a UInt32) Engine = Memory;\r\n\r\nINSERT INTO TABLE a SELECT number FROM system.numbers LIMIT 100000000;\r\n\r\nSELECT a\r\nFROM a\r\nGROUP BY a\r\nORDER BY a ASC\r\nLIMIT 5, 18446744073709551615;\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 11.183 sec. Processed 100.00 million rows, 400.00 MB (8.94 million rows/s., 35.77 MB/s.) \r\n```\r\n\r\nWhile if we use a smallest value for CH, it will return records.\r\n\r\n```\r\nSELECT a\r\nFROM a\r\nGROUP BY a\r\nORDER BY a ASC\r\nLIMIT 5, 184467468;\r\n\r\n[a really long list of rows]\r\n\r\n```\r\n\r\n**Expected behavior**\r\nIt should return the requested rows, or an error if the value is too large\r\n\r\n**Additional context**\r\n\r\nIt seems the query works perfectly without an offset clause.\n",
  "hints_text": "This case is integer overflow, because `SELECT number FROM numbers(100) ORDER BY number ASC LIMIT 2, 100000000  WITH TIES` works fine.\r\nDon't know how to fix it properly.\n> This case is integer overflow, because `SELECT number FROM numbers(100) ORDER BY number ASC LIMIT 2, 100000000 WITH TIES` works fine.\r\n> Don't know how to fix it properly.\r\n\r\nIs there some place where signed int is used for row number? Maybe if we convert it all to UInt64, it will work? And if we have some other kind of literal for LIMIT, we should report an error (we probably do so already).\n> Is there some place where signed int is used for row number?\r\n\r\nYes. It is not so easy for fix.\r\nhttps://github.com/ClickHouse/ClickHouse/blob/06446b4f08a142d6f1bc30664c47ded88ab51782/src/Processors/LimitTransform.cpp#L283-L286\n> > Is there some place where signed int is used for row number?\r\n> \r\n> Yes. It is not so easy for fix.\r\n> https://github.com/ClickHouse/ClickHouse/blob/06446b4f08a142d6f1bc30664c47ded88ab51782/src/Processors/LimitTransform.cpp#L283-L286\r\n\r\nIt should be possible to calculate absolute row numbers for chunk start and chunk end, and then compare these numbers to offset and limit. They all fit UInt64, so it must work. It also will be easier to read -- now I'm not even sure the calculations are correct (they must be correct, but it's not immediately clear from the code). In cases like these, when there is a lot of conditions, it can be helpful to make a decision table and then just write it down as code: https://www.hillelwayne.com/post/decision-tables/\r\nIt's easy to miss something when the conditions are not explicit and embedded into a chain of min's.\n@KochetovNicolai Signed integer overflow will be also reported by UBSan. We should fix it.\nDuplicate of #10470\nWith more investigation, it seems we have a limit, who is `2^63  - offset_size_clause`",
  "created_at": "2020-07-12T05:19:45Z"
}