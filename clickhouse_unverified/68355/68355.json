{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 68355,
  "instance_id": "ClickHouse__ClickHouse-68355",
  "issue_numbers": [
    "69555",
    "65762"
  ],
  "base_commit": "72f6af4fa11efb0b5bcc4c48be13e430588b12ba",
  "patch": "diff --git a/src/Access/LDAPAccessStorage.cpp b/src/Access/LDAPAccessStorage.cpp\nindex 3206b20b691b..96bd505e104f 100644\n--- a/src/Access/LDAPAccessStorage.cpp\n+++ b/src/Access/LDAPAccessStorage.cpp\n@@ -191,8 +191,8 @@ void LDAPAccessStorage::applyRoleChangeNoLock(bool grant, const UUID & role_id,\n     }\n     else\n     {\n-        granted_role_names.erase(role_id);\n         granted_role_ids.erase(role_name);\n+        granted_role_names.erase(role_id);\n     }\n }\n \n",
  "test_patch": "diff --git a/tests/integration/helpers/cluster.py b/tests/integration/helpers/cluster.py\nindex 821bb887435c..b8953346e238 100644\n--- a/tests/integration/helpers/cluster.py\n+++ b/tests/integration/helpers/cluster.py\n@@ -4716,6 +4716,9 @@ def write_embedded_config(name, dest_dir, fix_log_level=False):\n         if self.with_kerberized_hdfs:\n             depends_on.append(\"kerberizedhdfs1\")\n \n+        if self.with_ldap:\n+            depends_on.append(\"openldap\")\n+\n         if self.with_rabbitmq:\n             depends_on.append(\"rabbitmq1\")\n \ndiff --git a/tests/integration/test_ldap_external_user_directory/test.py b/tests/integration/test_ldap_external_user_directory/test.py\nindex 39753794d633..277a17eed7bb 100644\n--- a/tests/integration/test_ldap_external_user_directory/test.py\n+++ b/tests/integration/test_ldap_external_user_directory/test.py\n@@ -48,9 +48,32 @@ def add_ldap_group(ldap_cluster, group_cn, member_cn):\n     assert code == 0\n \n \n+def delete_ldap_group(ldap_cluster, group_cn):\n+    code, (stdout, stderr) = ldap_cluster.ldap_container.exec_run(\n+        [\n+            \"sh\",\n+            \"-c\",\n+            \"\"\"ldapdelete -r 'cn={group_cn},dc=example,dc=org' \\\n+-H ldap://{host}:{port} -D \"{admin_bind_dn}\" -x -w {admin_password}\n+            \"\"\".format(\n+                host=ldap_cluster.ldap_host,\n+                port=ldap_cluster.ldap_port,\n+                admin_bind_dn=LDAP_ADMIN_BIND_DN,\n+                admin_password=LDAP_ADMIN_PASSWORD,\n+                group_cn=group_cn,\n+            ),\n+        ],\n+        demux=True,\n+    )\n+    logging.debug(\n+        f\"test_ldap_external_user_directory code:{code} stdout:{stdout}, stderr:{stderr}\"\n+    )\n+    assert code == 0\n+\n+\n def test_authentication_pass():\n     assert instance.query(\n-        \"select currentUser()\", user=\"janedoe\", password=\"qwerty\"\n+        \"SELECT currentUser()\", user=\"janedoe\", password=\"qwerty\"\n     ) == TSV([[\"janedoe\"]])\n \n \n@@ -67,6 +90,9 @@ def test_authentication_fail():\n \n \n def test_role_mapping(ldap_cluster):\n+    instance.query(\"DROP ROLE IF EXISTS role_1\")\n+    instance.query(\"DROP ROLE IF EXISTS role_2\")\n+    instance.query(\"DROP ROLE IF EXISTS role_3\")\n     instance.query(\"CREATE ROLE role_1\")\n     instance.query(\"CREATE ROLE role_2\")\n     add_ldap_group(ldap_cluster, group_cn=\"clickhouse-role_1\", member_cn=\"johndoe\")\n@@ -93,3 +119,12 @@ def test_role_mapping(ldap_cluster):\n         user=\"johndoe\",\n         password=\"qwertz\",\n     ) == TSV([[\"role_1\"], [\"role_2\"], [\"role_3\"]])\n+\n+    instance.query(\"DROP ROLE role_1\")\n+    instance.query(\"DROP ROLE role_2\")\n+    instance.query(\"DROP ROLE role_3\")\n+\n+    delete_ldap_group(ldap_cluster, group_cn=\"clickhouse-role_1\")\n+    delete_ldap_group(ldap_cluster, group_cn=\"clickhouse-role_2\")\n+    delete_ldap_group(ldap_cluster, group_cn=\"clickhouse-role_3\")\n+    delete_ldap_group(ldap_cluster, group_cn=\"clickhouse-role_4\")\n",
  "problem_statement": "Crash with ldap on 24.8.4.13 (current latest)\nTrace:\r\n```\r\n2024.09.12 12:31:23.295053 [ 14406 ] {b60cfd44-8c83-497e-ba38-1c479869cd82} <Fatal> GWPAsan: *** GWP-ASan detected a memory error ***\r\n2024.09.12 12:31:23.295358 [ 14406 ] {b60cfd44-8c83-497e-ba38-1c479869cd82} <Fatal> GWPAsan: Use After Free (warning: buffer overflow/underflow detected on a free()'d allocation. This either means you have a buffer-overflow and a use-after-free at the same time, or you have a long-lived use-after-free bug where the allocation/deallocation metadata below has already been overwritten and is likely bogus) at 0x281473304510535 (71 bytes to the right of a 72-byte allocation at 0x281473304510464) by thread 14406 here:\r\n2024.09.12 12:31:23.295626 [ 14406 ] {b60cfd44-8c83-497e-ba38-1c479869cd82} <Fatal> GWPAsan: 0x281473304510535 was deallocated by thread 14406 here:\r\n2024.09.12 12:31:23.295815 [ 14406 ] {b60cfd44-8c83-497e-ba38-1c479869cd82} <Fatal> GWPAsan: <Empty trace>\r\n2024.09.12 12:31:23.295988 [ 14406 ] {b60cfd44-8c83-497e-ba38-1c479869cd82} <Fatal> GWPAsan: 0x281473304510535 was allocated by thread 14406 here:\r\n2024.09.12 12:31:23.296159 [ 14406 ] {b60cfd44-8c83-497e-ba38-1c479869cd82} <Fatal> GWPAsan: <Empty trace>\r\n2024.09.12 12:31:23.296370 [ 14406 ] {b60cfd44-8c83-497e-ba38-1c479869cd82} <Fatal> GWPAsan: *** End GWP-ASan report ***\r\n2024.09.12 12:31:23.297268 [ 15136 ] {} <Fatal> BaseDaemon: ########## Short fault info ############\r\n2024.09.12 12:31:23.297588 [ 15136 ] {} <Fatal> BaseDaemon: (version 24.8.4.13 (official build), build id: 7A2B16FBACA77EB7D47F452AE6FCC7216C28FDE1, git hash: 53195bc189b587afaabc52c4ca765aa54beea84f) (from thread 14406) Received signal 11\r\n2024.09.12 12:31:23.297904 [ 15136 ] {} <Fatal> BaseDaemon: Signal description: Segmentation fault\r\n2024.09.12 12:31:23.298128 [ 15136 ] {} <Fatal> BaseDaemon: Address: 0xffff9c544047. Access: . Attempted access has violated the permissions assigned to the memory area.\r\n2024.09.12 12:31:23.298311 [ 15136 ] {} <Fatal> BaseDaemon: Stack trace: 0x000000000c558228 0x0000ffff9dffb7dc 0x000000000ee226a1 0x000000000ee1dbac 0x000000000ee21b78 0x000000000eda3fa8 0x000000000ed95bc4 0x000000000edff1e4 0x000000000ff172c8 0x000000000ff16c98 0x000000000fd8a6a0 0x000000000fd86a08 0x0000000010caef0c 0x0000000010cc5588 0x000000001344be98 0x000000001344c374 0x00000000134173b4 0x00000000134157f0 0x0000ffff9df89624 0x0000ffff9dee062c\r\n2024.09.12 12:31:23.298477 [ 15136 ] {} <Fatal> BaseDaemon: ########################################\r\n2024.09.12 12:31:23.298812 [ 15136 ] {} <Fatal> BaseDaemon: (version 24.8.4.13 (official build), build id: 7A2B16FBACA77EB7D47F452AE6FCC7216C28FDE1, git hash: 53195bc189b587afaabc52c4ca765aa54beea84f) (from thread 14406) (query_id: b60cfd44-8c83-497e-ba38-1c479869cd82) (query: DROP ROLE IF EXISTS role_c09ae1cc_70e9_11ef_88aa_6975d6534d58_unknown\r\n) Received signal Segmentation fault (11)\r\n2024.09.12 12:31:23.299220 [ 15136 ] {} <Fatal> BaseDaemon: Address: 0xffff9c544047. Access: . Attempted access has violated the permissions assigned to the memory area.\r\n2024.09.12 12:31:23.299504 [ 15136 ] {} <Fatal> BaseDaemon: Stack trace: 0x000000000c558228 0x0000ffff9dffb7dc 0x000000000ee226a1 0x000000000ee1dbac 0x000000000ee21b78 0x000000000eda3fa8 0x000000000ed95bc4 0x000000000edff1e4 0x000000000ff172c8 0x000000000ff16c98 0x000000000fd8a6a0 0x000000000fd86a08 0x0000000010caef0c 0x0000000010cc5588 0x000000001344be98 0x000000001344c374 0x00000000134173b4 0x00000000134157f0 0x0000ffff9df89624 0x0000ffff9dee062c\r\n2024.09.12 12:31:23.300171 [ 15136 ] {} <Fatal> BaseDaemon: 0. signalHandler(int, siginfo_t*, void*) @ 0x000000000c558228\r\n2024.09.12 12:31:23.300411 [ 15136 ] {} <Fatal> BaseDaemon: 1. ? @ 0x0000ffff9dffb7dc\r\n2024.09.12 12:31:23.300696 [ 15136 ] {} <Fatal> BaseDaemon: 2. std::__tree_iterator<std::__value_type<String, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>>, std::__tree_node<std::__value_type<String, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>>, void*>*, long> std::__tree<std::__value_type<String, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>>, std::__map_value_compare<String, std::__value_type<String, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>>, std::less<String>, true>, std::allocator<std::__value_type<String, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>>>>::find<String>(String const&) @ 0x000000000ee226a1\r\n2024.09.12 12:31:23.301036 [ 15136 ] {} <Fatal> BaseDaemon: 3. DB::LDAPAccessStorage::applyRoleChangeNoLock(bool, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, String const&) @ 0x000000000ee1dbac\r\n2024.09.12 12:31:23.301585 [ 15136 ] {} <Fatal> BaseDaemon: 4. void std::__function::__policy_invoker<void (StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::shared_ptr<DB::IAccessEntity const> const&)>::__call_impl<std::__function::__default_alloc_func<DB::LDAPAccessStorage::setConfiguration(Poco::Util::AbstractConfiguration const&, String const&)::$_0, void (StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::shared_ptr<DB::IAccessEntity const> const&)>>(std::__function::__policy_storage const*, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::shared_ptr<DB::IAccessEntity const> const&) @ 0x000000000ee21b78\r\n2024.09.12 12:31:23.301863 [ 15136 ] {} <Fatal> BaseDaemon: 5. DB::AccessChangesNotifier::sendNotifications() @ 0x000000000eda3fa8\r\n2024.09.12 12:31:23.302085 [ 15136 ] {} <Fatal> BaseDaemon: 6. DB::AccessControl::removeImpl(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, bool) @ 0x000000000ed95bc4\r\n2024.09.12 12:31:23.302361 [ 15136 ] {} <Fatal> BaseDaemon: 7. DB::IAccessStorage::remove(std::vector<StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>, std::allocator<StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>>> const&, bool) @ 0x000000000edff1e4\r\n2024.09.12 12:31:23.302665 [ 15136 ] {} <Fatal> BaseDaemon: 8. DB::InterpreterDropAccessEntityQuery::execute()::$_0::operator()(std::vector<String, std::allocator<String>> const&, String const&) const @ 0x000000000ff172c8\r\n2024.09.12 12:31:23.303040 [ 15136 ] {} <Fatal> BaseDaemon: 9. DB::InterpreterDropAccessEntityQuery::execute() @ 0x000000000ff16c98\r\n2024.09.12 12:31:23.303357 [ 15136 ] {} <Fatal> BaseDaemon: 10. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*) @ 0x000000000fd8a6a0\r\n2024.09.12 12:31:23.303652 [ 15136 ] {} <Fatal> BaseDaemon: 11. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x000000000fd86a08\r\n2024.09.12 12:31:23.304005 [ 15136 ] {} <Fatal> BaseDaemon: 12. DB::TCPHandler::runImpl() @ 0x0000000010caef0c\r\n2024.09.12 12:31:23.304282 [ 15136 ] {} <Fatal> BaseDaemon: 13. DB::TCPHandler::run() @ 0x0000000010cc5588\r\n2024.09.12 12:31:23.304535 [ 15136 ] {} <Fatal> BaseDaemon: 14. Poco::Net::TCPServerConnection::start() @ 0x000000001344be98\r\n2024.09.12 12:31:23.304793 [ 15136 ] {} <Fatal> BaseDaemon: 15. Poco::Net::TCPServerDispatcher::run() @ 0x000000001344c374\r\n2024.09.12 12:31:23.304974 [ 15136 ] {} <Fatal> BaseDaemon: 16. Poco::PooledThread::run() @ 0x00000000134173b4\r\n2024.09.12 12:31:23.305156 [ 15136 ] {} <Fatal> BaseDaemon: 17. Poco::ThreadImpl::runnableEntry(void*) @ 0x00000000134157f0\r\n2024.09.12 12:31:23.305486 [ 15136 ] {} <Fatal> BaseDaemon: 18. start_thread @ 0x0000000000007624\r\n2024.09.12 12:31:23.305919 [ 15136 ] {} <Fatal> BaseDaemon: 19. ? @ 0x00000000000d162c\r\n2024.09.12 12:31:23.306105 [ 15136 ] {} <Fatal> BaseDaemon: Integrity check of the executable skipped because the reference checksum could not be read.\r\n2024.09.12 12:31:23.306652 [ 15136 ] {} <Fatal> BaseDaemon: Report this error to https://github.com/ClickHouse/ClickHouse/issues\r\n2024.09.12 12:31:23.307002 [ 15136 ] {} <Fatal> BaseDaemon: Changed settings: use_uncompressed_cache = false, load_balancing = 'random', max_memory_usage = 10000000000\r\n```\nTests `test_ldap_external_user_directory` occasionally flaky\nIntegration tests `test_ldap_external_user_directory` are [flaky](https://play.clickhouse.com/play?user=play#c2VsZWN0IHB1bGxfcmVxdWVzdF9udW1iZXIgYXMgcHIsIGNoZWNrX3N0YXJ0X3RpbWUsIGNoZWNrX25hbWUsIHRlc3RfbmFtZSwgdGVzdF9zdGF0dXMgYXMgc3RhdHVzLCByZXBvcnRfdXJsCmZyb20gY2hlY2tzCndoZXJlIHRvRGF0ZShjaGVja19zdGFydF90aW1lKSA+ICcyMDIzLTA3LTI4JyBhbmQgdGVzdF9uYW1lIGxpa2UgJyV0ZXN0X2xkYXBfZXh0ZXJuYWxfdXNlcl9kaXJlY3RvcnklJyBhbmQgc3RhdHVzIGluICgnRkFJTCcsICdFUlJPUicsICdGTEFLWScpCm9yZGVyIGJ5IGNoZWNrX3N0YXJ0X3RpbWUgZGVzYw==)\r\n\r\nExample [report](https://s3.amazonaws.com/clickhouse-test-reports/63206/bf93c3807014f4323960afb953565a48e3c26109/integration_tests__aarch64__[4_6].html)\r\n\r\nIt is interesting that it has not failed for months, and now it only fails in aarch64.\r\n\r\n```\r\n=================================== FAILURES ===================================\r\n___________________________ test_authentication_pass ___________________________\r\n[gw3] linux -- Python 3.10.12 /usr/bin/python3\r\n\r\n    def test_authentication_pass():\r\n>       assert instance.query(\r\n            \"select currentUser()\", user=\"janedoe\", password=\"qwerty\"\r\n        ) == TSV([[\"janedoe\"]])\r\n\r\ntest_ldap_external_user_directory/test.py:52: \r\n\r\n.........................................................................\r\n.........................................................................\r\n\r\nE           helpers.client.QueryRuntimeException: Client failed! Return code: 4, stderr: Code: 516. DB::Exception: Received from 172.16.9.3:9000. DB::Exception: janedoe: Authentication failed: password is incorrect, or there is no user with such name.. Stack trace:\r\nE           \r\nE           0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000c343e08\r\nE           1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000007b9f21c\r\nE           2. DB::AccessControl::authenticate(DB::Credentials const&, Poco::Net::IPAddress const&, String const&) const @ 0x000000000f10cce4\r\nE           3. DB::Session::authenticate(DB::Credentials const&, Poco::Net::SocketAddress const&) @ 0x000000001024ff20\r\nE           4. DB::TCPHandler::receiveHello() @ 0x00000000112643b4\r\nE           5. DB::TCPHandler::runImpl() @ 0x000000001125ab4c\r\nE           6. DB::TCPHandler::run() @ 0x0000000011273048\r\nE           7. Poco::Net::TCPServerConnection::start() @ 0x00000000135ae698\r\nE           8. Poco::Net::TCPServerDispatcher::run() @ 0x00000000135aeb74\r\nE           9. Poco::PooledThread::run() @ 0x0000000013579574\r\nE           10. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000013577950\r\nE           11. ? @ 0x000000000007d5c8\r\nE           12. ? @ 0x00000000000e5edc\r\nE           . (AUTHENTICATION_FAILED)\r\n\r\nhelpers/client.py:239: QueryRuntimeException\r\n------------------------------ Captured log call -------------------------------\r\n2024-06-26 04:06:01 [ 517 ] DEBUG : Executing query select currentUser() on instance (cluster.py:3449, query)\r\n```\n",
  "hints_text": "\n@alexey-milovidov let's keep the further discussion (or investigation) of this issue here.  \r\nMe or my colleagues will try to fix this\n@zvonand, it didn't help, and it prevents @AVMusorin to merge his PR: https://github.com/ClickHouse/ClickHouse/pull/66457\r\n\r\nhttps://s3.amazonaws.com/clickhouse-test-reports/66457/0d2459f0de566dfa13eecf3bd176e59ec11e0239/integration_tests__aarch64__[4_6].html\nHmm, looks like the reason is the same: CH makes a query to LDAP at `2024.07.22 23:54:21.786576`, but LDAP setup is finished at `23:54:21.85`, and slapd is started at `23:54:21.89`\r\n\r\nLooking into it, probably we still need a better healthcheck\nIt failed!!!",
  "created_at": "2024-08-14T15:22:09Z",
  "modified_files": [
    "src/Access/LDAPAccessStorage.cpp"
  ],
  "modified_test_files": [
    "tests/integration/helpers/cluster.py",
    "tests/integration/test_ldap_external_user_directory/test.py"
  ]
}