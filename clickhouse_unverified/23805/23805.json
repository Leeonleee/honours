{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 23805,
  "instance_id": "ClickHouse__ClickHouse-23805",
  "issue_numbers": [
    "23431"
  ],
  "base_commit": "4bb56849b37c625d4810e8ccbc5b7e1b55858088",
  "patch": "diff --git a/src/Client/Connection.cpp b/src/Client/Connection.cpp\nindex 70d8109545bd..d26f7454bccf 100644\n--- a/src/Client/Connection.cpp\n+++ b/src/Client/Connection.cpp\n@@ -680,8 +680,12 @@ void Connection::sendExternalTablesData(ExternalTablesData & data)\n         PipelineExecutorPtr executor;\n         auto on_cancel = [& executor]() { executor->cancel(); };\n \n+        if (!elem->pipe)\n+            elem->pipe = elem->creating_pipe_callback();\n+\n         QueryPipeline pipeline;\n         pipeline.init(std::move(*elem->pipe));\n+        elem->pipe.reset();\n         pipeline.resize(1);\n         auto sink = std::make_shared<ExternalTableDataSink>(pipeline.getHeader(), *this, *elem, std::move(on_cancel));\n         pipeline.setSinks([&](const Block &, QueryPipeline::StreamType type) -> ProcessorPtr\ndiff --git a/src/Client/Connection.h b/src/Client/Connection.h\nindex 6c7edfb2761d..80dbd9ed44e5 100644\n--- a/src/Client/Connection.h\n+++ b/src/Client/Connection.h\n@@ -41,6 +41,7 @@ struct ExternalTableData\n     /// Pipe of data form table;\n     std::unique_ptr<Pipe> pipe;\n     std::string table_name;\n+    std::function<std::unique_ptr<Pipe>()> creating_pipe_callback;\n     /// Flag if need to stop reading.\n     std::atomic_bool is_cancelled = false;\n };\ndiff --git a/src/DataStreams/RemoteQueryExecutor.cpp b/src/DataStreams/RemoteQueryExecutor.cpp\nindex 0961dd41458f..f15e54d34c6a 100644\n--- a/src/DataStreams/RemoteQueryExecutor.cpp\n+++ b/src/DataStreams/RemoteQueryExecutor.cpp\n@@ -458,8 +458,6 @@ void RemoteQueryExecutor::sendScalars()\n \n void RemoteQueryExecutor::sendExternalTables()\n {\n-    SelectQueryInfo query_info;\n-\n     size_t count = connections->size();\n \n     {\n@@ -474,24 +472,29 @@ void RemoteQueryExecutor::sendExternalTables()\n             for (const auto & table : external_tables)\n             {\n                 StoragePtr cur = table.second;\n-                auto metadata_snapshot = cur->getInMemoryMetadataPtr();\n-                QueryProcessingStage::Enum read_from_table_stage = cur->getQueryProcessingStage(\n-                    context, QueryProcessingStage::Complete, query_info);\n-\n-                Pipe pipe = cur->read(\n-                    metadata_snapshot->getColumns().getNamesOfPhysical(),\n-                    metadata_snapshot, query_info, context,\n-                    read_from_table_stage, DEFAULT_BLOCK_SIZE, 1);\n \n                 auto data = std::make_unique<ExternalTableData>();\n                 data->table_name = table.first;\n-\n-                if (pipe.empty())\n-                    data->pipe = std::make_unique<Pipe>(\n+                data->creating_pipe_callback = [cur, context = this->context]()\n+                {\n+                    SelectQueryInfo query_info;\n+                    auto metadata_snapshot = cur->getInMemoryMetadataPtr();\n+                    QueryProcessingStage::Enum read_from_table_stage = cur->getQueryProcessingStage(\n+                        context, QueryProcessingStage::Complete, query_info);\n+\n+                    Pipe pipe = cur->read(\n+                        metadata_snapshot->getColumns().getNamesOfPhysical(),\n+                        metadata_snapshot, query_info, context,\n+                        read_from_table_stage, DEFAULT_BLOCK_SIZE, 1);\n+\n+                    if (pipe.empty())\n+                        return std::make_unique<Pipe>(\n                             std::make_shared<SourceFromSingleChunk>(metadata_snapshot->getSampleBlock(), Chunk()));\n-                else\n-                    data->pipe = std::make_unique<Pipe>(std::move(pipe));\n \n+                    return std::make_unique<Pipe>(std::move(pipe));\n+                };\n+\n+                data->pipe = data->creating_pipe_callback();\n                 res.emplace_back(std::move(data));\n             }\n             external_tables_data.push_back(std::move(res));\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01851_hedged_connections_external_tables.reference b/tests/queries/0_stateless/01851_hedged_connections_external_tables.reference\nnew file mode 100644\nindex 000000000000..573541ac9702\n--- /dev/null\n+++ b/tests/queries/0_stateless/01851_hedged_connections_external_tables.reference\n@@ -0,0 +1,1 @@\n+0\ndiff --git a/tests/queries/0_stateless/01851_hedged_connections_external_tables.sql b/tests/queries/0_stateless/01851_hedged_connections_external_tables.sql\nnew file mode 100644\nindex 000000000000..c4625720e598\n--- /dev/null\n+++ b/tests/queries/0_stateless/01851_hedged_connections_external_tables.sql\n@@ -0,0 +1,1 @@\n+select number from remote('127.0.0.{3|2}', numbers(2)) where number global in (select number from numbers(1))\u3000settings async_socket_for_remote=1, use_hedged_requests = 1, sleep_in_send_data_ms=10, receive_data_timeout_ms=1;\n",
  "problem_statement": "Logical error: Can't initialize pipeline with empty pipe.: While executing Remote (version 21.4.4.30 (official build))\n CREATE TABLE ladnl.dnl_log\r\n(\r\n    `event_date` Date,\r\n    `date_id` UInt64,\r\n    `tm` FixedString(8),\r\n    `dt` DateTime DEFAULT toDateTime(concat(toString(event_date), ' ', tm)),\r\n    `host_id` UInt32,\r\n    `ip` Int32,\r\n    `cc` FixedString(2),\r\n    `code` UInt16,\r\n    `topdir` String,\r\n    `file` String,\r\n    `size` UInt32,\r\n    `flag` String,\r\n    `uagent` String,\r\n    `ok` UInt8,\r\n    `appid` UInt16,\r\n    `ver` UInt16 DEFAULT CAST(0, 'UInt16'),\r\n    `ltype` UInt16 DEFAULT CAST(0, 'UInt16'),\r\n    `keynum` Int16 DEFAULT CAST(0, 'Int16'),\r\n    `md5` String,\r\n    `serial` String,\r\n    `pkid` UInt32,\r\n    `pk_member` UInt16,\r\n    `pk_product` UInt32,\r\n    `cids` String,\r\n    `sid` UInt16,\r\n    `build` String,\r\n    `sku` String,\r\n    `iscommercial` UInt8,\r\n    `istrial` UInt8,\r\n    `isbeta` UInt8,\r\n    `iscorporate` UInt8,\r\n    `blocked` UInt8,\r\n    `expdate` Date,\r\n    `pcode` UInt16,\r\n    `ssl` UInt8 DEFAULT 0,\r\n    `ssl_reuse` UInt8 DEFAULT 0,\r\n    `ip_num` String DEFAULT IPv4NumToString(toUInt32(ip)),\r\n    `rport` UInt16 DEFAULT CAST(0, 'UInt16'),\r\n    `tcp` String,\r\n    `base` String,\r\n    `comp` String\r\n)\r\nENGINE = Distributed(dnl2019, 'ladnl', 'dnl_log_local', rand())\r\n\r\n\r\nSELECT count(),sum(vol) FROM (SELECT count() as cnt,sum(size) as vol FROM ladnl.dnl_log WHERE event_date='2021-04-20' and serial global in (select md5 FROM ladnl.dnl_log WHERE event_date='2021-04-20' AND host_id=191 AND appid=2143 AND keynum>0 group by md5) group by serial HAVING count()=73)\r\n\r\n2021.04.21 05:07:53.641943 [ 586494 ] {04d19dd0-692d-4dab-ab46-ac75cdc87eb8} <Error> DynamicQueryHandler: Code: 49, e.displayText() = DB::Exception: Can't initialize pipeline with empty pipe.: While executing Remote, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8914f0a in /usr/bin/clickhouse\r\n1. DB::QueryPipeline::init(DB::Pipe) @ 0x101b03f1 in /usr/bin/clickhouse\r\n2. DB::Connection::sendExternalTablesData(std::__1::vector<std::__1::unique_ptr<DB::ExternalTableData, std::__1::default_delete<DB::ExternalTableData> >, std::__1::allocator<std::__1::unique_ptr<DB::ExternalTableData, std::__1::default_delete<DB::ExternalTableData> > > >&) @ 0x1008c5db in /usr/bin/clickhouse\r\n3. DB::HedgedConnections::processNewReplicaState(DB::HedgedConnectionsFactory::State, DB::Connection*) @ 0x100a3f89 in /usr/bin/clickhouse\r\n4. DB::HedgedConnections::getReadyReplicaLocation(std::__1::function<void (int, Poco::Timespan const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>) @ 0x100a243f in /usr/bin/clickhouse\r\n5. DB::HedgedConnections::receivePacketUnlocked(std::__1::function<void (int, Poco::Timespan const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>) @ 0x100a323e in /usr/bin/clickhouse\r\n6. DB::RemoteQueryExecutorRoutine::operator()(boost::context::fiber&&) const @ 0xf11cb52 in /usr/bin/clickhouse\r\n7. void boost::context::detail::fiber_entry<boost::context::detail::fiber_record<boost::context::fiber, FiberStack&, DB::RemoteQueryExecutorRoutine> >(boost::context::detail::transfer_t) @ 0xf11ca2e in /usr/bin/clickhouse\r\n (version 21.4.4.30 (official build))\r\n\r\n\r\n\n",
  "hints_text": "The same issue with 21.3.6.55 when using GLOBAL IN/JOIN\n```\r\nselect number from remote('127.0.0.{3|2}', numbers(2)) where number global in (select number from numbers(1))\u3000settings async_socket_for_remote=1, use_hedged_requests = 1, sleep_in_send_data_ms=10, receive_data_timeout_ms=1;\r\n\r\nSELECT number\r\nFROM remote('127.0.0.{3|2}', numbers(2))\r\nWHERE number GLOBAL IN \r\n(\r\n    SELECT number\r\n    FROM numbers(1)\r\n)\r\nSETTINGS async_socket_for_remote = 1, use_hedged_requests = 1, sleep_in_send_data_ms = 10, receive_data_timeout_ms = 1\r\n\r\nQuery id: 6999b40e-9641-4646-b923-07cc12f9e6f4\r\n\r\n\r\n0 rows in set. Elapsed: 0.033 sec. \r\n\r\nReceived exception from server (version 21.4.4):\r\nCode: 49. DB::Exception: Received from localhost:9000. DB::Exception: Can't initialize pipeline with empty pipe.: While executing Remote. \r\n\r\n```\r\n\r\n```\r\n2021.04.30 16:59:51.571920 [ 11965 ] {6999b40e-9641-4646-b923-07cc12f9e6f4} <Error> executeQuery: Code: 49, e.displayText() = DB::Exception: Can't initialize pipeline with empty pipe.: While executing Remote (version 21.4.4.30 (official build)) (from [::1]:44122) (in query: select number from remote('127.0.0.{3|2}', numbers(2)) where number global in (select number from numbers(1)) settings async_socket_for_remote=1, use_hedged_requests = 1, sleep_in_send_data_ms=10, receive_data_timeout_ms=1;), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8914f0a in /home/nik-kochetov/test/21.4.4.30/usr/bin/clickhouse\r\n1. DB::QueryPipeline::init(DB::Pipe) @ 0x101b03f1 in /home/nik-kochetov/test/21.4.4.30/usr/bin/clickhouse\r\n2. DB::Connection::sendExternalTablesData(std::__1::vector<std::__1::unique_ptr<DB::ExternalTableData, std::__1::default_delete<DB::ExternalTableData> >, std::__1::allocator<std::__1::unique_ptr<DB::ExternalTableData, std::__1::default_delete<DB::ExternalTableData> > > >&) @ 0x1008c5db in /home/nik-kochetov/test/21.4.4.30/usr/bin/clickhouse\r\n3. DB::HedgedConnections::processNewReplicaState(DB::HedgedConnectionsFactory::State, DB::Connection*) @ 0x100a3f89 in /home/nik-kochetov/test/21.4.4.30/usr/bin/clickhouse\r\n4. DB::HedgedConnections::getReadyReplicaLocation(std::__1::function<void (int, Poco::Timespan const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>) @ 0x100a243f in /home/nik-kochetov/test/21.4.4.30/usr/bin/clickhouse\r\n5. DB::HedgedConnections::receivePacketUnlocked(std::__1::function<void (int, Poco::Timespan const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>) @ 0x100a323e in /home/nik-kochetov/test/21.4.4.30/usr/bin/clickhouse\r\n6. DB::RemoteQueryExecutorRoutine::operator()(boost::context::fiber&&) const @ 0xf11cb52 in /home/nik-kochetov/test/21.4.4.30/usr/bin/clickhouse\r\n7. void boost::context::detail::fiber_entry<boost::context::detail::fiber_record<boost::context::fiber, FiberStack&, DB::RemoteQueryExecutorRoutine> >(boost::context::detail::transfer_t) @ 0xf11ca2e in /home/nik-kochetov/test/21.4.4.30/usr/bin/clickhouse\r\n\r\n```\r\n\r\n@Avogar \r\n\r\nIt is because we resend external tables again for other replica. `ExternalTableData` happened to be not reusable.\r\n",
  "created_at": "2021-04-30T14:21:44Z",
  "modified_files": [
    "src/Client/Connection.cpp",
    "src/Client/Connection.h",
    "src/DataStreams/RemoteQueryExecutor.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/01851_hedged_connections_external_tables.reference",
    "b/tests/queries/0_stateless/01851_hedged_connections_external_tables.sql"
  ]
}