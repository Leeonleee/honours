diff --git a/tests/integration/test_attach_without_fetching/test.py b/tests/integration/test_attach_without_fetching/test.py
index 605ca6a4f51e..874f5b36ddc7 100644
--- a/tests/integration/test_attach_without_fetching/test.py
+++ b/tests/integration/test_attach_without_fetching/test.py
@@ -16,11 +16,10 @@ def fill_node(node):
     '''.format(replica=node.name))
 
 cluster = ClickHouseCluster(__file__)
-configs =["configs/remote_servers.xml"]
 
-node_1 = cluster.add_instance('replica1', with_zookeeper=True, main_configs=configs)
-node_2 = cluster.add_instance('replica2', with_zookeeper=True, main_configs=configs)
-node_3 = cluster.add_instance('replica3', with_zookeeper=True, main_configs=configs)
+node_1 = cluster.add_instance('replica1', with_zookeeper=True)
+node_2 = cluster.add_instance('replica2', with_zookeeper=True)
+node_3 = cluster.add_instance('replica3', with_zookeeper=True)
 
 @pytest.fixture(scope="module")
 def start_cluster():
diff --git a/tests/integration/test_grant_and_revoke/test.py b/tests/integration/test_grant_and_revoke/test.py
index c1be16fe17d1..1124f072a06a 100644
--- a/tests/integration/test_grant_and_revoke/test.py
+++ b/tests/integration/test_grant_and_revoke/test.py
@@ -151,7 +151,7 @@ def test_grant_all_on_table():
     instance.query("GRANT ALL ON test.table TO A WITH GRANT OPTION")
     instance.query("GRANT ALL ON test.table TO B", user='A')
     assert instance.query(
-        "SHOW GRANTS FOR B") == "GRANT SHOW TABLES, SHOW COLUMNS, SHOW DICTIONARIES, SELECT, INSERT, ALTER, CREATE TABLE, CREATE VIEW, CREATE DICTIONARY, DROP TABLE, DROP VIEW, DROP DICTIONARY, TRUNCATE, OPTIMIZE, SYSTEM MERGES, SYSTEM TTL MERGES, SYSTEM FETCHES, SYSTEM MOVES, SYSTEM SENDS, SYSTEM REPLICATION QUEUES, SYSTEM DROP REPLICA, SYSTEM SYNC REPLICA, SYSTEM RESTART REPLICA, SYSTEM FLUSH DISTRIBUTED, dictGet ON test.table TO B
"
+        "SHOW GRANTS FOR B") == "GRANT SHOW TABLES, SHOW COLUMNS, SHOW DICTIONARIES, SELECT, INSERT, ALTER, CREATE TABLE, CREATE VIEW, CREATE DICTIONARY, DROP TABLE, DROP VIEW, DROP DICTIONARY, TRUNCATE, OPTIMIZE, SYSTEM MERGES, SYSTEM TTL MERGES, SYSTEM FETCHES, SYSTEM MOVES, SYSTEM SENDS, SYSTEM REPLICATION QUEUES, SYSTEM DROP REPLICA, SYSTEM SYNC REPLICA, SYSTEM RESTART REPLICA, SYSTEM RESTORE REPLICA, SYSTEM FLUSH DISTRIBUTED, dictGet ON test.table TO B
"
     instance.query("REVOKE ALL ON test.table FROM B", user='A')
     assert instance.query("SHOW GRANTS FOR B") == ""
 
diff --git a/tests/integration/test_restore_replica/__init__.py b/tests/integration/test_restore_replica/__init__.py
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tests/integration/test_attach_without_fetching/configs/remote_servers.xml b/tests/integration/test_restore_replica/configs/remote_servers.xml
similarity index 79%
rename from tests/integration/test_attach_without_fetching/configs/remote_servers.xml
rename to tests/integration/test_restore_replica/configs/remote_servers.xml
index 7978f921b2e6..0709f97551a2 100644
--- a/tests/integration/test_attach_without_fetching/configs/remote_servers.xml
+++ b/tests/integration/test_restore_replica/configs/remote_servers.xml
@@ -4,15 +4,15 @@
             <shard>
                 <internal_replication>true</internal_replication>
                 <replica>
-                    <host>node_1_1</host>
+                    <host>replica1</host>
                     <port>9000</port>
                 </replica>
                 <replica>
-                    <host>node_1_2</host>
+                    <host>replica2</host>
                     <port>9000</port>
                 </replica>
                  <replica>
-                    <host>node_1_3</host>
+                    <host>replica3</host>
                     <port>9000</port>
                 </replica>
             </shard>
diff --git a/tests/integration/test_restore_replica/test.py b/tests/integration/test_restore_replica/test.py
new file mode 100644
index 000000000000..4197c0642439
--- /dev/null
+++ b/tests/integration/test_restore_replica/test.py
@@ -0,0 +1,156 @@
+import time
+import pytest
+
+from helpers.cluster import ClickHouseCluster
+from helpers.cluster import ClickHouseKiller
+from helpers.test_tools import assert_eq_with_retry
+from helpers.network import PartitionManager
+
+def fill_nodes(nodes):
+    for node in nodes:
+        node.query(
+        '''
+            CREATE TABLE test(n UInt32)
+            ENGINE = ReplicatedMergeTree('/clickhouse/tables/test/', '{replica}')
+            ORDER BY n PARTITION BY n % 10;
+        '''.format(replica=node.name))
+
+cluster = ClickHouseCluster(__file__)
+configs =["configs/remote_servers.xml"]
+
+node_1 = cluster.add_instance('replica1', with_zookeeper=True, main_configs=configs)
+node_2 = cluster.add_instance('replica2', with_zookeeper=True, main_configs=configs)
+node_3 = cluster.add_instance('replica3', with_zookeeper=True, main_configs=configs)
+nodes = [node_1, node_2, node_3]
+
+def fill_table():
+    node_1.query("TRUNCATE TABLE test")
+
+    for node in nodes:
+        node.query("SYSTEM SYNC REPLICA test")
+
+    check_data(0, 0)
+
+    # it will create multiple parts in each partition and probably cause merges
+    node_1.query("INSERT INTO test SELECT number + 0 FROM numbers(200)")
+    node_1.query("INSERT INTO test SELECT number + 200 FROM numbers(200)")
+    node_1.query("INSERT INTO test SELECT number + 400 FROM numbers(200)")
+    node_1.query("INSERT INTO test SELECT number + 600 FROM numbers(200)")
+    node_1.query("INSERT INTO test SELECT number + 800 FROM numbers(200)")
+    check_data(499500, 1000)
+
+@pytest.fixture(scope="module")
+def start_cluster():
+    try:
+        cluster.start()
+        fill_nodes(nodes)
+        yield cluster
+
+    except Exception as ex:
+        print(ex)
+
+    finally:
+        cluster.shutdown()
+
+def check_data(_sum: int, count: int) -> None:
+    res = "{}\t{}
".format(_sum, count)
+    assert_eq_with_retry(node_1, "SELECT sum(n), count() FROM test", res)
+    assert_eq_with_retry(node_2, "SELECT sum(n), count() FROM test", res)
+    assert_eq_with_retry(node_3, "SELECT sum(n), count() FROM test", res)
+
+def check_after_restoration():
+    check_data(1999000, 2000)
+
+    for node in nodes:
+        node.query_and_get_error("SYSTEM RESTORE REPLICA test")
+
+def test_restore_replica_invalid_tables(start_cluster):
+    print("Checking the invocation on non-existent and non-replicated tables")
+    node_1.query_and_get_error("SYSTEM RESTORE REPLICA i_dont_exist_42")
+    node_1.query_and_get_error("SYSTEM RESTORE REPLICA no_db.i_dont_exist_42")
+    node_1.query_and_get_error("SYSTEM RESTORE REPLICA system.numbers")
+
+def test_restore_replica_sequential(start_cluster):
+    zk = cluster.get_kazoo_client('zoo1')
+    fill_table()
+
+    print("Deleting root ZK path metadata")
+    zk.delete("/clickhouse/tables/test", recursive=True)
+    assert zk.exists("/clickhouse/tables/test") is None
+
+    node_1.query("SYSTEM RESTART REPLICA test")
+    node_1.query_and_get_error("INSERT INTO test SELECT number AS num FROM numbers(1000,2000) WHERE num % 2 = 0")
+
+    print("Restoring replica1")
+
+    node_1.query("SYSTEM RESTORE REPLICA test")
+    assert zk.exists("/clickhouse/tables/test")
+    check_data(499500, 1000)
+
+    node_1.query("INSERT INTO test SELECT number + 1000 FROM numbers(1000)")
+
+    print("Restoring other replicas")
+
+    node_2.query("SYSTEM RESTART REPLICA test")
+    node_2.query("SYSTEM RESTORE REPLICA test")
+
+    node_3.query("SYSTEM RESTART REPLICA test")
+    node_3.query("SYSTEM RESTORE REPLICA test")
+
+    node_2.query("SYSTEM SYNC REPLICA test")
+    node_3.query("SYSTEM SYNC REPLICA test")
+
+    check_after_restoration()
+
+def test_restore_replica_parallel(start_cluster):
+    zk = cluster.get_kazoo_client('zoo1')
+    fill_table()
+
+    print("Deleting root ZK path metadata")
+    zk.delete("/clickhouse/tables/test", recursive=True)
+    assert zk.exists("/clickhouse/tables/test") is None
+
+    node_1.query("SYSTEM RESTART REPLICA test")
+    node_1.query_and_get_error("INSERT INTO test SELECT number AS num FROM numbers(1000,2000) WHERE num % 2 = 0")
+
+    print("Restoring replicas in parallel")
+
+    node_2.query("SYSTEM RESTART REPLICA test")
+    node_3.query("SYSTEM RESTART REPLICA test")
+
+    node_1.query("SYSTEM RESTORE REPLICA test ON CLUSTER test_cluster")
+
+    assert zk.exists("/clickhouse/tables/test")
+    check_data(499500, 1000)
+
+    node_1.query("INSERT INTO test SELECT number + 1000 FROM numbers(1000)")
+
+    check_after_restoration()
+
+def test_restore_replica_alive_replicas(start_cluster):
+    zk = cluster.get_kazoo_client('zoo1')
+    fill_table()
+
+    print("Deleting replica2 path, trying to restore replica1")
+    zk.delete("/clickhouse/tables/test/replicas/replica2", recursive=True)
+    assert zk.exists("/clickhouse/tables/test/replicas/replica2") is None
+    node_1.query_and_get_error("SYSTEM RESTORE REPLICA test")
+
+    print("Deleting replica1 path, trying to restore replica1")
+    zk.delete("/clickhouse/tables/test/replicas/replica1", recursive=True)
+    assert zk.exists("/clickhouse/tables/test/replicas/replica1") is None
+
+    node_1.query("SYSTEM RESTART REPLICA test")
+    node_1.query("SYSTEM RESTORE REPLICA test")
+
+    node_2.query("SYSTEM RESTART REPLICA test")
+    node_2.query("SYSTEM RESTORE REPLICA test")
+
+    check_data(499500, 1000)
+
+    node_1.query("INSERT INTO test SELECT number + 1000 FROM numbers(1000)")
+
+    node_2.query("SYSTEM SYNC REPLICA test")
+    node_3.query("SYSTEM SYNC REPLICA test")
+
+    check_after_restoration()
diff --git a/tests/queries/0_stateless/01271_show_privileges.reference b/tests/queries/0_stateless/01271_show_privileges.reference
index 0ab0d57ebcfa..343d8ceeca36 100644
--- a/tests/queries/0_stateless/01271_show_privileges.reference
+++ b/tests/queries/0_stateless/01271_show_privileges.reference
@@ -103,6 +103,7 @@ SYSTEM REPLICATION QUEUES	['SYSTEM STOP REPLICATION QUEUES','SYSTEM START REPLIC
 SYSTEM DROP REPLICA	['DROP REPLICA']	TABLE	SYSTEM
 SYSTEM SYNC REPLICA	['SYNC REPLICA']	TABLE	SYSTEM
 SYSTEM RESTART REPLICA	['RESTART REPLICA']	TABLE	SYSTEM
+SYSTEM RESTORE REPLICA	['RESTORE REPLICA']	TABLE	SYSTEM
 SYSTEM FLUSH DISTRIBUTED	['FLUSH DISTRIBUTED']	TABLE	SYSTEM FLUSH
 SYSTEM FLUSH LOGS	['FLUSH LOGS']	GLOBAL	SYSTEM FLUSH
 SYSTEM FLUSH	[]	\N	SYSTEM
