{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 58539,
  "instance_id": "ClickHouse__ClickHouse-58539",
  "issue_numbers": [
    "58406"
  ],
  "base_commit": "2166df064021a53d706e5279e5217ba3c48fb455",
  "patch": "diff --git a/docs/en/operations/settings/settings.md b/docs/en/operations/settings/settings.md\nindex 6e087467bb93..0c7b99509723 100644\n--- a/docs/en/operations/settings/settings.md\n+++ b/docs/en/operations/settings/settings.md\n@@ -4771,6 +4771,24 @@ Type: Int64\n \n Default: 0\n \n+\n+## output_format_compression_level\n+\n+Default compression level if query output is compressed. The setting is applied when `SELECT` query has `INTO OUTFILE` or when writing to table functions `file`, `url`, `hdfs`, `s3`, or `azureBlobStorage`.\n+\n+Possible values: from `1` to `22`\n+\n+Default: `3`\n+\n+\n+## output_format_compression_zstd_window_log\n+\n+Can be used when the output compression method is `zstd`. If greater than `0`, this setting explicitly sets compression window size (power of `2`) and enables a long-range mode for zstd compression. This can help to achieve a better compression ratio.\n+\n+Possible values: non-negative numbers. Note that if the value is too small or too big, `zstdlib` will throw an exception. Typical values are from `20` (window size = `1MB`) to `30` (window size = `1GB`).\n+\n+Default: `0`\n+\n ## rewrite_count_distinct_if_with_count_distinct_implementation\n \n Allows you to rewrite `countDistcintIf` with [count_distinct_implementation](#count_distinct_implementation) setting.\ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex 4e057861f606..68bffe9f8016 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -204,6 +204,8 @@ class IColumn;\n     M(Bool, input_format_parallel_parsing, true, \"Enable parallel parsing for some data formats.\", 0) \\\n     M(UInt64, min_chunk_bytes_for_parallel_parsing, (10 * 1024 * 1024), \"The minimum chunk size in bytes, which each thread will parse in parallel.\", 0) \\\n     M(Bool, output_format_parallel_formatting, true, \"Enable parallel formatting for some data formats.\", 0) \\\n+    M(UInt64, output_format_compression_level, 3, \"Default compression level if query output is compressed. The setting is applied when `SELECT` query has `INTO OUTFILE` or when inserting to table function `file`, `url`, `hdfs`, `s3`, and `azureBlobStorage`.\", 0) \\\n+    M(UInt64, output_format_compression_zstd_window_log, 0, \"Can be used when the output compression method is `zstd`. If greater than `0`, this setting explicitly sets compression window size (power of `2`) and enables a long-range mode for zstd compression.\", 0) \\\n     \\\n     M(UInt64, merge_tree_min_rows_for_concurrent_read, (20 * 8192), \"If at least as many lines are read from one file, the reading can be parallelized.\", 0) \\\n     M(UInt64, merge_tree_min_bytes_for_concurrent_read, (24 * 10 * 1024 * 1024), \"If at least as many bytes are read from one file, the reading can be parallelized.\", 0) \\\ndiff --git a/src/IO/CompressionMethod.cpp b/src/IO/CompressionMethod.cpp\nindex 13e1adbb7024..fc415b73ec1d 100644\n--- a/src/IO/CompressionMethod.cpp\n+++ b/src/IO/CompressionMethod.cpp\n@@ -170,7 +170,7 @@ std::unique_ptr<ReadBuffer> wrapReadBufferWithCompressionMethod(\n }\n \n std::unique_ptr<WriteBuffer> wrapWriteBufferWithCompressionMethod(\n-    std::unique_ptr<WriteBuffer> nested, CompressionMethod method, int level, size_t buf_size, char * existing_memory, size_t alignment)\n+    std::unique_ptr<WriteBuffer> nested, CompressionMethod method, int level, int zstd_window_log, size_t buf_size, char * existing_memory, size_t alignment)\n {\n     if (method == DB::CompressionMethod::Gzip || method == CompressionMethod::Zlib)\n         return std::make_unique<ZlibDeflatingWriteBuffer>(std::move(nested), method, level, buf_size, existing_memory, alignment);\n@@ -183,7 +183,7 @@ std::unique_ptr<WriteBuffer> wrapWriteBufferWithCompressionMethod(\n         return std::make_unique<LZMADeflatingWriteBuffer>(std::move(nested), level, buf_size, existing_memory, alignment);\n \n     if (method == CompressionMethod::Zstd)\n-        return std::make_unique<ZstdDeflatingWriteBuffer>(std::move(nested), level, buf_size, existing_memory, alignment);\n+        return std::make_unique<ZstdDeflatingWriteBuffer>(std::move(nested), level, zstd_window_log, buf_size, existing_memory, alignment);\n \n     if (method == CompressionMethod::Lz4)\n         return std::make_unique<Lz4DeflatingWriteBuffer>(std::move(nested), level, buf_size, existing_memory, alignment);\ndiff --git a/src/IO/CompressionMethod.h b/src/IO/CompressionMethod.h\nindex c142531cd05f..511704059ecf 100644\n--- a/src/IO/CompressionMethod.h\n+++ b/src/IO/CompressionMethod.h\n@@ -66,6 +66,7 @@ std::unique_ptr<WriteBuffer> wrapWriteBufferWithCompressionMethod(\n     std::unique_ptr<WriteBuffer> nested,\n     CompressionMethod method,\n     int level,\n+    int zstd_window_log = 0,\n     size_t buf_size = DBMS_DEFAULT_BUFFER_SIZE,\n     char * existing_memory = nullptr,\n     size_t alignment = 0);\ndiff --git a/src/IO/ZstdDeflatingWriteBuffer.cpp b/src/IO/ZstdDeflatingWriteBuffer.cpp\nindex 949d65926b37..3b474a4de745 100644\n--- a/src/IO/ZstdDeflatingWriteBuffer.cpp\n+++ b/src/IO/ZstdDeflatingWriteBuffer.cpp\n@@ -1,30 +1,51 @@\n #include <IO/ZstdDeflatingWriteBuffer.h>\n #include <Common/Exception.h>\n+#include <IO/WriteHelpers.h>\n \n namespace DB\n {\n namespace ErrorCodes\n {\n     extern const int ZSTD_ENCODER_FAILED;\n+    extern const int ILLEGAL_CODEC_PARAMETER;\n+}\n+\n+static void setZstdParameter(ZSTD_CCtx * cctx, ZSTD_cParameter param, int value)\n+{\n+    auto ret = ZSTD_CCtx_setParameter(cctx, param, value);\n+    if (ZSTD_isError(ret))\n+        throw Exception(\n+            ErrorCodes::ZSTD_ENCODER_FAILED,\n+            \"zstd stream encoder option setting failed: error code: {}; zstd version: {}\",\n+            ret,\n+            ZSTD_VERSION_STRING);\n }\n \n ZstdDeflatingWriteBuffer::ZstdDeflatingWriteBuffer(\n-    std::unique_ptr<WriteBuffer> out_, int compression_level, size_t buf_size, char * existing_memory, size_t alignment)\n+    std::unique_ptr<WriteBuffer> out_, int compression_level, int window_log, size_t buf_size, char * existing_memory, size_t alignment)\n     : WriteBufferWithOwnMemoryDecorator(std::move(out_), buf_size, existing_memory, alignment)\n {\n     cctx = ZSTD_createCCtx();\n     if (cctx == nullptr)\n         throw Exception(ErrorCodes::ZSTD_ENCODER_FAILED, \"zstd stream encoder init failed: zstd version: {}\", ZSTD_VERSION_STRING);\n-    size_t ret = ZSTD_CCtx_setParameter(cctx, ZSTD_c_compressionLevel, compression_level);\n-    if (ZSTD_isError(ret))\n-        throw Exception(ErrorCodes::ZSTD_ENCODER_FAILED,\n-                        \"zstd stream encoder option setting failed: error code: {}; zstd version: {}\",\n-                        ret, ZSTD_VERSION_STRING);\n-    ret = ZSTD_CCtx_setParameter(cctx, ZSTD_c_checksumFlag, 1);\n-    if (ZSTD_isError(ret))\n-        throw Exception(ErrorCodes::ZSTD_ENCODER_FAILED,\n-                        \"zstd stream encoder option setting failed: error code: {}; zstd version: {}\",\n-                        ret, ZSTD_VERSION_STRING);\n+    setZstdParameter(cctx, ZSTD_c_compressionLevel, compression_level);\n+\n+    if (window_log > 0)\n+    {\n+        ZSTD_bounds window_log_bounds = ZSTD_cParam_getBounds(ZSTD_c_windowLog);\n+        if (ZSTD_isError(window_log_bounds.error))\n+            throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER, \"ZSTD windowLog parameter is not supported {}\",\n+                std::string(ZSTD_getErrorName(window_log_bounds.error)));\n+        if (window_log > window_log_bounds.upperBound || window_log < window_log_bounds.lowerBound)\n+            throw Exception(ErrorCodes::ILLEGAL_CODEC_PARAMETER,\n+                            \"ZSTD codec can't have window log more than {} and lower than {}, given {}\",\n+                            toString(window_log_bounds.upperBound),\n+                            toString(window_log_bounds.lowerBound), toString(window_log));\n+        setZstdParameter(cctx, ZSTD_c_enableLongDistanceMatching, 1);\n+        setZstdParameter(cctx, ZSTD_c_windowLog, window_log);\n+    }\n+\n+    setZstdParameter(cctx, ZSTD_c_checksumFlag, 1);\n \n     input = {nullptr, 0, 0};\n     output = {nullptr, 0, 0};\ndiff --git a/src/IO/ZstdDeflatingWriteBuffer.h b/src/IO/ZstdDeflatingWriteBuffer.h\nindex a66d6085a747..8c129b1bfbba 100644\n--- a/src/IO/ZstdDeflatingWriteBuffer.h\n+++ b/src/IO/ZstdDeflatingWriteBuffer.h\n@@ -17,6 +17,7 @@ class ZstdDeflatingWriteBuffer : public WriteBufferWithOwnMemoryDecorator\n     ZstdDeflatingWriteBuffer(\n         std::unique_ptr<WriteBuffer> out_,\n         int compression_level,\n+        int window_log = 0,\n         size_t buf_size = DBMS_DEFAULT_BUFFER_SIZE,\n         char * existing_memory = nullptr,\n         size_t alignment = 0);\ndiff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp\nindex 63804d2d86f2..23a1a703b162 100644\n--- a/src/Interpreters/executeQuery.cpp\n+++ b/src/Interpreters/executeQuery.cpp\n@@ -1434,11 +1434,12 @@ void executeQuery(\n                     const auto & compression_method_node = ast_query_with_output->compression->as<ASTLiteral &>();\n                     compression_method = compression_method_node.value.safeGet<std::string>();\n                 }\n-\n+                const auto & settings = context->getSettingsRef();\n                 compressed_buffer = wrapWriteBufferWithCompressionMethod(\n                     std::make_unique<WriteBufferFromFile>(out_file, DBMS_DEFAULT_BUFFER_SIZE, O_WRONLY | O_EXCL | O_CREAT),\n                     chooseCompressionMethod(out_file, compression_method),\n-                    /* compression level = */ 3\n+                    /* compression level = */ static_cast<int>(settings.output_format_compression_level),\n+                    /* zstd_window_log = */ static_cast<int>(settings.output_format_compression_zstd_window_log)\n                 );\n             }\n \ndiff --git a/src/Processors/Formats/Impl/Parquet/Write.cpp b/src/Processors/Formats/Impl/Parquet/Write.cpp\nindex 6d8f1ab55cb1..02ca2734ff85 100644\n--- a/src/Processors/Formats/Impl/Parquet/Write.cpp\n+++ b/src/Processors/Formats/Impl/Parquet/Write.cpp\n@@ -448,6 +448,7 @@ PODArray<char> & compress(PODArray<char> & source, PODArray<char> & scratch, Com\n                 std::move(dest_buf),\n                 method,\n                 /*level*/ 3,\n+                /*zstd_window_log*/ 0,\n                 source.size(),\n                 /*existing_memory*/ source.data());\n             chassert(compressed_buf->position() == source.data());\ndiff --git a/src/Server/HTTP/WriteBufferFromHTTPServerResponse.cpp b/src/Server/HTTP/WriteBufferFromHTTPServerResponse.cpp\nindex 1a12c09a8c7b..c32da278e496 100644\n--- a/src/Server/HTTP/WriteBufferFromHTTPServerResponse.cpp\n+++ b/src/Server/HTTP/WriteBufferFromHTTPServerResponse.cpp\n@@ -112,6 +112,7 @@ void WriteBufferFromHTTPServerResponse::nextImpl()\n                     std::make_unique<WriteBufferFromOStream>(*response_body_ostr),\n                     compress ? compression_method : CompressionMethod::None,\n                     compression_level,\n+                    0,\n                     working_buffer.size(),\n                     working_buffer.begin());\n             else\ndiff --git a/src/Storages/HDFS/StorageHDFS.cpp b/src/Storages/HDFS/StorageHDFS.cpp\nindex fdbb5e9f1719..a22c5903420d 100644\n--- a/src/Storages/HDFS/StorageHDFS.cpp\n+++ b/src/Storages/HDFS/StorageHDFS.cpp\n@@ -723,13 +723,13 @@ class HDFSSink : public SinkToStorage\n         const CompressionMethod compression_method)\n         : SinkToStorage(sample_block)\n     {\n+        const auto & settings = context->getSettingsRef();\n         write_buf = wrapWriteBufferWithCompressionMethod(\n             std::make_unique<WriteBufferFromHDFS>(\n-                uri,\n-                context->getGlobalContext()->getConfigRef(),\n-                context->getSettingsRef().hdfs_replication,\n-                context->getWriteSettings()),\n-            compression_method, 3);\n+                uri, context->getGlobalContext()->getConfigRef(), context->getSettingsRef().hdfs_replication, context->getWriteSettings()),\n+            compression_method,\n+            static_cast<int>(settings.output_format_compression_level),\n+            static_cast<int>(settings.output_format_compression_zstd_window_log));\n         writer = FormatFactory::instance().getOutputFormatParallelIfPossible(format, *write_buf, sample_block, context);\n     }\n \ndiff --git a/src/Storages/StorageAzureBlob.cpp b/src/Storages/StorageAzureBlob.cpp\nindex 9564bad485c2..0e00c62111c3 100644\n--- a/src/Storages/StorageAzureBlob.cpp\n+++ b/src/Storages/StorageAzureBlob.cpp\n@@ -533,7 +533,12 @@ class StorageAzureBlobSink : public SinkToStorage\n         , format_settings(format_settings_)\n     {\n         StoredObject object(blob_path);\n-        write_buf = wrapWriteBufferWithCompressionMethod(object_storage->writeObject(object, WriteMode::Rewrite), compression_method, 3);\n+        const auto & settings = context->getSettingsRef();\n+        write_buf = wrapWriteBufferWithCompressionMethod(\n+            object_storage->writeObject(object, WriteMode::Rewrite),\n+            compression_method,\n+            static_cast<int>(settings.output_format_compression_level),\n+            static_cast<int>(settings.output_format_compression_zstd_window_log));\n         writer = FormatFactory::instance().getOutputFormatParallelIfPossible(format, *write_buf, sample_block, context, format_settings);\n     }\n \ndiff --git a/src/Storages/StorageFile.cpp b/src/Storages/StorageFile.cpp\nindex 25bb6691ff68..0c8394064629 100644\n--- a/src/Storages/StorageFile.cpp\n+++ b/src/Storages/StorageFile.cpp\n@@ -1485,8 +1485,12 @@ class StorageFileSink final : public SinkToStorage\n \n         /// In case of formats with prefixes if file is not empty we have already written prefix.\n         bool do_not_write_prefix = naked_buffer->size();\n-\n-        write_buf = wrapWriteBufferWithCompressionMethod(std::move(naked_buffer), compression_method, 3);\n+        const auto & settings = context->getSettingsRef();\n+        write_buf = wrapWriteBufferWithCompressionMethod(\n+            std::move(naked_buffer),\n+            compression_method,\n+            static_cast<int>(settings.output_format_compression_level),\n+            static_cast<int>(settings.output_format_compression_zstd_window_log));\n \n         writer = FormatFactory::instance().getOutputFormatParallelIfPossible(format_name,\n                                                                              *write_buf, metadata_snapshot->getSampleBlock(), context, format_settings);\ndiff --git a/src/Storages/StorageS3.cpp b/src/Storages/StorageS3.cpp\nindex 60ae7f219f43..1af0b638df95 100644\n--- a/src/Storages/StorageS3.cpp\n+++ b/src/Storages/StorageS3.cpp\n@@ -932,6 +932,7 @@ class StorageS3Sink : public SinkToStorage\n             blob_log->query_id = context->getCurrentQueryId();\n         }\n \n+        const auto & settings = context->getSettingsRef();\n         write_buf = wrapWriteBufferWithCompressionMethod(\n             std::make_unique<WriteBufferFromS3>(\n                 configuration_.client,\n@@ -944,7 +945,8 @@ class StorageS3Sink : public SinkToStorage\n                 threadPoolCallbackRunner<void>(getIOThreadPool().get(), \"S3ParallelWrite\"),\n                 context->getWriteSettings()),\n             compression_method,\n-            3);\n+            static_cast<int>(settings.output_format_compression_level),\n+            static_cast<int>(settings.output_format_compression_zstd_window_log));\n         writer\n             = FormatFactory::instance().getOutputFormatParallelIfPossible(format, *write_buf, sample_block, context, format_settings);\n     }\ndiff --git a/src/Storages/StorageURL.cpp b/src/Storages/StorageURL.cpp\nindex d6b6f5af61c7..39fd6195698e 100644\n--- a/src/Storages/StorageURL.cpp\n+++ b/src/Storages/StorageURL.cpp\n@@ -540,11 +540,12 @@ StorageURLSink::StorageURLSink(\n         Poco::URI(uri), http_method, content_type, content_encoding, headers, timeouts, DBMS_DEFAULT_BUFFER_SIZE, proxy_config\n     );\n \n+    const auto & settings = context->getSettingsRef();\n     write_buf = wrapWriteBufferWithCompressionMethod(\n         std::move(write_buffer),\n         compression_method,\n-        3\n-    );\n+        static_cast<int>(settings.output_format_compression_level),\n+        static_cast<int>(settings.output_format_compression_zstd_window_log));\n     writer = FormatFactory::instance().getOutputFormat(format, *write_buf, sample_block, context, format_settings);\n }\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02961_output_format_compress_params.reference b/tests/queries/0_stateless/02961_output_format_compress_params.reference\nnew file mode 100644\nindex 000000000000..d0752a77fc71\n--- /dev/null\n+++ b/tests/queries/0_stateless/02961_output_format_compress_params.reference\n@@ -0,0 +1,2 @@\n+1\n+1000000\ndiff --git a/tests/queries/0_stateless/02961_output_format_compress_params.sh b/tests/queries/0_stateless/02961_output_format_compress_params.sh\nnew file mode 100755\nindex 000000000000..7275f9a0b2b1\n--- /dev/null\n+++ b/tests/queries/0_stateless/02961_output_format_compress_params.sh\n@@ -0,0 +1,13 @@\n+#!/usr/bin/env bash\n+# Tags: replica\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+file_with_random_postfix=test_02961_`date +%s%6N`.csv\n+\n+${CLICKHOUSE_CLIENT} --query \"INSERT INTO FUNCTION file('${file_with_random_postfix}', 'CSV', 'x UInt64', 'zstd') SELECT number FROM numbers(1000000) SETTINGS output_format_compression_level = 10, output_format_compression_zstd_window_log = 30, engine_file_truncate_on_insert = 1;\"\n+# Simple check that output_format_compression_zstd_window_log = 30 works\n+${CLICKHOUSE_CLIENT} --query \"SELECT count() FROM file('${file_with_random_postfix}', 'CSV', 'x UInt64', 'zstd') SETTINGS zstd_window_log_max = 29;\" 2>&1 | head -n 1 | grep -c \"ZSTD_DECODER_FAILED\"\n+${CLICKHOUSE_CLIENT} --query \"SELECT count() FROM file('${file_with_random_postfix}', 'CSV', 'x UInt64', 'zstd') SETTINGS zstd_window_log_max = 30;\"\n",
  "problem_statement": "Allow compression level for file-like storage engines and table functions\n> (you don't have to strictly follow this form)\r\n\r\n**Use case**\r\n\r\nWriting to a file but with a custom compression level (e.g. trade-off between speed and size)\r\n\r\n**Describe the solution you'd like**\r\n\r\n```\r\nINSERT INTO FUNCTION file[hdfs/url](name, path, schema, compression, compression_level) \r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently AFAIK there's no way to do this.\r\n\r\n**Additional context**\r\n\r\n> Add any other context or screenshots about the feature request here.\r\n\n",
  "hints_text": "Or do that via setting: `output_format_compression_level`\r\n\n+1, let's do it with a setting.\nThen I think it also makes sense to add `output_format_compression_zstd_window_log` for zstd long-range mode. @UnamedRus @alexey-milovidov wdyt?",
  "created_at": "2024-01-05T07:23:50Z"
}