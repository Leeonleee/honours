{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 18365,
  "instance_id": "ClickHouse__ClickHouse-18365",
  "issue_numbers": [
    "17682"
  ],
  "base_commit": "4e580f7b7cf119198f052750f90dae82d94d19ab",
  "patch": "diff --git a/src/Common/ThreadPool.cpp b/src/Common/ThreadPool.cpp\nindex 7b2c21086293..7fc0d65aa5bb 100644\n--- a/src/Common/ThreadPool.cpp\n+++ b/src/Common/ThreadPool.cpp\n@@ -55,6 +55,13 @@ void ThreadPoolImpl<Thread>::setMaxThreads(size_t value)\n     max_threads = value;\n }\n \n+template <typename Thread>\n+size_t ThreadPoolImpl<Thread>::getMaxThreads() const\n+{\n+    std::lock_guard lock(mutex);\n+    return max_threads;\n+}\n+\n template <typename Thread>\n void ThreadPoolImpl<Thread>::setMaxFreeThreads(size_t value)\n {\ndiff --git a/src/Common/ThreadPool.h b/src/Common/ThreadPool.h\nindex 8dd6cbbe02ca..0ae023e4ebd3 100644\n--- a/src/Common/ThreadPool.h\n+++ b/src/Common/ThreadPool.h\n@@ -71,6 +71,7 @@ class ThreadPoolImpl\n     void setMaxThreads(size_t value);\n     void setMaxFreeThreads(size_t value);\n     void setQueueSize(size_t value);\n+    size_t getMaxThreads() const;\n \n private:\n     mutable std::mutex mutex;\ndiff --git a/src/Interpreters/Aggregator.cpp b/src/Interpreters/Aggregator.cpp\nindex 87abca4d7cd8..de2c86d7c12f 100644\n--- a/src/Interpreters/Aggregator.cpp\n+++ b/src/Interpreters/Aggregator.cpp\n@@ -913,15 +913,15 @@ template <typename Method>\n Block Aggregator::convertOneBucketToBlock(\n     AggregatedDataVariants & data_variants,\n     Method & method,\n+    Arena * arena,\n     bool final,\n     size_t bucket) const\n {\n     Block block = prepareBlockAndFill(data_variants, final, method.data.impls[bucket].size(),\n-        [bucket, &method, this] (\n+        [bucket, &method, arena, this] (\n             MutableColumns & key_columns,\n             AggregateColumnsData & aggregate_columns,\n             MutableColumns & final_aggregate_columns,\n-            Arena * arena,\n             bool final_)\n         {\n             convertToBlockImpl(method, method.data.impls[bucket],\n@@ -950,7 +950,7 @@ Block Aggregator::mergeAndConvertOneBucketToBlock(\n         mergeBucketImpl<decltype(merged_data.NAME)::element_type>(variants, bucket, arena); \\\n         if (is_cancelled && is_cancelled->load(std::memory_order_seq_cst)) \\\n             return {}; \\\n-        block = convertOneBucketToBlock(merged_data, *merged_data.NAME, final, bucket); \\\n+        block = convertOneBucketToBlock(merged_data, *merged_data.NAME, arena, final, bucket); \\\n     }\n \n     APPLY_FOR_VARIANTS_TWO_LEVEL(M)\n@@ -982,7 +982,7 @@ void Aggregator::writeToTemporaryFileImpl(\n \n     for (size_t bucket = 0; bucket < Method::Data::NUM_BUCKETS; ++bucket)\n     {\n-        Block block = convertOneBucketToBlock(data_variants, method, false, bucket);\n+        Block block = convertOneBucketToBlock(data_variants, method, data_variants.aggregates_pool, false, bucket);\n         out.write(block);\n         update_max_sizes(block);\n     }\n@@ -1285,7 +1285,7 @@ Block Aggregator::prepareBlockAndFill(\n         }\n     }\n \n-    filler(key_columns, aggregate_columns_data, final_aggregate_columns, data_variants.aggregates_pool, final);\n+    filler(key_columns, aggregate_columns_data, final_aggregate_columns, final);\n \n     Block res = header.cloneEmpty();\n \n@@ -1352,7 +1352,6 @@ Block Aggregator::prepareBlockAndFillWithoutKey(AggregatedDataVariants & data_va\n         MutableColumns & key_columns,\n         AggregateColumnsData & aggregate_columns,\n         MutableColumns & final_aggregate_columns,\n-        Arena * arena,\n         bool final_)\n     {\n         if (data_variants.type == AggregatedDataVariants::Type::without_key || params.overflow_row)\n@@ -1367,7 +1366,8 @@ Block Aggregator::prepareBlockAndFillWithoutKey(AggregatedDataVariants & data_va\n             }\n             else\n             {\n-                insertAggregatesIntoColumns(data, final_aggregate_columns, arena);\n+                /// Always single-thread. It's safe to pass current arena from 'aggregates_pool'.\n+                insertAggregatesIntoColumns(data, final_aggregate_columns, data_variants.aggregates_pool);\n             }\n \n             if (params.overflow_row)\n@@ -1395,13 +1395,12 @@ Block Aggregator::prepareBlockAndFillSingleLevel(AggregatedDataVariants & data_v\n         MutableColumns & key_columns,\n         AggregateColumnsData & aggregate_columns,\n         MutableColumns & final_aggregate_columns,\n-        Arena * arena,\n         bool final_)\n     {\n     #define M(NAME) \\\n         else if (data_variants.type == AggregatedDataVariants::Type::NAME) \\\n             convertToBlockImpl(*data_variants.NAME, data_variants.NAME->data, \\\n-                key_columns, aggregate_columns, final_aggregate_columns, arena, final_);\n+                key_columns, aggregate_columns, final_aggregate_columns, data_variants.aggregates_pool, final_);\n \n         if (false) {} // NOLINT\n         APPLY_FOR_VARIANTS_SINGLE_LEVEL(M)\n@@ -1435,11 +1434,21 @@ BlocksList Aggregator::prepareBlocksAndFillTwoLevelImpl(\n     bool final,\n     ThreadPool * thread_pool) const\n {\n+    size_t max_threads = thread_pool ? thread_pool->getMaxThreads() : 1;\n+    if (max_threads > data_variants.aggregates_pools.size())\n+        for (size_t i = data_variants.aggregates_pools.size(); i < max_threads; ++i)\n+            data_variants.aggregates_pools.push_back(std::make_shared<Arena>());\n+\n     auto converter = [&](size_t bucket, ThreadGroupStatusPtr thread_group)\n     {\n         if (thread_group)\n             CurrentThread::attachToIfDetached(thread_group);\n-        return convertOneBucketToBlock(data_variants, method, final, bucket);\n+\n+        /// Select Arena to avoid race conditions\n+        size_t thread_number = static_cast<size_t>(bucket) % max_threads;\n+        Arena * arena = data_variants.aggregates_pools.at(thread_number).get();\n+\n+        return convertOneBucketToBlock(data_variants, method, arena, final, bucket);\n     };\n \n     /// packaged_task is used to ensure that exceptions are automatically thrown into the main stream.\n@@ -1949,7 +1958,7 @@ class MergingAndConvertingBlockInputStream : public IBlockInputStream\n             else if (method == AggregatedDataVariants::Type::NAME) \\\n             { \\\n                 aggregator.mergeBucketImpl<decltype(merged_data.NAME)::element_type>(data, bucket_num, arena); \\\n-                block = aggregator.convertOneBucketToBlock(merged_data, *merged_data.NAME, final, bucket_num); \\\n+                block = aggregator.convertOneBucketToBlock(merged_data, *merged_data.NAME, arena, final, bucket_num); \\\n             }\n \n             APPLY_FOR_VARIANTS_TWO_LEVEL(M)\ndiff --git a/src/Interpreters/Aggregator.h b/src/Interpreters/Aggregator.h\nindex c688da9d32d9..86806b7fbad7 100644\n--- a/src/Interpreters/Aggregator.h\n+++ b/src/Interpreters/Aggregator.h\n@@ -1212,6 +1212,7 @@ class Aggregator\n     Block convertOneBucketToBlock(\n         AggregatedDataVariants & data_variants,\n         Method & method,\n+        Arena * arena,\n         bool final,\n         size_t bucket) const;\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01605_dictinct_two_level.reference b/tests/queries/0_stateless/01605_dictinct_two_level.reference\nnew file mode 100644\nindex 000000000000..50d1615e1aae\n--- /dev/null\n+++ b/tests/queries/0_stateless/01605_dictinct_two_level.reference\n@@ -0,0 +1,20 @@\n+['0']\n+['1']\n+['2']\n+['3']\n+['4']\n+['5']\n+['6']\n+['7']\n+['8']\n+['9']\n+test.com\t['foo3223','foo6455','foo382','foo5566','foo1037']\n+test.com0\t['foo0']\n+test.com0.0001\t['foo1']\n+test.com0.0002\t['foo2']\n+test.com0.0003\t['foo3']\n+test.com0.0004\t['foo4']\n+test.com0.0005\t['foo5']\n+test.com0.0006\t['foo6']\n+test.com0.0007\t['foo7']\n+test.com0.0008\t['foo8']\ndiff --git a/tests/queries/0_stateless/01605_dictinct_two_level.sql b/tests/queries/0_stateless/01605_dictinct_two_level.sql\nnew file mode 100644\nindex 000000000000..5f20ae590c5e\n--- /dev/null\n+++ b/tests/queries/0_stateless/01605_dictinct_two_level.sql\n@@ -0,0 +1,25 @@\n+SET group_by_two_level_threshold_bytes = 1;\n+SET group_by_two_level_threshold = 1;\n+\n+SELECT groupArray(DISTINCT toString(number % 10)) FROM numbers_mt(50000) \n+    GROUP BY number ORDER BY number LIMIT 10\n+    SETTINGS max_threads = 2, max_block_size = 2000;\n+\n+DROP TABLE IF EXISTS dictinct_two_level;\n+\n+CREATE TABLE dictinct_two_level (\n+    time DateTime64(3),\n+    domain String,\n+    subdomain String\n+) ENGINE = MergeTree ORDER BY time;\n+\n+INSERT INTO dictinct_two_level SELECT 1546300800000, 'test.com', concat('foo', toString(number % 10000)) from numbers(10000);\n+INSERT INTO dictinct_two_level SELECT 1546300800000, concat('test.com', toString(number / 10000)) , concat('foo', toString(number % 10000)) from numbers(10000);\n+\n+SELECT\n+    domain, groupArraySample(5, 11111)(DISTINCT subdomain) AS example_subdomains\n+FROM dictinct_two_level\n+GROUP BY domain ORDER BY domain, example_subdomains\n+LIMIT 10;\n+\n+DROP TABLE IF EXISTS dictinct_two_level;\n",
  "problem_statement": "Server crash with groupArraySample(5)(distinct ...)\n**Describe the bug**\r\n\r\n```\r\nSELECT\r\n    domain \r\n    , groupArraySample(5)(distinct subdomain) AS example_subdomains\r\nFROM table\r\nWHERE time > now() - interval 1 hour\r\nGROUP BY domain\r\nLIMIT 100\r\n```\r\n\r\nCauses a server crash. If I remove the distinct it runs just fine. I appreciate it is probably not valid to use a distinct here, but it should not cause a full crash.\r\n\r\n```\r\n[clickhouse] 2020.12.01 13:06:12.037997 [ 265 ] <Fatal> BaseDaemon: ########################################\r\n[clickhouse] 2020.12.01 13:06:12.038106 [ 265 ] <Fatal> BaseDaemon: (version 20.11.3.3 (official build), build id: C88CD350740ED614) (from thread 165) (query_id: a94ba7b7-f82d-4d0e-ba0a-af0763003728) Received signal Segmentation fault (11)\r\n[clickhouse] 2020.12.01 13:06:12.038131 [ 265 ] <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Address not mapped to object.\r\n[clickhouse] 2020.12.01 13:06:12.038162 [ 265 ] <Fatal> BaseDaemon: Stack trace: 0x7dc0763 0x91da3ea 0xdab6dda 0xdabafeb 0xdabac8b 0xdaba3f5 0xda42adf 0xe4eb128 0xe34e96a 0xe38774c 0xe384877 0xe389825 0x7b6293d 0x7b66463 0x7f6507933609 0x7f6507849293\r\n[clickhouse] 2020.12.01 13:06:12.038136 [ 264 ] <Fatal> BaseDaemon: ########################################\r\n[clickhouse] 2020.12.01 13:06:12.038228 [ 264 ] <Fatal> BaseDaemon: (version 20.11.3.3 (official build), build id: C88CD350740ED614) (from thread 175) (query_id: a94ba7b7-f82d-4d0e-ba0a-af0763003728) Received signal Segmentation fault (11)\r\n[clickhouse] 2020.12.01 13:06:12.038267 [ 265 ] <Fatal> BaseDaemon: 2. DB::GroupArrayGeneralImpl<DB::GroupArrayNodeString, DB::GroupArrayTrait<true, (DB::Sampler)1> >::insertResultInto(char*, DB::IColumn&, DB::Arena*) const @ 0x7dc0763 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038282 [ 264 ] <Fatal> BaseDaemon: Address: 0x6 Access: read. Address not mapped to object.\r\n[clickhouse] 2020.12.01 13:06:12.038311 [ 265 ] <Fatal> BaseDaemon: 3. DB::AggregateFunctionDistinct<DB::AggregateFunctionDistinctSingleGenericData<true> >::insertResultInto(char*, DB::IColumn&, DB::Arena*) const @ 0x91da3ea in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038318 [ 264 ] <Fatal> BaseDaemon: Stack trace: 0x7dc0763 0x91da3ea 0xdab6dda 0xdabafeb 0xdabac8b 0xdaba3f5 0xda42adf 0xe4eb128 0xe34e96a 0xe38774c 0xe384877 0xe389825 0x7b6293d 0x7b66463 0x7f6507933609 0x7f6507849293\r\n[clickhouse] 2020.12.01 13:06:12.038342 [ 265 ] <Fatal> BaseDaemon: 4. void DB::Aggregator::insertAggregatesIntoColumns<char*>(char*&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*) const @ 0xdab6dda in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038386 [ 265 ] <Fatal> BaseDaemon: 5. void DB::Aggregator::convertToBlockImplFinal<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >, StringHashMap<char*, Allocator<true, true> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, StringHashMap<char*, Allocator<true, true> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*) const @ 0xdabafeb in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038456 [ 265 ] <Fatal> BaseDaemon: 6. void DB::Aggregator::convertToBlockImpl<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >, StringHashMap<char*, Allocator<true, true> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, StringHashMap<char*, Allocator<true, true> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*, std::__1::allocator<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*, bool) const @ 0xdabac8b in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038223 [ 266 ] <Fatal> BaseDaemon: ########################################\r\n[clickhouse] 2020.12.01 13:06:12.038562 [ 265 ] <Fatal> BaseDaemon: 7. DB::Block DB::Aggregator::prepareBlockAndFill<DB::Block DB::Aggregator::convertOneBucketToBlock<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregatedDataVariants&, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, bool, unsigned long) const::'lambda'(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*, std::__1::allocator<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*, bool)>(DB::AggregatedDataVariants&, bool, unsigned long, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&&) const @ 0xdaba3f5 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038570 [ 266 ] <Fatal> BaseDaemon: (version 20.11.3.3 (official build), build id: C88CD350740ED614) (from thread 161) (query_id: a94ba7b7-f82d-4d0e-ba0a-af0763003728) Received signal Segmentation fault (11)\r\n[clickhouse] 2020.12.01 13:06:12.038601 [ 265 ] <Fatal> BaseDaemon: 8. DB::Aggregator::mergeAndConvertOneBucketToBlock(std::__1::vector<std::__1::shared_ptr<DB::AggregatedDataVariants>, std::__1::allocator<std::__1::shared_ptr<DB::AggregatedDataVariants> > >&, DB::Arena*, bool, unsigned long, std::__1::atomic<bool>*) const @ 0xda42adf in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038607 [ 266 ] <Fatal> BaseDaemon: Address: 0x7 Access: read. Address not mapped to object.\r\n[clickhouse] 2020.12.01 13:06:12.038632 [ 265 ] <Fatal> BaseDaemon: 9. DB::ConvertingAggregatedToChunksSource::generate() @ 0xe4eb128 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038646 [ 266 ] <Fatal> BaseDaemon: Stack trace: 0x7dc0763 0x91da3ea 0xdab6dda 0xdabb112 0xdabac8b 0xdaba3f5 0xda42adf 0xe4eb128 0xe34e96a 0xe38774c 0xe384877 0xe389825 0x7b6293d 0x7b66463 0x7f6507933609 0x7f6507849293\r\n[clickhouse] 2020.12.01 13:06:12.038671 [ 265 ] <Fatal> BaseDaemon: 10. DB::ISource::work() @ 0xe34e96a in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038711 [ 265 ] <Fatal> BaseDaemon: 11. ? @ 0xe38774c in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038730 [ 266 ] <Fatal> BaseDaemon: 2. DB::GroupArrayGeneralImpl<DB::GroupArrayNodeString, DB::GroupArrayTrait<true, (DB::Sampler)1> >::insertResultInto(char*, DB::IColumn&, DB::Arena*) const @ 0x7dc0763 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038750 [ 265 ] <Fatal> BaseDaemon: 12. DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) @ 0xe384877 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038770 [ 266 ] <Fatal> BaseDaemon: 3. DB::AggregateFunctionDistinct<DB::AggregateFunctionDistinctSingleGenericData<true> >::insertResultInto(char*, DB::IColumn&, DB::Arena*) const @ 0x91da3ea in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038795 [ 265 ] <Fatal> BaseDaemon: 13. ? @ 0xe389825 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038831 [ 266 ] <Fatal> BaseDaemon: 4. void DB::Aggregator::insertAggregatesIntoColumns<char*>(char*&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*) const @ 0xdab6dda in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038822 [ 265 ] <Fatal> BaseDaemon: 14. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x7b6293d in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038884 [ 265 ] <Fatal> BaseDaemon: 15. ? @ 0x7b66463 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038935 [ 265 ] <Fatal> BaseDaemon: 16. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n[clickhouse] 2020.12.01 13:06:12.038899 [ 266 ] <Fatal> BaseDaemon: 5. void DB::Aggregator::convertToBlockImplFinal<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >, StringHashMap<char*, Allocator<true, true> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, StringHashMap<char*, Allocator<true, true> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*) const @ 0xdabb112 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038992 [ 265 ] <Fatal> BaseDaemon: 17. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n[clickhouse] 2020.12.01 13:06:12.039016 [ 266 ] <Fatal> BaseDaemon: 6. void DB::Aggregator::convertToBlockImpl<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >, StringHashMap<char*, Allocator<true, true> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, StringHashMap<char*, Allocator<true, true> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*, std::__1::allocator<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*, bool) const @ 0xdabac8b in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.038396 [ 264 ] <Fatal> BaseDaemon: 2. DB::GroupArrayGeneralImpl<DB::GroupArrayNodeString, DB::GroupArrayTrait<true, (DB::Sampler)1> >::insertResultInto(char*, DB::IColumn&, DB::Arena*) const @ 0x7dc0763 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039069 [ 266 ] <Fatal> BaseDaemon: 7. DB::Block DB::Aggregator::prepareBlockAndFill<DB::Block DB::Aggregator::convertOneBucketToBlock<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregatedDataVariants&, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, bool, unsigned long) const::'lambda'(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*, std::__1::allocator<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*, bool)>(DB::AggregatedDataVariants&, bool, unsigned long, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&&) const @ 0xdaba3f5 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039093 [ 264 ] <Fatal> BaseDaemon: 3. DB::AggregateFunctionDistinct<DB::AggregateFunctionDistinctSingleGenericData<true> >::insertResultInto(char*, DB::IColumn&, DB::Arena*) const @ 0x91da3ea in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039113 [ 266 ] <Fatal> BaseDaemon: 8. DB::Aggregator::mergeAndConvertOneBucketToBlock(std::__1::vector<std::__1::shared_ptr<DB::AggregatedDataVariants>, std::__1::allocator<std::__1::shared_ptr<DB::AggregatedDataVariants> > >&, DB::Arena*, bool, unsigned long, std::__1::atomic<bool>*) const @ 0xda42adf in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039147 [ 266 ] <Fatal> BaseDaemon: 9. DB::ConvertingAggregatedToChunksSource::generate() @ 0xe4eb128 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039152 [ 264 ] <Fatal> BaseDaemon: 4. void DB::Aggregator::insertAggregatesIntoColumns<char*>(char*&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*) const @ 0xdab6dda in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039211 [ 264 ] <Fatal> BaseDaemon: 5. void DB::Aggregator::convertToBlockImplFinal<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >, StringHashMap<char*, Allocator<true, true> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, StringHashMap<char*, Allocator<true, true> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*) const @ 0xdabafeb in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039178 [ 266 ] <Fatal> BaseDaemon: 10. DB::ISource::work() @ 0xe34e96a in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039281 [ 264 ] <Fatal> BaseDaemon: 6. void DB::Aggregator::convertToBlockImpl<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >, StringHashMap<char*, Allocator<true, true> > >(DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, StringHashMap<char*, Allocator<true, true> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*, std::__1::allocator<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*, bool) const @ 0xdabac8b in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039298 [ 266 ] <Fatal> BaseDaemon: 11. ? @ 0xe38774c in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039344 [ 264 ] <Fatal> BaseDaemon: 7. DB::Block DB::Aggregator::prepareBlockAndFill<DB::Block DB::Aggregator::convertOneBucketToBlock<DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> > >(DB::AggregatedDataVariants&, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&, bool, unsigned long) const::'lambda'(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, std::__1::vector<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*, std::__1::allocator<DB::PODArray<char*, 4096ul, Allocator<false, false>, 15ul, 16ul>*> >&, std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::Arena*, bool)>(DB::AggregatedDataVariants&, bool, unsigned long, DB::AggregationMethodStringNoCache<TwoLevelStringHashMap<char*, Allocator<true, true>, StringHashMap> >&&) const @ 0xdaba3f5 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039380 [ 266 ] <Fatal> BaseDaemon: 12. DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) @ 0xe384877 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039382 [ 264 ] <Fatal> BaseDaemon: 8. DB::Aggregator::mergeAndConvertOneBucketToBlock(std::__1::vector<std::__1::shared_ptr<DB::AggregatedDataVariants>, std::__1::allocator<std::__1::shared_ptr<DB::AggregatedDataVariants> > >&, DB::Arena*, bool, unsigned long, std::__1::atomic<bool>*) const @ 0xda42adf in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039500 [ 266 ] <Fatal> BaseDaemon: 13. ? @ 0xe389825 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039585 [ 266 ] <Fatal> BaseDaemon: 14. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x7b6293d in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039702 [ 266 ] <Fatal> BaseDaemon: 15. ? @ 0x7b66463 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039691 [ 264 ] <Fatal> BaseDaemon: 9. DB::ConvertingAggregatedToChunksSource::generate() @ 0xe4eb128 in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039762 [ 266 ] <Fatal> BaseDaemon: 16. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n[clickhouse] 2020.12.01 13:06:12.039814 [ 266 ] <Fatal> BaseDaemon: 17. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n[clickhouse] 2020.12.01 13:06:12.039771 [ 264 ] <Fatal> BaseDaemon: 10. DB::ISource::work() @ 0xe34e96a in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.039859 [ 264 ] <Fatal> BaseDaemon: 11. ? @ 0xe38774c in /usr/bin/clickhouse\r\n[clickhouse] 2020.12.01 13:06:12.040261 [ 267 ] <Fatal> BaseDaemon: ########################################\r\n\r\n```\n",
  "hints_text": "Please provide a minimal example to reproduce the crash\nHm it causes a reproducable crash on my live database, but it is a bit tricky to make it crash on test data.\r\n\r\nI think it may be memory allocation related? I have the below crashing once on a local dev container but usually when i try to reproduce it throws:\r\n\r\n```\r\nCode: 241. DB::Exception: Received from localhost:9000. DB::Exception: Memory limit (for query) exceeded: would use 128.00 TiB (attempt to allocate chunk of 140737486974640 bytes), maximum: 9.31 GiB: While executing ConvertingAggregatedToChunksSource. \r\n```\r\n\r\nThat allocation looks like a very crazy amount?\r\n\r\n```\r\ndocker run -d --rm --name clickhouse yandex/clickhouse-server:20.11.3.3\r\ndocker exec -it clickhouse clickhouse client -mn\r\nCREATE TABLE t (\r\n    `time` DateTime64(3) CODEC(DoubleDelta, ZSTD(1)),\r\n    `domain` String CODEC(ZSTD(1)),\r\n    `subdomain` String DEFAULT '' CODEC(ZSTD(1))\r\n) engine=MergeTree order by time;\r\n\r\ninsert into t select 1546300800000, 'test.com', concat('foo', toString(number % 10000)) from numbers(1000000);\r\ninsert into t select 1546300800000, concat('test.com', toString(number / 10000)) , concat('foo', toString(number % 10000)) from numbers(1000000);\r\n\r\nSELECT\r\n    domain\r\n    , groupArraySample(5)(distinct subdomain) AS example_subdomains\r\nFROM t\r\nGROUP BY domain\r\nLIMIT 100;\r\n```\nIt isn't related to `groupArraySample` but `distinct`.",
  "created_at": "2020-12-22T11:36:41Z",
  "modified_files": [
    "src/Common/ThreadPool.cpp",
    "src/Common/ThreadPool.h",
    "src/Interpreters/Aggregator.cpp",
    "src/Interpreters/Aggregator.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/01605_dictinct_two_level.reference",
    "b/tests/queries/0_stateless/01605_dictinct_two_level.sql"
  ]
}