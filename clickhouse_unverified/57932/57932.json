{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 57932,
  "instance_id": "ClickHouse__ClickHouse-57932",
  "issue_numbers": [
    "50346",
    "54570",
    "54988",
    "57930",
    "47579"
  ],
  "base_commit": "4ff0eefe23f5209caa628b26f53f77790c761d0e",
  "patch": "diff --git a/docs/en/engines/table-engines/mergetree-family/replacingmergetree.md b/docs/en/engines/table-engines/mergetree-family/replacingmergetree.md\nindex 6de818c130f0..9467da333986 100644\n--- a/docs/en/engines/table-engines/mergetree-family/replacingmergetree.md\n+++ b/docs/en/engines/table-engines/mergetree-family/replacingmergetree.md\n@@ -25,7 +25,7 @@ CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]\n [ORDER BY expr]\n [PRIMARY KEY expr]\n [SAMPLE BY expr]\n-[SETTINGS name=value, clean_deleted_rows=value, ...]\n+[SETTINGS name=value, ...]\n ```\n \n For a description of request parameters, see [statement description](../../../sql-reference/statements/create/table.md).\n@@ -88,53 +88,6 @@ SELECT * FROM mySecondReplacingMT FINAL;\n \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n ```\n \n-### is_deleted\n-\n-`is_deleted` \u2014  Name of a column used during a merge to determine whether the data in this row represents the state or is to be deleted; `1` is a \u201cdeleted\u201c row, `0` is a \u201cstate\u201c row.\n-\n-  Column data type \u2014 `UInt8`.\n-\n-:::note\n-`is_deleted` can only be enabled when `ver` is used.\n-\n-The row is deleted when `OPTIMIZE ... FINAL CLEANUP` or `OPTIMIZE ... FINAL` is used, or if the engine setting `clean_deleted_rows` has been set to `Always`.\n-\n-No matter the operation on the data, the version must be increased. If two inserted rows have the same version number, the last inserted row is the one kept.\n-\n-:::\n-\n-Example:\n-```sql\n--- with ver and is_deleted\n-CREATE OR REPLACE TABLE myThirdReplacingMT\n-(\n-    `key` Int64,\n-    `someCol` String,\n-    `eventTime` DateTime,\n-    `is_deleted` UInt8\n-)\n-ENGINE = ReplacingMergeTree(eventTime, is_deleted)\n-ORDER BY key;\n-\n-INSERT INTO myThirdReplacingMT Values (1, 'first', '2020-01-01 01:01:01', 0);\n-INSERT INTO myThirdReplacingMT Values (1, 'first', '2020-01-01 01:01:01', 1); \n-\n-select * from myThirdReplacingMT final;\n-\n-0 rows in set. Elapsed: 0.003 sec.\n-\n--- delete rows with is_deleted\n-OPTIMIZE TABLE myThirdReplacingMT FINAL CLEANUP; \n-\n-INSERT INTO myThirdReplacingMT Values (1, 'first', '2020-01-01 00:00:00', 0);\n-\n-select * from myThirdReplacingMT final; \n-\n-\u250c\u2500key\u2500\u252c\u2500someCol\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500eventTime\u2500\u252c\u2500is_deleted\u2500\u2510\n-\u2502   1 \u2502 first   \u2502 2020-01-01 00:00:00 \u2502          0 \u2502\n-\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n-```\n-\n ## Query clauses\n \n When creating a `ReplacingMergeTree` table the same [clauses](../../../engines/table-engines/mergetree-family/mergetree.md) are required, as when creating a `MergeTree` table.\ndiff --git a/docs/en/operations/settings/merge-tree-settings.md b/docs/en/operations/settings/merge-tree-settings.md\nindex c7e461d15ae6..da049554c67c 100644\n--- a/docs/en/operations/settings/merge-tree-settings.md\n+++ b/docs/en/operations/settings/merge-tree-settings.md\n@@ -852,16 +852,6 @@ If the file name for column is too long (more than `max_file_name_length` bytes)\n \n The maximal length of the file name to keep it as is without hashing. Takes effect only if setting `replace_long_file_name_to_hash` is enabled. The value of this setting does not include the length of file extension. So, it is recommended to set it below the maximum filename length (usually 255 bytes) with some gap to avoid filesystem errors. Default value: 127.\n \n-## clean_deleted_rows\n-\n-Enable/disable automatic deletion of rows flagged as `is_deleted` when perform `OPTIMIZE ... FINAL` on a table using the ReplacingMergeTree engine. When disabled, the `CLEANUP` keyword has to be added to the `OPTIMIZE ... FINAL` to have the same behaviour.\n-\n-Possible values:\n-\n-- `Always` or `Never`.\n-\n-Default value: `Never`\n-\n ## allow_experimental_block_number_column\n \n Persists virtual column `_block_number` on merges.\ndiff --git a/docs/ru/engines/table-engines/mergetree-family/replacingmergetree.md b/docs/ru/engines/table-engines/mergetree-family/replacingmergetree.md\nindex e8089b2c42b7..c17e7982b98e 100644\n--- a/docs/ru/engines/table-engines/mergetree-family/replacingmergetree.md\n+++ b/docs/ru/engines/table-engines/mergetree-family/replacingmergetree.md\n@@ -86,59 +86,6 @@ SELECT * FROM mySecondReplacingMT FINAL;\n \u2502   1 \u2502 first   \u2502 2020-01-01 01:01:01 \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n ```\n-### is_deleted\n-\n-`is_deleted` \u2014  \u0418\u043c\u044f \u0441\u0442\u043e\u043b\u0431\u0446\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0432\u043e \u0432\u0440\u0435\u043c\u044f \u0441\u043b\u0438\u044f\u043d\u0438\u044f \u0434\u043b\u044f \u043e\u0431\u043e\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0442\u043e\u0433\u043e, \u043d\u0443\u0436\u043d\u043e \u043b\u0438 \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0430\u0442\u044c \u0441\u0442\u0440\u043e\u043a\u0443 \u0438\u043b\u0438 \u043e\u043d\u0430 \u043f\u043e\u0434\u043b\u0435\u0436\u0438\u0442 \u0443\u0434\u0430\u043b\u0435\u043d\u0438\u044e; `1` - \u0434\u043b\u044f \u0443\u0434\u0430\u043b\u0435\u043d\u0438\u044f \u0441\u0442\u0440\u043e\u043a\u0438, `0` - \u0434\u043b\u044f \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441\u0442\u0440\u043e\u043a\u0438.\n-\n-  \u0422\u0438\u043f \u0434\u0430\u043d\u043d\u044b\u0445 \u0441\u0442\u043e\u043b\u0431\u0446\u0430 \u2014 `UInt8`.\n-\n-:::note\n-`is_deleted` \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d, \u0435\u0441\u043b\u0438 `ver` \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f.\n-\n-\u0421\u0442\u0440\u043e\u043a\u0430 \u0443\u0434\u0430\u043b\u044f\u0435\u0442\u0441\u044f \u0432 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0445 \u0441\u043b\u0443\u0447\u0430\u044f\u0445:\n-\n-    - \u043f\u0440\u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438 \u0438\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u0438 `OPTIMIZE ... FINAL CLEANUP`\n-    - \u043f\u0440\u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438 \u0438\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u0438 `OPTIMIZE ... FINAL`\n-    - \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0434\u0432\u0438\u0436\u043a\u0430 `clean_deleted_rows` \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d \u0432 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 `Always` (\u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e - `Never`)\n-    - \u0435\u0441\u0442\u044c \u043d\u043e\u0432\u044b\u0435 \u0432\u0435\u0440\u0441\u0438\u0438 \u0441\u0442\u0440\u043e\u043a\u0438\n-\n-\u041d\u0435 \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u0435\u0442\u0441\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c `FINAL CLEANUP` \u0438\u043b\u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0434\u0432\u0438\u0436\u043a\u0430 `clean_deleted_rows` \u0441\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c `Always`, \u044d\u0442\u043e \u043c\u043e\u0436\u0435\u0442 \u043f\u0440\u0438\u0432\u0435\u0441\u0442\u0438 \u043a \u043d\u0435\u043e\u0436\u0438\u0434\u0430\u043d\u043d\u044b\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430\u043c, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u0443\u0434\u0430\u043b\u0435\u043d\u043d\u044b\u0435 \u0441\u0442\u0440\u043e\u043a\u0438 \u043c\u043e\u0433\u0443\u0442 \u0432\u043d\u043e\u0432\u044c \u043f\u043e\u044f\u0432\u0438\u0442\u044c\u0441\u044f.\n-\n-\u0412\u043d\u0435 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u044b\u0445 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0439 \u043d\u0430\u0434 \u0434\u0430\u043d\u043d\u044b\u043c\u0438, \u0432\u0435\u0440\u0441\u0438\u044f \u0434\u043e\u043b\u0436\u043d\u0430 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0442\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0443 \u0434\u0432\u0443\u0445 \u0441\u0442\u0440\u043e\u043a \u043e\u0434\u043d\u0430 \u0438 \u0442\u0430 \u0436\u0435 \u0432\u0435\u0440\u0441\u0438\u044f, \u0442\u043e \u043e\u0441\u0442\u0430\u0435\u0442\u0441\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u044f\u044f \u0432\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u0430\u044f \u0441\u0442\u0440\u043e\u043a\u0430.\n-:::\n-\n-\u041f\u0440\u0438\u043c\u0435\u0440:\n-\n-```sql\n--- with ver and is_deleted\n-CREATE OR REPLACE TABLE myThirdReplacingMT\n-(\n-    `key` Int64,\n-    `someCol` String,\n-    `eventTime` DateTime,\n-    `is_deleted` UInt8\n-)\n-ENGINE = ReplacingMergeTree(eventTime, is_deleted)\n-ORDER BY key;\n-\n-INSERT INTO myThirdReplacingMT Values (1, 'first', '2020-01-01 01:01:01', 0);\n-INSERT INTO myThirdReplacingMT Values (1, 'first', '2020-01-01 01:01:01', 1); \n-\n-select * from myThirdReplacingMT final;\n-\n-0 rows in set. Elapsed: 0.003 sec.\n-\n--- delete rows with is_deleted\n-OPTIMIZE TABLE myThirdReplacingMT FINAL CLEANUP; \n-\n-INSERT INTO myThirdReplacingMT Values (1, 'first', '2020-01-01 00:00:00', 0);\n-\n-select * from myThirdReplacingMT final; \n-\n-\u250c\u2500key\u2500\u252c\u2500someCol\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500eventTime\u2500\u252c\u2500is_deleted\u2500\u2510\n-\u2502   1 \u2502 first   \u2502 2020-01-01 00:00:00 \u2502          0 \u2502\n-\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n-```\n \n ## \u0421\u0435\u043a\u0446\u0438\u0438 \u0437\u0430\u043f\u0440\u043e\u0441\u0430\n \ndiff --git a/programs/server/config.d/graphite_alternative.xml b/programs/server/config.d/graphite_alternative.xml\nnew file mode 120000\nindex 000000000000..400b9e75f1ff\n--- /dev/null\n+++ b/programs/server/config.d/graphite_alternative.xml\n@@ -0,0 +1,1 @@\n+../../../tests/config/config.d/graphite_alternative.xml\n\\ No newline at end of file\ndiff --git a/src/Core/SettingsEnums.cpp b/src/Core/SettingsEnums.cpp\nindex ee113a6776f1..c35e69977ed4 100644\n--- a/src/Core/SettingsEnums.cpp\n+++ b/src/Core/SettingsEnums.cpp\n@@ -98,8 +98,6 @@ IMPLEMENT_SETTING_AUTO_ENUM(DefaultDatabaseEngine, ErrorCodes::BAD_ARGUMENTS)\n \n IMPLEMENT_SETTING_AUTO_ENUM(DefaultTableEngine, ErrorCodes::BAD_ARGUMENTS)\n \n-IMPLEMENT_SETTING_AUTO_ENUM(CleanDeletedRows, ErrorCodes::BAD_ARGUMENTS)\n-\n IMPLEMENT_SETTING_MULTI_ENUM(MySQLDataTypesSupport, ErrorCodes::UNKNOWN_MYSQL_DATATYPES_SUPPORT_LEVEL,\n     {{\"decimal\",    MySQLDataTypesSupport::DECIMAL},\n      {\"datetime64\", MySQLDataTypesSupport::DATETIME64},\ndiff --git a/src/Core/SettingsEnums.h b/src/Core/SettingsEnums.h\nindex 7977a0b3ab6a..2e71c96b9545 100644\n--- a/src/Core/SettingsEnums.h\n+++ b/src/Core/SettingsEnums.h\n@@ -140,14 +140,6 @@ enum class DefaultTableEngine\n \n DECLARE_SETTING_ENUM(DefaultTableEngine)\n \n-enum class CleanDeletedRows\n-{\n-    Never = 0, /// Disable.\n-    Always,\n-};\n-\n-DECLARE_SETTING_ENUM(CleanDeletedRows)\n-\n enum class MySQLDataTypesSupport\n {\n     DECIMAL, // convert MySQL's decimal and number to ClickHouse Decimal when applicable\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex d10d6ed2630a..3da0e2508a09 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -15,7 +15,6 @@\n #include <Common/thread_local_rng.h>\n #include <Common/FieldVisitorToString.h>\n #include <Common/getMultipleKeysFromConfig.h>\n-#include <Common/getNumberOfPhysicalCPUCores.h>\n #include <Common/callOnce.h>\n #include <Common/SharedLockGuard.h>\n #include <Coordination/KeeperDispatcher.h>\n@@ -33,7 +32,6 @@\n #include <Storages/StorageS3Settings.h>\n #include <Disks/DiskLocal.h>\n #include <Disks/ObjectStorages/DiskObjectStorage.h>\n-#include <Disks/ObjectStorages/IObjectStorage.h>\n #include <Disks/StoragePolicy.h>\n #include <Disks/IO/IOUringReader.h>\n #include <IO/SynchronousReader.h>\n@@ -45,7 +43,6 @@\n #include <Interpreters/Cache/FileCacheFactory.h>\n #include <Interpreters/SessionTracker.h>\n #include <Core/ServerSettings.h>\n-#include <Interpreters/PreparedSets.h>\n #include <Core/Settings.h>\n #include <Core/SettingsQuirks.h>\n #include <Access/AccessControl.h>\ndiff --git a/src/Interpreters/InterpreterOptimizeQuery.cpp b/src/Interpreters/InterpreterOptimizeQuery.cpp\nindex ae456e8b31de..6be78deb8975 100644\n--- a/src/Interpreters/InterpreterOptimizeQuery.cpp\n+++ b/src/Interpreters/InterpreterOptimizeQuery.cpp\n@@ -79,7 +79,7 @@ BlockIO InterpreterOptimizeQuery::execute()\n     if (auto * snapshot_data = dynamic_cast<MergeTreeData::SnapshotData *>(storage_snapshot->data.get()))\n         snapshot_data->parts = {};\n \n-    table->optimize(query_ptr, metadata_snapshot, ast.partition, ast.final, ast.deduplicate, column_names, ast.cleanup, getContext());\n+    table->optimize(query_ptr, metadata_snapshot, ast.partition, ast.final, ast.deduplicate, column_names, getContext());\n \n     return {};\n }\ndiff --git a/src/Parsers/ASTOptimizeQuery.cpp b/src/Parsers/ASTOptimizeQuery.cpp\nindex 173310f79309..720c7699fb6b 100644\n--- a/src/Parsers/ASTOptimizeQuery.cpp\n+++ b/src/Parsers/ASTOptimizeQuery.cpp\n@@ -24,9 +24,6 @@ void ASTOptimizeQuery::formatQueryImpl(const FormatSettings & settings, FormatSt\n     if (deduplicate)\n         settings.ostr << (settings.hilite ? hilite_keyword : \"\") << \" DEDUPLICATE\" << (settings.hilite ? hilite_none : \"\");\n \n-    if (cleanup)\n-        settings.ostr << (settings.hilite ? hilite_keyword : \"\") << \" CLEANUP\" << (settings.hilite ? hilite_none : \"\");\n-\n     if (deduplicate_by_columns)\n     {\n         settings.ostr << (settings.hilite ? hilite_keyword : \"\") << \" BY \" << (settings.hilite ? hilite_none : \"\");\ndiff --git a/src/Parsers/ASTOptimizeQuery.h b/src/Parsers/ASTOptimizeQuery.h\nindex 4c914c119120..584b2f38fe64 100644\n--- a/src/Parsers/ASTOptimizeQuery.h\n+++ b/src/Parsers/ASTOptimizeQuery.h\n@@ -21,12 +21,10 @@ class ASTOptimizeQuery : public ASTQueryWithTableAndOutput, public ASTQueryWithO\n     bool deduplicate = false;\n     /// Deduplicate by columns.\n     ASTPtr deduplicate_by_columns;\n-    /// Delete 'is_deleted' data\n-    bool cleanup = false;\n     /** Get the text that identifies this element. */\n     String getID(char delim) const override\n     {\n-        return \"OptimizeQuery\" + (delim + getDatabase()) + delim + getTable() + (final ? \"_final\" : \"\") + (deduplicate ? \"_deduplicate\" : \"\")+ (cleanup ? \"_cleanup\" : \"\");\n+        return \"OptimizeQuery\" + (delim + getDatabase()) + delim + getTable() + (final ? \"_final\" : \"\") + (deduplicate ? \"_deduplicate\" : \"\");\n     }\n \n     ASTPtr clone() const override\ndiff --git a/src/Parsers/ParserOptimizeQuery.cpp b/src/Parsers/ParserOptimizeQuery.cpp\nindex e887ff445d29..826fbf38b362 100644\n--- a/src/Parsers/ParserOptimizeQuery.cpp\n+++ b/src/Parsers/ParserOptimizeQuery.cpp\n@@ -28,7 +28,6 @@ bool ParserOptimizeQuery::parseImpl(Pos & pos, ASTPtr & node, Expected & expecte\n     ParserKeyword s_partition(\"PARTITION\");\n     ParserKeyword s_final(\"FINAL\");\n     ParserKeyword s_deduplicate(\"DEDUPLICATE\");\n-    ParserKeyword s_cleanup(\"CLEANUP\");\n     ParserKeyword s_by(\"BY\");\n     ParserToken s_dot(TokenType::Dot);\n     ParserIdentifier name_p(true);\n@@ -39,7 +38,6 @@ bool ParserOptimizeQuery::parseImpl(Pos & pos, ASTPtr & node, Expected & expecte\n     ASTPtr partition;\n     bool final = false;\n     bool deduplicate = false;\n-    bool cleanup = false;\n     String cluster_str;\n \n     if (!s_optimize_table.ignore(pos, expected))\n@@ -70,9 +68,6 @@ bool ParserOptimizeQuery::parseImpl(Pos & pos, ASTPtr & node, Expected & expecte\n     if (s_deduplicate.ignore(pos, expected))\n         deduplicate = true;\n \n-    if (s_cleanup.ignore(pos, expected))\n-        cleanup = true;\n-\n     ASTPtr deduplicate_by_columns;\n     if (deduplicate && s_by.ignore(pos, expected))\n     {\n@@ -90,7 +85,6 @@ bool ParserOptimizeQuery::parseImpl(Pos & pos, ASTPtr & node, Expected & expecte\n     query->final = final;\n     query->deduplicate = deduplicate;\n     query->deduplicate_by_columns = deduplicate_by_columns;\n-    query->cleanup = cleanup;\n     query->database = database;\n     query->table = table;\n \ndiff --git a/src/Processors/Merges/Algorithms/ReplacingSortedAlgorithm.cpp b/src/Processors/Merges/Algorithms/ReplacingSortedAlgorithm.cpp\nindex 0c0598171b31..139ccd815d23 100644\n--- a/src/Processors/Merges/Algorithms/ReplacingSortedAlgorithm.cpp\n+++ b/src/Processors/Merges/Algorithms/ReplacingSortedAlgorithm.cpp\n@@ -3,33 +3,22 @@\n #include <Columns/ColumnsNumber.h>\n #include <IO/WriteBuffer.h>\n \n-namespace DB\n-{\n \n-namespace ErrorCodes\n+namespace DB\n {\n-    extern const int INCORRECT_DATA;\n-}\n \n ReplacingSortedAlgorithm::ReplacingSortedAlgorithm(\n     const Block & header_,\n     size_t num_inputs,\n     SortDescription description_,\n-    const String & is_deleted_column,\n     const String & version_column,\n     size_t max_block_size_rows,\n     size_t max_block_size_bytes,\n     WriteBuffer * out_row_sources_buf_,\n-    bool use_average_block_sizes,\n-    bool cleanup_,\n-    size_t * cleanedup_rows_count_)\n+    bool use_average_block_sizes)\n     : IMergingAlgorithmWithSharedChunks(header_, num_inputs, std::move(description_), out_row_sources_buf_, max_row_refs)\n     , merged_data(header_.cloneEmptyColumns(), use_average_block_sizes, max_block_size_rows, max_block_size_bytes)\n-    , cleanup(cleanup_)\n-    , cleanedup_rows_count(cleanedup_rows_count_)\n {\n-    if (!is_deleted_column.empty())\n-        is_deleted_column_number = header_.getPositionByName(is_deleted_column);\n     if (!version_column.empty())\n         version_column_number = header_.getPositionByName(version_column);\n }\n@@ -76,21 +65,7 @@ IMergingAlgorithm::Status ReplacingSortedAlgorithm::merge()\n \n             /// Write the data for the previous primary key.\n             if (!selected_row.empty())\n-            {\n-                if (is_deleted_column_number != -1)\n-                {\n-                    uint8_t value = assert_cast<const ColumnUInt8 &>(*(*selected_row.all_columns)[is_deleted_column_number]).getData()[selected_row.row_num];\n-                    if (!cleanup || !value)\n-                        insertRow();\n-                    else if (cleanup && cleanedup_rows_count != nullptr)\n-                    {\n-                        *cleanedup_rows_count += current_row_sources.size();\n-                        current_row_sources.resize(0);\n-                    }\n-                }\n-                else\n-                    insertRow();\n-            }\n+                insertRow();\n \n             selected_row.clear();\n         }\n@@ -100,13 +75,6 @@ IMergingAlgorithm::Status ReplacingSortedAlgorithm::merge()\n         if (out_row_sources_buf)\n             current_row_sources.emplace_back(current.impl->order, true);\n \n-        if (is_deleted_column_number != -1)\n-        {\n-            const UInt8 is_deleted = assert_cast<const ColumnUInt8 &>(*current->all_columns[is_deleted_column_number]).getData()[current->getRow()];\n-            if ((is_deleted != 1) && (is_deleted != 0))\n-                throw Exception(ErrorCodes::INCORRECT_DATA, \"Incorrect data: is_deleted = {} (must be 1 or 0).\", toString(is_deleted));\n-        }\n-\n         /// A non-strict comparison, since we select the last row for the same version values.\n         if (version_column_number == -1\n             || selected_row.empty()\n@@ -137,21 +105,7 @@ IMergingAlgorithm::Status ReplacingSortedAlgorithm::merge()\n \n     /// We will write the data for the last primary key.\n     if (!selected_row.empty())\n-    {\n-        if (is_deleted_column_number != -1)\n-        {\n-            uint8_t value = assert_cast<const ColumnUInt8 &>(*(*selected_row.all_columns)[is_deleted_column_number]).getData()[selected_row.row_num];\n-            if (!cleanup || !value)\n-                insertRow();\n-            else if (cleanup && cleanedup_rows_count != nullptr)\n-            {\n-                *cleanedup_rows_count += current_row_sources.size();\n-                current_row_sources.resize(0);\n-            }\n-        }\n-        else\n-            insertRow();\n-    }\n+        insertRow();\n \n     return Status(merged_data.pull(), true);\n }\ndiff --git a/src/Processors/Merges/Algorithms/ReplacingSortedAlgorithm.h b/src/Processors/Merges/Algorithms/ReplacingSortedAlgorithm.h\nindex b2258918fde5..2295d1c35d16 100644\n--- a/src/Processors/Merges/Algorithms/ReplacingSortedAlgorithm.h\n+++ b/src/Processors/Merges/Algorithms/ReplacingSortedAlgorithm.h\n@@ -21,14 +21,11 @@ class ReplacingSortedAlgorithm final : public IMergingAlgorithmWithSharedChunks\n     ReplacingSortedAlgorithm(\n         const Block & header, size_t num_inputs,\n         SortDescription description_,\n-        const String & is_deleted_column,\n         const String & version_column,\n         size_t max_block_size_rows,\n         size_t max_block_size_bytes,\n         WriteBuffer * out_row_sources_buf_ = nullptr,\n-        bool use_average_block_sizes = false,\n-        bool cleanup = false,\n-        size_t * cleanedup_rows_count = nullptr);\n+        bool use_average_block_sizes = false);\n \n     const char * getName() const override { return \"ReplacingSortedAlgorithm\"; }\n     Status merge() override;\n@@ -36,10 +33,7 @@ class ReplacingSortedAlgorithm final : public IMergingAlgorithmWithSharedChunks\n private:\n     MergedData merged_data;\n \n-    ssize_t is_deleted_column_number = -1;\n     ssize_t version_column_number = -1;\n-    bool cleanup = false;\n-    size_t * cleanedup_rows_count = nullptr;\n \n     using RowRef = detail::RowRefWithOwnedChunk;\n     static constexpr size_t max_row_refs = 2; /// last, current.\ndiff --git a/src/Processors/Merges/ReplacingSortedTransform.h b/src/Processors/Merges/ReplacingSortedTransform.h\nindex 7e293db1aa8a..8d25d153cb43 100644\n--- a/src/Processors/Merges/ReplacingSortedTransform.h\n+++ b/src/Processors/Merges/ReplacingSortedTransform.h\n@@ -14,26 +14,21 @@ class ReplacingSortedTransform final : public IMergingTransform<ReplacingSortedA\n     ReplacingSortedTransform(\n         const Block & header, size_t num_inputs,\n         SortDescription description_,\n-        const String & is_deleted_column, const String & version_column,\n+        const String & version_column,\n         size_t max_block_size_rows,\n         size_t max_block_size_bytes,\n         WriteBuffer * out_row_sources_buf_ = nullptr,\n-        bool use_average_block_sizes = false,\n-        bool cleanup = false,\n-        size_t * cleanedup_rows_count = nullptr)\n+        bool use_average_block_sizes = false)\n         : IMergingTransform(\n             num_inputs, header, header, /*have_all_inputs_=*/ true, /*limit_hint_=*/ 0, /*always_read_till_end_=*/ false,\n             header,\n             num_inputs,\n             std::move(description_),\n-            is_deleted_column,\n             version_column,\n             max_block_size_rows,\n             max_block_size_bytes,\n             out_row_sources_buf_,\n-            use_average_block_sizes,\n-            cleanup,\n-            cleanedup_rows_count)\n+            use_average_block_sizes)\n     {\n     }\n \ndiff --git a/src/Processors/QueryPlan/ReadFromMergeTree.cpp b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\nindex 2ceb0f2dc7fc..875b0d9bdbc1 100644\n--- a/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n+++ b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n@@ -1025,7 +1025,7 @@ static void addMergingFinal(\n \n             case MergeTreeData::MergingParams::Replacing:\n                 return std::make_shared<ReplacingSortedTransform>(header, num_outputs,\n-                            sort_description, merging_params.is_deleted_column, merging_params.version_column, max_block_size_rows, /*max_block_size_bytes=*/0, /*out_row_sources_buf_*/ nullptr, /*use_average_block_sizes*/ false, /*cleanup*/ !merging_params.is_deleted_column.empty());\n+                            sort_description, merging_params.version_column, max_block_size_rows, /*max_block_size_bytes=*/0, /*out_row_sources_buf_*/ nullptr, /*use_average_block_sizes*/ false);\n \n             case MergeTreeData::MergingParams::VersionedCollapsing:\n                 return std::make_shared<VersionedCollapsingTransform>(header, num_outputs,\n@@ -1099,8 +1099,7 @@ Pipe ReadFromMergeTree::spreadMarkRangesAmongStreamsFinal(\n         /// can use parallel select on such parts.\n         bool no_merging_final = settings.do_not_merge_across_partitions_select_final &&\n             std::distance(parts_to_merge_ranges[range_index], parts_to_merge_ranges[range_index + 1]) == 1 &&\n-            parts_to_merge_ranges[range_index]->data_part->info.level > 0 &&\n-            data.merging_params.is_deleted_column.empty();\n+            parts_to_merge_ranges[range_index]->data_part->info.level > 0;\n         Pipes pipes;\n         {\n             RangesInDataParts new_parts;\n@@ -1837,8 +1836,6 @@ Pipe ReadFromMergeTree::spreadMarkRanges(\n             }\n         }\n \n-        if (!data.merging_params.is_deleted_column.empty() && !names.contains(data.merging_params.is_deleted_column))\n-            column_names_to_read.push_back(data.merging_params.is_deleted_column);\n         if (!data.merging_params.sign_column.empty() && !names.contains(data.merging_params.sign_column))\n             column_names_to_read.push_back(data.merging_params.sign_column);\n         if (!data.merging_params.version_column.empty() && !names.contains(data.merging_params.version_column))\ndiff --git a/src/Storages/IStorage.h b/src/Storages/IStorage.h\nindex 2a705b801dae..428a4e5c24b5 100644\n--- a/src/Storages/IStorage.h\n+++ b/src/Storages/IStorage.h\n@@ -515,7 +515,6 @@ class IStorage : public std::enable_shared_from_this<IStorage>, public TypePromo\n         bool /*final*/,\n         bool /*deduplicate*/,\n         const Names & /* deduplicate_by_columns */,\n-        bool /*cleanup*/,\n         ContextPtr /*context*/)\n     {\n         throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method optimize is not supported by storage {}\", getName());\ndiff --git a/src/Storages/MergeTree/MergeFromLogEntryTask.cpp b/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\nindex 3d8bc62b5cc3..9be31859a193 100644\n--- a/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\n+++ b/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\n@@ -312,7 +312,6 @@ ReplicatedMergeMutateTaskBase::PrepareResult MergeFromLogEntryTask::prepare()\n             reserved_space,\n             entry.deduplicate,\n             entry.deduplicate_by_columns,\n-            entry.cleanup,\n             storage.merging_params,\n             NO_TRANSACTION_PTR);\n \ndiff --git a/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp b/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp\nindex c218acce903c..aed9f70d2167 100644\n--- a/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp\n+++ b/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp\n@@ -131,7 +131,6 @@ void MergePlainMergeTreeTask::prepare()\n             merge_mutate_entry->tagger->reserved_space,\n             deduplicate,\n             deduplicate_by_columns,\n-            cleanup,\n             storage.merging_params,\n             txn);\n }\ndiff --git a/src/Storages/MergeTree/MergePlainMergeTreeTask.h b/src/Storages/MergeTree/MergePlainMergeTreeTask.h\nindex 5cc9c0e50d36..2c93f9c9e2c5 100644\n--- a/src/Storages/MergeTree/MergePlainMergeTreeTask.h\n+++ b/src/Storages/MergeTree/MergePlainMergeTreeTask.h\n@@ -20,7 +20,6 @@ class MergePlainMergeTreeTask : public IExecutableTask\n         StorageMetadataPtr metadata_snapshot_,\n         bool deduplicate_,\n         Names deduplicate_by_columns_,\n-        bool cleanup_,\n         MergeMutateSelectedEntryPtr merge_mutate_entry_,\n         TableLockHolder table_lock_holder_,\n         IExecutableTask::TaskResultCallback & task_result_callback_)\n@@ -28,7 +27,6 @@ class MergePlainMergeTreeTask : public IExecutableTask\n         , metadata_snapshot(std::move(metadata_snapshot_))\n         , deduplicate(deduplicate_)\n         , deduplicate_by_columns(std::move(deduplicate_by_columns_))\n-        , cleanup(cleanup_)\n         , merge_mutate_entry(std::move(merge_mutate_entry_))\n         , table_lock_holder(std::move(table_lock_holder_))\n         , task_result_callback(task_result_callback_)\n@@ -69,7 +67,6 @@ class MergePlainMergeTreeTask : public IExecutableTask\n     StorageMetadataPtr metadata_snapshot;\n     bool deduplicate;\n     Names deduplicate_by_columns;\n-    bool cleanup;\n     MergeMutateSelectedEntryPtr merge_mutate_entry{nullptr};\n     TableLockHolder table_lock_holder;\n     FutureMergedMutatedPartPtr future_part{nullptr};\ndiff --git a/src/Storages/MergeTree/MergeTask.cpp b/src/Storages/MergeTree/MergeTask.cpp\nindex 822b3ae72a58..4609df203b9d 100644\n--- a/src/Storages/MergeTree/MergeTask.cpp\n+++ b/src/Storages/MergeTree/MergeTask.cpp\n@@ -68,10 +68,7 @@ static void extractMergingAndGatheringColumns(\n \n     /// Force version column for Replacing mode\n     if (merging_params.mode == MergeTreeData::MergingParams::Replacing)\n-    {\n-        key_columns.emplace(merging_params.is_deleted_column);\n         key_columns.emplace(merging_params.version_column);\n-    }\n \n     /// Force sign column for VersionedCollapsing mode. Version is already in primary key.\n     if (merging_params.mode == MergeTreeData::MergingParams::VersionedCollapsing)\n@@ -496,7 +493,6 @@ bool MergeTask::VerticalMergeStage::prepareVerticalMergeForAllColumns() const\n \n     size_t sum_input_rows_exact = global_ctx->merge_list_element_ptr->rows_read;\n     size_t input_rows_filtered = *global_ctx->input_rows_filtered;\n-    size_t cleanedup_rows_count = global_ctx->cleanedup_rows_count;\n     global_ctx->merge_list_element_ptr->columns_written = global_ctx->merging_column_names.size();\n     global_ctx->merge_list_element_ptr->progress.store(ctx->column_sizes->keyColumnsWeight(), std::memory_order_relaxed);\n \n@@ -510,12 +506,12 @@ bool MergeTask::VerticalMergeStage::prepareVerticalMergeForAllColumns() const\n     /// skipped writing rows_sources file. Otherwise rows_sources_count must be equal to the total\n     /// number of input rows.\n     if ((rows_sources_count > 0 || global_ctx->future_part->parts.size() > 1)\n-        && sum_input_rows_exact != rows_sources_count + input_rows_filtered + cleanedup_rows_count)\n+        && sum_input_rows_exact != rows_sources_count + input_rows_filtered)\n         throw Exception(\n             ErrorCodes::LOGICAL_ERROR,\n-            \"Number of rows in source parts ({}) excluding filtered rows ({}) and cleaned up rows ({}) differs from number \"\n+            \"Number of rows in source parts ({}) excluding filtered rows ({}) differs from number \"\n             \"of bytes written to rows_sources file ({}). It is a bug.\",\n-            sum_input_rows_exact, input_rows_filtered, cleanedup_rows_count, rows_sources_count);\n+            sum_input_rows_exact, input_rows_filtered, rows_sources_count);\n \n     /// TemporaryDataOnDisk::createRawStream returns WriteBufferFromFile implementing IReadableWriteBuffer\n     /// and we expect to get ReadBufferFromFile here.\n@@ -757,7 +753,6 @@ bool MergeTask::MergeProjectionsStage::mergeMinMaxIndexAndPrepareProjections() c\n             global_ctx->space_reservation,\n             global_ctx->deduplicate,\n             global_ctx->deduplicate_by_columns,\n-            global_ctx->cleanup,\n             projection_merging_params,\n             global_ctx->need_prefix,\n             global_ctx->new_data_part.get(),\n@@ -1004,9 +999,8 @@ void MergeTask::ExecuteAndFinalizeHorizontalPart::createMergedStream()\n \n         case MergeTreeData::MergingParams::Replacing:\n             merged_transform = std::make_shared<ReplacingSortedTransform>(\n-                header, pipes.size(), sort_description, ctx->merging_params.is_deleted_column, ctx->merging_params.version_column,\n-                merge_block_size_rows, merge_block_size_bytes, ctx->rows_sources_write_buf.get(), ctx->blocks_are_granules_size,\n-                (data_settings->clean_deleted_rows != CleanDeletedRows::Never) || global_ctx->cleanup, &global_ctx->cleanedup_rows_count);\n+                header, pipes.size(), sort_description, ctx->merging_params.version_column,\n+                merge_block_size_rows, merge_block_size_bytes, ctx->rows_sources_write_buf.get(), ctx->blocks_are_granules_size);\n             break;\n \n         case MergeTreeData::MergingParams::Graphite:\ndiff --git a/src/Storages/MergeTree/MergeTask.h b/src/Storages/MergeTree/MergeTask.h\nindex 8a96ceb8c400..aeede44fe881 100644\n--- a/src/Storages/MergeTree/MergeTask.h\n+++ b/src/Storages/MergeTree/MergeTask.h\n@@ -67,7 +67,6 @@ class MergeTask\n         ReservationSharedPtr space_reservation_,\n         bool deduplicate_,\n         Names deduplicate_by_columns_,\n-        bool cleanup_,\n         MergeTreeData::MergingParams merging_params_,\n         bool need_prefix,\n         IMergeTreeDataPart * parent_part_,\n@@ -91,7 +90,6 @@ class MergeTask\n             global_ctx->space_reservation = std::move(space_reservation_);\n             global_ctx->deduplicate = std::move(deduplicate_);\n             global_ctx->deduplicate_by_columns = std::move(deduplicate_by_columns_);\n-            global_ctx->cleanup = std::move(cleanup_);\n             global_ctx->parent_part = std::move(parent_part_);\n             global_ctx->data = std::move(data_);\n             global_ctx->mutator = std::move(mutator_);\n@@ -160,8 +158,6 @@ class MergeTask\n         ReservationSharedPtr space_reservation{nullptr};\n         bool deduplicate{false};\n         Names deduplicate_by_columns{};\n-        bool cleanup{false};\n-        size_t cleanedup_rows_count{0};\n \n         NamesAndTypesList gathering_columns{};\n         NamesAndTypesList merging_columns{};\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex d0c22e4e2b53..a47ad41016c9 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -846,10 +846,6 @@ void MergeTreeData::MergingParams::check(const StorageInMemoryMetadata & metadat\n {\n     const auto columns = metadata.getColumns().getAllPhysical();\n \n-    if (!is_deleted_column.empty() && mode != MergingParams::Replacing)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR,\n-                        \"is_deleted column for MergeTree cannot be specified in modes except Replacing.\");\n-\n     if (!sign_column.empty() && mode != MergingParams::Collapsing && mode != MergingParams::VersionedCollapsing)\n         throw Exception(ErrorCodes::LOGICAL_ERROR,\n                         \"Sign column for MergeTree cannot be specified \"\n@@ -919,41 +915,6 @@ void MergeTreeData::MergingParams::check(const StorageInMemoryMetadata & metadat\n             throw Exception(ErrorCodes::NO_SUCH_COLUMN_IN_TABLE, \"Version column {} does not exist in table declaration.\", version_column);\n     };\n \n-    /// Check that if the is_deleted column is needed, it exists and is of type UInt8. If exist, version column must be defined too but version checks are not done here.\n-    auto check_is_deleted_column = [this, & columns](bool is_optional, const std::string & storage)\n-    {\n-        if (is_deleted_column.empty())\n-        {\n-            if (is_optional)\n-                return;\n-\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: is_deleted ({}) column for storage {} is empty\", is_deleted_column, storage);\n-        }\n-        else\n-        {\n-            if (version_column.empty() && !is_optional)\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: Version column ({}) for storage {} is empty while is_deleted ({}) is not.\",\n-                                version_column, storage, is_deleted_column);\n-\n-            bool miss_is_deleted_column = true;\n-            for (const auto & column : columns)\n-            {\n-                if (column.name == is_deleted_column)\n-                {\n-                    if (!typeid_cast<const DataTypeUInt8 *>(column.type.get()))\n-                        throw Exception(ErrorCodes::BAD_TYPE_OF_FIELD, \"is_deleted column ({}) for storage {} must have type UInt8. Provided column of type {}.\",\n-                                        is_deleted_column, storage, column.type->getName());\n-                    miss_is_deleted_column = false;\n-                    break;\n-                }\n-            }\n-\n-            if (miss_is_deleted_column)\n-                throw Exception(ErrorCodes::NO_SUCH_COLUMN_IN_TABLE, \"is_deleted column {} does not exist in table declaration.\", is_deleted_column);\n-        }\n-    };\n-\n-\n     if (mode == MergingParams::Collapsing)\n         check_sign_column(false, \"CollapsingMergeTree\");\n \n@@ -990,7 +951,6 @@ void MergeTreeData::MergingParams::check(const StorageInMemoryMetadata & metadat\n \n     if (mode == MergingParams::Replacing)\n     {\n-        check_is_deleted_column(true, \"ReplacingMergeTree\");\n         check_version_column(true, \"ReplacingMergeTree\");\n     }\n \ndiff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h\nindex b3dd895d6974..7022ffba3055 100644\n--- a/src/Storages/MergeTree/MergeTreeData.h\n+++ b/src/Storages/MergeTree/MergeTreeData.h\n@@ -345,9 +345,6 @@ class MergeTreeData : public IStorage, public WithMutableContext\n         /// For Collapsing and VersionedCollapsing mode.\n         String sign_column;\n \n-        /// For Replacing mode. Can be empty for Replacing.\n-        String is_deleted_column;\n-\n         /// For Summing mode. If empty - columns_to_sum is determined automatically.\n         Names columns_to_sum;\n \ndiff --git a/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp b/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\nindex f78b383e1732..42f480ed18a4 100644\n--- a/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\n@@ -676,7 +676,6 @@ MergeTaskPtr MergeTreeDataMergerMutator::mergePartsToTemporaryPart(\n     ReservationSharedPtr space_reservation,\n     bool deduplicate,\n     const Names & deduplicate_by_columns,\n-    bool cleanup,\n     const MergeTreeData::MergingParams & merging_params,\n     const MergeTreeTransactionPtr & txn,\n     bool need_prefix,\n@@ -693,7 +692,6 @@ MergeTaskPtr MergeTreeDataMergerMutator::mergePartsToTemporaryPart(\n         space_reservation,\n         deduplicate,\n         deduplicate_by_columns,\n-        cleanup,\n         merging_params,\n         need_prefix,\n         parent_part,\ndiff --git a/src/Storages/MergeTree/MergeTreeDataMergerMutator.h b/src/Storages/MergeTree/MergeTreeDataMergerMutator.h\nindex 6eab0ee0c371..5e8a89c94a41 100644\n--- a/src/Storages/MergeTree/MergeTreeDataMergerMutator.h\n+++ b/src/Storages/MergeTree/MergeTreeDataMergerMutator.h\n@@ -165,7 +165,6 @@ class MergeTreeDataMergerMutator\n         ReservationSharedPtr space_reservation,\n         bool deduplicate,\n         const Names & deduplicate_by_columns,\n-        bool cleanup,\n         const MergeTreeData::MergingParams & merging_params,\n         const MergeTreeTransactionPtr & txn,\n         bool need_prefix = true,\ndiff --git a/src/Storages/MergeTree/MergeTreeDataWriter.cpp b/src/Storages/MergeTree/MergeTreeDataWriter.cpp\nindex 2a381afa8053..f63394a4d485 100644\n--- a/src/Storages/MergeTree/MergeTreeDataWriter.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataWriter.cpp\n@@ -325,7 +325,7 @@ Block MergeTreeDataWriter::mergeBlock(\n                 return nullptr;\n             case MergeTreeData::MergingParams::Replacing:\n                 return std::make_shared<ReplacingSortedAlgorithm>(\n-                    block, 1, sort_description, merging_params.is_deleted_column, merging_params.version_column, block_size + 1, /*block_size_bytes=*/0);\n+                    block, 1, sort_description, merging_params.version_column, block_size + 1, /*block_size_bytes=*/0);\n             case MergeTreeData::MergingParams::Collapsing:\n                 return std::make_shared<CollapsingSortedAlgorithm>(\n                     block, 1, sort_description, merging_params.sign_column,\ndiff --git a/src/Storages/MergeTree/MergeTreeSettings.h b/src/Storages/MergeTree/MergeTreeSettings.h\nindex 2a73668715da..d69fd289ac0e 100644\n--- a/src/Storages/MergeTree/MergeTreeSettings.h\n+++ b/src/Storages/MergeTree/MergeTreeSettings.h\n@@ -73,7 +73,6 @@ struct Settings;\n     M(Bool, min_age_to_force_merge_on_partition_only, false, \"Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.\", false) \\\n     M(UInt64, number_of_free_entries_in_pool_to_execute_optimize_entire_partition, 25, \"When there is less than specified number of free entries in pool, do not try to execute optimize entire partition with a merge (this merge is created when set min_age_to_force_merge_seconds > 0 and min_age_to_force_merge_on_partition_only = true). This is to leave free threads for regular merges and avoid \\\"Too many parts\\\"\", 0) \\\n     M(Bool, remove_rolled_back_parts_immediately, 1, \"Setting for an incomplete experimental feature.\", 0) \\\n-    M(CleanDeletedRows, clean_deleted_rows, CleanDeletedRows::Never, \"Is the Replicated Merge cleanup has to be done automatically at each merge or manually (possible values are 'Always'/'Never' (default))\", 0) \\\n     M(UInt64, replicated_max_mutations_in_one_entry, 10000, \"Max number of mutation commands that can be merged together and executed in one MUTATE_PART entry (0 means unlimited)\", 0) \\\n     M(UInt64, number_of_mutations_to_delay, 500, \"If table has at least that many unfinished mutations, artificially slow down mutations of table. Disabled if set to 0\", 0) \\\n     M(UInt64, number_of_mutations_to_throw, 1000, \"If table has at least that many unfinished mutations, throw 'Too many mutations' exception. Disabled if set to 0\", 0) \\\n@@ -232,7 +231,8 @@ struct Settings;\n     MAKE_OBSOLETE_MERGE_TREE_SETTING(M, Bool, use_metadata_cache, false) \\\n     MAKE_OBSOLETE_MERGE_TREE_SETTING(M, UInt64, merge_tree_enable_clear_old_broken_detached, 0) \\\n     MAKE_OBSOLETE_MERGE_TREE_SETTING(M, UInt64, merge_tree_clear_old_broken_detached_parts_ttl_timeout_seconds, 1ULL * 3600 * 24 * 30) \\\n-    MAKE_OBSOLETE_MERGE_TREE_SETTING(M, UInt64, async_block_ids_cache_min_update_interval_ms, 1000) \\\n+    MAKE_OBSOLETE_MERGE_TREE_SETTING(M, UInt64, async_block_ids_cache_min_update_interval_ms, 1000)   \\\n+    MAKE_OBSOLETE_MERGE_TREE_SETTING(M, String, clean_deleted_rows, \"\") \\\n \n     /// Settings that should not change after the creation of a table.\n     /// NOLINTNEXTLINE\ndiff --git a/src/Storages/MergeTree/MutateTask.cpp b/src/Storages/MergeTree/MutateTask.cpp\nindex ab4fb7efd88b..827749aa0941 100644\n--- a/src/Storages/MergeTree/MutateTask.cpp\n+++ b/src/Storages/MergeTree/MutateTask.cpp\n@@ -1050,7 +1050,6 @@ class MergeProjectionPartsTask : public IExecutableTask\n                 ctx->space_reservation,\n                 false, // TODO Do we need deduplicate for projections\n                 {},\n-                false, // no cleanup\n                 projection_merging_params,\n                 NO_TRANSACTION_PTR,\n                 /* need_prefix */ true,\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeLogEntry.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeLogEntry.cpp\nindex 9eb8b6ce24c3..85f99e3f8c3f 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeLogEntry.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeLogEntry.cpp\n@@ -96,9 +96,6 @@ void ReplicatedMergeTreeLogEntryData::writeText(WriteBuffer & out) const\n                 }\n             }\n \n-            if (cleanup)\n-                out << \"\\ncleanup: \" << cleanup;\n-\n             break;\n \n         case DROP_RANGE:\n@@ -272,8 +269,6 @@ void ReplicatedMergeTreeLogEntryData::readText(ReadBuffer & in, MergeTreeDataFor\n \n                     deduplicate_by_columns = std::move(new_deduplicate_by_columns);\n                 }\n-                else if (checkString(\"cleanup: \", in))\n-                    in >> cleanup;\n                 else\n                     trailing_newline_found = true;\n             }\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeLogEntry.h b/src/Storages/MergeTree/ReplicatedMergeTreeLogEntry.h\nindex 0ce59b18818f..4821a80a29be 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeLogEntry.h\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeLogEntry.h\n@@ -98,7 +98,6 @@ struct ReplicatedMergeTreeLogEntryData\n     Strings source_parts;\n     bool deduplicate = false; /// Do deduplicate on merge\n     Strings deduplicate_by_columns = {}; // Which columns should be checked for duplicates, empty means 'all' (default).\n-    bool cleanup = false;\n     MergeType merge_type = MergeType::Regular;\n     String column_name;\n     String index_name;\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeTableMetadata.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeTableMetadata.cpp\nindex 41188891118e..eec5454f9a79 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeTableMetadata.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeTableMetadata.cpp\n@@ -52,7 +52,6 @@ ReplicatedMergeTreeTableMetadata::ReplicatedMergeTreeTableMetadata(const MergeTr\n     index_granularity = data_settings->index_granularity;\n     merging_params_mode = static_cast<int>(data.merging_params.mode);\n     sign_column = data.merging_params.sign_column;\n-    is_deleted_column = data.merging_params.is_deleted_column;\n     columns_to_sum = fmt::format(\"{}\", fmt::join(data.merging_params.columns_to_sum.begin(), data.merging_params.columns_to_sum.end(), \",\"));\n     version_column = data.merging_params.version_column;\n     if (data.merging_params.mode == MergeTreeData::MergingParams::Graphite)\n@@ -157,8 +156,6 @@ void ReplicatedMergeTreeTableMetadata::write(WriteBuffer & out) const\n         out << \"merge parameters format version: \" << merge_params_version << \"\\n\";\n         if (!version_column.empty())\n             out << \"version column: \" << version_column << \"\\n\";\n-        if (!is_deleted_column.empty())\n-            out << \"is_deleted column: \" << is_deleted_column << \"\\n\";\n         if (!columns_to_sum.empty())\n             out << \"columns to sum: \" << columns_to_sum << \"\\n\";\n         if (!graphite_params_hash.empty())\n@@ -224,9 +221,6 @@ void ReplicatedMergeTreeTableMetadata::read(ReadBuffer & in)\n         if (checkString(\"version column: \", in))\n             in >> version_column >> \"\\n\";\n \n-        if (checkString(\"is_deleted column: \", in))\n-            in >> is_deleted_column >> \"\\n\";\n-\n         if (checkString(\"columns to sum: \", in))\n             in >> columns_to_sum >> \"\\n\";\n \n@@ -279,10 +273,6 @@ void ReplicatedMergeTreeTableMetadata::checkImmutableFieldsEquals(const Replicat\n             throw Exception(ErrorCodes::METADATA_MISMATCH, \"Existing table metadata in ZooKeeper differs in version column. \"\n                 \"Stored in ZooKeeper: {}, local: {}\", from_zk.version_column, version_column);\n \n-        if (is_deleted_column != from_zk.is_deleted_column)\n-            throw Exception(ErrorCodes::METADATA_MISMATCH, \"Existing table metadata in ZooKeeper differs in is_deleted column. \"\n-                \"Stored in ZooKeeper: {}, local: {}\", from_zk.is_deleted_column, is_deleted_column);\n-\n         if (columns_to_sum != from_zk.columns_to_sum)\n             throw Exception(ErrorCodes::METADATA_MISMATCH, \"Existing table metadata in ZooKeeper differs in sum columns. \"\n                 \"Stored in ZooKeeper: {}, local: {}\", from_zk.columns_to_sum, columns_to_sum);\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeTableMetadata.h b/src/Storages/MergeTree/ReplicatedMergeTreeTableMetadata.h\nindex 15ed8671f9b2..67de9fd64ba7 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeTableMetadata.h\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeTableMetadata.h\n@@ -29,7 +29,6 @@ struct ReplicatedMergeTreeTableMetadata\n     int merge_params_version = REPLICATED_MERGE_TREE_METADATA_WITH_ALL_MERGE_PARAMETERS;\n     String sign_column;\n     String version_column;\n-    String is_deleted_column;\n     String columns_to_sum;\n     String graphite_params_hash;\n     String primary_key;\ndiff --git a/src/Storages/MergeTree/registerStorageMergeTree.cpp b/src/Storages/MergeTree/registerStorageMergeTree.cpp\nindex 9a5af77d57cd..9ed87e5c9efe 100644\n--- a/src/Storages/MergeTree/registerStorageMergeTree.cpp\n+++ b/src/Storages/MergeTree/registerStorageMergeTree.cpp\n@@ -138,7 +138,7 @@ static StoragePtr create(const StorageFactory::Arguments & args)\n         * CollapsingMergeTree(date, [sample_key], primary_key, index_granularity, sign)\n         * SummingMergeTree(date, [sample_key], primary_key, index_granularity, [columns_to_sum])\n         * AggregatingMergeTree(date, [sample_key], primary_key, index_granularity)\n-        * ReplacingMergeTree(date, [sample_key], primary_key, index_granularity, [version_column [, is_deleted_column]])\n+        * ReplacingMergeTree(date, [sample_key], primary_key, index_granularity, [version_column])\n         * GraphiteMergeTree(date, [sample_key], primary_key, index_granularity, 'config_element')\n         *\n         * Alternatively, you can specify:\n@@ -441,15 +441,6 @@ static StoragePtr create(const StorageFactory::Arguments & args)\n     }\n     else if (merging_params.mode == MergeTreeData::MergingParams::Replacing)\n     {\n-        // if there is args and number of optional parameter is higher than 1\n-        // is_deleted is not allowed with the 'allow_deprecated_syntax_for_merge_tree' settings\n-        if (arg_cnt - arg_num == 2 && !engine_args[arg_cnt - 1]->as<ASTLiteral>() && is_extended_storage_def)\n-        {\n-            if (!tryGetIdentifierNameInto(engine_args[arg_cnt - 1], merging_params.is_deleted_column))\n-                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"is_deleted column name must be an identifier {}\", verbose_help_message);\n-            --arg_cnt;\n-        }\n-\n         /// If the last element is not index_granularity or replica_name (a literal), then this is the name of the version column.\n         if (arg_cnt && !engine_args[arg_cnt - 1]->as<ASTLiteral>())\n         {\ndiff --git a/src/Storages/RocksDB/StorageEmbeddedRocksDB.cpp b/src/Storages/RocksDB/StorageEmbeddedRocksDB.cpp\nindex 4ead714c7404..c9843211e08d 100644\n--- a/src/Storages/RocksDB/StorageEmbeddedRocksDB.cpp\n+++ b/src/Storages/RocksDB/StorageEmbeddedRocksDB.cpp\n@@ -321,7 +321,6 @@ bool StorageEmbeddedRocksDB::optimize(\n     bool final,\n     bool deduplicate,\n     const Names & /* deduplicate_by_columns */,\n-    bool cleanup,\n     ContextPtr /*context*/)\n {\n     if (partition)\n@@ -333,9 +332,6 @@ bool StorageEmbeddedRocksDB::optimize(\n     if (deduplicate)\n         throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"DEDUPLICATE cannot be specified when optimizing table of type EmbeddedRocksDB\");\n \n-    if (cleanup)\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"CLEANUP cannot be specified when optimizing table of type EmbeddedRocksDB\");\n-\n     std::shared_lock lock(rocksdb_ptr_mx);\n     rocksdb::CompactRangeOptions compact_options;\n     auto status = rocksdb_ptr->CompactRange(compact_options, nullptr, nullptr);\ndiff --git a/src/Storages/RocksDB/StorageEmbeddedRocksDB.h b/src/Storages/RocksDB/StorageEmbeddedRocksDB.h\nindex b59fe72ef47c..733baebb6016 100644\n--- a/src/Storages/RocksDB/StorageEmbeddedRocksDB.h\n+++ b/src/Storages/RocksDB/StorageEmbeddedRocksDB.h\n@@ -65,7 +65,6 @@ class StorageEmbeddedRocksDB final : public IStorage, public IKeyValueEntity, Wi\n         bool final,\n         bool deduplicate,\n         const Names & deduplicate_by_columns,\n-        bool cleanup,\n         ContextPtr context) override;\n \n     bool supportsParallelInsert() const override { return true; }\ndiff --git a/src/Storages/StorageBuffer.cpp b/src/Storages/StorageBuffer.cpp\nindex f3030dadc591..2646a7753e4c 100644\n--- a/src/Storages/StorageBuffer.cpp\n+++ b/src/Storages/StorageBuffer.cpp\n@@ -694,7 +694,7 @@ void StorageBuffer::flushAndPrepareForShutdown()\n \n     try\n     {\n-        optimize(nullptr /*query*/, getInMemoryMetadataPtr(), {} /*partition*/, false /*final*/, false /*deduplicate*/, {}, false /*cleanup*/, getContext());\n+        optimize(nullptr /*query*/, getInMemoryMetadataPtr(), {} /*partition*/, false /*final*/, false /*deduplicate*/, {}, getContext());\n     }\n     catch (...)\n     {\n@@ -720,7 +720,6 @@ bool StorageBuffer::optimize(\n     bool final,\n     bool deduplicate,\n     const Names & /* deduplicate_by_columns */,\n-    bool cleanup,\n     ContextPtr /*context*/)\n {\n     if (partition)\n@@ -732,9 +731,6 @@ bool StorageBuffer::optimize(\n     if (deduplicate)\n         throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"DEDUPLICATE cannot be specified when optimizing table of type Buffer\");\n \n-    if (cleanup)\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"CLEANUP cannot be specified when optimizing table of type Buffer\");\n-\n     flushAllBuffers(false);\n     return true;\n }\n@@ -1067,7 +1063,7 @@ void StorageBuffer::alter(const AlterCommands & params, ContextPtr local_context\n     auto metadata_snapshot = getInMemoryMetadataPtr();\n \n     /// Flush buffers to the storage because BufferSource skips buffers with old metadata_version.\n-    optimize({} /*query*/, metadata_snapshot, {} /*partition_id*/, false /*final*/, false /*deduplicate*/, {}, false /*cleanup*/, local_context);\n+    optimize({} /*query*/, metadata_snapshot, {} /*partition_id*/, false /*final*/, false /*deduplicate*/, {}, local_context);\n \n     StorageInMemoryMetadata new_metadata = *metadata_snapshot;\n     params.apply(new_metadata, local_context);\ndiff --git a/src/Storages/StorageBuffer.h b/src/Storages/StorageBuffer.h\nindex 94873ea04ce8..21eb86019fce 100644\n--- a/src/Storages/StorageBuffer.h\n+++ b/src/Storages/StorageBuffer.h\n@@ -100,7 +100,6 @@ friend class BufferSink;\n         bool final,\n         bool deduplicate,\n         const Names & deduplicate_by_columns,\n-        bool cleanup,\n         ContextPtr context) override;\n \n     bool supportsSampling() const override { return true; }\ndiff --git a/src/Storages/StorageMaterializedView.cpp b/src/Storages/StorageMaterializedView.cpp\nindex a7e2f246cec6..cf9180be1ee6 100644\n--- a/src/Storages/StorageMaterializedView.cpp\n+++ b/src/Storages/StorageMaterializedView.cpp\n@@ -262,13 +262,12 @@ bool StorageMaterializedView::optimize(\n     bool final,\n     bool deduplicate,\n     const Names & deduplicate_by_columns,\n-    bool cleanup,\n     ContextPtr local_context)\n {\n     checkStatementCanBeForwarded();\n     auto storage_ptr = getTargetTable();\n     auto metadata_snapshot = storage_ptr->getInMemoryMetadataPtr();\n-    return getTargetTable()->optimize(query, metadata_snapshot, partition, final, deduplicate, deduplicate_by_columns, cleanup, local_context);\n+    return getTargetTable()->optimize(query, metadata_snapshot, partition, final, deduplicate, deduplicate_by_columns, local_context);\n }\n \n void StorageMaterializedView::alter(\ndiff --git a/src/Storages/StorageMaterializedView.h b/src/Storages/StorageMaterializedView.h\nindex ae38cfb7e59c..03a6cba8cc6c 100644\n--- a/src/Storages/StorageMaterializedView.h\n+++ b/src/Storages/StorageMaterializedView.h\n@@ -54,7 +54,6 @@ class StorageMaterializedView final : public IStorage, WithMutableContext\n         bool final,\n         bool deduplicate,\n         const Names & deduplicate_by_columns,\n-        bool cleanup,\n         ContextPtr context) override;\n \n     void alter(const AlterCommands & params, ContextPtr context, AlterLockHolder & table_lock_holder) override;\ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex ed2e9c6d3ffe..eb8c52f8936a 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -1078,7 +1078,6 @@ bool StorageMergeTree::merge(\n     bool final,\n     bool deduplicate,\n     const Names & deduplicate_by_columns,\n-    bool cleanup,\n     const MergeTreeTransactionPtr & txn,\n     String & out_disable_reason,\n     bool optimize_skip_merged_partitions)\n@@ -1118,7 +1117,7 @@ bool StorageMergeTree::merge(\n     /// Copying a vector of columns `deduplicate by columns.\n     IExecutableTask::TaskResultCallback f = [](bool) {};\n     auto task = std::make_shared<MergePlainMergeTreeTask>(\n-        *this, metadata_snapshot, deduplicate, deduplicate_by_columns, cleanup, merge_mutate_entry, table_lock_holder, f);\n+        *this, metadata_snapshot, deduplicate, deduplicate_by_columns, merge_mutate_entry, table_lock_holder, f);\n \n     task->setCurrentTransaction(MergeTreeTransactionHolder{}, MergeTreeTransactionPtr{txn});\n \n@@ -1356,7 +1355,7 @@ bool StorageMergeTree::scheduleDataProcessingJob(BackgroundJobsAssignee & assign\n \n     if (merge_entry)\n     {\n-        auto task = std::make_shared<MergePlainMergeTreeTask>(*this, metadata_snapshot, /* deduplicate */ false, Names{}, /* cleanup */ false, merge_entry, shared_lock, common_assignee_trigger);\n+        auto task = std::make_shared<MergePlainMergeTreeTask>(*this, metadata_snapshot, /* deduplicate */ false, Names{}, merge_entry, shared_lock, common_assignee_trigger);\n         task->setCurrentTransaction(std::move(transaction_for_merge), std::move(txn));\n         bool scheduled = assignee.scheduleMergeMutateTask(task);\n         /// The problem that we already booked a slot for TTL merge, but a merge list entry will be created only in a prepare method\n@@ -1490,7 +1489,6 @@ bool StorageMergeTree::optimize(\n     bool final,\n     bool deduplicate,\n     const Names & deduplicate_by_columns,\n-    bool cleanup,\n     ContextPtr local_context)\n {\n     if (deduplicate)\n@@ -1506,13 +1504,6 @@ bool StorageMergeTree::optimize(\n     String disable_reason;\n     if (!partition && final)\n     {\n-        if (cleanup && this->merging_params.mode != MergingParams::Mode::Replacing)\n-        {\n-            constexpr const char * message = \"Cannot OPTIMIZE with CLEANUP table: {}\";\n-            disable_reason = \"only ReplacingMergeTree can be CLEANUP\";\n-            throw Exception(ErrorCodes::CANNOT_ASSIGN_OPTIMIZE, message, disable_reason);\n-        }\n-\n         DataPartsVector data_parts = getVisibleDataPartsVector(local_context);\n         std::unordered_set<String> partition_ids;\n \n@@ -1527,7 +1518,6 @@ bool StorageMergeTree::optimize(\n                     true,\n                     deduplicate,\n                     deduplicate_by_columns,\n-                    cleanup,\n                     txn,\n                     disable_reason,\n                     local_context->getSettingsRef().optimize_skip_merged_partitions))\n@@ -1555,7 +1545,6 @@ bool StorageMergeTree::optimize(\n                 final,\n                 deduplicate,\n                 deduplicate_by_columns,\n-                cleanup,\n                 txn,\n                 disable_reason,\n                 local_context->getSettingsRef().optimize_skip_merged_partitions))\ndiff --git a/src/Storages/StorageMergeTree.h b/src/Storages/StorageMergeTree.h\nindex 539037a90ae3..863a4b914871 100644\n--- a/src/Storages/StorageMergeTree.h\n+++ b/src/Storages/StorageMergeTree.h\n@@ -82,7 +82,6 @@ class StorageMergeTree final : public MergeTreeData\n         bool final,\n         bool deduplicate,\n         const Names & deduplicate_by_columns,\n-        bool cleanup,\n         ContextPtr context) override;\n \n     void mutate(const MutationCommands & commands, ContextPtr context) override;\n@@ -171,14 +170,13 @@ class StorageMergeTree final : public MergeTreeData\n       * Returns true if merge is finished successfully.\n       */\n     bool merge(\n-            bool aggressive,\n-            const String & partition_id,\n-            bool final, bool deduplicate,\n-            const Names & deduplicate_by_columns,\n-            bool cleanup,\n-            const MergeTreeTransactionPtr & txn,\n-            String & out_disable_reason,\n-            bool optimize_skip_merged_partitions = false);\n+        bool aggressive,\n+        const String & partition_id,\n+        bool final, bool deduplicate,\n+        const Names & deduplicate_by_columns,\n+        const MergeTreeTransactionPtr & txn,\n+        String & out_disable_reason,\n+        bool optimize_skip_merged_partitions = false);\n \n     void renameAndCommitEmptyParts(MutableDataPartsVector & new_parts, Transaction & transaction);\n \ndiff --git a/src/Storages/StorageProxy.h b/src/Storages/StorageProxy.h\nindex 5d57f75a6208..17f1b2a6d977 100644\n--- a/src/Storages/StorageProxy.h\n+++ b/src/Storages/StorageProxy.h\n@@ -121,16 +121,15 @@ class StorageProxy : public IStorage\n     }\n \n     bool optimize(\n-            const ASTPtr & query,\n-            const StorageMetadataPtr & metadata_snapshot,\n-            const ASTPtr & partition,\n-            bool final,\n-            bool deduplicate,\n-            const Names & deduplicate_by_columns,\n-            bool cleanup,\n-            ContextPtr context) override\n+        const ASTPtr & query,\n+        const StorageMetadataPtr & metadata_snapshot,\n+        const ASTPtr & partition,\n+        bool final,\n+        bool deduplicate,\n+        const Names & deduplicate_by_columns,\n+        ContextPtr context) override\n     {\n-        return getNested()->optimize(query, metadata_snapshot, partition, final, deduplicate, deduplicate_by_columns, cleanup, context);\n+        return getNested()->optimize(query, metadata_snapshot, partition, final, deduplicate, deduplicate_by_columns, context);\n     }\n \n     void mutate(const MutationCommands & commands, ContextPtr context) override { getNested()->mutate(commands, context); }\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex d0f7edf08ce9..3e4d6309ec84 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -3643,7 +3643,6 @@ void StorageReplicatedMergeTree::mergeSelectingTask()\n     const auto storage_settings_ptr = getSettings();\n     const bool deduplicate = false; /// TODO: read deduplicate option from table config\n     const Names deduplicate_by_columns = {};\n-    const bool cleanup = (storage_settings_ptr->clean_deleted_rows != CleanDeletedRows::Never);\n     CreateMergeEntryResult create_result = CreateMergeEntryResult::Other;\n \n     enum class AttemptStatus\n@@ -3727,12 +3726,10 @@ void StorageReplicatedMergeTree::mergeSelectingTask()\n                 future_merged_part->part_format,\n                 deduplicate,\n                 deduplicate_by_columns,\n-                cleanup,\n                 nullptr,\n                 merge_pred->getVersion(),\n                 future_merged_part->merge_type);\n \n-\n             if (create_result == CreateMergeEntryResult::Ok)\n                 return AttemptStatus::EntryCreated;\n             if (create_result == CreateMergeEntryResult::LogUpdated)\n@@ -3849,7 +3846,6 @@ StorageReplicatedMergeTree::CreateMergeEntryResult StorageReplicatedMergeTree::c\n     const MergeTreeDataPartFormat & merged_part_format,\n     bool deduplicate,\n     const Names & deduplicate_by_columns,\n-    bool cleanup,\n     ReplicatedMergeTreeLogEntryData * out_log_entry,\n     int32_t log_version,\n     MergeType merge_type)\n@@ -3889,7 +3885,6 @@ StorageReplicatedMergeTree::CreateMergeEntryResult StorageReplicatedMergeTree::c\n     entry.merge_type = merge_type;\n     entry.deduplicate = deduplicate;\n     entry.deduplicate_by_columns = deduplicate_by_columns;\n-    entry.cleanup = cleanup;\n     entry.create_time = time(nullptr);\n \n     for (const auto & part : parts)\n@@ -5635,7 +5630,6 @@ bool StorageReplicatedMergeTree::optimize(\n     bool final,\n     bool deduplicate,\n     const Names & deduplicate_by_columns,\n-    bool cleanup,\n     ContextPtr query_context)\n {\n     /// NOTE: exclusive lock cannot be used here, since this may lead to deadlock (see comments below),\n@@ -5647,9 +5641,6 @@ bool StorageReplicatedMergeTree::optimize(\n     if (!is_leader)\n         throw Exception(ErrorCodes::NOT_A_LEADER, \"OPTIMIZE cannot be done on this replica because it is not a leader\");\n \n-    if (cleanup)\n-        LOG_DEBUG(log, \"Cleanup the ReplicatedMergeTree.\");\n-\n     auto handle_noop = [&]<typename... Args>(FormatStringHelper<Args...> fmt_string, Args && ...args)\n     {\n         PreformattedMessage message = fmt_string.format(std::forward<Args>(args)...);\n@@ -5728,7 +5719,6 @@ bool StorageReplicatedMergeTree::optimize(\n                 future_merged_part->uuid,\n                 future_merged_part->part_format,\n                 deduplicate, deduplicate_by_columns,\n-                cleanup,\n                 &merge_entry, can_merge.getVersion(),\n                 future_merged_part->merge_type);\n \n@@ -5753,13 +5743,6 @@ bool StorageReplicatedMergeTree::optimize(\n     bool assigned = false;\n     if (!partition && final)\n     {\n-        if (cleanup && this->merging_params.mode != MergingParams::Mode::Replacing)\n-        {\n-            constexpr const char * message = \"Cannot OPTIMIZE with CLEANUP table: {}\";\n-            String disable_reason = \"only ReplacingMergeTree can be CLEANUP\";\n-            throw Exception(ErrorCodes::CANNOT_ASSIGN_OPTIMIZE, message, disable_reason);\n-        }\n-\n         DataPartsVector data_parts = getVisibleDataPartsVector(query_context);\n         std::unordered_set<String> partition_ids;\n \ndiff --git a/src/Storages/StorageReplicatedMergeTree.h b/src/Storages/StorageReplicatedMergeTree.h\nindex 159828effcfb..f68a7561b93e 100644\n--- a/src/Storages/StorageReplicatedMergeTree.h\n+++ b/src/Storages/StorageReplicatedMergeTree.h\n@@ -177,7 +177,6 @@ class StorageReplicatedMergeTree final : public MergeTreeData\n         bool final,\n         bool deduplicate,\n         const Names & deduplicate_by_columns,\n-        bool cleanup,\n         ContextPtr query_context) override;\n \n     void alter(const AlterCommands & commands, ContextPtr query_context, AlterLockHolder & table_lock_holder) override;\n@@ -747,7 +746,6 @@ class StorageReplicatedMergeTree final : public MergeTreeData\n         const MergeTreeDataPartFormat & merged_part_format,\n         bool deduplicate,\n         const Names & deduplicate_by_columns,\n-        bool cleanup,\n         ReplicatedMergeTreeLogEntryData * out_log_entry,\n         int32_t log_version,\n         MergeType merge_type);\ndiff --git a/src/Storages/WindowView/StorageWindowView.cpp b/src/Storages/WindowView/StorageWindowView.cpp\nindex 46c38ffa129a..3eff3f9f995a 100644\n--- a/src/Storages/WindowView/StorageWindowView.cpp\n+++ b/src/Storages/WindowView/StorageWindowView.cpp\n@@ -435,12 +435,11 @@ bool StorageWindowView::optimize(\n     bool final,\n     bool deduplicate,\n     const Names & deduplicate_by_columns,\n-    bool cleanup,\n     ContextPtr local_context)\n {\n     auto storage_ptr = getInnerTable();\n     auto metadata_snapshot = storage_ptr->getInMemoryMetadataPtr();\n-    return getInnerTable()->optimize(query, metadata_snapshot, partition, final, deduplicate, deduplicate_by_columns, cleanup, local_context);\n+    return getInnerTable()->optimize(query, metadata_snapshot, partition, final, deduplicate, deduplicate_by_columns, local_context);\n }\n \n void StorageWindowView::alter(\ndiff --git a/src/Storages/WindowView/StorageWindowView.h b/src/Storages/WindowView/StorageWindowView.h\nindex de8f880c6022..d2484ae8ebf4 100644\n--- a/src/Storages/WindowView/StorageWindowView.h\n+++ b/src/Storages/WindowView/StorageWindowView.h\n@@ -134,7 +134,6 @@ class StorageWindowView final : public IStorage, WithContext\n         bool final,\n         bool deduplicate,\n         const Names & deduplicate_by_columns,\n-        bool cleanup,\n         ContextPtr context) override;\n \n     void alter(const AlterCommands & params, ContextPtr context, AlterLockHolder & table_lock_holder) override;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/00577_replacing_merge_tree_vertical_merge.reference b/tests/queries/0_stateless/00577_replacing_merge_tree_vertical_merge.reference\nindex 6bac61731830..a4d91178d73d 100644\n--- a/tests/queries/0_stateless/00577_replacing_merge_tree_vertical_merge.reference\n+++ b/tests/queries/0_stateless/00577_replacing_merge_tree_vertical_merge.reference\n@@ -3,5 +3,7 @@\n 2018-01-01\t2\t2\n 2018-01-01\t2\t2\n == (Replicas) Test optimize ==\n+d1\t2\t1\n d2\t1\t0\n+d3\t2\t1\n d4\t1\t0\ndiff --git a/tests/queries/0_stateless/00577_replacing_merge_tree_vertical_merge.sql b/tests/queries/0_stateless/00577_replacing_merge_tree_vertical_merge.sql\nindex e3c1bb10426e..9e293d0f7e24 100644\n--- a/tests/queries/0_stateless/00577_replacing_merge_tree_vertical_merge.sql\n+++ b/tests/queries/0_stateless/00577_replacing_merge_tree_vertical_merge.sql\n@@ -7,14 +7,14 @@ create table tab_00577 (date Date, version UInt64, val UInt64) engine = Replacin\n insert into tab_00577 values ('2018-01-01', 2, 2), ('2018-01-01', 1, 1);\n insert into tab_00577 values ('2018-01-01', 0, 0);\n select * from tab_00577 order by version;\n-OPTIMIZE TABLE tab_00577 FINAL CLEANUP;\n+OPTIMIZE TABLE tab_00577 FINAL;\n select * from tab_00577;\n drop table tab_00577;\n \n \n DROP TABLE IF EXISTS testCleanupR1;\n CREATE TABLE testCleanupR1 (uid String, version UInt32, is_deleted UInt8)\n-    ENGINE = ReplicatedReplacingMergeTree('/clickhouse/{database}/tables/test_cleanup/', 'r1', version, is_deleted)\n+    ENGINE = ReplicatedReplacingMergeTree('/clickhouse/{database}/tables/test_cleanup/', 'r1', version)\n     ORDER BY uid SETTINGS enable_vertical_merge_algorithm = 1, vertical_merge_algorithm_min_rows_to_activate = 0, vertical_merge_algorithm_min_columns_to_activate = 0, min_rows_for_wide_part = 0,\n     min_bytes_for_wide_part = 0;\n INSERT INTO testCleanupR1 (*) VALUES ('d1', 1, 0),('d2', 1, 0),('d3', 1, 0),('d4', 1, 0);\n@@ -22,9 +22,9 @@ INSERT INTO testCleanupR1 (*) VALUES ('d3', 2, 1);\n INSERT INTO testCleanupR1 (*) VALUES ('d1', 2, 1);\n SYSTEM SYNC REPLICA testCleanupR1; -- Avoid \"Cannot select parts for optimization: Entry for part all_2_2_0 hasn't been read from the replication log yet\"\n \n-OPTIMIZE TABLE testCleanupR1 FINAL CLEANUP;\n+OPTIMIZE TABLE testCleanupR1 FINAL;\n \n -- Only d3 to d5 remain\n SELECT '== (Replicas) Test optimize ==';\n SELECT * FROM testCleanupR1 order by uid;\n-DROP TABLE IF EXISTS testCleanupR1\n\\ No newline at end of file\n+DROP TABLE IF EXISTS testCleanupR1\ndiff --git a/tests/queries/0_stateless/02490_replacing_merge_tree_is_deleted_column.reference b/tests/queries/0_stateless/02490_replacing_merge_tree_is_deleted_column.reference\ndeleted file mode 100644\nindex 04a2b75bb4f2..000000000000\n--- a/tests/queries/0_stateless/02490_replacing_merge_tree_is_deleted_column.reference\n+++ /dev/null\n@@ -1,99 +0,0 @@\n-== Test SELECT ... FINAL - no is_deleted ==\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-d6\t2\t1\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-d6\t2\t1\n-== Test SELECT ... FINAL - no is_deleted SETTINGS clean_deleted_rows=Always ==\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-d6\t2\t1\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-d6\t2\t1\n-== Test SELECT ... FINAL ==\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-d6\t2\t1\n-== Insert backups ==\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-== Insert a second batch with overlaping data ==\n-d1\t5\t0\n-d2\t3\t0\n-d3\t3\t0\n-d4\t3\t0\n-d5\t1\t0\n-== Only last version remains after OPTIMIZE W/ CLEANUP ==\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t1\t0\n-d5\t1\t0\n-d6\t3\t0\n-== OPTIMIZE W/ CLEANUP (remove d6) ==\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t1\t0\n-d5\t1\t0\n-== Test of the SETTINGS clean_deleted_rows as Always ==\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-d6\t2\t1\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-== Test of the SETTINGS clean_deleted_rows as Never ==\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t3\t0\n-d5\t1\t0\n-d6\t2\t1\n-== (Replicas) Test optimize ==\n-d2\t1\t0\n-d4\t1\t0\n-== (Replicas) Test settings ==\n-c2\t1\t0\n-c4\t1\t0\n-== Check cleanup & settings for other merge trees ==\n-d1\t1\t1\n-d1\t1\t1\n-d1\t1\t1\n-d1\t1\t1\t1\n-d1\t1\t1\t1\ndiff --git a/tests/queries/0_stateless/02490_replacing_merge_tree_is_deleted_column.sql b/tests/queries/0_stateless/02490_replacing_merge_tree_is_deleted_column.sql\ndeleted file mode 100644\nindex 8549300d49ff..000000000000\n--- a/tests/queries/0_stateless/02490_replacing_merge_tree_is_deleted_column.sql\n+++ /dev/null\n@@ -1,160 +0,0 @@\n--- Tags: zookeeper\n-\n--- Settings allow_deprecated_syntax_for_merge_tree prevent to enable the is_deleted column\n-set allow_deprecated_syntax_for_merge_tree=0;\n-\n--- Test the bahaviour without the is_deleted column\n-DROP TABLE IF EXISTS test;\n-CREATE TABLE test (uid String, version UInt32, is_deleted UInt8) ENGINE = ReplacingMergeTree(version) Order by (uid);\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d2', 1, 0), ('d6', 1, 0), ('d4', 1, 0), ('d6', 2, 1), ('d3', 1, 0), ('d1', 2, 1), ('d5', 1, 0), ('d4', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d4', 3, 0), ('d1', 5, 0);\n-SELECT '== Test SELECT ... FINAL - no is_deleted ==';\n-select * from test FINAL order by uid;\n-OPTIMIZE TABLE test FINAL CLEANUP;\n-select * from test order by uid;\n-\n-DROP TABLE IF EXISTS test;\n-CREATE TABLE test (uid String, version UInt32, is_deleted UInt8) ENGINE = ReplacingMergeTree(version) Order by (uid) SETTINGS clean_deleted_rows='Always';\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d2', 1, 0), ('d6', 1, 0), ('d4', 1, 0), ('d6', 2, 1), ('d3', 1, 0), ('d1', 2, 1), ('d5', 1, 0), ('d4', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d4', 3, 0), ('d1', 5, 0);\n-SELECT '== Test SELECT ... FINAL - no is_deleted SETTINGS clean_deleted_rows=Always ==';\n-select * from test FINAL order by uid;\n-OPTIMIZE TABLE test FINAL CLEANUP;\n-select * from test order by uid;\n-\n--- Test the new behaviour\n-DROP TABLE IF EXISTS test;\n-CREATE TABLE test (uid String, version UInt32, is_deleted UInt8) ENGINE = ReplacingMergeTree(version, is_deleted) Order by (uid);\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d2', 1, 0), ('d6', 1, 0), ('d4', 1, 0), ('d6', 2, 1), ('d3', 1, 0), ('d1', 2, 1), ('d5', 1, 0), ('d4', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d4', 3, 0), ('d1', 5, 0);\n-SELECT '== Test SELECT ... FINAL ==';\n-select * from test FINAL order by uid;\n-select * from test order by uid;\n-\n-SELECT '== Insert backups ==';\n-INSERT INTO test (*) VALUES ('d6', 1, 0), ('d4', 1, 0), ('d6', 2, 1), ('d3', 1, 0), ('d1', 2, 1), ('d5', 1, 0), ('d4', 2, 1);\n-select * from test FINAL order by uid;\n-\n-SELECT '== Insert a second batch with overlaping data ==';\n-INSERT INTO test (*) VALUES ('d4', 1, 0), ('d6', 2, 1), ('d3', 1, 0), ('d1', 2, 1), ('d5', 1, 0), ('d4', 2, 1), ('d1', 3, 1), ('d1', 4, 1), ('d4', 3, 0), ('d1', 5, 0), ('d2', 2, 1), ('d2', 3, 0), ('d3', 2, 1), ('d3', 3, 0);\n-select * from test FINAL order by uid;\n-\n-DROP TABLE IF EXISTS test;\n-CREATE TABLE test (uid String, version UInt32, is_deleted UInt8) ENGINE = ReplacingMergeTree(version, is_deleted) Order by (uid);\n-\n--- Expect d6 to be version=3 is_deleted=false\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d1', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d1', 5, 0), ('d2', 1, 0), ('d3', 1, 0), ('d4', 1, 0),  ('d5', 1, 0), ('d6', 1, 0), ('d6', 3, 0);\n--- Insert previous version of 'd6' but only v=3 is_deleted=false will remain\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d1', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d1', 5, 0), ('d2', 1, 0), ('d3', 1, 0), ('d4', 1, 0),  ('d5', 1, 0), ('d6', 1, 0), ('d6', 2, 1);\n-SELECT '== Only last version remains after OPTIMIZE W/ CLEANUP ==';\n-OPTIMIZE TABLE test FINAL CLEANUP;\n-select * from test order by uid;\n-\n--- insert d6 v=3 is_deleted=true (timestamp more recent so this version should be the one take into acount)\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d1', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d1', 5, 0), ('d2', 1, 0), ('d3', 1, 0), ('d4', 1, 0),  ('d5', 1, 0), ('d6', 1, 0), ('d6', 3, 1);\n-\n-SELECT '== OPTIMIZE W/ CLEANUP (remove d6) ==';\n-OPTIMIZE TABLE test FINAL CLEANUP;\n--- No d6 anymore\n-select * from test order by uid;\n-\n-DROP TABLE IF EXISTS test;\n-CREATE TABLE test (uid String, version UInt32, is_deleted UInt8) ENGINE = ReplacingMergeTree(version, is_deleted) Order by (uid) SETTINGS clean_deleted_rows='Always';\n-\n-SELECT '== Test of the SETTINGS clean_deleted_rows as Always ==';\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d2', 1, 0), ('d6', 1, 0), ('d4', 1, 0), ('d6', 2, 1), ('d3', 1, 0), ('d1', 2, 1), ('d5', 1, 0), ('d4', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d4', 3, 0), ('d1', 5, 0);\n--- Even if the setting is set to Always, the SELECT FINAL doesn't delete rows\n-select * from test FINAL order by uid;\n-select * from test order by uid;\n-\n-OPTIMIZE TABLE test FINAL;\n--- d6 has to be removed since we set clean_deleted_rows as 'Always'\n-select * from test order by uid;\n-\n-SELECT '== Test of the SETTINGS clean_deleted_rows as Never ==';\n-ALTER TABLE test MODIFY SETTING clean_deleted_rows='Never';\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d2', 1, 0), ('d6', 1, 0), ('d4', 1, 0), ('d6', 2, 1), ('d3', 1, 0), ('d1', 2, 1), ('d5', 1, 0), ('d4', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d4', 3, 0), ('d1', 5, 0);\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d2', 1, 0), ('d6', 1, 0), ('d4', 1, 0), ('d6', 2, 1), ('d3', 1, 0), ('d1', 2, 1), ('d5', 1, 0), ('d4', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d4', 3, 0), ('d1', 5, 0);\n-OPTIMIZE TABLE test FINAL;\n--- d6 has NOT to be removed since we set clean_deleted_rows as 'Never'\n-select * from test order by uid;\n-\n-DROP TABLE IF EXISTS testCleanupR1;\n-\n-CREATE TABLE testCleanupR1 (uid String, version UInt32, is_deleted UInt8)\n-    ENGINE = ReplicatedReplacingMergeTree('/clickhouse/{database}/tables/test_cleanup/', 'r1', version, is_deleted)\n-    ORDER BY uid;\n-\n-\n-INSERT INTO testCleanupR1 (*) VALUES ('d1', 1, 0),('d2', 1, 0),('d3', 1, 0),('d4', 1, 0);\n-INSERT INTO testCleanupR1 (*) VALUES ('d3', 2, 1);\n-INSERT INTO testCleanupR1 (*) VALUES ('d1', 2, 1);\n-SYSTEM SYNC REPLICA testCleanupR1; -- Avoid \"Cannot select parts for optimization: Entry for part all_2_2_0 hasn't been read from the replication log yet\"\n-\n-OPTIMIZE TABLE testCleanupR1 FINAL CLEANUP;\n-\n--- Only d3 to d5 remain\n-SELECT '== (Replicas) Test optimize ==';\n-SELECT * FROM testCleanupR1 order by uid;\n-\n-------------------------------\n-\n-DROP TABLE IF EXISTS testSettingsR1;\n-\n-CREATE TABLE testSettingsR1 (col1 String, version UInt32, is_deleted UInt8)\n-    ENGINE = ReplicatedReplacingMergeTree('/clickhouse/{database}/tables/test_setting/', 'r1', version, is_deleted)\n-    ORDER BY col1\n-    SETTINGS clean_deleted_rows = 'Always';\n-\n-INSERT INTO testSettingsR1 (*) VALUES ('c1', 1, 1),('c2', 1, 0),('c3', 1, 1),('c4', 1, 0);\n-SYSTEM SYNC REPLICA testSettingsR1; -- Avoid \"Cannot select parts for optimization: Entry for part all_2_2_0 hasn't been read from the replication log yet\"\n-\n-OPTIMIZE TABLE testSettingsR1 FINAL;\n-\n--- Only d3 to d5 remain\n-SELECT '== (Replicas) Test settings ==';\n-SELECT * FROM testSettingsR1 order by col1;\n-\n-\n-------------------------------\n--- Check errors\n-DROP TABLE IF EXISTS test;\n-CREATE TABLE test (uid String, version UInt32, is_deleted UInt8) ENGINE = ReplacingMergeTree(version, is_deleted) Order by (uid);\n-\n--- is_deleted == 0/1\n-INSERT INTO test (*) VALUES ('d1', 1, 2); -- { serverError INCORRECT_DATA }\n-\n-DROP TABLE IF EXISTS test;\n--- checkis_deleted type\n-CREATE TABLE test (uid String, version UInt32, is_deleted String) ENGINE = ReplacingMergeTree(version, is_deleted) Order by (uid); -- { serverError BAD_TYPE_OF_FIELD }\n-\n--- is_deleted column for other mergeTrees - ErrorCodes::LOGICAL_ERROR)\n-\n--- Check clean_deleted_rows='Always' for other MergeTrees\n-SELECT '== Check cleanup & settings for other merge trees ==';\n-CREATE TABLE testMT (uid String, version UInt32, is_deleted UInt8) ENGINE = MergeTree() Order by (uid) SETTINGS clean_deleted_rows='Always';\n-INSERT INTO testMT (*) VALUES ('d1', 1, 1);\n-OPTIMIZE TABLE testMT FINAL CLEANUP;  -- { serverError CANNOT_ASSIGN_OPTIMIZE }\n-OPTIMIZE TABLE testMT FINAL;\n-SELECT * FROM testMT order by uid;\n-\n-CREATE TABLE testSummingMT (uid String, version UInt32, is_deleted UInt8) ENGINE = SummingMergeTree() Order by (uid) SETTINGS clean_deleted_rows='Always';\n-INSERT INTO testSummingMT (*) VALUES ('d1', 1, 1);\n-OPTIMIZE TABLE testSummingMT FINAL CLEANUP;  -- { serverError CANNOT_ASSIGN_OPTIMIZE }\n-OPTIMIZE TABLE testSummingMT FINAL;\n-SELECT * FROM testSummingMT order by uid;\n-\n-CREATE TABLE testAggregatingMT (uid String, version UInt32, is_deleted UInt8) ENGINE = AggregatingMergeTree() Order by (uid) SETTINGS clean_deleted_rows='Always';\n-INSERT INTO testAggregatingMT (*) VALUES ('d1', 1, 1);\n-OPTIMIZE TABLE testAggregatingMT FINAL CLEANUP;  -- { serverError CANNOT_ASSIGN_OPTIMIZE }\n-OPTIMIZE TABLE testAggregatingMT FINAL;\n-SELECT * FROM testAggregatingMT order by uid;\n-\n-CREATE TABLE testCollapsingMT (uid String, version UInt32, is_deleted UInt8, sign Int8) ENGINE = CollapsingMergeTree(sign) Order by (uid) SETTINGS clean_deleted_rows='Always';\n-INSERT INTO testCollapsingMT (*) VALUES ('d1', 1, 1, 1);\n-OPTIMIZE TABLE testCollapsingMT FINAL CLEANUP;  -- { serverError CANNOT_ASSIGN_OPTIMIZE }\n-OPTIMIZE TABLE testCollapsingMT FINAL;\n-SELECT * FROM testCollapsingMT order by uid;\n-\n-CREATE TABLE testVersionedCMT (uid String, version UInt32, is_deleted UInt8, sign Int8) ENGINE = VersionedCollapsingMergeTree(sign, version) Order by (uid) SETTINGS clean_deleted_rows='Always';\n-INSERT INTO testVersionedCMT (*) VALUES ('d1', 1, 1, 1);\n-OPTIMIZE TABLE testVersionedCMT FINAL CLEANUP;  -- { serverError CANNOT_ASSIGN_OPTIMIZE }\n-OPTIMIZE TABLE testVersionedCMT FINAL;\n-SELECT * FROM testVersionedCMT order by uid;\ndiff --git a/tests/queries/0_stateless/02814_ReplacingMergeTree_fix_select_final_on_single_partition.reference b/tests/queries/0_stateless/02814_ReplacingMergeTree_fix_select_final_on_single_partition.reference\ndeleted file mode 100644\nindex d19222b55ecd..000000000000\n--- a/tests/queries/0_stateless/02814_ReplacingMergeTree_fix_select_final_on_single_partition.reference\n+++ /dev/null\n@@ -1,31 +0,0 @@\n---- Based on https://github.com/ClickHouse/ClickHouse/issues/49685\n---- Verify that ReplacingMergeTree properly handles _is_deleted:\n---- SELECT FINAL should take `_is_deleted` into consideration when there is only one partition.\n--- { echoOn }\n-\n-DROP TABLE IF EXISTS t;\n-CREATE TABLE t\n-(\n-    `account_id` UInt64,\n-    `_is_deleted` UInt8,\n-    `_version` UInt64\n-)\n-ENGINE = ReplacingMergeTree(_version, _is_deleted)\n-ORDER BY (account_id);\n-INSERT INTO t SELECT number, 0, 1 FROM numbers(1e3);\n--- Mark the first 100 rows as deleted.\n-INSERT INTO t SELECT number, 1, 1 FROM numbers(1e2);\n--- Put everything in one partition\n-OPTIMIZE TABLE t FINAL;\n-SELECT count() FROM t;\n-1000\n-SELECT count() FROM t FINAL;\n-900\n--- Both should produce the same number of rows.\n--- Previously, `do_not_merge_across_partitions_select_final = 1` showed more rows, \n--- as if no rows were deleted.\n-SELECT count() FROM t FINAL SETTINGS do_not_merge_across_partitions_select_final = 1;\n-900\n-SELECT count() FROM t FINAL SETTINGS do_not_merge_across_partitions_select_final = 0;\n-900\n-DROP TABLE t;\ndiff --git a/tests/queries/0_stateless/02814_ReplacingMergeTree_fix_select_final_on_single_partition.sql b/tests/queries/0_stateless/02814_ReplacingMergeTree_fix_select_final_on_single_partition.sql\ndeleted file mode 100644\nindex a89a1ff590a6..000000000000\n--- a/tests/queries/0_stateless/02814_ReplacingMergeTree_fix_select_final_on_single_partition.sql\n+++ /dev/null\n@@ -1,32 +0,0 @@\n---- Based on https://github.com/ClickHouse/ClickHouse/issues/49685\n---- Verify that ReplacingMergeTree properly handles _is_deleted:\n---- SELECT FINAL should take `_is_deleted` into consideration when there is only one partition.\n--- { echoOn }\n-\n-DROP TABLE IF EXISTS t;\n-CREATE TABLE t\n-(\n-    `account_id` UInt64,\n-    `_is_deleted` UInt8,\n-    `_version` UInt64\n-)\n-ENGINE = ReplacingMergeTree(_version, _is_deleted)\n-ORDER BY (account_id);\n-\n-INSERT INTO t SELECT number, 0, 1 FROM numbers(1e3);\n--- Mark the first 100 rows as deleted.\n-INSERT INTO t SELECT number, 1, 1 FROM numbers(1e2);\n-\n--- Put everything in one partition\n-OPTIMIZE TABLE t FINAL;\n-\n-SELECT count() FROM t;\n-SELECT count() FROM t FINAL;\n-\n--- Both should produce the same number of rows.\n--- Previously, `do_not_merge_across_partitions_select_final = 1` showed more rows, \n--- as if no rows were deleted.\n-SELECT count() FROM t FINAL SETTINGS do_not_merge_across_partitions_select_final = 1;\n-SELECT count() FROM t FINAL SETTINGS do_not_merge_across_partitions_select_final = 0;\n-\n-DROP TABLE t;\ndiff --git a/tests/queries/0_stateless/02861_replacing_merge_tree_with_cleanup.reference b/tests/queries/0_stateless/02861_replacing_merge_tree_with_cleanup.reference\ndeleted file mode 100644\nindex 9c9caa221391..000000000000\n--- a/tests/queries/0_stateless/02861_replacing_merge_tree_with_cleanup.reference\n+++ /dev/null\n@@ -1,13 +0,0 @@\n-== Only last version remains after OPTIMIZE W/ CLEANUP ==\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t1\t0\n-d5\t1\t0\n-d6\t3\t0\n-== OPTIMIZE W/ CLEANUP (remove d6) ==\n-d1\t5\t0\n-d2\t1\t0\n-d3\t1\t0\n-d4\t1\t0\n-d5\t1\t0\ndiff --git a/tests/queries/0_stateless/02861_replacing_merge_tree_with_cleanup.sql b/tests/queries/0_stateless/02861_replacing_merge_tree_with_cleanup.sql\ndeleted file mode 100644\nindex 7b78e2900e7e..000000000000\n--- a/tests/queries/0_stateless/02861_replacing_merge_tree_with_cleanup.sql\n+++ /dev/null\n@@ -1,23 +0,0 @@\n-DROP TABLE IF EXISTS test;\n-CREATE TABLE test (uid String, version UInt32, is_deleted UInt8) ENGINE = ReplacingMergeTree(version, is_deleted) Order by (uid) SETTINGS vertical_merge_algorithm_min_rows_to_activate = 1,\n-    vertical_merge_algorithm_min_columns_to_activate = 0,\n-    min_rows_for_wide_part = 1,\n-    min_bytes_for_wide_part = 1;\n-\n--- Expect d6 to be version=3 is_deleted=false\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d1', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d1', 5, 0), ('d2', 1, 0), ('d3', 1, 0), ('d4', 1, 0),  ('d5', 1, 0), ('d6', 1, 0), ('d6', 3, 0);\n--- Insert previous version of 'd6' but only v=3 is_deleted=false will remain\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d1', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d1', 5, 0), ('d2', 1, 0), ('d3', 1, 0), ('d4', 1, 0),  ('d5', 1, 0), ('d6', 1, 0), ('d6', 2, 1);\n-SELECT '== Only last version remains after OPTIMIZE W/ CLEANUP ==';\n-OPTIMIZE TABLE test FINAL CLEANUP;\n-select * from test order by uid;\n-\n--- insert d6 v=3 is_deleted=true (timestamp more recent so this version should be the one take into acount)\n-INSERT INTO test (*) VALUES ('d1', 1, 0), ('d1', 2, 1), ('d1', 3, 0), ('d1', 4, 1), ('d1', 5, 0), ('d2', 1, 0), ('d3', 1, 0), ('d4', 1, 0),  ('d5', 1, 0), ('d6', 1, 0), ('d6', 3, 1);\n-\n-SELECT '== OPTIMIZE W/ CLEANUP (remove d6) ==';\n-OPTIMIZE TABLE test FINAL CLEANUP;\n--- No d6 anymore\n-select * from test order by uid;\n-\n-DROP TABLE IF EXISTS test;\ndiff --git a/tests/queries/0_stateless/02910_replicated_merge_parameters_must_consistent.sql b/tests/queries/0_stateless/02910_replicated_merge_parameters_must_consistent.sql\nindex 3c1bec4fb3f1..c832e16e81ee 100644\n--- a/tests/queries/0_stateless/02910_replicated_merge_parameters_must_consistent.sql\n+++ b/tests/queries/0_stateless/02910_replicated_merge_parameters_must_consistent.sql\n@@ -17,26 +17,6 @@ CREATE TABLE t_r\n ENGINE = ReplicatedReplacingMergeTree('/tables/{database}/t/', 'r2')\n ORDER BY id; -- { serverError METADATA_MISMATCH }\n \n-CREATE TABLE t2\n-(\n-    `id` UInt64,\n-    `val` String,\n-    `legacy_ver` UInt64,\n-    `deleted` UInt8\n-)\n-ENGINE = ReplicatedReplacingMergeTree('/tables/{database}/t2/', 'r1', legacy_ver)\n-ORDER BY id;\n-\n-CREATE TABLE t2_r\n-(\n-    `id` UInt64,\n-    `val` String,\n-    `legacy_ver` UInt64,\n-    `deleted` UInt8\n-)\n-ENGINE = ReplicatedReplacingMergeTree('/tables/{database}/t2/', 'r2', legacy_ver, deleted)\n-ORDER BY id; -- { serverError METADATA_MISMATCH }\n-\n CREATE TABLE t3\n (\n     `key` UInt64,\n",
  "problem_statement": "ReplacingMergeTree with `is_deleted` column and `clean_deleted_rows=Always` works incorrectly\n```\r\ndell9510 :) CREATE TABLE test (uid String, version UInt32, is_deleted UInt8) ENGINE = ReplicatedReplacingMergeTree('/test/jhbsavk', '1', version, is_deleted) Order by (uid) settings clean_deleted_rows='Always';\r\n\r\ndell9510 :) CREATE TABLE test2 (uid String, version UInt32, is_deleted UInt8) ENGINE = ReplicatedReplacingMergeTree('/test/jhbsavk', '2', version, is_deleted) Order by (uid) settings clean_deleted_rows='Always';\r\n\r\ndell9510 :) system stop replicated sends test2\r\n\r\ndell9510 :) insert into test values (1, 1, 0)\r\ndell9510 :) insert into test2 values (2, 1, 0)\r\ndell9510 :) insert into test values (1, 2, 0)\r\ndell9510 :) insert into test values (1, 3, 1)\r\n\r\ndell9510 :) select *, _part from test\r\n\r\n\u250c\u2500uid\u2500\u252c\u2500version\u2500\u252c\u2500is_deleted\u2500\u252c\u2500_part\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 1   \u2502       2 \u2502          0 \u2502 all_2_2_0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u250c\u2500uid\u2500\u252c\u2500version\u2500\u252c\u2500is_deleted\u2500\u252c\u2500_part\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 1   \u2502       3 \u2502          1 \u2502 all_3_3_0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u250c\u2500uid\u2500\u252c\u2500version\u2500\u252c\u2500is_deleted\u2500\u252c\u2500_part\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 1   \u2502       1 \u2502          0 \u2502 all_0_0_0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n3 rows in set. Elapsed: 0.020 sec. \r\n\r\ndell9510 :) select * from test final\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.019 sec. \r\n\r\ndell9510 :) optimize table test\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.035 sec. \r\n\r\ndell9510 :) select * from test final\r\n\r\n\u250c\u2500uid\u2500\u252c\u2500version\u2500\u252c\u2500is_deleted\u2500\u2510\r\n\u2502 1   \u2502       1 \u2502          0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 row in set. Elapsed: 0.019 sec. \r\n\r\ndell9510 :) select *, _part from test\r\n\r\n\u250c\u2500uid\u2500\u252c\u2500version\u2500\u252c\u2500is_deleted\u2500\u252c\u2500_part\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 1   \u2502       1 \u2502          0 \u2502 all_0_0_0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 row in set. Elapsed: 0.014 sec. \r\n```\r\n\r\nRelated to https://github.com/ClickHouse/ClickHouse/pull/41005\n02490_replacing_merge_tree_is_deleted_column.sql is flaky\n2023.09.13 00:50:09.739289 [ 19093 ] {38c86424-30b0-4643-91c5-a049813d2c0b} <Error> executeQuery: Code: 341. DB::Exception: Log entry log-0000000003 is not precessed on local replica, most likely because the replica was shut down. (UNFINISHED) (version 23.9.1.823) (from [::1]:33788) (comment: 02490_replacing_merge_tree_is_deleted_column.sql) (in query: OPTIMIZE TABLE testCleanupR1 FINAL CLEANUP;), Stack trace (when copying this message, always include the lines below)\r\n\r\n[Link](https://s3.amazonaws.com/clickhouse-test-reports/47532/d683900765dca78704d59c175189a07a0a240660/stateless_tests__aarch64_.html)\nLonely part FINAL optimization for ReplacingMergeTree with is_deleted\nI have tried out https://github.com/ClickHouse/ClickHouse/pull/53919, and it looks really good for ReplacingMergeTree with just the `ver` parameter. Can it work just as well using the `is_deleted` parameter, too? For example, here I make two ReplacingMergeTrees. Both have an `is_deleted` column, but only one sets the `is_deleted` parameter on the ReplacingMergeTree:\r\n\r\n<table>\r\n<tr>\r\n<td>\r\n<pre><code>\r\nCREATE TABLE rmt\r\n(\r\n`id` UInt64,\r\n`dt` Date,\r\n`val` UInt64,\r\n`version` UInt64,\r\n`is_deleted` Bool\r\n)\r\nENGINE = ReplacingMergeTree(version)\r\nPARTITION BY dt\r\nORDER BY (id);\r\n</pre></code>\r\n</td>\r\n<td>\r\n<pre><code>\r\nCREATE TABLE rmt_is_deleted\r\n(\r\n`id` UInt64,\r\n`dt` Date,\r\n`val` UInt64,\r\n`version` UInt64,\r\n`is_deleted` Bool\r\n)\r\nENGINE = ReplacingMergeTree(version, is_deleted)\r\nPARTITION BY dt\r\nORDER BY (id);\r\n</code></pre>\r\n</td>\r\n</tr>\r\n</table>\r\n\r\nThen, I insert a bunch of records:\r\n\r\n```\r\nINSERT INTO rmt SELECT number, '2023-09-25', number*10, 0, number%2 FROM numbers(50_000_000);\r\nINSERT INTO rmt SELECT number, '2023-09-26', number*10, 0, number%2 FROM numbers(50_000_000);\r\n\r\nOPTIMIZE TABLE rmt FINAL;\r\n\r\nALTER TABLE rmt_is_deleted ATTACH PARTITION '2023-09-25' FROM rmt;\r\nALTER TABLE rmt_is_deleted ATTACH PARTITION '2023-09-26' FROM rmt;\r\n```\r\n\r\nPerformance is good querying ReplacingMergeTree with just the `ver` parameter. We can filter out `is_deleted` records ourselves:\r\n\r\n```\r\nSELECT\r\n    max(val),\r\n    count(*)\r\nFROM rmt\r\nFINAL\r\nWHERE NOT is_deleted\r\nSETTINGS max_threads = 1, do_not_merge_across_partitions_select_final = 1\r\n\r\nQuery id: e6118044-ce91-4900-aaf1-f84120d643df\r\n\r\n\u250c\u2500\u2500max(val)\u2500\u252c\u2500\u2500count()\u2500\u2510\r\n\u2502 499999980 \u2502 50000000 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 row in set. Elapsed: 1.431 sec. Processed 100.00 million rows, 900.00 MB (69.88 million rows/s., 628.92 MB/s.)\r\n```\r\n\r\nPerformance is not as good querying ReplacingMergeTree with the `is_deleted` parameter. I guess this is because, due to depending on the `is_deleted` column, we are triggering a merge that would otherwise have been bypassed by https://github.com/ClickHouse/ClickHouse/pull/53919. But, if we have a lonely part, couldn't we filter for `is_deleted` more cheaply, as demonstrated in the previous query?\r\n\r\n```\r\nSELECT\r\n    max(val),\r\n    count(*)\r\nFROM rmt_is_deleted\r\nFINAL\r\nSETTINGS max_threads = 1, do_not_merge_across_partitions_select_final = 1\r\n\r\nQuery id: 7415a4af-1617-4c14-8a82-bbca8fe1bcf2\r\n\r\n\u250c\u2500\u2500max(val)\u2500\u252c\u2500\u2500count()\u2500\u2510\r\n\u2502 499999980 \u2502 50000000 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 row in set. Elapsed: 5.550 sec. Processed 100.00 million rows, 1.70 GB (18.02 million rows/s., 306.31 MB/s.)\r\n```\r\n\r\n<details>\r\n<summary>EXPLAINs for rmt</summary>\r\n\r\n```\r\n\u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 Expression ((Projection + Before ORDER BY)) \u2502\r\n\u2502   Aggregating                               \u2502\r\n\u2502     Expression (Before GROUP BY)            \u2502\r\n\u2502       Filter (WHERE)                        \u2502\r\n\u2502         ReadFromMergeTree (demo.rmt)        \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n```\r\n\u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 (Expression)                                                                     \u2502\r\n\u2502 ExpressionTransform                                                              \u2502\r\n\u2502   (Aggregating)                                                                  \u2502\r\n\u2502   Resize 2 \u2192 1                                                                   \u2502\r\n\u2502     AggregatingTransform \u00d7 2                                                     \u2502\r\n\u2502       StrictResize 2 \u2192 2                                                         \u2502\r\n\u2502         (Expression)                                                             \u2502\r\n\u2502         ExpressionTransform \u00d7 2                                                  \u2502\r\n\u2502           (Filter)                                                               \u2502\r\n\u2502           FilterTransform \u00d7 2                                                    \u2502\r\n\u2502             (ReadFromMergeTree)                                                  \u2502\r\n\u2502             MergeTreeSelect(pool: ReadPoolInOrder, algorithm: InOrder) \u00d7 2 0 \u2192 1 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n</details>\r\n\r\n<details>\r\n<summary>EXPLAINs for rmt_is_deleted</summary>\r\n\r\n```\r\n\u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 Expression ((Projection + Before ORDER BY))    \u2502\r\n\u2502   Aggregating                                  \u2502\r\n\u2502     Expression (Before GROUP BY)               \u2502\r\n\u2502       ReadFromMergeTree (demo.rmt_is_deleted)  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n```\r\n\u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 (Expression)                                                                           \u2502\r\n\u2502 ExpressionTransform                                                                    \u2502\r\n\u2502   (Aggregating)                                                                        \u2502\r\n\u2502   Resize 2 \u2192 1                                                                         \u2502\r\n\u2502     AggregatingTransform \u00d7 2                                                           \u2502\r\n\u2502       StrictResize 2 \u2192 2                                                               \u2502\r\n\u2502         (Expression)                                                                   \u2502\r\n\u2502         ExpressionTransform \u00d7 2                                                        \u2502\r\n\u2502           (ReadFromMergeTree)                                                          \u2502\r\n\u2502           ExpressionTransform \u00d7 2                                                      \u2502\r\n\u2502             ReplacingSorted                                                            \u2502\r\n\u2502               ExpressionTransform                                                      \u2502\r\n\u2502                 MergeTreeSelect(pool: ReadPoolInOrder, algorithm: InOrder) 0 \u2192 1       \u2502\r\n\u2502                   ReplacingSorted                                                      \u2502\r\n\u2502                     ExpressionTransform                                                \u2502\r\n\u2502                       MergeTreeSelect(pool: ReadPoolInOrder, algorithm: InOrder) 0 \u2192 1 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n</details>\nRemove `OPTIMIZE CLEANUP` and `is_deleted`\nSorry, you might not like this proposal, but this feature is working incorrectly, and we have no other choice than to remove it. We didn't want or welcome this feature either.\nIncorrect values insertion into the `is_deleted` column of new ReplacingMergeTree engine\nDisabling the `optimize_on_insert` setting can result in the insertion in a ReplacingMergeTree table of incorrect data into the `is_deleted` column. As a consequence, running `SELECT ... FINAL` queries on the inserted tables leads to an exception.\r\n\r\nhttps://fiddle.clickhouse.com/17113269-e156-4cd3-b00c-6622050c15b9\r\n\r\n\r\n**How to reproduce:**\r\n\r\nClickHouse version 23.2\r\n```\r\nCREATE TABLE default.test\r\n(\r\n    `id` String,\r\n    `version` UInt32,\r\n    `is_deleted` UInt8\r\n)\r\nENGINE = ReplacingMergeTree(version, is_deleted)\r\nORDER BY id\r\nSETTINGS index_granularity = 8192\r\n\r\nSET optimize_on_insert=0;\r\n\r\nINSERT INTO test VALUES ('data1', 1, '6');\r\n\r\nSELECT * from test FINAL\r\n\r\n```\r\n**Result:**\r\nReceived exception from server (version 23.2.3):\r\nCode: 117. DB::Exception: Received from localhost:9000. DB::Exception: Incorrect data: is_deleted = 6 (must be 1 or 0).: While executing ReplacingSorted. (INCORRECT_DATA)\n",
  "hints_text": "related https://github.com/ClickHouse/ClickHouse/issues/49685\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/issues/49685#issuecomment-1546308031\n\ncould you pls share `select * from system.parts where table = 'rmt_is_deleted' \\G`\n@nickitat sure thing:\r\n\r\n<details>\r\n<summary><code>SELECT * FROM system.parts WHERE table = 'rmt_is_deleted' \\G</code></summary>\r\n\r\n```\r\nSELECT *\r\nFROM system.parts\r\nWHERE table = 'rmt_is_deleted'\r\n\r\nQuery id: ecdc8220-a979-4c1b-b923-efdce4e5566a\r\n\r\nRow 1:\r\n\u2500\u2500\u2500\u2500\u2500\u2500\r\npartition:                             2023-09-25\r\nname:                                  20230925_2_2_6\r\nuuid:                                  00000000-0000-0000-0000-000000000000\r\npart_type:                             Wide\r\nactive:                                1\r\nmarks:                                 6105\r\nrows:                                  50000000\r\nbytes_on_disk:                         403137590\r\ndata_compressed_bytes:                 403073794\r\ndata_uncompressed_bytes:               950054936\r\nprimary_key_size:                      4910\r\nmarks_bytes:                           58481\r\nsecondary_indices_compressed_bytes:    0\r\nsecondary_indices_uncompressed_bytes:  0\r\nsecondary_indices_marks_bytes:         0\r\nmodification_time:                     2023-09-25 13:29:46\r\nremove_time:                           1970-01-01 00:00:00\r\nrefcount:                              1\r\nmin_date:                              2023-09-25\r\nmax_date:                              2023-09-25\r\nmin_time:                              1970-01-01 00:00:00\r\nmax_time:                              1970-01-01 00:00:00\r\npartition_id:                          20230925\r\nmin_block_number:                      2\r\nmax_block_number:                      2\r\nlevel:                                 6\r\ndata_version:                          2\r\nprimary_key_bytes_in_memory:           48840\r\nprimary_key_bytes_in_memory_allocated: 65536\r\nis_frozen:                             0\r\ndatabase:                              demo\r\ntable:                                 rmt_is_deleted\r\nengine:                                ReplacingMergeTree\r\ndisk_name:                             default\r\npath:                                  /var/lib/clickhouse/store/923/92314d22-e79f-4cf9-957c-54324539f07d/20230925_2_2_6/\r\nhash_of_all_files:                     eacf5974f267d0e7d6620bae0aa18099\r\nhash_of_uncompressed_files:            5a3ad202f99d1969dab1a23a339ea695\r\nuncompressed_hash_of_compressed_files: 52ec43591fb398c8f903ceaff01ceb05\r\ndelete_ttl_info_min:                   1970-01-01 00:00:00\r\ndelete_ttl_info_max:                   1970-01-01 00:00:00\r\nmove_ttl_info.expression:              []\r\nmove_ttl_info.min:                     []\r\nmove_ttl_info.max:                     []\r\ndefault_compression_codec:             LZ4\r\nrecompression_ttl_info.expression:     []\r\nrecompression_ttl_info.min:            []\r\nrecompression_ttl_info.max:            []\r\ngroup_by_ttl_info.expression:          []\r\ngroup_by_ttl_info.min:                 []\r\ngroup_by_ttl_info.max:                 []\r\nrows_where_ttl_info.expression:        []\r\nrows_where_ttl_info.min:               []\r\nrows_where_ttl_info.max:               []\r\nprojections:                           []\r\nvisible:                               1\r\ncreation_tid:                          (1,1,'00000000-0000-0000-0000-000000000000')\r\nremoval_tid_lock:                      0\r\nremoval_tid:                           (0,0,'00000000-0000-0000-0000-000000000000')\r\ncreation_csn:                          0\r\nremoval_csn:                           0\r\nhas_lightweight_delete:                0\r\nlast_removal_attempt_time:             1970-01-01 00:00:00\r\nremoval_state:                         Cleanup thread hasn't seen this part yet\r\n\r\nRow 2:\r\n\u2500\u2500\u2500\u2500\u2500\u2500\r\npartition:                             2023-09-26\r\nname:                                  20230926_3_3_3\r\nuuid:                                  00000000-0000-0000-0000-000000000000\r\npart_type:                             Wide\r\nactive:                                1\r\nmarks:                                 6105\r\nrows:                                  50000000\r\nbytes_on_disk:                         403137590\r\ndata_compressed_bytes:                 403073794\r\ndata_uncompressed_bytes:               950054936\r\nprimary_key_size:                      4910\r\nmarks_bytes:                           58481\r\nsecondary_indices_compressed_bytes:    0\r\nsecondary_indices_uncompressed_bytes:  0\r\nsecondary_indices_marks_bytes:         0\r\nmodification_time:                     2023-09-25 13:29:52\r\nremove_time:                           1970-01-01 00:00:00\r\nrefcount:                              1\r\nmin_date:                              2023-09-26\r\nmax_date:                              2023-09-26\r\nmin_time:                              1970-01-01 00:00:00\r\nmax_time:                              1970-01-01 00:00:00\r\npartition_id:                          20230926\r\nmin_block_number:                      3\r\nmax_block_number:                      3\r\nlevel:                                 3\r\ndata_version:                          3\r\nprimary_key_bytes_in_memory:           48840\r\nprimary_key_bytes_in_memory_allocated: 65536\r\nis_frozen:                             0\r\ndatabase:                              demo\r\ntable:                                 rmt_is_deleted\r\nengine:                                ReplacingMergeTree\r\ndisk_name:                             disk2\r\npath:                                  /var/lib/clickhouse_disk2/store/923/92314d22-e79f-4cf9-957c-54324539f07d/20230926_3_3_3/\r\nhash_of_all_files:                     a43731d92c970c40b1718d3bc9cea45e\r\nhash_of_uncompressed_files:            202724e2edabca2de4bf50480bd05950\r\nuncompressed_hash_of_compressed_files: 85d15d824d6c867013cdbf156c61763e\r\ndelete_ttl_info_min:                   1970-01-01 00:00:00\r\ndelete_ttl_info_max:                   1970-01-01 00:00:00\r\nmove_ttl_info.expression:              []\r\nmove_ttl_info.min:                     []\r\nmove_ttl_info.max:                     []\r\ndefault_compression_codec:             LZ4\r\nrecompression_ttl_info.expression:     []\r\nrecompression_ttl_info.min:            []\r\nrecompression_ttl_info.max:            []\r\ngroup_by_ttl_info.expression:          []\r\ngroup_by_ttl_info.min:                 []\r\ngroup_by_ttl_info.max:                 []\r\nrows_where_ttl_info.expression:        []\r\nrows_where_ttl_info.min:               []\r\nrows_where_ttl_info.max:               []\r\nprojections:                           []\r\nvisible:                               1\r\ncreation_tid:                          (1,1,'00000000-0000-0000-0000-000000000000')\r\nremoval_tid_lock:                      0\r\nremoval_tid:                           (0,0,'00000000-0000-0000-0000-000000000000')\r\ncreation_csn:                          0\r\nremoval_csn:                           0\r\nhas_lightweight_delete:                0\r\nlast_removal_attempt_time:             1970-01-01 00:00:00\r\nremoval_state:                         Cleanup thread hasn't seen this part yet\r\n\r\n2 rows in set. Elapsed: 0.005 sec.\r\n```\r\n\r\n</details>\nI was struggling to understand why it happens, turned out that there is the explicit check for it:\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/d9a634eb0f3198658af25f86221a331b05e1cd39/src/Processors/QueryPlan/ReadFromMergeTree.cpp#L1085-L1088\n\nWorkaround: https://clickhouse.com/docs/en/sql-reference/statements/create/table#constraints ",
  "created_at": "2023-12-15T21:43:56Z"
}