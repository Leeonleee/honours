{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 29219,
  "instance_id": "ClickHouse__ClickHouse-29219",
  "issue_numbers": [
    "23860"
  ],
  "base_commit": "f1adde1b5f931dce69b38ca26fc02ea6dfb0bebf",
  "patch": "diff --git a/base/daemon/BaseDaemon.cpp b/base/daemon/BaseDaemon.cpp\nindex b3f6f05143db..2b703f7fa3a2 100644\n--- a/base/daemon/BaseDaemon.cpp\n+++ b/base/daemon/BaseDaemon.cpp\n@@ -63,6 +63,9 @@\n #include <Common/Elf.h>\n #include <filesystem>\n \n+#include <loggers/OwnFormattingChannel.h>\n+#include <loggers/OwnPatternFormatter.h>\n+\n #include <Common/config_version.h>\n \n #if defined(OS_DARWIN)\n@@ -1001,6 +1004,14 @@ void BaseDaemon::setupWatchdog()\n             memcpy(argv0, new_process_name, std::min(strlen(new_process_name), original_process_name.size()));\n         }\n \n+        /// If streaming compression of logs is used then we write watchdog logs to cerr\n+        if (config().getRawString(\"logger.stream_compress\", \"false\") == \"true\")\n+        {\n+            Poco::AutoPtr<OwnPatternFormatter> pf = new OwnPatternFormatter;\n+            Poco::AutoPtr<DB::OwnFormattingChannel> log = new DB::OwnFormattingChannel(pf, new Poco::ConsoleChannel(std::cerr));\n+            logger().setChannel(log);\n+        }\n+\n         logger().information(fmt::format(\"Will watch for the process with pid {}\", pid));\n \n         /// Forward signals to the child process.\ndiff --git a/base/loggers/Loggers.cpp b/base/loggers/Loggers.cpp\nindex 0f41296819e8..5eb9ef951764 100644\n--- a/base/loggers/Loggers.cpp\n+++ b/base/loggers/Loggers.cpp\n@@ -62,7 +62,13 @@ void Loggers::buildLoggers(Poco::Util::AbstractConfiguration & config, Poco::Log\n     if (!log_path.empty())\n     {\n         createDirectory(log_path);\n-        std::cerr << \"Logging \" << log_level_string << \" to \" << log_path << std::endl;\n+\n+        std::string ext;\n+        if (config.getRawString(\"logger.stream_compress\", \"false\") == \"true\")\n+            ext = \".lz4\";\n+\n+        std::cerr << \"Logging \" << log_level_string << \" to \" << log_path << ext << std::endl;\n+\n         auto log_level = Poco::Logger::parseLevel(log_level_string);\n         if (log_level > max_log_level)\n         {\n@@ -75,6 +81,7 @@ void Loggers::buildLoggers(Poco::Util::AbstractConfiguration & config, Poco::Log\n         log_file->setProperty(Poco::FileChannel::PROP_ROTATION, config.getRawString(\"logger.size\", \"100M\"));\n         log_file->setProperty(Poco::FileChannel::PROP_ARCHIVE, \"number\");\n         log_file->setProperty(Poco::FileChannel::PROP_COMPRESS, config.getRawString(\"logger.compress\", \"true\"));\n+        log_file->setProperty(Poco::FileChannel::PROP_STREAMCOMPRESS, config.getRawString(\"logger.stream_compress\", \"false\"));\n         log_file->setProperty(Poco::FileChannel::PROP_PURGECOUNT, config.getRawString(\"logger.count\", \"1\"));\n         log_file->setProperty(Poco::FileChannel::PROP_FLUSH, config.getRawString(\"logger.flush\", \"true\"));\n         log_file->setProperty(Poco::FileChannel::PROP_ROTATEONOPEN, config.getRawString(\"logger.rotateOnOpen\", \"false\"));\n@@ -100,13 +107,18 @@ void Loggers::buildLoggers(Poco::Util::AbstractConfiguration & config, Poco::Log\n             max_log_level = errorlog_level;\n         }\n \n-        std::cerr << \"Logging errors to \" << errorlog_path << std::endl;\n+        std::string ext;\n+        if (config.getRawString(\"logger.stream_compress\", \"false\") == \"true\")\n+            ext = \".lz4\";\n+\n+        std::cerr << \"Logging errors to \" << errorlog_path << ext << std::endl;\n \n         error_log_file = new Poco::FileChannel;\n         error_log_file->setProperty(Poco::FileChannel::PROP_PATH, fs::weakly_canonical(errorlog_path));\n         error_log_file->setProperty(Poco::FileChannel::PROP_ROTATION, config.getRawString(\"logger.size\", \"100M\"));\n         error_log_file->setProperty(Poco::FileChannel::PROP_ARCHIVE, \"number\");\n         error_log_file->setProperty(Poco::FileChannel::PROP_COMPRESS, config.getRawString(\"logger.compress\", \"true\"));\n+        error_log_file->setProperty(Poco::FileChannel::PROP_STREAMCOMPRESS, config.getRawString(\"logger.stream_compress\", \"false\"));\n         error_log_file->setProperty(Poco::FileChannel::PROP_PURGECOUNT, config.getRawString(\"logger.count\", \"1\"));\n         error_log_file->setProperty(Poco::FileChannel::PROP_FLUSH, config.getRawString(\"logger.flush\", \"true\"));\n         error_log_file->setProperty(Poco::FileChannel::PROP_ROTATEONOPEN, config.getRawString(\"logger.rotateOnOpen\", \"false\"));\ndiff --git a/contrib/poco b/contrib/poco\nindex 173fb3171783..258b9ba6cd24 160000\n--- a/contrib/poco\n+++ b/contrib/poco\n@@ -1,1 +1,1 @@\n-Subproject commit 173fb31717837d366152c508619b09dcf11786da\n+Subproject commit 258b9ba6cd245ff88e9346f75c43464c403f329d\ndiff --git a/contrib/poco-cmake/Foundation/CMakeLists.txt b/contrib/poco-cmake/Foundation/CMakeLists.txt\nindex a9a4933873cf..0c13d1093441 100644\n--- a/contrib/poco-cmake/Foundation/CMakeLists.txt\n+++ b/contrib/poco-cmake/Foundation/CMakeLists.txt\n@@ -51,6 +51,7 @@ if (USE_INTERNAL_POCO_LIBRARY)\n         \"${LIBRARY_DIR}/Foundation/src/Channel.cpp\"\n         \"${LIBRARY_DIR}/Foundation/src/Checksum.cpp\"\n         \"${LIBRARY_DIR}/Foundation/src/Clock.cpp\"\n+        \"${LIBRARY_DIR}/Foundation/src/CompressedLogFile.cpp\"\n         \"${LIBRARY_DIR}/Foundation/src/Condition.cpp\"\n         \"${LIBRARY_DIR}/Foundation/src/Configurable.cpp\"\n         \"${LIBRARY_DIR}/Foundation/src/ConsoleChannel.cpp\"\n@@ -222,7 +223,7 @@ if (USE_INTERNAL_POCO_LIBRARY)\n             POCO_OS_FAMILY_UNIX\n     )\n     target_include_directories (_poco_foundation SYSTEM PUBLIC \"${LIBRARY_DIR}/Foundation/include\")\n-    target_link_libraries (_poco_foundation PRIVATE Poco::Foundation::PCRE ${ZLIB_LIBRARIES})\n+    target_link_libraries (_poco_foundation PRIVATE Poco::Foundation::PCRE ${ZLIB_LIBRARIES} lz4)\n else ()\n     add_library (Poco::Foundation UNKNOWN IMPORTED GLOBAL)\n \n",
  "test_patch": "diff --git a/docker/test/integration/base/Dockerfile b/docker/test/integration/base/Dockerfile\nindex 519c64297e55..add4dad0132d 100644\n--- a/docker/test/integration/base/Dockerfile\n+++ b/docker/test/integration/base/Dockerfile\n@@ -19,6 +19,7 @@ RUN apt-get update \\\n         sqlite3 \\\n         curl \\\n         tar \\\n+        lz4 \\\n         krb5-user \\\n         iproute2 \\\n         lsof \\\ndiff --git a/tests/integration/test_backward_compatibility/test_aggregate_fixed_key.py b/tests/integration/test_backward_compatibility/test_aggregate_fixed_key.py\nindex 98658ec81d07..fc8d27cfa162 100644\n--- a/tests/integration/test_backward_compatibility/test_aggregate_fixed_key.py\n+++ b/tests/integration/test_backward_compatibility/test_aggregate_fixed_key.py\n@@ -4,8 +4,8 @@\n \n cluster = ClickHouseCluster(__file__, name=\"aggregate_fixed_key\")\n node1 = cluster.add_instance('node1', with_zookeeper=True, image='yandex/clickhouse-server', tag='21.3', with_installed_binary=True)\n-node2 = cluster.add_instance('node2', with_zookeeper=True, image='yandex/clickhouse-server')\n-node3 = cluster.add_instance('node3', with_zookeeper=True, image='yandex/clickhouse-server')\n+node2 = cluster.add_instance('node2', with_zookeeper=True)\n+node3 = cluster.add_instance('node3', with_zookeeper=True)\n \n \n @pytest.fixture(scope=\"module\")\ndiff --git a/tests/integration/test_log_lz4_streaming/__init__.py b/tests/integration/test_log_lz4_streaming/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_log_lz4_streaming/configs/logs.xml b/tests/integration/test_log_lz4_streaming/configs/logs.xml\nnew file mode 100644\nindex 000000000000..43a43cd231b9\n--- /dev/null\n+++ b/tests/integration/test_log_lz4_streaming/configs/logs.xml\n@@ -0,0 +1,5 @@\n+<yandex>\n+    <logger>\n+        <stream_compress>true</stream_compress>\n+    </logger>\n+</yandex>\ndiff --git a/tests/integration/test_log_lz4_streaming/test.py b/tests/integration/test_log_lz4_streaming/test.py\nnew file mode 100644\nindex 000000000000..7f2f22f28c94\n--- /dev/null\n+++ b/tests/integration/test_log_lz4_streaming/test.py\n@@ -0,0 +1,44 @@\n+import pytest\n+import time\n+\n+from helpers.cluster import ClickHouseCluster\n+\n+cluster = ClickHouseCluster(__file__)\n+\n+node = cluster.add_instance('node', main_configs=['configs/logs.xml'], stay_alive=True)\n+\n+@pytest.fixture(scope=\"module\")\n+def started_cluster():\n+    try:\n+        cluster.start()\n+        yield cluster\n+\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def check_log_file():\n+    assert node.file_exists(\"/var/log/clickhouse-server/clickhouse-server.log.lz4\")\n+\n+    lz4_output = node.exec_in_container([\"bash\", \"-c\", \"lz4 -t /var/log/clickhouse-server/clickhouse-server.log.lz4 2>&1\"], user='root')\n+    assert lz4_output.count('Error') == 0, lz4_output\n+\n+    compressed_size = int(node.exec_in_container([\"bash\", \"-c\", \"du -b /var/log/clickhouse-server/clickhouse-server.log.lz4 | awk {' print $1 '}\"], user='root'))\n+    uncompressed_size = int(lz4_output.split()[3])\n+    assert 0 < compressed_size < uncompressed_size, lz4_output\n+\n+\n+def test_concatenation(started_cluster):\n+    node.stop_clickhouse()\n+    node.start_clickhouse()\n+    node.stop_clickhouse()\n+\n+    check_log_file()\n+\n+\n+def test_incomplete_rotation(started_cluster):\n+    node.stop_clickhouse(kill=True)\n+    node.start_clickhouse()\n+    node.stop_clickhouse()\n+\n+    check_log_file()\n",
  "problem_statement": "RFC: LZ4 compressed clickhouse logs\nI really love clickhouse logs. They helped me a lot of times, they 'tell stories' :) \r\n\r\nBut on limited env (like tiny cloud instances) people often set the main log level from trace to information, or just disable it at all, keeping err log only - and motivation is very simple - logs are quite big, they take disk space & part of disk bandwidth - and that effect is very visible on tiny instances.\r\n\r\nMaybe if we would compress them with LZ4 (streaming) it will be fewer reasons to disable them? \r\n\r\nWhat do you think of that? (I'm not totally convinced if it's good, because logs usually are expected to be straight and simple). \n",
  "hints_text": "That's a good feature. It can be beneficial to enable streaming lz4 compression and disable gz compression of rotated files.\r\n\r\nJust to confirm, is it true that:\r\n- lz4 framing format allows streaming compression with appends and it can decompress the data at any point of time?\r\n- the integration in OS (at least Ubuntu), e.g. `less`, viewing inside `mc`, `grep` works with this format?\n```bash \r\napt-get update \r\napt-get install lz4\r\n\r\n# yes, it is appendable:\r\n$ echo 1 |  lz4c  >> log.lz4 \r\n$ echo 2 |  lz4c  >> log.lz4 \r\n$ echo 3 |  lz4c  >> log.lz4\r\n\r\n$ lz4cat log.lz4\r\n1\r\n2\r\n3\r\n\r\n# yes, there are nice command line wrappers: \r\n\r\n$ lz4cat log.lz4 | grep 2\r\n2\r\n\r\n$ lz4cat log.lz4 | less \r\n\r\n# ripgrep supports it out of the box (with -z flag)\r\napt-get install ripgrep\r\n\r\n$ rg -z 2 log.lz4 \r\n2:2\r\n\r\n# midnight commander view supports lz4 files natively\r\n```\r\n\r\nSee also manpages: http://manpages.ubuntu.com/manpages/bionic/man1/lz4.1.html \nBut there is a question - how well it will be able to compress in streaming mode (i guess if we will compress each line individually the compression will be poor), but i think it should have some modes for that. I.e. start appending only when clickhouse restart, otherwise write it a single stream. \r\n\r\nUPD: it seems we need 'AutoFraming' format: https://github.com/lz4/lz4/blob/dev/examples/streaming_api_basics.md",
  "created_at": "2021-09-21T11:20:07Z"
}