{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 4535,
  "instance_id": "ClickHouse__ClickHouse-4535",
  "issue_numbers": [
    "4316"
  ],
  "base_commit": "a4e56478cab004005b5f90657da0e828e8c2df67",
  "patch": "diff --git a/dbms/programs/server/TCPHandler.cpp b/dbms/programs/server/TCPHandler.cpp\nindex 32b877fb2b8a..013f047ae67c 100644\n--- a/dbms/programs/server/TCPHandler.cpp\n+++ b/dbms/programs/server/TCPHandler.cpp\n@@ -724,7 +724,7 @@ bool TCPHandler::receiveData()\n                 query_context.addExternalTable(external_table_name, storage);\n             }\n             /// The data will be written directly to the table.\n-            state.io.out = storage->write(ASTPtr(), query_context.getSettingsRef());\n+            state.io.out = storage->write(ASTPtr(), query_context);\n         }\n         if (block)\n             state.io.out->write(block);\ndiff --git a/dbms/src/Common/RWLock.cpp b/dbms/src/Common/RWLock.cpp\nindex 98e2a9f2995d..7eea6c7d76d4 100644\n--- a/dbms/src/Common/RWLock.cpp\n+++ b/dbms/src/Common/RWLock.cpp\n@@ -33,27 +33,28 @@ namespace ErrorCodes\n }\n \n \n-class RWLockImpl::LockHandlerImpl\n+class RWLockImpl::LockHolderImpl\n {\n     RWLock parent;\n     GroupsContainer::iterator it_group;\n     ClientsContainer::iterator it_client;\n-    ThreadToHandler::iterator it_handler;\n+    ThreadToHolder::iterator it_thread;\n+    QueryIdToHolder::iterator it_query;\n     CurrentMetrics::Increment active_client_increment;\n \n-    LockHandlerImpl(RWLock && parent, GroupsContainer::iterator it_group, ClientsContainer::iterator it_client);\n+    LockHolderImpl(RWLock && parent, GroupsContainer::iterator it_group, ClientsContainer::iterator it_client);\n \n public:\n \n-    LockHandlerImpl(const LockHandlerImpl & other) = delete;\n+    LockHolderImpl(const LockHolderImpl & other) = delete;\n \n-    ~LockHandlerImpl();\n+    ~LockHolderImpl();\n \n     friend class RWLockImpl;\n };\n \n \n-RWLockImpl::LockHandler RWLockImpl::getLock(RWLockImpl::Type type)\n+RWLockImpl::LockHolder RWLockImpl::getLock(RWLockImpl::Type type, const String & query_id)\n {\n     Stopwatch watch(CLOCK_MONOTONIC_COARSE);\n     CurrentMetrics::Increment waiting_client_increment((type == Read) ? CurrentMetrics::RWLockWaitingReaders\n@@ -66,28 +67,33 @@ RWLockImpl::LockHandler RWLockImpl::getLock(RWLockImpl::Type type)\n                                                 : ProfileEvents::RWLockWritersWaitMilliseconds, watch.elapsedMilliseconds());\n     };\n \n-    auto this_thread_id = std::this_thread::get_id();\n     GroupsContainer::iterator it_group;\n     ClientsContainer::iterator it_client;\n \n     std::unique_lock lock(mutex);\n \n-    /// Check if the same thread is acquiring previously acquired lock\n-    auto it_handler = thread_to_handler.find(this_thread_id);\n-    if (it_handler != thread_to_handler.end())\n-    {\n-        auto handler_ptr = it_handler->second.lock();\n+    /// Check if the same query is acquiring previously acquired lock\n+    LockHolder existing_holder_ptr;\n+\n+    auto this_thread_id = std::this_thread::get_id();\n+    auto it_thread = thread_to_holder.find(this_thread_id);\n \n-        /// Lock may be released in another thread, but not yet deleted inside |~LogHandlerImpl()|\n+    auto it_query = query_id_to_holder.end();\n+    if (query_id != RWLockImpl::NO_QUERY)\n+        it_query = query_id_to_holder.find(query_id);\n \n-        if (handler_ptr)\n-        {\n-            /// XXX: it means we can't upgrade lock from read to write - with proper waiting!\n-            if (type != Read || handler_ptr->it_group->type != Read)\n-                throw Exception(\"Attempt to acquire exclusive lock recursively\", ErrorCodes::LOGICAL_ERROR);\n+    if (it_thread != thread_to_holder.end())\n+        existing_holder_ptr = it_thread->second.lock();\n+    else if (it_query != query_id_to_holder.end())\n+        existing_holder_ptr = it_query->second.lock();\n \n-            return handler_ptr;\n-        }\n+    if (existing_holder_ptr)\n+    {\n+        /// XXX: it means we can't upgrade lock from read to write - with proper waiting!\n+        if (type != Read || existing_holder_ptr->it_group->type != Read)\n+            throw Exception(\"Attempt to acquire exclusive lock recursively\", ErrorCodes::LOGICAL_ERROR);\n+\n+        return existing_holder_ptr;\n     }\n \n     if (type == Type::Write || queue.empty() || queue.back().type == Type::Write)\n@@ -115,11 +121,15 @@ RWLockImpl::LockHandler RWLockImpl::getLock(RWLockImpl::Type type)\n         throw;\n     }\n \n-    LockHandler res(new LockHandlerImpl(shared_from_this(), it_group, it_client));\n+    LockHolder res(new LockHolderImpl(shared_from_this(), it_group, it_client));\n \n-    /// Insert myself (weak_ptr to the handler) to threads set to implement recursive lock\n-    it_handler = thread_to_handler.emplace(this_thread_id, res).first;\n-    res->it_handler = it_handler;\n+    /// Insert myself (weak_ptr to the holder) to threads set to implement recursive lock\n+    it_thread = thread_to_holder.emplace(this_thread_id, res).first;\n+    res->it_thread = it_thread;\n+\n+    if (query_id != RWLockImpl::NO_QUERY)\n+        it_query = query_id_to_holder.emplace(query_id, res).first;\n+    res->it_query = it_query;\n \n     /// We are first, we should not wait anything\n     /// If we are not the first client in the group, a notification could be already sent\n@@ -137,12 +147,15 @@ RWLockImpl::LockHandler RWLockImpl::getLock(RWLockImpl::Type type)\n }\n \n \n-RWLockImpl::LockHandlerImpl::~LockHandlerImpl()\n+RWLockImpl::LockHolderImpl::~LockHolderImpl()\n {\n     std::unique_lock lock(parent->mutex);\n \n-    /// Remove weak_ptr to the handler, since there are no owners of the current lock\n-    parent->thread_to_handler.erase(it_handler);\n+    /// Remove weak_ptrs to the holder, since there are no owners of the current lock\n+    parent->thread_to_holder.erase(it_thread);\n+\n+    if (it_query != parent->query_id_to_holder.end())\n+        parent->query_id_to_holder.erase(it_query);\n \n     /// Removes myself from client list of our group\n     it_group->clients.erase(it_client);\n@@ -161,7 +174,7 @@ RWLockImpl::LockHandlerImpl::~LockHandlerImpl()\n }\n \n \n-RWLockImpl::LockHandlerImpl::LockHandlerImpl(RWLock && parent, RWLockImpl::GroupsContainer::iterator it_group,\n+RWLockImpl::LockHolderImpl::LockHolderImpl(RWLock && parent, RWLockImpl::GroupsContainer::iterator it_group,\n                                              RWLockImpl::ClientsContainer::iterator it_client)\n     : parent{std::move(parent)}, it_group{it_group}, it_client{it_client},\n       active_client_increment{(*it_client == RWLockImpl::Read) ? CurrentMetrics::RWLockActiveReaders\ndiff --git a/dbms/src/Common/RWLock.h b/dbms/src/Common/RWLock.h\nindex fd95ed48e27c..858411dbb086 100644\n--- a/dbms/src/Common/RWLock.h\n+++ b/dbms/src/Common/RWLock.h\n@@ -1,4 +1,5 @@\n #pragma once\n+#include <Core/Types.h>\n #include <boost/core/noncopyable.hpp>\n #include <list>\n #include <vector>\n@@ -17,7 +18,13 @@ using RWLock = std::shared_ptr<RWLockImpl>;\n \n \n /// Implements shared lock with FIFO service\n-/// Can be acquired recursively (several calls from the same thread) in Read mode\n+/// Can be acquired recursively (several calls for the same query or the same OS thread) in Read mode\n+///\n+/// NOTE: it is important to allow acquiring the same lock in Read mode without waiting if it is already\n+/// acquired by another thread of the same query. Otherwise the following deadlock is possible:\n+/// - SELECT thread 1 locks in the Read mode\n+/// - ALTER tries to lock in the Write mode (waits for SELECT thread 1)\n+/// - SELECT thread 2 tries to lock in the Read mode (waits for ALTER)\n class RWLockImpl : public std::enable_shared_from_this<RWLockImpl>\n {\n public:\n@@ -29,14 +36,17 @@ class RWLockImpl : public std::enable_shared_from_this<RWLockImpl>\n \n     static RWLock create() { return RWLock(new RWLockImpl); }\n \n-    /// Just use LockHandler::reset() to release the lock\n-    class LockHandlerImpl;\n-    friend class LockHandlerImpl;\n-    using LockHandler = std::shared_ptr<LockHandlerImpl>;\n-\n+    /// Just use LockHolder::reset() to release the lock\n+    class LockHolderImpl;\n+    friend class LockHolderImpl;\n+    using LockHolder = std::shared_ptr<LockHolderImpl>;\n \n     /// Waits in the queue and returns appropriate lock\n-    LockHandler getLock(Type type);\n+    /// Empty query_id means the lock is acquired out of the query context (e.g. in a background thread).\n+    LockHolder getLock(Type type, const String & query_id);\n+\n+    /// Use as query_id to acquire a lock outside the query context.\n+    inline static const String NO_QUERY = String();\n \n private:\n     RWLockImpl() = default;\n@@ -44,7 +54,8 @@ class RWLockImpl : public std::enable_shared_from_this<RWLockImpl>\n     struct Group;\n     using GroupsContainer = std::list<Group>;\n     using ClientsContainer = std::list<Type>;\n-    using ThreadToHandler = std::map<std::thread::id, std::weak_ptr<LockHandlerImpl>>;\n+    using ThreadToHolder = std::map<std::thread::id, std::weak_ptr<LockHolderImpl>>;\n+    using QueryIdToHolder = std::map<String, std::weak_ptr<LockHolderImpl>>;\n \n     /// Group of clients that should be executed concurrently\n     /// i.e. a group could contain several readers, but only one writer\n@@ -61,7 +72,8 @@ class RWLockImpl : public std::enable_shared_from_this<RWLockImpl>\n \n     mutable std::mutex mutex;\n     GroupsContainer queue;\n-    ThreadToHandler thread_to_handler;\n+    ThreadToHolder thread_to_holder;\n+    QueryIdToHolder query_id_to_holder;\n };\n \n \ndiff --git a/dbms/src/Core/ExternalTable.cpp b/dbms/src/Core/ExternalTable.cpp\nindex 5bfdbb12e954..65bff362aa7c 100644\n--- a/dbms/src/Core/ExternalTable.cpp\n+++ b/dbms/src/Core/ExternalTable.cpp\n@@ -163,7 +163,7 @@ void ExternalTablesHandler::handlePart(const Poco::Net::MessageHeader & header,\n     StoragePtr storage = StorageMemory::create(data.second, ColumnsDescription{columns});\n     storage->startup();\n     context.addExternalTable(data.second, storage);\n-    BlockOutputStreamPtr output = storage->write(ASTPtr(), settings);\n+    BlockOutputStreamPtr output = storage->write(ASTPtr(), context);\n \n     /// Write data\n     data.first->readPrefix();\ndiff --git a/dbms/src/DataStreams/CreatingSetsBlockInputStream.cpp b/dbms/src/DataStreams/CreatingSetsBlockInputStream.cpp\nindex f47db3e3a8b0..9255527d072a 100644\n--- a/dbms/src/DataStreams/CreatingSetsBlockInputStream.cpp\n+++ b/dbms/src/DataStreams/CreatingSetsBlockInputStream.cpp\n@@ -19,10 +19,14 @@ namespace ErrorCodes\n CreatingSetsBlockInputStream::CreatingSetsBlockInputStream(\n     const BlockInputStreamPtr & input,\n     const SubqueriesForSets & subqueries_for_sets_,\n-    const SizeLimits & network_transfer_limits)\n-    : subqueries_for_sets(subqueries_for_sets_),\n-    network_transfer_limits(network_transfer_limits)\n+    const Context & context_)\n+    : subqueries_for_sets(subqueries_for_sets_)\n+    , context(context_)\n {\n+    const Settings & settings = context.getSettingsRef();\n+    network_transfer_limits = SizeLimits(\n+        settings.max_rows_to_transfer, settings.max_bytes_to_transfer, settings.transfer_overflow_mode);\n+\n     for (auto & elem : subqueries_for_sets)\n     {\n         if (elem.second.source)\n@@ -92,7 +96,7 @@ void CreatingSetsBlockInputStream::createOne(SubqueryForSet & subquery)\n \n     BlockOutputStreamPtr table_out;\n     if (subquery.table)\n-        table_out = subquery.table->write({}, {});\n+        table_out = subquery.table->write({}, context);\n \n     bool done_with_set = !subquery.set;\n     bool done_with_join = !subquery.join;\ndiff --git a/dbms/src/DataStreams/CreatingSetsBlockInputStream.h b/dbms/src/DataStreams/CreatingSetsBlockInputStream.h\nindex 241f43c9a06f..b37c45164b5a 100644\n--- a/dbms/src/DataStreams/CreatingSetsBlockInputStream.h\n+++ b/dbms/src/DataStreams/CreatingSetsBlockInputStream.h\n@@ -20,7 +20,7 @@ class CreatingSetsBlockInputStream : public IBlockInputStream\n     CreatingSetsBlockInputStream(\n         const BlockInputStreamPtr & input,\n         const SubqueriesForSets & subqueries_for_sets_,\n-        const SizeLimits & network_transfer_limits);\n+        const Context & context_);\n \n     String getName() const override { return \"CreatingSets\"; }\n \n@@ -35,6 +35,7 @@ class CreatingSetsBlockInputStream : public IBlockInputStream\n \n private:\n     SubqueriesForSets subqueries_for_sets;\n+    const Context & context;\n     bool created = false;\n \n     SizeLimits network_transfer_limits;\ndiff --git a/dbms/src/DataStreams/PushingToViewsBlockOutputStream.cpp b/dbms/src/DataStreams/PushingToViewsBlockOutputStream.cpp\nindex 19046b535ba5..5cb0a1e57e43 100644\n--- a/dbms/src/DataStreams/PushingToViewsBlockOutputStream.cpp\n+++ b/dbms/src/DataStreams/PushingToViewsBlockOutputStream.cpp\n@@ -20,7 +20,7 @@ PushingToViewsBlockOutputStream::PushingToViewsBlockOutputStream(\n       * Although now any insertion into the table is done via PushingToViewsBlockOutputStream,\n       *  but it's clear that here is not the best place for this functionality.\n       */\n-    addTableLock(storage->lockStructure(true));\n+    addTableLock(storage->lockStructure(true, context.getCurrentQueryId()));\n \n     /// If the \"root\" table deduplactes blocks, there are no need to make deduplication for children\n     /// Moreover, deduplication for AggregatingMergeTree children could produce false positives due to low size of inserting blocks\n@@ -45,7 +45,7 @@ PushingToViewsBlockOutputStream::PushingToViewsBlockOutputStream(\n             auto & materialized_view = dynamic_cast<const StorageMaterializedView &>(*dependent_table);\n \n             if (StoragePtr inner_table = materialized_view.tryGetTargetTable())\n-                addTableLock(inner_table->lockStructure(true));\n+                addTableLock(inner_table->lockStructure(true, context.getCurrentQueryId()));\n \n             auto query = materialized_view.getInnerQuery();\n             BlockOutputStreamPtr out = std::make_shared<PushingToViewsBlockOutputStream>(\n@@ -57,7 +57,7 @@ PushingToViewsBlockOutputStream::PushingToViewsBlockOutputStream(\n     /* Do not push to destination table if the flag is set */\n     if (!no_destination)\n     {\n-        output = storage->write(query_ptr, context.getSettingsRef());\n+        output = storage->write(query_ptr, context);\n         replicated_output = dynamic_cast<ReplicatedMergeTreeBlockOutputStream *>(output.get());\n     }\n }\ndiff --git a/dbms/src/Functions/FunctionJoinGet.cpp b/dbms/src/Functions/FunctionJoinGet.cpp\nindex 1c0cbff7506e..3ee3145dcfc6 100644\n--- a/dbms/src/Functions/FunctionJoinGet.cpp\n+++ b/dbms/src/Functions/FunctionJoinGet.cpp\n@@ -65,7 +65,7 @@ FunctionBasePtr FunctionBuilderJoinGet::buildImpl(const ColumnsWithTypeAndName &\n     auto join = storage_join->getJoin();\n     DataTypes data_types(arguments.size());\n \n-    auto table_lock = storage_join->lockStructure(false);\n+    auto table_lock = storage_join->lockStructure(false, context.getCurrentQueryId());\n     for (size_t i = 0; i < arguments.size(); ++i)\n         data_types[i] = arguments[i].type;\n \ndiff --git a/dbms/src/Interpreters/ExpressionAnalyzer.cpp b/dbms/src/Interpreters/ExpressionAnalyzer.cpp\nindex 9c642175cb00..4a2e62fe1ec9 100644\n--- a/dbms/src/Interpreters/ExpressionAnalyzer.cpp\n+++ b/dbms/src/Interpreters/ExpressionAnalyzer.cpp\n@@ -304,7 +304,7 @@ void ExpressionAnalyzer::makeSetsForIndexImpl(const ASTPtr & node)\n     {\n         const IAST & args = *func->arguments;\n \n-        if (storage && storage->mayBenefitFromIndexForIn(args.children.at(0)))\n+        if (storage && storage->mayBenefitFromIndexForIn(args.children.at(0), context))\n         {\n             const ASTPtr & arg = args.children.at(1);\n             if (typeid_cast<ASTSubquery *>(arg.get()) || isIdentifier(arg))\ndiff --git a/dbms/src/Interpreters/InterpreterCreateQuery.cpp b/dbms/src/Interpreters/InterpreterCreateQuery.cpp\nindex aee75ce28557..708bd616828c 100644\n--- a/dbms/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -591,7 +591,7 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)\n     if (!as_table_name.empty())\n     {\n         as_storage = context.getTable(as_database_name, as_table_name);\n-        as_storage_lock = as_storage->lockStructure(false);\n+        as_storage_lock = as_storage->lockStructure(false, context.getCurrentQueryId());\n     }\n \n     /// Set and retrieve list of columns.\ndiff --git a/dbms/src/Interpreters/InterpreterDescribeQuery.cpp b/dbms/src/Interpreters/InterpreterDescribeQuery.cpp\nindex d895c64e2311..19cb167168e9 100644\n--- a/dbms/src/Interpreters/InterpreterDescribeQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterDescribeQuery.cpp\n@@ -93,7 +93,7 @@ BlockInputStreamPtr InterpreterDescribeQuery::executeImpl()\n             table = context.getTable(database_name, table_name);\n         }\n \n-        auto table_lock = table->lockStructure(false);\n+        auto table_lock = table->lockStructure(false, context.getCurrentQueryId());\n         columns = table->getColumns().getAll();\n         column_defaults = table->getColumns().defaults;\n         column_comments = table->getColumns().comments;\ndiff --git a/dbms/src/Interpreters/InterpreterDropQuery.cpp b/dbms/src/Interpreters/InterpreterDropQuery.cpp\nindex c3af6d7fa0ac..c90017721c11 100644\n--- a/dbms/src/Interpreters/InterpreterDropQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterDropQuery.cpp\n@@ -69,7 +69,7 @@ BlockIO InterpreterDropQuery::executeToTable(String & database_name_, String & t\n         {\n             database_and_table.second->shutdown();\n             /// If table was already dropped by anyone, an exception will be thrown\n-            auto table_lock = database_and_table.second->lockForAlter();\n+            auto table_lock = database_and_table.second->lockForAlter(context.getCurrentQueryId());\n             /// Drop table from memory, don't touch data and metadata\n             database_and_table.first->detachTable(database_and_table.second->getTableName());\n         }\n@@ -78,7 +78,7 @@ BlockIO InterpreterDropQuery::executeToTable(String & database_name_, String & t\n             database_and_table.second->checkTableCanBeDropped();\n \n             /// If table was already dropped by anyone, an exception will be thrown\n-            auto table_lock = database_and_table.second->lockForAlter();\n+            auto table_lock = database_and_table.second->lockForAlter(context.getCurrentQueryId());\n             /// Drop table data, don't touch metadata\n             database_and_table.second->truncate(query_ptr, context);\n         }\n@@ -89,7 +89,7 @@ BlockIO InterpreterDropQuery::executeToTable(String & database_name_, String & t\n             database_and_table.second->shutdown();\n             /// If table was already dropped by anyone, an exception will be thrown\n \n-            auto table_lock = database_and_table.second->lockForAlter();\n+            auto table_lock = database_and_table.second->lockForAlter(context.getCurrentQueryId());\n             /// Delete table metadata and table itself from memory\n \n             database_and_table.first->removeTable(context, database_and_table.second->getTableName());\n@@ -126,7 +126,7 @@ BlockIO InterpreterDropQuery::executeToTemporaryTable(String & table_name, ASTDr\n             if (kind == ASTDropQuery::Kind::Truncate)\n             {\n                 /// If table was already dropped by anyone, an exception will be thrown\n-                auto table_lock = table->lockForAlter();\n+                auto table_lock = table->lockForAlter(context.getCurrentQueryId());\n                 /// Drop table data, don't touch metadata\n                 table->truncate(query_ptr, context);\n             }\n@@ -135,7 +135,7 @@ BlockIO InterpreterDropQuery::executeToTemporaryTable(String & table_name, ASTDr\n                 context_handle.tryRemoveExternalTable(table_name);\n                 table->shutdown();\n                 /// If table was already dropped by anyone, an exception will be thrown\n-                auto table_lock = table->lockForAlter();\n+                auto table_lock = table->lockForAlter(context.getCurrentQueryId());\n                 /// Delete table data\n                 table->drop();\n                 table->is_dropped = true;\ndiff --git a/dbms/src/Interpreters/InterpreterInsertQuery.cpp b/dbms/src/Interpreters/InterpreterInsertQuery.cpp\nindex 8249ff882324..00cf8e925cd0 100644\n--- a/dbms/src/Interpreters/InterpreterInsertQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterInsertQuery.cpp\n@@ -96,7 +96,7 @@ BlockIO InterpreterInsertQuery::execute()\n     checkAccess(query);\n     StoragePtr table = getTable(query);\n \n-    auto table_lock = table->lockStructure(true);\n+    auto table_lock = table->lockStructure(true, context.getCurrentQueryId());\n \n     /// We create a pipeline of several streams, into which we will write data.\n     BlockOutputStreamPtr out;\ndiff --git a/dbms/src/Interpreters/InterpreterOptimizeQuery.cpp b/dbms/src/Interpreters/InterpreterOptimizeQuery.cpp\nindex 7d46881539cf..789787943861 100644\n--- a/dbms/src/Interpreters/InterpreterOptimizeQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterOptimizeQuery.cpp\n@@ -23,7 +23,7 @@ BlockIO InterpreterOptimizeQuery::execute()\n         return executeDDLQueryOnCluster(query_ptr, context, {ast.database});\n \n     StoragePtr table = context.getTable(ast.database, ast.table);\n-    auto table_lock = table->lockStructure(true);\n+    auto table_lock = table->lockStructure(true, context.getCurrentQueryId());\n     table->optimize(query_ptr, ast.partition, ast.final, ast.deduplicate, context);\n     return {};\n }\ndiff --git a/dbms/src/Interpreters/InterpreterRenameQuery.cpp b/dbms/src/Interpreters/InterpreterRenameQuery.cpp\nindex 58c830f3627d..e3fbe1f1de8a 100644\n--- a/dbms/src/Interpreters/InterpreterRenameQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterRenameQuery.cpp\n@@ -101,7 +101,7 @@ BlockIO InterpreterRenameQuery::execute()\n \n     for (const auto & names : unique_tables_from)\n         if (auto table = context.tryGetTable(names.database_name, names.table_name))\n-            locks.emplace_back(table->lockForAlter());\n+            locks.emplace_back(table->lockForAlter(context.getCurrentQueryId()));\n \n     /** All tables are locked. If there are more than one rename in chain,\n       *  we need to hold global lock while doing all renames. Order matters to avoid deadlocks.\ndiff --git a/dbms/src/Interpreters/InterpreterSelectQuery.cpp b/dbms/src/Interpreters/InterpreterSelectQuery.cpp\nindex c53ea7cae9ef..87ab02af45ca 100644\n--- a/dbms/src/Interpreters/InterpreterSelectQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterSelectQuery.cpp\n@@ -194,7 +194,7 @@ InterpreterSelectQuery::InterpreterSelectQuery(\n     }\n \n     if (storage)\n-        table_lock = storage->lockStructure(false);\n+        table_lock = storage->lockStructure(false, context.getCurrentQueryId());\n \n     syntax_analyzer_result = SyntaxAnalyzer(context, subquery_depth).analyze(\n         query_ptr, source_header.getNamesAndTypesList(), required_result_column_names, storage);\n@@ -1474,12 +1474,9 @@ void InterpreterSelectQuery::executeExtremes(Pipeline & pipeline)\n \n void InterpreterSelectQuery::executeSubqueriesInSetsAndJoins(Pipeline & pipeline, SubqueriesForSets & subqueries_for_sets)\n {\n-    const Settings & settings = context.getSettingsRef();\n-\n     executeUnion(pipeline);\n     pipeline.firstStream() = std::make_shared<CreatingSetsBlockInputStream>(\n-        pipeline.firstStream(), subqueries_for_sets,\n-        SizeLimits(settings.max_rows_to_transfer, settings.max_bytes_to_transfer, settings.transfer_overflow_mode));\n+        pipeline.firstStream(), subqueries_for_sets, context);\n }\n \n void InterpreterSelectQuery::unifyStreams(Pipeline & pipeline)\ndiff --git a/dbms/src/Interpreters/InterpreterSystemQuery.cpp b/dbms/src/Interpreters/InterpreterSystemQuery.cpp\nindex 722a504f35ec..e1233a04180b 100644\n--- a/dbms/src/Interpreters/InterpreterSystemQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterSystemQuery.cpp\n@@ -239,7 +239,7 @@ StoragePtr InterpreterSystemQuery::tryRestartReplica(const String & database_nam\n         table->shutdown();\n \n         /// If table was already dropped by anyone, an exception will be thrown\n-        auto table_lock = table->lockForAlter();\n+        auto table_lock = table->lockForAlter(context.getCurrentQueryId());\n         create_ast = system_context.getCreateTableQuery(database_name, table_name);\n \n         database->detachTable(table_name);\ndiff --git a/dbms/src/Interpreters/MutationsInterpreter.cpp b/dbms/src/Interpreters/MutationsInterpreter.cpp\nindex 01db6679e6ba..fc3ebe2f76e1 100644\n--- a/dbms/src/Interpreters/MutationsInterpreter.cpp\n+++ b/dbms/src/Interpreters/MutationsInterpreter.cpp\n@@ -394,11 +394,7 @@ BlockInputStreamPtr MutationsInterpreter::addStreamsForLaterStages(BlockInputStr\n \n         const SubqueriesForSets & subqueries_for_sets = stage.analyzer->getSubqueriesForSets();\n         if (!subqueries_for_sets.empty())\n-        {\n-            const auto & settings = context.getSettingsRef();\n-            in = std::make_shared<CreatingSetsBlockInputStream>(in, subqueries_for_sets,\n-                SizeLimits(settings.max_rows_to_transfer, settings.max_bytes_to_transfer, settings.transfer_overflow_mode));\n-        }\n+            in = std::make_shared<CreatingSetsBlockInputStream>(in, subqueries_for_sets, context);\n     }\n \n     in = std::make_shared<MaterializingBlockInputStream>(in);\ndiff --git a/dbms/src/Storages/IStorage.cpp b/dbms/src/Storages/IStorage.cpp\nindex 0c2a4a4d0c97..e3d143adbb74 100644\n--- a/dbms/src/Storages/IStorage.cpp\n+++ b/dbms/src/Storages/IStorage.cpp\n@@ -5,13 +5,13 @@\n namespace DB\n {\n \n-TableStructureReadLock::TableStructureReadLock(StoragePtr storage_, bool lock_structure, bool lock_data)\n+TableStructureReadLock::TableStructureReadLock(StoragePtr storage_, bool lock_structure, bool lock_data, const String & query_id)\n     : storage(storage_)\n {\n     if (lock_data)\n-        data_lock = storage->data_lock->getLock(RWLockImpl::Read);\n+        data_lock = storage->data_lock->getLock(RWLockImpl::Read, query_id);\n     if (lock_structure)\n-        structure_lock = storage->structure_lock->getLock(RWLockImpl::Read);\n+        structure_lock = storage->structure_lock->getLock(RWLockImpl::Read, query_id);\n }\n \n void IStorage::alter(const AlterCommands & params, const String & database_name, const String & table_name, const Context & context)\n@@ -22,7 +22,7 @@ void IStorage::alter(const AlterCommands & params, const String & database_name,\n             throw Exception(\"Method alter supports only change comment of column for storage \" + getName(), ErrorCodes::NOT_IMPLEMENTED);\n     }\n \n-    auto lock = lockStructureForAlter();\n+    auto lock = lockStructureForAlter(context.getCurrentQueryId());\n     auto new_columns = getColumns();\n     auto new_indices = getIndicesDescription();\n     params.apply(new_columns);\ndiff --git a/dbms/src/Storages/IStorage.h b/dbms/src/Storages/IStorage.h\nindex 7397d285b801..5841126e8448 100644\n--- a/dbms/src/Storages/IStorage.h\n+++ b/dbms/src/Storages/IStorage.h\n@@ -60,19 +60,19 @@ class TableStructureReadLock\n \n     StoragePtr storage;\n     /// Order is important.\n-    RWLockImpl::LockHandler data_lock;\n-    RWLockImpl::LockHandler structure_lock;\n+    RWLockImpl::LockHolder data_lock;\n+    RWLockImpl::LockHolder structure_lock;\n \n public:\n-    TableStructureReadLock(StoragePtr storage_, bool lock_structure, bool lock_data);\n+    TableStructureReadLock(StoragePtr storage_, bool lock_structure, bool lock_data, const String & query_id);\n };\n \n \n using TableStructureReadLockPtr = std::shared_ptr<TableStructureReadLock>;\n using TableStructureReadLocks = std::vector<TableStructureReadLockPtr>;\n \n-using TableStructureWriteLock = RWLockImpl::LockHandler;\n-using TableDataWriteLock = RWLockImpl::LockHandler;\n+using TableStructureWriteLock = RWLockImpl::LockHolder;\n+using TableDataWriteLock = RWLockImpl::LockHolder;\n using TableFullWriteLock = std::pair<TableDataWriteLock, TableStructureWriteLock>;\n \n \n@@ -118,9 +118,9 @@ class IStorage : public std::enable_shared_from_this<IStorage>, private boost::n\n       * WARNING: You need to call methods from ITableDeclaration under such a lock. Without it, they are not thread safe.\n       * WARNING: To avoid deadlocks, this method must not be called under lock of Context.\n       */\n-    TableStructureReadLockPtr lockStructure(bool will_modify_data)\n+    TableStructureReadLockPtr lockStructure(bool will_modify_data, const String & query_id)\n     {\n-        TableStructureReadLockPtr res = std::make_shared<TableStructureReadLock>(shared_from_this(), true, will_modify_data);\n+        TableStructureReadLockPtr res = std::make_shared<TableStructureReadLock>(shared_from_this(), true, will_modify_data, query_id);\n         if (is_dropped)\n             throw Exception(\"Table is dropped\", ErrorCodes::TABLE_IS_DROPPED);\n         return res;\n@@ -128,11 +128,11 @@ class IStorage : public std::enable_shared_from_this<IStorage>, private boost::n\n \n     /** Does not allow reading the table structure. It is taken for ALTER, RENAME and DROP, TRUNCATE.\n       */\n-    TableFullWriteLock lockForAlter()\n+    TableFullWriteLock lockForAlter(const String & query_id)\n     {\n         /// The calculation order is important.\n-        auto res_data_lock = lockDataForAlter();\n-        auto res_structure_lock = lockStructureForAlter();\n+        auto res_data_lock = lockDataForAlter(query_id);\n+        auto res_structure_lock = lockStructureForAlter(query_id);\n \n         return {std::move(res_data_lock), std::move(res_structure_lock)};\n     }\n@@ -141,17 +141,17 @@ class IStorage : public std::enable_shared_from_this<IStorage>, private boost::n\n       * It is taken during write temporary data in ALTER MODIFY.\n       * Under this lock, you can take lockStructureForAlter() to change the structure of the table.\n       */\n-    TableDataWriteLock lockDataForAlter()\n+    TableDataWriteLock lockDataForAlter(const String & query_id)\n     {\n-        auto res = data_lock->getLock(RWLockImpl::Write);\n+        auto res = data_lock->getLock(RWLockImpl::Write, query_id);\n         if (is_dropped)\n             throw Exception(\"Table is dropped\", ErrorCodes::TABLE_IS_DROPPED);\n         return res;\n     }\n \n-    TableStructureWriteLock lockStructureForAlter()\n+    TableStructureWriteLock lockStructureForAlter(const String & query_id)\n     {\n-        auto res = structure_lock->getLock(RWLockImpl::Write);\n+        auto res = structure_lock->getLock(RWLockImpl::Write, query_id);\n         if (is_dropped)\n             throw Exception(\"Table is dropped\", ErrorCodes::TABLE_IS_DROPPED);\n         return res;\n@@ -199,7 +199,7 @@ class IStorage : public std::enable_shared_from_this<IStorage>, private boost::n\n       */\n     virtual BlockOutputStreamPtr write(\n         const ASTPtr & /*query*/,\n-        const Settings & /*settings*/)\n+        const Context & /*context*/)\n     {\n         throw Exception(\"Method write is not supported by storage \" + getName(), ErrorCodes::NOT_IMPLEMENTED);\n     }\n@@ -293,7 +293,7 @@ class IStorage : public std::enable_shared_from_this<IStorage>, private boost::n\n     virtual bool supportsIndexForIn() const { return false; }\n \n     /// Provides a hint that the storage engine may evaluate the IN-condition by using an index.\n-    virtual bool mayBenefitFromIndexForIn(const ASTPtr & /* left_in_operand */) const { return false; }\n+    virtual bool mayBenefitFromIndexForIn(const ASTPtr & /* left_in_operand */, const Context & /* query_context */) const { return false; }\n \n     /// Checks validity of the data\n     virtual bool checkData() const { throw Exception(\"Check query is not supported for \" + getName() + \" storage\", ErrorCodes::NOT_IMPLEMENTED); }\ndiff --git a/dbms/src/Storages/MergeTree/DataPartsExchange.cpp b/dbms/src/Storages/MergeTree/DataPartsExchange.cpp\nindex a1ffd45c6295..9a8346d36a71 100644\n--- a/dbms/src/Storages/MergeTree/DataPartsExchange.cpp\n+++ b/dbms/src/Storages/MergeTree/DataPartsExchange.cpp\n@@ -79,7 +79,7 @@ void Service::processQuery(const Poco::Net::HTMLForm & params, ReadBuffer & /*bo\n \n     try\n     {\n-        auto storage_lock = owned_storage->lockStructure(false);\n+        auto storage_lock = owned_storage->lockStructure(false, RWLockImpl::NO_QUERY);\n \n         MergeTreeData::DataPartPtr part = findPart(part_name);\n \ndiff --git a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAlterThread.cpp b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAlterThread.cpp\nindex d6295fb130a3..03b397e03905 100644\n--- a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAlterThread.cpp\n+++ b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeAlterThread.cpp\n@@ -108,7 +108,7 @@ void ReplicatedMergeTreeAlterThread::run()\n \n             LOG_INFO(log, \"Version of metadata nodes in ZooKeeper changed. Waiting for structure write lock.\");\n \n-            auto table_lock = storage.lockStructureForAlter();\n+            auto table_lock = storage.lockStructureForAlter(RWLockImpl::NO_QUERY);\n \n             if (columns_in_zk == storage.getColumns() && metadata_diff.empty())\n             {\n@@ -134,7 +134,7 @@ void ReplicatedMergeTreeAlterThread::run()\n         /// Update parts.\n         if (changed_columns_version || force_recheck_parts)\n         {\n-            auto table_lock = storage.lockStructure(false);\n+            auto table_lock = storage.lockStructure(false, RWLockImpl::NO_QUERY);\n \n             if (changed_columns_version)\n                 LOG_INFO(log, \"ALTER-ing parts\");\ndiff --git a/dbms/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp b/dbms/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp\nindex d32882f033e9..f0dad30025c7 100644\n--- a/dbms/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp\n+++ b/dbms/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp\n@@ -202,7 +202,7 @@ void ReplicatedMergeTreePartCheckThread::checkPart(const String & part_name)\n     else if (part->name == part_name)\n     {\n         auto zookeeper = storage.getZooKeeper();\n-        auto table_lock = storage.lockStructure(false);\n+        auto table_lock = storage.lockStructure(false, RWLockImpl::NO_QUERY);\n \n         auto local_part_header = ReplicatedMergeTreePartHeader::fromColumnsAndChecksums(\n             part->columns, part->checksums);\ndiff --git a/dbms/src/Storages/MergeTree/StorageFromMergeTreeDataPart.h b/dbms/src/Storages/MergeTree/StorageFromMergeTreeDataPart.h\nindex 1447ffb40d87..314474b3cae1 100644\n--- a/dbms/src/Storages/MergeTree/StorageFromMergeTreeDataPart.h\n+++ b/dbms/src/Storages/MergeTree/StorageFromMergeTreeDataPart.h\n@@ -32,7 +32,7 @@ class StorageFromMergeTreeDataPart : public ext::shared_ptr_helper<StorageFromMe\n \n     bool supportsIndexForIn() const override { return true; }\n \n-    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand) const override\n+    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand, const Context & /* query_context */) const override\n     {\n         return part->storage.mayBenefitFromIndexForIn(left_in_operand);\n     }\ndiff --git a/dbms/src/Storages/StorageBuffer.cpp b/dbms/src/Storages/StorageBuffer.cpp\nindex 9706b1d55628..b3cb485a6b4d 100644\n--- a/dbms/src/Storages/StorageBuffer.cpp\n+++ b/dbms/src/Storages/StorageBuffer.cpp\n@@ -150,7 +150,7 @@ BlockInputStreams StorageBuffer::read(\n         if (destination.get() == this)\n             throw Exception(\"Destination table is myself. Read will cause infinite loop.\", ErrorCodes::INFINITE_LOOP);\n \n-        auto destination_lock = destination->lockStructure(false);\n+        auto destination_lock = destination->lockStructure(false, context.getCurrentQueryId());\n \n         const bool dst_has_same_structure = std::all_of(column_names.begin(), column_names.end(), [this, destination](const String& column_name)\n         {\n@@ -392,13 +392,13 @@ class BufferBlockOutputStream : public IBlockOutputStream\n };\n \n \n-BlockOutputStreamPtr StorageBuffer::write(const ASTPtr & /*query*/, const Settings & /*settings*/)\n+BlockOutputStreamPtr StorageBuffer::write(const ASTPtr & /*query*/, const Context & /*context*/)\n {\n     return std::make_shared<BufferBlockOutputStream>(*this);\n }\n \n \n-bool StorageBuffer::mayBenefitFromIndexForIn(const ASTPtr & left_in_operand) const\n+bool StorageBuffer::mayBenefitFromIndexForIn(const ASTPtr & left_in_operand, const Context & query_context) const\n {\n     if (no_destination)\n         return false;\n@@ -408,7 +408,7 @@ bool StorageBuffer::mayBenefitFromIndexForIn(const ASTPtr & left_in_operand) con\n     if (destination.get() == this)\n         throw Exception(\"Destination table is myself. Read will cause infinite loop.\", ErrorCodes::INFINITE_LOOP);\n \n-    return destination->mayBenefitFromIndexForIn(left_in_operand);\n+    return destination->mayBenefitFromIndexForIn(left_in_operand, query_context);\n }\n \n \n@@ -679,7 +679,7 @@ void StorageBuffer::flushThread()\n \n void StorageBuffer::alter(const AlterCommands & params, const String & database_name, const String & table_name, const Context & context)\n {\n-    auto lock = lockStructureForAlter();\n+    auto lock = lockStructureForAlter(context.getCurrentQueryId());\n \n     /// So that no blocks of the old structure remain.\n     optimize({} /*query*/, {} /*partition_id*/, false /*final*/, false /*deduplicate*/, context);\ndiff --git a/dbms/src/Storages/StorageBuffer.h b/dbms/src/Storages/StorageBuffer.h\nindex 85ea3f086b59..854d4efd05db 100644\n--- a/dbms/src/Storages/StorageBuffer.h\n+++ b/dbms/src/Storages/StorageBuffer.h\n@@ -64,7 +64,7 @@ friend class BufferBlockOutputStream;\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     void startup() override;\n     /// Flush all buffers into the subordinate table and stop background thread.\n@@ -78,7 +78,7 @@ friend class BufferBlockOutputStream;\n     bool supportsFinal() const override { return true; }\n     bool supportsIndexForIn() const override { return true; }\n \n-    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand) const override;\n+    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand, const Context & query_context) const override;\n \n     /// The structure of the subordinate table is not checked and does not change.\n     void alter(const AlterCommands & params, const String & database_name, const String & table_name, const Context & context) override;\ndiff --git a/dbms/src/Storages/StorageDistributed.cpp b/dbms/src/Storages/StorageDistributed.cpp\nindex 8ea077b671fa..644576272d02 100644\n--- a/dbms/src/Storages/StorageDistributed.cpp\n+++ b/dbms/src/Storages/StorageDistributed.cpp\n@@ -307,9 +307,10 @@ BlockInputStreams StorageDistributed::read(\n }\n \n \n-BlockOutputStreamPtr StorageDistributed::write(const ASTPtr &, const Settings & settings)\n+BlockOutputStreamPtr StorageDistributed::write(const ASTPtr &, const Context & context)\n {\n     auto cluster = getCluster();\n+    const auto & settings = context.getSettingsRef();\n \n     /// Ban an attempt to make async insert into the table belonging to DatabaseMemory\n     if (path.empty() && !owned_cluster && !settings.insert_distributed_sync.value)\n@@ -337,7 +338,7 @@ BlockOutputStreamPtr StorageDistributed::write(const ASTPtr &, const Settings &\n \n void StorageDistributed::alter(const AlterCommands & params, const String & database_name, const String & current_table_name, const Context & context)\n {\n-    auto lock = lockStructureForAlter();\n+    auto lock = lockStructureForAlter(context.getCurrentQueryId());\n \n     auto new_columns = getColumns();\n     auto new_indices = getIndicesDescription();\ndiff --git a/dbms/src/Storages/StorageDistributed.h b/dbms/src/Storages/StorageDistributed.h\nindex caa52209804f..eecab76ea8ec 100644\n--- a/dbms/src/Storages/StorageDistributed.h\n+++ b/dbms/src/Storages/StorageDistributed.h\n@@ -71,7 +71,7 @@ class StorageDistributed : public ext::shared_ptr_helper<StorageDistributed>, pu\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     void drop() override {}\n \ndiff --git a/dbms/src/Storages/StorageFile.cpp b/dbms/src/Storages/StorageFile.cpp\nindex 9facf743c1c0..0c221cf33931 100644\n--- a/dbms/src/Storages/StorageFile.cpp\n+++ b/dbms/src/Storages/StorageFile.cpp\n@@ -252,7 +252,7 @@ class StorageFileBlockOutputStream : public IBlockOutputStream\n \n BlockOutputStreamPtr StorageFile::write(\n     const ASTPtr & /*query*/,\n-    const Settings & /*settings*/)\n+    const Context & /*context*/)\n {\n     return std::make_shared<StorageFileBlockOutputStream>(*this);\n }\ndiff --git a/dbms/src/Storages/StorageFile.h b/dbms/src/Storages/StorageFile.h\nindex 6716dc306a47..eb74ad615a7d 100644\n--- a/dbms/src/Storages/StorageFile.h\n+++ b/dbms/src/Storages/StorageFile.h\n@@ -41,7 +41,7 @@ class StorageFile : public ext::shared_ptr_helper<StorageFile>, public IStorage\n \n     BlockOutputStreamPtr write(\n         const ASTPtr & query,\n-        const Settings & settings) override;\n+        const Context & context) override;\n \n     void drop() override;\n \ndiff --git a/dbms/src/Storages/StorageHDFS.cpp b/dbms/src/Storages/StorageHDFS.cpp\nindex 84ef0a33a27d..4f6cf35c09e6 100644\n--- a/dbms/src/Storages/StorageHDFS.cpp\n+++ b/dbms/src/Storages/StorageHDFS.cpp\n@@ -146,7 +146,7 @@ BlockInputStreams StorageHDFS::read(\n \n void StorageHDFS::rename(const String & /*new_path_to_db*/, const String & /*new_database_name*/, const String & /*new_table_name*/) {}\n \n-BlockOutputStreamPtr StorageHDFS::write(const ASTPtr & /*query*/, const Settings & /*settings*/)\n+BlockOutputStreamPtr StorageHDFS::write(const ASTPtr & /*query*/, const Context & /*context*/)\n {\n     return std::make_shared<HDFSBlockOutputStream>(uri, format_name, getSampleBlock(), context);\n }\ndiff --git a/dbms/src/Storages/StorageHDFS.h b/dbms/src/Storages/StorageHDFS.h\nindex 6d5141eddbce..73342cf36717 100644\n--- a/dbms/src/Storages/StorageHDFS.h\n+++ b/dbms/src/Storages/StorageHDFS.h\n@@ -33,7 +33,7 @@ class StorageHDFS : public ext::shared_ptr_helper<StorageHDFS>, public IStorage\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     void rename(const String & new_path_to_db, const String & new_database_name, const String & new_table_name) override;\n \ndiff --git a/dbms/src/Storages/StorageLog.cpp b/dbms/src/Storages/StorageLog.cpp\nindex 76329da78276..968358990284 100644\n--- a/dbms/src/Storages/StorageLog.cpp\n+++ b/dbms/src/Storages/StorageLog.cpp\n@@ -619,7 +619,7 @@ BlockInputStreams StorageLog::read(\n }\n \n BlockOutputStreamPtr StorageLog::write(\n-    const ASTPtr & /*query*/, const Settings & /*settings*/)\n+    const ASTPtr & /*query*/, const Context & /*context*/)\n {\n     loadMarks();\n     return std::make_shared<LogBlockOutputStream>(*this);\ndiff --git a/dbms/src/Storages/StorageLog.h b/dbms/src/Storages/StorageLog.h\nindex 73a4d387dc55..cf0d07a3bfe7 100644\n--- a/dbms/src/Storages/StorageLog.h\n+++ b/dbms/src/Storages/StorageLog.h\n@@ -34,7 +34,7 @@ friend class LogBlockOutputStream;\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     void rename(const String & new_path_to_db, const String & new_database_name, const String & new_table_name) override;\n \ndiff --git a/dbms/src/Storages/StorageMaterializedView.cpp b/dbms/src/Storages/StorageMaterializedView.cpp\nindex ae33cac84272..93663badf56a 100644\n--- a/dbms/src/Storages/StorageMaterializedView.cpp\n+++ b/dbms/src/Storages/StorageMaterializedView.cpp\n@@ -190,18 +190,18 @@ BlockInputStreams StorageMaterializedView::read(\n     const unsigned num_streams)\n {\n     auto storage = getTargetTable();\n-    auto lock = storage->lockStructure(false);\n+    auto lock = storage->lockStructure(false, context.getCurrentQueryId());\n     auto streams = storage->read(column_names, query_info, context, processed_stage, max_block_size, num_streams);\n     for (auto & stream : streams)\n         stream->addTableLock(lock);\n     return streams;\n }\n \n-BlockOutputStreamPtr StorageMaterializedView::write(const ASTPtr & query, const Settings & settings)\n+BlockOutputStreamPtr StorageMaterializedView::write(const ASTPtr & query, const Context & context)\n {\n     auto storage = getTargetTable();\n-    auto lock = storage->lockStructure(true);\n-    auto stream = storage->write(query, settings);\n+    auto lock = storage->lockStructure(true, context.getCurrentQueryId());\n+    auto stream = storage->write(query, context);\n     stream->addTableLock(lock);\n     return stream;\n }\ndiff --git a/dbms/src/Storages/StorageMaterializedView.h b/dbms/src/Storages/StorageMaterializedView.h\nindex d308bd3550a4..8c2657b484bb 100644\n--- a/dbms/src/Storages/StorageMaterializedView.h\n+++ b/dbms/src/Storages/StorageMaterializedView.h\n@@ -26,9 +26,12 @@ class StorageMaterializedView : public ext::shared_ptr_helper<StorageMaterialize\n     bool supportsPrewhere() const override { return getTargetTable()->supportsPrewhere(); }\n     bool supportsFinal() const override { return getTargetTable()->supportsFinal(); }\n     bool supportsIndexForIn() const override { return getTargetTable()->supportsIndexForIn(); }\n-    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand) const override { return getTargetTable()->mayBenefitFromIndexForIn(left_in_operand); }\n+    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand, const Context & query_context) const override\n+    {\n+        return getTargetTable()->mayBenefitFromIndexForIn(left_in_operand, query_context);\n+    }\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n     void drop() override;\n \n     void truncate(const ASTPtr &, const Context &) override;\ndiff --git a/dbms/src/Storages/StorageMemory.cpp b/dbms/src/Storages/StorageMemory.cpp\nindex 3e2e779244fc..ddcf649a726a 100644\n--- a/dbms/src/Storages/StorageMemory.cpp\n+++ b/dbms/src/Storages/StorageMemory.cpp\n@@ -115,7 +115,7 @@ BlockInputStreams StorageMemory::read(\n \n \n BlockOutputStreamPtr StorageMemory::write(\n-    const ASTPtr & /*query*/, const Settings & /*settings*/)\n+    const ASTPtr & /*query*/, const Context & /*context*/)\n {\n     return std::make_shared<MemoryBlockOutputStream>(*this);\n }\ndiff --git a/dbms/src/Storages/StorageMemory.h b/dbms/src/Storages/StorageMemory.h\nindex 39bcce768947..89947b50b8fc 100644\n--- a/dbms/src/Storages/StorageMemory.h\n+++ b/dbms/src/Storages/StorageMemory.h\n@@ -36,7 +36,7 @@ friend class MemoryBlockOutputStream;\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     void drop() override;\n \ndiff --git a/dbms/src/Storages/StorageMerge.cpp b/dbms/src/Storages/StorageMerge.cpp\nindex b6426d253610..d8e3dfce6493 100644\n--- a/dbms/src/Storages/StorageMerge.cpp\n+++ b/dbms/src/Storages/StorageMerge.cpp\n@@ -122,15 +122,15 @@ bool StorageMerge::isRemote() const\n }\n \n \n-bool StorageMerge::mayBenefitFromIndexForIn(const ASTPtr & left_in_operand) const\n+bool StorageMerge::mayBenefitFromIndexForIn(const ASTPtr & left_in_operand, const Context & query_context) const\n {\n     /// It's beneficial if it is true for at least one table.\n-    StorageListWithLocks selected_tables = getSelectedTables();\n+    StorageListWithLocks selected_tables = getSelectedTables(query_context.getCurrentQueryId());\n \n     size_t i = 0;\n     for (const auto & table : selected_tables)\n     {\n-        if (table.first->mayBenefitFromIndexForIn(left_in_operand))\n+        if (table.first->mayBenefitFromIndexForIn(left_in_operand, query_context))\n             return true;\n \n         ++i;\n@@ -206,7 +206,8 @@ BlockInputStreams StorageMerge::read(\n     /** First we make list of selected tables to find out its size.\n       * This is necessary to correctly pass the recommended number of threads to each table.\n       */\n-    StorageListWithLocks selected_tables = getSelectedTables(query_info.query, has_table_virtual_column, true);\n+    StorageListWithLocks selected_tables = getSelectedTables(\n+        query_info.query, has_table_virtual_column, true, context.getCurrentQueryId());\n \n     if (selected_tables.empty())\n         return createSourceStreams(\n@@ -332,7 +333,7 @@ BlockInputStreams StorageMerge::createSourceStreams(const SelectQueryInfo & quer\n     return source_streams;\n }\n \n-StorageMerge::StorageListWithLocks StorageMerge::getSelectedTables() const\n+StorageMerge::StorageListWithLocks StorageMerge::getSelectedTables(const String & query_id) const\n {\n     StorageListWithLocks selected_tables;\n     auto database = global_context.getDatabase(source_database);\n@@ -344,7 +345,7 @@ StorageMerge::StorageListWithLocks StorageMerge::getSelectedTables() const\n         {\n             auto & table = iterator->table();\n             if (table.get() != this)\n-                selected_tables.emplace_back(table, table->lockStructure(false));\n+                selected_tables.emplace_back(table, table->lockStructure(false, query_id));\n         }\n \n         iterator->next();\n@@ -354,7 +355,7 @@ StorageMerge::StorageListWithLocks StorageMerge::getSelectedTables() const\n }\n \n \n-StorageMerge::StorageListWithLocks StorageMerge::getSelectedTables(const ASTPtr & query, bool has_virtual_column, bool get_lock) const\n+StorageMerge::StorageListWithLocks StorageMerge::getSelectedTables(const ASTPtr & query, bool has_virtual_column, bool get_lock, const String & query_id) const\n {\n     StorageListWithLocks selected_tables;\n     DatabasePtr database = global_context.getDatabase(source_database);\n@@ -374,7 +375,7 @@ StorageMerge::StorageListWithLocks StorageMerge::getSelectedTables(const ASTPtr\n             if (storage.get() != this)\n             {\n                 virtual_column->insert(storage->getTableName());\n-                selected_tables.emplace_back(storage, get_lock ? storage->lockStructure(false) : TableStructureReadLockPtr{});\n+                selected_tables.emplace_back(storage, get_lock ? storage->lockStructure(false, query_id) : TableStructureReadLockPtr{});\n             }\n         }\n \n@@ -396,7 +397,7 @@ StorageMerge::StorageListWithLocks StorageMerge::getSelectedTables(const ASTPtr\n \n void StorageMerge::alter(const AlterCommands & params, const String & database_name, const String & table_name, const Context & context)\n {\n-    auto lock = lockStructureForAlter();\n+    auto lock = lockStructureForAlter(context.getCurrentQueryId());\n \n     auto new_columns = getColumns();\n     auto new_indices = getIndicesDescription();\ndiff --git a/dbms/src/Storages/StorageMerge.h b/dbms/src/Storages/StorageMerge.h\nindex 1e91ed98ff39..000d8daed1a4 100644\n--- a/dbms/src/Storages/StorageMerge.h\n+++ b/dbms/src/Storages/StorageMerge.h\n@@ -46,7 +46,7 @@ class StorageMerge : public ext::shared_ptr_helper<StorageMerge>, public IStorag\n     /// the structure of sub-tables is not checked\n     void alter(const AlterCommands & params, const String & database_name, const String & table_name, const Context & context) override;\n \n-    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand) const override;\n+    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand, const Context & query_context) const override;\n \n private:\n     String name;\n@@ -56,9 +56,9 @@ class StorageMerge : public ext::shared_ptr_helper<StorageMerge>, public IStorag\n \n     using StorageListWithLocks = std::list<std::pair<StoragePtr, TableStructureReadLockPtr>>;\n \n-    StorageListWithLocks getSelectedTables() const;\n+    StorageListWithLocks getSelectedTables(const String & query_id) const;\n \n-    StorageMerge::StorageListWithLocks getSelectedTables(const ASTPtr & query, bool has_virtual_column, bool get_lock) const;\n+    StorageMerge::StorageListWithLocks getSelectedTables(const ASTPtr & query, bool has_virtual_column, bool get_lock, const String & query_id) const;\n \n     template <typename F>\n     StoragePtr getFirstTable(F && predicate) const;\ndiff --git a/dbms/src/Storages/StorageMergeTree.cpp b/dbms/src/Storages/StorageMergeTree.cpp\nindex 81d5186603a6..ba3fe04dd898 100644\n--- a/dbms/src/Storages/StorageMergeTree.cpp\n+++ b/dbms/src/Storages/StorageMergeTree.cpp\n@@ -126,7 +126,7 @@ BlockInputStreams StorageMergeTree::read(\n     return reader.read(column_names, query_info, context, max_block_size, num_streams);\n }\n \n-BlockOutputStreamPtr StorageMergeTree::write(const ASTPtr & /*query*/, const Settings & /*settings*/)\n+BlockOutputStreamPtr StorageMergeTree::write(const ASTPtr & /*query*/, const Context & /*context*/)\n {\n     return std::make_shared<MergeTreeBlockOutputStream>(*this);\n }\n@@ -199,7 +199,7 @@ void StorageMergeTree::alter(\n {\n     if (!params.is_mutable())\n     {\n-        auto table_soft_lock = lockStructureForAlter();\n+        auto table_soft_lock = lockStructureForAlter(context.getCurrentQueryId());\n         auto new_columns = getColumns();\n         auto new_indices = getIndicesDescription();\n         params.apply(new_columns);\n@@ -211,7 +211,7 @@ void StorageMergeTree::alter(\n     /// NOTE: Here, as in ReplicatedMergeTree, you can do ALTER which does not block the writing of data for a long time.\n     auto merge_blocker = merger_mutator.actions_blocker.cancel();\n \n-    auto table_soft_lock = lockDataForAlter();\n+    auto table_soft_lock = lockDataForAlter(context.getCurrentQueryId());\n \n     data.checkAlter(params, context);\n \n@@ -230,7 +230,7 @@ void StorageMergeTree::alter(\n             transactions.push_back(std::move(transaction));\n     }\n \n-    auto table_hard_lock = lockStructureForAlter();\n+    auto table_hard_lock = lockStructureForAlter(context.getCurrentQueryId());\n \n     IDatabase::ASTModifier storage_modifier = [&] (IAST & ast)\n     {\n@@ -452,7 +452,7 @@ bool StorageMergeTree::merge(\n     bool deduplicate,\n     String * out_disable_reason)\n {\n-    auto structure_lock = lockStructure(true);\n+    auto structure_lock = lockStructure(true, RWLockImpl::NO_QUERY);\n \n     FutureMergedMutatedPart future_part;\n \n@@ -562,7 +562,7 @@ bool StorageMergeTree::merge(\n \n bool StorageMergeTree::tryMutatePart()\n {\n-    auto structure_lock = lockStructure(true);\n+    auto structure_lock = lockStructure(true, RWLockImpl::NO_QUERY);\n \n     FutureMergedMutatedPart future_part;\n     MutationCommands commands;\n@@ -774,7 +774,7 @@ void StorageMergeTree::clearColumnInPartition(const ASTPtr & partition, const Fi\n     auto merge_blocker = merger_mutator.actions_blocker.cancel();\n \n     /// We don't change table structure, only data in some parts, parts are locked inside alterDataPart() function\n-    auto lock_read_structure = lockStructure(false);\n+    auto lock_read_structure = lockStructure(false, context.getCurrentQueryId());\n \n     String partition_id = data.getPartitionIDFromQuery(partition, context);\n     auto parts = data.getDataPartsVectorInPartition(MergeTreeDataPartState::Committed, partition_id);\n@@ -879,7 +879,7 @@ void StorageMergeTree::alterPartition(const ASTPtr & query, const PartitionComma\n \n             case PartitionCommand::FREEZE_PARTITION:\n             {\n-                auto lock = lockStructure(false);\n+                auto lock = lockStructure(false, context.getCurrentQueryId());\n                 data.freezePartition(command.partition, command.with_name, context);\n             }\n             break;\n@@ -890,7 +890,7 @@ void StorageMergeTree::alterPartition(const ASTPtr & query, const PartitionComma\n \n             case PartitionCommand::FREEZE_ALL_PARTITIONS:\n             {\n-                auto lock = lockStructure(false);\n+                auto lock = lockStructure(false, context.getCurrentQueryId());\n                 data.freezeAll(command.with_name, context);\n             }\n             break;\n@@ -908,7 +908,7 @@ void StorageMergeTree::dropPartition(const ASTPtr & partition, bool detach, cons\n         /// This protects against \"revival\" of data for a removed partition after completion of merge.\n         auto merge_blocker = merger_mutator.actions_blocker.cancel();\n         /// Waits for completion of merge and does not start new ones.\n-        auto lock = lockForAlter();\n+        auto lock = lockForAlter(context.getCurrentQueryId());\n \n         String partition_id = data.getPartitionIDFromQuery(partition, context);\n \n@@ -991,8 +991,8 @@ void StorageMergeTree::attachPartition(const ASTPtr & partition, bool attach_par\n \n void StorageMergeTree::replacePartitionFrom(const StoragePtr & source_table, const ASTPtr & partition, bool replace, const Context & context)\n {\n-    auto lock1 = lockStructure(false);\n-    auto lock2 = source_table->lockStructure(false);\n+    auto lock1 = lockStructure(false, context.getCurrentQueryId());\n+    auto lock2 = source_table->lockStructure(false, context.getCurrentQueryId());\n \n     Stopwatch watch;\n     MergeTreeData * src_data = data.checkStructureAndGetMergeTreeData(source_table);\ndiff --git a/dbms/src/Storages/StorageMergeTree.h b/dbms/src/Storages/StorageMergeTree.h\nindex 70968e0dcb43..d17b496bd978 100644\n--- a/dbms/src/Storages/StorageMergeTree.h\n+++ b/dbms/src/Storages/StorageMergeTree.h\n@@ -38,7 +38,10 @@ class StorageMergeTree : public ext::shared_ptr_helper<StorageMergeTree>, public\n     bool supportsPrewhere() const override { return data.supportsPrewhere(); }\n     bool supportsFinal() const override { return data.supportsFinal(); }\n     bool supportsIndexForIn() const override { return true; }\n-    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand) const override { return data.mayBenefitFromIndexForIn(left_in_operand); }\n+    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand, const Context & /* query_context */) const override\n+    {\n+        return data.mayBenefitFromIndexForIn(left_in_operand);\n+    }\n \n     const ColumnsDescription & getColumns() const override { return data.getColumns(); }\n     void setColumns(ColumnsDescription columns_) override { return data.setColumns(std::move(columns_)); }\n@@ -57,7 +60,7 @@ class StorageMergeTree : public ext::shared_ptr_helper<StorageMergeTree>, public\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     /** Perform the next step in combining the parts.\n       */\ndiff --git a/dbms/src/Storages/StorageMySQL.cpp b/dbms/src/Storages/StorageMySQL.cpp\nindex 76db23065fb6..127caefcd3bc 100644\n--- a/dbms/src/Storages/StorageMySQL.cpp\n+++ b/dbms/src/Storages/StorageMySQL.cpp\n@@ -179,9 +179,9 @@ class StorageMySQLBlockOutputStream : public IBlockOutputStream\n \n \n BlockOutputStreamPtr StorageMySQL::write(\n-    const ASTPtr & /*query*/, const Settings & settings)\n+    const ASTPtr & /*query*/, const Context & context)\n {\n-    return std::make_shared<StorageMySQLBlockOutputStream>(*this, remote_database_name, remote_table_name, pool.Get(), settings.mysql_max_rows_to_insert);\n+    return std::make_shared<StorageMySQLBlockOutputStream>(*this, remote_database_name, remote_table_name, pool.Get(), context.getSettingsRef().mysql_max_rows_to_insert);\n }\n \n void registerStorageMySQL(StorageFactory & factory)\ndiff --git a/dbms/src/Storages/StorageMySQL.h b/dbms/src/Storages/StorageMySQL.h\nindex ee6f0ed3fe85..0db81f4a3463 100644\n--- a/dbms/src/Storages/StorageMySQL.h\n+++ b/dbms/src/Storages/StorageMySQL.h\n@@ -40,7 +40,7 @@ class StorageMySQL : public ext::shared_ptr_helper<StorageMySQL>, public IStorag\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n private:\n     friend class StorageMySQLBlockOutputStream;\ndiff --git a/dbms/src/Storages/StorageNull.cpp b/dbms/src/Storages/StorageNull.cpp\nindex 59c46fcafd21..a920fe3c3955 100644\n--- a/dbms/src/Storages/StorageNull.cpp\n+++ b/dbms/src/Storages/StorageNull.cpp\n@@ -32,7 +32,7 @@ void registerStorageNull(StorageFactory & factory)\n \n void StorageNull::alter(const AlterCommands & params, const String & current_database_name, const String & current_table_name, const Context & context)\n {\n-    auto lock = lockStructureForAlter();\n+    auto lock = lockStructureForAlter(context.getCurrentQueryId());\n \n     ColumnsDescription new_columns = getColumns();\n     IndicesDescription new_indices = getIndicesDescription();\ndiff --git a/dbms/src/Storages/StorageNull.h b/dbms/src/Storages/StorageNull.h\nindex 19d93d7080f1..bf0704803160 100644\n--- a/dbms/src/Storages/StorageNull.h\n+++ b/dbms/src/Storages/StorageNull.h\n@@ -31,7 +31,7 @@ class StorageNull : public ext::shared_ptr_helper<StorageNull>, public IStorage\n         return { std::make_shared<NullBlockInputStream>(getSampleBlockForColumns(column_names)) };\n     }\n \n-    BlockOutputStreamPtr write(const ASTPtr &, const Settings &) override\n+    BlockOutputStreamPtr write(const ASTPtr &, const Context &) override\n     {\n         return std::make_shared<NullBlockOutputStream>(getSampleBlock());\n     }\ndiff --git a/dbms/src/Storages/StorageReplicatedMergeTree.cpp b/dbms/src/Storages/StorageReplicatedMergeTree.cpp\nindex 90b9140f12bb..b9bbf762c668 100644\n--- a/dbms/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/dbms/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -1089,7 +1089,7 @@ bool StorageReplicatedMergeTree::tryExecuteMerge(const LogEntry & entry)\n     /// Can throw an exception.\n     DiskSpaceMonitor::ReservationPtr reserved_space = DiskSpaceMonitor::reserve(full_path, estimated_space_for_merge);\n \n-    auto table_lock = lockStructure(false);\n+    auto table_lock = lockStructure(false, RWLockImpl::NO_QUERY);\n \n     FutureMergedMutatedPart future_merged_part(parts);\n     if (future_merged_part.name != entry.new_part_name)\n@@ -1219,7 +1219,7 @@ bool StorageReplicatedMergeTree::tryExecutePartMutation(const StorageReplicatedM\n     /// Can throw an exception.\n     DiskSpaceMonitor::ReservationPtr reserved_space = DiskSpaceMonitor::reserve(full_path, estimated_space_for_result);\n \n-    auto table_lock = lockStructure(false);\n+    auto table_lock = lockStructure(false, RWLockImpl::NO_QUERY);\n \n     MergeTreeData::MutableDataPartPtr new_part;\n     MergeTreeData::Transaction transaction(data);\n@@ -1528,7 +1528,7 @@ void StorageReplicatedMergeTree::executeClearColumnInPartition(const LogEntry &\n     /// We don't change table structure, only data in some parts\n     /// To disable reading from these parts, we will sequentially acquire write lock for each part inside alterDataPart()\n     /// If we will lock the whole table here, a deadlock can occur. For example, if use use Buffer table (CLICKHOUSE-3238)\n-    auto lock_read_structure = lockStructure(false);\n+    auto lock_read_structure = lockStructure(false, RWLockImpl::NO_QUERY);\n \n     auto zookeeper = getZooKeeper();\n \n@@ -1624,7 +1624,7 @@ bool StorageReplicatedMergeTree::executeReplaceRange(const LogEntry & entry)\n     PartDescriptions parts_to_add;\n     MergeTreeData::DataPartsVector parts_to_remove;\n \n-    auto structure_lock_dst_table = lockStructure(false);\n+    auto structure_lock_dst_table = lockStructure(false, RWLockImpl::NO_QUERY);\n \n     for (size_t i = 0; i < entry_replace.new_part_names.size(); ++i)\n     {\n@@ -1686,7 +1686,7 @@ bool StorageReplicatedMergeTree::executeReplaceRange(const LogEntry & entry)\n             return 0;\n         }\n \n-        structure_lock_src_table = source_table->lockStructure(false);\n+        structure_lock_src_table = source_table->lockStructure(false, RWLockImpl::NO_QUERY);\n \n         MergeTreeData::DataPartStates valid_states{MergeTreeDataPartState::PreCommitted, MergeTreeDataPartState::Committed,\n                                                    MergeTreeDataPartState::Outdated};\n@@ -2721,7 +2721,7 @@ bool StorageReplicatedMergeTree::fetchPart(const String & part_name, const Strin\n \n     TableStructureReadLockPtr table_lock;\n     if (!to_detached)\n-        table_lock = lockStructure(true);\n+        table_lock = lockStructure(true, RWLockImpl::NO_QUERY);\n \n     /// Logging\n     Stopwatch stopwatch;\n@@ -2992,10 +2992,11 @@ void StorageReplicatedMergeTree::assertNotReadonly() const\n }\n \n \n-BlockOutputStreamPtr StorageReplicatedMergeTree::write(const ASTPtr & /*query*/, const Settings & settings)\n+BlockOutputStreamPtr StorageReplicatedMergeTree::write(const ASTPtr & /*query*/, const Context & context)\n {\n     assertNotReadonly();\n \n+    const Settings & settings = context.getSettingsRef();\n     bool deduplicate = data.settings.replicated_deduplication_window != 0 && settings.insert_deduplicate;\n \n     return std::make_shared<ReplicatedMergeTreeBlockOutputStream>(*this,\n@@ -3123,7 +3124,7 @@ void StorageReplicatedMergeTree::alter(const AlterCommands & params,\n \n     {\n         /// Just to read current structure. Alter will be done in separate thread.\n-        auto table_lock = lockStructure(false);\n+        auto table_lock = lockStructure(false, query_context.getCurrentQueryId());\n \n         if (is_readonly)\n             throw Exception(\"Can't ALTER readonly table\", ErrorCodes::TABLE_IS_READ_ONLY);\n@@ -3381,7 +3382,7 @@ void StorageReplicatedMergeTree::alterPartition(const ASTPtr & query, const Part\n \n             case PartitionCommand::FREEZE_PARTITION:\n             {\n-                auto lock = lockStructure(false);\n+                auto lock = lockStructure(false, query_context.getCurrentQueryId());\n                 data.freezePartition(command.partition, command.with_name, query_context);\n             }\n             break;\n@@ -3392,7 +3393,7 @@ void StorageReplicatedMergeTree::alterPartition(const ASTPtr & query, const Part\n \n             case PartitionCommand::FREEZE_ALL_PARTITIONS:\n             {\n-                auto lock = lockStructure(false);\n+                auto lock = lockStructure(false, query_context.getCurrentQueryId());\n                 data.freezeAll(command.with_name, query_context);\n             }\n             break;\n@@ -4447,7 +4448,7 @@ void StorageReplicatedMergeTree::clearOldPartsAndRemoveFromZK()\n {\n     /// Critical section is not required (since grabOldParts() returns unique part set on each call)\n \n-    auto table_lock = lockStructure(false);\n+    auto table_lock = lockStructure(false, RWLockImpl::NO_QUERY);\n     auto zookeeper = getZooKeeper();\n \n     MergeTreeData::DataPartsVector parts = data.grabOldParts();\n@@ -4739,8 +4740,8 @@ void StorageReplicatedMergeTree::clearBlocksInPartition(\n void StorageReplicatedMergeTree::replacePartitionFrom(const StoragePtr & source_table, const ASTPtr & partition, bool replace,\n                                                       const Context & context)\n {\n-    auto lock1 = lockStructure(false);\n-    auto lock2 = source_table->lockStructure(false);\n+    auto lock1 = lockStructure(false, context.getCurrentQueryId());\n+    auto lock2 = source_table->lockStructure(false, context.getCurrentQueryId());\n \n     Stopwatch watch;\n     MergeTreeData * src_data = data.checkStructureAndGetMergeTreeData(source_table);\ndiff --git a/dbms/src/Storages/StorageReplicatedMergeTree.h b/dbms/src/Storages/StorageReplicatedMergeTree.h\nindex 884cc3440e11..e3a7d0230660 100644\n--- a/dbms/src/Storages/StorageReplicatedMergeTree.h\n+++ b/dbms/src/Storages/StorageReplicatedMergeTree.h\n@@ -112,7 +112,7 @@ class StorageReplicatedMergeTree : public ext::shared_ptr_helper<StorageReplicat\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     bool optimize(const ASTPtr & query, const ASTPtr & partition, bool final, bool deduplicate, const Context & query_context) override;\n \n@@ -133,7 +133,10 @@ class StorageReplicatedMergeTree : public ext::shared_ptr_helper<StorageReplicat\n     void rename(const String & new_path_to_db, const String & new_database_name, const String & new_table_name) override;\n \n     bool supportsIndexForIn() const override { return true; }\n-    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand) const override { return data.mayBenefitFromIndexForIn(left_in_operand); }\n+    bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand, const Context & /* query_context */) const override\n+    {\n+        return data.mayBenefitFromIndexForIn(left_in_operand);\n+    }\n \n     void checkTableCanBeDropped() const override;\n \ndiff --git a/dbms/src/Storages/StorageSet.cpp b/dbms/src/Storages/StorageSet.cpp\nindex 3a33270b1cd3..f1f4f039c8c8 100644\n--- a/dbms/src/Storages/StorageSet.cpp\n+++ b/dbms/src/Storages/StorageSet.cpp\n@@ -79,7 +79,7 @@ void SetOrJoinBlockOutputStream::writeSuffix()\n \n \n \n-BlockOutputStreamPtr StorageSetOrJoinBase::write(const ASTPtr & /*query*/, const Settings & /*settings*/)\n+BlockOutputStreamPtr StorageSetOrJoinBase::write(const ASTPtr & /*query*/, const Context & /*context*/)\n {\n     UInt64 id = ++increment;\n     return std::make_shared<SetOrJoinBlockOutputStream>(*this, path, path + \"tmp/\", toString(id) + \".bin\");\ndiff --git a/dbms/src/Storages/StorageSet.h b/dbms/src/Storages/StorageSet.h\nindex c5c7560e0f24..0585dc271c67 100644\n--- a/dbms/src/Storages/StorageSet.h\n+++ b/dbms/src/Storages/StorageSet.h\n@@ -23,7 +23,7 @@ class StorageSetOrJoinBase : public IStorage\n \n     void rename(const String & new_path_to_db, const String & new_database_name, const String & new_table_name) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     String getDataPath() const override { return path; }\n \ndiff --git a/dbms/src/Storages/StorageStripeLog.cpp b/dbms/src/Storages/StorageStripeLog.cpp\nindex 3519dfbc37c0..dba2e64a88f5 100644\n--- a/dbms/src/Storages/StorageStripeLog.cpp\n+++ b/dbms/src/Storages/StorageStripeLog.cpp\n@@ -276,7 +276,7 @@ BlockInputStreams StorageStripeLog::read(\n \n \n BlockOutputStreamPtr StorageStripeLog::write(\n-    const ASTPtr & /*query*/, const Settings & /*settings*/)\n+    const ASTPtr & /*query*/, const Context & /*context*/)\n {\n     return std::make_shared<StripeLogBlockOutputStream>(*this);\n }\ndiff --git a/dbms/src/Storages/StorageStripeLog.h b/dbms/src/Storages/StorageStripeLog.h\nindex 0282235de515..6489c82873e7 100644\n--- a/dbms/src/Storages/StorageStripeLog.h\n+++ b/dbms/src/Storages/StorageStripeLog.h\n@@ -36,7 +36,7 @@ friend class StripeLogBlockOutputStream;\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     void rename(const String & new_path_to_db, const String & new_database_name, const String & new_table_name) override;\n \ndiff --git a/dbms/src/Storages/StorageTinyLog.cpp b/dbms/src/Storages/StorageTinyLog.cpp\nindex e941039e075c..4690ab925e87 100644\n--- a/dbms/src/Storages/StorageTinyLog.cpp\n+++ b/dbms/src/Storages/StorageTinyLog.cpp\n@@ -398,7 +398,7 @@ BlockInputStreams StorageTinyLog::read(\n \n \n BlockOutputStreamPtr StorageTinyLog::write(\n-    const ASTPtr & /*query*/, const Settings & /*settings*/)\n+    const ASTPtr & /*query*/, const Context & /*context*/)\n {\n     return std::make_shared<TinyLogBlockOutputStream>(*this);\n }\ndiff --git a/dbms/src/Storages/StorageTinyLog.h b/dbms/src/Storages/StorageTinyLog.h\nindex b96570b44286..5b8e4bc90ac8 100644\n--- a/dbms/src/Storages/StorageTinyLog.h\n+++ b/dbms/src/Storages/StorageTinyLog.h\n@@ -35,7 +35,7 @@ friend class TinyLogBlockOutputStream;\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     void rename(const String & new_path_to_db, const String & new_database_name, const String & new_table_name) override;\n \ndiff --git a/dbms/src/Storages/StorageURL.cpp b/dbms/src/Storages/StorageURL.cpp\nindex e22858cedc57..3224527123bb 100644\n--- a/dbms/src/Storages/StorageURL.cpp\n+++ b/dbms/src/Storages/StorageURL.cpp\n@@ -184,7 +184,7 @@ BlockInputStreams IStorageURLBase::read(const Names & column_names,\n \n void IStorageURLBase::rename(const String & /*new_path_to_db*/, const String & /*new_database_name*/, const String & /*new_table_name*/) {}\n \n-BlockOutputStreamPtr IStorageURLBase::write(const ASTPtr & /*query*/, const Settings & /*settings*/)\n+BlockOutputStreamPtr IStorageURLBase::write(const ASTPtr & /*query*/, const Context & /*context*/)\n {\n     return std::make_shared<StorageURLBlockOutputStream>(\n         uri, format_name, getSampleBlock(), context_global, ConnectionTimeouts::getHTTPTimeouts(context_global.getSettingsRef()));\ndiff --git a/dbms/src/Storages/StorageURL.h b/dbms/src/Storages/StorageURL.h\nindex dff889b6037b..b84898c696db 100644\n--- a/dbms/src/Storages/StorageURL.h\n+++ b/dbms/src/Storages/StorageURL.h\n@@ -28,7 +28,7 @@ class IStorageURLBase : public IStorage\n         size_t max_block_size,\n         unsigned num_streams) override;\n \n-    BlockOutputStreamPtr write(const ASTPtr & query, const Settings & settings) override;\n+    BlockOutputStreamPtr write(const ASTPtr & query, const Context & context) override;\n \n     void rename(const String & new_path_to_db, const String & new_database_name, const String & new_table_name) override;\n \ndiff --git a/dbms/src/Storages/System/StorageSystemColumns.cpp b/dbms/src/Storages/System/StorageSystemColumns.cpp\nindex 9a3d1dd1ecb4..fe0c3d90d69a 100644\n--- a/dbms/src/Storages/System/StorageSystemColumns.cpp\n+++ b/dbms/src/Storages/System/StorageSystemColumns.cpp\n@@ -61,9 +61,13 @@ class ColumnsBlockInputStream : public IBlockInputStream\n         UInt64 max_block_size,\n         ColumnPtr databases,\n         ColumnPtr tables,\n-        Storages storages)\n-        : columns_mask(columns_mask), header(header), max_block_size(max_block_size),\n-        databases(databases), tables(tables), storages(std::move(storages)), total_tables(tables->size()) {}\n+        Storages storages,\n+        String query_id_)\n+        : columns_mask(columns_mask), header(header), max_block_size(max_block_size)\n+        , databases(databases), tables(tables), storages(std::move(storages))\n+        , query_id(std::move(query_id_)), total_tables(tables->size())\n+    {\n+    }\n \n     String getName() const override { return \"Columns\"; }\n     Block getHeader() const override { return header; }\n@@ -100,7 +104,7 @@ class ColumnsBlockInputStream : public IBlockInputStream\n \n                 try\n                 {\n-                    table_lock = storage->lockStructure(false);\n+                    table_lock = storage->lockStructure(false, query_id);\n                 }\n                 catch (const Exception & e)\n                 {\n@@ -251,6 +255,7 @@ class ColumnsBlockInputStream : public IBlockInputStream\n     ColumnPtr databases;\n     ColumnPtr tables;\n     Storages storages;\n+    String query_id;\n     size_t db_table_num = 0;\n     size_t total_tables;\n };\n@@ -343,7 +348,8 @@ BlockInputStreams StorageSystemColumns::read(\n \n     return {std::make_shared<ColumnsBlockInputStream>(\n         std::move(columns_mask), std::move(res_block), max_block_size,\n-        std::move(filtered_database_column), std::move(filtered_table_column), std::move(storages))};\n+        std::move(filtered_database_column), std::move(filtered_table_column), std::move(storages),\n+        context.getCurrentQueryId())};\n }\n \n }\ndiff --git a/dbms/src/Storages/System/StorageSystemPartsBase.cpp b/dbms/src/Storages/System/StorageSystemPartsBase.cpp\nindex 435a246018d3..f8449e7a937b 100644\n--- a/dbms/src/Storages/System/StorageSystemPartsBase.cpp\n+++ b/dbms/src/Storages/System/StorageSystemPartsBase.cpp\n@@ -43,7 +43,8 @@ class StoragesInfoStream\n {\n public:\n     StoragesInfoStream(const SelectQueryInfo & query_info, const Context & context, bool has_state_column)\n-            : has_state_column(has_state_column)\n+        : query_id(context.getCurrentQueryId())\n+        , has_state_column(has_state_column)\n     {\n         /// Will apply WHERE to subset of columns and then add more columns.\n         /// This is kind of complicated, but we use WHERE to do less work.\n@@ -166,7 +167,7 @@ class StoragesInfoStream\n             try\n             {\n                 /// For table not to be dropped and set of columns to remain constant.\n-                info.table_lock = info.storage->lockStructure(false);\n+                info.table_lock = info.storage->lockStructure(false, query_id);\n             }\n             catch (const Exception & e)\n             {\n@@ -220,6 +221,8 @@ class StoragesInfoStream\n     }\n \n private:\n+    String query_id;\n+\n     bool has_state_column;\n \n     ColumnPtr database_column;\n",
  "test_patch": "diff --git a/dbms/src/Common/tests/gtest_rw_lock.cpp b/dbms/src/Common/tests/gtest_rw_lock.cpp\nindex c95be0d641d3..6e9b91dc048c 100644\n--- a/dbms/src/Common/tests/gtest_rw_lock.cpp\n+++ b/dbms/src/Common/tests/gtest_rw_lock.cpp\n@@ -39,7 +39,7 @@ TEST(Common, RWLock_1)\n             auto type = (std::uniform_int_distribution<>(0, 9)(gen) >= round) ? RWLockImpl::Read : RWLockImpl::Write;\n             auto sleep_for = std::chrono::duration<int, std::micro>(std::uniform_int_distribution<>(1, 100)(gen));\n \n-            auto lock = fifo_lock->getLock(type);\n+            auto lock = fifo_lock->getLock(type, RWLockImpl::NO_QUERY);\n \n             if (type == RWLockImpl::Write)\n             {\n@@ -99,7 +99,7 @@ TEST(Common, RWLock_Recursive)\n     {\n         for (int i = 0; i < 2 * cycles; ++i)\n         {\n-            auto lock = fifo_lock->getLock(RWLockImpl::Write);\n+            auto lock = fifo_lock->getLock(RWLockImpl::Write, RWLockImpl::NO_QUERY);\n \n             auto sleep_for = std::chrono::duration<int, std::micro>(std::uniform_int_distribution<>(1, 100)(gen));\n             std::this_thread::sleep_for(sleep_for);\n@@ -110,17 +110,17 @@ TEST(Common, RWLock_Recursive)\n     {\n         for (int i = 0; i < cycles; ++i)\n         {\n-            auto lock1 = fifo_lock->getLock(RWLockImpl::Read);\n+            auto lock1 = fifo_lock->getLock(RWLockImpl::Read, RWLockImpl::NO_QUERY);\n \n             auto sleep_for = std::chrono::duration<int, std::micro>(std::uniform_int_distribution<>(1, 100)(gen));\n             std::this_thread::sleep_for(sleep_for);\n \n-            auto lock2 = fifo_lock->getLock(RWLockImpl::Read);\n+            auto lock2 = fifo_lock->getLock(RWLockImpl::Read, RWLockImpl::NO_QUERY);\n \n-            EXPECT_ANY_THROW({fifo_lock->getLock(RWLockImpl::Write);});\n+            EXPECT_ANY_THROW({fifo_lock->getLock(RWLockImpl::Write, RWLockImpl::NO_QUERY);});\n         }\n \n-        fifo_lock->getLock(RWLockImpl::Write);\n+        fifo_lock->getLock(RWLockImpl::Write, RWLockImpl::NO_QUERY);\n     });\n \n     t1.join();\n@@ -143,7 +143,7 @@ TEST(Common, RWLock_PerfTest_Readers)\n             {\n                 for (auto i = 0; i < cycles; ++i)\n                 {\n-                    auto lock = fifo_lock->getLock(RWLockImpl::Read);\n+                    auto lock = fifo_lock->getLock(RWLockImpl::Read, RWLockImpl::NO_QUERY);\n                 }\n             };\n \ndiff --git a/dbms/tests/queries/0_stateless/00840_concurrent_select_and_drop_deadlock.reference b/dbms/tests/queries/0_stateless/00840_concurrent_select_and_drop_deadlock.reference\nnew file mode 100644\nindex 000000000000..6d8907676485\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00840_concurrent_select_and_drop_deadlock.reference\n@@ -0,0 +1,1 @@\n+did not deadlock\ndiff --git a/dbms/tests/queries/0_stateless/00840_concurrent_select_and_drop_deadlock.sh b/dbms/tests/queries/0_stateless/00840_concurrent_select_and_drop_deadlock.sh\nnew file mode 100755\nindex 000000000000..739ea6ba33c5\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00840_concurrent_select_and_drop_deadlock.sh\n@@ -0,0 +1,15 @@\n+#!/usr/bin/env bash\n+\n+set -e\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+for i in {1..200}; do echo \"drop table if exists test.view\" | $CLICKHOUSE_CLIENT; echo \"create view test.view as select count(*),database,table from system.columns group by database,table\" | $CLICKHOUSE_CLIENT; done &\n+for i in {1..500}; do echo \"select * from test.view order by table\" | $CLICKHOUSE_CLIENT >/dev/null 2>&1 || true; done &\n+\n+wait\n+\n+echo \"drop table test.view\" | $CLICKHOUSE_CLIENT\n+\n+echo 'did not deadlock'\ndiff --git a/dbms/tests/queries/bugs/00840_select_drop.sh b/dbms/tests/queries/bugs/00840_select_drop.sh\ndeleted file mode 100755\nindex bcc10bfa54b8..000000000000\n--- a/dbms/tests/queries/bugs/00840_select_drop.sh\n+++ /dev/null\n@@ -1,11 +0,0 @@\n-#!/usr/bin/env bash\n-\n-set -e\n-\n-CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n-. $CURDIR/../shell_config.sh\n-\n-for i in {1..1000}; do echo \"ddl $i\"; echo \"drop table if exists test.view\" | $CLICKHOUSE_CLIENT; echo \"create view test.view as select count(*),database,table from system.columns group by database,table\" | $CLICKHOUSE_CLIENT; done &\n-for i in {1..1000}; do echo \"select $i\"; echo \"select * from test.view order by table\" | $CLICKHOUSE_CLIENT >/dev/null 2>&1 || true; done &\n-\n-wait\n",
  "problem_statement": "Deadlock with concurrent SELECT / DROP TABLE\nI get a random deadlock when performing concurrently a SELECT and a DROP TABLE on the same view. I've tested with Clickhouse 18.14.19 and 19.1.6.\r\n\r\nTo reproduce the problem, just launch these 2 scripts in different shells:\r\n\r\n`for i in {1..1000}; do echo $i; echo \"drop table if exists test_view\" | clickhouse-client; echo \"create view test_view as select count(*),database,table from system.columns group by database,table\" | clickhouse-client; done\r\n`\r\n\r\n`for i in {1..1000}; do echo $i; echo \"select * from test_view order by table\" | clickhouse-client >/dev/null; done\r\n`\r\n\r\nI can see in system.processes my 2 queries which are still running:\r\n\r\n```\r\nselect elapsed,query from system.processes limit 2 format Vertical\r\n\r\nRow 1:\r\n\u2500\u2500\u2500\u2500\u2500\u2500\r\nelapsed: 502.919283347\r\nquery:   select * from test_view order by table\r\n\r\nRow 2:\r\n\u2500\u2500\u2500\u2500\u2500\u2500\r\nelapsed: 502.918433233\r\nquery:   drop table if exists test_view\r\n\r\n```\n",
  "hints_text": "There is fundamental issue with current implementation of table locks.\r\nNevertheless, we are going to fix it.",
  "created_at": "2019-02-28T09:46:58Z",
  "modified_files": [
    "dbms/programs/server/TCPHandler.cpp",
    "dbms/src/Common/RWLock.cpp",
    "dbms/src/Common/RWLock.h",
    "dbms/src/Core/ExternalTable.cpp",
    "dbms/src/DataStreams/CreatingSetsBlockInputStream.cpp",
    "dbms/src/DataStreams/CreatingSetsBlockInputStream.h",
    "dbms/src/DataStreams/PushingToViewsBlockOutputStream.cpp",
    "dbms/src/Functions/FunctionJoinGet.cpp",
    "dbms/src/Interpreters/ExpressionAnalyzer.cpp",
    "dbms/src/Interpreters/InterpreterCreateQuery.cpp",
    "dbms/src/Interpreters/InterpreterDescribeQuery.cpp",
    "dbms/src/Interpreters/InterpreterDropQuery.cpp",
    "dbms/src/Interpreters/InterpreterInsertQuery.cpp",
    "dbms/src/Interpreters/InterpreterOptimizeQuery.cpp",
    "dbms/src/Interpreters/InterpreterRenameQuery.cpp",
    "dbms/src/Interpreters/InterpreterSelectQuery.cpp",
    "dbms/src/Interpreters/InterpreterSystemQuery.cpp",
    "dbms/src/Interpreters/MutationsInterpreter.cpp",
    "dbms/src/Storages/IStorage.cpp",
    "dbms/src/Storages/IStorage.h",
    "dbms/src/Storages/MergeTree/DataPartsExchange.cpp",
    "dbms/src/Storages/MergeTree/ReplicatedMergeTreeAlterThread.cpp",
    "dbms/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp",
    "dbms/src/Storages/MergeTree/StorageFromMergeTreeDataPart.h",
    "dbms/src/Storages/StorageBuffer.cpp",
    "dbms/src/Storages/StorageBuffer.h",
    "dbms/src/Storages/StorageDistributed.cpp",
    "dbms/src/Storages/StorageDistributed.h",
    "dbms/src/Storages/StorageFile.cpp",
    "dbms/src/Storages/StorageFile.h",
    "dbms/src/Storages/StorageHDFS.cpp",
    "dbms/src/Storages/StorageHDFS.h",
    "dbms/src/Storages/StorageLog.cpp",
    "dbms/src/Storages/StorageLog.h",
    "dbms/src/Storages/StorageMaterializedView.cpp",
    "dbms/src/Storages/StorageMaterializedView.h",
    "dbms/src/Storages/StorageMemory.cpp",
    "dbms/src/Storages/StorageMemory.h",
    "dbms/src/Storages/StorageMerge.cpp",
    "dbms/src/Storages/StorageMerge.h",
    "dbms/src/Storages/StorageMergeTree.cpp",
    "dbms/src/Storages/StorageMergeTree.h",
    "dbms/src/Storages/StorageMySQL.cpp",
    "dbms/src/Storages/StorageMySQL.h",
    "dbms/src/Storages/StorageNull.cpp",
    "dbms/src/Storages/StorageNull.h",
    "dbms/src/Storages/StorageReplicatedMergeTree.cpp",
    "dbms/src/Storages/StorageReplicatedMergeTree.h",
    "dbms/src/Storages/StorageSet.cpp",
    "dbms/src/Storages/StorageSet.h",
    "dbms/src/Storages/StorageStripeLog.cpp",
    "dbms/src/Storages/StorageStripeLog.h",
    "dbms/src/Storages/StorageTinyLog.cpp",
    "dbms/src/Storages/StorageTinyLog.h",
    "dbms/src/Storages/StorageURL.cpp",
    "dbms/src/Storages/StorageURL.h",
    "dbms/src/Storages/System/StorageSystemColumns.cpp",
    "dbms/src/Storages/System/StorageSystemPartsBase.cpp"
  ],
  "modified_test_files": [
    "dbms/src/Common/tests/gtest_rw_lock.cpp",
    "b/dbms/tests/queries/0_stateless/00840_concurrent_select_and_drop_deadlock.reference",
    "b/dbms/tests/queries/0_stateless/00840_concurrent_select_and_drop_deadlock.sh",
    "dbms/tests/queries/bugs/00840_select_drop.sh"
  ]
}