{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 42002,
  "instance_id": "ClickHouse__ClickHouse-42002",
  "issue_numbers": [
    "6551"
  ],
  "base_commit": "69ebf12dabf5c2b17758c5faf683b410684d5de8",
  "patch": "diff --git a/src/Interpreters/AsynchronousMetrics.cpp b/src/Interpreters/AsynchronousMetrics.cpp\nindex 23845e0424ea..338ae1bbbfd9 100644\n--- a/src/Interpreters/AsynchronousMetrics.cpp\n+++ b/src/Interpreters/AsynchronousMetrics.cpp\n@@ -1420,7 +1420,7 @@ void AsynchronousMetrics::update(TimePoint update_time)\n                 {\n                     const auto & settings = getContext()->getSettingsRef();\n \n-                    calculateMax(max_part_count_for_partition, table_merge_tree->getMaxPartsCountForPartition());\n+                    calculateMax(max_part_count_for_partition, table_merge_tree->getMaxPartsCountAndSizeForPartition().first);\n                     total_number_of_bytes += table_merge_tree->totalBytes(settings).value();\n                     total_number_of_rows += table_merge_tree->totalRows(settings).value();\n                     total_number_of_parts += table_merge_tree->getPartsCount();\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex 4a7d2b2dd63d..e6001905d032 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -3442,42 +3442,49 @@ size_t MergeTreeData::getPartsCount() const\n }\n \n \n-size_t MergeTreeData::getMaxPartsCountForPartitionWithState(DataPartState state) const\n+std::pair<size_t, size_t> MergeTreeData::getMaxPartsCountAndSizeForPartitionWithState(DataPartState state) const\n {\n     auto lock = lockParts();\n \n-    size_t res = 0;\n-    size_t cur_count = 0;\n+    size_t cur_parts_count = 0;\n+    size_t cur_parts_size = 0;\n+    size_t max_parts_count = 0;\n+    size_t argmax_parts_size = 0;\n+\n     const String * cur_partition_id = nullptr;\n \n     for (const auto & part : getDataPartsStateRange(state))\n     {\n-        if (cur_partition_id && part->info.partition_id == *cur_partition_id)\n-        {\n-            ++cur_count;\n-        }\n-        else\n+        if (!cur_partition_id || part->info.partition_id != *cur_partition_id)\n         {\n             cur_partition_id = &part->info.partition_id;\n-            cur_count = 1;\n+            cur_parts_count = 0;\n+            cur_parts_size = 0;\n         }\n \n-        res = std::max(res, cur_count);\n+        ++cur_parts_count;\n+        cur_parts_size += part->getBytesOnDisk();\n+\n+        if (cur_parts_count > max_parts_count)\n+        {\n+            max_parts_count = cur_parts_count;\n+            argmax_parts_size = cur_parts_size;\n+        }\n     }\n \n-    return res;\n+    return {max_parts_count, argmax_parts_size};\n }\n \n \n-size_t MergeTreeData::getMaxPartsCountForPartition() const\n+std::pair<size_t, size_t> MergeTreeData::getMaxPartsCountAndSizeForPartition() const\n {\n-    return getMaxPartsCountForPartitionWithState(DataPartState::Active);\n+    return getMaxPartsCountAndSizeForPartitionWithState(DataPartState::Active);\n }\n \n \n size_t MergeTreeData::getMaxInactivePartsCountForPartition() const\n {\n-    return getMaxPartsCountForPartitionWithState(DataPartState::Outdated);\n+    return getMaxPartsCountAndSizeForPartitionWithState(DataPartState::Outdated).first;\n }\n \n \n@@ -3507,7 +3514,7 @@ void MergeTreeData::delayInsertOrThrowIfNeeded(Poco::Event * until, ContextPtr q\n         throw Exception(\"Too many parts (\" + toString(parts_count_in_total) + \") in all partitions in total. This indicates wrong choice of partition key. The threshold can be modified with 'max_parts_in_total' setting in <merge_tree> element in config.xml or with per-table setting.\", ErrorCodes::TOO_MANY_PARTS);\n     }\n \n-    size_t parts_count_in_partition = getMaxPartsCountForPartition();\n+    auto [parts_count_in_partition, size_of_partition] = getMaxPartsCountAndSizeForPartition();\n     ssize_t k_inactive = -1;\n     if (settings->inactive_parts_to_throw_insert > 0 || settings->inactive_parts_to_delay_insert > 0)\n     {\n@@ -3526,13 +3533,17 @@ void MergeTreeData::delayInsertOrThrowIfNeeded(Poco::Event * until, ContextPtr q\n     auto parts_to_delay_insert = query_settings.parts_to_delay_insert ? query_settings.parts_to_delay_insert : settings->parts_to_delay_insert;\n     auto parts_to_throw_insert = query_settings.parts_to_throw_insert ? query_settings.parts_to_throw_insert : settings->parts_to_throw_insert;\n \n-    if (parts_count_in_partition >= parts_to_throw_insert)\n+    size_t average_part_size = parts_count_in_partition ? size_of_partition / parts_count_in_partition : 0;\n+    bool parts_are_large_enough_in_average = settings->max_avg_part_size_for_too_many_parts\n+        && average_part_size > settings->max_avg_part_size_for_too_many_parts;\n+\n+    if (parts_count_in_partition >= parts_to_throw_insert && !parts_are_large_enough_in_average)\n     {\n         ProfileEvents::increment(ProfileEvents::RejectedInserts);\n         throw Exception(\n             ErrorCodes::TOO_MANY_PARTS,\n-            \"Too many parts ({}). Merges are processing significantly slower than inserts\",\n-            parts_count_in_partition);\n+            \"Too many parts ({} with average size of {}). Merges are processing significantly slower than inserts\",\n+            parts_count_in_partition, ReadableSize(average_part_size));\n     }\n \n     if (k_inactive < 0 && parts_count_in_partition < parts_to_delay_insert)\n@@ -3541,7 +3552,7 @@ void MergeTreeData::delayInsertOrThrowIfNeeded(Poco::Event * until, ContextPtr q\n     const ssize_t k_active = ssize_t(parts_count_in_partition) - ssize_t(parts_to_delay_insert);\n     size_t max_k;\n     size_t k;\n-    if (k_active > k_inactive)\n+    if (k_active > k_inactive && !parts_are_large_enough_in_average)\n     {\n         max_k = parts_to_throw_insert - parts_to_delay_insert;\n         k = k_active + 1;\n@@ -3558,7 +3569,8 @@ void MergeTreeData::delayInsertOrThrowIfNeeded(Poco::Event * until, ContextPtr q\n \n     CurrentMetrics::Increment metric_increment(CurrentMetrics::DelayedInserts);\n \n-    LOG_INFO(log, \"Delaying inserting block by {} ms. because there are {} parts\", delay_milliseconds, parts_count_in_partition);\n+    LOG_INFO(log, \"Delaying inserting block by {} ms. because there are {} parts and their average size is {}\",\n+        delay_milliseconds, parts_count_in_partition, ReadableSize(average_part_size));\n \n     if (until)\n         until->tryWait(delay_milliseconds);\n@@ -3566,6 +3578,7 @@ void MergeTreeData::delayInsertOrThrowIfNeeded(Poco::Event * until, ContextPtr q\n         std::this_thread::sleep_for(std::chrono::milliseconds(static_cast<size_t>(delay_milliseconds)));\n }\n \n+\n MergeTreeData::DataPartPtr MergeTreeData::getActiveContainingPart(\n     const MergeTreePartInfo & part_info, MergeTreeData::DataPartState state, DataPartsLock & /*lock*/) const\n {\ndiff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h\nindex c3a70a9893b1..c4a5d66ccbeb 100644\n--- a/src/Storages/MergeTree/MergeTreeData.h\n+++ b/src/Storages/MergeTree/MergeTreeData.h\n@@ -520,8 +520,12 @@ class MergeTreeData : public IStorage, public WithMutableContext\n     size_t getTotalActiveSizeInRows() const;\n \n     size_t getPartsCount() const;\n-    size_t getMaxPartsCountForPartitionWithState(DataPartState state) const;\n-    size_t getMaxPartsCountForPartition() const;\n+\n+    /// Returns a pair with: max number of parts in partition across partitions; sum size of parts inside that partition.\n+    /// (if there are multiple partitions with max number of parts, the sum size of parts is returned for arbitrary of them)\n+    std::pair<size_t, size_t> getMaxPartsCountAndSizeForPartitionWithState(DataPartState state) const;\n+    std::pair<size_t, size_t> getMaxPartsCountAndSizeForPartition() const;\n+\n     size_t getMaxInactivePartsCountForPartition() const;\n \n     /// Get min value of part->info.getDataVersion() for all active parts.\ndiff --git a/src/Storages/MergeTree/MergeTreeSettings.h b/src/Storages/MergeTree/MergeTreeSettings.h\nindex 8d7f057e7205..a0db39a97f14 100644\n--- a/src/Storages/MergeTree/MergeTreeSettings.h\n+++ b/src/Storages/MergeTree/MergeTreeSettings.h\n@@ -70,6 +70,7 @@ struct Settings;\n     M(UInt64, inactive_parts_to_delay_insert, 0, \"If table contains at least that many inactive parts in single partition, artificially slow down insert into table.\", 0) \\\n     M(UInt64, parts_to_throw_insert, 300, \"If more than this number active parts in single partition, throw 'Too many parts ...' exception.\", 0) \\\n     M(UInt64, inactive_parts_to_throw_insert, 0, \"If more than this number inactive parts in single partition, throw 'Too many inactive parts ...' exception.\", 0) \\\n+    M(UInt64, max_avg_part_size_for_too_many_parts, 10ULL * 1024 * 1024 * 1024, \"The 'too many parts' check according to 'parts_to_delay_insert' and 'parts_to_throw_insert' will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts.\", 0) \\\n     M(UInt64, max_delay_to_insert, 1, \"Max delay of inserting data into MergeTree table in seconds, if there are a lot of unmerged parts in single partition.\", 0) \\\n     M(UInt64, max_parts_in_total, 100000, \"If more than this number active parts in all partitions in total, throw 'Too many parts ...' exception.\", 0) \\\n     \\\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02458_relax_too_many_parts.reference b/tests/queries/0_stateless/02458_relax_too_many_parts.reference\nnew file mode 100644\nindex 000000000000..6d532a1e49ab\n--- /dev/null\n+++ b/tests/queries/0_stateless/02458_relax_too_many_parts.reference\n@@ -0,0 +1,1 @@\n+4\t8000000\ndiff --git a/tests/queries/0_stateless/02458_relax_too_many_parts.sql b/tests/queries/0_stateless/02458_relax_too_many_parts.sql\nnew file mode 100644\nindex 000000000000..a1f8e86fce5f\n--- /dev/null\n+++ b/tests/queries/0_stateless/02458_relax_too_many_parts.sql\n@@ -0,0 +1,36 @@\n+DROP TABLE IF EXISTS test;\n+CREATE TABLE test (x UInt64, s String) ENGINE = MergeTree ORDER BY tuple() SETTINGS parts_to_throw_insert = 3;\n+\n+-- The \"too many parts\" threshold works:\n+SET max_block_size = 1, min_insert_block_size_rows = 1, min_insert_block_size_bytes = 1;\n+SYSTEM STOP MERGES test;\n+INSERT INTO test VALUES (1, 'a');\n+INSERT INTO test VALUES (2, 'a');\n+INSERT INTO test VALUES (3, 'a');\n+INSERT INTO test VALUES (4, 'a'); -- { serverError TOO_MANY_PARTS }\n+\n+-- But it can be relaxed with a setting:\n+ALTER TABLE test MODIFY SETTING max_avg_part_size_for_too_many_parts = '1M';\n+\n+-- It works in the same way if parts are small:\n+SYSTEM START MERGES test;\n+OPTIMIZE TABLE test FINAL;\n+SYSTEM STOP MERGES test;\n+\n+INSERT INTO test VALUES (5, 'a');\n+INSERT INTO test VALUES (6, 'a');\n+INSERT INTO test VALUES (7, 'a'); -- { serverError TOO_MANY_PARTS }\n+\n+-- But it allows having more parts if their average size is large:\n+SYSTEM START MERGES test;\n+OPTIMIZE TABLE test FINAL;\n+SYSTEM STOP MERGES test;\n+\n+SET max_block_size = 65000, min_insert_block_size_rows = 65000, min_insert_block_size_bytes = '1M';\n+INSERT INTO test SELECT number, randomString(1000) FROM numbers(0, 10000);\n+INSERT INTO test SELECT number, randomString(1000) FROM numbers(10000, 10000);\n+INSERT INTO test SELECT number, randomString(1000) FROM numbers(20000, 10000);\n+\n+SELECT count(), round(avg(bytes), -6) FROM system.parts WHERE database = currentDatabase() AND table = 'test' AND active;\n+\n+DROP TABLE test;\n",
  "problem_statement": "Relax \"Too many parts\" threshold.\nIf the server has huge disk shelves, the number of data parts can be large, because the maximum size of a single data part is just 150 GB. Example: a server has 150 TB of storage and there are 1000 data parts in a single partition of 150 GB each.\r\n\r\nProposal: delay inserts or throw an exception only if there are too many parts and their average size is less than a specified threshold (e.g. max_part_size / 10).\n",
  "hints_text": "@alexey-milovidov can you assign the issue to me?\n@DenisIsaev Ok.",
  "created_at": "2022-10-01T18:50:42Z"
}