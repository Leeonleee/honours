{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 6232,
  "instance_id": "ClickHouse__ClickHouse-6232",
  "issue_numbers": [
    "5547"
  ],
  "base_commit": "8949ef6dd3b4fd639919b1c524ffe2d09b70de9c",
  "patch": "diff --git a/dbms/src/DataStreams/IBlockInputStream.cpp b/dbms/src/DataStreams/IBlockInputStream.cpp\nindex 406a660879c5..a2c3fb2247c5 100644\n--- a/dbms/src/DataStreams/IBlockInputStream.cpp\n+++ b/dbms/src/DataStreams/IBlockInputStream.cpp\n@@ -255,6 +255,10 @@ static void limitProgressingSpeed(size_t total_progress_size, size_t max_speed_i\n     if (desired_microseconds > total_elapsed_microseconds)\n     {\n         UInt64 sleep_microseconds = desired_microseconds - total_elapsed_microseconds;\n+\n+        /// Never sleep more than one second (it should be enough to limit speed for a reasonable amount, and otherwise it's too easy to make query hang).\n+        sleep_microseconds = std::min(UInt64(1000000), sleep_microseconds);\n+\n         sleepForMicroseconds(sleep_microseconds);\n \n         ProfileEvents::increment(ProfileEvents::ThrottlerSleepMicroseconds, sleep_microseconds);\n@@ -349,7 +353,7 @@ void IBlockInputStream::progressImpl(const Progress & value)\n                         ErrorCodes::TOO_SLOW);\n \n                 /// If the predicted execution time is longer than `max_execution_time`.\n-                if (limits.max_execution_time != 0 && total_rows)\n+                if (limits.max_execution_time != 0 && total_rows && progress.read_rows)\n                 {\n                     double estimated_execution_time_seconds = elapsed_seconds * (static_cast<double>(total_rows) / progress.read_rows);\n \n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/00976_max_execution_speed.reference b/dbms/tests/queries/0_stateless/00976_max_execution_speed.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/dbms/tests/queries/0_stateless/00976_max_execution_speed.sql b/dbms/tests/queries/0_stateless/00976_max_execution_speed.sql\nnew file mode 100644\nindex 000000000000..06386d774130\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00976_max_execution_speed.sql\n@@ -0,0 +1,2 @@\n+SET max_execution_speed = 1, max_execution_time = 3;\n+SELECT count() FROM system.numbers; -- { serverError 159 }\n",
  "problem_statement": "Estimated query time is infinite\nHi all,\r\n\r\nWe have following settings:\r\n```sql\r\nset max_execution_time=5;\r\nset max_execution_speed=100000;\r\n```\r\n\r\nWe got:\r\n```sql\r\nSELECT \r\n    meta.1 AS origin, \r\n    meta.2 AS total\r\nFROM \r\n(\r\n    SELECT \r\n        (\r\n            SELECT (max(seq_no), count())\r\n            FROM order_fills_log \r\n            PREWHERE account_id IN (238461787185189)\r\n        ) AS meta\r\n    FROM order_fills_log \r\n    PREWHERE account_id IN (238461787185189)\r\n    LIMIT 0, 10\r\n)\r\n\r\n\u2197 Progress: 0.00 rows, 0.00 B (0.00 rows/s., 0.00 B/s.) Received exception from server (version 19.7.3):\r\nCode: 160. DB::Exception: Received from test7:9001, 10.225.17.23. DB::Exception: Estimated query execution time (inf seconds) is too long. Maximum: 5. Estimated rows to process: 16384. \r\n\r\n0 rows in set. Elapsed: 0.036 sec.\r\n```\r\n\r\nWe didn't expect such behavior, so how can we solve this problem?\n",
  "hints_text": "",
  "created_at": "2019-07-31T00:07:09Z"
}