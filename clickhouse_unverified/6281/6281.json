{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 6281,
  "instance_id": "ClickHouse__ClickHouse-6281",
  "issue_numbers": [
    "6257"
  ],
  "base_commit": "7bb387496ad9555b7c8939b815ed274121620c2f",
  "patch": "diff --git a/dbms/src/AggregateFunctions/AggregateFunctionFactory.cpp b/dbms/src/AggregateFunctions/AggregateFunctionFactory.cpp\nindex ce7adf5b96db..83fb9f48abe3 100644\n--- a/dbms/src/AggregateFunctions/AggregateFunctionFactory.cpp\n+++ b/dbms/src/AggregateFunctions/AggregateFunctionFactory.cpp\n@@ -49,12 +49,7 @@ static DataTypes convertLowCardinalityTypesToNested(const DataTypes & types)\n     DataTypes res_types;\n     res_types.reserve(types.size());\n     for (const auto & type : types)\n-    {\n-        if (auto * low_cardinality_type = typeid_cast<const DataTypeLowCardinality *>(type.get()))\n-            res_types.push_back(low_cardinality_type->getDictionaryType());\n-        else\n-            res_types.push_back(type);\n-    }\n+        res_types.emplace_back(recursiveRemoveLowCardinality(type));\n \n     return res_types;\n }\n@@ -69,7 +64,7 @@ AggregateFunctionPtr AggregateFunctionFactory::get(\n \n     /// If one of types is Nullable, we apply aggregate function combinator \"Null\".\n \n-    if (std::any_of(argument_types.begin(), argument_types.end(),\n+    if (std::any_of(type_without_low_cardinality.begin(), type_without_low_cardinality.end(),\n         [](const auto & type) { return type->isNullable(); }))\n     {\n         AggregateFunctionCombinatorPtr combinator = AggregateFunctionCombinatorFactory::instance().tryFindSuffix(\"Null\");\n@@ -83,11 +78,11 @@ AggregateFunctionPtr AggregateFunctionFactory::get(\n \n         /// A little hack - if we have NULL arguments, don't even create nested function.\n         /// Combinator will check if nested_function was created.\n-        if (name == \"count\" || std::none_of(argument_types.begin(), argument_types.end(),\n+        if (name == \"count\" || std::none_of(type_without_low_cardinality.begin(), type_without_low_cardinality.end(),\n             [](const auto & type) { return type->onlyNull(); }))\n             nested_function = getImpl(name, nested_types, nested_parameters, recursion_level);\n \n-        return combinator->transformAggregateFunction(nested_function, argument_types, parameters);\n+        return combinator->transformAggregateFunction(nested_function, type_without_low_cardinality, parameters);\n     }\n \n     auto res = getImpl(name, type_without_low_cardinality, parameters, recursion_level);\ndiff --git a/dbms/src/DataStreams/AggregatingSortedBlockInputStream.cpp b/dbms/src/DataStreams/AggregatingSortedBlockInputStream.cpp\nindex d3d5bd5c9089..44e8e7386da4 100644\n--- a/dbms/src/DataStreams/AggregatingSortedBlockInputStream.cpp\n+++ b/dbms/src/DataStreams/AggregatingSortedBlockInputStream.cpp\n@@ -4,6 +4,7 @@\n #include <Common/Arena.h>\n #include <DataTypes/DataTypeAggregateFunction.h>\n #include <DataTypes/DataTypeCustomSimpleAggregateFunction.h>\n+#include <DataTypes/DataTypeLowCardinality.h>\n \n \n namespace DB\n@@ -15,10 +16,52 @@ namespace ErrorCodes\n }\n \n \n+class RemovingLowCardinalityBlockInputStream : public IBlockInputStream\n+{\n+public:\n+    RemovingLowCardinalityBlockInputStream(BlockInputStreamPtr input_, ColumnNumbers positions_)\n+        : input(std::move(input_)), positions(std::move(positions_))\n+    {\n+        header = transform(input->getHeader());\n+    }\n+\n+    Block transform(Block block)\n+    {\n+        if (block)\n+        {\n+            for (auto & pos : positions)\n+            {\n+                auto & col = block.safeGetByPosition(pos);\n+                col.column = recursiveRemoveLowCardinality(col.column);\n+                col.type = recursiveRemoveLowCardinality(col.type);\n+            }\n+        }\n+\n+        return block;\n+    }\n+\n+    String getName() const override { return \"RemovingLowCardinality\"; }\n+    Block getHeader() const override { return header; }\n+    const BlockMissingValues & getMissingValues() const override { return input->getMissingValues(); }\n+    bool isSortedOutput() const override { return input->isSortedOutput(); }\n+    const SortDescription & getSortDescription() const override { return input->getSortDescription(); }\n+\n+protected:\n+    Block readImpl() override { return transform(input->read()); }\n+\n+private:\n+    Block header;\n+    BlockInputStreamPtr input;\n+    ColumnNumbers positions;\n+};\n+\n+\n AggregatingSortedBlockInputStream::AggregatingSortedBlockInputStream(\n     const BlockInputStreams & inputs_, const SortDescription & description_, size_t max_block_size_)\n     : MergingSortedBlockInputStream(inputs_, description_, max_block_size_)\n {\n+    ColumnNumbers positions;\n+\n     /// Fill in the column numbers that need to be aggregated.\n     for (size_t i = 0; i < num_columns; ++i)\n     {\n@@ -51,6 +94,9 @@ AggregatingSortedBlockInputStream::AggregatingSortedBlockInputStream(\n                 allocatesMemoryInArena = true;\n \n             columns_to_simple_aggregate.emplace_back(std::move(desc));\n+\n+            if (recursiveRemoveLowCardinality(column.type).get() != column.type.get())\n+                positions.emplace_back(i);\n         }\n         else\n         {\n@@ -58,6 +104,14 @@ AggregatingSortedBlockInputStream::AggregatingSortedBlockInputStream(\n             column_numbers_to_aggregate.push_back(i);\n         }\n     }\n+\n+    if (!positions.empty())\n+    {\n+        for (auto & input : children)\n+            input = std::make_shared<RemovingLowCardinalityBlockInputStream>(input, positions);\n+\n+        header = children.at(0)->getHeader();\n+    }\n }\n \n \ndiff --git a/dbms/src/Interpreters/ExpressionAnalyzer.cpp b/dbms/src/Interpreters/ExpressionAnalyzer.cpp\nindex 055f5c8f3ec0..04b41e1bfe24 100644\n--- a/dbms/src/Interpreters/ExpressionAnalyzer.cpp\n+++ b/dbms/src/Interpreters/ExpressionAnalyzer.cpp\n@@ -412,7 +412,7 @@ void ExpressionAnalyzer::getAggregates(const ASTPtr & ast, ExpressionActionsPtr\n \n             getRootActions(arguments[i], true, actions);\n             const std::string & name = arguments[i]->getColumnName();\n-            types[i] = recursiveRemoveLowCardinality(actions->getSampleBlock().getByName(name).type);\n+            types[i] = actions->getSampleBlock().getByName(name).type;\n             aggregate.argument_names[i] = name;\n         }\n \n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/00976_shard_low_cardinality_achimbab.reference b/dbms/tests/queries/0_stateless/00976_shard_low_cardinality_achimbab.reference\nnew file mode 100644\nindex 000000000000..9972842f9827\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00976_shard_low_cardinality_achimbab.reference\n@@ -0,0 +1,1 @@\n+1\t1\ndiff --git a/dbms/tests/queries/0_stateless/00976_shard_low_cardinality_achimbab.sql b/dbms/tests/queries/0_stateless/00976_shard_low_cardinality_achimbab.sql\nnew file mode 100644\nindex 000000000000..3736be891cdf\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00976_shard_low_cardinality_achimbab.sql\n@@ -0,0 +1,6 @@\n+DROP TABLE IF EXISTS han_1;\n+CREATE TABLE han_1 (k Int32, date_dt LowCardinality(Nullable(String))) \n+ENGINE = MergeTree() PARTITION BY k ORDER BY k;\n+INSERT INTO han_1 values (1, '2019-07-31');\n+SELECT k, uniq(date_dt) FROM remote('127.0.0.{1,2}', currentDatabase(), han_1) GROUP BY k;\n+DROP TABLE IF EXISTS han_1;\n",
  "problem_statement": "An uniq() query for the LowCardinality leads to an error.\nI got error messages when I sent a query with uniq() for LowCardinality to a  distributed table.\r\n* Code: 261. DB::Exception: Received from localhost:9000. DB::Exception: Unknown BlockInfo field number: 62: while receiving packet from tiara-clickhouse-data12.dakao.io:9000. \r\n* Code: 1000. DB::Exception: Received from localhost:9000. DB::Exception: Exception: Cannot read UniquesHashSet: too large size_degree.\r\n\r\nIt is reproduced with followig configurations.\r\n\r\n**local tables**\r\n```\r\nCREATE TABLE default.han_1 (k Int32, date_dt LowCardinality(Nullable(String))) \r\nENGINE = MergeTree() PARTITION BY k ORDER BY k SETTINGS index_granularity = 8192\r\n```\r\n\r\n**distributed tables**\r\n```\r\nCREATE TABLE default.han_dist (k Int32, date_dt LowCardinality(Nullable(String))) \r\nENGINE = Distributed(cluster_test, default, han_1)\r\n```\r\n\r\n**dataset**\r\n```1, '2019-07-31'``` for each han_1\r\n\r\n**query**\r\n```\r\nselect k, uniq(date_dt) from han_dist group by k\r\n```\n",
  "hints_text": "",
  "created_at": "2019-08-01T18:47:00Z"
}