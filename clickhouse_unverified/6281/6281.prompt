You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
An uniq() query for the LowCardinality leads to an error.
I got error messages when I sent a query with uniq() for LowCardinality to a  distributed table.
* Code: 261. DB::Exception: Received from localhost:9000. DB::Exception: Unknown BlockInfo field number: 62: while receiving packet from tiara-clickhouse-data12.dakao.io:9000. 
* Code: 1000. DB::Exception: Received from localhost:9000. DB::Exception: Exception: Cannot read UniquesHashSet: too large size_degree.

It is reproduced with followig configurations.

**local tables**
```
CREATE TABLE default.han_1 (k Int32, date_dt LowCardinality(Nullable(String))) 
ENGINE = MergeTree() PARTITION BY k ORDER BY k SETTINGS index_granularity = 8192
```

**distributed tables**
```
CREATE TABLE default.han_dist (k Int32, date_dt LowCardinality(Nullable(String))) 
ENGINE = Distributed(cluster_test, default, han_1)
```

**dataset**
```1, '2019-07-31'``` for each han_1

**query**
```
select k, uniq(date_dt) from han_dist group by k
```
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
