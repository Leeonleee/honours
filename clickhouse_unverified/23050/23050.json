{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 23050,
  "instance_id": "ClickHouse__ClickHouse-23050",
  "issue_numbers": [
    "19283"
  ],
  "base_commit": "9bb4d8769f1064ada4cce6b26d8ff61c11356965",
  "patch": "diff --git a/programs/client/Client.cpp b/programs/client/Client.cpp\nindex 1aec3677b414..3917d775cbc4 100644\n--- a/programs/client/Client.cpp\n+++ b/programs/client/Client.cpp\n@@ -2252,30 +2252,27 @@ class Client : public Poco::Util::Application\n             return;\n \n         processed_rows += block.rows();\n+\n+        /// Even if all blocks are empty, we still need to initialize the output stream to write empty resultset.\n         initBlockOutputStream(block);\n \n         /// The header block containing zero rows was used to initialize\n         /// block_out_stream, do not output it.\n         /// Also do not output too much data if we're fuzzing.\n-        if (block.rows() != 0\n-            && (query_fuzzer_runs == 0 || processed_rows < 100))\n-        {\n-            block_out_stream->write(block);\n-            written_first_block = true;\n-        }\n+        if (block.rows() == 0 || (query_fuzzer_runs != 0 && processed_rows >= 100))\n+            return;\n \n-        bool clear_progress = false;\n         if (need_render_progress)\n-            clear_progress = std_out.offset() > 0;\n-\n-        if (clear_progress)\n             clearProgress();\n \n+        block_out_stream->write(block);\n+        written_first_block = true;\n+\n         /// Received data block is immediately displayed to the user.\n         block_out_stream->flush();\n \n         /// Restore progress bar after data block.\n-        if (clear_progress)\n+        if (need_render_progress)\n             writeProgress();\n     }\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py b/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py\nindex 7924aa15d0ca..5f5f4d7a9609 100755\n--- a/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py\n+++ b/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py\n@@ -30,7 +30,6 @@\n     client1.send('CREATE LIVE VIEW test.lv AS SELECT toStartOfDay(time) AS day, location, avg(temperature) FROM test.mt GROUP BY day, location ORDER BY day, location')\n     client1.expect(prompt)\n     client1.send('WATCH test.lv FORMAT CSVWithNames')\n-    client1.expect(r'_version')\n     client2.send(\"INSERT INTO test.mt VALUES ('2019-01-01 00:00:00','New York',60),('2019-01-01 00:10:00','New York',70)\")\n     client2.expect(prompt)\n     client1.expect(r'\"2019-01-01 00:00:00\",\"New York\",65')\n@@ -60,7 +59,7 @@\n     match = client1.expect('(%s)|([#\\$] )' % prompt)\n     if match.groups()[1]:\n         client1.send(client1.command)\n-        client1.expect(prompt)    \n+        client1.expect(prompt)\n     client1.send('DROP TABLE test.lv')\n     client1.expect(prompt)\n     client1.send('DROP TABLE test.mt')\ndiff --git a/tests/queries/0_stateless/01184_insert_values_huge_strings.sh b/tests/queries/0_stateless/01184_insert_values_huge_strings.sh\ndeleted file mode 100755\nindex 9b63f401a59f..000000000000\n--- a/tests/queries/0_stateless/01184_insert_values_huge_strings.sh\n+++ /dev/null\n@@ -1,20 +0,0 @@\n-#!/usr/bin/env bash\n-\n-CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n-# shellcheck source=../shell_config.sh\n-. \"$CURDIR\"/../shell_config.sh\n-\n-$CLICKHOUSE_CLIENT -q \"drop table if exists huge_strings\"\n-$CLICKHOUSE_CLIENT -q \"create table huge_strings (n UInt64, l UInt64, s String, h UInt64) engine=MergeTree order by n\"\n-\n-for _ in {1..10}; do\n-  $CLICKHOUSE_CLIENT -q \"select number, (rand() % 100*1000*1000) as l, repeat(randomString(l/1000/1000), 1000*1000) as s, cityHash64(s) from numbers(10) format Values\" | $CLICKHOUSE_CLIENT -q \"insert into huge_strings values\" &\n-  $CLICKHOUSE_CLIENT -q \"select number % 10, (rand() % 100) as l, randomString(l) as s, cityHash64(s) from numbers(100000)\" | $CLICKHOUSE_CLIENT -q \"insert into huge_strings format TSV\" &\n-done;\n-wait\n-\n-$CLICKHOUSE_CLIENT -q \"select count() from huge_strings\"\n-$CLICKHOUSE_CLIENT -q \"select sum(l = length(s)) from huge_strings\"\n-$CLICKHOUSE_CLIENT -q \"select sum(h = cityHash64(s)) from huge_strings\"\n-\n-$CLICKHOUSE_CLIENT -q \"drop table huge_strings\"\ndiff --git a/tests/queries/0_stateless/01184_insert_values_huge_strings.reference b/tests/queries/0_stateless/01184_long_insert_values_huge_strings.reference\nsimilarity index 100%\nrename from tests/queries/0_stateless/01184_insert_values_huge_strings.reference\nrename to tests/queries/0_stateless/01184_long_insert_values_huge_strings.reference\ndiff --git a/tests/queries/0_stateless/01184_long_insert_values_huge_strings.sh b/tests/queries/0_stateless/01184_long_insert_values_huge_strings.sh\nnew file mode 100755\nindex 000000000000..f3b3431dffe3\n--- /dev/null\n+++ b/tests/queries/0_stateless/01184_long_insert_values_huge_strings.sh\n@@ -0,0 +1,22 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT -q \"drop table if exists huge_strings\"\n+$CLICKHOUSE_CLIENT -q \"create table huge_strings (n UInt64, l UInt64, s String, h UInt64) engine=MergeTree order by n\"\n+\n+# Timeouts are increased, because test can be slow with sanitizers and parallel runs.\n+\n+for _ in {1..10}; do\n+  $CLICKHOUSE_CLIENT --receive_timeout 100 --send_timeout 100 --connect_timeout 100 --query \"select number, (rand() % 10*1000*1000) as l, repeat(randomString(l/1000/1000), 1000*1000) as s, cityHash64(s) from numbers(10) format Values\" | $CLICKHOUSE_CLIENT --receive_timeout 100 --send_timeout 100 --connect_timeout 100 --query \"insert into huge_strings values\" &\n+  $CLICKHOUSE_CLIENT --receive_timeout 100 --send_timeout 100 --connect_timeout 100 --query \"select number % 10, (rand() % 10) as l, randomString(l) as s, cityHash64(s) from numbers(100000)\" | $CLICKHOUSE_CLIENT --receive_timeout 100 --send_timeout 100 --connect_timeout 100 --query \"insert into huge_strings format TSV\" &\n+done;\n+wait\n+\n+$CLICKHOUSE_CLIENT -q \"select count() from huge_strings\"\n+$CLICKHOUSE_CLIENT -q \"select sum(l = length(s)) from huge_strings\"\n+$CLICKHOUSE_CLIENT -q \"select sum(h = cityHash64(s)) from huge_strings\"\n+\n+$CLICKHOUSE_CLIENT -q \"drop table huge_strings\"\ndiff --git a/tests/queries/0_stateless/01246_insert_into_watch_live_view.py b/tests/queries/0_stateless/01246_insert_into_watch_live_view.py\nindex 0f7c6965b7b8..193d23999be5 100755\n--- a/tests/queries/0_stateless/01246_insert_into_watch_live_view.py\n+++ b/tests/queries/0_stateless/01246_insert_into_watch_live_view.py\n@@ -25,6 +25,8 @@\n \n     client1.send('DROP TABLE IF EXISTS test.lv')\n     client1.expect(prompt)\n+    client1.send('DROP TABLE IF EXISTS test.lv_sums')\n+    client1.expect(prompt)\n     client1.send('DROP TABLE IF EXISTS test.mt')\n     client1.expect(prompt)\n     client1.send('DROP TABLE IF EXISTS test.sums')\n@@ -39,12 +41,10 @@\n     client3.expect(prompt)\n \n     client3.send(\"WATCH test.lv_sums FORMAT CSVWithNames\")\n-    client3.expect('_version')\n \n     client1.send('INSERT INTO test.sums WATCH test.lv')\n     client1.expect(r'INSERT INTO')\n-    client1.expect(r'Progress')\n-    \n+\n     client3.expect('0,1.*\\r\\n')\n \n     client2.send('INSERT INTO test.mt VALUES (1),(2),(3)')\n@@ -67,7 +67,7 @@\n     match = client1.expect('(%s)|([#\\$] )' % prompt)\n     if match.groups()[1]:\n         client1.send(client1.command)\n-        client1.expect(prompt)    \n+        client1.expect(prompt)\n \n     client2.send('DROP TABLE test.lv')\n     client2.expect(prompt)\n",
  "problem_statement": "FORMAT JSON omits a }\nWhen formatting the output of query as JSON a closing curly brace is missing in the data section.\r\n\r\n**Does it reproduce on recent release?**\r\nReproducible in 21.1.2\r\n\r\n**How to reproduce**\r\n```\r\nClickHouse client version 21.1.2.15 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 21.1.2 revision 54443.\r\n```\r\n\r\nI used the Github dataset, created the table and importet data according to (https://github-sql.github.io/explorer/#download-the-dataset)\r\n\r\nThe query (from (https://github-sql.github.io/explorer/#how-has-the-list-of-top-repositories-changed-over-the-years), added `FORMAT JSON`)\r\n\r\n```\r\nSELECT\r\n    repo AS name,\r\n    groupArrayInsertAt(toUInt32(c), toUInt64(dateDiff('month', toDate('2015-01-01'), month))) AS data\r\nFROM\r\n(\r\n    SELECT\r\n        lower(repo_name) AS repo,\r\n        toStartOfMonth(created_at) AS month,\r\n        count() AS c\r\n    FROM github_events\r\n    WHERE (event_type = 'WatchEvent') AND (toYear(created_at) >= 2015) AND (repo IN\r\n    (\r\n        SELECT lower(repo_name) AS repo\r\n        FROM github_events\r\n        WHERE (event_type = 'WatchEvent') AND (toYear(created_at) >= 2015)\r\n        GROUP BY repo\r\n        ORDER BY count() DESC\r\n        LIMIT 10\r\n    ))\r\n    GROUP BY\r\n        repo,\r\n        month\r\n)\r\nGROUP BY repo\r\nORDER BY repo ASC\r\nFORMAT JSON\r\n```\r\nreturns\r\n```\r\n{\r\n        \"meta\":\r\n        [\r\n                {\r\n                        \"name\": \"name\",\r\n                        \"type\": \"LowCardinality(String)\"\r\n                },\r\n                {\r\n                        \"name\": \"data\",\r\n                        \"type\": \"Array(UInt32)\"\r\n                }\r\n        ],\r\n\r\n        \"data\":\r\n        [\r\n                {\r\n                        \"name\": \"996icu\\/996.icu\",\r\n                        \"data\": [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,182752,143840,7373,2344,1992,1526,1128,1021,1356,1493,874,559,856,885,1044,721,1018,1147,1157,783,784,197]\r\n                },\r\n                {\r\n                        \"name\": \"facebook\\/react\",\r\n                        \"data\": [1804,2785,2404,2059,1657,1493,1681,1578,1791,1944,1881,1900,2028,1688,2425,2206,1796,1820,2166,2076,2802,2522,2383,2134,3016,2833,2995,2658,2768,2717,2979,2677,3115,3271,2904,2591,3169,2429,3380,2744,2684,9092,2845,2711,2644,2376,2545,2198,2670,2618,3261,2917,2760,2144,2325,2132,2082,2130,2058,1943,1834,1821,2033,2282,2456,2122,2547,2290,2133,2131,2097,376]\r\n                },\r\n                {\r\n                        \"name\": \"freecodecamp\\/freecodecamp\",\r\n                        \"data\": [59,37,36,29,59,1196,10700,6194,3748,7826,11147,12775,17333,19204,16711,16233,18109,20430,10388,10157,11378,13257,14436,14567,15461,14096,14661,15004,16828,13811,1195,1203,922,1194,1041,943,1034,928,1212,952,854,1062,1583,1271,1036,2424,1044,982,1155,1129,2922,3314,1609,1081,1234,1055,1186,1249,1787,1234,1136,1091,1194,1556,1621,1303,1607,1506,1486,1669,1243,289]\r\n                },\r\n                {\r\n                        \"name\": \"getify\\/you-dont-know-js\",\r\n                        \"data\": [826,2772,877,1218,987,1492,998,1123,1975,1420,1188,1528,1446,1375,1466,1528,1585,4382,2625,2233,2383,1802,2086,2064,3389,2464,3178,2969,2637,2519,2409,2223,1820,1646,1844,1804,2292,1921,2183,2360,1745,1667,1600,1861,1713,1621,1620,1431,1818,1649,2216,2119,1838,1853,1969,1960,1471,1891,1945,1918,2178,2673,1518,1445,2104,1874,1556,1591,1467,1634,1195,543]\r\n                },\r\n                {\r\n                        \"name\": \"jwasham\\/coding-interview-university\",\r\n                        \"data\": [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,54,3043,4460,1518,983,1125,1071,1036,1202,1043,5860,1835,1609,1532,2303,2344,1384,1085,1166,1334,1275,1014,1374,1103,1057,1457,1271,1412,1195,4281,5654,2275,1970,2430,1451,1988,3288,4510,6989,8344,4294,5546,6347,3860,5833,2856,736]\r\n                },\r\n                {\r\n                        \"name\": \"kamranahmedse\\/developer-roadmap\",\r\n                        \"data\": [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13979,5944,3246,1566,1075,1191,1114,961,777,644,9617,4919,2266,3231,1710,1684,2149,2038,1614,2802,1616,1632,6700,4052,2847,3153,2092,1812,2038,1879,1529,1379,1724,1637,2546,2096,2259,8192,4466,3037,5168,4938,5821,6674,5038,709]\r\n                },\r\n                {\r\n                        \"name\": \"microsoft\\/vscode\",\r\n                        \"data\": [0,0,0,0,0,0,0,0,0,0,8199,1290,1047,892,1094,1959,1106,921,871,866,1042,1122,1201,1163,1767,1951,2028,1843,1704,1483,1620,1772,1779,2692,2852,2013,2179,1965,2175,1864,2312,3130,1994,2251,2300,2508,1855,1678,1875,1971,2918,2356,2973,1990,1918,1886,1856,1771,2712,2117,1700,1585,1898,2139,2276,1955,2290,1978,1800,1864,1791,331]\r\n                },\r\n                {\r\n                        \"name\": \"sindresorhus\\/awesome\",\r\n                        \"data\": [423,263,297,360,6808,2689,1139,2882,2307,2867,2010,2375,2590,2508,2292,1637,1668,1627,2022,2340,2320,2033,1758,2034,3096,2993,2452,1963,1837,2063,1889,2131,1969,2181,4252,2258,2900,2008,2967,2143,1970,2261,1696,1838,1650,2000,1912,1632,2079,2011,2771,2526,2121,2137,2223,2099,1895,1985,1984,2455,2802,2256,3374,2282,2353,2097,1992,2177,2189,1994,4369,539]\r\n                },\r\n                {\r\n                        \"name\": \"tensorflow\\/tensorflow\",\r\n                        \"data\": [0,0,0,0,0,0,0,0,0,0,14078,1931,2162,1492,1734,2290,2780,2207,1997,2038,2360,3034,2844,3344,3881,5164,4427,3633,3829,3525,3488,3588,3398,4318,5225,4802,4230,3359,4412,3592,3535,2829,2749,2404,2550,2596,2518,2202,2276,2081,3461,2820,2627,1910,2213,1853,2064,2010,2059,1658,1370,1284,1605,1638,1693,1407,1501,1294,1257,1214,1612,229]\r\n                },\r\n                {\r\n                        \"name\": \"vuejs\\/vue\",\r\n                        \"data\": [0,0,0,0,0,0,0,0,0,1374,1562,1647,1711,1039,1416,2165,2188,1862,2219,2454,3010,3976,3497,3294,4100,4480,4622,3757,3816,3706,4193,3969,4252,4084,3677,3529,4662,3327,4601,3959,3687,11164,4032,3775,3004,2859,3237,3208,3486,2957,5579,4306,3630,3180,3248,2805,2316,2829,2422,2401,1850,2296,3061,3258,2569,2427,2727,2458,2679,1870,1856,407]\r\n\r\n        ],\r\n\r\n        \"rows\": 10,\r\n\r\n        \"statistics\":\r\n        {\r\n                \"elapsed\": 0.657104025,\r\n                \"rows_read\": 231481344,\r\n                \"bytes_read\": 1581901060\r\n        }\r\n}\r\n```\r\n\r\nNotice the missing `}` after the last name/data tuple of the returned rows\r\n\r\nSadly i was not able to reproduce with a simpler statement or built in tables.\r\n\r\n**Expected behavior**\r\nThere should be a `}`\r\n\r\n\n",
  "hints_text": "Reproduces\nIt is only related to the behaviour of interactive clickhouse-client, not to the format itself: the line was cleared to render progress.\r\nHence minor priority.",
  "created_at": "2021-04-13T20:30:41Z",
  "modified_files": [
    "programs/client/Client.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py",
    "tests/queries/0_stateless/01184_insert_values_huge_strings.sh",
    "b/tests/queries/0_stateless/01184_long_insert_values_huge_strings.sh",
    "tests/queries/0_stateless/01246_insert_into_watch_live_view.py"
  ]
}