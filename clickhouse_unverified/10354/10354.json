{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 10354,
  "instance_id": "ClickHouse__ClickHouse-10354",
  "issue_numbers": [
    "9707"
  ],
  "base_commit": "abbeb13cf064f0978e177650e03d1f9a31cadc57",
  "patch": "diff --git a/src/Processors/Formats/Impl/AvroRowInputFormat.cpp b/src/Processors/Formats/Impl/AvroRowInputFormat.cpp\nindex 52ceaf063b72..567f94d19fec 100644\n--- a/src/Processors/Formats/Impl/AvroRowInputFormat.cpp\n+++ b/src/Processors/Formats/Impl/AvroRowInputFormat.cpp\n@@ -102,10 +102,6 @@ class InputStreamReadBufferAdapter : public avro::InputStream\n     ReadBuffer & in;\n };\n \n-static void deserializeNoop(IColumn &, avro::Decoder &)\n-{\n-}\n-\n /// Insert value with conversion to the column of target type.\n template <typename T>\n static void insertNumber(IColumn & column, WhichDataType type, T value)\n@@ -441,8 +437,43 @@ AvroDeserializer::SkipFn AvroDeserializer::createSkipFn(avro::NodePtr root_node)\n     }\n }\n \n+void AvroDeserializer::createActions(const Block & header, const avro::NodePtr& node, std::string current_path)\n+{\n+    if (node->type() == avro::AVRO_RECORD)\n+    {\n+        for (size_t i = 0; i < node->leaves(); ++i)\n+        {\n+            const auto & field_node = node->leafAt(i);\n+            const auto & field_name = node->nameAt(i);\n+            auto field_path = current_path.empty() ? field_name : current_path + \".\" + field_name;\n+            createActions(header, field_node, field_path);\n+        }\n+    }\n+    else\n+    {\n+        if (header.has(current_path))\n+        {\n+            auto target_column_idx = header.getPositionByName(current_path);\n+            const auto & column = header.getByPosition(target_column_idx);\n+            try\n+            {\n+                actions.emplace_back(target_column_idx, createDeserializeFn(node, column.type));\n+            }\n+            catch (Exception & e)\n+            {\n+                e.addMessage(\"column \" + column.name);\n+                throw;\n+            }\n+            column_found[target_column_idx] = true;\n+        }\n+        else\n+        {\n+            actions.emplace_back(createSkipFn(node));\n+        }\n+    }\n+}\n \n-AvroDeserializer::AvroDeserializer(const ColumnsWithTypeAndName & columns, avro::ValidSchema schema)\n+AvroDeserializer::AvroDeserializer(const Block & header, avro::ValidSchema schema)\n {\n     const auto & schema_root = schema.root();\n     if (schema_root->type() != avro::AVRO_RECORD)\n@@ -450,48 +481,23 @@ AvroDeserializer::AvroDeserializer(const ColumnsWithTypeAndName & columns, avro:\n         throw Exception(\"Root schema must be a record\", ErrorCodes::TYPE_MISMATCH);\n     }\n \n-    field_mapping.resize(schema_root->leaves(), -1);\n-\n-    for (size_t i = 0; i < schema_root->leaves(); ++i)\n-    {\n-        skip_fns.push_back(createSkipFn(schema_root->leafAt(i)));\n-        deserialize_fns.push_back(&deserializeNoop);\n-    }\n+    column_found.resize(header.columns());\n+    createActions(header, schema_root);\n \n-    for (size_t i = 0; i < columns.size(); ++i)\n+    for (size_t i = 0; i < header.columns(); ++i)\n     {\n-        const auto & column = columns[i];\n-        size_t field_index = 0;\n-        if (!schema_root->nameIndex(column.name, field_index))\n+        if (!column_found[i])\n         {\n-            throw Exception(\"Field \" + column.name + \" not found in Avro schema\", ErrorCodes::THERE_IS_NO_COLUMN);\n+            throw Exception(\"Field \" + header.getByPosition(i).name + \" not found in Avro schema\", ErrorCodes::THERE_IS_NO_COLUMN);\n         }\n-        auto field_schema = schema_root->leafAt(field_index);\n-        try\n-        {\n-            deserialize_fns[field_index] = createDeserializeFn(field_schema, column.type);\n-        }\n-        catch (Exception & e)\n-        {\n-            e.addMessage(\"column \" + column.name);\n-            throw;\n-        }\n-        field_mapping[field_index] = i;\n     }\n }\n \n void AvroDeserializer::deserializeRow(MutableColumns & columns, avro::Decoder & decoder) const\n {\n-    for (size_t i = 0; i < field_mapping.size(); i++)\n+    for (const auto& action : actions)\n     {\n-        if (field_mapping[i] >= 0)\n-        {\n-            deserialize_fns[i](*columns[field_mapping[i]], decoder);\n-        }\n-        else\n-        {\n-            skip_fns[i](decoder);\n-        }\n+        action.execute(columns, decoder);\n     }\n }\n \n@@ -499,7 +505,7 @@ void AvroDeserializer::deserializeRow(MutableColumns & columns, avro::Decoder &\n AvroRowInputFormat::AvroRowInputFormat(const Block & header_, ReadBuffer & in_, Params params_)\n     : IRowInputFormat(header_, in_, params_)\n     , file_reader(std::make_unique<InputStreamReadBufferAdapter>(in_))\n-    , deserializer(header_.getColumnsWithTypeAndName(), file_reader.dataSchema())\n+    , deserializer(output.getHeader(), file_reader.dataSchema())\n {\n     file_reader.init();\n }\n@@ -626,8 +632,7 @@ static uint32_t readConfluentSchemaId(ReadBuffer & in)\n \n AvroConfluentRowInputFormat::AvroConfluentRowInputFormat(\n     const Block & header_, ReadBuffer & in_, Params params_, const FormatSettings & format_settings_)\n-    : IRowInputFormat(header_.cloneEmpty(), in_, params_)\n-    , header_columns(header_.getColumnsWithTypeAndName())\n+    : IRowInputFormat(header_, in_, params_)\n     , schema_registry(getConfluentSchemaRegistry(format_settings_))\n     , input_stream(std::make_unique<InputStreamReadBufferAdapter>(in))\n     , decoder(avro::binaryDecoder())\n@@ -655,7 +660,7 @@ const AvroDeserializer & AvroConfluentRowInputFormat::getOrCreateDeserializer(Sc\n     if (it == deserializer_cache.end())\n     {\n         auto schema = schema_registry->getSchema(schema_id);\n-        AvroDeserializer deserializer(header_columns, schema);\n+        AvroDeserializer deserializer(output.getHeader(), schema);\n         it = deserializer_cache.emplace(schema_id, deserializer).first;\n     }\n     return it->second;\ndiff --git a/src/Processors/Formats/Impl/AvroRowInputFormat.h b/src/Processors/Formats/Impl/AvroRowInputFormat.h\nindex b54c8ecede5a..6245d704e74a 100644\n--- a/src/Processors/Formats/Impl/AvroRowInputFormat.h\n+++ b/src/Processors/Formats/Impl/AvroRowInputFormat.h\n@@ -22,7 +22,7 @@ namespace DB\n class AvroDeserializer\n {\n public:\n-    AvroDeserializer(const ColumnsWithTypeAndName & columns, avro::ValidSchema schema);\n+    AvroDeserializer(const Block & header, avro::ValidSchema schema);\n     void deserializeRow(MutableColumns & columns, avro::Decoder & decoder) const;\n \n private:\n@@ -31,15 +31,46 @@ class AvroDeserializer\n     static DeserializeFn createDeserializeFn(avro::NodePtr root_node, DataTypePtr target_type);\n     SkipFn createSkipFn(avro::NodePtr root_node);\n \n-    /// Map from field index in Avro schema to column number in block header. Or -1 if there is no corresponding column.\n-    std::vector<int> field_mapping;\n-\n-    /// How to skip the corresponding field in Avro schema.\n-    std::vector<SkipFn> skip_fns;\n-\n-    /// How to deserialize the corresponding field in Avro schema.\n-    std::vector<DeserializeFn> deserialize_fns;\n-\n+    struct Action\n+    {\n+        enum Type { Deserialize, Skip };\n+        Type type;\n+        /// Deserialize\n+        int target_column_idx;\n+        DeserializeFn deserialize_fn;\n+        /// Skip\n+        SkipFn skip_fn;\n+\n+        Action(int target_column_idx_, DeserializeFn deserialize_fn_)\n+            : type(Deserialize)\n+            , target_column_idx(target_column_idx_)\n+            , deserialize_fn(deserialize_fn_) {}\n+\n+        Action(SkipFn skip_fn_)\n+            : type(Skip)\n+            , skip_fn(skip_fn_) {}\n+\n+        void execute(MutableColumns & columns, avro::Decoder & decoder) const\n+        {\n+            switch (type)\n+            {\n+                case Deserialize:\n+                    deserialize_fn(*columns[target_column_idx], decoder);\n+                    break;\n+                case Skip:\n+                    skip_fn(decoder);\n+                    break;\n+            }\n+        }\n+    };\n+\n+    /// Populate actions by recursively traversing root schema\n+    void createActions(const Block & header, const avro::NodePtr& node, std::string current_path = \"\");\n+\n+    /// Bitmap of columns found in Avro schema\n+    std::vector<bool> column_found;\n+    /// Deserialize/Skip actions for a row\n+    std::vector<Action> actions;\n     /// Map from name of named Avro type (record, enum, fixed) to SkipFn.\n     /// This is to avoid infinite recursion when  Avro schema contains self-references. e.g. LinkedList\n     std::map<avro::Name, SkipFn> symbolic_skip_fn_map;\n@@ -73,7 +104,6 @@ class AvroConfluentRowInputFormat : public IRowInputFormat\n \n     class SchemaRegistry;\n private:\n-    const ColumnsWithTypeAndName header_columns;\n     std::shared_ptr<SchemaRegistry> schema_registry;\n     using SchemaId = uint32_t;\n     std::unordered_map<SchemaId, AvroDeserializer> deserializer_cache;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01060_avro.reference b/tests/queries/0_stateless/01060_avro.reference\nindex a21e7a3a1012..0550967a224b 100644\n--- a/tests/queries/0_stateless/01060_avro.reference\n+++ b/tests/queries/0_stateless/01060_avro.reference\n@@ -19,6 +19,10 @@\n = references\n \"a1\",\"c1\"\n \"a2\",\"c2\"\n+= nested\n+1,\"b1\",2.2,2.3,\"c3\"\n+2.3,\"b1\",1,\"c3\"\n+not found\n = compression\n 1000\n 1000\ndiff --git a/tests/queries/0_stateless/01060_avro.sh b/tests/queries/0_stateless/01060_avro.sh\nindex 15e97abfa520..a64b28847315 100755\n--- a/tests/queries/0_stateless/01060_avro.sh\n+++ b/tests/queries/0_stateless/01060_avro.sh\n@@ -27,6 +27,11 @@ cat $DATA_DIR/logical_types.avro | ${CLICKHOUSE_LOCAL} --input-format Avro --out\n echo = references\n cat $DATA_DIR/references.avro | ${CLICKHOUSE_LOCAL} --input-format Avro --output-format CSV -S \"a String, c String\" -q 'select * from table'\n \n+echo = nested\n+cat $DATA_DIR/nested.avro | ${CLICKHOUSE_LOCAL} --input-format Avro --output-format CSV -S 'a Int64, \"b.a\" String, \"b.b\" Double, \"b.c\" Double, c String' -q 'select * from table'\n+cat $DATA_DIR/nested.avro | ${CLICKHOUSE_LOCAL} --input-format Avro --output-format CSV -S '\"b.c\" Double, \"b.a\" String, a Int64, c String' -q 'select * from table'\n+cat $DATA_DIR/nested.avro | ${CLICKHOUSE_LOCAL} --input-format Avro --output-format CSV -S '\"b\" Double' -q 'select * from table' 2>&1 | grep -i 'not found' -o\n+\n echo = compression\n cat $DATA_DIR/simple.null.avro | ${CLICKHOUSE_LOCAL} --input-format Avro --output-format CSV -S 'a Int64' -q 'select count() from table'\n cat $DATA_DIR/simple.deflate.avro | ${CLICKHOUSE_LOCAL} --input-format Avro --output-format CSV -S 'a Int64' -q 'select count() from table'\n@@ -68,4 +73,4 @@ ${CLICKHOUSE_LOCAL} -q \"select toInt64(number) as a from numbers(0)  format Avro\n ${CLICKHOUSE_LOCAL} -q \"select toInt64(number) as a from numbers(1000)  format Avro\" | ${CLICKHOUSE_LOCAL} --input-format Avro --output-format CSV -S \"$S4\" -q 'select count() from table'\n \n # type supported via conversion\n-${CLICKHOUSE_LOCAL}  -q \"select toInt16(123) as a format Avro\" | wc -c\n\\ No newline at end of file\n+${CLICKHOUSE_LOCAL}  -q \"select toInt16(123) as a format Avro\" | wc -c | tr -d ' '\n\\ No newline at end of file\ndiff --git a/tests/queries/0_stateless/data_avro/generate_avro.sh b/tests/queries/0_stateless/data_avro/generate_avro.sh\nindex 6ec26efc0492..b6ec75ad4dd0 100755\n--- a/tests/queries/0_stateless/data_avro/generate_avro.sh\n+++ b/tests/queries/0_stateless/data_avro/generate_avro.sh\n@@ -8,6 +8,7 @@ avro-tools fromjson  --schema-file complex.avsc complex.json > complex.avro\n avro-tools fromjson  --schema-file logical_types.avsc logical_types.json > logical_types.avro\n avro-tools fromjson  --schema-file empty.avsc empty.json > empty.avro\n avro-tools fromjson  --schema-file references.avsc references.json >  references.avro\n+avro-tools fromjson  --schema-file nested.avsc nested.json > nested.avro\n \n #compression\n avro-tools fromjson --codec null  --schema-file simple.avsc simple.json > simple.null.avro\ndiff --git a/tests/queries/0_stateless/data_avro/nested.avro b/tests/queries/0_stateless/data_avro/nested.avro\nnew file mode 100644\nindex 000000000000..1415c45d3282\nBinary files /dev/null and b/tests/queries/0_stateless/data_avro/nested.avro differ\ndiff --git a/tests/queries/0_stateless/data_avro/nested.avsc b/tests/queries/0_stateless/data_avro/nested.avsc\nnew file mode 100644\nindex 000000000000..966dc6defb3e\n--- /dev/null\n+++ b/tests/queries/0_stateless/data_avro/nested.avsc\n@@ -0,0 +1,17 @@\n+{\n+    \"type\": \"record\",\n+    \"name\": \"main\",\n+    \"fields\": [\n+        {\"name\": \"a\", \"type\": \"long\"},\n+        {\"name\": \"b\", \"type\": {\n+            \"type\": \"record\",\n+            \"name\": \"sub1\",\n+            \"fields\": [\n+                {\"name\": \"a\", \"type\": \"string\"},\n+                {\"name\": \"b\", \"type\": \"double\"},\n+                {\"name\": \"c\", \"type\": \"double\"}\n+            ]\n+        }},\n+        {\"name\": \"c\", \"type\": \"string\"}\n+    ]\n+  }\n\\ No newline at end of file\ndiff --git a/tests/queries/0_stateless/data_avro/nested.json b/tests/queries/0_stateless/data_avro/nested.json\nnew file mode 100644\nindex 000000000000..63a7bc40e4bd\n--- /dev/null\n+++ b/tests/queries/0_stateless/data_avro/nested.json\n@@ -0,0 +1,1 @@\n+{\"a\":1, \"b\": {\"a\":\"b1\", \"b\": 2.2, \"c\": 2.3}, \"c\": \"c3\"}\n",
  "problem_statement": "Avro nested\nAvro and AvroConfluent formats (20.3.2.1) are a really nice feature (thanks!!). \r\n\r\nCurrent implementation (AFAIK) **doesn't allow reading nested structures**.\r\n\r\nMost Avro messages in real use-cases (i.e. CDC through Debezium) include nested structures, so feeding those messages into clickhouse will require some kind of pre-processing to flatten them.\r\n\r\nDebezium (i.e.) produces (default config) messages of this kind:\r\n```\r\n{\r\n\tbefore: {\r\n\t\t// table fields before\r\n\t},\r\n\tafter: {\r\n\t\t// table fields after\r\n\t},\r\n\tsource: {\r\n\t\t// metadata\r\n\t}\r\n}\r\n```\r\n\r\n**It would be really nice being able to access nested fields directly like before.fieldA or after.fieldB** (suggestion).\r\n\r\nThere are a lot of issues/questions related to the ability to read nested structures from Kafka in other formats (#4533, #8577, #4533, #8124, etc...).\r\n\r\nOpinions/feedback/alternatives?\n",
  "hints_text": "> are a really nice feature (thanks!!).\r\n\r\nkudos to @oandrew :) I don't have too much experience with Avro, @oandrew what do you think about adding support for nested? \r\n\nSounds good to me, I will try to add it sometime soon (probably this/next week).\nInspiration: [catj](https://github.com/soheilpro/catj)\nhttps://github.com/tomnomnom/gron ?",
  "created_at": "2020-04-18T21:36:19Z"
}