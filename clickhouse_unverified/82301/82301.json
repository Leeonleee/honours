{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 82301,
  "instance_id": "ClickHouse__ClickHouse-82301",
  "issue_numbers": [
    "81272"
  ],
  "base_commit": "fbdecd47d8f86a13524a5d0d65bb5daaf1a22e3c",
  "patch": "diff --git a/src/Databases/DataLake/GlueCatalog.cpp b/src/Databases/DataLake/GlueCatalog.cpp\nindex 59d0135fd790..d30b7c6597c0 100644\n--- a/src/Databases/DataLake/GlueCatalog.cpp\n+++ b/src/Databases/DataLake/GlueCatalog.cpp\n@@ -288,6 +288,13 @@ void GlueCatalog::getTableMetadata(\n             {\n                 const auto column_params = column.GetParameters();\n                 bool can_be_nullable = column_params.contains(\"iceberg.field.optional\") && column_params.at(\"iceberg.field.optional\") == \"true\";\n+\n+                /// Skip field if it's not \"current\" (for example Renamed). No idea how someone can utilize \"non current fields\" but for some reason\n+                /// they are returned by Glue API. So if you do \"RENAME COLUMN a to new_a\" glue will return two fields: a and new_a.\n+                /// And a will be marked as \"non current\" field.\n+                if (column_params.contains(\"iceberg.field.current\") && column_params.at(\"iceberg.field.current\") == \"false\")\n+                    continue;\n+\n                 schema.push_back({column.GetName(), getType(column.GetType(), can_be_nullable)});\n             }\n             result.setSchema(schema);\n",
  "test_patch": "diff --git a/tests/integration/test_database_glue/test.py b/tests/integration/test_database_glue/test.py\nindex 7680d9a10ff8..56ddd1c0bff3 100644\n--- a/tests/integration/test_database_glue/test.py\n+++ b/tests/integration/test_database_glue/test.py\n@@ -345,3 +345,43 @@ def test_hide_sensitive_info(started_cluster):\n     )\n     assert \"SECRET_1\" not in node.query(f\"SHOW CREATE DATABASE {CATALOG_NAME}\")\n     assert \"SECRET_2\" not in node.query(f\"SHOW CREATE DATABASE {CATALOG_NAME}\")\n+\n+\n+def test_select_after_rename(started_cluster):\n+    node = started_cluster.instances[\"node1\"]\n+\n+    test_ref = f\"test_list_tables_{uuid.uuid4()}\"\n+    table_name = f\"{test_ref}_table\"\n+    root_namespace = f\"{test_ref}_namespace\"\n+\n+    namespaces_to_create = [\n+        root_namespace,\n+        f\"{root_namespace}_A\",\n+        f\"{root_namespace}_B\",\n+        f\"{root_namespace}_C\",\n+    ]\n+\n+    catalog = load_catalog_impl(started_cluster)\n+\n+    for namespace in namespaces_to_create:\n+        catalog.create_namespace(namespace)\n+        assert len(catalog.list_tables(namespace)) == 0\n+\n+    for namespace in namespaces_to_create:\n+        table = create_table(catalog, namespace, table_name)\n+\n+        num_rows = 10\n+        df = generate_arrow_data(num_rows)\n+        table.append(df)\n+\n+        create_clickhouse_glue_database(started_cluster, node, CATALOG_NAME)\n+\n+        expected = DEFAULT_CREATE_TABLE.format(CATALOG_NAME, namespace, table_name)\n+        assert expected == node.query(\n+            f\"SHOW CREATE TABLE {CATALOG_NAME}.`{namespace}.{table_name}`\"\n+        )\n+\n+        with table.update_schema() as update:\n+            update.rename_column(\"bid\", \"new_bid\")\n+\n+        print(node.query(f\"SELECT * FROM {CATALOG_NAME}.`{namespace}.{table_name}`\"))\n",
  "problem_statement": "Can not read iceberg table with glue catalog after schema evolution (rename column, delete column)\n### Company or project name\n\n_No response_\n\n### Describe what's wrong\n\nI perform different schema evolution actions like rename column, delete column etc.\n\nAfter rename operation (RENAME COLUMN boolean_col TO new_boolean_col)\n```sql\ndescribe table iceberg_database.`iceberg.table`\n```\nI see both column in output.\n```\nnew_boolean_col\tNullable(Bool)  \nlong_col\tNullable(Int64)  \ndouble_col\tNullable(Float64)  \nstring_col\tNullable(String)  \ndate_col\tNullable(Date)  \nboolean_col\tNullable(Bool)  \n```\n\nAnd when I try to select from the table:\n```sql\nSELECT * FROM iceberg_database.`iceberg.table` ORDER BY tuple(*) FORMAT TabSeparated\n```\nI get:\n`\nCode: 10. DB::Exception: Received from localhost:9000. DB::Exception: Not found column or subcolumn boolean_col in block. There are only columns: new_boolean_col, long_col, double_col, string_col, date_col: While executing IcebergS3(iceberg_database.`iceberg.table`)Source. (NOT_FOUND_COLUMN_IN_BLOCK)\n`\n\n### Does it reproduce on the most recent release?\n\nYes\n\n### How to reproduce\n\n1. Create database DataLakeCatalog with type=glue\n2. Create iceberg table\n3. Perform schema evolution action\n4. Read from the table\n\nI was using pyiceberg to create iceberg table and change schema.\nAs glue catalog I used localstack.\n\n\n\n### Expected behavior\n\nSuccessful select.\n\n### Error message and/or stacktrace\n\nAfter deleting column `double_col`:\n```\nCode: 10. DB::Exception: Received from localhost:9000. DB::Exception: Not found column or subcolumn double_col in block. There are only columns: boolean_col, long_col, string_col, date_col: While executing IcebergS3(iceberg_database_0c9ed3d9_4133_11f0_9df3_c76e50725ea7.`iceberg_0c9ed3da_4133_11f0_9df3_c76e50725ea7.table_0c9ed3db_4133_11f0_9df3_c76e50725ea7`)Source.\n```\nDescribe table query shows deleted row.\n\n_______________________________________\n\nLooks like `add column`, `move column`, `update column type` actions work as expected.\n\n### Additional context\n\nI checked that I can correctly read table with PyIceberg and Spark to eliminate localstack as cause of a bug.\n\nWhen I was using rest catalog and PyIceberg, I was able to read tables after schema evolution.\n",
  "hints_text": "I was able to reproduce it with aws glue.",
  "created_at": "2025-06-20T15:46:33Z"
}