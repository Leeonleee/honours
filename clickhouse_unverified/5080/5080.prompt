You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Data get lost on heavy load via KafkaEngine
We have created Yandex tank scenario in order to test the database on heavy load.
We use **KafkaEngine** to populate the database. The problem is that the database starts loosing data at 100rps.

**How to reproduce**
* Create kafka group named _labeling__test_shard_localhost_
* Create kafka topic named _labeling__all_
* Create the database schema defined in **DB_SCHEMA.txt**
* Install **Yandex tank** 
* Use tank python script and configution files attached to this issue
* Run tank via the following command: 
_sudo docker run     -v $(pwd):/var/loadtest     -v $SSH_AUTH_SOCK:/ssh-agent -e SSH_AUTH_SOCK=/ssh-agent     --net host     -it direvius/yandex-tank -c ch_kafka_conf.yaml_

**Expected behavior**
The tank executes 100 requests, 30000 records each. So you should end up having 3000000 records via select count(), but you'll get less due to data loss.
To make sure that Kafka works as expected we used standard Kafka console consumer and it consumes exactly 3000000 messages.

**Error message and/or stacktrace**
There is nothing in server log file that corresponds to this issue.

**Additional context**
We do use the following versions of SW:
* Kafka 2.11
* Clickhouse 19.3.4 and the latest 

[DB_SCHEMA.txt](https://github.com/yandex/ClickHouse/files/2991319/DB_SCHEMA.txt)
[ya_tank.zip](https://github.com/yandex/ClickHouse/files/2991320/ya_tank.zip)
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
