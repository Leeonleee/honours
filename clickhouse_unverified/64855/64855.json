{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 64855,
  "instance_id": "ClickHouse__ClickHouse-64855",
  "issue_numbers": [
    "64611"
  ],
  "base_commit": "5251febf035c002bcbd87b157f281dd65fecb1c3",
  "patch": "diff --git a/src/Interpreters/ActionsDAG.cpp b/src/Interpreters/ActionsDAG.cpp\nindex cfccc835d29a..840aff9ebfbc 100644\n--- a/src/Interpreters/ActionsDAG.cpp\n+++ b/src/Interpreters/ActionsDAG.cpp\n@@ -1704,7 +1704,7 @@ void ActionsDAG::mergeNodes(ActionsDAG && second, NodeRawConstPtrs * out_outputs\n     }\n }\n \n-ActionsDAG::SplitResult ActionsDAG::split(std::unordered_set<const Node *> split_nodes, bool create_split_nodes_mapping) const\n+ActionsDAG::SplitResult ActionsDAG::split(std::unordered_set<const Node *> split_nodes, bool create_split_nodes_mapping, bool avoid_duplicate_inputs) const\n {\n     /// Split DAG into two parts.\n     /// (first_nodes, first_outputs) is a part which will have split_list in result.\n@@ -1718,6 +1718,14 @@ ActionsDAG::SplitResult ActionsDAG::split(std::unordered_set<const Node *> split\n     /// List of nodes from current actions which are not inputs, but will be in second part.\n     NodeRawConstPtrs new_inputs;\n \n+    /// Avoid new inputs to have the same name as existing inputs.\n+    /// It's allowed for DAG but may break Block invariant 'columns with identical name must have identical structure'.\n+    std::unordered_set<std::string_view> duplicate_inputs;\n+    size_t duplicate_counter = 0;\n+    if (avoid_duplicate_inputs)\n+        for (const auto * input : inputs)\n+            duplicate_inputs.insert(input->result_name);\n+\n     struct Frame\n     {\n         const Node * node = nullptr;\n@@ -1830,7 +1838,8 @@ ActionsDAG::SplitResult ActionsDAG::split(std::unordered_set<const Node *> split\n                                 input_node.result_name = child->result_name;\n                                 child_data.to_second = &second_nodes.emplace_back(std::move(input_node));\n \n-                                new_inputs.push_back(child);\n+                                if (child->type != ActionType::INPUT)\n+                                    new_inputs.push_back(child);\n                             }\n                         }\n \n@@ -1886,7 +1895,32 @@ ActionsDAG::SplitResult ActionsDAG::split(std::unordered_set<const Node *> split\n \n     for (const auto * input : new_inputs)\n     {\n-        const auto & cur = data[input];\n+        auto & cur = data[input];\n+\n+        if (avoid_duplicate_inputs)\n+        {\n+            bool is_name_updated = false;\n+            while (!duplicate_inputs.insert(cur.to_first->result_name).second)\n+            {\n+                is_name_updated = true;\n+                cur.to_first->result_name = fmt::format(\"{}_{}\", input->result_name, duplicate_counter);\n+                ++duplicate_counter;\n+            }\n+\n+            if (is_name_updated)\n+            {\n+                Node input_node;\n+                input_node.type = ActionType::INPUT;\n+                input_node.result_type = cur.to_first->result_type;\n+                input_node.result_name = cur.to_first->result_name;\n+\n+                auto * new_input = &second_nodes.emplace_back(std::move(input_node));\n+                cur.to_second->type = ActionType::ALIAS;\n+                cur.to_second->children = {new_input};\n+                cur.to_second = new_input;\n+            }\n+        }\n+\n         second_inputs.push_back(cur.to_second);\n         first_outputs.push_back(cur.to_first);\n     }\ndiff --git a/src/Interpreters/ActionsDAG.h b/src/Interpreters/ActionsDAG.h\nindex 8c0e3f0e5763..7c6753ac9dea 100644\n--- a/src/Interpreters/ActionsDAG.h\n+++ b/src/Interpreters/ActionsDAG.h\n@@ -343,7 +343,7 @@ class ActionsDAG\n     ///   initial DAG    : (a, b, c, d, e) -> (w, x, y, z)  | 1 a 2 b 3 c 4 d 5 e 6      ->  1 2 3 4 5 6 w x y z\n     ///   split (first)  : (a, c, d) -> (i, j, k, w, y)     | 1 a 2 b 3 c 4 d 5 e 6      ->  1 2 b 3 4 5 e 6 i j k w y\n     ///   split (second) : (i, j, k, y, b, e) -> (x, y, z)  | 1 2 b 3 4 5 e 6 i j k w y  ->  1 2 3 4 5 6 w x y z\n-    SplitResult split(std::unordered_set<const Node *> split_nodes, bool create_split_nodes_mapping = false) const;\n+    SplitResult split(std::unordered_set<const Node *> split_nodes, bool create_split_nodes_mapping = false, bool avoid_duplicate_inputs = false) const;\n \n     /// Splits actions into two parts. Returned first half may be swapped with ARRAY JOIN.\n     SplitResult splitActionsBeforeArrayJoin(const NameSet & array_joined_columns) const;\ndiff --git a/src/Processors/QueryPlan/Optimizations/optimizePrewhere.cpp b/src/Processors/QueryPlan/Optimizations/optimizePrewhere.cpp\nindex fbd9b451ddc6..74da7b8190fc 100644\n--- a/src/Processors/QueryPlan/Optimizations/optimizePrewhere.cpp\n+++ b/src/Processors/QueryPlan/Optimizations/optimizePrewhere.cpp\n@@ -118,7 +118,7 @@ void optimizePrewhere(Stack & stack, QueryPlan::Nodes &)\n         outputs.resize(size);\n     }\n \n-    auto split_result = filter_step->getExpression()->split(optimize_result.prewhere_nodes, true);\n+    auto split_result = filter_step->getExpression()->split(optimize_result.prewhere_nodes, true, true);\n \n     /// This is the leak of abstraction.\n     /// Splited actions may have inputs which are needed only for PREWHERE.\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03166_mv_prewhere_duplicating_name_bug.reference b/tests/queries/0_stateless/03166_mv_prewhere_duplicating_name_bug.reference\nnew file mode 100644\nindex 000000000000..b50fdcee2090\n--- /dev/null\n+++ b/tests/queries/0_stateless/03166_mv_prewhere_duplicating_name_bug.reference\n@@ -0,0 +1,2 @@\n+a\tb\n+a\tb\ndiff --git a/tests/queries/0_stateless/03166_mv_prewhere_duplicating_name_bug.sql b/tests/queries/0_stateless/03166_mv_prewhere_duplicating_name_bug.sql\nnew file mode 100644\nindex 000000000000..e32d23920dd4\n--- /dev/null\n+++ b/tests/queries/0_stateless/03166_mv_prewhere_duplicating_name_bug.sql\n@@ -0,0 +1,7 @@\n+create table src (x Int64) engine = Log;\n+create table dst (s String, lc LowCardinality(String)) engine MergeTree order by s;\n+create materialized view mv to dst (s String, lc String) as select 'a' as s, toLowCardinality('b') as lc from src;\n+insert into src values (1);\n+\n+select s, lc from mv where not ignore(lc) settings allow_experimental_analyzer=0;\n+select s, lc from mv where not ignore(lc) settings allow_experimental_analyzer=1;\n",
  "problem_statement": "AMBIGUOUS_COLUMN_NAME when reading from MV with mismatching schema\nRepro:\r\n\r\n```\r\ncreate table src (x Int64) engine Memory;\r\ncreate table dst (s String, lc LowCardinality(String)) engine MergeTree order by s;\r\ncreate materialized view mv to dst (s String, lc String) as select '' as s, toLowCardinality('') as lc from src;\r\ninsert into src values (1);\r\nselect s, lc from mv where ignore(lc) settings allow_experimental_analyzer=0;\r\n```\r\n(Notice that column `lc` has different type in the materialized view vs its destination table `dst`. This is supposed to be allowed. Reading from the MV automatically converts from dst types to mv types, see `makeConvertingActions()` call in `StorageMaterializedView::read()`.)\r\n\r\nError:\r\n```\r\nCode: 352. DB::Exception: Block structure mismatch in (columns with identical name must have identical structure) stream: different types:\r\nlc String String(size = 0)\r\nlc LowCardinality(String) ColumnLowCardinality(size = 0, UInt8(size = 0), ColumnUnique(size = 1, String(size = 1))). (AMBIGUOUS_COLUMN_NAME), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. /home/ubuntu/ClickHouse/contrib/llvm-project/libcxx/include/exception:141: std::exception::capture() @ 0x000000000aa2c262\r\n1. /home/ubuntu/ClickHouse/contrib/llvm-project/libcxx/include/exception:116: std::exception::exception[abi:v15000]() @ 0x000000000aa2c22d\r\n2. /home/ubuntu/ClickHouse/base/poco/Foundation/src/Exception.cpp:27: Poco::Exception::Exception(String const&, int) @ 0x0000000022a22100\r\n3. /home/ubuntu/ClickHouse/src/Common/Exception.cpp:99: DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x0000000012d295ee\r\n4. /home/ubuntu/ClickHouse/src/Common/Exception.h:95: DB::Exception::Exception(String&&, int, bool) @ 0x000000000aa221aa\r\n5. /home/ubuntu/ClickHouse/src/Common/Exception.h:68: DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000aa1f9a9\r\n6. /home/ubuntu/ClickHouse/src/Common/Exception.h:113: DB::Exception::Exception<std::basic_string_view<char, std::char_traits<char>>&, String, String>(int, FormatStringHelperImpl<std::type_identity<std::basic_string_view<char, std::char_traits<char>>&>::type, std::type_identity<String>::type, std::type_identit\r\ny<String>::type>, std::basic_string_view<char, std::char_traits<char>>&, String&&, String&&) @ 0x000000001992703b\r\n7. /home/ubuntu/ClickHouse/src/Core/Block.cpp:36: void DB::onError<void, std::basic_string_view<char, std::char_traits<char>>&, String, String>(int, FormatStringHelperImpl<std::type_identity<std::basic_string_view<char, std::char_traits<char>>&>::type, std::type_identity<String>::type, std::type_identity<Strin\r\ng>::type>, std::basic_string_view<char, std::char_traits<char>>&, String&&, String&&) @ 0x000000001991f46f\r\n8. /home/ubuntu/ClickHouse/src/Core/Block.cpp:52: void DB::checkColumnStructure<void>(DB::ColumnWithTypeAndName const&, DB::ColumnWithTypeAndName const&, std::basic_string_view<char, std::char_traits<char>>, bool, int) @ 0x000000001991959b\r\n9. /home/ubuntu/ClickHouse/src/Core/Block.cpp:0: DB::Block::insert(DB::ColumnWithTypeAndName) @ 0x0000000019919f69\r\n10. /home/ubuntu/ClickHouse/src/Interpreters/ActionsDAG.cpp:759: DB::ActionsDAG::updateHeader(DB::Block const&) const @ 0x000000001a4340d1\r\n11. /home/ubuntu/ClickHouse/src/Processors/QueryPlan/SourceStepWithFilter.cpp:39: DB::SourceStepWithFilter::applyPrewhereActions(DB::Block, std::shared_ptr<DB::PrewhereInfo> const&) @ 0x000000001ddef878\r\n12. /home/ubuntu/ClickHouse/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp:177: DB::MergeTreeSelectProcessor::transformHeader(DB::Block, std::shared_ptr<DB::PrewhereInfo> const&) @ 0x000000001ce78aa3\r\n13. /home/ubuntu/ClickHouse/src/Processors/QueryPlan/ReadFromMergeTree.cpp:1775: DB::ReadFromMergeTree::updatePrewhereInfo(std::shared_ptr<DB::PrewhereInfo> const&) @ 0x000000001dd35733\r\n14. /home/ubuntu/ClickHouse/src/Processors/QueryPlan/Optimizations/optimizePrewhere.cpp:174: DB::QueryPlanOptimizations::optimizePrewhere(std::vector<DB::QueryPlanOptimizations::Frame, std::allocator<DB::QueryPlanOptimizations::Frame>>&, std::list<DB::QueryPlan::Node, std::allocator<DB::QueryPlan::Node>>&) @ 0\r\nx000000001de0ccb1\r\n15. /home/ubuntu/ClickHouse/src/Processors/QueryPlan/Optimizations/optimizeTree.cpp:123: DB::QueryPlanOptimizations::optimizeTreeSecondPass(DB::QueryPlanOptimizationSettings const&, DB::QueryPlan::Node&, std::list<DB::QueryPlan::Node, std::allocator<DB::QueryPlan::Node>>&) @ 0x000000001de04c33\r\n16. /home/ubuntu/ClickHouse/src/Processors/QueryPlan/QueryPlan.cpp:506: DB::QueryPlan::optimize(DB::QueryPlanOptimizationSettings const&) @ 0x000000001dd0a5dd\r\n17. /home/ubuntu/ClickHouse/src/Processors/QueryPlan/QueryPlan.cpp:169: DB::QueryPlan::buildQueryPipeline(DB::QueryPlanOptimizationSettings const&, DB::BuildQueryPipelineSettings const&) @ 0x000000001dd0a0f7\r\n18. /home/ubuntu/ClickHouse/src/Interpreters/InterpreterSelectWithUnionQuery.cpp:380: DB::InterpreterSelectWithUnionQuery::execute() @ 0x000000001b61270b\r\n19. /home/ubuntu/ClickHouse/src/Interpreters/executeQuery.cpp:1208: DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*) @ 0x000000001bbc0e17\r\n20. /home/ubuntu/ClickHouse/src/Interpreters/executeQuery.cpp:1375: DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x000000001bbbb30a\r\n21. /home/ubuntu/ClickHouse/src/Server/TCPHandler.cpp:523: DB::TCPHandler::runImpl() @ 0x000000001d4417d9\r\n22. /home/ubuntu/ClickHouse/src/Server/TCPHandler.cpp:2342: DB::TCPHandler::run() @ 0x000000001d456abf\r\n23. /home/ubuntu/ClickHouse/base/poco/Net/src/TCPServerConnection.cpp:43: Poco::Net::TCPServerConnection::start() @ 0x00000000228ca9b9\r\n24. /home/ubuntu/ClickHouse/base/poco/Net/src/TCPServerDispatcher.cpp:115: Poco::Net::TCPServerDispatcher::run() @ 0x00000000228cb208\r\n25. /home/ubuntu/ClickHouse/base/poco/Foundation/src/ThreadPool.cpp:188: Poco::PooledThread::run() @ 0x0000000022aa2074\r\n26. /home/ubuntu/ClickHouse/base/poco/Foundation/src/Thread.cpp:46: Poco::(anonymous namespace)::RunnableHolder::run() @ 0x0000000022a9ee1a\r\n27. /home/ubuntu/ClickHouse/base/poco/Foundation/src/Thread_POSIX.cpp:335: Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000022a9db5e\r\n28. ? @ 0x00007ffff7c94ac3\r\n29. ? @ 0x00007ffff7d26850\r\n```\r\n\r\nDoesn't fail with `optimize_move_to_prewhere=0`\r\n\r\nProbably broken by https://github.com/ClickHouse/ClickHouse/pull/58554\r\n\r\nPresumably what happens is that the WHERE expression, which would normally run after the LowCardinality -> String conversion, gets moved to PREWHERE, where it would run before the LowCardinality -> String conversion, on different data type, and the planning gets confused by that in some way.\n",
  "hints_text": "",
  "created_at": "2024-06-05T15:55:35Z"
}