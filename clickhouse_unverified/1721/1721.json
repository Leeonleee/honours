{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 1721,
  "instance_id": "ClickHouse__ClickHouse-1721",
  "issue_numbers": [
    "957"
  ],
  "base_commit": "8f0cf29a56307e96c763fde6d293d8f551364968",
  "patch": "diff --git a/dbms/src/Interpreters/InterpreterCreateQuery.cpp b/dbms/src/Interpreters/InterpreterCreateQuery.cpp\nindex d0c112e154df..68de37b995e7 100644\n--- a/dbms/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -560,17 +560,20 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)\n         auto table_lock = res->lockStructure(true, __PRETTY_FUNCTION__);\n \n         /// Also see InterpreterInsertQuery.\n-        BlockOutputStreamPtr out =\n-            std::make_shared<ProhibitColumnsBlockOutputStream>(\n-                std::make_shared<AddingDefaultBlockOutputStream>(\n-                    std::make_shared<MaterializingBlockOutputStream>(\n-                        std::make_shared<PushingToViewsBlockOutputStream>(\n-                            create.database, create.table, res,\n-                            create.is_temporary ? context.getSessionContext() : context,\n-                            query_ptr)),\n-                    /// @note shouldn't these two contexts be session contexts in case of temporary table?\n-                    columns.columns, columns.column_defaults, context, static_cast<bool>(context.getSettingsRef().strict_insert_defaults)),\n-                columns.materialized_columns);\n+        BlockOutputStreamPtr out;\n+\n+        out = std::make_shared<PushingToViewsBlockOutputStream>(\n+            create.database, create.table, res, create.is_temporary ? context.getSessionContext() : context, query_ptr);\n+\n+        out = std::make_shared<MaterializingBlockOutputStream>(out);\n+\n+        /// @note shouldn't these two contexts be session contexts in case of temporary table?\n+        bool strict_insert_defaults = static_cast<bool>(context.getSettingsRef().strict_insert_defaults);\n+        out = std::make_shared<AddingDefaultBlockOutputStream>(\n+            out, columns.columns, columns.column_defaults, context, strict_insert_defaults);\n+\n+        if (!context.getSettingsRef().insert_allow_materialized_columns)\n+            out = std::make_shared<ProhibitColumnsBlockOutputStream>(out, columns.materialized_columns);\n \n         BlockIO io;\n         io.in_sample = as_select_sample;\ndiff --git a/dbms/src/Interpreters/InterpreterFactory.cpp b/dbms/src/Interpreters/InterpreterFactory.cpp\nindex 45bc97233178..d13c509053c3 100644\n--- a/dbms/src/Interpreters/InterpreterFactory.cpp\n+++ b/dbms/src/Interpreters/InterpreterFactory.cpp\n@@ -61,7 +61,8 @@ std::unique_ptr<IInterpreter> InterpreterFactory::get(ASTPtr & query, Context &\n     else if (typeid_cast<ASTInsertQuery *>(query.get()))\n     {\n         /// readonly is checked inside InterpreterInsertQuery\n-        return std::make_unique<InterpreterInsertQuery>(query, context);\n+        bool allow_materialized = static_cast<bool>(context.getSettingsRef().insert_allow_materialized_columns);\n+        return std::make_unique<InterpreterInsertQuery>(query, context, allow_materialized);\n     }\n     else if (typeid_cast<ASTCreateQuery *>(query.get()))\n     {\ndiff --git a/dbms/src/Interpreters/InterpreterInsertQuery.cpp b/dbms/src/Interpreters/InterpreterInsertQuery.cpp\nindex 72df1fae1735..7ae0708fb05e 100644\n--- a/dbms/src/Interpreters/InterpreterInsertQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterInsertQuery.cpp\n@@ -37,8 +37,9 @@ namespace ErrorCodes\n }\n \n \n-InterpreterInsertQuery::InterpreterInsertQuery(const ASTPtr & query_ptr_, const Context & context_)\n-    : query_ptr(query_ptr_), context(context_)\n+InterpreterInsertQuery::InterpreterInsertQuery(\n+    const ASTPtr & query_ptr_, const Context & context_, bool allow_materialized_)\n+    : query_ptr(query_ptr_), context(context_), allow_materialized(allow_materialized_)\n {\n     ProfileEvents::increment(ProfileEvents::InsertQuery);\n }\n@@ -118,7 +119,8 @@ BlockIO InterpreterInsertQuery::execute()\n     out = std::make_shared<AddingDefaultBlockOutputStream>(\n         out, required_columns, table->column_defaults, context, static_cast<bool>(context.getSettingsRef().strict_insert_defaults));\n \n-    out = std::make_shared<ProhibitColumnsBlockOutputStream>(out, table->materialized_columns);\n+    if (!allow_materialized)\n+        out = std::make_shared<ProhibitColumnsBlockOutputStream>(out, table->materialized_columns);\n \n     out = std::make_shared<SquashingBlockOutputStream>(\n         out, context.getSettingsRef().min_insert_block_size_rows, context.getSettingsRef().min_insert_block_size_bytes);\ndiff --git a/dbms/src/Interpreters/InterpreterInsertQuery.h b/dbms/src/Interpreters/InterpreterInsertQuery.h\nindex 7901ea594ef7..9bdc5cfcaba9 100644\n--- a/dbms/src/Interpreters/InterpreterInsertQuery.h\n+++ b/dbms/src/Interpreters/InterpreterInsertQuery.h\n@@ -15,7 +15,7 @@ namespace DB\n class InterpreterInsertQuery : public IInterpreter\n {\n public:\n-    InterpreterInsertQuery(const ASTPtr & query_ptr_, const Context & context_);\n+    InterpreterInsertQuery(const ASTPtr & query_ptr_, const Context & context_, bool allow_materialized_ = false);\n \n     /** Prepare a request for execution. Return block streams\n       * - the stream into which you can write data to execute the query, if INSERT;\n@@ -37,6 +37,7 @@ class InterpreterInsertQuery : public IInterpreter\n \n     ASTPtr query_ptr;\n     const Context & context;\n+    bool allow_materialized;\n };\n \n \ndiff --git a/dbms/src/Interpreters/Settings.h b/dbms/src/Interpreters/Settings.h\nindex f481fc5c3034..f94ad135cc1f 100644\n--- a/dbms/src/Interpreters/Settings.h\n+++ b/dbms/src/Interpreters/Settings.h\n@@ -301,7 +301,7 @@ struct Settings\n     M(SettingMilliseconds, stream_flush_interval_ms, DEFAULT_QUERY_LOG_FLUSH_INTERVAL_MILLISECONDS, \"Timeout for flushing data from streaming storages.\") \\\n     /* Schema identifier (used by schema-based formats) */ \\\n     M(SettingString, format_schema, \"\", \"Schema identifier (used by schema-based formats)\") \\\n-    \\\n+    M(SettingBool, insert_allow_materialized_columns, 0, \"If setting is enabled, Allow materialized columns in INSERT.\") \\\n     M(SettingSeconds, http_connection_timeout, DEFAULT_HTTP_READ_BUFFER_CONNECTION_TIMEOUT, \"HTTP connection timeout.\") \\\n     M(SettingSeconds, http_send_timeout, DEFAULT_HTTP_READ_BUFFER_TIMEOUT, \"HTTP send timeout\") \\\n     M(SettingSeconds, http_receive_timeout, DEFAULT_HTTP_READ_BUFFER_TIMEOUT, \"HTTP receive timeout\") \\\ndiff --git a/dbms/src/Storages/StorageBuffer.cpp b/dbms/src/Storages/StorageBuffer.cpp\nindex cdda74307cc2..b932324892df 100644\n--- a/dbms/src/Storages/StorageBuffer.cpp\n+++ b/dbms/src/Storages/StorageBuffer.cpp\n@@ -55,14 +55,14 @@ StorageBuffer::StorageBuffer(const std::string & name_, const NamesAndTypesList\n     const ColumnDefaults & column_defaults_,\n     Context & context_,\n     size_t num_shards_, const Thresholds & min_thresholds_, const Thresholds & max_thresholds_,\n-    const String & destination_database_, const String & destination_table_)\n+    const String & destination_database_, const String & destination_table_, bool allow_materialized_)\n     : IStorage{materialized_columns_, alias_columns_, column_defaults_},\n     name(name_), columns(columns_), context(context_),\n     num_shards(num_shards_), buffers(num_shards_),\n     min_thresholds(min_thresholds_), max_thresholds(max_thresholds_),\n     destination_database(destination_database_), destination_table(destination_table_),\n     no_destination(destination_database.empty() && destination_table.empty()),\n-    log(&Logger::get(\"StorageBuffer (\" + name + \")\"))\n+    allow_materialized(allow_materialized_), log(&Logger::get(\"StorageBuffer (\" + name + \")\"))\n {\n }\n \n@@ -527,7 +527,7 @@ void StorageBuffer::writeBlockToDestination(const Block & block, StoragePtr tabl\n     /** We will insert columns that are the intersection set of columns of the buffer table and the subordinate table.\n       * This will support some of the cases (but not all) when the table structure does not match.\n       */\n-    Block structure_of_destination_table = table->getSampleBlock();\n+    Block structure_of_destination_table = allow_materialized ? table->getSampleBlock() : table->getSampleBlockNonMaterialized();\n     Names columns_intersection;\n     columns_intersection.reserve(block.columns());\n     for (size_t i : ext::range(0, structure_of_destination_table.columns()))\n@@ -564,7 +564,7 @@ void StorageBuffer::writeBlockToDestination(const Block & block, StoragePtr tabl\n     for (const String & column : columns_intersection)\n         list_of_columns->children.push_back(std::make_shared<ASTIdentifier>(StringRange(), column, ASTIdentifier::Column));\n \n-    InterpreterInsertQuery interpreter{insert, context};\n+    InterpreterInsertQuery interpreter{insert, context, allow_materialized};\n \n     auto block_io = interpreter.execute();\n     block_io.out->writePrefix();\n@@ -650,7 +650,8 @@ void registerStorageBuffer(StorageFactory & factory)\n             num_buckets,\n             StorageBuffer::Thresholds{min_time, min_rows, min_bytes},\n             StorageBuffer::Thresholds{max_time, max_rows, max_bytes},\n-            destination_database, destination_table);\n+            destination_database, destination_table,\n+            static_cast<bool>(args.local_context.getSettingsRef().insert_allow_materialized_columns));\n     });\n }\n \ndiff --git a/dbms/src/Storages/StorageBuffer.h b/dbms/src/Storages/StorageBuffer.h\nindex 161e5d7ed10b..98cbcff661c5 100644\n--- a/dbms/src/Storages/StorageBuffer.h\n+++ b/dbms/src/Storages/StorageBuffer.h\n@@ -103,6 +103,7 @@ friend class BufferBlockOutputStream;\n     const String destination_database;\n     const String destination_table;\n     bool no_destination;    /// If set, do not write data from the buffer, but simply empty the buffer.\n+    bool allow_materialized;\n \n     Poco::Logger * log;\n \n@@ -131,7 +132,7 @@ friend class BufferBlockOutputStream;\n         const ColumnDefaults & column_defaults_,\n         Context & context_,\n         size_t num_shards_, const Thresholds & min_thresholds_, const Thresholds & max_thresholds_,\n-        const String & destination_database_, const String & destination_table_);\n+        const String & destination_database_, const String & destination_table_, bool allow_materialized_);\n };\n \n }\n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/00553_buff_exists_materlized_column.reference b/dbms/tests/queries/0_stateless/00553_buff_exists_materlized_column.reference\nnew file mode 100644\nindex 000000000000..32a047d30fce\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00553_buff_exists_materlized_column.reference\n@@ -0,0 +1,9 @@\n+1\t2\n+2\t3\n+3\t4\n+4\t5\n+1\t2\n+2\t3\n+3\t4\n+4\t5\n+5\t6\ndiff --git a/dbms/tests/queries/0_stateless/00553_buff_exists_materlized_column.sql b/dbms/tests/queries/0_stateless/00553_buff_exists_materlized_column.sql\nnew file mode 100644\nindex 000000000000..49aff2aa1849\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00553_buff_exists_materlized_column.sql\n@@ -0,0 +1,19 @@\n+DROP TABLE IF EXISTS test.nums;\n+DROP TABLE IF EXISTS test.nums_buf;\n+\n+SET insert_allow_materialized_columns = 1;\n+\n+CREATE TABLE test.nums ( n UInt64, m UInt64 MATERIALIZED n+1 ) ENGINE = Log;\n+CREATE TABLE test.nums_buf AS test.nums ENGINE = Buffer(test, nums, 1, 10, 100, 1, 3, 10000000, 100000000);\n+\n+INSERT INTO test.nums_buf (n) VALUES (1);\n+INSERT INTO test.nums_buf (n) VALUES (2);\n+INSERT INTO test.nums_buf (n) VALUES (3);\n+INSERT INTO test.nums_buf (n) VALUES (4);\n+INSERT INTO test.nums_buf (n) VALUES (5);\n+\n+SELECT n,m FROM test.nums ORDER BY n;\n+SELECT n,m FROM test.nums_buf ORDER BY n;\n+\n+DROP TABLE IF EXISTS test.nums;\n+DROP TABLE IF EXISTS test.nums_buf;\n",
  "problem_statement": "Buffer table does not work with materialized columns\nWhen the underlying table has a materialized column, the database raises an exception when trying to flush the buffer to disk. Here's a simple example that demonstrates the problem:\r\n```\r\nCREATE DATABASE IF NOT EXISTS test;\r\n\r\nCREATE TABLE test.nums (\r\n    n UInt64,\r\n    m UInt64 MATERIALIZED n+1\r\n) ENGINE = Log;\r\n\r\nCREATE TABLE nums_buf AS test.nums ENGINE = Buffer(test, nums, 1, 10, 100, 1, 3, 10000000, 100000000);\r\n\r\nINSERT INTO nums_buf (n) VALUES (1);\r\nINSERT INTO nums_buf (n) VALUES (2);\r\nINSERT INTO nums_buf (n) VALUES (3);\r\nINSERT INTO nums_buf (n) VALUES (4);\r\nINSERT INTO nums_buf (n) VALUES (5);\r\n```\r\n\r\nAfter inserting a few rows successfully, you get this error:\r\n```\r\nReceived exception from server:\r\nCode: 44. DB::Exception: Received from localhost:9000, ::1. DB::Exception: Cannot insert column m. \r\n```\r\n\r\nThe server log shows this stack trace:\r\n```\r\n2017.07.08 09:58:08.198983 [ 9 ] <Trace> StorageBuffer (nums_buf): Flushing buffer with 4 rows, 64 bytes, age 1 seconds.\r\n2017.07.08 09:58:08.238359 [ 9 ] <Error> void DB::StorageBuffer::flushThread(): Code: 44, e.displayText() = DB::Exception: Cannot insert column m, e.what() = DB::Exception, Stack trace:\r\n\r\n0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x2969826]\r\n1. clickhouse-server(DB::ProhibitColumnsBlockOutputStream::write(DB::Block const&)+0x112) [0x2bedfa2]\r\n2. clickhouse-server(DB::SquashingBlockOutputStream::finalize()+0x3f5) [0x2d74145]\r\n3. clickhouse-server(DB::SquashingBlockOutputStream::writeSuffix()+0x11) [0x2d742b1]\r\n4. clickhouse-server(DB::StorageBuffer::writeBlockToDestination(DB::Block const&, std::shared_ptr<DB::IStorage>)+0xb8c) [0x2a1c63c]\r\n5. clickhouse-server() [0x2a1d4f4]\r\n6. clickhouse-server(DB::StorageBuffer::flushThread()+0x63) [0x2a1d793]\r\n7. clickhouse-server() [0x36744ef]\r\n8. /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba) [0x7ff1c2c656ba]\r\n9. /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7ff1c22863dd]\r\n```\r\n\n",
  "hints_text": "Buffer tables just doing ordinary INSERTs to destination table.\r\nThat's why they could not have columns, that are MATERIALIZED in destination table.\r\n\r\nThis is understandable, but inconvenient behavior.\r\n\r\nWe could do one of the following:\r\n- add a flag, that will allow to INSERT into MATERIALIZED column, if INSERT is generated internally (it will also solve the same issue in Distributed tables);\r\n- add a check, that will verify, that Buffer table can INSERT data to destination table.\n> add a flag, that will allow to INSERT into MATERIALIZED column, if INSERT is generated internally (it will also solve the same issue in Distributed tables);\r\n\r\nThat is the preferred solution.\r\nThis is very easy task (half an hour for those who are familiar with the codebase).\r\n\r\n1. Add a setting `insert_allow_materialized_columns`, default 0.\r\n2. Use this setting in InterpreterInsertQuery, InterpreterCreateQuery to bypass ProhibitColumnsBlockInputStream.\r\n3. Pass this setting to INSERT query in StorageBuffer and in RemoteBlockOutputStream in DistributedDirectoryMonitor.",
  "created_at": "2018-01-01T11:55:00Z",
  "modified_files": [
    "dbms/src/Interpreters/InterpreterCreateQuery.cpp",
    "dbms/src/Interpreters/InterpreterFactory.cpp",
    "dbms/src/Interpreters/InterpreterInsertQuery.cpp",
    "dbms/src/Interpreters/InterpreterInsertQuery.h",
    "dbms/src/Interpreters/Settings.h",
    "dbms/src/Storages/StorageBuffer.cpp",
    "dbms/src/Storages/StorageBuffer.h"
  ],
  "modified_test_files": [
    "b/dbms/tests/queries/0_stateless/00553_buff_exists_materlized_column.reference",
    "b/dbms/tests/queries/0_stateless/00553_buff_exists_materlized_column.sql"
  ]
}