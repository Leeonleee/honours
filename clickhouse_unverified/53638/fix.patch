diff --git a/docs/en/operations/backup.md b/docs/en/operations/backup.md
index c3545a778b76..687bd66056b2 100644
--- a/docs/en/operations/backup.md
+++ b/docs/en/operations/backup.md
@@ -206,6 +206,55 @@ end_time:          2022-08-30 09:21:46
 1 row in set. Elapsed: 0.002 sec.
 ```
 
+Along with `system.backups` table, all backup and restore operations are also tracked in the system log table [backup_log](../operations/system-tables/backup_log.md): 
+```
+SELECT *
+FROM system.backup_log
+WHERE id = '7678b0b3-f519-4e6e-811f-5a0781a4eb52'
+ORDER BY event_time_microseconds ASC
+FORMAT Vertical
+```
+```response
+Row 1:
+──────
+event_date:              2023-08-18
+event_time_microseconds: 2023-08-18 11:13:43.097414
+id:                      7678b0b3-f519-4e6e-811f-5a0781a4eb52
+name:                    Disk('backups', '1.zip')
+status:                  CREATING_BACKUP
+error:                   
+start_time:              2023-08-18 11:13:43
+end_time:                1970-01-01 03:00:00
+num_files:               0
+total_size:              0
+num_entries:             0
+uncompressed_size:       0
+compressed_size:         0
+files_read:              0
+bytes_read:              0
+
+Row 2:
+──────
+event_date:              2023-08-18
+event_time_microseconds: 2023-08-18 11:13:43.174782
+id:                      7678b0b3-f519-4e6e-811f-5a0781a4eb52
+name:                    Disk('backups', '1.zip')
+status:                  BACKUP_FAILED
+#highlight-next-line
+error:                   Code: 598. DB::Exception: Backup Disk('backups', '1.zip') already exists. (BACKUP_ALREADY_EXISTS) (version 23.8.1.1)
+start_time:              2023-08-18 11:13:43
+end_time:                2023-08-18 11:13:43
+num_files:               0
+total_size:              0
+num_entries:             0
+uncompressed_size:       0
+compressed_size:         0
+files_read:              0
+bytes_read:              0
+
+2 rows in set. Elapsed: 0.075 sec. 
+```
+
 ## Configuring BACKUP/RESTORE to use an S3 Endpoint
 
 To write backups to an S3 bucket you need three pieces of information:
diff --git a/docs/en/operations/server-configuration-parameters/settings.md b/docs/en/operations/server-configuration-parameters/settings.md
index 55ee15a09d98..7d0ab4949262 100644
--- a/docs/en/operations/server-configuration-parameters/settings.md
+++ b/docs/en/operations/server-configuration-parameters/settings.md
@@ -2150,6 +2150,47 @@ The default server configuration file `config.xml` contains the following settin
 </crash_log>
 ```
 
+## backup_log {#server_configuration_parameters-backup_log}
+
+Settings for the [backup_log](../../operations/system-tables/backup_log.md) system table for logging `BACKUP` and `RESTORE` operations.
+
+Parameters:
+
+- `database` — Database name.
+- `table` — Table name.
+- `partition_by` — [Custom partitioning key](../../engines/table-engines/mergetree-family/custom-partitioning-key.md) for a system table. Can't be used if `engine` is defined.
+- `order_by` - [Custom sorting key](../../engines/table-engines/mergetree-family/mergetree.md#order_by) for a system table. Can't be used if `engine` is defined.
+- `engine` - [MergeTree Engine Definition](../../engines/table-engines/mergetree-family/mergetree.md#table_engine-mergetree-creating-a-table) for a system table. Can't be used if `partition_by` or `order_by` is defined.
+- `flush_interval_milliseconds` — Interval for flushing data from the buffer in memory to the table.
+- `max_size_rows` – Maximal size in lines for the logs. When non-flushed logs amount reaches max_size, logs dumped to the disk.
+Default: 1048576.
+- `reserved_size_rows` –  Pre-allocated memory size in lines for the logs.
+Default: 8192.
+- `buffer_size_rows_flush_threshold` – Lines amount threshold, reaching it launches flushing logs to the disk in background.
+Default: `max_size_rows / 2`.
+- `flush_on_crash` - Indication whether logs should be dumped to the disk in case of a crash.
+Default: false.
+- `storage_policy` – Name of storage policy to use for the table (optional).
+- `settings` - [Additional parameters](../../engines/table-engines/mergetree-family/mergetree.md#settings) that control the behavior of the MergeTree (optional).
+
+**Example**
+
+```xml
+<clickhouse>
+    <backup_log>
+        <database>system</database>
+        <table>backup_log</table>
+        <flush_interval_milliseconds>1000</flush_interval_milliseconds>
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <max_size_rows>1048576</max_size_rows>
+        <reserved_size_rows>8192</reserved_size_rows>
+        <buffer_size_rows_flush_threshold>524288</buffer_size_rows_flush_threshold>
+        <flush_on_crash>false</flush_on_crash>
+        <!-- <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + INTERVAL 30 day</engine> -->
+    </backup_log>
+</clickhouse>
+```
+
 ## query_masking_rules {#query-masking-rules}
 
 Regexp-based rules, which will be applied to queries as well as all log messages before storing them in server logs,
diff --git a/docs/en/operations/system-tables/backup_log.md b/docs/en/operations/system-tables/backup_log.md
new file mode 100644
index 000000000000..7e088fcad947
--- /dev/null
+++ b/docs/en/operations/system-tables/backup_log.md
@@ -0,0 +1,145 @@
+---
+slug: /en/operations/system-tables/backup_log
+---
+# backup_log
+
+Contains logging entries with the information about `BACKUP` and `RESTORE` operations.
+
+Columns:
+
+- `event_date` ([Date](../../sql-reference/data-types/date.md)) — Date of the entry.
+- `event_time_microseconds` ([DateTime64](../../sql-reference/data-types/datetime64.md)) — Time of the entry with microseconds precision.
+- `id` ([String](../../sql-reference/data-types/string.md)) — Identifier of the backup or restore operation.
+- `name` ([String](../../sql-reference/data-types/string.md)) — Name of the backup storage (the contents of the `FROM` or `TO` clause).
+- `status` ([Enum8](../../sql-reference/data-types/enum.md)) — Operation status. Possible values:
+    - `'CREATING_BACKUP'`
+    - `'BACKUP_CREATED'`
+    - `'BACKUP_FAILED'`
+    - `'RESTORING'`
+    - `'RESTORED'`
+    - `'RESTORE_FAILED'`
+- `error` ([String](../../sql-reference/data-types/string.md)) — Error message of the failed operation (empty string for successful operations).
+- `start_time` ([DateTime](../../sql-reference/data-types/datetime.md)) — Start time of the operation.
+- `end_time` ([DateTime](../../sql-reference/data-types/datetime.md)) — End time of the operation.
+- `num_files` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Number of files stored in the backup.
+- `total_size` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Total size of files stored in the backup.
+- `num_entries` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Number of entries in the backup, i.e. the number of files inside the folder if the backup is stored as a folder, or the number of files inside the archive if the backup is stored as an archive. It is not the same as `num_files` if it's an incremental backup or if it contains empty files or duplicates. The following is always true: `num_entries <= num_files`.
+- `uncompressed_size` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Uncompressed size of the backup.
+- `compressed_size` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Compressed size of the backup. If the backup is not stored as an archive it equals to `uncompressed_size`.
+- `files_read` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Number of files read during the restore operation.
+- `bytes_read` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Total size of files read during the restore operation.
+
+**Example**
+
+```sql
+BACKUP TABLE test_db.my_table TO Disk('backups_disk', '1.zip')
+```
+```response
+┌─id───────────────────────────────────┬─status─────────┐
+│ e5b74ecb-f6f1-426a-80be-872f90043885 │ BACKUP_CREATED │
+└──────────────────────────────────────┴────────────────┘
+```
+```sql
+SELECT * FROM system.backup_log WHERE id = 'e5b74ecb-f6f1-426a-80be-872f90043885' ORDER BY event_date, event_time_microseconds \G
+```
+```response
+Row 1:
+──────
+event_date:              2023-08-19
+event_time_microseconds: 2023-08-19 11:05:21.998566
+id:                      e5b74ecb-f6f1-426a-80be-872f90043885
+name:                    Disk('backups_disk', '1.zip')
+status:                  CREATING_BACKUP
+error:                   
+start_time:              2023-08-19 11:05:21
+end_time:                1970-01-01 03:00:00
+num_files:               0
+total_size:              0
+num_entries:             0
+uncompressed_size:       0
+compressed_size:         0
+files_read:              0
+bytes_read:              0
+
+Row 2:
+──────
+event_date:              2023-08-19
+event_time_microseconds: 2023-08-19 11:08:56.916192
+id:                      e5b74ecb-f6f1-426a-80be-872f90043885
+name:                    Disk('backups_disk', '1.zip')
+status:                  BACKUP_CREATED
+error:                   
+start_time:              2023-08-19 11:05:21
+end_time:                2023-08-19 11:08:56
+num_files:               57
+total_size:              4290364870
+num_entries:             46
+uncompressed_size:       4290362365
+compressed_size:         3525068304
+files_read:              0
+bytes_read:              0
+```
+```sql
+RESTORE TABLE test_db.my_table FROM Disk('backups_disk', '1.zip')
+```
+```response
+┌─id───────────────────────────────────┬─status───┐
+│ cdf1f731-52ef-42da-bc65-2e1bfcd4ce90 │ RESTORED │
+└──────────────────────────────────────┴──────────┘
+```
+```sql
+SELECT * FROM system.backup_log WHERE id = 'cdf1f731-52ef-42da-bc65-2e1bfcd4ce90' ORDER BY event_date, event_time_microseconds \G
+```
+```response
+Row 1:
+──────
+event_date:              2023-08-19
+event_time_microseconds: 2023-08-19 11:09:19.718077
+id:                      cdf1f731-52ef-42da-bc65-2e1bfcd4ce90
+name:                    Disk('backups_disk', '1.zip')
+status:                  RESTORING
+error:                   
+start_time:              2023-08-19 11:09:19
+end_time:                1970-01-01 03:00:00
+num_files:               0
+total_size:              0
+num_entries:             0
+uncompressed_size:       0
+compressed_size:         0
+files_read:              0
+bytes_read:              0
+
+Row 2:
+──────
+event_date:              2023-08-19
+event_time_microseconds: 2023-08-19 11:09:29.334234
+id:                      cdf1f731-52ef-42da-bc65-2e1bfcd4ce90
+name:                    Disk('backups_disk', '1.zip')
+status:                  RESTORED
+error:                   
+start_time:              2023-08-19 11:09:19
+end_time:                2023-08-19 11:09:29
+num_files:               57
+total_size:              4290364870
+num_entries:             46
+uncompressed_size:       4290362365
+compressed_size:         4290362365
+files_read:              57
+bytes_read:              4290364870
+```
+
+This is essentially the same information that is written in the system table `system.backups`:
+
+```sql
+SELECT * FROM system.backups ORDER BY start_time
+```
+```response
+┌─id───────────────────────────────────┬─name──────────────────────────┬─status─────────┬─error─┬──────────start_time─┬────────────end_time─┬─num_files─┬─total_size─┬─num_entries─┬─uncompressed_size─┬─compressed_size─┬─files_read─┬─bytes_read─┐
+│ e5b74ecb-f6f1-426a-80be-872f90043885 │ Disk('backups_disk', '1.zip') │ BACKUP_CREATED │       │ 2023-08-19 11:05:21 │ 2023-08-19 11:08:56 │        57 │ 4290364870 │          46 │        4290362365 │      3525068304 │          0 │          0 │
+│ cdf1f731-52ef-42da-bc65-2e1bfcd4ce90 │ Disk('backups_disk', '1.zip') │ RESTORED       │       │ 2023-08-19 11:09:19 │ 2023-08-19 11:09:29 │        57 │ 4290364870 │          46 │        4290362365 │      4290362365 │         57 │ 4290364870 │
+└──────────────────────────────────────┴───────────────────────────────┴────────────────┴───────┴─────────────────────┴─────────────────────┴───────────┴────────────┴─────────────┴───────────────────┴─────────────────┴────────────┴────────────┘
+```
+
+**See Also**
+
+- [Backup and Restore](../../operations/backup.md)
diff --git a/docs/en/operations/system-tables/index.md b/docs/en/operations/system-tables/index.md
index a46f306f6777..df42f80275e0 100644
--- a/docs/en/operations/system-tables/index.md
+++ b/docs/en/operations/system-tables/index.md
@@ -23,7 +23,7 @@ System tables:
 
 Most of system tables store their data in RAM. A ClickHouse server creates such system tables at the start.
 
-Unlike other system tables, the system log tables [metric_log](../../operations/system-tables/metric_log.md), [query_log](../../operations/system-tables/query_log.md), [query_thread_log](../../operations/system-tables/query_thread_log.md), [trace_log](../../operations/system-tables/trace_log.md), [part_log](../../operations/system-tables/part_log.md), [crash_log](../../operations/system-tables/crash-log.md) and [text_log](../../operations/system-tables/text_log.md) are served by [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) table engine and store their data in a filesystem by default. If you remove a table from a filesystem, the ClickHouse server creates the empty one again at the time of the next data writing. If system table schema changed in a new release, then ClickHouse renames the current table and creates a new one.
+Unlike other system tables, the system log tables [metric_log](../../operations/system-tables/metric_log.md), [query_log](../../operations/system-tables/query_log.md), [query_thread_log](../../operations/system-tables/query_thread_log.md), [trace_log](../../operations/system-tables/trace_log.md), [part_log](../../operations/system-tables/part_log.md), [crash_log](../../operations/system-tables/crash-log.md), [text_log](../../operations/system-tables/text_log.md) and [backup_log](../../operations/system-tables/backup_log.md) are served by [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) table engine and store their data in a filesystem by default. If you remove a table from a filesystem, the ClickHouse server creates the empty one again at the time of the next data writing. If system table schema changed in a new release, then ClickHouse renames the current table and creates a new one.
 
 System log tables can be customized by creating a config file with the same name as the table under `/etc/clickhouse-server/config.d/`, or setting corresponding elements in `/etc/clickhouse-server/config.xml`. Elements can be customized are:
 
@@ -32,7 +32,7 @@ System log tables can be customized by creating a config file with the same name
 - `partition_by`: specify [PARTITION BY](../../engines/table-engines/mergetree-family/custom-partitioning-key.md) expression.
 - `ttl`: specify table [TTL](../../sql-reference/statements/alter/ttl.md) expression.
 - `flush_interval_milliseconds`: interval of flushing data to disk.
-- `engine`: provide full engine expression (starting with `ENGINE =` ) with parameters. This option is contradict with `partition_by` and `ttl`. If set together, the server would raise an exception and exit.
+- `engine`: provide full engine expression (starting with `ENGINE =` ) with parameters. This option conflicts with `partition_by` and `ttl`. If set together, the server will raise an exception and exit.
 
 An example:
 
diff --git a/docs/ru/operations/server-configuration-parameters/settings.md b/docs/ru/operations/server-configuration-parameters/settings.md
index 652a03a0df58..1b488f5864de 100644
--- a/docs/ru/operations/server-configuration-parameters/settings.md
+++ b/docs/ru/operations/server-configuration-parameters/settings.md
@@ -1488,6 +1488,47 @@ ClickHouse использует потоки из глобального пул
 </crash_log>
 ```
 
+## backup_log {#server_configuration_parameters-backup_log}
+
+Настройки для системной таблицы [backup_log](../../operations/system-tables/backup_log.md), предназначенной для логирования операций `BACKUP` и `RESTORE`.
+
+Параметры:
+
+- `database` — имя базы данных.
+- `table` — имя таблицы.
+- `partition_by` — [произвольный ключ партиционирования](../../engines/table-engines/mergetree-family/custom-partitioning-key.md). Нельзя использовать одновременно с `engine`.
+- `order_by` - [произвольный ключ сортировки](../../engines/table-engines/mergetree-family/mergetree.md#order_by). Нельзя использовать одновременно с `engine`.
+- `engine` - [настройки MergeTree Engine](../../engines/table-engines/mergetree-family/mergetree.md#table_engine-mergetree-creating-a-table). Нельзя использовать с `partition_by` или `order_by`.
+- `flush_interval_milliseconds` — период сброса данных из буфера в памяти в таблицу.
+- `max_size_rows` – максимальный размер в строках для буфера с логами. Когда буфер будет заполнен полностью, сбрасывает логи на диск.
+Значение по умолчанию: 1024.
+- `reserved_size_rows` –  преаллоцированный размер в строках для буфера с логами.
+Значение по умолчанию: 1024.
+- `buffer_size_rows_flush_threshold` – количество строк в логе, при достижении которого логи начнут скидываться на диск в неблокирующем режиме.
+Значение по умолчанию: `max_size_rows / 2`.
+- `flush_on_crash` - должны ли логи быть сброшены на диск в случае неожиданной остановки программы.
+Значение по умолчанию: false.
+- `storage_policy` – название политики хранения (необязательный параметр).
+- `settings` - [дополнительные настройки MergeTree Engine](../../engines/table-engines/mergetree-family/mergetree.md#settings) (необязательный параметр).
+
+**Пример**
+
+```xml
+<clickhouse>
+    <backup_log>
+        <database>system</database>
+        <table>backup_log</table>
+        <flush_interval_milliseconds>1000</flush_interval_milliseconds>
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <max_size_rows>1048576</max_size_rows>
+        <reserved_size_rows>8192</reserved_size_rows>
+        <buffer_size_rows_flush_threshold>524288</buffer_size_rows_flush_threshold>
+        <flush_on_crash>false</flush_on_crash>
+        <!-- <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + INTERVAL 30 day</engine> -->
+    </backup_log>
+</clickhouse>
+```
+
 ## query_masking_rules {#query-masking-rules}
 
 Правила, основанные на регулярных выражениях, которые будут применены для всех запросов, а также для всех сообщений перед сохранением их в лог на сервере,
diff --git a/docs/ru/operations/system-tables/backup_log.md b/docs/ru/operations/system-tables/backup_log.md
new file mode 100644
index 000000000000..15c1bfb20a40
--- /dev/null
+++ b/docs/ru/operations/system-tables/backup_log.md
@@ -0,0 +1,145 @@
+---
+slug: /ru/operations/system-tables/backup_log
+---
+# system.backup_log {#system_tables-backup-log}
+
+Содержит информацию о всех операциях `BACKUP` and `RESTORE`.
+
+Колонки:
+
+- `event_date` ([Date](../../sql-reference/data-types/date.md)) — Дата события.
+- `event_time_microseconds` ([DateTime64](../../sql-reference/data-types/datetime64.md)) — Время события с точностью до микросекунд.
+- `id` ([String](../../sql-reference/data-types/string.md)) — Идентификатор операции.
+- `name` ([String](../../sql-reference/data-types/string.md)) — Название хранилища (содержимое секции `FROM` или `TO` в SQL запросе).
+- `status` ([Enum8](../../sql-reference/data-types/enum.md)) — Статус операции. Возможные значения:
+    - `'CREATING_BACKUP'`
+    - `'BACKUP_CREATED'`
+    - `'BACKUP_FAILED'`
+    - `'RESTORING'`
+    - `'RESTORED'`
+    - `'RESTORE_FAILED'`
+- `error` ([String](../../sql-reference/data-types/string.md)) — Сообщение об ошибке, при наличии (записи для успешных операций содержат пустую строку).
+- `start_time` ([DateTime](../../sql-reference/data-types/datetime.md)) — Время начала операции.
+- `end_time` ([DateTime](../../sql-reference/data-types/datetime.md)) — Время завершения операции.
+- `num_files` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Количество файлов, хранимых в бэкапе.
+- `total_size` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Общий размер файлов, хранимых в бэкапе.
+- `num_entries` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Количество позиций в бэкапе, т.е. либо количество файлов в папке (если бэкап хранится в папке), либо количество файлов в архиве (если бэкап хранится в архиве). Это значение не равно `num_files` в случае если это инкрементальный бэкап либо он содержит пустые файлы или дубликаты. Следующее утверждение верно всегда: `num_entries <= num_files`.
+- `uncompressed_size` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Размер бэкапа до сжатия.
+- `compressed_size` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Размер бэкапа после сжатия. Если бэкап не хранится в виде архива, это значение равно `uncompressed_size`.
+- `files_read` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Количество файлов, прочитанных во время операции восстановления.
+- `bytes_read` ([UInt64](../../sql-reference/data-types/int-uint.md#uint-ranges)) — Общий размер файлов, прочитанных во время операции восстановления.
+
+**Пример**
+
+```sql
+BACKUP TABLE test_db.my_table TO Disk('backups_disk', '1.zip')
+```
+```response
+┌─id───────────────────────────────────┬─status─────────┐
+│ e5b74ecb-f6f1-426a-80be-872f90043885 │ BACKUP_CREATED │
+└──────────────────────────────────────┴────────────────┘
+```
+```sql
+SELECT * FROM system.backup_log WHERE id = 'e5b74ecb-f6f1-426a-80be-872f90043885' ORDER BY event_date, event_time_microseconds \G
+```
+```response
+Row 1:
+──────
+event_date:              2023-08-19
+event_time_microseconds: 2023-08-19 11:05:21.998566
+id:                      e5b74ecb-f6f1-426a-80be-872f90043885
+name:                    Disk('backups_disk', '1.zip')
+status:                  CREATING_BACKUP
+error:                   
+start_time:              2023-08-19 11:05:21
+end_time:                1970-01-01 03:00:00
+num_files:               0
+total_size:              0
+num_entries:             0
+uncompressed_size:       0
+compressed_size:         0
+files_read:              0
+bytes_read:              0
+
+Row 2:
+──────
+event_date:              2023-08-19
+event_time_microseconds: 2023-08-19 11:08:56.916192
+id:                      e5b74ecb-f6f1-426a-80be-872f90043885
+name:                    Disk('backups_disk', '1.zip')
+status:                  BACKUP_CREATED
+error:                   
+start_time:              2023-08-19 11:05:21
+end_time:                2023-08-19 11:08:56
+num_files:               57
+total_size:              4290364870
+num_entries:             46
+uncompressed_size:       4290362365
+compressed_size:         3525068304
+files_read:              0
+bytes_read:              0
+```
+```sql
+RESTORE TABLE test_db.my_table FROM Disk('backups_disk', '1.zip')
+```
+```response
+┌─id───────────────────────────────────┬─status───┐
+│ cdf1f731-52ef-42da-bc65-2e1bfcd4ce90 │ RESTORED │
+└──────────────────────────────────────┴──────────┘
+```
+```sql
+SELECT * FROM system.backup_log WHERE id = 'cdf1f731-52ef-42da-bc65-2e1bfcd4ce90' ORDER BY event_date, event_time_microseconds \G
+```
+```response
+Row 1:
+──────
+event_date:              2023-08-19
+event_time_microseconds: 2023-08-19 11:09:19.718077
+id:                      cdf1f731-52ef-42da-bc65-2e1bfcd4ce90
+name:                    Disk('backups_disk', '1.zip')
+status:                  RESTORING
+error:                   
+start_time:              2023-08-19 11:09:19
+end_time:                1970-01-01 03:00:00
+num_files:               0
+total_size:              0
+num_entries:             0
+uncompressed_size:       0
+compressed_size:         0
+files_read:              0
+bytes_read:              0
+
+Row 2:
+──────
+event_date:              2023-08-19
+event_time_microseconds: 2023-08-19 11:09:29.334234
+id:                      cdf1f731-52ef-42da-bc65-2e1bfcd4ce90
+name:                    Disk('backups_disk', '1.zip')
+status:                  RESTORED
+error:                   
+start_time:              2023-08-19 11:09:19
+end_time:                2023-08-19 11:09:29
+num_files:               57
+total_size:              4290364870
+num_entries:             46
+uncompressed_size:       4290362365
+compressed_size:         4290362365
+files_read:              57
+bytes_read:              4290364870
+```
+
+Это по сути та же информация, что заносится и в системную таблицу `system.backups`:
+
+```sql
+SELECT * FROM system.backups ORDER BY start_time
+```
+```response
+┌─id───────────────────────────────────┬─name──────────────────────────┬─status─────────┬─error─┬──────────start_time─┬────────────end_time─┬─num_files─┬─total_size─┬─num_entries─┬─uncompressed_size─┬─compressed_size─┬─files_read─┬─bytes_read─┐
+│ e5b74ecb-f6f1-426a-80be-872f90043885 │ Disk('backups_disk', '1.zip') │ BACKUP_CREATED │       │ 2023-08-19 11:05:21 │ 2023-08-19 11:08:56 │        57 │ 4290364870 │          46 │        4290362365 │      3525068304 │          0 │          0 │
+│ cdf1f731-52ef-42da-bc65-2e1bfcd4ce90 │ Disk('backups_disk', '1.zip') │ RESTORED       │       │ 2023-08-19 11:09:19 │ 2023-08-19 11:09:29 │        57 │ 4290364870 │          46 │        4290362365 │      4290362365 │         57 │ 4290364870 │
+└──────────────────────────────────────┴───────────────────────────────┴────────────────┴───────┴─────────────────────┴─────────────────────┴───────────┴────────────┴─────────────┴───────────────────┴─────────────────┴────────────┴────────────┘
+```
+
+**См. также**
+
+- [Backup and Restore](../../operations/backup.md)
diff --git a/docs/ru/operations/system-tables/index.md b/docs/ru/operations/system-tables/index.md
index 24f79cae212c..aedefb241931 100644
--- a/docs/ru/operations/system-tables/index.md
+++ b/docs/ru/operations/system-tables/index.md
@@ -21,7 +21,7 @@ sidebar_label: "Системные таблицы"
 
 Большинство системных таблиц хранят свои данные в оперативной памяти. Сервер ClickHouse создает эти системные таблицы при старте.
 
-В отличие от других системных таблиц, таблицы с системными логами [metric_log](../../operations/system-tables/metric_log.md), [query_log](../../operations/system-tables/query_log.md), [query_thread_log](../../operations/system-tables/query_thread_log.md), [trace_log](../../operations/system-tables/trace_log.md), [part_log](../../operations/system-tables/part_log.md), [crash_log](../../operations/system-tables/crash-log.md) и [text_log](../../operations/system-tables/text_log.md) используют движок таблиц [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) и по умолчанию хранят свои данные в файловой системе. Если удалить таблицу из файловой системы, сервер ClickHouse снова создаст пустую таблицу во время следующей записи данных. Если схема системной таблицы изменилась в новом релизе, то ClickHouse переименует текущую таблицу и создаст новую.
+В отличие от других системных таблиц, таблицы с системными логами [metric_log](../../operations/system-tables/metric_log.md), [query_log](../../operations/system-tables/query_log.md), [query_thread_log](../../operations/system-tables/query_thread_log.md), [trace_log](../../operations/system-tables/trace_log.md), [part_log](../../operations/system-tables/part_log.md), [crash_log](../../operations/system-tables/crash-log.md), [text_log](../../operations/system-tables/text_log.md) и [backup_log](../../operations/system-tables/backup_log.md) используют движок таблиц [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) и по умолчанию хранят свои данные в файловой системе. Если удалить таблицу из файловой системы, сервер ClickHouse снова создаст пустую таблицу во время следующей записи данных. Если схема системной таблицы изменилась в новом релизе, то ClickHouse переименует текущую таблицу и создаст новую.
 
 Таблицы с системными логами `log` можно настроить, создав конфигурационный файл с тем же именем, что и таблица в разделе `/etc/clickhouse-server/config.d/`, или указав соответствующие элементы в `/etc/clickhouse-server/config.xml`. Настраиваться могут следующие элементы:
 
diff --git a/programs/server/config.xml b/programs/server/config.xml
index 07052441a016..117be72d7580 100644
--- a/programs/server/config.xml
+++ b/programs/server/config.xml
@@ -1220,6 +1220,16 @@
         <ttl>event_date + INTERVAL 3 DAY</ttl>
     </asynchronous_insert_log>
 
+    <!-- Backup/restore log.
+         Uncomment to write backup/restore log records into a system table.
+    <backup_log>
+        <database>system</database>
+        <table>backup_log</table>
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <flush_interval_milliseconds>0</flush_interval_milliseconds>
+    </backup_log>
+    -->
+
     <!-- <top_level_domains_path>/var/lib/clickhouse/top_level_domains/</top_level_domains_path> -->
     <!-- Custom TLD lists.
          Format: <name>/path/to/file</name>
diff --git a/src/Backups/BackupOperationInfo.h b/src/Backups/BackupOperationInfo.h
new file mode 100644
index 000000000000..d8342e7a8c91
--- /dev/null
+++ b/src/Backups/BackupOperationInfo.h
@@ -0,0 +1,54 @@
+#pragma once
+
+#include <Backups/BackupStatus.h>
+
+namespace DB
+{
+
+using BackupOperationID = String;
+
+/// Information about executing a BACKUP or RESTORE operation
+struct BackupOperationInfo
+{
+    /// Operation ID, can be either passed via SETTINGS id=... or be randomly generated UUID.
+    BackupOperationID id;
+
+    /// Operation name, a string like "Disk('backups', 'my_backup')"
+    String name;
+
+    /// This operation is internal and should not be shown in system.backups
+    bool internal = false;
+
+    /// Status of backup or restore operation.
+    BackupStatus status;
+
+    /// The number of files stored in the backup.
+    size_t num_files = 0;
+
+    /// The total size of files stored in the backup.
+    UInt64 total_size = 0;
+
+    /// The number of entries in the backup, i.e. the number of files inside the folder if the backup is stored as a folder.
+    size_t num_entries = 0;
+
+    /// The uncompressed size of the backup.
+    UInt64 uncompressed_size = 0;
+
+    /// The compressed size of the backup.
+    UInt64 compressed_size = 0;
+
+    /// Returns the number of files read during RESTORE from this backup.
+    size_t num_read_files = 0;
+
+    // Returns the total size of files read during RESTORE from this backup.
+    UInt64 num_read_bytes = 0;
+
+    /// Set only if there was an error.
+    std::exception_ptr exception;
+    String error_message;
+
+    std::chrono::system_clock::time_point start_time;
+    std::chrono::system_clock::time_point end_time;
+};
+
+}
diff --git a/src/Backups/BackupsWorker.cpp b/src/Backups/BackupsWorker.cpp
index 6c2abaf4fbab..e5cd905fbd11 100644
--- a/src/Backups/BackupsWorker.cpp
+++ b/src/Backups/BackupsWorker.cpp
@@ -14,6 +14,7 @@
 #include <Backups/RestorerFromBackup.h>
 #include <Interpreters/Cluster.h>
 #include <Interpreters/Context.h>
+#include <Interpreters/BackupLog.h>
 #include <Interpreters/executeDDLQueryOnCluster.h>
 #include <Parsers/ASTBackupQuery.h>
 #include <Parsers/ASTFunction.h>
@@ -44,7 +45,7 @@ namespace ErrorCodes
     extern const int CONCURRENT_ACCESS_NOT_SUPPORTED;
 }
 
-using OperationID = BackupsWorker::OperationID;
+using OperationID = BackupOperationID;
 namespace Stage = BackupCoordinationStage;
 
 namespace
@@ -230,6 +231,7 @@ BackupsWorker::BackupsWorker(size_t num_backup_threads, size_t num_restore_threa
 
 OperationID BackupsWorker::start(const ASTPtr & backup_or_restore_query, ContextMutablePtr context)
 {
+    backup_log = context->getBackupLog();
     const ASTBackupQuery & backup_query = typeid_cast<const ASTBackupQuery &>(*backup_or_restore_query);
     if (backup_query.kind == ASTBackupQuery::Kind::BACKUP)
         return startMakingBackup(backup_or_restore_query, context);
@@ -450,9 +452,10 @@ void BackupsWorker::doBackup(
         backup.reset();
 
         LOG_INFO(log, "{} {} was created successfully", (backup_settings.internal ? "Internal backup" : "Backup"), backup_name_for_logging);
-        setStatus(backup_id, BackupStatus::BACKUP_CREATED);
         /// NOTE: we need to update metadata again after backup->finalizeWriting(), because backup metadata is written there.
         setNumFilesAndSize(backup_id, num_files, total_size, num_entries, uncompressed_size, compressed_size, 0, 0);
+        /// NOTE: setStatus is called after setNumFilesAndSize in order to have actual information in a backup log record
+        setStatus(backup_id, BackupStatus::BACKUP_CREATED);
     }
     catch (...)
     {
@@ -875,7 +878,7 @@ void BackupsWorker::restoreTablesData(const OperationID & restore_id, BackupPtr
 
 void BackupsWorker::addInfo(const OperationID & id, const String & name, bool internal, BackupStatus status)
 {
-    Info info;
+    BackupOperationInfo info;
     info.id = id;
     info.name = name;
     info.internal = internal;
@@ -896,6 +899,9 @@ void BackupsWorker::addInfo(const OperationID & id, const String & name, bool in
             throw Exception(ErrorCodes::BAD_ARGUMENTS, "Cannot start a backup or restore: ID {} is already in use", id);
     }
 
+    if (backup_log)
+        backup_log->add(BackupLogElement{info});
+
     infos[id] = std::move(info);
 
     num_active_backups += getNumActiveBackupsChange(status);
@@ -929,6 +935,9 @@ void BackupsWorker::setStatus(const String & id, BackupStatus status, bool throw
         info.exception = std::current_exception();
     }
 
+    if (backup_log)
+        backup_log->add(BackupLogElement{info});
+
     num_active_backups += getNumActiveBackupsChange(status) - getNumActiveBackupsChange(old_status);
     num_active_restores += getNumActiveRestoresChange(status) - getNumActiveRestoresChange(old_status);
 }
@@ -938,6 +947,7 @@ void BackupsWorker::setNumFilesAndSize(const OperationID & id, size_t num_files,
                                        UInt64 uncompressed_size, UInt64 compressed_size, size_t num_read_files, UInt64 num_read_bytes)
 
 {
+    /// Current operation's info entry is updated here. The backup_log table is updated on its basis within a subsequent setStatus() call.
     std::lock_guard lock{infos_mutex};
     auto it = infos.find(id);
     if (it == infos.end())
@@ -970,7 +980,7 @@ void BackupsWorker::wait(const OperationID & id, bool rethrow_exception)
     });
 }
 
-BackupsWorker::Info BackupsWorker::getInfo(const OperationID & id) const
+BackupOperationInfo BackupsWorker::getInfo(const OperationID & id) const
 {
     std::lock_guard lock{infos_mutex};
     auto it = infos.find(id);
@@ -979,9 +989,9 @@ BackupsWorker::Info BackupsWorker::getInfo(const OperationID & id) const
     return it->second;
 }
 
-std::vector<BackupsWorker::Info> BackupsWorker::getAllInfos() const
+std::vector<BackupOperationInfo> BackupsWorker::getAllInfos() const
 {
-    std::vector<Info> res_infos;
+    std::vector<BackupOperationInfo> res_infos;
     std::lock_guard lock{infos_mutex};
     for (const auto & info : infos | boost::adaptors::map_values)
     {
diff --git a/src/Backups/BackupsWorker.h b/src/Backups/BackupsWorker.h
index ab4359ec2574..e7207cdcbd2f 100644
--- a/src/Backups/BackupsWorker.h
+++ b/src/Backups/BackupsWorker.h
@@ -1,6 +1,6 @@
 #pragma once
 
-#include <Backups/BackupStatus.h>
+#include <Backups/BackupOperationInfo.h>
 #include <Common/ThreadPool_fwd.h>
 #include <Interpreters/Context_fwd.h>
 #include <Core/UUID.h>
@@ -25,6 +25,7 @@ class IBackupEntry;
 using BackupEntries = std::vector<std::pair<String, std::shared_ptr<const IBackupEntry>>>;
 using DataRestoreTasks = std::vector<std::function<void()>>;
 struct ReadSettings;
+class BackupLog;
 
 /// Manager of backups and restores: executes backups and restores' threads in the background.
 /// Keeps information about backups and restores started in this session.
@@ -36,69 +37,22 @@ class BackupsWorker
     /// Waits until all tasks have been completed.
     void shutdown();
 
-    /// Backup's or restore's operation ID, can be either passed via SETTINGS id=... or be randomly generated UUID.
-    using OperationID = String;
-
     /// Starts executing a BACKUP or RESTORE query. Returns ID of the operation.
-    OperationID start(const ASTPtr & backup_or_restore_query, ContextMutablePtr context);
+    BackupOperationID start(const ASTPtr & backup_or_restore_query, ContextMutablePtr context);
 
     /// Waits until a BACKUP or RESTORE query started by start() is finished.
     /// The function returns immediately if the operation is already finished.
-    void wait(const OperationID & backup_or_restore_id, bool rethrow_exception = true);
-
-    /// Information about executing a BACKUP or RESTORE query started by calling start().
-    struct Info
-    {
-        /// Backup's or restore's operation ID, can be either passed via SETTINGS id=... or be randomly generated UUID.
-        OperationID id;
-
-        /// Backup's name, a string like "Disk('backups', 'my_backup')"
-        String name;
-
-        /// This operation is internal and should not be shown in system.backups
-        bool internal = false;
-
-        /// Status of backup or restore operation.
-        BackupStatus status;
-
-        /// The number of files stored in the backup.
-        size_t num_files = 0;
-
-        /// The total size of files stored in the backup.
-        UInt64 total_size = 0;
-
-        /// The number of entries in the backup, i.e. the number of files inside the folder if the backup is stored as a folder.
-        size_t num_entries = 0;
-
-        /// The uncompressed size of the backup.
-        UInt64 uncompressed_size = 0;
-
-        /// The compressed size of the backup.
-        UInt64 compressed_size = 0;
-
-        /// Returns the number of files read during RESTORE from this backup.
-        size_t num_read_files = 0;
-
-        // Returns the total size of files read during RESTORE from this backup.
-        UInt64 num_read_bytes = 0;
-
-        /// Set only if there was an error.
-        std::exception_ptr exception;
-        String error_message;
-
-        std::chrono::system_clock::time_point start_time;
-        std::chrono::system_clock::time_point end_time;
-    };
+    void wait(const BackupOperationID & backup_or_restore_id, bool rethrow_exception = true);
 
-    Info getInfo(const OperationID & id) const;
-    std::vector<Info> getAllInfos() const;
+    BackupOperationInfo getInfo(const BackupOperationID & id) const;
+    std::vector<BackupOperationInfo> getAllInfos() const;
 
 private:
-    OperationID startMakingBackup(const ASTPtr & query, const ContextPtr & context);
+    BackupOperationID startMakingBackup(const ASTPtr & query, const ContextPtr & context);
 
     void doBackup(
         const std::shared_ptr<ASTBackupQuery> & backup_query,
-        const OperationID & backup_id,
+        const BackupOperationID & backup_id,
         const String & backup_name_for_logging,
         const BackupInfo & backup_info,
         BackupSettings backup_settings,
@@ -111,13 +65,13 @@ class BackupsWorker
     void buildFileInfosForBackupEntries(const BackupPtr & backup, const BackupEntries & backup_entries, const ReadSettings & read_settings, std::shared_ptr<IBackupCoordination> backup_coordination);
 
     /// Write backup entries to an opened backup.
-    void writeBackupEntries(BackupMutablePtr backup, BackupEntries && backup_entries, const OperationID & backup_id, std::shared_ptr<IBackupCoordination> backup_coordination, bool internal);
+    void writeBackupEntries(BackupMutablePtr backup, BackupEntries && backup_entries, const BackupOperationID & backup_id, std::shared_ptr<IBackupCoordination> backup_coordination, bool internal);
 
-    OperationID startRestoring(const ASTPtr & query, ContextMutablePtr context);
+    BackupOperationID startRestoring(const ASTPtr & query, ContextMutablePtr context);
 
     void doRestore(
         const std::shared_ptr<ASTBackupQuery> & restore_query,
-        const OperationID & restore_id,
+        const BackupOperationID & restore_id,
         const String & backup_name_for_logging,
         const BackupInfo & backup_info,
         RestoreSettings restore_settings,
@@ -126,18 +80,19 @@ class BackupsWorker
         bool called_async);
 
     /// Run data restoring tasks which insert data to tables.
-    void restoreTablesData(const OperationID & restore_id, BackupPtr backup, DataRestoreTasks && tasks, ThreadPool & thread_pool);
+    void restoreTablesData(const BackupOperationID & restore_id, BackupPtr backup, DataRestoreTasks && tasks, ThreadPool & thread_pool);
 
-    void addInfo(const OperationID & id, const String & name, bool internal, BackupStatus status);
-    void setStatus(const OperationID & id, BackupStatus status, bool throw_if_error = true);
+    void addInfo(const BackupOperationID & id, const String & name, bool internal, BackupStatus status);
+    void setStatus(const BackupOperationID & id, BackupStatus status, bool throw_if_error = true);
     void setStatusSafe(const String & id, BackupStatus status) { setStatus(id, status, false); }
-    void setNumFilesAndSize(const OperationID & id, size_t num_files, UInt64 total_size, size_t num_entries,
+    void setNumFilesAndSize(const BackupOperationID & id, size_t num_files, UInt64 total_size, size_t num_entries,
                             UInt64 uncompressed_size, UInt64 compressed_size, size_t num_read_files, UInt64 num_read_bytes);
 
     std::unique_ptr<ThreadPool> backups_thread_pool;
     std::unique_ptr<ThreadPool> restores_thread_pool;
 
-    std::unordered_map<OperationID, Info> infos;
+    std::unordered_map<BackupOperationID, BackupOperationInfo> infos;
+    std::shared_ptr<BackupLog> backup_log;
     std::condition_variable status_changed;
     std::atomic<size_t> num_active_backups = 0;
     std::atomic<size_t> num_active_restores = 0;
diff --git a/src/Common/SystemLogBase.cpp b/src/Common/SystemLogBase.cpp
index 919020f12c91..611e14fd9b30 100644
--- a/src/Common/SystemLogBase.cpp
+++ b/src/Common/SystemLogBase.cpp
@@ -15,6 +15,7 @@
 #include <Interpreters/ZooKeeperLog.h>
 #include <Interpreters/TransactionsInfoLog.h>
 #include <Interpreters/AsynchronousInsertLog.h>
+#include <Interpreters/BackupLog.h>
 
 #include <Common/MemoryTrackerBlockerInThread.h>
 #include <Common/SystemLogBase.h>
diff --git a/src/Common/SystemLogBase.h b/src/Common/SystemLogBase.h
index 1f5832e7aac9..9770629e96af 100644
--- a/src/Common/SystemLogBase.h
+++ b/src/Common/SystemLogBase.h
@@ -29,7 +29,8 @@
     M(TextLogElement) \
     M(FilesystemCacheLogElement) \
     M(FilesystemReadPrefetchesLogElement) \
-    M(AsynchronousInsertLogElement)
+    M(AsynchronousInsertLogElement) \
+    M(BackupLogElement)
 
 namespace Poco
 {
diff --git a/src/Interpreters/BackupLog.cpp b/src/Interpreters/BackupLog.cpp
new file mode 100644
index 000000000000..5e6c038ac5de
--- /dev/null
+++ b/src/Interpreters/BackupLog.cpp
@@ -0,0 +1,61 @@
+#include <Interpreters/BackupLog.h>
+
+#include <DataTypes/DataTypeDate.h>
+#include <DataTypes/DataTypeDateTime64.h>
+#include <DataTypes/DataTypeEnum.h>
+#include <DataTypes/DataTypeString.h>
+#include <DataTypes/DataTypesNumber.h>
+
+namespace DB
+{
+
+BackupLogElement::BackupLogElement(BackupOperationInfo info_)
+    : event_time(std::chrono::system_clock::now())
+    , event_time_usec(timeInMicroseconds(event_time))
+    , info(std::move(info_))
+{
+}
+
+NamesAndTypesList BackupLogElement::getNamesAndTypes()
+{
+    return
+    {
+        {"event_date", std::make_shared<DataTypeDate>()},
+        {"event_time_microseconds", std::make_shared<DataTypeDateTime64>(6)},
+        {"id", std::make_shared<DataTypeString>()},
+        {"name", std::make_shared<DataTypeString>()},
+        {"status", std::make_shared<DataTypeEnum8>(getBackupStatusEnumValues())},
+        {"error", std::make_shared<DataTypeString>()},
+        {"start_time", std::make_shared<DataTypeDateTime>()},
+        {"end_time", std::make_shared<DataTypeDateTime>()},
+        {"num_files", std::make_shared<DataTypeUInt64>()},
+        {"total_size", std::make_shared<DataTypeUInt64>()},
+        {"num_entries", std::make_shared<DataTypeUInt64>()},
+        {"uncompressed_size", std::make_shared<DataTypeUInt64>()},
+        {"compressed_size", std::make_shared<DataTypeUInt64>()},
+        {"files_read", std::make_shared<DataTypeUInt64>()},
+        {"bytes_read", std::make_shared<DataTypeUInt64>()},
+    };
+}
+
+void BackupLogElement::appendToBlock(MutableColumns & columns) const
+{
+    size_t i = 0;
+    columns[i++]->insert(DateLUT::instance().toDayNum(std::chrono::system_clock::to_time_t(event_time)).toUnderType());
+    columns[i++]->insert(event_time_usec);
+    columns[i++]->insert(info.id);
+    columns[i++]->insert(info.name);
+    columns[i++]->insert(static_cast<Int8>(info.status));
+    columns[i++]->insert(info.error_message);
+    columns[i++]->insert(static_cast<UInt32>(std::chrono::system_clock::to_time_t(info.start_time)));
+    columns[i++]->insert(static_cast<UInt32>(std::chrono::system_clock::to_time_t(info.end_time)));
+    columns[i++]->insert(info.num_files);
+    columns[i++]->insert(info.total_size);
+    columns[i++]->insert(info.num_entries);
+    columns[i++]->insert(info.uncompressed_size);
+    columns[i++]->insert(info.compressed_size);
+    columns[i++]->insert(info.num_read_files);
+    columns[i++]->insert(info.num_read_bytes);
+}
+
+}
diff --git a/src/Interpreters/BackupLog.h b/src/Interpreters/BackupLog.h
new file mode 100644
index 000000000000..283b74f68baa
--- /dev/null
+++ b/src/Interpreters/BackupLog.h
@@ -0,0 +1,42 @@
+#pragma once
+
+#include <Interpreters/SystemLog.h>
+#include <Core/NamesAndTypes.h>
+#include <Core/NamesAndAliases.h>
+#include <Backups/BackupOperationInfo.h>
+
+namespace DB
+{
+
+/** A struct which will be inserted as row into backup_log table.
+  * Contains a record about backup or restore operation.
+  */
+struct BackupLogElement
+{
+    BackupLogElement() = default;
+    BackupLogElement(BackupOperationInfo info_);
+    BackupLogElement(const BackupLogElement &) = default;
+    BackupLogElement & operator=(const BackupLogElement &) = default;
+    BackupLogElement(BackupLogElement &&) = default;
+    BackupLogElement & operator=(BackupLogElement &&) = default;
+
+    std::chrono::system_clock::time_point event_time{};
+    Decimal64 event_time_usec{};
+    BackupOperationInfo info{};
+
+    static std::string name() { return "BackupLog"; }
+    static NamesAndTypesList getNamesAndTypes();
+    static NamesAndAliases getNamesAndAliases() { return {}; }
+    void appendToBlock(MutableColumns & columns) const;
+    static const char * getCustomColumnList() { return nullptr; }
+};
+
+class BackupLog : public SystemLog<BackupLogElement>
+{
+    using SystemLog<BackupLogElement>::SystemLog;
+
+public:
+    static const char * getDefaultOrderBy() { return "event_date, event_time_microseconds"; }
+};
+
+}
diff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp
index 59d778d1a67e..c3601ee9d905 100644
--- a/src/Interpreters/Context.cpp
+++ b/src/Interpreters/Context.cpp
@@ -64,8 +64,6 @@
 #include <Interpreters/InterserverCredentials.h>
 #include <Interpreters/Cluster.h>
 #include <Interpreters/InterserverIOHandler.h>
-#include <Interpreters/SystemLog.h>
-#include <Interpreters/SessionLog.h>
 #include <Interpreters/Context.h>
 #include <Interpreters/DDLWorker.h>
 #include <Interpreters/DDLTask.h>
@@ -3421,6 +3419,16 @@ std::shared_ptr<AsynchronousInsertLog> Context::getAsynchronousInsertLog() const
     return shared->system_logs->asynchronous_insert_log;
 }
 
+std::shared_ptr<BackupLog> Context::getBackupLog() const
+{
+    auto lock = getLock();
+
+    if (!shared->system_logs)
+        return {};
+
+    return shared->system_logs->backup_log;
+}
+
 std::vector<ISystemLog *> Context::getSystemLogs() const
 {
     auto lock = getLock();
diff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h
index 88c5b9e71dce..0eeea5b4fbdb 100644
--- a/src/Interpreters/Context.h
+++ b/src/Interpreters/Context.h
@@ -104,6 +104,7 @@ class ProcessorsProfileLog;
 class FilesystemCacheLog;
 class FilesystemReadPrefetchesLog;
 class AsynchronousInsertLog;
+class BackupLog;
 class IAsynchronousReader;
 struct MergeTreeSettings;
 struct InitialAllRangesAnnouncement;
@@ -1015,6 +1016,7 @@ class Context: public std::enable_shared_from_this<Context>
     std::shared_ptr<FilesystemCacheLog> getFilesystemCacheLog() const;
     std::shared_ptr<FilesystemReadPrefetchesLog> getFilesystemReadPrefetchesLog() const;
     std::shared_ptr<AsynchronousInsertLog> getAsynchronousInsertLog() const;
+    std::shared_ptr<BackupLog> getBackupLog() const;
 
     std::vector<ISystemLog *> getSystemLogs() const;
 
diff --git a/src/Interpreters/InterpreterBackupQuery.cpp b/src/Interpreters/InterpreterBackupQuery.cpp
index e238286a33cf..be5fcedce271 100644
--- a/src/Interpreters/InterpreterBackupQuery.cpp
+++ b/src/Interpreters/InterpreterBackupQuery.cpp
@@ -17,7 +17,7 @@ namespace DB
 
 namespace
 {
-    Block getResultRow(const BackupsWorker::Info & info)
+    Block getResultRow(const BackupOperationInfo & info)
     {
         auto column_id = ColumnString::create();
         auto column_status = ColumnInt8::create();
diff --git a/src/Interpreters/InterpreterSystemQuery.cpp b/src/Interpreters/InterpreterSystemQuery.cpp
index 20c0a2896372..12db14973bb6 100644
--- a/src/Interpreters/InterpreterSystemQuery.cpp
+++ b/src/Interpreters/InterpreterSystemQuery.cpp
@@ -36,6 +36,7 @@
 #include <Interpreters/TransactionsInfoLog.h>
 #include <Interpreters/ProcessorsProfileLog.h>
 #include <Interpreters/AsynchronousInsertLog.h>
+#include <Interpreters/BackupLog.h>
 #include <Interpreters/JIT/CompiledExpressionCache.h>
 #include <Interpreters/TransactionLog.h>
 #include <Interpreters/AsynchronousInsertQueue.h>
diff --git a/src/Interpreters/SystemLog.cpp b/src/Interpreters/SystemLog.cpp
index 23a5a96584ca..07ef6c33d29b 100644
--- a/src/Interpreters/SystemLog.cpp
+++ b/src/Interpreters/SystemLog.cpp
@@ -20,6 +20,7 @@
 #include <Interpreters/FilesystemCacheLog.h>
 #include <Interpreters/FilesystemReadPrefetchesLog.h>
 #include <Interpreters/ZooKeeperLog.h>
+#include <Interpreters/BackupLog.h>
 #include <Parsers/ASTCreateQuery.h>
 #include <Parsers/ASTFunction.h>
 #include <Parsers/ASTIndexDeclaration.h>
@@ -287,6 +288,7 @@ SystemLogs::SystemLogs(ContextPtr global_context, const Poco::Util::AbstractConf
         global_context, "system", "transactions_info_log", config, "transactions_info_log");
     processors_profile_log = createSystemLog<ProcessorsProfileLog>(global_context, "system", "processors_profile_log", config, "processors_profile_log");
     asynchronous_insert_log = createSystemLog<AsynchronousInsertLog>(global_context, "system", "asynchronous_insert_log", config, "asynchronous_insert_log");
+    backup_log = createSystemLog<BackupLog>(global_context, "system", "backup_log", config, "backup_log");
 
     if (query_log)
         logs.emplace_back(query_log.get());
@@ -325,6 +327,8 @@ SystemLogs::SystemLogs(ContextPtr global_context, const Poco::Util::AbstractConf
         logs.emplace_back(filesystem_read_prefetches_log.get());
     if (asynchronous_insert_log)
         logs.emplace_back(asynchronous_insert_log.get());
+    if (backup_log)
+        logs.emplace_back(backup_log.get());
 
     try
     {
diff --git a/src/Interpreters/SystemLog.h b/src/Interpreters/SystemLog.h
index cf287ad77754..ec04e1f4162b 100644
--- a/src/Interpreters/SystemLog.h
+++ b/src/Interpreters/SystemLog.h
@@ -49,6 +49,7 @@ class ProcessorsProfileLog;
 class FilesystemCacheLog;
 class FilesystemReadPrefetchesLog;
 class AsynchronousInsertLog;
+class BackupLog;
 
 /// System logs should be destroyed in destructor of the last Context and before tables,
 ///  because SystemLog destruction makes insert query while flushing data into underlying tables
@@ -84,6 +85,8 @@ struct SystemLogs
     /// Used to log processors profiling
     std::shared_ptr<ProcessorsProfileLog> processors_profile_log;
     std::shared_ptr<AsynchronousInsertLog> asynchronous_insert_log;
+    /// Backup and restore events
+    std::shared_ptr<BackupLog> backup_log;
 
     std::vector<ISystemLog *> logs;
 };
diff --git a/src/Storages/MergeTree/IDataPartStorage.h b/src/Storages/MergeTree/IDataPartStorage.h
index 2dd3805d2fcb..c76b17f33702 100644
--- a/src/Storages/MergeTree/IDataPartStorage.h
+++ b/src/Storages/MergeTree/IDataPartStorage.h
@@ -55,8 +55,6 @@ struct MergeTreeDataPartChecksums;
 class IReservation;
 using ReservationPtr = std::unique_ptr<IReservation>;
 
-class IStoragePolicy;
-
 class IDisk;
 using DiskPtr = std::shared_ptr<IDisk>;
 
diff --git a/src/Storages/StorageBuffer.cpp b/src/Storages/StorageBuffer.cpp
index eb154d0d9430..e011565edc17 100644
--- a/src/Storages/StorageBuffer.cpp
+++ b/src/Storages/StorageBuffer.cpp
@@ -1,7 +1,6 @@
 #include <boost/range/algorithm_ext/erase.hpp>
 #include <Interpreters/InterpreterSelectQuery.h>
 #include <Interpreters/InterpreterInsertQuery.h>
-#include <Interpreters/InterpreterAlterQuery.h>
 #include <Interpreters/castColumn.h>
 #include <Interpreters/evaluateConstantExpression.h>
 #include <Interpreters/addMissingDefaults.h>
diff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp
index f3d8f8773e2e..4f27cbc76ed8 100644
--- a/src/Storages/StorageMergeTree.cpp
+++ b/src/Storages/StorageMergeTree.cpp
@@ -13,7 +13,6 @@
 #include <Common/ProfileEventsScope.h>
 #include <Common/typeid_cast.h>
 #include <Common/ThreadPool.h>
-#include <Interpreters/InterpreterAlterQuery.h>
 #include <Interpreters/PartLog.h>
 #include <Interpreters/MutationsInterpreter.h>
 #include <Interpreters/Context.h>
diff --git a/src/Storages/StorageNull.cpp b/src/Storages/StorageNull.cpp
index 0ced128c8ef5..5e4fde99306b 100644
--- a/src/Storages/StorageNull.cpp
+++ b/src/Storages/StorageNull.cpp
@@ -2,7 +2,6 @@
 #include <Storages/StorageFactory.h>
 #include <Storages/AlterCommands.h>
 
-#include <Interpreters/InterpreterAlterQuery.h>
 #include <Interpreters/Context.h>
 #include <Databases/IDatabase.h>
 
diff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp
index 5e4a8add5e52..cf5314e42b7c 100644
--- a/src/Storages/StorageReplicatedMergeTree.cpp
+++ b/src/Storages/StorageReplicatedMergeTree.cpp
@@ -87,7 +87,6 @@
 #include <Interpreters/ClusterProxy/executeQuery.h>
 #include <Interpreters/Context.h>
 #include <Interpreters/DDLTask.h>
-#include <Interpreters/InterpreterAlterQuery.h>
 #include <Interpreters/InterpreterSelectQuery.h>
 #include <Interpreters/InterpreterSelectQueryAnalyzer.h>
 #include <Interpreters/InterserverCredentials.h>
diff --git a/src/Storages/System/StorageSystemBackups.cpp b/src/Storages/System/StorageSystemBackups.cpp
index 8e968f8f7c03..6fac9b048856 100644
--- a/src/Storages/System/StorageSystemBackups.cpp
+++ b/src/Storages/System/StorageSystemBackups.cpp
@@ -51,7 +51,7 @@ void StorageSystemBackups::fillData(MutableColumns & res_columns, ContextPtr con
     auto & column_num_read_files = assert_cast<ColumnUInt64 &>(*res_columns[column_index++]);
     auto & column_num_read_bytes = assert_cast<ColumnUInt64 &>(*res_columns[column_index++]);
 
-    auto add_row = [&](const BackupsWorker::Info & info)
+    auto add_row = [&](const BackupOperationInfo & info)
     {
         column_id.insertData(info.id.data(), info.id.size());
         column_name.insertData(info.name.data(), info.name.size());
