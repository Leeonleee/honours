{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 75577,
  "instance_id": "ClickHouse__ClickHouse-75577",
  "issue_numbers": [
    "74713"
  ],
  "base_commit": "fd436a635685ecb50280db03e94ede597c106e75",
  "patch": "diff --git a/base/poco/Foundation/include/Poco/Logger.h b/base/poco/Foundation/include/Poco/Logger.h\nindex f7da3c08fa32..74ddceea9dd5 100644\n--- a/base/poco/Foundation/include/Poco/Logger.h\n+++ b/base/poco/Foundation/include/Poco/Logger.h\n@@ -952,8 +952,6 @@ class Foundation_API Logger : public Channel\n     static std::pair<LoggerMapIterator, bool> add(Logger * pLogger);\n     static std::optional<LoggerMapIterator> find(const std::string & name);\n     static Logger * findRawPtr(const std::string & name);\n-    void unsafeSetChannel(Channel * pChannel);\n-    Channel* unsafeGetChannel() const;\n \n     Logger();\n     Logger(const Logger &);\ndiff --git a/base/poco/Foundation/src/Logger.cpp b/base/poco/Foundation/src/Logger.cpp\nindex 55564a7a1759..779af384b0be 100644\n--- a/base/poco/Foundation/src/Logger.cpp\n+++ b/base/poco/Foundation/src/Logger.cpp\n@@ -61,13 +61,6 @@ Logger::~Logger()\n \n \n void Logger::setChannel(Channel* pChannel)\n-{\n-\tstd::lock_guard<std::mutex> lock(getLoggerMutex());\n-\tunsafeSetChannel(pChannel);\n-}\n-\n-\n-void Logger::unsafeSetChannel(Channel* pChannel)\n {\n \tif (_pChannel) _pChannel->release();\n \t_pChannel = pChannel;\n@@ -76,14 +69,6 @@ void Logger::unsafeSetChannel(Channel* pChannel)\n \n \n Channel* Logger::getChannel() const\n-{\n-\tstd::lock_guard<std::mutex> lock(getLoggerMutex());\n-\n-\treturn unsafeGetChannel();\n-}\n-\n-\n-Channel* Logger::unsafeGetChannel() const\n {\n \treturn _pChannel;\n }\n@@ -104,7 +89,7 @@ void Logger::setLevel(const std::string& level)\n void Logger::setProperty(const std::string& name, const std::string& value)\n {\n \tif (name == \"channel\")\n-\t\tunsafeSetChannel(LoggingRegistry::defaultRegistry().channelForName(value));\n+\t\tsetChannel(LoggingRegistry::defaultRegistry().channelForName(value));\n \telse if (name == \"level\")\n \t\tsetLevel(value);\n \telse\n@@ -175,7 +160,7 @@ void Logger::setChannel(const std::string& name, Channel* pChannel)\n \t\t\tif (len == 0 ||\n \t\t\t\t(it.first.compare(0, len, name) == 0 && (it.first.length() == len || it.first[len] == '.')))\n \t\t\t{\n-\t\t\t\tit.second.logger->unsafeSetChannel(pChannel);\n+\t\t\t\tit.second.logger->setChannel(pChannel);\n \t\t\t}\n \t\t}\n \t}\n@@ -408,7 +393,7 @@ std::pair<Logger::LoggerMapIterator, bool> Logger::unsafeGet(const std::string&\n \t\telse\n \t\t{\n \t\t\tLogger& par = parent(name);\n-\t\t\tlogger = new Logger(name, par.unsafeGetChannel(), par.getLevel());\n+\t\t\tlogger = new Logger(name, par.getChannel(), par.getLevel());\n \t\t}\n \n \t\treturn add(logger);\ndiff --git a/docs/en/operations/server-configuration-parameters/settings.md b/docs/en/operations/server-configuration-parameters/settings.md\nindex 30440522b4ab..b8cbf4f555f8 100644\n--- a/docs/en/operations/server-configuration-parameters/settings.md\n+++ b/docs/en/operations/server-configuration-parameters/settings.md\n@@ -13,7 +13,7 @@ import TabItem from '@theme/TabItem';\n \n This section contains descriptions of server settings that cannot be changed at the session or query level. These settings are stored in the `config.xml` file on the ClickHouse server. For more information on configuration files in ClickHouse see [\"Configuration Files\"](/docs/en/operations/configuration-files).\n \n-Other settings are described in the \u201c[Settings](../../operations/settings/index.md#session-settings-intro)\u201d section. \n+Other settings are described in the \u201c[Settings](../../operations/settings/index.md#session-settings-intro)\u201d section.\n Before studying the settings, we recommend to read the [Configuration files](../../operations/configuration-files.md#configuration_files) section and note the use of substitutions (the `incl` and `optional` attributes).\n \n ## allow_use_jemalloc_memory\n@@ -121,7 +121,7 @@ Default: `16`\n \n ## background_merges_mutations_concurrency_ratio\n \n-Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently. \n+Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.\n \n For example, if the ratio equals to 2 and [`background_pool_size`](#background_pool_size) is set to 16 then ClickHouse can execute 32 background merges concurrently. This is possible, because background operations could be suspended and postponed. This is needed to give small merges more execution priority.\n \n@@ -430,11 +430,11 @@ Default: `1000`\n \n ## max_concurrent_queries\n \n-Limit on total number of concurrently executed queries. Note that limits on `INSERT` and `SELECT` queries, and on the maximum number of queries for users must also be considered. \n+Limit on total number of concurrently executed queries. Note that limits on `INSERT` and `SELECT` queries, and on the maximum number of queries for users must also be considered.\n \n-See also: \n+See also:\n - [`max_concurrent_insert_queries`](#max_concurrent_insert_queries)\n-- [`max_concurrent_select_queries`](#max_concurrent_select_queries) \n+- [`max_concurrent_select_queries`](#max_concurrent_select_queries)\n - [`max_concurrent_queries_for_all_users`](/docs/en/operations/settings/settings/#max_concurrent_queries_for_all_users)\n \n :::note\n@@ -465,7 +465,7 @@ Default: `0`\n \n ## max_concurrent_select_queries\n \n-Limit on total number of concurrently select queries. \n+Limit on total number of concurrently select queries.\n \n :::note\n \n@@ -481,12 +481,12 @@ Default: `0`\n ## max_waiting_queries\n \n Limit on total number of concurrently waiting queries.\n-Execution of a waiting query is blocked while required tables are loading asynchronously (see [`async_load_databases`](#async_load_databases). \n+Execution of a waiting query is blocked while required tables are loading asynchronously (see [`async_load_databases`](#async_load_databases).\n \n :::note\n Waiting queries are not counted when limits controlled by the following settings are checked:\n \n-- [`max_concurrent_queries`](#max_concurrent_queries) \n+- [`max_concurrent_queries`](#max_concurrent_queries)\n - [`max_concurrent_insert_queries`](#max_concurrent_insert_queries)\n - [`max_concurrent_select_queries`](#max_concurrent_select_queries)\n - [`max_concurrent_queries_for_user`](/docs/en/operations/settings/settings#max_concurrent_select_queries)\n@@ -646,7 +646,7 @@ Interval in seconds during which the server's maximum allowed memory consumption\n \n To disable the cgroup observer, set this value to `0`.\n \n-see settings: \n+see settings:\n - [`cgroup_memory_watcher_hard_limit_ratio`](#cgroup_memory_watcher_hard_limit_ratio)\n - [`cgroup_memory_watcher_soft_limit_ratio`](#cgroup_memory_watcher_soft_limit_ratio).\n \n@@ -750,7 +750,7 @@ Default: `100000`\n \n ## max_table_num_to_throw\n \n-If number of tables is greater than this value, server will throw an exception. \n+If number of tables is greater than this value, server will throw an exception.\n \n The following tables are not counted:\n - view\n@@ -779,7 +779,7 @@ Default: `0`\n \n ## max_replicated_table_num_to_throw\n \n-If the number of replicated tables is greater than this value, the server will throw an exception. \n+If the number of replicated tables is greater than this value, the server will throw an exception.\n \n Only counts tables for database engines:\n - Atomic\n@@ -911,7 +911,7 @@ Default: `10000`\n \n ## mmap_cache_size\n \n-Sets the cache size (in bytes) for mapped files. This setting allows avoiding frequent open/close calls (which are very expensive due to consequent page faults), and to reuse mappings from several threads and queries. The setting value is the number of mapped regions (usually equal to the number of mapped files). \n+Sets the cache size (in bytes) for mapped files. This setting allows avoiding frequent open/close calls (which are very expensive due to consequent page faults), and to reuse mappings from several threads and queries. The setting value is the number of mapped regions (usually equal to the number of mapped files).\n \n The amount of data in mapped files can be monitored in the following system tables with the following metrics:\n \n@@ -1388,7 +1388,7 @@ Default: `16`\n ## database_catalog_unused_dir_cleanup_period_sec\n \n Parameter of a task that cleans up garbage from `store/` directory.\n-Sets scheduling period of the task. \n+Sets scheduling period of the task.\n \n :::note\n A value of `0` means \"never\". The default value corresponds to 1 day.\n@@ -1597,7 +1597,7 @@ A value of `0` means ClickHouse disables HSTS. If you set a positive number, the\n \n ## mlock_executable\n \n-Perform `mlockall` after startup to lower first queries latency and to prevent clickhouse executable from being paged out under high IO load. \n+Perform `mlockall` after startup to lower first queries latency and to prevent clickhouse executable from being paged out under high IO load.\n \n :::note\n Enabling this option is recommended but will lead to increased startup time for up to a few seconds.\n@@ -1828,11 +1828,9 @@ The location and format of log messages.\n | `stream_compress`         | Compress log messages using LZ4. Set to `1` or `true` to enable.                                                                                                                    |\n | `console`                 | Do not write log messages to log files, instead print them in the console. Set to `1` or `true` to enable. Default is `1` if Clickhouse does not run in daemon mode, `0` otherwise. |\n | `console_log_level`       | Log level for console output. Defaults to `level`.                                                                                                                                  |\n-| `formatting`              | Log format for console output. Currently, only `json` is supported                                                                                                                  | \n+| `formatting`              | Log format for console output. Currently, only `json` is supported                                                                                                                  |\n | `use_syslog`              | Also forward log output to syslog.                                                                                                                                                  |\n | `syslog_level`            | Log level for logging to syslog.                                                                                                                                                    |\n-| `message_regexp`          | Only log messages that match this regular expression. Defaults to `\"\"`, indicating no filtering.                                                                                    |\n-| `message_regexp_negative` | Only log messages that don't match this regular expression. Defaults to `\"\"`, indicating no filtering.                                                                              |\n \n **Log format specifiers**\n \n@@ -1921,27 +1919,6 @@ The log level of individual log names can be overridden. For example, to mute al\n </logger>\n ```\n \n-**Regular Expression Filtering**\n-\n-The messages logged can be filtered using regular expressions using `message_regexp` and `message_regexp_negative`. This can be done on a per-level basis or globally. If both a global and logger-specific pattern is specified, the global pattern is overridden (ignored) and only the logger-specific pattern applies. The positive and negative patterns are considered independently for this situation. Note: Using this feature may cause a slight slowdown in performance.\n-\n-```xml\n-    <logger>\n-        <level>trace</level>\n-        <!-- Global: Don't log Trace messages -->\n-        <message_regexp_negative>.*Trace.*</message_regexp_negative>\n-\n-        <message_regexps>\n-            <logger>\n-                <!-- For the executeQuery logger, only log if message has \"Read\", but not \"from\" -->\n-                <name>executeQuery</name>\n-                <message_regexp>.*Read.*</message_regexp>\n-                <message_regexp_negative>.*from.*</message_regexp_negative>\n-            </logger>\n-        </message_regexps>\n-    </logger>\n-```\n-\n **syslog**\n \n To write log messages additionally to syslog:\n@@ -1969,7 +1946,7 @@ Keys for `<syslog>`:\n \n **Log formats**\n \n-You can specify the log format that will be outputted in the console log. Currently, only JSON is supported. \n+You can specify the log format that will be outputted in the console log. Currently, only JSON is supported.\n \n **Example**\n \n@@ -2117,12 +2094,12 @@ Default: 50 GB.\n \n ## background_pool_size\n \n-Sets the number of threads performing background merges and mutations for tables with MergeTree engines. \n+Sets the number of threads performing background merges and mutations for tables with MergeTree engines.\n \n :::note\n-- This setting could also be applied at server startup from the `default` profile configuration for backward compatibility at the ClickHouse server start. \n-- You can only increase the number of threads at runtime. \n-- To lower the number of threads you have to restart the server. \n+- This setting could also be applied at server startup from the `default` profile configuration for backward compatibility at the ClickHouse server start.\n+- You can only increase the number of threads at runtime.\n+- To lower the number of threads you have to restart the server.\n - By adjusting this setting, you manage CPU and disk load.\n :::\n \n@@ -2359,10 +2336,10 @@ Use the following parameters to configure logging:\n | `engine`                           | [MergeTree Engine Definition](../../engines/table-engines/mergetree-family/mergetree.md#table_engine-mergetree-creating-a-table) for a system table. Can't be used if `partition_by` or `order_by` defined. |                     |\n | `flush_interval_milliseconds`      | Interval for flushing data from the buffer in memory to the table.                                                                                                                                          |                     |\n | `max_size_rows`                    | Maximal size in lines for the logs. When non-flushed logs amount reaches max_size, logs dumped to the disk.                                                                                                 | `1048576`           |\n-| `reserved_size_rows`               | Pre-allocated memory size in lines for the logs.                                                                                                                                                            | `8192`              | \n+| `reserved_size_rows`               | Pre-allocated memory size in lines for the logs.                                                                                                                                                            | `8192`              |\n | `buffer_size_rows_flush_threshold` | Lines amount threshold, reaching it launches flushing logs to the disk in background.                                                                                                                       | `max_size_rows / 2` |\n | `flush_on_crash`                   | Indication whether logs should be dumped to the disk in case of a crash.                                                                                                                                    | `false`             |\n-| `storage_policy`                   | Name of storage policy to use for the table (optional)                                                                                                                                                      |                     | \n+| `storage_policy`                   | Name of storage policy to use for the table (optional)                                                                                                                                                      |                     |\n | `settings`                         | [Additional parameters](../../engines/table-engines/mergetree-family/mergetree.md/#settings) that control the behavior of the MergeTree (optional).                                                         |                     |\n \n **Example**\n@@ -2545,7 +2522,7 @@ Use the following parameters to configure logging:\n | Parameter                          | Description                                                                                                                                                                                                     | Default Value       |\n |------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------|\n | `database`                         | Name of the database.                                                                                                                                                                                           |                     |\n-| `table`                            | Name of the system table the queries will be logged in.                                                                                                                                                         |                     | \n+| `table`                            | Name of the system table the queries will be logged in.                                                                                                                                                         |                     |\n | `partition_by`                     | [Custom partitioning key](../../engines/table-engines/mergetree-family/custom-partitioning-key.md) for a system table. Can't be used if `engine` is defined.                                                                                                                        |                     |\n | `order_by`                         | [Custom sorting key](../../engines/table-engines/mergetree-family/mergetree.md#order_by) for a system table. Can't be used if `engine` is defined.                                                                                                                             |                     |\n | `engine`                           | [MergeTree Engine Definition](../../engines/table-engines/mergetree-family/mergetree.md#table_engine-mergetree-creating-a-table) for a system table. Can't be used if `partition_by` or `order_by` are defined. |                     |\n@@ -2554,7 +2531,7 @@ Use the following parameters to configure logging:\n | `reserved_size_rows`               | Pre-allocated memory size in lines for the logs.                                                                                                                                                                | `8192`              |\n | `buffer_size_rows_flush_threshold` | Lines amount threshold, reaching it launches flushing logs to the disk in background.                                                                                                                           | `max_size_rows / 2` |\n | `flush_on_crash`                   | Indication whether logs should be dumped to the disk in case of a crash                                                                                                                                         | `false`             |\n-| `storage_policy`                   | Name of storage policy to use for the table (optional)                                                                                                                                                          |                     |                                                                                                                                         \n+| `storage_policy`                   | Name of storage policy to use for the table (optional)                                                                                                                                                          |                     |\n | `settings`                         | [Additional parameters](../../engines/table-engines/mergetree-family/mergetree.md/#settings) that control the behavior of the MergeTree (optional).                                                             |                     |\n \n If the table does not exist, ClickHouse will create it. If the structure of the query thread log changed when the ClickHouse server was updated, the table with the old structure is renamed, and a new table is created automatically.\n@@ -3077,7 +3054,7 @@ Storage method for data part headers in ZooKeeper. This setting only applies to\n \n ClickHouse uses the setting for all the tables on the server. You can change the setting at any time. Existing tables change their behaviour when the setting changes.\n \n-**For each table** \n+**For each table**\n \n When creating a table, specify the corresponding [engine setting](../../engines/table-engines/mergetree-family/mergetree.md#table_engine-mergetree-creating-a-table). The behaviour of an existing table with this setting does not change, even if the global setting changes.\n \n@@ -3261,7 +3238,7 @@ Default: `0`\n \n Define proxy servers for HTTP and HTTPS requests, currently supported by S3 storage, S3 table functions, and URL functions.\n \n-There are three ways to define proxy servers: \n+There are three ways to define proxy servers:\n - environment variables\n - proxy lists\n - remote proxy resolvers.\n@@ -3524,7 +3501,7 @@ Changing this setting does not affect existing users. Create/alter authenticatio\n Non authentication create/alter queries will succeed.\n \n :::note\n-A value of `0` means unlimited. \n+A value of `0` means unlimited.\n :::\n \n Type: UInt64\ndiff --git a/src/Loggers/Loggers.cpp b/src/Loggers/Loggers.cpp\nindex ce91a07fabd7..e7bfb0754fdf 100644\n--- a/src/Loggers/Loggers.cpp\n+++ b/src/Loggers/Loggers.cpp\n@@ -1,14 +1,12 @@\n #include \"Loggers.h\"\n \n-#include <Loggers/OwnFilteringChannel.h>\n-#include <Loggers/OwnFormattingChannel.h>\n-#include <Loggers/OwnPatternFormatter.h>\n-#include <Loggers/OwnSplitChannel.h>\n+#include \"OwnFormattingChannel.h\"\n+#include \"OwnPatternFormatter.h\"\n+#include \"OwnSplitChannel.h\"\n \n #include <iostream>\n #include <sstream>\n \n-#include <Poco/AutoPtr.h>\n #include <Poco/ConsoleChannel.h>\n #include <Poco/Logger.h>\n #include <Poco/Net/RemoteSyslogChannel.h>\n@@ -224,18 +222,6 @@ void Loggers::buildLoggers(Poco::Util::AbstractConfiguration & config, Poco::Log\n     logger.close();\n \n     logger.setChannel(split);\n-\n-    const std::string global_pos_pattern = config.getRawString(\"logger.message_regexp\", \"\");\n-    const std::string global_neg_pattern = config.getRawString(\"logger.message_regexp_negative\", \"\");\n-\n-    Poco::AutoPtr<OwnPatternFormatter> pf;\n-    if (config.getString(\"logger.formatting.type\", \"\") == \"json\")\n-        pf = new OwnJSONPatternFormatter(config);\n-    else\n-        pf = new OwnPatternFormatter;\n-\n-    DB::createOrUpdateFilterChannel(logger, global_pos_pattern, global_neg_pattern, pf, Poco::Logger::ROOT);\n-\n     logger.setLevel(max_log_level);\n \n     // Global logging level and channel (it can be overridden for specific loggers).\n@@ -250,8 +236,6 @@ void Loggers::buildLoggers(Poco::Util::AbstractConfiguration & config, Poco::Log\n     {\n         logger.get(name).setLevel(max_log_level);\n         logger.get(name).setChannel(split);\n-\n-        DB::createOrUpdateFilterChannel(logger.get(name), global_pos_pattern, global_neg_pattern, pf, name);\n     }\n \n     // Explicitly specified log levels for specific loggers.\n@@ -278,26 +262,6 @@ void Loggers::buildLoggers(Poco::Util::AbstractConfiguration & config, Poco::Log\n             }\n         }\n     }\n-    // Explicitly specified regexp patterns for filtering specific loggers\n-    {\n-        Poco::Util::AbstractConfiguration::Keys loggers_regexp;\n-        config.keys(\"logger.message_regexps\", loggers_regexp);\n-\n-        if (!loggers_regexp.empty())\n-        {\n-            for (const auto & key : loggers_regexp)\n-            {\n-                if (key == \"logger\" || key.starts_with(\"logger[\"))\n-                {\n-                    const std::string name = config.getString(\"logger.message_regexps.\" + key + \".name\");\n-                    const std::string pos_pattern = config.getRawString(\"logger.message_regexps.\" + key + \".message_regexp\", global_pos_pattern);\n-                    const std::string neg_pattern = config.getRawString(\"logger.message_regexps.\" + key + \".message_regexp_negative\", global_neg_pattern);\n-\n-                    DB::createOrUpdateFilterChannel(logger.root().get(name), pos_pattern, neg_pattern, pf, name);\n-                }\n-            }\n-        }\n-    }\n #ifndef WITHOUT_TEXT_LOG\n     if (allowTextLog() && config.has(\"text_log\"))\n     {\n@@ -383,32 +347,16 @@ void Loggers::updateLevels(Poco::Util::AbstractConfiguration & config, Poco::Log\n     }\n     split->setLevel(\"syslog\", syslog_level);\n \n-    const std::string global_pos_pattern = config.getRawString(\"logger.message_regexp\", \"\");\n-    const std::string global_neg_pattern = config.getRawString(\"logger.message_regexp_negative\", \"\");\n-\n-    Poco::AutoPtr<OwnPatternFormatter> pf;\n-    if (config.getString(\"logger.formatting.type\", \"\") == \"json\")\n-        pf = new OwnJSONPatternFormatter(config);\n-    else\n-        pf = new OwnPatternFormatter;\n-\n-    DB::createOrUpdateFilterChannel(logger, global_pos_pattern, global_neg_pattern, pf, Poco::Logger::ROOT);\n-\n     // Global logging level (it can be overridden for specific loggers).\n     logger.setLevel(max_log_level);\n \n     // Set level to all already created loggers\n     std::vector<std::string> names;\n-    logger.root().names(names);\n \n-    // Set all to global in case logger.levels are not specified\n+    logger.root().names(names);\n     for (const auto & name : names)\n-    {\n         logger.root().get(name).setLevel(max_log_level);\n \n-        DB::createOrUpdateFilterChannel(logger.root().get(name), global_pos_pattern, global_neg_pattern, pf, name);\n-    }\n-\n     logger.root().setLevel(max_log_level);\n \n     // Explicitly specified log levels for specific loggers.\n@@ -435,27 +383,6 @@ void Loggers::updateLevels(Poco::Util::AbstractConfiguration & config, Poco::Log\n             }\n         }\n     }\n-\n-    // Explicitly specified regexp patterns for filtering specific loggers\n-    {\n-        Poco::Util::AbstractConfiguration::Keys loggers_regexp;\n-        config.keys(\"logger.message_regexps\", loggers_regexp);\n-\n-        if (!loggers_regexp.empty())\n-        {\n-            for (const auto & key : loggers_regexp)\n-            {\n-                if (key == \"logger\" || key.starts_with(\"logger[\"))\n-                {\n-                    const std::string name(config.getString(\"logger.message_regexps.\" + key + \".name\"));\n-                    const std::string pos_pattern(config.getRawString(\"logger.message_regexps.\" + key + \".message_regexp\", global_pos_pattern));\n-                    const std::string neg_pattern(config.getRawString(\"logger.message_regexps.\" + key + \".message_regexp_negative\", global_neg_pattern));\n-\n-                    DB::createOrUpdateFilterChannel(logger.root().get(name), pos_pattern, neg_pattern, pf, name);\n-                }\n-            }\n-        }\n-    }\n }\n \n /// NOLINTEND(readability-static-accessed-through-instance)\ndiff --git a/src/Loggers/OwnFilteringChannel.cpp b/src/Loggers/OwnFilteringChannel.cpp\ndeleted file mode 100644\nindex 36193c463142..000000000000\n--- a/src/Loggers/OwnFilteringChannel.cpp\n+++ /dev/null\n@@ -1,96 +0,0 @@\n-#include <shared_mutex>\n-#include <Loggers/OwnFilteringChannel.h>\n-#include <Poco/RegularExpression.h>\n-\n-\n-namespace DB\n-{\n-\n-void OwnFilteringChannel::log(const Poco::Message & msg)\n-{\n-    if (regexpFilteredOut(msg))\n-        return;\n-\n-    pChannel->log(msg);\n-}\n-\n-bool OwnFilteringChannel::regexpFilteredOut(const Poco::Message & msg)\n-{\n-    std::string formatted_text;\n-    auto [pos_pattern, neg_pattern] = safeGetPatterns();\n-\n-    // Skip checks if both patterns are empty\n-    if (!pos_pattern.empty() || !neg_pattern.empty())\n-    {\n-        // Apply formatting to the text\n-        if (pFormatter)\n-        {\n-            pFormatter->formatExtended(ExtendedLogMessage::getFrom(msg), formatted_text);\n-        }\n-        else\n-        {\n-            formatted_text = msg.getText();\n-        }\n-\n-        // Check for patterns in formatted text\n-        Poco::RegularExpression positive_regexp(pos_pattern);\n-        if (!pos_pattern.empty() && !positive_regexp.match(formatted_text))\n-        {\n-            return true;\n-        }\n-\n-        Poco::RegularExpression negative_regexp(neg_pattern);\n-        if (!neg_pattern.empty() && negative_regexp.match(formatted_text))\n-        {\n-            return true;\n-        }\n-    }\n-\n-    return false;\n-}\n-\n-void OwnFilteringChannel::setRegexpPatterns(const std::string & new_pos_pattern, const std::string & new_neg_pattern)\n-{\n-    auto [old_pos_pattern, old_neg_pattern] = safeGetPatterns();\n-    if (old_pos_pattern != new_pos_pattern || old_neg_pattern != new_neg_pattern)\n-    {\n-        std::unique_lock<std::shared_mutex> write_lock(pattern_mutex);\n-        positive_pattern = new_pos_pattern;\n-        negative_pattern = new_neg_pattern;\n-    }\n-}\n-\n-std::pair<std::string, std::string> OwnFilteringChannel::safeGetPatterns()\n-{\n-    std::shared_lock<std::shared_mutex> read_lock(pattern_mutex);\n-    return std::make_pair(positive_pattern, negative_pattern);\n-}\n-\n-void createOrUpdateFilterChannel(Poco::Logger & logger, const std::string & pos_pattern, const std::string & neg_pattern, Poco::AutoPtr<OwnPatternFormatter> pf, const std::string & name)\n-{\n-    Poco::AutoPtr<Poco::Channel> src_channel(logger.getChannel(), true /*shared*/);\n-    Poco::AutoPtr<DB::OwnFilteringChannel> filter_channel(dynamic_cast<DB::OwnFilteringChannel*>(src_channel.get()), true);\n-\n-    // If this logger doesn't have it's own unique filter channel\n-    if (!filter_channel)\n-    {\n-        // Skip if regexp feature has never been used yet\n-        if (pos_pattern.empty() && neg_pattern.empty())\n-            return;\n-\n-        Poco::AutoPtr<DB::OwnFilteringChannel> new_filter_channel = new DB::OwnFilteringChannel(src_channel, pf, pos_pattern, neg_pattern, name);\n-        logger.setChannel(new_filter_channel);\n-    }\n-    // If logger has filter channel, but not it's own unique one (e.g copied from another by default), create copy\n-    else if (filter_channel->getAssignedLoggerName() != name)\n-    {\n-        Poco::AutoPtr<DB::OwnFilteringChannel> new_filter_channel = new DB::OwnFilteringChannel(filter_channel, pos_pattern, neg_pattern, name);\n-        logger.setChannel(new_filter_channel);\n-    }\n-    else\n-    {\n-        filter_channel->setRegexpPatterns(pos_pattern, neg_pattern);\n-    }\n-}\n-\n-}\ndiff --git a/src/Loggers/OwnFilteringChannel.h b/src/Loggers/OwnFilteringChannel.h\ndeleted file mode 100644\nindex 5dce6007baf0..000000000000\n--- a/src/Loggers/OwnFilteringChannel.h\n+++ /dev/null\n@@ -1,84 +0,0 @@\n-#pragma once\n-#include <Poco/AutoPtr.h>\n-#include <Poco/Channel.h>\n-#include <Poco/Message.h>\n-#include <Poco/Logger.h>\n-#include <Poco/Util/AbstractConfiguration.h>\n-#include <Loggers/OwnPatternFormatter.h>\n-#include <shared_mutex>\n-\n-\n-namespace DB\n-{\n-\n-// Filters the logs based on regular expressions. Should be processed after formatting channel to read entire formatted text\n-class OwnFilteringChannel : public Poco::Channel\n-{\n-public:\n-    explicit OwnFilteringChannel(Poco::AutoPtr<Poco::Channel> pChannel_, Poco::AutoPtr<OwnPatternFormatter> pf,\n-        const std::string & positive_pattern_, const std::string & negative_pattern_, const std::string & name_)\n-    : logger_name(name_), positive_pattern(positive_pattern_), negative_pattern(negative_pattern_), pChannel(pChannel_), pFormatter(pf)\n-    {\n-    }\n-\n-    explicit OwnFilteringChannel(Poco::AutoPtr<OwnFilteringChannel> other, const std::string & positive_pattern_, const std::string & negative_pattern_, const std::string & name_)\n-    : logger_name(name_), positive_pattern(positive_pattern_), negative_pattern(negative_pattern_), pChannel(other->pChannel), pFormatter(other->pFormatter)\n-    {\n-    }\n-\n-    // Only log if pass both positive and negative regexp checks.\n-    // Checks the regexps on the formatted text (without color), but then passes the raw text\n-    // to the split channel to handle formatting for individual channels (e.g apply color)\n-    void log(const Poco::Message & msg) override;\n-\n-    // Sets the regex patterns to use for filtering. Specifying an empty string pattern \"\" indicates no filtering\n-    void setRegexpPatterns(const std::string & new_pos_pattern, const std::string & new_neg_pattern);\n-\n-    std::string getAssignedLoggerName() const\n-    {\n-        return logger_name;\n-    }\n-\n-    void open() override\n-    {\n-        if (pChannel)\n-            pChannel->open();\n-    }\n-\n-    void close() override\n-    {\n-        if (pChannel)\n-            pChannel->close();\n-    }\n-\n-    void setProperty(const std::string & name, const std::string & value) override\n-    {\n-        if (pChannel)\n-            pChannel->setProperty(name, value);\n-    }\n-\n-    std::string getProperty(const std::string & name) const override\n-    {\n-        if (pChannel)\n-            return pChannel->getProperty(name);\n-        return \"\";\n-    }\n-\n-private:\n-    bool regexpFilteredOut(const Poco::Message & msg);\n-\n-    // Create copy safely, so we don't have to worry about race conditions from reading and writing at the same time\n-    std::pair<std::string, std::string> safeGetPatterns();\n-\n-    const std::string logger_name;\n-    std::string positive_pattern;\n-    std::string negative_pattern;\n-    Poco::AutoPtr<Poco::Channel> pChannel;\n-    Poco::AutoPtr<OwnPatternFormatter> pFormatter;\n-    std::shared_mutex pattern_mutex;\n-};\n-\n-// Creates filter channel only if needed or updates if it already exists\n-void createOrUpdateFilterChannel(Poco::Logger & logger, const std::string & pos_pattern, const std::string & neg_pattern, Poco::AutoPtr<OwnPatternFormatter> pf, const std::string & name = \"\");\n-\n-}\n",
  "test_patch": "diff --git a/tests/integration/test_regexp_logger/__init__.py b/tests/integration/test_regexp_logger/__init__.py\ndeleted file mode 100644\nindex e69de29bb2d1..000000000000\ndiff --git a/tests/integration/test_regexp_logger/configs/log.xml b/tests/integration/test_regexp_logger/configs/log.xml\ndeleted file mode 100644\nindex a85417d05b81..000000000000\n--- a/tests/integration/test_regexp_logger/configs/log.xml\n+++ /dev/null\n@@ -1,6 +0,0 @@\n-<clickhouse>\n-    <logger>\n-        <level>trace</level>\n-        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\n-    </logger>\n-</clickhouse>\n\\ No newline at end of file\ndiff --git a/tests/integration/test_regexp_logger/test.py b/tests/integration/test_regexp_logger/test.py\ndeleted file mode 100644\nindex 4f8a7e4be8f0..000000000000\n--- a/tests/integration/test_regexp_logger/test.py\n+++ /dev/null\n@@ -1,74 +0,0 @@\n-import re\n-\n-import pytest\n-\n-from helpers.cluster import ClickHouseCluster\n-\n-cluster = ClickHouseCluster(__file__)\n-node = cluster.add_instance(\n-    \"node\", with_zookeeper=False, main_configs=[\"configs/log.xml\"]\n-)\n-\n-original_config = \"\"\"\n-<clickhouse>\n-    <logger>\n-        <level>trace</level>\n-        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\n-    </logger>\n-</clickhouse>\n-\"\"\"\n-\n-updated_config = \"\"\"\n-<clickhouse>\n-    <logger>\n-        <level>trace</level>\n-        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\n-        <message_regexp_negative>.*Loaded config.*</message_regexp_negative>\n-        <message_regexps>\n-            <logger>\n-                <name>executeQuery</name>\n-                <message_regexp>.*Read.*</message_regexp>\n-                <message_regexp_negative>.*from.*</message_regexp_negative>\n-            </logger>\n-        </message_regexps>\n-    </logger>\n-</clickhouse>\n-\"\"\"\n-\n-\n-@pytest.fixture(scope=\"module\")\n-def start_cluster():\n-    try:\n-        cluster.start()\n-        yield cluster\n-\n-    finally:\n-        cluster.shutdown()\n-\n-\n-def test_regexp_pattern_update(start_cluster):\n-    # Display config being used\n-    node.exec_in_container([\"cat\", \"/etc/clickhouse-server/config.d/log.xml\"])\n-\n-    # Make sure that there are enough log messages for the test\n-    for _ in range(5):\n-        node.query(\"SYSTEM RELOAD CONFIG\")\n-        node.query(\"SELECT 1\")\n-\n-    assert node.contains_in_log(r\".*Loaded config.*\")\n-    assert node.contains_in_log(r\".*executeQuery.*Read.*\")\n-    assert node.contains_in_log(r\".*executeQuery.*from.*\")\n-\n-    node.replace_config(\"/etc/clickhouse-server/config.d/log.xml\", updated_config)\n-    node.query(\"SYSTEM RELOAD CONFIG;\")\n-    node.rotate_logs()\n-\n-    for _ in range(5):\n-        node.query(\"SYSTEM RELOAD CONFIG\")\n-        node.query(\"SELECT 1\")\n-\n-    assert not node.contains_in_log(r\".*Loaded config.*\")\n-    assert node.contains_in_log(r\".*executeQuery.*Read.*\")\n-    assert not node.contains_in_log(r\".*executeQuery.*from.*\")\n-\n-    node.replace_config(\"/etc/clickhouse-server/config.d/log.xml\", original_config)\n",
  "problem_statement": "Data race while modifying `OwnFilteringChannel`\n### Describe the bug\n\nData race detected when running `test_regexp_logger/test.py::test_regexp_pattern_update`\nIt happens because of parallel modification of channels and using those channels when logging.\nWe use raw pointer to channel https://github.com/ClickHouse/ClickHouse/blob/master/src/Common/logger_useful.h#L78\n\nI suspect it's introduced here https://github.com/ClickHouse/ClickHouse/pull/69657\ncc @antaljanosbenjamin @petern48 \n\n\n\n### How to reproduce\n\nCaught by test\nhttps://s3.amazonaws.com/clickhouse-test-reports/0/de252016d9d61bb2085a1b41385ac8b5943cc759/integration_tests__tsan__[3_6].html\n\n### Error message and/or stacktrace\n\n```\nLogging trace to /var/log/clickhouse-server/clickhouse-server.log\nLogging errors to /var/log/clickhouse-server/clickhouse-server.err.log\n==================\nWARNING: ThreadSanitizer: data race (pid=1)\n  Write of size 8 at 0x724000058500 by thread T655 (mutexes: write M0):\n    #0 operator delete(void*, unsigned long) <null> (clickhouse+0x7e47b68) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #1 DB::OwnFilteringChannel::~OwnFilteringChannel() build_docker/./src/Loggers/OwnFilteringChannel.h:15:7 (clickhouse+0x10ba7e0a) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #2 non-virtual thunk to DB::OwnFilteringChannel::~OwnFilteringChannel() build_docker/./src/Loggers/OwnFilteringChannel.h (clickhouse+0x10ba7e0a)\n    #3 Poco::RefCountedObject::release() const build_docker/./base/poco/Foundation/include/Poco/RefCountedObject.h:88:13 (clickhouse+0x10ba6e6f) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #4 Poco::AutoPtr<Poco::Channel>::~AutoPtr() build_docker/./base/poco/Foundation/include/Poco/AutoPtr.h:91:19 (clickhouse+0x10ba6e6f)\n    #5 DB::createOrUpdateFilterChannel(Poco::Logger&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, Poco::AutoPtr<OwnPatternFormatter>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) build_docker/./src/Loggers/OwnFilteringChannel.cpp:94:1 (clickhouse+0x10ba6e6f)\n    #6 Loggers::updateLevels(Poco::Util::AbstractConfiguration&, Poco::Logger&) build_docker/./src/Loggers/Loggers.cpp:409:9 (clickhouse+0x10ba3c28) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #7 DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_0::operator()(Poco::AutoPtr<Poco::Util::AbstractConfiguration>, bool) const build_docker/./programs/server/Server.cpp:1813:13 (clickhouse+0x10ad35c1) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #8 decltype(std::declval<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_0&>()(std::declval<Poco::AutoPtr<Poco::Util::AbstractConfiguration>>(), std::declval<bool>())) std::__1::__invoke[abi:ne180100]<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_0&, Poco::AutoPtr<Poco::Util::AbstractConfiguration>, bool>(DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_0&, Poco::AutoPtr<Poco::Util::AbstractConfiguration>&&, bool&&) build_docker/./contrib/llvm-project/libcxx/include/__type_traits/invoke.h:344:25 (clickhouse+0x10ad1d29) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #9 void std::__1::__invoke_void_return_wrapper<void, true>::__call[abi:ne180100]<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_0&, Poco::AutoPtr<Poco::Util::AbstractConfiguration>, bool>(DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_0&, Poco::AutoPtr<Poco::Util::AbstractConfiguration>&&, bool&&) build_docker/./contrib/llvm-project/libcxx/include/__type_traits/invoke.h:419:5 (clickhouse+0x10ad1d29)\n    #10 std::__1::__function::__default_alloc_func<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_0, void (Poco::AutoPtr<Poco::Util::AbstractConfiguration>, bool)>::operator()[abi:ne180100](Poco::AutoPtr<Poco::Util::AbstractConfiguration>&&, bool&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:208:12 (clickhouse+0x10ad1d29)\n    #11 void std::__1::__function::__policy_invoker<void (Poco::AutoPtr<Poco::Util::AbstractConfiguration>, bool)>::__call_impl[abi:ne180100]<std::__1::__function::__default_alloc_func<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_0, void (Poco::AutoPtr<Poco::Util::AbstractConfiguration>, bool)>>(std::__1::__function::__policy_storage const*, Poco::AutoPtr<Poco::Util::AbstractConfiguration>&&, bool) build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:608:12 (clickhouse+0x10ad1d29)\n    #12 std::__1::__function::__policy_func<void (Poco::AutoPtr<Poco::Util::AbstractConfiguration>, bool)>::operator()[abi:ne180100](Poco::AutoPtr<Poco::Util::AbstractConfiguration>&&, bool&&) const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:714:12 (clickhouse+0x1de383be) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #13 std::__1::function<void (Poco::AutoPtr<Poco::Util::AbstractConfiguration>, bool)>::operator()(Poco::AutoPtr<Poco::Util::AbstractConfiguration>, bool) const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:981:10 (clickhouse+0x1de383be)\n    #14 DB::ConfigReloader::reloadIfNewer(bool, bool, bool, bool) build_docker/./src/Common/Config/ConfigReloader.cpp:165:13 (clickhouse+0x1de383be)\n    #15 DB::ConfigReloader::run() build_docker/./src/Common/Config/ConfigReloader.cpp:89:27 (clickhouse+0x1de398ed) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #16 decltype(*std::declval<DB::ConfigReloader*&>().*std::declval<void (DB::ConfigReloader::*&)()>()()) std::__1::__invoke[abi:ne180100]<void (DB::ConfigReloader::*&)(), DB::ConfigReloader*&, void>(void (DB::ConfigReloader::*&)(), DB::ConfigReloader*&) build_docker/./contrib/llvm-project/libcxx/include/__type_traits/invoke.h:312:25 (clickhouse+0x1de3b505) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #17 decltype(auto) std::__1::__apply_tuple_impl[abi:ne180100]<void (DB::ConfigReloader::*&)(), std::__1::tuple<DB::ConfigReloader*>&, 0ul>(void (DB::ConfigReloader::*&)(), std::__1::tuple<DB::ConfigReloader*>&, std::__1::__tuple_indices<0ul>) build_docker/./contrib/llvm-project/libcxx/include/tuple:1424:5 (clickhouse+0x1de3b505)\n    #18 decltype(auto) std::__1::apply[abi:ne180100]<void (DB::ConfigReloader::*&)(), std::__1::tuple<DB::ConfigReloader*>&>(void (DB::ConfigReloader::*&)(), std::__1::tuple<DB::ConfigReloader*>&) build_docker/./contrib/llvm-project/libcxx/include/tuple:1428:5 (clickhouse+0x1de3b505)\n    #19 ThreadFromGlobalPoolImpl<true, true>::ThreadFromGlobalPoolImpl<void (DB::ConfigReloader::*)(), DB::ConfigReloader*>(void (DB::ConfigReloader::*&&)(), DB::ConfigReloader*&&)::'lambda'()::operator()() build_docker/./src/Common/ThreadPool.h:311:13 (clickhouse+0x1de3b505)\n    #20 decltype(std::declval<void (DB::ConfigReloader::*)()>()(std::declval<DB::ConfigReloader*>())) std::__1::__invoke[abi:ne180100]<ThreadFromGlobalPoolImpl<true, true>::ThreadFromGlobalPoolImpl<void (DB::ConfigReloader::*)(), DB::ConfigReloader*>(void (DB::ConfigReloader::*&&)(), DB::ConfigReloader*&&)::'lambda'()&>(void (DB::ConfigReloader::*&&)(), DB::ConfigReloader*&&) build_docker/./contrib/llvm-project/libcxx/include/__type_traits/invoke.h:344:25 (clickhouse+0x1de3b421) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #21 void std::__1::__invoke_void_return_wrapper<void, true>::__call[abi:ne180100]<ThreadFromGlobalPoolImpl<true, true>::ThreadFromGlobalPoolImpl<void (DB::ConfigReloader::*)(), DB::ConfigReloader*>(void (DB::ConfigReloader::*&&)(), DB::ConfigReloader*&&)::'lambda'()&>(ThreadFromGlobalPoolImpl<true, true>::ThreadFromGlobalPoolImpl<void (DB::ConfigReloader::*)(), DB::ConfigReloader*>(void (DB::ConfigReloader::*&&)(), DB::ConfigReloader*&&)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__type_traits/invoke.h:419:5 (clickhouse+0x1de3b421)\n    #22 std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true, true>::ThreadFromGlobalPoolImpl<void (DB::ConfigReloader::*)(), DB::ConfigReloader*>(void (DB::ConfigReloader::*&&)(), DB::ConfigReloader*&&)::'lambda'(), void ()>::operator()[abi:ne180100]() build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:208:12 (clickhouse+0x1de3b421)\n    #23 void std::__1::__function::__policy_invoker<void ()>::__call_impl[abi:ne180100]<std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true, true>::ThreadFromGlobalPoolImpl<void (DB::ConfigReloader::*)(), DB::ConfigReloader*>(void (DB::ConfigReloader::*&&)(), DB::ConfigReloader*&&)::'lambda'(), void ()>>(std::__1::__function::__policy_storage const*) build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:608:12 (clickhouse+0x1de3b421)\n    #24 std::__1::__function::__policy_func<void ()>::operator()[abi:ne180100]() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:714:12 (clickhouse+0x1084252d) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #25 std::__1::function<void ()>::operator()() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:981:10 (clickhouse+0x1084252d)\n    #26 ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool::worker() build_docker/./src/Common/ThreadPool.cpp:785:17 (clickhouse+0x1084252d)\n    #27 decltype(*std::declval<ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool*>().*std::declval<void (ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool::*)()>()()) std::__1::__invoke[abi:ne180100]<void (ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool::*)(), ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool*, void>(void (ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool::*&&)(), ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool*&&) build_docker/./contrib/llvm-project/libcxx/include/__type_traits/invoke.h:312:25 (clickhouse+0x1084a6bb) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #28 void std::__1::__thread_execute[abi:ne180100]<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool::*)(), ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool*, 2ul>(std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool::*)(), ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool*>&, std::__1::__tuple_indices<2ul>) build_docker/./contrib/llvm-project/libcxx/include/__thread/thread.h:193:3 (clickhouse+0x1084a6bb)\n    #29 void* std::__1::__thread_proxy[abi:ne180100]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool::*)(), ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool*>>(void*) build_docker/./contrib/llvm-project/libcxx/include/__thread/thread.h:202:3 (clickhouse+0x1084a6bb)\n\n  Previous read of size 8 at 0x724000058500 by main thread:\n    #0 DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_19::operator()() const build_docker/./programs/server/Server.cpp:2526:9 (clickhouse+0x10ac8a61) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #1 BasicScopeGuard<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_19>::invoke() build_docker/./base/base/../base/scope_guard.h:101:9 (clickhouse+0x10ac8a61)\n    #2 BasicScopeGuard<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_19>::~BasicScopeGuard() build_docker/./base/base/../base/scope_guard.h:50:26 (clickhouse+0x10ac8a61)\n    #3 DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&) build_docker/./programs/server/Server.cpp:2597:5 (clickhouse+0x10ab8b95) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #4 Poco::Util::Application::run() build_docker/./base/poco/Util/src/Application.cpp:315:8 (clickhouse+0x222087fe) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #5 DB::Server::run() build_docker/./programs/server/Server.cpp:559:25 (clickhouse+0x10a99e85) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #6 Poco::Util::ServerApplication::run(int, char**) build_docker/./base/poco/Util/src/ServerApplication.cpp:131:9 (clickhouse+0x22226da0) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #7 mainEntryClickHouseServer(int, char**) build_docker/./programs/server/Server.cpp:357:20 (clickhouse+0x10a96b63) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #8 main build_docker/./programs/main.cpp:269:21 (clickhouse+0x7e494fc) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n\n  Mutex M0 (0x7248000074a0) created at:\n    #0 pthread_mutex_lock <null> (clickhouse+0x7dc71de) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #1 std::__1::__libcpp_mutex_lock[abi:ne180100](pthread_mutex_t*) build_docker/./contrib/llvm-project/libcxx/include/__threading_support:280:57 (clickhouse+0x25370f19) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #2 std::__1::mutex::lock() build_docker/./contrib/llvm-project/libcxx/src/mutex.cpp:29:12 (clickhouse+0x25370f19)\n    #3 std::__1::lock_guard<std::__1::mutex>::lock_guard[abi:ne180100](std::__1::mutex&) build_docker/./contrib/llvm-project/libcxx/include/__mutex/lock_guard.h:35:10 (clickhouse+0x1de37449) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #4 DB::ConfigReloader::reloadIfNewer(bool, bool, bool, bool) build_docker/./src/Common/Config/ConfigReloader.cpp:111:21 (clickhouse+0x1de37449)\n    #5 DB::ConfigReloader::ConfigReloader(std::__1::basic_string_view<char, std::__1::char_traits<char>>, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, zkutil::ZooKeeperNodeCache&&, std::__1::shared_ptr<Poco::Event> const&, std::__1::function<void (Poco::AutoPtr<Poco::Util::AbstractConfiguration>, bool)>&&) build_docker/./src/Common/Config/ConfigReloader.cpp:30:19 (clickhouse+0x1de369a5) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #6 std::__1::__unique_if<DB::ConfigReloader>::__unique_single std::__1::make_unique[abi:ne180100]<DB::ConfigReloader, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, zkutil::ZooKeeperNodeCache, std::__1::shared_ptr<Poco::Event>&, DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_0>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>&&, zkutil::ZooKeeperNodeCache&&, std::__1::shared_ptr<Poco::Event>&, DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&)::$_0&&) build_docker/./contrib/llvm-project/libcxx/include/__memory/unique_ptr.h:597:30 (clickhouse+0x10aafe5c) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #7 DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&) build_docker/./programs/server/Server.cpp:1735:33 (clickhouse+0x10aafe5c)\n    #8 Poco::Util::Application::run() build_docker/./base/poco/Util/src/Application.cpp:315:8 (clickhouse+0x222087fe) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #9 DB::Server::run() build_docker/./programs/server/Server.cpp:559:25 (clickhouse+0x10a99e85) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #10 Poco::Util::ServerApplication::run(int, char**) build_docker/./base/poco/Util/src/ServerApplication.cpp:131:9 (clickhouse+0x22226da0) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #11 mainEntryClickHouseServer(int, char**) build_docker/./programs/server/Server.cpp:357:20 (clickhouse+0x10a96b63) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #12 main build_docker/./programs/main.cpp:269:21 (clickhouse+0x7e494fc) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n\n  Thread T655 'ConfigReloader' (tid=662, running) created by main thread at:\n    #0 pthread_create <null> (clickhouse+0x7dc54d1) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #1 std::__1::__libcpp_thread_create[abi:ne180100](unsigned long*, void* (*)(void*), void*) build_docker/./contrib/llvm-project/libcxx/include/__threading_support:317:10 (clickhouse+0x10842cf5) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #2 std::__1::thread::thread<void (ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool::*)(), ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool*, void>(void (ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool::*&&)(), ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool*&&) build_docker/./contrib/llvm-project/libcxx/include/__thread/thread.h:212:14 (clickhouse+0x10842cf5)\n    #3 ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool::ThreadFromThreadPool(ThreadPoolImpl<std::__1::thread>&) build_docker/./src/Common/ThreadPool.cpp:598:14 (clickhouse+0x108418f5) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #4 std::__1::__unique_if<ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool>::__unique_single std::__1::make_unique[abi:ne180100]<ThreadPoolImpl<std::__1::thread>::ThreadFromThreadPool, ThreadPoolImpl<std::__1::thread>&>(ThreadPoolImpl<std::__1::thread>&) build_docker/./contrib/llvm-project/libcxx/include/__memory/unique_ptr.h:597:30 (clickhouse+0x10843507) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #5 void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool) build_docker/./src/Common/ThreadPool.cpp:284:30 (clickhouse+0x10843507)\n    #6 ThreadPoolImpl<std::__1::thread>::scheduleOrThrow(std::__1::function<void ()>, Priority, unsigned long, bool) build_docker/./src/Common/ThreadPool.cpp:490:5 (clickhouse+0x10844196) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #7 ThreadFromGlobalPoolImpl<true, true>::ThreadFromGlobalPoolImpl<DB::PeriodicLog<DB::ErrorLogElement>::startCollect(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, unsigned long)::'lambda'()>(DB::PeriodicLog<DB::ErrorLogElement>::startCollect(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, unsigned long)::'lambda'()&&) build_docker/./src/Common/ThreadPool.h:278:38 (clickhouse+0x1a2cb7a4) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #8 std::__1::__unique_if<ThreadFromGlobalPoolImpl<true, true>>::__unique_single std::__1::make_unique[abi:ne180100]<ThreadFromGlobalPoolImpl<true, true>, DB::PeriodicLog<DB::ErrorLogElement>::startCollect(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, unsigned long)::'lambda'()>(DB::PeriodicLog<DB::ErrorLogElement>::startCollect(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, unsigned long)::'lambda'()&&) build_docker/./contrib/llvm-project/libcxx/include/__memory/unique_ptr.h:597:30 (clickhouse+0x1a2ca7d5) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #9 DB::PeriodicLog<DB::ErrorLogElement>::startCollect(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, unsigned long) build_docker/./src/Interpreters/PeriodicLog.cpp:16:25 (clickhouse+0x1a2ca7d5)\n    #10 DB::SystemLogs::SystemLogs(std::__1::shared_ptr<DB::Context const>, Poco::Util::AbstractConfiguration const&) build_docker/./src/Interpreters/SystemLog.cpp:334:20 (clickhouse+0x1a14cb3f) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #11 std::__1::__unique_if<DB::SystemLogs>::__unique_single std::__1::make_unique[abi:ne180100]<DB::SystemLogs, std::__1::shared_ptr<DB::Context>, Poco::Util::AbstractConfiguration const&>(std::__1::shared_ptr<DB::Context>&&, Poco::Util::AbstractConfiguration const&) build_docker/./contrib/llvm-project/libcxx/include/__memory/unique_ptr.h:597:30 (clickhouse+0x1939d4d5) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #12 DB::Context::initializeSystemLogs()::$_0::operator()() const build_docker/./src/Interpreters/Context.cpp:4449:28 (clickhouse+0x1939d4d5)\n    #13 decltype(std::declval<DB::Context::initializeSystemLogs()::$_0>()()) std::__1::__invoke[abi:ne180100]<DB::Context::initializeSystemLogs()::$_0>(DB::Context::initializeSystemLogs()::$_0&&) build_docker/./contrib/llvm-project/libcxx/include/__type_traits/invoke.h:344:25 (clickhouse+0x1939d4d5)\n    #14 void std::__1::__call_once_param<std::__1::tuple<DB::Context::initializeSystemLogs()::$_0&&>>::__execute[abi:ne180100]<>(std::__1::__tuple_indices<...>) build_docker/./contrib/llvm-project/libcxx/include/__mutex/once_flag.h:97:5 (clickhouse+0x1939d4d5)\n    #15 std::__1::__call_once_param<std::__1::tuple<DB::Context::initializeSystemLogs()::$_0&&>>::operator()[abi:ne180100]() build_docker/./contrib/llvm-project/libcxx/include/__mutex/once_flag.h:91:5 (clickhouse+0x1939d4d5)\n    #16 void std::__1::__call_once_proxy[abi:ne180100]<std::__1::tuple<DB::Context::initializeSystemLogs()::$_0&&>>(void*) build_docker/./contrib/llvm-project/libcxx/include/__mutex/once_flag.h:118:3 (clickhouse+0x1939d4d5)\n    #17 std::__1::__call_once(unsigned long volatile&, void*, void (*)(void*)) build_docker/./contrib/llvm-project/libcxx/src/call_once.cpp:57:5 (clickhouse+0x252ef440) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #18 void std::__1::call_once[abi:ne180100]<DB::Context::initializeSystemLogs()::$_0>(std::__1::once_flag&, DB::Context::initializeSystemLogs()::$_0&&) build_docker/./contrib/llvm-project/libcxx/include/__mutex/once_flag.h:131:5 (clickhouse+0x19388f0a) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #19 void DB::callOnce<DB::Context::initializeSystemLogs()::$_0>(std::__1::once_flag&, DB::Context::initializeSystemLogs()::$_0&&) build_docker/./src/Common/callOnce.h:13:5 (clickhouse+0x19388f0a)\n    #20 DB::Context::initializeSystemLogs() build_docker/./src/Interpreters/Context.cpp:4448:5 (clickhouse+0x19388f0a)\n    #21 DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&) build_docker/./programs/server/Server.cpp:2299:25 (clickhouse+0x10ab502e) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #22 Poco::Util::Application::run() build_docker/./base/poco/Util/src/Application.cpp:315:8 (clickhouse+0x222087fe) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #23 DB::Server::run() build_docker/./programs/server/Server.cpp:559:25 (clickhouse+0x10a99e85) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #24 Poco::Util::ServerApplication::run(int, char**) build_docker/./base/poco/Util/src/ServerApplication.cpp:131:9 (clickhouse+0x22226da0) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #25 mainEntryClickHouseServer(int, char**) build_docker/./programs/server/Server.cpp:357:20 (clickhouse+0x10a96b63) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n    #26 main build_docker/./programs/main.cpp:269:21 (clickhouse+0x7e494fc) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2)\n\nSUMMARY: ThreadSanitizer: data race (/usr/bin/clickhouse+0x7e47b68) (BuildId: 16dfeed9d3f7c63aff0f7a2fcf98b48f8a8b7df2) in operator delete(void*, unsigned long)\n==================\nThreadSanitizer: reported 1 warnings\n```\n",
  "hints_text": "I quickly checked this out. I think the data race was already in the code based on [these comments](https://github.com/ClickHouse/ClickHouse/blob/master/programs/server/Server.cpp#L1810-L1812), but they were not reproduced before. The PR probably made it more likely to happen, but it is not the root cause of the issue.\n\nThat said, as the PR made it worse, I think we should think about this and try to solve. However I don't see a clear solution for this. I think we don't want to make every logging acquire a lock, thus we cannot just make logging and updating logger settings mutually exclusive. Therefore I am not sure how we can proceed with this. \nAs I finished my comment I just realized that with a `SYSTEM RELOAD CONFIG` query we could minize the chance of this happening probably, but it wouldn't solve the issue, just make it less likely to happen in our CI.",
  "created_at": "2025-02-05T09:04:45Z"
}