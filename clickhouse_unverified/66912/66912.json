{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 66912,
  "instance_id": "ClickHouse__ClickHouse-66912",
  "issue_numbers": [
    "64054"
  ],
  "base_commit": "8a5dcc5bd2231a293e01458bf67ff0eb774c56b3",
  "patch": "diff --git a/src/Analyzer/IQueryTreeNode.h b/src/Analyzer/IQueryTreeNode.h\nindex df3687f8fd91..b36c1401798c 100644\n--- a/src/Analyzer/IQueryTreeNode.h\n+++ b/src/Analyzer/IQueryTreeNode.h\n@@ -49,7 +49,7 @@ enum class QueryTreeNodeType : uint8_t\n /// Convert query tree node type to string\n const char * toString(QueryTreeNodeType type);\n \n-/** Query tree is semantical representation of query.\n+/** Query tree is a semantic representation of query.\n   * Query tree node represent node in query tree.\n   * IQueryTreeNode is base class for all query tree nodes.\n   *\ndiff --git a/src/Interpreters/IInterpreterUnionOrSelectQuery.cpp b/src/Interpreters/IInterpreterUnionOrSelectQuery.cpp\nindex d8f6df05ca44..f64b9540dbbe 100644\n--- a/src/Interpreters/IInterpreterUnionOrSelectQuery.cpp\n+++ b/src/Interpreters/IInterpreterUnionOrSelectQuery.cpp\n@@ -17,13 +17,19 @@\n namespace DB\n {\n \n-IInterpreterUnionOrSelectQuery::IInterpreterUnionOrSelectQuery(const DB::ASTPtr& query_ptr_,\n-        const DB::ContextMutablePtr& context_, const DB::SelectQueryOptions& options_)\n-        : query_ptr(query_ptr_)\n-        , context(context_)\n-        , options(options_)\n-        , max_streams(context->getSettingsRef().max_threads)\n+IInterpreterUnionOrSelectQuery::IInterpreterUnionOrSelectQuery(const ASTPtr & query_ptr_,\n+    const ContextMutablePtr & context_, const SelectQueryOptions & options_)\n+    : query_ptr(query_ptr_)\n+    , context(context_)\n+    , options(options_)\n+    , max_streams(context->getSettingsRef().max_threads)\n {\n+    /// FIXME All code here will work with the old analyzer, however for views over Distributed tables\n+    /// it's possible that new analyzer will be enabled in ::getQueryProcessingStage method\n+    /// of the underlying storage when all other parts of infrastructure are not ready for it\n+    /// (built with old analyzer).\n+    context->setSetting(\"allow_experimental_analyzer\", false);\n+\n     if (options.shard_num)\n         context->addSpecialScalar(\n                 \"_shard_num\",\ndiff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp\nindex 7bee497f6da7..0f24888cb79e 100644\n--- a/src/Interpreters/InterpreterSelectQuery.cpp\n+++ b/src/Interpreters/InterpreterSelectQuery.cpp\n@@ -75,7 +75,6 @@\n \n #include <Storages/MergeTree/MergeTreeWhereOptimizer.h>\n #include <Storages/StorageDistributed.h>\n-#include <Storages/StorageDummy.h>\n #include <Storages/StorageMerge.h>\n #include <Storages/StorageValues.h>\n #include <Storages/StorageView.h>\n@@ -214,11 +213,11 @@ InterpreterSelectQuery::InterpreterSelectQuery(\n {}\n \n InterpreterSelectQuery::InterpreterSelectQuery(\n-        const ASTPtr & query_ptr_,\n-        const ContextPtr & context_,\n-        Pipe input_pipe_,\n-        const SelectQueryOptions & options_)\n-        : InterpreterSelectQuery(query_ptr_, context_, std::move(input_pipe_), nullptr, options_.copy().noSubquery())\n+    const ASTPtr & query_ptr_,\n+    const ContextPtr & context_,\n+    Pipe input_pipe_,\n+    const SelectQueryOptions & options_)\n+    : InterpreterSelectQuery(query_ptr_, context_, std::move(input_pipe_), nullptr, options_.copy().noSubquery())\n {}\n \n InterpreterSelectQuery::InterpreterSelectQuery(\n@@ -227,18 +226,15 @@ InterpreterSelectQuery::InterpreterSelectQuery(\n     const StoragePtr & storage_,\n     const StorageMetadataPtr & metadata_snapshot_,\n     const SelectQueryOptions & options_)\n-    : InterpreterSelectQuery(\n-        query_ptr_, context_, std::nullopt, storage_, options_.copy().noSubquery(), {}, metadata_snapshot_)\n-{\n-}\n+    : InterpreterSelectQuery(query_ptr_, context_, std::nullopt, storage_, options_.copy().noSubquery(), {}, metadata_snapshot_)\n+{}\n \n InterpreterSelectQuery::InterpreterSelectQuery(\n     const ASTPtr & query_ptr_,\n     const ContextPtr & context_,\n     const SelectQueryOptions & options_,\n     PreparedSetsPtr prepared_sets_)\n-    : InterpreterSelectQuery(\n-        query_ptr_, context_, std::nullopt, nullptr, options_, {}, {}, prepared_sets_)\n+    : InterpreterSelectQuery(query_ptr_, context_, std::nullopt, nullptr, options_, {}, {}, prepared_sets_)\n {}\n \n InterpreterSelectQuery::~InterpreterSelectQuery() = default;\ndiff --git a/src/Interpreters/InterpreterSelectQuery.h b/src/Interpreters/InterpreterSelectQuery.h\nindex d4ed19d45ea9..ac1230a6eba9 100644\n--- a/src/Interpreters/InterpreterSelectQuery.h\n+++ b/src/Interpreters/InterpreterSelectQuery.h\n@@ -26,7 +26,6 @@ class Logger;\n namespace DB\n {\n \n-class SubqueryForSet;\n class InterpreterSelectWithUnionQuery;\n class Context;\n class QueryPlan;\ndiff --git a/src/Storages/StorageDistributed.cpp b/src/Storages/StorageDistributed.cpp\nindex 65323b4bb524..07892971ec22 100644\n--- a/src/Storages/StorageDistributed.cpp\n+++ b/src/Storages/StorageDistributed.cpp\n@@ -43,7 +43,6 @@\n #include <Parsers/parseQuery.h>\n #include <Parsers/IAST.h>\n \n-#include <Analyzer/Utils.h>\n #include <Analyzer/ColumnNode.h>\n #include <Analyzer/FunctionNode.h>\n #include <Analyzer/TableNode.h>\n@@ -61,26 +60,20 @@\n #include <Interpreters/ClusterProxy/SelectStreamFactory.h>\n #include <Interpreters/ClusterProxy/executeQuery.h>\n #include <Interpreters/Cluster.h>\n-#include <Interpreters/DatabaseAndTableWithAlias.h>\n #include <Interpreters/ExpressionAnalyzer.h>\n #include <Interpreters/InterpreterSelectQuery.h>\n #include <Interpreters/InterpreterSelectQueryAnalyzer.h>\n #include <Interpreters/InterpreterInsertQuery.h>\n #include <Interpreters/JoinedTables.h>\n-#include <Interpreters/TranslateQualifiedNamesVisitor.h>\n #include <Interpreters/AddDefaultDatabaseVisitor.h>\n #include <Interpreters/TreeRewriter.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/createBlockSelector.h>\n #include <Interpreters/evaluateConstantExpression.h>\n #include <Interpreters/getClusterName.h>\n-#include <Interpreters/getTableExpressions.h>\n #include <Interpreters/RequiredSourceColumnsVisitor.h>\n-#include <Interpreters/getCustomKeyFilterForParallelReplicas.h>\n #include <Interpreters/getHeaderForProcessingStage.h>\n \n-#include <Functions/IFunction.h>\n-#include <Functions/FunctionFactory.h>\n #include <TableFunctions/TableFunctionView.h>\n #include <TableFunctions/TableFunctionFactory.h>\n \n@@ -90,7 +83,6 @@\n #include <Processors/Executors/PushingPipelineExecutor.h>\n #include <Processors/Executors/CompletedPipelineExecutor.h>\n #include <Processors/QueryPlan/QueryPlan.h>\n-#include <Processors/QueryPlan/BuildQueryPipelineSettings.h>\n #include <Processors/QueryPlan/ReadFromPreparedSource.h>\n #include <Processors/QueryPlan/ExpressionStep.h>\n #include <Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h>\n@@ -496,7 +488,7 @@ QueryProcessingStage::Enum StorageDistributed::getQueryProcessingStage(\n     }\n \n     std::optional<QueryProcessingStage::Enum> optimized_stage;\n-    if (settings.allow_experimental_analyzer)\n+    if (query_info.query_tree)\n         optimized_stage = getOptimizedQueryProcessingStageAnalyzer(query_info, settings);\n     else\n         optimized_stage = getOptimizedQueryProcessingStage(query_info, settings);\n@@ -860,31 +852,28 @@ void StorageDistributed::read(\n         modified_query_info.query = queryNodeToDistributedSelectQuery(query_tree_distributed);\n \n         modified_query_info.query_tree = std::move(query_tree_distributed);\n+\n+        /// Return directly (with correct header) if no shard to query.\n+        if (modified_query_info.getCluster()->getShardsInfo().empty())\n+            return;\n     }\n     else\n     {\n         header = InterpreterSelectQuery(modified_query_info.query, local_context, SelectQueryOptions(processed_stage).analyze()).getSampleBlock();\n-    }\n \n-    if (!settings.allow_experimental_analyzer)\n-    {\n         modified_query_info.query = ClusterProxy::rewriteSelectQuery(\n             local_context, modified_query_info.query,\n             remote_database, remote_table, remote_table_function_ptr);\n-    }\n \n-    /// Return directly (with correct header) if no shard to query.\n-    if (modified_query_info.getCluster()->getShardsInfo().empty())\n-    {\n-        if (settings.allow_experimental_analyzer)\n-            return;\n-\n-        Pipe pipe(std::make_shared<NullSource>(header));\n-        auto read_from_pipe = std::make_unique<ReadFromPreparedSource>(std::move(pipe));\n-        read_from_pipe->setStepDescription(\"Read from NullSource (Distributed)\");\n-        query_plan.addStep(std::move(read_from_pipe));\n+        if (modified_query_info.getCluster()->getShardsInfo().empty())\n+        {\n+            Pipe pipe(std::make_shared<NullSource>(header));\n+            auto read_from_pipe = std::make_unique<ReadFromPreparedSource>(std::move(pipe));\n+            read_from_pipe->setStepDescription(\"Read from NullSource (Distributed)\");\n+            query_plan.addStep(std::move(read_from_pipe));\n \n-        return;\n+            return;\n+        }\n     }\n \n     const auto & snapshot_data = assert_cast<const SnapshotData &>(*storage_snapshot->data);\ndiff --git a/src/Storages/TTLDescription.cpp b/src/Storages/TTLDescription.cpp\nindex ac091e7cf3c0..92f6f17583d9 100644\n--- a/src/Storages/TTLDescription.cpp\n+++ b/src/Storages/TTLDescription.cpp\n@@ -172,7 +172,7 @@ static ExpressionAndSets buildExpressionAndSets(ASTPtr & ast, const NamesAndType\n     /// with subqueries it's possible that new analyzer will be enabled in ::read method\n     /// of underlying storage when all other parts of infra are not ready for it\n     /// (built with old analyzer).\n-    context_copy->setSetting(\"allow_experimental_analyzer\", Field{0});\n+    context_copy->setSetting(\"allow_experimental_analyzer\", false);\n     auto syntax_analyzer_result = TreeRewriter(context_copy).analyze(ast, columns);\n     ExpressionAnalyzer analyzer(ast, syntax_analyzer_result, context_copy);\n     auto dag = analyzer.getActionsDAG(false);\n",
  "test_patch": "diff --git a/src/Common/tests/gtest_resolve_pool.cpp b/src/Common/tests/gtest_resolve_pool.cpp\nindex b760b9b1524c..c443e961cc7e 100644\n--- a/src/Common/tests/gtest_resolve_pool.cpp\n+++ b/src/Common/tests/gtest_resolve_pool.cpp\n@@ -33,7 +33,7 @@ size_t toMilliseconds(auto duration)\n    return std::chrono::duration_cast<std::chrono::milliseconds>(duration).count();\n }\n \n-const auto epsilon = 500us;\n+const auto epsilon = 1ms;\n \n class ResolvePoolMock : public DB::HostResolver\n {\n@@ -358,54 +358,60 @@ void check_no_failed_address(size_t iteration, auto & resolver, auto & addresses\n \n TEST_F(ResolvePoolTest, BannedForConsiquenceFail)\n {\n-    auto history = 5ms;\n+    auto history = 10ms;\n     auto resolver = make_resolver(toMilliseconds(history));\n \n     auto failed_addr = resolver->resolve();\n     ASSERT_TRUE(addresses.contains(*failed_addr));\n \n-    auto start_at = now();\n \n     failed_addr.setFail();\n+    auto start_at = now();\n+\n     ASSERT_EQ(3, CurrentMetrics::get(metrics.active_count));\n     ASSERT_EQ(1, CurrentMetrics::get(metrics.banned_count));\n     check_no_failed_address(1, resolver, addresses, failed_addr, metrics, start_at + history - epsilon);\n \n     sleep_until(start_at + history + epsilon);\n-    start_at = now();\n \n     resolver->update();\n     ASSERT_EQ(3, CurrentMetrics::get(metrics.active_count));\n     ASSERT_EQ(0, CurrentMetrics::get(metrics.banned_count));\n \n     failed_addr.setFail();\n+    start_at = now();\n+\n     check_no_failed_address(2, resolver, addresses, failed_addr, metrics, start_at + history - epsilon);\n \n     sleep_until(start_at + history + epsilon);\n-    start_at = now();\n \n     resolver->update();\n+\n+    // too much time has passed\n+    if (now() > start_at + 2*history - epsilon)\n+        return;\n+\n     ASSERT_EQ(3, CurrentMetrics::get(metrics.active_count));\n     ASSERT_EQ(1, CurrentMetrics::get(metrics.banned_count));\n \n     // ip still banned adter history_ms + update, because it was his second consiquent fail\n-    check_no_failed_address(2, resolver, addresses, failed_addr, metrics, start_at + history - epsilon);\n+    check_no_failed_address(2, resolver, addresses, failed_addr, metrics, start_at + 2*history - epsilon);\n }\n \n TEST_F(ResolvePoolTest, NoAditionalBannForConcurrentFail)\n {\n-    auto history = 5ms;\n+    auto history = 10ms;\n     auto resolver = make_resolver(toMilliseconds(history));\n \n     auto failed_addr = resolver->resolve();\n     ASSERT_TRUE(addresses.contains(*failed_addr));\n \n-    auto start_at = now();\n-\n     failed_addr.setFail();\n     failed_addr.setFail();\n     failed_addr.setFail();\n \n+    auto start_at = now();\n+\n     ASSERT_EQ(3, CurrentMetrics::get(metrics.active_count));\n     ASSERT_EQ(1, CurrentMetrics::get(metrics.banned_count));\n     check_no_failed_address(3, resolver, addresses, failed_addr, metrics, start_at + history - epsilon);\n@@ -413,6 +419,7 @@ TEST_F(ResolvePoolTest, NoAditionalBannForConcurrentFail)\n     sleep_until(start_at + history + epsilon);\n \n     resolver->update();\n+\n     // ip is cleared after just 1 history_ms interval.\n     ASSERT_EQ(3, CurrentMetrics::get(metrics.active_count));\n     ASSERT_EQ(0, CurrentMetrics::get(metrics.banned_count));\n",
  "problem_statement": "Segmentation fault DB::StorageDistributed::getOptimizedQueryProcessingStageAnalyzer\nhttps://s3.amazonaws.com/clickhouse-test-reports/0/370b01e23b87a5f1c4039bb584bd631b02213207/stress_test__tsan_.html\r\n\r\n```\r\n[ 31987 ] {} <Fatal> BaseDaemon: ########## Short fault info ############\r\n [ 31987 ] {} <Fatal> BaseDaemon: (version 24.5.1.1 (official build), build id: 3D1133B4A4094B808640150348B77F0074A83FCF, git hash: 370b01e23b87a5f1c4039bb584bd631b02213207) (from thread 4069) Received signal 11\r\n [ 31987 ] {} <Fatal> BaseDaemon: Signal description: Segmentation fault\r\n [ 31987 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Address not mapped to object.\r\n [ 31987 ] {} <Fatal> BaseDaemon: Stack trace: 0x00005557a91c5f7d 0x00005557a94f13fb 0x00005557a139f8f6 0x00005557a139fe16 0x00007f788e6b6520 0x00005557b14d0d07 0x00005557b26c6a74 0x00005557b26c58ed 0x00005557b18d548f 0x00005557b18c9fc9 0x00005557b18c2857 0x00005557b18be2cc 0x00005557b18bdf66 0x0000\r\n [ 31987 ] {} <Fatal> BaseDaemon: ########################################\r\n [ 31987 ] {} <Fatal> BaseDaemon: (version 24.5.1.1 (official build), build id: 3D1133B4A4094B808640150348B77F0074A83FCF, git hash: 370b01e23b87a5f1c4039bb584bd631b02213207) (from thread 4069) (query_id: 0f661e01-f0bb-4cb0-be10-4b00b7476512) (query: ALTER TABLE `01746_dist`\r\n [ 31987 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Address not mapped to object.\r\n [ 31987 ] {} <Fatal> BaseDaemon: Stack trace: 0x00005557a91c5f7d 0x00005557a94f13fb 0x00005557a139f8f6 0x00005557a139fe16 0x00007f788e6b6520 0x00005557b14d0d07 0x00005557b26c6a74 0x00005557b26c58ed 0x00005557b18d548f 0x00005557b18c9fc9 0x00005557b18c2857 0x00005557b18be2cc 0x00005557b18bdf66 0x0000\r\n [ 31987 ] {} <Fatal> BaseDaemon: 0.0. inlined from ./build_docker/./src/Common/StackTrace.cpp:347: StackTrace::tryCapture()\r\n [ 31987 ] {} <Fatal> BaseDaemon: 0. ./build_docker/./src/Common/StackTrace.cpp:316: StackTrace::StackTrace(ucontext_t const&) @ 0x000000000ef7bf7d\r\n [ 31987 ] {} <Fatal> BaseDaemon: 1. ./build_docker/./src/Daemon/BaseDaemon.cpp:0: signalHandler(int, siginfo_t*, void*) @ 0x000000000f2a73fb\r\n [ 31987 ] {} <Fatal> BaseDaemon: 2. __tsan::CallUserSignalHandler(__tsan::ThreadState*, bool, bool, int, __sanitizer::__sanitizer_siginfo*, void*) @ 0x00000000071558f6\r\n [ 31987 ] {} <Fatal> BaseDaemon: 3. sighandler(int, __sanitizer::__sanitizer_siginfo*, void*) @ 0x0000000007155e16\r\n [ 31987 ] {} <Fatal> BaseDaemon: 4. ? @ 0x00007f788e6b6520\r\n [ 31987 ] {} <Fatal> BaseDaemon: 5. ./src/Common/typeid_cast.h:30: _Z11typeid_castIRKN2DB9QueryNodeENS0_14IQueryTreeNodeEQsr3stdE14is_reference_vIT_EES5_RT0_ @ 0x0000000017286d07\r\n [ 31987 ] {} <Fatal> BaseDaemon: 6. ./build_docker/./src/Storages/StorageDistributed.cpp:0: DB::StorageDistributed::getOptimizedQueryProcessingStageAnalyzer(DB::SelectQueryInfo const&, DB::Settings const&) const @ 0x000000001847ca74\r\n [ 31987 ] {} <Fatal> BaseDaemon: 7. ./build_docker/./src/Storages/StorageDistributed.cpp:0: DB::StorageDistributed::getQueryProcessingStage(std::shared_ptr<DB::Context const>, DB::QueryProcessingStage::Enum, std::shared_ptr<DB::StorageSnapshot> const&, DB::SelectQueryInfo&) const @ 0x000000001847b8\r\n [ 31987 ] {} <Fatal> BaseDaemon: 8. ./build_docker/./src/Interpreters/InterpreterSelectQuery.cpp:1019: DB::InterpreterSelectQuery::getSampleBlockImpl() @ 0x000000001768b48f\r\n [ 31987 ] {} <Fatal> BaseDaemon: 9. ./build_docker/./src/Interpreters/InterpreterSelectQuery.cpp:779: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context> const&, std::optional<DB::Pipe>, std::shared_ptr<DB::IStorage> const&, DB::SelectQu\r\n [ 31987 ] {} <Fatal> BaseDaemon: 10. ./build_docker/./src/Interpreters/InterpreterSelectQuery.cpp:0: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context> const&, std::optional<DB::Pipe>, std::shared_ptr<DB::IStorage> const&, DB::SelectQue\r\n [ 31987 ] {} <Fatal> BaseDaemon: 11.0. inlined from ./contrib/llvm-project/libcxx/include/optional:260: ~__optional_destruct_base\r\n [ 31987 ] {} <Fatal> BaseDaemon: 11. ./build_docker/./src/Interpreters/InterpreterSelectQuery.cpp:363: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, std::optional<DB::Pipe>, std::shared_ptr<DB::IStorage> const&, DB::S\r\n [ 31987 ] {} <Fatal> BaseDaemon: 12.0. inlined from ./contrib/llvm-project/libcxx/include/optional:260: ~__optional_destruct_base\r\n [ 31987 ] {} <Fatal> BaseDaemon: 12. ./build_docker/./src/Interpreters/InterpreterSelectQuery.cpp:203: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<St\r\n [ 31987 ] {} <Fatal> BaseDaemon: 13.0. inlined from ./contrib/llvm-project/libcxx/include/vector:666: vector\r\n [ 31987 ] {} <Fatal> BaseDaemon: 13.1. inlined from ./src/Interpreters/InterpreterSelectQuery.h:122: DB::InterpreterSelectQuery::getRequiredColumns()\r\n [ 31987 ] {} <Fatal> BaseDaemon: 13. ./build_docker/./src/Storages/IStorage.cpp:266: DB::IStorage::getDependentViewsByColumn(std::shared_ptr<DB::Context const>) const @ 0x00000000183f0d9d\r\n [ 31987 ] {} <Fatal> BaseDaemon: 14. ./build_docker/./src/Storages/StorageDistributed.cpp:0: DB::StorageDistributed::checkAlterIsPossible(DB::AlterCommands const&, std::shared_ptr<DB::Context const>) const @ 0x00000000184888a1\r\n [ 31987 ] {} <Fatal> BaseDaemon: 15. ./build_docker/./src/Interpreters/InterpreterAlterQuery.cpp:0: DB::InterpreterAlterQuery::executeToTable(DB::ASTAlterQuery const&) @ 0x0000000017156827\r\n [ 31987 ] {} <Fatal> BaseDaemon: 16. ./build_docker/./src/Interpreters/InterpreterAlterQuery.cpp:71: DB::InterpreterAlterQuery::execute() @ 0x00000000171540e3\r\n [ 31987 ] {} <Fatal> BaseDaemon: 17. ./build_docker/./src/Interpreters/executeQuery.cpp:0: DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*) @ 0x0000000017c1cf88\r\n [ 31987 ] {} <Fatal> BaseDaemon: 18. ./build_docker/./src/Interpreters/executeQuery.cpp:1395: DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000017c18478\r\n [ 31987 ] {} <Fatal> BaseDaemon: 19.0. inlined from ./contrib/llvm-project/libcxx/include/__memory/shared_ptr.h:612: shared_ptr\r\n [ 31987 ] {} <Fatal> BaseDaemon: 19.1. inlined from ./contrib/llvm-project/libcxx/include/__memory/shared_ptr.h:723: std::shared_ptr<DB::IAST>::operator=[abi:v15000](std::shared_ptr<DB::IAST>&&)\r\n [ 31987 ] {} <Fatal> BaseDaemon: 19.2. inlined from ./contrib/llvm-project/libcxx/include/tuple:1228: _ZNSt3__15tupleIJRNS_10shared_ptrIN2DB4IASTEEERNS2_7BlockIOEEEaSB6v15000IS4_S6_TnNS_9enable_ifIXsr21_EnableAssignFromPairILb0EONS_4pairIT_T0_EEEE5valueEiE4typeELi0EEERS8_SF_\r\n [ 31987 ] {} <Fatal> BaseDaemon: 19. ./build_docker/./src/Server/TCPHandler.cpp:522: DB::TCPHandler::runImpl() @ 0x0000000019423b09\r\n [ 31987 ] {} <Fatal> BaseDaemon: 20. ./build_docker/./src/Server/TCPHandler.cpp:2343: DB::TCPHandler::run() @ 0x0000000019441cc8\r\n [ 31987 ] {} <Fatal> BaseDaemon: 21. ./build_docker/./base/poco/Net/src/TCPServerConnection.cpp:57: Poco::Net::TCPServerConnection::start() @ 0x000000001cf18363\r\n [ 31987 ] {} <Fatal> BaseDaemon: 22.0. inlined from ./contrib/llvm-project/libcxx/include/__memory/unique_ptr.h:48: std::default_delete<Poco::Net::TCPServerConnection>::operator()[abi:v15000](Poco::Net::TCPServerConnection*) const\r\n [ 31987 ] {} <Fatal> BaseDaemon: 22.1. inlined from ./contrib/llvm-project/libcxx/include/__memory/unique_ptr.h:305: std::unique_ptr<Poco::Net::TCPServerConnection, std::default_delete<Poco::Net::TCPServerConnection>>::reset[abi:v15000](Poco::Net::TCPServerConnection*)\r\n [ 31987 ] {} <Fatal> BaseDaemon: 22.2. inlined from ./contrib/llvm-project/libcxx/include/__memory/unique_ptr.h:259: ~unique_ptr\r\n [ 31987 ] {} <Fatal> BaseDaemon: 22. ./build_docker/./base/poco/Net/src/TCPServerDispatcher.cpp:116: Poco::Net::TCPServerDispatcher::run() @ 0x000000001cf18bd2\r\n [ 31987 ] {} <Fatal> BaseDaemon: 23. ./build_docker/./base/poco/Foundation/src/ThreadPool.cpp:202: Poco::PooledThread::run() @ 0x000000001d1172e7\r\n [ 31987 ] {} <Fatal> BaseDaemon: 24. ./build_docker/./base/poco/Foundation/src/Thread.cpp:46: Poco::(anonymous namespace)::RunnableHolder::run() @ 0x000000001d115630\r\n [ 31987 ] {} <Fatal> BaseDaemon: 25.0. inlined from ./base/poco/Foundation/include/Poco/SharedPtr.h:231: Poco::SharedPtr<Poco::Runnable, Poco::ReferenceCounter, Poco::ReleasePolicy<Poco::Runnable>>::get()\r\n [ 31987 ] {} <Fatal> BaseDaemon: 25.1. inlined from ./base/poco/Foundation/include/Poco/SharedPtr.h:139: Poco::SharedPtr<Poco::Runnable, Poco::ReferenceCounter, Poco::ReleasePolicy<Poco::Runnable>>::assign(Poco::Runnable*)\r\n [ 31987 ] {} <Fatal> BaseDaemon: 25.2. inlined from ./base/poco/Foundation/include/Poco/SharedPtr.h:180: Poco::SharedPtr<Poco::Runnable, Poco::ReferenceCounter, Poco::ReleasePolicy<Poco::Runnable>>::operator=(Poco::Runnable*)\r\n [ 31987 ] {} <Fatal> BaseDaemon: 25. ./base/poco/Foundation/src/Thread_POSIX.cpp:350: Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001d113b0a\r\n [ 31987 ] {} <Fatal> BaseDaemon: 26. __tsan_thread_start_func @ 0x000000000714df2f\r\n [ 31987 ] {} <Fatal> BaseDaemon: 27. ? @ 0x00007f788e708ac3\r\n [ 31987 ] {} <Fatal> BaseDaemon: 28. ? @ 0x00007f788e79a850\r\n [ 31987 ] {} <Fatal> BaseDaemon: Integrity check of the executable successfully passed (checksum: 2B8ECF5BEDF3CED259BB3B5CA376900C)\r\n [ 31987 ] {} <Fatal> BaseDaemon: Report this error to https://github.com/ClickHouse/ClickHouse/issues\r\n [ 31987 ] {} <Fatal> BaseDaemon: Changed settings: min_compress_block_size = 3021730, max_compress_block_size = 2998720, max_block_size = 52105, max_joined_block_size_rows = 70855, max_threads = 63, max_read_buffer_size = 745832, connect_timeout_with_failover_ms = 2000, connect_timeout_with_failove\r\n [ 3212 ] {} <Fatal> Application: Child process was terminated by signal 11.\r\n [ 35686 ] {} <Fatal> Application: Child process was terminated by signal 9 (KILL). If it is not done by \\'forcestop\\' command or manually, the possible cause is OOM Killer (see \\'dmesg\\' and look at the \\'/var/log/kern.log\\' for the details).\r\n [ 1927 ] {} <Fatal> Application: Child process was terminated by signal 9 (KILL). If it is not done by \\'forcestop\\' command or manually, the possible cause is OOM Killer (see \\'dmesg\\' and look at the \\'/var/log/kern.log\\' for the details).\r\n [ 31987 ] {} <Fatal> BaseDaemon: ########## Short fault info ############\r\n [ 31987 ] {} <Fatal> BaseDaemon: (version 24.5.1.1 (official build), build id: 3D1133B4A4094B808640150348B77F0074A83FCF, git hash: 370b01e23b87a5f1c4039bb584bd631b02213207) (from thread 4069) Received signal 11\r\n [ 31987 ] {} <Fatal> BaseDaemon: Signal description: Segmentation fault\r\n [ 31987 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Address not mapped to object.\r\n [ 31987 ] {} <Fatal> BaseDaemon: Stack trace: 0x00005557a91c5f7d 0x00005557a94f13fb 0x00005557a139f8f6 0x00005557a139fe16 0x00007f788e6b6520 0x00005557b14d0d07 0x00005557b26c6a74 0x00005557b26c58ed 0x00005557b18d548f 0x00005557b18c9fc9 0x00005557b18c2857 0x00005557b18be2cc 0x00005557b18bdf66 0x0000\r\n [ 31987 ] {} <Fatal> BaseDaemon: ########################################\r\n [ 31987 ] {} <Fatal> BaseDaemon: (version 24.5.1.1 (official build), build id: 3D1133B4A4094B808640150348B77F0074A83FCF, git hash: 370b01e23b87a5f1c4039bb584bd631b02213207) (from thread 4069) (query_id: 0f661e01-f0bb-4cb0-be10-4b00b7476512) (query: ALTER TABLE `01746_dist`\r\n [ 31987 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Address not mapped to object.\r\n [ 31987 ] {} <Fatal> BaseDaemon: Stack trace: 0x00005557a91c5f7d 0x00005557a94f13fb 0x00005557a139f8f6 0x00005557a139fe16 0x00007f788e6b6520 0x00005557b14d0d07 0x00005557b26c6a74 0x00005557b26c58ed 0x00005557b18d548f 0x00005557b18c9fc9 0x00005557b18c2857 0x00005557b18be2cc 0x00005557b18bdf66 0x0000\r\n [ 31987 ] {} <Fatal> BaseDaemon: 0.0. inlined from ./build_docker/./src/Common/StackTrace.cpp:347: StackTrace::tryCapture()\r\n [ 31987 ] {} <Fatal> BaseDaemon: 0. ./build_docker/./src/Common/StackTrace.cpp:316: StackTrace::StackTrace(ucontext_t const&) @ 0x000000000ef7bf7d\r\n [ 31987 ] {} <Fatal> BaseDaemon: 1. ./build_docker/./src/Daemon/BaseDaemon.cpp:0: signalHandler(int, siginfo_t*, void*) @ 0x000000000f2a73fb\r\n [ 31987 ] {} <Fatal> BaseDaemon: 2. __tsan::CallUserSignalHandler(__tsan::ThreadState*, bool, bool, int, __sanitizer::__sanitizer_siginfo*, void*) @ 0x00000000071558f6\r\n [ 31987 ] {} <Fatal> BaseDaemon: 3. sighandler(int, __sanitizer::__sanitizer_siginfo*, void*) @ 0x0000000007155e16\r\n [ 31987 ] {} <Fatal> BaseDaemon: 4. ? @ 0x00007f788e6b6520\r\n [ 31987 ] {} <Fatal> BaseDaemon: 5. ./src/Common/typeid_cast.h:30: _Z11typeid_castIRKN2DB9QueryNodeENS0_14IQueryTreeNodeEQsr3stdE14is_reference_vIT_EES5_RT0_ @ 0x0000000017286d07\r\n [ 31987 ] {} <Fatal> BaseDaemon: 6. ./build_docker/./src/Storages/StorageDistributed.cpp:0: DB::StorageDistributed::getOptimizedQueryProcessingStageAnalyzer(DB::SelectQueryInfo const&, DB::Settings const&) const @ 0x000000001847ca74\r\n [ 31987 ] {} <Fatal> BaseDaemon: 7. ./build_docker/./src/Storages/StorageDistributed.cpp:0: DB::StorageDistributed::getQueryProcessingStage(std::shared_ptr<DB::Context const>, DB::QueryProcessingStage::Enum, std::shared_ptr<DB::StorageSnapshot> const&, DB::SelectQueryInfo&) const @ 0x000000001847b8\r\n [ 31987 ] {} <Fatal> BaseDaemon: 8. ./build_docker/./src/Interpreters/InterpreterSelectQuery.cpp:1019: DB::InterpreterSelectQuery::getSampleBlockImpl() @ 0x000000001768b48f\r\n [ 31987 ] {} <Fatal> BaseDaemon: 9. ./build_docker/./src/Interpreters/InterpreterSelectQuery.cpp:779: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context> const&, std::optional<DB::Pipe>, std::shared_ptr<DB::IStorage> const&, DB::SelectQu\r\n [ 31987 ] {} <Fatal> BaseDaemon: 10. ./build_docker/./src/Interpreters/InterpreterSelectQuery.cpp:0: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context> const&, std::optional<DB::Pipe>, std::shared_ptr<DB::IStorage> const&, DB::SelectQue\r\n [ 31987 ] {} <Fatal> BaseDaemon: 11.0. inlined from ./contrib/llvm-project/libcxx/include/optional:260: ~__optional_destruct_base\r\n [ 31987 ] {} <Fatal> BaseDaemon: 11. ./build_docker/./src/Interpreters/InterpreterSelectQuery.cpp:363: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, std::optional<DB::Pipe>, std::shared_ptr<DB::IStorage> const&, DB::S\r\n [ 31987 ] {} <Fatal> BaseDaemon: 12.0. inlined from ./contrib/llvm-project/libcxx/include/optional:260: ~__optional_destruct_base\r\n [ 31987 ] {} <Fatal> BaseDaemon: 12. ./build_docker/./src/Interpreters/InterpreterSelectQuery.cpp:203: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<St\r\n [ 31987 ] {} <Fatal> BaseDaemon: 13.0. inlined from ./contrib/llvm-project/libcxx/include/vector:666: vector\r\n [ 31987 ] {} <Fatal> BaseDaemon: 13.1. inlined from ./src/Interpreters/InterpreterSelectQuery.h:122: DB::InterpreterSelectQuery::getRequiredColumns()\r\n [ 31987 ] {} <Fatal> BaseDaemon: 13. ./build_docker/./src/Storages/IStorage.cpp:266: DB::IStorage::getDependentViewsByColumn(std::shared_ptr<DB::Context const>) const @ 0x00000000183f0d9d\r\n [ 31987 ] {} <Fatal> BaseDaemon: 14. ./build_docker/./src/Storages/StorageDistributed.cpp:0: DB::StorageDistributed::checkAlterIsPossible(DB::AlterCommands const&, std::shared_ptr<DB::Context const>) const @ 0x00000000184888a1\r\n [ 31987 ] {} <Fatal> BaseDaemon: 15. ./build_docker/./src/Interpreters/InterpreterAlterQuery.cpp:0: DB::InterpreterAlterQuery::executeToTable(DB::ASTAlterQuery const&) @ 0x0000000017156827\r\n [ 31987 ] {} <Fatal> BaseDaemon: 16. ./build_docker/./src/Interpreters/InterpreterAlterQuery.cpp:71: DB::InterpreterAlterQuery::execute() @ 0x00000000171540e3\r\n [ 31987 ] {} <Fatal> BaseDaemon: 17. ./build_docker/./src/Interpreters/executeQuery.cpp:0: DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*) @ 0x0000000017c1cf88\r\n [ 31987 ] {} <Fatal> BaseDaemon: 18. ./build_docker/./src/Interpreters/executeQuery.cpp:1395: DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000017c18478\r\n [ 31987 ] {} <Fatal> BaseDaemon: 19.0. inlined from ./contrib/llvm-project/libcxx/include/__memory/shared_ptr.h:612: shared_ptr\r\n [ 31987 ] {} <Fatal> BaseDaemon: 19.1. inlined from ./contrib/llvm-project/libcxx/include/__memory/shared_ptr.h:723: std::shared_ptr<DB::IAST>::operator=[abi:v15000](std::shared_ptr<DB::IAST>&&)\r\n [ 31987 ] {} <Fatal> BaseDaemon: 19.2. inlined from ./contrib/llvm-project/libcxx/include/tuple:1228: _ZNSt3__15tupleIJRNS_10shared_ptrIN2DB4IASTEEERNS2_7BlockIOEEEaSB6v15000IS4_S6_TnNS_9enable_ifIXsr21_EnableAssignFromPairILb0EONS_4pairIT_T0_EEEE5valueEiE4typeELi0EEERS8_SF_\r\n [ 31987 ] {} <Fatal> BaseDaemon: 19. ./build_docker/./src/Server/TCPHandler.cpp:522: DB::TCPHandler::runImpl() @ 0x0000000019423b09\r\n [ 31987 ] {} <Fatal> BaseDaemon: 20. ./build_docker/./src/Server/TCPHandler.cpp:2343: DB::TCPHandler::run() @ 0x0000000019441cc8\r\n```\n",
  "hints_text": "The problem is related to this lines: https://github.com/ClickHouse/ClickHouse/blob/ab94c884ebcc5b3e2a85846854b5edcc4983c039/src/Storages/IStorage.cpp#L266\r\n`IStorage` always uses old analyzer without checking `allow_experimental_analyzer`. Actually, right now analyzer is not used in mutations, see #61563\nhttps://s3.amazonaws.com/clickhouse-test-reports/65415/11e844c953380bbfda3b61dcd2dfda60b809f5e2/stress_test__debug_.html",
  "created_at": "2024-07-23T04:39:59Z",
  "modified_files": [
    "src/Analyzer/IQueryTreeNode.h",
    "src/Interpreters/IInterpreterUnionOrSelectQuery.cpp",
    "src/Interpreters/InterpreterSelectQuery.cpp",
    "src/Interpreters/InterpreterSelectQuery.h",
    "src/Storages/StorageDistributed.cpp",
    "src/Storages/TTLDescription.cpp"
  ],
  "modified_test_files": [
    "src/Common/tests/gtest_resolve_pool.cpp"
  ]
}