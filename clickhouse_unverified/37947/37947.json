{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 37947,
  "instance_id": "ClickHouse__ClickHouse-37947",
  "issue_numbers": [
    "33746"
  ],
  "base_commit": "0c1211eb610d8d7a7f1f8708132c37031eb2e5a8",
  "patch": "diff --git a/src/Dictionaries/ExternalQueryBuilder.cpp b/src/Dictionaries/ExternalQueryBuilder.cpp\nindex 1701f08fd67e..19dabe92d647 100644\n--- a/src/Dictionaries/ExternalQueryBuilder.cpp\n+++ b/src/Dictionaries/ExternalQueryBuilder.cpp\n@@ -84,6 +84,19 @@ std::string ExternalQueryBuilder::composeLoadAllQuery() const\n     }\n     else\n     {\n+        /** In case UPDATE_FIELD is specified in {condition} for dictionary that must load all data.\n+          * Replace {condition} with true_condition for initial dictionary load.\n+          * For next dictionary loads {condition} will be updated with UPDATE_FIELD.\n+          */\n+        static constexpr auto true_condition = \"(1 = 1)\";\n+        auto condition_position = query.find(CONDITION_PLACEHOLDER_TO_REPLACE_VALUE);\n+        if (condition_position != std::string::npos)\n+        {\n+            auto query_copy = query;\n+            query_copy.replace(condition_position, CONDITION_PLACEHOLDER_TO_REPLACE_VALUE.size(), true_condition);\n+            return query_copy;\n+        }\n+\n         return query;\n     }\n }\n",
  "test_patch": "diff --git a/tests/integration/test_dictionaries_update_field/test.py b/tests/integration/test_dictionaries_update_field/test.py\nindex a98239e3a40b..a82caab915c7 100644\n--- a/tests/integration/test_dictionaries_update_field/test.py\n+++ b/tests/integration/test_dictionaries_update_field/test.py\n@@ -33,32 +33,7 @@ def started_cluster():\n         cluster.shutdown()\n \n \n-@pytest.mark.parametrize(\n-    \"dictionary_name,dictionary_type\",\n-    [\n-        (\"flat_update_field_dictionary\", \"FLAT\"),\n-        (\"simple_key_hashed_update_field_dictionary\", \"HASHED\"),\n-        (\"complex_key_hashed_update_field_dictionary\", \"COMPLEX_KEY_HASHED\"),\n-    ],\n-)\n-def test_update_field(started_cluster, dictionary_name, dictionary_type):\n-    create_dictionary_query = \"\"\"\n-        CREATE DICTIONARY {dictionary_name}\n-        (\n-            key UInt64,\n-            value String,\n-            last_insert_time DateTime\n-        )\n-        PRIMARY KEY key\n-        SOURCE(CLICKHOUSE(table 'table_for_update_field_dictionary' update_field 'last_insert_time'))\n-        LAYOUT({dictionary_type}())\n-        LIFETIME(1);\n-        \"\"\".format(\n-        dictionary_name=dictionary_name, dictionary_type=dictionary_type\n-    )\n-\n-    node.query(create_dictionary_query)\n-\n+def dictionary_update_field_actions(dictionary_name):\n     node.query(\n         \"INSERT INTO table_for_update_field_dictionary VALUES (1, 'First', now());\"\n     )\n@@ -72,6 +47,7 @@ def test_update_field(started_cluster, dictionary_name, dictionary_type):\n     node.query(\n         \"INSERT INTO table_for_update_field_dictionary VALUES (2, 'Second', now());\"\n     )\n+\n     time.sleep(10)\n \n     query_result = node.query(\n@@ -103,3 +79,59 @@ def test_update_field(started_cluster, dictionary_name, dictionary_type):\n     node.query(\n         \"DROP DICTIONARY {dictionary_name}\".format(dictionary_name=dictionary_name)\n     )\n+\n+\n+@pytest.mark.parametrize(\n+    \"dictionary_name,dictionary_type\",\n+    [\n+        (\"flat_update_field_dictionary\", \"FLAT\"),\n+        (\"simple_key_hashed_update_field_dictionary\", \"HASHED\"),\n+        (\"complex_key_hashed_update_field_dictionary\", \"COMPLEX_KEY_HASHED\"),\n+    ],\n+)\n+def test_update_field(started_cluster, dictionary_name, dictionary_type):\n+    create_dictionary_query = \"\"\"\n+        CREATE DICTIONARY {dictionary_name}\n+        (\n+            key UInt64,\n+            value String,\n+            last_insert_time DateTime\n+        )\n+        PRIMARY KEY key\n+        SOURCE(CLICKHOUSE(table 'table_for_update_field_dictionary' update_field 'last_insert_time'))\n+        LAYOUT({dictionary_type}())\n+        LIFETIME(1);\n+        \"\"\".format(\n+        dictionary_name=dictionary_name, dictionary_type=dictionary_type\n+    )\n+\n+    node.query(create_dictionary_query)\n+    dictionary_update_field_actions(dictionary_name)\n+\n+\n+@pytest.mark.parametrize(\n+    \"dictionary_name,dictionary_type\",\n+    [\n+        (\"flat_update_field_dictionary\", \"FLAT\"),\n+        (\"simple_key_hashed_update_field_dictionary\", \"HASHED\"),\n+        (\"complex_key_hashed_update_field_dictionary\", \"COMPLEX_KEY_HASHED\"),\n+    ],\n+)\n+def test_update_field_custom_query(started_cluster, dictionary_name, dictionary_type):\n+    create_dictionary_query = \"\"\"\n+        CREATE DICTIONARY {dictionary_name}\n+        (\n+            key UInt64,\n+            value String,\n+            last_insert_time DateTime\n+        )\n+        PRIMARY KEY key\n+        SOURCE(CLICKHOUSE(query $doc$SELECT key, value, last_insert_time FROM table_for_update_field_dictionary WHERE {{condition}};$doc$ update_field 'last_insert_time'))\n+        LAYOUT({dictionary_type}())\n+        LIFETIME(1);\n+        \"\"\".format(\n+        dictionary_name=dictionary_name, dictionary_type=dictionary_type\n+    )\n+\n+    node.query(create_dictionary_query)\n+    dictionary_update_field_actions(dictionary_name)\n",
  "problem_statement": "{condition} placeholder does not work for external dictionaries with custom query and `update_field`\nUse of custom query/placeholder for external dictionaries.\r\nThe `placeholder` is similar to `update_field`\r\n\r\nCurrent implementation supports only simple table field like \r\n`SOURCE(CLICKHOUSE(... update_field 'added_time' update_lag 15))`\r\nbut miss support for complex/compound expressions (that for example could use index more efficiently).\r\n\r\nExample: \r\nquery = \"\r\n    ....\r\n    from t1\r\n    where :placeholder between col1 and col2 and col3=42\r\n    \"\r\ninvalidate_query=\r\nplaceholder_query = \"select max(col1) from t1 ...\",\r\nplaceholder_init_str = \"toDateTime('1970-01-01')\"\r\n\r\nSo initial value of placeholder is calculated from `placeholder_init_str`,\r\nnext value from `invalidate_query`\r\nand could be used in query.\r\n\r\nBy introducing this feature work with dictionary sources will be more flexible and general.\n",
  "hints_text": "After discussion, it seems that such feature request need to be explained better.\r\nHow it works right now.\r\n\r\nClient can specify `update_field` and for some dictionaries, like Flat, Hashed, ArrayHashed, RangeHashed will work functionality that only necessary data will be requested from source, and dictionary will be updated incrementally. For external source query ClickHouse will send query like this: \r\n```sql\r\nSELECT * FROM test_table WHERE update_field > last_update_time.\r\n```\r\n\r\n`invalidate_query` right now is used to check if dictionary was modified, it does not related to `update_field` in any way. It works like this, ClickHouse will get result of invalidate_query, during first dictionary load, if dictionary lifetime expires, ClickHouse will recheck result of invalidate_query, if it will be same as before, no update will be required. `invalidate_query` is necessary for check if dictionary was modified.\r\n\r\nNow related this feature request:\r\n\r\nIn which case current implementation does not provide necessary performance ? Could you please provide example with table configuration, and example select query ?\r\n\r\nWe could probably provide changing `update_field` to some update subquery, that way result query that will be sended to external DBMS will look like:\r\n```sql\r\nSELECT * FROM test_table WHERE (SELECT max(update_field) FROM test_table) > last_update_time.\r\n```\r\nBut not sure if this really makes any difference. We should not mix `invalidate_query`, and `update_field` logic, so I just need to better understand which issue  is in your current configuration.\n\r\nIt is about custom query support (https://github.com/ClickHouse/ClickHouse/pull/26995) and update field.\r\n\r\n```sql\r\nDROP TABLE IF EXISTS test_dict_source;\r\n\r\nCREATE TABLE test_dict_source engine=MergeTree ORDER BY insert_time SETTINGS index_granularity = 1 AS SELECT now() as insert_time, range(10) as ids, rand() as value from numbers(300);\r\n\r\n\r\n/* case 1: it's hard to put WHERE condition in the proper place for some queries */\r\nDROP DICTIONARY IF EXISTS test_dictionary_custom_query;\r\nCREATE DICTIONARY test_dictionary_custom_query\r\n(\r\n    id UInt64,\r\n    value UInt32\r\n)\r\nPRIMARY KEY id\r\nLAYOUT(FLAT())\r\nSOURCE(CLICKHOUSE(\r\n    UPDATE_FIELD insert_time\r\n    QUERY $doc$SELECT arrayJoin(ids), value FROM default.test_dict_source WHERE sleepEachRow(0.01) SETTINGS optimize_move_to_prewhere=0$doc$))\r\n\r\nLIFETIME(MIN 1 MAX 1);\r\n\r\n-- normal load\r\nselect dictGet(test_dictionary_custom_query, 'value', 1);\r\n\r\n-- load with UPDATE_FIELD (WHERE is misplaced)\r\nselect dictGet(test_dictionary_custom_query, 'value', 1);\r\n\r\n/*\r\nSELECT last_exception\r\nFROM system.dictionaries\r\nWHERE name = 'test_dictionary_custom_query'\r\n\r\nQuery id: 7c181a07-9095-4880-8382-f1daff89f5df\r\n\r\nRow 1:\r\n\u2500\u2500\u2500\u2500\u2500\u2500\r\nlast_exception: Code: 62. DB::Exception: Syntax error: failed at position 146 ('WHERE'): WHERE insert_time >= '2022-05-30 17:10:43';. Expected one of: UNION, EXCEPT, INTERSECT, INTO OUTFILE, FORMAT, SETTINGS, end of query. (SYNTAX_ERROR) (version 22.5.1.1)\r\n*/\r\n```\r\n\r\n`{condition}` placeholder should be the workaround (https://github.com/ClickHouse/ClickHouse/pull/26995#discussion_r686142595) but it seems that does not work:\r\n\r\n```sql\r\nDROP DICTIONARY IF EXISTS test_dictionary_custom_query;\r\nCREATE DICTIONARY test_dictionary_custom_query\r\n(\r\n    id UInt64,\r\n    value UInt32\r\n)\r\nPRIMARY KEY id\r\nLAYOUT(FLAT())\r\nSOURCE(CLICKHOUSE(\r\n    UPDATE_FIELD insert_time\r\n    QUERY $doc$SELECT arrayJoin(ids), value FROM default.test_dict_source WHERE sleepEachRow(0.01) AND {condition} SETTINGS optimize_move_to_prewhere=0$doc$))\r\n\r\nLIFETIME(MIN 1 MAX 1);\r\n\r\nselect dictGet(test_dictionary_custom_query, 'value', 1);\r\n\r\n/*\r\nSELECT last_exception\r\nFROM system.dictionaries\r\nWHERE name = 'test_dictionary_custom_query'\r\n\r\nQuery id: 7c181a07-9095-4880-8382-f1daff89f5df\r\n\r\n\u250c\u2500last_exception\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 Code: 62. DB::Exception: Syntax error: failed at position 99 ('}'): } SETTINGS optimize_move_to_prewhere=0. Expected colon between name and type. (SYNTAX_ERROR) (version 22.5.1.1) \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n*/\r\n```\r\n\r\ncase 2: manual push down of the condition is required to avoid full scans / big joins etc\r\n\r\n```sql\r\n/* i intentionally used here array join which turns off the predicate push down, to mimic the problem */\r\n/* IRL it is a complex query with a lot of suqueries & joins to postgres */\r\n\r\nDROP DICTIONARY IF EXISTS test_dictionary_custom_query;\r\nCREATE DICTIONARY test_dictionary_custom_query\r\n(\r\n    id UInt64,\r\n    value UInt32\r\n)\r\nPRIMARY KEY id\r\nLAYOUT(FLAT())\r\nSOURCE(CLICKHOUSE(\r\n    UPDATE_FIELD insert_time\r\n    QUERY $doc$SELECT id, value FROM (SELECT ids, value, insert_time FROM default.test_dict_source WHERE sleepEachRow(0.01)) t array join ids as id$doc$))\r\nLIFETIME(MIN 1 MAX 1);\r\n\r\n\r\n-- normal load\r\nselect dictGet(test_dictionary_custom_query, 'value', 1);\r\n\r\n-- that should be instant \r\nselect dictGet(test_dictionary_custom_query, 'value', 1);\r\n```\r\n\r\nAgain the `{condition}` placeholder should be enough to workaround the problem\r\n\r\n```sql\r\n    QUERY $doc$SELECT id, value FROM (SELECT ids, value, insert_time FROM default.test_dict_source WHERE sleepEachRow(0.01) AND {condition}) t array join ids as id$doc$))\r\n```\r\n\r\nThe alternative (maybe even more flexible) is introducing one more placeholder called `{last_load_time}`. (in that case it is not needed to use `update_field` at all).",
  "created_at": "2022-06-09T09:51:32Z",
  "modified_files": [
    "src/Dictionaries/ExternalQueryBuilder.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_dictionaries_update_field/test.py"
  ]
}