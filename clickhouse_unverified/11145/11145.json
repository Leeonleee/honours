{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 11145,
  "instance_id": "ClickHouse__ClickHouse-11145",
  "issue_numbers": [
    "7260"
  ],
  "base_commit": "27f365dc10d0ed59a25c4203869724d4d218c9b9",
  "patch": "diff --git a/contrib/cppkafka b/contrib/cppkafka\nindex 9b184d881c15..f555ee36aaa7 160000\n--- a/contrib/cppkafka\n+++ b/contrib/cppkafka\n@@ -1,1 +1,1 @@\n-Subproject commit 9b184d881c15cc50784b28688c7c99d3d764db24\n+Subproject commit f555ee36aaa74d17ca0dab3ce472070a610b2966\ndiff --git a/src/Storages/Kafka/ReadBufferFromKafkaConsumer.cpp b/src/Storages/Kafka/ReadBufferFromKafkaConsumer.cpp\nindex ad9d660a989b..0040cd049068 100644\n--- a/src/Storages/Kafka/ReadBufferFromKafkaConsumer.cpp\n+++ b/src/Storages/Kafka/ReadBufferFromKafkaConsumer.cpp\n@@ -15,6 +15,7 @@ namespace ErrorCodes\n \n using namespace std::chrono_literals;\n const auto MAX_TIME_TO_WAIT_FOR_ASSIGNMENT_MS = 15000;\n+const auto DRAIN_TIMEOUT_MS = 5000ms;\n \n \n ReadBufferFromKafkaConsumer::ReadBufferFromKafkaConsumer(\n@@ -80,9 +81,72 @@ ReadBufferFromKafkaConsumer::ReadBufferFromKafkaConsumer(\n     });\n }\n \n-// NOTE on removed desctuctor: There is no need to unsubscribe prior to calling rd_kafka_consumer_close().\n-// check: https://github.com/edenhill/librdkafka/blob/master/INTRODUCTION.md#termination\n-// manual destruction was source of weird errors (hangs during droping kafka table, etc.)\n+ReadBufferFromKafkaConsumer::~ReadBufferFromKafkaConsumer()\n+{\n+    try\n+    {\n+        if (!consumer->get_subscription().empty())\n+        {\n+            try\n+            {\n+                consumer->unsubscribe();\n+            }\n+            catch (const cppkafka::HandleException & e)\n+            {\n+                LOG_ERROR(log, \"Error during unsubscribe: \" << e.what());\n+            }\n+            drain();\n+        }\n+    }\n+    catch (const cppkafka::HandleException & e)\n+    {\n+        LOG_ERROR(log, \"Error while destructing consumer: \" << e.what());\n+    }\n+\n+}\n+\n+// Needed to drain rest of the messages / queued callback calls from the consumer\n+// after unsubscribe, otherwise consumer will hang on destruction\n+// see https://github.com/edenhill/librdkafka/issues/2077\n+//     https://github.com/confluentinc/confluent-kafka-go/issues/189 etc.\n+void ReadBufferFromKafkaConsumer::drain()\n+{\n+    auto start_time = std::chrono::steady_clock::now();\n+    cppkafka::Error last_error(RD_KAFKA_RESP_ERR_NO_ERROR);\n+\n+    while (true)\n+    {\n+        auto msg = consumer->poll(100ms);\n+        if (!msg)\n+            break;\n+\n+        auto error = msg.get_error();\n+\n+        if (error)\n+        {\n+            if (msg.is_eof() || error == last_error)\n+            {\n+                break;\n+            }\n+            else\n+            {\n+                LOG_ERROR(log, \"Error during draining: \" << error);\n+            }\n+        }\n+\n+        // i don't stop draining on first error,\n+        // only if it repeats once again sequentially\n+        last_error = error;\n+\n+        auto ts = std::chrono::steady_clock::now();\n+        if (std::chrono::duration_cast<std::chrono::milliseconds>(ts-start_time) > DRAIN_TIMEOUT_MS)\n+        {\n+            LOG_ERROR(log, \"Timeout during draining.\");\n+            break;\n+        }\n+    }\n+}\n+\n \n void ReadBufferFromKafkaConsumer::commit()\n {\ndiff --git a/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h b/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h\nindex 46dace827d0e..12da701a55d3 100644\n--- a/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h\n+++ b/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h\n@@ -28,7 +28,7 @@ class ReadBufferFromKafkaConsumer : public ReadBuffer\n         const std::atomic<bool> & stopped_,\n         const Names & _topics\n     );\n-\n+    ~ReadBufferFromKafkaConsumer() override;\n     void allowNext() { allowed = true; } // Allow to read next message.\n     void commit(); // Commit all processed messages.\n     void subscribe(); // Subscribe internal consumer to topics.\n@@ -75,6 +75,8 @@ class ReadBufferFromKafkaConsumer : public ReadBuffer\n     cppkafka::TopicPartitionList assignment;\n     const Names topics;\n \n+    void drain();\n+\n     bool nextImpl() override;\n };\n \ndiff --git a/src/Storages/Kafka/StorageKafka.cpp b/src/Storages/Kafka/StorageKafka.cpp\nindex 793a9a29676b..3f853c8899e8 100644\n--- a/src/Storages/Kafka/StorageKafka.cpp\n+++ b/src/Storages/Kafka/StorageKafka.cpp\n@@ -293,6 +293,7 @@ ConsumerBufferPtr StorageKafka::createReadBuffer()\n \n     // Create a consumer and subscribe to topics\n     auto consumer = std::make_shared<cppkafka::Consumer>(conf);\n+    consumer->set_destroy_flags(RD_KAFKA_DESTROY_F_NO_CONSUMER_CLOSE);\n \n     // Limit the number of batched messages to allow early cancellations\n     const Settings & settings = global_context.getSettingsRef();\n",
  "test_patch": "diff --git a/tests/integration/test_storage_kafka/test.py b/tests/integration/test_storage_kafka/test.py\nindex 9154ad67c059..8e329a1cb605 100644\n--- a/tests/integration/test_storage_kafka/test.py\n+++ b/tests/integration/test_storage_kafka/test.py\n@@ -246,6 +246,50 @@ def test_kafka_consumer_hang(kafka_cluster):\n     # 'dr'||'op' to avoid self matching\n     assert int(instance.query(\"select count() from system.processes where position(lower(query),'dr'||'op')>0\")) == 0\n \n+@pytest.mark.timeout(180)\n+def test_kafka_consumer_hang2(kafka_cluster):\n+\n+    instance.query('''\n+        DROP TABLE IF EXISTS test.kafka;\n+\n+        CREATE TABLE test.kafka (key UInt64, value UInt64)\n+            ENGINE = Kafka\n+            SETTINGS kafka_broker_list = 'kafka1:19092',\n+                     kafka_topic_list = 'consumer_hang2',\n+                     kafka_group_name = 'consumer_hang2',\n+                     kafka_format = 'JSONEachRow';\n+\n+        CREATE TABLE test.kafka2 (key UInt64, value UInt64)\n+            ENGINE = Kafka\n+            SETTINGS kafka_broker_list = 'kafka1:19092',\n+                     kafka_topic_list = 'consumer_hang2',\n+                     kafka_group_name = 'consumer_hang2',\n+                     kafka_format = 'JSONEachRow';\n+        ''')\n+\n+    # first consumer subscribe the topic, try to poll some data, and go to rest\n+    instance.query('SELECT * FROM test.kafka')\n+\n+    # second consumer do the same leading to rebalance in the first\n+    # consumer, try to poll some data\n+    instance.query('SELECT * FROM test.kafka2')\n+\n+#echo 'SELECT * FROM test.kafka; SELECT * FROM test.kafka2; DROP TABLE test.kafka;' | clickhouse client -mn &\n+#    kafka_cluster.open_bash_shell('instance')\n+\n+    # first consumer has pending rebalance callback unprocessed (no poll after select)\n+    # one of those queries was failing because of\n+    # https://github.com/edenhill/librdkafka/issues/2077\n+    # https://github.com/edenhill/librdkafka/issues/2898\n+    instance.query('DROP TABLE test.kafka')\n+    instance.query('DROP TABLE test.kafka2')\n+\n+\n+    # from a user perspective: we expect no hanging 'drop' queries\n+    # 'dr'||'op' to avoid self matching\n+    assert int(instance.query(\"select count() from system.processes where position(lower(query),'dr'||'op')>0\")) == 0\n+\n+\n @pytest.mark.timeout(180)\n def test_kafka_csv_with_delimiter(kafka_cluster):\n     instance.query('''\n@@ -1130,6 +1174,7 @@ def produce():\n \n     print(instance.query('SELECT count(), uniqExact(key), max(key) + 1 FROM test.destination'))\n \n+    # Some queries to debug...\n     # SELECT * FROM test.destination where key in (SELECT key FROM test.destination group by key having count() <> 1)\n     # select number + 1 as key from numbers(4141) left join test.destination using (key) where  test.destination.key = 0;\n     # SELECT * FROM test.destination WHERE key between 2360 and 2370 order by key;\n@@ -1137,6 +1182,18 @@ def produce():\n     # select toUInt64(0) as _partition, number + 1 as _offset from numbers(400) left join test.destination using (_partition,_offset) where test.destination.key = 0 order by _offset;\n     # SELECT * FROM test.destination WHERE _partition = 0 and _offset between 220 and 240 order by _offset;\n \n+    # CREATE TABLE test.reference (key UInt64, value UInt64) ENGINE = Kafka SETTINGS kafka_broker_list = 'kafka1:19092',\n+    #             kafka_topic_list = 'topic_with_multiple_partitions',\n+    #             kafka_group_name = 'rebalance_test_group_reference',\n+    #             kafka_format = 'JSONEachRow',\n+    #             kafka_max_block_size = 100000;\n+    #\n+    # CREATE MATERIALIZED VIEW test.reference_mv Engine=Log AS\n+    #     SELECT  key, value, _topic,_key,_offset, _partition, _timestamp, 'reference' as _consumed_by\n+    # FROM test.reference;\n+    #\n+    # select * from test.reference_mv left join test.destination using (key,_topic,_offset,_partition) where test.destination._consumed_by = '';\n+\n     result = int(instance.query('SELECT count() == uniqExact(key) FROM test.destination'))\n \n     for consumer_index in range(NUMBER_OF_CONSURRENT_CONSUMERS):\n",
  "problem_statement": "Kafka: drop Kafka table sometimes hangs\nstacktrace at the moment of hang.\r\nhttps://gist.github.com/filimonov/c51e77f50b4eebb43a133c6cfc4d9066\n",
  "hints_text": "According to stacktrace it's a known internal rdkafka problem, but it should be very rare - so more details about repro scenario are required.",
  "created_at": "2020-05-22T14:36:34Z",
  "modified_files": [
    "contrib/cppkafka",
    "src/Storages/Kafka/ReadBufferFromKafkaConsumer.cpp",
    "src/Storages/Kafka/ReadBufferFromKafkaConsumer.h",
    "src/Storages/Kafka/StorageKafka.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_storage_kafka/test.py"
  ]
}