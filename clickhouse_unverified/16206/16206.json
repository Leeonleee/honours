{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 16206,
  "instance_id": "ClickHouse__ClickHouse-16206",
  "issue_numbers": [
    "14560"
  ],
  "base_commit": "b26e979e5c91200eef24775df4e4bfb317a4f40a",
  "patch": "diff --git a/src/Common/MemoryTracker.cpp b/src/Common/MemoryTracker.cpp\nindex 5d51fc9f301b..87567591ddfe 100644\n--- a/src/Common/MemoryTracker.cpp\n+++ b/src/Common/MemoryTracker.cpp\n@@ -30,6 +30,8 @@ namespace ProfileEvents\n \n static constexpr size_t log_peak_memory_usage_every = 1ULL << 30;\n \n+thread_local bool MemoryTracker::BlockerInThread::is_blocked = false;\n+\n MemoryTracker total_memory_tracker(nullptr, VariableContext::Global);\n \n \n@@ -56,13 +58,15 @@ MemoryTracker::~MemoryTracker()\n void MemoryTracker::logPeakMemoryUsage() const\n {\n     const auto * description = description_ptr.load(std::memory_order_relaxed);\n-    LOG_DEBUG(&Poco::Logger::get(\"MemoryTracker\"), \"Peak memory usage{}: {}.\", (description ? \" \" + std::string(description) : \"\"), ReadableSize(peak));\n+    LOG_DEBUG(&Poco::Logger::get(\"MemoryTracker\"),\n+        \"Peak memory usage{}: {}.\", (description ? \" \" + std::string(description) : \"\"), ReadableSize(peak));\n }\n \n void MemoryTracker::logMemoryUsage(Int64 current) const\n {\n     const auto * description = description_ptr.load(std::memory_order_relaxed);\n-    LOG_DEBUG(&Poco::Logger::get(\"MemoryTracker\"), \"Current memory usage{}: {}.\", (description ? \" \" + std::string(description) : \"\"), ReadableSize(current));\n+    LOG_DEBUG(&Poco::Logger::get(\"MemoryTracker\"),\n+        \"Current memory usage{}: {}.\", (description ? \" \" + std::string(description) : \"\"), ReadableSize(current));\n }\n \n \n@@ -71,7 +75,7 @@ void MemoryTracker::alloc(Int64 size)\n     if (size < 0)\n         throw DB::Exception(DB::ErrorCodes::LOGICAL_ERROR, \"Negative size ({}) is passed to MemoryTracker. It is a bug.\", size);\n \n-    if (blocker.isCancelled())\n+    if (BlockerInThread::isBlocked())\n         return;\n \n     /** Using memory_order_relaxed means that if allocations are done simultaneously,\n@@ -86,12 +90,15 @@ void MemoryTracker::alloc(Int64 size)\n     Int64 current_hard_limit = hard_limit.load(std::memory_order_relaxed);\n     Int64 current_profiler_limit = profiler_limit.load(std::memory_order_relaxed);\n \n-    /// Cap the limit to the total_memory_tracker, since it may include some drift.\n+    /// Cap the limit to the total_memory_tracker, since it may include some drift\n+    /// for user-level memory tracker.\n     ///\n     /// And since total_memory_tracker is reset to the process resident\n     /// memory peridically (in AsynchronousMetrics::update()), any limit can be\n     /// capped to it, to avoid possible drift.\n-    if (unlikely(current_hard_limit && will_be > current_hard_limit))\n+    if (unlikely(current_hard_limit\n+        && will_be > current_hard_limit\n+        && level == VariableContext::User))\n     {\n         Int64 total_amount = total_memory_tracker.get();\n         if (amount > total_amount)\n@@ -104,10 +111,8 @@ void MemoryTracker::alloc(Int64 size)\n     std::bernoulli_distribution fault(fault_probability);\n     if (unlikely(fault_probability && fault(thread_local_rng)))\n     {\n-        free(size);\n-\n         /// Prevent recursion. Exception::ctor -> std::string -> new[] -> MemoryTracker::alloc\n-        auto untrack_lock = blocker.cancel(); // NOLINT\n+        BlockerInThread untrack_lock;\n \n         ProfileEvents::increment(ProfileEvents::QueryMemoryLimitExceeded);\n         std::stringstream message;\n@@ -118,12 +123,13 @@ void MemoryTracker::alloc(Int64 size)\n             << \" (attempt to allocate chunk of \" << size << \" bytes)\"\n             << \", maximum: \" << formatReadableSizeWithBinarySuffix(current_hard_limit);\n \n+        amount.fetch_sub(size, std::memory_order_relaxed);\n         throw DB::Exception(message.str(), DB::ErrorCodes::MEMORY_LIMIT_EXCEEDED);\n     }\n \n     if (unlikely(current_profiler_limit && will_be > current_profiler_limit))\n     {\n-        auto no_track = blocker.cancel();\n+        BlockerInThread untrack_lock;\n         DB::TraceCollector::collect(DB::TraceType::Memory, StackTrace(), size);\n         setOrRaiseProfilerLimit((will_be + profiler_step - 1) / profiler_step * profiler_step);\n     }\n@@ -131,16 +137,14 @@ void MemoryTracker::alloc(Int64 size)\n     std::bernoulli_distribution sample(sample_probability);\n     if (unlikely(sample_probability && sample(thread_local_rng)))\n     {\n-        auto no_track = blocker.cancel();\n+        BlockerInThread untrack_lock;\n         DB::TraceCollector::collect(DB::TraceType::MemorySample, StackTrace(), size);\n     }\n \n     if (unlikely(current_hard_limit && will_be > current_hard_limit))\n     {\n-        free(size);\n-\n         /// Prevent recursion. Exception::ctor -> std::string -> new[] -> MemoryTracker::alloc\n-        auto no_track = blocker.cancel(); // NOLINT\n+        BlockerInThread untrack_lock;\n \n         ProfileEvents::increment(ProfileEvents::QueryMemoryLimitExceeded);\n         std::stringstream message;\n@@ -151,6 +155,7 @@ void MemoryTracker::alloc(Int64 size)\n             << \" (attempt to allocate chunk of \" << size << \" bytes)\"\n             << \", maximum: \" << formatReadableSizeWithBinarySuffix(current_hard_limit);\n \n+        amount.fetch_sub(size, std::memory_order_relaxed);\n         throw DB::Exception(message.str(), DB::ErrorCodes::MEMORY_LIMIT_EXCEEDED);\n     }\n \n@@ -177,13 +182,13 @@ void MemoryTracker::updatePeak(Int64 will_be)\n \n void MemoryTracker::free(Int64 size)\n {\n-    if (blocker.isCancelled())\n+    if (BlockerInThread::isBlocked())\n         return;\n \n     std::bernoulli_distribution sample(sample_probability);\n     if (unlikely(sample_probability && sample(thread_local_rng)))\n     {\n-        auto no_track = blocker.cancel();\n+        BlockerInThread untrack_lock;\n         DB::TraceCollector::collect(DB::TraceType::MemorySample, StackTrace(), -size);\n     }\n \n@@ -298,11 +303,3 @@ namespace CurrentMemoryTracker\n         }\n     }\n }\n-\n-DB::SimpleActionLock getCurrentMemoryTrackerActionLock()\n-{\n-    auto * memory_tracker = DB::CurrentThread::getMemoryTracker();\n-    if (!memory_tracker)\n-        return {};\n-    return memory_tracker->blocker.cancel();\n-}\ndiff --git a/src/Common/MemoryTracker.h b/src/Common/MemoryTracker.h\nindex 8af683ae7909..9f4f43570248 100644\n--- a/src/Common/MemoryTracker.h\n+++ b/src/Common/MemoryTracker.h\n@@ -3,7 +3,6 @@\n #include <atomic>\n #include <common/types.h>\n #include <Common/CurrentMetrics.h>\n-#include <Common/SimpleActionBlocker.h>\n #include <Common/VariableContext.h>\n \n \n@@ -131,8 +130,18 @@ class MemoryTracker\n     /// Prints info about peak memory consumption into log.\n     void logPeakMemoryUsage() const;\n \n-    /// To be able to temporarily stop memory tracker\n-    DB::SimpleActionBlocker blocker;\n+    /// To be able to temporarily stop memory tracking from current thread.\n+    struct BlockerInThread\n+    {\n+    private:\n+        BlockerInThread(const BlockerInThread &) = delete;\n+        BlockerInThread & operator=(const BlockerInThread &) = delete;\n+        static thread_local bool is_blocked;\n+    public:\n+        BlockerInThread() { is_blocked = true; }\n+        ~BlockerInThread() { is_blocked = false; }\n+        static bool isBlocked() { return is_blocked; }\n+    };\n };\n \n extern MemoryTracker total_memory_tracker;\n@@ -145,7 +154,3 @@ namespace CurrentMemoryTracker\n     void realloc(Int64 old_size, Int64 new_size);\n     void free(Int64 size);\n }\n-\n-\n-/// Holding this object will temporarily disable memory tracking.\n-DB::SimpleActionLock getCurrentMemoryTrackerActionLock();\ndiff --git a/src/Interpreters/SystemLog.h b/src/Interpreters/SystemLog.h\nindex 2a0ce9cef537..99a854053487 100644\n--- a/src/Interpreters/SystemLog.h\n+++ b/src/Interpreters/SystemLog.h\n@@ -233,7 +233,7 @@ void SystemLog<LogElement>::add(const LogElement & element)\n     /// The size of allocation can be in order of a few megabytes.\n     /// But this should not be accounted for query memory usage.\n     /// Otherwise the tests like 01017_uniqCombined_memory_usage.sql will be flacky.\n-    auto temporarily_disable_memory_tracker = getCurrentMemoryTrackerActionLock();\n+    MemoryTracker::BlockerInThread temporarily_disable_memory_tracker;\n \n     /// Should not log messages under mutex.\n     bool queue_is_half_full = false;\ndiff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp\nindex d66fdeea46fe..817682839441 100644\n--- a/src/Interpreters/executeQuery.cpp\n+++ b/src/Interpreters/executeQuery.cpp\n@@ -157,7 +157,7 @@ static void setExceptionStackTrace(QueryLogElement & elem)\n {\n     /// Disable memory tracker for stack trace.\n     /// Because if exception is \"Memory limit (for query) exceed\", then we probably can't allocate another one string.\n-    auto temporarily_disable_memory_tracker = getCurrentMemoryTrackerActionLock();\n+    MemoryTracker::BlockerInThread temporarily_disable_memory_tracker;\n \n     try\n     {\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\nindex 27d306e1642f..319b486c2c6e 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n@@ -408,7 +408,7 @@ void IMergeTreeDataPart::loadColumnsChecksumsIndexes(bool require_columns_checks\n     /// Memory should not be limited during ATTACH TABLE query.\n     /// This is already true at the server startup but must be also ensured for manual table ATTACH.\n     /// Motivation: memory for index is shared between queries - not belong to the query itself.\n-    auto temporarily_disable_memory_tracker = getCurrentMemoryTrackerActionLock();\n+    MemoryTracker::BlockerInThread temporarily_disable_memory_tracker;\n \n     loadColumns(require_columns_checksums);\n     loadChecksums(require_columns_checksums);\ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp b/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\nindex c6b689da33a3..21db4827f42e 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\n@@ -212,7 +212,7 @@ void MergeTreeDataPartWriterOnDisk::calculateAndSerializePrimaryIndex(const Bloc\n      * And otherwise it will look like excessively growing memory consumption in context of query.\n      *  (observed in long INSERT SELECTs)\n      */\n-    auto temporarily_disable_memory_tracker = getCurrentMemoryTrackerActionLock();\n+    MemoryTracker::BlockerInThread temporarily_disable_memory_tracker;\n \n     /// Write index. The index contains Primary Key value for each `index_granularity` row.\n \ndiff --git a/src/Storages/MergeTree/MergeTreeMarksLoader.cpp b/src/Storages/MergeTree/MergeTreeMarksLoader.cpp\nindex a7107789bfdb..c5a99b128e9a 100644\n--- a/src/Storages/MergeTree/MergeTreeMarksLoader.cpp\n+++ b/src/Storages/MergeTree/MergeTreeMarksLoader.cpp\n@@ -48,7 +48,7 @@ const MarkInCompressedFile & MergeTreeMarksLoader::getMark(size_t row_index, siz\n MarkCache::MappedPtr MergeTreeMarksLoader::loadMarksImpl()\n {\n     /// Memory for marks must not be accounted as memory usage for query, because they are stored in shared cache.\n-    auto temporarily_disable_memory_tracker = getCurrentMemoryTrackerActionLock();\n+    MemoryTracker::BlockerInThread temporarily_disable_memory_tracker;\n \n     size_t file_size = disk->getFileSize(mrk_path);\n     size_t mark_size = index_granularity_info.getMarkSizeInBytes(columns_in_mark);\ndiff --git a/src/Storages/StorageBuffer.cpp b/src/Storages/StorageBuffer.cpp\nindex 659df2026c80..87d11e32eae4 100644\n--- a/src/Storages/StorageBuffer.cpp\n+++ b/src/Storages/StorageBuffer.cpp\n@@ -315,7 +315,7 @@ static void appendBlock(const Block & from, Block & to)\n \n     size_t old_rows = to.rows();\n \n-    auto temporarily_disable_memory_tracker = getCurrentMemoryTrackerActionLock();\n+    MemoryTracker::BlockerInThread temporarily_disable_memory_tracker;\n \n     try\n     {\n@@ -693,7 +693,7 @@ void StorageBuffer::writeBlockToDestination(const Block & block, StoragePtr tabl\n     }\n     auto destination_metadata_snapshot = table->getInMemoryMetadataPtr();\n \n-    auto temporarily_disable_memory_tracker = getCurrentMemoryTrackerActionLock();\n+    MemoryTracker::BlockerInThread temporarily_disable_memory_tracker;\n \n     auto insert = std::make_shared<ASTInsertQuery>();\n     insert->table_id = destination_id;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01529_bad_memory_tracking.reference b/tests/queries/0_stateless/01529_bad_memory_tracking.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/01529_bad_memory_tracking.sh b/tests/queries/0_stateless/01529_bad_memory_tracking.sh\nnew file mode 100755\nindex 000000000000..f91f6ebaf80c\n--- /dev/null\n+++ b/tests/queries/0_stateless/01529_bad_memory_tracking.sh\n@@ -0,0 +1,10 @@\n+#!/usr/bin/env bash\n+\n+CLICKHOUSE_CLIENT_SERVER_LOGS_LEVEL=fatal\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. \"$CURDIR\"/../shell_config.sh\n+\n+for _ in {1..10}; do\n+    ${CLICKHOUSE_CLIENT} --max_memory_usage '10G' --query \"SELECT i FROM generateRandom('i Array(Int8)', 1, 1, 1048577) LIMIT 65536\" 2>&1 | grep -v -P '^(Received exception from server|Code: 241)' ||:\n+done\n",
  "problem_statement": "A query from `generateRandom` function may lead to OOM\n**Describe the bug**\r\n`SELECT i FROM generateRandom('i Array(Int8)', 1048575, 10, 1048577) LIMIT 1048575`\r\n\r\nMemory limit should be respected.\n",
  "hints_text": "```\r\nSELECT i FROM generateRandom('i Array(Nullable(Enum8(\\'hello\\' = 1, \\'world\\' = 5)))', 1024, 1048575, 1048575) LIMIT 1048575\r\n```\nRegression: https://github.com/ClickHouse/ClickHouse/pull/12182\n\\+ wrong logic and logical race condition.",
  "created_at": "2020-10-21T00:32:58Z",
  "modified_files": [
    "src/Common/MemoryTracker.cpp",
    "src/Common/MemoryTracker.h",
    "src/Interpreters/SystemLog.h",
    "src/Interpreters/executeQuery.cpp",
    "src/Storages/MergeTree/IMergeTreeDataPart.cpp",
    "src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp",
    "src/Storages/MergeTree/MergeTreeMarksLoader.cpp",
    "src/Storages/StorageBuffer.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/01529_bad_memory_tracking.sh"
  ]
}