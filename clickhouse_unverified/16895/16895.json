{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 16895,
  "instance_id": "ClickHouse__ClickHouse-16895",
  "issue_numbers": [
    "15180",
    "16629",
    "5491"
  ],
  "base_commit": "6e62108606bbe8212ff301796ea5c19fd27da468",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex dc940822abcd..6ff72cfe478b 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -1215,6 +1215,20 @@ void MergeTreeData::clearOldWriteAheadLogs()\n     }\n }\n \n+void MergeTreeData::clearEmptyParts()\n+{\n+    auto parts = getDataPartsVector();\n+    for (const auto & part : parts)\n+    {\n+        if (part->rows_count == 0)\n+        {\n+            ASTPtr literal = std::make_shared<ASTLiteral>(part->name);\n+            /// If another replica has already started drop, it's ok, no need to throw.\n+            dropPartition(literal, /* detach = */ false, /*drop_part = */ true, global_context, /* throw_if_noop = */ false);\n+        }\n+    }\n+}\n+\n void MergeTreeData::rename(const String & new_table_path, const StorageID & new_table_id)\n {\n     auto disks = getStoragePolicy()->getDisks();\ndiff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h\nindex 0e3e5aff4f1d..34faafb3b1f3 100644\n--- a/src/Storages/MergeTree/MergeTreeData.h\n+++ b/src/Storages/MergeTree/MergeTreeData.h\n@@ -498,6 +498,8 @@ class MergeTreeData : public IStorage\n     /// Must be called with locked lockForShare() because use relative_data_path.\n     void clearOldTemporaryDirectories(ssize_t custom_directories_lifetime_seconds = -1);\n \n+    void clearEmptyParts();\n+\n     /// After the call to dropAllData() no method can be called.\n     /// Deletes the data directory and flushes the uncompressed blocks cache and the marks cache.\n     void dropAllData();\n@@ -876,7 +878,7 @@ class MergeTreeData : public IStorage\n     // Partition helpers\n     bool canReplacePartition(const DataPartPtr & src_part) const;\n \n-    virtual void dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & context) = 0;\n+    virtual void dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & context, bool throw_if_noop = true) = 0;\n     virtual PartitionCommandsResultInfo attachPartition(const ASTPtr & partition, const StorageMetadataPtr & metadata_snapshot, bool part, const Context & context) = 0;\n     virtual void replacePartitionFrom(const StoragePtr & source_table, const ASTPtr & partition, bool replace, const Context & context) = 0;\n     virtual void movePartitionToTable(const StoragePtr & dest_table, const ASTPtr & partition, const Context & context) = 0;\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp\nindex 5de0a79b2c32..701cb2fa1ede 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp\n@@ -72,6 +72,7 @@ void ReplicatedMergeTreeCleanupThread::iterate()\n         clearOldLogs();\n         clearOldBlocks();\n         clearOldMutations();\n+        storage.clearEmptyParts();\n     }\n }\n \ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\nindex 9263dab638a7..7a76c6c82467 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\n@@ -54,7 +54,8 @@ void ReplicatedMergeTreeQueue::addVirtualParts(const MergeTreeData::DataParts &\n bool ReplicatedMergeTreeQueue::isVirtualPart(const MergeTreeData::DataPartPtr & data_part) const\n {\n     std::lock_guard lock(state_mutex);\n-    return virtual_parts.getContainingPart(data_part->info) != data_part->name;\n+    auto virtual_part_name = virtual_parts.getContainingPart(data_part->info);\n+    return !virtual_part_name.empty() && virtual_part_name != data_part->name;\n }\n \n \ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex 48220a106c24..4d4b35ce7c47 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -99,6 +99,7 @@ void StorageMergeTree::startup()\n {\n     clearOldPartsFromFilesystem();\n     clearOldWriteAheadLogs();\n+    clearEmptyParts();\n \n     /// Temporary directories contain incomplete results of merges (after forced restart)\n     ///  and don't allow to reinitialize them, so delete each of them immediately\n@@ -947,6 +948,7 @@ std::optional<JobAndPool> StorageMergeTree::getDataProcessingJob()\n             clearOldTemporaryDirectories();\n             clearOldWriteAheadLogs();\n             clearOldMutations();\n+            clearEmptyParts();\n         }, PoolType::MERGE_MUTATE};\n     }\n     return {};\n@@ -1087,7 +1089,7 @@ ActionLock StorageMergeTree::stopMergesAndWait()\n }\n \n \n-void StorageMergeTree::dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & context)\n+void StorageMergeTree::dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & context, bool throw_if_noop)\n {\n     {\n         /// Asks to complete merges and does not allow them to start.\n@@ -1105,8 +1107,10 @@ void StorageMergeTree::dropPartition(const ASTPtr & partition, bool detach, bool\n \n             if (part)\n                 parts_to_remove.push_back(part);\n-            else\n+            else if (throw_if_noop)\n                 throw Exception(\"Part \" + part_name + \" not found, won't try to drop it.\", ErrorCodes::NO_SUCH_DATA_PART);\n+            else\n+                return;\n         }\n         else\n         {\ndiff --git a/src/Storages/StorageMergeTree.h b/src/Storages/StorageMergeTree.h\nindex e3796cb9d100..86d33e25df0f 100644\n--- a/src/Storages/StorageMergeTree.h\n+++ b/src/Storages/StorageMergeTree.h\n@@ -187,7 +187,7 @@ class StorageMergeTree final : public ext::shared_ptr_helper<StorageMergeTree>,\n     void clearOldMutations(bool truncate = false);\n \n     // Partition helpers\n-    void dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & context) override;\n+    void dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & context, bool throw_if_noop) override;\n     PartitionCommandsResultInfo attachPartition(const ASTPtr & partition, const StorageMetadataPtr & metadata_snapshot, bool part, const Context & context) override;\n \n     void replacePartitionFrom(const StoragePtr & source_table, const ASTPtr & partition, bool replace, const Context & context) override;\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex b93500000b5a..48a8a80c781a 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -4230,7 +4230,7 @@ bool StorageReplicatedMergeTree::getFakePartCoveringAllPartsInPartition(const St\n }\n \n \n-void StorageReplicatedMergeTree::dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & query_context)\n+void StorageReplicatedMergeTree::dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & query_context, bool throw_if_noop)\n {\n     assertNotReadonly();\n     if (!is_leader)\n@@ -4244,7 +4244,7 @@ void StorageReplicatedMergeTree::dropPartition(const ASTPtr & partition, bool de\n     if (drop_part)\n     {\n         String part_name = partition->as<ASTLiteral &>().value.safeGet<String>();\n-        did_drop = dropPart(zookeeper, part_name, entry, detach);\n+        did_drop = dropPart(zookeeper, part_name, entry, detach, throw_if_noop);\n     }\n     else\n     {\n@@ -5937,7 +5937,7 @@ bool StorageReplicatedMergeTree::waitForShrinkingQueueSize(size_t queue_size, UI\n }\n \n bool StorageReplicatedMergeTree::dropPart(\n-    zkutil::ZooKeeperPtr & zookeeper, String part_name, LogEntry & entry, bool detach)\n+    zkutil::ZooKeeperPtr & zookeeper, String part_name, LogEntry & entry, bool detach, bool throw_if_noop)\n {\n     LOG_TRACE(log, \"Will try to insert a log entry to DROP_RANGE for part: \" + part_name);\n \n@@ -5950,32 +5950,52 @@ bool StorageReplicatedMergeTree::dropPart(\n         auto part = getPartIfExists(part_info, {MergeTreeDataPartState::Committed});\n \n         if (!part)\n-            throw Exception(\"Part \" + part_name + \" not found locally, won't try to drop it.\", ErrorCodes::NO_SUCH_DATA_PART);\n+        {\n+            if (throw_if_noop)\n+                throw Exception(\"Part \" + part_name + \" not found locally, won't try to drop it.\", ErrorCodes::NO_SUCH_DATA_PART);\n+            return false;\n+        }\n \n         /// There isn't a lot we can do otherwise. Can't cancel merges because it is possible that a replica already\n         /// finished the merge.\n         if (partIsAssignedToBackgroundOperation(part))\n-            throw Exception(\"Part \" + part_name\n-                            + \" is currently participating in a background operation (mutation/merge)\"\n-                            + \", try again later\", ErrorCodes::PART_IS_TEMPORARILY_LOCKED);\n+        {\n+            if (throw_if_noop)\n+                throw Exception(\"Part \" + part_name\n+                                + \" is currently participating in a background operation (mutation/merge)\"\n+                                + \", try again later\", ErrorCodes::PART_IS_TEMPORARILY_LOCKED);\n+            return false;\n+        }\n \n         if (partIsLastQuorumPart(part->info))\n-            throw Exception(\"Part \" + part_name + \" is last inserted part with quorum in partition. Cannot drop\",\n-                            ErrorCodes::NOT_IMPLEMENTED);\n+        {\n+            if (throw_if_noop)\n+                throw Exception(\"Part \" + part_name + \" is last inserted part with quorum in partition. Cannot drop\",\n+                                ErrorCodes::NOT_IMPLEMENTED);\n+            return false;\n+        }\n \n         if (partIsInsertingWithParallelQuorum(part->info))\n-            throw Exception(\"Part \" + part_name + \" is inserting with parallel quorum. Cannot drop\",\n-                            ErrorCodes::NOT_IMPLEMENTED);\n+        {\n+            if (throw_if_noop)\n+                throw Exception(\"Part \" + part_name + \" is inserting with parallel quorum. Cannot drop\",\n+                                ErrorCodes::NOT_IMPLEMENTED);\n+            return false;\n+        }\n \n         Coordination::Requests ops;\n         getClearBlocksInPartitionOps(ops, *zookeeper, part_info.partition_id, part_info.min_block, part_info.max_block);\n         size_t clean_block_ops_size = ops.size();\n \n+        /// Set fake level to treat this part as virtual in queue.\n+        auto drop_part_info = part->info;\n+        drop_part_info.level = MergeTreePartInfo::MAX_LEVEL;\n+\n         /// If `part_name` is result of a recent merge and source parts are still available then\n         /// DROP_RANGE with detach will move this part together with source parts to `detached/` dir.\n         entry.type = LogEntry::DROP_RANGE;\n         entry.source_replica = replica_name;\n-        entry.new_part_name = part_name;\n+        entry.new_part_name = drop_part_info.getPartName();\n         entry.detach = detach;\n         entry.create_time = time(nullptr);\n \ndiff --git a/src/Storages/StorageReplicatedMergeTree.h b/src/Storages/StorageReplicatedMergeTree.h\nindex 3e6b809cfdf8..d3328f9843c2 100644\n--- a/src/Storages/StorageReplicatedMergeTree.h\n+++ b/src/Storages/StorageReplicatedMergeTree.h\n@@ -548,12 +548,12 @@ class StorageReplicatedMergeTree final : public ext::shared_ptr_helper<StorageRe\n     /// Info about how other replicas can access this one.\n     ReplicatedMergeTreeAddress getReplicatedMergeTreeAddress() const;\n \n-    bool dropPart(zkutil::ZooKeeperPtr & zookeeper, String part_name, LogEntry & entry, bool detach);\n+    bool dropPart(zkutil::ZooKeeperPtr & zookeeper, String part_name, LogEntry & entry, bool detach, bool throw_if_noop);\n     bool dropAllPartsInPartition(\n         zkutil::ZooKeeper & zookeeper, String & partition_id, LogEntry & entry, bool detach);\n \n     // Partition helpers\n-    void dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & query_context) override;\n+    void dropPartition(const ASTPtr & partition, bool detach, bool drop_part, const Context & query_context, bool throw_if_noop) override;\n     PartitionCommandsResultInfo attachPartition(const ASTPtr & partition, const StorageMetadataPtr & metadata_snapshot, bool part, const Context & query_context) override;\n     void replacePartitionFrom(const StoragePtr & source_table, const ASTPtr & partition, bool replace, const Context & query_context) override;\n     void movePartitionToTable(const StoragePtr & dest_table, const ASTPtr & partition, const Context & query_context) override;\n",
  "test_patch": "diff --git a/tests/integration/test_ttl_replicated/test.py b/tests/integration/test_ttl_replicated/test.py\nindex cbf13c202209..e98b3ba56258 100644\n--- a/tests/integration/test_ttl_replicated/test.py\n+++ b/tests/integration/test_ttl_replicated/test.py\n@@ -213,6 +213,14 @@ def test_ttl_double_delete_rule_returns_error(started_cluster):\n         assert False\n \n \n+def optimize_with_retry(node, table_name, retry=20):\n+    for i in range(retry):\n+        try:\n+            node.query(\"OPTIMIZE TABLE {name} FINAL SETTINGS optimize_throw_if_noop = 1\".format(name=table_name), settings={\"optimize_throw_if_noop\": \"1\"})\n+            break\n+        except e:\n+            time.sleep(0.5)\n+\n @pytest.mark.parametrize(\"name,engine\", [\n     (\"test_ttl_alter_delete\", \"MergeTree()\"),\n     (\"test_replicated_ttl_alter_delete\", \"ReplicatedMergeTree('/clickhouse/test_replicated_ttl_alter_delete', '1')\"),\n@@ -238,14 +246,6 @@ def test_ttl_alter_delete(started_cluster, name, engine):\n     \"\"\"\n     drop_table([node1], name)\n \n-    def optimize_with_retry(retry=20):\n-        for i in range(retry):\n-            try:\n-                node1.query(\"OPTIMIZE TABLE {name} FINAL\".format(name=name), settings={\"optimize_throw_if_noop\": \"1\"})\n-                break\n-            except:\n-                time.sleep(0.5)\n-\n     node1.query(\n         \"\"\"\n             CREATE TABLE {name} (\n@@ -267,7 +267,7 @@ def optimize_with_retry(retry=20):\n \n     time.sleep(1)\n \n-    optimize_with_retry()\n+    optimize_with_retry(node1, name)\n     r = node1.query(\"SELECT s1, b1 FROM {name} ORDER BY b1, s1\".format(name=name)).splitlines()\n     assert r == [\"\\t1\", \"hello2\\t2\"]\n \n@@ -277,7 +277,55 @@ def optimize_with_retry(retry=20):\n \n     time.sleep(1)\n \n-    optimize_with_retry()\n+    optimize_with_retry(node1, name)\n \n     r = node1.query(\"SELECT s1, b1 FROM {name} ORDER BY b1, s1\".format(name=name)).splitlines()\n     assert r == [\"\\t0\", \"\\t0\", \"hello2\\t2\"]\n+\n+def test_ttl_empty_parts(started_cluster):\n+    drop_table([node1, node2], \"test_ttl_empty_parts\")\n+    for node in [node1, node2]:\n+        node.query(\n+        '''\n+            CREATE TABLE test_ttl_empty_parts(date Date, id UInt32)\n+            ENGINE = ReplicatedMergeTree('/clickhouse/tables/test/test_ttl', '{replica}')\n+            ORDER BY id\n+            SETTINGS max_bytes_to_merge_at_min_space_in_pool = 1, max_bytes_to_merge_at_max_space_in_pool = 1,\n+                cleanup_delay_period = 1, cleanup_delay_period_random_add = 0\n+        '''.format(replica=node.name))\n+\n+    for i in range (1, 7):\n+        node1.query(\"INSERT INTO test_ttl_empty_parts SELECT '2{}00-01-0{}', number FROM numbers(1000)\".format(i % 2, i))\n+\n+    assert node1.query(\"SELECT count() FROM test_ttl_empty_parts\") == \"6000\\n\"\n+    assert node1.query(\"SELECT name FROM system.parts WHERE table = 'test_ttl_empty_parts' AND active ORDER BY name\") == \\\n+        \"all_0_0_0\\nall_1_1_0\\nall_2_2_0\\nall_3_3_0\\nall_4_4_0\\nall_5_5_0\\n\"\n+\n+    node1.query(\"ALTER TABLE test_ttl_empty_parts MODIFY TTL date\")\n+\n+    assert node1.query(\"SELECT count() FROM test_ttl_empty_parts\") == \"3000\\n\"\n+\n+    time.sleep(3) # Wait for cleanup thread\n+    assert node1.query(\"SELECT name FROM system.parts WHERE table = 'test_ttl_empty_parts' AND active ORDER BY name\") == \\\n+        \"all_0_0_0_6\\nall_2_2_0_6\\nall_4_4_0_6\\n\"\n+\n+    for node in [node1, node2]:\n+        node.query(\"ALTER TABLE test_ttl_empty_parts MODIFY SETTING max_bytes_to_merge_at_min_space_in_pool = 1000000000\")\n+        node.query(\"ALTER TABLE test_ttl_empty_parts MODIFY SETTING max_bytes_to_merge_at_max_space_in_pool = 1000000000\")\n+\n+    optimize_with_retry(node1, 'test_ttl_empty_parts')\n+    assert node1.query(\"SELECT name FROM system.parts WHERE table = 'test_ttl_empty_parts' AND active ORDER BY name\") == \"all_0_4_1_6\\n\"\n+\n+    # Check that after removing empty parts mutations and merges works\n+    node1.query(\"INSERT INTO test_ttl_empty_parts SELECT '2100-01-20', number FROM numbers(1000)\")\n+    node1.query(\"ALTER TABLE test_ttl_empty_parts DELETE WHERE id % 2 = 0 SETTINGS mutations_sync = 2\")\n+    assert node1.query(\"SELECT count() FROM test_ttl_empty_parts\") == \"2000\\n\"\n+\n+    optimize_with_retry(node1, 'test_ttl_empty_parts')\n+    assert node1.query(\"SELECT name FROM system.parts WHERE table = 'test_ttl_empty_parts' AND active ORDER BY name\") == \"all_0_7_2_8\\n\"\n+\n+    node2.query('SYSTEM SYNC REPLICA test_ttl_empty_parts', timeout=20)\n+\n+    error_msg = '<Error> default.test_ttl_empty_parts (ReplicatedMergeTreeCleanupThread)'\n+    assert not node1.contains_in_log(error_msg)\n+    assert not node2.contains_in_log(error_msg)\ndiff --git a/tests/queries/0_stateless/01560_ttl_remove_empty_parts.reference b/tests/queries/0_stateless/01560_ttl_remove_empty_parts.reference\nnew file mode 100644\nindex 000000000000..526c8b842bec\n--- /dev/null\n+++ b/tests/queries/0_stateless/01560_ttl_remove_empty_parts.reference\n@@ -0,0 +1,4 @@\n+1000\n+2\n+500\n+1\ndiff --git a/tests/queries/0_stateless/01560_ttl_remove_empty_parts.sql b/tests/queries/0_stateless/01560_ttl_remove_empty_parts.sql\nnew file mode 100644\nindex 000000000000..f40ed70caef2\n--- /dev/null\n+++ b/tests/queries/0_stateless/01560_ttl_remove_empty_parts.sql\n@@ -0,0 +1,20 @@\n+DROP TABLE IF EXISTS ttl_empty_parts;\n+\n+CREATE TABLE ttl_empty_parts (id UInt32, d Date) ENGINE = MergeTree ORDER BY tuple() PARTITION BY id;\n+\n+INSERT INTO ttl_empty_parts SELECT 0, toDate('2005-01-01') + number from numbers(500);\n+INSERT INTO ttl_empty_parts SELECT 1, toDate('2050-01-01') + number from numbers(500);\n+\n+SELECT count() FROM ttl_empty_parts;\n+SELECT count() FROM system.parts WHERE table = 'ttl_empty_parts' AND database = currentDatabase() AND active;\n+\n+ALTER TABLE ttl_empty_parts MODIFY TTL d;\n+\n+-- To be sure, that task, which clears outdated parts executed.\n+DETACH TABLE ttl_empty_parts;\n+ATTACH TABLE ttl_empty_parts;\n+\n+SELECT count() FROM ttl_empty_parts;\n+SELECT count() FROM system.parts WHERE table = 'ttl_empty_parts' AND database = currentDatabase() AND active;\n+\n+DROP TABLE ttl_empty_parts;\n",
  "problem_statement": "TTL_ONLY_DROP_PARTS does not drop empty parts \nI created table with following structure and inserted some test data. \r\nEmpty parts(rows = 0) still exists even if all rows from the table were deleted over TTL.\r\n\r\ncreate table  temp_ttl_partition_test\r\n (\r\n        rec_date DateTime,\r\n        user_id String\r\n)\r\nengine = MergeTree\r\npartition by formatDateTime(rec_date, '%Y%m%d%H')\r\nORDER BY user_id\r\nTTL rec_date + interval 10 minute\r\nSETTINGS ttl_only_drop_parts=1;\r\n\r\n\r\nCH version = 20.5.2.7\r\n\r\nExpected behavior: TTL_ONLY_DROP_PARTS must drop empty parts\r\n\r\n![bug](https://user-images.githubusercontent.com/26870989/93976110-244f3280-fd81-11ea-9e63-5eb6cee41b5d.png)\r\n\nWhy not remove outdated parts permanently after TTL merge?\n##  Description\u2028\r\n\r\nI find some empty parts after background merge. These parts are old enough to be deleted permanently. Why does it still exists?\r\n\r\n![image](https://user-images.githubusercontent.com/5371877/97964961-955c1e00-1df4-11eb-88ce-76cb0fc974cd.png)\r\n\r\n![image](https://user-images.githubusercontent.com/5371877/97964803-4f9f5580-1df4-11eb-9c34-b6239713a6ef.png)\r\n\r\n### Question1: Does it work as expect?\u2028\r\n\r\nI have read the source code about background merge logic, but not found logic to delete it.\r\n\r\n### Question2: Can it cause \"too many parts\" problem?\r\n\r\nMaybe, it can exceeds the parts amount limitation `max_parts_in_total`.\r\n\r\nNow, i can avoid this problem by the following two steps:\r\n\r\n* Wait for background merge or trigger merge manually by \"OPTIMIZE xxx\"\u2028 to ensure that only one part for one outdated partition.\r\n* Drop outdated partition by \"ALTER TABLE table_name DROP PARTITION XXX\".\r\n\r\n### Question3: Why not remote it permanently?\r\n\r\nWhy not do this? Are there any other considerations?\r\n\r\nCH version 19.16.20.1.\nMerges on a table with TTL leave empty partitions\nIt's possible that after a merge on a table with TTL there will be no more rows in some partitions. It makes sense to drop those partitions.\r\n```\r\ndrop table if exists ttl_00933_1;\r\ncreate table ttl_00933_1 (d Date, a Int) engine = MergeTree order by a partition by toYear(d) ttl d + interval 1 day;\r\ninsert into ttl_00933_1 values (toDate('2000-10-10'), 1);\r\ninsert into ttl_00933_1 values (toDate('2100-10-10'), 2);\r\noptimize table ttl_00933_1 final;\r\nselect partition, name, active, rows from system.parts where table = 'ttl_00933_1' and active\r\n\r\nSELECT\r\n    partition,\r\n    name,\r\n    active,\r\n    rows\r\nFROM system.parts\r\nWHERE (table = 'ttl_00933_1') AND active\r\n\r\n\u250c\u2500partition\u2500\u252c\u2500name\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500active\u2500\u252c\u2500rows\u2500\u2510\r\n\u2502 2000      \u2502 2000_1_1_1 \u2502      1 \u2502    0 \u2502\r\n\u2502 2100      \u2502 2100_2_2_0 \u2502      1 \u2502    1 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\n",
  "hints_text": "The outdated parts were removed in the background. The expired parts were replaced by empty parts with commited state, which generated in the merge phase. If the generated empty parts were not commited, and just remove the outdated parts, this problem will be solved.\r\n\r\nI have fixed this problem in my test env. Can I make a pull request?\r\n\n> The outdated parts were removed in the background. The expired parts were replaced by empty parts with commited state, which generated in the merge phase. If the generated empty parts were not commited, and just remove the outdated parts, this problem will be solved.\r\n> \r\n> I have fixed this problem in my test env. Can I make a pull request?\r\n\r\ncan you please give more detail on how you fix it in your env ?\nCurrently, ClickHouse doesn't delete empty parts from MergeTree for several reasons. It's expected behavior. However, they can be merged with non-empty parts in the background. We already have Draft PR where we try to delete empty parts https://github.com/ClickHouse/ClickHouse/pull/13252.\n> The outdated parts were removed in the background. The expired parts were replaced by empty parts with commited state, which generated in the merge phase. If the generated empty parts were not commited, and just remove the outdated parts, this problem will be solved.\r\n> \r\n> I have fixed this problem in my test env. Can I make a pull request?\r\n\r\nYou are welcome! We will be glad to see your solution.\n@ikainazarov As mentioned above, it's unexpected behaviour. I try to make a pr to improvement it.\nthank you guys \n#5491\nthere's an umbrella ticket covering TTL issues https://github.com/ClickHouse/ClickHouse/issues/10128\r\n\r\ntl;dr 19.16 version is quite old for it, consider an upgrade.\nhttps://github.com/ClickHouse/ClickHouse/pull/13252#issuecomment-667734024\nany updates here?\n@CurtizJ Please clarify.\n@CurtizJ has clarified that this behaviour is\r\n- expected;\r\n- correct;\r\n- cannot be avoided (otherwise some invariants for coordination of background merges will fail).\n@CurtizJ has found a way to remove parts in case if whole partition is going to be removed.\n> @CurtizJ has found a way to remove parts in case if whole partition is going to be removed.\r\n\r\nWhat is this way? \nI meant, that it's possible to remove empty parts, only if they are continious prefix of all parts sorted by block numbers in partition, because we can't remove random part from the middle due to merge algorithm. But it will cover most of cases. BTW, it's not implemented yet.",
  "created_at": "2020-11-11T16:39:23Z",
  "modified_files": [
    "src/Storages/MergeTree/MergeTreeData.cpp",
    "src/Storages/MergeTree/MergeTreeData.h",
    "src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp",
    "src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp",
    "src/Storages/StorageMergeTree.cpp",
    "src/Storages/StorageMergeTree.h",
    "src/Storages/StorageReplicatedMergeTree.cpp",
    "src/Storages/StorageReplicatedMergeTree.h"
  ],
  "modified_test_files": [
    "tests/integration/test_ttl_replicated/test.py",
    "b/tests/queries/0_stateless/01560_ttl_remove_empty_parts.reference",
    "b/tests/queries/0_stateless/01560_ttl_remove_empty_parts.sql"
  ]
}