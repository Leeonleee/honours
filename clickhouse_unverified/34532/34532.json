{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 34532,
  "instance_id": "ClickHouse__ClickHouse-34532",
  "issue_numbers": [
    "34526"
  ],
  "base_commit": "a2b1900333a1fa1ecc877c447c2ee4ac13fe5456",
  "patch": "diff --git a/src/Processors/Transforms/MergingAggregatedTransform.cpp b/src/Processors/Transforms/MergingAggregatedTransform.cpp\nindex 37419f55aaec..dd2b315d53cd 100644\n--- a/src/Processors/Transforms/MergingAggregatedTransform.cpp\n+++ b/src/Processors/Transforms/MergingAggregatedTransform.cpp\n@@ -1,5 +1,6 @@\n #include <Processors/Transforms/MergingAggregatedTransform.h>\n #include <Processors/Transforms/AggregatingTransform.h>\n+#include <Processors/Transforms/AggregatingInOrderTransform.h>\n \n namespace DB\n {\n@@ -34,21 +35,30 @@ void MergingAggregatedTransform::consume(Chunk chunk)\n     if (!info)\n         throw Exception(\"Chunk info was not set for chunk in MergingAggregatedTransform.\", ErrorCodes::LOGICAL_ERROR);\n \n-    const auto * agg_info = typeid_cast<const AggregatedChunkInfo *>(info.get());\n-    if (!agg_info)\n-        throw Exception(\"Chunk should have AggregatedChunkInfo in MergingAggregatedTransform.\", ErrorCodes::LOGICAL_ERROR);\n+    if (const auto * agg_info = typeid_cast<const AggregatedChunkInfo *>(info.get()))\n+    {\n+        /** If the remote servers used a two-level aggregation method,\n+        *  then blocks will contain information about the number of the bucket.\n+        * Then the calculations can be parallelized by buckets.\n+        * We decompose the blocks to the bucket numbers indicated in them.\n+        */\n \n-    /** If the remote servers used a two-level aggregation method,\n-      *  then blocks will contain information about the number of the bucket.\n-      * Then the calculations can be parallelized by buckets.\n-      * We decompose the blocks to the bucket numbers indicated in them.\n-      */\n+        auto block = getInputPort().getHeader().cloneWithColumns(chunk.getColumns());\n+        block.info.is_overflows = agg_info->is_overflows;\n+        block.info.bucket_num = agg_info->bucket_num;\n \n-    auto block = getInputPort().getHeader().cloneWithColumns(chunk.getColumns());\n-    block.info.is_overflows = agg_info->is_overflows;\n-    block.info.bucket_num = agg_info->bucket_num;\n+        bucket_to_blocks[agg_info->bucket_num].emplace_back(std::move(block));\n+    }\n+    else if (const auto * in_order_info = typeid_cast<const ChunkInfoWithAllocatedBytes *>(info.get()))\n+    {\n+        auto block = getInputPort().getHeader().cloneWithColumns(chunk.getColumns());\n+        block.info.is_overflows = false;\n+        block.info.bucket_num = -1;\n \n-    bucket_to_blocks[agg_info->bucket_num].emplace_back(std::move(block));\n+        bucket_to_blocks[block.info.bucket_num].emplace_back(std::move(block));\n+    }\n+    else\n+        throw Exception(\"Chunk should have AggregatedChunkInfo in MergingAggregatedTransform.\", ErrorCodes::LOGICAL_ERROR);\n }\n \n Chunk MergingAggregatedTransform::generate()\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02176_optimize_aggregation_in_order_empty.reference b/tests/queries/0_stateless/02176_optimize_aggregation_in_order_empty.reference\nindex 645cec31b478..5e8c7fc243f8 100644\n--- a/tests/queries/0_stateless/02176_optimize_aggregation_in_order_empty.reference\n+++ b/tests/queries/0_stateless/02176_optimize_aggregation_in_order_empty.reference\n@@ -5,4 +5,5 @@\n --   \"Chunk should have AggregatedChunkInfo in GroupingAggregatedTransform\"\n -- at first and after\n --   \"Chunk should have AggregatedChunkInfo in GroupingAggregatedTransform\"\n-select count() from remote('127.{1,2}', currentDatabase(), data_02176) where key = 0 group by key settings optimize_aggregation_in_order=1;\n+select count() from remote('127.{1,2}', currentDatabase(), data_02176) where key = 0 group by key;\n+select count() from remote('127.{1,2}', currentDatabase(), data_02176) where key = 0 group by key settings distributed_aggregation_memory_efficient=0;\ndiff --git a/tests/queries/0_stateless/02176_optimize_aggregation_in_order_empty.sql b/tests/queries/0_stateless/02176_optimize_aggregation_in_order_empty.sql\nindex a86fd4357c8e..35731c63f0d3 100644\n--- a/tests/queries/0_stateless/02176_optimize_aggregation_in_order_empty.sql\n+++ b/tests/queries/0_stateless/02176_optimize_aggregation_in_order_empty.sql\n@@ -1,6 +1,8 @@\n drop table if exists data_02176;\n create table data_02176 (key Int) Engine=MergeTree() order by key;\n \n+set optimize_aggregation_in_order=1;\n+\n -- { echoOn }\n \n -- regression for optimize_aggregation_in_order with empty result set\n@@ -8,7 +10,8 @@ create table data_02176 (key Int) Engine=MergeTree() order by key;\n --   \"Chunk should have AggregatedChunkInfo in GroupingAggregatedTransform\"\n -- at first and after\n --   \"Chunk should have AggregatedChunkInfo in GroupingAggregatedTransform\"\n-select count() from remote('127.{1,2}', currentDatabase(), data_02176) where key = 0 group by key settings optimize_aggregation_in_order=1;\n+select count() from remote('127.{1,2}', currentDatabase(), data_02176) where key = 0 group by key;\n+select count() from remote('127.{1,2}', currentDatabase(), data_02176) where key = 0 group by key settings distributed_aggregation_memory_efficient=0;\n \n -- { echoOff }\n drop table data_02176;\ndiff --git a/tests/queries/0_stateless/02177_merge_optimize_aggregation_in_order.reference b/tests/queries/0_stateless/02177_merge_optimize_aggregation_in_order.reference\nindex 00e893213c0f..0345e05303ce 100644\n--- a/tests/queries/0_stateless/02177_merge_optimize_aggregation_in_order.reference\n+++ b/tests/queries/0_stateless/02177_merge_optimize_aggregation_in_order.reference\n@@ -2,5 +2,7 @@\n \n -- regression for optimize_aggregation_in_order\n -- that cause \"Chunk should have AggregatedChunkInfo in GroupingAggregatedTransform\" error\n-select count() from remote('127.{1,2}', currentDatabase(), data_02177) group by key settings optimize_aggregation_in_order=1;\n+select count() from remote('127.{1,2}', currentDatabase(), data_02177) group by key;\n+2\n+select count() from remote('127.{1,2}', currentDatabase(), data_02177) group by key settings distributed_aggregation_memory_efficient=0;\n 2\ndiff --git a/tests/queries/0_stateless/02177_merge_optimize_aggregation_in_order.sql b/tests/queries/0_stateless/02177_merge_optimize_aggregation_in_order.sql\nindex 17c4a1dba29d..9dc3a24213e8 100644\n--- a/tests/queries/0_stateless/02177_merge_optimize_aggregation_in_order.sql\n+++ b/tests/queries/0_stateless/02177_merge_optimize_aggregation_in_order.sql\n@@ -2,11 +2,14 @@ drop table if exists data_02177;\n create table data_02177 (key Int) Engine=MergeTree() order by key;\n insert into data_02177 values (1);\n \n+set optimize_aggregation_in_order=1;\n+\n -- { echoOn }\n \n -- regression for optimize_aggregation_in_order\n -- that cause \"Chunk should have AggregatedChunkInfo in GroupingAggregatedTransform\" error\n-select count() from remote('127.{1,2}', currentDatabase(), data_02177) group by key settings optimize_aggregation_in_order=1;\n+select count() from remote('127.{1,2}', currentDatabase(), data_02177) group by key;\n+select count() from remote('127.{1,2}', currentDatabase(), data_02177) group by key settings distributed_aggregation_memory_efficient=0;\n \n -- { echoOff }\n drop table data_02177;\n",
  "problem_statement": "Logical error: 'Chunk should have AggregatedChunkInfo in MergingAggregatedTransform.'.\nHow to reproduce: run test 02177_merge_optimize_aggregation_in_order.sql with disabled setting `distributed_aggregation_memory_efficient`\r\n```\r\nch-client --distributed_aggregation_memory_efficient=0 -nmT < 02177_merge_optimize_aggregation_in_order.sql > /dev/null\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:02.309148 [ 32014 ] {2aff9729-8b32-4338-99ef-863797e3f865} <Fatal> : Logical error: 'Chunk should have AggregatedChunkInfo in MergingAggregatedTransform.'.\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:02.311371 [ 32085 ] <Fatal> BaseDaemon: ########################################\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:02.311877 [ 32085 ] <Fatal> BaseDaemon: (version 22.2.1.1, build id: 3214146F63D9D503) (from thread 32014) (query_id: 2aff9729-8b32-4338-99ef-863797e3f865) (query: -- { echoOn }\r\n\r\n-- regression for optimize_aggregation_in_order\r\n-- that cause \"Chunk should have AggregatedChunkInfo in GroupingAggregatedTransform\" error\r\nselect count() from remote('127.{1,2}', currentDatabase(), data_02177) group by key settings optimize_aggregation_in_order=1;) Received signal Aborted (6)\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:02.312248 [ 32085 ] <Fatal> BaseDaemon: \r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:02.312727 [ 32085 ] <Fatal> BaseDaemon: Stack trace: 0x7fda8742f18b 0x7fda8740e859 0x7fda89b8e1f9 0x7fda89b8e309 0x7fda5f79ff42 0x7fda60679858 0x7fda60436ed9 0x7fda60436dd5 0x7fda6043dfc1 0x7fda6043e297 0x7fda6043fa5f 0x7fda6043f9dd 0x7fda6043f981 0x7fda6043f892 0x7fda6043f75b 0x7fda6043f61d 0x7fda6043f5dd 0x7fda6043f5b5 0x7fda6043f580 0x7fda89c84f66 0x7fda89c7bd55 0x7fda89c7b715 0x7fda89c82064 0x7fda89c81fdd 0x7fda89c81f05 0x7fda89c81862 0x7fda87791609 0x7fda8750b293\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:02.816836 [ 32085 ] <Fatal> BaseDaemon: 4. raise @ 0x8ef218b in /home/avogar/ClickHouse/build/src/AggregateFunctions/libclickhouse_aggregate_functionsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:03.322922 [ 32085 ] <Fatal> BaseDaemon: 5. abort @ 0x8ed1859 in /home/avogar/ClickHouse/build/src/AggregateFunctions/libclickhouse_aggregate_functionsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:03.423435 [ 32085 ] <Fatal> BaseDaemon: 6. ./build/../src/Common/Exception.cpp:52: DB::handle_error_code(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool, std::__1::vector<void*, std::__1::allocator<void*> > const&) @ 0x3391f9 in /home/avogar/ClickHouse/build/src/libclickhouse_common_iod.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:03.504399 [ 32085 ] <Fatal> BaseDaemon: 7. ./build/../src/Common/Exception.cpp:59: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x339309 in /home/avogar/ClickHouse/build/src/libclickhouse_common_iod.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:03.625478 [ 32085 ] <Fatal> BaseDaemon: 8. ./build/../src/Processors/Transforms/MergingAggregatedTransform.cpp:39: DB::MergingAggregatedTransform::consume(DB::Chunk) @ 0x39ef42 in /home/avogar/ClickHouse/build/src/libclickhouse_processors_transformsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:03.687272 [ 32085 ] <Fatal> BaseDaemon: 9. ./build/../src/Processors/IAccumulatingTransform.cpp:97: DB::IAccumulatingTransform::work() @ 0x94858 in /home/avogar/ClickHouse/build/src/libclickhouse_processorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:03.717571 [ 32085 ] <Fatal> BaseDaemon: 10. ./build/../src/Processors/Executors/ExecutionThreadContext.cpp:45: DB::executeJob(DB::IProcessor*) @ 0xa3ed9 in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:03.744025 [ 32085 ] <Fatal> BaseDaemon: 11. ./build/../src/Processors/Executors/ExecutionThreadContext.cpp:63: DB::ExecutionThreadContext::executeTask() @ 0xa3dd5 in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:03.842685 [ 32085 ] <Fatal> BaseDaemon: 12. ./build/../src/Processors/Executors/PipelineExecutor.cpp:213: DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) @ 0xaafc1 in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:03.942610 [ 32085 ] <Fatal> BaseDaemon: 13. ./build/../src/Processors/Executors/PipelineExecutor.cpp:178: DB::PipelineExecutor::executeSingleThread(unsigned long) @ 0xab297 in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:04.052667 [ 32085 ] <Fatal> BaseDaemon: 14. ./build/../src/Processors/Executors/PipelineExecutor.cpp:306: DB::PipelineExecutor::executeImpl(unsigned long)::$_1::operator()() const @ 0xaca5f in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:04.166865 [ 32085 ] <Fatal> BaseDaemon: 15. ./build/../contrib/libcxx/include/type_traits:3682: decltype(std::__1::forward<DB::PipelineExecutor::executeImpl(unsigned long)::$_1&>(fp)()) std::__1::__invoke_constexpr<DB::PipelineExecutor::executeImpl(unsigned long)::$_1&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_1&) @ 0xac9dd in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:04.283613 [ 32085 ] <Fatal> BaseDaemon: 16. ./build/../contrib/libcxx/include/tuple:1415: decltype(auto) std::__1::__apply_tuple_impl<DB::PipelineExecutor::executeImpl(unsigned long)::$_1&, std::__1::tuple<>&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_1&, std::__1::tuple<>&, std::__1::__tuple_indices<>) @ 0xac981 in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:04.399453 [ 32085 ] <Fatal> BaseDaemon: 17. ./build/../contrib/libcxx/include/tuple:1424: decltype(auto) std::__1::apply<DB::PipelineExecutor::executeImpl(unsigned long)::$_1&, std::__1::tuple<>&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_1&, std::__1::tuple<>&) @ 0xac892 in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:04.491712 [ 32085 ] <Fatal> BaseDaemon: 18. ./build/../src/Common/ThreadPool.h:188: ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_1>(DB::PipelineExecutor::executeImpl(unsigned long)::$_1&&)::'lambda'()::operator()() @ 0xac75b in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:04.605126 [ 32085 ] <Fatal> BaseDaemon: 19. ./build/../contrib/libcxx/include/type_traits:3676: decltype(std::__1::forward<DB::PipelineExecutor::executeImpl(unsigned long)::$_1>(fp)()) std::__1::__invoke<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_1>(DB::PipelineExecutor::executeImpl(unsigned long)::$_1&&)::'lambda'()&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_1&&) @ 0xac61d in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:04.712576 [ 32085 ] <Fatal> BaseDaemon: 20. ./build/../contrib/libcxx/include/__functional_base:349: void std::__1::__invoke_void_return_wrapper<void>::__call<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_1>(DB::PipelineExecutor::executeImpl(unsigned long)::$_1&&)::'lambda'()&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_1&&...) @ 0xac5dd in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:04.828116 [ 32085 ] <Fatal> BaseDaemon: 21. ./build/../contrib/libcxx/include/functional:1608: std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_1>(DB::PipelineExecutor::executeImpl(unsigned long)::$_1&&)::'lambda'(), void ()>::operator()() @ 0xac5b5 in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:04.937114 [ 32085 ] <Fatal> BaseDaemon: 22. ./build/../contrib/libcxx/include/functional:2089: void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_1>(DB::PipelineExecutor::executeImpl(unsigned long)::$_1&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0xac580 in /home/avogar/ClickHouse/build/src/libclickhouse_processors_executorsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:05.021956 [ 32085 ] <Fatal> BaseDaemon: 23. ./build/../contrib/libcxx/include/functional:2221: std::__1::__function::__policy_func<void ()>::operator()() const @ 0x42ff66 in /home/avogar/ClickHouse/build/src/libclickhouse_common_iod.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:05.097268 [ 32085 ] <Fatal> BaseDaemon: 24. ./build/../contrib/libcxx/include/functional:2560: std::__1::function<void ()>::operator()() const @ 0x426d55 in /home/avogar/ClickHouse/build/src/libclickhouse_common_iod.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:05.164488 [ 32085 ] <Fatal> BaseDaemon: 25. ./build/../src/Common/ThreadPool.cpp:277: ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x426715 in /home/avogar/ClickHouse/build/src/libclickhouse_common_iod.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:05.250170 [ 32085 ] <Fatal> BaseDaemon: 26. ./build/../src/Common/ThreadPool.cpp:142: void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()::operator()() const @ 0x42d064 in /home/avogar/ClickHouse/build/src/libclickhouse_common_iod.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:05.340930 [ 32085 ] <Fatal> BaseDaemon: 27. ./build/../contrib/libcxx/include/type_traits:3676: decltype(std::__1::forward<void>(fp)(std::__1::forward<void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>(fp0)...)) std::__1::__invoke<void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>(void&&, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()&&...) @ 0x42cfdd in /home/avogar/ClickHouse/build/src/libclickhouse_common_iod.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:05.422304 [ 32085 ] <Fatal> BaseDaemon: 28. ./build/../contrib/libcxx/include/thread:281: void std::__1::__thread_execute<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>(std::__1::tuple<void, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>&, std::__1::__tuple_indices<>) @ 0x42cf05 in /home/avogar/ClickHouse/build/src/libclickhouse_common_iod.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:05.505732 [ 32085 ] <Fatal> BaseDaemon: 29. ./build/../contrib/libcxx/include/thread:291: void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()> >(void*) @ 0x42c862 in /home/avogar/ClickHouse/build/src/libclickhouse_common_iod.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:05.513282 [ 32085 ] <Fatal> BaseDaemon: 30. ? @ 0x141609 in /home/avogar/ClickHouse/build/contrib/libcxx-cmake/libcxxd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:05.980870 [ 32085 ] <Fatal> BaseDaemon: 31. clone @ 0x8fce293 in /home/avogar/ClickHouse/build/src/AggregateFunctions/libclickhouse_aggregate_functionsd.so\r\n[avogar-dev.vla.yp-c.yandex.net] 2022.02.11 16:23:05.981244 [ 32085 ] <Fatal> BaseDaemon: Calculated checksum of the binary: 3D3723E8BAB43521A090B28438FFD59E. There is no information about the reference checksum.\r\nError on processing query: Code: 32. DB::Exception: Attempt to read after eof: while receiving packet from localhost:9000. (ATTEMPT_TO_READ_AFTER_EOF) (version 22.2.1.1)\r\n(query: -- { echoOn }\r\n\r\n-- regression for optimize_aggregation_in_order\r\n-- that cause \"Chunk should have AggregatedChunkInfo in GroupingAggregatedTransform\" error\r\nselect count() from remote('127.{1,2}', currentDatabase(), data_02177) group by key settings optimize_aggregation_in_order=1;)\r\n```\n",
  "hints_text": "",
  "created_at": "2022-02-11T15:13:53Z",
  "modified_files": [
    "src/Processors/Transforms/MergingAggregatedTransform.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/02176_optimize_aggregation_in_order_empty.reference",
    "tests/queries/0_stateless/02176_optimize_aggregation_in_order_empty.sql",
    "tests/queries/0_stateless/02177_merge_optimize_aggregation_in_order.reference",
    "tests/queries/0_stateless/02177_merge_optimize_aggregation_in_order.sql"
  ]
}