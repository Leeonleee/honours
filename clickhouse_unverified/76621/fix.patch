diff --git a/contrib/librdkafka b/contrib/librdkafka
index 39d4ed49ccf3..1d2042c9cd39 160000
--- a/contrib/librdkafka
+++ b/contrib/librdkafka
@@ -1,1 +1,1 @@
-Subproject commit 39d4ed49ccf3406e2bf825d5d7b0903b5a290782
+Subproject commit 1d2042c9cd39f00fcacf71b2cdc31ea23075d66f
diff --git a/contrib/librdkafka-cmake/CMakeLists.txt b/contrib/librdkafka-cmake/CMakeLists.txt
index d84abd06dec0..e2ae6304839a 100644
--- a/contrib/librdkafka-cmake/CMakeLists.txt
+++ b/contrib/librdkafka-cmake/CMakeLists.txt
@@ -8,22 +8,24 @@ endif()
 set(RDKAFKA_SOURCE_DIR "${ClickHouse_SOURCE_DIR}/contrib/librdkafka/src")
 
 set(SRCS
+#  "${RDKAFKA_SOURCE_DIR}/cJSON.c"    # see below
   "${RDKAFKA_SOURCE_DIR}/crc32c.c"
-#  "${RDKAFKA_SOURCE_DIR}/lz4.c"
-#  "${RDKAFKA_SOURCE_DIR}/lz4frame.c"
-#  "${RDKAFKA_SOURCE_DIR}/lz4hc.c"
+#  "${RDKAFKA_SOURCE_DIR}/lz4.c"      # WITH_LZ4_EXT
+#  "${RDKAFKA_SOURCE_DIR}/lz4frame.c" # WITH_LZ4_EXT
+#  "${RDKAFKA_SOURCE_DIR}/lz4hc.c"    # WITH_LZ4_EXT
   "${RDKAFKA_SOURCE_DIR}/rdaddr.c"
   "${RDKAFKA_SOURCE_DIR}/rdavl.c"
+  "${RDKAFKA_SOURCE_DIR}/rdbase64.c"
   "${RDKAFKA_SOURCE_DIR}/rdbuf.c"
   "${RDKAFKA_SOURCE_DIR}/rdcrc32.c"
-  "${RDKAFKA_SOURCE_DIR}/rddl.c"
+  #"${RDKAFKA_SOURCE_DIR}/rddl.c" #  WITH_LIBDL OR WIN32 - we don't want to support dynamic loading
   "${RDKAFKA_SOURCE_DIR}/rdfnv1a.c"
-  "${RDKAFKA_SOURCE_DIR}/rdgz.c"
-  "${RDKAFKA_SOURCE_DIR}/rdhdrhistogram.c"
-  "${RDKAFKA_SOURCE_DIR}/rdkafka_admin.c" # looks optional
+  "${RDKAFKA_SOURCE_DIR}/rdgz.c" # WITH_ZLIB
+  #"${RDKAFKA_SOURCE_DIR}/rdhdrhistogram.c" # WITH_HDRHISTOGRAM - allows to collect some better stats (not used so far)
+  "${RDKAFKA_SOURCE_DIR}/rdkafka_admin.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_assignment.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_assignor.c"
-  "${RDKAFKA_SOURCE_DIR}/rdkafka_aux.c" # looks optional
+  "${RDKAFKA_SOURCE_DIR}/rdkafka_aux.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_background.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_broker.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_buf.c"
@@ -35,6 +37,8 @@ set(SRCS
   "${RDKAFKA_SOURCE_DIR}/rdkafka_error.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_event.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_feature.c"
+  "${RDKAFKA_SOURCE_DIR}/rdkafka_fetcher.c"
+  # "${RDKAFKA_SOURCE_DIR}/rdhttp.c" #  see WITH_CURL below
   "${RDKAFKA_SOURCE_DIR}/rdkafka_header.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_idempotence.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_interceptor.c"
@@ -51,25 +55,35 @@ set(SRCS
   "${RDKAFKA_SOURCE_DIR}/rdkafka_op.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_partition.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_pattern.c"
-  "${RDKAFKA_SOURCE_DIR}/rdkafka_plugin.c"
+#  "${RDKAFKA_SOURCE_DIR}/rdkafka_plugin.c" # WITH_PLUGINS, we don't support plugins (dynamic loading)
   "${RDKAFKA_SOURCE_DIR}/rdkafka_queue.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_range_assignor.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_request.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_roundrobin_assignor.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl.c"
-#  "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_cyrus.c"        # optionally included below
-#  "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_oauthbearer.c"  # optionally included below
+#  "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_cyrus.c"            # WITH_SASL_CYRUS, see below
+#  "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_oauthbearer.c"      # WITH_SASL_OAUTHBEARER, see below
+#  "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_oauthbearer_oidc.c" # WITH_OAUTHBEARER_OIDC, see below
   "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_plain.c"
-#  "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_scram.c"        # optionally included below
-#  "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_win32.c"
-#  "${RDKAFKA_SOURCE_DIR}/rdkafka_ssl.c"               # optionally included below
+#  "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_scram.c"     # WITH_SASL_SCRAM, see below
+#  "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_win32.c"     # WIN32
+#  "${RDKAFKA_SOURCE_DIR}/rdkafka_ssl.c"            # WITH_SSL, see below
   "${RDKAFKA_SOURCE_DIR}/rdkafka_sticky_assignor.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_subscription.c"
+  "${RDKAFKA_SOURCE_DIR}/rdkafka_telemetry.c"
+  "${RDKAFKA_SOURCE_DIR}/rdkafka_telemetry_decode.c"
+  "${RDKAFKA_SOURCE_DIR}/rdkafka_telemetry_encode.c"
+  "${RDKAFKA_SOURCE_DIR}/nanopb/pb_encode.c"
+  "${RDKAFKA_SOURCE_DIR}/nanopb/pb_decode.c"
+  "${RDKAFKA_SOURCE_DIR}/nanopb/pb_common.c"
+  "${RDKAFKA_SOURCE_DIR}/opentelemetry/metrics.pb.c"
+  "${RDKAFKA_SOURCE_DIR}/opentelemetry/common.pb.c"
+  "${RDKAFKA_SOURCE_DIR}/opentelemetry/resource.pb.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_timer.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_topic.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_transport.c"
   "${RDKAFKA_SOURCE_DIR}/rdkafka_txnmgr.c"
-  "${RDKAFKA_SOURCE_DIR}/rdkafka_zstd.c"
+  "${RDKAFKA_SOURCE_DIR}/rdkafka_zstd.c" # WITH_ZSTD
   "${RDKAFKA_SOURCE_DIR}/rdlist.c"
   "${RDKAFKA_SOURCE_DIR}/rdlog.c"
   "${RDKAFKA_SOURCE_DIR}/rdmap.c"
@@ -81,12 +95,17 @@ set(SRCS
   "${RDKAFKA_SOURCE_DIR}/rdunittest.c"
   "${RDKAFKA_SOURCE_DIR}/rdvarint.c"
   "${RDKAFKA_SOURCE_DIR}/rdxxhash.c"
-  # "${RDKAFKA_SOURCE_DIR}/regexp.c"
+  # "${RDKAFKA_SOURCE_DIR}/regexp.c" # NOT HAVE_REGEX
   "${RDKAFKA_SOURCE_DIR}/snappy.c"
   "${RDKAFKA_SOURCE_DIR}/tinycthread.c"
   "${RDKAFKA_SOURCE_DIR}/tinycthread_extra.c"
 )
 
+if(TARGET ch_contrib::curl)
+    message (STATUS "librdkafka with curl")
+    set(WITH_CURL 1)
+endif()
+
 if(TARGET ch_contrib::sasl2)
     message (STATUS "librdkafka with SASL support")
     set(WITH_SASL_CYRUS 1)
@@ -100,6 +119,12 @@ if(WITH_SASL_CYRUS)
 endif()
 list(APPEND SRCS "${RDKAFKA_SOURCE_DIR}/rdkafka_ssl.c")
 
+if(WITH_SSL AND WITH_CURL)
+  set(WITH_OAUTHBEARER_OIDC 1)
+  list(APPEND SRCS "${RDKAFKA_SOURCE_DIR}/rdhttp.c") # needed for WITH_OAUTHBEARER_OIDC
+  list(APPEND SRCS "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_oauthbearer_oidc.c")
+endif()
+
 if(WITH_SASL_CYRUS)
   list(APPEND SRCS "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_cyrus.c") # needed to support Kerberos, requires cyrus-sasl
 endif()
@@ -112,10 +137,19 @@ if(WITH_SASL_OAUTHBEARER)
   list(APPEND SRCS "${RDKAFKA_SOURCE_DIR}/rdkafka_sasl_oauthbearer.c")
 endif()
 
+## there is a conflict with the cJSON library from aws-s3
+# so normally we link cJSON lirary from contrib/aws (which have some extra patches to be thread safe)
+# but if we don't use aws-s3, we need to link the cJSON library from librdkafka (hacky)
+# which is (potentially) not thread safe (see https://github.com/confluentinc/librdkafka/issues/4159 ),
+if(NOT ENABLE_AWS_S3)
+   list(APPEND SRCS "${RDKAFKA_SOURCE_DIR}/cJSON.c")
+endif()
+
 add_library(_rdkafka ${SRCS})
 add_library(ch_contrib::rdkafka ALIAS _rdkafka)
-
 target_compile_options(_rdkafka PRIVATE -fno-sanitize=undefined)
+target_compile_definitions(_rdkafka PRIVATE -DCJSON_HIDE_SYMBOLS)
+
 # target_include_directories(_rdkafka SYSTEM PUBLIC include)
 target_include_directories(_rdkafka SYSTEM PUBLIC "${CMAKE_CURRENT_SOURCE_DIR}/include") # for "librdkafka/rdkafka.h"
 target_include_directories(_rdkafka SYSTEM PUBLIC ${RDKAFKA_SOURCE_DIR})                 # Because weird logic with "include_next" is used.
@@ -131,6 +165,10 @@ if(WITH_SASL_CYRUS)
     target_link_libraries(_rdkafka PRIVATE ch_contrib::sasl2)
 endif()
 
+if(WITH_CURL)
+  target_link_libraries(_rdkafka PRIVATE ch_contrib::curl)
+endif()
+
 file(MAKE_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}/auxdir")
 
 configure_file(
@@ -138,3 +176,47 @@ configure_file(
   "${CMAKE_CURRENT_BINARY_DIR}/config.h"
   IMMEDIATE @ONLY
 )
+
+# -----------------------------------------------------------------------------
+# Adjust to avoid the ClickHouse runtime trap for harmful functions:
+#
+# librdkafka uses the tinycthreads library for threading primitives.
+# Note that tinycthreads is not actually using the C11 threads API,
+# yet it defines and uses functions with the same names (e.g. mtx_lock,
+# thrd_create, etc.). ClickHouseâ€™s runtime trap monitors for these names
+# and will immediately terminate the program if they are present.
+#
+# To avoid triggering this runtime trap, we replace these symbols via compile
+# definitions. That is, we redefine each harmful function to an alias prefixed
+# with "rd_kafka_". This ensures that none of the original harmful symbol
+# names appear in the final binary.
+target_compile_definitions(_rdkafka PRIVATE
+  thrd_create=rd_kafka_thrd_create
+  thrd_equal=rd_kafka_thrd_equal
+  thrd_current=rd_kafka_thrd_current
+  thrd_sleep=rd_kafka_thrd_sleep
+  thrd_yield=rd_kafka_thrd_yield
+  thrd_exit=rd_kafka_thrd_exit
+  thrd_detach=rd_kafka_thrd_detach
+  thrd_join=rd_kafka_thrd_join
+
+  mtx_init=rd_kafka_mtx_init
+  mtx_lock=rd_kafka_mtx_lock
+  mtx_timedlock=rd_kafka_mtx_timedlock
+  mtx_trylock=rd_kafka_mtx_trylock
+  mtx_unlock=rd_kafka_mtx_unlock
+  mtx_destroy=rd_kafka_mtx_destroy
+  call_once=rd_kafka_call_once
+
+  cnd_init=rd_kafka_cnd_init
+  cnd_signal=rd_kafka_cnd_signal
+  cnd_broadcast=rd_kafka_cnd_broadcast
+  cnd_wait=rd_kafka_cnd_wait
+  cnd_timedwait=rd_kafka_cnd_timedwait
+  cnd_destroy=rd_kafka_cnd_destroy
+
+  tss_create=rd_kafka_tss_create
+  tss_get=rd_kafka_tss_get
+  tss_set=rd_kafka_tss_set
+  tss_delete=rd_kafka_tss_delete
+)
diff --git a/contrib/librdkafka-cmake/config.h.in b/contrib/librdkafka-cmake/config.h.in
index f6ec3bc0e79c..707698586435 100644
--- a/contrib/librdkafka-cmake/config.h.in
+++ b/contrib/librdkafka-cmake/config.h.in
@@ -1,33 +1,66 @@
-// Originally generated by ./configure
+// Automatically generated by ./configure
+///	NOTE: Version 2.8.0 was used to generate and manually modified after that. Therefore this should be fine
+/// until we upgrade to something newer than that.
+/// Commented out the followings:
+/// - #define ARCH "x86_64": we build on multiple archs
+/// - ENABLE_XXX: the commented out ones are only used in librdkafka's configure and CMake, but not in source
+///   NOTE: ENABLE_DEVEL and ENABLE_REFCNT_DEBUG is used in the source at the time of writing
+///
+/// Commented out the following to disable them:
+/// - ENABLE_C11THREADS: to maintain compatibility with old libc, maybe not necessary anymore
+/// - WITH_GCC
+/// - WITH_GXX
+/// - WITH_INSTALL
+/// - HAS_GNU_AR
+/// - HAVE_PIC
+/// - WITH_GNULD
+/// - WITH_C11THREADS
+/// - HAVE_PYTHON
+///
+/// Modified the follwoings:
+/// - WITH_{CURL,SASL_CYRUS,SASL_OAUTHBEARER,SASL_SCRAM}: made them CMake dependant
+/// - BUILT_WITH: tried to make some sense of it, don't spend to much time on it
+///
+/// Added:
+/// - special handling of __APPLE__
+
 #ifndef _CONFIG_H_
 #define _CONFIG_H_
-#define BUILT_WITH "GCC GXX PKGCONFIG OSXLD LIBDL PLUGINS ZLIB SSL SASL_CYRUS ZSTD HDRHISTOGRAM LZ4_EXT SNAPPY SOCKEM SASL_SCRAM CRC32C_HW"
+// BUILT_WITH
+#define BUILT_WITH "ZLIB ZSTD LZ4_EXT SNAPPY SSL SASL_CYRUS SASL_SCRAM SASL_OAUTHBEARER"
 
+// distro
+#define SOLIB_EXT ".so"
+//#define ARCH "x86_64"
 #define CPU "generic"
 #define WITHOUT_OPTIMIZATION 0
+#define WITH_STRIP 0
 #define ENABLE_DEVEL 0
 #define ENABLE_VALGRIND 0
 #define ENABLE_REFCNT_DEBUG 0
-#define ENABLE_SHAREDPTR_DEBUG 0
-#define ENABLE_LZ4_EXT 1
-#define ENABLE_SSL 1
-#define ENABLE_SASL 1
+
+// #define ENABLE_ZLIB 1
+// #define ENABLE_ZSTD 1
+// #define ENABLE_SSL 1
+// #define ENABLE_GSSAPI 1
+// #define ENABLE_LZ4_EXT 1
+// #define ENABLE_REGEX_EXT 1
+// #define ENABLE_C11THREADS "try"
+// #define ENABLE_SYSLOG 1
 #define MKL_APP_NAME "librdkafka"
 #define MKL_APP_DESC_ONELINE "The Apache Kafka C/C++ library"
-// distro
-#define SOLIB_EXT ".so"
 // gcc
-//#define WITH_GCC 1
+// #define WITH_GCC 1
 // gxx
-//#define WITH_GXX 1
-// pkgconfig
-//#define WITH_PKGCONFIG 1
+// #define WITH_GXX 1
 // install
-//#define WITH_INSTALL 1
+// #define WITH_INSTALL 1
+// gnuar
+// #define HAS_GNU_AR 1
 // PIC
-//#define HAVE_PIC 1
+// #define HAVE_PIC 1
 // gnulib
-//#define WITH_GNULD 1
+// #define WITH_GNULD 1
 // __atomic_32
 #define HAVE_ATOMICS_32 1
 // __atomic_32
@@ -43,43 +76,53 @@
 // atomic_64
 #define ATOMIC_OP(OP1,OP2,PTR,VAL) __atomic_ ## OP1 ## _ ## OP2(PTR, VAL, __ATOMIC_SEQ_CST)
 // parseversion
-#define RDKAFKA_VERSION_STR "1.6.0"
+#define RDKAFKA_VERSION_STR "2.8.0"
 // parseversion
-#define MKL_APP_VERSION "1.6.0"
+#define MKL_APP_VERSION "2.8.0"
+// disable C11 threads for compatibility with old libc, also C11 threads are condireder harmful
+#define WITH_C11THREADS 0
+// WITH_PLUGINS - see rd_kafka_plugin_new: it allow to dload some external plugins (no plans to support it in ClickHouse)
+#define WITH_PLUGINS 0
 // libdl
-#define WITH_LIBDL 1
-// WITH_PLUGINS
-#define WITH_PLUGINS 1
+#define WITH_LIBDL 0
 // zlib
 #define WITH_ZLIB 1
-// zstd
+// libzstd
 #define WITH_ZSTD 1
+// WITH_HDRHISTOGRAM - not used so far, can be useful for better stats
+// #define WITH_HDRHISTOGRAM 1
+// syslog
+//#define WITH_SYSLOG 1
 // WITH_SNAPPY
 #define WITH_SNAPPY 1
-// WITH_SOCKEM
-#define WITH_SOCKEM 1
+// WITH_SOCKEM - socket emulation (used for testing)
+//#define WITH_SOCKEM 1
 // libssl
 #cmakedefine WITH_SSL 1
 // WITH_SASL_SCRAM
 #cmakedefine WITH_SASL_SCRAM 1
 // WITH_SASL_OAUTHBEARER
 #cmakedefine WITH_SASL_OAUTHBEARER 1
+#cmakedefine WITH_OAUTHBEARER_OIDC 1
+// libsasl2
 #cmakedefine WITH_SASL_CYRUS 1
+// WITH_CURL
+#cmakedefine WITH_CURL 1
 // crc32chw
 #if !defined(__PPC__) && !defined(__riscv) && !defined(__aarch64__) && !defined(__s390x__) && !defined(__loongarch64)
 #define WITH_CRC32C_HW 1
 #endif
 // regex
 #define HAVE_REGEX 1
+// rand_r
+#define HAVE_RAND_R 1
 // strndup
 #define HAVE_STRNDUP 1
 // strerror_r
 #define HAVE_STRERROR_R 1
-// rand_r
-#define HAVE_RAND_R 1
-
+// strcasestr
+#define HAVE_STRCASESTR 1
 #ifdef __APPLE__
-// pthread_setname_np
 #define HAVE_PTHREAD_SETNAME_DARWIN 1
 #if (__ENVIRONMENT_MAC_OS_X_VERSION_MIN_REQUIRED__ <= 101400)
 #define _TTHREAD_EMULATE_TIMESPEC_GET_
@@ -90,8 +133,8 @@
 // pthread_setname_gnu
 #define HAVE_PTHREAD_SETNAME_GNU 1
 #endif
-// python
+// python3
 //#define HAVE_PYTHON 1
-// disable C11 threads for compatibility with old libc
-//#define WITH_C11THREADS 1
+// getrusage - used in a single test tests/rusage.c only
+//#define HAVE_GETRUSAGE 1
 #endif /* _CONFIG_H_ */
diff --git a/src/Storages/Kafka/KafkaConsumer.cpp b/src/Storages/Kafka/KafkaConsumer.cpp
index fbef36ddc26c..7b799ccec6f8 100644
--- a/src/Storages/Kafka/KafkaConsumer.cpp
+++ b/src/Storages/Kafka/KafkaConsumer.cpp
@@ -151,19 +151,12 @@ void KafkaConsumer::createConsumer(cppkafka::Configuration consumer_config)
 
 ConsumerPtr && KafkaConsumer::moveConsumer()
 {
+    // messages & assignment should be destroyed before consumer
     cleanUnprocessed();
-    if (!consumer->get_subscription().empty())
-    {
-        try
-        {
-            consumer->unsubscribe();
-        }
-        catch (const cppkafka::HandleException & e)
-        {
-            LOG_ERROR(log, "Error during unsubscribe: {}", e.what());
-        }
-        drain();
-    }
+    assignment.reset();
+
+    StorageKafkaUtils::consumerGracefulStop(*consumer, DRAIN_TIMEOUT_MS, log, [this](const cppkafka::Error & err) { setExceptionInfo(err); });
+
     return std::move(consumer);
 }
 
@@ -173,36 +166,12 @@ KafkaConsumer::~KafkaConsumer()
         return;
 
     cleanUnprocessed();
-    try
-    {
-        if (!consumer->get_subscription().empty())
-        {
-            try
-            {
-                consumer->unsubscribe();
-            }
-            catch (const cppkafka::HandleException & e)
-            {
-                LOG_ERROR(log, "Error during unsubscribe: {}", e.what());
-            }
-            drain();
-        }
-    }
-    catch (const cppkafka::HandleException & e)
-    {
-        LOG_ERROR(log, "Error while destructing consumer: {}", e.what());
-    }
-}
+    assignment.reset();
 
-// Needed to drain rest of the messages / queued callback calls from the consumer
-// after unsubscribe, otherwise consumer will hang on destruction
-// see https://github.com/edenhill/librdkafka/issues/2077
-//     https://github.com/confluentinc/confluent-kafka-go/issues/189 etc.
-void KafkaConsumer::drain()
-{
-    StorageKafkaUtils::drainConsumer(*consumer, DRAIN_TIMEOUT_MS, log, [this](const cppkafka::Error & err) { setExceptionInfo(err); });
+    StorageKafkaUtils::consumerGracefulStop(*consumer, DRAIN_TIMEOUT_MS, log, [this](const cppkafka::Error & err) { setExceptionInfo(err); });
 }
 
+
 void KafkaConsumer::commit()
 {
     auto print_offsets = [this] (const char * prefix, const cppkafka::TopicPartitionList & offsets)
@@ -236,7 +205,7 @@ void KafkaConsumer::commit()
 
     if (hasMorePolledMessages())
     {
-        LOG_WARNING(log, "Logical error. Non all polled messages were processed.");
+        LOG_WARNING(log, "Logical error. Not all polled messages were processed.");
     }
 
     if (offsets_stored > 0)
@@ -299,80 +268,105 @@ void KafkaConsumer::commit()
 
 void KafkaConsumer::subscribe()
 {
-    LOG_TRACE(log, "Already subscribed to topics: [{}]", boost::algorithm::join(consumer->get_subscription(), ", "));
+    cleanUnprocessed();
 
-    if (assignment.has_value())
-    {
-        LOG_TRACE(log, "Already assigned to: {}", assignment.value());
-    }
-    else
+    // we can reset any flags (except of CONSUMER_STOPPED) before attempt of reading new block of data
+    if (stalled_status != CONSUMER_STOPPED)
+        stalled_status = NO_MESSAGES_RETURNED;
+
+    auto subscription = consumer->get_subscription();
+
+    if (!subscription.empty())
     {
-        LOG_TRACE(log, "No assignment");
-    }
+        LOG_TRACE(log, "Already subscribed to topics: [{}]", boost::algorithm::join(subscription, ", "));
+
+        if (assignment.has_value())
+            LOG_TRACE(log, "Already assigned to: {}", assignment.value());
+        else
+            LOG_TRACE(log, "No assignment");
 
+        if (current_subscription_valid)
+            return;
+    }
 
     size_t max_retries = 5;
 
-    while (consumer->get_subscription().empty())
+    while (true)
     {
         --max_retries;
+
+        if (stopped)
+        {
+            LOG_TRACE(log, "Consumer is stopped; cannot subscribe.");
+            return;
+        }
+
+        LOG_TRACE(log, "Subscribing to topics: [{}]", boost::algorithm::join(topics, ", "));
+
         try
         {
             consumer->subscribe(topics);
-            // FIXME: if we failed to receive "subscribe" response while polling and destroy consumer now, then we may hang up.
-            //        see https://github.com/edenhill/librdkafka/issues/2077
         }
-        catch (cppkafka::HandleException & e)
+        catch (const cppkafka::HandleException & e)
         {
+            LOG_ERROR(log, "Exception during subscribe: {}", e.what());
+
             if (max_retries > 0 && e.get_error() == RD_KAFKA_RESP_ERR__TIMED_OUT)
                 continue;
+
+            setExceptionInfo(e.what());
             throw;
         }
+
+        subscription = consumer->get_subscription();
+
+        if (subscription.empty())
+        {
+            if (max_retries > 0)
+            {
+                LOG_WARNING(log, "Subscription is empty. Will try to resubscribe.");
+                continue;
+            }
+            else
+            {
+                throw Exception(ErrorCodes::CANNOT_COMMIT_OFFSET, "Can not get subscription.");
+            }
+        }
+        else
+        {
+            LOG_TRACE(log, "Subscribed to topics: [{}]", boost::algorithm::join(subscription, ", "));
+            break;
+        }
     }
 
-    cleanUnprocessed();
+    current_subscription_valid = true;
 
-    // we can reset any flags (except of CONSUMER_STOPPED) before attempt of reading new block of data
-    if (stalled_status != CONSUMER_STOPPED)
-        stalled_status = NO_MESSAGES_RETURNED;
+    // Immediately poll for messages (+callbacks) after successful subscription.
+    doPoll();
 }
 
 void KafkaConsumer::cleanUnprocessed()
 {
     messages.clear();
-    current = messages.begin();
+    current = messages.end();
     offsets_stored = 0;
 }
 
-void KafkaConsumer::unsubscribe()
+void KafkaConsumer::markDirty()
 {
-    LOG_TRACE(log, "Re-joining claimed consumer after failure");
-    cleanUnprocessed();
-
-    // it should not raise exception as used in destructor
-    try
-    {
-        // From docs: Any previous subscription will be unassigned and unsubscribed first.
-        consumer->subscribe(topics);
+    LOG_TRACE(log, "Marking consumer as dirty after failure, so it will rejoin consumer group on the next usage.");
 
-        // I wanted to avoid explicit unsubscribe as it requires draining the messages
-        // to close the consumer safely after unsubscribe
-        // see https://github.com/edenhill/librdkafka/issues/2077
-        //     https://github.com/confluentinc/confluent-kafka-go/issues/189 etc.
-    }
-    catch (const cppkafka::HandleException & e)
-    {
-        LOG_ERROR(log, "Exception from KafkaConsumer::unsubscribe: {}", e.what());
-    }
+    cleanUnprocessed();
 
+    // Next subscribe call will redo subscription, causing a rebalance/offset reset and potential duplicates.
+    current_subscription_valid = false;
 }
 
-
 void KafkaConsumer::resetToLastCommitted(const char * msg)
 {
     if (!assignment.has_value() || assignment->empty())
     {
-        LOG_TRACE(log, "Not assigned. Can't reset to last committed position.");
+        LOG_TRACE(log, "Not assigned; cannot reset to last committed position.");
         return;
     }
     auto committed_offset = consumer->get_offsets_committed(consumer->get_assignment());
@@ -380,19 +374,10 @@ void KafkaConsumer::resetToLastCommitted(const char * msg)
     LOG_TRACE(log, "{} Returned to committed position: {}", msg, committed_offset);
 }
 
-// it do the poll when needed
-ReadBufferPtr KafkaConsumer::consume()
-{
-    resetIfStopped();
-
-    if (polledDataUnusable())
-        return nullptr;
-
-    if (hasMorePolledMessages())
-        return getNextMessage();
 
-    if (intermediate_commit)
-        commit();
+void KafkaConsumer::doPoll()
+{
+    assert(current == messages.end());
 
     while (true)
     {
@@ -411,12 +396,16 @@ ReadBufferPtr KafkaConsumer::consume()
         auto new_messages = consumer->poll_batch(batch_size,
                             std::chrono::milliseconds(actual_poll_timeout_ms));
         last_poll_timestamp = timeInSeconds(std::chrono::system_clock::now());
+
+        // Remove messages with errors and log any exceptions.
+        auto num_errors = StorageKafkaUtils::eraseMessageErrors(new_messages, log, [this](const cppkafka::Error & err) { setExceptionInfo(err); });
         num_messages_read += new_messages.size();
 
         resetIfStopped();
+
         if (stalled_status == CONSUMER_STOPPED)
         {
-            return nullptr;
+            return;
         }
         if (stalled_status == REBALANCE_HAPPENED)
         {
@@ -425,9 +414,9 @@ ReadBufferPtr KafkaConsumer::consume()
                 // we have polled something just after rebalance.
                 // we will not use current batch, so we need to return to last committed position
                 // otherwise we will continue polling from that position
-                resetToLastCommitted("Rewind last poll after rebalance.");
+                resetToLastCommitted("Rewinding last poll after rebalance.");
             }
-            return nullptr;
+            return;
         }
 
         if (new_messages.empty())
@@ -436,7 +425,7 @@ ReadBufferPtr KafkaConsumer::consume()
             // If we're doing a manual select then it's better to get something after a wait, then immediate nothing.
             if (!assignment.has_value())
             {
-                waited_for_assignment += poll_timeout; // slightly inaccurate, but rough calculation is ok.
+                waited_for_assignment += poll_timeout; // Rough calculation for total wait time.
                 if (waited_for_assignment < MAX_TIME_TO_WAIT_FOR_ASSIGNMENT_MS)
                 {
                     continue;
@@ -444,40 +433,61 @@ ReadBufferPtr KafkaConsumer::consume()
 
                 LOG_WARNING(log, "Can't get assignment. Will keep trying.");
                 stalled_status = NO_ASSIGNMENT;
-                return nullptr;
+                return;
             }
+
             if (assignment->empty())
             {
                 LOG_TRACE(log, "Empty assignment.");
-                return nullptr;
+                return;
             }
 
-            LOG_TRACE(log, "Stalled");
-            return nullptr;
+            if (num_errors > 0)
+            {
+                LOG_WARNING(log, "Only errors polled.");
+                stalled_status = ERRORS_RETURNED;
+                return;
+            }
+
+            LOG_TRACE(log, "Stalled.");
+            return;
         }
 
         messages = std::move(new_messages);
         current = messages.begin();
+
+        ProfileEvents::increment(ProfileEvents::KafkaMessagesPolled, messages.size());
+
         LOG_TRACE(
             log,
             "Polled batch of {} messages. Offsets position: {}",
             messages.size(),
             consumer->get_offsets_position(consumer->get_assignment()));
+
+        stalled_status = NOT_STALLED;
+
         break;
     }
+}
 
-    filterMessageErrors();
-    if (current == messages.end())
-    {
-        LOG_ERROR(log, "Only errors left");
-        stalled_status = ERRORS_RETURNED;
+/// Consumes a single message from the buffered polled batch
+/// does the poll if needed
+ReadBufferPtr KafkaConsumer::consume()
+{
+    resetIfStopped();
+
+    if (polledDataUnusable())
         return nullptr;
-    }
 
-    ProfileEvents::increment(ProfileEvents::KafkaMessagesPolled, messages.size());
+    if (hasMorePolledMessages())
+        return getNextMessage();
 
-    stalled_status = NOT_STALLED;
-    return getNextMessage();
+    if (intermediate_commit)
+        commit();
+
+    doPoll();
+
+    return stalled_status == NOT_STALLED ? getNextMessage() : nullptr;
 }
 
 ReadBufferPtr KafkaConsumer::getNextMessage()
@@ -495,13 +505,6 @@ ReadBufferPtr KafkaConsumer::getNextMessage()
     return getNextMessage();
 }
 
-void KafkaConsumer::filterMessageErrors()
-{
-    assert(current == messages.begin());
-
-    StorageKafkaUtils::eraseMessageErrors(messages, log, [this](const cppkafka::Error & err) { setExceptionInfo(err); });
-    current = messages.begin();
-}
 
 void KafkaConsumer::resetIfStopped()
 {
diff --git a/src/Storages/Kafka/KafkaConsumer.h b/src/Storages/Kafka/KafkaConsumer.h
index b7cd8bb78b1a..9e299f67c4a3 100644
--- a/src/Storages/Kafka/KafkaConsumer.h
+++ b/src/Storages/Kafka/KafkaConsumer.h
@@ -80,7 +80,11 @@ class KafkaConsumer
 
     void commit(); // Commit all processed messages.
     void subscribe(); // Subscribe internal consumer to topics.
-    void unsubscribe(); // Unsubscribe internal consumer in case of failure.
+
+    // used during exception processing to restart the consumption from last committed offset
+    // Notes: duplicates can appear if the some data were already flushed
+    // it causes rebalance (and is an expensive way of exception handling)
+    void markDirty();
 
     auto pollTimeout() const { return poll_timeout; }
 
@@ -156,6 +160,7 @@ class KafkaConsumer
     const size_t batch_size = 1;
     const size_t poll_timeout = 0;
     size_t offsets_stored = 0;
+    bool current_subscription_valid = false;
 
     StalledStatus stalled_status = NO_MESSAGES_RETURNED;
 
@@ -189,10 +194,9 @@ class KafkaConsumer
     /// Last used time (for TTL)
     std::atomic<UInt64> last_used_usec = 0;
 
-    void drain();
+    void doPoll();
     void cleanUnprocessed();
     void resetIfStopped();
-    void filterMessageErrors();
     ReadBufferPtr getNextMessage();
 };
 
diff --git a/src/Storages/Kafka/KafkaConsumer2.cpp b/src/Storages/Kafka/KafkaConsumer2.cpp
index a70a73f9be5d..213b8e5f899f 100644
--- a/src/Storages/Kafka/KafkaConsumer2.cpp
+++ b/src/Storages/Kafka/KafkaConsumer2.cpp
@@ -127,34 +127,7 @@ KafkaConsumer2::KafkaConsumer2(
 
 KafkaConsumer2::~KafkaConsumer2()
 {
-    try
-    {
-        if (!consumer->get_subscription().empty())
-        {
-            try
-            {
-                consumer->unsubscribe();
-            }
-            catch (const cppkafka::HandleException & e)
-            {
-                LOG_ERROR(log, "Error during unsubscribe: {}", e.what());
-            }
-            drainConsumerQueue();
-        }
-    }
-    catch (const cppkafka::HandleException & e)
-    {
-        LOG_ERROR(log, "Error while destructing consumer: {}", e.what());
-    }
-}
-
-// Needed to drain rest of the messages / queued callback calls from the consumer after unsubscribe, otherwise consumer
-// will hang on destruction. Partition queues doesn't have to be attached as events are not handled by those queues.
-// see https://github.com/edenhill/librdkafka/issues/2077
-//     https://github.com/confluentinc/confluent-kafka-go/issues/189 etc.
-void KafkaConsumer2::drainConsumerQueue()
-{
-    StorageKafkaUtils::drainConsumer(*consumer, DRAIN_TIMEOUT_MS, log);
+    StorageKafkaUtils::consumerGracefulStop(*consumer, DRAIN_TIMEOUT_MS, log);
 }
 
 void KafkaConsumer2::pollEvents()
diff --git a/src/Storages/Kafka/KafkaConsumer2.h b/src/Storages/Kafka/KafkaConsumer2.h
index f928a39aeec0..6bba0bf89bbb 100644
--- a/src/Storages/Kafka/KafkaConsumer2.h
+++ b/src/Storages/Kafka/KafkaConsumer2.h
@@ -145,7 +145,6 @@ class KafkaConsumer2
     const Names topics;
 
     bool polledDataUnusable(const TopicPartition & topic_partition) const;
-    void drainConsumerQueue();
     void resetIfStopped();
     void filterMessageErrors();
     ReadBufferPtr getNextMessage();
diff --git a/src/Storages/Kafka/KafkaSource.cpp b/src/Storages/Kafka/KafkaSource.cpp
index 2ce8bddd546f..ed8b2285ecf0 100644
--- a/src/Storages/Kafka/KafkaSource.cpp
+++ b/src/Storages/Kafka/KafkaSource.cpp
@@ -64,7 +64,7 @@ KafkaSource::~KafkaSource()
         return;
 
     if (broken)
-        consumer->unsubscribe();
+        consumer->markDirty();
 
     storage.pushConsumer(consumer);
 }
diff --git a/src/Storages/Kafka/StorageKafka.cpp b/src/Storages/Kafka/StorageKafka.cpp
index aa4a89f8df86..bb44e8dc9dc9 100644
--- a/src/Storages/Kafka/StorageKafka.cpp
+++ b/src/Storages/Kafka/StorageKafka.cpp
@@ -287,6 +287,10 @@ void StorageKafka::startup()
 
 void StorageKafka::shutdown(bool)
 {
+    // Interrupt streaming, inform consumers to stop
+    for (auto & task : tasks)
+        task->stream_cancelled = true;
+
     shutdown_called = true;
     cleanup_cv.notify_one();
 
@@ -306,9 +310,6 @@ void StorageKafka::shutdown(bool)
         Stopwatch watch;
         for (auto & task : tasks)
         {
-            // Interrupt streaming thread
-            task->stream_cancelled = true;
-
             LOG_TEST(log, "Waiting for cleanup of a task");
             task->holder->deactivate();
         }
diff --git a/src/Storages/Kafka/StorageKafkaUtils.cpp b/src/Storages/Kafka/StorageKafkaUtils.cpp
index e3617cc1cf2e..42588fc43f51 100644
--- a/src/Storages/Kafka/StorageKafkaUtils.cpp
+++ b/src/Storages/Kafka/StorageKafkaUtils.cpp
@@ -333,6 +333,75 @@ String getDefaultClientId(const StorageID & table_id)
     return fmt::format("{}-{}-{}-{}", VERSION_NAME, getFQDNOrHostName(), table_id.database_name, table_id.table_name);
 }
 
+void consumerGracefulStop(
+    cppkafka::Consumer & consumer, const std::chrono::milliseconds drain_timeout, const LoggerPtr & log, ErrorHandler error_handler)
+{
+    // Note: librdkafka is very sensitive to the proper termination sequence and have some race conditions there.
+    // Before destruction, our objectives are:
+    //   (1) Process all outstanding callbacks by polling the event queue.
+    //   (2) Ensure that only special events (e.g. callbacks, rebalances) are polled (we don't want to poll regular messages).
+    //
+    // Previously, we performed an unsubscribe to stop message consumption and clear 'read' messages.
+    // However, unsubscribe triggers a rebalance that schedules additional background tasks, such as locking
+    // and removal of internal toppar queues. Meanwhile, polling to release callbacks may concurrently
+    // cause those same queues to be destroyed.
+    // This can lead to a situation where the background thread doing rebalance and the current thread doing polling access
+    // the toppar queues simultaneously, potentially locking them in a different order, which risks a deadlock.
+    //
+    // To mitigate this, we now:
+    //   (1) Avoid calling unsubscribe (letting rebalance occur naturally via consumer group timeout).
+    //   (2) Set up different rebalance callbacks to repeat (3) if a rebalance will occur before consumer destruction.
+    //   (3) Pause the consumer to stop processing new messages.
+    //   (4) Disconnect the toppar queues to reduce the risk of lock inversion (less cascading locks).
+    //   (5) Poll the event queue to process any remaining callbacks.
+
+    consumer.set_revocation_callback(
+        [](const cppkafka::TopicPartitionList &)
+        {
+            // we don't care during the destruction
+        });
+
+    consumer.set_assignment_callback(
+        [&consumer](const cppkafka::TopicPartitionList & topic_partitions)
+        {
+            if (!topic_partitions.empty())
+            {
+                consumer.pause_partitions(topic_partitions);
+            }
+
+            // it's not clear if get_partition_queue will work in that context
+            // as just after processing the callback cppkafka will call run assign
+            // and that can reset the queues
+
+        });
+
+    try
+    {
+        auto assignment = consumer.get_assignment();
+
+        if (!assignment.empty())
+        {
+            consumer.pause_partitions(assignment);
+
+            for (const auto& partition : assignment)
+            {
+                // that call disables the forwarding of the messages to the customer queue
+                consumer.get_partition_queue(partition);
+            }
+        }
+    }
+    catch (const cppkafka::HandleException & e)
+    {
+        LOG_ERROR(log, "Error during pause (consumerGracefulStop): {}", e.what());
+    }
+
+    drainConsumer(consumer, drain_timeout, log, std::move(error_handler));
+}
+
+// Needed to drain rest of the messages / queued callback calls from the consumer after unsubscribe, otherwise consumer
+// will hang on destruction. Partition queues doesn't have to be attached as events are not handled by those queues.
+// see https://github.com/edenhill/librdkafka/issues/2077
+//     https://github.com/confluentinc/confluent-kafka-go/issues/189 etc.
 void drainConsumer(
     cppkafka::Consumer & consumer, const std::chrono::milliseconds drain_timeout, const LoggerPtr & log, ErrorHandler error_handler)
 {
@@ -371,7 +440,7 @@ void drainConsumer(
     }
 }
 
-void eraseMessageErrors(Messages & messages, const LoggerPtr & log, ErrorHandler error_handler)
+size_t eraseMessageErrors(Messages & messages, const LoggerPtr & log, ErrorHandler error_handler)
 {
     size_t skipped = std::erase_if(
         messages,
@@ -389,6 +458,8 @@ void eraseMessageErrors(Messages & messages, const LoggerPtr & log, ErrorHandler
 
     if (skipped)
         LOG_ERROR(log, "There were {} messages with an error", skipped);
+
+    return skipped;
 }
 
 SettingsChanges createSettingsAdjustments(KafkaSettings & kafka_settings, const String & schema_name)
diff --git a/src/Storages/Kafka/StorageKafkaUtils.h b/src/Storages/Kafka/StorageKafkaUtils.h
index 5f681e94077e..c0ed83cb57d7 100644
--- a/src/Storages/Kafka/StorageKafkaUtils.h
+++ b/src/Storages/Kafka/StorageKafkaUtils.h
@@ -34,6 +34,12 @@ String getDefaultClientId(const StorageID & table_id);
 
 using ErrorHandler = std::function<void(const cppkafka::Error &)>;
 
+void consumerGracefulStop(
+    cppkafka::Consumer & consumer,
+    std::chrono::milliseconds drain_timeout,
+    const LoggerPtr & log,
+    ErrorHandler error_handler = [](const cppkafka::Error & /*err*/) {});
+
 void drainConsumer(
     cppkafka::Consumer & consumer,
     std::chrono::milliseconds drain_timeout,
@@ -41,7 +47,7 @@ void drainConsumer(
     ErrorHandler error_handler = [](const cppkafka::Error & /*err*/) {});
 
 using Messages = std::vector<cppkafka::Message>;
-void eraseMessageErrors(Messages & messages, const LoggerPtr & log, ErrorHandler error_handler = [](const cppkafka::Error & /*err*/) {});
+size_t eraseMessageErrors(Messages & messages, const LoggerPtr & log, ErrorHandler error_handler = [](const cppkafka::Error & /*err*/) {});
 
 SettingsChanges createSettingsAdjustments(KafkaSettings & kafka_settings, const String & schema_name);
 
