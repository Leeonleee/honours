diff --git a/tests/clickhouse-test b/tests/clickhouse-test
index abf251b1f39c..4c94e4d64937 100755
--- a/tests/clickhouse-test
+++ b/tests/clickhouse-test
@@ -337,6 +337,26 @@ class FailureReason(enum.Enum):
     INTERNAL_ERROR = "Test internal error: "
 
 
+class SettingsRandomizer:
+    settings = {
+        "max_insert_threads": lambda: 0 if random.random() < 0.5 else random.randint(1, 16),
+        "group_by_two_level_threshold": lambda: 1 if random.random() < 0.1 else 2 ** 60 if random.random() < 0.11 else 100000,
+        "group_by_two_level_threshold_bytes": lambda: 1 if random.random() < 0.1 else 2 ** 60 if random.random() < 0.11 else 50000000,
+        "distributed_aggregation_memory_efficient": lambda: random.randint(0, 1),
+        "fsync_metadata": lambda: random.randint(0, 1),
+        "priority": lambda: int(abs(random.gauss(0, 2))),
+        "output_format_parallel_formatting": lambda: random.randint(0, 1),
+        "input_format_parallel_parsing": lambda: random.randint(0, 1),
+    }
+
+    @staticmethod
+    def get_random_settings():
+        random_settings = []
+        for setting, generator in SettingsRandomizer.settings.items():
+            random_settings.append(setting + "=" + str(generator()) + "")
+        return random_settings
+
+
 class TestResult:
     def __init__(self, case_name: str, status: TestStatus, reason: Optional[FailureReason], total_time: float, description: str):
         self.case_name: str = case_name
@@ -417,6 +437,29 @@ class TestCase:
 
         return testcase_args
 
+    def add_random_settings(self, client_options):
+        if self.tags and 'no-random-settings' in self.tags:
+            return client_options
+
+        if len(self.base_url_params) == 0:
+            os.environ['CLICKHOUSE_URL_PARAMS'] = '&'.join(self.random_settings)
+        else:
+            os.environ['CLICKHOUSE_URL_PARAMS'] = self.base_url_params + '&' + '&'.join(self.random_settings)
+
+        new_options = "--allow_repeated_settings --" + " --".join(self.random_settings)
+        os.environ['CLICKHOUSE_CLIENT_OPT'] = self.base_client_options + new_options + ' '
+        return client_options + new_options
+
+    def remove_random_settings_from_env(self):
+        os.environ['CLICKHOUSE_URL_PARAMS'] = self.base_url_params
+        os.environ['CLICKHOUSE_CLIENT_OPT'] = self.base_client_options
+
+    def add_info_about_settings(self, description):
+        if self.tags and 'no-random-settings' in self.tags:
+            return description
+
+        return description + "
" + "Settings used in the test: " + "--" + " --".join(self.random_settings) + "
"
+
     def __init__(self, suite, case: str, args, is_concurrent: bool):
         self.case: str = case   # case file name
         self.tags: Set[str] = suite.all_tags[case] if case in suite.all_tags else set()
@@ -432,6 +475,10 @@ class TestCase:
         self.testcase_args = None
         self.runs_count = 0
 
+        self.random_settings = SettingsRandomizer.get_random_settings()
+        self.base_url_params = os.environ['CLICKHOUSE_URL_PARAMS'] if 'CLICKHOUSE_URL_PARAMS' in os.environ else ''
+        self.base_client_options = os.environ['CLICKHOUSE_CLIENT_OPT'] if 'CLICKHOUSE_CLIENT_OPT' in os.environ else ''
+
     # should skip test, should increment skipped_total, skip reason
     def should_skip_test(self, suite) -> Optional[FailureReason]:
         tags = self.tags
@@ -673,10 +720,13 @@ class TestCase:
 
             self.runs_count += 1
             self.testcase_args = self.configure_testcase_args(args, self.case_file, suite.suite_tmp_path)
+            client_options = self.add_random_settings(client_options)
             proc, stdout, stderr, total_time = self.run_single_test(server_logs_level, client_options)
 
             result = self.process_result_impl(proc, stdout, stderr, total_time)
             result.check_if_need_retry(args, stdout, stderr, self.runs_count)
+            if result.status == TestStatus.FAIL:
+                result.description = self.add_info_about_settings(result.description)
             return result
         except KeyboardInterrupt as e:
             raise e
@@ -684,17 +734,20 @@ class TestCase:
             return TestResult(self.name, TestStatus.FAIL,
                               FailureReason.INTERNAL_QUERY_FAIL,
                               0.,
-                              self.get_description_from_exception_info(sys.exc_info()))
+                              self.add_info_about_settings(self.get_description_from_exception_info(sys.exc_info())))
         except (ConnectionRefusedError, ConnectionResetError):
             return TestResult(self.name, TestStatus.FAIL,
                               FailureReason.SERVER_DIED,
                               0.,
-                              self.get_description_from_exception_info(sys.exc_info()))
+                              self.add_info_about_settings(self.get_description_from_exception_info(sys.exc_info())))
         except:
             return TestResult(self.name, TestStatus.UNKNOWN,
                               FailureReason.INTERNAL_ERROR,
                               0.,
                               self.get_description_from_exception_info(sys.exc_info()))
+        finally:
+            self.remove_random_settings_from_env()
+
 
 class TestSuite:
     @staticmethod
diff --git a/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql b/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql
index f9cbf92db41f..e29a166c1eed 100644
--- a/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql
+++ b/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql
@@ -1,5 +1,6 @@
 -- Tags: replica, distributed
 
+SET allow_experimental_parallel_reading_from_replicas = 0;
 SET max_parallel_replicas = 2;
 DROP TABLE IF EXISTS report;
 
diff --git a/tests/queries/0_stateless/00474_readonly_settings.reference b/tests/queries/0_stateless/00474_readonly_settings.reference
index b1da40ce414d..e2b45931965f 100644
--- a/tests/queries/0_stateless/00474_readonly_settings.reference
+++ b/tests/queries/0_stateless/00474_readonly_settings.reference
@@ -2,13 +2,11 @@
 			"value": 4611686018427387904
 			"name": "value",
 			"value": "4611686018427387904"
-value
-value
-Cannot modify 'output_format_json_quote_64bit_integers' setting in readonly mode
+OK
+OK
 			"name": "value",
 			"value": "9223372036854775808"
 			"name": "value",
 			"value": 9223372036854775808
-value
-value
-Cannot modify 'output_format_json_quote_64bit_integers' setting in readonly mode
+OK
+OK
diff --git a/tests/queries/0_stateless/00474_readonly_settings.sh b/tests/queries/0_stateless/00474_readonly_settings.sh
index 0887ecfa14e4..07b78c64a7ea 100755
--- a/tests/queries/0_stateless/00474_readonly_settings.sh
+++ b/tests/queries/0_stateless/00474_readonly_settings.sh
@@ -9,13 +9,15 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 $CLICKHOUSE_CLIENT --query="select toUInt64(pow(2, 62)) as value format JSON" --output_format_json_quote_64bit_integers=0 | grep value
 $CLICKHOUSE_CLIENT --query="select toUInt64(pow(2, 62)) as value format JSON" --output_format_json_quote_64bit_integers=1 | grep value
 
-$CLICKHOUSE_CLIENT --readonly=1 --multiquery --query="set output_format_json_quote_64bit_integers=1 ; select toUInt64(pow(2, 63)) as value format JSON" --server_logs_file=/dev/null 2>&1 | grep -o 'value\|Cannot modify .* setting in readonly mode'
-$CLICKHOUSE_CLIENT --readonly=1 --multiquery --query="set output_format_json_quote_64bit_integers=0 ; select toUInt64(pow(2, 63)) as value format JSON" --server_logs_file=/dev/null 2>&1 | grep -o 'value\|Cannot modify .* setting in readonly mode'
+$CLICKHOUSE_CLIENT --readonly=1 --multiquery --query="set output_format_json_quote_64bit_integers=1 ; select toUInt64(pow(2, 63)) as value format JSON" --server_logs_file=/dev/null 2>&1 | grep -o -q 'value\|Cannot modify .* setting in readonly mode' && echo "OK" || echo "FAIL"
+$CLICKHOUSE_CLIENT --readonly=1 --multiquery --query="set output_format_json_quote_64bit_integers=0 ; select toUInt64(pow(2, 63)) as value format JSON" --server_logs_file=/dev/null 2>&1 | grep -o -q 'value\|Cannot modify .* setting in readonly mode' && echo "OK" || echo "FAIL"
+
 
 ${CLICKHOUSE_CURL} -sS "${CLICKHOUSE_URL}&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=1" | grep value
 ${CLICKHOUSE_CURL} -sS "${CLICKHOUSE_URL}&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=0" | grep value
 
-${CLICKHOUSE_CURL} -sS "${CLICKHOUSE_URL}&session_id=readonly&session_timeout=3600" -d 'SET readonly = 1'
+#${CLICKHOUSE_CURL} -sS "${CLICKHOUSE_URL}&session_id=readonly&session_timeout=3600" -d 'SET readonly = 1'
+
+${CLICKHOUSE_CURL} -sS "${CLICKHOUSE_URL}&session_id=readonly&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=1" 2>&1 | grep -o -q 'value\|Cannot modify .* setting in readonly mode.' && echo "OK" || echo "FAIL"
+${CLICKHOUSE_CURL} -sS "${CLICKHOUSE_URL}&session_id=readonly&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=0" 2>&1 | grep -o -q 'value\|Cannot modify .* setting in readonly mode' && echo "OK" || echo "FAIL"
 
-${CLICKHOUSE_CURL} -sS "${CLICKHOUSE_URL}&session_id=readonly&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=1" 2>&1 | grep -o 'value\|Cannot modify .* setting in readonly mode.'
-${CLICKHOUSE_CURL} -sS "${CLICKHOUSE_URL}&session_id=readonly&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=0" 2>&1 | grep -o 'value\|Cannot modify .* setting in readonly mode'
diff --git a/tests/queries/0_stateless/00808_not_optimize_predicate.sql b/tests/queries/0_stateless/00808_not_optimize_predicate.sql
index 7c1e57706e27..ba8f5eb57535 100644
--- a/tests/queries/0_stateless/00808_not_optimize_predicate.sql
+++ b/tests/queries/0_stateless/00808_not_optimize_predicate.sql
@@ -1,4 +1,5 @@
 SET send_logs_level = 'fatal';
+SET convert_query_to_cnf = 0;
 
 DROP TABLE IF EXISTS test_00808;
 CREATE TABLE test_00808(date Date, id Int8, name String, value Int64, sign Int8) ENGINE = CollapsingMergeTree(sign) ORDER BY (id, date);
diff --git a/tests/queries/0_stateless/00826_cross_to_inner_join.sql b/tests/queries/0_stateless/00826_cross_to_inner_join.sql
index 392ade02ab78..ce0c8ea2bfc0 100644
--- a/tests/queries/0_stateless/00826_cross_to_inner_join.sql
+++ b/tests/queries/0_stateless/00826_cross_to_inner_join.sql
@@ -1,4 +1,6 @@
 SET enable_optimize_predicate_expression = 0;
+SET optimize_move_to_prewhere = 1;
+SET convert_query_to_cnf = 0;
 
 select * from system.one l cross join system.one r;
 
diff --git a/tests/queries/0_stateless/00849_multiple_comma_join_2.sql b/tests/queries/0_stateless/00849_multiple_comma_join_2.sql
index 58535f556d97..eabede3ff002 100644
--- a/tests/queries/0_stateless/00849_multiple_comma_join_2.sql
+++ b/tests/queries/0_stateless/00849_multiple_comma_join_2.sql
@@ -1,4 +1,5 @@
 SET enable_optimize_predicate_expression = 0;
+SET convert_query_to_cnf = 0;
 
 DROP TABLE IF EXISTS t1;
 DROP TABLE IF EXISTS t2;
diff --git a/tests/queries/0_stateless/00965_shard_unresolvable_addresses.sql b/tests/queries/0_stateless/00965_shard_unresolvable_addresses.sql
index 0d82519e4d30..555e7a983809 100644
--- a/tests/queries/0_stateless/00965_shard_unresolvable_addresses.sql
+++ b/tests/queries/0_stateless/00965_shard_unresolvable_addresses.sql
@@ -1,5 +1,7 @@
 -- Tags: shard
 
+SET prefer_localhost_replica = 1;
+
 SELECT count() FROM remote('127.0.0.1,localhos', system.one); -- { serverError 198 }
 SELECT count() FROM remote('127.0.0.1|localhos', system.one);
 
diff --git a/tests/queries/0_stateless/01010_pmj_right_table_memory_limits.sql b/tests/queries/0_stateless/01010_pmj_right_table_memory_limits.sql
index af747c936781..7804ce32a5ac 100644
--- a/tests/queries/0_stateless/01010_pmj_right_table_memory_limits.sql
+++ b/tests/queries/0_stateless/01010_pmj_right_table_memory_limits.sql
@@ -1,4 +1,4 @@
--- Tags: no-parallel, no-fasttest
+-- Tags: no-parallel, no-fasttest, no-random-settings
 
 SET max_memory_usage = 32000000;
 SET join_on_disk_max_files_to_merge = 4;
diff --git a/tests/queries/0_stateless/01017_uniqCombined_memory_usage.sql b/tests/queries/0_stateless/01017_uniqCombined_memory_usage.sql
index d47dc6b8d5fa..69bd15e3f542 100644
--- a/tests/queries/0_stateless/01017_uniqCombined_memory_usage.sql
+++ b/tests/queries/0_stateless/01017_uniqCombined_memory_usage.sql
@@ -1,4 +1,4 @@
--- Tags: no-tsan, no-asan, no-msan, no-replicated-database
+-- Tags: no-tsan, no-asan, no-msan, no-replicated-database, no-random-settings
 -- Tag no-tsan: Fine thresholds on memory usage
 -- Tag no-asan: Fine thresholds on memory usage
 -- Tag no-msan: Fine thresholds on memory usage
@@ -7,6 +7,8 @@
 -- sizeof(HLL) is (2^K * 6 / 8)
 -- hence max_memory_usage for 100 rows = (96<<10)*100 = 9830400
 
+SET use_uncompressed_cache = 0; 
+
 -- HashTable for UInt32 (used until (1<<13) elements), hence 8192 elements
 SELECT 'UInt32';
 SET max_memory_usage = 4000000;
@@ -19,6 +21,8 @@ SELECT 'UInt64';
 SET max_memory_usage = 4000000;
 SELECT sum(u) FROM (SELECT intDiv(number, 4096) AS k, uniqCombined(reinterpretAsString(number % 4096)) u FROM numbers(4096 * 100) GROUP BY k); -- { serverError 241 }
 SET max_memory_usage = 9830400;
+
+
 SELECT sum(u) FROM (SELECT intDiv(number, 4096) AS k, uniqCombined(reinterpretAsString(number % 4096)) u FROM numbers(4096 * 100) GROUP BY k);
 
 SELECT 'K=16';
diff --git a/tests/queries/0_stateless/01034_prewhere_max_parallel_replicas_distributed.sql b/tests/queries/0_stateless/01034_prewhere_max_parallel_replicas_distributed.sql
index 4eea4fd47c7e..6d1c7fd5ef6a 100644
--- a/tests/queries/0_stateless/01034_prewhere_max_parallel_replicas_distributed.sql
+++ b/tests/queries/0_stateless/01034_prewhere_max_parallel_replicas_distributed.sql
@@ -1,5 +1,7 @@
 -- Tags: replica, distributed
 
+set allow_experimental_parallel_reading_from_replicas=0;
+
 drop table if exists test_max_parallel_replicas_lr;
 
 -- If you wonder why the table is named with "_lr" suffix in this test.
diff --git a/tests/queries/0_stateless/01034_sample_final_distributed.sql b/tests/queries/0_stateless/01034_sample_final_distributed.sql
index b784b35cbb33..a81fef645dbd 100644
--- a/tests/queries/0_stateless/01034_sample_final_distributed.sql
+++ b/tests/queries/0_stateless/01034_sample_final_distributed.sql
@@ -1,5 +1,7 @@
 -- Tags: distributed
 
+set allow_experimental_parallel_reading_from_replicas = 0;
+
 drop table if exists sample_final;
 create table sample_final (CounterID UInt32, EventDate Date, EventTime DateTime, UserID UInt64, Sign Int8) engine = CollapsingMergeTree(Sign) order by (CounterID, EventDate, intHash32(UserID), EventTime) sample by intHash32(UserID);
 insert into sample_final select number / (8192 * 4), toDate('2019-01-01'), toDateTime('2019-01-01 00:00:01') + number, number / (8192 * 2), number % 3 = 1 ? -1 : 1 from numbers(1000000);
diff --git a/tests/queries/0_stateless/01056_predicate_optimizer_bugs.sql b/tests/queries/0_stateless/01056_predicate_optimizer_bugs.sql
index d59b8fc30ace..6d2bb2964d64 100644
--- a/tests/queries/0_stateless/01056_predicate_optimizer_bugs.sql
+++ b/tests/queries/0_stateless/01056_predicate_optimizer_bugs.sql
@@ -1,5 +1,6 @@
 SET enable_optimize_predicate_expression = 1;
 SET joined_subquery_requires_alias = 0;
+SET convert_query_to_cnf = 0;
 
 -- https://github.com/ClickHouse/ClickHouse/issues/3885
 -- https://github.com/ClickHouse/ClickHouse/issues/5485
diff --git a/tests/queries/0_stateless/01083_cross_to_inner_with_like.sql b/tests/queries/0_stateless/01083_cross_to_inner_with_like.sql
index 644190cbddfa..6ec6e80692c2 100644
--- a/tests/queries/0_stateless/01083_cross_to_inner_with_like.sql
+++ b/tests/queries/0_stateless/01083_cross_to_inner_with_like.sql
@@ -1,3 +1,5 @@
+SET convert_query_to_cnf = 0;
+
 DROP TABLE IF EXISTS n;
 DROP TABLE IF EXISTS r;
 
diff --git a/tests/queries/0_stateless/01099_parallel_distributed_insert_select.sql b/tests/queries/0_stateless/01099_parallel_distributed_insert_select.sql
index 4e011bf6b31c..de93166d8913 100644
--- a/tests/queries/0_stateless/01099_parallel_distributed_insert_select.sql
+++ b/tests/queries/0_stateless/01099_parallel_distributed_insert_select.sql
@@ -2,6 +2,8 @@
 
 -- set insert_distributed_sync = 1;  -- see https://github.com/ClickHouse/ClickHouse/issues/18971
 
+SET allow_experimental_parallel_reading_from_replicas = 0; -- see https://github.com/ClickHouse/ClickHouse/issues/34525
+
 DROP TABLE IF EXISTS local_01099_a;
 DROP TABLE IF EXISTS local_01099_b;
 DROP TABLE IF EXISTS distributed_01099_a;
diff --git a/tests/queries/0_stateless/01155_rename_move_materialized_view.sql b/tests/queries/0_stateless/01155_rename_move_materialized_view.sql
index 0b672cbddbf0..e0546ec8117f 100644
--- a/tests/queries/0_stateless/01155_rename_move_materialized_view.sql
+++ b/tests/queries/0_stateless/01155_rename_move_materialized_view.sql
@@ -1,5 +1,7 @@
 -- Tags: no-parallel
 
+SET prefer_localhost_replica = 1;
+
 DROP DATABASE IF EXISTS test_01155_ordinary;
 DROP DATABASE IF EXISTS test_01155_atomic;
 
diff --git a/tests/queries/0_stateless/01187_set_profile_as_setting.sh b/tests/queries/0_stateless/01187_set_profile_as_setting.sh
index ec07f4d36878..dacb609d790d 100755
--- a/tests/queries/0_stateless/01187_set_profile_as_setting.sh
+++ b/tests/queries/0_stateless/01187_set_profile_as_setting.sh
@@ -1,4 +1,5 @@
 #!/usr/bin/env bash
+# Tags: no-random-settings
 
 unset CLICKHOUSE_LOG_COMMENT
 
diff --git a/tests/queries/0_stateless/01271_optimize_arithmetic_operations_in_aggr_func_with_alias.sql b/tests/queries/0_stateless/01271_optimize_arithmetic_operations_in_aggr_func_with_alias.sql
index 73b87817bb3d..242a253e67cf 100644
--- a/tests/queries/0_stateless/01271_optimize_arithmetic_operations_in_aggr_func_with_alias.sql
+++ b/tests/queries/0_stateless/01271_optimize_arithmetic_operations_in_aggr_func_with_alias.sql
@@ -1,4 +1,5 @@
 set optimize_arithmetic_operations_in_aggregate_functions = 1;
+SET convert_query_to_cnf = 0;
 
 explain syntax select min((n as a) + (1 as b)) c from (select number n from numbers(10)) where a > 0 and b > 0 having c > 0;
 select min((n as a) + (1 as b)) c from (select number n from numbers(10)) where a > 0 and b > 0 having c > 0;
diff --git a/tests/queries/0_stateless/01275_parallel_mv.sql b/tests/queries/0_stateless/01275_parallel_mv.sql
index 32b43ce616f7..11e5ff41417e 100644
--- a/tests/queries/0_stateless/01275_parallel_mv.sql
+++ b/tests/queries/0_stateless/01275_parallel_mv.sql
@@ -1,3 +1,5 @@
+set max_threads = 0;
+
 drop table if exists testX;
 drop table if exists testXA;
 drop table if exists testXB;
diff --git a/tests/queries/0_stateless/01293_show_settings.sql b/tests/queries/0_stateless/01293_show_settings.sql
index 08f00ed201c1..3e55ffb58d72 100644
--- a/tests/queries/0_stateless/01293_show_settings.sql
+++ b/tests/queries/0_stateless/01293_show_settings.sql
@@ -1,3 +1,5 @@
+-- Tags: no-random-settings
+
 show settings like 'send_timeout';
 SHOW SETTINGS ILIKE '%CONNECT_timeout%';
 SHOW CHANGED SETTINGS ILIKE '%MEMORY%';
diff --git a/tests/queries/0_stateless/01293_system_distribution_queue.sql b/tests/queries/0_stateless/01293_system_distribution_queue.sql
index 34158fb081ce..9997f18f61d3 100644
--- a/tests/queries/0_stateless/01293_system_distribution_queue.sql
+++ b/tests/queries/0_stateless/01293_system_distribution_queue.sql
@@ -1,4 +1,5 @@
 -- Tags: no-parallel
+set prefer_localhost_replica = 1;
 
 drop table if exists null_01293;
 drop table if exists dist_01293;
diff --git a/tests/queries/0_stateless/01300_group_by_other_keys.sql b/tests/queries/0_stateless/01300_group_by_other_keys.sql
index 22cff012e71e..0e37ef55a6ad 100644
--- a/tests/queries/0_stateless/01300_group_by_other_keys.sql
+++ b/tests/queries/0_stateless/01300_group_by_other_keys.sql
@@ -1,3 +1,5 @@
+set max_block_size = 65505;
+
 set optimize_group_by_function_keys = 1;
 
 SELECT round(max(log(2) * number), 6) AS k FROM numbers(10000000) GROUP BY number % 2, number % 3, (number % 2 + number % 3) % 2 ORDER BY k;
diff --git a/tests/queries/0_stateless/01308_row_policy_and_trivial_count_query.sql b/tests/queries/0_stateless/01308_row_policy_and_trivial_count_query.sql
index cd41bb227eb2..81bd2ad97a9f 100644
--- a/tests/queries/0_stateless/01308_row_policy_and_trivial_count_query.sql
+++ b/tests/queries/0_stateless/01308_row_policy_and_trivial_count_query.sql
@@ -1,3 +1,5 @@
+SET optimize_move_to_prewhere = 1;
+
 DROP TABLE IF EXISTS t;
 
 CREATE TABLE t (x UInt8) ENGINE = MergeTree ORDER BY x;
diff --git a/tests/queries/0_stateless/01339_client_unrecognized_option.sh b/tests/queries/0_stateless/01339_client_unrecognized_option.sh
index 00c153ec915a..9f827ccb13e1 100755
--- a/tests/queries/0_stateless/01339_client_unrecognized_option.sh
+++ b/tests/queries/0_stateless/01339_client_unrecognized_option.sh
@@ -1,5 +1,5 @@
 #!/usr/bin/env bash
-# Tags: no-fasttest
+# Tags: no-fasttest, no-random-settings
 
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # shellcheck source=../shell_config.sh
diff --git a/tests/queries/0_stateless/01386_negative_float_constant_key_condition.sql b/tests/queries/0_stateless/01386_negative_float_constant_key_condition.sql
index c2191d6ab968..b45b9c84b182 100644
--- a/tests/queries/0_stateless/01386_negative_float_constant_key_condition.sql
+++ b/tests/queries/0_stateless/01386_negative_float_constant_key_condition.sql
@@ -1,3 +1,5 @@
+SET convert_query_to_cnf = 0;
+
 DROP TABLE IF EXISTS t0;
 
 CREATE TABLE t0
diff --git a/tests/queries/0_stateless/01415_overlimiting_threads_for_repica_bug.sql b/tests/queries/0_stateless/01415_overlimiting_threads_for_repica_bug.sql
index 306d94387a45..6b5c2ac8ffd2 100644
--- a/tests/queries/0_stateless/01415_overlimiting_threads_for_repica_bug.sql
+++ b/tests/queries/0_stateless/01415_overlimiting_threads_for_repica_bug.sql
@@ -1,5 +1,6 @@
 set log_queries = 1;
 set max_threads = 16;
+set prefer_localhost_replica = 1;
 
 select sum(number) from remote('127.0.0.{1|2}', numbers_mt(1000000)) group by number % 2 order by number % 2;
 
diff --git a/tests/queries/0_stateless/01457_create_as_table_function_structure.sql b/tests/queries/0_stateless/01457_create_as_table_function_structure.sql
index d7c681dc6158..bc677698d882 100644
--- a/tests/queries/0_stateless/01457_create_as_table_function_structure.sql
+++ b/tests/queries/0_stateless/01457_create_as_table_function_structure.sql
@@ -1,5 +1,7 @@
 -- Tags: no-parallel
 
+SET prefer_localhost_replica = 1;
+
 DROP DATABASE IF EXISTS test_01457;
 
 CREATE DATABASE test_01457;
diff --git a/tests/queries/0_stateless/01475_read_subcolumns.sql b/tests/queries/0_stateless/01475_read_subcolumns.sql
index fb26b19ed301..4724bec9eff2 100644
--- a/tests/queries/0_stateless/01475_read_subcolumns.sql
+++ b/tests/queries/0_stateless/01475_read_subcolumns.sql
@@ -1,4 +1,7 @@
 -- Tags: no-s3-storage
+
+SET use_uncompressed_cache = 0;
+
 SELECT '====array====';
 DROP TABLE IF EXISTS t_arr;
 CREATE TABLE t_arr (a Array(UInt32)) ENGINE = MergeTree ORDER BY tuple() SETTINGS min_bytes_for_wide_part = 0;
diff --git a/tests/queries/0_stateless/01517_select_final_distributed.sql b/tests/queries/0_stateless/01517_select_final_distributed.sql
index a3d1fcfc1851..701828b0b38f 100644
--- a/tests/queries/0_stateless/01517_select_final_distributed.sql
+++ b/tests/queries/0_stateless/01517_select_final_distributed.sql
@@ -1,5 +1,7 @@
 -- Tags: distributed
 
+SET allow_experimental_parallel_reading_from_replicas = 0;
+
 DROP TABLE IF EXISTS test5346;
 
 CREATE TABLE test5346 (`Id` String, `Timestamp` DateTime, `updated` DateTime) 
diff --git a/tests/queries/0_stateless/01533_multiple_nested.sql b/tests/queries/0_stateless/01533_multiple_nested.sql
index 40f287b4afd7..03724ce0b46e 100644
--- a/tests/queries/0_stateless/01533_multiple_nested.sql
+++ b/tests/queries/0_stateless/01533_multiple_nested.sql
@@ -3,6 +3,7 @@
 DROP TABLE IF EXISTS nested;
 
 SET flatten_nested = 0;
+SET use_uncompressed_cache = 0;
 
 CREATE TABLE nested
 (
diff --git a/tests/queries/0_stateless/01557_max_parallel_replicas_no_sample.sql b/tests/queries/0_stateless/01557_max_parallel_replicas_no_sample.sql
index 2b1a66147a4d..04777f5b31ce 100644
--- a/tests/queries/0_stateless/01557_max_parallel_replicas_no_sample.sql
+++ b/tests/queries/0_stateless/01557_max_parallel_replicas_no_sample.sql
@@ -1,5 +1,7 @@
 -- Tags: replica
 
+SET allow_experimental_parallel_reading_from_replicas=0;
+
 DROP TABLE IF EXISTS t;
 CREATE TABLE t (x String) ENGINE = MergeTree ORDER BY x;
 INSERT INTO t VALUES ('Hello');
diff --git a/tests/queries/0_stateless/01582_move_to_prewhere_compact_parts.sql b/tests/queries/0_stateless/01582_move_to_prewhere_compact_parts.sql
index 788c99da76dd..bd3e651e0dc5 100644
--- a/tests/queries/0_stateless/01582_move_to_prewhere_compact_parts.sql
+++ b/tests/queries/0_stateless/01582_move_to_prewhere_compact_parts.sql
@@ -1,3 +1,6 @@
+SET optimize_move_to_prewhere = 1;
+SET convert_query_to_cnf = 0;
+
 DROP TABLE IF EXISTS prewhere_move;
 CREATE TABLE prewhere_move (x Int, y String) ENGINE = MergeTree ORDER BY tuple();
 INSERT INTO prewhere_move SELECT number, toString(number) FROM numbers(1000);
diff --git a/tests/queries/0_stateless/01605_adaptive_granularity_block_borders.sql b/tests/queries/0_stateless/01605_adaptive_granularity_block_borders.sql
index a73045f5a6f5..9f26302e5641 100644
--- a/tests/queries/0_stateless/01605_adaptive_granularity_block_borders.sql
+++ b/tests/queries/0_stateless/01605_adaptive_granularity_block_borders.sql
@@ -1,3 +1,5 @@
+SET use_uncompressed_cache = 0;
+
 DROP TABLE IF EXISTS adaptive_table;
 
 --- If granularity of consequent blocks differs a lot, then adaptive
diff --git a/tests/queries/0_stateless/01655_plan_optimizations.sh b/tests/queries/0_stateless/01655_plan_optimizations.sh
index de3d3ac3eb6a..b66d788a3380 100755
--- a/tests/queries/0_stateless/01655_plan_optimizations.sh
+++ b/tests/queries/0_stateless/01655_plan_optimizations.sh
@@ -64,7 +64,7 @@ $CLICKHOUSE_CLIENT -q "
     settings enable_optimize_predicate_expression=0"
 
 echo "> one condition of filter should be pushed down after aggregating, other two conditions are ANDed"
-$CLICKHOUSE_CLIENT -q "
+$CLICKHOUSE_CLIENT --convert_query_to_cnf=0 -q "
     explain actions = 1 select s, y from (
         select sum(x) as s, y from (select number as x, number + 1 as y from numbers(10)) group by y
     ) where y != 0 and s - 8 and s - 4
@@ -77,7 +77,7 @@ $CLICKHOUSE_CLIENT -q "
     settings enable_optimize_predicate_expression=0"
 
 echo "> two conditions of filter should be pushed down after aggregating and ANDed, one condition is aliased"
-$CLICKHOUSE_CLIENT -q "
+$CLICKHOUSE_CLIENT --convert_query_to_cnf=0 -q "
     explain actions = 1 select s, y from (
         select sum(x) as s, y from (select number as x, number + 1 as y from numbers(10)) group by y
     ) where y != 0 and s != 8 and y - 4
@@ -127,7 +127,7 @@ $CLICKHOUSE_CLIENT -q "
     settings enable_optimize_predicate_expression=0"
 
 echo "> filter is pushed down before sorting steps"
-$CLICKHOUSE_CLIENT -q "
+$CLICKHOUSE_CLIENT --convert_query_to_cnf=0 -q "
     explain actions = 1 select x, y from (
         select number % 2 as x, number % 3 as y from numbers(6) order by y desc
     ) where x != 0 and y != 0
diff --git a/tests/queries/0_stateless/01666_blns_long.sql b/tests/queries/0_stateless/01666_blns_long.sql
index fd959cf0a738..74054551b189 100644
--- a/tests/queries/0_stateless/01666_blns_long.sql
+++ b/tests/queries/0_stateless/01666_blns_long.sql
@@ -27,6 +27,8 @@ OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 SOFTWARE.
 */
 
+SET max_insert_threads = 0;
+
 DROP TABLE IF EXISTS test;
 
 CREATE TABLE test
diff --git a/tests/queries/0_stateless/01671_aggregate_function_group_bitmap_data.sql b/tests/queries/0_stateless/01671_aggregate_function_group_bitmap_data.sql
index 3f5c5c2f25b6..d70665655ca3 100644
--- a/tests/queries/0_stateless/01671_aggregate_function_group_bitmap_data.sql
+++ b/tests/queries/0_stateless/01671_aggregate_function_group_bitmap_data.sql
@@ -1,3 +1,5 @@
+SET group_by_two_level_threshold = 10000;
+
 CREATE TABLE group_bitmap_data_test
 (
     `pickup_date` Date,
diff --git a/tests/queries/0_stateless/01737_move_order_key_to_prewhere_select_final.sql b/tests/queries/0_stateless/01737_move_order_key_to_prewhere_select_final.sql
index ecc11c625e31..789892dbd381 100644
--- a/tests/queries/0_stateless/01737_move_order_key_to_prewhere_select_final.sql
+++ b/tests/queries/0_stateless/01737_move_order_key_to_prewhere_select_final.sql
@@ -1,3 +1,6 @@
+SET optimize_move_to_prewhere = 1;
+SET convert_query_to_cnf = 0;
+
 DROP TABLE IF EXISTS prewhere_move_select_final;
 
 CREATE TABLE prewhere_move_select_final (x Int, y Int, z Int) ENGINE = ReplacingMergeTree() ORDER BY (x, y);
diff --git a/tests/queries/0_stateless/01746_long_zstd_http_compression_json_format.sh b/tests/queries/0_stateless/01746_long_zstd_http_compression_json_format.sh
index 02943cad5837..e10032e04fda 100755
--- a/tests/queries/0_stateless/01746_long_zstd_http_compression_json_format.sh
+++ b/tests/queries/0_stateless/01746_long_zstd_http_compression_json_format.sh
@@ -5,4 +5,4 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # shellcheck source=../shell_config.sh
 . "$CURDIR"/../shell_config.sh
 
-${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: zstd'              "${CLICKHOUSE_URL}&enable_http_compression=1" -d "SELECT toDate('2020-12-12') as datetime, 'test-pipeline' as pipeline, 'clickhouse-test-host-001.clickhouse.com' as host, 'clickhouse' as home, 'clickhouse' as detail, number as row_number FROM numbers(1000000) FORMAT JSON" | zstd -d | tail -n30 | head -n23
+${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: zstd'              "${CLICKHOUSE_URL}&enable_http_compression=1" -d "SELECT toDate('2020-12-12') as datetime, 'test-pipeline' as pipeline, 'clickhouse-test-host-001.clickhouse.com' as host, 'clickhouse' as home, 'clickhouse' as detail, number as row_number FROM numbers(1000000) SETTINGS max_block_size=65505 FORMAT JSON" | zstd -d | tail -n30 | head -n23
diff --git a/tests/queries/0_stateless/01763_max_distributed_depth.sql b/tests/queries/0_stateless/01763_max_distributed_depth.sql
index 12b2e3680075..f50d15e7121a 100644
--- a/tests/queries/0_stateless/01763_max_distributed_depth.sql
+++ b/tests/queries/0_stateless/01763_max_distributed_depth.sql
@@ -1,5 +1,7 @@
 -- Tags: distributed
 
+SET prefer_localhost_replica = 1;
+
 DROP TABLE IF EXISTS tt6;
 
 CREATE TABLE tt6
@@ -13,6 +15,8 @@ CREATE TABLE tt6
 )
 ENGINE = Distributed('test_shard_localhost', '', 'tt7', rand());
 
+DROP TABLE IF EXISTS tt7;
+
 CREATE TABLE tt7 as tt6 ENGINE = Distributed('test_shard_localhost', '', 'tt6', rand());
 
 INSERT INTO tt6 VALUES (1, 1, 1, 1, 'ok'); -- { serverError 581 }
@@ -28,3 +32,4 @@ INSERT INTO tt6 VALUES (1, 1, 1, 1, 'ok'); -- { serverError 306}
 SELECT * FROM tt6; -- { serverError 306 }
 
 DROP TABLE tt6;
+DROP TABLE tt7;
diff --git a/tests/queries/0_stateless/01786_explain_merge_tree.sh b/tests/queries/0_stateless/01786_explain_merge_tree.sh
index 6be86f9ce022..eb47f0650448 100755
--- a/tests/queries/0_stateless/01786_explain_merge_tree.sh
+++ b/tests/queries/0_stateless/01786_explain_merge_tree.sh
@@ -4,6 +4,8 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # shellcheck source=../shell_config.sh
 . "$CURDIR"/../shell_config.sh
 
+CLICKHOUSE_CLIENT="$CLICKHOUSE_CLIENT --optimize_move_to_prewhere=1 --convert_query_to_cnf=0"
+
 $CLICKHOUSE_CLIENT -q "drop table if exists test_index"
 $CLICKHOUSE_CLIENT -q "drop table if exists idx"
 
diff --git a/tests/queries/0_stateless/01798_uniq_theta_sketch.sql b/tests/queries/0_stateless/01798_uniq_theta_sketch.sql
index bb400c5de149..eace83d5cfa0 100644
--- a/tests/queries/0_stateless/01798_uniq_theta_sketch.sql
+++ b/tests/queries/0_stateless/01798_uniq_theta_sketch.sql
@@ -1,5 +1,7 @@
 -- Tags: no-fasttest
 
+SET max_block_size = 65505;
+
 SELECT 'uniqTheta many agrs';
 
 SELECT
diff --git a/tests/queries/0_stateless/01822_short_circuit.sql b/tests/queries/0_stateless/01822_short_circuit.sql
index 48fff04921b2..c7379d210eba 100644
--- a/tests/queries/0_stateless/01822_short_circuit.sql
+++ b/tests/queries/0_stateless/01822_short_circuit.sql
@@ -1,4 +1,5 @@
 set short_circuit_function_evaluation = 'enable';
+set convert_query_to_cnf = 0;
 
 select if(number > 0, intDiv(number + 100, number), throwIf(number)) from numbers(10);
 select multiIf(number == 0, 0, number == 1, intDiv(1, number), number == 2, intDiv(1, number - 1), number == 3, intDiv(1, number - 2), intDiv(1, number - 3)) from numbers(10);
diff --git a/tests/queries/0_stateless/01824_move_to_prewhere_many_columns.sql b/tests/queries/0_stateless/01824_move_to_prewhere_many_columns.sql
index e03972e818d2..c4ef5516fc83 100644
--- a/tests/queries/0_stateless/01824_move_to_prewhere_many_columns.sql
+++ b/tests/queries/0_stateless/01824_move_to_prewhere_many_columns.sql
@@ -1,3 +1,6 @@
+SET optimize_move_to_prewhere = 1;
+SET convert_query_to_cnf = 0;
+
 DROP TABLE IF EXISTS t_move_to_prewhere;
 
 CREATE TABLE t_move_to_prewhere (id UInt32, a UInt8, b UInt8, c UInt8, fat_string String)
diff --git a/tests/queries/0_stateless/01917_prewhere_column_type.sql b/tests/queries/0_stateless/01917_prewhere_column_type.sql
index 5147e6093a95..c0bc0c3e36b8 100644
--- a/tests/queries/0_stateless/01917_prewhere_column_type.sql
+++ b/tests/queries/0_stateless/01917_prewhere_column_type.sql
@@ -1,3 +1,5 @@
+SET optimize_move_to_prewhere = 1;
+
 DROP TABLE IF EXISTS t1;
 
 CREATE TABLE t1 ( s String, f Float32, e UInt16 ) ENGINE = MergeTree ORDER BY tuple() SETTINGS min_bytes_for_wide_part = '100G';
diff --git a/tests/queries/0_stateless/01943_query_id_check.sql b/tests/queries/0_stateless/01943_query_id_check.sql
index cb2ef0908540..ad9e88e04781 100644
--- a/tests/queries/0_stateless/01943_query_id_check.sql
+++ b/tests/queries/0_stateless/01943_query_id_check.sql
@@ -1,6 +1,8 @@
 -- Tags: no-replicated-database
 -- Tag no-replicated-database: Different query_id
 
+SET prefer_localhost_replica = 1;
+
 DROP TABLE IF EXISTS tmp;
 
 CREATE TABLE tmp ENGINE = TinyLog AS SELECT queryID();
diff --git a/tests/queries/0_stateless/01951_distributed_push_down_limit.sql b/tests/queries/0_stateless/01951_distributed_push_down_limit.sql
index fa2fc1800c12..184e63219881 100644
--- a/tests/queries/0_stateless/01951_distributed_push_down_limit.sql
+++ b/tests/queries/0_stateless/01951_distributed_push_down_limit.sql
@@ -1,5 +1,7 @@
 -- Tags: distributed
 
+set prefer_localhost_replica = 1;
+
 -- { echo }
 explain select * from remote('127.{1,2}', view(select * from numbers(1e6))) order by number limit 10 settings distributed_push_down_limit=0;
 explain select * from remote('127.{1,2}', view(select * from numbers(1e6))) order by number limit 10 settings distributed_push_down_limit=1;
diff --git a/tests/queries/0_stateless/01952_optimize_distributed_group_by_sharding_key.sql b/tests/queries/0_stateless/01952_optimize_distributed_group_by_sharding_key.sql
index d1f80b42e756..74b55b953155 100644
--- a/tests/queries/0_stateless/01952_optimize_distributed_group_by_sharding_key.sql
+++ b/tests/queries/0_stateless/01952_optimize_distributed_group_by_sharding_key.sql
@@ -2,6 +2,7 @@
 
 set optimize_skip_unused_shards=1;
 set optimize_distributed_group_by_sharding_key=1;
+set prefer_localhost_replica=1;
 
 -- { echo }
 explain select distinct k1 from remote('127.{1,2}', view(select 1 k1, 2 k2, 3 v from numbers(2)), cityHash64(k1, k2)); -- not optimized
diff --git a/tests/queries/0_stateless/02006_test_positional_arguments.sql b/tests/queries/0_stateless/02006_test_positional_arguments.sql
index 54b55c4a9f87..7442ca6bbf64 100644
--- a/tests/queries/0_stateless/02006_test_positional_arguments.sql
+++ b/tests/queries/0_stateless/02006_test_positional_arguments.sql
@@ -1,3 +1,4 @@
+set group_by_two_level_threshold = 100000;
 set enable_positional_arguments = 1;
 
 drop table if exists test;
diff --git a/tests/queries/0_stateless/02030_tuple_filter.sql b/tests/queries/0_stateless/02030_tuple_filter.sql
index 5efedeb8c0d5..c19f538b8e13 100644
--- a/tests/queries/0_stateless/02030_tuple_filter.sql
+++ b/tests/queries/0_stateless/02030_tuple_filter.sql
@@ -5,6 +5,7 @@ CREATE TABLE test_tuple_filter (id UInt32, value String, log_date Date) Engine=M
 INSERT INTO test_tuple_filter VALUES (1,'A','2021-01-01'),(2,'B','2021-01-01'),(3,'C','2021-01-01'),(4,'D','2021-01-02'),(5,'E','2021-01-02');
 
 SET force_primary_key = 1;
+SET optimize_move_to_prewhere = 1;
 
 SELECT * FROM test_tuple_filter WHERE (id, value) = (1, 'A');
 SELECT * FROM test_tuple_filter WHERE (1, 'A') = (id, value);
diff --git a/tests/queries/0_stateless/02050_client_profile_events.sh b/tests/queries/0_stateless/02050_client_profile_events.sh
index 459e8505e22d..f8bcea0d1bbc 100755
--- a/tests/queries/0_stateless/02050_client_profile_events.sh
+++ b/tests/queries/0_stateless/02050_client_profile_events.sh
@@ -7,7 +7,7 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # do not print any ProfileEvents packets
 $CLICKHOUSE_CLIENT -q 'select * from numbers(1e5) format Null' |& grep -c 'SelectedRows'
 # print only last (and also number of rows to provide more info in case of failures)
-$CLICKHOUSE_CLIENT --print-profile-events --profile-events-delay-ms=-1 -q 'select * from numbers(1e5)' 2> >(grep -o -e '\[ 0 \] SelectedRows: .*$' -e Exception) 1> >(wc -l)
+$CLICKHOUSE_CLIENT --max_block_size=65505 --print-profile-events --profile-events-delay-ms=-1 -q 'select * from numbers(1e5)' 2> >(grep -o -e '\[ 0 \] SelectedRows: .*$' -e Exception) 1> >(wc -l)
 # print everything
 profile_events="$($CLICKHOUSE_CLIENT --max_block_size 1 --print-profile-events -q 'select sleep(1) from numbers(2) format Null' |& grep -c 'SelectedRows')"
 test "$profile_events" -gt 1 && echo OK || echo "FAIL ($profile_events)"
diff --git a/tests/queries/0_stateless/02131_multiply_row_policies_on_same_column.sql b/tests/queries/0_stateless/02131_multiply_row_policies_on_same_column.sql
index 75f7f737e858..d0a55c6ba65b 100644
--- a/tests/queries/0_stateless/02131_multiply_row_policies_on_same_column.sql
+++ b/tests/queries/0_stateless/02131_multiply_row_policies_on_same_column.sql
@@ -1,3 +1,5 @@
+SET optimize_move_to_prewhere = 1;
+
 DROP TABLE IF EXISTS 02131_multiply_row_policies_on_same_column;
 CREATE TABLE 02131_multiply_row_policies_on_same_column (x UInt8) ENGINE = MergeTree ORDER BY x;
 INSERT INTO 02131_multiply_row_policies_on_same_column VALUES (1), (2), (3), (4);
diff --git a/tests/queries/0_stateless/02136_scalar_progress.sh b/tests/queries/0_stateless/02136_scalar_progress.sh
index 4608031f83d7..9f4429b0caaf 100755
--- a/tests/queries/0_stateless/02136_scalar_progress.sh
+++ b/tests/queries/0_stateless/02136_scalar_progress.sh
@@ -4,4 +4,4 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # shellcheck source=../shell_config.sh
 . "$CURDIR"/../shell_config.sh
 
-$CLICKHOUSE_CURL -sS "${CLICKHOUSE_URL}&wait_end_of_query=1&send_progress_in_http_headers=1&http_headers_progress_interval_ms=0" -d "SELECT (SELECT max(number), count(number) FROM numbers(100000));" -v 2>&1 | grep -E "X-ClickHouse-Summary|X-ClickHouse-Progress"
+$CLICKHOUSE_CURL -sS "${CLICKHOUSE_URL}&wait_end_of_query=1&send_progress_in_http_headers=1&http_headers_progress_interval_ms=0" -d "SELECT (SELECT max(number), count(number) FROM numbers(100000) settings max_block_size=65505);" -v 2>&1 | grep -E "X-ClickHouse-Summary|X-ClickHouse-Progress"
diff --git a/tests/queries/0_stateless/02136_scalar_read_rows_json.sh b/tests/queries/0_stateless/02136_scalar_read_rows_json.sh
index d589cb600868..34b4b6909b5c 100755
--- a/tests/queries/0_stateless/02136_scalar_read_rows_json.sh
+++ b/tests/queries/0_stateless/02136_scalar_read_rows_json.sh
@@ -7,4 +7,4 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 echo "#1"
 ${CLICKHOUSE_CLIENT} --query='SELECT count() FROM numbers(100) FORMAT JSON;' | grep -a -v "elapsed"
 echo "#2"
-${CLICKHOUSE_CLIENT} --query='SELECT (SELECT max(number), count(number) FROM numbers(100000) as n) FORMAT JSON;' | grep -a -v "elapsed" | grep -v "_subquery"
+${CLICKHOUSE_CLIENT} --query='SELECT (SELECT max(number), count(number) FROM numbers(100000) as n) SETTINGS max_block_size = 65505 FORMAT JSON;' | grep -a -v "elapsed" | grep -v "_subquery"
diff --git a/tests/queries/0_stateless/02156_storage_merge_prewhere.sql b/tests/queries/0_stateless/02156_storage_merge_prewhere.sql
index 69fa9ac5ee2c..b75d3fa22e58 100644
--- a/tests/queries/0_stateless/02156_storage_merge_prewhere.sql
+++ b/tests/queries/0_stateless/02156_storage_merge_prewhere.sql
@@ -1,3 +1,5 @@
+SET optimize_move_to_prewhere = 1;
+
 DROP TABLE IF EXISTS t_02156_mt1;
 DROP TABLE IF EXISTS t_02156_mt2;
 DROP TABLE IF EXISTS t_02156_log;
diff --git a/tests/queries/1_stateful/00084_external_aggregation.sql b/tests/queries/1_stateful/00084_external_aggregation.sql
index b3922eae0494..816d95f4b8b3 100644
--- a/tests/queries/1_stateful/00084_external_aggregation.sql
+++ b/tests/queries/1_stateful/00084_external_aggregation.sql
@@ -1,3 +1,5 @@
+-- Tags: no-random-settings
+
 SET max_bytes_before_external_group_by = 200000000;
 
 SET max_memory_usage = 1500000000;
diff --git a/tests/queries/1_stateful/00154_avro.sql b/tests/queries/1_stateful/00154_avro.sql
index ea5d665a3b45..f608da629d2d 100644
--- a/tests/queries/1_stateful/00154_avro.sql
+++ b/tests/queries/1_stateful/00154_avro.sql
@@ -2,7 +2,7 @@
 
 DROP TABLE IF EXISTS test.avro;
 
-SET max_threads = 1, max_block_size = 8192, min_insert_block_size_rows = 8192, min_insert_block_size_bytes = 1048576; -- lower memory usage
+SET max_threads = 1, max_insert_threads = 0, max_block_size = 8192, min_insert_block_size_rows = 8192, min_insert_block_size_bytes = 1048576; -- lower memory usage
 
 CREATE TABLE test.avro AS test.hits ENGINE = File(Avro);
 INSERT INTO test.avro SELECT * FROM test.hits LIMIT 10000;
diff --git a/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh
index 699700bcd3e5..276fc0274c2b 100755
--- a/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh
+++ b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh
@@ -1,5 +1,5 @@
 #!/usr/bin/env bash
-# Tags: no-tsan
+# Tags: no-tsan, no-random-settings
 
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 # shellcheck source=../shell_config.sh
