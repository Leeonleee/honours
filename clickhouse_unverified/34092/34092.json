{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 34092,
  "instance_id": "ClickHouse__ClickHouse-34092",
  "issue_numbers": [
    "32268"
  ],
  "base_commit": "c48c13601dd84eee70cfd0904827ff9859076b1a",
  "patch": "diff --git a/programs/client/Client.cpp b/programs/client/Client.cpp\nindex 26b4f5d018a6..a3f5c0ab1c71 100644\n--- a/programs/client/Client.cpp\n+++ b/programs/client/Client.cpp\n@@ -1126,7 +1126,12 @@ void Client::processOptions(const OptionsDescription & options_description,\n     {\n         const auto & name = setting.getName();\n         if (options.count(name))\n-            config().setString(name, options[name].as<String>());\n+        {\n+            if (allow_repeated_settings)\n+                config().setString(name, options[name].as<Strings>().back());\n+            else\n+                config().setString(name, options[name].as<String>());\n+        }\n     }\n \n     if (options.count(\"config-file\") && options.count(\"config\"))\ndiff --git a/src/Client/ClientBase.cpp b/src/Client/ClientBase.cpp\nindex a9529c706bd8..f89e3504c442 100644\n--- a/src/Client/ClientBase.cpp\n+++ b/src/Client/ClientBase.cpp\n@@ -1872,6 +1872,8 @@ void ClientBase::readArguments(\n                     prev_port_arg = port_arg;\n                 }\n             }\n+            else if (arg == \"--allow_repeated_settings\"sv)\n+                allow_repeated_settings = true;\n             else\n                 common_arguments.emplace_back(arg);\n         }\n@@ -1884,7 +1886,10 @@ void ClientBase::readArguments(\n \n void ClientBase::parseAndCheckOptions(OptionsDescription & options_description, po::variables_map & options, Arguments & arguments)\n {\n-    cmd_settings.addProgramOptions(options_description.main_description.value());\n+    if (allow_repeated_settings)\n+        cmd_settings.addProgramOptionsAsMultitokens(options_description.main_description.value());\n+    else\n+        cmd_settings.addProgramOptions(options_description.main_description.value());\n     /// Parse main commandline options.\n     auto parser = po::command_line_parser(arguments).options(options_description.main_description.value()).allow_unregistered();\n     po::parsed_options parsed = parser.run();\ndiff --git a/src/Client/ClientBase.h b/src/Client/ClientBase.h\nindex a92888868a4c..406e5aa66b7a 100644\n--- a/src/Client/ClientBase.h\n+++ b/src/Client/ClientBase.h\n@@ -260,6 +260,8 @@ class ClientBase : public Poco::Util::Application, public IHints<2, ClientBase>\n \n     std::vector<HostAndPort> hosts_and_ports{};\n \n+    bool allow_repeated_settings = false;\n+\n     bool cancelled = false;\n };\n \ndiff --git a/src/Core/Settings.cpp b/src/Core/Settings.cpp\nindex 87d7eee0daa2..411e73bdf1a0 100644\n--- a/src/Core/Settings.cpp\n+++ b/src/Core/Settings.cpp\n@@ -89,6 +89,14 @@ void Settings::addProgramOptions(boost::program_options::options_description & o\n     }\n }\n \n+void Settings::addProgramOptionsAsMultitokens(boost::program_options::options_description & options)\n+{\n+    for (const auto & field : all())\n+    {\n+        addProgramOptionAsMultitoken(options, field);\n+    }\n+}\n+\n void Settings::addProgramOption(boost::program_options::options_description & options, const SettingFieldRef & field)\n {\n     const std::string_view name = field.getName();\n@@ -97,6 +105,14 @@ void Settings::addProgramOption(boost::program_options::options_description & op\n         name.data(), boost::program_options::value<std::string>()->composing()->notifier(on_program_option), field.getDescription())));\n }\n \n+void Settings::addProgramOptionAsMultitoken(boost::program_options::options_description & options, const SettingFieldRef & field)\n+{\n+    const std::string_view name = field.getName();\n+    auto on_program_option = boost::function1<void, const Strings &>([this, name](const Strings & values) { set(name, values.back()); });\n+    options.add(boost::shared_ptr<boost::program_options::option_description>(new boost::program_options::option_description(\n+        name.data(), boost::program_options::value<Strings>()->multitoken()->composing()->notifier(on_program_option), field.getDescription())));\n+}\n+\n void Settings::checkNoSettingNamesAtTopLevel(const Poco::Util::AbstractConfiguration & config, const String & config_path)\n {\n     if (config.getBool(\"skip_check_for_incorrect_settings\", false))\ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex 987d8e5edd2e..5280e4b3eeb6 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -722,6 +722,11 @@ struct Settings : public BaseSettings<SettingsTraits>, public IHints<2, Settings\n     /// (Don't forget to call notify() on the `variables_map` after parsing it!)\n     void addProgramOptions(boost::program_options::options_description & options);\n \n+    /// Adds program options as to set the settings from a command line.\n+    /// Allows to set one setting multiple times, the last value will be used.\n+    /// (Don't forget to call notify() on the `variables_map` after parsing it!)\n+    void addProgramOptionsAsMultitokens(boost::program_options::options_description & options);\n+\n     /// Check that there is no user-level settings at the top level in config.\n     /// This is a common source of mistake (user don't know where to write user-level setting).\n     static void checkNoSettingNamesAtTopLevel(const Poco::Util::AbstractConfiguration & config, const String & config_path);\n@@ -729,6 +734,8 @@ struct Settings : public BaseSettings<SettingsTraits>, public IHints<2, Settings\n     std::vector<String> getAllRegisteredNames() const override;\n \n     void addProgramOption(boost::program_options::options_description & options, const SettingFieldRef & field);\n+\n+    void addProgramOptionAsMultitoken(boost::program_options::options_description & options, const SettingFieldRef & field);\n };\n \n /*\n",
  "test_patch": "diff --git a/tests/clickhouse-test b/tests/clickhouse-test\nindex abf251b1f39c..4c94e4d64937 100755\n--- a/tests/clickhouse-test\n+++ b/tests/clickhouse-test\n@@ -337,6 +337,26 @@ class FailureReason(enum.Enum):\n     INTERNAL_ERROR = \"Test internal error: \"\n \n \n+class SettingsRandomizer:\n+    settings = {\n+        \"max_insert_threads\": lambda: 0 if random.random() < 0.5 else random.randint(1, 16),\n+        \"group_by_two_level_threshold\": lambda: 1 if random.random() < 0.1 else 2 ** 60 if random.random() < 0.11 else 100000,\n+        \"group_by_two_level_threshold_bytes\": lambda: 1 if random.random() < 0.1 else 2 ** 60 if random.random() < 0.11 else 50000000,\n+        \"distributed_aggregation_memory_efficient\": lambda: random.randint(0, 1),\n+        \"fsync_metadata\": lambda: random.randint(0, 1),\n+        \"priority\": lambda: int(abs(random.gauss(0, 2))),\n+        \"output_format_parallel_formatting\": lambda: random.randint(0, 1),\n+        \"input_format_parallel_parsing\": lambda: random.randint(0, 1),\n+    }\n+\n+    @staticmethod\n+    def get_random_settings():\n+        random_settings = []\n+        for setting, generator in SettingsRandomizer.settings.items():\n+            random_settings.append(setting + \"=\" + str(generator()) + \"\")\n+        return random_settings\n+\n+\n class TestResult:\n     def __init__(self, case_name: str, status: TestStatus, reason: Optional[FailureReason], total_time: float, description: str):\n         self.case_name: str = case_name\n@@ -417,6 +437,29 @@ class TestCase:\n \n         return testcase_args\n \n+    def add_random_settings(self, client_options):\n+        if self.tags and 'no-random-settings' in self.tags:\n+            return client_options\n+\n+        if len(self.base_url_params) == 0:\n+            os.environ['CLICKHOUSE_URL_PARAMS'] = '&'.join(self.random_settings)\n+        else:\n+            os.environ['CLICKHOUSE_URL_PARAMS'] = self.base_url_params + '&' + '&'.join(self.random_settings)\n+\n+        new_options = \"--allow_repeated_settings --\" + \" --\".join(self.random_settings)\n+        os.environ['CLICKHOUSE_CLIENT_OPT'] = self.base_client_options + new_options + ' '\n+        return client_options + new_options\n+\n+    def remove_random_settings_from_env(self):\n+        os.environ['CLICKHOUSE_URL_PARAMS'] = self.base_url_params\n+        os.environ['CLICKHOUSE_CLIENT_OPT'] = self.base_client_options\n+\n+    def add_info_about_settings(self, description):\n+        if self.tags and 'no-random-settings' in self.tags:\n+            return description\n+\n+        return description + \"\\n\" + \"Settings used in the test: \" + \"--\" + \" --\".join(self.random_settings) + \"\\n\"\n+\n     def __init__(self, suite, case: str, args, is_concurrent: bool):\n         self.case: str = case   # case file name\n         self.tags: Set[str] = suite.all_tags[case] if case in suite.all_tags else set()\n@@ -432,6 +475,10 @@ class TestCase:\n         self.testcase_args = None\n         self.runs_count = 0\n \n+        self.random_settings = SettingsRandomizer.get_random_settings()\n+        self.base_url_params = os.environ['CLICKHOUSE_URL_PARAMS'] if 'CLICKHOUSE_URL_PARAMS' in os.environ else ''\n+        self.base_client_options = os.environ['CLICKHOUSE_CLIENT_OPT'] if 'CLICKHOUSE_CLIENT_OPT' in os.environ else ''\n+\n     # should skip test, should increment skipped_total, skip reason\n     def should_skip_test(self, suite) -> Optional[FailureReason]:\n         tags = self.tags\n@@ -673,10 +720,13 @@ class TestCase:\n \n             self.runs_count += 1\n             self.testcase_args = self.configure_testcase_args(args, self.case_file, suite.suite_tmp_path)\n+            client_options = self.add_random_settings(client_options)\n             proc, stdout, stderr, total_time = self.run_single_test(server_logs_level, client_options)\n \n             result = self.process_result_impl(proc, stdout, stderr, total_time)\n             result.check_if_need_retry(args, stdout, stderr, self.runs_count)\n+            if result.status == TestStatus.FAIL:\n+                result.description = self.add_info_about_settings(result.description)\n             return result\n         except KeyboardInterrupt as e:\n             raise e\n@@ -684,17 +734,20 @@ class TestCase:\n             return TestResult(self.name, TestStatus.FAIL,\n                               FailureReason.INTERNAL_QUERY_FAIL,\n                               0.,\n-                              self.get_description_from_exception_info(sys.exc_info()))\n+                              self.add_info_about_settings(self.get_description_from_exception_info(sys.exc_info())))\n         except (ConnectionRefusedError, ConnectionResetError):\n             return TestResult(self.name, TestStatus.FAIL,\n                               FailureReason.SERVER_DIED,\n                               0.,\n-                              self.get_description_from_exception_info(sys.exc_info()))\n+                              self.add_info_about_settings(self.get_description_from_exception_info(sys.exc_info())))\n         except:\n             return TestResult(self.name, TestStatus.UNKNOWN,\n                               FailureReason.INTERNAL_ERROR,\n                               0.,\n                               self.get_description_from_exception_info(sys.exc_info()))\n+        finally:\n+            self.remove_random_settings_from_env()\n+\n \n class TestSuite:\n     @staticmethod\ndiff --git a/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql b/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql\nindex f9cbf92db41f..e29a166c1eed 100644\n--- a/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql\n+++ b/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql\n@@ -1,5 +1,6 @@\n -- Tags: replica, distributed\n \n+SET allow_experimental_parallel_reading_from_replicas = 0;\n SET max_parallel_replicas = 2;\n DROP TABLE IF EXISTS report;\n \ndiff --git a/tests/queries/0_stateless/00474_readonly_settings.reference b/tests/queries/0_stateless/00474_readonly_settings.reference\nindex b1da40ce414d..e2b45931965f 100644\n--- a/tests/queries/0_stateless/00474_readonly_settings.reference\n+++ b/tests/queries/0_stateless/00474_readonly_settings.reference\n@@ -2,13 +2,11 @@\n \t\t\t\"value\": 4611686018427387904\n \t\t\t\"name\": \"value\",\n \t\t\t\"value\": \"4611686018427387904\"\n-value\n-value\n-Cannot modify 'output_format_json_quote_64bit_integers' setting in readonly mode\n+OK\n+OK\n \t\t\t\"name\": \"value\",\n \t\t\t\"value\": \"9223372036854775808\"\n \t\t\t\"name\": \"value\",\n \t\t\t\"value\": 9223372036854775808\n-value\n-value\n-Cannot modify 'output_format_json_quote_64bit_integers' setting in readonly mode\n+OK\n+OK\ndiff --git a/tests/queries/0_stateless/00474_readonly_settings.sh b/tests/queries/0_stateless/00474_readonly_settings.sh\nindex 0887ecfa14e4..07b78c64a7ea 100755\n--- a/tests/queries/0_stateless/00474_readonly_settings.sh\n+++ b/tests/queries/0_stateless/00474_readonly_settings.sh\n@@ -9,13 +9,15 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n $CLICKHOUSE_CLIENT --query=\"select toUInt64(pow(2, 62)) as value format JSON\" --output_format_json_quote_64bit_integers=0 | grep value\n $CLICKHOUSE_CLIENT --query=\"select toUInt64(pow(2, 62)) as value format JSON\" --output_format_json_quote_64bit_integers=1 | grep value\n \n-$CLICKHOUSE_CLIENT --readonly=1 --multiquery --query=\"set output_format_json_quote_64bit_integers=1 ; select toUInt64(pow(2, 63)) as value format JSON\" --server_logs_file=/dev/null 2>&1 | grep -o 'value\\|Cannot modify .* setting in readonly mode'\n-$CLICKHOUSE_CLIENT --readonly=1 --multiquery --query=\"set output_format_json_quote_64bit_integers=0 ; select toUInt64(pow(2, 63)) as value format JSON\" --server_logs_file=/dev/null 2>&1 | grep -o 'value\\|Cannot modify .* setting in readonly mode'\n+$CLICKHOUSE_CLIENT --readonly=1 --multiquery --query=\"set output_format_json_quote_64bit_integers=1 ; select toUInt64(pow(2, 63)) as value format JSON\" --server_logs_file=/dev/null 2>&1 | grep -o -q 'value\\|Cannot modify .* setting in readonly mode' && echo \"OK\" || echo \"FAIL\"\n+$CLICKHOUSE_CLIENT --readonly=1 --multiquery --query=\"set output_format_json_quote_64bit_integers=0 ; select toUInt64(pow(2, 63)) as value format JSON\" --server_logs_file=/dev/null 2>&1 | grep -o -q 'value\\|Cannot modify .* setting in readonly mode' && echo \"OK\" || echo \"FAIL\"\n+\n \n ${CLICKHOUSE_CURL} -sS \"${CLICKHOUSE_URL}&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=1\" | grep value\n ${CLICKHOUSE_CURL} -sS \"${CLICKHOUSE_URL}&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=0\" | grep value\n \n-${CLICKHOUSE_CURL} -sS \"${CLICKHOUSE_URL}&session_id=readonly&session_timeout=3600\" -d 'SET readonly = 1'\n+#${CLICKHOUSE_CURL} -sS \"${CLICKHOUSE_URL}&session_id=readonly&session_timeout=3600\" -d 'SET readonly = 1'\n+\n+${CLICKHOUSE_CURL} -sS \"${CLICKHOUSE_URL}&session_id=readonly&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=1\" 2>&1 | grep -o -q 'value\\|Cannot modify .* setting in readonly mode.' && echo \"OK\" || echo \"FAIL\"\n+${CLICKHOUSE_CURL} -sS \"${CLICKHOUSE_URL}&session_id=readonly&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=0\" 2>&1 | grep -o -q 'value\\|Cannot modify .* setting in readonly mode' && echo \"OK\" || echo \"FAIL\"\n \n-${CLICKHOUSE_CURL} -sS \"${CLICKHOUSE_URL}&session_id=readonly&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=1\" 2>&1 | grep -o 'value\\|Cannot modify .* setting in readonly mode.'\n-${CLICKHOUSE_CURL} -sS \"${CLICKHOUSE_URL}&session_id=readonly&query=SELECT+toUInt64(pow(2,+63))+as+value+format+JSON&output_format_json_quote_64bit_integers=0\" 2>&1 | grep -o 'value\\|Cannot modify .* setting in readonly mode'\ndiff --git a/tests/queries/0_stateless/00808_not_optimize_predicate.sql b/tests/queries/0_stateless/00808_not_optimize_predicate.sql\nindex 7c1e57706e27..ba8f5eb57535 100644\n--- a/tests/queries/0_stateless/00808_not_optimize_predicate.sql\n+++ b/tests/queries/0_stateless/00808_not_optimize_predicate.sql\n@@ -1,4 +1,5 @@\n SET send_logs_level = 'fatal';\n+SET convert_query_to_cnf = 0;\n \n DROP TABLE IF EXISTS test_00808;\n CREATE TABLE test_00808(date Date, id Int8, name String, value Int64, sign Int8) ENGINE = CollapsingMergeTree(sign) ORDER BY (id, date);\ndiff --git a/tests/queries/0_stateless/00826_cross_to_inner_join.sql b/tests/queries/0_stateless/00826_cross_to_inner_join.sql\nindex 392ade02ab78..ce0c8ea2bfc0 100644\n--- a/tests/queries/0_stateless/00826_cross_to_inner_join.sql\n+++ b/tests/queries/0_stateless/00826_cross_to_inner_join.sql\n@@ -1,4 +1,6 @@\n SET enable_optimize_predicate_expression = 0;\n+SET optimize_move_to_prewhere = 1;\n+SET convert_query_to_cnf = 0;\n \n select * from system.one l cross join system.one r;\n \ndiff --git a/tests/queries/0_stateless/00849_multiple_comma_join_2.sql b/tests/queries/0_stateless/00849_multiple_comma_join_2.sql\nindex 58535f556d97..eabede3ff002 100644\n--- a/tests/queries/0_stateless/00849_multiple_comma_join_2.sql\n+++ b/tests/queries/0_stateless/00849_multiple_comma_join_2.sql\n@@ -1,4 +1,5 @@\n SET enable_optimize_predicate_expression = 0;\n+SET convert_query_to_cnf = 0;\n \n DROP TABLE IF EXISTS t1;\n DROP TABLE IF EXISTS t2;\ndiff --git a/tests/queries/0_stateless/00965_shard_unresolvable_addresses.sql b/tests/queries/0_stateless/00965_shard_unresolvable_addresses.sql\nindex 0d82519e4d30..555e7a983809 100644\n--- a/tests/queries/0_stateless/00965_shard_unresolvable_addresses.sql\n+++ b/tests/queries/0_stateless/00965_shard_unresolvable_addresses.sql\n@@ -1,5 +1,7 @@\n -- Tags: shard\n \n+SET prefer_localhost_replica = 1;\n+\n SELECT count() FROM remote('127.0.0.1,localhos', system.one); -- { serverError 198 }\n SELECT count() FROM remote('127.0.0.1|localhos', system.one);\n \ndiff --git a/tests/queries/0_stateless/01010_pmj_right_table_memory_limits.sql b/tests/queries/0_stateless/01010_pmj_right_table_memory_limits.sql\nindex af747c936781..7804ce32a5ac 100644\n--- a/tests/queries/0_stateless/01010_pmj_right_table_memory_limits.sql\n+++ b/tests/queries/0_stateless/01010_pmj_right_table_memory_limits.sql\n@@ -1,4 +1,4 @@\n--- Tags: no-parallel, no-fasttest\n+-- Tags: no-parallel, no-fasttest, no-random-settings\n \n SET max_memory_usage = 32000000;\n SET join_on_disk_max_files_to_merge = 4;\ndiff --git a/tests/queries/0_stateless/01017_uniqCombined_memory_usage.sql b/tests/queries/0_stateless/01017_uniqCombined_memory_usage.sql\nindex d47dc6b8d5fa..69bd15e3f542 100644\n--- a/tests/queries/0_stateless/01017_uniqCombined_memory_usage.sql\n+++ b/tests/queries/0_stateless/01017_uniqCombined_memory_usage.sql\n@@ -1,4 +1,4 @@\n--- Tags: no-tsan, no-asan, no-msan, no-replicated-database\n+-- Tags: no-tsan, no-asan, no-msan, no-replicated-database, no-random-settings\n -- Tag no-tsan: Fine thresholds on memory usage\n -- Tag no-asan: Fine thresholds on memory usage\n -- Tag no-msan: Fine thresholds on memory usage\n@@ -7,6 +7,8 @@\n -- sizeof(HLL) is (2^K * 6 / 8)\n -- hence max_memory_usage for 100 rows = (96<<10)*100 = 9830400\n \n+SET use_uncompressed_cache = 0; \n+\n -- HashTable for UInt32 (used until (1<<13) elements), hence 8192 elements\n SELECT 'UInt32';\n SET max_memory_usage = 4000000;\n@@ -19,6 +21,8 @@ SELECT 'UInt64';\n SET max_memory_usage = 4000000;\n SELECT sum(u) FROM (SELECT intDiv(number, 4096) AS k, uniqCombined(reinterpretAsString(number % 4096)) u FROM numbers(4096 * 100) GROUP BY k); -- { serverError 241 }\n SET max_memory_usage = 9830400;\n+\n+\n SELECT sum(u) FROM (SELECT intDiv(number, 4096) AS k, uniqCombined(reinterpretAsString(number % 4096)) u FROM numbers(4096 * 100) GROUP BY k);\n \n SELECT 'K=16';\ndiff --git a/tests/queries/0_stateless/01034_prewhere_max_parallel_replicas_distributed.sql b/tests/queries/0_stateless/01034_prewhere_max_parallel_replicas_distributed.sql\nindex 4eea4fd47c7e..6d1c7fd5ef6a 100644\n--- a/tests/queries/0_stateless/01034_prewhere_max_parallel_replicas_distributed.sql\n+++ b/tests/queries/0_stateless/01034_prewhere_max_parallel_replicas_distributed.sql\n@@ -1,5 +1,7 @@\n -- Tags: replica, distributed\n \n+set allow_experimental_parallel_reading_from_replicas=0;\n+\n drop table if exists test_max_parallel_replicas_lr;\n \n -- If you wonder why the table is named with \"_lr\" suffix in this test.\ndiff --git a/tests/queries/0_stateless/01034_sample_final_distributed.sql b/tests/queries/0_stateless/01034_sample_final_distributed.sql\nindex b784b35cbb33..a81fef645dbd 100644\n--- a/tests/queries/0_stateless/01034_sample_final_distributed.sql\n+++ b/tests/queries/0_stateless/01034_sample_final_distributed.sql\n@@ -1,5 +1,7 @@\n -- Tags: distributed\n \n+set allow_experimental_parallel_reading_from_replicas = 0;\n+\n drop table if exists sample_final;\n create table sample_final (CounterID UInt32, EventDate Date, EventTime DateTime, UserID UInt64, Sign Int8) engine = CollapsingMergeTree(Sign) order by (CounterID, EventDate, intHash32(UserID), EventTime) sample by intHash32(UserID);\n insert into sample_final select number / (8192 * 4), toDate('2019-01-01'), toDateTime('2019-01-01 00:00:01') + number, number / (8192 * 2), number % 3 = 1 ? -1 : 1 from numbers(1000000);\ndiff --git a/tests/queries/0_stateless/01056_predicate_optimizer_bugs.sql b/tests/queries/0_stateless/01056_predicate_optimizer_bugs.sql\nindex d59b8fc30ace..6d2bb2964d64 100644\n--- a/tests/queries/0_stateless/01056_predicate_optimizer_bugs.sql\n+++ b/tests/queries/0_stateless/01056_predicate_optimizer_bugs.sql\n@@ -1,5 +1,6 @@\n SET enable_optimize_predicate_expression = 1;\n SET joined_subquery_requires_alias = 0;\n+SET convert_query_to_cnf = 0;\n \n -- https://github.com/ClickHouse/ClickHouse/issues/3885\n -- https://github.com/ClickHouse/ClickHouse/issues/5485\ndiff --git a/tests/queries/0_stateless/01083_cross_to_inner_with_like.sql b/tests/queries/0_stateless/01083_cross_to_inner_with_like.sql\nindex 644190cbddfa..6ec6e80692c2 100644\n--- a/tests/queries/0_stateless/01083_cross_to_inner_with_like.sql\n+++ b/tests/queries/0_stateless/01083_cross_to_inner_with_like.sql\n@@ -1,3 +1,5 @@\n+SET convert_query_to_cnf = 0;\n+\n DROP TABLE IF EXISTS n;\n DROP TABLE IF EXISTS r;\n \ndiff --git a/tests/queries/0_stateless/01099_parallel_distributed_insert_select.sql b/tests/queries/0_stateless/01099_parallel_distributed_insert_select.sql\nindex 4e011bf6b31c..de93166d8913 100644\n--- a/tests/queries/0_stateless/01099_parallel_distributed_insert_select.sql\n+++ b/tests/queries/0_stateless/01099_parallel_distributed_insert_select.sql\n@@ -2,6 +2,8 @@\n \n -- set insert_distributed_sync = 1;  -- see https://github.com/ClickHouse/ClickHouse/issues/18971\n \n+SET allow_experimental_parallel_reading_from_replicas = 0; -- see https://github.com/ClickHouse/ClickHouse/issues/34525\n+\n DROP TABLE IF EXISTS local_01099_a;\n DROP TABLE IF EXISTS local_01099_b;\n DROP TABLE IF EXISTS distributed_01099_a;\ndiff --git a/tests/queries/0_stateless/01155_rename_move_materialized_view.sql b/tests/queries/0_stateless/01155_rename_move_materialized_view.sql\nindex 0b672cbddbf0..e0546ec8117f 100644\n--- a/tests/queries/0_stateless/01155_rename_move_materialized_view.sql\n+++ b/tests/queries/0_stateless/01155_rename_move_materialized_view.sql\n@@ -1,5 +1,7 @@\n -- Tags: no-parallel\n \n+SET prefer_localhost_replica = 1;\n+\n DROP DATABASE IF EXISTS test_01155_ordinary;\n DROP DATABASE IF EXISTS test_01155_atomic;\n \ndiff --git a/tests/queries/0_stateless/01187_set_profile_as_setting.sh b/tests/queries/0_stateless/01187_set_profile_as_setting.sh\nindex ec07f4d36878..dacb609d790d 100755\n--- a/tests/queries/0_stateless/01187_set_profile_as_setting.sh\n+++ b/tests/queries/0_stateless/01187_set_profile_as_setting.sh\n@@ -1,4 +1,5 @@\n #!/usr/bin/env bash\n+# Tags: no-random-settings\n \n unset CLICKHOUSE_LOG_COMMENT\n \ndiff --git a/tests/queries/0_stateless/01271_optimize_arithmetic_operations_in_aggr_func_with_alias.sql b/tests/queries/0_stateless/01271_optimize_arithmetic_operations_in_aggr_func_with_alias.sql\nindex 73b87817bb3d..242a253e67cf 100644\n--- a/tests/queries/0_stateless/01271_optimize_arithmetic_operations_in_aggr_func_with_alias.sql\n+++ b/tests/queries/0_stateless/01271_optimize_arithmetic_operations_in_aggr_func_with_alias.sql\n@@ -1,4 +1,5 @@\n set optimize_arithmetic_operations_in_aggregate_functions = 1;\n+SET convert_query_to_cnf = 0;\n \n explain syntax select min((n as a) + (1 as b)) c from (select number n from numbers(10)) where a > 0 and b > 0 having c > 0;\n select min((n as a) + (1 as b)) c from (select number n from numbers(10)) where a > 0 and b > 0 having c > 0;\ndiff --git a/tests/queries/0_stateless/01275_parallel_mv.sql b/tests/queries/0_stateless/01275_parallel_mv.sql\nindex 32b43ce616f7..11e5ff41417e 100644\n--- a/tests/queries/0_stateless/01275_parallel_mv.sql\n+++ b/tests/queries/0_stateless/01275_parallel_mv.sql\n@@ -1,3 +1,5 @@\n+set max_threads = 0;\n+\n drop table if exists testX;\n drop table if exists testXA;\n drop table if exists testXB;\ndiff --git a/tests/queries/0_stateless/01293_show_settings.sql b/tests/queries/0_stateless/01293_show_settings.sql\nindex 08f00ed201c1..3e55ffb58d72 100644\n--- a/tests/queries/0_stateless/01293_show_settings.sql\n+++ b/tests/queries/0_stateless/01293_show_settings.sql\n@@ -1,3 +1,5 @@\n+-- Tags: no-random-settings\n+\n show settings like 'send_timeout';\n SHOW SETTINGS ILIKE '%CONNECT_timeout%';\n SHOW CHANGED SETTINGS ILIKE '%MEMORY%';\ndiff --git a/tests/queries/0_stateless/01293_system_distribution_queue.sql b/tests/queries/0_stateless/01293_system_distribution_queue.sql\nindex 34158fb081ce..9997f18f61d3 100644\n--- a/tests/queries/0_stateless/01293_system_distribution_queue.sql\n+++ b/tests/queries/0_stateless/01293_system_distribution_queue.sql\n@@ -1,4 +1,5 @@\n -- Tags: no-parallel\n+set prefer_localhost_replica = 1;\n \n drop table if exists null_01293;\n drop table if exists dist_01293;\ndiff --git a/tests/queries/0_stateless/01300_group_by_other_keys.sql b/tests/queries/0_stateless/01300_group_by_other_keys.sql\nindex 22cff012e71e..0e37ef55a6ad 100644\n--- a/tests/queries/0_stateless/01300_group_by_other_keys.sql\n+++ b/tests/queries/0_stateless/01300_group_by_other_keys.sql\n@@ -1,3 +1,5 @@\n+set max_block_size = 65505;\n+\n set optimize_group_by_function_keys = 1;\n \n SELECT round(max(log(2) * number), 6) AS k FROM numbers(10000000) GROUP BY number % 2, number % 3, (number % 2 + number % 3) % 2 ORDER BY k;\ndiff --git a/tests/queries/0_stateless/01308_row_policy_and_trivial_count_query.sql b/tests/queries/0_stateless/01308_row_policy_and_trivial_count_query.sql\nindex cd41bb227eb2..81bd2ad97a9f 100644\n--- a/tests/queries/0_stateless/01308_row_policy_and_trivial_count_query.sql\n+++ b/tests/queries/0_stateless/01308_row_policy_and_trivial_count_query.sql\n@@ -1,3 +1,5 @@\n+SET optimize_move_to_prewhere = 1;\n+\n DROP TABLE IF EXISTS t;\n \n CREATE TABLE t (x UInt8) ENGINE = MergeTree ORDER BY x;\ndiff --git a/tests/queries/0_stateless/01339_client_unrecognized_option.sh b/tests/queries/0_stateless/01339_client_unrecognized_option.sh\nindex 00c153ec915a..9f827ccb13e1 100755\n--- a/tests/queries/0_stateless/01339_client_unrecognized_option.sh\n+++ b/tests/queries/0_stateless/01339_client_unrecognized_option.sh\n@@ -1,5 +1,5 @@\n #!/usr/bin/env bash\n-# Tags: no-fasttest\n+# Tags: no-fasttest, no-random-settings\n \n CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\ndiff --git a/tests/queries/0_stateless/01386_negative_float_constant_key_condition.sql b/tests/queries/0_stateless/01386_negative_float_constant_key_condition.sql\nindex c2191d6ab968..b45b9c84b182 100644\n--- a/tests/queries/0_stateless/01386_negative_float_constant_key_condition.sql\n+++ b/tests/queries/0_stateless/01386_negative_float_constant_key_condition.sql\n@@ -1,3 +1,5 @@\n+SET convert_query_to_cnf = 0;\n+\n DROP TABLE IF EXISTS t0;\n \n CREATE TABLE t0\ndiff --git a/tests/queries/0_stateless/01415_overlimiting_threads_for_repica_bug.sql b/tests/queries/0_stateless/01415_overlimiting_threads_for_repica_bug.sql\nindex 306d94387a45..6b5c2ac8ffd2 100644\n--- a/tests/queries/0_stateless/01415_overlimiting_threads_for_repica_bug.sql\n+++ b/tests/queries/0_stateless/01415_overlimiting_threads_for_repica_bug.sql\n@@ -1,5 +1,6 @@\n set log_queries = 1;\n set max_threads = 16;\n+set prefer_localhost_replica = 1;\n \n select sum(number) from remote('127.0.0.{1|2}', numbers_mt(1000000)) group by number % 2 order by number % 2;\n \ndiff --git a/tests/queries/0_stateless/01457_create_as_table_function_structure.sql b/tests/queries/0_stateless/01457_create_as_table_function_structure.sql\nindex d7c681dc6158..bc677698d882 100644\n--- a/tests/queries/0_stateless/01457_create_as_table_function_structure.sql\n+++ b/tests/queries/0_stateless/01457_create_as_table_function_structure.sql\n@@ -1,5 +1,7 @@\n -- Tags: no-parallel\n \n+SET prefer_localhost_replica = 1;\n+\n DROP DATABASE IF EXISTS test_01457;\n \n CREATE DATABASE test_01457;\ndiff --git a/tests/queries/0_stateless/01475_read_subcolumns.sql b/tests/queries/0_stateless/01475_read_subcolumns.sql\nindex fb26b19ed301..4724bec9eff2 100644\n--- a/tests/queries/0_stateless/01475_read_subcolumns.sql\n+++ b/tests/queries/0_stateless/01475_read_subcolumns.sql\n@@ -1,4 +1,7 @@\n -- Tags: no-s3-storage\n+\n+SET use_uncompressed_cache = 0;\n+\n SELECT '====array====';\n DROP TABLE IF EXISTS t_arr;\n CREATE TABLE t_arr (a Array(UInt32)) ENGINE = MergeTree ORDER BY tuple() SETTINGS min_bytes_for_wide_part = 0;\ndiff --git a/tests/queries/0_stateless/01517_select_final_distributed.sql b/tests/queries/0_stateless/01517_select_final_distributed.sql\nindex a3d1fcfc1851..701828b0b38f 100644\n--- a/tests/queries/0_stateless/01517_select_final_distributed.sql\n+++ b/tests/queries/0_stateless/01517_select_final_distributed.sql\n@@ -1,5 +1,7 @@\n -- Tags: distributed\n \n+SET allow_experimental_parallel_reading_from_replicas = 0;\n+\n DROP TABLE IF EXISTS test5346;\n \n CREATE TABLE test5346 (`Id` String, `Timestamp` DateTime, `updated` DateTime) \ndiff --git a/tests/queries/0_stateless/01533_multiple_nested.sql b/tests/queries/0_stateless/01533_multiple_nested.sql\nindex 40f287b4afd7..03724ce0b46e 100644\n--- a/tests/queries/0_stateless/01533_multiple_nested.sql\n+++ b/tests/queries/0_stateless/01533_multiple_nested.sql\n@@ -3,6 +3,7 @@\n DROP TABLE IF EXISTS nested;\n \n SET flatten_nested = 0;\n+SET use_uncompressed_cache = 0;\n \n CREATE TABLE nested\n (\ndiff --git a/tests/queries/0_stateless/01557_max_parallel_replicas_no_sample.sql b/tests/queries/0_stateless/01557_max_parallel_replicas_no_sample.sql\nindex 2b1a66147a4d..04777f5b31ce 100644\n--- a/tests/queries/0_stateless/01557_max_parallel_replicas_no_sample.sql\n+++ b/tests/queries/0_stateless/01557_max_parallel_replicas_no_sample.sql\n@@ -1,5 +1,7 @@\n -- Tags: replica\n \n+SET allow_experimental_parallel_reading_from_replicas=0;\n+\n DROP TABLE IF EXISTS t;\n CREATE TABLE t (x String) ENGINE = MergeTree ORDER BY x;\n INSERT INTO t VALUES ('Hello');\ndiff --git a/tests/queries/0_stateless/01582_move_to_prewhere_compact_parts.sql b/tests/queries/0_stateless/01582_move_to_prewhere_compact_parts.sql\nindex 788c99da76dd..bd3e651e0dc5 100644\n--- a/tests/queries/0_stateless/01582_move_to_prewhere_compact_parts.sql\n+++ b/tests/queries/0_stateless/01582_move_to_prewhere_compact_parts.sql\n@@ -1,3 +1,6 @@\n+SET optimize_move_to_prewhere = 1;\n+SET convert_query_to_cnf = 0;\n+\n DROP TABLE IF EXISTS prewhere_move;\n CREATE TABLE prewhere_move (x Int, y String) ENGINE = MergeTree ORDER BY tuple();\n INSERT INTO prewhere_move SELECT number, toString(number) FROM numbers(1000);\ndiff --git a/tests/queries/0_stateless/01605_adaptive_granularity_block_borders.sql b/tests/queries/0_stateless/01605_adaptive_granularity_block_borders.sql\nindex a73045f5a6f5..9f26302e5641 100644\n--- a/tests/queries/0_stateless/01605_adaptive_granularity_block_borders.sql\n+++ b/tests/queries/0_stateless/01605_adaptive_granularity_block_borders.sql\n@@ -1,3 +1,5 @@\n+SET use_uncompressed_cache = 0;\n+\n DROP TABLE IF EXISTS adaptive_table;\n \n --- If granularity of consequent blocks differs a lot, then adaptive\ndiff --git a/tests/queries/0_stateless/01655_plan_optimizations.sh b/tests/queries/0_stateless/01655_plan_optimizations.sh\nindex de3d3ac3eb6a..b66d788a3380 100755\n--- a/tests/queries/0_stateless/01655_plan_optimizations.sh\n+++ b/tests/queries/0_stateless/01655_plan_optimizations.sh\n@@ -64,7 +64,7 @@ $CLICKHOUSE_CLIENT -q \"\n     settings enable_optimize_predicate_expression=0\"\n \n echo \"> one condition of filter should be pushed down after aggregating, other two conditions are ANDed\"\n-$CLICKHOUSE_CLIENT -q \"\n+$CLICKHOUSE_CLIENT --convert_query_to_cnf=0 -q \"\n     explain actions = 1 select s, y from (\n         select sum(x) as s, y from (select number as x, number + 1 as y from numbers(10)) group by y\n     ) where y != 0 and s - 8 and s - 4\n@@ -77,7 +77,7 @@ $CLICKHOUSE_CLIENT -q \"\n     settings enable_optimize_predicate_expression=0\"\n \n echo \"> two conditions of filter should be pushed down after aggregating and ANDed, one condition is aliased\"\n-$CLICKHOUSE_CLIENT -q \"\n+$CLICKHOUSE_CLIENT --convert_query_to_cnf=0 -q \"\n     explain actions = 1 select s, y from (\n         select sum(x) as s, y from (select number as x, number + 1 as y from numbers(10)) group by y\n     ) where y != 0 and s != 8 and y - 4\n@@ -127,7 +127,7 @@ $CLICKHOUSE_CLIENT -q \"\n     settings enable_optimize_predicate_expression=0\"\n \n echo \"> filter is pushed down before sorting steps\"\n-$CLICKHOUSE_CLIENT -q \"\n+$CLICKHOUSE_CLIENT --convert_query_to_cnf=0 -q \"\n     explain actions = 1 select x, y from (\n         select number % 2 as x, number % 3 as y from numbers(6) order by y desc\n     ) where x != 0 and y != 0\ndiff --git a/tests/queries/0_stateless/01666_blns_long.sql b/tests/queries/0_stateless/01666_blns_long.sql\nindex fd959cf0a738..74054551b189 100644\n--- a/tests/queries/0_stateless/01666_blns_long.sql\n+++ b/tests/queries/0_stateless/01666_blns_long.sql\n@@ -27,6 +27,8 @@ OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n SOFTWARE.\n */\n \n+SET max_insert_threads = 0;\n+\n DROP TABLE IF EXISTS test;\n \n CREATE TABLE test\ndiff --git a/tests/queries/0_stateless/01671_aggregate_function_group_bitmap_data.sql b/tests/queries/0_stateless/01671_aggregate_function_group_bitmap_data.sql\nindex 3f5c5c2f25b6..d70665655ca3 100644\n--- a/tests/queries/0_stateless/01671_aggregate_function_group_bitmap_data.sql\n+++ b/tests/queries/0_stateless/01671_aggregate_function_group_bitmap_data.sql\n@@ -1,3 +1,5 @@\n+SET group_by_two_level_threshold = 10000;\n+\n CREATE TABLE group_bitmap_data_test\n (\n     `pickup_date` Date,\ndiff --git a/tests/queries/0_stateless/01737_move_order_key_to_prewhere_select_final.sql b/tests/queries/0_stateless/01737_move_order_key_to_prewhere_select_final.sql\nindex ecc11c625e31..789892dbd381 100644\n--- a/tests/queries/0_stateless/01737_move_order_key_to_prewhere_select_final.sql\n+++ b/tests/queries/0_stateless/01737_move_order_key_to_prewhere_select_final.sql\n@@ -1,3 +1,6 @@\n+SET optimize_move_to_prewhere = 1;\n+SET convert_query_to_cnf = 0;\n+\n DROP TABLE IF EXISTS prewhere_move_select_final;\n \n CREATE TABLE prewhere_move_select_final (x Int, y Int, z Int) ENGINE = ReplacingMergeTree() ORDER BY (x, y);\ndiff --git a/tests/queries/0_stateless/01746_long_zstd_http_compression_json_format.sh b/tests/queries/0_stateless/01746_long_zstd_http_compression_json_format.sh\nindex 02943cad5837..e10032e04fda 100755\n--- a/tests/queries/0_stateless/01746_long_zstd_http_compression_json_format.sh\n+++ b/tests/queries/0_stateless/01746_long_zstd_http_compression_json_format.sh\n@@ -5,4 +5,4 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n . \"$CURDIR\"/../shell_config.sh\n \n-${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: zstd'              \"${CLICKHOUSE_URL}&enable_http_compression=1\" -d \"SELECT toDate('2020-12-12') as datetime, 'test-pipeline' as pipeline, 'clickhouse-test-host-001.clickhouse.com' as host, 'clickhouse' as home, 'clickhouse' as detail, number as row_number FROM numbers(1000000) FORMAT JSON\" | zstd -d | tail -n30 | head -n23\n+${CLICKHOUSE_CURL} -sS -H 'Accept-Encoding: zstd'              \"${CLICKHOUSE_URL}&enable_http_compression=1\" -d \"SELECT toDate('2020-12-12') as datetime, 'test-pipeline' as pipeline, 'clickhouse-test-host-001.clickhouse.com' as host, 'clickhouse' as home, 'clickhouse' as detail, number as row_number FROM numbers(1000000) SETTINGS max_block_size=65505 FORMAT JSON\" | zstd -d | tail -n30 | head -n23\ndiff --git a/tests/queries/0_stateless/01763_max_distributed_depth.sql b/tests/queries/0_stateless/01763_max_distributed_depth.sql\nindex 12b2e3680075..f50d15e7121a 100644\n--- a/tests/queries/0_stateless/01763_max_distributed_depth.sql\n+++ b/tests/queries/0_stateless/01763_max_distributed_depth.sql\n@@ -1,5 +1,7 @@\n -- Tags: distributed\n \n+SET prefer_localhost_replica = 1;\n+\n DROP TABLE IF EXISTS tt6;\n \n CREATE TABLE tt6\n@@ -13,6 +15,8 @@ CREATE TABLE tt6\n )\n ENGINE = Distributed('test_shard_localhost', '', 'tt7', rand());\n \n+DROP TABLE IF EXISTS tt7;\n+\n CREATE TABLE tt7 as tt6 ENGINE = Distributed('test_shard_localhost', '', 'tt6', rand());\n \n INSERT INTO tt6 VALUES (1, 1, 1, 1, 'ok'); -- { serverError 581 }\n@@ -28,3 +32,4 @@ INSERT INTO tt6 VALUES (1, 1, 1, 1, 'ok'); -- { serverError 306}\n SELECT * FROM tt6; -- { serverError 306 }\n \n DROP TABLE tt6;\n+DROP TABLE tt7;\ndiff --git a/tests/queries/0_stateless/01786_explain_merge_tree.sh b/tests/queries/0_stateless/01786_explain_merge_tree.sh\nindex 6be86f9ce022..eb47f0650448 100755\n--- a/tests/queries/0_stateless/01786_explain_merge_tree.sh\n+++ b/tests/queries/0_stateless/01786_explain_merge_tree.sh\n@@ -4,6 +4,8 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n . \"$CURDIR\"/../shell_config.sh\n \n+CLICKHOUSE_CLIENT=\"$CLICKHOUSE_CLIENT --optimize_move_to_prewhere=1 --convert_query_to_cnf=0\"\n+\n $CLICKHOUSE_CLIENT -q \"drop table if exists test_index\"\n $CLICKHOUSE_CLIENT -q \"drop table if exists idx\"\n \ndiff --git a/tests/queries/0_stateless/01798_uniq_theta_sketch.sql b/tests/queries/0_stateless/01798_uniq_theta_sketch.sql\nindex bb400c5de149..eace83d5cfa0 100644\n--- a/tests/queries/0_stateless/01798_uniq_theta_sketch.sql\n+++ b/tests/queries/0_stateless/01798_uniq_theta_sketch.sql\n@@ -1,5 +1,7 @@\n -- Tags: no-fasttest\n \n+SET max_block_size = 65505;\n+\n SELECT 'uniqTheta many agrs';\n \n SELECT\ndiff --git a/tests/queries/0_stateless/01822_short_circuit.sql b/tests/queries/0_stateless/01822_short_circuit.sql\nindex 48fff04921b2..c7379d210eba 100644\n--- a/tests/queries/0_stateless/01822_short_circuit.sql\n+++ b/tests/queries/0_stateless/01822_short_circuit.sql\n@@ -1,4 +1,5 @@\n set short_circuit_function_evaluation = 'enable';\n+set convert_query_to_cnf = 0;\n \n select if(number > 0, intDiv(number + 100, number), throwIf(number)) from numbers(10);\n select multiIf(number == 0, 0, number == 1, intDiv(1, number), number == 2, intDiv(1, number - 1), number == 3, intDiv(1, number - 2), intDiv(1, number - 3)) from numbers(10);\ndiff --git a/tests/queries/0_stateless/01824_move_to_prewhere_many_columns.sql b/tests/queries/0_stateless/01824_move_to_prewhere_many_columns.sql\nindex e03972e818d2..c4ef5516fc83 100644\n--- a/tests/queries/0_stateless/01824_move_to_prewhere_many_columns.sql\n+++ b/tests/queries/0_stateless/01824_move_to_prewhere_many_columns.sql\n@@ -1,3 +1,6 @@\n+SET optimize_move_to_prewhere = 1;\n+SET convert_query_to_cnf = 0;\n+\n DROP TABLE IF EXISTS t_move_to_prewhere;\n \n CREATE TABLE t_move_to_prewhere (id UInt32, a UInt8, b UInt8, c UInt8, fat_string String)\ndiff --git a/tests/queries/0_stateless/01917_prewhere_column_type.sql b/tests/queries/0_stateless/01917_prewhere_column_type.sql\nindex 5147e6093a95..c0bc0c3e36b8 100644\n--- a/tests/queries/0_stateless/01917_prewhere_column_type.sql\n+++ b/tests/queries/0_stateless/01917_prewhere_column_type.sql\n@@ -1,3 +1,5 @@\n+SET optimize_move_to_prewhere = 1;\n+\n DROP TABLE IF EXISTS t1;\n \n CREATE TABLE t1 ( s String, f Float32, e UInt16 ) ENGINE = MergeTree ORDER BY tuple() SETTINGS min_bytes_for_wide_part = '100G';\ndiff --git a/tests/queries/0_stateless/01943_query_id_check.sql b/tests/queries/0_stateless/01943_query_id_check.sql\nindex cb2ef0908540..ad9e88e04781 100644\n--- a/tests/queries/0_stateless/01943_query_id_check.sql\n+++ b/tests/queries/0_stateless/01943_query_id_check.sql\n@@ -1,6 +1,8 @@\n -- Tags: no-replicated-database\n -- Tag no-replicated-database: Different query_id\n \n+SET prefer_localhost_replica = 1;\n+\n DROP TABLE IF EXISTS tmp;\n \n CREATE TABLE tmp ENGINE = TinyLog AS SELECT queryID();\ndiff --git a/tests/queries/0_stateless/01951_distributed_push_down_limit.sql b/tests/queries/0_stateless/01951_distributed_push_down_limit.sql\nindex fa2fc1800c12..184e63219881 100644\n--- a/tests/queries/0_stateless/01951_distributed_push_down_limit.sql\n+++ b/tests/queries/0_stateless/01951_distributed_push_down_limit.sql\n@@ -1,5 +1,7 @@\n -- Tags: distributed\n \n+set prefer_localhost_replica = 1;\n+\n -- { echo }\n explain select * from remote('127.{1,2}', view(select * from numbers(1e6))) order by number limit 10 settings distributed_push_down_limit=0;\n explain select * from remote('127.{1,2}', view(select * from numbers(1e6))) order by number limit 10 settings distributed_push_down_limit=1;\ndiff --git a/tests/queries/0_stateless/01952_optimize_distributed_group_by_sharding_key.sql b/tests/queries/0_stateless/01952_optimize_distributed_group_by_sharding_key.sql\nindex d1f80b42e756..74b55b953155 100644\n--- a/tests/queries/0_stateless/01952_optimize_distributed_group_by_sharding_key.sql\n+++ b/tests/queries/0_stateless/01952_optimize_distributed_group_by_sharding_key.sql\n@@ -2,6 +2,7 @@\n \n set optimize_skip_unused_shards=1;\n set optimize_distributed_group_by_sharding_key=1;\n+set prefer_localhost_replica=1;\n \n -- { echo }\n explain select distinct k1 from remote('127.{1,2}', view(select 1 k1, 2 k2, 3 v from numbers(2)), cityHash64(k1, k2)); -- not optimized\ndiff --git a/tests/queries/0_stateless/02006_test_positional_arguments.sql b/tests/queries/0_stateless/02006_test_positional_arguments.sql\nindex 54b55c4a9f87..7442ca6bbf64 100644\n--- a/tests/queries/0_stateless/02006_test_positional_arguments.sql\n+++ b/tests/queries/0_stateless/02006_test_positional_arguments.sql\n@@ -1,3 +1,4 @@\n+set group_by_two_level_threshold = 100000;\n set enable_positional_arguments = 1;\n \n drop table if exists test;\ndiff --git a/tests/queries/0_stateless/02030_tuple_filter.sql b/tests/queries/0_stateless/02030_tuple_filter.sql\nindex 5efedeb8c0d5..c19f538b8e13 100644\n--- a/tests/queries/0_stateless/02030_tuple_filter.sql\n+++ b/tests/queries/0_stateless/02030_tuple_filter.sql\n@@ -5,6 +5,7 @@ CREATE TABLE test_tuple_filter (id UInt32, value String, log_date Date) Engine=M\n INSERT INTO test_tuple_filter VALUES (1,'A','2021-01-01'),(2,'B','2021-01-01'),(3,'C','2021-01-01'),(4,'D','2021-01-02'),(5,'E','2021-01-02');\n \n SET force_primary_key = 1;\n+SET optimize_move_to_prewhere = 1;\n \n SELECT * FROM test_tuple_filter WHERE (id, value) = (1, 'A');\n SELECT * FROM test_tuple_filter WHERE (1, 'A') = (id, value);\ndiff --git a/tests/queries/0_stateless/02050_client_profile_events.sh b/tests/queries/0_stateless/02050_client_profile_events.sh\nindex 459e8505e22d..f8bcea0d1bbc 100755\n--- a/tests/queries/0_stateless/02050_client_profile_events.sh\n+++ b/tests/queries/0_stateless/02050_client_profile_events.sh\n@@ -7,7 +7,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # do not print any ProfileEvents packets\n $CLICKHOUSE_CLIENT -q 'select * from numbers(1e5) format Null' |& grep -c 'SelectedRows'\n # print only last (and also number of rows to provide more info in case of failures)\n-$CLICKHOUSE_CLIENT --print-profile-events --profile-events-delay-ms=-1 -q 'select * from numbers(1e5)' 2> >(grep -o -e '\\[ 0 \\] SelectedRows: .*$' -e Exception) 1> >(wc -l)\n+$CLICKHOUSE_CLIENT --max_block_size=65505 --print-profile-events --profile-events-delay-ms=-1 -q 'select * from numbers(1e5)' 2> >(grep -o -e '\\[ 0 \\] SelectedRows: .*$' -e Exception) 1> >(wc -l)\n # print everything\n profile_events=\"$($CLICKHOUSE_CLIENT --max_block_size 1 --print-profile-events -q 'select sleep(1) from numbers(2) format Null' |& grep -c 'SelectedRows')\"\n test \"$profile_events\" -gt 1 && echo OK || echo \"FAIL ($profile_events)\"\ndiff --git a/tests/queries/0_stateless/02131_multiply_row_policies_on_same_column.sql b/tests/queries/0_stateless/02131_multiply_row_policies_on_same_column.sql\nindex 75f7f737e858..d0a55c6ba65b 100644\n--- a/tests/queries/0_stateless/02131_multiply_row_policies_on_same_column.sql\n+++ b/tests/queries/0_stateless/02131_multiply_row_policies_on_same_column.sql\n@@ -1,3 +1,5 @@\n+SET optimize_move_to_prewhere = 1;\n+\n DROP TABLE IF EXISTS 02131_multiply_row_policies_on_same_column;\n CREATE TABLE 02131_multiply_row_policies_on_same_column (x UInt8) ENGINE = MergeTree ORDER BY x;\n INSERT INTO 02131_multiply_row_policies_on_same_column VALUES (1), (2), (3), (4);\ndiff --git a/tests/queries/0_stateless/02136_scalar_progress.sh b/tests/queries/0_stateless/02136_scalar_progress.sh\nindex 4608031f83d7..9f4429b0caaf 100755\n--- a/tests/queries/0_stateless/02136_scalar_progress.sh\n+++ b/tests/queries/0_stateless/02136_scalar_progress.sh\n@@ -4,4 +4,4 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n . \"$CURDIR\"/../shell_config.sh\n \n-$CLICKHOUSE_CURL -sS \"${CLICKHOUSE_URL}&wait_end_of_query=1&send_progress_in_http_headers=1&http_headers_progress_interval_ms=0\" -d \"SELECT (SELECT max(number), count(number) FROM numbers(100000));\" -v 2>&1 | grep -E \"X-ClickHouse-Summary|X-ClickHouse-Progress\"\n+$CLICKHOUSE_CURL -sS \"${CLICKHOUSE_URL}&wait_end_of_query=1&send_progress_in_http_headers=1&http_headers_progress_interval_ms=0\" -d \"SELECT (SELECT max(number), count(number) FROM numbers(100000) settings max_block_size=65505);\" -v 2>&1 | grep -E \"X-ClickHouse-Summary|X-ClickHouse-Progress\"\ndiff --git a/tests/queries/0_stateless/02136_scalar_read_rows_json.sh b/tests/queries/0_stateless/02136_scalar_read_rows_json.sh\nindex d589cb600868..34b4b6909b5c 100755\n--- a/tests/queries/0_stateless/02136_scalar_read_rows_json.sh\n+++ b/tests/queries/0_stateless/02136_scalar_read_rows_json.sh\n@@ -7,4 +7,4 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n echo \"#1\"\n ${CLICKHOUSE_CLIENT} --query='SELECT count() FROM numbers(100) FORMAT JSON;' | grep -a -v \"elapsed\"\n echo \"#2\"\n-${CLICKHOUSE_CLIENT} --query='SELECT (SELECT max(number), count(number) FROM numbers(100000) as n) FORMAT JSON;' | grep -a -v \"elapsed\" | grep -v \"_subquery\"\n+${CLICKHOUSE_CLIENT} --query='SELECT (SELECT max(number), count(number) FROM numbers(100000) as n) SETTINGS max_block_size = 65505 FORMAT JSON;' | grep -a -v \"elapsed\" | grep -v \"_subquery\"\ndiff --git a/tests/queries/0_stateless/02156_storage_merge_prewhere.sql b/tests/queries/0_stateless/02156_storage_merge_prewhere.sql\nindex 69fa9ac5ee2c..b75d3fa22e58 100644\n--- a/tests/queries/0_stateless/02156_storage_merge_prewhere.sql\n+++ b/tests/queries/0_stateless/02156_storage_merge_prewhere.sql\n@@ -1,3 +1,5 @@\n+SET optimize_move_to_prewhere = 1;\n+\n DROP TABLE IF EXISTS t_02156_mt1;\n DROP TABLE IF EXISTS t_02156_mt2;\n DROP TABLE IF EXISTS t_02156_log;\ndiff --git a/tests/queries/1_stateful/00084_external_aggregation.sql b/tests/queries/1_stateful/00084_external_aggregation.sql\nindex b3922eae0494..816d95f4b8b3 100644\n--- a/tests/queries/1_stateful/00084_external_aggregation.sql\n+++ b/tests/queries/1_stateful/00084_external_aggregation.sql\n@@ -1,3 +1,5 @@\n+-- Tags: no-random-settings\n+\n SET max_bytes_before_external_group_by = 200000000;\n \n SET max_memory_usage = 1500000000;\ndiff --git a/tests/queries/1_stateful/00154_avro.sql b/tests/queries/1_stateful/00154_avro.sql\nindex ea5d665a3b45..f608da629d2d 100644\n--- a/tests/queries/1_stateful/00154_avro.sql\n+++ b/tests/queries/1_stateful/00154_avro.sql\n@@ -2,7 +2,7 @@\n \n DROP TABLE IF EXISTS test.avro;\n \n-SET max_threads = 1, max_block_size = 8192, min_insert_block_size_rows = 8192, min_insert_block_size_bytes = 1048576; -- lower memory usage\n+SET max_threads = 1, max_insert_threads = 0, max_block_size = 8192, min_insert_block_size_rows = 8192, min_insert_block_size_bytes = 1048576; -- lower memory usage\n \n CREATE TABLE test.avro AS test.hits ENGINE = File(Avro);\n INSERT INTO test.avro SELECT * FROM test.hits LIMIT 10000;\ndiff --git a/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh\nindex 699700bcd3e5..276fc0274c2b 100755\n--- a/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh\n+++ b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh\n@@ -1,5 +1,5 @@\n #!/usr/bin/env bash\n-# Tags: no-tsan\n+# Tags: no-tsan, no-random-settings\n \n CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n",
  "problem_statement": "Randomization of settings in functional tests.\nWe will create a list of settings and distributions of their values.\r\nThe settings will be randomly set before running functional tests, according to the distributions.\r\nThis can be implemented as a Python code directly inside `clickhouse-test` (no need for any configs or DSLs).\r\n\r\nExamples:\r\n- enable `convert_query_to_cnf` with probability 1/2;\r\n- set `max_block_size` uniformly random in a range of 8000..100000;\r\n- set `max_threads` uniformly random in a range of 1..64;\r\n\r\nIf a test needs fixed value of some setting, it should set it explicitly in the test.\n",
  "hints_text": "One more example: disabling setting `input_format_parallel_parsing` and changing `max_read_buffer_size` to small value. It will help to fuzz formats (using small `max_read_buffer_size` helped me to find some uncovered corner cases)\nEnabling `use_uncompressed_cache` will be also very helpful, because we almost doesn't have tests for it, but it's a surpriingly popular feature.",
  "created_at": "2022-01-28T11:27:40Z"
}