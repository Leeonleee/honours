{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 12959,
  "instance_id": "ClickHouse__ClickHouse-12959",
  "issue_numbers": [
    "8979"
  ],
  "base_commit": "77444e76a771088ba3067d3e8c791373420ec1f2",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex c71172850ba5..abd88ab36a81 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -2408,11 +2408,6 @@ static void loadPartAndFixMetadataImpl(MergeTreeData::MutableDataPartPtr part)\n     auto disk = part->volume->getDisk();\n     String full_part_path = part->getFullRelativePath();\n \n-    /// Earlier the list of  columns was written incorrectly. Delete it and re-create.\n-    /// But in compact parts we can't get list of columns without this file.\n-    if (isWidePart(part))\n-        disk->removeIfExists(full_part_path + \"columns.txt\");\n-\n     part->loadColumnsChecksumsIndexes(false, true);\n     part->modification_time = disk->getLastModified(full_part_path).epochTime();\n }\n",
  "test_patch": "diff --git a/tests/integration/test_backup_with_other_granularity/__init__.py b/tests/integration/test_backup_with_other_granularity/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_backup_with_other_granularity/test.py b/tests/integration/test_backup_with_other_granularity/test.py\nnew file mode 100644\nindex 000000000000..d4ca9bd1bacb\n--- /dev/null\n+++ b/tests/integration/test_backup_with_other_granularity/test.py\n@@ -0,0 +1,152 @@\n+import pytest\n+\n+\n+from helpers.cluster import ClickHouseCluster\n+cluster = ClickHouseCluster(__file__)\n+\n+\n+node1 = cluster.add_instance('node1', with_zookeeper=True, image='yandex/clickhouse-server:19.4.5.35', stay_alive=True, with_installed_binary=True)\n+node2 = cluster.add_instance('node2', with_zookeeper=True, image='yandex/clickhouse-server:19.4.5.35', stay_alive=True, with_installed_binary=True)\n+node3 = cluster.add_instance('node3', with_zookeeper=True, image='yandex/clickhouse-server:19.4.5.35', stay_alive=True, with_installed_binary=True)\n+node4 = cluster.add_instance('node4')\n+\n+\n+@pytest.fixture(scope=\"module\")\n+def started_cluster():\n+    try:\n+        cluster.start()\n+        yield cluster\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def test_backup_from_old_version(started_cluster):\n+    node1.query(\"CREATE TABLE source_table(A Int64, B String) Engine = MergeTree order by tuple()\")\n+\n+    node1.query(\"INSERT INTO source_table VALUES(1, '1')\")\n+\n+    assert node1.query(\"SELECT COUNT() FROM source_table\") == \"1\\n\"\n+\n+    node1.query(\"ALTER TABLE source_table ADD COLUMN Y String\")\n+\n+    node1.query(\"ALTER TABLE source_table FREEZE PARTITION tuple();\")\n+\n+    node1.restart_with_latest_version()\n+\n+    node1.query(\"CREATE TABLE dest_table (A Int64,  B String,  Y String) ENGINE = ReplicatedMergeTree('/test/dest_table1', '1')  ORDER BY tuple()\")\n+\n+    node1.query(\"INSERT INTO dest_table VALUES(2, '2', 'Hello')\")\n+\n+    assert node1.query(\"SELECT COUNT() FROM dest_table\") == \"1\\n\"\n+\n+    node1.exec_in_container(['bash', '-c', 'cp -r /var/lib/clickhouse/shadow/1/data/default/source_table/all_1_1_0/ /var/lib/clickhouse/data/default/dest_table/detached'])\n+\n+    assert node1.query(\"SELECT COUNT() FROM dest_table\") == \"1\\n\"\n+\n+    node1.query(\"ALTER TABLE dest_table ATTACH PARTITION tuple()\")\n+\n+    assert node1.query(\"SELECT sum(A) FROM dest_table\") == \"3\\n\"\n+\n+    node1.query(\"ALTER TABLE dest_table DETACH PARTITION tuple()\")\n+\n+    node1.query(\"ALTER TABLE dest_table ATTACH PARTITION tuple()\")\n+\n+    assert node1.query(\"SELECT sum(A) FROM dest_table\") == \"3\\n\"\n+\n+    assert node1.query(\"CHECK TABLE dest_table\") == \"1\\n\"\n+\n+\n+def test_backup_from_old_version_setting(started_cluster):\n+    node2.query(\"CREATE TABLE source_table(A Int64, B String) Engine = MergeTree order by tuple()\")\n+\n+    node2.query(\"INSERT INTO source_table VALUES(1, '1')\")\n+\n+    assert node2.query(\"SELECT COUNT() FROM source_table\") == \"1\\n\"\n+\n+    node2.query(\"ALTER TABLE source_table ADD COLUMN Y String\")\n+\n+    node2.query(\"ALTER TABLE source_table FREEZE PARTITION tuple();\")\n+\n+    node2.restart_with_latest_version()\n+\n+    node2.query(\"CREATE TABLE dest_table (A Int64,  B String,  Y String) ENGINE = ReplicatedMergeTree('/test/dest_table2', '1')  ORDER BY tuple() SETTINGS enable_mixed_granularity_parts = 1\")\n+\n+    node2.query(\"INSERT INTO dest_table VALUES(2, '2', 'Hello')\")\n+\n+    assert node2.query(\"SELECT COUNT() FROM dest_table\") == \"1\\n\"\n+\n+    node2.exec_in_container(['bash', '-c', 'cp -r /var/lib/clickhouse/shadow/1/data/default/source_table/all_1_1_0/ /var/lib/clickhouse/data/default/dest_table/detached'])\n+\n+    assert node2.query(\"SELECT COUNT() FROM dest_table\") == \"1\\n\"\n+\n+    node2.query(\"ALTER TABLE dest_table ATTACH PARTITION tuple()\")\n+\n+    assert node2.query(\"SELECT sum(A) FROM dest_table\") == \"3\\n\"\n+\n+    node2.query(\"ALTER TABLE dest_table DETACH PARTITION tuple()\")\n+\n+    node2.query(\"ALTER TABLE dest_table ATTACH PARTITION tuple()\")\n+\n+    assert node2.query(\"SELECT sum(A) FROM dest_table\") == \"3\\n\"\n+\n+    assert node1.query(\"CHECK TABLE dest_table\") == \"1\\n\"\n+\n+\n+def test_backup_from_old_version_config(started_cluster):\n+    node3.query(\"CREATE TABLE source_table(A Int64, B String) Engine = MergeTree order by tuple()\")\n+\n+    node3.query(\"INSERT INTO source_table VALUES(1, '1')\")\n+\n+    assert node3.query(\"SELECT COUNT() FROM source_table\") == \"1\\n\"\n+\n+    node3.query(\"ALTER TABLE source_table ADD COLUMN Y String\")\n+\n+    node3.query(\"ALTER TABLE source_table FREEZE PARTITION tuple();\")\n+\n+    def callback(n):\n+        n.replace_config(\"/etc/clickhouse-server/merge_tree_settings.xml\", \"<yandex><merge_tree><enable_mixed_granularity_parts>1</enable_mixed_granularity_parts></merge_tree></yandex>\")\n+\n+    node3.restart_with_latest_version(callback_onstop=callback)\n+\n+    node3.query(\"CREATE TABLE dest_table (A Int64,  B String,  Y String) ENGINE = ReplicatedMergeTree('/test/dest_table3', '1')  ORDER BY tuple() SETTINGS enable_mixed_granularity_parts = 1\")\n+\n+    node3.query(\"INSERT INTO dest_table VALUES(2, '2', 'Hello')\")\n+\n+    assert node3.query(\"SELECT COUNT() FROM dest_table\") == \"1\\n\"\n+\n+    node3.exec_in_container(['bash', '-c', 'cp -r /var/lib/clickhouse/shadow/1/data/default/source_table/all_1_1_0/ /var/lib/clickhouse/data/default/dest_table/detached'])\n+\n+    assert node3.query(\"SELECT COUNT() FROM dest_table\") == \"1\\n\"\n+\n+    node3.query(\"ALTER TABLE dest_table ATTACH PARTITION tuple()\")\n+\n+    assert node3.query(\"SELECT sum(A) FROM dest_table\") == \"3\\n\"\n+\n+    node3.query(\"ALTER TABLE dest_table DETACH PARTITION tuple()\")\n+\n+    node3.query(\"ALTER TABLE dest_table ATTACH PARTITION tuple()\")\n+\n+    assert node3.query(\"SELECT sum(A) FROM dest_table\") == \"3\\n\"\n+\n+    assert node1.query(\"CHECK TABLE dest_table\") == \"1\\n\"\n+\n+\n+def test_backup_and_alter(started_cluster):\n+    node4.query(\"CREATE TABLE backup_table(A Int64, B String, C Date) Engine = MergeTree order by tuple()\")\n+\n+    node4.query(\"INSERT INTO backup_table VALUES(2, '2', toDate('2019-10-01'))\")\n+\n+    node4.query(\"ALTER TABLE backup_table FREEZE PARTITION tuple();\")\n+\n+    node4.query(\"ALTER TABLE backup_table DROP COLUMN C\")\n+\n+    node4.query(\"ALTER TABLE backup_table MODIFY COLUMN B UInt64\")\n+\n+    node4.query(\"ALTER TABLE backup_table DROP PARTITION tuple()\")\n+\n+    node4.exec_in_container(['bash', '-c', 'cp -r /var/lib/clickhouse/shadow/1/data/default/backup_table/all_1_1_0/ /var/lib/clickhouse/data/default/backup_table/detached'])\n+\n+    node4.query(\"ALTER TABLE backup_table ATTACH PARTITION tuple()\")\n+\n+    assert node4.query(\"SELECT sum(A) FROM backup_table\") == \"2\\n\"\n+    assert node4.query(\"SELECT B + 2 FROM backup_table\") == \"4\\n\"\n",
  "problem_statement": "Missing data parts after restoring it from older CH version onto newer \nIn order to perform CH upgrade from version  to `19.16.10.44` we followed the following steps:\r\n- we spawned entirely new cluster `v19.16.10.44`\r\n- we created tables (tables as in prod)\r\n- restored data from s3 (previously backed up from prod in a NATIVE format - copy of all the parts) - copied into detached folder and then attach accordingly\r\n- restart all nodes in order to apply setting `enable_mixed_granularity_parts` for MergeTree Engine\r\n\r\nAfter restart we've noticed the following logs:\r\n```DB::Exception: No <column>.mrk file checksum for column <column> in part .../20190201_1_1_0/```\r\nFollowed by: ```Considering to remove broken part .../20190201_1_1_0 because it's impossible to repair ```\r\n\r\nAnd eventually, after some time:\r\n``` \r\n2020.01.30 16:49:41.760398 [ 31 ] {} <Warning> (ReplicatedMergeTreePartCheckThread): Checking part 20190201_1_1_0\r\n2020.01.30 16:49:41.760904 [ 31 ] {} <Warning> (ReplicatedMergeTreePartCheckThread): Checking if anyone has a part covering 20190201_1_1_0.\r\n2020.01.30 16:49:41.775452 [ 31 ] {} <Error> (ReplicatedMergeTreePartCheckThread): No replica has part covering 20190201_1_1_0 and a merge is impossible: we didn't find smaller parts with either the same min block or the same max block.\r\n2020.01.30 16:49:41.777693 [ 31 ] {} <Error> (ReplicatedMergeTreePartCheckThread): Part 20190201_1_1_0 is lost forever.\r\n```\r\n\r\nThat resulted in lost partitions.\r\n\r\nTables on production are using `ReplicatedCollapsingMergeTree` engine. They were create on version `19.4.1.1`. After some times we altered them in order to add some columns. It seems that parts that do not contain added columns are being `lost forever`.\r\n\r\n\r\nTable DDL\r\n```\r\nCREATE TABLE table_name ON CLUSTER '{cluster_name}'\r\n(\r\n  sign Int8, --field needed for the CollapsingMergeTree\r\n  \r\n  date Date,\r\n  id1 UInt32,\r\n  id2 UInt64,\r\n  screen_height UInt16,\r\n  screen_width UInt16,\r\n  session_number_of_views UInt16, \r\n  session_duration_msec UInt32, \r\n  language LowCardinality(String),\r\n  city LowCardinality(String),\r\n  country_code LowCardinality(String),\r\n  nested_thingy Nested \r\n  (\r\n    key String,\r\n    value String\r\n  ),\r\n  version LowCardinality(String),\r\n  browser_name LowCardinality(String), \r\n  browser_major_version UInt16,\r\n  browser_version LowCardinality(String),\r\n  platform_name LowCardinality(String),\r\n  platform_version LowCardinality(String),\r\n  referer_url String,\r\n  custom_vars_session Nested\r\n  ab_test_info Nested\r\n  (\r\n    abtest_id UInt32, \r\n    abtest_version UInt16\r\n  ),\r\n  external Nested\r\n  (\r\n    id String,\r\n    hashed_id UInt64,\r\n    provider UInt8\r\n  ),\r\n  has_playback_recorded UInt8, \r\n  density Float32,\r\n  session_connectivity_types UInt8,\r\n  os_version UInt64,\r\n  sdk_build_number UInt64,\r\n  manufacturer LowCardinality(String),\r\n  model LowCardinality(String),\r\n  precomputed_random Int32, \r\n) ENGINE = ReplicatedCollapsingMergeTree('/{cluster_name}-{env}/tables/shard{shard}/table_name', '{replica}', sign)\r\nPARTITION BY (date)\r\nORDER BY (...)\r\nSAMPLE BY id\r\nSETTINGS index_granularity=16834\r\n;\r\n\r\n```\r\n\n",
  "hints_text": "@alesapin would it be possible to explain the root cause of this problem?\n@alesapin Hello, did you get some time to take a look at this issue? \n@alesapin Hello, any news on this? Would it work with `20.3.8.53`? Thks\n> copied into detached folder and then attach accordingly\r\n\r\nHow did you do that? Do you use FREEZE or stop the server ? When you back up a active working copy you can get inconsistant copy.\r\n\r\n> B::Exception: No <column>.mrk file checksum for column <column> in part .../20190201_1_1_0/\r\n\r\nDoes the folder have that file? \nI could not reproduce this issue.\r\nMaybe it needs more than 1 replica\r\n```\r\n\r\n18.14.19 \r\ncreate table TX(A Int64, B String) Engine = MergeTree order by tuple();\r\ninsert into TX values(1, '1');\r\nalter table TX add column Y String;\r\nalter table TX freeze partition tuple();\r\n\r\nls shadow/.../all_1_1_0 \r\nA.bin  A.mrk  B.bin  B.mrk  checksums.txt  columns.txt\tcount.txt\r\n\r\n!!! No  Y  column in freezed part\r\n\r\n19.16.10.44\r\n\r\nCREATE TABLE dw.TX ( A Int64,  B String,  Y String) ENGINE = ReplicatedMergeTree('/test/txxxxxx', '1')  ORDER BY tuple()\r\ninsert into TX values(2, '2', '2');\r\ncp all_1_1_0  ....../detached/\r\nalter table TX attach partition tuple()\r\n\r\nSELECT * FROM TX\r\n\r\n\u250c\u2500A\u2500\u252c\u2500B\u2500\u252c\u2500Y\u2500\u2510\r\n\u2502 2 \u2502 2 \u2502 2 \u2502\r\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\r\n\u250c\u2500A\u2500\u252c\u2500B\u2500\u252c\u2500Y\u2500\u2510\r\n\u2502 1 \u2502 1 \u2502   \u2502\r\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\r\n\r\nls all_0_0_0\r\nA.bin  A.mrk2  B.bin  B.mrk2  checksums.txt  columns.txt  count.txt  Y.bin  Y.mrk2\r\n\r\nls all_1_1_0/\r\nA.bin  A.mrk  B.bin  B.mrk  checksums.txt  columns.txt\tcount.txt\r\n\r\nenable_mixed_granularity_parts=1\r\nrestart \r\n\r\nSELECT * FROM TX\r\n\r\n\u250c\u2500A\u2500\u252c\u2500B\u2500\u252c\u2500Y\u2500\u2510\r\n\u2502 2 \u2502 2 \u2502 2 \u2502\r\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\r\n\u250c\u2500A\u2500\u252c\u2500B\u2500\u252c\u2500Y\u2500\u2510\r\n\u2502 1 \u2502 1 \u2502   \u2502\r\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\r\n\r\n\r\nenable_mixed_granularity_parts=0\r\nrestart fails  Table contains parts with adaptive and non adaptive marks, but `setting enable_mixed_granularity_parts` is disabled,\r\n\r\n\r\nenable_mixed_granularity_parts=1\r\nrestart\r\n\r\nSELECT * FROM TX\r\n\r\n\u250c\u2500A\u2500\u252c\u2500B\u2500\u252c\u2500Y\u2500\u2510\r\n\u2502 2 \u2502 2 \u2502 2 \u2502\r\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\r\n\u250c\u2500A\u2500\u252c\u2500B\u2500\u252c\u2500Y\u2500\u2510\r\n\u2502 1 \u2502 1 \u2502   \u2502\r\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518\r\n\r\n\r\n\r\n```\n> > copied into detached folder and then attach accordingly\r\n> \r\n> How did you do that? Do you use FREEZE or stop the server? When you back up an active working copy you can get inconsistent copy.\r\n\r\nWe have a backup job in golang that does the backup to S3 every day, it does so by using FREEZE yes. (the backup job use SQL statements on CH). Moreover, the restoration of data worked perfectly on the same version of ClickHouse (19.4.1.1) but failed on the mentioned partition for 19.16.10.44...\r\n\r\n> > B::Exception: No .mrk file checksum for column  in part .../20190201_1_1_0/\r\n> \r\n> Does the folder have that file?\r\n\r\nWe only have retention of 13month, so no access to that folder anymore, but as @den-crane showed, the column is not present in an ancient partition and it shouldn't be an issue.\r\n\r\nAdditional info: we are using 6 shards composed of 2 replicas each for our cluster. We couldn't reproduce the failing behavior locally with docker-compose.\nHi, sorry for the long answer. It seems like index granularity is not relevant to this issue. This error says that checksum in file `checksums.txt` is absent for file `<column>.mrk`. So probably you have broken checksums in your back, but to investigate I'd like to look at `checksums.txt` file. Also, it's not clear, but is it possible to reproduce the error somehow? Also, I recommend updating to at least the latest LTS version 20.3.\r\n\r\n@den-crane's test is correct and this behavior is expected.",
  "created_at": "2020-07-27T19:41:50Z",
  "modified_files": [
    "src/Storages/MergeTree/MergeTreeData.cpp"
  ],
  "modified_test_files": [
    "b/tests/integration/test_backup_with_other_granularity/test.py"
  ]
}