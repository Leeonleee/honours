{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 82114,
  "instance_id": "ClickHouse__ClickHouse-82114",
  "issue_numbers": [
    "81301"
  ],
  "base_commit": "3083edd04e451a16a05ad92c1e699006496dd351",
  "patch": "diff --git a/src/Databases/DataLake/Common.cpp b/src/Databases/DataLake/Common.cpp\nindex 19f054528811..741f5cfa0097 100644\n--- a/src/Databases/DataLake/Common.cpp\n+++ b/src/Databases/DataLake/Common.cpp\n@@ -34,25 +34,32 @@ String trim(const String & str)\n std::vector<String> splitTypeArguments(const String & type_str)\n {\n     std::vector<String> args;\n-    int depth = 0;\n+    int angle_depth = 0;\n+    int paren_depth = 0;\n     size_t start = 0;\n-    for (size_t i = 0; i < type_str.size(); i++)\n+\n+    for (size_t i = 0; i < type_str.size(); ++i)\n     {\n-        if (type_str[i] == '<')\n-            depth++;\n-        else if (type_str[i] == '>')\n-            depth--;\n-        else if (type_str[i] == ',' && depth == 0)\n+        char c = type_str[i];\n+        if (c == '<')\n+            angle_depth++;\n+        else if (c == '>')\n+            angle_depth--;\n+        else if (c == '(')\n+            paren_depth++;\n+        else if (c == ')')\n+            paren_depth--;\n+        else if (c == ',' && angle_depth == 0 && paren_depth == 0)\n         {\n             args.push_back(trim(type_str.substr(start, i - start)));\n             start = i + 1;\n         }\n     }\n+\n     args.push_back(trim(type_str.substr(start)));\n     return args;\n }\n \n-\n DB::DataTypePtr getType(const String & type_name, bool nullable, const String & prefix)\n {\n     String name = trim(type_name);\n@@ -67,6 +74,7 @@ DB::DataTypePtr getType(const String & type_name, bool nullable, const String &\n     {\n         String inner = name.substr(4, name.size() - 5);\n         auto args = splitTypeArguments(inner);\n+\n         if (args.size() != 2)\n             throw DB::Exception(DB::ErrorCodes::DATALAKE_DATABASE_ERROR, \"Invalid data type {}\", type_name);\n \n",
  "test_patch": "diff --git a/tests/integration/test_database_glue/test.py b/tests/integration/test_database_glue/test.py\nindex 9028cc5e407b..7680d9a10ff8 100644\n--- a/tests/integration/test_database_glue/test.py\n+++ b/tests/integration/test_database_glue/test.py\n@@ -7,6 +7,7 @@\n import pyarrow as pa\n import pytest\n import urllib3\n+from datetime import datetime, timedelta\n from minio import Minio\n from pyiceberg.catalog import load_catalog\n from pyiceberg.partitioning import PartitionField, PartitionSpec\n@@ -14,13 +15,15 @@\n from pyiceberg.table.sorting import SortField, SortOrder\n from pyiceberg.transforms import DayTransform, IdentityTransform\n from helpers.config_cluster import minio_access_key, minio_secret_key\n+import decimal\n from pyiceberg.types import (\n     DoubleType,\n-    FloatType,\n     NestedField,\n     StringType,\n     StructType,\n     TimestampType,\n+    MapType,\n+    DecimalType,\n )\n \n from helpers.cluster import ClickHouseCluster, ClickHouseInstance, is_arm\n@@ -32,6 +35,11 @@\n BASE_URL = \"http://glue:3000\"\n BASE_URL_LOCAL_HOST = \"http://localhost:3000\"\n \n+def generate_decimal(precision=9, scale=2):\n+    max_value = 10**(precision - scale) - 1\n+    value = random.uniform(0, max_value)\n+    return round(decimal.Decimal(value), scale)\n+\n DEFAULT_SCHEMA = Schema(\n     NestedField(\n         field_id=1, name=\"datetime\", field_type=TimestampType(), required=False\n@@ -52,9 +60,21 @@\n         ),\n         required=False,\n     ),\n+    NestedField(\n+        field_id=6,\n+        name=\"map_string_decimal\",\n+        field_type=MapType(\n+            key_type=StringType(),\n+            value_type=DecimalType(9, 2),\n+            key_id=7,\n+            value_id=8,\n+            value_required=False,\n+        ),\n+        required=False,\n+    ),\n )\n \n-DEFAULT_CREATE_TABLE = \"CREATE TABLE {}.`{}.{}`\\\\n(\\\\n    `datetime` Nullable(DateTime64(6)),\\\\n    `symbol` Nullable(String),\\\\n    `bid` Nullable(Float64),\\\\n    `ask` Nullable(Float64),\\\\n    `details` Tuple(created_by Nullable(String))\\\\n)\\\\nENGINE = Iceberg(\\\\'http://minio:9000/warehouse-glue/data/\\\\', \\\\'minio\\\\', \\\\'[HIDDEN]\\\\')\\n\"\n+DEFAULT_CREATE_TABLE = \"CREATE TABLE {}.`{}.{}`\\\\n(\\\\n    `datetime` Nullable(DateTime64(6)),\\\\n    `symbol` Nullable(String),\\\\n    `bid` Nullable(Float64),\\\\n    `ask` Nullable(Float64),\\\\n    `details` Tuple(created_by Nullable(String)),\\\\n    `map_string_decimal` Map(String, Nullable(Decimal(9, 2)))\\\\n)\\\\nENGINE = Iceberg(\\\\'http://minio:9000/warehouse-glue/data/\\\\', \\\\'minio\\\\', \\\\'[HIDDEN]\\\\')\\n\"\n \n DEFAULT_PARTITION_SPEC = PartitionSpec(\n     PartitionField(\n@@ -104,15 +124,59 @@ def create_table(\n     )\n \n \n-def generate_record():\n-    return {\n-        \"datetime\": datetime.now(),\n-        \"symbol\": str(\"kek\"),\n-        \"bid\": round(random.uniform(100, 200), 2),\n-        \"ask\": round(random.uniform(200, 300), 2),\n-        \"details\": {\"created_by\": \"Alice Smith\"},\n-    }\n \n+def generate_arrow_data(num_rows=5):\n+    datetimes = []\n+    symbols = []\n+    bids = []\n+    asks = []\n+    details_created_by = []\n+    map_keys = []\n+    map_values = []\n+\n+    offsets = [0]\n+\n+    for _ in range(num_rows):\n+        datetimes.append(datetime.utcnow() - timedelta(minutes=random.randint(0, 60)))\n+        symbols.append(random.choice([\"AAPL\", \"GOOG\", \"MSFT\"]))\n+        bids.append(random.uniform(100, 150))\n+        asks.append(random.uniform(150, 200))\n+        details_created_by.append(random.choice([\"alice\", \"bob\", \"carol\"]))\n+\n+        # map<string, decimal(9,2)>\n+        keys = []\n+        values = []\n+        for i in range(random.randint(1, 3)):\n+            keys.append(f\"key{i}\")\n+            values.append(generate_decimal())\n+        map_keys.extend(keys)\n+        map_values.extend(values)\n+        offsets.append(offsets[-1] + len(keys))\n+\n+    # Struct for 'details'\n+    struct_array = pa.StructArray.from_arrays(\n+        [pa.array(details_created_by, type=pa.string())],\n+        names=[\"created_by\"]\n+    )\n+\n+    # Map array\n+    map_array = pa.MapArray.from_arrays(\n+        offsets=pa.array(offsets, type=pa.int32()),\n+        keys=pa.array(map_keys, type=pa.string()),\n+        items=pa.array(map_values, type=pa.decimal128(9, 2))\n+    )\n+\n+    # Final table\n+    table = pa.table({\n+        \"datetime\": pa.array(datetimes, type=pa.timestamp(\"us\")),\n+        \"symbol\": pa.array(symbols, type=pa.string()),\n+        \"bid\": pa.array(bids, type=pa.float64()),\n+        \"ask\": pa.array(asks, type=pa.float64()),\n+        \"details\": struct_array,\n+        \"map_string_decimal\": map_array,\n+    })\n+\n+    return table\n \n def create_clickhouse_glue_database(\n     started_cluster, node, name, additional_settings={}\n@@ -240,8 +304,7 @@ def test_select(started_cluster):\n         table = create_table(catalog, namespace, table_name)\n \n         num_rows = 10\n-        data = [generate_record() for _ in range(num_rows)]\n-        df = pa.Table.from_pylist(data)\n+        df = generate_arrow_data(num_rows)\n         table.append(df)\n \n         create_clickhouse_glue_database(started_cluster, node, CATALOG_NAME)\n",
  "problem_statement": "Database DataLakeCatalog type=glue: Invalid data type map<string,decimal(9,2)>\n### Describe what's wrong\n\nWhen reading from Iceberg table with nested column I get:\n```\nReceived exception from server (version 25.6.1):\nCode: 736. DB::Exception: Received from localhost:9000. DB::Exception: Invalid data type map<string,decimal(9,2)>. (DATALAKE_DATABASE_ERROR)\n(query: SELECT * FROM iceberg_db.`namespace.table` ORDER BY tuple() FORMAT Values)\n```\n\n### Does it reproduce on the most recent release?\n\nYes\n\n### How to reproduce\n\n1. Create database with `DataLakeCatalog` engine with type=`glue`\n2. Create a table with following structure (for example, in PyIceberg):\n ```python\nschema = Schema(\n            NestedField(\n                field_id=1,\n                name=\"map_string_decimal\",\n                field_type=MapType(\n                    key_type=StringType(),\n                    value_type=DecimalType(9, 2),\n                    key_id=2,\n                    value_id=3,\n                    value_required=False,\n                ),\n            )\n        )\n```\n3. Insert data\n```\n{\"key1\":123.45,\"key2\":67.89}\n```\n4. Run `select` or `describe table` query\n\n### Expected behavior\nSuccessful select (or describe table) query\n\n### Error message and/or stacktrace\n\nCode: 736. DB::Exception: Received from localhost:9000. DB::Exception: Invalid data type map<string,decimal(9,2)>. (DATALAKE_DATABASE_ERROR)\n\n### Additional context\n\nI was using PyIceberg to create iceberg table and change schema.\nAs glue catalog I used localstack.\n\nI checked that I can correctly read table with PyIceberg and Spark to eliminate localstack as cause of a bug. When I was using rest catalog and PyIceberg, I was able to read tables with such schema.\n",
  "hints_text": "",
  "created_at": "2025-06-18T15:51:57Z"
}