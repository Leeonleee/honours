{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 48299,
  "instance_id": "ClickHouse__ClickHouse-48299",
  "issue_numbers": [
    "47947"
  ],
  "base_commit": "1478bcc43760a3617a88b256294db647aa3c6af6",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex f9848b572f93..65a3391b4e01 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -6067,51 +6067,48 @@ bool MergeTreeData::isPrimaryOrMinMaxKeyColumnPossiblyWrappedInFunctions(\n }\n \n bool MergeTreeData::mayBenefitFromIndexForIn(\n-    const ASTPtr & left_in_operand, ContextPtr, const StorageMetadataPtr & metadata_snapshot) const\n+    const ASTPtr & left_in_operand, ContextPtr query_context, const StorageMetadataPtr & metadata_snapshot) const\n {\n     /// Make sure that the left side of the IN operator contain part of the key.\n     /// If there is a tuple on the left side of the IN operator, at least one item of the tuple\n-    ///  must be part of the key (probably wrapped by a chain of some acceptable functions).\n+    /// must be part of the key (probably wrapped by a chain of some acceptable functions).\n     const auto * left_in_operand_tuple = left_in_operand->as<ASTFunction>();\n-    const auto & index_wrapper_factory = MergeTreeIndexFactory::instance();\n-    if (left_in_operand_tuple && left_in_operand_tuple->name == \"tuple\")\n+    const auto & index_factory = MergeTreeIndexFactory::instance();\n+    const auto & query_settings = query_context->getSettingsRef();\n+\n+    auto check_for_one_argument = [&](const auto & ast)\n     {\n-        for (const auto & item : left_in_operand_tuple->arguments->children)\n+        if (isPrimaryOrMinMaxKeyColumnPossiblyWrappedInFunctions(ast, metadata_snapshot))\n+            return true;\n+\n+        if (query_settings.use_skip_indexes)\n         {\n-            if (isPrimaryOrMinMaxKeyColumnPossiblyWrappedInFunctions(item, metadata_snapshot))\n-                return true;\n             for (const auto & index : metadata_snapshot->getSecondaryIndices())\n-                if (index_wrapper_factory.get(index)->mayBenefitFromIndexForIn(item))\n-                    return true;\n-            for (const auto & projection : metadata_snapshot->getProjections())\n-            {\n-                if (projection.isPrimaryKeyColumnPossiblyWrappedInFunctions(item))\n+                if (index_factory.get(index)->mayBenefitFromIndexForIn(ast))\n                     return true;\n-            }\n         }\n-        /// The tuple itself may be part of the primary key, so check that as a last resort.\n-        if (isPrimaryOrMinMaxKeyColumnPossiblyWrappedInFunctions(left_in_operand, metadata_snapshot))\n-            return true;\n-        for (const auto & projection : metadata_snapshot->getProjections())\n+\n+        if (query_settings.allow_experimental_projection_optimization)\n         {\n-            if (projection.isPrimaryKeyColumnPossiblyWrappedInFunctions(left_in_operand))\n-                return true;\n+            for (const auto & projection : metadata_snapshot->getProjections())\n+                if (projection.isPrimaryKeyColumnPossiblyWrappedInFunctions(ast))\n+                    return true;\n         }\n+\n         return false;\n-    }\n-    else\n+    };\n+\n+    if (left_in_operand_tuple && left_in_operand_tuple->name == \"tuple\")\n     {\n-        for (const auto & index : metadata_snapshot->getSecondaryIndices())\n-            if (index_wrapper_factory.get(index)->mayBenefitFromIndexForIn(left_in_operand))\n+        for (const auto & item : left_in_operand_tuple->arguments->children)\n+            if (check_for_one_argument(item))\n                 return true;\n \n-        for (const auto & projection : metadata_snapshot->getProjections())\n-        {\n-            if (projection.isPrimaryKeyColumnPossiblyWrappedInFunctions(left_in_operand))\n-                return true;\n-        }\n-        return isPrimaryOrMinMaxKeyColumnPossiblyWrappedInFunctions(left_in_operand, metadata_snapshot);\n+        /// The tuple itself may be part of the primary key\n+        /// or skip index, so check that as a last resort.\n     }\n+\n+    return check_for_one_argument(left_in_operand);\n }\n \n using PartitionIdToMaxBlock = std::unordered_map<String, Int64>;\n",
  "test_patch": "diff --git a/tests/performance/set_disable_skip_index.xml b/tests/performance/set_disable_skip_index.xml\nnew file mode 100644\nindex 000000000000..5769f30eac93\n--- /dev/null\n+++ b/tests/performance/set_disable_skip_index.xml\n@@ -0,0 +1,17 @@\n+<test>\n+    <create_query>\n+        CREATE TABLE test_in_skip_idx\n+        (\n+            a UInt64,\n+            s String,\n+            INDEX idx s TYPE bloom_filter GRANULARITY 1\n+        )\n+        ENGINE = MergeTree() ORDER BY a\n+    </create_query>\n+\n+    <fill_query>INSERT INTO test_in_skip_idx SELECT number, number FROM numbers(10000000)</fill_query>\n+    <fill_query>OPTIMIZE TABLE test_in_skip_idx FINAL</fill_query>\n+\n+    <query>SELECT count() FROM test_in_skip_idx WHERE s IN (SELECT toString(number + 10000000) FROM numbers(100000)) SETTINGS use_skip_indexes = 0</query>\n+    <drop_query>DROP TABLE IF EXISTS test_in_skip_idx</drop_query>\n+</test>\ndiff --git a/tests/queries/0_stateless/02707_skip_index_with_in.reference b/tests/queries/0_stateless/02707_skip_index_with_in.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/02707_skip_index_with_in.sql b/tests/queries/0_stateless/02707_skip_index_with_in.sql\nnew file mode 100644\nindex 000000000000..4767619cee19\n--- /dev/null\n+++ b/tests/queries/0_stateless/02707_skip_index_with_in.sql\n@@ -0,0 +1,20 @@\n+DROP TABLE IF EXISTS t_skip_index_in;\n+\n+CREATE TABLE t_skip_index_in\n+(\n+    a String,\n+    b String,\n+    c String,\n+    INDEX idx_c c TYPE bloom_filter GRANULARITY 1\n+)\n+ENGINE = MergeTree\n+ORDER BY (a, b);\n+\n+INSERT INTO t_skip_index_in VALUES ('a', 'b', 'c');\n+\n+-- This query checks that set is not being built if indexes are not used,\n+-- because with EXPLAIN the set will be built only for analysis of indexes.\n+EXPLAIN SELECT count() FROM t_skip_index_in WHERE c IN (SELECT throwIf(1)) SETTINGS use_skip_indexes = 0 FORMAT Null;\n+EXPLAIN SELECT count() FROM t_skip_index_in WHERE c IN (SELECT throwIf(1)) SETTINGS use_skip_indexes = 1; -- { serverError FUNCTION_THROW_IF_VALUE_IS_NON_ZERO }\n+\n+DROP TABLE t_skip_index_in;\n",
  "problem_statement": "ClickHouse spends time in makeSetsForIndex for skip index with use_skip_indexes=0\n**Describe the situation**\r\nWhen you have a skip index defined on a table and are using an `IN (...)` construction, ClickHouse will always spend time in `makeSetsForIndex` regardless of the value of `use_skip_indexes`.\r\n\r\nFor some of our queries, evaluating the skip index takes more time than just reading all the rows so we set `use_skip_indexes=0` for these queries. However, we still see significant performance regression on these queries from simply having a skip index defined on the table because of the time spent in `makeSetsForIndex`.\r\n\r\nSetting `use_skip_indexes=0` and `use_index_for_in_with_subqueries=0` resolves the performance regression\r\n\r\n**Expected performance**\r\nI would expect us not to do any work related to skip indexes if `use_skip_indexes` is set to 0\r\n\r\n\n",
  "hints_text": "`makeSetsForIndex` is related to analysis of primary index, not skip indexes. So, the behaviour is expected. The correct settings to disable analysis of large sets is `use_index_for_in_with_subqueries`, as you mentioned.\nGot it - possible I'm misunderstanding what's happening in that function. If that's the case though, why would disabling it remove the performance overhead of the skip index?\r\n\r\nIf we don't have the skip index defined, there's no performance difference between use_index_for_in_with_subqueries=1 and use_index_for_in_with_subqueries=0\n@CurtizJ I think I may have tracked down what's happening here. This is the relevant code block that uses `use_index_for_in_with_subqueries` in ExpressionAnalyzer.cpp:\r\n\r\n```\r\n        if (storage()->mayBenefitFromIndexForIn(left_in_operand, getContext(), metadata_snapshot))\r\n        {\r\n            const ASTPtr & arg = args.children.at(1);\r\n            if (arg->as<ASTSubquery>() || arg->as<ASTTableIdentifier>())\r\n            {\r\n                if (settings.use_index_for_in_with_subqueries)\r\n                    tryMakeSetForIndexFromSubquery(arg, query_options);\r\n            }\r\n            else\r\n            {\r\n                auto temp_actions = std::make_shared<ActionsDAG>(columns_after_join);\r\n                getRootActions(left_in_operand, true, temp_actions);\r\n\r\n                if (prepared_sets && temp_actions->tryFindInOutputs(left_in_operand->getColumnName()))\r\n                    makeExplicitSet(func, *temp_actions, true, getContext(), settings.size_limits_for_set, *prepared_sets);\r\n            }\r\n        }\r\n```\r\n\r\nit's guarded by this call to `mayBenefitFromIndexForIn` - if I track that down to MergeTreeData.cpp we see it takes into account secondary indices as well as primary index:\r\n\r\n```\r\n            if (isPrimaryOrMinMaxKeyColumnPossiblyWrappedInFunctions(item, metadata_snapshot))\r\n                return true;\r\n            for (const auto & index : metadata_snapshot->getSecondaryIndices())\r\n                if (index_wrapper_factory.get(index)->mayBenefitFromIndexForIn(item))\r\n                    return true;\r\n```\r\n\r\nI don't see us accounting for the `use_skip_indexes` setting within `mayBenefitFromIndexForIn` which seems wrong since we aren't going to be using the secondary index at all if `use_skip_indexes=0`.\r\n\r\nThis makes me think that `makeSetsForIndex` is used for _both_ primary index and secondary indices - does this sound right to you?\nadding repro steps:\r\n\r\nfirst, create a table like:\r\n\r\n```\r\nCREATE TABLE default.index_perf_repro\r\n(\r\n    `a` String,\r\n    `b` String,\r\n    `c` String,\r\n    INDEX idx_c c TYPE bloom_filter GRANULARITY 1\r\n)\r\nENGINE = MergeTree\r\nORDER BY (a, b)\r\nSETTINGS index_granularity = 8192\r\n```\r\n\r\ninsert a bunch of data:\r\n\r\n```\r\ninsert into index_perf_repro select * from generateRandom('a String, b String, c String') limit 5000000;\r\n```\r\n\r\nquery using an `IN (subquery)` construction filtering over `c`:\r\n\r\n```\r\nSELECT count()\r\nFROM index_perf_repro\r\nWHERE (c IN (\r\n    SELECT *\r\n    FROM generateRandom('c String')\r\n    LIMIT 100000000\r\n)) AND startsWith(a, 'a')\r\n```\r\n\r\nthe key is the inner query result set needs to be very large for the time spent building sets to be noticeable in the trace logs\r\n\r\n\r\nsome example queries w/ the various configurations:\r\n\r\nfirst, save target list of `c` values to temporary table\r\n```\r\nCREATE TEMPORARY TABLE target_c AS\r\nSELECT *\r\nFROM generateRandom('c String')\r\nLIMIT 100000000\r\n```\r\n\r\n\r\nindex defined, use_skip_indexes=1, use_index_for_in_with_subqueries=1 takes ~20sec\r\n```\r\nSELECT count()\r\nFROM index_perf_repro\r\nWHERE (c IN (\r\n    SELECT *\r\n    FROM target_c\r\n)) AND startsWith(a, 'a')\r\nSETTINGS use_skip_indexes = 1, use_index_for_in_with_subqueries = 1\r\n```\r\n\r\nindex defined, use_skip_indexes=0, use_index_for_in_with_subqueries=1 takes ~19sec\r\n```\r\nSELECT count()\r\nFROM index_perf_repro\r\nWHERE (c IN (\r\n    SELECT *\r\n    FROM target_c\r\n)) AND startsWith(a, 'a')\r\nSETTINGS use_skip_indexes = 0, use_index_for_in_with_subqueries = 1\r\n```\r\n\r\nindex defined, use_skip_indexes=0, use_index_for_in_with_subqueries=0 takes ~17sec\r\n```\r\nSELECT count()\r\nFROM index_perf_repro\r\nWHERE (c IN (\r\n    SELECT *\r\n    FROM target_c\r\n)) AND startsWith(a, 'a')\r\nSETTINGS use_skip_indexes = 0, use_index_for_in_with_subqueries = 0\r\n```\r\n\r\nindex not defined takes ~17sec\r\n```\r\nALTER TABLE index_perf_repro\r\n    DROP INDEX idx_c;\r\n\r\nSELECT count()\r\nFROM index_perf_repro\r\nWHERE (c IN (\r\n    SELECT *\r\n    FROM target_c\r\n)) AND startsWith(a, 'a');\r\n```\nGot it, thank you. Looks like a real issue.",
  "created_at": "2023-03-31T16:13:28Z"
}