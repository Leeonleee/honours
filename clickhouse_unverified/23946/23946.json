{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 23946,
  "instance_id": "ClickHouse__ClickHouse-23946",
  "issue_numbers": [
    "8912"
  ],
  "base_commit": "e6ac136c3276495e675118a3dfce999a936f8a4d",
  "patch": "diff --git a/src/Dictionaries/HTTPDictionarySource.cpp b/src/Dictionaries/HTTPDictionarySource.cpp\nindex b674d5934448..8e0108f5562f 100644\n--- a/src/Dictionaries/HTTPDictionarySource.cpp\n+++ b/src/Dictionaries/HTTPDictionarySource.cpp\n@@ -42,7 +42,6 @@ HTTPDictionarySource::HTTPDictionarySource(\n     , context(context_)\n     , timeouts(ConnectionTimeouts::getHTTPTimeouts(context))\n {\n-\n     if (check_config)\n         context->getRemoteHostFilter().checkURL(Poco::URI(url));\n \n@@ -87,6 +86,16 @@ HTTPDictionarySource::HTTPDictionarySource(const HTTPDictionarySource & other)\n     credentials.setPassword(other.credentials.getPassword());\n }\n \n+BlockInputStreamPtr HTTPDictionarySource::createWrappedBuffer(std::unique_ptr<ReadWriteBufferFromHTTP> http_buffer_ptr)\n+{\n+    Poco::URI uri(url);\n+    String http_request_compression_method_str = http_buffer_ptr->getCompressMethod();\n+    auto in_ptr_wrapped\n+        = wrapReadBufferWithCompressionMethod(std::move(http_buffer_ptr), chooseCompressionMethod(uri.getPath(), http_request_compression_method_str));\n+    auto input_stream = context->getInputFormat(format, *in_ptr_wrapped, sample_block, max_block_size);\n+    return std::make_shared<OwningBlockInputStream<ReadBuffer>>(input_stream, std::move(in_ptr_wrapped));\n+}\n+\n void HTTPDictionarySource::getUpdateFieldAndDate(Poco::URI & uri)\n {\n     if (update_time != std::chrono::system_clock::from_time_t(0))\n@@ -109,10 +118,15 @@ BlockInputStreamPtr HTTPDictionarySource::loadAll()\n     LOG_TRACE(log, \"loadAll {}\", toString());\n     Poco::URI uri(url);\n     auto in_ptr = std::make_unique<ReadWriteBufferFromHTTP>(\n-        uri, Poco::Net::HTTPRequest::HTTP_GET, ReadWriteBufferFromHTTP::OutStreamCallback(), timeouts,\n-        0, credentials, DBMS_DEFAULT_BUFFER_SIZE, header_entries);\n-    auto input_stream = context->getInputFormat(format, *in_ptr, sample_block, max_block_size);\n-    return std::make_shared<OwningBlockInputStream<ReadWriteBufferFromHTTP>>(input_stream, std::move(in_ptr));\n+        uri,\n+        Poco::Net::HTTPRequest::HTTP_GET,\n+        ReadWriteBufferFromHTTP::OutStreamCallback(),\n+        timeouts,\n+        0,\n+        credentials,\n+        DBMS_DEFAULT_BUFFER_SIZE,\n+        header_entries);\n+    return createWrappedBuffer(std::move(in_ptr));\n }\n \n BlockInputStreamPtr HTTPDictionarySource::loadUpdatedAll()\n@@ -121,10 +135,15 @@ BlockInputStreamPtr HTTPDictionarySource::loadUpdatedAll()\n     getUpdateFieldAndDate(uri);\n     LOG_TRACE(log, \"loadUpdatedAll {}\", uri.toString());\n     auto in_ptr = std::make_unique<ReadWriteBufferFromHTTP>(\n-        uri, Poco::Net::HTTPRequest::HTTP_GET, ReadWriteBufferFromHTTP::OutStreamCallback(), timeouts,\n-        0, credentials, DBMS_DEFAULT_BUFFER_SIZE, header_entries);\n-    auto input_stream = context->getInputFormat(format, *in_ptr, sample_block, max_block_size);\n-    return std::make_shared<OwningBlockInputStream<ReadWriteBufferFromHTTP>>(input_stream, std::move(in_ptr));\n+        uri,\n+        Poco::Net::HTTPRequest::HTTP_GET,\n+        ReadWriteBufferFromHTTP::OutStreamCallback(),\n+        timeouts,\n+        0,\n+        credentials,\n+        DBMS_DEFAULT_BUFFER_SIZE,\n+        header_entries);\n+    return createWrappedBuffer(std::move(in_ptr));\n }\n \n BlockInputStreamPtr HTTPDictionarySource::loadIds(const std::vector<UInt64> & ids)\n@@ -142,10 +161,15 @@ BlockInputStreamPtr HTTPDictionarySource::loadIds(const std::vector<UInt64> & id\n \n     Poco::URI uri(url);\n     auto in_ptr = std::make_unique<ReadWriteBufferFromHTTP>(\n-        uri, Poco::Net::HTTPRequest::HTTP_POST, out_stream_callback, timeouts,\n-        0, credentials, DBMS_DEFAULT_BUFFER_SIZE, header_entries);\n-    auto input_stream = context->getInputFormat(format, *in_ptr, sample_block, max_block_size);\n-    return std::make_shared<OwningBlockInputStream<ReadWriteBufferFromHTTP>>(input_stream, std::move(in_ptr));\n+        uri,\n+        Poco::Net::HTTPRequest::HTTP_POST,\n+        out_stream_callback,\n+        timeouts,\n+        0,\n+        credentials,\n+        DBMS_DEFAULT_BUFFER_SIZE,\n+        header_entries);\n+    return createWrappedBuffer(std::move(in_ptr));\n }\n \n BlockInputStreamPtr HTTPDictionarySource::loadKeys(const Columns & key_columns, const std::vector<size_t> & requested_rows)\n@@ -163,10 +187,15 @@ BlockInputStreamPtr HTTPDictionarySource::loadKeys(const Columns & key_columns,\n \n     Poco::URI uri(url);\n     auto in_ptr = std::make_unique<ReadWriteBufferFromHTTP>(\n-        uri, Poco::Net::HTTPRequest::HTTP_POST, out_stream_callback, timeouts,\n-        0, credentials, DBMS_DEFAULT_BUFFER_SIZE, header_entries);\n-    auto input_stream = context->getInputFormat(format, *in_ptr, sample_block, max_block_size);\n-    return std::make_shared<OwningBlockInputStream<ReadWriteBufferFromHTTP>>(input_stream, std::move(in_ptr));\n+        uri,\n+        Poco::Net::HTTPRequest::HTTP_POST,\n+        out_stream_callback,\n+        timeouts,\n+        0,\n+        credentials,\n+        DBMS_DEFAULT_BUFFER_SIZE,\n+        header_entries);\n+    return createWrappedBuffer(std::move(in_ptr));\n }\n \n bool HTTPDictionarySource::isModified() const\n@@ -198,21 +227,19 @@ std::string HTTPDictionarySource::toString() const\n void registerDictionarySourceHTTP(DictionarySourceFactory & factory)\n {\n     auto create_table_source = [=](const DictionaryStructure & dict_struct,\n-                                 const Poco::Util::AbstractConfiguration & config,\n-                                 const std::string & config_prefix,\n-                                 Block & sample_block,\n-                                 ContextPtr context,\n-                                 const std::string & /* default_database */,\n-                                 bool check_config) -> DictionarySourcePtr\n-    {\n+                                   const Poco::Util::AbstractConfiguration & config,\n+                                   const std::string & config_prefix,\n+                                   Block & sample_block,\n+                                   ContextPtr context,\n+                                   const std::string & /* default_database */,\n+                                   bool check_config) -> DictionarySourcePtr {\n         if (dict_struct.has_expressions)\n             throw Exception(ErrorCodes::LOGICAL_ERROR, \"Dictionary source of type `http` does not support attribute expressions\");\n \n         auto context_local_copy = copyContextAndApplySettings(config_prefix, context, config);\n \n         return std::make_unique<HTTPDictionarySource>(\n-            dict_struct, config, config_prefix + \".http\",\n-            sample_block, context_local_copy, check_config);\n+            dict_struct, config, config_prefix + \".http\", sample_block, context_local_copy, check_config);\n     };\n     factory.registerSource(\"http\", create_table_source);\n }\ndiff --git a/src/Dictionaries/HTTPDictionarySource.h b/src/Dictionaries/HTTPDictionarySource.h\nindex c42c67ec8c9f..5b48e8a5a9c1 100644\n--- a/src/Dictionaries/HTTPDictionarySource.h\n+++ b/src/Dictionaries/HTTPDictionarySource.h\n@@ -8,6 +8,7 @@\n #include \"DictionaryStructure.h\"\n #include \"IDictionarySource.h\"\n #include <Interpreters/Context.h>\n+#include <IO/CompressionMethod.h>\n \n namespace Poco\n {\n@@ -53,6 +54,9 @@ class HTTPDictionarySource final : public IDictionarySource\n private:\n     void getUpdateFieldAndDate(Poco::URI & uri);\n \n+    // wrap buffer using encoding from made request\n+    BlockInputStreamPtr createWrappedBuffer(std::unique_ptr<ReadWriteBufferFromHTTP> http_buffer);\n+\n     Poco::Logger * log;\n \n     LocalDateTime getLastModification() const;\n@@ -70,3 +74,4 @@ class HTTPDictionarySource final : public IDictionarySource\n };\n \n }\n+\ndiff --git a/src/IO/CompressionMethod.cpp b/src/IO/CompressionMethod.cpp\nindex 6e437e34c105..c6bb5232c0ca 100644\n--- a/src/IO/CompressionMethod.cpp\n+++ b/src/IO/CompressionMethod.cpp\n@@ -46,7 +46,6 @@ std::string toContentEncodingName(CompressionMethod method)\n     __builtin_unreachable();\n }\n \n-\n CompressionMethod chooseCompressionMethod(const std::string & path, const std::string & hint)\n {\n     std::string file_extension;\ndiff --git a/src/IO/ReadWriteBufferFromHTTP.h b/src/IO/ReadWriteBufferFromHTTP.h\nindex 9cd37bd00f8e..16120de1525c 100644\n--- a/src/IO/ReadWriteBufferFromHTTP.h\n+++ b/src/IO/ReadWriteBufferFromHTTP.h\n@@ -91,7 +91,7 @@ namespace detail\n \n     protected:\n         Poco::URI uri;\n-        std::string method;\n+        std::string method, content_encoding;\n \n         UpdatableSessionPtr session;\n         std::istream * istr; /// owned by session\n@@ -137,6 +137,7 @@ namespace detail\n                 istr = receiveResponse(*sess, request, response, true);\n                 response.getCookies(cookies);\n \n+                content_encoding = response.get(\"Content-Encoding\", \"\");\n                 return istr;\n \n             }\n@@ -230,6 +231,11 @@ namespace detail\n             /// Some data maybe already read\n             next_callback(count());\n         }\n+\n+        const std::string& getCompressMethod() const\n+        {\n+            return content_encoding;\n+        }\n     };\n }\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01854_HTTP_dict_decompression.python b/tests/queries/0_stateless/01854_HTTP_dict_decompression.python\nnew file mode 100644\nindex 000000000000..98581a1e47cd\n--- /dev/null\n+++ b/tests/queries/0_stateless/01854_HTTP_dict_decompression.python\n@@ -0,0 +1,168 @@\n+#!/usr/bin/env python3\n+\n+from http.server import SimpleHTTPRequestHandler,HTTPServer\n+import socket\n+import csv\n+import sys\n+import tempfile\n+import threading\n+import os\n+import gzip\n+import traceback\n+import urllib.request\n+import subprocess\n+import lzma\n+\n+def get_local_port(host):\n+    with socket.socket() as fd:\n+        fd.bind((host, 0))\n+        return fd.getsockname()[1]\n+\n+CLICKHOUSE_HOST = os.environ.get('CLICKHOUSE_HOST', '127.0.0.1')\n+CLICKHOUSE_PORT_HTTP = os.environ.get('CLICKHOUSE_PORT_HTTP', '8123')\n+\n+#####################################################################################\n+# This test starts an HTTP server and serves data to clickhouse url-engine based table.\n+# The main goal of this test is checking that compress methods are working.\n+# In order for it to work ip+port of http server (given below) should be\n+# accessible from clickhouse server.\n+#####################################################################################\n+\n+# IP-address of this host accessible from outside world.\n+HTTP_SERVER_HOST = subprocess.check_output(['hostname', '-i']).decode('utf-8').strip()\n+HTTP_SERVER_PORT = get_local_port(HTTP_SERVER_HOST)\n+\n+# IP address and port of the HTTP server started from this script.\n+HTTP_SERVER_ADDRESS = (HTTP_SERVER_HOST, HTTP_SERVER_PORT)\n+HTTP_SERVER_URL_STR = 'http://' + ':'.join(str(s) for s in HTTP_SERVER_ADDRESS) + \"/\"\n+\n+# Because we need to check content of file.csv we can create this content and avoid reading csv \n+CSV_DATA = \"Hello, 1\\nWorld, 2\\nThis, 152\\nis, 9283\\ntesting, 2313213\\ndata, 555\\n\"\n+\n+\n+# Choose compression method \n+# (Will change during test, need to check standart data sending, to make sure that nothing broke)\n+COMPRESS_METHOD = 'none'\n+ADDING_ENDING = ''\n+ENDINGS = ['.gz', '.xz']\n+SEND_ENCODING = True\n+\n+def get_ch_answer(query):\n+    url = os.environ.get('CLICKHOUSE_URL', 'http://{host}:{port}'.format(host=CLICKHOUSE_HOST, port=CLICKHOUSE_PORT_HTTP))\n+    return urllib.request.urlopen(url, data=query.encode()).read().decode()\n+\n+def check_answers(query, answer):\n+    ch_answer = get_ch_answer(query)\n+    if ch_answer.strip() != answer.strip():\n+        print(\"FAIL on query:\", query, file=sys.stderr)\n+        print(\"Expected answer:\", answer, file=sys.stderr)\n+        print(\"Fetched answer :\", ch_answer, file=sys.stderr)\n+        raise Exception(\"Fail on query\")\n+\n+# Server with head method which is useful for debuging by hands\n+class HttpProcessor(SimpleHTTPRequestHandler):\n+    def _set_headers(self):\n+        self.send_response(200)\n+        if SEND_ENCODING:\n+            self.send_header('Content-Encoding', COMPRESS_METHOD)\n+        if COMPRESS_METHOD == 'none':\n+            self.send_header('Content-Length', len(CSV_DATA.encode()))\n+        else:\n+            self.compress_data()\n+            self.send_header('Content-Length', len(self.data))\n+        self.send_header('Content-Type', 'text/csv')\n+        self.end_headers()\n+\n+    def do_HEAD(self):\n+        self._set_headers()\n+        return\n+\n+    def compress_data(self):\n+        if COMPRESS_METHOD == 'gzip':\n+            self.data = gzip.compress((CSV_DATA).encode())\n+        elif COMPRESS_METHOD == 'lzma':\n+            self.data = lzma.compress((CSV_DATA).encode())\n+        else:\n+            self.data = 'WRONG CONVERSATION'.encode()\n+\n+\n+    def do_GET(self):\n+        self._set_headers()\n+    \n+        if COMPRESS_METHOD == 'none':\n+            self.wfile.write(CSV_DATA.encode())\n+        else:\n+            self.wfile.write(self.data)\n+        return\n+\n+    def log_message(self, format, *args):\n+        return\n+\n+def start_server(requests_amount):\n+    httpd = HTTPServer(HTTP_SERVER_ADDRESS, HttpProcessor)\n+\n+    def real_func():\n+        for i in range(requests_amount):\n+            httpd.handle_request()\n+\n+    t = threading.Thread(target=real_func)\n+    return t\n+\n+#####################################################################\n+# Testing area.\n+#####################################################################\n+\n+def test_select(dict_name=\"\", schema=\"word String, counter UInt32\", requests=[], answers=[], test_data=\"\"):\n+    global ADDING_ENDING\n+    global SEND_ENCODING\n+    global COMPRESS_METHOD\n+    for i in range(len(requests)):\n+        if i > 2:\n+            ADDING_ENDING = ENDINGS[i-3]\n+            SEND_ENCODING = False\n+        \n+        if dict_name:\n+            get_ch_answer(\"drop dictionary if exists {}\".format(dict_name))\n+            get_ch_answer('''CREATE DICTIONARY {} ({})\n+            PRIMARY KEY word\n+            SOURCE(HTTP(url '{}' format 'CSV'))\n+            LAYOUT(complex_key_hashed())\n+            LIFETIME(0)'''.format(dict_name, schema, HTTP_SERVER_URL_STR+'/test.csv' + ADDING_ENDING))\n+\n+        COMPRESS_METHOD = requests[i]\n+        print(i, COMPRESS_METHOD, ADDING_ENDING, SEND_ENCODING)\n+        check_answers(\"select * from {}\".format(dict_name), answers[i])\n+\n+def main():\n+    # first three for encoding, second three for url\n+    insert_requests = [\n+            'none',\n+            'gzip',\n+            'lzma',\n+            'gzip',\n+            'lzma'\n+    ]\n+\n+    # This answers got experemently in non compressed mode and they are correct\n+    answers = ['''This\t152\\nHello\t1\\nis\t9283\\ndata\t555\\nWorld\t2\\ntesting\t2313213'''] * 5\n+\n+    t = start_server(len(insert_requests))\n+    t.start()\n+    test_select(dict_name=\"test_table_select\", requests=insert_requests, answers=answers)\n+    t.join()\n+    print(\"PASSED\")\n+\n+\n+\n+if __name__ == \"__main__\":\n+    try:\n+        main()\n+    except Exception as ex:\n+        exc_type, exc_value, exc_traceback = sys.exc_info()\n+        traceback.print_tb(exc_traceback, file=sys.stderr)\n+        print(ex, file=sys.stderr)\n+        sys.stderr.flush()\n+\n+        os._exit(1)\n+\n+\ndiff --git a/tests/queries/0_stateless/01854_HTTP_dict_decompression.reference b/tests/queries/0_stateless/01854_HTTP_dict_decompression.reference\nnew file mode 100644\nindex 000000000000..61bde4a97364\n--- /dev/null\n+++ b/tests/queries/0_stateless/01854_HTTP_dict_decompression.reference\n@@ -0,0 +1,6 @@\n+0 none  True\n+1 gzip  True\n+2 lzma  True\n+3 gzip .gz False\n+4 lzma .xz False\n+PASSED\ndiff --git a/tests/queries/0_stateless/01854_HTTP_dict_decompression.sh b/tests/queries/0_stateless/01854_HTTP_dict_decompression.sh\nnew file mode 100755\nindex 000000000000..cca710e85cf0\n--- /dev/null\n+++ b/tests/queries/0_stateless/01854_HTTP_dict_decompression.sh\n@@ -0,0 +1,7 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+python3 \"$CURDIR\"/01854_HTTP_dict_decompression.python\n",
  "problem_statement": "HTTP dictionary source doesn't support HTTP compression\n**Describe the bug or unexpected behaviour**\r\nClickHouse silently fails to import dictionaries over HTTP with forced HTTP compression.\r\n\r\n**How to reproduce**\r\nClickHouse server version 19.17.6 revision 54428\r\n\r\n1. Upload pre-compressed dictionary file with correct Content-Encoding header to S3:\r\n    ```\r\n    $ http -h HEAD https://xxx/xxx.csv | grep Content\r\n    Content-Type: text/csv\r\n    Content-Length: 45533570\r\n    Content-Encoding: gzip\r\n    ```\r\n2. Create dictionary\r\n    ```\r\n    CREATE DICTIONARY ipreg (\r\n        prefix String,\r\n        region_id UInt32\r\n    )\r\n    PRIMARY KEY prefix\r\n    SOURCE(HTTP(url 'https://xxx/xxx.csv' format 'CSV'))\r\n    LAYOUT(IP_TRIE())\r\n    LIFETIME(0)\r\n    ```\r\n\r\n3. Check dictionary\r\n    ```\r\n    SELECT *\r\n    FROM system.dictionaries\r\n\r\n    Row 1:\r\n    \u2500\u2500\u2500\u2500\u2500\u2500\r\n    database:           logs\r\n    name:               ipreg\r\n    status:             LOADED\r\n    origin:             logs.ipreg\r\n    type:               Trie\r\n    key:                (String)\r\n    attribute.names:    ['region_id']\r\n    attribute.types:    ['UInt32']\r\n    bytes_allocated:    0\r\n    query_count:        0\r\n    hit_rate:           1\r\n    element_count:      0\r\n    load_factor:        nan\r\n    source:             https://xxx/xxx.csv\r\n    loading_start_time: 2020-01-28 23:07:37\r\n    loading_duration:   0.083\r\n    last_exception:     \r\n\r\n    1 rows in set. Elapsed: 0.038 sec. \r\n    ```\r\n   It's not imported.\r\n\r\n**Expected behavior**\r\nClickHouse imports dictionary or explicitly fails.\n",
  "hints_text": "Issue is taken. Will be fixed soon",
  "created_at": "2021-05-07T23:25:49Z"
}