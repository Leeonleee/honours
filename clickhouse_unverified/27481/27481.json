{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 27481,
  "instance_id": "ClickHouse__ClickHouse-27481",
  "issue_numbers": [
    "26175"
  ],
  "base_commit": "ce739d1c32bef4df0b286137a88f990de795955b",
  "patch": "diff --git a/src/AggregateFunctions/AggregateFunctionSparkbar.cpp b/src/AggregateFunctions/AggregateFunctionSparkbar.cpp\nnew file mode 100644\nindex 000000000000..7f1196173a75\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionSparkbar.cpp\n@@ -0,0 +1,72 @@\n+#include <AggregateFunctions/AggregateFunctionSparkbar.h>\n+#include <AggregateFunctions/FactoryHelpers.h>\n+#include <AggregateFunctions/Helpers.h>\n+#include <AggregateFunctions/AggregateFunctionFactory.h>\n+\n+\n+namespace DB\n+{\n+\n+struct Settings;\n+\n+namespace ErrorCodes\n+{\n+    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+}\n+\n+namespace\n+{\n+\n+template <template <typename, typename> class AggregateFunctionTemplate, typename Data, typename ... TArgs>\n+static IAggregateFunction * createWithUIntegerOrTimeType(const std::string & name, const IDataType & argument_type, TArgs && ... args)\n+{\n+    WhichDataType which(argument_type);\n+    if (which.idx == TypeIndex::Date || which.idx == TypeIndex::UInt16) return new AggregateFunctionTemplate<UInt16, Data>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::DateTime || which.idx == TypeIndex::UInt32) return new AggregateFunctionTemplate<UInt32, Data>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::UInt8) return new AggregateFunctionTemplate<UInt8, Data>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::UInt64) return new AggregateFunctionTemplate<UInt64, Data>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::UInt128) return new AggregateFunctionTemplate<UInt128, Data>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::UInt256) return new AggregateFunctionTemplate<UInt256, Data>(std::forward<TArgs>(args)...);\n+    throw Exception(\"The first argument type must be UInt or Date or DateTime for aggregate function \" + name, ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT);\n+}\n+\n+template <typename ... TArgs>\n+AggregateFunctionPtr createAggregateFunctionSparkbarImpl(const std::string & name, const IDataType & x_argument_type, const IDataType & y_argument_type, TArgs ... args)\n+{\n+    WhichDataType which(y_argument_type);\n+#define DISPATCH(TYPE) \\\n+    if (which.idx == TypeIndex::TYPE) return AggregateFunctionPtr(createWithUIntegerOrTimeType<AggregateFunctionSparkbar, TYPE>(name, x_argument_type, std::forward<TArgs>(args)...));\n+    FOR_NUMERIC_TYPES(DISPATCH)\n+#undef DISPATCH\n+\n+    throw Exception(\"The second argument type must be numeric for aggregate function \" + name, ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT);\n+}\n+\n+\n+AggregateFunctionPtr createAggregateFunctionSparkbar(const std::string & name, const DataTypes & arguments, const Array & params, const Settings *)\n+{\n+    assertBinary(name, arguments);\n+\n+    if (params.size() != 1 && params.size() != 3)\n+        throw Exception(\"The number of params does not match for aggregate function \" + name, ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH);\n+\n+    if (params.size() == 3)\n+    {\n+        if (params.at(1).getType() != arguments[0]->getDefault().getType() || params.at(2).getType() != arguments[0]->getDefault().getType())\n+        {\n+            throw Exception(\"The second and third parameters are not the same type as the first arguments for aggregate function \" + name, ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT);\n+        }\n+    }\n+    return createAggregateFunctionSparkbarImpl(name, *arguments[0], *arguments[1], arguments, params);\n+}\n+\n+\n+}\n+\n+void registerAggregateFunctionSparkbar(AggregateFunctionFactory & factory)\n+{\n+    factory.registerFunction(\"sparkbar\", createAggregateFunctionSparkbar);\n+}\n+\n+}\ndiff --git a/src/AggregateFunctions/AggregateFunctionSparkbar.h b/src/AggregateFunctions/AggregateFunctionSparkbar.h\nnew file mode 100644\nindex 000000000000..51c10d05f6fe\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionSparkbar.h\n@@ -0,0 +1,309 @@\n+#pragma once\n+\n+#include <DataTypes/DataTypeString.h>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <common/range.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+#include <Columns/ColumnString.h>\n+#include <common/logger_useful.h>\n+#include <IO/ReadBufferFromString.h>\n+#include <Common/HashTable/HashMap.h>\n+\n+namespace DB\n+{\n+\n+template<typename X, typename Y>\n+struct AggregateFunctionSparkbarData\n+{\n+\n+    using Points = HashMap<X, Y>;\n+    Points points;\n+\n+    X min_x = std::numeric_limits<X>::max();\n+    X max_x = std::numeric_limits<X>::lowest();\n+\n+    Y min_y = std::numeric_limits<Y>::max();\n+    Y max_y = std::numeric_limits<Y>::lowest();\n+\n+    void insert(const X & x, const Y & y)\n+    {\n+        auto result = points.insert({x, y});\n+        if (!result.second)\n+            result.first->getMapped() += y;\n+    }\n+\n+    void add(X x, Y y)\n+    {\n+        insert(x, y);\n+        min_x = std::min(x, min_x);\n+        max_x = std::max(x, max_x);\n+        min_y = std::min(y, min_y);\n+        max_y = std::max(y, max_y);\n+    }\n+\n+    void merge(const AggregateFunctionSparkbarData & other)\n+    {\n+        if (other.points.empty())\n+            return;\n+\n+        for (auto & point : other.points)\n+            insert(point.getKey(), point.getMapped());\n+\n+        min_x = std::min(other.min_x, min_x);\n+        max_x = std::max(other.max_x, max_x);\n+        min_y = std::min(other.min_y, min_y);\n+        max_y = std::max(other.max_y, max_y);\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        writeBinary(min_x, buf);\n+        writeBinary(max_x, buf);\n+        writeBinary(min_y, buf);\n+        writeBinary(max_y, buf);\n+        writeVarUInt(points.size(), buf);\n+\n+        for (const auto & elem : points)\n+        {\n+            writeBinary(elem.getKey(), buf);\n+            writeBinary(elem.getMapped(), buf);\n+        }\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        readBinary(min_x, buf);\n+        readBinary(max_x, buf);\n+        readBinary(min_y, buf);\n+        readBinary(max_y, buf);\n+        size_t size;\n+        readVarUInt(size, buf);\n+\n+        /// TODO Protection against huge size\n+        X x;\n+        Y y;\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            readBinary(x, buf);\n+            readBinary(y, buf);\n+            insert(x, y);\n+        }\n+    }\n+\n+};\n+\n+template<typename X, typename Y>\n+class AggregateFunctionSparkbar final\n+    : public IAggregateFunctionDataHelper<AggregateFunctionSparkbarData<X, Y>, AggregateFunctionSparkbar<X, Y>>\n+{\n+\n+private:\n+    size_t width;\n+    X min_x;\n+    X max_x;\n+\n+    String getBar(const UInt8 value) const\n+    {\n+        // \u2581\u2582\u2583\u2584\u2585\u2586\u2587\u2588\n+        switch (value)\n+        {\n+            case 1: return \"\u2581\";\n+            case 2: return \"\u2582\";\n+            case 3: return \"\u2583\";\n+            case 4: return \"\u2584\";\n+            case 5: return \"\u2585\";\n+            case 6: return \"\u2586\";\n+            case 7: return \"\u2587\";\n+            case 8: return \"\u2588\";\n+        }\n+        return \" \";\n+    }\n+\n+    /**\n+     *  The minimum value of y is rendered as the lowest height \"\u2581\",\n+     *  the maximum value of y is rendered as the highest height \"\u2588\", and the middle value will be rendered proportionally.\n+     *  If a bucket has no y value, it will be rendered as \" \".\n+     *  If the actual number of buckets is greater than the specified bucket, it will be compressed by width.\n+     *  For example, there are actually 11 buckets, specify 10 buckets, and divide the 11 buckets as follows (11/10):\n+     *  0.0-1.1, 1.1-2.2, 2.2-3.3, 3.3-4.4, 4.4-5.5, 5.5-6.6, 6.6-7.7, 7.7-8.8, 8.8-9.9, 9.9-11.\n+     *  The y value of the first bucket will be calculated as follows:\n+     *  the actual y value of the first position + the actual second position y*0.1, and the remaining y*0.9 is reserved for the next bucket.\n+     *  The next bucket will use the last y*0.9 + the actual third position y*0.2, and the remaining y*0.8 will be reserved for the next bucket. And so on.\n+     */\n+    String render(const AggregateFunctionSparkbarData<X, Y> & data) const\n+    {\n+        String value;\n+        if (data.points.empty() || !width)\n+            return value;\n+        X local_min_x = data.min_x;\n+        X local_max_x = data.max_x;\n+        size_t diff_x = local_max_x - local_min_x;\n+        if ((diff_x + 1) <= width)\n+        {\n+            Y min_y = data.min_y;\n+            Y max_y = data.max_y;\n+            Float64 diff_y = max_y - min_y;\n+\n+            if (diff_y)\n+            {\n+                for (size_t i = 0; i <= diff_x; ++i)\n+                {\n+                    auto it = data.points.find(local_min_x + i);\n+                    bool found = it != data.points.end();\n+                    value += getBar(found ? static_cast<UInt8>(std::round(((it->getMapped() - min_y) / diff_y) * 7) + 1) : 0);\n+                }\n+            }\n+            else\n+            {\n+                for (size_t i = 0; i <= diff_x; ++i)\n+                    value += getBar(data.points.has(local_min_x + i) ? 1 : 0);\n+            }\n+        }\n+        else\n+        {\n+            // begin reshapes to width buckets\n+            Float64 multiple_d = (diff_x + 1) / static_cast<Float64>(width);\n+\n+            std::optional<Float64> min_y;\n+            std::optional<Float64> max_y;\n+\n+            std::optional<Float64> new_y;\n+            std::vector<std::optional<Float64>> newPoints;\n+            newPoints.reserve(width);\n+\n+            std::pair<size_t, Float64> bound{0, 0.0};\n+            size_t cur_bucket_num = 0;\n+            // upper bound for bucket\n+            auto upperBound = [&](size_t bucket_num)\n+            {\n+                bound.second = (bucket_num + 1) * multiple_d;\n+                bound.first = std::floor(bound.second);\n+            };\n+            upperBound(cur_bucket_num);\n+            for (size_t i = 0; i <= (diff_x + 1); ++i)\n+            {\n+                if (i == bound.first) // is bound\n+                {\n+                    Float64 proportion = bound.second - bound.first;\n+                    auto it = data.points.find(local_min_x + i);\n+                    bool found = (it != data.points.end());\n+                    if (found)\n+                        new_y = new_y.value_or(0) + it->getMapped() * proportion;\n+\n+                    if (new_y)\n+                    {\n+                        Float64 avg_y = new_y.value() / multiple_d;\n+\n+                        newPoints.emplace_back(avg_y);\n+                        // If min_y has no value, or if the avg_y of the current bucket is less than min_y, update it.\n+                        if (!min_y || avg_y < min_y)\n+                            min_y = avg_y;\n+                        if (!max_y || avg_y > max_y)\n+                            max_y = avg_y;\n+                    }\n+                    else\n+                    {\n+                        newPoints.emplace_back();\n+                    }\n+\n+                    // next bucket\n+                    new_y = found ? ((1 - proportion) * it->getMapped()) : std::optional<Float64>();\n+                    upperBound(++cur_bucket_num);\n+                }\n+                else\n+                {\n+                    auto it = data.points.find(local_min_x + i);\n+                    if (it != data.points.end())\n+                        new_y = new_y.value_or(0) + it->getMapped();\n+                }\n+            }\n+\n+            if (!min_y || !max_y) // No value is set\n+                return {};\n+\n+            Float64 diff_y = max_y.value() - min_y.value();\n+\n+            auto getBars = [&] (const std::optional<Float64> & point_y)\n+            {\n+                value += getBar(point_y ? static_cast<UInt8>(std::round(((point_y.value() - min_y.value()) / diff_y) * 7) + 1) : 0);\n+            };\n+            auto getBarsForConstant = [&] (const std::optional<Float64> & point_y)\n+            {\n+                value += getBar(point_y ? 1 : 0);\n+            };\n+\n+            if (diff_y)\n+                std::for_each(newPoints.begin(), newPoints.end(), getBars);\n+            else\n+                std::for_each(newPoints.begin(), newPoints.end(), getBarsForConstant);\n+        }\n+        return value;\n+    }\n+\n+\n+public:\n+    AggregateFunctionSparkbar(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<AggregateFunctionSparkbarData<X, Y>, AggregateFunctionSparkbar>(\n+        arguments, params)\n+    {\n+        width = params.at(0).safeGet<UInt64>();\n+        if (params.size() == 3)\n+        {\n+            min_x = params.at(1).safeGet<X>();\n+            max_x = params.at(2).safeGet<X>();\n+        }\n+        else\n+        {\n+            min_x = std::numeric_limits<X>::min();\n+            max_x = std::numeric_limits<X>::max();\n+        }\n+    }\n+\n+    String getName() const override\n+    {\n+        return \"sparkbar\";\n+    }\n+\n+    DataTypePtr getReturnType() const override\n+    {\n+        return std::make_shared<DataTypeString>();\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * /*arena*/) const override\n+    {\n+        X x = assert_cast<const ColumnVector<X> *>(columns[0])->getData()[row_num];\n+        if (min_x <= x && x <= max_x)\n+        {\n+            Y y = assert_cast<const ColumnVector<Y> *>(columns[1])->getData()[row_num];\n+            this->data(place).add(x, y);\n+        }\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * /*arena*/) const override\n+    {\n+        this->data(place).merge(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf) const override\n+    {\n+        this->data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena * /*arena*/) const override\n+    {\n+        auto & to_column = assert_cast<ColumnString &>(to);\n+        const auto & data = this->data(place);\n+        const String & value = render(data);\n+        to_column.insertData(value.data(), value.size());\n+    }\n+};\n+\n+}\ndiff --git a/src/AggregateFunctions/registerAggregateFunctions.cpp b/src/AggregateFunctions/registerAggregateFunctions.cpp\nindex 70248d4cfde3..dd1f292a3926 100644\n--- a/src/AggregateFunctions/registerAggregateFunctions.cpp\n+++ b/src/AggregateFunctions/registerAggregateFunctions.cpp\n@@ -50,6 +50,7 @@ void registerAggregateFunctionWelchTTest(AggregateFunctionFactory &);\n void registerAggregateFunctionStudentTTest(AggregateFunctionFactory &);\n void registerAggregateFunctionSingleValueOrNull(AggregateFunctionFactory &);\n void registerAggregateFunctionSequenceNextNode(AggregateFunctionFactory &);\n+void registerAggregateFunctionSparkbar(AggregateFunctionFactory &);\n \n class AggregateFunctionCombinatorFactory;\n void registerAggregateFunctionCombinatorIf(AggregateFunctionCombinatorFactory &);\n@@ -119,6 +120,7 @@ void registerAggregateFunctions()\n         registerWindowFunctions(factory);\n \n         registerAggregateFunctionIntervalLengthSum(factory);\n+        registerAggregateFunctionSparkbar(factory);\n     }\n \n     {\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02016_aggregation_spark_bar.reference b/tests/queries/0_stateless/02016_aggregation_spark_bar.reference\nnew file mode 100644\nindex 000000000000..cc6cc81037ba\n--- /dev/null\n+++ b/tests/queries/0_stateless/02016_aggregation_spark_bar.reference\n@@ -0,0 +1,24 @@\n+\u2581\n+\u2581\u2588\n+\u2583\u2588\u2581\n+\u2584\u2585\u2588\u2581\n+\u2584\u2584\u2588\u2587\u2581\n+\u2583\u2584\u2585\u2588\u2583\u2581\n+\u2582\u2585\u2583\u2587\u2588\u2581\u2582\n+\u2582\u2585\u2583\u2585\u2588\u2588 \u2581\n+\u2581\u2585\u2584\u2583\u2588\u2588\u2585 \u2581\n+\u2581\u2584\u2584\u2582\u2585\u2587\u2588\u2582 \u2582\n+\u2581\u2584\u2585\u2582\u2583\u2587\u2586\u2588  \u2582\n+\n+\n+\n+\u2581\n+\u2586\u2588\u2581\u2583\n+\u2585\u2581\u2582\u2588\u2587\n+\u2581\u2582\u2587\u2586\u2588  \u2581\n+\u2581\u2588\n+\u2581\u2588\n+\u2581\u2581\u2588\n+\u2581\u2581\u2588\n+\u2581\u2583\u2585\u2588\n+\u2581\u2584\u2582\u2587\u2588\ndiff --git a/tests/queries/0_stateless/02016_aggregation_spark_bar.sql b/tests/queries/0_stateless/02016_aggregation_spark_bar.sql\nnew file mode 100644\nindex 000000000000..90403332529a\n--- /dev/null\n+++ b/tests/queries/0_stateless/02016_aggregation_spark_bar.sql\n@@ -0,0 +1,35 @@\n+DROP TABLE IF EXISTS spark_bar_test;\n+\n+CREATE TABLE spark_bar_test (`cnt` UInt64,`event_date` Date) ENGINE = MergeTree ORDER BY event_date SETTINGS index_granularity = 8192;\n+\n+INSERT INTO spark_bar_test VALUES(1,'2020-01-01'),(4,'2020-01-02'),(5,'2020-01-03'),(2,'2020-01-04'),(3,'2020-01-05'),(7,'2020-01-06'),(6,'2020-01-07'),(8,'2020-01-08'),(2,'2020-01-11');\n+\n+SELECT sparkbar(1)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(2)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(3)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(4)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(5)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(6)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(7)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(8)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(9)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(10)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(11)(event_date,cnt) FROM spark_bar_test;\n+\n+SELECT sparkbar(11,2,5)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(11,3,7)(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(11,4,11)(event_date,cnt) FROM spark_bar_test;\n+\n+SELECT sparkbar(11,toDate('2020-01-02'),toDate('2020-01-02'))(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(11,toDate('2020-01-02'),toDate('2020-01-05'))(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(11,toDate('2020-01-03'),toDate('2020-01-07'))(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(11,toDate('2020-01-04'),toDate('2020-01-11'))(event_date,cnt) FROM spark_bar_test;\n+\n+SELECT sparkbar(2,toDate('2020-01-01'),toDate('2020-01-08'))(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(2,toDate('2020-01-02'),toDate('2020-01-09'))(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(3,toDate('2020-01-01'),toDate('2020-01-09'))(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(3,toDate('2020-01-01'),toDate('2020-01-10'))(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(4,toDate('2020-01-01'),toDate('2020-01-08'))(event_date,cnt) FROM spark_bar_test;\n+SELECT sparkbar(5,toDate('2020-01-01'),toDate('2020-01-10'))(event_date,cnt) FROM spark_bar_test;\n+\n+DROP TABLE IF EXISTS spark_bar_test;\n",
  "problem_statement": "`sparkbar` aggregate function\nSee https://github.com/deeplook/sparklines\r\n\r\n**Describe the solution you'd like**\r\n```\r\nsparkbar(width)(x, y)\r\nsparkbar(width, min_x, max_x)(x, y)\r\n\r\n\u2581\u2582\u2585\u2586\u2587\u2586\u2585\r\n```\r\n\r\nAn aggregate function calculates a histogram of `y` by `x` and then reshapes it to `width` buckets if the histogram is larger.\r\nLinear weighted average is used for reshaping. If multiple values correspond to a single bucket, they are also averaged.\r\nThe function returns a string.\r\n\r\nThe height of bar is proportional to the difference between `y` and the minimum value of `y` on the observed data (and then rounded to the nearest neighbor for rendering). The value of `y` can be negative but the bar height is always non negative. There are 8 different heights that can be rendered plus one additional character - whitespace that is used for absense of the value.\r\n\r\nThe boundaries for x and y can be calculated automatically or provided in parameters.\r\n\r\n**Further info**\r\n\r\nSimilar function can use ANSI escape sequences for 24-bit color to render heatmaps.\r\n\r\nWe can encode server's memory usage during query processing directly inside the famous progress bar in clickhouse-client.\n",
  "hints_text": "@alexey-milovidov Hi, may I take this task?\nSure. It will be very appreciated!",
  "created_at": "2021-08-09T15:24:34Z",
  "modified_files": [
    "b/src/AggregateFunctions/AggregateFunctionSparkbar.cpp",
    "b/src/AggregateFunctions/AggregateFunctionSparkbar.h",
    "src/AggregateFunctions/registerAggregateFunctions.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02016_aggregation_spark_bar.reference",
    "b/tests/queries/0_stateless/02016_aggregation_spark_bar.sql"
  ]
}