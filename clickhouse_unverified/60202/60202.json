{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 60202,
  "instance_id": "ClickHouse__ClickHouse-60202",
  "issue_numbers": [
    "58096"
  ],
  "base_commit": "659d960990a1d7dfba0e8004e2f4dde8fa79c22d",
  "patch": "diff --git a/docs/en/sql-reference/functions/tuple-functions.md b/docs/en/sql-reference/functions/tuple-functions.md\nindex 5930239dc562..b089de67e98f 100644\n--- a/docs/en/sql-reference/functions/tuple-functions.md\n+++ b/docs/en/sql-reference/functions/tuple-functions.md\n@@ -542,7 +542,7 @@ Alias: `scalarProduct`.\n \n - Scalar product.\n \n-Type: [Int/UInt](../../sql-reference/data-types/int-uint.md), [Float](../../sql-reference/data-types/float.md) or [Decimal](../../sql-reference/data-types/decimal.md).\n+Type: [Int/UInt](../../sql-reference/data-types/int-uint.md) or [Float](../../sql-reference/data-types/float.md).\n \n **Example**\n \ndiff --git a/src/Functions/array/arrayDistance.cpp b/src/Functions/array/arrayDistance.cpp\nindex 670442c0c79c..71564f6fa93e 100644\n--- a/src/Functions/array/arrayDistance.cpp\n+++ b/src/Functions/array/arrayDistance.cpp\n@@ -90,17 +90,19 @@ struct L2Distance\n         size_t & i_y,\n         State<ResultType> & state)\n     {\n+        static constexpr bool is_float32 = std::is_same_v<ResultType, Float32>;\n+\n         __m512 sums;\n-        if constexpr (std::is_same_v<ResultType, Float32>)\n+        if constexpr (is_float32)\n             sums = _mm512_setzero_ps();\n         else\n             sums = _mm512_setzero_pd();\n \n-        const size_t n = (std::is_same_v<ResultType, Float32>) ? 16 : 8;\n+        constexpr size_t n = is_float32 ? 16 : 8;\n \n         for (; i_x + n < i_max; i_x += n, i_y += n)\n         {\n-            if constexpr (std::is_same_v<ResultType, Float32>)\n+            if constexpr (is_float32)\n             {\n                 __m512 x = _mm512_loadu_ps(data_x + i_x);\n                 __m512 y = _mm512_loadu_ps(data_y + i_y);\n@@ -116,7 +118,7 @@ struct L2Distance\n             }\n         }\n \n-        if constexpr (std::is_same_v<ResultType, Float32>)\n+        if constexpr (is_float32)\n             state.sum = _mm512_reduce_add_ps(sums);\n         else\n             state.sum = _mm512_reduce_add_pd(sums);\n@@ -247,11 +249,13 @@ struct CosineDistance\n         size_t & i_y,\n         State<ResultType> & state)\n     {\n+        static constexpr bool is_float32 = std::is_same_v<ResultType, Float32>;\n+\n         __m512 dot_products;\n         __m512 x_squareds;\n         __m512 y_squareds;\n \n-        if constexpr (std::is_same_v<ResultType, Float32>)\n+        if constexpr (is_float32)\n         {\n             dot_products = _mm512_setzero_ps();\n             x_squareds = _mm512_setzero_ps();\n@@ -264,11 +268,11 @@ struct CosineDistance\n             y_squareds = _mm512_setzero_pd();\n         }\n \n-        const size_t n = (std::is_same_v<ResultType, Float32>) ? 16 : 8;\n+        constexpr size_t n = is_float32 ? 16 : 8;\n \n         for (; i_x + n < i_max; i_x += n, i_y += n)\n         {\n-            if constexpr (std::is_same_v<ResultType, Float32>)\n+            if constexpr (is_float32)\n             {\n                 __m512 x = _mm512_loadu_ps(data_x + i_x);\n                 __m512 y = _mm512_loadu_ps(data_y + i_y);\n@@ -286,7 +290,7 @@ struct CosineDistance\n             }\n         }\n \n-        if constexpr (std::is_same_v<ResultType, Float32>)\n+        if constexpr (is_float32)\n         {\n             state.dot_prod = _mm512_reduce_add_ps(dot_products);\n             state.x_squared = _mm512_reduce_add_ps(x_squareds);\n@@ -312,7 +316,11 @@ template <class Kernel>\n class FunctionArrayDistance : public IFunction\n {\n public:\n-    String getName() const override { static auto name = String(\"array\") + Kernel::name + \"Distance\"; return name; }\n+    String getName() const override\n+    {\n+        static auto name = String(\"array\") + Kernel::name + \"Distance\";\n+        return name;\n+    }\n     static FunctionPtr create(ContextPtr) { return std::make_shared<FunctionArrayDistance<Kernel>>(); }\n     size_t getNumberOfArguments() const override { return 2; }\n     ColumnNumbers getArgumentsThatAreAlwaysConstant() const override { return {}; }\ndiff --git a/src/Functions/array/arrayDotProduct.cpp b/src/Functions/array/arrayDotProduct.cpp\nindex 47e865785d42..6c615a058c30 100644\n--- a/src/Functions/array/arrayDotProduct.cpp\n+++ b/src/Functions/array/arrayDotProduct.cpp\n@@ -1,44 +1,51 @@\n+#include <Columns/ColumnArray.h>\n+#include <Columns/ColumnVector.h>\n+#include <DataTypes/DataTypeArray.h>\n #include <DataTypes/DataTypesNumber.h>\n+#include <Functions/FunctionBinaryArithmetic.h>\n #include <Functions/FunctionFactory.h>\n-#include <Core/Types_fwd.h>\n-#include <DataTypes/Serializations/ISerialization.h>\n+#include <Functions/IFunction.h>\n #include <Functions/castTypeToEither.h>\n-#include <Functions/array/arrayScalarProduct.h>\n+#include <Interpreters/Context_fwd.h>\n #include <base/types.h>\n-#include <Functions/FunctionBinaryArithmetic.h>\n \n+#if USE_MULTITARGET_CODE\n+#include <immintrin.h>\n+#endif\n \n namespace DB\n {\n \n namespace ErrorCodes\n {\n+    extern const int BAD_ARGUMENTS;\n+    extern const int ILLEGAL_COLUMN;\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int LOGICAL_ERROR;\n }\n \n-struct NameArrayDotProduct\n+\n+struct DotProduct\n {\n     static constexpr auto name = \"arrayDotProduct\";\n-};\n \n-class ArrayDotProductImpl\n-{\n-public:\n     static DataTypePtr getReturnType(const DataTypePtr & left, const DataTypePtr & right)\n     {\n         using Types = TypeList<DataTypeFloat32, DataTypeFloat64,\n                                DataTypeUInt8, DataTypeUInt16, DataTypeUInt32, DataTypeUInt64,\n                                DataTypeInt8, DataTypeInt16, DataTypeInt32, DataTypeInt64>;\n+        Types types;\n \n         DataTypePtr result_type;\n-        bool valid = castTypeToEither(Types{}, left.get(), [&](const auto & left_)\n+        bool valid = castTypeToEither(types, left.get(), [&](const auto & left_)\n         {\n-            return castTypeToEither(Types{}, right.get(), [&](const auto & right_)\n+            return castTypeToEither(types, right.get(), [&](const auto & right_)\n             {\n-                using LeftDataType = typename std::decay_t<decltype(left_)>::FieldType;\n-                using RightDataType = typename std::decay_t<decltype(right_)>::FieldType;\n-                using ResultType = typename NumberTraits::ResultOfAdditionMultiplication<LeftDataType, RightDataType>::Type;\n-                if (std::is_same_v<LeftDataType, Float32> && std::is_same_v<RightDataType, Float32>)\n+                using LeftType = typename std::decay_t<decltype(left_)>::FieldType;\n+                using RightType = typename std::decay_t<decltype(right_)>::FieldType;\n+                using ResultType = typename NumberTraits::ResultOfAdditionMultiplication<LeftType, RightType>::Type;\n+\n+                if constexpr (std::is_same_v<LeftType, Float32> && std::is_same_v<RightType, Float32>)\n                     result_type = std::make_shared<DataTypeFloat32>();\n                 else\n                     result_type = std::make_shared<DataTypeFromFieldType<ResultType>>();\n@@ -49,26 +56,268 @@ class ArrayDotProductImpl\n         if (!valid)\n             throw Exception(\n                 ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                \"Arguments of function {} \"\n-                \"only support: UInt8, UInt16, UInt32, UInt64, Int8, Int16, Int32, Int64, Float32, Float64.\",\n-                std::string(NameArrayDotProduct::name));\n+                \"Arguments of function {} only support: UInt8, UInt16, UInt32, UInt64, Int8, Int16, Int32, Int64, Float32, Float64.\", name);\n         return result_type;\n     }\n \n-    template <typename ResultType, typename T, typename U>\n-    static inline NO_SANITIZE_UNDEFINED ResultType apply(\n-        const T * left,\n-        const U * right,\n-        size_t size)\n+    template <typename Type>\n+    struct State\n+    {\n+        Type sum = 0;\n+    };\n+\n+    template <typename Type>\n+    static void accumulate(State<Type> & state, Type x, Type y)\n+    {\n+        state.sum += x * y;\n+    }\n+\n+    template <typename Type>\n+    static void combine(State<Type> & state, const State<Type> & other_state)\n+    {\n+        state.sum += other_state.sum;\n+    }\n+\n+#if USE_MULTITARGET_CODE\n+    template <typename Type>\n+    AVX512_FUNCTION_SPECIFIC_ATTRIBUTE static void accumulateCombine(\n+        const Type * __restrict data_x,\n+        const Type * __restrict data_y,\n+        size_t i_max,\n+        size_t & i,\n+        State<Type> & state)\n+    {\n+        static constexpr bool is_float32 = std::is_same_v<Type, Float32>;\n+\n+        __m512 sums;\n+        if constexpr (is_float32)\n+            sums = _mm512_setzero_ps();\n+        else\n+            sums = _mm512_setzero_pd();\n+\n+        constexpr size_t n = is_float32 ? 16 : 8;\n+\n+        for (; i + n < i_max; i += n)\n+        {\n+            if constexpr (is_float32)\n+            {\n+                __m512 x = _mm512_loadu_ps(data_x + i);\n+                __m512 y = _mm512_loadu_ps(data_y + i);\n+                sums = _mm512_fmadd_ps(x, y, sums);\n+            }\n+            else\n+            {\n+                __m512 x = _mm512_loadu_pd(data_x + i);\n+                __m512 y = _mm512_loadu_pd(data_y + i);\n+                sums = _mm512_fmadd_pd(x, y, sums);\n+            }\n+        }\n+\n+        if constexpr (is_float32)\n+            state.sum = _mm512_reduce_add_ps(sums);\n+        else\n+            state.sum = _mm512_reduce_add_pd(sums);\n+    }\n+#endif\n+\n+    template <typename Type>\n+    static Type finalize(const State<Type> & state)\n+    {\n+        return state.sum;\n+    }\n+\n+};\n+\n+\n+/// The implementation is modeled after the implementation of distance functions arrayL1Distance, arrayL2Distance, etc.\n+/// The main difference is that arrayDotProduct() interferes the result type differently.\n+template <typename Kernel>\n+class FunctionArrayScalarProduct : public IFunction\n+{\n+public:\n+    static constexpr auto name = Kernel::name;\n+\n+    String getName() const override { return name; }\n+    static FunctionPtr create(ContextPtr) { return std::make_shared<FunctionArrayScalarProduct>(); }\n+    size_t getNumberOfArguments() const override { return 2; }\n+    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n+\n+    DataTypePtr getReturnTypeImpl(const DataTypes & arguments) const override\n+    {\n+        std::array<DataTypePtr, 2> nested_types;\n+        for (size_t i = 0; i < 2; ++i)\n+        {\n+            const DataTypeArray * array_type = checkAndGetDataType<DataTypeArray>(arguments[i].get());\n+            if (!array_type)\n+                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+                        \"Arguments for function {} must be of type Array\", getName());\n+\n+            const auto & nested_type = array_type->getNestedType();\n+            if (!isNativeNumber(nested_type))\n+                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+                        \"Function {} cannot process values of type {}\", getName(), nested_type->getName());\n+\n+            nested_types[i] = nested_type;\n+        }\n+\n+        return Kernel::getReturnType(nested_types[0], nested_types[1]);\n+    }\n+\n+    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr & result_type, size_t /* input_rows_count */) const override\n+    {\n+        switch (result_type->getTypeId())\n+        {\n+        #define SUPPORTED_TYPE(type) \\\n+            case TypeIndex::type: \\\n+                return executeWithResultType<type>(arguments); \\\n+                break;\n+\n+            SUPPORTED_TYPE(UInt8)\n+            SUPPORTED_TYPE(UInt16)\n+            SUPPORTED_TYPE(UInt32)\n+            SUPPORTED_TYPE(UInt64)\n+            SUPPORTED_TYPE(Int8)\n+            SUPPORTED_TYPE(Int16)\n+            SUPPORTED_TYPE(Int32)\n+            SUPPORTED_TYPE(Int64)\n+            SUPPORTED_TYPE(Float32)\n+            SUPPORTED_TYPE(Float64)\n+        #undef SUPPORTED_TYPE\n+\n+            default:\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unexpected result type {}\", result_type->getName());\n+        }\n+    }\n+\n+private:\n+    template <typename ResultType>\n+    ColumnPtr executeWithResultType(const ColumnsWithTypeAndName & arguments) const\n+    {\n+        ColumnPtr res;\n+        if (!((res = executeWithResultTypeAndLeft<ResultType, UInt8>(arguments))\n+            || (res = executeWithResultTypeAndLeft<ResultType, UInt16>(arguments))\n+            || (res = executeWithResultTypeAndLeft<ResultType, UInt32>(arguments))\n+            || (res = executeWithResultTypeAndLeft<ResultType, UInt64>(arguments))\n+            || (res = executeWithResultTypeAndLeft<ResultType, Int8>(arguments))\n+            || (res = executeWithResultTypeAndLeft<ResultType, Int16>(arguments))\n+            || (res = executeWithResultTypeAndLeft<ResultType, Int32>(arguments))\n+            || (res = executeWithResultTypeAndLeft<ResultType, Int64>(arguments))\n+            || (res = executeWithResultTypeAndLeft<ResultType, Float32>(arguments))\n+            || (res = executeWithResultTypeAndLeft<ResultType, Float64>(arguments))))\n+            throw Exception(ErrorCodes::ILLEGAL_COLUMN,\n+                \"Illegal column {} of first argument of function {}\", arguments[0].column->getName(), getName());\n+\n+        return res;\n+    }\n+\n+    template <typename ResultType, typename LeftType>\n+    ColumnPtr executeWithResultTypeAndLeft(const ColumnsWithTypeAndName & arguments) const\n+    {\n+        ColumnPtr res;\n+        if (   (res = executeWithResultTypeAndLeftAndRight<ResultType, LeftType, UInt8>(arguments))\n+            || (res = executeWithResultTypeAndLeftAndRight<ResultType, LeftType, UInt16>(arguments))\n+            || (res = executeWithResultTypeAndLeftAndRight<ResultType, LeftType, UInt32>(arguments))\n+            || (res = executeWithResultTypeAndLeftAndRight<ResultType, LeftType, UInt64>(arguments))\n+            || (res = executeWithResultTypeAndLeftAndRight<ResultType, LeftType, Int8>(arguments))\n+            || (res = executeWithResultTypeAndLeftAndRight<ResultType, LeftType, Int16>(arguments))\n+            || (res = executeWithResultTypeAndLeftAndRight<ResultType, LeftType, Int32>(arguments))\n+            || (res = executeWithResultTypeAndLeftAndRight<ResultType, LeftType, Int64>(arguments))\n+            || (res = executeWithResultTypeAndLeftAndRight<ResultType, LeftType, Float32>(arguments))\n+            || (res = executeWithResultTypeAndLeftAndRight<ResultType, LeftType, Float64>(arguments)))\n+            return res;\n+\n+       return nullptr;\n+    }\n+\n+    template <typename ResultType, typename LeftType, typename RightType>\n+    ColumnPtr executeWithResultTypeAndLeftAndRight(const ColumnsWithTypeAndName & arguments) const\n+    {\n+        ColumnPtr col_left = arguments[0].column->convertToFullColumnIfConst();\n+        ColumnPtr col_right = arguments[1].column->convertToFullColumnIfConst();\n+        if (!col_left || !col_right)\n+            return nullptr;\n+\n+        const ColumnArray * col_arr_left = checkAndGetColumn<ColumnArray>(col_left.get());\n+        const ColumnArray * cokl_arr_right = checkAndGetColumn<ColumnArray>(col_right.get());\n+        if (!col_arr_left || !cokl_arr_right)\n+            return nullptr;\n+\n+        const ColumnVector<LeftType> * col_arr_nested_left = checkAndGetColumn<ColumnVector<LeftType>>(col_arr_left->getData());\n+        const ColumnVector<RightType> * col_arr_nested_right = checkAndGetColumn<ColumnVector<RightType>>(cokl_arr_right->getData());\n+        if (!col_arr_nested_left || !col_arr_nested_right)\n+            return nullptr;\n+\n+        if (!col_arr_left->hasEqualOffsets(*cokl_arr_right))\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Array arguments for function {} must have equal sizes\", getName());\n+\n+        auto col_res = ColumnVector<ResultType>::create();\n+\n+        vector(\n+            col_arr_nested_left->getData(),\n+            col_arr_nested_right->getData(),\n+            col_arr_left->getOffsets(),\n+            col_res->getData());\n+\n+        return col_res;\n+    }\n+\n+    template <typename ResultType, typename LeftType, typename RightType>\n+    static void vector(\n+        const PaddedPODArray<LeftType> & left,\n+        const PaddedPODArray<RightType> & right,\n+        const ColumnArray::Offsets & offsets,\n+        PaddedPODArray<ResultType> & result)\n     {\n-        ResultType result = 0;\n-        for (size_t i = 0; i < size; ++i)\n-            result += static_cast<ResultType>(left[i]) * static_cast<ResultType>(right[i]);\n-        return result;\n+        size_t size = offsets.size();\n+        result.resize(size);\n+\n+        ColumnArray::Offset current_offset = 0;\n+        for (size_t row = 0; row < size; ++row)\n+        {\n+            size_t array_size = offsets[row] - current_offset;\n+\n+            typename Kernel::template State<ResultType> state;\n+            size_t i = 0;\n+\n+            /// SIMD optimization: process multiple elements in both input arrays at once.\n+            /// To avoid combinatorial explosion of SIMD kernels, focus on\n+            /// - the two most common input/output types (Float32 x Float32) --> Float32 and (Float64 x Float64) --> Float64 instead of 10 x\n+            ///   10 input types x 8 output types,\n+            /// - the most powerful SIMD instruction set (AVX-512F).\n+#if USE_MULTITARGET_CODE\n+            if constexpr ((std::is_same_v<ResultType, Float32> || std::is_same_v<ResultType, Float64>)\n+                            && std::is_same_v<ResultType, LeftType> && std::is_same_v<LeftType, RightType>)\n+            {\n+                if (isArchSupported(TargetArch::AVX512F))\n+                    Kernel::template accumulateCombine<ResultType>(&left[current_offset], &right[current_offset], array_size, i, state);\n+            }\n+#else\n+            /// Process chunks in vectorized manner\n+            static constexpr size_t VEC_SIZE = 4;\n+            typename Kernel::template State<ResultType> states[VEC_SIZE];\n+            for (; i + VEC_SIZE < array_size; i += VEC_SIZE)\n+            {\n+                for (size_t j = 0; j < VEC_SIZE; ++j)\n+                    Kernel::template accumulate<ResultType>(states[j], static_cast<ResultType>(left[i + j]), static_cast<ResultType>(right[i + j]));\n+            }\n+\n+            for (const auto & other_state : states)\n+                Kernel::template combine<ResultType>(state, other_state);\n+#endif\n+\n+            /// Process the tail\n+            for (; i < array_size; ++i)\n+                Kernel::template accumulate<ResultType>(state, static_cast<ResultType>(left[i]), static_cast<ResultType>(right[i]));\n+\n+            /// ResultType res = Kernel::template finalize<ResultType>(state);\n+            result[row] = Kernel::template finalize<ResultType>(state);\n+\n+            current_offset = offsets[row];\n+        }\n     }\n };\n \n-using FunctionArrayDotProduct = FunctionArrayScalarProduct<ArrayDotProductImpl, NameArrayDotProduct>;\n+using FunctionArrayDotProduct = FunctionArrayScalarProduct<DotProduct>;\n \n REGISTER_FUNCTION(ArrayDotProduct)\n {\n@@ -77,4 +326,5 @@ REGISTER_FUNCTION(ArrayDotProduct)\n \n // These functions are used by TupleOrArrayFunction in Function/vectorFunctions.cpp\n FunctionPtr createFunctionArrayDotProduct(ContextPtr context_) { return FunctionArrayDotProduct::create(context_); }\n+\n }\ndiff --git a/src/Functions/array/arrayScalarProduct.h b/src/Functions/array/arrayScalarProduct.h\ndeleted file mode 100644\nindex 374a2d8a1944..000000000000\n--- a/src/Functions/array/arrayScalarProduct.h\n+++ /dev/null\n@@ -1,182 +0,0 @@\n-#pragma once\n-\n-#include <Columns/ColumnArray.h>\n-#include <Columns/ColumnVector.h>\n-#include <DataTypes/DataTypeArray.h>\n-#include <Functions/FunctionHelpers.h>\n-#include <Functions/IFunction.h>\n-#include <Interpreters/Context_fwd.h>\n-#include <Core/TypeId.h>\n-\n-\n-namespace DB\n-{\n-\n-class Context;\n-\n-namespace ErrorCodes\n-{\n-    extern const int ILLEGAL_COLUMN;\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-    extern const int BAD_ARGUMENTS;\n-    extern const int LOGICAL_ERROR;\n-}\n-\n-\n-template <typename Method, typename Name>\n-class FunctionArrayScalarProduct : public IFunction\n-{\n-public:\n-    static constexpr auto name = Name::name;\n-    static FunctionPtr create(ContextPtr) { return std::make_shared<FunctionArrayScalarProduct>(); }\n-\n-private:\n-\n-    template <typename ResultType, typename T>\n-    ColumnPtr executeNumber(const ColumnsWithTypeAndName & arguments) const\n-    {\n-        ColumnPtr res;\n-        if (   (res = executeNumberNumber<ResultType, T, UInt8>(arguments))\n-            || (res = executeNumberNumber<ResultType, T, UInt16>(arguments))\n-            || (res = executeNumberNumber<ResultType, T, UInt32>(arguments))\n-            || (res = executeNumberNumber<ResultType, T, UInt64>(arguments))\n-            || (res = executeNumberNumber<ResultType, T, Int8>(arguments))\n-            || (res = executeNumberNumber<ResultType, T, Int16>(arguments))\n-            || (res = executeNumberNumber<ResultType, T, Int32>(arguments))\n-            || (res = executeNumberNumber<ResultType, T, Int64>(arguments))\n-            || (res = executeNumberNumber<ResultType, T, Float32>(arguments))\n-            || (res = executeNumberNumber<ResultType, T, Float64>(arguments)))\n-            return res;\n-\n-       return nullptr;\n-    }\n-\n-\n-    template <typename ResultType, typename T, typename U>\n-    ColumnPtr executeNumberNumber(const ColumnsWithTypeAndName & arguments) const\n-    {\n-        ColumnPtr col1 = arguments[0].column->convertToFullColumnIfConst();\n-        ColumnPtr col2 = arguments[1].column->convertToFullColumnIfConst();\n-        if (!col1 || !col2)\n-            return nullptr;\n-\n-        const ColumnArray * col_array1 = checkAndGetColumn<ColumnArray>(col1.get());\n-        const ColumnArray * col_array2 = checkAndGetColumn<ColumnArray>(col2.get());\n-        if (!col_array1 || !col_array2)\n-            return nullptr;\n-\n-        if (!col_array1->hasEqualOffsets(*col_array2))\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Array arguments for function {} must have equal sizes\", getName());\n-\n-        const ColumnVector<T> * col_nested1 = checkAndGetColumn<ColumnVector<T>>(col_array1->getData());\n-        const ColumnVector<U> * col_nested2 = checkAndGetColumn<ColumnVector<U>>(col_array2->getData());\n-        if (!col_nested1 || !col_nested2)\n-            return nullptr;\n-\n-        auto col_res = ColumnVector<ResultType>::create();\n-\n-        vector(\n-            col_nested1->getData(),\n-            col_nested2->getData(),\n-            col_array1->getOffsets(),\n-            col_res->getData());\n-\n-        return col_res;\n-    }\n-\n-    template <typename ResultType, typename T, typename U>\n-    static NO_INLINE void vector(\n-        const PaddedPODArray<T> & data1,\n-        const PaddedPODArray<U> & data2,\n-        const ColumnArray::Offsets & offsets,\n-        PaddedPODArray<ResultType> & result)\n-    {\n-        size_t size = offsets.size();\n-        result.resize(size);\n-\n-        ColumnArray::Offset current_offset = 0;\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            size_t array_size = offsets[i] - current_offset;\n-            result[i] = Method::template apply<ResultType, T, U>(&data1[current_offset], &data2[current_offset], array_size);\n-            current_offset = offsets[i];\n-        }\n-    }\n-\n-public:\n-    String getName() const override { return name; }\n-    size_t getNumberOfArguments() const override { return 2; }\n-\n-    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n-\n-\n-    DataTypePtr getReturnTypeImpl(const DataTypes & arguments) const override\n-    {\n-        // Basic type check\n-        std::vector<DataTypePtr> nested_types(2, nullptr);\n-        for (size_t i = 0; i < getNumberOfArguments(); ++i)\n-        {\n-            const DataTypeArray * array_type = checkAndGetDataType<DataTypeArray>(arguments[i].get());\n-            if (!array_type)\n-                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"All arguments for function {} must be an array.\", getName());\n-\n-            const auto & nested_type = array_type->getNestedType();\n-            if (!isNativeNumber(nested_type) && !isEnum(nested_type))\n-                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"{} cannot process values of type {}\",\n-                                getName(), nested_type->getName());\n-            nested_types[i] = nested_type;\n-        }\n-\n-        // Detail type check in Method, then return ReturnType\n-        return Method::getReturnType(nested_types[0], nested_types[1]);\n-    }\n-\n-    template <typename ResultType>\n-    ColumnPtr executeWithResultType(const ColumnsWithTypeAndName & arguments) const\n-    {\n-        ColumnPtr res;\n-        if (!((res = executeNumber<ResultType, UInt8>(arguments))\n-            || (res = executeNumber<ResultType, UInt16>(arguments))\n-            || (res = executeNumber<ResultType, UInt32>(arguments))\n-            || (res = executeNumber<ResultType, UInt64>(arguments))\n-            || (res = executeNumber<ResultType, Int8>(arguments))\n-            || (res = executeNumber<ResultType, Int16>(arguments))\n-            || (res = executeNumber<ResultType, Int32>(arguments))\n-            || (res = executeNumber<ResultType, Int64>(arguments))\n-            || (res = executeNumber<ResultType, Float32>(arguments))\n-            || (res = executeNumber<ResultType, Float64>(arguments))))\n-            throw Exception(ErrorCodes::ILLEGAL_COLUMN,\n-                \"Illegal column {} of first argument of function {}\", arguments[0].column->getName(), getName());\n-\n-        return res;\n-    }\n-\n-    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr & result_type, size_t /* input_rows_count */) const override\n-    {\n-        switch (result_type->getTypeId())\n-        {\n-        #define SUPPORTED_TYPE(type) \\\n-            case TypeIndex::type: \\\n-                return executeWithResultType<type>(arguments); \\\n-                break;\n-\n-            SUPPORTED_TYPE(UInt8)\n-            SUPPORTED_TYPE(UInt16)\n-            SUPPORTED_TYPE(UInt32)\n-            SUPPORTED_TYPE(UInt64)\n-            SUPPORTED_TYPE(Int8)\n-            SUPPORTED_TYPE(Int16)\n-            SUPPORTED_TYPE(Int32)\n-            SUPPORTED_TYPE(Int64)\n-            SUPPORTED_TYPE(Float32)\n-            SUPPORTED_TYPE(Float64)\n-        #undef SUPPORTED_TYPE\n-\n-            default:\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unexpected result type {}\", result_type->getName());\n-        }\n-    }\n-};\n-\n-}\n-\n",
  "test_patch": "diff --git a/tests/performance/dotProduct.xml b/tests/performance/dotProduct.xml\nnew file mode 100644\nindex 000000000000..6e056964ebb6\n--- /dev/null\n+++ b/tests/performance/dotProduct.xml\n@@ -0,0 +1,62 @@\n+<test>\n+\n+    <substitutions>\n+        <substitution>\n+            <name>element_type</name>\n+            <values>\n+                <!-- integer cases are not relevant in practice for vector search, disable to reduce test runtime -->\n+                <!-- <value>UInt8</value> -->\n+                <!-- <value>Int16</value> -->\n+                <!-- <value>Int32</value> -->\n+                <!-- <value>Int64</value> -->\n+                <value>Float32</value>\n+                <value>Float64</value>\n+            </values>\n+        </substitution>\n+    </substitutions>\n+\n+    <create_query>\n+        CREATE TABLE vecs_{element_type} (\n+            v Array({element_type})\n+        ) ENGINE=Memory;\n+    </create_query>\n+\n+    <!-- Gererate arrays with random data -->\n+    <!-- Dimension = 150 is realistic for vector search use cases -->\n+\n+    <fill_query>\n+        INSERT INTO vecs_{element_type}\n+        SELECT v FROM (\n+            SELECT\n+                number AS n,\n+                [\n+                    rand(n*10), rand(n*10+1), rand(n*10+2), rand(n*10+3), rand(n*10+4), rand(n*10+5), rand(n*10+6), rand(n*10+7), rand(n*10+8), rand(n*10+9),\n+                    rand(n*10+10), rand(n*10+11), rand(n*10+12), rand(n*10+13), rand(n*10+14), rand(n*10+15), rand(n*10+16), rand(n*10+17), rand(n*10+18), rand(n*10+19),\n+                    rand(n*10+20), rand(n*10+21), rand(n*10+22), rand(n*10+23), rand(n*10+24), rand(n*10+25), rand(n*10+26), rand(n*10+27), rand(n*10+28), rand(n*10+29),\n+                    rand(n*10+30), rand(n*10+31), rand(n*10+32), rand(n*10+33), rand(n*10+34), rand(n*10+35), rand(n*10+36), rand(n*10+37), rand(n*10+38), rand(n*10+39),\n+                    rand(n*10+40), rand(n*10+41), rand(n*10+42), rand(n*10+43), rand(n*10+44), rand(n*10+45), rand(n*10+46), rand(n*10+47), rand(n*10+48), rand(n*10+49),\n+                    rand(n*10+50), rand(n*10+51), rand(n*10+52), rand(n*10+53), rand(n*10+54), rand(n*10+55), rand(n*10+56), rand(n*10+57), rand(n*10+58), rand(n*10+59),\n+                    rand(n*10+60), rand(n*10+61), rand(n*10+62), rand(n*10+63), rand(n*10+64), rand(n*10+65), rand(n*10+66), rand(n*10+67), rand(n*10+68), rand(n*10+69),\n+                    rand(n*10+70), rand(n*10+71), rand(n*10+72), rand(n*10+73), rand(n*10+74), rand(n*10+75), rand(n*10+76), rand(n*10+77), rand(n*10+78), rand(n*10+79),\n+                    rand(n*10+80), rand(n*10+81), rand(n*10+82), rand(n*10+83), rand(n*10+84), rand(n*10+85), rand(n*10+86), rand(n*10+87), rand(n*10+88), rand(n*10+89),\n+                    rand(n*10+90), rand(n*10+91), rand(n*10+92), rand(n*10+93), rand(n*10+94), rand(n*10+95), rand(n*10+96), rand(n*10+97), rand(n*10+98), rand(n*10+99),\n+                    rand(n*10+100), rand(n*10+101), rand(n*10+102), rand(n*10+103), rand(n*10+104), rand(n*10+105), rand(n*10+106), rand(n*10+107), rand(n*10+108), rand(n*10+109),\n+                    rand(n*10+110), rand(n*10+111), rand(n*10+112), rand(n*10+113), rand(n*10+114), rand(n*10+115), rand(n*10+116), rand(n*10+117), rand(n*10+118), rand(n*10+119),\n+                    rand(n*10+120), rand(n*10+121), rand(n*10+122), rand(n*10+123), rand(n*10+124), rand(n*10+125), rand(n*10+126), rand(n*10+127), rand(n*10+128), rand(n*10+129),\n+                    rand(n*10+130), rand(n*10+131), rand(n*10+132), rand(n*10+133), rand(n*10+134), rand(n*10+135), rand(n*10+136), rand(n*10+137), rand(n*10+138), rand(n*10+139),\n+                    rand(n*10+140), rand(n*10+141), rand(n*10+142), rand(n*10+143), rand(n*10+144), rand(n*10+145), rand(n*10+146), rand(n*10+147), rand(n*10+148), rand(n*10+149)\n+                ] AS v\n+            FROM system.numbers\n+            LIMIT 5000000\n+        );\n+    </fill_query>\n+\n+    <settings>\n+        <max_threads>1</max_threads>\n+    </settings>\n+\n+    <query>SELECT sum(dp) FROM (SELECT dotProduct(v, v) AS dp FROM vecs_{element_type})</query>\n+\n+    <drop_query>DROP TABLE vecs_{element_type}</drop_query>\n+\n+</test>\ndiff --git a/tests/performance/norm_distance.xml b/tests/performance/norm_distance.xml\nindex 1e879607dac7..69ed71d026f8 100644\n--- a/tests/performance/norm_distance.xml\n+++ b/tests/performance/norm_distance.xml\n@@ -4,11 +4,11 @@\n         <substitution>\n             <name>element_type</name>\n             <values>\n-                <!-- 8 and 16 bit cases are not relevant in practice, disable to reduce test runtime -->\n+                <!-- integer cases are not relevant in practice for vector search, disable to reduce test runtime -->\n                 <!-- <value>UInt8</value> -->\n                 <!-- <value>Int16</value> -->\n-                <value>Int32</value>\n-                <value>Int64</value>\n+                <!-- <value>Int32</value> -->\n+                <!-- <value>Int64</value> -->\n                 <value>Float32</value>\n                 <value>Float64</value>\n             </values>\ndiff --git a/tests/queries/0_stateless/02708_dotProduct.reference b/tests/queries/0_stateless/02708_dotProduct.reference\nnew file mode 100644\nindex 000000000000..5cc9a9f05023\n--- /dev/null\n+++ b/tests/queries/0_stateless/02708_dotProduct.reference\n@@ -0,0 +1,34 @@\n+-- Negative tests\n+-- Tests\n+   -- Array\n+[1,2,3]\t[4,5,6]\t32\tUInt16\n+[1,2,3]\t[4,5,6]\t32\tUInt32\n+[1,2,3]\t[4,5,6]\t32\tUInt64\n+[1,2,3]\t[4,5,6]\t32\tUInt64\n+[-1,-2,-3]\t[4,5,6]\t-32\tInt16\n+[-1,-2,-3]\t[4,5,6]\t-32\tInt32\n+[-1,-2,-3]\t[4,5,6]\t-32\tInt64\n+[-1,-2,-3]\t[4,5,6]\t-32\tInt64\n+[1,2,3]\t[4,5,6]\t32\tFloat32\n+[1,2,3]\t[4,5,6]\t32\tFloat64\n+   -- Tuple\n+(1,2,3)\t(4,5,6)\t32\tUInt64\n+(1,2,3)\t(4,5,6)\t32\tUInt64\n+(1,2,3)\t(4,5,6)\t32\tUInt64\n+(1,2,3)\t(4,5,6)\t32\tUInt64\n+(-1,-2,-3)\t(4,5,6)\t-32\tInt64\n+(-1,-2,-3)\t(4,5,6)\t-32\tInt64\n+(-1,-2,-3)\t(4,5,6)\t-32\tInt64\n+(-1,-2,-3)\t(4,5,6)\t-32\tInt64\n+(1,2,3)\t(4,5,6)\t32\tFloat64\n+(1,2,3)\t(4,5,6)\t32\tFloat64\n+-- Non-const argument\n+[1,2,3]\t[4,5,6]\t32\tUInt16\n+ -- Array with mixed element arguments types (result type is the supertype)\n+[1,2,3]\t[4,5,6]\t32\tFloat32\n+ -- Tuple with mixed element arguments types\n+(1,2,3)\t(4,5,6)\t32\tFloat64\n+-- Aliases\n+32\n+32\n+32\ndiff --git a/tests/queries/0_stateless/02708_dotProduct.sql b/tests/queries/0_stateless/02708_dotProduct.sql\nnew file mode 100644\nindex 000000000000..6ad615664e87\n--- /dev/null\n+++ b/tests/queries/0_stateless/02708_dotProduct.sql\n@@ -0,0 +1,47 @@\n+SELECT '-- Negative tests';\n+\n+SELECT arrayDotProduct([1, 2]); -- { serverError NUMBER_OF_ARGUMENTS_DOESNT_MATCH }\n+SELECT arrayDotProduct([1, 2], 'abc'); -- { serverError ILLEGAL_TYPE_OF_ARGUMENT }\n+SELECT arrayDotProduct('abc', [1, 2]); -- { serverError ILLEGAL_TYPE_OF_ARGUMENT }\n+SELECT arrayDotProduct([1, 2], ['abc', 'def']); -- { serverError ILLEGAL_TYPE_OF_ARGUMENT }\n+SELECT arrayDotProduct([1, 2], [3, 4, 5]); -- { serverError BAD_ARGUMENTS }\n+SELECT dotProduct([1, 2], (3, 4, 5)); -- { serverError ILLEGAL_TYPE_OF_ARGUMENT }\n+\n+SELECT '-- Tests';\n+SELECT '   -- Array';\n+SELECT [1, 2, 3]::Array(UInt8) AS x, [4, 5, 6]::Array(UInt8) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT [1, 2, 3]::Array(UInt16) AS x, [4, 5, 6]::Array(UInt16) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT [1, 2, 3]::Array(UInt32) AS x, [4, 5, 6]::Array(UInt32) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT [1, 2, 3]::Array(UInt64) AS x, [4, 5, 6]::Array(UInt64) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT [-1, -2, -3]::Array(Int8) AS x, [4, 5, 6]::Array(Int8) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT [-1, -2, -3]::Array(Int16) AS x, [4, 5, 6]::Array(Int16) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT [-1, -2, -3]::Array(Int32) AS x, [4, 5, 6]::Array(Int32) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT [-1, -2, -3]::Array(Int64) AS x, [4, 5, 6]::Array(Int64) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT [1, 2, 3]::Array(Float32) AS x, [4, 5, 6]::Array(Float32) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT [1, 2, 3]::Array(Float64) AS x, [4, 5, 6]::Array(Float64) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+\n+SELECT '   -- Tuple';\n+SELECT (1::UInt8, 2::UInt8, 3::UInt8) AS x, (4::UInt8, 5::UInt8, 6::UInt8) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT (1::UInt16, 2::UInt16, 3::UInt16) AS x, (4::UInt16, 5::UInt16, 6::UInt16) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT (1::UInt32, 2::UInt32, 3::UInt32) AS x, (4::UInt32, 5::UInt32, 6::UInt32) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT (1::UInt64, 2::UInt64, 3::UInt64) AS x, (4::UInt64, 5::UInt64, 6::UInt64) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT (-1::Int8, -2::Int8, -3::Int8) AS x, (4::Int8, 5::Int8, 6::Int8) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT (-1::Int16, -2::Int16, -3::Int16) AS x, (4::Int16, 5::Int16, 6::Int16) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT (-1::Int32, -2::Int32, -3::Int32) AS x, (4::Int32, 5::Int32, 6::Int32) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT (-1::Int64, -2::Int64, -3::Int64) AS x, (4::Int64, 5::Int64, 6::Int64) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT (1::Float32, 2::Float32, 3::Float32) AS x, (4::Float32, 5::Float32, 6::Float32) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+SELECT (1::Float64, 2::Float64, 3::Float64) AS x, (4::Float64, 5::Float64, 6::Float64) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+\n+SELECT '-- Non-const argument';\n+SELECT materialize([1::UInt8, 2::UInt8, 3::UInt8]) AS x, [4::UInt8, 5::UInt8, 6::UInt8] AS y, dotProduct(x, y) AS res, toTypeName(res);\n+\n+SELECT ' -- Array with mixed element arguments types (result type is the supertype)';\n+SELECT [1::UInt16, 2::UInt8, 3::Float32] AS x, [4::Int16, 5::Float32, 6::UInt8] AS y, dotProduct(x, y) AS res, toTypeName(res);\n+\n+SELECT ' -- Tuple with mixed element arguments types';\n+SELECT (1::UInt16, 2::UInt8, 3::Float32) AS x, (4::Int16, 5::Float32, 6::UInt8) AS y, dotProduct(x, y) AS res, toTypeName(res);\n+\n+SELECT '-- Aliases';\n+SELECT scalarProduct([1, 2, 3], [4, 5, 6]);\n+SELECT scalarProduct((1, 2, 3), (4, 5, 6));\n+SELECT arrayDotProduct([1, 2, 3], [4, 5, 6]); -- actually no alias but the internal function for arrays\ndiff --git a/tests/queries/0_stateless/02708_dot_product.reference b/tests/queries/0_stateless/02708_dot_product.reference\ndeleted file mode 100644\nindex 45e53871aa23..000000000000\n--- a/tests/queries/0_stateless/02708_dot_product.reference\n+++ /dev/null\n@@ -1,14 +0,0 @@\n-3881.304\n-3881.304\n-3881.304\n-376.5\n-230\n-0\n-0\n-Float64\n-Float32\n-Float64\n-Float64\n-UInt16\n-UInt64\n-Int64\ndiff --git a/tests/queries/0_stateless/02708_dot_product.sql b/tests/queries/0_stateless/02708_dot_product.sql\ndeleted file mode 100644\nindex e94cb577bf40..000000000000\n--- a/tests/queries/0_stateless/02708_dot_product.sql\n+++ /dev/null\n@@ -1,55 +0,0 @@\n-SELECT dotProduct([12, 2.22, 302], [1.32, 231.2, 11.1]);\n-\n-SELECT scalarProduct([12, 2.22, 302], [1.32, 231.2, 11.1]);\n-\n-SELECT arrayDotProduct([12, 2.22, 302], [1.32, 231.2, 11.1]);\n-\n-SELECT dotProduct([1.3, 2, 3, 4, 5], [222, 12, 5.3, 2, 8]);\n-\n-SELECT dotProduct([1, 1, 1, 1, 1], [222, 12, 0, -12, 8]);\n-\n-SELECT round(dotProduct([12345678901234567], [1]) - dotProduct(tuple(12345678901234567), tuple(1)), 2);\n-\n-SELECT round(dotProduct([-1, 2, 3.002], [2, 3.4, 4]) - dotProduct((-1, 2, 3.002), (2, 3.4, 4)), 2);\n-\n-DROP TABLE IF EXISTS product_fp64_fp64;\n-CREATE TABLE product_fp64_fp64 (x Array(Float64), y Array(Float64)) engine = MergeTree() order by x;\n-INSERT INTO TABLE product_fp64_fp64 (x, y) values ([1, 2], [3, 4]);\n-SELECT toTypeName(dotProduct(x, y)) from product_fp64_fp64;\n-DROP TABLE product_fp64_fp64;\n-\n-DROP TABLE IF EXISTS product_fp32_fp32;\n-CREATE TABLE product_fp32_fp32 (x Array(Float32), y Array(Float32)) engine = MergeTree() order by x;\n-INSERT INTO TABLE product_fp32_fp32 (x, y) values ([1, 2], [3, 4]);\n-SELECT toTypeName(dotProduct(x, y)) from product_fp32_fp32;\n-DROP TABLE product_fp32_fp32;\n-\n-DROP TABLE IF EXISTS product_fp32_fp64;\n-CREATE TABLE product_fp32_fp64 (x Array(Float32), y Array(Float64)) engine = MergeTree() order by x;\n-INSERT INTO TABLE product_fp32_fp64 (x, y) values ([1, 2], [3, 4]);\n-SELECT toTypeName(dotProduct(x, y)) from product_fp32_fp64;\n-DROP TABLE product_fp32_fp64;\n-\n-DROP TABLE IF EXISTS product_uint8_fp64;\n-CREATE TABLE product_uint8_fp64 (x Array(UInt8), y Array(Float64)) engine = MergeTree() order by x;\n-INSERT INTO TABLE product_uint8_fp64 (x, y) values ([1, 2], [3, 4]);\n-SELECT toTypeName(dotProduct(x, y)) from product_uint8_fp64;\n-DROP TABLE product_uint8_fp64;\n-\n-DROP TABLE IF EXISTS product_uint8_uint8;\n-CREATE TABLE product_uint8_uint8 (x Array(UInt8), y Array(UInt8)) engine = MergeTree() order by x;\n-INSERT INTO TABLE product_uint8_uint8 (x, y) values ([1, 2], [3, 4]);\n-SELECT toTypeName(dotProduct(x, y)) from product_uint8_uint8;\n-DROP TABLE product_uint8_uint8;\n-\n-DROP TABLE IF EXISTS product_uint64_uint64;\n-CREATE TABLE product_uint64_uint64 (x Array(UInt64), y Array(UInt64)) engine = MergeTree() order by x;\n-INSERT INTO TABLE product_uint64_uint64 (x, y) values ([1, 2], [3, 4]);\n-SELECT toTypeName(dotProduct(x, y)) from product_uint64_uint64;\n-DROP TABLE product_uint64_uint64;\n-\n-DROP TABLE IF EXISTS product_int32_uint64;\n-CREATE TABLE product_int32_uint64 (x Array(Int32), y Array(UInt64)) engine = MergeTree() order by x;\n-INSERT INTO TABLE product_int32_uint64 (x, y) values ([1, 2], [3, 4]);\n-SELECT toTypeName(dotProduct(x, y)) from product_int32_uint64;\n-DROP TABLE product_int32_uint64;\n",
  "problem_statement": "`dotProduct` is not optimized for vector Similarity\n## Background\r\n\r\nVector similarity is very popular right now, and ClickHouse has a few tutorials about this  [Source](https://clickhouse.com/blog/approximate-nearest-neighbour-ann-with-sql-powered-local-sensitive-hashing-lsh-random-projections). Regarding distances between vectors, they mention the most common ones:\r\n\r\n- Euclidean distance\r\n- Cosine distance\r\n\r\n![Captura de pantalla 2023-12-20 a las 21 01 10](https://github.com/ClickHouse/ClickHouse/assets/31625296/2b361182-490c-417d-a232-fcbd275cce37)\r\n\r\nBut in my opinion dotProduct is a better replacement for cosineDistance because **is the same but faster**, let me explain...\r\n\r\n## cosineDistance == dotProduct of L2 normalized vectors\r\n\r\n`dotProduct` has a much cheaper computation than `cosineDistance`. But they produce different things.\r\n\r\n![download](https://github.com/ClickHouse/ClickHouse/assets/31625296/4b046243-b4aa-4806-b64a-e86c9b65c217)\r\n\r\nHowever, **the dotProduct of the L2-normalized vectors** is mathematically the same that cosineDistance, but computationally cheaper because only the norm of the query verctor is computed at search time. The following formula illustrate this:\r\n\r\n![Captura de pantalla 2023-12-20 a las 21 30 29](https://github.com/ClickHouse/ClickHouse/assets/31625296/eff51b1e-1dca-4887-b458-bbf6c9eca552)\r\n\r\n>  L2 normalization is dividing (element-wise) the vector by its L2Norm. This produces the unit vector (vector lenght = 1) pointing to the same direction of the original vector.\r\n\r\n## Poor performance of `dotProduct` in clickhouse now\r\n\r\nBoth `cosineDistance` and `dotProduct` exist in clickhouse. `dotProduct` should be faster, but currently is (~16x) slower .\r\n\r\n```sql\r\nWITH cosineDistance(img_emb, <query_emb>) AS score\r\nSELECT id, score, caption\r\nFROM laion\r\nORDER BY score DESC\r\nLIMIT 3\r\n# 3 rows in set. Elapsed: 0.535 sec. Processed 1.00 million rows, 2.13 GB (1.87 million rows/s., 3.98 GB/s.) Peak memory usage: 164.25 MiB.\r\n\r\nWITH dotProduct(img_emb, <query_emb>) AS score\r\nSELECT id, score, caption\r\nFROM laion\r\nORDER BY score DESC\r\nLIMIT 3\r\n# 3 rows in set. Elapsed: 8.385 sec. Processed 1.00 million rows, 2.13 GB (119.31 thousand rows/s., 254.04 MB/s.) Peak memory usage: 420.67 MiB.\r\n```\r\n\r\n## Possible solution\r\n\r\nI know projects like [SimSIMD](https://github.com/ashvardanian/SimSIMD) could help with this optimization.\r\n\r\n\n",
  "hints_text": "Can you provide a reproducible example, or describe more detail about your test case?\r\nIn my testing with array as input, `cosineDistance` is only slightly faster than `dotProduct`. And their underlying implement is almost identical.\nI'm checking with the following script:\r\n\r\n```\r\nCREATE TABLE vectors\r\n(\r\n    v Array(Float32)\r\n) ENGINE = Memory;\r\n\r\nSET max_block_size = 16;\r\nINSERT INTO vectors SELECT arrayMap(x -> randUniform(0, 1, x), range(1024)) FROM numbers(1e6);\r\n\r\nWITH arrayMap(x -> randUniform(0, 1, x), range(1024)) AS target\r\nSELECT count() FROM vectors WHERE NOT ignore(dotProduct(v, target));\r\n```\r\n\r\nI see that `cosineDistance` is faster, but only marginally.\n# Reproduce example\r\n\r\n## Hardware & Software \r\n- Machine: Macbook Air M1 cpu (2020)\r\n- Software: Clickhouse from [quick start guide](https://clickhouse.com/docs/en/getting-started/quick-start)\r\n  - ClickHouse client version 23.12.1.711 (official build).\r\n  - Connected to ClickHouse server version 23.12.1.\r\n\r\n## Data\r\n1M from laion400M (part: 0)\r\n```bash\r\nwget --tries=100 https://deploy.laion.ai/8f83b608504d46bb81708ec86e912220/embeddings/img_emb/img_emb_0.npy          # download image embedding\r\nwget --tries=100 https://deploy.laion.ai/8f83b608504d46bb81708ec86e912220/embeddings/metadata/metadata_0.parquet    # download metadata\r\n````\r\n\r\n## Create table\r\n\r\n```sql\r\nCREATE TABLE laion\r\nENGINE = MergeTree\r\nORDER BY key\r\nAS\r\n(\r\n  SELECT * EXCEPT (row_num1, row_num2)\r\n  FROM\r\n  (\r\n      SELECT *, rowNumberInAllBlocks() as row_num1\r\n      FROM file('/Users/javi/Desktop/clickhouse/user_files/laion400M/metadata_0.parquet', 'Parquet', 'key UInt32, width UInt32, height UInt32, url String, caption String, NSFW String, similarity Float32')\r\n  ) AS laion_metadata,\r\n  (\r\n      SELECT *, rowNumberInAllBlocks() as row_num2\r\n      FROM file('/Users/javi/Desktop/clickhouse/user_files/laion400M/img_emb_0.npy', 'Npy', 'img_emb Array(Float32)' )\r\n  ) AS laion_img_emb\r\n  WHERE row_num1 = row_num2\r\n)\r\n# 0 rows in set. Elapsed: 25.233 sec. Processed 2.00 million rows, 1.18 GB (79.30 thousand rows/s., 46.74 MB/s.)\r\n# Peak memory usage: 3.41 GiB.\r\n\r\n# Chech number of rows\r\nSELECT count(*)\r\nFROM laion\r\n# \u250c\u2500count()\u2500\u2510\r\n# \u2502 1000448 \u2502\r\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n## Query\r\n```sql\r\n# Manually copy the 1st embedding. (This will be the emb_query)\r\nSELECT img_emb\r\nFROM laion\r\nLIMIT 1\r\n\r\n\r\nWITH dotProduct(img_emb, [-0.01651,0.0160217,...emb_query...,-0.0291748,-0.0173035]) AS score\r\nSELECT key, score, caption\r\nFROM laion\r\nORDER BY score DESC\r\nLIMIT 3\r\nFORMAT Vertical\r\n# 3 rows in set. Elapsed: 0.447 sec. Processed 1.00 million rows, 2.13 GB (2.24 million rows/s., 4.77 GB/s.)\r\n# Peak memory usage: 164.05 MiB.\r\n\r\nWITH cosineDistance(img_emb, [-0.01651,0.0160217,...emb_query...,-0.0291748,-0.0173035]) AS score\r\nSELECT key, score, caption\r\nFROM laion\r\nORDER BY score DESC\r\nLIMIT 3\r\nFORMAT Vertical\r\n# 3 rows in set. Elapsed: 8.603 sec. Processed 1.00 million rows, 2.13 GB (116.29 thousand rows/s., 247.61 MB/s.)\r\n# Peak memory usage: 420.01 MiB.\r\n```\nInspired from [SimSIMD](https://github.com/ashvardanian/SimSIMD/blob/main/include/simsimd/spatial.h) project, maybe a SIMD version (AVX2) of dot product can be implemented.\r\n\r\n```c\r\n#include <immintrin.h>\r\n\r\n// Function to calculate dot product using AVX2 for float vectors\r\n// https://github.com/kshitijl/avx2-examples/blob/master/examples/04-dot-product.c\r\nfloat avx2_dot_product_float(const float* vector1, const float* vector2, const int size)\r\n{\r\n    __m256 sum = _mm256_setzero_ps(); // Initialize the sum to zero (.0, .0, .0, .0, .0, .0, .0, .0)\r\n\r\n    // Perform the dot product in increments of 8 floats at a time\r\n    for (int i = 0; i < size; i += 8) {\r\n        __m256 vec1 = _mm256_loadu_ps(vector1+i); // Load 8 floats from vector1 ( also &vector1[i] )\r\n        __m256 vec2 = _mm256_loadu_ps(vector2+i]); // Load 8 floats from vector2 ( also &vector2[i] )\r\n        __m256 product = _mm256_mul_ps(vec1, vec2); // Multiply corresponding floats\r\n        sum = _mm256_add_ps(sum, product); // Accumulate the dot product into sum\r\n    }\r\n\r\n    // Find the partial dot-product for the remaining elements\r\n    // after dealing with all 256-bit blocks.\r\n    float trash = 0.0;\r\n    for(i = size-size%8; i<size; ++i)\r\n        trash += vector1[i] * vector2[i];\r\n\r\n    return sum_8_floats(sum) - trash;\r\n}\r\n\r\n\r\n// https://stackoverflow.com/a/13222410\r\nfloat sum_8_floats(__m256 x) // x = ( x7, x6, x5, x4, x3, x2, x1, x0 )\r\n{\r\n    const __m128 hiQuad = _mm256_extractf128_ps(x, 1);       // hiQuad = ( x7, x6, x5, x4 )\r\n    const __m128 loQuad = _mm256_castps256_ps128(x);         // loQuad = ( x3, x2, x1, x0 )\r\n    const __m128 sumQuad = _mm_add_ps(loQuad, hiQuad);       // sumQuad = ( x3+x7, x2+x6, x1+x5, x0+x4 )\r\n    const __m128 loDual = sumQuad;                           // loDual = ( -, -, x1+x5, x0+x4 )\r\n    const __m128 hiDual = _mm_movehl_ps(sumQuad, sumQuad);   // hiDual = ( -, -, x3+x7, x2+x6 )\r\n    const __m128 sumDual = _mm_add_ps(loDual, hiDual);       // sumDual = ( -, -, x1+x3+x5+x7, x0+x2+x4+x6 )\r\n    const __m128 lo = sumDual;                               // lo = ( -, -, -, x0+x2+x4+x6 )\r\n    const __m128 hi = _mm_shuffle_ps(sumDual, sumDual, 0x1); // hi = ( -, -, -, x1+x3+x5+x7 )\r\n    const __m128 sum = _mm_add_ss(lo, hi);                   // sum = ( -, -, -, x0+x1+x2+x3+x4+x5+x6+x7 )\r\n    return _mm_cvtss_f32(sum);\r\n}\r\n```\nI implemented vectorization without knowing about this issue. My implementation and the one in SimSIMD is almost the same (which is a good sign, I guess).",
  "created_at": "2024-02-20T23:01:21Z",
  "modified_files": [
    "docs/en/sql-reference/functions/tuple-functions.md",
    "src/Functions/array/arrayDistance.cpp",
    "src/Functions/array/arrayDotProduct.cpp",
    "src/Functions/array/arrayScalarProduct.h"
  ],
  "modified_test_files": [
    "b/tests/performance/dotProduct.xml",
    "tests/performance/norm_distance.xml",
    "b/tests/queries/0_stateless/02708_dotProduct.reference",
    "b/tests/queries/0_stateless/02708_dotProduct.sql",
    "tests/queries/0_stateless/02708_dot_product.reference",
    "tests/queries/0_stateless/02708_dot_product.sql"
  ]
}