{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 41342,
  "instance_id": "ClickHouse__ClickHouse-41342",
  "issue_numbers": [
    "39845"
  ],
  "base_commit": "36b63badb3c9e3c8ee6d5a6338af45afaa43c634",
  "patch": "diff --git a/programs/keeper/CMakeLists.txt b/programs/keeper/CMakeLists.txt\nindex ce176ccade50..9266a4ca4197 100644\n--- a/programs/keeper/CMakeLists.txt\n+++ b/programs/keeper/CMakeLists.txt\n@@ -45,6 +45,7 @@ if (BUILD_STANDALONE_KEEPER)\n         ${CMAKE_CURRENT_SOURCE_DIR}/../../src/Coordination/KeeperLogStore.cpp\n         ${CMAKE_CURRENT_SOURCE_DIR}/../../src/Coordination/KeeperServer.cpp\n         ${CMAKE_CURRENT_SOURCE_DIR}/../../src/Coordination/KeeperSnapshotManager.cpp\n+        ${CMAKE_CURRENT_SOURCE_DIR}/../../src/Coordination/KeeperSnapshotManagerS3.cpp\n         ${CMAKE_CURRENT_SOURCE_DIR}/../../src/Coordination/KeeperStateMachine.cpp\n         ${CMAKE_CURRENT_SOURCE_DIR}/../../src/Coordination/KeeperStateManager.cpp\n         ${CMAKE_CURRENT_SOURCE_DIR}/../../src/Coordination/KeeperStorage.cpp\ndiff --git a/src/Coordination/KeeperDispatcher.cpp b/src/Coordination/KeeperDispatcher.cpp\nindex d725ecb5cfea..6e9116d4b757 100644\n--- a/src/Coordination/KeeperDispatcher.cpp\n+++ b/src/Coordination/KeeperDispatcher.cpp\n@@ -1,13 +1,20 @@\n #include <Coordination/KeeperDispatcher.h>\n+\n+#include <Poco/Path.h>\n+#include <Poco/Util/AbstractConfiguration.h>\n+\n+#include <Common/hex.h>\n #include <Common/setThreadName.h>\n #include <Common/ZooKeeper/KeeperException.h>\n+#include <Common/checkStackSize.h>\n+#include <Common/CurrentMetrics.h>\n+\n+\n #include <future>\n #include <chrono>\n-#include <Poco/Path.h>\n-#include <Common/hex.h>\n #include <filesystem>\n-#include <Common/checkStackSize.h>\n-#include <Common/CurrentMetrics.h>\n+#include <iterator>\n+#include <limits>\n \n namespace CurrentMetrics\n {\n@@ -32,9 +39,7 @@ KeeperDispatcher::KeeperDispatcher()\n     : responses_queue(std::numeric_limits<size_t>::max())\n     , configuration_and_settings(std::make_shared<KeeperConfigurationAndSettings>())\n     , log(&Poco::Logger::get(\"KeeperDispatcher\"))\n-{\n-}\n-\n+{}\n \n void KeeperDispatcher::requestThread()\n {\n@@ -191,7 +196,13 @@ void KeeperDispatcher::snapshotThread()\n \n         try\n         {\n-            task.create_snapshot(std::move(task.snapshot));\n+            auto snapshot_path = task.create_snapshot(std::move(task.snapshot));\n+\n+            if (snapshot_path.empty())\n+                continue;\n+\n+            if (isLeader())\n+                snapshot_s3.uploadSnapshot(snapshot_path);\n         }\n         catch (...)\n         {\n@@ -285,7 +296,9 @@ void KeeperDispatcher::initialize(const Poco::Util::AbstractConfiguration & conf\n     responses_thread = ThreadFromGlobalPool([this] { responseThread(); });\n     snapshot_thread = ThreadFromGlobalPool([this] { snapshotThread(); });\n \n-    server = std::make_unique<KeeperServer>(configuration_and_settings, config, responses_queue, snapshots_queue);\n+    snapshot_s3.startup(config);\n+\n+    server = std::make_unique<KeeperServer>(configuration_and_settings, config, responses_queue, snapshots_queue, snapshot_s3);\n \n     try\n     {\n@@ -312,7 +325,6 @@ void KeeperDispatcher::initialize(const Poco::Util::AbstractConfiguration & conf\n     /// Start it after keeper server start\n     session_cleaner_thread = ThreadFromGlobalPool([this] { sessionCleanerTask(); });\n     update_configuration_thread = ThreadFromGlobalPool([this] { updateConfigurationThread(); });\n-    updateConfiguration(config);\n \n     LOG_DEBUG(log, \"Dispatcher initialized\");\n }\n@@ -415,6 +427,8 @@ void KeeperDispatcher::shutdown()\n         if (server)\n             server->shutdown();\n \n+        snapshot_s3.shutdown();\n+\n         CurrentMetrics::set(CurrentMetrics::KeeperAliveConnections, 0);\n \n     }\n@@ -678,6 +692,8 @@ void KeeperDispatcher::updateConfiguration(const Poco::Util::AbstractConfigurati\n         if (!push_result)\n             throw Exception(ErrorCodes::SYSTEM_ERROR, \"Cannot push configuration update to queue\");\n     }\n+\n+    snapshot_s3.updateS3Configuration(config);\n }\n \n void KeeperDispatcher::updateKeeperStatLatency(uint64_t process_time_ms)\ndiff --git a/src/Coordination/KeeperDispatcher.h b/src/Coordination/KeeperDispatcher.h\nindex 3b524b24ed7a..0003867adbef 100644\n--- a/src/Coordination/KeeperDispatcher.h\n+++ b/src/Coordination/KeeperDispatcher.h\n@@ -14,6 +14,7 @@\n #include <Coordination/CoordinationSettings.h>\n #include <Coordination/Keeper4LWInfo.h>\n #include <Coordination/KeeperConnectionStats.h>\n+#include <Coordination/KeeperSnapshotManagerS3.h>\n \n namespace DB\n {\n@@ -76,6 +77,8 @@ class KeeperDispatcher\n     /// Counter for new session_id requests.\n     std::atomic<int64_t> internal_session_id_counter{0};\n \n+    KeeperSnapshotManagerS3 snapshot_s3;\n+\n     /// Thread put requests to raft\n     void requestThread();\n     /// Thread put responses for subscribed sessions\ndiff --git a/src/Coordination/KeeperServer.cpp b/src/Coordination/KeeperServer.cpp\nindex 7a0cee746c6c..1c8959379dac 100644\n--- a/src/Coordination/KeeperServer.cpp\n+++ b/src/Coordination/KeeperServer.cpp\n@@ -8,6 +8,7 @@\n #include <string>\n #include <Coordination/KeeperStateMachine.h>\n #include <Coordination/KeeperStateManager.h>\n+#include <Coordination/KeeperSnapshotManagerS3.h>\n #include <Coordination/LoggerWrapper.h>\n #include <Coordination/ReadBufferFromNuraftBuffer.h>\n #include <Coordination/WriteBufferFromNuraftBuffer.h>\n@@ -105,7 +106,8 @@ KeeperServer::KeeperServer(\n     const KeeperConfigurationAndSettingsPtr & configuration_and_settings_,\n     const Poco::Util::AbstractConfiguration & config,\n     ResponsesQueue & responses_queue_,\n-    SnapshotsQueue & snapshots_queue_)\n+    SnapshotsQueue & snapshots_queue_,\n+    KeeperSnapshotManagerS3 & snapshot_manager_s3)\n     : server_id(configuration_and_settings_->server_id)\n     , coordination_settings(configuration_and_settings_->coordination_settings)\n     , log(&Poco::Logger::get(\"KeeperServer\"))\n@@ -125,6 +127,7 @@ KeeperServer::KeeperServer(\n         configuration_and_settings_->snapshot_storage_path,\n         coordination_settings,\n         keeper_context,\n+        config.getBool(\"keeper_server.upload_snapshot_on_exit\", true) ? &snapshot_manager_s3 : nullptr,\n         checkAndGetSuperdigest(configuration_and_settings_->super_digest));\n \n     state_manager = nuraft::cs_new<KeeperStateManager>(\ndiff --git a/src/Coordination/KeeperServer.h b/src/Coordination/KeeperServer.h\nindex 6873ef2a01e0..a33e29b45405 100644\n--- a/src/Coordination/KeeperServer.h\n+++ b/src/Coordination/KeeperServer.h\n@@ -71,7 +71,8 @@ class KeeperServer\n         const KeeperConfigurationAndSettingsPtr & settings_,\n         const Poco::Util::AbstractConfiguration & config_,\n         ResponsesQueue & responses_queue_,\n-        SnapshotsQueue & snapshots_queue_);\n+        SnapshotsQueue & snapshots_queue_,\n+        KeeperSnapshotManagerS3 & snapshot_manager_s3);\n \n     /// Load state machine from the latest snapshot and load log storage. Start NuRaft with required settings.\n     void startup(const Poco::Util::AbstractConfiguration & config, bool enable_ipv6 = true);\ndiff --git a/src/Coordination/KeeperSnapshotManager.h b/src/Coordination/KeeperSnapshotManager.h\nindex c00ce9421e74..526477120832 100644\n--- a/src/Coordination/KeeperSnapshotManager.h\n+++ b/src/Coordination/KeeperSnapshotManager.h\n@@ -87,7 +87,7 @@ struct KeeperStorageSnapshot\n };\n \n using KeeperStorageSnapshotPtr = std::shared_ptr<KeeperStorageSnapshot>;\n-using CreateSnapshotCallback = std::function<void(KeeperStorageSnapshotPtr &&)>;\n+using CreateSnapshotCallback = std::function<std::string(KeeperStorageSnapshotPtr &&)>;\n \n \n using SnapshotMetaAndStorage = std::pair<SnapshotMetadataPtr, KeeperStoragePtr>;\ndiff --git a/src/Coordination/KeeperSnapshotManagerS3.cpp b/src/Coordination/KeeperSnapshotManagerS3.cpp\nnew file mode 100644\nindex 000000000000..2e19d496407f\n--- /dev/null\n+++ b/src/Coordination/KeeperSnapshotManagerS3.cpp\n@@ -0,0 +1,311 @@\n+#include <Coordination/KeeperSnapshotManagerS3.h>\n+\n+#if USE_AWS_S3\n+#include <Core/UUID.h>\n+\n+#include <Common/Exception.h>\n+#include <Common/setThreadName.h>\n+\n+#include <IO/S3Common.h>\n+#include <IO/WriteBufferFromS3.h>\n+#include <IO/ReadBufferFromS3.h>\n+#include <IO/ReadBufferFromFile.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/S3/PocoHTTPClient.h>\n+#include <IO/WriteHelpers.h>\n+#include <IO/copyData.h>\n+\n+#include <aws/core/auth/AWSCredentials.h>\n+#include <aws/s3/S3Client.h>\n+#include <aws/s3/S3Errors.h>\n+#include <aws/s3/model/HeadObjectRequest.h>\n+#include <aws/s3/model/DeleteObjectRequest.h>\n+\n+#include <filesystem>\n+\n+namespace fs = std::filesystem;\n+\n+namespace DB\n+{\n+\n+struct KeeperSnapshotManagerS3::S3Configuration\n+{\n+    S3Configuration(S3::URI uri_, S3::AuthSettings auth_settings_, std::shared_ptr<const Aws::S3::S3Client> client_)\n+        : uri(std::move(uri_))\n+        , auth_settings(std::move(auth_settings_))\n+        , client(std::move(client_))\n+    {}\n+\n+    S3::URI uri;\n+    S3::AuthSettings auth_settings;\n+    std::shared_ptr<const Aws::S3::S3Client> client;\n+};\n+\n+KeeperSnapshotManagerS3::KeeperSnapshotManagerS3()\n+    : snapshots_s3_queue(std::numeric_limits<size_t>::max())\n+    , log(&Poco::Logger::get(\"KeeperSnapshotManagerS3\"))\n+    , uuid(UUIDHelpers::generateV4())\n+{}\n+\n+void KeeperSnapshotManagerS3::updateS3Configuration(const Poco::Util::AbstractConfiguration & config)\n+{\n+    try\n+    {\n+        const std::string config_prefix = \"keeper_server.s3_snapshot\";\n+\n+        if (!config.has(config_prefix))\n+        {\n+            std::lock_guard client_lock{snapshot_s3_client_mutex};\n+            if (snapshot_s3_client)\n+                LOG_INFO(log, \"S3 configuration was removed\");\n+            snapshot_s3_client = nullptr;\n+            return;\n+        }\n+\n+        auto auth_settings = S3::AuthSettings::loadFromConfig(config_prefix, config);\n+\n+        auto endpoint = config.getString(config_prefix + \".endpoint\");\n+        auto new_uri = S3::URI{Poco::URI(endpoint)};\n+\n+        {\n+            std::lock_guard client_lock{snapshot_s3_client_mutex};\n+            // if client is not changed (same auth settings, same endpoint) we don't need to update\n+            if (snapshot_s3_client && snapshot_s3_client->client && auth_settings == snapshot_s3_client->auth_settings\n+                && snapshot_s3_client->uri.uri == new_uri.uri)\n+                return;\n+        }\n+\n+        LOG_INFO(log, \"S3 configuration was updated\");\n+\n+        auto credentials = Aws::Auth::AWSCredentials(auth_settings.access_key_id, auth_settings.secret_access_key);\n+        HeaderCollection headers = auth_settings.headers;\n+\n+        static constexpr size_t s3_max_redirects = 10;\n+        static constexpr bool enable_s3_requests_logging = false;\n+\n+        if (!new_uri.key.empty())\n+        {\n+            LOG_ERROR(log, \"Invalid endpoint defined for S3, it shouldn't contain key, endpoint: {}\", endpoint);\n+            return;\n+        }\n+\n+        S3::PocoHTTPClientConfiguration client_configuration = S3::ClientFactory::instance().createClientConfiguration(\n+            auth_settings.region,\n+            RemoteHostFilter(), s3_max_redirects,\n+            enable_s3_requests_logging,\n+            /* for_disk_s3 = */ false);\n+\n+        client_configuration.endpointOverride = new_uri.endpoint;\n+\n+        auto client = S3::ClientFactory::instance().create(\n+            client_configuration,\n+            new_uri.is_virtual_hosted_style,\n+            credentials.GetAWSAccessKeyId(),\n+            credentials.GetAWSSecretKey(),\n+            auth_settings.server_side_encryption_customer_key_base64,\n+            std::move(headers),\n+            auth_settings.use_environment_credentials.value_or(false),\n+            auth_settings.use_insecure_imds_request.value_or(false));\n+\n+        auto new_client = std::make_shared<KeeperSnapshotManagerS3::S3Configuration>(std::move(new_uri), std::move(auth_settings), std::move(client));\n+\n+        {\n+            std::lock_guard client_lock{snapshot_s3_client_mutex};\n+            snapshot_s3_client = std::move(new_client);\n+        }\n+        LOG_INFO(log, \"S3 client was updated\");\n+    }\n+    catch (...)\n+    {\n+        LOG_ERROR(log, \"Failed to create an S3 client for snapshots\");\n+        tryLogCurrentException(__PRETTY_FUNCTION__);\n+    }\n+}\n+std::shared_ptr<KeeperSnapshotManagerS3::S3Configuration> KeeperSnapshotManagerS3::getSnapshotS3Client() const\n+{\n+    std::lock_guard lock{snapshot_s3_client_mutex};\n+    return snapshot_s3_client;\n+}\n+\n+void KeeperSnapshotManagerS3::uploadSnapshotImpl(const std::string & snapshot_path)\n+{\n+    try\n+    {\n+        auto s3_client = getSnapshotS3Client();\n+        if (s3_client == nullptr)\n+            return;\n+\n+        S3Settings::ReadWriteSettings read_write_settings;\n+        read_write_settings.upload_part_size_multiply_parts_count_threshold = 10000;\n+\n+        const auto create_writer = [&](const auto & key)\n+        {\n+            return WriteBufferFromS3\n+            {\n+                s3_client->client,\n+                s3_client->uri.bucket,\n+                key,\n+                read_write_settings\n+            };\n+        };\n+\n+        const auto file_exists = [&](const auto & key)\n+        {\n+            Aws::S3::Model::HeadObjectRequest request;\n+            request.SetBucket(s3_client->uri.bucket);\n+            request.SetKey(key);\n+            auto outcome = s3_client->client->HeadObject(request);\n+\n+            if (outcome.IsSuccess())\n+                return true;\n+\n+            const auto & error = outcome.GetError();\n+            if (error.GetErrorType() != Aws::S3::S3Errors::NO_SUCH_KEY && error.GetErrorType() != Aws::S3::S3Errors::RESOURCE_NOT_FOUND)\n+                throw S3Exception(error.GetErrorType(), \"Failed to verify existence of lock file: {}\", error.GetMessage());\n+\n+            return false;\n+        };\n+\n+\n+        LOG_INFO(log, \"Will try to upload snapshot on {} to S3\", snapshot_path);\n+        ReadBufferFromFile snapshot_file(snapshot_path);\n+\n+        auto snapshot_name = fs::path(snapshot_path).filename().string();\n+        auto lock_file = fmt::format(\".{}_LOCK\", snapshot_name);\n+\n+        if (file_exists(snapshot_name))\n+        {\n+            LOG_ERROR(log, \"Snapshot {} already exists\", snapshot_name);\n+            return;\n+        }\n+\n+        // First we need to verify that there isn't already a lock file for the snapshot we want to upload\n+        // Only leader uploads a snapshot, but there can be a rare case where we have 2 leaders in NuRaft\n+        if (file_exists(lock_file))\n+        {\n+            LOG_ERROR(log, \"Lock file for {} already, exists. Probably a different node is already uploading the snapshot\", snapshot_name);\n+            return;\n+        }\n+\n+        // We write our UUID to lock file\n+        LOG_DEBUG(log, \"Trying to create a lock file\");\n+        WriteBufferFromS3 lock_writer = create_writer(lock_file);\n+        writeUUIDText(uuid, lock_writer);\n+        lock_writer.finalize();\n+\n+        // We read back the written UUID, if it's the same we can upload the file\n+        ReadBufferFromS3 lock_reader\n+        {\n+            s3_client->client,\n+            s3_client->uri.bucket,\n+            lock_file,\n+            \"\",\n+            1,\n+            {}\n+        };\n+\n+        std::string read_uuid;\n+        readStringUntilEOF(read_uuid, lock_reader);\n+\n+        if (read_uuid != toString(uuid))\n+        {\n+            LOG_ERROR(log, \"Failed to create a lock file\");\n+            return;\n+        }\n+\n+        SCOPE_EXIT(\n+        {\n+            LOG_INFO(log, \"Removing lock file\");\n+            try\n+            {\n+                Aws::S3::Model::DeleteObjectRequest delete_request;\n+                delete_request.SetBucket(s3_client->uri.bucket);\n+                delete_request.SetKey(lock_file);\n+                auto delete_outcome = s3_client->client->DeleteObject(delete_request);\n+                if (!delete_outcome.IsSuccess())\n+                    throw S3Exception(delete_outcome.GetError().GetMessage(), delete_outcome.GetError().GetErrorType());\n+            }\n+            catch (...)\n+            {\n+                LOG_INFO(log, \"Failed to delete lock file for {} from S3\", snapshot_path);\n+                tryLogCurrentException(__PRETTY_FUNCTION__);\n+            }\n+        });\n+\n+        WriteBufferFromS3 snapshot_writer = create_writer(snapshot_name);\n+        copyData(snapshot_file, snapshot_writer);\n+        snapshot_writer.finalize();\n+\n+        LOG_INFO(log, \"Successfully uploaded {} to S3\", snapshot_path);\n+    }\n+    catch (...)\n+    {\n+        LOG_INFO(log, \"Failure during upload of {} to S3\", snapshot_path);\n+        tryLogCurrentException(__PRETTY_FUNCTION__);\n+    }\n+}\n+\n+void KeeperSnapshotManagerS3::snapshotS3Thread()\n+{\n+    setThreadName(\"KeeperS3SnpT\");\n+\n+    while (!shutdown_called)\n+    {\n+        std::string snapshot_path;\n+        if (!snapshots_s3_queue.pop(snapshot_path))\n+            break;\n+\n+        if (shutdown_called)\n+            break;\n+\n+        uploadSnapshotImpl(snapshot_path);\n+    }\n+}\n+\n+void KeeperSnapshotManagerS3::uploadSnapshot(const std::string & path, bool async_upload)\n+{\n+    if (getSnapshotS3Client() == nullptr)\n+        return;\n+\n+    if (async_upload)\n+    {\n+        if (!snapshots_s3_queue.push(path))\n+            LOG_WARNING(log, \"Failed to add snapshot {} to S3 queue\", path);\n+\n+        return;\n+    }\n+\n+    uploadSnapshotImpl(path);\n+}\n+\n+void KeeperSnapshotManagerS3::startup(const Poco::Util::AbstractConfiguration & config)\n+{\n+    updateS3Configuration(config);\n+    snapshot_s3_thread = ThreadFromGlobalPool([this] { snapshotS3Thread(); });\n+}\n+\n+void KeeperSnapshotManagerS3::shutdown()\n+{\n+    if (shutdown_called)\n+        return;\n+\n+    LOG_DEBUG(log, \"Shutting down KeeperSnapshotManagerS3\");\n+    shutdown_called = true;\n+\n+    try\n+    {\n+        snapshots_s3_queue.finish();\n+        if (snapshot_s3_thread.joinable())\n+            snapshot_s3_thread.join();\n+    }\n+    catch (...)\n+    {\n+        tryLogCurrentException(__PRETTY_FUNCTION__);\n+    }\n+\n+    LOG_INFO(log, \"KeeperSnapshotManagerS3 shut down\");\n+}\n+\n+}\n+\n+#endif\ndiff --git a/src/Coordination/KeeperSnapshotManagerS3.h b/src/Coordination/KeeperSnapshotManagerS3.h\nnew file mode 100644\nindex 000000000000..5b62d114aae6\n--- /dev/null\n+++ b/src/Coordination/KeeperSnapshotManagerS3.h\n@@ -0,0 +1,68 @@\n+#pragma once\n+\n+#include \"config.h\"\n+\n+#include <Poco/Util/AbstractConfiguration.h>\n+\n+#if USE_AWS_S3\n+#include <Common/ConcurrentBoundedQueue.h>\n+#include <Common/ThreadPool.h>\n+#include <Common/logger_useful.h>\n+\n+#include <string>\n+#endif\n+\n+namespace DB\n+{\n+\n+#if USE_AWS_S3\n+class KeeperSnapshotManagerS3\n+{\n+public:\n+    KeeperSnapshotManagerS3();\n+\n+    void updateS3Configuration(const Poco::Util::AbstractConfiguration & config);\n+    void uploadSnapshot(const std::string & path, bool async_upload = true);\n+\n+    void startup(const Poco::Util::AbstractConfiguration & config);\n+    void shutdown();\n+private:\n+    using SnapshotS3Queue = ConcurrentBoundedQueue<std::string>;\n+    SnapshotS3Queue snapshots_s3_queue;\n+\n+    /// Upload new snapshots to S3\n+    ThreadFromGlobalPool snapshot_s3_thread;\n+\n+    struct S3Configuration;\n+    mutable std::mutex snapshot_s3_client_mutex;\n+    std::shared_ptr<S3Configuration> snapshot_s3_client;\n+\n+    std::atomic<bool> shutdown_called{false};\n+\n+    Poco::Logger * log;\n+\n+    UUID uuid;\n+\n+    std::shared_ptr<S3Configuration> getSnapshotS3Client() const;\n+\n+    void uploadSnapshotImpl(const std::string & snapshot_path);\n+\n+    /// Thread upload snapshots to S3 in the background\n+    void snapshotS3Thread();\n+};\n+#else\n+class KeeperSnapshotManagerS3\n+{\n+public:\n+    KeeperSnapshotManagerS3() = default;\n+\n+    void updateS3Configuration(const Poco::Util::AbstractConfiguration &) {}\n+    void uploadSnapshot(const std::string &, [[maybe_unused]] bool async_upload = true) {}\n+\n+    void startup(const Poco::Util::AbstractConfiguration &) {}\n+\n+    void shutdown() {}\n+};\n+#endif\n+\n+}\ndiff --git a/src/Coordination/KeeperStateMachine.cpp b/src/Coordination/KeeperStateMachine.cpp\nindex c5a66ce29cab..ee5bfa48357e 100644\n--- a/src/Coordination/KeeperStateMachine.cpp\n+++ b/src/Coordination/KeeperStateMachine.cpp\n@@ -44,6 +44,7 @@ KeeperStateMachine::KeeperStateMachine(\n     const std::string & snapshots_path_,\n     const CoordinationSettingsPtr & coordination_settings_,\n     const KeeperContextPtr & keeper_context_,\n+    KeeperSnapshotManagerS3 * snapshot_manager_s3_,\n     const std::string & superdigest_)\n     : coordination_settings(coordination_settings_)\n     , snapshot_manager(\n@@ -59,6 +60,7 @@ KeeperStateMachine::KeeperStateMachine(\n     , log(&Poco::Logger::get(\"KeeperStateMachine\"))\n     , superdigest(superdigest_)\n     , keeper_context(keeper_context_)\n+    , snapshot_manager_s3(snapshot_manager_s3_)\n {\n }\n \n@@ -400,13 +402,22 @@ void KeeperStateMachine::create_snapshot(nuraft::snapshot & s, nuraft::async_res\n         }\n \n         when_done(ret, exception);\n+\n+        return ret ? latest_snapshot_path : \"\";\n     };\n \n \n     if (keeper_context->server_state == KeeperContext::Phase::SHUTDOWN)\n     {\n         LOG_INFO(log, \"Creating a snapshot during shutdown because 'create_snapshot_on_exit' is enabled.\");\n-        snapshot_task.create_snapshot(std::move(snapshot_task.snapshot));\n+        auto snapshot_path = snapshot_task.create_snapshot(std::move(snapshot_task.snapshot));\n+\n+        if (!snapshot_path.empty() && snapshot_manager_s3)\n+        {\n+            LOG_INFO(log, \"Uploading snapshot {} during shutdown because 'upload_snapshot_on_exit' is enabled.\", snapshot_path);\n+            snapshot_manager_s3->uploadSnapshot(snapshot_path, /* asnyc_upload */ false);\n+        }\n+\n         return;\n     }\n \ndiff --git a/src/Coordination/KeeperStateMachine.h b/src/Coordination/KeeperStateMachine.h\nindex fbd4fdc5ac2b..ffc7fce1cfea 100644\n--- a/src/Coordination/KeeperStateMachine.h\n+++ b/src/Coordination/KeeperStateMachine.h\n@@ -2,11 +2,13 @@\n \n #include <Coordination/CoordinationSettings.h>\n #include <Coordination/KeeperSnapshotManager.h>\n+#include <Coordination/KeeperSnapshotManagerS3.h>\n+#include <Coordination/KeeperContext.h>\n #include <Coordination/KeeperStorage.h>\n+\n #include <libnuraft/nuraft.hxx>\n #include <Common/ConcurrentBoundedQueue.h>\n #include <Common/logger_useful.h>\n-#include <Coordination/KeeperContext.h>\n \n \n namespace DB\n@@ -26,6 +28,7 @@ class KeeperStateMachine : public nuraft::state_machine\n         const std::string & snapshots_path_,\n         const CoordinationSettingsPtr & coordination_settings_,\n         const KeeperContextPtr & keeper_context_,\n+        KeeperSnapshotManagerS3 * snapshot_manager_s3_,\n         const std::string & superdigest_ = \"\");\n \n     /// Read state from the latest snapshot\n@@ -146,6 +149,8 @@ class KeeperStateMachine : public nuraft::state_machine\n     const std::string superdigest;\n \n     KeeperContextPtr keeper_context;\n+\n+    KeeperSnapshotManagerS3 * snapshot_manager_s3;\n };\n \n }\ndiff --git a/src/IO/S3/PocoHTTPClient.h b/src/IO/S3/PocoHTTPClient.h\nindex 57e4369e565b..5649638285db 100644\n--- a/src/IO/S3/PocoHTTPClient.h\n+++ b/src/IO/S3/PocoHTTPClient.h\n@@ -2,20 +2,22 @@\n \n #include \"config.h\"\n \n+#include <string>\n+#include <vector>\n+\n #if USE_AWS_S3\n \n #include <Common/RemoteHostFilter.h>\n #include <IO/ConnectionTimeouts.h>\n #include <IO/HTTPCommon.h>\n #include <IO/S3/SessionAwareIOStream.h>\n-#include <Storages/StorageS3Settings.h>\n+#include <Storages/HeaderCollection.h>\n \n #include <aws/core/client/ClientConfiguration.h>\n #include <aws/core/http/HttpClient.h>\n #include <aws/core/http/HttpRequest.h>\n #include <aws/core/http/standard/StandardHttpResponse.h>\n \n-\n namespace Aws::Http::Standard\n {\n class StandardHttpResponse;\n@@ -23,6 +25,7 @@ class StandardHttpResponse;\n \n namespace DB\n {\n+\n class Context;\n }\n \ndiff --git a/src/IO/S3Common.cpp b/src/IO/S3Common.cpp\nindex df19748b4930..859f5ce796be 100644\n--- a/src/IO/S3Common.cpp\n+++ b/src/IO/S3Common.cpp\n@@ -1,9 +1,11 @@\n+#include <IO/S3Common.h>\n+\n+#include <Common/Exception.h>\n+#include <Poco/Util/AbstractConfiguration.h>\n #include \"config.h\"\n \n #if USE_AWS_S3\n \n-#    include <IO/S3Common.h>\n-\n #    include <Common/quoteString.h>\n \n #    include <IO/WriteBufferFromString.h>\n@@ -780,25 +782,16 @@ namespace S3\n \n             boost::to_upper(name);\n             if (name != S3 && name != COS && name != OBS && name != OSS)\n-            {\n                 throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Object storage system name is unrecognized in virtual hosted style S3 URI: {}\", quoteString(name));\n-            }\n+\n             if (name == S3)\n-            {\n                 storage_name = name;\n-            }\n             else if (name == OBS)\n-            {\n                 storage_name = OBS;\n-            }\n             else if (name == OSS)\n-            {\n                 storage_name = OSS;\n-            }\n             else\n-            {\n                 storage_name = COSN;\n-            }\n         }\n         else if (re2::RE2::PartialMatch(uri.getPath(), path_style_pattern, &bucket, &key))\n         {\n@@ -851,8 +844,82 @@ namespace S3\n     {\n         return getObjectInfo(client_ptr, bucket, key, version_id, throw_on_error, for_disk_s3).size;\n     }\n+\n }\n \n }\n \n #endif\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int INVALID_CONFIG_PARAMETER;\n+}\n+\n+namespace S3\n+{\n+\n+AuthSettings AuthSettings::loadFromConfig(const std::string & config_elem, const Poco::Util::AbstractConfiguration & config)\n+{\n+    auto access_key_id = config.getString(config_elem + \".access_key_id\", \"\");\n+    auto secret_access_key = config.getString(config_elem + \".secret_access_key\", \"\");\n+    auto region = config.getString(config_elem + \".region\", \"\");\n+    auto server_side_encryption_customer_key_base64 = config.getString(config_elem + \".server_side_encryption_customer_key_base64\", \"\");\n+\n+    std::optional<bool> use_environment_credentials;\n+    if (config.has(config_elem + \".use_environment_credentials\"))\n+        use_environment_credentials = config.getBool(config_elem + \".use_environment_credentials\");\n+\n+    std::optional<bool> use_insecure_imds_request;\n+    if (config.has(config_elem + \".use_insecure_imds_request\"))\n+        use_insecure_imds_request = config.getBool(config_elem + \".use_insecure_imds_request\");\n+\n+    HeaderCollection headers;\n+    Poco::Util::AbstractConfiguration::Keys subconfig_keys;\n+    config.keys(config_elem, subconfig_keys);\n+    for (const std::string & subkey : subconfig_keys)\n+    {\n+        if (subkey.starts_with(\"header\"))\n+        {\n+            auto header_str = config.getString(config_elem + \".\" + subkey);\n+            auto delimiter = header_str.find(':');\n+            if (delimiter == std::string::npos)\n+                throw Exception(\"Malformed s3 header value\", ErrorCodes::INVALID_CONFIG_PARAMETER);\n+            headers.emplace_back(HttpHeader{header_str.substr(0, delimiter), header_str.substr(delimiter + 1, String::npos)});\n+        }\n+    }\n+\n+    return AuthSettings\n+    {\n+        std::move(access_key_id), std::move(secret_access_key),\n+        std::move(region),\n+        std::move(server_side_encryption_customer_key_base64),\n+        std::move(headers),\n+        use_environment_credentials,\n+        use_insecure_imds_request\n+    };\n+}\n+\n+\n+void AuthSettings::updateFrom(const AuthSettings & from)\n+{\n+    /// Update with check for emptyness only parameters which\n+    /// can be passed not only from config, but via ast.\n+\n+    if (!from.access_key_id.empty())\n+        access_key_id = from.access_key_id;\n+    if (!from.secret_access_key.empty())\n+        secret_access_key = from.secret_access_key;\n+\n+    headers = from.headers;\n+    region = from.region;\n+    server_side_encryption_customer_key_base64 = from.server_side_encryption_customer_key_base64;\n+    use_environment_credentials = from.use_environment_credentials;\n+    use_insecure_imds_request = from.use_insecure_imds_request;\n+}\n+\n+}\n+}\ndiff --git a/src/IO/S3Common.h b/src/IO/S3Common.h\nindex 5c27b32985ff..93e5eb78c7ff 100644\n--- a/src/IO/S3Common.h\n+++ b/src/IO/S3Common.h\n@@ -1,5 +1,11 @@\n #pragma once\n \n+#include <Storages/HeaderCollection.h>\n+#include <IO/S3/PocoHTTPClient.h>\n+\n+#include <string>\n+#include <optional>\n+\n #include \"config.h\"\n \n #if USE_AWS_S3\n@@ -8,7 +14,6 @@\n #include <aws/core/Aws.h>\n #include <aws/core/client/ClientConfiguration.h>\n #include <aws/s3/S3Errors.h>\n-#include <IO/S3/PocoHTTPClient.h>\n #include <Poco/URI.h>\n \n #include <Common/Exception.h>\n@@ -27,8 +32,6 @@ namespace ErrorCodes\n }\n \n class RemoteHostFilter;\n-struct HttpHeader;\n-using HeaderCollection = std::vector<HttpHeader>;\n \n class S3Exception : public Exception\n {\n@@ -130,5 +133,33 @@ S3::ObjectInfo getObjectInfo(std::shared_ptr<const Aws::S3::S3Client> client_ptr\n size_t getObjectSize(std::shared_ptr<const Aws::S3::S3Client> client_ptr, const String & bucket, const String & key, const String & version_id, bool throw_on_error, bool for_disk_s3);\n \n }\n-\n #endif\n+\n+namespace Poco::Util\n+{\n+class AbstractConfiguration;\n+};\n+\n+namespace DB::S3\n+{\n+\n+struct AuthSettings\n+{\n+    static AuthSettings loadFromConfig(const std::string & config_elem, const Poco::Util::AbstractConfiguration & config);\n+\n+    std::string access_key_id;\n+    std::string secret_access_key;\n+    std::string region;\n+    std::string server_side_encryption_customer_key_base64;\n+\n+    HeaderCollection headers;\n+\n+    std::optional<bool> use_environment_credentials;\n+    std::optional<bool> use_insecure_imds_request;\n+\n+    bool operator==(const AuthSettings & other) const = default;\n+\n+    void updateFrom(const AuthSettings & from);\n+};\n+\n+}\ndiff --git a/src/Storages/ExternalDataSourceConfiguration.h b/src/Storages/ExternalDataSourceConfiguration.h\nindex 0890247eb45d..5736336983a9 100644\n--- a/src/Storages/ExternalDataSourceConfiguration.h\n+++ b/src/Storages/ExternalDataSourceConfiguration.h\n@@ -117,7 +117,7 @@ struct URLBasedDataSourceConfiguration\n \n struct StorageS3Configuration : URLBasedDataSourceConfiguration\n {\n-    S3Settings::AuthSettings auth_settings;\n+    S3::AuthSettings auth_settings;\n     S3Settings::ReadWriteSettings rw_settings;\n };\n \ndiff --git a/src/Storages/StorageS3.h b/src/Storages/StorageS3.h\nindex a983a59d98ce..c74a85019643 100644\n--- a/src/Storages/StorageS3.h\n+++ b/src/Storages/StorageS3.h\n@@ -197,7 +197,7 @@ class StorageS3 : public IStorage, WithContext\n         const S3::URI uri;\n         std::shared_ptr<const Aws::S3::S3Client> client;\n \n-        S3Settings::AuthSettings auth_settings;\n+        S3::AuthSettings auth_settings;\n         S3Settings::ReadWriteSettings rw_settings;\n \n         /// If s3 configuration was passed from ast, then it is static.\n@@ -209,7 +209,7 @@ class StorageS3 : public IStorage, WithContext\n \n         S3Configuration(\n             const String & url_,\n-            const S3Settings::AuthSettings & auth_settings_,\n+            const S3::AuthSettings & auth_settings_,\n             const S3Settings::ReadWriteSettings & rw_settings_,\n             const HeaderCollection & headers_from_ast_)\n             : uri(S3::URI(url_))\ndiff --git a/src/Storages/StorageS3Settings.cpp b/src/Storages/StorageS3Settings.cpp\nindex 4ab3375e1886..65e9bb1ab8c4 100644\n--- a/src/Storages/StorageS3Settings.cpp\n+++ b/src/Storages/StorageS3Settings.cpp\n@@ -1,5 +1,7 @@\n #include <Storages/StorageS3Settings.h>\n \n+#include <IO/S3Common.h>\n+\n #include <Poco/Util/AbstractConfiguration.h>\n #include <Common/Exception.h>\n #include <Interpreters/Context.h>\n@@ -9,10 +11,6 @@\n \n namespace DB\n {\n-namespace ErrorCodes\n-{\n-    extern const int INVALID_CONFIG_PARAMETER;\n-}\n \n void StorageS3Settings::loadFromConfig(const String & config_elem, const Poco::Util::AbstractConfiguration & config, const Settings & settings)\n {\n@@ -46,41 +44,8 @@ void StorageS3Settings::loadFromConfig(const String & config_elem, const Poco::U\n         if (config.has(config_elem + \".\" + key + \".endpoint\"))\n         {\n             auto endpoint = get_string_for_key(key, \"endpoint\", false);\n-            auto access_key_id = get_string_for_key(key, \"access_key_id\");\n-            auto secret_access_key = get_string_for_key(key, \"secret_access_key\");\n-            auto region = get_string_for_key(key, \"region\");\n-            auto server_side_encryption_customer_key_base64 = get_string_for_key(key, \"server_side_encryption_customer_key_base64\");\n-\n-            std::optional<bool> use_environment_credentials;\n-            if (config.has(config_elem + \".\" + key + \".use_environment_credentials\"))\n-                use_environment_credentials = config.getBool(config_elem + \".\" + key + \".use_environment_credentials\");\n-\n-            std::optional<bool> use_insecure_imds_request;\n-            if (config.has(config_elem + \".\" + key + \".use_insecure_imds_request\"))\n-                use_insecure_imds_request = config.getBool(config_elem + \".\" + key + \".use_insecure_imds_request\");\n-\n-            HeaderCollection headers;\n-            Poco::Util::AbstractConfiguration::Keys subconfig_keys;\n-            config.keys(config_elem + \".\" + key, subconfig_keys);\n-            for (const String & subkey : subconfig_keys)\n-            {\n-                if (subkey.starts_with(\"header\"))\n-                {\n-                    auto header_str = config.getString(config_elem + \".\" + key + \".\" + subkey);\n-                    auto delimiter = header_str.find(':');\n-                    if (delimiter == String::npos)\n-                        throw Exception(\"Malformed s3 header value\", ErrorCodes::INVALID_CONFIG_PARAMETER);\n-                    headers.emplace_back(HttpHeader{header_str.substr(0, delimiter), header_str.substr(delimiter + 1, String::npos)});\n-                }\n-            }\n-\n-            S3Settings::AuthSettings auth_settings{\n-                    std::move(access_key_id), std::move(secret_access_key),\n-                    std::move(region),\n-                    std::move(server_side_encryption_customer_key_base64),\n-                    std::move(headers),\n-                    use_environment_credentials,\n-                    use_insecure_imds_request};\n+\n+            auto auth_settings = S3::AuthSettings::loadFromConfig(config_elem + \".\" + key, config);\n \n             S3Settings::ReadWriteSettings rw_settings;\n             rw_settings.max_single_read_retries = get_uint_for_key(key, \"max_single_read_retries\", true, settings.s3_max_single_read_retries);\ndiff --git a/src/Storages/StorageS3Settings.h b/src/Storages/StorageS3Settings.h\nindex 80ef4f52debd..2da4a1d75904 100644\n--- a/src/Storages/StorageS3Settings.h\n+++ b/src/Storages/StorageS3Settings.h\n@@ -9,6 +9,8 @@\n #include <Interpreters/Context_fwd.h>\n #include <Storages/HeaderCollection.h>\n \n+#include <IO/S3Common.h>\n+\n namespace Poco::Util\n {\n class AbstractConfiguration;\n@@ -21,46 +23,6 @@ struct Settings;\n \n struct S3Settings\n {\n-    struct AuthSettings\n-    {\n-        String access_key_id;\n-        String secret_access_key;\n-        String region;\n-        String server_side_encryption_customer_key_base64;\n-\n-        HeaderCollection headers;\n-\n-        std::optional<bool> use_environment_credentials;\n-        std::optional<bool> use_insecure_imds_request;\n-\n-        inline bool operator==(const AuthSettings & other) const\n-        {\n-            return access_key_id == other.access_key_id && secret_access_key == other.secret_access_key\n-                && region == other.region\n-                && server_side_encryption_customer_key_base64 == other.server_side_encryption_customer_key_base64\n-                && headers == other.headers\n-                && use_environment_credentials == other.use_environment_credentials\n-                && use_insecure_imds_request == other.use_insecure_imds_request;\n-        }\n-\n-        void updateFrom(const AuthSettings & from)\n-        {\n-            /// Update with check for emptyness only parameters which\n-            /// can be passed not only from config, but via ast.\n-\n-            if (!from.access_key_id.empty())\n-                access_key_id = from.access_key_id;\n-            if (!from.secret_access_key.empty())\n-                secret_access_key = from.secret_access_key;\n-\n-            headers = from.headers;\n-            region = from.region;\n-            server_side_encryption_customer_key_base64 = from.server_side_encryption_customer_key_base64;\n-            use_environment_credentials = from.use_environment_credentials;\n-            use_insecure_imds_request = from.use_insecure_imds_request;\n-        }\n-    };\n-\n     struct ReadWriteSettings\n     {\n         size_t max_single_read_retries = 0;\n@@ -90,7 +52,7 @@ struct S3Settings\n         void updateFromSettingsIfEmpty(const Settings & settings);\n     };\n \n-    AuthSettings auth_settings;\n+    S3::AuthSettings auth_settings;\n     ReadWriteSettings rw_settings;\n \n     inline bool operator==(const S3Settings & other) const\ndiff --git a/utils/keeper-data-dumper/main.cpp b/utils/keeper-data-dumper/main.cpp\nindex 0762c740ac17..dd3c3a4e2ada 100644\n--- a/utils/keeper-data-dumper/main.cpp\n+++ b/utils/keeper-data-dumper/main.cpp\n@@ -63,7 +63,7 @@ int main(int argc, char *argv[])\n     SnapshotsQueue snapshots_queue{1};\n     CoordinationSettingsPtr settings = std::make_shared<CoordinationSettings>();\n     KeeperContextPtr keeper_context = std::make_shared<DB::KeeperContext>();\n-    auto state_machine = std::make_shared<KeeperStateMachine>(queue, snapshots_queue, argv[1], settings, keeper_context);\n+    auto state_machine = std::make_shared<KeeperStateMachine>(queue, snapshots_queue, argv[1], settings, keeper_context, nullptr);\n     state_machine->init();\n     size_t last_commited_index = state_machine->last_commit_index();\n \n",
  "test_patch": "diff --git a/src/Coordination/tests/gtest_coordination.cpp b/src/Coordination/tests/gtest_coordination.cpp\nindex 5bb1ecc7c85e..b1d27d4541db 100644\n--- a/src/Coordination/tests/gtest_coordination.cpp\n+++ b/src/Coordination/tests/gtest_coordination.cpp\n@@ -1318,7 +1318,7 @@ void testLogAndStateMachine(Coordination::CoordinationSettingsPtr settings, uint\n \n     ResponsesQueue queue(std::numeric_limits<size_t>::max());\n     SnapshotsQueue snapshots_queue{1};\n-    auto state_machine = std::make_shared<KeeperStateMachine>(queue, snapshots_queue, \"./snapshots\", settings, keeper_context);\n+    auto state_machine = std::make_shared<KeeperStateMachine>(queue, snapshots_queue, \"./snapshots\", settings, keeper_context, nullptr);\n     state_machine->init();\n     DB::KeeperLogStore changelog(\"./logs\", settings->rotate_log_storage_interval, true, enable_compression);\n     changelog.init(state_machine->last_commit_index() + 1, settings->reserved_log_items);\n@@ -1359,7 +1359,7 @@ void testLogAndStateMachine(Coordination::CoordinationSettingsPtr settings, uint\n     }\n \n     SnapshotsQueue snapshots_queue1{1};\n-    auto restore_machine = std::make_shared<KeeperStateMachine>(queue, snapshots_queue1, \"./snapshots\", settings, keeper_context);\n+    auto restore_machine = std::make_shared<KeeperStateMachine>(queue, snapshots_queue1, \"./snapshots\", settings, keeper_context, nullptr);\n     restore_machine->init();\n     EXPECT_EQ(restore_machine->last_commit_index(), total_logs - total_logs % settings->snapshot_distance);\n \n@@ -1471,7 +1471,7 @@ TEST_P(CoordinationTest, TestEphemeralNodeRemove)\n \n     ResponsesQueue queue(std::numeric_limits<size_t>::max());\n     SnapshotsQueue snapshots_queue{1};\n-    auto state_machine = std::make_shared<KeeperStateMachine>(queue, snapshots_queue, \"./snapshots\", settings, keeper_context);\n+    auto state_machine = std::make_shared<KeeperStateMachine>(queue, snapshots_queue, \"./snapshots\", settings, keeper_context, nullptr);\n     state_machine->init();\n \n     std::shared_ptr<ZooKeeperCreateRequest> request_c = std::make_shared<ZooKeeperCreateRequest>();\ndiff --git a/tests/integration/test_keeper_s3_snapshot/__init__.py b/tests/integration/test_keeper_s3_snapshot/__init__.py\nnew file mode 100644\nindex 000000000000..e5a0d9b4834e\n--- /dev/null\n+++ b/tests/integration/test_keeper_s3_snapshot/__init__.py\n@@ -0,0 +1,1 @@\n+#!/usr/bin/env python3\ndiff --git a/tests/integration/test_keeper_s3_snapshot/configs/keeper_config1.xml b/tests/integration/test_keeper_s3_snapshot/configs/keeper_config1.xml\nnew file mode 100644\nindex 000000000000..8459ea3e0680\n--- /dev/null\n+++ b/tests/integration/test_keeper_s3_snapshot/configs/keeper_config1.xml\n@@ -0,0 +1,42 @@\n+<clickhouse>\n+    <keeper_server>\n+        <s3_snapshot>\n+            <endpoint>http://minio1:9001/snapshots/</endpoint>\n+            <access_key_id>minio</access_key_id>\n+            <secret_access_key>minio123</secret_access_key>\n+        </s3_snapshot>\n+        <tcp_port>9181</tcp_port>\n+        <server_id>1</server_id>\n+        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>\n+        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>\n+        <four_letter_word_white_list>*</four_letter_word_white_list>\n+\n+        <coordination_settings>\n+            <operation_timeout_ms>5000</operation_timeout_ms>\n+            <session_timeout_ms>10000</session_timeout_ms>\n+            <min_session_timeout_ms>5000</min_session_timeout_ms>\n+            <snapshot_distance>50</snapshot_distance>\n+            <raft_logs_level>trace</raft_logs_level>\n+        </coordination_settings>\n+\n+        <raft_configuration>\n+            <server>\n+                <id>1</id>\n+                <hostname>node1</hostname>\n+                <port>9234</port>\n+            </server>\n+            <server>\n+                <id>2</id>\n+                <hostname>node2</hostname>\n+                <port>9234</port>\n+                <start_as_follower>true</start_as_follower>\n+            </server>\n+            <server>\n+                <id>3</id>\n+                <hostname>node3</hostname>\n+                <port>9234</port>\n+                <start_as_follower>true</start_as_follower>\n+            </server>\n+        </raft_configuration>\n+    </keeper_server>\n+</clickhouse>\ndiff --git a/tests/integration/test_keeper_s3_snapshot/configs/keeper_config2.xml b/tests/integration/test_keeper_s3_snapshot/configs/keeper_config2.xml\nnew file mode 100644\nindex 000000000000..dfe73628f663\n--- /dev/null\n+++ b/tests/integration/test_keeper_s3_snapshot/configs/keeper_config2.xml\n@@ -0,0 +1,42 @@\n+<clickhouse>\n+    <keeper_server>\n+        <s3_snapshot>\n+            <endpoint>http://minio1:9001/snapshots/</endpoint>\n+            <access_key_id>minio</access_key_id>\n+            <secret_access_key>minio123</secret_access_key>\n+        </s3_snapshot>\n+        <tcp_port>9181</tcp_port>\n+        <server_id>2</server_id>\n+        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>\n+        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>\n+        <four_letter_word_white_list>*</four_letter_word_white_list>\n+\n+        <coordination_settings>\n+            <operation_timeout_ms>5000</operation_timeout_ms>\n+            <session_timeout_ms>10000</session_timeout_ms>\n+            <min_session_timeout_ms>5000</min_session_timeout_ms>\n+            <snapshot_distance>75</snapshot_distance>\n+            <raft_logs_level>trace</raft_logs_level>\n+        </coordination_settings>\n+\n+        <raft_configuration>\n+            <server>\n+                <id>1</id>\n+                <hostname>node1</hostname>\n+                <port>9234</port>\n+            </server>\n+            <server>\n+                <id>2</id>\n+                <hostname>node2</hostname>\n+                <port>9234</port>\n+                <start_as_follower>true</start_as_follower>\n+            </server>\n+            <server>\n+                <id>3</id>\n+                <hostname>node3</hostname>\n+                <port>9234</port>\n+                <start_as_follower>true</start_as_follower>\n+            </server>\n+        </raft_configuration>\n+    </keeper_server>\n+</clickhouse>\ndiff --git a/tests/integration/test_keeper_s3_snapshot/configs/keeper_config3.xml b/tests/integration/test_keeper_s3_snapshot/configs/keeper_config3.xml\nnew file mode 100644\nindex 000000000000..948d95277188\n--- /dev/null\n+++ b/tests/integration/test_keeper_s3_snapshot/configs/keeper_config3.xml\n@@ -0,0 +1,42 @@\n+<clickhouse>\n+    <keeper_server>\n+        <s3_snapshot>\n+            <endpoint>http://minio1:9001/snapshots/</endpoint>\n+            <access_key_id>minio</access_key_id>\n+            <secret_access_key>minio123</secret_access_key>\n+        </s3_snapshot>\n+        <tcp_port>9181</tcp_port>\n+        <server_id>3</server_id>\n+        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>\n+        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>\n+        <four_letter_word_white_list>*</four_letter_word_white_list>\n+\n+        <coordination_settings>\n+            <operation_timeout_ms>5000</operation_timeout_ms>\n+            <session_timeout_ms>10000</session_timeout_ms>\n+            <min_session_timeout_ms>5000</min_session_timeout_ms>\n+            <snapshot_distance>75</snapshot_distance>\n+            <raft_logs_level>trace</raft_logs_level>\n+        </coordination_settings>\n+\n+        <raft_configuration>\n+            <server>\n+                <id>1</id>\n+                <hostname>node1</hostname>\n+                <port>9234</port>\n+            </server>\n+            <server>\n+                <id>2</id>\n+                <hostname>node2</hostname>\n+                <port>9234</port>\n+                <start_as_follower>true</start_as_follower>\n+            </server>\n+            <server>\n+                <id>3</id>\n+                <hostname>node3</hostname>\n+                <port>9234</port>\n+                <start_as_follower>true</start_as_follower>\n+            </server>\n+        </raft_configuration>\n+    </keeper_server>\n+</clickhouse>\ndiff --git a/tests/integration/test_keeper_s3_snapshot/test.py b/tests/integration/test_keeper_s3_snapshot/test.py\nnew file mode 100644\nindex 000000000000..3e19bc4822c9\n--- /dev/null\n+++ b/tests/integration/test_keeper_s3_snapshot/test.py\n@@ -0,0 +1,120 @@\n+import pytest\n+from helpers.cluster import ClickHouseCluster\n+from time import sleep\n+\n+from kazoo.client import KazooClient\n+\n+# from kazoo.protocol.serialization import Connect, read_buffer, write_buffer\n+\n+cluster = ClickHouseCluster(__file__)\n+node1 = cluster.add_instance(\n+    \"node1\",\n+    main_configs=[\"configs/keeper_config1.xml\"],\n+    stay_alive=True,\n+    with_minio=True,\n+)\n+node2 = cluster.add_instance(\n+    \"node2\",\n+    main_configs=[\"configs/keeper_config2.xml\"],\n+    stay_alive=True,\n+    with_minio=True,\n+)\n+node3 = cluster.add_instance(\n+    \"node3\",\n+    main_configs=[\"configs/keeper_config3.xml\"],\n+    stay_alive=True,\n+    with_minio=True,\n+)\n+\n+\n+@pytest.fixture(scope=\"module\")\n+def started_cluster():\n+    try:\n+        cluster.start()\n+\n+        cluster.minio_client.make_bucket(\"snapshots\")\n+\n+        yield cluster\n+\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def get_fake_zk(nodename, timeout=30.0):\n+    _fake_zk_instance = KazooClient(\n+        hosts=cluster.get_instance_ip(nodename) + \":9181\", timeout=timeout\n+    )\n+    _fake_zk_instance.start()\n+    return _fake_zk_instance\n+\n+\n+def destroy_zk_client(zk):\n+    try:\n+        if zk:\n+            zk.stop()\n+            zk.close()\n+    except:\n+        pass\n+\n+\n+def wait_node(node):\n+    for _ in range(100):\n+        zk = None\n+        try:\n+            zk = get_fake_zk(node.name, timeout=30.0)\n+            zk.sync(\"/\")\n+            print(\"node\", node.name, \"ready\")\n+            break\n+        except Exception as ex:\n+            sleep(0.2)\n+            print(\"Waiting until\", node.name, \"will be ready, exception\", ex)\n+        finally:\n+            destroy_zk_client(zk)\n+    else:\n+        raise Exception(\"Can't wait node\", node.name, \"to become ready\")\n+\n+\n+def test_s3_upload(started_cluster):\n+    node1_zk = get_fake_zk(node1.name)\n+\n+    # we defined in configs snapshot_distance as 50\n+    # so after 50 requests we should generate a snapshot\n+    for _ in range(210):\n+        node1_zk.create(\"/test\", sequence=True)\n+\n+    def get_saved_snapshots():\n+        return [\n+            obj.object_name\n+            for obj in list(cluster.minio_client.list_objects(\"snapshots\"))\n+        ]\n+\n+    saved_snapshots = get_saved_snapshots()\n+    assert set(saved_snapshots) == set(\n+        [\n+            \"snapshot_50.bin.zstd\",\n+            \"snapshot_100.bin.zstd\",\n+            \"snapshot_150.bin.zstd\",\n+            \"snapshot_200.bin.zstd\",\n+        ]\n+    )\n+\n+    destroy_zk_client(node1_zk)\n+    node1.stop_clickhouse(kill=True)\n+\n+    # wait for new leader to be picked and that it continues\n+    # uploading snapshots\n+    wait_node(node2)\n+    node2_zk = get_fake_zk(node2.name)\n+    for _ in range(200):\n+        node2_zk.create(\"/test\", sequence=True)\n+\n+    saved_snapshots = get_saved_snapshots()\n+\n+    assert len(saved_snapshots) > 4\n+\n+    success_upload_message = \"Successfully uploaded\"\n+    assert node2.contains_in_log(success_upload_message) or node3.contains_in_log(\n+        success_upload_message\n+    )\n+\n+    destroy_zk_client(node2_zk)\n",
  "problem_statement": "ClickHouse Keeper - add an option to write snapshots to s3.\n**Use case**\r\n\r\nAn option to asynchronously send snapshots to s3.\r\nIt is useful as a backup (to allow restoration to some recent state if all the servers were lost)\r\nand it does not replace the usual snapshots.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA configuration option. Only one of the Keepers will write the snapshot.\r\nThe most obvious variant - the leader will do it.\r\nAnother variant - it can be simply configured on only one of the nodes.\r\n\r\nThe snapshot is written in a separate background thread and is written as-is: exactly the same file.\r\n\r\nIn case of errors during write, it can be repeated up to the configured amount of times with exponential backoff - then it will be giving up with an error message, but it will not affect overall operation.\n",
  "hints_text": "",
  "created_at": "2022-09-15T09:15:31Z"
}