{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 9048,
  "instance_id": "ClickHouse__ClickHouse-9048",
  "issue_numbers": [
    "9019"
  ],
  "base_commit": "3e8179108b89e7c04642b5a82dcf2fd327439cea",
  "patch": "diff --git a/dbms/src/Interpreters/MutationsInterpreter.cpp b/dbms/src/Interpreters/MutationsInterpreter.cpp\nindex 8ff10e92deeb..812a7b9a400e 100644\n--- a/dbms/src/Interpreters/MutationsInterpreter.cpp\n+++ b/dbms/src/Interpreters/MutationsInterpreter.cpp\n@@ -18,6 +18,7 @@\n #include <Parsers/ASTExpressionList.h>\n #include <Parsers/ASTSelectQuery.h>\n #include <Parsers/formatAST.h>\n+#include <Parsers/ASTOrderByElement.h>\n #include <IO/WriteHelpers.h>\n \n \n@@ -525,6 +526,39 @@ ASTPtr MutationsInterpreter::prepareInterpreterSelectQuery(std::vector<Stage> &\n         }\n         select->setExpression(ASTSelectQuery::Expression::WHERE, std::move(where_expression));\n     }\n+    auto metadata = storage->getInMemoryMetadata();\n+    /// We have to execute select in order of primary key\n+    /// because we don't sort results additionaly and don't have\n+    /// any guarantees on data order without ORDER BY. It's almost free, because we\n+    /// have optimization for data read in primary key order.\n+    if (metadata.order_by_ast)\n+    {\n+        ASTPtr dummy;\n+\n+        ASTPtr key_expr;\n+        if (metadata.primary_key_ast)\n+            key_expr = metadata.primary_key_ast;\n+        else\n+            key_expr = metadata.order_by_ast;\n+\n+        bool empty = false;\n+        /// In all other cases we cannot have empty key\n+        if (auto key_function = key_expr->as<ASTFunction>())\n+            empty = key_function->arguments->children.size() == 0;\n+\n+        /// Not explicitely spicified empty key\n+        if (!empty)\n+        {\n+            auto order_by_expr = std::make_shared<ASTOrderByElement>(1, 1, false, dummy, false, dummy, dummy, dummy);\n+\n+\n+            order_by_expr->children.push_back(key_expr);\n+            auto res = std::make_shared<ASTExpressionList>();\n+            res->children.push_back(order_by_expr);\n+\n+            select->setExpression(ASTSelectQuery::Expression::ORDER_BY, std::move(res));\n+        }\n+    }\n \n     return select;\n }\ndiff --git a/dbms/src/Storages/MergeTree/StorageFromMergeTreeDataPart.h b/dbms/src/Storages/MergeTree/StorageFromMergeTreeDataPart.h\nindex 1326c61b1f64..d9f89219c161 100644\n--- a/dbms/src/Storages/MergeTree/StorageFromMergeTreeDataPart.h\n+++ b/dbms/src/Storages/MergeTree/StorageFromMergeTreeDataPart.h\n@@ -47,6 +47,12 @@ class StorageFromMergeTreeDataPart : public ext::shared_ptr_helper<StorageFromMe\n         return part->storage.mayBenefitFromIndexForIn(left_in_operand, query_context);\n     }\n \n+    StorageInMemoryMetadata getInMemoryMetadata() const override\n+    {\n+        return part->storage.getInMemoryMetadata();\n+    }\n+\n+\n protected:\n     StorageFromMergeTreeDataPart(const MergeTreeData::DataPartPtr & part_)\n         : IStorage(getIDFromPart(part_), part_->storage.getVirtuals())\ndiff --git a/dbms/src/Storages/StorageReplicatedMergeTree.cpp b/dbms/src/Storages/StorageReplicatedMergeTree.cpp\nindex db113624f68b..e3a38f54219b 100644\n--- a/dbms/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/dbms/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -3222,6 +3222,7 @@ void StorageReplicatedMergeTree::alter(\n     /// metadata alter.\n     if (params.isSettingsAlter())\n     {\n+        lockStructureExclusively(table_lock_holder, query_context.getCurrentQueryId());\n         /// We don't replicate storage_settings_ptr ALTER. It's local operation.\n         /// Also we don't upgrade alter lock to table structure lock.\n         LOG_DEBUG(log, \"ALTER storage_settings_ptr only\");\n@@ -3271,9 +3272,7 @@ void StorageReplicatedMergeTree::alter(\n     std::vector<ChangedNode> changed_nodes;\n \n     {\n-        /// Just to read current structure. Alter will be done in separate thread.\n-        auto table_lock = lockStructureForShare(false, query_context.getCurrentQueryId());\n-\n+        /// We can safely read structure, because we guarded with alter_intention_lock\n         if (is_readonly)\n             throw Exception(\"Can't ALTER readonly table\", ErrorCodes::TABLE_IS_READ_ONLY);\n \n@@ -3305,10 +3304,13 @@ void StorageReplicatedMergeTree::alter(\n \n         /// Perform settings update locally\n \n-        auto old_metadata = getInMemoryMetadata();\n-        old_metadata.settings_ast = metadata.settings_ast;\n-        changeSettings(metadata.settings_ast, table_lock_holder);\n-        global_context.getDatabase(table_id.database_name)->alterTable(query_context, table_id.table_name, old_metadata);\n+        {\n+            lockStructureExclusively(table_lock_holder, query_context.getCurrentQueryId());\n+            auto old_metadata = getInMemoryMetadata();\n+            old_metadata.settings_ast = metadata.settings_ast;\n+            changeSettings(metadata.settings_ast, table_lock_holder);\n+            global_context.getDatabase(table_id.database_name)->alterTable(query_context, table_id.table_name, old_metadata);\n+        }\n \n         /// Modify shared metadata nodes in ZooKeeper.\n         Coordination::Requests ops;\n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/01077_mutations_index_consistency.reference b/dbms/tests/queries/0_stateless/01077_mutations_index_consistency.reference\nnew file mode 100644\nindex 000000000000..a685149b8d41\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/01077_mutations_index_consistency.reference\n@@ -0,0 +1,4 @@\n+43200\n+0\n+43200\n+43200\ndiff --git a/dbms/tests/queries/0_stateless/01077_mutations_index_consistency.sh b/dbms/tests/queries/0_stateless/01077_mutations_index_consistency.sh\nnew file mode 100755\nindex 000000000000..cecf0c0fce07\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/01077_mutations_index_consistency.sh\n@@ -0,0 +1,60 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+\n+$CLICKHOUSE_CLIENT --query \"DROP TABLE IF EXISTS movement\"\n+\n+$CLICKHOUSE_CLIENT -n --query \"CREATE TABLE movement (date DateTime('Europe/Moscow')) Engine = MergeTree ORDER BY (toStartOfHour(date));\"\n+\n+$CLICKHOUSE_CLIENT --query \"insert into movement select toDateTime('2020-01-22 00:00:00') + number%(23*3600) from numbers(1000000);\"\n+\n+$CLICKHOUSE_CLIENT --query \"OPTIMIZE TABLE movement FINAL\"\n+\n+$CLICKHOUSE_CLIENT -n --query \"\n+SELECT\n+    count(),\n+    toStartOfHour(date) AS Hour\n+FROM movement\n+WHERE (date >= toDateTime('2020-01-22T10:00:00')) AND (date <= toDateTime('2020-01-22T23:00:00'))\n+GROUP BY Hour\n+ORDER BY Hour DESC\n+\" | grep \"16:00:00\" | cut -f1\n+\n+\n+$CLICKHOUSE_CLIENT --query \"alter table movement delete where date >= toDateTime('2020-01-22T16:00:00')  and date < toDateTime('2020-01-22T17:00:00') SETTINGS mutations_sync = 2\"\n+\n+$CLICKHOUSE_CLIENT -n --query \"\n+SELECT\n+    count(),\n+    toStartOfHour(date) AS Hour\n+FROM movement\n+WHERE (date >= toDateTime('2020-01-22T10:00:00')) AND (date <= toDateTime('2020-01-22T23:00:00'))\n+GROUP BY Hour\n+ORDER BY Hour DESC\n+\" | grep \"16:00:00\" | wc -l\n+\n+\n+$CLICKHOUSE_CLIENT -n --query \"\n+SELECT\n+    count(),\n+    toStartOfHour(date) AS Hour\n+FROM movement\n+WHERE (date >= toDateTime('2020-01-22T10:00:00')) AND (date <= toDateTime('2020-01-22T23:00:00'))\n+GROUP BY Hour\n+ORDER BY Hour DESC\n+\" | grep \"22:00:00\" | cut -f1\n+\n+\n+$CLICKHOUSE_CLIENT -n --query \"\n+SELECT\n+    count(),\n+    toStartOfHour(date) AS Hour\n+FROM movement\n+GROUP BY Hour\n+ORDER BY Hour DESC\n+\" | grep \"22:00:00\" | cut -f1\n+\n+\n+$CLICKHOUSE_CLIENT --query \"DROP TABLE IF EXISTS movement\"\n",
  "problem_statement": "Broken indicies and inconsistent queries results\nHi! \r\n\r\nAfter updating Clickhouse from 19.13.1.11 version to 20.1.3.7 and when we run queries like this:\r\n\r\n```\r\nselect courseId, uniqExact(learnerId) from entities_attempts_distributed group by courseId order by courseId\r\n```\r\nand \r\n```\r\nselect uniqExact(learnerId) from entities_attempts_distributed where courseId = 41\r\n``` \r\nwe have different results. For example first query returns 21500 unique values for courseId = 41 and second query returns 3500 unique values for courseId = 41.\r\n\r\nIf we change second query to \r\n```\r\nselect uniqExact(learnerId) from entities_attempts_distributed where identity(courseId) = 41\r\n``` \r\nwe have same result with first query. So, it's possible that in some moment table indicies was corrupted.\r\n\r\nWe have ReplicatedMergeTree table with structure:\r\n\r\n```\r\nCREATE TABLE cursometr.entities_attempts_replicated (`learnerId` UInt64, `courseId` UInt64, `actorId` UInt64, `entityIri` String, `startedAt` DateTime, `attemptNumber` UInt16, `attemptLearningNumber` UInt16, `attemptRepeatingNumber` UInt16, `attemptBeforePassedNumber` UInt16, `attemptAfterPassedNumber` UInt16, `endedAt` DateTime, `passed` UInt8, `success` UInt8, `learning` UInt8, `repeating` UInt8, `beforePassed` UInt8, `afterPassed` UInt8, `result` Float32, `durationTotal` UInt32, `durationLearning` UInt32, `durationRepeating` UInt32, `durationBeforePassed` UInt32, `durationAfterPassed` UInt32, `reject` UInt8, `version` DateTime, `hash` UInt64, `queryId` UInt64) ENGINE = ReplicatedMergeTree('/clickhouse/tables/cursometr/{shard}/entities_attempts', '{replica}') PARTITION BY toStartOfDay(version) ORDER BY (courseId, learnerId, hash, entityIri) SETTINGS index_granularity = 8192\r\n```\r\n\r\nInserts in this table performs via temporary table with same structure. When data successfully inserted in temporary table we move partitions to main table `entities_attempts_replicated` with query \r\n```\r\nalter table entities_attempts_replicated attach partition $partition from $temp_table_name\r\n```\r\nWhen partitions successfully moved to main table we drop temporary table.\r\n\r\nSometimes we run queries to delete old data by column `hash`. To perform consistent mutation we collect list of actual hashes and insert them into memory table. Query looks like \r\n```\r\nalter table entities_attempts_replicated delete where hash not in (select hash from $temporary_hashes_table)\r\n```\r\n\r\nSo, we don't know at which moment data corrupts, but we can try to make step-by-step reproducing manual if needed.\n",
  "hints_text": "related: https://github.com/ClickHouse/ClickHouse/issues/8982\r\n\n>  but we can try to make step-by-step reproducing manual if needed\r\n\r\nIt will really be cool if you will be able to create a [complete & reproducible example](https://stackoverflow.com/help/minimal-reproducible-example).\n@aopetrov86 I understood nothing and your outputs proofed nothing. I recommend you to open own issue with table DDL and some examples",
  "created_at": "2020-02-07T13:56:27Z"
}