{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 37198,
  "instance_id": "ClickHouse__ClickHouse-37198",
  "issue_numbers": [
    "35570",
    "33867",
    "37318"
  ],
  "base_commit": "18c3ae5b377068fbafd4c0d2185ffd776c9c059e",
  "patch": "diff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex 08a3df0a3e37..6f01ecdcbcd6 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -538,11 +538,12 @@ static constexpr UInt64 operator\"\"_GiB(unsigned long long value)\n     M(Bool, engine_file_allow_create_multiple_files, false, \"Enables or disables creating a new file on each insert in file engine tables if format has suffix.\", 0) \\\n     M(Bool, allow_experimental_database_replicated, false, \"Allow to create databases with Replicated engine\", 0) \\\n     M(UInt64, database_replicated_initial_query_timeout_sec, 300, \"How long initial DDL query should wait for Replicated database to precess previous DDL queue entries\", 0) \\\n+    M(Bool, database_replicated_enforce_synchronous_settings, false, \"Enforces synchronous waiting for some queries (see also database_atomic_wait_for_drop_and_detach_synchronously, mutation_sync, replication_alter_partitions_sync). Not recommended to enable these settings.\", 0) \\\n     M(UInt64, max_distributed_depth, 5, \"Maximum distributed query depth\", 0) \\\n     M(Bool, database_replicated_always_detach_permanently, false, \"Execute DETACH TABLE as DETACH TABLE PERMANENTLY if database engine is Replicated\", 0) \\\n     M(Bool, database_replicated_allow_only_replicated_engine, false, \"Allow to create only Replicated tables in database with engine Replicated\", 0) \\\n     M(DistributedDDLOutputMode, distributed_ddl_output_mode, DistributedDDLOutputMode::THROW, \"Format of distributed DDL query result\", 0) \\\n-    M(UInt64, distributed_ddl_entry_format_version, 2, \"Version of DDL entry to write into ZooKeeper\", 0) \\\n+    M(UInt64, distributed_ddl_entry_format_version, 3, \"Compatibility version of distributed DDL (ON CLUSTER) queries\", 0) \\\n     \\\n     M(UInt64, external_storage_max_read_rows, 0, \"Limit maximum number of rows when table with external engine should flush history data. Now supported only for MySQL table engine, database engine, dictionary and MaterializedMySQL. If equal to 0, this setting is disabled\", 0) \\\n     M(UInt64, external_storage_max_read_bytes, 0, \"Limit maximum number of bytes when table with external engine should flush history data. Now supported only for MySQL table engine, database engine, dictionary and MaterializedMySQL. If equal to 0, this setting is disabled\", 0)  \\\ndiff --git a/src/Databases/DatabaseAtomic.cpp b/src/Databases/DatabaseAtomic.cpp\nindex 1d7ff40135ca..759f4b9276cc 100644\n--- a/src/Databases/DatabaseAtomic.cpp\n+++ b/src/Databases/DatabaseAtomic.cpp\n@@ -118,13 +118,19 @@ void DatabaseAtomic::dropTable(ContextPtr local_context, const String & table_na\n     if (table)\n         table->dropInnerTableIfAny(sync, local_context);\n     else\n-        throw Exception(ErrorCodes::UNKNOWN_TABLE, \"Table {}.{} doesn't exist\",\n-                        backQuote(getDatabaseName()), backQuote(table_name));\n+        throw Exception(ErrorCodes::UNKNOWN_TABLE, \"Table {}.{} doesn't exist\", backQuote(getDatabaseName()), backQuote(table_name));\n \n+    dropTableImpl(local_context, table_name, sync);\n+}\n+\n+void DatabaseAtomic::dropTableImpl(ContextPtr local_context, const String & table_name, bool sync)\n+{\n     String table_metadata_path = getObjectMetadataPath(table_name);\n     String table_metadata_path_drop;\n+    StoragePtr table;\n     {\n         std::lock_guard lock(mutex);\n+        table = getTableUnlocked(table_name);\n         table_metadata_path_drop = DatabaseCatalog::instance().getPathForDroppedMetadata(table->getStorageID());\n         auto txn = local_context->getZooKeeperMetadataTransaction();\n         if (txn && !local_context->isInternalSubquery())\n@@ -417,9 +423,9 @@ UUID DatabaseAtomic::tryGetTableUUID(const String & table_name) const\n     return UUIDHelpers::Nil;\n }\n \n-void DatabaseAtomic::beforeLoadingMetadata(ContextMutablePtr /*context*/, bool force_restore, bool /*force_attach*/)\n+void DatabaseAtomic::beforeLoadingMetadata(ContextMutablePtr /*context*/, LoadingStrictnessLevel mode)\n {\n-    if (!force_restore)\n+    if (mode < LoadingStrictnessLevel::FORCE_RESTORE)\n         return;\n \n     /// Recreate symlinks to table data dirs in case of force restore, because some of them may be broken\n@@ -436,17 +442,17 @@ void DatabaseAtomic::beforeLoadingMetadata(ContextMutablePtr /*context*/, bool f\n }\n \n void DatabaseAtomic::loadStoredObjects(\n-    ContextMutablePtr local_context, bool force_restore, bool force_attach, bool skip_startup_tables)\n+    ContextMutablePtr local_context, LoadingStrictnessLevel mode, bool skip_startup_tables)\n {\n-    beforeLoadingMetadata(local_context, force_restore, force_attach);\n-    DatabaseOrdinary::loadStoredObjects(local_context, force_restore, force_attach, skip_startup_tables);\n+    beforeLoadingMetadata(local_context, mode);\n+    DatabaseOrdinary::loadStoredObjects(local_context, mode, skip_startup_tables);\n }\n \n-void DatabaseAtomic::startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach)\n+void DatabaseAtomic::startupTables(ThreadPool & thread_pool, LoadingStrictnessLevel mode)\n {\n-    DatabaseOrdinary::startupTables(thread_pool, force_restore, force_attach);\n+    DatabaseOrdinary::startupTables(thread_pool, mode);\n \n-    if (!force_restore)\n+    if (mode < LoadingStrictnessLevel::FORCE_RESTORE)\n         return;\n \n     NameToPathMap table_names;\ndiff --git a/src/Databases/DatabaseAtomic.h b/src/Databases/DatabaseAtomic.h\nindex 6cb2226a7f8a..cb275812098b 100644\n--- a/src/Databases/DatabaseAtomic.h\n+++ b/src/Databases/DatabaseAtomic.h\n@@ -36,6 +36,7 @@ class DatabaseAtomic : public DatabaseOrdinary\n             bool dictionary) override;\n \n     void dropTable(ContextPtr context, const String & table_name, bool sync) override;\n+    void dropTableImpl(ContextPtr context, const String & table_name, bool sync);\n \n     void attachTable(ContextPtr context, const String & name, const StoragePtr & table, const String & relative_table_path) override;\n     StoragePtr detachTable(ContextPtr context, const String & name) override;\n@@ -47,11 +48,11 @@ class DatabaseAtomic : public DatabaseOrdinary\n \n     DatabaseTablesIteratorPtr getTablesIterator(ContextPtr context, const FilterByNameFunction & filter_by_table_name) const override;\n \n-    void loadStoredObjects(ContextMutablePtr context, bool force_restore, bool force_attach, bool skip_startup_tables) override;\n+    void loadStoredObjects(ContextMutablePtr context, LoadingStrictnessLevel mode, bool skip_startup_tables) override;\n \n-    void beforeLoadingMetadata(ContextMutablePtr context, bool force_restore, bool force_attach) override;\n+    void beforeLoadingMetadata(ContextMutablePtr context, LoadingStrictnessLevel mode) override;\n \n-    void startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach) override;\n+    void startupTables(ThreadPool & thread_pool, LoadingStrictnessLevel mode) override;\n \n     /// Atomic database cannot be detached if there is detached table which still in use\n     void assertCanBeDetached(bool cleanup) override;\ndiff --git a/src/Databases/DatabaseLazy.cpp b/src/Databases/DatabaseLazy.cpp\nindex 3a1b30098785..9aa65602835a 100644\n--- a/src/Databases/DatabaseLazy.cpp\n+++ b/src/Databases/DatabaseLazy.cpp\n@@ -38,7 +38,7 @@ DatabaseLazy::DatabaseLazy(const String & name_, const String & metadata_path_,\n \n \n void DatabaseLazy::loadStoredObjects(\n-    ContextMutablePtr local_context, bool /* force_restore */, bool /*force_attach*/, bool /* skip_startup_tables */)\n+    ContextMutablePtr local_context, LoadingStrictnessLevel /*mode*/, bool /* skip_startup_tables */)\n {\n     iterateMetadataFiles(local_context, [this, &local_context](const String & file_name)\n     {\ndiff --git a/src/Databases/DatabaseLazy.h b/src/Databases/DatabaseLazy.h\nindex d3c3ed2843b0..b01038073ef2 100644\n--- a/src/Databases/DatabaseLazy.h\n+++ b/src/Databases/DatabaseLazy.h\n@@ -26,7 +26,7 @@ class DatabaseLazy final : public DatabaseOnDisk\n \n     bool canContainDistributedTables() const override { return false; }\n \n-    void loadStoredObjects(ContextMutablePtr context, bool force_restore, bool force_attach, bool skip_startup_tables) override;\n+    void loadStoredObjects(ContextMutablePtr context, LoadingStrictnessLevel /*mode*/, bool skip_startup_tables) override;\n \n     void createTable(\n         ContextPtr context,\ndiff --git a/src/Databases/DatabaseOnDisk.cpp b/src/Databases/DatabaseOnDisk.cpp\nindex fe229ba6ee96..b5bb6c7c759f 100644\n--- a/src/Databases/DatabaseOnDisk.cpp\n+++ b/src/Databases/DatabaseOnDisk.cpp\n@@ -230,7 +230,7 @@ void DatabaseOnDisk::createTable(\n \n /// If the table was detached permanently we will have a flag file with\n /// .sql.detached extension, is not needed anymore since we attached the table back\n-void DatabaseOnDisk::removeDetachedPermanentlyFlag(ContextPtr, const String & table_name, const String & table_metadata_path, bool) const\n+void DatabaseOnDisk::removeDetachedPermanentlyFlag(ContextPtr, const String & table_name, const String & table_metadata_path, bool)\n {\n     try\n     {\ndiff --git a/src/Databases/DatabaseOnDisk.h b/src/Databases/DatabaseOnDisk.h\nindex 90aba6be1699..0db6a94b86d2 100644\n--- a/src/Databases/DatabaseOnDisk.h\n+++ b/src/Databases/DatabaseOnDisk.h\n@@ -94,7 +94,7 @@ class DatabaseOnDisk : public DatabaseWithOwnTablesBase\n     virtual void commitCreateTable(const ASTCreateQuery & query, const StoragePtr & table,\n                                    const String & table_metadata_tmp_path, const String & table_metadata_path, ContextPtr query_context);\n \n-    virtual void removeDetachedPermanentlyFlag(ContextPtr context, const String & table_name, const String & table_metadata_path, bool attach) const;\n+    virtual void removeDetachedPermanentlyFlag(ContextPtr context, const String & table_name, const String & table_metadata_path, bool attach);\n     virtual void setDetachedTableNotInUseForce(const UUID & /*uuid*/) {}\n \n     const String metadata_path;\ndiff --git a/src/Databases/DatabaseOrdinary.cpp b/src/Databases/DatabaseOrdinary.cpp\nindex 18b702223829..c6b089ea2c63 100644\n--- a/src/Databases/DatabaseOrdinary.cpp\n+++ b/src/Databases/DatabaseOrdinary.cpp\n@@ -81,7 +81,7 @@ DatabaseOrdinary::DatabaseOrdinary(\n }\n \n void DatabaseOrdinary::loadStoredObjects(\n-    ContextMutablePtr local_context, bool force_restore, bool force_attach, bool skip_startup_tables)\n+    ContextMutablePtr local_context, LoadingStrictnessLevel mode, bool skip_startup_tables)\n {\n     /** Tables load faster if they are loaded in sorted (by name) order.\n       * Otherwise (for the ext4 filesystem), `DirectoryIterator` iterates through them in some order,\n@@ -89,6 +89,7 @@ void DatabaseOrdinary::loadStoredObjects(\n       */\n \n     ParsedTablesMetadata metadata;\n+    bool force_attach = LoadingStrictnessLevel::FORCE_ATTACH <= mode;\n     loadTablesMetadata(local_context, metadata, force_attach);\n \n     size_t total_tables = metadata.parsed_tables.size() - metadata.total_dictionaries;\n@@ -118,7 +119,7 @@ void DatabaseOrdinary::loadStoredObjects(\n         {\n             pool.scheduleOrThrowOnError([&]()\n             {\n-                loadTableFromMetadata(local_context, path, name, ast, force_restore);\n+                loadTableFromMetadata(local_context, path, name, ast, mode);\n \n                 /// Messages, so that it's not boring to wait for the server to load for a long time.\n                 logAboutProgress(log, ++dictionaries_processed, metadata.total_dictionaries, watch);\n@@ -140,7 +141,7 @@ void DatabaseOrdinary::loadStoredObjects(\n         {\n             pool.scheduleOrThrowOnError([&]()\n             {\n-                loadTableFromMetadata(local_context, path, name, ast, force_restore);\n+                loadTableFromMetadata(local_context, path, name, ast, mode);\n \n                 /// Messages, so that it's not boring to wait for the server to load for a long time.\n                 logAboutProgress(log, ++tables_processed, total_tables, watch);\n@@ -153,7 +154,7 @@ void DatabaseOrdinary::loadStoredObjects(\n     if (!skip_startup_tables)\n     {\n         /// After all tables was basically initialized, startup them.\n-        startupTables(pool, force_restore, force_attach);\n+        startupTables(pool, mode);\n     }\n }\n \n@@ -238,7 +239,8 @@ void DatabaseOrdinary::loadTablesMetadata(ContextPtr local_context, ParsedTables\n              TSA_SUPPRESS_WARNING_FOR_READ(database_name), tables_in_database, dictionaries_in_database);\n }\n \n-void DatabaseOrdinary::loadTableFromMetadata(ContextMutablePtr local_context, const String & file_path, const QualifiedTableName & name, const ASTPtr & ast, bool force_restore)\n+void DatabaseOrdinary::loadTableFromMetadata(ContextMutablePtr local_context, const String & file_path, const QualifiedTableName & name, const ASTPtr & ast,\n+    LoadingStrictnessLevel mode)\n {\n     assert(name.database == TSA_SUPPRESS_WARNING_FOR_READ(database_name));\n     const auto & create_query = ast->as<const ASTCreateQuery &>();\n@@ -248,11 +250,10 @@ void DatabaseOrdinary::loadTableFromMetadata(ContextMutablePtr local_context, co\n         create_query,\n         *this,\n         name.database,\n-        file_path,\n-        force_restore);\n+        file_path, LoadingStrictnessLevel::FORCE_RESTORE <= mode);\n }\n \n-void DatabaseOrdinary::startupTables(ThreadPool & thread_pool, bool /*force_restore*/, bool /*force_attach*/)\n+void DatabaseOrdinary::startupTables(ThreadPool & thread_pool, LoadingStrictnessLevel /*mode*/)\n {\n     LOG_INFO(log, \"Starting up tables.\");\n \ndiff --git a/src/Databases/DatabaseOrdinary.h b/src/Databases/DatabaseOrdinary.h\nindex 6e524ae18b0c..386d6613af34 100644\n--- a/src/Databases/DatabaseOrdinary.h\n+++ b/src/Databases/DatabaseOrdinary.h\n@@ -21,15 +21,16 @@ class DatabaseOrdinary : public DatabaseOnDisk\n \n     String getEngineName() const override { return \"Ordinary\"; }\n \n-    void loadStoredObjects(ContextMutablePtr context, bool force_restore, bool force_attach, bool skip_startup_tables) override;\n+    void loadStoredObjects(ContextMutablePtr context, LoadingStrictnessLevel mode, bool skip_startup_tables) override;\n \n     bool supportsLoadingInTopologicalOrder() const override { return true; }\n \n     void loadTablesMetadata(ContextPtr context, ParsedTablesMetadata & metadata, bool is_startup) override;\n \n-    void loadTableFromMetadata(ContextMutablePtr local_context, const String & file_path, const QualifiedTableName & name, const ASTPtr & ast, bool force_restore) override;\n+    void loadTableFromMetadata(ContextMutablePtr local_context, const String & file_path, const QualifiedTableName & name, const ASTPtr & ast,\n+        LoadingStrictnessLevel mode) override;\n \n-    void startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach) override;\n+    void startupTables(ThreadPool & thread_pool, LoadingStrictnessLevel mode) override;\n \n     void alterTable(\n         ContextPtr context,\ndiff --git a/src/Databases/DatabaseReplicated.cpp b/src/Databases/DatabaseReplicated.cpp\nindex a7ad632efff6..21e7eb05d34c 100644\n--- a/src/Databases/DatabaseReplicated.cpp\n+++ b/src/Databases/DatabaseReplicated.cpp\n@@ -48,10 +48,12 @@ namespace ErrorCodes\n     extern const int CANNOT_RESTORE_TABLE;\n }\n \n+static constexpr const char * REPLICATED_DATABASE_MARK = \"DatabaseReplicated\";\n static constexpr const char * DROPPED_MARK = \"DROPPED\";\n static constexpr const char * BROKEN_TABLES_SUFFIX = \"_broken_tables\";\n static constexpr const char * BROKEN_REPLICATED_TABLES_SUFFIX = \"_broken_replicated_tables\";\n \n+static constexpr size_t METADATA_FILE_BUFFER_SIZE = 32768;\n \n zkutil::ZooKeeperPtr DatabaseReplicated::getZooKeeper() const\n {\n@@ -63,6 +65,13 @@ static inline String getHostID(ContextPtr global_context, const UUID & db_uuid)\n     return Cluster::Address::toString(getFQDNOrHostName(), global_context->getTCPPort()) + ':' + toString(db_uuid);\n }\n \n+static inline UInt64 getMetadataHash(const String & table_name, const String & metadata)\n+{\n+    SipHash hash;\n+    hash.update(table_name);\n+    hash.update(metadata);\n+    return hash.get64();\n+}\n \n DatabaseReplicated::~DatabaseReplicated() = default;\n \n@@ -80,6 +89,7 @@ DatabaseReplicated::DatabaseReplicated(\n     , shard_name(shard_name_)\n     , replica_name(replica_name_)\n     , db_settings(std::move(db_settings_))\n+    , tables_metadata_digest(0)\n {\n     if (zookeeper_path.empty() || shard_name.empty() || replica_name.empty())\n         throw Exception(\"ZooKeeper path, shard and replica names must be non-empty\", ErrorCodes::BAD_ARGUMENTS);\n@@ -232,7 +242,7 @@ void DatabaseReplicated::fillClusterAuthInfo(String collection_name, const Poco:\n     cluster_auth_info.cluster_secure_connection = config_ref.getBool(config_prefix + \".cluster_secure_connection\", false);\n }\n \n-void DatabaseReplicated::tryConnectToZooKeeperAndInitDatabase(bool force_attach)\n+void DatabaseReplicated::tryConnectToZooKeeperAndInitDatabase(LoadingStrictnessLevel mode)\n {\n     try\n     {\n@@ -250,27 +260,48 @@ void DatabaseReplicated::tryConnectToZooKeeperAndInitDatabase(bool force_attach)\n         }\n \n         replica_path = fs::path(zookeeper_path) / \"replicas\" / getFullReplicaName();\n+        bool is_create_query = mode == LoadingStrictnessLevel::CREATE;\n \n         String replica_host_id;\n         if (current_zookeeper->tryGet(replica_path, replica_host_id))\n         {\n+            if (replica_host_id == DROPPED_MARK && !is_create_query)\n+            {\n+                LOG_WARNING(log, \"Database {} exists locally, but marked dropped in ZooKeeper ({}). \"\n+                                 \"Will not try to start it up\", getDatabaseName(), replica_path);\n+                is_probably_dropped = true;\n+                return;\n+            }\n+\n             String host_id = getHostID(getContext(), db_uuid);\n-            if (replica_host_id != host_id)\n-                throw Exception(ErrorCodes::REPLICA_IS_ALREADY_EXIST,\n-                                \"Replica {} of shard {} of replicated database at {} already exists. Replica host ID: '{}', current host ID: '{}'\",\n-                                replica_name, shard_name, zookeeper_path, replica_host_id, host_id);\n+            if (is_create_query || replica_host_id != host_id)\n+            {\n+                throw Exception(\n+                    ErrorCodes::REPLICA_IS_ALREADY_EXIST,\n+                    \"Replica {} of shard {} of replicated database at {} already exists. Replica host ID: '{}', current host ID: '{}'\",\n+                    replica_name, shard_name, zookeeper_path, replica_host_id, host_id);\n+            }\n         }\n-        else\n+        else if (is_create_query)\n         {\n-            /// Throws if replica with the same name already exists\n+            /// Create new replica. Throws if replica with the same name already exists\n             createReplicaNodesInZooKeeper(current_zookeeper);\n         }\n+        else\n+        {\n+            /// It's not CREATE query, but replica does not exist. Probably it was dropped.\n+            /// Do not create anything, continue as readonly.\n+            LOG_WARNING(log, \"Database {} exists locally, but its replica does not exist in ZooKeeper ({}). \"\n+                             \"Assuming it was dropped, will not try to start it up\", getDatabaseName(), replica_path);\n+            is_probably_dropped = true;\n+            return;\n+        }\n \n         is_readonly = false;\n     }\n     catch (...)\n     {\n-        if (!force_attach)\n+        if (mode < LoadingStrictnessLevel::FORCE_ATTACH)\n             throw;\n \n         /// It's server startup, ignore error.\n@@ -284,7 +315,7 @@ bool DatabaseReplicated::createDatabaseNodesInZooKeeper(const zkutil::ZooKeeperP\n     current_zookeeper->createAncestors(zookeeper_path);\n \n     Coordination::Requests ops;\n-    ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path, \"\", zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path, REPLICATED_DATABASE_MARK, zkutil::CreateMode::Persistent));\n     ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/log\", \"\", zkutil::CreateMode::Persistent));\n     ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/replicas\", \"\", zkutil::CreateMode::Persistent));\n     ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/counter\", \"\", zkutil::CreateMode::Persistent));\n@@ -306,10 +337,42 @@ bool DatabaseReplicated::createDatabaseNodesInZooKeeper(const zkutil::ZooKeeperP\n \n     /// Other codes are unexpected, will throw\n     zkutil::KeeperMultiException::check(res, ops, responses);\n-    assert(false);\n+    chassert(false);\n     __builtin_unreachable();\n }\n \n+bool DatabaseReplicated::looksLikeReplicatedDatabasePath(const ZooKeeperPtr & current_zookeeper, const String & path)\n+{\n+    Coordination::Stat stat;\n+    String maybe_database_mark;\n+    if (!current_zookeeper->tryGet(path, maybe_database_mark, &stat))\n+        return false;\n+    if (maybe_database_mark.starts_with(REPLICATED_DATABASE_MARK))\n+        return true;\n+    if (maybe_database_mark.empty())\n+        return false;\n+\n+    /// Old versions did not have REPLICATED_DATABASE_MARK. Check specific nodes exist and add mark.\n+    Coordination::Requests ops;\n+    ops.emplace_back(zkutil::makeCheckRequest(path + \"/log\", -1));\n+    ops.emplace_back(zkutil::makeCheckRequest(path + \"/replicas\", -1));\n+    ops.emplace_back(zkutil::makeCheckRequest(path + \"/counter\", -1));\n+    ops.emplace_back(zkutil::makeCheckRequest(path + \"/metadata\", -1));\n+    ops.emplace_back(zkutil::makeCheckRequest(path + \"/max_log_ptr\", -1));\n+    ops.emplace_back(zkutil::makeCheckRequest(path + \"/logs_to_keep\", -1));\n+    ops.emplace_back(zkutil::makeSetRequest(path, REPLICATED_DATABASE_MARK, stat.version));\n+    Coordination::Responses responses;\n+    auto res = current_zookeeper->tryMulti(ops, responses);\n+    if (res == Coordination::Error::ZOK)\n+        return true;\n+\n+    /// Recheck database mark (just in case of concurrent update).\n+    if (!current_zookeeper->tryGet(path, maybe_database_mark, &stat))\n+        return false;\n+\n+    return maybe_database_mark.starts_with(REPLICATED_DATABASE_MARK);\n+}\n+\n void DatabaseReplicated::createEmptyLogEntry(const ZooKeeperPtr & current_zookeeper)\n {\n     /// On replica creation add empty entry to log. Can be used to trigger some actions on other replicas (e.g. update cluster info).\n@@ -319,11 +382,17 @@ void DatabaseReplicated::createEmptyLogEntry(const ZooKeeperPtr & current_zookee\n \n bool DatabaseReplicated::waitForReplicaToProcessAllEntries(UInt64 timeout_ms)\n {\n+    if (!ddl_worker)\n+        return false;\n     return ddl_worker->waitForReplicaToProcessAllEntries(timeout_ms);\n }\n \n void DatabaseReplicated::createReplicaNodesInZooKeeper(const zkutil::ZooKeeperPtr & current_zookeeper)\n {\n+    if (!looksLikeReplicatedDatabasePath(current_zookeeper, zookeeper_path))\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Cannot add new database replica: provided path {} \"\n+                        \"already contains some data and it does not look like Replicated database path.\", zookeeper_path);\n+\n     /// Write host name to replica_path, it will protect from multiple replicas with the same name\n     auto host_id = getHostID(getContext(), db_uuid);\n \n@@ -334,6 +403,7 @@ void DatabaseReplicated::createReplicaNodesInZooKeeper(const zkutil::ZooKeeperPt\n         Coordination::Requests ops;\n         ops.emplace_back(zkutil::makeCreateRequest(replica_path, host_id, zkutil::CreateMode::Persistent));\n         ops.emplace_back(zkutil::makeCreateRequest(replica_path + \"/log_ptr\", \"0\", zkutil::CreateMode::Persistent));\n+        ops.emplace_back(zkutil::makeCreateRequest(replica_path + \"/digest\", \"0\", zkutil::CreateMode::Persistent));\n         /// In addition to creating the replica nodes, we record the max_log_ptr at the instant where\n         /// we declared ourself as an existing replica. We'll need this during recoverLostReplica to\n         /// notify other nodes that issued new queries while this node was recovering.\n@@ -354,25 +424,89 @@ void DatabaseReplicated::createReplicaNodesInZooKeeper(const zkutil::ZooKeeperPt\n     createEmptyLogEntry(current_zookeeper);\n }\n \n-void DatabaseReplicated::beforeLoadingMetadata(ContextMutablePtr /*context*/, bool /*force_restore*/, bool force_attach)\n+void DatabaseReplicated::beforeLoadingMetadata(ContextMutablePtr /*context*/, LoadingStrictnessLevel mode)\n {\n-    tryConnectToZooKeeperAndInitDatabase(force_attach);\n+    tryConnectToZooKeeperAndInitDatabase(mode);\n }\n \n void DatabaseReplicated::loadStoredObjects(\n-    ContextMutablePtr local_context, bool force_restore, bool force_attach, bool skip_startup_tables)\n+    ContextMutablePtr local_context, LoadingStrictnessLevel mode, bool skip_startup_tables)\n {\n-    beforeLoadingMetadata(local_context, force_restore, force_attach);\n-    DatabaseAtomic::loadStoredObjects(local_context, force_restore, force_attach, skip_startup_tables);\n+    beforeLoadingMetadata(local_context, mode);\n+    DatabaseAtomic::loadStoredObjects(local_context, mode, skip_startup_tables);\n }\n \n-void DatabaseReplicated::startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach)\n+UInt64 DatabaseReplicated::getMetadataHash(const String & table_name) const\n {\n-    DatabaseAtomic::startupTables(thread_pool, force_restore, force_attach);\n+    return DB::getMetadataHash(table_name, readMetadataFile(table_name));\n+}\n+\n+void DatabaseReplicated::startupTables(ThreadPool & thread_pool, LoadingStrictnessLevel mode)\n+{\n+    DatabaseAtomic::startupTables(thread_pool, mode);\n+\n+    /// TSA: No concurrent writes are possible during loading\n+    UInt64 digest = 0;\n+    for (const auto & table : TSA_SUPPRESS_WARNING_FOR_READ(tables))\n+        digest += getMetadataHash(table.first);\n+\n+    LOG_DEBUG(log, \"Calculated metadata digest of {} tables: {}\", TSA_SUPPRESS_WARNING_FOR_READ(tables).size(), digest);\n+    chassert(!TSA_SUPPRESS_WARNING_FOR_READ(tables_metadata_digest));\n+    TSA_SUPPRESS_WARNING_FOR_WRITE(tables_metadata_digest) = digest;\n+\n     ddl_worker = std::make_unique<DatabaseReplicatedDDLWorker>(this, getContext());\n+    if (is_probably_dropped)\n+        return;\n     ddl_worker->startup();\n }\n \n+bool DatabaseReplicated::checkDigestValid(const ContextPtr & local_context, bool debug_check /* = true */) const\n+{\n+    if (debug_check)\n+    {\n+        /// Reduce number of debug checks\n+        if (thread_local_rng() % 16)\n+            return true;\n+    }\n+\n+    LOG_TEST(log, \"Current in-memory metadata digest: {}\", tables_metadata_digest);\n+\n+    /// Database is probably being dropped\n+    if (!local_context->getZooKeeperMetadataTransaction() && !ddl_worker->isCurrentlyActive())\n+        return true;\n+\n+    UInt64 local_digest = 0;\n+    {\n+        std::lock_guard lock{mutex};\n+        for (const auto & table : TSA_SUPPRESS_WARNING_FOR_READ(tables))\n+            local_digest += getMetadataHash(table.first);\n+    }\n+\n+    if (local_digest != tables_metadata_digest)\n+    {\n+        LOG_ERROR(log, \"Digest of local metadata ({}) is not equal to in-memory digest ({})\", local_digest, tables_metadata_digest);\n+        return false;\n+    }\n+\n+    /// Do not check digest in Keeper after internal subquery, it's probably not committed yet\n+    if (local_context->isInternalSubquery())\n+        return true;\n+\n+    /// Check does not make sense to check digest in Keeper during recovering\n+    if (is_recovering)\n+        return true;\n+\n+    String zk_digest = getZooKeeper()->get(replica_path + \"/digest\");\n+    String local_digest_str = toString(local_digest);\n+    if (zk_digest != local_digest_str)\n+    {\n+        LOG_ERROR(log, \"Digest of local metadata ({}) is not equal to digest in Keeper ({})\", local_digest_str, zk_digest);\n+        return false;\n+    }\n+\n+    return true;\n+}\n+\n void DatabaseReplicated::checkQueryValid(const ASTPtr & query, ContextPtr query_context) const\n {\n     /// Replicas will set correct name of current database in query context (database name can be different on replicas)\n@@ -512,7 +646,7 @@ static UUID getTableUUIDIfReplicated(const String & metadata, ContextPtr context\n         return UUIDHelpers::Nil;\n     if (!startsWith(create.storage->engine->name, \"Replicated\") || !endsWith(create.storage->engine->name, \"MergeTree\"))\n         return UUIDHelpers::Nil;\n-    assert(create.uuid != UUIDHelpers::Nil);\n+    chassert(create.uuid != UUIDHelpers::Nil);\n     return create.uuid;\n }\n \n@@ -532,9 +666,6 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n     else\n         LOG_WARNING(log, \"Will recover replica with staled log pointer {} from log pointer {}\", our_log_ptr, max_log_ptr);\n \n-    if (new_replica && !empty())\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"It's new replica, but database is not empty\");\n-\n     auto table_name_to_metadata = tryGetConsistentMetadataSnapshot(current_zookeeper, max_log_ptr);\n \n     /// For ReplicatedMergeTree tables we can compare only UUIDs to ensure that it's the same table.\n@@ -578,7 +709,7 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n         auto in_zk = table_name_to_metadata.find(name);\n         if (in_zk == table_name_to_metadata.end() || in_zk->second != readMetadataFile(name))\n         {\n-            /// Local table does not exits in ZooKeeper or has different metadata\n+            /// Local table does not exist in ZooKeeper or has different metadata\n             tables_to_detach.emplace_back(std::move(name));\n         }\n     }\n@@ -640,7 +771,13 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n             assert(db_name < to_database_name);\n             DDLGuardPtr to_table_guard = DatabaseCatalog::instance().getDDLGuard(to_database_name, to_name);\n             auto to_db_ptr = DatabaseCatalog::instance().getDatabase(to_database_name);\n-            DatabaseAtomic::renameTable(make_query_context(), broken_table_name, *to_db_ptr, to_name, false, false);\n+\n+            std::lock_guard lock{metadata_mutex};\n+            UInt64 new_digest = tables_metadata_digest;\n+            new_digest -= getMetadataHash(broken_table_name);\n+            DatabaseAtomic::renameTable(make_query_context(), broken_table_name, *to_db_ptr, to_name, /* exchange */ false, /* dictionary */ false);\n+            tables_metadata_digest = new_digest;\n+            assert(checkDigestValid(getContext()));\n             ++moved_tables;\n         };\n \n@@ -649,9 +786,24 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n             LOG_DEBUG(log, \"Will DROP TABLE {}, because it does not store data on disk and can be safely dropped\", backQuoteIfNeed(table_name));\n             dropped_tables.push_back(tryGetTableUUID(table_name));\n             dropped_dictionaries += table->isDictionary();\n-\n             table->flushAndShutdown();\n-            DatabaseAtomic::dropTable(make_query_context(), table_name, true);\n+\n+            if (table->getName() == \"MaterializedView\" || table->getName() == \"WindowView\")\n+            {\n+                /// We have to drop MV inner table, so MV will not try to do it implicitly breaking some invariants.\n+                /// Also we have to commit metadata transaction, because it's not committed by default for inner tables of MVs.\n+                /// Yep, I hate inner tables of materialized views.\n+                auto mv_drop_inner_table_context = make_query_context();\n+                table->dropInnerTableIfAny(sync, mv_drop_inner_table_context);\n+                mv_drop_inner_table_context->getZooKeeperMetadataTransaction()->commit();\n+            }\n+\n+            std::lock_guard lock{metadata_mutex};\n+            UInt64 new_digest = tables_metadata_digest;\n+            new_digest -= getMetadataHash(table_name);\n+            DatabaseAtomic::dropTableImpl(make_query_context(), table_name, /* sync */ true);\n+            tables_metadata_digest = new_digest;\n+            assert(checkDigestValid(getContext()));\n         }\n         else if (!table->supportsReplication())\n         {\n@@ -677,7 +829,15 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n         /// TODO Maybe we should do it in two steps: rename all tables to temporary names and then rename them to actual names?\n         DDLGuardPtr table_guard = DatabaseCatalog::instance().getDDLGuard(db_name, std::min(from, to));\n         DDLGuardPtr to_table_guard = DatabaseCatalog::instance().getDDLGuard(db_name, std::max(from, to));\n+\n+        std::lock_guard lock{metadata_mutex};\n+        UInt64 new_digest = tables_metadata_digest;\n+        String statement = readMetadataFile(from);\n+        new_digest -= DB::getMetadataHash(from, statement);\n+        new_digest += DB::getMetadataHash(to, statement);\n         DatabaseAtomic::renameTable(make_query_context(), from, *this, to, false, false);\n+        tables_metadata_digest = new_digest;\n+        assert(checkDigestValid(getContext()));\n     }\n \n     for (const auto & id : dropped_tables)\n@@ -712,6 +872,10 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n                 LOG_INFO(log, \"Marked recovered {} as finished\", entry_name);\n         }\n     }\n+\n+    std::lock_guard lock{metadata_mutex};\n+    chassert(checkDigestValid(getContext()));\n+    current_zookeeper->set(replica_path + \"/digest\", toString(tables_metadata_digest));\n }\n \n std::map<String, String> DatabaseReplicated::tryGetConsistentMetadataSnapshot(const ZooKeeperPtr & zookeeper, UInt32 & max_log_ptr)\n@@ -749,8 +913,8 @@ std::map<String, String> DatabaseReplicated::tryGetConsistentMetadataSnapshot(co\n         }\n         else\n         {\n-            assert(max_log_ptr == new_max_log_ptr);\n-            assert(table_names.size() != table_name_to_metadata.size());\n+            chassert(max_log_ptr == new_max_log_ptr);\n+            chassert(table_names.size() != table_name_to_metadata.size());\n             LOG_DEBUG(log, \"Cannot get metadata of some tables due to ZooKeeper error, will retry\");\n         }\n     }\n@@ -801,6 +965,8 @@ void DatabaseReplicated::drop(ContextPtr context_)\n \n void DatabaseReplicated::stopReplication()\n {\n+    if (is_probably_dropped)\n+        return;\n     if (ddl_worker)\n         ddl_worker->shutdown();\n }\n@@ -817,12 +983,29 @@ void DatabaseReplicated::dropTable(ContextPtr local_context, const String & tabl\n {\n     auto txn = local_context->getZooKeeperMetadataTransaction();\n     assert(!ddl_worker->isCurrentlyActive() || txn || startsWith(table_name, \".inner_id.\"));\n-    if (txn && txn->isInitialQuery())\n+    if (txn && txn->isInitialQuery() && !txn->isCreateOrReplaceQuery())\n     {\n         String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(table_name);\n         txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path, -1));\n     }\n-    DatabaseAtomic::dropTable(local_context, table_name, sync);\n+\n+    auto table = tryGetTable(table_name, getContext());\n+    if (table->getName() == \"MaterializedView\" || table->getName() == \"WindowView\")\n+    {\n+        /// Avoid recursive locking of metadata_mutex\n+        table->dropInnerTableIfAny(sync, local_context);\n+    }\n+\n+    std::lock_guard lock{metadata_mutex};\n+    UInt64 new_digest = tables_metadata_digest;\n+    new_digest -= getMetadataHash(table_name);\n+    if (txn && !txn->isCreateOrReplaceQuery())\n+        txn->addOp(zkutil::makeSetRequest(replica_path + \"/digest\", toString(new_digest), -1));\n+\n+    DatabaseAtomic::dropTableImpl(local_context, table_name, sync);\n+    tables_metadata_digest = new_digest;\n+\n+    assert(checkDigestValid(local_context));\n }\n \n void DatabaseReplicated::renameTable(ContextPtr local_context, const String & table_name, IDatabase & to_database,\n@@ -831,31 +1014,51 @@ void DatabaseReplicated::renameTable(ContextPtr local_context, const String & ta\n     auto txn = local_context->getZooKeeperMetadataTransaction();\n     assert(txn);\n \n+    if (this != &to_database)\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Moving tables between databases is not supported for Replicated engine\");\n+    if (table_name == to_table_name)\n+        throw Exception(ErrorCodes::INCORRECT_QUERY, \"Cannot rename table to itself\");\n+    if (!isTableExist(table_name, local_context))\n+        throw Exception(ErrorCodes::UNKNOWN_TABLE, \"Table {} does not exist\", table_name);\n+    if (exchange && !to_database.isTableExist(to_table_name, local_context))\n+        throw Exception(ErrorCodes::UNKNOWN_TABLE, \"Table {} does not exist\", to_table_name);\n+\n+    String statement = readMetadataFile(table_name);\n+    String statement_to;\n+    if (exchange)\n+        statement_to = readMetadataFile(to_table_name);\n+\n     if (txn->isInitialQuery())\n     {\n-        if (this != &to_database)\n-            throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Moving tables between databases is not supported for Replicated engine\");\n-        if (table_name == to_table_name)\n-            throw Exception(ErrorCodes::INCORRECT_QUERY, \"Cannot rename table to itself\");\n-        if (!isTableExist(table_name, local_context))\n-            throw Exception(ErrorCodes::UNKNOWN_TABLE, \"Table {} does not exist\", table_name);\n-        if (exchange && !to_database.isTableExist(to_table_name, local_context))\n-            throw Exception(ErrorCodes::UNKNOWN_TABLE, \"Table {} does not exist\", to_table_name);\n-\n-        String statement = readMetadataFile(table_name);\n         String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(table_name);\n         String metadata_zk_path_to = zookeeper_path + \"/metadata/\" + escapeForFileName(to_table_name);\n-        txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path, -1));\n+        if (!txn->isCreateOrReplaceQuery())\n+            txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path, -1));\n+\n         if (exchange)\n         {\n-            String statement_to = readMetadataFile(to_table_name);\n             txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path_to, -1));\n-            txn->addOp(zkutil::makeCreateRequest(metadata_zk_path, statement_to, zkutil::CreateMode::Persistent));\n+            if (!txn->isCreateOrReplaceQuery())\n+                txn->addOp(zkutil::makeCreateRequest(metadata_zk_path, statement_to, zkutil::CreateMode::Persistent));\n         }\n         txn->addOp(zkutil::makeCreateRequest(metadata_zk_path_to, statement, zkutil::CreateMode::Persistent));\n     }\n \n+    std::lock_guard lock{metadata_mutex};\n+    UInt64 new_digest = tables_metadata_digest;\n+    new_digest -= DB::getMetadataHash(table_name, statement);\n+    new_digest += DB::getMetadataHash(to_table_name, statement);\n+    if (exchange)\n+    {\n+        new_digest -= DB::getMetadataHash(to_table_name, statement_to);\n+        new_digest += DB::getMetadataHash(table_name, statement_to);\n+    }\n+    if (txn)\n+        txn->addOp(zkutil::makeSetRequest(replica_path + \"/digest\", toString(new_digest), -1));\n+\n     DatabaseAtomic::renameTable(local_context, table_name, to_database, to_table_name, exchange, dictionary);\n+    tables_metadata_digest = new_digest;\n+    assert(checkDigestValid(local_context));\n }\n \n void DatabaseReplicated::commitCreateTable(const ASTCreateQuery & query, const StoragePtr & table,\n@@ -864,14 +1067,24 @@ void DatabaseReplicated::commitCreateTable(const ASTCreateQuery & query, const S\n {\n     auto txn = query_context->getZooKeeperMetadataTransaction();\n     assert(!ddl_worker->isCurrentlyActive() || txn);\n-    if (txn && txn->isInitialQuery())\n+\n+    String statement = getObjectDefinitionFromCreateQuery(query.clone());\n+    if (txn && txn->isInitialQuery() && !txn->isCreateOrReplaceQuery())\n     {\n         String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(query.getTable());\n-        String statement = getObjectDefinitionFromCreateQuery(query.clone());\n         /// zk::multi(...) will throw if `metadata_zk_path` exists\n         txn->addOp(zkutil::makeCreateRequest(metadata_zk_path, statement, zkutil::CreateMode::Persistent));\n     }\n+\n+    std::lock_guard lock{metadata_mutex};\n+    UInt64 new_digest = tables_metadata_digest;\n+    new_digest += DB::getMetadataHash(query.getTable(), statement);\n+    if (txn && !txn->isCreateOrReplaceQuery())\n+        txn->addOp(zkutil::makeSetRequest(replica_path + \"/digest\", toString(new_digest), -1));\n+\n     DatabaseAtomic::commitCreateTable(query, table, table_metadata_tmp_path, table_metadata_path, query_context);\n+    tables_metadata_digest = new_digest;\n+    assert(checkDigestValid(query_context));\n }\n \n void DatabaseReplicated::commitAlterTable(const StorageID & table_id,\n@@ -879,12 +1092,23 @@ void DatabaseReplicated::commitAlterTable(const StorageID & table_id,\n                                           const String & statement, ContextPtr query_context)\n {\n     auto txn = query_context->getZooKeeperMetadataTransaction();\n+    assert(!ddl_worker->isCurrentlyActive() || txn);\n     if (txn && txn->isInitialQuery())\n     {\n         String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(table_id.table_name);\n         txn->addOp(zkutil::makeSetRequest(metadata_zk_path, statement, -1));\n     }\n+\n+    std::lock_guard lock{metadata_mutex};\n+    UInt64 new_digest = tables_metadata_digest;\n+    new_digest -= getMetadataHash(table_id.table_name);\n+    new_digest += DB::getMetadataHash(table_id.table_name, statement);\n+    if (txn)\n+        txn->addOp(zkutil::makeSetRequest(replica_path + \"/digest\", toString(new_digest), -1));\n+\n     DatabaseAtomic::commitAlterTable(table_id, table_metadata_tmp_path, table_metadata_path, statement, query_context);\n+    tables_metadata_digest = new_digest;\n+    assert(checkDigestValid(query_context));\n }\n \n void DatabaseReplicated::detachTablePermanently(ContextPtr local_context, const String & table_name)\n@@ -898,10 +1122,19 @@ void DatabaseReplicated::detachTablePermanently(ContextPtr local_context, const\n         String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(table_name);\n         txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path, -1));\n     }\n+\n+    std::lock_guard lock{metadata_mutex};\n+    UInt64 new_digest = tables_metadata_digest;\n+    new_digest -= getMetadataHash(table_name);\n+    if (txn)\n+        txn->addOp(zkutil::makeSetRequest(replica_path + \"/digest\", toString(new_digest), -1));\n+\n     DatabaseAtomic::detachTablePermanently(local_context, table_name);\n+    tables_metadata_digest = new_digest;\n+    assert(checkDigestValid(local_context));\n }\n \n-void DatabaseReplicated::removeDetachedPermanentlyFlag(ContextPtr local_context, const String & table_name, const String & table_metadata_path, bool attach) const\n+void DatabaseReplicated::removeDetachedPermanentlyFlag(ContextPtr local_context, const String & table_name, const String & table_metadata_path, bool attach)\n {\n     auto txn = local_context->getZooKeeperMetadataTransaction();\n     assert(!ddl_worker->isCurrentlyActive() || txn);\n@@ -911,14 +1144,26 @@ void DatabaseReplicated::removeDetachedPermanentlyFlag(ContextPtr local_context,\n         String statement = readMetadataFile(table_name);\n         txn->addOp(zkutil::makeCreateRequest(metadata_zk_path, statement, zkutil::CreateMode::Persistent));\n     }\n+\n+    std::lock_guard lock{metadata_mutex};\n+    UInt64 new_digest = tables_metadata_digest;\n+    if (attach)\n+    {\n+        new_digest += getMetadataHash(table_name);\n+        if (txn)\n+            txn->addOp(zkutil::makeSetRequest(replica_path + \"/digest\", toString(new_digest), -1));\n+    }\n+\n     DatabaseAtomic::removeDetachedPermanentlyFlag(local_context, table_name, table_metadata_path, attach);\n+    tables_metadata_digest = new_digest;\n+    assert(checkDigestValid(local_context));\n }\n \n \n String DatabaseReplicated::readMetadataFile(const String & table_name) const\n {\n     String statement;\n-    ReadBufferFromFile in(getObjectMetadataPath(table_name), 4096);\n+    ReadBufferFromFile in(getObjectMetadataPath(table_name), METADATA_FILE_BUFFER_SIZE);\n     readStringUntilEOF(statement, in);\n     return statement;\n }\ndiff --git a/src/Databases/DatabaseReplicated.h b/src/Databases/DatabaseReplicated.h\nindex 07014702067b..56689ed94bff 100644\n--- a/src/Databases/DatabaseReplicated.h\n+++ b/src/Databases/DatabaseReplicated.h\n@@ -40,7 +40,7 @@ class DatabaseReplicated : public DatabaseAtomic\n                           const String & table_metadata_tmp_path, const String & table_metadata_path,\n                           const String & statement, ContextPtr query_context) override;\n     void detachTablePermanently(ContextPtr context, const String & table_name) override;\n-    void removeDetachedPermanentlyFlag(ContextPtr context, const String & table_name, const String & table_metadata_path, bool attach) const override;\n+    void removeDetachedPermanentlyFlag(ContextPtr context, const String & table_name, const String & table_metadata_path, bool attach) override;\n \n     bool waitForReplicaToProcessAllEntries(UInt64 timeout_ms);\n \n@@ -64,11 +64,11 @@ class DatabaseReplicated : public DatabaseAtomic\n \n     void drop(ContextPtr /*context*/) override;\n \n-    void loadStoredObjects(ContextMutablePtr context, bool force_restore, bool force_attach, bool skip_startup_tables) override;\n+    void loadStoredObjects(ContextMutablePtr context, LoadingStrictnessLevel mode, bool skip_startup_tables) override;\n \n-    void beforeLoadingMetadata(ContextMutablePtr context, bool force_restore, bool force_attach) override;\n+    void beforeLoadingMetadata(ContextMutablePtr context, LoadingStrictnessLevel mode) override;\n \n-    void startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach) override;\n+    void startupTables(ThreadPool & thread_pool, LoadingStrictnessLevel mode) override;\n \n     void shutdown() override;\n \n@@ -78,8 +78,9 @@ class DatabaseReplicated : public DatabaseAtomic\n     friend struct DatabaseReplicatedTask;\n     friend class DatabaseReplicatedDDLWorker;\n private:\n-    void tryConnectToZooKeeperAndInitDatabase(bool force_attach);\n+    void tryConnectToZooKeeperAndInitDatabase(LoadingStrictnessLevel mode);\n     bool createDatabaseNodesInZooKeeper(const ZooKeeperPtr & current_zookeeper);\n+    static bool looksLikeReplicatedDatabasePath(const ZooKeeperPtr & current_zookeeper, const String & path);\n     void createReplicaNodesInZooKeeper(const ZooKeeperPtr & current_zookeeper);\n \n     struct\n@@ -110,6 +111,9 @@ class DatabaseReplicated : public DatabaseAtomic\n         return is_recovering && typeid_cast<DatabaseAtomic *>(&to_database);\n     }\n \n+    UInt64 getMetadataHash(const String & table_name) const;\n+    bool checkDigestValid(const ContextPtr & local_context, bool debug_check = true) const TSA_REQUIRES(metadata_mutex);\n+\n     String zookeeper_path;\n     String shard_name;\n     String replica_name;\n@@ -119,10 +123,20 @@ class DatabaseReplicated : public DatabaseAtomic\n     zkutil::ZooKeeperPtr getZooKeeper() const;\n \n     std::atomic_bool is_readonly = true;\n+    std::atomic_bool is_probably_dropped = false;\n     std::atomic_bool is_recovering = false;\n     std::unique_ptr<DatabaseReplicatedDDLWorker> ddl_worker;\n     UInt32 max_log_ptr_at_creation = 0;\n \n+    /// Usually operation with metadata are single-threaded because of the way replication works,\n+    /// but StorageReplicatedMergeTree may call alterTable outside from DatabaseReplicatedDDLWorker causing race conditions.\n+    std::mutex metadata_mutex;\n+\n+    /// Sum of hashes of pairs (table_name, table_create_statement).\n+    /// We calculate this sum from local metadata files and compare it will value in ZooKeeper.\n+    /// It allows to detect if metadata is broken and recover replica.\n+    UInt64 tables_metadata_digest TSA_GUARDED_BY(metadata_mutex);\n+\n     mutable ClusterPtr cluster;\n };\n \ndiff --git a/src/Databases/DatabaseReplicatedSettings.h b/src/Databases/DatabaseReplicatedSettings.h\nindex 8bed1ababf62..c19ec1fb7a44 100644\n--- a/src/Databases/DatabaseReplicatedSettings.h\n+++ b/src/Databases/DatabaseReplicatedSettings.h\n@@ -12,6 +12,7 @@ class ASTStorage;\n     M(UInt64, max_replication_lag_to_enqueue, 10, \"Replica will throw exception on attempt to execute query if its replication lag greater\", 0) \\\n     M(UInt64, wait_entry_commited_timeout_sec, 3600, \"Replicas will try to cancel query if timeout exceed, but initiator host has not executed it yet\", 0) \\\n     M(String, collection_name, \"\", \"A name of a collection defined in server's config where all info for cluster authentication is defined\", 0) \\\n+    M(Bool, check_consistency, true, \"Check consistency of local metadata and metadata in Keeper, do replica recovery on inconsistency\", 0) \\\n \n \n DECLARE_SETTINGS_TRAITS(DatabaseReplicatedSettingsTraits, LIST_OF_DATABASE_REPLICATED_SETTINGS)\ndiff --git a/src/Databases/DatabaseReplicatedWorker.cpp b/src/Databases/DatabaseReplicatedWorker.cpp\nindex 96b4e273ce73..63d5af8da3dd 100644\n--- a/src/Databases/DatabaseReplicatedWorker.cpp\n+++ b/src/Databases/DatabaseReplicatedWorker.cpp\n@@ -32,9 +32,10 @@ bool DatabaseReplicatedDDLWorker::initializeMainThread()\n     {\n         try\n         {\n+            chassert(!database->is_probably_dropped);\n             auto zookeeper = getAndSetZooKeeper();\n             if (database->is_readonly)\n-                database->tryConnectToZooKeeperAndInitDatabase(false);\n+                database->tryConnectToZooKeeperAndInitDatabase(LoadingStrictnessLevel::ATTACH);\n             initializeReplication();\n             initialized = true;\n             return true;\n@@ -65,8 +66,34 @@ void DatabaseReplicatedDDLWorker::initializeReplication()\n     UInt32 our_log_ptr = parse<UInt32>(log_ptr_str);\n     UInt32 max_log_ptr = parse<UInt32>(zookeeper->get(database->zookeeper_path + \"/max_log_ptr\"));\n     logs_to_keep = parse<UInt32>(zookeeper->get(database->zookeeper_path + \"/logs_to_keep\"));\n-    if (our_log_ptr == 0 || our_log_ptr + logs_to_keep < max_log_ptr)\n+\n+    UInt64 digest;\n+    String digest_str;\n+    UInt64 local_digest;\n+    if (zookeeper->tryGet(database->replica_path + \"/digest\", digest_str))\n     {\n+        digest = parse<UInt64>(digest_str);\n+        std::lock_guard lock{database->metadata_mutex};\n+        local_digest = database->tables_metadata_digest;\n+    }\n+    else\n+    {\n+        /// Database was created by old ClickHouse versions, let's create the node\n+        std::lock_guard lock{database->metadata_mutex};\n+        digest = local_digest = database->tables_metadata_digest;\n+        digest_str = toString(digest);\n+        zookeeper->create(database->replica_path + \"/digest\", digest_str, zkutil::CreateMode::Persistent);\n+    }\n+\n+    bool is_new_replica = our_log_ptr == 0;\n+    bool lost_according_to_log_ptr = our_log_ptr + logs_to_keep < max_log_ptr;\n+    bool lost_according_to_digest = database->db_settings.check_consistency && local_digest != digest;\n+\n+    if (is_new_replica || lost_according_to_log_ptr || lost_according_to_digest)\n+    {\n+        if (!is_new_replica)\n+            LOG_WARNING(log, \"Replica seems to be lost: our_log_ptr={}, max_log_ptr={}, local_digest={}, zk_digest={}\",\n+                        our_log_ptr, max_log_ptr, local_digest, digest);\n         database->recoverLostReplica(zookeeper, our_log_ptr, max_log_ptr);\n         zookeeper->set(database->replica_path + \"/log_ptr\", toString(max_log_ptr));\n         initializeLogPointer(DDLTaskBase::getLogEntryName(max_log_ptr));\n@@ -77,6 +104,10 @@ void DatabaseReplicatedDDLWorker::initializeReplication()\n         last_skipped_entry_name.emplace(log_entry_name);\n         initializeLogPointer(log_entry_name);\n     }\n+\n+    std::lock_guard lock{database->metadata_mutex};\n+    if (!database->checkDigestValid(context))\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Inconsistent database metadata after reconnection to ZooKeeper\");\n }\n \n String DatabaseReplicatedDDLWorker::enqueueQuery(DDLLogEntry & entry)\n@@ -93,7 +124,7 @@ bool DatabaseReplicatedDDLWorker::waitForReplicaToProcessAllEntries(UInt64 timeo\n     const auto max_log_ptr_path = database->zookeeper_path + \"/max_log_ptr\";\n     UInt32 our_log_ptr = parse<UInt32>(zookeeper->get(our_log_ptr_path));\n     UInt32 max_log_ptr = parse<UInt32>(zookeeper->get(max_log_ptr_path));\n-    assert(our_log_ptr <= max_log_ptr);\n+    chassert(our_log_ptr <= max_log_ptr);\n \n     /// max_log_ptr is the number of the last successfully executed request on the initiator\n     /// The log could contain other entries which are not committed yet\n@@ -108,7 +139,6 @@ bool DatabaseReplicatedDDLWorker::waitForReplicaToProcessAllEntries(UInt64 timeo\n         std::unique_lock lock{mutex};\n         bool processed = wait_current_task_change.wait_for(lock, std::chrono::milliseconds(timeout_ms), [&]()\n         {\n-            assert(zookeeper->expired() || current_task <= max_log);\n             return zookeeper->expired() || current_task == max_log || stop_flag;\n         });\n \n@@ -181,6 +211,7 @@ String DatabaseReplicatedDDLWorker::enqueueQueryImpl(const ZooKeeperPtr & zookee\n     /// Create status dirs\n     ops.emplace_back(zkutil::makeCreateRequest(node_path + \"/active\", \"\", zkutil::CreateMode::Persistent));\n     ops.emplace_back(zkutil::makeCreateRequest(node_path + \"/finished\", \"\", zkutil::CreateMode::Persistent));\n+    ops.emplace_back(zkutil::makeCreateRequest(node_path + \"/synced\", \"\", zkutil::CreateMode::Persistent));\n     zookeeper->multi(ops);\n \n \n@@ -206,7 +237,7 @@ String DatabaseReplicatedDDLWorker::tryEnqueueAndExecuteEntry(DDLLogEntry & entr\n     auto task = std::make_unique<DatabaseReplicatedTask>(entry_name, entry_path, database);\n     task->entry = entry;\n     task->parseQueryFromEntry(context);\n-    assert(!task->entry.query.empty());\n+    chassert(!task->entry.query.empty());\n     assert(!zookeeper->exists(task->getFinishedNodePath()));\n     task->is_initial_query = true;\n \ndiff --git a/src/Databases/IDatabase.h b/src/Databases/IDatabase.h\nindex 72155bc818c4..338ee045c9db 100644\n--- a/src/Databases/IDatabase.h\n+++ b/src/Databases/IDatabase.h\n@@ -1,12 +1,13 @@\n #pragma once\n \n-#include <base/types.h>\n+#include <Core/UUID.h>\n+#include <Databases/LoadingStrictnessLevel.h>\n+#include <Interpreters/Context_fwd.h>\n #include <Parsers/IAST_fwd.h>\n #include <Storages/IStorage_fwd.h>\n-#include <Interpreters/Context_fwd.h>\n+#include <base/types.h>\n #include <Common/Exception.h>\n #include <Common/ThreadPool.h>\n-#include <Core/UUID.h>\n \n #include <ctime>\n #include <functional>\n@@ -132,18 +133,15 @@ class IDatabase : public std::enable_shared_from_this<IDatabase>\n     /// You can call only once, right after the object is created.\n     virtual void loadStoredObjects( /// NOLINT\n         ContextMutablePtr /*context*/,\n-        bool /*force_restore*/,\n-        bool /*force_attach*/ = false,\n-        bool /* skip_startup_tables */ = false)\n+        LoadingStrictnessLevel /*mode*/,\n+        bool /* skip_startup_tables */)\n     {\n     }\n \n     virtual bool supportsLoadingInTopologicalOrder() const { return false; }\n \n     virtual void beforeLoadingMetadata(\n-        ContextMutablePtr /*context*/,\n-        bool /*force_restore*/,\n-        bool /*force_attach*/)\n+        ContextMutablePtr /*context*/, LoadingStrictnessLevel /*mode*/)\n     {\n     }\n \n@@ -152,12 +150,13 @@ class IDatabase : public std::enable_shared_from_this<IDatabase>\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Not implemented\");\n     }\n \n-    virtual void loadTableFromMetadata(ContextMutablePtr /*local_context*/, const String & /*file_path*/, const QualifiedTableName & /*name*/, const ASTPtr & /*ast*/, bool /*force_restore*/)\n+    virtual void loadTableFromMetadata(ContextMutablePtr /*local_context*/, const String & /*file_path*/, const QualifiedTableName & /*name*/, const ASTPtr & /*ast*/,\n+        LoadingStrictnessLevel /*mode*/)\n     {\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Not implemented\");\n     }\n \n-    virtual void startupTables(ThreadPool & /*thread_pool*/, bool /*force_restore*/, bool /*force_attach*/) {}\n+    virtual void startupTables(ThreadPool & /*thread_pool*/, LoadingStrictnessLevel /*mode*/) {}\n \n     /// Check the existence of the table in memory (attached).\n     virtual bool isTableExist(const String & name, ContextPtr context) const = 0;\ndiff --git a/src/Databases/LoadingStrictnessLevel.cpp b/src/Databases/LoadingStrictnessLevel.cpp\nnew file mode 100644\nindex 000000000000..8d491ca56892\n--- /dev/null\n+++ b/src/Databases/LoadingStrictnessLevel.cpp\n@@ -0,0 +1,28 @@\n+#include <Databases/LoadingStrictnessLevel.h>\n+#include <cassert>\n+\n+namespace DB\n+{\n+\n+LoadingStrictnessLevel getLoadingStrictnessLevel(bool attach, bool force_attach, bool force_restore)\n+{\n+    if (force_restore)\n+    {\n+        assert(attach);\n+        assert(force_attach);\n+        return LoadingStrictnessLevel::FORCE_RESTORE;\n+    }\n+\n+    if (force_attach)\n+    {\n+        assert(attach);\n+        return LoadingStrictnessLevel::FORCE_ATTACH;\n+    }\n+\n+    if (attach)\n+        return LoadingStrictnessLevel::ATTACH;\n+\n+    return LoadingStrictnessLevel::CREATE;\n+}\n+\n+}\ndiff --git a/src/Databases/LoadingStrictnessLevel.h b/src/Databases/LoadingStrictnessLevel.h\nnew file mode 100644\nindex 000000000000..b6449a0a9fd6\n--- /dev/null\n+++ b/src/Databases/LoadingStrictnessLevel.h\n@@ -0,0 +1,21 @@\n+#pragma once\n+\n+namespace DB\n+{\n+\n+/// Strictness mode for loading a table or database\n+enum class LoadingStrictnessLevel\n+{\n+    /// Do all possible sanity checks\n+    CREATE = 0,\n+    /// Expect existing paths on FS and in ZK for ATTACH query\n+    ATTACH = 1,\n+    /// We ignore some error on server startup\n+    FORCE_ATTACH = 2,\n+    /// Skip all sanity checks (if force_restore_data flag exists)\n+    FORCE_RESTORE = 3,\n+};\n+\n+LoadingStrictnessLevel getLoadingStrictnessLevel(bool attach, bool force_attach, bool force_restore);\n+\n+}\ndiff --git a/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp b/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp\nindex 230a0b4d4a40..91dbadca4093 100644\n--- a/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp\n+++ b/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp\n@@ -63,11 +63,11 @@ void DatabaseMaterializedMySQL::setException(const std::exception_ptr & exceptio\n     exception = exception_;\n }\n \n-void DatabaseMaterializedMySQL::startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach)\n+void DatabaseMaterializedMySQL::startupTables(ThreadPool & thread_pool, LoadingStrictnessLevel mode)\n {\n-    DatabaseAtomic::startupTables(thread_pool, force_restore, force_attach);\n+    DatabaseAtomic::startupTables(thread_pool, mode);\n \n-    if (!force_attach)\n+    if (mode < LoadingStrictnessLevel::FORCE_ATTACH)\n         materialize_thread.assertMySQLAvailable();\n \n     materialize_thread.startSynchronization();\ndiff --git a/src/Databases/MySQL/DatabaseMaterializedMySQL.h b/src/Databases/MySQL/DatabaseMaterializedMySQL.h\nindex a6810f29d87c..27a7ddc8acfe 100644\n--- a/src/Databases/MySQL/DatabaseMaterializedMySQL.h\n+++ b/src/Databases/MySQL/DatabaseMaterializedMySQL.h\n@@ -48,7 +48,7 @@ class DatabaseMaterializedMySQL : public DatabaseAtomic\n public:\n     String getEngineName() const override { return \"MaterializedMySQL\"; }\n \n-    void startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach) override;\n+    void startupTables(ThreadPool & thread_pool, LoadingStrictnessLevel mode) override;\n \n     void createTable(ContextPtr context_, const String & name, const StoragePtr & table, const ASTPtr & query) override;\n \ndiff --git a/src/Databases/MySQL/DatabaseMySQL.cpp b/src/Databases/MySQL/DatabaseMySQL.cpp\nindex 95098ba9cbd8..01c342c17719 100644\n--- a/src/Databases/MySQL/DatabaseMySQL.cpp\n+++ b/src/Databases/MySQL/DatabaseMySQL.cpp\n@@ -398,7 +398,7 @@ String DatabaseMySQL::getMetadataPath() const\n     return metadata_path;\n }\n \n-void DatabaseMySQL::loadStoredObjects(ContextMutablePtr, bool, bool /*force_attach*/, bool /* skip_startup_tables */)\n+void DatabaseMySQL::loadStoredObjects(ContextMutablePtr, LoadingStrictnessLevel /*mode*/, bool /* skip_startup_tables */)\n {\n \n     std::lock_guard<std::mutex> lock{mutex};\ndiff --git a/src/Databases/MySQL/DatabaseMySQL.h b/src/Databases/MySQL/DatabaseMySQL.h\nindex 542cd65c1f14..5d0a366e5e64 100644\n--- a/src/Databases/MySQL/DatabaseMySQL.h\n+++ b/src/Databases/MySQL/DatabaseMySQL.h\n@@ -76,7 +76,7 @@ class DatabaseMySQL final : public IDatabase, WithContext\n \n     void createTable(ContextPtr, const String & table_name, const StoragePtr & storage, const ASTPtr & create_query) override;\n \n-    void loadStoredObjects(ContextMutablePtr, bool, bool force_attach, bool skip_startup_tables) override;\n+    void loadStoredObjects(ContextMutablePtr, LoadingStrictnessLevel /*mode*/, bool skip_startup_tables) override;\n \n     StoragePtr detachTable(ContextPtr context, const String & table_name) override;\n \ndiff --git a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp\nindex 08a0859e6db1..523cc7041be6 100644\n--- a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp\n+++ b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp\n@@ -125,9 +125,9 @@ void DatabaseMaterializedPostgreSQL::startSynchronization()\n }\n \n \n-void DatabaseMaterializedPostgreSQL::startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach)\n+void DatabaseMaterializedPostgreSQL::startupTables(ThreadPool & thread_pool, LoadingStrictnessLevel mode)\n {\n-    DatabaseAtomic::startupTables(thread_pool, force_restore, force_attach);\n+    DatabaseAtomic::startupTables(thread_pool, mode);\n     startup_task->activateAndSchedule();\n }\n \ndiff --git a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h\nindex ac2bcedca608..6363e8e07c40 100644\n--- a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h\n+++ b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h\n@@ -40,7 +40,7 @@ class DatabaseMaterializedPostgreSQL : public DatabaseAtomic\n \n     String getMetadataPath() const override { return metadata_path; }\n \n-    void startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach) override;\n+    void startupTables(ThreadPool & thread_pool, LoadingStrictnessLevel mode) override;\n \n     DatabaseTablesIteratorPtr\n     getTablesIterator(ContextPtr context, const DatabaseOnDisk::FilterByNameFunction & filter_by_table_name) const override;\ndiff --git a/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp b/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp\nindex c4b815c0c9fb..8e89765b6352 100644\n--- a/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp\n+++ b/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp\n@@ -290,7 +290,7 @@ void DatabasePostgreSQL::drop(ContextPtr /*context*/)\n }\n \n \n-void DatabasePostgreSQL::loadStoredObjects(ContextMutablePtr /* context */, bool, bool /*force_attach*/, bool /* skip_startup_tables */)\n+void DatabasePostgreSQL::loadStoredObjects(ContextMutablePtr /* context */, LoadingStrictnessLevel /*mode*/, bool /* skip_startup_tables */)\n {\n     {\n         std::lock_guard<std::mutex> lock{mutex};\ndiff --git a/src/Databases/PostgreSQL/DatabasePostgreSQL.h b/src/Databases/PostgreSQL/DatabasePostgreSQL.h\nindex fe4dff2ca93a..d70e529e4a65 100644\n--- a/src/Databases/PostgreSQL/DatabasePostgreSQL.h\n+++ b/src/Databases/PostgreSQL/DatabasePostgreSQL.h\n@@ -45,7 +45,7 @@ class DatabasePostgreSQL final : public IDatabase, WithContext\n \n     bool empty() const override;\n \n-    void loadStoredObjects(ContextMutablePtr, bool, bool force_attach, bool skip_startup_tables) override;\n+    void loadStoredObjects(ContextMutablePtr, LoadingStrictnessLevel /*mode*/, bool skip_startup_tables) override;\n \n     DatabaseTablesIteratorPtr getTablesIterator(ContextPtr context, const FilterByNameFunction & filter_by_table_name) const override;\n \ndiff --git a/src/Databases/TablesLoader.cpp b/src/Databases/TablesLoader.cpp\nindex 7e9b83d423a6..1114206d4693 100644\n--- a/src/Databases/TablesLoader.cpp\n+++ b/src/Databases/TablesLoader.cpp\n@@ -62,11 +62,10 @@ void logAboutProgress(Poco::Logger * log, size_t processed, size_t total, Atomic\n     }\n }\n \n-TablesLoader::TablesLoader(ContextMutablePtr global_context_, Databases databases_, bool force_restore_, bool force_attach_)\n+TablesLoader::TablesLoader(ContextMutablePtr global_context_, Databases databases_, LoadingStrictnessLevel strictness_mode_)\n : global_context(global_context_)\n , databases(std::move(databases_))\n-, force_restore(force_restore_)\n-, force_attach(force_attach_)\n+, strictness_mode(strictness_mode_)\n {\n     metadata.default_database = global_context->getCurrentDatabase();\n     log = &Poco::Logger::get(\"TablesLoader\");\n@@ -83,7 +82,7 @@ void TablesLoader::loadTables()\n         if (need_resolve_dependencies && database.second->supportsLoadingInTopologicalOrder())\n             databases_to_load.push_back(database.first);\n         else\n-            database.second->loadStoredObjects(global_context, force_restore, force_attach, true);\n+            database.second->loadStoredObjects(global_context, strictness_mode, /* skip_startup_tables */ true);\n     }\n \n     if (databases_to_load.empty())\n@@ -92,8 +91,9 @@ void TablesLoader::loadTables()\n     /// Read and parse metadata from Ordinary, Atomic, Materialized*, Replicated, etc databases. Build dependency graph.\n     for (auto & database_name : databases_to_load)\n     {\n-        databases[database_name]->beforeLoadingMetadata(global_context, force_restore, force_attach);\n-        databases[database_name]->loadTablesMetadata(global_context, metadata, force_attach);\n+        databases[database_name]->beforeLoadingMetadata(global_context, strictness_mode);\n+        bool is_startup = LoadingStrictnessLevel::FORCE_ATTACH <= strictness_mode;\n+        databases[database_name]->loadTablesMetadata(global_context, metadata, is_startup);\n     }\n \n     LOG_INFO(log, \"Parsed metadata of {} tables in {} databases in {} sec\",\n@@ -119,7 +119,7 @@ void TablesLoader::startupTables()\n {\n     /// Startup tables after all tables are loaded. Background tasks (merges, mutations, etc) may slow down data parts loading.\n     for (auto & database : databases)\n-        database.second->startupTables(pool, force_restore, force_attach);\n+        database.second->startupTables(pool, strictness_mode);\n }\n \n \n@@ -253,7 +253,7 @@ void TablesLoader::startLoadingIndependentTables(ThreadPool & pool, size_t level\n         pool.scheduleOrThrowOnError([this, load_context, total_tables, &table_name]()\n         {\n             const auto & path_and_query = metadata.parsed_tables[table_name];\n-            databases[table_name.database]->loadTableFromMetadata(load_context, path_and_query.path, table_name, path_and_query.ast, force_restore);\n+            databases[table_name.database]->loadTableFromMetadata(load_context, path_and_query.path, table_name, path_and_query.ast, strictness_mode);\n             logAboutProgress(log, ++tables_processed, total_tables, stopwatch);\n         });\n     }\ndiff --git a/src/Databases/TablesLoader.h b/src/Databases/TablesLoader.h\nindex 43e8bfdb92cd..7a29d0e3958f 100644\n--- a/src/Databases/TablesLoader.h\n+++ b/src/Databases/TablesLoader.h\n@@ -1,14 +1,15 @@\n #pragma once\n-#include <Core/Types.h>\n-#include <Core/QualifiedTableName.h>\n-#include <Parsers/IAST_fwd.h>\n-#include <Interpreters/Context_fwd.h>\n-#include <Common/ThreadPool.h>\n-#include <Common/Stopwatch.h>\n #include <map>\n+#include <mutex>\n #include <unordered_map>\n #include <unordered_set>\n-#include <mutex>\n+#include <Core/QualifiedTableName.h>\n+#include <Core/Types.h>\n+#include <Databases/LoadingStrictnessLevel.h>\n+#include <Interpreters/Context_fwd.h>\n+#include <Parsers/IAST_fwd.h>\n+#include <Common/Stopwatch.h>\n+#include <Common/ThreadPool.h>\n \n namespace Poco\n {\n@@ -78,7 +79,7 @@ class TablesLoader\n public:\n     using Databases = std::map<String, DatabasePtr>;\n \n-    TablesLoader(ContextMutablePtr global_context_, Databases databases_, bool force_restore_ = false, bool force_attach_ = false);\n+    TablesLoader(ContextMutablePtr global_context_, Databases databases_, LoadingStrictnessLevel strictness_mode_);\n     TablesLoader() = delete;\n \n     void loadTables();\n@@ -87,8 +88,7 @@ class TablesLoader\n private:\n     ContextMutablePtr global_context;\n     Databases databases;\n-    bool force_restore;\n-    bool force_attach;\n+    LoadingStrictnessLevel strictness_mode;\n \n     Strings databases_to_load;\n     ParsedTablesMetadata metadata;\ndiff --git a/src/Interpreters/DDLTask.cpp b/src/Interpreters/DDLTask.cpp\nindex 71fcd7a18840..880a624376dc 100644\n--- a/src/Interpreters/DDLTask.cpp\n+++ b/src/Interpreters/DDLTask.cpp\n@@ -25,6 +25,7 @@ namespace ErrorCodes\n     extern const int UNKNOWN_TYPE_OF_QUERY;\n     extern const int INCONSISTENT_CLUSTER_DEFINITION;\n     extern const int LOGICAL_ERROR;\n+    extern const int DNS_ERROR;\n }\n \n HostID HostID::fromString(const String & host_port_str)\n@@ -58,7 +59,12 @@ void DDLLogEntry::assertVersion() const\n void DDLLogEntry::setSettingsIfRequired(ContextPtr context)\n {\n     version = context->getSettingsRef().distributed_ddl_entry_format_version;\n-    if (version == 2)\n+\n+    /// NORMALIZE_CREATE_ON_INITIATOR_VERSION does not affect entry format in ZooKeeper\n+    if (version == NORMALIZE_CREATE_ON_INITIATOR_VERSION)\n+        version = SETTINGS_IN_ZK_VERSION;\n+\n+    if (version == SETTINGS_IN_ZK_VERSION)\n         settings.emplace(context->getSettingsRef().changes());\n }\n \n@@ -69,7 +75,7 @@ String DDLLogEntry::toString() const\n     wb << \"version: \" << version << \"\\n\";\n     wb << \"query: \" << escape << query << \"\\n\";\n \n-    bool write_hosts = version == 1 || !hosts.empty();\n+    bool write_hosts = version == OLDEST_VERSION || !hosts.empty();\n     if (write_hosts)\n     {\n         Strings host_id_strings(hosts.size());\n@@ -79,7 +85,7 @@ String DDLLogEntry::toString() const\n \n     wb << \"initiator: \" << initiator << \"\\n\";\n \n-    bool write_settings = 1 <= version && settings && !settings->empty();\n+    bool write_settings = SETTINGS_IN_ZK_VERSION <= version && settings && !settings->empty();\n     if (write_settings)\n     {\n         ASTSetQuery ast;\n@@ -164,17 +170,33 @@ ContextMutablePtr DDLTaskBase::makeQueryContext(ContextPtr from_context, const Z\n bool DDLTask::findCurrentHostID(ContextPtr global_context, Poco::Logger * log)\n {\n     bool host_in_hostlist = false;\n+    std::exception_ptr first_exception = nullptr;\n \n     for (const HostID & host : entry.hosts)\n     {\n         auto maybe_secure_port = global_context->getTCPPortSecure();\n \n-        /// The port is considered local if it matches TCP or TCP secure port that the server is listening.\n-        bool is_local_port = (maybe_secure_port && host.isLocalAddress(*maybe_secure_port))\n-                             || host.isLocalAddress(global_context->getTCPPort());\n+        try\n+        {\n+            /// The port is considered local if it matches TCP or TCP secure port that the server is listening.\n+            bool is_local_port\n+                = (maybe_secure_port && host.isLocalAddress(*maybe_secure_port)) || host.isLocalAddress(global_context->getTCPPort());\n \n-        if (!is_local_port)\n+            if (!is_local_port)\n+                continue;\n+        }\n+        catch (const Exception & e)\n+        {\n+            if (e.code() != ErrorCodes::DNS_ERROR)\n+                throw;\n+\n+            if (!first_exception)\n+                first_exception = std::current_exception();\n+\n+            /// Ignore unknown hosts (in case DNS record was removed)\n+            /// We will rethrow exception if we don't find local host in the list.\n             continue;\n+        }\n \n         if (host_in_hostlist)\n         {\n@@ -190,6 +212,12 @@ bool DDLTask::findCurrentHostID(ContextPtr global_context, Poco::Logger * log)\n         }\n     }\n \n+    if (!host_in_hostlist && first_exception)\n+    {\n+        /// We don't know for sure if we should process task or not\n+        std::rethrow_exception(first_exception);\n+    }\n+\n     return host_in_hostlist;\n }\n \n@@ -361,7 +389,7 @@ void DatabaseReplicatedTask::parseQueryFromEntry(ContextPtr context)\n     if (auto * ddl_query = dynamic_cast<ASTQueryWithTableAndOutput *>(query.get()))\n     {\n         /// Update database name with actual name of local database\n-        assert(!ddl_query->database);\n+        chassert(!ddl_query->database);\n         ddl_query->setDatabase(database->getDatabaseName());\n     }\n }\n@@ -397,6 +425,24 @@ Coordination::RequestPtr DatabaseReplicatedTask::getOpToUpdateLogPointer()\n     return zkutil::makeSetRequest(database->replica_path + \"/log_ptr\", toString(getLogEntryNumber(entry_name)), -1);\n }\n \n+void DatabaseReplicatedTask::createSyncedNodeIfNeed(const ZooKeeperPtr & zookeeper)\n+{\n+    assert(!completely_processed);\n+    if (!entry.settings)\n+        return;\n+\n+    Field value;\n+    if (!entry.settings->tryGet(\"database_replicated_enforce_synchronous_settings\", value))\n+        return;\n+\n+    /// Bool type is really weird, sometimes it's Bool and sometimes it's UInt64...\n+    assert(value.getType() == Field::Types::Bool || value.getType() == Field::Types::UInt64);\n+    if (!value.get<UInt64>())\n+        return;\n+\n+    zookeeper->createIfNotExists(getSyncedNodePath(), \"\");\n+}\n+\n String DDLTaskBase::getLogEntryName(UInt32 log_entry_number)\n {\n     return zkutil::getSequentialNodeName(\"query-\", log_entry_number);\ndiff --git a/src/Interpreters/DDLTask.h b/src/Interpreters/DDLTask.h\nindex d3728918a2d3..d5990edd43f4 100644\n--- a/src/Interpreters/DDLTask.h\n+++ b/src/Interpreters/DDLTask.h\n@@ -66,6 +66,10 @@ struct HostID\n \n struct DDLLogEntry\n {\n+    static constexpr const UInt64 OLDEST_VERSION = 1;\n+    static constexpr const UInt64 SETTINGS_IN_ZK_VERSION = 2;\n+    static constexpr const UInt64 NORMALIZE_CREATE_ON_INITIATOR_VERSION = 3;\n+\n     UInt64 version = 1;\n     String query;\n     std::vector<HostID> hosts;\n@@ -109,9 +113,12 @@ struct DDLTaskBase\n     virtual ContextMutablePtr makeQueryContext(ContextPtr from_context, const ZooKeeperPtr & zookeeper);\n     virtual Coordination::RequestPtr getOpToUpdateLogPointer() { return nullptr; }\n \n+    virtual void createSyncedNodeIfNeed(const ZooKeeperPtr & /*zookeeper*/) {}\n+\n     inline String getActiveNodePath() const { return fs::path(entry_path) / \"active\" / host_id_str; }\n     inline String getFinishedNodePath() const { return fs::path(entry_path) / \"finished\" / host_id_str; }\n     inline String getShardNodePath() const { return fs::path(entry_path) / \"shards\" / getShardID(); }\n+    inline String getSyncedNodePath() const { return fs::path(entry_path) / \"synced\" / host_id_str; }\n \n     static String getLogEntryName(UInt32 log_entry_number);\n     static UInt32 getLogEntryNumber(const String & log_entry_name);\n@@ -147,6 +154,7 @@ struct DatabaseReplicatedTask : public DDLTaskBase\n     void parseQueryFromEntry(ContextPtr context) override;\n     ContextMutablePtr makeQueryContext(ContextPtr from_context, const ZooKeeperPtr & zookeeper) override;\n     Coordination::RequestPtr getOpToUpdateLogPointer() override;\n+    void createSyncedNodeIfNeed(const ZooKeeperPtr & zookeeper) override;\n \n     DatabaseReplicated * database;\n };\n@@ -174,6 +182,12 @@ class ZooKeeperMetadataTransaction\n     String task_path;\n     Coordination::Requests ops;\n \n+    /// CREATE OR REPLACE is special query that consists of 3 separate DDL queries (CREATE, RENAME, DROP)\n+    /// and not all changes should be applied to metadata in ZooKeeper\n+    /// (otherwise we may get partially applied changes on connection loss).\n+    /// So we need this flag to avoid doing unnecessary operations with metadata.\n+    bool is_create_or_replace_query = false;\n+\n public:\n     ZooKeeperMetadataTransaction(const ZooKeeperPtr & current_zookeeper_, const String & zookeeper_path_, bool is_initial_query_, const String & task_path_)\n     : current_zookeeper(current_zookeeper_)\n@@ -193,6 +207,10 @@ class ZooKeeperMetadataTransaction\n \n     ZooKeeperPtr getZooKeeper() const { return current_zookeeper; }\n \n+    void setIsCreateOrReplaceQuery() { is_create_or_replace_query = true; }\n+\n+    bool isCreateOrReplaceQuery() const { return is_create_or_replace_query; }\n+\n     void addOp(Coordination::RequestPtr && op)\n     {\n         if (isExecuted())\ndiff --git a/src/Interpreters/DDLWorker.cpp b/src/Interpreters/DDLWorker.cpp\nindex 13432940c1be..6ec20ab5f5fc 100644\n--- a/src/Interpreters/DDLWorker.cpp\n+++ b/src/Interpreters/DDLWorker.cpp\n@@ -112,6 +112,8 @@ DDLWorker::DDLWorker(\n \n void DDLWorker::startup()\n {\n+    [[maybe_unused]] bool prev_stop_flag = stop_flag.exchange(false);\n+    chassert(true);\n     main_thread = ThreadFromGlobalPool(&DDLWorker::runMainThread, this);\n     cleanup_thread = ThreadFromGlobalPool(&DDLWorker::runCleanupThread, this);\n }\n@@ -251,7 +253,7 @@ void DDLWorker::scheduleTasks(bool reinitialized)\n             auto & task = *task_it;\n             if (task->completely_processed)\n             {\n-                assert(task->was_executed);\n+                chassert(task->was_executed);\n                 /// Status must be written (but finished/ node may not exist if entry was deleted).\n                 /// If someone is deleting entry concurrently, then /active status dir must not exist.\n                 assert(zookeeper->exists(task->getFinishedNodePath()) || !zookeeper->exists(fs::path(task->entry_path) / \"active\"));\n@@ -267,7 +269,13 @@ void DDLWorker::scheduleTasks(bool reinitialized)\n                 /// but we lost connection while waiting for the response.\n                 /// Yeah, distributed systems is a zoo.\n                 if (status_written)\n+                {\n+                    /// TODO We cannot guarantee that query was actually executed synchronously if connection was lost.\n+                    /// Let's simple create synced/ node for now, but it would be better to pass UNFINISHED status to initiator\n+                    /// or wait for query to actually finish (requires https://github.com/ClickHouse/ClickHouse/issues/23513)\n+                    task->createSyncedNodeIfNeed(zookeeper);\n                     task->completely_processed = true;\n+                }\n                 else\n                     processTask(*task, zookeeper);\n                 ++task_it;\n@@ -312,7 +320,7 @@ void DDLWorker::scheduleTasks(bool reinitialized)\n     if (first_failed_task_name)\n     {\n         /// If we had failed tasks, then we should start from the first failed task.\n-        assert(reinitialized);\n+        chassert(reinitialized);\n         begin_node = std::lower_bound(queue_nodes.begin(), queue_nodes.end(), first_failed_task_name);\n     }\n     else\n@@ -505,7 +513,7 @@ void DDLWorker::updateMaxDDLEntryID(const String & entry_name)\n void DDLWorker::processTask(DDLTaskBase & task, const ZooKeeperPtr & zookeeper)\n {\n     LOG_DEBUG(log, \"Processing task {} ({})\", task.entry_name, task.entry.query);\n-    assert(!task.completely_processed);\n+    chassert(!task.completely_processed);\n \n     String active_node_path = task.getActiveNodePath();\n     String finished_node_path = task.getFinishedNodePath();\n@@ -523,14 +531,14 @@ void DDLWorker::processTask(DDLTaskBase & task, const ZooKeeperPtr & zookeeper)\n     {\n         if (create_active_res != Coordination::Error::ZNONODE && create_active_res != Coordination::Error::ZNODEEXISTS)\n         {\n-            assert(Coordination::isHardwareError(create_active_res));\n+            chassert(Coordination::isHardwareError(create_active_res));\n             throw Coordination::Exception(create_active_res, active_node_path);\n         }\n \n         /// Status dirs were not created in enqueueQuery(...) or someone is removing entry\n         if (create_active_res == Coordination::Error::ZNONODE)\n         {\n-            assert(dynamic_cast<DatabaseReplicatedTask *>(&task) == nullptr);\n+            chassert(dynamic_cast<DatabaseReplicatedTask *>(&task) == nullptr);\n             if (task.was_executed)\n             {\n                 /// Special case:\n@@ -643,6 +651,7 @@ void DDLWorker::processTask(DDLTaskBase & task, const ZooKeeperPtr & zookeeper)\n     /// Active node was removed in multi ops\n     active_node->setAlreadyRemoved();\n \n+    task.createSyncedNodeIfNeed(zookeeper);\n     task.completely_processed = true;\n     updateMaxDDLEntryID(task.entry_name);\n }\n@@ -810,7 +819,7 @@ bool DDLWorker::tryExecuteQueryOnLeaderReplica(\n         }\n     }\n \n-    assert(!(executed_by_us && executed_by_other_leader));\n+    chassert(!(executed_by_us && executed_by_other_leader));\n \n     /// Not executed by leader so was not executed at all\n     if (!executed_by_us && !executed_by_other_leader)\n@@ -901,9 +910,9 @@ void DDLWorker::cleanupQueue(Int64, const ZooKeeperPtr & zookeeper)\n                 /// Possible rare case: initiator node has lost connection after enqueueing entry and failed to create status dirs.\n                 /// No one has started to process the entry, so node_path/active and node_path/finished nodes were never created, node_path has no children.\n                 /// Entry became outdated, but we cannot remove remove it in a transaction with node_path/finished.\n-                assert(res[0]->error == Coordination::Error::ZOK && res[1]->error == Coordination::Error::ZNONODE);\n+                chassert(res[0]->error == Coordination::Error::ZOK && res[1]->error == Coordination::Error::ZNONODE);\n                 rm_entry_res = zookeeper->tryRemove(node_path);\n-                assert(rm_entry_res != Coordination::Error::ZNOTEMPTY);\n+                chassert(rm_entry_res != Coordination::Error::ZNOTEMPTY);\n                 continue;\n             }\n             zkutil::KeeperMultiException::check(rm_entry_res, ops, res);\n@@ -1004,7 +1013,7 @@ String DDLWorker::enqueueQuery(DDLLogEntry & entry)\n \n bool DDLWorker::initializeMainThread()\n {\n-    assert(!initialized);\n+    chassert(!initialized);\n     setThreadName(\"DDLWorker\");\n     LOG_DEBUG(log, \"Initializing DDLWorker thread\");\n \n@@ -1023,7 +1032,7 @@ bool DDLWorker::initializeMainThread()\n             {\n                 /// A logical error.\n                 LOG_ERROR(log, \"ZooKeeper error: {}. Failed to start DDLWorker.\", getCurrentExceptionMessage(true));\n-                assert(false);  /// Catch such failures in tests with debug build\n+                chassert(false);  /// Catch such failures in tests with debug build\n             }\n \n             tryLogCurrentException(__PRETTY_FUNCTION__);\ndiff --git a/src/Interpreters/DDLWorker.h b/src/Interpreters/DDLWorker.h\nindex 5dc6d4acbe52..7ddcc80c02a1 100644\n--- a/src/Interpreters/DDLWorker.h\n+++ b/src/Interpreters/DDLWorker.h\n@@ -138,7 +138,7 @@ class DDLWorker\n     std::shared_ptr<Poco::Event> queue_updated_event = std::make_shared<Poco::Event>();\n     std::shared_ptr<Poco::Event> cleanup_event = std::make_shared<Poco::Event>();\n     std::atomic<bool> initialized = false;\n-    std::atomic<bool> stop_flag = false;\n+    std::atomic<bool> stop_flag = true;\n \n     ThreadFromGlobalPool main_thread;\n     ThreadFromGlobalPool cleanup_thread;\ndiff --git a/src/Interpreters/InterpreterAlterQuery.cpp b/src/Interpreters/InterpreterAlterQuery.cpp\nindex 056a3d9f7b45..762afd289230 100644\n--- a/src/Interpreters/InterpreterAlterQuery.cpp\n+++ b/src/Interpreters/InterpreterAlterQuery.cpp\n@@ -66,7 +66,7 @@ BlockIO InterpreterAlterQuery::executeToTable(const ASTAlterQuery & alter)\n {\n     BlockIO res;\n \n-    if (!alter.cluster.empty())\n+    if (!alter.cluster.empty() && !maybeRemoveOnCluster(query_ptr, getContext()))\n     {\n         DDLQueryOnClusterParams params;\n         params.access_to_check = getRequiredAccess();\ndiff --git a/src/Interpreters/InterpreterCreateQuery.cpp b/src/Interpreters/InterpreterCreateQuery.cpp\nindex 7a00bbf524cd..e66fe543ab0c 100644\n--- a/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -249,6 +249,7 @@ BlockIO InterpreterCreateQuery::createDatabase(ASTCreateQuery & create)\n \n     bool need_write_metadata = !create.attach || !fs::exists(metadata_file_path);\n     bool need_lock_uuid = internal || need_write_metadata;\n+    auto mode = getLoadingStrictnessLevel(create.attach, force_attach, has_force_restore_data_flag);\n \n     /// Lock uuid, so we will known it's already in use.\n     /// We do it when attaching databases on server startup (internal) and on CREATE query (!create.attach);\n@@ -303,8 +304,9 @@ BlockIO InterpreterCreateQuery::createDatabase(ASTCreateQuery & create)\n \n         if (!load_database_without_tables)\n         {\n+\n             /// We use global context here, because storages lifetime is bigger than query context lifetime\n-            TablesLoader loader{getContext()->getGlobalContext(), {{database_name, database}}, has_force_restore_data_flag, create.attach && force_attach}; //-V560\n+            TablesLoader loader{getContext()->getGlobalContext(), {{database_name, database}}, mode}; //-V560\n             loader.loadTables();\n             loader.startupTables();\n         }\n@@ -1017,6 +1019,9 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)\n             }\n         }\n \n+        if (!create.cluster.empty())\n+            return executeQueryOnCluster(create);\n+\n         bool if_not_exists = create.if_not_exists;\n \n         // Table SQL definition is available even if the table is detached (even permanently)\n@@ -1153,6 +1158,9 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)\n         }\n     }\n \n+    if (!create.cluster.empty())\n+        return executeQueryOnCluster(create);\n+\n     if (create.replace_table)\n         return doCreateOrReplaceTable(create, properties);\n \n@@ -1358,25 +1366,15 @@ BlockIO InterpreterCreateQuery::doCreateOrReplaceTable(ASTCreateQuery & create,\n {\n     /// Replicated database requires separate contexts for each DDL query\n     ContextPtr current_context = getContext();\n+    if (auto txn = current_context->getZooKeeperMetadataTransaction())\n+        txn->setIsCreateOrReplaceQuery();\n     ContextMutablePtr create_context = Context::createCopy(current_context);\n     create_context->setQueryContext(std::const_pointer_cast<Context>(current_context));\n \n-    auto make_drop_context = [&](bool on_error) -> ContextMutablePtr\n+    auto make_drop_context = [&]() -> ContextMutablePtr\n     {\n         ContextMutablePtr drop_context = Context::createCopy(current_context);\n-        drop_context->makeQueryContext();\n-        if (on_error)\n-            return drop_context;\n-\n-        if (auto txn = current_context->getZooKeeperMetadataTransaction())\n-        {\n-            /// Execute drop as separate query, because [CREATE OR] REPLACE query can be considered as\n-            /// successfully executed after RENAME/EXCHANGE query.\n-            drop_context->resetZooKeeperMetadataTransaction();\n-            auto drop_txn = std::make_shared<ZooKeeperMetadataTransaction>(txn->getZooKeeper(), txn->getDatabaseZooKeeperPath(),\n-                                                                           txn->isInitialQuery(), txn->getTaskZooKeeperPath());\n-            drop_context->initZooKeeperMetadataTransaction(drop_txn);\n-        }\n+        drop_context->setQueryContext(std::const_pointer_cast<Context>(current_context));\n         return drop_context;\n     };\n \n@@ -1452,7 +1450,7 @@ BlockIO InterpreterCreateQuery::doCreateOrReplaceTable(ASTCreateQuery & create,\n         if (!interpreter_rename.renamedInsteadOfExchange())\n         {\n             /// Target table was replaced with new one, drop old table\n-            auto drop_context = make_drop_context(false);\n+            auto drop_context = make_drop_context();\n             InterpreterDropQuery(ast_drop, drop_context).execute();\n         }\n \n@@ -1465,7 +1463,7 @@ BlockIO InterpreterCreateQuery::doCreateOrReplaceTable(ASTCreateQuery & create,\n         /// Drop temporary table if it was successfully created, but was not renamed to target name\n         if (created && !renamed)\n         {\n-            auto drop_context = make_drop_context(true);\n+            auto drop_context = make_drop_context();\n             InterpreterDropQuery(ast_drop, drop_context).execute();\n         }\n         throw;\n@@ -1511,6 +1509,11 @@ void InterpreterCreateQuery::prepareOnClusterQuery(ASTCreateQuery & create, Cont\n \n     if (cluster->maybeCrossReplication())\n     {\n+        auto on_cluster_version = local_context->getSettingsRef().distributed_ddl_entry_format_version;\n+        if (DDLLogEntry::NORMALIZE_CREATE_ON_INITIATOR_VERSION <= on_cluster_version)\n+            throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Value {} of setting distributed_ddl_entry_format_version \"\n+                                                         \"is incompatible with cross-replication\", on_cluster_version);\n+\n         /// Check that {uuid} macro is not used in zookeeper_path for ReplicatedMergeTree.\n         /// Otherwise replicas will generate different paths.\n         if (!create.storage)\n@@ -1543,16 +1546,25 @@ void InterpreterCreateQuery::prepareOnClusterQuery(ASTCreateQuery & create, Cont\n     }\n }\n \n+BlockIO InterpreterCreateQuery::executeQueryOnCluster(ASTCreateQuery & create)\n+{\n+    prepareOnClusterQuery(create, getContext(), create.cluster);\n+    DDLQueryOnClusterParams params;\n+    params.access_to_check = getRequiredAccess();\n+    return executeDDLQueryOnCluster(query_ptr, getContext(), params);\n+}\n+\n BlockIO InterpreterCreateQuery::execute()\n {\n     FunctionNameNormalizer().visit(query_ptr.get());\n     auto & create = query_ptr->as<ASTCreateQuery &>();\n-    if (!create.cluster.empty())\n+\n+    bool is_create_database = create.database && !create.table;\n+    if (!create.cluster.empty() && !maybeRemoveOnCluster(query_ptr, getContext()))\n     {\n-        prepareOnClusterQuery(create, getContext(), create.cluster);\n-        DDLQueryOnClusterParams params;\n-        params.access_to_check = getRequiredAccess();\n-        return executeDDLQueryOnCluster(query_ptr, getContext(), params);\n+        auto on_cluster_version = getContext()->getSettingsRef().distributed_ddl_entry_format_version;\n+        if (is_create_database || on_cluster_version < DDLLogEntry::NORMALIZE_CREATE_ON_INITIATOR_VERSION)\n+            return executeQueryOnCluster(create);\n     }\n \n     getContext()->checkAccess(getRequiredAccess());\n@@ -1560,7 +1572,7 @@ BlockIO InterpreterCreateQuery::execute()\n     ASTQueryWithOutput::resetOutputASTIfExist(create);\n \n     /// CREATE|ATTACH DATABASE\n-    if (create.database && !create.table)\n+    if (is_create_database)\n         return createDatabase(create);\n     else\n         return createTable(create);\ndiff --git a/src/Interpreters/InterpreterCreateQuery.h b/src/Interpreters/InterpreterCreateQuery.h\nindex b6c8e10668a0..984310b29529 100644\n--- a/src/Interpreters/InterpreterCreateQuery.h\n+++ b/src/Interpreters/InterpreterCreateQuery.h\n@@ -100,6 +100,8 @@ class InterpreterCreateQuery : public IInterpreter, WithMutableContext\n     /// It's used to prevent automatic schema inference while table creation on each server startup.\n     void addColumnsDescriptionToCreateQueryIfNecessary(ASTCreateQuery & create, const StoragePtr & storage);\n \n+    BlockIO executeQueryOnCluster(ASTCreateQuery & create);\n+\n     ASTPtr query_ptr;\n \n     /// Skip safety threshold when loading tables.\ndiff --git a/src/Interpreters/InterpreterDropQuery.cpp b/src/Interpreters/InterpreterDropQuery.cpp\nindex bb3f91d52106..1f83992dbbe4 100644\n--- a/src/Interpreters/InterpreterDropQuery.cpp\n+++ b/src/Interpreters/InterpreterDropQuery.cpp\n@@ -54,7 +54,7 @@ InterpreterDropQuery::InterpreterDropQuery(const ASTPtr & query_ptr_, ContextMut\n BlockIO InterpreterDropQuery::execute()\n {\n     auto & drop = query_ptr->as<ASTDropQuery &>();\n-    if (!drop.cluster.empty())\n+    if (!drop.cluster.empty() && !maybeRemoveOnCluster(query_ptr, getContext()))\n     {\n         DDLQueryOnClusterParams params;\n         params.access_to_check = getRequiredAccessForDDLOnCluster();\ndiff --git a/src/Interpreters/InterpreterSystemQuery.cpp b/src/Interpreters/InterpreterSystemQuery.cpp\nindex b37274a3152d..8fe55a1635d0 100644\n--- a/src/Interpreters/InterpreterSystemQuery.cpp\n+++ b/src/Interpreters/InterpreterSystemQuery.cpp\n@@ -760,6 +760,7 @@ void InterpreterSystemQuery::syncReplica(ASTSystemQuery &)\n void InterpreterSystemQuery::syncReplicatedDatabase(ASTSystemQuery & query)\n {\n     const auto database_name = query.getDatabase();\n+    auto guard = DatabaseCatalog::instance().getDDLGuard(database_name, \"\");\n     auto database = DatabaseCatalog::instance().getDatabase(database_name);\n \n     if (auto * ptr = typeid_cast<DatabaseReplicated *>(database.get()))\n@@ -767,8 +768,7 @@ void InterpreterSystemQuery::syncReplicatedDatabase(ASTSystemQuery & query)\n         LOG_TRACE(log, \"Synchronizing entries in the database replica's (name: {}) queue with the log\", database_name);\n         if (!ptr->waitForReplicaToProcessAllEntries(getContext()->getSettingsRef().receive_timeout.totalMilliseconds()))\n         {\n-            LOG_ERROR(log, \"SYNC DATABASE REPLICA {}: Timed out!\", database_name);\n-            throw Exception(ErrorCodes::TIMEOUT_EXCEEDED, \"SYNC DATABASE REPLICA {}: command timed out. \" \\\n+            throw Exception(ErrorCodes::TIMEOUT_EXCEEDED, \"SYNC DATABASE REPLICA {}: database is readonly or command timed out. \" \\\n                     \"See the 'receive_timeout' setting\", database_name);\n         }\n         LOG_TRACE(log, \"SYNC DATABASE REPLICA {}: OK\", database_name);\ndiff --git a/src/Interpreters/executeDDLQueryOnCluster.cpp b/src/Interpreters/executeDDLQueryOnCluster.cpp\nindex 387f4e892a1c..7cc4efcb64df 100644\n--- a/src/Interpreters/executeDDLQueryOnCluster.cpp\n+++ b/src/Interpreters/executeDDLQueryOnCluster.cpp\n@@ -12,9 +12,11 @@\n #include <Access/ContextAccess.h>\n #include <Common/Macros.h>\n #include <Common/ZooKeeper/ZooKeeper.h>\n+#include <Databases/DatabaseReplicated.h>\n #include <DataTypes/DataTypesNumber.h>\n #include <DataTypes/DataTypeString.h>\n #include <DataTypes/DataTypeNullable.h>\n+#include <DataTypes/DataTypeEnum.h>\n #include <Processors/Sinks/EmptySink.h>\n #include <QueryPipeline/Pipe.h>\n #include <filesystem>\n@@ -181,10 +183,24 @@ class DDLQueryStatusSource final : public ISource\n private:\n     static Strings getChildrenAllowNoNode(const std::shared_ptr<zkutil::ZooKeeper> & zookeeper, const String & node_path);\n \n+    static Block getSampleBlock(ContextPtr context_, bool hosts_to_wait);\n+\n     Strings getNewAndUpdate(const Strings & current_list_of_finished_hosts);\n \n     std::pair<String, UInt16> parseHostAndPort(const String & host_id) const;\n \n+    Chunk generateChunkWithUnfinishedHosts() const;\n+\n+    enum ReplicatedDatabaseQueryStatus\n+    {\n+        /// Query is (successfully) finished\n+        OK = 0,\n+        /// Query is not finished yet, but replica is currently executing it\n+        IN_PROGRESS = 1,\n+        /// Replica is not available or busy with previous queries. It will process query asynchronously\n+        QUEUED = 2,\n+    };\n+\n     String node_path;\n     ContextPtr context;\n     Stopwatch watch;\n@@ -200,7 +216,7 @@ class DDLQueryStatusSource final : public ISource\n     std::unique_ptr<Exception> first_exception;\n \n     Int64 timeout_seconds = 120;\n-    bool by_hostname = true;\n+    bool is_replicated_database = false;\n     bool throw_on_timeout = true;\n     bool timeout_exceeded = false;\n };\n@@ -221,7 +237,7 @@ BlockIO getDistributedDDLStatus(const String & node_path, const DDLLogEntry & en\n     return io;\n }\n \n-static Block getSampleBlock(ContextPtr context_, bool hosts_to_wait)\n+Block DDLQueryStatusSource::getSampleBlock(ContextPtr context_, bool hosts_to_wait)\n {\n     auto output_mode = context_->getSettingsRef().distributed_ddl_output_mode;\n \n@@ -232,19 +248,38 @@ static Block getSampleBlock(ContextPtr context_, bool hosts_to_wait)\n         return std::make_shared<DataTypeNullable>(type);\n     };\n \n-    Block res = Block{\n-        {std::make_shared<DataTypeString>(),                         \"host\"},\n-        {std::make_shared<DataTypeUInt16>(),                         \"port\"},\n-        {maybe_make_nullable(std::make_shared<DataTypeInt64>()),     \"status\"},\n-        {maybe_make_nullable(std::make_shared<DataTypeString>()),    \"error\"},\n-        {std::make_shared<DataTypeUInt64>(),                         \"num_hosts_remaining\"},\n-        {std::make_shared<DataTypeUInt64>(),                         \"num_hosts_active\"},\n+    auto get_status_enum = []()\n+    {\n+        return std::make_shared<DataTypeEnum8>(\n+            DataTypeEnum8::Values\n+            {\n+                {\"OK\",              static_cast<Int8>(OK)},\n+                {\"IN_PROGRESS\",     static_cast<Int8>(IN_PROGRESS)},\n+                {\"QUEUED\",          static_cast<Int8>(QUEUED)},\n+            });\n     };\n \n     if (hosts_to_wait)\n-        res.erase(\"port\");\n-\n-    return res;\n+    {\n+        return Block{\n+            {std::make_shared<DataTypeString>(), \"shard\"},\n+            {std::make_shared<DataTypeString>(), \"replica\"},\n+            {get_status_enum(), \"status\"},\n+            {std::make_shared<DataTypeUInt64>(), \"num_hosts_remaining\"},\n+            {std::make_shared<DataTypeUInt64>(), \"num_hosts_active\"},\n+        };\n+    }\n+    else\n+    {\n+        return Block{\n+            {std::make_shared<DataTypeString>(), \"host\"},\n+            {std::make_shared<DataTypeUInt16>(), \"port\"},\n+            {maybe_make_nullable(std::make_shared<DataTypeInt64>()), \"status\"},\n+            {maybe_make_nullable(std::make_shared<DataTypeString>()), \"error\"},\n+            {std::make_shared<DataTypeUInt64>(), \"num_hosts_remaining\"},\n+            {std::make_shared<DataTypeUInt64>(), \"num_hosts_active\"},\n+        };\n+    }\n }\n \n DDLQueryStatusSource::DDLQueryStatusSource(\n@@ -261,7 +296,7 @@ DDLQueryStatusSource::DDLQueryStatusSource(\n     if (hosts_to_wait)\n     {\n         waiting_hosts = NameSet(hosts_to_wait->begin(), hosts_to_wait->end());\n-        by_hostname = false;\n+        is_replicated_database = true;\n     }\n     else\n     {\n@@ -277,7 +312,7 @@ std::pair<String, UInt16> DDLQueryStatusSource::parseHostAndPort(const String &\n {\n     String host = host_id;\n     UInt16 port = 0;\n-    if (by_hostname)\n+    if (!is_replicated_database)\n     {\n         auto host_and_port = Cluster::Address::fromString(host_id);\n         host = host_and_port.first;\n@@ -286,6 +321,43 @@ std::pair<String, UInt16> DDLQueryStatusSource::parseHostAndPort(const String &\n     return {host, port};\n }\n \n+Chunk DDLQueryStatusSource::generateChunkWithUnfinishedHosts() const\n+{\n+    NameSet unfinished_hosts = waiting_hosts;\n+    for (const auto & host_id : finished_hosts)\n+        unfinished_hosts.erase(host_id);\n+\n+    NameSet active_hosts_set = NameSet{current_active_hosts.begin(), current_active_hosts.end()};\n+\n+    /// Query is not finished on the rest hosts, so fill the corresponding rows with NULLs.\n+    MutableColumns columns = output.getHeader().cloneEmptyColumns();\n+    for (const String & host_id : unfinished_hosts)\n+    {\n+        size_t num = 0;\n+        if (is_replicated_database)\n+        {\n+            auto [shard, replica] = DatabaseReplicated::parseFullReplicaName(host_id);\n+            columns[num++]->insert(shard);\n+            columns[num++]->insert(replica);\n+            if (active_hosts_set.contains(host_id))\n+                columns[num++]->insert(IN_PROGRESS);\n+            else\n+                columns[num++]->insert(QUEUED);\n+        }\n+        else\n+        {\n+            auto [host, port] = parseHostAndPort(host_id);\n+            columns[num++]->insert(host);\n+            columns[num++]->insert(port);\n+            columns[num++]->insert(Field{});\n+            columns[num++]->insert(Field{});\n+        }\n+        columns[num++]->insert(unfinished_hosts.size());\n+        columns[num++]->insert(current_active_hosts.size());\n+    }\n+    return Chunk(std::move(columns), unfinished_hosts.size());\n+}\n+\n Chunk DDLQueryStatusSource::generate()\n {\n     bool all_hosts_finished = num_hosts_finished >= waiting_hosts.size();\n@@ -296,6 +368,10 @@ Chunk DDLQueryStatusSource::generate()\n     if (all_hosts_finished || timeout_exceeded)\n         return {};\n \n+    String node_to_wait = \"finished\";\n+    if (is_replicated_database && context->getSettingsRef().database_replicated_enforce_synchronous_settings)\n+        node_to_wait = \"synced\";\n+\n     auto zookeeper = context->getZooKeeper();\n     size_t try_number = 0;\n \n@@ -320,30 +396,16 @@ Chunk DDLQueryStatusSource::generate()\n                     first_exception = std::make_unique<Exception>(\n                         fmt::format(msg_format, node_path, timeout_seconds, num_unfinished_hosts, num_active_hosts),\n                         ErrorCodes::TIMEOUT_EXCEEDED);\n+\n+                /// For Replicated database print a list of unfinished hosts as well. Will return empty block on next iteration.\n+                if (is_replicated_database)\n+                    return generateChunkWithUnfinishedHosts();\n                 return {};\n             }\n \n             LOG_INFO(log, msg_format, node_path, timeout_seconds, num_unfinished_hosts, num_active_hosts);\n \n-            NameSet unfinished_hosts = waiting_hosts;\n-            for (const auto & host_id : finished_hosts)\n-                unfinished_hosts.erase(host_id);\n-\n-            /// Query is not finished on the rest hosts, so fill the corresponding rows with NULLs.\n-            MutableColumns columns = output.getHeader().cloneEmptyColumns();\n-            for (const String & host_id : unfinished_hosts)\n-            {\n-                auto [host, port] = parseHostAndPort(host_id);\n-                size_t num = 0;\n-                columns[num++]->insert(host);\n-                if (by_hostname)\n-                    columns[num++]->insert(port);\n-                columns[num++]->insert(Field{});\n-                columns[num++]->insert(Field{});\n-                columns[num++]->insert(num_unfinished_hosts);\n-                columns[num++]->insert(num_active_hosts);\n-            }\n-            return Chunk(std::move(columns), unfinished_hosts.size());\n+            return generateChunkWithUnfinishedHosts();\n         }\n \n         if (num_hosts_finished != 0 || try_number != 0)\n@@ -365,7 +427,7 @@ Chunk DDLQueryStatusSource::generate()\n             return {};\n         }\n \n-        Strings new_hosts = getNewAndUpdate(getChildrenAllowNoNode(zookeeper, fs::path(node_path) / \"finished\"));\n+        Strings new_hosts = getNewAndUpdate(getChildrenAllowNoNode(zookeeper, fs::path(node_path) / node_to_wait));\n         ++try_number;\n         if (new_hosts.empty())\n             continue;\n@@ -376,17 +438,27 @@ Chunk DDLQueryStatusSource::generate()\n         for (const String & host_id : new_hosts)\n         {\n             ExecutionStatus status(-1, \"Cannot obtain error message\");\n+\n+            if (node_to_wait == \"finished\")\n             {\n                 String status_data;\n                 if (zookeeper->tryGet(fs::path(node_path) / \"finished\" / host_id, status_data))\n                     status.tryDeserializeText(status_data);\n             }\n+            else\n+            {\n+                status = ExecutionStatus{0};\n+            }\n \n-            auto [host, port] = parseHostAndPort(host_id);\n \n             if (status.code != 0 && !first_exception\n                 && context->getSettingsRef().distributed_ddl_output_mode != DistributedDDLOutputMode::NEVER_THROW)\n             {\n+                /// Replicated database retries in case of error, it should not write error status.\n+                if (is_replicated_database)\n+                    throw Exception(ErrorCodes::LOGICAL_ERROR, \"There was an error on {}: {} (probably it's a bug)\", host_id, status.message);\n+\n+                auto [host, port] = parseHostAndPort(host_id);\n                 first_exception = std::make_unique<Exception>(\n                     fmt::format(\"There was an error on [{}:{}]: {}\", host, port, status.message), status.code);\n             }\n@@ -394,11 +466,23 @@ Chunk DDLQueryStatusSource::generate()\n             ++num_hosts_finished;\n \n             size_t num = 0;\n-            columns[num++]->insert(host);\n-            if (by_hostname)\n+            if (is_replicated_database)\n+            {\n+                if (status.code != 0)\n+                    throw Exception(ErrorCodes::LOGICAL_ERROR, \"There was an error on {}: {} (probably it's a bug)\", host_id, status.message);\n+                auto [shard, replica] = DatabaseReplicated::parseFullReplicaName(host_id);\n+                columns[num++]->insert(shard);\n+                columns[num++]->insert(replica);\n+                columns[num++]->insert(OK);\n+            }\n+            else\n+            {\n+                auto [host, port] = parseHostAndPort(host_id);\n+                columns[num++]->insert(host);\n                 columns[num++]->insert(port);\n-            columns[num++]->insert(status.code);\n-            columns[num++]->insert(status.message);\n+                columns[num++]->insert(status.code);\n+                columns[num++]->insert(status.message);\n+            }\n             columns[num++]->insert(waiting_hosts.size() - num_hosts_finished);\n             columns[num++]->insert(current_active_hosts.size());\n         }\n@@ -464,4 +548,26 @@ Strings DDLQueryStatusSource::getNewAndUpdate(const Strings & current_list_of_fi\n }\n \n \n+bool maybeRemoveOnCluster(const ASTPtr & query_ptr, ContextPtr context)\n+{\n+    const auto * query = dynamic_cast<const ASTQueryWithTableAndOutput *>(query_ptr.get());\n+    if (!query || !query->table)\n+        return false;\n+\n+    String database_name = query->getDatabase();\n+    if (database_name.empty())\n+        database_name = context->getCurrentDatabase();\n+\n+    auto * query_on_cluster = dynamic_cast<ASTQueryWithOnCluster *>(query_ptr.get());\n+    if (database_name != query_on_cluster->cluster)\n+        return false;\n+\n+    auto db = DatabaseCatalog::instance().tryGetDatabase(database_name);\n+    if (!db || db->getEngineName() != \"Replicated\")\n+        return false;\n+\n+    query_on_cluster->cluster.clear();\n+    return true;\n+}\n+\n }\ndiff --git a/src/Interpreters/executeDDLQueryOnCluster.h b/src/Interpreters/executeDDLQueryOnCluster.h\nindex 3004fe2ff2e6..8df199f0ede4 100644\n--- a/src/Interpreters/executeDDLQueryOnCluster.h\n+++ b/src/Interpreters/executeDDLQueryOnCluster.h\n@@ -45,4 +45,6 @@ BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr, ContextPtr context, c\n BlockIO getDistributedDDLStatus(\n     const String & node_path, const DDLLogEntry & entry, ContextPtr context, const std::optional<Strings> & hosts_to_wait = {});\n \n+bool maybeRemoveOnCluster(const ASTPtr & query_ptr, ContextPtr context);\n+\n }\ndiff --git a/src/Interpreters/loadMetadata.cpp b/src/Interpreters/loadMetadata.cpp\nindex 15d4f7929f87..9ac076b99c5a 100644\n--- a/src/Interpreters/loadMetadata.cpp\n+++ b/src/Interpreters/loadMetadata.cpp\n@@ -38,6 +38,7 @@ static void executeCreateQuery(\n     ContextMutablePtr context,\n     const String & database,\n     const String & file_name,\n+    bool create,\n     bool has_force_restore_data_flag)\n {\n     ParserCreateQuery parser;\n@@ -49,8 +50,11 @@ static void executeCreateQuery(\n \n     InterpreterCreateQuery interpreter(ast, context);\n     interpreter.setInternal(true);\n-    interpreter.setForceAttach(true);\n-    interpreter.setForceRestoreData(has_force_restore_data_flag);\n+    if (!create)\n+    {\n+        interpreter.setForceAttach(true);\n+        interpreter.setForceRestoreData(has_force_restore_data_flag);\n+    }\n     interpreter.setLoadDatabaseWithoutTables(true);\n     interpreter.execute();\n }\n@@ -86,7 +90,7 @@ static void loadDatabase(\n \n     try\n     {\n-        executeCreateQuery(database_attach_query, context, database, database_metadata_file, force_restore_data);\n+        executeCreateQuery(database_attach_query, context, database, database_metadata_file, /* create */ true, force_restore_data);\n     }\n     catch (Exception & e)\n     {\n@@ -173,7 +177,8 @@ void loadMetadata(ContextMutablePtr context, const String & default_database_nam\n         loaded_databases.insert({name, DatabaseCatalog::instance().getDatabase(name)});\n     }\n \n-    TablesLoader loader{context, std::move(loaded_databases), has_force_restore_data_flag, /* force_attach */ true};\n+    auto mode = getLoadingStrictnessLevel(/* attach */ true, /* force_attach */ true, has_force_restore_data_flag);\n+    TablesLoader loader{context, std::move(loaded_databases), mode};\n     loader.loadTables();\n     loader.startupTables();\n \n@@ -207,7 +212,7 @@ static void loadSystemDatabaseImpl(ContextMutablePtr context, const String & dat\n         database_create_query += database_name;\n         database_create_query += \" ENGINE=\";\n         database_create_query += default_engine;\n-        executeCreateQuery(database_create_query, context, database_name, \"<no file>\", true);\n+        executeCreateQuery(database_create_query, context, database_name, \"<no file>\", true, true);\n     }\n }\n \n@@ -315,7 +320,7 @@ void maybeConvertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const Datab\n         {\n             {DatabaseCatalog::SYSTEM_DATABASE, DatabaseCatalog::instance().getSystemDatabase()},\n         };\n-        TablesLoader loader{context, databases, /* force_restore */ true, /* force_attach */ true};\n+        TablesLoader loader{context, databases, LoadingStrictnessLevel::FORCE_RESTORE};\n         loader.loadTables();\n \n         /// Will startup tables usual way\n@@ -331,7 +336,7 @@ void maybeConvertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const Datab\n void startupSystemTables()\n {\n     ThreadPool pool;\n-    DatabaseCatalog::instance().getSystemDatabase()->startupTables(pool, /* force_restore */ true, /* force_attach */ true);\n+    DatabaseCatalog::instance().getSystemDatabase()->startupTables(pool, LoadingStrictnessLevel::FORCE_RESTORE);\n }\n \n void loadMetadataSystem(ContextMutablePtr context)\n@@ -346,7 +351,7 @@ void loadMetadataSystem(ContextMutablePtr context)\n         {DatabaseCatalog::INFORMATION_SCHEMA, DatabaseCatalog::instance().getDatabase(DatabaseCatalog::INFORMATION_SCHEMA)},\n         {DatabaseCatalog::INFORMATION_SCHEMA_UPPERCASE, DatabaseCatalog::instance().getDatabase(DatabaseCatalog::INFORMATION_SCHEMA_UPPERCASE)},\n     };\n-    TablesLoader loader{context, databases, /* force_restore */ true, /* force_attach */ true};\n+    TablesLoader loader{context, databases, LoadingStrictnessLevel::FORCE_RESTORE};\n     loader.loadTables();\n     /// Will startup tables in system database after all databases are loaded.\n }\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 90b516320008..7e36bafa34f7 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -41,6 +41,7 @@\n #include <Storages/Freeze.h>\n \n #include <Databases/DatabaseOnDisk.h>\n+#include <Databases/DatabaseReplicated.h>\n \n #include <Parsers/formatAST.h>\n #include <Parsers/parseQuery.h>\n@@ -1112,19 +1113,18 @@ void StorageReplicatedMergeTree::checkTableStructure(const String & zookeeper_pr\n     }\n }\n \n-void StorageReplicatedMergeTree::setTableStructure(\n+void StorageReplicatedMergeTree::setTableStructure(const StorageID & table_id, const ContextPtr & local_context,\n     ColumnsDescription new_columns, const ReplicatedMergeTreeTableMetadata::Diff & metadata_diff)\n {\n     StorageInMemoryMetadata old_metadata = getInMemoryMetadata();\n-    StorageInMemoryMetadata new_metadata = metadata_diff.getNewMetadata(new_columns, getContext(), old_metadata);\n+    StorageInMemoryMetadata new_metadata = metadata_diff.getNewMetadata(new_columns, local_context, old_metadata);\n \n     /// Even if the primary/sorting/partition keys didn't change we must reinitialize it\n     /// because primary/partition key column types might have changed.\n     checkTTLExpressions(new_metadata, old_metadata);\n     setProperties(new_metadata, old_metadata);\n \n-    auto table_id = getStorageID();\n-    DatabaseCatalog::instance().getDatabase(table_id.database_name)->alterTable(getContext(), table_id, new_metadata);\n+    DatabaseCatalog::instance().getDatabase(table_id.database_name)->alterTable(local_context, table_id, new_metadata);\n }\n \n \n@@ -4733,7 +4733,31 @@ bool StorageReplicatedMergeTree::executeMetadataAlter(const StorageReplicatedMer\n     requests.emplace_back(zkutil::makeSetRequest(fs::path(replica_path) / \"columns\", entry.columns_str, -1));\n     requests.emplace_back(zkutil::makeSetRequest(fs::path(replica_path) / \"metadata\", entry.metadata_str, -1));\n \n-    zookeeper->multi(requests);\n+    auto table_id = getStorageID();\n+    auto alter_context = getContext();\n+\n+    auto database = DatabaseCatalog::instance().getDatabase(table_id.database_name);\n+    bool is_in_replicated_database = database->getEngineName() == \"Replicated\";\n+\n+    if (is_in_replicated_database)\n+    {\n+        auto mutable_alter_context = Context::createCopy(getContext());\n+        const auto * replicated = dynamic_cast<const DatabaseReplicated *>(database.get());\n+        mutable_alter_context->makeQueryContext();\n+        auto alter_txn = std::make_shared<ZooKeeperMetadataTransaction>(zookeeper, replicated->getZooKeeperPath(),\n+                                                                       /* is_initial_query */ false, /* task_zk_path */ \"\");\n+        mutable_alter_context->initZooKeeperMetadataTransaction(alter_txn);\n+        alter_context = mutable_alter_context;\n+\n+        for (auto & op : requests)\n+            alter_txn->addOp(std::move(op));\n+        requests.clear();\n+        /// Requests will be executed by database in setTableStructure\n+    }\n+    else\n+    {\n+        zookeeper->multi(requests);\n+    }\n \n     {\n         auto table_lock_holder = lockForShare(RWLockImpl::NO_QUERY, getSettings()->lock_acquire_timeout_for_background_operations);\n@@ -4741,13 +4765,14 @@ bool StorageReplicatedMergeTree::executeMetadataAlter(const StorageReplicatedMer\n         LOG_INFO(log, \"Metadata changed in ZooKeeper. Applying changes locally.\");\n \n         auto metadata_diff = ReplicatedMergeTreeTableMetadata(*this, getInMemoryMetadataPtr()).checkAndFindDiff(metadata_from_entry, getInMemoryMetadataPtr()->getColumns(), getContext());\n-        setTableStructure(std::move(columns_from_entry), metadata_diff);\n+        setTableStructure(table_id, alter_context, std::move(columns_from_entry), metadata_diff);\n         metadata_version = entry.alter_version;\n \n         LOG_INFO(log, \"Applied changes to the metadata of the table. Current metadata version: {}\", metadata_version);\n     }\n \n     /// This transaction may not happen, but it's OK, because on the next retry we will eventually create/update this node\n+    /// TODO Maybe do in in one transaction for Replicated database?\n     zookeeper->createOrUpdate(fs::path(replica_path) / \"metadata_version\", std::to_string(metadata_version), zkutil::CreateMode::Persistent);\n \n     return true;\ndiff --git a/src/Storages/StorageReplicatedMergeTree.h b/src/Storages/StorageReplicatedMergeTree.h\nindex c6b0a7f47fcc..3f03fb70f7a5 100644\n--- a/src/Storages/StorageReplicatedMergeTree.h\n+++ b/src/Storages/StorageReplicatedMergeTree.h\n@@ -491,7 +491,8 @@ class StorageReplicatedMergeTree final : public MergeTreeData\n \n     /// A part of ALTER: apply metadata changes only (data parts are altered separately).\n     /// Must be called under IStorage::lockForAlter() lock.\n-    void setTableStructure(ColumnsDescription new_columns, const ReplicatedMergeTreeTableMetadata::Diff & metadata_diff);\n+    void setTableStructure(const StorageID & table_id, const ContextPtr & local_context,\n+                           ColumnsDescription new_columns, const ReplicatedMergeTreeTableMetadata::Diff & metadata_diff);\n \n     /** Check that the set of parts corresponds to that in ZK (/replicas/me/parts/).\n       * If any parts described in ZK are not locally, throw an exception.\n",
  "test_patch": "diff --git a/tests/clickhouse-test b/tests/clickhouse-test\nindex 03ade3f66c8e..71f603a69ca2 100755\n--- a/tests/clickhouse-test\n+++ b/tests/clickhouse-test\n@@ -55,8 +55,6 @@ MESSAGES_TO_RETRY = [\n     \"ConnectionPoolWithFailover: Connection failed at try\",\n     \"DB::Exception: New table appeared in database being dropped or detached. Try again\",\n     \"is already started to be removing by another replica right now\",\n-    \"DB::Exception: Cannot enqueue query\",\n-    \"is executing longer than distributed_ddl_task_timeout\",  # FIXME\n ]\n \n MAX_RETRIES = 3\ndiff --git a/tests/config/users.d/database_replicated.xml b/tests/config/users.d/database_replicated.xml\nindex 279591494c19..2b96e7418b61 100644\n--- a/tests/config/users.d/database_replicated.xml\n+++ b/tests/config/users.d/database_replicated.xml\n@@ -6,7 +6,7 @@\n             <database_replicated_initial_query_timeout_sec>120</database_replicated_initial_query_timeout_sec>\n             <distributed_ddl_task_timeout>120</distributed_ddl_task_timeout>\n             <database_replicated_always_detach_permanently>1</database_replicated_always_detach_permanently>\n-            <distributed_ddl_entry_format_version>2</distributed_ddl_entry_format_version>\n+            <database_replicated_enforce_synchronous_settings>1</database_replicated_enforce_synchronous_settings>\n         </default>\n     </profiles>\n </clickhouse>\ndiff --git a/tests/integration/test_distributed_ddl/test.py b/tests/integration/test_distributed_ddl/test.py\nindex 85d0a5f0999d..065795b55ebd 100755\n--- a/tests/integration/test_distributed_ddl/test.py\n+++ b/tests/integration/test_distributed_ddl/test.py\n@@ -49,6 +49,7 @@ def test_default_database(test_cluster):\n     test_cluster.ddl_check_query(\n         instance,\n         \"CREATE TABLE null ON CLUSTER 'cluster2' (s String DEFAULT 'escape\\t\\nme') ENGINE = Null\",\n+        settings={\"distributed_ddl_entry_format_version\": 2},\n     )\n \n     contents = instance.query(\n@@ -57,7 +58,9 @@ def test_default_database(test_cluster):\n     assert TSV(contents) == TSV(\"ch1\\tdefault\\nch2\\ttest2\\nch3\\tdefault\\nch4\\ttest2\\n\")\n \n     test_cluster.ddl_check_query(\n-        instance, \"DROP TABLE IF EXISTS null ON CLUSTER cluster2\"\n+        instance,\n+        \"DROP TABLE IF EXISTS null ON CLUSTER cluster2\",\n+        settings={\"distributed_ddl_entry_format_version\": 2},\n     )\n     test_cluster.ddl_check_query(\n         instance, \"DROP DATABASE IF EXISTS test2 ON CLUSTER 'cluster'\"\ndiff --git a/tests/integration/test_distributed_ddl_on_cross_replication/configs/settings.xml b/tests/integration/test_distributed_ddl_on_cross_replication/configs/settings.xml\nnew file mode 100644\nindex 000000000000..2387e2661e4c\n--- /dev/null\n+++ b/tests/integration/test_distributed_ddl_on_cross_replication/configs/settings.xml\n@@ -0,0 +1,7 @@\n+<clickhouse>\n+    <profiles>\n+        <default>\n+            <distributed_ddl_entry_format_version>2</distributed_ddl_entry_format_version>\n+        </default>\n+    </profiles>\n+</clickhouse>\n\\ No newline at end of file\ndiff --git a/tests/integration/test_distributed_ddl_on_cross_replication/test.py b/tests/integration/test_distributed_ddl_on_cross_replication/test.py\nindex b89091d4034b..2b710b4a3e3c 100644\n--- a/tests/integration/test_distributed_ddl_on_cross_replication/test.py\n+++ b/tests/integration/test_distributed_ddl_on_cross_replication/test.py\n@@ -7,18 +7,21 @@\n node1 = cluster.add_instance(\n     \"node1\",\n     main_configs=[\"configs/remote_servers.xml\"],\n+    user_configs=[\"configs/settings.xml\"],\n     with_zookeeper=True,\n     macros={\"shard\": 1, \"replica\": 1, \"shard_bk\": 3, \"replica_bk\": 2},\n )\n node2 = cluster.add_instance(\n     \"node2\",\n     main_configs=[\"configs/remote_servers.xml\"],\n+    user_configs=[\"configs/settings.xml\"],\n     with_zookeeper=True,\n     macros={\"shard\": 2, \"replica\": 1, \"shard_bk\": 1, \"replica_bk\": 2},\n )\n node3 = cluster.add_instance(\n     \"node3\",\n     main_configs=[\"configs/remote_servers.xml\"],\n+    user_configs=[\"configs/settings.xml\"],\n     with_zookeeper=True,\n     macros={\"shard\": 3, \"replica\": 1, \"shard_bk\": 2, \"replica_bk\": 2},\n )\ndiff --git a/tests/integration/test_replicated_database/test.py b/tests/integration/test_replicated_database/test.py\nindex 11ca0d2f9620..f716fac85082 100644\n--- a/tests/integration/test_replicated_database/test.py\n+++ b/tests/integration/test_replicated_database/test.py\n@@ -3,6 +3,7 @@\n import time\n import re\n import pytest\n+import threading\n \n from helpers.cluster import ClickHouseCluster\n from helpers.test_tools import assert_eq_with_retry, assert_logs_contain\n@@ -417,7 +418,7 @@ def test_alters_from_different_replicas(started_cluster):\n         \"distributed_ddl_task_timeout\": 5,\n         \"distributed_ddl_output_mode\": \"null_status_on_timeout\",\n     }\n-    assert \"shard1|replica2\\t\\\\N\\t\\\\N\" in main_node.query(\n+    assert \"shard1\\treplica2\\tQUEUED\\t\" in main_node.query(\n         \"ALTER TABLE testdb.concurrent_test ADD COLUMN Added2 UInt32;\",\n         settings=settings,\n     )\n@@ -425,7 +426,7 @@ def test_alters_from_different_replicas(started_cluster):\n         \"distributed_ddl_task_timeout\": 5,\n         \"distributed_ddl_output_mode\": \"never_throw\",\n     }\n-    assert \"shard1|replica2\\t\\\\N\\t\\\\N\" in competing_node.query(\n+    assert \"shard1\\treplica2\\tQUEUED\\t\" in competing_node.query(\n         \"ALTER TABLE testdb.concurrent_test ADD COLUMN Added1 UInt32 AFTER Added0;\",\n         settings=settings,\n     )\n@@ -495,11 +496,11 @@ def test_alters_from_different_replicas(started_cluster):\n     )\n     res = main_node.query(\"ALTER TABLE testdb.concurrent_test DELETE WHERE UserID % 2\")\n     assert (\n-        \"shard1|replica1\" in res\n-        and \"shard1|replica2\" in res\n-        and \"shard1|replica3\" in res\n+        \"shard1\\treplica1\\tOK\" in res\n+        and \"shard1\\treplica2\\tOK\" in res\n+        and \"shard1\\treplica3\\tOK\" in res\n     )\n-    assert \"shard2|replica1\" in res and \"shard2|replica2\" in res\n+    assert \"shard2\\treplica1\\tOK\" in res and \"shard2\\treplica2\\tOK\" in res\n \n     expected = (\n         \"1\\t1\\tmain_node\\n\"\n@@ -553,65 +554,76 @@ def test_alters_from_different_replicas(started_cluster):\n     snapshot_recovering_node.query(\"DROP DATABASE testdb SYNC\")\n \n \n-def test_recover_staled_replica(started_cluster):\n+def create_some_tables(db):\n+    settings = {\"distributed_ddl_task_timeout\": 0}\n     main_node.query(\n-        \"CREATE DATABASE recover ENGINE = Replicated('/clickhouse/databases/recover', 'shard1', 'replica1');\"\n-    )\n-    started_cluster.get_kazoo_client(\"zoo1\").set(\n-        \"/clickhouse/databases/recover/logs_to_keep\", b\"10\"\n+        \"CREATE TABLE {}.t1 (n int) ENGINE=Memory\".format(db), settings=settings\n     )\n     dummy_node.query(\n-        \"CREATE DATABASE recover ENGINE = Replicated('/clickhouse/databases/recover', 'shard1', 'replica2');\"\n-    )\n-\n-    settings = {\"distributed_ddl_task_timeout\": 0}\n-    main_node.query(\"CREATE TABLE recover.t1 (n int) ENGINE=Memory\", settings=settings)\n-    dummy_node.query(\n-        \"CREATE TABLE recover.t2 (s String) ENGINE=Memory\", settings=settings\n+        \"CREATE TABLE {}.t2 (s String) ENGINE=Memory\".format(db), settings=settings\n     )\n     main_node.query(\n-        \"CREATE TABLE recover.mt1 (n int) ENGINE=MergeTree order by n\",\n+        \"CREATE TABLE {}.mt1 (n int) ENGINE=MergeTree order by n\".format(db),\n         settings=settings,\n     )\n     dummy_node.query(\n-        \"CREATE TABLE recover.mt2 (n int) ENGINE=MergeTree order by n\",\n+        \"CREATE TABLE {}.mt2 (n int) ENGINE=MergeTree order by n\".format(db),\n         settings=settings,\n     )\n     main_node.query(\n-        \"CREATE TABLE recover.rmt1 (n int) ENGINE=ReplicatedMergeTree order by n\",\n+        \"CREATE TABLE {}.rmt1 (n int) ENGINE=ReplicatedMergeTree order by n\".format(db),\n         settings=settings,\n     )\n     dummy_node.query(\n-        \"CREATE TABLE recover.rmt2 (n int) ENGINE=ReplicatedMergeTree order by n\",\n+        \"CREATE TABLE {}.rmt2 (n int) ENGINE=ReplicatedMergeTree order by n\".format(db),\n         settings=settings,\n     )\n     main_node.query(\n-        \"CREATE TABLE recover.rmt3 (n int) ENGINE=ReplicatedMergeTree order by n\",\n+        \"CREATE TABLE {}.rmt3 (n int) ENGINE=ReplicatedMergeTree order by n\".format(db),\n         settings=settings,\n     )\n     dummy_node.query(\n-        \"CREATE TABLE recover.rmt5 (n int) ENGINE=ReplicatedMergeTree order by n\",\n+        \"CREATE TABLE {}.rmt5 (n int) ENGINE=ReplicatedMergeTree order by n\".format(db),\n         settings=settings,\n     )\n     main_node.query(\n-        \"CREATE MATERIALIZED VIEW recover.mv1 (n int) ENGINE=ReplicatedMergeTree order by n AS SELECT n FROM recover.rmt1\",\n+        \"CREATE MATERIALIZED VIEW {}.mv1 (n int) ENGINE=ReplicatedMergeTree order by n AS SELECT n FROM recover.rmt1\".format(\n+            db\n+        ),\n         settings=settings,\n     )\n     dummy_node.query(\n-        \"CREATE MATERIALIZED VIEW recover.mv2 (n int) ENGINE=ReplicatedMergeTree order by n  AS SELECT n FROM recover.rmt2\",\n+        \"CREATE MATERIALIZED VIEW {}.mv2 (n int) ENGINE=ReplicatedMergeTree order by n  AS SELECT n FROM recover.rmt2\".format(\n+            db\n+        ),\n         settings=settings,\n     )\n     main_node.query(\n-        \"CREATE DICTIONARY recover.d1 (n int DEFAULT 0, m int DEFAULT 1) PRIMARY KEY n \"\n+        \"CREATE DICTIONARY {}.d1 (n int DEFAULT 0, m int DEFAULT 1) PRIMARY KEY n \"\n         \"SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'rmt1' PASSWORD '' DB 'recover')) \"\n-        \"LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT())\"\n+        \"LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT())\".format(db)\n     )\n     dummy_node.query(\n-        \"CREATE DICTIONARY recover.d2 (n int DEFAULT 0, m int DEFAULT 1) PRIMARY KEY n \"\n+        \"CREATE DICTIONARY {}.d2 (n int DEFAULT 0, m int DEFAULT 1) PRIMARY KEY n \"\n         \"SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'rmt2' PASSWORD '' DB 'recover')) \"\n-        \"LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT())\"\n+        \"LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT())\".format(db)\n     )\n \n+\n+def test_recover_staled_replica(started_cluster):\n+    main_node.query(\n+        \"CREATE DATABASE recover ENGINE = Replicated('/clickhouse/databases/recover', 'shard1', 'replica1');\"\n+    )\n+    started_cluster.get_kazoo_client(\"zoo1\").set(\n+        \"/clickhouse/databases/recover/logs_to_keep\", b\"10\"\n+    )\n+    dummy_node.query(\n+        \"CREATE DATABASE recover ENGINE = Replicated('/clickhouse/databases/recover', 'shard1', 'replica2');\"\n+    )\n+\n+    settings = {\"distributed_ddl_task_timeout\": 0}\n+    create_some_tables(\"recover\")\n+\n     for table in [\"t1\", \"t2\", \"mt1\", \"mt2\", \"rmt1\", \"rmt2\", \"rmt3\", \"rmt5\"]:\n         main_node.query(\"INSERT INTO recover.{} VALUES (42)\".format(table))\n     for table in [\"t1\", \"t2\", \"mt1\", \"mt2\"]:\n@@ -867,3 +879,106 @@ def test_sync_replica(started_cluster):\n     )\n     assert lp1 == max_lp\n     assert lp2 == max_lp\n+\n+\n+def test_force_synchronous_settings(started_cluster):\n+    main_node.query(\n+        \"CREATE DATABASE test_force_synchronous_settings ENGINE = Replicated('/clickhouse/databases/test2', 'shard1', 'replica1');\"\n+    )\n+    dummy_node.query(\n+        \"CREATE DATABASE test_force_synchronous_settings ENGINE = Replicated('/clickhouse/databases/test2', 'shard1', 'replica2');\"\n+    )\n+    snapshotting_node.query(\n+        \"CREATE DATABASE test_force_synchronous_settings ENGINE = Replicated('/clickhouse/databases/test2', 'shard2', 'replica1');\"\n+    )\n+    main_node.query(\n+        \"CREATE TABLE test_force_synchronous_settings.t (n int) ENGINE=ReplicatedMergeTree('/test/same/path/{shard}', '{replica}') ORDER BY tuple()\"\n+    )\n+    main_node.query(\n+        \"INSERT INTO test_force_synchronous_settings.t SELECT * FROM numbers(10)\"\n+    )\n+    snapshotting_node.query(\n+        \"INSERT INTO test_force_synchronous_settings.t SELECT * FROM numbers(10)\"\n+    )\n+    snapshotting_node.query(\n+        \"SYSTEM SYNC DATABASE REPLICA test_force_synchronous_settings\"\n+    )\n+    dummy_node.query(\"SYSTEM SYNC DATABASE REPLICA test_force_synchronous_settings\")\n+\n+    snapshotting_node.query(\"SYSTEM STOP MERGES test_force_synchronous_settings.t\")\n+\n+    def start_merges_func():\n+        time.sleep(5)\n+        snapshotting_node.query(\"SYSTEM START MERGES test_force_synchronous_settings.t\")\n+\n+    start_merges_thread = threading.Thread(target=start_merges_func)\n+    start_merges_thread.start()\n+\n+    settings = {\n+        \"mutations_sync\": 2,\n+        \"database_replicated_enforce_synchronous_settings\": 1,\n+    }\n+    main_node.query(\n+        \"ALTER TABLE test_force_synchronous_settings.t UPDATE n = n * 10 WHERE 1\",\n+        settings=settings,\n+    )\n+    assert \"10\\t450\\n\" == snapshotting_node.query(\n+        \"SELECT count(), sum(n) FROM test_force_synchronous_settings.t\"\n+    )\n+    start_merges_thread.join()\n+\n+    def select_func():\n+        dummy_node.query(\n+            \"SELECT sleepEachRow(1) FROM test_force_synchronous_settings.t\"\n+        )\n+\n+    select_thread = threading.Thread(target=select_func)\n+    select_thread.start()\n+\n+    settings = {\"database_replicated_enforce_synchronous_settings\": 1}\n+    snapshotting_node.query(\n+        \"DROP TABLE test_force_synchronous_settings.t SYNC\", settings=settings\n+    )\n+    main_node.query(\n+        \"CREATE TABLE test_force_synchronous_settings.t (n String) ENGINE=ReplicatedMergeTree('/test/same/path/{shard}', '{replica}') ORDER BY tuple()\"\n+    )\n+    select_thread.join()\n+\n+\n+def test_recover_digest_mismatch(started_cluster):\n+    main_node.query(\n+        \"CREATE DATABASE recover_digest_mismatch ENGINE = Replicated('/clickhouse/databases/recover_digest_mismatch', 'shard1', 'replica1');\"\n+    )\n+    dummy_node.query(\n+        \"CREATE DATABASE recover_digest_mismatch ENGINE = Replicated('/clickhouse/databases/recover_digest_mismatch', 'shard1', 'replica2');\"\n+    )\n+\n+    create_some_tables(\"recover_digest_mismatch\")\n+\n+    ways_to_corrupt_metadata = [\n+        f\"mv /var/lib/clickhouse/metadata/recover_digest_mismatch/t1.sql /var/lib/clickhouse/metadata/recover_digest_mismatch/m1.sql\",\n+        f\"sed --follow-symlinks -i 's/Int32/String/' /var/lib/clickhouse/metadata/recover_digest_mismatch/mv1.sql\",\n+        f\"rm -f /var/lib/clickhouse/metadata/recover_digest_mismatch/d1.sql\",\n+        # f\"rm -rf /var/lib/clickhouse/metadata/recover_digest_mismatch/\", # Directory already exists\n+        f\"rm -rf /var/lib/clickhouse/store\",\n+    ]\n+\n+    for command in ways_to_corrupt_metadata:\n+        need_remove_is_active_node = \"rm -rf\" in command\n+        dummy_node.stop_clickhouse(kill=not need_remove_is_active_node)\n+        dummy_node.exec_in_container([\"bash\", \"-c\", command])\n+        dummy_node.start_clickhouse()\n+\n+        query = (\n+            \"SELECT name, uuid, create_table_query FROM system.tables WHERE database='recover_digest_mismatch' AND name NOT LIKE '.inner_id.%' \"\n+            \"ORDER BY name SETTINGS show_table_uuid_in_table_create_query_if_not_nil=1\"\n+        )\n+        expected = main_node.query(query)\n+\n+        if \"rm -rf\" in command:\n+            # NOTE Otherwise it fails to recreate ReplicatedMergeTree table due to \"Replica already exists\"\n+            main_node.query(\n+                \"SYSTEM DROP REPLICA '2' FROM DATABASE recover_digest_mismatch\"\n+            )\n+\n+        assert_eq_with_retry(dummy_node, query, expected)\ndiff --git a/tests/queries/0_stateless/00993_system_parts_race_condition_drop_zookeeper.sh b/tests/queries/0_stateless/00993_system_parts_race_condition_drop_zookeeper.sh\nindex 55ef2edd42b0..dc01ce40398f 100755\n--- a/tests/queries/0_stateless/00993_system_parts_race_condition_drop_zookeeper.sh\n+++ b/tests/queries/0_stateless/00993_system_parts_race_condition_drop_zookeeper.sh\n@@ -58,7 +58,7 @@ function thread6()\n         $CLICKHOUSE_CLIENT -n -q \"DROP TABLE IF EXISTS alter_table_$REPLICA;\n             CREATE TABLE alter_table_$REPLICA (a UInt8, b Int16, c Float32, d String, e Array(UInt8), f Nullable(UUID), g Tuple(UInt8, UInt16)) ENGINE = ReplicatedMergeTree('/clickhouse/tables/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX/alter_table', 'r_$REPLICA') ORDER BY a PARTITION BY b % 10 SETTINGS old_parts_lifetime = 1, cleanup_delay_period = 0, cleanup_delay_period_random_add = 0;\";\n         sleep 0.$RANDOM;\n-        done\n+    done\n }\n \n # https://stackoverflow.com/questions/9954794/execute-a-shell-function-with-timeout\ndiff --git a/tests/queries/0_stateless/01111_create_drop_replicated_db_stress.reference b/tests/queries/0_stateless/01111_create_drop_replicated_db_stress.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/01111_create_drop_replicated_db_stress.sh b/tests/queries/0_stateless/01111_create_drop_replicated_db_stress.sh\nnew file mode 100755\nindex 000000000000..addf503e44aa\n--- /dev/null\n+++ b/tests/queries/0_stateless/01111_create_drop_replicated_db_stress.sh\n@@ -0,0 +1,108 @@\n+#!/usr/bin/env bash\n+# Tags: race, zookeeper, no-backward-compatibility-check\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+\n+function create_db()\n+{\n+    while true; do\n+        SHARD=$(($RANDOM % 2))\n+        REPLICA=$(($RANDOM % 2))\n+        SUFFIX=$(($RANDOM % 16))\n+        # Multiple database replicas on one server are actually not supported (until we have namespaces).\n+        # So CREATE TABLE queries will fail on all replicas except one. But it's still makes sense for a stress test.\n+        $CLICKHOUSE_CLIENT --allow_experimental_database_replicated=1 --query \\\n+        \"create database if not exists ${CLICKHOUSE_DATABASE}_repl_$SUFFIX engine=Replicated('/test/01111/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX', '$SHARD', '$REPLICA')\" \\\n+         2>&1| grep -Fa \"Exception: \" | grep -Fv \"REPLICA_IS_ALREADY_EXIST\" | grep -Fiv \"Will not try to start it up\" | \\\n+         grep -Fv \"Coordination::Exception\" | grep -Fv \"already contains some data and it does not look like Replicated database path\"\n+        sleep 0.$RANDOM\n+    done\n+}\n+\n+function drop_db()\n+{\n+    while true; do\n+        database=$($CLICKHOUSE_CLIENT -q \"select name from system.databases where name like '${CLICKHOUSE_DATABASE}%' order by rand() limit 1\")\n+        if [[ \"$database\" == \"$CLICKHOUSE_DATABASE\" ]]; then return; fi\n+        if [ -z \"$database\" ]; then return; fi\n+        $CLICKHOUSE_CLIENT -n --query \\\n+        \"drop database if exists $database\" 2>&1| grep -Fa \"Exception: \"\n+        sleep 0.$RANDOM\n+    done\n+}\n+\n+function sync_db()\n+{\n+    while true; do\n+        database=$($CLICKHOUSE_CLIENT -q \"select name from system.databases where name like '${CLICKHOUSE_DATABASE}%' order by rand() limit 1\")\n+        if [ -z \"$database\" ]; then return; fi\n+        $CLICKHOUSE_CLIENT --receive_timeout=1 -q \\\n+        \"system sync database replica $database\" 2>&1| grep -Fa \"Exception: \" | grep -Fv TIMEOUT_EXCEEDED | grep -Fv \"only with Replicated engine\" | grep -Fv UNKNOWN_DATABASE\n+        sleep 0.$RANDOM\n+    done\n+}\n+\n+function create_table()\n+{\n+    while true; do\n+        database=$($CLICKHOUSE_CLIENT -q \"select name from system.databases where name like '${CLICKHOUSE_DATABASE}%' order by rand() limit 1\")\n+        if [ -z \"$database\" ]; then return; fi\n+        $CLICKHOUSE_CLIENT --distributed_ddl_task_timeout=0 -q \\\n+        \"create table $database.rmt_$RANDOM (n int) engine=ReplicatedMergeTree order by tuple() -- suppress $CLICKHOUSE_TEST_ZOOKEEPER_PREFIX\" \\\n+        2>&1| grep -Fa \"Exception: \" | grep -Fv \"Macro 'uuid' and empty arguments\" | grep -Fv \"Cannot enqueue query\" | grep -Fv \"ZooKeeper session expired\" | grep -Fv UNKNOWN_DATABASE\n+        sleep 0.$RANDOM\n+    done\n+}\n+\n+function alter_table()\n+{\n+    while true; do\n+        table=$($CLICKHOUSE_CLIENT -q \"select database || '.' || name from system.tables where database like '${CLICKHOUSE_DATABASE}%' order by rand() limit 1\")\n+        if [ -z \"$table\" ]; then return; fi\n+        $CLICKHOUSE_CLIENT --distributed_ddl_task_timeout=0 -q \\\n+        \"alter table $table on cluster $database update n = n + (select max(n) from merge(REGEXP('${CLICKHOUSE_DATABASE}.*'), '.*')) where 1 settings allow_nondeterministic_mutations=1\" \\\n+        2>&1| grep -Fa \"Exception: \" | grep -Fv \"Cannot enqueue query\" | grep -Fv \"ZooKeeper session expired\" | grep -Fv UNKNOWN_DATABASE | grep -Fv UNKNOWN_TABLE | grep -Fv TABLE_IS_READ_ONLY\n+        sleep 0.$RANDOM\n+    done\n+}\n+\n+function insert()\n+{\n+    while true; do\n+        table=$($CLICKHOUSE_CLIENT -q \"select database || '.' || name from system.tables where database like '${CLICKHOUSE_DATABASE}%' order by rand() limit 1\")\n+        if [ -z \"$table\" ]; then return; fi\n+        $CLICKHOUSE_CLIENT -q \\\n+        \"insert into $table values ($RANDOM)\" 2>&1| grep -Fa \"Exception: \" | grep -Fv UNKNOWN_DATABASE | grep -Fv UNKNOWN_TABLE | grep -Fv TABLE_IS_READ_ONLY\n+    done\n+}\n+\n+\n+\n+export -f create_db\n+export -f drop_db\n+export -f sync_db\n+export -f create_table\n+export -f alter_table\n+export -f insert\n+\n+TIMEOUT=30\n+\n+timeout $TIMEOUT bash -c create_db &\n+timeout $TIMEOUT bash -c sync_db &\n+timeout $TIMEOUT bash -c create_table &\n+timeout $TIMEOUT bash -c alter_table &\n+timeout $TIMEOUT bash -c insert &\n+\n+sleep 1 # give other queries a head start\n+timeout $TIMEOUT bash -c drop_db &\n+\n+wait\n+\n+readarray -t databases_arr < <(${CLICKHOUSE_CLIENT} -q \"select name from system.databases where name like '${CLICKHOUSE_DATABASE}_%'\")\n+for db in \"${databases_arr[@]}\"\n+do\n+    $CLICKHOUSE_CLIENT -q \"drop database if exists $db\"\n+done\ndiff --git a/tests/queries/0_stateless/01152_cross_replication.sql b/tests/queries/0_stateless/01152_cross_replication.sql\nindex 60b2c34be07c..5d0134005394 100644\n--- a/tests/queries/0_stateless/01152_cross_replication.sql\n+++ b/tests/queries/0_stateless/01152_cross_replication.sql\n@@ -8,6 +8,8 @@ DROP TABLE IF EXISTS demo_loan_01568_dist;\n CREATE DATABASE shard_0;\n CREATE DATABASE shard_1;\n \n+CREATE TABLE demo_loan_01568 ON CLUSTER test_cluster_two_shards_different_databases ( `id` Int64 COMMENT 'id', `date_stat` Date COMMENT 'date of stat', `customer_no` String COMMENT 'customer no', `loan_principal` Float64 COMMENT 'loan principal' ) ENGINE=ReplacingMergeTree() ORDER BY id PARTITION BY toYYYYMM(date_stat); -- { serverError 48 }\n+SET distributed_ddl_entry_format_version = 2;\n CREATE TABLE demo_loan_01568 ON CLUSTER test_cluster_two_shards_different_databases ( `id` Int64 COMMENT 'id', `date_stat` Date COMMENT 'date of stat', `customer_no` String COMMENT 'customer no', `loan_principal` Float64 COMMENT 'loan principal' ) ENGINE=ReplacingMergeTree() ORDER BY id PARTITION BY toYYYYMM(date_stat); -- { serverError 371 }\n SET distributed_ddl_output_mode='throw';\n CREATE TABLE shard_0.demo_loan_01568 ON CLUSTER test_cluster_two_shards_different_databases ( `id` Int64 COMMENT 'id', `date_stat` Date COMMENT 'date of stat', `customer_no` String COMMENT 'customer no', `loan_principal` Float64 COMMENT 'loan principal' ) ENGINE=ReplacingMergeTree() ORDER BY id PARTITION BY toYYYYMM(date_stat);\ndiff --git a/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.reference b/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.reference\nindex bedf9e9a091c..4397810b68d7 100644\n--- a/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.reference\n+++ b/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.reference\n@@ -27,19 +27,19 @@ localhost\t9000\t57\tCode: 57. Error: Table default.never_throw already exists. (TA\n localhost\t9000\t0\t\t1\t0\n localhost\t1\t\\N\t\\N\t1\t0\n distributed_ddl_queue\n-2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.none ON CLUSTER test_shard_localhost (`n` int) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n-2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.none ON CLUSTER test_shard_localhost (`n` int) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t57\tCode: 57. DB::Error: Table default.none already exists. (TABLE_ALREADY_EXISTS)\t1\t1\n+2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.none ON CLUSTER test_shard_localhost (`n` Int32) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n+2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.none ON CLUSTER test_shard_localhost (`n` Int32) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t57\tCode: 57. DB::Error: Table default.none already exists. (TABLE_ALREADY_EXISTS)\t1\t1\n 2\tlocalhost\t9000\ttest_unavailable_shard\tDROP TABLE IF EXISTS default.none ON CLUSTER test_unavailable_shard\t1\tlocalhost\t1\tInactive\t\\N\t\\N\t\\N\t\\N\n 2\tlocalhost\t9000\ttest_unavailable_shard\tDROP TABLE IF EXISTS default.none ON CLUSTER test_unavailable_shard\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n-2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.throw ON CLUSTER test_shard_localhost (`n` int) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n-2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.throw ON CLUSTER test_shard_localhost (`n` int) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t57\tCode: 57. DB::Error: Table default.throw already exists. (TABLE_ALREADY_EXISTS)\t1\t1\n+2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.throw ON CLUSTER test_shard_localhost (`n` Int32) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n+2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.throw ON CLUSTER test_shard_localhost (`n` Int32) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t57\tCode: 57. DB::Error: Table default.throw already exists. (TABLE_ALREADY_EXISTS)\t1\t1\n 2\tlocalhost\t9000\ttest_unavailable_shard\tDROP TABLE IF EXISTS default.throw ON CLUSTER test_unavailable_shard\t1\tlocalhost\t1\tInactive\t\\N\t\\N\t\\N\t\\N\n 2\tlocalhost\t9000\ttest_unavailable_shard\tDROP TABLE IF EXISTS default.throw ON CLUSTER test_unavailable_shard\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n-2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.null_status ON CLUSTER test_shard_localhost (`n` int) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n-2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.null_status ON CLUSTER test_shard_localhost (`n` int) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t57\tCode: 57. DB::Error: Table default.null_status already exists. (TABLE_ALREADY_EXISTS)\t1\t1\n+2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.null_status ON CLUSTER test_shard_localhost (`n` Int32) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n+2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.null_status ON CLUSTER test_shard_localhost (`n` Int32) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t57\tCode: 57. DB::Error: Table default.null_status already exists. (TABLE_ALREADY_EXISTS)\t1\t1\n 2\tlocalhost\t9000\ttest_unavailable_shard\tDROP TABLE IF EXISTS default.null_status ON CLUSTER test_unavailable_shard\t1\tlocalhost\t1\tInactive\t\\N\t\\N\t\\N\t\\N\n 2\tlocalhost\t9000\ttest_unavailable_shard\tDROP TABLE IF EXISTS default.null_status ON CLUSTER test_unavailable_shard\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n-2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.never_throw ON CLUSTER test_shard_localhost (`n` int) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n-2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.never_throw ON CLUSTER test_shard_localhost (`n` int) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t57\tCode: 57. DB::Error: Table default.never_throw already exists. (TABLE_ALREADY_EXISTS)\t1\t1\n+2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.never_throw ON CLUSTER test_shard_localhost (`n` Int32) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\n+2\tlocalhost\t9000\ttest_shard_localhost\tCREATE TABLE default.never_throw ON CLUSTER test_shard_localhost (`n` Int32) ENGINE = Memory\t1\tlocalhost\t9000\tFinished\t57\tCode: 57. DB::Error: Table default.never_throw already exists. (TABLE_ALREADY_EXISTS)\t1\t1\n 2\tlocalhost\t9000\ttest_unavailable_shard\tDROP TABLE IF EXISTS default.never_throw ON CLUSTER test_unavailable_shard\t1\tlocalhost\t1\tInactive\t\\N\t\\N\t\\N\t\\N\n 2\tlocalhost\t9000\ttest_unavailable_shard\tDROP TABLE IF EXISTS default.never_throw ON CLUSTER test_unavailable_shard\t1\tlocalhost\t9000\tFinished\t0\t\t1\t1\ndiff --git a/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.sh b/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.sh\nindex e632841bd011..c18514d0ecc4 100755\n--- a/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.sh\n+++ b/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.sh\n@@ -38,7 +38,6 @@ LOG_COMMENT=\"${CLICKHOUSE_LOG_COMMENT}_$RAND_COMMENT\"\n \n CLICKHOUSE_CLIENT_WITH_SETTINGS=${CLICKHOUSE_CLIENT/--log_comment ${CLICKHOUSE_LOG_COMMENT}/--log_comment ${LOG_COMMENT}}\n CLICKHOUSE_CLIENT_WITH_SETTINGS+=\" --output_format_parallel_formatting=0 \"\n-CLICKHOUSE_CLIENT_WITH_SETTINGS+=\" --distributed_ddl_entry_format_version=2 \"\n \n CLIENT=${CLICKHOUSE_CLIENT_WITH_SETTINGS}\n CLIENT+=\" --distributed_ddl_task_timeout=$TIMEOUT \"\ndiff --git a/tests/queries/0_stateless/02232_allow_only_replicated_engine.sh b/tests/queries/0_stateless/02232_allow_only_replicated_engine.sh\nindex c84b1ab0e555..3ff2dabfa43c 100755\n--- a/tests/queries/0_stateless/02232_allow_only_replicated_engine.sh\n+++ b/tests/queries/0_stateless/02232_allow_only_replicated_engine.sh\n@@ -11,8 +11,8 @@ ${CLICKHOUSE_CLIENT} -q \"CREATE USER user_${CLICKHOUSE_DATABASE} settings databa\n ${CLICKHOUSE_CLIENT} -q \"GRANT CREATE TABLE ON ${CLICKHOUSE_DATABASE}_db.* TO user_${CLICKHOUSE_DATABASE}\"\n ${CLICKHOUSE_CLIENT} --allow_experimental_database_replicated=1 --query \"CREATE DATABASE ${CLICKHOUSE_DATABASE}_db engine = Replicated('/clickhouse/databases/${CLICKHOUSE_TEST_ZOOKEEPER_PREFIX}/${CLICKHOUSE_DATABASE}_db', '{shard}', '{replica}')\"\n ${CLICKHOUSE_CLIENT} --distributed_ddl_output_mode=none --user \"user_${CLICKHOUSE_DATABASE}\" --query \"CREATE TABLE ${CLICKHOUSE_DATABASE}_db.tab_memory (x UInt32) engine = Memory;\"\n-${CLICKHOUSE_CLIENT} --distributed_ddl_output_mode=none --user \"user_${CLICKHOUSE_DATABASE}\" -n --query \"set distributed_ddl_entry_format_version=2; CREATE TABLE ${CLICKHOUSE_DATABASE}_db.tab_mt (x UInt32) engine = MergeTree order by x;\" 2>&1 | grep -o \"Only tables with a Replicated engine\"\n-${CLICKHOUSE_CLIENT} --distributed_ddl_output_mode=none -n --query \"set distributed_ddl_entry_format_version=2; CREATE TABLE ${CLICKHOUSE_DATABASE}_db.tab_mt (x UInt32) engine = MergeTree order by x;\"\n-${CLICKHOUSE_CLIENT} --distributed_ddl_output_mode=none --user \"user_${CLICKHOUSE_DATABASE}\" -n --query \"set distributed_ddl_entry_format_version=2; CREATE TABLE ${CLICKHOUSE_DATABASE}_db.tab_rmt (x UInt32) engine = ReplicatedMergeTree order by x;\"\n+${CLICKHOUSE_CLIENT} --distributed_ddl_output_mode=none --user \"user_${CLICKHOUSE_DATABASE}\" -n --query \"CREATE TABLE ${CLICKHOUSE_DATABASE}_db.tab_mt (x UInt32) engine = MergeTree order by x;\" 2>&1 | grep -o \"Only tables with a Replicated engine\"\n+${CLICKHOUSE_CLIENT} --distributed_ddl_output_mode=none -n --query \"CREATE TABLE ${CLICKHOUSE_DATABASE}_db.tab_mt (x UInt32) engine = MergeTree order by x;\"\n+${CLICKHOUSE_CLIENT} --distributed_ddl_output_mode=none --user \"user_${CLICKHOUSE_DATABASE}\" -n --query \"CREATE TABLE ${CLICKHOUSE_DATABASE}_db.tab_rmt (x UInt32) engine = ReplicatedMergeTree order by x;\"\n ${CLICKHOUSE_CLIENT} --query \"DROP DATABASE ${CLICKHOUSE_DATABASE}_db\"\n ${CLICKHOUSE_CLIENT} -q \"DROP USER user_${CLICKHOUSE_DATABASE}\"\ndiff --git a/tests/queries/0_stateless/02400_create_table_on_cluster_normalization.reference b/tests/queries/0_stateless/02400_create_table_on_cluster_normalization.reference\nnew file mode 100644\nindex 000000000000..c00653f2bb3a\n--- /dev/null\n+++ b/tests/queries/0_stateless/02400_create_table_on_cluster_normalization.reference\n@@ -0,0 +1,5 @@\n+localhost\t9000\t0\t\t0\t0\n+localhost\t9000\t0\t\t0\t0\n+1\t2\t3\t4\n+5\t6\t7\t8\n+CREATE TABLE default.t_l5ydey\\n(\\n    `c_qv5rv` Int32,\\n    `c_rutjs4` Int32,\\n    `c_wmj` Int32,\\n    `c_m3` String\\n)\\nENGINE = Distributed(\\'test_shard_localhost\\', \\'default\\', \\'local_t_l5ydey\\', rand())\ndiff --git a/tests/queries/0_stateless/02400_create_table_on_cluster_normalization.sql b/tests/queries/0_stateless/02400_create_table_on_cluster_normalization.sql\nnew file mode 100644\nindex 000000000000..54e4ccf6762d\n--- /dev/null\n+++ b/tests/queries/0_stateless/02400_create_table_on_cluster_normalization.sql\n@@ -0,0 +1,27 @@\n+-- Tags: no-replicated-database\n+-- Tag no-replicated-database: ON CLUSTER is not allowed\n+drop table if exists local_t_l5ydey;\n+\n+create table local_t_l5ydey on cluster test_shard_localhost (\n+    c_qv5rv INTEGER ,\n+    c_rutjs4 INTEGER ,\n+    c_wmj INTEGER ,\n+    c_m3 TEXT NOT NULL,\n+    primary key(c_qv5rv)\n+) engine=ReplicatedMergeTree('/clickhouse/tables/test_' || currentDatabase() || '/{shard}/local_t_l5ydey', '{replica}');\n+\n+create table t_l5ydey on cluster test_shard_localhost as local_t_l5ydey\n+    engine=Distributed('test_shard_localhost', currentDatabase(),'local_t_l5ydey', rand());\n+\n+insert into local_t_l5ydey values (1, 2, 3, '4');\n+insert into t_l5ydey values (5, 6, 7, '8');\n+system flush distributed t_l5ydey;\n+\n+select * from t_l5ydey order by c_qv5rv;\n+show create t_l5ydey;\n+\n+-- Correct error code if creating database with the same path as table has\n+set allow_experimental_database_replicated=1;\n+create database local_t_l5ydey engine=Replicated('/clickhouse/tables/test_' || currentDatabase() || '/{shard}/local_t_l5ydey', '1', '1'); -- { serverError BAD_ARGUMENTS }\n+\n+drop table local_t_l5ydey;\n",
  "problem_statement": "Support Replicated Database in ClickHouse Copier\n**Use case**\r\n\r\nClickHouse copier doesn't currently work with replicated databases. It results in the following error:\r\n\r\n```\r\n2022.03.09 13:55:03.267739 [ 2160190 ] {} <Error> Application: Code: 80. DB::Exception: Received from k8s-ns179cef-c179cef1-da30ec77d6-0ae794c2c59d4061.elb.us-east-2.amazonaws.com:9440. DB::Exception: It's not initial query. ON CLUSTER is not allowed for Replicated database.. Stack trace:\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xb06a5ba in /usr/bin/clickhouse\r\n1. DB::DatabaseReplicated::tryEnqueueReplicatedDDL(std::__1::shared_ptr<DB::IAST> const&, std::__1::shared_ptr<DB::Context const>) @ 0x14f76371 in /usr/bin/clickhouse\r\n2. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x15625b65 in /usr/bin/clickhouse\r\n3. DB::InterpreterCreateQuery::execute() @ 0x1562d44b in /usr/bin/clickhouse\r\n4. ? @ 0x15959c29 in /usr/bin/clickhouse\r\n5. DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::Context>, bool, DB::QueryProcessingStage::Enum) @ 0x15957775 in /usr/bin/clickhouse\r\n6. DB::TCPHandler::runImpl() @ 0x1649ddfa in /usr/bin/clickhouse\r\n7. DB::TCPHandler::run() @ 0x164b1d99 in /usr/bin/clickhouse\r\n8. Poco::Net::TCPServerConnection::start() @ 0x19768a4f in /usr/bin/clickhouse\r\n9. Poco::Net::TCPServerDispatcher::run() @ 0x1976aea1 in /usr/bin/clickhouse\r\n10. Poco::PooledThread::run() @ 0x19927ea9 in /usr/bin/clickhouse\r\n11. Poco::ThreadImpl::runnableEntry(void*) @ 0x19925200 in /usr/bin/clickhouse\r\n12. ? @ 0x7f9f93792609 in ?\r\n13. clone @ 0x7f9f936b9293 in ?\r\n. (INCORRECT_QUERY), Stack trace (when copying this message, always include the lines below):\r\n```\r\n\r\n**Describe the solution you'd like**\r\n\r\nRemove `ON_CLUSTER` for  replicated db.\r\n\nDatabaseReplicated: Replica ... already exists. Replica host ID: 'DROPPED'\nhttps://s3.amazonaws.com/clickhouse-test-reports/33847/8921725d716e05b13dc82f2db1c3d5bfc3ad6983/stress_test__debug__actions_.html\nAlways use default database when creating distributed table\n**Describe the unexpected behaviour**\r\nAlways use default database when creating distributed table\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use\r\n22.4.5.9\r\n\r\nThe following statements fail with exceptions:\r\n\r\n```\r\ncreate database test on cluster test_cluster;\r\n\r\nuse test;\r\n\r\ncreate table local_t_l5ydey on cluster test_cluster ( \r\nc_qv5rv INTEGER ,\r\nc_rutjs4 INTEGER ,\r\nc_wmj INTEGER ,\r\nc_m3 TEXT NOT NULL,\r\nprimary key(c_qv5rv)\r\n)\r\nengine=ReplicatedMergeTree('/clickhouse/tables/test/{shard}/local_t_l5ydey', '{replica}');\r\n\r\ncreate table t_l5ydey on cluster test_cluster as local_t_l5ydey\r\nengine=Distributed('test_cluster','test','local_t_l5ydey', rand())\r\n```\r\n\r\n```\r\nQuery id: c0de0142-df6f-4703-9a68-9a491263133d\r\n\r\n\u250c\u2500host\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500port\u2500\u252c\u2500status\u2500\u252c\u2500error\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500num_hosts_remaining\u2500\u252c\u2500num_hosts_active\u2500\u2510\r\n\u2502 127.0.0.1 \u2502 5000 \u2502     60 \u2502 Code: 60. DB::Exception: Table default.local_t_l5ydey doesn't exist. (UNKNOWN_TABLE) (version 22.4.5.9 (official build)) \u2502                   3 \u2502                0 \u2502\r\n\u2502 127.0.0.1 \u2502 5001 \u2502     60 \u2502 Code: 60. DB::Exception: Table default.local_t_l5ydey doesn't exist. (UNKNOWN_TABLE) (version 22.4.5.9 (official build)) \u2502                   2 \u2502                0 \u2502\r\n\u2502 127.0.0.1 \u2502 5002 \u2502     60 \u2502 Code: 60. DB::Exception: Table default.local_t_l5ydey doesn't exist. (UNKNOWN_TABLE) (version 22.4.5.9 (official build)) \u2502                   1 \u2502                0 \u2502\r\n\u2502 127.0.0.1 \u2502 5003 \u2502     60 \u2502 Code: 60. DB::Exception: Table default.local_t_l5ydey doesn't exist. (UNKNOWN_TABLE) (version 22.4.5.9 (official build)) \u2502                   0 \u2502                0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u2192 Progress: 0.00 rows, 0.00 B (0.00 rows/s., 0.00 B/s.)  0%\r\n4 rows in set. Elapsed: 0.173 sec. \r\n\r\nReceived exception from server (version 22.4.5):\r\nCode: 60. DB::Exception: Received from localhost:5000. DB::Exception: There was an error on [127.0.0.1:5000]: Code: 60. DB::Exception: Table default.local_t_l5ydey doesn't exist. (UNKNOWN_TABLE) (version 22.4.5.9 (official build)). (UNKNOWN_TABLE)\r\n```\r\n\r\nThe \"create table ... as ...\" statement uses the default database after the \"use\" statement.\r\n\r\n**Expected behavior**\r\nThe \"create table ... as ...\" statement should use the current used database.\r\n\n",
  "hints_text": "\n\n",
  "created_at": "2022-05-13T15:43:08Z"
}