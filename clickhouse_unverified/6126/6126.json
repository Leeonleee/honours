{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 6126,
  "instance_id": "ClickHouse__ClickHouse-6126",
  "issue_numbers": [
    "6121"
  ],
  "base_commit": "ba988735cc9fdade13640ae12a8d4c292f4d3f3c",
  "patch": "diff --git a/dbms/src/Storages/MergeTree/MergedBlockOutputStream.cpp b/dbms/src/Storages/MergeTree/MergedBlockOutputStream.cpp\nindex 8b38f1ff32e4..5ed783c034f7 100644\n--- a/dbms/src/Storages/MergeTree/MergedBlockOutputStream.cpp\n+++ b/dbms/src/Storages/MergeTree/MergedBlockOutputStream.cpp\n@@ -381,18 +381,18 @@ void MergedBlockOutputStream::writeImpl(const Block & block, const IColumn::Perm\n     }\n \n     rows_count += rows;\n-\n     {\n         /// Creating block for update\n         Block indices_update_block(skip_indexes_columns);\n+        size_t skip_index_current_mark = 0;\n+\n         /// Filling and writing skip indices like in IMergedBlockOutputStream::writeColumn\n         for (size_t i = 0; i < storage.skip_indices.size(); ++i)\n         {\n             const auto index = storage.skip_indices[i];\n             auto & stream = *skip_indices_streams[i];\n             size_t prev_pos = 0;\n-\n-            size_t skip_index_current_mark = 0;\n+            skip_index_current_mark = skip_index_mark;\n             while (prev_pos < rows)\n             {\n                 UInt64 limit = 0;\n@@ -417,6 +417,8 @@ void MergedBlockOutputStream::writeImpl(const Block & block, const IColumn::Perm\n                         /// to be compatible with normal .mrk2 file format\n                         if (storage.canUseAdaptiveGranularity())\n                             writeIntBinary(1UL, stream.marks);\n+\n+                        ++skip_index_current_mark;\n                     }\n                 }\n \n@@ -435,9 +437,9 @@ void MergedBlockOutputStream::writeImpl(const Block & block, const IColumn::Perm\n                     }\n                 }\n                 prev_pos = pos;\n-                ++skip_index_current_mark;\n             }\n         }\n+        skip_index_mark = skip_index_current_mark;\n     }\n \n     {\ndiff --git a/dbms/src/Storages/MergeTree/MergedBlockOutputStream.h b/dbms/src/Storages/MergeTree/MergedBlockOutputStream.h\nindex 467660413b30..3acb01c3c0aa 100644\n--- a/dbms/src/Storages/MergeTree/MergedBlockOutputStream.h\n+++ b/dbms/src/Storages/MergeTree/MergedBlockOutputStream.h\n@@ -68,6 +68,7 @@ class MergedBlockOutputStream final : public IMergedBlockOutputStream\n     String part_path;\n \n     size_t rows_count = 0;\n+    size_t skip_index_mark = 0;\n \n     std::unique_ptr<WriteBufferFromFile> index_file_stream;\n     std::unique_ptr<HashingWriteBuffer> index_stream;\n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/00974_adaptive_granularity_secondary_index.reference b/dbms/tests/queries/0_stateless/00974_adaptive_granularity_secondary_index.reference\nnew file mode 100644\nindex 000000000000..5878ba472255\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00974_adaptive_granularity_secondary_index.reference\n@@ -0,0 +1,2 @@\n+1000\n+1000\ndiff --git a/dbms/tests/queries/0_stateless/00974_adaptive_granularity_secondary_index.sql b/dbms/tests/queries/0_stateless/00974_adaptive_granularity_secondary_index.sql\nnew file mode 100644\nindex 000000000000..328ec86f060a\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00974_adaptive_granularity_secondary_index.sql\n@@ -0,0 +1,56 @@\n+SET allow_experimental_data_skipping_indices = 1;\n+\n+DROP TABLE IF EXISTS indexed_table;\n+\n+CREATE TABLE indexed_table\n+(\n+    `tm` DateTime,\n+    `log_message` String,\n+    INDEX log_message log_message TYPE tokenbf_v1(4096, 2, 0) GRANULARITY 1\n+)\n+ENGINE = MergeTree\n+ORDER BY (tm)\n+SETTINGS index_granularity_bytes = 50;\n+\n+INSERT INTO indexed_table SELECT toDateTime('2019-05-27 10:00:00') + number % 100, 'h' FROM numbers(1000);\n+\n+INSERT INTO indexed_table\n+SELECT\n+    toDateTime('2019-05-27 10:00:00') + number % 100,\n+    concat('hhhhhhhhhhhhhhhhhhhhhhhhh', 'xxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'yyyyyyyyyyyyyyyyyyyyyyyyyy', toString(rand()))\n+FROM numbers(1000);\n+\n+OPTIMIZE TABLE indexed_table FINAL;\n+\n+SELECT COUNT() FROM indexed_table WHERE log_message like '%x%';\n+\n+DROP TABLE IF EXISTS indexed_table;\n+\n+DROP TABLE IF EXISTS another_indexed_table;\n+\n+CREATE TABLE another_indexed_table\n+(\n+  `tm` DateTime,\n+  `log_message` String,\n+  INDEX log_message log_message TYPE tokenbf_v1(4096, 2, 0) GRANULARITY 1\n+)\n+ENGINE = MergeTree\n+ORDER BY (tm)\n+SETTINGS index_granularity_bytes = 50,\n+         vertical_merge_algorithm_min_rows_to_activate=0,\n+         vertical_merge_algorithm_min_columns_to_activate=0;\n+\n+\n+INSERT INTO another_indexed_table SELECT toDateTime('2019-05-27 10:00:00') + number % 100, 'h' FROM numbers(1000);\n+\n+INSERT INTO another_indexed_table\n+SELECT\n+  toDateTime('2019-05-27 10:00:00') + number % 100,\n+  concat('hhhhhhhhhhhhhhhhhhhhhhhhh', 'xxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'yyyyyyyyyyyyyyyyyyyyyyyyyy', toString(rand()))\n+  FROM numbers(1000);\n+\n+OPTIMIZE TABLE another_indexed_table FINAL;\n+\n+SELECT COUNT() FROM another_indexed_table WHERE log_message like '%x%';\n+\n+DROP TABLE IF EXISTS another_indexed_table;\n",
  "problem_statement": "Merge + data skipping indicies can lead to 'Bad size of marks file' \nIn some scenarios merge can produce shorter marks file for index data. \n",
  "hints_text": "",
  "created_at": "2019-07-23T15:30:58Z"
}