{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 51446,
  "instance_id": "ClickHouse__ClickHouse-51446",
  "issue_numbers": [
    "51085"
  ],
  "base_commit": "ec7b22d218182a3bfc6d34766c39e61d6d2c5420",
  "patch": "diff --git a/docs/en/operations/server-configuration-parameters/settings.md b/docs/en/operations/server-configuration-parameters/settings.md\nindex a7637082496d..03cd56ef119c 100644\n--- a/docs/en/operations/server-configuration-parameters/settings.md\n+++ b/docs/en/operations/server-configuration-parameters/settings.md\n@@ -221,6 +221,10 @@ Default: 1024\n \n Size of cache for index marks. Zero means disabled.\n \n+:::note\n+This setting can be modified at runtime and will take effect immediately.\n+:::\n+\n Type: UInt64\n \n Default: 0\n@@ -230,6 +234,10 @@ Default: 0\n \n Size of cache for uncompressed blocks of MergeTree indices. Zero means disabled.\n \n+:::note\n+This setting can be modified at runtime and will take effect immediately.\n+:::\n+\n Type: UInt64\n \n Default: 0\n@@ -255,6 +263,10 @@ Default: SLRU\n \n Size of cache for marks (index of MergeTree family of tables).\n \n+:::note\n+This setting can be modified at runtime and will take effect immediately.\n+:::\n+\n Type: UInt64\n \n Default: 5368709120\n@@ -288,7 +300,7 @@ Default: 1000\n Limit on total number of concurrently executed queries. Zero means Unlimited. Note that limits on insert and select queries, and on the maximum number of queries for users must also be considered.  See also max_concurrent_insert_queries, max_concurrent_select_queries, max_concurrent_queries_for_all_users. Zero means unlimited.\n \n :::note\n-These settings can be modified at runtime and will take effect immediately. Queries that are already running will remain unchanged.\n+This setting can be modified at runtime and will take effect immediately. Queries that are already running will remain unchanged.\n :::\n \n Type: UInt64\n@@ -300,7 +312,7 @@ Default: 0\n Limit on total number of concurrent insert queries. Zero means Unlimited.\n \n :::note\n-These settings can be modified at runtime and will take effect immediately. Queries that are already running will remain unchanged.\n+This setting can be modified at runtime and will take effect immediately. Queries that are already running will remain unchanged.\n :::\n \n Type: UInt64\n@@ -312,7 +324,7 @@ Default: 0\n Limit on total number of concurrently select queries. Zero means Unlimited.\n \n :::note\n-These settings can be modified at runtime and will take effect immediately. Queries that are already running will remain unchanged.\n+This setting can be modified at runtime and will take effect immediately. Queries that are already running will remain unchanged.\n :::\n \n Type: UInt64\n@@ -456,6 +468,10 @@ Sets the cache size (in bytes) for mapped files. This setting allows avoiding fr\n \n Note that the amount of data in mapped files does not consume memory directly and is not accounted for in query or server memory usage \u2014 because this memory can be discarded similar to the OS page cache. The cache is dropped (the files are closed) automatically on the removal of old parts in tables of the MergeTree family, also it can be dropped manually by the `SYSTEM DROP MMAP CACHE` query.\n \n+:::note\n+This setting can be modified at runtime and will take effect immediately.\n+:::\n+\n Type: UInt64\n \n Default: 1000\n@@ -605,6 +621,10 @@ There is one shared cache for the server. Memory is allocated on demand. The cac\n \n The uncompressed cache is advantageous for very short queries in individual cases.\n \n+:::note\n+This setting can be modified at runtime and will take effect immediately.\n+:::\n+\n Type: UInt64\n \n Default: 0\ndiff --git a/docs/en/sql-reference/statements/system.md b/docs/en/sql-reference/statements/system.md\nindex 59970dbeccd9..962639099aee 100644\n--- a/docs/en/sql-reference/statements/system.md\n+++ b/docs/en/sql-reference/statements/system.md\n@@ -66,13 +66,13 @@ RELOAD FUNCTION [ON CLUSTER cluster_name] function_name\n \n ## DROP DNS CACHE\n \n-Resets ClickHouse\u2019s internal DNS cache. Sometimes (for old ClickHouse versions) it is necessary to use this command when changing the infrastructure (changing the IP address of another ClickHouse server or the server used by dictionaries).\n+Clears ClickHouse\u2019s internal DNS cache. Sometimes (for old ClickHouse versions) it is necessary to use this command when changing the infrastructure (changing the IP address of another ClickHouse server or the server used by dictionaries).\n \n For more convenient (automatic) cache management, see disable_internal_dns_cache, dns_cache_update_period parameters.\n \n ## DROP MARK CACHE\n \n-Resets the mark cache.\n+Clears the mark cache.\n \n ## DROP REPLICA\n \n@@ -106,22 +106,18 @@ Similar to `SYSTEM DROP REPLICA`, but removes the `Replicated` database replica\n \n ## DROP UNCOMPRESSED CACHE\n \n-Reset the uncompressed data cache.\n+Clears the uncompressed data cache.\n The uncompressed data cache is enabled/disabled with the query/user/profile-level setting [use_uncompressed_cache](../../operations/settings/settings.md#setting-use_uncompressed_cache).\n Its size can be configured using the server-level setting [uncompressed_cache_size](../../operations/server-configuration-parameters/settings.md#server-settings-uncompressed_cache_size).\n \n ## DROP COMPILED EXPRESSION CACHE\n \n-Reset the compiled expression cache.\n+Clears the compiled expression cache.\n The compiled expression cache is enabled/disabled with the query/user/profile-level setting [compile_expressions](../../operations/settings/settings.md#compile-expressions).\n \n ## DROP QUERY CACHE\n \n-Resets the [query cache](../../operations/query-cache.md).\n-\n-```sql\n-SYSTEM DROP QUERY CACHE [ON CLUSTER cluster_name]\n-```\n+Clears the [query cache](../../operations/query-cache.md).\n \n ## FLUSH LOGS\n \ndiff --git a/programs/local/LocalServer.cpp b/programs/local/LocalServer.cpp\nindex b38e17ecade0..2ba4d245f215 100644\n--- a/programs/local/LocalServer.cpp\n+++ b/programs/local/LocalServer.cpp\n@@ -668,8 +668,7 @@ void LocalServer::processConfig()\n         uncompressed_cache_size = max_cache_size;\n         LOG_INFO(log, \"Lowered uncompressed cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n     }\n-    if (uncompressed_cache_size)\n-        global_context->setUncompressedCache(uncompressed_cache_policy, uncompressed_cache_size);\n+    global_context->setUncompressedCache(uncompressed_cache_policy, uncompressed_cache_size);\n \n     String mark_cache_policy = config().getString(\"mark_cache_policy\", DEFAULT_MARK_CACHE_POLICY);\n     size_t mark_cache_size = config().getUInt64(\"mark_cache_size\", DEFAULT_MARK_CACHE_MAX_SIZE);\n@@ -680,8 +679,7 @@ void LocalServer::processConfig()\n         mark_cache_size = max_cache_size;\n         LOG_INFO(log, \"Lowered mark cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(mark_cache_size));\n     }\n-    if (mark_cache_size)\n-        global_context->setMarkCache(mark_cache_policy, mark_cache_size);\n+    global_context->setMarkCache(mark_cache_policy, mark_cache_size);\n \n     size_t index_uncompressed_cache_size = config().getUInt64(\"index_uncompressed_cache_size\", DEFAULT_INDEX_UNCOMPRESSED_CACHE_MAX_SIZE);\n     if (index_uncompressed_cache_size > max_cache_size)\n@@ -689,8 +687,7 @@ void LocalServer::processConfig()\n         index_uncompressed_cache_size = max_cache_size;\n         LOG_INFO(log, \"Lowered index uncompressed cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n     }\n-    if (index_uncompressed_cache_size)\n-        global_context->setIndexUncompressedCache(index_uncompressed_cache_size);\n+    global_context->setIndexUncompressedCache(index_uncompressed_cache_size);\n \n     size_t index_mark_cache_size = config().getUInt64(\"index_mark_cache_size\", DEFAULT_INDEX_MARK_CACHE_MAX_SIZE);\n     if (index_mark_cache_size > max_cache_size)\n@@ -698,8 +695,7 @@ void LocalServer::processConfig()\n         index_mark_cache_size = max_cache_size;\n         LOG_INFO(log, \"Lowered index mark cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n     }\n-    if (index_mark_cache_size)\n-        global_context->setIndexMarkCache(index_mark_cache_size);\n+    global_context->setIndexMarkCache(index_mark_cache_size);\n \n     size_t mmap_cache_size = config().getUInt64(\"mmap_cache_size\", DEFAULT_MMAP_CACHE_MAX_SIZE);\n     if (mmap_cache_size > max_cache_size)\n@@ -707,11 +703,10 @@ void LocalServer::processConfig()\n         mmap_cache_size = max_cache_size;\n         LOG_INFO(log, \"Lowered mmap file cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n     }\n-    if (mmap_cache_size)\n-        global_context->setMMappedFileCache(mmap_cache_size);\n+    global_context->setMMappedFileCache(mmap_cache_size);\n \n-    /// In Server.cpp (./clickhouse-server), we would initialize the query cache here.\n-    /// Intentionally not doing this in clickhouse-local as it doesn't make sense.\n+    /// Initialize a dummy query cache.\n+    global_context->setQueryCache(0, 0, 0, 0);\n \n #if USE_EMBEDDED_COMPILER\n     size_t compiled_expression_cache_max_size_in_bytes = config().getUInt64(\"compiled_expression_cache_size\", DEFAULT_COMPILED_EXPRESSION_CACHE_MAX_SIZE);\ndiff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex 96f89c867a2c..ac8d1cb98d97 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -1105,6 +1105,69 @@ try\n     if (config().has(\"macros\"))\n         global_context->setMacros(std::make_unique<Macros>(config(), \"macros\", log));\n \n+    /// Set up caches.\n+\n+    const size_t max_cache_size = static_cast<size_t>(physical_server_memory * server_settings.cache_size_to_ram_max_ratio);\n+\n+    String uncompressed_cache_policy = server_settings.uncompressed_cache_policy;\n+    size_t uncompressed_cache_size = server_settings.uncompressed_cache_size;\n+    if (uncompressed_cache_size > max_cache_size)\n+    {\n+        uncompressed_cache_size = max_cache_size;\n+        LOG_INFO(log, \"Lowered uncompressed cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n+    }\n+    global_context->setUncompressedCache(uncompressed_cache_policy, uncompressed_cache_size);\n+\n+    String mark_cache_policy = server_settings.mark_cache_policy;\n+    size_t mark_cache_size = server_settings.mark_cache_size;\n+    if (mark_cache_size > max_cache_size)\n+    {\n+        mark_cache_size = max_cache_size;\n+        LOG_INFO(log, \"Lowered mark cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(mark_cache_size));\n+    }\n+    global_context->setMarkCache(mark_cache_policy, mark_cache_size);\n+\n+    size_t index_uncompressed_cache_size = server_settings.index_uncompressed_cache_size;\n+    if (index_uncompressed_cache_size > max_cache_size)\n+    {\n+        index_uncompressed_cache_size = max_cache_size;\n+        LOG_INFO(log, \"Lowered index uncompressed cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n+    }\n+    global_context->setIndexUncompressedCache(index_uncompressed_cache_size);\n+\n+    size_t index_mark_cache_size = server_settings.index_mark_cache_size;\n+    if (index_mark_cache_size > max_cache_size)\n+    {\n+        index_mark_cache_size = max_cache_size;\n+        LOG_INFO(log, \"Lowered index mark cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n+    }\n+    global_context->setIndexMarkCache(index_mark_cache_size);\n+\n+    size_t mmap_cache_size = server_settings.mmap_cache_size;\n+    if (mmap_cache_size > max_cache_size)\n+    {\n+        mmap_cache_size = max_cache_size;\n+        LOG_INFO(log, \"Lowered mmap file cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n+    }\n+    global_context->setMMappedFileCache(mmap_cache_size);\n+\n+    size_t query_cache_max_size_in_bytes = config().getUInt64(\"query_cache.max_size_in_bytes\", DEFAULT_QUERY_CACHE_MAX_SIZE);\n+    size_t query_cache_max_entries = config().getUInt64(\"query_cache.max_entries\", DEFAULT_QUERY_CACHE_MAX_ENTRIES);\n+    size_t query_cache_query_cache_max_entry_size_in_bytes = config().getUInt64(\"query_cache.max_entry_size_in_bytes\", DEFAULT_QUERY_CACHE_MAX_ENTRY_SIZE_IN_BYTES);\n+    size_t query_cache_max_entry_size_in_rows = config().getUInt64(\"query_cache.max_entry_rows_in_rows\", DEFAULT_QUERY_CACHE_MAX_ENTRY_SIZE_IN_ROWS);\n+    if (query_cache_max_size_in_bytes > max_cache_size)\n+    {\n+        query_cache_max_size_in_bytes = max_cache_size;\n+        LOG_INFO(log, \"Lowered query cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n+    }\n+    global_context->setQueryCache(query_cache_max_size_in_bytes, query_cache_max_entries, query_cache_query_cache_max_entry_size_in_bytes, query_cache_max_entry_size_in_rows);\n+\n+#if USE_EMBEDDED_COMPILER\n+    size_t compiled_expression_cache_max_size_in_bytes = config().getUInt64(\"compiled_expression_cache_size\", DEFAULT_COMPILED_EXPRESSION_CACHE_MAX_SIZE);\n+    size_t compiled_expression_cache_max_elements = config().getUInt64(\"compiled_expression_cache_elements_size\", DEFAULT_COMPILED_EXPRESSION_CACHE_MAX_ENTRIES);\n+    CompiledExpressionCacheFactory::instance().init(compiled_expression_cache_max_size_in_bytes, compiled_expression_cache_max_elements);\n+#endif\n+\n     /// Initialize main config reloader.\n     std::string include_from_path = config().getString(\"include_from\", \"/etc/metrika.xml\");\n \n@@ -1324,7 +1387,14 @@ try\n \n             global_context->updateStorageConfiguration(*config);\n             global_context->updateInterserverCredentials(*config);\n+\n+            global_context->updateUncompressedCacheConfiguration(*config);\n+            global_context->updateMarkCacheConfiguration(*config);\n+            global_context->updateIndexUncompressedCacheConfiguration(*config);\n+            global_context->updateIndexMarkCacheConfiguration(*config);\n+            global_context->updateMMappedFileCacheConfiguration(*config);\n             global_context->updateQueryCacheConfiguration(*config);\n+\n             CompressionCodecEncrypted::Configuration::instance().tryLoad(*config, \"encryption_codecs\");\n #if USE_SSL\n             CertificateReloader::instance().tryLoad(*config);\n@@ -1484,19 +1554,6 @@ try\n     /// Limit on total number of concurrently executed queries.\n     global_context->getProcessList().setMaxSize(server_settings.max_concurrent_queries);\n \n-    /// Set up caches.\n-\n-    const size_t max_cache_size = static_cast<size_t>(physical_server_memory * server_settings.cache_size_to_ram_max_ratio);\n-\n-    String uncompressed_cache_policy = server_settings.uncompressed_cache_policy;\n-    size_t uncompressed_cache_size = server_settings.uncompressed_cache_size;\n-    if (uncompressed_cache_size > max_cache_size)\n-    {\n-        uncompressed_cache_size = max_cache_size;\n-        LOG_INFO(log, \"Lowered uncompressed cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n-    }\n-    global_context->setUncompressedCache(uncompressed_cache_policy, uncompressed_cache_size);\n-\n     /// Load global settings from default_profile and system_profile.\n     global_context->setDefaultProfiles(config());\n \n@@ -1512,61 +1569,6 @@ try\n             server_settings.async_insert_queue_flush_on_shutdown));\n     }\n \n-    String mark_cache_policy = server_settings.mark_cache_policy;\n-    size_t mark_cache_size = server_settings.mark_cache_size;\n-    if (!mark_cache_size)\n-        LOG_ERROR(log, \"Too low mark cache size will lead to severe performance degradation.\");\n-    if (mark_cache_size > max_cache_size)\n-    {\n-        mark_cache_size = max_cache_size;\n-        LOG_INFO(log, \"Lowered mark cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(mark_cache_size));\n-    }\n-    global_context->setMarkCache(mark_cache_policy, mark_cache_size);\n-\n-    size_t index_uncompressed_cache_size = server_settings.index_uncompressed_cache_size;\n-    if (index_uncompressed_cache_size > max_cache_size)\n-    {\n-        index_uncompressed_cache_size = max_cache_size;\n-        LOG_INFO(log, \"Lowered index uncompressed cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n-    }\n-    if (index_uncompressed_cache_size)\n-        global_context->setIndexUncompressedCache(server_settings.index_uncompressed_cache_size);\n-\n-    size_t index_mark_cache_size = server_settings.index_mark_cache_size;\n-    if (index_mark_cache_size > max_cache_size)\n-    {\n-        index_mark_cache_size = max_cache_size;\n-        LOG_INFO(log, \"Lowered index mark cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n-    }\n-    if (index_mark_cache_size)\n-        global_context->setIndexMarkCache(server_settings.index_mark_cache_size);\n-\n-    size_t mmap_cache_size = server_settings.mmap_cache_size;\n-    if (mmap_cache_size > max_cache_size)\n-    {\n-        mmap_cache_size = max_cache_size;\n-        LOG_INFO(log, \"Lowered mmap file cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n-    }\n-    if (mmap_cache_size)\n-        global_context->setMMappedFileCache(server_settings.mmap_cache_size);\n-\n-    size_t query_cache_max_size_in_bytes = config().getUInt64(\"query_cache.max_size_in_bytes\", DEFAULT_QUERY_CACHE_MAX_SIZE);\n-    size_t query_cache_max_entries = config().getUInt64(\"query_cache.max_entries\", DEFAULT_QUERY_CACHE_MAX_ENTRIES);\n-    size_t query_cache_query_cache_max_entry_size_in_bytes = config().getUInt64(\"query_cache.max_entry_size_in_bytes\", DEFAULT_QUERY_CACHE_MAX_ENTRY_SIZE_IN_BYTES);\n-    size_t query_cache_max_entry_size_in_rows = config().getUInt64(\"query_cache.max_entry_rows_in_rows\", DEFAULT_QUERY_CACHE_MAX_ENTRY_SIZE_IN_ROWS);\n-    if (query_cache_max_size_in_bytes > max_cache_size)\n-    {\n-        query_cache_max_size_in_bytes = max_cache_size;\n-        LOG_INFO(log, \"Lowered query cache size to {} because the system has limited RAM\", formatReadableSizeWithBinarySuffix(uncompressed_cache_size));\n-    }\n-    global_context->setQueryCache(query_cache_max_size_in_bytes, query_cache_max_entries, query_cache_query_cache_max_entry_size_in_bytes, query_cache_max_entry_size_in_rows);\n-\n-#if USE_EMBEDDED_COMPILER\n-    size_t compiled_expression_cache_max_size_in_bytes = config().getUInt64(\"compiled_expression_cache_size\", DEFAULT_COMPILED_EXPRESSION_CACHE_MAX_SIZE);\n-    size_t compiled_expression_cache_max_elements = config().getUInt64(\"compiled_expression_cache_elements_size\", DEFAULT_COMPILED_EXPRESSION_CACHE_MAX_ENTRIES);\n-    CompiledExpressionCacheFactory::instance().init(compiled_expression_cache_max_size_in_bytes, compiled_expression_cache_max_elements);\n-#endif\n-\n     /// Set path for format schema files\n     fs::path format_schema_path(config().getString(\"format_schema_path\", path / \"format_schemas/\"));\n     global_context->setFormatSchemaPath(format_schema_path);\ndiff --git a/src/Access/MultipleAccessStorage.cpp b/src/Access/MultipleAccessStorage.cpp\nindex 0550c140c179..81dc15da7bcb 100644\n--- a/src/Access/MultipleAccessStorage.cpp\n+++ b/src/Access/MultipleAccessStorage.cpp\n@@ -46,7 +46,7 @@ void MultipleAccessStorage::setStorages(const std::vector<StoragePtr> & storages\n {\n     std::lock_guard lock{mutex};\n     nested_storages = std::make_shared<const Storages>(storages);\n-    ids_cache.reset();\n+    ids_cache.clear();\n }\n \n void MultipleAccessStorage::addStorage(const StoragePtr & new_storage)\n@@ -69,7 +69,7 @@ void MultipleAccessStorage::removeStorage(const StoragePtr & storage_to_remove)\n     auto new_storages = std::make_shared<Storages>(*nested_storages);\n     new_storages->erase(new_storages->begin() + index);\n     nested_storages = new_storages;\n-    ids_cache.reset();\n+    ids_cache.clear();\n }\n \n std::vector<StoragePtr> MultipleAccessStorage::getStorages()\ndiff --git a/src/Common/CacheBase.h b/src/Common/CacheBase.h\nindex aa7b3ea10cf1..ac2a64bd87c1 100644\n--- a/src/Common/CacheBase.h\n+++ b/src/Common/CacheBase.h\n@@ -151,7 +151,7 @@ class CacheBase\n         std::lock_guard cache_lock(mutex);\n \n         /// Insert the new value only if the token is still in present in insert_tokens.\n-        /// (The token may be absent because of a concurrent reset() call).\n+        /// (The token may be absent because of a concurrent clear() call).\n         bool result = false;\n         auto token_it = insert_tokens.find(key);\n         if (token_it != insert_tokens.end() && token_it->second.get() == token)\n@@ -179,13 +179,13 @@ class CacheBase\n         return cache_policy->dump();\n     }\n \n-    void reset()\n+    void clear()\n     {\n         std::lock_guard lock(mutex);\n         insert_tokens.clear();\n         hits = 0;\n         misses = 0;\n-        cache_policy->reset(lock);\n+        cache_policy->clear(lock);\n     }\n \n     void remove(const Key & key)\ndiff --git a/src/Common/DNSResolver.cpp b/src/Common/DNSResolver.cpp\nindex 285362e32f1d..6a685b602ae4 100644\n--- a/src/Common/DNSResolver.cpp\n+++ b/src/Common/DNSResolver.cpp\n@@ -270,8 +270,8 @@ std::unordered_set<String> DNSResolver::reverseResolve(const Poco::Net::IPAddres\n \n void DNSResolver::dropCache()\n {\n-    impl->cache_host.reset();\n-    impl->cache_address.reset();\n+    impl->cache_host.clear();\n+    impl->cache_address.clear();\n \n     std::scoped_lock lock(impl->update_mutex, impl->drop_mutex);\n \ndiff --git a/src/Common/ICachePolicy.h b/src/Common/ICachePolicy.h\nindex 9edbc77b8af3..0925944002f5 100644\n--- a/src/Common/ICachePolicy.h\n+++ b/src/Common/ICachePolicy.h\n@@ -10,11 +10,6 @@\n namespace DB\n {\n \n-namespace ErrorCodes\n-{\n-    extern const int NOT_IMPLEMENTED;\n-}\n-\n template <typename T>\n struct EqualWeightFunction\n {\n@@ -46,8 +41,8 @@ class ICachePolicy\n     virtual size_t count(std::lock_guard<std::mutex> & /*cache_lock*/) const = 0;\n     virtual size_t maxSize(std::lock_guard<std::mutex>& /*cache_lock*/) const = 0;\n \n-    virtual void setMaxCount(size_t /*max_count*/, std::lock_guard<std::mutex> & /* cache_lock */) { throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Not implemented for cache policy\"); }\n-    virtual void setMaxSize(size_t /*max_size_in_bytes*/, std::lock_guard<std::mutex> & /* cache_lock */) { throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Not implemented for cache policy\"); }\n+    virtual void setMaxCount(size_t /*max_count*/, std::lock_guard<std::mutex> & /* cache_lock */) = 0;\n+    virtual void setMaxSize(size_t /*max_size_in_bytes*/, std::lock_guard<std::mutex> & /* cache_lock */) = 0;\n     virtual void setQuotaForUser(const String & user_name, size_t max_size_in_bytes, size_t max_entries, std::lock_guard<std::mutex> & /*cache_lock*/) { user_quotas->setQuotaForUser(user_name, max_size_in_bytes, max_entries); }\n \n     /// HashFunction usually hashes the entire key and the found key will be equal the provided key. In such cases, use get(). It is also\n@@ -60,7 +55,7 @@ class ICachePolicy\n \n     virtual void remove(const Key & key, std::lock_guard<std::mutex> & /*cache_lock*/) = 0;\n \n-    virtual void reset(std::lock_guard<std::mutex> & /*cache_lock*/) = 0;\n+    virtual void clear(std::lock_guard<std::mutex> & /*cache_lock*/) = 0;\n     virtual std::vector<KeyMapped> dump() const = 0;\n \n protected:\ndiff --git a/src/Common/LRUCachePolicy.h b/src/Common/LRUCachePolicy.h\nindex 25ad15db5826..b1c8680a003a 100644\n--- a/src/Common/LRUCachePolicy.h\n+++ b/src/Common/LRUCachePolicy.h\n@@ -7,9 +7,8 @@\n \n namespace DB\n {\n-/// Cache policy LRU evicts entries which are not used for a long time.\n-/// WeightFunction is a functor that takes Mapped as a parameter and returns \"weight\" (approximate size)\n-/// of that value.\n+/// Cache policy LRU evicts entries which are not used for a long time. Also see cache policy SLRU for reference.\n+/// WeightFunction is a functor that takes Mapped as a parameter and returns \"weight\" (approximate size) of that value.\n /// Cache starts to evict entries when their total weight exceeds max_size_in_bytes.\n /// Value weight should not change after insertion.\n /// To work with the thread-safe implementation of this class use a class \"CacheBase\" with first parameter \"LRU\"\n@@ -24,11 +23,12 @@ class LRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n     using typename Base::OnWeightLossFunction;\n \n     /** Initialize LRUCachePolicy with max_size_in_bytes and max_count.\n+     *  max_size_in_bytes == 0 means the cache accepts no entries.\n       * max_count == 0 means no elements size restrictions.\n       */\n     LRUCachePolicy(size_t max_size_in_bytes_, size_t max_count_, OnWeightLossFunction on_weight_loss_function_)\n         : Base(std::make_unique<NoCachePolicyUserQuota>())\n-        , max_size_in_bytes(std::max(1uz, max_size_in_bytes_))\n+        , max_size_in_bytes(max_size_in_bytes_)\n         , max_count(max_count_)\n         , on_weight_loss_function(on_weight_loss_function_)\n     {\n@@ -49,7 +49,19 @@ class LRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n         return max_size_in_bytes;\n     }\n \n-    void reset(std::lock_guard<std::mutex> & /* cache_lock */) override\n+    void setMaxCount(size_t max_count_, std::lock_guard<std::mutex> & /* cache_lock */) override\n+    {\n+        max_count = max_count_;\n+        removeOverflow();\n+    }\n+\n+    void setMaxSize(size_t max_size_in_bytes_, std::lock_guard<std::mutex> & /* cache_lock */) override\n+    {\n+        max_size_in_bytes = max_size_in_bytes_;\n+        removeOverflow();\n+    }\n+\n+    void clear(std::lock_guard<std::mutex> & /* cache_lock */) override\n     {\n         queue.clear();\n         cells.clear();\n@@ -155,8 +167,8 @@ class LRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n \n     /// Total weight of values.\n     size_t current_size_in_bytes = 0;\n-    const size_t max_size_in_bytes;\n-    const size_t max_count;\n+    size_t max_size_in_bytes;\n+    size_t max_count;\n \n     WeightFunction weight_function;\n     OnWeightLossFunction on_weight_loss_function;\n@@ -172,10 +184,7 @@ class LRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n \n             auto it = cells.find(key);\n             if (it == cells.end())\n-            {\n-                // Queue became inconsistent\n-                abort();\n-            }\n+                std::terminate(); // Queue became inconsistent\n \n             const auto & cell = it->second;\n \n@@ -190,10 +199,7 @@ class LRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n         on_weight_loss_function(current_weight_lost);\n \n         if (current_size_in_bytes > (1ull << 63))\n-        {\n-            // Queue became inconsistent\n-            abort();\n-        }\n+            std::terminate(); // Queue became inconsistent\n     }\n };\n \ndiff --git a/src/Common/SLRUCachePolicy.h b/src/Common/SLRUCachePolicy.h\nindex 62ceda82ceb0..f2e4586902df 100644\n--- a/src/Common/SLRUCachePolicy.h\n+++ b/src/Common/SLRUCachePolicy.h\n@@ -9,9 +9,8 @@ namespace DB\n {\n \n /// Cache policy SLRU evicts entries which were used only once and are not used for a long time,\n-/// this policy protects entries which were used more then once from a sequential scan.\n-/// WeightFunction is a functor that takes Mapped as a parameter and returns \"weight\" (approximate size)\n-/// of that value.\n+/// this policy protects entries which were used more then once from a sequential scan. Also see cache policy LRU for reference.\n+/// WeightFunction is a functor that takes Mapped as a parameter and returns \"weight\" (approximate size) of that value.\n /// Cache starts to evict entries when their total weight exceeds max_size_in_bytes.\n /// Value weight should not change after insertion.\n /// To work with the thread-safe implementation of this class use a class \"CacheBase\" with first parameter \"SLRU\"\n@@ -30,8 +29,9 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n       * max_protected_size == 0 means that the default protected size is equal to half of the total max size.\n       */\n     /// TODO: construct from special struct with cache policy parameters (also with max_protected_size).\n-    SLRUCachePolicy(size_t max_size_in_bytes_, size_t max_count_, double size_ratio, OnWeightLossFunction on_weight_loss_function_)\n+    SLRUCachePolicy(size_t max_size_in_bytes_, size_t max_count_, double size_ratio_, OnWeightLossFunction on_weight_loss_function_)\n         : Base(std::make_unique<NoCachePolicyUserQuota>())\n+        , size_ratio(size_ratio_)\n         , max_protected_size(static_cast<size_t>(max_size_in_bytes_ * std::min(1.0, size_ratio)))\n         , max_size_in_bytes(max_size_in_bytes_)\n         , max_count(max_count_)\n@@ -54,7 +54,22 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n         return max_size_in_bytes;\n     }\n \n-    void reset(std::lock_guard<std::mutex> & /* cache_lock */) override\n+    void setMaxCount(size_t max_count_, std::lock_guard<std::mutex> & /* cache_lock */) override\n+    {\n+        max_count = max_count_;\n+        removeOverflow(protected_queue, max_protected_size, current_protected_size, /*is_protected=*/true);\n+        removeOverflow(probationary_queue, max_size_in_bytes, current_size_in_bytes, /*is_protected=*/false);\n+    }\n+\n+    void setMaxSize(size_t max_size_in_bytes_, std::lock_guard<std::mutex> & /* cache_lock */) override\n+    {\n+        max_protected_size = static_cast<size_t>(max_size_in_bytes_ * std::min(1.0, size_ratio));\n+        max_size_in_bytes = max_size_in_bytes_;\n+        removeOverflow(protected_queue, max_protected_size, current_protected_size, /*is_protected=*/true);\n+        removeOverflow(probationary_queue, max_size_in_bytes, current_size_in_bytes, /*is_protected=*/false);\n+    }\n+\n+    void clear(std::lock_guard<std::mutex> & /* cache_lock */) override\n     {\n         cells.clear();\n         probationary_queue.clear();\n@@ -68,12 +83,13 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n         auto it = cells.find(key);\n         if (it == cells.end())\n             return;\n+\n         auto & cell = it->second;\n+\n         current_size_in_bytes -= cell.size;\n         if (cell.is_protected)\n-        {\n             current_protected_size -= cell.size;\n-        }\n+\n         auto & queue = cell.is_protected ? protected_queue : probationary_queue;\n         queue.erase(cell.queue_iterator);\n         cells.erase(it);\n@@ -192,16 +208,17 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n \n     Cells cells;\n \n+    const double size_ratio;\n     size_t current_protected_size = 0;\n     size_t current_size_in_bytes = 0;\n-    const size_t max_protected_size;\n-    const size_t max_size_in_bytes;\n-    const size_t max_count;\n+    size_t max_protected_size;\n+    size_t max_size_in_bytes;\n+    size_t max_count;\n \n     WeightFunction weight_function;\n     OnWeightLossFunction on_weight_loss_function;\n \n-    void removeOverflow(SLRUQueue & queue, const size_t max_weight_size, size_t & current_weight_size, bool is_protected)\n+    void removeOverflow(SLRUQueue & queue, size_t max_weight_size, size_t & current_weight_size, bool is_protected)\n     {\n         size_t current_weight_lost = 0;\n         size_t queue_size = queue.size();\n@@ -223,8 +240,7 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n         {\n             need_remove = [&]()\n             {\n-                return ((max_count != 0 && cells.size() > max_count)\n-                || (current_weight_size > max_weight_size)) && (queue_size > 0);\n+                return ((max_count != 0 && cells.size() > max_count) || (current_weight_size > max_weight_size)) && (queue_size > 0);\n             };\n         }\n \n@@ -234,10 +250,7 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n \n             auto it = cells.find(key);\n             if (it == cells.end())\n-            {\n-                // Queue became inconsistent\n-                abort();\n-            }\n+                std::terminate(); // Queue became inconsistent\n \n             auto & cell = it->second;\n \n@@ -262,10 +275,7 @@ class SLRUCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFun\n             on_weight_loss_function(current_weight_lost);\n \n         if (current_size_in_bytes > (1ull << 63))\n-        {\n-            // Queue became inconsistent\n-            abort();\n-        }\n+            std::terminate(); // Queue became inconsistent\n     }\n };\n \ndiff --git a/src/Common/TTLCachePolicy.h b/src/Common/TTLCachePolicy.h\nindex 93bbec0d76bf..3b87936b8f93 100644\n--- a/src/Common/TTLCachePolicy.h\n+++ b/src/Common/TTLCachePolicy.h\n@@ -121,7 +121,7 @@ class TTLCachePolicy : public ICachePolicy<Key, Mapped, HashFunction, WeightFunc\n         max_size_in_bytes = max_size_in_bytes_;\n     }\n \n-    void reset(std::lock_guard<std::mutex> & /* cache_lock */) override\n+    void clear(std::lock_guard<std::mutex> & /* cache_lock */) override\n     {\n         cache.clear();\n     }\ndiff --git a/src/Core/ServerSettings.h b/src/Core/ServerSettings.h\nindex 3740929b4915..5f419ef051c7 100644\n--- a/src/Core/ServerSettings.h\n+++ b/src/Core/ServerSettings.h\n@@ -39,7 +39,7 @@ namespace DB\n     M(UInt64, restore_threads, 16, \"The maximum number of threads to execute RESTORE requests.\", 0) \\\n     M(Int32, max_connections, 1024, \"Max server connections.\", 0) \\\n     M(UInt32, asynchronous_metrics_update_period_s, 1, \"Period in seconds for updating asynchronous metrics.\", 0) \\\n-    M(UInt32, asynchronous_heavy_metrics_update_period_s, 120, \"Period in seconds for updating asynchronous metrics.\", 0) \\\n+    M(UInt32, asynchronous_heavy_metrics_update_period_s, 120, \"Period in seconds for updating heavy asynchronous metrics.\", 0) \\\n     M(String, default_database, \"default\", \"Default database name.\", 0) \\\n     M(String, tmp_policy, \"\", \"Policy for storage with temporary data.\", 0) \\\n     M(UInt64, max_temporary_data_on_disk_size, 0, \"The maximum amount of storage that could be used for external aggregation, joins or sorting., \", 0) \\\ndiff --git a/src/Interpreters/Cache/QueryCache.cpp b/src/Interpreters/Cache/QueryCache.cpp\nindex 134aa0956d12..7f84cee56586 100644\n--- a/src/Interpreters/Cache/QueryCache.cpp\n+++ b/src/Interpreters/Cache/QueryCache.cpp\n@@ -471,6 +471,21 @@ std::unique_ptr<SourceFromChunks> QueryCache::Reader::getSourceExtremes()\n     return std::move(source_from_chunks_extremes);\n }\n \n+QueryCache::QueryCache(size_t max_size_in_bytes, size_t max_entries, size_t max_entry_size_in_bytes_, size_t max_entry_size_in_rows_)\n+    : cache(std::make_unique<TTLCachePolicy<Key, Entry, KeyHasher, QueryCacheEntryWeight, IsStale>>(std::make_unique<PerUserTTLCachePolicyUserQuota>()))\n+{\n+    updateConfiguration(max_size_in_bytes, max_entries, max_entry_size_in_bytes_, max_entry_size_in_rows_);\n+}\n+\n+void QueryCache::updateConfiguration(size_t max_size_in_bytes, size_t max_entries, size_t max_entry_size_in_bytes_, size_t max_entry_size_in_rows_)\n+{\n+    std::lock_guard lock(mutex);\n+    cache.setMaxSize(max_size_in_bytes);\n+    cache.setMaxCount(max_entries);\n+    max_entry_size_in_bytes = max_entry_size_in_bytes_;\n+    max_entry_size_in_rows = max_entry_size_in_rows_;\n+}\n+\n QueryCache::Reader QueryCache::createReader(const Key & key)\n {\n     std::lock_guard lock(mutex);\n@@ -488,9 +503,9 @@ QueryCache::Writer QueryCache::createWriter(const Key & key, std::chrono::millis\n     return Writer(cache, key, max_entry_size_in_bytes, max_entry_size_in_rows, min_query_runtime, squash_partial_results, max_block_size);\n }\n \n-void QueryCache::reset()\n+void QueryCache::clear()\n {\n-    cache.reset();\n+    cache.clear();\n     std::lock_guard lock(mutex);\n     times_executed.clear();\n }\n@@ -521,19 +536,4 @@ std::vector<QueryCache::Cache::KeyMapped> QueryCache::dump() const\n     return cache.dump();\n }\n \n-QueryCache::QueryCache(size_t max_size_in_bytes, size_t max_entries, size_t max_entry_size_in_bytes_, size_t max_entry_size_in_rows_)\n-    : cache(std::make_unique<TTLCachePolicy<Key, Entry, KeyHasher, QueryCacheEntryWeight, IsStale>>(std::make_unique<PerUserTTLCachePolicyUserQuota>()))\n-{\n-    updateConfiguration(max_size_in_bytes, max_entries, max_entry_size_in_bytes_, max_entry_size_in_rows_);\n-}\n-\n-void QueryCache::updateConfiguration(size_t max_size_in_bytes, size_t max_entries, size_t max_entry_size_in_bytes_, size_t max_entry_size_in_rows_)\n-{\n-    std::lock_guard lock(mutex);\n-    cache.setMaxSize(max_size_in_bytes);\n-    cache.setMaxCount(max_entries);\n-    max_entry_size_in_bytes = max_entry_size_in_bytes_;\n-    max_entry_size_in_rows = max_entry_size_in_rows_;\n-}\n-\n }\ndiff --git a/src/Interpreters/Cache/QueryCache.h b/src/Interpreters/Cache/QueryCache.h\nindex 0c0674c63020..27028536ded1 100644\n--- a/src/Interpreters/Cache/QueryCache.h\n+++ b/src/Interpreters/Cache/QueryCache.h\n@@ -180,7 +180,7 @@ class QueryCache\n     Reader createReader(const Key & key);\n     Writer createWriter(const Key & key, std::chrono::milliseconds min_query_runtime, bool squash_partial_results, size_t max_block_size, size_t max_query_cache_size_in_bytes_quota, size_t max_query_cache_entries_quota);\n \n-    void reset();\n+    void clear();\n \n     size_t weight() const;\n     size_t count() const;\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex 4f58e7c3401c..254d272ad977 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -547,7 +547,7 @@ struct ContextSharedPart : boost::noncopyable\n               */\n #if USE_EMBEDDED_COMPILER\n             if (auto * cache = CompiledExpressionCacheFactory::instance().tryGetCache())\n-                cache->reset();\n+                cache->clear();\n #endif\n \n             /// Preemptive destruction is important, because these objects may have a refcount to ContextShared (cyclic reference).\n@@ -2261,6 +2261,16 @@ void Context::setUncompressedCache(const String & uncompressed_cache_policy, siz\n     shared->uncompressed_cache = std::make_shared<UncompressedCache>(uncompressed_cache_policy, max_size_in_bytes);\n }\n \n+void Context::updateUncompressedCacheConfiguration(const Poco::Util::AbstractConfiguration & config)\n+{\n+    auto lock = getLock();\n+\n+    if (!shared->uncompressed_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Uncompressed cache was not created yet.\");\n+\n+    size_t max_size_in_bytes = config.getUInt64(\"uncompressed_cache_size\", DEFAULT_UNCOMPRESSED_CACHE_MAX_SIZE);\n+    shared->uncompressed_cache->setMaxSize(max_size_in_bytes);\n+}\n \n UncompressedCachePtr Context::getUncompressedCache() const\n {\n@@ -2268,15 +2278,14 @@ UncompressedCachePtr Context::getUncompressedCache() const\n     return shared->uncompressed_cache;\n }\n \n-\n void Context::clearUncompressedCache() const\n {\n     auto lock = getLock();\n+\n     if (shared->uncompressed_cache)\n-        shared->uncompressed_cache->reset();\n+        shared->uncompressed_cache->clear();\n }\n \n-\n void Context::setMarkCache(const String & mark_cache_policy, size_t cache_size_in_bytes)\n {\n     auto lock = getLock();\n@@ -2287,6 +2296,17 @@ void Context::setMarkCache(const String & mark_cache_policy, size_t cache_size_i\n     shared->mark_cache = std::make_shared<MarkCache>(mark_cache_policy, cache_size_in_bytes);\n }\n \n+void Context::updateMarkCacheConfiguration(const Poco::Util::AbstractConfiguration & config)\n+{\n+    auto lock = getLock();\n+\n+    if (!shared->mark_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Mark cache was not created yet.\");\n+\n+    size_t max_size_in_bytes = config.getUInt64(\"mark_cache_size\", DEFAULT_MARK_CACHE_MAX_SIZE);\n+    shared->mark_cache->setMaxSize(max_size_in_bytes);\n+}\n+\n MarkCachePtr Context::getMarkCache() const\n {\n     auto lock = getLock();\n@@ -2296,8 +2316,9 @@ MarkCachePtr Context::getMarkCache() const\n void Context::clearMarkCache() const\n {\n     auto lock = getLock();\n+\n     if (shared->mark_cache)\n-        shared->mark_cache->reset();\n+        shared->mark_cache->clear();\n }\n \n ThreadPool & Context::getLoadMarksThreadpool() const\n@@ -2325,21 +2346,31 @@ void Context::setIndexUncompressedCache(size_t max_size_in_bytes)\n     shared->index_uncompressed_cache = std::make_shared<UncompressedCache>(max_size_in_bytes);\n }\n \n+void Context::updateIndexUncompressedCacheConfiguration(const Poco::Util::AbstractConfiguration & config)\n+{\n+    auto lock = getLock();\n+\n+    if (!shared->index_uncompressed_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Index uncompressed cache was not created yet.\");\n+\n+    size_t max_size_in_bytes = config.getUInt64(\"index_uncompressed_cache_size\", DEFAULT_INDEX_UNCOMPRESSED_CACHE_MAX_SIZE);\n+    shared->index_uncompressed_cache->setMaxSize(max_size_in_bytes);\n+}\n+\n UncompressedCachePtr Context::getIndexUncompressedCache() const\n {\n     auto lock = getLock();\n     return shared->index_uncompressed_cache;\n }\n \n-\n void Context::clearIndexUncompressedCache() const\n {\n     auto lock = getLock();\n+\n     if (shared->index_uncompressed_cache)\n-        shared->index_uncompressed_cache->reset();\n+        shared->index_uncompressed_cache->clear();\n }\n \n-\n void Context::setIndexMarkCache(size_t cache_size_in_bytes)\n {\n     auto lock = getLock();\n@@ -2350,6 +2381,17 @@ void Context::setIndexMarkCache(size_t cache_size_in_bytes)\n     shared->index_mark_cache = std::make_shared<MarkCache>(cache_size_in_bytes);\n }\n \n+void Context::updateIndexMarkCacheConfiguration(const Poco::Util::AbstractConfiguration & config)\n+{\n+    auto lock = getLock();\n+\n+    if (!shared->index_mark_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Index mark cache was not created yet.\");\n+\n+    size_t max_size_in_bytes = config.getUInt64(\"index_mark_cache_size\", DEFAULT_INDEX_MARK_CACHE_MAX_SIZE);\n+    shared->index_mark_cache->setMaxSize(max_size_in_bytes);\n+}\n+\n MarkCachePtr Context::getIndexMarkCache() const\n {\n     auto lock = getLock();\n@@ -2359,8 +2401,9 @@ MarkCachePtr Context::getIndexMarkCache() const\n void Context::clearIndexMarkCache() const\n {\n     auto lock = getLock();\n+\n     if (shared->index_mark_cache)\n-        shared->index_mark_cache->reset();\n+        shared->index_mark_cache->clear();\n }\n \n void Context::setMMappedFileCache(size_t cache_size_in_num_entries)\n@@ -2373,6 +2416,17 @@ void Context::setMMappedFileCache(size_t cache_size_in_num_entries)\n     shared->mmap_cache = std::make_shared<MMappedFileCache>(cache_size_in_num_entries);\n }\n \n+void Context::updateMMappedFileCacheConfiguration(const Poco::Util::AbstractConfiguration & config)\n+{\n+    auto lock = getLock();\n+\n+    if (!shared->mmap_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Mapped file cache was not created yet.\");\n+\n+    size_t max_size_in_bytes = config.getUInt64(\"mmap_cache_size\", DEFAULT_MMAP_CACHE_MAX_SIZE);\n+    shared->mmap_cache->setMaxSize(max_size_in_bytes);\n+}\n+\n MMappedFileCachePtr Context::getMMappedFileCache() const\n {\n     auto lock = getLock();\n@@ -2382,8 +2436,9 @@ MMappedFileCachePtr Context::getMMappedFileCache() const\n void Context::clearMMappedFileCache() const\n {\n     auto lock = getLock();\n+\n     if (shared->mmap_cache)\n-        shared->mmap_cache->reset();\n+        shared->mmap_cache->clear();\n }\n \n void Context::setQueryCache(size_t max_size_in_bytes, size_t max_entries, size_t max_entry_size_in_bytes, size_t max_entry_size_in_rows)\n@@ -2399,14 +2454,15 @@ void Context::setQueryCache(size_t max_size_in_bytes, size_t max_entries, size_t\n void Context::updateQueryCacheConfiguration(const Poco::Util::AbstractConfiguration & config)\n {\n     auto lock = getLock();\n-    if (shared->query_cache)\n-    {\n-        size_t max_size_in_bytes = config.getUInt64(\"query_cache.max_size_in_bytes\", DEFAULT_QUERY_CACHE_MAX_SIZE);\n-        size_t max_entries = config.getUInt64(\"query_cache.max_entries\", DEFAULT_QUERY_CACHE_MAX_ENTRIES);\n-        size_t max_entry_size_in_bytes = config.getUInt64(\"query_cache.max_entry_size_in_bytes\", DEFAULT_QUERY_CACHE_MAX_ENTRY_SIZE_IN_BYTES);\n-        size_t max_entry_size_in_rows = config.getUInt64(\"query_cache.max_entry_rows_in_rows\", DEFAULT_QUERY_CACHE_MAX_ENTRY_SIZE_IN_ROWS);\n-        shared->query_cache->updateConfiguration(max_size_in_bytes, max_entries, max_entry_size_in_bytes, max_entry_size_in_rows);\n-    }\n+\n+    if (!shared->query_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Query cache was not created yet.\");\n+\n+    size_t max_size_in_bytes = config.getUInt64(\"query_cache.max_size_in_bytes\", DEFAULT_QUERY_CACHE_MAX_SIZE);\n+    size_t max_entries = config.getUInt64(\"query_cache.max_entries\", DEFAULT_QUERY_CACHE_MAX_ENTRIES);\n+    size_t max_entry_size_in_bytes = config.getUInt64(\"query_cache.max_entry_size_in_bytes\", DEFAULT_QUERY_CACHE_MAX_ENTRY_SIZE_IN_BYTES);\n+    size_t max_entry_size_in_rows = config.getUInt64(\"query_cache.max_entry_rows_in_rows\", DEFAULT_QUERY_CACHE_MAX_ENTRY_SIZE_IN_ROWS);\n+    shared->query_cache->updateConfiguration(max_size_in_bytes, max_entries, max_entry_size_in_bytes, max_entry_size_in_rows);\n }\n \n QueryCachePtr Context::getQueryCache() const\n@@ -2418,30 +2474,36 @@ QueryCachePtr Context::getQueryCache() const\n void Context::clearQueryCache() const\n {\n     auto lock = getLock();\n+\n     if (shared->query_cache)\n-        shared->query_cache->reset();\n+        shared->query_cache->clear();\n }\n \n void Context::clearCaches() const\n {\n     auto lock = getLock();\n \n-    if (shared->uncompressed_cache)\n-        shared->uncompressed_cache->reset();\n+    if (!shared->uncompressed_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Uncompressed cache was not created yet.\");\n+    shared->uncompressed_cache->clear();\n \n-    if (shared->mark_cache)\n-        shared->mark_cache->reset();\n+    if (!shared->mark_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Mark cache was not created yet.\");\n+    shared->mark_cache->clear();\n \n-    if (shared->index_uncompressed_cache)\n-        shared->index_uncompressed_cache->reset();\n+    if (!shared->index_uncompressed_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Index uncompressed cache was not created yet.\");\n+    shared->index_uncompressed_cache->clear();\n \n-    if (shared->index_mark_cache)\n-        shared->index_mark_cache->reset();\n+    if (!shared->index_mark_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Index mark cache was not created yet.\");\n+    shared->index_mark_cache->clear();\n \n-    if (shared->mmap_cache)\n-        shared->mmap_cache->reset();\n+    if (!shared->mmap_cache)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Mmapped file cache was not created yet.\");\n+    shared->mmap_cache->clear();\n \n-    /// Intentionally not dropping the query cache which is transactionally inconsistent by design.\n+    /// Intentionally not clearing the query cache which is transactionally inconsistent by design.\n }\n \n ThreadPool & Context::getPrefetchThreadpool() const\ndiff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h\nindex 587fe402d4ec..363c630ba3ce 100644\n--- a/src/Interpreters/Context.h\n+++ b/src/Interpreters/Context.h\n@@ -917,33 +917,32 @@ class Context: public std::enable_shared_from_this<Context>\n \n     /// --- Caches ------------------------------------------------------------------------------------------\n \n-    /// Create a cache of uncompressed blocks of specified size. This can be done only once.\n     void setUncompressedCache(const String & uncompressed_cache_policy, size_t max_size_in_bytes);\n+    void updateUncompressedCacheConfiguration(const Poco::Util::AbstractConfiguration & config);\n     std::shared_ptr<UncompressedCache> getUncompressedCache() const;\n     void clearUncompressedCache() const;\n \n-    /// Create a cache of marks of specified size. This can be done only once.\n     void setMarkCache(const String & mark_cache_policy, size_t cache_size_in_bytes);\n+    void updateMarkCacheConfiguration(const Poco::Util::AbstractConfiguration & config);\n     std::shared_ptr<MarkCache> getMarkCache() const;\n     void clearMarkCache() const;\n     ThreadPool & getLoadMarksThreadpool() const;\n \n-    /// Create a cache of index uncompressed blocks of specified size. This can be done only once.\n     void setIndexUncompressedCache(size_t max_size_in_bytes);\n+    void updateIndexUncompressedCacheConfiguration(const Poco::Util::AbstractConfiguration & config);\n     std::shared_ptr<UncompressedCache> getIndexUncompressedCache() const;\n     void clearIndexUncompressedCache() const;\n \n-    /// Create a cache of index marks of specified size. This can be done only once.\n     void setIndexMarkCache(size_t cache_size_in_bytes);\n+    void updateIndexMarkCacheConfiguration(const Poco::Util::AbstractConfiguration & config);\n     std::shared_ptr<MarkCache> getIndexMarkCache() const;\n     void clearIndexMarkCache() const;\n \n-    /// Create a cache of mapped files to avoid frequent open/map/unmap/close and to reuse from several threads.\n     void setMMappedFileCache(size_t cache_size_in_num_entries);\n+    void updateMMappedFileCacheConfiguration(const Poco::Util::AbstractConfiguration & config);\n     std::shared_ptr<MMappedFileCache> getMMappedFileCache() const;\n     void clearMMappedFileCache() const;\n \n-    /// Create a cache of query results for statements which run repeatedly.\n     void setQueryCache(size_t max_size_in_bytes, size_t max_entries, size_t max_entry_size_in_bytes, size_t max_entry_size_in_rows);\n     void updateQueryCacheConfiguration(const Poco::Util::AbstractConfiguration & config);\n     std::shared_ptr<QueryCache> getQueryCache() const;\ndiff --git a/src/Interpreters/InterpreterSystemQuery.cpp b/src/Interpreters/InterpreterSystemQuery.cpp\nindex 9c8bc256fa25..dd0ee6b44441 100644\n--- a/src/Interpreters/InterpreterSystemQuery.cpp\n+++ b/src/Interpreters/InterpreterSystemQuery.cpp\n@@ -345,7 +345,7 @@ BlockIO InterpreterSystemQuery::execute()\n         case Type::DROP_COMPILED_EXPRESSION_CACHE:\n             getContext()->checkAccess(AccessType::SYSTEM_DROP_COMPILED_EXPRESSION_CACHE);\n             if (auto * cache = CompiledExpressionCacheFactory::instance().tryGetCache())\n-                cache->reset();\n+                cache->clear();\n             break;\n #endif\n #if USE_AWS_S3\ndiff --git a/src/Interpreters/ServerAsynchronousMetrics.cpp b/src/Interpreters/ServerAsynchronousMetrics.cpp\nindex 1b78ff4d2b69..daf896ff67bf 100644\n--- a/src/Interpreters/ServerAsynchronousMetrics.cpp\n+++ b/src/Interpreters/ServerAsynchronousMetrics.cpp\n@@ -6,6 +6,7 @@\n #include <Interpreters/Cache/FileCache.h>\n #include <Interpreters/Cache/FileCacheFactory.h>\n #include <Interpreters/Context.h>\n+#include <Interpreters/Cache/QueryCache.h>\n #include <Interpreters/JIT/CompiledExpressionCache.h>\n \n #include <Databases/IDatabase.h>\n",
  "test_patch": "diff --git a/src/Common/tests/gtest_slru_cache.cpp b/src/Common/tests/gtest_slru_cache.cpp\nindex ed04f427d9d0..76e7df26b7aa 100644\n--- a/src/Common/tests/gtest_slru_cache.cpp\n+++ b/src/Common/tests/gtest_slru_cache.cpp\n@@ -92,7 +92,7 @@ TEST(SLRUCache, removeFromProtected)\n     ASSERT_TRUE(value == nullptr);\n }\n \n-TEST(SLRUCache, reset)\n+TEST(SLRUCache, clear)\n {\n     using SimpleCacheBase = DB::CacheBase<int, int>;\n     auto slru_cache = SimpleCacheBase(\"SLRU\", /*max_size_in_bytes=*/10, /*max_count=*/0, /*size_ratio*/0.5);\n@@ -101,7 +101,7 @@ TEST(SLRUCache, reset)\n \n     slru_cache.set(2, std::make_shared<int>(4)); /// add to protected_queue\n \n-    slru_cache.reset();\n+    slru_cache.clear();\n \n     auto value = slru_cache.get(1);\n     ASSERT_TRUE(value == nullptr);\ndiff --git a/tests/integration/test_runtime_configurable_cache_size/__init__.py b/tests/integration/test_runtime_configurable_cache_size/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_runtime_configurable_cache_size/configs/default.xml b/tests/integration/test_runtime_configurable_cache_size/configs/default.xml\nnew file mode 100644\nindex 000000000000..3500c145a67c\n--- /dev/null\n+++ b/tests/integration/test_runtime_configurable_cache_size/configs/default.xml\n@@ -0,0 +1,9 @@\n+<clickhouse>\n+\n+    <query_cache>\n+        <max_entries>2</max_entries>\n+    </query_cache>\n+\n+    <mark_cache_size>496</mark_cache_size>\n+\n+</clickhouse>\ndiff --git a/tests/integration/test_runtime_configurable_cache_size/configs/smaller_mark_cache.xml b/tests/integration/test_runtime_configurable_cache_size/configs/smaller_mark_cache.xml\nnew file mode 100644\nindex 000000000000..2613b4bbeee6\n--- /dev/null\n+++ b/tests/integration/test_runtime_configurable_cache_size/configs/smaller_mark_cache.xml\n@@ -0,0 +1,5 @@\n+<clickhouse>\n+\n+    <mark_cache_size>248</mark_cache_size>\n+\n+</clickhouse>\ndiff --git a/tests/integration/test_runtime_configurable_cache_size/configs/smaller_query_cache.xml b/tests/integration/test_runtime_configurable_cache_size/configs/smaller_query_cache.xml\nnew file mode 100644\nindex 000000000000..6f2de0fa8f53\n--- /dev/null\n+++ b/tests/integration/test_runtime_configurable_cache_size/configs/smaller_query_cache.xml\n@@ -0,0 +1,7 @@\n+<clickhouse>\n+\n+    <query_cache>\n+        <max_entries>1</max_entries>\n+    </query_cache>\n+\n+</clickhouse>\ndiff --git a/tests/integration/test_runtime_configurable_cache_size/test.py b/tests/integration/test_runtime_configurable_cache_size/test.py\nnew file mode 100644\nindex 000000000000..6119ff1ebea3\n--- /dev/null\n+++ b/tests/integration/test_runtime_configurable_cache_size/test.py\n@@ -0,0 +1,144 @@\n+import os\n+import pytest\n+import shutil\n+import time\n+from helpers.cluster import ClickHouseCluster\n+\n+# Tests that sizes of in-memory caches (mark / uncompressed / index mark / index uncompressed / mmapped file / query cache) can be changed\n+# at runtime (issue #51085). This file tests only the mark cache (which uses the SLRU cache policy) and the query cache (which uses the TTL\n+# cache policy). As such, both tests are representative for the other caches.\n+\n+cluster = ClickHouseCluster(__file__)\n+node = cluster.add_instance(\n+    \"node\",\n+    main_configs=[\"configs/default.xml\"],\n+    stay_alive=True,\n+)\n+\n+\n+@pytest.fixture(scope=\"module\")\n+def start_cluster():\n+    try:\n+        cluster.start()\n+        yield cluster\n+    finally:\n+        cluster.shutdown()\n+\n+\n+SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))\n+CONFIG_DIR = os.path.join(SCRIPT_DIR, \"configs\")\n+\n+\n+# temporarily disabled due to https://github.com/ClickHouse/ClickHouse/pull/51446#issuecomment-1687066351\n+# def test_mark_cache_size_is_runtime_configurable(start_cluster):\n+#     # the initial config specifies the mark cache size as 496 bytes, just enough to hold two marks\n+#     node.query(\"SYSTEM DROP MARK CACHE\")\n+#\n+#     node.query(\"CREATE TABLE test1 (val String) ENGINE=MergeTree ORDER BY val\")\n+#     node.query(\"INSERT INTO test1 VALUES ('abc') ('def') ('ghi')\")\n+#     node.query(\"SELECT * FROM test1 WHERE val = 'def'\")  # cache 1st mark\n+#\n+#     node.query(\"CREATE TABLE test2 (val String) ENGINE=MergeTree ORDER BY val\")\n+#     node.query(\"INSERT INTO test2 VALUES ('abc') ('def') ('ghi')\")\n+#     node.query(\"SELECT * FROM test2 WHERE val = 'def'\")  # cache 2nd mark\n+#\n+#     # Result checking is based on asynchronous metrics. These are calculated by default every 1.0 sec, and this is also the\n+#     # smallest possible value. Found no statement to force-recalculate them, therefore waaaaait...\n+#     time.sleep(2.0)\n+#     res = node.query(\n+#         \"SELECT value FROM system.asynchronous_metrics WHERE metric LIKE 'MarkCacheFiles'\"\n+#     )\n+#     assert res == \"2\\n\"\n+#     res = node.query(\n+#         \"SELECT value FROM system.asynchronous_metrics WHERE metric LIKE 'MarkCacheBytes'\"\n+#     )\n+#     assert res == \"496\\n\"\n+#\n+#     # switch to a config with a mark cache size of 248 bytes\n+#     node.copy_file_to_container(\n+#         os.path.join(CONFIG_DIR, \"smaller_mark_cache.xml\"),\n+#         \"/etc/clickhouse-server/config.d/default.xml\",\n+#     )\n+#\n+#     node.query(\"SYSTEM RELOAD CONFIG\")\n+#\n+#     # check that eviction worked as expected\n+#     time.sleep(2.0)\n+#     res = node.query(\n+#         \"SELECT value FROM system.asynchronous_metrics WHERE metric LIKE 'MarkCacheFiles'\"\n+#     )\n+#     assert res == \"1\\n\"\n+#     res = node.query(\n+#         \"SELECT value FROM system.asynchronous_metrics WHERE metric LIKE 'MarkCacheBytes'\"\n+#     )\n+#     assert res == \"248\\n\"\n+#\n+#     # check that the new mark cache maximum size is respected when more marks are cached\n+#     node.query(\"CREATE TABLE test3 (val String) ENGINE=MergeTree ORDER BY val\")\n+#     node.query(\"INSERT INTO test3 VALUES ('abc') ('def') ('ghi')\")\n+#     node.query(\"SELECT * FROM test3 WHERE val = 'def'\")\n+#     time.sleep(2.0)\n+#     res = node.query(\n+#         \"SELECT value FROM system.asynchronous_metrics WHERE metric LIKE 'MarkCacheFiles'\"\n+#     )\n+#     assert res == \"1\\n\"\n+#     res = node.query(\n+#         \"SELECT value FROM system.asynchronous_metrics WHERE metric LIKE 'MarkCacheBytes'\"\n+#     )\n+#     assert res == \"248\\n\"\n+#\n+#     # restore the original config\n+#     node.copy_file_to_container(\n+#         os.path.join(CONFIG_DIR, \"default.xml\"),\n+#         \"/etc/clickhouse-server/config.d/default.xml\",\n+#     )\n+\n+\n+def test_query_cache_size_is_runtime_configurable(start_cluster):\n+    # the inital config specifies the maximum query cache size as 2, run 3 queries, expect 2 cache entries\n+    node.query(\"SYSTEM DROP QUERY CACHE\")\n+    node.query(\"SELECT 1 SETTINGS use_query_cache = 1, query_cache_ttl = 1\")\n+    node.query(\"SELECT 2 SETTINGS use_query_cache = 1, query_cache_ttl = 1\")\n+    node.query(\"SELECT 3 SETTINGS use_query_cache = 1, query_cache_ttl = 1\")\n+\n+    time.sleep(2.0)\n+    res = node.query(\n+        \"SELECT value FROM system.asynchronous_metrics WHERE metric = 'QueryCacheEntries'\"\n+    )\n+    assert res == \"2\\n\"\n+\n+    # switch to a config with a maximum query cache size of 1\n+    node.copy_file_to_container(\n+        os.path.join(CONFIG_DIR, \"smaller_query_cache.xml\"),\n+        \"/etc/clickhouse-server/config.d/default.xml\",\n+    )\n+\n+    node.query(\"SYSTEM RELOAD CONFIG\")\n+\n+    # check that eviction worked as expected\n+    time.sleep(2.0)\n+    res = node.query(\n+        \"SELECT value FROM system.asynchronous_metrics WHERE metric = 'QueryCacheEntries'\"\n+    )\n+    assert (\n+        res == \"2\\n\"\n+    )  # \"Why not 1?\", you think. Reason is that QC uses the TTLCachePolicy that evicts lazily only upon insert.\n+    # Not a real issue, can be changed later, at least there's a test now.\n+\n+    # Also, you may also wonder \"why query_cache_ttl = 1\"? Reason is that TTLCachePolicy only removes *stale* entries. With the default TTL\n+    # (60 sec), no entries would be removed at all. Again: not a real issue, can be changed later and there's at least a test now.\n+\n+    # check that the new query cache maximum size is respected when more queries run\n+    node.query(\"SELECT 4 SETTINGS use_query_cache = 1, query_cache_ttl = 1\")\n+    node.query(\"SELECT 5 SETTINGS use_query_cache = 1, query_cache_ttl = 1\")\n+    time.sleep(2.0)\n+    res = node.query(\n+        \"SELECT value FROM system.asynchronous_metrics WHERE metric = 'QueryCacheEntries'\"\n+    )\n+    assert res == \"1\\n\"\n+\n+    # restore the original config\n+    node.copy_file_to_container(\n+        os.path.join(CONFIG_DIR, \"default.xml\"),\n+        \"/etc/clickhouse-server/config.d/default.xml\",\n+    )\n",
  "problem_statement": "Dynamically update `mark_cache_size`, `index_mark_cache_size` and `mmap_cache_size` from config\nNow, `mark_cache_size`, `index_mark_cache_size` and `mmap_cache_size` are set at server startup and never changes.\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/1cb7ba4895e0666eeba8654a45ec8c124b904864/programs/server/Server.cpp#L1459-L1466\r\n\r\nWe can support that settings into `ConfigReloader` as well. Caches should support dynamic changes in size.\r\nIn case if cache uses more memory than changed limit, some entries should be ejected instantly.\r\nAt least for LRU it should be easy: just call `removeOverflow`\r\nhttps://github.com/ClickHouse/ClickHouse/blob/ab6ac6beb19ae23d0676f7626c6fa9b72353de3e/src/Common/LRUCachePolicy.h#L128\r\n\r\n\r\n\n",
  "hints_text": "@KochetovNicolai Hi\uff0cI'm Feng Wen(ext-alicloud). Will `uncompressed_cache_size` also support dynamic change ?\n In my linked PR, all caches support dynamic reconfiguration.",
  "created_at": "2023-06-26T19:25:10Z"
}