{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 11330,
  "instance_id": "ClickHouse__ClickHouse-11330",
  "issue_numbers": [
    "10241"
  ],
  "base_commit": "c22e8f6b9b287d269fd1087b5e241a7ea3f87349",
  "patch": "diff --git a/src/DataStreams/PushingToViewsBlockOutputStream.cpp b/src/DataStreams/PushingToViewsBlockOutputStream.cpp\nindex 7f730b5fd3f2..b7a5c3f34e46 100644\n--- a/src/DataStreams/PushingToViewsBlockOutputStream.cpp\n+++ b/src/DataStreams/PushingToViewsBlockOutputStream.cpp\n@@ -153,7 +153,7 @@ void PushingToViewsBlockOutputStream::write(const Block & block)\n     const Settings & settings = context.getSettingsRef();\n     if (settings.parallel_view_processing && views.size() > 1)\n     {\n-        // Push to views concurrently if enabled, and more than one view is attached\n+        // Push to views concurrently if enabled and more than one view is attached\n         ThreadPool pool(std::min(size_t(settings.max_threads), views.size()));\n         for (size_t view_num = 0; view_num < views.size(); ++view_num)\n         {\n@@ -208,6 +208,45 @@ void PushingToViewsBlockOutputStream::writeSuffix()\n \n     std::exception_ptr first_exception;\n \n+    const Settings & settings = context.getSettingsRef();\n+    bool parallel_processing = false;\n+\n+    /// Run writeSuffix() for views in separate thread pool.\n+    /// In could have been done in PushingToViewsBlockOutputStream::process, however\n+    /// it is not good if insert into main table fail but into view succeed.\n+    if (settings.parallel_view_processing && views.size() > 1)\n+    {\n+        parallel_processing = true;\n+\n+        // Push to views concurrently if enabled and more than one view is attached\n+        ThreadPool pool(std::min(size_t(settings.max_threads), views.size()));\n+        auto thread_group = CurrentThread::getGroup();\n+\n+        for (auto & view : views)\n+        {\n+            if (view.exception)\n+                continue;\n+\n+            pool.scheduleOrThrowOnError([thread_group, &view]\n+            {\n+                setThreadName(\"PushingToViews\");\n+                if (thread_group)\n+                    CurrentThread::attachToIfDetached(thread_group);\n+\n+                try\n+                {\n+                    view.out->writeSuffix();\n+                }\n+                catch (...)\n+                {\n+                    view.exception = std::current_exception();\n+                }\n+            });\n+        }\n+        // Wait for concurrent view processing\n+        pool.wait();\n+    }\n+\n     for (auto & view : views)\n     {\n         if (view.exception)\n@@ -218,6 +257,9 @@ void PushingToViewsBlockOutputStream::writeSuffix()\n             continue;\n         }\n \n+        if (parallel_processing)\n+            continue;\n+\n         try\n         {\n             view.out->writeSuffix();\n",
  "test_patch": "diff --git a/tests/performance/parallel_mv.xml b/tests/performance/parallel_mv.xml\nnew file mode 100644\nindex 000000000000..ef50d5067085\n--- /dev/null\n+++ b/tests/performance/parallel_mv.xml\n@@ -0,0 +1,24 @@\n+<test>\n+    <settings>\n+        <parallel_view_processing>1</parallel_view_processing>\n+    </settings>\n+\n+    <create_query>create table main_table (number UInt64) engine = MergeTree order by tuple();</create_query>\n+    <create_query>create materialized view mv_1 engine = MergeTree order by tuple() as\n+        select number, toString(number) from main_table where number % 13 != 0;</create_query>\n+    <create_query>create materialized view mv_2 engine = MergeTree order by tuple() as\n+        select number, toString(number) from main_table where number % 13 != 1;</create_query>\n+    <create_query>create materialized view mv_3 engine = MergeTree order by tuple() as\n+        select number, toString(number) from main_table where number % 13 != 3;</create_query>\n+    <create_query>create materialized view mv_4 engine = MergeTree order by tuple() as\n+        select number, toString(number) from main_table where number % 13 != 4;</create_query>\n+\n+    <!--<query>insert into main_table select number from numbers(100000)</query>-->\n+    <query>insert into main_table select number from numbers(1000000)</query>\n+\n+    <drop_query>drop table if exists main_table;</drop_query>\n+    <drop_query>drop table if exists mv_1;</drop_query>\n+    <drop_query>drop table if exists mv_2;</drop_query>\n+    <drop_query>drop table if exists mv_3;</drop_query>\n+    <drop_query>drop table if exists mv_4;</drop_query>\n+</test>\n",
  "problem_statement": "parallel_view_processing behavior has changed.\nparallel_view_processing=1\r\n\r\n```\r\ndrop table if exists testX;\r\ndrop table if exists testXA;\r\ndrop table if exists testXB;\r\ndrop table if exists testXC;\r\ncreate table testX ( A Int64) engine=MergeTree order by tuple();\r\n\r\ncreate materialized view testXA engine=MergeTree order by tuple() \r\nas select sleep(1) from testX;\r\n\r\ncreate materialized view testXB engine=MergeTree order by tuple() \r\nas select sleep(2),throwIf(A=1) from testX;\r\n\r\ncreate materialized view testXC engine=MergeTree order by tuple() \r\nas select sleep(1) from testX;\r\n\r\ninsert into testX select number from numbers(10);\r\nselect count() from testX;\r\nselect count() from testXA;\r\nselect count() from testXB;\r\nselect count() from testXC; \r\n```\r\n\r\n18.14.18\r\n10\r\n10\r\n0\r\n10\r\n\r\n19.13.7.57\r\n10\r\n0\r\n0\r\n0\r\n\r\n18.14.18\r\n```\r\n26.891574 [ 23 ]  <Debug> executeQuery: (from [::1]:33136) insert into testX select number from numbers(10)\r\n26.891788 [ 23 ]  <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n26.891846 [ 23 ]  <Debug> executeQuery: Query pipeline:\r\n26.892203 [ 208 ]  <Trace> dw.testX (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n26.892487 [ 209 ]  <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n26.892528 [ 211 ]  <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n26.892531 [ 210 ]  <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n27.892829 [ 209 ]  <Trace> dw..inner.testXC (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n27.892862 [ 211 ]  <Trace> dw..inner.testXA (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n28.892788 [ 210 ]  <Trace> ThreadStatus: Thread 210 exited\r\n28.892788 [ 209 ]  <Trace> ThreadStatus: Thread 209 exited\r\n28.892829 [ 211 ]  <Trace> ThreadStatus: Thread 211 exited\r\n28.892956 [ 208 ]  <Trace> ThreadStatus: Thread 208 exited\r\n28.893027 [ 23 ]  <Error> executeQuery: Code: 395, e.displayText() = DB::Exception: Value passed to 'throwIf' \r\n28.893086 [ 23 ]  <Debug> MemoryTracker: Peak memory usage (for query): 4.02 MiB.\r\n```\r\nThreads 209, 211 did insert before Exception\r\n\r\n19.13.7.57\r\n\r\n```\r\n15.756235 [ 8174 ] <Debug> executeQuery: (from [::1]:53622) INSERT INTO testX SELECT number FROM numbers(10)\r\n15.756628 [ 8174 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n15.756696 [ 8174 ] <Debug> executeQuery: Query pipeline:\r\n15.757001 [ 30 ] <Trace> dw.testX: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n15.757196 [ 120 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n15.757196 [ 50 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n15.757314 [ 81 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n17.757825 [ 8174 ] <Error> executeQuery: Code: 395, e.displayText() = DB::Exception: Value passed to 'throwIf' \r\n17.757901 [ 8174 ] <Debug> MemoryTracker: Peak memory usage (for query): 2.30 KiB.\r\n17.757961 [ 8174 ] <Debug> MemoryTracker: Peak memory usage (total): 2.30 KiB.\r\n17.757976 [ 8174 ] <Information> TCPHandler: Processed in 2.002 sec.\r\n```\r\nThreads 120, 81 never inserted\r\n\r\n\r\nWe suspect it impacts performance because INSERTS start after all SELECTS (for 1 block ?) finished.\n",
  "hints_text": "The performance impact is visible with a high number of MVs.\r\n\r\n```\r\ndrop table if exists testX;\r\ndrop table if exists testXA;\r\ndrop table if exists testXB;\r\ndrop table if exists testXC;\r\ndrop table if exists testXD;\r\ndrop table if exists testXE;\r\ndrop table if exists testXF;\r\n\r\ncreate table testX ( A Int64) engine=MergeTree order by tuple();\r\ncreate MATERIALIZED view testXA engine=MergeTree order by tuple() as select * from testX;\r\ncreate MATERIALIZED view testXB engine=MergeTree order by tuple() as select * from testX;\r\ncreate MATERIALIZED view testXC engine=MergeTree order by tuple() as select * from testX;\r\ncreate MATERIALIZED view testXD engine=MergeTree order by tuple() as select * from testX;\r\ncreate MATERIALIZED view testXE engine=MergeTree order by tuple() as select * from testX;\r\ncreate MATERIALIZED view testXF engine=MergeTree order by tuple() as select * from testX;\r\ninsert into testX select number from numbers(100000) settings max_block_size=1000000;\r\n```\r\n\r\n18.14.18 Elapsed: **0.005 sec.** Processed 100.00 thousand rows\r\n```\r\n16.473089 [ 23 ] <Debug> executeQuery: (from [::1]:37306) insert into testX select number from numbers(100000) settings max_block_size=1000000\r\n16.473328 [ 23 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.473386 [ 23 ] <Debug> executeQuery: Query pipeline:\r\n16.474951 [ 224 ] <Trace> dw.testX (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.475310 [ 227 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.475319 [ 226 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.475327 [ 225 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.475349 [ 229 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.475358 [ 228 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.475364 [ 230 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n16.476860 [ 226 ] <Trace> dw..inner.testXB (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.476925 [ 227 ] <Trace> dw..inner.testXE (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.476999 [ 225 ] <Trace> dw..inner.testXA (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.477016 [ 229 ] <Trace> dw..inner.testXC (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.477453 [ 230 ] <Trace> dw..inner.testXD (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.477453 [ 228 ] <Trace> dw..inner.testXF (Data): Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n16.477524 [ 229 ] <Trace> ThreadStatus: Thread 229 exited\r\n16.477526 [ 227 ] <Trace> ThreadStatus: Thread 227 exited\r\n16.477531 [ 228 ] <Trace> ThreadStatus: Thread 228 exited\r\n16.477533 [ 225 ] <Trace> ThreadStatus: Thread 225 exited\r\n16.477528 [ 226 ] <Trace> ThreadStatus: Thread 226 exited\r\n16.477533 [ 230 ] <Trace> ThreadStatus: Thread 230 exited\r\n16.477651 [ 224 ] <Trace> ThreadStatus: Thread 224 exited\r\n16.477696 [ 23 ] <Information> executeQuery: Read 100000 rows, 781.25 KiB in 0.005 sec., 21904293 rows/sec., 167.12 MiB/sec.\r\n16.477703 [ 23 ] <Debug> MemoryTracker: Peak memory usage (for query): 19.81 MiB.\r\n16.477738 [ 23 ] <Information> TCPHandler: Processed in 0.005 sec.\r\n```\r\n\r\n\r\n19.13.7.57 Elapsed: **0.011 sec.** Processed 100.00 thousand rows,\r\n```\r\n\r\n30.642405 [ 8238 ] <Debug> executeQuery: (from [::1]:37958) INSERT INTO testX SELECT number FROM numbers(100000) SETTINGS max_block_size = 1000000\r\n30.642916 [ 8238 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.642994 [ 8238 ] <Debug> executeQuery: Query pipeline:\r\n30.644472 [ 68 ] <Trace> dw.testX: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.644640 [ 110 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.644643 [ 95 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.644654 [ 86 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.644654 [ 71 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.644713 [ 75 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.644713 [ 92 ] <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n30.646644 [ 68 ] <Trace> dw..inner.testXA: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.647871 [ 68 ] <Trace> dw..inner.testXB: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.649033 [ 68 ] <Trace> dw..inner.testXC: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.650233 [ 68 ] <Trace> dw..inner.testXD: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.651459 [ 68 ] <Trace> dw..inner.testXE: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.652714 [ 68 ] <Trace> dw..inner.testXF: Renaming temporary part tmp_insert_all_1_1_0 to all_1_1_0.\r\n30.652812 [ 8238 ] <Information> executeQuery: Read 100000 rows, 781.25 KiB in 0.010 sec., 9649717 rows/sec., 73.62 MiB/sec.\r\n30.652824 [ 8238 ] <Debug> MemoryTracker: Peak memory usage (for query): 6.00 MiB.\r\n30.652873 [ 8238 ] <Debug> MemoryTracker: Peak memory usage (total): 6.00 MiB.\r\n30.652880 [ 8238 ] <Information> TCPHandler: Processed in 0.011 sec.\r\n```\r\n\r\nAll inserts are executed by the same thread [ 68 ]\nThe change happened in September 2019\r\n19.11.11.57 -> 19.11.12.69\r\n19.13.4.32 -> 19.13.5.44\n#7195\nBroken in #3796 if I'm not mistaken.\nThis is not fixed.\r\nI've checked 20.4.4.18, all inserts into MVs are done by the same thread consecutively.\nyes, no  parallelism during  MV inserts  (one thread [ 202101 ]  for all MV)\r\n\r\n20.5.1.3496\r\n\r\ninsert into testX select number from numbers(100000) settings max_block_size=1000000;\r\n\r\nparallel_view_processing=0    **Elapsed: 0.010 sec.** \r\n\r\nparallel_view_processing=1     **Elapsed: 0.010 sec.** / EXPECTED 0.005 sec.\r\n \r\n\r\n```\r\n49.839500 [ 202161 ]  executeQuery: (from [::1]:58112) INSERT INTO testX SELECT number FROM numbers(100000) SETTINGS max_block_size = 1000000\r\n49.839558 [ 202161 ]  ContextAccess (default): Access granted: INSERT(A) ON dw.testX\r\n49.839589 [ 202161 ]  ContextAccess (default): Access granted: CREATE TEMPORARY TABLE ON *.*\r\n49.839694 [ 202161 ]  InterpreterSelectQuery: FetchColumns -> Complete\r\n49.839763 [ 202161 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.839777 [ 202161 ]  ContextAccess (default): Access granted: INSERT(A) ON dw.`.inner.testXA`\r\n49.839816 [ 202161 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.839826 [ 202161 ]  ContextAccess (default): Access granted: INSERT(A) ON dw.`.inner.testXB`\r\n49.839863 [ 202161 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.839873 [ 202161 ]  ContextAccess (default): Access granted: INSERT(A) ON dw.`.inner.testXC`\r\n49.839909 [ 202161 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.839919 [ 202161 ]  ContextAccess (default): Access granted: INSERT(A) ON dw.`.inner.testXD`\r\n49.839954 [ 202161 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.839976 [ 202161 ]  ContextAccess (default): Access granted: INSERT(A) ON dw.`.inner.testXE`\r\n49.840014 [ 202161 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.840024 [ 202161 ]  ContextAccess (default): Access granted: INSERT(A) ON dw.`.inner.testXF`\r\n49.840079 [ 202161 ]  executeQuery: Query pipeline:\r\n49.840317 [ 202101 ]  DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 588.93 GiB.\r\n49.841459 [ 202101 ]  dw.testX: Renaming temporary part tmp_insert_all_4_4_0 to all_4_4_0.\r\n49.841604 [ 202124 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.841632 [ 202143 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.841632 [ 202146 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.841638 [ 202124 ]  InterpreterSelectQuery: FetchColumns -> Complete\r\n49.841641 [ 202157 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.841658 [ 202146 ]  InterpreterSelectQuery: FetchColumns -> Complete\r\n49.841660 [ 202143 ]  InterpreterSelectQuery: FetchColumns -> Complete\r\n49.841669 [ 202157 ]  InterpreterSelectQuery: FetchColumns -> Complete\r\n49.841719 [ 202126 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.841719 [ 202154 ]  ContextAccess (default): Access granted: SELECT(A) ON dw.testX\r\n49.841764 [ 202154 ]  InterpreterSelectQuery: FetchColumns -> Complete\r\n49.841764 [ 202126 ]  InterpreterSelectQuery: FetchColumns -> Complete\r\n49.841846 [ 202101 ]  DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 588.93 GiB.\r\n49.842991 [ 202101 ]  dw.`.inner.testXA`: Renaming temporary part tmp_insert_all_4_4_0 to all_4_4_0.\r\n49.843024 [ 202101 ]  DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 588.93 GiB.\r\n49.844130 [ 202101 ]  dw.`.inner.testXB`: Renaming temporary part tmp_insert_all_4_4_0 to all_4_4_0.\r\n49.844157 [ 202101 ]  DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 588.93 GiB.\r\n49.845262 [ 202101 ]  dw.`.inner.testXC`: Renaming temporary part tmp_insert_all_4_4_0 to all_4_4_0.\r\n49.845287 [ 202101 ]  DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 588.93 GiB.\r\n49.846409 [ 202101 ]  dw.`.inner.testXD`: Renaming temporary part tmp_insert_all_4_4_0 to all_4_4_0.\r\n49.846436 [ 202101 ]  DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 588.93 GiB.\r\n49.847540 [ 202101 ]  dw.`.inner.testXE`: Renaming temporary part tmp_insert_all_4_4_0 to all_4_4_0.\r\n49.847565 [ 202101 ]  DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 588.93 GiB.\r\n49.848670 [ 202101 ]  dw.`.inner.testXF`: Renaming temporary part tmp_insert_all_4_4_0 to all_4_4_0.\r\n49.848767 [ 202161 ]  <Information> executeQuery: Read 100000 rows, 781.25 KiB in 0.009 sec., 10835079 rows/sec., 82.67 MiB/sec.\r\n49.848782 [ 202161 ]  MemoryTracker: Peak memory usage (for query): 14.99 KiB.\r\n\r\n```",
  "created_at": "2020-06-01T09:15:52Z"
}