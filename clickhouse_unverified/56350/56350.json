{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 56350,
  "instance_id": "ClickHouse__ClickHouse-56350",
  "issue_numbers": [
    "55148"
  ],
  "base_commit": "213c7cffb5eae1951f67b8531ec69262696c7e3d",
  "patch": "diff --git a/contrib/libssh-cmake/CMakeLists.txt b/contrib/libssh-cmake/CMakeLists.txt\nindex 1e58a856119b..7a3816d4dce7 100644\n--- a/contrib/libssh-cmake/CMakeLists.txt\n+++ b/contrib/libssh-cmake/CMakeLists.txt\n@@ -7,12 +7,6 @@ endif()\n \n set(LIB_SOURCE_DIR \"${ClickHouse_SOURCE_DIR}/contrib/libssh\")\n set(LIB_BINARY_DIR \"${ClickHouse_BINARY_DIR}/contrib/libssh\")\n-# Specify search path for CMake modules to be loaded by include()\n-# and find_package()\n-list(APPEND CMAKE_MODULE_PATH \"${LIB_SOURCE_DIR}/cmake/Modules\")\n-\n-include(DefineCMakeDefaults)\n-include(DefineCompilerFlags)\n \n project(libssh VERSION 0.9.7 LANGUAGES C)\n \n@@ -29,12 +23,6 @@ set(APPLICATION_NAME ${PROJECT_NAME})\n set(LIBRARY_VERSION \"4.8.7\")\n set(LIBRARY_SOVERSION \"4\")\n \n-# where to look first for cmake modules, before ${CMAKE_ROOT}/Modules/ is checked\n-\n-# add definitions\n-\n-include(DefinePlatformDefaults)\n-\n # Copy library files to a lib sub-directory\n set(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${LIB_BINARY_DIR}/lib\")\n \ndiff --git a/contrib/libssh-cmake/IncludeSources.cmake b/contrib/libssh-cmake/IncludeSources.cmake\nindex d72cf11da1f3..30348d5d7dd7 100644\n--- a/contrib/libssh-cmake/IncludeSources.cmake\n+++ b/contrib/libssh-cmake/IncludeSources.cmake\n@@ -1,20 +1,8 @@\n-set(LIBSSH_LINK_LIBRARIES\n-  ${LIBSSH_REQUIRED_LIBRARIES}\n-)\n-\n-\n set(LIBSSH_LINK_LIBRARIES\n   ${LIBSSH_LINK_LIBRARIES}\n   OpenSSL::Crypto\n )\n \n-if (MINGW AND Threads_FOUND)\n-  set(LIBSSH_LINK_LIBRARIES\n-    ${LIBSSH_LINK_LIBRARIES}\n-    Threads::Threads\n-  )\n-endif()\n-\n set(libssh_SRCS\n   ${LIB_SOURCE_DIR}/src/agent.c\n   ${LIB_SOURCE_DIR}/src/auth.c\n@@ -66,30 +54,11 @@ set(libssh_SRCS\n   ${LIB_SOURCE_DIR}/src/pki_ed25519_common.c\n )\n \n-if (DEFAULT_C_NO_DEPRECATION_FLAGS)\n-    set_source_files_properties(known_hosts.c\n-                                PROPERTIES\n-                                    COMPILE_FLAGS ${DEFAULT_C_NO_DEPRECATION_FLAGS})\n-endif()\n-\n-if (CMAKE_USE_PTHREADS_INIT)\n-    set(libssh_SRCS\n-        ${libssh_SRCS}\n-        ${LIB_SOURCE_DIR}/src/threads/noop.c\n-        ${LIB_SOURCE_DIR}/src/threads/pthread.c\n-    )\n-elseif (CMAKE_USE_WIN32_THREADS_INIT)\n-        set(libssh_SRCS\n-            ${libssh_SRCS}\n-            ${LIB_SOURCE_DIR}/src/threads/noop.c\n-            ${LIB_SOURCE_DIR}/src/threads/winlocks.c\n-        )\n-else()\n-    set(libssh_SRCS\n-        ${libssh_SRCS}\n-        ${LIB_SOURCE_DIR}/src/threads/noop.c\n-    )\n-endif()\n+set(libssh_SRCS\n+    ${libssh_SRCS}\n+    ${LIB_SOURCE_DIR}/src/threads/noop.c\n+    ${LIB_SOURCE_DIR}/src/threads/pthread.c\n+)\n \n # LIBCRYPT specific\n set(libssh_SRCS\n@@ -127,14 +96,3 @@ target_compile_options(_ssh\n                      PRIVATE\n                         ${DEFAULT_C_COMPILE_FLAGS}\n                         -D_GNU_SOURCE)\n-\n-\n-set_target_properties(_ssh\n-    PROPERTIES\n-      VERSION\n-        ${LIBRARY_VERSION}\n-      SOVERSION\n-        ${LIBRARY_SOVERSION}\n-      DEFINE_SYMBOL\n-        LIBSSH_EXPORTS\n-)\ndiff --git a/src/Access/UsersConfigAccessStorage.cpp b/src/Access/UsersConfigAccessStorage.cpp\nindex 952a10648292..2b0fb3f9b2e1 100644\n--- a/src/Access/UsersConfigAccessStorage.cpp\n+++ b/src/Access/UsersConfigAccessStorage.cpp\n@@ -12,7 +12,7 @@\n #include <Common/Config/ConfigReloader.h>\n #include <Common/StringUtils/StringUtils.h>\n #include <Common/quoteString.h>\n-#include <Common/TransformEndianness.hpp>\n+#include <Common/transformEndianness.h>\n #include <Core/Settings.h>\n #include <Interpreters/executeQuery.h>\n #include <Parsers/Access/ASTGrantQuery.h>\ndiff --git a/src/AggregateFunctions/AggregateFunctionAnalysisOfVariance.cpp b/src/AggregateFunctions/AggregateFunctionAnalysisOfVariance.cpp\nindex 9ef2d295828c..934a8dffd90a 100644\n--- a/src/AggregateFunctions/AggregateFunctionAnalysisOfVariance.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionAnalysisOfVariance.cpp\n@@ -1,7 +1,18 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionAnalysisOfVariance.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n \n+#include <IO/VarInt.h>\n+\n+#include <array>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeTuple.h>\n+#include <Columns/ColumnNullable.h>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/Moments.h>\n+#include <Common/NaNUtils.h>\n+#include <Common/assert_cast.h>\n+\n+\n namespace DB\n {\n \n@@ -13,6 +24,82 @@ namespace ErrorCodes\n namespace\n {\n \n+using AggregateFunctionAnalysisOfVarianceData = AnalysisOfVarianceMoments<Float64>;\n+\n+\n+/// One way analysis of variance\n+/// Provides a statistical test of whether two or more population means are equal (null hypothesis)\n+/// Has an assumption that subjects from group i have normal distribution.\n+/// Accepts two arguments - a value and a group number which this value belongs to.\n+/// Groups are enumerated starting from 0 and there should be at least two groups to perform a test\n+/// Moreover there should be at least one group with the number of observations greater than one.\n+class AggregateFunctionAnalysisOfVariance final : public IAggregateFunctionDataHelper<AggregateFunctionAnalysisOfVarianceData, AggregateFunctionAnalysisOfVariance>\n+{\n+public:\n+    explicit AggregateFunctionAnalysisOfVariance(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper(arguments, params, createResultType())\n+    {}\n+\n+    DataTypePtr createResultType() const\n+    {\n+        DataTypes types {std::make_shared<DataTypeNumber<Float64>>(), std::make_shared<DataTypeNumber<Float64>>() };\n+        Strings names {\"f_statistic\", \"p_value\"};\n+        return std::make_shared<DataTypeTuple>(\n+            std::move(types),\n+            std::move(names)\n+        );\n+    }\n+\n+    String getName() const override { return \"analysisOfVariance\"; }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        data(place).add(columns[0]->getFloat64(row_num), columns[1]->getUInt(row_num));\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        data(place).merge(data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        data(place).write(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        data(place).read(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        auto f_stat = data(place).getFStatistic();\n+\n+        auto & column_tuple = assert_cast<ColumnTuple &>(to);\n+        auto & column_stat = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(0));\n+        auto & column_value = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(1));\n+\n+        if (unlikely(!std::isfinite(f_stat) || f_stat < 0))\n+        {\n+            column_stat.getData().push_back(std::numeric_limits<Float64>::quiet_NaN());\n+            column_value.getData().push_back(std::numeric_limits<Float64>::quiet_NaN());\n+            return;\n+        }\n+\n+        auto p_value = data(place).getPValue(f_stat);\n+\n+        /// Because p-value is a probability.\n+        p_value = std::min(1.0, std::max(0.0, p_value));\n+\n+        column_stat.getData().push_back(f_stat);\n+        column_value.getData().push_back(p_value);\n+    }\n+\n+};\n+\n AggregateFunctionPtr createAggregateFunctionAnalysisOfVariance(const std::string & name, const DataTypes & arguments, const Array & parameters, const Settings *)\n {\n     assertNoParameters(name, parameters);\ndiff --git a/src/AggregateFunctions/AggregateFunctionAnalysisOfVariance.h b/src/AggregateFunctions/AggregateFunctionAnalysisOfVariance.h\ndeleted file mode 100644\nindex 76e749dc1fe7..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionAnalysisOfVariance.h\n+++ /dev/null\n@@ -1,97 +0,0 @@\n-#pragma once\n-\n-#include <IO/VarInt.h>\n-#include <IO/WriteHelpers.h>\n-\n-#include <array>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <Columns/ColumnNullable.h>\n-#include <Columns/ColumnsCommon.h>\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/Moments.h>\n-#include \"Common/NaNUtils.h\"\n-#include <Common/assert_cast.h>\n-#include <Core/Types.h>\n-\n-\n-namespace DB\n-{\n-\n-using AggregateFunctionAnalysisOfVarianceData = AnalysisOfVarianceMoments<Float64>;\n-\n-\n-/// One way analysis of variance\n-/// Provides a statistical test of whether two or more population means are equal (null hypothesis)\n-/// Has an assumption that subjects from group i have normal distribution.\n-/// Accepts two arguments - a value and a group number which this value belongs to.\n-/// Groups are enumerated starting from 0 and there should be at least two groups to perform a test\n-/// Moreover there should be at least one group with the number of observations greater than one.\n-class AggregateFunctionAnalysisOfVariance final : public IAggregateFunctionDataHelper<AggregateFunctionAnalysisOfVarianceData, AggregateFunctionAnalysisOfVariance>\n-{\n-public:\n-    explicit AggregateFunctionAnalysisOfVariance(const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper(arguments, params, createResultType())\n-    {}\n-\n-    DataTypePtr createResultType() const\n-    {\n-        DataTypes types {std::make_shared<DataTypeNumber<Float64>>(), std::make_shared<DataTypeNumber<Float64>>() };\n-        Strings names {\"f_statistic\", \"p_value\"};\n-        return std::make_shared<DataTypeTuple>(\n-            std::move(types),\n-            std::move(names)\n-        );\n-    }\n-\n-    String getName() const override { return \"analysisOfVariance\"; }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        data(place).add(columns[0]->getFloat64(row_num), columns[1]->getUInt(row_num));\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        data(place).merge(data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        data(place).write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        data(place).read(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        auto f_stat = data(place).getFStatistic();\n-\n-        auto & column_tuple = assert_cast<ColumnTuple &>(to);\n-        auto & column_stat = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(0));\n-        auto & column_value = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(1));\n-\n-        if (unlikely(!std::isfinite(f_stat) || f_stat < 0))\n-        {\n-            column_stat.getData().push_back(std::numeric_limits<Float64>::quiet_NaN());\n-            column_value.getData().push_back(std::numeric_limits<Float64>::quiet_NaN());\n-            return;\n-        }\n-\n-        auto p_value = data(place).getPValue(f_stat);\n-\n-        /// Because p-value is a probability.\n-        p_value = std::min(1.0, std::max(0.0, p_value));\n-\n-        column_stat.getData().push_back(f_stat);\n-        column_value.getData().push_back(p_value);\n-    }\n-\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionAvgWeighted.cpp b/src/AggregateFunctions/AggregateFunctionAvgWeighted.cpp\nindex e840005facff..d33e843fac97 100644\n--- a/src/AggregateFunctions/AggregateFunctionAvgWeighted.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionAvgWeighted.cpp\n@@ -1,12 +1,14 @@\n #include <memory>\n #include <type_traits>\n+#include <AggregateFunctions/AggregateFunctionAvg.h>\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionAvgWeighted.h>\n #include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n \n+\n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n@@ -16,13 +18,93 @@ namespace ErrorCodes\n \n namespace\n {\n+\n+template <typename T>\n+using AvgWeightedFieldType = std::conditional_t<DecimalOrExtendedInt<T>,\n+        Float64, // no way to do UInt128 * UInt128, better cast to Float64\n+        NearestFieldType<T>>;\n+\n+template <typename T, typename U>\n+using MaxFieldType = std::conditional_t<(sizeof(AvgWeightedFieldType<T>) > sizeof(AvgWeightedFieldType<U>)),\n+    AvgWeightedFieldType<T>, AvgWeightedFieldType<U>>;\n+\n+template <typename Value, typename Weight>\n+class AggregateFunctionAvgWeighted final :\n+    public AggregateFunctionAvgBase<\n+        MaxFieldType<Value, Weight>, AvgWeightedFieldType<Weight>, AggregateFunctionAvgWeighted<Value, Weight>>\n+{\n+public:\n+    using Base = AggregateFunctionAvgBase<\n+        MaxFieldType<Value, Weight>, AvgWeightedFieldType<Weight>, AggregateFunctionAvgWeighted<Value, Weight>>;\n+    using Base::Base;\n+\n+    using Numerator = typename Base::Numerator;\n+    using Denominator = typename Base::Denominator;\n+    using Fraction = typename Base::Fraction;\n+\n+    void NO_SANITIZE_UNDEFINED add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        const auto & weights = static_cast<const ColumnVector<Weight> &>(*columns[1]);\n+\n+        this->data(place).numerator += static_cast<Numerator>(\n+            static_cast<const ColumnVector<Value> &>(*columns[0]).getData()[row_num])\n+            * static_cast<Numerator>(weights.getData()[row_num]);\n+\n+        this->data(place).denominator += static_cast<Denominator>(weights.getData()[row_num]);\n+    }\n+\n+    String getName() const override { return \"avgWeighted\"; }\n+\n+#if USE_EMBEDDED_COMPILER\n+\n+    bool isCompilable() const override\n+    {\n+        bool can_be_compiled = Base::isCompilable();\n+        can_be_compiled &= canBeNativeType<Weight>();\n+\n+        return can_be_compiled;\n+    }\n+\n+    void compileAdd(llvm::IRBuilderBase & builder, llvm::Value * aggregate_data_ptr, const ValuesWithType & arguments) const override\n+    {\n+        llvm::IRBuilder<> & b = static_cast<llvm::IRBuilder<> &>(builder);\n+\n+        auto * numerator_type = toNativeType<Numerator>(b);\n+        auto * numerator_ptr = aggregate_data_ptr;\n+        auto * numerator_value = b.CreateLoad(numerator_type, numerator_ptr);\n+\n+        auto numerator_data_type = toNativeDataType<Numerator>();\n+        auto * argument = nativeCast(b, arguments[0], numerator_data_type);\n+        auto * weight = nativeCast(b, arguments[1], numerator_data_type);\n+\n+        llvm::Value * value_weight_multiplication = argument->getType()->isIntegerTy() ? b.CreateMul(argument, weight) : b.CreateFMul(argument, weight);\n+        auto * numerator_result_value = numerator_type->isIntegerTy() ? b.CreateAdd(numerator_value, value_weight_multiplication) : b.CreateFAdd(numerator_value, value_weight_multiplication);\n+        b.CreateStore(numerator_result_value, numerator_ptr);\n+\n+        auto * denominator_type = toNativeType<Denominator>(b);\n+\n+        static constexpr size_t denominator_offset = offsetof(Fraction, denominator);\n+        auto * denominator_ptr = b.CreateConstInBoundsGEP1_64(b.getInt8Ty(), aggregate_data_ptr, denominator_offset);\n+\n+        auto * weight_cast_to_denominator = nativeCast(b, arguments[1], toNativeDataType<Denominator>());\n+\n+        auto * denominator_value = b.CreateLoad(denominator_type, denominator_ptr);\n+        auto * denominator_value_updated = denominator_type->isIntegerTy() ? b.CreateAdd(denominator_value, weight_cast_to_denominator) : b.CreateFAdd(denominator_value, weight_cast_to_denominator);\n+\n+        b.CreateStore(denominator_value_updated, denominator_ptr);\n+    }\n+\n+#endif\n+\n+};\n+\n bool allowTypes(const DataTypePtr& left, const DataTypePtr& right) noexcept\n {\n     const WhichDataType l_dt(left), r_dt(right);\n \n     constexpr auto allow = [](WhichDataType t)\n     {\n-        return t.isInt() || t.isUInt() || t.isFloat() || t.isDecimal();\n+        return t.isInt() || t.isUInt() || t.isFloat();\n     };\n \n     return allow(l_dt) && allow(r_dt);\n@@ -33,7 +115,6 @@ bool allowTypes(const DataTypePtr& left, const DataTypePtr& right) noexcept\n     { \\\n         LINE(Int8); LINE(Int16); LINE(Int32); LINE(Int64); LINE(Int128); LINE(Int256); \\\n         LINE(UInt8); LINE(UInt16); LINE(UInt32); LINE(UInt64); LINE(UInt128); LINE(UInt256); \\\n-        LINE(Decimal32); LINE(Decimal64); LINE(Decimal128); LINE(Decimal256); \\\n         LINE(Float32); LINE(Float64); \\\n         default: return nullptr; \\\n     }\n@@ -75,31 +156,14 @@ createAggregateFunctionAvgWeighted(const std::string & name, const DataTypes & a\n                         \"Types {} and {} are non-conforming as arguments for aggregate function {}\",\n                         data_type->getName(), data_type_weight->getName(), name);\n \n-    AggregateFunctionPtr ptr;\n-\n-    const bool left_decimal = isDecimal(data_type);\n-    const bool right_decimal = isDecimal(data_type_weight);\n-\n-    /// We multiply value by weight, so actual scale of numerator is <scale of value> + <scale of weight>\n-    if (left_decimal && right_decimal)\n-        ptr.reset(create(*data_type, *data_type_weight,\n-            argument_types,\n-            getDecimalScale(*data_type) + getDecimalScale(*data_type_weight), getDecimalScale(*data_type_weight)));\n-    else if (left_decimal)\n-        ptr.reset(create(*data_type, *data_type_weight, argument_types,\n-            getDecimalScale(*data_type)));\n-    else if (right_decimal)\n-        ptr.reset(create(*data_type, *data_type_weight, argument_types,\n-            getDecimalScale(*data_type_weight), getDecimalScale(*data_type_weight)));\n-    else\n-        ptr.reset(create(*data_type, *data_type_weight, argument_types));\n-\n-    return ptr;\n+    return AggregateFunctionPtr(create(*data_type, *data_type_weight, argument_types));\n }\n+\n }\n \n void registerAggregateFunctionAvgWeighted(AggregateFunctionFactory & factory)\n {\n-    factory.registerFunction(\"avgWeighted\", createAggregateFunctionAvgWeighted, AggregateFunctionFactory::CaseSensitive);\n+    factory.registerFunction(\"avgWeighted\", createAggregateFunctionAvgWeighted);\n }\n+\n }\ndiff --git a/src/AggregateFunctions/AggregateFunctionAvgWeighted.h b/src/AggregateFunctions/AggregateFunctionAvgWeighted.h\ndeleted file mode 100644\nindex 5a3869032cad..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionAvgWeighted.h\n+++ /dev/null\n@@ -1,90 +0,0 @@\n-#pragma once\n-\n-#include <type_traits>\n-#include <AggregateFunctions/AggregateFunctionAvg.h>\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-template <typename T>\n-using AvgWeightedFieldType = std::conditional_t<is_decimal<T>,\n-    std::conditional_t<std::is_same_v<T, Decimal256>, Decimal256, Decimal128>,\n-    std::conditional_t<DecimalOrExtendedInt<T>,\n-        Float64, // no way to do UInt128 * UInt128, better cast to Float64\n-        NearestFieldType<T>>>;\n-\n-template <typename T, typename U>\n-using MaxFieldType = std::conditional_t<(sizeof(AvgWeightedFieldType<T>) > sizeof(AvgWeightedFieldType<U>)),\n-    AvgWeightedFieldType<T>, AvgWeightedFieldType<U>>;\n-\n-template <typename Value, typename Weight>\n-class AggregateFunctionAvgWeighted final :\n-    public AggregateFunctionAvgBase<\n-        MaxFieldType<Value, Weight>, AvgWeightedFieldType<Weight>, AggregateFunctionAvgWeighted<Value, Weight>>\n-{\n-public:\n-    using Base = AggregateFunctionAvgBase<\n-        MaxFieldType<Value, Weight>, AvgWeightedFieldType<Weight>, AggregateFunctionAvgWeighted<Value, Weight>>;\n-    using Base::Base;\n-\n-    using Numerator = typename Base::Numerator;\n-    using Denominator = typename Base::Denominator;\n-    using Fraction = typename Base::Fraction;\n-\n-    void NO_SANITIZE_UNDEFINED add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        const auto& weights = static_cast<const ColumnVectorOrDecimal<Weight> &>(*columns[1]);\n-\n-        this->data(place).numerator += static_cast<Numerator>(\n-            static_cast<const ColumnVectorOrDecimal<Value> &>(*columns[0]).getData()[row_num]) *\n-            static_cast<Numerator>(weights.getData()[row_num]);\n-\n-        this->data(place).denominator += static_cast<Denominator>(weights.getData()[row_num]);\n-    }\n-\n-    String getName() const override { return \"avgWeighted\"; }\n-\n-#if USE_EMBEDDED_COMPILER\n-\n-    bool isCompilable() const override\n-    {\n-        bool can_be_compiled = Base::isCompilable();\n-        can_be_compiled &= canBeNativeType<Weight>();\n-\n-        return can_be_compiled;\n-    }\n-\n-    void compileAdd(llvm::IRBuilderBase & builder, llvm::Value * aggregate_data_ptr, const ValuesWithType & arguments) const override\n-    {\n-        llvm::IRBuilder<> & b = static_cast<llvm::IRBuilder<> &>(builder);\n-\n-        auto * numerator_type = toNativeType<Numerator>(b);\n-        auto * numerator_ptr = aggregate_data_ptr;\n-        auto * numerator_value = b.CreateLoad(numerator_type, numerator_ptr);\n-\n-        auto numerator_data_type = toNativeDataType<Numerator>();\n-        auto * argument = nativeCast(b, arguments[0], numerator_data_type);\n-        auto * weight = nativeCast(b, arguments[1], numerator_data_type);\n-\n-        llvm::Value * value_weight_multiplication = argument->getType()->isIntegerTy() ? b.CreateMul(argument, weight) : b.CreateFMul(argument, weight);\n-        auto * numerator_result_value = numerator_type->isIntegerTy() ? b.CreateAdd(numerator_value, value_weight_multiplication) : b.CreateFAdd(numerator_value, value_weight_multiplication);\n-        b.CreateStore(numerator_result_value, numerator_ptr);\n-\n-        auto * denominator_type = toNativeType<Denominator>(b);\n-\n-        static constexpr size_t denominator_offset = offsetof(Fraction, denominator);\n-        auto * denominator_ptr = b.CreateConstInBoundsGEP1_64(b.getInt8Ty(), aggregate_data_ptr, denominator_offset);\n-\n-        auto * weight_cast_to_denominator = nativeCast(b, arguments[1], toNativeDataType<Denominator>());\n-\n-        auto * denominator_value = b.CreateLoad(denominator_type, denominator_ptr);\n-        auto * denominator_value_updated = denominator_type->isIntegerTy() ? b.CreateAdd(denominator_value, weight_cast_to_denominator) : b.CreateFAdd(denominator_value, weight_cast_to_denominator);\n-\n-        b.CreateStore(denominator_value_updated, denominator_ptr);\n-    }\n-\n-#endif\n-\n-};\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionBitwise.cpp b/src/AggregateFunctions/AggregateFunctionBitwise.cpp\nindex f5c2deb45886..619251552e41 100644\n--- a/src/AggregateFunctions/AggregateFunctionBitwise.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionBitwise.cpp\n@@ -1,11 +1,27 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionBitwise.h>\n #include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n \n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadHelpers.h>\n+\n+#include <DataTypes/DataTypesNumber.h>\n+#include <Columns/ColumnVector.h>\n+#include <Common/assert_cast.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+\n+#include \"config.h\"\n+\n+#if USE_EMBEDDED_COMPILER\n+#    include <llvm/IR/IRBuilder.h>\n+#    include <DataTypes/Native.h>\n+#endif\n+\n \n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n@@ -16,6 +32,179 @@ namespace ErrorCodes\n namespace\n {\n \n+template <typename T>\n+struct AggregateFunctionGroupBitOrData\n+{\n+    T value = 0;\n+    static const char * name() { return \"groupBitOr\"; }\n+    void update(T x) { value |= x; }\n+\n+#if USE_EMBEDDED_COMPILER\n+\n+    static void compileCreate(llvm::IRBuilderBase & builder, llvm::Value * value_ptr)\n+    {\n+        auto type = toNativeType<T>(builder);\n+        builder.CreateStore(llvm::Constant::getNullValue(type), value_ptr);\n+    }\n+\n+    static llvm::Value* compileUpdate(llvm::IRBuilderBase & builder, llvm::Value * lhs, llvm::Value * rhs)\n+    {\n+        return builder.CreateOr(lhs, rhs);\n+    }\n+\n+#endif\n+};\n+\n+template <typename T>\n+struct AggregateFunctionGroupBitAndData\n+{\n+    T value = -1; /// Two's complement arithmetic, sign extension.\n+    static const char * name() { return \"groupBitAnd\"; }\n+    void update(T x) { value &= x; }\n+\n+#if USE_EMBEDDED_COMPILER\n+\n+    static void compileCreate(llvm::IRBuilderBase & builder, llvm::Value * value_ptr)\n+    {\n+        auto type = toNativeType<T>(builder);\n+        builder.CreateStore(llvm::ConstantInt::get(type, -1), value_ptr);\n+    }\n+\n+    static llvm::Value* compileUpdate(llvm::IRBuilderBase & builder, llvm::Value * lhs, llvm::Value * rhs)\n+    {\n+        return builder.CreateAnd(lhs, rhs);\n+    }\n+\n+#endif\n+};\n+\n+template <typename T>\n+struct AggregateFunctionGroupBitXorData\n+{\n+    T value = 0;\n+    static const char * name() { return \"groupBitXor\"; }\n+    void update(T x) { value ^= x; }\n+\n+#if USE_EMBEDDED_COMPILER\n+\n+    static void compileCreate(llvm::IRBuilderBase & builder, llvm::Value * value_ptr)\n+    {\n+        auto type = toNativeType<T>(builder);\n+        builder.CreateStore(llvm::Constant::getNullValue(type), value_ptr);\n+    }\n+\n+    static llvm::Value* compileUpdate(llvm::IRBuilderBase & builder, llvm::Value * lhs, llvm::Value * rhs)\n+    {\n+        return builder.CreateXor(lhs, rhs);\n+    }\n+\n+#endif\n+};\n+\n+\n+/// Counts bitwise operation on numbers.\n+template <typename T, typename Data>\n+class AggregateFunctionBitwise final : public IAggregateFunctionDataHelper<Data, AggregateFunctionBitwise<T, Data>>\n+{\n+public:\n+    explicit AggregateFunctionBitwise(const DataTypePtr & type)\n+        : IAggregateFunctionDataHelper<Data, AggregateFunctionBitwise<T, Data>>({type}, {}, createResultType())\n+    {}\n+\n+    String getName() const override { return Data::name(); }\n+\n+    static DataTypePtr createResultType()\n+    {\n+        return std::make_shared<DataTypeNumber<T>>();\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        this->data(place).update(assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num]);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).update(this->data(rhs).value);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        writeBinary(this->data(place).value, buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        readBinary(this->data(place).value, buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        assert_cast<ColumnVector<T> &>(to).getData().push_back(this->data(place).value);\n+    }\n+\n+#if USE_EMBEDDED_COMPILER\n+\n+    bool isCompilable() const override\n+    {\n+        auto return_type = this->getResultType();\n+        return canBeNativeType(*return_type);\n+    }\n+\n+    void compileCreate(llvm::IRBuilderBase & builder, llvm::Value * aggregate_data_ptr) const override\n+    {\n+        auto * value_ptr = aggregate_data_ptr;\n+        Data::compileCreate(builder, value_ptr);\n+    }\n+\n+    void compileAdd(llvm::IRBuilderBase & builder, llvm::Value * aggregate_data_ptr, const ValuesWithType & arguments) const override\n+    {\n+        llvm::IRBuilder<> & b = static_cast<llvm::IRBuilder<> &>(builder);\n+\n+        auto * return_type = toNativeType(b, this->getResultType());\n+\n+        auto * value_ptr = aggregate_data_ptr;\n+        auto * value = b.CreateLoad(return_type, value_ptr);\n+\n+        auto * result_value = Data::compileUpdate(builder, value, arguments[0].value);\n+\n+        b.CreateStore(result_value, value_ptr);\n+    }\n+\n+    void compileMerge(llvm::IRBuilderBase & builder, llvm::Value * aggregate_data_dst_ptr, llvm::Value * aggregate_data_src_ptr) const override\n+    {\n+        llvm::IRBuilder<> & b = static_cast<llvm::IRBuilder<> &>(builder);\n+\n+        auto * return_type = toNativeType(b, this->getResultType());\n+\n+        auto * value_dst_ptr = aggregate_data_dst_ptr;\n+        auto * value_dst = b.CreateLoad(return_type, value_dst_ptr);\n+\n+        auto * value_src_ptr = aggregate_data_src_ptr;\n+        auto * value_src = b.CreateLoad(return_type, value_src_ptr);\n+\n+        auto * result_value = Data::compileUpdate(builder, value_dst, value_src);\n+\n+        b.CreateStore(result_value, value_dst_ptr);\n+    }\n+\n+    llvm::Value * compileGetResult(llvm::IRBuilderBase & builder, llvm::Value * aggregate_data_ptr) const override\n+    {\n+        llvm::IRBuilder<> & b = static_cast<llvm::IRBuilder<> &>(builder);\n+\n+        auto * return_type = toNativeType(b, this->getResultType());\n+        auto * value_ptr = aggregate_data_ptr;\n+\n+        return b.CreateLoad(return_type, value_ptr);\n+    }\n+\n+#endif\n+\n+};\n+\n+\n template <template <typename> class Data>\n AggregateFunctionPtr createAggregateFunctionBitwise(const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n {\ndiff --git a/src/AggregateFunctions/AggregateFunctionBitwise.h b/src/AggregateFunctions/AggregateFunctionBitwise.h\ndeleted file mode 100644\nindex 71479b309c7c..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionBitwise.h\n+++ /dev/null\n@@ -1,197 +0,0 @@\n-#pragma once\n-\n-#include <IO/WriteHelpers.h>\n-#include <IO/ReadHelpers.h>\n-\n-#include <DataTypes/DataTypesNumber.h>\n-#include <Columns/ColumnVector.h>\n-#include <Common/assert_cast.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-#include \"config.h\"\n-\n-#if USE_EMBEDDED_COMPILER\n-#    include <llvm/IR/IRBuilder.h>\n-#    include <DataTypes/Native.h>\n-#endif\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-\n-template <typename T>\n-struct AggregateFunctionGroupBitOrData\n-{\n-    T value = 0;\n-    static const char * name() { return \"groupBitOr\"; }\n-    void update(T x) { value |= x; }\n-\n-#if USE_EMBEDDED_COMPILER\n-\n-    static void compileCreate(llvm::IRBuilderBase & builder, llvm::Value * value_ptr)\n-    {\n-        auto type = toNativeType<T>(builder);\n-        builder.CreateStore(llvm::Constant::getNullValue(type), value_ptr);\n-    }\n-\n-    static llvm::Value* compileUpdate(llvm::IRBuilderBase & builder, llvm::Value * lhs, llvm::Value * rhs)\n-    {\n-        return builder.CreateOr(lhs, rhs);\n-    }\n-\n-#endif\n-};\n-\n-template <typename T>\n-struct AggregateFunctionGroupBitAndData\n-{\n-    T value = -1; /// Two's complement arithmetic, sign extension.\n-    static const char * name() { return \"groupBitAnd\"; }\n-    void update(T x) { value &= x; }\n-\n-#if USE_EMBEDDED_COMPILER\n-\n-    static void compileCreate(llvm::IRBuilderBase & builder, llvm::Value * value_ptr)\n-    {\n-        auto type = toNativeType<T>(builder);\n-        builder.CreateStore(llvm::ConstantInt::get(type, -1), value_ptr);\n-    }\n-\n-    static llvm::Value* compileUpdate(llvm::IRBuilderBase & builder, llvm::Value * lhs, llvm::Value * rhs)\n-    {\n-        return builder.CreateAnd(lhs, rhs);\n-    }\n-\n-#endif\n-};\n-\n-template <typename T>\n-struct AggregateFunctionGroupBitXorData\n-{\n-    T value = 0;\n-    static const char * name() { return \"groupBitXor\"; }\n-    void update(T x) { value ^= x; }\n-\n-#if USE_EMBEDDED_COMPILER\n-\n-    static void compileCreate(llvm::IRBuilderBase & builder, llvm::Value * value_ptr)\n-    {\n-        auto type = toNativeType<T>(builder);\n-        builder.CreateStore(llvm::Constant::getNullValue(type), value_ptr);\n-    }\n-\n-    static llvm::Value* compileUpdate(llvm::IRBuilderBase & builder, llvm::Value * lhs, llvm::Value * rhs)\n-    {\n-        return builder.CreateXor(lhs, rhs);\n-    }\n-\n-#endif\n-};\n-\n-\n-/// Counts bitwise operation on numbers.\n-template <typename T, typename Data>\n-class AggregateFunctionBitwise final : public IAggregateFunctionDataHelper<Data, AggregateFunctionBitwise<T, Data>>\n-{\n-public:\n-    explicit AggregateFunctionBitwise(const DataTypePtr & type)\n-        : IAggregateFunctionDataHelper<Data, AggregateFunctionBitwise<T, Data>>({type}, {}, createResultType())\n-    {}\n-\n-    String getName() const override { return Data::name(); }\n-\n-    static DataTypePtr createResultType()\n-    {\n-        return std::make_shared<DataTypeNumber<T>>();\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        this->data(place).update(assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num]);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).update(this->data(rhs).value);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        writeBinary(this->data(place).value, buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        readBinary(this->data(place).value, buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        assert_cast<ColumnVector<T> &>(to).getData().push_back(this->data(place).value);\n-    }\n-\n-#if USE_EMBEDDED_COMPILER\n-\n-    bool isCompilable() const override\n-    {\n-        auto return_type = this->getResultType();\n-        return canBeNativeType(*return_type);\n-    }\n-\n-    void compileCreate(llvm::IRBuilderBase & builder, llvm::Value * aggregate_data_ptr) const override\n-    {\n-        auto * value_ptr = aggregate_data_ptr;\n-        Data::compileCreate(builder, value_ptr);\n-    }\n-\n-    void compileAdd(llvm::IRBuilderBase & builder, llvm::Value * aggregate_data_ptr, const ValuesWithType & arguments) const override\n-    {\n-        llvm::IRBuilder<> & b = static_cast<llvm::IRBuilder<> &>(builder);\n-\n-        auto * return_type = toNativeType(b, this->getResultType());\n-\n-        auto * value_ptr = aggregate_data_ptr;\n-        auto * value = b.CreateLoad(return_type, value_ptr);\n-\n-        auto * result_value = Data::compileUpdate(builder, value, arguments[0].value);\n-\n-        b.CreateStore(result_value, value_ptr);\n-    }\n-\n-    void compileMerge(llvm::IRBuilderBase & builder, llvm::Value * aggregate_data_dst_ptr, llvm::Value * aggregate_data_src_ptr) const override\n-    {\n-        llvm::IRBuilder<> & b = static_cast<llvm::IRBuilder<> &>(builder);\n-\n-        auto * return_type = toNativeType(b, this->getResultType());\n-\n-        auto * value_dst_ptr = aggregate_data_dst_ptr;\n-        auto * value_dst = b.CreateLoad(return_type, value_dst_ptr);\n-\n-        auto * value_src_ptr = aggregate_data_src_ptr;\n-        auto * value_src = b.CreateLoad(return_type, value_src_ptr);\n-\n-        auto * result_value = Data::compileUpdate(builder, value_dst, value_src);\n-\n-        b.CreateStore(result_value, value_dst_ptr);\n-    }\n-\n-    llvm::Value * compileGetResult(llvm::IRBuilderBase & builder, llvm::Value * aggregate_data_ptr) const override\n-    {\n-        llvm::IRBuilder<> & b = static_cast<llvm::IRBuilder<> &>(builder);\n-\n-        auto * return_type = toNativeType(b, this->getResultType());\n-        auto * value_ptr = aggregate_data_ptr;\n-\n-        return b.CreateLoad(return_type, value_ptr);\n-    }\n-\n-#endif\n-\n-};\n-\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionBoundingRatio.cpp b/src/AggregateFunctions/AggregateFunctionBoundingRatio.cpp\nindex 9c3eec3f1f84..62adb74924db 100644\n--- a/src/AggregateFunctions/AggregateFunctionBoundingRatio.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionBoundingRatio.cpp\n@@ -1,7 +1,14 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionBoundingRatio.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n \n+#include <DataTypes/DataTypesNumber.h>\n+#include <Columns/ColumnsNumber.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <Common/assert_cast.h>\n+#include <Common/transformEndianness.h>\n+\n \n namespace DB\n {\n@@ -10,11 +17,169 @@ struct Settings;\n namespace ErrorCodes\n {\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int BAD_ARGUMENTS;\n }\n \n namespace\n {\n \n+/** Tracks the leftmost and rightmost (x, y) data points.\n+  */\n+struct AggregateFunctionBoundingRatioData\n+{\n+    struct Point\n+    {\n+        Float64 x;\n+        Float64 y;\n+    };\n+\n+    bool empty = true;\n+    Point left;\n+    Point right;\n+\n+    void add(Float64 x, Float64 y)\n+    {\n+        Point point{x, y};\n+\n+        if (empty)\n+        {\n+            left = point;\n+            right = point;\n+            empty = false;\n+        }\n+        else if (point.x < left.x)\n+        {\n+            left = point;\n+        }\n+        else if (point.x > right.x)\n+        {\n+            right = point;\n+        }\n+    }\n+\n+    void merge(const AggregateFunctionBoundingRatioData & other)\n+    {\n+        if (empty)\n+        {\n+            *this = other;\n+        }\n+        else\n+        {\n+            if (other.left.x < left.x)\n+                left = other.left;\n+            if (other.right.x > right.x)\n+                right = other.right;\n+        }\n+    }\n+\n+    void serialize(WriteBuffer & buf) const;\n+    void deserialize(ReadBuffer & buf);\n+};\n+\n+template <std::endian endian>\n+inline void transformEndianness(AggregateFunctionBoundingRatioData::Point & p)\n+{\n+    DB::transformEndianness<endian>(p.x);\n+    DB::transformEndianness<endian>(p.y);\n+}\n+\n+void AggregateFunctionBoundingRatioData::serialize(WriteBuffer & buf) const\n+{\n+    writeBinaryLittleEndian(empty, buf);\n+\n+    if (!empty)\n+    {\n+        writeBinaryLittleEndian(left, buf);\n+        writeBinaryLittleEndian(right, buf);\n+    }\n+}\n+\n+void AggregateFunctionBoundingRatioData::deserialize(ReadBuffer & buf)\n+{\n+    readBinaryLittleEndian(empty, buf);\n+\n+    if (!empty)\n+    {\n+        readBinaryLittleEndian(left, buf);\n+        readBinaryLittleEndian(right, buf);\n+    }\n+}\n+\n+inline void writeBinary(const AggregateFunctionBoundingRatioData::Point & p, WriteBuffer & buf)\n+{\n+    writePODBinary(p, buf);\n+}\n+\n+inline void readBinary(AggregateFunctionBoundingRatioData::Point & p, ReadBuffer & buf)\n+{\n+    readPODBinary(p, buf);\n+}\n+\n+\n+class AggregateFunctionBoundingRatio final : public IAggregateFunctionDataHelper<AggregateFunctionBoundingRatioData, AggregateFunctionBoundingRatio>\n+{\n+private:\n+    /** Calculates the slope of a line between leftmost and rightmost data points.\n+      * (y2 - y1) / (x2 - x1)\n+      */\n+    static Float64 NO_SANITIZE_UNDEFINED getBoundingRatio(const AggregateFunctionBoundingRatioData & data)\n+    {\n+        if (data.empty)\n+            return std::numeric_limits<Float64>::quiet_NaN();\n+\n+        return (data.right.y - data.left.y) / (data.right.x - data.left.x);\n+    }\n+\n+public:\n+    String getName() const override\n+    {\n+        return \"boundingRatio\";\n+    }\n+\n+    explicit AggregateFunctionBoundingRatio(const DataTypes & arguments)\n+        : IAggregateFunctionDataHelper<AggregateFunctionBoundingRatioData, AggregateFunctionBoundingRatio>(arguments, {}, std::make_shared<DataTypeFloat64>())\n+    {\n+        const auto * x_arg = arguments.at(0).get();\n+        const auto * y_arg = arguments.at(1).get();\n+\n+        if (!x_arg->isValueRepresentedByNumber() || !y_arg->isValueRepresentedByNumber())\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS,\n+                            \"Illegal types of arguments of aggregate function {}, must have number representation.\",\n+                            getName());\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, const size_t row_num, Arena *) const override\n+    {\n+        /// NOTE Slightly inefficient.\n+        const auto x = columns[0]->getFloat64(row_num);\n+        const auto y = columns[1]->getFloat64(row_num);\n+        data(place).add(x, y);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        data(place).merge(data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        data(place).deserialize(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        assert_cast<ColumnFloat64 &>(to).getData().push_back(getBoundingRatio(data(place)));\n+    }\n+};\n+\n+\n AggregateFunctionPtr createAggregateFunctionRate(const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n {\n     assertNoParameters(name, parameters);\ndiff --git a/src/AggregateFunctions/AggregateFunctionBoundingRatio.h b/src/AggregateFunctions/AggregateFunctionBoundingRatio.h\ndeleted file mode 100644\nindex c41fb551a963..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionBoundingRatio.h\n+++ /dev/null\n@@ -1,177 +0,0 @@\n-#pragma once\n-\n-#include <DataTypes/DataTypesNumber.h>\n-#include <Columns/ColumnsNumber.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <AggregateFunctions/Helpers.h>\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <Common/assert_cast.h>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int BAD_ARGUMENTS;\n-}\n-\n-/** Tracks the leftmost and rightmost (x, y) data points.\n-  */\n-struct AggregateFunctionBoundingRatioData\n-{\n-    struct Point\n-    {\n-        Float64 x;\n-        Float64 y;\n-    };\n-\n-    bool empty = true;\n-    Point left;\n-    Point right;\n-\n-    void add(Float64 x, Float64 y)\n-    {\n-        Point point{x, y};\n-\n-        if (empty)\n-        {\n-            left = point;\n-            right = point;\n-            empty = false;\n-        }\n-        else if (point.x < left.x)\n-        {\n-            left = point;\n-        }\n-        else if (point.x > right.x)\n-        {\n-            right = point;\n-        }\n-    }\n-\n-    void merge(const AggregateFunctionBoundingRatioData & other)\n-    {\n-        if (empty)\n-        {\n-            *this = other;\n-        }\n-        else\n-        {\n-            if (other.left.x < left.x)\n-                left = other.left;\n-            if (other.right.x > right.x)\n-                right = other.right;\n-        }\n-    }\n-\n-    void serialize(WriteBuffer & buf) const;\n-    void deserialize(ReadBuffer & buf);\n-};\n-\n-template <std::endian endian>\n-inline void transformEndianness(AggregateFunctionBoundingRatioData::Point & p)\n-{\n-    transformEndianness<endian>(p.x);\n-    transformEndianness<endian>(p.y);\n-}\n-\n-void AggregateFunctionBoundingRatioData::serialize(WriteBuffer & buf) const\n-{\n-    writeBinaryLittleEndian(empty, buf);\n-\n-    if (!empty)\n-    {\n-        writeBinaryLittleEndian(left, buf);\n-        writeBinaryLittleEndian(right, buf);\n-    }\n-}\n-\n-void AggregateFunctionBoundingRatioData::deserialize(ReadBuffer & buf)\n-{\n-    readBinaryLittleEndian(empty, buf);\n-\n-    if (!empty)\n-    {\n-        readBinaryLittleEndian(left, buf);\n-        readBinaryLittleEndian(right, buf);\n-    }\n-}\n-\n-inline void writeBinary(const AggregateFunctionBoundingRatioData::Point & p, WriteBuffer & buf)\n-{\n-    writePODBinary(p, buf);\n-}\n-\n-inline void readBinary(AggregateFunctionBoundingRatioData::Point & p, ReadBuffer & buf)\n-{\n-    readPODBinary(p, buf);\n-}\n-\n-\n-class AggregateFunctionBoundingRatio final : public IAggregateFunctionDataHelper<AggregateFunctionBoundingRatioData, AggregateFunctionBoundingRatio>\n-{\n-private:\n-    /** Calculates the slope of a line between leftmost and rightmost data points.\n-      * (y2 - y1) / (x2 - x1)\n-      */\n-    static Float64 NO_SANITIZE_UNDEFINED getBoundingRatio(const AggregateFunctionBoundingRatioData & data)\n-    {\n-        if (data.empty)\n-            return std::numeric_limits<Float64>::quiet_NaN();\n-\n-        return (data.right.y - data.left.y) / (data.right.x - data.left.x);\n-    }\n-\n-public:\n-    String getName() const override\n-    {\n-        return \"boundingRatio\";\n-    }\n-\n-    explicit AggregateFunctionBoundingRatio(const DataTypes & arguments)\n-        : IAggregateFunctionDataHelper<AggregateFunctionBoundingRatioData, AggregateFunctionBoundingRatio>(arguments, {}, std::make_shared<DataTypeFloat64>())\n-    {\n-        const auto * x_arg = arguments.at(0).get();\n-        const auto * y_arg = arguments.at(1).get();\n-\n-        if (!x_arg->isValueRepresentedByNumber() || !y_arg->isValueRepresentedByNumber())\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS,\n-                            \"Illegal types of arguments of aggregate function {}, must have number representation.\",\n-                            getName());\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, const size_t row_num, Arena *) const override\n-    {\n-        /// NOTE Slightly inefficient.\n-        const auto x = columns[0]->getFloat64(row_num);\n-        const auto y = columns[1]->getFloat64(row_num);\n-        data(place).add(x, y);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        data(place).merge(data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        data(place).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        data(place).deserialize(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        assert_cast<ColumnFloat64 &>(to).getData().push_back(getBoundingRatio(data(place)));\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionDeltaSum.cpp b/src/AggregateFunctions/AggregateFunctionDeltaSum.cpp\nindex f36e0cb46825..a846490a89e5 100644\n--- a/src/AggregateFunctions/AggregateFunctionDeltaSum.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionDeltaSum.cpp\n@@ -1,9 +1,15 @@\n-#include <AggregateFunctions/AggregateFunctionDeltaSum.h>\n-\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n #include <AggregateFunctions/Helpers.h>\n \n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+\n+#include <Columns/ColumnVector.h>\n+#include <DataTypes/DataTypesNumber.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+\n \n namespace DB\n {\n@@ -18,6 +24,113 @@ namespace ErrorCodes\n namespace\n {\n \n+template <typename T>\n+struct AggregationFunctionDeltaSumData\n+{\n+    T sum = 0;\n+    T last = 0;\n+    T first = 0;\n+    bool seen = false;\n+};\n+\n+template <typename T>\n+class AggregationFunctionDeltaSum final\n+    : public IAggregateFunctionDataHelper<AggregationFunctionDeltaSumData<T>, AggregationFunctionDeltaSum<T>>\n+{\n+public:\n+    AggregationFunctionDeltaSum(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<AggregationFunctionDeltaSumData<T>, AggregationFunctionDeltaSum<T>>{arguments, params, createResultType()}\n+    {}\n+\n+    AggregationFunctionDeltaSum()\n+        : IAggregateFunctionDataHelper<AggregationFunctionDeltaSumData<T>, AggregationFunctionDeltaSum<T>>{}\n+    {}\n+\n+    String getName() const override { return \"deltaSum\"; }\n+\n+    static DataTypePtr createResultType() { return std::make_shared<DataTypeNumber<T>>(); }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void NO_SANITIZE_UNDEFINED ALWAYS_INLINE add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        auto value = assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num];\n+\n+        if ((this->data(place).last < value) && this->data(place).seen)\n+        {\n+            this->data(place).sum += (value - this->data(place).last);\n+        }\n+\n+        this->data(place).last = value;\n+\n+        if (!this->data(place).seen)\n+        {\n+            this->data(place).first = value;\n+            this->data(place).seen = true;\n+        }\n+    }\n+\n+    void NO_SANITIZE_UNDEFINED merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        auto place_data = &this->data(place);\n+        auto rhs_data = &this->data(rhs);\n+\n+        if ((place_data->last < rhs_data->first) && place_data->seen && rhs_data->seen)\n+        {\n+            // If the lhs last number seen is less than the first number the rhs saw, the lhs is before\n+            // the rhs, for example [0, 2] [4, 7]. So we want to add the deltasums, but also add the\n+            // difference between lhs last number and rhs first number (the 2 and 4). Then we want to\n+            // take last value from the rhs, so first and last become 0 and 7.\n+\n+            place_data->sum += rhs_data->sum + (rhs_data->first - place_data->last);\n+            place_data->last = rhs_data->last;\n+        }\n+        else if ((rhs_data->first < place_data->last && rhs_data->seen && place_data->seen))\n+        {\n+            // In the opposite scenario, the lhs comes after the rhs, e.g. [4, 6] [1, 2]. Since we\n+            // assume the input interval states are sorted by time, we assume this is a counter\n+            // reset, and therefore do *not* add the difference between our first value and the\n+            // rhs last value.\n+\n+            place_data->sum += rhs_data->sum;\n+            place_data->last = rhs_data->last;\n+        }\n+        else if (rhs_data->seen && !place_data->seen)\n+        {\n+            // If we're here then the lhs is an empty state and the rhs does have some state, so\n+            // we'll just take that state.\n+\n+            place_data->first = rhs_data->first;\n+            place_data->last = rhs_data->last;\n+            place_data->sum = rhs_data->sum;\n+            place_data->seen = rhs_data->seen;\n+        }\n+\n+        // Otherwise lhs either has data or is uninitialized, so we don't need to modify its values.\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        writeBinaryLittleEndian(this->data(place).sum, buf);\n+        writeBinaryLittleEndian(this->data(place).first, buf);\n+        writeBinaryLittleEndian(this->data(place).last, buf);\n+        writeBinaryLittleEndian(this->data(place).seen, buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        readBinaryLittleEndian(this->data(place).sum, buf);\n+        readBinaryLittleEndian(this->data(place).first, buf);\n+        readBinaryLittleEndian(this->data(place).last, buf);\n+        readBinaryLittleEndian(this->data(place).seen, buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        assert_cast<ColumnVector<T> &>(to).getData().push_back(this->data(place).sum);\n+    }\n+};\n+\n AggregateFunctionPtr createAggregateFunctionDeltaSum(\n     const String & name,\n     const DataTypes & arguments,\ndiff --git a/src/AggregateFunctions/AggregateFunctionDeltaSum.h b/src/AggregateFunctions/AggregateFunctionDeltaSum.h\ndeleted file mode 100644\nindex d64f949825a8..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionDeltaSum.h\n+++ /dev/null\n@@ -1,126 +0,0 @@\n-#pragma once\n-\n-#include <type_traits>\n-\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-\n-#include <Columns/ColumnVector.h>\n-#include <DataTypes/DataTypesDecimal.h>\n-#include <DataTypes/DataTypesNumber.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-template <typename T>\n-struct AggregationFunctionDeltaSumData\n-{\n-    T sum = 0;\n-    T last = 0;\n-    T first = 0;\n-    bool seen = false;\n-};\n-\n-template <typename T>\n-class AggregationFunctionDeltaSum final\n-    : public IAggregateFunctionDataHelper<AggregationFunctionDeltaSumData<T>, AggregationFunctionDeltaSum<T>>\n-{\n-public:\n-    AggregationFunctionDeltaSum(const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper<AggregationFunctionDeltaSumData<T>, AggregationFunctionDeltaSum<T>>{arguments, params, createResultType()}\n-    {}\n-\n-    AggregationFunctionDeltaSum()\n-        : IAggregateFunctionDataHelper<AggregationFunctionDeltaSumData<T>, AggregationFunctionDeltaSum<T>>{}\n-    {}\n-\n-    String getName() const override { return \"deltaSum\"; }\n-\n-    static DataTypePtr createResultType() { return std::make_shared<DataTypeNumber<T>>(); }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void NO_SANITIZE_UNDEFINED ALWAYS_INLINE add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        auto value = assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num];\n-\n-        if ((this->data(place).last < value) && this->data(place).seen)\n-        {\n-            this->data(place).sum += (value - this->data(place).last);\n-        }\n-\n-        this->data(place).last = value;\n-\n-        if (!this->data(place).seen)\n-        {\n-            this->data(place).first = value;\n-            this->data(place).seen = true;\n-        }\n-    }\n-\n-    void NO_SANITIZE_UNDEFINED ALWAYS_INLINE merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        auto place_data = &this->data(place);\n-        auto rhs_data = &this->data(rhs);\n-\n-        if ((place_data->last < rhs_data->first) && place_data->seen && rhs_data->seen)\n-        {\n-            // If the lhs last number seen is less than the first number the rhs saw, the lhs is before\n-            // the rhs, for example [0, 2] [4, 7]. So we want to add the deltasums, but also add the\n-            // difference between lhs last number and rhs first number (the 2 and 4). Then we want to\n-            // take last value from the rhs, so first and last become 0 and 7.\n-\n-            place_data->sum += rhs_data->sum + (rhs_data->first - place_data->last);\n-            place_data->last = rhs_data->last;\n-        }\n-        else if ((rhs_data->first < place_data->last && rhs_data->seen && place_data->seen))\n-        {\n-            // In the opposite scenario, the lhs comes after the rhs, e.g. [4, 6] [1, 2]. Since we\n-            // assume the input interval states are sorted by time, we assume this is a counter\n-            // reset, and therefore do *not* add the difference between our first value and the\n-            // rhs last value.\n-\n-            place_data->sum += rhs_data->sum;\n-            place_data->last = rhs_data->last;\n-        }\n-        else if (rhs_data->seen && !place_data->seen)\n-        {\n-            // If we're here then the lhs is an empty state and the rhs does have some state, so\n-            // we'll just take that state.\n-\n-            place_data->first = rhs_data->first;\n-            place_data->last = rhs_data->last;\n-            place_data->sum = rhs_data->sum;\n-            place_data->seen = rhs_data->seen;\n-        }\n-\n-        // Otherwise lhs either has data or is uninitialized, so we don't need to modify its values.\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        writeBinaryLittleEndian(this->data(place).sum, buf);\n-        writeBinaryLittleEndian(this->data(place).first, buf);\n-        writeBinaryLittleEndian(this->data(place).last, buf);\n-        writeBinaryLittleEndian(this->data(place).seen, buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        readBinaryLittleEndian(this->data(place).sum, buf);\n-        readBinaryLittleEndian(this->data(place).first, buf);\n-        readBinaryLittleEndian(this->data(place).last, buf);\n-        readBinaryLittleEndian(this->data(place).seen, buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        assert_cast<ColumnVector<T> &>(to).getData().push_back(this->data(place).sum);\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionDeltaSumTimestamp.cpp b/src/AggregateFunctions/AggregateFunctionDeltaSumTimestamp.cpp\nindex 6c07e34668f4..5819c533fd96 100644\n--- a/src/AggregateFunctions/AggregateFunctionDeltaSumTimestamp.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionDeltaSumTimestamp.cpp\n@@ -1,22 +1,181 @@\n-#include <AggregateFunctions/AggregateFunctionDeltaSumTimestamp.h>\n-\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n #include <AggregateFunctions/Helpers.h>\n \n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+\n+#include <Columns/ColumnVector.h>\n+#include <DataTypes/DataTypesNumber.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+\n \n namespace DB\n {\n \n namespace ErrorCodes\n {\n-    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n }\n \n namespace\n {\n \n+template <typename ValueType, typename TimestampType>\n+struct AggregationFunctionDeltaSumTimestampData\n+{\n+    ValueType sum = 0;\n+    ValueType first = 0;\n+    ValueType last = 0;\n+    TimestampType first_ts = 0;\n+    TimestampType last_ts = 0;\n+    bool seen = false;\n+};\n+\n+template <typename ValueType, typename TimestampType>\n+class AggregationFunctionDeltaSumTimestamp final\n+    : public IAggregateFunctionDataHelper<\n+        AggregationFunctionDeltaSumTimestampData<ValueType, TimestampType>,\n+        AggregationFunctionDeltaSumTimestamp<ValueType, TimestampType>\n+      >\n+{\n+public:\n+    AggregationFunctionDeltaSumTimestamp(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<\n+            AggregationFunctionDeltaSumTimestampData<ValueType, TimestampType>,\n+            AggregationFunctionDeltaSumTimestamp<ValueType, TimestampType>\n+        >{arguments, params, createResultType()}\n+    {}\n+\n+    AggregationFunctionDeltaSumTimestamp()\n+        : IAggregateFunctionDataHelper<\n+            AggregationFunctionDeltaSumTimestampData<ValueType, TimestampType>,\n+            AggregationFunctionDeltaSumTimestamp<ValueType, TimestampType>\n+        >{}\n+    {}\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    String getName() const override { return \"deltaSumTimestamp\"; }\n+\n+    static DataTypePtr createResultType() { return std::make_shared<DataTypeNumber<ValueType>>(); }\n+\n+    void NO_SANITIZE_UNDEFINED ALWAYS_INLINE add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        auto value = assert_cast<const ColumnVector<ValueType> &>(*columns[0]).getData()[row_num];\n+        auto ts = assert_cast<const ColumnVector<TimestampType> &>(*columns[1]).getData()[row_num];\n+\n+        auto & data = this->data(place);\n+\n+        if ((data.last < value) && data.seen)\n+        {\n+            data.sum += (value - data.last);\n+        }\n+\n+        data.last = value;\n+        data.last_ts = ts;\n+\n+        if (!data.seen)\n+        {\n+            data.first = value;\n+            data.seen = true;\n+            data.first_ts = ts;\n+        }\n+    }\n+\n+    // before returns true if lhs is before rhs or false if it is not or can't be determined\n+    bool ALWAYS_INLINE before(\n+        const AggregationFunctionDeltaSumTimestampData<ValueType, TimestampType> & lhs,\n+        const AggregationFunctionDeltaSumTimestampData<ValueType, TimestampType> & rhs) const\n+    {\n+        if (lhs.last_ts < rhs.first_ts)\n+            return true;\n+        if (lhs.last_ts == rhs.first_ts && (lhs.last_ts < rhs.last_ts || lhs.first_ts < rhs.first_ts))\n+            return true;\n+        return false;\n+    }\n+\n+    void NO_SANITIZE_UNDEFINED merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        auto & place_data = this->data(place);\n+        auto & rhs_data = this->data(rhs);\n+\n+        if (!place_data.seen && rhs_data.seen)\n+        {\n+            place_data.sum = rhs_data.sum;\n+            place_data.seen = true;\n+            place_data.first = rhs_data.first;\n+            place_data.first_ts = rhs_data.first_ts;\n+            place_data.last = rhs_data.last;\n+            place_data.last_ts = rhs_data.last_ts;\n+        }\n+        else if (place_data.seen && !rhs_data.seen)\n+        {\n+            return;\n+        }\n+        else if (before(place_data, rhs_data))\n+        {\n+            // This state came before the rhs state\n+\n+            if (rhs_data.first > place_data.last)\n+                place_data.sum += (rhs_data.first - place_data.last);\n+            place_data.sum += rhs_data.sum;\n+            place_data.last = rhs_data.last;\n+            place_data.last_ts = rhs_data.last_ts;\n+        }\n+        else if (before(rhs_data, place_data))\n+        {\n+            // This state came after the rhs state\n+\n+            if (place_data.first > rhs_data.last)\n+                place_data.sum += (place_data.first - rhs_data.last);\n+            place_data.sum += rhs_data.sum;\n+            place_data.first = rhs_data.first;\n+            place_data.first_ts = rhs_data.first_ts;\n+        }\n+        else\n+        {\n+            // If none of those conditions matched, it means both states we are merging have all\n+            // same timestamps. We have to pick either the smaller or larger value so that the\n+            // result is deterministic.\n+\n+            if (place_data.first < rhs_data.first)\n+            {\n+                place_data.first = rhs_data.first;\n+                place_data.last = rhs_data.last;\n+            }\n+        }\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        const auto & data = this->data(place);\n+        writeBinaryLittleEndian(data.sum, buf);\n+        writeBinaryLittleEndian(data.first, buf);\n+        writeBinaryLittleEndian(data.first_ts, buf);\n+        writeBinaryLittleEndian(data.last, buf);\n+        writeBinaryLittleEndian(data.last_ts, buf);\n+        writeBinaryLittleEndian(data.seen, buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        auto & data = this->data(place);\n+        readBinaryLittleEndian(data.sum, buf);\n+        readBinaryLittleEndian(data.first, buf);\n+        readBinaryLittleEndian(data.first_ts, buf);\n+        readBinaryLittleEndian(data.last, buf);\n+        readBinaryLittleEndian(data.last_ts, buf);\n+        readBinaryLittleEndian(data.seen, buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        assert_cast<ColumnVector<ValueType> &>(to).getData().push_back(this->data(place).sum);\n+    }\n+};\n+\n AggregateFunctionPtr createAggregateFunctionDeltaSumTimestamp(\n     const String & name,\n     const DataTypes & arguments,\n@@ -24,10 +183,7 @@ AggregateFunctionPtr createAggregateFunctionDeltaSumTimestamp(\n     const Settings *)\n {\n     assertNoParameters(name, params);\n-\n-    if (arguments.size() != 2)\n-        throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n-            \"Incorrect number of arguments for aggregate function {}\", name);\n+    assertBinary(name, arguments);\n \n     if (!isInteger(arguments[0]) && !isFloat(arguments[0]) && !isDate(arguments[0]) && !isDateTime(arguments[0]))\n         throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}, \"\ndiff --git a/src/AggregateFunctions/AggregateFunctionDeltaSumTimestamp.h b/src/AggregateFunctions/AggregateFunctionDeltaSumTimestamp.h\ndeleted file mode 100644\nindex 5eeb1425afb7..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionDeltaSumTimestamp.h\n+++ /dev/null\n@@ -1,171 +0,0 @@\n-#pragma once\n-\n-#include <type_traits>\n-\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-\n-#include <Columns/ColumnVector.h>\n-#include <DataTypes/DataTypesDecimal.h>\n-#include <DataTypes/DataTypesNumber.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-\n-namespace DB\n-{\n-\n-template <typename ValueType, typename TimestampType>\n-struct AggregationFunctionDeltaSumTimestampData\n-{\n-    ValueType sum = 0;\n-    ValueType first = 0;\n-    ValueType last = 0;\n-    TimestampType first_ts = 0;\n-    TimestampType last_ts = 0;\n-    bool seen = false;\n-};\n-\n-template <typename ValueType, typename TimestampType>\n-class AggregationFunctionDeltaSumTimestamp final\n-    : public IAggregateFunctionDataHelper<\n-        AggregationFunctionDeltaSumTimestampData<ValueType, TimestampType>,\n-        AggregationFunctionDeltaSumTimestamp<ValueType, TimestampType>\n-      >\n-{\n-public:\n-    AggregationFunctionDeltaSumTimestamp(const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper<\n-            AggregationFunctionDeltaSumTimestampData<ValueType, TimestampType>,\n-            AggregationFunctionDeltaSumTimestamp<ValueType, TimestampType>\n-        >{arguments, params, createResultType()}\n-    {}\n-\n-    AggregationFunctionDeltaSumTimestamp()\n-        : IAggregateFunctionDataHelper<\n-            AggregationFunctionDeltaSumTimestampData<ValueType, TimestampType>,\n-            AggregationFunctionDeltaSumTimestamp<ValueType, TimestampType>\n-        >{}\n-    {}\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    String getName() const override { return \"deltaSumTimestamp\"; }\n-\n-    static DataTypePtr createResultType() { return std::make_shared<DataTypeNumber<ValueType>>(); }\n-\n-    void NO_SANITIZE_UNDEFINED ALWAYS_INLINE add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        auto value = assert_cast<const ColumnVector<ValueType> &>(*columns[0]).getData()[row_num];\n-        auto ts = assert_cast<const ColumnVector<TimestampType> &>(*columns[1]).getData()[row_num];\n-\n-        if ((this->data(place).last < value) && this->data(place).seen)\n-        {\n-            this->data(place).sum += (value - this->data(place).last);\n-        }\n-\n-        this->data(place).last = value;\n-        this->data(place).last_ts = ts;\n-\n-        if (!this->data(place).seen)\n-        {\n-            this->data(place).first = value;\n-            this->data(place).seen = true;\n-            this->data(place).first_ts = ts;\n-        }\n-    }\n-\n-    // before returns true if lhs is before rhs or false if it is not or can't be determined\n-    bool ALWAYS_INLINE before (\n-        const AggregationFunctionDeltaSumTimestampData<ValueType, TimestampType> * lhs,\n-        const AggregationFunctionDeltaSumTimestampData<ValueType, TimestampType> * rhs\n-    ) const\n-    {\n-        if (lhs->last_ts < rhs->first_ts)\n-        {\n-            return true;\n-        }\n-        if (lhs->last_ts == rhs->first_ts && (lhs->last_ts < rhs->last_ts || lhs->first_ts < rhs->first_ts))\n-        {\n-            return true;\n-        }\n-        return false;\n-    }\n-\n-    void NO_SANITIZE_UNDEFINED ALWAYS_INLINE merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        auto place_data = &this->data(place);\n-        auto rhs_data = &this->data(rhs);\n-\n-        if (!place_data->seen && rhs_data->seen)\n-        {\n-            place_data->sum = rhs_data->sum;\n-            place_data->seen = true;\n-            place_data->first = rhs_data->first;\n-            place_data->first_ts = rhs_data->first_ts;\n-            place_data->last = rhs_data->last;\n-            place_data->last_ts = rhs_data->last_ts;\n-        }\n-        else if (place_data->seen && !rhs_data->seen)\n-            return;\n-        else if (before(place_data, rhs_data))\n-        {\n-            // This state came before the rhs state\n-\n-            if (rhs_data->first > place_data->last)\n-                place_data->sum += (rhs_data->first - place_data->last);\n-            place_data->sum += rhs_data->sum;\n-            place_data->last = rhs_data->last;\n-            place_data->last_ts = rhs_data->last_ts;\n-        }\n-        else if (before(rhs_data, place_data))\n-        {\n-            // This state came after the rhs state\n-\n-            if (place_data->first > rhs_data->last)\n-                place_data->sum += (place_data->first - rhs_data->last);\n-            place_data->sum += rhs_data->sum;\n-            place_data->first = rhs_data->first;\n-            place_data->first_ts = rhs_data->first_ts;\n-        }\n-        else\n-        {\n-            // If none of those conditions matched, it means both states we are merging have all\n-            // same timestamps. We have to pick either the smaller or larger value so that the\n-            // result is deterministic.\n-\n-            if (place_data->first < rhs_data->first)\n-            {\n-                place_data->first = rhs_data->first;\n-                place_data->last = rhs_data->last;\n-            }\n-        }\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        writeBinaryLittleEndian(this->data(place).sum, buf);\n-        writeBinaryLittleEndian(this->data(place).first, buf);\n-        writeBinaryLittleEndian(this->data(place).first_ts, buf);\n-        writeBinaryLittleEndian(this->data(place).last, buf);\n-        writeBinaryLittleEndian(this->data(place).last_ts, buf);\n-        writeBinaryLittleEndian(this->data(place).seen, buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        readBinaryLittleEndian(this->data(place).sum, buf);\n-        readBinaryLittleEndian(this->data(place).first, buf);\n-        readBinaryLittleEndian(this->data(place).first_ts, buf);\n-        readBinaryLittleEndian(this->data(place).last, buf);\n-        readBinaryLittleEndian(this->data(place).last_ts, buf);\n-        readBinaryLittleEndian(this->data(place).seen, buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        assert_cast<ColumnVector<ValueType> &>(to).getData().push_back(this->data(place).sum);\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionEntropy.cpp b/src/AggregateFunctions/AggregateFunctionEntropy.cpp\nindex 373a80c395c3..e3b4aecff712 100644\n--- a/src/AggregateFunctions/AggregateFunctionEntropy.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionEntropy.cpp\n@@ -1,8 +1,18 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionEntropy.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n #include <AggregateFunctions/Helpers.h>\n \n+#include <Common/HashTable/HashMap.h>\n+#include <Common/NaNUtils.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/UniqVariadicHash.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <Columns/ColumnVector.h>\n+#include <Common/assert_cast.h>\n+\n+#include <cmath>\n+\n \n namespace DB\n {\n@@ -16,6 +26,133 @@ namespace ErrorCodes\n namespace\n {\n \n+/** Calculates Shannon Entropy, using HashMap and computing empirical distribution function.\n+  * Entropy is measured in bits (base-2 logarithm is used).\n+  */\n+template <typename Value>\n+struct EntropyData\n+{\n+    using Weight = UInt64;\n+\n+    using HashingMap = HashMapWithStackMemory<Value, Weight, HashCRC32<Value>, 4>;\n+\n+    /// For the case of pre-hashed values.\n+    using TrivialMap = HashMapWithStackMemory<Value, Weight, UInt128TrivialHash, 4>;\n+\n+    using Map = std::conditional_t<std::is_same_v<UInt128, Value>, TrivialMap, HashingMap>;\n+\n+    Map map;\n+\n+    void add(const Value & x)\n+    {\n+        if (!isNaN(x))\n+            ++map[x];\n+    }\n+\n+    void add(const Value & x, const Weight & weight)\n+    {\n+        if (!isNaN(x))\n+            map[x] += weight;\n+    }\n+\n+    void merge(const EntropyData & rhs)\n+    {\n+        for (const auto & pair : rhs.map)\n+            map[pair.getKey()] += pair.getMapped();\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        map.write(buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        typename Map::Reader reader(buf);\n+        while (reader.next())\n+        {\n+            const auto & pair = reader.get();\n+            map[pair.first] = pair.second;\n+        }\n+    }\n+\n+    Float64 get() const\n+    {\n+        UInt64 total_value = 0;\n+        for (const auto & pair : map)\n+            total_value += pair.getMapped();\n+\n+        Float64 shannon_entropy = 0;\n+        for (const auto & pair : map)\n+        {\n+            Float64 frequency = Float64(pair.getMapped()) / total_value;\n+            shannon_entropy -= frequency * log2(frequency);\n+        }\n+\n+        return shannon_entropy;\n+    }\n+};\n+\n+\n+template <typename Value>\n+class AggregateFunctionEntropy final : public IAggregateFunctionDataHelper<EntropyData<Value>, AggregateFunctionEntropy<Value>>\n+{\n+private:\n+    size_t num_args;\n+\n+public:\n+    explicit AggregateFunctionEntropy(const DataTypes & argument_types_)\n+        : IAggregateFunctionDataHelper<EntropyData<Value>, AggregateFunctionEntropy<Value>>(argument_types_, {}, createResultType())\n+        , num_args(argument_types_.size())\n+    {\n+    }\n+\n+    String getName() const override { return \"entropy\"; }\n+\n+    static DataTypePtr createResultType()\n+    {\n+        return std::make_shared<DataTypeNumber<Float64>>();\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        if constexpr (!std::is_same_v<UInt128, Value>)\n+        {\n+            /// Here we manage only with numerical types\n+            const auto & column = assert_cast<const ColumnVector <Value> &>(*columns[0]);\n+            this->data(place).add(column.getData()[row_num]);\n+        }\n+        else\n+        {\n+            this->data(place).add(UniqVariadicHash<true, false>::apply(num_args, columns, row_num));\n+        }\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(const_cast<AggregateDataPtr>(place)).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        auto & column = assert_cast<ColumnVector<Float64> &>(to);\n+        column.getData().push_back(this->data(place).get());\n+    }\n+};\n+\n+\n AggregateFunctionPtr createAggregateFunctionEntropy(\n     const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n {\ndiff --git a/src/AggregateFunctions/AggregateFunctionEntropy.h b/src/AggregateFunctions/AggregateFunctionEntropy.h\ndeleted file mode 100644\nindex 9321b5c5825f..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionEntropy.h\n+++ /dev/null\n@@ -1,145 +0,0 @@\n-#pragma once\n-\n-#include <Common/HashTable/HashMap.h>\n-#include <Common/NaNUtils.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/UniqVariadicHash.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <Columns/ColumnVector.h>\n-#include <Common/assert_cast.h>\n-\n-#include <cmath>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-/** Calculates Shannon Entropy, using HashMap and computing empirical distribution function.\n-  * Entropy is measured in bits (base-2 logarithm is used).\n-  */\n-template <typename Value>\n-struct EntropyData\n-{\n-    using Weight = UInt64;\n-\n-    using HashingMap = HashMapWithStackMemory<Value, Weight, HashCRC32<Value>, 4>;\n-\n-    /// For the case of pre-hashed values.\n-    using TrivialMap = HashMapWithStackMemory<Value, Weight, UInt128TrivialHash, 4>;\n-\n-    using Map = std::conditional_t<std::is_same_v<UInt128, Value>, TrivialMap, HashingMap>;\n-\n-    Map map;\n-\n-    void add(const Value & x)\n-    {\n-        if (!isNaN(x))\n-            ++map[x];\n-    }\n-\n-    void add(const Value & x, const Weight & weight)\n-    {\n-        if (!isNaN(x))\n-            map[x] += weight;\n-    }\n-\n-    void merge(const EntropyData & rhs)\n-    {\n-        for (const auto & pair : rhs.map)\n-            map[pair.getKey()] += pair.getMapped();\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        map.write(buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        typename Map::Reader reader(buf);\n-        while (reader.next())\n-        {\n-            const auto & pair = reader.get();\n-            map[pair.first] = pair.second;\n-        }\n-    }\n-\n-    Float64 get() const\n-    {\n-        UInt64 total_value = 0;\n-        for (const auto & pair : map)\n-            total_value += pair.getMapped();\n-\n-        Float64 shannon_entropy = 0;\n-        for (const auto & pair : map)\n-        {\n-            Float64 frequency = Float64(pair.getMapped()) / total_value;\n-            shannon_entropy -= frequency * log2(frequency);\n-        }\n-\n-        return shannon_entropy;\n-    }\n-};\n-\n-\n-template <typename Value>\n-class AggregateFunctionEntropy final : public IAggregateFunctionDataHelper<EntropyData<Value>, AggregateFunctionEntropy<Value>>\n-{\n-private:\n-    size_t num_args;\n-\n-public:\n-    explicit AggregateFunctionEntropy(const DataTypes & argument_types_)\n-        : IAggregateFunctionDataHelper<EntropyData<Value>, AggregateFunctionEntropy<Value>>(argument_types_, {}, createResultType())\n-        , num_args(argument_types_.size())\n-    {\n-    }\n-\n-    String getName() const override { return \"entropy\"; }\n-\n-    static DataTypePtr createResultType()\n-    {\n-        return std::make_shared<DataTypeNumber<Float64>>();\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        if constexpr (!std::is_same_v<UInt128, Value>)\n-        {\n-            /// Here we manage only with numerical types\n-            const auto & column = assert_cast<const ColumnVector <Value> &>(*columns[0]);\n-            this->data(place).add(column.getData()[row_num]);\n-        }\n-        else\n-        {\n-            this->data(place).add(UniqVariadicHash<true, false>::apply(num_args, columns, row_num));\n-        }\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(const_cast<AggregateDataPtr>(place)).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).deserialize(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        auto & column = assert_cast<ColumnVector<Float64> &>(to);\n-        column.getData().push_back(this->data(place).get());\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionGroupArray.cpp b/src/AggregateFunctions/AggregateFunctionGroupArray.cpp\nindex fec4a6fe50ae..b95471df90a3 100644\n--- a/src/AggregateFunctions/AggregateFunctionGroupArray.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionGroupArray.cpp\n@@ -1,12 +1,32 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionGroupArray.h>\n #include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n-#include <DataTypes/DataTypeDate.h>\n-#include <DataTypes/DataTypeDateTime.h>\n #include <Interpreters/Context.h>\n #include <Core/ServerSettings.h>\n \n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadBufferFromString.h>\n+#include <IO/WriteBufferFromString.h>\n+#include <IO/Operators.h>\n+\n+#include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypeString.h>\n+#include <DataTypes/DataTypesNumber.h>\n+\n+#include <Columns/ColumnArray.h>\n+#include <Columns/ColumnString.h>\n+#include <Columns/ColumnVector.h>\n+\n+#include <Common/ArenaAllocator.h>\n+#include <Common/assert_cast.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+\n+#include <type_traits>\n+\n+#define AGGREGATE_FUNCTION_GROUP_ARRAY_MAX_ELEMENT_SIZE 0xFFFFFF\n+\n \n namespace DB\n {\n@@ -16,11 +36,670 @@ namespace ErrorCodes\n {\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n     extern const int BAD_ARGUMENTS;\n+    extern const int TOO_LARGE_ARRAY_SIZE;\n }\n \n namespace\n {\n \n+enum class Sampler\n+{\n+    NONE,\n+    RNG,\n+};\n+\n+template <bool Thas_limit, bool Tlast, Sampler Tsampler>\n+struct GroupArrayTrait\n+{\n+    static constexpr bool has_limit = Thas_limit;\n+    static constexpr bool last = Tlast;\n+    static constexpr Sampler sampler = Tsampler;\n+};\n+\n+template <typename Trait>\n+constexpr const char * getNameByTrait()\n+{\n+    if (Trait::last)\n+        return \"groupArrayLast\";\n+    if (Trait::sampler == Sampler::NONE)\n+        return \"groupArray\";\n+    else if (Trait::sampler == Sampler::RNG)\n+        return \"groupArraySample\";\n+\n+    UNREACHABLE();\n+}\n+\n+template <typename T>\n+struct GroupArraySamplerData\n+{\n+    /// For easy serialization.\n+    static_assert(std::has_unique_object_representations_v<T> || std::is_floating_point_v<T>);\n+\n+    // Switch to ordinary Allocator after 4096 bytes to avoid fragmentation and trash in Arena\n+    using Allocator = MixedAlignedArenaAllocator<alignof(T), 4096>;\n+    using Array = PODArray<T, 32, Allocator>;\n+\n+    Array value;\n+    size_t total_values = 0;\n+    pcg32_fast rng;\n+\n+    UInt64 genRandom(size_t lim)\n+    {\n+        chassert(lim != 0);\n+\n+        /// With a large number of values, we will generate random numbers several times slower.\n+        if (lim <= static_cast<UInt64>(rng.max()))\n+            return rng() % lim;\n+        else\n+            return (static_cast<UInt64>(rng()) * (static_cast<UInt64>(rng.max()) + 1ULL) + static_cast<UInt64>(rng())) % lim;\n+    }\n+\n+    void randomShuffle()\n+    {\n+        size_t size = value.size();\n+        chassert(size < std::numeric_limits<size_t>::max());\n+\n+        for (size_t i = 1; i < size; ++i)\n+        {\n+            size_t j = genRandom(i + 1);\n+            std::swap(value[i], value[j]);\n+        }\n+    }\n+};\n+\n+/// A particular case is an implementation for numeric types.\n+template <typename T, bool has_sampler>\n+struct GroupArrayNumericData;\n+\n+template <typename T>\n+struct GroupArrayNumericData<T, false>\n+{\n+    /// For easy serialization.\n+    static_assert(std::has_unique_object_representations_v<T> || std::is_floating_point_v<T>);\n+\n+    // Switch to ordinary Allocator after 4096 bytes to avoid fragmentation and trash in Arena\n+    using Allocator = MixedAlignedArenaAllocator<alignof(T), 4096>;\n+    using Array = PODArray<T, 32, Allocator>;\n+\n+    // For groupArrayLast()\n+    size_t total_values = 0;\n+    Array value;\n+};\n+\n+template <typename T>\n+struct GroupArrayNumericData<T, true> : public GroupArraySamplerData<T>\n+{\n+};\n+\n+template <typename T, typename Trait>\n+class GroupArrayNumericImpl final\n+    : public IAggregateFunctionDataHelper<GroupArrayNumericData<T, Trait::sampler != Sampler::NONE>, GroupArrayNumericImpl<T, Trait>>\n+{\n+    using Data = GroupArrayNumericData<T, Trait::sampler != Sampler::NONE>;\n+    static constexpr bool limit_num_elems = Trait::has_limit;\n+    UInt64 max_elems;\n+    std::optional<UInt64> seed;\n+\n+public:\n+    explicit GroupArrayNumericImpl(\n+        const DataTypePtr & data_type_, const Array & parameters_, UInt64 max_elems_, std::optional<UInt64> seed_)\n+        : IAggregateFunctionDataHelper<GroupArrayNumericData<T, Trait::sampler != Sampler::NONE>, GroupArrayNumericImpl<T, Trait>>(\n+            {data_type_}, parameters_, std::make_shared<DataTypeArray>(data_type_))\n+        , max_elems(max_elems_)\n+        , seed(seed_)\n+    {\n+    }\n+\n+    String getName() const override { return getNameByTrait<Trait>(); }\n+\n+    void insertWithSampler(Data & a, const T & v, Arena * arena) const\n+    {\n+        ++a.total_values;\n+        if (a.value.size() < max_elems)\n+            a.value.push_back(v, arena);\n+        else\n+        {\n+            UInt64 rnd = a.genRandom(a.total_values);\n+            if (rnd < max_elems)\n+                a.value[rnd] = v;\n+        }\n+    }\n+\n+    void create(AggregateDataPtr __restrict place) const override /// NOLINT\n+    {\n+        [[maybe_unused]] auto a = new (place) Data;\n+        if constexpr (Trait::sampler == Sampler::RNG)\n+            a->rng.seed(seed.value_or(thread_local_rng()));\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        const auto & row_value = assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num];\n+        auto & cur_elems = this->data(place);\n+\n+        ++cur_elems.total_values;\n+\n+        if constexpr (Trait::sampler == Sampler::NONE)\n+        {\n+            if (limit_num_elems && cur_elems.value.size() >= max_elems)\n+            {\n+                if constexpr (Trait::last)\n+                    cur_elems.value[(cur_elems.total_values - 1) % max_elems] = row_value;\n+                return;\n+            }\n+\n+            cur_elems.value.push_back(row_value, arena);\n+        }\n+\n+        if constexpr (Trait::sampler == Sampler::RNG)\n+        {\n+            if (cur_elems.value.size() < max_elems)\n+                cur_elems.value.push_back(row_value, arena);\n+            else\n+            {\n+                UInt64 rnd = cur_elems.genRandom(cur_elems.total_values);\n+                if (rnd < max_elems)\n+                    cur_elems.value[rnd] = row_value;\n+            }\n+        }\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n+    {\n+        auto & cur_elems = this->data(place);\n+        auto & rhs_elems = this->data(rhs);\n+\n+        if (rhs_elems.value.empty())\n+            return;\n+\n+        if constexpr (Trait::last)\n+            mergeNoSamplerLast(cur_elems, rhs_elems, arena);\n+        else if constexpr (Trait::sampler == Sampler::NONE)\n+            mergeNoSampler(cur_elems, rhs_elems, arena);\n+        else if constexpr (Trait::sampler == Sampler::RNG)\n+            mergeWithRNGSampler(cur_elems, rhs_elems, arena);\n+    }\n+\n+    void mergeNoSamplerLast(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n+    {\n+        UInt64 new_elements = std::min(static_cast<size_t>(max_elems), cur_elems.value.size() + rhs_elems.value.size());\n+        cur_elems.value.resize_exact(new_elements, arena);\n+        for (auto & value : rhs_elems.value)\n+        {\n+            cur_elems.value[cur_elems.total_values % max_elems] = value;\n+            ++cur_elems.total_values;\n+        }\n+        chassert(rhs_elems.total_values >= rhs_elems.value.size());\n+        cur_elems.total_values += rhs_elems.total_values - rhs_elems.value.size();\n+    }\n+\n+    void mergeNoSampler(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n+    {\n+        if (!limit_num_elems)\n+        {\n+            if (rhs_elems.value.size())\n+                cur_elems.value.insertByOffsets(rhs_elems.value, 0, rhs_elems.value.size(), arena);\n+        }\n+        else\n+        {\n+            UInt64 elems_to_insert = std::min(static_cast<size_t>(max_elems) - cur_elems.value.size(), rhs_elems.value.size());\n+            if (elems_to_insert)\n+                cur_elems.value.insertByOffsets(rhs_elems.value, 0, elems_to_insert, arena);\n+        }\n+    }\n+\n+    void mergeWithRNGSampler(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n+    {\n+        if (rhs_elems.total_values <= max_elems)\n+        {\n+            for (size_t i = 0; i < rhs_elems.value.size(); ++i)\n+                insertWithSampler(cur_elems, rhs_elems.value[i], arena);\n+        }\n+        else if (cur_elems.total_values <= max_elems)\n+        {\n+            decltype(cur_elems.value) from;\n+            from.swap(cur_elems.value, arena);\n+            cur_elems.value.assign(rhs_elems.value.begin(), rhs_elems.value.end(), arena);\n+            cur_elems.total_values = rhs_elems.total_values;\n+            for (size_t i = 0; i < from.size(); ++i)\n+                insertWithSampler(cur_elems, from[i], arena);\n+        }\n+        else\n+        {\n+            cur_elems.randomShuffle();\n+            cur_elems.total_values += rhs_elems.total_values;\n+            for (size_t i = 0; i < max_elems; ++i)\n+            {\n+                UInt64 rnd = cur_elems.genRandom(cur_elems.total_values);\n+                if (rnd < rhs_elems.total_values)\n+                    cur_elems.value[i] = rhs_elems.value[i];\n+            }\n+        }\n+    }\n+\n+    static void checkArraySize(size_t elems, size_t max_elems)\n+    {\n+        if (unlikely(elems > max_elems))\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n+                            \"Too large array size {} (maximum: {})\", elems, max_elems);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        const auto & value = this->data(place).value;\n+        const UInt64 size = value.size();\n+        checkArraySize(size, max_elems);\n+        writeVarUInt(size, buf);\n+        for (const auto & element : value)\n+            writeBinaryLittleEndian(element, buf);\n+\n+        if constexpr (Trait::last)\n+            writeBinaryLittleEndian(this->data(place).total_values, buf);\n+\n+        if constexpr (Trait::sampler == Sampler::RNG)\n+        {\n+            writeBinaryLittleEndian(this->data(place).total_values, buf);\n+            WriteBufferFromOwnString rng_buf;\n+            rng_buf << this->data(place).rng;\n+            writeStringBinary(rng_buf.str(), buf);\n+        }\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n+    {\n+        size_t size = 0;\n+        readVarUInt(size, buf);\n+        checkArraySize(size, max_elems);\n+\n+        auto & value = this->data(place).value;\n+\n+        value.resize_exact(size, arena);\n+        for (auto & element : value)\n+            readBinaryLittleEndian(element, buf);\n+\n+        if constexpr (Trait::last)\n+            readBinaryLittleEndian(this->data(place).total_values, buf);\n+\n+        if constexpr (Trait::sampler == Sampler::RNG)\n+        {\n+            readBinaryLittleEndian(this->data(place).total_values, buf);\n+            std::string rng_string;\n+            readStringBinary(rng_string, buf);\n+            ReadBufferFromString rng_buf(rng_string);\n+            rng_buf >> this->data(place).rng;\n+        }\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        const auto & value = this->data(place).value;\n+        size_t size = value.size();\n+\n+        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n+        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n+\n+        offsets_to.push_back(offsets_to.back() + size);\n+\n+        if (size)\n+        {\n+            typename ColumnVector<T>::Container & data_to = assert_cast<ColumnVector<T> &>(arr_to.getData()).getData();\n+            data_to.insert(this->data(place).value.begin(), this->data(place).value.end());\n+        }\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return true; }\n+};\n+\n+\n+/// General case\n+\n+\n+/// Nodes used to implement a linked list for storage of groupArray states\n+\n+template <typename Node>\n+struct GroupArrayNodeBase\n+{\n+    UInt64 size; // size of payload\n+\n+    /// Returns pointer to actual payload\n+    char * data() { return reinterpret_cast<char *>(this) + sizeof(Node); }\n+\n+    const char * data() const { return reinterpret_cast<const char *>(this) + sizeof(Node); }\n+\n+    /// Clones existing node (does not modify next field)\n+    Node * clone(Arena * arena) const\n+    {\n+        return reinterpret_cast<Node *>(\n+            const_cast<char *>(arena->alignedInsert(reinterpret_cast<const char *>(this), sizeof(Node) + size, alignof(Node))));\n+    }\n+\n+    static void checkElementSize(size_t size, size_t max_size)\n+    {\n+        if (unlikely(size > max_size))\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n+                            \"Too large array element size {} (maximum: {})\", size, max_size);\n+    }\n+\n+    /// Write node to buffer\n+    void write(WriteBuffer & buf) const\n+    {\n+        checkElementSize(size, AGGREGATE_FUNCTION_GROUP_ARRAY_MAX_ELEMENT_SIZE);\n+        writeVarUInt(size, buf);\n+        buf.write(data(), size);\n+    }\n+\n+    /// Reads and allocates node from ReadBuffer's data (doesn't set next)\n+    static Node * read(ReadBuffer & buf, Arena * arena)\n+    {\n+        UInt64 size;\n+        readVarUInt(size, buf);\n+        checkElementSize(size, AGGREGATE_FUNCTION_GROUP_ARRAY_MAX_ELEMENT_SIZE);\n+\n+        Node * node = reinterpret_cast<Node *>(arena->alignedAlloc(sizeof(Node) + size, alignof(Node)));\n+        node->size = size;\n+        buf.readStrict(node->data(), size);\n+        return node;\n+    }\n+};\n+\n+struct GroupArrayNodeString : public GroupArrayNodeBase<GroupArrayNodeString>\n+{\n+    using Node = GroupArrayNodeString;\n+\n+    /// Create node from string\n+    static Node * allocate(const IColumn & column, size_t row_num, Arena * arena)\n+    {\n+        StringRef string = assert_cast<const ColumnString &>(column).getDataAt(row_num);\n+\n+        Node * node = reinterpret_cast<Node *>(arena->alignedAlloc(sizeof(Node) + string.size, alignof(Node)));\n+        node->size = string.size;\n+        memcpy(node->data(), string.data, string.size);\n+\n+        return node;\n+    }\n+\n+    void insertInto(IColumn & column)\n+    {\n+        assert_cast<ColumnString &>(column).insertData(data(), size);\n+    }\n+};\n+\n+struct GroupArrayNodeGeneral : public GroupArrayNodeBase<GroupArrayNodeGeneral>\n+{\n+    using Node = GroupArrayNodeGeneral;\n+\n+    static Node * allocate(const IColumn & column, size_t row_num, Arena * arena)\n+    {\n+        const char * begin = arena->alignedAlloc(sizeof(Node), alignof(Node));\n+        StringRef value = column.serializeValueIntoArena(row_num, *arena, begin);\n+\n+        Node * node = reinterpret_cast<Node *>(const_cast<char *>(begin));\n+        node->size = value.size;\n+\n+        return node;\n+    }\n+\n+    void insertInto(IColumn & column) { column.deserializeAndInsertFromArena(data()); }\n+};\n+\n+template <typename Node, bool has_sampler>\n+struct GroupArrayGeneralData;\n+\n+template <typename Node>\n+struct GroupArrayGeneralData<Node, false>\n+{\n+    // Switch to ordinary Allocator after 4096 bytes to avoid fragmentation and trash in Arena\n+    using Allocator = MixedAlignedArenaAllocator<alignof(Node *), 4096>;\n+    using Array = PODArray<Node *, 32, Allocator>;\n+\n+    // For groupArrayLast()\n+    size_t total_values = 0;\n+    Array value;\n+};\n+\n+template <typename Node>\n+struct GroupArrayGeneralData<Node, true> : public GroupArraySamplerData<Node *>\n+{\n+};\n+\n+/// Implementation of groupArray for String or any ComplexObject via Array\n+template <typename Node, typename Trait>\n+class GroupArrayGeneralImpl final\n+    : public IAggregateFunctionDataHelper<GroupArrayGeneralData<Node, Trait::sampler != Sampler::NONE>, GroupArrayGeneralImpl<Node, Trait>>\n+{\n+    static constexpr bool limit_num_elems = Trait::has_limit;\n+    using Data = GroupArrayGeneralData<Node, Trait::sampler != Sampler::NONE>;\n+    static Data & data(AggregateDataPtr __restrict place) { return *reinterpret_cast<Data *>(place); }\n+    static const Data & data(ConstAggregateDataPtr __restrict place) { return *reinterpret_cast<const Data *>(place); }\n+\n+    DataTypePtr & data_type;\n+    UInt64 max_elems;\n+    std::optional<UInt64> seed;\n+\n+public:\n+    GroupArrayGeneralImpl(const DataTypePtr & data_type_, const Array & parameters_, UInt64 max_elems_, std::optional<UInt64> seed_)\n+        : IAggregateFunctionDataHelper<GroupArrayGeneralData<Node, Trait::sampler != Sampler::NONE>, GroupArrayGeneralImpl<Node, Trait>>(\n+            {data_type_}, parameters_, std::make_shared<DataTypeArray>(data_type_))\n+        , data_type(this->argument_types[0])\n+        , max_elems(max_elems_)\n+        , seed(seed_)\n+    {\n+    }\n+\n+    String getName() const override { return getNameByTrait<Trait>(); }\n+\n+    void insertWithSampler(Data & a, const Node * v, Arena * arena) const\n+    {\n+        ++a.total_values;\n+        if (a.value.size() < max_elems)\n+            a.value.push_back(v->clone(arena), arena);\n+        else\n+        {\n+            UInt64 rnd = a.genRandom(a.total_values);\n+            if (rnd < max_elems)\n+                a.value[rnd] = v->clone(arena);\n+        }\n+    }\n+\n+    void create(AggregateDataPtr __restrict place) const override /// NOLINT\n+    {\n+        [[maybe_unused]] auto a = new (place) Data;\n+        if constexpr (Trait::sampler == Sampler::RNG)\n+            a->rng.seed(seed.value_or(thread_local_rng()));\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        auto & cur_elems = data(place);\n+\n+        ++cur_elems.total_values;\n+\n+        if constexpr (Trait::sampler == Sampler::NONE)\n+        {\n+            if (limit_num_elems && cur_elems.value.size() >= max_elems)\n+            {\n+                if (Trait::last)\n+                {\n+                    Node * node = Node::allocate(*columns[0], row_num, arena);\n+                    cur_elems.value[(cur_elems.total_values - 1) % max_elems] = node;\n+                }\n+                return;\n+            }\n+\n+            Node * node = Node::allocate(*columns[0], row_num, arena);\n+            cur_elems.value.push_back(node, arena);\n+        }\n+\n+        if constexpr (Trait::sampler == Sampler::RNG)\n+        {\n+            if (cur_elems.value.size() < max_elems)\n+                cur_elems.value.push_back(Node::allocate(*columns[0], row_num, arena), arena);\n+            else\n+            {\n+                UInt64 rnd = cur_elems.genRandom(cur_elems.total_values);\n+                if (rnd < max_elems)\n+                    cur_elems.value[rnd] = Node::allocate(*columns[0], row_num, arena);\n+            }\n+        }\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n+    {\n+        auto & cur_elems = data(place);\n+        auto & rhs_elems = data(rhs);\n+\n+        if (rhs_elems.value.empty())\n+            return;\n+\n+        if constexpr (Trait::last)\n+            mergeNoSamplerLast(cur_elems, rhs_elems, arena);\n+        else if constexpr (Trait::sampler == Sampler::NONE)\n+            mergeNoSampler(cur_elems, rhs_elems, arena);\n+        else if constexpr (Trait::sampler == Sampler::RNG)\n+            mergeWithRNGSampler(cur_elems, rhs_elems, arena);\n+    }\n+\n+    void ALWAYS_INLINE mergeNoSamplerLast(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n+    {\n+        UInt64 new_elements = std::min(static_cast<size_t>(max_elems), cur_elems.value.size() + rhs_elems.value.size());\n+        cur_elems.value.resize_exact(new_elements, arena);\n+        for (auto & value : rhs_elems.value)\n+        {\n+            cur_elems.value[cur_elems.total_values % max_elems] = value->clone(arena);\n+            ++cur_elems.total_values;\n+        }\n+        chassert(rhs_elems.total_values >= rhs_elems.value.size());\n+        cur_elems.total_values += rhs_elems.total_values - rhs_elems.value.size();\n+    }\n+\n+    void ALWAYS_INLINE mergeNoSampler(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n+    {\n+        UInt64 new_elems;\n+        if (limit_num_elems)\n+        {\n+            if (cur_elems.value.size() >= max_elems)\n+                return;\n+            new_elems = std::min(rhs_elems.value.size(), static_cast<size_t>(max_elems) - cur_elems.value.size());\n+        }\n+        else\n+            new_elems = rhs_elems.value.size();\n+\n+        for (UInt64 i = 0; i < new_elems; ++i)\n+            cur_elems.value.push_back(rhs_elems.value[i]->clone(arena), arena);\n+    }\n+\n+    void ALWAYS_INLINE mergeWithRNGSampler(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n+    {\n+        if (rhs_elems.total_values <= max_elems)\n+        {\n+            for (size_t i = 0; i < rhs_elems.value.size(); ++i)\n+                insertWithSampler(cur_elems, rhs_elems.value[i], arena);\n+        }\n+        else if (cur_elems.total_values <= max_elems)\n+        {\n+            decltype(cur_elems.value) from;\n+            from.swap(cur_elems.value, arena);\n+            for (auto & node : rhs_elems.value)\n+                cur_elems.value.push_back(node->clone(arena), arena);\n+            cur_elems.total_values = rhs_elems.total_values;\n+            for (size_t i = 0; i < from.size(); ++i)\n+                insertWithSampler(cur_elems, from[i], arena);\n+        }\n+        else\n+        {\n+            cur_elems.randomShuffle();\n+            cur_elems.total_values += rhs_elems.total_values;\n+            for (size_t i = 0; i < max_elems; ++i)\n+            {\n+                UInt64 rnd = cur_elems.genRandom(cur_elems.total_values);\n+                if (rnd < rhs_elems.total_values)\n+                    cur_elems.value[i] = rhs_elems.value[i]->clone(arena);\n+            }\n+        }\n+    }\n+\n+    static void checkArraySize(size_t elems, size_t max_elems)\n+    {\n+        if (unlikely(elems > max_elems))\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n+                            \"Too large array size {} (maximum: {})\", elems, max_elems);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        UInt64 elems = data(place).value.size();\n+        checkArraySize(elems, max_elems);\n+        writeVarUInt(elems, buf);\n+\n+        auto & value = data(place).value;\n+        for (auto & node : value)\n+            node->write(buf);\n+\n+        if constexpr (Trait::last)\n+            writeBinaryLittleEndian(data(place).total_values, buf);\n+\n+        if constexpr (Trait::sampler == Sampler::RNG)\n+        {\n+            writeBinaryLittleEndian(data(place).total_values, buf);\n+            WriteBufferFromOwnString rng_buf;\n+            rng_buf << data(place).rng;\n+            writeStringBinary(rng_buf.str(), buf);\n+        }\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n+    {\n+        UInt64 elems;\n+        readVarUInt(elems, buf);\n+\n+        if (unlikely(elems == 0))\n+            return;\n+\n+        checkArraySize(elems, max_elems);\n+\n+        auto & value = data(place).value;\n+\n+        value.resize_exact(elems, arena);\n+        for (UInt64 i = 0; i < elems; ++i)\n+            value[i] = Node::read(buf, arena);\n+\n+        if constexpr (Trait::last)\n+            readBinaryLittleEndian(data(place).total_values, buf);\n+\n+        if constexpr (Trait::sampler == Sampler::RNG)\n+        {\n+            readBinaryLittleEndian(data(place).total_values, buf);\n+            std::string rng_string;\n+            readStringBinary(rng_string, buf);\n+            ReadBufferFromString rng_buf(rng_string);\n+            rng_buf >> data(place).rng;\n+        }\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        auto & column_array = assert_cast<ColumnArray &>(to);\n+\n+        auto & offsets = column_array.getOffsets();\n+        offsets.push_back(offsets.back() + data(place).value.size());\n+\n+        auto & column_data = column_array.getData();\n+\n+        if (std::is_same_v<Node, GroupArrayNodeString>)\n+        {\n+            auto & string_offsets = assert_cast<ColumnString &>(column_data).getOffsets();\n+            string_offsets.reserve(string_offsets.size() + data(place).value.size());\n+        }\n+\n+        auto & value = data(place).value;\n+        for (auto & node : value)\n+            node->insertInto(column_data);\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return true; }\n+};\n+\n+\n template <template <typename, typename> class AggregateFunctionTemplate, typename Data, typename ... TArgs>\n IAggregateFunction * createWithNumericOrTimeType(const IDataType & argument_type, TArgs && ... args)\n {\n@@ -87,10 +766,10 @@ AggregateFunctionPtr createAggregateFunctionGroupArray(\n     {\n         if (Tlast)\n             throw Exception(ErrorCodes::BAD_ARGUMENTS, \"groupArrayLast make sense only with max_elems (groupArrayLast(max_elems)())\");\n-        return createAggregateFunctionGroupArrayImpl<GroupArrayTrait</* Thas_limit= */ false, Tlast, /* Tsampler= */ Sampler::NONE>>(argument_types[0], parameters, max_elems);\n+        return createAggregateFunctionGroupArrayImpl<GroupArrayTrait</* Thas_limit= */ false, Tlast, /* Tsampler= */ Sampler::NONE>>(argument_types[0], parameters, max_elems, std::nullopt);\n     }\n     else\n-        return createAggregateFunctionGroupArrayImpl<GroupArrayTrait</* Thas_limit= */ true, Tlast, /* Tsampler= */ Sampler::NONE>>(argument_types[0], parameters, max_elems);\n+        return createAggregateFunctionGroupArrayImpl<GroupArrayTrait</* Thas_limit= */ true, Tlast, /* Tsampler= */ Sampler::NONE>>(argument_types[0], parameters, max_elems, std::nullopt);\n }\n \n AggregateFunctionPtr createAggregateFunctionGroupArraySample(\n@@ -117,11 +796,9 @@ AggregateFunctionPtr createAggregateFunctionGroupArraySample(\n \n     UInt64 max_elems = get_parameter(0);\n \n-    UInt64 seed;\n+    std::optional<UInt64> seed;\n     if (parameters.size() >= 2)\n         seed = get_parameter(1);\n-    else\n-        seed = thread_local_rng();\n \n     return createAggregateFunctionGroupArrayImpl<GroupArrayTrait</* Thas_limit= */ true, /* Tlast= */ false, /* Tsampler= */ Sampler::RNG>>(argument_types[0], parameters, max_elems, seed);\n }\ndiff --git a/src/AggregateFunctions/AggregateFunctionGroupArray.h b/src/AggregateFunctions/AggregateFunctionGroupArray.h\ndeleted file mode 100644\nindex 49552b57c82e..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionGroupArray.h\n+++ /dev/null\n@@ -1,690 +0,0 @@\n-#pragma once\n-\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <IO/ReadBufferFromString.h>\n-#include <IO/WriteBufferFromString.h>\n-#include <IO/Operators.h>\n-\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypeString.h>\n-#include <DataTypes/DataTypesNumber.h>\n-\n-#include <Columns/ColumnArray.h>\n-#include <Columns/ColumnString.h>\n-#include <Columns/ColumnVector.h>\n-\n-#include <Common/ArenaAllocator.h>\n-#include <Common/assert_cast.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-#include <type_traits>\n-\n-#define AGGREGATE_FUNCTION_GROUP_ARRAY_MAX_ELEMENT_SIZE 0xFFFFFF\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int TOO_LARGE_ARRAY_SIZE;\n-}\n-\n-enum class Sampler\n-{\n-    NONE,\n-    RNG,\n-};\n-\n-template <bool Thas_limit, bool Tlast, Sampler Tsampler>\n-struct GroupArrayTrait\n-{\n-    static constexpr bool has_limit = Thas_limit;\n-    static constexpr bool last = Tlast;\n-    static constexpr Sampler sampler = Tsampler;\n-};\n-\n-template <typename Trait>\n-static constexpr const char * getNameByTrait()\n-{\n-    if (Trait::last)\n-        return \"groupArrayLast\";\n-    if (Trait::sampler == Sampler::NONE)\n-        return \"groupArray\";\n-    else if (Trait::sampler == Sampler::RNG)\n-        return \"groupArraySample\";\n-\n-    UNREACHABLE();\n-}\n-\n-template <typename T>\n-struct GroupArraySamplerData\n-{\n-    /// For easy serialization.\n-    static_assert(std::has_unique_object_representations_v<T> || std::is_floating_point_v<T>);\n-\n-    // Switch to ordinary Allocator after 4096 bytes to avoid fragmentation and trash in Arena\n-    using Allocator = MixedAlignedArenaAllocator<alignof(T), 4096>;\n-    using Array = PODArray<T, 32, Allocator>;\n-\n-    Array value;\n-    size_t total_values = 0;\n-    pcg32_fast rng;\n-\n-    UInt64 genRandom(size_t lim)\n-    {\n-        /// With a large number of values, we will generate random numbers several times slower.\n-        if (lim <= static_cast<UInt64>(rng.max()))\n-            return static_cast<UInt32>(rng()) % static_cast<UInt32>(lim);\n-        else\n-            return (static_cast<UInt64>(rng()) * (static_cast<UInt64>(rng.max()) + 1ULL) + static_cast<UInt64>(rng())) % lim;\n-    }\n-\n-    void randomShuffle()\n-    {\n-        for (size_t i = 1; i < value.size(); ++i)\n-        {\n-            size_t j = genRandom(i + 1);\n-            std::swap(value[i], value[j]);\n-        }\n-    }\n-};\n-\n-/// A particular case is an implementation for numeric types.\n-template <typename T, bool has_sampler>\n-struct GroupArrayNumericData;\n-\n-template <typename T>\n-struct GroupArrayNumericData<T, false>\n-{\n-    /// For easy serialization.\n-    static_assert(std::has_unique_object_representations_v<T> || std::is_floating_point_v<T>);\n-\n-    // Switch to ordinary Allocator after 4096 bytes to avoid fragmentation and trash in Arena\n-    using Allocator = MixedAlignedArenaAllocator<alignof(T), 4096>;\n-    using Array = PODArray<T, 32, Allocator>;\n-\n-    // For groupArrayLast()\n-    size_t total_values = 0;\n-    Array value;\n-};\n-\n-template <typename T>\n-struct GroupArrayNumericData<T, true> : public GroupArraySamplerData<T>\n-{\n-};\n-\n-template <typename T, typename Trait>\n-class GroupArrayNumericImpl final\n-    : public IAggregateFunctionDataHelper<GroupArrayNumericData<T, Trait::sampler != Sampler::NONE>, GroupArrayNumericImpl<T, Trait>>\n-{\n-    using Data = GroupArrayNumericData<T, Trait::sampler != Sampler::NONE>;\n-    static constexpr bool limit_num_elems = Trait::has_limit;\n-    UInt64 max_elems;\n-    UInt64 seed;\n-\n-public:\n-    explicit GroupArrayNumericImpl(\n-        const DataTypePtr & data_type_, const Array & parameters_, UInt64 max_elems_, UInt64 seed_ = 123456)\n-        : IAggregateFunctionDataHelper<GroupArrayNumericData<T, Trait::sampler != Sampler::NONE>, GroupArrayNumericImpl<T, Trait>>(\n-            {data_type_}, parameters_, std::make_shared<DataTypeArray>(data_type_))\n-        , max_elems(max_elems_)\n-        , seed(seed_)\n-    {\n-    }\n-\n-    String getName() const override { return getNameByTrait<Trait>(); }\n-\n-    void insertWithSampler(Data & a, const T & v, Arena * arena) const\n-    {\n-        ++a.total_values;\n-        if (a.value.size() < max_elems)\n-            a.value.push_back(v, arena);\n-        else\n-        {\n-            UInt64 rnd = a.genRandom(a.total_values);\n-            if (rnd < max_elems)\n-                a.value[rnd] = v;\n-        }\n-    }\n-\n-    void create(AggregateDataPtr __restrict place) const override /// NOLINT\n-    {\n-        [[maybe_unused]] auto a = new (place) Data;\n-        if constexpr (Trait::sampler == Sampler::RNG)\n-            a->rng.seed(seed);\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        const auto & row_value = assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num];\n-        auto & cur_elems = this->data(place);\n-\n-        ++cur_elems.total_values;\n-\n-        if constexpr (Trait::sampler == Sampler::NONE)\n-        {\n-            if (limit_num_elems && cur_elems.value.size() >= max_elems)\n-            {\n-                if constexpr (Trait::last)\n-                    cur_elems.value[(cur_elems.total_values - 1) % max_elems] = row_value;\n-                return;\n-            }\n-\n-            cur_elems.value.push_back(row_value, arena);\n-        }\n-\n-        if constexpr (Trait::sampler == Sampler::RNG)\n-        {\n-            if (cur_elems.value.size() < max_elems)\n-                cur_elems.value.push_back(row_value, arena);\n-            else\n-            {\n-                UInt64 rnd = cur_elems.genRandom(cur_elems.total_values);\n-                if (rnd < max_elems)\n-                    cur_elems.value[rnd] = row_value;\n-            }\n-        }\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n-    {\n-        auto & cur_elems = this->data(place);\n-        auto & rhs_elems = this->data(rhs);\n-\n-        if (rhs_elems.value.empty())\n-            return;\n-\n-        if constexpr (Trait::last)\n-            mergeNoSamplerLast(cur_elems, rhs_elems, arena);\n-        else if constexpr (Trait::sampler == Sampler::NONE)\n-            mergeNoSampler(cur_elems, rhs_elems, arena);\n-        else if constexpr (Trait::sampler == Sampler::RNG)\n-            mergeWithRNGSampler(cur_elems, rhs_elems, arena);\n-    }\n-\n-    void mergeNoSamplerLast(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n-    {\n-        UInt64 new_elements = std::min(static_cast<size_t>(max_elems), cur_elems.value.size() + rhs_elems.value.size());\n-        cur_elems.value.resize_exact(new_elements, arena);\n-        for (auto & value : rhs_elems.value)\n-        {\n-            cur_elems.value[cur_elems.total_values % max_elems] = value;\n-            ++cur_elems.total_values;\n-        }\n-        assert(rhs_elems.total_values >= rhs_elems.value.size());\n-        cur_elems.total_values += rhs_elems.total_values - rhs_elems.value.size();\n-    }\n-\n-    void mergeNoSampler(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n-    {\n-        if (!limit_num_elems)\n-        {\n-            if (rhs_elems.value.size())\n-                cur_elems.value.insertByOffsets(rhs_elems.value, 0, rhs_elems.value.size(), arena);\n-        }\n-        else\n-        {\n-            UInt64 elems_to_insert = std::min(static_cast<size_t>(max_elems) - cur_elems.value.size(), rhs_elems.value.size());\n-            if (elems_to_insert)\n-                cur_elems.value.insertByOffsets(rhs_elems.value, 0, elems_to_insert, arena);\n-        }\n-    }\n-\n-    void mergeWithRNGSampler(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n-    {\n-        if (rhs_elems.total_values <= max_elems)\n-        {\n-            for (size_t i = 0; i < rhs_elems.value.size(); ++i)\n-                insertWithSampler(cur_elems, rhs_elems.value[i], arena);\n-        }\n-        else if (cur_elems.total_values <= max_elems)\n-        {\n-            decltype(cur_elems.value) from;\n-            from.swap(cur_elems.value, arena);\n-            cur_elems.value.assign(rhs_elems.value.begin(), rhs_elems.value.end(), arena);\n-            cur_elems.total_values = rhs_elems.total_values;\n-            for (size_t i = 0; i < from.size(); ++i)\n-                insertWithSampler(cur_elems, from[i], arena);\n-        }\n-        else\n-        {\n-            cur_elems.randomShuffle();\n-            cur_elems.total_values += rhs_elems.total_values;\n-            for (size_t i = 0; i < max_elems; ++i)\n-            {\n-                UInt64 rnd = cur_elems.genRandom(cur_elems.total_values);\n-                if (rnd < rhs_elems.total_values)\n-                    cur_elems.value[i] = rhs_elems.value[i];\n-            }\n-        }\n-    }\n-\n-    static void checkArraySize(size_t elems, size_t max_elems)\n-    {\n-        if (unlikely(elems > max_elems))\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n-                            \"Too large array size {} (maximum: {})\", elems, max_elems);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        const auto & value = this->data(place).value;\n-        const UInt64 size = value.size();\n-        checkArraySize(size, max_elems);\n-        writeVarUInt(size, buf);\n-        for (const auto & element : value)\n-            writeBinaryLittleEndian(element, buf);\n-\n-        if constexpr (Trait::last)\n-            writeBinaryLittleEndian(this->data(place).total_values, buf);\n-\n-        if constexpr (Trait::sampler == Sampler::RNG)\n-        {\n-            writeBinaryLittleEndian(this->data(place).total_values, buf);\n-            WriteBufferFromOwnString rng_buf;\n-            rng_buf << this->data(place).rng;\n-            writeStringBinary(rng_buf.str(), buf);\n-        }\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        size_t size = 0;\n-        readVarUInt(size, buf);\n-        checkArraySize(size, max_elems);\n-\n-        auto & value = this->data(place).value;\n-\n-        value.resize_exact(size, arena);\n-        for (auto & element : value)\n-            readBinaryLittleEndian(element, buf);\n-\n-        if constexpr (Trait::last)\n-            readBinaryLittleEndian(this->data(place).total_values, buf);\n-\n-        if constexpr (Trait::sampler == Sampler::RNG)\n-        {\n-            readBinaryLittleEndian(this->data(place).total_values, buf);\n-            std::string rng_string;\n-            readStringBinary(rng_string, buf);\n-            ReadBufferFromString rng_buf(rng_string);\n-            rng_buf >> this->data(place).rng;\n-        }\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        const auto & value = this->data(place).value;\n-        size_t size = value.size();\n-\n-        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n-        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n-\n-        offsets_to.push_back(offsets_to.back() + size);\n-\n-        if (size)\n-        {\n-            typename ColumnVector<T>::Container & data_to = assert_cast<ColumnVector<T> &>(arr_to.getData()).getData();\n-            data_to.insert(this->data(place).value.begin(), this->data(place).value.end());\n-        }\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return true; }\n-};\n-\n-\n-/// General case\n-\n-\n-/// Nodes used to implement a linked list for storage of groupArray states\n-\n-template <typename Node>\n-struct GroupArrayNodeBase\n-{\n-    UInt64 size; // size of payload\n-\n-    /// Returns pointer to actual payload\n-    char * data() { return reinterpret_cast<char *>(this) + sizeof(Node); }\n-\n-    const char * data() const { return reinterpret_cast<const char *>(this) + sizeof(Node); }\n-\n-    /// Clones existing node (does not modify next field)\n-    Node * clone(Arena * arena) const\n-    {\n-        return reinterpret_cast<Node *>(\n-            const_cast<char *>(arena->alignedInsert(reinterpret_cast<const char *>(this), sizeof(Node) + size, alignof(Node))));\n-    }\n-\n-    static void checkElementSize(size_t size, size_t max_size)\n-    {\n-        if (unlikely(size > max_size))\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n-                            \"Too large array element size {} (maximum: {})\", size, max_size);\n-    }\n-\n-    /// Write node to buffer\n-    void write(WriteBuffer & buf) const\n-    {\n-        checkElementSize(size, AGGREGATE_FUNCTION_GROUP_ARRAY_MAX_ELEMENT_SIZE);\n-        writeVarUInt(size, buf);\n-        buf.write(data(), size);\n-    }\n-\n-    /// Reads and allocates node from ReadBuffer's data (doesn't set next)\n-    static Node * read(ReadBuffer & buf, Arena * arena)\n-    {\n-        UInt64 size;\n-        readVarUInt(size, buf);\n-        checkElementSize(size, AGGREGATE_FUNCTION_GROUP_ARRAY_MAX_ELEMENT_SIZE);\n-\n-        Node * node = reinterpret_cast<Node *>(arena->alignedAlloc(sizeof(Node) + size, alignof(Node)));\n-        node->size = size;\n-        buf.readStrict(node->data(), size);\n-        return node;\n-    }\n-};\n-\n-struct GroupArrayNodeString : public GroupArrayNodeBase<GroupArrayNodeString>\n-{\n-    using Node = GroupArrayNodeString;\n-\n-    /// Create node from string\n-    static Node * allocate(const IColumn & column, size_t row_num, Arena * arena)\n-    {\n-        StringRef string = assert_cast<const ColumnString &>(column).getDataAt(row_num);\n-\n-        Node * node = reinterpret_cast<Node *>(arena->alignedAlloc(sizeof(Node) + string.size, alignof(Node)));\n-        node->size = string.size;\n-        memcpy(node->data(), string.data, string.size);\n-\n-        return node;\n-    }\n-\n-    void insertInto(IColumn & column)\n-    {\n-        assert_cast<ColumnString &>(column).insertData(data(), size);\n-    }\n-};\n-\n-struct GroupArrayNodeGeneral : public GroupArrayNodeBase<GroupArrayNodeGeneral>\n-{\n-    using Node = GroupArrayNodeGeneral;\n-\n-    static Node * allocate(const IColumn & column, size_t row_num, Arena * arena)\n-    {\n-        const char * begin = arena->alignedAlloc(sizeof(Node), alignof(Node));\n-        StringRef value = column.serializeValueIntoArena(row_num, *arena, begin);\n-\n-        Node * node = reinterpret_cast<Node *>(const_cast<char *>(begin));\n-        node->size = value.size;\n-\n-        return node;\n-    }\n-\n-    void insertInto(IColumn & column) { column.deserializeAndInsertFromArena(data()); }\n-};\n-\n-template <typename Node, bool has_sampler>\n-struct GroupArrayGeneralData;\n-\n-template <typename Node>\n-struct GroupArrayGeneralData<Node, false>\n-{\n-    // Switch to ordinary Allocator after 4096 bytes to avoid fragmentation and trash in Arena\n-    using Allocator = MixedAlignedArenaAllocator<alignof(Node *), 4096>;\n-    using Array = PODArray<Node *, 32, Allocator>;\n-\n-    // For groupArrayLast()\n-    size_t total_values = 0;\n-    Array value;\n-};\n-\n-template <typename Node>\n-struct GroupArrayGeneralData<Node, true> : public GroupArraySamplerData<Node *>\n-{\n-};\n-\n-/// Implementation of groupArray for String or any ComplexObject via Array\n-template <typename Node, typename Trait>\n-class GroupArrayGeneralImpl final\n-    : public IAggregateFunctionDataHelper<GroupArrayGeneralData<Node, Trait::sampler != Sampler::NONE>, GroupArrayGeneralImpl<Node, Trait>>\n-{\n-    static constexpr bool limit_num_elems = Trait::has_limit;\n-    using Data = GroupArrayGeneralData<Node, Trait::sampler != Sampler::NONE>;\n-    static Data & data(AggregateDataPtr __restrict place) { return *reinterpret_cast<Data *>(place); }\n-    static const Data & data(ConstAggregateDataPtr __restrict place) { return *reinterpret_cast<const Data *>(place); }\n-\n-    DataTypePtr & data_type;\n-    UInt64 max_elems;\n-    UInt64 seed;\n-\n-public:\n-    GroupArrayGeneralImpl(const DataTypePtr & data_type_, const Array & parameters_, UInt64 max_elems_, UInt64 seed_ = 123456)\n-        : IAggregateFunctionDataHelper<GroupArrayGeneralData<Node, Trait::sampler != Sampler::NONE>, GroupArrayGeneralImpl<Node, Trait>>(\n-            {data_type_}, parameters_, std::make_shared<DataTypeArray>(data_type_))\n-        , data_type(this->argument_types[0])\n-        , max_elems(max_elems_)\n-        , seed(seed_)\n-    {\n-    }\n-\n-    String getName() const override { return getNameByTrait<Trait>(); }\n-\n-    void insertWithSampler(Data & a, const Node * v, Arena * arena) const\n-    {\n-        ++a.total_values;\n-        if (a.value.size() < max_elems)\n-            a.value.push_back(v->clone(arena), arena);\n-        else\n-        {\n-            UInt64 rnd = a.genRandom(a.total_values);\n-            if (rnd < max_elems)\n-                a.value[rnd] = v->clone(arena);\n-        }\n-    }\n-\n-    void create(AggregateDataPtr __restrict place) const override /// NOLINT\n-    {\n-        [[maybe_unused]] auto a = new (place) Data;\n-        if constexpr (Trait::sampler == Sampler::RNG)\n-            a->rng.seed(seed);\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        auto & cur_elems = data(place);\n-\n-        ++cur_elems.total_values;\n-\n-        if constexpr (Trait::sampler == Sampler::NONE)\n-        {\n-            if (limit_num_elems && cur_elems.value.size() >= max_elems)\n-            {\n-                if (Trait::last)\n-                {\n-                    Node * node = Node::allocate(*columns[0], row_num, arena);\n-                    cur_elems.value[(cur_elems.total_values - 1) % max_elems] = node;\n-                }\n-                return;\n-            }\n-\n-            Node * node = Node::allocate(*columns[0], row_num, arena);\n-            cur_elems.value.push_back(node, arena);\n-        }\n-\n-        if constexpr (Trait::sampler == Sampler::RNG)\n-        {\n-            if (cur_elems.value.size() < max_elems)\n-                cur_elems.value.push_back(Node::allocate(*columns[0], row_num, arena), arena);\n-            else\n-            {\n-                UInt64 rnd = cur_elems.genRandom(cur_elems.total_values);\n-                if (rnd < max_elems)\n-                    cur_elems.value[rnd] = Node::allocate(*columns[0], row_num, arena);\n-            }\n-        }\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n-    {\n-        auto & cur_elems = data(place);\n-        auto & rhs_elems = data(rhs);\n-\n-        if (rhs_elems.value.empty())\n-            return;\n-\n-        if constexpr (Trait::last)\n-            mergeNoSamplerLast(cur_elems, rhs_elems, arena);\n-        else if constexpr (Trait::sampler == Sampler::NONE)\n-            mergeNoSampler(cur_elems, rhs_elems, arena);\n-        else if constexpr (Trait::sampler == Sampler::RNG)\n-            mergeWithRNGSampler(cur_elems, rhs_elems, arena);\n-    }\n-\n-    void ALWAYS_INLINE mergeNoSamplerLast(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n-    {\n-        UInt64 new_elements = std::min(static_cast<size_t>(max_elems), cur_elems.value.size() + rhs_elems.value.size());\n-        cur_elems.value.resize_exact(new_elements, arena);\n-        for (auto & value : rhs_elems.value)\n-        {\n-            cur_elems.value[cur_elems.total_values % max_elems] = value->clone(arena);\n-            ++cur_elems.total_values;\n-        }\n-        assert(rhs_elems.total_values >= rhs_elems.value.size());\n-        cur_elems.total_values += rhs_elems.total_values - rhs_elems.value.size();\n-    }\n-\n-    void ALWAYS_INLINE mergeNoSampler(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n-    {\n-        UInt64 new_elems;\n-        if (limit_num_elems)\n-        {\n-            if (cur_elems.value.size() >= max_elems)\n-                return;\n-            new_elems = std::min(rhs_elems.value.size(), static_cast<size_t>(max_elems) - cur_elems.value.size());\n-        }\n-        else\n-            new_elems = rhs_elems.value.size();\n-\n-        for (UInt64 i = 0; i < new_elems; ++i)\n-            cur_elems.value.push_back(rhs_elems.value[i]->clone(arena), arena);\n-    }\n-\n-    void ALWAYS_INLINE mergeWithRNGSampler(Data & cur_elems, const Data & rhs_elems, Arena * arena) const\n-    {\n-        if (rhs_elems.total_values <= max_elems)\n-        {\n-            for (size_t i = 0; i < rhs_elems.value.size(); ++i)\n-                insertWithSampler(cur_elems, rhs_elems.value[i], arena);\n-        }\n-        else if (cur_elems.total_values <= max_elems)\n-        {\n-            decltype(cur_elems.value) from;\n-            from.swap(cur_elems.value, arena);\n-            for (auto & node : rhs_elems.value)\n-                cur_elems.value.push_back(node->clone(arena), arena);\n-            cur_elems.total_values = rhs_elems.total_values;\n-            for (size_t i = 0; i < from.size(); ++i)\n-                insertWithSampler(cur_elems, from[i], arena);\n-        }\n-        else\n-        {\n-            cur_elems.randomShuffle();\n-            cur_elems.total_values += rhs_elems.total_values;\n-            for (size_t i = 0; i < max_elems; ++i)\n-            {\n-                UInt64 rnd = cur_elems.genRandom(cur_elems.total_values);\n-                if (rnd < rhs_elems.total_values)\n-                    cur_elems.value[i] = rhs_elems.value[i]->clone(arena);\n-            }\n-        }\n-    }\n-\n-    static void checkArraySize(size_t elems, size_t max_elems)\n-    {\n-        if (unlikely(elems > max_elems))\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n-                            \"Too large array size {} (maximum: {})\", elems, max_elems);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        UInt64 elems = data(place).value.size();\n-        checkArraySize(elems, max_elems);\n-        writeVarUInt(elems, buf);\n-\n-        auto & value = data(place).value;\n-        for (auto & node : value)\n-            node->write(buf);\n-\n-        if constexpr (Trait::last)\n-            writeBinaryLittleEndian(data(place).total_values, buf);\n-\n-        if constexpr (Trait::sampler == Sampler::RNG)\n-        {\n-            writeBinaryLittleEndian(data(place).total_values, buf);\n-            WriteBufferFromOwnString rng_buf;\n-            rng_buf << data(place).rng;\n-            writeStringBinary(rng_buf.str(), buf);\n-        }\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        UInt64 elems;\n-        readVarUInt(elems, buf);\n-\n-        if (unlikely(elems == 0))\n-            return;\n-\n-        checkArraySize(elems, max_elems);\n-\n-        auto & value = data(place).value;\n-\n-        value.resize_exact(elems, arena);\n-        for (UInt64 i = 0; i < elems; ++i)\n-            value[i] = Node::read(buf, arena);\n-\n-        if constexpr (Trait::last)\n-            readBinaryLittleEndian(data(place).total_values, buf);\n-\n-        if constexpr (Trait::sampler == Sampler::RNG)\n-        {\n-            readBinaryLittleEndian(data(place).total_values, buf);\n-            std::string rng_string;\n-            readStringBinary(rng_string, buf);\n-            ReadBufferFromString rng_buf(rng_string);\n-            rng_buf >> data(place).rng;\n-        }\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        auto & column_array = assert_cast<ColumnArray &>(to);\n-\n-        auto & offsets = column_array.getOffsets();\n-        offsets.push_back(offsets.back() + data(place).value.size());\n-\n-        auto & column_data = column_array.getData();\n-\n-        if (std::is_same_v<Node, GroupArrayNodeString>)\n-        {\n-            auto & string_offsets = assert_cast<ColumnString &>(column_data).getOffsets();\n-            string_offsets.reserve(string_offsets.size() + data(place).value.size());\n-        }\n-\n-        auto & value = data(place).value;\n-        for (auto & node : value)\n-            node->insertInto(column_data);\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return true; }\n-};\n-\n-#undef AGGREGATE_FUNCTION_GROUP_ARRAY_MAX_ELEMENT_SIZE\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionGroupArrayInsertAt.cpp b/src/AggregateFunctions/AggregateFunctionGroupArrayInsertAt.cpp\nindex f5cb927e1754..60e8df642839 100644\n--- a/src/AggregateFunctions/AggregateFunctionGroupArrayInsertAt.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionGroupArrayInsertAt.cpp\n@@ -1,21 +1,218 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionGroupArrayInsertAt.h>\n-#include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n \n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadHelpers.h>\n+\n+#include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypesNumber.h>\n+\n+#include <Columns/ColumnArray.h>\n+\n+#include <Common/FieldVisitorToString.h>\n+#include <Common/FieldVisitorConvertToNumber.h>\n+#include <Common/assert_cast.h>\n+#include <Interpreters/convertFieldToType.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+\n+#define AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE 0xFFFFFF\n+\n \n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n {\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int TOO_LARGE_ARRAY_SIZE;\n+    extern const int CANNOT_CONVERT_TYPE;\n+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n }\n \n namespace\n {\n \n+/** Aggregate function, that takes two arguments: value and position,\n+  *  and as a result, builds an array with values are located at corresponding positions.\n+  *\n+  * If more than one value was inserted to single position, the any value (first in case of single thread) is stored.\n+  * If no values was inserted to some position, then default value will be substituted.\n+  *\n+  * Aggregate function also accept optional parameters:\n+  * - default value to substitute;\n+  * - length to resize result arrays (if you want to have results of same length for all aggregation keys);\n+  *\n+  * If you want to pass length, default value should be also given.\n+  */\n+\n+\n+/// Generic case (inefficient).\n+struct AggregateFunctionGroupArrayInsertAtDataGeneric\n+{\n+    Array value;    /// TODO Add MemoryTracker\n+};\n+\n+\n+class AggregateFunctionGroupArrayInsertAtGeneric final\n+    : public IAggregateFunctionDataHelper<AggregateFunctionGroupArrayInsertAtDataGeneric, AggregateFunctionGroupArrayInsertAtGeneric>\n+{\n+private:\n+    DataTypePtr type;\n+    SerializationPtr serialization;\n+    Field default_value;\n+    UInt64 length_to_resize = 0;    /// zero means - do not do resizing.\n+\n+public:\n+    AggregateFunctionGroupArrayInsertAtGeneric(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<AggregateFunctionGroupArrayInsertAtDataGeneric, AggregateFunctionGroupArrayInsertAtGeneric>(arguments, params, std::make_shared<DataTypeArray>(arguments[0]))\n+        , type(argument_types[0])\n+        , serialization(type->getDefaultSerialization())\n+    {\n+        if (!params.empty())\n+        {\n+            if (params.size() > 2)\n+                throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} requires at most two parameters.\", getName());\n+\n+            default_value = params[0];\n+\n+            if (params.size() == 2)\n+            {\n+                length_to_resize = applyVisitor(FieldVisitorConvertToNumber<UInt64>(), params[1]);\n+                if (length_to_resize > AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE)\n+                    throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n+                                    \"Too large array size (maximum: {})\", AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE);\n+            }\n+        }\n+\n+        if (!isUInt(arguments[1]))\n+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Second argument of aggregate function {} must be unsigned integer.\", getName());\n+\n+        if (default_value.isNull())\n+            default_value = type->getDefault();\n+        else\n+        {\n+            Field converted = convertFieldToType(default_value, *type);\n+            if (converted.isNull())\n+                throw Exception(ErrorCodes::CANNOT_CONVERT_TYPE, \"Cannot convert parameter of aggregate function {} ({}) \"\n+                                \"to type {} to be used as default value in array\",\n+                                getName(), applyVisitor(FieldVisitorToString(), default_value), type->getName());\n+\n+            default_value = converted;\n+        }\n+    }\n+\n+    String getName() const override { return \"groupArrayInsertAt\"; }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        /// TODO Do positions need to be 1-based for this function?\n+        size_t position = columns[1]->getUInt(row_num);\n+\n+        /// If position is larger than size to which array will be cut - simply ignore value.\n+        if (length_to_resize && position >= length_to_resize)\n+            return;\n+\n+        if (position >= AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE)\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE, \"Too large array size: \"\n+                \"position argument ({}) is greater or equals to limit ({})\",\n+                position, AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE);\n+\n+        Array & arr = data(place).value;\n+\n+        if (arr.size() <= position)\n+            arr.resize(position + 1);\n+        else if (!arr[position].isNull())\n+            return; /// Element was already inserted to the specified position.\n+\n+        columns[0]->get(row_num, arr[position]);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        Array & arr_lhs = data(place).value;\n+        const Array & arr_rhs = data(rhs).value;\n+\n+        if (arr_lhs.size() < arr_rhs.size())\n+            arr_lhs.resize(arr_rhs.size());\n+\n+        for (size_t i = 0, size = arr_rhs.size(); i < size; ++i)\n+            if (arr_lhs[i].isNull() && !arr_rhs[i].isNull())\n+                arr_lhs[i] = arr_rhs[i];\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        const Array & arr = data(place).value;\n+        size_t size = arr.size();\n+        writeVarUInt(size, buf);\n+\n+        for (const Field & elem : arr)\n+        {\n+            if (elem.isNull())\n+            {\n+                writeBinary(UInt8(1), buf);\n+            }\n+            else\n+            {\n+                writeBinary(UInt8(0), buf);\n+                serialization->serializeBinary(elem, buf, {});\n+            }\n+        }\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        size_t size = 0;\n+        readVarUInt(size, buf);\n+\n+        if (size > AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE)\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n+                            \"Too large array size (maximum: {})\", AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE);\n+\n+        Array & arr = data(place).value;\n+\n+        arr.resize(size);\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            UInt8 is_null = 0;\n+            readBinary(is_null, buf);\n+            if (!is_null)\n+                serialization->deserializeBinary(arr[i], buf, {});\n+        }\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        ColumnArray & to_array = assert_cast<ColumnArray &>(to);\n+        IColumn & to_data = to_array.getData();\n+        ColumnArray::Offsets & to_offsets = to_array.getOffsets();\n+\n+        const Array & arr = data(place).value;\n+\n+        for (const Field & elem : arr)\n+        {\n+            if (!elem.isNull())\n+                to_data.insert(elem);\n+            else\n+                to_data.insert(default_value);\n+        }\n+\n+        size_t result_array_size = length_to_resize ? length_to_resize : arr.size();\n+\n+        /// Pad array if need.\n+        for (size_t i = arr.size(); i < result_array_size; ++i)\n+            to_data.insert(default_value);\n+\n+        to_offsets.push_back(to_offsets.back() + result_array_size);\n+    }\n+};\n+\n+\n AggregateFunctionPtr createAggregateFunctionGroupArrayInsertAt(\n     const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n {\ndiff --git a/src/AggregateFunctions/AggregateFunctionGroupArrayInsertAt.h b/src/AggregateFunctions/AggregateFunctionGroupArrayInsertAt.h\ndeleted file mode 100644\nindex 023e237ef96b..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionGroupArrayInsertAt.h\n+++ /dev/null\n@@ -1,215 +0,0 @@\n-#pragma once\n-\n-#include <IO/WriteHelpers.h>\n-#include <IO/ReadHelpers.h>\n-\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypesNumber.h>\n-\n-#include <Columns/ColumnArray.h>\n-#include <Columns/ColumnVector.h>\n-\n-#include <Common/FieldVisitorToString.h>\n-#include <Common/FieldVisitorConvertToNumber.h>\n-#include <Common/assert_cast.h>\n-#include <Interpreters/convertFieldToType.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-#define AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE 0xFFFFFF\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int TOO_LARGE_ARRAY_SIZE;\n-    extern const int CANNOT_CONVERT_TYPE;\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n-}\n-\n-\n-/** Aggregate function, that takes two arguments: value and position,\n-  *  and as a result, builds an array with values are located at corresponding positions.\n-  *\n-  * If more than one value was inserted to single position, the any value (first in case of single thread) is stored.\n-  * If no values was inserted to some position, then default value will be substituted.\n-  *\n-  * Aggregate function also accept optional parameters:\n-  * - default value to substitute;\n-  * - length to resize result arrays (if you want to have results of same length for all aggregation keys);\n-  *\n-  * If you want to pass length, default value should be also given.\n-  */\n-\n-\n-/// Generic case (inefficient).\n-struct AggregateFunctionGroupArrayInsertAtDataGeneric\n-{\n-    Array value;    /// TODO Add MemoryTracker\n-};\n-\n-\n-class AggregateFunctionGroupArrayInsertAtGeneric final\n-    : public IAggregateFunctionDataHelper<AggregateFunctionGroupArrayInsertAtDataGeneric, AggregateFunctionGroupArrayInsertAtGeneric>\n-{\n-private:\n-    DataTypePtr type;\n-    SerializationPtr serialization;\n-    Field default_value;\n-    UInt64 length_to_resize = 0;    /// zero means - do not do resizing.\n-\n-public:\n-    AggregateFunctionGroupArrayInsertAtGeneric(const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper<AggregateFunctionGroupArrayInsertAtDataGeneric, AggregateFunctionGroupArrayInsertAtGeneric>(arguments, params, std::make_shared<DataTypeArray>(arguments[0]))\n-        , type(argument_types[0])\n-        , serialization(type->getDefaultSerialization())\n-    {\n-        if (!params.empty())\n-        {\n-            if (params.size() > 2)\n-                throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} requires at most two parameters.\", getName());\n-\n-            default_value = params[0];\n-\n-            if (params.size() == 2)\n-            {\n-                length_to_resize = applyVisitor(FieldVisitorConvertToNumber<UInt64>(), params[1]);\n-                if (length_to_resize > AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE)\n-                    throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n-                                    \"Too large array size (maximum: {})\", AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE);\n-            }\n-        }\n-\n-        if (!isUInt(arguments[1]))\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Second argument of aggregate function {} must be unsigned integer.\", getName());\n-\n-        if (default_value.isNull())\n-            default_value = type->getDefault();\n-        else\n-        {\n-            Field converted = convertFieldToType(default_value, *type);\n-            if (converted.isNull())\n-                throw Exception(ErrorCodes::CANNOT_CONVERT_TYPE, \"Cannot convert parameter of aggregate function {} ({}) \"\n-                                \"to type {} to be used as default value in array\",\n-                                getName(), applyVisitor(FieldVisitorToString(), default_value), type->getName());\n-\n-            default_value = converted;\n-        }\n-    }\n-\n-    String getName() const override { return \"groupArrayInsertAt\"; }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        /// TODO Do positions need to be 1-based for this function?\n-        size_t position = columns[1]->getUInt(row_num);\n-\n-        /// If position is larger than size to which array will be cut - simply ignore value.\n-        if (length_to_resize && position >= length_to_resize)\n-            return;\n-\n-        if (position >= AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE)\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE, \"Too large array size: \"\n-                \"position argument ({}) is greater or equals to limit ({})\",\n-                position, AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE);\n-\n-        Array & arr = data(place).value;\n-\n-        if (arr.size() <= position)\n-            arr.resize(position + 1);\n-        else if (!arr[position].isNull())\n-            return; /// Element was already inserted to the specified position.\n-\n-        columns[0]->get(row_num, arr[position]);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        Array & arr_lhs = data(place).value;\n-        const Array & arr_rhs = data(rhs).value;\n-\n-        if (arr_lhs.size() < arr_rhs.size())\n-            arr_lhs.resize(arr_rhs.size());\n-\n-        for (size_t i = 0, size = arr_rhs.size(); i < size; ++i)\n-            if (arr_lhs[i].isNull() && !arr_rhs[i].isNull())\n-                arr_lhs[i] = arr_rhs[i];\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        const Array & arr = data(place).value;\n-        size_t size = arr.size();\n-        writeVarUInt(size, buf);\n-\n-        for (const Field & elem : arr)\n-        {\n-            if (elem.isNull())\n-            {\n-                writeBinary(UInt8(1), buf);\n-            }\n-            else\n-            {\n-                writeBinary(UInt8(0), buf);\n-                serialization->serializeBinary(elem, buf, {});\n-            }\n-        }\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        size_t size = 0;\n-        readVarUInt(size, buf);\n-\n-        if (size > AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE)\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n-                            \"Too large array size (maximum: {})\", AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE);\n-\n-        Array & arr = data(place).value;\n-\n-        arr.resize(size);\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            UInt8 is_null = 0;\n-            readBinary(is_null, buf);\n-            if (!is_null)\n-                serialization->deserializeBinary(arr[i], buf, {});\n-        }\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        ColumnArray & to_array = assert_cast<ColumnArray &>(to);\n-        IColumn & to_data = to_array.getData();\n-        ColumnArray::Offsets & to_offsets = to_array.getOffsets();\n-\n-        const Array & arr = data(place).value;\n-\n-        for (const Field & elem : arr)\n-        {\n-            if (!elem.isNull())\n-                to_data.insert(elem);\n-            else\n-                to_data.insert(default_value);\n-        }\n-\n-        size_t result_array_size = length_to_resize ? length_to_resize : arr.size();\n-\n-        /// Pad array if need.\n-        for (size_t i = arr.size(); i < result_array_size; ++i)\n-            to_data.insert(default_value);\n-\n-        to_offsets.push_back(to_offsets.back() + result_array_size);\n-    }\n-};\n-\n-\n-#undef AGGREGATE_FUNCTION_GROUP_ARRAY_INSERT_AT_MAX_SIZE\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionGroupBitmap.cpp b/src/AggregateFunctions/AggregateFunctionGroupBitmap.cpp\nindex fd350b47026d..0cc5874f65e7 100644\n--- a/src/AggregateFunctions/AggregateFunctionGroupBitmap.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionGroupBitmap.cpp\n@@ -2,8 +2,14 @@\n #include <AggregateFunctions/FactoryHelpers.h>\n #include <DataTypes/DataTypeAggregateFunction.h>\n \n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <Columns/ColumnAggregateFunction.h>\n+#include <Columns/ColumnVector.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <Common/assert_cast.h>\n+\n // TODO include this last because of a broken roaring header. See the comment inside.\n-#include <AggregateFunctions/AggregateFunctionGroupBitmap.h>\n+#include <AggregateFunctions/AggregateFunctionGroupBitmapData.h>\n \n \n namespace DB\n@@ -17,77 +23,255 @@ namespace ErrorCodes\n \n namespace\n {\n-    template <template <typename, typename> class AggregateFunctionTemplate, template <typename> typename Data, typename... TArgs>\n-    IAggregateFunction * createWithIntegerType(const IDataType & argument_type, TArgs &&... args)\n+\n+/// Counts bitmap operation on numbers.\n+template <typename T, typename Data>\n+class AggregateFunctionBitmap final : public IAggregateFunctionDataHelper<Data, AggregateFunctionBitmap<T, Data>>\n+{\n+public:\n+    explicit AggregateFunctionBitmap(const DataTypePtr & type)\n+        : IAggregateFunctionDataHelper<Data, AggregateFunctionBitmap<T, Data>>({type}, {}, createResultType())\n+    {\n+    }\n+\n+    String getName() const override { return Data::name(); }\n+\n+    static DataTypePtr createResultType() { return std::make_shared<DataTypeNumber<T>>(); }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        this->data(place).roaring_bitmap_with_small_set.add(assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num]);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).roaring_bitmap_with_small_set.merge(this->data(rhs).roaring_bitmap_with_small_set);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).roaring_bitmap_with_small_set.write(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n     {\n-        WhichDataType which(argument_type);\n-        if (which.idx == TypeIndex::UInt8) return new AggregateFunctionTemplate<UInt8, Data<UInt8>>(std::forward<TArgs>(args)...);\n-        if (which.idx == TypeIndex::UInt16) return new AggregateFunctionTemplate<UInt16, Data<UInt16>>(std::forward<TArgs>(args)...);\n-        if (which.idx == TypeIndex::UInt32) return new AggregateFunctionTemplate<UInt32, Data<UInt32>>(std::forward<TArgs>(args)...);\n-        if (which.idx == TypeIndex::UInt64) return new AggregateFunctionTemplate<UInt64, Data<UInt64>>(std::forward<TArgs>(args)...);\n-        if (which.idx == TypeIndex::Int8) return new AggregateFunctionTemplate<Int8, Data<Int8>>(std::forward<TArgs>(args)...);\n-        if (which.idx == TypeIndex::Int16) return new AggregateFunctionTemplate<Int16, Data<Int16>>(std::forward<TArgs>(args)...);\n-        if (which.idx == TypeIndex::Int32) return new AggregateFunctionTemplate<Int32, Data<Int32>>(std::forward<TArgs>(args)...);\n-        if (which.idx == TypeIndex::Int64) return new AggregateFunctionTemplate<Int64, Data<Int64>>(std::forward<TArgs>(args)...);\n-        return nullptr;\n+        this->data(place).roaring_bitmap_with_small_set.read(buf);\n     }\n \n-    template <template <typename> typename Data>\n-    AggregateFunctionPtr createAggregateFunctionBitmap(\n-        const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n     {\n-        assertNoParameters(name, parameters);\n-        assertUnary(name, argument_types);\n+        assert_cast<ColumnVector<T> &>(to).getData().push_back(\n+            static_cast<T>(this->data(place).roaring_bitmap_with_small_set.size()));\n+    }\n+};\n+\n \n-        if (!argument_types[0]->canBeUsedInBitOperations())\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                            \"The type {} of argument for aggregate function {} \"\n-                            \"is illegal, because it cannot be used in Bitmap operations\",\n-                            argument_types[0]->getName(), name);\n+/// This aggregate function takes the states of AggregateFunctionBitmap as its argument.\n+template <typename T, typename Data, typename Policy>\n+class AggregateFunctionBitmapL2 final : public IAggregateFunctionDataHelper<Data, AggregateFunctionBitmapL2<T, Data, Policy>>\n+{\n+private:\n+    static constexpr size_t STATE_VERSION_1_MIN_REVISION = 54455;\n+public:\n+    explicit AggregateFunctionBitmapL2(const DataTypePtr & type)\n+        : IAggregateFunctionDataHelper<Data, AggregateFunctionBitmapL2<T, Data, Policy>>({type}, {}, createResultType())\n+    {\n+    }\n \n-        AggregateFunctionPtr res(createWithIntegerType<AggregateFunctionBitmap, Data>(*argument_types[0], argument_types[0]));\n+    String getName() const override { return Policy::name; }\n \n-        if (!res)\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n-                argument_types[0]->getName(), name);\n+    static DataTypePtr createResultType() { return std::make_shared<DataTypeNumber<T>>(); }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    DataTypePtr getStateType() const override\n+    {\n+        return this->argument_types.at(0);\n+    }\n \n-        return res;\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        Data & data_lhs = this->data(place);\n+        const Data & data_rhs = this->data(assert_cast<const ColumnAggregateFunction &>(*columns[0]).getData()[row_num]);\n+        if (!data_lhs.init)\n+        {\n+            data_lhs.init = true;\n+            data_lhs.roaring_bitmap_with_small_set.merge(data_rhs.roaring_bitmap_with_small_set);\n+        }\n+        else\n+        {\n+            Policy::apply(data_lhs, data_rhs);\n+        }\n     }\n \n-    // Additional aggregate functions to manipulate bitmaps.\n-    template <template <typename, typename> typename AggregateFunctionTemplate>\n-    AggregateFunctionPtr createAggregateFunctionBitmapL2(\n-        const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n     {\n-        assertNoParameters(name, parameters);\n-        assertUnary(name, argument_types);\n+        Data & data_lhs = this->data(place);\n+        const Data & data_rhs = this->data(rhs);\n+\n+        if (!data_rhs.init)\n+            return;\n+\n+        if (!data_lhs.init)\n+        {\n+            data_lhs.init = true;\n+            data_lhs.roaring_bitmap_with_small_set.merge(data_rhs.roaring_bitmap_with_small_set);\n+        }\n+        else\n+        {\n+            Policy::apply(data_lhs, data_rhs);\n+        }\n+    }\n+\n+    bool isVersioned() const override { return true; }\n \n-        DataTypePtr argument_type_ptr = argument_types[0];\n-        WhichDataType which(*argument_type_ptr);\n-        if (which.idx != TypeIndex::AggregateFunction)\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n-                argument_types[0]->getName(), name);\n+    size_t getDefaultVersion() const override { return 1; }\n \n-        /// groupBitmap needs to know about the data type that was used to create bitmaps.\n-        /// We need to look inside the type of its argument to obtain it.\n-        const DataTypeAggregateFunction & datatype_aggfunc = dynamic_cast<const DataTypeAggregateFunction &>(*argument_type_ptr);\n-        AggregateFunctionPtr aggfunc = datatype_aggfunc.getFunction();\n+    size_t getVersionFromRevision(size_t revision) const override\n+    {\n+        if (revision >= STATE_VERSION_1_MIN_REVISION)\n+            return 1;\n+        else\n+            return 0;\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> version) const override\n+    {\n+        if (!version)\n+            version = getDefaultVersion();\n \n-        if (aggfunc->getName() != AggregateFunctionGroupBitmapData<UInt8>::name())\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n-                argument_types[0]->getName(), name);\n+        if (*version >= 1)\n+            DB::writeBoolText(this->data(place).init, buf);\n \n-        DataTypePtr nested_argument_type_ptr = aggfunc->getArgumentTypes()[0];\n+        this->data(place).roaring_bitmap_with_small_set.write(buf);\n+    }\n \n-        AggregateFunctionPtr res(createWithIntegerType<AggregateFunctionTemplate, AggregateFunctionGroupBitmapData>(\n-            *nested_argument_type_ptr, argument_type_ptr));\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> version, Arena *) const override\n+    {\n+        if (!version)\n+            version = getDefaultVersion();\n \n-        if (!res)\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n-                argument_types[0]->getName(), name);\n+        if (*version >= 1)\n+            DB::readBoolText(this->data(place).init, buf);\n+        this->data(place).roaring_bitmap_with_small_set.read(buf);\n+    }\n \n-        return res;\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        assert_cast<ColumnVector<T> &>(to).getData().push_back(\n+            static_cast<T>(this->data(place).roaring_bitmap_with_small_set.size()));\n     }\n+};\n+\n+\n+template <typename Data>\n+class BitmapAndPolicy\n+{\n+public:\n+    static constexpr auto name = \"groupBitmapAnd\";\n+    static void apply(Data & lhs, const Data & rhs) { lhs.roaring_bitmap_with_small_set.rb_and(rhs.roaring_bitmap_with_small_set); }\n+};\n+\n+template <typename Data>\n+class BitmapOrPolicy\n+{\n+public:\n+    static constexpr auto name = \"groupBitmapOr\";\n+    static void apply(Data & lhs, const Data & rhs) { lhs.roaring_bitmap_with_small_set.rb_or(rhs.roaring_bitmap_with_small_set); }\n+};\n+\n+template <typename Data>\n+class BitmapXorPolicy\n+{\n+public:\n+    static constexpr auto name = \"groupBitmapXor\";\n+    static void apply(Data & lhs, const Data & rhs) { lhs.roaring_bitmap_with_small_set.rb_xor(rhs.roaring_bitmap_with_small_set); }\n+};\n+\n+template <typename T, typename Data>\n+using AggregateFunctionBitmapL2And = AggregateFunctionBitmapL2<T, Data, BitmapAndPolicy<Data>>;\n+\n+template <typename T, typename Data>\n+using AggregateFunctionBitmapL2Or = AggregateFunctionBitmapL2<T, Data, BitmapOrPolicy<Data>>;\n+\n+template <typename T, typename Data>\n+using AggregateFunctionBitmapL2Xor = AggregateFunctionBitmapL2<T, Data, BitmapXorPolicy<Data>>;\n+\n+\n+template <template <typename, typename> class AggregateFunctionTemplate, template <typename> typename Data, typename... TArgs>\n+IAggregateFunction * createWithIntegerType(const IDataType & argument_type, TArgs &&... args)\n+{\n+    WhichDataType which(argument_type);\n+    if (which.idx == TypeIndex::UInt8) return new AggregateFunctionTemplate<UInt8, Data<UInt8>>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::UInt16) return new AggregateFunctionTemplate<UInt16, Data<UInt16>>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::UInt32) return new AggregateFunctionTemplate<UInt32, Data<UInt32>>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::UInt64) return new AggregateFunctionTemplate<UInt64, Data<UInt64>>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::Int8) return new AggregateFunctionTemplate<Int8, Data<Int8>>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::Int16) return new AggregateFunctionTemplate<Int16, Data<Int16>>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::Int32) return new AggregateFunctionTemplate<Int32, Data<Int32>>(std::forward<TArgs>(args)...);\n+    if (which.idx == TypeIndex::Int64) return new AggregateFunctionTemplate<Int64, Data<Int64>>(std::forward<TArgs>(args)...);\n+    return nullptr;\n+}\n+\n+template <template <typename> typename Data>\n+AggregateFunctionPtr createAggregateFunctionBitmap(\n+    const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+{\n+    assertNoParameters(name, parameters);\n+    assertUnary(name, argument_types);\n+\n+    if (!argument_types[0]->canBeUsedInBitOperations())\n+        throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+                        \"The type {} of argument for aggregate function {} \"\n+                        \"is illegal, because it cannot be used in Bitmap operations\",\n+                        argument_types[0]->getName(), name);\n+\n+    AggregateFunctionPtr res(createWithIntegerType<AggregateFunctionBitmap, Data>(*argument_types[0], argument_types[0]));\n+\n+    if (!res)\n+        throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n+            argument_types[0]->getName(), name);\n+\n+    return res;\n+}\n+\n+// Additional aggregate functions to manipulate bitmaps.\n+template <template <typename, typename> typename AggregateFunctionTemplate>\n+AggregateFunctionPtr createAggregateFunctionBitmapL2(\n+    const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+{\n+    assertNoParameters(name, parameters);\n+    assertUnary(name, argument_types);\n+\n+    DataTypePtr argument_type_ptr = argument_types[0];\n+    WhichDataType which(*argument_type_ptr);\n+    if (which.idx != TypeIndex::AggregateFunction)\n+        throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n+            argument_types[0]->getName(), name);\n+\n+    /// groupBitmap needs to know about the data type that was used to create bitmaps.\n+    /// We need to look inside the type of its argument to obtain it.\n+    const DataTypeAggregateFunction & datatype_aggfunc = dynamic_cast<const DataTypeAggregateFunction &>(*argument_type_ptr);\n+    AggregateFunctionPtr aggfunc = datatype_aggfunc.getFunction();\n+\n+    if (aggfunc->getName() != AggregateFunctionGroupBitmapData<UInt8>::name())\n+        throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n+            argument_types[0]->getName(), name);\n+\n+    DataTypePtr nested_argument_type_ptr = aggfunc->getArgumentTypes()[0];\n+\n+    AggregateFunctionPtr res(createWithIntegerType<AggregateFunctionTemplate, AggregateFunctionGroupBitmapData>(\n+        *nested_argument_type_ptr, argument_type_ptr));\n+\n+    if (!res)\n+        throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n+            argument_types[0]->getName(), name);\n+\n+    return res;\n+}\n+\n }\n \n void registerAggregateFunctionsBitmap(AggregateFunctionFactory & factory)\ndiff --git a/src/AggregateFunctions/AggregateFunctionGroupBitmap.h b/src/AggregateFunctions/AggregateFunctionGroupBitmap.h\ndeleted file mode 100644\nindex a32bb330884b..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionGroupBitmap.h\n+++ /dev/null\n@@ -1,191 +0,0 @@\n-#pragma once\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <Columns/ColumnAggregateFunction.h>\n-#include <Columns/ColumnVector.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <Common/assert_cast.h>\n-\n-// TODO include this last because of a broken roaring header. See the comment inside.\n-#include <AggregateFunctions/AggregateFunctionGroupBitmapData.h>\n-\n-\n-namespace DB\n-{\n-\n-/// Counts bitmap operation on numbers.\n-template <typename T, typename Data>\n-class AggregateFunctionBitmap final : public IAggregateFunctionDataHelper<Data, AggregateFunctionBitmap<T, Data>>\n-{\n-public:\n-    explicit AggregateFunctionBitmap(const DataTypePtr & type)\n-        : IAggregateFunctionDataHelper<Data, AggregateFunctionBitmap<T, Data>>({type}, {}, createResultType())\n-    {\n-    }\n-\n-    String getName() const override { return Data::name(); }\n-\n-    static DataTypePtr createResultType() { return std::make_shared<DataTypeNumber<T>>(); }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        this->data(place).roaring_bitmap_with_small_set.add(assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num]);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).roaring_bitmap_with_small_set.merge(this->data(rhs).roaring_bitmap_with_small_set);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).roaring_bitmap_with_small_set.write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).roaring_bitmap_with_small_set.read(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        assert_cast<ColumnVector<T> &>(to).getData().push_back(\n-            static_cast<T>(this->data(place).roaring_bitmap_with_small_set.size()));\n-    }\n-};\n-\n-\n-/// This aggregate function takes the states of AggregateFunctionBitmap as its argument.\n-template <typename T, typename Data, typename Policy>\n-class AggregateFunctionBitmapL2 final : public IAggregateFunctionDataHelper<Data, AggregateFunctionBitmapL2<T, Data, Policy>>\n-{\n-private:\n-    static constexpr size_t STATE_VERSION_1_MIN_REVISION = 54455;\n-public:\n-    explicit AggregateFunctionBitmapL2(const DataTypePtr & type)\n-        : IAggregateFunctionDataHelper<Data, AggregateFunctionBitmapL2<T, Data, Policy>>({type}, {}, createResultType())\n-    {\n-    }\n-\n-    String getName() const override { return Policy::name; }\n-\n-    static DataTypePtr createResultType() { return std::make_shared<DataTypeNumber<T>>(); }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    DataTypePtr getStateType() const override\n-    {\n-        return this->argument_types.at(0);\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        Data & data_lhs = this->data(place);\n-        const Data & data_rhs = this->data(assert_cast<const ColumnAggregateFunction &>(*columns[0]).getData()[row_num]);\n-        if (!data_lhs.init)\n-        {\n-            data_lhs.init = true;\n-            data_lhs.roaring_bitmap_with_small_set.merge(data_rhs.roaring_bitmap_with_small_set);\n-        }\n-        else\n-        {\n-            Policy::apply(data_lhs, data_rhs);\n-        }\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        Data & data_lhs = this->data(place);\n-        const Data & data_rhs = this->data(rhs);\n-\n-        if (!data_rhs.init)\n-            return;\n-\n-        if (!data_lhs.init)\n-        {\n-            data_lhs.init = true;\n-            data_lhs.roaring_bitmap_with_small_set.merge(data_rhs.roaring_bitmap_with_small_set);\n-        }\n-        else\n-        {\n-            Policy::apply(data_lhs, data_rhs);\n-        }\n-    }\n-\n-    bool isVersioned() const override { return true; }\n-\n-    size_t getDefaultVersion() const override { return 1; }\n-\n-    size_t getVersionFromRevision(size_t revision) const override\n-    {\n-        if (revision >= STATE_VERSION_1_MIN_REVISION)\n-            return 1;\n-        else\n-            return 0;\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> version) const override\n-    {\n-        if (!version)\n-            version = getDefaultVersion();\n-\n-        if (*version >= 1)\n-            DB::writeBoolText(this->data(place).init, buf);\n-\n-        this->data(place).roaring_bitmap_with_small_set.write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> version, Arena *) const override\n-    {\n-        if (!version)\n-            version = getDefaultVersion();\n-\n-        if (*version >= 1)\n-            DB::readBoolText(this->data(place).init, buf);\n-        this->data(place).roaring_bitmap_with_small_set.read(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        assert_cast<ColumnVector<T> &>(to).getData().push_back(\n-            static_cast<T>(this->data(place).roaring_bitmap_with_small_set.size()));\n-    }\n-};\n-\n-\n-template <typename Data>\n-class BitmapAndPolicy\n-{\n-public:\n-    static constexpr auto name = \"groupBitmapAnd\";\n-    static void apply(Data & lhs, const Data & rhs) { lhs.roaring_bitmap_with_small_set.rb_and(rhs.roaring_bitmap_with_small_set); }\n-};\n-\n-template <typename Data>\n-class BitmapOrPolicy\n-{\n-public:\n-    static constexpr auto name = \"groupBitmapOr\";\n-    static void apply(Data & lhs, const Data & rhs) { lhs.roaring_bitmap_with_small_set.rb_or(rhs.roaring_bitmap_with_small_set); }\n-};\n-\n-template <typename Data>\n-class BitmapXorPolicy\n-{\n-public:\n-    static constexpr auto name = \"groupBitmapXor\";\n-    static void apply(Data & lhs, const Data & rhs) { lhs.roaring_bitmap_with_small_set.rb_xor(rhs.roaring_bitmap_with_small_set); }\n-};\n-\n-template <typename T, typename Data>\n-using AggregateFunctionBitmapL2And = AggregateFunctionBitmapL2<T, Data, BitmapAndPolicy<Data>>;\n-\n-template <typename T, typename Data>\n-using AggregateFunctionBitmapL2Or = AggregateFunctionBitmapL2<T, Data, BitmapOrPolicy<Data>>;\n-\n-template <typename T, typename Data>\n-using AggregateFunctionBitmapL2Xor = AggregateFunctionBitmapL2<T, Data, BitmapXorPolicy<Data>>;\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionGroupUniqArray.cpp b/src/AggregateFunctions/AggregateFunctionGroupUniqArray.cpp\nindex 9e8060d44ccb..b2431be89d68 100644\n--- a/src/AggregateFunctions/AggregateFunctionGroupUniqArray.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionGroupUniqArray.cpp\n@@ -1,14 +1,31 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionGroupUniqArray.h>\n #include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n #include <DataTypes/DataTypeDate.h>\n #include <DataTypes/DataTypeDateTime.h>\n #include <DataTypes/DataTypeIPv4andIPv6.h>\n \n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/ReadHelpersArena.h>\n+\n+#include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeString.h>\n+\n+#include <Columns/ColumnArray.h>\n+\n+#include <Common/HashTable/HashSet.h>\n+#include <Common/HashTable/HashTableKeyHolder.h>\n+#include <Common/assert_cast.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/KeyHolderHelpers.h>\n+\n \n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n@@ -21,6 +38,211 @@ namespace ErrorCodes\n namespace\n {\n \n+template <typename T>\n+struct AggregateFunctionGroupUniqArrayData\n+{\n+    /// When creating, the hash table must be small.\n+    using Set = HashSetWithStackMemory<T, DefaultHash<T>, 4>;\n+\n+    Set value;\n+};\n+\n+\n+/// Puts all values to the hash set. Returns an array of unique values. Implemented for numeric types.\n+template <typename T, typename LimitNumElems>\n+class AggregateFunctionGroupUniqArray\n+    : public IAggregateFunctionDataHelper<AggregateFunctionGroupUniqArrayData<T>, AggregateFunctionGroupUniqArray<T, LimitNumElems>>\n+{\n+    static constexpr bool limit_num_elems = LimitNumElems::value;\n+    UInt64 max_elems;\n+\n+private:\n+    using State = AggregateFunctionGroupUniqArrayData<T>;\n+\n+public:\n+    AggregateFunctionGroupUniqArray(const DataTypePtr & argument_type, const Array & parameters_, UInt64 max_elems_ = std::numeric_limits<UInt64>::max())\n+        : IAggregateFunctionDataHelper<AggregateFunctionGroupUniqArrayData<T>,\n+          AggregateFunctionGroupUniqArray<T, LimitNumElems>>({argument_type}, parameters_, std::make_shared<DataTypeArray>(argument_type)),\n+          max_elems(max_elems_) {}\n+\n+    AggregateFunctionGroupUniqArray(const DataTypePtr & argument_type, const Array & parameters_, const DataTypePtr & result_type_, UInt64 max_elems_ = std::numeric_limits<UInt64>::max())\n+        : IAggregateFunctionDataHelper<AggregateFunctionGroupUniqArrayData<T>,\n+          AggregateFunctionGroupUniqArray<T, LimitNumElems>>({argument_type}, parameters_, result_type_),\n+          max_elems(max_elems_) {}\n+\n+\n+    String getName() const override { return \"groupUniqArray\"; }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        if (limit_num_elems && this->data(place).value.size() >= max_elems)\n+            return;\n+        this->data(place).value.insert(assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num]);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        if (!limit_num_elems)\n+            this->data(place).value.merge(this->data(rhs).value);\n+        else\n+        {\n+            auto & cur_set = this->data(place).value;\n+            auto & rhs_set = this->data(rhs).value;\n+\n+            for (auto & rhs_elem : rhs_set)\n+            {\n+                if (cur_set.size() >= max_elems)\n+                    return;\n+                cur_set.insert(rhs_elem.getValue());\n+            }\n+        }\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        auto & set = this->data(place).value;\n+        size_t size = set.size();\n+        writeVarUInt(size, buf);\n+        for (const auto & elem : set)\n+            writeBinaryLittleEndian(elem.key, buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).value.read(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n+        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n+\n+        const typename State::Set & set = this->data(place).value;\n+        size_t size = set.size();\n+\n+        offsets_to.push_back(offsets_to.back() + size);\n+\n+        typename ColumnVector<T>::Container & data_to = assert_cast<ColumnVector<T> &>(arr_to.getData()).getData();\n+        size_t old_size = data_to.size();\n+        data_to.resize(old_size + size);\n+\n+        size_t i = 0;\n+        for (auto it = set.begin(); it != set.end(); ++it, ++i)\n+            data_to[old_size + i] = it->getValue();\n+    }\n+};\n+\n+\n+/// Generic implementation, it uses serialized representation as object descriptor.\n+struct AggregateFunctionGroupUniqArrayGenericData\n+{\n+    static constexpr size_t INITIAL_SIZE_DEGREE = 3; /// adjustable\n+\n+    using Set = HashSetWithSavedHashWithStackMemory<StringRef, StringRefHash,\n+        INITIAL_SIZE_DEGREE>;\n+\n+    Set value;\n+};\n+\n+template <bool is_plain_column>\n+static void deserializeAndInsertImpl(StringRef str, IColumn & data_to);\n+\n+/** Template parameter with true value should be used for columns that store their elements in memory continuously.\n+ *  For such columns groupUniqArray() can be implemented more efficiently (especially for small numeric arrays).\n+ */\n+template <bool is_plain_column = false, typename LimitNumElems = std::false_type>\n+class AggregateFunctionGroupUniqArrayGeneric\n+    : public IAggregateFunctionDataHelper<AggregateFunctionGroupUniqArrayGenericData,\n+        AggregateFunctionGroupUniqArrayGeneric<is_plain_column, LimitNumElems>>\n+{\n+    DataTypePtr & input_data_type;\n+\n+    static constexpr bool limit_num_elems = LimitNumElems::value;\n+    UInt64 max_elems;\n+\n+    using State = AggregateFunctionGroupUniqArrayGenericData;\n+\n+public:\n+    AggregateFunctionGroupUniqArrayGeneric(const DataTypePtr & input_data_type_, const Array & parameters_, UInt64 max_elems_ = std::numeric_limits<UInt64>::max())\n+        : IAggregateFunctionDataHelper<AggregateFunctionGroupUniqArrayGenericData, AggregateFunctionGroupUniqArrayGeneric<is_plain_column, LimitNumElems>>({input_data_type_}, parameters_, std::make_shared<DataTypeArray>(input_data_type_))\n+        , input_data_type(this->argument_types[0])\n+        , max_elems(max_elems_) {}\n+\n+    String getName() const override { return \"groupUniqArray\"; }\n+\n+    bool allocatesMemoryInArena() const override\n+    {\n+        return true;\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        auto & set = this->data(place).value;\n+        writeVarUInt(set.size(), buf);\n+\n+        for (const auto & elem : set)\n+        {\n+            writeStringBinary(elem.getValue(), buf);\n+        }\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n+    {\n+        auto & set = this->data(place).value;\n+        size_t size;\n+        readVarUInt(size, buf);\n+\n+        for (size_t i = 0; i < size; ++i)\n+            set.insert(readStringBinaryInto(*arena, buf));\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        auto & set = this->data(place).value;\n+        if (limit_num_elems && set.size() >= max_elems)\n+            return;\n+\n+        bool inserted;\n+        State::Set::LookupResult it;\n+        auto key_holder = getKeyHolder<is_plain_column>(*columns[0], row_num, *arena);\n+        set.emplace(key_holder, it, inserted);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n+    {\n+        auto & cur_set = this->data(place).value;\n+        auto & rhs_set = this->data(rhs).value;\n+\n+        bool inserted;\n+        State::Set::LookupResult it;\n+        for (auto & rhs_elem : rhs_set)\n+        {\n+            if (limit_num_elems && cur_set.size() >= max_elems)\n+                return;\n+\n+            // We have to copy the keys to our arena.\n+            chassert(arena != nullptr);\n+            cur_set.emplace(ArenaKeyHolder{rhs_elem.getValue(), *arena}, it, inserted);\n+        }\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n+        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n+        IColumn & data_to = arr_to.getData();\n+\n+        auto & set = this->data(place).value;\n+        offsets_to.push_back(offsets_to.back() + set.size());\n+\n+        for (auto & elem : set)\n+            deserializeAndInsert<is_plain_column>(elem.getValue(), data_to);\n+    }\n+};\n+\n+\n /// Substitute return type for Date and DateTime\n template <typename HasLimit>\n class AggregateFunctionGroupUniqArrayDate : public AggregateFunctionGroupUniqArray<DataTypeDate::FieldType, HasLimit>\ndiff --git a/src/AggregateFunctions/AggregateFunctionGroupUniqArray.h b/src/AggregateFunctions/AggregateFunctionGroupUniqArray.h\ndeleted file mode 100644\nindex dd8abf93d900..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionGroupUniqArray.h\n+++ /dev/null\n@@ -1,236 +0,0 @@\n-#pragma once\n-\n-#include <cassert>\n-\n-#include <IO/WriteHelpers.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/ReadHelpersArena.h>\n-\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeString.h>\n-\n-#include <Columns/ColumnArray.h>\n-\n-#include <Common/HashTable/HashSet.h>\n-#include <Common/HashTable/HashTableKeyHolder.h>\n-#include <Common/assert_cast.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/KeyHolderHelpers.h>\n-\n-#define AGGREGATE_FUNCTION_GROUP_ARRAY_UNIQ_MAX_SIZE 0xFFFFFF\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-\n-template <typename T>\n-struct AggregateFunctionGroupUniqArrayData\n-{\n-    /// When creating, the hash table must be small.\n-    using Set = HashSetWithStackMemory<T, DefaultHash<T>, 4>;\n-\n-    Set value;\n-};\n-\n-\n-/// Puts all values to the hash set. Returns an array of unique values. Implemented for numeric types.\n-template <typename T, typename LimitNumElems>\n-class AggregateFunctionGroupUniqArray\n-    : public IAggregateFunctionDataHelper<AggregateFunctionGroupUniqArrayData<T>, AggregateFunctionGroupUniqArray<T, LimitNumElems>>\n-{\n-    static constexpr bool limit_num_elems = LimitNumElems::value;\n-    UInt64 max_elems;\n-\n-private:\n-    using State = AggregateFunctionGroupUniqArrayData<T>;\n-\n-public:\n-    AggregateFunctionGroupUniqArray(const DataTypePtr & argument_type, const Array & parameters_, UInt64 max_elems_ = std::numeric_limits<UInt64>::max())\n-        : IAggregateFunctionDataHelper<AggregateFunctionGroupUniqArrayData<T>,\n-          AggregateFunctionGroupUniqArray<T, LimitNumElems>>({argument_type}, parameters_, std::make_shared<DataTypeArray>(argument_type)),\n-          max_elems(max_elems_) {}\n-\n-    AggregateFunctionGroupUniqArray(const DataTypePtr & argument_type, const Array & parameters_, const DataTypePtr & result_type_, UInt64 max_elems_ = std::numeric_limits<UInt64>::max())\n-        : IAggregateFunctionDataHelper<AggregateFunctionGroupUniqArrayData<T>,\n-          AggregateFunctionGroupUniqArray<T, LimitNumElems>>({argument_type}, parameters_, result_type_),\n-          max_elems(max_elems_) {}\n-\n-\n-    String getName() const override { return \"groupUniqArray\"; }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        if (limit_num_elems && this->data(place).value.size() >= max_elems)\n-            return;\n-        this->data(place).value.insert(assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num]);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        if (!limit_num_elems)\n-            this->data(place).value.merge(this->data(rhs).value);\n-        else\n-        {\n-            auto & cur_set = this->data(place).value;\n-            auto & rhs_set = this->data(rhs).value;\n-\n-            for (auto & rhs_elem : rhs_set)\n-            {\n-                if (cur_set.size() >= max_elems)\n-                    return;\n-                cur_set.insert(rhs_elem.getValue());\n-            }\n-        }\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        auto & set = this->data(place).value;\n-        size_t size = set.size();\n-        writeVarUInt(size, buf);\n-        for (const auto & elem : set)\n-            writeBinaryLittleEndian(elem.key, buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).value.read(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n-        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n-\n-        const typename State::Set & set = this->data(place).value;\n-        size_t size = set.size();\n-\n-        offsets_to.push_back(offsets_to.back() + size);\n-\n-        typename ColumnVector<T>::Container & data_to = assert_cast<ColumnVector<T> &>(arr_to.getData()).getData();\n-        size_t old_size = data_to.size();\n-        data_to.resize(old_size + size);\n-\n-        size_t i = 0;\n-        for (auto it = set.begin(); it != set.end(); ++it, ++i)\n-            data_to[old_size + i] = it->getValue();\n-    }\n-};\n-\n-\n-/// Generic implementation, it uses serialized representation as object descriptor.\n-struct AggregateFunctionGroupUniqArrayGenericData\n-{\n-    static constexpr size_t INITIAL_SIZE_DEGREE = 3; /// adjustable\n-\n-    using Set = HashSetWithSavedHashWithStackMemory<StringRef, StringRefHash,\n-        INITIAL_SIZE_DEGREE>;\n-\n-    Set value;\n-};\n-\n-template <bool is_plain_column>\n-static void deserializeAndInsertImpl(StringRef str, IColumn & data_to);\n-\n-/** Template parameter with true value should be used for columns that store their elements in memory continuously.\n- *  For such columns groupUniqArray() can be implemented more efficiently (especially for small numeric arrays).\n- */\n-template <bool is_plain_column = false, typename LimitNumElems = std::false_type>\n-class AggregateFunctionGroupUniqArrayGeneric\n-    : public IAggregateFunctionDataHelper<AggregateFunctionGroupUniqArrayGenericData,\n-        AggregateFunctionGroupUniqArrayGeneric<is_plain_column, LimitNumElems>>\n-{\n-    DataTypePtr & input_data_type;\n-\n-    static constexpr bool limit_num_elems = LimitNumElems::value;\n-    UInt64 max_elems;\n-\n-    using State = AggregateFunctionGroupUniqArrayGenericData;\n-\n-public:\n-    AggregateFunctionGroupUniqArrayGeneric(const DataTypePtr & input_data_type_, const Array & parameters_, UInt64 max_elems_ = std::numeric_limits<UInt64>::max())\n-        : IAggregateFunctionDataHelper<AggregateFunctionGroupUniqArrayGenericData, AggregateFunctionGroupUniqArrayGeneric<is_plain_column, LimitNumElems>>({input_data_type_}, parameters_, std::make_shared<DataTypeArray>(input_data_type_))\n-        , input_data_type(this->argument_types[0])\n-        , max_elems(max_elems_) {}\n-\n-    String getName() const override { return \"groupUniqArray\"; }\n-\n-    bool allocatesMemoryInArena() const override\n-    {\n-        return true;\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        auto & set = this->data(place).value;\n-        writeVarUInt(set.size(), buf);\n-\n-        for (const auto & elem : set)\n-        {\n-            writeStringBinary(elem.getValue(), buf);\n-        }\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        auto & set = this->data(place).value;\n-        size_t size;\n-        readVarUInt(size, buf);\n-\n-        for (size_t i = 0; i < size; ++i)\n-            set.insert(readStringBinaryInto(*arena, buf));\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        auto & set = this->data(place).value;\n-        if (limit_num_elems && set.size() >= max_elems)\n-            return;\n-\n-        bool inserted;\n-        State::Set::LookupResult it;\n-        auto key_holder = getKeyHolder<is_plain_column>(*columns[0], row_num, *arena);\n-        set.emplace(key_holder, it, inserted);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n-    {\n-        auto & cur_set = this->data(place).value;\n-        auto & rhs_set = this->data(rhs).value;\n-\n-        bool inserted;\n-        State::Set::LookupResult it;\n-        for (auto & rhs_elem : rhs_set)\n-        {\n-            if (limit_num_elems && cur_set.size() >= max_elems)\n-                return;\n-\n-            // We have to copy the keys to our arena.\n-            assert(arena != nullptr);\n-            cur_set.emplace(ArenaKeyHolder{rhs_elem.getValue(), *arena}, it, inserted);\n-        }\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n-        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n-        IColumn & data_to = arr_to.getData();\n-\n-        auto & set = this->data(place).value;\n-        offsets_to.push_back(offsets_to.back() + set.size());\n-\n-        for (auto & elem : set)\n-            deserializeAndInsert<is_plain_column>(elem.getValue(), data_to);\n-    }\n-};\n-\n-#undef AGGREGATE_FUNCTION_GROUP_ARRAY_UNIQ_MAX_SIZE\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionHistogram.cpp b/src/AggregateFunctions/AggregateFunctionHistogram.cpp\nindex b430e433bef4..4e935b4def13 100644\n--- a/src/AggregateFunctions/AggregateFunctionHistogram.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionHistogram.cpp\n@@ -1,9 +1,31 @@\n-#include <AggregateFunctions/AggregateFunctionHistogram.h>\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n #include <AggregateFunctions/Helpers.h>\n #include <Common/FieldVisitorConvertToNumber.h>\n \n+#include <Common/NaNUtils.h>\n+\n+#include <Columns/ColumnVector.h>\n+#include <Columns/ColumnTuple.h>\n+#include <Columns/ColumnArray.h>\n+#include <Common/assert_cast.h>\n+\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypeTuple.h>\n+\n+#include <IO/WriteBuffer.h>\n+#include <IO/ReadBuffer.h>\n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/VarInt.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+\n+#include <queue>\n+#include <cmath>\n+#include <cstddef>\n+\n \n namespace DB\n {\n@@ -16,12 +38,357 @@ namespace ErrorCodes\n     extern const int BAD_ARGUMENTS;\n     extern const int UNSUPPORTED_PARAMETER;\n     extern const int PARAMETER_OUT_OF_BOUND;\n+    extern const int TOO_LARGE_ARRAY_SIZE;\n+    extern const int INCORRECT_DATA;\n }\n \n \n namespace\n {\n \n+/** distance compression algorithm implementation\n+  * http://jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf\n+  */\n+class AggregateFunctionHistogramData\n+{\n+public:\n+    using Mean = Float64;\n+    using Weight = Float64;\n+\n+    constexpr static size_t bins_count_limit = 250;\n+\n+private:\n+    struct WeightedValue\n+    {\n+        Mean mean;\n+        Weight weight;\n+\n+        WeightedValue operator+(const WeightedValue & other) const\n+        {\n+            return {mean + other.weight * (other.mean - mean) / (other.weight + weight), other.weight + weight};\n+        }\n+    };\n+\n+    // quantity of stored weighted-values\n+    UInt32 size;\n+\n+    // calculated lower and upper bounds of seen points\n+    Mean lower_bound;\n+    Mean upper_bound;\n+\n+    // Weighted values representation of histogram.\n+    WeightedValue points[0];\n+\n+    void sort()\n+    {\n+        ::sort(points, points + size,\n+            [](const WeightedValue & first, const WeightedValue & second)\n+            {\n+                return first.mean < second.mean;\n+            });\n+    }\n+\n+    template <typename T>\n+    struct PriorityQueueStorage\n+    {\n+        size_t size = 0;\n+        T * data_ptr;\n+\n+        explicit PriorityQueueStorage(T * value)\n+            : data_ptr(value)\n+        {\n+        }\n+\n+        void push_back(T val) /// NOLINT\n+        {\n+            data_ptr[size] = std::move(val);\n+            ++size;\n+        }\n+\n+        void pop_back() { --size; } /// NOLINT\n+        T * begin() { return data_ptr; }\n+        T * end() const { return data_ptr + size; }\n+        bool empty() const { return size == 0; }\n+        T & front() { return *data_ptr; }\n+        const T & front() const { return *data_ptr; }\n+\n+        using value_type = T;\n+        using reference = T&;\n+        using const_reference = const T&;\n+        using size_type = size_t;\n+    };\n+\n+    /**\n+     * Repeatedly fuse most close values until max_bins bins left\n+     */\n+    void compress(UInt32 max_bins)\n+    {\n+        sort();\n+        auto new_size = size;\n+        if (size <= max_bins)\n+            return;\n+\n+        // Maintain doubly-linked list of \"active\" points\n+        // and store neighbour pairs in priority queue by distance\n+        UInt32 previous[size + 1];\n+        UInt32 next[size + 1];\n+        bool active[size + 1];\n+        std::fill(active, active + size, true);\n+        active[size] = false;\n+\n+        auto delete_node = [&](UInt32 i)\n+        {\n+            previous[next[i]] = previous[i];\n+            next[previous[i]] = next[i];\n+            active[i] = false;\n+        };\n+\n+        for (size_t i = 0; i <= size; ++i)\n+        {\n+            previous[i] = static_cast<UInt32>(i - 1);\n+            next[i] = static_cast<UInt32>(i + 1);\n+        }\n+\n+        next[size] = 0;\n+        previous[0] = size;\n+\n+        using QueueItem = std::pair<Mean, UInt32>;\n+\n+        QueueItem storage[2 * size - max_bins];\n+\n+        std::priority_queue<\n+            QueueItem,\n+            PriorityQueueStorage<QueueItem>,\n+            std::greater<>>\n+                queue{std::greater<>(),\n+                        PriorityQueueStorage<QueueItem>(storage)};\n+\n+        auto quality = [&](UInt32 i) { return points[next[i]].mean - points[i].mean; };\n+\n+        for (size_t i = 0; i + 1 < size; ++i)\n+            queue.push({quality(static_cast<UInt32>(i)), i});\n+\n+        while (new_size > max_bins && !queue.empty())\n+        {\n+            auto min_item = queue.top();\n+            queue.pop();\n+            auto left = min_item.second;\n+            auto right = next[left];\n+\n+            if (!active[left] || !active[right] || quality(left) > min_item.first)\n+                continue;\n+\n+            points[left] = points[left] + points[right];\n+\n+            delete_node(right);\n+            if (active[next[left]])\n+                queue.push({quality(left), left});\n+            if (active[previous[left]])\n+                queue.push({quality(previous[left]), previous[left]});\n+\n+            --new_size;\n+        }\n+\n+        size_t left = 0;\n+        for (size_t right = 0; right < size; ++right)\n+        {\n+            if (active[right])\n+            {\n+                points[left] = points[right];\n+                ++left;\n+            }\n+        }\n+        size = new_size;\n+    }\n+\n+    /***\n+     * Delete too close points from histogram.\n+     * Assumes that points are sorted.\n+     */\n+    void unique()\n+    {\n+        if (size == 0)\n+            return;\n+\n+        size_t left = 0;\n+\n+        for (auto right = left + 1; right < size; ++right)\n+        {\n+            // Fuse points if their text representations differ only in last digit\n+            auto min_diff = 10 * (points[left].mean + points[right].mean) * std::numeric_limits<Mean>::epsilon();\n+            if (points[left].mean + std::fabs(min_diff) >= points[right].mean)\n+            {\n+                points[left] = points[left] + points[right];\n+            }\n+            else\n+            {\n+                ++left;\n+                points[left] = points[right];\n+            }\n+        }\n+        size = static_cast<UInt32>(left + 1);\n+    }\n+\n+public:\n+    AggregateFunctionHistogramData()\n+        : size(0)\n+        , lower_bound(std::numeric_limits<Mean>::max())\n+        , upper_bound(std::numeric_limits<Mean>::lowest())\n+    {\n+        static_assert(offsetof(AggregateFunctionHistogramData, points) == sizeof(AggregateFunctionHistogramData), \"points should be last member\");\n+    }\n+\n+    static size_t structSize(size_t max_bins)\n+    {\n+        return sizeof(AggregateFunctionHistogramData) + max_bins * 2 * sizeof(WeightedValue);\n+    }\n+\n+    void insertResultInto(ColumnVector<Mean> & to_lower, ColumnVector<Mean> & to_upper, ColumnVector<Weight> & to_weights, UInt32 max_bins)\n+    {\n+        compress(max_bins);\n+        unique();\n+\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            to_lower.insertValue((i == 0) ? lower_bound : (points[i].mean + points[i - 1].mean) / 2);\n+            to_upper.insertValue((i + 1 == size) ? upper_bound : (points[i].mean + points[i + 1].mean) / 2);\n+\n+            // linear density approximation\n+            Weight lower_weight = (i == 0) ? points[i].weight : ((points[i - 1].weight) + points[i].weight * 3) / 4;\n+            Weight upper_weight = (i + 1 == size) ? points[i].weight : (points[i + 1].weight + points[i].weight * 3) / 4;\n+            to_weights.insertValue((lower_weight + upper_weight) / 2);\n+        }\n+    }\n+\n+    void add(Mean value, Weight weight, UInt32 max_bins)\n+    {\n+        // nans break sort and compression\n+        // infs don't fit in bins partition method\n+        if (!isFinite(value))\n+            throw Exception(ErrorCodes::INCORRECT_DATA, \"Invalid value (inf or nan) for aggregation by 'histogram' function\");\n+\n+        points[size] = {value, weight};\n+        ++size;\n+        lower_bound = std::min(lower_bound, value);\n+        upper_bound = std::max(upper_bound, value);\n+\n+        if (size >= max_bins * 2)\n+            compress(max_bins);\n+    }\n+\n+    void merge(const AggregateFunctionHistogramData & other, UInt32 max_bins)\n+    {\n+        lower_bound = std::min(lower_bound, other.lower_bound);\n+        upper_bound = std::max(upper_bound, other.upper_bound);\n+        for (size_t i = 0; i < other.size; ++i)\n+            add(other.points[i].mean, other.points[i].weight, max_bins);\n+    }\n+\n+    void write(WriteBuffer & buf) const\n+    {\n+        writeBinary(lower_bound, buf);\n+        writeBinary(upper_bound, buf);\n+\n+        writeVarUInt(size, buf);\n+        buf.write(reinterpret_cast<const char *>(points), size * sizeof(WeightedValue));\n+    }\n+\n+    void read(ReadBuffer & buf, UInt32 max_bins)\n+    {\n+        readBinary(lower_bound, buf);\n+        readBinary(upper_bound, buf);\n+\n+        readVarUInt(size, buf);\n+        if (size > max_bins * 2)\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE, \"Too many bins\");\n+        static constexpr size_t max_size = 1_GiB;\n+        if (size > max_size)\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n+                            \"Too large array size in histogram (maximum: {})\", max_size);\n+\n+        buf.readStrict(reinterpret_cast<char *>(points), size * sizeof(WeightedValue));\n+    }\n+};\n+\n+template <typename T>\n+class AggregateFunctionHistogram final: public IAggregateFunctionDataHelper<AggregateFunctionHistogramData, AggregateFunctionHistogram<T>>\n+{\n+private:\n+    using Data = AggregateFunctionHistogramData;\n+\n+    const UInt32 max_bins;\n+\n+public:\n+    AggregateFunctionHistogram(UInt32 max_bins_, const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<AggregateFunctionHistogramData, AggregateFunctionHistogram<T>>(arguments, params, createResultType())\n+        , max_bins(max_bins_)\n+    {\n+    }\n+\n+    size_t sizeOfData() const override\n+    {\n+        return Data::structSize(max_bins);\n+    }\n+    static DataTypePtr createResultType()\n+    {\n+        DataTypes types;\n+        auto mean = std::make_shared<DataTypeNumber<Data::Mean>>();\n+        auto weight = std::make_shared<DataTypeNumber<Data::Weight>>();\n+\n+        // lower bound\n+        types.emplace_back(mean);\n+        // upper bound\n+        types.emplace_back(mean);\n+        // weight\n+        types.emplace_back(weight);\n+\n+        auto tuple = std::make_shared<DataTypeTuple>(types);\n+        return std::make_shared<DataTypeArray>(tuple);\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        auto val = assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num];\n+        this->data(place).add(static_cast<Data::Mean>(val), 1, max_bins);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs), max_bins);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).write(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).read(buf, max_bins);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        auto & data = this->data(place);\n+\n+        auto & to_array = assert_cast<ColumnArray &>(to);\n+        ColumnArray::Offsets & offsets_to = to_array.getOffsets();\n+        auto & to_tuple = assert_cast<ColumnTuple &>(to_array.getData());\n+\n+        auto & to_lower = assert_cast<ColumnVector<Data::Mean> &>(to_tuple.getColumn(0));\n+        auto & to_upper = assert_cast<ColumnVector<Data::Mean> &>(to_tuple.getColumn(1));\n+        auto & to_weights = assert_cast<ColumnVector<Data::Weight> &>(to_tuple.getColumn(2));\n+        data.insertResultInto(to_lower, to_upper, to_weights, max_bins);\n+\n+        offsets_to.push_back(to_tuple.size());\n+    }\n+\n+    String getName() const override { return \"histogram\"; }\n+};\n+\n+\n AggregateFunctionPtr createAggregateFunctionHistogram(const std::string & name, const DataTypes & arguments, const Array & params, const Settings *)\n {\n     if (params.size() != 1)\ndiff --git a/src/AggregateFunctions/AggregateFunctionHistogram.h b/src/AggregateFunctions/AggregateFunctionHistogram.h\ndeleted file mode 100644\nindex 967bc9bb5179..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionHistogram.h\n+++ /dev/null\n@@ -1,382 +0,0 @@\n-#pragma once\n-\n-#include <base/sort.h>\n-\n-#include <Common/NaNUtils.h>\n-\n-#include <Columns/ColumnVector.h>\n-#include <Columns/ColumnTuple.h>\n-#include <Columns/ColumnArray.h>\n-#include <Common/assert_cast.h>\n-\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypeTuple.h>\n-\n-#include <IO/WriteBuffer.h>\n-#include <IO/ReadBuffer.h>\n-#include <IO/WriteHelpers.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/VarInt.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-#include <math.h>\n-#include <queue>\n-#include <stddef.h>\n-\n-namespace DB\n-{\n-struct Settings;\n-class Arena;\n-\n-namespace ErrorCodes\n-{\n-    extern const int TOO_LARGE_ARRAY_SIZE;\n-    extern const int INCORRECT_DATA;\n-}\n-\n-/**\n- * distance compression algorithm implementation\n- * http://jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf\n- */\n-class AggregateFunctionHistogramData\n-{\n-public:\n-    using Mean = Float64;\n-    using Weight = Float64;\n-\n-    constexpr static size_t bins_count_limit = 250;\n-\n-private:\n-    struct WeightedValue\n-    {\n-        Mean mean;\n-        Weight weight;\n-\n-        WeightedValue operator+(const WeightedValue & other) const\n-        {\n-            return {mean + other.weight * (other.mean - mean) / (other.weight + weight), other.weight + weight};\n-        }\n-    };\n-\n-    // quantity of stored weighted-values\n-    UInt32 size;\n-\n-    // calculated lower and upper bounds of seen points\n-    Mean lower_bound;\n-    Mean upper_bound;\n-\n-    // Weighted values representation of histogram.\n-    WeightedValue points[0];\n-\n-    void sort()\n-    {\n-        ::sort(points, points + size,\n-            [](const WeightedValue & first, const WeightedValue & second)\n-            {\n-                return first.mean < second.mean;\n-            });\n-    }\n-\n-    template <typename T>\n-    struct PriorityQueueStorage\n-    {\n-        size_t size = 0;\n-        T * data_ptr;\n-\n-        explicit PriorityQueueStorage(T * value)\n-            : data_ptr(value)\n-        {\n-        }\n-\n-        void push_back(T val) /// NOLINT\n-        {\n-            data_ptr[size] = std::move(val);\n-            ++size;\n-        }\n-\n-        void pop_back() { --size; } /// NOLINT\n-        T * begin() { return data_ptr; }\n-        T * end() const { return data_ptr + size; }\n-        bool empty() const { return size == 0; }\n-        T & front() { return *data_ptr; }\n-        const T & front() const { return *data_ptr; }\n-\n-        using value_type = T;\n-        using reference = T&;\n-        using const_reference = const T&;\n-        using size_type = size_t;\n-    };\n-\n-    /**\n-     * Repeatedly fuse most close values until max_bins bins left\n-     */\n-    void compress(UInt32 max_bins)\n-    {\n-        sort();\n-        auto new_size = size;\n-        if (size <= max_bins)\n-            return;\n-\n-        // Maintain doubly-linked list of \"active\" points\n-        // and store neighbour pairs in priority queue by distance\n-        UInt32 previous[size + 1];\n-        UInt32 next[size + 1];\n-        bool active[size + 1];\n-        std::fill(active, active + size, true);\n-        active[size] = false;\n-\n-        auto delete_node = [&](UInt32 i)\n-        {\n-            previous[next[i]] = previous[i];\n-            next[previous[i]] = next[i];\n-            active[i] = false;\n-        };\n-\n-        for (size_t i = 0; i <= size; ++i)\n-        {\n-            previous[i] = static_cast<UInt32>(i - 1);\n-            next[i] = static_cast<UInt32>(i + 1);\n-        }\n-\n-        next[size] = 0;\n-        previous[0] = size;\n-\n-        using QueueItem = std::pair<Mean, UInt32>;\n-\n-        QueueItem storage[2 * size - max_bins];\n-\n-        std::priority_queue<\n-            QueueItem,\n-            PriorityQueueStorage<QueueItem>,\n-            std::greater<QueueItem>>\n-                queue{std::greater<QueueItem>(),\n-                        PriorityQueueStorage<QueueItem>(storage)};\n-\n-        auto quality = [&](UInt32 i) { return points[next[i]].mean - points[i].mean; };\n-\n-        for (size_t i = 0; i + 1 < size; ++i)\n-            queue.push({quality(static_cast<UInt32>(i)), i});\n-\n-        while (new_size > max_bins && !queue.empty())\n-        {\n-            auto min_item = queue.top();\n-            queue.pop();\n-            auto left = min_item.second;\n-            auto right = next[left];\n-\n-            if (!active[left] || !active[right] || quality(left) > min_item.first)\n-                continue;\n-\n-            points[left] = points[left] + points[right];\n-\n-            delete_node(right);\n-            if (active[next[left]])\n-                queue.push({quality(left), left});\n-            if (active[previous[left]])\n-                queue.push({quality(previous[left]), previous[left]});\n-\n-            --new_size;\n-        }\n-\n-        size_t left = 0;\n-        for (size_t right = 0; right < size; ++right)\n-        {\n-            if (active[right])\n-            {\n-                points[left] = points[right];\n-                ++left;\n-            }\n-        }\n-        size = new_size;\n-    }\n-\n-    /***\n-     * Delete too close points from histogram.\n-     * Assumes that points are sorted.\n-     */\n-    void unique()\n-    {\n-        if (size == 0)\n-            return;\n-\n-        size_t left = 0;\n-\n-        for (auto right = left + 1; right < size; ++right)\n-        {\n-            // Fuse points if their text representations differ only in last digit\n-            auto min_diff = 10 * (points[left].mean + points[right].mean) * std::numeric_limits<Mean>::epsilon();\n-            if (points[left].mean + std::fabs(min_diff) >= points[right].mean)\n-            {\n-                points[left] = points[left] + points[right];\n-            }\n-            else\n-            {\n-                ++left;\n-                points[left] = points[right];\n-            }\n-        }\n-        size = static_cast<UInt32>(left + 1);\n-    }\n-\n-public:\n-    AggregateFunctionHistogramData()\n-        : size(0)\n-        , lower_bound(std::numeric_limits<Mean>::max())\n-        , upper_bound(std::numeric_limits<Mean>::lowest())\n-    {\n-        static_assert(offsetof(AggregateFunctionHistogramData, points) == sizeof(AggregateFunctionHistogramData), \"points should be last member\");\n-    }\n-\n-    static size_t structSize(size_t max_bins)\n-    {\n-        return sizeof(AggregateFunctionHistogramData) + max_bins * 2 * sizeof(WeightedValue);\n-    }\n-\n-    void insertResultInto(ColumnVector<Mean> & to_lower, ColumnVector<Mean> & to_upper, ColumnVector<Weight> & to_weights, UInt32 max_bins)\n-    {\n-        compress(max_bins);\n-        unique();\n-\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            to_lower.insertValue((i == 0) ? lower_bound : (points[i].mean + points[i - 1].mean) / 2);\n-            to_upper.insertValue((i + 1 == size) ? upper_bound : (points[i].mean + points[i + 1].mean) / 2);\n-\n-            // linear density approximation\n-            Weight lower_weight = (i == 0) ? points[i].weight : ((points[i - 1].weight) + points[i].weight * 3) / 4;\n-            Weight upper_weight = (i + 1 == size) ? points[i].weight : (points[i + 1].weight + points[i].weight * 3) / 4;\n-            to_weights.insertValue((lower_weight + upper_weight) / 2);\n-        }\n-    }\n-\n-    void add(Mean value, Weight weight, UInt32 max_bins)\n-    {\n-        // nans break sort and compression\n-        // infs don't fit in bins partition method\n-        if (!isFinite(value))\n-            throw Exception(ErrorCodes::INCORRECT_DATA, \"Invalid value (inf or nan) for aggregation by 'histogram' function\");\n-\n-        points[size] = {value, weight};\n-        ++size;\n-        lower_bound = std::min(lower_bound, value);\n-        upper_bound = std::max(upper_bound, value);\n-\n-        if (size >= max_bins * 2)\n-            compress(max_bins);\n-    }\n-\n-    void merge(const AggregateFunctionHistogramData & other, UInt32 max_bins)\n-    {\n-        lower_bound = std::min(lower_bound, other.lower_bound);\n-        upper_bound = std::max(upper_bound, other.upper_bound);\n-        for (size_t i = 0; i < other.size; ++i)\n-            add(other.points[i].mean, other.points[i].weight, max_bins);\n-    }\n-\n-    void write(WriteBuffer & buf) const\n-    {\n-        writeBinary(lower_bound, buf);\n-        writeBinary(upper_bound, buf);\n-\n-        writeVarUInt(size, buf);\n-        buf.write(reinterpret_cast<const char *>(points), size * sizeof(WeightedValue));\n-    }\n-\n-    void read(ReadBuffer & buf, UInt32 max_bins)\n-    {\n-        readBinary(lower_bound, buf);\n-        readBinary(upper_bound, buf);\n-\n-        readVarUInt(size, buf);\n-        if (size > max_bins * 2)\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE, \"Too many bins\");\n-        static constexpr size_t max_size = 1_GiB;\n-        if (size > max_size)\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n-                            \"Too large array size in histogram (maximum: {})\", max_size);\n-\n-        buf.readStrict(reinterpret_cast<char *>(points), size * sizeof(WeightedValue));\n-    }\n-};\n-\n-template <typename T>\n-class AggregateFunctionHistogram final: public IAggregateFunctionDataHelper<AggregateFunctionHistogramData, AggregateFunctionHistogram<T>>\n-{\n-private:\n-    using Data = AggregateFunctionHistogramData;\n-\n-    const UInt32 max_bins;\n-\n-public:\n-    AggregateFunctionHistogram(UInt32 max_bins_, const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper<AggregateFunctionHistogramData, AggregateFunctionHistogram<T>>(arguments, params, createResultType())\n-        , max_bins(max_bins_)\n-    {\n-    }\n-\n-    size_t sizeOfData() const override\n-    {\n-        return Data::structSize(max_bins);\n-    }\n-    static DataTypePtr createResultType()\n-    {\n-        DataTypes types;\n-        auto mean = std::make_shared<DataTypeNumber<Data::Mean>>();\n-        auto weight = std::make_shared<DataTypeNumber<Data::Weight>>();\n-\n-        // lower bound\n-        types.emplace_back(mean);\n-        // upper bound\n-        types.emplace_back(mean);\n-        // weight\n-        types.emplace_back(weight);\n-\n-        auto tuple = std::make_shared<DataTypeTuple>(types);\n-        return std::make_shared<DataTypeArray>(tuple);\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        auto val = assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num];\n-        this->data(place).add(static_cast<Data::Mean>(val), 1, max_bins);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs), max_bins);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).read(buf, max_bins);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        auto & data = this->data(place);\n-\n-        auto & to_array = assert_cast<ColumnArray &>(to);\n-        ColumnArray::Offsets & offsets_to = to_array.getOffsets();\n-        auto & to_tuple = assert_cast<ColumnTuple &>(to_array.getData());\n-\n-        auto & to_lower = assert_cast<ColumnVector<Data::Mean> &>(to_tuple.getColumn(0));\n-        auto & to_upper = assert_cast<ColumnVector<Data::Mean> &>(to_tuple.getColumn(1));\n-        auto & to_weights = assert_cast<ColumnVector<Data::Weight> &>(to_tuple.getColumn(2));\n-        data.insertResultInto(to_lower, to_upper, to_weights, max_bins);\n-\n-        offsets_to.push_back(to_tuple.size());\n-    }\n-\n-    String getName() const override { return \"histogram\"; }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionIntervalLengthSum.cpp b/src/AggregateFunctions/AggregateFunctionIntervalLengthSum.cpp\nindex 5e01fb73299b..eacd0596757c 100644\n--- a/src/AggregateFunctions/AggregateFunctionIntervalLengthSum.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionIntervalLengthSum.cpp\n@@ -1,57 +1,272 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionIntervalLengthSum.h>\n-#include <AggregateFunctions/FactoryHelpers.h>\n #include <AggregateFunctions/Helpers.h>\n #include <DataTypes/DataTypeDate.h>\n-#include <DataTypes/DataTypeDateTime.h>\n \n-#include <base/range.h>\n+#include <unordered_set>\n+\n+#include <AggregateFunctions/Combinators/AggregateFunctionNull.h>\n+\n+#include <Columns/ColumnsNumber.h>\n+\n+#include <Common/assert_cast.h>\n+#include <DataTypes/DataTypesNumber.h>\n+\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n \n \n namespace DB\n {\n+\n namespace ErrorCodes\n {\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int TOO_LARGE_ARRAY_SIZE;\n }\n \n struct Settings;\n \n namespace\n {\n-    template <template <typename> class Data>\n-    AggregateFunctionPtr\n-    createAggregateFunctionIntervalLengthSum(const std::string & name, const DataTypes & arguments, const Array &, const Settings *)\n+\n+/** Calculate total length of intervals without intersections. Each interval is the pair of numbers [begin, end];\n+  * Returns UInt64 for integral types (UInt/Int*, Date/DateTime) and returns Float64 for Float*.\n+  *\n+  * Implementation simply stores intervals sorted by beginning and sums lengths at final.\n+  */\n+template <typename T>\n+struct AggregateFunctionIntervalLengthSumData\n+{\n+    constexpr static size_t MAX_ARRAY_SIZE = 0xFFFFFF;\n+\n+    using Segment = std::pair<T, T>;\n+    using Segments = PODArrayWithStackMemory<Segment, 64>;\n+\n+    bool sorted = false;\n+\n+    Segments segments;\n+\n+    void add(T begin, T end)\n     {\n-        if (arguments.size() != 2)\n-            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n-                \"Aggregate function {} requires two timestamps argument.\", name);\n+        /// Reversed intervals are counted by absolute value of their length.\n+        if (unlikely(end < begin))\n+            std::swap(begin, end);\n+        else if (unlikely(begin == end))\n+            return;\n \n-        auto args = {arguments[0].get(), arguments[1].get()};\n+        if (sorted && !segments.empty())\n+            sorted = segments.back().first <= begin;\n+        segments.emplace_back(begin, end);\n+    }\n \n-        if (WhichDataType{args.begin()[0]}.idx != WhichDataType{args.begin()[1]}.idx)\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                            \"Illegal types {} and {} of arguments \"\n-                            \"of aggregate function {}, both arguments should have same data type\",\n-                            args.begin()[0]->getName(), args.begin()[1]->getName(), name);\n+    void merge(const AggregateFunctionIntervalLengthSumData & other)\n+    {\n+        if (other.segments.empty())\n+            return;\n+\n+        const auto size = segments.size();\n+\n+        segments.insert(std::begin(other.segments), std::end(other.segments));\n+\n+        /// either sort whole container or do so partially merging ranges afterwards\n+        if (!sorted && !other.sorted)\n+        {\n+            ::sort(std::begin(segments), std::end(segments));\n+        }\n+        else\n+        {\n+            const auto begin = std::begin(segments);\n+            const auto middle = std::next(begin, size);\n+            const auto end = std::end(segments);\n+\n+            if (!sorted)\n+                ::sort(begin, middle);\n+\n+            if (!other.sorted)\n+                ::sort(middle, end);\n+\n+            std::inplace_merge(begin, middle, end);\n+        }\n+\n+        sorted = true;\n+    }\n+\n+    void sort()\n+    {\n+        if (sorted)\n+            return;\n+\n+        ::sort(std::begin(segments), std::end(segments));\n+        sorted = true;\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        writeBinary(sorted, buf);\n+        writeBinary(segments.size(), buf);\n+\n+        for (const auto & time_gap : segments)\n+        {\n+            writeBinary(time_gap.first, buf);\n+            writeBinary(time_gap.second, buf);\n+        }\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        readBinary(sorted, buf);\n+\n+        size_t size;\n+        readBinary(size, buf);\n+\n+        if (unlikely(size > MAX_ARRAY_SIZE))\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE, \"Too large array size (maximum: {})\", MAX_ARRAY_SIZE);\n+\n+        segments.clear();\n+        segments.reserve(size);\n+\n+        Segment segment;\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            readBinary(segment.first, buf);\n+            readBinary(segment.second, buf);\n+            segments.emplace_back(segment);\n+        }\n+    }\n+};\n+\n+template <typename T, typename Data>\n+class AggregateFunctionIntervalLengthSum final : public IAggregateFunctionDataHelper<Data, AggregateFunctionIntervalLengthSum<T, Data>>\n+{\n+private:\n+    static auto NO_SANITIZE_UNDEFINED length(typename Data::Segment segment)\n+    {\n+        return segment.second - segment.first;\n+    }\n+\n+    template <typename TResult>\n+    TResult getIntervalLengthSum(Data & data) const\n+    {\n+        if (data.segments.empty())\n+            return 0;\n+\n+        data.sort();\n+\n+        TResult res = 0;\n+\n+        typename Data::Segment curr_segment = data.segments[0];\n \n-        for (const auto & arg : args)\n+        for (size_t i = 1, size = data.segments.size(); i < size; ++i)\n         {\n-            if (!isNativeNumber(arg) && !isDate(arg) && !isDateTime(arg))\n-                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                                \"Illegal type {} of argument of aggregate function {}, must \"\n-                                \"be native integral type, Date/DateTime or Float\", arg->getName(), name);\n+            const typename Data::Segment & next_segment = data.segments[i];\n+\n+            /// Check if current interval intersects with next one then add length, otherwise advance interval end.\n+            if (curr_segment.second < next_segment.first)\n+            {\n+                res += length(curr_segment);\n+                curr_segment = next_segment;\n+            }\n+            else if (next_segment.second > curr_segment.second)\n+            {\n+                curr_segment.second = next_segment.second;\n+            }\n         }\n+        res += length(curr_segment);\n+\n+        return res;\n+    }\n+\n+public:\n+    String getName() const override { return \"intervalLengthSum\"; }\n+\n+    explicit AggregateFunctionIntervalLengthSum(const DataTypes & arguments)\n+        : IAggregateFunctionDataHelper<Data, AggregateFunctionIntervalLengthSum<T, Data>>(arguments, {}, createResultType())\n+    {\n+    }\n+\n+    static DataTypePtr createResultType()\n+    {\n+        if constexpr (std::is_floating_point_v<T>)\n+            return std::make_shared<DataTypeFloat64>();\n+        return std::make_shared<DataTypeUInt64>();\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    AggregateFunctionPtr getOwnNullAdapter(\n+        const AggregateFunctionPtr & nested_function,\n+        const DataTypes & arguments,\n+        const Array & params,\n+        const AggregateFunctionProperties & /*properties*/) const override\n+    {\n+        return std::make_shared<AggregateFunctionNullVariadic<false, false>>(nested_function, arguments, params);\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, const size_t row_num, Arena *) const override\n+    {\n+        auto begin = assert_cast<const ColumnVector<T> *>(columns[0])->getData()[row_num];\n+        auto end = assert_cast<const ColumnVector<T> *>(columns[1])->getData()[row_num];\n+        this->data(place).add(begin, end);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs));\n+    }\n \n-        AggregateFunctionPtr res(createWithBasicNumberOrDateOrDateTime<AggregateFunctionIntervalLengthSum, Data>(*arguments[0], arguments));\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        if constexpr (std::is_floating_point_v<T>)\n+            assert_cast<ColumnFloat64 &>(to).getData().push_back(getIntervalLengthSum<Float64>(this->data(place)));\n+        else\n+            assert_cast<ColumnUInt64 &>(to).getData().push_back(getIntervalLengthSum<UInt64>(this->data(place)));\n+    }\n+};\n \n-        if (res)\n-            return res;\n \n+template <template <typename> class Data>\n+AggregateFunctionPtr\n+createAggregateFunctionIntervalLengthSum(const std::string & name, const DataTypes & arguments, const Array &, const Settings *)\n+{\n+    if (arguments.size() != 2)\n+        throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n+            \"Aggregate function {} requires two timestamps argument.\", name);\n+\n+    auto args = {arguments[0].get(), arguments[1].get()};\n+\n+    if (WhichDataType{args.begin()[0]}.idx != WhichDataType{args.begin()[1]}.idx)\n         throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                        \"Illegal type {} of argument of aggregate function {}, must \"\n-                        \"be native integral type, Date/DateTime or Float\", arguments.front().get()->getName(), name);\n+                        \"Illegal types {} and {} of arguments \"\n+                        \"of aggregate function {}, both arguments should have same data type\",\n+                        args.begin()[0]->getName(), args.begin()[1]->getName(), name);\n+\n+    for (const auto & arg : args)\n+    {\n+        if (!isNativeNumber(arg) && !isDate(arg) && !isDateTime(arg))\n+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+                            \"Illegal type {} of argument of aggregate function {}, must \"\n+                            \"be native integral type, Date/DateTime or Float\", arg->getName(), name);\n+    }\n+\n+    AggregateFunctionPtr res(createWithBasicNumberOrDateOrDateTime<AggregateFunctionIntervalLengthSum, Data>(*arguments[0], arguments));\n+\n+    if (res)\n+        return res;\n+\n+    throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+                    \"Illegal type {} of argument of aggregate function {}, must \"\n+                    \"be native integral type, Date/DateTime or Float\", arguments.front().get()->getName(), name);\n }\n \n }\ndiff --git a/src/AggregateFunctions/AggregateFunctionIntervalLengthSum.h b/src/AggregateFunctions/AggregateFunctionIntervalLengthSum.h\ndeleted file mode 100644\nindex e16645c7a1e9..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionIntervalLengthSum.h\n+++ /dev/null\n@@ -1,232 +0,0 @@\n-#pragma once\n-\n-#include <unordered_set>\n-\n-#include <AggregateFunctions/Combinators/AggregateFunctionNull.h>\n-\n-#include <Columns/ColumnsNumber.h>\n-\n-#include <Common/assert_cast.h>\n-#include <base/arithmeticOverflow.h>\n-#include <base/sort.h>\n-\n-#include <DataTypes/DataTypeDateTime.h>\n-#include <DataTypes/DataTypesNumber.h>\n-\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-\n-\n-namespace DB\n-{\n-\n-namespace ErrorCodes\n-{\n-    extern const int TOO_LARGE_ARRAY_SIZE;\n-}\n-\n-/** Calculate total length of intervals without intersections. Each interval is the pair of numbers [begin, end];\n-  * Returns UInt64 for integral types (UInt/Int*, Date/DateTime) and returns Float64 for Float*.\n-  *\n-  * Implementation simply stores intervals sorted by beginning and sums lengths at final.\n-  */\n-template <typename T>\n-struct AggregateFunctionIntervalLengthSumData\n-{\n-    constexpr static size_t MAX_ARRAY_SIZE = 0xFFFFFF;\n-\n-    using Segment = std::pair<T, T>;\n-    using Segments = PODArrayWithStackMemory<Segment, 64>;\n-\n-    bool sorted = false;\n-\n-    Segments segments;\n-\n-    void add(T begin, T end)\n-    {\n-        /// Reversed intervals are counted by absolute value of their length.\n-        if (unlikely(end < begin))\n-            std::swap(begin, end);\n-        else if (unlikely(begin == end))\n-            return;\n-\n-        if (sorted && !segments.empty())\n-            sorted = segments.back().first <= begin;\n-        segments.emplace_back(begin, end);\n-    }\n-\n-    void merge(const AggregateFunctionIntervalLengthSumData & other)\n-    {\n-        if (other.segments.empty())\n-            return;\n-\n-        const auto size = segments.size();\n-\n-        segments.insert(std::begin(other.segments), std::end(other.segments));\n-\n-        /// either sort whole container or do so partially merging ranges afterwards\n-        if (!sorted && !other.sorted)\n-        {\n-            ::sort(std::begin(segments), std::end(segments));\n-        }\n-        else\n-        {\n-            const auto begin = std::begin(segments);\n-            const auto middle = std::next(begin, size);\n-            const auto end = std::end(segments);\n-\n-            if (!sorted)\n-                ::sort(begin, middle);\n-\n-            if (!other.sorted)\n-                ::sort(middle, end);\n-\n-            std::inplace_merge(begin, middle, end);\n-        }\n-\n-        sorted = true;\n-    }\n-\n-    void sort()\n-    {\n-        if (sorted)\n-            return;\n-\n-        ::sort(std::begin(segments), std::end(segments));\n-        sorted = true;\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        writeBinary(sorted, buf);\n-        writeBinary(segments.size(), buf);\n-\n-        for (const auto & time_gap : segments)\n-        {\n-            writeBinary(time_gap.first, buf);\n-            writeBinary(time_gap.second, buf);\n-        }\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        readBinary(sorted, buf);\n-\n-        size_t size;\n-        readBinary(size, buf);\n-\n-        if (unlikely(size > MAX_ARRAY_SIZE))\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE, \"Too large array size (maximum: {})\", MAX_ARRAY_SIZE);\n-\n-        segments.clear();\n-        segments.reserve(size);\n-\n-        Segment segment;\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            readBinary(segment.first, buf);\n-            readBinary(segment.second, buf);\n-            segments.emplace_back(segment);\n-        }\n-    }\n-};\n-\n-template <typename T, typename Data>\n-class AggregateFunctionIntervalLengthSum final : public IAggregateFunctionDataHelper<Data, AggregateFunctionIntervalLengthSum<T, Data>>\n-{\n-private:\n-    static auto NO_SANITIZE_UNDEFINED length(typename Data::Segment segment)\n-    {\n-        return segment.second - segment.first;\n-    }\n-\n-    template <typename TResult>\n-    TResult getIntervalLengthSum(Data & data) const\n-    {\n-        if (data.segments.empty())\n-            return 0;\n-\n-        data.sort();\n-\n-        TResult res = 0;\n-\n-        typename Data::Segment curr_segment = data.segments[0];\n-\n-        for (size_t i = 1, size = data.segments.size(); i < size; ++i)\n-        {\n-            const typename Data::Segment & next_segment = data.segments[i];\n-\n-            /// Check if current interval intersects with next one then add length, otherwise advance interval end.\n-            if (curr_segment.second < next_segment.first)\n-            {\n-                res += length(curr_segment);\n-                curr_segment = next_segment;\n-            }\n-            else if (next_segment.second > curr_segment.second)\n-            {\n-                curr_segment.second = next_segment.second;\n-            }\n-        }\n-        res += length(curr_segment);\n-\n-        return res;\n-    }\n-\n-public:\n-    String getName() const override { return \"intervalLengthSum\"; }\n-\n-    explicit AggregateFunctionIntervalLengthSum(const DataTypes & arguments)\n-        : IAggregateFunctionDataHelper<Data, AggregateFunctionIntervalLengthSum<T, Data>>(arguments, {}, createResultType())\n-    {\n-    }\n-\n-    static DataTypePtr createResultType()\n-    {\n-        if constexpr (std::is_floating_point_v<T>)\n-            return std::make_shared<DataTypeFloat64>();\n-        return std::make_shared<DataTypeUInt64>();\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    AggregateFunctionPtr getOwnNullAdapter(\n-        const AggregateFunctionPtr & nested_function,\n-        const DataTypes & arguments,\n-        const Array & params,\n-        const AggregateFunctionProperties & /*properties*/) const override\n-    {\n-        return std::make_shared<AggregateFunctionNullVariadic<false, false>>(nested_function, arguments, params);\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, const size_t row_num, Arena *) const override\n-    {\n-        auto begin = assert_cast<const ColumnVector<T> *>(columns[0])->getData()[row_num];\n-        auto end = assert_cast<const ColumnVector<T> *>(columns[1])->getData()[row_num];\n-        this->data(place).add(begin, end);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).deserialize(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        if constexpr (std::is_floating_point_v<T>)\n-            assert_cast<ColumnFloat64 &>(to).getData().push_back(getIntervalLengthSum<Float64>(this->data(place)));\n-        else\n-            assert_cast<ColumnUInt64 &>(to).getData().push_back(getIntervalLengthSum<UInt64>(this->data(place)));\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionKolmogorovSmirnovTest.cpp b/src/AggregateFunctions/AggregateFunctionKolmogorovSmirnovTest.cpp\nindex 9bd06c3ef4d5..882150325be3 100644\n--- a/src/AggregateFunctions/AggregateFunctionKolmogorovSmirnovTest.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionKolmogorovSmirnovTest.cpp\n@@ -1,19 +1,339 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionKolmogorovSmirnovTest.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/StatCommon.h>\n+#include <Columns/ColumnVector.h>\n+#include <Columns/ColumnTuple.h>\n+#include <Common/Exception.h>\n+#include <Common/assert_cast.h>\n+#include <Common/PODArray_fwd.h>\n+#include <DataTypes/DataTypeNullable.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeTuple.h>\n+#include <IO/ReadHelpers.h>\n+\n \n namespace ErrorCodes\n {\n     extern const int NOT_IMPLEMENTED;\n+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int BAD_ARGUMENTS;\n }\n \n namespace DB\n {\n+\n struct Settings;\n \n namespace\n {\n \n+struct KolmogorovSmirnov : public StatisticalSample<Float64, Float64>\n+{\n+    enum class Alternative\n+    {\n+        TwoSided,\n+        Less,\n+        Greater\n+    };\n+\n+    std::pair<Float64, Float64> getResult(Alternative alternative, String method)\n+    {\n+        ::sort(x.begin(), x.end());\n+        ::sort(y.begin(), y.end());\n+\n+        Float64 max_s = std::numeric_limits<Float64>::min();\n+        Float64 min_s = std::numeric_limits<Float64>::max();\n+        Float64 now_s = 0;\n+        UInt64 pos_x = 0;\n+        UInt64 pos_y = 0;\n+        UInt64 pos_tmp;\n+        UInt64 n1 = x.size();\n+        UInt64 n2 = y.size();\n+\n+        const Float64 n1_d = 1. / n1;\n+        const Float64 n2_d = 1. / n2;\n+        const Float64 tol = 1e-7;\n+\n+        // reference: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test\n+        while (pos_x < x.size() && pos_y < y.size())\n+        {\n+            if (likely(fabs(x[pos_x] - y[pos_y]) >= tol))\n+            {\n+                if (x[pos_x] < y[pos_y])\n+                {\n+                    now_s += n1_d;\n+                    ++pos_x;\n+                }\n+                else\n+                {\n+                    now_s -= n2_d;\n+                    ++pos_y;\n+                }\n+            }\n+            else\n+            {\n+                pos_tmp = pos_x + 1;\n+                while (pos_tmp < x.size() && unlikely(fabs(x[pos_tmp] - x[pos_x]) <= tol))\n+                    pos_tmp++;\n+                now_s += n1_d * (pos_tmp - pos_x);\n+                pos_x = pos_tmp;\n+                pos_tmp = pos_y + 1;\n+                while (pos_tmp < y.size() && unlikely(fabs(y[pos_tmp] - y[pos_y]) <= tol))\n+                    pos_tmp++;\n+                now_s -= n2_d * (pos_tmp - pos_y);\n+                pos_y = pos_tmp;\n+            }\n+            max_s = std::max(max_s, now_s);\n+            min_s = std::min(min_s, now_s);\n+        }\n+        now_s += n1_d * (x.size() - pos_x) - n2_d * (y.size() - pos_y);\n+        min_s = std::min(min_s, now_s);\n+        max_s = std::max(max_s, now_s);\n+\n+        Float64 d = 0;\n+        if (alternative == Alternative::TwoSided)\n+            d = std::max(std::abs(max_s), std::abs(min_s));\n+        else if (alternative == Alternative::Less)\n+            d = -min_s;\n+        else if (alternative == Alternative::Greater)\n+            d = max_s;\n+\n+        UInt64 g = std::__gcd(n1, n2);\n+        UInt64 nx_g = n1 / g;\n+        UInt64 ny_g = n2 / g;\n+\n+        if (method == \"auto\")\n+            method = std::max(n1, n2) <= 10000 ? \"exact\" : \"asymptotic\";\n+        else if (method == \"exact\" && nx_g >= std::numeric_limits<Int32>::max() / ny_g)\n+            method = \"asymptotic\";\n+\n+        Float64 p_value = std::numeric_limits<Float64>::infinity();\n+\n+        if (method == \"exact\")\n+        {\n+            /* reference:\n+             * Gunar Schr\u00f6er and Dietrich Trenkler\n+             * Exact and Randomization Distributions of Kolmogorov-Smirnov, Tests for Two or Three Samples\n+             *\n+             * and\n+             *\n+             * Thomas Viehmann\n+             * Numerically more stable computation of the p-values for the two-sample Kolmogorov-Smirnov test\n+             */\n+            if (n2 > n1)\n+                std::swap(n1, n2);\n+\n+            const Float64 f_n1 = static_cast<Float64>(n1);\n+            const Float64 f_n2 = static_cast<Float64>(n2);\n+            const Float64 k_d = (0.5 + floor(d * f_n2 * f_n1 - tol)) / (f_n2 * f_n1);\n+            PaddedPODArray<Float64> c(n1 + 1);\n+\n+            auto check = alternative == Alternative::TwoSided ?\n+                         [](const Float64 & q, const Float64 & r, const Float64 & s) { return fabs(r - s) >= q; }\n+                       : [](const Float64 & q, const Float64 & r, const Float64 & s) { return r - s >= q; };\n+\n+            c[0] = 0;\n+            for (UInt64 j = 1; j <= n1; j++)\n+                if (check(k_d, 0., j / f_n1))\n+                    c[j] = 1.;\n+                else\n+                    c[j] = c[j - 1];\n+\n+            for (UInt64 i = 1; i <= n2; i++)\n+            {\n+                if (check(k_d, i / f_n2, 0.))\n+                    c[0] = 1.;\n+                for (UInt64 j = 1; j <= n1; j++)\n+                    if (check(k_d, i / f_n2, j / f_n1))\n+                        c[j] = 1.;\n+                    else\n+                    {\n+                        Float64 v = i / static_cast<Float64>(i + j);\n+                        Float64 w = j / static_cast<Float64>(i + j);\n+                        c[j] = v * c[j] + w * c[j - 1];\n+                    }\n+            }\n+            p_value = c[n1];\n+        }\n+        else if (method == \"asymp\" || method == \"asymptotic\")\n+        {\n+            Float64 n = std::min(n1, n2);\n+            Float64 m = std::max(n1, n2);\n+            Float64 p = sqrt((n * m) / (n + m)) * d;\n+\n+            if (alternative == Alternative::TwoSided)\n+            {\n+                /* reference:\n+                 * J.DURBIN\n+                 * Distribution theory for tests based on the sample distribution function\n+                 */\n+                Float64 new_val, old_val, s, w, z;\n+                UInt64 k_max = static_cast<UInt64>(sqrt(2 - log(tol)));\n+\n+                if (p < 1)\n+                {\n+                    z = - (M_PI_2 * M_PI_4) / (p * p);\n+                    w = log(p);\n+                    s = 0;\n+                    for (UInt64 k = 1; k < k_max; k += 2)\n+                        s += exp(k * k * z - w);\n+                    p = s / 0.398942280401432677939946059934;\n+                }\n+                else\n+                {\n+                    z = -2 * p * p;\n+                    s = -1;\n+                    UInt64 k = 1;\n+                    old_val = 0;\n+                    new_val = 1;\n+                    while (fabs(old_val - new_val) > tol)\n+                    {\n+                        old_val = new_val;\n+                        new_val += 2 * s * exp(z * k * k);\n+                        s *= -1;\n+                        k++;\n+                    }\n+                    p = new_val;\n+                }\n+                p_value = 1 - p;\n+            }\n+            else\n+            {\n+                /* reference:\n+                 * J. L. HODGES, Jr\n+                 * The significance probability of the Smirnov two-sample test\n+                 */\n+\n+                // Use Hodges' suggested approximation Eqn 5.3\n+                // Requires m to be the larger of (n1, n2)\n+                Float64 expt = -2 * p * p - 2 * p * (m + 2 * n) / sqrt(m * n * (m + n)) / 3.0;\n+                p_value = exp(expt);\n+            }\n+        }\n+        return {d, p_value};\n+    }\n+\n+};\n+\n+class AggregateFunctionKolmogorovSmirnov final:\n+    public IAggregateFunctionDataHelper<KolmogorovSmirnov, AggregateFunctionKolmogorovSmirnov>\n+{\n+private:\n+    using Alternative = typename KolmogorovSmirnov::Alternative;\n+    Alternative alternative = Alternative::TwoSided;\n+    String method = \"auto\";\n+\n+public:\n+    explicit AggregateFunctionKolmogorovSmirnov(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<KolmogorovSmirnov, AggregateFunctionKolmogorovSmirnov> ({arguments}, {}, createResultType())\n+    {\n+        if (params.size() > 2)\n+            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} require two parameter or less\", getName());\n+\n+        if (params.empty())\n+            return;\n+\n+        if (params[0].getType() != Field::Types::String)\n+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Aggregate function {} require first parameter to be a String\", getName());\n+\n+        const auto & param = params[0].get<String>();\n+        if (param == \"two-sided\")\n+            alternative = Alternative::TwoSided;\n+        else if (param == \"less\")\n+            alternative = Alternative::Less;\n+        else if (param == \"greater\")\n+            alternative = Alternative::Greater;\n+        else\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unknown parameter in aggregate function {}. \"\n+                    \"It must be one of: 'two-sided', 'less', 'greater'\", getName());\n+\n+        if (params.size() != 2)\n+            return;\n+\n+        if (params[1].getType() != Field::Types::String)\n+                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Aggregate function {} require second parameter to be a String\", getName());\n+\n+        method = params[1].get<String>();\n+        if (method != \"auto\" && method != \"exact\" && method != \"asymp\" && method != \"asymptotic\")\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unknown method in aggregate function {}. \"\n+                    \"It must be one of: 'auto', 'exact', 'asymp' (or 'asymptotic')\", getName());\n+    }\n+\n+    String getName() const override\n+    {\n+        return \"kolmogorovSmirnovTest\";\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return true; }\n+\n+    static DataTypePtr createResultType()\n+    {\n+        DataTypes types\n+        {\n+            std::make_shared<DataTypeNumber<Float64>>(),\n+            std::make_shared<DataTypeNumber<Float64>>(),\n+        };\n+\n+        Strings names\n+        {\n+            \"d_statistic\",\n+            \"p_value\"\n+        };\n+\n+        return std::make_shared<DataTypeTuple>(\n+            std::move(types),\n+            std::move(names)\n+        );\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        Float64 value = columns[0]->getFloat64(row_num);\n+        UInt8 is_second = columns[1]->getUInt(row_num);\n+        if (is_second)\n+            this->data(place).addY(value, arena);\n+        else\n+            this->data(place).addX(value, arena);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n+    {\n+        this->data(place).merge(this->data(rhs), arena);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).write(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n+    {\n+        this->data(place).read(buf, arena);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        if (!this->data(place).size_x || !this->data(place).size_y)\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Aggregate function {} require both samples to be non empty\", getName());\n+\n+        auto [d_statistic, p_value] = this->data(place).getResult(alternative, method);\n+\n+        /// Because p-value is a probability.\n+        p_value = std::min(1.0, std::max(0.0, p_value));\n+\n+        auto & column_tuple = assert_cast<ColumnTuple &>(to);\n+        auto & column_stat = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(0));\n+        auto & column_value = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(1));\n+\n+        column_stat.getData().push_back(d_statistic);\n+        column_value.getData().push_back(p_value);\n+    }\n+\n+};\n+\n+\n AggregateFunctionPtr createAggregateFunctionKolmogorovSmirnovTest(\n     const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n {\ndiff --git a/src/AggregateFunctions/AggregateFunctionKolmogorovSmirnovTest.h b/src/AggregateFunctions/AggregateFunctionKolmogorovSmirnovTest.h\ndeleted file mode 100644\nindex 5629de31c88b..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionKolmogorovSmirnovTest.h\n+++ /dev/null\n@@ -1,331 +0,0 @@\n-#pragma once\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/StatCommon.h>\n-#include <Columns/ColumnVector.h>\n-#include <Columns/ColumnTuple.h>\n-#include <Common/Exception.h>\n-#include <Common/assert_cast.h>\n-#include <Common/PODArray_fwd.h>\n-#include <base/types.h>\n-#include <DataTypes/DataTypeNullable.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n-    extern const int BAD_ARGUMENTS;\n-}\n-\n-struct KolmogorovSmirnov : public StatisticalSample<Float64, Float64>\n-{\n-    enum class Alternative\n-    {\n-        TwoSided,\n-        Less,\n-        Greater\n-    };\n-\n-    std::pair<Float64, Float64> getResult(Alternative alternative, String method)\n-    {\n-        ::sort(x.begin(), x.end());\n-        ::sort(y.begin(), y.end());\n-\n-        Float64 max_s = std::numeric_limits<Float64>::min();\n-        Float64 min_s = std::numeric_limits<Float64>::max();\n-        Float64 now_s = 0;\n-        UInt64 pos_x = 0;\n-        UInt64 pos_y = 0;\n-        UInt64 pos_tmp;\n-        UInt64 n1 = x.size();\n-        UInt64 n2 = y.size();\n-\n-        const Float64 n1_d = 1. / n1;\n-        const Float64 n2_d = 1. / n2;\n-        const Float64 tol = 1e-7;\n-\n-        // reference: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test\n-        while (pos_x < x.size() && pos_y < y.size())\n-        {\n-            if (likely(fabs(x[pos_x] - y[pos_y]) >= tol))\n-            {\n-                if (x[pos_x] < y[pos_y])\n-                {\n-                    now_s += n1_d;\n-                    ++pos_x;\n-                }\n-                else\n-                {\n-                    now_s -= n2_d;\n-                    ++pos_y;\n-                }\n-            }\n-            else\n-            {\n-                pos_tmp = pos_x + 1;\n-                while (pos_tmp < x.size() && unlikely(fabs(x[pos_tmp] - x[pos_x]) <= tol))\n-                    pos_tmp++;\n-                now_s += n1_d * (pos_tmp - pos_x);\n-                pos_x = pos_tmp;\n-                pos_tmp = pos_y + 1;\n-                while (pos_tmp < y.size() && unlikely(fabs(y[pos_tmp] - y[pos_y]) <= tol))\n-                    pos_tmp++;\n-                now_s -= n2_d * (pos_tmp - pos_y);\n-                pos_y = pos_tmp;\n-            }\n-            max_s = std::max(max_s, now_s);\n-            min_s = std::min(min_s, now_s);\n-        }\n-        now_s += n1_d * (x.size() - pos_x) - n2_d * (y.size() - pos_y);\n-        min_s = std::min(min_s, now_s);\n-        max_s = std::max(max_s, now_s);\n-\n-        Float64 d = 0;\n-        if (alternative == Alternative::TwoSided)\n-            d = std::max(std::abs(max_s), std::abs(min_s));\n-        else if (alternative == Alternative::Less)\n-            d = -min_s;\n-        else if (alternative == Alternative::Greater)\n-            d = max_s;\n-\n-        UInt64 g = std::__gcd(n1, n2);\n-        UInt64 nx_g = n1 / g;\n-        UInt64 ny_g = n2 / g;\n-\n-        if (method == \"auto\")\n-            method = std::max(n1, n2) <= 10000 ? \"exact\" : \"asymptotic\";\n-        else if (method == \"exact\" && nx_g >= std::numeric_limits<Int32>::max() / ny_g)\n-            method = \"asymptotic\";\n-\n-        Float64 p_value = std::numeric_limits<Float64>::infinity();\n-\n-        if (method == \"exact\")\n-        {\n-            /* reference:\n-             * Gunar Schr\u00f6er and Dietrich Trenkler\n-             * Exact and Randomization Distributions of Kolmogorov-Smirnov, Tests for Two or Three Samples\n-             *\n-             * and\n-             *\n-             * Thomas Viehmann\n-             * Numerically more stable computation of the p-values for the two-sample Kolmogorov-Smirnov test\n-             */\n-            if (n2 > n1)\n-                std::swap(n1, n2);\n-\n-            const Float64 f_n1 = static_cast<Float64>(n1);\n-            const Float64 f_n2 = static_cast<Float64>(n2);\n-            const Float64 k_d = (0.5 + floor(d * f_n2 * f_n1 - tol)) / (f_n2 * f_n1);\n-            PaddedPODArray<Float64> c(n1 + 1);\n-\n-            auto check = alternative == Alternative::TwoSided ?\n-                         [](const Float64 & q, const Float64 & r, const Float64 & s) { return fabs(r - s) >= q; }\n-                       : [](const Float64 & q, const Float64 & r, const Float64 & s) { return r - s >= q; };\n-\n-            c[0] = 0;\n-            for (UInt64 j = 1; j <= n1; j++)\n-                if (check(k_d, 0., j / f_n1))\n-                    c[j] = 1.;\n-                else\n-                    c[j] = c[j - 1];\n-\n-            for (UInt64 i = 1; i <= n2; i++)\n-            {\n-                if (check(k_d, i / f_n2, 0.))\n-                    c[0] = 1.;\n-                for (UInt64 j = 1; j <= n1; j++)\n-                    if (check(k_d, i / f_n2, j / f_n1))\n-                        c[j] = 1.;\n-                    else\n-                    {\n-                        Float64 v = i / static_cast<Float64>(i + j);\n-                        Float64 w = j / static_cast<Float64>(i + j);\n-                        c[j] = v * c[j] + w * c[j - 1];\n-                    }\n-            }\n-            p_value = c[n1];\n-        }\n-        else if (method == \"asymp\" || method == \"asymptotic\")\n-        {\n-            Float64 n = std::min(n1, n2);\n-            Float64 m = std::max(n1, n2);\n-            Float64 p = sqrt((n * m) / (n + m)) * d;\n-\n-            if (alternative == Alternative::TwoSided)\n-            {\n-                /* reference:\n-                 * J.DURBIN\n-                 * Distribution theory for tests based on the sample distribution function\n-                 */\n-                Float64 new_val, old_val, s, w, z;\n-                UInt64 k_max = static_cast<UInt64>(sqrt(2 - log(tol)));\n-\n-                if (p < 1)\n-                {\n-                    z = - (M_PI_2 * M_PI_4) / (p * p);\n-                    w = log(p);\n-                    s = 0;\n-                    for (UInt64 k = 1; k < k_max; k += 2)\n-                        s += exp(k * k * z - w);\n-                    p = s / 0.398942280401432677939946059934;\n-                }\n-                else\n-                {\n-                    z = -2 * p * p;\n-                    s = -1;\n-                    UInt64 k = 1;\n-                    old_val = 0;\n-                    new_val = 1;\n-                    while (fabs(old_val - new_val) > tol)\n-                    {\n-                        old_val = new_val;\n-                        new_val += 2 * s * exp(z * k * k);\n-                        s *= -1;\n-                        k++;\n-                    }\n-                    p = new_val;\n-                }\n-                p_value = 1 - p;\n-            }\n-            else\n-            {\n-                /* reference:\n-                 * J. L. HODGES, Jr\n-                 * The significance probability of the Smirnov two-sample test\n-                 */\n-\n-                // Use Hodges' suggested approximation Eqn 5.3\n-                // Requires m to be the larger of (n1, n2)\n-                Float64 expt = -2 * p * p - 2 * p * (m + 2 * n) / sqrt(m * n * (m + n)) / 3.0;\n-                p_value = exp(expt);\n-            }\n-        }\n-        return {d, p_value};\n-    }\n-\n-};\n-\n-class AggregateFunctionKolmogorovSmirnov final:\n-    public IAggregateFunctionDataHelper<KolmogorovSmirnov, AggregateFunctionKolmogorovSmirnov>\n-{\n-private:\n-    using Alternative = typename KolmogorovSmirnov::Alternative;\n-    Alternative alternative = Alternative::TwoSided;\n-    String method = \"auto\";\n-\n-public:\n-    explicit AggregateFunctionKolmogorovSmirnov(const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper<KolmogorovSmirnov, AggregateFunctionKolmogorovSmirnov> ({arguments}, {}, createResultType())\n-    {\n-        if (params.size() > 2)\n-            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} require two parameter or less\", getName());\n-\n-        if (params.empty())\n-            return;\n-\n-        if (params[0].getType() != Field::Types::String)\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Aggregate function {} require first parameter to be a String\", getName());\n-\n-        const auto & param = params[0].get<String>();\n-        if (param == \"two-sided\")\n-            alternative = Alternative::TwoSided;\n-        else if (param == \"less\")\n-            alternative = Alternative::Less;\n-        else if (param == \"greater\")\n-            alternative = Alternative::Greater;\n-        else\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unknown parameter in aggregate function {}. \"\n-                    \"It must be one of: 'two-sided', 'less', 'greater'\", getName());\n-\n-        if (params.size() != 2)\n-            return;\n-\n-        if (params[1].getType() != Field::Types::String)\n-                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Aggregate function {} require second parameter to be a String\", getName());\n-\n-        method = params[1].get<String>();\n-        if (method != \"auto\" && method != \"exact\" && method != \"asymp\" && method != \"asymptotic\")\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unknown method in aggregate function {}. \"\n-                    \"It must be one of: 'auto', 'exact', 'asymp' (or 'asymptotic')\", getName());\n-    }\n-\n-    String getName() const override\n-    {\n-        return \"kolmogorovSmirnovTest\";\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return true; }\n-\n-    static DataTypePtr createResultType()\n-    {\n-        DataTypes types\n-        {\n-            std::make_shared<DataTypeNumber<Float64>>(),\n-            std::make_shared<DataTypeNumber<Float64>>(),\n-        };\n-\n-        Strings names\n-        {\n-            \"d_statistic\",\n-            \"p_value\"\n-        };\n-\n-        return std::make_shared<DataTypeTuple>(\n-            std::move(types),\n-            std::move(names)\n-        );\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        Float64 value = columns[0]->getFloat64(row_num);\n-        UInt8 is_second = columns[1]->getUInt(row_num);\n-        if (is_second)\n-            this->data(place).addY(value, arena);\n-        else\n-            this->data(place).addX(value, arena);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n-    {\n-        this->data(place).merge(this->data(rhs), arena);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        this->data(place).read(buf, arena);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        if (!this->data(place).size_x || !this->data(place).size_y)\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Aggregate function {} require both samples to be non empty\", getName());\n-\n-        auto [d_statistic, p_value] = this->data(place).getResult(alternative, method);\n-\n-        /// Because p-value is a probability.\n-        p_value = std::min(1.0, std::max(0.0, p_value));\n-\n-        auto & column_tuple = assert_cast<ColumnTuple &>(to);\n-        auto & column_stat = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(0));\n-        auto & column_value = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(1));\n-\n-        column_stat.getData().push_back(d_statistic);\n-        column_value.getData().push_back(p_value);\n-    }\n-\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionLargestTriangleThreeBuckets.cpp b/src/AggregateFunctions/AggregateFunctionLargestTriangleThreeBuckets.cpp\nindex 9052f7a66611..83fc4f80c488 100644\n--- a/src/AggregateFunctions/AggregateFunctionLargestTriangleThreeBuckets.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionLargestTriangleThreeBuckets.cpp\n@@ -1,12 +1,30 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionLargestTriangleThreeBuckets.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n-#include <AggregateFunctions/Helpers.h>\n+\n+#include <numeric>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/StatCommon.h>\n+#include <Columns/ColumnArray.h>\n+#include <Columns/ColumnTuple.h>\n+#include <Columns/ColumnVector.h>\n+#include <Columns/ColumnsDateTime.h>\n+#include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypeNullable.h>\n+#include <DataTypes/DataTypeTuple.h>\n+#include <DataTypes/DataTypesDecimal.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <IO/ReadHelpers.h>\n+#include <Common/PODArray.h>\n+#include <Common/assert_cast.h>\n+\n+#include <boost/math/distributions/normal.hpp>\n \n \n namespace ErrorCodes\n {\n-extern const int NOT_IMPLEMENTED;\n+    extern const int NOT_IMPLEMENTED;\n+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n }\n \n namespace DB\n@@ -16,29 +34,320 @@ struct Settings;\n namespace\n {\n \n-    AggregateFunctionPtr\n-    createAggregateFunctionLargestTriangleThreeBuckets(const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+struct LargestTriangleThreeBucketsData : public StatisticalSample<Float64, Float64>\n+{\n+    void add(const Float64 xval, const Float64 yval, Arena * arena)\n+    {\n+        this->addX(xval, arena);\n+        this->addY(yval, arena);\n+    }\n+\n+    void sort(Arena * arena)\n     {\n-        assertBinary(name, argument_types);\n+        // sort the this->x and this->y in ascending order of this->x using index\n+        std::vector<size_t> index(this->x.size());\n \n+        std::iota(index.begin(), index.end(), 0);\n+        ::sort(index.begin(), index.end(), [&](size_t i1, size_t i2) { return this->x[i1] < this->x[i2]; });\n \n-        if (!(isNumber(argument_types[0]) || isDateOrDate32(argument_types[0]) || isDateTime(argument_types[0])\n-              || isDateTime64(argument_types[0])))\n-            throw Exception(\n-                ErrorCodes::NOT_IMPLEMENTED,\n-                \"Aggregate function {} only supports Date, Date32, DateTime, DateTime64 and Number as the first argument\",\n-                name);\n+        SampleX temp_x{};\n+        SampleY temp_y{};\n+\n+        for (size_t i = 0; i < this->x.size(); ++i)\n+        {\n+            temp_x.push_back(this->x[index[i]], arena);\n+            temp_y.push_back(this->y[index[i]], arena);\n+        }\n+\n+        for (size_t i = 0; i < this->x.size(); ++i)\n+        {\n+            this->x[i] = temp_x[i];\n+            this->y[i] = temp_y[i];\n+        }\n+    }\n+\n+    PODArray<std::pair<Float64, Float64>> getResult(size_t total_buckets, Arena * arena)\n+    {\n+        // Sort the data\n+        this->sort(arena);\n+\n+        PODArray<std::pair<Float64, Float64>> result;\n+\n+        // Handle special cases for small data list\n+        if (this->x.size() <= total_buckets)\n+        {\n+            for (size_t i = 0; i < this->x.size(); ++i)\n+            {\n+                result.emplace_back(std::make_pair(this->x[i], this->y[i]));\n+            }\n+            return result;\n+        }\n+\n+        // Handle special cases for 0 or 1 or 2 buckets\n+        if (total_buckets == 0)\n+            return result;\n+        if (total_buckets == 1)\n+        {\n+            result.emplace_back(std::make_pair(this->x.front(), this->y.front()));\n+            return result;\n+        }\n+        if (total_buckets == 2)\n+        {\n+            result.emplace_back(std::make_pair(this->x.front(), this->y.front()));\n+            result.emplace_back(std::make_pair(this->x.back(), this->y.back()));\n+            return result;\n+        }\n+\n+        // Find the size of each bucket\n+        size_t single_bucket_size = this->x.size() / total_buckets;\n+\n+        // Include the first data point\n+        result.emplace_back(std::make_pair(this->x[0], this->y[0]));\n+\n+        for (size_t i = 1; i < total_buckets - 1; ++i) // Skip the first and last bucket\n+        {\n+            size_t start_index = i * single_bucket_size;\n+            size_t end_index = (i + 1) * single_bucket_size;\n+\n+            // Compute the average point in the next bucket\n+            Float64 avg_x = 0;\n+            Float64 avg_y = 0;\n+            for (size_t j = end_index; j < (i + 2) * single_bucket_size; ++j)\n+            {\n+                avg_x += this->x[j];\n+                avg_y += this->y[j];\n+            }\n+            avg_x /= single_bucket_size;\n+            avg_y /= single_bucket_size;\n+\n+            // Find the point in the current bucket that forms the largest triangle\n+            size_t max_index = start_index;\n+            Float64 max_area = 0.0;\n+            for (size_t j = start_index; j < end_index; ++j)\n+            {\n+                Float64 area = std::abs(\n+                    0.5\n+                    * (result.back().first * this->y[j] + this->x[j] * avg_y + avg_x * result.back().second - result.back().first * avg_y\n+                       - this->x[j] * result.back().second - avg_x * this->y[j]));\n+                if (area > max_area)\n+                {\n+                    max_area = area;\n+                    max_index = j;\n+                }\n+            }\n \n-        if (!(isNumber(argument_types[1]) || isDateOrDate32(argument_types[1]) || isDateTime(argument_types[1])\n-              || isDateTime64(argument_types[1])))\n+            // Include the selected point\n+            result.emplace_back(std::make_pair(this->x[max_index], this->y[max_index]));\n+        }\n+\n+        // Include the last data point\n+        result.emplace_back(std::make_pair(this->x.back(), this->y.back()));\n+\n+        return result;\n+    }\n+};\n+\n+class AggregateFunctionLargestTriangleThreeBuckets final : public IAggregateFunctionDataHelper<LargestTriangleThreeBucketsData, AggregateFunctionLargestTriangleThreeBuckets>\n+{\n+private:\n+    UInt64 total_buckets{0};\n+    TypeIndex x_type;\n+    TypeIndex y_type;\n+\n+public:\n+    explicit AggregateFunctionLargestTriangleThreeBuckets(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<LargestTriangleThreeBucketsData, AggregateFunctionLargestTriangleThreeBuckets>({arguments}, {}, createResultType(arguments))\n+    {\n+        if (params.size() != 1)\n+            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} require one parameter\", getName());\n+\n+        if (params[0].getType() != Field::Types::UInt64)\n             throw Exception(\n-                ErrorCodes::NOT_IMPLEMENTED,\n-                \"Aggregate function {} only supports Date, Date32, DateTime, DateTime64 and Number as the second argument\",\n-                name);\n+                ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Aggregate function {} require first parameter to be a UInt64\", getName());\n \n-        return std::make_shared<AggregateFunctionLargestTriangleThreeBuckets>(argument_types, parameters);\n+        total_buckets = params[0].get<UInt64>();\n+\n+        this->x_type = WhichDataType(arguments[0]).idx;\n+        this->y_type = WhichDataType(arguments[1]).idx;\n     }\n \n+    static constexpr auto name = \"largestTriangleThreeBuckets\";\n+\n+    String getName() const override { return name; }\n+\n+    bool allocatesMemoryInArena() const override { return true; }\n+\n+    static DataTypePtr createResultType(const DataTypes & arguments)\n+    {\n+        TypeIndex x_type = arguments[0]->getTypeId();\n+        TypeIndex y_type = arguments[1]->getTypeId();\n+\n+        UInt32 x_scale = 0;\n+        UInt32 y_scale = 0;\n+\n+        if (const auto * datetime64_type = typeid_cast<const DataTypeDateTime64 *>(arguments[0].get()))\n+        {\n+            x_scale = datetime64_type->getScale();\n+        }\n+\n+        if (const auto * datetime64_type = typeid_cast<const DataTypeDateTime64 *>(arguments[1].get()))\n+        {\n+            y_scale = datetime64_type->getScale();\n+        }\n+\n+        DataTypes types = {getDataTypeFromTypeIndex(x_type, x_scale), getDataTypeFromTypeIndex(y_type, y_scale)};\n+\n+        auto tuple = std::make_shared<DataTypeTuple>(std::move(types));\n+\n+        return std::make_shared<DataTypeArray>(tuple);\n+    }\n+\n+    static DataTypePtr getDataTypeFromTypeIndex(TypeIndex type_index, UInt32 scale)\n+    {\n+        DataTypePtr data_type;\n+        switch (type_index)\n+        {\n+            case TypeIndex::Date:\n+                data_type = std::make_shared<DataTypeDate>();\n+                break;\n+            case TypeIndex::Date32:\n+                data_type = std::make_shared<DataTypeDate32>();\n+                break;\n+            case TypeIndex::DateTime:\n+                data_type = std::make_shared<DataTypeDateTime>();\n+                break;\n+            case TypeIndex::DateTime64:\n+                data_type = std::make_shared<DataTypeDateTime64>(scale);\n+                break;\n+            default:\n+                data_type = std::make_shared<DataTypeNumber<Float64>>();\n+        }\n+        return data_type;\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        Float64 x = getFloat64DataFromColumn(columns[0], row_num, this->x_type);\n+        Float64 y = getFloat64DataFromColumn(columns[1], row_num, this->y_type);\n+        this->data(place).add(x, y, arena);\n+    }\n+\n+    Float64 getFloat64DataFromColumn(const IColumn * column, size_t row_num, TypeIndex type_index) const\n+    {\n+        switch (type_index)\n+        {\n+            case TypeIndex::Date:\n+                return static_cast<const ColumnDate &>(*column).getData()[row_num];\n+            case TypeIndex::Date32:\n+                return static_cast<const ColumnDate32 &>(*column).getData()[row_num];\n+            case TypeIndex::DateTime:\n+                return static_cast<const ColumnDateTime &>(*column).getData()[row_num];\n+            case TypeIndex::DateTime64:\n+                return static_cast<const ColumnDateTime64 &>(*column).getData()[row_num];\n+            default:\n+                return column->getFloat64(row_num);\n+        }\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n+    {\n+        auto & a = this->data(place);\n+        const auto & b = this->data(rhs);\n+\n+        a.merge(b, arena);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).write(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n+    {\n+        this->data(place).read(buf, arena);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena * arena) const override\n+    {\n+        auto res = this->data(place).getResult(total_buckets, arena);\n+\n+        auto & col = assert_cast<ColumnArray &>(to);\n+        auto & col_offsets = assert_cast<ColumnArray::ColumnOffsets &>(col.getOffsetsColumn());\n+\n+        auto column_x_adder_func = getColumnAdderFunc(x_type);\n+        auto column_y_adder_func = getColumnAdderFunc(y_type);\n+\n+        for (const auto & elem : res)\n+        {\n+            auto & column_tuple = assert_cast<ColumnTuple &>(col.getData());\n+            column_x_adder_func(column_tuple.getColumn(0), elem.first);\n+            column_y_adder_func(column_tuple.getColumn(1), elem.second);\n+        }\n+\n+        col_offsets.getData().push_back(col.getData().size());\n+    }\n+\n+    std::function<void(IColumn &, Float64)> getColumnAdderFunc(TypeIndex type_index) const\n+    {\n+        switch (type_index)\n+        {\n+            case TypeIndex::Date:\n+                return [](IColumn & column, Float64 value)\n+                {\n+                    auto & col = assert_cast<ColumnDate &>(column);\n+                    col.getData().push_back(static_cast<UInt16>(value));\n+                };\n+            case TypeIndex::Date32:\n+                return [](IColumn & column, Float64 value)\n+                {\n+                    auto & col = assert_cast<ColumnDate32 &>(column);\n+                    col.getData().push_back(static_cast<UInt32>(value));\n+                };\n+            case TypeIndex::DateTime:\n+                return [](IColumn & column, Float64 value)\n+                {\n+                    auto & col = assert_cast<ColumnDateTime &>(column);\n+                    col.getData().push_back(static_cast<UInt32>(value));\n+                };\n+            case TypeIndex::DateTime64:\n+                return [](IColumn & column, Float64 value)\n+                {\n+                    auto & col = assert_cast<ColumnDateTime64 &>(column);\n+                    col.getData().push_back(static_cast<UInt64>(value));\n+                };\n+            default:\n+                return [](IColumn & column, Float64 value)\n+                {\n+                    auto & col = assert_cast<ColumnFloat64 &>(column);\n+                    col.getData().push_back(value);\n+                };\n+        }\n+    }\n+};\n+\n+\n+AggregateFunctionPtr\n+createAggregateFunctionLargestTriangleThreeBuckets(const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+{\n+    assertBinary(name, argument_types);\n+\n+    if (!(isNumber(argument_types[0]) || isDateOrDate32(argument_types[0]) || isDateTime(argument_types[0])\n+          || isDateTime64(argument_types[0])))\n+        throw Exception(\n+            ErrorCodes::NOT_IMPLEMENTED,\n+            \"Aggregate function {} only supports Date, Date32, DateTime, DateTime64 and Number as the first argument\",\n+            name);\n+\n+    if (!(isNumber(argument_types[1]) || isDateOrDate32(argument_types[1]) || isDateTime(argument_types[1])\n+          || isDateTime64(argument_types[1])))\n+        throw Exception(\n+            ErrorCodes::NOT_IMPLEMENTED,\n+            \"Aggregate function {} only supports Date, Date32, DateTime, DateTime64 and Number as the second argument\",\n+            name);\n+\n+    return std::make_shared<AggregateFunctionLargestTriangleThreeBuckets>(argument_types, parameters);\n+}\n+\n }\n \n \ndiff --git a/src/AggregateFunctions/AggregateFunctionLargestTriangleThreeBuckets.h b/src/AggregateFunctions/AggregateFunctionLargestTriangleThreeBuckets.h\ndeleted file mode 100644\nindex 0f2e888e9672..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionLargestTriangleThreeBuckets.h\n+++ /dev/null\n@@ -1,327 +0,0 @@\n-#pragma once\n-\n-#include <iostream>\n-#include <limits>\n-#include <numeric>\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/StatCommon.h>\n-#include <Columns/ColumnArray.h>\n-#include <Columns/ColumnTuple.h>\n-#include <Columns/ColumnVector.h>\n-#include <Columns/ColumnsDateTime.h>\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypeNullable.h>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <DataTypes/DataTypesDecimal.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <base/types.h>\n-#include <Common/PODArray_fwd.h>\n-#include <Common/assert_cast.h>\n-\n-#include <boost/math/distributions/normal.hpp>\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n-}\n-\n-\n-struct LargestTriangleThreeBucketsData : public StatisticalSample<Float64, Float64>\n-{\n-    void add(const Float64 xval, const Float64 yval, Arena * arena)\n-    {\n-        this->addX(xval, arena);\n-        this->addY(yval, arena);\n-    }\n-\n-    void sort(Arena * arena)\n-    {\n-        // sort the this->x and this->y in ascending order of this->x using index\n-        std::vector<size_t> index(this->x.size());\n-\n-        std::iota(index.begin(), index.end(), 0);\n-        ::sort(index.begin(), index.end(), [&](size_t i1, size_t i2) { return this->x[i1] < this->x[i2]; });\n-\n-        SampleX temp_x{};\n-        SampleY temp_y{};\n-\n-        for (size_t i = 0; i < this->x.size(); ++i)\n-        {\n-            temp_x.push_back(this->x[index[i]], arena);\n-            temp_y.push_back(this->y[index[i]], arena);\n-        }\n-\n-        for (size_t i = 0; i < this->x.size(); ++i)\n-        {\n-            this->x[i] = temp_x[i];\n-            this->y[i] = temp_y[i];\n-        }\n-    }\n-\n-    PODArray<std::pair<Float64, Float64>> getResult(size_t total_buckets, Arena * arena)\n-    {\n-        // Sort the data\n-        this->sort(arena);\n-\n-        PODArray<std::pair<Float64, Float64>> result;\n-\n-        // Handle special cases for small data list\n-        if (this->x.size() <= total_buckets)\n-        {\n-            for (size_t i = 0; i < this->x.size(); ++i)\n-            {\n-                result.emplace_back(std::make_pair(this->x[i], this->y[i]));\n-            }\n-            return result;\n-        }\n-\n-        // Handle special cases for 0 or 1 or 2 buckets\n-        if (total_buckets == 0)\n-            return result;\n-        if (total_buckets == 1)\n-        {\n-            result.emplace_back(std::make_pair(this->x.front(), this->y.front()));\n-            return result;\n-        }\n-        if (total_buckets == 2)\n-        {\n-            result.emplace_back(std::make_pair(this->x.front(), this->y.front()));\n-            result.emplace_back(std::make_pair(this->x.back(), this->y.back()));\n-            return result;\n-        }\n-\n-        // Find the size of each bucket\n-        size_t single_bucket_size = this->x.size() / total_buckets;\n-\n-        // Include the first data point\n-        result.emplace_back(std::make_pair(this->x[0], this->y[0]));\n-\n-        for (size_t i = 1; i < total_buckets - 1; ++i) // Skip the first and last bucket\n-        {\n-            size_t start_index = i * single_bucket_size;\n-            size_t end_index = (i + 1) * single_bucket_size;\n-\n-            // Compute the average point in the next bucket\n-            Float64 avg_x = 0;\n-            Float64 avg_y = 0;\n-            for (size_t j = end_index; j < (i + 2) * single_bucket_size; ++j)\n-            {\n-                avg_x += this->x[j];\n-                avg_y += this->y[j];\n-            }\n-            avg_x /= single_bucket_size;\n-            avg_y /= single_bucket_size;\n-\n-            // Find the point in the current bucket that forms the largest triangle\n-            size_t max_index = start_index;\n-            Float64 max_area = 0.0;\n-            for (size_t j = start_index; j < end_index; ++j)\n-            {\n-                Float64 area = std::abs(\n-                    0.5\n-                    * (result.back().first * this->y[j] + this->x[j] * avg_y + avg_x * result.back().second - result.back().first * avg_y\n-                       - this->x[j] * result.back().second - avg_x * this->y[j]));\n-                if (area > max_area)\n-                {\n-                    max_area = area;\n-                    max_index = j;\n-                }\n-            }\n-\n-            // Include the selected point\n-            result.emplace_back(std::make_pair(this->x[max_index], this->y[max_index]));\n-        }\n-\n-        // Include the last data point\n-        result.emplace_back(std::make_pair(this->x.back(), this->y.back()));\n-\n-        return result;\n-    }\n-};\n-\n-class AggregateFunctionLargestTriangleThreeBuckets final : public IAggregateFunctionDataHelper<LargestTriangleThreeBucketsData, AggregateFunctionLargestTriangleThreeBuckets>\n-{\n-private:\n-    UInt64 total_buckets{0};\n-    TypeIndex x_type;\n-    TypeIndex y_type;\n-\n-public:\n-    explicit AggregateFunctionLargestTriangleThreeBuckets(const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper<LargestTriangleThreeBucketsData, AggregateFunctionLargestTriangleThreeBuckets>({arguments}, {}, createResultType(arguments))\n-    {\n-        if (params.size() != 1)\n-            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} require one parameter\", getName());\n-\n-        if (params[0].getType() != Field::Types::UInt64)\n-            throw Exception(\n-                ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Aggregate function {} require first parameter to be a UInt64\", getName());\n-\n-        total_buckets = params[0].get<UInt64>();\n-\n-        this->x_type = WhichDataType(arguments[0]).idx;\n-        this->y_type = WhichDataType(arguments[1]).idx;\n-    }\n-\n-    static constexpr auto name = \"largestTriangleThreeBuckets\";\n-\n-    String getName() const override { return name; }\n-\n-    bool allocatesMemoryInArena() const override { return true; }\n-\n-    static DataTypePtr createResultType(const DataTypes & arguments)\n-    {\n-        TypeIndex x_type = arguments[0]->getTypeId();\n-        TypeIndex y_type = arguments[1]->getTypeId();\n-\n-        UInt32 x_scale = 0;\n-        UInt32 y_scale = 0;\n-\n-        if (const auto * datetime64_type = typeid_cast<const DataTypeDateTime64 *>(arguments[0].get()))\n-        {\n-            x_scale = datetime64_type->getScale();\n-        }\n-\n-        if (const auto * datetime64_type = typeid_cast<const DataTypeDateTime64 *>(arguments[1].get()))\n-        {\n-            y_scale = datetime64_type->getScale();\n-        }\n-\n-        DataTypes types = {getDataTypeFromTypeIndex(x_type, x_scale), getDataTypeFromTypeIndex(y_type, y_scale)};\n-\n-        auto tuple = std::make_shared<DataTypeTuple>(std::move(types));\n-\n-        return std::make_shared<DataTypeArray>(tuple);\n-    }\n-\n-    static DataTypePtr getDataTypeFromTypeIndex(TypeIndex type_index, UInt32 scale)\n-    {\n-        DataTypePtr data_type;\n-        switch (type_index)\n-        {\n-            case TypeIndex::Date:\n-                data_type = std::make_shared<DataTypeDate>();\n-                break;\n-            case TypeIndex::Date32:\n-                data_type = std::make_shared<DataTypeDate32>();\n-                break;\n-            case TypeIndex::DateTime:\n-                data_type = std::make_shared<DataTypeDateTime>();\n-                break;\n-            case TypeIndex::DateTime64:\n-                data_type = std::make_shared<DataTypeDateTime64>(scale);\n-                break;\n-            default:\n-                data_type = std::make_shared<DataTypeNumber<Float64>>();\n-        }\n-        return data_type;\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        Float64 x = getFloat64DataFromColumn(columns[0], row_num, this->x_type);\n-        Float64 y = getFloat64DataFromColumn(columns[1], row_num, this->y_type);\n-        this->data(place).add(x, y, arena);\n-    }\n-\n-    Float64 getFloat64DataFromColumn(const IColumn * column, size_t row_num, TypeIndex type_index) const\n-    {\n-        switch (type_index)\n-        {\n-            case TypeIndex::Date:\n-                return static_cast<const ColumnDate &>(*column).getData()[row_num];\n-            case TypeIndex::Date32:\n-                return static_cast<const ColumnDate32 &>(*column).getData()[row_num];\n-            case TypeIndex::DateTime:\n-                return static_cast<const ColumnDateTime &>(*column).getData()[row_num];\n-            case TypeIndex::DateTime64:\n-                return static_cast<const ColumnDateTime64 &>(*column).getData()[row_num];\n-            default:\n-                return column->getFloat64(row_num);\n-        }\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n-    {\n-        auto & a = this->data(place);\n-        const auto & b = this->data(rhs);\n-\n-        a.merge(b, arena);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        this->data(place).read(buf, arena);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena * arena) const override\n-    {\n-        auto res = this->data(place).getResult(total_buckets, arena);\n-\n-        auto & col = assert_cast<ColumnArray &>(to);\n-        auto & col_offsets = assert_cast<ColumnArray::ColumnOffsets &>(col.getOffsetsColumn());\n-\n-        auto column_x_adder_func = getColumnAdderFunc(x_type);\n-        auto column_y_adder_func = getColumnAdderFunc(y_type);\n-\n-        for (size_t i = 0; i < res.size(); ++i)\n-        {\n-            auto & column_tuple = assert_cast<ColumnTuple &>(col.getData());\n-            column_x_adder_func(column_tuple.getColumn(0), res[i].first);\n-            column_y_adder_func(column_tuple.getColumn(1), res[i].second);\n-        }\n-\n-        col_offsets.getData().push_back(col.getData().size());\n-    }\n-\n-    std::function<void(IColumn &, Float64)> getColumnAdderFunc(TypeIndex type_index) const\n-    {\n-        switch (type_index)\n-        {\n-            case TypeIndex::Date:\n-                return [](IColumn & column, Float64 value)\n-                {\n-                    auto & col = assert_cast<ColumnDate &>(column);\n-                    col.getData().push_back(static_cast<UInt16>(value));\n-                };\n-            case TypeIndex::Date32:\n-                return [](IColumn & column, Float64 value)\n-                {\n-                    auto & col = assert_cast<ColumnDate32 &>(column);\n-                    col.getData().push_back(static_cast<UInt32>(value));\n-                };\n-            case TypeIndex::DateTime:\n-                return [](IColumn & column, Float64 value)\n-                {\n-                    auto & col = assert_cast<ColumnDateTime &>(column);\n-                    col.getData().push_back(static_cast<UInt32>(value));\n-                };\n-            case TypeIndex::DateTime64:\n-                return [](IColumn & column, Float64 value)\n-                {\n-                    auto & col = assert_cast<ColumnDateTime64 &>(column);\n-                    col.getData().push_back(static_cast<UInt64>(value));\n-                };\n-            default:\n-                return [](IColumn & column, Float64 value)\n-                {\n-                    auto & col = assert_cast<ColumnFloat64 &>(column);\n-                    col.getData().push_back(value);\n-                };\n-        }\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionMannWhitney.cpp b/src/AggregateFunctions/AggregateFunctionMannWhitney.cpp\nindex daf0f5e9c5a6..a70da7b35d57 100644\n--- a/src/AggregateFunctions/AggregateFunctionMannWhitney.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionMannWhitney.cpp\n@@ -1,21 +1,254 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionMannWhitney.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n-#include <AggregateFunctions/Helpers.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/StatCommon.h>\n+#include <Columns/ColumnVector.h>\n+#include <Columns/ColumnTuple.h>\n+#include <Common/assert_cast.h>\n+#include <Common/PODArray.h>\n+#include <DataTypes/DataTypesDecimal.h>\n+#include <DataTypes/DataTypeNullable.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeTuple.h>\n+#include <IO/ReadHelpers.h>\n+#include <limits>\n+\n+#include <boost/math/distributions/normal.hpp>\n \n \n namespace ErrorCodes\n {\n-extern const int NOT_IMPLEMENTED;\n+    extern const int NOT_IMPLEMENTED;\n+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int BAD_ARGUMENTS;\n }\n \n namespace DB\n {\n+\n struct Settings;\n \n namespace\n {\n \n+struct MannWhitneyData : public StatisticalSample<Float64, Float64>\n+{\n+    /*Since null hypothesis is \"for randomly selected values X and Y from two populations,\n+     *the probability of X being greater than Y is equal to the probability of Y being greater than X\".\n+     *Or \"the distribution F of first sample equals to the distribution G of second sample\".\n+     *Then alternative for this hypothesis (H1) is \"two-sided\"(F != G), \"less\"(F < G), \"greater\" (F > G). */\n+    enum class Alternative\n+    {\n+        TwoSided,\n+        Less,\n+        Greater\n+    };\n+\n+    /// The behaviour equals to the similar function from scipy.\n+    /// https://github.com/scipy/scipy/blob/ab9e9f17e0b7b2d618c4d4d8402cd4c0c200d6c0/scipy/stats/stats.py#L6978\n+    std::pair<Float64, Float64> getResult(Alternative alternative, bool continuity_correction)\n+    {\n+        ConcatenatedSamples both(this->x, this->y);\n+        RanksArray ranks;\n+        Float64 tie_correction;\n+\n+        /// Compute ranks according to both samples.\n+        std::tie(ranks, tie_correction) = computeRanksAndTieCorrection(both);\n+\n+        const Float64 n1 = this->size_x;\n+        const Float64 n2 = this->size_y;\n+\n+        Float64 r1 = 0;\n+        for (size_t i = 0; i < n1; ++i)\n+            r1 += ranks[i];\n+\n+        const Float64 u1 = n1 * n2 + (n1 * (n1 + 1.)) / 2. - r1;\n+        const Float64 u2 = n1 * n2 - u1;\n+\n+        /// The distribution of U-statistic under null hypothesis H0  is symmetric with respect to meanrank.\n+        const Float64 meanrank = n1 * n2 /2. + 0.5 * continuity_correction;\n+        const Float64 sd = std::sqrt(tie_correction * n1 * n2 * (n1 + n2 + 1) / 12.0);\n+\n+        Float64 u = 0;\n+        if (alternative == Alternative::TwoSided)\n+            /// There is no difference which u_i to take as u, because z will be differ only in sign and we take std::abs() from it.\n+            u = std::max(u1, u2);\n+        else if (alternative == Alternative::Less)\n+            u = u1;\n+        else if (alternative == Alternative::Greater)\n+            u = u2;\n+\n+        Float64 z = (u - meanrank) / sd;\n+\n+        if (unlikely(!std::isfinite(z)))\n+            return {std::numeric_limits<Float64>::quiet_NaN(), std::numeric_limits<Float64>::quiet_NaN()};\n+\n+        if (alternative == Alternative::TwoSided)\n+            z = std::abs(z);\n+\n+        auto standard_normal_distribution = boost::math::normal_distribution<Float64>();\n+        auto cdf = boost::math::cdf(standard_normal_distribution, z);\n+\n+        Float64 p_value = 0;\n+        if (alternative == Alternative::TwoSided)\n+            p_value = 2 - 2 * cdf;\n+        else\n+            p_value = 1 - cdf;\n+\n+        return {u2, p_value};\n+    }\n+\n+private:\n+    using Sample = typename StatisticalSample<Float64, Float64>::SampleX;\n+\n+    /// We need to compute ranks according to all samples. Use this class to avoid extra copy and memory allocation.\n+    class ConcatenatedSamples\n+    {\n+        public:\n+            ConcatenatedSamples(const Sample & first_, const Sample & second_)\n+                : first(first_), second(second_) {}\n+\n+            const Float64 & operator[](size_t ind) const\n+            {\n+                if (ind < first.size())\n+                    return first[ind];\n+                return second[ind % first.size()];\n+            }\n+\n+            size_t size() const\n+            {\n+                return first.size() + second.size();\n+            }\n+\n+        private:\n+            const Sample & first;\n+            const Sample & second;\n+    };\n+};\n+\n+class AggregateFunctionMannWhitney final:\n+    public IAggregateFunctionDataHelper<MannWhitneyData, AggregateFunctionMannWhitney>\n+{\n+private:\n+    using Alternative = typename MannWhitneyData::Alternative;\n+    Alternative alternative;\n+    bool continuity_correction{true};\n+\n+public:\n+    explicit AggregateFunctionMannWhitney(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<MannWhitneyData, AggregateFunctionMannWhitney> ({arguments}, {}, createResultType())\n+    {\n+        if (params.size() > 2)\n+            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} require two parameter or less\", getName());\n+\n+        if (params.empty())\n+        {\n+            alternative = Alternative::TwoSided;\n+            return;\n+        }\n+\n+        if (params[0].getType() != Field::Types::String)\n+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Aggregate function {} require first parameter to be a String\", getName());\n+\n+        const auto & param = params[0].get<String>();\n+        if (param == \"two-sided\")\n+            alternative = Alternative::TwoSided;\n+        else if (param == \"less\")\n+            alternative = Alternative::Less;\n+        else if (param == \"greater\")\n+            alternative = Alternative::Greater;\n+        else\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unknown parameter in aggregate function {}. \"\n+                    \"It must be one of: 'two-sided', 'less', 'greater'\", getName());\n+\n+        if (params.size() != 2)\n+            return;\n+\n+        if (params[1].getType() != Field::Types::UInt64)\n+                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Aggregate function {} require second parameter to be a UInt64\", getName());\n+\n+        continuity_correction = static_cast<bool>(params[1].get<UInt64>());\n+    }\n+\n+    String getName() const override\n+    {\n+        return \"mannWhitneyUTest\";\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return true; }\n+\n+    static DataTypePtr createResultType()\n+    {\n+        DataTypes types\n+        {\n+            std::make_shared<DataTypeNumber<Float64>>(),\n+            std::make_shared<DataTypeNumber<Float64>>(),\n+        };\n+\n+        Strings names\n+        {\n+            \"u_statistic\",\n+            \"p_value\"\n+        };\n+\n+        return std::make_shared<DataTypeTuple>(\n+            std::move(types),\n+            std::move(names)\n+        );\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        Float64 value = columns[0]->getFloat64(row_num);\n+        UInt8 is_second = columns[1]->getUInt(row_num);\n+\n+        if (is_second)\n+            this->data(place).addY(value, arena);\n+        else\n+            this->data(place).addX(value, arena);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n+    {\n+        auto & a = this->data(place);\n+        const auto & b = this->data(rhs);\n+\n+        a.merge(b, arena);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).write(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n+    {\n+        this->data(place).read(buf, arena);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        if (!this->data(place).size_x || !this->data(place).size_y)\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Aggregate function {} require both samples to be non empty\", getName());\n+\n+        auto [u_statistic, p_value] = this->data(place).getResult(alternative, continuity_correction);\n+\n+        /// Because p-value is a probability.\n+        p_value = std::min(1.0, std::max(0.0, p_value));\n+\n+        auto & column_tuple = assert_cast<ColumnTuple &>(to);\n+        auto & column_stat = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(0));\n+        auto & column_value = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(1));\n+\n+        column_stat.getData().push_back(u_statistic);\n+        column_value.getData().push_back(p_value);\n+    }\n+\n+};\n+\n+\n AggregateFunctionPtr createAggregateFunctionMannWhitneyUTest(\n     const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n {\ndiff --git a/src/AggregateFunctions/AggregateFunctionMannWhitney.h b/src/AggregateFunctions/AggregateFunctionMannWhitney.h\ndeleted file mode 100644\nindex ac6ce0d0ca92..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionMannWhitney.h\n+++ /dev/null\n@@ -1,249 +0,0 @@\n-#pragma once\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/StatCommon.h>\n-#include <Columns/ColumnArray.h>\n-#include <Columns/ColumnVector.h>\n-#include <Columns/ColumnTuple.h>\n-#include <Common/assert_cast.h>\n-#include <Common/PODArray_fwd.h>\n-#include <base/types.h>\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypesDecimal.h>\n-#include <DataTypes/DataTypeNullable.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <limits>\n-\n-#include <boost/math/distributions/normal.hpp>\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n-    extern const int BAD_ARGUMENTS;\n-}\n-\n-\n-struct MannWhitneyData : public StatisticalSample<Float64, Float64>\n-{\n-    /*Since null hypothesis is \"for randomly selected values X and Y from two populations,\n-     *the probability of X being greater than Y is equal to the probability of Y being greater than X\".\n-     *Or \"the distribution F of first sample equals to the distribution G of second sample\".\n-     *Then alternative for this hypothesis (H1) is \"two-sided\"(F != G), \"less\"(F < G), \"greater\" (F > G). */\n-    enum class Alternative\n-    {\n-        TwoSided,\n-        Less,\n-        Greater\n-    };\n-\n-    /// The behaviour equals to the similar function from scipy.\n-    /// https://github.com/scipy/scipy/blob/ab9e9f17e0b7b2d618c4d4d8402cd4c0c200d6c0/scipy/stats/stats.py#L6978\n-    std::pair<Float64, Float64> getResult(Alternative alternative, bool continuity_correction)\n-    {\n-        ConcatenatedSamples both(this->x, this->y);\n-        RanksArray ranks;\n-        Float64 tie_correction;\n-\n-        /// Compute ranks according to both samples.\n-        std::tie(ranks, tie_correction) = computeRanksAndTieCorrection(both);\n-\n-        const Float64 n1 = this->size_x;\n-        const Float64 n2 = this->size_y;\n-\n-        Float64 r1 = 0;\n-        for (size_t i = 0; i < n1; ++i)\n-            r1 += ranks[i];\n-\n-        const Float64 u1 = n1 * n2 + (n1 * (n1 + 1.)) / 2. - r1;\n-        const Float64 u2 = n1 * n2 - u1;\n-\n-        /// The distribution of U-statistic under null hypothesis H0  is symmetric with respect to meanrank.\n-        const Float64 meanrank = n1 * n2 /2. + 0.5 * continuity_correction;\n-        const Float64 sd = std::sqrt(tie_correction * n1 * n2 * (n1 + n2 + 1) / 12.0);\n-\n-        Float64 u = 0;\n-        if (alternative == Alternative::TwoSided)\n-            /// There is no difference which u_i to take as u, because z will be differ only in sign and we take std::abs() from it.\n-            u = std::max(u1, u2);\n-        else if (alternative == Alternative::Less)\n-            u = u1;\n-        else if (alternative == Alternative::Greater)\n-            u = u2;\n-\n-        Float64 z = (u - meanrank) / sd;\n-\n-        if (unlikely(!std::isfinite(z)))\n-            return {std::numeric_limits<Float64>::quiet_NaN(), std::numeric_limits<Float64>::quiet_NaN()};\n-\n-        if (alternative == Alternative::TwoSided)\n-            z = std::abs(z);\n-\n-        auto standard_normal_distribution = boost::math::normal_distribution<Float64>();\n-        auto cdf = boost::math::cdf(standard_normal_distribution, z);\n-\n-        Float64 p_value = 0;\n-        if (alternative == Alternative::TwoSided)\n-            p_value = 2 - 2 * cdf;\n-        else\n-            p_value = 1 - cdf;\n-\n-        return {u2, p_value};\n-    }\n-\n-private:\n-    using Sample = typename StatisticalSample<Float64, Float64>::SampleX;\n-\n-    /// We need to compute ranks according to all samples. Use this class to avoid extra copy and memory allocation.\n-    class ConcatenatedSamples\n-    {\n-        public:\n-            ConcatenatedSamples(const Sample & first_, const Sample & second_)\n-                : first(first_), second(second_) {}\n-\n-            const Float64 & operator[](size_t ind) const\n-            {\n-                if (ind < first.size())\n-                    return first[ind];\n-                return second[ind % first.size()];\n-            }\n-\n-            size_t size() const\n-            {\n-                return first.size() + second.size();\n-            }\n-\n-        private:\n-            const Sample & first;\n-            const Sample & second;\n-    };\n-};\n-\n-class AggregateFunctionMannWhitney final:\n-    public IAggregateFunctionDataHelper<MannWhitneyData, AggregateFunctionMannWhitney>\n-{\n-private:\n-    using Alternative = typename MannWhitneyData::Alternative;\n-    Alternative alternative;\n-    bool continuity_correction{true};\n-\n-public:\n-    explicit AggregateFunctionMannWhitney(const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper<MannWhitneyData, AggregateFunctionMannWhitney> ({arguments}, {}, createResultType())\n-    {\n-        if (params.size() > 2)\n-            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} require two parameter or less\", getName());\n-\n-        if (params.empty())\n-        {\n-            alternative = Alternative::TwoSided;\n-            return;\n-        }\n-\n-        if (params[0].getType() != Field::Types::String)\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Aggregate function {} require first parameter to be a String\", getName());\n-\n-        const auto & param = params[0].get<String>();\n-        if (param == \"two-sided\")\n-            alternative = Alternative::TwoSided;\n-        else if (param == \"less\")\n-            alternative = Alternative::Less;\n-        else if (param == \"greater\")\n-            alternative = Alternative::Greater;\n-        else\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unknown parameter in aggregate function {}. \"\n-                    \"It must be one of: 'two-sided', 'less', 'greater'\", getName());\n-\n-        if (params.size() != 2)\n-            return;\n-\n-        if (params[1].getType() != Field::Types::UInt64)\n-                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Aggregate function {} require second parameter to be a UInt64\", getName());\n-\n-        continuity_correction = static_cast<bool>(params[1].get<UInt64>());\n-    }\n-\n-    String getName() const override\n-    {\n-        return \"mannWhitneyUTest\";\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return true; }\n-\n-    static DataTypePtr createResultType()\n-    {\n-        DataTypes types\n-        {\n-            std::make_shared<DataTypeNumber<Float64>>(),\n-            std::make_shared<DataTypeNumber<Float64>>(),\n-        };\n-\n-        Strings names\n-        {\n-            \"u_statistic\",\n-            \"p_value\"\n-        };\n-\n-        return std::make_shared<DataTypeTuple>(\n-            std::move(types),\n-            std::move(names)\n-        );\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        Float64 value = columns[0]->getFloat64(row_num);\n-        UInt8 is_second = columns[1]->getUInt(row_num);\n-\n-        if (is_second)\n-            this->data(place).addY(value, arena);\n-        else\n-            this->data(place).addX(value, arena);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n-    {\n-        auto & a = this->data(place);\n-        const auto & b = this->data(rhs);\n-\n-        a.merge(b, arena);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        this->data(place).read(buf, arena);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        if (!this->data(place).size_x || !this->data(place).size_y)\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Aggregate function {} require both samples to be non empty\", getName());\n-\n-        auto [u_statistic, p_value] = this->data(place).getResult(alternative, continuity_correction);\n-\n-        /// Because p-value is a probability.\n-        p_value = std::min(1.0, std::max(0.0, p_value));\n-\n-        auto & column_tuple = assert_cast<ColumnTuple &>(to);\n-        auto & column_stat = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(0));\n-        auto & column_value = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(1));\n-\n-        column_stat.getData().push_back(u_statistic);\n-        column_value.getData().push_back(p_value);\n-    }\n-\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionMaxIntersections.cpp b/src/AggregateFunctions/AggregateFunctionMaxIntersections.cpp\nindex c93920a5ef29..66b5314e05c4 100644\n--- a/src/AggregateFunctions/AggregateFunctionMaxIntersections.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionMaxIntersections.cpp\n@@ -1,8 +1,21 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionMaxIntersections.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n #include <AggregateFunctions/Helpers.h>\n \n+#include <DataTypes/DataTypesNumber.h>\n+#include <Columns/ColumnsNumber.h>\n+\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+\n+#include <Common/ArenaAllocator.h>\n+#include <Common/NaNUtils.h>\n+#include <Common/assert_cast.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+\n+#define AGGREGATE_FUNCTION_MAX_INTERSECTIONS_MAX_ARRAY_SIZE 0xFFFFFF\n+\n \n namespace DB\n {\n@@ -11,24 +24,186 @@ struct Settings;\n namespace ErrorCodes\n {\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int TOO_LARGE_ARRAY_SIZE;\n }\n \n namespace\n {\n-    AggregateFunctionPtr createAggregateFunctionMaxIntersections(\n-        AggregateFunctionIntersectionsKind kind,\n-        const std::string & name, const DataTypes & argument_types, const Array & parameters)\n+\n+/** maxIntersections: returns maximum count of the intersected intervals defined by start_column and end_column values,\n+  * maxIntersectionsPosition: returns leftmost position of maximum intersection of intervals.\n+  */\n+\n+/// Similar to GroupArrayNumericData.\n+template <typename T>\n+struct MaxIntersectionsData\n+{\n+    /// Left or right end of the interval and signed weight; with positive sign for begin of interval and negative sign for end of interval.\n+    using Value = std::pair<T, Int64>;\n+\n+    // Switch to ordinary Allocator after 4096 bytes to avoid fragmentation and trash in Arena\n+    using Allocator = MixedAlignedArenaAllocator<alignof(Value), 4096>;\n+    using Array = PODArray<Value, 32, Allocator>;\n+\n+    Array value;\n+};\n+\n+enum class AggregateFunctionIntersectionsKind\n+{\n+    Count,\n+    Position\n+};\n+\n+template <typename PointType>\n+class AggregateFunctionIntersectionsMax final\n+    : public IAggregateFunctionDataHelper<MaxIntersectionsData<PointType>, AggregateFunctionIntersectionsMax<PointType>>\n+{\n+private:\n+    AggregateFunctionIntersectionsKind kind;\n+\n+public:\n+    AggregateFunctionIntersectionsMax(AggregateFunctionIntersectionsKind kind_, const DataTypes & arguments)\n+        : IAggregateFunctionDataHelper<MaxIntersectionsData<PointType>, AggregateFunctionIntersectionsMax<PointType>>(arguments, {}, createResultType(kind_))\n+        , kind(kind_)\n+    {\n+        if (!isNativeNumber(arguments[0]))\n+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"{}: first argument must be represented by integer\", getName());\n+\n+        if (!isNativeNumber(arguments[1]))\n+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"{}: second argument must be represented by integer\", getName());\n+\n+        if (!arguments[0]->equals(*arguments[1]))\n+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"{}: arguments must have the same type\", getName());\n+    }\n+\n+    String getName() const override\n+    {\n+        return kind == AggregateFunctionIntersectionsKind::Count\n+            ? \"maxIntersections\"\n+            : \"maxIntersectionsPosition\";\n+    }\n+\n+    static DataTypePtr createResultType(AggregateFunctionIntersectionsKind kind_)\n+    {\n+        if (kind_ == AggregateFunctionIntersectionsKind::Count)\n+            return std::make_shared<DataTypeUInt64>();\n+        else\n+            return std::make_shared<DataTypeNumber<PointType>>();\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        PointType left = assert_cast<const ColumnVector<PointType> &>(*columns[0]).getData()[row_num];\n+        PointType right = assert_cast<const ColumnVector<PointType> &>(*columns[1]).getData()[row_num];\n+\n+        if (!isNaN(left))\n+            this->data(place).value.push_back(std::make_pair(left, Int64(1)), arena);\n+\n+        if (!isNaN(right))\n+            this->data(place).value.push_back(std::make_pair(right, Int64(-1)), arena);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n+    {\n+        auto & cur_elems = this->data(place);\n+        auto & rhs_elems = this->data(rhs);\n+\n+        cur_elems.value.insert(rhs_elems.value.begin(), rhs_elems.value.end(), arena);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        const auto & value = this->data(place).value;\n+        size_t size = value.size();\n+        writeVarUInt(size, buf);\n+\n+        /// In this version, pairs were serialized with padding.\n+        /// We must ensure that padding bytes are zero-filled.\n+\n+        static_assert(offsetof(typename MaxIntersectionsData<PointType>::Value, first) == 0);\n+        static_assert(offsetof(typename MaxIntersectionsData<PointType>::Value, second) > 0);\n+\n+        char zero_padding[offsetof(typename MaxIntersectionsData<PointType>::Value, second) - sizeof(value[0].first)]{};\n+\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            writePODBinary(value[i].first, buf);\n+            writePODBinary(zero_padding, buf);\n+            if constexpr (std::endian::native == std::endian::little)\n+                writePODBinary(value[i].second, buf);\n+            else\n+                writePODBinary(std::byteswap(value[i].second), buf);\n+        }\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n     {\n-        assertBinary(name, argument_types);\n-        assertNoParameters(name, parameters);\n+        size_t size = 0;\n+        readVarUInt(size, buf);\n+\n+        if (unlikely(size > AGGREGATE_FUNCTION_MAX_INTERSECTIONS_MAX_ARRAY_SIZE))\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n+                            \"Too large array size (maximum: {})\", AGGREGATE_FUNCTION_MAX_INTERSECTIONS_MAX_ARRAY_SIZE);\n \n-        AggregateFunctionPtr res(createWithNumericType<AggregateFunctionIntersectionsMax>(*argument_types[0], kind, argument_types));\n-        if (!res)\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal types {} and {} of argument for aggregate function {}\",\n-                argument_types[0]->getName(), argument_types[1]->getName(), name);\n+        auto & value = this->data(place).value;\n \n-        return res;\n+        value.resize(size, arena);\n+        buf.readStrict(reinterpret_cast<char *>(value.data()), size * sizeof(value[0]));\n     }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        Int64 current_intersections = 0;\n+        Int64 max_intersections = 0;\n+        PointType position_of_max_intersections = 0;\n+\n+        /// const_cast because we will sort the array\n+        auto & array = this->data(place).value;\n+\n+        /// Sort by position; for equal position, sort by weight to get deterministic result.\n+        ::sort(array.begin(), array.end());\n+\n+        for (const auto & point_weight : array)\n+        {\n+            current_intersections += point_weight.second;\n+            if (current_intersections > max_intersections)\n+            {\n+                max_intersections = current_intersections;\n+                position_of_max_intersections = point_weight.first;\n+            }\n+        }\n+\n+        if (kind == AggregateFunctionIntersectionsKind::Count)\n+        {\n+            auto & result_column = assert_cast<ColumnUInt64 &>(to).getData();\n+            result_column.push_back(max_intersections);\n+        }\n+        else\n+        {\n+            auto & result_column = assert_cast<ColumnVector<PointType> &>(to).getData();\n+            result_column.push_back(position_of_max_intersections);\n+        }\n+    }\n+};\n+\n+\n+AggregateFunctionPtr createAggregateFunctionMaxIntersections(\n+    AggregateFunctionIntersectionsKind kind,\n+    const std::string & name, const DataTypes & argument_types, const Array & parameters)\n+{\n+    assertBinary(name, argument_types);\n+    assertNoParameters(name, parameters);\n+\n+    AggregateFunctionPtr res(createWithNumericType<AggregateFunctionIntersectionsMax>(*argument_types[0], kind, argument_types));\n+    if (!res)\n+        throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal types {} and {} of argument for aggregate function {}\",\n+            argument_types[0]->getName(), argument_types[1]->getName(), name);\n+\n+    return res;\n+}\n+\n }\n \n void registerAggregateFunctionsMaxIntersections(AggregateFunctionFactory & factory)\ndiff --git a/src/AggregateFunctions/AggregateFunctionMaxIntersections.h b/src/AggregateFunctions/AggregateFunctionMaxIntersections.h\ndeleted file mode 100644\nindex fb333da3b85f..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionMaxIntersections.h\n+++ /dev/null\n@@ -1,189 +0,0 @@\n-#pragma once\n-\n-#include <base/sort.h>\n-\n-#include <DataTypes/DataTypesNumber.h>\n-#include <Columns/ColumnsNumber.h>\n-\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-\n-#include <Common/ArenaAllocator.h>\n-#include <Common/NaNUtils.h>\n-#include <Common/assert_cast.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-#define AGGREGATE_FUNCTION_MAX_INTERSECTIONS_MAX_ARRAY_SIZE 0xFFFFFF\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-    extern const int TOO_LARGE_ARRAY_SIZE;\n-}\n-\n-\n-/** maxIntersections: returns maximum count of the intersected intervals defined by start_column and end_column values,\n-  * maxIntersectionsPosition: returns leftmost position of maximum intersection of intervals.\n-  */\n-\n-/// Similar to GroupArrayNumericData.\n-template <typename T>\n-struct MaxIntersectionsData\n-{\n-    /// Left or right end of the interval and signed weight; with positive sign for begin of interval and negative sign for end of interval.\n-    using Value = std::pair<T, Int64>;\n-\n-    // Switch to ordinary Allocator after 4096 bytes to avoid fragmentation and trash in Arena\n-    using Allocator = MixedAlignedArenaAllocator<alignof(Value), 4096>;\n-    using Array = PODArray<Value, 32, Allocator>;\n-\n-    Array value;\n-};\n-\n-enum class AggregateFunctionIntersectionsKind\n-{\n-    Count,\n-    Position\n-};\n-\n-template <typename PointType>\n-class AggregateFunctionIntersectionsMax final\n-    : public IAggregateFunctionDataHelper<MaxIntersectionsData<PointType>, AggregateFunctionIntersectionsMax<PointType>>\n-{\n-private:\n-    AggregateFunctionIntersectionsKind kind;\n-\n-public:\n-    AggregateFunctionIntersectionsMax(AggregateFunctionIntersectionsKind kind_, const DataTypes & arguments)\n-        : IAggregateFunctionDataHelper<MaxIntersectionsData<PointType>, AggregateFunctionIntersectionsMax<PointType>>(arguments, {}, createResultType(kind_))\n-        , kind(kind_)\n-    {\n-        if (!isNativeNumber(arguments[0]))\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"{}: first argument must be represented by integer\", getName());\n-\n-        if (!isNativeNumber(arguments[1]))\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"{}: second argument must be represented by integer\", getName());\n-\n-        if (!arguments[0]->equals(*arguments[1]))\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"{}: arguments must have the same type\", getName());\n-    }\n-\n-    String getName() const override\n-    {\n-        return kind == AggregateFunctionIntersectionsKind::Count\n-            ? \"maxIntersections\"\n-            : \"maxIntersectionsPosition\";\n-    }\n-\n-    static DataTypePtr createResultType(AggregateFunctionIntersectionsKind kind_)\n-    {\n-        if (kind_ == AggregateFunctionIntersectionsKind::Count)\n-            return std::make_shared<DataTypeUInt64>();\n-        else\n-            return std::make_shared<DataTypeNumber<PointType>>();\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        PointType left = assert_cast<const ColumnVector<PointType> &>(*columns[0]).getData()[row_num];\n-        PointType right = assert_cast<const ColumnVector<PointType> &>(*columns[1]).getData()[row_num];\n-\n-        if (!isNaN(left))\n-            this->data(place).value.push_back(std::make_pair(left, Int64(1)), arena);\n-\n-        if (!isNaN(right))\n-            this->data(place).value.push_back(std::make_pair(right, Int64(-1)), arena);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n-    {\n-        auto & cur_elems = this->data(place);\n-        auto & rhs_elems = this->data(rhs);\n-\n-        cur_elems.value.insert(rhs_elems.value.begin(), rhs_elems.value.end(), arena);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        const auto & value = this->data(place).value;\n-        size_t size = value.size();\n-        writeVarUInt(size, buf);\n-\n-        /// In this version, pairs were serialized with padding.\n-        /// We must ensure that padding bytes are zero-filled.\n-\n-        static_assert(offsetof(typename MaxIntersectionsData<PointType>::Value, first) == 0);\n-        static_assert(offsetof(typename MaxIntersectionsData<PointType>::Value, second) > 0);\n-\n-        char zero_padding[offsetof(typename MaxIntersectionsData<PointType>::Value, second) - sizeof(value[0].first)]{};\n-\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            writePODBinary(value[i].first, buf);\n-            writePODBinary(zero_padding, buf);\n-            if constexpr (std::endian::native == std::endian::little)\n-                writePODBinary(value[i].second, buf);\n-            else\n-                writePODBinary(std::byteswap(value[i].second), buf);\n-        }\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        size_t size = 0;\n-        readVarUInt(size, buf);\n-\n-        if (unlikely(size > AGGREGATE_FUNCTION_MAX_INTERSECTIONS_MAX_ARRAY_SIZE))\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n-                            \"Too large array size (maximum: {})\", AGGREGATE_FUNCTION_MAX_INTERSECTIONS_MAX_ARRAY_SIZE);\n-\n-        auto & value = this->data(place).value;\n-\n-        value.resize(size, arena);\n-        buf.readStrict(reinterpret_cast<char *>(value.data()), size * sizeof(value[0]));\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        Int64 current_intersections = 0;\n-        Int64 max_intersections = 0;\n-        PointType position_of_max_intersections = 0;\n-\n-        /// const_cast because we will sort the array\n-        auto & array = this->data(place).value;\n-\n-        /// Sort by position; for equal position, sort by weight to get deterministic result.\n-        ::sort(array.begin(), array.end());\n-\n-        for (const auto & point_weight : array)\n-        {\n-            current_intersections += point_weight.second;\n-            if (current_intersections > max_intersections)\n-            {\n-                max_intersections = current_intersections;\n-                position_of_max_intersections = point_weight.first;\n-            }\n-        }\n-\n-        if (kind == AggregateFunctionIntersectionsKind::Count)\n-        {\n-            auto & result_column = assert_cast<ColumnUInt64 &>(to).getData();\n-            result_column.push_back(max_intersections);\n-        }\n-        else\n-        {\n-            auto & result_column = assert_cast<ColumnVector<PointType> &>(to).getData();\n-            result_column.push_back(position_of_max_intersections);\n-        }\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionMeanZTest.cpp b/src/AggregateFunctions/AggregateFunctionMeanZTest.cpp\nindex 99d0d0063d59..7f4b1d9d6dce 100644\n--- a/src/AggregateFunctions/AggregateFunctionMeanZTest.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionMeanZTest.cpp\n@@ -1,8 +1,16 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionMeanZTest.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n #include <AggregateFunctions/Moments.h>\n \n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/StatCommon.h>\n+#include <Columns/ColumnVector.h>\n+#include <Columns/ColumnTuple.h>\n+#include <Common/assert_cast.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeTuple.h>\n+#include <cmath>\n+\n \n namespace ErrorCodes\n {\n@@ -18,6 +26,121 @@ struct Settings;\n namespace\n {\n \n+/// Returns tuple of (z-statistic, p-value, confidence-interval-low, confidence-interval-high)\n+template <typename Data>\n+class AggregateFunctionMeanZTest :\n+    public IAggregateFunctionDataHelper<Data, AggregateFunctionMeanZTest<Data>>\n+{\n+private:\n+    Float64 pop_var_x;\n+    Float64 pop_var_y;\n+    Float64 confidence_level;\n+\n+public:\n+    AggregateFunctionMeanZTest(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<Data, AggregateFunctionMeanZTest<Data>>({arguments}, params, createResultType())\n+    {\n+        pop_var_x = params.at(0).safeGet<Float64>();\n+        pop_var_y = params.at(1).safeGet<Float64>();\n+        confidence_level = params.at(2).safeGet<Float64>();\n+\n+        if (!std::isfinite(pop_var_x) || !std::isfinite(pop_var_y) || !std::isfinite(confidence_level))\n+        {\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Aggregate function {} requires finite parameter values.\", Data::name);\n+        }\n+\n+        if (pop_var_x < 0.0 || pop_var_y < 0.0)\n+        {\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS,\n+                            \"Population variance parameters must be larger than or equal to zero \"\n+                            \"in aggregate function {}.\", Data::name);\n+        }\n+\n+        if (confidence_level <= 0.0 || confidence_level >= 1.0)\n+        {\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Confidence level parameter must be between 0 and 1 in aggregate function {}.\", Data::name);\n+        }\n+    }\n+\n+    String getName() const override\n+    {\n+        return Data::name;\n+    }\n+\n+    static DataTypePtr createResultType()\n+    {\n+        DataTypes types\n+        {\n+            std::make_shared<DataTypeNumber<Float64>>(),\n+            std::make_shared<DataTypeNumber<Float64>>(),\n+            std::make_shared<DataTypeNumber<Float64>>(),\n+            std::make_shared<DataTypeNumber<Float64>>(),\n+        };\n+\n+        Strings names\n+        {\n+            \"z_statistic\",\n+            \"p_value\",\n+            \"confidence_interval_low\",\n+            \"confidence_interval_high\"\n+        };\n+\n+        return std::make_shared<DataTypeTuple>(\n+            std::move(types),\n+            std::move(names)\n+        );\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        Float64 value = columns[0]->getFloat64(row_num);\n+        UInt8 is_second = columns[1]->getUInt(row_num);\n+\n+        if (is_second)\n+            this->data(place).addY(value);\n+        else\n+            this->data(place).addX(value);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).write(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).read(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        auto [z_stat, p_value] = this->data(place).getResult(pop_var_x, pop_var_y);\n+        auto [ci_low, ci_high] = this->data(place).getConfidenceIntervals(pop_var_x, pop_var_y, confidence_level);\n+\n+        /// Because p-value is a probability.\n+        p_value = std::min(1.0, std::max(0.0, p_value));\n+\n+        auto & column_tuple = assert_cast<ColumnTuple &>(to);\n+        auto & column_stat = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(0));\n+        auto & column_value = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(1));\n+        auto & column_ci_low = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(2));\n+        auto & column_ci_high = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(3));\n+\n+        column_stat.getData().push_back(z_stat);\n+        column_value.getData().push_back(p_value);\n+        column_ci_low.getData().push_back(ci_low);\n+        column_ci_high.getData().push_back(ci_high);\n+    }\n+};\n+\n+\n struct MeanZTestData : public ZTestMoments<Float64>\n {\n     static constexpr auto name = \"meanZTest\";\ndiff --git a/src/AggregateFunctions/AggregateFunctionMeanZTest.h b/src/AggregateFunctions/AggregateFunctionMeanZTest.h\ndeleted file mode 100644\nindex 6e67d167d6b7..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionMeanZTest.h\n+++ /dev/null\n@@ -1,141 +0,0 @@\n-#pragma once\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/StatCommon.h>\n-#include <Columns/ColumnVector.h>\n-#include <Columns/ColumnTuple.h>\n-#include <Common/assert_cast.h>\n-#include <Core/Types.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <cmath>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-class ReadBuffer;\n-class WriteBuffer;\n-\n-namespace ErrorCodes\n-{\n-    extern const int BAD_ARGUMENTS;\n-}\n-\n-\n-/// Returns tuple of (z-statistic, p-value, confidence-interval-low, confidence-interval-high)\n-template <typename Data>\n-class AggregateFunctionMeanZTest :\n-    public IAggregateFunctionDataHelper<Data, AggregateFunctionMeanZTest<Data>>\n-{\n-private:\n-    Float64 pop_var_x;\n-    Float64 pop_var_y;\n-    Float64 confidence_level;\n-\n-public:\n-    AggregateFunctionMeanZTest(const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper<Data, AggregateFunctionMeanZTest<Data>>({arguments}, params, createResultType())\n-    {\n-        pop_var_x = params.at(0).safeGet<Float64>();\n-        pop_var_y = params.at(1).safeGet<Float64>();\n-        confidence_level = params.at(2).safeGet<Float64>();\n-\n-        if (!std::isfinite(pop_var_x) || !std::isfinite(pop_var_y) || !std::isfinite(confidence_level))\n-        {\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Aggregate function {} requires finite parameter values.\", Data::name);\n-        }\n-\n-        if (pop_var_x < 0.0 || pop_var_y < 0.0)\n-        {\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS,\n-                            \"Population variance parameters must be larger than or equal to zero \"\n-                            \"in aggregate function {}.\", Data::name);\n-        }\n-\n-        if (confidence_level <= 0.0 || confidence_level >= 1.0)\n-        {\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Confidence level parameter must be between 0 and 1 in aggregate function {}.\", Data::name);\n-        }\n-    }\n-\n-    String getName() const override\n-    {\n-        return Data::name;\n-    }\n-\n-    static DataTypePtr createResultType()\n-    {\n-        DataTypes types\n-        {\n-            std::make_shared<DataTypeNumber<Float64>>(),\n-            std::make_shared<DataTypeNumber<Float64>>(),\n-            std::make_shared<DataTypeNumber<Float64>>(),\n-            std::make_shared<DataTypeNumber<Float64>>(),\n-        };\n-\n-        Strings names\n-        {\n-            \"z_statistic\",\n-            \"p_value\",\n-            \"confidence_interval_low\",\n-            \"confidence_interval_high\"\n-        };\n-\n-        return std::make_shared<DataTypeTuple>(\n-            std::move(types),\n-            std::move(names)\n-        );\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        Float64 value = columns[0]->getFloat64(row_num);\n-        UInt8 is_second = columns[1]->getUInt(row_num);\n-\n-        if (is_second)\n-            this->data(place).addY(value);\n-        else\n-            this->data(place).addX(value);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).read(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        auto [z_stat, p_value] = this->data(place).getResult(pop_var_x, pop_var_y);\n-        auto [ci_low, ci_high] = this->data(place).getConfidenceIntervals(pop_var_x, pop_var_y, confidence_level);\n-\n-        /// Because p-value is a probability.\n-        p_value = std::min(1.0, std::max(0.0, p_value));\n-\n-        auto & column_tuple = assert_cast<ColumnTuple &>(to);\n-        auto & column_stat = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(0));\n-        auto & column_value = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(1));\n-        auto & column_ci_low = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(2));\n-        auto & column_ci_high = assert_cast<ColumnVector<Float64> &>(column_tuple.getColumn(3));\n-\n-        column_stat.getData().push_back(z_stat);\n-        column_value.getData().push_back(p_value);\n-        column_ci_low.getData().push_back(ci_low);\n-        column_ci_high.getData().push_back(ci_high);\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantile.cpp b/src/AggregateFunctions/AggregateFunctionQuantile.cpp\nindex 6a2520a379e5..110f6c6b4d6a 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantile.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantile.cpp\n@@ -1,5 +1,5 @@\n #include <AggregateFunctions/AggregateFunctionQuantile.h>\n-#include <AggregateFunctions/QuantileReservoirSampler.h>\n+#include <AggregateFunctions/ReservoirSampler.h>\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n #include <AggregateFunctions/Helpers.h>\n #include <DataTypes/DataTypeDate.h>\n@@ -9,18 +9,108 @@\n \n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n {\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int NOT_IMPLEMENTED;\n }\n \n namespace\n {\n \n-template <typename Value, bool float_return> using FuncQuantile = AggregateFunctionQuantile<Value, QuantileReservoirSampler<Value>, NameQuantile, false, std::conditional_t<float_return, Float64, void>, false>;\n-template <typename Value, bool float_return> using FuncQuantiles = AggregateFunctionQuantile<Value, QuantileReservoirSampler<Value>, NameQuantiles, false, std::conditional_t<float_return, Float64, void>, true>;\n+/** Quantile calculation with \"reservoir sample\" algorithm.\n+  * It collects pseudorandom subset of limited size from a stream of values,\n+  *  and approximate quantile from it.\n+  * The result is non-deterministic. Also look at QuantileReservoirSamplerDeterministic.\n+  *\n+  * This algorithm is quite inefficient in terms of precision for memory usage,\n+  *  but very efficient in CPU (though less efficient than QuantileTiming and than QuantileExact for small sets).\n+  */\n+template <typename Value>\n+struct QuantileReservoirSampler\n+{\n+    using Data = ReservoirSampler<Value, ReservoirSamplerOnEmpty::RETURN_NAN_OR_ZERO>;\n+    Data data;\n+\n+    void add(const Value & x)\n+    {\n+        data.insert(x);\n+    }\n+\n+    template <typename Weight>\n+    void add(const Value &, const Weight &)\n+    {\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method add with weight is not implemented for ReservoirSampler\");\n+    }\n+\n+    void merge(const QuantileReservoirSampler & rhs)\n+    {\n+        data.merge(rhs.data);\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        data.write(buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        data.read(buf);\n+    }\n+\n+    /// Get the value of the `level` quantile. The level must be between 0 and 1.\n+    Value get(Float64 level)\n+    {\n+        if (data.empty())\n+            return {};\n+\n+        if constexpr (is_decimal<Value>)\n+            return Value(static_cast<typename Value::NativeType>(data.quantileInterpolated(level)));\n+        else\n+            return static_cast<Value>(data.quantileInterpolated(level));\n+    }\n+\n+    /// Get the `size` values of `levels` quantiles. Write `size` results starting with `result` address.\n+    /// indices - an array of index levels such that the corresponding elements will go in ascending order.\n+    void getMany(const Float64 * levels, const size_t * indices, size_t size, Value * result)\n+    {\n+        bool is_empty = data.empty();\n+\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            if (is_empty)\n+            {\n+                result[i] = Value{};\n+            }\n+            else\n+            {\n+                if constexpr (is_decimal<Value>)\n+                    result[indices[i]] = Value(static_cast<typename Value::NativeType>(data.quantileInterpolated(levels[indices[i]])));\n+                else\n+                    result[indices[i]] = Value(data.quantileInterpolated(levels[indices[i]]));\n+            }\n+        }\n+    }\n+\n+    /// The same, but in the case of an empty state, NaN is returned.\n+    Float64 getFloat(Float64 level)\n+    {\n+        return data.quantileInterpolated(level);\n+    }\n+\n+    void getManyFloat(const Float64 * levels, const size_t * indices, size_t size, Float64 * result)\n+    {\n+        for (size_t i = 0; i < size; ++i)\n+            result[indices[i]] = data.quantileInterpolated(levels[indices[i]]);\n+    }\n+};\n+\n+\n+template <typename Value, bool float_return> using FuncQuantile = AggregateFunctionQuantile<Value, QuantileReservoirSampler<Value>, NameQuantile, false, std::conditional_t<float_return, Float64, void>, false, false>;\n+template <typename Value, bool float_return> using FuncQuantiles = AggregateFunctionQuantile<Value, QuantileReservoirSampler<Value>, NameQuantiles, false, std::conditional_t<float_return, Float64, void>, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantile.h b/src/AggregateFunctions/AggregateFunctionQuantile.h\nindex 07db655025d2..dc8d419763ea 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantile.h\n+++ b/src/AggregateFunctions/AggregateFunctionQuantile.h\n@@ -54,15 +54,16 @@ template <\n     typename FloatReturnType,\n     /// If true, the function will accept multiple parameters with quantile levels\n     ///  and return an Array filled with many values of that quantiles.\n-    bool returns_many>\n+    bool returns_many,\n+    /// If the first parameter (before level) is accuracy.\n+    bool has_accuracy_parameter>\n class AggregateFunctionQuantile final\n-    : public IAggregateFunctionDataHelper<Data, AggregateFunctionQuantile<Value, Data, Name, has_second_arg, FloatReturnType, returns_many>>\n+    : public IAggregateFunctionDataHelper<Data, AggregateFunctionQuantile<Value, Data, Name, has_second_arg, FloatReturnType, returns_many, has_accuracy_parameter>>\n {\n private:\n     using ColVecType = ColumnVectorOrDecimal<Value>;\n \n     static constexpr bool returns_float = !(std::is_same_v<FloatReturnType, void>);\n-    static constexpr bool is_quantile_gk = std::is_same_v<Data, QuantileGK<Value>>;\n     static_assert(!is_decimal<Value> || !returns_float);\n \n     QuantileLevels<Float64> levels;\n@@ -77,16 +78,16 @@ class AggregateFunctionQuantile final\n \n public:\n     AggregateFunctionQuantile(const DataTypes & argument_types_, const Array & params)\n-        : IAggregateFunctionDataHelper<Data, AggregateFunctionQuantile<Value, Data, Name, has_second_arg, FloatReturnType, returns_many>>(\n+        : IAggregateFunctionDataHelper<Data, AggregateFunctionQuantile<Value, Data, Name, has_second_arg, FloatReturnType, returns_many, has_accuracy_parameter>>(\n             argument_types_, params, createResultType(argument_types_))\n-        , levels(is_quantile_gk && !params.empty() ? Array(params.begin() + 1, params.end()) : params, returns_many)\n+        , levels(has_accuracy_parameter && !params.empty() ? Array(params.begin() + 1, params.end()) : params, returns_many)\n         , level(levels.levels[0])\n         , argument_type(this->argument_types[0])\n     {\n         if (!returns_many && levels.size() > 1)\n             throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} requires one level parameter or less\", getName());\n \n-        if constexpr (is_quantile_gk)\n+        if constexpr (has_accuracy_parameter)\n         {\n             if (params.empty())\n                 throw Exception(\n@@ -115,7 +116,7 @@ class AggregateFunctionQuantile final\n \n     void create(AggregateDataPtr __restrict place) const override /// NOLINT\n     {\n-        if constexpr (is_quantile_gk)\n+        if constexpr (has_accuracy_parameter)\n             new (place) Data(accuracy);\n         else\n             new (place) Data;\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileApprox.cpp b/src/AggregateFunctions/AggregateFunctionQuantileApprox.cpp\ndeleted file mode 100644\nindex c190aaa30d59..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionQuantileApprox.cpp\n+++ /dev/null\n@@ -1,71 +0,0 @@\n-#include <AggregateFunctions/AggregateFunctionQuantile.h>\n-#include <AggregateFunctions/QuantileApprox.h>\n-#include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/Helpers.h>\n-#include <DataTypes/DataTypeDate.h>\n-#include <DataTypes/DataTypeDateTime.h>\n-#include <Core/Field.h>\n-\n-namespace DB\n-{\n-\n-namespace ErrorCodes\n-{\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-}\n-\n-namespace\n-{\n-\n-template <typename Value, bool _> using FuncQuantileGK = AggregateFunctionQuantile<Value, QuantileGK<Value>, NameQuantileGK, false, void, false>;\n-template <typename Value, bool _> using FuncQuantilesGK = AggregateFunctionQuantile<Value, QuantileGK<Value>, NameQuantilesGK, false, void, true>;\n-\n-template <template <typename, bool> class Function>\n-AggregateFunctionPtr createAggregateFunctionQuantile(\n-    const std::string & name, const DataTypes & argument_types, const Array & params, const Settings *)\n-{\n-    /// Second argument type check doesn't depend on the type of the first one.\n-    Function<void, true>::assertSecondArg(argument_types);\n-\n-    const DataTypePtr & argument_type = argument_types[0];\n-    WhichDataType which(argument_type);\n-\n-#define DISPATCH(TYPE) \\\n-    if (which.idx == TypeIndex::TYPE) \\\n-        return std::make_shared<Function<TYPE, true>>(argument_types, params);\n-    FOR_BASIC_NUMERIC_TYPES(DISPATCH)\n-#undef DISPATCH\n-\n-    if (which.idx == TypeIndex::Date) return std::make_shared<Function<DataTypeDate::FieldType, false>>(argument_types, params);\n-    if (which.idx == TypeIndex::DateTime) return std::make_shared<Function<DataTypeDateTime::FieldType, false>>(argument_types, params);\n-\n-    if (which.idx == TypeIndex::Decimal32) return std::make_shared<Function<Decimal32, false>>(argument_types, params);\n-    if (which.idx == TypeIndex::Decimal64) return std::make_shared<Function<Decimal64, false>>(argument_types, params);\n-    if (which.idx == TypeIndex::Decimal128) return std::make_shared<Function<Decimal128, false>>(argument_types, params);\n-    if (which.idx == TypeIndex::Decimal256) return std::make_shared<Function<Decimal256, false>>(argument_types, params);\n-    if (which.idx == TypeIndex::DateTime64) return std::make_shared<Function<DateTime64, false>>(argument_types, params);\n-\n-    if (which.idx == TypeIndex::Int128) return std::make_shared<Function<Int128, true>>(argument_types, params);\n-    if (which.idx == TypeIndex::UInt128) return std::make_shared<Function<UInt128, true>>(argument_types, params);\n-    if (which.idx == TypeIndex::Int256) return std::make_shared<Function<Int256, true>>(argument_types, params);\n-    if (which.idx == TypeIndex::UInt256) return std::make_shared<Function<UInt256, true>>(argument_types, params);\n-\n-    throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n-                    argument_type->getName(), name);\n-}\n-\n-}\n-\n-void registerAggregateFunctionsQuantileApprox(AggregateFunctionFactory & factory)\n-{\n-    /// For aggregate functions returning array we cannot return NULL on empty set.\n-    AggregateFunctionProperties properties = { .returns_default_when_only_null = true };\n-\n-    factory.registerFunction(NameQuantileGK::name, createAggregateFunctionQuantile<FuncQuantileGK>);\n-    factory.registerFunction(NameQuantilesGK::name, {createAggregateFunctionQuantile<FuncQuantilesGK>, properties});\n-\n-    /// 'median' is an alias for 'quantile'\n-    factory.registerAlias(\"medianGK\", NameQuantileGK::name);\n-}\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileBFloat16.cpp b/src/AggregateFunctions/AggregateFunctionQuantileBFloat16.cpp\nindex a0c600b59511..c211ba031365 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileBFloat16.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileBFloat16.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool float_return> using FuncQuantileBFloat16 = AggregateFunctionQuantile<Value, QuantileBFloat16Histogram<Value>, NameQuantileBFloat16, false, std::conditional_t<float_return, Float64, void>, false>;\n-template <typename Value, bool float_return> using FuncQuantilesBFloat16 = AggregateFunctionQuantile<Value, QuantileBFloat16Histogram<Value>, NameQuantilesBFloat16, false, std::conditional_t<float_return, Float64, void>, true>;\n+template <typename Value, bool float_return> using FuncQuantileBFloat16 = AggregateFunctionQuantile<Value, QuantileBFloat16Histogram<Value>, NameQuantileBFloat16, false, std::conditional_t<float_return, Float64, void>, false, false>;\n+template <typename Value, bool float_return> using FuncQuantilesBFloat16 = AggregateFunctionQuantile<Value, QuantileBFloat16Histogram<Value>, NameQuantilesBFloat16, false, std::conditional_t<float_return, Float64, void>, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileBFloat16Weighted.cpp b/src/AggregateFunctions/AggregateFunctionQuantileBFloat16Weighted.cpp\nindex f3feb067857b..702848ee4fa3 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileBFloat16Weighted.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileBFloat16Weighted.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool float_return> using FuncQuantileBFloat16Weighted = AggregateFunctionQuantile<Value, QuantileBFloat16Histogram<Value>, NameQuantileBFloat16Weighted, true, std::conditional_t<float_return, Float64, void>, false>;\n-template <typename Value, bool float_return> using FuncQuantilesBFloat16Weighted = AggregateFunctionQuantile<Value, QuantileBFloat16Histogram<Value>, NameQuantilesBFloat16Weighted, true, std::conditional_t<float_return, Float64, void>, true>;\n+template <typename Value, bool float_return> using FuncQuantileBFloat16Weighted = AggregateFunctionQuantile<Value, QuantileBFloat16Histogram<Value>, NameQuantileBFloat16Weighted, true, std::conditional_t<float_return, Float64, void>, false, false>;\n+template <typename Value, bool float_return> using FuncQuantilesBFloat16Weighted = AggregateFunctionQuantile<Value, QuantileBFloat16Histogram<Value>, NameQuantilesBFloat16Weighted, true, std::conditional_t<float_return, Float64, void>, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileDeterministic.cpp b/src/AggregateFunctions/AggregateFunctionQuantileDeterministic.cpp\nindex af9e3f345bac..f9f114d69e4d 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileDeterministic.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileDeterministic.cpp\n@@ -1,5 +1,5 @@\n #include <AggregateFunctions/AggregateFunctionQuantile.h>\n-#include <AggregateFunctions/QuantileReservoirSamplerDeterministic.h>\n+#include <AggregateFunctions/ReservoirSamplerDeterministic.h>\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n #include <AggregateFunctions/Helpers.h>\n #include <DataTypes/DataTypeDate.h>\n@@ -9,18 +9,108 @@\n \n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n {\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int NOT_IMPLEMENTED;\n }\n \n namespace\n {\n \n-template <typename Value, bool float_return> using FuncQuantileDeterministic = AggregateFunctionQuantile<Value, QuantileReservoirSamplerDeterministic<Value>, NameQuantileDeterministic, true, std::conditional_t<float_return, Float64, void>, false>;\n-template <typename Value, bool float_return> using FuncQuantilesDeterministic = AggregateFunctionQuantile<Value, QuantileReservoirSamplerDeterministic<Value>, NameQuantilesDeterministic, true, std::conditional_t<float_return, Float64, void>, true>;\n+/** Quantile calculation with \"reservoir sample\" algorithm.\n+  * It collects pseudorandom subset of limited size from a stream of values,\n+  *  and approximate quantile from it.\n+  * The function accept second argument, named \"determinator\"\n+  *  and a hash function from it is calculated and used as a source for randomness\n+  *  to apply random sampling.\n+  * The function is deterministic, but care should be taken with choose of \"determinator\" argument.\n+  */\n+template <typename Value>\n+struct QuantileReservoirSamplerDeterministic\n+{\n+    using Data = ReservoirSamplerDeterministic<Value, ReservoirSamplerDeterministicOnEmpty::RETURN_NAN_OR_ZERO>;\n+    Data data;\n+\n+    void add(const Value &)\n+    {\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method add without determinator is not implemented for ReservoirSamplerDeterministic\");\n+    }\n+\n+    template <typename Determinator>\n+    void add(const Value & x, const Determinator & determinator)\n+    {\n+        data.insert(x, determinator);\n+    }\n+\n+    void merge(const QuantileReservoirSamplerDeterministic & rhs)\n+    {\n+        data.merge(rhs.data);\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        data.write(buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        data.read(buf);\n+    }\n+\n+    /// Get the value of the `level` quantile. The level must be between 0 and 1.\n+    Value get(Float64 level)\n+    {\n+        if (data.empty())\n+            return {};\n+\n+        if constexpr (is_decimal<Value>)\n+            return static_cast<typename Value::NativeType>(data.quantileInterpolated(level));\n+        else\n+            return static_cast<Value>(data.quantileInterpolated(level));\n+    }\n+\n+    /// Get the `size` values of `levels` quantiles. Write `size` results starting with `result` address.\n+    /// indices - an array of index levels such that the corresponding elements will go in ascending order.\n+    void getMany(const Float64 * levels, const size_t * indices, size_t size, Value * result)\n+    {\n+        bool is_empty = data.empty();\n+\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            if (is_empty)\n+            {\n+                result[i] = Value{};\n+            }\n+            else\n+            {\n+                if constexpr (is_decimal<Value>)\n+                    result[indices[i]] = static_cast<typename Value::NativeType>(data.quantileInterpolated(levels[indices[i]]));\n+                else\n+                    result[indices[i]] = static_cast<Value>(data.quantileInterpolated(levels[indices[i]]));\n+            }\n+        }\n+    }\n+\n+    /// The same, but in the case of an empty state, NaN is returned.\n+    Float64 getFloat(Float64 level)\n+    {\n+        return data.quantileInterpolated(level);\n+    }\n+\n+    void getManyFloat(const Float64 * levels, const size_t * indices, size_t size, Float64 * result)\n+    {\n+        for (size_t i = 0; i < size; ++i)\n+            result[indices[i]] = data.quantileInterpolated(levels[indices[i]]);\n+    }\n+};\n+\n+\n+template <typename Value, bool float_return> using FuncQuantileDeterministic = AggregateFunctionQuantile<Value, QuantileReservoirSamplerDeterministic<Value>, NameQuantileDeterministic, true, std::conditional_t<float_return, Float64, void>, false, false>;\n+template <typename Value, bool float_return> using FuncQuantilesDeterministic = AggregateFunctionQuantile<Value, QuantileReservoirSamplerDeterministic<Value>, NameQuantilesDeterministic, true, std::conditional_t<float_return, Float64, void>, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileExact.cpp b/src/AggregateFunctions/AggregateFunctionQuantileExact.cpp\nindex cd925b86694a..3098c498ce94 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileExact.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileExact.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool _> using FuncQuantileExact = AggregateFunctionQuantile<Value, QuantileExact<Value>, NameQuantileExact, false, void, false>;\n-template <typename Value, bool _> using FuncQuantilesExact = AggregateFunctionQuantile<Value, QuantileExact<Value>, NameQuantilesExact, false, void, true>;\n+template <typename Value, bool _> using FuncQuantileExact = AggregateFunctionQuantile<Value, QuantileExact<Value>, NameQuantileExact, false, void, false, false>;\n+template <typename Value, bool _> using FuncQuantilesExact = AggregateFunctionQuantile<Value, QuantileExact<Value>, NameQuantilesExact, false, void, true, false>;\n \n \n template <template <typename, bool> class Function>\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileExactExclusive.cpp b/src/AggregateFunctions/AggregateFunctionQuantileExactExclusive.cpp\nindex 0cf6d53c0c81..64ae5f01f589 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileExactExclusive.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileExactExclusive.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool _> using FuncQuantileExactExclusive = AggregateFunctionQuantile<Value, QuantileExactExclusive<Value>, NameQuantileExactExclusive, false, Float64, false>;\n-template <typename Value, bool _> using FuncQuantilesExactExclusive = AggregateFunctionQuantile<Value, QuantileExactExclusive<Value>, NameQuantilesExactExclusive, false, Float64, true>;\n+template <typename Value, bool _> using FuncQuantileExactExclusive = AggregateFunctionQuantile<Value, QuantileExactExclusive<Value>, NameQuantileExactExclusive, false, Float64, false, false>;\n+template <typename Value, bool _> using FuncQuantilesExactExclusive = AggregateFunctionQuantile<Value, QuantileExactExclusive<Value>, NameQuantilesExactExclusive, false, Float64, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileExactHigh.cpp b/src/AggregateFunctions/AggregateFunctionQuantileExactHigh.cpp\nindex 820667fcfb5f..a224b8fc10f6 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileExactHigh.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileExactHigh.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool _> using FuncQuantileExactHigh = AggregateFunctionQuantile<Value, QuantileExactHigh<Value>, NameQuantileExactHigh, false, void, false>;\n-template <typename Value, bool _> using FuncQuantilesExactHigh = AggregateFunctionQuantile<Value, QuantileExactHigh<Value>, NameQuantilesExactHigh, false, void, true>;\n+template <typename Value, bool _> using FuncQuantileExactHigh = AggregateFunctionQuantile<Value, QuantileExactHigh<Value>, NameQuantileExactHigh, false, void, false, false>;\n+template <typename Value, bool _> using FuncQuantilesExactHigh = AggregateFunctionQuantile<Value, QuantileExactHigh<Value>, NameQuantilesExactHigh, false, void, true, false>;\n \n \n template <template <typename, bool> class Function>\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileExactInclusive.cpp b/src/AggregateFunctions/AggregateFunctionQuantileExactInclusive.cpp\nindex 9d9db538e603..96703c271d8e 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileExactInclusive.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileExactInclusive.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool _> using FuncQuantileExactInclusive = AggregateFunctionQuantile<Value, QuantileExactInclusive<Value>, NameQuantileExactInclusive, false, Float64, false>;\n-template <typename Value, bool _> using FuncQuantilesExactInclusive = AggregateFunctionQuantile<Value, QuantileExactInclusive<Value>, NameQuantilesExactInclusive, false, Float64, true>;\n+template <typename Value, bool _> using FuncQuantileExactInclusive = AggregateFunctionQuantile<Value, QuantileExactInclusive<Value>, NameQuantileExactInclusive, false, Float64, false, false>;\n+template <typename Value, bool _> using FuncQuantilesExactInclusive = AggregateFunctionQuantile<Value, QuantileExactInclusive<Value>, NameQuantilesExactInclusive, false, Float64, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileExactLow.cpp b/src/AggregateFunctions/AggregateFunctionQuantileExactLow.cpp\nindex 5009a82134e1..221281a7bb3b 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileExactLow.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileExactLow.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool _> using FuncQuantileExactLow = AggregateFunctionQuantile<Value, QuantileExactLow<Value>, NameQuantileExactLow, false, void, false>;\n-template <typename Value, bool _> using FuncQuantilesExactLow = AggregateFunctionQuantile<Value, QuantileExactLow<Value>, NameQuantilesExactLow, false, void, true>;\n+template <typename Value, bool _> using FuncQuantileExactLow = AggregateFunctionQuantile<Value, QuantileExactLow<Value>, NameQuantileExactLow, false, void, false, false>;\n+template <typename Value, bool _> using FuncQuantilesExactLow = AggregateFunctionQuantile<Value, QuantileExactLow<Value>, NameQuantilesExactLow, false, void, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileExactWeighted.cpp b/src/AggregateFunctions/AggregateFunctionQuantileExactWeighted.cpp\nindex 80571ca6eb46..e5066fe9c3dd 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileExactWeighted.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileExactWeighted.cpp\n@@ -1,26 +1,216 @@\n #include <AggregateFunctions/AggregateFunctionQuantile.h>\n-#include <AggregateFunctions/QuantileExactWeighted.h>\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n #include <AggregateFunctions/Helpers.h>\n #include <DataTypes/DataTypeDate.h>\n #include <DataTypes/DataTypeDateTime.h>\n #include <Core/Field.h>\n \n+#include <Common/HashTable/HashMap.h>\n+#include <Common/NaNUtils.h>\n+\n \n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n {\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int NOT_IMPLEMENTED;\n }\n \n namespace\n {\n \n-template <typename Value, bool _> using FuncQuantileExactWeighted = AggregateFunctionQuantile<Value, QuantileExactWeighted<Value>, NameQuantileExactWeighted, true, void, false>;\n-template <typename Value, bool _> using FuncQuantilesExactWeighted = AggregateFunctionQuantile<Value, QuantileExactWeighted<Value>, NameQuantilesExactWeighted, true, void, true>;\n+/** Calculates quantile by counting number of occurrences for each value in a hash map.\n+  *\n+  * It uses O(distinct(N)) memory. Can be naturally applied for values with weight.\n+  * In case of many identical values, it can be more efficient than QuantileExact even when weight is not used.\n+  */\n+template <typename Value>\n+struct QuantileExactWeighted\n+{\n+    struct Int128Hash\n+    {\n+        size_t operator()(Int128 x) const\n+        {\n+            return CityHash_v1_0_2::Hash128to64({x >> 64, x & 0xffffffffffffffffll});\n+        }\n+    };\n+\n+    using Weight = UInt64;\n+    using UnderlyingType = NativeType<Value>;\n+    using Hasher = HashCRC32<UnderlyingType>;\n+\n+    /// When creating, the hash table must be small.\n+    using Map = HashMapWithStackMemory<UnderlyingType, Weight, Hasher, 4>;\n+\n+    Map map;\n+\n+    void add(const Value & x)\n+    {\n+        /// We must skip NaNs as they are not compatible with comparison sorting.\n+        if (!isNaN(x))\n+            ++map[x];\n+    }\n+\n+    void add(const Value & x, Weight weight)\n+    {\n+        if (!isNaN(x))\n+            map[x] += weight;\n+    }\n+\n+    void merge(const QuantileExactWeighted & rhs)\n+    {\n+        for (const auto & pair : rhs.map)\n+            map[pair.getKey()] += pair.getMapped();\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        map.write(buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        typename Map::Reader reader(buf);\n+        while (reader.next())\n+        {\n+            const auto & pair = reader.get();\n+            map[pair.first] = pair.second;\n+        }\n+    }\n+\n+    /// Get the value of the `level` quantile. The level must be between 0 and 1.\n+    Value get(Float64 level) const\n+    {\n+        size_t size = map.size();\n+\n+        if (0 == size)\n+            return std::numeric_limits<Value>::quiet_NaN();\n+\n+        /// Copy the data to a temporary array to get the element you need in order.\n+        using Pair = typename Map::value_type;\n+        std::unique_ptr<Pair[]> array_holder(new Pair[size]);\n+        Pair * array = array_holder.get();\n+\n+        /// Note: 64-bit integer weight can overflow.\n+        /// We do some implementation specific behaviour (return approximate or garbage results).\n+        /// Float64 is used as accumulator here to get approximate results.\n+        /// But weight can be already overflowed in computations in 'add' and 'merge' methods.\n+        /// It will be reasonable to change the type of weight to Float64 in the map,\n+        /// but we don't do that for compatibility of serialized data.\n+\n+        size_t i = 0;\n+        Float64 sum_weight = 0;\n+        for (const auto & pair : map)\n+        {\n+            sum_weight += pair.getMapped();\n+            array[i] = pair.getValue();\n+            ++i;\n+        }\n+\n+        ::sort(array, array + size, [](const Pair & a, const Pair & b) { return a.first < b.first; });\n+\n+        Float64 threshold = std::ceil(sum_weight * level);\n+        Float64 accumulated = 0;\n+\n+        const Pair * it = array;\n+        const Pair * end = array + size;\n+        while (it < end)\n+        {\n+            accumulated += it->second;\n+\n+            if (accumulated >= threshold)\n+                break;\n+\n+            ++it;\n+        }\n+\n+        if (it == end)\n+            --it;\n+\n+        return it->first;\n+    }\n+\n+    /// Get the `size` values of `levels` quantiles. Write `size` results starting with `result` address.\n+    /// indices - an array of index levels such that the corresponding elements will go in ascending order.\n+    void getMany(const Float64 * levels, const size_t * indices, size_t num_levels, Value * result) const\n+    {\n+        size_t size = map.size();\n+\n+        if (0 == size)\n+        {\n+            for (size_t i = 0; i < num_levels; ++i)\n+                result[i] = Value();\n+            return;\n+        }\n+\n+        /// Copy the data to a temporary array to get the element you need in order.\n+        using Pair = typename Map::value_type;\n+        std::unique_ptr<Pair[]> array_holder(new Pair[size]);\n+        Pair * array = array_holder.get();\n+\n+        size_t i = 0;\n+        Float64 sum_weight = 0;\n+        for (const auto & pair : map)\n+        {\n+            sum_weight += pair.getMapped();\n+            array[i] = pair.getValue();\n+            ++i;\n+        }\n+\n+        ::sort(array, array + size, [](const Pair & a, const Pair & b) { return a.first < b.first; });\n+\n+        Float64 accumulated = 0;\n+\n+        const Pair * it = array;\n+        const Pair * end = array + size;\n+\n+        size_t level_index = 0;\n+        Float64 threshold = std::ceil(sum_weight * levels[indices[level_index]]);\n+\n+        while (it < end)\n+        {\n+            accumulated += it->second;\n+\n+            while (accumulated >= threshold)\n+            {\n+                result[indices[level_index]] = it->first;\n+                ++level_index;\n+\n+                if (level_index == num_levels)\n+                    return;\n+\n+                threshold = std::ceil(sum_weight * levels[indices[level_index]]);\n+            }\n+\n+            ++it;\n+        }\n+\n+        while (level_index < num_levels)\n+        {\n+            result[indices[level_index]] = array[size - 1].first;\n+            ++level_index;\n+        }\n+    }\n+\n+    /// The same, but in the case of an empty state, NaN is returned.\n+    Float64 getFloat(Float64) const\n+    {\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getFloat is not implemented for QuantileExact\");\n+    }\n+\n+    void getManyFloat(const Float64 *, const size_t *, size_t, Float64 *) const\n+    {\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getManyFloat is not implemented for QuantileExact\");\n+    }\n+};\n+\n+\n+template <typename Value, bool _> using FuncQuantileExactWeighted = AggregateFunctionQuantile<Value, QuantileExactWeighted<Value>, NameQuantileExactWeighted, true, void, false, false>;\n+template <typename Value, bool _> using FuncQuantilesExactWeighted = AggregateFunctionQuantile<Value, QuantileExactWeighted<Value>, NameQuantilesExactWeighted, true, void, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/QuantileApprox.h b/src/AggregateFunctions/AggregateFunctionQuantileGK.cpp\nsimilarity index 82%\nrename from src/AggregateFunctions/QuantileApprox.h\nrename to src/AggregateFunctions/AggregateFunctionQuantileGK.cpp\nindex 6b2a6cf43984..2c0b3e551365 100644\n--- a/src/AggregateFunctions/QuantileApprox.h\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileGK.cpp\n@@ -1,22 +1,29 @@\n-#pragma once\n-\n+#include <AggregateFunctions/AggregateFunctionQuantile.h>\n+#include <AggregateFunctions/AggregateFunctionFactory.h>\n+#include <AggregateFunctions/Helpers.h>\n+#include <DataTypes/DataTypeDate.h>\n+#include <DataTypes/DataTypeDateTime.h>\n+#include <Core/Field.h>\n #include <cmath>\n-#include <base/sort.h>\n #include <Common/RadixSort.h>\n #include <IO/WriteBuffer.h>\n #include <IO/ReadBuffer.h>\n #include <IO/WriteHelpers.h>\n #include <IO/ReadHelpers.h>\n \n-\n namespace DB\n {\n+\n namespace ErrorCodes\n {\n+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n     extern const int LOGICAL_ERROR;\n     extern const int NOT_IMPLEMENTED;\n }\n \n+namespace\n+{\n+\n template <typename T>\n class ApproxSampler\n {\n@@ -474,4 +481,56 @@ class QuantileGK\n     }\n };\n \n+\n+template <typename Value, bool _> using FuncQuantileGK = AggregateFunctionQuantile<Value, QuantileGK<Value>, NameQuantileGK, false, void, false, true>;\n+template <typename Value, bool _> using FuncQuantilesGK = AggregateFunctionQuantile<Value, QuantileGK<Value>, NameQuantilesGK, false, void, true, true>;\n+\n+template <template <typename, bool> class Function>\n+AggregateFunctionPtr createAggregateFunctionQuantile(\n+    const std::string & name, const DataTypes & argument_types, const Array & params, const Settings *)\n+{\n+    /// Second argument type check doesn't depend on the type of the first one.\n+    Function<void, true>::assertSecondArg(argument_types);\n+\n+    const DataTypePtr & argument_type = argument_types[0];\n+    WhichDataType which(argument_type);\n+\n+#define DISPATCH(TYPE) \\\n+    if (which.idx == TypeIndex::TYPE) \\\n+        return std::make_shared<Function<TYPE, true>>(argument_types, params);\n+    FOR_BASIC_NUMERIC_TYPES(DISPATCH)\n+#undef DISPATCH\n+\n+    if (which.idx == TypeIndex::Date) return std::make_shared<Function<DataTypeDate::FieldType, false>>(argument_types, params);\n+    if (which.idx == TypeIndex::DateTime) return std::make_shared<Function<DataTypeDateTime::FieldType, false>>(argument_types, params);\n+\n+    if (which.idx == TypeIndex::Decimal32) return std::make_shared<Function<Decimal32, false>>(argument_types, params);\n+    if (which.idx == TypeIndex::Decimal64) return std::make_shared<Function<Decimal64, false>>(argument_types, params);\n+    if (which.idx == TypeIndex::Decimal128) return std::make_shared<Function<Decimal128, false>>(argument_types, params);\n+    if (which.idx == TypeIndex::Decimal256) return std::make_shared<Function<Decimal256, false>>(argument_types, params);\n+    if (which.idx == TypeIndex::DateTime64) return std::make_shared<Function<DateTime64, false>>(argument_types, params);\n+\n+    if (which.idx == TypeIndex::Int128) return std::make_shared<Function<Int128, true>>(argument_types, params);\n+    if (which.idx == TypeIndex::UInt128) return std::make_shared<Function<UInt128, true>>(argument_types, params);\n+    if (which.idx == TypeIndex::Int256) return std::make_shared<Function<Int256, true>>(argument_types, params);\n+    if (which.idx == TypeIndex::UInt256) return std::make_shared<Function<UInt256, true>>(argument_types, params);\n+\n+    throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n+                    argument_type->getName(), name);\n+}\n+\n+}\n+\n+void registerAggregateFunctionsQuantileApprox(AggregateFunctionFactory & factory)\n+{\n+    /// For aggregate functions returning array we cannot return NULL on empty set.\n+    AggregateFunctionProperties properties = { .returns_default_when_only_null = true };\n+\n+    factory.registerFunction(NameQuantileGK::name, createAggregateFunctionQuantile<FuncQuantileGK>);\n+    factory.registerFunction(NameQuantilesGK::name, {createAggregateFunctionQuantile<FuncQuantilesGK>, properties});\n+\n+    /// 'median' is an alias for 'quantile'\n+    factory.registerAlias(\"medianGK\", NameQuantileGK::name);\n+}\n+\n }\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileInterpolatedWeighted.cpp b/src/AggregateFunctions/AggregateFunctionQuantileInterpolatedWeighted.cpp\nindex a71993043e76..2b8b72a549aa 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileInterpolatedWeighted.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileInterpolatedWeighted.cpp\n@@ -1,58 +1,353 @@\n #include <AggregateFunctions/AggregateFunctionQuantile.h>\n-#include <AggregateFunctions/QuantileInterpolatedWeighted.h>\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n #include <AggregateFunctions/Helpers.h>\n #include <DataTypes/DataTypeDate.h>\n #include <DataTypes/DataTypeDateTime.h>\n #include <Core/Field.h>\n+#include <Common/HashTable/HashMap.h>\n+#include <Common/NaNUtils.h>\n \n \n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n {\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int NOT_IMPLEMENTED;\n }\n \n namespace\n {\n \n-    template <typename Value, bool _> using FuncQuantileInterpolatedWeighted = AggregateFunctionQuantile<Value, QuantileInterpolatedWeighted<Value>, NameQuantileInterpolatedWeighted, true, void, false>;\n-    template <typename Value, bool _> using FuncQuantilesInterpolatedWeighted = AggregateFunctionQuantile<Value, QuantileInterpolatedWeighted<Value>, NameQuantilesInterpolatedWeighted, true, void, true>;\n+/** Approximates Quantile by:\n+  * - sorting input values and weights\n+  * - building a cumulative distribution based on weights\n+  * - performing linear interpolation between the weights and values\n+  *\n+  */\n+template <typename Value>\n+struct QuantileInterpolatedWeighted\n+{\n+    struct Int128Hash\n+    {\n+        size_t operator()(Int128 x) const\n+        {\n+            return CityHash_v1_0_2::Hash128to64({x >> 64, x & 0xffffffffffffffffll});\n+        }\n+    };\n+\n+    using Weight = UInt64;\n+    using UnderlyingType = NativeType<Value>;\n+    using Hasher = HashCRC32<UnderlyingType>;\n+\n+    /// When creating, the hash table must be small.\n+    using Map = HashMapWithStackMemory<UnderlyingType, Weight, Hasher, 4>;\n+\n+    Map map;\n+\n+    void add(const Value & x)\n+    {\n+        /// We must skip NaNs as they are not compatible with comparison sorting.\n+        if (!isNaN(x))\n+            ++map[x];\n+    }\n+\n+    void add(const Value & x, Weight weight)\n+    {\n+        if (!isNaN(x))\n+            map[x] += weight;\n+    }\n+\n+    void merge(const QuantileInterpolatedWeighted & rhs)\n+    {\n+        for (const auto & pair : rhs.map)\n+            map[pair.getKey()] += pair.getMapped();\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        map.write(buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        typename Map::Reader reader(buf);\n+        while (reader.next())\n+        {\n+            const auto & pair = reader.get();\n+            map[pair.first] = pair.second;\n+        }\n+    }\n+\n+    Value get(Float64 level) const\n+    {\n+        return getImpl<Value>(level);\n+    }\n+\n+    void getMany(const Float64 * levels, const size_t * indices, size_t size, Value * result) const\n+    {\n+        getManyImpl<Value>(levels, indices, size, result);\n+    }\n \n-    template <template <typename, bool> class Function>\n-    AggregateFunctionPtr createAggregateFunctionQuantile(\n-        const std::string & name, const DataTypes & argument_types, const Array & params, const Settings *)\n+    /// The same, but in the case of an empty state, NaN is returned.\n+    Float64 getFloat(Float64) const\n     {\n-        /// Second argument type check doesn't depend on the type of the first one.\n-        Function<void, true>::assertSecondArg(argument_types);\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getFloat is not implemented for QuantileInterpolatedWeighted\");\n+    }\n+\n+    void getManyFloat(const Float64 *, const size_t *, size_t, Float64 *) const\n+    {\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getManyFloat is not implemented for QuantileInterpolatedWeighted\");\n+    }\n+\n+private:\n+    using Pair = typename std::pair<UnderlyingType, Float64>;\n+\n+    /// Get the value of the `level` quantile. The level must be between 0 and 1.\n+    template <typename T>\n+    T getImpl(Float64 level) const\n+    {\n+        size_t size = map.size();\n+\n+        if (0 == size)\n+            return std::numeric_limits<Value>::quiet_NaN();\n+\n+        /// Maintain a vector of pair of values and weights for easier sorting and for building\n+        /// a cumulative distribution using the provided weights.\n+        std::vector<Pair> value_weight_pairs;\n+        value_weight_pairs.reserve(size);\n+\n+        /// Note: weight provided must be a 64-bit integer\n+        /// Float64 is used as accumulator here to get approximate results.\n+        /// But weight used in the internal array is stored as Float64 as we\n+        /// do some quantile estimation operation which involves division and\n+        /// require Float64 level of precision.\n+\n+        Float64 sum_weight = 0;\n+        for (const auto & pair : map)\n+        {\n+            sum_weight += pair.getMapped();\n+            auto value = pair.getKey();\n+            auto weight = pair.getMapped();\n+            value_weight_pairs.push_back({value, weight});\n+        }\n+\n+        ::sort(value_weight_pairs.begin(), value_weight_pairs.end(), [](const Pair & a, const Pair & b) { return a.first < b.first; });\n+\n+        Float64 accumulated = 0;\n+\n+        /// vector for populating and storing the cumulative sum using the provided weights.\n+        /// example: [0,1,2,3,4,5] -> [0,1,3,6,10,15]\n+        std::vector<Float64> weights_cum_sum;\n+        weights_cum_sum.reserve(size);\n+\n+        for (size_t idx = 0; idx < size; ++idx)\n+        {\n+            accumulated += value_weight_pairs[idx].second;\n+            weights_cum_sum.push_back(accumulated);\n+        }\n \n-        const DataTypePtr & argument_type = argument_types[0];\n-        WhichDataType which(argument_type);\n+        /// The following estimation of quantile is general and the idea is:\n+        /// https://en.wikipedia.org/wiki/Percentile#The_weighted_percentile_method\n+\n+        /// calculates a simple cumulative distribution based on weights\n+        if (sum_weight != 0)\n+        {\n+            for (size_t idx = 0; idx < size; ++idx)\n+                value_weight_pairs[idx].second = (weights_cum_sum[idx] - 0.5 * value_weight_pairs[idx].second) / sum_weight;\n+        }\n+\n+        /// perform linear interpolation\n+        size_t idx = 0;\n+        if (size >= 2)\n+        {\n+            if (level >= value_weight_pairs[size - 2].second)\n+            {\n+                idx = size - 2;\n+            }\n+            else\n+            {\n+                size_t start = 0, end = size - 1;\n+                while (start <= end)\n+                {\n+                    size_t mid = start + (end - start) / 2;\n+                    if (mid > size)\n+                        break;\n+                    if (level > value_weight_pairs[mid + 1].second)\n+                        start = mid + 1;\n+                    else\n+                    {\n+                        idx = mid;\n+                        end = mid - 1;\n+                    }\n+                }\n+            }\n+        }\n+\n+        size_t l = idx;\n+        size_t u = idx + 1 < size ? idx + 1 : idx;\n+\n+        Float64 xl = value_weight_pairs[l].second, xr = value_weight_pairs[u].second;\n+        UnderlyingType yl = value_weight_pairs[l].first, yr = value_weight_pairs[u].first;\n+\n+        if (level < xl)\n+            yr = yl;\n+        if (level > xr)\n+            yl = yr;\n+\n+        return static_cast<T>(interpolate(level, xl, xr, yl, yr));\n+    }\n+\n+    /// Get the `size` values of `levels` quantiles. Write `size` results starting with `result` address.\n+    /// indices - an array of index levels such that the corresponding elements will go in ascending order.\n+    template <typename T>\n+    void getManyImpl(const Float64 * levels, const size_t * indices, size_t num_levels, Value * result) const\n+    {\n+        size_t size = map.size();\n+\n+        if (0 == size)\n+        {\n+            for (size_t i = 0; i < num_levels; ++i)\n+                result[i] = Value();\n+            return;\n+        }\n+\n+        std::vector<Pair> value_weight_pairs;\n+        value_weight_pairs.reserve(size);\n+\n+        Float64 sum_weight = 0;\n+        for (const auto & pair : map)\n+        {\n+            sum_weight += pair.getMapped();\n+            auto value = pair.getKey();\n+            auto weight = pair.getMapped();\n+            value_weight_pairs.push_back({value, weight});\n+        }\n+\n+        ::sort(value_weight_pairs.begin(), value_weight_pairs.end(), [](const Pair & a, const Pair & b) { return a.first < b.first; });\n+\n+        Float64 accumulated = 0;\n+\n+        /// vector for populating and storing the cumulative sum using the provided weights.\n+        /// example: [0,1,2,3,4,5] -> [0,1,3,6,10,15]\n+        std::vector<Float64> weights_cum_sum;\n+        weights_cum_sum.reserve(size);\n+\n+        for (size_t idx = 0; idx < size; ++idx)\n+        {\n+            accumulated += value_weight_pairs[idx].second;\n+            weights_cum_sum.emplace_back(accumulated);\n+        }\n+\n+\n+        /// The following estimation of quantile is general and the idea is:\n+        /// https://en.wikipedia.org/wiki/Percentile#The_weighted_percentile_method\n+\n+        /// calculates a simple cumulative distribution based on weights\n+        if (sum_weight != 0)\n+        {\n+            for (size_t idx = 0; idx < size; ++idx)\n+                value_weight_pairs[idx].second = (weights_cum_sum[idx] - 0.5 * value_weight_pairs[idx].second) / sum_weight;\n+        }\n+\n+        for (size_t level_index = 0; level_index < num_levels; ++level_index)\n+        {\n+            /// perform linear interpolation for every level\n+            auto level = levels[indices[level_index]];\n+\n+            size_t idx = 0;\n+            if (size >= 2)\n+            {\n+                if (level >= value_weight_pairs[size - 2].second)\n+                {\n+                    idx = size - 2;\n+                }\n+                else\n+                {\n+                    size_t start = 0, end = size - 1;\n+                    while (start <= end)\n+                    {\n+                        size_t mid = start + (end - start) / 2;\n+                        if (mid > size)\n+                            break;\n+                        if (level > value_weight_pairs[mid + 1].second)\n+                            start = mid + 1;\n+                        else\n+                        {\n+                            idx = mid;\n+                            end = mid - 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            size_t l = idx;\n+            size_t u = idx + 1 < size ? idx + 1 : idx;\n+\n+            Float64 xl = value_weight_pairs[l].second, xr = value_weight_pairs[u].second;\n+            UnderlyingType yl = value_weight_pairs[l].first, yr = value_weight_pairs[u].first;\n+\n+            if (level < xl)\n+                yr = yl;\n+            if (level > xr)\n+                yl = yr;\n+\n+            result[indices[level_index]] = static_cast<T>(interpolate(level, xl, xr, yl, yr));\n+        }\n+    }\n+\n+    /// This ignores overflows or NaN's that might arise during add, sub and mul operations and doesn't aim to provide exact\n+    /// results since `the quantileInterpolatedWeighted` function itself relies mainly on approximation.\n+    UnderlyingType NO_SANITIZE_UNDEFINED interpolate(Float64 level, Float64 xl, Float64 xr, UnderlyingType yl, UnderlyingType yr) const\n+    {\n+        UnderlyingType dy = yr - yl;\n+        Float64 dx = xr - xl;\n+        dx = dx == 0 ? 1 : dx; /// to handle NaN behavior that might arise during integer division below.\n+\n+        /// yl + (dy / dx) * (level - xl)\n+        return static_cast<UnderlyingType>(yl + (dy / dx) * (level - xl));\n+    }\n+};\n+\n+\n+template <typename Value, bool _> using FuncQuantileInterpolatedWeighted = AggregateFunctionQuantile<Value, QuantileInterpolatedWeighted<Value>, NameQuantileInterpolatedWeighted, true, void, false, false>;\n+template <typename Value, bool _> using FuncQuantilesInterpolatedWeighted = AggregateFunctionQuantile<Value, QuantileInterpolatedWeighted<Value>, NameQuantilesInterpolatedWeighted, true, void, true, false>;\n+\n+template <template <typename, bool> class Function>\n+AggregateFunctionPtr createAggregateFunctionQuantile(\n+    const std::string & name, const DataTypes & argument_types, const Array & params, const Settings *)\n+{\n+    /// Second argument type check doesn't depend on the type of the first one.\n+    Function<void, true>::assertSecondArg(argument_types);\n+\n+    const DataTypePtr & argument_type = argument_types[0];\n+    WhichDataType which(argument_type);\n \n #define DISPATCH(TYPE) \\\n-    if (which.idx == TypeIndex::TYPE) return std::make_shared<Function<TYPE, true>>(argument_types, params);\n-        FOR_BASIC_NUMERIC_TYPES(DISPATCH)\n+if (which.idx == TypeIndex::TYPE) return std::make_shared<Function<TYPE, true>>(argument_types, params);\n+    FOR_BASIC_NUMERIC_TYPES(DISPATCH)\n #undef DISPATCH\n-        if (which.idx == TypeIndex::Date) return std::make_shared<Function<DataTypeDate::FieldType, false>>(argument_types, params);\n-        if (which.idx == TypeIndex::DateTime) return std::make_shared<Function<DataTypeDateTime::FieldType, false>>(argument_types, params);\n-\n-        if (which.idx == TypeIndex::Decimal32) return std::make_shared<Function<Decimal32, false>>(argument_types, params);\n-        if (which.idx == TypeIndex::Decimal64) return std::make_shared<Function<Decimal64, false>>(argument_types, params);\n-        if (which.idx == TypeIndex::Decimal128) return std::make_shared<Function<Decimal128, false>>(argument_types, params);\n-        if (which.idx == TypeIndex::Decimal256) return std::make_shared<Function<Decimal256, false>>(argument_types, params);\n-        if (which.idx == TypeIndex::DateTime64) return std::make_shared<Function<DateTime64, false>>(argument_types, params);\n-\n-        if (which.idx == TypeIndex::Int128) return std::make_shared<Function<Int128, true>>(argument_types, params);\n-        if (which.idx == TypeIndex::UInt128) return std::make_shared<Function<UInt128, true>>(argument_types, params);\n-        if (which.idx == TypeIndex::Int256) return std::make_shared<Function<Int256, true>>(argument_types, params);\n-        if (which.idx == TypeIndex::UInt256) return std::make_shared<Function<UInt256, true>>(argument_types, params);\n-\n-        throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n-                        argument_type->getName(), name);\n-    }\n+    if (which.idx == TypeIndex::Date) return std::make_shared<Function<DataTypeDate::FieldType, false>>(argument_types, params);\n+    if (which.idx == TypeIndex::DateTime) return std::make_shared<Function<DataTypeDateTime::FieldType, false>>(argument_types, params);\n+\n+    if (which.idx == TypeIndex::Decimal32) return std::make_shared<Function<Decimal32, false>>(argument_types, params);\n+    if (which.idx == TypeIndex::Decimal64) return std::make_shared<Function<Decimal64, false>>(argument_types, params);\n+    if (which.idx == TypeIndex::Decimal128) return std::make_shared<Function<Decimal128, false>>(argument_types, params);\n+    if (which.idx == TypeIndex::Decimal256) return std::make_shared<Function<Decimal256, false>>(argument_types, params);\n+    if (which.idx == TypeIndex::DateTime64) return std::make_shared<Function<DateTime64, false>>(argument_types, params);\n+\n+    if (which.idx == TypeIndex::Int128) return std::make_shared<Function<Int128, true>>(argument_types, params);\n+    if (which.idx == TypeIndex::UInt128) return std::make_shared<Function<UInt128, true>>(argument_types, params);\n+    if (which.idx == TypeIndex::Int256) return std::make_shared<Function<Int256, true>>(argument_types, params);\n+    if (which.idx == TypeIndex::UInt256) return std::make_shared<Function<UInt256, true>>(argument_types, params);\n+\n+    throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type {} of argument for aggregate function {}\",\n+                    argument_type->getName(), name);\n+}\n+\n }\n \n void registerAggregateFunctionsQuantileInterpolatedWeighted(AggregateFunctionFactory & factory)\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileTDigest.cpp b/src/AggregateFunctions/AggregateFunctionQuantileTDigest.cpp\nindex 79e34f473193..e3896ffb0d7b 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileTDigest.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileTDigest.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool float_return> using FuncQuantileTDigest = AggregateFunctionQuantile<Value, QuantileTDigest<Value>, NameQuantileTDigest, false, std::conditional_t<float_return, Float32, void>, false>;\n-template <typename Value, bool float_return> using FuncQuantilesTDigest = AggregateFunctionQuantile<Value, QuantileTDigest<Value>, NameQuantilesTDigest, false, std::conditional_t<float_return, Float32, void>, true>;\n+template <typename Value, bool float_return> using FuncQuantileTDigest = AggregateFunctionQuantile<Value, QuantileTDigest<Value>, NameQuantileTDigest, false, std::conditional_t<float_return, Float32, void>, false, false>;\n+template <typename Value, bool float_return> using FuncQuantilesTDigest = AggregateFunctionQuantile<Value, QuantileTDigest<Value>, NameQuantilesTDigest, false, std::conditional_t<float_return, Float32, void>, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileTDigestWeighted.cpp b/src/AggregateFunctions/AggregateFunctionQuantileTDigestWeighted.cpp\nindex a9c07343fa5e..56d5fd364124 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileTDigestWeighted.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileTDigestWeighted.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool float_return> using FuncQuantileTDigestWeighted = AggregateFunctionQuantile<Value, QuantileTDigest<Value>, NameQuantileTDigestWeighted, true, std::conditional_t<float_return, Float32, void>, false>;\n-template <typename Value, bool float_return> using FuncQuantilesTDigestWeighted = AggregateFunctionQuantile<Value, QuantileTDigest<Value>, NameQuantilesTDigestWeighted, true, std::conditional_t<float_return, Float32, void>, true>;\n+template <typename Value, bool float_return> using FuncQuantileTDigestWeighted = AggregateFunctionQuantile<Value, QuantileTDigest<Value>, NameQuantileTDigestWeighted, true, std::conditional_t<float_return, Float32, void>, false, false>;\n+template <typename Value, bool float_return> using FuncQuantilesTDigestWeighted = AggregateFunctionQuantile<Value, QuantileTDigest<Value>, NameQuantilesTDigestWeighted, true, std::conditional_t<float_return, Float32, void>, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileTiming.cpp b/src/AggregateFunctions/AggregateFunctionQuantileTiming.cpp\nindex 553123f3e795..b3fbd50b6e27 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileTiming.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileTiming.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool _> using FuncQuantileTiming = AggregateFunctionQuantile<Value, QuantileTiming<Value>, NameQuantileTiming, false, Float32, false>;\n-template <typename Value, bool _> using FuncQuantilesTiming = AggregateFunctionQuantile<Value, QuantileTiming<Value>, NameQuantilesTiming, false, Float32, true>;\n+template <typename Value, bool _> using FuncQuantileTiming = AggregateFunctionQuantile<Value, QuantileTiming<Value>, NameQuantileTiming, false, Float32, false, false>;\n+template <typename Value, bool _> using FuncQuantilesTiming = AggregateFunctionQuantile<Value, QuantileTiming<Value>, NameQuantilesTiming, false, Float32, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionQuantileTimingWeighted.cpp b/src/AggregateFunctions/AggregateFunctionQuantileTimingWeighted.cpp\nindex e2d7aaf76039..7bbba7283133 100644\n--- a/src/AggregateFunctions/AggregateFunctionQuantileTimingWeighted.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionQuantileTimingWeighted.cpp\n@@ -19,8 +19,8 @@ namespace ErrorCodes\n namespace\n {\n \n-template <typename Value, bool _> using FuncQuantileTimingWeighted = AggregateFunctionQuantile<Value, QuantileTiming<Value>, NameQuantileTimingWeighted, true, Float32, false>;\n-template <typename Value, bool _> using FuncQuantilesTimingWeighted = AggregateFunctionQuantile<Value, QuantileTiming<Value>, NameQuantilesTimingWeighted, true, Float32, true>;\n+template <typename Value, bool _> using FuncQuantileTimingWeighted = AggregateFunctionQuantile<Value, QuantileTiming<Value>, NameQuantileTimingWeighted, true, Float32, false, false>;\n+template <typename Value, bool _> using FuncQuantilesTimingWeighted = AggregateFunctionQuantile<Value, QuantileTiming<Value>, NameQuantilesTimingWeighted, true, Float32, true, false>;\n \n template <template <typename, bool> class Function>\n AggregateFunctionPtr createAggregateFunctionQuantile(\ndiff --git a/src/AggregateFunctions/AggregateFunctionRankCorrelation.cpp b/src/AggregateFunctions/AggregateFunctionRankCorrelation.cpp\nindex 56eb3437a05e..d338808c7170 100644\n--- a/src/AggregateFunctions/AggregateFunctionRankCorrelation.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionRankCorrelation.cpp\n@@ -1,7 +1,13 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionRankCorrelation.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n-#include <AggregateFunctions/Helpers.h>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/StatCommon.h>\n+#include <Columns/ColumnVector.h>\n+#include <Columns/ColumnTuple.h>\n+#include <Common/assert_cast.h>\n+#include <Common/PODArray_fwd.h>\n+#include <DataTypes/DataTypeNullable.h>\n+#include <DataTypes/DataTypesNumber.h>\n \n \n namespace ErrorCodes\n@@ -16,6 +22,83 @@ struct Settings;\n namespace\n {\n \n+struct RankCorrelationData : public StatisticalSample<Float64, Float64>\n+{\n+    Float64 getResult()\n+    {\n+        RanksArray ranks_x;\n+        std::tie(ranks_x, std::ignore) = computeRanksAndTieCorrection(this->x);\n+\n+        RanksArray ranks_y;\n+        std::tie(ranks_y, std::ignore) = computeRanksAndTieCorrection(this->y);\n+\n+        /// Sizes can be non-equal due to skipped NaNs.\n+        const Float64 size = static_cast<Float64>(std::min(this->size_x, this->size_y));\n+\n+        /// Count d^2 sum\n+        Float64 answer = 0;\n+        for (size_t j = 0; j < size; ++j)\n+            answer += (ranks_x[j] - ranks_y[j]) * (ranks_x[j] - ranks_y[j]);\n+\n+        answer *= 6;\n+        answer /= size * (size * size - 1);\n+        answer = 1 - answer;\n+        return answer;\n+    }\n+};\n+\n+class AggregateFunctionRankCorrelation :\n+    public IAggregateFunctionDataHelper<RankCorrelationData, AggregateFunctionRankCorrelation>\n+{\n+public:\n+    explicit AggregateFunctionRankCorrelation(const DataTypes & arguments)\n+        : IAggregateFunctionDataHelper<RankCorrelationData, AggregateFunctionRankCorrelation> ({arguments}, {}, std::make_shared<DataTypeNumber<Float64>>())\n+    {}\n+\n+    String getName() const override\n+    {\n+        return \"rankCorr\";\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return true; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        Float64 new_x = columns[0]->getFloat64(row_num);\n+        Float64 new_y = columns[1]->getFloat64(row_num);\n+        this->data(place).addX(new_x, arena);\n+        this->data(place).addY(new_y, arena);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n+    {\n+        auto & a = this->data(place);\n+        const auto & b = this->data(rhs);\n+\n+        a.merge(b, arena);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).write(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n+    {\n+        this->data(place).read(buf, arena);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        auto answer = this->data(place).getResult();\n+\n+        auto & column = static_cast<ColumnVector<Float64> &>(to);\n+        column.getData().push_back(answer);\n+    }\n+\n+};\n+\n+\n AggregateFunctionPtr createAggregateFunctionRankCorrelation(\n     const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n {\ndiff --git a/src/AggregateFunctions/AggregateFunctionRankCorrelation.h b/src/AggregateFunctions/AggregateFunctionRankCorrelation.h\ndeleted file mode 100644\nindex 4f7d04100cf5..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionRankCorrelation.h\n+++ /dev/null\n@@ -1,98 +0,0 @@\n-#pragma once\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/StatCommon.h>\n-#include <Columns/ColumnArray.h>\n-#include <Columns/ColumnVector.h>\n-#include <Columns/ColumnTuple.h>\n-#include <Common/assert_cast.h>\n-#include <Common/PODArray_fwd.h>\n-#include <base/types.h>\n-#include <DataTypes/DataTypesDecimal.h>\n-#include <DataTypes/DataTypeNullable.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <DataTypes/DataTypeArray.h>\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-\n-struct RankCorrelationData : public StatisticalSample<Float64, Float64>\n-{\n-    Float64 getResult()\n-    {\n-        RanksArray ranks_x;\n-        std::tie(ranks_x, std::ignore) = computeRanksAndTieCorrection(this->x);\n-\n-        RanksArray ranks_y;\n-        std::tie(ranks_y, std::ignore) = computeRanksAndTieCorrection(this->y);\n-\n-        /// Sizes can be non-equal due to skipped NaNs.\n-        const Float64 size = static_cast<Float64>(std::min(this->size_x, this->size_y));\n-\n-        /// Count d^2 sum\n-        Float64 answer = 0;\n-        for (size_t j = 0; j < size; ++j)\n-            answer += (ranks_x[j] - ranks_y[j]) * (ranks_x[j] - ranks_y[j]);\n-\n-        answer *= 6;\n-        answer /= size * (size * size - 1);\n-        answer = 1 - answer;\n-        return answer;\n-    }\n-};\n-\n-class AggregateFunctionRankCorrelation :\n-    public IAggregateFunctionDataHelper<RankCorrelationData, AggregateFunctionRankCorrelation>\n-{\n-public:\n-    explicit AggregateFunctionRankCorrelation(const DataTypes & arguments)\n-        :IAggregateFunctionDataHelper<RankCorrelationData, AggregateFunctionRankCorrelation> ({arguments}, {}, std::make_shared<DataTypeNumber<Float64>>())\n-    {}\n-\n-    String getName() const override\n-    {\n-        return \"rankCorr\";\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return true; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        Float64 new_x = columns[0]->getFloat64(row_num);\n-        Float64 new_y = columns[1]->getFloat64(row_num);\n-        this->data(place).addX(new_x, arena);\n-        this->data(place).addY(new_y, arena);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n-    {\n-        auto & a = this->data(place);\n-        const auto & b = this->data(rhs);\n-\n-        a.merge(b, arena);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        this->data(place).read(buf, arena);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        auto answer = this->data(place).getResult();\n-\n-        auto & column = static_cast<ColumnVector<Float64> &>(to);\n-        column.getData().push_back(answer);\n-    }\n-\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionRetention.cpp b/src/AggregateFunctions/AggregateFunctionRetention.cpp\nindex f037696b2056..a004f3527a2d 100644\n--- a/src/AggregateFunctions/AggregateFunctionRetention.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionRetention.cpp\n@@ -1,21 +1,150 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionRetention.h>\n-#include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n \n+#include <unordered_set>\n+#include <Columns/ColumnArray.h>\n+#include <Common/assert_cast.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeArray.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+#include <bitset>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+\n \n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n {\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n }\n \n namespace\n {\n \n+struct AggregateFunctionRetentionData\n+{\n+    static constexpr auto max_events = 32;\n+\n+    using Events = std::bitset<max_events>;\n+\n+    Events events;\n+\n+    void add(UInt8 event)\n+    {\n+        events.set(event);\n+    }\n+\n+    void merge(const AggregateFunctionRetentionData & other)\n+    {\n+        events |= other.events;\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        UInt32 event_value = static_cast<UInt32>(events.to_ulong());\n+        writeBinary(event_value, buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        UInt32 event_value;\n+        readBinary(event_value, buf);\n+        events = event_value;\n+    }\n+};\n+\n+/**\n+  * The max size of events is 32, that's enough for retention analytics\n+  *\n+  * Usage:\n+  * - retention(cond1, cond2, cond3, ....)\n+  * - returns [cond1_flag, cond1_flag && cond2_flag, cond1_flag && cond3_flag, ...]\n+  */\n+class AggregateFunctionRetention final\n+        : public IAggregateFunctionDataHelper<AggregateFunctionRetentionData, AggregateFunctionRetention>\n+{\n+private:\n+    UInt8 events_size;\n+\n+public:\n+    String getName() const override\n+    {\n+        return \"retention\";\n+    }\n+\n+    explicit AggregateFunctionRetention(const DataTypes & arguments)\n+        : IAggregateFunctionDataHelper<AggregateFunctionRetentionData, AggregateFunctionRetention>(arguments, {}, std::make_shared<DataTypeArray>(std::make_shared<DataTypeUInt8>()))\n+    {\n+        for (const auto i : collections::range(0, arguments.size()))\n+        {\n+            const auto * cond_arg = arguments[i].get();\n+            if (!isUInt8(cond_arg))\n+                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+                                \"Illegal type {} of argument {} of aggregate function {}, must be UInt8\",\n+                                cond_arg->getName(), i, getName());\n+        }\n+\n+        events_size = static_cast<UInt8>(arguments.size());\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, const size_t row_num, Arena *) const override\n+    {\n+        for (const auto i : collections::range(0, events_size))\n+        {\n+            auto event = assert_cast<const ColumnVector<UInt8> *>(columns[i])->getData()[row_num];\n+            if (event)\n+            {\n+                this->data(place).add(i);\n+            }\n+        }\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        auto & data_to = assert_cast<ColumnUInt8 &>(assert_cast<ColumnArray &>(to).getData()).getData();\n+        auto & offsets_to = assert_cast<ColumnArray &>(to).getOffsets();\n+\n+        ColumnArray::Offset current_offset = data_to.size();\n+        data_to.resize(current_offset + events_size);\n+\n+        const bool first_flag = this->data(place).events.test(0);\n+        data_to[current_offset] = first_flag;\n+        ++current_offset;\n+\n+        for (size_t i = 1; i < events_size; ++i)\n+        {\n+            data_to[current_offset] = (first_flag && this->data(place).events.test(i));\n+            ++current_offset;\n+        }\n+\n+        offsets_to.push_back(current_offset);\n+    }\n+};\n+\n+\n AggregateFunctionPtr createAggregateFunctionRetention(const std::string & name, const DataTypes & arguments, const Array & params, const Settings *)\n {\n     assertNoParameters(name, params);\ndiff --git a/src/AggregateFunctions/AggregateFunctionRetention.h b/src/AggregateFunctions/AggregateFunctionRetention.h\ndeleted file mode 100644\nindex 63ff5921540a..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionRetention.h\n+++ /dev/null\n@@ -1,143 +0,0 @@\n-#pragma once\n-\n-#include <unordered_set>\n-#include <Columns/ColumnsNumber.h>\n-#include <Columns/ColumnArray.h>\n-#include <Common/assert_cast.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeArray.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <base/range.h>\n-#include <bitset>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-}\n-\n-struct AggregateFunctionRetentionData\n-{\n-    static constexpr auto max_events = 32;\n-\n-    using Events = std::bitset<max_events>;\n-\n-    Events events;\n-\n-    void add(UInt8 event)\n-    {\n-        events.set(event);\n-    }\n-\n-    void merge(const AggregateFunctionRetentionData & other)\n-    {\n-        events |= other.events;\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        UInt32 event_value = static_cast<UInt32>(events.to_ulong());\n-        writeBinary(event_value, buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        UInt32 event_value;\n-        readBinary(event_value, buf);\n-        events = event_value;\n-    }\n-};\n-\n-/**\n-  * The max size of events is 32, that's enough for retention analytics\n-  *\n-  * Usage:\n-  * - retention(cond1, cond2, cond3, ....)\n-  * - returns [cond1_flag, cond1_flag && cond2_flag, cond1_flag && cond3_flag, ...]\n-  */\n-class AggregateFunctionRetention final\n-        : public IAggregateFunctionDataHelper<AggregateFunctionRetentionData, AggregateFunctionRetention>\n-{\n-private:\n-    UInt8 events_size;\n-\n-public:\n-    String getName() const override\n-    {\n-        return \"retention\";\n-    }\n-\n-    explicit AggregateFunctionRetention(const DataTypes & arguments)\n-        : IAggregateFunctionDataHelper<AggregateFunctionRetentionData, AggregateFunctionRetention>(arguments, {}, std::make_shared<DataTypeArray>(std::make_shared<DataTypeUInt8>()))\n-    {\n-        for (const auto i : collections::range(0, arguments.size()))\n-        {\n-            const auto * cond_arg = arguments[i].get();\n-            if (!isUInt8(cond_arg))\n-                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                                \"Illegal type {} of argument {} of aggregate function {}, must be UInt8\",\n-                                cond_arg->getName(), i, getName());\n-        }\n-\n-        events_size = static_cast<UInt8>(arguments.size());\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, const size_t row_num, Arena *) const override\n-    {\n-        for (const auto i : collections::range(0, events_size))\n-        {\n-            auto event = assert_cast<const ColumnVector<UInt8> *>(columns[i])->getData()[row_num];\n-            if (event)\n-            {\n-                this->data(place).add(i);\n-            }\n-        }\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).deserialize(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        auto & data_to = assert_cast<ColumnUInt8 &>(assert_cast<ColumnArray &>(to).getData()).getData();\n-        auto & offsets_to = assert_cast<ColumnArray &>(to).getOffsets();\n-\n-        ColumnArray::Offset current_offset = data_to.size();\n-        data_to.resize(current_offset + events_size);\n-\n-        const bool first_flag = this->data(place).events.test(0);\n-        data_to[current_offset] = first_flag;\n-        ++current_offset;\n-\n-        for (size_t i = 1; i < events_size; ++i)\n-        {\n-            data_to[current_offset] = (first_flag && this->data(place).events.test(i));\n-            ++current_offset;\n-        }\n-\n-        offsets_to.push_back(current_offset);\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionSequenceMatch.cpp b/src/AggregateFunctions/AggregateFunctionSequenceMatch.cpp\nindex 3dd9a8b658da..ff9259e3aacc 100644\n--- a/src/AggregateFunctions/AggregateFunctionSequenceMatch.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionSequenceMatch.cpp\n@@ -1,15 +1,22 @@\n #include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionSequenceMatch.h>\n \n #include <DataTypes/DataTypeDate.h>\n-#include <DataTypes/DataTypeDate32.h>\n #include <DataTypes/DataTypeDateTime.h>\n \n-#include <base/range.h>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <Columns/ColumnsNumber.h>\n+#include <Common/assert_cast.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+#include <bitset>\n+#include <stack>\n+\n \n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n@@ -18,11 +25,689 @@ namespace ErrorCodes\n     extern const int TOO_MANY_ARGUMENTS_FOR_FUNCTION;\n     extern const int TOO_FEW_ARGUMENTS_FOR_FUNCTION;\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int TOO_SLOW;\n+    extern const int SYNTAX_ERROR;\n+    extern const int BAD_ARGUMENTS;\n+    extern const int LOGICAL_ERROR;\n }\n \n namespace\n {\n \n+/// helper type for comparing `std::pair`s using solely the .first member\n+template <template <typename> class Comparator>\n+struct ComparePairFirst final\n+{\n+    template <typename T1, typename T2>\n+    bool operator()(const std::pair<T1, T2> & lhs, const std::pair<T1, T2> & rhs) const\n+    {\n+        return Comparator<T1>{}(lhs.first, rhs.first);\n+    }\n+};\n+\n+constexpr size_t max_events = 32;\n+\n+template <typename T>\n+struct AggregateFunctionSequenceMatchData final\n+{\n+    using Timestamp = T;\n+    using Events = std::bitset<max_events>;\n+    using TimestampEvents = std::pair<Timestamp, Events>;\n+    using Comparator = ComparePairFirst<std::less>;\n+\n+    bool sorted = true;\n+    PODArrayWithStackMemory<TimestampEvents, 64> events_list;\n+    /// sequenceMatch conditions met at least once in events_list\n+    Events conditions_met;\n+\n+    void add(const Timestamp timestamp, const Events & events)\n+    {\n+        /// store information exclusively for rows with at least one event\n+        if (events.any())\n+        {\n+            events_list.emplace_back(timestamp, events);\n+            sorted = false;\n+            conditions_met |= events;\n+        }\n+    }\n+\n+    void merge(const AggregateFunctionSequenceMatchData & other)\n+    {\n+        if (other.events_list.empty())\n+            return;\n+\n+        events_list.insert(std::begin(other.events_list), std::end(other.events_list));\n+        sorted = false;\n+        conditions_met |= other.conditions_met;\n+    }\n+\n+    void sort()\n+    {\n+        if (sorted)\n+            return;\n+\n+        ::sort(std::begin(events_list), std::end(events_list), Comparator{});\n+        sorted = true;\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        writeBinary(sorted, buf);\n+        writeBinary(events_list.size(), buf);\n+\n+        for (const auto & events : events_list)\n+        {\n+            writeBinary(events.first, buf);\n+            writeBinary(events.second.to_ulong(), buf);\n+        }\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        readBinary(sorted, buf);\n+\n+        size_t size;\n+        readBinary(size, buf);\n+\n+        /// If we lose these flags, functionality is broken\n+        /// If we serialize/deserialize these flags, we have compatibility issues\n+        /// If we set these flags to 1, we have a minor performance penalty, which seems acceptable\n+        conditions_met.set();\n+\n+        events_list.clear();\n+        events_list.reserve(size);\n+\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            Timestamp timestamp;\n+            readBinary(timestamp, buf);\n+\n+            UInt64 events;\n+            readBinary(events, buf);\n+\n+            events_list.emplace_back(timestamp, Events{events});\n+        }\n+    }\n+};\n+\n+\n+/// Max number of iterations to match the pattern against a sequence, exception thrown when exceeded\n+constexpr auto sequence_match_max_iterations = 1000000;\n+\n+\n+template <typename T, typename Data, typename Derived>\n+class AggregateFunctionSequenceBase : public IAggregateFunctionDataHelper<Data, Derived>\n+{\n+public:\n+    AggregateFunctionSequenceBase(const DataTypes & arguments, const Array & params, const String & pattern_, const DataTypePtr & result_type_)\n+        : IAggregateFunctionDataHelper<Data, Derived>(arguments, params, result_type_)\n+        , pattern(pattern_)\n+    {\n+        arg_count = arguments.size();\n+        parsePattern();\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, const size_t row_num, Arena *) const override\n+    {\n+        const auto timestamp = assert_cast<const ColumnVector<T> *>(columns[0])->getData()[row_num];\n+\n+        typename Data::Events events;\n+        for (const auto i : collections::range(1, arg_count))\n+        {\n+            const auto event = assert_cast<const ColumnUInt8 *>(columns[i])->getData()[row_num];\n+            events.set(i - 1, event);\n+        }\n+\n+        this->data(place).add(timestamp, events);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    bool haveSameStateRepresentationImpl(const IAggregateFunction & rhs) const override\n+    {\n+        return this->getName() == rhs.getName() && this->haveEqualArgumentTypes(rhs);\n+    }\n+\n+private:\n+    enum class PatternActionType\n+    {\n+        SpecificEvent,\n+        AnyEvent,\n+        KleeneStar,\n+        TimeLessOrEqual,\n+        TimeLess,\n+        TimeGreaterOrEqual,\n+        TimeGreater,\n+        TimeEqual\n+    };\n+\n+    struct PatternAction final\n+    {\n+        PatternActionType type;\n+        std::uint64_t extra;\n+\n+        PatternAction() = default;\n+        explicit PatternAction(const PatternActionType type_, const std::uint64_t extra_ = 0) : type{type_}, extra{extra_} {}\n+    };\n+\n+    using PatternActions = PODArrayWithStackMemory<PatternAction, 64>;\n+\n+    Derived & derived() { return static_cast<Derived &>(*this); }\n+\n+    void parsePattern()\n+    {\n+        actions.clear();\n+        actions.emplace_back(PatternActionType::KleeneStar);\n+\n+        dfa_states.clear();\n+        dfa_states.emplace_back(true);\n+\n+        pattern_has_time = false;\n+\n+        const char * pos = pattern.data();\n+        const char * begin = pos;\n+        const char * end = pos + pattern.size();\n+\n+        auto throw_exception = [&](const std::string & msg)\n+        {\n+            throw Exception(ErrorCodes::SYNTAX_ERROR, \"{} '{}' at position {}\", msg, std::string(pos, end), toString(pos - begin));\n+        };\n+\n+        auto match = [&pos, end](const char * str) mutable\n+        {\n+            size_t length = strlen(str);\n+            if (pos + length <= end && 0 == memcmp(pos, str, length))\n+            {\n+                pos += length;\n+                return true;\n+            }\n+            return false;\n+        };\n+\n+        while (pos < end)\n+        {\n+            if (match(\"(?\"))\n+            {\n+                if (match(\"t\"))\n+                {\n+                    PatternActionType type;\n+\n+                    if (match(\"<=\"))\n+                        type = PatternActionType::TimeLessOrEqual;\n+                    else if (match(\"<\"))\n+                        type = PatternActionType::TimeLess;\n+                    else if (match(\">=\"))\n+                        type = PatternActionType::TimeGreaterOrEqual;\n+                    else if (match(\">\"))\n+                        type = PatternActionType::TimeGreater;\n+                    else if (match(\"==\"))\n+                        type = PatternActionType::TimeEqual;\n+                    else\n+                        throw_exception(\"Unknown time condition\");\n+\n+                    UInt64 duration = 0;\n+                    const auto * prev_pos = pos;\n+                    pos = tryReadIntText(duration, pos, end);\n+                    if (pos == prev_pos)\n+                        throw_exception(\"Could not parse number\");\n+\n+                    if (actions.back().type != PatternActionType::SpecificEvent &&\n+                        actions.back().type != PatternActionType::AnyEvent &&\n+                        actions.back().type != PatternActionType::KleeneStar)\n+                        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Temporal condition should be preceded by an event condition\");\n+\n+                    pattern_has_time = true;\n+                    actions.emplace_back(type, duration);\n+                }\n+                else\n+                {\n+                    UInt64 event_number = 0;\n+                    const auto * prev_pos = pos;\n+                    pos = tryReadIntText(event_number, pos, end);\n+                    if (pos == prev_pos)\n+                        throw_exception(\"Could not parse number\");\n+\n+                    if (event_number > arg_count - 1)\n+                        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Event number {} is out of range\", event_number);\n+\n+                    actions.emplace_back(PatternActionType::SpecificEvent, event_number - 1);\n+                    dfa_states.back().transition = DFATransition::SpecificEvent;\n+                    dfa_states.back().event = static_cast<uint32_t>(event_number - 1);\n+                    dfa_states.emplace_back();\n+                    conditions_in_pattern.set(event_number - 1);\n+                }\n+\n+                if (!match(\")\"))\n+                    throw_exception(\"Expected closing parenthesis, found\");\n+\n+            }\n+            else if (match(\".*\"))\n+            {\n+                actions.emplace_back(PatternActionType::KleeneStar);\n+                dfa_states.back().has_kleene = true;\n+            }\n+            else if (match(\".\"))\n+            {\n+                actions.emplace_back(PatternActionType::AnyEvent);\n+                dfa_states.back().transition = DFATransition::AnyEvent;\n+                dfa_states.emplace_back();\n+            }\n+            else\n+                throw_exception(\"Could not parse pattern, unexpected starting symbol\");\n+        }\n+    }\n+\n+protected:\n+    /// Uses a DFA based approach in order to better handle patterns without\n+    /// time assertions.\n+    ///\n+    /// NOTE: This implementation relies on the assumption that the pattern is *small*.\n+    ///\n+    /// This algorithm performs in O(mn) (with m the number of DFA states and N the number\n+    /// of events) with a memory consumption and memory allocations in O(m). It means that\n+    /// if n >>> m (which is expected to be the case), this algorithm can be considered linear.\n+    template <typename EventEntry>\n+    bool dfaMatch(EventEntry & events_it, const EventEntry events_end) const\n+    {\n+        using ActiveStates = std::vector<bool>;\n+\n+        /// Those two vectors keep track of which states should be considered for the current\n+        /// event as well as the states which should be considered for the next event.\n+        ActiveStates active_states(dfa_states.size(), false);\n+        ActiveStates next_active_states(dfa_states.size(), false);\n+        active_states[0] = true;\n+\n+        /// Keeps track of dead-ends in order not to iterate over all the events to realize that\n+        /// the match failed.\n+        size_t n_active = 1;\n+\n+        for (/* empty */; events_it != events_end && n_active > 0 && !active_states.back(); ++events_it)\n+        {\n+            n_active = 0;\n+            next_active_states.assign(dfa_states.size(), false);\n+\n+            for (size_t state = 0; state < dfa_states.size(); ++state)\n+            {\n+                if (!active_states[state])\n+                {\n+                    continue;\n+                }\n+\n+                switch (dfa_states[state].transition)\n+                {\n+                    case DFATransition::None:\n+                        break;\n+                    case DFATransition::AnyEvent:\n+                        next_active_states[state + 1] = true;\n+                        ++n_active;\n+                        break;\n+                    case DFATransition::SpecificEvent:\n+                        if (events_it->second.test(dfa_states[state].event))\n+                        {\n+                            next_active_states[state + 1] = true;\n+                            ++n_active;\n+                        }\n+                        break;\n+                }\n+\n+                if (dfa_states[state].has_kleene)\n+                {\n+                    next_active_states[state] = true;\n+                    ++n_active;\n+                }\n+            }\n+            swap(active_states, next_active_states);\n+        }\n+\n+        return active_states.back();\n+    }\n+\n+    template <typename EventEntry>\n+    bool backtrackingMatch(EventEntry & events_it, const EventEntry events_end) const\n+    {\n+        const auto action_begin = std::begin(actions);\n+        const auto action_end = std::end(actions);\n+        auto action_it = action_begin;\n+\n+        const auto events_begin = events_it;\n+        auto base_it = events_it;\n+\n+        /// an iterator to action plus an iterator to row in events list plus timestamp at the start of sequence\n+        using backtrack_info = std::tuple<decltype(action_it), EventEntry, EventEntry>;\n+        std::stack<backtrack_info> back_stack;\n+\n+        /// backtrack if possible\n+        const auto do_backtrack = [&]\n+        {\n+            while (!back_stack.empty())\n+            {\n+                auto & top = back_stack.top();\n+\n+                action_it = std::get<0>(top);\n+                events_it = std::next(std::get<1>(top));\n+                base_it = std::get<2>(top);\n+\n+                back_stack.pop();\n+\n+                if (events_it != events_end)\n+                    return true;\n+            }\n+\n+            return false;\n+        };\n+\n+        size_t i = 0;\n+        while (action_it != action_end && events_it != events_end)\n+        {\n+            if (action_it->type == PatternActionType::SpecificEvent)\n+            {\n+                if (events_it->second.test(action_it->extra))\n+                {\n+                    /// move to the next action and events\n+                    base_it = events_it;\n+                    ++action_it, ++events_it;\n+                }\n+                else if (!do_backtrack())\n+                    /// backtracking failed, bail out\n+                    break;\n+            }\n+            else if (action_it->type == PatternActionType::AnyEvent)\n+            {\n+                base_it = events_it;\n+                ++action_it, ++events_it;\n+            }\n+            else if (action_it->type == PatternActionType::KleeneStar)\n+            {\n+                back_stack.emplace(action_it, events_it, base_it);\n+                base_it = events_it;\n+                ++action_it;\n+            }\n+            else if (action_it->type == PatternActionType::TimeLessOrEqual)\n+            {\n+                if (events_it->first <= base_it->first + action_it->extra)\n+                {\n+                    /// condition satisfied, move onto next action\n+                    back_stack.emplace(action_it, events_it, base_it);\n+                    base_it = events_it;\n+                    ++action_it;\n+                }\n+                else if (!do_backtrack())\n+                    break;\n+            }\n+            else if (action_it->type == PatternActionType::TimeLess)\n+            {\n+                if (events_it->first < base_it->first + action_it->extra)\n+                {\n+                    back_stack.emplace(action_it, events_it, base_it);\n+                    base_it = events_it;\n+                    ++action_it;\n+                }\n+                else if (!do_backtrack())\n+                    break;\n+            }\n+            else if (action_it->type == PatternActionType::TimeGreaterOrEqual)\n+            {\n+                if (events_it->first >= base_it->first + action_it->extra)\n+                {\n+                    back_stack.emplace(action_it, events_it, base_it);\n+                    base_it = events_it;\n+                    ++action_it;\n+                }\n+                else if (++events_it == events_end && !do_backtrack())\n+                    break;\n+            }\n+            else if (action_it->type == PatternActionType::TimeGreater)\n+            {\n+                if (events_it->first > base_it->first + action_it->extra)\n+                {\n+                    back_stack.emplace(action_it, events_it, base_it);\n+                    base_it = events_it;\n+                    ++action_it;\n+                }\n+                else if (++events_it == events_end && !do_backtrack())\n+                    break;\n+            }\n+            else if (action_it->type == PatternActionType::TimeEqual)\n+            {\n+                if (events_it->first == base_it->first + action_it->extra)\n+                {\n+                    back_stack.emplace(action_it, events_it, base_it);\n+                    base_it = events_it;\n+                    ++action_it;\n+                }\n+                else if (++events_it == events_end && !do_backtrack())\n+                    break;\n+            }\n+            else\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unknown PatternActionType\");\n+\n+            if (++i > sequence_match_max_iterations)\n+                throw Exception(ErrorCodes::TOO_SLOW, \"Pattern application proves too difficult, exceeding max iterations ({})\",\n+                    sequence_match_max_iterations);\n+        }\n+\n+        /// if there are some actions remaining\n+        if (action_it != action_end)\n+        {\n+            /// match multiple empty strings at end\n+            while (action_it->type == PatternActionType::KleeneStar ||\n+                   action_it->type == PatternActionType::TimeLessOrEqual ||\n+                   action_it->type == PatternActionType::TimeLess ||\n+                   (action_it->type == PatternActionType::TimeGreaterOrEqual && action_it->extra == 0))\n+                ++action_it;\n+        }\n+\n+        if (events_it == events_begin)\n+            ++events_it;\n+\n+        return action_it == action_end;\n+    }\n+\n+    /// Splits the pattern into deterministic parts separated by non-deterministic fragments\n+    /// (time constraints and Kleene stars), and tries to match the deterministic parts in their specified order,\n+    /// ignoring the non-deterministic fragments.\n+    /// This function can quickly check that a full match is not possible if some deterministic fragment is missing.\n+    template <typename EventEntry>\n+    bool couldMatchDeterministicParts(const EventEntry events_begin, const EventEntry events_end, bool limit_iterations = true) const\n+    {\n+        size_t events_processed = 0;\n+        auto events_it = events_begin;\n+\n+        const auto actions_end = std::end(actions);\n+        auto actions_it = std::begin(actions);\n+        auto det_part_begin = actions_it;\n+\n+        auto match_deterministic_part = [&events_it, events_end, &events_processed, det_part_begin, actions_it, limit_iterations]()\n+        {\n+            auto events_it_init = events_it;\n+            auto det_part_it = det_part_begin;\n+\n+            while (det_part_it != actions_it && events_it != events_end)\n+            {\n+                /// matching any event\n+                if (det_part_it->type == PatternActionType::AnyEvent)\n+                    ++events_it, ++det_part_it;\n+\n+                /// matching specific event\n+                else\n+                {\n+                    if (events_it->second.test(det_part_it->extra))\n+                        ++events_it, ++det_part_it;\n+\n+                    /// abandon current matching, try to match the deterministic fragment further in the list\n+                    else\n+                    {\n+                        events_it = ++events_it_init;\n+                        det_part_it = det_part_begin;\n+                    }\n+                }\n+\n+                if (limit_iterations && ++events_processed > sequence_match_max_iterations)\n+                    throw Exception(ErrorCodes::TOO_SLOW, \"Pattern application proves too difficult, exceeding max iterations ({})\",\n+                        sequence_match_max_iterations);\n+            }\n+\n+            return det_part_it == actions_it;\n+        };\n+\n+        for (; actions_it != actions_end; ++actions_it)\n+            if (actions_it->type != PatternActionType::SpecificEvent && actions_it->type != PatternActionType::AnyEvent)\n+            {\n+                if (!match_deterministic_part())\n+                    return false;\n+                det_part_begin = std::next(actions_it);\n+            }\n+\n+        return match_deterministic_part();\n+    }\n+\n+private:\n+    enum class DFATransition : char\n+    {\n+        ///   .-------.\n+        ///   |       |\n+        ///   `-------'\n+        None,\n+        ///   .-------.  (?[0-9])\n+        ///   |       | ----------\n+        ///   `-------'\n+        SpecificEvent,\n+        ///   .-------.      .\n+        ///   |       | ----------\n+        ///   `-------'\n+        AnyEvent,\n+    };\n+\n+    struct DFAState\n+    {\n+        explicit DFAState(bool has_kleene_ = false)\n+            : has_kleene{has_kleene_}, event{0}, transition{DFATransition::None}\n+        {}\n+\n+        ///   .-------.\n+        ///   |       | - - -\n+        ///   `-------'\n+        ///     |_^\n+        bool has_kleene;\n+        /// In the case of a state transitions with a `SpecificEvent`,\n+        /// `event` contains the value of the event.\n+        uint32_t event;\n+        /// The kind of transition out of this state.\n+        DFATransition transition;\n+    };\n+\n+    using DFAStates = std::vector<DFAState>;\n+\n+protected:\n+    /// `True` if the parsed pattern contains time assertions (?t...), `false` otherwise.\n+    bool pattern_has_time;\n+    /// sequenceMatch conditions met at least once in the pattern\n+    std::bitset<max_events> conditions_in_pattern;\n+\n+private:\n+    std::string pattern;\n+    size_t arg_count;\n+    PatternActions actions;\n+\n+    DFAStates dfa_states;\n+};\n+\n+template <typename T, typename Data>\n+class AggregateFunctionSequenceMatch final : public AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceMatch<T, Data>>\n+{\n+public:\n+    AggregateFunctionSequenceMatch(const DataTypes & arguments, const Array & params, const String & pattern_)\n+        : AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceMatch<T, Data>>(arguments, params, pattern_, std::make_shared<DataTypeUInt8>()) {}\n+\n+    using AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceMatch<T, Data>>::AggregateFunctionSequenceBase;\n+\n+    String getName() const override { return \"sequenceMatch\"; }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        auto & output = assert_cast<ColumnUInt8 &>(to).getData();\n+        if ((this->conditions_in_pattern & this->data(place).conditions_met) != this->conditions_in_pattern)\n+        {\n+            output.push_back(false);\n+            return;\n+        }\n+        this->data(place).sort();\n+\n+        const auto & data_ref = this->data(place);\n+\n+        const auto events_begin = std::begin(data_ref.events_list);\n+        const auto events_end = std::end(data_ref.events_list);\n+        auto events_it = events_begin;\n+\n+        bool match = (this->pattern_has_time ?\n+            (this->couldMatchDeterministicParts(events_begin, events_end) && this->backtrackingMatch(events_it, events_end)) :\n+            this->dfaMatch(events_it, events_end));\n+        output.push_back(match);\n+    }\n+};\n+\n+template <typename T, typename Data>\n+class AggregateFunctionSequenceCount final : public AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceCount<T, Data>>\n+{\n+public:\n+    AggregateFunctionSequenceCount(const DataTypes & arguments, const Array & params, const String & pattern_)\n+        : AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceCount<T, Data>>(arguments, params, pattern_, std::make_shared<DataTypeUInt64>()) {}\n+\n+    using AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceCount<T, Data>>::AggregateFunctionSequenceBase;\n+\n+    String getName() const override { return \"sequenceCount\"; }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        auto & output = assert_cast<ColumnUInt64 &>(to).getData();\n+        if ((this->conditions_in_pattern & this->data(place).conditions_met) != this->conditions_in_pattern)\n+        {\n+            output.push_back(0);\n+            return;\n+        }\n+        this->data(place).sort();\n+        output.push_back(count(place));\n+    }\n+\n+private:\n+    UInt64 count(ConstAggregateDataPtr __restrict place) const\n+    {\n+        const auto & data_ref = this->data(place);\n+\n+        const auto events_begin = std::begin(data_ref.events_list);\n+        const auto events_end = std::end(data_ref.events_list);\n+        auto events_it = events_begin;\n+\n+        size_t count = 0;\n+        // check if there is a chance of matching the sequence at least once\n+        if (this->couldMatchDeterministicParts(events_begin, events_end))\n+        {\n+            while (events_it != events_end && this->backtrackingMatch(events_it, events_end))\n+                ++count;\n+        }\n+\n+        return count;\n+    }\n+};\n+\n+\n template <template <typename, typename> typename AggregateFunction, template <typename> typename Data>\n AggregateFunctionPtr createAggregateFunctionSequenceBase(\n     const std::string & name, const DataTypes & argument_types, const Array & params, const Settings *)\ndiff --git a/src/AggregateFunctions/AggregateFunctionSequenceMatch.h b/src/AggregateFunctions/AggregateFunctionSequenceMatch.h\ndeleted file mode 100644\nindex f2e17940d358..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionSequenceMatch.h\n+++ /dev/null\n@@ -1,702 +0,0 @@\n-#pragma once\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <DataTypes/DataTypeDateTime.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <Columns/ColumnsNumber.h>\n-#include <Common/assert_cast.h>\n-#include <base/range.h>\n-#include <base/sort.h>\n-#include <Common/PODArray.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <bitset>\n-#include <stack>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int TOO_SLOW;\n-    extern const int SYNTAX_ERROR;\n-    extern const int BAD_ARGUMENTS;\n-    extern const int LOGICAL_ERROR;\n-}\n-\n-/// helper type for comparing `std::pair`s using solely the .first member\n-template <template <typename> class Comparator>\n-struct ComparePairFirst final\n-{\n-    template <typename T1, typename T2>\n-    bool operator()(const std::pair<T1, T2> & lhs, const std::pair<T1, T2> & rhs) const\n-    {\n-        return Comparator<T1>{}(lhs.first, rhs.first);\n-    }\n-};\n-\n-static constexpr size_t max_events = 32;\n-\n-template <typename T>\n-struct AggregateFunctionSequenceMatchData final\n-{\n-    using Timestamp = T;\n-    using Events = std::bitset<max_events>;\n-    using TimestampEvents = std::pair<Timestamp, Events>;\n-    using Comparator = ComparePairFirst<std::less>;\n-\n-    bool sorted = true;\n-    PODArrayWithStackMemory<TimestampEvents, 64> events_list;\n-    /// sequenceMatch conditions met at least once in events_list\n-    Events conditions_met;\n-\n-    void add(const Timestamp timestamp, const Events & events)\n-    {\n-        /// store information exclusively for rows with at least one event\n-        if (events.any())\n-        {\n-            events_list.emplace_back(timestamp, events);\n-            sorted = false;\n-            conditions_met |= events;\n-        }\n-    }\n-\n-    void merge(const AggregateFunctionSequenceMatchData & other)\n-    {\n-        if (other.events_list.empty())\n-            return;\n-\n-        events_list.insert(std::begin(other.events_list), std::end(other.events_list));\n-        sorted = false;\n-        conditions_met |= other.conditions_met;\n-    }\n-\n-    void sort()\n-    {\n-        if (sorted)\n-            return;\n-\n-        ::sort(std::begin(events_list), std::end(events_list), Comparator{});\n-        sorted = true;\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        writeBinary(sorted, buf);\n-        writeBinary(events_list.size(), buf);\n-\n-        for (const auto & events : events_list)\n-        {\n-            writeBinary(events.first, buf);\n-            writeBinary(events.second.to_ulong(), buf);\n-        }\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        readBinary(sorted, buf);\n-\n-        size_t size;\n-        readBinary(size, buf);\n-\n-        /// If we lose these flags, functionality is broken\n-        /// If we serialize/deserialize these flags, we have compatibility issues\n-        /// If we set these flags to 1, we have a minor performance penalty, which seems acceptable\n-        conditions_met.set();\n-\n-        events_list.clear();\n-        events_list.reserve(size);\n-\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            Timestamp timestamp;\n-            readBinary(timestamp, buf);\n-\n-            UInt64 events;\n-            readBinary(events, buf);\n-\n-            events_list.emplace_back(timestamp, Events{events});\n-        }\n-    }\n-};\n-\n-\n-/// Max number of iterations to match the pattern against a sequence, exception thrown when exceeded\n-constexpr auto sequence_match_max_iterations = 1000000;\n-\n-\n-template <typename T, typename Data, typename Derived>\n-class AggregateFunctionSequenceBase : public IAggregateFunctionDataHelper<Data, Derived>\n-{\n-public:\n-    AggregateFunctionSequenceBase(const DataTypes & arguments, const Array & params, const String & pattern_, const DataTypePtr & result_type_)\n-        : IAggregateFunctionDataHelper<Data, Derived>(arguments, params, result_type_)\n-        , pattern(pattern_)\n-    {\n-        arg_count = arguments.size();\n-        parsePattern();\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, const size_t row_num, Arena *) const override\n-    {\n-        const auto timestamp = assert_cast<const ColumnVector<T> *>(columns[0])->getData()[row_num];\n-\n-        typename Data::Events events;\n-        for (const auto i : collections::range(1, arg_count))\n-        {\n-            const auto event = assert_cast<const ColumnUInt8 *>(columns[i])->getData()[row_num];\n-            events.set(i - 1, event);\n-        }\n-\n-        this->data(place).add(timestamp, events);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).deserialize(buf);\n-    }\n-\n-    bool haveSameStateRepresentationImpl(const IAggregateFunction & rhs) const override\n-    {\n-        return this->getName() == rhs.getName() && this->haveEqualArgumentTypes(rhs);\n-    }\n-\n-private:\n-    enum class PatternActionType\n-    {\n-        SpecificEvent,\n-        AnyEvent,\n-        KleeneStar,\n-        TimeLessOrEqual,\n-        TimeLess,\n-        TimeGreaterOrEqual,\n-        TimeGreater,\n-        TimeEqual\n-    };\n-\n-    struct PatternAction final\n-    {\n-        PatternActionType type;\n-        std::uint64_t extra;\n-\n-        PatternAction() = default;\n-        explicit PatternAction(const PatternActionType type_, const std::uint64_t extra_ = 0) : type{type_}, extra{extra_} {}\n-    };\n-\n-    using PatternActions = PODArrayWithStackMemory<PatternAction, 64>;\n-\n-    Derived & derived() { return static_cast<Derived &>(*this); }\n-\n-    void parsePattern()\n-    {\n-        actions.clear();\n-        actions.emplace_back(PatternActionType::KleeneStar);\n-\n-        dfa_states.clear();\n-        dfa_states.emplace_back(true);\n-\n-        pattern_has_time = false;\n-\n-        const char * pos = pattern.data();\n-        const char * begin = pos;\n-        const char * end = pos + pattern.size();\n-\n-        auto throw_exception = [&](const std::string & msg)\n-        {\n-            throw Exception(ErrorCodes::SYNTAX_ERROR, \"{} '{}' at position {}\", msg, std::string(pos, end), toString(pos - begin));\n-        };\n-\n-        auto match = [&pos, end](const char * str) mutable\n-        {\n-            size_t length = strlen(str);\n-            if (pos + length <= end && 0 == memcmp(pos, str, length))\n-            {\n-                pos += length;\n-                return true;\n-            }\n-            return false;\n-        };\n-\n-        while (pos < end)\n-        {\n-            if (match(\"(?\"))\n-            {\n-                if (match(\"t\"))\n-                {\n-                    PatternActionType type;\n-\n-                    if (match(\"<=\"))\n-                        type = PatternActionType::TimeLessOrEqual;\n-                    else if (match(\"<\"))\n-                        type = PatternActionType::TimeLess;\n-                    else if (match(\">=\"))\n-                        type = PatternActionType::TimeGreaterOrEqual;\n-                    else if (match(\">\"))\n-                        type = PatternActionType::TimeGreater;\n-                    else if (match(\"==\"))\n-                        type = PatternActionType::TimeEqual;\n-                    else\n-                        throw_exception(\"Unknown time condition\");\n-\n-                    UInt64 duration = 0;\n-                    const auto * prev_pos = pos;\n-                    pos = tryReadIntText(duration, pos, end);\n-                    if (pos == prev_pos)\n-                        throw_exception(\"Could not parse number\");\n-\n-                    if (actions.back().type != PatternActionType::SpecificEvent &&\n-                        actions.back().type != PatternActionType::AnyEvent &&\n-                        actions.back().type != PatternActionType::KleeneStar)\n-                        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Temporal condition should be preceded by an event condition\");\n-\n-                    pattern_has_time = true;\n-                    actions.emplace_back(type, duration);\n-                }\n-                else\n-                {\n-                    UInt64 event_number = 0;\n-                    const auto * prev_pos = pos;\n-                    pos = tryReadIntText(event_number, pos, end);\n-                    if (pos == prev_pos)\n-                        throw_exception(\"Could not parse number\");\n-\n-                    if (event_number > arg_count - 1)\n-                        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Event number {} is out of range\", event_number);\n-\n-                    actions.emplace_back(PatternActionType::SpecificEvent, event_number - 1);\n-                    dfa_states.back().transition = DFATransition::SpecificEvent;\n-                    dfa_states.back().event = static_cast<uint32_t>(event_number - 1);\n-                    dfa_states.emplace_back();\n-                    conditions_in_pattern.set(event_number - 1);\n-                }\n-\n-                if (!match(\")\"))\n-                    throw_exception(\"Expected closing parenthesis, found\");\n-\n-            }\n-            else if (match(\".*\"))\n-            {\n-                actions.emplace_back(PatternActionType::KleeneStar);\n-                dfa_states.back().has_kleene = true;\n-            }\n-            else if (match(\".\"))\n-            {\n-                actions.emplace_back(PatternActionType::AnyEvent);\n-                dfa_states.back().transition = DFATransition::AnyEvent;\n-                dfa_states.emplace_back();\n-            }\n-            else\n-                throw_exception(\"Could not parse pattern, unexpected starting symbol\");\n-        }\n-    }\n-\n-protected:\n-    /// Uses a DFA based approach in order to better handle patterns without\n-    /// time assertions.\n-    ///\n-    /// NOTE: This implementation relies on the assumption that the pattern is *small*.\n-    ///\n-    /// This algorithm performs in O(mn) (with m the number of DFA states and N the number\n-    /// of events) with a memory consumption and memory allocations in O(m). It means that\n-    /// if n >>> m (which is expected to be the case), this algorithm can be considered linear.\n-    template <typename EventEntry>\n-    bool dfaMatch(EventEntry & events_it, const EventEntry events_end) const\n-    {\n-        using ActiveStates = std::vector<bool>;\n-\n-        /// Those two vectors keep track of which states should be considered for the current\n-        /// event as well as the states which should be considered for the next event.\n-        ActiveStates active_states(dfa_states.size(), false);\n-        ActiveStates next_active_states(dfa_states.size(), false);\n-        active_states[0] = true;\n-\n-        /// Keeps track of dead-ends in order not to iterate over all the events to realize that\n-        /// the match failed.\n-        size_t n_active = 1;\n-\n-        for (/* empty */; events_it != events_end && n_active > 0 && !active_states.back(); ++events_it)\n-        {\n-            n_active = 0;\n-            next_active_states.assign(dfa_states.size(), false);\n-\n-            for (size_t state = 0; state < dfa_states.size(); ++state)\n-            {\n-                if (!active_states[state])\n-                {\n-                    continue;\n-                }\n-\n-                switch (dfa_states[state].transition)\n-                {\n-                    case DFATransition::None:\n-                        break;\n-                    case DFATransition::AnyEvent:\n-                        next_active_states[state + 1] = true;\n-                        ++n_active;\n-                        break;\n-                    case DFATransition::SpecificEvent:\n-                        if (events_it->second.test(dfa_states[state].event))\n-                        {\n-                            next_active_states[state + 1] = true;\n-                            ++n_active;\n-                        }\n-                        break;\n-                }\n-\n-                if (dfa_states[state].has_kleene)\n-                {\n-                    next_active_states[state] = true;\n-                    ++n_active;\n-                }\n-            }\n-            swap(active_states, next_active_states);\n-        }\n-\n-        return active_states.back();\n-    }\n-\n-    template <typename EventEntry>\n-    bool backtrackingMatch(EventEntry & events_it, const EventEntry events_end) const\n-    {\n-        const auto action_begin = std::begin(actions);\n-        const auto action_end = std::end(actions);\n-        auto action_it = action_begin;\n-\n-        const auto events_begin = events_it;\n-        auto base_it = events_it;\n-\n-        /// an iterator to action plus an iterator to row in events list plus timestamp at the start of sequence\n-        using backtrack_info = std::tuple<decltype(action_it), EventEntry, EventEntry>;\n-        std::stack<backtrack_info> back_stack;\n-\n-        /// backtrack if possible\n-        const auto do_backtrack = [&]\n-        {\n-            while (!back_stack.empty())\n-            {\n-                auto & top = back_stack.top();\n-\n-                action_it = std::get<0>(top);\n-                events_it = std::next(std::get<1>(top));\n-                base_it = std::get<2>(top);\n-\n-                back_stack.pop();\n-\n-                if (events_it != events_end)\n-                    return true;\n-            }\n-\n-            return false;\n-        };\n-\n-        size_t i = 0;\n-        while (action_it != action_end && events_it != events_end)\n-        {\n-            if (action_it->type == PatternActionType::SpecificEvent)\n-            {\n-                if (events_it->second.test(action_it->extra))\n-                {\n-                    /// move to the next action and events\n-                    base_it = events_it;\n-                    ++action_it, ++events_it;\n-                }\n-                else if (!do_backtrack())\n-                    /// backtracking failed, bail out\n-                    break;\n-            }\n-            else if (action_it->type == PatternActionType::AnyEvent)\n-            {\n-                base_it = events_it;\n-                ++action_it, ++events_it;\n-            }\n-            else if (action_it->type == PatternActionType::KleeneStar)\n-            {\n-                back_stack.emplace(action_it, events_it, base_it);\n-                base_it = events_it;\n-                ++action_it;\n-            }\n-            else if (action_it->type == PatternActionType::TimeLessOrEqual)\n-            {\n-                if (events_it->first <= base_it->first + action_it->extra)\n-                {\n-                    /// condition satisfied, move onto next action\n-                    back_stack.emplace(action_it, events_it, base_it);\n-                    base_it = events_it;\n-                    ++action_it;\n-                }\n-                else if (!do_backtrack())\n-                    break;\n-            }\n-            else if (action_it->type == PatternActionType::TimeLess)\n-            {\n-                if (events_it->first < base_it->first + action_it->extra)\n-                {\n-                    back_stack.emplace(action_it, events_it, base_it);\n-                    base_it = events_it;\n-                    ++action_it;\n-                }\n-                else if (!do_backtrack())\n-                    break;\n-            }\n-            else if (action_it->type == PatternActionType::TimeGreaterOrEqual)\n-            {\n-                if (events_it->first >= base_it->first + action_it->extra)\n-                {\n-                    back_stack.emplace(action_it, events_it, base_it);\n-                    base_it = events_it;\n-                    ++action_it;\n-                }\n-                else if (++events_it == events_end && !do_backtrack())\n-                    break;\n-            }\n-            else if (action_it->type == PatternActionType::TimeGreater)\n-            {\n-                if (events_it->first > base_it->first + action_it->extra)\n-                {\n-                    back_stack.emplace(action_it, events_it, base_it);\n-                    base_it = events_it;\n-                    ++action_it;\n-                }\n-                else if (++events_it == events_end && !do_backtrack())\n-                    break;\n-            }\n-            else if (action_it->type == PatternActionType::TimeEqual)\n-            {\n-                if (events_it->first == base_it->first + action_it->extra)\n-                {\n-                    back_stack.emplace(action_it, events_it, base_it);\n-                    base_it = events_it;\n-                    ++action_it;\n-                }\n-                else if (++events_it == events_end && !do_backtrack())\n-                    break;\n-            }\n-            else\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unknown PatternActionType\");\n-\n-            if (++i > sequence_match_max_iterations)\n-                throw Exception(ErrorCodes::TOO_SLOW, \"Pattern application proves too difficult, exceeding max iterations ({})\",\n-                    sequence_match_max_iterations);\n-        }\n-\n-        /// if there are some actions remaining\n-        if (action_it != action_end)\n-        {\n-            /// match multiple empty strings at end\n-            while (action_it->type == PatternActionType::KleeneStar ||\n-                   action_it->type == PatternActionType::TimeLessOrEqual ||\n-                   action_it->type == PatternActionType::TimeLess ||\n-                   (action_it->type == PatternActionType::TimeGreaterOrEqual && action_it->extra == 0))\n-                ++action_it;\n-        }\n-\n-        if (events_it == events_begin)\n-            ++events_it;\n-\n-        return action_it == action_end;\n-    }\n-\n-    /// Splits the pattern into deterministic parts separated by non-deterministic fragments\n-    /// (time constraints and Kleene stars), and tries to match the deterministic parts in their specified order,\n-    /// ignoring the non-deterministic fragments.\n-    /// This function can quickly check that a full match is not possible if some deterministic fragment is missing.\n-    template <typename EventEntry>\n-    bool couldMatchDeterministicParts(const EventEntry events_begin, const EventEntry events_end, bool limit_iterations = true) const\n-    {\n-        size_t events_processed = 0;\n-        auto events_it = events_begin;\n-\n-        const auto actions_end = std::end(actions);\n-        auto actions_it = std::begin(actions);\n-        auto det_part_begin = actions_it;\n-\n-        auto match_deterministic_part = [&events_it, events_end, &events_processed, det_part_begin, actions_it, limit_iterations]()\n-        {\n-            auto events_it_init = events_it;\n-            auto det_part_it = det_part_begin;\n-\n-            while (det_part_it != actions_it && events_it != events_end)\n-            {\n-                /// matching any event\n-                if (det_part_it->type == PatternActionType::AnyEvent)\n-                    ++events_it, ++det_part_it;\n-\n-                /// matching specific event\n-                else\n-                {\n-                    if (events_it->second.test(det_part_it->extra))\n-                        ++events_it, ++det_part_it;\n-\n-                    /// abandon current matching, try to match the deterministic fragment further in the list\n-                    else\n-                    {\n-                        events_it = ++events_it_init;\n-                        det_part_it = det_part_begin;\n-                    }\n-                }\n-\n-                if (limit_iterations && ++events_processed > sequence_match_max_iterations)\n-                    throw Exception(ErrorCodes::TOO_SLOW, \"Pattern application proves too difficult, exceeding max iterations ({})\",\n-                        sequence_match_max_iterations);\n-            }\n-\n-            return det_part_it == actions_it;\n-        };\n-\n-        for (; actions_it != actions_end; ++actions_it)\n-            if (actions_it->type != PatternActionType::SpecificEvent && actions_it->type != PatternActionType::AnyEvent)\n-            {\n-                if (!match_deterministic_part())\n-                    return false;\n-                det_part_begin = std::next(actions_it);\n-            }\n-\n-        return match_deterministic_part();\n-    }\n-\n-private:\n-    enum class DFATransition : char\n-    {\n-        ///   .-------.\n-        ///   |       |\n-        ///   `-------'\n-        None,\n-        ///   .-------.  (?[0-9])\n-        ///   |       | ----------\n-        ///   `-------'\n-        SpecificEvent,\n-        ///   .-------.      .\n-        ///   |       | ----------\n-        ///   `-------'\n-        AnyEvent,\n-    };\n-\n-    struct DFAState\n-    {\n-        explicit DFAState(bool has_kleene_ = false)\n-            : has_kleene{has_kleene_}, event{0}, transition{DFATransition::None}\n-        {}\n-\n-        ///   .-------.\n-        ///   |       | - - -\n-        ///   `-------'\n-        ///     |_^\n-        bool has_kleene;\n-        /// In the case of a state transitions with a `SpecificEvent`,\n-        /// `event` contains the value of the event.\n-        uint32_t event;\n-        /// The kind of transition out of this state.\n-        DFATransition transition;\n-    };\n-\n-    using DFAStates = std::vector<DFAState>;\n-\n-protected:\n-    /// `True` if the parsed pattern contains time assertions (?t...), `false` otherwise.\n-    bool pattern_has_time;\n-    /// sequenceMatch conditions met at least once in the pattern\n-    std::bitset<max_events> conditions_in_pattern;\n-\n-private:\n-    std::string pattern;\n-    size_t arg_count;\n-    PatternActions actions;\n-\n-    DFAStates dfa_states;\n-};\n-\n-template <typename T, typename Data>\n-class AggregateFunctionSequenceMatch final : public AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceMatch<T, Data>>\n-{\n-public:\n-    AggregateFunctionSequenceMatch(const DataTypes & arguments, const Array & params, const String & pattern_)\n-        : AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceMatch<T, Data>>(arguments, params, pattern_, std::make_shared<DataTypeUInt8>()) {}\n-\n-    using AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceMatch<T, Data>>::AggregateFunctionSequenceBase;\n-\n-    String getName() const override { return \"sequenceMatch\"; }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        auto & output = assert_cast<ColumnUInt8 &>(to).getData();\n-        if ((this->conditions_in_pattern & this->data(place).conditions_met) != this->conditions_in_pattern)\n-        {\n-            output.push_back(false);\n-            return;\n-        }\n-        this->data(place).sort();\n-\n-        const auto & data_ref = this->data(place);\n-\n-        const auto events_begin = std::begin(data_ref.events_list);\n-        const auto events_end = std::end(data_ref.events_list);\n-        auto events_it = events_begin;\n-\n-        bool match = (this->pattern_has_time ?\n-            (this->couldMatchDeterministicParts(events_begin, events_end) && this->backtrackingMatch(events_it, events_end)) :\n-            this->dfaMatch(events_it, events_end));\n-        output.push_back(match);\n-    }\n-};\n-\n-template <typename T, typename Data>\n-class AggregateFunctionSequenceCount final : public AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceCount<T, Data>>\n-{\n-public:\n-    AggregateFunctionSequenceCount(const DataTypes & arguments, const Array & params, const String & pattern_)\n-        : AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceCount<T, Data>>(arguments, params, pattern_, std::make_shared<DataTypeUInt64>()) {}\n-\n-    using AggregateFunctionSequenceBase<T, Data, AggregateFunctionSequenceCount<T, Data>>::AggregateFunctionSequenceBase;\n-\n-    String getName() const override { return \"sequenceCount\"; }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        auto & output = assert_cast<ColumnUInt64 &>(to).getData();\n-        if ((this->conditions_in_pattern & this->data(place).conditions_met) != this->conditions_in_pattern)\n-        {\n-            output.push_back(0);\n-            return;\n-        }\n-        this->data(place).sort();\n-        output.push_back(count(place));\n-    }\n-\n-private:\n-    UInt64 count(ConstAggregateDataPtr __restrict place) const\n-    {\n-        const auto & data_ref = this->data(place);\n-\n-        const auto events_begin = std::begin(data_ref.events_list);\n-        const auto events_end = std::end(data_ref.events_list);\n-        auto events_it = events_begin;\n-\n-        size_t count = 0;\n-        // check if there is a chance of matching the sequence at least once\n-        if (this->couldMatchDeterministicParts(events_begin, events_end))\n-        {\n-            while (events_it != events_end && this->backtrackingMatch(events_it, events_end))\n-                ++count;\n-        }\n-\n-        return count;\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionSequenceNextNode.cpp b/src/AggregateFunctions/AggregateFunctionSequenceNextNode.cpp\nindex 7bb19b13ca0b..3bbd00f0662b 100644\n--- a/src/AggregateFunctions/AggregateFunctionSequenceNextNode.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionSequenceNextNode.cpp\n@@ -1,14 +1,25 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionSequenceNextNode.h>\n-#include <AggregateFunctions/Helpers.h>\n-#include <AggregateFunctions/FactoryHelpers.h>\n #include <Core/Settings.h>\n #include <DataTypes/DataTypeDate.h>\n #include <DataTypes/DataTypeDateTime.h>\n #include <DataTypes/DataTypeNullable.h>\n #include <Interpreters/Context.h>\n-#include <Common/CurrentThread.h>\n-#include <base/range.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadBufferFromString.h>\n+#include <IO/WriteBufferFromString.h>\n+#include <DataTypes/DataTypesNumber.h>\n+\n+#include <Columns/ColumnString.h>\n+#include <Columns/ColumnVector.h>\n+#include <Columns/ColumnNullable.h>\n+\n+#include <Common/ArenaAllocator.h>\n+#include <Common/assert_cast.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+\n+#include <bitset>\n \n \n namespace DB\n@@ -24,11 +35,409 @@ namespace ErrorCodes\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n     extern const int BAD_ARGUMENTS;\n     extern const int UNKNOWN_AGGREGATE_FUNCTION;\n+    extern const int TOO_LARGE_ARRAY_SIZE;\n }\n \n namespace\n {\n \n+enum class SequenceDirection\n+{\n+    Forward,\n+    Backward,\n+};\n+\n+enum SequenceBase\n+{\n+    Head,\n+    Tail,\n+    FirstMatch,\n+    LastMatch,\n+};\n+\n+/// This is for security\n+const UInt64 max_node_size_deserialize = 0xFFFFFF;\n+\n+/// NodeBase used to implement a linked list for storage of SequenceNextNodeImpl\n+template <typename Node, size_t MaxEventsSize>\n+struct NodeBase\n+{\n+    UInt64 size; /// size of payload\n+\n+    DataTypeDateTime::FieldType event_time;\n+    std::bitset<MaxEventsSize> events_bitset;\n+    bool can_be_base;\n+\n+    char * data() { return reinterpret_cast<char *>(this) + sizeof(Node); }\n+\n+    const char * data() const { return reinterpret_cast<const char *>(this) + sizeof(Node); }\n+\n+    Node * clone(Arena * arena) const\n+    {\n+        return reinterpret_cast<Node *>(\n+            const_cast<char *>(arena->alignedInsert(reinterpret_cast<const char *>(this), sizeof(Node) + size, alignof(Node))));\n+    }\n+\n+    void write(WriteBuffer & buf) const\n+    {\n+        writeVarUInt(size, buf);\n+        buf.write(data(), size);\n+\n+        writeBinary(event_time, buf);\n+        UInt64 ulong_bitset = events_bitset.to_ulong();\n+        writeBinary(ulong_bitset, buf);\n+        writeBinary(can_be_base, buf);\n+    }\n+\n+    static Node * read(ReadBuffer & buf, Arena * arena)\n+    {\n+        UInt64 size;\n+        readVarUInt(size, buf);\n+        if (unlikely(size > max_node_size_deserialize))\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE, \"Too large node state size\");\n+\n+        Node * node = reinterpret_cast<Node *>(arena->alignedAlloc(sizeof(Node) + size, alignof(Node)));\n+        node->size = size;\n+        buf.readStrict(node->data(), size);\n+\n+        readBinary(node->event_time, buf);\n+        UInt64 ulong_bitset;\n+        readBinary(ulong_bitset, buf);\n+        node->events_bitset = ulong_bitset;\n+        readBinary(node->can_be_base, buf);\n+\n+        return node;\n+    }\n+};\n+\n+/// It stores String, timestamp, bitset of matched events.\n+template <size_t MaxEventsSize>\n+struct NodeString : public NodeBase<NodeString<MaxEventsSize>, MaxEventsSize>\n+{\n+    using Node = NodeString<MaxEventsSize>;\n+\n+    static Node * allocate(const IColumn & column, size_t row_num, Arena * arena)\n+    {\n+        StringRef string = assert_cast<const ColumnString &>(column).getDataAt(row_num);\n+\n+        Node * node = reinterpret_cast<Node *>(arena->alignedAlloc(sizeof(Node) + string.size, alignof(Node)));\n+        node->size = string.size;\n+        memcpy(node->data(), string.data, string.size);\n+\n+        return node;\n+    }\n+\n+    void insertInto(IColumn & column)\n+    {\n+        assert_cast<ColumnString &>(column).insertData(this->data(), this->size);\n+    }\n+\n+    bool compare(const Node * rhs) const\n+    {\n+        auto cmp = strncmp(this->data(), rhs->data(), std::min(this->size, rhs->size));\n+        return (cmp == 0) ? this->size < rhs->size : cmp < 0;\n+    }\n+};\n+\n+/// TODO : Support other types than string\n+template <typename Node>\n+struct SequenceNextNodeGeneralData\n+{\n+    using Allocator = MixedAlignedArenaAllocator<alignof(Node *), 4096>;\n+    using Array = PODArray<Node *, 32, Allocator>;\n+\n+    Array value;\n+    bool sorted = false;\n+\n+    struct Comparator final\n+    {\n+        bool operator()(const Node * lhs, const Node * rhs) const\n+        {\n+            return lhs->event_time == rhs->event_time ? lhs->compare(rhs) : lhs->event_time < rhs->event_time;\n+        }\n+    };\n+\n+    void sort()\n+    {\n+        if (!sorted)\n+        {\n+            std::stable_sort(std::begin(value), std::end(value), Comparator{});\n+            sorted = true;\n+        }\n+    }\n+};\n+\n+/// Implementation of sequenceFirstNode\n+template <typename T, typename Node>\n+class SequenceNextNodeImpl final\n+    : public IAggregateFunctionDataHelper<SequenceNextNodeGeneralData<Node>, SequenceNextNodeImpl<T, Node>>\n+{\n+    using Self = SequenceNextNodeImpl<T, Node>;\n+\n+    using Data = SequenceNextNodeGeneralData<Node>;\n+    static Data & data(AggregateDataPtr __restrict place) { return *reinterpret_cast<Data *>(place); }\n+    static const Data & data(ConstAggregateDataPtr __restrict place) { return *reinterpret_cast<const Data *>(place); }\n+\n+    static constexpr size_t base_cond_column_idx = 2;\n+    static constexpr size_t event_column_idx = 1;\n+\n+    SequenceBase seq_base_kind;\n+    SequenceDirection seq_direction;\n+    const size_t min_required_args;\n+\n+    DataTypePtr & data_type;\n+    UInt8 events_size;\n+    UInt64 max_elems;\n+public:\n+    SequenceNextNodeImpl(\n+        const DataTypePtr & data_type_,\n+        const DataTypes & arguments,\n+        const Array & parameters_,\n+        SequenceBase seq_base_kind_,\n+        SequenceDirection seq_direction_,\n+        size_t min_required_args_,\n+        UInt64 max_elems_ = std::numeric_limits<UInt64>::max())\n+        : IAggregateFunctionDataHelper<SequenceNextNodeGeneralData<Node>, Self>(arguments, parameters_, data_type_)\n+        , seq_base_kind(seq_base_kind_)\n+        , seq_direction(seq_direction_)\n+        , min_required_args(min_required_args_)\n+        , data_type(this->argument_types[0])\n+        , events_size(arguments.size() - min_required_args)\n+        , max_elems(max_elems_)\n+    {\n+    }\n+\n+    String getName() const override { return \"sequenceNextNode\"; }\n+\n+    bool haveSameStateRepresentationImpl(const IAggregateFunction & rhs) const override\n+    {\n+        return this->getName() == rhs.getName() && this->haveEqualArgumentTypes(rhs);\n+    }\n+\n+    void insert(Data & a, const Node * v, Arena * arena) const\n+    {\n+        ++a.total_values;\n+        a.value.push_back(v->clone(arena), arena);\n+    }\n+\n+    void create(AggregateDataPtr __restrict place) const override /// NOLINT\n+    {\n+        new (place) Data;\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        Node * node = Node::allocate(*columns[event_column_idx], row_num, arena);\n+\n+        const auto timestamp = assert_cast<const ColumnVector<T> *>(columns[0])->getData()[row_num];\n+\n+        /// The events_bitset variable stores matched events in the form of bitset.\n+        /// Each Nth-bit indicates that the Nth-event are matched.\n+        /// For example, event1 and event3 is matched then the values of events_bitset is 0x00000005.\n+        ///   0x00000000\n+        /// +          1 (bit of event1)\n+        /// +          4 (bit of event3)\n+        node->events_bitset.reset();\n+        for (UInt8 i = 0; i < events_size; ++i)\n+            if (assert_cast<const ColumnVector<UInt8> *>(columns[min_required_args + i])->getData()[row_num])\n+                node->events_bitset.set(i);\n+        node->event_time = static_cast<DataTypeDateTime::FieldType>(timestamp);\n+\n+        node->can_be_base = assert_cast<const ColumnVector<UInt8> *>(columns[base_cond_column_idx])->getData()[row_num];\n+\n+        data(place).value.push_back(node, arena);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n+    {\n+        if (data(rhs).value.empty())\n+            return;\n+\n+        if (data(place).value.size() >= max_elems)\n+            return;\n+\n+        auto & a = data(place).value;\n+        auto & b = data(rhs).value;\n+        const auto a_size = a.size();\n+\n+        const UInt64 new_elems = std::min(data(rhs).value.size(), static_cast<size_t>(max_elems) - data(place).value.size());\n+        for (UInt64 i = 0; i < new_elems; ++i)\n+            a.push_back(b[i]->clone(arena), arena);\n+\n+        /// Either sort whole container or do so partially merging ranges afterwards\n+        using Comparator = typename SequenceNextNodeGeneralData<Node>::Comparator;\n+\n+        if (!data(place).sorted && !data(rhs).sorted)\n+            std::stable_sort(std::begin(a), std::end(a), Comparator{});\n+        else\n+        {\n+            const auto begin = std::begin(a);\n+            const auto middle = std::next(begin, a_size);\n+            const auto end = std::end(a);\n+\n+            if (!data(place).sorted)\n+                std::stable_sort(begin, middle, Comparator{});\n+\n+            if (!data(rhs).sorted)\n+                std::stable_sort(middle, end, Comparator{});\n+\n+            std::inplace_merge(begin, middle, end, Comparator{});\n+        }\n+\n+        data(place).sorted = true;\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        /// Temporarily do a const_cast to sort the values. It helps to reduce the computational burden on the initiator node.\n+        this->data(const_cast<AggregateDataPtr>(place)).sort();\n+\n+        writeBinary(data(place).sorted, buf);\n+\n+        auto & value = data(place).value;\n+\n+        size_t size = std::min(static_cast<size_t>(events_size + 1), value.size());\n+        switch (seq_base_kind)\n+        {\n+            case SequenceBase::Head:\n+                writeVarUInt(size, buf);\n+                for (size_t i = 0; i < size; ++i)\n+                    value[i]->write(buf);\n+                break;\n+\n+            case SequenceBase::Tail:\n+                writeVarUInt(size, buf);\n+                for (size_t i = 0; i < size; ++i)\n+                    value[value.size() - size + i]->write(buf);\n+                break;\n+\n+            case SequenceBase::FirstMatch:\n+            case SequenceBase::LastMatch:\n+                writeVarUInt(value.size(), buf);\n+                for (auto & node : value)\n+                    node->write(buf);\n+                break;\n+        }\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n+    {\n+        readBinary(data(place).sorted, buf);\n+\n+        UInt64 size;\n+        readVarUInt(size, buf);\n+\n+        if (unlikely(size == 0))\n+            return;\n+\n+        if (unlikely(size > max_node_size_deserialize))\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n+                            \"Too large array size (maximum: {})\", max_node_size_deserialize);\n+\n+        auto & value = data(place).value;\n+\n+        value.resize(size, arena);\n+        for (UInt64 i = 0; i < size; ++i)\n+            value[i] = Node::read(buf, arena);\n+    }\n+\n+    inline std::optional<size_t> getBaseIndex(Data & data) const\n+    {\n+        if (data.value.size() == 0)\n+            return {};\n+\n+        switch (seq_base_kind)\n+        {\n+            case SequenceBase::Head:\n+                if (data.value[0]->can_be_base)\n+                    return 0;\n+                break;\n+\n+            case SequenceBase::Tail:\n+                if (data.value[data.value.size() - 1]->can_be_base)\n+                    return data.value.size() - 1;\n+                break;\n+\n+            case SequenceBase::FirstMatch:\n+                for (size_t i = 0; i < data.value.size(); ++i)\n+                {\n+                    if (data.value[i]->events_bitset.test(0) && data.value[i]->can_be_base)\n+                        return i;\n+                }\n+                break;\n+\n+            case SequenceBase::LastMatch:\n+                for (size_t i = 0; i < data.value.size(); ++i)\n+                {\n+                    auto reversed_i = data.value.size() - i - 1;\n+                    if (data.value[reversed_i]->events_bitset.test(0) && data.value[reversed_i]->can_be_base)\n+                        return reversed_i;\n+                }\n+                break;\n+        }\n+\n+        return {};\n+    }\n+\n+    /// This method returns an index of next node that matched the events.\n+    /// matched events in the chain of events are represented as a bitmask.\n+    /// The first matched event is 0x00000001, the second one is 0x00000002, the third one is 0x00000004, and so on.\n+    UInt32 getNextNodeIndex(Data & data) const\n+    {\n+        const UInt32 unmatched_idx = static_cast<UInt32>(data.value.size());\n+\n+        if (data.value.size() <= events_size)\n+            return unmatched_idx;\n+\n+        data.sort();\n+\n+        std::optional<size_t> base_opt = getBaseIndex(data);\n+        if (!base_opt.has_value())\n+            return unmatched_idx;\n+        UInt32 base = static_cast<UInt32>(base_opt.value());\n+\n+        if (events_size == 0)\n+            return data.value.size() > 0 ? base : unmatched_idx;\n+\n+        UInt32 i = 0;\n+        switch (seq_direction)\n+        {\n+            case SequenceDirection::Forward:\n+                for (i = 0; i < events_size && base + i < data.value.size(); ++i)\n+                    if (!data.value[base + i]->events_bitset.test(i))\n+                        break;\n+                return (i == events_size) ? base + i : unmatched_idx;\n+\n+            case SequenceDirection::Backward:\n+                for (i = 0; i < events_size && i < base; ++i)\n+                    if (!data.value[base - i]->events_bitset.test(i))\n+                        break;\n+                return (i == events_size) ? base - i : unmatched_idx;\n+        }\n+        UNREACHABLE();\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        auto & value = data(place).value;\n+\n+        UInt32 event_idx = getNextNodeIndex(this->data(place));\n+        if (event_idx < value.size())\n+        {\n+            ColumnNullable & to_concrete = assert_cast<ColumnNullable &>(to);\n+            value[event_idx]->insertInto(to_concrete.getNestedColumn());\n+            to_concrete.getNullMapData().push_back(0);\n+        }\n+        else\n+        {\n+            to.insertDefault();\n+        }\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return true; }\n+};\n+\n+\n template <typename T>\n inline AggregateFunctionPtr createAggregateFunctionSequenceNodeImpl(\n     const DataTypePtr data_type, const DataTypes & argument_types, const Array & parameters, SequenceDirection direction, SequenceBase base)\ndiff --git a/src/AggregateFunctions/AggregateFunctionSequenceNextNode.h b/src/AggregateFunctions/AggregateFunctionSequenceNextNode.h\ndeleted file mode 100644\nindex 0f132a28b2b6..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionSequenceNextNode.h\n+++ /dev/null\n@@ -1,432 +0,0 @@\n-#pragma once\n-\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <IO/ReadBufferFromString.h>\n-#include <IO/WriteBufferFromString.h>\n-#include <IO/Operators.h>\n-\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypeString.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeDateTime.h>\n-\n-#include <Columns/ColumnString.h>\n-#include <Columns/ColumnVector.h>\n-#include <Columns/ColumnNullable.h>\n-\n-#include <Common/ArenaAllocator.h>\n-#include <Common/assert_cast.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-#include <type_traits>\n-#include <bitset>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int TOO_LARGE_ARRAY_SIZE;\n-}\n-\n-enum class SequenceDirection\n-{\n-    Forward,\n-    Backward,\n-};\n-\n-enum SequenceBase\n-{\n-    Head,\n-    Tail,\n-    FirstMatch,\n-    LastMatch,\n-};\n-\n-/// This is for security\n-static const UInt64 max_node_size_deserialize = 0xFFFFFF;\n-\n-/// NodeBase used to implement a linked list for storage of SequenceNextNodeImpl\n-template <typename Node, size_t MaxEventsSize>\n-struct NodeBase\n-{\n-    UInt64 size; /// size of payload\n-\n-    DataTypeDateTime::FieldType event_time;\n-    std::bitset<MaxEventsSize> events_bitset;\n-    bool can_be_base;\n-\n-    char * data() { return reinterpret_cast<char *>(this) + sizeof(Node); }\n-\n-    const char * data() const { return reinterpret_cast<const char *>(this) + sizeof(Node); }\n-\n-    Node * clone(Arena * arena) const\n-    {\n-        return reinterpret_cast<Node *>(\n-            const_cast<char *>(arena->alignedInsert(reinterpret_cast<const char *>(this), sizeof(Node) + size, alignof(Node))));\n-    }\n-\n-    void write(WriteBuffer & buf) const\n-    {\n-        writeVarUInt(size, buf);\n-        buf.write(data(), size);\n-\n-        writeBinary(event_time, buf);\n-        UInt64 ulong_bitset = events_bitset.to_ulong();\n-        writeBinary(ulong_bitset, buf);\n-        writeBinary(can_be_base, buf);\n-    }\n-\n-    static Node * read(ReadBuffer & buf, Arena * arena)\n-    {\n-        UInt64 size;\n-        readVarUInt(size, buf);\n-        if (unlikely(size > max_node_size_deserialize))\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE, \"Too large node state size\");\n-\n-        Node * node = reinterpret_cast<Node *>(arena->alignedAlloc(sizeof(Node) + size, alignof(Node)));\n-        node->size = size;\n-        buf.readStrict(node->data(), size);\n-\n-        readBinary(node->event_time, buf);\n-        UInt64 ulong_bitset;\n-        readBinary(ulong_bitset, buf);\n-        node->events_bitset = ulong_bitset;\n-        readBinary(node->can_be_base, buf);\n-\n-        return node;\n-    }\n-};\n-\n-/// It stores String, timestamp, bitset of matched events.\n-template <size_t MaxEventsSize>\n-struct NodeString : public NodeBase<NodeString<MaxEventsSize>, MaxEventsSize>\n-{\n-    using Node = NodeString<MaxEventsSize>;\n-\n-    static Node * allocate(const IColumn & column, size_t row_num, Arena * arena)\n-    {\n-        StringRef string = assert_cast<const ColumnString &>(column).getDataAt(row_num);\n-\n-        Node * node = reinterpret_cast<Node *>(arena->alignedAlloc(sizeof(Node) + string.size, alignof(Node)));\n-        node->size = string.size;\n-        memcpy(node->data(), string.data, string.size);\n-\n-        return node;\n-    }\n-\n-    void insertInto(IColumn & column)\n-    {\n-        assert_cast<ColumnString &>(column).insertData(this->data(), this->size);\n-    }\n-\n-    bool compare(const Node * rhs) const\n-    {\n-        auto cmp = strncmp(this->data(), rhs->data(), std::min(this->size, rhs->size));\n-        return (cmp == 0) ? this->size < rhs->size : cmp < 0;\n-    }\n-};\n-\n-/// TODO : Support other types than string\n-template <typename Node>\n-struct SequenceNextNodeGeneralData\n-{\n-    using Allocator = MixedAlignedArenaAllocator<alignof(Node *), 4096>;\n-    using Array = PODArray<Node *, 32, Allocator>;\n-\n-    Array value;\n-    bool sorted = false;\n-\n-    struct Comparator final\n-    {\n-        bool operator()(const Node * lhs, const Node * rhs) const\n-        {\n-            return lhs->event_time == rhs->event_time ? lhs->compare(rhs) : lhs->event_time < rhs->event_time;\n-        }\n-    };\n-\n-    void sort()\n-    {\n-        if (!sorted)\n-        {\n-            std::stable_sort(std::begin(value), std::end(value), Comparator{});\n-            sorted = true;\n-        }\n-    }\n-};\n-\n-/// Implementation of sequenceFirstNode\n-template <typename T, typename Node>\n-class SequenceNextNodeImpl final\n-    : public IAggregateFunctionDataHelper<SequenceNextNodeGeneralData<Node>, SequenceNextNodeImpl<T, Node>>\n-{\n-    using Self = SequenceNextNodeImpl<T, Node>;\n-\n-    using Data = SequenceNextNodeGeneralData<Node>;\n-    static Data & data(AggregateDataPtr __restrict place) { return *reinterpret_cast<Data *>(place); }\n-    static const Data & data(ConstAggregateDataPtr __restrict place) { return *reinterpret_cast<const Data *>(place); }\n-\n-    static constexpr size_t base_cond_column_idx = 2;\n-    static constexpr size_t event_column_idx = 1;\n-\n-    SequenceBase seq_base_kind;\n-    SequenceDirection seq_direction;\n-    const size_t min_required_args;\n-\n-    DataTypePtr & data_type;\n-    UInt8 events_size;\n-    UInt64 max_elems;\n-public:\n-    SequenceNextNodeImpl(\n-        const DataTypePtr & data_type_,\n-        const DataTypes & arguments,\n-        const Array & parameters_,\n-        SequenceBase seq_base_kind_,\n-        SequenceDirection seq_direction_,\n-        size_t min_required_args_,\n-        UInt64 max_elems_ = std::numeric_limits<UInt64>::max())\n-        : IAggregateFunctionDataHelper<SequenceNextNodeGeneralData<Node>, Self>(arguments, parameters_, data_type_)\n-        , seq_base_kind(seq_base_kind_)\n-        , seq_direction(seq_direction_)\n-        , min_required_args(min_required_args_)\n-        , data_type(this->argument_types[0])\n-        , events_size(arguments.size() - min_required_args)\n-        , max_elems(max_elems_)\n-    {\n-    }\n-\n-    String getName() const override { return \"sequenceNextNode\"; }\n-\n-    bool haveSameStateRepresentationImpl(const IAggregateFunction & rhs) const override\n-    {\n-        return this->getName() == rhs.getName() && this->haveEqualArgumentTypes(rhs);\n-    }\n-\n-    void insert(Data & a, const Node * v, Arena * arena) const\n-    {\n-        ++a.total_values;\n-        a.value.push_back(v->clone(arena), arena);\n-    }\n-\n-    void create(AggregateDataPtr __restrict place) const override /// NOLINT\n-    {\n-        new (place) Data;\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        Node * node = Node::allocate(*columns[event_column_idx], row_num, arena);\n-\n-        const auto timestamp = assert_cast<const ColumnVector<T> *>(columns[0])->getData()[row_num];\n-\n-        /// The events_bitset variable stores matched events in the form of bitset.\n-        /// Each Nth-bit indicates that the Nth-event are matched.\n-        /// For example, event1 and event3 is matched then the values of events_bitset is 0x00000005.\n-        ///   0x00000000\n-        /// +          1 (bit of event1)\n-        /// +          4 (bit of event3)\n-        node->events_bitset.reset();\n-        for (UInt8 i = 0; i < events_size; ++i)\n-            if (assert_cast<const ColumnVector<UInt8> *>(columns[min_required_args + i])->getData()[row_num])\n-                node->events_bitset.set(i);\n-        node->event_time = static_cast<DataTypeDateTime::FieldType>(timestamp);\n-\n-        node->can_be_base = assert_cast<const ColumnVector<UInt8> *>(columns[base_cond_column_idx])->getData()[row_num];\n-\n-        data(place).value.push_back(node, arena);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n-    {\n-        if (data(rhs).value.empty())\n-            return;\n-\n-        if (data(place).value.size() >= max_elems)\n-            return;\n-\n-        auto & a = data(place).value;\n-        auto & b = data(rhs).value;\n-        const auto a_size = a.size();\n-\n-        const UInt64 new_elems = std::min(data(rhs).value.size(), static_cast<size_t>(max_elems) - data(place).value.size());\n-        for (UInt64 i = 0; i < new_elems; ++i)\n-            a.push_back(b[i]->clone(arena), arena);\n-\n-        /// Either sort whole container or do so partially merging ranges afterwards\n-        using Comparator = typename SequenceNextNodeGeneralData<Node>::Comparator;\n-\n-        if (!data(place).sorted && !data(rhs).sorted)\n-            std::stable_sort(std::begin(a), std::end(a), Comparator{});\n-        else\n-        {\n-            const auto begin = std::begin(a);\n-            const auto middle = std::next(begin, a_size);\n-            const auto end = std::end(a);\n-\n-            if (!data(place).sorted)\n-                std::stable_sort(begin, middle, Comparator{});\n-\n-            if (!data(rhs).sorted)\n-                std::stable_sort(middle, end, Comparator{});\n-\n-            std::inplace_merge(begin, middle, end, Comparator{});\n-        }\n-\n-        data(place).sorted = true;\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        /// Temporarily do a const_cast to sort the values. It helps to reduce the computational burden on the initiator node.\n-        this->data(const_cast<AggregateDataPtr>(place)).sort();\n-\n-        writeBinary(data(place).sorted, buf);\n-\n-        auto & value = data(place).value;\n-\n-        size_t size = std::min(static_cast<size_t>(events_size + 1), value.size());\n-        switch (seq_base_kind)\n-        {\n-            case SequenceBase::Head:\n-                writeVarUInt(size, buf);\n-                for (size_t i = 0; i < size; ++i)\n-                    value[i]->write(buf);\n-                break;\n-\n-            case SequenceBase::Tail:\n-                writeVarUInt(size, buf);\n-                for (size_t i = 0; i < size; ++i)\n-                    value[value.size() - size + i]->write(buf);\n-                break;\n-\n-            case SequenceBase::FirstMatch:\n-            case SequenceBase::LastMatch:\n-                writeVarUInt(value.size(), buf);\n-                for (auto & node : value)\n-                    node->write(buf);\n-                break;\n-        }\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        readBinary(data(place).sorted, buf);\n-\n-        UInt64 size;\n-        readVarUInt(size, buf);\n-\n-        if (unlikely(size == 0))\n-            return;\n-\n-        if (unlikely(size > max_node_size_deserialize))\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n-                            \"Too large array size (maximum: {})\", max_node_size_deserialize);\n-\n-        auto & value = data(place).value;\n-\n-        value.resize(size, arena);\n-        for (UInt64 i = 0; i < size; ++i)\n-            value[i] = Node::read(buf, arena);\n-    }\n-\n-    inline std::optional<size_t> getBaseIndex(Data & data) const\n-    {\n-        if (data.value.size() == 0)\n-            return {};\n-\n-        switch (seq_base_kind)\n-        {\n-            case SequenceBase::Head:\n-                if (data.value[0]->can_be_base)\n-                    return 0;\n-                break;\n-\n-            case SequenceBase::Tail:\n-                if (data.value[data.value.size() - 1]->can_be_base)\n-                    return data.value.size() - 1;\n-                break;\n-\n-            case SequenceBase::FirstMatch:\n-                for (size_t i = 0; i < data.value.size(); ++i)\n-                {\n-                    if (data.value[i]->events_bitset.test(0) && data.value[i]->can_be_base)\n-                        return i;\n-                }\n-                break;\n-\n-            case SequenceBase::LastMatch:\n-                for (size_t i = 0; i < data.value.size(); ++i)\n-                {\n-                    auto reversed_i = data.value.size() - i - 1;\n-                    if (data.value[reversed_i]->events_bitset.test(0) && data.value[reversed_i]->can_be_base)\n-                        return reversed_i;\n-                }\n-                break;\n-        }\n-\n-        return {};\n-    }\n-\n-    /// This method returns an index of next node that matched the events.\n-    /// matched events in the chain of events are represented as a bitmask.\n-    /// The first matched event is 0x00000001, the second one is 0x00000002, the third one is 0x00000004, and so on.\n-    UInt32 getNextNodeIndex(Data & data) const\n-    {\n-        const UInt32 unmatched_idx = static_cast<UInt32>(data.value.size());\n-\n-        if (data.value.size() <= events_size)\n-            return unmatched_idx;\n-\n-        data.sort();\n-\n-        std::optional<size_t> base_opt = getBaseIndex(data);\n-        if (!base_opt.has_value())\n-            return unmatched_idx;\n-        UInt32 base = static_cast<UInt32>(base_opt.value());\n-\n-        if (events_size == 0)\n-            return data.value.size() > 0 ? base : unmatched_idx;\n-\n-        UInt32 i = 0;\n-        switch (seq_direction)\n-        {\n-            case SequenceDirection::Forward:\n-                for (i = 0; i < events_size && base + i < data.value.size(); ++i)\n-                    if (!data.value[base + i]->events_bitset.test(i))\n-                        break;\n-                return (i == events_size) ? base + i : unmatched_idx;\n-\n-            case SequenceDirection::Backward:\n-                for (i = 0; i < events_size && i < base; ++i)\n-                    if (!data.value[base - i]->events_bitset.test(i))\n-                        break;\n-                return (i == events_size) ? base - i : unmatched_idx;\n-        }\n-        UNREACHABLE();\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        auto & value = data(place).value;\n-\n-        UInt32 event_idx = getNextNodeIndex(this->data(place));\n-        if (event_idx < value.size())\n-        {\n-            ColumnNullable & to_concrete = assert_cast<ColumnNullable &>(to);\n-            value[event_idx]->insertInto(to_concrete.getNestedColumn());\n-            to_concrete.getNullMapData().push_back(0);\n-        }\n-        else\n-        {\n-            to.insertDefault();\n-        }\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return true; }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionSimpleLinearRegression.cpp b/src/AggregateFunctions/AggregateFunctionSimpleLinearRegression.cpp\nindex 1489db558579..75d2fe595d84 100644\n--- a/src/AggregateFunctions/AggregateFunctionSimpleLinearRegression.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionSimpleLinearRegression.cpp\n@@ -1,10 +1,21 @@\n-#include <AggregateFunctions/AggregateFunctionSimpleLinearRegression.h>\n-\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n \n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <Columns/ColumnVector.h>\n+#include <Columns/ColumnTuple.h>\n+#include <Common/assert_cast.h>\n+#include <DataTypes/DataTypeNullable.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeTuple.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+#include <limits>\n+\n+\n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n@@ -15,6 +26,161 @@ namespace ErrorCodes\n namespace\n {\n \n+struct AggregateFunctionSimpleLinearRegressionData final\n+{\n+    size_t count = 0;\n+    Float64 sum_x = 0;\n+    Float64 sum_y = 0;\n+    Float64 sum_xx = 0;\n+    Float64 sum_xy = 0;\n+\n+    void add(Float64 x, Float64 y)\n+    {\n+        count += 1;\n+        sum_x += x;\n+        sum_y += y;\n+        sum_xx += x * x;\n+        sum_xy += x * y;\n+    }\n+\n+    void merge(const AggregateFunctionSimpleLinearRegressionData & other)\n+    {\n+        count += other.count;\n+        sum_x += other.sum_x;\n+        sum_y += other.sum_y;\n+        sum_xx += other.sum_xx;\n+        sum_xy += other.sum_xy;\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        writeBinary(count, buf);\n+        writeBinary(sum_x, buf);\n+        writeBinary(sum_y, buf);\n+        writeBinary(sum_xx, buf);\n+        writeBinary(sum_xy, buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        readBinary(count, buf);\n+        readBinary(sum_x, buf);\n+        readBinary(sum_y, buf);\n+        readBinary(sum_xx, buf);\n+        readBinary(sum_xy, buf);\n+    }\n+\n+    Float64 getK() const\n+    {\n+        Float64 divisor = sum_xx * count - sum_x * sum_x;\n+\n+        if (divisor == 0)\n+            return std::numeric_limits<Float64>::quiet_NaN();\n+\n+        return (sum_xy * count - sum_x * sum_y) / divisor;\n+    }\n+\n+    Float64 getB(Float64 k) const\n+    {\n+        if (count == 0)\n+            return std::numeric_limits<Float64>::quiet_NaN();\n+\n+        return (sum_y - k * sum_x) / count;\n+    }\n+};\n+\n+/// Calculates simple linear regression parameters.\n+/// Result is a tuple (k, b) for y = k * x + b equation, solved by least squares approximation.\n+class AggregateFunctionSimpleLinearRegression final : public IAggregateFunctionDataHelper<\n+    AggregateFunctionSimpleLinearRegressionData,\n+    AggregateFunctionSimpleLinearRegression>\n+{\n+public:\n+    AggregateFunctionSimpleLinearRegression(\n+        const DataTypes & arguments,\n+        const Array & params\n+    ):\n+        IAggregateFunctionDataHelper<\n+            AggregateFunctionSimpleLinearRegressionData,\n+            AggregateFunctionSimpleLinearRegression\n+        > {arguments, params, createResultType()}\n+    {\n+        // notice: arguments has been checked before\n+    }\n+\n+    String getName() const override\n+    {\n+        return \"simpleLinearRegression\";\n+    }\n+\n+    void add(\n+        AggregateDataPtr __restrict place,\n+        const IColumn ** columns,\n+        size_t row_num,\n+        Arena *\n+    ) const override\n+    {\n+        Float64 x = columns[0]->getFloat64(row_num);\n+        Float64 y = columns[1]->getFloat64(row_num);\n+\n+        this->data(place).add(x, y);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    static DataTypePtr createResultType()\n+    {\n+        DataTypes types\n+        {\n+            std::make_shared<DataTypeNumber<Float64>>(),\n+            std::make_shared<DataTypeNumber<Float64>>(),\n+        };\n+\n+        Strings names\n+        {\n+            \"k\",\n+            \"b\",\n+        };\n+\n+        return std::make_shared<DataTypeTuple>(\n+            std::move(types),\n+            std::move(names)\n+        );\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void insertResultInto(\n+        AggregateDataPtr __restrict place,\n+        IColumn & to,\n+        Arena *) const override\n+    {\n+        Float64 k = this->data(place).getK();\n+        Float64 b = this->data(place).getB(k);\n+\n+        auto & col_tuple = assert_cast<ColumnTuple &>(to);\n+        auto & col_k = assert_cast<ColumnVector<Float64> &>(col_tuple.getColumn(0));\n+        auto & col_b = assert_cast<ColumnVector<Float64> &>(col_tuple.getColumn(1));\n+\n+        col_k.getData().push_back(k);\n+        col_b.getData().push_back(b);\n+    }\n+};\n+\n+\n AggregateFunctionPtr createAggregateFunctionSimpleLinearRegression(\n     const String & name,\n     const DataTypes & arguments,\n@@ -24,51 +190,12 @@ AggregateFunctionPtr createAggregateFunctionSimpleLinearRegression(\n     assertNoParameters(name, params);\n     assertBinary(name, arguments);\n \n-    const IDataType * x_arg = arguments.front().get();\n-    WhichDataType which_x = x_arg;\n-\n-    const IDataType * y_arg = arguments.back().get();\n-    WhichDataType which_y = y_arg;\n-\n-\n-    #define FOR_LEASTSQR_TYPES_2(M, T) \\\n-        M(T, UInt8) \\\n-        M(T, UInt16) \\\n-        M(T, UInt32) \\\n-        M(T, UInt64) \\\n-        M(T, Int8) \\\n-        M(T, Int16) \\\n-        M(T, Int32) \\\n-        M(T, Int64) \\\n-        M(T, Float32) \\\n-        M(T, Float64)\n-    #define FOR_LEASTSQR_TYPES(M) \\\n-        FOR_LEASTSQR_TYPES_2(M, UInt8) \\\n-        FOR_LEASTSQR_TYPES_2(M, UInt16) \\\n-        FOR_LEASTSQR_TYPES_2(M, UInt32) \\\n-        FOR_LEASTSQR_TYPES_2(M, UInt64) \\\n-        FOR_LEASTSQR_TYPES_2(M, Int8) \\\n-        FOR_LEASTSQR_TYPES_2(M, Int16) \\\n-        FOR_LEASTSQR_TYPES_2(M, Int32) \\\n-        FOR_LEASTSQR_TYPES_2(M, Int64) \\\n-        FOR_LEASTSQR_TYPES_2(M, Float32) \\\n-        FOR_LEASTSQR_TYPES_2(M, Float64)\n-    #define DISPATCH(T1, T2) \\\n-        if (which_x.idx == TypeIndex::T1 && which_y.idx == TypeIndex::T2) \\\n-            return std::make_shared<AggregateFunctionSimpleLinearRegression<T1, T2>>(/* NOLINT */ \\\n-                arguments, \\\n-                params \\\n-            );\n-\n-    FOR_LEASTSQR_TYPES(DISPATCH)\n-\n-    #undef FOR_LEASTSQR_TYPES_2\n-    #undef FOR_LEASTSQR_TYPES\n-    #undef DISPATCH\n-\n-    throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                    \"Illegal types ({}, {}) of arguments of aggregate function {}, must \"\n-                    \"be Native Ints, Native UInts or Floats\", x_arg->getName(), y_arg->getName(), name);\n+    if (!isNumber(arguments[0]) || !isNumber(arguments[1]))\n+        throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+            \"Illegal types ({}, {}) of arguments of aggregate function {}, must \"\n+            \"be Native Ints, Native UInts or Floats\", arguments[0]->getName(), arguments[1]->getName(), name);\n+\n+    return std::make_shared<AggregateFunctionSimpleLinearRegression>(arguments, params);\n }\n \n }\ndiff --git a/src/AggregateFunctions/AggregateFunctionSimpleLinearRegression.h b/src/AggregateFunctions/AggregateFunctionSimpleLinearRegression.h\ndeleted file mode 100644\nindex b0d448afb55b..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionSimpleLinearRegression.h\n+++ /dev/null\n@@ -1,182 +0,0 @@\n-#pragma once\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <Columns/ColumnVector.h>\n-#include <Columns/ColumnTuple.h>\n-#include <Common/assert_cast.h>\n-#include <DataTypes/DataTypeNullable.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <limits>\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-}\n-\n-template <typename T>\n-struct AggregateFunctionSimpleLinearRegressionData final\n-{\n-    size_t count = 0;\n-    T sum_x = 0;\n-    T sum_y = 0;\n-    T sum_xx = 0;\n-    T sum_xy = 0;\n-\n-    void add(T x, T y)\n-    {\n-        count += 1;\n-        sum_x += x;\n-        sum_y += y;\n-        sum_xx += x * x;\n-        sum_xy += x * y;\n-    }\n-\n-    void merge(const AggregateFunctionSimpleLinearRegressionData & other)\n-    {\n-        count += other.count;\n-        sum_x += other.sum_x;\n-        sum_y += other.sum_y;\n-        sum_xx += other.sum_xx;\n-        sum_xy += other.sum_xy;\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        writeBinary(count, buf);\n-        writeBinary(sum_x, buf);\n-        writeBinary(sum_y, buf);\n-        writeBinary(sum_xx, buf);\n-        writeBinary(sum_xy, buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        readBinary(count, buf);\n-        readBinary(sum_x, buf);\n-        readBinary(sum_y, buf);\n-        readBinary(sum_xx, buf);\n-        readBinary(sum_xy, buf);\n-    }\n-\n-    T getK() const\n-    {\n-        T divisor = sum_xx * count - sum_x * sum_x;\n-\n-        if (divisor == 0)\n-            return std::numeric_limits<T>::quiet_NaN();\n-\n-        return (sum_xy * count - sum_x * sum_y) / divisor;\n-    }\n-\n-    T getB(T k) const\n-    {\n-        if (count == 0)\n-            return std::numeric_limits<T>::quiet_NaN();\n-\n-        return (sum_y - k * sum_x) / count;\n-    }\n-};\n-\n-/// Calculates simple linear regression parameters.\n-/// Result is a tuple (k, b) for y = k * x + b equation, solved by least squares approximation.\n-template <typename X, typename Y, typename Ret = Float64>\n-class AggregateFunctionSimpleLinearRegression final : public IAggregateFunctionDataHelper<\n-    AggregateFunctionSimpleLinearRegressionData<Ret>,\n-    AggregateFunctionSimpleLinearRegression<X, Y, Ret>\n->\n-{\n-public:\n-    AggregateFunctionSimpleLinearRegression(\n-        const DataTypes & arguments,\n-        const Array & params\n-    ):\n-        IAggregateFunctionDataHelper<\n-            AggregateFunctionSimpleLinearRegressionData<Ret>,\n-            AggregateFunctionSimpleLinearRegression<X, Y, Ret>\n-        > {arguments, params, createResultType()}\n-    {\n-        // notice: arguments has been checked before\n-    }\n-\n-    String getName() const override\n-    {\n-        return \"simpleLinearRegression\";\n-    }\n-\n-    void add(\n-        AggregateDataPtr __restrict place,\n-        const IColumn ** columns,\n-        size_t row_num,\n-        Arena *\n-    ) const override\n-    {\n-        auto col_x = assert_cast<const ColumnVector<X> *>(columns[0]);\n-        auto col_y = assert_cast<const ColumnVector<Y> *>(columns[1]);\n-\n-        X x = col_x->getData()[row_num];\n-        Y y = col_y->getData()[row_num];\n-\n-        this->data(place).add(x, y);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).deserialize(buf);\n-    }\n-\n-    static DataTypePtr createResultType()\n-    {\n-        DataTypes types\n-        {\n-            std::make_shared<DataTypeNumber<Ret>>(),\n-            std::make_shared<DataTypeNumber<Ret>>(),\n-        };\n-\n-        Strings names\n-        {\n-            \"k\",\n-            \"b\",\n-        };\n-\n-        return std::make_shared<DataTypeTuple>(\n-            std::move(types),\n-            std::move(names)\n-        );\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void insertResultInto(\n-        AggregateDataPtr __restrict place,\n-        IColumn & to,\n-        Arena *) const override\n-    {\n-        Ret k = this->data(place).getK();\n-        Ret b = this->data(place).getB(k);\n-\n-        auto & col_tuple = assert_cast<ColumnTuple &>(to);\n-        auto & col_k = assert_cast<ColumnVector<Ret> &>(col_tuple.getColumn(0));\n-        auto & col_b = assert_cast<ColumnVector<Ret> &>(col_tuple.getColumn(1));\n-\n-        col_k.getData().push_back(k);\n-        col_b.getData().push_back(b);\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionSparkbar.cpp b/src/AggregateFunctions/AggregateFunctionSparkbar.cpp\nindex e87e3b306c2f..7ff9df038243 100644\n--- a/src/AggregateFunctions/AggregateFunctionSparkbar.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionSparkbar.cpp\n@@ -1,8 +1,18 @@\n-#include <AggregateFunctions/AggregateFunctionSparkbar.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n-#include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n \n+#include <array>\n+#include <string_view>\n+#include <DataTypes/DataTypeString.h>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+#include <Columns/ColumnString.h>\n+#include <Common/PODArray.h>\n+#include <IO/ReadBufferFromString.h>\n+#include <Common/HashTable/HashMap.h>\n+#include <Columns/IColumn.h>\n+\n \n namespace DB\n {\n@@ -13,11 +23,309 @@ namespace ErrorCodes\n {\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int BAD_ARGUMENTS;\n }\n \n namespace\n {\n \n+template<typename X, typename Y>\n+struct AggregateFunctionSparkbarData\n+{\n+    /// TODO: calculate histogram instead of storing all points\n+    using Points = HashMap<X, Y>;\n+    Points points;\n+\n+    X min_x = std::numeric_limits<X>::max();\n+    X max_x = std::numeric_limits<X>::lowest();\n+\n+    Y min_y = std::numeric_limits<Y>::max();\n+    Y max_y = std::numeric_limits<Y>::lowest();\n+\n+    Y insert(const X & x, const Y & y)\n+    {\n+        if (isNaN(y) || y <= 0)\n+            return 0;\n+\n+        auto [it, inserted] = points.insert({x, y});\n+        if (!inserted)\n+        {\n+            if constexpr (std::is_floating_point_v<Y>)\n+            {\n+                it->getMapped() += y;\n+                return it->getMapped();\n+            }\n+            else\n+            {\n+                Y res;\n+                bool has_overfllow = common::addOverflow(it->getMapped(), y, res);\n+                it->getMapped() = has_overfllow ? std::numeric_limits<Y>::max() : res;\n+            }\n+        }\n+        return it->getMapped();\n+    }\n+\n+    void add(X x, Y y)\n+    {\n+        auto new_y = insert(x, y);\n+\n+        min_x = std::min(x, min_x);\n+        max_x = std::max(x, max_x);\n+\n+        min_y = std::min(y, min_y);\n+        max_y = std::max(new_y, max_y);\n+    }\n+\n+    void merge(const AggregateFunctionSparkbarData & other)\n+    {\n+        if (other.points.empty())\n+            return;\n+\n+        for (auto & point : other.points)\n+        {\n+            auto new_y = insert(point.getKey(), point.getMapped());\n+            max_y = std::max(new_y, max_y);\n+        }\n+\n+        min_x = std::min(other.min_x, min_x);\n+        max_x = std::max(other.max_x, max_x);\n+\n+        min_y = std::min(other.min_y, min_y);\n+        max_y = std::max(other.max_y, max_y);\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        writeBinary(min_x, buf);\n+        writeBinary(max_x, buf);\n+        writeBinary(min_y, buf);\n+        writeBinary(max_y, buf);\n+        writeVarUInt(points.size(), buf);\n+\n+        for (const auto & elem : points)\n+        {\n+            writeBinary(elem.getKey(), buf);\n+            writeBinary(elem.getMapped(), buf);\n+        }\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        readBinary(min_x, buf);\n+        readBinary(max_x, buf);\n+        readBinary(min_y, buf);\n+        readBinary(max_y, buf);\n+        size_t size;\n+        readVarUInt(size, buf);\n+\n+        X x;\n+        Y y;\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            readBinary(x, buf);\n+            readBinary(y, buf);\n+            insert(x, y);\n+        }\n+    }\n+};\n+\n+template<typename X, typename Y>\n+class AggregateFunctionSparkbar final\n+    : public IAggregateFunctionDataHelper<AggregateFunctionSparkbarData<X, Y>, AggregateFunctionSparkbar<X, Y>>\n+{\n+\n+private:\n+    static constexpr size_t BAR_LEVELS = 8;\n+    const size_t width = 0;\n+\n+    /// Range for x specified in parameters.\n+    const bool is_specified_range_x = false;\n+    const X begin_x = std::numeric_limits<X>::min();\n+    const X end_x = std::numeric_limits<X>::max();\n+\n+    size_t updateFrame(ColumnString::Chars & frame, Y value) const\n+    {\n+        static constexpr std::array<std::string_view, BAR_LEVELS + 1> bars{\" \", \"\u2581\", \"\u2582\", \"\u2583\", \"\u2584\", \"\u2585\", \"\u2586\", \"\u2587\", \"\u2588\"};\n+        const auto & bar = (isNaN(value) || value < 1 || static_cast<Y>(BAR_LEVELS) < value) ? bars[0] : bars[static_cast<UInt8>(value)];\n+        frame.insert(bar.begin(), bar.end());\n+        return bar.size();\n+    }\n+\n+    /**\n+     *  The minimum value of y is rendered as the lowest height \"\u2581\",\n+     *  the maximum value of y is rendered as the highest height \"\u2588\", and the middle value will be rendered proportionally.\n+     *  If a bucket has no y value, it will be rendered as \" \".\n+     */\n+    void render(ColumnString & to_column, const AggregateFunctionSparkbarData<X, Y> & data) const\n+    {\n+        auto & values = to_column.getChars();\n+        auto & offsets = to_column.getOffsets();\n+\n+        if (data.points.empty())\n+        {\n+            values.push_back('\\0');\n+            offsets.push_back(offsets.empty() ? 1 : offsets.back() + 1);\n+            return;\n+        }\n+\n+        auto from_x = is_specified_range_x ? begin_x : data.min_x;\n+        auto to_x = is_specified_range_x ? end_x : data.max_x;\n+\n+        if (from_x >= to_x)\n+        {\n+            size_t sz = updateFrame(values, 8);\n+            values.push_back('\\0');\n+            offsets.push_back(offsets.empty() ? sz + 1 : offsets.back() + sz + 1);\n+            return;\n+        }\n+\n+        PaddedPODArray<Y> histogram(width, 0);\n+        PaddedPODArray<UInt64> count_histogram(width, 0); /// The number of points in each bucket\n+\n+        for (const auto & point : data.points)\n+        {\n+            if (point.getKey() < from_x || to_x < point.getKey())\n+                continue;\n+\n+            X delta = to_x - from_x;\n+            if (delta < std::numeric_limits<X>::max())\n+                delta = delta + 1;\n+\n+            X value = point.getKey() - from_x;\n+            Float64 w = histogram.size();\n+            size_t index = std::min<size_t>(static_cast<size_t>(w / delta * value), histogram.size() - 1);\n+\n+            Y res;\n+            bool has_overfllow = false;\n+            if constexpr (std::is_floating_point_v<Y>)\n+                res = histogram[index] + point.getMapped();\n+            else\n+                has_overfllow = common::addOverflow(histogram[index], point.getMapped(), res);\n+\n+            if (unlikely(has_overfllow))\n+            {\n+                /// In case of overflow, just saturate\n+                /// Do not count new values, because we do not know how many of them were added\n+                histogram[index] = std::numeric_limits<Y>::max();\n+            }\n+            else\n+            {\n+                histogram[index] = res;\n+                count_histogram[index] += 1;\n+            }\n+        }\n+\n+        for (size_t i = 0; i < histogram.size(); ++i)\n+        {\n+            if (count_histogram[i] > 0)\n+                histogram[i] /= count_histogram[i];\n+        }\n+\n+        Y y_max = 0;\n+        for (auto & y : histogram)\n+        {\n+            if (isNaN(y) || y <= 0)\n+                continue;\n+            y_max = std::max(y_max, y);\n+        }\n+\n+        if (y_max == 0)\n+        {\n+            values.push_back('\\0');\n+            offsets.push_back(offsets.empty() ? 1 : offsets.back() + 1);\n+            return;\n+        }\n+\n+        /// Scale the histogram to the range [0, BAR_LEVELS]\n+        for (auto & y : histogram)\n+        {\n+            if (isNaN(y) || y <= 0)\n+            {\n+                y = 0;\n+                continue;\n+            }\n+\n+            constexpr auto levels_num = static_cast<Y>(BAR_LEVELS - 1);\n+            if constexpr (std::is_floating_point_v<Y>)\n+            {\n+                y = y / (y_max / levels_num) + 1;\n+            }\n+            else\n+            {\n+                Y scaled;\n+                bool has_overfllow = common::mulOverflow<Y>(y, levels_num, scaled);\n+\n+                if (has_overfllow)\n+                    y = y / (y_max / levels_num) + 1;\n+                else\n+                    y = scaled / y_max + 1;\n+            }\n+        }\n+\n+        size_t sz = 0;\n+        for (const auto & y : histogram)\n+            sz += updateFrame(values, y);\n+\n+        values.push_back('\\0');\n+        offsets.push_back(offsets.empty() ? sz + 1 : offsets.back() + sz + 1);\n+    }\n+\n+public:\n+    AggregateFunctionSparkbar(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<AggregateFunctionSparkbarData<X, Y>, AggregateFunctionSparkbar>(arguments, params, std::make_shared<DataTypeString>())\n+        , width(params.empty() ? 0 : params.at(0).safeGet<UInt64>())\n+        , is_specified_range_x(params.size() >= 3)\n+        , begin_x(is_specified_range_x ? static_cast<X>(params.at(1).safeGet<X>()) : std::numeric_limits<X>::min())\n+        , end_x(is_specified_range_x ? static_cast<X>(params.at(2).safeGet<X>()) : std::numeric_limits<X>::max())\n+    {\n+        if (width < 2 || 1024 < width)\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Parameter width must be in range [2, 1024]\");\n+\n+        if (begin_x >= end_x)\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Parameter `min_x` must be less than `max_x`\");\n+    }\n+\n+    String getName() const override\n+    {\n+        return \"sparkbar\";\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * /*arena*/) const override\n+    {\n+        X x = assert_cast<const ColumnVector<X> *>(columns[0])->getData()[row_num];\n+        if (begin_x <= x && x <= end_x)\n+        {\n+            Y y = assert_cast<const ColumnVector<Y> *>(columns[1])->getData()[row_num];\n+            this->data(place).add(x, y);\n+        }\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr __restrict rhs, Arena * /*arena*/) const override\n+    {\n+        this->data(place).merge(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena * /*arena*/) const override\n+    {\n+        auto & to_column = assert_cast<ColumnString &>(to);\n+        const auto & data = this->data(place);\n+        render(to_column, data);\n+    }\n+};\n+\n+\n template <template <typename, typename> class AggregateFunctionTemplate, typename Data, typename ... TArgs>\n IAggregateFunction * createWithUIntegerOrTimeType(const std::string & name, const IDataType & argument_type, TArgs && ... args)\n {\ndiff --git a/src/AggregateFunctions/AggregateFunctionSparkbar.h b/src/AggregateFunctions/AggregateFunctionSparkbar.h\ndeleted file mode 100644\nindex 30e107bc4db7..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionSparkbar.h\n+++ /dev/null\n@@ -1,323 +0,0 @@\n-#pragma once\n-\n-#include <base/arithmeticOverflow.h>\n-\n-#include <array>\n-#include <string_view>\n-#include <DataTypes/DataTypeString.h>\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <base/range.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <Columns/ColumnString.h>\n-#include <Common/PODArray.h>\n-#include <IO/ReadBufferFromString.h>\n-#include <Common/HashTable/HashMap.h>\n-#include <Columns/IColumn.h>\n-\n-\n-namespace DB\n-{\n-\n-namespace ErrorCodes\n-{\n-    extern const int BAD_ARGUMENTS;\n-}\n-\n-template<typename X, typename Y>\n-struct AggregateFunctionSparkbarData\n-{\n-    /// TODO: calculate histogram instead of storing all points\n-    using Points = HashMap<X, Y>;\n-    Points points;\n-\n-    X min_x = std::numeric_limits<X>::max();\n-    X max_x = std::numeric_limits<X>::lowest();\n-\n-    Y min_y = std::numeric_limits<Y>::max();\n-    Y max_y = std::numeric_limits<Y>::lowest();\n-\n-    Y insert(const X & x, const Y & y)\n-    {\n-        if (isNaN(y) || y <= 0)\n-            return 0;\n-\n-        auto [it, inserted] = points.insert({x, y});\n-        if (!inserted)\n-        {\n-            if constexpr (std::is_floating_point_v<Y>)\n-            {\n-                it->getMapped() += y;\n-                return it->getMapped();\n-            }\n-            else\n-            {\n-                Y res;\n-                bool has_overfllow = common::addOverflow(it->getMapped(), y, res);\n-                it->getMapped() = has_overfllow ? std::numeric_limits<Y>::max() : res;\n-            }\n-        }\n-        return it->getMapped();\n-    }\n-\n-    void add(X x, Y y)\n-    {\n-        auto new_y = insert(x, y);\n-\n-        min_x = std::min(x, min_x);\n-        max_x = std::max(x, max_x);\n-\n-        min_y = std::min(y, min_y);\n-        max_y = std::max(new_y, max_y);\n-    }\n-\n-    void merge(const AggregateFunctionSparkbarData & other)\n-    {\n-        if (other.points.empty())\n-            return;\n-\n-        for (auto & point : other.points)\n-        {\n-            auto new_y = insert(point.getKey(), point.getMapped());\n-            max_y = std::max(new_y, max_y);\n-        }\n-\n-        min_x = std::min(other.min_x, min_x);\n-        max_x = std::max(other.max_x, max_x);\n-\n-        min_y = std::min(other.min_y, min_y);\n-        max_y = std::max(other.max_y, max_y);\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        writeBinary(min_x, buf);\n-        writeBinary(max_x, buf);\n-        writeBinary(min_y, buf);\n-        writeBinary(max_y, buf);\n-        writeVarUInt(points.size(), buf);\n-\n-        for (const auto & elem : points)\n-        {\n-            writeBinary(elem.getKey(), buf);\n-            writeBinary(elem.getMapped(), buf);\n-        }\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        readBinary(min_x, buf);\n-        readBinary(max_x, buf);\n-        readBinary(min_y, buf);\n-        readBinary(max_y, buf);\n-        size_t size;\n-        readVarUInt(size, buf);\n-\n-        X x;\n-        Y y;\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            readBinary(x, buf);\n-            readBinary(y, buf);\n-            insert(x, y);\n-        }\n-    }\n-};\n-\n-template<typename X, typename Y>\n-class AggregateFunctionSparkbar final\n-    : public IAggregateFunctionDataHelper<AggregateFunctionSparkbarData<X, Y>, AggregateFunctionSparkbar<X, Y>>\n-{\n-\n-private:\n-    static constexpr size_t BAR_LEVELS = 8;\n-    const size_t width = 0;\n-\n-    /// Range for x specified in parameters.\n-    const bool is_specified_range_x = false;\n-    const X begin_x = std::numeric_limits<X>::min();\n-    const X end_x = std::numeric_limits<X>::max();\n-\n-    size_t updateFrame(ColumnString::Chars & frame, Y value) const\n-    {\n-        static constexpr std::array<std::string_view, BAR_LEVELS + 1> bars{\" \", \"\u2581\", \"\u2582\", \"\u2583\", \"\u2584\", \"\u2585\", \"\u2586\", \"\u2587\", \"\u2588\"};\n-        const auto & bar = (isNaN(value) || value < 1 || static_cast<Y>(BAR_LEVELS) < value) ? bars[0] : bars[static_cast<UInt8>(value)];\n-        frame.insert(bar.begin(), bar.end());\n-        return bar.size();\n-    }\n-\n-    /**\n-     *  The minimum value of y is rendered as the lowest height \"\u2581\",\n-     *  the maximum value of y is rendered as the highest height \"\u2588\", and the middle value will be rendered proportionally.\n-     *  If a bucket has no y value, it will be rendered as \" \".\n-     */\n-    void render(ColumnString & to_column, const AggregateFunctionSparkbarData<X, Y> & data) const\n-    {\n-        auto & values = to_column.getChars();\n-        auto & offsets = to_column.getOffsets();\n-\n-        if (data.points.empty())\n-        {\n-            values.push_back('\\0');\n-            offsets.push_back(offsets.empty() ? 1 : offsets.back() + 1);\n-            return;\n-        }\n-\n-        auto from_x = is_specified_range_x ? begin_x : data.min_x;\n-        auto to_x = is_specified_range_x ? end_x : data.max_x;\n-\n-        if (from_x >= to_x)\n-        {\n-            size_t sz = updateFrame(values, 8);\n-            values.push_back('\\0');\n-            offsets.push_back(offsets.empty() ? sz + 1 : offsets.back() + sz + 1);\n-            return;\n-        }\n-\n-        PaddedPODArray<Y> histogram(width, 0);\n-        PaddedPODArray<UInt64> count_histogram(width, 0); /// The number of points in each bucket\n-\n-        for (const auto & point : data.points)\n-        {\n-            if (point.getKey() < from_x || to_x < point.getKey())\n-                continue;\n-\n-            X delta = to_x - from_x;\n-            if (delta < std::numeric_limits<X>::max())\n-                delta = delta + 1;\n-\n-            X value = point.getKey() - from_x;\n-            Float64 w = histogram.size();\n-            size_t index = std::min<size_t>(static_cast<size_t>(w / delta * value), histogram.size() - 1);\n-\n-            Y res;\n-            bool has_overfllow = false;\n-            if constexpr (std::is_floating_point_v<Y>)\n-                res = histogram[index] + point.getMapped();\n-            else\n-                has_overfllow = common::addOverflow(histogram[index], point.getMapped(), res);\n-\n-            if (unlikely(has_overfllow))\n-            {\n-                /// In case of overflow, just saturate\n-                /// Do not count new values, because we do not know how many of them were added\n-                histogram[index] = std::numeric_limits<Y>::max();\n-            }\n-            else\n-            {\n-                histogram[index] = res;\n-                count_histogram[index] += 1;\n-            }\n-        }\n-\n-        for (size_t i = 0; i < histogram.size(); ++i)\n-        {\n-            if (count_histogram[i] > 0)\n-                histogram[i] /= count_histogram[i];\n-        }\n-\n-        Y y_max = 0;\n-        for (auto & y : histogram)\n-        {\n-            if (isNaN(y) || y <= 0)\n-                continue;\n-            y_max = std::max(y_max, y);\n-        }\n-\n-        if (y_max == 0)\n-        {\n-            values.push_back('\\0');\n-            offsets.push_back(offsets.empty() ? 1 : offsets.back() + 1);\n-            return;\n-        }\n-\n-        /// Scale the histogram to the range [0, BAR_LEVELS]\n-        for (auto & y : histogram)\n-        {\n-            if (isNaN(y) || y <= 0)\n-            {\n-                y = 0;\n-                continue;\n-            }\n-\n-            constexpr auto levels_num = static_cast<Y>(BAR_LEVELS - 1);\n-            if constexpr (std::is_floating_point_v<Y>)\n-            {\n-                y = y / (y_max / levels_num) + 1;\n-            }\n-            else\n-            {\n-                Y scaled;\n-                bool has_overfllow = common::mulOverflow<Y>(y, levels_num, scaled);\n-\n-                if (has_overfllow)\n-                    y = y / (y_max / levels_num) + 1;\n-                else\n-                    y = scaled / y_max + 1;\n-            }\n-        }\n-\n-        size_t sz = 0;\n-        for (const auto & y : histogram)\n-            sz += updateFrame(values, y);\n-\n-        values.push_back('\\0');\n-        offsets.push_back(offsets.empty() ? sz + 1 : offsets.back() + sz + 1);\n-    }\n-\n-public:\n-    AggregateFunctionSparkbar(const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper<AggregateFunctionSparkbarData<X, Y>, AggregateFunctionSparkbar>(arguments, params, std::make_shared<DataTypeString>())\n-        , width(params.empty() ? 0 : params.at(0).safeGet<UInt64>())\n-        , is_specified_range_x(params.size() >= 3)\n-        , begin_x(is_specified_range_x ? static_cast<X>(params.at(1).safeGet<X>()) : std::numeric_limits<X>::min())\n-        , end_x(is_specified_range_x ? static_cast<X>(params.at(2).safeGet<X>()) : std::numeric_limits<X>::max())\n-    {\n-        if (width < 2 || 1024 < width)\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Parameter width must be in range [2, 1024]\");\n-\n-        if (begin_x >= end_x)\n-            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Parameter `min_x` must be less than `max_x`\");\n-    }\n-\n-    String getName() const override\n-    {\n-        return \"sparkbar\";\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * /*arena*/) const override\n-    {\n-        X x = assert_cast<const ColumnVector<X> *>(columns[0])->getData()[row_num];\n-        if (begin_x <= x && x <= end_x)\n-        {\n-            Y y = assert_cast<const ColumnVector<Y> *>(columns[1])->getData()[row_num];\n-            this->data(place).add(x, y);\n-        }\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr __restrict rhs, Arena * /*arena*/) const override\n-    {\n-        this->data(place).merge(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).deserialize(buf);\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena * /*arena*/) const override\n-    {\n-        auto & to_column = assert_cast<ColumnString &>(to);\n-        const auto & data = this->data(place);\n-        render(to_column, data);\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionStatistics.cpp b/src/AggregateFunctions/AggregateFunctionStatistics.cpp\nindex 00a47497adaa..e9d9b7409cad 100644\n--- a/src/AggregateFunctions/AggregateFunctionStatistics.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionStatistics.cpp\n@@ -1,7 +1,15 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n #include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n-#include <AggregateFunctions/AggregateFunctionStatistics.h>\n+\n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadHelpers.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <Columns/ColumnsNumber.h>\n+#include <Common/assert_cast.h>\n+\n+#include <cmath>\n \n \n namespace DB\n@@ -16,6 +24,430 @@ namespace ErrorCodes\n namespace\n {\n \n+/// This function returns true if both values are large and comparable.\n+/// It is used to calculate the mean value by merging two sources.\n+/// It means that if the sizes of both sources are large and comparable, then we must apply a special\n+///  formula guaranteeing more stability.\n+bool areComparable(UInt64 a, UInt64 b)\n+{\n+    const Float64 sensitivity = 0.001;\n+    const UInt64 threshold = 10000;\n+\n+    if ((a == 0) || (b == 0))\n+        return false;\n+\n+    auto res = std::minmax(a, b);\n+    return (((1 - static_cast<Float64>(res.first) / res.second) < sensitivity) && (res.first > threshold));\n+}\n+\n+\n+/** Statistical aggregate functions\n+  * varSamp - sample variance\n+  * stddevSamp - mean sample quadratic deviation\n+  * varPop - variance\n+  * stddevPop - standard deviation\n+  * covarSamp - selective covariance\n+  * covarPop - covariance\n+  * corr - correlation\n+  */\n+\n+/** Parallel and incremental algorithm for calculating variance.\n+  * Source: \"Updating formulae and a pairwise algorithm for computing sample variances\"\n+  * (Chan et al., Stanford University, 12.1979)\n+  */\n+struct AggregateFunctionVarianceData\n+{\n+    void update(const IColumn & column, size_t row_num)\n+    {\n+        Float64 val = column.getFloat64(row_num);\n+        Float64 delta = val - mean;\n+\n+        ++count;\n+        mean += delta / count;\n+        m2 += delta * (val - mean);\n+    }\n+\n+    void mergeWith(const AggregateFunctionVarianceData & source)\n+    {\n+        UInt64 total_count = count + source.count;\n+        if (total_count == 0)\n+            return;\n+\n+        Float64 factor = static_cast<Float64>(count * source.count) / total_count;\n+        Float64 delta = mean - source.mean;\n+\n+        if (areComparable(count, source.count))\n+            mean = (source.count * source.mean + count * mean) / total_count;\n+        else\n+            mean = source.mean + delta * (static_cast<Float64>(count) / total_count);\n+\n+        m2 += source.m2 + delta * delta * factor;\n+        count = total_count;\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        writeVarUInt(count, buf);\n+        writeBinary(mean, buf);\n+        writeBinary(m2, buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        readVarUInt(count, buf);\n+        readBinary(mean, buf);\n+        readBinary(m2, buf);\n+    }\n+\n+    UInt64 count = 0;\n+    Float64 mean = 0.0;\n+    Float64 m2 = 0.0;\n+};\n+\n+enum class VarKind\n+{\n+    varSampStable,\n+    stddevSampStable,\n+    varPopStable,\n+    stddevPopStable,\n+};\n+\n+/** The main code for the implementation of varSamp, stddevSamp, varPop, stddevPop.\n+  */\n+class AggregateFunctionVariance final\n+    : public IAggregateFunctionDataHelper<AggregateFunctionVarianceData, AggregateFunctionVariance>\n+{\n+private:\n+    VarKind kind;\n+\n+    static Float64 getVarSamp(Float64 m2, UInt64 count)\n+    {\n+        if (count < 2)\n+            return std::numeric_limits<Float64>::infinity();\n+        else\n+            return m2 / (count - 1);\n+    }\n+\n+    static Float64 getStddevSamp(Float64 m2, UInt64 count)\n+    {\n+        return sqrt(getVarSamp(m2, count));\n+    }\n+\n+    static Float64 getVarPop(Float64 m2, UInt64 count)\n+    {\n+        if (count == 0)\n+            return std::numeric_limits<Float64>::infinity();\n+        else if (count == 1)\n+            return 0.0;\n+        else\n+            return m2 / count;\n+    }\n+\n+    static Float64 getStddevPop(Float64 m2, UInt64 count)\n+    {\n+        return sqrt(getVarPop(m2, count));\n+    }\n+\n+    Float64 getResult(ConstAggregateDataPtr __restrict place) const\n+    {\n+        const auto & data = this->data(place);\n+        switch (kind)\n+        {\n+            case VarKind::varSampStable: return getVarSamp(data.m2, data.count);\n+            case VarKind::stddevSampStable: return getStddevSamp(data.m2, data.count);\n+            case VarKind::varPopStable: return getVarPop(data.m2, data.count);\n+            case VarKind::stddevPopStable: return getStddevPop(data.m2, data.count);\n+        }\n+    }\n+\n+public:\n+    explicit AggregateFunctionVariance(VarKind kind_, const DataTypePtr & arg)\n+        : IAggregateFunctionDataHelper<AggregateFunctionVarianceData, AggregateFunctionVariance>({arg}, {}, std::make_shared<DataTypeFloat64>()),\n+        kind(kind_)\n+    {\n+    }\n+\n+    String getName() const override\n+    {\n+        switch (kind)\n+        {\n+            case VarKind::varSampStable: return \"varSampStable\";\n+            case VarKind::stddevSampStable: return \"stddevSampStable\";\n+            case VarKind::varPopStable: return \"varPopStable\";\n+            case VarKind::stddevPopStable: return \"stddevPopStable\";\n+        }\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        this->data(place).update(*columns[0], row_num);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).mergeWith(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        assert_cast<ColumnFloat64 &>(to).getData().push_back(getResult(place));\n+    }\n+};\n+\n+\n+/** If `compute_marginal_moments` flag is set this class provides the successor\n+  * CovarianceData support of marginal moments for calculating the correlation.\n+  */\n+template <bool compute_marginal_moments>\n+struct BaseCovarianceData\n+{\n+    void incrementMarginalMoments(Float64, Float64) {}\n+    void mergeWith(const BaseCovarianceData &) {}\n+    void serialize(WriteBuffer &) const {}\n+    void deserialize(const ReadBuffer &) {}\n+};\n+\n+template <>\n+struct BaseCovarianceData<true>\n+{\n+    void incrementMarginalMoments(Float64 left_incr, Float64 right_incr)\n+    {\n+        left_m2 += left_incr;\n+        right_m2 += right_incr;\n+    }\n+\n+    void mergeWith(const BaseCovarianceData & source)\n+    {\n+        left_m2 += source.left_m2;\n+        right_m2 += source.right_m2;\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        writeBinary(left_m2, buf);\n+        writeBinary(right_m2, buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        readBinary(left_m2, buf);\n+        readBinary(right_m2, buf);\n+    }\n+\n+    Float64 left_m2 = 0.0;\n+    Float64 right_m2 = 0.0;\n+};\n+\n+/** Parallel and incremental algorithm for calculating covariance.\n+  * Source: \"Numerically Stable, Single-Pass, Parallel Statistics Algorithms\"\n+  * (J. Bennett et al., Sandia National Laboratories,\n+  *  2009 IEEE International Conference on Cluster Computing)\n+  */\n+template <bool compute_marginal_moments>\n+struct CovarianceData : public BaseCovarianceData<compute_marginal_moments>\n+{\n+    using Base = BaseCovarianceData<compute_marginal_moments>;\n+\n+    void update(const IColumn & column_left, const IColumn & column_right, size_t row_num)\n+    {\n+        Float64 left_val = column_left.getFloat64(row_num);\n+        Float64 left_delta = left_val - left_mean;\n+\n+        Float64 right_val = column_right.getFloat64(row_num);\n+        Float64 right_delta = right_val - right_mean;\n+\n+        Float64 old_right_mean = right_mean;\n+\n+        ++count;\n+\n+        left_mean += left_delta / count;\n+        right_mean += right_delta / count;\n+        co_moment += (left_val - left_mean) * (right_val - old_right_mean);\n+\n+        /// Update the marginal moments, if any.\n+        if (compute_marginal_moments)\n+        {\n+            Float64 left_incr = left_delta * (left_val - left_mean);\n+            Float64 right_incr = right_delta * (right_val - right_mean);\n+            Base::incrementMarginalMoments(left_incr, right_incr);\n+        }\n+    }\n+\n+    void mergeWith(const CovarianceData & source)\n+    {\n+        UInt64 total_count = count + source.count;\n+        if (total_count == 0)\n+            return;\n+\n+        Float64 factor = static_cast<Float64>(count * source.count) / total_count;\n+        Float64 left_delta = left_mean - source.left_mean;\n+        Float64 right_delta = right_mean - source.right_mean;\n+\n+        if (areComparable(count, source.count))\n+        {\n+            left_mean = (source.count * source.left_mean + count * left_mean) / total_count;\n+            right_mean = (source.count * source.right_mean + count * right_mean) / total_count;\n+        }\n+        else\n+        {\n+            left_mean = source.left_mean + left_delta * (static_cast<Float64>(count) / total_count);\n+            right_mean = source.right_mean + right_delta * (static_cast<Float64>(count) / total_count);\n+        }\n+\n+        co_moment += source.co_moment + left_delta * right_delta * factor;\n+        count = total_count;\n+\n+        /// Update the marginal moments, if any.\n+        if (compute_marginal_moments)\n+        {\n+            Float64 left_incr = left_delta * left_delta * factor;\n+            Float64 right_incr = right_delta * right_delta * factor;\n+            Base::mergeWith(source);\n+            Base::incrementMarginalMoments(left_incr, right_incr);\n+        }\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        writeVarUInt(count, buf);\n+        writeBinary(left_mean, buf);\n+        writeBinary(right_mean, buf);\n+        writeBinary(co_moment, buf);\n+        Base::serialize(buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        readVarUInt(count, buf);\n+        readBinary(left_mean, buf);\n+        readBinary(right_mean, buf);\n+        readBinary(co_moment, buf);\n+        Base::deserialize(buf);\n+    }\n+\n+    UInt64 count = 0;\n+    Float64 left_mean = 0.0;\n+    Float64 right_mean = 0.0;\n+    Float64 co_moment = 0.0;\n+};\n+\n+enum class CovarKind\n+{\n+    covarSampStable,\n+    covarPopStable,\n+    corrStable,\n+};\n+\n+template <bool compute_marginal_moments>\n+class AggregateFunctionCovariance final\n+    : public IAggregateFunctionDataHelper<\n+        CovarianceData<compute_marginal_moments>,\n+        AggregateFunctionCovariance<compute_marginal_moments>>\n+{\n+private:\n+    CovarKind kind;\n+\n+    static Float64 getCovarSamp(Float64 co_moment, UInt64 count)\n+    {\n+        if (count < 2)\n+            return std::numeric_limits<Float64>::infinity();\n+        else\n+            return co_moment / (count - 1);\n+    }\n+\n+    static Float64 getCovarPop(Float64 co_moment, UInt64 count)\n+    {\n+        if (count == 0)\n+            return std::numeric_limits<Float64>::infinity();\n+        else if (count == 1)\n+            return 0.0;\n+        else\n+            return co_moment / count;\n+    }\n+\n+    static Float64 getCorr(Float64 co_moment, Float64 left_m2, Float64 right_m2, UInt64 count)\n+    {\n+        if (count < 2)\n+            return std::numeric_limits<Float64>::infinity();\n+        else\n+            return co_moment / sqrt(left_m2 * right_m2);\n+    }\n+\n+    Float64 getResult(ConstAggregateDataPtr __restrict place) const\n+    {\n+        const auto & data = this->data(place);\n+        switch (kind)\n+        {\n+            case CovarKind::covarSampStable: return getCovarSamp(data.co_moment, data.count);\n+            case CovarKind::covarPopStable: return getCovarPop(data.co_moment, data.count);\n+\n+            case CovarKind::corrStable:\n+                if constexpr (compute_marginal_moments)\n+                    return getCorr(data.co_moment, data.left_m2, data.right_m2, data.count);\n+                else\n+                    return 0;\n+        }\n+    }\n+\n+public:\n+    explicit AggregateFunctionCovariance(CovarKind kind_, const DataTypes & args) : IAggregateFunctionDataHelper<\n+        CovarianceData<compute_marginal_moments>,\n+        AggregateFunctionCovariance<compute_marginal_moments>>(args, {}, std::make_shared<DataTypeFloat64>()),\n+        kind(kind_)\n+    {\n+    }\n+\n+    String getName() const override\n+    {\n+        switch (kind)\n+        {\n+            case CovarKind::covarSampStable: return \"covarSampStable\";\n+            case CovarKind::covarPopStable: return \"covarPopStable\";\n+            case CovarKind::corrStable: return \"corrStable\";\n+        }\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        this->data(place).update(*columns[0], *columns[1], row_num);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).mergeWith(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        assert_cast<ColumnFloat64 &>(to).getData().push_back(getResult(place));\n+    }\n+};\n+\n+\n template <template <typename> typename FunctionTemplate>\n AggregateFunctionPtr createAggregateFunctionStatisticsUnary(\n     const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n@@ -51,13 +483,54 @@ AggregateFunctionPtr createAggregateFunctionStatisticsBinary(\n \n void registerAggregateFunctionsStatisticsStable(AggregateFunctionFactory & factory)\n {\n-    factory.registerFunction(\"varSampStable\", createAggregateFunctionStatisticsUnary<AggregateFunctionVarSampStable>);\n-    factory.registerFunction(\"varPopStable\", createAggregateFunctionStatisticsUnary<AggregateFunctionVarPopStable>);\n-    factory.registerFunction(\"stddevSampStable\", createAggregateFunctionStatisticsUnary<AggregateFunctionStddevSampStable>);\n-    factory.registerFunction(\"stddevPopStable\", createAggregateFunctionStatisticsUnary<AggregateFunctionStddevPopStable>);\n-    factory.registerFunction(\"covarSampStable\", createAggregateFunctionStatisticsBinary<AggregateFunctionCovarSampStable>);\n-    factory.registerFunction(\"covarPopStable\", createAggregateFunctionStatisticsBinary<AggregateFunctionCovarPopStable>);\n-    factory.registerFunction(\"corrStable\", createAggregateFunctionStatisticsBinary<AggregateFunctionCorrStable>);\n+    factory.registerFunction(\"varSampStable\", [](const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+    {\n+        assertNoParameters(name, parameters);\n+        assertUnary(name, argument_types);\n+        return std::make_shared<AggregateFunctionVariance>(VarKind::varSampStable, argument_types[0]);\n+    });\n+\n+    factory.registerFunction(\"varPopStable\", [](const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+    {\n+        assertNoParameters(name, parameters);\n+        assertUnary(name, argument_types);\n+        return std::make_shared<AggregateFunctionVariance>(VarKind::varPopStable, argument_types[0]);\n+    });\n+\n+    factory.registerFunction(\"stddevSampStable\", [](const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+    {\n+        assertNoParameters(name, parameters);\n+        assertUnary(name, argument_types);\n+        return std::make_shared<AggregateFunctionVariance>(VarKind::stddevSampStable, argument_types[0]);\n+    });\n+\n+    factory.registerFunction(\"stddevPopStable\", [](const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+    {\n+        assertNoParameters(name, parameters);\n+        assertUnary(name, argument_types);\n+        return std::make_shared<AggregateFunctionVariance>(VarKind::stddevPopStable, argument_types[0]);\n+    });\n+\n+    factory.registerFunction(\"covarSampStable\", [](const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+    {\n+        assertNoParameters(name, parameters);\n+        assertBinary(name, argument_types);\n+        return std::make_shared<AggregateFunctionCovariance<false>>(CovarKind::covarSampStable, argument_types);\n+    });\n+\n+    factory.registerFunction(\"covarPopStable\", [](const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+    {\n+        assertNoParameters(name, parameters);\n+        assertBinary(name, argument_types);\n+        return std::make_shared<AggregateFunctionCovariance<false>>(CovarKind::covarPopStable, argument_types);\n+    });\n+\n+    factory.registerFunction(\"corrStable\", [](const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\n+    {\n+        assertNoParameters(name, parameters);\n+        assertBinary(name, argument_types);\n+        return std::make_shared<AggregateFunctionCovariance<true>>(CovarKind::corrStable, argument_types);\n+    });\n }\n \n }\ndiff --git a/src/AggregateFunctions/AggregateFunctionStatistics.h b/src/AggregateFunctions/AggregateFunctionStatistics.h\ndeleted file mode 100644\nindex eb2d66b7e94a..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionStatistics.h\n+++ /dev/null\n@@ -1,468 +0,0 @@\n-#pragma once\n-\n-#include <IO/WriteHelpers.h>\n-#include <IO/ReadHelpers.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <Columns/ColumnsNumber.h>\n-#include <Common/assert_cast.h>\n-\n-#include <cmath>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace detail\n-{\n-\n-/// This function returns true if both values are large and comparable.\n-/// It is used to calculate the mean value by merging two sources.\n-/// It means that if the sizes of both sources are large and comparable, then we must apply a special\n-///  formula guaranteeing more stability.\n-bool areComparable(UInt64 a, UInt64 b)\n-{\n-    const Float64 sensitivity = 0.001;\n-    const UInt64 threshold = 10000;\n-\n-    if ((a == 0) || (b == 0))\n-        return false;\n-\n-    auto res = std::minmax(a, b);\n-    return (((1 - static_cast<Float64>(res.first) / res.second) < sensitivity) && (res.first > threshold));\n-}\n-\n-}\n-\n-/** Statistical aggregate functions\n-  * varSamp - sample variance\n-  * stddevSamp - mean sample quadratic deviation\n-  * varPop - variance\n-  * stddevPop - standard deviation\n-  * covarSamp - selective covariance\n-  * covarPop - covariance\n-  * corr - correlation\n-  */\n-\n-/** Parallel and incremental algorithm for calculating variance.\n-  * Source: \"Updating formulae and a pairwise algorithm for computing sample variances\"\n-  * (Chan et al., Stanford University, 12.1979)\n-  */\n-template <typename T, typename Op>\n-class AggregateFunctionVarianceData\n-{\n-public:\n-    void update(const IColumn & column, size_t row_num)\n-    {\n-        T received = assert_cast<const ColumnVector<T> &>(column).getData()[row_num];\n-        Float64 val = static_cast<Float64>(received);\n-        Float64 delta = val - mean;\n-\n-        ++count;\n-        mean += delta / count;\n-        m2 += delta * (val - mean);\n-    }\n-\n-    void mergeWith(const AggregateFunctionVarianceData & source)\n-    {\n-        UInt64 total_count = count + source.count;\n-        if (total_count == 0)\n-            return;\n-\n-        Float64 factor = static_cast<Float64>(count * source.count) / total_count;\n-        Float64 delta = mean - source.mean;\n-\n-        if (detail::areComparable(count, source.count))\n-            mean = (source.count * source.mean + count * mean) / total_count;\n-        else\n-            mean = source.mean + delta * (static_cast<Float64>(count) / total_count);\n-\n-        m2 += source.m2 + delta * delta * factor;\n-        count = total_count;\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        writeVarUInt(count, buf);\n-        writeBinary(mean, buf);\n-        writeBinary(m2, buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        readVarUInt(count, buf);\n-        readBinary(mean, buf);\n-        readBinary(m2, buf);\n-    }\n-\n-    void publish(IColumn & to) const\n-    {\n-        assert_cast<ColumnFloat64 &>(to).getData().push_back(Op::apply(m2, count));\n-    }\n-\n-private:\n-    UInt64 count = 0;\n-    Float64 mean = 0.0;\n-    Float64 m2 = 0.0;\n-};\n-\n-/** The main code for the implementation of varSamp, stddevSamp, varPop, stddevPop.\n-  */\n-template <typename T, typename Op>\n-class AggregateFunctionVariance final\n-    : public IAggregateFunctionDataHelper<AggregateFunctionVarianceData<T, Op>, AggregateFunctionVariance<T, Op>>\n-{\n-public:\n-    explicit AggregateFunctionVariance(const DataTypePtr & arg)\n-        : IAggregateFunctionDataHelper<AggregateFunctionVarianceData<T, Op>, AggregateFunctionVariance<T, Op>>({arg}, {}, std::make_shared<DataTypeFloat64>())\n-    {}\n-\n-    String getName() const override { return Op::name; }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        this->data(place).update(*columns[0], row_num);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).mergeWith(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).deserialize(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        this->data(place).publish(to);\n-    }\n-};\n-\n-/** Implementing the varSamp function.\n-  */\n-struct AggregateFunctionVarSampImpl\n-{\n-    static constexpr auto name = \"varSampStable\";\n-\n-    static inline Float64 apply(Float64 m2, UInt64 count)\n-    {\n-        if (count < 2)\n-            return std::numeric_limits<Float64>::infinity();\n-        else\n-            return m2 / (count - 1);\n-    }\n-};\n-\n-/** Implementing the stddevSamp function.\n-  */\n-struct AggregateFunctionStdDevSampImpl\n-{\n-    static constexpr auto name = \"stddevSampStable\";\n-\n-    static inline Float64 apply(Float64 m2, UInt64 count)\n-    {\n-        return sqrt(AggregateFunctionVarSampImpl::apply(m2, count));\n-    }\n-};\n-\n-/** Implementing the varPop function.\n-  */\n-struct AggregateFunctionVarPopImpl\n-{\n-    static constexpr auto name = \"varPopStable\";\n-\n-    static inline Float64 apply(Float64 m2, UInt64 count)\n-    {\n-        if (count == 0)\n-            return std::numeric_limits<Float64>::infinity();\n-        else if (count == 1)\n-            return 0.0;\n-        else\n-            return m2 / count;\n-    }\n-};\n-\n-/** Implementing the stddevPop function.\n-  */\n-struct AggregateFunctionStdDevPopImpl\n-{\n-    static constexpr auto name = \"stddevPopStable\";\n-\n-    static inline Float64 apply(Float64 m2, UInt64 count)\n-    {\n-        return sqrt(AggregateFunctionVarPopImpl::apply(m2, count));\n-    }\n-};\n-\n-/** If `compute_marginal_moments` flag is set this class provides the successor\n-  * CovarianceData support of marginal moments for calculating the correlation.\n-  */\n-template <bool compute_marginal_moments>\n-class BaseCovarianceData\n-{\n-protected:\n-    void incrementMarginalMoments(Float64, Float64) {}\n-    void mergeWith(const BaseCovarianceData &) {}\n-    void serialize(WriteBuffer &) const {}\n-    void deserialize(const ReadBuffer &) {}\n-};\n-\n-template <>\n-class BaseCovarianceData<true>\n-{\n-protected:\n-    void incrementMarginalMoments(Float64 left_incr, Float64 right_incr)\n-    {\n-        left_m2 += left_incr;\n-        right_m2 += right_incr;\n-    }\n-\n-    void mergeWith(const BaseCovarianceData & source)\n-    {\n-        left_m2 += source.left_m2;\n-        right_m2 += source.right_m2;\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        writeBinary(left_m2, buf);\n-        writeBinary(right_m2, buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        readBinary(left_m2, buf);\n-        readBinary(right_m2, buf);\n-    }\n-\n-    Float64 left_m2 = 0.0;\n-    Float64 right_m2 = 0.0;\n-};\n-\n-/** Parallel and incremental algorithm for calculating covariance.\n-  * Source: \"Numerically Stable, Single-Pass, Parallel Statistics Algorithms\"\n-  * (J. Bennett et al., Sandia National Laboratories,\n-  *  2009 IEEE International Conference on Cluster Computing)\n-  */\n-template <typename T, typename U, typename Op, bool compute_marginal_moments>\n-class CovarianceData : public BaseCovarianceData<compute_marginal_moments>\n-{\n-private:\n-    using Base = BaseCovarianceData<compute_marginal_moments>;\n-\n-public:\n-    void update(const IColumn & column_left, const IColumn & column_right, size_t row_num)\n-    {\n-        T left_received = assert_cast<const ColumnVector<T> &>(column_left).getData()[row_num];\n-        Float64 left_val = static_cast<Float64>(left_received);\n-        Float64 left_delta = left_val - left_mean;\n-\n-        U right_received = assert_cast<const ColumnVector<U> &>(column_right).getData()[row_num];\n-        Float64 right_val = static_cast<Float64>(right_received);\n-        Float64 right_delta = right_val - right_mean;\n-\n-        Float64 old_right_mean = right_mean;\n-\n-        ++count;\n-\n-        left_mean += left_delta / count;\n-        right_mean += right_delta / count;\n-        co_moment += (left_val - left_mean) * (right_val - old_right_mean);\n-\n-        /// Update the marginal moments, if any.\n-        if (compute_marginal_moments)\n-        {\n-            Float64 left_incr = left_delta * (left_val - left_mean);\n-            Float64 right_incr = right_delta * (right_val - right_mean);\n-            Base::incrementMarginalMoments(left_incr, right_incr);\n-        }\n-    }\n-\n-    void mergeWith(const CovarianceData & source)\n-    {\n-        UInt64 total_count = count + source.count;\n-        if (total_count == 0)\n-            return;\n-\n-        Float64 factor = static_cast<Float64>(count * source.count) / total_count;\n-        Float64 left_delta = left_mean - source.left_mean;\n-        Float64 right_delta = right_mean - source.right_mean;\n-\n-        if (detail::areComparable(count, source.count))\n-        {\n-            left_mean = (source.count * source.left_mean + count * left_mean) / total_count;\n-            right_mean = (source.count * source.right_mean + count * right_mean) / total_count;\n-        }\n-        else\n-        {\n-            left_mean = source.left_mean + left_delta * (static_cast<Float64>(count) / total_count);\n-            right_mean = source.right_mean + right_delta * (static_cast<Float64>(count) / total_count);\n-        }\n-\n-        co_moment += source.co_moment + left_delta * right_delta * factor;\n-        count = total_count;\n-\n-        /// Update the marginal moments, if any.\n-        if (compute_marginal_moments)\n-        {\n-            Float64 left_incr = left_delta * left_delta * factor;\n-            Float64 right_incr = right_delta * right_delta * factor;\n-            Base::mergeWith(source);\n-            Base::incrementMarginalMoments(left_incr, right_incr);\n-        }\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        writeVarUInt(count, buf);\n-        writeBinary(left_mean, buf);\n-        writeBinary(right_mean, buf);\n-        writeBinary(co_moment, buf);\n-        Base::serialize(buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        readVarUInt(count, buf);\n-        readBinary(left_mean, buf);\n-        readBinary(right_mean, buf);\n-        readBinary(co_moment, buf);\n-        Base::deserialize(buf);\n-    }\n-\n-    void publish(IColumn & to) const\n-    {\n-        if constexpr (compute_marginal_moments)\n-            assert_cast<ColumnFloat64 &>(to).getData().push_back(Op::apply(co_moment, Base::left_m2, Base::right_m2, count));\n-        else\n-            assert_cast<ColumnFloat64 &>(to).getData().push_back(Op::apply(co_moment, count));\n-    }\n-\n-private:\n-    UInt64 count = 0;\n-    Float64 left_mean = 0.0;\n-    Float64 right_mean = 0.0;\n-    Float64 co_moment = 0.0;\n-};\n-\n-template <typename T, typename U, typename Op, bool compute_marginal_moments = false>\n-class AggregateFunctionCovariance final\n-    : public IAggregateFunctionDataHelper<\n-        CovarianceData<T, U, Op, compute_marginal_moments>,\n-        AggregateFunctionCovariance<T, U, Op, compute_marginal_moments>>\n-{\n-public:\n-    explicit AggregateFunctionCovariance(const DataTypes & args) : IAggregateFunctionDataHelper<\n-        CovarianceData<T, U, Op, compute_marginal_moments>,\n-        AggregateFunctionCovariance<T, U, Op, compute_marginal_moments>>(args, {}, std::make_shared<DataTypeFloat64>())\n-    {}\n-\n-    String getName() const override { return Op::name; }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        this->data(place).update(*columns[0], *columns[1], row_num);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).mergeWith(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).deserialize(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        this->data(place).publish(to);\n-    }\n-};\n-\n-/** Implementing the covarSamp function.\n-  */\n-struct AggregateFunctionCovarSampImpl\n-{\n-    static constexpr auto name = \"covarSampStable\";\n-\n-    static inline Float64 apply(Float64 co_moment, UInt64 count)\n-    {\n-        if (count < 2)\n-            return std::numeric_limits<Float64>::infinity();\n-        else\n-            return co_moment / (count - 1);\n-    }\n-};\n-\n-/** Implementing the covarPop function.\n-  */\n-struct AggregateFunctionCovarPopImpl\n-{\n-    static constexpr auto name = \"covarPopStable\";\n-\n-    static inline Float64 apply(Float64 co_moment, UInt64 count)\n-    {\n-        if (count == 0)\n-            return std::numeric_limits<Float64>::infinity();\n-        else if (count == 1)\n-            return 0.0;\n-        else\n-            return co_moment / count;\n-    }\n-};\n-\n-/** `corr` function implementation.\n-  */\n-struct AggregateFunctionCorrImpl\n-{\n-    static constexpr auto name = \"corrStable\";\n-\n-    static inline Float64 apply(Float64 co_moment, Float64 left_m2, Float64 right_m2, UInt64 count)\n-    {\n-        if (count < 2)\n-            return std::numeric_limits<Float64>::infinity();\n-        else\n-            return co_moment / sqrt(left_m2 * right_m2);\n-    }\n-};\n-\n-template <typename T>\n-using AggregateFunctionVarSampStable = AggregateFunctionVariance<T, AggregateFunctionVarSampImpl>;\n-\n-template <typename T>\n-using AggregateFunctionStddevSampStable = AggregateFunctionVariance<T, AggregateFunctionStdDevSampImpl>;\n-\n-template <typename T>\n-using AggregateFunctionVarPopStable = AggregateFunctionVariance<T, AggregateFunctionVarPopImpl>;\n-\n-template <typename T>\n-using AggregateFunctionStddevPopStable = AggregateFunctionVariance<T, AggregateFunctionStdDevPopImpl>;\n-\n-template <typename T, typename U>\n-using AggregateFunctionCovarSampStable = AggregateFunctionCovariance<T, U, AggregateFunctionCovarSampImpl>;\n-\n-template <typename T, typename U>\n-using AggregateFunctionCovarPopStable = AggregateFunctionCovariance<T, U, AggregateFunctionCovarPopImpl>;\n-\n-template <typename T, typename U>\n-using AggregateFunctionCorrStable = AggregateFunctionCovariance<T, U, AggregateFunctionCorrImpl, true>;\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionSumCount.cpp b/src/AggregateFunctions/AggregateFunctionSumCount.cpp\nindex 946b5987c094..356794f81a31 100644\n--- a/src/AggregateFunctions/AggregateFunctionSumCount.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionSumCount.cpp\n@@ -1,7 +1,8 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionSumCount.h>\n #include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n+#include <DataTypes/DataTypeTuple.h>\n+#include <AggregateFunctions/AggregateFunctionAvg.h>\n \n \n namespace DB\n@@ -16,6 +17,59 @@ namespace ErrorCodes\n \n namespace\n {\n+\n+template <typename T>\n+class AggregateFunctionSumCount final : public AggregateFunctionAvg<T>\n+{\n+public:\n+    using Base = AggregateFunctionAvg<T>;\n+\n+    explicit AggregateFunctionSumCount(const DataTypes & argument_types_, UInt32 num_scale_ = 0)\n+        : Base(argument_types_, createResultType(num_scale_), num_scale_)\n+    {}\n+\n+    static DataTypePtr createResultType(UInt32 num_scale_)\n+    {\n+        auto second_elem = std::make_shared<DataTypeUInt64>();\n+        return std::make_shared<DataTypeTuple>(DataTypes{getReturnTypeFirstElement(num_scale_), std::move(second_elem)});\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const final\n+    {\n+        assert_cast<ColumnVectorOrDecimal<AvgFieldType<T>> &>((assert_cast<ColumnTuple &>(to)).getColumn(0)).getData().push_back(\n+            this->data(place).numerator);\n+\n+        assert_cast<ColumnUInt64 &>((assert_cast<ColumnTuple &>(to)).getColumn(1)).getData().push_back(\n+            this->data(place).denominator);\n+    }\n+\n+    String getName() const final { return \"sumCount\"; }\n+\n+#if USE_EMBEDDED_COMPILER\n+\n+    bool isCompilable() const override\n+    {\n+        return false;\n+    }\n+\n+#endif\n+\n+private:\n+    static auto getReturnTypeFirstElement(UInt32 num_scale_)\n+    {\n+        using FieldType = AvgFieldType<T>;\n+\n+        if constexpr (!is_decimal<T>)\n+            return std::make_shared<DataTypeNumber<FieldType>>();\n+        else\n+        {\n+            using DataType = DataTypeDecimal<FieldType>;\n+            return std::make_shared<DataType>(DataType::maxPrecision(), num_scale_);\n+        }\n+    }\n+};\n+\n+\n bool allowType(const DataTypePtr& type) noexcept\n {\n     const WhichDataType t(type);\ndiff --git a/src/AggregateFunctions/AggregateFunctionSumCount.h b/src/AggregateFunctions/AggregateFunctionSumCount.h\ndeleted file mode 100644\nindex 7058204ed745..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionSumCount.h\n+++ /dev/null\n@@ -1,61 +0,0 @@\n-#pragma once\n-\n-#include <type_traits>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <AggregateFunctions/AggregateFunctionAvg.h>\n-\n-\n-namespace DB\n-{\n-template <typename T>\n-class AggregateFunctionSumCount final : public AggregateFunctionAvg<T>\n-{\n-public:\n-    using Base = AggregateFunctionAvg<T>;\n-\n-    explicit AggregateFunctionSumCount(const DataTypes & argument_types_, UInt32 num_scale_ = 0)\n-        : Base(argument_types_, createResultType(num_scale_), num_scale_)\n-    {}\n-\n-    static DataTypePtr createResultType(UInt32 num_scale_)\n-    {\n-        auto second_elem = std::make_shared<DataTypeUInt64>();\n-        return std::make_shared<DataTypeTuple>(DataTypes{getReturnTypeFirstElement(num_scale_), std::move(second_elem)});\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const final\n-    {\n-        assert_cast<ColumnVectorOrDecimal<AvgFieldType<T>> &>((assert_cast<ColumnTuple &>(to)).getColumn(0)).getData().push_back(\n-            this->data(place).numerator);\n-\n-        assert_cast<ColumnUInt64 &>((assert_cast<ColumnTuple &>(to)).getColumn(1)).getData().push_back(\n-            this->data(place).denominator);\n-    }\n-\n-    String getName() const final { return \"sumCount\"; }\n-\n-#if USE_EMBEDDED_COMPILER\n-\n-    bool isCompilable() const override\n-    {\n-        return false;\n-    }\n-\n-#endif\n-\n-private:\n-    static auto getReturnTypeFirstElement(UInt32 num_scale_)\n-    {\n-        using FieldType = AvgFieldType<T>;\n-\n-        if constexpr (!is_decimal<T>)\n-            return std::make_shared<DataTypeNumber<FieldType>>();\n-        else\n-        {\n-            using DataType = DataTypeDecimal<FieldType>;\n-            return std::make_shared<DataType>(DataType::maxPrecision(), num_scale_);\n-        }\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionSumMap.cpp b/src/AggregateFunctions/AggregateFunctionSumMap.cpp\nindex 8204db3ff10f..04bc908396a7 100644\n--- a/src/AggregateFunctions/AggregateFunctionSumMap.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionSumMap.cpp\n@@ -1,24 +1,676 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionSumMap.h>\n-#include <AggregateFunctions/Helpers.h>\n-#include <AggregateFunctions/FactoryHelpers.h>\n #include <Functions/FunctionHelpers.h>\n-#include <IO/WriteHelpers.h>\n+\n+#include <IO/ReadHelpers.h>\n+\n+#include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypeTuple.h>\n+#include <DataTypes/DataTypeNullable.h>\n+\n+#include <Columns/ColumnArray.h>\n+#include <Columns/ColumnTuple.h>\n+#include <Columns/ColumnString.h>\n+\n+#include <Common/FieldVisitorSum.h>\n+#include <Common/assert_cast.h>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/FactoryHelpers.h>\n+#include <map>\n \n \n namespace DB\n {\n+\n struct Settings;\n \n namespace ErrorCodes\n {\n-    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int BAD_ARGUMENTS;\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int LOGICAL_ERROR;\n }\n \n namespace\n {\n \n+struct AggregateFunctionMapData\n+{\n+    // Map needs to be ordered to maintain function properties\n+    std::map<Field, Array> merged_maps;\n+};\n+\n+/** Aggregate function, that takes at least two arguments: keys and values, and as a result, builds a tuple of at least 2 arrays -\n+  * ordered keys and variable number of argument values aggregated by corresponding keys.\n+  *\n+  * sumMap function is the most useful when using SummingMergeTree to sum Nested columns, which name ends in \"Map\".\n+  *\n+  * Example: sumMap(k, v...) of:\n+  *  k           v\n+  *  [1,2,3]     [10,10,10]\n+  *  [3,4,5]     [10,10,10]\n+  *  [4,5,6]     [10,10,10]\n+  *  [6,7,8]     [10,10,10]\n+  *  [7,5,3]     [5,15,25]\n+  *  [8,9,10]    [20,20,20]\n+  * will return:\n+  *  ([1,2,3,4,5,6,7,8,9,10],[10,10,45,20,35,20,15,30,20,20])\n+  *\n+  * minMap and maxMap share the same idea, but calculate min and max correspondingly.\n+  *\n+  * NOTE: The implementation of these functions are \"amateur grade\" - not efficient and low quality.\n+  */\n+\n+template <typename Derived, typename Visitor, bool overflow, bool tuple_argument, bool compact>\n+class AggregateFunctionMapBase : public IAggregateFunctionDataHelper<\n+    AggregateFunctionMapData, Derived>\n+{\n+private:\n+    static constexpr auto STATE_VERSION_1_MIN_REVISION = 54452;\n+\n+    DataTypePtr keys_type;\n+    SerializationPtr keys_serialization;\n+    DataTypes values_types;\n+    Serializations values_serializations;\n+    Serializations promoted_values_serializations;\n+\n+public:\n+    using Base = IAggregateFunctionDataHelper<AggregateFunctionMapData, Derived>;\n+\n+    AggregateFunctionMapBase(const DataTypePtr & keys_type_,\n+            const DataTypes & values_types_, const DataTypes & argument_types_)\n+        : Base(argument_types_, {} /* parameters */, createResultType(keys_type_, values_types_))\n+        , keys_type(keys_type_)\n+        , keys_serialization(keys_type->getDefaultSerialization())\n+        , values_types(values_types_)\n+    {\n+        values_serializations.reserve(values_types.size());\n+        promoted_values_serializations.reserve(values_types.size());\n+        for (const auto & type : values_types)\n+        {\n+            values_serializations.emplace_back(type->getDefaultSerialization());\n+            if (type->canBePromoted())\n+            {\n+                if (type->isNullable())\n+                    promoted_values_serializations.emplace_back(\n+                         makeNullable(removeNullable(type)->promoteNumericType())->getDefaultSerialization());\n+                else\n+                    promoted_values_serializations.emplace_back(type->promoteNumericType()->getDefaultSerialization());\n+            }\n+            else\n+            {\n+                promoted_values_serializations.emplace_back(type->getDefaultSerialization());\n+            }\n+        }\n+    }\n+\n+    bool isVersioned() const override { return true; }\n+\n+    size_t getDefaultVersion() const override { return 1; }\n+\n+    size_t getVersionFromRevision(size_t revision) const override\n+    {\n+        if (revision >= STATE_VERSION_1_MIN_REVISION)\n+            return 1;\n+        else\n+            return 0;\n+    }\n+\n+    static DataTypePtr createResultType(\n+        const DataTypePtr & keys_type_,\n+        const DataTypes & values_types_)\n+    {\n+        DataTypes types;\n+        types.emplace_back(std::make_shared<DataTypeArray>(keys_type_));\n+\n+        for (const auto & value_type : values_types_)\n+        {\n+            if constexpr (std::is_same_v<Visitor, FieldVisitorSum>)\n+            {\n+                if (!value_type->isSummable())\n+                    throw Exception{ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+                        \"Values for -Map cannot be summed, passed type {}\",\n+                        value_type->getName()};\n+            }\n+\n+            DataTypePtr result_type;\n+\n+            if constexpr (overflow)\n+            {\n+                if (value_type->onlyNull())\n+                    throw Exception{ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+                        \"Cannot calculate -Map of type {}\",\n+                        value_type->getName()};\n+\n+                // Overflow, meaning that the returned type is the same as\n+                // the input type. Nulls are skipped.\n+                result_type = removeNullable(value_type);\n+            }\n+            else\n+            {\n+                auto value_type_without_nullable = removeNullable(value_type);\n+\n+                // No overflow, meaning we promote the types if necessary.\n+                if (!value_type_without_nullable->canBePromoted())\n+                    throw Exception{ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+                        \"Values for -Map are expected to be Numeric, Float or Decimal, passed type {}\",\n+                        value_type->getName()};\n+\n+                WhichDataType value_type_to_check(value_type_without_nullable);\n+\n+                /// Do not promote decimal because of implementation issues of this function design\n+                /// Currently we cannot get result column type in case of decimal we cannot get decimal scale\n+                /// in method void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+                /// If we decide to make this function more efficient we should promote decimal type during summ\n+                if (value_type_to_check.isDecimal())\n+                    result_type = value_type_without_nullable;\n+                else\n+                    result_type = value_type_without_nullable->promoteNumericType();\n+            }\n+\n+            types.emplace_back(std::make_shared<DataTypeArray>(result_type));\n+        }\n+\n+        return std::make_shared<DataTypeTuple>(types);\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    static auto getArgumentColumns(const IColumn ** columns)\n+    {\n+        if constexpr (tuple_argument)\n+        {\n+            return assert_cast<const ColumnTuple *>(columns[0])->getColumns();\n+        }\n+        else\n+        {\n+            return columns;\n+        }\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns_, const size_t row_num, Arena *) const override\n+    {\n+        const auto & columns = getArgumentColumns(columns_);\n+\n+        // Column 0 contains array of keys of known type\n+        const ColumnArray & array_column0 = assert_cast<const ColumnArray &>(*columns[0]);\n+        const IColumn::Offsets & offsets0 = array_column0.getOffsets();\n+        const IColumn & key_column = array_column0.getData();\n+        const size_t keys_vec_offset = offsets0[row_num - 1];\n+        const size_t keys_vec_size = (offsets0[row_num] - keys_vec_offset);\n+\n+        // Columns 1..n contain arrays of numeric values to sum\n+        auto & merged_maps = this->data(place).merged_maps;\n+        for (size_t col = 0, size = values_types.size(); col < size; ++col)\n+        {\n+            const auto & array_column = assert_cast<const ColumnArray &>(*columns[col + 1]);\n+            const IColumn & value_column = array_column.getData();\n+            const IColumn::Offsets & offsets = array_column.getOffsets();\n+            const size_t values_vec_offset = offsets[row_num - 1];\n+            const size_t values_vec_size = (offsets[row_num] - values_vec_offset);\n+\n+            // Expect key and value arrays to be of same length\n+            if (keys_vec_size != values_vec_size)\n+                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Sizes of keys and values arrays do not match\");\n+\n+            // Insert column values for all keys\n+            for (size_t i = 0; i < keys_vec_size; ++i)\n+            {\n+                Field value = value_column[values_vec_offset + i];\n+                Field key = key_column[keys_vec_offset + i];\n+\n+                if (!keepKey(key))\n+                    continue;\n+\n+                auto [it, inserted] = merged_maps.emplace(key, Array());\n+\n+                if (inserted)\n+                {\n+                    it->second.resize(size);\n+                    it->second[col] = value;\n+                }\n+                else\n+                {\n+                    if (!value.isNull())\n+                    {\n+                        if (it->second[col].isNull())\n+                            it->second[col] = value;\n+                        else\n+                            applyVisitor(Visitor(value), it->second[col]);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        auto & merged_maps = this->data(place).merged_maps;\n+        const auto & rhs_maps = this->data(rhs).merged_maps;\n+\n+        for (const auto & elem : rhs_maps)\n+        {\n+            const auto & it = merged_maps.find(elem.first);\n+            if (it != merged_maps.end())\n+            {\n+                for (size_t col = 0; col < values_types.size(); ++col)\n+                    if (!elem.second[col].isNull())\n+                        applyVisitor(Visitor(elem.second[col]), it->second[col]);\n+            }\n+            else\n+                merged_maps[elem.first] = elem.second;\n+        }\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> version) const override\n+    {\n+        if (!version)\n+            version = getDefaultVersion();\n+\n+        const auto & merged_maps = this->data(place).merged_maps;\n+        size_t size = merged_maps.size();\n+        writeVarUInt(size, buf);\n+\n+        std::function<void(size_t, const Array &)> serialize;\n+        switch (*version)\n+        {\n+            case 0:\n+            {\n+                serialize = [&](size_t col_idx, const Array & values)\n+                {\n+                    values_serializations[col_idx]->serializeBinary(values[col_idx], buf, {});\n+                };\n+                break;\n+            }\n+            case 1:\n+            {\n+                serialize = [&](size_t col_idx, const Array & values)\n+                {\n+                    Field value = values[col_idx];\n+\n+                    /// Compatibility with previous versions.\n+                    if (value.getType() == Field::Types::Decimal32)\n+                    {\n+                        auto source = value.get<DecimalField<Decimal32>>();\n+                        value = DecimalField<Decimal128>(source.getValue(), source.getScale());\n+                    }\n+                    else if (value.getType() == Field::Types::Decimal64)\n+                    {\n+                        auto source = value.get<DecimalField<Decimal64>>();\n+                        value = DecimalField<Decimal128>(source.getValue(), source.getScale());\n+                    }\n+\n+                    promoted_values_serializations[col_idx]->serializeBinary(value, buf, {});\n+                };\n+                break;\n+            }\n+            default:\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unknown version {}, of -Map aggregate function serialization state\", *version);\n+        }\n+\n+        for (const auto & elem : merged_maps)\n+        {\n+            keys_serialization->serializeBinary(elem.first, buf, {});\n+            for (size_t col = 0; col < values_types.size(); ++col)\n+                serialize(col, elem.second);\n+        }\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> version, Arena *) const override\n+    {\n+        if (!version)\n+            version = getDefaultVersion();\n+\n+        auto & merged_maps = this->data(place).merged_maps;\n+        size_t size = 0;\n+        readVarUInt(size, buf);\n+\n+        std::function<void(size_t, Array &)> deserialize;\n+        switch (*version)\n+        {\n+            case 0:\n+            {\n+                deserialize = [&](size_t col_idx, Array & values)\n+                {\n+                    values_serializations[col_idx]->deserializeBinary(values[col_idx], buf, {});\n+                };\n+                break;\n+            }\n+            case 1:\n+            {\n+                deserialize = [&](size_t col_idx, Array & values)\n+                {\n+                    Field & value = values[col_idx];\n+                    promoted_values_serializations[col_idx]->deserializeBinary(value, buf, {});\n+\n+                    /// Compatibility with previous versions.\n+                    if (value.getType() == Field::Types::Decimal128)\n+                    {\n+                        auto source = value.get<DecimalField<Decimal128>>();\n+                        WhichDataType value_type(values_types[col_idx]);\n+                        if (value_type.isDecimal32())\n+                        {\n+                            value = DecimalField<Decimal32>(source.getValue(), source.getScale());\n+                        }\n+                        else if (value_type.isDecimal64())\n+                        {\n+                            value = DecimalField<Decimal64>(source.getValue(), source.getScale());\n+                        }\n+                    }\n+                };\n+                break;\n+            }\n+            default:\n+                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unexpected version {} of -Map aggregate function serialization state\", *version);\n+        }\n+\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            Field key;\n+            keys_serialization->deserializeBinary(key, buf, {});\n+\n+            Array values;\n+            values.resize(values_types.size());\n+\n+            for (size_t col = 0; col < values_types.size(); ++col)\n+                deserialize(col, values);\n+\n+            merged_maps[key] = values;\n+        }\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        size_t num_columns = values_types.size();\n+\n+        // Final step does compaction of keys that have zero values, this mutates the state\n+        auto & merged_maps = this->data(place).merged_maps;\n+\n+        // Remove keys which are zeros or empty. This should be enabled only for sumMap.\n+        if constexpr (compact)\n+        {\n+            for (auto it = merged_maps.cbegin(); it != merged_maps.cend();)\n+            {\n+                // Key is not compacted if it has at least one non-zero value\n+                bool erase = true;\n+                for (size_t col = 0; col < num_columns; ++col)\n+                {\n+                    if (!it->second[col].isNull() && it->second[col] != values_types[col]->getDefault())\n+                    {\n+                        erase = false;\n+                        break;\n+                    }\n+                }\n+\n+                if (erase)\n+                    it = merged_maps.erase(it);\n+                else\n+                    ++it;\n+            }\n+        }\n+\n+        size_t size = merged_maps.size();\n+\n+        auto & to_tuple = assert_cast<ColumnTuple &>(to);\n+        auto & to_keys_arr = assert_cast<ColumnArray &>(to_tuple.getColumn(0));\n+        auto & to_keys_col = to_keys_arr.getData();\n+\n+        // Advance column offsets\n+        auto & to_keys_offsets = to_keys_arr.getOffsets();\n+        to_keys_offsets.push_back(to_keys_offsets.back() + size);\n+        to_keys_col.reserve(size);\n+\n+        for (size_t col = 0; col < num_columns; ++col)\n+        {\n+            auto & to_values_arr = assert_cast<ColumnArray &>(to_tuple.getColumn(col + 1));\n+            auto & to_values_offsets = to_values_arr.getOffsets();\n+            to_values_offsets.push_back(to_values_offsets.back() + size);\n+            to_values_arr.getData().reserve(size);\n+        }\n+\n+        // Write arrays of keys and values\n+        for (const auto & elem : merged_maps)\n+        {\n+            // Write array of keys into column\n+            to_keys_col.insert(elem.first);\n+\n+            // Write 0..n arrays of values\n+            for (size_t col = 0; col < num_columns; ++col)\n+            {\n+                auto & to_values_col = assert_cast<ColumnArray &>(to_tuple.getColumn(col + 1)).getData();\n+                if (elem.second[col].isNull())\n+                    to_values_col.insertDefault();\n+                else\n+                    to_values_col.insert(elem.second[col]);\n+            }\n+        }\n+    }\n+\n+    bool keepKey(const Field & key) const { return static_cast<const Derived &>(*this).keepKey(key); }\n+    String getName() const override { return Derived::getNameImpl(); }\n+};\n+\n+template <bool overflow, bool tuple_argument>\n+class AggregateFunctionSumMap final :\n+    public AggregateFunctionMapBase<AggregateFunctionSumMap<overflow, tuple_argument>, FieldVisitorSum, overflow, tuple_argument, true>\n+{\n+private:\n+    using Self = AggregateFunctionSumMap<overflow, tuple_argument>;\n+    using Base = AggregateFunctionMapBase<Self, FieldVisitorSum, overflow, tuple_argument, true>;\n+\n+public:\n+    AggregateFunctionSumMap(const DataTypePtr & keys_type_,\n+            DataTypes & values_types_, const DataTypes & argument_types_,\n+            const Array & params_)\n+        : Base{keys_type_, values_types_, argument_types_}\n+    {\n+        // The constructor accepts parameters to have a uniform interface with\n+        // sumMapFiltered, but this function doesn't have any parameters.\n+        assertNoParameters(getNameImpl(), params_);\n+    }\n+\n+    static String getNameImpl()\n+    {\n+        if constexpr (overflow)\n+        {\n+            return \"sumMapWithOverflow\";\n+        }\n+        else\n+        {\n+            return \"sumMap\";\n+        }\n+    }\n+\n+    bool keepKey(const Field &) const { return true; }\n+};\n+\n+\n+template <bool overflow, bool tuple_argument>\n+class AggregateFunctionSumMapFiltered final :\n+    public AggregateFunctionMapBase<\n+        AggregateFunctionSumMapFiltered<overflow, tuple_argument>,\n+        FieldVisitorSum,\n+        overflow,\n+        tuple_argument,\n+        true>\n+{\n+private:\n+    using Self = AggregateFunctionSumMapFiltered<overflow, tuple_argument>;\n+    using Base = AggregateFunctionMapBase<Self, FieldVisitorSum, overflow, tuple_argument, true>;\n+\n+    using ContainerT = std::set<Field>;\n+    ContainerT keys_to_keep;\n+\n+public:\n+    AggregateFunctionSumMapFiltered(const DataTypePtr & keys_type_,\n+            const DataTypes & values_types_, const DataTypes & argument_types_,\n+            const Array & params_)\n+        : Base{keys_type_, values_types_, argument_types_}\n+    {\n+        if (params_.size() != 1)\n+            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n+                \"Aggregate function '{}' requires exactly one parameter \"\n+                \"of Array type\", getNameImpl());\n+\n+        Array keys_to_keep_values;\n+        if (!params_.front().tryGet<Array>(keys_to_keep_values))\n+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n+                \"Aggregate function {} requires an Array as a parameter\",\n+                getNameImpl());\n+\n+        this->parameters = params_;\n+\n+        for (const Field & f : keys_to_keep_values)\n+            keys_to_keep.emplace(f);\n+    }\n+\n+    static String getNameImpl()\n+    {\n+        if constexpr (overflow)\n+        {\n+            return \"sumMapFilteredWithOverflow\";\n+        }\n+        else\n+        {\n+            return \"sumMapFiltered\";\n+        }\n+    }\n+\n+    bool keepKey(const Field & key) const { return keys_to_keep.contains(key); }\n+};\n+\n+\n+/** Implements `Max` operation.\n+ *  Returns true if changed\n+ */\n+class FieldVisitorMax : public StaticVisitor<bool>\n+{\n+private:\n+    const Field & rhs;\n+\n+    template <typename FieldType>\n+    bool compareImpl(FieldType & x) const\n+    {\n+        auto val = rhs.get<FieldType>();\n+        if (val > x)\n+        {\n+            x = val;\n+            return true;\n+        }\n+\n+        return false;\n+    }\n+\n+public:\n+    explicit FieldVisitorMax(const Field & rhs_) : rhs(rhs_) {}\n+\n+    bool operator() (Null &) const\n+    {\n+        /// Do not update current value, skip nulls\n+        return false;\n+    }\n+\n+    bool operator() (AggregateFunctionStateData &) const { throw Exception(ErrorCodes::LOGICAL_ERROR, \"Cannot compare AggregateFunctionStates\"); }\n+\n+    bool operator() (Array & x) const { return compareImpl<Array>(x); }\n+    bool operator() (Tuple & x) const { return compareImpl<Tuple>(x); }\n+    template <typename T>\n+    bool operator() (DecimalField<T> & x) const { return compareImpl<DecimalField<T>>(x); }\n+    template <typename T>\n+    bool operator() (T & x) const { return compareImpl<T>(x); }\n+};\n+\n+/** Implements `Min` operation.\n+ *  Returns true if changed\n+ */\n+class FieldVisitorMin : public StaticVisitor<bool>\n+{\n+private:\n+    const Field & rhs;\n+\n+    template <typename FieldType>\n+    bool compareImpl(FieldType & x) const\n+    {\n+        auto val = rhs.get<FieldType>();\n+        if (val < x)\n+        {\n+            x = val;\n+            return true;\n+        }\n+\n+        return false;\n+    }\n+\n+public:\n+    explicit FieldVisitorMin(const Field & rhs_) : rhs(rhs_) {}\n+\n+\n+    bool operator() (Null &) const\n+    {\n+        /// Do not update current value, skip nulls\n+        return false;\n+    }\n+\n+    bool operator() (AggregateFunctionStateData &) const { throw Exception(ErrorCodes::LOGICAL_ERROR, \"Cannot sum AggregateFunctionStates\"); }\n+\n+    bool operator() (Array & x) const { return compareImpl<Array>(x); }\n+    bool operator() (Tuple & x) const { return compareImpl<Tuple>(x); }\n+    template <typename T>\n+    bool operator() (DecimalField<T> & x) const { return compareImpl<DecimalField<T>>(x); }\n+    template <typename T>\n+    bool operator() (T & x) const { return compareImpl<T>(x); }\n+};\n+\n+\n+template <bool tuple_argument>\n+class AggregateFunctionMinMap final :\n+    public AggregateFunctionMapBase<AggregateFunctionMinMap<tuple_argument>, FieldVisitorMin, true, tuple_argument, false>\n+{\n+private:\n+    using Self = AggregateFunctionMinMap<tuple_argument>;\n+    using Base = AggregateFunctionMapBase<Self, FieldVisitorMin, true, tuple_argument, false>;\n+\n+public:\n+    AggregateFunctionMinMap(const DataTypePtr & keys_type_,\n+            DataTypes & values_types_, const DataTypes & argument_types_,\n+            const Array & params_)\n+        : Base{keys_type_, values_types_, argument_types_}\n+    {\n+        // The constructor accepts parameters to have a uniform interface with\n+        // sumMapFiltered, but this function doesn't have any parameters.\n+        assertNoParameters(getNameImpl(), params_);\n+    }\n+\n+    static String getNameImpl() { return \"minMap\"; }\n+\n+    bool keepKey(const Field &) const { return true; }\n+};\n+\n+template <bool tuple_argument>\n+class AggregateFunctionMaxMap final :\n+    public AggregateFunctionMapBase<AggregateFunctionMaxMap<tuple_argument>, FieldVisitorMax, true, tuple_argument, false>\n+{\n+private:\n+    using Self = AggregateFunctionMaxMap<tuple_argument>;\n+    using Base = AggregateFunctionMapBase<Self, FieldVisitorMax, true, tuple_argument, false>;\n+\n+public:\n+    AggregateFunctionMaxMap(const DataTypePtr & keys_type_,\n+            DataTypes & values_types_, const DataTypes & argument_types_,\n+            const Array & params_)\n+        : Base{keys_type_, values_types_, argument_types_}\n+    {\n+        // The constructor accepts parameters to have a uniform interface with\n+        // sumMapFiltered, but this function doesn't have any parameters.\n+        assertNoParameters(getNameImpl(), params_);\n+    }\n+\n+    static String getNameImpl() { return \"maxMap\"; }\n+\n+    bool keepKey(const Field &) const { return true; }\n+};\n+\n+\n auto parseArguments(const std::string & name, const DataTypes & arguments)\n {\n     DataTypes args;\n@@ -69,77 +721,6 @@ auto parseArguments(const std::string & name, const DataTypes & arguments)\n     return std::tuple<DataTypePtr, DataTypes, bool>{std::move(keys_type), std::move(values_types), tuple_argument};\n }\n \n-// This function instantiates a particular overload of the sumMap family of\n-// functions.\n-// The template parameter MappedFunction<bool template_argument> is an aggregate\n-// function template that allows to choose the aggregate function variant that\n-// accepts either normal arguments or tuple argument.\n-template<template <bool tuple_argument> typename MappedFunction>\n-AggregateFunctionPtr createAggregateFunctionMap(const std::string & name, const DataTypes & arguments, const Array & params, const Settings *)\n-{\n-    auto [keys_type, values_types, tuple_argument] = parseArguments(name, arguments);\n-\n-    AggregateFunctionPtr res;\n-    if (tuple_argument)\n-    {\n-        res.reset(createWithNumericBasedType<MappedFunction<true>::template F>(*keys_type, keys_type, values_types, arguments, params));\n-        if (!res)\n-            res.reset(createWithDecimalType<MappedFunction<true>::template F>(*keys_type, keys_type, values_types, arguments, params));\n-        if (!res)\n-            res.reset(createWithStringType<MappedFunction<true>::template F>(*keys_type, keys_type, values_types, arguments, params));\n-    }\n-    else\n-    {\n-        res.reset(createWithNumericBasedType<MappedFunction<false>::template F>(*keys_type, keys_type, values_types, arguments, params));\n-        if (!res)\n-            res.reset(createWithDecimalType<MappedFunction<false>::template F>(*keys_type, keys_type, values_types, arguments, params));\n-        if (!res)\n-            res.reset(createWithStringType<MappedFunction<false>::template F>(*keys_type, keys_type, values_types, arguments, params));\n-    }\n-    if (!res)\n-        throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal type of argument for aggregate function {}\", name);\n-\n-    return res;\n-}\n-\n-// This template chooses the sumMap variant with given filtering and overflow\n-// handling.\n-template <bool filtered, bool overflow>\n-struct SumMapVariants\n-{\n-    // SumMapVariants chooses the `overflow` and `filtered` parameters of the\n-    // aggregate functions. The `tuple_argument` and the value type `T` are left\n-    // as free parameters.\n-    // DispatchOnTupleArgument chooses `tuple_argument`, and the value type `T`\n-    // is left free.\n-    template <bool tuple_argument>\n-    struct DispatchOnTupleArgument\n-    {\n-        template <typename T>\n-        using F = std::conditional_t<filtered,\n-            AggregateFunctionSumMapFiltered<T, overflow, tuple_argument>,\n-            AggregateFunctionSumMap<T, overflow, tuple_argument>>;\n-    };\n-};\n-\n-// This template gives an aggregate function template that is narrowed\n-// to accept either tuple argumen or normal arguments.\n-template <bool tuple_argument>\n-struct MinMapDispatchOnTupleArgument\n-{\n-    template <typename T>\n-    using F = AggregateFunctionMinMap<T, tuple_argument>;\n-};\n-\n-// This template gives an aggregate function template that is narrowed\n-// to accept either tuple argumen or normal arguments.\n-template <bool tuple_argument>\n-struct MaxMapDispatchOnTupleArgument\n-{\n-    template <typename T>\n-    using F = AggregateFunctionMaxMap<T, tuple_argument>;\n-};\n-\n }\n \n void registerAggregateFunctionSumMap(AggregateFunctionFactory & factory)\n@@ -147,26 +728,61 @@ void registerAggregateFunctionSumMap(AggregateFunctionFactory & factory)\n     // these functions used to be called *Map, with now these names occupied by\n     // Map combinator, which redirects calls here if was called with\n     // array or tuple arguments.\n-    factory.registerFunction(\"sumMappedArrays\", createAggregateFunctionMap<\n-        SumMapVariants<false, false>::DispatchOnTupleArgument>);\n+    factory.registerFunction(\"sumMappedArrays\", [](const std::string & name, const DataTypes & arguments, const Array & params, const Settings *) -> AggregateFunctionPtr\n+    {\n+        auto [keys_type, values_types, tuple_argument] = parseArguments(name, arguments);\n+        if (tuple_argument)\n+            return std::make_shared<AggregateFunctionSumMap<false, true>>(keys_type, values_types, arguments, params);\n+        else\n+            return std::make_shared<AggregateFunctionSumMap<false, false>>(keys_type, values_types, arguments, params);\n+    });\n \n-    factory.registerFunction(\"minMappedArrays\",\n-        createAggregateFunctionMap<MinMapDispatchOnTupleArgument>);\n+    factory.registerFunction(\"minMappedArrays\", [](const std::string & name, const DataTypes & arguments, const Array & params, const Settings *) -> AggregateFunctionPtr\n+    {\n+        auto [keys_type, values_types, tuple_argument] = parseArguments(name, arguments);\n+        if (tuple_argument)\n+            return std::make_shared<AggregateFunctionMinMap<true>>(keys_type, values_types, arguments, params);\n+        else\n+            return std::make_shared<AggregateFunctionMinMap<false>>(keys_type, values_types, arguments, params);\n+    });\n \n-    factory.registerFunction(\"maxMappedArrays\",\n-        createAggregateFunctionMap<MaxMapDispatchOnTupleArgument>);\n+    factory.registerFunction(\"maxMappedArrays\", [](const std::string & name, const DataTypes & arguments, const Array & params, const Settings *) -> AggregateFunctionPtr\n+    {\n+        auto [keys_type, values_types, tuple_argument] = parseArguments(name, arguments);\n+        if (tuple_argument)\n+            return std::make_shared<AggregateFunctionMaxMap<true>>(keys_type, values_types, arguments, params);\n+        else\n+            return std::make_shared<AggregateFunctionMaxMap<false>>(keys_type, values_types, arguments, params);\n+    });\n \n     // these functions could be renamed to *MappedArrays too, but it would\n     // break backward compatibility\n-    factory.registerFunction(\"sumMapWithOverflow\", createAggregateFunctionMap<\n-        SumMapVariants<false, true>::DispatchOnTupleArgument>);\n+    factory.registerFunction(\"sumMapWithOverflow\", [](const std::string & name, const DataTypes & arguments, const Array & params, const Settings *) -> AggregateFunctionPtr\n+    {\n+        auto [keys_type, values_types, tuple_argument] = parseArguments(name, arguments);\n+        if (tuple_argument)\n+            return std::make_shared<AggregateFunctionSumMap<true, true>>(keys_type, values_types, arguments, params);\n+        else\n+            return std::make_shared<AggregateFunctionSumMap<true, false>>(keys_type, values_types, arguments, params);\n+    });\n \n-    factory.registerFunction(\"sumMapFiltered\", createAggregateFunctionMap<\n-        SumMapVariants<true, false>::DispatchOnTupleArgument>);\n+    factory.registerFunction(\"sumMapFiltered\", [](const std::string & name, const DataTypes & arguments, const Array & params, const Settings *) -> AggregateFunctionPtr\n+    {\n+        auto [keys_type, values_types, tuple_argument] = parseArguments(name, arguments);\n+        if (tuple_argument)\n+            return std::make_shared<AggregateFunctionSumMapFiltered<false, true>>(keys_type, values_types, arguments, params);\n+        else\n+            return std::make_shared<AggregateFunctionSumMapFiltered<false, false>>(keys_type, values_types, arguments, params);\n+    });\n \n-    factory.registerFunction(\"sumMapFilteredWithOverflow\",\n-        createAggregateFunctionMap<\n-            SumMapVariants<true, true>::DispatchOnTupleArgument>);\n+    factory.registerFunction(\"sumMapFilteredWithOverflow\", [](const std::string & name, const DataTypes & arguments, const Array & params, const Settings *) -> AggregateFunctionPtr\n+    {\n+        auto [keys_type, values_types, tuple_argument] = parseArguments(name, arguments);\n+        if (tuple_argument)\n+            return std::make_shared<AggregateFunctionSumMapFiltered<true, true>>(keys_type, values_types, arguments, params);\n+        else\n+            return std::make_shared<AggregateFunctionSumMapFiltered<true, false>>(keys_type, values_types, arguments, params);\n+    });\n }\n \n }\ndiff --git a/src/AggregateFunctions/AggregateFunctionSumMap.h b/src/AggregateFunctions/AggregateFunctionSumMap.h\ndeleted file mode 100644\nindex b30f5ff5220e..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionSumMap.h\n+++ /dev/null\n@@ -1,656 +0,0 @@\n-#pragma once\n-\n-#include <IO/WriteHelpers.h>\n-#include <IO/ReadHelpers.h>\n-\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <DataTypes/DataTypeNullable.h>\n-\n-#include <Columns/ColumnArray.h>\n-#include <Columns/ColumnTuple.h>\n-#include <Columns/ColumnVector.h>\n-#include <Columns/ColumnDecimal.h>\n-#include <Columns/ColumnString.h>\n-\n-#include <Common/FieldVisitorSum.h>\n-#include <Common/assert_cast.h>\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/FactoryHelpers.h>\n-#include <map>\n-#include <Common/ClickHouseRevision.h>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int BAD_ARGUMENTS;\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n-    extern const int LOGICAL_ERROR;\n-}\n-\n-template <typename T>\n-struct AggregateFunctionMapData\n-{\n-    // Map needs to be ordered to maintain function properties\n-    std::map<T, Array> merged_maps;\n-};\n-\n-/** Aggregate function, that takes at least two arguments: keys and values, and as a result, builds a tuple of at least 2 arrays -\n-  * ordered keys and variable number of argument values aggregated by corresponding keys.\n-  *\n-  * sumMap function is the most useful when using SummingMergeTree to sum Nested columns, which name ends in \"Map\".\n-  *\n-  * Example: sumMap(k, v...) of:\n-  *  k           v\n-  *  [1,2,3]     [10,10,10]\n-  *  [3,4,5]     [10,10,10]\n-  *  [4,5,6]     [10,10,10]\n-  *  [6,7,8]     [10,10,10]\n-  *  [7,5,3]     [5,15,25]\n-  *  [8,9,10]    [20,20,20]\n-  * will return:\n-  *  ([1,2,3,4,5,6,7,8,9,10],[10,10,45,20,35,20,15,30,20,20])\n-  *\n-  * minMap and maxMap share the same idea, but calculate min and max correspondingly.\n-  *\n-  * NOTE: The implementation of these functions are \"amateur grade\" - not efficient and low quality.\n-  */\n-\n-template <typename T, typename Derived, typename Visitor, bool overflow, bool tuple_argument, bool compact>\n-class AggregateFunctionMapBase : public IAggregateFunctionDataHelper<\n-    AggregateFunctionMapData<NearestFieldType<T>>, Derived>\n-{\n-private:\n-    static constexpr auto STATE_VERSION_1_MIN_REVISION = 54452;\n-\n-    DataTypePtr keys_type;\n-    SerializationPtr keys_serialization;\n-    DataTypes values_types;\n-    Serializations values_serializations;\n-    Serializations promoted_values_serializations;\n-\n-public:\n-    using Base = IAggregateFunctionDataHelper<\n-        AggregateFunctionMapData<NearestFieldType<T>>, Derived>;\n-\n-    AggregateFunctionMapBase(const DataTypePtr & keys_type_,\n-            const DataTypes & values_types_, const DataTypes & argument_types_)\n-        : Base(argument_types_, {} /* parameters */, createResultType(keys_type_, values_types_, getName()))\n-        , keys_type(keys_type_)\n-        , keys_serialization(keys_type->getDefaultSerialization())\n-        , values_types(values_types_)\n-    {\n-        values_serializations.reserve(values_types.size());\n-        promoted_values_serializations.reserve(values_types.size());\n-        for (const auto & type : values_types)\n-        {\n-            values_serializations.emplace_back(type->getDefaultSerialization());\n-            if (type->canBePromoted())\n-            {\n-                if (type->isNullable())\n-                    promoted_values_serializations.emplace_back(\n-                         makeNullable(removeNullable(type)->promoteNumericType())->getDefaultSerialization());\n-                else\n-                    promoted_values_serializations.emplace_back(type->promoteNumericType()->getDefaultSerialization());\n-            }\n-            else\n-            {\n-                promoted_values_serializations.emplace_back(type->getDefaultSerialization());\n-            }\n-        }\n-    }\n-\n-    bool isVersioned() const override { return true; }\n-\n-    size_t getDefaultVersion() const override { return 1; }\n-\n-    size_t getVersionFromRevision(size_t revision) const override\n-    {\n-        if (revision >= STATE_VERSION_1_MIN_REVISION)\n-            return 1;\n-        else\n-            return 0;\n-    }\n-\n-    static DataTypePtr createResultType(\n-        const DataTypePtr & keys_type_,\n-        const DataTypes & values_types_,\n-        const String & name_)\n-    {\n-        DataTypes types;\n-        types.emplace_back(std::make_shared<DataTypeArray>(keys_type_));\n-\n-        for (const auto & value_type : values_types_)\n-        {\n-            if constexpr (std::is_same_v<Visitor, FieldVisitorSum>)\n-            {\n-                if (!value_type->isSummable())\n-                    throw Exception{ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                        \"Values for {} cannot be summed, passed type {}\",\n-                        name_, value_type->getName()};\n-            }\n-\n-            DataTypePtr result_type;\n-\n-            if constexpr (overflow)\n-            {\n-                if (value_type->onlyNull())\n-                    throw Exception{ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                        \"Cannot calculate {} of type {}\",\n-                        name_, value_type->getName()};\n-\n-                // Overflow, meaning that the returned type is the same as\n-                // the input type. Nulls are skipped.\n-                result_type = removeNullable(value_type);\n-            }\n-            else\n-            {\n-                auto value_type_without_nullable = removeNullable(value_type);\n-\n-                // No overflow, meaning we promote the types if necessary.\n-                if (!value_type_without_nullable->canBePromoted())\n-                    throw Exception{ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                        \"Values for {} are expected to be Numeric, Float or Decimal, passed type {}\",\n-                        name_, value_type->getName()};\n-\n-                WhichDataType value_type_to_check(value_type_without_nullable);\n-\n-                /// Do not promote decimal because of implementation issues of this function design\n-                /// Currently we cannot get result column type in case of decimal we cannot get decimal scale\n-                /// in method void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-                /// If we decide to make this function more efficient we should promote decimal type during summ\n-                if (value_type_to_check.isDecimal())\n-                    result_type = value_type_without_nullable;\n-                else\n-                    result_type = value_type_without_nullable->promoteNumericType();\n-            }\n-\n-            types.emplace_back(std::make_shared<DataTypeArray>(result_type));\n-        }\n-\n-        return std::make_shared<DataTypeTuple>(types);\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    static const auto & getArgumentColumns(const IColumn**& columns)\n-    {\n-        if constexpr (tuple_argument)\n-        {\n-            return assert_cast<const ColumnTuple *>(columns[0])->getColumns();\n-        }\n-        else\n-        {\n-            return columns;\n-        }\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns_, const size_t row_num, Arena *) const override\n-    {\n-        const auto & columns = getArgumentColumns(columns_);\n-\n-        // Column 0 contains array of keys of known type\n-        const ColumnArray & array_column0 = assert_cast<const ColumnArray &>(*columns[0]);\n-        const IColumn::Offsets & offsets0 = array_column0.getOffsets();\n-        const IColumn & key_column = array_column0.getData();\n-        const size_t keys_vec_offset = offsets0[row_num - 1];\n-        const size_t keys_vec_size = (offsets0[row_num] - keys_vec_offset);\n-\n-        // Columns 1..n contain arrays of numeric values to sum\n-        auto & merged_maps = this->data(place).merged_maps;\n-        for (size_t col = 0, size = values_types.size(); col < size; ++col)\n-        {\n-            const auto & array_column = assert_cast<const ColumnArray &>(*columns[col + 1]);\n-            const IColumn & value_column = array_column.getData();\n-            const IColumn::Offsets & offsets = array_column.getOffsets();\n-            const size_t values_vec_offset = offsets[row_num - 1];\n-            const size_t values_vec_size = (offsets[row_num] - values_vec_offset);\n-\n-            // Expect key and value arrays to be of same length\n-            if (keys_vec_size != values_vec_size)\n-                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Sizes of keys and values arrays do not match\");\n-\n-            // Insert column values for all keys\n-            for (size_t i = 0; i < keys_vec_size; ++i)\n-            {\n-                auto value = value_column[values_vec_offset + i];\n-                T key = static_cast<T>(key_column[keys_vec_offset + i].get<T>());\n-\n-                if (!keepKey(key))\n-                    continue;\n-\n-                decltype(merged_maps.begin()) it;\n-                if constexpr (is_decimal<T>)\n-                {\n-                    // FIXME why is storing NearestFieldType not enough, and we\n-                    // have to check for decimals again here?\n-                    UInt32 scale = static_cast<const ColumnDecimal<T> &>(key_column).getScale();\n-                    it = merged_maps.find(DecimalField<T>(key, scale));\n-                }\n-                else\n-                    it = merged_maps.find(key);\n-\n-                if (it != merged_maps.end())\n-                {\n-                    if (!value.isNull())\n-                    {\n-                        if (it->second[col].isNull())\n-                            it->second[col] = value;\n-                        else\n-                            applyVisitor(Visitor(value), it->second[col]);\n-                    }\n-                }\n-                else\n-                {\n-                    // Create a value array for this key\n-                    Array new_values;\n-                    new_values.resize(size);\n-                    new_values[col] = value;\n-\n-                    if constexpr (is_decimal<T>)\n-                    {\n-                        UInt32 scale = static_cast<const ColumnDecimal<T> &>(key_column).getScale();\n-                        merged_maps.emplace(DecimalField<T>(key, scale), std::move(new_values));\n-                    }\n-                    else\n-                    {\n-                        merged_maps.emplace(key, std::move(new_values));\n-                    }\n-                }\n-            }\n-        }\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        auto & merged_maps = this->data(place).merged_maps;\n-        const auto & rhs_maps = this->data(rhs).merged_maps;\n-\n-        for (const auto & elem : rhs_maps)\n-        {\n-            const auto & it = merged_maps.find(elem.first);\n-            if (it != merged_maps.end())\n-            {\n-                for (size_t col = 0; col < values_types.size(); ++col)\n-                    if (!elem.second[col].isNull())\n-                        applyVisitor(Visitor(elem.second[col]), it->second[col]);\n-            }\n-            else\n-                merged_maps[elem.first] = elem.second;\n-        }\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> version) const override\n-    {\n-        if (!version)\n-            version = getDefaultVersion();\n-\n-        const auto & merged_maps = this->data(place).merged_maps;\n-        size_t size = merged_maps.size();\n-        writeVarUInt(size, buf);\n-\n-        std::function<void(size_t, const Array &)> serialize;\n-        switch (*version)\n-        {\n-            case 0:\n-            {\n-                serialize = [&](size_t col_idx, const Array & values){ values_serializations[col_idx]->serializeBinary(values[col_idx], buf, {}); };\n-                break;\n-            }\n-            case 1:\n-            {\n-                serialize = [&](size_t col_idx, const Array & values){ promoted_values_serializations[col_idx]->serializeBinary(values[col_idx], buf, {}); };\n-                break;\n-            }\n-        }\n-\n-        for (const auto & elem : merged_maps)\n-        {\n-            keys_serialization->serializeBinary(elem.first, buf, {});\n-            for (size_t col = 0; col < values_types.size(); ++col)\n-                serialize(col, elem.second);\n-        }\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> version, Arena *) const override\n-    {\n-        if (!version)\n-            version = getDefaultVersion();\n-\n-        auto & merged_maps = this->data(place).merged_maps;\n-        size_t size = 0;\n-        readVarUInt(size, buf);\n-\n-        std::function<void(size_t, Array &)> deserialize;\n-        switch (*version)\n-        {\n-            case 0:\n-            {\n-                deserialize = [&](size_t col_idx, Array & values){ values_serializations[col_idx]->deserializeBinary(values[col_idx], buf, {}); };\n-                break;\n-            }\n-            case 1:\n-            {\n-                deserialize = [&](size_t col_idx, Array & values){ promoted_values_serializations[col_idx]->deserializeBinary(values[col_idx], buf, {}); };\n-                break;\n-            }\n-        }\n-\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            Field key;\n-            keys_serialization->deserializeBinary(key, buf, {});\n-\n-            Array values;\n-            values.resize(values_types.size());\n-\n-            for (size_t col = 0; col < values_types.size(); ++col)\n-                deserialize(col, values);\n-\n-            if constexpr (is_decimal<T>)\n-                merged_maps[key.get<DecimalField<T>>()] = values;\n-            else\n-                merged_maps[key.get<T>()] = values;\n-        }\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        size_t num_columns = values_types.size();\n-\n-        // Final step does compaction of keys that have zero values, this mutates the state\n-        auto & merged_maps = this->data(place).merged_maps;\n-\n-        // Remove keys which are zeros or empty. This should be enabled only for sumMap.\n-        if constexpr (compact)\n-        {\n-            for (auto it = merged_maps.cbegin(); it != merged_maps.cend();)\n-            {\n-                // Key is not compacted if it has at least one non-zero value\n-                bool erase = true;\n-                for (size_t col = 0; col < num_columns; ++col)\n-                {\n-                    if (!it->second[col].isNull() && it->second[col] != values_types[col]->getDefault())\n-                    {\n-                        erase = false;\n-                        break;\n-                    }\n-                }\n-\n-                if (erase)\n-                    it = merged_maps.erase(it);\n-                else\n-                    ++it;\n-            }\n-        }\n-\n-        size_t size = merged_maps.size();\n-\n-        auto & to_tuple = assert_cast<ColumnTuple &>(to);\n-        auto & to_keys_arr = assert_cast<ColumnArray &>(to_tuple.getColumn(0));\n-        auto & to_keys_col = to_keys_arr.getData();\n-\n-        // Advance column offsets\n-        auto & to_keys_offsets = to_keys_arr.getOffsets();\n-        to_keys_offsets.push_back(to_keys_offsets.back() + size);\n-        to_keys_col.reserve(size);\n-\n-        for (size_t col = 0; col < num_columns; ++col)\n-        {\n-            auto & to_values_arr = assert_cast<ColumnArray &>(to_tuple.getColumn(col + 1));\n-            auto & to_values_offsets = to_values_arr.getOffsets();\n-            to_values_offsets.push_back(to_values_offsets.back() + size);\n-            to_values_arr.getData().reserve(size);\n-        }\n-\n-        // Write arrays of keys and values\n-        for (const auto & elem : merged_maps)\n-        {\n-            // Write array of keys into column\n-            to_keys_col.insert(elem.first);\n-\n-            // Write 0..n arrays of values\n-            for (size_t col = 0; col < num_columns; ++col)\n-            {\n-                auto & to_values_col = assert_cast<ColumnArray &>(to_tuple.getColumn(col + 1)).getData();\n-                if (elem.second[col].isNull())\n-                    to_values_col.insertDefault();\n-                else\n-                    to_values_col.insert(elem.second[col]);\n-            }\n-        }\n-    }\n-\n-    bool keepKey(const T & key) const { return static_cast<const Derived &>(*this).keepKey(key); }\n-    String getName() const override { return Derived::getNameImpl(); }\n-};\n-\n-template <typename T, bool overflow, bool tuple_argument>\n-class AggregateFunctionSumMap final :\n-    public AggregateFunctionMapBase<T, AggregateFunctionSumMap<T, overflow, tuple_argument>, FieldVisitorSum, overflow, tuple_argument, true>\n-{\n-private:\n-    using Self = AggregateFunctionSumMap<T, overflow, tuple_argument>;\n-    using Base = AggregateFunctionMapBase<T, Self, FieldVisitorSum, overflow, tuple_argument, true>;\n-\n-public:\n-    AggregateFunctionSumMap(const DataTypePtr & keys_type_,\n-            DataTypes & values_types_, const DataTypes & argument_types_,\n-            const Array & params_)\n-        : Base{keys_type_, values_types_, argument_types_}\n-    {\n-        // The constructor accepts parameters to have a uniform interface with\n-        // sumMapFiltered, but this function doesn't have any parameters.\n-        assertNoParameters(getNameImpl(), params_);\n-    }\n-\n-    static String getNameImpl()\n-    {\n-        if constexpr (overflow)\n-        {\n-            return \"sumMapWithOverflow\";\n-        }\n-        else\n-        {\n-            return \"sumMap\";\n-        }\n-    }\n-\n-    bool keepKey(const T &) const { return true; }\n-};\n-\n-\n-template <typename T, bool overflow, bool tuple_argument>\n-class AggregateFunctionSumMapFiltered final :\n-    public AggregateFunctionMapBase<T,\n-        AggregateFunctionSumMapFiltered<T, overflow, tuple_argument>,\n-        FieldVisitorSum,\n-        overflow,\n-        tuple_argument,\n-        true>\n-{\n-private:\n-    using Self = AggregateFunctionSumMapFiltered<T, overflow, tuple_argument>;\n-    using Base = AggregateFunctionMapBase<T, Self, FieldVisitorSum, overflow, tuple_argument, true>;\n-\n-    using ContainerT = std::unordered_set<T>;\n-\n-    ContainerT keys_to_keep;\n-\n-public:\n-    AggregateFunctionSumMapFiltered(const DataTypePtr & keys_type_,\n-            const DataTypes & values_types_, const DataTypes & argument_types_,\n-            const Array & params_)\n-        : Base{keys_type_, values_types_, argument_types_}\n-    {\n-        if (params_.size() != 1)\n-            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n-                \"Aggregate function '{}' requires exactly one parameter \"\n-                \"of Array type\", getNameImpl());\n-\n-        Array keys_to_keep_values;\n-        if (!params_.front().tryGet<Array>(keys_to_keep_values))\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n-                \"Aggregate function {} requires an Array as a parameter\",\n-                getNameImpl());\n-\n-        this->parameters = params_;\n-\n-        keys_to_keep.reserve(keys_to_keep_values.size());\n-\n-        for (const Field & f : keys_to_keep_values)\n-            keys_to_keep.emplace(f.safeGet<T>());\n-    }\n-\n-    static String getNameImpl()\n-    {\n-        if constexpr (overflow)\n-        {\n-            return \"sumMapFilteredWithOverflow\";\n-        }\n-        else\n-        {\n-            return \"sumMapFiltered\";\n-        }\n-    }\n-\n-    bool keepKey(const T & key) const { return keys_to_keep.count(key); }\n-};\n-\n-\n-/** Implements `Max` operation.\n- *  Returns true if changed\n- */\n-class FieldVisitorMax : public StaticVisitor<bool>\n-{\n-private:\n-    const Field & rhs;\n-\n-    template <typename FieldType>\n-    bool compareImpl(FieldType & x) const\n-    {\n-        auto val = rhs.get<FieldType>();\n-        if (val > x)\n-        {\n-            x = val;\n-            return true;\n-        }\n-\n-        return false;\n-    }\n-\n-public:\n-    explicit FieldVisitorMax(const Field & rhs_) : rhs(rhs_) {}\n-\n-    bool operator() (Null &) const\n-    {\n-        /// Do not update current value, skip nulls\n-        return false;\n-    }\n-\n-    bool operator() (AggregateFunctionStateData &) const { throw Exception(ErrorCodes::LOGICAL_ERROR, \"Cannot compare AggregateFunctionStates\"); }\n-\n-    bool operator() (Array & x) const { return compareImpl<Array>(x); }\n-    bool operator() (Tuple & x) const { return compareImpl<Tuple>(x); }\n-    template <typename T>\n-    bool operator() (DecimalField<T> & x) const { return compareImpl<DecimalField<T>>(x); }\n-    template <typename T>\n-    bool operator() (T & x) const { return compareImpl<T>(x); }\n-};\n-\n-/** Implements `Min` operation.\n- *  Returns true if changed\n- */\n-class FieldVisitorMin : public StaticVisitor<bool>\n-{\n-private:\n-    const Field & rhs;\n-\n-    template <typename FieldType>\n-    bool compareImpl(FieldType & x) const\n-    {\n-        auto val = rhs.get<FieldType>();\n-        if (val < x)\n-        {\n-            x = val;\n-            return true;\n-        }\n-\n-        return false;\n-    }\n-\n-public:\n-    explicit FieldVisitorMin(const Field & rhs_) : rhs(rhs_) {}\n-\n-\n-    bool operator() (Null &) const\n-    {\n-        /// Do not update current value, skip nulls\n-        return false;\n-    }\n-\n-    bool operator() (AggregateFunctionStateData &) const { throw Exception(ErrorCodes::LOGICAL_ERROR, \"Cannot sum AggregateFunctionStates\"); }\n-\n-    bool operator() (Array & x) const { return compareImpl<Array>(x); }\n-    bool operator() (Tuple & x) const { return compareImpl<Tuple>(x); }\n-    template <typename T>\n-    bool operator() (DecimalField<T> & x) const { return compareImpl<DecimalField<T>>(x); }\n-    template <typename T>\n-    bool operator() (T & x) const { return compareImpl<T>(x); }\n-};\n-\n-\n-template <typename T, bool tuple_argument>\n-class AggregateFunctionMinMap final :\n-    public AggregateFunctionMapBase<T, AggregateFunctionMinMap<T, tuple_argument>, FieldVisitorMin, true, tuple_argument, false>\n-{\n-private:\n-    using Self = AggregateFunctionMinMap<T, tuple_argument>;\n-    using Base = AggregateFunctionMapBase<T, Self, FieldVisitorMin, true, tuple_argument, false>;\n-\n-public:\n-    AggregateFunctionMinMap(const DataTypePtr & keys_type_,\n-            DataTypes & values_types_, const DataTypes & argument_types_,\n-            const Array & params_)\n-        : Base{keys_type_, values_types_, argument_types_}\n-    {\n-        // The constructor accepts parameters to have a uniform interface with\n-        // sumMapFiltered, but this function doesn't have any parameters.\n-        assertNoParameters(getNameImpl(), params_);\n-    }\n-\n-    static String getNameImpl() { return \"minMap\"; }\n-\n-    bool keepKey(const T &) const { return true; }\n-};\n-\n-template <typename T, bool tuple_argument>\n-class AggregateFunctionMaxMap final :\n-    public AggregateFunctionMapBase<T, AggregateFunctionMaxMap<T, tuple_argument>, FieldVisitorMax, true, tuple_argument, false>\n-{\n-private:\n-    using Self = AggregateFunctionMaxMap<T, tuple_argument>;\n-    using Base = AggregateFunctionMapBase<T, Self, FieldVisitorMax, true, tuple_argument, false>;\n-\n-public:\n-    AggregateFunctionMaxMap(const DataTypePtr & keys_type_,\n-            DataTypes & values_types_, const DataTypes & argument_types_,\n-            const Array & params_)\n-        : Base{keys_type_, values_types_, argument_types_}\n-    {\n-        // The constructor accepts parameters to have a uniform interface with\n-        // sumMapFiltered, but this function doesn't have any parameters.\n-        assertNoParameters(getNameImpl(), params_);\n-    }\n-\n-    static String getNameImpl() { return \"maxMap\"; }\n-\n-    bool keepKey(const T &) const { return true; }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionTopK.cpp b/src/AggregateFunctions/AggregateFunctionTopK.cpp\nindex f7b3524d1b97..745fa9a6f236 100644\n--- a/src/AggregateFunctions/AggregateFunctionTopK.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionTopK.cpp\n@@ -1,5 +1,4 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionTopK.h>\n #include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n #include <Common/FieldVisitorConvertToNumber.h>\n@@ -7,6 +6,20 @@\n #include <DataTypes/DataTypeDateTime.h>\n #include <DataTypes/DataTypeIPv4andIPv6.h>\n \n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/ReadHelpersArena.h>\n+\n+#include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypeString.h>\n+\n+#include <Columns/ColumnArray.h>\n+\n+#include <Common/SpaceSaving.h>\n+#include <Common/assert_cast.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+\n \n namespace DB\n {\n@@ -25,6 +38,229 @@ namespace ErrorCodes\n namespace\n {\n \n+inline constexpr UInt64 TOP_K_MAX_SIZE = 0xFFFFFF;\n+\n+template <typename T>\n+struct AggregateFunctionTopKData\n+{\n+    using Set = SpaceSaving<T, HashCRC32<T>>;\n+\n+    Set value;\n+};\n+\n+\n+template <typename T, bool is_weighted>\n+class AggregateFunctionTopK\n+    : public IAggregateFunctionDataHelper<AggregateFunctionTopKData<T>, AggregateFunctionTopK<T, is_weighted>>\n+{\n+protected:\n+    using State = AggregateFunctionTopKData<T>;\n+    UInt64 threshold;\n+    UInt64 reserved;\n+\n+public:\n+    AggregateFunctionTopK(UInt64 threshold_, UInt64 load_factor, const DataTypes & argument_types_, const Array & params)\n+        : IAggregateFunctionDataHelper<AggregateFunctionTopKData<T>, AggregateFunctionTopK<T, is_weighted>>(argument_types_, params, createResultType(argument_types_))\n+        , threshold(threshold_), reserved(load_factor * threshold)\n+    {}\n+\n+    AggregateFunctionTopK(UInt64 threshold_, UInt64 load_factor, const DataTypes & argument_types_, const Array & params, const DataTypePtr & result_type_)\n+        : IAggregateFunctionDataHelper<AggregateFunctionTopKData<T>, AggregateFunctionTopK<T, is_weighted>>(argument_types_, params, result_type_)\n+        , threshold(threshold_), reserved(load_factor * threshold)\n+    {}\n+\n+    String getName() const override { return is_weighted ? \"topKWeighted\" : \"topK\"; }\n+\n+    static DataTypePtr createResultType(const DataTypes & argument_types_)\n+    {\n+        return std::make_shared<DataTypeArray>(argument_types_[0]);\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        auto & set = this->data(place).value;\n+        if (set.capacity() != reserved)\n+            set.resize(reserved);\n+\n+        if constexpr (is_weighted)\n+            set.insert(assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num], columns[1]->getUInt(row_num));\n+        else\n+            set.insert(assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num]);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        auto & set = this->data(place).value;\n+        if (set.capacity() != reserved)\n+            set.resize(reserved);\n+        set.merge(this->data(rhs).value);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).value.write(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version  */, Arena *) const override\n+    {\n+        auto & set = this->data(place).value;\n+        set.resize(reserved);\n+        set.read(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n+        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n+\n+        const typename State::Set & set = this->data(place).value;\n+        auto result_vec = set.topK(threshold);\n+        size_t size = result_vec.size();\n+\n+        offsets_to.push_back(offsets_to.back() + size);\n+\n+        typename ColumnVector<T>::Container & data_to = assert_cast<ColumnVector<T> &>(arr_to.getData()).getData();\n+        size_t old_size = data_to.size();\n+        data_to.resize(old_size + size);\n+\n+        size_t i = 0;\n+        for (auto it = result_vec.begin(); it != result_vec.end(); ++it, ++i)\n+            data_to[old_size + i] = it->key;\n+    }\n+};\n+\n+\n+/// Generic implementation, it uses serialized representation as object descriptor.\n+struct AggregateFunctionTopKGenericData\n+{\n+    using Set = SpaceSaving<StringRef, StringRefHash>;\n+\n+    Set value;\n+};\n+\n+/** Template parameter with true value should be used for columns that store their elements in memory continuously.\n+ *  For such columns topK() can be implemented more efficiently (especially for small numeric arrays).\n+ */\n+template <bool is_plain_column, bool is_weighted>\n+class AggregateFunctionTopKGeneric\n+    : public IAggregateFunctionDataHelper<AggregateFunctionTopKGenericData, AggregateFunctionTopKGeneric<is_plain_column, is_weighted>>\n+{\n+private:\n+    using State = AggregateFunctionTopKGenericData;\n+\n+    UInt64 threshold;\n+    UInt64 reserved;\n+\n+    static void deserializeAndInsert(StringRef str, IColumn & data_to);\n+\n+public:\n+    AggregateFunctionTopKGeneric(\n+        UInt64 threshold_, UInt64 load_factor, const DataTypes & argument_types_, const Array & params)\n+        : IAggregateFunctionDataHelper<AggregateFunctionTopKGenericData, AggregateFunctionTopKGeneric<is_plain_column, is_weighted>>(argument_types_, params, createResultType(argument_types_))\n+        , threshold(threshold_), reserved(load_factor * threshold) {}\n+\n+    String getName() const override { return is_weighted ? \"topKWeighted\" : \"topK\"; }\n+\n+    static DataTypePtr createResultType(const DataTypes & argument_types_)\n+    {\n+        return std::make_shared<DataTypeArray>(argument_types_[0]);\n+    }\n+\n+    bool allocatesMemoryInArena() const override\n+    {\n+        return true;\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).value.write(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n+    {\n+        auto & set = this->data(place).value;\n+        set.clear();\n+\n+        // Specialized here because there's no deserialiser for StringRef\n+        size_t size = 0;\n+        readVarUInt(size, buf);\n+        if (unlikely(size > TOP_K_MAX_SIZE))\n+            throw Exception(\n+                ErrorCodes::ARGUMENT_OUT_OF_BOUND,\n+                \"Too large size ({}) for aggregate function '{}' state (maximum is {})\",\n+                size,\n+                getName(),\n+                TOP_K_MAX_SIZE);\n+        set.resize(size);\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            auto ref = readStringBinaryInto(*arena, buf);\n+            UInt64 count;\n+            UInt64 error;\n+            readVarUInt(count, buf);\n+            readVarUInt(error, buf);\n+            set.insert(ref, count, error);\n+            arena->rollback(ref.size);\n+        }\n+\n+        set.readAlphaMap(buf);\n+    }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        auto & set = this->data(place).value;\n+        if (set.capacity() != reserved)\n+            set.resize(reserved);\n+\n+        if constexpr (is_plain_column)\n+        {\n+            if constexpr (is_weighted)\n+                set.insert(columns[0]->getDataAt(row_num), columns[1]->getUInt(row_num));\n+            else\n+                set.insert(columns[0]->getDataAt(row_num));\n+        }\n+        else\n+        {\n+            const char * begin = nullptr;\n+            StringRef str_serialized = columns[0]->serializeValueIntoArena(row_num, *arena, begin);\n+            if constexpr (is_weighted)\n+                set.insert(str_serialized, columns[1]->getUInt(row_num));\n+            else\n+                set.insert(str_serialized);\n+            arena->rollback(str_serialized.size);\n+        }\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        auto & set = this->data(place).value;\n+        if (set.capacity() != reserved)\n+            set.resize(reserved);\n+        set.merge(this->data(rhs).value);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n+        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n+        IColumn & data_to = arr_to.getData();\n+\n+        auto result_vec = this->data(place).value.topK(threshold);\n+        offsets_to.push_back(offsets_to.back() + result_vec.size());\n+\n+        for (auto & elem : result_vec)\n+        {\n+            if constexpr (is_plain_column)\n+                data_to.insertData(elem.key.data, elem.key.size);\n+            else\n+                data_to.deserializeAndInsertFromArena(elem.key.data);\n+        }\n+    }\n+};\n+\n+\n /// Substitute return type for Date and DateTime\n template <bool is_weighted>\n class AggregateFunctionTopKDate : public AggregateFunctionTopK<DataTypeDate::FieldType, is_weighted>\ndiff --git a/src/AggregateFunctions/AggregateFunctionTopK.h b/src/AggregateFunctions/AggregateFunctionTopK.h\ndeleted file mode 100644\nindex 89c49b245300..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionTopK.h\n+++ /dev/null\n@@ -1,250 +0,0 @@\n-#pragma once\n-\n-#include <IO/WriteHelpers.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/ReadHelpersArena.h>\n-\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeString.h>\n-\n-#include <Columns/ColumnArray.h>\n-\n-#include <Common/SpaceSaving.h>\n-#include <Common/assert_cast.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-static inline constexpr UInt64 TOP_K_MAX_SIZE = 0xFFFFFF;\n-\n-namespace ErrorCodes\n-{\n-    extern const int ARGUMENT_OUT_OF_BOUND;\n-}\n-\n-template <typename T>\n-struct AggregateFunctionTopKData\n-{\n-    using Set = SpaceSaving<T, HashCRC32<T>>;\n-\n-    Set value;\n-};\n-\n-\n-template <typename T, bool is_weighted>\n-class AggregateFunctionTopK\n-    : public IAggregateFunctionDataHelper<AggregateFunctionTopKData<T>, AggregateFunctionTopK<T, is_weighted>>\n-{\n-protected:\n-    using State = AggregateFunctionTopKData<T>;\n-    UInt64 threshold;\n-    UInt64 reserved;\n-\n-public:\n-    AggregateFunctionTopK(UInt64 threshold_, UInt64 load_factor, const DataTypes & argument_types_, const Array & params)\n-        : IAggregateFunctionDataHelper<AggregateFunctionTopKData<T>, AggregateFunctionTopK<T, is_weighted>>(argument_types_, params, createResultType(argument_types_))\n-        , threshold(threshold_), reserved(load_factor * threshold)\n-    {}\n-\n-    AggregateFunctionTopK(UInt64 threshold_, UInt64 load_factor, const DataTypes & argument_types_, const Array & params, const DataTypePtr & result_type_)\n-        : IAggregateFunctionDataHelper<AggregateFunctionTopKData<T>, AggregateFunctionTopK<T, is_weighted>>(argument_types_, params, result_type_)\n-        , threshold(threshold_), reserved(load_factor * threshold)\n-    {}\n-\n-    String getName() const override { return is_weighted ? \"topKWeighted\" : \"topK\"; }\n-\n-    static DataTypePtr createResultType(const DataTypes & argument_types_)\n-    {\n-        return std::make_shared<DataTypeArray>(argument_types_[0]);\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        auto & set = this->data(place).value;\n-        if (set.capacity() != reserved)\n-            set.resize(reserved);\n-\n-        if constexpr (is_weighted)\n-            set.insert(assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num], columns[1]->getUInt(row_num));\n-        else\n-            set.insert(assert_cast<const ColumnVector<T> &>(*columns[0]).getData()[row_num]);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        auto & set = this->data(place).value;\n-        if (set.capacity() != reserved)\n-            set.resize(reserved);\n-        set.merge(this->data(rhs).value);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).value.write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version  */, Arena *) const override\n-    {\n-        auto & set = this->data(place).value;\n-        set.resize(reserved);\n-        set.read(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n-        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n-\n-        const typename State::Set & set = this->data(place).value;\n-        auto result_vec = set.topK(threshold);\n-        size_t size = result_vec.size();\n-\n-        offsets_to.push_back(offsets_to.back() + size);\n-\n-        typename ColumnVector<T>::Container & data_to = assert_cast<ColumnVector<T> &>(arr_to.getData()).getData();\n-        size_t old_size = data_to.size();\n-        data_to.resize(old_size + size);\n-\n-        size_t i = 0;\n-        for (auto it = result_vec.begin(); it != result_vec.end(); ++it, ++i)\n-            data_to[old_size + i] = it->key;\n-    }\n-};\n-\n-\n-/// Generic implementation, it uses serialized representation as object descriptor.\n-struct AggregateFunctionTopKGenericData\n-{\n-    using Set = SpaceSaving<StringRef, StringRefHash>;\n-\n-    Set value;\n-};\n-\n-/** Template parameter with true value should be used for columns that store their elements in memory continuously.\n- *  For such columns topK() can be implemented more efficiently (especially for small numeric arrays).\n- */\n-template <bool is_plain_column, bool is_weighted>\n-class AggregateFunctionTopKGeneric\n-    : public IAggregateFunctionDataHelper<AggregateFunctionTopKGenericData, AggregateFunctionTopKGeneric<is_plain_column, is_weighted>>\n-{\n-private:\n-    using State = AggregateFunctionTopKGenericData;\n-\n-    UInt64 threshold;\n-    UInt64 reserved;\n-\n-    static void deserializeAndInsert(StringRef str, IColumn & data_to);\n-\n-public:\n-    AggregateFunctionTopKGeneric(\n-        UInt64 threshold_, UInt64 load_factor, const DataTypes & argument_types_, const Array & params)\n-        : IAggregateFunctionDataHelper<AggregateFunctionTopKGenericData, AggregateFunctionTopKGeneric<is_plain_column, is_weighted>>(argument_types_, params, createResultType(argument_types_))\n-        , threshold(threshold_), reserved(load_factor * threshold) {}\n-\n-    String getName() const override { return is_weighted ? \"topKWeighted\" : \"topK\"; }\n-\n-    static DataTypePtr createResultType(const DataTypes & argument_types_)\n-    {\n-        return std::make_shared<DataTypeArray>(argument_types_[0]);\n-    }\n-\n-    bool allocatesMemoryInArena() const override\n-    {\n-        return true;\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).value.write(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        auto & set = this->data(place).value;\n-        set.clear();\n-\n-        // Specialized here because there's no deserialiser for StringRef\n-        size_t size = 0;\n-        readVarUInt(size, buf);\n-        if (unlikely(size > TOP_K_MAX_SIZE))\n-            throw Exception(\n-                ErrorCodes::ARGUMENT_OUT_OF_BOUND,\n-                \"Too large size ({}) for aggregate function '{}' state (maximum is {})\",\n-                size,\n-                getName(),\n-                TOP_K_MAX_SIZE);\n-        set.resize(size);\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            auto ref = readStringBinaryInto(*arena, buf);\n-            UInt64 count;\n-            UInt64 error;\n-            readVarUInt(count, buf);\n-            readVarUInt(error, buf);\n-            set.insert(ref, count, error);\n-            arena->rollback(ref.size);\n-        }\n-\n-        set.readAlphaMap(buf);\n-    }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        auto & set = this->data(place).value;\n-        if (set.capacity() != reserved)\n-            set.resize(reserved);\n-\n-        if constexpr (is_plain_column)\n-        {\n-            if constexpr (is_weighted)\n-                set.insert(columns[0]->getDataAt(row_num), columns[1]->getUInt(row_num));\n-            else\n-                set.insert(columns[0]->getDataAt(row_num));\n-        }\n-        else\n-        {\n-            const char * begin = nullptr;\n-            StringRef str_serialized = columns[0]->serializeValueIntoArena(row_num, *arena, begin);\n-            if constexpr (is_weighted)\n-                set.insert(str_serialized, columns[1]->getUInt(row_num));\n-            else\n-                set.insert(str_serialized);\n-            arena->rollback(str_serialized.size);\n-        }\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        auto & set = this->data(place).value;\n-        if (set.capacity() != reserved)\n-            set.resize(reserved);\n-        set.merge(this->data(rhs).value);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n-        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n-        IColumn & data_to = arr_to.getData();\n-\n-        auto result_vec = this->data(place).value.topK(threshold);\n-        offsets_to.push_back(offsets_to.back() + result_vec.size());\n-\n-        for (auto & elem : result_vec)\n-        {\n-            if constexpr (is_plain_column)\n-                data_to.insertData(elem.key.data, elem.key.size);\n-            else\n-                data_to.deserializeAndInsertFromArena(elem.key.data);\n-        }\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined.cpp b/src/AggregateFunctions/AggregateFunctionUniqCombined.cpp\nindex ff3b463e9060..89e0a77f45c0 100644\n--- a/src/AggregateFunctions/AggregateFunctionUniqCombined.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined.cpp\n@@ -1,23 +1,8 @@\n #include <AggregateFunctions/AggregateFunctionUniqCombined.h>\n \n-#include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/Helpers.h>\n-\n-#include <Common/FieldVisitorConvertToNumber.h>\n-\n-#include <DataTypes/DataTypeDate.h>\n-#include <DataTypes/DataTypeDate32.h>\n-#include <DataTypes/DataTypeDateTime.h>\n-#include <DataTypes/DataTypeIPv4andIPv6.h>\n-\n-#include <functional>\n-\n-\n namespace DB\n {\n \n-struct Settings;\n-\n namespace ErrorCodes\n {\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n@@ -26,119 +11,56 @@ namespace ErrorCodes\n \n namespace\n {\n-    template <UInt8 K, typename HashValueType>\n-    struct WithK\n-    {\n-        template <typename T>\n-        using AggregateFunction = AggregateFunctionUniqCombined<T, K, HashValueType>;\n \n-        template <bool is_exact, bool argument_is_tuple>\n-        using AggregateFunctionVariadic = AggregateFunctionUniqCombinedVariadic<is_exact, argument_is_tuple, K, HashValueType>;\n-    };\n+AggregateFunctionPtr createAggregateFunctionUniqCombined(bool use_64_bit_hash,\n+    const std::string & name, const DataTypes & argument_types, const Array & params)\n+{\n+    /// log2 of the number of cells in HyperLogLog.\n+    /// Reasonable default value, selected to be comparable in quality with \"uniq\" aggregate function.\n+    UInt8 precision = 17;\n \n-    template <UInt8 K, typename HashValueType>\n-    AggregateFunctionPtr createAggregateFunctionWithK(const DataTypes & argument_types, const Array & params)\n+    if (!params.empty())\n     {\n-        /// We use exact hash function if the arguments are not contiguous in memory, because only exact hash function has support for this case.\n-        bool use_exact_hash_function = !isAllArgumentsContiguousInMemory(argument_types);\n-\n-        if (argument_types.size() == 1)\n-        {\n-            const IDataType & argument_type = *argument_types[0];\n-\n-            AggregateFunctionPtr res(createWithNumericType<WithK<K, HashValueType>::template AggregateFunction>(*argument_types[0], argument_types, params));\n-\n-            WhichDataType which(argument_type);\n-            if (res)\n-                return res;\n-            else if (which.isDate())\n-                return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeDate::FieldType>>(argument_types, params);\n-            else if (which.isDate32())\n-                return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeDate32::FieldType>>(argument_types, params);\n-            else if (which.isDateTime())\n-                return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeDateTime::FieldType>>(argument_types, params);\n-            else if (which.isStringOrFixedString())\n-                return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<String>>(argument_types, params);\n-            else if (which.isUUID())\n-                return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeUUID::FieldType>>(argument_types, params);\n-            else if (which.isIPv4())\n-                return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeIPv4::FieldType>>(argument_types, params);\n-            else if (which.isIPv6())\n-                return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeIPv6::FieldType>>(argument_types, params);\n-            else if (which.isTuple())\n-            {\n-                if (use_exact_hash_function)\n-                    return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunctionVariadic<true, true>>(argument_types, params);\n-                else\n-                    return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunctionVariadic<false, true>>(argument_types, params);\n-            }\n-        }\n-\n-        /// \"Variadic\" method also works as a fallback generic case for a single argument.\n-        if (use_exact_hash_function)\n-            return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunctionVariadic<true, false>>(argument_types, params);\n-        else\n-            return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunctionVariadic<false, false>>(argument_types, params);\n+        if (params.size() != 1)\n+            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} requires one parameter or less.\",\n+                name);\n+\n+        UInt64 precision_param = applyVisitor(FieldVisitorConvertToNumber<UInt64>(), params[0]);\n+        // This range is hardcoded below\n+        if (precision_param > 20 || precision_param < 12)\n+            throw Exception(ErrorCodes::ARGUMENT_OUT_OF_BOUND, \"Parameter for aggregate function {} is out of range: [12, 20].\",\n+                name);\n+        precision = precision_param;\n     }\n \n-    template <UInt8 K>\n-    AggregateFunctionPtr createAggregateFunctionWithHashType(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params)\n-    {\n-        if (use_64_bit_hash)\n-            return createAggregateFunctionWithK<K, UInt64>(argument_types, params);\n-        else\n-            return createAggregateFunctionWithK<K, UInt32>(argument_types, params);\n-    }\n+    if (argument_types.empty())\n+        throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Incorrect number of arguments for aggregate function {}\", name);\n \n-    AggregateFunctionPtr createAggregateFunctionUniqCombined(bool use_64_bit_hash,\n-        const std::string & name, const DataTypes & argument_types, const Array & params)\n+    switch (precision) // NOLINT(bugprone-switch-missing-default-case)\n     {\n-        /// log2 of the number of cells in HyperLogLog.\n-        /// Reasonable default value, selected to be comparable in quality with \"uniq\" aggregate function.\n-        UInt8 precision = 17;\n-\n-        if (!params.empty())\n-        {\n-            if (params.size() != 1)\n-                throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Aggregate function {} requires one parameter or less.\",\n-                    name);\n-\n-            UInt64 precision_param = applyVisitor(FieldVisitorConvertToNumber<UInt64>(), params[0]);\n-            // This range is hardcoded below\n-            if (precision_param > 20 || precision_param < 12)\n-                throw Exception(ErrorCodes::ARGUMENT_OUT_OF_BOUND, \"Parameter for aggregate function {} is out of range: [12, 20].\",\n-                    name);\n-            precision = precision_param;\n-        }\n-\n-        if (argument_types.empty())\n-            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Incorrect number of arguments for aggregate function {}\", name);\n-\n-        switch (precision) // NOLINT(bugprone-switch-missing-default-case)\n-        {\n-            case 12:\n-                return createAggregateFunctionWithHashType<12>(use_64_bit_hash, argument_types, params);\n-            case 13:\n-                return createAggregateFunctionWithHashType<13>(use_64_bit_hash, argument_types, params);\n-            case 14:\n-                return createAggregateFunctionWithHashType<14>(use_64_bit_hash, argument_types, params);\n-            case 15:\n-                return createAggregateFunctionWithHashType<15>(use_64_bit_hash, argument_types, params);\n-            case 16:\n-                return createAggregateFunctionWithHashType<16>(use_64_bit_hash, argument_types, params);\n-            case 17:\n-                return createAggregateFunctionWithHashType<17>(use_64_bit_hash, argument_types, params);\n-            case 18:\n-                return createAggregateFunctionWithHashType<18>(use_64_bit_hash, argument_types, params);\n-            case 19:\n-                return createAggregateFunctionWithHashType<19>(use_64_bit_hash, argument_types, params);\n-            case 20:\n-                return createAggregateFunctionWithHashType<20>(use_64_bit_hash, argument_types, params);\n-        }\n-\n-        UNREACHABLE();\n+        case 12:\n+            return createAggregateFunctionWithHashType<12>(use_64_bit_hash, argument_types, params);\n+        case 13:\n+            return createAggregateFunctionWithHashType<13>(use_64_bit_hash, argument_types, params);\n+        case 14:\n+            return createAggregateFunctionWithHashType<14>(use_64_bit_hash, argument_types, params);\n+        case 15:\n+            return createAggregateFunctionWithHashType<15>(use_64_bit_hash, argument_types, params);\n+        case 16:\n+            return createAggregateFunctionWithHashType<16>(use_64_bit_hash, argument_types, params);\n+        case 17:\n+            return createAggregateFunctionWithHashType<17>(use_64_bit_hash, argument_types, params);\n+        case 18:\n+            return createAggregateFunctionWithHashType<18>(use_64_bit_hash, argument_types, params);\n+        case 19:\n+            return createAggregateFunctionWithHashType<19>(use_64_bit_hash, argument_types, params);\n+        case 20:\n+            return createAggregateFunctionWithHashType<20>(use_64_bit_hash, argument_types, params);\n     }\n \n+    UNREACHABLE();\n+}\n+\n }\n \n void registerAggregateFunctionUniqCombined(AggregateFunctionFactory & factory)\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined.h b/src/AggregateFunctions/AggregateFunctionUniqCombined.h\nindex 5e8fa69f9ded..107744426108 100644\n--- a/src/AggregateFunctions/AggregateFunctionUniqCombined.h\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined.h\n@@ -1,5 +1,15 @@\n #pragma once\n \n+#include <AggregateFunctions/AggregateFunctionFactory.h>\n+#include <AggregateFunctions/Helpers.h>\n+\n+#include <Common/FieldVisitorConvertToNumber.h>\n+\n+#include <DataTypes/DataTypeDate.h>\n+#include <DataTypes/DataTypeDate32.h>\n+#include <DataTypes/DataTypeDateTime.h>\n+#include <DataTypes/DataTypeIPv4andIPv6.h>\n+\n #include <base/bit_cast.h>\n \n #include <Common/CombinedCardinalityEstimator.h>\n@@ -16,58 +26,15 @@\n #include <AggregateFunctions/UniqVariadicHash.h>\n \n #include <Columns/ColumnVector.h>\n-#include <Columns/ColumnsNumber.h>\n+\n+#include <functional>\n \n \n namespace DB\n {\n-struct Settings;\n-namespace detail\n-{\n-    /** Hash function for uniqCombined/uniqCombined64 (based on Ret).\n-     */\n-    template <typename T, typename Ret>\n-    struct AggregateFunctionUniqCombinedTraits\n-    {\n-        static Ret hash(T x)\n-        {\n-            if constexpr (sizeof(T) > sizeof(UInt64))\n-                return static_cast<Ret>(DefaultHash64<T>(x));\n-            else\n-                return static_cast<Ret>(intHash64(x));\n-        }\n-    };\n-\n-    template <typename Ret>\n-    struct AggregateFunctionUniqCombinedTraits<UInt128, Ret>\n-    {\n-        static Ret hash(UInt128 x)\n-        {\n-            return static_cast<Ret>(sipHash64(x));\n-        }\n-    };\n-\n-    template <typename Ret>\n-    struct AggregateFunctionUniqCombinedTraits<Float32, Ret>\n-    {\n-        static Ret hash(Float32 x)\n-        {\n-            UInt64 res = bit_cast<UInt64>(x);\n-            return static_cast<Ret>(intHash64(res));\n-        }\n-    };\n \n-    template <typename Ret>\n-    struct AggregateFunctionUniqCombinedTraits<Float64, Ret>\n-    {\n-        static Ret hash(Float64 x)\n-        {\n-            UInt64 res = bit_cast<UInt64>(x);\n-            return static_cast<Ret>(intHash64(res));\n-        }\n-    };\n+struct Settings;\n \n-}\n \n // Unlike HashTableGrower always grows to power of 2.\n struct UniqCombinedHashTableGrower : public HashTableGrowerWithPrecalculation<>\n@@ -75,55 +42,40 @@ struct UniqCombinedHashTableGrower : public HashTableGrowerWithPrecalculation<>\n     void increaseSize() { increaseSizeDegree(1); }\n };\n \n-template <typename Key, UInt8 K>\n-struct AggregateFunctionUniqCombinedDataWithKey\n+namespace\n {\n+\n+template <typename T, UInt8 K, typename HashValueType>\n+struct AggregateFunctionUniqCombinedData\n+{\n+    using Key = std::conditional_t<\n+        std::is_same_v<T, String> || std::is_same_v<T, IPv6>,\n+        UInt64,\n+        HashValueType>;\n+\n     // TODO(ilezhankin): pre-generate values for |UniqCombinedBiasData|,\n     //                   at the moment gen-bias-data.py script doesn't work.\n \n     // We want to migrate from |HashSet| to |HyperLogLogCounter| when the sizes in memory become almost equal.\n     // The size per element in |HashSet| is sizeof(Key)*2 bytes, and the overall size of |HyperLogLogCounter| is 2^K * 6 bits.\n     // For Key=UInt32 we can calculate: 2^X * 4 * 2 \u2264 2^(K-3) * 6 \u21d2 X \u2264 K-4.\n-    using Set = CombinedCardinalityEstimator<Key, HashSet<Key, TrivialHash, UniqCombinedHashTableGrower>, 16, K - 5 + (sizeof(Key) == sizeof(UInt32)), K, TrivialHash, Key>;\n \n-    Set set;\n-};\n-\n-template <typename Key>\n-struct AggregateFunctionUniqCombinedDataWithKey<Key, 17>\n-{\n-    using Set = CombinedCardinalityEstimator<Key,\n+    /// Note: I don't recall what is special with '17' - probably it is one of the original functions that has to be compatible.\n+    using Set = CombinedCardinalityEstimator<\n+        Key,\n         HashSet<Key, TrivialHash, UniqCombinedHashTableGrower>,\n         16,\n-        12 + (sizeof(Key) == sizeof(UInt32)),\n-        17,\n+        K - 5 + (sizeof(Key) == sizeof(UInt32)),\n+        K,\n         TrivialHash,\n         Key,\n-        HyperLogLogBiasEstimator<UniqCombinedBiasData>,\n+        std::conditional_t<K == 17, HyperLogLogBiasEstimator<UniqCombinedBiasData>, TrivialBiasEstimator>,\n         HyperLogLogMode::FullFeatured>;\n \n     Set set;\n };\n \n \n-template <typename T, UInt8 K, typename HashValueType>\n-struct AggregateFunctionUniqCombinedData : public AggregateFunctionUniqCombinedDataWithKey<HashValueType, K>\n-{\n-};\n-\n-\n-/// For String keys, 64 bit hash is always used (both for uniqCombined and uniqCombined64),\n-///  because of backwards compatibility (64 bit hash was already used for uniqCombined).\n-template <UInt8 K, typename HashValueType>\n-struct AggregateFunctionUniqCombinedData<String, K, HashValueType> : public AggregateFunctionUniqCombinedDataWithKey<UInt64 /*always*/, K>\n-{\n-};\n-\n-template <UInt8 K, typename HashValueType>\n-struct AggregateFunctionUniqCombinedData<IPv6, K, HashValueType> : public AggregateFunctionUniqCombinedDataWithKey<UInt64 /*always*/, K>\n-{\n-};\n-\n template <typename T, UInt8 K, typename HashValueType>\n class AggregateFunctionUniqCombined final\n     : public IAggregateFunctionDataHelper<AggregateFunctionUniqCombinedData<T, K, HashValueType>, AggregateFunctionUniqCombined<T, K, HashValueType>>\n@@ -153,7 +105,30 @@ class AggregateFunctionUniqCombined final\n         else\n         {\n             const auto & value = assert_cast<const ColumnVector<T> &>(*columns[0]).getElement(row_num);\n-            this->data(place).set.insert(detail::AggregateFunctionUniqCombinedTraits<T, HashValueType>::hash(value));\n+\n+            HashValueType hash;\n+\n+            if constexpr (std::is_same_v<T, UInt128>)\n+            {\n+                /// This specialization exists due to historical circumstances.\n+                /// Initially UInt128 was introduced only for UUID, and then the other big-integer types were added.\n+                hash = static_cast<HashValueType>(sipHash64(value));\n+            }\n+            else if constexpr (std::is_floating_point_v<T>)\n+            {\n+                hash = static_cast<HashValueType>(intHash64(bit_cast<UInt64>(value)));\n+            }\n+            else if constexpr (sizeof(T) > sizeof(UInt64))\n+            {\n+                hash = static_cast<HashValueType>(DefaultHash64<T>(value));\n+            }\n+            else\n+            {\n+                /// This specialization exists also for compatibility with the initial implementation.\n+                hash = static_cast<HashValueType>(intHash64(value));\n+            }\n+\n+            this->data(place).set.insert(hash);\n         }\n     }\n \n@@ -237,4 +212,83 @@ class AggregateFunctionUniqCombinedVariadic final : public IAggregateFunctionDat\n     }\n };\n \n+\n+template <UInt8 K, typename HashValueType>\n+struct WithK\n+{\n+    template <typename T>\n+    using AggregateFunction = AggregateFunctionUniqCombined<T, K, HashValueType>;\n+\n+    template <bool is_exact, bool argument_is_tuple>\n+    using AggregateFunctionVariadic = AggregateFunctionUniqCombinedVariadic<is_exact, argument_is_tuple, K, HashValueType>;\n+};\n+\n+template <UInt8 K, typename HashValueType>\n+AggregateFunctionPtr createAggregateFunctionWithK(const DataTypes & argument_types, const Array & params)\n+{\n+    /// We use exact hash function if the arguments are not contiguous in memory, because only exact hash function has support for this case.\n+    bool use_exact_hash_function = !isAllArgumentsContiguousInMemory(argument_types);\n+\n+    if (argument_types.size() == 1)\n+    {\n+        const IDataType & argument_type = *argument_types[0];\n+\n+        AggregateFunctionPtr res(createWithNumericType<WithK<K, HashValueType>::template AggregateFunction>(*argument_types[0], argument_types, params));\n+\n+        WhichDataType which(argument_type);\n+        if (res)\n+            return res;\n+        else if (which.isDate())\n+            return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeDate::FieldType>>(argument_types, params);\n+        else if (which.isDate32())\n+            return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeDate32::FieldType>>(argument_types, params);\n+        else if (which.isDateTime())\n+            return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeDateTime::FieldType>>(argument_types, params);\n+        else if (which.isStringOrFixedString())\n+            return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<String>>(argument_types, params);\n+        else if (which.isUUID())\n+            return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeUUID::FieldType>>(argument_types, params);\n+        else if (which.isIPv4())\n+            return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeIPv4::FieldType>>(argument_types, params);\n+        else if (which.isIPv6())\n+            return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunction<DataTypeIPv6::FieldType>>(argument_types, params);\n+        else if (which.isTuple())\n+        {\n+            if (use_exact_hash_function)\n+                return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunctionVariadic<true, true>>(argument_types, params);\n+            else\n+                return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunctionVariadic<false, true>>(argument_types, params);\n+        }\n+    }\n+\n+    /// \"Variadic\" method also works as a fallback generic case for a single argument.\n+    if (use_exact_hash_function)\n+        return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunctionVariadic<true, false>>(argument_types, params);\n+    else\n+        return std::make_shared<typename WithK<K, HashValueType>::template AggregateFunctionVariadic<false, false>>(argument_types, params);\n+}\n+\n+}\n+\n+template <UInt8 K>\n+AggregateFunctionPtr createAggregateFunctionWithHashType(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params)\n+{\n+    if (use_64_bit_hash)\n+        return createAggregateFunctionWithK<K, UInt64>(argument_types, params);\n+    else\n+        return createAggregateFunctionWithK<K, UInt32>(argument_types, params);\n+}\n+\n+/// Let's instantiate these templates in separate translation units,\n+/// otherwise this translation unit becomes too large.\n+extern template AggregateFunctionPtr createAggregateFunctionWithHashType<12>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+extern template AggregateFunctionPtr createAggregateFunctionWithHashType<13>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+extern template AggregateFunctionPtr createAggregateFunctionWithHashType<14>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+extern template AggregateFunctionPtr createAggregateFunctionWithHashType<15>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+extern template AggregateFunctionPtr createAggregateFunctionWithHashType<16>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+extern template AggregateFunctionPtr createAggregateFunctionWithHashType<17>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+extern template AggregateFunctionPtr createAggregateFunctionWithHashType<18>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+extern template AggregateFunctionPtr createAggregateFunctionWithHashType<19>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+extern template AggregateFunctionPtr createAggregateFunctionWithHashType<20>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+\n }\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined12.cpp b/src/AggregateFunctions/AggregateFunctionUniqCombined12.cpp\nnew file mode 100644\nindex 000000000000..ac4b1f21951f\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined12.cpp\n@@ -0,0 +1,6 @@\n+#include <AggregateFunctions/AggregateFunctionUniqCombined.h>\n+\n+namespace DB\n+{\n+template AggregateFunctionPtr createAggregateFunctionWithHashType<12>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+}\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined13.cpp b/src/AggregateFunctions/AggregateFunctionUniqCombined13.cpp\nnew file mode 100644\nindex 000000000000..96a7340cb320\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined13.cpp\n@@ -0,0 +1,6 @@\n+#include <AggregateFunctions/AggregateFunctionUniqCombined.h>\n+\n+namespace DB\n+{\n+template AggregateFunctionPtr createAggregateFunctionWithHashType<13>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+}\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined14.cpp b/src/AggregateFunctions/AggregateFunctionUniqCombined14.cpp\nnew file mode 100644\nindex 000000000000..92d316e1b578\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined14.cpp\n@@ -0,0 +1,6 @@\n+#include <AggregateFunctions/AggregateFunctionUniqCombined.h>\n+\n+namespace DB\n+{\n+template AggregateFunctionPtr createAggregateFunctionWithHashType<14>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+}\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined15.cpp b/src/AggregateFunctions/AggregateFunctionUniqCombined15.cpp\nnew file mode 100644\nindex 000000000000..aab81ee8f4ee\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined15.cpp\n@@ -0,0 +1,6 @@\n+#include <AggregateFunctions/AggregateFunctionUniqCombined.h>\n+\n+namespace DB\n+{\n+template AggregateFunctionPtr createAggregateFunctionWithHashType<15>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+}\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined16.cpp b/src/AggregateFunctions/AggregateFunctionUniqCombined16.cpp\nnew file mode 100644\nindex 000000000000..b1d572a50923\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined16.cpp\n@@ -0,0 +1,6 @@\n+#include <AggregateFunctions/AggregateFunctionUniqCombined.h>\n+\n+namespace DB\n+{\n+template AggregateFunctionPtr createAggregateFunctionWithHashType<16>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+}\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined17.cpp b/src/AggregateFunctions/AggregateFunctionUniqCombined17.cpp\nnew file mode 100644\nindex 000000000000..d968437080be\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined17.cpp\n@@ -0,0 +1,6 @@\n+#include <AggregateFunctions/AggregateFunctionUniqCombined.h>\n+\n+namespace DB\n+{\n+template AggregateFunctionPtr createAggregateFunctionWithHashType<17>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+}\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined18.cpp b/src/AggregateFunctions/AggregateFunctionUniqCombined18.cpp\nnew file mode 100644\nindex 000000000000..8940e021cfd4\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined18.cpp\n@@ -0,0 +1,6 @@\n+#include <AggregateFunctions/AggregateFunctionUniqCombined.h>\n+\n+namespace DB\n+{\n+template AggregateFunctionPtr createAggregateFunctionWithHashType<18>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+}\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined19.cpp b/src/AggregateFunctions/AggregateFunctionUniqCombined19.cpp\nnew file mode 100644\nindex 000000000000..58c2ee90bf16\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined19.cpp\n@@ -0,0 +1,6 @@\n+#include <AggregateFunctions/AggregateFunctionUniqCombined.h>\n+\n+namespace DB\n+{\n+template AggregateFunctionPtr createAggregateFunctionWithHashType<19>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+}\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqCombined20.cpp b/src/AggregateFunctions/AggregateFunctionUniqCombined20.cpp\nnew file mode 100644\nindex 000000000000..87e530a4c1ba\n--- /dev/null\n+++ b/src/AggregateFunctions/AggregateFunctionUniqCombined20.cpp\n@@ -0,0 +1,6 @@\n+#include <AggregateFunctions/AggregateFunctionUniqCombined.h>\n+\n+namespace DB\n+{\n+template AggregateFunctionPtr createAggregateFunctionWithHashType<20>(bool use_64_bit_hash, const DataTypes & argument_types, const Array & params);\n+}\ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqUpTo.cpp b/src/AggregateFunctions/AggregateFunctionUniqUpTo.cpp\nindex 9fc3a05b1c58..4e99aa98c36c 100644\n--- a/src/AggregateFunctions/AggregateFunctionUniqUpTo.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionUniqUpTo.cpp\n@@ -1,12 +1,24 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n #include <AggregateFunctions/Helpers.h>\n-#include <AggregateFunctions/AggregateFunctionUniqUpTo.h>\n #include <Common/FieldVisitorConvertToNumber.h>\n #include <DataTypes/DataTypeDate.h>\n #include <DataTypes/DataTypeDate32.h>\n #include <DataTypes/DataTypeDateTime.h>\n-#include <DataTypes/DataTypeString.h>\n-#include <DataTypes/DataTypeFixedString.h>\n+\n+#include <Common/typeid_cast.h>\n+#include <Common/assert_cast.h>\n+\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/UniqVariadicHash.h>\n+\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypeTuple.h>\n+#include <DataTypes/DataTypeUUID.h>\n+\n+#include <Columns/ColumnsNumber.h>\n+\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n \n \n namespace DB\n@@ -24,6 +36,258 @@ namespace ErrorCodes\n namespace\n {\n \n+/** Counts the number of unique values up to no more than specified in the parameter.\n+  *\n+  * Example: uniqUpTo(3)(UserID)\n+  * - will count the number of unique visitors, return 1, 2, 3 or 4 if visitors > = 4.\n+  *\n+  * For strings, a non-cryptographic hash function is used, due to which the calculation may be a bit inaccurate.\n+  */\n+\n+template <typename T>\n+struct AggregateFunctionUniqUpToData\n+{\n+/** If count == threshold + 1 - this means that it is \"overflowed\" (values greater than threshold).\n+  * In this case (for example, after calling the merge function), the `data` array does not necessarily contain the initialized values\n+  * - example: combine a state in which there are few values, with another state that has overflowed;\n+  *   then set count to `threshold + 1`, and values from another state are not copied.\n+  */\n+    UInt8 count = 0;\n+    char data_ptr[0];\n+\n+    T load(size_t i) const\n+    {\n+        return unalignedLoad<T>(data_ptr + i * sizeof(T));\n+    }\n+\n+    void store(size_t i, const T & x)\n+    {\n+        unalignedStore<T>(data_ptr + i * sizeof(T), x);\n+    }\n+\n+    size_t size() const\n+    {\n+        return count;\n+    }\n+\n+    /// threshold - for how many elements there is room in a `data`.\n+    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n+    void ALWAYS_INLINE insert(T x, UInt8 threshold)\n+    {\n+        /// The state is already full - nothing needs to be done.\n+        if (count > threshold)\n+            return;\n+\n+        /// Linear search for the matching element.\n+        for (size_t i = 0; i < count; ++i)\n+            if (load(i) == x)\n+                return;\n+\n+        /// Did not find the matching element. If there is room for one more element, insert it.\n+        if (count < threshold)\n+            store(count, x);\n+\n+        /// After increasing count, the state may be overflowed.\n+        ++count;\n+    }\n+\n+    void merge(const AggregateFunctionUniqUpToData<T> & rhs, UInt8 threshold)\n+    {\n+        if (count > threshold)\n+            return;\n+\n+        if (rhs.count > threshold)\n+        {\n+        /// If `rhs` is overflowed, then set `count` too also overflowed for the current state.\n+            count = rhs.count;\n+            return;\n+        }\n+\n+        for (size_t i = 0; i < rhs.count; ++i)\n+            insert(rhs.load(i), threshold);\n+    }\n+\n+    void write(WriteBuffer & wb, UInt8 threshold) const\n+    {\n+        writeBinary(count, wb);\n+\n+        /// Write values only if the state is not overflowed. Otherwise, they are not needed, and only the fact that the state is overflowed is important.\n+        if (count <= threshold)\n+            wb.write(data_ptr, count * sizeof(T));\n+    }\n+\n+    void read(ReadBuffer & rb, UInt8 threshold)\n+    {\n+        readBinary(count, rb);\n+\n+        if (count <= threshold)\n+            rb.readStrict(data_ptr, count * sizeof(T));\n+    }\n+\n+    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n+    void ALWAYS_INLINE add(const IColumn & column, size_t row_num, UInt8 threshold)\n+    {\n+        insert(assert_cast<const ColumnVector<T> &>(column).getData()[row_num], threshold);\n+    }\n+};\n+\n+\n+/// For strings, their hashes are remembered.\n+template <>\n+struct AggregateFunctionUniqUpToData<String> : AggregateFunctionUniqUpToData<UInt64>\n+{\n+    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n+    void ALWAYS_INLINE add(const IColumn & column, size_t row_num, UInt8 threshold)\n+    {\n+        /// Keep in mind that calculations are approximate.\n+        StringRef value = column.getDataAt(row_num);\n+        insert(CityHash_v1_0_2::CityHash64(value.data, value.size), threshold);\n+    }\n+};\n+\n+template <>\n+struct AggregateFunctionUniqUpToData<UInt128> : AggregateFunctionUniqUpToData<UInt64>\n+{\n+    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n+    void ALWAYS_INLINE add(const IColumn & column, size_t row_num, UInt8 threshold)\n+    {\n+        UInt128 value = assert_cast<const ColumnVector<UInt128> &>(column).getData()[row_num];\n+        insert(sipHash64(value), threshold);\n+    }\n+};\n+\n+template <>\n+struct AggregateFunctionUniqUpToData<UInt256> : AggregateFunctionUniqUpToData<UInt64>\n+{\n+    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n+    void ALWAYS_INLINE add(const IColumn & column, size_t row_num, UInt8 threshold)\n+    {\n+        UInt256 value = assert_cast<const ColumnVector<UInt256> &>(column).getData()[row_num];\n+        insert(sipHash64(value), threshold);\n+    }\n+};\n+\n+template <>\n+struct AggregateFunctionUniqUpToData<Int256> : AggregateFunctionUniqUpToData<UInt64>\n+{\n+    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n+    void ALWAYS_INLINE add(const IColumn & column, size_t row_num, UInt8 threshold)\n+    {\n+        Int256 value = assert_cast<const ColumnVector<Int256> &>(column).getData()[row_num];\n+        insert(sipHash64(value), threshold);\n+    }\n+};\n+\n+\n+template <typename T>\n+class AggregateFunctionUniqUpTo final : public IAggregateFunctionDataHelper<AggregateFunctionUniqUpToData<T>, AggregateFunctionUniqUpTo<T>>\n+{\n+private:\n+    UInt8 threshold;\n+\n+public:\n+    AggregateFunctionUniqUpTo(UInt8 threshold_, const DataTypes & argument_types_, const Array & params_)\n+        : IAggregateFunctionDataHelper<AggregateFunctionUniqUpToData<T>, AggregateFunctionUniqUpTo<T>>(argument_types_, params_, std::make_shared<DataTypeUInt64>())\n+        , threshold(threshold_)\n+    {\n+    }\n+\n+    size_t sizeOfData() const override\n+    {\n+        return sizeof(AggregateFunctionUniqUpToData<T>) + sizeof(T) * threshold;\n+    }\n+\n+    String getName() const override { return \"uniqUpTo\"; }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n+    void ALWAYS_INLINE add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        this->data(place).add(*columns[0], row_num, threshold);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs), threshold);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).write(buf, threshold);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).read(buf, threshold);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        assert_cast<ColumnUInt64 &>(to).getData().push_back(this->data(place).size());\n+    }\n+};\n+\n+\n+/** For multiple arguments. To compute, hashes them.\n+  * You can pass multiple arguments as is; You can also pass one argument - a tuple.\n+  * But (for the possibility of effective implementation), you can not pass several arguments, among which there are tuples.\n+  */\n+template <bool is_exact, bool argument_is_tuple>\n+class AggregateFunctionUniqUpToVariadic final\n+    : public IAggregateFunctionDataHelper<AggregateFunctionUniqUpToData<UInt64>, AggregateFunctionUniqUpToVariadic<is_exact, argument_is_tuple>>\n+{\n+private:\n+    size_t num_args = 0;\n+    UInt8 threshold;\n+\n+public:\n+    AggregateFunctionUniqUpToVariadic(const DataTypes & arguments, const Array & params, UInt8 threshold_)\n+        : IAggregateFunctionDataHelper<AggregateFunctionUniqUpToData<UInt64>, AggregateFunctionUniqUpToVariadic<is_exact, argument_is_tuple>>(arguments, params, std::make_shared<DataTypeUInt64>())\n+        , threshold(threshold_)\n+    {\n+        if (argument_is_tuple)\n+            num_args = typeid_cast<const DataTypeTuple &>(*arguments[0]).getElements().size();\n+        else\n+            num_args = arguments.size();\n+    }\n+\n+    size_t sizeOfData() const override\n+    {\n+        return sizeof(AggregateFunctionUniqUpToData<UInt64>) + sizeof(UInt64) * threshold;\n+    }\n+\n+    String getName() const override { return \"uniqUpTo\"; }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        this->data(place).insert(UInt64(UniqVariadicHash<is_exact, argument_is_tuple>::apply(num_args, columns, row_num)), threshold);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs), threshold);\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).write(buf, threshold);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version  */, Arena *) const override\n+    {\n+        this->data(place).read(buf, threshold);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        assert_cast<ColumnUInt64 &>(to).getData().push_back(this->data(place).size());\n+    }\n+};\n+\n+\n constexpr UInt8 uniq_upto_max_threshold = 100;\n \n \ndiff --git a/src/AggregateFunctions/AggregateFunctionUniqUpTo.h b/src/AggregateFunctions/AggregateFunctionUniqUpTo.h\ndeleted file mode 100644\nindex 377f2580070e..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionUniqUpTo.h\n+++ /dev/null\n@@ -1,278 +0,0 @@\n-#pragma once\n-\n-#include <base/unaligned.h>\n-\n-#include <Common/typeid_cast.h>\n-#include <Common/assert_cast.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/UniqVariadicHash.h>\n-\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <DataTypes/DataTypeUUID.h>\n-\n-#include <Columns/ColumnsNumber.h>\n-\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-\n-/** Counts the number of unique values up to no more than specified in the parameter.\n-  *\n-  * Example: uniqUpTo(3)(UserID)\n-  * - will count the number of unique visitors, return 1, 2, 3 or 4 if visitors > = 4.\n-  *\n-  * For strings, a non-cryptographic hash function is used, due to which the calculation may be a bit inaccurate.\n-  */\n-\n-template <typename T>\n-struct AggregateFunctionUniqUpToData\n-{\n-/** If count == threshold + 1 - this means that it is \"overflowed\" (values greater than threshold).\n-  * In this case (for example, after calling the merge function), the `data` array does not necessarily contain the initialized values\n-  * - example: combine a state in which there are few values, with another state that has overflowed;\n-  *   then set count to `threshold + 1`, and values from another state are not copied.\n-  */\n-    UInt8 count = 0;\n-    char data_ptr[0];\n-\n-    T load(size_t i) const\n-    {\n-        return unalignedLoad<T>(data_ptr + i * sizeof(T));\n-    }\n-\n-    void store(size_t i, const T & x)\n-    {\n-        unalignedStore<T>(data_ptr + i * sizeof(T), x);\n-    }\n-\n-    size_t size() const\n-    {\n-        return count;\n-    }\n-\n-    /// threshold - for how many elements there is room in a `data`.\n-    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n-    void ALWAYS_INLINE insert(T x, UInt8 threshold)\n-    {\n-        /// The state is already full - nothing needs to be done.\n-        if (count > threshold)\n-            return;\n-\n-        /// Linear search for the matching element.\n-        for (size_t i = 0; i < count; ++i)\n-            if (load(i) == x)\n-                return;\n-\n-        /// Did not find the matching element. If there is room for one more element, insert it.\n-        if (count < threshold)\n-            store(count, x);\n-\n-        /// After increasing count, the state may be overflowed.\n-        ++count;\n-    }\n-\n-    void merge(const AggregateFunctionUniqUpToData<T> & rhs, UInt8 threshold)\n-    {\n-        if (count > threshold)\n-            return;\n-\n-        if (rhs.count > threshold)\n-        {\n-        /// If `rhs` is overflowed, then set `count` too also overflowed for the current state.\n-            count = rhs.count;\n-            return;\n-        }\n-\n-        for (size_t i = 0; i < rhs.count; ++i)\n-            insert(rhs.load(i), threshold);\n-    }\n-\n-    void write(WriteBuffer & wb, UInt8 threshold) const\n-    {\n-        writeBinary(count, wb);\n-\n-        /// Write values only if the state is not overflowed. Otherwise, they are not needed, and only the fact that the state is overflowed is important.\n-        if (count <= threshold)\n-            wb.write(data_ptr, count * sizeof(T));\n-    }\n-\n-    void read(ReadBuffer & rb, UInt8 threshold)\n-    {\n-        readBinary(count, rb);\n-\n-        if (count <= threshold)\n-            rb.readStrict(data_ptr, count * sizeof(T));\n-    }\n-\n-    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n-    void ALWAYS_INLINE add(const IColumn & column, size_t row_num, UInt8 threshold)\n-    {\n-        insert(assert_cast<const ColumnVector<T> &>(column).getData()[row_num], threshold);\n-    }\n-};\n-\n-\n-/// For strings, their hashes are remembered.\n-template <>\n-struct AggregateFunctionUniqUpToData<String> : AggregateFunctionUniqUpToData<UInt64>\n-{\n-    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n-    void ALWAYS_INLINE add(const IColumn & column, size_t row_num, UInt8 threshold)\n-    {\n-        /// Keep in mind that calculations are approximate.\n-        StringRef value = column.getDataAt(row_num);\n-        insert(CityHash_v1_0_2::CityHash64(value.data, value.size), threshold);\n-    }\n-};\n-\n-template <>\n-struct AggregateFunctionUniqUpToData<UInt128> : AggregateFunctionUniqUpToData<UInt64>\n-{\n-    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n-    void ALWAYS_INLINE add(const IColumn & column, size_t row_num, UInt8 threshold)\n-    {\n-        UInt128 value = assert_cast<const ColumnVector<UInt128> &>(column).getData()[row_num];\n-        insert(sipHash64(value), threshold);\n-    }\n-};\n-\n-template <>\n-struct AggregateFunctionUniqUpToData<UInt256> : AggregateFunctionUniqUpToData<UInt64>\n-{\n-    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n-    void ALWAYS_INLINE add(const IColumn & column, size_t row_num, UInt8 threshold)\n-    {\n-        UInt256 value = assert_cast<const ColumnVector<UInt256> &>(column).getData()[row_num];\n-        insert(sipHash64(value), threshold);\n-    }\n-};\n-\n-template <>\n-struct AggregateFunctionUniqUpToData<Int256> : AggregateFunctionUniqUpToData<UInt64>\n-{\n-    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n-    void ALWAYS_INLINE add(const IColumn & column, size_t row_num, UInt8 threshold)\n-    {\n-        Int256 value = assert_cast<const ColumnVector<Int256> &>(column).getData()[row_num];\n-        insert(sipHash64(value), threshold);\n-    }\n-};\n-\n-\n-template <typename T>\n-class AggregateFunctionUniqUpTo final : public IAggregateFunctionDataHelper<AggregateFunctionUniqUpToData<T>, AggregateFunctionUniqUpTo<T>>\n-{\n-private:\n-    UInt8 threshold;\n-\n-public:\n-    AggregateFunctionUniqUpTo(UInt8 threshold_, const DataTypes & argument_types_, const Array & params_)\n-        : IAggregateFunctionDataHelper<AggregateFunctionUniqUpToData<T>, AggregateFunctionUniqUpTo<T>>(argument_types_, params_, std::make_shared<DataTypeUInt64>())\n-        , threshold(threshold_)\n-    {\n-    }\n-\n-    size_t sizeOfData() const override\n-    {\n-        return sizeof(AggregateFunctionUniqUpToData<T>) + sizeof(T) * threshold;\n-    }\n-\n-    String getName() const override { return \"uniqUpTo\"; }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    /// ALWAYS_INLINE is required to have better code layout for uniqUpTo function\n-    void ALWAYS_INLINE add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        this->data(place).add(*columns[0], row_num, threshold);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs), threshold);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).write(buf, threshold);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).read(buf, threshold);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        assert_cast<ColumnUInt64 &>(to).getData().push_back(this->data(place).size());\n-    }\n-};\n-\n-\n-/** For multiple arguments. To compute, hashes them.\n-  * You can pass multiple arguments as is; You can also pass one argument - a tuple.\n-  * But (for the possibility of effective implementation), you can not pass several arguments, among which there are tuples.\n-  */\n-template <bool is_exact, bool argument_is_tuple>\n-class AggregateFunctionUniqUpToVariadic final\n-    : public IAggregateFunctionDataHelper<AggregateFunctionUniqUpToData<UInt64>, AggregateFunctionUniqUpToVariadic<is_exact, argument_is_tuple>>\n-{\n-private:\n-    size_t num_args = 0;\n-    UInt8 threshold;\n-\n-public:\n-    AggregateFunctionUniqUpToVariadic(const DataTypes & arguments, const Array & params, UInt8 threshold_)\n-        : IAggregateFunctionDataHelper<AggregateFunctionUniqUpToData<UInt64>, AggregateFunctionUniqUpToVariadic<is_exact, argument_is_tuple>>(arguments, params, std::make_shared<DataTypeUInt64>())\n-        , threshold(threshold_)\n-    {\n-        if (argument_is_tuple)\n-            num_args = typeid_cast<const DataTypeTuple &>(*arguments[0]).getElements().size();\n-        else\n-            num_args = arguments.size();\n-    }\n-\n-    size_t sizeOfData() const override\n-    {\n-        return sizeof(AggregateFunctionUniqUpToData<UInt64>) + sizeof(UInt64) * threshold;\n-    }\n-\n-    String getName() const override { return \"uniqUpTo\"; }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        this->data(place).insert(UInt64(UniqVariadicHash<is_exact, argument_is_tuple>::apply(num_args, columns, row_num)), threshold);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs), threshold);\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).write(buf, threshold);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version  */, Arena *) const override\n-    {\n-        this->data(place).read(buf, threshold);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        assert_cast<ColumnUInt64 &>(to).getData().push_back(this->data(place).size());\n-    }\n-};\n-\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionVarianceMatrix.cpp b/src/AggregateFunctions/AggregateFunctionVarianceMatrix.cpp\nindex ffb93b5d3b24..81804b562214 100644\n--- a/src/AggregateFunctions/AggregateFunctionVarianceMatrix.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionVarianceMatrix.cpp\n@@ -1,7 +1,11 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n-#include <AggregateFunctions/AggregateFunctionVarianceMatrix.h>\n+#include <Columns/ColumnArray.h>\n+#include <Common/PODArray_fwd.h>\n+#include <DataTypes/DataTypeArray.h>\n+#include <AggregateFunctions/IAggregateFunction.h>\n+#include <AggregateFunctions/Moments.h>\n+#include <DataTypes/DataTypesNumber.h>\n \n \n namespace DB\n@@ -16,6 +20,147 @@ namespace ErrorCodes\n namespace\n {\n \n+enum class StatisticsMatrixFunctionKind\n+{\n+    covarPopMatrix,\n+    covarSampMatrix,\n+    corrMatrix\n+};\n+\n+template <StatisticsMatrixFunctionKind _kind>\n+struct AggregateFunctionVarianceMatrixData\n+{\n+    using DataType = std::conditional_t<_kind == StatisticsMatrixFunctionKind::corrMatrix, CorrMoments<Float64>, CovarMoments<Float64>>;\n+\n+    AggregateFunctionVarianceMatrixData() = default;\n+\n+    explicit AggregateFunctionVarianceMatrixData(const size_t _num_args)\n+        : num_args(_num_args)\n+    {\n+        data_matrix.resize_fill(num_args * (num_args + 1) / 2, DataType());\n+    }\n+\n+    void add(const IColumn ** column, const size_t row_num)\n+    {\n+        for (size_t i = 0; i < num_args; ++i)\n+            for (size_t j = 0; j <= i; ++j)\n+                 data_matrix[i * (i + 1) / 2 + j].add(column[i]->getFloat64(row_num), column[j]->getFloat64(row_num));\n+    }\n+\n+    void merge(const AggregateFunctionVarianceMatrixData & other)\n+    {\n+        for (size_t i = 0; i < num_args; ++i)\n+            for (size_t j = 0; j <= i; ++j)\n+                data_matrix[i * (i + 1) / 2 + j].merge(other.data_matrix[i * (i + 1) / 2 + j]);\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        for (size_t i = 0; i < num_args; ++i)\n+            for (size_t j = 0; j <= i; ++j)\n+                data_matrix[i * (i + 1) / 2 + j].write(buf);\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        for (size_t i = 0; i < num_args; ++i)\n+            for (size_t j = 0; j <= i; ++j)\n+                data_matrix[i * (i + 1) / 2 + j].read(buf);\n+    }\n+\n+    void insertResultInto(IColumn & to) const\n+    {\n+        auto & data_to = assert_cast<ColumnFloat64 &>(assert_cast<ColumnArray &>(assert_cast<ColumnArray &>(to).getData()).getData()).getData();\n+        auto & root_offsets_to = assert_cast<ColumnArray &>(to).getOffsets();\n+        auto & nested_offsets_to = assert_cast<ColumnArray &>(assert_cast<ColumnArray &>(to).getData()).getOffsets();\n+        for (size_t i = 0; i < num_args; ++i)\n+        {\n+            for (size_t j = 0; j < num_args; ++j)\n+            {\n+                auto & data = i < j ? data_matrix[j * (j + 1) / 2 + i] : data_matrix[i * (i + 1) / 2 + j];\n+                if constexpr (kind == StatisticsMatrixFunctionKind::covarPopMatrix)\n+                    data_to.push_back(data.getPopulation());\n+                if constexpr (kind == StatisticsMatrixFunctionKind::covarSampMatrix)\n+                    data_to.push_back(data.getSample());\n+                if constexpr (kind == StatisticsMatrixFunctionKind::corrMatrix)\n+                    data_to.push_back(data.get());\n+            }\n+            nested_offsets_to.push_back(nested_offsets_to.back() + num_args);\n+        }\n+        root_offsets_to.push_back(root_offsets_to.back() + num_args);\n+    }\n+\n+    static constexpr StatisticsMatrixFunctionKind kind = _kind;\n+    PaddedPODArray<DataType> data_matrix;\n+    size_t num_args;\n+};\n+\n+template <typename Data>\n+class AggregateFunctionVarianceMatrix final\n+    : public IAggregateFunctionDataHelper<Data, AggregateFunctionVarianceMatrix<Data>>\n+{\n+public:\n+    explicit AggregateFunctionVarianceMatrix(const DataTypes & argument_types_)\n+        : IAggregateFunctionDataHelper<Data, AggregateFunctionVarianceMatrix<Data>>(argument_types_, {}, createResultType())\n+    {}\n+\n+    AggregateFunctionVarianceMatrix(const IDataType &, const DataTypes & argument_types_)\n+        : IAggregateFunctionDataHelper<Data, AggregateFunctionVarianceMatrix<Data>>(argument_types_, {}, createResultType())\n+    {}\n+\n+    String getName() const override\n+    {\n+        switch (Data::kind)\n+        {\n+            case StatisticsMatrixFunctionKind::covarPopMatrix: return \"covarPopMatrix\";\n+            case StatisticsMatrixFunctionKind::covarSampMatrix: return \"covarSampMatrix\";\n+            case StatisticsMatrixFunctionKind::corrMatrix: return \"corrMatrix\";\n+        }\n+    }\n+\n+    void create(AggregateDataPtr __restrict place) const override /// NOLINT\n+    {\n+        new (place) Data(this->argument_types.size());\n+    }\n+\n+    static DataTypePtr createResultType()\n+    {\n+        return std::make_shared<DataTypeArray>(std::make_shared<DataTypeArray>(std::make_shared<DataTypeFloat64>()));\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n+    {\n+        this->data(place).add(columns, row_num);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        this->data(place).insertResultInto(to);\n+    }\n+};\n+\n+using AggregateFunctionCovarPopMatrix = AggregateFunctionVarianceMatrix<AggregateFunctionVarianceMatrixData<StatisticsMatrixFunctionKind::covarPopMatrix>>;\n+using AggregateFunctionCovarSampMatrix = AggregateFunctionVarianceMatrix<AggregateFunctionVarianceMatrixData<StatisticsMatrixFunctionKind::covarSampMatrix>>;\n+using AggregateFunctionCorrMatrix = AggregateFunctionVarianceMatrix<AggregateFunctionVarianceMatrixData<StatisticsMatrixFunctionKind::corrMatrix>>;\n+\n+\n template <typename FunctionTemplate>\n AggregateFunctionPtr createAggregateFunctionVarianceMatrix(\n     const std::string & name, const DataTypes & argument_types, const Array & parameters, const Settings *)\ndiff --git a/src/AggregateFunctions/AggregateFunctionVarianceMatrix.h b/src/AggregateFunctions/AggregateFunctionVarianceMatrix.h\ndeleted file mode 100644\nindex 6d05c3edf459..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionVarianceMatrix.h\n+++ /dev/null\n@@ -1,159 +0,0 @@\n-#pragma once\n-\n-#include <Columns/ColumnArray.h>\n-#include <Columns/ColumnsNumber.h>\n-#include <Common/PODArray.h>\n-#include <Common/PODArray_fwd.h>\n-#include <DataTypes/DataTypeArray.h>\n-#include <AggregateFunctions/IAggregateFunction.h>\n-#include <AggregateFunctions/Moments.h>\n-#include <DataTypes/DataTypesNumber.h>\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-enum class StatisticsMatrixFunctionKind\n-{\n-    covarPopMatrix,\n-    covarSampMatrix,\n-    corrMatrix\n-};\n-\n-template <StatisticsMatrixFunctionKind _kind>\n-struct AggregateFunctionVarianceMatrixData\n-{\n-    using DataType = std::conditional_t<_kind == StatisticsMatrixFunctionKind::corrMatrix, CorrMoments<Float64>, CovarMoments<Float64>>;\n-\n-    AggregateFunctionVarianceMatrixData() = default;\n-\n-    explicit AggregateFunctionVarianceMatrixData(const size_t _num_args)\n-        : num_args(_num_args)\n-    {\n-        data_matrix.resize_fill(num_args * (num_args + 1) / 2, DataType());\n-    }\n-\n-    void add(const IColumn ** column, const size_t row_num)\n-    {\n-        for (size_t i = 0; i < num_args; ++i)\n-            for (size_t j = 0; j <= i; ++j)\n-                 data_matrix[i * (i + 1) / 2 + j].add(column[i]->getFloat64(row_num), column[j]->getFloat64(row_num));\n-    }\n-\n-    void merge(const AggregateFunctionVarianceMatrixData & other)\n-    {\n-        for (size_t i = 0; i < num_args; ++i)\n-            for (size_t j = 0; j <= i; ++j)\n-                data_matrix[i * (i + 1) / 2 + j].merge(other.data_matrix[i * (i + 1) / 2 + j]);\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        for (size_t i = 0; i < num_args; ++i)\n-            for (size_t j = 0; j <= i; ++j)\n-                data_matrix[i * (i + 1) / 2 + j].write(buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        for (size_t i = 0; i < num_args; ++i)\n-            for (size_t j = 0; j <= i; ++j)\n-                data_matrix[i * (i + 1) / 2 + j].read(buf);\n-    }\n-\n-    void insertResultInto(IColumn & to) const\n-    {\n-        auto & data_to = assert_cast<ColumnFloat64 &>(assert_cast<ColumnArray &>(assert_cast<ColumnArray &>(to).getData()).getData()).getData();\n-        auto & root_offsets_to = assert_cast<ColumnArray &>(to).getOffsets();\n-        auto & nested_offsets_to = assert_cast<ColumnArray &>(assert_cast<ColumnArray &>(to).getData()).getOffsets();\n-        for (size_t i = 0; i < num_args; ++i)\n-        {\n-            for (size_t j = 0; j < num_args; ++j)\n-            {\n-                auto & data = i < j ? data_matrix[j * (j + 1) / 2 + i] : data_matrix[i * (i + 1) / 2 + j];\n-                if constexpr (kind == StatisticsMatrixFunctionKind::covarPopMatrix)\n-                    data_to.push_back(data.getPopulation());\n-                if constexpr (kind == StatisticsMatrixFunctionKind::covarSampMatrix)\n-                    data_to.push_back(data.getSample());\n-                if constexpr (kind == StatisticsMatrixFunctionKind::corrMatrix)\n-                    data_to.push_back(data.get());\n-            }\n-            nested_offsets_to.push_back(nested_offsets_to.back() + num_args);\n-        }\n-        root_offsets_to.push_back(root_offsets_to.back() + num_args);\n-    }\n-\n-    static constexpr StatisticsMatrixFunctionKind kind = _kind;\n-    PaddedPODArray<DataType> data_matrix;\n-    size_t num_args;\n-};\n-\n-template <typename Data>\n-class AggregateFunctionVarianceMatrix final\n-    : public IAggregateFunctionDataHelper<Data, AggregateFunctionVarianceMatrix<Data>>\n-{\n-public:\n-\n-    explicit AggregateFunctionVarianceMatrix(const DataTypes & argument_types_)\n-        : IAggregateFunctionDataHelper<Data, AggregateFunctionVarianceMatrix<Data>>(argument_types_, {}, createResultType())\n-    {}\n-\n-    AggregateFunctionVarianceMatrix(const IDataType &, const DataTypes & argument_types_)\n-        : IAggregateFunctionDataHelper<Data, AggregateFunctionVarianceMatrix<Data>>(argument_types_, {}, createResultType())\n-    {}\n-\n-    String getName() const override\n-    {\n-        if constexpr (Data::kind == StatisticsMatrixFunctionKind::covarPopMatrix)\n-            return \"covarPopMatrix\";\n-        if constexpr (Data::kind == StatisticsMatrixFunctionKind::covarSampMatrix)\n-            return \"covarSampMatrix\";\n-        if constexpr (Data::kind == StatisticsMatrixFunctionKind::corrMatrix)\n-            return \"corrMatrix\";\n-        UNREACHABLE();\n-    }\n-\n-    void create(AggregateDataPtr __restrict place) const override\n-    {\n-        new (place) Data(this->argument_types.size());\n-    }\n-\n-    static DataTypePtr createResultType()\n-    {\n-        return std::make_shared<DataTypeArray>(std::make_shared<DataTypeArray>(std::make_shared<DataTypeFloat64>()));\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena *) const override\n-    {\n-        this->data(place).add(columns, row_num);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena *) const override\n-    {\n-        this->data(place).deserialize(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        this->data(place).insertResultInto(to);\n-    }\n-};\n-\n-using AggregateFunctionCovarPopMatrix = AggregateFunctionVarianceMatrix<AggregateFunctionVarianceMatrixData<StatisticsMatrixFunctionKind::covarPopMatrix>>;\n-using AggregateFunctionCovarSampMatrix = AggregateFunctionVarianceMatrix<AggregateFunctionVarianceMatrixData<StatisticsMatrixFunctionKind::covarSampMatrix>>;\n-using AggregateFunctionCorrMatrix = AggregateFunctionVarianceMatrix<AggregateFunctionVarianceMatrixData<StatisticsMatrixFunctionKind::corrMatrix>>;\n-\n-}\n-\ndiff --git a/src/AggregateFunctions/AggregateFunctionWindowFunnel.cpp b/src/AggregateFunctions/AggregateFunctionWindowFunnel.cpp\nindex d80d683fd04b..f15d067a302b 100644\n--- a/src/AggregateFunctions/AggregateFunctionWindowFunnel.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionWindowFunnel.cpp\n@@ -1,13 +1,15 @@\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionWindowFunnel.h>\n-#include <AggregateFunctions/FactoryHelpers.h>\n #include <AggregateFunctions/Helpers.h>\n #include <Core/Settings.h>\n #include <DataTypes/DataTypeDate.h>\n-#include <DataTypes/DataTypeDate32.h>\n #include <DataTypes/DataTypeDateTime.h>\n \n-#include <base/range.h>\n+#include <unordered_set>\n+#include <Columns/ColumnsNumber.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+#include <Common/assert_cast.h>\n \n \n namespace DB\n@@ -18,11 +20,282 @@ namespace ErrorCodes\n {\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int TOO_LARGE_ARRAY_SIZE;\n+    extern const int BAD_ARGUMENTS;\n }\n \n namespace\n {\n \n+constexpr size_t max_events = 32;\n+\n+template <typename T>\n+struct AggregateFunctionWindowFunnelData\n+{\n+    using TimestampEvent = std::pair<T, UInt8>;\n+    using TimestampEvents = PODArrayWithStackMemory<TimestampEvent, 64>;\n+\n+    bool sorted = true;\n+    TimestampEvents events_list;\n+\n+    size_t size() const\n+    {\n+        return events_list.size();\n+    }\n+\n+    void add(T timestamp, UInt8 event)\n+    {\n+        /// Since most events should have already been sorted by timestamp.\n+        if (sorted && events_list.size() > 0)\n+        {\n+            if (events_list.back().first == timestamp)\n+                sorted = events_list.back().second <= event;\n+            else\n+                sorted = events_list.back().first <= timestamp;\n+        }\n+        events_list.emplace_back(timestamp, event);\n+    }\n+\n+    void merge(const AggregateFunctionWindowFunnelData & other)\n+    {\n+        if (other.events_list.empty())\n+            return;\n+\n+        const auto size = events_list.size();\n+\n+        events_list.insert(std::begin(other.events_list), std::end(other.events_list));\n+\n+        /// either sort whole container or do so partially merging ranges afterwards\n+        if (!sorted && !other.sorted)\n+            std::stable_sort(std::begin(events_list), std::end(events_list));\n+        else\n+        {\n+            const auto begin = std::begin(events_list);\n+            const auto middle = std::next(begin, size);\n+            const auto end = std::end(events_list);\n+\n+            if (!sorted)\n+                std::stable_sort(begin, middle);\n+\n+            if (!other.sorted)\n+                std::stable_sort(middle, end);\n+\n+            std::inplace_merge(begin, middle, end);\n+        }\n+\n+        sorted = true;\n+    }\n+\n+    void sort()\n+    {\n+        if (!sorted)\n+        {\n+            std::stable_sort(std::begin(events_list), std::end(events_list));\n+            sorted = true;\n+        }\n+    }\n+\n+    void serialize(WriteBuffer & buf) const\n+    {\n+        writeBinary(sorted, buf);\n+        writeBinary(events_list.size(), buf);\n+\n+        for (const auto & events : events_list)\n+        {\n+            writeBinary(events.first, buf);\n+            writeBinary(events.second, buf);\n+        }\n+    }\n+\n+    void deserialize(ReadBuffer & buf)\n+    {\n+        readBinary(sorted, buf);\n+\n+        size_t size;\n+        readBinary(size, buf);\n+\n+        if (size > 100'000'000) /// The constant is arbitrary\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE, \"Too large size of the state of windowFunnel\");\n+\n+        events_list.clear();\n+        events_list.reserve(size);\n+\n+        T timestamp;\n+        UInt8 event;\n+\n+        for (size_t i = 0; i < size; ++i)\n+        {\n+            readBinary(timestamp, buf);\n+            readBinary(event, buf);\n+            events_list.emplace_back(timestamp, event);\n+        }\n+    }\n+};\n+\n+/** Calculates the max event level in a sliding window.\n+  * The max size of events is 32, that's enough for funnel analytics\n+  *\n+  * Usage:\n+  * - windowFunnel(window)(timestamp, cond1, cond2, cond3, ....)\n+  */\n+template <typename T, typename Data>\n+class AggregateFunctionWindowFunnel final\n+    : public IAggregateFunctionDataHelper<Data, AggregateFunctionWindowFunnel<T, Data>>\n+{\n+private:\n+    UInt64 window;\n+    UInt8 events_size;\n+    /// When the 'strict_deduplication' is set, it applies conditions only for the not repeating values.\n+    bool strict_deduplication;\n+\n+    /// When the 'strict_order' is set, it doesn't allow interventions of other events.\n+    /// In the case of 'A->B->D->C', it stops finding 'A->B->C' at the 'D' and the max event level is 2.\n+    bool strict_order;\n+\n+    /// Applies conditions only to events with strictly increasing timestamps\n+    bool strict_increase;\n+\n+    /// Loop through the entire events_list, update the event timestamp value\n+    /// The level path must be 1---2---3---...---check_events_size, find the max event level that satisfied the path in the sliding window.\n+    /// If found, returns the max event level, else return 0.\n+    /// The algorithm works in O(n) time, but the overall function works in O(n * log(n)) due to sorting.\n+    UInt8 getEventLevel(Data & data) const\n+    {\n+        if (data.size() == 0)\n+            return 0;\n+        if (!strict_order && events_size == 1)\n+            return 1;\n+\n+        data.sort();\n+\n+        /// events_timestamp stores the timestamp of the first and previous i-th level event happen within time window\n+        std::vector<std::optional<std::pair<UInt64, UInt64>>> events_timestamp(events_size);\n+        bool first_event = false;\n+        for (size_t i = 0; i < data.events_list.size(); ++i)\n+        {\n+            const T & timestamp = data.events_list[i].first;\n+            const auto & event_idx = data.events_list[i].second - 1;\n+            if (strict_order && event_idx == -1)\n+            {\n+                if (first_event)\n+                    break;\n+                else\n+                    continue;\n+            }\n+            else if (event_idx == 0)\n+            {\n+                events_timestamp[0] = std::make_pair(timestamp, timestamp);\n+                first_event = true;\n+            }\n+            else if (strict_deduplication && events_timestamp[event_idx].has_value())\n+            {\n+                return data.events_list[i - 1].second;\n+            }\n+            else if (strict_order && first_event && !events_timestamp[event_idx - 1].has_value())\n+            {\n+                for (size_t event = 0; event < events_timestamp.size(); ++event)\n+                {\n+                    if (!events_timestamp[event].has_value())\n+                        return event;\n+                }\n+            }\n+            else if (events_timestamp[event_idx - 1].has_value())\n+            {\n+                auto first_timestamp = events_timestamp[event_idx - 1]->first;\n+                bool time_matched = timestamp <= first_timestamp + window;\n+                if (strict_increase)\n+                    time_matched = time_matched && events_timestamp[event_idx - 1]->second < timestamp;\n+                if (time_matched)\n+                {\n+                    events_timestamp[event_idx] = std::make_pair(first_timestamp, timestamp);\n+                    if (event_idx + 1 == events_size)\n+                        return events_size;\n+                }\n+            }\n+        }\n+\n+        for (size_t event = events_timestamp.size(); event > 0; --event)\n+        {\n+            if (events_timestamp[event - 1].has_value())\n+                return event;\n+        }\n+        return 0;\n+    }\n+\n+public:\n+    String getName() const override\n+    {\n+        return \"windowFunnel\";\n+    }\n+\n+    AggregateFunctionWindowFunnel(const DataTypes & arguments, const Array & params)\n+        : IAggregateFunctionDataHelper<Data, AggregateFunctionWindowFunnel<T, Data>>(arguments, params, std::make_shared<DataTypeUInt8>())\n+    {\n+        events_size = arguments.size() - 1;\n+        window = params.at(0).safeGet<UInt64>();\n+\n+        strict_deduplication = false;\n+        strict_order = false;\n+        strict_increase = false;\n+        for (size_t i = 1; i < params.size(); ++i)\n+        {\n+            String option = params.at(i).safeGet<String>();\n+            if (option == \"strict_deduplication\")\n+                strict_deduplication = true;\n+            else if (option == \"strict_order\")\n+                strict_order = true;\n+            else if (option == \"strict_increase\")\n+                strict_increase = true;\n+            else if (option == \"strict\")\n+                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"strict is replaced with strict_deduplication in Aggregate function {}\", getName());\n+            else\n+                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Aggregate function {} doesn't support a parameter: {}\", getName(), option);\n+        }\n+    }\n+\n+    bool allocatesMemoryInArena() const override { return false; }\n+\n+    void add(AggregateDataPtr __restrict place, const IColumn ** columns, const size_t row_num, Arena *) const override\n+    {\n+        bool has_event = false;\n+        const auto timestamp = assert_cast<const ColumnVector<T> *>(columns[0])->getData()[row_num];\n+        /// reverse iteration and stable sorting are needed for events that are qualified by more than one condition.\n+        for (auto i = events_size; i > 0; --i)\n+        {\n+            auto event = assert_cast<const ColumnVector<UInt8> *>(columns[i])->getData()[row_num];\n+            if (event)\n+            {\n+                this->data(place).add(timestamp, i);\n+                has_event = true;\n+            }\n+        }\n+\n+        if (strict_order && !has_event)\n+            this->data(place).add(timestamp, 0);\n+    }\n+\n+    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n+    {\n+        this->data(place).merge(this->data(rhs));\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        this->data(place).serialize(buf);\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version  */, Arena *) const override\n+    {\n+        this->data(place).deserialize(buf);\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        assert_cast<ColumnUInt8 &>(to).getData().push_back(getEventLevel(this->data(place)));\n+    }\n+};\n+\n+\n template <template <typename> class Data>\n AggregateFunctionPtr\n createAggregateFunctionWindowFunnel(const std::string & name, const DataTypes & arguments, const Array & params, const Settings *)\ndiff --git a/src/AggregateFunctions/AggregateFunctionWindowFunnel.h b/src/AggregateFunctions/AggregateFunctionWindowFunnel.h\ndeleted file mode 100644\nindex 8fee41b9f75c..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionWindowFunnel.h\n+++ /dev/null\n@@ -1,287 +0,0 @@\n-#pragma once\n-\n-#include <unordered_set>\n-#include <Columns/ColumnsNumber.h>\n-#include <DataTypes/DataTypeDateTime.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <Common/assert_cast.h>\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int BAD_ARGUMENTS;\n-}\n-\n-static constexpr size_t max_events = 32;\n-\n-template <typename T>\n-struct AggregateFunctionWindowFunnelData\n-{\n-    using TimestampEvent = std::pair<T, UInt8>;\n-    using TimestampEvents = PODArrayWithStackMemory<TimestampEvent, 64>;\n-\n-    bool sorted = true;\n-    TimestampEvents events_list;\n-\n-    size_t size() const\n-    {\n-        return events_list.size();\n-    }\n-\n-    void add(T timestamp, UInt8 event)\n-    {\n-        /// Since most events should have already been sorted by timestamp.\n-        if (sorted && events_list.size() > 0)\n-        {\n-            if (events_list.back().first == timestamp)\n-                sorted = events_list.back().second <= event;\n-            else\n-                sorted = events_list.back().first <= timestamp;\n-        }\n-        events_list.emplace_back(timestamp, event);\n-    }\n-\n-    void merge(const AggregateFunctionWindowFunnelData & other)\n-    {\n-        if (other.events_list.empty())\n-            return;\n-\n-        const auto size = events_list.size();\n-\n-        events_list.insert(std::begin(other.events_list), std::end(other.events_list));\n-\n-        /// either sort whole container or do so partially merging ranges afterwards\n-        if (!sorted && !other.sorted)\n-            std::stable_sort(std::begin(events_list), std::end(events_list));\n-        else\n-        {\n-            const auto begin = std::begin(events_list);\n-            const auto middle = std::next(begin, size);\n-            const auto end = std::end(events_list);\n-\n-            if (!sorted)\n-                std::stable_sort(begin, middle);\n-\n-            if (!other.sorted)\n-                std::stable_sort(middle, end);\n-\n-            std::inplace_merge(begin, middle, end);\n-        }\n-\n-        sorted = true;\n-    }\n-\n-    void sort()\n-    {\n-        if (!sorted)\n-        {\n-            std::stable_sort(std::begin(events_list), std::end(events_list));\n-            sorted = true;\n-        }\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        writeBinary(sorted, buf);\n-        writeBinary(events_list.size(), buf);\n-\n-        for (const auto & events : events_list)\n-        {\n-            writeBinary(events.first, buf);\n-            writeBinary(events.second, buf);\n-        }\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        readBinary(sorted, buf);\n-\n-        size_t size;\n-        readBinary(size, buf);\n-\n-        /// TODO Protection against huge size\n-\n-        events_list.clear();\n-        events_list.reserve(size);\n-\n-        T timestamp;\n-        UInt8 event;\n-\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            readBinary(timestamp, buf);\n-            readBinary(event, buf);\n-            events_list.emplace_back(timestamp, event);\n-        }\n-    }\n-};\n-\n-/** Calculates the max event level in a sliding window.\n-  * The max size of events is 32, that's enough for funnel analytics\n-  *\n-  * Usage:\n-  * - windowFunnel(window)(timestamp, cond1, cond2, cond3, ....)\n-  */\n-template <typename T, typename Data>\n-class AggregateFunctionWindowFunnel final\n-    : public IAggregateFunctionDataHelper<Data, AggregateFunctionWindowFunnel<T, Data>>\n-{\n-private:\n-    UInt64 window;\n-    UInt8 events_size;\n-    /// When the 'strict_deduplication' is set, it applies conditions only for the not repeating values.\n-    bool strict_deduplication;\n-\n-    /// When the 'strict_order' is set, it doesn't allow interventions of other events.\n-    /// In the case of 'A->B->D->C', it stops finding 'A->B->C' at the 'D' and the max event level is 2.\n-    bool strict_order;\n-\n-    /// Applies conditions only to events with strictly increasing timestamps\n-    bool strict_increase;\n-\n-    /// Loop through the entire events_list, update the event timestamp value\n-    /// The level path must be 1---2---3---...---check_events_size, find the max event level that satisfied the path in the sliding window.\n-    /// If found, returns the max event level, else return 0.\n-    /// The algorithm works in O(n) time, but the overall function works in O(n * log(n)) due to sorting.\n-    UInt8 getEventLevel(Data & data) const\n-    {\n-        if (data.size() == 0)\n-            return 0;\n-        if (!strict_order && events_size == 1)\n-            return 1;\n-\n-        data.sort();\n-\n-        /// events_timestamp stores the timestamp of the first and previous i-th level event happen within time window\n-        std::vector<std::optional<std::pair<UInt64, UInt64>>> events_timestamp(events_size);\n-        bool first_event = false;\n-        for (size_t i = 0; i < data.events_list.size(); ++i)\n-        {\n-            const T & timestamp = data.events_list[i].first;\n-            const auto & event_idx = data.events_list[i].second - 1;\n-            if (strict_order && event_idx == -1)\n-            {\n-                if (first_event)\n-                    break;\n-                else\n-                    continue;\n-            }\n-            else if (event_idx == 0)\n-            {\n-                events_timestamp[0] = std::make_pair(timestamp, timestamp);\n-                first_event = true;\n-            }\n-            else if (strict_deduplication && events_timestamp[event_idx].has_value())\n-            {\n-                return data.events_list[i - 1].second;\n-            }\n-            else if (strict_order && first_event && !events_timestamp[event_idx - 1].has_value())\n-            {\n-                for (size_t event = 0; event < events_timestamp.size(); ++event)\n-                {\n-                    if (!events_timestamp[event].has_value())\n-                        return event;\n-                }\n-            }\n-            else if (events_timestamp[event_idx - 1].has_value())\n-            {\n-                auto first_timestamp = events_timestamp[event_idx - 1]->first;\n-                bool time_matched = timestamp <= first_timestamp + window;\n-                if (strict_increase)\n-                    time_matched = time_matched && events_timestamp[event_idx - 1]->second < timestamp;\n-                if (time_matched)\n-                {\n-                    events_timestamp[event_idx] = std::make_pair(first_timestamp, timestamp);\n-                    if (event_idx + 1 == events_size)\n-                        return events_size;\n-                }\n-            }\n-        }\n-\n-        for (size_t event = events_timestamp.size(); event > 0; --event)\n-        {\n-            if (events_timestamp[event - 1].has_value())\n-                return event;\n-        }\n-        return 0;\n-    }\n-\n-public:\n-    String getName() const override\n-    {\n-        return \"windowFunnel\";\n-    }\n-\n-    AggregateFunctionWindowFunnel(const DataTypes & arguments, const Array & params)\n-        : IAggregateFunctionDataHelper<Data, AggregateFunctionWindowFunnel<T, Data>>(arguments, params, std::make_shared<DataTypeUInt8>())\n-    {\n-        events_size = arguments.size() - 1;\n-        window = params.at(0).safeGet<UInt64>();\n-\n-        strict_deduplication = false;\n-        strict_order = false;\n-        strict_increase = false;\n-        for (size_t i = 1; i < params.size(); ++i)\n-        {\n-            String option = params.at(i).safeGet<String>();\n-            if (option == \"strict_deduplication\")\n-                strict_deduplication = true;\n-            else if (option == \"strict_order\")\n-                strict_order = true;\n-            else if (option == \"strict_increase\")\n-                strict_increase = true;\n-            else if (option == \"strict\")\n-                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"strict is replaced with strict_deduplication in Aggregate function {}\", getName());\n-            else\n-                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Aggregate function {} doesn't support a parameter: {}\", getName(), option);\n-        }\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return false; }\n-\n-    void add(AggregateDataPtr __restrict place, const IColumn ** columns, const size_t row_num, Arena *) const override\n-    {\n-        bool has_event = false;\n-        const auto timestamp = assert_cast<const ColumnVector<T> *>(columns[0])->getData()[row_num];\n-        /// reverse iteration and stable sorting are needed for events that are qualified by more than one condition.\n-        for (auto i = events_size; i > 0; --i)\n-        {\n-            auto event = assert_cast<const ColumnVector<UInt8> *>(columns[i])->getData()[row_num];\n-            if (event)\n-            {\n-                this->data(place).add(timestamp, i);\n-                has_event = true;\n-            }\n-        }\n-\n-        if (strict_order && !has_event)\n-            this->data(place).add(timestamp, 0);\n-    }\n-\n-    void merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena *) const override\n-    {\n-        this->data(place).merge(this->data(rhs));\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        this->data(place).serialize(buf);\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version  */, Arena *) const override\n-    {\n-        this->data(place).deserialize(buf);\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        assert_cast<ColumnUInt8 &>(to).getData().push_back(getEventLevel(this->data(place)));\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/QuantileExactWeighted.h b/src/AggregateFunctions/QuantileExactWeighted.h\ndeleted file mode 100644\nindex c6a779ede61e..000000000000\n--- a/src/AggregateFunctions/QuantileExactWeighted.h\n+++ /dev/null\n@@ -1,203 +0,0 @@\n-#pragma once\n-\n-#include <base/sort.h>\n-\n-#include <Common/HashTable/HashMap.h>\n-#include <Common/NaNUtils.h>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int NOT_IMPLEMENTED;\n-}\n-\n-/** Calculates quantile by counting number of occurrences for each value in a hash map.\n-  *\n-  * It uses O(distinct(N)) memory. Can be naturally applied for values with weight.\n-  * In case of many identical values, it can be more efficient than QuantileExact even when weight is not used.\n-  */\n-template <typename Value>\n-struct QuantileExactWeighted\n-{\n-    struct Int128Hash\n-    {\n-        size_t operator()(Int128 x) const\n-        {\n-            return CityHash_v1_0_2::Hash128to64({x >> 64, x & 0xffffffffffffffffll});\n-        }\n-    };\n-\n-    using Weight = UInt64;\n-    using UnderlyingType = NativeType<Value>;\n-    using Hasher = HashCRC32<UnderlyingType>;\n-\n-    /// When creating, the hash table must be small.\n-    using Map = HashMapWithStackMemory<UnderlyingType, Weight, Hasher, 4>;\n-\n-    Map map;\n-\n-    void add(const Value & x)\n-    {\n-        /// We must skip NaNs as they are not compatible with comparison sorting.\n-        if (!isNaN(x))\n-            ++map[x];\n-    }\n-\n-    void add(const Value & x, Weight weight)\n-    {\n-        if (!isNaN(x))\n-            map[x] += weight;\n-    }\n-\n-    void merge(const QuantileExactWeighted & rhs)\n-    {\n-        for (const auto & pair : rhs.map)\n-            map[pair.getKey()] += pair.getMapped();\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        map.write(buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        typename Map::Reader reader(buf);\n-        while (reader.next())\n-        {\n-            const auto & pair = reader.get();\n-            map[pair.first] = pair.second;\n-        }\n-    }\n-\n-    /// Get the value of the `level` quantile. The level must be between 0 and 1.\n-    Value get(Float64 level) const\n-    {\n-        size_t size = map.size();\n-\n-        if (0 == size)\n-            return std::numeric_limits<Value>::quiet_NaN();\n-\n-        /// Copy the data to a temporary array to get the element you need in order.\n-        using Pair = typename Map::value_type;\n-        std::unique_ptr<Pair[]> array_holder(new Pair[size]);\n-        Pair * array = array_holder.get();\n-\n-        /// Note: 64-bit integer weight can overflow.\n-        /// We do some implementation specific behaviour (return approximate or garbage results).\n-        /// Float64 is used as accumulator here to get approximate results.\n-        /// But weight can be already overflowed in computations in 'add' and 'merge' methods.\n-        /// It will be reasonable to change the type of weight to Float64 in the map,\n-        /// but we don't do that for compatibility of serialized data.\n-\n-        size_t i = 0;\n-        Float64 sum_weight = 0;\n-        for (const auto & pair : map)\n-        {\n-            sum_weight += pair.getMapped();\n-            array[i] = pair.getValue();\n-            ++i;\n-        }\n-\n-        ::sort(array, array + size, [](const Pair & a, const Pair & b) { return a.first < b.first; });\n-\n-        Float64 threshold = std::ceil(sum_weight * level);\n-        Float64 accumulated = 0;\n-\n-        const Pair * it = array;\n-        const Pair * end = array + size;\n-        while (it < end)\n-        {\n-            accumulated += it->second;\n-\n-            if (accumulated >= threshold)\n-                break;\n-\n-            ++it;\n-        }\n-\n-        if (it == end)\n-            --it;\n-\n-        return it->first;\n-    }\n-\n-    /// Get the `size` values of `levels` quantiles. Write `size` results starting with `result` address.\n-    /// indices - an array of index levels such that the corresponding elements will go in ascending order.\n-    void getMany(const Float64 * levels, const size_t * indices, size_t num_levels, Value * result) const\n-    {\n-        size_t size = map.size();\n-\n-        if (0 == size)\n-        {\n-            for (size_t i = 0; i < num_levels; ++i)\n-                result[i] = Value();\n-            return;\n-        }\n-\n-        /// Copy the data to a temporary array to get the element you need in order.\n-        using Pair = typename Map::value_type;\n-        std::unique_ptr<Pair[]> array_holder(new Pair[size]);\n-        Pair * array = array_holder.get();\n-\n-        size_t i = 0;\n-        Float64 sum_weight = 0;\n-        for (const auto & pair : map)\n-        {\n-            sum_weight += pair.getMapped();\n-            array[i] = pair.getValue();\n-            ++i;\n-        }\n-\n-        ::sort(array, array + size, [](const Pair & a, const Pair & b) { return a.first < b.first; });\n-\n-        Float64 accumulated = 0;\n-\n-        const Pair * it = array;\n-        const Pair * end = array + size;\n-\n-        size_t level_index = 0;\n-        Float64 threshold = std::ceil(sum_weight * levels[indices[level_index]]);\n-\n-        while (it < end)\n-        {\n-            accumulated += it->second;\n-\n-            while (accumulated >= threshold)\n-            {\n-                result[indices[level_index]] = it->first;\n-                ++level_index;\n-\n-                if (level_index == num_levels)\n-                    return;\n-\n-                threshold = std::ceil(sum_weight * levels[indices[level_index]]);\n-            }\n-\n-            ++it;\n-        }\n-\n-        while (level_index < num_levels)\n-        {\n-            result[indices[level_index]] = array[size - 1].first;\n-            ++level_index;\n-        }\n-    }\n-\n-    /// The same, but in the case of an empty state, NaN is returned.\n-    Float64 getFloat(Float64) const\n-    {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getFloat is not implemented for QuantileExact\");\n-    }\n-\n-    void getManyFloat(const Float64 *, const size_t *, size_t, Float64 *) const\n-    {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getManyFloat is not implemented for QuantileExact\");\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/QuantileInterpolatedWeighted.h b/src/AggregateFunctions/QuantileInterpolatedWeighted.h\ndeleted file mode 100644\nindex 5b1eb315af3e..000000000000\n--- a/src/AggregateFunctions/QuantileInterpolatedWeighted.h\n+++ /dev/null\n@@ -1,308 +0,0 @@\n-#pragma once\n-\n-#include <base/sort.h>\n-\n-#include <Common/HashTable/HashMap.h>\n-#include <Common/NaNUtils.h>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int NOT_IMPLEMENTED;\n-}\n-\n-/** Approximates Quantile by:\n-  * - sorting input values and weights\n-  * - building a cumulative distribution based on weights\n-  * - performing linear interpolation between the weights and values\n-  *\n-  */\n-template <typename Value>\n-struct QuantileInterpolatedWeighted\n-{\n-    struct Int128Hash\n-    {\n-        size_t operator()(Int128 x) const\n-        {\n-            return CityHash_v1_0_2::Hash128to64({x >> 64, x & 0xffffffffffffffffll});\n-        }\n-    };\n-\n-    using Weight = UInt64;\n-    using UnderlyingType = NativeType<Value>;\n-    using Hasher = HashCRC32<UnderlyingType>;\n-\n-    /// When creating, the hash table must be small.\n-    using Map = HashMapWithStackMemory<UnderlyingType, Weight, Hasher, 4>;\n-\n-    Map map;\n-\n-    void add(const Value & x)\n-    {\n-        /// We must skip NaNs as they are not compatible with comparison sorting.\n-        if (!isNaN(x))\n-            ++map[x];\n-    }\n-\n-    void add(const Value & x, Weight weight)\n-    {\n-        if (!isNaN(x))\n-            map[x] += weight;\n-    }\n-\n-    void merge(const QuantileInterpolatedWeighted & rhs)\n-    {\n-        for (const auto & pair : rhs.map)\n-            map[pair.getKey()] += pair.getMapped();\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        map.write(buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        typename Map::Reader reader(buf);\n-        while (reader.next())\n-        {\n-            const auto & pair = reader.get();\n-            map[pair.first] = pair.second;\n-        }\n-    }\n-\n-    Value get(Float64 level) const\n-    {\n-        return getImpl<Value>(level);\n-    }\n-\n-    void getMany(const Float64 * levels, const size_t * indices, size_t size, Value * result) const\n-    {\n-        getManyImpl<Value>(levels, indices, size, result);\n-    }\n-\n-    /// The same, but in the case of an empty state, NaN is returned.\n-    Float64 getFloat(Float64) const\n-    {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getFloat is not implemented for QuantileInterpolatedWeighted\");\n-    }\n-\n-    void getManyFloat(const Float64 *, const size_t *, size_t, Float64 *) const\n-    {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method getManyFloat is not implemented for QuantileInterpolatedWeighted\");\n-    }\n-\n-private:\n-    using Pair = typename std::pair<UnderlyingType, Float64>;\n-\n-    /// Get the value of the `level` quantile. The level must be between 0 and 1.\n-    template <typename T>\n-    T getImpl(Float64 level) const\n-    {\n-        size_t size = map.size();\n-\n-        if (0 == size)\n-            return std::numeric_limits<Value>::quiet_NaN();\n-\n-        /// Maintain a vector of pair of values and weights for easier sorting and for building\n-        /// a cumulative distribution using the provided weights.\n-        std::vector<Pair> value_weight_pairs;\n-        value_weight_pairs.reserve(size);\n-\n-        /// Note: weight provided must be a 64-bit integer\n-        /// Float64 is used as accumulator here to get approximate results.\n-        /// But weight used in the internal array is stored as Float64 as we\n-        /// do some quantile estimation operation which involves division and\n-        /// require Float64 level of precision.\n-\n-        Float64 sum_weight = 0;\n-        for (const auto & pair : map)\n-        {\n-            sum_weight += pair.getMapped();\n-            auto value = pair.getKey();\n-            auto weight = pair.getMapped();\n-            value_weight_pairs.push_back({value, weight});\n-        }\n-\n-        ::sort(value_weight_pairs.begin(), value_weight_pairs.end(), [](const Pair & a, const Pair & b) { return a.first < b.first; });\n-\n-        Float64 accumulated = 0;\n-\n-        /// vector for populating and storing the cumulative sum using the provided weights.\n-        /// example: [0,1,2,3,4,5] -> [0,1,3,6,10,15]\n-        std::vector<Float64> weights_cum_sum;\n-        weights_cum_sum.reserve(size);\n-\n-        for (size_t idx = 0; idx < size; ++idx)\n-        {\n-            accumulated += value_weight_pairs[idx].second;\n-            weights_cum_sum.push_back(accumulated);\n-        }\n-\n-        /// The following estimation of quantile is general and the idea is:\n-        /// https://en.wikipedia.org/wiki/Percentile#The_weighted_percentile_method\n-\n-        /// calculates a simple cumulative distribution based on weights\n-        if (sum_weight != 0)\n-        {\n-            for (size_t idx = 0; idx < size; ++idx)\n-                value_weight_pairs[idx].second = (weights_cum_sum[idx] - 0.5 * value_weight_pairs[idx].second) / sum_weight;\n-        }\n-\n-        /// perform linear interpolation\n-        size_t idx = 0;\n-        if (size >= 2)\n-        {\n-            if (level >= value_weight_pairs[size - 2].second)\n-            {\n-                idx = size - 2;\n-            }\n-            else\n-            {\n-                size_t start = 0, end = size - 1;\n-                while (start <= end)\n-                {\n-                    size_t mid = start + (end - start) / 2;\n-                    if (mid > size)\n-                        break;\n-                    if (level > value_weight_pairs[mid + 1].second)\n-                        start = mid + 1;\n-                    else\n-                    {\n-                        idx = mid;\n-                        end = mid - 1;\n-                    }\n-                }\n-            }\n-        }\n-\n-        size_t l = idx;\n-        size_t u = idx + 1 < size ? idx + 1 : idx;\n-\n-        Float64 xl = value_weight_pairs[l].second, xr = value_weight_pairs[u].second;\n-        UnderlyingType yl = value_weight_pairs[l].first, yr = value_weight_pairs[u].first;\n-\n-        if (level < xl)\n-            yr = yl;\n-        if (level > xr)\n-            yl = yr;\n-\n-        return static_cast<T>(interpolate(level, xl, xr, yl, yr));\n-    }\n-\n-    /// Get the `size` values of `levels` quantiles. Write `size` results starting with `result` address.\n-    /// indices - an array of index levels such that the corresponding elements will go in ascending order.\n-    template <typename T>\n-    void getManyImpl(const Float64 * levels, const size_t * indices, size_t num_levels, Value * result) const\n-    {\n-        size_t size = map.size();\n-\n-        if (0 == size)\n-        {\n-            for (size_t i = 0; i < num_levels; ++i)\n-                result[i] = Value();\n-            return;\n-        }\n-\n-        std::vector<Pair> value_weight_pairs;\n-        value_weight_pairs.reserve(size);\n-\n-        Float64 sum_weight = 0;\n-        for (const auto & pair : map)\n-        {\n-            sum_weight += pair.getMapped();\n-            auto value = pair.getKey();\n-            auto weight = pair.getMapped();\n-            value_weight_pairs.push_back({value, weight});\n-        }\n-\n-        ::sort(value_weight_pairs.begin(), value_weight_pairs.end(), [](const Pair & a, const Pair & b) { return a.first < b.first; });\n-\n-        Float64 accumulated = 0;\n-\n-        /// vector for populating and storing the cumulative sum using the provided weights.\n-        /// example: [0,1,2,3,4,5] -> [0,1,3,6,10,15]\n-        std::vector<Float64> weights_cum_sum;\n-        weights_cum_sum.reserve(size);\n-\n-        for (size_t idx = 0; idx < size; ++idx)\n-        {\n-            accumulated += value_weight_pairs[idx].second;\n-            weights_cum_sum.emplace_back(accumulated);\n-        }\n-\n-\n-        /// The following estimation of quantile is general and the idea is:\n-        /// https://en.wikipedia.org/wiki/Percentile#The_weighted_percentile_method\n-\n-        /// calculates a simple cumulative distribution based on weights\n-        if (sum_weight != 0)\n-        {\n-            for (size_t idx = 0; idx < size; ++idx)\n-                value_weight_pairs[idx].second = (weights_cum_sum[idx] - 0.5 * value_weight_pairs[idx].second) / sum_weight;\n-        }\n-\n-        for (size_t level_index = 0; level_index < num_levels; ++level_index)\n-        {\n-            /// perform linear interpolation for every level\n-            auto level = levels[indices[level_index]];\n-\n-            size_t idx = 0;\n-            if (size >= 2)\n-            {\n-                if (level >= value_weight_pairs[size - 2].second)\n-                {\n-                    idx = size - 2;\n-                }\n-                else\n-                {\n-                    size_t start = 0, end = size - 1;\n-                    while (start <= end)\n-                    {\n-                        size_t mid = start + (end - start) / 2;\n-                        if (mid > size)\n-                            break;\n-                        if (level > value_weight_pairs[mid + 1].second)\n-                            start = mid + 1;\n-                        else\n-                        {\n-                            idx = mid;\n-                            end = mid - 1;\n-                        }\n-                    }\n-                }\n-            }\n-\n-            size_t l = idx;\n-            size_t u = idx + 1 < size ? idx + 1 : idx;\n-\n-            Float64 xl = value_weight_pairs[l].second, xr = value_weight_pairs[u].second;\n-            UnderlyingType yl = value_weight_pairs[l].first, yr = value_weight_pairs[u].first;\n-\n-            if (level < xl)\n-                yr = yl;\n-            if (level > xr)\n-                yl = yr;\n-\n-            result[indices[level_index]] = static_cast<T>(interpolate(level, xl, xr, yl, yr));\n-        }\n-    }\n-\n-    /// This ignores overflows or NaN's that might arise during add, sub and mul operations and doesn't aim to provide exact\n-    /// results since `the quantileInterpolatedWeighted` function itself relies mainly on approximation.\n-    UnderlyingType NO_SANITIZE_UNDEFINED interpolate(Float64 level, Float64 xl, Float64 xr, UnderlyingType yl, UnderlyingType yr) const\n-    {\n-        UnderlyingType dy = yr - yl;\n-        Float64 dx = xr - xl;\n-        dx = dx == 0 ? 1 : dx; /// to handle NaN behavior that might arise during integer division below.\n-\n-        /// yl + (dy / dx) * (level - xl)\n-        return static_cast<UnderlyingType>(yl + (dy / dx) * (level - xl));\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/QuantileReservoirSampler.h b/src/AggregateFunctions/QuantileReservoirSampler.h\ndeleted file mode 100644\nindex a19064fbbafc..000000000000\n--- a/src/AggregateFunctions/QuantileReservoirSampler.h\n+++ /dev/null\n@@ -1,102 +0,0 @@\n-#pragma once\n-\n-#include <AggregateFunctions/ReservoirSampler.h>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int NOT_IMPLEMENTED;\n-}\n-\n-/** Quantile calculation with \"reservoir sample\" algorithm.\n-  * It collects pseudorandom subset of limited size from a stream of values,\n-  *  and approximate quantile from it.\n-  * The result is non-deterministic. Also look at QuantileReservoirSamplerDeterministic.\n-  *\n-  * This algorithm is quite inefficient in terms of precision for memory usage,\n-  *  but very efficient in CPU (though less efficient than QuantileTiming and than QuantileExact for small sets).\n-  */\n-template <typename Value>\n-struct QuantileReservoirSampler\n-{\n-    using Data = ReservoirSampler<Value, ReservoirSamplerOnEmpty::RETURN_NAN_OR_ZERO>;\n-    Data data;\n-\n-    void add(const Value & x)\n-    {\n-        data.insert(x);\n-    }\n-\n-    template <typename Weight>\n-    void add(const Value &, const Weight &)\n-    {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method add with weight is not implemented for ReservoirSampler\");\n-    }\n-\n-    void merge(const QuantileReservoirSampler & rhs)\n-    {\n-        data.merge(rhs.data);\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        data.write(buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        data.read(buf);\n-    }\n-\n-    /// Get the value of the `level` quantile. The level must be between 0 and 1.\n-    Value get(Float64 level)\n-    {\n-        if (data.empty())\n-            return {};\n-\n-        if constexpr (is_decimal<Value>)\n-            return Value(static_cast<typename Value::NativeType>(data.quantileInterpolated(level)));\n-        else\n-            return static_cast<Value>(data.quantileInterpolated(level));\n-    }\n-\n-    /// Get the `size` values of `levels` quantiles. Write `size` results starting with `result` address.\n-    /// indices - an array of index levels such that the corresponding elements will go in ascending order.\n-    void getMany(const Float64 * levels, const size_t * indices, size_t size, Value * result)\n-    {\n-        bool is_empty = data.empty();\n-\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            if (is_empty)\n-            {\n-                result[i] = Value{};\n-            }\n-            else\n-            {\n-                if constexpr (is_decimal<Value>)\n-                    result[indices[i]] = Value(static_cast<typename Value::NativeType>(data.quantileInterpolated(levels[indices[i]])));\n-                else\n-                    result[indices[i]] = Value(data.quantileInterpolated(levels[indices[i]]));\n-            }\n-        }\n-    }\n-\n-    /// The same, but in the case of an empty state, NaN is returned.\n-    Float64 getFloat(Float64 level)\n-    {\n-        return data.quantileInterpolated(level);\n-    }\n-\n-    void getManyFloat(const Float64 * levels, const size_t * indices, size_t size, Float64 * result)\n-    {\n-        for (size_t i = 0; i < size; ++i)\n-            result[indices[i]] = data.quantileInterpolated(levels[indices[i]]);\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/QuantileReservoirSamplerDeterministic.h b/src/AggregateFunctions/QuantileReservoirSamplerDeterministic.h\ndeleted file mode 100644\nindex 41f9f557834c..000000000000\n--- a/src/AggregateFunctions/QuantileReservoirSamplerDeterministic.h\n+++ /dev/null\n@@ -1,102 +0,0 @@\n-#pragma once\n-\n-#include <AggregateFunctions/ReservoirSamplerDeterministic.h>\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int NOT_IMPLEMENTED;\n-}\n-\n-/** Quantile calculation with \"reservoir sample\" algorithm.\n-  * It collects pseudorandom subset of limited size from a stream of values,\n-  *  and approximate quantile from it.\n-  * The function accept second argument, named \"determinator\"\n-  *  and a hash function from it is calculated and used as a source for randomness\n-  *  to apply random sampling.\n-  * The function is deterministic, but care should be taken with choose of \"determinator\" argument.\n-  */\n-template <typename Value>\n-struct QuantileReservoirSamplerDeterministic\n-{\n-    using Data = ReservoirSamplerDeterministic<Value, ReservoirSamplerDeterministicOnEmpty::RETURN_NAN_OR_ZERO>;\n-    Data data;\n-\n-    void add(const Value &)\n-    {\n-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Method add without determinator is not implemented for ReservoirSamplerDeterministic\");\n-    }\n-\n-    template <typename Determinator>\n-    void add(const Value & x, const Determinator & determinator)\n-    {\n-        data.insert(x, determinator);\n-    }\n-\n-    void merge(const QuantileReservoirSamplerDeterministic & rhs)\n-    {\n-        data.merge(rhs.data);\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        data.write(buf);\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        data.read(buf);\n-    }\n-\n-    /// Get the value of the `level` quantile. The level must be between 0 and 1.\n-    Value get(Float64 level)\n-    {\n-        if (data.empty())\n-            return {};\n-\n-        if constexpr (is_decimal<Value>)\n-            return static_cast<typename Value::NativeType>(data.quantileInterpolated(level));\n-        else\n-            return static_cast<Value>(data.quantileInterpolated(level));\n-    }\n-\n-    /// Get the `size` values of `levels` quantiles. Write `size` results starting with `result` address.\n-    /// indices - an array of index levels such that the corresponding elements will go in ascending order.\n-    void getMany(const Float64 * levels, const size_t * indices, size_t size, Value * result)\n-    {\n-        bool is_empty = data.empty();\n-\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            if (is_empty)\n-            {\n-                result[i] = Value{};\n-            }\n-            else\n-            {\n-                if constexpr (is_decimal<Value>)\n-                    result[indices[i]] = static_cast<typename Value::NativeType>(data.quantileInterpolated(levels[indices[i]]));\n-                else\n-                    result[indices[i]] = static_cast<Value>(data.quantileInterpolated(levels[indices[i]]));\n-            }\n-        }\n-    }\n-\n-    /// The same, but in the case of an empty state, NaN is returned.\n-    Float64 getFloat(Float64 level)\n-    {\n-        return data.quantileInterpolated(level);\n-    }\n-\n-    void getManyFloat(const Float64 * levels, const size_t * indices, size_t size, Float64 * result)\n-    {\n-        for (size_t i = 0; i < size; ++i)\n-            result[indices[i]] = data.quantileInterpolated(levels[indices[i]]);\n-    }\n-};\n-\n-}\ndiff --git a/src/AggregateFunctions/ReservoirSampler.h b/src/AggregateFunctions/ReservoirSampler.h\nindex 7409a3fa0dd6..37fc05a2e4ce 100644\n--- a/src/AggregateFunctions/ReservoirSampler.h\n+++ b/src/AggregateFunctions/ReservoirSampler.h\n@@ -255,11 +255,11 @@ class ReservoirSampler\n \n     UInt64 genRandom(UInt64 limit)\n     {\n-        assert(limit > 0);\n+        chassert(limit > 0);\n \n         /// With a large number of values, we will generate random numbers several times slower.\n         if (limit <= static_cast<UInt64>(rng.max()))\n-            return static_cast<UInt32>(rng()) % static_cast<UInt32>(limit);\n+            return rng() % limit;\n         else\n             return (static_cast<UInt64>(rng()) * (static_cast<UInt64>(rng.max()) + 1ULL) + static_cast<UInt64>(rng())) % limit;\n     }\ndiff --git a/src/Common/HashTable/HashTable.h b/src/Common/HashTable/HashTable.h\nindex f6cec1ce6a91..f23c4ca15ddb 100644\n--- a/src/Common/HashTable/HashTable.h\n+++ b/src/Common/HashTable/HashTable.h\n@@ -853,7 +853,7 @@ class HashTable : private boost::noncopyable,\n \n     private:\n         DB::ReadBuffer & in;\n-        Cell cell;\n+        Cell cell{};\n         size_t read_count = 0;\n         size_t size = 0;\n         bool is_eof = false;\ndiff --git a/src/Common/HyperLogLogCounter.h b/src/Common/HyperLogLogCounter.h\nindex bda56a38c51e..092ed6f3d805 100644\n--- a/src/Common/HyperLogLogCounter.h\n+++ b/src/Common/HyperLogLogCounter.h\n@@ -4,7 +4,7 @@\n #include <Common/HyperLogLogBiasEstimator.h>\n #include <Common/CompactArray.h>\n #include <Common/HashTable/Hash.h>\n-#include <Common/TransformEndianness.hpp>\n+#include <Common/transformEndianness.h>\n \n #include <IO/ReadBuffer.h>\n #include <IO/WriteBuffer.h>\ndiff --git a/src/Common/SipHash.h b/src/Common/SipHash.h\nindex 22cff7a49428..5f27fdaa4b69 100644\n--- a/src/Common/SipHash.h\n+++ b/src/Common/SipHash.h\n@@ -13,8 +13,6 @@\n   * (~ 700 MB/sec, 15 million strings per second)\n   */\n \n-#include \"TransformEndianness.hpp\"\n-\n #include <bit>\n #include <string>\n #include <type_traits>\n@@ -24,9 +22,11 @@\n #include <base/unaligned.h>\n #include <base/hex.h>\n #include <Common/Exception.h>\n+#include <Common/transformEndianness.h>\n \n #include <city.h>\n \n+\n namespace DB::ErrorCodes\n {\n     extern const int LOGICAL_ERROR;\ndiff --git a/src/Common/TransformEndianness.hpp b/src/Common/transformEndianness.h\nsimilarity index 100%\nrename from src/Common/TransformEndianness.hpp\nrename to src/Common/transformEndianness.h\ndiff --git a/src/Core/callOnTypeIndex.h b/src/Core/callOnTypeIndex.h\nindex 39ce37c4c139..f5f67df563be 100644\n--- a/src/Core/callOnTypeIndex.h\n+++ b/src/Core/callOnTypeIndex.h\n@@ -4,6 +4,7 @@\n \n #include <Core/Types.h>\n \n+\n namespace DB\n {\n \n@@ -16,7 +17,7 @@ struct TypePair\n \n \n template <typename T, bool _int, bool _float, bool _decimal, bool _datetime, typename F>\n-bool callOnBasicType(TypeIndex number, F && f)\n+static bool callOnBasicType(TypeIndex number, F && f)\n {\n     if constexpr (_int)\n     {\n@@ -86,7 +87,7 @@ bool callOnBasicType(TypeIndex number, F && f)\n \n /// Unroll template using TypeIndex\n template <bool _int, bool _float, bool _decimal, bool _datetime, typename F>\n-inline bool callOnBasicTypes(TypeIndex type_num1, TypeIndex type_num2, F && f)\n+static inline bool callOnBasicTypes(TypeIndex type_num1, TypeIndex type_num2, F && f)\n {\n     if constexpr (_int)\n     {\n@@ -170,7 +171,7 @@ template <is_decimal T> class DataTypeDecimal;\n \n \n template <typename T, typename F, typename... ExtraArgs>\n-bool callOnIndexAndDataType(TypeIndex number, F && f, ExtraArgs && ... args)\n+static bool callOnIndexAndDataType(TypeIndex number, F && f, ExtraArgs && ... args)\n {\n     switch (number)\n     {\ndiff --git a/src/Functions/FunctionJoinGet.cpp b/src/Functions/FunctionJoinGet.cpp\nindex 00bc3d8142a4..5602c88c60eb 100644\n--- a/src/Functions/FunctionJoinGet.cpp\n+++ b/src/Functions/FunctionJoinGet.cpp\n@@ -1,21 +1,119 @@\n-#include <Functions/FunctionJoinGet.h>\n-\n #include <Columns/ColumnString.h>\n #include <Functions/FunctionFactory.h>\n #include <Functions/FunctionHelpers.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/HashJoin.h>\n+#include <Functions/IFunction.h>\n #include <Storages/StorageJoin.h>\n+#include <Storages/TableLockHolder.h>\n+#include <Core/Block.h>\n \n \n namespace DB\n {\n+\n namespace ErrorCodes\n {\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n }\n \n+class HashJoin;\n+using StorageJoinPtr = std::shared_ptr<StorageJoin>;\n+\n+namespace\n+{\n+\n+template <bool or_null>\n+class ExecutableFunctionJoinGet final : public IExecutableFunction, WithContext\n+{\n+public:\n+    ExecutableFunctionJoinGet(ContextPtr context_,\n+                              TableLockHolder table_lock_,\n+                              StorageJoinPtr storage_join_,\n+                              const DB::Block & result_columns_)\n+        : WithContext(context_)\n+        , table_lock(std::move(table_lock_))\n+        , storage_join(std::move(storage_join_))\n+        , result_columns(result_columns_)\n+    {}\n+\n+    static constexpr auto name = or_null ? \"joinGetOrNull\" : \"joinGet\";\n+\n+    bool useDefaultImplementationForNulls() const override { return false; }\n+    bool useDefaultImplementationForLowCardinalityColumns() const override { return false; }\n+    bool useDefaultImplementationForConstants() const override { return true; }\n+\n+    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override;\n+\n+    String getName() const override { return name; }\n+\n+private:\n+    TableLockHolder table_lock;\n+    StorageJoinPtr storage_join;\n+    DB::Block result_columns;\n+};\n+\n+template <bool or_null>\n+class FunctionJoinGet final : public IFunctionBase, WithContext\n+{\n+public:\n+    static constexpr auto name = or_null ? \"joinGetOrNull\" : \"joinGet\";\n+\n+    FunctionJoinGet(ContextPtr context_,\n+                    TableLockHolder table_lock_,\n+                    StorageJoinPtr storage_join_, String attr_name_,\n+                    DataTypes argument_types_, DataTypePtr return_type_)\n+        : WithContext(context_)\n+        , table_lock(std::move(table_lock_))\n+        , storage_join(storage_join_)\n+        , attr_name(std::move(attr_name_))\n+        , argument_types(std::move(argument_types_))\n+        , return_type(std::move(return_type_))\n+    {\n+    }\n+\n+    String getName() const override { return name; }\n+\n+    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n+\n+    const DataTypes & getArgumentTypes() const override { return argument_types; }\n+    const DataTypePtr & getResultType() const override { return return_type; }\n+\n+    ExecutableFunctionPtr prepare(const ColumnsWithTypeAndName &) const override;\n+\n+private:\n+    TableLockHolder table_lock;\n+    StorageJoinPtr storage_join;\n+    const String attr_name;\n+    DataTypes argument_types;\n+    DataTypePtr return_type;\n+};\n+\n+template <bool or_null>\n+class JoinGetOverloadResolver final : public IFunctionOverloadResolver, WithContext\n+{\n+public:\n+    static constexpr auto name = or_null ? \"joinGetOrNull\" : \"joinGet\";\n+    static FunctionOverloadResolverPtr create(ContextPtr context_) { return std::make_unique<JoinGetOverloadResolver>(context_); }\n+\n+    explicit JoinGetOverloadResolver(ContextPtr context_) : WithContext(context_) {}\n+\n+    bool isDeterministic() const override { return false; }\n+    String getName() const override { return name; }\n+\n+    FunctionBasePtr buildImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &) const override;\n+    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName &) const override { return {}; } // Not used\n+\n+    bool useDefaultImplementationForNulls() const override { return false; }\n+    bool useDefaultImplementationForLowCardinalityColumns() const override { return false; }\n+\n+    bool isVariadic() const override { return true; }\n+    size_t getNumberOfArguments() const override { return 0; }\n+    ColumnNumbers getArgumentsThatAreAlwaysConstant() const override { return {0, 1}; }\n+};\n+\n+\n template <bool or_null>\n ColumnPtr ExecutableFunctionJoinGet<or_null>::executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t) const\n {\n@@ -35,7 +133,7 @@ ExecutableFunctionPtr FunctionJoinGet<or_null>::prepare(const ColumnsWithTypeAnd\n     return std::make_unique<ExecutableFunctionJoinGet<or_null>>(getContext(), table_lock, storage_join, result_columns);\n }\n \n-static std::pair<std::shared_ptr<StorageJoin>, String>\n+std::pair<std::shared_ptr<StorageJoin>, String>\n getJoin(const ColumnsWithTypeAndName & arguments, ContextPtr context)\n {\n     String join_name;\n@@ -96,6 +194,8 @@ FunctionBasePtr JoinGetOverloadResolver<or_null>::buildImpl(const ColumnsWithTyp\n     return std::make_unique<FunctionJoinGet<or_null>>(getContext(), table_lock, storage_join, attr_name, argument_types, return_type);\n }\n \n+}\n+\n REGISTER_FUNCTION(JoinGet)\n {\n     // joinGet\n@@ -104,10 +204,4 @@ REGISTER_FUNCTION(JoinGet)\n     factory.registerFunction<JoinGetOverloadResolver<true>>();\n }\n \n-template class ExecutableFunctionJoinGet<true>;\n-template class ExecutableFunctionJoinGet<false>;\n-template class FunctionJoinGet<true>;\n-template class FunctionJoinGet<false>;\n-template class JoinGetOverloadResolver<true>;\n-template class JoinGetOverloadResolver<false>;\n }\ndiff --git a/src/Functions/FunctionJoinGet.h b/src/Functions/FunctionJoinGet.h\ndeleted file mode 100644\nindex 998a892f3df4..000000000000\n--- a/src/Functions/FunctionJoinGet.h\n+++ /dev/null\n@@ -1,105 +0,0 @@\n-#pragma once\n-\n-#include <Functions/IFunction.h>\n-#include <Interpreters/Context_fwd.h>\n-#include <Storages/IStorage_fwd.h>\n-#include <Storages/TableLockHolder.h>\n-#include <Core/Block.h>\n-\n-namespace DB\n-{\n-\n-class HashJoin;\n-class StorageJoin;\n-using StorageJoinPtr = std::shared_ptr<StorageJoin>;\n-\n-template <bool or_null>\n-class ExecutableFunctionJoinGet final : public IExecutableFunction, WithContext\n-{\n-public:\n-    ExecutableFunctionJoinGet(ContextPtr context_,\n-                              TableLockHolder table_lock_,\n-                              StorageJoinPtr storage_join_,\n-                              const DB::Block & result_columns_)\n-        : WithContext(context_)\n-        , table_lock(std::move(table_lock_))\n-        , storage_join(std::move(storage_join_))\n-        , result_columns(result_columns_)\n-    {}\n-\n-    static constexpr auto name = or_null ? \"joinGetOrNull\" : \"joinGet\";\n-\n-    bool useDefaultImplementationForNulls() const override { return false; }\n-    bool useDefaultImplementationForLowCardinalityColumns() const override { return false; }\n-    bool useDefaultImplementationForConstants() const override { return true; }\n-\n-    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override;\n-\n-    String getName() const override { return name; }\n-\n-private:\n-    TableLockHolder table_lock;\n-    StorageJoinPtr storage_join;\n-    DB::Block result_columns;\n-};\n-\n-template <bool or_null>\n-class FunctionJoinGet final : public IFunctionBase, WithContext\n-{\n-public:\n-    static constexpr auto name = or_null ? \"joinGetOrNull\" : \"joinGet\";\n-\n-    FunctionJoinGet(ContextPtr context_,\n-                    TableLockHolder table_lock_,\n-                    StorageJoinPtr storage_join_, String attr_name_,\n-                    DataTypes argument_types_, DataTypePtr return_type_)\n-        : WithContext(context_)\n-        , table_lock(std::move(table_lock_))\n-        , storage_join(storage_join_)\n-        , attr_name(std::move(attr_name_))\n-        , argument_types(std::move(argument_types_))\n-        , return_type(std::move(return_type_))\n-    {\n-    }\n-\n-    String getName() const override { return name; }\n-\n-    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n-\n-    const DataTypes & getArgumentTypes() const override { return argument_types; }\n-    const DataTypePtr & getResultType() const override { return return_type; }\n-\n-    ExecutableFunctionPtr prepare(const ColumnsWithTypeAndName &) const override;\n-\n-private:\n-    TableLockHolder table_lock;\n-    StorageJoinPtr storage_join;\n-    const String attr_name;\n-    DataTypes argument_types;\n-    DataTypePtr return_type;\n-};\n-\n-template <bool or_null>\n-class JoinGetOverloadResolver final : public IFunctionOverloadResolver, WithContext\n-{\n-public:\n-    static constexpr auto name = or_null ? \"joinGetOrNull\" : \"joinGet\";\n-    static FunctionOverloadResolverPtr create(ContextPtr context_) { return std::make_unique<JoinGetOverloadResolver>(context_); }\n-\n-    explicit JoinGetOverloadResolver(ContextPtr context_) : WithContext(context_) {}\n-\n-    bool isDeterministic() const override { return false; }\n-    String getName() const override { return name; }\n-\n-    FunctionBasePtr buildImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &) const override;\n-    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName &) const override { return {}; } // Not used\n-\n-    bool useDefaultImplementationForNulls() const override { return false; }\n-    bool useDefaultImplementationForLowCardinalityColumns() const override { return false; }\n-\n-    bool isVariadic() const override { return true; }\n-    size_t getNumberOfArguments() const override { return 0; }\n-    ColumnNumbers getArgumentsThatAreAlwaysConstant() const override { return {0, 1}; }\n-};\n-\n-}\ndiff --git a/src/Functions/FunctionSnowflake.h b/src/Functions/FunctionSnowflake.h\ndeleted file mode 100644\nindex 26c8138633ba..000000000000\n--- a/src/Functions/FunctionSnowflake.h\n+++ /dev/null\n@@ -1,247 +0,0 @@\n-#pragma once\n-\n-#include <Functions/extractTimeZoneFromFunctionArguments.h>\n-#include <Functions/IFunction.h>\n-#include <Functions/FunctionHelpers.h>\n-#include <DataTypes/DataTypeDateTime64.h>\n-#include <DataTypes/DataTypesDecimal.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <Columns/ColumnConst.h>\n-#include <Columns/ColumnsDateTime.h>\n-#include <Columns/ColumnsNumber.h>\n-#include <Core/DecimalFunctions.h>\n-#include <Interpreters/Context.h>\n-\n-#include <base/arithmeticOverflow.h>\n-\n-\n-namespace DB\n-{\n-namespace ErrorCodes\n-{\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-}\n-\n-/** According to Twitter's post on Snowflake, we can extract the timestamp for a snowflake ID by right shifting\n- * the snowflake ID by 22 bits(10 bits machine ID and 12 bits sequence ID) and adding the Twitter epoch time of 1288834974657.\n- * https://en.wikipedia.org/wiki/Snowflake_ID\n- * https://blog.twitter.com/engineering/en_us/a/2010/announcing-snowflake\n- * https://ws-dl.blogspot.com/2019/08/2019-08-03-tweetedat-finding-tweet.html\n-*/\n-static constexpr size_t snowflake_epoch = 1288834974657L;\n-static constexpr int time_shift = 22;\n-\n-class FunctionDateTimeToSnowflake : public IFunction\n-{\n-private:\n-    const char * name;\n-\n-public:\n-    explicit FunctionDateTimeToSnowflake(const char * name_) : name(name_) { }\n-\n-    String getName() const override { return name; }\n-    size_t getNumberOfArguments() const override { return 1; }\n-    bool useDefaultImplementationForConstants() const override { return true; }\n-    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n-\n-    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override\n-    {\n-        FunctionArgumentDescriptors args{\n-            {\"value\", &isDateTime<IDataType>, nullptr, \"DateTime\"}\n-        };\n-        validateFunctionArgumentTypes(*this, arguments, args);\n-\n-        return std::make_shared<DataTypeInt64>();\n-    }\n-\n-    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override\n-    {\n-        const auto & src = arguments[0];\n-        const auto & src_column = *src.column;\n-\n-        auto res_column = ColumnInt64::create(input_rows_count);\n-        auto & res_data = res_column->getData();\n-\n-        const auto & src_data = typeid_cast<const ColumnUInt32 &>(src_column).getData();\n-        for (size_t i = 0; i < input_rows_count; ++i)\n-            res_data[i] = (Int64(src_data[i]) * 1000 - snowflake_epoch) << time_shift;\n-\n-        return res_column;\n-    }\n-};\n-\n-class FunctionSnowflakeToDateTime : public IFunction\n-{\n-private:\n-    const char * name;\n-    const bool allow_nonconst_timezone_arguments;\n-\n-public:\n-    explicit FunctionSnowflakeToDateTime(const char * name_, ContextPtr context)\n-        : name(name_)\n-        , allow_nonconst_timezone_arguments(context->getSettings().allow_nonconst_timezone_arguments)\n-    {}\n-\n-    String getName() const override { return name; }\n-    size_t getNumberOfArguments() const override { return 0; }\n-    bool isVariadic() const override { return true; }\n-    bool useDefaultImplementationForConstants() const override { return true; }\n-    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n-\n-    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override\n-    {\n-        FunctionArgumentDescriptors mandatory_args{\n-            {\"value\", &isInt64<IDataType>, nullptr, \"Int64\"}\n-        };\n-        FunctionArgumentDescriptors optional_args{\n-            {\"time_zone\", &isString<IDataType>, nullptr, \"String\"}\n-        };\n-        validateFunctionArgumentTypes(*this, arguments, mandatory_args, optional_args);\n-\n-        String timezone;\n-        if (arguments.size() == 2)\n-            timezone = extractTimeZoneNameFromFunctionArguments(arguments, 1, 0, allow_nonconst_timezone_arguments);\n-\n-        return std::make_shared<DataTypeDateTime>(timezone);\n-    }\n-\n-    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override\n-    {\n-        const auto & src = arguments[0];\n-        const auto & src_column = *src.column;\n-\n-        auto res_column = ColumnUInt32::create(input_rows_count);\n-        auto & res_data = res_column->getData();\n-\n-        if (const auto * src_column_non_const = typeid_cast<const ColumnInt64 *>(&src_column))\n-        {\n-            const auto & src_data = src_column_non_const->getData();\n-            for (size_t i = 0; i < input_rows_count; ++i)\n-                res_data[i] = static_cast<UInt32>(\n-                    ((src_data[i] >> time_shift) + snowflake_epoch) / 1000);\n-        }\n-        else if (const auto * src_column_const = typeid_cast<const ColumnConst *>(&src_column))\n-        {\n-            Int64 src_val = src_column_const->getValue<Int64>();\n-            for (size_t i = 0; i < input_rows_count; ++i)\n-                res_data[i] = static_cast<UInt32>(\n-                    ((src_val >> time_shift) + snowflake_epoch) / 1000);\n-        }\n-        else\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal argument for function {}\", name);\n-\n-        return res_column;\n-    }\n-};\n-\n-\n-class FunctionDateTime64ToSnowflake : public IFunction\n-{\n-private:\n-    const char * name;\n-\n-public:\n-    explicit FunctionDateTime64ToSnowflake(const char * name_) : name(name_) { }\n-\n-    String getName() const override { return name; }\n-    size_t getNumberOfArguments() const override { return 1; }\n-    bool useDefaultImplementationForConstants() const override { return true; }\n-    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n-\n-    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override\n-    {\n-        FunctionArgumentDescriptors args{\n-            {\"value\", &isDateTime64<IDataType>, nullptr, \"DateTime64\"}\n-        };\n-        validateFunctionArgumentTypes(*this, arguments, args);\n-\n-        return std::make_shared<DataTypeInt64>();\n-    }\n-\n-    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override\n-    {\n-        const auto & src = arguments[0];\n-\n-        const auto & src_column = *src.column;\n-        auto res_column = ColumnInt64::create(input_rows_count);\n-        auto & res_data = res_column->getData();\n-\n-        const auto & src_data = typeid_cast<const ColumnDecimal<DateTime64> &>(src_column).getData();\n-\n-        /// timestamps in snowflake-ids are millisecond-based, convert input to milliseconds\n-        UInt32 src_scale = getDecimalScale(*arguments[0].type);\n-        Int64 multiplier_msec = DecimalUtils::scaleMultiplier<DateTime64>(3);\n-        Int64 multiplier_src = DecimalUtils::scaleMultiplier<DateTime64>(src_scale);\n-        auto factor = multiplier_msec / static_cast<double>(multiplier_src);\n-\n-        for (size_t i = 0; i < input_rows_count; ++i)\n-            res_data[i] = static_cast<Int64>(src_data[i] * factor - snowflake_epoch) << time_shift;\n-\n-        return res_column;\n-    }\n-};\n-\n-\n-class FunctionSnowflakeToDateTime64 : public IFunction\n-{\n-private:\n-    const char * name;\n-    const bool allow_nonconst_timezone_arguments;\n-\n-public:\n-    explicit FunctionSnowflakeToDateTime64(const char * name_, ContextPtr context)\n-        : name(name_)\n-        , allow_nonconst_timezone_arguments(context->getSettings().allow_nonconst_timezone_arguments)\n-    {}\n-\n-    String getName() const override { return name; }\n-    size_t getNumberOfArguments() const override { return 0; }\n-    bool isVariadic() const override { return true; }\n-    bool useDefaultImplementationForConstants() const override { return true; }\n-    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n-\n-    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override\n-    {\n-        FunctionArgumentDescriptors mandatory_args{\n-            {\"value\", &isInt64<IDataType>, nullptr, \"Int64\"}\n-        };\n-        FunctionArgumentDescriptors optional_args{\n-            {\"time_zone\", &isString<IDataType>, nullptr, \"String\"}\n-        };\n-        validateFunctionArgumentTypes(*this, arguments, mandatory_args, optional_args);\n-\n-        String timezone;\n-        if (arguments.size() == 2)\n-            timezone = extractTimeZoneNameFromFunctionArguments(arguments, 1, 0, allow_nonconst_timezone_arguments);\n-\n-        return std::make_shared<DataTypeDateTime64>(3, timezone);\n-    }\n-\n-    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override\n-    {\n-        const auto & src = arguments[0];\n-        const auto & src_column = *src.column;\n-\n-        auto res_column = ColumnDecimal<DateTime64>::create(input_rows_count, 3);\n-        auto & res_data = res_column->getData();\n-\n-        if (const auto * src_column_non_const = typeid_cast<const ColumnInt64 *>(&src_column))\n-        {\n-            const auto & src_data = src_column_non_const->getData();\n-            for (size_t i = 0; i < input_rows_count; ++i)\n-                res_data[i] = (src_data[i] >> time_shift) + snowflake_epoch;\n-        }\n-        else if (const auto * src_column_const = typeid_cast<const ColumnConst *>(&src_column))\n-        {\n-            Int64 src_val = src_column_const->getValue<Int64>();\n-            for (size_t i = 0; i < input_rows_count; ++i)\n-                res_data[i] = (src_val >> time_shift) + snowflake_epoch;\n-        }\n-        else\n-            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal argument for function {}\", name);\n-\n-        return res_column;\n-    }\n-};\n-\n-}\ndiff --git a/src/Functions/FunctionToDecimalString.cpp b/src/Functions/FunctionToDecimalString.cpp\ndeleted file mode 100644\nindex fe417b191373..000000000000\n--- a/src/Functions/FunctionToDecimalString.cpp\n+++ /dev/null\n@@ -1,22 +0,0 @@\n-#include <Functions/FunctionFactory.h>\n-#include <Functions/FunctionToDecimalString.h>\n-#include <Functions/IFunction.h>\n-\n-namespace DB\n-{\n-\n-REGISTER_FUNCTION(ToDecimalString)\n-{\n-    factory.registerFunction<FunctionToDecimalString>(\n-        FunctionDocumentation{\n-            .description=R\"(\n-Returns string representation of a number. First argument is the number of any numeric type,\n-second argument is the desired number of digits in fractional part. Returns String.\n-\n-        )\",\n-            .examples{{\"toDecimalString\", \"SELECT toDecimalString(2.1456,2)\", \"\"}},\n-            .categories{\"String\"}\n-        }, FunctionFactory::CaseInsensitive);\n-}\n-\n-}\ndiff --git a/src/Functions/array/arrayElement.cpp b/src/Functions/array/arrayElement.cpp\nindex d7c29070c91b..e628cd871645 100644\n--- a/src/Functions/array/arrayElement.cpp\n+++ b/src/Functions/array/arrayElement.cpp\n@@ -31,6 +31,9 @@ namespace ErrorCodes\n     extern const int ZERO_ARRAY_OR_TUPLE_INDEX;\n }\n \n+namespace\n+{\n+\n namespace ArrayImpl\n {\n     class NullMapBuilder;\n@@ -130,7 +133,6 @@ class NullMapBuilder\n {\n public:\n     explicit operator bool() const { return src_null_map; }\n-    bool operator!() const { return !src_null_map; }\n \n     void initSource(const UInt8 * src_null_map_)\n     {\n@@ -900,7 +902,7 @@ void FunctionArrayElement::executeMatchConstKeyToIndex(\n }\n \n template <typename F>\n-static bool castColumnString(const IColumn * column, F && f)\n+bool castColumnString(const IColumn * column, F && f)\n {\n     return castTypeToEither<ColumnString, ColumnFixedString>(column, std::forward<F>(f));\n }\n@@ -943,13 +945,13 @@ bool FunctionArrayElement::matchKeyToIndexString(\n }\n \n template <typename FromType, typename ToType>\n-static constexpr bool areConvertibleTypes =\n+constexpr bool areConvertibleTypes =\n     std::is_same_v<FromType, ToType>\n         || (is_integer<FromType> && is_integer<ToType>\n             && std::is_convertible_v<FromType, ToType>);\n \n template <typename F>\n-static bool castColumnNumeric(const IColumn * column, F && f)\n+bool castColumnNumeric(const IColumn * column, F && f)\n {\n     return castTypeToEither<\n         ColumnVector<UInt8>,\n@@ -1250,6 +1252,8 @@ ColumnPtr FunctionArrayElement::perform(const ColumnsWithTypeAndName & arguments\n     return res;\n }\n \n+}\n+\n \n REGISTER_FUNCTION(ArrayElement)\n {\ndiff --git a/src/Functions/castTypeToEither.h b/src/Functions/castTypeToEither.h\nindex aa8330366f1e..58b13e350b2b 100644\n--- a/src/Functions/castTypeToEither.h\n+++ b/src/Functions/castTypeToEither.h\n@@ -5,6 +5,7 @@\n \n namespace DB\n {\n+\n template <typename... Ts, typename T, typename F>\n static bool castTypeToEither(const T * type, F && f)\n {\n@@ -12,8 +13,9 @@ static bool castTypeToEither(const T * type, F && f)\n }\n \n template <class ...Args>\n-constexpr bool castTypeToEither(TypeList<Args...>, const auto * type, auto && f)\n+static bool castTypeToEither(TypeList<Args...>, const auto * type, auto && f)\n {\n     return ((typeid_cast<const Args *>(type) != nullptr && std::forward<decltype(f)>(f)(*typeid_cast<const Args *>(type))) || ...);\n }\n+\n }\ndiff --git a/src/Functions/modulo.cpp b/src/Functions/modulo.cpp\nindex 8b8919f7b26b..cbc2ec2cd0a9 100644\n--- a/src/Functions/modulo.cpp\n+++ b/src/Functions/modulo.cpp\n@@ -176,7 +176,7 @@ REGISTER_FUNCTION(PositiveModulo)\n {\n     factory.registerFunction<FunctionPositiveModulo>(FunctionDocumentation\n         {\n-            .description=R\"(\n+            .description = R\"(\n Calculates the remainder when dividing `a` by `b`. Similar to function `modulo` except that `positiveModulo` always return non-negative number.\n Returns the difference between `a` and the nearest integer not greater than `a` divisible by `b`.\n In other words, the function returning the modulus (modulo) in the terms of Modular Arithmetic.\ndiff --git a/src/Functions/reinterpretAs.cpp b/src/Functions/reinterpretAs.cpp\nindex 9e86a70f8770..5293b6886783 100644\n--- a/src/Functions/reinterpretAs.cpp\n+++ b/src/Functions/reinterpretAs.cpp\n@@ -19,7 +19,7 @@\n #include <DataTypes/DataTypesDecimal.h>\n #include <DataTypes/DataTypesNumber.h>\n \n-#include <Common/TransformEndianness.hpp>\n+#include <Common/transformEndianness.h>\n #include <Common/memcpySmall.h>\n #include <Common/typeid_cast.h>\n \ndiff --git a/src/Functions/snowflake.cpp b/src/Functions/snowflake.cpp\nindex c18f1c033329..6aafa2cb5cfb 100644\n--- a/src/Functions/snowflake.cpp\n+++ b/src/Functions/snowflake.cpp\n@@ -1,9 +1,251 @@\n-#include <Functions/FunctionSnowflake.h>\n #include <Functions/FunctionFactory.h>\n+#include <Functions/extractTimeZoneFromFunctionArguments.h>\n+#include <Functions/IFunction.h>\n+#include <Functions/FunctionHelpers.h>\n+#include <DataTypes/DataTypeDateTime64.h>\n+#include <DataTypes/DataTypesDecimal.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <Columns/ColumnConst.h>\n+#include <Columns/ColumnsNumber.h>\n+#include <Core/DecimalFunctions.h>\n+#include <Interpreters/Context.h>\n+\n \n namespace DB\n {\n \n+namespace ErrorCodes\n+{\n+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n+}\n+\n+namespace\n+{\n+\n+/** According to Twitter's post on Snowflake, we can extract the timestamp for a snowflake ID by right shifting\n+ * the snowflake ID by 22 bits(10 bits machine ID and 12 bits sequence ID) and adding the Twitter epoch time of 1288834974657.\n+ * https://en.wikipedia.org/wiki/Snowflake_ID\n+ * https://blog.twitter.com/engineering/en_us/a/2010/announcing-snowflake\n+ * https://ws-dl.blogspot.com/2019/08/2019-08-03-tweetedat-finding-tweet.html\n+*/\n+constexpr size_t snowflake_epoch = 1288834974657L;\n+constexpr int time_shift = 22;\n+\n+class FunctionDateTimeToSnowflake : public IFunction\n+{\n+private:\n+    const char * name;\n+\n+public:\n+    explicit FunctionDateTimeToSnowflake(const char * name_) : name(name_) { }\n+\n+    String getName() const override { return name; }\n+    size_t getNumberOfArguments() const override { return 1; }\n+    bool useDefaultImplementationForConstants() const override { return true; }\n+    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n+\n+    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override\n+    {\n+        FunctionArgumentDescriptors args{\n+            {\"value\", &isDateTime<IDataType>, nullptr, \"DateTime\"}\n+        };\n+        validateFunctionArgumentTypes(*this, arguments, args);\n+\n+        return std::make_shared<DataTypeInt64>();\n+    }\n+\n+    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override\n+    {\n+        const auto & src = arguments[0];\n+        const auto & src_column = *src.column;\n+\n+        auto res_column = ColumnInt64::create(input_rows_count);\n+        auto & res_data = res_column->getData();\n+\n+        const auto & src_data = typeid_cast<const ColumnUInt32 &>(src_column).getData();\n+        for (size_t i = 0; i < input_rows_count; ++i)\n+            res_data[i] = (Int64(src_data[i]) * 1000 - snowflake_epoch) << time_shift;\n+\n+        return res_column;\n+    }\n+};\n+\n+class FunctionSnowflakeToDateTime : public IFunction\n+{\n+private:\n+    const char * name;\n+    const bool allow_nonconst_timezone_arguments;\n+\n+public:\n+    explicit FunctionSnowflakeToDateTime(const char * name_, ContextPtr context)\n+        : name(name_)\n+        , allow_nonconst_timezone_arguments(context->getSettings().allow_nonconst_timezone_arguments)\n+    {}\n+\n+    String getName() const override { return name; }\n+    size_t getNumberOfArguments() const override { return 0; }\n+    bool isVariadic() const override { return true; }\n+    bool useDefaultImplementationForConstants() const override { return true; }\n+    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n+\n+    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override\n+    {\n+        FunctionArgumentDescriptors mandatory_args{\n+            {\"value\", &isInt64<IDataType>, nullptr, \"Int64\"}\n+        };\n+        FunctionArgumentDescriptors optional_args{\n+            {\"time_zone\", &isString<IDataType>, nullptr, \"String\"}\n+        };\n+        validateFunctionArgumentTypes(*this, arguments, mandatory_args, optional_args);\n+\n+        String timezone;\n+        if (arguments.size() == 2)\n+            timezone = extractTimeZoneNameFromFunctionArguments(arguments, 1, 0, allow_nonconst_timezone_arguments);\n+\n+        return std::make_shared<DataTypeDateTime>(timezone);\n+    }\n+\n+    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override\n+    {\n+        const auto & src = arguments[0];\n+        const auto & src_column = *src.column;\n+\n+        auto res_column = ColumnUInt32::create(input_rows_count);\n+        auto & res_data = res_column->getData();\n+\n+        if (const auto * src_column_non_const = typeid_cast<const ColumnInt64 *>(&src_column))\n+        {\n+            const auto & src_data = src_column_non_const->getData();\n+            for (size_t i = 0; i < input_rows_count; ++i)\n+                res_data[i] = static_cast<UInt32>(\n+                    ((src_data[i] >> time_shift) + snowflake_epoch) / 1000);\n+        }\n+        else if (const auto * src_column_const = typeid_cast<const ColumnConst *>(&src_column))\n+        {\n+            Int64 src_val = src_column_const->getValue<Int64>();\n+            for (size_t i = 0; i < input_rows_count; ++i)\n+                res_data[i] = static_cast<UInt32>(\n+                    ((src_val >> time_shift) + snowflake_epoch) / 1000);\n+        }\n+        else\n+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal argument for function {}\", name);\n+\n+        return res_column;\n+    }\n+};\n+\n+\n+class FunctionDateTime64ToSnowflake : public IFunction\n+{\n+private:\n+    const char * name;\n+\n+public:\n+    explicit FunctionDateTime64ToSnowflake(const char * name_) : name(name_) { }\n+\n+    String getName() const override { return name; }\n+    size_t getNumberOfArguments() const override { return 1; }\n+    bool useDefaultImplementationForConstants() const override { return true; }\n+    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n+\n+    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override\n+    {\n+        FunctionArgumentDescriptors args{\n+            {\"value\", &isDateTime64<IDataType>, nullptr, \"DateTime64\"}\n+        };\n+        validateFunctionArgumentTypes(*this, arguments, args);\n+\n+        return std::make_shared<DataTypeInt64>();\n+    }\n+\n+    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override\n+    {\n+        const auto & src = arguments[0];\n+\n+        const auto & src_column = *src.column;\n+        auto res_column = ColumnInt64::create(input_rows_count);\n+        auto & res_data = res_column->getData();\n+\n+        const auto & src_data = typeid_cast<const ColumnDecimal<DateTime64> &>(src_column).getData();\n+\n+        /// timestamps in snowflake-ids are millisecond-based, convert input to milliseconds\n+        UInt32 src_scale = getDecimalScale(*arguments[0].type);\n+        Int64 multiplier_msec = DecimalUtils::scaleMultiplier<DateTime64>(3);\n+        Int64 multiplier_src = DecimalUtils::scaleMultiplier<DateTime64>(src_scale);\n+        auto factor = multiplier_msec / static_cast<double>(multiplier_src);\n+\n+        for (size_t i = 0; i < input_rows_count; ++i)\n+            res_data[i] = static_cast<Int64>(src_data[i] * factor - snowflake_epoch) << time_shift;\n+\n+        return res_column;\n+    }\n+};\n+\n+\n+class FunctionSnowflakeToDateTime64 : public IFunction\n+{\n+private:\n+    const char * name;\n+    const bool allow_nonconst_timezone_arguments;\n+\n+public:\n+    explicit FunctionSnowflakeToDateTime64(const char * name_, ContextPtr context)\n+        : name(name_)\n+        , allow_nonconst_timezone_arguments(context->getSettings().allow_nonconst_timezone_arguments)\n+    {}\n+\n+    String getName() const override { return name; }\n+    size_t getNumberOfArguments() const override { return 0; }\n+    bool isVariadic() const override { return true; }\n+    bool useDefaultImplementationForConstants() const override { return true; }\n+    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n+\n+    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override\n+    {\n+        FunctionArgumentDescriptors mandatory_args{\n+            {\"value\", &isInt64<IDataType>, nullptr, \"Int64\"}\n+        };\n+        FunctionArgumentDescriptors optional_args{\n+            {\"time_zone\", &isString<IDataType>, nullptr, \"String\"}\n+        };\n+        validateFunctionArgumentTypes(*this, arguments, mandatory_args, optional_args);\n+\n+        String timezone;\n+        if (arguments.size() == 2)\n+            timezone = extractTimeZoneNameFromFunctionArguments(arguments, 1, 0, allow_nonconst_timezone_arguments);\n+\n+        return std::make_shared<DataTypeDateTime64>(3, timezone);\n+    }\n+\n+    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override\n+    {\n+        const auto & src = arguments[0];\n+        const auto & src_column = *src.column;\n+\n+        auto res_column = ColumnDecimal<DateTime64>::create(input_rows_count, 3);\n+        auto & res_data = res_column->getData();\n+\n+        if (const auto * src_column_non_const = typeid_cast<const ColumnInt64 *>(&src_column))\n+        {\n+            const auto & src_data = src_column_non_const->getData();\n+            for (size_t i = 0; i < input_rows_count; ++i)\n+                res_data[i] = (src_data[i] >> time_shift) + snowflake_epoch;\n+        }\n+        else if (const auto * src_column_const = typeid_cast<const ColumnConst *>(&src_column))\n+        {\n+            Int64 src_val = src_column_const->getValue<Int64>();\n+            for (size_t i = 0; i < input_rows_count; ++i)\n+                res_data[i] = (src_val >> time_shift) + snowflake_epoch;\n+        }\n+        else\n+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, \"Illegal argument for function {}\", name);\n+\n+        return res_column;\n+    }\n+};\n+\n+}\n+\n REGISTER_FUNCTION(DateTimeToSnowflake)\n {\n     factory.registerFunction(\"dateTimeToSnowflake\",\ndiff --git a/src/Functions/FunctionToDecimalString.h b/src/Functions/toDecimalString.cpp\nsimilarity index 95%\nrename from src/Functions/FunctionToDecimalString.h\nrename to src/Functions/toDecimalString.cpp\nindex 3dd946203ccd..75593901bb34 100644\n--- a/src/Functions/FunctionToDecimalString.h\n+++ b/src/Functions/toDecimalString.cpp\n@@ -1,10 +1,7 @@\n-#pragma once\n-\n-#include <Core/Types.h>\n-#include <Core/DecimalFunctions.h>\n+#include <Functions/FunctionFactory.h>\n #include <Functions/IFunction.h>\n+#include <Core/Types.h>\n #include <Functions/FunctionHelpers.h>\n-#include <Columns/ColumnsNumber.h>\n #include <Columns/ColumnString.h>\n #include <Columns/ColumnVector.h>\n #include <Columns/ColumnDecimal.h>\n@@ -14,6 +11,7 @@\n #include <IO/WriteHelpers.h>\n #include <Interpreters/Context_fwd.h>\n \n+\n namespace DB\n {\n \n@@ -23,6 +21,9 @@ namespace ErrorCodes\n     extern const int CANNOT_PRINT_FLOAT_OR_DOUBLE_NUMBER;\n }\n \n+namespace\n+{\n+\n class FunctionToDecimalString : public IFunction\n {\n public:\n@@ -260,3 +261,19 @@ class FunctionToDecimalString : public IFunction\n };\n \n }\n+\n+REGISTER_FUNCTION(ToDecimalString)\n+{\n+    factory.registerFunction<FunctionToDecimalString>(\n+        FunctionDocumentation{\n+            .description=R\"(\n+Returns string representation of a number. First argument is the number of any numeric type,\n+second argument is the desired number of digits in fractional part. Returns String.\n+\n+        )\",\n+            .examples{{\"toDecimalString\", \"SELECT toDecimalString(2.1456,2)\", \"\"}},\n+            .categories{\"String\"}\n+        }, FunctionFactory::CaseInsensitive);\n+}\n+\n+}\ndiff --git a/src/IO/ReadHelpers.h b/src/IO/ReadHelpers.h\nindex c5a456d70f64..5c55b36d3c33 100644\n--- a/src/IO/ReadHelpers.h\n+++ b/src/IO/ReadHelpers.h\n@@ -17,7 +17,7 @@\n #include <Common/DateLUT.h>\n #include <Common/LocalDate.h>\n #include <Common/LocalDateTime.h>\n-#include <Common/TransformEndianness.hpp>\n+#include <Common/transformEndianness.h>\n #include <base/StringRef.h>\n #include <base/arithmeticOverflow.h>\n #include <base/sort.h>\ndiff --git a/src/IO/WriteHelpers.h b/src/IO/WriteHelpers.h\nindex 58883ff60a9c..094352638e6e 100644\n--- a/src/IO/WriteHelpers.h\n+++ b/src/IO/WriteHelpers.h\n@@ -15,7 +15,7 @@\n #include <Common/DateLUT.h>\n #include <Common/LocalDate.h>\n #include <Common/LocalDateTime.h>\n-#include <Common/TransformEndianness.hpp>\n+#include <Common/transformEndianness.h>\n #include <base/find_symbols.h>\n #include <base/StringRef.h>\n #include <base/DecomposedFloat.h>\ndiff --git a/src/Interpreters/InterpreterSystemQuery.cpp b/src/Interpreters/InterpreterSystemQuery.cpp\nindex ea0e95c2b279..b278e4843165 100644\n--- a/src/Interpreters/InterpreterSystemQuery.cpp\n+++ b/src/Interpreters/InterpreterSystemQuery.cpp\n@@ -17,12 +17,10 @@\n #include <Functions/UserDefined/ExternalUserDefinedExecutableFunctionsLoader.h>\n #include <Interpreters/EmbeddedDictionaries.h>\n #include <Interpreters/ActionLocksManager.h>\n-#include <Interpreters/InterpreterDropQuery.h>\n #include <Interpreters/InterpreterCreateQuery.h>\n #include <Interpreters/InterpreterRenameQuery.h>\n #include <Interpreters/QueryLog.h>\n #include <Interpreters/executeDDLQueryOnCluster.h>\n-#include <Interpreters/PartLog.h>\n #include <Interpreters/QueryThreadLog.h>\n #include <Interpreters/QueryViewsLog.h>\n #include <Interpreters/SessionLog.h>\n@@ -57,7 +55,6 @@\n #include <Storages/HDFS/StorageHDFS.h>\n #include <Storages/System/StorageSystemFilesystemCache.h>\n #include <Parsers/ASTSystemQuery.h>\n-#include <Parsers/ASTDropQuery.h>\n #include <Parsers/ASTCreateQuery.h>\n #include <Common/ThreadFuzzer.h>\n #include <csignal>\ndiff --git a/src/Parsers/ParserSystemQuery.cpp b/src/Parsers/ParserSystemQuery.cpp\nindex a26fdc1396b3..acf458ea583f 100644\n--- a/src/Parsers/ParserSystemQuery.cpp\n+++ b/src/Parsers/ParserSystemQuery.cpp\n@@ -7,11 +7,6 @@\n #include <Parsers/parseDatabaseAndTableName.h>\n \n #include <magic_enum.hpp>\n-#include <base/EnumReflection.h>\n-\n-namespace ErrorCodes\n-{\n-}\n \n \n namespace DB\ndiff --git a/src/Storages/System/StorageSystemParts.cpp b/src/Storages/System/StorageSystemParts.cpp\nindex 4bf1053a7b67..57c455fcdc7c 100644\n--- a/src/Storages/System/StorageSystemParts.cpp\n+++ b/src/Storages/System/StorageSystemParts.cpp\n@@ -1,25 +1,22 @@\n-#include \"StorageSystemParts.h\"\n+#include <Storages/System/StorageSystemParts.h>\n #include <atomic>\n #include <memory>\n #include <string_view>\n \n-#include <Common/escapeForFileName.h>\n-#include <Columns/ColumnString.h>\n #include <DataTypes/DataTypeString.h>\n #include <DataTypes/DataTypeArray.h>\n #include <DataTypes/DataTypesNumber.h>\n #include <DataTypes/DataTypeDateTime.h>\n #include <DataTypes/DataTypeDate.h>\n #include <DataTypes/DataTypeUUID.h>\n-#include <Storages/VirtualColumnUtils.h>\n-#include <Databases/IDatabase.h>\n #include <Parsers/queryToString.h>\n-#include <base/hex.h>\n #include <Interpreters/TransactionVersionMetadata.h>\n #include <Interpreters/Context.h>\n \n+\n namespace\n {\n+\n std::string_view getRemovalStateDescription(DB::DataPartRemovalState state)\n {\n     switch (state)\ndiff --git a/src/Storages/System/StorageSystemTables.cpp b/src/Storages/System/StorageSystemTables.cpp\nindex 715c98ee92a3..d888813f6ce4 100644\n--- a/src/Storages/System/StorageSystemTables.cpp\n+++ b/src/Storages/System/StorageSystemTables.cpp\n@@ -7,7 +7,6 @@\n #include <Storages/MergeTree/MergeTreeData.h>\n #include <Storages/SelectQueryInfo.h>\n #include <Storages/VirtualColumnUtils.h>\n-#include <Databases/IDatabase.h>\n #include <Access/ContextAccess.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/formatWithPossiblyHidingSecrets.h>\n@@ -70,7 +69,10 @@ StorageSystemTables::StorageSystemTables(const StorageID & table_id_)\n }\n \n \n-static ColumnPtr getFilteredDatabases(const SelectQueryInfo & query_info, ContextPtr context)\n+namespace\n+{\n+\n+ColumnPtr getFilteredDatabases(const SelectQueryInfo & query_info, ContextPtr context)\n {\n     MutableColumnPtr column = ColumnString::create();\n \n@@ -88,7 +90,7 @@ static ColumnPtr getFilteredDatabases(const SelectQueryInfo & query_info, Contex\n     return block.getByPosition(0).column;\n }\n \n-static ColumnPtr getFilteredTables(const ASTPtr & query, const ColumnPtr & filtered_databases_column, ContextPtr context)\n+ColumnPtr getFilteredTables(const ASTPtr & query, const ColumnPtr & filtered_databases_column, ContextPtr context)\n {\n     MutableColumnPtr column = ColumnString::create();\n \n@@ -110,7 +112,7 @@ static ColumnPtr getFilteredTables(const ASTPtr & query, const ColumnPtr & filte\n \n /// Avoid heavy operation on tables if we only queried columns that we can get without table object.\n /// Otherwise it will require table initialization for Lazy database.\n-static bool needTable(const DatabasePtr & database, const Block & header)\n+bool needTable(const DatabasePtr & database, const Block & header)\n {\n     if (database->getEngineName() != \"Lazy\")\n         return true;\n@@ -602,6 +604,8 @@ class TablesBlockSource : public ISource\n     std::string database_name;\n };\n \n+}\n+\n \n Pipe StorageSystemTables::read(\n     const Names & column_names,\ndiff --git a/src/Storages/System/StorageSystemTimeZones.cpp b/src/Storages/System/StorageSystemTimeZones.cpp\nindex dc3711812a68..e0d7d2a5c42c 100644\n--- a/src/Storages/System/StorageSystemTimeZones.cpp\n+++ b/src/Storages/System/StorageSystemTimeZones.cpp\n@@ -10,7 +10,8 @@ namespace DB\n {\n NamesAndTypesList StorageSystemTimeZones::getNamesAndTypes()\n {\n-    return {\n+    return\n+    {\n         {\"time_zone\", std::make_shared<DataTypeString>()},\n     };\n }\ndiff --git a/src/TableFunctions/Hive/TableFunctionHive.cpp b/src/TableFunctions/Hive/TableFunctionHive.cpp\nindex ebebee13092b..d88850875324 100644\n--- a/src/TableFunctions/Hive/TableFunctionHive.cpp\n+++ b/src/TableFunctions/Hive/TableFunctionHive.cpp\n@@ -1,12 +1,13 @@\n-#include <TableFunctions/Hive/TableFunctionHive.h>\n+#include \"config.h\"\n \n #if USE_HIVE\n+\n+#include <TableFunctions/ITableFunction.h>\n+#include <Poco/Logger.h>\n #include <memory>\n #include <Common/Exception.h>\n #include <Common/ErrorCodes.h>\n-#include <Parsers/ASTLiteral.h>\n #include <Parsers/ExpressionListParsers.h>\n-#include <Parsers/queryToString.h>\n #include <Parsers/parseQuery.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/evaluateConstantExpression.h>\n@@ -15,75 +16,111 @@\n #include <Storages/checkAndGetLiteralArgument.h>\n #include <TableFunctions/TableFunctionFactory.h>\n #include <Interpreters/parseColumnsListForTableFunction.h>\n-#include <Common/logger_useful.h>\n \n namespace DB\n {\n-    namespace ErrorCodes\n-    {\n-        extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n-    }\n-\n-    void TableFunctionHive::parseArguments(const ASTPtr & ast_function_, ContextPtr context_)\n-    {\n-        ASTs & args_func = ast_function_->children;\n-        if (args_func.size() != 1)\n-            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Table function '{}' must have arguments.\", getName());\n-\n-        ASTs & args = args_func.at(0)->children;\n-\n-        if (args.size() != 5)\n-            throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n-                            \"The signature of function {} is:\\n - hive_url, hive_database, hive_table, structure, partition_by_keys\",\n-                            getName());\n-\n-        for (auto & arg : args)\n-            arg = evaluateConstantExpressionOrIdentifierAsLiteral(arg, context_);\n-\n-        hive_metastore_url = checkAndGetLiteralArgument<String>(args[0], \"hive_url\");\n-        hive_database = checkAndGetLiteralArgument<String>(args[1], \"hive_database\");\n-        hive_table = checkAndGetLiteralArgument<String>(args[2], \"hive_table\");\n-        table_structure = checkAndGetLiteralArgument<String>(args[3], \"structure\");\n-        partition_by_def = checkAndGetLiteralArgument<String>(args[4], \"partition_by_keys\");\n-\n-        actual_columns = parseColumnsListFromString(table_structure, context_);\n-    }\n-\n-    ColumnsDescription TableFunctionHive::getActualTableStructure(ContextPtr /*context_*/, bool /*is_insert_query*/) const { return actual_columns; }\n-\n-    StoragePtr TableFunctionHive::executeImpl(\n-        const ASTPtr & /*ast_function_*/,\n-        ContextPtr context_,\n-        const std::string & table_name_,\n-        ColumnsDescription /*cached_columns_*/,\n-        bool /*is_insert_query*/) const\n-    {\n-        const Settings & settings = context_->getSettings();\n-        ParserExpression partition_by_parser;\n-        ASTPtr partition_by_ast = parseQuery(\n-            partition_by_parser,\n-            \"(\" + partition_by_def + \")\",\n-            \"partition by declaration list\",\n-            settings.max_query_size,\n-            settings.max_parser_depth);\n-        StoragePtr storage;\n-        storage = std::make_shared<StorageHive>(\n-            hive_metastore_url,\n-            hive_database,\n-            hive_table,\n-            StorageID(getDatabaseName(), table_name_),\n-            actual_columns,\n-            ConstraintsDescription{},\n-            \"\",\n-            partition_by_ast,\n-            std::make_unique<HiveSettings>(),\n-            context_);\n-\n-        return storage;\n-    }\n-\n-\n-    void registerTableFunctionHive(TableFunctionFactory & factory_) { factory_.registerFunction<TableFunctionHive>(); }\n \n+namespace ErrorCodes\n+{\n+    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n }\n+\n+\n+namespace\n+{\n+\n+class TableFunctionHive : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"hive\";\n+    static constexpr auto storage_type_name = \"Hive\";\n+    std::string getName() const override { return name; }\n+\n+    bool hasStaticStructure() const override { return true; }\n+\n+    StoragePtr executeImpl(\n+        const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+\n+    const char * getStorageTypeName() const override { return storage_type_name; }\n+    ColumnsDescription getActualTableStructure(ContextPtr, bool is_insert_query) const override;\n+    void parseArguments(const ASTPtr & ast_function_, ContextPtr context_) override;\n+\n+private:\n+    Poco::Logger * logger = &Poco::Logger::get(\"TableFunctionHive\");\n+\n+    String cluster_name;\n+    String hive_metastore_url;\n+    String hive_database;\n+    String hive_table;\n+    String table_structure;\n+    String partition_by_def;\n+\n+    ColumnsDescription actual_columns;\n+};\n+\n+void TableFunctionHive::parseArguments(const ASTPtr & ast_function_, ContextPtr context_)\n+{\n+    ASTs & args_func = ast_function_->children;\n+    if (args_func.size() != 1)\n+        throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Table function '{}' must have arguments.\", getName());\n+\n+    ASTs & args = args_func.at(0)->children;\n+\n+    if (args.size() != 5)\n+        throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\n+                        \"The signature of function {} is:\\n - hive_url, hive_database, hive_table, structure, partition_by_keys\",\n+                        getName());\n+\n+    for (auto & arg : args)\n+        arg = evaluateConstantExpressionOrIdentifierAsLiteral(arg, context_);\n+\n+    hive_metastore_url = checkAndGetLiteralArgument<String>(args[0], \"hive_url\");\n+    hive_database = checkAndGetLiteralArgument<String>(args[1], \"hive_database\");\n+    hive_table = checkAndGetLiteralArgument<String>(args[2], \"hive_table\");\n+    table_structure = checkAndGetLiteralArgument<String>(args[3], \"structure\");\n+    partition_by_def = checkAndGetLiteralArgument<String>(args[4], \"partition_by_keys\");\n+\n+    actual_columns = parseColumnsListFromString(table_structure, context_);\n+}\n+\n+ColumnsDescription TableFunctionHive::getActualTableStructure(ContextPtr /*context_*/, bool /*is_insert_query*/) const { return actual_columns; }\n+\n+StoragePtr TableFunctionHive::executeImpl(\n+    const ASTPtr & /*ast_function_*/,\n+    ContextPtr context_,\n+    const std::string & table_name_,\n+    ColumnsDescription /*cached_columns_*/,\n+    bool /*is_insert_query*/) const\n+{\n+    const Settings & settings = context_->getSettings();\n+    ParserExpression partition_by_parser;\n+    ASTPtr partition_by_ast = parseQuery(\n+        partition_by_parser,\n+        \"(\" + partition_by_def + \")\",\n+        \"partition by declaration list\",\n+        settings.max_query_size,\n+        settings.max_parser_depth);\n+    StoragePtr storage;\n+    storage = std::make_shared<StorageHive>(\n+        hive_metastore_url,\n+        hive_database,\n+        hive_table,\n+        StorageID(getDatabaseName(), table_name_),\n+        actual_columns,\n+        ConstraintsDescription{},\n+        \"\",\n+        partition_by_ast,\n+        std::make_unique<HiveSettings>(),\n+        context_);\n+\n+    return storage;\n+}\n+\n+}\n+\n+\n+void registerTableFunctionHive(TableFunctionFactory & factory_) { factory_.registerFunction<TableFunctionHive>(); }\n+\n+}\n+\n #endif\ndiff --git a/src/TableFunctions/Hive/TableFunctionHive.h b/src/TableFunctions/Hive/TableFunctionHive.h\ndeleted file mode 100644\nindex 5e48be46ce18..000000000000\n--- a/src/TableFunctions/Hive/TableFunctionHive.h\n+++ /dev/null\n@@ -1,39 +0,0 @@\n-#pragma once\n-#include \"config.h\"\n-\n-#if USE_HIVE\n-#include <TableFunctions/ITableFunction.h>\n-#include <Poco/Logger.h>\n-namespace DB\n-{\n-class Context;\n-class TableFunctionHive : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"hive\";\n-    static constexpr auto storage_type_name = \"Hive\";\n-    std::string getName() const override { return name; }\n-\n-    bool hasStaticStructure() const override { return true; }\n-\n-    StoragePtr executeImpl(\n-        const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-\n-    const char * getStorageTypeName() const override { return storage_type_name; }\n-    ColumnsDescription getActualTableStructure(ContextPtr, bool is_insert_query) const override;\n-    void parseArguments(const ASTPtr & ast_function_, ContextPtr context_) override;\n-\n-private:\n-    Poco::Logger * logger = &Poco::Logger::get(\"TableFunctionHive\");\n-\n-    String cluster_name;\n-    String hive_metastore_url;\n-    String hive_database;\n-    String hive_table;\n-    String table_structure;\n-    String partition_by_def;\n-\n-    ColumnsDescription actual_columns;\n-};\n-}\n-#endif\ndiff --git a/src/TableFunctions/ITableFunctionXDBC.cpp b/src/TableFunctions/ITableFunctionXDBC.cpp\nindex 59702259b356..b1746ea769ff 100644\n--- a/src/TableFunctions/ITableFunctionXDBC.cpp\n+++ b/src/TableFunctions/ITableFunctionXDBC.cpp\n@@ -9,12 +9,16 @@\n #include <Parsers/parseQuery.h>\n #include <Storages/StorageXDBC.h>\n #include <TableFunctions/ITableFunction.h>\n-#include <TableFunctions/ITableFunctionXDBC.h>\n #include <TableFunctions/TableFunctionFactory.h>\n #include <Poco/Net/HTTPRequest.h>\n #include <Common/Exception.h>\n #include \"registerTableFunctions.h\"\n \n+#include <Poco/Util/AbstractConfiguration.h>\n+#include <BridgeHelper/XDBCBridgeHelper.h>\n+\n+#include \"config.h\"\n+\n \n namespace DB\n {\n@@ -24,6 +28,79 @@ namespace ErrorCodes\n     extern const int LOGICAL_ERROR;\n }\n \n+namespace\n+{\n+\n+/**\n+ * Base class for table functions, that works over external bridge\n+ * Xdbc (Xdbc connect string, table) - creates a temporary StorageXDBC.\n+ */\n+class ITableFunctionXDBC : public ITableFunction\n+{\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+\n+    /* A factory method to create bridge helper, that will assist in remote interaction */\n+    virtual BridgeHelperPtr createBridgeHelper(ContextPtr context,\n+        Poco::Timespan http_timeout_,\n+        const std::string & connection_string_,\n+        bool use_connection_pooling_) const = 0;\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    void startBridgeIfNot(ContextPtr context) const;\n+\n+    String connection_string;\n+    String schema_name;\n+    String remote_table_name;\n+    mutable BridgeHelperPtr helper;\n+};\n+\n+class TableFunctionJDBC : public ITableFunctionXDBC\n+{\n+public:\n+    static constexpr auto name = \"jdbc\";\n+    std::string getName() const override\n+    {\n+        return name;\n+    }\n+\n+private:\n+    BridgeHelperPtr createBridgeHelper(ContextPtr context,\n+        Poco::Timespan http_timeout_,\n+        const std::string & connection_string_,\n+        bool use_connection_pooling_) const override\n+    {\n+        return std::make_shared<XDBCBridgeHelper<JDBCBridgeMixin>>(context, http_timeout_, connection_string_, use_connection_pooling_);\n+    }\n+\n+    const char * getStorageTypeName() const override { return \"JDBC\"; }\n+};\n+\n+class TableFunctionODBC : public ITableFunctionXDBC\n+{\n+public:\n+    static constexpr auto name = \"odbc\";\n+    std::string getName() const override\n+    {\n+        return name;\n+    }\n+\n+private:\n+    BridgeHelperPtr createBridgeHelper(ContextPtr context,\n+        Poco::Timespan http_timeout_,\n+        const std::string & connection_string_,\n+        bool use_connection_pooling_) const override\n+    {\n+        return std::make_shared<XDBCBridgeHelper<ODBCBridgeMixin>>(context, http_timeout_, connection_string_, use_connection_pooling_);\n+    }\n+\n+    const char * getStorageTypeName() const override { return \"ODBC\"; }\n+};\n+\n+\n void ITableFunctionXDBC::parseArguments(const ASTPtr & ast_function, ContextPtr context)\n {\n     const auto & args_func = ast_function->as<ASTFunction &>();\n@@ -102,6 +179,8 @@ StoragePtr ITableFunctionXDBC::executeImpl(const ASTPtr & /*ast_function*/, Cont\n     return result;\n }\n \n+}\n+\n void registerTableFunctionJDBC(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionJDBC>();\ndiff --git a/src/TableFunctions/ITableFunctionXDBC.h b/src/TableFunctions/ITableFunctionXDBC.h\ndeleted file mode 100644\nindex da0fa83033bf..000000000000\n--- a/src/TableFunctions/ITableFunctionXDBC.h\n+++ /dev/null\n@@ -1,80 +0,0 @@\n-#pragma once\n-\n-#include <Storages/StorageXDBC.h>\n-#include <TableFunctions/ITableFunction.h>\n-#include <Poco/Util/AbstractConfiguration.h>\n-#include <BridgeHelper/XDBCBridgeHelper.h>\n-\n-#include \"config.h\"\n-\n-namespace DB\n-{\n-/**\n- * Base class for table functions, that works over external bridge\n- * Xdbc (Xdbc connect string, table) - creates a temporary StorageXDBC.\n- */\n-class ITableFunctionXDBC : public ITableFunction\n-{\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-\n-    /* A factory method to create bridge helper, that will assist in remote interaction */\n-    virtual BridgeHelperPtr createBridgeHelper(ContextPtr context,\n-        Poco::Timespan http_timeout_,\n-        const std::string & connection_string_,\n-        bool use_connection_pooling_) const = 0;\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    void startBridgeIfNot(ContextPtr context) const;\n-\n-    String connection_string;\n-    String schema_name;\n-    String remote_table_name;\n-    mutable BridgeHelperPtr helper;\n-};\n-\n-class TableFunctionJDBC : public ITableFunctionXDBC\n-{\n-public:\n-    static constexpr auto name = \"jdbc\";\n-    std::string getName() const override\n-    {\n-        return name;\n-    }\n-\n-private:\n-    BridgeHelperPtr createBridgeHelper(ContextPtr context,\n-        Poco::Timespan http_timeout_,\n-        const std::string & connection_string_,\n-        bool use_connection_pooling_) const override\n-    {\n-        return std::make_shared<XDBCBridgeHelper<JDBCBridgeMixin>>(context, http_timeout_, connection_string_, use_connection_pooling_);\n-    }\n-\n-    const char * getStorageTypeName() const override { return \"JDBC\"; }\n-};\n-\n-class TableFunctionODBC : public ITableFunctionXDBC\n-{\n-public:\n-    static constexpr auto name = \"odbc\";\n-    std::string getName() const override\n-    {\n-        return name;\n-    }\n-\n-private:\n-    BridgeHelperPtr createBridgeHelper(ContextPtr context,\n-        Poco::Timespan http_timeout_,\n-        const std::string & connection_string_,\n-        bool use_connection_pooling_) const override\n-    {\n-        return std::make_shared<XDBCBridgeHelper<ODBCBridgeMixin>>(context, http_timeout_, connection_string_, use_connection_pooling_);\n-    }\n-\n-    const char * getStorageTypeName() const override { return \"ODBC\"; }\n-};\n-}\ndiff --git a/src/TableFunctions/TableFunctionDictionary.cpp b/src/TableFunctions/TableFunctionDictionary.cpp\nindex f0060acb4119..5249487f1f5a 100644\n--- a/src/TableFunctions/TableFunctionDictionary.cpp\n+++ b/src/TableFunctions/TableFunctionDictionary.cpp\n@@ -6,15 +6,16 @@\n #include <DataTypes/DataTypeString.h>\n #include <DataTypes/DataTypesNumber.h>\n \n-#include <Interpreters/Context.h>\n #include <Interpreters/ExternalDictionariesLoader.h>\n #include <Interpreters/evaluateConstantExpression.h>\n+#include <Interpreters/Context.h>\n \n #include <Storages/StorageDictionary.h>\n #include <Storages/checkAndGetLiteralArgument.h>\n \n #include <TableFunctions/TableFunctionFactory.h>\n \n+\n namespace DB\n {\n \n@@ -72,7 +73,6 @@ ColumnsDescription TableFunctionDictionary::getActualTableStructure(ContextPtr c\n     /// otherwise, we get table structure by dictionary structure.\n     auto dictionary_structure = external_loader.getDictionaryStructure(dictionary_name, context);\n     return ColumnsDescription(StorageDictionary::getNamesAndTypes(dictionary_structure));\n-\n }\n \n StoragePtr TableFunctionDictionary::executeImpl(\n@@ -87,6 +87,7 @@ StoragePtr TableFunctionDictionary::executeImpl(\n     return result;\n }\n \n+\n void registerTableFunctionDictionary(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionDictionary>();\ndiff --git a/src/TableFunctions/TableFunctionDictionary.h b/src/TableFunctions/TableFunctionDictionary.h\nindex d0beb292fe14..2cf722c95f00 100644\n--- a/src/TableFunctions/TableFunctionDictionary.h\n+++ b/src/TableFunctions/TableFunctionDictionary.h\n@@ -27,4 +27,6 @@ class TableFunctionDictionary final : public ITableFunction\n private:\n     String dictionary_name;\n     ColumnsDescription dictionary_columns;\n-};}\n+};\n+\n+}\ndiff --git a/src/TableFunctions/TableFunctionExecutable.cpp b/src/TableFunctions/TableFunctionExecutable.cpp\nindex 5a64a9881568..209446dc9dd5 100644\n--- a/src/TableFunctions/TableFunctionExecutable.cpp\n+++ b/src/TableFunctions/TableFunctionExecutable.cpp\n@@ -1,4 +1,3 @@\n-#include <TableFunctions/TableFunctionExecutable.h>\n \n #include <Common/Exception.h>\n #include <TableFunctions/TableFunctionFactory.h>\n@@ -12,9 +11,7 @@\n #include <Parsers/parseQuery.h>\n #include <Storages/checkAndGetLiteralArgument.h>\n #include <Storages/StorageExecutable.h>\n-#include <DataTypes/DataTypeFactory.h>\n #include <Interpreters/evaluateConstantExpression.h>\n-#include <Interpreters/interpretSubquery.h>\n #include <boost/algorithm/string.hpp>\n #include \"registerTableFunctions.h\"\n \n@@ -30,6 +27,44 @@ namespace ErrorCodes\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n }\n \n+namespace\n+{\n+\n+/* executable(script_name_optional_arguments, format, structure, input_query) - creates a temporary storage from executable file\n+ *\n+ *\n+ * The file must be in the clickhouse data directory.\n+ * The relative path begins with the clickhouse data directory.\n+ */\n+class TableFunctionExecutable : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"executable\";\n+\n+    std::string getName() const override { return name; }\n+\n+    bool hasStaticStructure() const override { return true; }\n+\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+\n+    const char * getStorageTypeName() const override { return \"Executable\"; }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+\n+    std::vector<size_t> skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr context) const override;\n+\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    String script_name;\n+    std::vector<String> arguments;\n+    String format;\n+    String structure;\n+    std::vector<ASTPtr> input_queries;\n+    ASTPtr settings_query = nullptr;\n+};\n+\n+\n std::vector<size_t> TableFunctionExecutable::skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr) const\n {\n     const auto & table_function_node = query_node_table_function->as<TableFunctionNode &>();\n@@ -140,6 +175,8 @@ StoragePtr TableFunctionExecutable::executeImpl(const ASTPtr & /*ast_function*/,\n     return storage;\n }\n \n+}\n+\n void registerTableFunctionExecutable(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionExecutable>();\ndiff --git a/src/TableFunctions/TableFunctionExecutable.h b/src/TableFunctions/TableFunctionExecutable.h\ndeleted file mode 100644\nindex aa595312fe4f..000000000000\n--- a/src/TableFunctions/TableFunctionExecutable.h\n+++ /dev/null\n@@ -1,44 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunction.h>\n-\n-namespace DB\n-{\n-\n-class Context;\n-class ASTSetQuery;\n-\n-/* executable(script_name_optional_arguments, format, structure, input_query) - creates a temporary storage from executable file\n- *\n- *\n- * The file must be in the clickhouse data directory.\n- * The relative path begins with the clickhouse data directory.\n- */\n-class TableFunctionExecutable : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"executable\";\n-\n-    std::string getName() const override { return name; }\n-\n-    bool hasStaticStructure() const override { return true; }\n-\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-\n-    const char * getStorageTypeName() const override { return \"Executable\"; }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-\n-    std::vector<size_t> skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr context) const override;\n-\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    String script_name;\n-    std::vector<String> arguments;\n-    String format;\n-    String structure;\n-    std::vector<ASTPtr> input_queries;\n-    ASTPtr settings_query = nullptr;\n-};\n-}\ndiff --git a/src/TableFunctions/TableFunctionExplain.cpp b/src/TableFunctions/TableFunctionExplain.cpp\nindex f127979d92a1..f993a9820cbe 100644\n--- a/src/TableFunctions/TableFunctionExplain.cpp\n+++ b/src/TableFunctions/TableFunctionExplain.cpp\n@@ -1,27 +1,54 @@\n #include <Parsers/ASTFunction.h>\n #include <Parsers/ASTSelectWithUnionQuery.h>\n-#include <Parsers/ASTSetQuery.h>\n #include <Parsers/ParserSetQuery.h>\n #include <Parsers/parseQuery.h>\n #include <Parsers/queryToString.h>\n #include <Storages/StorageValues.h>\n #include <TableFunctions/ITableFunction.h>\n #include <TableFunctions/TableFunctionFactory.h>\n-#include <TableFunctions/TableFunctionExplain.h>\n #include <TableFunctions/registerTableFunctions.h>\n #include <Processors/Executors/PullingPipelineExecutor.h>\n #include <Analyzer/TableFunctionNode.h>\n #include <Interpreters/InterpreterSetQuery.h>\n+#include <Interpreters/InterpreterExplainQuery.h>\n #include <Interpreters/Context.h>\n \n+\n namespace DB\n {\n+\n namespace ErrorCodes\n {\n     extern const int LOGICAL_ERROR;\n     extern const int BAD_ARGUMENTS;\n }\n \n+namespace\n+{\n+\n+class TableFunctionExplain : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"viewExplain\";\n+\n+    std::string getName() const override { return name; }\n+\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const String & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+\n+    const char * getStorageTypeName() const override { return \"Explain\"; }\n+\n+    std::vector<size_t> skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr context) const override;\n+\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+\n+    InterpreterExplainQuery getInterpreter(ContextPtr context) const;\n+\n+    ASTPtr query = nullptr;\n+};\n+\n std::vector<size_t> TableFunctionExplain::skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr /*context*/) const\n {\n     const auto & table_function_node = query_node_table_function->as<TableFunctionNode &>();\n@@ -100,7 +127,7 @@ ColumnsDescription TableFunctionExplain::getActualTableStructure(ContextPtr cont\n     return columns_description;\n }\n \n-static Block executeMonoBlock(QueryPipeline & pipeline)\n+Block executeMonoBlock(QueryPipeline & pipeline)\n {\n     if (!pipeline.pulling())\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Expected pulling pipeline\");\n@@ -145,6 +172,8 @@ InterpreterExplainQuery TableFunctionExplain::getInterpreter(ContextPtr context)\n     return InterpreterExplainQuery(query, context);\n }\n \n+}\n+\n void registerTableFunctionExplain(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionExplain>({.documentation = {\ndiff --git a/src/TableFunctions/TableFunctionExplain.h b/src/TableFunctions/TableFunctionExplain.h\ndeleted file mode 100644\nindex 2eb7e35d0b55..000000000000\n--- a/src/TableFunctions/TableFunctionExplain.h\n+++ /dev/null\n@@ -1,35 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunction.h>\n-#include <Parsers/ASTExplainQuery.h>\n-#include <Interpreters/InterpreterExplainQuery.h>\n-#include <base/types.h>\n-\n-\n-namespace DB\n-{\n-\n-class TableFunctionExplain : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"viewExplain\";\n-\n-    std::string getName() const override { return name; }\n-\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const String & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-\n-    const char * getStorageTypeName() const override { return \"Explain\"; }\n-\n-    std::vector<size_t> skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr context) const override;\n-\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-\n-    InterpreterExplainQuery getInterpreter(ContextPtr context) const;\n-\n-    ASTPtr query = nullptr;\n-};\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionFile.cpp b/src/TableFunctions/TableFunctionFile.cpp\nindex f75c56e65237..52d9ca26f37e 100644\n--- a/src/TableFunctions/TableFunctionFile.cpp\n+++ b/src/TableFunctions/TableFunctionFile.cpp\n@@ -1,5 +1,5 @@\n-#include <TableFunctions/TableFunctionFile.h>\n #include <Interpreters/parseColumnsListForTableFunction.h>\n+#include <TableFunctions/ITableFunctionFileLike.h>\n \n #include \"Parsers/IAST_fwd.h\"\n #include \"registerTableFunctions.h\"\n@@ -12,6 +12,7 @@\n #include <Formats/FormatFactory.h>\n #include <Parsers/ASTIdentifier_fwd.h>\n \n+\n namespace DB\n {\n \n@@ -20,6 +21,42 @@ namespace ErrorCodes\n     extern const int BAD_ARGUMENTS;\n }\n \n+namespace\n+{\n+\n+/* file(path, format[, structure, compression]) - creates a temporary storage from file\n+ *\n+ * The file must be in the clickhouse data directory.\n+ * The relative path begins with the clickhouse data directory.\n+ */\n+class TableFunctionFile : public ITableFunctionFileLike\n+{\n+public:\n+    static constexpr auto name = \"file\";\n+    std::string getName() const override\n+    {\n+        return name;\n+    }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+\n+    std::unordered_set<String> getVirtualsToCheckBeforeUsingStructureHint() const override\n+    {\n+        return {\"_path\", \"_file\"};\n+    }\n+\n+protected:\n+    int fd = -1;\n+    void parseFirstArguments(const ASTPtr & arg, const ContextPtr & context) override;\n+    String getFormatFromFirstArgument() override;\n+\n+private:\n+    StoragePtr getStorage(\n+        const String & source, const String & format_, const ColumnsDescription & columns, ContextPtr global_context,\n+        const std::string & table_name, const std::string & compression_method_) const override;\n+    const char * getStorageTypeName() const override { return \"File\"; }\n+};\n+\n void TableFunctionFile::parseFirstArguments(const ASTPtr & arg, const ContextPtr & context)\n {\n     if (context->getApplicationType() != Context::ApplicationType::LOCAL)\n@@ -111,6 +148,8 @@ ColumnsDescription TableFunctionFile::getActualTableStructure(ContextPtr context\n     return parseColumnsListFromString(structure, context);\n }\n \n+}\n+\n void registerTableFunctionFile(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionFile>();\ndiff --git a/src/TableFunctions/TableFunctionFile.h b/src/TableFunctions/TableFunctionFile.h\ndeleted file mode 100644\nindex 439ae87b4ae1..000000000000\n--- a/src/TableFunctions/TableFunctionFile.h\n+++ /dev/null\n@@ -1,42 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunctionFileLike.h>\n-\n-\n-namespace DB\n-{\n-\n-/* file(path, format[, structure, compression]) - creates a temporary storage from file\n- *\n- * The file must be in the clickhouse data directory.\n- * The relative path begins with the clickhouse data directory.\n- */\n-class TableFunctionFile : public ITableFunctionFileLike\n-{\n-public:\n-    static constexpr auto name = \"file\";\n-    std::string getName() const override\n-    {\n-        return name;\n-    }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-\n-    std::unordered_set<String> getVirtualsToCheckBeforeUsingStructureHint() const override\n-    {\n-        return {\"_path\", \"_file\"};\n-    }\n-\n-protected:\n-    int fd = -1;\n-    void parseFirstArguments(const ASTPtr & arg, const ContextPtr & context) override;\n-    String getFormatFromFirstArgument() override;\n-\n-private:\n-    StoragePtr getStorage(\n-        const String & source, const String & format_, const ColumnsDescription & columns, ContextPtr global_context,\n-        const std::string & table_name, const std::string & compression_method_) const override;\n-    const char * getStorageTypeName() const override { return \"File\"; }\n-};\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionFormat.cpp b/src/TableFunctions/TableFunctionFormat.cpp\nindex 3afe7ffde586..4b6d0f70c0a8 100644\n--- a/src/TableFunctions/TableFunctionFormat.cpp\n+++ b/src/TableFunctions/TableFunctionFormat.cpp\n@@ -18,7 +18,6 @@\n #include <Storages/StorageValues.h>\n #include <Storages/checkAndGetLiteralArgument.h>\n \n-#include <TableFunctions/TableFunctionFormat.h>\n #include <TableFunctions/TableFunctionFactory.h>\n \n \n@@ -31,6 +30,32 @@ namespace ErrorCodes\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n }\n \n+namespace\n+{\n+\n+/* format(format_name, data) - ...\n+ */\n+class TableFunctionFormat : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"format\";\n+    std::string getName() const override { return name; }\n+    bool hasStaticStructure() const override { return false; }\n+\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+    const char * getStorageTypeName() const override { return \"Values\"; }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    Block parseData(ColumnsDescription columns, ContextPtr context) const;\n+\n+    String format;\n+    String data;\n+    String structure = \"auto\";\n+};\n+\n void TableFunctionFormat::parseArguments(const ASTPtr & ast_function, ContextPtr context)\n {\n     ASTs & args_func = ast_function->children;\n@@ -104,7 +129,7 @@ StoragePtr TableFunctionFormat::executeImpl(const ASTPtr & /*ast_function*/, Con\n     return res;\n }\n \n-static const FunctionDocumentation format_table_function_documentation =\n+const FunctionDocumentation format_table_function_documentation =\n {\n     .description=R\"(\n Extracts table structure from data and parses it according to specified input format.\n@@ -168,8 +193,12 @@ Returned value: A table with data parsed from `data` argument according specifie\n     .categories{\"format\", \"table-functions\"}\n };\n \n+}\n+\n+\n void registerTableFunctionFormat(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionFormat>({format_table_function_documentation, false}, TableFunctionFactory::CaseInsensitive);\n }\n+\n }\ndiff --git a/src/TableFunctions/TableFunctionFormat.h b/src/TableFunctions/TableFunctionFormat.h\ndeleted file mode 100644\nindex e20e8b6ea4bb..000000000000\n--- a/src/TableFunctions/TableFunctionFormat.h\n+++ /dev/null\n@@ -1,34 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunction.h>\n-\n-\n-namespace DB\n-{\n-\n-class Context;\n-\n-/* format(format_name, data) - ...\n- */\n-class TableFunctionFormat : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"format\";\n-    std::string getName() const override { return name; }\n-    bool hasStaticStructure() const override { return false; }\n-\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-    const char * getStorageTypeName() const override { return \"Values\"; }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    Block parseData(ColumnsDescription columns, ContextPtr context) const;\n-\n-    String format;\n-    String data;\n-    String structure = \"auto\";\n-};\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionGenerateRandom.cpp b/src/TableFunctions/TableFunctionGenerateRandom.cpp\nindex c6a9154cc66c..af2845949870 100644\n--- a/src/TableFunctions/TableFunctionGenerateRandom.cpp\n+++ b/src/TableFunctions/TableFunctionGenerateRandom.cpp\n@@ -8,7 +8,6 @@\n \n #include <TableFunctions/ITableFunction.h>\n #include <TableFunctions/TableFunctionFactory.h>\n-#include <TableFunctions/TableFunctionGenerateRandom.h>\n #include <Functions/FunctionGenerateRandomStructure.h>\n #include <Interpreters/parseColumnsListForTableFunction.h>\n #include <Interpreters/evaluateConstantExpression.h>\n@@ -28,6 +27,36 @@ namespace ErrorCodes\n     extern const int LOGICAL_ERROR;\n }\n \n+namespace\n+{\n+\n+/* generateRandom([structure, max_array_length, max_string_length, random_seed])\n+ * - creates a temporary storage that generates columns with random data\n+ */\n+class TableFunctionGenerateRandom : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"generateRandom\";\n+    std::string getName() const override { return name; }\n+    bool hasStaticStructure() const override { return structure != \"auto\"; }\n+\n+    bool needStructureHint() const override { return structure == \"auto\"; }\n+    void setStructureHint(const ColumnsDescription & structure_hint_) override { structure_hint = structure_hint_; }\n+\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+    const char * getStorageTypeName() const override { return \"GenerateRandom\"; }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    String structure = \"auto\";\n+    UInt64 max_string_length = 10;\n+    UInt64 max_array_length = 10;\n+    std::optional<UInt64> random_seed;\n+    ColumnsDescription structure_hint;\n+};\n+\n void TableFunctionGenerateRandom::parseArguments(const ASTPtr & ast_function, ContextPtr context)\n {\n     ASTs & args_func = ast_function->children;\n@@ -122,11 +151,11 @@ StoragePtr TableFunctionGenerateRandom::executeImpl(const ASTPtr & /*ast_functio\n     return res;\n }\n \n+}\n+\n void registerTableFunctionGenerate(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionGenerateRandom>({.documentation = {}, .allow_readonly = true});\n }\n \n }\n-\n-\ndiff --git a/src/TableFunctions/TableFunctionGenerateRandom.h b/src/TableFunctions/TableFunctionGenerateRandom.h\ndeleted file mode 100644\nindex a5d11ce0af6f..000000000000\n--- a/src/TableFunctions/TableFunctionGenerateRandom.h\n+++ /dev/null\n@@ -1,36 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunction.h>\n-\n-namespace DB\n-{\n-\n-/* generateRandom([structure, max_array_length, max_string_length, random_seed])\n- * - creates a temporary storage that generates columns with random data\n- */\n-class TableFunctionGenerateRandom : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"generateRandom\";\n-    std::string getName() const override { return name; }\n-    bool hasStaticStructure() const override { return structure != \"auto\"; }\n-\n-    bool needStructureHint() const override { return structure == \"auto\"; }\n-    void setStructureHint(const ColumnsDescription & structure_hint_) override { structure_hint = structure_hint_; }\n-\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-    const char * getStorageTypeName() const override { return \"GenerateRandom\"; }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    String structure = \"auto\";\n-    UInt64 max_string_length = 10;\n-    UInt64 max_array_length = 10;\n-    std::optional<UInt64> random_seed;\n-    ColumnsDescription structure_hint;\n-};\n-\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionInput.cpp b/src/TableFunctions/TableFunctionInput.cpp\nindex 658a55c6fc4d..29a377ceaab0 100644\n--- a/src/TableFunctions/TableFunctionInput.cpp\n+++ b/src/TableFunctions/TableFunctionInput.cpp\n@@ -1,4 +1,3 @@\n-#include <TableFunctions/TableFunctionInput.h>\n #include <TableFunctions/TableFunctionFactory.h>\n #include <Interpreters/parseColumnsListForTableFunction.h>\n #include <Parsers/ASTFunction.h>\n@@ -21,6 +20,31 @@ namespace ErrorCodes\n     extern const int CANNOT_EXTRACT_TABLE_STRUCTURE;\n }\n \n+namespace\n+{\n+\n+/* input(structure) - allows to make INSERT SELECT from incoming stream of data\n+ */\n+class TableFunctionInput : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"input\";\n+    std::string getName() const override { return name; }\n+    bool hasStaticStructure() const override { return true; }\n+    bool needStructureHint() const override { return true; }\n+    void setStructureHint(const ColumnsDescription & structure_hint_) override { structure_hint = structure_hint_; }\n+\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+    const char * getStorageTypeName() const override { return \"Input\"; }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    String structure;\n+    ColumnsDescription structure_hint;\n+};\n+\n void TableFunctionInput::parseArguments(const ASTPtr & ast_function, ContextPtr context)\n {\n     const auto * function = ast_function->as<ASTFunction>();\n@@ -65,6 +89,8 @@ StoragePtr TableFunctionInput::executeImpl(const ASTPtr & /*ast_function*/, Cont\n     return storage;\n }\n \n+}\n+\n void registerTableFunctionInput(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionInput>();\ndiff --git a/src/TableFunctions/TableFunctionInput.h b/src/TableFunctions/TableFunctionInput.h\ndeleted file mode 100644\nindex 3164ce43eef9..000000000000\n--- a/src/TableFunctions/TableFunctionInput.h\n+++ /dev/null\n@@ -1,33 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunction.h>\n-\n-\n-namespace DB\n-{\n-\n-class Context;\n-\n-/* input(structure) - allows to make INSERT SELECT from incoming stream of data\n- */\n-class TableFunctionInput : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"input\";\n-    std::string getName() const override { return name; }\n-    bool hasStaticStructure() const override { return true; }\n-    bool needStructureHint() const override { return true; }\n-    void setStructureHint(const ColumnsDescription & structure_hint_) override { structure_hint = structure_hint_; }\n-\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-    const char * getStorageTypeName() const override { return \"Input\"; }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    String structure;\n-    ColumnsDescription structure_hint;\n-};\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionMerge.cpp b/src/TableFunctions/TableFunctionMerge.cpp\nindex 599953a1add7..e7b5a34958fb 100644\n--- a/src/TableFunctions/TableFunctionMerge.cpp\n+++ b/src/TableFunctions/TableFunctionMerge.cpp\n@@ -2,7 +2,6 @@\n #include <Common/typeid_cast.h>\n #include <Storages/StorageMerge.h>\n #include <Storages/checkAndGetLiteralArgument.h>\n-#include <Parsers/ASTLiteral.h>\n #include <Parsers/ASTFunction.h>\n #include <TableFunctions/ITableFunction.h>\n #include <Analyzer/FunctionNode.h>\n@@ -10,7 +9,6 @@\n #include <Interpreters/evaluateConstantExpression.h>\n #include <Interpreters/Context.h>\n #include <Access/ContextAccess.h>\n-#include <TableFunctions/TableFunctionMerge.h>\n #include <TableFunctions/TableFunctionFactory.h>\n #include <TableFunctions/registerTableFunctions.h>\n \n@@ -26,18 +24,46 @@ namespace ErrorCodes\n \n namespace\n {\n-    [[noreturn]] void throwNoTablesMatchRegexp(const String & source_database_regexp, const String & source_table_regexp)\n-    {\n-        throw Exception(\n-            ErrorCodes::BAD_ARGUMENTS,\n-            \"Error while executing table function merge. Either there is no database, which matches regular expression `{}`, or there are \"\n-            \"no tables in database matches `{}`, which fit tables expression: {}\",\n-            source_database_regexp,\n-            source_database_regexp,\n-            source_table_regexp);\n-    }\n+\n+[[noreturn]] void throwNoTablesMatchRegexp(const String & source_database_regexp, const String & source_table_regexp)\n+{\n+    throw Exception(\n+        ErrorCodes::BAD_ARGUMENTS,\n+        \"Error while executing table function merge. Either there is no database, which matches regular expression `{}`, or there are \"\n+        \"no tables in database matches `{}`, which fit tables expression: {}\",\n+        source_database_regexp,\n+        source_database_regexp,\n+        source_table_regexp);\n }\n \n+/* merge (db_name, tables_regexp) - creates a temporary StorageMerge.\n+ * The structure of the table is taken from the first table that came up, suitable for regexp.\n+ * If there is no such table, an exception is thrown.\n+ */\n+class TableFunctionMerge : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"merge\";\n+    std::string getName() const override { return name; }\n+\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+    const char * getStorageTypeName() const override { return \"Merge\"; }\n+\n+    using TableSet = std::set<String>;\n+    using DBToTableSetMap = std::map<String, TableSet>;\n+    const DBToTableSetMap & getSourceDatabasesAndTables(ContextPtr context) const;\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+    std::vector<size_t> skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr context) const override;\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+    static TableSet getMatchedTablesWithAccess(const String & database_name, const String & table_regexp, const ContextPtr & context);\n+\n+    String source_database_name_or_regexp;\n+    String source_table_regexp;\n+    bool database_is_regexp = false;\n+    mutable std::optional<DBToTableSetMap> source_databases_and_tables;\n+};\n+\n std::vector<size_t> TableFunctionMerge::skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr) const\n {\n     auto & table_function_node = query_node_table_function->as<TableFunctionNode &>();\n@@ -179,6 +205,8 @@ TableFunctionMerge::getMatchedTablesWithAccess(const String & database_name, con\n     return tables;\n }\n \n+}\n+\n void registerTableFunctionMerge(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionMerge>();\ndiff --git a/src/TableFunctions/TableFunctionMerge.h b/src/TableFunctions/TableFunctionMerge.h\ndeleted file mode 100644\nindex 8cc5119978a9..000000000000\n--- a/src/TableFunctions/TableFunctionMerge.h\n+++ /dev/null\n@@ -1,38 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunction.h>\n-\n-\n-namespace DB\n-{\n-\n-/* merge (db_name, tables_regexp) - creates a temporary StorageMerge.\n- * The structure of the table is taken from the first table that came up, suitable for regexp.\n- * If there is no such table, an exception is thrown.\n- */\n-class TableFunctionMerge : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"merge\";\n-    std::string getName() const override { return name; }\n-\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-    const char * getStorageTypeName() const override { return \"Merge\"; }\n-\n-    using TableSet = std::set<String>;\n-    using DBToTableSetMap = std::map<String, TableSet>;\n-    const DBToTableSetMap & getSourceDatabasesAndTables(ContextPtr context) const;\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-    std::vector<size_t> skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr context) const override;\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-    static TableSet getMatchedTablesWithAccess(const String & database_name, const String & table_regexp, const ContextPtr & context);\n-\n-    String source_database_name_or_regexp;\n-    String source_table_regexp;\n-    bool database_is_regexp = false;\n-    mutable std::optional<DBToTableSetMap> source_databases_and_tables;\n-};\n-\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionMongoDB.cpp b/src/TableFunctions/TableFunctionMongoDB.cpp\nindex 5c7c1d98cdf2..b2cf1b4675ef 100644\n--- a/src/TableFunctions/TableFunctionMongoDB.cpp\n+++ b/src/TableFunctions/TableFunctionMongoDB.cpp\n@@ -1,12 +1,11 @@\n-#include <TableFunctions/TableFunctionMongoDB.h>\n+#include <Storages/StorageMongoDB.h>\n+#include <Storages/ExternalDataSourceConfiguration.h>\n \n #include <Common/Exception.h>\n \n-#include <Interpreters/evaluateConstantExpression.h>\n #include <Interpreters/Context.h>\n \n #include <Parsers/ASTFunction.h>\n-#include <Parsers/ASTLiteral.h>\n #include <Parsers/ASTIdentifier.h>\n \n #include <TableFunctions/TableFunctionFactory.h>\n@@ -25,6 +24,29 @@ namespace ErrorCodes\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n }\n \n+namespace\n+{\n+\n+class TableFunctionMongoDB : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"mongodb\";\n+\n+    std::string getName() const override { return name; }\n+\n+private:\n+    StoragePtr executeImpl(\n+            const ASTPtr & ast_function, ContextPtr context,\n+            const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+\n+    const char * getStorageTypeName() const override { return \"MongoDB\"; }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    std::optional<StorageMongoDB::Configuration> configuration;\n+    String structure;\n+};\n \n StoragePtr TableFunctionMongoDB::executeImpl(const ASTPtr & /*ast_function*/,\n         ContextPtr context, const String & table_name, ColumnsDescription /*cached_columns*/, bool is_insert_query) const\n@@ -97,6 +119,7 @@ void TableFunctionMongoDB::parseArguments(const ASTPtr & ast_function, ContextPt\n     configuration = StorageMongoDB::getConfiguration(main_arguments, context);\n }\n \n+}\n \n void registerTableFunctionMongoDB(TableFunctionFactory & factory)\n {\ndiff --git a/src/TableFunctions/TableFunctionMongoDB.h b/src/TableFunctions/TableFunctionMongoDB.h\ndeleted file mode 100644\nindex c2c15cabe5a2..000000000000\n--- a/src/TableFunctions/TableFunctionMongoDB.h\n+++ /dev/null\n@@ -1,31 +0,0 @@\n-#pragma once\n-\n-#include <Storages/StorageMongoDB.h>\n-#include <TableFunctions/ITableFunction.h>\n-#include <Storages/ExternalDataSourceConfiguration.h>\n-\n-namespace DB\n-{\n-\n-class TableFunctionMongoDB : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"mongodb\";\n-\n-    std::string getName() const override { return name; }\n-\n-private:\n-    StoragePtr executeImpl(\n-            const ASTPtr & ast_function, ContextPtr context,\n-            const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-\n-    const char * getStorageTypeName() const override { return \"MongoDB\"; }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    std::optional<StorageMongoDB::Configuration> configuration;\n-    String structure;\n-};\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionMySQL.cpp b/src/TableFunctions/TableFunctionMySQL.cpp\nindex a5c6962697d0..b027cf428802 100644\n--- a/src/TableFunctions/TableFunctionMySQL.cpp\n+++ b/src/TableFunctions/TableFunctionMySQL.cpp\n@@ -1,15 +1,15 @@\n #include \"config.h\"\n \n #if USE_MYSQL\n+\n+#include <Storages/StorageMySQL.h>\n #include <Processors/Sources/MySQLSource.h>\n #include <Interpreters/Context.h>\n-#include <Interpreters/evaluateConstantExpression.h>\n #include <Parsers/ASTFunction.h>\n #include <Storages/MySQL/MySQLSettings.h>\n #include <Storages/MySQL/MySQLHelpers.h>\n #include <TableFunctions/ITableFunction.h>\n #include <TableFunctions/TableFunctionFactory.h>\n-#include <TableFunctions/TableFunctionMySQL.h>\n #include <Common/Exception.h>\n #include <Common/parseAddress.h>\n #include <Common/quoteString.h>\n@@ -27,6 +27,32 @@ namespace ErrorCodes\n     extern const int LOGICAL_ERROR;\n }\n \n+namespace\n+{\n+\n+/* mysql ('host:port', database, table, user, password) - creates a temporary StorageMySQL.\n+ * The structure of the table is taken from the mysql query DESCRIBE table.\n+ * If there is no such table, an exception is thrown.\n+ */\n+class TableFunctionMySQL : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"mysql\";\n+    std::string getName() const override\n+    {\n+        return name;\n+    }\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+    const char * getStorageTypeName() const override { return \"MySQL\"; }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    mutable std::optional<mysqlxx::PoolWithFailover> pool;\n+    std::optional<StorageMySQL::Configuration> configuration;\n+};\n+\n void TableFunctionMySQL::parseArguments(const ASTPtr & ast_function, ContextPtr context)\n {\n     const auto & args_func = ast_function->as<ASTFunction &>();\n@@ -88,11 +114,14 @@ StoragePtr TableFunctionMySQL::executeImpl(\n     return res;\n }\n \n+}\n+\n \n void registerTableFunctionMySQL(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionMySQL>();\n }\n+\n }\n \n #endif\ndiff --git a/src/TableFunctions/TableFunctionMySQL.h b/src/TableFunctions/TableFunctionMySQL.h\ndeleted file mode 100644\nindex 04f619f5f4b7..000000000000\n--- a/src/TableFunctions/TableFunctionMySQL.h\n+++ /dev/null\n@@ -1,38 +0,0 @@\n-#pragma once\n-#include \"config.h\"\n-\n-#if USE_MYSQL\n-#include <TableFunctions/ITableFunction.h>\n-#include <Storages/StorageMySQL.h>\n-#include <mysqlxx/Pool.h>\n-\n-\n-namespace DB\n-{\n-\n-/* mysql ('host:port', database, table, user, password) - creates a temporary StorageMySQL.\n- * The structure of the table is taken from the mysql query DESCRIBE table.\n- * If there is no such table, an exception is thrown.\n- */\n-class TableFunctionMySQL : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"mysql\";\n-    std::string getName() const override\n-    {\n-        return name;\n-    }\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-    const char * getStorageTypeName() const override { return \"MySQL\"; }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    mutable std::optional<mysqlxx::PoolWithFailover> pool;\n-    std::optional<StorageMySQL::Configuration> configuration;\n-};\n-\n-}\n-\n-#endif\ndiff --git a/src/TableFunctions/TableFunctionNull.cpp b/src/TableFunctions/TableFunctionNull.cpp\nindex 57911e16d4b7..75a97bccb978 100644\n--- a/src/TableFunctions/TableFunctionNull.cpp\n+++ b/src/TableFunctions/TableFunctionNull.cpp\n@@ -1,12 +1,12 @@\n #include <Interpreters/Context.h>\n-#include <Parsers/ASTLiteral.h>\n #include <Parsers/ASTFunction.h>\n #include <Storages/checkAndGetLiteralArgument.h>\n #include <Storages/StorageNull.h>\n #include <Interpreters/parseColumnsListForTableFunction.h>\n #include <TableFunctions/TableFunctionFactory.h>\n-#include <TableFunctions/TableFunctionNull.h>\n #include <Interpreters/evaluateConstantExpression.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <TableFunctions/ITableFunction.h>\n #include \"registerTableFunctions.h\"\n \n \n@@ -17,6 +17,36 @@ namespace ErrorCodes\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n }\n \n+namespace\n+{\n+\n+/* null(structure) - creates a temporary null storage\n+ *\n+ * Used for testing purposes, for convenience writing tests and demos.\n+ */\n+class TableFunctionNull : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"null\";\n+    std::string getName() const override { return name; }\n+\n+    bool needStructureHint() const override { return structure == \"auto\"; }\n+\n+    void setStructureHint(const ColumnsDescription & structure_hint_) override { structure_hint = structure_hint_; }\n+\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const String & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+    const char * getStorageTypeName() const override { return \"Null\"; }\n+\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+\n+    String structure = \"auto\";\n+    ColumnsDescription structure_hint;\n+\n+    const ColumnsDescription default_structure{NamesAndTypesList{{\"dummy\", std::make_shared<DataTypeUInt8>()}}};\n+};\n+\n void TableFunctionNull::parseArguments(const ASTPtr & ast_function, ContextPtr context)\n {\n     const auto * function = ast_function->as<ASTFunction>();\n@@ -54,8 +84,11 @@ StoragePtr TableFunctionNull::executeImpl(const ASTPtr & /*ast_function*/, Conte\n     return res;\n }\n \n+}\n+\n void registerTableFunctionNull(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionNull>({.documentation = {}, .allow_readonly = true});\n }\n+\n }\ndiff --git a/src/TableFunctions/TableFunctionNull.h b/src/TableFunctions/TableFunctionNull.h\ndeleted file mode 100644\nindex e80552d4cffa..000000000000\n--- a/src/TableFunctions/TableFunctionNull.h\n+++ /dev/null\n@@ -1,37 +0,0 @@\n-#pragma once\n-\n-#include <Core/Types.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <TableFunctions/ITableFunction.h>\n-\n-\n-namespace DB\n-{\n-\n-/* null(structure) - creates a temporary null storage\n- *\n- * Used for testing purposes, for convenience writing tests and demos.\n- */\n-class TableFunctionNull : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"null\";\n-    std::string getName() const override { return name; }\n-\n-    bool needStructureHint() const override { return structure == \"auto\"; }\n-\n-    void setStructureHint(const ColumnsDescription & structure_hint_) override { structure_hint = structure_hint_; }\n-\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const String & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-    const char * getStorageTypeName() const override { return \"Null\"; }\n-\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-\n-    String structure = \"auto\";\n-    ColumnsDescription structure_hint;\n-\n-    const ColumnsDescription default_structure{NamesAndTypesList{{\"dummy\", std::make_shared<DataTypeUInt8>()}}};\n-};\n-}\ndiff --git a/src/TableFunctions/TableFunctionNumbers.cpp b/src/TableFunctions/TableFunctionNumbers.cpp\nindex d6cf50bc7d6b..9abd764f91d2 100644\n--- a/src/TableFunctions/TableFunctionNumbers.cpp\n+++ b/src/TableFunctions/TableFunctionNumbers.cpp\n@@ -1,5 +1,4 @@\n #include <TableFunctions/ITableFunction.h>\n-#include <TableFunctions/TableFunctionNumbers.h>\n #include <TableFunctions/TableFunctionFactory.h>\n #include <Parsers/ASTFunction.h>\n #include <Common/typeid_cast.h>\n@@ -21,6 +20,28 @@ namespace ErrorCodes\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n }\n \n+namespace\n+{\n+\n+/* numbers(limit), numbers_mt(limit)\n+ * - the same as SELECT number FROM system.numbers LIMIT limit.\n+ * Used for testing purposes, as a simple example of table function.\n+ */\n+template <bool multithreaded>\n+class TableFunctionNumbers : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = multithreaded ? \"numbers_mt\" : \"numbers\";\n+    std::string getName() const override { return name; }\n+    bool hasStaticStructure() const override { return true; }\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+    const char * getStorageTypeName() const override { return \"SystemNumbers\"; }\n+\n+    UInt64 evaluateArgument(ContextPtr context, ASTPtr & argument) const;\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+};\n \n template <bool multithreaded>\n ColumnsDescription TableFunctionNumbers<multithreaded>::getActualTableStructure(ContextPtr /*context*/, bool /*is_insert_query*/) const\n@@ -49,12 +70,6 @@ StoragePtr TableFunctionNumbers<multithreaded>::executeImpl(const ASTPtr & ast_f\n     throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Table function '{}' requires 'limit' or 'offset, limit'.\", getName());\n }\n \n-void registerTableFunctionNumbers(TableFunctionFactory & factory)\n-{\n-    factory.registerFunction<TableFunctionNumbers<true>>({.documentation = {}, .allow_readonly = true});\n-    factory.registerFunction<TableFunctionNumbers<false>>({.documentation = {}, .allow_readonly = true});\n-}\n-\n template <bool multithreaded>\n UInt64 TableFunctionNumbers<multithreaded>::evaluateArgument(ContextPtr context, ASTPtr & argument) const\n {\n@@ -72,3 +87,11 @@ UInt64 TableFunctionNumbers<multithreaded>::evaluateArgument(ContextPtr context,\n }\n \n }\n+\n+void registerTableFunctionNumbers(TableFunctionFactory & factory)\n+{\n+    factory.registerFunction<TableFunctionNumbers<true>>({.documentation = {}, .allow_readonly = true});\n+    factory.registerFunction<TableFunctionNumbers<false>>({.documentation = {}, .allow_readonly = true});\n+}\n+\n+}\ndiff --git a/src/TableFunctions/TableFunctionNumbers.h b/src/TableFunctions/TableFunctionNumbers.h\ndeleted file mode 100644\nindex e380f40f7b2c..000000000000\n--- a/src/TableFunctions/TableFunctionNumbers.h\n+++ /dev/null\n@@ -1,31 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunction.h>\n-#include <base/types.h>\n-\n-\n-namespace DB\n-{\n-\n-/* numbers(limit), numbers_mt(limit)\n- * - the same as SELECT number FROM system.numbers LIMIT limit.\n- * Used for testing purposes, as a simple example of table function.\n- */\n-template <bool multithreaded>\n-class TableFunctionNumbers : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = multithreaded ? \"numbers_mt\" : \"numbers\";\n-    std::string getName() const override { return name; }\n-    bool hasStaticStructure() const override { return true; }\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-    const char * getStorageTypeName() const override { return \"SystemNumbers\"; }\n-\n-    UInt64 evaluateArgument(ContextPtr context, ASTPtr & argument) const;\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-};\n-\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionPostgreSQL.cpp b/src/TableFunctions/TableFunctionPostgreSQL.cpp\nindex 6ed5883c3cc9..8d94988cd653 100644\n--- a/src/TableFunctions/TableFunctionPostgreSQL.cpp\n+++ b/src/TableFunctions/TableFunctionPostgreSQL.cpp\n@@ -1,13 +1,15 @@\n-#include <TableFunctions/TableFunctionPostgreSQL.h>\n+#include \"config.h\"\n \n #if USE_LIBPQXX\n-#include <Interpreters/evaluateConstantExpression.h>\n-#include <Parsers/ASTFunction.h>\n+\n #include <TableFunctions/ITableFunction.h>\n+#include <Core/PostgreSQL/PoolWithFailover.h>\n+#include <Storages/StoragePostgreSQL.h>\n+#include <Parsers/ASTFunction.h>\n #include <TableFunctions/TableFunctionFactory.h>\n #include <Common/Exception.h>\n-#include \"registerTableFunctions.h\"\n #include <Common/parseRemoteDescription.h>\n+#include \"registerTableFunctions.h\"\n \n \n namespace DB\n@@ -18,6 +20,28 @@ namespace ErrorCodes\n     extern const int BAD_ARGUMENTS;\n }\n \n+namespace\n+{\n+\n+class TableFunctionPostgreSQL : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"postgresql\";\n+    std::string getName() const override { return name; }\n+\n+private:\n+    StoragePtr executeImpl(\n+            const ASTPtr & ast_function, ContextPtr context,\n+            const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+\n+    const char * getStorageTypeName() const override { return \"PostgreSQL\"; }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    postgres::PoolWithFailoverPtr connection_pool;\n+    std::optional<StoragePostgreSQL::Configuration> configuration;\n+};\n \n StoragePtr TableFunctionPostgreSQL::executeImpl(const ASTPtr & /*ast_function*/,\n         ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool /*is_insert_query*/) const\n@@ -60,6 +84,8 @@ void TableFunctionPostgreSQL::parseArguments(const ASTPtr & ast_function, Contex\n         settings.postgresql_connection_pool_auto_close_connection);\n }\n \n+}\n+\n \n void registerTableFunctionPostgreSQL(TableFunctionFactory & factory)\n {\ndiff --git a/src/TableFunctions/TableFunctionPostgreSQL.h b/src/TableFunctions/TableFunctionPostgreSQL.h\ndeleted file mode 100644\nindex f7d77567dd44..000000000000\n--- a/src/TableFunctions/TableFunctionPostgreSQL.h\n+++ /dev/null\n@@ -1,36 +0,0 @@\n-#pragma once\n-#include \"config.h\"\n-\n-#if USE_LIBPQXX\n-#include <TableFunctions/ITableFunction.h>\n-#include <Core/PostgreSQL/PoolWithFailover.h>\n-#include <Storages/ExternalDataSourceConfiguration.h>\n-#include <Storages/StoragePostgreSQL.h>\n-\n-\n-namespace DB\n-{\n-\n-class TableFunctionPostgreSQL : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"postgresql\";\n-    std::string getName() const override { return name; }\n-\n-private:\n-    StoragePtr executeImpl(\n-            const ASTPtr & ast_function, ContextPtr context,\n-            const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-\n-    const char * getStorageTypeName() const override { return \"PostgreSQL\"; }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    postgres::PoolWithFailoverPtr connection_pool;\n-    std::optional<StoragePostgreSQL::Configuration> configuration;\n-};\n-\n-}\n-\n-#endif\ndiff --git a/src/TableFunctions/TableFunctionRedis.cpp b/src/TableFunctions/TableFunctionRedis.cpp\nindex 0b7433845b46..f87ba6d1c6d9 100644\n--- a/src/TableFunctions/TableFunctionRedis.cpp\n+++ b/src/TableFunctions/TableFunctionRedis.cpp\n@@ -1,5 +1,3 @@\n-#include <TableFunctions/TableFunctionRedis.h>\n-\n #include <Common/Exception.h>\n #include <Common/parseAddress.h>\n \n@@ -15,6 +13,10 @@\n #include <Storages/checkAndGetLiteralArgument.h>\n #include <Interpreters/evaluateConstantExpression.h>\n \n+#include <Storages/StorageRedis.h>\n+#include <TableFunctions/ITableFunction.h>\n+#include <Storages/ExternalDataSourceConfiguration.h>\n+\n \n namespace DB\n {\n@@ -24,6 +26,33 @@ namespace ErrorCodes\n     extern const int BAD_ARGUMENTS;\n }\n \n+namespace\n+{\n+\n+/* Implements Redis table function.\n+ * Use redis(host:port, key, structure[, db_index[, password[, pool_size]]]);\n+ */\n+class TableFunctionRedis : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"redis\";\n+    String getName() const override { return name; }\n+\n+private:\n+    StoragePtr executeImpl(\n+        const ASTPtr & ast_function, ContextPtr context,\n+        const String & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+\n+    const char * getStorageTypeName() const override { return \"Redis\"; }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    RedisConfiguration configuration;\n+    String structure;\n+    String primary_key;\n+};\n+\n StoragePtr TableFunctionRedis::executeImpl(\n     const ASTPtr & /*ast_function*/, ContextPtr context, const String & table_name, ColumnsDescription /*cached_columns*/, bool is_insert_query) const\n {\n@@ -85,6 +114,7 @@ void TableFunctionRedis::parseArguments(const ASTPtr & ast_function, ContextPtr\n         throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Bad arguments redis table function structure should contains key.\");\n }\n \n+}\n \n void registerTableFunctionRedis(TableFunctionFactory & factory)\n {\ndiff --git a/src/TableFunctions/TableFunctionRedis.h b/src/TableFunctions/TableFunctionRedis.h\ndeleted file mode 100644\nindex a7fc0df0a155..000000000000\n--- a/src/TableFunctions/TableFunctionRedis.h\n+++ /dev/null\n@@ -1,34 +0,0 @@\n-#pragma once\n-\n-#include <Storages/StorageRedis.h>\n-#include <TableFunctions/ITableFunction.h>\n-#include <Storages/ExternalDataSourceConfiguration.h>\n-\n-namespace DB\n-{\n-\n-/* Implements Redis table function.\n- * Use redis(host:port, key, structure[, db_index[, password[, pool_size]]]);\n- */\n-class TableFunctionRedis : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"redis\";\n-    String getName() const override { return name; }\n-\n-private:\n-    StoragePtr executeImpl(\n-        const ASTPtr & ast_function, ContextPtr context,\n-        const String & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-\n-    const char * getStorageTypeName() const override { return \"Redis\"; }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    RedisConfiguration configuration;\n-    String structure;\n-    String primary_key;\n-};\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionSQLite.cpp b/src/TableFunctions/TableFunctionSQLite.cpp\nindex dfd104ef81a2..e367e05bf736 100644\n--- a/src/TableFunctions/TableFunctionSQLite.cpp\n+++ b/src/TableFunctions/TableFunctionSQLite.cpp\n@@ -1,9 +1,10 @@\n-#include <TableFunctions/TableFunctionSQLite.h>\n+#include \"config.h\"\n \n #if USE_SQLITE\n \n #include <Common/Exception.h>\n-#include <Common/quoteString.h>\n+#include <TableFunctions/ITableFunction.h>\n+#include <Storages/StorageSQLite.h>\n \n #include <Databases/SQLite/SQLiteUtils.h>\n #include \"registerTableFunctions.h\"\n@@ -12,7 +13,6 @@\n \n #include <Parsers/ASTFunction.h>\n \n-#include <TableFunctions/ITableFunction.h>\n #include <TableFunctions/TableFunctionFactory.h>\n \n #include <Storages/checkAndGetLiteralArgument.h>\n@@ -27,6 +27,28 @@ namespace ErrorCodes\n     extern const int BAD_ARGUMENTS;\n }\n \n+namespace\n+{\n+\n+class TableFunctionSQLite : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"sqlite\";\n+    std::string getName() const override { return name; }\n+\n+private:\n+    StoragePtr executeImpl(\n+            const ASTPtr & ast_function, ContextPtr context,\n+            const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+\n+    const char * getStorageTypeName() const override { return \"SQLite\"; }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    String database_path, remote_table_name;\n+    std::shared_ptr<sqlite3> sqlite_db;\n+};\n \n StoragePtr TableFunctionSQLite::executeImpl(const ASTPtr & /*ast_function*/,\n         ContextPtr context, const String & table_name, ColumnsDescription cached_columns, bool /*is_insert_query*/) const\n@@ -69,6 +91,7 @@ void TableFunctionSQLite::parseArguments(const ASTPtr & ast_function, ContextPtr\n     sqlite_db = openSQLiteDB(database_path, context);\n }\n \n+}\n \n void registerTableFunctionSQLite(TableFunctionFactory & factory)\n {\ndiff --git a/src/TableFunctions/TableFunctionSQLite.h b/src/TableFunctions/TableFunctionSQLite.h\ndeleted file mode 100644\nindex 74318f058a9c..000000000000\n--- a/src/TableFunctions/TableFunctionSQLite.h\n+++ /dev/null\n@@ -1,34 +0,0 @@\n-#pragma once\n-#include \"config.h\"\n-\n-#if USE_SQLITE\n-#include <TableFunctions/ITableFunction.h>\n-#include <Storages/StorageSQLite.h>\n-\n-\n-namespace DB\n-{\n-\n-class TableFunctionSQLite : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"sqlite\";\n-    std::string getName() const override { return name; }\n-\n-private:\n-    StoragePtr executeImpl(\n-            const ASTPtr & ast_function, ContextPtr context,\n-            const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-\n-    const char * getStorageTypeName() const override { return \"SQLite\"; }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    String database_path, remote_table_name;\n-    std::shared_ptr<sqlite3> sqlite_db;\n-};\n-\n-}\n-\n-#endif\ndiff --git a/src/TableFunctions/TableFunctionValues.cpp b/src/TableFunctions/TableFunctionValues.cpp\nindex 42a19874704d..7b2a61c25eb3 100644\n--- a/src/TableFunctions/TableFunctionValues.cpp\n+++ b/src/TableFunctions/TableFunctionValues.cpp\n@@ -9,7 +9,6 @@\n #include <Parsers/ASTExpressionList.h>\n #include <Parsers/ASTLiteral.h>\n \n-#include <TableFunctions/TableFunctionValues.h>\n #include <TableFunctions/TableFunctionFactory.h>\n #include <Interpreters/parseColumnsListForTableFunction.h>\n \n@@ -30,7 +29,32 @@ namespace ErrorCodes\n     extern const int CANNOT_EXTRACT_TABLE_STRUCTURE;\n }\n \n-static void parseAndInsertValues(MutableColumns & res_columns, const ASTs & args, const Block & sample_block, size_t start, ContextPtr context)\n+namespace\n+{\n+\n+/* values(structure, values...) - creates a temporary storage filling columns with values\n+ * values is case-insensitive table function.\n+ */\n+class TableFunctionValues : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = \"values\";\n+    std::string getName() const override { return name; }\n+    bool hasStaticStructure() const override { return true; }\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+    const char * getStorageTypeName() const override { return \"Values\"; }\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    static DataTypes getTypesFromArgument(const ASTPtr & arg, ContextPtr context);\n+\n+    ColumnsDescription structure;\n+    bool has_structure_in_arguments;\n+};\n+\n+void parseAndInsertValues(MutableColumns & res_columns, const ASTs & args, const Block & sample_block, size_t start, ContextPtr context)\n {\n     if (res_columns.size() == 1) /// Parsing arguments as Fields\n     {\n@@ -146,6 +170,8 @@ StoragePtr TableFunctionValues::executeImpl(const ASTPtr & ast_function, Context\n     return res;\n }\n \n+}\n+\n void registerTableFunctionValues(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionValues>({.documentation = {}, .allow_readonly = true}, TableFunctionFactory::CaseInsensitive);\ndiff --git a/src/TableFunctions/TableFunctionValues.h b/src/TableFunctions/TableFunctionValues.h\ndeleted file mode 100644\nindex 7c87bff835eb..000000000000\n--- a/src/TableFunctions/TableFunctionValues.h\n+++ /dev/null\n@@ -1,30 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunction.h>\n-\n-namespace DB\n-{\n-/* values(structure, values...) - creates a temporary storage filling columns with values\n- * values is case-insensitive table function.\n- */\n-class TableFunctionValues : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"values\";\n-    std::string getName() const override { return name; }\n-    bool hasStaticStructure() const override { return true; }\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-    const char * getStorageTypeName() const override { return \"Values\"; }\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    static DataTypes getTypesFromArgument(const ASTPtr & arg, ContextPtr context);\n-\n-    ColumnsDescription structure;\n-    bool has_structure_in_arguments;\n-};\n-\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionViewIfPermitted.cpp b/src/TableFunctions/TableFunctionViewIfPermitted.cpp\nindex d7944df1b28d..b16918039889 100644\n--- a/src/TableFunctions/TableFunctionViewIfPermitted.cpp\n+++ b/src/TableFunctions/TableFunctionViewIfPermitted.cpp\n@@ -3,12 +3,13 @@\n #include <Parsers/ASTFunction.h>\n #include <Parsers/ASTLiteral.h>\n #include <Parsers/ASTSelectWithUnionQuery.h>\n+#include <Parsers/ASTCreateQuery.h>\n+#include <base/types.h>\n #include <Storages/StorageNull.h>\n #include <Storages/StorageView.h>\n #include <Storages/checkAndGetLiteralArgument.h>\n #include <TableFunctions/ITableFunction.h>\n #include <TableFunctions/TableFunctionFactory.h>\n-#include <TableFunctions/TableFunctionViewIfPermitted.h>\n #include <Interpreters/parseColumnsListForTableFunction.h>\n #include <Interpreters/evaluateConstantExpression.h>\n #include \"registerTableFunctions.h\"\n@@ -16,6 +17,7 @@\n \n namespace DB\n {\n+\n namespace ErrorCodes\n {\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n@@ -23,11 +25,37 @@ namespace ErrorCodes\n     extern const int ACCESS_DENIED;\n }\n \n+namespace\n+{\n \n-const ASTSelectWithUnionQuery & TableFunctionViewIfPermitted::getSelectQuery() const\n+/* viewIfPermitted(query ELSE null('structure'))\n+ * Works as \"view(query)\" if the current user has the permissions required to execute \"query\"; works as \"null('structure')\" otherwise.\n+ */\n+class TableFunctionViewIfPermitted : public ITableFunction\n {\n-    return *create.select;\n-}\n+public:\n+    static constexpr auto name = \"viewIfPermitted\";\n+\n+    std::string getName() const override { return name; }\n+\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const String & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+\n+    const char * getStorageTypeName() const override { return \"ViewIfPermitted\"; }\n+\n+    std::vector<size_t> skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr context) const override;\n+\n+    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+\n+    bool isPermitted(const ContextPtr & context, const ColumnsDescription & else_columns) const;\n+\n+    ASTCreateQuery create;\n+    ASTPtr else_ast;\n+    TableFunctionPtr else_table_function;\n+};\n+\n \n std::vector<size_t> TableFunctionViewIfPermitted::skipAnalysisForArguments(const QueryTreeNodePtr &, ContextPtr) const\n {\n@@ -118,6 +146,8 @@ bool TableFunctionViewIfPermitted::isPermitted(const ContextPtr & context, const\n     return true;\n }\n \n+}\n+\n void registerTableFunctionViewIfPermitted(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionViewIfPermitted>({.documentation = {}, .allow_readonly = true});\ndiff --git a/src/TableFunctions/TableFunctionViewIfPermitted.h b/src/TableFunctions/TableFunctionViewIfPermitted.h\ndeleted file mode 100644\nindex bee4e15bfa53..000000000000\n--- a/src/TableFunctions/TableFunctionViewIfPermitted.h\n+++ /dev/null\n@@ -1,40 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunction.h>\n-#include <Parsers/ASTCreateQuery.h>\n-#include <base/types.h>\n-\n-namespace DB\n-{\n-\n-/* viewIfPermitted(query ELSE null('structure'))\n- * Works as \"view(query)\" if the current user has the permissions required to execute \"query\"; works as \"null('structure')\" otherwise.\n- */\n-class TableFunctionViewIfPermitted : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = \"viewIfPermitted\";\n-\n-    std::string getName() const override { return name; }\n-\n-    const ASTSelectWithUnionQuery & getSelectQuery() const;\n-\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const String & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-\n-    const char * getStorageTypeName() const override { return \"ViewIfPermitted\"; }\n-\n-    std::vector<size_t> skipAnalysisForArguments(const QueryTreeNodePtr & query_node_table_function, ContextPtr context) const override;\n-\n-    void parseArguments(const ASTPtr & ast_function, ContextPtr context) override;\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-\n-    bool isPermitted(const ContextPtr & context, const ColumnsDescription & else_columns) const;\n-\n-    ASTCreateQuery create;\n-    ASTPtr else_ast;\n-    TableFunctionPtr else_table_function;\n-};\n-\n-}\ndiff --git a/src/TableFunctions/TableFunctionZeros.cpp b/src/TableFunctions/TableFunctionZeros.cpp\nindex eb93626590e9..f23b6540959c 100644\n--- a/src/TableFunctions/TableFunctionZeros.cpp\n+++ b/src/TableFunctions/TableFunctionZeros.cpp\n@@ -1,5 +1,4 @@\n #include <TableFunctions/ITableFunction.h>\n-#include <TableFunctions/TableFunctionZeros.h>\n #include <TableFunctions/TableFunctionFactory.h>\n #include <Parsers/ASTFunction.h>\n #include <Storages/checkAndGetLiteralArgument.h>\n@@ -15,9 +14,32 @@ namespace DB\n \n namespace ErrorCodes\n {\n-extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n+    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n }\n \n+namespace\n+{\n+\n+/* zeros(limit), zeros_mt(limit)\n+ * - the same as SELECT zero FROM system.zeros LIMIT limit.\n+ * Used for testing purposes, as a simple example of table function.\n+ */\n+template <bool multithreaded>\n+class TableFunctionZeros : public ITableFunction\n+{\n+public:\n+    static constexpr auto name = multithreaded ? \"zeros_mt\" : \"zeros\";\n+    std::string getName() const override { return name; }\n+    bool hasStaticStructure() const override { return true; }\n+private:\n+    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n+    const char * getStorageTypeName() const override { return \"SystemZeros\"; }\n+\n+    UInt64 evaluateArgument(ContextPtr context, ASTPtr & argument) const;\n+\n+    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n+};\n+\n \n template <bool multithreaded>\n ColumnsDescription TableFunctionZeros<multithreaded>::getActualTableStructure(ContextPtr /*context*/, bool /*is_insert_query*/) const\n@@ -46,6 +68,14 @@ StoragePtr TableFunctionZeros<multithreaded>::executeImpl(const ASTPtr & ast_fun\n     throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH, \"Table function '{}' requires 'limit'.\", getName());\n }\n \n+template <bool multithreaded>\n+UInt64 TableFunctionZeros<multithreaded>::evaluateArgument(ContextPtr context, ASTPtr & argument) const\n+{\n+    return checkAndGetLiteralArgument<UInt64>(evaluateConstantExpressionOrIdentifierAsLiteral(argument, context), \"length\");\n+}\n+\n+}\n+\n void registerTableFunctionZeros(TableFunctionFactory & factory)\n {\n     factory.registerFunction<TableFunctionZeros<true>>({.documentation = {\n@@ -71,13 +101,7 @@ void registerTableFunctionZeros(TableFunctionFactory & factory)\n                 See also the `system.zeros` table.\n                 )\",\n             .examples={{\"1\", \"SELECT count() FROM zeros_mt(1000000000) WHERE NOT ignore(randomPrintableASCII(10))\", \"\"}}\n-}});\n-}\n-\n-template <bool multithreaded>\n-UInt64 TableFunctionZeros<multithreaded>::evaluateArgument(ContextPtr context, ASTPtr & argument) const\n-{\n-    return checkAndGetLiteralArgument<UInt64>(evaluateConstantExpressionOrIdentifierAsLiteral(argument, context), \"length\");\n+    }});\n }\n \n }\ndiff --git a/src/TableFunctions/TableFunctionZeros.h b/src/TableFunctions/TableFunctionZeros.h\ndeleted file mode 100644\nindex 07d523ee37ca..000000000000\n--- a/src/TableFunctions/TableFunctionZeros.h\n+++ /dev/null\n@@ -1,31 +0,0 @@\n-#pragma once\n-\n-#include <TableFunctions/ITableFunction.h>\n-#include <base/types.h>\n-\n-\n-namespace DB\n-{\n-\n-/* zeros(limit), zeros_mt(limit)\n- * - the same as SELECT zero FROM system.zeros LIMIT limit.\n- * Used for testing purposes, as a simple example of table function.\n- */\n-template <bool multithreaded>\n-class TableFunctionZeros : public ITableFunction\n-{\n-public:\n-    static constexpr auto name = multithreaded ? \"zeros_mt\" : \"zeros\";\n-    std::string getName() const override { return name; }\n-    bool hasStaticStructure() const override { return true; }\n-private:\n-    StoragePtr executeImpl(const ASTPtr & ast_function, ContextPtr context, const std::string & table_name, ColumnsDescription cached_columns, bool is_insert_query) const override;\n-    const char * getStorageTypeName() const override { return \"SystemZeros\"; }\n-\n-    UInt64 evaluateArgument(ContextPtr context, ASTPtr & argument) const;\n-\n-    ColumnsDescription getActualTableStructure(ContextPtr context, bool is_insert_query) const override;\n-};\n-\n-\n-}\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01035_avg_weighted_long.reference b/tests/queries/0_stateless/01035_avg_weighted_long.reference\nindex f3efdc522b71..3d95ee5e4531 100644\n--- a/tests/queries/0_stateless/01035_avg_weighted_long.reference\n+++ b/tests/queries/0_stateless/01035_avg_weighted_long.reference\n@@ -1,7 +1,5 @@\n 2.3333333333333335\n nan\n-1\n-1\n 8\n nan\n 8\n@@ -211,20 +209,4 @@ nan\n 1\n 1\n 1\n-2\n-2\n-2\n-2\n-2\n-2\n-2\n-2\n-2\n-2\n-2\n-2\n-2\n-2\n-2\n-2\n 1\ndiff --git a/tests/queries/0_stateless/01035_avg_weighted_long.sh b/tests/queries/0_stateless/01035_avg_weighted_long.sh\nindex 8838b07a3d77..0e76d6e328d8 100755\n--- a/tests/queries/0_stateless/01035_avg_weighted_long.sh\n+++ b/tests/queries/0_stateless/01035_avg_weighted_long.sh\n@@ -7,13 +7,9 @@ CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n ${CLICKHOUSE_CLIENT} --query=\"SELECT avgWeighted(x, weight) FROM (SELECT t.1 AS x, t.2 AS weight FROM (SELECT arrayJoin([(1, 5), (2, 4), (3, 3), (4, 2), (5, 1)]) AS t));\"\n ${CLICKHOUSE_CLIENT} --query=\"SELECT avgWeighted(x, weight) FROM (SELECT t.1 AS x, t.2 AS weight FROM (SELECT arrayJoin([(1, 0), (2, 0), (3, 0), (4, 0), (5, 0)]) AS t));\"\n-${CLICKHOUSE_CLIENT} --query=\"SELECT avgWeighted(x, y) FROM (select toDecimal256(1, 0) x, toDecimal256(1, 1) y);\"\n-${CLICKHOUSE_CLIENT} --query=\"SELECT avgWeighted(x, y) FROM (select toDecimal32(1, 0) x, toDecimal256(1, 1) y);\"\n \n types=(\"Int8\" \"Int16\" \"Int32\" \"Int64\" \"UInt8\" \"UInt16\" \"UInt32\" \"UInt64\" \"Float32\" \"Float64\")\n exttypes=(\"Int128\" \"Int256\" \"UInt256\")\n-# Decimal types\n-dtypes=(\"32\" \"64\" \"128\" \"256\")\n \n (\n     for left in \"${types[@]}\"\n@@ -32,14 +28,6 @@ dtypes=(\"32\" \"64\" \"128\" \"256\")\n             echo \"SELECT avgWeighted(to${left}(1), to${right}(2));\"\n         done\n     done\n-\n-    for left in \"${dtypes[@]}\"\n-    do\n-        for right in \"${dtypes[@]}\"\n-        do\n-            echo \"SELECT avgWeighted(toDecimal${left}(2, 4), toDecimal${right}(1, 4));\"\n-        done\n-    done\n ) | clickhouse-client -nm\n \n echo \"$(${CLICKHOUSE_CLIENT} --server_logs_file=/dev/null --query=\"SELECT avgWeighted(['string'], toFloat64(0))\" 2>&1)\" \\\ndiff --git a/tests/queries/0_stateless/01668_avg_weighted_ubsan.reference b/tests/queries/0_stateless/01668_avg_weighted_ubsan.reference\nindex a8921b27cffc..ec064f61ba77 100644\n--- a/tests/queries/0_stateless/01668_avg_weighted_ubsan.reference\n+++ b/tests/queries/0_stateless/01668_avg_weighted_ubsan.reference\n@@ -1,14 +1,1 @@\n -0\n-nan\n-nan\n-1\n-2\n-3\n-4\n-5\n-6\n-7\n-8\n-9\n-nan\n-nan\ndiff --git a/tests/queries/0_stateless/01668_avg_weighted_ubsan.sql b/tests/queries/0_stateless/01668_avg_weighted_ubsan.sql\nindex 1c31c23eaee3..24e7dc0cb90d 100644\n--- a/tests/queries/0_stateless/01668_avg_weighted_ubsan.sql\n+++ b/tests/queries/0_stateless/01668_avg_weighted_ubsan.sql\n@@ -1,5 +1,1 @@\n SELECT round(avgWeighted(x, y)) FROM (SELECT 1023 AS x, 1000000000 AS y UNION ALL SELECT 10 AS x, -9223372036854775808 AS y);\n-select avgWeighted(number, toDecimal128(number, 9)) from numbers(0);\n-SELECT avgWeighted(a, toDecimal64(c, 9)) OVER (PARTITION BY c) FROM (SELECT number AS a, number AS c FROM numbers(10));\n-select avg(toDecimal128(number, 9)) from numbers(0);\n-select avgWeighted(number, toDecimal128(0, 9)) from numbers(10);\ndiff --git a/tests/queries/0_stateless/02912_group_array_sample.reference b/tests/queries/0_stateless/02912_group_array_sample.reference\nnew file mode 100644\nindex 000000000000..d00491fd7e5b\n--- /dev/null\n+++ b/tests/queries/0_stateless/02912_group_array_sample.reference\n@@ -0,0 +1,1 @@\n+1\ndiff --git a/tests/queries/0_stateless/02912_group_array_sample.sql b/tests/queries/0_stateless/02912_group_array_sample.sql\nnew file mode 100644\nindex 000000000000..6cf9d45170b1\n--- /dev/null\n+++ b/tests/queries/0_stateless/02912_group_array_sample.sql\n@@ -0,0 +1,2 @@\n+-- Checks that the random seed is different for multiple states of aggregation:\n+SELECT uniq(x) > 50 FROM (SELECT number, groupArraySample(10)(arrayJoin(range(1000))) AS x FROM numbers(100) GROUP BY number);\ndiff --git a/tests/queries/0_stateless/02913_sum_map_state.reference b/tests/queries/0_stateless/02913_sum_map_state.reference\nnew file mode 100644\nindex 000000000000..bfe24f39796b\n--- /dev/null\n+++ b/tests/queries/0_stateless/02913_sum_map_state.reference\n@@ -0,0 +1,1 @@\n+0200000000010000000000000000000000000000000100000002000000000000000000000000000000\ndiff --git a/tests/queries/0_stateless/02913_sum_map_state.sql b/tests/queries/0_stateless/02913_sum_map_state.sql\nnew file mode 100644\nindex 000000000000..9f4fd27bb2dc\n--- /dev/null\n+++ b/tests/queries/0_stateless/02913_sum_map_state.sql\n@@ -0,0 +1,1 @@\n+SELECT hex(sumMappedArraysState([CAST('0.1', 'Decimal(3)'), CAST('1', 'Decimal(3)')], [CAST('1.2', 'Decimal(3)'), CAST('2', 'Decimal(3)')]));\n",
  "problem_statement": "MemorySanitizer: use-of-uninitialized-value ParallelFormattingOutputFormat\nhttps://s3.amazonaws.com/clickhouse-test-reports/0/c911c8daf4bd626315d6b67f35ed7ea0f6c476ce/stress_test__msan_.html\r\n```\r\n==2319==WARNING: MemorySanitizer: use-of-uninitialized-value\r\n    #0 0x55d1f880abe4 in std::__1::basic_streambuf<char, std::__1::char_traits<char>>::xsputn(char const*, long) build_docker/./contrib/llvm-project/libcxx/include/streambuf:467:17\r\n    #1 0x55d1f881ad73 in std::__1::basic_streambuf<char, std::__1::char_traits<char>>::sputn[abi:v15000](char const*, long) build_docker/./contrib/llvm-project/libcxx/include/streambuf:232:14\r\n    #2 0x55d1f881ad73 in std::__1::basic_ostream<char, std::__1::char_traits<char>>::write(char const*, long) build_docker/./contrib/llvm-project/libcxx/include/ostream:959:32\r\n    #3 0x55d1cd395182 in DB::WriteBufferFromOStream::nextImpl() build_docker/./src/IO/WriteBufferFromOStream.cpp:18:11\r\n    #4 0x55d1ea006528 in DB::WriteBuffer::next() build_docker/./src/IO/WriteBuffer.h:48:13\r\n    #5 0x55d1ea006528 in DB::WriteBufferFromHTTPServerResponse::nextImpl() build_docker/./src/Server/HTTP/WriteBufferFromHTTPServerResponse.cpp:135:14\r\n    #6 0x55d1b60f75e2 in DB::WriteBuffer::write(char const*, unsigned long) (/usr/bin/clickhouse+0x87d35e2) (BuildId: 4f9913e1b62e9bb16da6d33ab81450962130a50a)\r\n    #7 0x55d1ea66a8a2 in DB::ParallelFormattingOutputFormat::collectorThreadFunction(std::__1::shared_ptr<DB::ThreadGroup> const&) build_docker/./src/Processors/Formats/Impl/ParallelFormattingOutputFormat.cpp:158:21\r\n    #8 0x55d1ea03ea91 in DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()::operator()() const build_docker/./src/Processors/Formats/Impl/ParallelFormattingOutputFormat.h:102:13\r\n    #9 0x55d1ea03ea91 in decltype(std::declval<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&>()()) std::__1::__invoke[abi:v15000]<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #10 0x55d1ea03ea91 in decltype(auto) std::__1::__apply_tuple_impl[abi:v15000]<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&, std::__1::__tuple_indices<>) build_docker/./contrib/llvm-project/libcxx/include/tuple:1789:1\r\n    #11 0x55d1ea03ea91 in decltype(auto) std::__1::apply[abi:v15000]<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&) build_docker/./contrib/llvm-project/libcxx/include/tuple:1798:1\r\n    #12 0x55d1ea03ea91 in ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()::operator()() build_docker/./src/Common/ThreadPool.h:242:13\r\n    #13 0x55d1ea03e8de in decltype(std::declval<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>()()) std::__1::__invoke[abi:v15000]<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #14 0x55d1ea03e8de in void std::__1::__invoke_void_return_wrapper<void, true>::__call<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()&>(ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:479:9\r\n    #15 0x55d1ea03e8de in std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'(), void ()>::operator()[abi:v15000]() build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:235:12\r\n    #16 0x55d1ea03e8de in void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'(), void ()>>(std::__1::__function::__policy_storage const*) build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:716:16\r\n    #17 0x55d1cd188e8e in std::__1::__function::__policy_func<void ()>::operator()[abi:v15000]() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:848:16\r\n    #18 0x55d1cd188e8e in std::__1::function<void ()>::operator()() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:1187:12\r\n    #19 0x55d1cd188e8e in ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) build_docker/./src/Common/ThreadPool.cpp:426:13\r\n    #20 0x55d1cd197b0a in void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()::operator()() const build_docker/./src/Common/ThreadPool.cpp:179:73\r\n    #21 0x55d1cd197b0a in decltype(std::declval<void>()()) std::__1::__invoke[abi:v15000]<void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #22 0x55d1cd197b0a in void std::__1::__thread_execute[abi:v15000]<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(std::__1::tuple<void, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>&, std::__1::__tuple_indices<>) build_docker/./contrib/llvm-project/libcxx/include/thread:284:5\r\n    #23 0x55d1cd197b0a in void* std::__1::__thread_proxy[abi:v15000]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>>(void*) build_docker/./contrib/llvm-project/libcxx/include/thread:295:5\r\n    #24 0x7f2e7c482b42  (/lib/x86_64-linux-gnu/libc.so.6+0x94b42) (BuildId: 229b7dc509053fe4df5e29e8629911f0c3bc66dd)\r\n    #25 0x7f2e7c5149ff  (/lib/x86_64-linux-gnu/libc.so.6+0x1269ff) (BuildId: 229b7dc509053fe4df5e29e8629911f0c3bc66dd)\r\n\r\n  Uninitialized value was stored to memory at\r\n    #0 0x55d1f880abdd in std::__1::basic_streambuf<char, std::__1::char_traits<char>>::xsputn(char const*, long) build_docker/./contrib/llvm-project/libcxx/include/streambuf:467:51\r\n    #1 0x55d1f881ad73 in std::__1::basic_streambuf<char, std::__1::char_traits<char>>::sputn[abi:v15000](char const*, long) build_docker/./contrib/llvm-project/libcxx/include/streambuf:232:14\r\n    #2 0x55d1f881ad73 in std::__1::basic_ostream<char, std::__1::char_traits<char>>::write(char const*, long) build_docker/./contrib/llvm-project/libcxx/include/ostream:959:32\r\n    #3 0x55d1cd395182 in DB::WriteBufferFromOStream::nextImpl() build_docker/./src/IO/WriteBufferFromOStream.cpp:18:11\r\n    #4 0x55d1ea006528 in DB::WriteBuffer::next() build_docker/./src/IO/WriteBuffer.h:48:13\r\n    #5 0x55d1ea006528 in DB::WriteBufferFromHTTPServerResponse::nextImpl() build_docker/./src/Server/HTTP/WriteBufferFromHTTPServerResponse.cpp:135:14\r\n    #6 0x55d1b60f75e2 in DB::WriteBuffer::write(char const*, unsigned long) (/usr/bin/clickhouse+0x87d35e2) (BuildId: 4f9913e1b62e9bb16da6d33ab81450962130a50a)\r\n    #7 0x55d1ea66a8a2 in DB::ParallelFormattingOutputFormat::collectorThreadFunction(std::__1::shared_ptr<DB::ThreadGroup> const&) build_docker/./src/Processors/Formats/Impl/ParallelFormattingOutputFormat.cpp:158:21\r\n    #8 0x55d1ea03ea91 in DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()::operator()() const build_docker/./src/Processors/Formats/Impl/ParallelFormattingOutputFormat.h:102:13\r\n    #9 0x55d1ea03ea91 in decltype(std::declval<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&>()()) std::__1::__invoke[abi:v15000]<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #10 0x55d1ea03ea91 in decltype(auto) std::__1::__apply_tuple_impl[abi:v15000]<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&, std::__1::__tuple_indices<>) build_docker/./contrib/llvm-project/libcxx/include/tuple:1789:1\r\n    #11 0x55d1ea03ea91 in decltype(auto) std::__1::apply[abi:v15000]<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&) build_docker/./contrib/llvm-project/libcxx/include/tuple:1798:1\r\n    #12 0x55d1ea03ea91 in ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()::operator()() build_docker/./src/Common/ThreadPool.h:242:13\r\n    #13 0x55d1ea03e8de in decltype(std::declval<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>()()) std::__1::__invoke[abi:v15000]<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #14 0x55d1ea03e8de in void std::__1::__invoke_void_return_wrapper<void, true>::__call<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()&>(ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:479:9\r\n    #15 0x55d1ea03e8de in std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'(), void ()>::operator()[abi:v15000]() build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:235:12\r\n    #16 0x55d1ea03e8de in void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'(), void ()>>(std::__1::__function::__policy_storage const*) build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:716:16\r\n    #17 0x55d1cd188e8e in std::__1::__function::__policy_func<void ()>::operator()[abi:v15000]() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:848:16\r\n    #18 0x55d1cd188e8e in std::__1::function<void ()>::operator()() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:1187:12\r\n    #19 0x55d1cd188e8e in ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) build_docker/./src/Common/ThreadPool.cpp:426:13\r\n    #20 0x55d1cd197b0a in void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()::operator()() const build_docker/./src/Common/ThreadPool.cpp:179:73\r\n    #21 0x55d1cd197b0a in decltype(std::declval<void>()()) std::__1::__invoke[abi:v15000]<void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #22 0x55d1cd197b0a in void std::__1::__thread_execute[abi:v15000]<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(std::__1::tuple<void, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>&, std::__1::__tuple_indices<>) build_docker/./contrib/llvm-project/libcxx/include/thread:284:5\r\n    #23 0x55d1cd197b0a in void* std::__1::__thread_proxy[abi:v15000]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>>(void*) build_docker/./contrib/llvm-project/libcxx/include/thread:295:5\r\n    #24 0x7f2e7c482b42  (/lib/x86_64-linux-gnu/libc.so.6+0x94b42) (BuildId: 229b7dc509053fe4df5e29e8629911f0c3bc66dd)\r\n\r\n  Uninitialized value was stored to memory at\r\n    #0 0x55d1b60055ca in __msan_memcpy (/usr/bin/clickhouse+0x86e15ca) (BuildId: 4f9913e1b62e9bb16da6d33ab81450962130a50a)\r\n    #1 0x55d1b60f7693 in DB::WriteBuffer::write(char const*, unsigned long) (/usr/bin/clickhouse+0x87d3693) (BuildId: 4f9913e1b62e9bb16da6d33ab81450962130a50a)\r\n    #2 0x55d1ea66a8a2 in DB::ParallelFormattingOutputFormat::collectorThreadFunction(std::__1::shared_ptr<DB::ThreadGroup> const&) build_docker/./src/Processors/Formats/Impl/ParallelFormattingOutputFormat.cpp:158:21\r\n    #3 0x55d1ea03ea91 in DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()::operator()() const build_docker/./src/Processors/Formats/Impl/ParallelFormattingOutputFormat.h:102:13\r\n    #4 0x55d1ea03ea91 in decltype(std::declval<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&>()()) std::__1::__invoke[abi:v15000]<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #5 0x55d1ea03ea91 in decltype(auto) std::__1::__apply_tuple_impl[abi:v15000]<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&, std::__1::__tuple_indices<>) build_docker/./contrib/llvm-project/libcxx/include/tuple:1789:1\r\n    #6 0x55d1ea03ea91 in decltype(auto) std::__1::apply[abi:v15000]<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&, std::__1::tuple<>&) build_docker/./contrib/llvm-project/libcxx/include/tuple:1798:1\r\n    #7 0x55d1ea03ea91 in ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()::operator()() build_docker/./src/Common/ThreadPool.h:242:13\r\n    #8 0x55d1ea03e8de in decltype(std::declval<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>()()) std::__1::__invoke[abi:v15000]<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()&>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #9 0x55d1ea03e8de in void std::__1::__invoke_void_return_wrapper<void, true>::__call<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()&>(ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:479:9\r\n    #10 0x55d1ea03e8de in std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'(), void ()>::operator()[abi:v15000]() build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:235:12\r\n    #11 0x55d1ea03e8de in void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()>(DB::ParallelFormattingOutputFormat::ParallelFormattingOutputFormat(DB::ParallelFormattingOutputFormat::Params)::'lambda'()&&)::'lambda'(), void ()>>(std::__1::__function::__policy_storage const*) build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:716:16\r\n    #12 0x55d1cd188e8e in std::__1::__function::__policy_func<void ()>::operator()[abi:v15000]() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:848:16\r\n    #13 0x55d1cd188e8e in std::__1::function<void ()>::operator()() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:1187:12\r\n    #14 0x55d1cd188e8e in ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) build_docker/./src/Common/ThreadPool.cpp:426:13\r\n    #15 0x55d1cd197b0a in void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()::operator()() const build_docker/./src/Common/ThreadPool.cpp:179:73\r\n    #16 0x55d1cd197b0a in decltype(std::declval<void>()()) std::__1::__invoke[abi:v15000]<void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #17 0x55d1cd197b0a in void std::__1::__thread_execute[abi:v15000]<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(std::__1::tuple<void, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>&, std::__1::__tuple_indices<>) build_docker/./contrib/llvm-project/libcxx/include/thread:284:5\r\n    #18 0x55d1cd197b0a in void* std::__1::__thread_proxy[abi:v15000]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>>(void*) build_docker/./contrib/llvm-project/libcxx/include/thread:295:5\r\n    #19 0x7f2e7c482b42  (/lib/x86_64-linux-gnu/libc.so.6+0x94b42) (BuildId: 229b7dc509053fe4df5e29e8629911f0c3bc66dd)\r\n\r\n  Uninitialized value was stored to memory at\r\n    #0 0x55d1b600e84a in realloc (/usr/bin/clickhouse+0x86ea84a) (BuildId: 4f9913e1b62e9bb16da6d33ab81450962130a50a)\r\n    #1 0x55d1ccd978a7 in Allocator<false, false>::realloc(void*, unsigned long, unsigned long, unsigned long) build_docker/./src/Common/Allocator.h:118:30\r\n    #2 0x55d1cd0005a3 in DB::Memory<Allocator<false, false>>::resize(unsigned long) build_docker/./src/IO/BufferWithOwnMemory.h:101:49\r\n    #3 0x55d1ea66ee73 in DB::BufferWithOutsideMemory<DB::WriteBuffer>::nextImpl() build_docker/./src/IO/BufferWithOwnMemory.h:191:16\r\n    #4 0x55d1ea14279c in DB::WriteBuffer::next() build_docker/./src/IO/WriteBuffer.h:48:13\r\n    #5 0x55d1ea14279c in DB::IOutputFormat::flush() build_docker/./src/Processors/Formats/IOutputFormat.cpp:169:9\r\n    #6 0x55d1ea562322 in DB::OutputFormatWithUTF8ValidationAdaptorBase<DB::IRowOutputFormat>::flush() build_docker/./src/Processors/Formats/OutputFormatWithUTF8ValidationAdaptor.h:36:15\r\n    #7 0x55d1ea5613e2 in DB::RowOutputFormatWithExceptionHandlerAdaptor<DB::OutputFormatWithUTF8ValidationAdaptorBase<DB::IRowOutputFormat>, bool>::flush() build_docker/./src/Processors/Formats/RowOutputFormatWithExceptionHandlerAdaptor.h:66:15\r\n    #8 0x55d1ea66bd13 in DB::ParallelFormattingOutputFormat::formatterThreadFunction(unsigned long, unsigned long, std::__1::shared_ptr<DB::ThreadGroup> const&) build_docker/./src/Processors/Formats/Impl/ParallelFormattingOutputFormat.cpp:264:24\r\n    #9 0x55d1ea66ea82 in DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()::operator()() const build_docker/./src/Processors/Formats/Impl/ParallelFormattingOutputFormat.h:299:13\r\n    #10 0x55d1ea66ea82 in decltype(std::declval<DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()&>()()) std::__1::__invoke[abi:v15000]<DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()&>(DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #11 0x55d1ea66ea82 in void std::__1::__invoke_void_return_wrapper<void, true>::__call<DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()&>(DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:479:9\r\n    #12 0x55d1ea66ea82 in std::__1::__function::__default_alloc_func<DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'(), void ()>::operator()[abi:v15000]() build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:235:12\r\n    #13 0x55d1ea66ea82 in void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'(), void ()>>(std::__1::__function::__policy_storage const*) build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:716:16\r\n    #14 0x55d1cd19250e in std::__1::__function::__policy_func<void ()>::operator()[abi:v15000]() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:848:16\r\n    #15 0x55d1cd19250e in std::__1::function<void ()>::operator()() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:1187:12\r\n    #16 0x55d1cd19250e in ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::worker(std::__1::__list_iterator<ThreadFromGlobalPoolImpl<false>, void*>) build_docker/./src/Common/ThreadPool.cpp:426:13\r\n    #17 0x55d1cd19e292 in void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()::operator()() const build_docker/./src/Common/ThreadPool.cpp:179:73\r\n    #18 0x55d1cd19e292 in decltype(std::declval<void>()()) std::__1::__invoke[abi:v15000]<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()&>(void&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #19 0x55d1cd19e292 in decltype(auto) std::__1::__apply_tuple_impl[abi:v15000]<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()&, std::__1::tuple<>&>(void&&, std::__1::tuple<>&, std::__1::__tuple_indices<>) build_docker/./contrib/llvm-project/libcxx/include/tuple:1789:1\r\n    #20 0x55d1cd19e292 in decltype(auto) std::__1::apply[abi:v15000]<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()&, std::__1::tuple<>&>(void&&, std::__1::tuple<>&) build_docker/./contrib/llvm-project/libcxx/include/tuple:1798:1\r\n    #21 0x55d1cd19e292 in ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'()::operator()() build_docker/./src/Common/ThreadPool.h:242:13\r\n    #22 0x55d1cd19e13e in decltype(std::declval<void>()()) std::__1::__invoke[abi:v15000]<ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'()&>(void&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #23 0x55d1cd19e13e in void std::__1::__invoke_void_return_wrapper<void, true>::__call<ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'()&>(ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:479:9\r\n    #24 0x55d1cd19e13e in std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'(), void ()>::operator()[abi:v15000]() build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:235:12\r\n    #25 0x55d1cd19e13e in void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'(), void ()>>(std::__1::__function::__policy_storage const*) build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:716:16\r\n    #26 0x55d1cd188e8e in std::__1::__function::__policy_func<void ()>::operator()[abi:v15000]() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:848:16\r\n    #27 0x55d1cd188e8e in std::__1::function<void ()>::operator()() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:1187:12\r\n    #28 0x55d1cd188e8e in ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) build_docker/./src/Common/ThreadPool.cpp:426:13\r\n    #29 0x55d1cd197b0a in void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()::operator()() const build_docker/./src/Common/ThreadPool.cpp:179:73\r\n    #30 0x55d1cd197b0a in decltype(std::declval<void>()()) std::__1::__invoke[abi:v15000]<void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #31 0x55d1cd197b0a in void std::__1::__thread_execute[abi:v15000]<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(std::__1::tuple<void, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>&, std::__1::__tuple_indices<>) build_docker/./contrib/llvm-project/libcxx/include/thread:284:5\r\n    #32 0x55d1cd197b0a in void* std::__1::__thread_proxy[abi:v15000]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>>(void*) build_docker/./contrib/llvm-project/libcxx/include/thread:295:5\r\n    #33 0x7f2e7c482b42  (/lib/x86_64-linux-gnu/libc.so.6+0x94b42) (BuildId: 229b7dc509053fe4df5e29e8629911f0c3bc66dd)\r\n\r\n  Uninitialized value was created by a heap allocation\r\n    #0 0x55d1b600e84a in realloc (/usr/bin/clickhouse+0x86ea84a) (BuildId: 4f9913e1b62e9bb16da6d33ab81450962130a50a)\r\n    #1 0x55d1ccd978a7 in Allocator<false, false>::realloc(void*, unsigned long, unsigned long, unsigned long) build_docker/./src/Common/Allocator.h:118:30\r\n    #2 0x55d1cd0005a3 in DB::Memory<Allocator<false, false>>::resize(unsigned long) build_docker/./src/IO/BufferWithOwnMemory.h:101:49\r\n    #3 0x55d1ea66ee73 in DB::BufferWithOutsideMemory<DB::WriteBuffer>::nextImpl() build_docker/./src/IO/BufferWithOwnMemory.h:191:16\r\n    #4 0x55d1b60f75e2 in DB::WriteBuffer::write(char const*, unsigned long) (/usr/bin/clickhouse+0x87d35e2) (BuildId: 4f9913e1b62e9bb16da6d33ab81450962130a50a)\r\n    #5 0x55d1cd01b2d4 in DB::WriteBufferValidUTF8::putValid(char*, unsigned long) build_docker/./src/IO/WriteBufferValidUTF8.cpp:63:19\r\n    #6 0x55d1cd01b2d4 in DB::WriteBufferValidUTF8::nextImpl() build_docker/./src/IO/WriteBufferValidUTF8.cpp:131:5\r\n    #7 0x55d1b60f75e2 in DB::WriteBuffer::write(char const*, unsigned long) (/usr/bin/clickhouse+0x87d35e2) (BuildId: 4f9913e1b62e9bb16da6d33ab81450962130a50a)\r\n    #8 0x55d1ea565378 in DB::PeekableWriteBuffer::dropCheckpoint() build_docker/./src/IO/PeekableWriteBuffer.cpp:50:21\r\n    #9 0x55d1ea56185b in DB::RowOutputFormatWithExceptionHandlerAdaptor<DB::OutputFormatWithUTF8ValidationAdaptorBase<DB::IRowOutputFormat>, bool>::consume(DB::Chunk) build_docker/./src/Processors/Formats/RowOutputFormatWithExceptionHandlerAdaptor.h:52:27\r\n    #10 0x55d1ea66bc59 in DB::ParallelFormattingOutputFormat::formatterThreadFunction(unsigned long, unsigned long, std::__1::shared_ptr<DB::ThreadGroup> const&) build_docker/./src/Processors/Formats/Impl/ParallelFormattingOutputFormat.cpp:235:32\r\n    #11 0x55d1ea66ea82 in DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()::operator()() const build_docker/./src/Processors/Formats/Impl/ParallelFormattingOutputFormat.h:299:13\r\n    #12 0x55d1ea66ea82 in decltype(std::declval<DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()&>()()) std::__1::__invoke[abi:v15000]<DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()&>(DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #13 0x55d1ea66ea82 in void std::__1::__invoke_void_return_wrapper<void, true>::__call<DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()&>(DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:479:9\r\n    #14 0x55d1ea66ea82 in std::__1::__function::__default_alloc_func<DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'(), void ()>::operator()[abi:v15000]() build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:235:12\r\n    #15 0x55d1ea66ea82 in void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<DB::ParallelFormattingOutputFormat::scheduleFormatterThreadForUnitWithNumber(unsigned long, unsigned long)::'lambda'(), void ()>>(std::__1::__function::__policy_storage const*) build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:716:16\r\n    #16 0x55d1cd19250e in std::__1::__function::__policy_func<void ()>::operator()[abi:v15000]() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:848:16\r\n    #17 0x55d1cd19250e in std::__1::function<void ()>::operator()() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:1187:12\r\n    #18 0x55d1cd19250e in ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::worker(std::__1::__list_iterator<ThreadFromGlobalPoolImpl<false>, void*>) build_docker/./src/Common/ThreadPool.cpp:426:13\r\n    #19 0x55d1cd19e292 in void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()::operator()() const build_docker/./src/Common/ThreadPool.cpp:179:73\r\n    #20 0x55d1cd19e292 in decltype(std::declval<void>()()) std::__1::__invoke[abi:v15000]<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()&>(void&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #21 0x55d1cd19e292 in decltype(auto) std::__1::__apply_tuple_impl[abi:v15000]<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()&, std::__1::tuple<>&>(void&&, std::__1::tuple<>&, std::__1::__tuple_indices<>) build_docker/./contrib/llvm-project/libcxx/include/tuple:1789:1\r\n    #22 0x55d1cd19e292 in decltype(auto) std::__1::apply[abi:v15000]<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()&, std::__1::tuple<>&>(void&&, std::__1::tuple<>&) build_docker/./contrib/llvm-project/libcxx/include/tuple:1798:1\r\n    #23 0x55d1cd19e292 in ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'()::operator()() build_docker/./src/Common/ThreadPool.h:242:13\r\n    #24 0x55d1cd19e13e in decltype(std::declval<void>()()) std::__1::__invoke[abi:v15000]<ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'()&>(void&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #25 0x55d1cd19e13e in void std::__1::__invoke_void_return_wrapper<void, true>::__call<ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'()&>(ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'()&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:479:9\r\n    #26 0x55d1cd19e13e in std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'(), void ()>::operator()[abi:v15000]() build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:235:12\r\n    #27 0x55d1cd19e13e in void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'(), void ()>>(std::__1::__function::__policy_storage const*) build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:716:16\r\n    #28 0x55d1cd188e8e in std::__1::__function::__policy_func<void ()>::operator()[abi:v15000]() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:848:16\r\n    #29 0x55d1cd188e8e in std::__1::function<void ()>::operator()() const build_docker/./contrib/llvm-project/libcxx/include/__functional/function.h:1187:12\r\n    #30 0x55d1cd188e8e in ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) build_docker/./src/Common/ThreadPool.cpp:426:13\r\n    #31 0x55d1cd197b0a in void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()::operator()() const build_docker/./src/Common/ThreadPool.cpp:179:73\r\n    #32 0x55d1cd197b0a in decltype(std::declval<void>()()) std::__1::__invoke[abi:v15000]<void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&) build_docker/./contrib/llvm-project/libcxx/include/__functional/invoke.h:394:23\r\n    #33 0x55d1cd197b0a in void std::__1::__thread_execute[abi:v15000]<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>(std::__1::tuple<void, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>&, std::__1::__tuple_indices<>) build_docker/./contrib/llvm-project/libcxx/include/thread:284:5\r\n    #34 0x55d1cd197b0a in void* std::__1::__thread_proxy[abi:v15000]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, Priority, std::__1::optional<unsigned long>, bool)::'lambda0'()>>(void*) build_docker/./contrib/llvm-project/libcxx/include/thread:295:5\r\n    #35 0x7f2e7c482b42  (/lib/x86_64-linux-gnu/libc.so.6+0x94b42) (BuildId: 229b7dc509053fe4df5e29e8629911f0c3bc66dd)\r\n\r\nSUMMARY: MemorySanitizer: use-of-uninitialized-value build_docker/./contrib/llvm-project/libcxx/include/streambuf:467:17 in std::__1::basic_streambuf<char, std::__1::char_traits<char>>::xsputn(char const*, long)\r\n```\n",
  "hints_text": "https://s3.amazonaws.com/clickhouse-test-reports/55123/558b2ff7b9e8da32986714f9642bbd163a032ef6/stress_test__msan_.html\nHere more clean logs with the same problem\r\n\r\nhttps://s3.amazonaws.com/clickhouse-test-reports/55566/a58d00f492216c685b9010bf35446b4f1062569e/stress_test__msan_/stderr.log\r\n\r\nI spend a day and I did not find the error.\r\n\r\nSome context:\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/f899254e2c6498688b5643d3804844673424dd0e/src/Processors/Formats/Impl/ParallelFormattingOutputFormat.cpp#L214\r\nHere some uninitalized memory are stored at unit.segment.data() by malloc;\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/f899254e2c6498688b5643d3804844673424dd0e/src/Processors/Formats/Impl/ParallelFormattingOutputFormat.cpp#L217\r\nThe buffer created upon that memory. But it is a write buffer. All the data which is rewritten by that buffer is legitimate to be read after.\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/f899254e2c6498688b5643d3804844673424dd0e/src/Processors/Formats/Impl/ParallelFormattingOutputFormat.cpp#L267 \r\nHere the size of written data is stored.\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/f899254e2c6498688b5643d3804844673424dd0e/src/Processors/Formats/Impl/ParallelFormattingOutputFormat.cpp#L158\r\nMemory sanitizer shows that uninitalized data has been read here.\r\nBut as I see, only written data could be read here.\r\n\r\n\r\nHere the core dump\r\nhttps://s3.amazonaws.com/clickhouse-test-reports/55566/a58d00f492216c685b9010bf35446b4f1062569e/stress_test__msan_/gdb.log\r\n\r\n```\r\nunit = @0x7210004028e0: \r\n\r\nstatus = DB::ParallelFormattingOutputFormat::READY_TO_READ}, \r\n\r\ntype = DB::ParallelFormattingOutputFormat::ProcessingUnitType::PLAIN,\r\n\r\nchunk = {empty}, \r\n\r\nsegment = { \r\n     static pad_right = 63, \r\n     m_capacity = 1048639, \r\n     m_size = 592321, \r\n     m_data = 0x7f2c37b38000 \"[\\\"2014-03-17 04:02:52\\\", \\\"\\\", \\\"\\314\\305:\\363[\\240\\\\u0003Uc\\203\\270m\\237\\325\\374\\\\u001A\\\"]\\n[\\\"2014-03-17 04:02:52\\\", \\\"LG Optimus\\\", \\\"\\314\\305:\\363[\\240\\\\u0003Uc\\203\\270m\\237\\325\\374\\\\u001A\\\"]\\n[\\\"2014-03-17 04:02:52\\\", \\\"LG Optimus\\\", \\\"\\314\\305:\\363[\\240\\\\u0003Uc\\203\\270m\\237\\325\\374\\\\u001A\\\"]\\n[\\\"2014\"..., \r\n     alignment = 0\r\n}, \r\n\r\nactual_memory_size = 1344736, \r\n\r\nstatistics = {watch = {start_ns = 2177357817268, stop_ns = 0, clock_type = 4, is_running = true}, \r\nprogress = {read_rows =  0, read_bytes =  0, total_rows_to_read = 0, total_bytes_to_read =  0, written_rows = 0, written_bytes = 0, result_rows = 0, result_bytes = 0, elapsed_ns = 0}, applied_limit = false, rows_before_limit = 0, totals = {}, num_rows = 0, chunk_info = {}, \r\n\r\nrows_num = 22858\r\n```\r\n\r\nThis is bad:\r\n```\r\nsegment.m_size = 592321\r\nsegment.m_capacity = 1048639 (this is NOT DBMS_DEFAULT_BUFFER_SIZE 1048576ULL)\r\nactual_memory_size = 1344736  \r\nDBMS_DEFAULT_BUFFER_SIZE = 1048576\r\n``",
  "created_at": "2023-11-06T00:13:41Z"
}