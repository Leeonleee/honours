diff --git a/dbms/tests/external_dictionaries/generate_and_test.py b/dbms/tests/external_dictionaries/generate_and_test.py
index 9c775610b2dc..98b673453268 100755
--- a/dbms/tests/external_dictionaries/generate_and_test.py
+++ b/dbms/tests/external_dictionaries/generate_and_test.py
@@ -7,6 +7,7 @@
 import time
 import lxml.etree as et
 import atexit
+import fnmatch
 from itertools import chain
 from os import system
 from argparse import ArgumentParser
@@ -136,8 +137,16 @@ def generate_structure(args):
             # [ 'library_c_complex_mixed_key_cache', 2, False ],
         ])
 
+    for range_hashed_range_type in range_hashed_range_types:
+        base_name = 'range_hashed_' + range_hashed_range_type
+        dictionaries.extend([
+            [ 'file_' + base_name, 3, False ],
+            # [ 'clickhouse_' + base_name, 3, True ],
+            # [ 'executable_flat' + base_name, 3, True ]
+        ])
 
-files = [ 'key_simple.tsv', 'key_complex_integers.tsv', 'key_complex_mixed.tsv' ]
+
+files = [ 'key_simple.tsv', 'key_complex_integers.tsv', 'key_complex_mixed.tsv', 'key_range_hashed_{range_hashed_range_type}.tsv' ]
 
 
 types = [
@@ -166,6 +175,37 @@ def generate_structure(args):
     '2015-11-25', '2015-11-25 00:00:00', "550e8400-e29b-41d4-a716-446655440000"
 ]
 
+range_hashed_range_types = [
+    '', # default type (Date) for compatibility with older versions
+    'UInt8', 'UInt16', 'UInt32', 'UInt64',
+    'Int8', 'Int16', 'Int32', 'Int64',
+    'Date', 'DateTime'
+]
+
+# values for range_hashed dictionary according to range_min/range_max type.
+range_hashed_dictGet_values = {
+    # [(range_min, range_max), (hit, ...), (miss, ...)]
+    # due to the nature of reference results, there should be equal number of hit and miss cases.
+    'UInt8':  [('1', '10'), ('1', '5', '10'), ('0', '11', '255')],
+    'UInt16': [('1', '10'), ('1', '5', '10'), ('0', '11', '65535')],
+    'UInt32': [('1', '10'), ('1', '5', '10'), ('0', '11', '4294967295')],
+    'UInt64': [('1', '10'), ('1', '5', '10'), ('0', '11', '18446744073709551605')],
+    'Int8':   [('-10', '10'), ('-10', '0', '10'), ('-11', '11', '255')],
+    'Int16':  [('-10', '10'), ('-10', '0', '10'), ('-11', '11', '65535')],
+    'Int32':  [('-10', '10'), ('-10', '0', '10'), ('-11', '11', '4294967295')],
+    'Int64':  [('-10', '10'), ('-10', '0', '10'), ('-11', '11', '18446744073709551605')],
+    # default type (Date) for compatibility with older versions:
+    '':         [("toDate('2015-11-20')", "toDate('2015-11-25')"),
+                 ("toDate('2015-11-20')", "toDate('2015-11-22')", "toDate('2015-11-25')"),
+                 ("toDate('2015-11-19')", "toDate('2015-11-26')", "toDate('2018-09-14')")],
+    'Date':     [("toDate('2015-11-20')", "toDate('2015-11-25')"),
+                 ("toDate('2015-11-20')", "toDate('2015-11-22')", "toDate('2015-11-25')"),
+                 ("toDate('2015-11-19')", "toDate('2015-11-26')", "toDate('2018-09-14')")],
+    'DateTime': [("toDateTime('2015-11-20 00:00:00')", "toDateTime('2015-11-25 00:00:00')"),
+                 ("toDateTime('2015-11-20 00:00:00')", "toDateTime('2015-11-22 00:00:00')", "toDateTime('2015-11-25 00:00:00')"),
+                 ("toDateTime('2015-11-19 23:59:59')", "toDateTime('2015-10-26 00:00:01')", "toDateTime('2018-09-14 00:00:00')")],
+}
+
 
 def dump_report(destination, suite, test_case, report):
     if destination is not None:
@@ -196,7 +236,8 @@ def columns():
     key_columns = [
         [ 'id' ],
         [ 'key0', 'key1' ],
-        [ 'key0_str', 'key1' ]
+        [ 'key0_str', 'key1' ],
+        # Explicitly no column for range_hashed, since it is completely separate case
     ]
 
     print 'Creating ClickHouse table'
@@ -214,13 +255,19 @@ def columns():
               ') engine=Log; insert into test.dictionary_source format TabSeparated'
               '"'.format(source = args.source, ch = args.client, port = args.port))
 
-    # generate 3 files with different key types
+    # generate files with different key types
     print 'Creating .tsv files'
     file_source_query = 'select %s from test.dictionary_source format TabSeparated;'
     for file, keys in zip(files, key_columns):
         query = file_source_query % comma_separated(chain(keys, columns(), [ 'Parent' ] if 1 == len(keys) else []))
         call([ args.client, '--port', args.port, '--query', query ], 'generated/' + file)
 
+    for range_hashed_range_type in range_hashed_range_types:
+        file = files[3].format(range_hashed_range_type=range_hashed_range_type)
+        keys = list(chain(['id'], range_hashed_dictGet_values[range_hashed_range_type][0]))
+        query = file_source_query % comma_separated(chain(keys, columns(), ['Parent'] if 1 == len(keys) else []))
+        call([args.client, '--port', args.port, '--query', query], 'generated/' + file)
+
     # create MySQL table from complete_query
     if not args.no_mysql:
         print 'Creating MySQL table'
@@ -411,6 +458,7 @@ def generate_dictionaries(args):
     layout_cache = '<cache><size_in_cells>128</size_in_cells></cache>'
     layout_complex_key_hashed = '<complex_key_hashed />'
     layout_complex_key_cache = '<complex_key_cache><size_in_cells>128</size_in_cells></complex_key_cache>'
+    layout_range_hashed = '<range_hashed />'
 
     key_simple = '''
     <id>
@@ -444,7 +492,22 @@ def generate_dictionaries(args):
     </key>
     '''
 
-    keys = [ key_simple, key_complex_integers, key_complex_mixed ]
+    # For range hashed, range_min and range_max are kind of additional keys, so it makes sense to put it here.
+    key_range_hashed = '''
+    <id>
+        <name>id</name>
+    </id>
+    <range_min>
+            <name>StartDate</name>
+            {range_hashed_range_type}
+    </range_min>
+    <range_max>
+            <name>EndDate</name>
+            {range_hashed_range_type}
+    </range_max>
+    '''
+
+    keys = [ key_simple, key_complex_integers, key_complex_mixed, key_range_hashed ]
 
     parent_attribute = '''
     <attribute>
@@ -549,11 +612,27 @@ def generate_dictionaries(args):
         #[ source_library_c, layout_complex_key_cache ],
     ])
 
+    for range_hashed_range_type in range_hashed_range_types:
+        sources_and_layouts.extend([
+            [ source_file % (generated_prefix + (files[3].format(range_hashed_range_type=range_hashed_range_type))), (layout_range_hashed, range_hashed_range_type) ],
+            # [ source_clickhouse, layout_range_hashed ],
+            # [ source_executable, layout_range_hashed ]
+        ])
+
     for (name, key_idx, has_parent), (source, layout) in zip(dictionaries, sources_and_layouts):
         filename = os.path.join(args.generated, 'dictionary_%s.xml' % name)
+        key = keys[key_idx]
+
+        if key_idx == 3:
+            layout, range_hashed_range_type = layout
+            # Wrap non-empty type (default) with <type> tag.
+            if range_hashed_range_type:
+                range_hashed_range_type = '<type>{}</type>'.format(range_hashed_range_type)
+            key = key.format(range_hashed_range_type=range_hashed_range_type)
+
         with open(filename, 'w') as file:
             dictionary_xml = dictionary_skeleton.format(
-                key = keys[key_idx], parent = parent_attribute if has_parent else '', **locals())
+                parent = parent_attribute if has_parent else '', **locals())
             file.write(dictionary_xml)
 
 
@@ -570,17 +649,31 @@ def http_killer():
         def https_killer():
            https_server.kill()
 
-    keys = [ 'toUInt64(n)', '(n, n)', '(toString(n), n)' ]
+    if args.filter:
+        print 'Only test cases matching filter "{}" are going to be executed.'.format(args.filter)
+
+    keys = [ 'toUInt64(n)', '(n, n)', '(toString(n), n)', 'toUInt64(n)' ]
     dict_get_query_skeleton = "select dictGet{type}('{name}', '{type}_', {key}) from system.one array join range(8) as n;"
     dict_has_query_skeleton = "select dictHas('{name}', {key}) from system.one array join range(8) as n;"
     dict_get_or_default_query_skeleton = "select dictGet{type}OrDefault('{name}', '{type}_', {key}, to{type}({default})) from system.one array join range(8) as n;"
     dict_hierarchy_query_skeleton = "select dictGetHierarchy('{name}' as d, key), dictIsIn(d, key, toUInt64(1)), dictIsIn(d, key, key) from system.one array join range(toUInt64(8)) as key;"
+    # Designed to match 4 rows hit, 4 rows miss pattern of reference file
+    dict_get_query_range_hashed_skeleton = """
+            select dictGet{type}('{name}', '{type}_', {key}, r)
+            from system.one
+                array join range(4) as n
+                cross join (select r from system.one array join array({hit}, {miss}) as r);
+    """
 
     def test_query(dict, query, reference, name):
         global failures
         global SERVER_DIED
 
         print "{0:100}".format('Dictionary: ' + dict + ' Name: ' + name + ": "),
+        if args.filter and not fnmatch.fnmatch(dict, args.filter) and not fnmatch.fnmatch(name, args.filter):
+            print " ... skipped due to filter."
+            return
+
         sys.stdout.flush()
         report_testcase = et.Element("testcase", attrib = {"name": name})
 
@@ -688,19 +781,30 @@ def test_query(dict, query, reference, name):
         key = keys[key_idx]
         print 'Testing dictionary', name
 
-        # query dictHas
-        test_query(name, dict_has_query_skeleton.format(**locals()), 'has', 'dictHas')
+        if key_idx == 3:
+            t = name.split('_')[-1] # get range_min/max type from dictionary name
+            for type, default in zip(types, explicit_defaults):
+                if SERVER_DIED and not args.no_break:
+                    break
+                for hit, miss in zip(*range_hashed_dictGet_values[t][1:]):
+                    test_query(name,
+                        dict_get_query_range_hashed_skeleton.format(**locals()),
+                            type, 'dictGet' + type)
 
-        # query dictGet*
-        for type, default in zip(types, explicit_defaults):
-            if SERVER_DIED and not args.no_break:
-                break
-            test_query(name,
-                dict_get_query_skeleton.format(**locals()),
-                type, 'dictGet' + type)
-            test_query(name,
-                dict_get_or_default_query_skeleton.format(**locals()),
-                type + 'OrDefault', 'dictGet' + type + 'OrDefault')
+        else:
+            # query dictHas is not supported for range_hashed dictionaries
+            test_query(name, dict_has_query_skeleton.format(**locals()), 'has', 'dictHas')
+
+            # query dictGet*
+            for type, default in zip(types, explicit_defaults):
+                if SERVER_DIED and not args.no_break:
+                    break
+                test_query(name,
+                    dict_get_query_skeleton.format(**locals()),
+                    type, 'dictGet' + type)
+                test_query(name,
+                    dict_get_or_default_query_skeleton.format(**locals()),
+                    type + 'OrDefault', 'dictGet' + type + 'OrDefault')
 
         # query dictGetHierarchy, dictIsIn
         if has_parent:
@@ -750,6 +854,8 @@ def main(args):
     parser.add_argument('--https_path', default = '/generated/', help = 'https server path')
     parser.add_argument('--no_break', action='store_true', help = 'Dont stop on errors')
 
+    parser.add_argument('--filter', type = str, default = None, help = 'Run only test cases matching given glob filter.')
+
     args = parser.parse_args()
 
     main(args)
diff --git a/dbms/tests/external_dictionaries/run.sh b/dbms/tests/external_dictionaries/run.sh
index b134be0fac52..a04be3080a97 100755
--- a/dbms/tests/external_dictionaries/run.sh
+++ b/dbms/tests/external_dictionaries/run.sh
@@ -7,78 +7,98 @@ if [ -z $(which python) ]; then
     sudo apt-get -y install python-lxml python-termcolor
 fi
 
-# MySQL
-if [ -z $(which mysqld) ] || [ -z $(which mysqld) ]; then
-    echo 'Installing MySQL'
-    sudo debconf-set-selections <<< 'mysql-server mysql-server/root_password password '
-    sudo debconf-set-selections <<< 'mysql-server mysql-server/root_password_again password '
-    sudo apt-get -y --force-yes install mysql-server >/dev/null
-    which mysqld >/dev/null
-    if [ $? -ne 0 ]; then
-        echo 'Failed installing mysql-server'
-        exit -1
+NO_MYSQL=0
+NO_MONGO=0
+
+for arg in "$@"; do
+    if [ "$arg" = "--no_mysql" ]; then
+        NO_MYSQL=1
+    fi
+    if [ "$arg" == "--no_mongo" ]; then
+        NO_MONGO=1
     fi
+done
 
-    echo 'Installed mysql-server'
+# MySQL
+if [ $NO_MYSQL -eq 1 ]; then
+    echo "Not using MySQL"
 else
-    echo 'MySQL already installed'
-fi
+    if [ -z $(which mysqld) ] || [ -z $(which mysqld) ]; then
+        echo 'Installing MySQL'
+        sudo debconf-set-selections <<< 'mysql-server mysql-server/root_password password '
+        sudo debconf-set-selections <<< 'mysql-server mysql-server/root_password_again password '
+        sudo apt-get -y --force-yes install mysql-server >/dev/null
+        which mysqld >/dev/null
+        if [ $? -ne 0 ]; then
+            echo 'Failed installing mysql-server'
+            exit -1
+        fi
 
-MY_CNF=/etc/mysql/my.cnf
-LOCAL_INFILE_ENABLED=$(grep 'local-infile' $MY_CNF | cut -d= -f2)
-if [ -z $LOCAL_INFILE_ENABLED ] || [ $LOCAL_INFILE_ENABLED != 1 ]; then
-    echo 'Enabling local-infile support'
-    if [ -z "$(grep 'local-infile' $MY_CNF)" ]; then
-        # add local-infile
-        MY_CNF_PATTERN='/\[mysqld\]/alocal-infile = 1'
+        echo 'Installed mysql-server'
     else
-        # edit local-infile just in case
-        MY_CNF_PATTERN='s/local-infile.*/local-infile = 1/'
+        echo 'MySQL already installed'
     fi
-    sudo sed -i "$MY_CNF_PATTERN" $MY_CNF
 
-    echo 'Enabled local-infile support for mysql'
-    sudo service mysql stop
-    sudo service mysql start
-else
-    echo 'Support for local-infile already present'
-    echo 'select 1;' | mysql $MYSQL_OPTIONS &>/dev/null
-    if [ $? -ne 0 ]; then
+    MY_CNF=/etc/mysql/my.cnf
+    LOCAL_INFILE_ENABLED=$(grep 'local-infile' $MY_CNF | cut -d= -f2)
+    if [ -z $LOCAL_INFILE_ENABLED ] || [ $LOCAL_INFILE_ENABLED != 1 ]; then
+        echo 'Enabling local-infile support'
+        if [ -z "$(grep 'local-infile' $MY_CNF)" ]; then
+            # add local-infile
+            MY_CNF_PATTERN='/\[mysqld\]/alocal-infile = 1'
+        else
+            # edit local-infile just in case
+            MY_CNF_PATTERN='s/local-infile.*/local-infile = 1/'
+        fi
+        sudo sed -i "$MY_CNF_PATTERN" $MY_CNF
+
+        echo 'Enabled local-infile support for mysql'
+        sudo service mysql stop
         sudo service mysql start
     else
-        echo 'MySQL already started'
+        echo 'Support for local-infile already present'
+        echo 'select 1;' | mysql $MYSQL_OPTIONS &>/dev/null
+        if [ $? -ne 0 ]; then
+            sudo service mysql start
+        else
+            echo 'MySQL already started'
+        fi
     fi
 fi
 
 # MongoDB
-if [ -z $(which mongod) ] || [ -z $(which mongo) ]; then
-    echo 'Installing MongoDB'
+if [ $NO_MONGO -eq 1 ]; then
+    echo "Not using MongoDB"
+else
+    if [ -z $(which mongod) ] || [ -z $(which mongo) ]; then
+        echo 'Installing MongoDB'
 
-    if [ $OS_NAME == "trusty" ]; then
-        MONGODB_ORG_VERSION=3.0.6
-        sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 7F0CEB10 &>/dev/null
-        #echo "deb http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.0.list >/dev/null
-        sudo apt-get update &>/dev/null
-        sudo apt-get install -y mongodb-org=$MONGODB_ORG_VERSION >/dev/null
+        if [ $OS_NAME == "trusty" ]; then
+            MONGODB_ORG_VERSION=3.0.6
+            sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 7F0CEB10 &>/dev/null
+            #echo "deb http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.0.list >/dev/null
+            sudo apt-get update &>/dev/null
+            sudo apt-get install -y mongodb-org=$MONGODB_ORG_VERSION >/dev/null
 
-        which mongod >/dev/null
-        if [ $? -ne 0 ]; then
-            echo 'Failed installing mongodb-org'
-            exit -1
+            which mongod >/dev/null
+            if [ $? -ne 0 ]; then
+                echo 'Failed installing mongodb-org'
+                exit -1
+            fi
+
+            echo "Installed mongodb-org $MONGODB_ORG_VERSION"
+        else
+            sudo apt-get install -y mongodb
         fi
 
-        echo "Installed mongodb-org $MONGODB_ORG_VERSION"
-    else
-        sudo apt-get install -y mongodb
     fi
 
-fi
-
-echo | mongo &>/dev/null
-if [ $? -ne 0 ]; then
-    sudo service mongod start
-else
-    echo 'MongoDB already started'
+    echo | mongo &>/dev/null
+    if [ $? -ne 0 ]; then
+        sudo service mongod start
+    else
+        echo 'MongoDB already started'
+    fi
 fi
 
 # ClickHouse
@@ -91,7 +111,7 @@ if [ $? -ne 0 ]; then
 fi
 echo 'Started ClickHouse server'
 PID=$(grep PID clickhouse/status | sed 's/PID: //')
-python ./generate_and_test.py
+python ./generate_and_test.py "$@"
 if [ $? -ne 0 ]; then
     echo 'Some test failed'
 fi
