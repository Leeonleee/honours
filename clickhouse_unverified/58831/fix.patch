diff --git a/base/poco/Foundation/include/Poco/Logger.h b/base/poco/Foundation/include/Poco/Logger.h
index ffe3766dfec7..f91d836f1909 100644
--- a/base/poco/Foundation/include/Poco/Logger.h
+++ b/base/poco/Foundation/include/Poco/Logger.h
@@ -33,7 +33,8 @@ namespace Poco
 
 
 class Exception;
-
+class Logger;
+using LoggerPtr = std::shared_ptr<Logger>;
 
 class Foundation_API Logger : public Channel
 /// Logger is a special Channel that acts as the main
@@ -870,6 +871,11 @@ class Foundation_API Logger : public Channel
     /// If the Logger does not yet exist, it is created, based
     /// on its parent logger.
 
+    static LoggerPtr getShared(const std::string & name);
+    /// Returns a shared pointer to the Logger with the given name.
+    /// If the Logger does not yet exist, it is created, based
+    /// on its parent logger.
+
     static Logger & unsafeGet(const std::string & name);
     /// Returns a reference to the Logger with the given name.
     /// If the Logger does not yet exist, it is created, based
@@ -885,6 +891,11 @@ class Foundation_API Logger : public Channel
     /// given name. The Logger's Channel and log level as set as
     /// specified.
 
+    static LoggerPtr createShared(const std::string & name, Channel * pChannel, int level = Message::PRIO_INFORMATION);
+    /// Creates and returns a shared pointer to a Logger with the
+    /// given name. The Logger's Channel and log level as set as
+    /// specified.
+
     static Logger & root();
     /// Returns a reference to the root logger, which is the ultimate
     /// ancestor of all Loggers.
@@ -893,7 +904,7 @@ class Foundation_API Logger : public Channel
     /// Returns a pointer to the Logger with the given name if it
     /// exists, or a null pointer otherwise.
 
-    static void destroy(const std::string & name);
+    static bool destroy(const std::string & name);
     /// Destroys the logger with the specified name. Does nothing
     /// if the logger is not found.
     ///
@@ -938,6 +949,7 @@ class Foundation_API Logger : public Channel
     void log(const std::string & text, Message::Priority prio, const char * file, int line);
 
     static std::string format(const std::string & fmt, int argc, std::string argv[]);
+    static Logger & unsafeCreate(const std::string & name, Channel * pChannel, int level = Message::PRIO_INFORMATION);
     static Logger & parent(const std::string & name);
     static void add(Logger * pLogger);
     static Logger * find(const std::string & name);
@@ -952,7 +964,6 @@ class Foundation_API Logger : public Channel
     std::atomic_int _level;
 
     static LoggerMap * _pLoggerMap;
-    static Mutex _mapMtx;
 };
 
 
diff --git a/base/poco/Foundation/include/Poco/RefCountedObject.h b/base/poco/Foundation/include/Poco/RefCountedObject.h
index 4ad32e30cad9..db966089e006 100644
--- a/base/poco/Foundation/include/Poco/RefCountedObject.h
+++ b/base/poco/Foundation/include/Poco/RefCountedObject.h
@@ -38,15 +38,15 @@ class Foundation_API RefCountedObject
     /// Creates the RefCountedObject.
     /// The initial reference count is one.
 
-    void duplicate() const;
-    /// Increments the object's reference count.
+    size_t duplicate() const;
+    /// Increments the object's reference count, returns reference count before call.
 
-    void release() const throw();
+    size_t release() const throw();
     /// Decrements the object's reference count
     /// and deletes the object if the count
-    /// reaches zero.
+    /// reaches zero, returns reference count before call.
 
-    int referenceCount() const;
+    size_t referenceCount() const;
     /// Returns the reference count.
 
 protected:
@@ -57,36 +57,40 @@ class Foundation_API RefCountedObject
     RefCountedObject(const RefCountedObject &);
     RefCountedObject & operator=(const RefCountedObject &);
 
-    mutable AtomicCounter _counter;
+    mutable std::atomic<size_t> _counter;
 };
 
 
 //
 // inlines
 //
-inline int RefCountedObject::referenceCount() const
+inline size_t RefCountedObject::referenceCount() const
 {
-    return _counter.value();
+    return _counter.load(std::memory_order_acquire);
 }
 
 
-inline void RefCountedObject::duplicate() const
+inline size_t RefCountedObject::duplicate() const
 {
-    ++_counter;
+    return _counter.fetch_add(1, std::memory_order_acq_rel);
 }
 
 
-inline void RefCountedObject::release() const throw()
+inline size_t RefCountedObject::release() const throw()
 {
+    size_t reference_count_before = _counter.fetch_sub(1, std::memory_order_acq_rel);
+
     try
     {
-        if (--_counter == 0)
+        if (reference_count_before == 1)
             delete this;
     }
     catch (...)
     {
         poco_unexpected();
     }
+
+    return reference_count_before;
 }
 
 
diff --git a/base/poco/Foundation/src/Logger.cpp b/base/poco/Foundation/src/Logger.cpp
index 3d5de585b4f9..7c54116aaa4d 100644
--- a/base/poco/Foundation/src/Logger.cpp
+++ b/base/poco/Foundation/src/Logger.cpp
@@ -20,12 +20,29 @@
 #include "Poco/NumberParser.h"
 #include "Poco/String.h"
 
+#include <mutex>
+
+namespace
+{
+
+std::mutex & getLoggerMutex()
+{
+	auto get_logger_mutex_placeholder_memory = []()
+	{
+		static char buffer[sizeof(std::mutex)]{};
+		return buffer;
+	};
+
+	static std::mutex * logger_mutex = new (get_logger_mutex_placeholder_memory()) std::mutex();
+	return *logger_mutex;
+}
+
+}
 
 namespace Poco {
 
 
 Logger::LoggerMap* Logger::_pLoggerMap = 0;
-Mutex Logger::_mapMtx;
 const std::string Logger::ROOT;
 
 
@@ -73,7 +90,7 @@ void Logger::setProperty(const std::string& name, const std::string& value)
 		setChannel(LoggingRegistry::defaultRegistry().channelForName(value));
 	else if (name == "level")
 		setLevel(value);
-	else 
+	else
 		Channel::setProperty(name, value);
 }
 
@@ -112,14 +129,14 @@ void Logger::dump(const std::string& msg, const void* buffer, std::size_t length
 
 void Logger::setLevel(const std::string& name, int level)
 {
-	Mutex::ScopedLock lock(_mapMtx);
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
 
 	if (_pLoggerMap)
 	{
 		std::string::size_type len = name.length();
 		for (LoggerMap::iterator it = _pLoggerMap->begin(); it != _pLoggerMap->end(); ++it)
 		{
-			if (len == 0 || 
+			if (len == 0 ||
 				(it->first.compare(0, len, name) == 0 && (it->first.length() == len || it->first[len] == '.')))
 			{
 				it->second->setLevel(level);
@@ -131,7 +148,7 @@ void Logger::setLevel(const std::string& name, int level)
 
 void Logger::setChannel(const std::string& name, Channel* pChannel)
 {
-	Mutex::ScopedLock lock(_mapMtx);
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
 
 	if (_pLoggerMap)
 	{
@@ -150,7 +167,7 @@ void Logger::setChannel(const std::string& name, Channel* pChannel)
 
 void Logger::setProperty(const std::string& loggerName, const std::string& propertyName, const std::string& value)
 {
-	Mutex::ScopedLock lock(_mapMtx);
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
 
 	if (_pLoggerMap)
 	{
@@ -280,13 +297,41 @@ void Logger::formatDump(std::string& message, const void* buffer, std::size_t le
 }
 
 
+namespace
+{
+
+struct LoggerDeleter
+{
+	void operator()(Poco::Logger * logger)
+	{
+		if (Logger::destroy(logger->name()))
+			return;
+
+		logger->release();
+	}
+};
+
+inline LoggerPtr makeLoggerPtr(Logger & logger)
+{
+	logger.duplicate();
+	return std::shared_ptr<Logger>(&logger, LoggerDeleter());
+}
+
+}
+
 Logger& Logger::get(const std::string& name)
 {
-	Mutex::ScopedLock lock(_mapMtx);
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
 
 	return unsafeGet(name);
 }
 
+LoggerPtr Logger::getShared(const std::string & name)
+{
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
+
+	return makeLoggerPtr(unsafeGet(name));
+}
 
 Logger& Logger::unsafeGet(const std::string& name)
 {
@@ -310,18 +355,21 @@ Logger& Logger::unsafeGet(const std::string& name)
 
 Logger& Logger::create(const std::string& name, Channel* pChannel, int level)
 {
-	Mutex::ScopedLock lock(_mapMtx);
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
 
-	if (find(name)) throw ExistsException();
-	Logger* pLogger = new Logger(name, pChannel, level);
-	add(pLogger);
-	return *pLogger;
+	return unsafeCreate(name, pChannel, level);
 }
 
+LoggerPtr Logger::createShared(const std::string & name, Channel * pChannel, int level)
+{
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
+
+	return makeLoggerPtr(unsafeCreate(name, pChannel, level));
+}
 
 Logger& Logger::root()
 {
-	Mutex::ScopedLock lock(_mapMtx);
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
 
 	return unsafeGet(ROOT);
 }
@@ -329,7 +377,7 @@ Logger& Logger::root()
 
 Logger* Logger::has(const std::string& name)
 {
-	Mutex::ScopedLock lock(_mapMtx);
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
 
 	return find(name);
 }
@@ -337,7 +385,7 @@ Logger* Logger::has(const std::string& name)
 
 void Logger::shutdown()
 {
-	Mutex::ScopedLock lock(_mapMtx);
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
 
 	if (_pLoggerMap)
 	{
@@ -363,25 +411,29 @@ Logger* Logger::find(const std::string& name)
 }
 
 
-void Logger::destroy(const std::string& name)
+bool Logger::destroy(const std::string& name)
 {
-	Mutex::ScopedLock lock(_mapMtx);
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
 
 	if (_pLoggerMap)
 	{
 		LoggerMap::iterator it = _pLoggerMap->find(name);
 		if (it != _pLoggerMap->end())
 		{
-			it->second->release();
-			_pLoggerMap->erase(it);
+			if (it->second->release() == 1)
+				_pLoggerMap->erase(it);
+
+			return true;
 		}
 	}
+
+	return false;
 }
 
 
 void Logger::names(std::vector<std::string>& names)
 {
-	Mutex::ScopedLock lock(_mapMtx);
+	std::lock_guard<std::mutex> lock(getLoggerMutex());
 
 	names.clear();
 	if (_pLoggerMap)
@@ -393,6 +445,14 @@ void Logger::names(std::vector<std::string>& names)
 	}
 }
 
+Logger& Logger::unsafeCreate(const std::string & name, Channel * pChannel, int level)
+{
+	if (find(name)) throw ExistsException();
+	Logger* pLogger = new Logger(name, pChannel, level);
+	add(pLogger);
+
+	return *pLogger;
+}
 
 Logger& Logger::parent(const std::string& name)
 {
diff --git a/programs/copier/ClusterCopier.h b/programs/copier/ClusterCopier.h
index 063b13e90780..01f8b30f5463 100644
--- a/programs/copier/ClusterCopier.h
+++ b/programs/copier/ClusterCopier.h
@@ -20,7 +20,7 @@ class ClusterCopier : WithMutableContext
                   const String & host_id_,
                   const String & proxy_database_name_,
                   ContextMutablePtr context_,
-                  Poco::Logger * log_)
+                  LoggerRawPtr log_)
             : WithMutableContext(context_),
             task_zookeeper_path(task_path_),
             host_id(host_id_),
@@ -230,7 +230,7 @@ class ClusterCopier : WithMutableContext
 
     bool experimental_use_sample_offset{false};
 
-    Poco::Logger * log;
+    LoggerRawPtr log;
 
     UInt64 max_table_tries = 3;
     UInt64 max_shard_partition_tries = 3;
diff --git a/programs/copier/ZooKeeperStaff.h b/programs/copier/ZooKeeperStaff.h
index 36dcfa508425..bbdec230d2df 100644
--- a/programs/copier/ZooKeeperStaff.h
+++ b/programs/copier/ZooKeeperStaff.h
@@ -177,7 +177,7 @@ class CleanStateClock
         auto watch_callback =
                 [my_stale = stale] (const Coordination::WatchResponse & rsp)
                 {
-                    auto logger = &Poco::Logger::get("ClusterCopier");
+                    auto logger = getLogger("ClusterCopier");
                     if (rsp.error == Coordination::Error::ZOK)
                     {
                         switch (rsp.type)
diff --git a/programs/keeper-client/KeeperClient.cpp b/programs/keeper-client/KeeperClient.cpp
index 7ed4499efbd2..fa66a69687c2 100644
--- a/programs/keeper-client/KeeperClient.cpp
+++ b/programs/keeper-client/KeeperClient.cpp
@@ -375,7 +375,7 @@ int KeeperClient::main(const std::vector<String> & /* args */)
 
     if (!config().has("host") && !config().has("port") && !keys.empty())
     {
-        LOG_INFO(&Poco::Logger::get("KeeperClient"), "Found keeper node in the config.xml, will use it for connection");
+        LOG_INFO(getLogger("KeeperClient"), "Found keeper node in the config.xml, will use it for connection");
 
         for (const auto & key : keys)
         {
diff --git a/programs/keeper-converter/KeeperConverter.cpp b/programs/keeper-converter/KeeperConverter.cpp
index 20448aafa2f1..2b2759412ab3 100644
--- a/programs/keeper-converter/KeeperConverter.cpp
+++ b/programs/keeper-converter/KeeperConverter.cpp
@@ -28,7 +28,7 @@ int mainEntryClickHouseKeeperConverter(int argc, char ** argv)
     po::store(po::command_line_parser(argc, argv).options(desc).run(), options);
     Poco::AutoPtr<Poco::ConsoleChannel> console_channel(new Poco::ConsoleChannel);
 
-    Poco::Logger * logger = &Poco::Logger::get("KeeperConverter");
+    LoggerPtr logger = getLogger("KeeperConverter");
     logger->setChannel(console_channel);
 
     if (options.count("help"))
diff --git a/programs/keeper/Keeper.cpp b/programs/keeper/Keeper.cpp
index 109884ec899b..c751702dc6fb 100644
--- a/programs/keeper/Keeper.cpp
+++ b/programs/keeper/Keeper.cpp
@@ -624,7 +624,7 @@ catch (...)
 
 void Keeper::logRevision() const
 {
-    LOG_INFO(&Poco::Logger::get("Application"),
+    LOG_INFO(getLogger("Application"),
         "Starting ClickHouse Keeper {} (revision: {}, git hash: {}, build id: {}), PID {}",
         VERSION_STRING,
         ClickHouseRevision::getVersionRevision(),
diff --git a/programs/library-bridge/CatBoostLibraryHandlerFactory.cpp b/programs/library-bridge/CatBoostLibraryHandlerFactory.cpp
index 6ee078f6c5cf..7ce896636e70 100644
--- a/programs/library-bridge/CatBoostLibraryHandlerFactory.cpp
+++ b/programs/library-bridge/CatBoostLibraryHandlerFactory.cpp
@@ -13,7 +13,7 @@ CatBoostLibraryHandlerFactory & CatBoostLibraryHandlerFactory::instance()
 }
 
 CatBoostLibraryHandlerFactory::CatBoostLibraryHandlerFactory()
-    : log(&Poco::Logger::get("CatBoostLibraryHandlerFactory"))
+    : log(getLogger("CatBoostLibraryHandlerFactory"))
 {
 }
 
diff --git a/programs/library-bridge/CatBoostLibraryHandlerFactory.h b/programs/library-bridge/CatBoostLibraryHandlerFactory.h
index 6ba3fe84ec9e..e29834cbe791 100644
--- a/programs/library-bridge/CatBoostLibraryHandlerFactory.h
+++ b/programs/library-bridge/CatBoostLibraryHandlerFactory.h
@@ -31,7 +31,7 @@ class CatBoostLibraryHandlerFactory final : private boost::noncopyable
     /// map: model path --> catboost library handler
     std::unordered_map<String, CatBoostLibraryHandlerPtr> library_handlers TSA_GUARDED_BY(mutex);
     std::mutex mutex;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/programs/library-bridge/ExternalDictionaryLibraryAPI.cpp b/programs/library-bridge/ExternalDictionaryLibraryAPI.cpp
index 70cd6fca3751..4fa5c991f0f8 100644
--- a/programs/library-bridge/ExternalDictionaryLibraryAPI.cpp
+++ b/programs/library-bridge/ExternalDictionaryLibraryAPI.cpp
@@ -9,40 +9,40 @@ const char DICT_LOGGER_NAME[] = "LibraryDictionarySourceExternal";
 
 void ExternalDictionaryLibraryAPI::log(LogLevel level, CString msg)
 {
-    auto & logger = Poco::Logger::get(DICT_LOGGER_NAME);
+    auto logger = getLogger(DICT_LOGGER_NAME);
     switch (level)
     {
         case LogLevel::TRACE:
-            if (logger.trace())
-                logger.trace(msg);
+            if (logger->trace())
+                logger->trace(msg);
             break;
         case LogLevel::DEBUG:
-            if (logger.debug())
-                logger.debug(msg);
+            if (logger->debug())
+                logger->debug(msg);
             break;
         case LogLevel::INFORMATION:
-            if (logger.information())
-                logger.information(msg);
+            if (logger->information())
+                logger->information(msg);
             break;
         case LogLevel::NOTICE:
-            if (logger.notice())
-                logger.notice(msg);
+            if (logger->notice())
+                logger->notice(msg);
             break;
         case LogLevel::WARNING:
-            if (logger.warning())
-                logger.warning(msg);
+            if (logger->warning())
+                logger->warning(msg);
             break;
         case LogLevel::ERROR:
-            if (logger.error())
-                logger.error(msg);
+            if (logger->error())
+                logger->error(msg);
             break;
         case LogLevel::CRITICAL:
-            if (logger.critical())
-                logger.critical(msg);
+            if (logger->critical())
+                logger->critical(msg);
             break;
         case LogLevel::FATAL:
-            if (logger.fatal())
-                logger.fatal(msg);
+            if (logger->fatal())
+                logger->fatal(msg);
             break;
     }
 }
diff --git a/programs/library-bridge/ExternalDictionaryLibraryHandlerFactory.cpp b/programs/library-bridge/ExternalDictionaryLibraryHandlerFactory.cpp
index 6acd9af20ed8..1b2b57beeb11 100644
--- a/programs/library-bridge/ExternalDictionaryLibraryHandlerFactory.cpp
+++ b/programs/library-bridge/ExternalDictionaryLibraryHandlerFactory.cpp
@@ -26,7 +26,7 @@ void ExternalDictionaryLibraryHandlerFactory::create(
 
     if (library_handlers.contains(dictionary_id))
     {
-        LOG_WARNING(&Poco::Logger::get("ExternalDictionaryLibraryHandlerFactory"), "Library handler with dictionary id {} already exists", dictionary_id);
+        LOG_WARNING(getLogger("ExternalDictionaryLibraryHandlerFactory"), "Library handler with dictionary id {} already exists", dictionary_id);
         return;
     }
 
diff --git a/programs/library-bridge/LibraryBridgeHandlerFactory.cpp b/programs/library-bridge/LibraryBridgeHandlerFactory.cpp
index 4af1f8355e80..e5ab22f2d40d 100644
--- a/programs/library-bridge/LibraryBridgeHandlerFactory.cpp
+++ b/programs/library-bridge/LibraryBridgeHandlerFactory.cpp
@@ -12,7 +12,7 @@ LibraryBridgeHandlerFactory::LibraryBridgeHandlerFactory(
     size_t keep_alive_timeout_,
     ContextPtr context_)
     : WithContext(context_)
-    , log(&Poco::Logger::get(name_))
+    , log(getLogger(name_))
     , name(name_)
     , keep_alive_timeout(keep_alive_timeout_)
 {
diff --git a/programs/library-bridge/LibraryBridgeHandlerFactory.h b/programs/library-bridge/LibraryBridgeHandlerFactory.h
index 7565052c4cbe..5b0f088bc296 100644
--- a/programs/library-bridge/LibraryBridgeHandlerFactory.h
+++ b/programs/library-bridge/LibraryBridgeHandlerFactory.h
@@ -19,7 +19,7 @@ class LibraryBridgeHandlerFactory : public HTTPRequestHandlerFactory, WithContex
     std::unique_ptr<HTTPRequestHandler> createRequestHandler(const HTTPServerRequest & request) override;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     const std::string name;
     const size_t keep_alive_timeout;
 };
diff --git a/programs/library-bridge/LibraryBridgeHandlers.cpp b/programs/library-bridge/LibraryBridgeHandlers.cpp
index b0b465460e08..ab146f458df9 100644
--- a/programs/library-bridge/LibraryBridgeHandlers.cpp
+++ b/programs/library-bridge/LibraryBridgeHandlers.cpp
@@ -47,7 +47,7 @@ namespace
         if (!response.sent())
             *response.send() << message << '
';
 
-        LOG_WARNING(&Poco::Logger::get("LibraryBridge"), fmt::runtime(message));
+        LOG_WARNING(getLogger("LibraryBridge"), fmt::runtime(message));
     }
 
     std::shared_ptr<Block> parseColumns(String && column_string)
@@ -92,7 +92,7 @@ static void writeData(Block data, OutputFormatPtr format)
 ExternalDictionaryLibraryBridgeRequestHandler::ExternalDictionaryLibraryBridgeRequestHandler(size_t keep_alive_timeout_, ContextPtr context_)
     : WithContext(context_)
     , keep_alive_timeout(keep_alive_timeout_)
-    , log(&Poco::Logger::get("ExternalDictionaryLibraryBridgeRequestHandler"))
+    , log(getLogger("ExternalDictionaryLibraryBridgeRequestHandler"))
 {
 }
 
@@ -380,7 +380,7 @@ void ExternalDictionaryLibraryBridgeRequestHandler::handleRequest(HTTPServerRequ
 ExternalDictionaryLibraryBridgeExistsHandler::ExternalDictionaryLibraryBridgeExistsHandler(size_t keep_alive_timeout_, ContextPtr context_)
     : WithContext(context_)
     , keep_alive_timeout(keep_alive_timeout_)
-    , log(&Poco::Logger::get("ExternalDictionaryLibraryBridgeExistsHandler"))
+    , log(getLogger("ExternalDictionaryLibraryBridgeExistsHandler"))
 {
 }
 
@@ -419,7 +419,7 @@ CatBoostLibraryBridgeRequestHandler::CatBoostLibraryBridgeRequestHandler(
     size_t keep_alive_timeout_, ContextPtr context_)
     : WithContext(context_)
     , keep_alive_timeout(keep_alive_timeout_)
-    , log(&Poco::Logger::get("CatBoostLibraryBridgeRequestHandler"))
+    , log(getLogger("CatBoostLibraryBridgeRequestHandler"))
 {
 }
 
@@ -623,7 +623,7 @@ void CatBoostLibraryBridgeRequestHandler::handleRequest(HTTPServerRequest & requ
 CatBoostLibraryBridgeExistsHandler::CatBoostLibraryBridgeExistsHandler(size_t keep_alive_timeout_, ContextPtr context_)
     : WithContext(context_)
     , keep_alive_timeout(keep_alive_timeout_)
-    , log(&Poco::Logger::get("CatBoostLibraryBridgeExistsHandler"))
+    , log(getLogger("CatBoostLibraryBridgeExistsHandler"))
 {
 }
 
diff --git a/programs/library-bridge/LibraryBridgeHandlers.h b/programs/library-bridge/LibraryBridgeHandlers.h
index 4f08d7a60840..1db71eb24cb8 100644
--- a/programs/library-bridge/LibraryBridgeHandlers.h
+++ b/programs/library-bridge/LibraryBridgeHandlers.h
@@ -26,7 +26,7 @@ class ExternalDictionaryLibraryBridgeRequestHandler : public HTTPRequestHandler,
     static constexpr inline auto FORMAT = "RowBinary";
 
     const size_t keep_alive_timeout;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 
@@ -40,7 +40,7 @@ class ExternalDictionaryLibraryBridgeExistsHandler : public HTTPRequestHandler,
 
 private:
     const size_t keep_alive_timeout;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 
@@ -69,7 +69,7 @@ class CatBoostLibraryBridgeRequestHandler : public HTTPRequestHandler, WithConte
 
 private:
     const size_t keep_alive_timeout;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 
@@ -83,7 +83,7 @@ class CatBoostLibraryBridgeExistsHandler : public HTTPRequestHandler, WithContex
 
 private:
     const size_t keep_alive_timeout;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/programs/local/LocalServer.cpp b/programs/local/LocalServer.cpp
index 4e0b9eeb731a..443d4a52fa3e 100644
--- a/programs/local/LocalServer.cpp
+++ b/programs/local/LocalServer.cpp
@@ -221,7 +221,7 @@ void LocalServer::tryInitPath()
     {
         // The path is not provided explicitly - use a unique path in the system temporary directory
         // (or in the current dir if temporary don't exist)
-        Poco::Logger * log = &logger();
+        LoggerRawPtr log = &logger();
         std::filesystem::path parent_folder;
         std::filesystem::path default_path;
 
@@ -631,7 +631,7 @@ void LocalServer::processConfig()
 
     tryInitPath();
 
-    Poco::Logger * log = &logger();
+    LoggerRawPtr log = &logger();
 
     /// Maybe useless
     if (config().has("macros"))
diff --git a/programs/odbc-bridge/ColumnInfoHandler.h b/programs/odbc-bridge/ColumnInfoHandler.h
index e3087701182c..ca7044fdf328 100644
--- a/programs/odbc-bridge/ColumnInfoHandler.h
+++ b/programs/odbc-bridge/ColumnInfoHandler.h
@@ -18,7 +18,7 @@ class ODBCColumnsInfoHandler : public HTTPRequestHandler, WithContext
 public:
     ODBCColumnsInfoHandler(size_t keep_alive_timeout_, ContextPtr context_)
         : WithContext(context_)
-        , log(&Poco::Logger::get("ODBCColumnsInfoHandler"))
+        , log(getLogger("ODBCColumnsInfoHandler"))
         , keep_alive_timeout(keep_alive_timeout_)
     {
     }
@@ -26,7 +26,7 @@ class ODBCColumnsInfoHandler : public HTTPRequestHandler, WithContext
     void handleRequest(HTTPServerRequest & request, HTTPServerResponse & response, const ProfileEvents::Event & write_event) override;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     size_t keep_alive_timeout;
 };
 
diff --git a/programs/odbc-bridge/IdentifierQuoteHandler.h b/programs/odbc-bridge/IdentifierQuoteHandler.h
index ff5c02ca07b3..7b78c5b4b93c 100644
--- a/programs/odbc-bridge/IdentifierQuoteHandler.h
+++ b/programs/odbc-bridge/IdentifierQuoteHandler.h
@@ -16,7 +16,7 @@ class IdentifierQuoteHandler : public HTTPRequestHandler, WithContext
 public:
     IdentifierQuoteHandler(size_t keep_alive_timeout_, ContextPtr context_)
         : WithContext(context_)
-        , log(&Poco::Logger::get("IdentifierQuoteHandler"))
+        , log(getLogger("IdentifierQuoteHandler"))
         , keep_alive_timeout(keep_alive_timeout_)
     {
     }
@@ -24,7 +24,7 @@ class IdentifierQuoteHandler : public HTTPRequestHandler, WithContext
     void handleRequest(HTTPServerRequest & request, HTTPServerResponse & response, const ProfileEvents::Event & write_event) override;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     size_t keep_alive_timeout;
 };
 
diff --git a/programs/odbc-bridge/MainHandler.h b/programs/odbc-bridge/MainHandler.h
index 7977245ff821..ed0c6b2e28c3 100644
--- a/programs/odbc-bridge/MainHandler.h
+++ b/programs/odbc-bridge/MainHandler.h
@@ -24,7 +24,7 @@ class ODBCHandler : public HTTPRequestHandler, WithContext
         ContextPtr context_,
         const String & mode_)
         : WithContext(context_)
-        , log(&Poco::Logger::get("ODBCHandler"))
+        , log(getLogger("ODBCHandler"))
         , keep_alive_timeout(keep_alive_timeout_)
         , mode(mode_)
     {
@@ -33,7 +33,7 @@ class ODBCHandler : public HTTPRequestHandler, WithContext
     void handleRequest(HTTPServerRequest & request, HTTPServerResponse & response, const ProfileEvents::Event & write_event) override;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
 
     size_t keep_alive_timeout;
     String mode;
diff --git a/programs/odbc-bridge/ODBCBlockInputStream.cpp b/programs/odbc-bridge/ODBCBlockInputStream.cpp
index 3aa3d9a652b6..c46144c3dc83 100644
--- a/programs/odbc-bridge/ODBCBlockInputStream.cpp
+++ b/programs/odbc-bridge/ODBCBlockInputStream.cpp
@@ -23,7 +23,7 @@ namespace ErrorCodes
 ODBCSource::ODBCSource(
     nanodbc::ConnectionHolderPtr connection_holder, const std::string & query_str, const Block & sample_block, const UInt64 max_block_size_)
     : ISource(sample_block)
-    , log(&Poco::Logger::get("ODBCSource"))
+    , log(getLogger("ODBCSource"))
     , max_block_size{max_block_size_}
     , query(query_str)
 {
diff --git a/programs/odbc-bridge/ODBCBlockInputStream.h b/programs/odbc-bridge/ODBCBlockInputStream.h
index 79d5816ad014..dedd98f930f5 100644
--- a/programs/odbc-bridge/ODBCBlockInputStream.h
+++ b/programs/odbc-bridge/ODBCBlockInputStream.h
@@ -30,7 +30,7 @@ class ODBCSource final : public ISource
         column.insertFrom(sample_column, 0);
     }
 
-    Poco::Logger * log;
+    LoggerPtr log;
     const UInt64 max_block_size;
     ExternalResultDescription description;
 
diff --git a/programs/odbc-bridge/ODBCBlockOutputStream.cpp b/programs/odbc-bridge/ODBCBlockOutputStream.cpp
index eb5901ad3e1f..87c09d1e7571 100644
--- a/programs/odbc-bridge/ODBCBlockOutputStream.cpp
+++ b/programs/odbc-bridge/ODBCBlockOutputStream.cpp
@@ -19,7 +19,7 @@ ODBCSink::ODBCSink(
     ContextPtr local_context_,
     IdentifierQuotingStyle quoting_)
     : ISink(sample_block_)
-    , log(&Poco::Logger::get("ODBCSink"))
+    , log(getLogger("ODBCSink"))
     , connection_holder(std::move(connection_holder_))
     , db_name(remote_database_name_)
     , table_name(remote_table_name_)
diff --git a/programs/odbc-bridge/ODBCBlockOutputStream.h b/programs/odbc-bridge/ODBCBlockOutputStream.h
index f5e7b4e3a2d5..06edce92e1a6 100644
--- a/programs/odbc-bridge/ODBCBlockOutputStream.h
+++ b/programs/odbc-bridge/ODBCBlockOutputStream.h
@@ -30,7 +30,7 @@ using ValueType = ExternalResultDescription::ValueType;
     void consume(Chunk chunk) override;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
 
     nanodbc::ConnectionHolderPtr connection_holder;
     std::string db_name;
diff --git a/programs/odbc-bridge/ODBCHandlerFactory.cpp b/programs/odbc-bridge/ODBCHandlerFactory.cpp
index dd21358df8c3..eebb0c24c7a8 100644
--- a/programs/odbc-bridge/ODBCHandlerFactory.cpp
+++ b/programs/odbc-bridge/ODBCHandlerFactory.cpp
@@ -11,7 +11,7 @@ namespace DB
 
 ODBCBridgeHandlerFactory::ODBCBridgeHandlerFactory(const std::string & name_, size_t keep_alive_timeout_, ContextPtr context_)
     : WithContext(context_)
-    , log(&Poco::Logger::get(name_))
+    , log(getLogger(name_))
     , name(name_)
     , keep_alive_timeout(keep_alive_timeout_)
 {
diff --git a/programs/odbc-bridge/ODBCHandlerFactory.h b/programs/odbc-bridge/ODBCHandlerFactory.h
index 3e3da7c9f246..4aaf1b55453c 100644
--- a/programs/odbc-bridge/ODBCHandlerFactory.h
+++ b/programs/odbc-bridge/ODBCHandlerFactory.h
@@ -22,7 +22,7 @@ class ODBCBridgeHandlerFactory : public HTTPRequestHandlerFactory, WithContext
     std::unique_ptr<HTTPRequestHandler> createRequestHandler(const HTTPServerRequest & request) override;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     std::string name;
     size_t keep_alive_timeout;
 };
diff --git a/programs/odbc-bridge/ODBCPooledConnectionFactory.h b/programs/odbc-bridge/ODBCPooledConnectionFactory.h
index a10055c66598..b70e45f2b9db 100644
--- a/programs/odbc-bridge/ODBCPooledConnectionFactory.h
+++ b/programs/odbc-bridge/ODBCPooledConnectionFactory.h
@@ -97,7 +97,7 @@ T execute(nanodbc::ConnectionHolderPtr connection_holder, std::function<T(nanodb
         /// https://docs.microsoft.com/ru-ru/sql/odbc/reference/appendixes/appendix-a-odbc-error-codes?view=sql-server-ver15
         bool is_retriable = e.state().starts_with("08") || e.state().starts_with("24") || e.state().starts_with("25");
         LOG_ERROR(
-            &Poco::Logger::get("ODBCConnection"),
+            getLogger("ODBCConnection"),
             "ODBC query failed with error: {}, state: {}, native code: {}{}",
             e.what(), e.state(), e.native(), is_retriable ? ", will retry" : "");
 
diff --git a/programs/odbc-bridge/SchemaAllowedHandler.h b/programs/odbc-bridge/SchemaAllowedHandler.h
index aa0b04b1d314..8dc725dbb33b 100644
--- a/programs/odbc-bridge/SchemaAllowedHandler.h
+++ b/programs/odbc-bridge/SchemaAllowedHandler.h
@@ -19,7 +19,7 @@ class SchemaAllowedHandler : public HTTPRequestHandler, WithContext
 public:
     SchemaAllowedHandler(size_t keep_alive_timeout_, ContextPtr context_)
         : WithContext(context_)
-        , log(&Poco::Logger::get("SchemaAllowedHandler"))
+        , log(getLogger("SchemaAllowedHandler"))
         , keep_alive_timeout(keep_alive_timeout_)
     {
     }
@@ -27,7 +27,7 @@ class SchemaAllowedHandler : public HTTPRequestHandler, WithContext
     void handleRequest(HTTPServerRequest & request, HTTPServerResponse & response, const ProfileEvents::Event & write_event) override;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     size_t keep_alive_timeout;
 };
 
diff --git a/programs/odbc-bridge/getIdentifierQuote.cpp b/programs/odbc-bridge/getIdentifierQuote.cpp
index 793e398363ce..15bd055e6153 100644
--- a/programs/odbc-bridge/getIdentifierQuote.cpp
+++ b/programs/odbc-bridge/getIdentifierQuote.cpp
@@ -26,7 +26,7 @@ std::string getIdentifierQuote(nanodbc::ConnectionHolderPtr connection_holder)
     }
     catch (...)
     {
-        LOG_WARNING(&Poco::Logger::get("ODBCGetIdentifierQuote"), "Cannot fetch identifier quote. Default double quote is used. Reason: {}", getCurrentExceptionMessage(false));
+        LOG_WARNING(getLogger("ODBCGetIdentifierQuote"), "Cannot fetch identifier quote. Default double quote is used. Reason: {}", getCurrentExceptionMessage(false));
         return "\"";
     }
 
diff --git a/programs/server/Server.cpp b/programs/server/Server.cpp
index 96f3119e0733..8a0357771d27 100644
--- a/programs/server/Server.cpp
+++ b/programs/server/Server.cpp
@@ -365,7 +365,7 @@ void Server::createServer(
 namespace
 {
 
-void setOOMScore(int value, Poco::Logger * log)
+void setOOMScore(int value, LoggerRawPtr log)
 {
     try
     {
@@ -450,7 +450,7 @@ void checkForUsersNotInMainConfig(
     const Poco::Util::AbstractConfiguration & config,
     const std::string & config_path,
     const std::string & users_config_path,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     if (config.getBool("skip_check_for_incorrect_settings", false))
         return;
@@ -2491,7 +2491,7 @@ void Server::stopServers(
     const ServerType & server_type
 ) const
 {
-    Poco::Logger * log = &logger();
+    LoggerRawPtr log = &logger();
 
     /// Remove servers once all their connections are closed
     auto check_server = [&log](const char prefix[], auto & server)
@@ -2530,7 +2530,7 @@ void Server::updateServers(
     std::vector<ProtocolServerAdapter> & servers,
     std::vector<ProtocolServerAdapter> & servers_to_start_before_tables)
 {
-    Poco::Logger * log = &logger();
+    LoggerRawPtr log = &logger();
 
     const auto listen_hosts = getListenHosts(config);
     const auto interserver_listen_hosts = getInterserverListenHosts(config);
diff --git a/src/Access/AccessControl.cpp b/src/Access/AccessControl.cpp
index 5de405d9f8fe..71ad219110df 100644
--- a/src/Access/AccessControl.cpp
+++ b/src/Access/AccessControl.cpp
@@ -47,7 +47,7 @@ namespace
         const Poco::Util::AbstractConfiguration & config,
         const std::string & config_path,
         const std::string & users_config_path,
-        Poco::Logger * log)
+        LoggerPtr log)
     {
         if (config.getBool("skip_check_for_incorrect_settings", false))
             return;
diff --git a/src/Access/AccessRights.cpp b/src/Access/AccessRights.cpp
index 520a11bd696c..72cbeca4f114 100644
--- a/src/Access/AccessRights.cpp
+++ b/src/Access/AccessRights.cpp
@@ -443,7 +443,7 @@ struct AccessRights::Node
             optimizeTree();
     }
 
-    void logTree(Poco::Logger * log, const String & title) const
+    void logTree(LoggerPtr log, const String & title) const
     {
         LOG_TRACE(log, "Tree({}): level={}, name={}, flags={}, min_flags={}, max_flags={}, num_children={}",
             title, level, node_name ? *node_name : "NULL", flags.toString(),
@@ -1158,7 +1158,7 @@ AccessRights AccessRights::getFullAccess()
 
 void AccessRights::logTree() const
 {
-    auto * log = &Poco::Logger::get("AccessRights");
+    auto log = getLogger("AccessRights");
     if (root)
     {
         root->logTree(log, "");
diff --git a/src/Access/Common/AllowedClientHosts.cpp b/src/Access/Common/AllowedClientHosts.cpp
index 801ccd3748b9..c677465a7a1c 100644
--- a/src/Access/Common/AllowedClientHosts.cpp
+++ b/src/Access/Common/AllowedClientHosts.cpp
@@ -514,7 +514,7 @@ bool AllowedClientHosts::contains(const IPAddress & client_address) const
                 throw;
             /// Try to ignore DNS errors: if host cannot be resolved, skip it and try next.
             LOG_WARNING(
-                &Poco::Logger::get("AddressPatterns"),
+                getLogger("AddressPatterns"),
                 "Failed to check if the allowed client hosts contain address {}. {}, code = {}",
                 client_address.toString(), e.displayText(), e.code());
             return false;
@@ -556,7 +556,7 @@ bool AllowedClientHosts::contains(const IPAddress & client_address) const
                 throw;
             /// Try to ignore DNS errors: if host cannot be resolved, skip it and try next.
             LOG_WARNING(
-                &Poco::Logger::get("AddressPatterns"),
+                getLogger("AddressPatterns"),
                 "Failed to check if the allowed client hosts contain address {}. {}, code = {}",
                 client_address.toString(), e.displayText(), e.code());
             return false;
diff --git a/src/Access/ContextAccess.cpp b/src/Access/ContextAccess.cpp
index 567b131c00e3..0943e797e3ff 100644
--- a/src/Access/ContextAccess.cpp
+++ b/src/Access/ContextAccess.cpp
@@ -298,7 +298,7 @@ void ContextAccess::setUser(const UserPtr & user_) const
     }
 
     user_name = user->getName();
-    trace_log = &Poco::Logger::get("ContextAccess (" + user_name + ")");
+    trace_log = getLogger("ContextAccess (" + user_name + ")");
 
     std::vector<UUID> current_roles, current_roles_with_admin_option;
     if (params.use_default_roles)
diff --git a/src/Access/ContextAccess.h b/src/Access/ContextAccess.h
index caf903b85bd9..237c423d2618 100644
--- a/src/Access/ContextAccess.h
+++ b/src/Access/ContextAccess.h
@@ -185,9 +185,10 @@ class ContextAccess : public std::enable_shared_from_this<ContextAccess>
 
     mutable std::atomic<bool> initialized = false; // can be removed after Bug 5504 is resolved
     mutable std::atomic<bool> user_was_dropped = false;
-    mutable std::atomic<Poco::Logger *> trace_log = nullptr;
 
     mutable std::mutex mutex;
+    /// TODO: Fix race
+    mutable LoggerPtr trace_log;
     mutable UserPtr user TSA_GUARDED_BY(mutex);
     mutable String user_name TSA_GUARDED_BY(mutex);
     mutable scope_guard subscription_for_user_change TSA_GUARDED_BY(mutex);
diff --git a/src/Access/DiskAccessStorage.cpp b/src/Access/DiskAccessStorage.cpp
index 190c7567b854..3c20ef3d102e 100644
--- a/src/Access/DiskAccessStorage.cpp
+++ b/src/Access/DiskAccessStorage.cpp
@@ -47,7 +47,7 @@ namespace
     }
 
 
-    AccessEntityPtr tryReadEntityFile(const String & file_path, Poco::Logger & log)
+    AccessEntityPtr tryReadEntityFile(const String & file_path, LoggerPtr log)
     {
         try
         {
@@ -55,7 +55,7 @@ namespace
         }
         catch (...)
         {
-            tryLogCurrentException(&log);
+            tryLogCurrentException(log);
             return nullptr;
         }
     }
@@ -378,7 +378,7 @@ void DiskAccessStorage::reloadAllAndRebuildLists()
             continue;
 
         const auto access_entity_file_path = getEntityFilePath(directory_path, id);
-        auto entity = tryReadEntityFile(access_entity_file_path, *getLogger());
+        auto entity = tryReadEntityFile(access_entity_file_path, getLogger());
         if (!entity)
             continue;
 
diff --git a/src/Access/ExternalAuthenticators.cpp b/src/Access/ExternalAuthenticators.cpp
index 351bcb95c737..77812ac5eb5d 100644
--- a/src/Access/ExternalAuthenticators.cpp
+++ b/src/Access/ExternalAuthenticators.cpp
@@ -279,7 +279,7 @@ void ExternalAuthenticators::reset()
     resetImpl();
 }
 
-void ExternalAuthenticators::setConfiguration(const Poco::Util::AbstractConfiguration & config, Poco::Logger * log)
+void ExternalAuthenticators::setConfiguration(const Poco::Util::AbstractConfiguration & config, LoggerPtr log)
 {
     std::lock_guard lock(mutex);
     resetImpl();
diff --git a/src/Access/ExternalAuthenticators.h b/src/Access/ExternalAuthenticators.h
index 46c51f0d2f30..3a710e6df26a 100644
--- a/src/Access/ExternalAuthenticators.h
+++ b/src/Access/ExternalAuthenticators.h
@@ -36,7 +36,7 @@ class ExternalAuthenticators
 {
 public:
     void reset();
-    void setConfiguration(const Poco::Util::AbstractConfiguration & config, Poco::Logger * log);
+    void setConfiguration(const Poco::Util::AbstractConfiguration & config, LoggerPtr log);
 
     // The name and readiness of the credentials must be verified before calling these.
     bool checkLDAPCredentials(const String & server, const BasicCredentials & credentials,
diff --git a/src/Access/GSSAcceptor.cpp b/src/Access/GSSAcceptor.cpp
index 02946f0d74da..cfa1af6a2004 100644
--- a/src/Access/GSSAcceptor.cpp
+++ b/src/Access/GSSAcceptor.cpp
@@ -328,7 +328,7 @@ void GSSAcceptorContext::initHandles()
     }
 }
 
-String GSSAcceptorContext::processToken(const String & input_token, Poco::Logger * log)
+String GSSAcceptorContext::processToken(const String & input_token, LoggerPtr log)
 {
     std::lock_guard lock(gss_global_mutex);
 
@@ -455,7 +455,7 @@ void GSSAcceptorContext::initHandles()
 {
 }
 
-String GSSAcceptorContext::processToken(const String &, Poco::Logger *)
+String GSSAcceptorContext::processToken(const String &, LoggerPtr)
 {
     throw Exception(ErrorCodes::FEATURE_IS_NOT_ENABLED_AT_BUILD_TIME, "ClickHouse was built without GSS-API/Kerberos support");
 }
diff --git a/src/Access/GSSAcceptor.h b/src/Access/GSSAcceptor.h
index ba448ae474e8..8d490fb47ae5 100644
--- a/src/Access/GSSAcceptor.h
+++ b/src/Access/GSSAcceptor.h
@@ -3,6 +3,7 @@
 #include "config.h"
 
 #include <Access/Credentials.h>
+#include <Common/Logger.h>
 #include <base/types.h>
 #include <memory>
 
@@ -42,7 +43,7 @@ class GSSAcceptorContext
 
     const String & getRealm() const;
     bool isFailed() const;
-    MAYBE_NORETURN String processToken(const String & input_token, Poco::Logger * log);
+    MAYBE_NORETURN String processToken(const String & input_token, LoggerPtr log);
 
 private:
     void reset();
diff --git a/src/Access/IAccessStorage.cpp b/src/Access/IAccessStorage.cpp
index 222f38b41b69..fbe9e2310028 100644
--- a/src/Access/IAccessStorage.cpp
+++ b/src/Access/IAccessStorage.cpp
@@ -6,6 +6,7 @@
 #include <Backups/BackupEntriesCollector.h>
 #include <Common/Exception.h>
 #include <Common/quoteString.h>
+#include <Common/callOnce.h>
 #include <IO/WriteHelpers.h>
 #include <Interpreters/Context.h>
 #include <Poco/UUIDGenerator.h>
@@ -615,7 +616,7 @@ UUID IAccessStorage::generateRandomID()
 }
 
 
-void IAccessStorage::clearConflictsInEntitiesList(std::vector<std::pair<UUID, AccessEntityPtr>> & entities, const Poco::Logger * log_)
+void IAccessStorage::clearConflictsInEntitiesList(std::vector<std::pair<UUID, AccessEntityPtr>> & entities, const LoggerPtr log_)
 {
     std::unordered_map<UUID, size_t> positions_by_id;
     std::unordered_map<std::string_view, size_t> positions_by_type_and_name[static_cast<size_t>(AccessEntityType::MAX)];
@@ -671,12 +672,13 @@ void IAccessStorage::clearConflictsInEntitiesList(std::vector<std::pair<UUID, Ac
 }
 
 
-Poco::Logger * IAccessStorage::getLogger() const
+LoggerPtr IAccessStorage::getLogger() const
 {
-    Poco::Logger * ptr = log.load();
-    if (!ptr)
-        log.store(ptr = &Poco::Logger::get("Access(" + storage_name + ")"), std::memory_order_relaxed);
-    return ptr;
+    callOnce(log_initialized, [&] {
+        log = ::getLogger("Access(" + storage_name + ")");
+    });
+
+    return log;
 }
 
 
diff --git a/src/Access/IAccessStorage.h b/src/Access/IAccessStorage.h
index 797318438e11..5ac66fc9b8a0 100644
--- a/src/Access/IAccessStorage.h
+++ b/src/Access/IAccessStorage.h
@@ -6,6 +6,7 @@
 #include <Parsers/IParser.h>
 #include <Parsers/parseIdentifierOrStringLiteral.h>
 #include <Common/SettingsChanges.h>
+#include <Common/callOnce.h>
 
 #include <atomic>
 #include <functional>
@@ -225,9 +226,9 @@ class IAccessStorage : public boost::noncopyable
         SettingsChanges & settings) const;
     virtual bool isAddressAllowed(const User & user, const Poco::Net::IPAddress & address) const;
     static UUID generateRandomID();
-    Poco::Logger * getLogger() const;
+    LoggerPtr getLogger() const;
     static String formatEntityTypeWithName(AccessEntityType type, const String & name) { return AccessEntityTypeInfo::get(type).formatEntityNameWithType(name); }
-    static void clearConflictsInEntitiesList(std::vector<std::pair<UUID, AccessEntityPtr>> & entities, const Poco::Logger * log_);
+    static void clearConflictsInEntitiesList(std::vector<std::pair<UUID, AccessEntityPtr>> & entities, const LoggerPtr log_);
     [[noreturn]] void throwNotFound(const UUID & id) const;
     [[noreturn]] void throwNotFound(AccessEntityType type, const String & name) const;
     [[noreturn]] static void throwBadCast(const UUID & id, AccessEntityType type, const String & name, AccessEntityType required_type);
@@ -246,7 +247,9 @@ class IAccessStorage : public boost::noncopyable
 
 private:
     const String storage_name;
-    mutable std::atomic<Poco::Logger *> log = nullptr;
+
+    mutable OnceFlag log_initialized;
+    mutable LoggerPtr log = nullptr;
 };
 
 
diff --git a/src/Access/KerberosInit.cpp b/src/Access/KerberosInit.cpp
index 772938ad9b29..3cda1c8e13c8 100644
--- a/src/Access/KerberosInit.cpp
+++ b/src/Access/KerberosInit.cpp
@@ -63,7 +63,7 @@ String KerberosInit::fmtError(krb5_error_code code) const
 
 void KerberosInit::init(const String & keytab_file, const String & principal, const String & cache_name)
 {
-    auto * log = &Poco::Logger::get("KerberosInit");
+    auto log = getLogger("KerberosInit");
     LOG_TRACE(log,"Trying to authenticate with Kerberos v5");
 
     krb5_error_code ret;
diff --git a/src/Access/LDAPClient.cpp b/src/Access/LDAPClient.cpp
index 7926298061d5..3a0b82b9a760 100644
--- a/src/Access/LDAPClient.cpp
+++ b/src/Access/LDAPClient.cpp
@@ -532,7 +532,7 @@ LDAPClient::SearchResults LDAPClient::search(const SearchParams & search_params)
 
                     for (size_t i = 0; referrals[i]; ++i)
                     {
-                        LOG_WARNING(&Poco::Logger::get("LDAPClient"), "Received reference during LDAP search but not following it: {}", referrals[i]);
+                        LOG_WARNING(getLogger("LDAPClient"), "Received reference during LDAP search but not following it: {}", referrals[i]);
                     }
                 }
 
diff --git a/src/Access/RowPolicyCache.cpp b/src/Access/RowPolicyCache.cpp
index bb9da674477c..13140099a639 100644
--- a/src/Access/RowPolicyCache.cpp
+++ b/src/Access/RowPolicyCache.cpp
@@ -91,7 +91,7 @@ void RowPolicyCache::PolicyInfo::setPolicy(const RowPolicyPtr & policy_)
         catch (...)
         {
             tryLogCurrentException(
-                &Poco::Logger::get("RowPolicy"),
+                getLogger("RowPolicy"),
                 String("Could not parse the condition ") + toString(filter_type) + " of row policy "
                     + backQuote(policy->getName()));
         }
diff --git a/src/Access/SettingsAuthResponseParser.cpp b/src/Access/SettingsAuthResponseParser.cpp
index 62d15f1dcfc8..a90ae61f93a9 100644
--- a/src/Access/SettingsAuthResponseParser.cpp
+++ b/src/Access/SettingsAuthResponseParser.cpp
@@ -37,7 +37,7 @@ SettingsAuthResponseParser::parse(const Poco::Net::HTTPResponse & response, std:
     }
     catch (...)
     {
-        LOG_INFO(&Poco::Logger::get("HTTPAuthentication"), "Failed to parse settings from authentication response. Skip it.");
+        LOG_INFO(getLogger("HTTPAuthentication"), "Failed to parse settings from authentication response. Skip it.");
     }
     return result;
 }
diff --git a/src/Backups/BackupCoordinationLocal.cpp b/src/Backups/BackupCoordinationLocal.cpp
index fb91bae2303b..9964de2ad6e0 100644
--- a/src/Backups/BackupCoordinationLocal.cpp
+++ b/src/Backups/BackupCoordinationLocal.cpp
@@ -9,7 +9,7 @@ namespace DB
 {
 
 BackupCoordinationLocal::BackupCoordinationLocal(bool plain_backup_)
-    : log(&Poco::Logger::get("BackupCoordinationLocal")), file_infos(plain_backup_)
+    : log(getLogger("BackupCoordinationLocal")), file_infos(plain_backup_)
 {
 }
 
diff --git a/src/Backups/BackupCoordinationLocal.h b/src/Backups/BackupCoordinationLocal.h
index f73cbbe29a89..7719ffd3e52e 100644
--- a/src/Backups/BackupCoordinationLocal.h
+++ b/src/Backups/BackupCoordinationLocal.h
@@ -57,7 +57,7 @@ class BackupCoordinationLocal : public IBackupCoordination
     bool hasConcurrentBackups(const std::atomic<size_t> & num_active_backups) const override;
 
 private:
-    Poco::Logger * const log;
+    LoggerPtr const log;
 
     BackupCoordinationReplicatedTables TSA_GUARDED_BY(replicated_tables_mutex) replicated_tables;
     BackupCoordinationReplicatedAccess TSA_GUARDED_BY(replicated_access_mutex) replicated_access;
diff --git a/src/Backups/BackupCoordinationRemote.cpp b/src/Backups/BackupCoordinationRemote.cpp
index 4662f436aba4..9c509858b2a3 100644
--- a/src/Backups/BackupCoordinationRemote.cpp
+++ b/src/Backups/BackupCoordinationRemote.cpp
@@ -173,7 +173,7 @@ BackupCoordinationRemote::BackupCoordinationRemote(
     , current_host_index(findCurrentHostIndex(all_hosts, current_host))
     , plain_backup(plain_backup_)
     , is_internal(is_internal_)
-    , log(&Poco::Logger::get("BackupCoordinationRemote"))
+    , log(getLogger("BackupCoordinationRemote"))
     , with_retries(
         log,
         get_zookeeper_,
diff --git a/src/Backups/BackupCoordinationRemote.h b/src/Backups/BackupCoordinationRemote.h
index 81980ee56373..ce891699bd29 100644
--- a/src/Backups/BackupCoordinationRemote.h
+++ b/src/Backups/BackupCoordinationRemote.h
@@ -102,7 +102,7 @@ class BackupCoordinationRemote : public IBackupCoordination
     const size_t current_host_index;
     const bool plain_backup;
     const bool is_internal;
-    Poco::Logger * const log;
+    LoggerPtr const log;
 
     /// The order of these two fields matters, because stage_sync holds a reference to with_retries object
     mutable WithRetries with_retries;
diff --git a/src/Backups/BackupCoordinationStageSync.cpp b/src/Backups/BackupCoordinationStageSync.cpp
index 2eba3440be93..17ef163ce352 100644
--- a/src/Backups/BackupCoordinationStageSync.cpp
+++ b/src/Backups/BackupCoordinationStageSync.cpp
@@ -24,7 +24,7 @@ namespace ErrorCodes
 BackupCoordinationStageSync::BackupCoordinationStageSync(
     const String & root_zookeeper_path_,
     WithRetries & with_retries_,
-    Poco::Logger * log_)
+    LoggerPtr log_)
     : zookeeper_path(root_zookeeper_path_ + "/stage")
     , with_retries(with_retries_)
     , log(log_)
diff --git a/src/Backups/BackupCoordinationStageSync.h b/src/Backups/BackupCoordinationStageSync.h
index e34fbcc099b7..a06c5c610416 100644
--- a/src/Backups/BackupCoordinationStageSync.h
+++ b/src/Backups/BackupCoordinationStageSync.h
@@ -12,7 +12,7 @@ class BackupCoordinationStageSync
     BackupCoordinationStageSync(
         const String & root_zookeeper_path_,
         WithRetries & with_retries_,
-        Poco::Logger * log_);
+        LoggerPtr log_);
 
     /// Sets the stage of the current host and signal other hosts if there were other hosts waiting for that.
     void set(const String & current_host, const String & new_stage, const String & message, const bool & all_hosts = false);
@@ -36,7 +36,7 @@ class BackupCoordinationStageSync
     String zookeeper_path;
     /// A reference to the field of parent object - BackupCoordinationRemote or RestoreCoordinationRemote
     WithRetries & with_retries;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Backups/BackupEntriesCollector.cpp b/src/Backups/BackupEntriesCollector.cpp
index bf9cf50a67ad..5c0b80aa894a 100644
--- a/src/Backups/BackupEntriesCollector.cpp
+++ b/src/Backups/BackupEntriesCollector.cpp
@@ -97,7 +97,7 @@ BackupEntriesCollector::BackupEntriesCollector(
     , max_sleep_before_next_attempt_to_collect_metadata(
           context->getConfigRef().getUInt64("backups.max_sleep_before_next_attempt_to_collect_metadata", 5000))
     , compare_collected_metadata(context->getConfigRef().getBool("backups.compare_collected_metadata", true))
-    , log(&Poco::Logger::get("BackupEntriesCollector"))
+    , log(getLogger("BackupEntriesCollector"))
     , global_zookeeper_retries_info(
           context->getSettingsRef().backup_restore_keeper_max_retries,
           context->getSettingsRef().backup_restore_keeper_retry_initial_backoff_ms,
diff --git a/src/Backups/BackupEntriesCollector.h b/src/Backups/BackupEntriesCollector.h
index fcbc5e5985fa..bad67e494c4c 100644
--- a/src/Backups/BackupEntriesCollector.h
+++ b/src/Backups/BackupEntriesCollector.h
@@ -129,7 +129,7 @@ class BackupEntriesCollector : private boost::noncopyable
     /// Whether we should collect the metadata after a successful attempt one more time and check that nothing has changed.
     const bool compare_collected_metadata;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     /// Unfortunately we can use ZooKeeper for collecting information for backup
     /// and we need to retry...
     ZooKeeperRetriesInfo global_zookeeper_retries_info;
diff --git a/src/Backups/BackupFileInfo.cpp b/src/Backups/BackupFileInfo.cpp
index 2a1642f3b84b..f14b955149e3 100644
--- a/src/Backups/BackupFileInfo.cpp
+++ b/src/Backups/BackupFileInfo.cpp
@@ -102,7 +102,7 @@ BackupFileInfo buildFileInfoForBackupEntry(
     const BackupEntryPtr & backup_entry,
     const BackupPtr & base_backup,
     const ReadSettings & read_settings,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     auto adjusted_path = removeLeadingSlash(file_name);
 
@@ -129,7 +129,7 @@ BackupFileInfo buildFileInfoForBackupEntry(
     }
 
     if (!log)
-        log = &Poco::Logger::get("FileInfoFromBackupEntry");
+        log = getLogger("FileInfoFromBackupEntry");
 
     std::optional<SizeAndChecksum> base_backup_file_info = getInfoAboutFileFromBaseBackupIfExists(base_backup, adjusted_path);
 
@@ -216,7 +216,7 @@ BackupFileInfos buildFileInfosForBackupEntries(const BackupEntries & backup_entr
     std::exception_ptr exception;
 
     auto thread_group = CurrentThread::getGroup();
-    Poco::Logger * log = &Poco::Logger::get("FileInfosFromBackupEntries");
+    LoggerPtr log = getLogger("FileInfosFromBackupEntries");
 
     for (size_t i = 0; i != backup_entries.size(); ++i)
     {
diff --git a/src/Backups/BackupFileInfo.h b/src/Backups/BackupFileInfo.h
index 15c385950024..a1405a9cafb4 100644
--- a/src/Backups/BackupFileInfo.h
+++ b/src/Backups/BackupFileInfo.h
@@ -2,8 +2,7 @@
 
 #include <Core/Types.h>
 #include <Common/ThreadPool_fwd.h>
-
-namespace Poco { class Logger; }
+#include <Common/Logger.h>
 
 namespace DB
 {
@@ -77,7 +76,7 @@ struct BackupFileInfo
 using BackupFileInfos = std::vector<BackupFileInfo>;
 
 /// Builds a BackupFileInfo for a specified backup entry.
-BackupFileInfo buildFileInfoForBackupEntry(const String & file_name, const BackupEntryPtr & backup_entry, const BackupPtr & base_backup, const ReadSettings & read_settings, Poco::Logger * log);
+BackupFileInfo buildFileInfoForBackupEntry(const String & file_name, const BackupEntryPtr & backup_entry, const BackupPtr & base_backup, const ReadSettings & read_settings, LoggerPtr log);
 
 /// Builds a vector of BackupFileInfos for specified backup entries.
 BackupFileInfos buildFileInfosForBackupEntries(const BackupEntries & backup_entries, const BackupPtr & base_backup, const ReadSettings & read_settings, ThreadPool & thread_pool, QueryStatusPtr process_list_element);
diff --git a/src/Backups/BackupIO_Default.cpp b/src/Backups/BackupIO_Default.cpp
index 5ac522695ce2..77fd4532c8f2 100644
--- a/src/Backups/BackupIO_Default.cpp
+++ b/src/Backups/BackupIO_Default.cpp
@@ -10,7 +10,7 @@
 namespace DB
 {
 
-BackupReaderDefault::BackupReaderDefault(const ReadSettings & read_settings_, const WriteSettings & write_settings_, Poco::Logger * log_)
+BackupReaderDefault::BackupReaderDefault(const ReadSettings & read_settings_, const WriteSettings & write_settings_, LoggerPtr log_)
     : log(log_)
     , read_settings(read_settings_)
     , write_settings(write_settings_)
@@ -36,7 +36,7 @@ void BackupReaderDefault::copyFileToDisk(const String & path_in_backup, size_t f
     write_buffer->finalize();
 }
 
-BackupWriterDefault::BackupWriterDefault(const ReadSettings & read_settings_, const WriteSettings & write_settings_, Poco::Logger * log_)
+BackupWriterDefault::BackupWriterDefault(const ReadSettings & read_settings_, const WriteSettings & write_settings_, LoggerPtr log_)
     : log(log_)
     , read_settings(read_settings_)
     , write_settings(write_settings_)
diff --git a/src/Backups/BackupIO_Default.h b/src/Backups/BackupIO_Default.h
index b4888fecd2fb..639293f22d9f 100644
--- a/src/Backups/BackupIO_Default.h
+++ b/src/Backups/BackupIO_Default.h
@@ -18,7 +18,7 @@ enum class WriteMode;
 class BackupReaderDefault : public IBackupReader
 {
 public:
-    BackupReaderDefault(const ReadSettings & read_settings_, const WriteSettings & write_settings_, Poco::Logger * log_);
+    BackupReaderDefault(const ReadSettings & read_settings_, const WriteSettings & write_settings_, LoggerPtr log_);
     ~BackupReaderDefault() override = default;
 
     /// The function copyFileToDisk() can be much faster than reading the file with readFile() and then writing it to some disk.
@@ -33,7 +33,7 @@ class BackupReaderDefault : public IBackupReader
     size_t getWriteBufferSize() const override { return write_buffer_size; }
 
 protected:
-    Poco::Logger * const log;
+    LoggerPtr const log;
     const ReadSettings read_settings;
 
     /// The write settings are used to write to the source disk in copyFileToDisk().
@@ -45,7 +45,7 @@ class BackupReaderDefault : public IBackupReader
 class BackupWriterDefault : public IBackupWriter
 {
 public:
-    BackupWriterDefault(const ReadSettings & read_settings_, const WriteSettings & write_settings_, Poco::Logger * log_);
+    BackupWriterDefault(const ReadSettings & read_settings_, const WriteSettings & write_settings_, LoggerPtr log_);
     ~BackupWriterDefault() override = default;
 
     bool fileContentsEqual(const String & file_name, const String & expected_file_contents) override;
@@ -60,7 +60,7 @@ class BackupWriterDefault : public IBackupWriter
     /// Here readFile() is used only to implement fileContentsEqual().
     virtual std::unique_ptr<ReadBuffer> readFile(const String & file_name, size_t expected_file_size) = 0;
 
-    Poco::Logger * const log;
+    LoggerPtr const log;
 
     /// The read settings are used to read from the source disk in copyFileFromDisk().
     const ReadSettings read_settings;
diff --git a/src/Backups/BackupIO_Disk.cpp b/src/Backups/BackupIO_Disk.cpp
index 91e8b97bc20a..27b594f6bb8d 100644
--- a/src/Backups/BackupIO_Disk.cpp
+++ b/src/Backups/BackupIO_Disk.cpp
@@ -9,7 +9,7 @@ namespace DB
 {
 
 BackupReaderDisk::BackupReaderDisk(const DiskPtr & disk_, const String & root_path_, const ReadSettings & read_settings_, const WriteSettings & write_settings_)
-    : BackupReaderDefault(read_settings_, write_settings_, &Poco::Logger::get("BackupReaderDisk"))
+    : BackupReaderDefault(read_settings_, write_settings_, getLogger("BackupReaderDisk"))
     , disk(disk_)
     , root_path(root_path_)
     , data_source_description(disk->getDataSourceDescription())
@@ -57,7 +57,7 @@ void BackupReaderDisk::copyFileToDisk(const String & path_in_backup, size_t file
 
 
 BackupWriterDisk::BackupWriterDisk(const DiskPtr & disk_, const String & root_path_, const ReadSettings & read_settings_, const WriteSettings & write_settings_)
-    : BackupWriterDefault(read_settings_, write_settings_, &Poco::Logger::get("BackupWriterDisk"))
+    : BackupWriterDefault(read_settings_, write_settings_, getLogger("BackupWriterDisk"))
     , disk(disk_)
     , root_path(root_path_)
     , data_source_description(disk->getDataSourceDescription())
diff --git a/src/Backups/BackupIO_File.cpp b/src/Backups/BackupIO_File.cpp
index 5384637a9693..35544a526f16 100644
--- a/src/Backups/BackupIO_File.cpp
+++ b/src/Backups/BackupIO_File.cpp
@@ -17,7 +17,7 @@ namespace ErrorCodes
 }
 
 BackupReaderFile::BackupReaderFile(const String & root_path_, const ReadSettings & read_settings_, const WriteSettings & write_settings_)
-    : BackupReaderDefault(read_settings_, write_settings_, &Poco::Logger::get("BackupReaderFile"))
+    : BackupReaderDefault(read_settings_, write_settings_, getLogger("BackupReaderFile"))
     , root_path(root_path_)
     , data_source_description(DiskLocal::getLocalDataSourceDescription(root_path))
 {
@@ -75,7 +75,7 @@ void BackupReaderFile::copyFileToDisk(const String & path_in_backup, size_t file
 
 
 BackupWriterFile::BackupWriterFile(const String & root_path_, const ReadSettings & read_settings_, const WriteSettings & write_settings_)
-    : BackupWriterDefault(read_settings_, write_settings_, &Poco::Logger::get("BackupWriterFile"))
+    : BackupWriterDefault(read_settings_, write_settings_, getLogger("BackupWriterFile"))
     , root_path(root_path_)
     , data_source_description(DiskLocal::getLocalDataSourceDescription(root_path))
 {
diff --git a/src/Backups/BackupIO_S3.cpp b/src/Backups/BackupIO_S3.cpp
index 381c58dd0456..fa4c1af36983 100644
--- a/src/Backups/BackupIO_S3.cpp
+++ b/src/Backups/BackupIO_S3.cpp
@@ -124,7 +124,7 @@ BackupReaderS3::BackupReaderS3(
     const ReadSettings & read_settings_,
     const WriteSettings & write_settings_,
     const ContextPtr & context_)
-    : BackupReaderDefault(read_settings_, write_settings_, &Poco::Logger::get("BackupReaderS3"))
+    : BackupReaderDefault(read_settings_, write_settings_, getLogger("BackupReaderS3"))
     , s3_uri(s3_uri_)
     , data_source_description{DataSourceType::ObjectStorage, ObjectStorageType::S3, MetadataStorageType::None, s3_uri.endpoint, false, false}
     , s3_settings(context_->getStorageS3Settings().getSettings(s3_uri.uri.toString()))
@@ -214,7 +214,7 @@ BackupWriterS3::BackupWriterS3(
     const ReadSettings & read_settings_,
     const WriteSettings & write_settings_,
     const ContextPtr & context_)
-    : BackupWriterDefault(read_settings_, write_settings_, &Poco::Logger::get("BackupWriterS3"))
+    : BackupWriterDefault(read_settings_, write_settings_, getLogger("BackupWriterS3"))
     , s3_uri(s3_uri_)
     , data_source_description{DataSourceType::ObjectStorage, ObjectStorageType::S3, MetadataStorageType::None, s3_uri.endpoint, false, false}
     , s3_settings(context_->getStorageS3Settings().getSettings(s3_uri.uri.toString()))
diff --git a/src/Backups/BackupImpl.cpp b/src/Backups/BackupImpl.cpp
index 9ac68bc24378..0961c867cab6 100644
--- a/src/Backups/BackupImpl.cpp
+++ b/src/Backups/BackupImpl.cpp
@@ -105,7 +105,7 @@ BackupImpl::BackupImpl(
     , version(INITIAL_BACKUP_VERSION)
     , base_backup_info(base_backup_info_)
     , use_same_s3_credentials_for_base_backup(use_same_s3_credentials_for_base_backup_)
-    , log(&Poco::Logger::get("BackupImpl"))
+    , log(getLogger("BackupImpl"))
 {
     open();
 }
@@ -136,7 +136,7 @@ BackupImpl::BackupImpl(
     , base_backup_info(base_backup_info_)
     , deduplicate_files(deduplicate_files_)
     , use_same_s3_credentials_for_base_backup(use_same_s3_credentials_for_base_backup_)
-    , log(&Poco::Logger::get("BackupImpl"))
+    , log(getLogger("BackupImpl"))
 {
     open();
 }
diff --git a/src/Backups/BackupImpl.h b/src/Backups/BackupImpl.h
index b369fe001719..e9803b46bb4d 100644
--- a/src/Backups/BackupImpl.h
+++ b/src/Backups/BackupImpl.h
@@ -153,7 +153,7 @@ class BackupImpl : public IBackup
     bool writing_finalized = false;
     bool deduplicate_files = true;
     bool use_same_s3_credentials_for_base_backup = false;
-    const Poco::Logger * log;
+    const LoggerPtr log;
 };
 
 }
diff --git a/src/Backups/BackupsWorker.cpp b/src/Backups/BackupsWorker.cpp
index 9c1b6d8af97e..c19be22c7499 100644
--- a/src/Backups/BackupsWorker.cpp
+++ b/src/Backups/BackupsWorker.cpp
@@ -380,7 +380,7 @@ BackupsWorker::BackupsWorker(ContextMutablePtr global_context, size_t num_backup
     , allow_concurrent_backups(allow_concurrent_backups_)
     , allow_concurrent_restores(allow_concurrent_restores_)
     , test_inject_sleep(test_inject_sleep_)
-    , log(&Poco::Logger::get("BackupsWorker"))
+    , log(getLogger("BackupsWorker"))
     , backup_log(global_context->getBackupLog())
     , process_list(global_context->getProcessList())
 {
diff --git a/src/Backups/BackupsWorker.h b/src/Backups/BackupsWorker.h
index 7a514e7032ba..73c8bf194730 100644
--- a/src/Backups/BackupsWorker.h
+++ b/src/Backups/BackupsWorker.h
@@ -127,7 +127,7 @@ class BackupsWorker
     const bool allow_concurrent_restores;
     const bool test_inject_sleep;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     struct ExtendedOperationInfo
     {
diff --git a/src/Backups/RestoreCoordinationLocal.cpp b/src/Backups/RestoreCoordinationLocal.cpp
index cf606151b53e..4a91b8d95a5e 100644
--- a/src/Backups/RestoreCoordinationLocal.cpp
+++ b/src/Backups/RestoreCoordinationLocal.cpp
@@ -6,7 +6,7 @@
 namespace DB
 {
 
-RestoreCoordinationLocal::RestoreCoordinationLocal() : log(&Poco::Logger::get("RestoreCoordinationLocal"))
+RestoreCoordinationLocal::RestoreCoordinationLocal() : log(getLogger("RestoreCoordinationLocal"))
 {
 }
 
diff --git a/src/Backups/RestoreCoordinationLocal.h b/src/Backups/RestoreCoordinationLocal.h
index 7f6ffe1eeec1..5e51b719d637 100644
--- a/src/Backups/RestoreCoordinationLocal.h
+++ b/src/Backups/RestoreCoordinationLocal.h
@@ -51,7 +51,7 @@ class RestoreCoordinationLocal : public IRestoreCoordination
     bool hasConcurrentRestores(const std::atomic<size_t> & num_active_restores) const override;
 
 private:
-    Poco::Logger * const log;
+    LoggerPtr const log;
 
     std::set<std::pair<String /* database_zk_path */, String /* table_name */>> acquired_tables_in_replicated_databases;
     std::unordered_set<String /* table_zk_path */> acquired_data_in_replicated_tables;
diff --git a/src/Backups/RestoreCoordinationRemote.cpp b/src/Backups/RestoreCoordinationRemote.cpp
index 0d2b3832bad5..84106737fc9d 100644
--- a/src/Backups/RestoreCoordinationRemote.cpp
+++ b/src/Backups/RestoreCoordinationRemote.cpp
@@ -32,7 +32,7 @@ RestoreCoordinationRemote::RestoreCoordinationRemote(
     , current_host(current_host_)
     , current_host_index(BackupCoordinationRemote::findCurrentHostIndex(all_hosts, current_host))
     , is_internal(is_internal_)
-    , log(&Poco::Logger::get("RestoreCoordinationRemote"))
+    , log(getLogger("RestoreCoordinationRemote"))
     , with_retries(
         log,
         get_zookeeper_,
diff --git a/src/Backups/RestoreCoordinationRemote.h b/src/Backups/RestoreCoordinationRemote.h
index f7e678645df5..9c299865cfa7 100644
--- a/src/Backups/RestoreCoordinationRemote.h
+++ b/src/Backups/RestoreCoordinationRemote.h
@@ -73,7 +73,7 @@ class RestoreCoordinationRemote : public IRestoreCoordination
     const String current_host;
     const size_t current_host_index;
     const bool is_internal;
-    Poco::Logger * const log;
+    LoggerPtr const log;
 
     mutable WithRetries with_retries;
     std::optional<BackupCoordinationStageSync> stage_sync;
diff --git a/src/Backups/RestorerFromBackup.cpp b/src/Backups/RestorerFromBackup.cpp
index f218410e5993..6f18c070cd73 100644
--- a/src/Backups/RestorerFromBackup.cpp
+++ b/src/Backups/RestorerFromBackup.cpp
@@ -89,7 +89,7 @@ RestorerFromBackup::RestorerFromBackup(
     , process_list_element(context->getProcessListElement())
     , on_cluster_first_sync_timeout(context->getConfigRef().getUInt64("backups.on_cluster_first_sync_timeout", 180000))
     , create_table_timeout(context->getConfigRef().getUInt64("backups.create_table_timeout", 300000))
-    , log(&Poco::Logger::get("RestorerFromBackup"))
+    , log(getLogger("RestorerFromBackup"))
     , tables_dependencies("RestorerFromBackup")
 {
 }
diff --git a/src/Backups/RestorerFromBackup.h b/src/Backups/RestorerFromBackup.h
index fad79a3a2e6d..5e4ee0c38329 100644
--- a/src/Backups/RestorerFromBackup.h
+++ b/src/Backups/RestorerFromBackup.h
@@ -79,7 +79,7 @@ class RestorerFromBackup : private boost::noncopyable
     QueryStatusPtr process_list_element;
     std::chrono::milliseconds on_cluster_first_sync_timeout;
     std::chrono::milliseconds create_table_timeout;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     Strings all_hosts;
     DDLRenamingMap renaming_map;
diff --git a/src/Backups/WithRetries.cpp b/src/Backups/WithRetries.cpp
index db36bc92d92b..66851fa42ce4 100644
--- a/src/Backups/WithRetries.cpp
+++ b/src/Backups/WithRetries.cpp
@@ -21,7 +21,7 @@ WithRetries::KeeperSettings WithRetries::KeeperSettings::fromContext(ContextPtr
 }
 
 WithRetries::WithRetries(
-    Poco::Logger * log_, zkutil::GetZooKeeper get_zookeeper_, const KeeperSettings & settings_, QueryStatusPtr process_list_element_, RenewerCallback callback_)
+    LoggerPtr log_, zkutil::GetZooKeeper get_zookeeper_, const KeeperSettings & settings_, QueryStatusPtr process_list_element_, RenewerCallback callback_)
     : log(log_)
     , get_zookeeper(get_zookeeper_)
     , settings(settings_)
diff --git a/src/Backups/WithRetries.h b/src/Backups/WithRetries.h
index edfccc658d91..3a6e28996b93 100644
--- a/src/Backups/WithRetries.h
+++ b/src/Backups/WithRetries.h
@@ -52,7 +52,7 @@ class WithRetries
     };
 
     RetriesControlHolder createRetriesControlHolder(const String & name);
-    WithRetries(Poco::Logger * log, zkutil::GetZooKeeper get_zookeeper_, const KeeperSettings & settings, QueryStatusPtr process_list_element_, RenewerCallback callback);
+    WithRetries(LoggerPtr log, zkutil::GetZooKeeper get_zookeeper_, const KeeperSettings & settings, QueryStatusPtr process_list_element_, RenewerCallback callback);
 
     /// Used to re-establish new connection inside a retry loop.
     void renewZooKeeper(FaultyKeeper my_faulty_zookeeper) const;
@@ -62,7 +62,7 @@ class WithRetries
     /// This will provide a special wrapper which is useful for testing
     FaultyKeeper getFaultyZooKeeper() const;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     zkutil::GetZooKeeper get_zookeeper;
     KeeperSettings settings;
     QueryStatusPtr process_list_element;
diff --git a/src/BridgeHelper/IBridgeHelper.h b/src/BridgeHelper/IBridgeHelper.h
index 272d97c8a781..6812bd04a030 100644
--- a/src/BridgeHelper/IBridgeHelper.h
+++ b/src/BridgeHelper/IBridgeHelper.h
@@ -51,7 +51,7 @@ class IBridgeHelper: protected WithContext
 
     virtual const Poco::Util::AbstractConfiguration & getConfig() const = 0;
 
-    virtual Poco::Logger * getLog() const = 0;
+    virtual LoggerPtr getLog() const = 0;
 
     virtual Poco::Timespan getHTTPTimeout() const = 0;
 
diff --git a/src/BridgeHelper/LibraryBridgeHelper.cpp b/src/BridgeHelper/LibraryBridgeHelper.cpp
index e83707595b9b..84bfe096e796 100644
--- a/src/BridgeHelper/LibraryBridgeHelper.cpp
+++ b/src/BridgeHelper/LibraryBridgeHelper.cpp
@@ -8,7 +8,7 @@ namespace DB
 LibraryBridgeHelper::LibraryBridgeHelper(ContextPtr context_)
     : IBridgeHelper(context_)
     , config(context_->getConfigRef())
-    , log(&Poco::Logger::get("LibraryBridgeHelper"))
+    , log(getLogger("LibraryBridgeHelper"))
     , http_timeout(context_->getGlobalContext()->getSettingsRef().http_receive_timeout.value)
     , bridge_host(config.getString("library_bridge.host", DEFAULT_HOST))
     , bridge_port(config.getUInt("library_bridge.port", DEFAULT_PORT))
diff --git a/src/BridgeHelper/LibraryBridgeHelper.h b/src/BridgeHelper/LibraryBridgeHelper.h
index 1723d1f8fb4d..8940f9d1c9ee 100644
--- a/src/BridgeHelper/LibraryBridgeHelper.h
+++ b/src/BridgeHelper/LibraryBridgeHelper.h
@@ -31,7 +31,7 @@ class LibraryBridgeHelper : public IBridgeHelper
 
     const Poco::Util::AbstractConfiguration & getConfig() const override { return config; }
 
-    Poco::Logger * getLog() const override { return log; }
+    LoggerPtr getLog() const override { return log; }
 
     Poco::Timespan getHTTPTimeout() const override { return http_timeout; }
 
@@ -40,7 +40,7 @@ class LibraryBridgeHelper : public IBridgeHelper
     static constexpr inline size_t DEFAULT_PORT = 9012;
 
     const Poco::Util::AbstractConfiguration & config;
-    Poco::Logger * log;
+    LoggerPtr log;
     const Poco::Timespan http_timeout;
     std::string bridge_host;
     size_t bridge_port;
diff --git a/src/BridgeHelper/XDBCBridgeHelper.h b/src/BridgeHelper/XDBCBridgeHelper.h
index 060de74b5b16..d208b8ddab07 100644
--- a/src/BridgeHelper/XDBCBridgeHelper.h
+++ b/src/BridgeHelper/XDBCBridgeHelper.h
@@ -65,7 +65,7 @@ class XDBCBridgeHelper : public IXDBCBridgeHelper
             const std::string & connection_string_,
             bool use_connection_pooling_)
         : IXDBCBridgeHelper(context_->getGlobalContext())
-        , log(&Poco::Logger::get(BridgeHelperMixin::getName() + "BridgeHelper"))
+        , log(getLogger(BridgeHelperMixin::getName() + "BridgeHelper"))
         , connection_string(connection_string_)
         , use_connection_pooling(use_connection_pooling_)
         , http_timeout(http_timeout_)
@@ -123,7 +123,7 @@ class XDBCBridgeHelper : public IXDBCBridgeHelper
 
     const Poco::Util::AbstractConfiguration & getConfig() const override { return config; }
 
-    Poco::Logger * getLog() const override { return log; }
+    LoggerPtr getLog() const override { return log; }
 
     bool startBridgeManually() const override { return BridgeHelperMixin::startBridgeManually(); }
 
@@ -146,7 +146,7 @@ class XDBCBridgeHelper : public IXDBCBridgeHelper
 private:
     using Configuration = Poco::Util::AbstractConfiguration;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     std::string connection_string;
     bool use_connection_pooling;
     Poco::Timespan http_timeout;
diff --git a/src/Client/Connection.h b/src/Client/Connection.h
index 2f209fc92d03..e93a7539d153 100644
--- a/src/Client/Connection.h
+++ b/src/Client/Connection.h
@@ -4,6 +4,7 @@
 #include <Poco/Net/StreamSocket.h>
 
 #include <Common/SSH/Wrappers.h>
+#include <Common/callOnce.h>
 #include <Client/IServerConnection.h>
 #include <Core/Defines.h>
 
@@ -244,16 +245,18 @@ class Connection : public IServerConnection
         {
         }
 
-        Poco::Logger * get()
+        LoggerPtr get()
         {
-            if (!log)
-                log = &Poco::Logger::get("Connection (" + parent.getDescription() + ")");
+            callOnce(log_initialized, [&] {
+                log = getLogger("Connection (" + parent.getDescription() + ")");
+            });
 
             return log;
         }
 
     private:
-        std::atomic<Poco::Logger *> log;
+        OnceFlag log_initialized;
+        LoggerPtr log;
         Connection & parent;
     };
 
diff --git a/src/Client/ConnectionEstablisher.cpp b/src/Client/ConnectionEstablisher.cpp
index e5b1347add5b..a9009e5bb25f 100644
--- a/src/Client/ConnectionEstablisher.cpp
+++ b/src/Client/ConnectionEstablisher.cpp
@@ -25,7 +25,7 @@ ConnectionEstablisher::ConnectionEstablisher(
     IConnectionPool * pool_,
     const ConnectionTimeouts * timeouts_,
     const Settings & settings_,
-    Poco::Logger * log_,
+    LoggerPtr log_,
     const QualifiedTableName * table_to_check_)
     : pool(pool_), timeouts(timeouts_), settings(settings_), log(log_), table_to_check(table_to_check_), is_finished(false)
 {
@@ -114,7 +114,7 @@ ConnectionEstablisherAsync::ConnectionEstablisherAsync(
     IConnectionPool * pool_,
     const ConnectionTimeouts * timeouts_,
     const Settings & settings_,
-    Poco::Logger * log_,
+    LoggerPtr log_,
     const QualifiedTableName * table_to_check_)
     : AsyncTaskExecutor(std::make_unique<Task>(*this)), connection_establisher(pool_, timeouts_, settings_, log_, table_to_check_)
 {
diff --git a/src/Client/ConnectionEstablisher.h b/src/Client/ConnectionEstablisher.h
index 880e44c8a1a5..7ea65708b1d5 100644
--- a/src/Client/ConnectionEstablisher.h
+++ b/src/Client/ConnectionEstablisher.h
@@ -23,7 +23,7 @@ class ConnectionEstablisher
     ConnectionEstablisher(IConnectionPool * pool_,
                           const ConnectionTimeouts * timeouts_,
                           const Settings & settings_,
-                          Poco::Logger * log,
+                          LoggerPtr log,
                           const QualifiedTableName * table_to_check = nullptr);
 
     /// Establish connection and save it in result, write possible exception message in fail_message.
@@ -38,7 +38,7 @@ class ConnectionEstablisher
     IConnectionPool * pool;
     const ConnectionTimeouts * timeouts;
     const Settings & settings;
-    Poco::Logger * log;
+    LoggerPtr log;
     const QualifiedTableName * table_to_check;
 
     bool is_finished;
@@ -61,7 +61,7 @@ class ConnectionEstablisherAsync : public AsyncTaskExecutor
     ConnectionEstablisherAsync(IConnectionPool * pool_,
                                const ConnectionTimeouts * timeouts_,
                                const Settings & settings_,
-                               Poco::Logger * log_,
+                               LoggerPtr log_,
                                const QualifiedTableName * table_to_check_ = nullptr);
 
     /// Get file descriptor that can be added in epoll and be polled,
diff --git a/src/Client/ConnectionPool.h b/src/Client/ConnectionPool.h
index d663c052abca..1886a0431a54 100644
--- a/src/Client/ConnectionPool.h
+++ b/src/Client/ConnectionPool.h
@@ -64,7 +64,7 @@ class ConnectionPool : public IConnectionPool, private PoolBase<Connection>
             Protocol::Secure secure_,
             Priority priority_ = Priority{1})
        : Base(max_connections_,
-        &Poco::Logger::get("ConnectionPool (" + host_ + ":" + toString(port_) + ")")),
+        getLogger("ConnectionPool (" + host_ + ":" + toString(port_) + ")")),
         host(host_),
         port(port_),
         default_database(default_database_),
diff --git a/src/Client/ConnectionPoolWithFailover.cpp b/src/Client/ConnectionPoolWithFailover.cpp
index 43166659b186..c05fbb317c81 100644
--- a/src/Client/ConnectionPoolWithFailover.cpp
+++ b/src/Client/ConnectionPoolWithFailover.cpp
@@ -29,7 +29,7 @@ ConnectionPoolWithFailover::ConnectionPoolWithFailover(
         LoadBalancing load_balancing,
         time_t decrease_error_period_,
         size_t max_error_cap_)
-    : Base(std::move(nested_pools_), decrease_error_period_, max_error_cap_, &Poco::Logger::get("ConnectionPoolWithFailover"))
+    : Base(std::move(nested_pools_), decrease_error_period_, max_error_cap_, getLogger("ConnectionPoolWithFailover"))
     , get_priority_load_balancing(load_balancing)
 {
     const std::string & local_hostname = getFQDNOrHostName();
diff --git a/src/Client/HedgedConnectionsFactory.cpp b/src/Client/HedgedConnectionsFactory.cpp
index f7b5ceedc965..01f9a32ce75b 100644
--- a/src/Client/HedgedConnectionsFactory.cpp
+++ b/src/Client/HedgedConnectionsFactory.cpp
@@ -34,7 +34,7 @@ HedgedConnectionsFactory::HedgedConnectionsFactory(
     : pool(pool_)
     , timeouts(timeouts_)
     , table_to_check(table_to_check_)
-    , log(&Poco::Logger::get("HedgedConnectionsFactory"))
+    , log(getLogger("HedgedConnectionsFactory"))
     , max_tries(max_tries_)
     , fallback_to_stale_replicas(fallback_to_stale_replicas_)
     , max_parallel_replicas(max_parallel_replicas_)
diff --git a/src/Client/HedgedConnectionsFactory.h b/src/Client/HedgedConnectionsFactory.h
index f187e9b2abb1..ce7b553acdd3 100644
--- a/src/Client/HedgedConnectionsFactory.h
+++ b/src/Client/HedgedConnectionsFactory.h
@@ -133,7 +133,7 @@ class HedgedConnectionsFactory
     std::shared_ptr<QualifiedTableName> table_to_check;
     int last_used_index = -1;
     Epoll epoll;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::string fail_messages;
 
     /// The maximum number of attempts to connect to replicas.
diff --git a/src/Common/Allocator.cpp b/src/Common/Allocator.cpp
index 24a96c1c85b3..e80c125c2a0b 100644
--- a/src/Common/Allocator.cpp
+++ b/src/Common/Allocator.cpp
@@ -50,7 +50,7 @@ void prefaultPages([[maybe_unused]] void * buf_, [[maybe_unused]] size_t len_)
     auto [buf, len] = adjustToPageSize(buf_, len_, page_size);
     if (::madvise(buf, len, MADV_POPULATE_WRITE) < 0)
         LOG_TRACE(
-            LogFrequencyLimiter(&Poco::Logger::get("Allocator"), 1),
+            LogFrequencyLimiter(getLogger("Allocator"), 1),
             "Attempt to populate pages failed: {} (EINVAL is expected for kernels < 5.14)",
             errnoToString(errno));
 #endif
diff --git a/src/Common/AsyncLoader.cpp b/src/Common/AsyncLoader.cpp
index 3b7eac3e0d40..e9de95363bc8 100644
--- a/src/Common/AsyncLoader.cpp
+++ b/src/Common/AsyncLoader.cpp
@@ -34,7 +34,7 @@ namespace ErrorCodes
 static constexpr size_t PRINT_MESSAGE_EACH_N_OBJECTS = 256;
 static constexpr size_t PRINT_MESSAGE_EACH_N_SECONDS = 5;
 
-void logAboutProgress(Poco::Logger * log, size_t processed, size_t total, AtomicStopwatch & watch)
+void logAboutProgress(LoggerPtr log, size_t processed, size_t total, AtomicStopwatch & watch)
 {
     if (total && (processed % PRINT_MESSAGE_EACH_N_OBJECTS == 0 || watch.compareAndRestart(PRINT_MESSAGE_EACH_N_SECONDS)))
     {
@@ -205,7 +205,7 @@ void LoadTask::detach()
 AsyncLoader::AsyncLoader(std::vector<PoolInitializer> pool_initializers, bool log_failures_, bool log_progress_)
     : log_failures(log_failures_)
     , log_progress(log_progress_)
-    , log(&Poco::Logger::get("AsyncLoader"))
+    , log(getLogger("AsyncLoader"))
 {
     pools.reserve(pool_initializers.size());
     for (auto && init : pool_initializers)
diff --git a/src/Common/AsyncLoader.h b/src/Common/AsyncLoader.h
index b02bc2ac06a8..c2a9c901f1cc 100644
--- a/src/Common/AsyncLoader.h
+++ b/src/Common/AsyncLoader.h
@@ -15,6 +15,7 @@
 #include <Common/Priority.h>
 #include <Common/Stopwatch.h>
 #include <Common/ThreadPool_fwd.h>
+#include <Common/Logger.h>
 
 
 namespace Poco { class Logger; }
@@ -40,7 +41,7 @@ using LoadTaskPtr = std::shared_ptr<LoadTask>;
 using LoadTaskPtrs = std::vector<LoadTaskPtr>;
 class AsyncLoader;
 
-void logAboutProgress(Poco::Logger * log, size_t processed, size_t total, AtomicStopwatch & watch);
+void logAboutProgress(LoggerPtr log, size_t processed, size_t total, AtomicStopwatch & watch);
 
 // Execution status of a load job.
 enum class LoadStatus
@@ -419,7 +420,7 @@ class AsyncLoader : private boost::noncopyable
     // Logging
     const bool log_failures; // Worker should log all exceptions caught from job functions.
     const bool log_progress; // Periodically log total progress
-    Poco::Logger * log;
+    LoggerPtr log;
 
     mutable std::mutex mutex; // Guards all the fields below.
     bool is_running = true;
diff --git a/src/Common/AsynchronousMetrics.cpp b/src/Common/AsynchronousMetrics.cpp
index ec94d17f5908..b24d9bcc301a 100644
--- a/src/Common/AsynchronousMetrics.cpp
+++ b/src/Common/AsynchronousMetrics.cpp
@@ -58,7 +58,7 @@ AsynchronousMetrics::AsynchronousMetrics(
     int update_period_seconds,
     const ProtocolServerMetricsFunc & protocol_server_metrics_func_)
     : update_period(update_period_seconds)
-    , log(&Poco::Logger::get("AsynchronousMetrics"))
+    , log(getLogger("AsynchronousMetrics"))
     , protocol_server_metrics_func(protocol_server_metrics_func_)
 {
 #if defined(OS_LINUX)
@@ -125,7 +125,7 @@ void AsynchronousMetrics::openSensors() TSA_REQUIRES(data_mutex)
         catch (const ErrnoException & e)
         {
             LOG_WARNING(
-                &Poco::Logger::get("AsynchronousMetrics"),
+                getLogger("AsynchronousMetrics"),
                 "Thermal monitor '{}' exists but could not be read: {}.",
                 thermal_device_index,
                 errnoToString(e.getErrno()));
@@ -254,7 +254,7 @@ void AsynchronousMetrics::openSensorsChips() TSA_REQUIRES(data_mutex)
             catch (const ErrnoException & e)
             {
                 LOG_WARNING(
-                    &Poco::Logger::get("AsynchronousMetrics"),
+                    getLogger("AsynchronousMetrics"),
                     "Hardware monitor '{}', sensor '{}' exists but could not be read: {}.",
                     hwmon_name,
                     sensor_index,
diff --git a/src/Common/AsynchronousMetrics.h b/src/Common/AsynchronousMetrics.h
index b9a5862dbffe..305e8136b8ac 100644
--- a/src/Common/AsynchronousMetrics.h
+++ b/src/Common/AsynchronousMetrics.h
@@ -82,7 +82,7 @@ class AsynchronousMetrics
 protected:
     const Duration update_period;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 private:
     virtual void updateImpl(TimePoint update_time, TimePoint current_time, bool force_update, bool first_run, AsynchronousMetricValues & new_values) = 0;
     virtual void logImpl(AsynchronousMetricValues &) {}
diff --git a/src/Common/Config/ConfigProcessor.cpp b/src/Common/Config/ConfigProcessor.cpp
index 92e66fee4896..641e7ddcdaa8 100644
--- a/src/Common/Config/ConfigProcessor.cpp
+++ b/src/Common/Config/ConfigProcessor.cpp
@@ -77,23 +77,17 @@ ConfigProcessor::ConfigProcessor(
     , name_pool(new Poco::XML::NamePool(65521))
     , dom_parser(name_pool)
 {
-    if (log_to_console && !Poco::Logger::has("ConfigProcessor"))
+    if (log_to_console && !hasLogger("ConfigProcessor"))
     {
         channel_ptr = new Poco::ConsoleChannel;
-        log = &Poco::Logger::create("ConfigProcessor", channel_ptr.get(), Poco::Message::PRIO_TRACE);
+        log = createLogger("ConfigProcessor", channel_ptr.get(), Poco::Message::PRIO_TRACE);
     }
     else
     {
-        log = &Poco::Logger::get("ConfigProcessor");
+        log = getLogger("ConfigProcessor");
     }
 }
 
-ConfigProcessor::~ConfigProcessor()
-{
-    if (channel_ptr) /// This means we have created a new console logger in the constructor.
-        Poco::Logger::destroy("ConfigProcessor");
-}
-
 static std::unordered_map<std::string, std::string_view> embedded_configs;
 
 void ConfigProcessor::registerEmbeddedConfig(std::string name, std::string_view content)
diff --git a/src/Common/Config/ConfigProcessor.h b/src/Common/Config/ConfigProcessor.h
index 98592d8846e4..5712c36d7370 100644
--- a/src/Common/Config/ConfigProcessor.h
+++ b/src/Common/Config/ConfigProcessor.h
@@ -7,6 +7,8 @@
 #include <vector>
 #include <memory>
 
+#include <Common/Logger.h>
+
 #include <Poco/DOM/Document.h>
 #include <Poco/DOM/DOMParser.h>
 #include <Poco/DOM/DOMWriter.h>
@@ -44,8 +46,6 @@ class ConfigProcessor
         bool log_to_console = false,
         const Substitutions & substitutions = Substitutions());
 
-    ~ConfigProcessor();
-
     /// Perform config includes and substitutions and return the resulting XML-document.
     ///
     /// Suppose path is "/path/file.xml"
@@ -125,7 +125,7 @@ class ConfigProcessor
 
     bool throw_on_bad_incl;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     Poco::AutoPtr<Poco::Channel> channel_ptr;
 
     Substitutions substitutions;
diff --git a/src/Common/Config/ConfigReloader.h b/src/Common/Config/ConfigReloader.h
index 2529c7a52369..13a797bad085 100644
--- a/src/Common/Config/ConfigReloader.h
+++ b/src/Common/Config/ConfigReloader.h
@@ -69,7 +69,7 @@ class ConfigReloader
 
     static constexpr auto reload_interval = std::chrono::seconds(2);
 
-    Poco::Logger * log = &Poco::Logger::get("ConfigReloader");
+    LoggerPtr log = getLogger("ConfigReloader");
 
     std::string config_path;
     std::vector<std::string> extra_paths;
diff --git a/src/Common/DNSResolver.cpp b/src/Common/DNSResolver.cpp
index 9cb352da0ba9..fcbbaf6b0be0 100644
--- a/src/Common/DNSResolver.cpp
+++ b/src/Common/DNSResolver.cpp
@@ -104,7 +104,7 @@ DNSResolver::IPAddresses hostByName(const std::string & host)
     }
     catch (const Poco::Net::DNSException & e)
     {
-        LOG_WARNING(&Poco::Logger::get("DNSResolver"), "Cannot resolve host ({}), error {}: {}.", host, e.code(), e.name());
+        LOG_WARNING(getLogger("DNSResolver"), "Cannot resolve host ({}), error {}: {}.", host, e.code(), e.name());
         addresses.clear();
     }
 
@@ -201,7 +201,7 @@ struct DNSResolver::Impl
 };
 
 
-DNSResolver::DNSResolver() : impl(std::make_unique<DNSResolver::Impl>()), log(&Poco::Logger::get("DNSResolver")) {}
+DNSResolver::DNSResolver() : impl(std::make_unique<DNSResolver::Impl>()), log(getLogger("DNSResolver")) {}
 
 Poco::Net::IPAddress DNSResolver::resolveHost(const std::string & host)
 {
diff --git a/src/Common/DNSResolver.h b/src/Common/DNSResolver.h
index 1017607a5bdb..965688f84f24 100644
--- a/src/Common/DNSResolver.h
+++ b/src/Common/DNSResolver.h
@@ -73,7 +73,7 @@ class DNSResolver : private boost::noncopyable
 
     struct Impl;
     std::unique_ptr<Impl> impl;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Updates cached value and returns true it has been changed.
     bool updateHost(const String & host);
diff --git a/src/Common/EnvironmentProxyConfigurationResolver.cpp b/src/Common/EnvironmentProxyConfigurationResolver.cpp
index 58507904ce99..f2c60afa1a88 100644
--- a/src/Common/EnvironmentProxyConfigurationResolver.cpp
+++ b/src/Common/EnvironmentProxyConfigurationResolver.cpp
@@ -50,7 +50,7 @@ ProxyConfiguration EnvironmentProxyConfigurationResolver::resolve()
     auto scheme = uri.getScheme();
     auto port = uri.getPort();
 
-    LOG_TRACE(&Poco::Logger::get("EnvironmentProxyConfigurationResolver"), "Use proxy from environment: {}://{}:{}", scheme, host, port);
+    LOG_TRACE(getLogger("EnvironmentProxyConfigurationResolver"), "Use proxy from environment: {}://{}:{}", scheme, host, port);
 
     return ProxyConfiguration {
         host,
diff --git a/src/Common/ErrorHandlers.h b/src/Common/ErrorHandlers.h
index 301377bff837..a4a7c4683aa7 100644
--- a/src/Common/ErrorHandlers.h
+++ b/src/Common/ErrorHandlers.h
@@ -27,7 +27,7 @@ class ServerErrorHandler : public Poco::ErrorHandler
     void exception()                        override { logException(); }
 
 private:
-    Poco::Logger * log = &Poco::Logger::get("ServerErrorHandler");
+    LoggerPtr log = getLogger("ServerErrorHandler");
 
     void logException()
     {
diff --git a/src/Common/Exception.cpp b/src/Common/Exception.cpp
index e5e8cf2c8187..ff83f6ba8073 100644
--- a/src/Common/Exception.cpp
+++ b/src/Common/Exception.cpp
@@ -235,8 +235,9 @@ void tryLogCurrentException(const char * log_name, const std::string & start_of_
     /// MemoryTracker until the exception will be logged.
     LockMemoryExceptionInThread lock_memory_tracker(VariableContext::Global);
 
-    /// Poco::Logger::get can allocate memory too
-    tryLogCurrentExceptionImpl(&Poco::Logger::get(log_name), start_of_message);
+    /// getLogger can allocate memory too
+    auto logger = getLogger(log_name);
+    tryLogCurrentExceptionImpl(logger.get(), start_of_message);
 }
 
 void tryLogCurrentException(Poco::Logger * logger, const std::string & start_of_message)
@@ -251,6 +252,11 @@ void tryLogCurrentException(Poco::Logger * logger, const std::string & start_of_
     tryLogCurrentExceptionImpl(logger, start_of_message);
 }
 
+void tryLogCurrentException(LoggerPtr logger, const std::string & start_of_message)
+{
+    tryLogCurrentException(logger.get(), start_of_message);
+}
+
 static void getNoSpaceLeftInfoMessage(std::filesystem::path path, String & msg)
 {
     path = std::filesystem::absolute(path);
@@ -511,7 +517,7 @@ void tryLogException(std::exception_ptr e, const char * log_name, const std::str
     }
 }
 
-void tryLogException(std::exception_ptr e, Poco::Logger * logger, const std::string & start_of_message)
+void tryLogException(std::exception_ptr e, LoggerPtr logger, const std::string & start_of_message)
 {
     try
     {
diff --git a/src/Common/Exception.h b/src/Common/Exception.h
index 6f30fde3876a..8afed6034cfa 100644
--- a/src/Common/Exception.h
+++ b/src/Common/Exception.h
@@ -10,6 +10,7 @@
 #include <base/errnoToString.h>
 #include <base/scope_guard.h>
 #include <Common/LoggingFormatStringHelpers.h>
+#include <Common/Logger.h>
 #include <Common/StackTrace.h>
 
 #include <fmt/format.h>
@@ -240,8 +241,10 @@ using Exceptions = std::vector<std::exception_ptr>;
 /** Try to write an exception to the log (and forget about it).
   * Can be used in destructors in the catch-all block.
   */
+/// TODO: Logger leak constexpr overload
 void tryLogCurrentException(const char * log_name, const std::string & start_of_message = "");
 void tryLogCurrentException(Poco::Logger * logger, const std::string & start_of_message = "");
+void tryLogCurrentException(LoggerPtr logger, const std::string & start_of_message = "");
 
 
 /** Prints current exception in canonical format.
@@ -284,9 +287,9 @@ struct ExecutionStatus
     bool tryDeserializeText(const std::string & data);
 };
 
-
+/// TODO: Logger leak constexpr overload
 void tryLogException(std::exception_ptr e, const char * log_name, const std::string & start_of_message = "");
-void tryLogException(std::exception_ptr e, Poco::Logger * logger, const std::string & start_of_message = "");
+void tryLogException(std::exception_ptr e, LoggerPtr logger, const std::string & start_of_message = "");
 
 std::string getExceptionMessage(const Exception & e, bool with_stacktrace, bool check_embedded_stacktrace = false);
 PreformattedMessage getExceptionMessageAndPattern(const Exception & e, bool with_stacktrace, bool check_embedded_stacktrace = false);
diff --git a/src/Common/FileChecker.cpp b/src/Common/FileChecker.cpp
index 049dee459a7c..098ea4b1ac46 100644
--- a/src/Common/FileChecker.cpp
+++ b/src/Common/FileChecker.cpp
@@ -29,7 +29,7 @@ FileChecker::FileChecker(const String & file_info_path_) : FileChecker(nullptr,
 
 FileChecker::FileChecker(DiskPtr disk_, const String & file_info_path_)
     : disk(std::move(disk_))
-    , log(&Poco::Logger::get("FileChecker"))
+    , log(getLogger("FileChecker"))
 {
     setPath(file_info_path_);
     try
diff --git a/src/Common/FileChecker.h b/src/Common/FileChecker.h
index b0dd0814edd5..c7ba1b912280 100644
--- a/src/Common/FileChecker.h
+++ b/src/Common/FileChecker.h
@@ -1,6 +1,7 @@
 #pragma once
 
 #include <Storages/CheckResults.h>
+#include <Common/Logger.h>
 #include <map>
 #include <base/types.h>
 #include <memory>
@@ -84,7 +85,7 @@ class FileChecker
     size_t getRealFileSize(const String & path_) const;
 
     const DiskPtr disk;
-    const Poco::Logger * log;
+    const LoggerPtr log;
 
     String files_info_path;
     std::map<String, size_t> map;
diff --git a/src/Common/FrequencyHolder.cpp b/src/Common/FrequencyHolder.cpp
index 7dc1f622aebe..a25486865866 100644
--- a/src/Common/FrequencyHolder.cpp
+++ b/src/Common/FrequencyHolder.cpp
@@ -34,7 +34,7 @@ FrequencyHolder::FrequencyHolder()
 
 void FrequencyHolder::loadEncodingsFrequency()
 {
-    Poco::Logger * log = &Poco::Logger::get("EncodingsFrequency");
+    LoggerPtr log = getLogger("EncodingsFrequency");
 
     LOG_TRACE(log, "Loading embedded charset frequencies");
 
@@ -92,7 +92,7 @@ void FrequencyHolder::loadEncodingsFrequency()
 
 void FrequencyHolder::loadEmotionalDict()
 {
-    Poco::Logger * log = &Poco::Logger::get("EmotionalDict");
+    LoggerPtr log = getLogger("EmotionalDict");
     LOG_TRACE(log, "Loading embedded emotional dictionary");
 
     std::string_view resource(reinterpret_cast<const char *>(gresource_tonality_ru_zstData), gresource_tonality_ru_zstSize);
@@ -130,7 +130,7 @@ void FrequencyHolder::loadEmotionalDict()
 
 void FrequencyHolder::loadProgrammingFrequency()
 {
-    Poco::Logger * log = &Poco::Logger::get("ProgrammingFrequency");
+    LoggerPtr log = getLogger("ProgrammingFrequency");
 
     LOG_TRACE(log, "Loading embedded programming languages frequencies loading");
 
diff --git a/src/Common/Jemalloc.cpp b/src/Common/Jemalloc.cpp
index a8b9d70e7314..3eb8691a1e18 100644
--- a/src/Common/Jemalloc.cpp
+++ b/src/Common/Jemalloc.cpp
@@ -25,7 +25,7 @@ namespace ErrorCodes
 
 void purgeJemallocArenas()
 {
-    LOG_TRACE(&Poco::Logger::get("SystemJemalloc"), "Purging unused memory");
+    LOG_TRACE(getLogger("SystemJemalloc"), "Purging unused memory");
     Stopwatch watch;
     mallctl("arena." STRINGIFY(MALLCTL_ARENAS_ALL) ".purge", nullptr, nullptr, nullptr, 0);
     ProfileEvents::increment(ProfileEvents::MemoryAllocatorPurge);
@@ -53,12 +53,12 @@ void setJemallocProfileActive(bool value)
     mallctl("prof.active", &active, &active_size, nullptr, 0);
     if (active == value)
     {
-        LOG_TRACE(&Poco::Logger::get("SystemJemalloc"), "Profiling is already {}", active ? "enabled" : "disabled");
+        LOG_TRACE(getLogger("SystemJemalloc"), "Profiling is already {}", active ? "enabled" : "disabled");
         return;
     }
 
     mallctl("prof.active", nullptr, nullptr, &value, sizeof(bool));
-    LOG_TRACE(&Poco::Logger::get("SystemJemalloc"), "Profiling is {}", value ? "enabled" : "disabled");
+    LOG_TRACE(getLogger("SystemJemalloc"), "Profiling is {}", value ? "enabled" : "disabled");
 }
 
 std::string flushJemallocProfile(const std::string & file_prefix)
@@ -69,7 +69,7 @@ std::string flushJemallocProfile(const std::string & file_prefix)
     int n = mallctl("opt.prof_prefix", &prefix_buffer, &prefix_size, nullptr, 0);
     if (!n && std::string_view(prefix_buffer) != "jeprof")
     {
-        LOG_TRACE(&Poco::Logger::get("SystemJemalloc"), "Flushing memory profile with prefix {}", prefix_buffer);
+        LOG_TRACE(getLogger("SystemJemalloc"), "Flushing memory profile with prefix {}", prefix_buffer);
         mallctl("prof.dump", nullptr, nullptr, nullptr, 0);
         return prefix_buffer;
     }
@@ -78,7 +78,7 @@ std::string flushJemallocProfile(const std::string & file_prefix)
     std::string profile_dump_path = fmt::format("{}.{}.{}.heap", file_prefix, getpid(), profile_counter.fetch_add(1));
     const auto * profile_dump_path_str = profile_dump_path.c_str();
 
-    LOG_TRACE(&Poco::Logger::get("SystemJemalloc"), "Flushing memory profile to {}", profile_dump_path_str);
+    LOG_TRACE(getLogger("SystemJemalloc"), "Flushing memory profile to {}", profile_dump_path_str);
     mallctl("prof.dump", nullptr, nullptr, &profile_dump_path_str, sizeof(profile_dump_path_str));
     return profile_dump_path;
 }
diff --git a/src/Common/LRUResourceCache.h b/src/Common/LRUResourceCache.h
index 1fe3075a2a31..4ccaa272346d 100644
--- a/src/Common/LRUResourceCache.h
+++ b/src/Common/LRUResourceCache.h
@@ -235,7 +235,7 @@ class LRUResourceCache
                 else
                 {
                     // should not reach here
-                    LOG_ERROR(&Poco::Logger::get("LRUResourceCache"), "element is in invalid status.");
+                    LOG_ERROR(getLogger("LRUResourceCache"), "element is in invalid status.");
                     abort();
                 }
             }
@@ -306,7 +306,7 @@ class LRUResourceCache
         auto it = cells.find(key);
         if (it == cells.end() || it->second.reference_count == 0)
         {
-            LOG_ERROR(&Poco::Logger::get("LRUResourceCache"), "try to release an invalid element");
+            LOG_ERROR(getLogger("LRUResourceCache"), "try to release an invalid element");
             abort();
         }
 
@@ -359,7 +359,7 @@ class LRUResourceCache
             auto cell_it = cells.find(key);
             if (cell_it == cells.end())
             {
-                LOG_ERROR(&Poco::Logger::get("LRUResourceCache"), "LRUResourceCache became inconsistent. There must be a bug in it.");
+                LOG_ERROR(getLogger("LRUResourceCache"), "LRUResourceCache became inconsistent. There must be a bug in it.");
                 abort();
             }
 
@@ -379,7 +379,7 @@ class LRUResourceCache
 
         if (loss_weight > current_weight + weight)
         {
-            LOG_ERROR(&Poco::Logger::get("LRUResourceCache"), "LRUResourceCache became inconsistent. There must be a bug in it.");
+            LOG_ERROR(getLogger("LRUResourceCache"), "LRUResourceCache became inconsistent. There must be a bug in it.");
             abort();
         }
 
diff --git a/src/Common/Logger.cpp b/src/Common/Logger.cpp
new file mode 100644
index 000000000000..c8d557bc3a3b
--- /dev/null
+++ b/src/Common/Logger.cpp
@@ -0,0 +1,27 @@
+#include <Poco/Logger.h>
+#include <Common/Logger.h>
+
+LoggerPtr getLogger(const std::string & name)
+{
+    return Poco::Logger::getShared(name);
+}
+
+LoggerPtr createLogger(const std::string & name, Poco::Channel * channel, Poco::Message::Priority level)
+{
+    return Poco::Logger::createShared(name, channel, level);
+}
+
+LoggerRawPtr getRawLogger(const std::string & name)
+{
+    return &Poco::Logger::get(name);
+}
+
+LoggerRawPtr createRawLogger(const std::string & name, Poco::Channel * channel, Poco::Message::Priority level)
+{
+    return &Poco::Logger::create(name, channel, level);
+}
+
+bool hasLogger(const std::string & name)
+{
+    return Poco::Logger::has(name);
+}
diff --git a/src/Common/Logger.h b/src/Common/Logger.h
new file mode 100644
index 000000000000..13e1c6bf8f57
--- /dev/null
+++ b/src/Common/Logger.h
@@ -0,0 +1,50 @@
+#pragma once
+
+#include <memory>
+
+#include <Poco/Channel.h>
+#include <Poco/Logger.h>
+#include <Poco/Message.h>
+
+using LoggerPtr = Poco::LoggerPtr;
+
+using LoggerRawPtr = Poco::Logger *;
+
+/** RAII wrappers around Poco/Logger.h.
+  *
+  * You should use this functions in case Logger instance lifetime needs to be properly
+  * managed, because otherwise it will leak memory.
+  *
+  * For example when Logger is created when table is created and Logger contains table name.
+  * Then it must be destroyed when underlying table is destroyed.
+  */
+
+/** Get Logger with specified name. If the Logger does not exists, it is created.
+  * Logger is destroyed, when last shared ptr that refers to Logger with specified name is destroyed.
+  */
+LoggerPtr getLogger(const std::string & name);
+
+/** Create Logger with specified name, channel and logging level.
+  * If Logger already exists, throws exception.
+  * Logger is destroyed, when last shared ptr that refers to Logger with specified name is destroyed.
+  */
+LoggerPtr createLogger(const std::string & name, Poco::Channel * channel, Poco::Message::Priority level = Poco::Message::PRIO_INFORMATION);
+
+/** Create raw Poco::Logger that will not be destroyed before program termination.
+  * This can be used in cases when specific Logger instance can be singletone.
+  *
+  * For example you need to pass Logger into low-level libraries as raw pointer, and using
+  * RAII wrapper is inconvenient.
+  *
+  * Generally you should always use getLogger functions.
+  */
+
+LoggerRawPtr getRawLogger(const std::string & name);
+
+LoggerRawPtr createRawLogger(const std::string & name, Poco::Channel * channel, Poco::Message::Priority level = Poco::Message::PRIO_INFORMATION);
+
+
+/** Returns true, if currently Logger with specified name is created.
+  * Otherwise, returns false.
+  */
+bool hasLogger(const std::string & name);
diff --git a/src/Common/LoggingFormatStringHelpers.cpp b/src/Common/LoggingFormatStringHelpers.cpp
index 074c8dd28039..b3353a590100 100644
--- a/src/Common/LoggingFormatStringHelpers.cpp
+++ b/src/Common/LoggingFormatStringHelpers.cpp
@@ -80,8 +80,8 @@ void LogFrequencyLimiterIml::cleanup(time_t too_old_threshold_s)
 std::mutex LogSeriesLimiter::mutex;
 time_t LogSeriesLimiter::last_cleanup = 0;
 
-LogSeriesLimiter::LogSeriesLimiter(Poco::Logger * logger_, size_t allowed_count_, time_t interval_s_)
-    : logger(logger_)
+LogSeriesLimiter::LogSeriesLimiter(LoggerPtr logger_, size_t allowed_count_, time_t interval_s_)
+    : logger(std::move(logger_))
 {
     if (allowed_count_ == 0)
     {
diff --git a/src/Common/LoggingFormatStringHelpers.h b/src/Common/LoggingFormatStringHelpers.h
index ef7ec0c6144b..b0f0a5cd7167 100644
--- a/src/Common/LoggingFormatStringHelpers.h
+++ b/src/Common/LoggingFormatStringHelpers.h
@@ -8,7 +8,7 @@
 #include <Poco/Logger.h>
 #include <Poco/Message.h>
 #include <base/EnumReflection.h>
-
+#include <Common/Logger.h>
 
 struct PreformattedMessage;
 consteval void formatStringCheckArgsNumImpl(std::string_view str, size_t nargs);
@@ -203,10 +203,10 @@ class LogFrequencyLimiterIml
     static time_t last_cleanup;
     static std::mutex mutex;
 
-    Poco::Logger * logger;
+    LoggerPtr logger;
     time_t min_interval_s;
 public:
-    LogFrequencyLimiterIml(Poco::Logger * logger_, time_t min_interval_s_) : logger(logger_), min_interval_s(min_interval_s_) {}
+    LogFrequencyLimiterIml(LoggerPtr logger_, time_t min_interval_s_) : logger(std::move(logger_)), min_interval_s(min_interval_s_) {}
 
     LogFrequencyLimiterIml & operator -> () { return *this; }
     bool is(Poco::Message::Priority priority) { return logger->is(priority); }
@@ -218,7 +218,7 @@ class LogFrequencyLimiterIml
     /// Clears messages that were logged last time more than too_old_threshold_s seconds ago
     static void cleanup(time_t too_old_threshold_s = 600);
 
-    Poco::Logger * getLogger() { return logger; }
+    LoggerPtr getLogger() { return logger; }
 };
 
 /// This wrapper helps to avoid too noisy log messages from similar objects.
@@ -240,11 +240,11 @@ class LogSeriesLimiter
         return records;
     }
 
-    Poco::Logger * logger = nullptr;
+    LoggerPtr logger = nullptr;
     bool accepted = false;
     String debug_message;
 public:
-    LogSeriesLimiter(Poco::Logger * logger_, size_t allowed_count_, time_t interval_s_);
+    LogSeriesLimiter(LoggerPtr logger_, size_t allowed_count_, time_t interval_s_);
 
     LogSeriesLimiter & operator -> () { return *this; }
     bool is(Poco::Message::Priority priority) { return logger->is(priority); }
@@ -253,18 +253,18 @@ class LogSeriesLimiter
 
     void log(Poco::Message & message);
 
-    Poco::Logger * getLogger() { return logger; }
+    LoggerPtr getLogger() { return logger; }
 };
 
 /// This wrapper is useful to save formatted message into a String before sending it to a logger
 class LogToStrImpl
 {
     String & out_str;
-    Poco::Logger * logger;
+    LoggerPtr logger;
     std::unique_ptr<LogFrequencyLimiterIml> maybe_nested;
     bool propagate_to_actual_log = true;
 public:
-    LogToStrImpl(String & out_str_, Poco::Logger * logger_) : out_str(out_str_), logger(logger_) {}
+    LogToStrImpl(String & out_str_, LoggerPtr logger_) : out_str(out_str_), logger(std::move(logger_)) {}
     LogToStrImpl(String & out_str_, std::unique_ptr<LogFrequencyLimiterIml> && maybe_nested_)
         : out_str(out_str_), logger(maybe_nested_->getLogger()), maybe_nested(std::move(maybe_nested_)) {}
     LogToStrImpl & operator -> () { return *this; }
diff --git a/src/Common/Macros.cpp b/src/Common/Macros.cpp
index 0035e7abfe85..9e0977d9bcc2 100644
--- a/src/Common/Macros.cpp
+++ b/src/Common/Macros.cpp
@@ -38,6 +38,10 @@ Macros::Macros(const Poco::Util::AbstractConfiguration & config, const String &
     }
 }
 
+Macros::Macros(const Poco::Util::AbstractConfiguration & config, const String & root_key, LoggerPtr log)
+    : Macros(config, root_key, log.get())
+{}
+
 Macros::Macros(std::map<String, String> map)
 {
     macros = std::move(map);
diff --git a/src/Common/Macros.h b/src/Common/Macros.h
index 9fe5717effc0..8b9eded7dcb7 100644
--- a/src/Common/Macros.h
+++ b/src/Common/Macros.h
@@ -26,6 +26,7 @@ class Macros
 {
 public:
     Macros() = default;
+    Macros(const Poco::Util::AbstractConfiguration & config, const String & key, LoggerPtr log = nullptr);
     Macros(const Poco::Util::AbstractConfiguration & config, const String & key, Poco::Logger * log = nullptr);
     explicit Macros(std::map<String, String> map);
 
diff --git a/src/Common/MemoryTracker.cpp b/src/Common/MemoryTracker.cpp
index 5672bb0ae10d..28cfa98666aa 100644
--- a/src/Common/MemoryTracker.cpp
+++ b/src/Common/MemoryTracker.cpp
@@ -155,14 +155,14 @@ void MemoryTracker::logPeakMemoryUsage()
     auto peak_bytes = peak.load(std::memory_order::relaxed);
     if (peak_bytes < 128 * 1024)
         return;
-    LOG_DEBUG(&Poco::Logger::get("MemoryTracker"),
+    LOG_DEBUG(getLogger("MemoryTracker"),
         "Peak memory usage{}: {}.", (description ? " " + std::string(description) : ""), ReadableSize(peak_bytes));
 }
 
 void MemoryTracker::logMemoryUsage(Int64 current) const
 {
     const auto * description = description_ptr.load(std::memory_order_relaxed);
-    LOG_DEBUG(&Poco::Logger::get("MemoryTracker"),
+    LOG_DEBUG(getLogger("MemoryTracker"),
         "Current memory usage{}: {}.", (description ? " " + std::string(description) : ""), ReadableSize(current));
 }
 
@@ -170,7 +170,7 @@ void MemoryTracker::injectFault() const
 {
     if (!memoryTrackerCanThrow(level, true))
     {
-        LOG_WARNING(&Poco::Logger::get("MemoryTracker"),
+        LOG_WARNING(getLogger("MemoryTracker"),
                     "Cannot inject fault at specific point. Uncaught exceptions: {}, stack trace:
{}",
                     std::uncaught_exceptions(), StackTrace().toString());
         return;
@@ -201,7 +201,7 @@ void MemoryTracker::debugLogBigAllocationWithoutCheck(Int64 size [[maybe_unused]
         return;
 
     MemoryTrackerBlockerInThread blocker(VariableContext::Global);
-    LOG_TEST(&Poco::Logger::get("MemoryTracker"), "Too big allocation ({} bytes) without checking memory limits, "
+    LOG_TEST(getLogger("MemoryTracker"), "Too big allocation ({} bytes) without checking memory limits, "
                                                    "it may lead to OOM. Stack trace: {}", size, StackTrace().toString());
 #else
     return;     /// Avoid trash logging in release builds
diff --git a/src/Common/NamedCollections/NamedCollectionUtils.cpp b/src/Common/NamedCollections/NamedCollectionUtils.cpp
index d62d54b9f375..fe0f42467c78 100644
--- a/src/Common/NamedCollections/NamedCollectionUtils.cpp
+++ b/src/Common/NamedCollections/NamedCollectionUtils.cpp
@@ -135,7 +135,7 @@ class LoadFromSQL : private WithContext
             else
             {
                 LOG_WARNING(
-                    &Poco::Logger::get("NamedCollectionsLoadFromSQL"),
+                    getLogger("NamedCollectionsLoadFromSQL"),
                     "Unexpected file {} in named collections directory",
                     current_path.filename().string());
             }
@@ -345,7 +345,7 @@ void loadFromConfigUnlocked(const Poco::Util::AbstractConfiguration & config, st
 {
     auto named_collections = LoadFromConfig(config).getAll();
     LOG_TRACE(
-        &Poco::Logger::get("NamedCollectionsUtils"),
+        getLogger("NamedCollectionsUtils"),
         "Loaded {} collections from config", named_collections.size());
 
     NamedCollectionFactory::instance().add(std::move(named_collections));
@@ -372,7 +372,7 @@ void loadFromSQLUnlocked(ContextPtr context, std::unique_lock<std::mutex> &)
 {
     auto named_collections = LoadFromSQL(context).getAll();
     LOG_TRACE(
-        &Poco::Logger::get("NamedCollectionsUtils"),
+        getLogger("NamedCollectionsUtils"),
         "Loaded {} collections from SQL", named_collections.size());
 
     NamedCollectionFactory::instance().add(std::move(named_collections));
diff --git a/src/Common/NetlinkMetricsProvider.cpp b/src/Common/NetlinkMetricsProvider.cpp
index 23173f316896..6969b5b75429 100644
--- a/src/Common/NetlinkMetricsProvider.cpp
+++ b/src/Common/NetlinkMetricsProvider.cpp
@@ -216,7 +216,7 @@ bool checkPermissionsImpl()
         {
             /// This error happens all the time when running inside Docker - consider it ok,
             /// don't create noise with this error.
-            LOG_DEBUG(&Poco::Logger::get(__PRETTY_FUNCTION__), getCurrentExceptionMessageAndPattern(/* with_stacktrace */ false));
+            LOG_DEBUG(getLogger(__PRETTY_FUNCTION__), getCurrentExceptionMessageAndPattern(/* with_stacktrace */ false));
         }
         else
         {
diff --git a/src/Common/OptimizedRegularExpression.cpp b/src/Common/OptimizedRegularExpression.cpp
index 8a5804692782..b6852964efe5 100644
--- a/src/Common/OptimizedRegularExpression.cpp
+++ b/src/Common/OptimizedRegularExpression.cpp
@@ -463,7 +463,7 @@ catch (...)
     is_trivial = false;
     required_substring_is_prefix = false;
     alternatives.clear();
-    LOG_ERROR(&Poco::Logger::get("OptimizeRegularExpression"), "Analyze RegularExpression failed, got error: {}", DB::getCurrentExceptionMessage(false));
+    LOG_ERROR(getLogger("OptimizeRegularExpression"), "Analyze RegularExpression failed, got error: {}", DB::getCurrentExceptionMessage(false));
 }
 
 OptimizedRegularExpression::OptimizedRegularExpression(const std::string & regexp_, int options)
diff --git a/src/Common/PipeFDs.cpp b/src/Common/PipeFDs.cpp
index f2a913467a9d..ceadbb2f9833 100644
--- a/src/Common/PipeFDs.cpp
+++ b/src/Common/PipeFDs.cpp
@@ -97,7 +97,7 @@ void LazyPipeFDs::setNonBlockingReadWrite()
 void LazyPipeFDs::tryIncreaseSize(int desired_size)
 {
 #if defined(OS_LINUX)
-    Poco::Logger * log = &Poco::Logger::get("Pipe");
+    LoggerPtr log = getLogger("Pipe");
 
     /** Increase pipe size to avoid slowdown during fine-grained trace collection.
       */
diff --git a/src/Common/PoolBase.h b/src/Common/PoolBase.h
index 5575b56f2999..ef35002c45a1 100644
--- a/src/Common/PoolBase.h
+++ b/src/Common/PoolBase.h
@@ -223,9 +223,9 @@ class PoolBase : private boost::noncopyable
     std::condition_variable available;
 
 protected:
-    Poco::Logger * log;
+    LoggerPtr log;
 
-    PoolBase(unsigned max_items_, Poco::Logger * log_, BehaviourOnLimit behaviour_on_limit_ = BehaviourOnLimit::Wait)
+    PoolBase(unsigned max_items_, LoggerPtr log_, BehaviourOnLimit behaviour_on_limit_ = BehaviourOnLimit::Wait)
         : max_items(max_items_), behaviour_on_limit(behaviour_on_limit_), log(log_)
     {
         items.reserve(max_items);
diff --git a/src/Common/PoolWithFailoverBase.h b/src/Common/PoolWithFailoverBase.h
index f960d551996c..6da4445950ce 100644
--- a/src/Common/PoolWithFailoverBase.h
+++ b/src/Common/PoolWithFailoverBase.h
@@ -58,7 +58,7 @@ class PoolWithFailoverBase : private boost::noncopyable
             NestedPools nested_pools_,
             time_t decrease_error_period_,
             size_t max_error_cap_,
-            Poco::Logger * log_)
+            LoggerPtr log_)
         : nested_pools(std::move(nested_pools_))
         , decrease_error_period(decrease_error_period_)
         , max_error_cap(max_error_cap_)
@@ -159,7 +159,7 @@ class PoolWithFailoverBase : private boost::noncopyable
     /// The time when error counts were last decreased.
     time_t last_error_decrease_time = 0;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 
diff --git a/src/Common/ProxyConfigurationResolverProvider.cpp b/src/Common/ProxyConfigurationResolverProvider.cpp
index 96ebb934643e..d15b4d98615d 100644
--- a/src/Common/ProxyConfigurationResolverProvider.cpp
+++ b/src/Common/ProxyConfigurationResolverProvider.cpp
@@ -36,7 +36,7 @@ namespace
         auto proxy_port = configuration.getUInt(resolver_prefix + ".proxy_port");
         auto cache_ttl = configuration.getUInt(resolver_prefix + ".proxy_cache_time", 10);
 
-        LOG_DEBUG(&Poco::Logger::get("ProxyConfigurationResolverProvider"), "Configured remote proxy resolver: {}, Scheme: {}, Port: {}",
+        LOG_DEBUG(getLogger("ProxyConfigurationResolverProvider"), "Configured remote proxy resolver: {}, Scheme: {}, Port: {}",
                   endpoint.toString(), proxy_scheme, proxy_port);
 
         auto server_configuration = RemoteProxyConfigurationResolver::RemoteServerConfiguration {
@@ -71,7 +71,7 @@ namespace
 
                 uris.push_back(proxy_uri);
 
-                LOG_DEBUG(&Poco::Logger::get("ProxyConfigurationResolverProvider"), "Configured proxy: {}", proxy_uri.toString());
+                LOG_DEBUG(getLogger("ProxyConfigurationResolverProvider"), "Configured proxy: {}", proxy_uri.toString());
             }
         }
 
diff --git a/src/Common/ProxyListConfigurationResolver.cpp b/src/Common/ProxyListConfigurationResolver.cpp
index 68d676643d62..01a6f52185fc 100644
--- a/src/Common/ProxyListConfigurationResolver.cpp
+++ b/src/Common/ProxyListConfigurationResolver.cpp
@@ -26,7 +26,7 @@ ProxyConfiguration ProxyListConfigurationResolver::resolve()
 
     auto & proxy = proxies[index];
 
-    LOG_DEBUG(&Poco::Logger::get("ProxyListConfigurationResolver"), "Use proxy: {}", proxies[index].toString());
+    LOG_DEBUG(getLogger("ProxyListConfigurationResolver"), "Use proxy: {}", proxies[index].toString());
 
     return ProxyConfiguration {
         proxy.getHost(),
diff --git a/src/Common/QueryProfiler.cpp b/src/Common/QueryProfiler.cpp
index 16c8d4e223f7..34ffbf6c498f 100644
--- a/src/Common/QueryProfiler.cpp
+++ b/src/Common/QueryProfiler.cpp
@@ -105,7 +105,7 @@ namespace ErrorCodes
 
 #ifndef __APPLE__
 Timer::Timer()
-    : log(&Poco::Logger::get("Timer"))
+    : log(getLogger("Timer"))
 {}
 
 void Timer::createIfNecessary(UInt64 thread_id, int clock_type, int pause_signal)
@@ -211,7 +211,7 @@ void Timer::cleanup()
 
 template <typename ProfilerImpl>
 QueryProfilerBase<ProfilerImpl>::QueryProfilerBase(UInt64 thread_id, int clock_type, UInt32 period, int pause_signal_)
-    : log(&Poco::Logger::get("QueryProfiler"))
+    : log(getLogger("QueryProfiler"))
     , pause_signal(pause_signal_)
 {
 #if defined(SANITIZER)
diff --git a/src/Common/QueryProfiler.h b/src/Common/QueryProfiler.h
index 87432a4b6998..254b11137ccb 100644
--- a/src/Common/QueryProfiler.h
+++ b/src/Common/QueryProfiler.h
@@ -7,6 +7,8 @@
 
 #include "config.h"
 
+#include <Common/Logger.h>
+
 
 namespace Poco
 {
@@ -43,7 +45,7 @@ class Timer
     void cleanup();
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     std::optional<timer_t> timer_id;
 };
 #endif
@@ -58,7 +60,7 @@ class QueryProfilerBase
 private:
     void cleanup();
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
 #ifndef __APPLE__
     inline static thread_local Timer timer = Timer();
diff --git a/src/Common/RemoteProxyConfigurationResolver.cpp b/src/Common/RemoteProxyConfigurationResolver.cpp
index 7342933beff5..117c8a34dbb5 100644
--- a/src/Common/RemoteProxyConfigurationResolver.cpp
+++ b/src/Common/RemoteProxyConfigurationResolver.cpp
@@ -27,7 +27,7 @@ RemoteProxyConfigurationResolver::RemoteProxyConfigurationResolver(
 
 ProxyConfiguration RemoteProxyConfigurationResolver::resolve()
 {
-    auto * logger = &Poco::Logger::get("RemoteProxyConfigurationResolver");
+    auto logger = getLogger("RemoteProxyConfigurationResolver");
 
     auto & [endpoint, proxy_protocol, proxy_port, cache_ttl_] = remote_server_configuration;
 
diff --git a/src/Common/SensitiveDataMasker.cpp b/src/Common/SensitiveDataMasker.cpp
index 33770c3e78af..70346919f65b 100644
--- a/src/Common/SensitiveDataMasker.cpp
+++ b/src/Common/SensitiveDataMasker.cpp
@@ -112,7 +112,7 @@ SensitiveDataMasker::SensitiveDataMasker(const Poco::Util::AbstractConfiguration
 {
     Poco::Util::AbstractConfiguration::Keys keys;
     config.keys(config_prefix, keys);
-    Poco::Logger * logger = &Poco::Logger::get("SensitiveDataMaskerConfigRead");
+    LoggerPtr logger = getLogger("SensitiveDataMaskerConfigRead");
 
     std::set<std::string> used_names;
 
diff --git a/src/Common/ShellCommand.cpp b/src/Common/ShellCommand.cpp
index f4efc9e3526e..98a21b43d763 100644
--- a/src/Common/ShellCommand.cpp
+++ b/src/Common/ShellCommand.cpp
@@ -54,9 +54,9 @@ ShellCommand::ShellCommand(pid_t pid_, int & in_fd_, int & out_fd_, int & err_fd
 {
 }
 
-Poco::Logger * ShellCommand::getLogger()
+LoggerPtr ShellCommand::getLogger()
 {
-    return &Poco::Logger::get("ShellCommand");
+    return ::getLogger("ShellCommand");
 }
 
 ShellCommand::~ShellCommand()
diff --git a/src/Common/ShellCommand.h b/src/Common/ShellCommand.h
index da65d2ae494f..5ebc1daefa1c 100644
--- a/src/Common/ShellCommand.h
+++ b/src/Common/ShellCommand.h
@@ -97,7 +97,7 @@ class ShellCommand final
 
     bool tryWaitProcessWithTimeout(size_t timeout_in_seconds);
 
-    static Poco::Logger * getLogger();
+    static LoggerPtr getLogger();
 
     /// Print command name and the list of arguments to log. NOTE: No escaping of arguments is performed.
     static void logCommand(const char * filename, char * const argv[]);
diff --git a/src/Common/StatusFile.cpp b/src/Common/StatusFile.cpp
index 0a9aa2f27395..56eb1d4d0cbc 100644
--- a/src/Common/StatusFile.cpp
+++ b/src/Common/StatusFile.cpp
@@ -56,9 +56,9 @@ StatusFile::StatusFile(std::string path_, FillFunction fill_)
         }
 
         if (!contents.empty())
-            LOG_INFO(&Poco::Logger::get("StatusFile"), "Status file {} already exists - unclean restart. Contents:
{}", path, contents);
+            LOG_INFO(getLogger("StatusFile"), "Status file {} already exists - unclean restart. Contents:
{}", path, contents);
         else
-            LOG_INFO(&Poco::Logger::get("StatusFile"), "Status file {} already exists and is empty - probably unclean hardware restart.", path);
+            LOG_INFO(getLogger("StatusFile"), "Status file {} already exists and is empty - probably unclean hardware restart.", path);
     }
 
     fd = ::open(path.c_str(), O_WRONLY | O_CREAT | O_CLOEXEC, 0666);
@@ -99,10 +99,10 @@ StatusFile::StatusFile(std::string path_, FillFunction fill_)
 StatusFile::~StatusFile()
 {
     if (0 != close(fd))
-        LOG_ERROR(&Poco::Logger::get("StatusFile"), "Cannot close file {}, {}", path, errnoToString());
+        LOG_ERROR(getLogger("StatusFile"), "Cannot close file {}, {}", path, errnoToString());
 
     if (0 != unlink(path.c_str()))
-        LOG_ERROR(&Poco::Logger::get("StatusFile"), "Cannot unlink file {}, {}", path, errnoToString());
+        LOG_ERROR(getLogger("StatusFile"), "Cannot unlink file {}, {}", path, errnoToString());
 }
 
 }
diff --git a/src/Common/SystemLogBase.cpp b/src/Common/SystemLogBase.cpp
index d82b582fee6b..4dee6d905d99 100644
--- a/src/Common/SystemLogBase.cpp
+++ b/src/Common/SystemLogBase.cpp
@@ -39,7 +39,7 @@ ISystemLog::~ISystemLog() = default;
 
 template <typename LogElement>
 SystemLogQueue<LogElement>::SystemLogQueue(const SystemLogQueueSettings & settings_)
-    : log(&Poco::Logger::get("SystemLogQueue (" + settings_.database + "." +settings_.table + ")"))
+    : log(getLogger("SystemLogQueue (" + settings_.database + "." +settings_.table + ")"))
     , settings(settings_)
 
 {
diff --git a/src/Common/SystemLogBase.h b/src/Common/SystemLogBase.h
index 1ced313b36ac..a734c70f2852 100644
--- a/src/Common/SystemLogBase.h
+++ b/src/Common/SystemLogBase.h
@@ -121,7 +121,7 @@ class SystemLogQueue
     /// Data shared between callers of add()/flush()/shutdown(), and the saving thread
     std::mutex mutex;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     // Queue is bounded. But its size is quite large to not block in all normal cases.
     std::vector<LogElement> queue;
diff --git a/src/Common/TLDListsHolder.cpp b/src/Common/TLDListsHolder.cpp
index 623b88f83a54..c3991b869831 100644
--- a/src/Common/TLDListsHolder.cpp
+++ b/src/Common/TLDListsHolder.cpp
@@ -55,7 +55,7 @@ void TLDListsHolder::parseConfig(const std::string & top_level_domains_path, con
     Poco::Util::AbstractConfiguration::Keys config_keys;
     config.keys("top_level_domains_lists", config_keys);
 
-    Poco::Logger * log = &Poco::Logger::get("TLDListsHolder");
+    LoggerPtr log = getLogger("TLDListsHolder");
 
     for (const auto & key : config_keys)
     {
diff --git a/src/Common/ThreadProfileEvents.cpp b/src/Common/ThreadProfileEvents.cpp
index 256f53df011a..990151d73fff 100644
--- a/src/Common/ThreadProfileEvents.cpp
+++ b/src/Common/ThreadProfileEvents.cpp
@@ -300,7 +300,7 @@ static void enablePerfEvent(int event_fd)
 {
     if (ioctl(event_fd, PERF_EVENT_IOC_ENABLE, 0))
     {
-        LOG_WARNING(&Poco::Logger::get("PerfEvents"),
+        LOG_WARNING(getLogger("PerfEvents"),
             "Can't enable perf event with file descriptor {}: '{}' ({})",
             event_fd, errnoToString(), errno);
     }
@@ -310,7 +310,7 @@ static void disablePerfEvent(int event_fd)
 {
     if (ioctl(event_fd, PERF_EVENT_IOC_DISABLE, 0))
     {
-        LOG_WARNING(&Poco::Logger::get("PerfEvents"),
+        LOG_WARNING(getLogger("PerfEvents"),
             "Can't disable perf event with file descriptor {}: '{}' ({})",
             event_fd, errnoToString(), errno);
     }
@@ -320,7 +320,7 @@ static void releasePerfEvent(int event_fd)
 {
     if (close(event_fd))
     {
-        LOG_WARNING(&Poco::Logger::get("PerfEvents"),
+        LOG_WARNING(getLogger("PerfEvents"),
             "Can't close perf event file descriptor {}: {} ({})",
             event_fd, errnoToString(), errno);
     }
@@ -333,12 +333,12 @@ static bool validatePerfEventDescriptor(int & fd)
 
     if (errno == EBADF)
     {
-        LOG_WARNING(&Poco::Logger::get("PerfEvents"),
+        LOG_WARNING(getLogger("PerfEvents"),
             "Event descriptor {} was closed from the outside; reopening", fd);
     }
     else
     {
-        LOG_WARNING(&Poco::Logger::get("PerfEvents"),
+        LOG_WARNING(getLogger("PerfEvents"),
             "Error while checking availability of event descriptor {}: {} ({})",
             fd, errnoToString(), errno);
 
@@ -416,7 +416,7 @@ bool PerfEventsCounters::processThreadLocalChanges(const std::string & needed_ev
     bool has_cap_sys_admin = hasLinuxCapability(CAP_SYS_ADMIN);
     if (perf_event_paranoid >= 3 && !has_cap_sys_admin)
     {
-        LOG_WARNING(&Poco::Logger::get("PerfEvents"),
+        LOG_WARNING(getLogger("PerfEvents"),
             "Not enough permissions to record perf events: "
             "perf_event_paranoid = {} and CAP_SYS_ADMIN = 0",
             perf_event_paranoid);
@@ -444,7 +444,7 @@ bool PerfEventsCounters::processThreadLocalChanges(const std::string & needed_ev
             // ENOENT means that the event is not supported. Don't log it, because
             // this is called for each thread and would be too verbose. Log other
             // error codes because they might signify an error.
-            LOG_WARNING(&Poco::Logger::get("PerfEvents"),
+            LOG_WARNING(getLogger("PerfEvents"),
                 "Failed to open perf event {} (event_type={}, event_config={}): "
                 "'{}' ({})", event_info.settings_name, event_info.event_type,
                 event_info.event_config, errnoToString(), errno);
@@ -484,7 +484,7 @@ std::vector<size_t> PerfEventsCounters::eventIndicesFromString(const std::string
         }
         else
         {
-            LOG_ERROR(&Poco::Logger::get("PerfEvents"),
+            LOG_ERROR(getLogger("PerfEvents"),
                 "Unknown perf event name '{}' specified in settings", event_name);
         }
     }
@@ -531,7 +531,7 @@ void PerfEventsCounters::finalizeProfileEvents(ProfileEvents::Counters & profile
 
         if (bytes_read != bytes_to_read)
         {
-            LOG_WARNING(&Poco::Logger::get("PerfEvents"),
+            LOG_WARNING(getLogger("PerfEvents"),
                 "Can't read event value from file descriptor {}: '{}' ({})",
                 fd, errnoToString(), errno);
             current_values[i] = {};
diff --git a/src/Common/ThreadStatus.cpp b/src/Common/ThreadStatus.cpp
index c99823b2dfaf..05524a5d6b9b 100644
--- a/src/Common/ThreadStatus.cpp
+++ b/src/Common/ThreadStatus.cpp
@@ -76,7 +76,7 @@ ThreadStatus::ThreadStatus(bool check_current_thread_on_destruction_)
     last_rusage = std::make_unique<RUsageCounters>();
 
     memory_tracker.setDescription("(for thread)");
-    log = &Poco::Logger::get("ThreadStatus");
+    log = getLogger("ThreadStatus");
 
     current_thread = this;
 
diff --git a/src/Common/ThreadStatus.h b/src/Common/ThreadStatus.h
index b8bdebf10edf..f7534c35a982 100644
--- a/src/Common/ThreadStatus.h
+++ b/src/Common/ThreadStatus.h
@@ -236,7 +236,7 @@ class ThreadStatus : public boost::noncopyable
     using Deleter = std::function<void()>;
     Deleter deleter;
 
-    Poco::Logger * log = nullptr;
+    LoggerPtr log = nullptr;
 
     bool check_current_thread_on_destruction;
 
diff --git a/src/Common/ZooKeeper/ZooKeeper.cpp b/src/Common/ZooKeeper/ZooKeeper.cpp
index 70b8df5cd2cd..8a8465de491e 100644
--- a/src/Common/ZooKeeper/ZooKeeper.cpp
+++ b/src/Common/ZooKeeper/ZooKeeper.cpp
@@ -60,7 +60,7 @@ void ZooKeeper::init(ZooKeeperArgs args_)
 
 {
     args = std::move(args_);
-    log = &Poco::Logger::get("ZooKeeper");
+    log = getLogger("ZooKeeper");
 
     if (args.implementation == "zookeeper")
     {
@@ -1455,7 +1455,7 @@ Coordination::RequestPtr makeExistsRequest(const std::string & path)
     return request;
 }
 
-std::string normalizeZooKeeperPath(std::string zookeeper_path, bool check_starts_with_slash, Poco::Logger * log)
+std::string normalizeZooKeeperPath(std::string zookeeper_path, bool check_starts_with_slash, LoggerPtr log)
 {
     if (!zookeeper_path.empty() && zookeeper_path.back() == '/')
         zookeeper_path.resize(zookeeper_path.size() - 1);
@@ -1491,7 +1491,7 @@ String extractZooKeeperName(const String & path)
     return default_zookeeper_name;
 }
 
-String extractZooKeeperPath(const String & path, bool check_starts_with_slash, Poco::Logger * log)
+String extractZooKeeperPath(const String & path, bool check_starts_with_slash, LoggerPtr log)
 {
     if (path.empty())
         throw DB::Exception(DB::ErrorCodes::BAD_ARGUMENTS, "ZooKeeper path should not be empty");
diff --git a/src/Common/ZooKeeper/ZooKeeper.h b/src/Common/ZooKeeper/ZooKeeper.h
index 1f29af0797b8..811546fb4b9b 100644
--- a/src/Common/ZooKeeper/ZooKeeper.h
+++ b/src/Common/ZooKeeper/ZooKeeper.h
@@ -650,7 +650,7 @@ class ZooKeeper
 
     ZooKeeperArgs args;
 
-    Poco::Logger * log = nullptr;
+    LoggerPtr log = nullptr;
     std::shared_ptr<DB::ZooKeeperLog> zk_log;
 
     AtomicStopwatch session_uptime;
@@ -729,7 +729,7 @@ class EphemeralNodeHolder
             else
             {
                 ProfileEvents::increment(ProfileEvents::CannotRemoveEphemeralNode);
-                LOG_DEBUG(&Poco::Logger::get("EphemeralNodeHolder"), "Cannot remove {} since session has been expired", path);
+                LOG_DEBUG(getLogger("EphemeralNodeHolder"), "Cannot remove {} since session has been expired", path);
             }
         }
         catch (...)
@@ -749,11 +749,11 @@ class EphemeralNodeHolder
 
 using EphemeralNodeHolderPtr = EphemeralNodeHolder::Ptr;
 
-String normalizeZooKeeperPath(std::string zookeeper_path, bool check_starts_with_slash, Poco::Logger * log = nullptr);
+String normalizeZooKeeperPath(std::string zookeeper_path, bool check_starts_with_slash, LoggerPtr log = nullptr);
 
 String extractZooKeeperName(const String & path);
 
-String extractZooKeeperPath(const String & path, bool check_starts_with_slash, Poco::Logger * log = nullptr);
+String extractZooKeeperPath(const String & path, bool check_starts_with_slash, LoggerPtr log = nullptr);
 
 String getSequentialNodeName(const String & prefix, UInt64 number);
 
diff --git a/src/Common/ZooKeeper/ZooKeeperCommon.cpp b/src/Common/ZooKeeper/ZooKeeperCommon.cpp
index 592d142e9250..660ae59e81e9 100644
--- a/src/Common/ZooKeeper/ZooKeeperCommon.cpp
+++ b/src/Common/ZooKeeper/ZooKeeperCommon.cpp
@@ -929,7 +929,7 @@ ZooKeeperRequest::~ZooKeeperRequest()
     constexpr UInt64 max_request_time_ns = 1000000000ULL; /// 1 sec
     if (max_request_time_ns < elapsed_ns)
     {
-        LOG_TEST(&Poco::Logger::get(__PRETTY_FUNCTION__), "Processing of request xid={} took {} ms", xid, elapsed_ns / 1000000UL);
+        LOG_TEST(getLogger(__PRETTY_FUNCTION__), "Processing of request xid={} took {} ms", xid, elapsed_ns / 1000000UL);
     }
 }
 
@@ -950,7 +950,7 @@ ZooKeeperResponse::~ZooKeeperResponse()
     constexpr UInt64 max_request_time_ns = 1000000000ULL; /// 1 sec
     if (max_request_time_ns < elapsed_ns)
     {
-        LOG_TEST(&Poco::Logger::get(__PRETTY_FUNCTION__), "Processing of response xid={} took {} ms", xid, elapsed_ns / 1000000UL);
+        LOG_TEST(getLogger(__PRETTY_FUNCTION__), "Processing of response xid={} took {} ms", xid, elapsed_ns / 1000000UL);
     }
 }
 
diff --git a/src/Common/ZooKeeper/ZooKeeperImpl.cpp b/src/Common/ZooKeeper/ZooKeeperImpl.cpp
index d732b900d37f..1fbadbd7616c 100644
--- a/src/Common/ZooKeeper/ZooKeeperImpl.cpp
+++ b/src/Common/ZooKeeper/ZooKeeperImpl.cpp
@@ -342,7 +342,7 @@ ZooKeeper::ZooKeeper(
     std::shared_ptr<ZooKeeperLog> zk_log_)
     : args(args_)
 {
-    log = &Poco::Logger::get("ZooKeeperClient");
+    log = getLogger("ZooKeeperClient");
     std::atomic_store(&zk_log, std::move(zk_log_));
 
     if (!args.chroot.empty())
diff --git a/src/Common/ZooKeeper/ZooKeeperImpl.h b/src/Common/ZooKeeper/ZooKeeperImpl.h
index 13e1dc9e3cd8..b63f67bf7a6f 100644
--- a/src/Common/ZooKeeper/ZooKeeperImpl.h
+++ b/src/Common/ZooKeeper/ZooKeeperImpl.h
@@ -308,7 +308,7 @@ class ZooKeeper final : public IKeeper
     ThreadReference send_thread;
     ThreadReference receive_thread;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     void connect(
         const Nodes & node,
diff --git a/src/Common/ZooKeeper/ZooKeeperLock.cpp b/src/Common/ZooKeeper/ZooKeeperLock.cpp
index 6ee1c380efbb..b90bcfd2b55a 100644
--- a/src/Common/ZooKeeper/ZooKeeperLock.cpp
+++ b/src/Common/ZooKeeper/ZooKeeperLock.cpp
@@ -26,7 +26,7 @@ ZooKeeperLock::ZooKeeperLock(
     : zookeeper(zookeeper_)
     , lock_path(fs::path(lock_prefix_) / lock_name_)
     , lock_message(lock_message_)
-    , log(&Poco::Logger::get("zkutil::Lock"))
+    , log(getLogger("zkutil::Lock"))
 {
     zookeeper->createIfNotExists(lock_prefix_, "");
 }
diff --git a/src/Common/ZooKeeper/ZooKeeperLock.h b/src/Common/ZooKeeper/ZooKeeperLock.h
index 146527c6c943..6271afaf6e24 100644
--- a/src/Common/ZooKeeper/ZooKeeperLock.h
+++ b/src/Common/ZooKeeper/ZooKeeperLock.h
@@ -46,7 +46,7 @@ class ZooKeeperLock
 
     std::string lock_path;
     std::string lock_message;
-    Poco::Logger * log;
+    LoggerPtr log;
     bool locked = false;
 
 };
diff --git a/src/Common/ZooKeeper/ZooKeeperWithFaultInjection.cpp b/src/Common/ZooKeeper/ZooKeeperWithFaultInjection.cpp
index 72923ca0487f..694004dee232 100644
--- a/src/Common/ZooKeeper/ZooKeeperWithFaultInjection.cpp
+++ b/src/Common/ZooKeeper/ZooKeeperWithFaultInjection.cpp
@@ -9,7 +9,7 @@ ZooKeeperWithFaultInjection::ZooKeeperWithFaultInjection(
     double fault_injection_probability,
     UInt64 fault_injection_seed,
     std::string name_,
-    Poco::Logger * logger_)
+    LoggerPtr logger_)
     : keeper(keeper_)
     , fault_policy(std::make_unique<RandomFaultInjection>(fault_injection_probability, fault_injection_seed))
     , name(std::move(name_))
diff --git a/src/Common/ZooKeeper/ZooKeeperWithFaultInjection.h b/src/Common/ZooKeeper/ZooKeeperWithFaultInjection.h
index 57e1f0f3b876..2ee456a23b95 100644
--- a/src/Common/ZooKeeper/ZooKeeperWithFaultInjection.h
+++ b/src/Common/ZooKeeper/ZooKeeperWithFaultInjection.h
@@ -62,7 +62,7 @@ class ZooKeeperWithFaultInjection
 
     std::unique_ptr<RandomFaultInjection> fault_policy;
     std::string name;
-    Poco::Logger * logger = nullptr;
+    LoggerPtr logger = nullptr;
     const UInt64 seed = 0;
 
     std::vector<std::string> session_ephemeral_nodes;
@@ -87,7 +87,7 @@ class ZooKeeperWithFaultInjection
         double fault_injection_probability,
         UInt64 fault_injection_seed,
         std::string name_,
-        Poco::Logger * logger_);
+        LoggerPtr logger_);
 
     explicit ZooKeeperWithFaultInjection(zkutil::ZooKeeper::Ptr const & keeper_) : keeper(keeper_) { }
     static ZooKeeperWithFaultInjection::Ptr createInstance(
@@ -95,7 +95,7 @@ class ZooKeeperWithFaultInjection
         UInt64 fault_injection_seed,
         zkutil::ZooKeeper::Ptr const & zookeeper,
         std::string name,
-        Poco::Logger * logger)
+        LoggerPtr logger)
     {
         /// validate all parameters here, constructor just accept everything
         if (fault_injection_probability < 0.0)
diff --git a/src/Common/logger_useful.h b/src/Common/logger_useful.h
index d9fe5ac91908..3899d060b7c6 100644
--- a/src/Common/logger_useful.h
+++ b/src/Common/logger_useful.h
@@ -8,6 +8,7 @@
 #include <Common/CurrentThread.h>
 #include <Common/ProfileEvents.h>
 #include <Common/LoggingFormatStringHelpers.h>
+#include <Common/Logger.h>
 
 namespace Poco { class Logger; }
 
@@ -19,11 +20,11 @@ using LogSeriesLimiterPtr = std::shared_ptr<LogSeriesLimiter>;
 
 namespace
 {
-    [[maybe_unused]] const ::Poco::Logger * getLogger(const ::Poco::Logger * logger) { return logger; }
-    [[maybe_unused]] const ::Poco::Logger * getLogger(const std::atomic<::Poco::Logger *> & logger) { return logger.load(); }
-    [[maybe_unused]] std::unique_ptr<LogToStrImpl> getLogger(std::unique_ptr<LogToStrImpl> && logger) { return logger; }
-    [[maybe_unused]] std::unique_ptr<LogFrequencyLimiterIml> getLogger(std::unique_ptr<LogFrequencyLimiterIml> && logger) { return logger; }
-    [[maybe_unused]] LogSeriesLimiterPtr getLogger(LogSeriesLimiterPtr & logger) { return logger; }
+    [[maybe_unused]] const ::Poco::Logger * getLoggerHelper(const LoggerPtr & logger) { return logger.get(); }
+    [[maybe_unused]] const ::Poco::Logger * getLoggerHelper(const ::Poco::Logger * logger) { return logger; }
+    [[maybe_unused]] std::unique_ptr<LogToStrImpl> getLoggerHelper(std::unique_ptr<LogToStrImpl> && logger) { return logger; }
+    [[maybe_unused]] std::unique_ptr<LogFrequencyLimiterIml> getLoggerHelper(std::unique_ptr<LogFrequencyLimiterIml> && logger) { return logger; }
+    [[maybe_unused]] LogSeriesLimiterPtr getLoggerHelper(LogSeriesLimiterPtr & logger) { return logger; }
 }
 
 #define LOG_IMPL_FIRST_ARG(X, ...) X
@@ -62,7 +63,7 @@ namespace
 
 #define LOG_IMPL(logger, priority, PRIORITY, ...) do                                                                \
 {                                                                                                                   \
-    auto _logger = ::getLogger(logger);                                                                             \
+    auto _logger = ::getLoggerHelper(logger);                                                                             \
     const bool _is_clients_log = (DB::CurrentThread::getGroup() != nullptr) &&                                      \
         (DB::CurrentThread::get().getClientLogsLevel() >= (priority));                                              \
     if (!_is_clients_log && !_logger->is((PRIORITY)))                                                               \
diff --git a/src/Common/makeSocketAddress.cpp b/src/Common/makeSocketAddress.cpp
index b5df6a4ef033..ba5bb53cd20f 100644
--- a/src/Common/makeSocketAddress.cpp
+++ b/src/Common/makeSocketAddress.cpp
@@ -33,4 +33,9 @@ Poco::Net::SocketAddress makeSocketAddress(const std::string & host, uint16_t po
     return socket_address;
 }
 
+Poco::Net::SocketAddress makeSocketAddress(const std::string & host, uint16_t port, LoggerPtr log)
+{
+    return makeSocketAddress(host, port, log.get());
+}
+
 }
diff --git a/src/Common/makeSocketAddress.h b/src/Common/makeSocketAddress.h
index 9c7d10a04718..439a4ef1e9bf 100644
--- a/src/Common/makeSocketAddress.h
+++ b/src/Common/makeSocketAddress.h
@@ -1,5 +1,7 @@
 #pragma once
+
 #include <Poco/Net/SocketAddress.h>
+#include <Common/Logger.h>
 
 namespace Poco { class Logger; }
 
@@ -8,4 +10,6 @@ namespace DB
 
 Poco::Net::SocketAddress makeSocketAddress(const std::string & host, uint16_t port, Poco::Logger * log);
 
+Poco::Net::SocketAddress makeSocketAddress(const std::string & host, uint16_t port, LoggerPtr log);
+
 }
diff --git a/src/Common/mysqlxx/Query.cpp b/src/Common/mysqlxx/Query.cpp
index e30ed2b75c81..babfc8c7c41d 100644
--- a/src/Common/mysqlxx/Query.cpp
+++ b/src/Common/mysqlxx/Query.cpp
@@ -52,7 +52,7 @@ void Query::executeImpl()
 {
     MYSQL* mysql_driver = conn->getDriver();
 
-    LOG_TRACE(&Poco::Logger::get("mysqlxx::Query"), "Running MySQL query using connection {}", mysql_thread_id(mysql_driver));
+    LOG_TRACE(getLogger("mysqlxx::Query"), "Running MySQL query using connection {}", mysql_thread_id(mysql_driver));
     if (mysql_real_query(mysql_driver, query.data(), query.size()))
     {
         const auto err_no = mysql_errno(mysql_driver);
diff --git a/src/Common/mysqlxx/mysqlxx/Pool.h b/src/Common/mysqlxx/mysqlxx/Pool.h
index bb4d0cefbdc8..c85295c4dd08 100644
--- a/src/Common/mysqlxx/mysqlxx/Pool.h
+++ b/src/Common/mysqlxx/mysqlxx/Pool.h
@@ -202,7 +202,7 @@ class Pool final
     void removeConnection(Connection * connection);
 
 protected:
-    Poco::Logger * log = &Poco::Logger::get("mysqlxx::Pool");
+    LoggerPtr log = getLogger("mysqlxx::Pool");
 
     /// Number of MySQL connections which are created at launch.
     unsigned default_connections;
diff --git a/src/Common/parseRemoteDescription.cpp b/src/Common/parseRemoteDescription.cpp
index 7b2045b9de15..df3820b11f90 100644
--- a/src/Common/parseRemoteDescription.cpp
+++ b/src/Common/parseRemoteDescription.cpp
@@ -179,7 +179,7 @@ std::vector<std::pair<String, uint16_t>> parseRemoteDescriptionForExternalDataba
         size_t colon = address.find(':');
         if (colon == String::npos)
         {
-            LOG_WARNING(&Poco::Logger::get("ParseRemoteDescription"), "Port is not found for host: {}. Using default port {}", address, default_port);
+            LOG_WARNING(getLogger("ParseRemoteDescription"), "Port is not found for host: {}. Using default port {}", address, default_port);
             result.emplace_back(std::make_pair(address, default_port));
         }
         else
diff --git a/src/Compression/CompressionCodecDeflateQpl.cpp b/src/Compression/CompressionCodecDeflateQpl.cpp
index ee0356adde5e..631a12cc2522 100644
--- a/src/Compression/CompressionCodecDeflateQpl.cpp
+++ b/src/Compression/CompressionCodecDeflateQpl.cpp
@@ -33,7 +33,7 @@ DeflateQplJobHWPool::DeflateQplJobHWPool()
     : max_hw_jobs(0)
     , random_engine(randomSeed())
 {
-    Poco::Logger * log = &Poco::Logger::get("DeflateQplJobHWPool");
+    LoggerPtr log = getLogger("DeflateQplJobHWPool");
     const char * qpl_version = qpl_get_library_version();
 
     // loop all configured workqueue size to get maximum job number.
@@ -141,7 +141,7 @@ void DeflateQplJobHWPool::unLockJob(UInt32 index)
 }
 
 HardwareCodecDeflateQpl::HardwareCodecDeflateQpl(SoftwareCodecDeflateQpl & sw_codec_)
-    : log(&Poco::Logger::get("HardwareCodecDeflateQpl"))
+    : log(getLogger("HardwareCodecDeflateQpl"))
     , sw_codec(sw_codec_)
 {
 }
diff --git a/src/Compression/CompressionCodecDeflateQpl.h b/src/Compression/CompressionCodecDeflateQpl.h
index 3d9a9b13921d..c5978335fe8d 100644
--- a/src/Compression/CompressionCodecDeflateQpl.h
+++ b/src/Compression/CompressionCodecDeflateQpl.h
@@ -88,7 +88,7 @@ class HardwareCodecDeflateQpl
     /// For each submission, push job ID && job object into this map;
     /// For flush, pop out job ID && job object from this map. Use job ID to release job lock and use job object to check job status till complete.
     std::map<UInt32, qpl_job *> decomp_async_job_map;
-    Poco::Logger * log;
+    LoggerPtr log;
     /// Provides a fallback in case of errors.
     SoftwareCodecDeflateQpl & sw_codec;
 };
diff --git a/src/Compression/CompressionCodecEncrypted.cpp b/src/Compression/CompressionCodecEncrypted.cpp
index 8d945417fc11..3b7f4824069c 100644
--- a/src/Compression/CompressionCodecEncrypted.cpp
+++ b/src/Compression/CompressionCodecEncrypted.cpp
@@ -694,7 +694,7 @@ bool CompressionCodecEncrypted::Configuration::tryLoad(const Poco::Util::Abstrac
 /// if encryption is disabled, print warning about this.
 void CompressionCodecEncrypted::Configuration::load(const Poco::Util::AbstractConfiguration & config [[maybe_unused]], const String & config_prefix [[maybe_unused]])
 {
-    LOG_WARNING(&Poco::Logger::get("CompressionCodecEncrypted"), "Server was built without SSL support. Encryption is disabled.");
+    LOG_WARNING(getLogger("CompressionCodecEncrypted"), "Server was built without SSL support. Encryption is disabled.");
 }
 
 }
diff --git a/src/Compression/CompressionCodecZSTDQAT.cpp b/src/Compression/CompressionCodecZSTDQAT.cpp
index 4828a71a515c..5a4ef70a30ae 100644
--- a/src/Compression/CompressionCodecZSTDQAT.cpp
+++ b/src/Compression/CompressionCodecZSTDQAT.cpp
@@ -34,7 +34,7 @@ class CompressionCodecZSTDQAT : public CompressionCodecZSTD
 
 private:
     const int level;
-    Poco::Logger * log;
+    LoggerPtr log;
     static std::atomic<int> qat_state; /// Global initialization status of QAT device, we fall back back to software compression if uninitialized
 };
 
@@ -103,7 +103,7 @@ void registerCodecZSTDQAT(CompressionCodecFactory & factory)
 CompressionCodecZSTDQAT::CompressionCodecZSTDQAT(int level_)
     : CompressionCodecZSTD(level_)
     , level(level_)
-    , log(&Poco::Logger::get("CompressionCodecZSTDQAT"))
+    , log(getLogger("CompressionCodecZSTDQAT"))
 {
     setCodecDescription("ZSTD_QAT", {std::make_shared<ASTLiteral>(static_cast<UInt64>(level))});
 }
diff --git a/src/Coordination/Changelog.cpp b/src/Coordination/Changelog.cpp
index 7f1135eec947..5a58932606e5 100644
--- a/src/Coordination/Changelog.cpp
+++ b/src/Coordination/Changelog.cpp
@@ -116,7 +116,7 @@ class ChangelogWriter
         : existing_changelogs(existing_changelogs_)
         , log_file_settings(log_file_settings_)
         , keeper_context(std::move(keeper_context_))
-        , log(&Poco::Logger::get("Changelog"))
+        , log(getLogger("Changelog"))
     {
     }
 
@@ -454,7 +454,7 @@ class ChangelogWriter
 
     KeeperContextPtr keeper_context;
 
-    Poco::Logger * const log;
+    LoggerPtr const log;
 };
 
 struct ChangelogReadResult
@@ -493,7 +493,7 @@ class ChangelogReader
     }
 
     /// start_log_index -- all entries with index < start_log_index will be skipped, but accounted into total_entries_read_from_log
-    ChangelogReadResult readChangelog(IndexToLogEntry & logs, uint64_t start_log_index, Poco::Logger * log)
+    ChangelogReadResult readChangelog(IndexToLogEntry & logs, uint64_t start_log_index, LoggerPtr log)
     {
         ChangelogReadResult result{};
         result.compressed_log = compression_method != CompressionMethod::None;
@@ -592,7 +592,7 @@ class ChangelogReader
 };
 
 Changelog::Changelog(
-    Poco::Logger * log_, LogFileSettings log_file_settings, FlushSettings flush_settings_, KeeperContextPtr keeper_context_)
+    LoggerPtr log_, LogFileSettings log_file_settings, FlushSettings flush_settings_, KeeperContextPtr keeper_context_)
     : changelogs_detached_dir("detached")
     , rotate_interval(log_file_settings.rotate_interval)
     , compress_logs(log_file_settings.compress_logs)
diff --git a/src/Coordination/Changelog.h b/src/Coordination/Changelog.h
index 20f850e3f627..612c68ab7333 100644
--- a/src/Coordination/Changelog.h
+++ b/src/Coordination/Changelog.h
@@ -94,7 +94,7 @@ class Changelog
 {
 public:
     Changelog(
-        Poco::Logger * log_,
+        LoggerPtr log_,
         LogFileSettings log_file_settings,
         FlushSettings flush_settings,
         KeeperContextPtr keeper_context_);
@@ -185,7 +185,7 @@ class Changelog
     const String changelogs_detached_dir;
     const uint64_t rotate_interval;
     const bool compress_logs;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::mutex writer_mutex;
     /// Current writer for changelog file
diff --git a/src/Coordination/FourLetterCommand.cpp b/src/Coordination/FourLetterCommand.cpp
index af2e4ec5a348..4862acd448f3 100644
--- a/src/Coordination/FourLetterCommand.cpp
+++ b/src/Coordination/FourLetterCommand.cpp
@@ -234,7 +234,7 @@ void FourLetterCommandFactory::initializeAllowList(KeeperDispatcher & keeper_dis
             }
             else
             {
-                auto * log = &Poco::Logger::get("FourLetterCommandFactory");
+                auto log = getLogger("FourLetterCommandFactory");
                 LOG_WARNING(log, "Find invalid keeper 4lw command {} when initializing, ignore it.", token);
             }
         }
diff --git a/src/Coordination/KeeperContext.cpp b/src/Coordination/KeeperContext.cpp
index 0d9eb2544a6c..baad8d98e6af 100644
--- a/src/Coordination/KeeperContext.cpp
+++ b/src/Coordination/KeeperContext.cpp
@@ -55,7 +55,7 @@ void KeeperContext::initialize(const Poco::Util::AbstractConfiguration & config,
         if (!keeper_az.empty())
         {
             system_nodes_with_data[keeper_availability_zone_path] = keeper_az;
-            LOG_INFO(&Poco::Logger::get("KeeperContext"), "Initialize the KeeperContext with availability zone: '{}'", keeper_az);
+            LOG_INFO(getLogger("KeeperContext"), "Initialize the KeeperContext with availability zone: '{}'", keeper_az);
         }
     }
 
@@ -88,7 +88,7 @@ bool diskValidator(const Poco::Util::AbstractConfiguration & config, const std::
             supported_disk_types.end(),
             [&](const auto supported_type) { return disk_type != supported_type; }))
     {
-        LOG_INFO(&Poco::Logger::get("KeeperContext"), "Disk type '{}' is not supported for Keeper", disk_type);
+        LOG_INFO(getLogger("KeeperContext"), "Disk type '{}' is not supported for Keeper", disk_type);
         return false;
     }
 
@@ -374,7 +374,7 @@ void KeeperContext::initializeFeatureFlags(const Poco::Util::AbstractConfigurati
         system_nodes_with_data[keeper_api_feature_flags_path] = feature_flags.getFeatureFlags();
     }
 
-    feature_flags.logFlags(&Poco::Logger::get("KeeperContext"));
+    feature_flags.logFlags(getLogger("KeeperContext"));
 }
 
 void KeeperContext::updateKeeperMemorySoftLimit(const Poco::Util::AbstractConfiguration & config)
diff --git a/src/Coordination/KeeperDispatcher.cpp b/src/Coordination/KeeperDispatcher.cpp
index 8bf48f23f504..35bc953a705e 100644
--- a/src/Coordination/KeeperDispatcher.cpp
+++ b/src/Coordination/KeeperDispatcher.cpp
@@ -94,7 +94,7 @@ bool checkIfRequestIncreaseMem(const Coordination::ZooKeeperRequestPtr & request
 KeeperDispatcher::KeeperDispatcher()
     : responses_queue(std::numeric_limits<size_t>::max())
     , configuration_and_settings(std::make_shared<KeeperConfigurationAndSettings>())
-    , log(&Poco::Logger::get("KeeperDispatcher"))
+    , log(getLogger("KeeperDispatcher"))
 {}
 
 void KeeperDispatcher::requestThread()
diff --git a/src/Coordination/KeeperDispatcher.h b/src/Coordination/KeeperDispatcher.h
index 9c487e7f0f9b..db41fb2ea26b 100644
--- a/src/Coordination/KeeperDispatcher.h
+++ b/src/Coordination/KeeperDispatcher.h
@@ -70,7 +70,7 @@ class KeeperDispatcher
 
     KeeperConfigurationAndSettingsPtr configuration_and_settings;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Counter for new session_id requests.
     std::atomic<int64_t> internal_session_id_counter{0};
diff --git a/src/Coordination/KeeperFeatureFlags.cpp b/src/Coordination/KeeperFeatureFlags.cpp
index d0cd1c86b553..2aad6cbed32e 100644
--- a/src/Coordination/KeeperFeatureFlags.cpp
+++ b/src/Coordination/KeeperFeatureFlags.cpp
@@ -80,7 +80,7 @@ const std::string & KeeperFeatureFlags::getFeatureFlags() const
     return feature_flags;
 }
 
-void KeeperFeatureFlags::logFlags(Poco::Logger * log) const
+void KeeperFeatureFlags::logFlags(LoggerPtr log) const
 {
     for (const auto & [feature_flag, feature_flag_name] : magic_enum::enum_entries<KeeperFeatureFlag>())
     {
diff --git a/src/Coordination/KeeperFeatureFlags.h b/src/Coordination/KeeperFeatureFlags.h
index 4db972fa2a06..4e26ca607361 100644
--- a/src/Coordination/KeeperFeatureFlags.h
+++ b/src/Coordination/KeeperFeatureFlags.h
@@ -32,7 +32,7 @@ class KeeperFeatureFlags
     void enableFeatureFlag(KeeperFeatureFlag feature);
     void disableFeatureFlag(KeeperFeatureFlag feature);
 
-    void logFlags(Poco::Logger * log) const;
+    void logFlags(LoggerPtr log) const;
 private:
     std::string feature_flags;
 };
diff --git a/src/Coordination/KeeperLogStore.cpp b/src/Coordination/KeeperLogStore.cpp
index 8cff3419afcd..ce7c715237e1 100644
--- a/src/Coordination/KeeperLogStore.cpp
+++ b/src/Coordination/KeeperLogStore.cpp
@@ -7,7 +7,7 @@ namespace DB
 {
 
 KeeperLogStore::KeeperLogStore(LogFileSettings log_file_settings, FlushSettings flush_settings, KeeperContextPtr keeper_context)
-    : log(&Poco::Logger::get("KeeperLogStore")), changelog(log, log_file_settings, flush_settings, keeper_context)
+    : log(getLogger("KeeperLogStore")), changelog(log, log_file_settings, flush_settings, keeper_context)
 {
     if (log_file_settings.force_sync)
         LOG_INFO(log, "force_sync enabled");
diff --git a/src/Coordination/KeeperLogStore.h b/src/Coordination/KeeperLogStore.h
index de9205241bd9..aa277f19d883 100644
--- a/src/Coordination/KeeperLogStore.h
+++ b/src/Coordination/KeeperLogStore.h
@@ -74,7 +74,7 @@ class KeeperLogStore : public nuraft::log_store
 
 private:
     mutable std::mutex changelog_lock;
-    Poco::Logger * log;
+    LoggerPtr log;
     Changelog changelog TSA_GUARDED_BY(changelog_lock);
 };
 
diff --git a/src/Coordination/KeeperServer.cpp b/src/Coordination/KeeperServer.cpp
index 45619ab38a1b..722b1303cc82 100644
--- a/src/Coordination/KeeperServer.cpp
+++ b/src/Coordination/KeeperServer.cpp
@@ -92,7 +92,7 @@ std::string checkAndGetSuperdigest(const String & user_and_digest)
     return user_and_digest;
 }
 
-int32_t getValueOrMaxInt32AndLogWarning(uint64_t value, const std::string & name, Poco::Logger * log)
+int32_t getValueOrMaxInt32AndLogWarning(uint64_t value, const std::string & name, LoggerPtr log)
 {
     if (value > std::numeric_limits<int32_t>::max())
     {
@@ -120,7 +120,7 @@ KeeperServer::KeeperServer(
     KeeperStateMachine::CommitCallback commit_callback)
     : server_id(configuration_and_settings_->server_id)
     , coordination_settings(configuration_and_settings_->coordination_settings)
-    , log(&Poco::Logger::get("KeeperServer"))
+    , log(getLogger("KeeperServer"))
     , is_recovering(config.getBool("keeper_server.force_recovery", false))
     , keeper_context{std::move(keeper_context_)}
     , create_snapshot_on_exit(config.getBool("keeper_server.create_snapshot_on_exit", true))
diff --git a/src/Coordination/KeeperServer.h b/src/Coordination/KeeperServer.h
index 8c657ab28a70..ef298df3efca 100644
--- a/src/Coordination/KeeperServer.h
+++ b/src/Coordination/KeeperServer.h
@@ -48,7 +48,7 @@ class KeeperServer
 
     nuraft::ptr<nuraft::cluster_config> last_local_config;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Callback func which is called by NuRaft on all internal events.
     /// Used to determine the moment when raft is ready to server new requests
diff --git a/src/Coordination/KeeperSnapshotManager.cpp b/src/Coordination/KeeperSnapshotManager.cpp
index ee5935015e4f..f53b80317121 100644
--- a/src/Coordination/KeeperSnapshotManager.cpp
+++ b/src/Coordination/KeeperSnapshotManager.cpp
@@ -383,7 +383,7 @@ void KeeperStorageSnapshot::deserialize(SnapshotDeserializationResult & deserial
         {
             if (keeper_context->ignoreSystemPathOnStartup() || keeper_context->getServerState() != KeeperContext::Phase::INIT)
             {
-                LOG_ERROR(&Poco::Logger::get("KeeperSnapshotManager"), "{}. Ignoring it", error_msg);
+                LOG_ERROR(getLogger("KeeperSnapshotManager"), "{}. Ignoring it", error_msg);
                 continue;
             }
             else
@@ -399,7 +399,7 @@ void KeeperStorageSnapshot::deserialize(SnapshotDeserializationResult & deserial
             {
                 if (keeper_context->ignoreSystemPathOnStartup() || keeper_context->getServerState() != KeeperContext::Phase::INIT)
                 {
-                    LOG_ERROR(&Poco::Logger::get("KeeperSnapshotManager"), "{}. Ignoring it", error_msg);
+                    LOG_ERROR(getLogger("KeeperSnapshotManager"), "{}. Ignoring it", error_msg);
                     node = KeeperStorage::Node{};
                 }
                 else
@@ -437,7 +437,7 @@ void KeeperStorageSnapshot::deserialize(SnapshotDeserializationResult & deserial
             {
 #ifdef NDEBUG
                 /// TODO (alesapin) remove this, it should be always CORRUPTED_DATA.
-                LOG_ERROR(&Poco::Logger::get("KeeperSnapshotManager"), "Children counter in stat.numChildren {}"
+                LOG_ERROR(getLogger("KeeperSnapshotManager"), "Children counter in stat.numChildren {}"
                             " is different from actual children size {} for node {}", itr.value.stat.numChildren, itr.value.getChildren().size(), itr.key);
 #else
                 throw Exception(ErrorCodes::LOGICAL_ERROR, "Children counter in stat.numChildren {}"
@@ -594,7 +594,7 @@ KeeperSnapshotManager::KeeperSnapshotManager(
 
             if (!inserted)
                 LOG_WARNING(
-                    &Poco::Logger::get("KeeperSnapshotManager"),
+                    getLogger("KeeperSnapshotManager"),
                     "Found another snapshots with last log idx {}, will use snapshot from disk {}",
                     snapshot_up_to,
                     disk->getName());
diff --git a/src/Coordination/KeeperSnapshotManager.h b/src/Coordination/KeeperSnapshotManager.h
index 6096ba318da2..48a66e79cd84 100644
--- a/src/Coordination/KeeperSnapshotManager.h
+++ b/src/Coordination/KeeperSnapshotManager.h
@@ -188,7 +188,7 @@ class KeeperSnapshotManager
 
     KeeperContextPtr keeper_context;
 
-    Poco::Logger * log = &Poco::Logger::get("KeeperSnapshotManager");
+    LoggerPtr log = getLogger("KeeperSnapshotManager");
 };
 
 /// Keeper create snapshots in background thread. KeeperStateMachine just create
diff --git a/src/Coordination/KeeperSnapshotManagerS3.cpp b/src/Coordination/KeeperSnapshotManagerS3.cpp
index 716184e07d0c..0337a564660e 100644
--- a/src/Coordination/KeeperSnapshotManagerS3.cpp
+++ b/src/Coordination/KeeperSnapshotManagerS3.cpp
@@ -43,7 +43,7 @@ struct KeeperSnapshotManagerS3::S3Configuration
 
 KeeperSnapshotManagerS3::KeeperSnapshotManagerS3()
     : snapshots_s3_queue(std::numeric_limits<size_t>::max())
-    , log(&Poco::Logger::get("KeeperSnapshotManagerS3"))
+    , log(getLogger("KeeperSnapshotManagerS3"))
     , uuid(UUIDHelpers::generateV4())
 {}
 
diff --git a/src/Coordination/KeeperSnapshotManagerS3.h b/src/Coordination/KeeperSnapshotManagerS3.h
index e17cf5a1cfbf..d03deb60c1a4 100644
--- a/src/Coordination/KeeperSnapshotManagerS3.h
+++ b/src/Coordination/KeeperSnapshotManagerS3.h
@@ -45,7 +45,7 @@ class KeeperSnapshotManagerS3
 
     std::atomic<bool> shutdown_called{false};
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     UUID uuid;
 
diff --git a/src/Coordination/KeeperStateMachine.cpp b/src/Coordination/KeeperStateMachine.cpp
index 39a2347ff802..8d50f0a76b17 100644
--- a/src/Coordination/KeeperStateMachine.cpp
+++ b/src/Coordination/KeeperStateMachine.cpp
@@ -59,7 +59,7 @@ KeeperStateMachine::KeeperStateMachine(
     , snapshots_queue(snapshots_queue_)
     , min_request_size_to_cache(coordination_settings_->min_request_size_for_cache)
     , last_committed_idx(0)
-    , log(&Poco::Logger::get("KeeperStateMachine"))
+    , log(getLogger("KeeperStateMachine"))
     , superdigest(superdigest_)
     , keeper_context(keeper_context_)
     , snapshot_manager_s3(snapshot_manager_s3_)
@@ -144,7 +144,7 @@ void assertDigest(
     if (!KeeperStorage::checkDigest(first, second))
     {
         LOG_FATAL(
-            &Poco::Logger::get("KeeperStateMachine"),
+            getLogger("KeeperStateMachine"),
             "Digest for nodes is not matching after {} request of type '{}'.
Expected digest - {}, actual digest - {} (digest "
             "{}). Keeper will terminate to avoid inconsistencies.
Extra information about the request:
{}",
             committing ? "committing" : "preprocessing",
@@ -679,7 +679,7 @@ void KeeperStateMachine::save_logical_snp_obj(
     }
 }
 
-static int bufferFromFile(Poco::Logger * log, const std::string & path, nuraft::ptr<nuraft::buffer> & data_out)
+static int bufferFromFile(LoggerPtr log, const std::string & path, nuraft::ptr<nuraft::buffer> & data_out)
 {
     if (path.empty() || !std::filesystem::exists(path))
     {
diff --git a/src/Coordination/KeeperStateMachine.h b/src/Coordination/KeeperStateMachine.h
index aad5d3aafd4c..b11cd53c00e9 100644
--- a/src/Coordination/KeeperStateMachine.h
+++ b/src/Coordination/KeeperStateMachine.h
@@ -173,7 +173,7 @@ class KeeperStateMachine : public nuraft::state_machine
     /// Last committed Raft log number.
     std::atomic<uint64_t> last_committed_idx;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Cluster config for our quorum.
     /// It's a copy of config stored in StateManager, but here
diff --git a/src/Coordination/KeeperStateManager.cpp b/src/Coordination/KeeperStateManager.cpp
index efe8a0cb2bd1..4fbb9b52e6e3 100644
--- a/src/Coordination/KeeperStateManager.cpp
+++ b/src/Coordination/KeeperStateManager.cpp
@@ -227,7 +227,7 @@ KeeperStateManager::KeeperStateManager(int server_id_, const std::string & host,
           keeper_context_))
     , server_state_file_name("state")
     , keeper_context(keeper_context_)
-    , logger(&Poco::Logger::get("KeeperStateManager"))
+    , logger(getLogger("KeeperStateManager"))
 {
     auto peer_config = nuraft::cs_new<nuraft::srv_config>(my_server_id, host + ":" + std::to_string(port));
     configuration_wrapper.cluster_config = nuraft::cs_new<nuraft::cluster_config>();
@@ -262,7 +262,7 @@ KeeperStateManager::KeeperStateManager(
           keeper_context_))
     , server_state_file_name(server_state_file_name_)
     , keeper_context(keeper_context_)
-    , logger(&Poco::Logger::get("KeeperStateManager"))
+    , logger(getLogger("KeeperStateManager"))
 {
 }
 
@@ -495,7 +495,7 @@ ClusterUpdateActions KeeperStateManager::getRaftConfigurationDiff(
             if (old_endpoint != server_config->get_endpoint())
             {
                 LOG_WARNING(
-                    &Poco::Logger::get("RaftConfiguration"),
+                    getLogger("RaftConfiguration"),
                     "Config will be ignored because a server with ID {} is already present in the cluster on a different endpoint ({}). "
                     "The endpoint of the current servers should not be changed. For servers on a new endpoint, please use a new ID.",
                     new_id,
diff --git a/src/Coordination/KeeperStateManager.h b/src/Coordination/KeeperStateManager.h
index fd05261ac6c6..02dd6b2ff53a 100644
--- a/src/Coordination/KeeperStateManager.h
+++ b/src/Coordination/KeeperStateManager.h
@@ -128,7 +128,7 @@ class KeeperStateManager : public nuraft::state_mgr
 
     KeeperContextPtr keeper_context;
 
-    Poco::Logger * logger;
+    LoggerPtr logger;
 
 public:
     /// Parse configuration from xml config.
diff --git a/src/Coordination/KeeperStorage.cpp b/src/Coordination/KeeperStorage.cpp
index c128d7c2f98f..992d4ca8a954 100644
--- a/src/Coordination/KeeperStorage.cpp
+++ b/src/Coordination/KeeperStorage.cpp
@@ -609,7 +609,7 @@ namespace
 [[noreturn]] void onStorageInconsistency()
 {
     LOG_ERROR(
-        &Poco::Logger::get("KeeperStorage"),
+        getLogger("KeeperStorage"),
         "Inconsistency found between uncommitted and committed data. Keeper will terminate to avoid undefined behaviour.");
     std::terminate();
 }
@@ -887,7 +887,7 @@ void handleSystemNodeModification(const KeeperContext & keeper_context, std::str
             "If you still want to ignore it, you can set 'keeper_server.ignore_system_path_on_startup' to true.",
             error_msg);
 
-    LOG_ERROR(&Poco::Logger::get("KeeperStorage"), fmt::runtime(error_msg));
+    LOG_ERROR(getLogger("KeeperStorage"), fmt::runtime(error_msg));
 }
 
 }
@@ -2381,7 +2381,7 @@ void KeeperStorage::rollbackRequest(int64_t rollback_zxid, bool allow_missing)
     }
     catch (...)
     {
-        LOG_FATAL(&Poco::Logger::get("KeeperStorage"), "Failed to rollback log. Terminating to avoid inconsistencies");
+        LOG_FATAL(getLogger("KeeperStorage"), "Failed to rollback log. Terminating to avoid inconsistencies");
         std::terminate();
     }
 }
diff --git a/src/Coordination/LoggerWrapper.h b/src/Coordination/LoggerWrapper.h
index d092a8d44407..d08c42b68684 100644
--- a/src/Coordination/LoggerWrapper.h
+++ b/src/Coordination/LoggerWrapper.h
@@ -26,7 +26,7 @@ class LoggerWrapper : public nuraft::logger
 
 public:
     LoggerWrapper(const std::string & name, LogsLevel level_)
-        : log(&Poco::Logger::get(name))
+        : log(getLogger(name))
         , level(level_)
     {
         log->setLevel(static_cast<int>(LEVELS.at(level)));
@@ -57,7 +57,7 @@ class LoggerWrapper : public nuraft::logger
     }
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     std::atomic<LogsLevel> level;
 };
 
diff --git a/src/Coordination/ZooKeeperDataReader.cpp b/src/Coordination/ZooKeeperDataReader.cpp
index b55ebef327ff..6b9d5f7c8eb1 100644
--- a/src/Coordination/ZooKeeperDataReader.cpp
+++ b/src/Coordination/ZooKeeperDataReader.cpp
@@ -90,7 +90,7 @@ void deserializeACLMap(KeeperStorage & storage, ReadBuffer & in)
     }
 }
 
-int64_t deserializeStorageData(KeeperStorage & storage, ReadBuffer & in, Poco::Logger * log)
+int64_t deserializeStorageData(KeeperStorage & storage, ReadBuffer & in, LoggerPtr log)
 {
     int64_t max_zxid = 0;
     std::string path;
@@ -146,7 +146,7 @@ int64_t deserializeStorageData(KeeperStorage & storage, ReadBuffer & in, Poco::L
     return max_zxid;
 }
 
-void deserializeKeeperStorageFromSnapshot(KeeperStorage & storage, const std::string & snapshot_path, Poco::Logger * log)
+void deserializeKeeperStorageFromSnapshot(KeeperStorage & storage, const std::string & snapshot_path, LoggerPtr log)
 {
     LOG_INFO(log, "Deserializing storage snapshot {}", snapshot_path);
     int64_t zxid = getZxidFromName(snapshot_path);
@@ -185,7 +185,7 @@ void deserializeKeeperStorageFromSnapshot(KeeperStorage & storage, const std::st
     LOG_INFO(log, "Finished, snapshot ZXID {}", storage.zxid);
 }
 
-void deserializeKeeperStorageFromSnapshotsDir(KeeperStorage & storage, const std::string & path, Poco::Logger * log)
+void deserializeKeeperStorageFromSnapshotsDir(KeeperStorage & storage, const std::string & path, LoggerPtr log)
 {
     namespace fs = std::filesystem;
     std::map<int64_t, std::string> existing_snapshots;
@@ -473,7 +473,7 @@ bool hasErrorsInMultiRequest(Coordination::ZooKeeperRequestPtr request)
 
 }
 
-bool deserializeTxn(KeeperStorage & storage, ReadBuffer & in, Poco::Logger * /*log*/)
+bool deserializeTxn(KeeperStorage & storage, ReadBuffer & in, LoggerPtr /*log*/)
 {
     int64_t checksum;
     Coordination::read(checksum, in);
@@ -528,7 +528,7 @@ bool deserializeTxn(KeeperStorage & storage, ReadBuffer & in, Poco::Logger * /*l
     return true;
 }
 
-void deserializeLogAndApplyToStorage(KeeperStorage & storage, const std::string & log_path, Poco::Logger * log)
+void deserializeLogAndApplyToStorage(KeeperStorage & storage, const std::string & log_path, LoggerPtr log)
 {
     ReadBufferFromFile reader(log_path);
 
@@ -552,7 +552,7 @@ void deserializeLogAndApplyToStorage(KeeperStorage & storage, const std::string
     LOG_INFO(log, "Finished {} deserialization, totally read {} records", log_path, counter);
 }
 
-void deserializeLogsAndApplyToStorage(KeeperStorage & storage, const std::string & path, Poco::Logger * log)
+void deserializeLogsAndApplyToStorage(KeeperStorage & storage, const std::string & path, LoggerPtr log)
 {
     namespace fs = std::filesystem;
     std::map<int64_t, std::string> existing_logs;
diff --git a/src/Coordination/ZooKeeperDataReader.h b/src/Coordination/ZooKeeperDataReader.h
index 8fd86ba99e21..648dc95adcfc 100644
--- a/src/Coordination/ZooKeeperDataReader.h
+++ b/src/Coordination/ZooKeeperDataReader.h
@@ -5,12 +5,12 @@
 namespace DB
 {
 
-void deserializeKeeperStorageFromSnapshot(KeeperStorage & storage, const std::string & snapshot_path, Poco::Logger * log);
+void deserializeKeeperStorageFromSnapshot(KeeperStorage & storage, const std::string & snapshot_path, LoggerPtr log);
 
-void deserializeKeeperStorageFromSnapshotsDir(KeeperStorage & storage, const std::string & path, Poco::Logger * log);
+void deserializeKeeperStorageFromSnapshotsDir(KeeperStorage & storage, const std::string & path, LoggerPtr log);
 
-void deserializeLogAndApplyToStorage(KeeperStorage & storage, const std::string & log_path, Poco::Logger * log);
+void deserializeLogAndApplyToStorage(KeeperStorage & storage, const std::string & log_path, LoggerPtr log);
 
-void deserializeLogsAndApplyToStorage(KeeperStorage & storage, const std::string & path, Poco::Logger * log);
+void deserializeLogsAndApplyToStorage(KeeperStorage & storage, const std::string & path, LoggerPtr log);
 
 }
diff --git a/src/Core/BackgroundSchedulePool.cpp b/src/Core/BackgroundSchedulePool.cpp
index fa892bc3c844..4facdeb4631f 100644
--- a/src/Core/BackgroundSchedulePool.cpp
+++ b/src/Core/BackgroundSchedulePool.cpp
@@ -116,7 +116,7 @@ void BackgroundSchedulePoolTaskInfo::execute()
     static constexpr UInt64 slow_execution_threshold_ms = 200;
 
     if (milliseconds >= slow_execution_threshold_ms)
-        LOG_TRACE(&Poco::Logger::get(log_name), "Execution took {} ms.", milliseconds);
+        LOG_TRACE(getLogger(log_name), "Execution took {} ms.", milliseconds);
 
     {
         std::lock_guard lock_schedule(schedule_mutex);
@@ -160,7 +160,7 @@ BackgroundSchedulePool::BackgroundSchedulePool(size_t size_, CurrentMetrics::Met
     , size_metric(size_metric_, size_)
     , thread_name(thread_name_)
 {
-    LOG_INFO(&Poco::Logger::get("BackgroundSchedulePool/" + thread_name), "Create BackgroundSchedulePool with {} threads", size_);
+    LOG_INFO(getLogger("BackgroundSchedulePool/" + thread_name), "Create BackgroundSchedulePool with {} threads", size_);
 
     threads.resize(size_);
 
@@ -174,7 +174,7 @@ BackgroundSchedulePool::BackgroundSchedulePool(size_t size_, CurrentMetrics::Met
     catch (...)
     {
         LOG_FATAL(
-            &Poco::Logger::get("BackgroundSchedulePool/" + thread_name),
+            getLogger("BackgroundSchedulePool/" + thread_name),
             "Couldn't get {} threads from global thread pool: {}",
             size_,
             getCurrentExceptionCode() == DB::ErrorCodes::CANNOT_SCHEDULE_TASK
@@ -192,7 +192,7 @@ void BackgroundSchedulePool::increaseThreadsCount(size_t new_threads_count)
 
     if (new_threads_count < old_threads_count)
     {
-        LOG_WARNING(&Poco::Logger::get("BackgroundSchedulePool/" + thread_name),
+        LOG_WARNING(getLogger("BackgroundSchedulePool/" + thread_name),
             "Tried to increase the number of threads but the new threads count ({}) is not greater than old one ({})", new_threads_count, old_threads_count);
         return;
     }
@@ -219,7 +219,7 @@ BackgroundSchedulePool::~BackgroundSchedulePool()
         tasks_cond_var.notify_all();
         delayed_tasks_cond_var.notify_all();
 
-        LOG_TRACE(&Poco::Logger::get("BackgroundSchedulePool/" + thread_name), "Waiting for threads to finish.");
+        LOG_TRACE(getLogger("BackgroundSchedulePool/" + thread_name), "Waiting for threads to finish.");
         delayed_thread->join();
 
         for (auto & thread : threads)
diff --git a/src/Core/BaseSettings.cpp b/src/Core/BaseSettings.cpp
index 72a8070e6529..a7e1ab99af7e 100644
--- a/src/Core/BaseSettings.cpp
+++ b/src/Core/BaseSettings.cpp
@@ -47,8 +47,7 @@ void BaseSettingsHelpers::throwSettingNotFound(std::string_view name)
 
 void BaseSettingsHelpers::warningSettingNotFound(std::string_view name)
 {
-    static auto * log = &Poco::Logger::get("Settings");
-    LOG_WARNING(log, "Unknown setting {}, skipping", name);
+    LOG_WARNING(getLogger("Settings"), "Unknown setting {}, skipping", name);
 }
 
 }
diff --git a/src/Core/MySQL/Authentication.cpp b/src/Core/MySQL/Authentication.cpp
index 2c10bd887228..ac6ed70dbb52 100644
--- a/src/Core/MySQL/Authentication.cpp
+++ b/src/Core/MySQL/Authentication.cpp
@@ -102,7 +102,7 @@ void Native41::authenticate(
 
 #if USE_SSL
 
-Sha256Password::Sha256Password(RSA & public_key_, RSA & private_key_, Poco::Logger * log_)
+Sha256Password::Sha256Password(RSA & public_key_, RSA & private_key_, LoggerPtr log_)
     : public_key(public_key_), private_key(private_key_), log(log_)
 {
     /** Native authentication sent 20 bytes + '\0' character = 21 bytes.
diff --git a/src/Core/MySQL/Authentication.h b/src/Core/MySQL/Authentication.h
index ee6aaac02bcb..3179fa20f593 100644
--- a/src/Core/MySQL/Authentication.h
+++ b/src/Core/MySQL/Authentication.h
@@ -61,7 +61,7 @@ class Native41 : public IPlugin
 class Sha256Password : public IPlugin
 {
 public:
-    Sha256Password(RSA & public_key_, RSA & private_key_, Poco::Logger * log_);
+    Sha256Password(RSA & public_key_, RSA & private_key_, LoggerPtr log_);
 
     String getName() override { return "sha256_password"; }
 
@@ -74,7 +74,7 @@ class Sha256Password : public IPlugin
 private:
     RSA & public_key;
     RSA & private_key;
-    Poco::Logger * log;
+    LoggerPtr log;
     String scramble;
 };
 #endif
diff --git a/src/Core/PostgreSQL/Connection.cpp b/src/Core/PostgreSQL/Connection.cpp
index 5a589a80d021..eea24dd69407 100644
--- a/src/Core/PostgreSQL/Connection.cpp
+++ b/src/Core/PostgreSQL/Connection.cpp
@@ -9,7 +9,7 @@ namespace postgres
 
 Connection::Connection(const ConnectionInfo & connection_info_, bool replication_, size_t num_tries_)
     : connection_info(connection_info_), replication(replication_), num_tries(num_tries_)
-    , log(&Poco::Logger::get("PostgreSQLReplicaConnection"))
+    , log(getLogger("PostgreSQLReplicaConnection"))
 {
     if (replication)
         connection_info = {fmt::format("{} replication=database", connection_info.connection_string), connection_info.host_port};
@@ -65,7 +65,7 @@ void Connection::updateConnection()
     if (replication)
         connection->set_variable("default_transaction_isolation", "'repeatable read'");
 
-    LOG_DEBUG(&Poco::Logger::get("PostgreSQLConnection"), "New connection to {}", connection_info.host_port);
+    LOG_DEBUG(getLogger("PostgreSQLConnection"), "New connection to {}", connection_info.host_port);
 }
 
 void Connection::connect()
diff --git a/src/Core/PostgreSQL/Connection.h b/src/Core/PostgreSQL/Connection.h
index efc10b6ed20e..5e0aa0983d59 100644
--- a/src/Core/PostgreSQL/Connection.h
+++ b/src/Core/PostgreSQL/Connection.h
@@ -6,6 +6,7 @@
 
 #include <pqxx/pqxx>
 #include <Core/Types.h>
+#include <Common/Logger.h>
 #include <boost/noncopyable.hpp>
 
 /** Methods to work with PostgreSQL connection object.
@@ -61,7 +62,7 @@ class Connection : private boost::noncopyable
     bool replication;
     size_t num_tries;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 using ConnectionPtr = std::unique_ptr<Connection>;
diff --git a/src/Core/PostgreSQL/PoolWithFailover.cpp b/src/Core/PostgreSQL/PoolWithFailover.cpp
index 3655681c5158..a034c50094d4 100644
--- a/src/Core/PostgreSQL/PoolWithFailover.cpp
+++ b/src/Core/PostgreSQL/PoolWithFailover.cpp
@@ -32,7 +32,7 @@ PoolWithFailover::PoolWithFailover(
     , max_tries(max_tries_)
     , auto_close_connection(auto_close_connection_)
 {
-    LOG_TRACE(&Poco::Logger::get("PostgreSQLConnectionPool"), "PostgreSQL connection pool size: {}, connection wait timeout: {}, max failover tries: {}",
+    LOG_TRACE(getLogger("PostgreSQLConnectionPool"), "PostgreSQL connection pool size: {}, connection wait timeout: {}, max failover tries: {}",
               pool_size, pool_wait_timeout, max_tries_);
 
     for (const auto & [priority, configurations] : configurations_by_priority)
@@ -56,13 +56,13 @@ PoolWithFailover::PoolWithFailover(
     , max_tries(max_tries_)
     , auto_close_connection(auto_close_connection_)
 {
-    LOG_TRACE(&Poco::Logger::get("PostgreSQLConnectionPool"), "PostgreSQL connection pool size: {}, connection wait timeout: {}, max failover tries: {}",
+    LOG_TRACE(getLogger("PostgreSQLConnectionPool"), "PostgreSQL connection pool size: {}, connection wait timeout: {}, max failover tries: {}",
               pool_size, pool_wait_timeout, max_tries_);
 
     /// Replicas have the same priority, but traversed replicas are moved to the end of the queue.
     for (const auto & [host, port] : configuration.addresses)
     {
-        LOG_DEBUG(&Poco::Logger::get("PostgreSQLPoolWithFailover"), "Adding address host: {}, port: {} to connection pool", host, port);
+        LOG_DEBUG(getLogger("PostgreSQLPoolWithFailover"), "Adding address host: {}, port: {} to connection pool", host, port);
         auto connection_string = formatConnectionString(configuration.database, host, port, configuration.username, configuration.password);
         replicas_with_priority[0].emplace_back(connection_string, pool_size);
     }
diff --git a/src/Core/PostgreSQL/PoolWithFailover.h b/src/Core/PostgreSQL/PoolWithFailover.h
index bf3782afba40..3c538fc3dea8 100644
--- a/src/Core/PostgreSQL/PoolWithFailover.h
+++ b/src/Core/PostgreSQL/PoolWithFailover.h
@@ -62,7 +62,7 @@ using RemoteDescription = std::vector<std::pair<String, uint16_t>>;
     size_t max_tries;
     bool auto_close_connection;
     std::mutex mutex;
-    Poco::Logger * log = &Poco::Logger::get("PostgreSQLConnectionPool");
+    LoggerPtr log = getLogger("PostgreSQLConnectionPool");
 };
 
 using PoolWithFailoverPtr = std::shared_ptr<PoolWithFailover>;
diff --git a/src/Core/PostgreSQLProtocol.h b/src/Core/PostgreSQLProtocol.h
index b0d7646a5f73..7630fbb0b230 100644
--- a/src/Core/PostgreSQLProtocol.h
+++ b/src/Core/PostgreSQLProtocol.h
@@ -872,7 +872,7 @@ class CleartextPasswordAuth : public AuthenticationMethod
 class AuthenticationManager
 {
 private:
-    Poco::Logger * log = &Poco::Logger::get("AuthenticationManager");
+    LoggerPtr log = getLogger("AuthenticationManager");
     std::unordered_map<AuthenticationType, std::shared_ptr<AuthenticationMethod>> type_to_method = {};
 
 public:
diff --git a/src/Core/ServerUUID.h b/src/Core/ServerUUID.h
index 36bbf0e63153..b5ea17426cb2 100644
--- a/src/Core/ServerUUID.h
+++ b/src/Core/ServerUUID.h
@@ -1,12 +1,10 @@
 #pragma once
+
 #include <Core/UUID.h>
+#include <Common/Logger.h>
 #include <filesystem>
 
 namespace fs = std::filesystem;
-namespace Poco
-{
-    class Logger;
-}
 
 namespace DB
 {
diff --git a/src/Core/SettingsQuirks.cpp b/src/Core/SettingsQuirks.cpp
index 1a79c23d955a..24dcd43a09cd 100644
--- a/src/Core/SettingsQuirks.cpp
+++ b/src/Core/SettingsQuirks.cpp
@@ -17,7 +17,7 @@ namespace
 ///
 ///   [1]: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=339ddb53d373
 ///   [2]: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=0c54a6a44bf3
-bool nestedEpollWorks(Poco::Logger * log)
+bool nestedEpollWorks(LoggerPtr log)
 {
     if (Poco::Environment::os() != POCO_OS_LINUX)
         return true;
@@ -48,7 +48,7 @@ namespace DB
 {
 
 /// Update some settings defaults to avoid some known issues.
-void applySettingsQuirks(Settings & settings, Poco::Logger * log)
+void applySettingsQuirks(Settings & settings, LoggerPtr log)
 {
     if (!nestedEpollWorks(log))
     {
diff --git a/src/Core/SettingsQuirks.h b/src/Core/SettingsQuirks.h
index 38def8eebf2b..f6b2a4e33fae 100644
--- a/src/Core/SettingsQuirks.h
+++ b/src/Core/SettingsQuirks.h
@@ -1,9 +1,6 @@
 #pragma once
 
-namespace Poco
-{
-class Logger;
-}
+#include <Common/Logger.h>
 
 namespace DB
 {
@@ -11,6 +8,6 @@ namespace DB
 struct Settings;
 
 /// Update some settings defaults to avoid some known issues.
-void applySettingsQuirks(Settings & settings, Poco::Logger * log = nullptr);
+void applySettingsQuirks(Settings & settings, LoggerPtr log = nullptr);
 
 }
diff --git a/src/Core/SortDescription.cpp b/src/Core/SortDescription.cpp
index 9ba7df8ef24a..9edc79a1ff12 100644
--- a/src/Core/SortDescription.cpp
+++ b/src/Core/SortDescription.cpp
@@ -108,10 +108,9 @@ static std::string getSortDescriptionDump(const SortDescription & description, c
     return buffer.str();
 }
 
-static Poco::Logger * getLogger()
+static LoggerPtr getLogger()
 {
-    static Poco::Logger & logger = Poco::Logger::get("SortDescription");
-    return &logger;
+    return ::getLogger("SortDescription");
 }
 
 void compileSortDescriptionIfNeeded(SortDescription & description, const DataTypes & sort_description_types, bool increase_compile_attempts)
diff --git a/src/Daemon/BaseDaemon.cpp b/src/Daemon/BaseDaemon.cpp
index b7685159f984..289a41bb75e2 100644
--- a/src/Daemon/BaseDaemon.cpp
+++ b/src/Daemon/BaseDaemon.cpp
@@ -210,7 +210,7 @@ class SignalListener : public Poco::Runnable
     static constexpr int SanitizerTrap = -3;
 
     explicit SignalListener(BaseDaemon & daemon_)
-        : log(&Poco::Logger::get("BaseDaemon"))
+        : log(getLogger("BaseDaemon"))
         , daemon(daemon_)
     {
     }
@@ -295,7 +295,7 @@ class SignalListener : public Poco::Runnable
     }
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     BaseDaemon & daemon;
 
     void onTerminate(std::string_view message, UInt32 thread_num) const
diff --git a/src/Daemon/SentryWriter.cpp b/src/Daemon/SentryWriter.cpp
index 2050d5038795..ebfd18abeee8 100644
--- a/src/Daemon/SentryWriter.cpp
+++ b/src/Daemon/SentryWriter.cpp
@@ -68,7 +68,7 @@ void SentryWriter::initialize(Poco::Util::LayeredConfiguration & config)
 {
     bool enabled = false;
     bool debug = config.getBool("send_crash_reports.debug", false);
-    auto * logger = &Poco::Logger::get("SentryWriter");
+    auto logger = getLogger("SentryWriter");
 
     if (config.getBool("send_crash_reports.enabled", false))
     {
@@ -140,7 +140,7 @@ void SentryWriter::shutdown()
 
 void SentryWriter::onFault(int sig, const std::string & error_message, const StackTrace & stack_trace)
 {
-    auto * logger = &Poco::Logger::get("SentryWriter");
+    auto logger = getLogger("SentryWriter");
     if (initialized)
     {
         sentry_value_t event = sentry_value_new_message_event(SENTRY_LEVEL_FATAL, "fault", error_message.c_str());
diff --git a/src/Databases/DatabaseDictionary.cpp b/src/Databases/DatabaseDictionary.cpp
index e2e0d52cd88b..9a65c7a46ef8 100644
--- a/src/Databases/DatabaseDictionary.cpp
+++ b/src/Databases/DatabaseDictionary.cpp
@@ -51,7 +51,7 @@ namespace
 
 DatabaseDictionary::DatabaseDictionary(const String & name_, ContextPtr context_)
     : IDatabase(name_), WithContext(context_->getGlobalContext())
-    , log(&Poco::Logger::get("DatabaseDictionary(" + database_name + ")"))
+    , log(getLogger("DatabaseDictionary(" + database_name + ")"))
 {
 }
 
diff --git a/src/Databases/DatabaseDictionary.h b/src/Databases/DatabaseDictionary.h
index 425d048aa65b..469801d183e6 100644
--- a/src/Databases/DatabaseDictionary.h
+++ b/src/Databases/DatabaseDictionary.h
@@ -48,7 +48,7 @@ class DatabaseDictionary final : public IDatabase, WithContext
     ASTPtr getCreateTableQueryImpl(const String & table_name, ContextPtr context, bool throw_on_error) const override;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
 
     Tables listTables(const FilterByNameFunction & filter_by_name) const;
 };
diff --git a/src/Databases/DatabaseFilesystem.cpp b/src/Databases/DatabaseFilesystem.cpp
index 5564f1d07cf2..55ae60469edc 100644
--- a/src/Databases/DatabaseFilesystem.cpp
+++ b/src/Databases/DatabaseFilesystem.cpp
@@ -32,7 +32,7 @@ namespace ErrorCodes
 }
 
 DatabaseFilesystem::DatabaseFilesystem(const String & name_, const String & path_, ContextPtr context_)
-    : IDatabase(name_), WithContext(context_->getGlobalContext()), path(path_), log(&Poco::Logger::get("DatabaseFileSystem(" + name_ + ")"))
+    : IDatabase(name_), WithContext(context_->getGlobalContext()), path(path_), log(getLogger("DatabaseFileSystem(" + name_ + ")"))
 {
     bool is_local = context_->getApplicationType() == Context::ApplicationType::LOCAL;
     fs::path user_files_path = is_local ? "" : fs::canonical(getContext()->getUserFilesPath());
diff --git a/src/Databases/DatabaseFilesystem.h b/src/Databases/DatabaseFilesystem.h
index b72891b9a5ca..3338aa28c21a 100644
--- a/src/Databases/DatabaseFilesystem.h
+++ b/src/Databases/DatabaseFilesystem.h
@@ -61,7 +61,7 @@ class DatabaseFilesystem : public IDatabase, protected WithContext
 private:
     String path;
     mutable Tables loaded_tables TSA_GUARDED_BY(mutex);
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Databases/DatabaseHDFS.cpp b/src/Databases/DatabaseHDFS.cpp
index 9d0395e42174..3a1e6b16ccf8 100644
--- a/src/Databases/DatabaseHDFS.cpp
+++ b/src/Databases/DatabaseHDFS.cpp
@@ -45,7 +45,7 @@ DatabaseHDFS::DatabaseHDFS(const String & name_, const String & source_url, Cont
     : IDatabase(name_)
     , WithContext(context_->getGlobalContext())
     , source(source_url)
-    , log(&Poco::Logger::get("DatabaseHDFS(" + name_ + ")"))
+    , log(getLogger("DatabaseHDFS(" + name_ + ")"))
 {
     if (!source.empty())
     {
diff --git a/src/Databases/DatabaseHDFS.h b/src/Databases/DatabaseHDFS.h
index 957b2080135c..b586a912e163 100644
--- a/src/Databases/DatabaseHDFS.h
+++ b/src/Databases/DatabaseHDFS.h
@@ -60,7 +60,7 @@ class DatabaseHDFS : public IDatabase, protected WithContext
     const String source;
 
     mutable Tables loaded_tables TSA_GUARDED_BY(mutex);
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Databases/DatabaseOnDisk.cpp b/src/Databases/DatabaseOnDisk.cpp
index 12b0dc077990..67ecd7be66a4 100644
--- a/src/Databases/DatabaseOnDisk.cpp
+++ b/src/Databases/DatabaseOnDisk.cpp
@@ -660,7 +660,7 @@ void DatabaseOnDisk::iterateMetadataFiles(ContextPtr local_context, const Iterat
 }
 
 ASTPtr DatabaseOnDisk::parseQueryFromMetadata(
-    Poco::Logger * logger,
+    LoggerPtr logger,
     ContextPtr local_context,
     const String & metadata_file_path,
     bool throw_on_error /*= true*/,
diff --git a/src/Databases/DatabaseOnDisk.h b/src/Databases/DatabaseOnDisk.h
index 59c2c27068e6..b20b754b727b 100644
--- a/src/Databases/DatabaseOnDisk.h
+++ b/src/Databases/DatabaseOnDisk.h
@@ -68,7 +68,7 @@ class DatabaseOnDisk : public DatabaseWithOwnTablesBase
     String getTableDataPath(const ASTCreateQuery & query) const override { return getTableDataPath(query.getTable()); }
     String getMetadataPath() const override { return metadata_path; }
 
-    static ASTPtr parseQueryFromMetadata(Poco::Logger * log, ContextPtr context, const String & metadata_file_path, bool throw_on_error = true, bool remove_empty = false);
+    static ASTPtr parseQueryFromMetadata(LoggerPtr log, ContextPtr context, const String & metadata_file_path, bool throw_on_error = true, bool remove_empty = false);
 
     /// will throw when the table we want to attach already exists (in active / detached / detached permanently form)
     void checkMetadataFilenameAvailability(const String & to_table_name) const override;
diff --git a/src/Databases/DatabaseS3.cpp b/src/Databases/DatabaseS3.cpp
index 1721b0e9e97b..d2ca5a05ea4b 100644
--- a/src/Databases/DatabaseS3.cpp
+++ b/src/Databases/DatabaseS3.cpp
@@ -49,7 +49,7 @@ DatabaseS3::DatabaseS3(const String & name_, const Configuration& config_, Conte
     : IDatabase(name_)
     , WithContext(context_->getGlobalContext())
     , config(config_)
-    , log(&Poco::Logger::get("DatabaseS3(" + name_ + ")"))
+    , log(getLogger("DatabaseS3(" + name_ + ")"))
 {
 }
 
diff --git a/src/Databases/DatabaseS3.h b/src/Databases/DatabaseS3.h
index 8297ae4e02d6..5e7375dbd58e 100644
--- a/src/Databases/DatabaseS3.h
+++ b/src/Databases/DatabaseS3.h
@@ -73,7 +73,7 @@ class DatabaseS3 : public IDatabase, protected WithContext
     const Configuration config;
 
     mutable Tables loaded_tables TSA_GUARDED_BY(mutex);
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Databases/DatabasesCommon.cpp b/src/Databases/DatabasesCommon.cpp
index bda487376213..963cf0064df8 100644
--- a/src/Databases/DatabasesCommon.cpp
+++ b/src/Databases/DatabasesCommon.cpp
@@ -197,7 +197,7 @@ void cleanupObjectDefinitionFromTemporaryFlags(ASTCreateQuery & query)
 
 
 DatabaseWithOwnTablesBase::DatabaseWithOwnTablesBase(const String & name_, const String & logger, ContextPtr context_)
-        : IDatabase(name_), WithContext(context_->getGlobalContext()), log(&Poco::Logger::get(logger))
+        : IDatabase(name_), WithContext(context_->getGlobalContext()), log(getLogger(logger))
 {
 }
 
diff --git a/src/Databases/DatabasesCommon.h b/src/Databases/DatabasesCommon.h
index fc67596d3de8..4e9d967c11a9 100644
--- a/src/Databases/DatabasesCommon.h
+++ b/src/Databases/DatabasesCommon.h
@@ -45,7 +45,7 @@ class DatabaseWithOwnTablesBase : public IDatabase, protected WithContext
 
 protected:
     Tables tables TSA_GUARDED_BY(mutex);
-    Poco::Logger * log;
+    LoggerPtr log;
 
     DatabaseWithOwnTablesBase(const String & name_, const String & logger, ContextPtr context);
 
diff --git a/src/Databases/DatabasesOverlay.cpp b/src/Databases/DatabasesOverlay.cpp
index b44a97980725..8cea34416989 100644
--- a/src/Databases/DatabasesOverlay.cpp
+++ b/src/Databases/DatabasesOverlay.cpp
@@ -17,7 +17,7 @@ namespace ErrorCodes
 }
 
 DatabasesOverlay::DatabasesOverlay(const String & name_, ContextPtr context_)
-    : IDatabase(name_), WithContext(context_->getGlobalContext()), log(&Poco::Logger::get("DatabaseOverlay(" + name_ + ")"))
+    : IDatabase(name_), WithContext(context_->getGlobalContext()), log(getLogger("DatabaseOverlay(" + name_ + ")"))
 {
 }
 
diff --git a/src/Databases/DatabasesOverlay.h b/src/Databases/DatabasesOverlay.h
index 0f31bbd6a47f..b58df506f709 100644
--- a/src/Databases/DatabasesOverlay.h
+++ b/src/Databases/DatabasesOverlay.h
@@ -60,7 +60,7 @@ class DatabasesOverlay : public IDatabase, protected WithContext
 
 protected:
     std::vector<DatabasePtr> databases;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp b/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp
index 5834fb96dc6a..2656835f912a 100644
--- a/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp
+++ b/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp
@@ -116,7 +116,7 @@ static BlockIO tryToExecuteQuery(const String & query_to_execute, ContextMutable
     catch (...)
     {
         tryLogCurrentException(
-            &Poco::Logger::get("MaterializedMySQLSyncThread(" + database + ")"),
+            getLogger("MaterializedMySQLSyncThread(" + database + ")"),
             "Query " + query_to_execute + " wasn't finished successfully");
         throw;
     }
@@ -255,7 +255,7 @@ MaterializedMySQLSyncThread::MaterializedMySQLSyncThread(
     const MySQLReplication::BinlogClientPtr & binlog_client_,
     MaterializedMySQLSettings * settings_)
     : WithContext(context_->getGlobalContext())
-    , log(&Poco::Logger::get("MaterializedMySQLSyncThread"))
+    , log(getLogger("MaterializedMySQLSyncThread"))
     , database_name(database_name_)
     , mysql_database_name(mysql_database_name_)
     , pool(std::move(pool_)) /// NOLINT
@@ -504,7 +504,7 @@ static inline void dumpDataForTables(
             StreamSettings mysql_input_stream_settings(context->getSettingsRef());
             String mysql_select_all_query = "SELECT " + rewriteMysqlQueryColumn(connection, mysql_database_name, table_name, context->getSettingsRef()) + " FROM "
                     + backQuoteIfNeed(mysql_database_name) + "." + backQuoteIfNeed(table_name);
-            LOG_INFO(&Poco::Logger::get("MaterializedMySQLSyncThread(" + database_name + ")"), "mysql_select_all_query is {}", mysql_select_all_query);
+            LOG_INFO(getLogger("MaterializedMySQLSyncThread(" + database_name + ")"), "mysql_select_all_query is {}", mysql_select_all_query);
             auto input = std::make_unique<MySQLSource>(connection, mysql_select_all_query, pipeline.getHeader(), mysql_input_stream_settings);
             auto counting = std::make_shared<CountingTransform>(pipeline.getHeader());
             Pipe pipe(std::move(input));
@@ -516,7 +516,7 @@ static inline void dumpDataForTables(
             executor.execute();
 
             const Progress & progress = counting->getProgress();
-            LOG_INFO(&Poco::Logger::get("MaterializedMySQLSyncThread(" + database_name + ")"),
+            LOG_INFO(getLogger("MaterializedMySQLSyncThread(" + database_name + ")"),
                 "Materialize MySQL step 1: dump {}, {} rows, {} in {} sec., {} rows/sec., {}/sec."
                 , table_name, formatReadableQuantity(progress.written_rows), formatReadableSizeWithBinarySuffix(progress.written_bytes)
                 , watch.elapsedSeconds(), formatReadableQuantity(static_cast<size_t>(progress.written_rows / watch.elapsedSeconds()))
diff --git a/src/Databases/MySQL/MaterializedMySQLSyncThread.h b/src/Databases/MySQL/MaterializedMySQLSyncThread.h
index 004a4d67d324..03e558bfd68d 100644
--- a/src/Databases/MySQL/MaterializedMySQLSyncThread.h
+++ b/src/Databases/MySQL/MaterializedMySQLSyncThread.h
@@ -56,7 +56,7 @@ class MaterializedMySQLSyncThread : WithContext
     void assertMySQLAvailable();
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
 
     String database_name;
     String mysql_database_name;
diff --git a/src/Databases/MySQL/MySQLBinlogClient.cpp b/src/Databases/MySQL/MySQLBinlogClient.cpp
index e7d707f76ce4..94e01673e88f 100644
--- a/src/Databases/MySQL/MySQLBinlogClient.cpp
+++ b/src/Databases/MySQL/MySQLBinlogClient.cpp
@@ -17,7 +17,7 @@ BinlogClient::BinlogClient(const BinlogFactoryPtr & factory_,
     , binlog_client_name(name)
     , max_bytes_in_buffer(max_bytes_in_buffer_)
     , max_flush_ms(max_flush_ms_)
-    , logger(&Poco::Logger::get("BinlogClient(" + name + ")"))
+    , logger(getLogger("BinlogClient(" + name + ")"))
 {
 }
 
diff --git a/src/Databases/MySQL/MySQLBinlogClient.h b/src/Databases/MySQL/MySQLBinlogClient.h
index b76934d08cf6..a45b885d87b3 100644
--- a/src/Databases/MySQL/MySQLBinlogClient.h
+++ b/src/Databases/MySQL/MySQLBinlogClient.h
@@ -48,7 +48,7 @@ class BinlogClient
     std::vector<BinlogEventsDispatcherPtr> dispatchers;
     String binlog_checksum;
     mutable std::mutex mutex;
-    Poco::Logger * logger = nullptr;
+    LoggerPtr logger = nullptr;
     int dispatchers_count = 0;
 };
 
diff --git a/src/Databases/MySQL/MySQLBinlogEventsDispatcher.cpp b/src/Databases/MySQL/MySQLBinlogEventsDispatcher.cpp
index 4af307f9c0f9..d027d4b21921 100644
--- a/src/Databases/MySQL/MySQLBinlogEventsDispatcher.cpp
+++ b/src/Databases/MySQL/MySQLBinlogEventsDispatcher.cpp
@@ -19,7 +19,7 @@ class BinlogFromDispatcher : public IBinlog
         , mysql_database_names(mysql_database_names_)
         , max_bytes(max_bytes_)
         , max_waiting_ms(max_waiting_ms_)
-        , logger(&Poco::Logger::get("BinlogFromDispatcher(" + name + ")"))
+        , logger(getLogger("BinlogFromDispatcher(" + name + ")"))
     {
     }
 
@@ -65,7 +65,7 @@ class BinlogFromDispatcher : public IBinlog
 
     std::condition_variable cv;
     bool is_cancelled = false;
-    Poco::Logger * logger = nullptr;
+    LoggerPtr logger = nullptr;
     std::exception_ptr exception;
 };
 
@@ -84,7 +84,7 @@ BinlogEventsDispatcher::BinlogEventsDispatcher(const String & logger_name_, size
     : logger_name(logger_name_)
     , max_bytes_in_buffer(max_bytes_in_buffer_)
     , max_flush_ms(max_flush_ms_)
-    , logger(&Poco::Logger::get("BinlogEventsDispatcher(" + logger_name + ")"))
+    , logger(getLogger("BinlogEventsDispatcher(" + logger_name + ")"))
     , dispatching_thread(std::make_unique<ThreadFromGlobalPool>([this]() { dispatchEvents(); }))
 {
 }
diff --git a/src/Databases/MySQL/MySQLBinlogEventsDispatcher.h b/src/Databases/MySQL/MySQLBinlogEventsDispatcher.h
index 433796970150..324deba3617d 100644
--- a/src/Databases/MySQL/MySQLBinlogEventsDispatcher.h
+++ b/src/Databases/MySQL/MySQLBinlogEventsDispatcher.h
@@ -110,7 +110,7 @@ class BinlogEventsDispatcher final : boost::noncopyable
     const String logger_name;
     const size_t max_bytes_in_buffer = 0;
     const UInt64 max_flush_ms = 0;
-    Poco::Logger * logger = nullptr;
+    LoggerPtr logger = nullptr;
 
     BinlogPtr binlog_read_from;
 
diff --git a/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp b/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp
index 1fe5c078581a..b07b203f7862 100644
--- a/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp
+++ b/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp
@@ -57,7 +57,7 @@ DatabasePostgreSQL::DatabasePostgreSQL(
     , configuration(configuration_)
     , pool(std::move(pool_))
     , cache_tables(cache_tables_)
-    , log(&Poco::Logger::get("DatabasePostgreSQL(" + dbname_ + ")"))
+    , log(getLogger("DatabasePostgreSQL(" + dbname_ + ")"))
 {
     fs::create_directories(metadata_path);
     cleaner_task = getContext()->getSchedulePool().createTask("PostgreSQLCleanerTask", [this]{ removeOutdatedTables(); });
@@ -531,7 +531,7 @@ void registerDatabasePostgreSQL(DatabaseFactory & factory)
                 else
                 {
                     use_table_cache = safeGetLiteralValue<UInt8>(engine_args[4], engine_name);
-                    LOG_WARNING(&Poco::Logger::get("DatabaseFactory"), "A deprecated syntax of PostgreSQL database engine is used");
+                    LOG_WARNING(getLogger("DatabaseFactory"), "A deprecated syntax of PostgreSQL database engine is used");
                     is_deprecated_syntax = true;
                 }
             }
diff --git a/src/Databases/PostgreSQL/DatabasePostgreSQL.h b/src/Databases/PostgreSQL/DatabasePostgreSQL.h
index d731e06649be..3ba7333c98ec 100644
--- a/src/Databases/PostgreSQL/DatabasePostgreSQL.h
+++ b/src/Databases/PostgreSQL/DatabasePostgreSQL.h
@@ -73,7 +73,7 @@ class DatabasePostgreSQL final : public IDatabase, WithContext
     mutable Tables cached_tables;
     std::unordered_set<std::string> detached_or_dropped;
     BackgroundSchedulePool::TaskHolder cleaner_task;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     String getTableNameForLogs(const String & table_name) const;
 
diff --git a/src/Databases/SQLite/DatabaseSQLite.cpp b/src/Databases/SQLite/DatabaseSQLite.cpp
index 605a354bd7eb..b3d5288cdf77 100644
--- a/src/Databases/SQLite/DatabaseSQLite.cpp
+++ b/src/Databases/SQLite/DatabaseSQLite.cpp
@@ -33,7 +33,7 @@ DatabaseSQLite::DatabaseSQLite(
     , WithContext(context_->getGlobalContext())
     , database_engine_define(database_engine_define_->clone())
     , database_path(database_path_)
-    , log(&Poco::Logger::get("DatabaseSQLite"))
+    , log(getLogger("DatabaseSQLite"))
 {
     sqlite_db = openSQLiteDB(database_path_, context_, !is_attach_);
 }
diff --git a/src/Databases/SQLite/DatabaseSQLite.h b/src/Databases/SQLite/DatabaseSQLite.h
index a89fbc32c3d7..e5e93bbc8ce3 100644
--- a/src/Databases/SQLite/DatabaseSQLite.h
+++ b/src/Databases/SQLite/DatabaseSQLite.h
@@ -50,7 +50,7 @@ class DatabaseSQLite final : public IDatabase, WithContext
 
     mutable SQLitePtr sqlite_db;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     bool checkSQLiteTable(const String & table_name) const;
 
diff --git a/src/Databases/SQLite/SQLiteUtils.cpp b/src/Databases/SQLite/SQLiteUtils.cpp
index 19b8662707b1..eeea04476d3d 100644
--- a/src/Databases/SQLite/SQLiteUtils.cpp
+++ b/src/Databases/SQLite/SQLiteUtils.cpp
@@ -21,7 +21,7 @@ void processSQLiteError(const String & message, bool throw_on_error)
     if (throw_on_error)
         throw Exception::createDeprecated(message, ErrorCodes::PATH_ACCESS_DENIED);
     else
-        LOG_ERROR(&Poco::Logger::get("SQLiteEngine"), fmt::runtime(message));
+        LOG_ERROR(getLogger("SQLiteEngine"), fmt::runtime(message));
 }
 
 String validateSQLiteDatabasePath(const String & path, const String & user_files_path, bool need_check, bool throw_on_error)
@@ -54,7 +54,7 @@ SQLitePtr openSQLiteDB(const String & path, ContextPtr context, bool throw_on_er
         return nullptr;
 
     if (!fs::exists(database_path))
-        LOG_DEBUG(&Poco::Logger::get("SQLite"), "SQLite database path {} does not exist, will create an empty SQLite database", database_path);
+        LOG_DEBUG(getLogger("SQLite"), "SQLite database path {} does not exist, will create an empty SQLite database", database_path);
 
     sqlite3 * tmp_sqlite_db = nullptr;
     int status;
diff --git a/src/Databases/TablesDependencyGraph.cpp b/src/Databases/TablesDependencyGraph.cpp
index 16404c6870f5..6b9e202d9005 100644
--- a/src/Databases/TablesDependencyGraph.cpp
+++ b/src/Databases/TablesDependencyGraph.cpp
@@ -720,10 +720,10 @@ void TablesDependencyGraph::log() const
 }
 
 
-Poco::Logger * TablesDependencyGraph::getLogger() const
+LoggerPtr TablesDependencyGraph::getLogger() const
 {
     if (!logger)
-        logger = &Poco::Logger::get(name_for_logging);
+        logger = ::getLogger(name_for_logging);
     return logger;
 }
 
diff --git a/src/Databases/TablesDependencyGraph.h b/src/Databases/TablesDependencyGraph.h
index 50be3bbf969b..f0553cef3216 100644
--- a/src/Databases/TablesDependencyGraph.h
+++ b/src/Databases/TablesDependencyGraph.h
@@ -163,7 +163,7 @@ class TablesDependencyGraph
     mutable bool levels_calculated = false;
 
     const String name_for_logging;
-    mutable Poco::Logger * logger = nullptr;
+    mutable LoggerPtr logger = nullptr;
 
     Node * findNode(const StorageID & table_id) const;
     Node * addOrUpdateNode(const StorageID & table_id);
@@ -175,7 +175,7 @@ class TablesDependencyGraph
     void setNeedRecalculateLevels() const;
     const NodesSortedByLevel & getNodesSortedByLevel() const;
 
-    Poco::Logger * getLogger() const;
+    LoggerPtr getLogger() const;
 };
 
 }
diff --git a/src/Databases/TablesLoader.cpp b/src/Databases/TablesLoader.cpp
index f1b5c4377fef..48745ff91c2b 100644
--- a/src/Databases/TablesLoader.cpp
+++ b/src/Databases/TablesLoader.cpp
@@ -29,7 +29,7 @@ TablesLoader::TablesLoader(ContextMutablePtr global_context_, Databases database
     , async_loader(global_context->getAsyncLoader())
 {
     metadata.default_database = global_context->getCurrentDatabase();
-    log = &Poco::Logger::get("TablesLoader");
+    log = getLogger("TablesLoader");
 }
 
 LoadTaskPtrs TablesLoader::loadTablesAsync(LoadJobSet load_after)
diff --git a/src/Databases/TablesLoader.h b/src/Databases/TablesLoader.h
index 038aa35895f9..26b5777f1a97 100644
--- a/src/Databases/TablesLoader.h
+++ b/src/Databases/TablesLoader.h
@@ -73,7 +73,7 @@ class TablesLoader
     TablesDependencyGraph referential_dependencies;
     TablesDependencyGraph loading_dependencies;
     TablesDependencyGraph all_loading_dependencies;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::atomic<size_t> tables_processed{0};
     AtomicStopwatch stopwatch;
 
diff --git a/src/Dictionaries/CacheDictionary.cpp b/src/Dictionaries/CacheDictionary.cpp
index b40a60e09153..000f0ef5b4c6 100644
--- a/src/Dictionaries/CacheDictionary.cpp
+++ b/src/Dictionaries/CacheDictionary.cpp
@@ -63,7 +63,7 @@ CacheDictionary<dictionary_key_type>::CacheDictionary(
             update(unit_to_update);
         })
     , configuration(configuration_)
-    , log(&Poco::Logger::get("ExternalDictionaries"))
+    , log(getLogger("ExternalDictionaries"))
     , rnd_engine(randomSeed())
 {
     if (!source_ptr->supportsSelectiveLoad())
diff --git a/src/Dictionaries/CacheDictionary.h b/src/Dictionaries/CacheDictionary.h
index 66efb4a85a51..aae86a83f12a 100644
--- a/src/Dictionaries/CacheDictionary.h
+++ b/src/Dictionaries/CacheDictionary.h
@@ -202,7 +202,7 @@ class CacheDictionary final : public IDictionary
 
     const CacheDictionaryConfiguration configuration;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     mutable pcg64 rnd_engine;
 
diff --git a/src/Dictionaries/CassandraDictionarySource.cpp b/src/Dictionaries/CassandraDictionarySource.cpp
index e0cf2483b3d5..b3bf288ef5af 100644
--- a/src/Dictionaries/CassandraDictionarySource.cpp
+++ b/src/Dictionaries/CassandraDictionarySource.cpp
@@ -105,7 +105,7 @@ CassandraDictionarySource::CassandraDictionarySource(
     const DictionaryStructure & dict_struct_,
     const Configuration & configuration_,
     const Block & sample_block_)
-    : log(&Poco::Logger::get("CassandraDictionarySource"))
+    : log(getLogger("CassandraDictionarySource"))
     , dict_struct(dict_struct_)
     , configuration(configuration_)
     , sample_block(sample_block_)
diff --git a/src/Dictionaries/CassandraDictionarySource.h b/src/Dictionaries/CassandraDictionarySource.h
index 2591b33c6388..3700642fc5b5 100644
--- a/src/Dictionaries/CassandraDictionarySource.h
+++ b/src/Dictionaries/CassandraDictionarySource.h
@@ -77,7 +77,7 @@ class CassandraDictionarySource final : public IDictionarySource
     void maybeAllowFiltering(String & query) const;
     CassSessionShared getSession();
 
-    Poco::Logger * log;
+    LoggerPtr log;
     const DictionaryStructure dict_struct;
     const Configuration configuration;
     Block sample_block;
diff --git a/src/Dictionaries/CassandraHelpers.cpp b/src/Dictionaries/CassandraHelpers.cpp
index e93b3fe8d496..4c569d00957a 100644
--- a/src/Dictionaries/CassandraHelpers.cpp
+++ b/src/Dictionaries/CassandraHelpers.cpp
@@ -47,7 +47,7 @@ void setupCassandraDriverLibraryLogging(CassLogLevel level)
 {
     std::call_once(setup_logging_flag, [level]()
     {
-        Poco::Logger * logger = &Poco::Logger::get("CassandraDriverLibrary");
+        Poco::Logger * logger = getRawLogger("CassandraDriverLibrary");
         cass_log_set_level(level);
         if (level != CASS_LOG_DISABLED)
             cass_log_set_callback(cassandraLogCallback, logger);
diff --git a/src/Dictionaries/ClickHouseDictionarySource.h b/src/Dictionaries/ClickHouseDictionarySource.h
index cfb6a0bcd378..3357514eab2b 100644
--- a/src/Dictionaries/ClickHouseDictionarySource.h
+++ b/src/Dictionaries/ClickHouseDictionarySource.h
@@ -85,7 +85,7 @@ class ClickHouseDictionarySource final : public IDictionarySource
     ContextMutablePtr context;
     ConnectionPoolWithFailoverPtr pool;
     std::string load_all_query;
-    Poco::Logger * log = &Poco::Logger::get("ClickHouseDictionarySource");
+    LoggerPtr log = getLogger("ClickHouseDictionarySource");
 
     /// RegExpTreeDictionary is the only dictionary whose structure of attributions differ from the input block.
     /// For now we need to modify sample_block in the ctor of RegExpTreeDictionary.
diff --git a/src/Dictionaries/DictionaryFactory.cpp b/src/Dictionaries/DictionaryFactory.cpp
index f6102d7c6571..a566fb27de40 100644
--- a/src/Dictionaries/DictionaryFactory.cpp
+++ b/src/Dictionaries/DictionaryFactory.cpp
@@ -46,7 +46,7 @@ DictionaryPtr DictionaryFactory::create(
 
     DictionarySourcePtr source_ptr = DictionarySourceFactory::instance().create(
         name, config, config_prefix + ".source", dict_struct, global_context, config.getString(config_prefix + ".database", ""), created_from_ddl);
-    LOG_TRACE(&Poco::Logger::get("DictionaryFactory"), "Created dictionary source '{}' for dictionary '{}'", source_ptr->toString(), name);
+    LOG_TRACE(getLogger("DictionaryFactory"), "Created dictionary source '{}' for dictionary '{}'", source_ptr->toString(), name);
 
     const auto & layout_type = keys.front();
 
diff --git a/src/Dictionaries/DictionarySourceFactory.cpp b/src/Dictionaries/DictionarySourceFactory.cpp
index 5ae4bb5a4397..eedf6967c139 100644
--- a/src/Dictionaries/DictionarySourceFactory.cpp
+++ b/src/Dictionaries/DictionarySourceFactory.cpp
@@ -65,7 +65,7 @@ namespace
 }
 
 
-DictionarySourceFactory::DictionarySourceFactory() : log(&Poco::Logger::get("DictionarySourceFactory"))
+DictionarySourceFactory::DictionarySourceFactory() : log(getLogger("DictionarySourceFactory"))
 {
 }
 
diff --git a/src/Dictionaries/DictionarySourceFactory.h b/src/Dictionaries/DictionarySourceFactory.h
index 4c867db4ea1d..a9007230047c 100644
--- a/src/Dictionaries/DictionarySourceFactory.h
+++ b/src/Dictionaries/DictionarySourceFactory.h
@@ -59,7 +59,7 @@ class DictionarySourceFactory : private boost::noncopyable
     using SourceRegistry = std::unordered_map<std::string, Creator>;
     SourceRegistry registered_sources;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Dictionaries/DirectDictionary.cpp b/src/Dictionaries/DirectDictionary.cpp
index 64c7eb14024f..5bfcb22c23b2 100644
--- a/src/Dictionaries/DirectDictionary.cpp
+++ b/src/Dictionaries/DirectDictionary.cpp
@@ -118,7 +118,7 @@ Columns DirectDictionary<dictionary_key_type>::getColumns(
         block_key_columns.clear();
     }
 
-    LOG_DEBUG(&Poco::Logger::get("DirectDictionary"), "read {} blocks with {} rows from pipeline in {} ms",
+    LOG_DEBUG(getLogger("DirectDictionary"), "read {} blocks with {} rows from pipeline in {} ms",
         block_num, rows_num, watch.elapsedMilliseconds());
 
     Field value_to_insert;
@@ -353,7 +353,7 @@ Pipe DirectDictionary<dictionary_key_type>::getSourcePipe(
             pipe = Pipe(std::make_shared<SourceFromQueryPipeline<PullingPipelineExecutor>>(std::move(pipeline)));
     }
 
-    LOG_DEBUG(&Poco::Logger::get("DirectDictionary"), "building pipeline for loading keys done in {} ms", watch.elapsedMilliseconds());
+    LOG_DEBUG(getLogger("DirectDictionary"), "building pipeline for loading keys done in {} ms", watch.elapsedMilliseconds());
     return pipe;
 }
 
diff --git a/src/Dictionaries/Embedded/RegionsHierarchies.cpp b/src/Dictionaries/Embedded/RegionsHierarchies.cpp
index c3c62bcc83cb..3f1222fff3ff 100644
--- a/src/Dictionaries/Embedded/RegionsHierarchies.cpp
+++ b/src/Dictionaries/Embedded/RegionsHierarchies.cpp
@@ -8,7 +8,7 @@ namespace DB
 
 RegionsHierarchies::RegionsHierarchies(IRegionsHierarchiesDataProviderPtr data_provider)
 {
-    Poco::Logger * log = &Poco::Logger::get("RegionsHierarchies");
+    LoggerPtr log = getLogger("RegionsHierarchies");
 
     LOG_DEBUG(log, "Adding default regions hierarchy");
     data.emplace("", data_provider->getDefaultHierarchySource());
diff --git a/src/Dictionaries/Embedded/RegionsHierarchy.cpp b/src/Dictionaries/Embedded/RegionsHierarchy.cpp
index 23f4c250a23e..a59f6fcd0e70 100644
--- a/src/Dictionaries/Embedded/RegionsHierarchy.cpp
+++ b/src/Dictionaries/Embedded/RegionsHierarchy.cpp
@@ -23,7 +23,7 @@ RegionsHierarchy::RegionsHierarchy(IRegionsHierarchyDataSourcePtr data_source_)
 
 void RegionsHierarchy::reload()
 {
-    Poco::Logger * log = &Poco::Logger::get("RegionsHierarchy");
+    LoggerPtr log = getLogger("RegionsHierarchy");
 
     if (!data_source->isModified())
         return;
diff --git a/src/Dictionaries/Embedded/RegionsNames.cpp b/src/Dictionaries/Embedded/RegionsNames.cpp
index 847dfe99b103..c89bacc7ec91 100644
--- a/src/Dictionaries/Embedded/RegionsNames.cpp
+++ b/src/Dictionaries/Embedded/RegionsNames.cpp
@@ -42,7 +42,7 @@ std::string RegionsNames::dumpSupportedLanguagesNames()
 
 void RegionsNames::reload()
 {
-    Poco::Logger * log = &Poco::Logger::get("RegionsNames");
+    LoggerPtr log = getLogger("RegionsNames");
     LOG_DEBUG(log, "Reloading regions names");
 
     RegionID max_region_id = 0;
diff --git a/src/Dictionaries/ExecutableDictionarySource.cpp b/src/Dictionaries/ExecutableDictionarySource.cpp
index f1acd6102742..6b9f97a6d5cf 100644
--- a/src/Dictionaries/ExecutableDictionarySource.cpp
+++ b/src/Dictionaries/ExecutableDictionarySource.cpp
@@ -71,7 +71,7 @@ ExecutableDictionarySource::ExecutableDictionarySource(
     Block & sample_block_,
     std::shared_ptr<ShellCommandSourceCoordinator> coordinator_,
     ContextPtr context_)
-    : log(&Poco::Logger::get("ExecutableDictionarySource"))
+    : log(getLogger("ExecutableDictionarySource"))
     , dict_struct(dict_struct_)
     , configuration(configuration_)
     , sample_block(sample_block_)
@@ -93,7 +93,7 @@ ExecutableDictionarySource::ExecutableDictionarySource(
 }
 
 ExecutableDictionarySource::ExecutableDictionarySource(const ExecutableDictionarySource & other)
-    : log(&Poco::Logger::get("ExecutableDictionarySource"))
+    : log(getLogger("ExecutableDictionarySource"))
     , update_time(other.update_time)
     , dict_struct(other.dict_struct)
     , configuration(other.configuration)
diff --git a/src/Dictionaries/ExecutableDictionarySource.h b/src/Dictionaries/ExecutableDictionarySource.h
index c7067a628938..eb936434218a 100644
--- a/src/Dictionaries/ExecutableDictionarySource.h
+++ b/src/Dictionaries/ExecutableDictionarySource.h
@@ -63,7 +63,7 @@ class ExecutableDictionarySource final : public IDictionarySource
     QueryPipeline getStreamForBlock(const Block & block);
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     time_t update_time = 0;
     const DictionaryStructure dict_struct;
     const Configuration configuration;
diff --git a/src/Dictionaries/ExecutablePoolDictionarySource.cpp b/src/Dictionaries/ExecutablePoolDictionarySource.cpp
index d28c73c9c52b..d8111afdc199 100644
--- a/src/Dictionaries/ExecutablePoolDictionarySource.cpp
+++ b/src/Dictionaries/ExecutablePoolDictionarySource.cpp
@@ -40,7 +40,7 @@ ExecutablePoolDictionarySource::ExecutablePoolDictionarySource(
     , sample_block(sample_block_)
     , coordinator(std::move(coordinator_))
     , context(context_)
-    , log(&Poco::Logger::get("ExecutablePoolDictionarySource"))
+    , log(getLogger("ExecutablePoolDictionarySource"))
 {
     /// Remove keys from sample_block for implicit_key dictionary because
     /// these columns will not be returned from source
@@ -64,7 +64,7 @@ ExecutablePoolDictionarySource::ExecutablePoolDictionarySource(const ExecutableP
     , sample_block(other.sample_block)
     , coordinator(other.coordinator)
     , context(Context::createCopy(other.context))
-    , log(&Poco::Logger::get("ExecutablePoolDictionarySource"))
+    , log(getLogger("ExecutablePoolDictionarySource"))
 {
 }
 
diff --git a/src/Dictionaries/ExecutablePoolDictionarySource.h b/src/Dictionaries/ExecutablePoolDictionarySource.h
index e8cc6e834068..752d8ea2757f 100644
--- a/src/Dictionaries/ExecutablePoolDictionarySource.h
+++ b/src/Dictionaries/ExecutablePoolDictionarySource.h
@@ -72,7 +72,7 @@ class ExecutablePoolDictionarySource final : public IDictionarySource
     Block sample_block;
     std::shared_ptr<ShellCommandSourceCoordinator> coordinator;
     ContextPtr context;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Dictionaries/FileDictionarySource.cpp b/src/Dictionaries/FileDictionarySource.cpp
index 86287971428e..16a4ecaee754 100644
--- a/src/Dictionaries/FileDictionarySource.cpp
+++ b/src/Dictionaries/FileDictionarySource.cpp
@@ -48,7 +48,7 @@ FileDictionarySource::FileDictionarySource(const FileDictionarySource & other)
 
 QueryPipeline FileDictionarySource::loadAll()
 {
-    LOG_TRACE(&Poco::Logger::get("FileDictionary"), "loadAll {}", toString());
+    LOG_TRACE(getLogger("FileDictionary"), "loadAll {}", toString());
     auto in_ptr = std::make_unique<ReadBufferFromFile>(filepath);
     auto source = context->getInputFormat(format, *in_ptr, sample_block, max_block_size);
     source->addBuffer(std::move(in_ptr));
diff --git a/src/Dictionaries/HTTPDictionarySource.cpp b/src/Dictionaries/HTTPDictionarySource.cpp
index 689593a969ef..bf42b7931ed9 100644
--- a/src/Dictionaries/HTTPDictionarySource.cpp
+++ b/src/Dictionaries/HTTPDictionarySource.cpp
@@ -32,7 +32,7 @@ HTTPDictionarySource::HTTPDictionarySource(
     const Poco::Net::HTTPBasicCredentials & credentials_,
     Block & sample_block_,
     ContextPtr context_)
-    : log(&Poco::Logger::get("HTTPDictionarySource"))
+    : log(getLogger("HTTPDictionarySource"))
     , update_time(std::chrono::system_clock::from_time_t(0))
     , dict_struct(dict_struct_)
     , configuration(configuration_)
@@ -45,7 +45,7 @@ HTTPDictionarySource::HTTPDictionarySource(
 }
 
 HTTPDictionarySource::HTTPDictionarySource(const HTTPDictionarySource & other)
-    : log(&Poco::Logger::get("HTTPDictionarySource"))
+    : log(getLogger("HTTPDictionarySource"))
     , update_time(other.update_time)
     , dict_struct(other.dict_struct)
     , configuration(other.configuration)
diff --git a/src/Dictionaries/HTTPDictionarySource.h b/src/Dictionaries/HTTPDictionarySource.h
index e22aacd89f1f..414372fe7ac2 100644
--- a/src/Dictionaries/HTTPDictionarySource.h
+++ b/src/Dictionaries/HTTPDictionarySource.h
@@ -66,7 +66,7 @@ class HTTPDictionarySource final : public IDictionarySource
     // wrap buffer using encoding from made request
     QueryPipeline createWrappedBuffer(std::unique_ptr<ReadWriteBufferFromHTTP> http_buffer);
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     LocalDateTime getLastModification() const;
 
diff --git a/src/Dictionaries/HashedArrayDictionary.cpp b/src/Dictionaries/HashedArrayDictionary.cpp
index 4c9ff8abe80a..648ecb681fc0 100644
--- a/src/Dictionaries/HashedArrayDictionary.cpp
+++ b/src/Dictionaries/HashedArrayDictionary.cpp
@@ -32,7 +32,7 @@ HashedArrayDictionary<dictionary_key_type, sharded>::HashedArrayDictionary(
     const HashedArrayDictionaryStorageConfiguration & configuration_,
     BlockPtr update_field_loaded_block_)
     : IDictionary(dict_id_)
-    , log(&Poco::Logger::get("HashedArrayDictionary"))
+    , log(getLogger("HashedArrayDictionary"))
     , dict_struct(dict_struct_)
     , source_ptr(std::move(source_ptr_))
     , configuration(configuration_)
@@ -822,7 +822,7 @@ void HashedArrayDictionary<dictionary_key_type, sharded>::loadData()
         if (parallel_loader)
             parallel_loader->finish();
 
-        LOG_DEBUG(&Poco::Logger::get("HashedArrayDictionary"),
+        LOG_DEBUG(getLogger("HashedArrayDictionary"),
             "Finished {}reading {} blocks with {} rows from pipeline in {:.2f} sec and inserted into hashtable in {:.2f} sec",
             configuration.use_async_executor ? "asynchronous " : "",
             total_blocks, total_rows, pull_time_microseconds / 1000000.0, process_time_microseconds / 1000000.0);
diff --git a/src/Dictionaries/HashedArrayDictionary.h b/src/Dictionaries/HashedArrayDictionary.h
index 606008ce9210..86b21443e186 100644
--- a/src/Dictionaries/HashedArrayDictionary.h
+++ b/src/Dictionaries/HashedArrayDictionary.h
@@ -244,7 +244,7 @@ class HashedArrayDictionary final : public IDictionary
 
     void resize(size_t total_rows);
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     const DictionaryStructure dict_struct;
     const DictionarySourcePtr source_ptr;
diff --git a/src/Dictionaries/HashedDictionary.h b/src/Dictionaries/HashedDictionary.h
index 8009ffab80a3..0b8419dd242c 100644
--- a/src/Dictionaries/HashedDictionary.h
+++ b/src/Dictionaries/HashedDictionary.h
@@ -251,7 +251,7 @@ class HashedDictionary final : public IDictionary
 
     void resize(size_t added_rows);
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     const DictionaryStructure dict_struct;
     const DictionarySourcePtr source_ptr;
@@ -293,7 +293,7 @@ HashedDictionary<dictionary_key_type, sparse, sharded>::HashedDictionary(
     const HashedDictionaryConfiguration & configuration_,
     BlockPtr update_field_loaded_block_)
     : IDictionary(dict_id_)
-    , log(&Poco::Logger::get("HashedDictionary"))
+    , log(getLogger("HashedDictionary"))
     , dict_struct(dict_struct_)
     , source_ptr(std::move(source_ptr_))
     , configuration(configuration_)
diff --git a/src/Dictionaries/IPAddressDictionary.cpp b/src/Dictionaries/IPAddressDictionary.cpp
index 2e3c09c67c5d..98ba95f00538 100644
--- a/src/Dictionaries/IPAddressDictionary.cpp
+++ b/src/Dictionaries/IPAddressDictionary.cpp
@@ -205,7 +205,7 @@ IPAddressDictionary::IPAddressDictionary(
     , source_ptr{std::move(source_ptr_)}
     , configuration(configuration_)
     , access_to_key_from_attributes(dict_struct_.access_to_key_from_attributes)
-    , logger(&Poco::Logger::get("IPAddressDictionary"))
+    , logger(getLogger("IPAddressDictionary"))
 {
     createAttributes();
     loadData();
diff --git a/src/Dictionaries/IPAddressDictionary.h b/src/Dictionaries/IPAddressDictionary.h
index c5b9287c2b54..d758e23043d6 100644
--- a/src/Dictionaries/IPAddressDictionary.h
+++ b/src/Dictionaries/IPAddressDictionary.h
@@ -234,7 +234,7 @@ class IPAddressDictionary final : public IDictionary
     mutable std::atomic<size_t> query_count{0};
     mutable std::atomic<size_t> found_count{0};
 
-    Poco::Logger * logger;
+    LoggerPtr logger;
 };
 
 }
diff --git a/src/Dictionaries/LibraryDictionarySource.cpp b/src/Dictionaries/LibraryDictionarySource.cpp
index 7eb4d803fe8f..f6f104ca11da 100644
--- a/src/Dictionaries/LibraryDictionarySource.cpp
+++ b/src/Dictionaries/LibraryDictionarySource.cpp
@@ -30,7 +30,7 @@ LibraryDictionarySource::LibraryDictionarySource(
     Block & sample_block_,
     ContextPtr context_,
     bool created_from_ddl)
-    : log(&Poco::Logger::get("LibraryDictionarySource"))
+    : log(getLogger("LibraryDictionarySource"))
     , dict_struct{dict_struct_}
     , config_prefix{config_prefix_}
     , path{config.getString(config_prefix + ".path", "")}
@@ -78,7 +78,7 @@ LibraryDictionarySource::~LibraryDictionarySource()
 
 
 LibraryDictionarySource::LibraryDictionarySource(const LibraryDictionarySource & other)
-    : log(&Poco::Logger::get("LibraryDictionarySource"))
+    : log(getLogger("LibraryDictionarySource"))
     , dict_struct{other.dict_struct}
     , config_prefix{other.config_prefix}
     , path{other.path}
diff --git a/src/Dictionaries/LibraryDictionarySource.h b/src/Dictionaries/LibraryDictionarySource.h
index 57ab9976a3b6..04a3d838577c 100644
--- a/src/Dictionaries/LibraryDictionarySource.h
+++ b/src/Dictionaries/LibraryDictionarySource.h
@@ -75,7 +75,7 @@ class LibraryDictionarySource final : public IDictionarySource
 
     static Field getDictID() { return UUIDHelpers::generateV4(); }
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     const DictionaryStructure dict_struct;
     const std::string config_prefix;
diff --git a/src/Dictionaries/MySQLDictionarySource.cpp b/src/Dictionaries/MySQLDictionarySource.cpp
index e61409e2b54b..9a84512fde6b 100644
--- a/src/Dictionaries/MySQLDictionarySource.cpp
+++ b/src/Dictionaries/MySQLDictionarySource.cpp
@@ -173,7 +173,7 @@ MySQLDictionarySource::MySQLDictionarySource(
     mysqlxx::PoolWithFailoverPtr pool_,
     const Block & sample_block_,
     const StreamSettings & settings_)
-    : log(&Poco::Logger::get("MySQLDictionarySource"))
+    : log(getLogger("MySQLDictionarySource"))
     , update_time(std::chrono::system_clock::from_time_t(0))
     , dict_struct(dict_struct_)
     , configuration(configuration_)
@@ -187,7 +187,7 @@ MySQLDictionarySource::MySQLDictionarySource(
 
 /// copy-constructor is provided in order to support cloneability
 MySQLDictionarySource::MySQLDictionarySource(const MySQLDictionarySource & other)
-    : log(&Poco::Logger::get("MySQLDictionarySource"))
+    : log(getLogger("MySQLDictionarySource"))
     , update_time(other.update_time)
     , dict_struct(other.dict_struct)
     , configuration(other.configuration)
diff --git a/src/Dictionaries/MySQLDictionarySource.h b/src/Dictionaries/MySQLDictionarySource.h
index 1d43ebfe2ba6..d9eea3f3e261 100644
--- a/src/Dictionaries/MySQLDictionarySource.h
+++ b/src/Dictionaries/MySQLDictionarySource.h
@@ -82,7 +82,7 @@ class MySQLDictionarySource final : public IDictionarySource
     // execute invalidate_query. expects single cell in result
     std::string doInvalidateQuery(const std::string & request) const;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::chrono::time_point<std::chrono::system_clock> update_time;
     const DictionaryStructure dict_struct;
diff --git a/src/Dictionaries/NullDictionarySource.cpp b/src/Dictionaries/NullDictionarySource.cpp
index 45dcc77f93d0..2d5656e13359 100644
--- a/src/Dictionaries/NullDictionarySource.cpp
+++ b/src/Dictionaries/NullDictionarySource.cpp
@@ -20,7 +20,7 @@ NullDictionarySource::NullDictionarySource(const NullDictionarySource & other) :
 
 QueryPipeline NullDictionarySource::loadAll()
 {
-    LOG_TRACE(&Poco::Logger::get("NullDictionarySource"), "loadAll {}", toString());
+    LOG_TRACE(getLogger("NullDictionarySource"), "loadAll {}", toString());
     return QueryPipeline(std::make_shared<NullSource>(sample_block));
 }
 
diff --git a/src/Dictionaries/PolygonDictionaryUtils.cpp b/src/Dictionaries/PolygonDictionaryUtils.cpp
index 2af97d3fc6fa..8f060fe7b8d0 100644
--- a/src/Dictionaries/PolygonDictionaryUtils.cpp
+++ b/src/Dictionaries/PolygonDictionaryUtils.cpp
@@ -69,7 +69,7 @@ const FinalCellWithSlabs * FinalCellWithSlabs::find(Coord, Coord) const
 
 SlabsPolygonIndex::SlabsPolygonIndex(
     const std::vector<Polygon> & polygons)
-    : log(&Poco::Logger::get("SlabsPolygonIndex")),
+    : log(getLogger("SlabsPolygonIndex")),
       sorted_x(uniqueX(polygons))
 {
     indexBuild(polygons);
diff --git a/src/Dictionaries/PolygonDictionaryUtils.h b/src/Dictionaries/PolygonDictionaryUtils.h
index 5268cb93f780..0acf0d23e5ee 100644
--- a/src/Dictionaries/PolygonDictionaryUtils.h
+++ b/src/Dictionaries/PolygonDictionaryUtils.h
@@ -83,7 +83,7 @@ class SlabsPolygonIndex
     /** Auxiliary function for adding ring to the index */
     void indexAddRing(const Ring & ring, size_t polygon_id);
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /** Sorted distinct coordinates of all vertices */
     std::vector<Coord> sorted_x;
diff --git a/src/Dictionaries/PostgreSQLDictionarySource.cpp b/src/Dictionaries/PostgreSQLDictionarySource.cpp
index 8ec783083927..c7401386e400 100644
--- a/src/Dictionaries/PostgreSQLDictionarySource.cpp
+++ b/src/Dictionaries/PostgreSQLDictionarySource.cpp
@@ -57,7 +57,7 @@ PostgreSQLDictionarySource::PostgreSQLDictionarySource(
     , configuration(configuration_)
     , pool(std::move(pool_))
     , sample_block(sample_block_)
-    , log(&Poco::Logger::get("PostgreSQLDictionarySource"))
+    , log(getLogger("PostgreSQLDictionarySource"))
     , query_builder(makeExternalQueryBuilder(dict_struct, configuration.schema, configuration.table, configuration.query, configuration.where))
     , load_all_query(query_builder.composeLoadAllQuery())
 {
@@ -70,7 +70,7 @@ PostgreSQLDictionarySource::PostgreSQLDictionarySource(const PostgreSQLDictionar
     , configuration(other.configuration)
     , pool(other.pool)
     , sample_block(other.sample_block)
-    , log(&Poco::Logger::get("PostgreSQLDictionarySource"))
+    , log(getLogger("PostgreSQLDictionarySource"))
     , query_builder(makeExternalQueryBuilder(dict_struct, configuration.schema, configuration.table, configuration.query, configuration.where))
     , load_all_query(query_builder.composeLoadAllQuery())
     , update_time(other.update_time)
diff --git a/src/Dictionaries/PostgreSQLDictionarySource.h b/src/Dictionaries/PostgreSQLDictionarySource.h
index 1305333458b3..3070184ab3d6 100644
--- a/src/Dictionaries/PostgreSQLDictionarySource.h
+++ b/src/Dictionaries/PostgreSQLDictionarySource.h
@@ -61,7 +61,7 @@ class PostgreSQLDictionarySource final : public IDictionarySource
     const Configuration configuration;
     postgres::PoolWithFailoverPtr pool;
     Block sample_block;
-    Poco::Logger * log;
+    LoggerPtr log;
     ExternalQueryBuilder query_builder;
     const std::string load_all_query;
     std::chrono::time_point<std::chrono::system_clock> update_time;
diff --git a/src/Dictionaries/RegExpTreeDictionary.cpp b/src/Dictionaries/RegExpTreeDictionary.cpp
index bbd101d55aaf..a95327372768 100644
--- a/src/Dictionaries/RegExpTreeDictionary.cpp
+++ b/src/Dictionaries/RegExpTreeDictionary.cpp
@@ -139,7 +139,7 @@ struct RegExpTreeDictionary::RegexTreeNode
     std::unordered_map<String, AttributeValue> attributes;
 };
 
-std::vector<StringPiece> createStringPieces(const String & value, int num_captures, const String & regex, Poco::Logger * logger)
+std::vector<StringPiece> createStringPieces(const String & value, int num_captures, const String & regex, LoggerPtr logger)
 {
     std::vector<StringPiece> result;
     String literal;
@@ -401,7 +401,7 @@ RegExpTreeDictionary::RegExpTreeDictionary(
       use_vectorscan(use_vectorscan_),
       flag_case_insensitive(flag_case_insensitive_),
       flag_dotall(flag_dotall_),
-      logger(&Poco::Logger::get("RegExpTreeDictionary"))
+      logger(getLogger("RegExpTreeDictionary"))
 {
     if (auto * ch_source = typeid_cast<ClickHouseDictionarySource *>(source_ptr.get()))
     {
diff --git a/src/Dictionaries/RegExpTreeDictionary.h b/src/Dictionaries/RegExpTreeDictionary.h
index 6597584ed45c..78b7f441d349 100644
--- a/src/Dictionaries/RegExpTreeDictionary.h
+++ b/src/Dictionaries/RegExpTreeDictionary.h
@@ -208,7 +208,7 @@ class RegExpTreeDictionary : public IDictionary
     MultiRegexps::DataBasePtr origin_db;
     #endif
 
-    Poco::Logger * logger;
+    LoggerPtr logger;
 };
 
 }
diff --git a/src/Dictionaries/XDBCDictionarySource.cpp b/src/Dictionaries/XDBCDictionarySource.cpp
index 080f7db96be7..70fe889a8ead 100644
--- a/src/Dictionaries/XDBCDictionarySource.cpp
+++ b/src/Dictionaries/XDBCDictionarySource.cpp
@@ -67,7 +67,7 @@ XDBCDictionarySource::XDBCDictionarySource(
     ContextPtr context_,
     const BridgeHelperPtr bridge_)
     : WithContext(context_->getGlobalContext())
-    , log(&Poco::Logger::get(bridge_->getName() + "DictionarySource"))
+    , log(getLogger(bridge_->getName() + "DictionarySource"))
     , update_time(std::chrono::system_clock::from_time_t(0))
     , dict_struct(dict_struct_)
     , configuration(configuration_)
@@ -86,7 +86,7 @@ XDBCDictionarySource::XDBCDictionarySource(
 /// copy-constructor is provided in order to support cloneability
 XDBCDictionarySource::XDBCDictionarySource(const XDBCDictionarySource & other)
     : WithContext(other.getContext())
-    , log(&Poco::Logger::get(other.bridge_helper->getName() + "DictionarySource"))
+    , log(getLogger(other.bridge_helper->getName() + "DictionarySource"))
     , update_time(other.update_time)
     , dict_struct(other.dict_struct)
     , configuration(other.configuration)
diff --git a/src/Dictionaries/XDBCDictionarySource.h b/src/Dictionaries/XDBCDictionarySource.h
index 8ca2e172aa6f..6011563c5223 100644
--- a/src/Dictionaries/XDBCDictionarySource.h
+++ b/src/Dictionaries/XDBCDictionarySource.h
@@ -76,7 +76,7 @@ class XDBCDictionarySource final : public IDictionarySource, WithContext
 
     QueryPipeline loadFromQuery(const Poco::URI & url, const Block & required_sample_block, const std::string & query) const;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::chrono::time_point<std::chrono::system_clock> update_time;
     const DictionaryStructure dict_struct;
diff --git a/src/Dictionaries/YAMLRegExpTreeDictionarySource.cpp b/src/Dictionaries/YAMLRegExpTreeDictionarySource.cpp
index 118d0f6a0f3c..f1591943a122 100644
--- a/src/Dictionaries/YAMLRegExpTreeDictionarySource.cpp
+++ b/src/Dictionaries/YAMLRegExpTreeDictionarySource.cpp
@@ -284,7 +284,7 @@ Block parseYAMLAsRegExpTree(const YAML::Node & node, const String & key_name, co
 
 YAMLRegExpTreeDictionarySource::YAMLRegExpTreeDictionarySource(
     const String & filepath_, const DictionaryStructure & dict_struct, ContextPtr context_, bool created_from_ddl)
-    : filepath(filepath_), structure(dict_struct), context(context_), logger(&Poco::Logger::get(kYAMLRegExpTreeDictionarySource))
+    : filepath(filepath_), structure(dict_struct), context(context_), logger(getLogger(kYAMLRegExpTreeDictionarySource))
 {
     key_name = (*structure.key)[0].name;
 
diff --git a/src/Dictionaries/YAMLRegExpTreeDictionarySource.h b/src/Dictionaries/YAMLRegExpTreeDictionarySource.h
index f5dd9b7d186d..041cbca81c65 100644
--- a/src/Dictionaries/YAMLRegExpTreeDictionarySource.h
+++ b/src/Dictionaries/YAMLRegExpTreeDictionarySource.h
@@ -64,7 +64,7 @@ class YAMLRegExpTreeDictionarySource : public IDictionarySource
 
     ContextPtr context;
 
-    Poco::Logger * logger;
+    LoggerPtr logger;
     Poco::Timestamp last_modification;
 
     Poco::Timestamp getLastModification() const;
diff --git a/src/Dictionaries/registerHashedDictionary.cpp b/src/Dictionaries/registerHashedDictionary.cpp
index f511cad04b0a..303ca8c577e4 100644
--- a/src/Dictionaries/registerHashedDictionary.cpp
+++ b/src/Dictionaries/registerHashedDictionary.cpp
@@ -50,7 +50,7 @@ void registerDictionaryHashed(DictionaryFactory & factory)
         const std::string dictionary_layout_prefix = ".layout." + dictionary_layout_name;
         const bool preallocate = config.getBool(config_prefix + dictionary_layout_prefix + ".preallocate", false);
         if (preallocate)
-            LOG_WARNING(&Poco::Logger::get("HashedDictionary"), "'prellocate' attribute is obsolete, consider looking at 'shards'");
+            LOG_WARNING(getLogger("HashedDictionary"), "'prellocate' attribute is obsolete, consider looking at 'shards'");
 
         Int64 shards = config.getInt(config_prefix + dictionary_layout_prefix + ".shards", 1);
         if (shards <= 0 || shards > 128)
diff --git a/src/Disks/DiskLocal.cpp b/src/Disks/DiskLocal.cpp
index 07c2beb002d9..f5d67d37b07a 100644
--- a/src/Disks/DiskLocal.cpp
+++ b/src/Disks/DiskLocal.cpp
@@ -106,7 +106,7 @@ class DiskLocalReservation : public IReservation
             if (disk->reserved_bytes < size)
             {
                 disk->reserved_bytes = 0;
-                LOG_ERROR(&Poco::Logger::get("DiskLocal"), "Unbalanced reservations size for disk '{}'.", disk->getName());
+                LOG_ERROR(getLogger("DiskLocal"), "Unbalanced reservations size for disk '{}'.", disk->getName());
             }
             else
             {
@@ -114,7 +114,7 @@ class DiskLocalReservation : public IReservation
             }
 
             if (disk->reservation_count == 0)
-                LOG_ERROR(&Poco::Logger::get("DiskLocal"), "Unbalanced reservation count for disk '{}'.", disk->getName());
+                LOG_ERROR(getLogger("DiskLocal"), "Unbalanced reservation count for disk '{}'.", disk->getName());
             else
                 --disk->reservation_count;
         }
@@ -475,7 +475,7 @@ DiskLocal::DiskLocal(const String & name_, const String & path_, UInt64 keep_fre
     : IDisk(name_, config, config_prefix)
     , disk_path(path_)
     , keep_free_space_bytes(keep_free_space_bytes_)
-    , logger(&Poco::Logger::get("DiskLocal"))
+    , logger(getLogger("DiskLocal"))
     , data_source_description(getLocalDataSourceDescription(disk_path))
 {
 }
@@ -494,7 +494,7 @@ DiskLocal::DiskLocal(const String & name_, const String & path_)
     : IDisk(name_)
     , disk_path(path_)
     , keep_free_space_bytes(0)
-    , logger(&Poco::Logger::get("DiskLocal"))
+    , logger(getLogger("DiskLocal"))
     , data_source_description(getLocalDataSourceDescription(disk_path))
 {
 }
diff --git a/src/Disks/DiskLocal.h b/src/Disks/DiskLocal.h
index affce5a847e3..b9703019c191 100644
--- a/src/Disks/DiskLocal.h
+++ b/src/Disks/DiskLocal.h
@@ -153,7 +153,7 @@ class DiskLocal : public IDisk
     const String disk_path;
     const String disk_checker_path = ".disk_checker_file";
     std::atomic<UInt64> keep_free_space_bytes;
-    Poco::Logger * logger;
+    LoggerPtr logger;
     DataSourceDescription data_source_description;
 
     UInt64 reserved_bytes = 0;
diff --git a/src/Disks/DiskLocalCheckThread.cpp b/src/Disks/DiskLocalCheckThread.cpp
index 87fcc0d1cf5a..e95c614336bf 100644
--- a/src/Disks/DiskLocalCheckThread.cpp
+++ b/src/Disks/DiskLocalCheckThread.cpp
@@ -13,7 +13,7 @@ DiskLocalCheckThread::DiskLocalCheckThread(DiskLocal * disk_, ContextPtr context
     : WithContext(context_)
     , disk(std::move(disk_))
     , check_period_ms(local_disk_check_period_ms)
-    , log(&Poco::Logger::get(fmt::format("DiskLocalCheckThread({})", disk->getName())))
+    , log(getLogger(fmt::format("DiskLocalCheckThread({})", disk->getName())))
 {
     task = getContext()->getSchedulePool().createTask(log->name(), [this] { run(); });
 }
diff --git a/src/Disks/DiskLocalCheckThread.h b/src/Disks/DiskLocalCheckThread.h
index eb688d599ca0..046b75531360 100644
--- a/src/Disks/DiskLocalCheckThread.h
+++ b/src/Disks/DiskLocalCheckThread.h
@@ -29,7 +29,7 @@ class DiskLocalCheckThread : WithContext
 
     DiskLocal * disk;
     size_t check_period_ms;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::atomic<bool> need_stop{false};
 
     BackgroundSchedulePool::TaskHolder task;
diff --git a/src/Disks/DiskSelector.cpp b/src/Disks/DiskSelector.cpp
index dad1c7285609..a9260a249ddd 100644
--- a/src/Disks/DiskSelector.cpp
+++ b/src/Disks/DiskSelector.cpp
@@ -124,7 +124,7 @@ DiskSelectorPtr DiskSelector::updateFromConfig(
         if (num_disks_removed_from_config > 0)
         {
             LOG_WARNING(
-                &Poco::Logger::get("DiskSelector"),
+                getLogger("DiskSelector"),
                 "{} disappeared from configuration, this change will be applied after restart of ClickHouse",
                 warning.str());
         }
diff --git a/src/Disks/IDisk.cpp b/src/Disks/IDisk.cpp
index 5426f8d09049..066acc250a28 100644
--- a/src/Disks/IDisk.cpp
+++ b/src/Disks/IDisk.cpp
@@ -33,7 +33,7 @@ void IDisk::copyFile( /// NOLINT
     const std::function<void()> & cancellation_hook
     )
 {
-    LOG_DEBUG(&Poco::Logger::get("IDisk"), "Copying from {} (path: {}) {} to {} (path: {}) {}.",
+    LOG_DEBUG(getLogger("IDisk"), "Copying from {} (path: {}) {} to {} (path: {}) {}.",
               getName(), getPath(), from_file_path, to_disk.getName(), to_disk.getPath(), to_file_path);
 
     auto in = readFile(from_file_path, read_settings);
@@ -194,7 +194,7 @@ void IDisk::startup(ContextPtr context, bool skip_access_check)
     {
         if (isReadOnly())
         {
-            LOG_DEBUG(&Poco::Logger::get("IDisk"),
+            LOG_DEBUG(getLogger("IDisk"),
                 "Skip access check for disk {} (read-only disk).",
                 getName());
         }
diff --git a/src/Disks/IO/AsynchronousBoundedReadBuffer.cpp b/src/Disks/IO/AsynchronousBoundedReadBuffer.cpp
index 1952d8ae253b..8eecd0d99d1c 100644
--- a/src/Disks/IO/AsynchronousBoundedReadBuffer.cpp
+++ b/src/Disks/IO/AsynchronousBoundedReadBuffer.cpp
@@ -55,7 +55,7 @@ AsynchronousBoundedReadBuffer::AsynchronousBoundedReadBuffer(
     , prefetch_buffer(chooseBufferSizeForRemoteReading(read_settings, impl->getFileSize()))
     , query_id(CurrentThread::isInitialized() && CurrentThread::get().getQueryContext() != nullptr ? CurrentThread::getQueryId() : "")
     , current_reader_id(getRandomASCIIString(8))
-    , log(&Poco::Logger::get("AsynchronousBoundedReadBuffer"))
+    , log(getLogger("AsynchronousBoundedReadBuffer"))
     , async_read_counters(async_read_counters_)
     , prefetches_log(prefetches_log_)
 {
diff --git a/src/Disks/IO/AsynchronousBoundedReadBuffer.h b/src/Disks/IO/AsynchronousBoundedReadBuffer.h
index c43b08ce2b00..e5030f37b1d9 100644
--- a/src/Disks/IO/AsynchronousBoundedReadBuffer.h
+++ b/src/Disks/IO/AsynchronousBoundedReadBuffer.h
@@ -67,7 +67,7 @@ class AsynchronousBoundedReadBuffer : public ReadBufferFromFileBase
     const std::string query_id;
     const std::string current_reader_id;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     AsyncReadCountersPtr async_read_counters;
     FilesystemReadPrefetchesLogPtr prefetches_log;
diff --git a/src/Disks/IO/CachedOnDiskReadBufferFromFile.cpp b/src/Disks/IO/CachedOnDiskReadBufferFromFile.cpp
index 2b169bd9c7db..7ce3d58dcd8f 100644
--- a/src/Disks/IO/CachedOnDiskReadBufferFromFile.cpp
+++ b/src/Disks/IO/CachedOnDiskReadBufferFromFile.cpp
@@ -60,9 +60,9 @@ CachedOnDiskReadBufferFromFile::CachedOnDiskReadBufferFromFile(
     std::shared_ptr<FilesystemCacheLog> cache_log_)
     : ReadBufferFromFileBase(use_external_buffer_ ? 0 : settings_.remote_fs_buffer_size, nullptr, 0, file_size_)
 #ifdef ABORT_ON_LOGICAL_ERROR
-    , log(&Poco::Logger::get(fmt::format("CachedOnDiskReadBufferFromFile({})", cache_key_)))
+    , log(getLogger(fmt::format("CachedOnDiskReadBufferFromFile({})", cache_key_)))
 #else
-    , log(&Poco::Logger::get("CachedOnDiskReadBufferFromFile"))
+    , log(getLogger("CachedOnDiskReadBufferFromFile"))
 #endif
     , cache_key(cache_key_)
     , source_file_path(source_file_path_)
diff --git a/src/Disks/IO/CachedOnDiskReadBufferFromFile.h b/src/Disks/IO/CachedOnDiskReadBufferFromFile.h
index e2ea5dce3c05..74fb6220af23 100644
--- a/src/Disks/IO/CachedOnDiskReadBufferFromFile.h
+++ b/src/Disks/IO/CachedOnDiskReadBufferFromFile.h
@@ -105,7 +105,7 @@ class CachedOnDiskReadBufferFromFile : public ReadBufferFromFileBase
 
     bool nextFileSegmentsBatch();
 
-    Poco::Logger * log;
+    LoggerPtr log;
     FileCacheKey cache_key;
     String source_file_path;
 
diff --git a/src/Disks/IO/CachedOnDiskWriteBufferFromFile.cpp b/src/Disks/IO/CachedOnDiskWriteBufferFromFile.cpp
index a97f25e80e5a..25c8ab1c4aea 100644
--- a/src/Disks/IO/CachedOnDiskWriteBufferFromFile.cpp
+++ b/src/Disks/IO/CachedOnDiskWriteBufferFromFile.cpp
@@ -31,7 +31,7 @@ FileSegmentRangeWriter::FileSegmentRangeWriter(
     const String & source_path_)
     : cache(cache_)
     , key(key_)
-    , log(&Poco::Logger::get("FileSegmentRangeWriter"))
+    , log(getLogger("FileSegmentRangeWriter"))
     , cache_log(cache_log_)
     , query_id(query_id_)
     , source_path(source_path_)
@@ -205,7 +205,7 @@ CachedOnDiskWriteBufferFromFile::CachedOnDiskWriteBufferFromFile(
     const FileCacheUserInfo & user_,
     std::shared_ptr<FilesystemCacheLog> cache_log_)
     : WriteBufferFromFileDecorator(std::move(impl_))
-    , log(&Poco::Logger::get("CachedOnDiskWriteBufferFromFile"))
+    , log(getLogger("CachedOnDiskWriteBufferFromFile"))
     , cache(cache_)
     , source_path(source_path_)
     , key(key_)
diff --git a/src/Disks/IO/CachedOnDiskWriteBufferFromFile.h b/src/Disks/IO/CachedOnDiskWriteBufferFromFile.h
index 2a4e78f44c6b..59e0c76ca3d2 100644
--- a/src/Disks/IO/CachedOnDiskWriteBufferFromFile.h
+++ b/src/Disks/IO/CachedOnDiskWriteBufferFromFile.h
@@ -54,7 +54,7 @@ class FileSegmentRangeWriter
     FileCache * cache;
     FileSegment::Key key;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     std::shared_ptr<FilesystemCacheLog> cache_log;
     String query_id;
     String source_path;
@@ -93,7 +93,7 @@ class CachedOnDiskWriteBufferFromFile final : public WriteBufferFromFileDecorato
 private:
     void cacheData(char * data, size_t size, bool throw_on_error);
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     FileCachePtr cache;
     String source_path;
diff --git a/src/Disks/IO/IOUringReader.cpp b/src/Disks/IO/IOUringReader.cpp
index 4c9f665093d6..90a4d285ecbe 100644
--- a/src/Disks/IO/IOUringReader.cpp
+++ b/src/Disks/IO/IOUringReader.cpp
@@ -46,7 +46,7 @@ namespace ErrorCodes
 }
 
 IOUringReader::IOUringReader(uint32_t entries_)
-    : log(&Poco::Logger::get("IOUringReader"))
+    : log(getLogger("IOUringReader"))
 {
     struct io_uring_probe * probe = io_uring_get_probe();
     if (!probe)
diff --git a/src/Disks/IO/IOUringReader.h b/src/Disks/IO/IOUringReader.h
index b038b3acf7d1..2504dd73a6bc 100644
--- a/src/Disks/IO/IOUringReader.h
+++ b/src/Disks/IO/IOUringReader.h
@@ -73,7 +73,7 @@ class IOUringReader final : public IAsynchronousReader
         return promise.get_future();
     }
 
-    const Poco::Logger * log;
+    const LoggerPtr log;
 
 public:
     IOUringReader(uint32_t entries_);
diff --git a/src/Disks/IO/ReadBufferFromAzureBlobStorage.h b/src/Disks/IO/ReadBufferFromAzureBlobStorage.h
index 4e21f5436536..68058b84a2f6 100644
--- a/src/Disks/IO/ReadBufferFromAzureBlobStorage.h
+++ b/src/Disks/IO/ReadBufferFromAzureBlobStorage.h
@@ -73,7 +73,7 @@ class ReadBufferFromAzureBlobStorage : public ReadBufferFromFileBase
     char * data_ptr;
     size_t data_capacity;
 
-    Poco::Logger * log = &Poco::Logger::get("ReadBufferFromAzureBlobStorage");
+    LoggerPtr log = getLogger("ReadBufferFromAzureBlobStorage");
 };
 
 }
diff --git a/src/Disks/IO/ReadBufferFromRemoteFSGather.cpp b/src/Disks/IO/ReadBufferFromRemoteFSGather.cpp
index 63bacaa99e91..923aab5c3431 100644
--- a/src/Disks/IO/ReadBufferFromRemoteFSGather.cpp
+++ b/src/Disks/IO/ReadBufferFromRemoteFSGather.cpp
@@ -56,7 +56,7 @@ ReadBufferFromRemoteFSGather::ReadBufferFromRemoteFSGather(
     , query_id(CurrentThread::getQueryId())
     , use_external_buffer(use_external_buffer_)
     , with_cache(withCache(settings))
-    , log(&Poco::Logger::get("ReadBufferFromRemoteFSGather"))
+    , log(getLogger("ReadBufferFromRemoteFSGather"))
 {
     if (!blobs_to_read.empty())
         current_object = blobs_to_read.front();
diff --git a/src/Disks/IO/ReadBufferFromRemoteFSGather.h b/src/Disks/IO/ReadBufferFromRemoteFSGather.h
index c5886dea603c..93ded9fefb33 100644
--- a/src/Disks/IO/ReadBufferFromRemoteFSGather.h
+++ b/src/Disks/IO/ReadBufferFromRemoteFSGather.h
@@ -82,7 +82,7 @@ friend class ReadIndirectBufferFromRemoteFS;
     size_t current_buf_idx = 0;
     std::unique_ptr<ReadBufferFromFileBase> current_buf;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 size_t chooseBufferSizeForRemoteReading(const DB::ReadSettings & settings, size_t file_size);
diff --git a/src/Disks/IO/ReadBufferFromWebServer.cpp b/src/Disks/IO/ReadBufferFromWebServer.cpp
index 7a6028561835..cc8723927383 100644
--- a/src/Disks/IO/ReadBufferFromWebServer.cpp
+++ b/src/Disks/IO/ReadBufferFromWebServer.cpp
@@ -27,7 +27,7 @@ ReadBufferFromWebServer::ReadBufferFromWebServer(
     bool use_external_buffer_,
     size_t read_until_position_)
     : ReadBufferFromFileBase(settings_.remote_fs_buffer_size, nullptr, 0)
-    , log(&Poco::Logger::get("ReadBufferFromWebServer"))
+    , log(getLogger("ReadBufferFromWebServer"))
     , context(context_)
     , url(url_)
     , buf_size(settings_.remote_fs_buffer_size)
diff --git a/src/Disks/IO/ReadBufferFromWebServer.h b/src/Disks/IO/ReadBufferFromWebServer.h
index b4edf16b095e..68ad752bbdb5 100644
--- a/src/Disks/IO/ReadBufferFromWebServer.h
+++ b/src/Disks/IO/ReadBufferFromWebServer.h
@@ -41,7 +41,7 @@ class ReadBufferFromWebServer : public ReadBufferFromFileBase
 private:
     std::unique_ptr<ReadBuffer> initialize();
 
-    Poco::Logger * log;
+    LoggerPtr log;
     ContextPtr context;
 
     const String url;
diff --git a/src/Disks/IO/WriteBufferFromAzureBlobStorage.cpp b/src/Disks/IO/WriteBufferFromAzureBlobStorage.cpp
index a2e84edf45ff..d281c3dfdc25 100644
--- a/src/Disks/IO/WriteBufferFromAzureBlobStorage.cpp
+++ b/src/Disks/IO/WriteBufferFromAzureBlobStorage.cpp
@@ -27,7 +27,7 @@ WriteBufferFromAzureBlobStorage::WriteBufferFromAzureBlobStorage(
     size_t buf_size_,
     const WriteSettings & write_settings_)
     : WriteBufferFromFileBase(buf_size_, nullptr, 0)
-    , log(&Poco::Logger::get("WriteBufferFromAzureBlobStorage"))
+    , log(getLogger("WriteBufferFromAzureBlobStorage"))
     , max_single_part_upload_size(max_single_part_upload_size_)
     , blob_path(blob_path_)
     , write_settings(write_settings_)
diff --git a/src/Disks/IO/WriteBufferFromAzureBlobStorage.h b/src/Disks/IO/WriteBufferFromAzureBlobStorage.h
index f1be81922e19..5e4f97b0a082 100644
--- a/src/Disks/IO/WriteBufferFromAzureBlobStorage.h
+++ b/src/Disks/IO/WriteBufferFromAzureBlobStorage.h
@@ -45,7 +45,7 @@ class WriteBufferFromAzureBlobStorage : public WriteBufferFromFileBase
     void execWithRetry(std::function<void()> func, size_t num_tries, size_t cost = 0);
     void uploadBlock(const char * data, size_t size);
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     const size_t max_single_part_upload_size;
     const std::string blob_path;
diff --git a/src/Disks/ObjectStorages/AzureBlobStorage/AzureObjectStorage.cpp b/src/Disks/ObjectStorages/AzureBlobStorage/AzureObjectStorage.cpp
index 93fed1e61bf9..05bf2281842f 100644
--- a/src/Disks/ObjectStorages/AzureBlobStorage/AzureObjectStorage.cpp
+++ b/src/Disks/ObjectStorages/AzureBlobStorage/AzureObjectStorage.cpp
@@ -96,7 +96,7 @@ AzureObjectStorage::AzureObjectStorage(
     : name(name_)
     , client(std::move(client_))
     , settings(std::move(settings_))
-    , log(&Poco::Logger::get("AzureObjectStorage"))
+    , log(getLogger("AzureObjectStorage"))
 {
 }
 
diff --git a/src/Disks/ObjectStorages/AzureBlobStorage/AzureObjectStorage.h b/src/Disks/ObjectStorages/AzureBlobStorage/AzureObjectStorage.h
index 85213a3c24f9..a05eb824b91b 100644
--- a/src/Disks/ObjectStorages/AzureBlobStorage/AzureObjectStorage.h
+++ b/src/Disks/ObjectStorages/AzureBlobStorage/AzureObjectStorage.h
@@ -134,7 +134,7 @@ class AzureObjectStorage : public IObjectStorage
     MultiVersion<Azure::Storage::Blobs::BlobContainerClient> client;
     MultiVersion<AzureObjectStorageSettings> settings;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Disks/ObjectStorages/Cached/CachedObjectStorage.cpp b/src/Disks/ObjectStorages/Cached/CachedObjectStorage.cpp
index d4aba197ae41..1444f4c9c76a 100644
--- a/src/Disks/ObjectStorages/Cached/CachedObjectStorage.cpp
+++ b/src/Disks/ObjectStorages/Cached/CachedObjectStorage.cpp
@@ -24,7 +24,7 @@ CachedObjectStorage::CachedObjectStorage(
     , cache(cache_)
     , cache_settings(cache_settings_)
     , cache_config_name(cache_config_name_)
-    , log(&Poco::Logger::get(getName()))
+    , log(getLogger(getName()))
 {
     cache->initialize();
 }
diff --git a/src/Disks/ObjectStorages/Cached/CachedObjectStorage.h b/src/Disks/ObjectStorages/Cached/CachedObjectStorage.h
index 028b0f7c5104..7b231b688051 100644
--- a/src/Disks/ObjectStorages/Cached/CachedObjectStorage.h
+++ b/src/Disks/ObjectStorages/Cached/CachedObjectStorage.h
@@ -129,7 +129,7 @@ class CachedObjectStorage final : public IObjectStorage
     FileCachePtr cache;
     FileCacheSettings cache_settings;
     std::string cache_config_name;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Disks/ObjectStorages/Cached/registerDiskCache.cpp b/src/Disks/ObjectStorages/Cached/registerDiskCache.cpp
index 5d788f2641a8..6e0453f5f021 100644
--- a/src/Disks/ObjectStorages/Cached/registerDiskCache.cpp
+++ b/src/Disks/ObjectStorages/Cached/registerDiskCache.cpp
@@ -114,7 +114,7 @@ void registerDiskCache(DiskFactory & factory, bool /* global_skip_access_check *
         disk_object_storage->wrapWithCache(cache, file_cache_settings, name);
 
         LOG_INFO(
-            &Poco::Logger::get("DiskCache"),
+            getLogger("DiskCache"),
             "Registered cached disk (`{}`) with structure: {}",
             name, assert_cast<DiskObjectStorage *>(disk_object_storage.get())->getStructure());
 
diff --git a/src/Disks/ObjectStorages/DiskObjectStorage.cpp b/src/Disks/ObjectStorages/DiskObjectStorage.cpp
index 3c39fa2a8ff7..9c4132f433ff 100644
--- a/src/Disks/ObjectStorages/DiskObjectStorage.cpp
+++ b/src/Disks/ObjectStorages/DiskObjectStorage.cpp
@@ -67,7 +67,7 @@ DiskObjectStorage::DiskObjectStorage(
     const String & config_prefix)
     : IDisk(name_, config, config_prefix)
     , object_key_prefix(object_key_prefix_)
-    , log (&Poco::Logger::get("DiskObjectStorage(" + name + ")"))
+    , log(getLogger("DiskObjectStorage(" + name + ")"))
     , metadata_storage(std::move(metadata_storage_))
     , object_storage(std::move(object_storage_))
     , send_metadata(config.getBool(config_prefix + ".send_metadata", false))
diff --git a/src/Disks/ObjectStorages/DiskObjectStorage.h b/src/Disks/ObjectStorages/DiskObjectStorage.h
index 983af483b8a2..e15765097133 100644
--- a/src/Disks/ObjectStorages/DiskObjectStorage.h
+++ b/src/Disks/ObjectStorages/DiskObjectStorage.h
@@ -219,7 +219,7 @@ friend class DiskObjectStorageRemoteMetadataRestoreHelper;
     String getWriteResourceName() const;
 
     const String object_key_prefix;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     MetadataStoragePtr metadata_storage;
     ObjectStoragePtr object_storage;
diff --git a/src/Disks/ObjectStorages/DiskObjectStorageMetadata.cpp b/src/Disks/ObjectStorages/DiskObjectStorageMetadata.cpp
index 881f7a46c168..19b8b51384fb 100644
--- a/src/Disks/ObjectStorages/DiskObjectStorageMetadata.cpp
+++ b/src/Disks/ObjectStorages/DiskObjectStorageMetadata.cpp
@@ -104,7 +104,7 @@ void DiskObjectStorageMetadata::serialize(WriteBuffer & buf, bool sync) const
 
     if (version == VERSION_FULL_OBJECT_KEY && !storage_metadata_write_full_object_key)
     {
-        Poco::Logger * logger = &Poco::Logger::get("DiskObjectStorageMetadata");
+        LoggerPtr logger = getLogger("DiskObjectStorageMetadata");
         LOG_WARNING(
             logger,
             "Metadata file {} is written with VERSION_FULL_OBJECT_KEY version"
@@ -192,7 +192,7 @@ void DiskObjectStorageMetadata::addObject(ObjectStorageKey key, size_t size)
         bool storage_metadata_write_full_object_key = getWriteFullObjectKeySetting();
         if (!storage_metadata_write_full_object_key)
         {
-            Poco::Logger * logger = &Poco::Logger::get("DiskObjectStorageMetadata");
+            LoggerPtr logger = getLogger("DiskObjectStorageMetadata");
             LOG_WARNING(
                 logger,
                 "Metadata file {} has at least one key {} without fixed common key prefix."
diff --git a/src/Disks/ObjectStorages/DiskObjectStorageTransaction.cpp b/src/Disks/ObjectStorages/DiskObjectStorageTransaction.cpp
index f39e16828c53..de7a71e8dc14 100644
--- a/src/Disks/ObjectStorages/DiskObjectStorageTransaction.cpp
+++ b/src/Disks/ObjectStorages/DiskObjectStorageTransaction.cpp
@@ -242,7 +242,7 @@ struct RemoveManyObjectStorageOperation final : public IDiskObjectStorageOperati
                     || e.code() == ErrorCodes::CANNOT_OPEN_FILE)
                 {
                     LOG_DEBUG(
-                        &Poco::Logger::get("RemoveManyObjectStorageOperation"),
+                        getLogger("RemoveManyObjectStorageOperation"),
                         "Can't read metadata because of an exception. Just remove it from the filesystem. Path: {}, exception: {}",
                         metadata_storage.getPath() + path,
                         e.message());
@@ -276,7 +276,7 @@ struct RemoveManyObjectStorageOperation final : public IDiskObjectStorageOperati
         if (!keep_all_batch_data)
         {
             LOG_DEBUG(
-                &Poco::Logger::get("RemoveManyObjectStorageOperation"),
+                getLogger("RemoveManyObjectStorageOperation"),
                 "metadata and objects were removed for [{}], "
                 "only metadata were removed for [{}].",
                 boost::algorithm::join(paths_removed_with_objects, ", "),
@@ -345,7 +345,7 @@ struct RemoveRecursiveObjectStorageOperation final : public IDiskObjectStorageOp
                     || e.code() == ErrorCodes::CANNOT_PARSE_INPUT_ASSERTION_FAILED)
                 {
                     LOG_DEBUG(
-                        &Poco::Logger::get("RemoveRecursiveObjectStorageOperation"),
+                        getLogger("RemoveRecursiveObjectStorageOperation"),
                         "Can't read metadata because of an exception. Just remove it from the filesystem. Path: {}, exception: {}",
                         metadata_storage.getPath() + path_to_remove,
                         e.message());
@@ -399,7 +399,7 @@ struct RemoveRecursiveObjectStorageOperation final : public IDiskObjectStorageOp
             object_storage.removeObjectsIfExist(remove_from_remote);
 
             LOG_DEBUG(
-                &Poco::Logger::get("RemoveRecursiveObjectStorageOperation"),
+                getLogger("RemoveRecursiveObjectStorageOperation"),
                 "Recursively remove path {}: "
                 "metadata and objects were removed for [{}], "
                 "only metadata were removed for [{}].",
@@ -905,7 +905,7 @@ void DiskObjectStorageTransaction::commit()
         catch (...)
         {
             tryLogCurrentException(
-                &Poco::Logger::get("DiskObjectStorageTransaction"),
+                getLogger("DiskObjectStorageTransaction"),
                 fmt::format("An error occurred while executing transaction's operation #{} ({})", i, operations_to_execute[i]->getInfoForLog()));
 
             for (int64_t j = i; j >= 0; --j)
@@ -917,7 +917,7 @@ void DiskObjectStorageTransaction::commit()
                 catch (...)
                 {
                     tryLogCurrentException(
-                        &Poco::Logger::get("DiskObjectStorageTransaction"),
+                        getLogger("DiskObjectStorageTransaction"),
                         fmt::format("An error occurred while undoing transaction's operation #{}", i));
 
                     throw;
diff --git a/src/Disks/ObjectStorages/Local/LocalObjectStorage.cpp b/src/Disks/ObjectStorages/Local/LocalObjectStorage.cpp
index b3c1c3202a52..02700b358e01 100644
--- a/src/Disks/ObjectStorages/Local/LocalObjectStorage.cpp
+++ b/src/Disks/ObjectStorages/Local/LocalObjectStorage.cpp
@@ -25,7 +25,7 @@ namespace ErrorCodes
 
 LocalObjectStorage::LocalObjectStorage(String key_prefix_)
     : key_prefix(std::move(key_prefix_))
-    , log(&Poco::Logger::get("LocalObjectStorage"))
+    , log(getLogger("LocalObjectStorage"))
 {
     if (auto block_device_id = tryGetBlockDeviceId("/"); block_device_id.has_value())
         description = *block_device_id;
diff --git a/src/Disks/ObjectStorages/Local/LocalObjectStorage.h b/src/Disks/ObjectStorages/Local/LocalObjectStorage.h
index 522e73b415d3..ed5f8c1f537f 100644
--- a/src/Disks/ObjectStorages/Local/LocalObjectStorage.h
+++ b/src/Disks/ObjectStorages/Local/LocalObjectStorage.h
@@ -90,7 +90,7 @@ class LocalObjectStorage : public IObjectStorage
 
 private:
     String key_prefix;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::string description;
 };
 
diff --git a/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp b/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp
index 499435543845..4cc49288af63 100644
--- a/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp
+++ b/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp
@@ -482,7 +482,7 @@ void S3ObjectStorage::copyObjectToAnotherObjectStorage( // NOLINT
             /// If authentication/permissions error occurs then fallthrough to copy with buffer.
             if (exc.getS3ErrorCode() != Aws::S3::S3Errors::ACCESS_DENIED)
                 throw;
-            LOG_WARNING(&Poco::Logger::get("S3ObjectStorage"),
+            LOG_WARNING(getLogger("S3ObjectStorage"),
                 "S3-server-side copy object from the disk {} to the disk {} can not be performed: {}
",
                 getName(), dest_s3->getName(), exc.what());
         }
diff --git a/src/Disks/ObjectStorages/S3/S3ObjectStorage.h b/src/Disks/ObjectStorages/S3/S3ObjectStorage.h
index 820d4977f98f..ab0fa5bed689 100644
--- a/src/Disks/ObjectStorages/S3/S3ObjectStorage.h
+++ b/src/Disks/ObjectStorages/S3/S3ObjectStorage.h
@@ -59,7 +59,7 @@ class S3ObjectStorage : public IObjectStorage
         , client(std::move(client_))
         , s3_settings(std::move(s3_settings_))
         , s3_capabilities(s3_capabilities_)
-        , log(&Poco::Logger::get(logger_name))
+        , log(getLogger(logger_name))
     {
     }
 
@@ -179,7 +179,7 @@ class S3ObjectStorage : public IObjectStorage
     MultiVersion<S3ObjectStorageSettings> s3_settings;
     S3Capabilities s3_capabilities;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 /// Do not encode keys, store as-is, and do not require separate disk for metadata.
diff --git a/src/Disks/ObjectStorages/Web/WebObjectStorage.cpp b/src/Disks/ObjectStorages/Web/WebObjectStorage.cpp
index ff4216a83da2..0223c24973e6 100644
--- a/src/Disks/ObjectStorages/Web/WebObjectStorage.cpp
+++ b/src/Disks/ObjectStorages/Web/WebObjectStorage.cpp
@@ -119,7 +119,7 @@ WebObjectStorage::WebObjectStorage(
     ContextPtr context_)
     : WithContext(context_->getGlobalContext())
     , url(url_)
-    , log(&Poco::Logger::get("WebObjectStorage"))
+    , log(getLogger("WebObjectStorage"))
 {
 }
 
@@ -130,7 +130,7 @@ bool WebObjectStorage::exists(const StoredObject & object) const
 
 bool WebObjectStorage::exists(const std::string & path) const
 {
-    LOG_TRACE(&Poco::Logger::get("DiskWeb"), "Checking existence of path: {}", path);
+    LOG_TRACE(getLogger("DiskWeb"), "Checking existence of path: {}", path);
     return tryGetFileInfo(path) != nullptr;
 }
 
diff --git a/src/Disks/ObjectStorages/Web/WebObjectStorage.h b/src/Disks/ObjectStorages/Web/WebObjectStorage.h
index 9688873f0c48..a285742c66d8 100644
--- a/src/Disks/ObjectStorages/Web/WebObjectStorage.h
+++ b/src/Disks/ObjectStorages/Web/WebObjectStorage.h
@@ -158,7 +158,7 @@ class WebObjectStorage : public IObjectStorage, WithContext
     loadFiles(const String & path, const std::unique_lock<std::shared_mutex> &) const;
 
     const String url;
-    Poco::Logger * log;
+    LoggerPtr log;
     size_t min_bytes_for_seek;
 };
 
diff --git a/src/Disks/StoragePolicy.cpp b/src/Disks/StoragePolicy.cpp
index 6cf22cbaa1b9..13bd74ceaebc 100644
--- a/src/Disks/StoragePolicy.cpp
+++ b/src/Disks/StoragePolicy.cpp
@@ -41,7 +41,7 @@ StoragePolicy::StoragePolicy(
     const String & config_prefix,
     DiskSelectorPtr disks)
     : name(std::move(name_))
-    , log(&Poco::Logger::get("StoragePolicy (" + name + ")"))
+    , log(getLogger("StoragePolicy (" + name + ")"))
 {
     Poco::Util::AbstractConfiguration::Keys keys;
     String volumes_prefix = config_prefix + ".volumes";
@@ -96,7 +96,7 @@ StoragePolicy::StoragePolicy(String name_, Volumes volumes_, double move_factor_
     : volumes(std::move(volumes_))
     , name(std::move(name_))
     , move_factor(move_factor_)
-    , log(&Poco::Logger::get("StoragePolicy (" + name + ")"))
+    , log(getLogger("StoragePolicy (" + name + ")"))
 {
     if (volumes.empty())
         throw Exception(ErrorCodes::NO_ELEMENTS_IN_CONFIG, "Storage policy {} must contain at least one Volume.", backQuote(name));
@@ -418,7 +418,7 @@ StoragePolicySelector::StoragePolicySelector(
          */
 
         policies.emplace(name, std::make_shared<StoragePolicy>(name, config, config_prefix + "." + name, disks));
-        LOG_INFO(&Poco::Logger::get("StoragePolicySelector"), "Storage policy {} loaded", backQuote(name));
+        LOG_INFO(getLogger("StoragePolicySelector"), "Storage policy {} loaded", backQuote(name));
     }
 
     /// Add default policy if it isn't explicitly specified.
diff --git a/src/Disks/StoragePolicy.h b/src/Disks/StoragePolicy.h
index d210d8c1e2f6..501e033abc38 100644
--- a/src/Disks/StoragePolicy.h
+++ b/src/Disks/StoragePolicy.h
@@ -105,7 +105,7 @@ class StoragePolicy : public IStoragePolicy
 
     void buildVolumeIndices();
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 
diff --git a/src/Disks/TemporaryFileOnDisk.cpp b/src/Disks/TemporaryFileOnDisk.cpp
index 06d7da4af588..92219a7f25f2 100644
--- a/src/Disks/TemporaryFileOnDisk.cpp
+++ b/src/Disks/TemporaryFileOnDisk.cpp
@@ -59,7 +59,7 @@ TemporaryFileOnDisk::~TemporaryFileOnDisk()
 
         if (!disk->exists(relative_path))
         {
-            LOG_WARNING(&Poco::Logger::get("TemporaryFileOnDisk"), "Temporary path '{}' does not exist in '{}'", relative_path, disk->getPath());
+            LOG_WARNING(getLogger("TemporaryFileOnDisk"), "Temporary path '{}' does not exist in '{}'", relative_path, disk->getPath());
             return;
         }
 
diff --git a/src/Disks/VolumeJBOD.cpp b/src/Disks/VolumeJBOD.cpp
index 682a167bf5f0..e437684b8021 100644
--- a/src/Disks/VolumeJBOD.cpp
+++ b/src/Disks/VolumeJBOD.cpp
@@ -21,7 +21,7 @@ VolumeJBOD::VolumeJBOD(
     : IVolume(name_, config, config_prefix, disk_selector)
     , disks_by_size(disks.begin(), disks.end())
 {
-    Poco::Logger * logger = &Poco::Logger::get("StorageConfiguration");
+    LoggerPtr logger = getLogger("StorageConfiguration");
 
     auto has_max_bytes = config.has(config_prefix + ".max_data_part_size_bytes");
     auto has_max_ratio = config.has(config_prefix + ".max_data_part_size_ratio");
diff --git a/src/Disks/getOrCreateDiskFromAST.cpp b/src/Disks/getOrCreateDiskFromAST.cpp
index ab2fb5e7f8b4..7b2762613b6a 100644
--- a/src/Disks/getOrCreateDiskFromAST.cpp
+++ b/src/Disks/getOrCreateDiskFromAST.cpp
@@ -114,7 +114,7 @@ std::string getOrCreateDiskFromDiskAST(const ASTPtr & disk_function, ContextPtr
     FlattenDiskConfigurationVisitor{data}.visit(ast);
 
     auto disk_name = assert_cast<const ASTLiteral &>(*ast).value.get<String>();
-    LOG_TRACE(&Poco::Logger::get("getOrCreateDiskFromDiskAST"), "Result disk name: {}", disk_name);
+    LOG_TRACE(getLogger("getOrCreateDiskFromDiskAST"), "Result disk name: {}", disk_name);
     return disk_name;
 }
 
diff --git a/src/Formats/FormatFactory.cpp b/src/Formats/FormatFactory.cpp
index 608f9433d6fa..62cbadec4f47 100644
--- a/src/Formats/FormatFactory.cpp
+++ b/src/Formats/FormatFactory.cpp
@@ -395,7 +395,7 @@ std::unique_ptr<ReadBuffer> FormatFactory::wrapReadBufferIfNeeded(
         {
             parallel_read = false;
             LOG_TRACE(
-                &Poco::Logger::get("FormatFactory"),
+                getLogger("FormatFactory"),
                 "Failed to setup ParallelReadBuffer because of an exception:
{}.
"
                 "Falling back to the single-threaded buffer",
                 e.displayText());
@@ -405,7 +405,7 @@ std::unique_ptr<ReadBuffer> FormatFactory::wrapReadBufferIfNeeded(
     if (parallel_read)
     {
         LOG_TRACE(
-            &Poco::Logger::get("FormatFactory"),
+            getLogger("FormatFactory"),
             "Using ParallelReadBuffer with {} workers with chunks of {} bytes",
             max_download_threads,
             settings.max_download_buffer_size);
diff --git a/src/Formats/ProtobufSerializer.cpp b/src/Formats/ProtobufSerializer.cpp
index dd37c25719c1..c0d0713e2542 100644
--- a/src/Formats/ProtobufSerializer.cpp
+++ b/src/Formats/ProtobufSerializer.cpp
@@ -3045,7 +3045,7 @@ namespace
             {
                 *root_serializer_ptr = message_serializer.get();
 #if 0
-                LOG_INFO(&Poco::Logger::get("ProtobufSerializer"), "Serialization tree:
{}", get_root_desc_function(0));
+                LOG_INFO(getLogger("ProtobufSerializer"), "Serialization tree:
{}", get_root_desc_function(0));
 #endif
                 return message_serializer;
             }
@@ -3054,7 +3054,7 @@ namespace
                 auto envelope_serializer = std::make_unique<ProtobufSerializerEnvelope>(std::move(message_serializer), reader_or_writer);
                 *root_serializer_ptr = envelope_serializer.get();
 #if 0
-                LOG_INFO(&Poco::Logger::get("ProtobufSerializer"), "Serialization tree:
{}", get_root_desc_function(0));
+                LOG_INFO(getLogger("ProtobufSerializer"), "Serialization tree:
{}", get_root_desc_function(0));
 #endif
                 return envelope_serializer;
             }
diff --git a/src/Functions/UserDefined/ExternalUserDefinedExecutableFunctionsLoader.cpp b/src/Functions/UserDefined/ExternalUserDefinedExecutableFunctionsLoader.cpp
index f3c9f511ef64..db98f88e53ba 100644
--- a/src/Functions/UserDefined/ExternalUserDefinedExecutableFunctionsLoader.cpp
+++ b/src/Functions/UserDefined/ExternalUserDefinedExecutableFunctionsLoader.cpp
@@ -95,7 +95,7 @@ namespace
 }
 
 ExternalUserDefinedExecutableFunctionsLoader::ExternalUserDefinedExecutableFunctionsLoader(ContextPtr global_context_)
-    : ExternalLoader("external user defined function", &Poco::Logger::get("ExternalUserDefinedExecutableFunctionsLoader"))
+    : ExternalLoader("external user defined function", getLogger("ExternalUserDefinedExecutableFunctionsLoader"))
     , WithContext(global_context_)
 {
     setConfigSettings({"function", "name", "database", "uuid"});
diff --git a/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.cpp b/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.cpp
index 271c464e79ae..34946db7d9eb 100644
--- a/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.cpp
+++ b/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.cpp
@@ -54,7 +54,7 @@ namespace
 UserDefinedSQLObjectsDiskStorage::UserDefinedSQLObjectsDiskStorage(const ContextPtr & global_context_, const String & dir_path_)
     : global_context(global_context_)
     , dir_path{makeDirectoryPathCanonical(dir_path_)}
-    , log{&Poco::Logger::get("UserDefinedSQLObjectsLoaderFromDisk")}
+    , log{getLogger("UserDefinedSQLObjectsLoaderFromDisk")}
 {
     createDirectory();
 }
diff --git a/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.h b/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.h
index f0986dbda727..ae0cbd0c5897 100644
--- a/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.h
+++ b/src/Functions/UserDefined/UserDefinedSQLObjectsDiskStorage.h
@@ -44,7 +44,7 @@ class UserDefinedSQLObjectsDiskStorage : public UserDefinedSQLObjectsStorageBase
 
     ContextPtr global_context;
     String dir_path;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::atomic<bool> objects_loaded = false;
 };
 
diff --git a/src/Functions/UserDefined/UserDefinedSQLObjectsZooKeeperStorage.cpp b/src/Functions/UserDefined/UserDefinedSQLObjectsZooKeeperStorage.cpp
index 6e5a53384377..c43b223ffeb6 100644
--- a/src/Functions/UserDefined/UserDefinedSQLObjectsZooKeeperStorage.cpp
+++ b/src/Functions/UserDefined/UserDefinedSQLObjectsZooKeeperStorage.cpp
@@ -53,7 +53,7 @@ UserDefinedSQLObjectsZooKeeperStorage::UserDefinedSQLObjectsZooKeeperStorage(
     , zookeeper_getter{[global_context_]() { return global_context_->getZooKeeper(); }}
     , zookeeper_path{zookeeper_path_}
     , watch_queue{std::make_shared<ConcurrentBoundedQueue<std::pair<UserDefinedSQLObjectType, String>>>(std::numeric_limits<size_t>::max())}
-    , log{&Poco::Logger::get("UserDefinedSQLObjectsLoaderFromZooKeeper")}
+    , log{getLogger("UserDefinedSQLObjectsLoaderFromZooKeeper")}
 {
     if (zookeeper_path.empty())
         throw Exception(ErrorCodes::BAD_ARGUMENTS, "ZooKeeper path must be non-empty");
diff --git a/src/Functions/UserDefined/UserDefinedSQLObjectsZooKeeperStorage.h b/src/Functions/UserDefined/UserDefinedSQLObjectsZooKeeperStorage.h
index 9f41763c59ca..61002be2bfd3 100644
--- a/src/Functions/UserDefined/UserDefinedSQLObjectsZooKeeperStorage.h
+++ b/src/Functions/UserDefined/UserDefinedSQLObjectsZooKeeperStorage.h
@@ -80,7 +80,7 @@ class UserDefinedSQLObjectsZooKeeperStorage : public UserDefinedSQLObjectsStorag
     using UserDefinedSQLObjectTypeAndName = std::pair<UserDefinedSQLObjectType, String>;
     std::shared_ptr<ConcurrentBoundedQueue<UserDefinedSQLObjectTypeAndName>> watch_queue;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Functions/logTrace.cpp b/src/Functions/logTrace.cpp
index 55f387cbfeb2..923ea9fd70ef 100644
--- a/src/Functions/logTrace.cpp
+++ b/src/Functions/logTrace.cpp
@@ -46,7 +46,7 @@ namespace
                 throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, "First argument for function {} must be Constant string",
                     getName());
 
-            static auto * log = &Poco::Logger::get("FunctionLogTrace");
+            static auto log = getLogger("FunctionLogTrace");
             LOG_TRACE(log, fmt::runtime(message));
 
             return DataTypeUInt8().createColumnConst(input_rows_count, 0);
diff --git a/src/IO/Archives/ZipArchiveWriter.cpp b/src/IO/Archives/ZipArchiveWriter.cpp
index 785a5005f878..8cb4a2e0bd69 100644
--- a/src/IO/Archives/ZipArchiveWriter.cpp
+++ b/src/IO/Archives/ZipArchiveWriter.cpp
@@ -246,7 +246,7 @@ ZipArchiveWriter::~ZipArchiveWriter()
         /// However it is suspicious to destroy instance without finalization at the green path.
         if (!std::uncaught_exceptions() && std::current_exception() == nullptr)
         {
-            Poco::Logger * log = &Poco::Logger::get("ZipArchiveWriter");
+            LoggerPtr log = getLogger("ZipArchiveWriter");
             LOG_ERROR(log,
                        "ZipArchiveWriter is not finalized when destructor is called. "
                        "The zip archive might not be written at all or might be truncated. "
diff --git a/src/IO/HTTPCommon.cpp b/src/IO/HTTPCommon.cpp
index cce394c67c98..c4468a1b896f 100644
--- a/src/IO/HTTPCommon.cpp
+++ b/src/IO/HTTPCommon.cpp
@@ -70,7 +70,7 @@ namespace
         static_assert(std::has_virtual_destructor_v<Session>, "The base class must have a virtual destructor");
 
     public:
-        HTTPSessionAdapter(const std::string & host, UInt16 port) : Session(host, port), log{&Poco::Logger::get("HTTPSessionAdapter")} { }
+        HTTPSessionAdapter(const std::string & host, UInt16 port) : Session(host, port), log{getLogger("HTTPSessionAdapter")} { }
         ~HTTPSessionAdapter() override = default;
 
     protected:
@@ -132,7 +132,7 @@ namespace
                 }
             }
         }
-        Poco::Logger * log;
+        LoggerPtr log;
     };
 
     bool isHTTPS(const Poco::URI & uri)
@@ -223,7 +223,7 @@ namespace
             bool wait_on_pool_size_limit)
             : Base(
                 static_cast<unsigned>(max_pool_size_),
-                &Poco::Logger::get("HTTPSessionPool"),
+                getLogger("HTTPSessionPool"),
                 wait_on_pool_size_limit ? BehaviourOnLimit::Wait : BehaviourOnLimit::AllocateNewBypassingPool)
             , host(host_)
             , port(port_)
diff --git a/src/IO/ParallelReadBuffer.cpp b/src/IO/ParallelReadBuffer.cpp
index 8d73f221748f..cdeb8a186351 100644
--- a/src/IO/ParallelReadBuffer.cpp
+++ b/src/IO/ParallelReadBuffer.cpp
@@ -50,7 +50,7 @@ ParallelReadBuffer::ParallelReadBuffer(
     , file_size(file_size_)
     , range_step(std::max(1ul, range_step_))
 {
-    LOG_TRACE(&Poco::Logger::get("ParallelReadBuffer"), "Parallel reading is used");
+    LOG_TRACE(getLogger("ParallelReadBuffer"), "Parallel reading is used");
 
     try
     {
diff --git a/src/IO/ReadBufferFromS3.h b/src/IO/ReadBufferFromS3.h
index 101e25f8b436..f28c23a71d7a 100644
--- a/src/IO/ReadBufferFromS3.h
+++ b/src/IO/ReadBufferFromS3.h
@@ -39,7 +39,7 @@ class ReadBufferFromS3 : public ReadBufferFromFileBase
     std::optional<Aws::S3::Model::GetObjectResult> read_result;
     std::unique_ptr<ReadBuffer> impl;
 
-    Poco::Logger * log = &Poco::Logger::get("ReadBufferFromS3");
+    LoggerPtr log = getLogger("ReadBufferFromS3");
 
 public:
     ReadBufferFromS3(
diff --git a/src/IO/ReadWriteBufferFromHTTP.cpp b/src/IO/ReadWriteBufferFromHTTP.cpp
index b2c4a53bd9b2..bf5c426f8036 100644
--- a/src/IO/ReadWriteBufferFromHTTP.cpp
+++ b/src/IO/ReadWriteBufferFromHTTP.cpp
@@ -265,7 +265,7 @@ ReadWriteBufferFromHTTPBase<UpdatableSessionPtr>::ReadWriteBufferFromHTTPBase(
     , file_info(file_info_)
     , http_skip_not_found_url(http_skip_not_found_url_)
     , settings {settings_}
-    , log(&Poco::Logger::get("ReadWriteBufferFromHTTP"))
+    , log(getLogger("ReadWriteBufferFromHTTP"))
     , proxy_config(proxy_config_)
 {
     if (settings.http_max_tries <= 0 || settings.http_retry_initial_backoff_ms <= 0
diff --git a/src/IO/ReadWriteBufferFromHTTP.h b/src/IO/ReadWriteBufferFromHTTP.h
index 29c0804bb280..63ca3e0417cd 100644
--- a/src/IO/ReadWriteBufferFromHTTP.h
+++ b/src/IO/ReadWriteBufferFromHTTP.h
@@ -109,7 +109,7 @@ namespace detail
         bool http_skip_not_found_url;
 
         ReadSettings settings;
-        Poco::Logger * log;
+        LoggerPtr log;
 
         ProxyConfiguration proxy_config;
 
diff --git a/src/IO/S3/AWSLogger.cpp b/src/IO/S3/AWSLogger.cpp
index d6162823aeee..dcdba7753b27 100644
--- a/src/IO/S3/AWSLogger.cpp
+++ b/src/IO/S3/AWSLogger.cpp
@@ -41,7 +41,7 @@ AWSLogger::AWSLogger(bool enable_s3_requests_logging_)
     : enable_s3_requests_logging(enable_s3_requests_logging_)
 {
     for (auto [tag, name] : S3_LOGGER_TAG_NAMES)
-        tag_loggers[tag] = &Poco::Logger::get(name);
+        tag_loggers[tag] = getLogger(name);
 
     default_logger = tag_loggers[S3_LOGGER_TAG_NAMES[0][0]];
 }
diff --git a/src/IO/S3/AWSLogger.h b/src/IO/S3/AWSLogger.h
index fdb6eed1f868..a4987f17c0dd 100644
--- a/src/IO/S3/AWSLogger.h
+++ b/src/IO/S3/AWSLogger.h
@@ -6,6 +6,7 @@
 #include <aws/core/utils/logging/LogSystemInterface.h>
 #include <base/types.h>
 #include <unordered_map>
+#include <Common/Logger.h>
 
 namespace Poco { class Logger; }
 
@@ -29,9 +30,9 @@ class AWSLogger final : public Aws::Utils::Logging::LogSystemInterface
     void Flush() final {}
 
 private:
-    Poco::Logger * default_logger;
+    LoggerPtr default_logger;
     bool enable_s3_requests_logging;
-    std::unordered_map<String, Poco::Logger *> tag_loggers;
+    std::unordered_map<String, LoggerPtr> tag_loggers;
 };
 
 }
diff --git a/src/IO/S3/Client.cpp b/src/IO/S3/Client.cpp
index 64259ce5a76f..7f0ede727408 100644
--- a/src/IO/S3/Client.cpp
+++ b/src/IO/S3/Client.cpp
@@ -184,7 +184,7 @@ Client::Client(
     , client_settings(client_settings_)
     , max_redirects(max_redirects_)
     , sse_kms_config(std::move(sse_kms_config_))
-    , log(&Poco::Logger::get("S3Client"))
+    , log(getLogger("S3Client"))
 {
     auto * endpoint_provider = dynamic_cast<Aws::S3::Endpoint::S3DefaultEpProviderBase *>(accessEndpointProvider().get());
     endpoint_provider->GetBuiltInParameters().GetParameter("Region").GetString(explicit_region);
@@ -234,7 +234,7 @@ Client::Client(
     , provider_type(other.provider_type)
     , max_redirects(other.max_redirects)
     , sse_kms_config(other.sse_kms_config)
-    , log(&Poco::Logger::get("S3Client"))
+    , log(getLogger("S3Client"))
 {
     cache = std::make_shared<ClientCache>(*other.cache);
     ClientCacheRegistry::instance().registerClient(cache);
@@ -854,7 +854,7 @@ void ClientCacheRegistry::clearCacheForAll()
         }
         else
         {
-            LOG_INFO(&Poco::Logger::get("ClientCacheRegistry"), "Deleting leftover S3 client cache");
+            LOG_INFO(getLogger("ClientCacheRegistry"), "Deleting leftover S3 client cache");
             it = client_caches.erase(it);
         }
     }
diff --git a/src/IO/S3/Client.h b/src/IO/S3/Client.h
index 677b739fd396..8da21bd2c2c7 100644
--- a/src/IO/S3/Client.h
+++ b/src/IO/S3/Client.h
@@ -281,7 +281,7 @@ class Client : private Aws::S3::S3Client
 
     const ServerSideEncryptionKMSConfig sse_kms_config;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 class ClientFactory
diff --git a/src/IO/S3/Credentials.cpp b/src/IO/S3/Credentials.cpp
index b0b33244015f..e64f54b99ad3 100644
--- a/src/IO/S3/Credentials.cpp
+++ b/src/IO/S3/Credentials.cpp
@@ -76,7 +76,7 @@ constexpr int AVAILABILITY_ZONE_REQUEST_TIMEOUT_SECONDS = 3;
 AWSEC2MetadataClient::AWSEC2MetadataClient(const Aws::Client::ClientConfiguration & client_configuration, const char * endpoint_)
     : Aws::Internal::AWSHttpResourceClient(client_configuration)
     , endpoint(endpoint_)
-    , logger(&Poco::Logger::get("AWSEC2InstanceProfileConfigLoader"))
+    , logger(getLogger("AWSEC2InstanceProfileConfigLoader"))
 {
 }
 
@@ -200,7 +200,7 @@ Aws::String AWSEC2MetadataClient::getCurrentRegion() const
 
 static Aws::String getAWSMetadataEndpoint()
 {
-    auto * logger = &Poco::Logger::get("AWSEC2InstanceProfileConfigLoader");
+    auto logger = getLogger("AWSEC2InstanceProfileConfigLoader");
     Aws::String ec2_metadata_service_endpoint = Aws::Environment::GetEnv("AWS_EC2_METADATA_SERVICE_ENDPOINT");
     if (ec2_metadata_service_endpoint.empty())
     {
@@ -285,7 +285,7 @@ String getGCPAvailabilityZoneOrException()
 
 String getRunningAvailabilityZone()
 {
-    LOG_INFO(&Poco::Logger::get("Application"), "Trying to detect the availability zone.");
+    LOG_INFO(getLogger("Application"), "Trying to detect the availability zone.");
     try
     {
         return AWSEC2MetadataClient::getAvailabilityZoneOrException();
@@ -310,7 +310,7 @@ String getRunningAvailabilityZone()
 AWSEC2InstanceProfileConfigLoader::AWSEC2InstanceProfileConfigLoader(const std::shared_ptr<AWSEC2MetadataClient> & client_, bool use_secure_pull_)
     : client(client_)
     , use_secure_pull(use_secure_pull_)
-    , logger(&Poco::Logger::get("AWSEC2InstanceProfileConfigLoader"))
+    , logger(getLogger("AWSEC2InstanceProfileConfigLoader"))
 {
 }
 
@@ -352,7 +352,7 @@ bool AWSEC2InstanceProfileConfigLoader::LoadInternal()
 AWSInstanceProfileCredentialsProvider::AWSInstanceProfileCredentialsProvider(const std::shared_ptr<AWSEC2InstanceProfileConfigLoader> & config_loader)
     : ec2_metadata_config_loader(config_loader)
     , load_frequency_ms(Aws::Auth::REFRESH_THRESHOLD)
-    , logger(&Poco::Logger::get("AWSInstanceProfileCredentialsProvider"))
+    , logger(getLogger("AWSInstanceProfileCredentialsProvider"))
 {
     LOG_INFO(logger, "Creating Instance with injected EC2MetadataClient and refresh rate.");
 }
@@ -396,7 +396,7 @@ void AWSInstanceProfileCredentialsProvider::refreshIfExpired()
 
 AwsAuthSTSAssumeRoleWebIdentityCredentialsProvider::AwsAuthSTSAssumeRoleWebIdentityCredentialsProvider(
     DB::S3::PocoHTTPClientConfiguration & aws_client_configuration, uint64_t expiration_window_seconds_)
-    : logger(&Poco::Logger::get("AwsAuthSTSAssumeRoleWebIdentityCredentialsProvider"))
+    : logger(getLogger("AwsAuthSTSAssumeRoleWebIdentityCredentialsProvider"))
     , expiration_window_seconds(expiration_window_seconds_)
 {
     // check environment variables
@@ -529,7 +529,7 @@ SSOCredentialsProvider::SSOCredentialsProvider(DB::S3::PocoHTTPClientConfigurati
     : profile_to_use(Aws::Auth::GetConfigProfileName())
     , aws_client_configuration(std::move(aws_client_configuration_))
     , expiration_window_seconds(expiration_window_seconds_)
-    , logger(&Poco::Logger::get(SSO_CREDENTIALS_PROVIDER_LOG_TAG))
+    , logger(getLogger(SSO_CREDENTIALS_PROVIDER_LOG_TAG))
 {
     LOG_TRACE(logger, "Setting sso credentials provider to read config from {}", profile_to_use);
 }
@@ -659,7 +659,7 @@ S3CredentialsProviderChain::S3CredentialsProviderChain(
         const Aws::Auth::AWSCredentials & credentials,
         CredentialsConfiguration credentials_configuration)
 {
-    auto * logger = &Poco::Logger::get("S3CredentialsProviderChain");
+    auto logger = getLogger("S3CredentialsProviderChain");
 
     /// we don't provide any credentials to avoid signing
     if (credentials_configuration.no_sign_request)
diff --git a/src/IO/S3/Credentials.h b/src/IO/S3/Credentials.h
index 5e83ea307989..34dc0c1d2bd0 100644
--- a/src/IO/S3/Credentials.h
+++ b/src/IO/S3/Credentials.h
@@ -70,7 +70,7 @@ class AWSEC2MetadataClient : public Aws::Internal::AWSHttpResourceClient
     const Aws::String endpoint;
     mutable std::recursive_mutex token_mutex;
     mutable Aws::String token;
-    Poco::Logger * logger;
+    LoggerPtr logger;
 };
 
 std::shared_ptr<AWSEC2MetadataClient> InitEC2MetadataClient(const Aws::Client::ClientConfiguration & client_configuration);
@@ -88,7 +88,7 @@ class AWSEC2InstanceProfileConfigLoader : public Aws::Config::AWSProfileConfigLo
 private:
     std::shared_ptr<AWSEC2MetadataClient> client;
     bool use_secure_pull;
-    Poco::Logger * logger;
+    LoggerPtr logger;
 };
 
 class AWSInstanceProfileCredentialsProvider : public Aws::Auth::AWSCredentialsProvider
@@ -107,7 +107,7 @@ class AWSInstanceProfileCredentialsProvider : public Aws::Auth::AWSCredentialsPr
 
     std::shared_ptr<AWSEC2InstanceProfileConfigLoader> ec2_metadata_config_loader;
     Int64 load_frequency_ms;
-    Poco::Logger * logger;
+    LoggerPtr logger;
 };
 
 class AwsAuthSTSAssumeRoleWebIdentityCredentialsProvider : public Aws::Auth::AWSCredentialsProvider
@@ -133,7 +133,7 @@ class AwsAuthSTSAssumeRoleWebIdentityCredentialsProvider : public Aws::Auth::AWS
     Aws::String session_name;
     Aws::String token;
     bool initialized = false;
-    Poco::Logger * logger;
+    LoggerPtr logger;
     uint64_t expiration_window_seconds;
 };
 
@@ -163,7 +163,7 @@ class SSOCredentialsProvider : public Aws::Auth::AWSCredentialsProvider
 
     DB::S3::PocoHTTPClientConfiguration aws_client_configuration;
     uint64_t expiration_window_seconds;
-    Poco::Logger * logger;
+    LoggerPtr logger;
 
     void Reload() override;
     void refreshIfExpired();
diff --git a/src/IO/S3/PocoHTTPClient.cpp b/src/IO/S3/PocoHTTPClient.cpp
index 946bd74dcb52..21acdfd69f26 100644
--- a/src/IO/S3/PocoHTTPClient.cpp
+++ b/src/IO/S3/PocoHTTPClient.cpp
@@ -345,7 +345,7 @@ void PocoHTTPClient::makeRequestInternalImpl(
 {
     using SessionPtr = std::conditional_t<pooled, PooledHTTPSessionPtr, HTTPSessionPtr>;
 
-    Poco::Logger * log = &Poco::Logger::get("AWSClient");
+    LoggerPtr log = getLogger("AWSClient");
 
     auto uri = request.GetUri().GetURIString();
     auto method = getMethod(request);
diff --git a/src/IO/S3/copyS3File.cpp b/src/IO/S3/copyS3File.cpp
index 830377622ef2..98024e74f8ec 100644
--- a/src/IO/S3/copyS3File.cpp
+++ b/src/IO/S3/copyS3File.cpp
@@ -61,7 +61,7 @@ namespace
             ThreadPoolCallbackRunner<void> schedule_,
             bool for_disk_s3_,
             BlobStorageLogWriterPtr blob_storage_log_,
-            const Poco::Logger * log_)
+            const LoggerPtr log_)
             : client_ptr(client_ptr_)
             , dest_bucket(dest_bucket_)
             , dest_key(dest_key_)
@@ -87,7 +87,7 @@ namespace
         ThreadPoolCallbackRunner<void> schedule;
         bool for_disk_s3;
         BlobStorageLogWriterPtr blob_storage_log;
-        const Poco::Logger * log;
+        const LoggerPtr log;
 
         /// Represents a task uploading a single part.
         /// Keep this struct small because there can be thousands of parts.
@@ -475,7 +475,7 @@ namespace
             ThreadPoolCallbackRunner<void> schedule_,
             bool for_disk_s3_,
             BlobStorageLogWriterPtr blob_storage_log_)
-            : UploadHelper(client_ptr_, dest_bucket_, dest_key_, request_settings_, object_metadata_, schedule_, for_disk_s3_, blob_storage_log_, &Poco::Logger::get("copyDataToS3File"))
+            : UploadHelper(client_ptr_, dest_bucket_, dest_key_, request_settings_, object_metadata_, schedule_, for_disk_s3_, blob_storage_log_, getLogger("copyDataToS3File"))
             , create_read_buffer(create_read_buffer_)
             , offset(offset_)
             , size(size_)
@@ -658,7 +658,7 @@ namespace
             ThreadPoolCallbackRunner<void> schedule_,
             bool for_disk_s3_,
             BlobStorageLogWriterPtr blob_storage_log_)
-            : UploadHelper(client_ptr_, dest_bucket_, dest_key_, request_settings_, object_metadata_, schedule_, for_disk_s3_, blob_storage_log_, &Poco::Logger::get("copyS3File"))
+            : UploadHelper(client_ptr_, dest_bucket_, dest_key_, request_settings_, object_metadata_, schedule_, for_disk_s3_, blob_storage_log_, getLogger("copyS3File"))
             , src_bucket(src_bucket_)
             , src_key(src_key_)
             , offset(src_offset_)
diff --git a/src/IO/WriteBuffer.cpp b/src/IO/WriteBuffer.cpp
index 61fdd31e16a3..bcc7445486ea 100644
--- a/src/IO/WriteBuffer.cpp
+++ b/src/IO/WriteBuffer.cpp
@@ -17,7 +17,7 @@ WriteBuffer::~WriteBuffer()
         /// However it is suspicious to destroy instance without finalization at the green path
         if (!std::uncaught_exceptions() && std::current_exception() == nullptr)
         {
-            Poco::Logger * log = &Poco::Logger::get("WriteBuffer");
+            LoggerPtr log = getLogger("WriteBuffer");
             LOG_ERROR(
                 log,
                 "WriteBuffer is not finalized when destructor is called. "
diff --git a/src/IO/WriteBufferFromEncryptedFile.h b/src/IO/WriteBufferFromEncryptedFile.h
index c6edcf765337..2b59bb468d13 100644
--- a/src/IO/WriteBufferFromEncryptedFile.h
+++ b/src/IO/WriteBufferFromEncryptedFile.h
@@ -40,7 +40,7 @@ class WriteBufferFromEncryptedFile : public WriteBufferDecorator<WriteBufferFrom
 
     FileEncryption::Encryptor encryptor;
 
-    Poco::Logger * log = &Poco::Logger::get("WriteBufferFromEncryptedFile");
+    LoggerPtr log = getLogger("WriteBufferFromEncryptedFile");
 };
 
 }
diff --git a/src/IO/WriteBufferFromHTTP.cpp b/src/IO/WriteBufferFromHTTP.cpp
index 3b2721e3bff7..8ddcbc03b84c 100644
--- a/src/IO/WriteBufferFromHTTP.cpp
+++ b/src/IO/WriteBufferFromHTTP.cpp
@@ -33,7 +33,7 @@ WriteBufferFromHTTP::WriteBufferFromHTTP(
     for (const auto & header: additional_headers)
         request.add(header.name, header.value);
 
-    LOG_TRACE((&Poco::Logger::get("WriteBufferToHTTP")), "Sending request to {}", uri.toString());
+    LOG_TRACE((getLogger("WriteBufferToHTTP")), "Sending request to {}", uri.toString());
 
     ostr = &session->sendRequest(request);
 }
diff --git a/src/IO/WriteBufferFromS3.h b/src/IO/WriteBufferFromS3.h
index 191e522c59a2..230f39b074e4 100644
--- a/src/IO/WriteBufferFromS3.h
+++ b/src/IO/WriteBufferFromS3.h
@@ -91,7 +91,7 @@ class WriteBufferFromS3 final : public WriteBufferFromFileBase
     const WriteSettings write_settings;
     const std::shared_ptr<const S3::Client> client_ptr;
     const std::optional<std::map<String, String>> object_metadata;
-    Poco::Logger * log = &Poco::Logger::get("WriteBufferFromS3");
+    LoggerPtr log = getLogger("WriteBufferFromS3");
     LogSeriesLimiterPtr limitedLog = std::make_shared<LogSeriesLimiter>(log, 1, 5);
 
     IBufferAllocationPolicyPtr buffer_allocation_policy;
diff --git a/src/Interpreters/Aggregator.cpp b/src/Interpreters/Aggregator.cpp
index 4171818d3e6a..331cd991ea19 100644
--- a/src/Interpreters/Aggregator.cpp
+++ b/src/Interpreters/Aggregator.cpp
@@ -105,7 +105,7 @@ class HashTablesStatistics
         if (const auto hint = cache->get(params.key))
         {
             LOG_TRACE(
-                &Poco::Logger::get("Aggregator"),
+                getLogger("Aggregator"),
                 "An entry for key={} found in cache: sum_of_sizes={}, median_size={}",
                 params.key,
                 hint->sum_of_sizes,
@@ -129,7 +129,7 @@ class HashTablesStatistics
             || hint->median_size < median_size)
         {
             LOG_TRACE(
-                &Poco::Logger::get("Aggregator"),
+                getLogger("Aggregator"),
                 "Statistics updated for key={}: new sum_of_sizes={}, median_size={}",
                 params.key,
                 sum_of_sizes,
@@ -229,7 +229,7 @@ void initDataVariantsWithSizeHint(
                 /// But we will also work with the big (i.e. not so cache friendly) HT from the beginning which may result in a slight slowdown.
                 /// So let's just do nothing.
                 LOG_TRACE(
-                    &Poco::Logger::get("Aggregator"),
+                    getLogger("Aggregator"),
                     "No space were preallocated in hash tables because 'max_size_to_preallocate_for_aggregation' has too small value: {}, "
                     "should be at least {}",
                     stats_collecting_params.max_size_to_preallocate_for_aggregation,
diff --git a/src/Interpreters/Aggregator.h b/src/Interpreters/Aggregator.h
index f4aa78043ca4..109bd0dd939a 100644
--- a/src/Interpreters/Aggregator.h
+++ b/src/Interpreters/Aggregator.h
@@ -1293,7 +1293,7 @@ class Aggregator final
     /// How many RAM were used to process the query before processing the first block.
     Int64 memory_usage_before_aggregation = 0;
 
-    Poco::Logger * log = &Poco::Logger::get("Aggregator");
+    LoggerPtr log = getLogger("Aggregator");
 
     /// For external aggregation.
     TemporaryDataOnDiskPtr tmp_data;
diff --git a/src/Interpreters/AsynchronousInsertQueue.cpp b/src/Interpreters/AsynchronousInsertQueue.cpp
index 63ee62cdef49..8206c31624ca 100644
--- a/src/Interpreters/AsynchronousInsertQueue.cpp
+++ b/src/Interpreters/AsynchronousInsertQueue.cpp
@@ -515,7 +515,7 @@ try
 
     SCOPE_EXIT(CurrentMetrics::sub(CurrentMetrics::PendingAsyncInsert, data->entries.size()));
 
-    const auto * log = &Poco::Logger::get("AsynchronousInsertQueue");
+    const auto log = getLogger("AsynchronousInsertQueue");
     const auto & insert_query = assert_cast<const ASTInsertQuery &>(*key.query);
 
     auto insert_context = Context::createCopy(global_context);
@@ -732,7 +732,7 @@ Chunk AsynchronousInsertQueue::processEntriesWithParsing(
     const std::list<InsertData::EntryPtr> & entries,
     const Block & header,
     const ContextPtr & insert_context,
-    const Poco::Logger * logger,
+    const LoggerPtr logger,
     LogFunc && add_to_async_insert_log)
 {
     size_t total_rows = 0;
diff --git a/src/Interpreters/AsynchronousInsertQueue.h b/src/Interpreters/AsynchronousInsertQueue.h
index 99394d0fb14d..f4bfdbd38a5c 100644
--- a/src/Interpreters/AsynchronousInsertQueue.h
+++ b/src/Interpreters/AsynchronousInsertQueue.h
@@ -214,7 +214,7 @@ class AsynchronousInsertQueue : public WithContext
     /// Uses async_insert_busy_timeout_ms and processBatchDeadlines()
     std::vector<ThreadFromGlobalPool> dump_by_first_update_threads;
 
-    Poco::Logger * log = &Poco::Logger::get("AsynchronousInsertQueue");
+    LoggerPtr log = getLogger("AsynchronousInsertQueue");
 
     PushResult pushDataChunk(ASTPtr query, DataChunk chunk, ContextPtr query_context);
     void preprocessInsertQuery(const ASTPtr & query, const ContextPtr & query_context);
@@ -230,7 +230,7 @@ class AsynchronousInsertQueue : public WithContext
         const std::list<InsertData::EntryPtr> & entries,
         const Block & header,
         const ContextPtr & insert_context,
-        const Poco::Logger * logger,
+        const LoggerPtr logger,
         LogFunc && add_to_async_insert_log);
 
     template <typename LogFunc>
diff --git a/src/Interpreters/Cache/FileCache.cpp b/src/Interpreters/Cache/FileCache.cpp
index 9c29a9c4a47c..d242544f787b 100644
--- a/src/Interpreters/Cache/FileCache.cpp
+++ b/src/Interpreters/Cache/FileCache.cpp
@@ -85,7 +85,7 @@ FileCache::FileCache(const std::string & cache_name, const FileCacheSettings & s
     , boundary_alignment(settings.boundary_alignment)
     , load_metadata_threads(settings.load_metadata_threads)
     , write_cache_per_user_directory(settings.write_cache_per_user_id_directory)
-    , log(&Poco::Logger::get("FileCache(" + cache_name + ")"))
+    , log(getLogger("FileCache(" + cache_name + ")"))
     , metadata(settings.base_path, settings.background_download_queue_size_limit, settings.background_download_threads, write_cache_per_user_directory)
 {
     if (settings.cache_policy == "LRU")
diff --git a/src/Interpreters/Cache/FileCache.h b/src/Interpreters/Cache/FileCache.h
index 64e03b739680..2de2f347999e 100644
--- a/src/Interpreters/Cache/FileCache.h
+++ b/src/Interpreters/Cache/FileCache.h
@@ -193,7 +193,7 @@ class FileCache : private boost::noncopyable
     size_t load_metadata_threads;
     const bool write_cache_per_user_directory;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::exception_ptr init_exception;
     std::atomic<bool> is_initialized = false;
diff --git a/src/Interpreters/Cache/FileSegment.cpp b/src/Interpreters/Cache/FileSegment.cpp
index 8e5d1fd757fc..9866d95f5efb 100644
--- a/src/Interpreters/Cache/FileSegment.cpp
+++ b/src/Interpreters/Cache/FileSegment.cpp
@@ -65,9 +65,9 @@ FileSegment::FileSegment(
     , queue_iterator(queue_iterator_)
     , cache(cache_)
 #ifdef ABORT_ON_LOGICAL_ERROR
-    , log(&Poco::Logger::get(fmt::format("FileSegment({}) : {}", key_.toString(), range().toString())))
+    , log(getLogger(fmt::format("FileSegment({}) : {}", key_.toString(), range().toString())))
 #else
-    , log(&Poco::Logger::get("FileSegment"))
+    , log(getLogger("FileSegment"))
 #endif
 {
     /// On creation, file segment state can be EMPTY, DOWNLOADED, DOWNLOADING.
diff --git a/src/Interpreters/Cache/FileSegment.h b/src/Interpreters/Cache/FileSegment.h
index cb718bcdd2ed..9a2e243131be 100644
--- a/src/Interpreters/Cache/FileSegment.h
+++ b/src/Interpreters/Cache/FileSegment.h
@@ -269,7 +269,7 @@ friend class FileCache; /// Because of reserved_size in tryReserve().
     FileCache * cache;
     std::condition_variable cv;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::atomic<size_t> hits_count = 0; /// cache hits.
     std::atomic<size_t> ref_count = 0; /// Used for getting snapshot state
diff --git a/src/Interpreters/Cache/LRUFileCachePriority.h b/src/Interpreters/Cache/LRUFileCachePriority.h
index 998b11723d81..a74a4b8b621a 100644
--- a/src/Interpreters/Cache/LRUFileCachePriority.h
+++ b/src/Interpreters/Cache/LRUFileCachePriority.h
@@ -71,7 +71,7 @@ class LRUFileCachePriority final : public IFileCachePriority
     friend class SLRUFileCachePriority;
 
     LRUQueue queue;
-    Poco::Logger * log = &Poco::Logger::get("LRUFileCachePriority");
+    LoggerPtr log = getLogger("LRUFileCachePriority");
     StatePtr state;
 
     void updateElementsCount(int64_t num);
diff --git a/src/Interpreters/Cache/Metadata.cpp b/src/Interpreters/Cache/Metadata.cpp
index 953413a8ef2c..b6f04807ad82 100644
--- a/src/Interpreters/Cache/Metadata.cpp
+++ b/src/Interpreters/Cache/Metadata.cpp
@@ -153,7 +153,7 @@ std::string KeyMetadata::getFileSegmentPath(const FileSegment & file_segment) co
     return cache_metadata->getFileSegmentPath(key, file_segment.offset(), file_segment.getKind(), user);
 }
 
-Poco::Logger * KeyMetadata::logger() const
+LoggerPtr KeyMetadata::logger() const
 {
     return cache_metadata->log;
 }
@@ -167,7 +167,7 @@ CacheMetadata::CacheMetadata(
     , cleanup_queue(std::make_shared<CleanupQueue>())
     , download_queue(std::make_shared<DownloadQueue>(background_download_queue_size_limit_))
     , write_cache_per_user_directory(write_cache_per_user_directory_)
-    , log(&Poco::Logger::get("CacheMetadata"))
+    , log(getLogger("CacheMetadata"))
     , download_threads_num(background_download_threads_)
 {
 }
diff --git a/src/Interpreters/Cache/Metadata.h b/src/Interpreters/Cache/Metadata.h
index 3003ad74e186..c02127cdef30 100644
--- a/src/Interpreters/Cache/Metadata.h
+++ b/src/Interpreters/Cache/Metadata.h
@@ -99,7 +99,7 @@ struct KeyMetadata : private std::map<size_t, FileSegmentMetadataPtr>,
     std::atomic<bool> created_base_directory = false;
 
     LockedKeyPtr lockNoStateCheck();
-    Poco::Logger * logger() const;
+    LoggerPtr logger() const;
     bool addToDownloadQueue(FileSegmentPtr file_segment);
     void addToCleanupQueue();
 };
@@ -177,7 +177,7 @@ class CacheMetadata : private boost::noncopyable
     const DownloadQueuePtr download_queue;
     const bool write_cache_per_user_directory;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     mutable std::shared_mutex key_prefix_directory_mutex;
 
     struct MetadataBucket : public std::unordered_map<FileCacheKey, KeyMetadataPtr>
diff --git a/src/Interpreters/Cache/QueryCache.h b/src/Interpreters/Cache/QueryCache.h
index 2dd4887dd20a..c574f3085e30 100644
--- a/src/Interpreters/Cache/QueryCache.h
+++ b/src/Interpreters/Cache/QueryCache.h
@@ -156,7 +156,7 @@ class QueryCache
         Cache::MappedPtr query_result TSA_GUARDED_BY(mutex) = std::make_shared<Entry>();
         std::atomic<bool> skip_insert = false;
         bool was_finalized = false;
-        Poco::Logger * logger = &Poco::Logger::get("QueryCache");
+        LoggerPtr logger = getLogger("QueryCache");
 
         Writer(Cache & cache_, const Key & key_,
             size_t max_entry_size_in_bytes_, size_t max_entry_size_in_rows_,
@@ -183,7 +183,7 @@ class QueryCache
         std::unique_ptr<SourceFromChunks> source_from_chunks;
         std::unique_ptr<SourceFromChunks> source_from_chunks_totals;
         std::unique_ptr<SourceFromChunks> source_from_chunks_extremes;
-        Poco::Logger * logger = &Poco::Logger::get("QueryCache");
+        LoggerPtr logger = getLogger("QueryCache");
         friend class QueryCache; /// for createReader()
     };
 
diff --git a/src/Interpreters/Cache/SLRUFileCachePriority.h b/src/Interpreters/Cache/SLRUFileCachePriority.h
index e949979ae611..d97fa80a6c78 100644
--- a/src/Interpreters/Cache/SLRUFileCachePriority.h
+++ b/src/Interpreters/Cache/SLRUFileCachePriority.h
@@ -58,7 +58,7 @@ class SLRUFileCachePriority : public IFileCachePriority
     double size_ratio;
     LRUFileCachePriority protected_queue;
     LRUFileCachePriority probationary_queue;
-    Poco::Logger * log = &Poco::Logger::get("SLRUFileCachePriority");
+    LoggerPtr log = getLogger("SLRUFileCachePriority");
 
     void increasePriority(SLRUIterator & iterator, const CacheGuard::Lock & lock);
 };
diff --git a/src/Interpreters/Cache/WriteBufferToFileSegment.cpp b/src/Interpreters/Cache/WriteBufferToFileSegment.cpp
index bf5b8712fb73..751e78a0a2d0 100644
--- a/src/Interpreters/Cache/WriteBufferToFileSegment.cpp
+++ b/src/Interpreters/Cache/WriteBufferToFileSegment.cpp
@@ -74,7 +74,7 @@ void WriteBufferToFileSegment::nextImpl()
     }
     catch (...)
     {
-        LOG_WARNING(&Poco::Logger::get("WriteBufferToFileSegment"), "Failed to write to the underlying buffer ({})", file_segment->getInfoForLog());
+        LOG_WARNING(getLogger("WriteBufferToFileSegment"), "Failed to write to the underlying buffer ({})", file_segment->getInfoForLog());
         throw;
     }
 
diff --git a/src/Interpreters/ClusterDiscovery.cpp b/src/Interpreters/ClusterDiscovery.cpp
index d0b00056cb4e..52b74597c4b4 100644
--- a/src/Interpreters/ClusterDiscovery.cpp
+++ b/src/Interpreters/ClusterDiscovery.cpp
@@ -116,7 +116,7 @@ ClusterDiscovery::ClusterDiscovery(
     const String & config_prefix)
     : context(Context::createCopy(context_))
     , current_node_name(toString(ServerUUID::get()))
-    , log(&Poco::Logger::get("ClusterDiscovery"))
+    , log(getLogger("ClusterDiscovery"))
 {
     LOG_DEBUG(log, "Cluster discovery is enabled");
 
@@ -553,7 +553,7 @@ bool ClusterDiscovery::NodeInfo::parse(const String & data, NodeInfo & result)
         else
         {
             LOG_ERROR(
-                &Poco::Logger::get("ClusterDiscovery"),
+                getLogger("ClusterDiscovery"),
                 "Unsupported version '{}' of data in zk node '{}'",
                 ver, data.size() < 1024 ? data : "[data too long]");
         }
@@ -561,7 +561,7 @@ bool ClusterDiscovery::NodeInfo::parse(const String & data, NodeInfo & result)
     catch (Poco::Exception & e)
     {
         LOG_WARNING(
-            &Poco::Logger::get("ClusterDiscovery"),
+            getLogger("ClusterDiscovery"),
             "Can't parse '{}' from node: {}",
             data.size() < 1024 ? data : "[data too long]", e.displayText());
         return false;
diff --git a/src/Interpreters/ClusterDiscovery.h b/src/Interpreters/ClusterDiscovery.h
index 8083fb6db413..756ed3d8d9be 100644
--- a/src/Interpreters/ClusterDiscovery.h
+++ b/src/Interpreters/ClusterDiscovery.h
@@ -152,7 +152,7 @@ class ClusterDiscovery
     bool is_initialized = false;
     ThreadFromGlobalPool main_thread;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp b/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp
index f8a070a6fde1..f0592735cafa 100644
--- a/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp
+++ b/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp
@@ -175,7 +175,7 @@ void SelectStreamFactory::createForShard(
             ProfileEvents::increment(ProfileEvents::DistributedConnectionMissingTable);
             if (shard_info.hasRemoteConnections())
             {
-                LOG_WARNING(&Poco::Logger::get("ClusterProxy::SelectStreamFactory"),
+                LOG_WARNING(getLogger("ClusterProxy::SelectStreamFactory"),
                     "There is no table {} on local replica of shard {}, will try remote replicas.",
                     main_table.getNameForLogs(), shard_info.shard_num);
                 emplace_remote_stream();
@@ -213,7 +213,7 @@ void SelectStreamFactory::createForShard(
 
         /// If we reached this point, local replica is stale.
         ProfileEvents::increment(ProfileEvents::DistributedConnectionStaleReplica);
-        LOG_WARNING(&Poco::Logger::get("ClusterProxy::SelectStreamFactory"), "Local replica of shard {} is stale (delay: {}s.)", shard_info.shard_num, local_delay);
+        LOG_WARNING(getLogger("ClusterProxy::SelectStreamFactory"), "Local replica of shard {} is stale (delay: {}s.)", shard_info.shard_num, local_delay);
 
         if (!settings.fallback_to_stale_replicas_for_distributed_queries)
         {
diff --git a/src/Interpreters/ClusterProxy/executeQuery.cpp b/src/Interpreters/ClusterProxy/executeQuery.cpp
index 5865e669e47b..35451e1d774c 100644
--- a/src/Interpreters/ClusterProxy/executeQuery.cpp
+++ b/src/Interpreters/ClusterProxy/executeQuery.cpp
@@ -42,7 +42,7 @@ ContextMutablePtr updateSettingsForCluster(const Cluster & cluster,
     const Settings & settings,
     const StorageID & main_table,
     ASTPtr additional_filter_ast,
-    Poco::Logger * log,
+    LoggerPtr log,
     const DistributedSettings * distributed_settings)
 {
     Settings new_settings = settings;
@@ -202,7 +202,7 @@ void executeQuery(
     const StorageID & main_table,
     const ASTPtr & table_func_ptr,
     SelectStreamFactory & stream_factory,
-    Poco::Logger * log,
+    LoggerPtr log,
     const ASTPtr & query_ast,
     ContextPtr context,
     const SelectQueryInfo & query_info,
@@ -347,14 +347,14 @@ void executeQueryWithParallelReplicas(
         if (settings.use_hedged_requests.changed)
         {
             LOG_WARNING(
-                &Poco::Logger::get("executeQueryWithParallelReplicas"),
+                getLogger("executeQueryWithParallelReplicas"),
                 "Setting 'use_hedged_requests' explicitly with enabled 'allow_experimental_parallel_reading_from_replicas' has no effect. "
                 "Hedged connections are not used for parallel reading from replicas");
         }
         else
         {
             LOG_INFO(
-                &Poco::Logger::get("executeQueryWithParallelReplicas"),
+                getLogger("executeQueryWithParallelReplicas"),
                 "Disabling 'use_hedged_requests' in favor of 'allow_experimental_parallel_reading_from_replicas'. Hedged connections are "
                 "not used for parallel reading from replicas");
         }
@@ -390,7 +390,7 @@ void executeQueryWithParallelReplicas(
 
         chassert(shard_count == not_optimized_cluster->getShardsAddresses().size());
 
-        LOG_DEBUG(&Poco::Logger::get("executeQueryWithParallelReplicas"), "Parallel replicas query in shard scope: shard_num={} cluster={}",
+        LOG_DEBUG(getLogger("executeQueryWithParallelReplicas"), "Parallel replicas query in shard scope: shard_num={} cluster={}",
                   shard_num, not_optimized_cluster->getName());
 
         // get cluster for shard specified by shard_num
@@ -417,7 +417,7 @@ void executeQueryWithParallelReplicas(
         getThrottler(new_context),
         std::move(scalars),
         std::move(external_tables),
-        &Poco::Logger::get("ReadFromParallelRemoteReplicasStep"),
+        getLogger("ReadFromParallelRemoteReplicasStep"),
         std::move(storage_limits));
 
     query_plan.addStep(std::move(read_from_remote));
diff --git a/src/Interpreters/ClusterProxy/executeQuery.h b/src/Interpreters/ClusterProxy/executeQuery.h
index a19ece0bbdcc..bbc3c6c9e49c 100644
--- a/src/Interpreters/ClusterProxy/executeQuery.h
+++ b/src/Interpreters/ClusterProxy/executeQuery.h
@@ -43,7 +43,7 @@ ContextMutablePtr updateSettingsForCluster(const Cluster & cluster,
     const Settings & settings,
     const StorageID & main_table,
     ASTPtr additional_filter_ast = nullptr,
-    Poco::Logger * log = nullptr,
+    LoggerPtr log = nullptr,
     const DistributedSettings * distributed_settings = nullptr);
 
 using AdditionalShardFilterGenerator = std::function<ASTPtr(uint64_t)>;
@@ -57,7 +57,7 @@ void executeQuery(
     const StorageID & main_table,
     const ASTPtr & table_func_ptr,
     SelectStreamFactory & stream_factory,
-    Poco::Logger * log,
+    LoggerPtr log,
     const ASTPtr & query_ast,
     ContextPtr context,
     const SelectQueryInfo & query_info,
diff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp
index 9778a02f1fa9..2472fbbe5960 100644
--- a/src/Interpreters/Context.cpp
+++ b/src/Interpreters/Context.cpp
@@ -198,7 +198,7 @@ namespace ErrorCodes
   */
 struct ContextSharedPart : boost::noncopyable
 {
-    Poco::Logger * log = &Poco::Logger::get("Context");
+    LoggerPtr log = getLogger("Context");
 
     /// For access of most of shared objects.
     mutable ContextSharedMutex mutex;
@@ -1011,7 +1011,7 @@ void Context::setFilesystemCacheUser(const String & user)
     shared->filesystem_cache_user = user;
 }
 
-static void setupTmpPath(Poco::Logger * log, const std::string & path)
+static void setupTmpPath(LoggerPtr log, const std::string & path)
 try
 {
     LOG_DEBUG(log, "Setting up {} to store temporary data in it", path);
@@ -4292,7 +4292,7 @@ void Context::setDefaultProfiles(const Poco::Util::AbstractConfiguration & confi
     shared->system_profile_name = config.getString("system_profile", shared->default_profile_name);
     setCurrentProfile(shared->system_profile_name);
 
-    applySettingsQuirks(settings, &Poco::Logger::get("SettingsQuirks"));
+    applySettingsQuirks(settings, getLogger("SettingsQuirks"));
 
     shared->buffer_profile_name = config.getString("buffer_profile", shared->system_profile_name);
     buffer_context = Context::createCopy(shared_from_this());
diff --git a/src/Interpreters/CrossToInnerJoinVisitor.cpp b/src/Interpreters/CrossToInnerJoinVisitor.cpp
index 005450c2a2c8..42af164f4ad3 100644
--- a/src/Interpreters/CrossToInnerJoinVisitor.cpp
+++ b/src/Interpreters/CrossToInnerJoinVisitor.cpp
@@ -249,7 +249,7 @@ void CrossToInnerJoinMatcher::visit(ASTSelectQuery & select, ASTPtr &, Data & da
                 ASTPtr on_expr = makeOnExpression(expr_it->second);
                 if (rewritten = joined.rewriteCrossToInner(on_expr); rewritten)
                 {
-                    LOG_DEBUG(&Poco::Logger::get("CrossToInnerJoin"), "Rewritten '{}' to '{}'", query_before, queryToString(*joined.tableJoin()));
+                    LOG_DEBUG(getLogger("CrossToInnerJoin"), "Rewritten '{}' to '{}'", query_before, queryToString(*joined.tableJoin()));
                 }
             }
 
diff --git a/src/Interpreters/DDLTask.cpp b/src/Interpreters/DDLTask.cpp
index d418be51cc59..90eec421abf4 100644
--- a/src/Interpreters/DDLTask.cpp
+++ b/src/Interpreters/DDLTask.cpp
@@ -215,7 +215,7 @@ ContextMutablePtr DDLTaskBase::makeQueryContext(ContextPtr from_context, const Z
 }
 
 
-bool DDLTask::findCurrentHostID(ContextPtr global_context, Poco::Logger * log, const ZooKeeperPtr & zookeeper, const std::optional<std::string> & config_host_name)
+bool DDLTask::findCurrentHostID(ContextPtr global_context, LoggerPtr log, const ZooKeeperPtr & zookeeper, const std::optional<std::string> & config_host_name)
 {
     bool host_in_hostlist = false;
     std::exception_ptr first_exception = nullptr;
@@ -312,7 +312,7 @@ bool DDLTask::findCurrentHostID(ContextPtr global_context, Poco::Logger * log, c
     return host_in_hostlist;
 }
 
-void DDLTask::setClusterInfo(ContextPtr context, Poco::Logger * log)
+void DDLTask::setClusterInfo(ContextPtr context, LoggerPtr log)
 {
     auto * query_on_cluster = dynamic_cast<ASTQueryWithOnCluster *>(query.get());
     if (!query_on_cluster)
diff --git a/src/Interpreters/DDLTask.h b/src/Interpreters/DDLTask.h
index bc45b46bf0f2..5a8a5bfb1842 100644
--- a/src/Interpreters/DDLTask.h
+++ b/src/Interpreters/DDLTask.h
@@ -146,9 +146,9 @@ struct DDLTask : public DDLTaskBase
 {
     DDLTask(const String & name, const String & path) : DDLTaskBase(name, path) {}
 
-    bool findCurrentHostID(ContextPtr global_context, Poco::Logger * log, const ZooKeeperPtr & zookeeper, const std::optional<std::string> & config_host_name);
+    bool findCurrentHostID(ContextPtr global_context, LoggerPtr log, const ZooKeeperPtr & zookeeper, const std::optional<std::string> & config_host_name);
 
-    void setClusterInfo(ContextPtr context, Poco::Logger * log);
+    void setClusterInfo(ContextPtr context, LoggerPtr log);
 
     String getShardID() const override;
 
diff --git a/src/Interpreters/DDLWorker.cpp b/src/Interpreters/DDLWorker.cpp
index c0611dfaf7df..fd807d54eff6 100644
--- a/src/Interpreters/DDLWorker.cpp
+++ b/src/Interpreters/DDLWorker.cpp
@@ -79,7 +79,7 @@ DDLWorker::DDLWorker(
     const CurrentMetrics::Metric * max_entry_metric_,
     const CurrentMetrics::Metric * max_pushed_entry_metric_)
     : context(Context::createCopy(context_))
-    , log(&Poco::Logger::get(logger_name))
+    , log(getLogger(logger_name))
     , pool_size(pool_size_)
     , max_entry_metric(max_entry_metric_)
     , max_pushed_entry_metric(max_pushed_entry_metric_)
diff --git a/src/Interpreters/DDLWorker.h b/src/Interpreters/DDLWorker.h
index adc9a491d815..9eb6606e73cd 100644
--- a/src/Interpreters/DDLWorker.h
+++ b/src/Interpreters/DDLWorker.h
@@ -151,7 +151,7 @@ class DDLWorker
     void runCleanupThread();
 
     ContextMutablePtr context;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::optional<std::string> config_host_name; /// host_name from config
 
diff --git a/src/Interpreters/DNSCacheUpdater.cpp b/src/Interpreters/DNSCacheUpdater.cpp
index c6a38d85acbb..4769395acaab 100644
--- a/src/Interpreters/DNSCacheUpdater.cpp
+++ b/src/Interpreters/DNSCacheUpdater.cpp
@@ -24,7 +24,7 @@ void DNSCacheUpdater::run()
     /// Reload cluster config if IP of any host has been changed since last update.
     if (resolver.updateCache(max_consecutive_failures))
     {
-        LOG_INFO(&Poco::Logger::get("DNSCacheUpdater"), "IPs of some hosts have been changed. Will reload cluster config.");
+        LOG_INFO(getLogger("DNSCacheUpdater"), "IPs of some hosts have been changed. Will reload cluster config.");
         try
         {
             getContext()->reloadClusterConfig();
@@ -45,7 +45,7 @@ void DNSCacheUpdater::run()
 
 void DNSCacheUpdater::start()
 {
-    LOG_INFO(&Poco::Logger::get("DNSCacheUpdater"), "Update period {} seconds", update_period_seconds);
+    LOG_INFO(getLogger("DNSCacheUpdater"), "Update period {} seconds", update_period_seconds);
     task_handle->activateAndSchedule();
 }
 
diff --git a/src/Interpreters/DatabaseCatalog.cpp b/src/Interpreters/DatabaseCatalog.cpp
index 138ec588202f..87985d1d12b5 100644
--- a/src/Interpreters/DatabaseCatalog.cpp
+++ b/src/Interpreters/DatabaseCatalog.cpp
@@ -827,7 +827,7 @@ DatabaseCatalog::DatabaseCatalog(ContextMutablePtr global_context_)
     , referential_dependencies{"ReferentialDeps"}
     , loading_dependencies{"LoadingDeps"}
     , view_dependencies{"ViewDeps"}
-    , log(&Poco::Logger::get("DatabaseCatalog"))
+    , log(getLogger("DatabaseCatalog"))
     , first_async_drop_in_queue(tables_marked_dropped.end())
 {
 }
diff --git a/src/Interpreters/DatabaseCatalog.h b/src/Interpreters/DatabaseCatalog.h
index 19882b0b8281..beb73e3ef96a 100644
--- a/src/Interpreters/DatabaseCatalog.h
+++ b/src/Interpreters/DatabaseCatalog.h
@@ -318,7 +318,7 @@ class DatabaseCatalog : boost::noncopyable, WithMutableContext
     /// View dependencies between a source table and its view.
     TablesDependencyGraph view_dependencies TSA_GUARDED_BY(databases_mutex);
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::atomic_bool is_shutting_down = false;
 
diff --git a/src/Interpreters/DirectJoin.cpp b/src/Interpreters/DirectJoin.cpp
index 431f216436dc..3255b56b3be6 100644
--- a/src/Interpreters/DirectJoin.cpp
+++ b/src/Interpreters/DirectJoin.cpp
@@ -67,7 +67,7 @@ DirectKeyValueJoin::DirectKeyValueJoin(std::shared_ptr<TableJoin> table_join_,
     : table_join(table_join_)
     , storage(storage_)
     , right_sample_block(right_sample_block_)
-    , log(&Poco::Logger::get("DirectKeyValueJoin"))
+    , log(getLogger("DirectKeyValueJoin"))
 {
     if (!table_join->oneDisjunct() ||
         table_join->getOnlyClause().key_names_left.size() != 1 ||
diff --git a/src/Interpreters/DirectJoin.h b/src/Interpreters/DirectJoin.h
index 5f6643148181..ef8d12a1b8f1 100644
--- a/src/Interpreters/DirectJoin.h
+++ b/src/Interpreters/DirectJoin.h
@@ -60,7 +60,7 @@ class DirectKeyValueJoin : public IJoin
     Block right_sample_block;
     Block right_sample_block_with_storage_column_names;
     Block sample_block_with_columns_to_add;
-    Poco::Logger * log;
+    LoggerPtr log;
 
 };
 
diff --git a/src/Interpreters/EmbeddedDictionaries.cpp b/src/Interpreters/EmbeddedDictionaries.cpp
index 6c0ccce66b57..1435d16cb073 100644
--- a/src/Interpreters/EmbeddedDictionaries.cpp
+++ b/src/Interpreters/EmbeddedDictionaries.cpp
@@ -125,7 +125,7 @@ EmbeddedDictionaries::EmbeddedDictionaries(
     ContextPtr context_,
     const bool throw_on_error)
     : WithContext(context_)
-    , log(&Poco::Logger::get("EmbeddedDictionaries"))
+    , log(getLogger("EmbeddedDictionaries"))
     , geo_dictionaries_loader(std::move(geo_dictionaries_loader_))
     , reload_period(getContext()->getConfigRef().getInt("builtin_dictionaries_reload_interval", 3600))
 {
diff --git a/src/Interpreters/EmbeddedDictionaries.h b/src/Interpreters/EmbeddedDictionaries.h
index e71098636fe7..b537146e92d7 100644
--- a/src/Interpreters/EmbeddedDictionaries.h
+++ b/src/Interpreters/EmbeddedDictionaries.h
@@ -24,7 +24,7 @@ class GeoDictionariesLoader;
 class EmbeddedDictionaries : WithContext
 {
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
 
     MultiVersion<RegionsHierarchies> regions_hierarchies;
     MultiVersion<RegionsNames> regions_names;
diff --git a/src/Interpreters/ExpressionAnalyzer.cpp b/src/Interpreters/ExpressionAnalyzer.cpp
index 5c628436d609..fefbd67bfc17 100644
--- a/src/Interpreters/ExpressionAnalyzer.cpp
+++ b/src/Interpreters/ExpressionAnalyzer.cpp
@@ -120,7 +120,7 @@ bool allowEarlyConstantFolding(const ActionsDAG & actions, const Settings & sett
     return true;
 }
 
-Poco::Logger * getLogger() { return &Poco::Logger::get("ExpressionAnalyzer"); }
+LoggerPtr getLogger() { return ::getLogger("ExpressionAnalyzer"); }
 
 }
 
diff --git a/src/Interpreters/ExpressionJIT.cpp b/src/Interpreters/ExpressionJIT.cpp
index 0eacb598fbe9..16275b23053f 100644
--- a/src/Interpreters/ExpressionJIT.cpp
+++ b/src/Interpreters/ExpressionJIT.cpp
@@ -38,10 +38,9 @@ static CHJIT & getJITInstance()
     return jit;
 }
 
-static Poco::Logger * getLogger()
+static LoggerPtr getLogger()
 {
-    static Poco::Logger & logger = Poco::Logger::get("ExpressionJIT");
-    return &logger;
+    return ::getLogger("ExpressionJIT");
 }
 
 class CompiledFunctionHolder : public CompiledExpressionCacheEntry
diff --git a/src/Interpreters/ExternalDictionariesLoader.cpp b/src/Interpreters/ExternalDictionariesLoader.cpp
index 46171c95cb0f..74984de00643 100644
--- a/src/Interpreters/ExternalDictionariesLoader.cpp
+++ b/src/Interpreters/ExternalDictionariesLoader.cpp
@@ -22,7 +22,7 @@ namespace ErrorCodes
 
 /// Must not acquire Context lock in constructor to avoid possibility of deadlocks.
 ExternalDictionariesLoader::ExternalDictionariesLoader(ContextPtr global_context_)
-    : ExternalLoader("external dictionary", &Poco::Logger::get("ExternalDictionariesLoader"))
+    : ExternalLoader("external dictionary", getLogger("ExternalDictionariesLoader"))
     , WithContext(global_context_)
 {
     setConfigSettings({"dictionary", "name", "database", "uuid"});
diff --git a/src/Interpreters/ExternalLoader.cpp b/src/Interpreters/ExternalLoader.cpp
index 56d480d87354..36664cbd06fb 100644
--- a/src/Interpreters/ExternalLoader.cpp
+++ b/src/Interpreters/ExternalLoader.cpp
@@ -95,7 +95,7 @@ namespace
 class ExternalLoader::LoadablesConfigReader : private boost::noncopyable
 {
 public:
-    LoadablesConfigReader(const String & type_name_, Poco::Logger * log_)
+    LoadablesConfigReader(const String & type_name_, LoggerPtr log_)
         : type_name(type_name_), log(log_)
     {
     }
@@ -377,7 +377,7 @@ class ExternalLoader::LoadablesConfigReader : private boost::noncopyable
     }
 
     const String type_name;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::mutex mutex;
     ExternalLoaderConfigSettings settings;
@@ -401,7 +401,7 @@ class ExternalLoader::LoadingDispatcher : private boost::noncopyable
     LoadingDispatcher(
         const CreateObjectFunction & create_object_function_,
         const String & type_name_,
-        Poco::Logger * log_)
+        LoggerPtr log_)
         : create_object(create_object_function_)
         , type_name(type_name_)
         , log(log_)
@@ -1193,7 +1193,7 @@ class ExternalLoader::LoadingDispatcher : private boost::noncopyable
 
     const CreateObjectFunction create_object;
     const String type_name;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     mutable std::mutex mutex;
     std::condition_variable event;
@@ -1273,7 +1273,7 @@ class ExternalLoader::PeriodicUpdater : private boost::noncopyable
 };
 
 
-ExternalLoader::ExternalLoader(const String & type_name_, Poco::Logger * log_)
+ExternalLoader::ExternalLoader(const String & type_name_, LoggerPtr log_)
     : config_files_reader(std::make_unique<LoadablesConfigReader>(type_name_, log_))
     , loading_dispatcher(std::make_unique<LoadingDispatcher>(
           [this](auto && a, auto && b, auto && c) { return createObject(a, b, c); },
diff --git a/src/Interpreters/ExternalLoader.h b/src/Interpreters/ExternalLoader.h
index 49b4ea77e0d3..a5d83bdab50a 100644
--- a/src/Interpreters/ExternalLoader.h
+++ b/src/Interpreters/ExternalLoader.h
@@ -8,6 +8,7 @@
 #include <Interpreters/IExternalLoaderConfigRepository.h>
 #include <base/scope_guard.h>
 #include <Common/ExternalLoaderStatus.h>
+#include <Common/Logger.h>
 #include <Core/Types.h>
 
 namespace Poco { class Logger; }
@@ -84,7 +85,7 @@ class ExternalLoader
     template <typename T>
     static constexpr bool is_vector_load_result_type = std::is_same_v<T, LoadResults> || std::is_same_v<T, Loadables>;
 
-    ExternalLoader(const String & type_name_, Poco::Logger * log);
+    ExternalLoader(const String & type_name_, LoggerPtr log);
     virtual ~ExternalLoader();
 
     /// Adds a repository which will be used to read configurations from.
@@ -230,7 +231,7 @@ class ExternalLoader
     std::unique_ptr<PeriodicUpdater> periodic_updater;
 
     const String type_name;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Interpreters/FullSortingMergeJoin.h b/src/Interpreters/FullSortingMergeJoin.h
index 3fc9f8920ed7..7688d44f7a96 100644
--- a/src/Interpreters/FullSortingMergeJoin.h
+++ b/src/Interpreters/FullSortingMergeJoin.h
@@ -25,7 +25,7 @@ class FullSortingMergeJoin : public IJoin
         : table_join(table_join_)
         , right_sample_block(right_sample_block_)
     {
-        LOG_TRACE(&Poco::Logger::get("FullSortingMergeJoin"), "Will use full sorting merge join");
+        LOG_TRACE(getLogger("FullSortingMergeJoin"), "Will use full sorting merge join");
     }
 
     std::string getName() const override { return "FullSortingMergeJoin"; }
diff --git a/src/Interpreters/GraceHashJoin.cpp b/src/Interpreters/GraceHashJoin.cpp
index 26d666a89133..5fb92a68a297 100644
--- a/src/Interpreters/GraceHashJoin.cpp
+++ b/src/Interpreters/GraceHashJoin.cpp
@@ -121,7 +121,7 @@ class GraceHashJoin::FileBucket : boost::noncopyable
 public:
     using BucketLock = std::unique_lock<std::mutex>;
 
-    explicit FileBucket(size_t bucket_index_, TemporaryFileStream & left_file_, TemporaryFileStream & right_file_, Poco::Logger * log_)
+    explicit FileBucket(size_t bucket_index_, TemporaryFileStream & left_file_, TemporaryFileStream & right_file_, LoggerPtr log_)
         : idx{bucket_index_}
         , left_file{left_file_}
         , right_file{right_file_}
@@ -223,7 +223,7 @@ class GraceHashJoin::FileBucket : boost::noncopyable
 
     std::atomic<State> state;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 namespace
@@ -261,7 +261,7 @@ GraceHashJoin::GraceHashJoin(
     const Block & right_sample_block_,
     TemporaryDataOnDiskScopePtr tmp_data_,
     bool any_take_last_row_)
-    : log{&Poco::Logger::get("GraceHashJoin")}
+    : log{getLogger("GraceHashJoin")}
     , context{context_}
     , table_join{std::move(table_join_)}
     , left_sample_block{left_sample_block_}
@@ -403,7 +403,7 @@ void GraceHashJoin::addBuckets(const size_t bucket_count)
         catch (...)
         {
             LOG_ERROR(
-                &Poco::Logger::get("GraceHashJoin"),
+                getLogger("GraceHashJoin"),
                 "Can't create bucket {} due to error: {}",
                 current_size + i,
                 getCurrentExceptionMessage(false));
diff --git a/src/Interpreters/GraceHashJoin.h b/src/Interpreters/GraceHashJoin.h
index 2cadeee10b97..ff396683230d 100644
--- a/src/Interpreters/GraceHashJoin.h
+++ b/src/Interpreters/GraceHashJoin.h
@@ -120,7 +120,7 @@ class GraceHashJoin final : public IJoin
     /// Structure block to store in the HashJoin according to sample_block.
     Block prepareRightBlock(const Block & block);
 
-    Poco::Logger * log;
+    LoggerPtr log;
     ContextPtr context;
     std::shared_ptr<TableJoin> table_join;
     Block left_sample_block;
diff --git a/src/Interpreters/HashJoin.cpp b/src/Interpreters/HashJoin.cpp
index 467cc4c25319..33dc178ca00c 100644
--- a/src/Interpreters/HashJoin.cpp
+++ b/src/Interpreters/HashJoin.cpp
@@ -245,7 +245,7 @@ HashJoin::HashJoin(std::shared_ptr<TableJoin> table_join_, const Block & right_s
     , right_sample_block(right_sample_block_)
     , max_joined_block_rows(table_join->maxJoinedBlockRows())
     , instance_log_id(!instance_id_.empty() ? "(" + instance_id_ + ") " : "")
-    , log(&Poco::Logger::get("HashJoin"))
+    , log(getLogger("HashJoin"))
 {
     LOG_TRACE(log, "{}Keys: {}, datatype: {}, kind: {}, strictness: {}, right header: {}",
         instance_log_id, TableJoin::formatClauses(table_join->getClauses(), true), data->type, kind, strictness, right_sample_block.dumpStructure());
diff --git a/src/Interpreters/HashJoin.h b/src/Interpreters/HashJoin.h
index 17f003adc4b2..29bb90700092 100644
--- a/src/Interpreters/HashJoin.h
+++ b/src/Interpreters/HashJoin.h
@@ -446,7 +446,7 @@ class HashJoin : public IJoin
     /// Several instances can be created, for example, in GraceHashJoin to handle different buckets
     String instance_log_id;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Should be set via setLock to protect hash table from modification from StorageJoin
     /// If set HashJoin instance is not available for modification (addBlockToJoin)
diff --git a/src/Interpreters/InternalTextLogsQueue.cpp b/src/Interpreters/InternalTextLogsQueue.cpp
index 3be58a11beba..ca8461937ac3 100644
--- a/src/Interpreters/InternalTextLogsQueue.cpp
+++ b/src/Interpreters/InternalTextLogsQueue.cpp
@@ -43,7 +43,7 @@ void InternalTextLogsQueue::pushBlock(Block && log_block)
     if (blocksHaveEqualStructure(sample_block, log_block))
         (void)(emplace(log_block.mutateColumns()));
     else
-        LOG_WARNING(&Poco::Logger::get("InternalTextLogsQueue"), "Log block have different structure");
+        LOG_WARNING(getLogger("InternalTextLogsQueue"), "Log block have different structure");
 }
 
 std::string_view InternalTextLogsQueue::getPriorityName(int priority)
diff --git a/src/Interpreters/InterpreterCheckQuery.cpp b/src/Interpreters/InterpreterCheckQuery.cpp
index 0cc4afd62f22..98a281bd5ade 100644
--- a/src/Interpreters/InterpreterCheckQuery.cpp
+++ b/src/Interpreters/InterpreterCheckQuery.cpp
@@ -149,7 +149,7 @@ class TableCheckTask : public ChunkInfo
 class TableCheckSource : public ISource
 {
 public:
-    TableCheckSource(Strings databases_, ContextPtr context_, Poco::Logger * log_)
+    TableCheckSource(Strings databases_, ContextPtr context_, LoggerPtr log_)
         : ISource(getSingleValueBlock(0))
         , databases(databases_)
         , context(context_)
@@ -157,7 +157,7 @@ class TableCheckSource : public ISource
     {
     }
 
-    TableCheckSource(std::shared_ptr<TableCheckTask> table_check_task_, Poco::Logger * log_)
+    TableCheckSource(std::shared_ptr<TableCheckTask> table_check_task_, LoggerPtr log_)
         : ISource(getSingleValueBlock(0))
         , table_check_task(table_check_task_)
         , log(log_)
@@ -260,14 +260,14 @@ class TableCheckSource : public ISource
 
     ContextPtr context;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 /// Receives TableCheckTask and returns CheckResult converted to sinle-row chunk
 class TableCheckWorkerProcessor : public ISimpleTransform
 {
 public:
-    TableCheckWorkerProcessor(bool with_table_name_, Poco::Logger * log_)
+    TableCheckWorkerProcessor(bool with_table_name_, LoggerPtr log_)
         : ISimpleTransform(getSingleValueBlock(0), getHeaderForCheckResult(with_table_name_), true)
         , with_table_name(with_table_name_)
         , log(log_)
@@ -308,7 +308,7 @@ class TableCheckWorkerProcessor : public ISimpleTransform
     /// If true, then output will contain columns with database and table names
     bool with_table_name;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 /// Accumulates all results and returns single value
diff --git a/src/Interpreters/InterpreterCheckQuery.h b/src/Interpreters/InterpreterCheckQuery.h
index 5ffd1d4298f6..4bba3ed780ca 100644
--- a/src/Interpreters/InterpreterCheckQuery.h
+++ b/src/Interpreters/InterpreterCheckQuery.h
@@ -19,7 +19,7 @@ class InterpreterCheckQuery : public IInterpreter, WithContext
 private:
     ASTPtr query_ptr;
 
-    Poco::Logger * log = &Poco::Logger::get("InterpreterCheckQuery");
+    LoggerPtr log = getLogger("InterpreterCheckQuery");
 };
 
 }
diff --git a/src/Interpreters/InterpreterCreateQuery.cpp b/src/Interpreters/InterpreterCreateQuery.cpp
index d002cc6d9806..9ce1c8566220 100644
--- a/src/Interpreters/InterpreterCreateQuery.cpp
+++ b/src/Interpreters/InterpreterCreateQuery.cpp
@@ -1214,7 +1214,7 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)
     }
     else if (create.attach && !create.attach_short_syntax && getContext()->getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY)
     {
-        auto * log = &Poco::Logger::get("InterpreterCreateQuery");
+        auto log = getLogger("InterpreterCreateQuery");
         LOG_WARNING(log, "ATTACH TABLE query with full table definition is not recommended: "
                          "use either ATTACH TABLE {}; to attach existing table "
                          "or CREATE TABLE {} <table definition>; to create new table "
@@ -1455,7 +1455,7 @@ bool InterpreterCreateQuery::doCreateTable(ASTCreateQuery & create,
             /// so the existing directory probably contains some leftovers from previous unsuccessful attempts to create the table
 
             fs::path trash_path = fs::path{getContext()->getPath()} / "trash" / data_path / getHexUIntLowercase(thread_local_rng());
-            LOG_WARNING(&Poco::Logger::get("InterpreterCreateQuery"), "Directory for {} data {} already exists. Will move it to {}",
+            LOG_WARNING(getLogger("InterpreterCreateQuery"), "Directory for {} data {} already exists. Will move it to {}",
                         Poco::toLower(storage_name), String(data_path), trash_path);
             fs::create_directories(trash_path.parent_path());
             renameNoReplace(full_data_path, trash_path);
diff --git a/src/Interpreters/InterpreterKillQueryQuery.cpp b/src/Interpreters/InterpreterKillQueryQuery.cpp
index 5efffdaa194a..3431cd5e568a 100644
--- a/src/Interpreters/InterpreterKillQueryQuery.cpp
+++ b/src/Interpreters/InterpreterKillQueryQuery.cpp
@@ -161,7 +161,7 @@ class SyncKillQuerySource : public ISource
                 if (curr_process.processed)
                     continue;
 
-                LOG_DEBUG(&Poco::Logger::get("KillQuery"), "Will kill query {} (synchronously)", curr_process.query_id);
+                LOG_DEBUG(getLogger("KillQuery"), "Will kill query {} (synchronously)", curr_process.query_id);
 
                 auto code = process_list.sendCancelToQuery(curr_process.query_id, curr_process.user, true);
 
@@ -229,7 +229,7 @@ BlockIO InterpreterKillQueryQuery::execute()
             for (const auto & query_desc : queries_to_stop)
             {
                 if (!query.test)
-                    LOG_DEBUG(&Poco::Logger::get("KillQuery"), "Will kill query {} (asynchronously)", query_desc.query_id);
+                    LOG_DEBUG(getLogger("KillQuery"), "Will kill query {} (asynchronously)", query_desc.query_id);
                 auto code = (query.test) ? CancellationCode::Unknown : process_list.sendCancelToQuery(query_desc.query_id, query_desc.user, true);
                 insertResultRow(query_desc.source_num, code, processes_block, header, res_columns);
             }
diff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp
index 4e4e25617e4c..2d994483ba83 100644
--- a/src/Interpreters/InterpreterSelectQuery.cpp
+++ b/src/Interpreters/InterpreterSelectQuery.cpp
@@ -381,7 +381,7 @@ InterpreterSelectQuery::InterpreterSelectQuery(
     : IInterpreterUnionOrSelectQuery(options_.modify_inplace ? query_ptr_ : query_ptr_->clone(), context_, options_)
     , storage(storage_)
     , input_pipe(std::move(input_pipe_))
-    , log(&Poco::Logger::get("InterpreterSelectQuery"))
+    , log(getLogger("InterpreterSelectQuery"))
     , metadata_snapshot(metadata_snapshot_)
     , prepared_sets(prepared_sets_)
 {
diff --git a/src/Interpreters/InterpreterSelectQuery.h b/src/Interpreters/InterpreterSelectQuery.h
index fbb53d71755c..c307e457649c 100644
--- a/src/Interpreters/InterpreterSelectQuery.h
+++ b/src/Interpreters/InterpreterSelectQuery.h
@@ -253,7 +253,7 @@ class InterpreterSelectQuery : public IInterpreterUnionOrSelectQuery
     /// Used when we read from prepared input, not table or subquery.
     std::optional<Pipe> input_pipe;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     StorageMetadataPtr metadata_snapshot;
     StorageSnapshotPtr storage_snapshot;
 
diff --git a/src/Interpreters/InterpreterSystemQuery.cpp b/src/Interpreters/InterpreterSystemQuery.cpp
index 8a242cee213d..9a80553f1493 100644
--- a/src/Interpreters/InterpreterSystemQuery.cpp
+++ b/src/Interpreters/InterpreterSystemQuery.cpp
@@ -221,7 +221,7 @@ void InterpreterSystemQuery::startStopAction(StorageActionBlockType action_type,
 
 void InterpreterSystemQuery::startStopActionInDatabase(StorageActionBlockType action_type, bool start,
                                                        const String & database_name, const DatabasePtr & database,
-                                                       const ContextPtr & local_context, Poco::Logger * log)
+                                                       const ContextPtr & local_context, LoggerPtr log)
 {
     auto manager = local_context->getActionLocksManager();
     auto access = local_context->getAccess();
@@ -251,7 +251,7 @@ void InterpreterSystemQuery::startStopActionInDatabase(StorageActionBlockType ac
 
 
 InterpreterSystemQuery::InterpreterSystemQuery(const ASTPtr & query_ptr_, ContextMutablePtr context_)
-        : WithMutableContext(context_), query_ptr(query_ptr_->clone()), log(&Poco::Logger::get("InterpreterSystemQuery"))
+        : WithMutableContext(context_), query_ptr(query_ptr_->clone()), log(getLogger("InterpreterSystemQuery"))
 {
 }
 
diff --git a/src/Interpreters/InterpreterSystemQuery.h b/src/Interpreters/InterpreterSystemQuery.h
index 89de7402b4d3..1419c430aca2 100644
--- a/src/Interpreters/InterpreterSystemQuery.h
+++ b/src/Interpreters/InterpreterSystemQuery.h
@@ -43,11 +43,11 @@ class InterpreterSystemQuery : public IInterpreter, WithMutableContext
 
     static void startStopActionInDatabase(StorageActionBlockType action_type, bool start,
                                           const String & database_name, const DatabasePtr & database,
-                                          const ContextPtr & local_context, Poco::Logger * log);
+                                          const ContextPtr & local_context, LoggerPtr log);
 
 private:
     ASTPtr query_ptr;
-    Poco::Logger * log = nullptr;
+    LoggerPtr log = nullptr;
     StorageID table_id = StorageID::createEmpty();      /// Will be set up if query contains table name
     VolumePtr volume_ptr;
 
diff --git a/src/Interpreters/InterserverCredentials.cpp b/src/Interpreters/InterserverCredentials.cpp
index 094b58789a8d..c344732a2620 100644
--- a/src/Interpreters/InterserverCredentials.cpp
+++ b/src/Interpreters/InterserverCredentials.cpp
@@ -35,7 +35,7 @@ InterserverCredentials::CurrentCredentials InterserverCredentials::parseCredenti
     const Poco::Util::AbstractConfiguration & config,
     const std::string & root_tag)
 {
-    auto * log = &Poco::Logger::get("InterserverCredentials");
+    auto log = getLogger("InterserverCredentials");
     CurrentCredentials store;
     store.emplace_back(current_user_, current_password_);
     if (config.getBool(root_tag + ".allow_empty", false))
diff --git a/src/Interpreters/JoinedTables.cpp b/src/Interpreters/JoinedTables.cpp
index c104af770f06..9be8bf178a19 100644
--- a/src/Interpreters/JoinedTables.cpp
+++ b/src/Interpreters/JoinedTables.cpp
@@ -335,12 +335,12 @@ std::shared_ptr<TableJoin> JoinedTables::makeTableJoin(const ASTSelectQuery & se
                 auto dictionary = dictionary_helper.getDictionary(dictionary_name);
                 if (!dictionary)
                 {
-                    LOG_TRACE(&Poco::Logger::get("JoinedTables"), "Can't use dictionary join: dictionary '{}' was not found", dictionary_name);
+                    LOG_TRACE(getLogger("JoinedTables"), "Can't use dictionary join: dictionary '{}' was not found", dictionary_name);
                     return nullptr;
                 }
                 if (dictionary->getSpecialKeyType() == DictionarySpecialKeyType::Range)
                 {
-                    LOG_TRACE(&Poco::Logger::get("JoinedTables"), "Can't use dictionary join: dictionary '{}' is a range dictionary", dictionary_name);
+                    LOG_TRACE(getLogger("JoinedTables"), "Can't use dictionary join: dictionary '{}' is a range dictionary", dictionary_name);
                     return nullptr;
                 }
 
diff --git a/src/Interpreters/MergeJoin.cpp b/src/Interpreters/MergeJoin.cpp
index 4a80e1a3c56e..901c82029eec 100644
--- a/src/Interpreters/MergeJoin.cpp
+++ b/src/Interpreters/MergeJoin.cpp
@@ -492,7 +492,7 @@ MergeJoin::MergeJoin(std::shared_ptr<TableJoin> table_join_, const Block & right
     , max_joined_block_rows(table_join->maxJoinedBlockRows())
     , max_rows_in_right_block(table_join->maxRowsInRightBlock())
     , max_files_to_merge(table_join->maxFilesToMerge())
-    , log(&Poco::Logger::get("MergeJoin"))
+    , log(getLogger("MergeJoin"))
 {
     switch (table_join->strictness())
     {
diff --git a/src/Interpreters/MergeJoin.h b/src/Interpreters/MergeJoin.h
index 98fae1d419fc..4486c134d518 100644
--- a/src/Interpreters/MergeJoin.h
+++ b/src/Interpreters/MergeJoin.h
@@ -117,7 +117,7 @@ class MergeJoin : public IJoin
 
     Names lowcard_right_keys;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     void changeLeftColumns(Block & block, MutableColumns && columns) const;
     void addRightColumns(Block & block, MutableColumns && columns);
diff --git a/src/Interpreters/MutationsInterpreter.cpp b/src/Interpreters/MutationsInterpreter.cpp
index 86cd2d84fa37..cc447dfef242 100644
--- a/src/Interpreters/MutationsInterpreter.cpp
+++ b/src/Interpreters/MutationsInterpreter.cpp
@@ -1284,7 +1284,7 @@ void MutationsInterpreter::Source::read(
             plan, *data, storage_snapshot, part,
             std::move(virtual_columns.columns_to_read),
             apply_deleted_mask_, filter, context_,
-            &Poco::Logger::get("MutationsInterpreter"));
+            getLogger("MutationsInterpreter"));
 
         virtual_columns.addVirtuals(plan);
     }
diff --git a/src/Interpreters/PartLog.cpp b/src/Interpreters/PartLog.cpp
index 9819b8e3ec4e..a7f20a067854 100644
--- a/src/Interpreters/PartLog.cpp
+++ b/src/Interpreters/PartLog.cpp
@@ -271,7 +271,7 @@ bool PartLog::addNewParts(
     }
     catch (...)
     {
-        tryLogCurrentException(part_log ? part_log->log : &Poco::Logger::get("PartLog"), __PRETTY_FUNCTION__);
+        tryLogCurrentException(part_log ? part_log->log : getLogger("PartLog"), __PRETTY_FUNCTION__);
         return false;
     }
 
diff --git a/src/Interpreters/PasteJoin.h b/src/Interpreters/PasteJoin.h
index df7bb2f280c1..f87a70215517 100644
--- a/src/Interpreters/PasteJoin.h
+++ b/src/Interpreters/PasteJoin.h
@@ -24,7 +24,7 @@ class PasteJoin : public IJoin
         : table_join(table_join_)
         , right_sample_block(right_sample_block_)
     {
-        LOG_TRACE(&Poco::Logger::get("PasteJoin"), "Will use paste join");
+        LOG_TRACE(getLogger("PasteJoin"), "Will use paste join");
     }
 
     std::string getName() const override { return "PasteJoin"; }
diff --git a/src/Interpreters/ProcessList.cpp b/src/Interpreters/ProcessList.cpp
index 2b84b7655b37..5b3b87114ae8 100644
--- a/src/Interpreters/ProcessList.cpp
+++ b/src/Interpreters/ProcessList.cpp
@@ -86,7 +86,7 @@ ProcessList::insert(const String & query_, const IAST * ast, ContextMutablePtr q
         if (!is_unlimited_query && max_size && processes.size() >= max_size)
         {
             if (queue_max_wait_ms)
-                LOG_WARNING(&Poco::Logger::get("ProcessList"), "Too many simultaneous queries, will wait {} ms.", queue_max_wait_ms);
+                LOG_WARNING(getLogger("ProcessList"), "Too many simultaneous queries, will wait {} ms.", queue_max_wait_ms);
             if (!queue_max_wait_ms || !have_space.wait_for(lock, std::chrono::milliseconds(queue_max_wait_ms), [&]{ return processes.size() < max_size; }))
                 throw Exception(ErrorCodes::TOO_MANY_SIMULTANEOUS_QUERIES, "Too many simultaneous queries. Maximum: {}", max_size);
         }
@@ -295,7 +295,7 @@ ProcessListEntry::~ProcessListEntry()
     auto user_process_list_it = parent.user_to_queries.find(user);
     if (user_process_list_it == parent.user_to_queries.end())
     {
-        LOG_ERROR(&Poco::Logger::get("ProcessList"), "Logical error: cannot find user in ProcessList");
+        LOG_ERROR(getLogger("ProcessList"), "Logical error: cannot find user in ProcessList");
         std::terminate();
     }
 
@@ -323,7 +323,7 @@ ProcessListEntry::~ProcessListEntry()
 
     if (!found)
     {
-        LOG_ERROR(&Poco::Logger::get("ProcessList"), "Logical error: cannot find query by query_id and pointer to ProcessListElement in ProcessListForUser");
+        LOG_ERROR(getLogger("ProcessList"), "Logical error: cannot find query by query_id and pointer to ProcessListElement in ProcessListForUser");
         std::terminate();
     }
 
diff --git a/src/Interpreters/Session.cpp b/src/Interpreters/Session.cpp
index d2f9fe8b325e..533f33033e38 100644
--- a/src/Interpreters/Session.cpp
+++ b/src/Interpreters/Session.cpp
@@ -265,7 +265,7 @@ class NamedSessionsStorage
     ThreadFromGlobalPool thread;
     bool quit = false;
 
-    Poco::Logger * log = &Poco::Logger::get("NamedSessionsStorage");
+    LoggerPtr log = getLogger("NamedSessionsStorage");
 };
 
 
@@ -282,7 +282,7 @@ void Session::shutdownNamedSessions()
 Session::Session(const ContextPtr & global_context_, ClientInfo::Interface interface_, bool is_secure, const std::string & certificate)
     : auth_id(UUIDHelpers::generateV4()),
       global_context(global_context_),
-      log(&Poco::Logger::get(String{magic_enum::enum_name(interface_)} + "-Session"))
+      log(getLogger(String{magic_enum::enum_name(interface_)} + "-Session"))
 {
     prepared_client_info.emplace();
     prepared_client_info->interface = interface_;
diff --git a/src/Interpreters/Session.h b/src/Interpreters/Session.h
index 75e1414b8cba..cde000d89fa8 100644
--- a/src/Interpreters/Session.h
+++ b/src/Interpreters/Session.h
@@ -123,7 +123,7 @@ class Session
     /// to set when creating a session context
     SettingsChanges settings_from_auth_server;
 
-    Poco::Logger * log = nullptr;
+    LoggerPtr log = nullptr;
 };
 
 }
diff --git a/src/Interpreters/Set.h b/src/Interpreters/Set.h
index 7136b090c42f..5a65d40d89f2 100644
--- a/src/Interpreters/Set.h
+++ b/src/Interpreters/Set.h
@@ -33,7 +33,7 @@ class Set
     /// store all set elements in explicit form.
     /// This is needed for subsequent use for index.
     Set(const SizeLimits & limits_, size_t max_elements_to_fill_, bool transform_null_in_)
-        : log(&Poco::Logger::get("Set")),
+        : log(getLogger("Set")),
         limits(limits_), max_elements_to_fill(max_elements_to_fill_), transform_null_in(transform_null_in_),
         cast_cache(std::make_unique<InternalCastFunctionCache>())
     {}
@@ -114,7 +114,7 @@ class Set
     /// Types for set_elements.
     DataTypes set_elements_types;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Limitations on the maximum size of the set
     SizeLimits limits;
diff --git a/src/Interpreters/SystemLog.cpp b/src/Interpreters/SystemLog.cpp
index 954368db3127..2fb782befa16 100644
--- a/src/Interpreters/SystemLog.cpp
+++ b/src/Interpreters/SystemLog.cpp
@@ -125,13 +125,13 @@ std::shared_ptr<TSystemLog> createSystemLog(
 {
     if (!config.has(config_prefix))
     {
-        LOG_DEBUG(&Poco::Logger::get("SystemLog"),
+        LOG_DEBUG(getLogger("SystemLog"),
                 "Not creating {}.{} since corresponding section '{}' is missing from config",
                 default_database_name, default_table_name, config_prefix);
 
         return {};
     }
-    LOG_DEBUG(&Poco::Logger::get("SystemLog"),
+    LOG_DEBUG(getLogger("SystemLog"),
               "Creating {}.{} from {}", default_database_name, default_table_name, config_prefix);
 
     SystemLogSettings log_settings;
@@ -143,7 +143,7 @@ std::shared_ptr<TSystemLog> createSystemLog(
     {
         /// System tables must be loaded before other tables, but loading order is undefined for all databases except `system`
         LOG_ERROR(
-            &Poco::Logger::get("SystemLog"),
+            getLogger("SystemLog"),
             "Custom database name for a system table specified in config."
             " Table `{}` will be created in `system` database instead of `{}`",
             log_settings.queue_settings.table,
@@ -395,7 +395,7 @@ SystemLog<LogElement>::SystemLog(
     std::shared_ptr<SystemLogQueue<LogElement>> queue_)
     : Base(settings_.queue_settings, queue_)
     , WithContext(context_)
-    , log(&Poco::Logger::get("SystemLog (" + settings_.queue_settings.database + "." + settings_.queue_settings.table + ")"))
+    , log(getLogger("SystemLog (" + settings_.queue_settings.database + "." + settings_.queue_settings.table + ")"))
     , table_id(settings_.queue_settings.database, settings_.queue_settings.table)
     , storage_def(settings_.engine)
     , create_query(serializeAST(*getCreateTableQuery()))
diff --git a/src/Interpreters/SystemLog.h b/src/Interpreters/SystemLog.h
index 8c357e43be98..c296b91e24a7 100644
--- a/src/Interpreters/SystemLog.h
+++ b/src/Interpreters/SystemLog.h
@@ -131,7 +131,7 @@ class SystemLog : public SystemLogBase<LogElement>, private boost::noncopyable,
     void stopFlushThread() override;
 
 protected:
-    Poco::Logger * log;
+    LoggerPtr log;
 
     using ISystemLog::is_shutdown;
     using ISystemLog::saving_thread;
diff --git a/src/Interpreters/TableJoin.cpp b/src/Interpreters/TableJoin.cpp
index efe3fd7f7403..e9fa224df111 100644
--- a/src/Interpreters/TableJoin.cpp
+++ b/src/Interpreters/TableJoin.cpp
@@ -683,7 +683,7 @@ void TableJoin::inferJoinKeyCommonType(const LeftNamesAndTypes & left, const Rig
     if (!left_type_map.empty() || !right_type_map.empty())
     {
         LOG_TRACE(
-            &Poco::Logger::get("TableJoin"),
+            getLogger("TableJoin"),
             "Infer supertype for joined columns. Left: [{}], Right: [{}]",
             formatTypeMap(left_type_map, left_types),
             formatTypeMap(right_type_map, right_types));
@@ -876,7 +876,7 @@ static void addJoinConditionWithAnd(ASTPtr & current_cond, const ASTPtr & new_co
 void TableJoin::addJoinCondition(const ASTPtr & ast, bool is_left)
 {
     auto & cond_ast = is_left ? clauses.back().on_filter_condition_left : clauses.back().on_filter_condition_right;
-    LOG_TRACE(&Poco::Logger::get("TableJoin"), "Adding join condition for {} table: {} -> {}",
+    LOG_TRACE(getLogger("TableJoin"), "Adding join condition for {} table: {} -> {}",
               (is_left ? "left" : "right"), ast ? queryToString(ast) : "NULL", cond_ast ? queryToString(cond_ast) : "NULL");
     addJoinConditionWithAnd(cond_ast, ast);
 }
diff --git a/src/Interpreters/TemporaryDataOnDisk.cpp b/src/Interpreters/TemporaryDataOnDisk.cpp
index 3ad72af95f97..a48e7d8e040a 100644
--- a/src/Interpreters/TemporaryDataOnDisk.cpp
+++ b/src/Interpreters/TemporaryDataOnDisk.cpp
@@ -223,7 +223,7 @@ struct TemporaryFileStream::InputReader
         , in_compressed_buf(in_file_buf)
         , in_reader(in_compressed_buf, header_, DBMS_TCP_PROTOCOL_VERSION)
     {
-        LOG_TEST(&Poco::Logger::get("TemporaryFileStream"), "Reading {} from {}", header_.dumpStructure(), path);
+        LOG_TEST(getLogger("TemporaryFileStream"), "Reading {} from {}", header_.dumpStructure(), path);
     }
 
     explicit InputReader(const String & path, size_t size = 0)
@@ -231,7 +231,7 @@ struct TemporaryFileStream::InputReader
         , in_compressed_buf(in_file_buf)
         , in_reader(in_compressed_buf, DBMS_TCP_PROTOCOL_VERSION)
     {
-        LOG_TEST(&Poco::Logger::get("TemporaryFileStream"), "Reading from {}", path);
+        LOG_TEST(getLogger("TemporaryFileStream"), "Reading from {}", path);
     }
 
     Block read()
@@ -250,7 +250,7 @@ TemporaryFileStream::TemporaryFileStream(TemporaryFileOnDiskHolder file_, const
     , file(std::move(file_))
     , out_writer(std::make_unique<OutputWriter>(std::make_unique<WriteBufferFromFile>(file->getAbsolutePath()), header))
 {
-    LOG_TEST(&Poco::Logger::get("TemporaryFileStream"), "Writing to temporary file {}", file->getAbsolutePath());
+    LOG_TEST(getLogger("TemporaryFileStream"), "Writing to temporary file {}", file->getAbsolutePath());
 }
 
 TemporaryFileStream::TemporaryFileStream(FileSegmentsHolderPtr segments_, const Block & header_, TemporaryDataOnDisk * parent_)
@@ -262,7 +262,7 @@ TemporaryFileStream::TemporaryFileStream(FileSegmentsHolderPtr segments_, const
         throw Exception(ErrorCodes::LOGICAL_ERROR, "TemporaryFileStream can be created only from single segment");
     auto out_buf = std::make_unique<WriteBufferToFileSegment>(&segment_holder->front());
 
-    LOG_TEST(&Poco::Logger::get("TemporaryFileStream"), "Writing to temporary file {}", out_buf->getFileName());
+    LOG_TEST(getLogger("TemporaryFileStream"), "Writing to temporary file {}", out_buf->getFileName());
     out_writer = std::make_unique<OutputWriter>(std::move(out_buf), header);
 }
 
diff --git a/src/Interpreters/TraceCollector.cpp b/src/Interpreters/TraceCollector.cpp
index 30fbe26d0385..1fe11be60906 100644
--- a/src/Interpreters/TraceCollector.cpp
+++ b/src/Interpreters/TraceCollector.cpp
@@ -65,7 +65,7 @@ TraceCollector::~TraceCollector()
     if (thread.joinable())
         thread.join();
     else
-        LOG_ERROR(&Poco::Logger::get("TraceCollector"), "TraceCollector thread is malformed and cannot be joined");
+        LOG_ERROR(getLogger("TraceCollector"), "TraceCollector thread is malformed and cannot be joined");
 }
 
 
diff --git a/src/Interpreters/TransactionLog.cpp b/src/Interpreters/TransactionLog.cpp
index a86f6110a840..96c69536c9a5 100644
--- a/src/Interpreters/TransactionLog.cpp
+++ b/src/Interpreters/TransactionLog.cpp
@@ -21,7 +21,7 @@ namespace ErrorCodes
     extern const int UNKNOWN_STATUS_OF_TRANSACTION;
 }
 
-static void tryWriteEventToSystemLog(Poco::Logger * log, ContextPtr context,
+static void tryWriteEventToSystemLog(LoggerPtr log, ContextPtr context,
                                      TransactionsInfoLogElement::Type type, const TransactionID & tid, CSN csn = Tx::UnknownCSN)
 try
 {
@@ -44,7 +44,7 @@ catch (...)
 
 TransactionLog::TransactionLog()
     : global_context(Context::getGlobalContextInstance())
-    , log(&Poco::Logger::get("TransactionLog"))
+    , log(getLogger("TransactionLog"))
     , zookeeper_path(global_context->getConfigRef().getString("transaction_log.zookeeper_path", "/clickhouse/txn"))
     , zookeeper_path_log(zookeeper_path + "/log")
     , fault_probability_before_commit(global_context->getConfigRef().getDouble("transaction_log.fault_probability_before_commit", 0))
diff --git a/src/Interpreters/TransactionLog.h b/src/Interpreters/TransactionLog.h
index 6e8777d85198..58847553dfda 100644
--- a/src/Interpreters/TransactionLog.h
+++ b/src/Interpreters/TransactionLog.h
@@ -154,7 +154,7 @@ class TransactionLog final : public SingletonHelper<TransactionLog>
     CSN getCSNImpl(const TIDHash & tid_hash, const std::atomic<CSN> * failback_with_strict_load_csn = nullptr) const;
 
     const ContextPtr global_context;
-    Poco::Logger * const log;
+    LoggerPtr const log;
 
     /// The newest snapshot available for reading
     std::atomic<CSN> latest_snapshot;
diff --git a/src/Interpreters/TransactionVersionMetadata.cpp b/src/Interpreters/TransactionVersionMetadata.cpp
index 01735a798b91..7bedca5d5c75 100644
--- a/src/Interpreters/TransactionVersionMetadata.cpp
+++ b/src/Interpreters/TransactionVersionMetadata.cpp
@@ -23,7 +23,7 @@ namespace ErrorCodes
 VersionMetadata::VersionMetadata()
 {
     /// It would be better to make it static, but static loggers do not work for some reason (initialization order?)
-    log = &Poco::Logger::get("VersionMetadata");
+    log = getLogger("VersionMetadata");
 }
 
 /// It can be used for introspection purposes only
diff --git a/src/Interpreters/TransactionVersionMetadata.h b/src/Interpreters/TransactionVersionMetadata.h
index 18ac445cc29d..4309975d195b 100644
--- a/src/Interpreters/TransactionVersionMetadata.h
+++ b/src/Interpreters/TransactionVersionMetadata.h
@@ -72,7 +72,7 @@ struct VersionMetadata
 
     String toString(bool one_line = true) const;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     VersionMetadata();
 };
 
diff --git a/src/Interpreters/TransactionsInfoLog.cpp b/src/Interpreters/TransactionsInfoLog.cpp
index e893be814ca9..4a413439671e 100644
--- a/src/Interpreters/TransactionsInfoLog.cpp
+++ b/src/Interpreters/TransactionsInfoLog.cpp
@@ -92,7 +92,7 @@ void TransactionsInfoLogElement::appendToBlock(MutableColumns & columns) const
 }
 
 
-void tryWriteEventToSystemLog(Poco::Logger * log,
+void tryWriteEventToSystemLog(LoggerPtr log,
                               TransactionsInfoLogElement::Type type, const TransactionID & tid,
                               const TransactionInfoContext & context)
 try
diff --git a/src/Interpreters/TransactionsInfoLog.h b/src/Interpreters/TransactionsInfoLog.h
index 0a607704e741..009d1b67474a 100644
--- a/src/Interpreters/TransactionsInfoLog.h
+++ b/src/Interpreters/TransactionsInfoLog.h
@@ -54,7 +54,7 @@ class TransactionsInfoLog : public SystemLog<TransactionsInfoLogElement>
 };
 
 
-void tryWriteEventToSystemLog(Poco::Logger * log, TransactionsInfoLogElement::Type type,
+void tryWriteEventToSystemLog(LoggerPtr log, TransactionsInfoLogElement::Type type,
                               const TransactionID & tid, const TransactionInfoContext & context);
 
 }
diff --git a/src/Interpreters/TreeRewriter.cpp b/src/Interpreters/TreeRewriter.cpp
index 6ed3ff2f1e6e..ecd021328e78 100644
--- a/src/Interpreters/TreeRewriter.cpp
+++ b/src/Interpreters/TreeRewriter.cpp
@@ -642,13 +642,13 @@ bool tryJoinOnConst(TableJoin & analyzed_join, const ASTPtr & on_expression, Con
         if (eval_const_res.value())
         {
             /// JOIN ON 1 == 1
-            LOG_DEBUG(&Poco::Logger::get("TreeRewriter"), "Join on constant executed as cross join");
+            LOG_DEBUG(getLogger("TreeRewriter"), "Join on constant executed as cross join");
             analyzed_join.resetToCross();
         }
         else
         {
             /// JOIN ON 1 != 1
-            LOG_DEBUG(&Poco::Logger::get("TreeRewriter"), "Join on constant executed as empty join");
+            LOG_DEBUG(getLogger("TreeRewriter"), "Join on constant executed as empty join");
             analyzed_join.resetKeys();
         }
         return true;
diff --git a/src/Interpreters/executeDDLQueryOnCluster.cpp b/src/Interpreters/executeDDLQueryOnCluster.cpp
index 6b6054fdae3e..6122ec6180a3 100644
--- a/src/Interpreters/executeDDLQueryOnCluster.cpp
+++ b/src/Interpreters/executeDDLQueryOnCluster.cpp
@@ -221,7 +221,7 @@ class DDLQueryStatusSource final : public ISource
     String node_path;
     ContextPtr context;
     Stopwatch watch;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     NameSet waiting_hosts;  /// hosts from task host list
     NameSet finished_hosts; /// finished hosts from host list
@@ -309,7 +309,7 @@ DDLQueryStatusSource::DDLQueryStatusSource(
     , node_path(zk_node_path)
     , context(context_)
     , watch(CLOCK_MONOTONIC_COARSE)
-    , log(&Poco::Logger::get("DDLQueryStatusSource"))
+    , log(getLogger("DDLQueryStatusSource"))
 {
     auto output_mode = context->getSettingsRef().distributed_ddl_output_mode;
     throw_on_timeout = output_mode == DistributedDDLOutputMode::THROW || output_mode == DistributedDDLOutputMode::THROW_ONLY_ACTIVE
@@ -382,7 +382,7 @@ Chunk DDLQueryStatusSource::generateChunkWithUnfinishedHosts() const
     return Chunk(std::move(columns), unfinished_hosts.size());
 }
 
-static NameSet getOfflineHosts(const String & node_path, const NameSet & hosts_to_wait, const ZooKeeperPtr & zookeeper, Poco::Logger * log)
+static NameSet getOfflineHosts(const String & node_path, const NameSet & hosts_to_wait, const ZooKeeperPtr & zookeeper, LoggerPtr log)
 {
     fs::path replicas_path;
     if (node_path.ends_with('/'))
@@ -470,7 +470,7 @@ Chunk DDLQueryStatusSource::generate()
 
         {
             auto retries_ctl = ZooKeeperRetriesControl(
-                "executeDDLQueryOnCluster", &Poco::Logger::get("DDLQueryStatusSource"), getRetriesInfo(), context->getProcessListElement());
+                "executeDDLQueryOnCluster", getLogger("DDLQueryStatusSource"), getRetriesInfo(), context->getProcessListElement());
             retries_ctl.retryLoop([&]()
             {
                 auto zookeeper = context->getZooKeeper();
@@ -540,7 +540,7 @@ Chunk DDLQueryStatusSource::generate()
 
                 auto retries_ctl = ZooKeeperRetriesControl(
                     "executeDDLQueryOnCluster",
-                    &Poco::Logger::get("DDLQueryStatusSource"),
+                    getLogger("DDLQueryStatusSource"),
                     getRetriesInfo(),
                     context->getProcessListElement());
                 retries_ctl.retryLoop([&]()
diff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp
index 533d58aaa8f2..a377d2e0b971 100644
--- a/src/Interpreters/executeQuery.cpp
+++ b/src/Interpreters/executeQuery.cpp
@@ -119,7 +119,7 @@ static void logQuery(const String & query, ContextPtr context, bool internal, Qu
 {
     if (internal)
     {
-        LOG_DEBUG(&Poco::Logger::get("executeQuery"), "(internal) {} (stage: {})", toOneLineQuery(query), QueryProcessingStage::toString(stage));
+        LOG_DEBUG(getLogger("executeQuery"), "(internal) {} (stage: {})", toOneLineQuery(query), QueryProcessingStage::toString(stage));
     }
     else
     {
@@ -142,7 +142,7 @@ static void logQuery(const String & query, ContextPtr context, bool internal, Qu
         if (auto txn = context->getCurrentTransaction())
             transaction_info = fmt::format(" (TID: {}, TIDH: {})", txn->tid, txn->tid.getHash());
 
-        LOG_DEBUG(&Poco::Logger::get("executeQuery"), "(from {}{}{}){}{} {} (stage: {})",
+        LOG_DEBUG(getLogger("executeQuery"), "(from {}{}{}){}{} {} (stage: {})",
             client_info.current_address.toString(),
             (current_user != "default" ? ", user: " + current_user : ""),
             (!initial_query_id.empty() && current_query_id != initial_query_id ? ", initial_query_id: " + initial_query_id : std::string()),
@@ -153,7 +153,7 @@ static void logQuery(const String & query, ContextPtr context, bool internal, Qu
 
         if (client_info.client_trace_context.trace_id != UUID())
         {
-            LOG_TRACE(&Poco::Logger::get("executeQuery"),
+            LOG_TRACE(getLogger("executeQuery"),
                 "OpenTelemetry traceparent '{}'",
                 client_info.client_trace_context.composeTraceparentHeader());
         }
@@ -207,9 +207,9 @@ static void logException(ContextPtr context, QueryLogElement & elem, bool log_er
             elem.stack_trace);
 
     if (log_error)
-        LOG_ERROR(&Poco::Logger::get("executeQuery"), message);
+        LOG_ERROR(getLogger("executeQuery"), message);
     else
-        LOG_INFO(&Poco::Logger::get("executeQuery"), message);
+        LOG_INFO(getLogger("executeQuery"), message);
 }
 
 static void
@@ -396,7 +396,7 @@ void logQueryFinish(
             double elapsed_seconds = static_cast<double>(info.elapsed_microseconds) / 1000000.0;
             double rows_per_second = static_cast<double>(elem.read_rows) / elapsed_seconds;
             LOG_DEBUG(
-                &Poco::Logger::get("executeQuery"),
+                getLogger("executeQuery"),
                 "Read {} rows, {} in {} sec., {} rows/sec., {}/sec.",
                 elem.read_rows,
                 ReadableSize(elem.read_bytes),
@@ -660,7 +660,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
     /// we still have enough span logs for the execution of external queries.
     std::shared_ptr<OpenTelemetry::SpanHolder> query_span = internal ? nullptr : std::make_shared<OpenTelemetry::SpanHolder>("query");
     if (query_span && query_span->trace_id != UUID{})
-        LOG_TRACE(&Poco::Logger::get("executeQuery"), "Query span trace_id for opentelemetry log: {}", query_span->trace_id);
+        LOG_TRACE(getLogger("executeQuery"), "Query span trace_id for opentelemetry log: {}", query_span->trace_id);
 
     auto query_start_time = std::chrono::system_clock::now();
 
@@ -925,7 +925,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
 
         bool async_insert = false;
         auto * queue = context->getAsynchronousInsertQueue();
-        auto * logger = &Poco::Logger::get("executeQuery");
+        auto logger = getLogger("executeQuery");
 
         if (insert_query && async_insert_enabled)
         {
@@ -1131,7 +1131,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
                             const size_t num_query_runs = query_cache->recordQueryRun(key);
                             if (num_query_runs <= settings.query_cache_min_query_runs)
                             {
-                                LOG_TRACE(&Poco::Logger::get("QueryCache"),
+                                LOG_TRACE(getLogger("QueryCache"),
                                         "Skipped insert because the query ran {} times but the minimum required number of query runs to cache the query result is {}",
                                         num_query_runs, settings.query_cache_min_query_runs);
                             }
@@ -1387,7 +1387,7 @@ void executeQuery(
             catch (const DB::Exception & e)
             {
                 /// Ignore this exception and report the original one
-                LOG_WARNING(&Poco::Logger::get("executeQuery"), getExceptionMessageAndPattern(e, true));
+                LOG_WARNING(getLogger("executeQuery"), getExceptionMessageAndPattern(e, true));
             }
         }
     };
diff --git a/src/Interpreters/loadMetadata.cpp b/src/Interpreters/loadMetadata.cpp
index a2d2c56c710f..0b7a6dc92b07 100644
--- a/src/Interpreters/loadMetadata.cpp
+++ b/src/Interpreters/loadMetadata.cpp
@@ -156,7 +156,7 @@ static void checkIncompleteOrdinaryToAtomicConversion(ContextPtr context, const
 
 LoadTaskPtrs loadMetadata(ContextMutablePtr context, const String & default_database_name, bool async_load_databases)
 {
-    Poco::Logger * log = &Poco::Logger::get("loadMetadata");
+    LoggerPtr log = getLogger("loadMetadata");
 
     String path = context->getPath() + "metadata";
 
@@ -290,7 +290,7 @@ static void loadSystemDatabaseImpl(ContextMutablePtr context, const String & dat
     }
 }
 
-static void convertOrdinaryDatabaseToAtomic(Poco::Logger * log, ContextMutablePtr context, const DatabasePtr & database,
+static void convertOrdinaryDatabaseToAtomic(LoggerPtr log, ContextMutablePtr context, const DatabasePtr & database,
                                             const String & name, const String tmp_name)
 {
     /// It's kind of C++ script that creates temporary database with Atomic engine,
@@ -369,7 +369,7 @@ static void convertOrdinaryDatabaseToAtomic(Poco::Logger * log, ContextMutablePt
 /// Can be called only during server startup when there are no queries from users.
 static void maybeConvertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const String & database_name, LoadTaskPtrs * startup_tasks = nullptr)
 {
-    Poco::Logger * log = &Poco::Logger::get("loadMetadata");
+    LoggerPtr log = getLogger("loadMetadata");
 
     auto database = DatabaseCatalog::instance().getDatabase(database_name);
     if (!database)
@@ -482,7 +482,7 @@ void convertDatabasesEnginesIfNeed(const LoadTaskPtrs & load_metadata, ContextMu
     if (!fs::exists(convert_flag_path))
         return;
 
-    LOG_INFO(&Poco::Logger::get("loadMetadata"), "Found convert_ordinary_to_atomic file in flags directory, "
+    LOG_INFO(getLogger("loadMetadata"), "Found convert_ordinary_to_atomic file in flags directory, "
                                                  "will try to convert all Ordinary databases to Atomic");
 
     // Wait for all table to be loaded and started
@@ -492,7 +492,7 @@ void convertDatabasesEnginesIfNeed(const LoadTaskPtrs & load_metadata, ContextMu
         if (name != DatabaseCatalog::SYSTEM_DATABASE)
             maybeConvertOrdinaryDatabaseToAtomic(context, name);
 
-    LOG_INFO(&Poco::Logger::get("loadMetadata"), "Conversion finished, removing convert_ordinary_to_atomic flag");
+    LOG_INFO(getLogger("loadMetadata"), "Conversion finished, removing convert_ordinary_to_atomic flag");
     fs::remove(convert_flag_path);
 }
 
diff --git a/src/Interpreters/removeOnClusterClauseIfNeeded.cpp b/src/Interpreters/removeOnClusterClauseIfNeeded.cpp
index f8df03ed8306..44167fe72424 100644
--- a/src/Interpreters/removeOnClusterClauseIfNeeded.cpp
+++ b/src/Interpreters/removeOnClusterClauseIfNeeded.cpp
@@ -52,7 +52,7 @@ ASTPtr removeOnClusterClauseIfNeeded(const ASTPtr & query, ContextPtr context, c
             && context->getSettings().ignore_on_cluster_for_replicated_access_entities_queries
             && context->getAccessControl().containsStorage(ReplicatedAccessStorage::STORAGE_TYPE)))
     {
-        LOG_DEBUG(&Poco::Logger::get("removeOnClusterClauseIfNeeded"), "ON CLUSTER clause was ignored for query {}", query->getID());
+        LOG_DEBUG(getLogger("removeOnClusterClauseIfNeeded"), "ON CLUSTER clause was ignored for query {}", query->getID());
         return query_on_cluster->getRewrittenASTWithoutOnCluster(params);
     }
 
diff --git a/src/Parsers/DumpASTNode.h b/src/Parsers/DumpASTNode.h
index 60fcece55904..5efc0e018f47 100644
--- a/src/Parsers/DumpASTNode.h
+++ b/src/Parsers/DumpASTNode.h
@@ -165,7 +165,7 @@ class DebugASTLog
         : log(nullptr)
     {
         if constexpr (_enable)
-            log = &Poco::Logger::get("AST");
+            log = getLogger("AST");
     }
 
     ~DebugASTLog()
@@ -177,7 +177,7 @@ class DebugASTLog
     WriteBuffer * stream() { return (_enable ? &buf : nullptr); }
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     WriteBufferFromOwnString buf;
 };
 
diff --git a/src/Planner/Planner.cpp b/src/Planner/Planner.cpp
index f2def5713257..b55f0e440388 100644
--- a/src/Planner/Planner.cpp
+++ b/src/Planner/Planner.cpp
@@ -1196,7 +1196,7 @@ void Planner::buildQueryPlanIfNeeded()
     if (query_plan.isInitialized())
         return;
 
-    LOG_TRACE(&Poco::Logger::get("Planner"), "Query {} to stage {}{}",
+    LOG_TRACE(getLogger("Planner"), "Query {} to stage {}{}",
         query_tree->formatConvertedASTForErrorMessage(),
         QueryProcessingStage::toString(select_query_options.to_stage),
         select_query_options.only_analyze ? " only analyze" : "");
@@ -1355,7 +1355,7 @@ void Planner::buildPlanForQueryNode()
 
             auto & mutable_context = planner_context->getMutableQueryContext();
             mutable_context->setSetting("allow_experimental_parallel_reading_from_replicas", Field(0));
-            LOG_DEBUG(&Poco::Logger::get("Planner"), "Disabling parallel replicas to execute a query with IN with subquery");
+            LOG_DEBUG(getLogger("Planner"), "Disabling parallel replicas to execute a query with IN with subquery");
         }
     }
 
@@ -1382,7 +1382,7 @@ void Planner::buildPlanForQueryNode()
                 else
                 {
                     LOG_DEBUG(
-                        &Poco::Logger::get("Planner"),
+                        getLogger("Planner"),
                         "FINAL modifier is not supported with parallel replicas. Query will be executed without using them.");
                     auto & mutable_context = planner_context->getMutableQueryContext();
                     mutable_context->setSetting("allow_experimental_parallel_reading_from_replicas", Field(0));
@@ -1401,7 +1401,7 @@ void Planner::buildPlanForQueryNode()
             else
             {
                 LOG_DEBUG(
-                    &Poco::Logger::get("Planner"),
+                    getLogger("Planner"),
                     "JOINs are not supported with parallel replicas. Query will be executed without using them.");
 
                 auto & mutable_context = planner_context->getMutableQueryContext();
@@ -1422,7 +1422,7 @@ void Planner::buildPlanForQueryNode()
     query_plan = std::move(join_tree_query_plan.query_plan);
     used_row_policies = std::move(join_tree_query_plan.used_row_policies);
 
-    LOG_TRACE(&Poco::Logger::get("Planner"), "Query {} from stage {} to stage {}{}",
+    LOG_TRACE(getLogger("Planner"), "Query {} from stage {} to stage {}{}",
         query_tree->formatConvertedASTForErrorMessage(),
         QueryProcessingStage::toString(from_stage),
         QueryProcessingStage::toString(select_query_options.to_stage),
diff --git a/src/Planner/PlannerJoinTree.cpp b/src/Planner/PlannerJoinTree.cpp
index 552f25d70358..ab25f6d24234 100644
--- a/src/Planner/PlannerJoinTree.cpp
+++ b/src/Planner/PlannerJoinTree.cpp
@@ -276,7 +276,7 @@ bool applyTrivialCountIfPossible(
         /// The query could use trivial count if it didn't use parallel replicas, so let's disable it
         query_context->setSetting("allow_experimental_parallel_reading_from_replicas", Field(0));
         query_context->setSetting("max_parallel_replicas", UInt64{0});
-        LOG_TRACE(&Poco::Logger::get("Planner"), "Disabling parallel replicas to be able to use a trivial count optimization");
+        LOG_TRACE(getLogger("Planner"), "Disabling parallel replicas to be able to use a trivial count optimization");
 
     }
 
@@ -478,7 +478,7 @@ FilterDAGInfo buildCustomKeyFilterIfNeeded(const StoragePtr & storage,
                 "(setting 'max_parallel_replcias'), but the table does not have custom_key defined for it "
                 " or it's invalid (setting 'parallel_replicas_custom_key')");
 
-    LOG_TRACE(&Poco::Logger::get("Planner"), "Processing query on a replica using custom_key '{}'", settings.parallel_replicas_custom_key.value);
+    LOG_TRACE(getLogger("Planner"), "Processing query on a replica using custom_key '{}'", settings.parallel_replicas_custom_key.value);
 
     auto parallel_replicas_custom_filter_ast = getCustomKeyFilterForParallelReplica(
             settings.parallel_replicas_count,
@@ -725,7 +725,7 @@ JoinTreeQueryPlan buildQueryPlanForTableExpression(QueryTreeNodePtr table_expres
 
                     size_t number_of_replicas_to_use = rows_to_read / settings.parallel_replicas_min_number_of_rows_per_replica;
                     LOG_TRACE(
-                        &Poco::Logger::get("Planner"),
+                        getLogger("Planner"),
                         "Estimated {} rows to read. It is enough work for {} parallel replicas",
                         rows_to_read,
                         number_of_replicas_to_use);
@@ -735,12 +735,12 @@ JoinTreeQueryPlan buildQueryPlanForTableExpression(QueryTreeNodePtr table_expres
                         planner_context->getMutableQueryContext()->setSetting(
                             "allow_experimental_parallel_reading_from_replicas", Field(0));
                         planner_context->getMutableQueryContext()->setSetting("max_parallel_replicas", UInt64{0});
-                        LOG_DEBUG(&Poco::Logger::get("Planner"), "Disabling parallel replicas because there aren't enough rows to read");
+                        LOG_DEBUG(getLogger("Planner"), "Disabling parallel replicas because there aren't enough rows to read");
                     }
                     else if (number_of_replicas_to_use < settings.max_parallel_replicas)
                     {
                         planner_context->getMutableQueryContext()->setSetting("max_parallel_replicas", number_of_replicas_to_use);
-                        LOG_DEBUG(&Poco::Logger::get("Planner"), "Reducing the number of replicas to use to {}", number_of_replicas_to_use);
+                        LOG_DEBUG(getLogger("Planner"), "Reducing the number of replicas to use to {}", number_of_replicas_to_use);
                     }
                 }
 
diff --git a/src/Planner/PlannerJoins.cpp b/src/Planner/PlannerJoins.cpp
index 9b249d21a247..94ee249106a5 100644
--- a/src/Planner/PlannerJoins.cpp
+++ b/src/Planner/PlannerJoins.cpp
@@ -388,8 +388,8 @@ JoinClausesAndActions buildJoinClausesAndActions(//const ColumnsWithTypeAndName
     ActionsDAGPtr left_join_actions = std::make_shared<ActionsDAG>(left_table_expression_columns);
     ActionsDAGPtr right_join_actions = std::make_shared<ActionsDAG>(right_table_expression_columns);
 
-    // LOG_TRACE(&Poco::Logger::get("Planner"), "buildJoinClausesAndActions cols {} ", left_join_actions->dumpDAG());
-    // LOG_TRACE(&Poco::Logger::get("Planner"), "buildJoinClausesAndActions cols {} ", right_join_actions->dumpDAG());
+    // LOG_TRACE(getLogger("Planner"), "buildJoinClausesAndActions cols {} ", left_join_actions->dumpDAG());
+    // LOG_TRACE(getLogger("Planner"), "buildJoinClausesAndActions cols {} ", right_join_actions->dumpDAG());
 
     /** In ActionsDAG if input node has constant representation additional constant column is added.
       * That way we cannot simply check that node has INPUT type during resolution of expression join table side.
@@ -411,8 +411,8 @@ JoinClausesAndActions buildJoinClausesAndActions(//const ColumnsWithTypeAndName
       * ON (t1.id = t2.id) AND 1 != 1 AND (t1.value >= t1.value);
       */
     auto join_expression = join_node.getJoinExpression();
-    // LOG_TRACE(&Poco::Logger::get("Planner"), "buildJoinClausesAndActions expr {} ", join_expression->formatConvertedASTForErrorMessage());
-    // LOG_TRACE(&Poco::Logger::get("Planner"), "buildJoinClausesAndActions expr {} ", join_expression->dumpTree());
+    // LOG_TRACE(getLogger("Planner"), "buildJoinClausesAndActions expr {} ", join_expression->formatConvertedASTForErrorMessage());
+    // LOG_TRACE(getLogger("Planner"), "buildJoinClausesAndActions expr {} ", join_expression->dumpTree());
 
     auto * constant_join_expression = join_expression->as<ConstantNode>();
 
diff --git a/src/Processors/Executors/PipelineExecutor.h b/src/Processors/Executors/PipelineExecutor.h
index dee12dad2829..862a460f0ed2 100644
--- a/src/Processors/Executors/PipelineExecutor.h
+++ b/src/Processors/Executors/PipelineExecutor.h
@@ -83,7 +83,7 @@ class PipelineExecutor
     std::atomic_bool cancelled = false;
     std::atomic_bool cancelled_reading = false;
 
-    Poco::Logger * log = &Poco::Logger::get("PipelineExecutor");
+    LoggerPtr log = getLogger("PipelineExecutor");
 
     /// Now it's used to check if query was killed.
     QueryStatusPtr process_list_element;
diff --git a/src/Processors/Formats/IRowInputFormat.cpp b/src/Processors/Formats/IRowInputFormat.cpp
index 5f27fa78c55d..8c317a34a9d5 100644
--- a/src/Processors/Formats/IRowInputFormat.cpp
+++ b/src/Processors/Formats/IRowInputFormat.cpp
@@ -230,7 +230,7 @@ Chunk IRowInputFormat::read()
     {
         if (num_errors && (params.allow_errors_num > 0 || params.allow_errors_ratio > 0))
         {
-            Poco::Logger * log = &Poco::Logger::get("IRowInputFormat");
+            LoggerPtr log = getLogger("IRowInputFormat");
             LOG_DEBUG(log, "Skipped {} rows with errors while reading the input stream", num_errors);
         }
 
diff --git a/src/Processors/Formats/ISchemaReader.cpp b/src/Processors/Formats/ISchemaReader.cpp
index 26c632b83dc5..79b7ca17a5af 100644
--- a/src/Processors/Formats/ISchemaReader.cpp
+++ b/src/Processors/Formats/ISchemaReader.cpp
@@ -91,7 +91,7 @@ void IIRowSchemaReader::setContext(ContextPtr & context)
     }
     else
     {
-        LOG_WARNING(&Poco::Logger::get("IIRowSchemaReader"), "Couldn't parse schema inference hints: {}. This setting will be ignored", hints_parsing_error);
+        LOG_WARNING(getLogger("IIRowSchemaReader"), "Couldn't parse schema inference hints: {}. This setting will be ignored", hints_parsing_error);
     }
 }
 
diff --git a/src/Processors/Formats/Impl/AvroRowInputFormat.cpp b/src/Processors/Formats/Impl/AvroRowInputFormat.cpp
index 5722c6600717..8dc8fa516dc0 100644
--- a/src/Processors/Formats/Impl/AvroRowInputFormat.cpp
+++ b/src/Processors/Formats/Impl/AvroRowInputFormat.cpp
@@ -984,7 +984,7 @@ class AvroConfluentRowInputFormat::SchemaRegistry
             try
             {
                 Poco::URI url(base_url, base_url.getPath() + "/schemas/ids/" + std::to_string(id));
-                LOG_TRACE((&Poco::Logger::get("AvroConfluentRowInputFormat")), "Fetching schema id = {} from url {}", id, url.toString());
+                LOG_TRACE((getLogger("AvroConfluentRowInputFormat")), "Fetching schema id = {} from url {}", id, url.toString());
 
                 /// One second for connect/send/receive. Just in case.
                 auto timeouts = ConnectionTimeouts()
@@ -1029,7 +1029,7 @@ class AvroConfluentRowInputFormat::SchemaRegistry
                 markSessionForReuse(session);
 
                 auto schema = json_body->getValue<std::string>("schema");
-                LOG_TRACE((&Poco::Logger::get("AvroConfluentRowInputFormat")), "Successfully fetched schema id = {}
{}", id, schema);
+                LOG_TRACE((getLogger("AvroConfluentRowInputFormat")), "Successfully fetched schema id = {}
{}", id, schema);
                 return avro::compileJsonSchemaFromString(schema);
             }
             catch (const Exception &)
diff --git a/src/Processors/Formats/Impl/DWARFBlockInputFormat.cpp b/src/Processors/Formats/Impl/DWARFBlockInputFormat.cpp
index 43ef25210325..b655e892d3b4 100644
--- a/src/Processors/Formats/Impl/DWARFBlockInputFormat.cpp
+++ b/src/Processors/Formats/Impl/DWARFBlockInputFormat.cpp
@@ -198,7 +198,7 @@ void DWARFBlockInputFormat::initializeIfNeeded()
     if (elf.has_value())
         return;
 
-    LOG_DEBUG(&Poco::Logger::get("DWARF"), "Opening ELF");
+    LOG_DEBUG(getLogger("DWARF"), "Opening ELF");
     initELF();
     if (is_stopped)
         return;
@@ -209,7 +209,7 @@ void DWARFBlockInputFormat::initializeIfNeeded()
     auto abbrev_section = elf->findSectionByName(".debug_abbrev");
     if (!abbrev_section.has_value())
         throw Exception(ErrorCodes::CANNOT_PARSE_ELF, "No .debug_abbrev section");
-    LOG_DEBUG(&Poco::Logger::get("DWARF"), ".debug_abbrev is {:.3f} MiB, .debug_info is {:.3f} MiB", abbrev_section->size() * 1. / (1 << 20), info_section->size() * 1. / (1 << 20));
+    LOG_DEBUG(getLogger("DWARF"), ".debug_abbrev is {:.3f} MiB, .debug_info is {:.3f} MiB", abbrev_section->size() * 1. / (1 << 20), info_section->size() * 1. / (1 << 20));
 
     /// (The StringRef points into Elf's mmap of the whole file, or into file_contents.)
     extractor.emplace(llvm::StringRef(info_section->begin(), info_section->size()), /*IsLittleEndian*/ true, /*AddressSize*/ 8);
@@ -237,7 +237,7 @@ void DWARFBlockInputFormat::initializeIfNeeded()
     for (std::unique_ptr<llvm::DWARFUnit> & unit : dwarf_context->info_section_units())
         units_queue.emplace_back(unit.get());
 
-    LOG_DEBUG(&Poco::Logger::get("DWARF"), "{} units, reading in {} threads", units_queue.size(), num_threads);
+    LOG_DEBUG(getLogger("DWARF"), "{} units, reading in {} threads", units_queue.size(), num_threads);
 
     pool.emplace(CurrentMetrics::DWARFReaderThreads, CurrentMetrics::DWARFReaderThreadsActive, CurrentMetrics::DWARFReaderThreadsScheduled, num_threads);
     for (size_t i = 0; i < num_threads; ++i)
@@ -782,7 +782,7 @@ void DWARFBlockInputFormat::parseFilenameTable(UnitState & unit, uint64_t offset
     auto error = prologue.parse(*debug_line_extractor, &offset, /*RecoverableErrorHandler*/ [&](auto e)
         {
             if (++seen_debug_line_warnings < 10)
-                LOG_INFO(&Poco::Logger::get("DWARF"), "Parsing error: {}", llvm::toString(std::move(e)));
+                LOG_INFO(getLogger("DWARF"), "Parsing error: {}", llvm::toString(std::move(e)));
         }, *dwarf_context, unit.dwarf_unit);
 
     if (error)
diff --git a/src/Processors/Formats/Impl/ParallelFormattingOutputFormat.h b/src/Processors/Formats/Impl/ParallelFormattingOutputFormat.h
index c2f08479730e..50a736463594 100644
--- a/src/Processors/Formats/Impl/ParallelFormattingOutputFormat.h
+++ b/src/Processors/Formats/Impl/ParallelFormattingOutputFormat.h
@@ -84,7 +84,7 @@ class ParallelFormattingOutputFormat : public IOutputFormat
         , pool(CurrentMetrics::ParallelFormattingOutputFormatThreads, CurrentMetrics::ParallelFormattingOutputFormatThreadsActive, CurrentMetrics::ParallelFormattingOutputFormatThreadsScheduled, params.max_threads_for_parallel_formatting)
 
     {
-        LOG_TEST(&Poco::Logger::get("ParallelFormattingOutputFormat"), "Parallel formatting is being used");
+        LOG_TEST(getLogger("ParallelFormattingOutputFormat"), "Parallel formatting is being used");
 
         NullWriteBuffer buf;
         save_totals_and_extremes_in_statistics = internal_formatter_creator(buf)->areTotalsAndExtremesUsedInFinalize();
diff --git a/src/Processors/Formats/Impl/ParallelParsingInputFormat.h b/src/Processors/Formats/Impl/ParallelParsingInputFormat.h
index ff97afa83487..c4736ceea3af 100644
--- a/src/Processors/Formats/Impl/ParallelParsingInputFormat.h
+++ b/src/Processors/Formats/Impl/ParallelParsingInputFormat.h
@@ -111,7 +111,7 @@ class ParallelParsingInputFormat : public IInputFormat
         // bump into reader thread on wraparound.
         processing_units.resize(params.max_threads + 2);
 
-        LOG_TRACE(&Poco::Logger::get("ParallelParsingInputFormat"), "Parallel parsing is used");
+        LOG_TRACE(getLogger("ParallelParsingInputFormat"), "Parallel parsing is used");
     }
 
     ~ParallelParsingInputFormat() override
diff --git a/src/Processors/Formats/Impl/ValuesBlockInputFormat.cpp b/src/Processors/Formats/Impl/ValuesBlockInputFormat.cpp
index aa193ffd36a0..3e61bfbc7942 100644
--- a/src/Processors/Formats/Impl/ValuesBlockInputFormat.cpp
+++ b/src/Processors/Formats/Impl/ValuesBlockInputFormat.cpp
@@ -492,7 +492,7 @@ bool ValuesBlockInputFormat::parseExpression(IColumn & column, size_t column_idx
                 &found_in_cache,
                 delimiter);
 
-            LOG_TEST(&Poco::Logger::get("ValuesBlockInputFormat"), "Will use an expression template to parse column {}: {}",
+            LOG_TEST(getLogger("ValuesBlockInputFormat"), "Will use an expression template to parse column {}: {}",
                      column_idx, structure->dumpTemplate());
 
             templates[column_idx].emplace(structure);
diff --git a/src/Processors/Merges/Algorithms/CollapsingSortedAlgorithm.cpp b/src/Processors/Merges/Algorithms/CollapsingSortedAlgorithm.cpp
index 14325223602e..8948cee217ca 100644
--- a/src/Processors/Merges/Algorithms/CollapsingSortedAlgorithm.cpp
+++ b/src/Processors/Merges/Algorithms/CollapsingSortedAlgorithm.cpp
@@ -28,7 +28,7 @@ CollapsingSortedAlgorithm::CollapsingSortedAlgorithm(
     bool only_positive_sign_,
     size_t max_block_size_rows_,
     size_t max_block_size_bytes_,
-    Poco::Logger * log_,
+    LoggerPtr log_,
     WriteBuffer * out_row_sources_buf_,
     bool use_average_block_sizes)
     : IMergingAlgorithmWithSharedChunks(header_, num_inputs, std::move(description_), out_row_sources_buf_, max_row_refs)
diff --git a/src/Processors/Merges/Algorithms/CollapsingSortedAlgorithm.h b/src/Processors/Merges/Algorithms/CollapsingSortedAlgorithm.h
index 28bb87cb394f..be1a3a3bf33d 100644
--- a/src/Processors/Merges/Algorithms/CollapsingSortedAlgorithm.h
+++ b/src/Processors/Merges/Algorithms/CollapsingSortedAlgorithm.h
@@ -34,7 +34,7 @@ class CollapsingSortedAlgorithm final : public IMergingAlgorithmWithSharedChunks
         bool only_positive_sign_, /// For select final. Skip rows with sum(sign) < 0.
         size_t max_block_size_rows_,
         size_t max_block_size_bytes_,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         WriteBuffer * out_row_sources_buf_ = nullptr,
         bool use_average_block_sizes = false);
 
@@ -64,7 +64,7 @@ class CollapsingSortedAlgorithm final : public IMergingAlgorithmWithSharedChunks
     PODArray<RowSourcePart> current_row_sources;   /// Sources of rows with the current primary key
 
     size_t count_incorrect_data = 0;    /// To prevent too many error messages from writing to the log.
-    Poco::Logger * log;
+    LoggerPtr log;
 
     void reportIncorrectData();
     void insertRow(RowRef & row);
diff --git a/src/Processors/Merges/Algorithms/RowRef.h b/src/Processors/Merges/Algorithms/RowRef.h
index 81969cd19880..ee64224d44df 100644
--- a/src/Processors/Merges/Algorithms/RowRef.h
+++ b/src/Processors/Merges/Algorithms/RowRef.h
@@ -86,7 +86,7 @@ class SharedChunkAllocator
     {
         if (free_chunks.size() != chunks.size())
         {
-            LOG_ERROR(&Poco::Logger::get("SharedChunkAllocator"), "SharedChunkAllocator was destroyed before RowRef was released. StackTrace: {}", StackTrace().toString());
+            LOG_ERROR(getLogger("SharedChunkAllocator"), "SharedChunkAllocator was destroyed before RowRef was released. StackTrace: {}", StackTrace().toString());
 
             return;
         }
@@ -103,7 +103,7 @@ class SharedChunkAllocator
             /// This may happen if allocator was removed before chunks.
             /// Log message and exit, because we don't want to throw exception in destructor.
 
-            LOG_ERROR(&Poco::Logger::get("SharedChunkAllocator"), "SharedChunkAllocator was destroyed before RowRef was released. StackTrace: {}", StackTrace().toString());
+            LOG_ERROR(getLogger("SharedChunkAllocator"), "SharedChunkAllocator was destroyed before RowRef was released. StackTrace: {}", StackTrace().toString());
 
             return;
         }
diff --git a/src/Processors/Merges/CollapsingSortedTransform.h b/src/Processors/Merges/CollapsingSortedTransform.h
index b0cb6bc6d624..4479ac82f66d 100644
--- a/src/Processors/Merges/CollapsingSortedTransform.h
+++ b/src/Processors/Merges/CollapsingSortedTransform.h
@@ -29,7 +29,7 @@ class CollapsingSortedTransform final : public IMergingTransform<CollapsingSorte
             only_positive_sign,
             max_block_size_rows,
             max_block_size_bytes,
-            &Poco::Logger::get("CollapsingSortedTransform"),
+            getLogger("CollapsingSortedTransform"),
             out_row_sources_buf_,
             use_average_block_sizes)
     {
diff --git a/src/Processors/Merges/MergingSortedTransform.cpp b/src/Processors/Merges/MergingSortedTransform.cpp
index 62275f37857f..338b1ff79353 100644
--- a/src/Processors/Merges/MergingSortedTransform.cpp
+++ b/src/Processors/Merges/MergingSortedTransform.cpp
@@ -53,7 +53,7 @@ void MergingSortedTransform::onFinish()
 
     const auto & merged_data = algorithm.getMergedData();
 
-    auto * log = &Poco::Logger::get("MergingSortedTransform");
+    auto log = getLogger("MergingSortedTransform");
 
     double seconds = total_stopwatch.elapsedSeconds();
 
diff --git a/src/Processors/QueryPlan/CreateSetAndFilterOnTheFlyStep.h b/src/Processors/QueryPlan/CreateSetAndFilterOnTheFlyStep.h
index 023901dba026..70ae4c6156e1 100644
--- a/src/Processors/QueryPlan/CreateSetAndFilterOnTheFlyStep.h
+++ b/src/Processors/QueryPlan/CreateSetAndFilterOnTheFlyStep.h
@@ -54,7 +54,7 @@ class CreateSetAndFilterOnTheFlyStep : public ITransformingStep
 
     JoinTableSide position;
 
-    Poco::Logger * log = &Poco::Logger::get("CreateSetAndFilterOnTheFlyStep");
+    LoggerPtr log = getLogger("CreateSetAndFilterOnTheFlyStep");
 };
 
 }
diff --git a/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp b/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp
index 3b31a809f9df..e71bcc5602aa 100644
--- a/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp
+++ b/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp
@@ -383,7 +383,7 @@ size_t tryPushDownFilter(QueryPlan::Node * parent_node, QueryPlan::Nodes & nodes
             const size_t updated_steps = tryAddNewFilterStep(parent_node, nodes, split_filter, can_remove_filter, child_idx);
             if (updated_steps > 0)
             {
-                LOG_DEBUG(&Poco::Logger::get("QueryPlanOptimizations"), "Pushed down filter {} to the {} side of join", split_filter_column_name, kind);
+                LOG_DEBUG(getLogger("QueryPlanOptimizations"), "Pushed down filter {} to the {} side of join", split_filter_column_name, kind);
             }
             return updated_steps;
         };
diff --git a/src/Processors/QueryPlan/Optimizations/optimizePrewhere.cpp b/src/Processors/QueryPlan/Optimizations/optimizePrewhere.cpp
index 5c5171d4296d..7902b36f80ec 100644
--- a/src/Processors/QueryPlan/Optimizations/optimizePrewhere.cpp
+++ b/src/Processors/QueryPlan/Optimizations/optimizePrewhere.cpp
@@ -164,7 +164,7 @@ void optimizePrewhere(Stack & stack, QueryPlan::Nodes & nodes)
         storage.getConditionEstimatorByPredicate(read_from_merge_tree->getQueryInfo(), storage_snapshot, context),
         queried_columns,
         storage.supportedPrewhereColumns(),
-        &Poco::Logger::get("QueryPlanOptimizePrewhere")};
+        getLogger("QueryPlanOptimizePrewhere")};
 
     auto optimize_result = where_optimizer.optimize(filter_step->getExpression(),
         filter_step->getFilterColumnName(),
diff --git a/src/Processors/QueryPlan/Optimizations/optimizeUseAggregateProjection.cpp b/src/Processors/QueryPlan/Optimizations/optimizeUseAggregateProjection.cpp
index c3e651154ae7..534716cc60e9 100644
--- a/src/Processors/QueryPlan/Optimizations/optimizeUseAggregateProjection.cpp
+++ b/src/Processors/QueryPlan/Optimizations/optimizeUseAggregateProjection.cpp
@@ -123,7 +123,7 @@ std::optional<AggregateFunctionMatches> matchAggregateFunctions(
         if (it == projection_aggregate_functions.end())
         {
             // LOG_TRACE(
-            //     &Poco::Logger::get("optimizeUseProjections"),
+            //     getLogger("optimizeUseProjections"),
             //     "Cannot match agg func {} by name {}",
             //     aggregate.column_name, aggregate.function->getName());
 
@@ -151,7 +151,7 @@ std::optional<AggregateFunctionMatches> matchAggregateFunctions(
             /// not match.
             if (!candidate.function->getStateType()->equals(*aggregate.function->getStateType()))
             {
-                // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Cannot match agg func {} vs {} by state {} vs {}",
+                // LOG_TRACE(getLogger("optimizeUseProjections"), "Cannot match agg func {} vs {} by state {} vs {}",
                 //     aggregate.column_name, candidate.column_name,
                 //     candidate.function->getStateType()->getName(), aggregate.function->getStateType()->getName());
                 continue;
@@ -194,7 +194,7 @@ std::optional<AggregateFunctionMatches> matchAggregateFunctions(
                 if (mt == matches.end())
                 {
                     // LOG_TRACE(
-                    //     &Poco::Logger::get("optimizeUseProjections"),
+                    //     getLogger("optimizeUseProjections"),
                     //     "Cannot match agg func {} vs {} : can't match arg {} vs {} : no node in map",
                     //     aggregate.column_name, candidate.column_name, query_name, proj_name);
 
@@ -205,7 +205,7 @@ std::optional<AggregateFunctionMatches> matchAggregateFunctions(
                 if (node_match.node != proj_node || node_match.monotonicity)
                 {
                     // LOG_TRACE(
-                    //     &Poco::Logger::get("optimizeUseProjections"),
+                    //     getLogger("optimizeUseProjections"),
                     //     "Cannot match agg func {} vs {} : can't match arg {} vs {} : no match or monotonicity",
                     //     aggregate.column_name, candidate.column_name, query_name, proj_name);
 
@@ -285,7 +285,7 @@ ActionsDAGPtr analyzeAggregateProjection(
 
     // for (const auto & [node, match] : matches)
     // {
-    //     LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Match {} {} -> {} {} (with monotonicity : {})",
+    //     LOG_TRACE(getLogger("optimizeUseProjections"), "Match {} {} -> {} {} (with monotonicity : {})",
     //         static_cast<const void *>(node), node->result_name,
     //         static_cast<const void *>(match.node), (match.node ? match.node->result_name : ""), match.monotonicity != std::nullopt);
     // }
@@ -379,7 +379,7 @@ ActionsDAGPtr analyzeAggregateProjection(
             /// Not a match and there is no matched child.
             if (frame.node->type == ActionsDAG::ActionType::INPUT)
             {
-                // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Cannot find match for {}", frame.node->result_name);
+                // LOG_TRACE(getLogger("optimizeUseProjections"), "Cannot find match for {}", frame.node->result_name);
                 return {};
             }
 
@@ -389,7 +389,7 @@ ActionsDAGPtr analyzeAggregateProjection(
         }
     }
 
-    // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Folding actions by projection");
+    // LOG_TRACE(getLogger("optimizeUseProjections"), "Folding actions by projection");
 
     auto proj_dag = query.dag->foldActionsByProjection(new_inputs, query_key_nodes);
     appendAggregateFunctions(*proj_dag, aggregates, *matched_aggregates);
@@ -453,7 +453,7 @@ AggregateProjectionCandidates getAggregateProjectionCandidates(
     if (!can_use_minmax_projection && agg_projections.empty())
         return candidates;
 
-    // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Has agg projection");
+    // LOG_TRACE(getLogger("optimizeUseProjections"), "Has agg projection");
 
     QueryDAG dag;
     if (!dag.build(*node.children.front()))
@@ -461,22 +461,22 @@ AggregateProjectionCandidates getAggregateProjectionCandidates(
 
     auto query_index = buildDAGIndex(*dag.dag);
 
-    // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Query DAG: {}", dag.dag->dumpDAG());
+    // LOG_TRACE(getLogger("optimizeUseProjections"), "Query DAG: {}", dag.dag->dumpDAG());
 
     candidates.has_filter = dag.filter_node;
 
     if (can_use_minmax_projection)
     {
         const auto * projection = &*(metadata->minmax_count_projection);
-        // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Try projection {}", projection->name);
+        // LOG_TRACE(getLogger("optimizeUseProjections"), "Try projection {}", projection->name);
         auto info = getAggregatingProjectionInfo(*projection, context, metadata, key_virtual_columns);
-        // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Projection DAG {}", info.before_aggregation->dumpDAG());
+        // LOG_TRACE(getLogger("optimizeUseProjections"), "Projection DAG {}", info.before_aggregation->dumpDAG());
         if (auto proj_dag = analyzeAggregateProjection(info, dag, query_index, keys, aggregates))
         {
-            // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Projection analyzed DAG {}", proj_dag->dumpDAG());
+            // LOG_TRACE(getLogger("optimizeUseProjections"), "Projection analyzed DAG {}", proj_dag->dumpDAG());
             AggregateProjectionCandidate candidate{.info = std::move(info), .dag = std::move(proj_dag)};
 
-            // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Projection sample block {}", sample_block.dumpStructure());
+            // LOG_TRACE(getLogger("optimizeUseProjections"), "Projection sample block {}", sample_block.dumpStructure());
             auto block = reading.getMergeTreeData().getMinMaxCountProjectionBlock(
                 metadata,
                 candidate.dag->getRequiredColumnsNames(),
@@ -485,7 +485,7 @@ AggregateProjectionCandidates getAggregateProjectionCandidates(
                 max_added_blocks.get(),
                 context);
 
-            // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Projection sample block 2 {}", block.dumpStructure());
+            // LOG_TRACE(getLogger("optimizeUseProjections"), "Projection sample block 2 {}", block.dumpStructure());
 
             // minmax_count_projection cannot be used when there is no data to process, because
             // it will produce incorrect result during constant aggregation.
@@ -518,12 +518,12 @@ AggregateProjectionCandidates getAggregateProjectionCandidates(
         candidates.real.reserve(agg_projections.size());
         for (const auto * projection : agg_projections)
         {
-            // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Try projection {}", projection->name);
+            // LOG_TRACE(getLogger("optimizeUseProjections"), "Try projection {}", projection->name);
             auto info = getAggregatingProjectionInfo(*projection, context, metadata, key_virtual_columns);
-            // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Projection DAG {}", info.before_aggregation->dumpDAG());
+            // LOG_TRACE(getLogger("optimizeUseProjections"), "Projection DAG {}", info.before_aggregation->dumpDAG());
             if (auto proj_dag = analyzeAggregateProjection(info, dag, query_index, keys, aggregates))
             {
-                // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Projection analyzed DAG {}", proj_dag->dumpDAG());
+                // LOG_TRACE(getLogger("optimizeUseProjections"), "Projection analyzed DAG {}", proj_dag->dumpDAG());
                 AggregateProjectionCandidate candidate{.info = std::move(info), .dag = std::move(proj_dag)};
                 candidate.projection = projection;
                 candidates.real.emplace_back(std::move(candidate));
@@ -650,7 +650,7 @@ bool optimizeUseAggregateProjections(QueryPlan::Node & node, QueryPlan::Nodes &
     /// Add reading from projection step.
     if (candidates.minmax_projection)
     {
-        // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Minmax proj block {}",
+        // LOG_TRACE(getLogger("optimizeUseProjections"), "Minmax proj block {}",
         //           candidates.minmax_projection->block.dumpStructure());
 
         Pipe pipe(std::make_shared<SourceFromSingleChunk>(std::move(candidates.minmax_projection->block)));
@@ -712,7 +712,7 @@ bool optimizeUseAggregateProjections(QueryPlan::Node & node, QueryPlan::Nodes &
         });
     }
 
-    // LOG_TRACE(&Poco::Logger::get("optimizeUseProjections"), "Projection reading header {}",
+    // LOG_TRACE(getLogger("optimizeUseProjections"), "Projection reading header {}",
     //           projection_reading->getOutputStream().header.dumpStructure());
 
     projection_reading->setStepDescription(best_candidate->projection->name);
diff --git a/src/Processors/QueryPlan/Optimizations/removeRedundantDistinct.cpp b/src/Processors/QueryPlan/Optimizations/removeRedundantDistinct.cpp
index a6029d673e32..232d3118612b 100644
--- a/src/Processors/QueryPlan/Optimizations/removeRedundantDistinct.cpp
+++ b/src/Processors/QueryPlan/Optimizations/removeRedundantDistinct.cpp
@@ -39,14 +39,14 @@ namespace
             else
                 ss << value;
 
-            LOG_DEBUG(&Poco::Logger::get("redundantDistinct"), "{}{}{}", key, separator, ss.str());
+            LOG_DEBUG(getLogger("redundantDistinct"), "{}{}{}", key, separator, ss.str());
         }
     }
 
     void logActionsDAG(const String & prefix, const ActionsDAGPtr & actions)
     {
         if constexpr (debug_logging_enabled)
-            LOG_DEBUG(&Poco::Logger::get("redundantDistinct"), "{} :
{}", prefix, actions->dumpDAG());
+            LOG_DEBUG(getLogger("redundantDistinct"), "{} :
{}", prefix, actions->dumpDAG());
     }
 
     using DistinctColumns = std::set<std::string_view>;
diff --git a/src/Processors/QueryPlan/QueryPlanVisitor.h b/src/Processors/QueryPlan/QueryPlanVisitor.h
index 0f2652166491..aed1a2b22497 100644
--- a/src/Processors/QueryPlan/QueryPlanVisitor.h
+++ b/src/Processors/QueryPlan/QueryPlanVisitor.h
@@ -99,7 +99,7 @@ class QueryPlanVisitor
         {
             const IQueryPlanStep * current_step = node->step.get();
             LOG_DEBUG(
-                &Poco::Logger::get("QueryPlanVisitor"),
+                getLogger("QueryPlanVisitor"),
                 "{}: {}: {}",
                 prefix,
                 getStepId(current_step),
diff --git a/src/Processors/QueryPlan/ReadFromMergeTree.cpp b/src/Processors/QueryPlan/ReadFromMergeTree.cpp
index d02e387afc3d..0465ff54f5a0 100644
--- a/src/Processors/QueryPlan/ReadFromMergeTree.cpp
+++ b/src/Processors/QueryPlan/ReadFromMergeTree.cpp
@@ -247,7 +247,7 @@ ReadFromMergeTree::ReadFromMergeTree(
     size_t num_streams_,
     bool sample_factor_column_queried_,
     std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read_,
-    Poco::Logger * log_,
+    LoggerPtr log_,
     AnalysisResultPtr analyzed_result_ptr_,
     bool enable_parallel_reading)
     : SourceStepWithFilter(DataStream{.header = MergeTreeSelectProcessor::transformHeader(
@@ -274,7 +274,7 @@ ReadFromMergeTree::ReadFromMergeTree(
     , requested_num_streams(num_streams_)
     , sample_factor_column_queried(sample_factor_column_queried_)
     , max_block_numbers_to_read(std::move(max_block_numbers_to_read_))
-    , log(log_)
+    , log(std::move(log_))
     , analyzed_result_ptr(analyzed_result_ptr_)
     , is_parallel_reading_from_replicas(enable_parallel_reading)
 {
@@ -1476,7 +1476,7 @@ ReadFromMergeTree::AnalysisResultPtr ReadFromMergeTree::selectRangesToRead(
     const MergeTreeData & data,
     const Names & real_column_names,
     bool sample_factor_column_queried,
-    Poco::Logger * log,
+    LoggerPtr log,
     std::optional<Indexes> & indexes)
 {
     auto updated_query_info_with_filter_dag = query_info;
@@ -1508,7 +1508,7 @@ ReadFromMergeTree::AnalysisResultPtr ReadFromMergeTree::selectRangesToReadImpl(
     const MergeTreeData & data,
     const Names & real_column_names,
     bool sample_factor_column_queried,
-    Poco::Logger * log,
+    LoggerPtr log,
     std::optional<Indexes> & indexes)
 {
     AnalysisResult result;
diff --git a/src/Processors/QueryPlan/ReadFromMergeTree.h b/src/Processors/QueryPlan/ReadFromMergeTree.h
index aed2a270ca18..fdeaff57279f 100644
--- a/src/Processors/QueryPlan/ReadFromMergeTree.h
+++ b/src/Processors/QueryPlan/ReadFromMergeTree.h
@@ -120,7 +120,7 @@ class ReadFromMergeTree final : public SourceStepWithFilter
         size_t num_streams_,
         bool sample_factor_column_queried_,
         std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read_,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         AnalysisResultPtr analyzed_result_ptr_,
         bool enable_parallel_reading);
 
@@ -168,7 +168,7 @@ class ReadFromMergeTree final : public SourceStepWithFilter
         const MergeTreeData & data,
         const Names & real_column_names,
         bool sample_factor_column_queried,
-        Poco::Logger * log,
+        LoggerPtr log,
         std::optional<Indexes> & indexes);
 
     AnalysisResultPtr selectRangesToRead(
@@ -217,7 +217,7 @@ class ReadFromMergeTree final : public SourceStepWithFilter
         const MergeTreeData & data,
         const Names & real_column_names,
         bool sample_factor_column_queried,
-        Poco::Logger * log,
+        LoggerPtr log,
         std::optional<Indexes> & indexes);
 
     int getSortDirection() const
@@ -259,7 +259,7 @@ class ReadFromMergeTree final : public SourceStepWithFilter
     /// Pre-computed value, needed to trigger sets creating for PK
     mutable std::optional<Indexes> indexes;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     UInt64 selected_parts = 0;
     UInt64 selected_rows = 0;
     UInt64 selected_marks = 0;
diff --git a/src/Processors/QueryPlan/ReadFromRemote.cpp b/src/Processors/QueryPlan/ReadFromRemote.cpp
index 4bbba4cfa304..4dd799039655 100644
--- a/src/Processors/QueryPlan/ReadFromRemote.cpp
+++ b/src/Processors/QueryPlan/ReadFromRemote.cpp
@@ -102,7 +102,7 @@ ReadFromRemote::ReadFromRemote(
     ThrottlerPtr throttler_,
     Scalars scalars_,
     Tables external_tables_,
-    Poco::Logger * log_,
+    LoggerPtr log_,
     UInt32 shard_count_,
     std::shared_ptr<const StorageLimitsList> storage_limits_,
     const String & cluster_name_)
@@ -172,7 +172,7 @@ void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::SelectStream
         catch (const Exception & ex)
         {
             if (ex.code() == ErrorCodes::ALL_CONNECTION_TRIES_FAILED)
-                LOG_WARNING(&Poco::Logger::get("ClusterProxy::SelectStreamFactory"),
+                LOG_WARNING(getLogger("ClusterProxy::SelectStreamFactory"),
                     "Connections to remote replicas of local shard {} failed, will use stale local replica", my_shard.shard_info.shard_num);
             else
                 throw;
@@ -361,7 +361,7 @@ ReadFromParallelRemoteReplicasStep::ReadFromParallelRemoteReplicasStep(
     ThrottlerPtr throttler_,
     Scalars scalars_,
     Tables external_tables_,
-    Poco::Logger * log_,
+    LoggerPtr log_,
     std::shared_ptr<const StorageLimitsList> storage_limits_)
     : ISourceStep(DataStream{.header = std::move(header_)})
     , cluster(cluster_)
@@ -402,7 +402,7 @@ void ReadFromParallelRemoteReplicasStep::initializePipeline(QueryPipelineBuilder
     size_t all_replicas_count = current_settings.max_parallel_replicas;
     if (all_replicas_count > cluster->getShardsInfo().size())
     {
-        LOG_INFO(&Poco::Logger::get("ReadFromParallelRemoteReplicasStep"),
+        LOG_INFO(getLogger("ReadFromParallelRemoteReplicasStep"),
             "The number of replicas requested ({}) is bigger than the real number available in the cluster ({}). "\
             "Will use the latter number to execute the query.", current_settings.max_parallel_replicas, cluster->getShardsInfo().size());
         all_replicas_count = cluster->getShardsInfo().size();
diff --git a/src/Processors/QueryPlan/ReadFromRemote.h b/src/Processors/QueryPlan/ReadFromRemote.h
index 82ef45d6bbf4..f853a12910b6 100644
--- a/src/Processors/QueryPlan/ReadFromRemote.h
+++ b/src/Processors/QueryPlan/ReadFromRemote.h
@@ -35,7 +35,7 @@ class ReadFromRemote final : public ISourceStep
         ThrottlerPtr throttler_,
         Scalars scalars_,
         Tables external_tables_,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         UInt32 shard_count_,
         std::shared_ptr<const StorageLimitsList> storage_limits_,
         const String & cluster_name_);
@@ -57,7 +57,7 @@ class ReadFromRemote final : public ISourceStep
     Scalars scalars;
     Tables external_tables;
     std::shared_ptr<const StorageLimitsList> storage_limits;
-    Poco::Logger * log;
+    LoggerPtr log;
     UInt32 shard_count;
     const String cluster_name;
     std::optional<GetPriorityForLoadBalancing> priority_func_factory;
@@ -80,7 +80,7 @@ class ReadFromParallelRemoteReplicasStep : public ISourceStep
         ThrottlerPtr throttler_,
         Scalars scalars_,
         Tables external_tables_,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         std::shared_ptr<const StorageLimitsList> storage_limits_);
 
     String getName() const override { return "ReadFromRemoteParallelReplicas"; }
@@ -103,7 +103,7 @@ class ReadFromParallelRemoteReplicasStep : public ISourceStep
     Scalars scalars;
     Tables external_tables;
     std::shared_ptr<const StorageLimitsList> storage_limits;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Processors/Sources/MySQLSource.cpp b/src/Processors/Sources/MySQLSource.cpp
index 81225d1cdf25..be691fd5b2e1 100644
--- a/src/Processors/Sources/MySQLSource.cpp
+++ b/src/Processors/Sources/MySQLSource.cpp
@@ -58,7 +58,7 @@ MySQLSource::MySQLSource(
     const Block & sample_block,
     const StreamSettings & settings_)
     : ISource(sample_block.cloneEmpty())
-    , log(&Poco::Logger::get("MySQLSource"))
+    , log(getLogger("MySQLSource"))
     , connection{std::make_unique<Connection>(entry, query_str)}
     , settings{std::make_unique<StreamSettings>(settings_)}
 {
@@ -69,7 +69,7 @@ MySQLSource::MySQLSource(
 /// For descendant MySQLWithFailoverSource
 MySQLSource::MySQLSource(const Block &sample_block_, const StreamSettings & settings_)
     : ISource(sample_block_.cloneEmpty())
-    , log(&Poco::Logger::get("MySQLSource"))
+    , log(getLogger("MySQLSource"))
     , settings(std::make_unique<StreamSettings>(settings_))
 {
     description.init(sample_block_);
diff --git a/src/Processors/Sources/MySQLSource.h b/src/Processors/Sources/MySQLSource.h
index c4d447886c04..fc26ffa3645e 100644
--- a/src/Processors/Sources/MySQLSource.h
+++ b/src/Processors/Sources/MySQLSource.h
@@ -50,7 +50,7 @@ class MySQLSource : public ISource
         mysqlxx::UseQueryResult result;
     };
 
-    Poco::Logger * log;
+    LoggerPtr log;
     std::unique_ptr<Connection> connection;
 
     const std::unique_ptr<StreamSettings> settings;
diff --git a/src/Processors/Sources/ShellCommandSource.cpp b/src/Processors/Sources/ShellCommandSource.cpp
index 1f23292c6b3f..55eaf67eb3b1 100644
--- a/src/Processors/Sources/ShellCommandSource.cpp
+++ b/src/Processors/Sources/ShellCommandSource.cpp
@@ -158,7 +158,7 @@ class TimeoutReadBufferFromFileDescriptor : public BufferWithOwnMemory<ReadBuffe
                         throw Exception(ErrorCodes::UNSUPPORTED_METHOD, "Executable generates stderr: {}", str);
                     else if (stderr_reaction == ExternalCommandStderrReaction::LOG)
                         LOG_WARNING(
-                            &::Poco::Logger::get("TimeoutReadBufferFromFileDescriptor"), "Executable generates stderr: {}", str);
+                            getLogger("TimeoutReadBufferFromFileDescriptor"), "Executable generates stderr: {}", str);
                     else if (stderr_reaction == ExternalCommandStderrReaction::LOG_FIRST)
                     {
                         res = std::min(ssize_t(stderr_result_buf.reserve()), res);
@@ -217,7 +217,7 @@ class TimeoutReadBufferFromFileDescriptor : public BufferWithOwnMemory<ReadBuffe
             stderr_result.reserve(stderr_result_buf.size());
             stderr_result.append(stderr_result_buf.begin(), stderr_result_buf.end());
             LOG_WARNING(
-                &::Poco::Logger::get("ShellCommandSource"),
+                getLogger("ShellCommandSource"),
                 "Executable generates stderr at the {}: {}",
                 stderr_reaction == ExternalCommandStderrReaction::LOG_FIRST ? "beginning" : "end",
                 stderr_result);
diff --git a/src/Processors/Transforms/AggregatingInOrderTransform.h b/src/Processors/Transforms/AggregatingInOrderTransform.h
index af63ac61c3c5..5d50e97f5524 100644
--- a/src/Processors/Transforms/AggregatingInOrderTransform.h
+++ b/src/Processors/Transforms/AggregatingInOrderTransform.h
@@ -83,7 +83,7 @@ class AggregatingInOrderTransform : public IProcessor
     Chunk current_chunk;
     Chunk to_push_chunk;
 
-    Poco::Logger * log = &Poco::Logger::get("AggregatingInOrderTransform");
+    LoggerPtr log = getLogger("AggregatingInOrderTransform");
 };
 
 
diff --git a/src/Processors/Transforms/AggregatingTransform.h b/src/Processors/Transforms/AggregatingTransform.h
index 91fdf479ffbd..e05528afdc73 100644
--- a/src/Processors/Transforms/AggregatingTransform.h
+++ b/src/Processors/Transforms/AggregatingTransform.h
@@ -180,7 +180,7 @@ class AggregatingTransform : public IProcessor
     Processors processors;
 
     AggregatingTransformParamsPtr params;
-    Poco::Logger * log = &Poco::Logger::get("AggregatingTransform");
+    LoggerPtr log = getLogger("AggregatingTransform");
 
     ColumnRawPtrs key_columns;
     Aggregator::AggregateColumns aggregate_columns;
diff --git a/src/Processors/Transforms/ColumnGathererTransform.cpp b/src/Processors/Transforms/ColumnGathererTransform.cpp
index 7c2b93faa913..d7f52a538e1b 100644
--- a/src/Processors/Transforms/ColumnGathererTransform.cpp
+++ b/src/Processors/Transforms/ColumnGathererTransform.cpp
@@ -128,7 +128,7 @@ ColumnGathererTransform::ColumnGathererTransform(
     : IMergingTransform<ColumnGathererStream>(
         num_inputs, header, header, /*have_all_inputs_=*/ true, /*limit_hint_=*/ 0, /*always_read_till_end_=*/ false,
         num_inputs, row_sources_buf_, block_preferred_size_)
-    , log(&Poco::Logger::get("ColumnGathererStream"))
+    , log(getLogger("ColumnGathererStream"))
 {
     if (header.columns() != 1)
         throw Exception(ErrorCodes::INCORRECT_NUMBER_OF_COLUMNS, "Header should have 1 column, but contains {}",
diff --git a/src/Processors/Transforms/ColumnGathererTransform.h b/src/Processors/Transforms/ColumnGathererTransform.h
index b5bbbff9aca1..885cb3f81ba3 100644
--- a/src/Processors/Transforms/ColumnGathererTransform.h
+++ b/src/Processors/Transforms/ColumnGathererTransform.h
@@ -120,7 +120,7 @@ class ColumnGathererTransform final : public IMergingTransform<ColumnGathererStr
     void onFinish() override;
     UInt64 elapsed_ns = 0;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 
diff --git a/src/Processors/Transforms/CreateSetAndFilterOnTheFlyTransform.h b/src/Processors/Transforms/CreateSetAndFilterOnTheFlyTransform.h
index d214a310a8c9..0f5dab06fc91 100644
--- a/src/Processors/Transforms/CreateSetAndFilterOnTheFlyTransform.h
+++ b/src/Processors/Transforms/CreateSetAndFilterOnTheFlyTransform.h
@@ -67,7 +67,7 @@ class CreatingSetsOnTheFlyTransform : public ISimpleTransform
     /// Set to fill
     SetWithStatePtr set;
 
-    Poco::Logger * log = &Poco::Logger::get("CreatingSetsOnTheFlyTransform");
+    LoggerPtr log = getLogger("CreatingSetsOnTheFlyTransform");
 };
 
 /*
@@ -108,7 +108,7 @@ class FilterBySetOnTheFlyTransform : public ISimpleTransform
         size_t result_rows = 0;
     } stat;
 
-    Poco::Logger * log = &Poco::Logger::get("FilterBySetOnTheFlyTransform");
+    LoggerPtr log = getLogger("FilterBySetOnTheFlyTransform");
 };
 
 }
diff --git a/src/Processors/Transforms/CreatingSetsTransform.h b/src/Processors/Transforms/CreatingSetsTransform.h
index d1ec7dcbca74..74dcd829b4da 100644
--- a/src/Processors/Transforms/CreatingSetsTransform.h
+++ b/src/Processors/Transforms/CreatingSetsTransform.h
@@ -63,7 +63,7 @@ class CreatingSetsTransform : public IAccumulatingTransform
     size_t bytes_to_transfer = 0;
 
     using Logger = Poco::Logger;
-    Poco::Logger * log = &Poco::Logger::get("CreatingSetsTransform");
+    LoggerPtr log = getLogger("CreatingSetsTransform");
 
     bool is_initialized = false;
 
diff --git a/src/Processors/Transforms/FillingTransform.cpp b/src/Processors/Transforms/FillingTransform.cpp
index b725c3e1a5fb..aaa98e968031 100644
--- a/src/Processors/Transforms/FillingTransform.cpp
+++ b/src/Processors/Transforms/FillingTransform.cpp
@@ -28,7 +28,7 @@ void logDebug(String key, const T & value, const char * separator = " : ")
         else
             ss << value;
 
-        LOG_DEBUG(&Poco::Logger::get("FillingTransform"), "{}{}{}", key, separator, ss.str());
+        LOG_DEBUG(getLogger("FillingTransform"), "{}{}{}", key, separator, ss.str());
     }
 }
 
diff --git a/src/Processors/Transforms/JoiningTransform.cpp b/src/Processors/Transforms/JoiningTransform.cpp
index 4e7868ea1c2d..0c0a86ce270c 100644
--- a/src/Processors/Transforms/JoiningTransform.cpp
+++ b/src/Processors/Transforms/JoiningTransform.cpp
@@ -14,12 +14,12 @@ namespace ErrorCodes
 
 Block JoiningTransform::transformHeader(Block header, const JoinPtr & join)
 {
-    LOG_DEBUG(&Poco::Logger::get("JoiningTransform"), "Before join block: '{}'", header.dumpStructure());
+    LOG_DEBUG(getLogger("JoiningTransform"), "Before join block: '{}'", header.dumpStructure());
     join->checkTypesOfKeys(header);
     join->initialize(header);
     ExtraBlockPtr tmp;
     join->joinBlock(header, tmp);
-    LOG_DEBUG(&Poco::Logger::get("JoiningTransform"), "After join block: '{}'", header.dumpStructure());
+    LOG_DEBUG(getLogger("JoiningTransform"), "After join block: '{}'", header.dumpStructure());
     return header;
 }
 
diff --git a/src/Processors/Transforms/MergeJoinTransform.cpp b/src/Processors/Transforms/MergeJoinTransform.cpp
index 15c88244cbd3..2d313d4ea5c3 100644
--- a/src/Processors/Transforms/MergeJoinTransform.cpp
+++ b/src/Processors/Transforms/MergeJoinTransform.cpp
@@ -273,7 +273,7 @@ MergeJoinAlgorithm::MergeJoinAlgorithm(
     size_t max_block_size_)
     : table_join(table_join_)
     , max_block_size(max_block_size_)
-    , log(&Poco::Logger::get("MergeJoinAlgorithm"))
+    , log(getLogger("MergeJoinAlgorithm"))
 {
     if (input_headers.size() != 2)
         throw Exception(ErrorCodes::LOGICAL_ERROR, "MergeJoinAlgorithm requires exactly two inputs");
@@ -860,7 +860,7 @@ MergeJoinTransform::MergeJoinTransform(
         /* always_read_till_end_= */ false,
         /* empty_chunk_on_finish_= */ true,
         table_join, input_headers, max_block_size)
-    , log(&Poco::Logger::get("MergeJoinTransform"))
+    , log(getLogger("MergeJoinTransform"))
 {
     LOG_TRACE(log, "Use MergeJoinTransform");
 }
diff --git a/src/Processors/Transforms/MergeJoinTransform.h b/src/Processors/Transforms/MergeJoinTransform.h
index eb45169a2b07..793de00db406 100644
--- a/src/Processors/Transforms/MergeJoinTransform.h
+++ b/src/Processors/Transforms/MergeJoinTransform.h
@@ -269,7 +269,7 @@ class MergeJoinAlgorithm final : public IMergingAlgorithm
 
     Statistic stat;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 class MergeJoinTransform final : public IMergingTransform<MergeJoinAlgorithm>
@@ -289,7 +289,7 @@ class MergeJoinTransform final : public IMergingTransform<MergeJoinAlgorithm>
 protected:
     void onFinish() override;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Processors/Transforms/MergeSortingTransform.cpp b/src/Processors/Transforms/MergeSortingTransform.cpp
index de77711d1294..64d84ea4b007 100644
--- a/src/Processors/Transforms/MergeSortingTransform.cpp
+++ b/src/Processors/Transforms/MergeSortingTransform.cpp
@@ -30,7 +30,7 @@ namespace DB
 class BufferingToFileTransform : public IAccumulatingTransform
 {
 public:
-    BufferingToFileTransform(const Block & header, TemporaryFileStream & tmp_stream_, Poco::Logger * log_)
+    BufferingToFileTransform(const Block & header, TemporaryFileStream & tmp_stream_, LoggerPtr log_)
         : IAccumulatingTransform(header, header)
         , tmp_stream(tmp_stream_)
         , log(log_)
@@ -73,7 +73,7 @@ class BufferingToFileTransform : public IAccumulatingTransform
 private:
     TemporaryFileStream & tmp_stream;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 MergeSortingTransform::MergeSortingTransform(
diff --git a/src/Processors/Transforms/MergeSortingTransform.h b/src/Processors/Transforms/MergeSortingTransform.h
index e8c180b69032..4478d5a07e83 100644
--- a/src/Processors/Transforms/MergeSortingTransform.h
+++ b/src/Processors/Transforms/MergeSortingTransform.h
@@ -50,7 +50,7 @@ class MergeSortingTransform : public SortingTransform
     size_t sum_rows_in_blocks = 0;
     size_t sum_bytes_in_blocks = 0;
 
-    Poco::Logger * log = &Poco::Logger::get("MergeSortingTransform");
+    LoggerPtr log = getLogger("MergeSortingTransform");
 
     /// If remerge doesn't save memory at least several times, mark it as useless and don't do it anymore.
     bool remerge_is_useful = true;
diff --git a/src/Processors/Transforms/MergingAggregatedTransform.h b/src/Processors/Transforms/MergingAggregatedTransform.h
index 73e0d8cd0132..ade76b2f3048 100644
--- a/src/Processors/Transforms/MergingAggregatedTransform.h
+++ b/src/Processors/Transforms/MergingAggregatedTransform.h
@@ -21,7 +21,7 @@ class MergingAggregatedTransform : public IAccumulatingTransform
 
 private:
     AggregatingTransformParamsPtr params;
-    Poco::Logger * log = &Poco::Logger::get("MergingAggregatedTransform");
+    LoggerPtr log = getLogger("MergingAggregatedTransform");
     size_t max_threads;
 
     AggregatedDataVariants data_variants;
diff --git a/src/Processors/Transforms/PasteJoinTransform.cpp b/src/Processors/Transforms/PasteJoinTransform.cpp
index ff3e2fb85e55..d2fa7eed256d 100644
--- a/src/Processors/Transforms/PasteJoinTransform.cpp
+++ b/src/Processors/Transforms/PasteJoinTransform.cpp
@@ -33,7 +33,7 @@ PasteJoinAlgorithm::PasteJoinAlgorithm(
     size_t max_block_size_)
     : table_join(table_join_)
     , max_block_size(max_block_size_)
-    , log(&Poco::Logger::get("PasteJoinAlgorithm"))
+    , log(getLogger("PasteJoinAlgorithm"))
 {
     if (input_headers.size() != 2)
         throw Exception(ErrorCodes::LOGICAL_ERROR, "PasteJoinAlgorithm requires exactly two inputs");
@@ -117,7 +117,7 @@ PasteJoinTransform::PasteJoinTransform(
         /* always_read_till_end_= */ false,
         /* empty_chunk_on_finish_= */ true,
         table_join, input_headers, max_block_size)
-    , log(&Poco::Logger::get("PasteJoinTransform"))
+    , log(getLogger("PasteJoinTransform"))
 {
     LOG_TRACE(log, "Use PasteJoinTransform");
 }
diff --git a/src/Processors/Transforms/PasteJoinTransform.h b/src/Processors/Transforms/PasteJoinTransform.h
index 7ecf70e18dc2..04cb5486cd5d 100644
--- a/src/Processors/Transforms/PasteJoinTransform.h
+++ b/src/Processors/Transforms/PasteJoinTransform.h
@@ -61,7 +61,7 @@ class PasteJoinAlgorithm final : public IMergingAlgorithm
 
     Statistic stat;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     UInt64 last_used_row[2] = {0, 0};
 };
 
@@ -82,7 +82,7 @@ class PasteJoinTransform final : public IMergingTransform<PasteJoinAlgorithm>
 protected:
     void onFinish() override;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Processors/Transforms/TTLCalcTransform.cpp b/src/Processors/Transforms/TTLCalcTransform.cpp
index 31fb61239ef8..2b4ed96d4e38 100644
--- a/src/Processors/Transforms/TTLCalcTransform.cpp
+++ b/src/Processors/Transforms/TTLCalcTransform.cpp
@@ -13,7 +13,7 @@ TTLCalcTransform::TTLCalcTransform(
     bool force_)
     : IAccumulatingTransform(header_, header_)
     , data_part(data_part_)
-    , log(&Poco::Logger::get(storage_.getLogName() + " (TTLCalcTransform)"))
+    , log(getLogger(storage_.getLogName() + " (TTLCalcTransform)"))
 {
     auto old_ttl_infos = data_part->ttl_infos;
 
diff --git a/src/Processors/Transforms/TTLCalcTransform.h b/src/Processors/Transforms/TTLCalcTransform.h
index 495879400dce..baa31c01c526 100644
--- a/src/Processors/Transforms/TTLCalcTransform.h
+++ b/src/Processors/Transforms/TTLCalcTransform.h
@@ -38,7 +38,7 @@ class TTLCalcTransform : public IAccumulatingTransform
 
     /// ttl_infos and empty_columns are updating while reading
     const MergeTreeData::MutableDataPartPtr & data_part;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Processors/Transforms/TTLTransform.cpp b/src/Processors/Transforms/TTLTransform.cpp
index 7cde86098c7a..db9326f9acf0 100644
--- a/src/Processors/Transforms/TTLTransform.cpp
+++ b/src/Processors/Transforms/TTLTransform.cpp
@@ -25,7 +25,7 @@ TTLTransform::TTLTransform(
     bool force_)
     : IAccumulatingTransform(header_, header_)
     , data_part(data_part_)
-    , log(&Poco::Logger::get(storage_.getLogName() + " (TTLTransform)"))
+    , log(getLogger(storage_.getLogName() + " (TTLTransform)"))
 {
     auto old_ttl_infos = data_part->ttl_infos;
 
diff --git a/src/Processors/Transforms/TTLTransform.h b/src/Processors/Transforms/TTLTransform.h
index 3f0dffd19989..3606db7f4c2c 100644
--- a/src/Processors/Transforms/TTLTransform.h
+++ b/src/Processors/Transforms/TTLTransform.h
@@ -42,7 +42,7 @@ class TTLTransform : public IAccumulatingTransform
 
     /// ttl_infos and empty_columns are updating while reading
     const MergeTreeData::MutableDataPartPtr & data_part;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Processors/Transforms/buildPushingToViewsChain.cpp b/src/Processors/Transforms/buildPushingToViewsChain.cpp
index 71d652e74d07..960cc0190015 100644
--- a/src/Processors/Transforms/buildPushingToViewsChain.cpp
+++ b/src/Processors/Transforms/buildPushingToViewsChain.cpp
@@ -267,7 +267,7 @@ Chain buildPushingToViewsChain(
         if (view == nullptr)
         {
             LOG_WARNING(
-                &Poco::Logger::get("PushingToViews"), "Trying to access table {} but it doesn't exist", view_id.getFullTableName());
+                getLogger("PushingToViews"), "Trying to access table {} but it doesn't exist", view_id.getFullTableName());
             continue;
         }
 
@@ -310,7 +310,7 @@ Chain buildPushingToViewsChain(
                 // In case the materialized view is dropped/detached at this point, we register a warning and ignore it
                 assert(materialized_view->is_dropped || materialized_view->is_detached);
                 LOG_WARNING(
-                    &Poco::Logger::get("PushingToViews"), "Trying to access table {} but it doesn't exist", view_id.getFullTableName());
+                    getLogger("PushingToViews"), "Trying to access table {} but it doesn't exist", view_id.getFullTableName());
                 continue;
             }
 
@@ -341,7 +341,7 @@ Chain buildPushingToViewsChain(
                 /// It may happen if materialize view query was changed and it doesn't depend on this source table anymore.
                 /// See setting `allow_experimental_alter_materialized_view_structure`
                 LOG_DEBUG(
-                    &Poco::Logger::get("PushingToViews"), "Table '{}' is not a source for view '{}' anymore, current source is '{}'",
+                    getLogger("PushingToViews"), "Table '{}' is not a source for view '{}' anymore, current source is '{}'",
                         select_query.select_table_id.getFullTableName(), view_id.getFullTableName(), table_id);
                 continue;
             }
@@ -835,14 +835,14 @@ void FinalizingViewsTransform::work()
 
             /// Exception will be ignored, it is saved here for the system.query_views_log
             if (materialized_views_ignore_errors)
-                tryLogException(view.exception, &Poco::Logger::get("PushingToViews"), "Cannot push to the storage, ignoring the error");
+                tryLogException(view.exception, getLogger("PushingToViews"), "Cannot push to the storage, ignoring the error");
         }
         else
         {
             view.runtime_stats->setStatus(QueryViewsLogElement::ViewStatus::QUERY_FINISH);
 
             LOG_TRACE(
-                &Poco::Logger::get("PushingToViews"),
+                getLogger("PushingToViews"),
                 "Pushing ({}) from {} to {} took {} ms.",
                 views_data->max_threads <= 1 ? "sequentially" : ("parallel " + std::to_string(views_data->max_threads)),
                 views_data->source_storage_id.getNameForLogs(),
diff --git a/src/QueryPipeline/RemoteQueryExecutor.h b/src/QueryPipeline/RemoteQueryExecutor.h
index 5a8ccc2592b2..444f1258f3e4 100644
--- a/src/QueryPipeline/RemoteQueryExecutor.h
+++ b/src/QueryPipeline/RemoteQueryExecutor.h
@@ -186,7 +186,7 @@ class RemoteQueryExecutor
 
     void setMainTable(StorageID main_table_) { main_table = std::move(main_table_); }
 
-    void setLogger(Poco::Logger * logger) { log = logger; }
+    void setLogger(LoggerPtr logger) { log = logger; }
 
     const Block & getHeader() const { return header; }
 
@@ -283,7 +283,7 @@ class RemoteQueryExecutor
     PoolMode pool_mode = PoolMode::GET_MANY;
     StorageID main_table = StorageID::createEmpty();
 
-    Poco::Logger * log = nullptr;
+    LoggerPtr log = nullptr;
 
     GetPriorityForLoadBalancing::Func priority_func;
 
diff --git a/src/Server/CertificateReloader.cpp b/src/Server/CertificateReloader.cpp
index 8795d4807de1..c974f450c9a3 100644
--- a/src/Server/CertificateReloader.cpp
+++ b/src/Server/CertificateReloader.cpp
@@ -105,7 +105,7 @@ CertificateReloader::Data::Data(std::string cert_path, std::string key_path, std
 }
 
 
-bool CertificateReloader::File::changeIfModified(std::string new_path, Poco::Logger * logger)
+bool CertificateReloader::File::changeIfModified(std::string new_path, LoggerPtr logger)
 {
     std::error_code ec;
     std::filesystem::file_time_type new_modification_time = std::filesystem::last_write_time(new_path, ec);
diff --git a/src/Server/CertificateReloader.h b/src/Server/CertificateReloader.h
index 9f04179b8d6c..028914e682f1 100644
--- a/src/Server/CertificateReloader.h
+++ b/src/Server/CertificateReloader.h
@@ -14,6 +14,7 @@
 #include <Poco/Crypto/RSAKey.h>
 #include <Poco/Crypto/X509Certificate.h>
 #include <Common/MultiVersion.h>
+#include <Common/Logger.h>
 
 
 namespace DB
@@ -51,7 +52,7 @@ class CertificateReloader
 private:
     CertificateReloader() = default;
 
-    Poco::Logger * log = &Poco::Logger::get("CertificateReloader");
+    LoggerPtr log = getLogger("CertificateReloader");
 
     struct File
     {
@@ -61,7 +62,7 @@ class CertificateReloader
         std::string path;
         std::filesystem::file_time_type modification_time;
 
-        bool changeIfModified(std::string new_path, Poco::Logger * logger);
+        bool changeIfModified(std::string new_path, LoggerPtr logger);
     };
 
     File cert_file{"certificate"};
diff --git a/src/Server/GRPCServer.cpp b/src/Server/GRPCServer.cpp
index 6bb6ba139adf..f31a8d6feb50 100644
--- a/src/Server/GRPCServer.cpp
+++ b/src/Server/GRPCServer.cpp
@@ -76,7 +76,7 @@ namespace
         static std::once_flag once_flag;
         std::call_once(once_flag, [&config]
         {
-            static Poco::Logger * logger = &Poco::Logger::get("grpc");
+            static LoggerPtr logger = getLogger("grpc");
             gpr_set_log_function([](gpr_log_func_args* args)
             {
                 if (args->severity == GPR_LOG_SEVERITY_DEBUG)
@@ -614,7 +614,7 @@ namespace
     class Call
     {
     public:
-        Call(CallType call_type_, std::unique_ptr<BaseResponder> responder_, IServer & iserver_, Poco::Logger * log_);
+        Call(CallType call_type_, std::unique_ptr<BaseResponder> responder_, IServer & iserver_, LoggerPtr log_);
         ~Call();
 
         void start(const std::function<void(void)> & on_finish_call_callback);
@@ -656,7 +656,7 @@ namespace
         const CallType call_type;
         std::unique_ptr<BaseResponder> responder;
         IServer & iserver;
-        Poco::Logger * log = nullptr;
+        LoggerPtr log = nullptr;
 
         std::optional<Session> session;
         ContextMutablePtr query_context;
@@ -718,7 +718,7 @@ namespace
     };
 // NOLINTEND(clang-analyzer-optin.performance.Padding)
 
-    Call::Call(CallType call_type_, std::unique_ptr<BaseResponder> responder_, IServer & iserver_, Poco::Logger * log_)
+    Call::Call(CallType call_type_, std::unique_ptr<BaseResponder> responder_, IServer & iserver_, LoggerPtr log_)
         : call_type(call_type_), responder(std::move(responder_)), iserver(iserver_), log(log_)
     {
     }
@@ -1843,7 +1843,7 @@ class GRPCServer::Runner
 GRPCServer::GRPCServer(IServer & iserver_, const Poco::Net::SocketAddress & address_to_listen_)
     : iserver(iserver_)
     , address_to_listen(address_to_listen_)
-    , log(&Poco::Logger::get("GRPCServer"))
+    , log(getLogger("GRPCServer"))
     , runner(std::make_unique<Runner>(*this))
 {}
 
diff --git a/src/Server/GRPCServer.h b/src/Server/GRPCServer.h
index 359a2506e953..a9c8161298fc 100644
--- a/src/Server/GRPCServer.h
+++ b/src/Server/GRPCServer.h
@@ -5,6 +5,7 @@
 #if USE_GRPC
 #include <Poco/Net/SocketAddress.h>
 #include <base/types.h>
+#include <Common/Logger.h>
 #include "clickhouse_grpc.grpc.pb.h"
 
 namespace Poco { class Logger; }
@@ -46,7 +47,7 @@ class GRPCServer
 
     IServer & iserver;
     const Poco::Net::SocketAddress address_to_listen;
-    Poco::Logger * log;
+    LoggerPtr log;
     GRPCService grpc_service;
     std::unique_ptr<grpc::Server> grpc_server;
     std::unique_ptr<grpc::ServerCompletionQueue> queue;
diff --git a/src/Server/HTTP/HTTPServerRequest.cpp b/src/Server/HTTP/HTTPServerRequest.cpp
index 4a6e85ba0fba..9db02eac2206 100644
--- a/src/Server/HTTP/HTTPServerRequest.cpp
+++ b/src/Server/HTTP/HTTPServerRequest.cpp
@@ -65,7 +65,7 @@ HTTPServerRequest::HTTPServerRequest(HTTPContextPtr context, HTTPServerResponse
     {
         stream = std::move(in);
         if (!startsWith(getContentType(), "multipart/form-data"))
-            LOG_WARNING(LogFrequencyLimiter(&Poco::Logger::get("HTTPServerRequest"), 10), "Got an HTTP request with no content length "
+            LOG_WARNING(LogFrequencyLimiter(getLogger("HTTPServerRequest"), 10), "Got an HTTP request with no content length "
                 "and no chunked/multipart encoding, it may be impossible to distinguish graceful EOF from abnormal connection loss");
     }
     else
diff --git a/src/Server/HTTPHandler.cpp b/src/Server/HTTPHandler.cpp
index bdc8e7d59c9c..72e7c5552f85 100644
--- a/src/Server/HTTPHandler.cpp
+++ b/src/Server/HTTPHandler.cpp
@@ -137,7 +137,7 @@ bool tryAddHttpOptionHeadersFromConfig(HTTPServerResponse & response, const Poco
             {
                 /// If there is empty header name, it will not be processed and message about it will be in logs
                 if (config.getString("http_options_response." + config_key + ".name", "").empty())
-                    LOG_WARNING(&Poco::Logger::get("processOptionsRequest"), "Empty header was found in config. It will not be processed.");
+                    LOG_WARNING(getLogger("processOptionsRequest"), "Empty header was found in config. It will not be processed.");
                 else
                     response.add(config.getString("http_options_response." + config_key + ".name", ""),
                                     config.getString("http_options_response." + config_key + ".value", ""));
@@ -328,7 +328,7 @@ void HTTPHandler::pushDelayedResults(Output & used_output)
 
 HTTPHandler::HTTPHandler(IServer & server_, const std::string & name, const std::optional<String> & content_type_override_)
     : server(server_)
-    , log(&Poco::Logger::get(name))
+    , log(getLogger(name))
     , default_settings(server.context()->getSettingsRef())
     , content_type_override(content_type_override_)
 {
diff --git a/src/Server/HTTPHandler.h b/src/Server/HTTPHandler.h
index 0b623fe5f656..fa2d0dae1993 100644
--- a/src/Server/HTTPHandler.h
+++ b/src/Server/HTTPHandler.h
@@ -100,7 +100,7 @@ class HTTPHandler : public HTTPRequestHandler
     };
 
     IServer & server;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// It is the name of the server that will be sent in an http-header X-ClickHouse-Server-Display-Name.
     String server_display_name;
diff --git a/src/Server/HTTPRequestHandlerFactoryMain.cpp b/src/Server/HTTPRequestHandlerFactoryMain.cpp
index 5481bcd5083c..48c2ab21468a 100644
--- a/src/Server/HTTPRequestHandlerFactoryMain.cpp
+++ b/src/Server/HTTPRequestHandlerFactoryMain.cpp
@@ -7,7 +7,7 @@ namespace DB
 {
 
 HTTPRequestHandlerFactoryMain::HTTPRequestHandlerFactoryMain(const std::string & name_)
-    : log(&Poco::Logger::get(name_)), name(name_)
+    : log(getLogger(name_)), name(name_)
 {
 }
 
diff --git a/src/Server/HTTPRequestHandlerFactoryMain.h b/src/Server/HTTPRequestHandlerFactoryMain.h
index 07b278d831c3..1075b7d1d60d 100644
--- a/src/Server/HTTPRequestHandlerFactoryMain.h
+++ b/src/Server/HTTPRequestHandlerFactoryMain.h
@@ -21,7 +21,7 @@ class HTTPRequestHandlerFactoryMain : public HTTPRequestHandlerFactory
     std::unique_ptr<HTTPRequestHandler> createRequestHandler(const HTTPServerRequest & request) override;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     std::string name;
     HTTPPathHints hints;
 
diff --git a/src/Server/InterserverIOHTTPHandler.h b/src/Server/InterserverIOHTTPHandler.h
index 66042ad3d1df..226a06f5a457 100644
--- a/src/Server/InterserverIOHTTPHandler.h
+++ b/src/Server/InterserverIOHTTPHandler.h
@@ -26,7 +26,7 @@ class InterserverIOHTTPHandler : public HTTPRequestHandler
 public:
     explicit InterserverIOHTTPHandler(IServer & server_)
         : server(server_)
-        , log(&Poco::Logger::get("InterserverIOHTTPHandler"))
+        , log(getLogger("InterserverIOHTTPHandler"))
     {
     }
 
@@ -39,7 +39,7 @@ class InterserverIOHTTPHandler : public HTTPRequestHandler
     };
 
     IServer & server;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     CurrentMetrics::Increment metric_increment{CurrentMetrics::InterserverConnection};
 
diff --git a/src/Server/KeeperReadinessHandler.cpp b/src/Server/KeeperReadinessHandler.cpp
index de6edd199d74..c973be040c8e 100644
--- a/src/Server/KeeperReadinessHandler.cpp
+++ b/src/Server/KeeperReadinessHandler.cpp
@@ -63,7 +63,7 @@ void KeeperReadinessHandler::handleRequest(HTTPServerRequest & /*request*/, HTTP
         }
         catch (...)
         {
-            LOG_ERROR((&Poco::Logger::get("KeeperReadinessHandler")), "Cannot send exception to client");
+            LOG_ERROR((getLogger("KeeperReadinessHandler")), "Cannot send exception to client");
         }
     }
 }
diff --git a/src/Server/KeeperTCPHandler.cpp b/src/Server/KeeperTCPHandler.cpp
index 76b84f0ce6e1..6709cd298e5b 100644
--- a/src/Server/KeeperTCPHandler.cpp
+++ b/src/Server/KeeperTCPHandler.cpp
@@ -220,7 +220,7 @@ KeeperTCPHandler::KeeperTCPHandler(
     Poco::Timespan send_timeout_,
     const Poco::Net::StreamSocket & socket_)
     : Poco::Net::TCPServerConnection(socket_)
-    , log(&Poco::Logger::get("KeeperTCPHandler"))
+    , log(getLogger("KeeperTCPHandler"))
     , keeper_dispatcher(keeper_dispatcher_)
     , operation_timeout(
           0,
diff --git a/src/Server/KeeperTCPHandler.h b/src/Server/KeeperTCPHandler.h
index adb1baa084f9..c1c522eee89d 100644
--- a/src/Server/KeeperTCPHandler.h
+++ b/src/Server/KeeperTCPHandler.h
@@ -63,7 +63,7 @@ class KeeperTCPHandler : public Poco::Net::TCPServerConnection
     ~KeeperTCPHandler() override;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     std::shared_ptr<KeeperDispatcher> keeper_dispatcher;
     Poco::Timespan operation_timeout;
     Poco::Timespan min_session_timeout;
diff --git a/src/Server/KeeperTCPHandlerFactory.h b/src/Server/KeeperTCPHandlerFactory.h
index 36f284442c6c..239bf8b55247 100644
--- a/src/Server/KeeperTCPHandlerFactory.h
+++ b/src/Server/KeeperTCPHandlerFactory.h
@@ -17,7 +17,7 @@ class KeeperTCPHandlerFactory : public TCPServerConnectionFactory
 private:
     ConfigGetter config_getter;
     std::shared_ptr<KeeperDispatcher> keeper_dispatcher;
-    Poco::Logger * log;
+    LoggerPtr log;
     Poco::Timespan receive_timeout;
     Poco::Timespan send_timeout;
 
@@ -37,7 +37,7 @@ class KeeperTCPHandlerFactory : public TCPServerConnectionFactory
         bool secure)
         : config_getter(config_getter_)
         , keeper_dispatcher(keeper_dispatcher_)
-        , log(&Poco::Logger::get(std::string{"KeeperTCP"} + (secure ? "S" : "") + "HandlerFactory"))
+        , log(getLogger(std::string{"KeeperTCP"} + (secure ? "S" : "") + "HandlerFactory"))
         , receive_timeout(/* seconds = */ receive_timeout_seconds, /* microseconds = */ 0)
         , send_timeout(/* seconds = */ send_timeout_seconds, /* microseconds = */ 0)
     {
diff --git a/src/Server/MySQLHandler.cpp b/src/Server/MySQLHandler.cpp
index 969eb24d126c..c159a09c8740 100644
--- a/src/Server/MySQLHandler.cpp
+++ b/src/Server/MySQLHandler.cpp
@@ -78,7 +78,7 @@ MySQLHandler::MySQLHandler(
     : Poco::Net::TCPServerConnection(socket_)
     , server(server_)
     , tcp_server(tcp_server_)
-    , log(&Poco::Logger::get("MySQLHandler"))
+    , log(getLogger("MySQLHandler"))
     , connection_id(connection_id_)
     , auth_plugin(new MySQLProtocol::Authentication::Native41())
     , read_event(read_event_)
diff --git a/src/Server/MySQLHandler.h b/src/Server/MySQLHandler.h
index 36d63ebca849..867a90a6205a 100644
--- a/src/Server/MySQLHandler.h
+++ b/src/Server/MySQLHandler.h
@@ -81,7 +81,7 @@ class MySQLHandler : public Poco::Net::TCPServerConnection
 
     IServer & server;
     TCPServer & tcp_server;
-    Poco::Logger * log;
+    LoggerPtr log;
     uint32_t connection_id = 0;
 
     uint32_t server_capabilities = 0;
diff --git a/src/Server/MySQLHandlerFactory.cpp b/src/Server/MySQLHandlerFactory.cpp
index 79234c647aa6..1dd43e6dab2a 100644
--- a/src/Server/MySQLHandlerFactory.cpp
+++ b/src/Server/MySQLHandlerFactory.cpp
@@ -23,7 +23,7 @@ namespace ErrorCodes
 
 MySQLHandlerFactory::MySQLHandlerFactory(IServer & server_, const ProfileEvents::Event & read_event_, const ProfileEvents::Event & write_event_)
     : server(server_)
-    , log(&Poco::Logger::get("MySQLHandlerFactory"))
+    , log(getLogger("MySQLHandlerFactory"))
     , read_event(read_event_)
     , write_event(write_event_)
 {
diff --git a/src/Server/MySQLHandlerFactory.h b/src/Server/MySQLHandlerFactory.h
index 307ee3b2f0de..4108269d7380 100644
--- a/src/Server/MySQLHandlerFactory.h
+++ b/src/Server/MySQLHandlerFactory.h
@@ -20,7 +20,7 @@ class MySQLHandlerFactory : public TCPServerConnectionFactory
 {
 private:
     IServer & server;
-    Poco::Logger * log;
+    LoggerPtr log;
 
 #if USE_SSL
     struct RSADeleter
diff --git a/src/Server/PostgreSQLHandler.h b/src/Server/PostgreSQLHandler.h
index 57b91a0ad044..1c23d8964152 100644
--- a/src/Server/PostgreSQLHandler.h
+++ b/src/Server/PostgreSQLHandler.h
@@ -40,7 +40,7 @@ class PostgreSQLHandler : public Poco::Net::TCPServerConnection
     void run() final;
 
 private:
-    Poco::Logger * log = &Poco::Logger::get("PostgreSQLHandler");
+    LoggerPtr log = getLogger("PostgreSQLHandler");
 
     IServer & server;
     TCPServer & tcp_server;
diff --git a/src/Server/PostgreSQLHandlerFactory.cpp b/src/Server/PostgreSQLHandlerFactory.cpp
index 096bbbdcda9a..29eb75679760 100644
--- a/src/Server/PostgreSQLHandlerFactory.cpp
+++ b/src/Server/PostgreSQLHandlerFactory.cpp
@@ -7,7 +7,7 @@ namespace DB
 
 PostgreSQLHandlerFactory::PostgreSQLHandlerFactory(IServer & server_, const ProfileEvents::Event & read_event_, const ProfileEvents::Event & write_event_)
     : server(server_)
-    , log(&Poco::Logger::get("PostgreSQLHandlerFactory"))
+    , log(getLogger("PostgreSQLHandlerFactory"))
     , read_event(read_event_)
     , write_event(write_event_)
 {
diff --git a/src/Server/PostgreSQLHandlerFactory.h b/src/Server/PostgreSQLHandlerFactory.h
index e5f762fca6d7..43674306ff66 100644
--- a/src/Server/PostgreSQLHandlerFactory.h
+++ b/src/Server/PostgreSQLHandlerFactory.h
@@ -14,7 +14,7 @@ class PostgreSQLHandlerFactory : public TCPServerConnectionFactory
 {
 private:
     IServer & server;
-    Poco::Logger * log;
+    LoggerPtr log;
     ProfileEvents::Event read_event;
     ProfileEvents::Event write_event;
 
diff --git a/src/Server/ProxyV1Handler.h b/src/Server/ProxyV1Handler.h
index b50c2acbc550..a044b9a966b1 100644
--- a/src/Server/ProxyV1Handler.h
+++ b/src/Server/ProxyV1Handler.h
@@ -13,7 +13,7 @@ class ProxyV1Handler : public Poco::Net::TCPServerConnection
     using StreamSocket = Poco::Net::StreamSocket;
 public:
     explicit ProxyV1Handler(const StreamSocket & socket, IServer & server_, const std::string & conf_name_, TCPProtocolStackData & stack_data_)
-        : Poco::Net::TCPServerConnection(socket), log(&Poco::Logger::get("ProxyV1Handler")), server(server_), conf_name(conf_name_), stack_data(stack_data_) {}
+        : Poco::Net::TCPServerConnection(socket), log(getLogger("ProxyV1Handler")), server(server_), conf_name(conf_name_), stack_data(stack_data_) {}
 
     void run() override;
 
@@ -21,7 +21,7 @@ class ProxyV1Handler : public Poco::Net::TCPServerConnection
     bool readWord(int max_len, std::string & word, bool & eol);
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     IServer & server;
     std::string conf_name;
     TCPProtocolStackData & stack_data;
diff --git a/src/Server/ProxyV1HandlerFactory.h b/src/Server/ProxyV1HandlerFactory.h
index 028596d745d0..0398c8c1ccff 100644
--- a/src/Server/ProxyV1HandlerFactory.h
+++ b/src/Server/ProxyV1HandlerFactory.h
@@ -16,7 +16,7 @@ class ProxyV1HandlerFactory : public TCPServerConnectionFactory
 {
 private:
     IServer & server;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::string conf_name;
 
     class DummyTCPHandler : public Poco::Net::TCPServerConnection
@@ -28,7 +28,7 @@ class ProxyV1HandlerFactory : public TCPServerConnectionFactory
 
 public:
     explicit ProxyV1HandlerFactory(IServer & server_, const std::string & conf_name_)
-        : server(server_), log(&Poco::Logger::get("ProxyV1HandlerFactory")), conf_name(conf_name_)
+        : server(server_), log(getLogger("ProxyV1HandlerFactory")), conf_name(conf_name_)
     {
     }
 
diff --git a/src/Server/ReplicasStatusHandler.cpp b/src/Server/ReplicasStatusHandler.cpp
index 07f3b67b6a7e..91c6bd722d32 100644
--- a/src/Server/ReplicasStatusHandler.cpp
+++ b/src/Server/ReplicasStatusHandler.cpp
@@ -118,7 +118,7 @@ void ReplicasStatusHandler::handleRequest(HTTPServerRequest & request, HTTPServe
         }
         catch (...)
         {
-            LOG_ERROR((&Poco::Logger::get("ReplicasStatusHandler")), "Cannot send exception to client");
+            LOG_ERROR((getLogger("ReplicasStatusHandler")), "Cannot send exception to client");
         }
     }
 }
diff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp
index fa7206eeaac9..ec6b374518d7 100644
--- a/src/Server/TCPHandler.cpp
+++ b/src/Server/TCPHandler.cpp
@@ -189,7 +189,7 @@ TCPHandler::TCPHandler(IServer & server_, TCPServer & tcp_server_, const Poco::N
     , server(server_)
     , tcp_server(tcp_server_)
     , parse_proxy_protocol(parse_proxy_protocol_)
-    , log(&Poco::Logger::get("TCPHandler"))
+    , log(getLogger("TCPHandler"))
     , read_event(read_event_)
     , write_event(write_event_)
     , server_display_name(std::move(server_display_name_))
@@ -200,7 +200,7 @@ TCPHandler::TCPHandler(IServer & server_, TCPServer & tcp_server_, const Poco::N
 : Poco::Net::TCPServerConnection(socket_)
     , server(server_)
     , tcp_server(tcp_server_)
-    , log(&Poco::Logger::get("TCPHandler"))
+    , log(getLogger("TCPHandler"))
     , forwarded_for(stack_data.forwarded_for)
     , certificate(stack_data.certificate)
     , read_event(read_event_)
diff --git a/src/Server/TCPHandler.h b/src/Server/TCPHandler.h
index 4eb84ee5eee5..26cecf466629 100644
--- a/src/Server/TCPHandler.h
+++ b/src/Server/TCPHandler.h
@@ -160,7 +160,7 @@ class TCPHandler : public Poco::Net::TCPServerConnection
     IServer & server;
     TCPServer & tcp_server;
     bool parse_proxy_protocol = false;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     String forwarded_for;
     String certificate;
diff --git a/src/Server/TCPHandlerFactory.h b/src/Server/TCPHandlerFactory.h
index 3eb032f4250b..d65c9898b23b 100644
--- a/src/Server/TCPHandlerFactory.h
+++ b/src/Server/TCPHandlerFactory.h
@@ -18,7 +18,7 @@ class TCPHandlerFactory : public TCPServerConnectionFactory
 private:
     IServer & server;
     bool parse_proxy_protocol = false;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::string server_display_name;
 
     ProfileEvents::Event read_event;
@@ -38,7 +38,7 @@ class TCPHandlerFactory : public TCPServerConnectionFactory
       */
     TCPHandlerFactory(IServer & server_, bool secure_, bool parse_proxy_protocol_, const ProfileEvents::Event & read_event_ = ProfileEvents::end(), const ProfileEvents::Event & write_event_ = ProfileEvents::end())
         : server(server_), parse_proxy_protocol(parse_proxy_protocol_)
-        , log(&Poco::Logger::get(std::string("TCP") + (secure_ ? "S" : "") + "HandlerFactory"))
+        , log(getLogger(std::string("TCP") + (secure_ ? "S" : "") + "HandlerFactory"))
         , read_event(read_event_)
         , write_event(write_event_)
     {
diff --git a/src/Server/TCPProtocolStackFactory.h b/src/Server/TCPProtocolStackFactory.h
index 7373e6e1c4ea..b76bb8d72fdf 100644
--- a/src/Server/TCPProtocolStackFactory.h
+++ b/src/Server/TCPProtocolStackFactory.h
@@ -23,7 +23,7 @@ class TCPProtocolStackFactory : public TCPServerConnectionFactory
 {
 private:
     IServer & server [[maybe_unused]];
-    Poco::Logger * log;
+    LoggerPtr log;
     std::string conf_name;
     std::vector<TCPServerConnectionFactory::Ptr> stack;
     AllowedClientHosts allowed_client_hosts;
@@ -38,7 +38,7 @@ class TCPProtocolStackFactory : public TCPServerConnectionFactory
 public:
     template <typename... T>
     explicit TCPProtocolStackFactory(IServer & server_, const std::string & conf_name_, T... factory)
-        : server(server_), log(&Poco::Logger::get("TCPProtocolStackFactory")), conf_name(conf_name_), stack({factory...})
+        : server(server_), log(getLogger("TCPProtocolStackFactory")), conf_name(conf_name_), stack({factory...})
     {
         const auto & config = server.config();
         /// Fill list of allowed hosts.
diff --git a/src/Server/TLSHandlerFactory.h b/src/Server/TLSHandlerFactory.h
index 9e3002d29719..19602c7d25e9 100644
--- a/src/Server/TLSHandlerFactory.h
+++ b/src/Server/TLSHandlerFactory.h
@@ -19,7 +19,7 @@ class TLSHandlerFactory : public TCPServerConnectionFactory
 {
 private:
     IServer & server;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::string conf_name;
 
     class DummyTCPHandler : public Poco::Net::TCPServerConnection
@@ -31,7 +31,7 @@ class TLSHandlerFactory : public TCPServerConnectionFactory
 
 public:
     explicit TLSHandlerFactory(IServer & server_, const std::string & conf_name_)
-        : server(server_), log(&Poco::Logger::get("TLSHandlerFactory")), conf_name(conf_name_)
+        : server(server_), log(getLogger("TLSHandlerFactory")), conf_name(conf_name_)
     {
     }
 
diff --git a/src/Storages/Cache/ExternalDataSourceCache.h b/src/Storages/Cache/ExternalDataSourceCache.h
index 937801c47671..a5dea2f63db8 100644
--- a/src/Storages/Cache/ExternalDataSourceCache.h
+++ b/src/Storages/Cache/ExternalDataSourceCache.h
@@ -91,7 +91,7 @@ class ExternalDataSourceCache : private boost::noncopyable
     std::mutex mutex;
     std::unique_ptr<RemoteFileCacheType> lru_caches;
 
-    Poco::Logger * log = &Poco::Logger::get("ExternalDataSourceCache");
+    LoggerPtr log = getLogger("ExternalDataSourceCache");
 
     String calculateLocalPath(IRemoteFileMetadataPtr meta) const;
 
diff --git a/src/Storages/Cache/RemoteCacheController.cpp b/src/Storages/Cache/RemoteCacheController.cpp
index b72f5336ea47..403d0c8e43b9 100644
--- a/src/Storages/Cache/RemoteCacheController.cpp
+++ b/src/Storages/Cache/RemoteCacheController.cpp
@@ -20,7 +20,7 @@ namespace ErrorCodes
 
 std::shared_ptr<RemoteCacheController> RemoteCacheController::recover(const std::filesystem::path & local_path_)
 {
-    auto * log = &Poco::Logger::get("RemoteCacheController");
+    auto log = getLogger("RemoteCacheController");
 
     if (!std::filesystem::exists(local_path_ / "data.bin"))
     {
diff --git a/src/Storages/Cache/RemoteCacheController.h b/src/Storages/Cache/RemoteCacheController.h
index fafe363bbd48..782a6b895198 100644
--- a/src/Storages/Cache/RemoteCacheController.h
+++ b/src/Storages/Cache/RemoteCacheController.h
@@ -116,7 +116,7 @@ class RemoteCacheController
     //std::shared_ptr<ReadBuffer> remote_read_buffer;
     std::unique_ptr<WriteBufferFromFileBase> data_file_writer;
 
-    Poco::Logger * log = &Poco::Logger::get("RemoteCacheController");
+    LoggerPtr log = getLogger("RemoteCacheController");
 };
 using RemoteCacheControllerPtr = std::shared_ptr<RemoteCacheController>;
 
diff --git a/src/Storages/DataLakes/DeltaLakeMetadataParser.cpp b/src/Storages/DataLakes/DeltaLakeMetadataParser.cpp
index b8bffb267e57..3584f137225d 100644
--- a/src/Storages/DataLakes/DeltaLakeMetadataParser.cpp
+++ b/src/Storages/DataLakes/DeltaLakeMetadataParser.cpp
@@ -314,7 +314,7 @@ struct DeltaLakeMetadataParser<Configuration, MetadataReadHelper>::Impl
         return version;
     }
 
-    Poco::Logger * log = &Poco::Logger::get("DeltaLakeMetadataParser");
+    LoggerPtr log = getLogger("DeltaLakeMetadataParser");
 };
 
 
diff --git a/src/Storages/DataLakes/HudiMetadataParser.cpp b/src/Storages/DataLakes/HudiMetadataParser.cpp
index 78d69c839891..699dfe8fda02 100644
--- a/src/Storages/DataLakes/HudiMetadataParser.cpp
+++ b/src/Storages/DataLakes/HudiMetadataParser.cpp
@@ -50,7 +50,7 @@ struct HudiMetadataParser<Configuration, MetadataReadHelper>::Impl
       */
     Strings processMetadataFiles(const Configuration & configuration)
     {
-        auto * log = &Poco::Logger::get("HudiMetadataParser");
+        auto log = getLogger("HudiMetadataParser");
 
         const auto keys = MetadataReadHelper::listFiles(configuration, "", Poco::toLower(configuration.format));
 
diff --git a/src/Storages/DataLakes/IStorageDataLake.h b/src/Storages/DataLakes/IStorageDataLake.h
index d87b1272ba68..db3f835494f8 100644
--- a/src/Storages/DataLakes/IStorageDataLake.h
+++ b/src/Storages/DataLakes/IStorageDataLake.h
@@ -25,7 +25,7 @@ class IStorageDataLake : public Storage
     explicit IStorageDataLake(const Configuration & configuration_, ContextPtr context_, bool attach, Args && ...args)
         : Storage(getConfigurationForDataRead(configuration_, context_, {}, attach), context_, std::forward<Args>(args)...)
         , base_configuration(configuration_)
-        , log(&Poco::Logger::get(getName())) {} // NOLINT(clang-analyzer-optin.cplusplus.VirtualCall)
+        , log(getLogger(getName())) {} // NOLINT(clang-analyzer-optin.cplusplus.VirtualCall)
 
     template <class ...Args>
     static StoragePtr create(const Configuration & configuration_, ContextPtr context_, bool attach, Args && ...args)
@@ -78,7 +78,7 @@ class IStorageDataLake : public Storage
                 configuration.keys = keys;
 
             LOG_TRACE(
-                &Poco::Logger::get("DataLake"),
+                getLogger("DataLake"),
                 "New configuration path: {}, keys: {}",
                 configuration.getPath(), fmt::join(configuration.keys, ", "));
 
@@ -112,7 +112,7 @@ class IStorageDataLake : public Storage
 
     Configuration base_configuration;
     std::mutex configuration_update_mutex;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 
diff --git a/src/Storages/DataLakes/Iceberg/IcebergMetadata.cpp b/src/Storages/DataLakes/Iceberg/IcebergMetadata.cpp
index e0c7e26a2e12..e01a9a831c09 100644
--- a/src/Storages/DataLakes/Iceberg/IcebergMetadata.cpp
+++ b/src/Storages/DataLakes/Iceberg/IcebergMetadata.cpp
@@ -58,7 +58,7 @@ IcebergMetadata::IcebergMetadata(
     , manifest_list_file(std::move(manifest_list_file_))
     , current_schema_id(current_schema_id_)
     , schema(std::move(schema_))
-    , log(&Poco::Logger::get("IcebergMetadata"))
+    , log(getLogger("IcebergMetadata"))
 {
 }
 
@@ -375,7 +375,7 @@ std::pair<Int32, String> getMetadataFileAndVersion(const StorageS3::Configuratio
 std::unique_ptr<IcebergMetadata> parseIcebergMetadata(const StorageS3::Configuration & configuration, ContextPtr context_)
 {
     const auto [metadata_version, metadata_file_path] = getMetadataFileAndVersion(configuration);
-    LOG_DEBUG(&Poco::Logger::get("IcebergMetadata"), "Parse metadata {}", metadata_file_path);
+    LOG_DEBUG(getLogger("IcebergMetadata"), "Parse metadata {}", metadata_file_path);
     auto buf = S3DataLakeMetadataReadHelper::createReadBuffer(metadata_file_path, context_, configuration);
     String json_str;
     readJSONObjectPossiblyInvalid(json_str, *buf);
diff --git a/src/Storages/DataLakes/Iceberg/IcebergMetadata.h b/src/Storages/DataLakes/Iceberg/IcebergMetadata.h
index d42ad84f472e..3e6a2ec34157 100644
--- a/src/Storages/DataLakes/Iceberg/IcebergMetadata.h
+++ b/src/Storages/DataLakes/Iceberg/IcebergMetadata.h
@@ -84,7 +84,7 @@ class IcebergMetadata : WithContext
     Int32 current_schema_id;
     NamesAndTypesList schema;
     Strings data_files;
-    Poco::Logger * log;
+    LoggerPtr log;
 
 };
 
diff --git a/src/Storages/DataLakes/S3MetadataReader.cpp b/src/Storages/DataLakes/S3MetadataReader.cpp
index ac472c190e44..d66e21550a33 100644
--- a/src/Storages/DataLakes/S3MetadataReader.cpp
+++ b/src/Storages/DataLakes/S3MetadataReader.cpp
@@ -77,7 +77,7 @@ std::vector<String> S3DataLakeMetadataReadHelper::listFiles(
         is_finished = !outcome.GetResult().GetIsTruncated();
     }
 
-    LOG_TRACE(&Poco::Logger::get("S3DataLakeMetadataReadHelper"), "Listed {} files", res.size());
+    LOG_TRACE(getLogger("S3DataLakeMetadataReadHelper"), "Listed {} files", res.size());
 
     return res;
 }
diff --git a/src/Storages/Distributed/DistributedAsyncInsertDirectoryQueue.cpp b/src/Storages/Distributed/DistributedAsyncInsertDirectoryQueue.cpp
index 26fa489a63df..4e01cb2c6cff 100644
--- a/src/Storages/Distributed/DistributedAsyncInsertDirectoryQueue.cpp
+++ b/src/Storages/Distributed/DistributedAsyncInsertDirectoryQueue.cpp
@@ -60,7 +60,7 @@ namespace
 {
 
 template <typename PoolFactory>
-ConnectionPoolPtrs createPoolsForAddresses(const Cluster::Addresses & addresses, PoolFactory && factory, Poco::Logger * log)
+ConnectionPoolPtrs createPoolsForAddresses(const Cluster::Addresses & addresses, PoolFactory && factory, LoggerPtr log)
 {
     ConnectionPoolPtrs pools;
 
@@ -121,7 +121,7 @@ DistributedAsyncInsertDirectoryQueue::DistributedAsyncInsertDirectoryQueue(
     , default_sleep_time(storage.getDistributedSettingsRef().background_insert_sleep_time_ms.totalMilliseconds())
     , sleep_time(default_sleep_time)
     , max_sleep_time(storage.getDistributedSettingsRef().background_insert_max_sleep_time_ms.totalMilliseconds())
-    , log(&Poco::Logger::get(getLoggerName()))
+    , log(getLogger(getLoggerName()))
     , monitor_blocker(monitor_blocker_)
     , metric_pending_bytes(CurrentMetrics::DistributedBytesToInsert, 0)
     , metric_pending_files(CurrentMetrics::DistributedFilesToInsert, 0)
diff --git a/src/Storages/Distributed/DistributedAsyncInsertDirectoryQueue.h b/src/Storages/Distributed/DistributedAsyncInsertDirectoryQueue.h
index 8bbd99c786a6..f7d7553851a8 100644
--- a/src/Storages/Distributed/DistributedAsyncInsertDirectoryQueue.h
+++ b/src/Storages/Distributed/DistributedAsyncInsertDirectoryQueue.h
@@ -145,7 +145,7 @@ class DistributedAsyncInsertDirectoryQueue
     const std::chrono::milliseconds max_sleep_time;
     std::chrono::time_point<std::chrono::system_clock> last_decrease_time {std::chrono::system_clock::now()};
     std::mutex mutex;
-    Poco::Logger * log;
+    LoggerPtr log;
     ActionBlocker & monitor_blocker;
 
     BackgroundSchedulePoolTaskHolder task_handle;
diff --git a/src/Storages/Distributed/DistributedAsyncInsertHeader.cpp b/src/Storages/Distributed/DistributedAsyncInsertHeader.cpp
index a8ed89e66f12..cfcee4dc8a26 100644
--- a/src/Storages/Distributed/DistributedAsyncInsertHeader.cpp
+++ b/src/Storages/Distributed/DistributedAsyncInsertHeader.cpp
@@ -18,7 +18,7 @@ namespace ErrorCodes
     extern const int CHECKSUM_DOESNT_MATCH;
 }
 
-DistributedAsyncInsertHeader DistributedAsyncInsertHeader::read(ReadBufferFromFile & in, Poco::Logger * log)
+DistributedAsyncInsertHeader DistributedAsyncInsertHeader::read(ReadBufferFromFile & in, LoggerPtr log)
 {
     DistributedAsyncInsertHeader distributed_header;
 
diff --git a/src/Storages/Distributed/DistributedAsyncInsertHeader.h b/src/Storages/Distributed/DistributedAsyncInsertHeader.h
index a7330fa5ef1b..fb4b46964637 100644
--- a/src/Storages/Distributed/DistributedAsyncInsertHeader.h
+++ b/src/Storages/Distributed/DistributedAsyncInsertHeader.h
@@ -38,7 +38,7 @@ struct DistributedAsyncInsertHeader
     std::string block_header_string;
     Block block_header;
 
-    static DistributedAsyncInsertHeader read(ReadBufferFromFile & in, Poco::Logger * log);
+    static DistributedAsyncInsertHeader read(ReadBufferFromFile & in, LoggerPtr log);
     OpenTelemetry::TracingContextHolderPtr createTracingContextHolder(const char * function, std::shared_ptr<OpenTelemetrySpanLog> open_telemetry_span_log) const;
 };
 
diff --git a/src/Storages/Distributed/DistributedAsyncInsertHelpers.cpp b/src/Storages/Distributed/DistributedAsyncInsertHelpers.cpp
index 98073ba1e089..a9bdef31711d 100644
--- a/src/Storages/Distributed/DistributedAsyncInsertHelpers.cpp
+++ b/src/Storages/Distributed/DistributedAsyncInsertHelpers.cpp
@@ -72,7 +72,7 @@ void writeRemoteConvert(
     RemoteInserter & remote,
     bool compression_expected,
     ReadBufferFromFile & in,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     if (!remote.getHeader())
     {
diff --git a/src/Storages/Distributed/DistributedAsyncInsertHelpers.h b/src/Storages/Distributed/DistributedAsyncInsertHelpers.h
index 9543450418ca..202d9ff6fff8 100644
--- a/src/Storages/Distributed/DistributedAsyncInsertHelpers.h
+++ b/src/Storages/Distributed/DistributedAsyncInsertHelpers.h
@@ -1,9 +1,7 @@
 #pragma once
 
-namespace Poco
-{
-class Logger;
-}
+#include <Common/Logger.h>
+
 
 namespace DB
 {
@@ -30,6 +28,6 @@ void writeRemoteConvert(
     RemoteInserter & remote,
     bool compression_expected,
     ReadBufferFromFile & in,
-    Poco::Logger * log);
+    LoggerPtr log);
 
 }
diff --git a/src/Storages/Distributed/DistributedAsyncInsertSource.cpp b/src/Storages/Distributed/DistributedAsyncInsertSource.cpp
index 7992636ac112..33e53da2857f 100644
--- a/src/Storages/Distributed/DistributedAsyncInsertSource.cpp
+++ b/src/Storages/Distributed/DistributedAsyncInsertSource.cpp
@@ -10,7 +10,7 @@ namespace DB
 
 struct DistributedAsyncInsertSource::Data
 {
-    Poco::Logger * log = nullptr;
+    LoggerPtr log = nullptr;
 
     ReadBufferFromFile in;
     CompressedReadBuffer decompressing_in;
@@ -19,7 +19,7 @@ struct DistributedAsyncInsertSource::Data
     Block first_block;
 
     explicit Data(const String & file_name)
-        : log(&Poco::Logger::get("DistributedAsyncInsertSource"))
+        : log(getLogger("DistributedAsyncInsertSource"))
         , in(file_name)
         , decompressing_in(in)
         , block_in(decompressing_in, DistributedAsyncInsertHeader::read(in, log).revision)
diff --git a/src/Storages/Distributed/DistributedSink.cpp b/src/Storages/Distributed/DistributedSink.cpp
index 650539ef1e92..1efa98d0c13b 100644
--- a/src/Storages/Distributed/DistributedSink.cpp
+++ b/src/Storages/Distributed/DistributedSink.cpp
@@ -62,7 +62,7 @@ namespace ErrorCodes
     extern const int ABORTED;
 }
 
-static Block adoptBlock(const Block & header, const Block & block, Poco::Logger * log)
+static Block adoptBlock(const Block & header, const Block & block, LoggerPtr log)
 {
     if (blocksHaveEqualStructure(header, block))
         return block;
@@ -84,7 +84,7 @@ static Block adoptBlock(const Block & header, const Block & block, Poco::Logger
 }
 
 
-static void writeBlockConvert(PushingPipelineExecutor & executor, const Block & block, size_t repeats, Poco::Logger * log)
+static void writeBlockConvert(PushingPipelineExecutor & executor, const Block & block, size_t repeats, LoggerPtr log)
 {
     Block adopted_block = adoptBlock(executor.getHeader(), block, log);
     for (size_t i = 0; i < repeats; ++i)
@@ -126,7 +126,7 @@ DistributedSink::DistributedSink(
     , insert_timeout(insert_timeout_)
     , main_table(main_table_)
     , columns_to_send(columns_to_send_.begin(), columns_to_send_.end())
-    , log(&Poco::Logger::get("DistributedSink"))
+    , log(getLogger("DistributedSink"))
 {
     const auto & settings = context->getSettingsRef();
     if (settings.max_distributed_depth && context->getClientInfo().distributed_depth >= settings.max_distributed_depth)
diff --git a/src/Storages/Distributed/DistributedSink.h b/src/Storages/Distributed/DistributedSink.h
index 1bb4419e1a56..654c1db354f3 100644
--- a/src/Storages/Distributed/DistributedSink.h
+++ b/src/Storages/Distributed/DistributedSink.h
@@ -152,7 +152,7 @@ class DistributedSink : public SinkToStorage
 
     std::atomic<unsigned> finished_jobs_count{0};
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/FileLog/FileLogConsumer.cpp b/src/Storages/FileLog/FileLogConsumer.cpp
index bfe081c7bad9..1bd3026ab8c6 100644
--- a/src/Storages/FileLog/FileLogConsumer.cpp
+++ b/src/Storages/FileLog/FileLogConsumer.cpp
@@ -22,7 +22,7 @@ FileLogConsumer::FileLogConsumer(
     ContextPtr context_,
     size_t stream_number_,
     size_t max_streams_number_)
-    : log(&Poco::Logger::get("FileLogConsumer " + toString(stream_number_)))
+    : log(getLogger("FileLogConsumer " + toString(stream_number_)))
     , storage(storage_)
     , batch_size(max_batch_size)
     , poll_timeout(poll_timeout_)
diff --git a/src/Storages/FileLog/FileLogConsumer.h b/src/Storages/FileLog/FileLogConsumer.h
index b19f3a9350ba..e44bfeb18064 100644
--- a/src/Storages/FileLog/FileLogConsumer.h
+++ b/src/Storages/FileLog/FileLogConsumer.h
@@ -42,7 +42,7 @@ class FileLogConsumer
 
     BufferStatus buffer_status = BufferStatus::INIT;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     StorageFileLog & storage;
 
diff --git a/src/Storages/FileLog/FileLogDirectoryWatcher.cpp b/src/Storages/FileLog/FileLogDirectoryWatcher.cpp
index 9d488616e851..844b31fd7c91 100644
--- a/src/Storages/FileLog/FileLogDirectoryWatcher.cpp
+++ b/src/Storages/FileLog/FileLogDirectoryWatcher.cpp
@@ -6,7 +6,7 @@ namespace DB
 FileLogDirectoryWatcher::FileLogDirectoryWatcher(const std::string & path_, StorageFileLog & storage_, ContextPtr context_)
     : path(path_)
     , storage(storage_)
-    , log(&Poco::Logger::get("FileLogDirectoryWatcher(" + path + ")"))
+    , log(getLogger("FileLogDirectoryWatcher(" + path + ")"))
     , dw(std::make_unique<DirectoryWatcherBase>(*this, path, context_))
 {
 }
diff --git a/src/Storages/FileLog/FileLogDirectoryWatcher.h b/src/Storages/FileLog/FileLogDirectoryWatcher.h
index 9b7afcf8e129..1cf3697c7c07 100644
--- a/src/Storages/FileLog/FileLogDirectoryWatcher.h
+++ b/src/Storages/FileLog/FileLogDirectoryWatcher.h
@@ -65,7 +65,7 @@ class FileLogDirectoryWatcher
     /// accessed in thread created by dw.
     Events events;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::mutex mutex;
 
diff --git a/src/Storages/FileLog/StorageFileLog.cpp b/src/Storages/FileLog/StorageFileLog.cpp
index ef776a3d3137..9c7648ef658b 100644
--- a/src/Storages/FileLog/StorageFileLog.cpp
+++ b/src/Storages/FileLog/StorageFileLog.cpp
@@ -139,7 +139,7 @@ StorageFileLog::StorageFileLog(
     , path(path_)
     , metadata_base_path(std::filesystem::path(metadata_base_path_) / "metadata")
     , format_name(format_name_)
-    , log(&Poco::Logger::get("StorageFileLog (" + table_id_.table_name + ")"))
+    , log(getLogger("StorageFileLog (" + table_id_.table_name + ")"))
     , disk(getContext()->getStoragePolicy("default")->getDisks().at(0))
     , milliseconds_to_wait(filelog_settings->poll_directory_watch_events_backoff_init.totalMilliseconds())
 {
diff --git a/src/Storages/FileLog/StorageFileLog.h b/src/Storages/FileLog/StorageFileLog.h
index 33442d8b33b5..cc5815a1cef4 100644
--- a/src/Storages/FileLog/StorageFileLog.h
+++ b/src/Storages/FileLog/StorageFileLog.h
@@ -149,7 +149,7 @@ class StorageFileLog final : public IStorage, WithContext
     FileInfos file_infos;
 
     const String format_name;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     DiskPtr disk;
 
diff --git a/src/Storages/Freeze.cpp b/src/Storages/Freeze.cpp
index b9642ec79078..a5a5a07c9a12 100644
--- a/src/Storages/Freeze.cpp
+++ b/src/Storages/Freeze.cpp
@@ -76,7 +76,7 @@ bool FreezeMetaData::load(DiskPtr data_disk, const String & path)
     readIntText(version, buffer);
     if (version < 1 || version > 2)
     {
-        LOG_ERROR(&Poco::Logger::get("FreezeMetaData"), "Unknown frozen metadata version: {}", version);
+        LOG_ERROR(getLogger("FreezeMetaData"), "Unknown frozen metadata version: {}", version);
         return false;
     }
     DB::assertChar('
', buffer);
diff --git a/src/Storages/Freeze.h b/src/Storages/Freeze.h
index a64be7465dd2..5775653aaeaa 100644
--- a/src/Storages/Freeze.h
+++ b/src/Storages/Freeze.h
@@ -38,7 +38,7 @@ class Unfreezer
 private:
     ContextPtr local_context;
     zkutil::ZooKeeperPtr zookeeper;
-    Poco::Logger * log = &Poco::Logger::get("Unfreezer");
+    LoggerPtr log = getLogger("Unfreezer");
     static constexpr std::string_view backup_directory_prefix = "shadow";
     static bool removeFreezedPart(DiskPtr disk, const String & path, const String & part_name, ContextPtr local_context, zkutil::ZooKeeperPtr zookeeper);
 };
diff --git a/src/Storages/HDFS/AsynchronousReadBufferFromHDFS.cpp b/src/Storages/HDFS/AsynchronousReadBufferFromHDFS.cpp
index 553473fcc9eb..65df2c020ba1 100644
--- a/src/Storages/HDFS/AsynchronousReadBufferFromHDFS.cpp
+++ b/src/Storages/HDFS/AsynchronousReadBufferFromHDFS.cpp
@@ -44,7 +44,7 @@ AsynchronousReadBufferFromHDFS::AsynchronousReadBufferFromHDFS(
     , prefetch_buffer(settings_.remote_fs_buffer_size)
     , read_until_position(impl->getFileSize())
     , use_prefetch(settings_.remote_fs_prefetch)
-    , log(&Poco::Logger::get("AsynchronousReadBufferFromHDFS"))
+    , log(getLogger("AsynchronousReadBufferFromHDFS"))
 {
     ProfileEvents::increment(ProfileEvents::RemoteFSBuffers);
 }
diff --git a/src/Storages/HDFS/AsynchronousReadBufferFromHDFS.h b/src/Storages/HDFS/AsynchronousReadBufferFromHDFS.h
index 9c01bd6e434e..1d3e8b8e3e98 100644
--- a/src/Storages/HDFS/AsynchronousReadBufferFromHDFS.h
+++ b/src/Storages/HDFS/AsynchronousReadBufferFromHDFS.h
@@ -62,7 +62,7 @@ class AsynchronousReadBufferFromHDFS : public ReadBufferFromFileBase
     std::optional<size_t> read_until_position;
     bool use_prefetch;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Metrics to profile prefetch
     Stopwatch interval_watch;
diff --git a/src/Storages/HDFS/HDFSCommon.cpp b/src/Storages/HDFS/HDFSCommon.cpp
index 12b32b740deb..f9a55a1285ad 100644
--- a/src/Storages/HDFS/HDFSCommon.cpp
+++ b/src/Storages/HDFS/HDFSCommon.cpp
@@ -55,7 +55,7 @@ void HDFSBuilderWrapper::loadFromConfig(
             need_kinit = true;
             hadoop_kerberos_keytab = config.getString(key_path);
             #else // USE_KRB5
-            LOG_WARNING(&Poco::Logger::get("HDFSClient"), "hadoop_kerberos_keytab parameter is ignored because ClickHouse was built without support of krb5 library.");
+            LOG_WARNING(getLogger("HDFSClient"), "hadoop_kerberos_keytab parameter is ignored because ClickHouse was built without support of krb5 library.");
             #endif // USE_KRB5
             continue;
         }
@@ -66,7 +66,7 @@ void HDFSBuilderWrapper::loadFromConfig(
             hadoop_kerberos_principal = config.getString(key_path);
             hdfsBuilderSetPrincipal(hdfs_builder, hadoop_kerberos_principal.c_str());
             #else // USE_KRB5
-            LOG_WARNING(&Poco::Logger::get("HDFSClient"), "hadoop_kerberos_principal parameter is ignored because ClickHouse was built without support of krb5 library.");
+            LOG_WARNING(getLogger("HDFSClient"), "hadoop_kerberos_principal parameter is ignored because ClickHouse was built without support of krb5 library.");
             #endif // USE_KRB5
             continue;
         }
@@ -81,7 +81,7 @@ void HDFSBuilderWrapper::loadFromConfig(
             hadoop_security_kerberos_ticket_cache_path = config.getString(key_path);
             // standard param - pass further
             #else // USE_KRB5
-            LOG_WARNING(&Poco::Logger::get("HDFSClient"), "hadoop.security.kerberos.ticket.cache.path parameter is ignored because ClickHouse was built without support of krb5 library.");
+            LOG_WARNING(getLogger("HDFSClient"), "hadoop.security.kerberos.ticket.cache.path parameter is ignored because ClickHouse was built without support of krb5 library.");
             #endif // USE_KRB5
         }
 
@@ -95,7 +95,7 @@ void HDFSBuilderWrapper::loadFromConfig(
 #if USE_KRB5
 void HDFSBuilderWrapper::runKinit()
 {
-    LOG_DEBUG(&Poco::Logger::get("HDFSClient"), "Running KerberosInit");
+    LOG_DEBUG(getLogger("HDFSClient"), "Running KerberosInit");
     try
     {
         kerberosInit(hadoop_kerberos_keytab,hadoop_kerberos_principal,hadoop_security_kerberos_ticket_cache_path);
@@ -104,7 +104,7 @@ void HDFSBuilderWrapper::runKinit()
     {
         throw Exception(ErrorCodes::KERBEROS_ERROR, "KerberosInit failure: {}", getExceptionMessage(e, false));
     }
-    LOG_DEBUG(&Poco::Logger::get("HDFSClient"), "Finished KerberosInit");
+    LOG_DEBUG(getLogger("HDFSClient"), "Finished KerberosInit");
 }
 #endif // USE_KRB5
 
diff --git a/src/Storages/HDFS/StorageHDFS.h b/src/Storages/HDFS/StorageHDFS.h
index f1f0019d3e05..7170763c959f 100644
--- a/src/Storages/HDFS/StorageHDFS.h
+++ b/src/Storages/HDFS/StorageHDFS.h
@@ -105,7 +105,7 @@ class StorageHDFS final : public IStorage, WithContext
     bool is_path_with_globs;
     NamesAndTypesList virtual_columns;
 
-    Poco::Logger * log = &Poco::Logger::get("StorageHDFS");
+    LoggerPtr log = getLogger("StorageHDFS");
 };
 
 class PullingPipelineExecutor;
diff --git a/src/Storages/HDFS/StorageHDFSCluster.cpp b/src/Storages/HDFS/StorageHDFSCluster.cpp
index 2e8129b9845e..fad294361026 100644
--- a/src/Storages/HDFS/StorageHDFSCluster.cpp
+++ b/src/Storages/HDFS/StorageHDFSCluster.cpp
@@ -45,7 +45,7 @@ StorageHDFSCluster::StorageHDFSCluster(
     const ConstraintsDescription & constraints_,
     const String & compression_method_,
     bool structure_argument_was_provided_)
-    : IStorageCluster(cluster_name_, table_id_, &Poco::Logger::get("StorageHDFSCluster (" + table_id_.table_name + ")"), structure_argument_was_provided_)
+    : IStorageCluster(cluster_name_, table_id_, getLogger("StorageHDFSCluster (" + table_id_.table_name + ")"), structure_argument_was_provided_)
     , uri(uri_)
     , format_name(format_name_)
     , compression_method(compression_method_)
diff --git a/src/Storages/Hive/HiveCommon.cpp b/src/Storages/Hive/HiveCommon.cpp
index 609adcf65c94..b58302f262ec 100644
--- a/src/Storages/Hive/HiveCommon.cpp
+++ b/src/Storages/Hive/HiveCommon.cpp
@@ -25,7 +25,7 @@ static const int hive_metastore_client_recv_timeout_ms = 10000;
 static const int hive_metastore_client_send_timeout_ms = 10000;
 
 ThriftHiveMetastoreClientPool::ThriftHiveMetastoreClientPool(ThriftHiveMetastoreClientBuilder builder_)
-    : PoolBase<Object>(max_hive_metastore_client_connections, &Poco::Logger::get("ThriftHiveMetastoreClientPool")), builder(builder_)
+    : PoolBase<Object>(max_hive_metastore_client_connections, getLogger("ThriftHiveMetastoreClientPool")), builder(builder_)
 {
 }
 
diff --git a/src/Storages/Hive/HiveCommon.h b/src/Storages/Hive/HiveCommon.h
index e2c19fb1684e..0f9d3364ffd4 100644
--- a/src/Storages/Hive/HiveCommon.h
+++ b/src/Storages/Hive/HiveCommon.h
@@ -115,7 +115,7 @@ class HiveMetastoreClient
         const bool empty_partition_keys;
         const HiveFilesCachePtr hive_files_cache;
 
-        Poco::Logger * log = &Poco::Logger::get("HiveMetastoreClient");
+        LoggerPtr log = getLogger("HiveMetastoreClient");
     };
 
 
@@ -138,7 +138,7 @@ class HiveMetastoreClient
     CacheBase<String, HiveTableMetadata> table_metadata_cache;
     ThriftHiveMetastoreClientPool client_pool;
 
-    Poco::Logger * log = &Poco::Logger::get("HiveMetastoreClient");
+    LoggerPtr log = getLogger("HiveMetastoreClient");
 };
 
 using HiveMetastoreClientPtr = std::shared_ptr<HiveMetastoreClient>;
diff --git a/src/Storages/Hive/StorageHive.cpp b/src/Storages/Hive/StorageHive.cpp
index a9347ac4d995..a7ee8ff98916 100644
--- a/src/Storages/Hive/StorageHive.cpp
+++ b/src/Storages/Hive/StorageHive.cpp
@@ -411,7 +411,7 @@ class StorageHiveSource : public ISource, WithContext
     bool generate_chunk_from_metadata{false};
     UInt64 current_file_remained_rows = 0;
 
-    Poco::Logger * log = &Poco::Logger::get("StorageHive");
+    LoggerPtr log = getLogger("StorageHive");
 };
 
 
@@ -780,7 +780,7 @@ class ReadFromHive : public SourceStepWithFilter
         HDFSFSPtr fs_,
         HiveMetastoreClient::HiveTableMetadataPtr hive_table_metadata_,
         Block sample_block_,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         ContextPtr context_,
         size_t max_block_size_,
         size_t num_streams_)
@@ -805,7 +805,7 @@ class ReadFromHive : public SourceStepWithFilter
     HDFSFSPtr fs;
     HiveMetastoreClient::HiveTableMetadataPtr hive_table_metadata;
     Block sample_block;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     ContextPtr context;
     size_t max_block_size;
diff --git a/src/Storages/Hive/StorageHive.h b/src/Storages/Hive/StorageHive.h
index b0ec96604ccc..07440097f7a2 100644
--- a/src/Storages/Hive/StorageHive.h
+++ b/src/Storages/Hive/StorageHive.h
@@ -149,7 +149,7 @@ class StorageHive final : public IStorage, WithContext
 
     std::shared_ptr<HiveSettings> storage_settings;
 
-    Poco::Logger * log = &Poco::Logger::get("StorageHive");
+    LoggerPtr log = getLogger("StorageHive");
 };
 
 }
diff --git a/src/Storages/IMessageProducer.cpp b/src/Storages/IMessageProducer.cpp
index cf3146960417..c723ec77b700 100644
--- a/src/Storages/IMessageProducer.cpp
+++ b/src/Storages/IMessageProducer.cpp
@@ -4,7 +4,7 @@
 namespace DB
 {
 
-IMessageProducer::IMessageProducer(Poco::Logger * log_) : log(log_)
+IMessageProducer::IMessageProducer(LoggerPtr log_) : log(log_)
 {
 }
 
diff --git a/src/Storages/IMessageProducer.h b/src/Storages/IMessageProducer.h
index 12580d5f94a3..c769c3251916 100644
--- a/src/Storages/IMessageProducer.h
+++ b/src/Storages/IMessageProducer.h
@@ -16,7 +16,7 @@ namespace DB
 class IMessageProducer
 {
 public:
-    explicit IMessageProducer(Poco::Logger * log_);
+    explicit IMessageProducer(LoggerPtr log_);
 
     /// Do some preparations.
     virtual void start(const ContextPtr & context) = 0;
@@ -30,14 +30,14 @@ class IMessageProducer
     virtual ~IMessageProducer() = default;
 
 protected:
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 /// Implements interface for concurrent message producing.
 class AsynchronousMessageProducer : public IMessageProducer
 {
 public:
-    explicit AsynchronousMessageProducer(Poco::Logger * log_) : IMessageProducer(log_) {}
+    explicit AsynchronousMessageProducer(LoggerPtr log_) : IMessageProducer(log_) {}
 
     /// Create and schedule task in BackgroundSchedulePool that will produce messages.
     void start(const ContextPtr & context) override;
diff --git a/src/Storages/IStorageCluster.cpp b/src/Storages/IStorageCluster.cpp
index 6f42d8f855ca..c9eb07bd9d11 100644
--- a/src/Storages/IStorageCluster.cpp
+++ b/src/Storages/IStorageCluster.cpp
@@ -32,7 +32,7 @@ namespace DB
 IStorageCluster::IStorageCluster(
     const String & cluster_name_,
     const StorageID & table_id_,
-    Poco::Logger * log_,
+    LoggerPtr log_,
     bool structure_argument_was_provided_)
     : IStorage(table_id_)
     , log(log_)
@@ -54,7 +54,7 @@ class ReadFromCluster : public SourceStepWithFilter
         ASTPtr query_to_send_,
         QueryProcessingStage::Enum processed_stage_,
         ClusterPtr cluster_,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         ContextPtr context_)
         : SourceStepWithFilter(DataStream{.header = std::move(sample_block)})
         , storage(std::move(storage_))
@@ -71,7 +71,7 @@ class ReadFromCluster : public SourceStepWithFilter
     ASTPtr query_to_send;
     QueryProcessingStage::Enum processed_stage;
     ClusterPtr cluster;
-    Poco::Logger * log;
+    LoggerPtr log;
     ContextPtr context;
 
     std::optional<RemoteQueryExecutor::Extension> extension;
diff --git a/src/Storages/IStorageCluster.h b/src/Storages/IStorageCluster.h
index b233f20103db..8d93e94be9ad 100644
--- a/src/Storages/IStorageCluster.h
+++ b/src/Storages/IStorageCluster.h
@@ -19,7 +19,7 @@ class IStorageCluster : public IStorage
     IStorageCluster(
         const String & cluster_name_,
         const StorageID & table_id_,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         bool structure_argument_was_provided_);
 
     void read(
@@ -46,7 +46,7 @@ class IStorageCluster : public IStorage
     virtual void addColumnsStructureToQuery(ASTPtr & query, const String & structure, const ContextPtr & context) = 0;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
     String cluster_name;
     bool structure_argument_was_provided;
 };
diff --git a/src/Storages/Kafka/KafkaConsumer.cpp b/src/Storages/Kafka/KafkaConsumer.cpp
index 40f2897322de..47167e19a38b 100644
--- a/src/Storages/Kafka/KafkaConsumer.cpp
+++ b/src/Storages/Kafka/KafkaConsumer.cpp
@@ -47,7 +47,7 @@ const auto DRAIN_TIMEOUT_MS = 5000ms;
 
 
 KafkaConsumer::KafkaConsumer(
-    Poco::Logger * log_,
+    LoggerPtr log_,
     size_t max_batch_size,
     size_t poll_timeout_,
     bool intermediate_commit_,
diff --git a/src/Storages/Kafka/KafkaConsumer.h b/src/Storages/Kafka/KafkaConsumer.h
index c4dfc56312fe..9cc78d428566 100644
--- a/src/Storages/Kafka/KafkaConsumer.h
+++ b/src/Storages/Kafka/KafkaConsumer.h
@@ -62,7 +62,7 @@ class KafkaConsumer
     };
 
     KafkaConsumer(
-        Poco::Logger * log_,
+        LoggerPtr log_,
         size_t max_batch_size,
         size_t poll_timeout_,
         bool intermediate_commit_,
@@ -150,7 +150,7 @@ class KafkaConsumer
     std::string rdkafka_stat;
 
     ConsumerPtr consumer;
-    Poco::Logger * log;
+    LoggerPtr log;
     const size_t batch_size = 1;
     const size_t poll_timeout = 0;
     size_t offsets_stored = 0;
diff --git a/src/Storages/Kafka/KafkaProducer.cpp b/src/Storages/Kafka/KafkaProducer.cpp
index edbfc76ef939..77676fb010b4 100644
--- a/src/Storages/Kafka/KafkaProducer.cpp
+++ b/src/Storages/Kafka/KafkaProducer.cpp
@@ -18,7 +18,7 @@ namespace DB
 
 KafkaProducer::KafkaProducer(
     ProducerPtr producer_, const std::string & topic_, std::chrono::milliseconds poll_timeout, std::atomic<bool> & shutdown_called_, const Block & header)
-    : IMessageProducer(&Poco::Logger::get("KafkaProducer"))
+    : IMessageProducer(getLogger("KafkaProducer"))
     , producer(producer_)
     , topic(topic_)
     , timeout(poll_timeout)
diff --git a/src/Storages/Kafka/KafkaSource.cpp b/src/Storages/Kafka/KafkaSource.cpp
index 1fbd7e2d705f..dc62c13f6332 100644
--- a/src/Storages/Kafka/KafkaSource.cpp
+++ b/src/Storages/Kafka/KafkaSource.cpp
@@ -33,7 +33,7 @@ KafkaSource::KafkaSource(
     const StorageSnapshotPtr & storage_snapshot_,
     const ContextPtr & context_,
     const Names & columns,
-    Poco::Logger * log_,
+    LoggerPtr log_,
     size_t max_block_size_,
     bool commit_in_suffix_)
     : ISource(storage_snapshot_->getSampleBlockForColumns(columns))
diff --git a/src/Storages/Kafka/KafkaSource.h b/src/Storages/Kafka/KafkaSource.h
index 485a8e55b6a9..a1b94b15a19a 100644
--- a/src/Storages/Kafka/KafkaSource.h
+++ b/src/Storages/Kafka/KafkaSource.h
@@ -22,7 +22,7 @@ class KafkaSource : public ISource
         const StorageSnapshotPtr & storage_snapshot_,
         const ContextPtr & context_,
         const Names & columns,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         size_t max_block_size_,
         bool commit_in_suffix = false);
     ~KafkaSource() override;
@@ -41,7 +41,7 @@ class KafkaSource : public ISource
     StorageSnapshotPtr storage_snapshot;
     ContextPtr context;
     Names column_names;
-    Poco::Logger * log;
+    LoggerPtr log;
     UInt64 max_block_size;
 
     KafkaConsumerPtr consumer;
diff --git a/src/Storages/Kafka/StorageKafka.cpp b/src/Storages/Kafka/StorageKafka.cpp
index 522a381700d0..aa347fc719de 100644
--- a/src/Storages/Kafka/StorageKafka.cpp
+++ b/src/Storages/Kafka/StorageKafka.cpp
@@ -327,7 +327,7 @@ StorageKafka::StorageKafka(
     , max_rows_per_message(kafka_settings->kafka_max_rows_per_message.value)
     , schema_name(getContext()->getMacros()->expand(kafka_settings->kafka_schema.value, macros_info))
     , num_consumers(kafka_settings->kafka_num_consumers.value)
-    , log(&Poco::Logger::get("StorageKafka (" + table_id_.table_name + ")"))
+    , log(getLogger("StorageKafka (" + table_id_.table_name + ")"))
     , intermediate_commit(kafka_settings->kafka_commit_every_batch.value)
     , settings_adjustments(createSettingsAdjustments())
     , thread_per_consumer(kafka_settings->kafka_thread_per_consumer.value)
diff --git a/src/Storages/Kafka/StorageKafka.h b/src/Storages/Kafka/StorageKafka.h
index d370d6018f77..f9a1e3ff6f3a 100644
--- a/src/Storages/Kafka/StorageKafka.h
+++ b/src/Storages/Kafka/StorageKafka.h
@@ -101,7 +101,7 @@ class StorageKafka final : public IStorage, WithContext
     const size_t max_rows_per_message;
     const String schema_name;
     const size_t num_consumers; /// total number of consumers
-    Poco::Logger * log;
+    LoggerPtr log;
     const bool intermediate_commit;
     const SettingsChanges settings_adjustments;
 
diff --git a/src/Storages/LiveView/StorageLiveView.cpp b/src/Storages/LiveView/StorageLiveView.cpp
index 3c116321083e..f81225bbee32 100644
--- a/src/Storages/LiveView/StorageLiveView.cpp
+++ b/src/Storages/LiveView/StorageLiveView.cpp
@@ -209,7 +209,7 @@ StorageLiveView::StorageLiveView(
     live_view_context = Context::createCopy(getContext());
     live_view_context->makeQueryContext();
 
-    log = &Poco::Logger::get("StorageLiveView (" + table_id_.database_name + "." + table_id_.table_name + ")");
+    log = getLogger("StorageLiveView (" + table_id_.database_name + "." + table_id_.table_name + ")");
 
     StorageInMemoryMetadata storage_metadata;
     storage_metadata.setColumns(columns_);
diff --git a/src/Storages/LiveView/StorageLiveView.h b/src/Storages/LiveView/StorageLiveView.h
index e0566d586ee1..6b8780cb81b0 100644
--- a/src/Storages/LiveView/StorageLiveView.h
+++ b/src/Storages/LiveView/StorageLiveView.h
@@ -184,7 +184,7 @@ using MilliSeconds = std::chrono::milliseconds;
 
     ContextMutablePtr live_view_context;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     bool is_periodically_refreshed = false;
     Seconds periodic_live_view_refresh;
diff --git a/src/Storages/MaterializedView/RefreshTask.cpp b/src/Storages/MaterializedView/RefreshTask.cpp
index bc26301e3b9e..daf7bd657841 100644
--- a/src/Storages/MaterializedView/RefreshTask.cpp
+++ b/src/Storages/MaterializedView/RefreshTask.cpp
@@ -27,7 +27,7 @@ namespace ErrorCodes
 
 RefreshTask::RefreshTask(
     const ASTRefreshStrategy & strategy)
-    : log(&Poco::Logger::get("RefreshTask"))
+    : log(getLogger("RefreshTask"))
     , refresh_schedule(strategy)
 {}
 
diff --git a/src/Storages/MaterializedView/RefreshTask.h b/src/Storages/MaterializedView/RefreshTask.h
index 8a062f6f3591..78599f4f4b41 100644
--- a/src/Storages/MaterializedView/RefreshTask.h
+++ b/src/Storages/MaterializedView/RefreshTask.h
@@ -62,7 +62,7 @@ class RefreshTask : public std::enable_shared_from_this<RefreshTask>
     void setFakeTime(std::optional<Int64> t);
 
 private:
-    Poco::Logger * log = nullptr;
+    LoggerPtr log = nullptr;
     std::weak_ptr<IStorage> view_to_refresh;
 
     /// Protects interrupt_execution and running_executor.
diff --git a/src/Storages/MergeTree/AsyncBlockIDsCache.cpp b/src/Storages/MergeTree/AsyncBlockIDsCache.cpp
index cc3bc8fc2a8e..9d64592ed64f 100644
--- a/src/Storages/MergeTree/AsyncBlockIDsCache.cpp
+++ b/src/Storages/MergeTree/AsyncBlockIDsCache.cpp
@@ -60,7 +60,7 @@ AsyncBlockIDsCache<TStorage>::AsyncBlockIDsCache(TStorage & storage_)
     , update_wait(storage.getSettings()->async_block_ids_cache_update_wait_ms)
     , path(storage.getZooKeeperPath() + "/async_blocks")
     , log_name(storage.getStorageID().getFullTableName() + " (AsyncBlockIDsCache)")
-    , log(&Poco::Logger::get(log_name))
+    , log(getLogger(log_name))
 {
     task = storage.getContext()->getSchedulePool().createTask(log_name, [this]{ update(); });
 }
diff --git a/src/Storages/MergeTree/AsyncBlockIDsCache.h b/src/Storages/MergeTree/AsyncBlockIDsCache.h
index 38c38da0033d..bea012f1d329 100644
--- a/src/Storages/MergeTree/AsyncBlockIDsCache.h
+++ b/src/Storages/MergeTree/AsyncBlockIDsCache.h
@@ -43,7 +43,7 @@ class AsyncBlockIDsCache
     BackgroundSchedulePool::TaskHolder task;
 
     const String log_name;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/MergeTree/DataPartStorageOnDiskBase.cpp b/src/Storages/MergeTree/DataPartStorageOnDiskBase.cpp
index f4b92ff8c577..0cb9eb84bf8d 100644
--- a/src/Storages/MergeTree/DataPartStorageOnDiskBase.cpp
+++ b/src/Storages/MergeTree/DataPartStorageOnDiskBase.cpp
@@ -57,7 +57,7 @@ std::string DataPartStorageOnDiskBase::getRelativePath() const
     return fs::path(root_path) / part_dir / "";
 }
 
-std::optional<String> DataPartStorageOnDiskBase::getRelativePathForPrefix(Poco::Logger * log, const String & prefix, bool detached, bool broken) const
+std::optional<String> DataPartStorageOnDiskBase::getRelativePathForPrefix(LoggerPtr log, const String & prefix, bool detached, bool broken) const
 {
     assert(!broken || detached);
     String res;
@@ -471,7 +471,7 @@ MutableDataPartStoragePtr DataPartStorageOnDiskBase::clonePart(
     const DiskPtr & dst_disk,
     const ReadSettings & read_settings,
     const WriteSettings & write_settings,
-    Poco::Logger * log,
+    LoggerPtr log,
     const std::function<void()> & cancellation_hook) const
 {
     String path_to_clone = fs::path(to) / dir_path / "";
@@ -505,7 +505,7 @@ MutableDataPartStoragePtr DataPartStorageOnDiskBase::clonePart(
 void DataPartStorageOnDiskBase::rename(
     std::string new_root_path,
     std::string new_part_dir,
-    Poco::Logger * log,
+    LoggerPtr log,
     bool remove_new_dir_if_exists,
     bool fsync_part_dir)
 {
@@ -564,7 +564,7 @@ void DataPartStorageOnDiskBase::remove(
     const MergeTreeDataPartChecksums & checksums,
     std::list<ProjectionChecksums> projections,
     bool is_temp,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     /// NOTE We rename part to delete_tmp_<relative_path> instead of delete_tmp_<name> to avoid race condition
     /// when we try to remove two parts with the same name, but different relative paths,
@@ -722,7 +722,7 @@ void DataPartStorageOnDiskBase::clearDirectory(
     const CanRemoveDescription & can_remove_description,
     const MergeTreeDataPartChecksums & checksums,
     bool is_temp,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     auto disk = volume->getDisk();
     auto [can_remove_shared_data, names_not_to_remove] = can_remove_description;
diff --git a/src/Storages/MergeTree/DataPartStorageOnDiskBase.h b/src/Storages/MergeTree/DataPartStorageOnDiskBase.h
index 339acce59537..52dc850c7fdd 100644
--- a/src/Storages/MergeTree/DataPartStorageOnDiskBase.h
+++ b/src/Storages/MergeTree/DataPartStorageOnDiskBase.h
@@ -25,7 +25,7 @@ class DataPartStorageOnDiskBase : public IDataPartStorage
     UInt64 calculateTotalSizeOnDisk() const override;
 
     /// Returns path to place detached part in or nullopt if we don't need to detach part (if it already exists and has the same content)
-    std::optional<String> getRelativePathForPrefix(Poco::Logger * log, const String & prefix, bool detached, bool broken) const override;
+    std::optional<String> getRelativePathForPrefix(LoggerPtr log, const String & prefix, bool detached, bool broken) const override;
 
     /// Returns true if detached part already exists and has the same content (compares checksums.txt and the list of files)
     bool looksLikeBrokenDetachedPartHasTheSameContent(const String & detached_part_path, std::optional<String> & original_checksums_content,
@@ -74,14 +74,14 @@ class DataPartStorageOnDiskBase : public IDataPartStorage
         const DiskPtr & dst_disk,
         const ReadSettings & read_settings,
         const WriteSettings & write_settings,
-        Poco::Logger * log,
+        LoggerPtr log,
         const std::function<void()> & cancellation_hook
         ) const override;
 
     void rename(
         std::string new_root_path,
         std::string new_part_dir,
-        Poco::Logger * log,
+        LoggerPtr log,
         bool remove_new_dir_if_exists,
         bool fsync_part_dir) override;
 
@@ -90,7 +90,7 @@ class DataPartStorageOnDiskBase : public IDataPartStorage
         const MergeTreeDataPartChecksums & checksums,
         std::list<ProjectionChecksums> projections,
         bool is_temp,
-        Poco::Logger * log) override;
+        LoggerPtr log) override;
 
     void changeRootPath(const std::string & from_root, const std::string & to_root) override;
     void createDirectories() override;
@@ -130,7 +130,7 @@ class DataPartStorageOnDiskBase : public IDataPartStorage
         const CanRemoveDescription & can_remove_description,
         const MergeTreeDataPartChecksums & checksums,
         bool is_temp,
-        Poco::Logger * log);
+        LoggerPtr log);
 
     /// For names of expected data part files returns the actual names
     /// of files in filesystem to which data of these files is written.
diff --git a/src/Storages/MergeTree/DataPartsExchange.cpp b/src/Storages/MergeTree/DataPartsExchange.cpp
index a59f2a356e88..ce70fbe18e50 100644
--- a/src/Storages/MergeTree/DataPartsExchange.cpp
+++ b/src/Storages/MergeTree/DataPartsExchange.cpp
@@ -99,7 +99,7 @@ struct ReplicatedFetchReadCallback
 
 Service::Service(StorageReplicatedMergeTree & data_)
     : data(data_)
-    , log(&Poco::Logger::get(data.getStorageID().getNameForLogs() + " (Replicated PartsService)"))
+    , log(getLogger(data.getStorageID().getNameForLogs() + " (Replicated PartsService)"))
 {}
 
 std::string Service::getId(const std::string & node_id) const
@@ -415,7 +415,7 @@ MergeTreeData::DataPartPtr Service::findPart(const String & name)
 
 Fetcher::Fetcher(StorageReplicatedMergeTree & data_)
     : data(data_)
-    , log(&Poco::Logger::get(data.getStorageID().getNameForLogs() + " (Fetcher)"))
+    , log(getLogger(data.getStorageID().getNameForLogs() + " (Fetcher)"))
 {}
 
 std::pair<MergeTreeData::MutableDataPartPtr, scope_guard> Fetcher::fetchSelectedPart(
diff --git a/src/Storages/MergeTree/DataPartsExchange.h b/src/Storages/MergeTree/DataPartsExchange.h
index 07939a660a87..8c15dc3cfdb4 100644
--- a/src/Storages/MergeTree/DataPartsExchange.h
+++ b/src/Storages/MergeTree/DataPartsExchange.h
@@ -55,7 +55,7 @@ class Service final : public InterserverIOEndpoint
     /// StorageReplicatedMergeTree::shutdown() waits for all parts exchange handlers to finish,
     /// so Service will never access dangling reference to storage
     StorageReplicatedMergeTree & data;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 /** Client for getting the parts from the table *MergeTree.
@@ -137,7 +137,7 @@ class Fetcher final : private boost::noncopyable
        ThrottlerPtr throttler);
 
     StorageReplicatedMergeTree & data;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/MergeTree/EphemeralLockInZooKeeper.cpp b/src/Storages/MergeTree/EphemeralLockInZooKeeper.cpp
index 5741e11aa224..1ffb51774302 100644
--- a/src/Storages/MergeTree/EphemeralLockInZooKeeper.cpp
+++ b/src/Storages/MergeTree/EphemeralLockInZooKeeper.cpp
@@ -64,7 +64,7 @@ std::optional<EphemeralLockInZooKeeper> createEphemeralLockInZooKeeper(
                 {
                     const String & failed_op_path = ops[failed_idx]->getPath();
                     LOG_DEBUG(
-                        &Poco::Logger::get("createEphemeralLockInZooKeeper"),
+                        getLogger("createEphemeralLockInZooKeeper"),
                         "Deduplication path already exists: deduplication_path={}",
                         failed_op_path);
                     return EphemeralLockInZooKeeper{"", nullptr, "", failed_op_path};
@@ -73,7 +73,7 @@ std::optional<EphemeralLockInZooKeeper> createEphemeralLockInZooKeeper(
             else if (responses[0]->error == Coordination::Error::ZNODEEXISTS)
             {
                 LOG_DEBUG(
-                    &Poco::Logger::get("createEphemeralLockInZooKeeper"),
+                    getLogger("createEphemeralLockInZooKeeper"),
                     "Deduplication path already exists: deduplication_path={}",
                     deduplication_path);
                 return {};
@@ -119,7 +119,7 @@ EphemeralLockInZooKeeper::~EphemeralLockInZooKeeper()
     {
         if (Coordination::isHardwareError(e.code))
             LOG_DEBUG(
-                &Poco::Logger::get("EphemeralLockInZooKeeper"),
+                getLogger("EphemeralLockInZooKeeper"),
                 "ZooKeeper communication error during unlock: code={} message='{}'",
                 e.code,
                 e.message());
@@ -130,7 +130,7 @@ EphemeralLockInZooKeeper::~EphemeralLockInZooKeeper()
             /// But it's possible that the multi op request can be executed on server side, and client will not get response due to network issue.
             /// In such case, assumeUnlocked() will not be called, so we'll get ZNONODE error here since the noded is already deleted
             LOG_DEBUG(
-                &Poco::Logger::get("EphemeralLockInZooKeeper"),
+                getLogger("EphemeralLockInZooKeeper"),
                 "ZooKeeper node was already deleted: code={} message={}",
                 e.code,
                 e.message());
@@ -168,7 +168,7 @@ EphemeralLocksInAllPartitions::EphemeralLocksInAllPartitions(
         Coordination::Error rc = zookeeper->tryMulti(lock_ops, lock_responses);
         if (rc == Coordination::Error::ZBADVERSION)
         {
-            LOG_TRACE(&Poco::Logger::get("EphemeralLocksInAllPartitions"), "Someone has inserted a block in a new partition while we were creating locks. Retry.");
+            LOG_TRACE(getLogger("EphemeralLocksInAllPartitions"), "Someone has inserted a block in a new partition while we were creating locks. Retry.");
             continue;
         }
         else if (rc != Coordination::Error::ZOK)
diff --git a/src/Storages/MergeTree/IDataPartStorage.h b/src/Storages/MergeTree/IDataPartStorage.h
index afbe91a8a6d7..5899ef58cd57 100644
--- a/src/Storages/MergeTree/IDataPartStorage.h
+++ b/src/Storages/MergeTree/IDataPartStorage.h
@@ -151,12 +151,12 @@ class IDataPartStorage : public boost::noncopyable
         const MergeTreeDataPartChecksums & checksums,
         std::list<ProjectionChecksums> projections,
         bool is_temp,
-        Poco::Logger * log) = 0;
+        LoggerPtr log) = 0;
 
     /// Get a name like 'prefix_partdir_tryN' which does not exist in a root dir.
     /// TODO: remove it.
     virtual std::optional<String> getRelativePathForPrefix(
-        Poco::Logger * log, const String & prefix, bool detached, bool broken) const = 0;
+        LoggerPtr log, const String & prefix, bool detached, bool broken) const = 0;
 
     /// Reset part directory, used for in-memory parts.
     /// TODO: remove it.
@@ -263,7 +263,7 @@ class IDataPartStorage : public boost::noncopyable
         const DiskPtr & disk,
         const ReadSettings & read_settings,
         const WriteSettings & write_settings,
-        Poco::Logger * log,
+        LoggerPtr log,
         const std::function<void()> & cancellation_hook
         ) const = 0;
 
@@ -314,7 +314,7 @@ class IDataPartStorage : public boost::noncopyable
     virtual void rename(
         std::string new_root_path,
         std::string new_part_dir,
-        Poco::Logger * log,
+        LoggerPtr log,
         bool remove_new_dir_if_exists,
         bool fsync_part_dir) = 0;
 
diff --git a/src/Storages/MergeTree/InsertBlockInfo.cpp b/src/Storages/MergeTree/InsertBlockInfo.cpp
index ac900f8cf097..2de3ae8996a7 100644
--- a/src/Storages/MergeTree/InsertBlockInfo.cpp
+++ b/src/Storages/MergeTree/InsertBlockInfo.cpp
@@ -9,7 +9,7 @@ namespace ErrorCodes
 }
 
 AsyncInsertBlockInfo::AsyncInsertBlockInfo(
-    Poco::Logger * log_,
+    LoggerPtr log_,
     std::vector<std::string> && block_id_,
     BlockWithPartition && block_,
     std::optional<BlockWithPartition> && unmerged_block_with_partition_)
diff --git a/src/Storages/MergeTree/InsertBlockInfo.h b/src/Storages/MergeTree/InsertBlockInfo.h
index 3882373c0fa9..7d7ec0c9f292 100644
--- a/src/Storages/MergeTree/InsertBlockInfo.h
+++ b/src/Storages/MergeTree/InsertBlockInfo.h
@@ -8,7 +8,7 @@ namespace DB
 struct SyncInsertBlockInfo
 {
     SyncInsertBlockInfo(
-        Poco::Logger * /*log_*/,
+        LoggerPtr /*log_*/,
         std::string && block_id_,
         BlockWithPartition && /*block_*/,
         std::optional<BlockWithPartition> && /*unmerged_block_with_partition_*/)
@@ -25,7 +25,7 @@ struct SyncInsertBlockInfo
 
 struct AsyncInsertBlockInfo
 {
-    Poco::Logger * log;
+    LoggerPtr log;
     std::vector<std::string> block_id;
     BlockWithPartition block_with_partition;
     /// Some merging algorithms can mofidy the block which loses the information about the async insert offsets
@@ -34,7 +34,7 @@ struct AsyncInsertBlockInfo
     std::unordered_map<String, std::vector<size_t>> block_id_to_offset_idx;
 
     AsyncInsertBlockInfo(
-        Poco::Logger * log_,
+        LoggerPtr log_,
         std::vector<std::string> && block_id_,
         BlockWithPartition && block_,
         std::optional<BlockWithPartition> && unmerged_block_with_partition_);
diff --git a/src/Storages/MergeTree/LeaderElection.h b/src/Storages/MergeTree/LeaderElection.h
index 2e48892563be..3bd486fd54a9 100644
--- a/src/Storages/MergeTree/LeaderElection.h
+++ b/src/Storages/MergeTree/LeaderElection.h
@@ -19,7 +19,7 @@ namespace zkutil
   * For now, every replica can become leader if there is no leader among replicas with old version.
   */
 
-void checkNoOldLeaders(Poco::Logger * log, ZooKeeper & zookeeper, const String path)
+void checkNoOldLeaders(LoggerPtr log, ZooKeeper & zookeeper, const String path)
 {
     /// Previous versions (before 21.12) used to create ephemeral sequential node path/leader_election-
     /// Replica with the lexicographically smallest node name becomes leader (before 20.6) or enables multi-leader mode (since 20.6)
diff --git a/src/Storages/MergeTree/MergeFromLogEntryTask.cpp b/src/Storages/MergeTree/MergeFromLogEntryTask.cpp
index 23037b1ee7ab..ae6e398026d7 100644
--- a/src/Storages/MergeTree/MergeFromLogEntryTask.cpp
+++ b/src/Storages/MergeTree/MergeFromLogEntryTask.cpp
@@ -28,7 +28,7 @@ MergeFromLogEntryTask::MergeFromLogEntryTask(
     StorageReplicatedMergeTree & storage_,
     IExecutableTask::TaskResultCallback & task_result_callback_)
     : ReplicatedMergeMutateTaskBase(
-        &Poco::Logger::get(
+        getLogger(
             storage_.getStorageID().getShortName() + "::" + selected_entry_->log_entry->new_part_name + " (MergeFromLogEntryTask)"),
         storage_,
         selected_entry_,
diff --git a/src/Storages/MergeTree/MergeTask.h b/src/Storages/MergeTree/MergeTask.h
index b2a5796737d8..6f5336baaad3 100644
--- a/src/Storages/MergeTree/MergeTask.h
+++ b/src/Storages/MergeTree/MergeTask.h
@@ -228,7 +228,7 @@ class MergeTask
         size_t sum_compressed_bytes_upper_bound{0};
         bool blocks_are_granules_size{false};
 
-        Poco::Logger * log{&Poco::Logger::get("MergeTask::PrepareStage")};
+        LoggerPtr log{getLogger("MergeTask::PrepareStage")};
 
         /// Dependencies for next stages
         std::list<DB::NameAndTypePair>::const_iterator it_name_and_type;
@@ -354,7 +354,7 @@ class MergeTask
         MergeTasks tasks_for_projections;
         MergeTasks::iterator projections_iterator;
 
-        Poco::Logger * log{&Poco::Logger::get("MergeTask::MergeProjectionsStage")};
+        LoggerPtr log{getLogger("MergeTask::MergeProjectionsStage")};
     };
 
     using MergeProjectionsRuntimeContextPtr = std::shared_ptr<MergeProjectionsRuntimeContext>;
diff --git a/src/Storages/MergeTree/MergeTreeBackgroundExecutor.cpp b/src/Storages/MergeTree/MergeTreeBackgroundExecutor.cpp
index a3f8e02f5eb1..8cb0badc19bf 100644
--- a/src/Storages/MergeTree/MergeTreeBackgroundExecutor.cpp
+++ b/src/Storages/MergeTree/MergeTreeBackgroundExecutor.cpp
@@ -144,7 +144,7 @@ bool MergeTreeBackgroundExecutor<Queue>::trySchedule(ExecutableTaskPtr task)
     return true;
 }
 
-void printExceptionWithRespectToAbort(Poco::Logger * log, const String & query_id)
+void printExceptionWithRespectToAbort(LoggerPtr log, const String & query_id)
 {
     std::exception_ptr ex = std::current_exception();
 
diff --git a/src/Storages/MergeTree/MergeTreeBackgroundExecutor.h b/src/Storages/MergeTree/MergeTreeBackgroundExecutor.h
index 63f75ffc8d93..0ed032935894 100644
--- a/src/Storages/MergeTree/MergeTreeBackgroundExecutor.h
+++ b/src/Storages/MergeTree/MergeTreeBackgroundExecutor.h
@@ -307,7 +307,7 @@ class MergeTreeBackgroundExecutor final : boost::noncopyable
     std::condition_variable has_tasks TSA_GUARDED_BY(mutex);
     bool shutdown TSA_GUARDED_BY(mutex) = false;
     std::unique_ptr<ThreadPool> pool;
-    Poco::Logger * log = &Poco::Logger::get("MergeTreeBackgroundExecutor");
+    LoggerPtr log = getLogger("MergeTreeBackgroundExecutor");
 };
 
 extern template class MergeTreeBackgroundExecutor<RoundRobinRuntimeQueue>;
diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp
index 61332a4ff384..39c113c240eb 100644
--- a/src/Storages/MergeTree/MergeTreeData.cpp
+++ b/src/Storages/MergeTree/MergeTreeData.cpp
@@ -355,7 +355,7 @@ MergeTreeData::MergeTreeData(
     , require_part_metadata(require_part_metadata_)
     , broken_part_callback(broken_part_callback_)
     , log_name(std::make_shared<String>(table_id_.getNameForLogs()))
-    , log(&Poco::Logger::get(*log_name))
+    , log(getLogger(*log_name))
     , storage_settings(std::move(storage_settings_))
     , pinned_part_uuids(std::make_shared<PinnedPartUUIDs>())
     , data_parts_by_info(data_parts_indexes.get<TagByInfo>())
@@ -1222,7 +1222,7 @@ MergeTreeData::PartLoadingTree::build(PartLoadingInfos nodes)
 }
 
 static std::optional<size_t> calculatePartSizeSafe(
-    const MergeTreeData::DataPartPtr & part, Poco::Logger * log)
+    const MergeTreeData::DataPartPtr & part, const LoggerPtr & log)
 {
     try
     {
@@ -2735,7 +2735,7 @@ void MergeTreeData::renameInMemory(const StorageID & new_table_id)
 {
     IStorage::renameInMemory(new_table_id);
     std::atomic_store(&log_name, std::make_shared<String>(new_table_id.getNameForLogs()));
-    log = &Poco::Logger::get(*log_name);
+    log = getLogger(*log_name);
 }
 
 void MergeTreeData::dropAllData()
diff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h
index f0dbaf0e307a..caef247500a8 100644
--- a/src/Storages/MergeTree/MergeTreeData.h
+++ b/src/Storages/MergeTree/MergeTreeData.h
@@ -5,6 +5,7 @@
 #include <Common/SimpleIncrement.h>
 #include <Common/SharedMutex.h>
 #include <Common/MultiVersion.h>
+#include <Common/Logger.h>
 #include <Storages/IStorage.h>
 #include <IO/ReadBufferFromString.h>
 #include <IO/WriteBufferFromFile.h>
@@ -1117,7 +1118,7 @@ class MergeTreeData : public IStorage, public WithMutableContext
     /// log_name will change during table RENAME. Use atomic_shared_ptr to allow concurrent RW.
     /// NOTE clang-14 doesn't have atomic_shared_ptr yet. Use std::atomic* operations for now.
     std::shared_ptr<String> log_name;
-    std::atomic<Poco::Logger *> log;
+    LoggerPtr log;
 
     /// Storage settings.
     /// Use get and set to receive readonly versions.
@@ -1601,10 +1602,10 @@ struct CurrentlySubmergingEmergingTagger
     MergeTreeData & storage;
     String emerging_part_name;
     MergeTreeData::DataPartsVector submerging_parts;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     CurrentlySubmergingEmergingTagger(
-        MergeTreeData & storage_, const String & name_, MergeTreeData::DataPartsVector && parts_, Poco::Logger * log_)
+        MergeTreeData & storage_, const String & name_, MergeTreeData::DataPartsVector && parts_, LoggerPtr log_)
         : storage(storage_), emerging_part_name(name_), submerging_parts(std::move(parts_)), log(log_)
     {
     }
diff --git a/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp b/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp
index 8c03aef6f99f..58fddde7b545 100644
--- a/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp
+++ b/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp
@@ -66,7 +66,7 @@ static const double DISK_USAGE_COEFFICIENT_TO_SELECT = 2;
 static const double DISK_USAGE_COEFFICIENT_TO_RESERVE = 1.1;
 
 MergeTreeDataMergerMutator::MergeTreeDataMergerMutator(MergeTreeData & data_)
-    : data(data_), log(&Poco::Logger::get(data.getLogName() + " (MergerMutator)"))
+    : data(data_), log(getLogger(data.getLogName() + " (MergerMutator)"))
 {
 }
 
diff --git a/src/Storages/MergeTree/MergeTreeDataMergerMutator.h b/src/Storages/MergeTree/MergeTreeDataMergerMutator.h
index 6eab0ee0c371..f3a3f51b6c3a 100644
--- a/src/Storages/MergeTree/MergeTreeDataMergerMutator.h
+++ b/src/Storages/MergeTree/MergeTreeDataMergerMutator.h
@@ -213,7 +213,7 @@ public :
 private:
     MergeTreeData & data;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// When the last time you wrote to the log that the disk space was running out (not to write about this too often).
     time_t disk_space_warning_time = 0;
diff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
index 66f593bbf331..a76d370d057f 100644
--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
@@ -74,7 +74,7 @@ namespace ErrorCodes
 
 
 MergeTreeDataSelectExecutor::MergeTreeDataSelectExecutor(const MergeTreeData & data_)
-    : data(data_), log(&Poco::Logger::get(data.getLogName() + " (SelectExecutor)"))
+    : data(data_), log(getLogger(data.getLogName() + " (SelectExecutor)"))
 {
 }
 
@@ -83,7 +83,7 @@ size_t MergeTreeDataSelectExecutor::getApproximateTotalRowsToRead(
     const StorageMetadataPtr & metadata_snapshot,
     const KeyCondition & key_condition,
     const Settings & settings,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     size_t rows_count = 0;
 
@@ -167,7 +167,7 @@ MergeTreeDataSelectSamplingData MergeTreeDataSelectExecutor::getSampling(
     const StorageMetadataPtr & metadata_snapshot,
     ContextPtr context,
     bool sample_factor_column_queried,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     const Settings & settings = context->getSettingsRef();
     /// Sampling.
@@ -503,7 +503,7 @@ void MergeTreeDataSelectExecutor::filterPartsByPartition(
     const MergeTreeData & data,
     const ContextPtr & context,
     const PartitionIdToMaxBlock * max_block_numbers_to_read,
-    Poco::Logger * log,
+    LoggerPtr log,
     ReadFromMergeTree::IndexStats & index_stats)
 {
     chassert(alter_conversions.empty() || parts.size() == alter_conversions.size());
@@ -590,7 +590,7 @@ RangesInDataParts MergeTreeDataSelectExecutor::filterPartsByPrimaryKeyAndSkipInd
     const std::optional<KeyCondition> & part_offset_condition,
     const UsefulSkipIndexes & skip_indexes,
     const MergeTreeReaderSettings & reader_settings,
-    Poco::Logger * log,
+    LoggerPtr log,
     size_t num_streams,
     ReadFromMergeTree::IndexStats & index_stats,
     bool use_skip_indexes)
@@ -1082,7 +1082,7 @@ MarkRanges MergeTreeDataSelectExecutor::markRangesFromPKRange(
     const KeyCondition & key_condition,
     const std::optional<KeyCondition> & part_offset_condition,
     const Settings & settings,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     MarkRanges res;
 
@@ -1322,7 +1322,7 @@ MarkRanges MergeTreeDataSelectExecutor::filterMarksUsingIndex(
     const MergeTreeReaderSettings & reader_settings,
     MarkCache * mark_cache,
     UncompressedCache * uncompressed_cache,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     if (!index_helper->getDeserializedFormat(part->getDataPartStorage(), index_helper->getFileName()))
     {
@@ -1440,7 +1440,7 @@ MarkRanges MergeTreeDataSelectExecutor::filterMarksUsingMergedIndex(
     const MergeTreeReaderSettings & reader_settings,
     MarkCache * mark_cache,
     UncompressedCache * uncompressed_cache,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     for (const auto & index_helper : indices)
     {
@@ -1596,7 +1596,7 @@ void MergeTreeDataSelectExecutor::selectPartsToReadWithUUIDFilter(
     const PartitionIdToMaxBlock * max_block_numbers_to_read,
     ContextPtr query_context,
     PartFilterCounters & counters,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     /// process_parts prepare parts that have to be read for the query,
     /// returns false if duplicated parts' UUID have been met
diff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h
index ba1f20054f08..17975354187e 100644
--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h
+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h
@@ -71,11 +71,11 @@ class MergeTreeDataSelectExecutor
         const KeyCondition & key_condition,
         const std::optional<KeyCondition> & part_offset_condition,
         const Settings & settings,
-        Poco::Logger * log);
+        LoggerPtr log);
 
 private:
     const MergeTreeData & data;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Get the approximate value (bottom estimate - only by full marks) of the number of rows falling under the index.
     static size_t getApproximateTotalRowsToRead(
@@ -83,7 +83,7 @@ class MergeTreeDataSelectExecutor
         const StorageMetadataPtr & metadata_snapshot,
         const KeyCondition & key_condition,
         const Settings & settings,
-        Poco::Logger * log);
+        LoggerPtr log);
 
     static MarkRanges filterMarksUsingIndex(
         MergeTreeIndexPtr index_helper,
@@ -94,7 +94,7 @@ class MergeTreeDataSelectExecutor
         const MergeTreeReaderSettings & reader_settings,
         MarkCache * mark_cache,
         UncompressedCache * uncompressed_cache,
-        Poco::Logger * log);
+        LoggerPtr log);
 
     static MarkRanges filterMarksUsingMergedIndex(
         MergeTreeIndices indices,
@@ -105,7 +105,7 @@ class MergeTreeDataSelectExecutor
         const MergeTreeReaderSettings & reader_settings,
         MarkCache * mark_cache,
         UncompressedCache * uncompressed_cache,
-        Poco::Logger * log);
+        LoggerPtr log);
 
     struct PartFilterCounters
     {
@@ -141,7 +141,7 @@ class MergeTreeDataSelectExecutor
         const PartitionIdToMaxBlock * max_block_numbers_to_read,
         ContextPtr query_context,
         PartFilterCounters & counters,
-        Poco::Logger * log);
+        LoggerPtr log);
 
 public:
     /// For given number rows and bytes, get the number of marks to read.
@@ -184,7 +184,7 @@ class MergeTreeDataSelectExecutor
         const MergeTreeData & data,
         const ContextPtr & context,
         const PartitionIdToMaxBlock * max_block_numbers_to_read,
-        Poco::Logger * log,
+        LoggerPtr log,
         ReadFromMergeTree::IndexStats & index_stats);
 
     /// Filter parts using primary key and secondary indexes.
@@ -199,7 +199,7 @@ class MergeTreeDataSelectExecutor
         const std::optional<KeyCondition> & part_offset_condition,
         const UsefulSkipIndexes & skip_indexes,
         const MergeTreeReaderSettings & reader_settings,
-        Poco::Logger * log,
+        LoggerPtr log,
         size_t num_streams,
         ReadFromMergeTree::IndexStats & index_stats,
         bool use_skip_indexes);
@@ -216,7 +216,7 @@ class MergeTreeDataSelectExecutor
         const StorageMetadataPtr & metadata_snapshot,
         ContextPtr context,
         bool sample_factor_column_queried,
-        Poco::Logger * log);
+        LoggerPtr log);
 
     /// Check query limits: max_partitions_to_read, max_concurrent_queries.
     /// Also, return QueryIdHolder. If not null, we should keep it until query finishes.
diff --git a/src/Storages/MergeTree/MergeTreeDataWriter.cpp b/src/Storages/MergeTree/MergeTreeDataWriter.cpp
index 3c0b2d2b42e9..ce3015c5dcb7 100644
--- a/src/Storages/MergeTree/MergeTreeDataWriter.cpp
+++ b/src/Storages/MergeTree/MergeTreeDataWriter.cpp
@@ -115,7 +115,7 @@ void buildScatterSelector(
     if (max_parts && partitions_count >= max_parts && !throw_on_limit)
     {
         const auto & client_info = context->getClientInfo();
-        Poco::Logger * log = &Poco::Logger::get("MergeTreeDataWriter");
+        LoggerPtr log = getLogger("MergeTreeDataWriter");
 
         LOG_WARNING(log, "INSERT query from initial_user {} (query ID: {}) inserted a block "
                          "that created parts in {} partitions. This is being logged "
@@ -335,7 +335,7 @@ Block MergeTreeDataWriter::mergeBlock(
             case MergeTreeData::MergingParams::Collapsing:
                 return std::make_shared<CollapsingSortedAlgorithm>(
                     block, 1, sort_description, merging_params.sign_column,
-                    false, block_size + 1, /*block_size_bytes=*/0, &Poco::Logger::get("MergeTreeDataWriter"));
+                    false, block_size + 1, /*block_size_bytes=*/0, getLogger("MergeTreeDataWriter"));
             case MergeTreeData::MergingParams::Summing:
                 return std::make_shared<SummingSortedAlgorithm>(
                     block, 1, sort_description, merging_params.columns_to_sum,
@@ -618,7 +618,7 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeProjectionPartImpl(
     bool is_temp,
     IMergeTreeDataPart * parent_part,
     const MergeTreeData & data,
-    Poco::Logger * log,
+    LoggerPtr log,
     Block block,
     const ProjectionDescription & projection)
 {
@@ -729,7 +729,7 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeProjectionPartImpl(
 
 MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeProjectionPart(
     const MergeTreeData & data,
-    Poco::Logger * log,
+    LoggerPtr log,
     Block block,
     const ProjectionDescription & projection,
     IMergeTreeDataPart * parent_part)
@@ -748,7 +748,7 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeProjectionPart(
 /// projection part merges.
 MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeTempProjectionPart(
     const MergeTreeData & data,
-    Poco::Logger * log,
+    LoggerPtr log,
     Block block,
     const ProjectionDescription & projection,
     IMergeTreeDataPart * parent_part,
diff --git a/src/Storages/MergeTree/MergeTreeDataWriter.h b/src/Storages/MergeTree/MergeTreeDataWriter.h
index 2fb6b1f22d43..8fb8b82dbe6a 100644
--- a/src/Storages/MergeTree/MergeTreeDataWriter.h
+++ b/src/Storages/MergeTree/MergeTreeDataWriter.h
@@ -45,8 +45,9 @@ class MergeTreeDataWriter
 public:
     explicit MergeTreeDataWriter(MergeTreeData & data_)
         : data(data_)
-        , log(&Poco::Logger::get(data.getLogName() + " (Writer)"))
-    {}
+        , log(getLogger(data.getLogName() + " (Writer)"))
+    {
+    }
 
     /** Split the block to blocks, each of them must be written as separate part.
       *  (split rows by partition)
@@ -91,7 +92,7 @@ class MergeTreeDataWriter
     /// For insertion.
     static TemporaryPart writeProjectionPart(
         const MergeTreeData & data,
-        Poco::Logger * log,
+        LoggerPtr log,
         Block block,
         const ProjectionDescription & projection,
         IMergeTreeDataPart * parent_part);
@@ -99,7 +100,7 @@ class MergeTreeDataWriter
     /// For mutation: MATERIALIZE PROJECTION.
     static TemporaryPart writeTempProjectionPart(
         const MergeTreeData & data,
-        Poco::Logger * log,
+        LoggerPtr log,
         Block block,
         const ProjectionDescription & projection,
         IMergeTreeDataPart * parent_part,
@@ -126,12 +127,12 @@ class MergeTreeDataWriter
         bool is_temp,
         IMergeTreeDataPart * parent_part,
         const MergeTreeData & data,
-        Poco::Logger * log,
+        LoggerPtr log,
         Block block,
         const ProjectionDescription & projection);
 
     MergeTreeData & data;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/MergeTree/MergeTreePartsMover.h b/src/Storages/MergeTree/MergeTreePartsMover.h
index b9109e51309c..43d8ebdd6d34 100644
--- a/src/Storages/MergeTree/MergeTreePartsMover.h
+++ b/src/Storages/MergeTree/MergeTreePartsMover.h
@@ -48,7 +48,7 @@ class MergeTreePartsMover
 
     explicit MergeTreePartsMover(MergeTreeData * data_)
         : data(data_)
-        , log(&Poco::Logger::get("MergeTreePartsMover"))
+        , log(getLogger("MergeTreePartsMover"))
     {
     }
 
@@ -81,7 +81,7 @@ class MergeTreePartsMover
 private:
 
     MergeTreeData * data;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 
diff --git a/src/Storages/MergeTree/MergeTreePrefetchedReadPool.cpp b/src/Storages/MergeTree/MergeTreePrefetchedReadPool.cpp
index 3f9632637b66..47c2fe07bb47 100644
--- a/src/Storages/MergeTree/MergeTreePrefetchedReadPool.cpp
+++ b/src/Storages/MergeTree/MergeTreePrefetchedReadPool.cpp
@@ -128,7 +128,7 @@ MergeTreePrefetchedReadPool::MergeTreePrefetchedReadPool(
         context_)
     , WithContext(context_)
     , prefetch_threadpool(getContext()->getPrefetchThreadpool())
-    , log(&Poco::Logger::get("MergeTreePrefetchedReadPool(" + (parts_ranges.empty() ? "" : parts_ranges.front().data_part->storage.getStorageID().getNameForLogs()) + ")"))
+    , log(getLogger("MergeTreePrefetchedReadPool(" + (parts_ranges.empty() ? "" : parts_ranges.front().data_part->storage.getStorageID().getNameForLogs()) + ")"))
 {
     /// Tasks creation might also create a lost of readers - check they do not
     /// do any time consuming operations in ctor.
diff --git a/src/Storages/MergeTree/MergeTreePrefetchedReadPool.h b/src/Storages/MergeTree/MergeTreePrefetchedReadPool.h
index 9925d4e2fa4f..378034c5eae5 100644
--- a/src/Storages/MergeTree/MergeTreePrefetchedReadPool.h
+++ b/src/Storages/MergeTree/MergeTreePrefetchedReadPool.h
@@ -122,7 +122,7 @@ class MergeTreePrefetchedReadPool : public MergeTreeReadPoolBase, private WithCo
     TasksPerThread per_thread_tasks;
     std::priority_queue<TaskHolder> prefetch_queue; /// the smallest on top
     bool started_prefetches = false;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// A struct which allows to track max number of tasks which were in the
     /// threadpool simultaneously (similar to CurrentMetrics, but the result
diff --git a/src/Storages/MergeTree/MergeTreeRangeReader.h b/src/Storages/MergeTree/MergeTreeRangeReader.h
index 04d421389634..79ed18f4d1f4 100644
--- a/src/Storages/MergeTree/MergeTreeRangeReader.h
+++ b/src/Storages/MergeTree/MergeTreeRangeReader.h
@@ -231,7 +231,7 @@ class MergeTreeRangeReader
 
         using RangesInfo = std::vector<RangeInfo>;
 
-        explicit ReadResult(Poco::Logger * log_) : log(log_) {}
+        explicit ReadResult(LoggerPtr log_) : log(log_) {}
 
         static size_t getLastMark(const MergeTreeRangeReader::ReadResult::RangesInfo & ranges);
 
@@ -298,7 +298,7 @@ class MergeTreeRangeReader
         size_t countZeroTails(const IColumn::Filter & filter, NumRows & zero_tails, bool can_read_incomplete_granules) const;
         static size_t numZerosInTail(const UInt8 * begin, const UInt8 * end);
 
-        Poco::Logger * log;
+        LoggerPtr log;
     };
 
     ReadResult read(size_t max_rows, MarkRanges & ranges);
@@ -325,7 +325,7 @@ class MergeTreeRangeReader
     bool is_initialized = false;
     Names non_const_virtual_column_names;
 
-    Poco::Logger * log = &Poco::Logger::get("MergeTreeRangeReader");
+    LoggerPtr log = getLogger("MergeTreeRangeReader");
 };
 
 }
diff --git a/src/Storages/MergeTree/MergeTreeReadPool.h b/src/Storages/MergeTree/MergeTreeReadPool.h
index 3a1af947cae1..e45ccad912f1 100644
--- a/src/Storages/MergeTree/MergeTreeReadPool.h
+++ b/src/Storages/MergeTree/MergeTreeReadPool.h
@@ -108,7 +108,7 @@ class MergeTreeReadPool : public MergeTreeReadPoolBase
     std::vector<ThreadTask> threads_tasks;
     std::set<size_t> remaining_thread_tasks;
 
-    Poco::Logger * log = &Poco::Logger::get("MergeTreeReadPool");
+    LoggerPtr log = getLogger("MergeTreeReadPool");
 };
 
 }
diff --git a/src/Storages/MergeTree/MergeTreeReadPoolParallelReplicas.h b/src/Storages/MergeTree/MergeTreeReadPoolParallelReplicas.h
index 7579a892b67c..6a548dffe374 100644
--- a/src/Storages/MergeTree/MergeTreeReadPoolParallelReplicas.h
+++ b/src/Storages/MergeTree/MergeTreeReadPoolParallelReplicas.h
@@ -34,7 +34,7 @@ class MergeTreeReadPoolParallelReplicas : public MergeTreeReadPoolBase
     const CoordinationMode coordination_mode;
     RangesInDataPartsDescription buffered_ranges;
     bool no_more_tasks_available{false};
-    Poco::Logger * log = &Poco::Logger::get("MergeTreeReadPoolParallelReplicas");
+    LoggerPtr log = getLogger("MergeTreeReadPoolParallelReplicas");
 };
 
 }
diff --git a/src/Storages/MergeTree/MergeTreeSelectProcessor.h b/src/Storages/MergeTree/MergeTreeSelectProcessor.h
index cf1a6313b514..b06ae788e91d 100644
--- a/src/Storages/MergeTree/MergeTreeSelectProcessor.h
+++ b/src/Storages/MergeTree/MergeTreeSelectProcessor.h
@@ -114,7 +114,7 @@ class MergeTreeSelectProcessor : private boost::noncopyable
     /// Should we add part level to produced chunk. Part level is useful for next steps if query has FINAL
     bool add_part_level = false;
 
-    Poco::Logger * log = &Poco::Logger::get("MergeTreeSelectProcessor");
+    LoggerPtr log = getLogger("MergeTreeSelectProcessor");
     std::atomic<bool> is_cancelled{false};
 };
 
diff --git a/src/Storages/MergeTree/MergeTreeSequentialSource.cpp b/src/Storages/MergeTree/MergeTreeSequentialSource.cpp
index 82e9f8fd2db8..29af7fb4820f 100644
--- a/src/Storages/MergeTree/MergeTreeSequentialSource.cpp
+++ b/src/Storages/MergeTree/MergeTreeSequentialSource.cpp
@@ -68,7 +68,7 @@ class MergeTreeSequentialSource : public ISource
     /// Should read using direct IO
     bool read_with_direct_io;
 
-    Poco::Logger * log = &Poco::Logger::get("MergeTreeSequentialSource");
+    LoggerPtr log = getLogger("MergeTreeSequentialSource");
 
     std::optional<MarkRanges> mark_ranges;
 
@@ -318,7 +318,7 @@ class ReadFromPart final : public ISourceStep
         bool apply_deleted_mask_,
         ActionsDAGPtr filter_,
         ContextPtr context_,
-        Poco::Logger * log_)
+        LoggerPtr log_)
         : ISourceStep(DataStream{.header = storage_snapshot_->getSampleBlockForColumns(columns_to_read_)})
         , type(type_)
         , storage(storage_)
@@ -381,7 +381,7 @@ class ReadFromPart final : public ISourceStep
     bool apply_deleted_mask;
     ActionsDAGPtr filter;
     ContextPtr context;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 void createReadFromPartStep(
@@ -394,7 +394,7 @@ void createReadFromPartStep(
     bool apply_deleted_mask,
     ActionsDAGPtr filter,
     ContextPtr context,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     auto reading = std::make_unique<ReadFromPart>(type,
         storage, storage_snapshot, std::move(data_part),
diff --git a/src/Storages/MergeTree/MergeTreeSequentialSource.h b/src/Storages/MergeTree/MergeTreeSequentialSource.h
index 41def48aab6a..a5e36a7726ff 100644
--- a/src/Storages/MergeTree/MergeTreeSequentialSource.h
+++ b/src/Storages/MergeTree/MergeTreeSequentialSource.h
@@ -41,6 +41,6 @@ void createReadFromPartStep(
     bool apply_deleted_mask,
     ActionsDAGPtr filter,
     ContextPtr context,
-    Poco::Logger * log);
+    LoggerPtr log);
 
 }
diff --git a/src/Storages/MergeTree/MergeTreeSettings.cpp b/src/Storages/MergeTree/MergeTreeSettings.cpp
index 153930b400d3..b42da22239eb 100644
--- a/src/Storages/MergeTree/MergeTreeSettings.cpp
+++ b/src/Storages/MergeTree/MergeTreeSettings.cpp
@@ -65,7 +65,7 @@ void MergeTreeSettings::loadFromQuery(ASTStorage & storage_def, ContextPtr conte
                         if (ast && isDiskFunction(ast))
                         {
                             auto disk_name = getOrCreateDiskFromDiskAST(ast, context, is_attach);
-                            LOG_TRACE(&Poco::Logger::get("MergeTreeSettings"), "Created custom disk {}", disk_name);
+                            LOG_TRACE(getLogger("MergeTreeSettings"), "Created custom disk {}", disk_name);
                             value = disk_name;
                         }
                     }
diff --git a/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp b/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp
index 0cac051bb2cf..3f3dadb3cc51 100644
--- a/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp
+++ b/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp
@@ -56,7 +56,7 @@ MergeTreeWhereOptimizer::MergeTreeWhereOptimizer(
     const ConditionEstimator & estimator_,
     const Names & queried_columns_,
     const std::optional<NameSet> & supported_columns_,
-    Poco::Logger * log_)
+    LoggerPtr log_)
     : estimator(estimator_)
     , table_columns{collections::map<std::unordered_set>(
         metadata_snapshot->getColumns().getAllPhysical(), [](const NameAndTypePair & col) { return col.name; })}
diff --git a/src/Storages/MergeTree/MergeTreeWhereOptimizer.h b/src/Storages/MergeTree/MergeTreeWhereOptimizer.h
index 0ef7ac9efff3..7a6651210d02 100644
--- a/src/Storages/MergeTree/MergeTreeWhereOptimizer.h
+++ b/src/Storages/MergeTree/MergeTreeWhereOptimizer.h
@@ -41,7 +41,7 @@ class MergeTreeWhereOptimizer : private boost::noncopyable
         const ConditionEstimator & estimator_,
         const Names & queried_columns_,
         const std::optional<NameSet> & supported_columns_,
-        Poco::Logger * log_);
+        LoggerPtr log_);
 
     void optimize(SelectQueryInfo & select_query_info, const ContextPtr & context) const;
 
@@ -156,7 +156,7 @@ class MergeTreeWhereOptimizer : private boost::noncopyable
     const std::optional<NameSet> supported_columns;
     const NameSet sorting_key_names;
     const NameToIndexMap primary_key_names_positions;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::unordered_map<std::string, UInt64> column_sizes;
     UInt64 total_size_of_queried_columns = 0;
 };
diff --git a/src/Storages/MergeTree/MergeTreeWriteAheadLog.cpp b/src/Storages/MergeTree/MergeTreeWriteAheadLog.cpp
index a8b3df483ed5..2236c1a93805 100644
--- a/src/Storages/MergeTree/MergeTreeWriteAheadLog.cpp
+++ b/src/Storages/MergeTree/MergeTreeWriteAheadLog.cpp
@@ -36,7 +36,7 @@ MergeTreeWriteAheadLog::MergeTreeWriteAheadLog(
     , name(name_)
     , path(storage.getRelativeDataPath() + name_)
     , pool(storage.getContext()->getSchedulePool())
-    , log(&Poco::Logger::get(storage.getLogName() + " (WriteAheadLog)"))
+    , log(getLogger(storage.getLogName() + " (WriteAheadLog)"))
 {
     init();
     sync_task = pool.createTask("MergeTreeWriteAheadLog::sync", [this]
diff --git a/src/Storages/MergeTree/MergeTreeWriteAheadLog.h b/src/Storages/MergeTree/MergeTreeWriteAheadLog.h
index 5fb9dd907a17..9550fa6ecee5 100644
--- a/src/Storages/MergeTree/MergeTreeWriteAheadLog.h
+++ b/src/Storages/MergeTree/MergeTreeWriteAheadLog.h
@@ -99,7 +99,7 @@ class MergeTreeWriteAheadLog
 
     mutable std::mutex write_mutex;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/MergeTree/MergedBlockOutputStream.cpp b/src/Storages/MergeTree/MergedBlockOutputStream.cpp
index 8b34c221eec6..1d10a1433efd 100644
--- a/src/Storages/MergeTree/MergedBlockOutputStream.cpp
+++ b/src/Storages/MergeTree/MergedBlockOutputStream.cpp
@@ -155,7 +155,7 @@ MergedBlockOutputStream::Finalizer MergedBlockOutputStream::finalizePartAsync(
     for (const auto & name : checksums_to_remove)
         checksums.files.erase(name);
 
-    LOG_TRACE(&Poco::Logger::get("MergedBlockOutputStream"), "filled checksums {}", new_part->getNameWithState());
+    LOG_TRACE(getLogger("MergedBlockOutputStream"), "filled checksums {}", new_part->getNameWithState());
 
     for (const auto & [projection_name, projection_part] : new_part->getProjectionParts())
         checksums.addFile(
diff --git a/src/Storages/MergeTree/MutateFromLogEntryTask.h b/src/Storages/MergeTree/MutateFromLogEntryTask.h
index 42d8307e948e..68c7f4642148 100644
--- a/src/Storages/MergeTree/MutateFromLogEntryTask.h
+++ b/src/Storages/MergeTree/MutateFromLogEntryTask.h
@@ -23,7 +23,7 @@ class MutateFromLogEntryTask : public ReplicatedMergeMutateTaskBase
         StorageReplicatedMergeTree & storage_,
         Callback && task_result_callback_)
         : ReplicatedMergeMutateTaskBase(
-            &Poco::Logger::get(storage_.getStorageID().getShortName() + "::" + selected_entry_->log_entry->new_part_name + " (MutateFromLogEntryTask)"),
+            getLogger(storage_.getStorageID().getShortName() + "::" + selected_entry_->log_entry->new_part_name + " (MutateFromLogEntryTask)"),
             storage_,
             selected_entry_,
             task_result_callback_)
diff --git a/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp b/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp
index bf8e879e3d07..0b19aebe36d6 100644
--- a/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp
+++ b/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp
@@ -111,7 +111,7 @@ bool MutatePlainMergeTreeTask::executeStep()
                 if (merge_mutate_entry->txn)
                     merge_mutate_entry->txn->onException();
                 PreformattedMessage exception_message = getCurrentExceptionMessageAndPattern(/* with_stacktrace */ false);
-                LOG_ERROR(&Poco::Logger::get("MutatePlainMergeTreeTask"), exception_message);
+                LOG_ERROR(getLogger("MutatePlainMergeTreeTask"), exception_message);
                 storage.updateMutationEntriesErrors(future_part, false, exception_message.text);
                 write_part_log(ExecutionStatus::fromCurrentException("", true));
                 tryLogCurrentException(__PRETTY_FUNCTION__);
diff --git a/src/Storages/MergeTree/MutateTask.cpp b/src/Storages/MergeTree/MutateTask.cpp
index e4070aa82626..6bcdfe34296b 100644
--- a/src/Storages/MergeTree/MutateTask.cpp
+++ b/src/Storages/MergeTree/MutateTask.cpp
@@ -61,7 +61,7 @@ static void splitAndModifyMutationCommands(
     const MutationCommands & commands,
     MutationCommands & for_interpreter,
     MutationCommands & for_file_renames,
-    Poco::Logger * log)
+    LoggerPtr log)
 {
     auto part_columns = part->getColumnsDescription();
 
@@ -896,7 +896,7 @@ struct MutationContext
     TableLockHolder * holder;
     MergeListEntry * mutate_entry;
 
-    Poco::Logger * log{&Poco::Logger::get("MutateTask")};
+    LoggerPtr log{getLogger("MutateTask")};
 
     FutureMergedMutatedPartPtr future_part;
     MergeTreeData::DataPartPtr source_part;
@@ -975,7 +975,7 @@ class MergeProjectionPartsTask : public IExecutableTask
         , projection(projection_)
         , block_num(block_num_)
         , ctx(ctx_)
-        , log(&Poco::Logger::get("MergeProjectionPartsTask"))
+        , log(getLogger("MergeProjectionPartsTask"))
         {
             LOG_DEBUG(log, "Selected {} projection_parts from {} to {}", parts.size(), parts.front()->name, parts.back()->name);
             level_parts[current_level] = std::move(parts);
@@ -1079,7 +1079,7 @@ class MergeProjectionPartsTask : public IExecutableTask
     size_t & block_num;
     MutationContextPtr ctx;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::map<size_t, MergeTreeData::MutableDataPartsVector> level_parts;
     size_t current_level = 0;
diff --git a/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp
index 484a0b37644e..abc51bde3fb8 100644
--- a/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp
+++ b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp
@@ -245,7 +245,7 @@ class DefaultCoordinator : public ParallelReplicasReadingCoordinator::ImplInterf
     };
     std::vector<ReplicaStatus> replica_status;
 
-    Poco::Logger * log = &Poco::Logger::get("DefaultCoordinator");
+    LoggerPtr log = getLogger("DefaultCoordinator");
 
     /// Workflow of a segment:
     /// 0. `all_parts_to_read` contains all the parts and thus all the segments initially present there (virtually)
@@ -835,7 +835,7 @@ class InOrderCoordinator : public ParallelReplicasReadingCoordinator::ImplInterf
     Parts all_parts_to_read;
     size_t total_rows_to_read = 0;
 
-    Poco::Logger * log = &Poco::Logger::get(fmt::format("{}{}", magic_enum::enum_name(mode), "Coordinator"));
+    LoggerPtr log = getLogger(fmt::format("{}{}", magic_enum::enum_name(mode), "Coordinator"));
 };
 
 template <CoordinationMode mode>
diff --git a/src/Storages/MergeTree/PartMovesBetweenShardsOrchestrator.cpp b/src/Storages/MergeTree/PartMovesBetweenShardsOrchestrator.cpp
index 76b8080f64cd..78fcfabb7044 100644
--- a/src/Storages/MergeTree/PartMovesBetweenShardsOrchestrator.cpp
+++ b/src/Storages/MergeTree/PartMovesBetweenShardsOrchestrator.cpp
@@ -20,7 +20,7 @@ PartMovesBetweenShardsOrchestrator::PartMovesBetweenShardsOrchestrator(StorageRe
     : storage(storage_)
     , zookeeper_path(storage.zookeeper_path)
     , logger_name(storage.getStorageID().getFullTableName() + " (PartMovesBetweenShardsOrchestrator)")
-    , log(&Poco::Logger::get(logger_name))
+    , log(getLogger(logger_name))
     , entries_znode_path(zookeeper_path + "/part_moves_shard")
 {
     /// Schedule pool is not designed for long-running tasks. TODO replace with a separate thread?
diff --git a/src/Storages/MergeTree/PartMovesBetweenShardsOrchestrator.h b/src/Storages/MergeTree/PartMovesBetweenShardsOrchestrator.h
index af21022953c5..abe259c77ab5 100644
--- a/src/Storages/MergeTree/PartMovesBetweenShardsOrchestrator.h
+++ b/src/Storages/MergeTree/PartMovesBetweenShardsOrchestrator.h
@@ -176,7 +176,7 @@ class PartMovesBetweenShardsOrchestrator
 
     String zookeeper_path;
     String logger_name;
-    Poco::Logger * log = nullptr;
+    LoggerPtr log = nullptr;
     std::atomic<bool> need_stop{false};
 
     BackgroundSchedulePool::TaskHolder task;
diff --git a/src/Storages/MergeTree/PartitionPruner.cpp b/src/Storages/MergeTree/PartitionPruner.cpp
index 668576f90211..eb51d600da3b 100644
--- a/src/Storages/MergeTree/PartitionPruner.cpp
+++ b/src/Storages/MergeTree/PartitionPruner.cpp
@@ -59,7 +59,7 @@ bool PartitionPruner::canBePruned(const IMergeTreeDataPart & part) const
         {
             WriteBufferFromOwnString buf;
             part.partition.serializeText(part.storage, buf, FormatSettings{});
-            LOG_TRACE(&Poco::Logger::get("PartitionPruner"), "Partition {} gets pruned", buf.str());
+            LOG_TRACE(getLogger("PartitionPruner"), "Partition {} gets pruned", buf.str());
         }
     }
 
diff --git a/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.h b/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.h
index 18fcacecc9e3..2b1fcec62a83 100644
--- a/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.h
+++ b/src/Storages/MergeTree/ReplicatedMergeMutateTaskBase.h
@@ -17,7 +17,7 @@ class ReplicatedMergeMutateTaskBase : public IExecutableTask
 {
 public:
     ReplicatedMergeMutateTaskBase(
-        Poco::Logger * log_,
+        LoggerPtr log_,
         StorageReplicatedMergeTree & storage_,
         ReplicatedMergeTreeQueue::SelectedEntryPtr & selected_entry_,
         IExecutableTask::TaskResultCallback & task_result_callback_)
@@ -66,7 +66,7 @@ class ReplicatedMergeMutateTaskBase : public IExecutableTask
     ReplicatedMergeTreeQueue::SelectedEntryPtr selected_entry;
     ReplicatedMergeTreeLogEntry & entry;
     MergeList::EntryPtr merge_mutate_entry{nullptr};
-    Poco::Logger * log;
+    LoggerPtr log;
     /// ProfileEvents for current part will be stored here
     ProfileEvents::Counters profile_counters;
     ContextMutablePtr task_context;
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreeAttachThread.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeAttachThread.cpp
index a544ac908a4c..336d19692d43 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreeAttachThread.cpp
+++ b/src/Storages/MergeTree/ReplicatedMergeTreeAttachThread.cpp
@@ -19,7 +19,7 @@ namespace ErrorCodes
 ReplicatedMergeTreeAttachThread::ReplicatedMergeTreeAttachThread(StorageReplicatedMergeTree & storage_)
     : storage(storage_)
     , log_name(storage.getStorageID().getFullTableName() + " (ReplicatedMergeTreeAttachThread)")
-    , log(&Poco::Logger::get(log_name))
+    , log(getLogger(log_name))
 {
     task = storage.getContext()->getSchedulePool().createTask(log_name, [this] { run(); });
     const auto storage_settings = storage.getSettings();
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreeAttachThread.h b/src/Storages/MergeTree/ReplicatedMergeTreeAttachThread.h
index 222b30b519b1..250a5ed34d1c 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreeAttachThread.h
+++ b/src/Storages/MergeTree/ReplicatedMergeTreeAttachThread.h
@@ -34,7 +34,7 @@ class ReplicatedMergeTreeAttachThread
     BackgroundSchedulePool::TaskHolder task;
 
     std::string log_name;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::atomic<bool> first_try_done{false};
 
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp
index 8daee661c752..67942491ae25 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp
+++ b/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp
@@ -24,7 +24,7 @@ namespace ErrorCodes
 ReplicatedMergeTreeCleanupThread::ReplicatedMergeTreeCleanupThread(StorageReplicatedMergeTree & storage_)
     : storage(storage_)
     , log_name(storage.getStorageID().getFullTableName() + " (ReplicatedMergeTreeCleanupThread)")
-    , log(&Poco::Logger::get(log_name))
+    , log(getLogger(log_name))
     , sleep_ms(storage.getSettings()->cleanup_delay_period * 1000)
 {
     task = storage.getContext()->getSchedulePool().createTask(log_name, [this]{ run(); });
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.h b/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.h
index ae9aabdb4e7f..5beaef569955 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.h
+++ b/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.h
@@ -40,7 +40,7 @@ class ReplicatedMergeTreeCleanupThread
 private:
     StorageReplicatedMergeTree & storage;
     String log_name;
-    Poco::Logger * log;
+    LoggerPtr log;
     BackgroundSchedulePool::TaskHolder task;
     pcg64 rng{randomSeed()};
 
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp b/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp
index b1875464725b..156c41563ec0 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp
+++ b/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.cpp
@@ -28,7 +28,7 @@ static const auto PART_CHECK_ERROR_SLEEP_MS = 5 * 1000;
 ReplicatedMergeTreePartCheckThread::ReplicatedMergeTreePartCheckThread(StorageReplicatedMergeTree & storage_)
     : storage(storage_)
     , log_name(storage.getStorageID().getFullTableName() + " (ReplicatedMergeTreePartCheckThread)")
-    , log(&Poco::Logger::get(log_name))
+    , log(getLogger(log_name))
 {
     task = storage.getContext()->getSchedulePool().createTask(log_name, [this] { run(); });
     task->schedule();
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.h b/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.h
index 68dc6ca3d1de..f2e26b3d324f 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.h
+++ b/src/Storages/MergeTree/ReplicatedMergeTreePartCheckThread.h
@@ -87,7 +87,7 @@ class ReplicatedMergeTreePartCheckThread
 
     StorageReplicatedMergeTree & storage;
     String log_name;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     using StringSet = std::set<String>;
     struct PartToCheck
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp
index a3afa8cd88a9..8d921bdcb1c5 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp
+++ b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp
@@ -36,7 +36,7 @@ ReplicatedMergeTreeQueue::ReplicatedMergeTreeQueue(StorageReplicatedMergeTree &
     zookeeper_path = storage.zookeeper_path;
     replica_path = storage.replica_path;
     logger_name = storage.getStorageID().getFullTableName() + " (ReplicatedMergeTreeQueue)";
-    log = &Poco::Logger::get(logger_name);
+    log = getLogger(logger_name);
 }
 
 
@@ -2149,7 +2149,7 @@ LocalMergePredicate::LocalMergePredicate(ReplicatedMergeTreeQueue & queue_)
 
 template<typename VirtualPartsT, typename MutationsStateT>
 CommittingBlocks BaseMergePredicate<VirtualPartsT, MutationsStateT>::getCommittingBlocks(
-    zkutil::ZooKeeperPtr & zookeeper, const std::string & zookeeper_path, Poco::Logger * log_)
+    zkutil::ZooKeeperPtr & zookeeper, const std::string & zookeeper_path, LoggerPtr log_)
 {
     CommittingBlocks committing_blocks;
 
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h
index 92201b11d37d..84106565dff0 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h
+++ b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h
@@ -71,7 +71,7 @@ class ReplicatedMergeTreeQueue
     String zookeeper_path;
     String replica_path;
     String logger_name;
-    Poco::Logger * log = nullptr;
+    LoggerPtr log = nullptr;
 
     /// Protects the queue, future_parts and other queue state variables.
     mutable std::mutex state_mutex;
@@ -519,7 +519,7 @@ class BaseMergePredicate
     /// This predicate is checked for the first part of each range.
     bool canMergeSinglePart(const MergeTreeData::DataPartPtr & part, String & out_reason) const;
 
-    CommittingBlocks getCommittingBlocks(zkutil::ZooKeeperPtr & zookeeper, const std::string & zookeeper_path, Poco::Logger * log_);
+    CommittingBlocks getCommittingBlocks(zkutil::ZooKeeperPtr & zookeeper, const std::string & zookeeper_path, LoggerPtr log_);
 
 protected:
     /// A list of partitions that can be used in the merge predicate
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.cpp
index 579592b0b3e8..b79418da7916 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.cpp
+++ b/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.cpp
@@ -33,7 +33,7 @@ static String generateActiveNodeIdentifier()
 ReplicatedMergeTreeRestartingThread::ReplicatedMergeTreeRestartingThread(StorageReplicatedMergeTree & storage_)
     : storage(storage_)
     , log_name(storage.getStorageID().getFullTableName() + " (ReplicatedMergeTreeRestartingThread)")
-    , log(&Poco::Logger::get(log_name))
+    , log(getLogger(log_name))
     , active_node_identifier(generateActiveNodeIdentifier())
 {
     const auto storage_settings = storage.getSettings();
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.h b/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.h
index 02103272a1f5..01071d80e8bf 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.h
+++ b/src/Storages/MergeTree/ReplicatedMergeTreeRestartingThread.h
@@ -42,7 +42,7 @@ class ReplicatedMergeTreeRestartingThread
 private:
     StorageReplicatedMergeTree & storage;
     String log_name;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::atomic<bool> need_stop {false};
 
     /// The random data we wrote into `/replicas/me/is_active`.
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp
index 73ad595ec20e..1fb2393948a6 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp
+++ b/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp
@@ -58,7 +58,7 @@ struct ReplicatedMergeTreeSinkImpl<async_insert>::DelayedChunk
         ProfileEvents::Counters part_counters;
 
         Partition() = default;
-        Partition(Poco::Logger * log_,
+        Partition(LoggerPtr log_,
                   MergeTreeDataWriter::TemporaryPart && temp_part_,
                   UInt64 elapsed_ns_,
                   BlockIDsType && block_id_,
@@ -92,7 +92,7 @@ std::vector<Int64> testSelfDeduplicate(std::vector<Int64> data, std::vector<size
     BlockWithPartition block1(std::move(block), Row(), std::move(offsets), std::move(tokens));
     ProfileEvents::Counters profile_counters;
     ReplicatedMergeTreeSinkImpl<true>::DelayedChunk::Partition part(
-        &Poco::Logger::get("testSelfDeduplicate"), MergeTreeDataWriter::TemporaryPart(), 0, std::move(hashes), std::move(block1), std::nullopt, std::move(profile_counters));
+        getLogger("testSelfDeduplicate"), MergeTreeDataWriter::TemporaryPart(), 0, std::move(hashes), std::move(block1), std::nullopt, std::move(profile_counters));
 
     part.filterSelfDuplicate();
 
@@ -138,7 +138,7 @@ ReplicatedMergeTreeSinkImpl<async_insert>::ReplicatedMergeTreeSinkImpl(
     , is_attach(is_attach_)
     , quorum_parallel(quorum_parallel_)
     , deduplicate(deduplicate_)
-    , log(&Poco::Logger::get(storage.getLogName() + " (Replicated OutputStream)"))
+    , log(getLogger(storage.getLogName() + " (Replicated OutputStream)"))
     , context(context_)
     , storage_snapshot(storage.getStorageSnapshotWithoutData(metadata_snapshot, context_))
 {
diff --git a/src/Storages/MergeTree/ReplicatedMergeTreeSink.h b/src/Storages/MergeTree/ReplicatedMergeTreeSink.h
index 4811d93775b6..bc23204e7d39 100644
--- a/src/Storages/MergeTree/ReplicatedMergeTreeSink.h
+++ b/src/Storages/MergeTree/ReplicatedMergeTreeSink.h
@@ -128,7 +128,7 @@ class ReplicatedMergeTreeSinkImpl : public SinkToStorage
     bool last_block_is_duplicate = false;
     UInt64 num_blocks_processed = 0;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     ContextPtr context;
     StorageSnapshotPtr storage_snapshot;
diff --git a/src/Storages/MergeTree/ZooKeeperRetries.h b/src/Storages/MergeTree/ZooKeeperRetries.h
index 92faf80e61b4..ecef174c6c77 100644
--- a/src/Storages/MergeTree/ZooKeeperRetries.h
+++ b/src/Storages/MergeTree/ZooKeeperRetries.h
@@ -30,7 +30,7 @@ struct ZooKeeperRetriesInfo
 class ZooKeeperRetriesControl
 {
 public:
-    ZooKeeperRetriesControl(std::string name_, Poco::Logger * logger_, ZooKeeperRetriesInfo retries_info_, QueryStatusPtr elem)
+    ZooKeeperRetriesControl(std::string name_, LoggerPtr logger_, ZooKeeperRetriesInfo retries_info_, QueryStatusPtr elem)
         : name(std::move(name_)), logger(logger_), retries_info(retries_info_), process_list_element(elem)
     {
     }
@@ -160,7 +160,7 @@ class ZooKeeperRetriesControl
 
     const std::string & getName() const { return name; }
 
-    Poco::Logger * getLogger() const { return logger; }
+    LoggerPtr getLogger() const { return logger; }
 
 private:
     struct KeeperError
@@ -263,7 +263,7 @@ class ZooKeeperRetriesControl
 
 
     std::string name;
-    Poco::Logger * logger = nullptr;
+    LoggerPtr logger = nullptr;
     ZooKeeperRetriesInfo retries_info;
     UInt64 total_failures = 0;
     UserError user_error;
diff --git a/src/Storages/MergeTree/checkDataPart.cpp b/src/Storages/MergeTree/checkDataPart.cpp
index 8cf5b6a88945..8ae9b54b6e92 100644
--- a/src/Storages/MergeTree/checkDataPart.cpp
+++ b/src/Storages/MergeTree/checkDataPart.cpp
@@ -338,7 +338,7 @@ IMergeTreeDataPart::Checksums checkDataPart(
             throw;
 
         LOG_DEBUG(
-            &Poco::Logger::get("checkDataPart"),
+            getLogger("checkDataPart"),
             "Will drop cache for data part {} and will check it once again", data_part->name);
 
         auto & cache = *FileCacheFactory::instance().getByName(*cache_name)->cache;
diff --git a/src/Storages/MessageQueueSink.cpp b/src/Storages/MessageQueueSink.cpp
index 1aa19c9ccde5..4fb81d690707 100644
--- a/src/Storages/MessageQueueSink.cpp
+++ b/src/Storages/MessageQueueSink.cpp
@@ -20,7 +20,7 @@ MessageQueueSink::MessageQueueSink(
 void MessageQueueSink::onStart()
 {
     LOG_TEST(
-        &Poco::Logger::get("MessageQueueSink"),
+        getLogger("MessageQueueSink"),
         "Executing startup for MessageQueueSink");
 
     initialize();
diff --git a/src/Storages/NATS/NATSConnection.cpp b/src/Storages/NATS/NATSConnection.cpp
index 70b3599aa090..d7ad0cf8219e 100644
--- a/src/Storages/NATS/NATSConnection.cpp
+++ b/src/Storages/NATS/NATSConnection.cpp
@@ -13,7 +13,7 @@ static const auto RETRIES_MAX = 20;
 static const auto CONNECTED_TO_BUFFER_SIZE = 256;
 
 
-NATSConnectionManager::NATSConnectionManager(const NATSConfiguration & configuration_, Poco::Logger * log_)
+NATSConnectionManager::NATSConnectionManager(const NATSConfiguration & configuration_, LoggerPtr log_)
     : configuration(configuration_)
     , log(log_)
     , event_handler(loop.getLoop(), log)
@@ -115,8 +115,8 @@ void NATSConnectionManager::connectImpl()
     }
     natsOptions_SetMaxReconnect(options, configuration.max_reconnect);
     natsOptions_SetReconnectWait(options, configuration.reconnect_wait);
-    natsOptions_SetDisconnectedCB(options, disconnectedCallback, log);
-    natsOptions_SetReconnectedCB(options, reconnectedCallback, log);
+    natsOptions_SetDisconnectedCB(options, disconnectedCallback, log.get());
+    natsOptions_SetReconnectedCB(options, reconnectedCallback, log.get());
     natsStatus status;
     {
         auto lock = event_handler.setThreadLocalLoop();
diff --git a/src/Storages/NATS/NATSConnection.h b/src/Storages/NATS/NATSConnection.h
index b49070473b28..c350f395a927 100644
--- a/src/Storages/NATS/NATSConnection.h
+++ b/src/Storages/NATS/NATSConnection.h
@@ -24,7 +24,7 @@ struct NATSConfiguration
 class NATSConnectionManager
 {
 public:
-    NATSConnectionManager(const NATSConfiguration & configuration_, Poco::Logger * log_);
+    NATSConnectionManager(const NATSConfiguration & configuration_, LoggerPtr log_);
     ~NATSConnectionManager();
 
     bool isConnected();
@@ -54,7 +54,7 @@ class NATSConnectionManager
     static void reconnectedCallback(natsConnection * nc, void * log);
 
     NATSConfiguration configuration;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     UVLoop loop;
     NATSHandler event_handler;
diff --git a/src/Storages/NATS/NATSConsumer.cpp b/src/Storages/NATS/NATSConsumer.cpp
index c7b40973b72e..136cb13ddfac 100644
--- a/src/Storages/NATS/NATSConsumer.cpp
+++ b/src/Storages/NATS/NATSConsumer.cpp
@@ -21,7 +21,7 @@ NATSConsumer::NATSConsumer(
     StorageNATS & storage_,
     std::vector<String> & subjects_,
     const String & subscribe_queue_name,
-    Poco::Logger * log_,
+    LoggerPtr log_,
     uint32_t queue_size_,
     const std::atomic<bool> & stopped_)
     : connection(connection_)
diff --git a/src/Storages/NATS/NATSConsumer.h b/src/Storages/NATS/NATSConsumer.h
index a5470433303d..e8d3a849c2a0 100644
--- a/src/Storages/NATS/NATSConsumer.h
+++ b/src/Storages/NATS/NATSConsumer.h
@@ -24,7 +24,7 @@ class NATSConsumer
         StorageNATS & storage_,
         std::vector<String> & subjects_,
         const String & subscribe_queue_name,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         uint32_t queue_size_,
         const std::atomic<bool> & stopped_);
 
@@ -58,7 +58,7 @@ class NATSConsumer
     StorageNATS & storage;
     std::vector<SubscriptionPtr> subscriptions;
     std::vector<String> subjects;
-    Poco::Logger * log;
+    LoggerPtr log;
     const std::atomic<bool> & stopped;
 
     bool subscribed = false;
diff --git a/src/Storages/NATS/NATSHandler.cpp b/src/Storages/NATS/NATSHandler.cpp
index 7006e5633a92..03f1fc1a4955 100644
--- a/src/Storages/NATS/NATSHandler.cpp
+++ b/src/Storages/NATS/NATSHandler.cpp
@@ -12,7 +12,7 @@ namespace DB
 
 static const auto MAX_THREAD_WORK_DURATION_MS = 60000;
 
-NATSHandler::NATSHandler(uv_loop_t * loop_, Poco::Logger * log_) :
+NATSHandler::NATSHandler(uv_loop_t * loop_, LoggerPtr log_) :
     loop(loop_),
     log(log_),
     loop_running(false),
diff --git a/src/Storages/NATS/NATSHandler.h b/src/Storages/NATS/NATSHandler.h
index e3894c888a3c..6f9ec398cfae 100644
--- a/src/Storages/NATS/NATSHandler.h
+++ b/src/Storages/NATS/NATSHandler.h
@@ -6,7 +6,7 @@
 #include <thread>
 #include <nats.h>
 #include <base/types.h>
-#include <Poco/Logger.h>
+#include <Common/Logger.h>
 
 namespace DB
 {
@@ -23,7 +23,7 @@ using LockPtr = std::unique_ptr<std::lock_guard<std::mutex>>;
 class NATSHandler
 {
 public:
-    NATSHandler(uv_loop_t * loop_, Poco::Logger * log_);
+    NATSHandler(uv_loop_t * loop_, LoggerPtr log_);
 
     ~NATSHandler();
 
@@ -47,7 +47,7 @@ class NATSHandler
 private:
     uv_loop_t * loop;
     natsOptions * opts = nullptr;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::atomic<bool> loop_running;
     std::atomic<UInt8> loop_state;
diff --git a/src/Storages/NATS/NATSProducer.cpp b/src/Storages/NATS/NATSProducer.cpp
index a8510149baf2..fb8abb016f80 100644
--- a/src/Storages/NATS/NATSProducer.cpp
+++ b/src/Storages/NATS/NATSProducer.cpp
@@ -23,7 +23,7 @@ NATSProducer::NATSProducer(
     const NATSConfiguration & configuration_,
     const String & subject_,
     std::atomic<bool> & shutdown_called_,
-    Poco::Logger * log_)
+    LoggerPtr log_)
     : AsynchronousMessageProducer(log_)
     , connection(configuration_, log_)
     , subject(subject_)
diff --git a/src/Storages/NATS/NATSProducer.h b/src/Storages/NATS/NATSProducer.h
index 0303d05969b2..6923553a551b 100644
--- a/src/Storages/NATS/NATSProducer.h
+++ b/src/Storages/NATS/NATSProducer.h
@@ -20,7 +20,7 @@ class NATSProducer : public AsynchronousMessageProducer
         const NATSConfiguration & configuration_,
         const String & subject_,
         std::atomic<bool> & shutdown_called_,
-        Poco::Logger * log_);
+        LoggerPtr log_);
 
     void produce(const String & message, size_t rows_in_message, const Columns & columns, size_t last_row) override;
 
diff --git a/src/Storages/NATS/StorageNATS.cpp b/src/Storages/NATS/StorageNATS.cpp
index 9cb1fbd85061..2af9a9f974f9 100644
--- a/src/Storages/NATS/StorageNATS.cpp
+++ b/src/Storages/NATS/StorageNATS.cpp
@@ -59,7 +59,7 @@ StorageNATS::StorageNATS(
     , schema_name(getContext()->getMacros()->expand(nats_settings->nats_schema))
     , num_consumers(nats_settings->nats_num_consumers.value)
     , max_rows_per_message(nats_settings->nats_max_rows_per_message)
-    , log(&Poco::Logger::get("StorageNATS (" + table_id_.table_name + ")"))
+    , log(getLogger("StorageNATS (" + table_id_.table_name + ")"))
     , semaphore(0, static_cast<int>(num_consumers))
     , queue_size(std::max(QUEUE_SIZE, static_cast<uint32_t>(getMaxBlockSize())))
     , is_attach(is_attach_)
diff --git a/src/Storages/NATS/StorageNATS.h b/src/Storages/NATS/StorageNATS.h
index 16a162b85008..882119f5cdbc 100644
--- a/src/Storages/NATS/StorageNATS.h
+++ b/src/Storages/NATS/StorageNATS.h
@@ -78,7 +78,7 @@ class StorageNATS final : public IStorage, WithContext
     size_t num_consumers;
     size_t max_rows_per_message;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     NATSConnectionManagerPtr connection; /// Connection for all consumers
     NATSConfiguration configuration;
diff --git a/src/Storages/PostgreSQL/MaterializedPostgreSQLConsumer.cpp b/src/Storages/PostgreSQL/MaterializedPostgreSQLConsumer.cpp
index b24421094098..f99ebf517928 100644
--- a/src/Storages/PostgreSQL/MaterializedPostgreSQLConsumer.cpp
+++ b/src/Storages/PostgreSQL/MaterializedPostgreSQLConsumer.cpp
@@ -51,7 +51,7 @@ MaterializedPostgreSQLConsumer::MaterializedPostgreSQLConsumer(
     bool schema_as_a_part_of_table_name_,
     StorageInfos storages_info_,
     const String & name_for_logger)
-    : log(&Poco::Logger::get("PostgreSQLReplicaConsumer(" + name_for_logger + ")"))
+    : log(getLogger("PostgreSQLReplicaConsumer(" + name_for_logger + ")"))
     , context(context_)
     , replication_slot_name(replication_slot_name_)
     , publication_name(publication_name_)
@@ -76,7 +76,7 @@ MaterializedPostgreSQLConsumer::MaterializedPostgreSQLConsumer(
 }
 
 
-MaterializedPostgreSQLConsumer::StorageData::StorageData(const StorageInfo & storage_info, Poco::Logger * log_)
+MaterializedPostgreSQLConsumer::StorageData::StorageData(const StorageInfo & storage_info, LoggerPtr log_)
     : storage(storage_info.storage)
     , table_description(storage_info.storage->getInMemoryMetadataPtr()->getSampleBlock())
     , columns_attributes(storage_info.attributes)
diff --git a/src/Storages/PostgreSQL/MaterializedPostgreSQLConsumer.h b/src/Storages/PostgreSQL/MaterializedPostgreSQLConsumer.h
index 3e95c1cd7de5..972c03e50d86 100644
--- a/src/Storages/PostgreSQL/MaterializedPostgreSQLConsumer.h
+++ b/src/Storages/PostgreSQL/MaterializedPostgreSQLConsumer.h
@@ -32,7 +32,7 @@ class MaterializedPostgreSQLConsumer
 private:
     struct StorageData
     {
-        explicit StorageData(const StorageInfo & storage_info, Poco::Logger * log_);
+        explicit StorageData(const StorageInfo & storage_info, LoggerPtr log_);
 
         size_t getColumnsNum() const { return table_description.sample_block.columns(); }
 
@@ -137,7 +137,7 @@ class MaterializedPostgreSQLConsumer
         return (static_cast<Int64>(upper_half) << 32) + lower_half;
     }
 
-    Poco::Logger * log;
+    LoggerPtr log;
     ContextPtr context;
     const std::string replication_slot_name, publication_name;
 
diff --git a/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.cpp b/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.cpp
index 43de2069b195..2bb1e2dde0d7 100644
--- a/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.cpp
+++ b/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.cpp
@@ -128,7 +128,7 @@ PostgreSQLReplicationHandler::PostgreSQLReplicationHandler(
     const MaterializedPostgreSQLSettings & replication_settings,
     bool is_materialized_postgresql_database_)
     : WithContext(context_->getGlobalContext())
-    , log(&Poco::Logger::get("PostgreSQLReplicationHandler"))
+    , log(getLogger("PostgreSQLReplicationHandler"))
     , is_attach(is_attach_)
     , postgres_database(postgres_database_)
     , postgres_schema(replication_settings.materialized_postgresql_schema)
diff --git a/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.h b/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.h
index 5d426b3c512d..5c519053d844 100644
--- a/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.h
+++ b/src/Storages/PostgreSQL/PostgreSQLReplicationHandler.h
@@ -102,7 +102,7 @@ friend class TemporaryReplicationSlot;
 
     void assertInitialized() const;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// If it is not attach, i.e. a create query, then if publication already exists - always drop it.
     bool is_attach;
diff --git a/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.cpp b/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.cpp
index 0faf553797ad..f13cb820ec35 100644
--- a/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.cpp
+++ b/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.cpp
@@ -60,7 +60,7 @@ StorageMaterializedPostgreSQL::StorageMaterializedPostgreSQL(
     std::unique_ptr<MaterializedPostgreSQLSettings> replication_settings)
     : IStorage(table_id_)
     , WithContext(context_->getGlobalContext())
-    , log(&Poco::Logger::get("StorageMaterializedPostgreSQL(" + postgres::formatNameForLogs(remote_database_name, remote_table_name_) + ")"))
+    , log(getLogger("StorageMaterializedPostgreSQL(" + postgres::formatNameForLogs(remote_database_name, remote_table_name_) + ")"))
     , is_materialized_postgresql_database(false)
     , has_nested(false)
     , nested_context(makeNestedTableContext(context_->getGlobalContext()))
@@ -101,7 +101,7 @@ StorageMaterializedPostgreSQL::StorageMaterializedPostgreSQL(
         const String & postgres_table_name)
     : IStorage(table_id_)
     , WithContext(context_->getGlobalContext())
-    , log(&Poco::Logger::get("StorageMaterializedPostgreSQL(" + postgres::formatNameForLogs(postgres_database_name, postgres_table_name) + ")"))
+    , log(getLogger("StorageMaterializedPostgreSQL(" + postgres::formatNameForLogs(postgres_database_name, postgres_table_name) + ")"))
     , is_materialized_postgresql_database(true)
     , has_nested(false)
     , nested_context(makeNestedTableContext(context_->getGlobalContext()))
@@ -120,7 +120,7 @@ StorageMaterializedPostgreSQL::StorageMaterializedPostgreSQL(
         const String & postgres_table_name)
     : IStorage(StorageID(nested_storage_->getStorageID().database_name, nested_storage_->getStorageID().table_name))
     , WithContext(context_->getGlobalContext())
-    , log(&Poco::Logger::get("StorageMaterializedPostgreSQL(" + postgres::formatNameForLogs(postgres_database_name, postgres_table_name) + ")"))
+    , log(getLogger("StorageMaterializedPostgreSQL(" + postgres::formatNameForLogs(postgres_database_name, postgres_table_name) + ")"))
     , is_materialized_postgresql_database(true)
     , has_nested(true)
     , nested_context(makeNestedTableContext(context_->getGlobalContext()))
@@ -141,7 +141,7 @@ StoragePtr StorageMaterializedPostgreSQL::createTemporary() const
     auto tmp_storage = DatabaseCatalog::instance().tryGetTable(tmp_table_id, nested_context);
     if (tmp_storage)
     {
-        LOG_TRACE(&Poco::Logger::get("MaterializedPostgreSQLStorage"), "Temporary table {} already exists, dropping", tmp_table_id.getNameForLogs());
+        LOG_TRACE(getLogger("MaterializedPostgreSQLStorage"), "Temporary table {} already exists, dropping", tmp_table_id.getNameForLogs());
         InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind::Drop, getContext(), getContext(), tmp_table_id, /* sync */true);
     }
 
diff --git a/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.h b/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.h
index bebbb74ddd11..9c9418a8caa9 100644
--- a/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.h
+++ b/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.h
@@ -142,7 +142,7 @@ class StorageMaterializedPostgreSQL final : public IStorage, WithContext
 
     String getNestedTableName() const;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Not nullptr only for single MaterializedPostgreSQL storage, because for MaterializedPostgreSQL
     /// database engine there is one replication handler for all tables.
diff --git a/src/Storages/RabbitMQ/RabbitMQConnection.cpp b/src/Storages/RabbitMQ/RabbitMQConnection.cpp
index 13d065774a27..98ceba42676b 100644
--- a/src/Storages/RabbitMQ/RabbitMQConnection.cpp
+++ b/src/Storages/RabbitMQ/RabbitMQConnection.cpp
@@ -11,7 +11,7 @@ static const auto CONNECT_SLEEP = 200;
 static const auto RETRIES_MAX = 20;
 
 
-RabbitMQConnection::RabbitMQConnection(const RabbitMQConfiguration & configuration_, Poco::Logger * log_)
+RabbitMQConnection::RabbitMQConnection(const RabbitMQConfiguration & configuration_, LoggerPtr log_)
     : configuration(configuration_)
     , log(log_)
     , event_handler(loop.getLoop(), log)
diff --git a/src/Storages/RabbitMQ/RabbitMQConnection.h b/src/Storages/RabbitMQ/RabbitMQConnection.h
index 698230b16f4a..5adb64561948 100644
--- a/src/Storages/RabbitMQ/RabbitMQConnection.h
+++ b/src/Storages/RabbitMQ/RabbitMQConnection.h
@@ -22,7 +22,7 @@ struct RabbitMQConfiguration
 class RabbitMQConnection
 {
 public:
-    RabbitMQConnection(const RabbitMQConfiguration & configuration_, Poco::Logger * log_);
+    RabbitMQConnection(const RabbitMQConfiguration & configuration_, LoggerPtr log_);
 
     bool isConnected();
 
@@ -51,7 +51,7 @@ class RabbitMQConnection
     void disconnectImpl(bool immediately = false);
 
     RabbitMQConfiguration configuration;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     UVLoop loop;
     /// Preserve order of destruction here:
diff --git a/src/Storages/RabbitMQ/RabbitMQConsumer.cpp b/src/Storages/RabbitMQ/RabbitMQConsumer.cpp
index f6facc04212e..1843bebe3c7f 100644
--- a/src/Storages/RabbitMQ/RabbitMQConsumer.cpp
+++ b/src/Storages/RabbitMQ/RabbitMQConsumer.cpp
@@ -24,7 +24,7 @@ RabbitMQConsumer::RabbitMQConsumer(
         std::vector<String> & queues_,
         size_t channel_id_base_,
         const String & channel_base_,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         uint32_t queue_size_)
         : event_handler(event_handler_)
         , queues(queues_)
diff --git a/src/Storages/RabbitMQ/RabbitMQConsumer.h b/src/Storages/RabbitMQ/RabbitMQConsumer.h
index 89dfa060eecb..c78b33bfc7cc 100644
--- a/src/Storages/RabbitMQ/RabbitMQConsumer.h
+++ b/src/Storages/RabbitMQ/RabbitMQConsumer.h
@@ -32,7 +32,7 @@ class RabbitMQConsumer
         std::vector<String> & queues_,
         size_t channel_id_base_,
         const String & channel_base_,
-        Poco::Logger * log_,
+        LoggerPtr log_,
         uint32_t queue_size_);
 
     struct CommitInfo
@@ -88,7 +88,7 @@ class RabbitMQConsumer
     const String channel_base;
     const size_t channel_id_base;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     std::atomic<bool> stopped;
 
     String channel_id;
diff --git a/src/Storages/RabbitMQ/RabbitMQHandler.cpp b/src/Storages/RabbitMQ/RabbitMQHandler.cpp
index 745af0d20e3a..be352f26f7be 100644
--- a/src/Storages/RabbitMQ/RabbitMQHandler.cpp
+++ b/src/Storages/RabbitMQ/RabbitMQHandler.cpp
@@ -8,7 +8,7 @@ namespace DB
 /* The object of this class is shared between concurrent consumers (who share the same connection == share the same
  * event loop and handler).
  */
-RabbitMQHandler::RabbitMQHandler(uv_loop_t * loop_, Poco::Logger * log_) :
+RabbitMQHandler::RabbitMQHandler(uv_loop_t * loop_, LoggerPtr log_) :
     AMQP::LibUvHandler(loop_),
     loop(loop_),
     log(log_),
diff --git a/src/Storages/RabbitMQ/RabbitMQHandler.h b/src/Storages/RabbitMQ/RabbitMQHandler.h
index 4223732a4a07..244692cf8009 100644
--- a/src/Storages/RabbitMQ/RabbitMQHandler.h
+++ b/src/Storages/RabbitMQ/RabbitMQHandler.h
@@ -24,7 +24,7 @@ class RabbitMQHandler : public AMQP::LibUvHandler
 {
 
 public:
-    RabbitMQHandler(uv_loop_t * loop_, Poco::Logger * log_);
+    RabbitMQHandler(uv_loop_t * loop_, LoggerPtr log_);
 
     void onError(AMQP::TcpConnection * connection, const char * message) override;
     void onReady(AMQP::TcpConnection * connection) override;
@@ -50,7 +50,7 @@ class RabbitMQHandler : public AMQP::LibUvHandler
 
 private:
     uv_loop_t * loop;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::atomic<bool> connection_running, loop_running;
     std::atomic<UInt8> loop_state;
diff --git a/src/Storages/RabbitMQ/RabbitMQProducer.cpp b/src/Storages/RabbitMQ/RabbitMQProducer.cpp
index 246569060d00..7ad83213b9b1 100644
--- a/src/Storages/RabbitMQ/RabbitMQProducer.cpp
+++ b/src/Storages/RabbitMQ/RabbitMQProducer.cpp
@@ -31,7 +31,7 @@ RabbitMQProducer::RabbitMQProducer(
     const size_t channel_id_base_,
     const bool persistent_,
     std::atomic<bool> & shutdown_called_,
-    Poco::Logger * log_)
+    LoggerPtr log_)
     : AsynchronousMessageProducer(log_)
     , connection(configuration_, log_)
     , routing_keys(routing_keys_)
diff --git a/src/Storages/RabbitMQ/RabbitMQProducer.h b/src/Storages/RabbitMQ/RabbitMQProducer.h
index 70afbbb9b903..a790eda0d085 100644
--- a/src/Storages/RabbitMQ/RabbitMQProducer.h
+++ b/src/Storages/RabbitMQ/RabbitMQProducer.h
@@ -24,7 +24,7 @@ class RabbitMQProducer : public AsynchronousMessageProducer
         const size_t channel_id_base_,
         const bool persistent_,
         std::atomic<bool> & shutdown_called_,
-        Poco::Logger * log_);
+        LoggerPtr log_);
 
     void produce(const String & message, size_t rows_in_message, const Columns & columns, size_t last_row) override;
 
diff --git a/src/Storages/RabbitMQ/RabbitMQSource.cpp b/src/Storages/RabbitMQ/RabbitMQSource.cpp
index 793064c10f88..3cec448fc115 100644
--- a/src/Storages/RabbitMQ/RabbitMQSource.cpp
+++ b/src/Storages/RabbitMQ/RabbitMQSource.cpp
@@ -70,7 +70,7 @@ RabbitMQSource::RabbitMQSource(
     , ack_in_suffix(ack_in_suffix_)
     , non_virtual_header(std::move(headers.first))
     , virtual_header(std::move(headers.second))
-    , log(&Poco::Logger::get("RabbitMQSource"))
+    , log(getLogger("RabbitMQSource"))
     , max_execution_time_ms(max_execution_time_)
 {
     storage.incrementReader();
diff --git a/src/Storages/RabbitMQ/RabbitMQSource.h b/src/Storages/RabbitMQ/RabbitMQSource.h
index a25b3d502220..21d059bfae2e 100644
--- a/src/Storages/RabbitMQ/RabbitMQSource.h
+++ b/src/Storages/RabbitMQ/RabbitMQSource.h
@@ -47,7 +47,7 @@ class RabbitMQSource : public ISource
     const Block non_virtual_header;
     const Block virtual_header;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     RabbitMQConsumerPtr consumer;
 
     uint64_t max_execution_time_ms = 0;
diff --git a/src/Storages/RabbitMQ/StorageRabbitMQ.cpp b/src/Storages/RabbitMQ/StorageRabbitMQ.cpp
index fce2d775b157..025f421db592 100644
--- a/src/Storages/RabbitMQ/StorageRabbitMQ.cpp
+++ b/src/Storages/RabbitMQ/StorageRabbitMQ.cpp
@@ -86,7 +86,7 @@ StorageRabbitMQ::StorageRabbitMQ(
         , persistent(rabbitmq_settings->rabbitmq_persistent.value)
         , use_user_setup(rabbitmq_settings->rabbitmq_queue_consume.value)
         , hash_exchange(num_consumers > 1 || num_queues > 1)
-        , log(&Poco::Logger::get("StorageRabbitMQ (" + table_id_.table_name + ")"))
+        , log(getLogger("StorageRabbitMQ (" + table_id_.table_name + ")"))
         , semaphore(0, static_cast<int>(num_consumers))
         , unique_strbase(getRandomName())
         , queue_size(std::max(QUEUE_SIZE, static_cast<uint32_t>(getMaxBlockSize())))
diff --git a/src/Storages/RabbitMQ/StorageRabbitMQ.h b/src/Storages/RabbitMQ/StorageRabbitMQ.h
index 120930cf01d1..be46caf97989 100644
--- a/src/Storages/RabbitMQ/StorageRabbitMQ.h
+++ b/src/Storages/RabbitMQ/StorageRabbitMQ.h
@@ -102,7 +102,7 @@ class StorageRabbitMQ final: public IStorage, WithContext
     bool use_user_setup;
 
     bool hash_exchange;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     RabbitMQConnectionPtr connection; /// Connection for all consumers
     RabbitMQConfiguration configuration;
diff --git a/src/Storages/S3Queue/S3QueueFilesMetadata.cpp b/src/Storages/S3Queue/S3QueueFilesMetadata.cpp
index f49e1d6f25c5..a2b41eb4685e 100644
--- a/src/Storages/S3Queue/S3QueueFilesMetadata.cpp
+++ b/src/Storages/S3Queue/S3QueueFilesMetadata.cpp
@@ -133,7 +133,7 @@ S3QueueFilesMetadata::S3QueueFilesMetadata(const fs::path & zookeeper_path_, con
     , zookeeper_processed_path(zookeeper_path_ / "processed")
     , zookeeper_failed_path(zookeeper_path_ / "failed")
     , zookeeper_cleanup_lock_path(zookeeper_path_ / "cleanup_lock")
-    , log(&Poco::Logger::get("S3QueueFilesMetadata"))
+    , log(getLogger("S3QueueFilesMetadata"))
 {
     if (mode == S3QueueMode::UNORDERED && (max_set_size || max_set_age_sec))
     {
@@ -689,7 +689,7 @@ S3QueueFilesMetadata::ProcessingNodeHolder::ProcessingNodeHolder(
     , path(path_)
     , zk_node_path(zk_node_path_)
     , processing_id(processing_id_)
-    , log(&Poco::Logger::get("ProcessingNodeHolder"))
+    , log(getLogger("ProcessingNodeHolder"))
 {
 }
 
diff --git a/src/Storages/S3Queue/S3QueueFilesMetadata.h b/src/Storages/S3Queue/S3QueueFilesMetadata.h
index f3be7c5c3a0d..390cb5a64ab0 100644
--- a/src/Storages/S3Queue/S3QueueFilesMetadata.h
+++ b/src/Storages/S3Queue/S3QueueFilesMetadata.h
@@ -93,7 +93,7 @@ class S3QueueFilesMetadata
     const fs::path zookeeper_failed_path;
     const fs::path zookeeper_cleanup_lock_path;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::atomic_bool shutdown = false;
     BackgroundSchedulePool::TaskHolder task;
@@ -169,7 +169,7 @@ class S3QueueFilesMetadata::ProcessingNodeHolder
     std::string zk_node_path;
     std::string processing_id;
     bool removed = false;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/S3Queue/S3QueueSource.cpp b/src/Storages/S3Queue/S3QueueSource.cpp
index 27bec039f96c..54155ad3ea7d 100644
--- a/src/Storages/S3Queue/S3QueueSource.cpp
+++ b/src/Storages/S3Queue/S3QueueSource.cpp
@@ -60,7 +60,7 @@ StorageS3QueueSource::KeyWithInfoPtr StorageS3QueueSource::FileIterator::next()
 
         if (shutdown_called)
         {
-            LOG_TEST(&Poco::Logger::get("StorageS3QueueSource"), "Shutdown was called, stopping file iterator");
+            LOG_TEST(getLogger("StorageS3QueueSource"), "Shutdown was called, stopping file iterator");
             return {};
         }
 
@@ -91,7 +91,7 @@ StorageS3QueueSource::StorageS3QueueSource(
     const std::atomic<bool> & table_is_being_dropped_,
     std::shared_ptr<S3QueueLog> s3_queue_log_,
     const StorageID & storage_id_,
-    Poco::Logger * log_)
+    LoggerPtr log_)
     : ISource(header_)
     , WithContext(context_)
     , name(std::move(name_))
diff --git a/src/Storages/S3Queue/S3QueueSource.h b/src/Storages/S3Queue/S3QueueSource.h
index 542f8e8fd8c7..82e75020efb2 100644
--- a/src/Storages/S3Queue/S3QueueSource.h
+++ b/src/Storages/S3Queue/S3QueueSource.h
@@ -67,7 +67,7 @@ class StorageS3QueueSource : public ISource, WithContext
         const std::atomic<bool> & table_is_being_dropped_,
         std::shared_ptr<S3QueueLog> s3_queue_log_,
         const StorageID & storage_id_,
-        Poco::Logger * log_);
+        LoggerPtr log_);
 
     ~StorageS3QueueSource() override;
 
@@ -89,7 +89,7 @@ class StorageS3QueueSource : public ISource, WithContext
     const StorageID storage_id;
 
     RemoveFileFunc remove_file_func;
-    Poco::Logger * log;
+    LoggerPtr log;
 
     using ReaderHolder = StorageS3Source::ReaderHolder;
     ReaderHolder reader;
diff --git a/src/Storages/S3Queue/StorageS3Queue.cpp b/src/Storages/S3Queue/StorageS3Queue.cpp
index bc33e8cf2a90..48c284c022aa 100644
--- a/src/Storages/S3Queue/StorageS3Queue.cpp
+++ b/src/Storages/S3Queue/StorageS3Queue.cpp
@@ -75,7 +75,7 @@ namespace
         return zkutil::extractZooKeeperPath(result_zk_path, true);
     }
 
-    void checkAndAdjustSettings(S3QueueSettings & s3queue_settings, const Settings & settings, Poco::Logger * log)
+    void checkAndAdjustSettings(S3QueueSettings & s3queue_settings, const Settings & settings, LoggerPtr log)
     {
         if (s3queue_settings.mode == S3QueueMode::ORDERED && s3queue_settings.s3queue_processing_threads_num > 1)
         {
@@ -119,7 +119,7 @@ StorageS3Queue::StorageS3Queue(
     , configuration{configuration_}
     , format_settings(format_settings_)
     , reschedule_processing_interval_ms(s3queue_settings->s3queue_polling_min_timeout_ms)
-    , log(&Poco::Logger::get("StorageS3Queue (" + table_id_.table_name + ")"))
+    , log(getLogger("StorageS3Queue (" + table_id_.table_name + ")"))
 {
     if (configuration.url.key.empty())
     {
@@ -600,7 +600,7 @@ void registerStorageS3QueueImpl(const String & name, StorageFactory & factory)
                     if (user_format_settings.has(change.name))
                         user_format_settings.set(change.name, change.value);
                     else
-                        LOG_TRACE(&Poco::Logger::get("StorageS3"), "Remove: {}", change.name);
+                        LOG_TRACE(getLogger("StorageS3"), "Remove: {}", change.name);
                     args.storage_def->settings->changes.removeSetting(change.name);
                 }
 
diff --git a/src/Storages/S3Queue/StorageS3Queue.h b/src/Storages/S3Queue/StorageS3Queue.h
index 3d3594dc2ab3..5d2be610d58a 100644
--- a/src/Storages/S3Queue/StorageS3Queue.h
+++ b/src/Storages/S3Queue/StorageS3Queue.h
@@ -79,7 +79,7 @@ class StorageS3Queue : public IStorage, WithContext
     std::atomic<bool> shutdown_called = false;
     std::atomic<bool> table_is_being_dropped = false;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     void startup() override;
     void shutdown(bool is_drop) override;
diff --git a/src/Storages/StorageAzureBlob.h b/src/Storages/StorageAzureBlob.h
index 16e5b9edfb69..6fc3c5ce5920 100644
--- a/src/Storages/StorageAzureBlob.h
+++ b/src/Storages/StorageAzureBlob.h
@@ -319,7 +319,7 @@ class StorageAzureBlobSource : public ISource, WithContext
 
     ReaderHolder reader;
 
-    Poco::Logger * log = &Poco::Logger::get("StorageAzureBlobSource");
+    LoggerPtr log = getLogger("StorageAzureBlobSource");
 
     ThreadPool create_reader_pool;
     ThreadPoolCallbackRunner<ReaderHolder> create_reader_scheduler;
diff --git a/src/Storages/StorageAzureBlobCluster.cpp b/src/Storages/StorageAzureBlobCluster.cpp
index a6372577fb05..1d587512f38f 100644
--- a/src/Storages/StorageAzureBlobCluster.cpp
+++ b/src/Storages/StorageAzureBlobCluster.cpp
@@ -38,7 +38,7 @@ StorageAzureBlobCluster::StorageAzureBlobCluster(
     const ConstraintsDescription & constraints_,
     ContextPtr context_,
     bool structure_argument_was_provided_)
-    : IStorageCluster(cluster_name_, table_id_, &Poco::Logger::get("StorageAzureBlobCluster (" + table_id_.table_name + ")"), structure_argument_was_provided_)
+    : IStorageCluster(cluster_name_, table_id_, getLogger("StorageAzureBlobCluster (" + table_id_.table_name + ")"), structure_argument_was_provided_)
     , configuration{configuration_}
     , object_storage(std::move(object_storage_))
 {
diff --git a/src/Storages/StorageBuffer.cpp b/src/Storages/StorageBuffer.cpp
index 6f4b1563a46b..d5c135bb81dc 100644
--- a/src/Storages/StorageBuffer.cpp
+++ b/src/Storages/StorageBuffer.cpp
@@ -137,7 +137,7 @@ StorageBuffer::StorageBuffer(
     , flush_thresholds(flush_thresholds_)
     , destination_id(destination_id_)
     , allow_materialized(allow_materialized_)
-    , log(&Poco::Logger::get("StorageBuffer (" + table_id_.getFullTableName() + ")"))
+    , log(getLogger("StorageBuffer (" + table_id_.getFullTableName() + ")"))
     , bg_pool(getContext()->getBufferFlushSchedulePool())
 {
     StorageInMemoryMetadata storage_metadata;
@@ -433,7 +433,7 @@ void StorageBuffer::read(
 }
 
 
-static void appendBlock(Poco::Logger * log, const Block & from, Block & to)
+static void appendBlock(LoggerPtr log, const Block & from, Block & to)
 {
     size_t rows = from.rows();
     size_t old_rows = to.rows();
diff --git a/src/Storages/StorageBuffer.h b/src/Storages/StorageBuffer.h
index ef646a125483..47f6239b1734 100644
--- a/src/Storages/StorageBuffer.h
+++ b/src/Storages/StorageBuffer.h
@@ -166,7 +166,7 @@ friend class BufferSink;
     Writes lifetime_writes;
     Writes total_writes;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     void flushAllBuffers(bool check_thresholds = true);
     bool flushBuffer(Buffer & buffer, bool check_thresholds, bool locked = false);
diff --git a/src/Storages/StorageDistributed.cpp b/src/Storages/StorageDistributed.cpp
index 987ea4a4957f..2d05efdd74f6 100644
--- a/src/Storages/StorageDistributed.cpp
+++ b/src/Storages/StorageDistributed.cpp
@@ -329,7 +329,7 @@ StorageDistributed::StorageDistributed(
     , remote_database(remote_database_)
     , remote_table(remote_table_)
     , remote_table_function_ptr(remote_table_function_ptr_)
-    , log(&Poco::Logger::get("StorageDistributed (" + id_.table_name + ")"))
+    , log(getLogger("StorageDistributed (" + id_.table_name + ")"))
     , owned_cluster(std::move(owned_cluster_))
     , cluster_name(getContext()->getMacros()->expand(cluster_name_))
     , has_sharding_key(sharding_key_)
diff --git a/src/Storages/StorageDistributed.h b/src/Storages/StorageDistributed.h
index b7ed85e87df3..161a5983f941 100644
--- a/src/Storages/StorageDistributed.h
+++ b/src/Storages/StorageDistributed.h
@@ -238,7 +238,7 @@ class StorageDistributed final : public IStorage, WithContext
     String remote_table;
     ASTPtr remote_table_function_ptr;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Used to implement TableFunctionRemote.
     std::shared_ptr<Cluster> owned_cluster;
diff --git a/src/Storages/StorageExecutable.cpp b/src/Storages/StorageExecutable.cpp
index 2acbf3f46106..e475211deb39 100644
--- a/src/Storages/StorageExecutable.cpp
+++ b/src/Storages/StorageExecutable.cpp
@@ -80,7 +80,7 @@ StorageExecutable::StorageExecutable(
     : IStorage(table_id_)
     , settings(settings_)
     , input_queries(input_queries_)
-    , log(settings.is_executable_pool ? &Poco::Logger::get("StorageExecutablePool") : &Poco::Logger::get("StorageExecutable"))
+    , log(settings.is_executable_pool ? getLogger("StorageExecutablePool") : getLogger("StorageExecutable"))
 {
     StorageInMemoryMetadata storage_metadata;
     storage_metadata.setColumns(columns);
diff --git a/src/Storages/StorageExecutable.h b/src/Storages/StorageExecutable.h
index 37455385675c..2be2a84ab497 100644
--- a/src/Storages/StorageExecutable.h
+++ b/src/Storages/StorageExecutable.h
@@ -45,7 +45,7 @@ class StorageExecutable final : public IStorage
 private:
     ExecutableSettings settings;
     std::vector<ASTPtr> input_queries;
-    Poco::Logger * log;
+    LoggerPtr log;
     std::unique_ptr<ShellCommandSourceCoordinator> coordinator;
 };
 
diff --git a/src/Storages/StorageFile.cpp b/src/Storages/StorageFile.cpp
index 9f864813de9a..8979e068fb53 100644
--- a/src/Storages/StorageFile.cpp
+++ b/src/Storages/StorageFile.cpp
@@ -1040,7 +1040,7 @@ void StorageFileSource::beforeDestroy()
             catch (const std::exception & e)
             {
                 // Cannot throw exception from destructor, will write only error
-                LOG_ERROR(&Poco::Logger::get("~StorageFileSource"), "Failed to rename file {}: {}", file_path_ref, e.what());
+                LOG_ERROR(getLogger("~StorageFileSource"), "Failed to rename file {}: {}", file_path_ref, e.what());
                 continue;
             }
         }
diff --git a/src/Storages/StorageFile.h b/src/Storages/StorageFile.h
index b74868597a6c..2955eb0f1aac 100644
--- a/src/Storages/StorageFile.h
+++ b/src/Storages/StorageFile.h
@@ -163,7 +163,7 @@ class StorageFile final : public IStorage
 
     mutable std::shared_timed_mutex rwlock;
 
-    Poco::Logger * log = &Poco::Logger::get("StorageFile");
+    LoggerPtr log = getLogger("StorageFile");
 
     /// Total number of bytes to read (sums for multiple files in case of globs). Needed for progress bar.
     size_t total_bytes_to_read = 0;
diff --git a/src/Storages/StorageFileCluster.cpp b/src/Storages/StorageFileCluster.cpp
index c12124f1e07e..0cc961bb464d 100644
--- a/src/Storages/StorageFileCluster.cpp
+++ b/src/Storages/StorageFileCluster.cpp
@@ -34,7 +34,7 @@ StorageFileCluster::StorageFileCluster(
     const ColumnsDescription & columns_,
     const ConstraintsDescription & constraints_,
     bool structure_argument_was_provided_)
-    : IStorageCluster(cluster_name_, table_id_, &Poco::Logger::get("StorageFileCluster (" + table_id_.table_name + ")"), structure_argument_was_provided_)
+    : IStorageCluster(cluster_name_, table_id_, getLogger("StorageFileCluster (" + table_id_.table_name + ")"), structure_argument_was_provided_)
     , filename(filename_)
     , format_name(format_name_)
     , compression_method(compression_method_)
diff --git a/src/Storages/StorageJoin.cpp b/src/Storages/StorageJoin.cpp
index efe446a8ccd8..b9e082c0b224 100644
--- a/src/Storages/StorageJoin.cpp
+++ b/src/Storages/StorageJoin.cpp
@@ -104,7 +104,7 @@ void StorageJoin::truncate(const ASTPtr &, const StorageMetadataPtr &, ContextPt
     if (disk->exists(path))
         disk->removeRecursive(path);
     else
-        LOG_INFO(&Poco::Logger::get("StorageJoin"), "Path {} is already removed from disk {}", path, disk->getName());
+        LOG_INFO(getLogger("StorageJoin"), "Path {} is already removed from disk {}", path, disk->getName());
 
     disk->createDirectories(path);
     disk->createDirectories(fs::path(path) / "tmp/");
diff --git a/src/Storages/StorageKeeperMap.cpp b/src/Storages/StorageKeeperMap.cpp
index 8914838afed3..80abaa3ea2d2 100644
--- a/src/Storages/StorageKeeperMap.cpp
+++ b/src/Storages/StorageKeeperMap.cpp
@@ -321,7 +321,7 @@ StorageKeeperMap::StorageKeeperMap(
     , primary_key(primary_key_)
     , zookeeper_name(zkutil::extractZooKeeperName(zk_root_path_))
     , keys_limit(keys_limit_)
-    , log(&Poco::Logger::get(fmt::format("StorageKeeperMap ({})", table_id.getNameForLogs())))
+    , log(getLogger(fmt::format("StorageKeeperMap ({})", table_id.getNameForLogs())))
 {
     std::string path_prefix = context_->getConfigRef().getString("keeper_map_path_prefix", "");
     if (path_prefix.empty())
@@ -776,7 +776,7 @@ void StorageKeeperMap::backupData(BackupEntriesCollector & backup_entries_collec
 
         auto with_retries = std::make_shared<WithRetries>
         (
-            &Poco::Logger::get(fmt::format("StorageKeeperMapBackup ({})", getStorageID().getNameForLogs())),
+            getLogger(fmt::format("StorageKeeperMapBackup ({})", getStorageID().getNameForLogs())),
             [&] { return getClient(); },
             WithRetries::KeeperSettings::fromContext(backup_entries_collector.getContext()),
             backup_entries_collector.getContext()->getProcessListElement(),
@@ -808,7 +808,7 @@ void StorageKeeperMap::restoreDataFromBackup(RestorerFromBackup & restorer, cons
 
     auto with_retries = std::make_shared<WithRetries>
     (
-        &Poco::Logger::get(fmt::format("StorageKeeperMapRestore ({})", getStorageID().getNameForLogs())),
+        getLogger(fmt::format("StorageKeeperMapRestore ({})", getStorageID().getNameForLogs())),
         [&] { return getClient(); },
         WithRetries::KeeperSettings::fromContext(restorer.getContext()),
         restorer.getContext()->getProcessListElement(),
diff --git a/src/Storages/StorageKeeperMap.h b/src/Storages/StorageKeeperMap.h
index aa9687243d88..9dca96a24a36 100644
--- a/src/Storages/StorageKeeperMap.h
+++ b/src/Storages/StorageKeeperMap.h
@@ -146,7 +146,7 @@ class StorageKeeperMap final : public IStorage, public IKeyValueEntity, WithCont
     mutable std::mutex init_mutex;
     mutable std::optional<bool> table_is_valid;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/StorageMaterializedView.cpp b/src/Storages/StorageMaterializedView.cpp
index 050e76c9205c..bfe75e61bcde 100644
--- a/src/Storages/StorageMaterializedView.cpp
+++ b/src/Storages/StorageMaterializedView.cpp
@@ -523,7 +523,7 @@ void StorageMaterializedView::backupData(BackupEntriesCollector & backup_entries
         if (auto table = tryGetTargetTable())
             table->backupData(backup_entries_collector, data_path_in_backup, partitions);
         else
-            LOG_WARNING(&Poco::Logger::get("StorageMaterializedView"),
+            LOG_WARNING(getLogger("StorageMaterializedView"),
                         "Inner table does not exist, will not backup any data");
     }
 }
diff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp
index fbdde15c2af9..7e6c5ca39243 100644
--- a/src/Storages/StorageMergeTree.cpp
+++ b/src/Storages/StorageMergeTree.cpp
@@ -74,7 +74,7 @@ namespace ActionLocks
     extern const StorageActionBlockType PartsMove;
 }
 
-static MergeTreeTransactionPtr tryGetTransactionForMutation(const MergeTreeMutationEntry & mutation, Poco::Logger * log = nullptr)
+static MergeTreeTransactionPtr tryGetTransactionForMutation(const MergeTreeMutationEntry & mutation, LoggerPtr log = nullptr)
 {
     assert(!mutation.tid.isEmpty());
     if (mutation.tid.isPrehistoric())
diff --git a/src/Storages/StorageMySQL.cpp b/src/Storages/StorageMySQL.cpp
index 76a439eabafc..da391909dff4 100644
--- a/src/Storages/StorageMySQL.cpp
+++ b/src/Storages/StorageMySQL.cpp
@@ -55,7 +55,7 @@ StorageMySQL::StorageMySQL(
     , on_duplicate_clause{on_duplicate_clause_}
     , mysql_settings(mysql_settings_)
     , pool(std::make_shared<mysqlxx::PoolWithFailover>(pool_))
-    , log(&Poco::Logger::get("StorageMySQL (" + table_id_.table_name + ")"))
+    , log(getLogger("StorageMySQL (" + table_id_.table_name + ")"))
 {
     StorageInMemoryMetadata storage_metadata;
 
diff --git a/src/Storages/StorageMySQL.h b/src/Storages/StorageMySQL.h
index 5303117cf5c8..daabd66a5309 100644
--- a/src/Storages/StorageMySQL.h
+++ b/src/Storages/StorageMySQL.h
@@ -92,7 +92,7 @@ class StorageMySQL final : public IStorage, WithContext
 
     mysqlxx::PoolWithFailoverPtr pool;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/StoragePostgreSQL.cpp b/src/Storages/StoragePostgreSQL.cpp
index 8fe2a161dba4..9379cb5a1c6c 100644
--- a/src/Storages/StoragePostgreSQL.cpp
+++ b/src/Storages/StoragePostgreSQL.cpp
@@ -72,7 +72,7 @@ StoragePostgreSQL::StoragePostgreSQL(
     , remote_table_schema(remote_table_schema_)
     , on_conflict(on_conflict_)
     , pool(std::move(pool_))
-    , log(&Poco::Logger::get("StoragePostgreSQL (" + table_id_.table_name + ")"))
+    , log(getLogger("StoragePostgreSQL (" + table_id_.table_name + ")"))
 {
     StorageInMemoryMetadata storage_metadata;
 
diff --git a/src/Storages/StoragePostgreSQL.h b/src/Storages/StoragePostgreSQL.h
index 725a935aa46c..1ed4f7a7611b 100644
--- a/src/Storages/StoragePostgreSQL.h
+++ b/src/Storages/StoragePostgreSQL.h
@@ -79,7 +79,7 @@ class StoragePostgreSQL final : public IStorage
     String on_conflict;
     postgres::PoolWithFailoverPtr pool;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/StorageRedis.cpp b/src/Storages/StorageRedis.cpp
index ddb1b62c7b03..83bb3c606c92 100644
--- a/src/Storages/StorageRedis.cpp
+++ b/src/Storages/StorageRedis.cpp
@@ -206,7 +206,7 @@ StorageRedis::StorageRedis(
     , WithContext(context_->getGlobalContext())
     , table_id(table_id_)
     , configuration(configuration_)
-    , log(&Poco::Logger::get("StorageRedis"))
+    , log(getLogger("StorageRedis"))
     , primary_key(primary_key_)
 {
     pool = std::make_shared<RedisPool>(configuration.pool_size);
diff --git a/src/Storages/StorageRedis.h b/src/Storages/StorageRedis.h
index a525a4ed7de9..a0eb2bfa580d 100644
--- a/src/Storages/StorageRedis.h
+++ b/src/Storages/StorageRedis.h
@@ -74,7 +74,7 @@ class StorageRedis : public IStorage, public IKeyValueEntity, WithContext
     StorageID table_id;
     RedisConfiguration configuration;
 
-    Poco::Logger * log;
+    LoggerPtr log;
     RedisPoolPtr pool;
 
     const String primary_key;
diff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp
index 715cbab9eeae..c82721d2a18f 100644
--- a/src/Storages/StorageReplicatedMergeTree.cpp
+++ b/src/Storages/StorageReplicatedMergeTree.cpp
@@ -1133,7 +1133,7 @@ void StorageReplicatedMergeTree::drop()
 }
 
 void StorageReplicatedMergeTree::dropReplica(zkutil::ZooKeeperPtr zookeeper, const String & zookeeper_path, const String & replica,
-                                             Poco::Logger * logger, MergeTreeSettingsPtr table_settings, std::optional<bool> * has_metadata_out)
+                                             LoggerPtr logger, MergeTreeSettingsPtr table_settings, std::optional<bool> * has_metadata_out)
 {
     if (zookeeper->expired())
         throw Exception(ErrorCodes::TABLE_WAS_NOT_DROPPED, "Table was not dropped because ZooKeeper session has expired.");
@@ -1251,7 +1251,7 @@ void StorageReplicatedMergeTree::dropReplica(zkutil::ZooKeeperPtr zookeeper, con
     }
 }
 
-void StorageReplicatedMergeTree::dropReplica(const String & drop_zookeeper_path, const String & drop_replica, Poco::Logger * logger)
+void StorageReplicatedMergeTree::dropReplica(const String & drop_zookeeper_path, const String & drop_replica, LoggerPtr logger)
 {
     zkutil::ZooKeeperPtr zookeeper = getZooKeeperIfTableShutDown();
 
@@ -1266,7 +1266,7 @@ void StorageReplicatedMergeTree::dropReplica(const String & drop_zookeeper_path,
 
 
 bool StorageReplicatedMergeTree::removeTableNodesFromZooKeeper(zkutil::ZooKeeperPtr zookeeper,
-        const String & zookeeper_path, const zkutil::EphemeralNodeHolder::Ptr & metadata_drop_lock, Poco::Logger * logger)
+        const String & zookeeper_path, const zkutil::EphemeralNodeHolder::Ptr & metadata_drop_lock, LoggerPtr logger)
 {
     bool completely_removed = false;
 
@@ -4316,7 +4316,7 @@ void StorageReplicatedMergeTree::waitForUniquePartsToBeFetchedByOtherReplicas(St
         LOG_INFO(log, "Successfully waited all the parts");
 }
 
-std::set<MergeTreePartInfo> StorageReplicatedMergeTree::findReplicaUniqueParts(const String & replica_name_, const String & zookeeper_path_, MergeTreeDataFormatVersion format_version_, zkutil::ZooKeeper::Ptr zookeeper_, Poco::Logger * log_)
+std::set<MergeTreePartInfo> StorageReplicatedMergeTree::findReplicaUniqueParts(const String & replica_name_, const String & zookeeper_path_, MergeTreeDataFormatVersion format_version_, zkutil::ZooKeeper::Ptr zookeeper_, LoggerPtr log_)
 {
     if (!zookeeper_->exists(fs::path(zookeeper_path_) / "replicas" / replica_name_ / "is_active"))
     {
@@ -9364,7 +9364,7 @@ namespace
 /// But sometimes we need an opposite. When we deleting all_0_0_0_1 it can be non replicated to other replicas, so we are the only owner of this part.
 /// In this case when we will drop all_0_0_0_1 we will drop blobs for all_0_0_0. But it will lead to dataloss. For such case we need to check that other replicas
 /// still need parent part.
-std::pair<bool, NameSet> getParentLockedBlobs(const ZooKeeperWithFaultInjectionPtr & zookeeper_ptr, const std::string & zero_copy_part_path_prefix, const MergeTreePartInfo & part_info, MergeTreeDataFormatVersion format_version, Poco::Logger * log)
+std::pair<bool, NameSet> getParentLockedBlobs(const ZooKeeperWithFaultInjectionPtr & zookeeper_ptr, const std::string & zero_copy_part_path_prefix, const MergeTreePartInfo & part_info, MergeTreeDataFormatVersion format_version, LoggerPtr log)
 {
     NameSet files_not_to_remove;
 
@@ -9455,7 +9455,7 @@ std::pair<bool, NameSet> getParentLockedBlobs(const ZooKeeperWithFaultInjectionP
 std::pair<bool, NameSet> StorageReplicatedMergeTree::unlockSharedDataByID(
         String part_id, const String & table_uuid, const MergeTreePartInfo & part_info,
         const String & replica_name_, const std::string & disk_type, const ZooKeeperWithFaultInjectionPtr & zookeeper_ptr, const MergeTreeSettings & settings,
-        Poco::Logger * logger, const String & zookeeper_path_old, MergeTreeDataFormatVersion data_format_version)
+        LoggerPtr logger, const String & zookeeper_path_old, MergeTreeDataFormatVersion data_format_version)
 {
     boost::replace_all(part_id, "/", "_");
 
@@ -10143,7 +10143,7 @@ void StorageReplicatedMergeTree::createZeroCopyLockNode(
                 size_t failed_op = zkutil::getFailedOpIndex(error, responses);
                 if (ops[failed_op]->getPath() == zookeeper_node)
                 {
-                    LOG_WARNING(&Poco::Logger::get("ZeroCopyLocks"), "Replacing persistent lock with ephemeral for path {}. It can happen only in case of local part loss", zookeeper_node);
+                    LOG_WARNING(getLogger("ZeroCopyLocks"), "Replacing persistent lock with ephemeral for path {}. It can happen only in case of local part loss", zookeeper_node);
                     replace_existing_lock = true;
                     continue;
                 }
@@ -10201,7 +10201,7 @@ bool StorageReplicatedMergeTree::removeSharedDetachedPart(DiskPtr disk, const St
                 detached_replica_name,
                 disk->getDataSourceDescription().toString(),
                 std::make_shared<ZooKeeperWithFaultInjection>(zookeeper), local_context->getReplicatedMergeTreeSettings(),
-                &Poco::Logger::get("StorageReplicatedMergeTree"),
+                getLogger("StorageReplicatedMergeTree"),
                 detached_zookeeper_path,
                 MERGE_TREE_DATA_MIN_FORMAT_VERSION_WITH_CUSTOM_PARTITIONING);
 
diff --git a/src/Storages/StorageReplicatedMergeTree.h b/src/Storages/StorageReplicatedMergeTree.h
index 3c3c2f56fe2d..c682b1ec88d0 100644
--- a/src/Storages/StorageReplicatedMergeTree.h
+++ b/src/Storages/StorageReplicatedMergeTree.h
@@ -255,13 +255,13 @@ class StorageReplicatedMergeTree final : public MergeTreeData
     /** Remove a specific replica from zookeeper.
      */
     static void dropReplica(zkutil::ZooKeeperPtr zookeeper, const String & zookeeper_path, const String & replica,
-                            Poco::Logger * logger, MergeTreeSettingsPtr table_settings = nullptr, std::optional<bool> * has_metadata_out = nullptr);
+                            LoggerPtr logger, MergeTreeSettingsPtr table_settings = nullptr, std::optional<bool> * has_metadata_out = nullptr);
 
-    void dropReplica(const String & drop_zookeeper_path, const String & drop_replica, Poco::Logger * logger);
+    void dropReplica(const String & drop_zookeeper_path, const String & drop_replica, LoggerPtr logger);
 
     /// Removes table from ZooKeeper after the last replica was dropped
     static bool removeTableNodesFromZooKeeper(zkutil::ZooKeeperPtr zookeeper, const String & zookeeper_path,
-                                              const zkutil::EphemeralNodeHolder::Ptr & metadata_drop_lock, Poco::Logger * logger);
+                                              const zkutil::EphemeralNodeHolder::Ptr & metadata_drop_lock, LoggerPtr logger);
 
     /// Schedules job to execute in background pool (merge, mutate, drop range and so on)
     bool scheduleDataProcessingJob(BackgroundJobsAssignee & assignee) override;
@@ -308,7 +308,7 @@ class StorageReplicatedMergeTree final : public MergeTreeData
         const std::string & disk_type,
         const ZooKeeperWithFaultInjectionPtr & zookeeper_,
         const MergeTreeSettings & settings,
-        Poco::Logger * logger,
+        LoggerPtr logger,
         const String & zookeeper_path_old,
         MergeTreeDataFormatVersion data_format_version);
 
@@ -773,7 +773,7 @@ class StorageReplicatedMergeTree final : public MergeTreeData
     String findReplicaHavingCoveringPart(LogEntry & entry, bool active);
     bool findReplicaHavingCoveringPart(const String & part_name, bool active);
     String findReplicaHavingCoveringPartImplLowLevel(LogEntry * entry, const String & part_name, String & found_part_name, bool active);
-    static std::set<MergeTreePartInfo> findReplicaUniqueParts(const String & replica_name_, const String & zookeeper_path_, MergeTreeDataFormatVersion format_version_, zkutil::ZooKeeper::Ptr zookeeper_, Poco::Logger * log_);
+    static std::set<MergeTreePartInfo> findReplicaUniqueParts(const String & replica_name_, const String & zookeeper_path_, MergeTreeDataFormatVersion format_version_, zkutil::ZooKeeper::Ptr zookeeper_, LoggerPtr log_);
 
     /** Download the specified part from the specified replica.
       * If `to_detached`, the part is placed in the `detached` directory.
diff --git a/src/Storages/StorageS3.cpp b/src/Storages/StorageS3.cpp
index c376af5a3d7b..1a7704b4d67a 100644
--- a/src/Storages/StorageS3.cpp
+++ b/src/Storages/StorageS3.cpp
@@ -1194,7 +1194,7 @@ void ReadFromStorageS3Step::initializePipeline(QueryPipelineBuilder & pipeline,
 
     const size_t max_threads = local_context->getSettingsRef().max_threads;
     const size_t max_parsing_threads = num_streams >= max_threads ? 1 : (max_threads / std::max(num_streams, 1ul));
-    LOG_DEBUG(&Poco::Logger::get("StorageS3"), "Reading in {} streams, {} threads per stream", num_streams, max_parsing_threads);
+    LOG_DEBUG(getLogger("StorageS3"), "Reading in {} streams, {} threads per stream", num_streams, max_parsing_threads);
 
     Pipes pipes;
     pipes.reserve(num_streams);
@@ -1347,7 +1347,7 @@ void StorageS3::truncate(const ASTPtr & /* query */, const StorageMetadataPtr &,
     }
 
     for (const auto & error : response.GetResult().GetErrors())
-        LOG_WARNING(&Poco::Logger::get("StorageS3"), "Failed to delete {}, error: {}", error.GetKey(), error.GetMessage());
+        LOG_WARNING(getLogger("StorageS3"), "Failed to delete {}, error: {}", error.GetKey(), error.GetMessage());
 }
 
 StorageS3::Configuration StorageS3::updateConfigurationAndGetCopy(ContextPtr local_context)
diff --git a/src/Storages/StorageS3.h b/src/Storages/StorageS3.h
index b90a0d394cb2..8d020c5e9a2d 100644
--- a/src/Storages/StorageS3.h
+++ b/src/Storages/StorageS3.h
@@ -242,7 +242,7 @@ class StorageS3Source : public SourceWithKeyCondition, WithContext
     size_t max_parsing_threads = 1;
     bool need_only_count;
 
-    Poco::Logger * log = &Poco::Logger::get("StorageS3Source");
+    LoggerPtr log = getLogger("StorageS3Source");
 
     ThreadPool create_reader_pool;
     ThreadPoolCallbackRunner<ReaderHolder> create_reader_scheduler;
diff --git a/src/Storages/StorageS3Cluster.cpp b/src/Storages/StorageS3Cluster.cpp
index e1738056e9d7..25c2b42b766f 100644
--- a/src/Storages/StorageS3Cluster.cpp
+++ b/src/Storages/StorageS3Cluster.cpp
@@ -40,7 +40,7 @@ StorageS3Cluster::StorageS3Cluster(
     const ConstraintsDescription & constraints_,
     ContextPtr context_,
     bool structure_argument_was_provided_)
-    : IStorageCluster(cluster_name_, table_id_, &Poco::Logger::get("StorageS3Cluster (" + table_id_.table_name + ")"), structure_argument_was_provided_)
+    : IStorageCluster(cluster_name_, table_id_, getLogger("StorageS3Cluster (" + table_id_.table_name + ")"), structure_argument_was_provided_)
     , s3_configuration{configuration_}
 {
     context_->getGlobalContext()->getRemoteHostFilter().checkURL(configuration_.url.uri);
diff --git a/src/Storages/StorageSQLite.cpp b/src/Storages/StorageSQLite.cpp
index d5db5763da91..85c5e16a1bf9 100644
--- a/src/Storages/StorageSQLite.cpp
+++ b/src/Storages/StorageSQLite.cpp
@@ -42,7 +42,7 @@ StorageSQLite::StorageSQLite(
     , remote_table_name(remote_table_name_)
     , database_path(database_path_)
     , sqlite_db(sqlite_db_)
-    , log(&Poco::Logger::get("StorageSQLite (" + table_id_.table_name + ")"))
+    , log(getLogger("StorageSQLite (" + table_id_.table_name + ")"))
 {
     StorageInMemoryMetadata storage_metadata;
 
diff --git a/src/Storages/StorageSQLite.h b/src/Storages/StorageSQLite.h
index 9da040cbd5c5..baacdfb48997 100644
--- a/src/Storages/StorageSQLite.h
+++ b/src/Storages/StorageSQLite.h
@@ -50,7 +50,7 @@ class StorageSQLite final : public IStorage, public WithContext
     String remote_table_name;
     String database_path;
     SQLitePtr sqlite_db;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/StorageSet.cpp b/src/Storages/StorageSet.cpp
index 1b0db1da8005..7d7f3113cdbd 100644
--- a/src/Storages/StorageSet.cpp
+++ b/src/Storages/StorageSet.cpp
@@ -218,7 +218,7 @@ void StorageSet::truncate(const ASTPtr &, const StorageMetadataPtr & metadata_sn
     if (disk->exists(path))
         disk->removeRecursive(path);
     else
-        LOG_INFO(&Poco::Logger::get("StorageSet"), "Path {} is already removed from disk {}", path, disk->getName());
+        LOG_INFO(getLogger("StorageSet"), "Path {} is already removed from disk {}", path, disk->getName());
 
     disk->createDirectories(path);
     disk->createDirectories(fs::path(path) / "tmp/");
@@ -284,7 +284,7 @@ void StorageSetOrJoinBase::restoreFromFile(const String & file_path)
     finishInsert();
 
     /// TODO Add speed, compressed bytes, data volume in memory, compression ratio ... Generalize all statistics logging in project.
-    LOG_INFO(&Poco::Logger::get("StorageSetOrJoinBase"), "Loaded from backup file {}. {} rows, {}. State has {} unique rows.",
+    LOG_INFO(getLogger("StorageSetOrJoinBase"), "Loaded from backup file {}. {} rows, {}. State has {} unique rows.",
         file_path, info.rows, ReadableSize(info.bytes), getSize(ctx));
 }
 
diff --git a/src/Storages/StorageStripeLog.cpp b/src/Storages/StorageStripeLog.cpp
index 91f6246d1018..359f142949f2 100644
--- a/src/Storages/StorageStripeLog.cpp
+++ b/src/Storages/StorageStripeLog.cpp
@@ -277,7 +277,7 @@ StorageStripeLog::StorageStripeLog(
     , index_file_path(table_path + "index.mrk")
     , file_checker(disk, table_path + "sizes.json")
     , max_compress_block_size(context_->getSettings().max_compress_block_size)
-    , log(&Poco::Logger::get("StorageStripeLog"))
+    , log(getLogger("StorageStripeLog"))
 {
     StorageInMemoryMetadata storage_metadata;
     storage_metadata.setColumns(columns_);
diff --git a/src/Storages/StorageStripeLog.h b/src/Storages/StorageStripeLog.h
index a05117a9ad59..c7f3e7e21e6d 100644
--- a/src/Storages/StorageStripeLog.h
+++ b/src/Storages/StorageStripeLog.h
@@ -123,7 +123,7 @@ friend class StripeLogSink;
 
     mutable std::shared_timed_mutex rwlock;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/StorageURL.cpp b/src/Storages/StorageURL.cpp
index 0ba72af6fc08..631c06bd87b2 100644
--- a/src/Storages/StorageURL.cpp
+++ b/src/Storages/StorageURL.cpp
@@ -1284,7 +1284,7 @@ StorageURLWithFailover::StorageURLWithFailover(
     {
         Poco::URI poco_uri(uri_option);
         context_->getRemoteHostFilter().checkURL(poco_uri);
-        LOG_DEBUG(&Poco::Logger::get("StorageURLDistributed"), "Adding URL option: {}", uri_option);
+        LOG_DEBUG(getLogger("StorageURLDistributed"), "Adding URL option: {}", uri_option);
         uri_options.emplace_back(uri_option);
     }
 }
diff --git a/src/Storages/StorageURLCluster.cpp b/src/Storages/StorageURLCluster.cpp
index a0b5fcd6f285..2365887983d7 100644
--- a/src/Storages/StorageURLCluster.cpp
+++ b/src/Storages/StorageURLCluster.cpp
@@ -45,7 +45,7 @@ StorageURLCluster::StorageURLCluster(
     const ConstraintsDescription & constraints_,
     const StorageURL::Configuration & configuration_,
     bool structure_argument_was_provided_)
-    : IStorageCluster(cluster_name_, table_id_, &Poco::Logger::get("StorageURLCluster (" + table_id_.table_name + ")"), structure_argument_was_provided_)
+    : IStorageCluster(cluster_name_, table_id_, getLogger("StorageURLCluster (" + table_id_.table_name + ")"), structure_argument_was_provided_)
     , uri(uri_)
 {
     context_->getRemoteHostFilter().checkURL(Poco::URI(uri));
diff --git a/src/Storages/StorageXDBC.cpp b/src/Storages/StorageXDBC.cpp
index a274b1ba4db8..259abefb00fd 100644
--- a/src/Storages/StorageXDBC.cpp
+++ b/src/Storages/StorageXDBC.cpp
@@ -45,7 +45,7 @@ StorageXDBC::StorageXDBC(
     , bridge_helper(bridge_helper_)
     , remote_database_name(remote_database_name_)
     , remote_table_name(remote_table_name_)
-    , log(&Poco::Logger::get("Storage" + bridge_helper->getName()))
+    , log(getLogger("Storage" + bridge_helper->getName()))
 {
     uri = bridge_helper->getMainURI().toString();
 }
diff --git a/src/Storages/StorageXDBC.h b/src/Storages/StorageXDBC.h
index fe678785dc28..cba15a832267 100644
--- a/src/Storages/StorageXDBC.h
+++ b/src/Storages/StorageXDBC.h
@@ -47,7 +47,7 @@ class StorageXDBC : public IStorageURLBase
     std::string remote_database_name;
     std::string remote_table_name;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::string getReadMethod() const override;
 
diff --git a/src/Storages/System/StorageSystemDatabases.cpp b/src/Storages/System/StorageSystemDatabases.cpp
index 0ffed6c97718..51ecb8f17cae 100644
--- a/src/Storages/System/StorageSystemDatabases.cpp
+++ b/src/Storages/System/StorageSystemDatabases.cpp
@@ -54,7 +54,7 @@ static String getEngineFull(const ContextPtr & ctx, const DatabasePtr & database
             return {};
 
         guard.reset();
-        LOG_TRACE(&Poco::Logger::get("StorageSystemDatabases"), "Failed to lock database {} ({}), will retry", name, database->getUUID());
+        LOG_TRACE(getLogger("StorageSystemDatabases"), "Failed to lock database {} ({}), will retry", name, database->getUUID());
     }
 
     ASTPtr ast = database->getCreateDatabaseQuery();
diff --git a/src/Storages/System/StorageSystemJemalloc.cpp b/src/Storages/System/StorageSystemJemalloc.cpp
index 9c3a075b2c15..15543208dd9e 100644
--- a/src/Storages/System/StorageSystemJemalloc.cpp
+++ b/src/Storages/System/StorageSystemJemalloc.cpp
@@ -77,7 +77,7 @@ void fillJemallocBins(MutableColumns & res_columns)
 
 void fillJemallocBins(MutableColumns &)
 {
-    LOG_INFO(&Poco::Logger::get("StorageSystemJemallocBins"), "jemalloc is not enabled");
+    LOG_INFO(getLogger("StorageSystemJemallocBins"), "jemalloc is not enabled");
 }
 
 #endif // USE_JEMALLOC
diff --git a/src/Storages/System/StorageSystemReplicas.cpp b/src/Storages/System/StorageSystemReplicas.cpp
index d9a120954434..eeb3db342b49 100644
--- a/src/Storages/System/StorageSystemReplicas.cpp
+++ b/src/Storages/System/StorageSystemReplicas.cpp
@@ -56,12 +56,12 @@ class StatusRequestsPool
     /// Used to assign unique incremental ids to requests.
     UInt64 request_id TSA_GUARDED_BY(mutex) = 0;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
 public:
     explicit StatusRequestsPool(size_t max_threads)
         : thread_pool(CurrentMetrics::SystemReplicasThreads, CurrentMetrics::SystemReplicasThreadsActive, CurrentMetrics::SystemReplicasThreadsScheduled, max_threads)
-        , log(&Poco::Logger::get("StatusRequestsPool"))
+        , log(getLogger("StatusRequestsPool"))
     {}
 
     ~StatusRequestsPool()
diff --git a/src/Storages/System/StorageSystemStackTrace.cpp b/src/Storages/System/StorageSystemStackTrace.cpp
index e02d4bf1733b..b17d04e98955 100644
--- a/src/Storages/System/StorageSystemStackTrace.cpp
+++ b/src/Storages/System/StorageSystemStackTrace.cpp
@@ -173,7 +173,7 @@ bool wait(int timeout_ms)
 }
 
 using ThreadIdToName = std::unordered_map<UInt64, String, DefaultHash<UInt64>>;
-ThreadIdToName getFilteredThreadNames(const ActionsDAG::Node * predicate, ContextPtr context, const PaddedPODArray<UInt64> & thread_ids, Poco::Logger * log)
+ThreadIdToName getFilteredThreadNames(const ActionsDAG::Node * predicate, ContextPtr context, const PaddedPODArray<UInt64> & thread_ids, LoggerPtr log)
 {
     ThreadIdToName tid_to_name;
     MutableColumnPtr all_thread_names = ColumnString::create();
@@ -274,7 +274,7 @@ bool isSignalBlocked(UInt64 tid, int signal)
 class StackTraceSource : public ISource
 {
 public:
-    StackTraceSource(const Names & column_names, Block header_, ASTPtr && query_, ActionsDAGPtr && filter_dag_, ContextPtr context_, UInt64 max_block_size_, Poco::Logger * log_)
+    StackTraceSource(const Names & column_names, Block header_, ASTPtr && query_, ActionsDAGPtr && filter_dag_, ContextPtr context_, UInt64 max_block_size_, LoggerPtr log_)
         : ISource(header_)
         , context(context_)
         , header(std::move(header_))
@@ -426,7 +426,7 @@ class StackTraceSource : public ISource
     bool send_signal = false;
     bool read_thread_names = false;
 
-    Poco::Logger * log;
+    LoggerPtr log;
 
     std::filesystem::directory_iterator proc_it;
     std::filesystem::directory_iterator end;
@@ -481,7 +481,7 @@ class ReadFromSystemStackTrace : public SourceStepWithFilter
         ASTPtr && query_,
         ContextPtr context_,
         size_t max_block_size_,
-        Poco::Logger * log_)
+        LoggerPtr log_)
         : SourceStepWithFilter(DataStream{.header = std::move(sample_block)})
         , column_names(column_names_)
         , query(query_)
@@ -496,7 +496,7 @@ class ReadFromSystemStackTrace : public SourceStepWithFilter
     ASTPtr query;
     ContextPtr context;
     size_t max_block_size;
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
@@ -504,7 +504,7 @@ class ReadFromSystemStackTrace : public SourceStepWithFilter
 
 StorageSystemStackTrace::StorageSystemStackTrace(const StorageID & table_id_)
     : IStorage(table_id_)
-    , log(&Poco::Logger::get("StorageSystemStackTrace"))
+    , log(getLogger("StorageSystemStackTrace"))
 {
     StorageInMemoryMetadata storage_metadata;
     storage_metadata.setColumns(ColumnsDescription({
diff --git a/src/Storages/System/StorageSystemStackTrace.h b/src/Storages/System/StorageSystemStackTrace.h
index 18216cea1bd3..ce1b7f8ccd2a 100644
--- a/src/Storages/System/StorageSystemStackTrace.h
+++ b/src/Storages/System/StorageSystemStackTrace.h
@@ -38,7 +38,7 @@ class StorageSystemStackTrace final : public IStorage
     bool isSystemStorage() const override { return true; }
 
 protected:
-    Poco::Logger * log;
+    LoggerPtr log;
 };
 
 }
diff --git a/src/Storages/UVLoop.h b/src/Storages/UVLoop.h
index 4945e1b56fac..dd1d64973d12 100644
--- a/src/Storages/UVLoop.h
+++ b/src/Storages/UVLoop.h
@@ -63,7 +63,7 @@ class UVLoop : public boost::noncopyable
 
 private:
     std::unique_ptr<uv_loop_t> loop_ptr;
-    Poco::Logger * log = &Poco::Logger::get("UVLoop");
+    LoggerPtr log = getLogger("UVLoop");
 
     static void onUVWalkClosingCallback(uv_handle_t * handle, void *)
     {
diff --git a/src/Storages/WindowView/StorageWindowView.cpp b/src/Storages/WindowView/StorageWindowView.cpp
index f9ba8e9717f9..0764685cb07a 100644
--- a/src/Storages/WindowView/StorageWindowView.cpp
+++ b/src/Storages/WindowView/StorageWindowView.cpp
@@ -1160,7 +1160,7 @@ StorageWindowView::StorageWindowView(
     bool attach_)
     : IStorage(table_id_)
     , WithContext(context_->getGlobalContext())
-    , log(&Poco::Logger::get(fmt::format("StorageWindowView({}.{})", table_id_.database_name, table_id_.table_name)))
+    , log(getLogger(fmt::format("StorageWindowView({}.{})", table_id_.database_name, table_id_.table_name)))
     , fire_signal_timeout_s(context_->getSettingsRef().wait_for_window_view_fire_signal_timeout.totalSeconds())
     , clean_interval_usec(context_->getSettingsRef().window_view_clean_interval.totalMicroseconds())
 {
diff --git a/src/Storages/WindowView/StorageWindowView.h b/src/Storages/WindowView/StorageWindowView.h
index de8f880c6022..969fda8f78e2 100644
--- a/src/Storages/WindowView/StorageWindowView.h
+++ b/src/Storages/WindowView/StorageWindowView.h
@@ -177,7 +177,7 @@ class StorageWindowView final : public IStorage, WithContext
     const Block & getOutputHeader() const;
 
 private:
-    Poco::Logger * log;
+    LoggerPtr log;
 
     /// Stored query, e.g. SELECT * FROM * GROUP BY tumble(now(), *)
     ASTPtr select_query;
diff --git a/src/TableFunctions/Hive/TableFunctionHive.cpp b/src/TableFunctions/Hive/TableFunctionHive.cpp
index d88850875324..e840d5fc8bee 100644
--- a/src/TableFunctions/Hive/TableFunctionHive.cpp
+++ b/src/TableFunctions/Hive/TableFunctionHive.cpp
@@ -46,7 +46,7 @@ class TableFunctionHive : public ITableFunction
     void parseArguments(const ASTPtr & ast_function_, ContextPtr context_) override;
 
 private:
-    Poco::Logger * logger = &Poco::Logger::get("TableFunctionHive");
+    LoggerPtr logger = getLogger("TableFunctionHive");
 
     String cluster_name;
     String hive_metastore_url;
