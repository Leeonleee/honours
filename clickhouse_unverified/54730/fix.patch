diff --git a/src/Client/ClientBase.cpp b/src/Client/ClientBase.cpp
index 30ffffdeeb1e..9e368c9c3d15 100644
--- a/src/Client/ClientBase.cpp
+++ b/src/Client/ClientBase.cpp
@@ -106,6 +106,7 @@ namespace ErrorCodes
     extern const int CANNOT_OPEN_FILE;
     extern const int FILE_ALREADY_EXISTS;
     extern const int USER_SESSION_LIMIT_EXCEEDED;
+    extern const int NOT_IMPLEMENTED;
 }
 
 }
@@ -1384,7 +1385,7 @@ void ClientBase::processInsertQuery(const String & query_to_execute, ASTPtr pars
     }
 
     /// Process the query that requires transferring data blocks to the server.
-    const auto parsed_insert_query = parsed_query->as<ASTInsertQuery &>();
+    const auto & parsed_insert_query = parsed_query->as<ASTInsertQuery &>();
     if ((!parsed_insert_query.data && !parsed_insert_query.infile) && (is_interactive || (!stdin_is_a_tty && std_in.eof())))
     {
         const auto & settings = global_context->getSettingsRef();
@@ -1830,10 +1831,20 @@ void ClientBase::processParsedSingleQuery(const String & full_query, const Strin
         if (insert && insert->select)
             insert->tryFindInputFunction(input_function);
 
-        bool is_async_insert = global_context->getSettingsRef().async_insert && insert && insert->hasInlinedData();
+        bool is_async_insert_with_inlined_data = global_context->getSettingsRef().async_insert && insert && insert->hasInlinedData();
+
+        if (is_async_insert_with_inlined_data)
+        {
+            bool have_data_in_stdin = !is_interactive && !stdin_is_a_tty && !std_in.eof();
+            bool have_external_data = have_data_in_stdin || insert->infile;
+
+            if (have_external_data)
+                throw Exception(ErrorCodes::NOT_IMPLEMENTED,
+                    "Processing async inserts with both inlined and external data (from stdin or infile) is not supported");
+        }
 
         /// INSERT query for which data transfer is needed (not an INSERT SELECT or input()) is processed separately.
-        if (insert && (!insert->select || input_function) && !insert->watch && !is_async_insert)
+        if (insert && (!insert->select || input_function) && !insert->watch && !is_async_insert_with_inlined_data)
         {
             if (input_function && insert->format.empty())
                 throw Exception(ErrorCodes::INVALID_USAGE_OF_INPUT, "FORMAT must be specified for function input()");
diff --git a/src/Client/LocalConnection.cpp b/src/Client/LocalConnection.cpp
index c05f039ffb61..15ba1bcd1991 100644
--- a/src/Client/LocalConnection.cpp
+++ b/src/Client/LocalConnection.cpp
@@ -125,7 +125,7 @@ void LocalConnection::sendQuery(
 
     try
     {
-        state->io = executeQuery(state->query, query_context, false, state->stage);
+        state->io = executeQuery(state->query, query_context, false, state->stage).second;
 
         if (state->io.pipeline.pushing())
         {
diff --git a/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp b/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp
index 7409e80ac8cd..3d10e66e9645 100644
--- a/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp
+++ b/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp
@@ -75,7 +75,7 @@ static BlockIO tryToExecuteQuery(const String & query_to_execute, ContextMutable
         if (!database.empty())
             query_context->setCurrentDatabase(database);
 
-        return executeQuery("/*" + comment + "*/ " + query_to_execute, query_context, true);
+        return executeQuery("/*" + comment + "*/ " + query_to_execute, query_context, true).second;
     }
     catch (...)
     {
diff --git a/src/Dictionaries/ClickHouseDictionarySource.cpp b/src/Dictionaries/ClickHouseDictionarySource.cpp
index 2dc7f6145b31..92fae2bc4959 100644
--- a/src/Dictionaries/ClickHouseDictionarySource.cpp
+++ b/src/Dictionaries/ClickHouseDictionarySource.cpp
@@ -168,8 +168,7 @@ QueryPipeline ClickHouseDictionarySource::createStreamForQuery(const String & qu
 
     if (configuration.is_local)
     {
-        pipeline = executeQuery(query, context_copy, true).pipeline;
-
+        pipeline = executeQuery(query, context_copy, true).second.pipeline;
         pipeline.convertStructureTo(empty_sample_block.getColumnsWithTypeAndName());
     }
     else
@@ -191,7 +190,7 @@ std::string ClickHouseDictionarySource::doInvalidateQuery(const std::string & re
 
     if (configuration.is_local)
     {
-        return readInvalidateQuery(executeQuery(request, context_copy, true).pipeline);
+        return readInvalidateQuery(executeQuery(request, context_copy, true).second.pipeline);
     }
     else
     {
diff --git a/src/Interpreters/Access/InterpreterShowAccessEntitiesQuery.cpp b/src/Interpreters/Access/InterpreterShowAccessEntitiesQuery.cpp
index e7b9237b680f..b0937dc2f668 100644
--- a/src/Interpreters/Access/InterpreterShowAccessEntitiesQuery.cpp
+++ b/src/Interpreters/Access/InterpreterShowAccessEntitiesQuery.cpp
@@ -23,7 +23,7 @@ InterpreterShowAccessEntitiesQuery::InterpreterShowAccessEntitiesQuery(const AST
 
 BlockIO InterpreterShowAccessEntitiesQuery::execute()
 {
-    return executeQuery(getRewrittenQuery(), getContext(), true);
+    return executeQuery(getRewrittenQuery(), getContext(), true).second;
 }
 
 
diff --git a/src/Interpreters/Access/InterpreterShowPrivilegesQuery.cpp b/src/Interpreters/Access/InterpreterShowPrivilegesQuery.cpp
index 05aa74d7dc43..213e3c813faa 100644
--- a/src/Interpreters/Access/InterpreterShowPrivilegesQuery.cpp
+++ b/src/Interpreters/Access/InterpreterShowPrivilegesQuery.cpp
@@ -12,7 +12,7 @@ InterpreterShowPrivilegesQuery::InterpreterShowPrivilegesQuery(const ASTPtr & qu
 
 BlockIO InterpreterShowPrivilegesQuery::execute()
 {
-    return executeQuery("SELECT * FROM system.privileges", context, true);
+    return executeQuery("SELECT * FROM system.privileges", context, true).second;
 }
 
 }
diff --git a/src/Interpreters/AsynchronousInsertLog.cpp b/src/Interpreters/AsynchronousInsertLog.cpp
index d7c9059d9de8..092862bb2b11 100644
--- a/src/Interpreters/AsynchronousInsertLog.cpp
+++ b/src/Interpreters/AsynchronousInsertLog.cpp
@@ -24,6 +24,13 @@ NamesAndTypesList AsynchronousInsertLogElement::getNamesAndTypes()
             {"FlushError",   static_cast<Int8>(Status::FlushError)},
         });
 
+    auto type_data_kind = std::make_shared<DataTypeEnum8>(
+        DataTypeEnum8::Values
+        {
+            {"Parsed",       static_cast<Int8>(DataKind::Parsed)},
+            {"Preprocessed", static_cast<Int8>(DataKind::Preprocessed)},
+        });
+
     return
     {
         {"event_date", std::make_shared<DataTypeDate>()},
@@ -39,6 +46,7 @@ NamesAndTypesList AsynchronousInsertLogElement::getNamesAndTypes()
         {"rows", std::make_shared<DataTypeUInt64>()},
         {"exception", std::make_shared<DataTypeString>()},
         {"status", type_status},
+        {"data_kind", type_data_kind},
 
         {"flush_time", std::make_shared<DataTypeDateTime>()},
         {"flush_time_microseconds", std::make_shared<DataTypeDateTime64>(6)},
@@ -64,6 +72,7 @@ void AsynchronousInsertLogElement::appendToBlock(MutableColumns & columns) const
     columns[i++]->insert(rows);
     columns[i++]->insert(exception);
     columns[i++]->insert(status);
+    columns[i++]->insert(data_kind);
 
     columns[i++]->insert(flush_time);
     columns[i++]->insert(flush_time_microseconds);
diff --git a/src/Interpreters/AsynchronousInsertLog.h b/src/Interpreters/AsynchronousInsertLog.h
index a76db78d3eaa..3a93b29dabe5 100644
--- a/src/Interpreters/AsynchronousInsertLog.h
+++ b/src/Interpreters/AsynchronousInsertLog.h
@@ -1,6 +1,6 @@
 #pragma once
 
-#include "Common/Exception.h"
+#include <Interpreters/AsynchronousInsertQueue.h>
 #include <Interpreters/SystemLog.h>
 #include <Core/NamesAndTypes.h>
 #include <Core/NamesAndAliases.h>
@@ -31,6 +31,9 @@ struct AsynchronousInsertLogElement
     String exception;
     Status status{};
 
+    using DataKind = AsynchronousInsertQueue::DataKind;
+    DataKind data_kind{};
+
     time_t flush_time{};
     Decimal64 flush_time_microseconds{};
     String flush_query_id;
diff --git a/src/Interpreters/AsynchronousInsertQueue.cpp b/src/Interpreters/AsynchronousInsertQueue.cpp
index a343fae6251e..70ce2df813c9 100644
--- a/src/Interpreters/AsynchronousInsertQueue.cpp
+++ b/src/Interpreters/AsynchronousInsertQueue.cpp
@@ -58,47 +58,33 @@ namespace ErrorCodes
     extern const int UNKNOWN_EXCEPTION;
     extern const int UNKNOWN_FORMAT;
     extern const int BAD_ARGUMENTS;
+    extern const int LOGICAL_ERROR;
 }
 
-AsynchronousInsertQueue::InsertQuery::InsertQuery(const ASTPtr & query_, const Settings & settings_, const std::optional<UUID> & user_id_, const std::vector<UUID> & current_roles_)
+static const NameSet settings_to_skip
+{
+    /// We don't consider this setting because it is only for deduplication,
+    /// which means we can put two inserts with different tokens in the same block safely.
+    "insert_deduplication_token",
+    "log_comment",
+};
+
+AsynchronousInsertQueue::InsertQuery::InsertQuery(
+    const ASTPtr & query_,
+    const std::optional<UUID> & user_id_,
+    const std::vector<UUID> & current_roles_,
+    const Settings & settings_,
+    DataKind data_kind_)
     : query(query_->clone())
     , query_str(queryToString(query))
-    , settings(settings_)
     , user_id(user_id_)
     , current_roles(current_roles_)
-    , hash(calculateHash())
-{
-}
-
-AsynchronousInsertQueue::InsertQuery::InsertQuery(const InsertQuery & other)
-    : query(other.query->clone())
-    , query_str(other.query_str)
-    , settings(other.settings)
-    , user_id(other.user_id)
-    , current_roles(other.current_roles)
-    , hash(other.hash)
-{
-}
-
-AsynchronousInsertQueue::InsertQuery &
-AsynchronousInsertQueue::InsertQuery::operator=(const InsertQuery & other)
-{
-    if (this != &other)
-    {
-        query = other.query->clone();
-        query_str = other.query_str;
-        user_id = other.user_id;
-        current_roles = other.current_roles;
-        settings = other.settings;
-        hash = other.hash;
-    }
-
-    return *this;
-}
-
-UInt128 AsynchronousInsertQueue::InsertQuery::calculateHash() const
+    , settings(settings_)
+    , data_kind(data_kind_)
 {
     SipHash siphash;
+
+    siphash.update(data_kind);
     query->updateTreeHash(siphash);
 
     if (user_id)
@@ -110,26 +96,50 @@ UInt128 AsynchronousInsertQueue::InsertQuery::calculateHash() const
 
     for (const auto & setting : settings.allChanged())
     {
-        /// We don't consider this setting because it is only for deduplication,
-        /// which means we can put two inserts with different tokens in the same block safely.
-        if (setting.getName() == "insert_deduplication_token")
+        if (settings_to_skip.contains(setting.getName()))
             continue;
+
+        setting_changes.emplace_back(setting.getName(), setting.getValue());
         siphash.update(setting.getName());
         applyVisitor(FieldVisitorHash(siphash), setting.getValue());
     }
 
-    return siphash.get128();
+    hash = siphash.get128();
+}
+
+AsynchronousInsertQueue::InsertQuery &
+AsynchronousInsertQueue::InsertQuery::operator=(const InsertQuery & other)
+{
+    if (this != &other)
+    {
+        query = other.query->clone();
+        query_str = other.query_str;
+        user_id = other.user_id;
+        current_roles = other.current_roles;
+        settings = other.settings;
+        data_kind = other.data_kind;
+        hash = other.hash;
+        setting_changes = other.setting_changes;
+    }
+
+    return *this;
 }
 
 bool AsynchronousInsertQueue::InsertQuery::operator==(const InsertQuery & other) const
 {
-    return query_str == other.query_str && user_id == other.user_id && current_roles == other.current_roles && settings == other.settings;
+    return toTupleCmp() == other.toTupleCmp();
 }
 
-AsynchronousInsertQueue::InsertData::Entry::Entry(String && bytes_, String && query_id_, const String & async_dedup_token_, MemoryTracker * user_memory_tracker_)
-    : bytes(std::move(bytes_))
+AsynchronousInsertQueue::InsertData::Entry::Entry(
+    DataChunk && chunk_,
+    String && query_id_,
+    const String & async_dedup_token_,
+    const String & format_,
+    MemoryTracker * user_memory_tracker_)
+    : chunk(std::move(chunk_))
     , query_id(std::move(query_id_))
     , async_dedup_token(async_dedup_token_)
+    , format(format_)
     , user_memory_tracker(user_memory_tracker_)
     , create_time(std::chrono::system_clock::now())
 {
@@ -146,7 +156,7 @@ void AsynchronousInsertQueue::InsertData::Entry::finish(std::exception_ptr excep
         // Each entry in the list may correspond to a different user,
         // so we need to switch current thread's MemoryTracker.
         MemoryTrackerSwitcher switcher(user_memory_tracker);
-        bytes = "";
+        chunk = {};
     }
 
     if (exception_)
@@ -216,15 +226,12 @@ void AsynchronousInsertQueue::scheduleDataProcessingJob(const InsertQuery & key,
     });
 }
 
-AsynchronousInsertQueue::PushResult
-AsynchronousInsertQueue::push(ASTPtr query, ContextPtr query_context)
+void AsynchronousInsertQueue::preprocessInsertQuery(const ASTPtr & query, const ContextPtr & query_context)
 {
-    query = query->clone();
-    const auto & settings = query_context->getSettingsRef();
     auto & insert_query = query->as<ASTInsertQuery &>();
     insert_query.async_insert_flush = true;
 
-    InterpreterInsertQuery interpreter(query, query_context, settings.insert_allow_materialized_columns);
+    InterpreterInsertQuery interpreter(query, query_context, query_context->getSettingsRef().insert_allow_materialized_columns);
     auto table = interpreter.getTable(insert_query);
     auto sample_block = interpreter.getSampleBlock(insert_query, table, table->getInMemoryMetadataPtr());
 
@@ -235,6 +242,13 @@ AsynchronousInsertQueue::push(ASTPtr query, ContextPtr query_context)
     /// InterpreterInsertQuery::getTable() -> ITableFunction::execute().
     if (insert_query.table_id)
         query_context->checkAccess(AccessType::INSERT, insert_query.table_id, sample_block.getNames());
+}
+
+AsynchronousInsertQueue::PushResult
+AsynchronousInsertQueue::pushQueryWithInlinedData(ASTPtr query, ContextPtr query_context)
+{
+    query = query->clone();
+    preprocessInsertQuery(query, query_context);
 
     String bytes;
     {
@@ -245,7 +259,7 @@ AsynchronousInsertQueue::push(ASTPtr query, ContextPtr query_context)
         auto read_buf = getReadBufferFromASTInsertQuery(query);
 
         LimitReadBuffer limit_buf(
-            *read_buf, settings.async_insert_max_data_size,
+            *read_buf, query_context->getSettingsRef().async_insert_max_data_size,
             /*throw_exception=*/ false, /*exact_limit=*/ {});
 
         WriteBufferFromString write_buf(bytes);
@@ -270,9 +284,35 @@ AsynchronousInsertQueue::push(ASTPtr query, ContextPtr query_context)
         }
     }
 
-    auto entry = std::make_shared<InsertData::Entry>(std::move(bytes), query_context->getCurrentQueryId(), settings.insert_deduplication_token, CurrentThread::getUserMemoryTracker());
+    return pushDataChunk(std::move(query), std::move(bytes), std::move(query_context));
+}
+
+AsynchronousInsertQueue::PushResult
+AsynchronousInsertQueue::pushQueryWithBlock(ASTPtr query, Block block, ContextPtr query_context)
+{
+    query = query->clone();
+    preprocessInsertQuery(query, query_context);
+    return pushDataChunk(std::move(query), std::move(block), std::move(query_context));
+}
+
+AsynchronousInsertQueue::PushResult
+AsynchronousInsertQueue::pushDataChunk(ASTPtr query, DataChunk chunk, ContextPtr query_context)
+{
+    const auto & settings = query_context->getSettingsRef();
+    auto & insert_query = query->as<ASTInsertQuery &>();
+
+    auto data_kind = chunk.getDataKind();
+    auto entry = std::make_shared<InsertData::Entry>(
+        std::move(chunk), query_context->getCurrentQueryId(),
+        settings.insert_deduplication_token, insert_query.format,
+        CurrentThread::getUserMemoryTracker());
 
-    InsertQuery key{query, settings, query_context->getUserID(), query_context->getCurrentRoles()};
+    /// If data is parsed on client we don't care of format which is written
+    /// in INSERT query. Replace it to put all such queries into one bucket in queue.
+    if (data_kind == DataKind::Preprocessed)
+        insert_query.format = "Native";
+
+    InsertQuery key{query, query_context->getUserID(), query_context->getCurrentRoles(), settings, data_kind};
     InsertDataPtr data_to_process;
     std::future<void> insert_future;
 
@@ -292,7 +332,7 @@ AsynchronousInsertQueue::push(ASTPtr query, ContextPtr query_context)
 
         auto queue_it = it->second;
         auto & data = queue_it->second.data;
-        size_t entry_data_size = entry->bytes.size();
+        size_t entry_data_size = entry->chunk.byteSize();
 
         assert(data);
         data->size_in_bytes += entry_data_size;
@@ -456,6 +496,13 @@ catch (...)
     tryLogCurrentException("AsynchronousInsertQueue", "Failed to add elements to AsynchronousInsertLog");
 }
 
+String serializeQuery(const IAST & query, size_t max_length)
+{
+    return query.hasSecretParts()
+        ? query.formatForLogging(max_length)
+        : wipeSensitiveDataAndCutToLength(serializeAST(query), max_length);
+}
+
 }
 
 // static
@@ -469,6 +516,7 @@ try
 
     const auto * log = &Poco::Logger::get("AsynchronousInsertQueue");
     const auto & insert_query = assert_cast<const ASTInsertQuery &>(*key.query);
+
     auto insert_context = Context::createCopy(global_context);
     bool internal = false; // To enable logging this query
     bool async_insert = true;
@@ -478,6 +526,10 @@ try
 
     /// 'resetParser' doesn't work for parallel parsing.
     key.settings.set("input_format_parallel_parsing", false);
+    /// It maybe insert into distributed table.
+    /// It doesn't make sense to make insert into destination tables asynchronous.
+    key.settings.set("async_insert", false);
+
     insert_context->makeQueryContext();
 
     /// Access rights must be checked for the user who executed the initial INSERT query.
@@ -491,6 +543,7 @@ try
 
     auto insert_query_id = insert_context->getCurrentQueryId();
     auto query_start_time = std::chrono::system_clock::now();
+
     Stopwatch start_watch{CLOCK_MONOTONIC};
     insert_context->setQueryKind(ClientInfo::QueryKind::INITIAL_QUERY);
     insert_context->setInitialQueryStartTime(query_start_time);
@@ -499,36 +552,45 @@ try
 
     DB::CurrentThread::QueryScope query_scope_holder(insert_context);
 
-    size_t log_queries_cut_to_length = insert_context->getSettingsRef().log_queries_cut_to_length;
-    String query_for_logging = insert_query.hasSecretParts()
-        ? insert_query.formatForLogging(log_queries_cut_to_length)
-        : wipeSensitiveDataAndCutToLength(serializeAST(insert_query), log_queries_cut_to_length);
+    auto query_for_logging = serializeQuery(*key.query, insert_context->getSettingsRef().log_queries_cut_to_length);
 
     /// We add it to the process list so
     /// a) it appears in system.processes
     /// b) can be cancelled if we want to
     /// c) has an associated process list element where runtime metrics are stored
-    auto process_list_entry
-        = insert_context->getProcessList().insert(query_for_logging, key.query.get(), insert_context, start_watch.getStart());
+    auto process_list_entry = insert_context->getProcessList().insert(
+        query_for_logging,
+        key.query.get(),
+        insert_context,
+        start_watch.getStart());
+
     auto query_status = process_list_entry->getQueryStatus();
     insert_context->setProcessListElement(std::move(query_status));
 
-    String query_database{};
-    String query_table{};
+    String query_database;
+    String query_table;
+
     if (insert_query.table_id)
     {
         query_database = insert_query.table_id.getDatabaseName();
         query_table = insert_query.table_id.getTableName();
         insert_context->setInsertionTable(insert_query.table_id);
     }
+
     std::unique_ptr<DB::IInterpreter> interpreter;
     QueryPipeline pipeline;
     QueryLogElement query_log_elem;
 
+    auto async_insert_log = global_context->getAsynchronousInsertLog();
+    std::vector<AsynchronousInsertLogElement> log_elements;
+    if (async_insert_log)
+        log_elements.reserve(data->entries.size());
+
     try
     {
         interpreter = std::make_unique<InterpreterInsertQuery>(
             key.query, insert_context, key.settings.insert_allow_materialized_columns, false, false, true);
+
         pipeline = interpreter->execute().pipeline;
         chassert(pipeline.pushing());
 
@@ -550,92 +612,39 @@ try
         throw;
     }
 
-    auto header = pipeline.getHeader();
-    auto format = getInputFormatFromASTInsertQuery(key.query, false, header, insert_context, nullptr);
-
-    size_t total_rows = 0;
-    InsertData::EntryPtr current_entry;
-    String current_exception;
-
-    auto on_error = [&](const MutableColumns & result_columns, Exception & e)
+    auto add_entry_to_log = [&](
+        const auto & entry, const auto & entry_query_for_logging,
+        const auto & exception, size_t num_rows, size_t num_bytes)
     {
-        current_exception = e.displayText();
-        LOG_ERROR(log, "Failed parsing for query '{}' with query id {}. {}",
-            key.query_str, current_entry->query_id, current_exception);
-
-        for (const auto & column : result_columns)
-            if (column->size() > total_rows)
-                column->popBack(column->size() - total_rows);
-
-        current_entry->finish(std::current_exception());
-        return 0;
-    };
-
-    std::shared_ptr<ISimpleTransform> adding_defaults_transform;
-    if (insert_context->getSettingsRef().input_format_defaults_for_omitted_fields && insert_query.table_id)
-    {
-        StoragePtr storage = DatabaseCatalog::instance().getTable(insert_query.table_id, insert_context);
-        auto metadata_snapshot = storage->getInMemoryMetadataPtr();
-        const auto & columns = metadata_snapshot->getColumns();
-        if (columns.hasDefaults())
-            adding_defaults_transform = std::make_shared<AddingDefaultsTransform>(header, columns, *format, insert_context);
-    }
-
-    auto insert_log = global_context->getAsynchronousInsertLog();
-    std::vector<AsynchronousInsertLogElement> log_elements;
-
-    if (insert_log)
-        log_elements.reserve(data->entries.size());
-
-    StreamingFormatExecutor executor(header, format, std::move(on_error), std::move(adding_defaults_transform));
-    std::unique_ptr<ReadBuffer> last_buffer;
-    auto chunk_info = std::make_shared<AsyncInsertInfo>();
-    for (const auto & entry : data->entries)
-    {
-        auto buffer = std::make_unique<ReadBufferFromString>(entry->bytes);
-        current_entry = entry;
-        auto bytes_size = entry->bytes.size();
-        size_t num_rows = executor.execute(*buffer);
-        total_rows += num_rows;
-        chunk_info->offsets.push_back(total_rows);
-        chunk_info->tokens.push_back(entry->async_dedup_token);
-
-        /// Keep buffer, because it still can be used
-        /// in destructor, while resetting buffer at next iteration.
-        last_buffer = std::move(buffer);
-
-        if (insert_log)
+        if (!async_insert_log)
+            return;
+
+        AsynchronousInsertLogElement elem;
+        elem.event_time = timeInSeconds(entry->create_time);
+        elem.event_time_microseconds = timeInMicroseconds(entry->create_time);
+        elem.query_for_logging = entry_query_for_logging;
+        elem.database = query_database;
+        elem.table = query_table;
+        elem.format = entry->format;
+        elem.query_id = entry->query_id;
+        elem.bytes = num_bytes;
+        elem.rows = num_rows;
+        elem.exception = exception;
+        elem.data_kind = entry->chunk.getDataKind();
+
+        /// If there was a parsing error,
+        /// the entry won't be flushed anyway,
+        /// so add the log element immediately.
+        if (!elem.exception.empty())
         {
-            AsynchronousInsertLogElement elem;
-            elem.event_time = timeInSeconds(entry->create_time);
-            elem.event_time_microseconds = timeInMicroseconds(entry->create_time);
-            elem.query_for_logging = query_for_logging;
-            elem.database = query_database;
-            elem.table = query_table;
-            elem.format = insert_query.format;
-            elem.query_id = entry->query_id;
-            elem.bytes = bytes_size;
-            elem.rows = num_rows;
-            elem.exception = current_exception;
-            current_exception.clear();
-
-            /// If there was a parsing error,
-            /// the entry won't be flushed anyway,
-            /// so add the log element immediately.
-            if (!elem.exception.empty())
-            {
-                elem.status = AsynchronousInsertLogElement::ParsingError;
-                insert_log->add(std::move(elem));
-            }
-            else
-            {
-                log_elements.push_back(elem);
-            }
+            elem.status = AsynchronousInsertLogElement::ParsingError;
+            async_insert_log->add(std::move(elem));
         }
-    }
-
-    format->addBuffer(std::move(last_buffer));
-    ProfileEvents::increment(ProfileEvents::AsyncInsertRows, total_rows);
+        else
+        {
+            log_elements.push_back(elem);
+        }
+    };
 
     auto finish_entries = [&]
     {
@@ -648,11 +657,21 @@ try
         if (!log_elements.empty())
         {
             auto flush_time = std::chrono::system_clock::now();
-            appendElementsToLogSafe(*insert_log, std::move(log_elements), flush_time, insert_query_id, "");
+            appendElementsToLogSafe(*async_insert_log, std::move(log_elements), flush_time, insert_query_id, "");
         }
     };
 
-    if (total_rows == 0)
+    Chunk chunk;
+    auto header = pipeline.getHeader();
+
+    if (key.data_kind == DataKind::Parsed)
+        chunk = processEntriesWithParsing(key, data->entries, header, insert_context, log, add_entry_to_log);
+    else
+        chunk = processPreprocessedEntries(key, data->entries, header, insert_context, add_entry_to_log);
+
+    ProfileEvents::increment(ProfileEvents::AsyncInsertRows, chunk.getNumRows());
+
+    if (chunk.getNumRows() == 0)
     {
         finish_entries();
         return;
@@ -660,9 +679,8 @@ try
 
     try
     {
-        auto chunk = Chunk(executor.getResultColumns(), total_rows);
-        chunk.setChunkInfo(std::move(chunk_info));
-        size_t total_bytes = chunk.bytes();
+        size_t num_rows = chunk.getNumRows();
+        size_t num_bytes = chunk.bytes();
 
         auto source = std::make_shared<SourceFromSingleChunk>(header, std::move(chunk));
         pipeline.complete(Pipe(std::move(source)));
@@ -670,8 +688,7 @@ try
         CompletedPipelineExecutor completed_executor(pipeline);
         completed_executor.execute();
 
-        LOG_INFO(log, "Flushed {} rows, {} bytes for query '{}'",
-            total_rows, total_bytes, key.query_str);
+        LOG_INFO(log, "Flushed {} rows, {} bytes for query '{}'", num_rows, num_bytes, key.query_str);
 
         bool pulling_pipeline = false;
         logQueryFinish(query_log_elem, insert_context, key.query, pipeline, pulling_pipeline, query_span, QueryCache::Usage::None, internal);
@@ -684,7 +701,7 @@ try
         {
             auto exception = getCurrentExceptionMessage(false);
             auto flush_time = std::chrono::system_clock::now();
-            appendElementsToLogSafe(*insert_log, std::move(log_elements), flush_time, insert_query_id, exception);
+            appendElementsToLogSafe(*async_insert_log, std::move(log_elements), flush_time, insert_query_id, exception);
         }
         throw;
     }
@@ -708,6 +725,133 @@ catch (...)
     finishWithException(key.query, data->entries, Exception(ErrorCodes::UNKNOWN_EXCEPTION, "Unknown exception"));
 }
 
+template <typename LogFunc>
+Chunk AsynchronousInsertQueue::processEntriesWithParsing(
+    const InsertQuery & key,
+    const std::list<InsertData::EntryPtr> & entries,
+    const Block & header,
+    const ContextPtr & insert_context,
+    const Poco::Logger * logger,
+    LogFunc && add_to_async_insert_log)
+{
+    size_t total_rows = 0;
+    InsertData::EntryPtr current_entry;
+    String current_exception;
+
+    const auto & insert_query = assert_cast<const ASTInsertQuery &>(*key.query);
+    auto format = getInputFormatFromASTInsertQuery(key.query, false, header, insert_context, nullptr);
+    std::shared_ptr<ISimpleTransform> adding_defaults_transform;
+
+    if (insert_context->getSettingsRef().input_format_defaults_for_omitted_fields && insert_query.table_id)
+    {
+        StoragePtr storage = DatabaseCatalog::instance().getTable(insert_query.table_id, insert_context);
+        auto metadata_snapshot = storage->getInMemoryMetadataPtr();
+        const auto & columns = metadata_snapshot->getColumns();
+        if (columns.hasDefaults())
+            adding_defaults_transform = std::make_shared<AddingDefaultsTransform>(header, columns, *format, insert_context);
+    }
+
+    auto on_error = [&](const MutableColumns & result_columns, Exception & e)
+    {
+        current_exception = e.displayText();
+        LOG_ERROR(logger, "Failed parsing for query '{}' with query id {}. {}",
+            key.query_str, current_entry->query_id, current_exception);
+
+        for (const auto & column : result_columns)
+            if (column->size() > total_rows)
+                column->popBack(column->size() - total_rows);
+
+        current_entry->finish(std::current_exception());
+        return 0;
+    };
+
+    StreamingFormatExecutor executor(header, format, std::move(on_error), std::move(adding_defaults_transform));
+    std::unique_ptr<ReadBuffer> last_buffer;
+    auto chunk_info = std::make_shared<AsyncInsertInfo>();
+    auto query_for_logging = serializeQuery(*key.query, insert_context->getSettingsRef().log_queries_cut_to_length);
+
+    for (const auto & entry : entries)
+    {
+        current_entry = entry;
+
+        const auto * bytes = entry->chunk.asString();
+        if (!bytes)
+            throw Exception(ErrorCodes::LOGICAL_ERROR,
+                "Expected entry with data kind Parsed. Got: {}", entry->chunk.getDataKind());
+
+        auto buffer = std::make_unique<ReadBufferFromString>(*bytes);
+        size_t num_bytes = bytes->size();
+        size_t num_rows = executor.execute(*buffer);
+
+        /// Keep buffer, because it still can be used
+        /// in destructor, while resetting buffer at next iteration.
+        last_buffer = std::move(buffer);
+
+        total_rows += num_rows;
+        chunk_info->offsets.push_back(total_rows);
+        chunk_info->tokens.push_back(entry->async_dedup_token);
+
+        add_to_async_insert_log(entry, query_for_logging, current_exception, num_rows, num_bytes);
+        current_exception.clear();
+    }
+
+    format->addBuffer(std::move(last_buffer));
+
+    Chunk chunk(executor.getResultColumns(), total_rows);
+    chunk.setChunkInfo(std::move(chunk_info));
+    return chunk;
+}
+
+template <typename LogFunc>
+Chunk AsynchronousInsertQueue::processPreprocessedEntries(
+    const InsertQuery & key,
+    const std::list<InsertData::EntryPtr> & entries,
+    const Block & header,
+    const ContextPtr & insert_context,
+    LogFunc && add_to_async_insert_log)
+{
+    size_t total_rows = 0;
+    auto chunk_info = std::make_shared<AsyncInsertInfo>();
+    auto result_columns = header.cloneEmptyColumns();
+
+    std::unordered_map<String, String> format_to_query;
+
+    auto get_query_by_format = [&](const String & format) -> const String &
+    {
+        auto [it, inserted] = format_to_query.try_emplace(format);
+        if (!inserted)
+            return it->second;
+
+        auto query = key.query->clone();
+        assert_cast<ASTInsertQuery &>(*query).format = format;
+        it->second = serializeQuery(*query, insert_context->getSettingsRef().log_queries_cut_to_length);
+        return it->second;
+    };
+
+    for (const auto & entry : entries)
+    {
+        const auto * block = entry->chunk.asBlock();
+        if (!block)
+            throw Exception(ErrorCodes::LOGICAL_ERROR,
+                "Expected entry with data kind Preprocessed. Got: {}", entry->chunk.getDataKind());
+
+        auto columns = block->getColumns();
+        for (size_t i = 0, s = columns.size(); i < s; ++i)
+            result_columns[i]->insertRangeFrom(*columns[i], 0, columns[i]->size());
+
+        total_rows += block->rows();
+        chunk_info->offsets.push_back(total_rows);
+        chunk_info->tokens.push_back(entry->async_dedup_token);
+
+        const auto & query_for_logging = get_query_by_format(entry->format);
+        add_to_async_insert_log(entry, query_for_logging, "", block->rows(), block->bytes());
+    }
+
+    Chunk chunk(std::move(result_columns), total_rows);
+    chunk.setChunkInfo(std::move(chunk_info));
+    return chunk;
+}
+
 template <typename E>
 void AsynchronousInsertQueue::finishWithException(
     const ASTPtr & query, const std::list<InsertData::EntryPtr> & entries, const E & exception)
diff --git a/src/Interpreters/AsynchronousInsertQueue.h b/src/Interpreters/AsynchronousInsertQueue.h
index 2b92e336d098..99394d0fb14d 100644
--- a/src/Interpreters/AsynchronousInsertQueue.h
+++ b/src/Interpreters/AsynchronousInsertQueue.h
@@ -1,13 +1,16 @@
 #pragma once
 
+#include <Core/Block.h>
 #include <Core/Settings.h>
 #include <Parsers/IAST_fwd.h>
 #include <Poco/Logger.h>
 #include <Common/CurrentThread.h>
 #include <Common/MemoryTrackerSwitcher.h>
 #include <Common/ThreadPool.h>
+#include <Processors/Chunk.h>
 
 #include <future>
+#include <variant>
 
 namespace DB
 {
@@ -38,11 +41,23 @@ class AsynchronousInsertQueue : public WithContext
         /// Read buffer that contains extracted
         /// from query data in case of too much data.
         std::unique_ptr<ReadBuffer> insert_data_buffer;
+
+        /// Block that contains received by Native
+        /// protocol data in case of too much data.
+        Block insert_block;
+    };
+
+    enum class DataKind
+    {
+        Parsed = 0,
+        Preprocessed = 1,
     };
 
     /// Force flush the whole queue.
     void flushAll();
-    PushResult push(ASTPtr query, ContextPtr query_context);
+
+    PushResult pushQueryWithInlinedData(ASTPtr query, ContextPtr query_context);
+    PushResult pushQueryWithBlock(ASTPtr query, Block block, ContextPtr query_context);
     size_t getPoolSize() const { return pool_size; }
 
 private:
@@ -52,18 +67,55 @@ class AsynchronousInsertQueue : public WithContext
     public:
         ASTPtr query;
         String query_str;
-        Settings settings;
         std::optional<UUID> user_id;
         std::vector<UUID> current_roles;
+        Settings settings;
+
+        DataKind data_kind;
         UInt128 hash;
 
-        InsertQuery(const ASTPtr & query_, const Settings & settings_, const std::optional<UUID> & user_id_, const std::vector<UUID> & current_roles_);
-        InsertQuery(const InsertQuery & other);
+        InsertQuery(
+            const ASTPtr & query_,
+            const std::optional<UUID> & user_id_,
+            const std::vector<UUID> & current_roles_,
+            const Settings & settings_,
+            DataKind data_kind_);
+
+        InsertQuery(const InsertQuery & other) { *this = other; }
         InsertQuery & operator=(const InsertQuery & other);
         bool operator==(const InsertQuery & other) const;
 
     private:
-        UInt128 calculateHash() const;
+        auto toTupleCmp() const { return std::tie(data_kind, query_str, user_id, current_roles, setting_changes); }
+
+        std::vector<SettingChange> setting_changes;
+    };
+
+    struct DataChunk : public std::variant<String, Block>
+    {
+        using std::variant<String, Block>::variant;
+
+        size_t byteSize() const
+        {
+            return std::visit([]<typename T>(const T & arg)
+            {
+                if constexpr (std::is_same_v<T, Block>)
+                    return arg.bytes();
+                else
+                    return arg.size();
+            }, *this);
+        }
+
+        DataKind getDataKind() const
+        {
+            if (std::holds_alternative<Block>(*this))
+                return DataKind::Preprocessed;
+            else
+                return DataKind::Parsed;
+        }
+
+        const String * asString() const { return std::get_if<String>(this); }
+        const Block * asBlock() const { return std::get_if<Block>(this); }
     };
 
     struct InsertData
@@ -71,13 +123,19 @@ class AsynchronousInsertQueue : public WithContext
         struct Entry
         {
         public:
-            String bytes;
+            DataChunk chunk;
             const String query_id;
             const String async_dedup_token;
+            const String format;
             MemoryTracker * const user_memory_tracker;
             const std::chrono::time_point<std::chrono::system_clock> create_time;
 
-            Entry(String && bytes_, String && query_id_, const String & async_dedup_token, MemoryTracker * user_memory_tracker_);
+            Entry(
+                DataChunk && chunk_,
+                String && query_id_,
+                const String & async_dedup_token_,
+                const String & format_,
+                MemoryTracker * user_memory_tracker_);
 
             void finish(std::exception_ptr exception_ = nullptr);
             std::future<void> getFuture() { return promise.get_future(); }
@@ -158,11 +216,31 @@ class AsynchronousInsertQueue : public WithContext
 
     Poco::Logger * log = &Poco::Logger::get("AsynchronousInsertQueue");
 
+    PushResult pushDataChunk(ASTPtr query, DataChunk chunk, ContextPtr query_context);
+    void preprocessInsertQuery(const ASTPtr & query, const ContextPtr & query_context);
+
     void processBatchDeadlines(size_t shard_num);
     void scheduleDataProcessingJob(const InsertQuery & key, InsertDataPtr data, ContextPtr global_context);
 
     static void processData(InsertQuery key, InsertDataPtr data, ContextPtr global_context);
 
+    template <typename LogFunc>
+    static Chunk processEntriesWithParsing(
+        const InsertQuery & key,
+        const std::list<InsertData::EntryPtr> & entries,
+        const Block & header,
+        const ContextPtr & insert_context,
+        const Poco::Logger * logger,
+        LogFunc && add_to_async_insert_log);
+
+    template <typename LogFunc>
+    static Chunk processPreprocessedEntries(
+        const InsertQuery & key,
+        const std::list<InsertData::EntryPtr> & entries,
+        const Block & header,
+        const ContextPtr & insert_context,
+        LogFunc && add_to_async_insert_log);
+
     template <typename E>
     static void finishWithException(const ASTPtr & query, const std::list<InsertData::EntryPtr> & entries, const E & exception);
 
diff --git a/src/Interpreters/InterpreterKillQueryQuery.cpp b/src/Interpreters/InterpreterKillQueryQuery.cpp
index 590b7fe37b8f..1c2e3ff67772 100644
--- a/src/Interpreters/InterpreterKillQueryQuery.cpp
+++ b/src/Interpreters/InterpreterKillQueryQuery.cpp
@@ -420,7 +420,7 @@ Block InterpreterKillQueryQuery::getSelectResult(const String & columns, const S
     if (where_expression)
         select_query += " WHERE " + queryToString(where_expression);
 
-    auto io = executeQuery(select_query, getContext(), true);
+    auto io = executeQuery(select_query, getContext(), true).second;
     PullingPipelineExecutor executor(io.pipeline);
     Block res;
     while (!res && executor.pull(res));
diff --git a/src/Interpreters/InterpreterShowColumnsQuery.cpp b/src/Interpreters/InterpreterShowColumnsQuery.cpp
index e1f736ba4fb3..025499affda0 100644
--- a/src/Interpreters/InterpreterShowColumnsQuery.cpp
+++ b/src/Interpreters/InterpreterShowColumnsQuery.cpp
@@ -94,7 +94,7 @@ WHERE
 
 BlockIO InterpreterShowColumnsQuery::execute()
 {
-    return executeQuery(getRewrittenQuery(), getContext(), true);
+    return executeQuery(getRewrittenQuery(), getContext(), true).second;
 }
 
 
diff --git a/src/Interpreters/InterpreterShowEngineQuery.cpp b/src/Interpreters/InterpreterShowEngineQuery.cpp
index 8fd829f39ec9..a2367e9bfdf4 100644
--- a/src/Interpreters/InterpreterShowEngineQuery.cpp
+++ b/src/Interpreters/InterpreterShowEngineQuery.cpp
@@ -12,7 +12,7 @@ namespace DB
 
 BlockIO InterpreterShowEnginesQuery::execute()
 {
-    return executeQuery("SELECT * FROM system.table_engines ORDER BY name", getContext(), true);
+    return executeQuery("SELECT * FROM system.table_engines ORDER BY name", getContext(), true).second;
 }
 
 }
diff --git a/src/Interpreters/InterpreterShowFunctionsQuery.cpp b/src/Interpreters/InterpreterShowFunctionsQuery.cpp
index efadb929451f..ace22ca4bb60 100644
--- a/src/Interpreters/InterpreterShowFunctionsQuery.cpp
+++ b/src/Interpreters/InterpreterShowFunctionsQuery.cpp
@@ -15,7 +15,7 @@ InterpreterShowFunctionsQuery::InterpreterShowFunctionsQuery(const ASTPtr & quer
 
 BlockIO InterpreterShowFunctionsQuery::execute()
 {
-    return executeQuery(getRewrittenQuery(), getContext(), true);
+    return executeQuery(getRewrittenQuery(), getContext(), true).second;
 }
 
 String InterpreterShowFunctionsQuery::getRewrittenQuery()
diff --git a/src/Interpreters/InterpreterShowIndexesQuery.cpp b/src/Interpreters/InterpreterShowIndexesQuery.cpp
index 149420006fb7..9b36f1496e70 100644
--- a/src/Interpreters/InterpreterShowIndexesQuery.cpp
+++ b/src/Interpreters/InterpreterShowIndexesQuery.cpp
@@ -107,7 +107,7 @@ ORDER BY index_type, expression, column_name, seq_in_index;)", database, table,
 
 BlockIO InterpreterShowIndexesQuery::execute()
 {
-    return executeQuery(getRewrittenQuery(), getContext(), true);
+    return executeQuery(getRewrittenQuery(), getContext(), true).second;
 }
 
 
diff --git a/src/Interpreters/InterpreterShowProcesslistQuery.cpp b/src/Interpreters/InterpreterShowProcesslistQuery.cpp
index f9241368a8f7..4ed5f4171c69 100644
--- a/src/Interpreters/InterpreterShowProcesslistQuery.cpp
+++ b/src/Interpreters/InterpreterShowProcesslistQuery.cpp
@@ -12,7 +12,7 @@ namespace DB
 
 BlockIO InterpreterShowProcesslistQuery::execute()
 {
-    return executeQuery("SELECT * FROM system.processes ORDER BY elapsed DESC", getContext(), true);
+    return executeQuery("SELECT * FROM system.processes ORDER BY elapsed DESC", getContext(), true).second;
 }
 
 }
diff --git a/src/Interpreters/InterpreterShowTablesQuery.cpp b/src/Interpreters/InterpreterShowTablesQuery.cpp
index 5fe0a862e057..97bd8e7a8b70 100644
--- a/src/Interpreters/InterpreterShowTablesQuery.cpp
+++ b/src/Interpreters/InterpreterShowTablesQuery.cpp
@@ -188,7 +188,7 @@ BlockIO InterpreterShowTablesQuery::execute()
         return res;
     }
 
-    return executeQuery(getRewrittenQuery(), getContext(), true);
+    return executeQuery(getRewrittenQuery(), getContext(), true).second;
 }
 
 /// (*) Sorting is strictly speaking not necessary but 1. it is convenient for users, 2. SQL currently does not allow to
diff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp
index eb9c7e344a66..c41cffa3ceb9 100644
--- a/src/Interpreters/executeQuery.cpp
+++ b/src/Interpreters/executeQuery.cpp
@@ -925,12 +925,10 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
                 reason = "asynchronous insert queue is not configured";
             else if (insert_query->select)
                 reason = "insert query has select";
-            else if (!insert_query->hasInlinedData())
-                reason = "insert query doesn't have inlined data";
-            else
+            else if (insert_query->hasInlinedData())
                 async_insert = true;
 
-            if (!async_insert)
+            if (!reason.empty())
                 LOG_DEBUG(logger, "Setting async_insert=1, but INSERT query will be executed synchronously (reason: {})", reason);
         }
 
@@ -953,7 +951,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
                 quota->checkExceeded(QuotaType::ERRORS);
             }
 
-            auto result = queue->push(ast, context);
+            auto result = queue->pushQueryWithInlinedData(ast, context);
 
             if (result.status == AsynchronousInsertQueue::PushResult::OK)
             {
@@ -1223,19 +1221,20 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
         throw;
     }
 
-    return std::make_tuple(ast, std::move(res));
+    return std::make_tuple(std::move(ast), std::move(res));
 }
 
 
-BlockIO executeQuery(
+std::pair<ASTPtr, BlockIO> executeQuery(
     const String & query,
     ContextMutablePtr context,
     bool internal,
     QueryProcessingStage::Enum stage)
 {
     ASTPtr ast;
-    BlockIO streams;
-    std::tie(ast, streams) = executeQueryImpl(query.data(), query.data() + query.size(), context, internal, stage, nullptr);
+    BlockIO res;
+
+    std::tie(ast, res) = executeQueryImpl(query.data(), query.data() + query.size(), context, internal, stage, nullptr);
 
     if (const auto * ast_query_with_output = dynamic_cast<const ASTQueryWithOutput *>(ast.get()))
     {
@@ -1244,26 +1243,12 @@ BlockIO executeQuery(
                 : context->getDefaultFormat();
 
         if (format_name == "Null")
-            streams.null_format = true;
+            res.null_format = true;
     }
 
-    return streams;
+    return std::make_pair(std::move(ast), std::move(res));
 }
 
-BlockIO executeQuery(
-    bool allow_processors,
-    const String & query,
-    ContextMutablePtr context,
-    bool internal,
-    QueryProcessingStage::Enum stage)
-{
-    if (!allow_processors)
-        throw Exception(ErrorCodes::NOT_IMPLEMENTED, "Flag allow_processors is deprecated for executeQuery");
-
-    return executeQuery(query, context, internal, stage);
-}
-
-
 void executeQuery(
     ReadBuffer & istr,
     WriteBuffer & ostr,
diff --git a/src/Interpreters/executeQuery.h b/src/Interpreters/executeQuery.h
index a31d4f2f08cf..6f14f54d7d6d 100644
--- a/src/Interpreters/executeQuery.h
+++ b/src/Interpreters/executeQuery.h
@@ -43,7 +43,7 @@ void executeQuery(
 
 /// More low-level function for server-to-server interaction.
 /// Prepares a query for execution but doesn't execute it.
-/// Returns a pair of block streams which, when used, will result in query execution.
+/// Returns a pair of parsed query and BlockIO which, when used, will result in query execution.
 /// This means that the caller can to the extent control the query execution pipeline.
 ///
 /// To execute:
@@ -55,22 +55,13 @@ void executeQuery(
 ///
 /// Correctly formatting the results (according to INTO OUTFILE and FORMAT sections)
 /// must be done separately.
-BlockIO executeQuery(
+std::pair<ASTPtr, BlockIO> executeQuery(
     const String & query,     /// Query text without INSERT data. The latter must be written to BlockIO::out.
     ContextMutablePtr context,       /// DB, tables, data types, storage engines, functions, aggregate functions...
     bool internal = false,    /// If true, this query is caused by another query and thus needn't be registered in the ProcessList.
     QueryProcessingStage::Enum stage = QueryProcessingStage::Complete    /// To which stage the query must be executed.
 );
 
-/// Old interface with allow_processors flag. For compatibility.
-BlockIO executeQuery(
-    bool allow_processors,  /// If can use processors pipeline
-    const String & query,
-    ContextMutablePtr context,
-    bool internal = false,
-    QueryProcessingStage::Enum stage = QueryProcessingStage::Complete
-);
-
 /// Executes BlockIO returned from executeQuery(...)
 /// if built pipeline does not require any input and does not produce any output.
 void executeTrivialBlockIO(BlockIO & streams, ContextPtr context);
diff --git a/src/Interpreters/fuzzers/execute_query_fuzzer.cpp b/src/Interpreters/fuzzers/execute_query_fuzzer.cpp
index f12c01120cfe..0f6bfc1ae584 100644
--- a/src/Interpreters/fuzzers/execute_query_fuzzer.cpp
+++ b/src/Interpreters/fuzzers/execute_query_fuzzer.cpp
@@ -42,7 +42,7 @@ extern "C" int LLVMFuzzerTestOneInput(const uint8_t * data, size_t size)
         static bool initialized = initialize();
         (void) initialized;
 
-        auto io = DB::executeQuery(input, context, true, QueryProcessingStage::Complete);
+        auto io = DB::executeQuery(input, context, true, QueryProcessingStage::Complete).second;
 
         PullingPipelineExecutor executor(io.pipeline);
         Block res;
diff --git a/src/Interpreters/loadMetadata.cpp b/src/Interpreters/loadMetadata.cpp
index aeb45c08bea9..faa1dcda2c0f 100644
--- a/src/Interpreters/loadMetadata.cpp
+++ b/src/Interpreters/loadMetadata.cpp
@@ -282,7 +282,7 @@ static void convertOrdinaryDatabaseToAtomic(Poco::Logger * log, ContextMutablePt
     LOG_INFO(log, "Will convert database {} from Ordinary to Atomic", name_quoted);
 
     String create_database_query = fmt::format("CREATE DATABASE IF NOT EXISTS {}", tmp_name_quoted);
-    auto res = executeQuery(create_database_query, context, true);
+    auto res = executeQuery(create_database_query, context, true).second;
     executeTrivialBlockIO(res, context);
     res = {};
     auto tmp_database = DatabaseCatalog::instance().getDatabase(tmp_name);
@@ -322,7 +322,7 @@ static void convertOrdinaryDatabaseToAtomic(Poco::Logger * log, ContextMutablePt
         String tmp_qualified_quoted_name = id.getFullTableName();
 
         String move_table_query = fmt::format("RENAME TABLE {} TO {}", qualified_quoted_name, tmp_qualified_quoted_name);
-        res = executeQuery(move_table_query, context, true);
+        res = executeQuery(move_table_query, context, true).second;
         executeTrivialBlockIO(res, context);
         res = {};
     }
@@ -334,12 +334,12 @@ static void convertOrdinaryDatabaseToAtomic(Poco::Logger * log, ContextMutablePt
 
     String drop_query = fmt::format("DROP DATABASE {}", name_quoted);
     context->setSetting("force_remove_data_recursively_on_drop", false);
-    res = executeQuery(drop_query, context, true);
+    res = executeQuery(drop_query, context, true).second;
     executeTrivialBlockIO(res, context);
     res = {};
 
     String rename_query = fmt::format("RENAME DATABASE {} TO {}", tmp_name_quoted, name_quoted);
-    res = executeQuery(rename_query, context, true);
+    res = executeQuery(rename_query, context, true).second;
     executeTrivialBlockIO(res, context);
 
     LOG_INFO(log, "Finished database engine conversion of {}", name_quoted);
@@ -409,7 +409,7 @@ static void maybeConvertOrdinaryDatabaseToAtomic(ContextMutablePtr context, cons
 
         /// Reload database just in case (and update logger name)
         String detach_query = fmt::format("DETACH DATABASE {}", backQuoteIfNeed(database_name));
-        auto res = executeQuery(detach_query, context, true);
+        auto res = executeQuery(detach_query, context, true).second;
         executeTrivialBlockIO(res, context);
         res = {};
 
diff --git a/src/Processors/Executors/StreamingFormatExecutor.cpp b/src/Processors/Executors/StreamingFormatExecutor.cpp
index 468189890320..281961f7c7c4 100644
--- a/src/Processors/Executors/StreamingFormatExecutor.cpp
+++ b/src/Processors/Executors/StreamingFormatExecutor.cpp
@@ -66,21 +66,9 @@ size_t StreamingFormatExecutor::execute()
                     return new_rows;
 
                 case IProcessor::Status::PortFull:
-                {
-                    auto chunk = port.pull();
-                    if (adding_defaults_transform)
-                        adding_defaults_transform->transform(chunk);
-
-                    auto chunk_rows = chunk.getNumRows();
-                    new_rows += chunk_rows;
-
-                    auto columns = chunk.detachColumns();
-
-                    for (size_t i = 0, s = columns.size(); i < s; ++i)
-                        result_columns[i]->insertRangeFrom(*columns[i], 0, columns[i]->size());
-
+                    new_rows += insertChunk(port.pull());
                     break;
-                }
+
                 case IProcessor::Status::NeedData:
                 case IProcessor::Status::Async:
                 case IProcessor::Status::ExpandPipeline:
@@ -107,4 +95,17 @@ size_t StreamingFormatExecutor::execute()
     }
 }
 
+size_t StreamingFormatExecutor::insertChunk(Chunk chunk)
+{
+    size_t chunk_rows = chunk.getNumRows();
+    if (adding_defaults_transform)
+        adding_defaults_transform->transform(chunk);
+
+    auto columns = chunk.detachColumns();
+    for (size_t i = 0, s = columns.size(); i < s; ++i)
+        result_columns[i]->insertRangeFrom(*columns[i], 0, columns[i]->size());
+
+    return chunk_rows;
+}
+
 }
diff --git a/src/Processors/Executors/StreamingFormatExecutor.h b/src/Processors/Executors/StreamingFormatExecutor.h
index f5a1562a3408..3aa90ab03602 100644
--- a/src/Processors/Executors/StreamingFormatExecutor.h
+++ b/src/Processors/Executors/StreamingFormatExecutor.h
@@ -33,6 +33,9 @@ class StreamingFormatExecutor
     /// Execute with provided read buffer.
     size_t execute(ReadBuffer & buffer);
 
+    /// Inserts into result columns already preprocessed chunk.
+    size_t insertChunk(Chunk chunk);
+
     /// Releases currently accumulated columns.
     MutableColumns getResultColumns();
 
diff --git a/src/Processors/Transforms/SquashingChunksTransform.h b/src/Processors/Transforms/SquashingChunksTransform.h
index df13f539b906..f82e9e46a617 100644
--- a/src/Processors/Transforms/SquashingChunksTransform.h
+++ b/src/Processors/Transforms/SquashingChunksTransform.h
@@ -22,7 +22,6 @@ class SquashingChunksTransform : public ExceptionKeepingTransform
     GenerateResult onGenerate() override;
     void onFinish() override;
 
-
 private:
     SquashingTransform squashing;
     Chunk cur_chunk;
diff --git a/src/Server/GRPCServer.cpp b/src/Server/GRPCServer.cpp
index 4d9f5c983c57..812c2b5489db 100644
--- a/src/Server/GRPCServer.cpp
+++ b/src/Server/GRPCServer.cpp
@@ -949,7 +949,7 @@ namespace
             query_end = insert_query->data;
         }
         String query(begin, query_end);
-        io = ::DB::executeQuery(true, query, query_context);
+        io = ::DB::executeQuery(query, query_context).second;
     }
 
     void Call::processInput()
diff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp
index 8303ee2c9a1b..4908bf82b460 100644
--- a/src/Server/TCPHandler.cpp
+++ b/src/Server/TCPHandler.cpp
@@ -1,3 +1,7 @@
+#include "Interpreters/AsynchronousInsertQueue.h"
+#include "Interpreters/Context_fwd.h"
+#include "Interpreters/SquashingTransform.h"
+#include "Parsers/ASTInsertQuery.h"
 #include <algorithm>
 #include <exception>
 #include <iterator>
@@ -99,6 +103,7 @@ namespace DB::ErrorCodes
     extern const int AUTHENTICATION_FAILED;
     extern const int QUERY_WAS_CANCELLED;
     extern const int CLIENT_INFO_DOES_NOT_MATCH;
+    extern const int TIMEOUT_EXCEEDED;
     extern const int SUPPORT_IS_DISABLED;
     extern const int UNSUPPORTED_METHOD;
     extern const int FUNCTION_NOT_ALLOWED;
@@ -497,7 +502,7 @@ void TCPHandler::runImpl()
             });
 
             /// Processing Query
-            state.io = executeQuery(state.query, query_context, false, state.stage);
+            std::tie(state.parsed_query, state.io) = executeQuery(state.query, query_context, false, state.stage);
 
             after_check_cancelled.restart();
             after_send_progress.restart();
@@ -810,35 +815,66 @@ void TCPHandler::skipData()
         throw Exception(ErrorCodes::QUERY_WAS_CANCELLED, "Query was cancelled");
 }
 
+void TCPHandler::startInsertQuery()
+{
+    /// Send ColumnsDescription for insertion table
+    if (client_tcp_protocol_version >= DBMS_MIN_REVISION_WITH_COLUMN_DEFAULTS_METADATA)
+    {
+        const auto & table_id = query_context->getInsertionTable();
+        if (query_context->getSettingsRef().input_format_defaults_for_omitted_fields)
+        {
+            if (!table_id.empty())
+            {
+                auto storage_ptr = DatabaseCatalog::instance().getTable(table_id, query_context);
+                sendTableColumns(storage_ptr->getInMemoryMetadataPtr()->getColumns());
+            }
+        }
+    }
+
+    /// Send block to the client - table structure.
+    sendData(state.io.pipeline.getHeader());
+    sendLogs();
+}
+
+AsynchronousInsertQueue::PushResult TCPHandler::processAsyncInsertQuery(AsynchronousInsertQueue & insert_queue)
+{
+    using PushResult = AsynchronousInsertQueue::PushResult;
+
+    startInsertQuery();
+    SquashingTransform squashing(0, query_context->getSettingsRef().async_insert_max_data_size);
+
+    while (readDataNext())
+    {
+        auto result = squashing.add(std::move(state.block_for_insert));
+        if (result)
+        {
+            return PushResult
+            {
+                .status = PushResult::TOO_MUCH_DATA,
+                .insert_block = std::move(result),
+            };
+        }
+    }
+
+    auto result = squashing.add({});
+    return insert_queue.pushQueryWithBlock(state.parsed_query, std::move(result), query_context);
+}
 
 void TCPHandler::processInsertQuery()
 {
     size_t num_threads = state.io.pipeline.getNumThreads();
 
-    auto run_executor = [&](auto & executor)
+    auto run_executor = [&](auto & executor, Block processed_data)
     {
         /// Made above the rest of the lines,
-        /// so that in case of `writePrefix` function throws an exception,
+        /// so that in case of `start` function throws an exception,
         /// client receive exception before sending data.
         executor.start();
 
-        /// Send ColumnsDescription for insertion table
-        if (client_tcp_protocol_version >= DBMS_MIN_REVISION_WITH_COLUMN_DEFAULTS_METADATA)
-        {
-            const auto & table_id = query_context->getInsertionTable();
-            if (query_context->getSettingsRef().input_format_defaults_for_omitted_fields)
-            {
-                if (!table_id.empty())
-                {
-                    auto storage_ptr = DatabaseCatalog::instance().getTable(table_id, query_context);
-                    sendTableColumns(storage_ptr->getInMemoryMetadataPtr()->getColumns());
-                }
-            }
-        }
-
-        /// Send block to the client - table structure.
-        sendData(executor.getHeader());
-        sendLogs();
+        if (processed_data)
+            executor.push(std::move(processed_data));
+        else
+            startInsertQuery();
 
         while (readDataNext())
             executor.push(std::move(state.block_for_insert));
@@ -849,15 +885,55 @@ void TCPHandler::processInsertQuery()
             executor.finish();
     };
 
+    Block processed_block;
+    const auto & settings = query_context->getSettingsRef();
+
+    auto * insert_queue = query_context->getAsynchronousInsertQueue();
+    const auto & insert_query = assert_cast<const ASTInsertQuery &>(*state.parsed_query);
+
+    bool async_insert_enabled = settings.async_insert;
+    if (insert_query.table_id)
+        if (auto table = DatabaseCatalog::instance().tryGetTable(insert_query.table_id, query_context))
+            async_insert_enabled |= table->areAsynchronousInsertsEnabled();
+
+    if (insert_queue && async_insert_enabled && !insert_query.select)
+    {
+        auto result = processAsyncInsertQuery(*insert_queue);
+        if (result.status == AsynchronousInsertQueue::PushResult::OK)
+        {
+            if (settings.wait_for_async_insert)
+            {
+                size_t timeout_ms = settings.wait_for_async_insert_timeout.totalMilliseconds();
+                auto wait_status = result.future.wait_for(std::chrono::milliseconds(timeout_ms));
+
+                if (wait_status == std::future_status::deferred)
+                    throw Exception(ErrorCodes::LOGICAL_ERROR, "Logical error: got future in deferred state");
+
+                if (wait_status == std::future_status::timeout)
+                    throw Exception(ErrorCodes::TIMEOUT_EXCEEDED, "Wait for async insert timeout ({} ms) exceeded)", timeout_ms);
+
+                result.future.get();
+            }
+
+            sendInsertProfileEvents();
+            return;
+        }
+        else if (result.status == AsynchronousInsertQueue::PushResult::TOO_MUCH_DATA)
+        {
+            LOG_DEBUG(log, "Setting async_insert=1, but INSERT query will be executed synchronously because it has too much data");
+            processed_block = std::move(result.insert_block);
+        }
+    }
+
     if (num_threads > 1)
     {
         PushingAsyncPipelineExecutor executor(state.io.pipeline);
-        run_executor(executor);
+        run_executor(executor, std::move(processed_block));
     }
     else
     {
         PushingPipelineExecutor executor(state.io.pipeline);
-        run_executor(executor);
+        run_executor(executor, processed_block);
     }
 
     sendInsertProfileEvents();
diff --git a/src/Server/TCPHandler.h b/src/Server/TCPHandler.h
index 7ebb605e1c93..9fd243baa6c5 100644
--- a/src/Server/TCPHandler.h
+++ b/src/Server/TCPHandler.h
@@ -21,6 +21,7 @@
 #include <Formats/NativeWriter.h>
 
 #include "IServer.h"
+#include "Interpreters/AsynchronousInsertQueue.h"
 #include "Server/TCPProtocolStackData.h"
 #include "Storages/MergeTree/RequestResponse.h"
 #include "base/types.h"
@@ -73,6 +74,8 @@ struct QueryState
 
     /// Query text.
     String query;
+    /// Parsed query
+    ASTPtr parsed_query;
     /// Streams of blocks, that are processing the query.
     BlockIO io;
 
@@ -247,7 +250,9 @@ class TCPHandler : public Poco::Net::TCPServerConnection
     [[noreturn]] void receiveUnexpectedTablesStatusRequest();
 
     /// Process INSERT query
+    void startInsertQuery();
     void processInsertQuery();
+    AsynchronousInsertQueue::PushResult processAsyncInsertQuery(AsynchronousInsertQueue & insert_queue);
 
     /// Process a request that does not require the receiving of data blocks from the client
     void processOrdinaryQuery();
diff --git a/src/Storages/System/StorageSystemAsynchronousInserts.cpp b/src/Storages/System/StorageSystemAsynchronousInserts.cpp
index 15258ccfd7f1..ec3a9d92f308 100644
--- a/src/Storages/System/StorageSystemAsynchronousInserts.cpp
+++ b/src/Storages/System/StorageSystemAsynchronousInserts.cpp
@@ -82,7 +82,7 @@ void StorageSystemAsynchronousInserts::fillData(MutableColumns & res_columns, Co
             for (const auto & entry : data->entries)
             {
                 arr_query_id.push_back(entry->query_id);
-                arr_bytes.push_back(entry->bytes.size());
+                arr_bytes.push_back(entry->chunk.byteSize());
             }
 
             res_columns[i++]->insert(arr_query_id);
