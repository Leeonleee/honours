{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 12857,
  "instance_id": "ClickHouse__ClickHouse-12857",
  "issue_numbers": [
    "10605"
  ],
  "base_commit": "7dac65ce0f542f9e399fbec4ea708ccc1cafce80",
  "patch": "diff --git a/src/Dictionaries/DictionaryStructure.cpp b/src/Dictionaries/DictionaryStructure.cpp\nindex 74bf67a2738f..79df24d96537 100644\n--- a/src/Dictionaries/DictionaryStructure.cpp\n+++ b/src/Dictionaries/DictionaryStructure.cpp\n@@ -193,6 +193,7 @@ DictionaryStructure::DictionaryStructure(const Poco::Util::AbstractConfiguration\n     }\n \n     attributes = getAttributes(config, config_prefix);\n+\n     if (attributes.empty())\n         throw Exception{\"Dictionary has no attributes defined\", ErrorCodes::BAD_ARGUMENTS};\n }\n@@ -302,6 +303,12 @@ std::vector<DictionaryAttribute> DictionaryStructure::getAttributes(\n         checkAttributeKeys(attribute_keys);\n \n         const auto name = config.getString(prefix + \"name\");\n+\n+        /// Don't include range_min and range_max in attributes list, otherwise\n+        /// columns will be duplicated\n+        if ((range_min && name == range_min->name) || (range_max && name == range_max->name))\n+            continue;\n+\n         const auto type_string = config.getString(prefix + \"type\");\n         const auto type = DataTypeFactory::instance().get(type_string);\n         const auto underlying_type = getAttributeUnderlyingType(type_string);\ndiff --git a/src/Dictionaries/DictionaryStructure.h b/src/Dictionaries/DictionaryStructure.h\nindex 2893dea2e4f4..5a9fa7979c35 100644\n--- a/src/Dictionaries/DictionaryStructure.h\n+++ b/src/Dictionaries/DictionaryStructure.h\n@@ -113,6 +113,7 @@ struct DictionaryStructure final\n     size_t getKeySize() const;\n \n private:\n+    /// range_min and range_max have to be parsed before this function call\n     std::vector<DictionaryAttribute> getAttributes(\n         const Poco::Util::AbstractConfiguration & config,\n         const std::string & config_prefix,\n",
  "test_patch": "diff --git a/tests/integration/test_range_hashed_dictionary_types/__init__.py b/tests/integration/test_range_hashed_dictionary_types/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_range_hashed_dictionary_types/test.py b/tests/integration/test_range_hashed_dictionary_types/test.py\nnew file mode 100644\nindex 000000000000..24d4d5d40941\n--- /dev/null\n+++ b/tests/integration/test_range_hashed_dictionary_types/test.py\n@@ -0,0 +1,42 @@\n+import pytest\n+\n+\n+from helpers.cluster import ClickHouseCluster\n+cluster = ClickHouseCluster(__file__)\n+\n+node1 = cluster.add_instance('node1')\n+\n+\n+@pytest.fixture(scope=\"module\")\n+def started_cluster():\n+    try:\n+        cluster.start()\n+        yield cluster\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def test_range_hashed_dict(started_cluster):\n+    script = \"echo '4990954156238030839\\t2018-12-31 21:00:00\\t2020-12-30 20:59:59\\t0.1\\tRU' > /var/lib/clickhouse/user_files/rates.tsv\"\n+    node1.exec_in_container([\"bash\", \"-c\", script])\n+    node1.query(\"\"\"\n+    CREATE DICTIONARY rates\n+    (\n+        hash_id UInt64,\n+        start_date DateTime default '0000-00-00 00:00:00',\n+        end_date DateTime default '0000-00-00 00:00:00',\n+        price Float64,\n+        currency String\n+    )\n+    PRIMARY KEY hash_id\n+    SOURCE(file(\n+        path '/var/lib/clickhouse/user_files/rates.tsv'\n+        format 'TSV'\n+    ))\n+    LAYOUT(RANGE_HASHED())\n+    RANGE(MIN start_date MAX end_date)\n+    LIFETIME(60);\n+    \"\"\")\n+    node1.query(\"SYSTEM RELOAD DICTIONARY default.rates\")\n+\n+    assert node1.query(\"SELECT dictGetString('default.rates', 'currency', toUInt64(4990954156238030839), toDateTime('2019-10-01 00:00:00'))\") == \"RU\\n\"\n",
  "problem_statement": "Error when import RANGE_HASHED dictionary over http with csv-, tsv- formats\n**Describe the bug**\r\nWhen I try to load *RANGE_HASHED* dictionary over http I'm getting error below:\r\n\r\n```\r\nRow 1:\r\nColumn 0,   name: hash_id,    type: UInt64,             parsed text: \"4990954156238030839\"\r\nColumn 1,   name: start_date, type: Nullable(DateTime), parsed text: \"2018-12-31 21:00:00\"\r\nColumn 2,   name: end_date,   type: Nullable(DateTime), parsed text: \"2020-12-30 20:59:59\"\r\nColumn 3,   name: start_date, type: DateTime,           ERROR: text \"0.1<TAB>RU<LINE FEED>\" is not like DateTime\r\n```\r\n\r\nI think the reason is unexpected extra start_date and end_date fields\r\n\r\n**How to reproduce**\r\nVersion: 20.3.8.53\r\n\r\n_Dictionary:_\r\n```\r\nCREATE DICTIONARY rates\r\n(\r\n\thash_id UInt64,\r\n\tstart_date DateTime,\r\n\tend_date DateTime,\r\n\tprice Float64,\r\n\tcurrency String\r\n)\r\nPRIMARY KEY hash_id\r\nSOURCE(HTTP(\r\n    url 'http://localhost/dictionary/rates.tsv'\r\n    format 'TSV'\r\n))\r\nLAYOUT(RANGE_HASHED())\r\nRANGE(MIN start_date MAX end_date)\r\nLIFETIME(60);\r\n```\r\n\r\n_File:_\r\n```\r\n4990954156238030839\t\"2018-12-31 21:00:00\"\t\"2020-12-30 20:59:59\"\t0.1\t\"RU\"\r\n```\r\n\r\n**Error message and/or stacktrace**\r\n```\r\n2020.04.30 00:00:04.041356 [ 3740 ] {} <Error> ExternalDictionariesLoader: Could not load external dictionary 'default.customer_rate_all', next update is scheduled at 2020-04-30 00:07:23: Code: 41, e.displayText() = DB::Exception: Cannot parse datetime: (at row 1)\r\n\r\nRow 1:\r\nColumn 0,   name: hash_id,    type: UInt64,             parsed text: \"4990954156238030839\"\r\nColumn 1,   name: start_date, type: Nullable(DateTime), parsed text: \"2018-12-31 21:00:00\"\r\nColumn 2,   name: end_date,   type: Nullable(DateTime), parsed text: \"2020-12-30 20:59:59\"\r\nColumn 3,   name: start_date, type: DateTime,           ERROR: text \"0.1<TAB>RU<LINE FEED>\" is not like DateTime\r\n\r\n, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x10542450 in /usr/bin/clickhouse\r\n1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x8f4272d in /usr/bin/clickhouse\r\n2. void DB::readDateTimeTextFallback<void>(long&, DB::ReadBuffer&, DateLUTImpl const&) @ 0x8f7d6c8 in /usr/bin/clickhouse\r\n3. DB::DataTypeDateTime::deserializeTextEscaped(DB::IColumn&, DB::ReadBuffer&, DB::FormatSettings const&) const @ 0xceb003d in /usr/bin/clickhouse\r\n4. DB::TabSeparatedRowInputFormat::readField(DB::IColumn&, std::__1::shared_ptr<DB::IDataType const> const&, bool) @ 0xdd90829 in /usr/bin/clickhouse\r\n5. DB::TabSeparatedRowInputFormat::readRow(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::RowReadExtension&) @ 0xdd90bdb in /usr/bin/clickhouse\r\n6. DB::IRowInputFormat::generate() @ 0xdc2b8d1 in /usr/bin/clickhouse\r\n7. DB::ISource::work() @ 0xdba8ceb in /usr/bin/clickhouse\r\n8. DB::InputStreamFromInputFormat::readImpl() @ 0xdb5986d in /usr/bin/clickhouse\r\n9. DB::IBlockInputStream::read() @ 0xce5701f in /usr/bin/clickhouse\r\n10. DB::ParallelParsingBlockInputStream::parserThreadFunction(unsigned long) @ 0xdb5e462 in /usr/bin/clickhouse\r\n11. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8f6792b in /usr/bin/clickhouse\r\n12. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const @ 0x8f68608 in /usr/bin/clickhouse\r\n13. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8f667eb in /usr/bin/clickhouse\r\n14. ? @ 0x8f64c33 in /usr/bin/clickhouse\r\n15. start_thread @ 0x8f27 in /lib/x86_64-linux-gnu/libpthread-2.30.so\r\n16. clone @ 0xfd2ef in /lib/x86_64-linux-gnu/libc-2.30.so\r\n (version 20.3.8.53 (official build))\r\n```\r\n\n",
  "hints_text": "```\r\ncat /var/lib/clickhouse/user_files/rates.tsv\r\n4990954156238030839\t2018-12-31 21:00:00\t2020-12-30 20:59:59\t0.1\tRU\r\n\r\nCREATE DICTIONARY rates\r\n(\r\n\thash_id UInt64,\r\n\tstart_date DateTime default '0000-00-00 00:00:00',\r\n\tend_date DateTime default '0000-00-00 00:00:00',\r\n\tprice Float64,\r\n\tcurrency String\r\n)\r\nPRIMARY KEY hash_id\r\nSOURCE(file(\r\n    path '/var/lib/clickhouse/user_files/rates.tsv'\r\n    format 'TSV'\r\n))\r\nLAYOUT(RANGE_HASHED())\r\nRANGE(MIN start_date MAX end_date)\r\nLIFETIME(60);\r\n\r\nReceived exception from server (version 20.4.1):\r\nCode: 41. DB::Exception: Received from localhost:9000. DB::Exception: Cannot parse datetime: (at row 1)\r\n\r\nRow 1:\r\nColumn 0,   name: hash_id,    type: UInt64,             parsed text: \"4990954156238030839\"\r\nColumn 1,   name: start_date, type: Nullable(DateTime), parsed text: \"2018-12-31 21:00:00\"\r\nColumn 2,   name: end_date,   type: Nullable(DateTime), parsed text: \"2020-12-30 20:59:59\"\r\nColumn 3,   name: start_date, type: DateTime,           parsed text: \"0\"ERROR: DateTime must be in YYYY-MM-DD hh:mm:ss or NNNNNNNNNN (unix timestamp, exactly 10 digits) format.\r\n```\nSeeing the same from mysql source.\nhttps://github.com/ClickHouse/ClickHouse/issues/10093\nnot  related to #10093.\r\nStill relevant 20.3.9.70\r\n\r\n? CREATE DICTIONARY  RANGE_HASHED does not support arbitrary types in RANGE (only date). ?",
  "created_at": "2020-07-27T14:07:56Z",
  "modified_files": [
    "src/Dictionaries/DictionaryStructure.cpp",
    "src/Dictionaries/DictionaryStructure.h"
  ],
  "modified_test_files": [
    "b/tests/integration/test_range_hashed_dictionary_types/test.py"
  ]
}