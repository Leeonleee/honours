{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 27033,
  "instance_id": "ClickHouse__ClickHouse-27033",
  "issue_numbers": [
    "27011"
  ],
  "base_commit": "b7101baac91040592b2c17ab9f06dbdf9013ef0f",
  "patch": "diff --git a/src/Databases/DatabaseReplicated.cpp b/src/Databases/DatabaseReplicated.cpp\nindex 2c433c790339..ac6c525af68f 100644\n--- a/src/Databases/DatabaseReplicated.cpp\n+++ b/src/Databases/DatabaseReplicated.cpp\n@@ -40,6 +40,7 @@ namespace ErrorCodes\n     extern const int NOT_IMPLEMENTED;\n     extern const int INCORRECT_QUERY;\n     extern const int ALL_CONNECTION_TRIES_FAILED;\n+    extern const int NO_ACTIVE_REPLICAS;\n }\n \n static constexpr const char * DROPPED_MARK = \"DROPPED\";\n@@ -137,7 +138,9 @@ ClusterPtr DatabaseReplicated::getClusterImpl() const\n         Coordination::Stat stat;\n         hosts = zookeeper->getChildren(zookeeper_path + \"/replicas\", &stat);\n         if (hosts.empty())\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"No hosts found\");\n+            throw Exception(ErrorCodes::NO_ACTIVE_REPLICAS, \"No replicas of database {} found. \"\n+                            \"It's possible if the first replica is not fully created yet \"\n+                            \"or if the last replica was just dropped or due to logical error\", database_name);\n         Int32 cversion = stat.cversion;\n         std::sort(hosts.begin(), hosts.end());\n \n@@ -514,6 +517,19 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n         }\n     }\n \n+    auto make_query_context = [this, current_zookeeper]()\n+    {\n+        auto query_context = Context::createCopy(getContext());\n+        query_context->makeQueryContext();\n+        query_context->getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n+        query_context->getClientInfo().is_replicated_database_internal = true;\n+        query_context->setCurrentDatabase(database_name);\n+        query_context->setCurrentQueryId(\"\");\n+        auto txn = std::make_shared<ZooKeeperMetadataTransaction>(current_zookeeper, zookeeper_path, false);\n+        query_context->initZooKeeperMetadataTransaction(txn);\n+        return query_context;\n+    };\n+\n     String db_name = getDatabaseName();\n     String to_db_name = getDatabaseName() + BROKEN_TABLES_SUFFIX;\n     if (total_tables * db_settings.max_broken_tables_ratio < tables_to_detach.size())\n@@ -548,7 +564,7 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n             dropped_dictionaries += table->isDictionary();\n \n             table->flushAndShutdown();\n-            DatabaseAtomic::dropTable(getContext(), table_name, true);\n+            DatabaseAtomic::dropTable(make_query_context(), table_name, true);\n         }\n         else\n         {\n@@ -558,7 +574,7 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n             assert(db_name < to_db_name);\n             DDLGuardPtr to_table_guard = DatabaseCatalog::instance().getDDLGuard(to_db_name, to_name);\n             auto to_db_ptr = DatabaseCatalog::instance().getDatabase(to_db_name);\n-            DatabaseAtomic::renameTable(getContext(), table_name, *to_db_ptr, to_name, false, false);\n+            DatabaseAtomic::renameTable(make_query_context(), table_name, *to_db_ptr, to_name, false, false);\n             ++moved_tables;\n         }\n     }\n@@ -577,7 +593,7 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n         /// TODO Maybe we should do it in two steps: rename all tables to temporary names and then rename them to actual names?\n         DDLGuardPtr table_guard = DatabaseCatalog::instance().getDDLGuard(db_name, std::min(from, to));\n         DDLGuardPtr to_table_guard = DatabaseCatalog::instance().getDDLGuard(db_name, std::max(from, to));\n-        DatabaseAtomic::renameTable(getContext(), from, *this, to, false, false);\n+        DatabaseAtomic::renameTable(make_query_context(), from, *this, to, false, false);\n     }\n \n     for (const auto & id : dropped_tables)\n@@ -592,15 +608,9 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n         }\n \n         auto query_ast = parseQueryFromMetadataInZooKeeper(name_and_meta.first, name_and_meta.second);\n-\n-        auto query_context = Context::createCopy(getContext());\n-        query_context->makeQueryContext();\n-        query_context->getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n-        query_context->setCurrentDatabase(database_name);\n-        query_context->setCurrentQueryId(\"\"); // generate random query_id\n-\n         LOG_INFO(log, \"Executing {}\", serializeAST(*query_ast));\n-        InterpreterCreateQuery(query_ast, query_context).execute();\n+        auto create_query_context = make_query_context();\n+        InterpreterCreateQuery(query_ast, create_query_context).execute();\n     }\n \n     current_zookeeper->set(replica_path + \"/log_ptr\", toString(max_log_ptr));\ndiff --git a/src/Databases/DatabaseReplicatedWorker.cpp b/src/Databases/DatabaseReplicatedWorker.cpp\nindex eb7e65e1b709..365a5d028165 100644\n--- a/src/Databases/DatabaseReplicatedWorker.cpp\n+++ b/src/Databases/DatabaseReplicatedWorker.cpp\n@@ -60,12 +60,13 @@ void DatabaseReplicatedDDLWorker::initializeReplication()\n     /// Check if we need to recover replica.\n     /// Invariant: replica is lost if it's log_ptr value is less then max_log_ptr - logs_to_keep.\n \n-    String log_ptr_str = current_zookeeper->get(database->replica_path + \"/log_ptr\");\n+    auto zookeeper = getAndSetZooKeeper();\n+    String log_ptr_str = zookeeper->get(database->replica_path + \"/log_ptr\");\n     UInt32 our_log_ptr = parse<UInt32>(log_ptr_str);\n-    UInt32 max_log_ptr = parse<UInt32>(current_zookeeper->get(database->zookeeper_path + \"/max_log_ptr\"));\n-    logs_to_keep = parse<UInt32>(current_zookeeper->get(database->zookeeper_path + \"/logs_to_keep\"));\n+    UInt32 max_log_ptr = parse<UInt32>(zookeeper->get(database->zookeeper_path + \"/max_log_ptr\"));\n+    logs_to_keep = parse<UInt32>(zookeeper->get(database->zookeeper_path + \"/logs_to_keep\"));\n     if (our_log_ptr == 0 || our_log_ptr + logs_to_keep < max_log_ptr)\n-        database->recoverLostReplica(current_zookeeper, our_log_ptr, max_log_ptr);\n+        database->recoverLostReplica(zookeeper, our_log_ptr, max_log_ptr);\n     else\n         last_skipped_entry_name.emplace(DDLTaskBase::getLogEntryName(our_log_ptr));\n }\n@@ -198,7 +199,7 @@ DDLTaskPtr DatabaseReplicatedDDLWorker::initAndCheckTask(const String & entry_na\n         }\n     }\n \n-    UInt32 our_log_ptr = parse<UInt32>(current_zookeeper->get(fs::path(database->replica_path) / \"log_ptr\"));\n+    UInt32 our_log_ptr = parse<UInt32>(zookeeper->get(fs::path(database->replica_path) / \"log_ptr\"));\n     UInt32 entry_num = DatabaseReplicatedTask::getLogEntryNumber(entry_name);\n \n     if (entry_num <= our_log_ptr)\ndiff --git a/src/Interpreters/ClientInfo.h b/src/Interpreters/ClientInfo.h\nindex d6158a2d7d52..7c169e6ebb50 100644\n--- a/src/Interpreters/ClientInfo.h\n+++ b/src/Interpreters/ClientInfo.h\n@@ -100,6 +100,8 @@ class ClientInfo\n \n     UInt64 distributed_depth = 0;\n \n+    bool is_replicated_database_internal = false;\n+\n     bool empty() const { return query_kind == QueryKind::NO_QUERY; }\n \n     /** Serialization and deserialization.\ndiff --git a/src/Interpreters/DDLTask.cpp b/src/Interpreters/DDLTask.cpp\nindex 4fb44738d8d9..8bebc2fb442b 100644\n--- a/src/Interpreters/DDLTask.cpp\n+++ b/src/Interpreters/DDLTask.cpp\n@@ -359,6 +359,7 @@ ContextMutablePtr DatabaseReplicatedTask::makeQueryContext(ContextPtr from_conte\n {\n     auto query_context = DDLTaskBase::makeQueryContext(from_context, zookeeper);\n     query_context->getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n+    query_context->getClientInfo().is_replicated_database_internal = true;\n     query_context->setCurrentDatabase(database->getDatabaseName());\n \n     auto txn = std::make_shared<ZooKeeperMetadataTransaction>(zookeeper, database->zookeeper_path, is_initial_query);\ndiff --git a/src/Interpreters/DDLTask.h b/src/Interpreters/DDLTask.h\nindex 703d691a3586..41ab9ec80584 100644\n--- a/src/Interpreters/DDLTask.h\n+++ b/src/Interpreters/DDLTask.h\n@@ -196,7 +196,7 @@ class ZooKeeperMetadataTransaction\n \n     void commit();\n \n-    ~ZooKeeperMetadataTransaction() { assert(isExecuted() || std::uncaught_exceptions()); }\n+    ~ZooKeeperMetadataTransaction() { assert(isExecuted() || std::uncaught_exceptions() || ops.empty()); }\n };\n \n ClusterPtr tryGetReplicatedDatabaseCluster(const String & cluster_name);\ndiff --git a/src/Interpreters/InterpreterAlterQuery.cpp b/src/Interpreters/InterpreterAlterQuery.cpp\nindex 6f0af049d05c..76e7afb7009d 100644\n--- a/src/Interpreters/InterpreterAlterQuery.cpp\n+++ b/src/Interpreters/InterpreterAlterQuery.cpp\n@@ -54,7 +54,7 @@ BlockIO InterpreterAlterQuery::execute()\n \n     DatabasePtr database = DatabaseCatalog::instance().getDatabase(table_id.database_name);\n     if (typeid_cast<DatabaseReplicated *>(database.get())\n-        && getContext()->getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY)\n+        && !getContext()->getClientInfo().is_replicated_database_internal)\n     {\n         auto guard = DatabaseCatalog::instance().getDDLGuard(table_id.database_name, table_id.table_name);\n         guard->releaseTableLock();\n@@ -100,7 +100,8 @@ BlockIO InterpreterAlterQuery::execute()\n     if (typeid_cast<DatabaseReplicated *>(database.get()))\n     {\n         int command_types_count = !mutation_commands.empty() + !partition_commands.empty() + !live_view_commands.empty() + !alter_commands.empty();\n-        if (1 < command_types_count)\n+        bool mixed_settings_amd_metadata_alter = alter_commands.hasSettingsAlterCommand() && !alter_commands.isSettingsAlter();\n+        if (1 < command_types_count || mixed_settings_amd_metadata_alter)\n             throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"For Replicated databases it's not allowed \"\n                                                          \"to execute ALTERs of different types in single query\");\n     }\ndiff --git a/src/Interpreters/InterpreterCreateQuery.cpp b/src/Interpreters/InterpreterCreateQuery.cpp\nindex 1f7e239b5042..b3cbfdcd035c 100644\n--- a/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -856,7 +856,7 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)\n             auto guard = DatabaseCatalog::instance().getDDLGuard(database_name, create.table);\n \n             if (auto* ptr = typeid_cast<DatabaseReplicated *>(database.get());\n-                ptr && getContext()->getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY)\n+                ptr && !getContext()->getClientInfo().is_replicated_database_internal)\n             {\n                 create.database = database_name;\n                 guard->releaseTableLock();\n@@ -950,7 +950,7 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)\n         auto guard = DatabaseCatalog::instance().getDDLGuard(create.database, create.table);\n \n         if (auto * ptr = typeid_cast<DatabaseReplicated *>(database.get());\n-            ptr && getContext()->getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY)\n+            ptr && !getContext()->getClientInfo().is_replicated_database_internal)\n         {\n             assertOrSetUUID(create, database);\n             guard->releaseTableLock();\ndiff --git a/src/Interpreters/InterpreterDropQuery.cpp b/src/Interpreters/InterpreterDropQuery.cpp\nindex d5f6c3260c32..0e15c6be27cf 100644\n--- a/src/Interpreters/InterpreterDropQuery.cpp\n+++ b/src/Interpreters/InterpreterDropQuery.cpp\n@@ -133,7 +133,7 @@ BlockIO InterpreterDropQuery::executeToTableImpl(ASTDropQuery & query, DatabaseP\n         /// Prevents recursive drop from drop database query. The original query must specify a table.\n         bool is_drop_or_detach_database = query_ptr->as<ASTDropQuery>()->table.empty();\n         bool is_replicated_ddl_query = typeid_cast<DatabaseReplicated *>(database.get()) &&\n-                                       getContext()->getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY &&\n+                                       !getContext()->getClientInfo().is_replicated_database_internal &&\n                                        !is_drop_or_detach_database;\n \n         AccessFlags drop_storage;\n@@ -426,6 +426,7 @@ void InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind kind, ContextPtr\n         if (auto txn = current_context->getZooKeeperMetadataTransaction())\n         {\n             /// For Replicated database\n+            drop_context->getClientInfo().is_replicated_database_internal = true;\n             drop_context->setQueryContext(std::const_pointer_cast<Context>(current_context));\n             drop_context->initZooKeeperMetadataTransaction(txn, true);\n         }\ndiff --git a/src/Interpreters/InterpreterRenameQuery.cpp b/src/Interpreters/InterpreterRenameQuery.cpp\nindex 515559ad903c..373953e75308 100644\n--- a/src/Interpreters/InterpreterRenameQuery.cpp\n+++ b/src/Interpreters/InterpreterRenameQuery.cpp\n@@ -81,7 +81,7 @@ BlockIO InterpreterRenameQuery::executeToTables(const ASTRenameQuery & rename, c\n \n         DatabasePtr database = database_catalog.getDatabase(elem.from_database_name);\n         if (typeid_cast<DatabaseReplicated *>(database.get())\n-            && getContext()->getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY)\n+            && !getContext()->getClientInfo().is_replicated_database_internal)\n         {\n             if (1 < descriptions.size())\n                 throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Database {} is Replicated, \"\ndiff --git a/src/Storages/AlterCommands.cpp b/src/Storages/AlterCommands.cpp\nindex 9e9510b51a44..1bb8e6bb9b00 100644\n--- a/src/Storages/AlterCommands.cpp\n+++ b/src/Storages/AlterCommands.cpp\n@@ -1276,6 +1276,11 @@ void AlterCommands::validate(const StorageInMemoryMetadata & metadata, ContextPt\n     validateColumnsDefaultsAndGetSampleBlock(default_expr_list, all_columns.getAll(), context);\n }\n \n+bool AlterCommands::hasSettingsAlterCommand() const\n+{\n+    return std::any_of(begin(), end(), [](const AlterCommand & c) { return c.isSettingsAlter(); });\n+}\n+\n bool AlterCommands::isSettingsAlter() const\n {\n     return std::all_of(begin(), end(), [](const AlterCommand & c) { return c.isSettingsAlter(); });\ndiff --git a/src/Storages/AlterCommands.h b/src/Storages/AlterCommands.h\nindex 6987de68f9c4..60f4ad7d552d 100644\n--- a/src/Storages/AlterCommands.h\n+++ b/src/Storages/AlterCommands.h\n@@ -195,9 +195,12 @@ class AlterCommands : public std::vector<AlterCommand>\n     void apply(StorageInMemoryMetadata & metadata, ContextPtr context) const;\n \n     /// At least one command modify settings.\n+    bool hasSettingsAlterCommand() const;\n+\n+    /// All commands modify settings only.\n     bool isSettingsAlter() const;\n \n-    /// At least one command modify comments.\n+    /// All commands modify comments only.\n     bool isCommentAlter() const;\n \n     /// Return mutation commands which some storages may execute as part of\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 8b6267943bd3..0049f28e5681 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -4972,6 +4972,8 @@ void StorageReplicatedMergeTree::alter(\n \n         if (auto txn = query_context->getZooKeeperMetadataTransaction())\n         {\n+            /// It would be better to clone ops instead of moving, so we could retry on ZBADVERSION,\n+            /// but clone() is not implemented for Coordination::Request.\n             txn->moveOpsTo(ops);\n             /// NOTE: IDatabase::alterTable(...) is called when executing ALTER_METADATA queue entry without query context,\n             /// so we have to update metadata of DatabaseReplicated here.\n@@ -5015,6 +5017,11 @@ void StorageReplicatedMergeTree::alter(\n                 throw Exception(\"Metadata on replica is not up to date with common metadata in Zookeeper. Cannot alter\",\n                     ErrorCodes::CANNOT_ASSIGN_ALTER);\n \n+            /// Cannot retry automatically, because some zookeeper ops were lost on the first attempt. Will retry on DDLWorker-level.\n+            if (query_context->getZooKeeperMetadataTransaction())\n+                throw Exception(\"Cannot execute alter, because mutations version was suddenly changed due to concurrent alter\",\n+                                ErrorCodes::CANNOT_ASSIGN_ALTER);\n+\n             continue;\n         }\n         else\n@@ -6007,6 +6014,10 @@ void StorageReplicatedMergeTree::mutate(const MutationCommands & commands, Conte\n         }\n         else if (rc == Coordination::Error::ZBADVERSION)\n         {\n+            /// Cannot retry automatically, because some zookeeper ops were lost on the first attempt. Will retry on DDLWorker-level.\n+            if (query_context->getZooKeeperMetadataTransaction())\n+                throw Exception(\"Cannot execute alter, because mutations version was suddenly changed due to concurrent alter\",\n+                                ErrorCodes::CANNOT_ASSIGN_ALTER);\n             LOG_TRACE(log, \"Version conflict when trying to create a mutation node, retrying...\");\n             continue;\n         }\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/00980_zookeeper_merge_tree_alter_settings.reference b/tests/queries/0_stateless/00980_zookeeper_merge_tree_alter_settings.reference\nindex 357d1bef78d5..811facbac408 100644\n--- a/tests/queries/0_stateless/00980_zookeeper_merge_tree_alter_settings.reference\n+++ b/tests/queries/0_stateless/00980_zookeeper_merge_tree_alter_settings.reference\n@@ -1,21 +1,21 @@\n-CREATE TABLE default.replicated_table_for_alter1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_alter\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n-CREATE TABLE default.replicated_table_for_alter1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_alter\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.replicated_table_for_alter1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_alter\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.replicated_table_for_alter1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_alter\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n 4\n 4\n 4\n 4\n 6\n 6\n-CREATE TABLE default.replicated_table_for_alter1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_alter\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, use_minimalistic_part_header_in_zookeeper = 1\n-CREATE TABLE default.replicated_table_for_alter2\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_alter\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, parts_to_throw_insert = 1, parts_to_delay_insert = 1\n-CREATE TABLE default.replicated_table_for_alter1\\n(\\n    `id` UInt64,\\n    `Data` String,\\n    `Data2` UInt64\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_alter\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, use_minimalistic_part_header_in_zookeeper = 1, check_delay_period = 15\n-CREATE TABLE default.replicated_table_for_alter2\\n(\\n    `id` UInt64,\\n    `Data` String,\\n    `Data2` UInt64\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_alter\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, parts_to_throw_insert = 1, parts_to_delay_insert = 1\n-CREATE TABLE default.replicated_table_for_reset_setting1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_reset_setting\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n-CREATE TABLE default.replicated_table_for_reset_setting2\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_reset_setting\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n-CREATE TABLE default.replicated_table_for_reset_setting1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_reset_setting\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n-CREATE TABLE default.replicated_table_for_reset_setting1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_reset_setting\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, merge_with_ttl_timeout = 100\n-CREATE TABLE default.replicated_table_for_reset_setting2\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_reset_setting\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, merge_with_ttl_timeout = 200\n-CREATE TABLE default.replicated_table_for_reset_setting1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_reset_setting\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, merge_with_ttl_timeout = 100\n-CREATE TABLE default.replicated_table_for_reset_setting2\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_reset_setting\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, merge_with_ttl_timeout = 200\n-CREATE TABLE default.replicated_table_for_reset_setting1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_reset_setting\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n-CREATE TABLE default.replicated_table_for_reset_setting2\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980/replicated_table_for_reset_setting\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.replicated_table_for_alter1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_alter\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, use_minimalistic_part_header_in_zookeeper = 1\n+CREATE TABLE default.replicated_table_for_alter2\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_alter\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, parts_to_throw_insert = 1, parts_to_delay_insert = 1\n+CREATE TABLE default.replicated_table_for_alter1\\n(\\n    `id` UInt64,\\n    `Data` String,\\n    `Data2` UInt64\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_alter\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, use_minimalistic_part_header_in_zookeeper = 1, check_delay_period = 15\n+CREATE TABLE default.replicated_table_for_alter2\\n(\\n    `id` UInt64,\\n    `Data` String,\\n    `Data2` UInt64\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_alter\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, parts_to_throw_insert = 1, parts_to_delay_insert = 1\n+CREATE TABLE default.replicated_table_for_reset_setting1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_reset_setting\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.replicated_table_for_reset_setting2\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_reset_setting\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.replicated_table_for_reset_setting1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_reset_setting\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.replicated_table_for_reset_setting1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_reset_setting\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, merge_with_ttl_timeout = 100\n+CREATE TABLE default.replicated_table_for_reset_setting2\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_reset_setting\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, merge_with_ttl_timeout = 200\n+CREATE TABLE default.replicated_table_for_reset_setting1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_reset_setting\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, merge_with_ttl_timeout = 100\n+CREATE TABLE default.replicated_table_for_reset_setting2\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_reset_setting\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192, merge_with_ttl_timeout = 200\n+CREATE TABLE default.replicated_table_for_reset_setting1\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_reset_setting\\', \\'1\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.replicated_table_for_reset_setting2\\n(\\n    `id` UInt64,\\n    `Data` String\\n)\\nENGINE = ReplicatedMergeTree(\\'/clickhouse/tables/test_00980_default/replicated_table_for_reset_setting\\', \\'2\\')\\nORDER BY id\\nSETTINGS index_granularity = 8192\ndiff --git a/tests/queries/0_stateless/00980_zookeeper_merge_tree_alter_settings.sql b/tests/queries/0_stateless/00980_zookeeper_merge_tree_alter_settings.sql\nindex 6ad8860227dc..25516f577ec3 100644\n--- a/tests/queries/0_stateless/00980_zookeeper_merge_tree_alter_settings.sql\n+++ b/tests/queries/0_stateless/00980_zookeeper_merge_tree_alter_settings.sql\n@@ -6,12 +6,12 @@ SET replication_alter_partitions_sync = 2;\n CREATE TABLE replicated_table_for_alter1 (\n   id UInt64,\n   Data String\n-) ENGINE = ReplicatedMergeTree('/clickhouse/tables/test_00980/replicated_table_for_alter', '1') ORDER BY id;\n+) ENGINE = ReplicatedMergeTree('/clickhouse/tables/test_00980_{database}/replicated_table_for_alter', '1') ORDER BY id;\n \n CREATE TABLE replicated_table_for_alter2 (\n   id UInt64,\n   Data String\n-) ENGINE = ReplicatedMergeTree('/clickhouse/tables/test_00980/replicated_table_for_alter', '2') ORDER BY id;\n+) ENGINE = ReplicatedMergeTree('/clickhouse/tables/test_00980_{database}/replicated_table_for_alter', '2') ORDER BY id;\n \n SHOW CREATE TABLE replicated_table_for_alter1;\n \n@@ -76,12 +76,12 @@ SET replication_alter_partitions_sync = 2;\n CREATE TABLE replicated_table_for_reset_setting1 (\n  id UInt64,\n  Data String\n-) ENGINE = ReplicatedMergeTree('/clickhouse/tables/test_00980/replicated_table_for_reset_setting', '1') ORDER BY id;\n+) ENGINE = ReplicatedMergeTree('/clickhouse/tables/test_00980_{database}/replicated_table_for_reset_setting', '1') ORDER BY id;\n \n CREATE TABLE replicated_table_for_reset_setting2 (\n  id UInt64,\n  Data String\n-) ENGINE = ReplicatedMergeTree('/clickhouse/tables/test_00980/replicated_table_for_reset_setting', '2') ORDER BY id;\n+) ENGINE = ReplicatedMergeTree('/clickhouse/tables/test_00980_{database}/replicated_table_for_reset_setting', '2') ORDER BY id;\n \n SHOW CREATE TABLE replicated_table_for_reset_setting1;\n SHOW CREATE TABLE replicated_table_for_reset_setting2;\ndiff --git a/tests/queries/0_stateless/01149_zookeeper_mutation_stuck_after_replace_partition.sql b/tests/queries/0_stateless/01149_zookeeper_mutation_stuck_after_replace_partition.sql\nindex 18508635cf94..ca8f70b3cf42 100644\n--- a/tests/queries/0_stateless/01149_zookeeper_mutation_stuck_after_replace_partition.sql\n+++ b/tests/queries/0_stateless/01149_zookeeper_mutation_stuck_after_replace_partition.sql\n@@ -1,3 +1,4 @@\n+set send_logs_level='error';\n drop table if exists mt;\n drop table if exists rmt sync;\n \ndiff --git a/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.sh b/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.sh\nindex 7347fc5d6264..483979d00db8 100755\n--- a/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.sh\n+++ b/tests/queries/0_stateless/01175_distributed_ddl_output_mode_long.sh\n@@ -14,7 +14,7 @@ function run_until_out_contains()\n     PATTERN=$1\n     shift\n \n-    while true\n+    for _ in {1..20}\n     do\n         \"$@\" > \"${CLICKHOUSE_TMP}/out\" 2>&1\n         if grep -q \"$PATTERN\" \"${CLICKHOUSE_TMP}/out\"\ndiff --git a/tests/queries/0_stateless/01294_system_distributed_on_cluster.sql b/tests/queries/0_stateless/01294_system_distributed_on_cluster.sql\nindex d56bddba3c60..525974e78ba4 100644\n--- a/tests/queries/0_stateless/01294_system_distributed_on_cluster.sql\n+++ b/tests/queries/0_stateless/01294_system_distributed_on_cluster.sql\n@@ -3,6 +3,7 @@\n -- quirk for ON CLUSTER does not uses currentDatabase()\n drop database if exists db_01294;\n create database db_01294;\n+set distributed_ddl_output_mode='throw';\n \n drop table if exists db_01294.dist_01294;\n create table db_01294.dist_01294 as system.one engine=Distributed(test_shard_localhost, system, one);\ndiff --git a/tests/queries/0_stateless/01415_sticking_mutations.sh b/tests/queries/0_stateless/01415_sticking_mutations.sh\nindex 9bd0a6eeebf2..2e86b6d972d6 100755\n--- a/tests/queries/0_stateless/01415_sticking_mutations.sh\n+++ b/tests/queries/0_stateless/01415_sticking_mutations.sh\n@@ -33,9 +33,10 @@ function check_sticky_mutations()\n \n     query_result=$($CLICKHOUSE_CLIENT --query=\"$check_query\" 2>&1)\n \n-    while [ \"$query_result\" == \"0\" ]\n+    for _ in {1..50}\n     do\n         query_result=$($CLICKHOUSE_CLIENT --query=\"$check_query\" 2>&1)\n+        if ! [ \"$query_result\" == \"0\" ]; then break; fi\n         sleep 0.5\n     done\n     ##### wait mutation to start #####\ndiff --git a/tests/queries/skip_list.json b/tests/queries/skip_list.json\nindex bb1442b1ff9e..f4aeffdc50df 100644\n--- a/tests/queries/skip_list.json\n+++ b/tests/queries/skip_list.json\n@@ -119,16 +119,14 @@\n         \"memory_tracking\",\n         \"memory_usage\",\n         \"live_view\",\n-        \"01181_db_atomic_drop_on_cluster\",\n-        \"01175_distributed_ddl_output_mode\",\n-        \"01415_sticking_mutations\",\n-        \"00980_zookeeper_merge_tree_alter_settings\",\n         \"01148_zookeeper_path_macros_unfolding\",\n-        \"01294_system_distributed_on_cluster\",\n         \"01269_create_with_null\",\n         \"01451_replicated_detach_drop_and_quorum\",\n         \"01188_attach_table_from_path\",\n-        \"01149_zookeeper_mutation_stuck_after_replace_partition\",\n+        /// ON CLUSTER is not allowed\n+        \"01181_db_atomic_drop_on_cluster\",\n+        \"01175_distributed_ddl_output_mode\",\n+        \"01415_sticking_mutations\",\n         /// user_files\n         \"01721_engine_file_truncate_on_insert\",\n         /// Fails due to additional replicas or shards\n@@ -158,6 +156,8 @@\n         \"00152_insert_different_granularity\",\n         \"00054_merge_tree_partitions\",\n         \"01781_merge_tree_deduplication\",\n+        \"00980_zookeeper_merge_tree_alter_settings\",\n+        \"00980_merge_alter_settings\",\n         /// Old syntax is not allowed\n         \"01062_alter_on_mutataion_zookeeper\",\n         \"00925_zookeeper_empty_replicated_merge_tree_optimize_final\",\n@@ -175,10 +175,11 @@\n         /// Does not support renaming of multiple tables in single query\n         \"00634_rename_view\",\n         \"00140_rename\",\n+        /// Different query_id\n+        \"01943_query_id_check\",\n         /// Requires investigation\n         \"00953_zookeeper_suetin_deduplication_bug\",\n         \"01783_http_chunk_size\",\n-        \"01943_query_id_check\",\n         \"00166_explain_estimate\"\n     ],\n     \"polymorphic-parts\": [\n",
  "problem_statement": "DatabaseReplicated::commitCreateTable: Assertion `!ddl_worker->isCurrentlyActive() || txn' failed.\n```\r\nclickhouse-server: ../src/Databases/DatabaseReplicated.cpp:758: virtual void DB::DatabaseReplicated::commitCreateTable(const DB::ASTCreateQuery &, const DB::StoragePtr &, const DB::String &, const DB::String &, DB::ContextPtr): Assertion `!ddl_worker->isCurrentlyActive() || txn' failed.\r\n```\r\n\r\nhttps://clickhouse-test-reports.s3.yandex.net/0/cae5502d51ce1179dfed788383942c5962e36420/stress_test_(debug).html\r\n\r\n```\r\n2021.07.30 12:34:02.771937 [ 2366 ] {} <Fatal> BaseDaemon: ########################################\r\n2021.07.30 12:34:02.772466 [ 2366 ] {} <Fatal> BaseDaemon: (version 21.9.1.7617 (official build), build id: 2834ACCE2A3D004B31E1C6ABA166D4BC63F285D8) (from thread 612) (query_id: a3c01d0c-799e-4d0a-981b-78b6666ab5fb) Received signal Aborted (6)\r\n2021.07.30 12:34:02.778008 [ 2366 ] {} <Fatal> BaseDaemon:\r\n2021.07.30 12:34:02.778375 [ 2366 ] {} <Fatal> BaseDaemon: Stack trace: 0x7fdbb13f018b 0x7fdbb13cf859 0x7fdbb13cf729 0x7fdbb13e0f36 0x1d7d9d61 0x1d7f071c 0x1db63877 0x1db613b5 0x1db64b6c 0x1e575270 0x1e5770c1 0x1d9e995b 0x1d9e8792 0x1d9e6c24 0x1d9defdc 0x1d9f9f37 0x1d9f9e7a 0x1d9f9d72 0x1d9f9c2f 0x1d9f9b3d 0x1d9f9afd 0x1d9f9ad5 0x1d9f9aa0 0x13041909 0x13040a35 0x13067a0e 0x1306ed24 0x1306ec7d 0x1306eba5 0x1306e4c2 0x7fdbb15b6609 0x7fdbb14cc293\r\n2021.07.30 12:34:02.779366 [ 2366 ] {} <Fatal> BaseDaemon: 4. gsignal @ 0x4618b in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n2021.07.30 12:34:02.779620 [ 2366 ] {} <Fatal> BaseDaemon: 5. abort @ 0x25859 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n2021.07.30 12:34:02.779823 [ 2366 ] {} <Fatal> BaseDaemon: 6. ? @ 0x25729 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n2021.07.30 12:34:02.780050 [ 2366 ] {} <Fatal> BaseDaemon: 7. ? @ 0x36f36 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n2021.07.30 12:34:04.300044 [ 2366 ] {} <Fatal> BaseDaemon: 8. ./obj-x86_64-linux-gnu/../src/Databases/DatabaseReplicated.cpp:767: DB::DatabaseReplicated::commitCreateTable(DB::ASTCreateQuery const&, std::__1::shared_ptr<DB::IStorage> const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::Context const>) @ 0x1d7d9d61 in /usr/bin/clickhouse\r\n2021.07.30 12:34:05.195747 [ 2366 ] {} <Fatal> BaseDaemon: 9. ./obj-x86_64-linux-gnu/../src/Databases/DatabaseOnDisk.cpp:277: DB::DatabaseOnDisk::createTable(std::__1::shared_ptr<DB::Context const>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::IStorage> const&, std::__1::shared_ptr<DB::IAST> const&) @ 0x1d7f071c in /usr/bin/clickhouse\r\n2021.07.30 12:34:06.871109 [ 2366 ] {} <Fatal> BaseDaemon: 10. ./obj-x86_64-linux-gnu/../src/Interpreters/InterpreterCreateQuery.cpp:1085: DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&) @ 0x1db63877 in /usr/bin/clickhouse\r\n2021.07.30 12:34:08.001460 [ 2366 ] {} <Fatal> BaseDaemon: 11. ./obj-x86_64-linux-gnu/../src/Interpreters/InterpreterCreateQuery.cpp:965: DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x1db613b5 in /usr/bin/clickhouse\r\n2021.07.30 12:34:09.061780 [ 2366 ] {} <Fatal> BaseDaemon: 12. ./obj-x86_64-linux-gnu/../src/Interpreters/InterpreterCreateQuery.cpp:0: DB::InterpreterCreateQuery::execute() @ 0x1db64b6c in /usr/bin/clickhouse\r\n2021.07.30 12:34:10.562954 [ 2366 ] {} <Fatal> BaseDaemon: 13. ./obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:556: DB::executeQueryImpl(char const*, char const*, std::__1::shared_ptr<DB::Context>, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer*) @ 0x1e575270 in /usr/bin/clickhouse\r\n2021.07.30 12:34:11.486539 [ 2366 ] {} <Fatal> BaseDaemon: 14. ./obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:988: DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, std::__1::shared_ptr<DB::Context>, std::__1::function<void (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>, std::__1::optional<DB::FormatSettings> const&, std::__1::function<void ()>) @ 0x1e5770c1 in /usr/bin/clickhouse\r\n2021.07.30 12:34:12.786528 [ 2366 ] {} <Fatal> BaseDaemon: 15. ./obj-x86_64-linux-gnu/../src/Interpreters/DDLWorker.cpp:517: DB::DDLWorker::tryExecuteQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x1d9e995b in /usr/bin/clickhouse\r\n2021.07.30 12:34:13.713227 [ 2366 ] {} <Fatal> BaseDaemon: 16. ./obj-x86_64-linux-gnu/../src/Interpreters/DDLWorker.cpp:677: DB::DDLWorker::processTask(DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x1d9e8792 in /usr/bin/clickhouse\r\n2021.07.30 12:34:14.608145 [ 2366 ] {} <Fatal> BaseDaemon: 17. ./obj-x86_64-linux-gnu/../src/Interpreters/DDLWorker.cpp:478: DB::DDLWorker::scheduleTasks(bool) @ 0x1d9e6c24 in /usr/bin/clickhouse\r\n2021.07.30 12:34:15.564433 [ 2366 ] {} <Fatal> BaseDaemon: 18. ./obj-x86_64-linux-gnu/../src/Interpreters/DDLWorker.cpp:1139: DB::DDLWorker::runMainThread() @ 0x1d9defdc in /usr/bin/clickhouse\r\n2021.07.30 12:34:16.565278 [ 2366 ] {} <Fatal> BaseDaemon: 19. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3624: decltype(*(std::__1::forward<DB::DDLWorker*&>(fp0)).*fp()) std::__1::__invoke_constexpr<void (DB::DDLWorker::*&)(), DB::DDLWorker*&, void>(void (DB::DDLWorker::*&)(), DB::DDLWorker*&) @ 0x1d9f9f37 in /usr/bin/clickhouse\r\n2021.07.30 12:34:17.544062 [ 2366 ] {} <Fatal> BaseDaemon: 20. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/tuple:1415: decltype(auto) std::__1::__apply_tuple_impl<void (DB::DDLWorker::*&)(), std::__1::tuple<DB::DDLWorker*>&, 0ul>(void (DB::DDLWorker::*&)(), std::__1::tuple<DB::DDLWorker*>&, std::__1::__tuple_indices<0ul>) @ 0x1d9f9e7a in /usr/bin/clickhouse\r\n2021.07.30 12:34:18.535802 [ 2366 ] {} <Fatal> BaseDaemon: 21. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/tuple:1424: decltype(auto) std::__1::apply<void (DB::DDLWorker::*&)(), std::__1::tuple<DB::DDLWorker*>&>(void (DB::DDLWorker::*&)(), std::__1::tuple<DB::DDLWorker*>&) @ 0x1d9f9d72 in /usr/bin/clickhouse\r\n2021.07.30 12:34:19.486957 [ 2366 ] {} <Fatal> BaseDaemon: 22. ./obj-x86_64-linux-gnu/../src/Common/ThreadPool.h:182: ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::DDLWorker::*)(), DB::DDLWorker*>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&)::'lambda'()::operator()() @ 0x1d9f9c2f in /usr/bin/clickhouse\r\n2021.07.30 12:34:20.464853 [ 2366 ] {} <Fatal> BaseDaemon: 23. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3676: decltype(std::__1::forward<void (DB::DDLWorker::*)()>(fp)(std::__1::forward<DB::DDLWorker*>(fp0))) std::__1::__invoke<ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::DDLWorker::*)(), DB::DDLWorker*>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&)::'lambda'()&>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&) @ 0x1d9f9b3d in /usr/bin/clickhouse\r\n2021.07.30 12:34:21.476712 [ 2366 ] {} <Fatal> BaseDaemon: 24. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/__functional_base:349: void std::__1::__invoke_void_return_wrapper<void>::__call<ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::DDLWorker::*)(), DB::DDLWorker*>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&)::'lambda'()&>(void (DB::DDLWorker::*&&)()...) @ 0x1d9f9afd in /usr/bin/clickhouse\r\n2021.07.30 12:34:22.472870 [ 2366 ] {} <Fatal> BaseDaemon: 25. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:1608: std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::DDLWorker::*)(), DB::DDLWorker*>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&)::'lambda'(), void ()>::operator()() @ 0x1d9f9ad5 in /usr/bin/clickhouse\r\n2021.07.30 12:34:25.280036 [ 412 ] {} <Fatal> Application: Child process was terminated by signal 6.\r\n```\n",
  "hints_text": "",
  "created_at": "2021-07-30T16:36:12Z"
}