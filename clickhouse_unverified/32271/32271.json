{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 32271,
  "instance_id": "ClickHouse__ClickHouse-32271",
  "issue_numbers": [
    "32993"
  ],
  "base_commit": "b84591d17a18410dd2672bf22d44a45f4f7d70ec",
  "patch": "diff --git a/src/Core/ExternalTable.cpp b/src/Core/ExternalTable.cpp\nindex b4adbcc06624..3b515fab5c9c 100644\n--- a/src/Core/ExternalTable.cpp\n+++ b/src/Core/ExternalTable.cpp\n@@ -169,7 +169,7 @@ void ExternalTablesHandler::handlePart(const Poco::Net::MessageHeader & header,\n     processors.push_back(std::move(sink));\n     processors.push_back(std::move(exception_handling));\n \n-    auto executor = std::make_shared<PipelineExecutor>(processors);\n+    auto executor = std::make_shared<PipelineExecutor>(processors, getContext()->getProcessListElement());\n     executor->execute(/*num_threads = */ 1);\n \n     /// We are ready to receive the next file, for this we clear all the information received\ndiff --git a/src/Formats/FormatFactory.cpp b/src/Formats/FormatFactory.cpp\nindex d292bbf551c8..cf2cdd6c547b 100644\n--- a/src/Formats/FormatFactory.cpp\n+++ b/src/Formats/FormatFactory.cpp\n@@ -1,17 +1,18 @@\n #include <Formats/FormatFactory.h>\n \n #include <algorithm>\n-#include <Common/Exception.h>\n-#include <Interpreters/Context.h>\n #include <Core/Settings.h>\n #include <Formats/FormatSettings.h>\n+#include <Interpreters/Context.h>\n+#include <Interpreters/ProcessList.h>\n #include <Processors/Formats/IRowInputFormat.h>\n #include <Processors/Formats/IRowOutputFormat.h>\n-#include <Processors/Formats/Impl/ValuesBlockInputFormat.h>\n #include <Processors/Formats/Impl/MySQLOutputFormat.h>\n-#include <Processors/Formats/Impl/ParallelParsingInputFormat.h>\n #include <Processors/Formats/Impl/ParallelFormattingOutputFormat.h>\n+#include <Processors/Formats/Impl/ParallelParsingInputFormat.h>\n+#include <Processors/Formats/Impl/ValuesBlockInputFormat.h>\n #include <Poco/URI.h>\n+#include <Common/Exception.h>\n \n #include <IO/BufferWithOwnMemory.h>\n #include <IO/ReadHelpers.h>\n@@ -235,6 +236,18 @@ InputFormatPtr FormatFactory::getInputFormat(\n     return format;\n }\n \n+static void addExistingProgressToOutputFormat(OutputFormatPtr format, ContextPtr context)\n+{\n+    auto element_id = context->getProcessListElement();\n+    if (element_id)\n+    {\n+        /// While preparing the query there might have been progress (for example in subscalar subqueries) so add it here\n+        auto current_progress = element_id->getProgressIn();\n+        Progress read_progress{current_progress.read_rows, current_progress.read_bytes, current_progress.total_rows_to_read};\n+        format->onProgress(read_progress);\n+    }\n+}\n+\n OutputFormatPtr FormatFactory::getOutputFormatParallelIfPossible(\n     const String & name,\n     WriteBuffer & buf,\n@@ -263,7 +276,9 @@ OutputFormatPtr FormatFactory::getOutputFormatParallelIfPossible(\n         if (context->hasQueryContext() && settings.log_queries)\n             context->getQueryContext()->addQueryFactoriesInfo(Context::QueryLogFactories::Format, name);\n \n-        return std::make_shared<ParallelFormattingOutputFormat>(builder);\n+        auto format = std::make_shared<ParallelFormattingOutputFormat>(builder);\n+        addExistingProgressToOutputFormat(format, context);\n+        return format;\n     }\n \n     return getOutputFormat(name, buf, sample, context, callback, _format_settings);\n@@ -303,6 +318,8 @@ OutputFormatPtr FormatFactory::getOutputFormat(\n     if (auto * mysql = typeid_cast<MySQLOutputFormat *>(format.get()))\n         mysql->setContext(context);\n \n+    addExistingProgressToOutputFormat(format, context);\n+\n     return format;\n }\n \ndiff --git a/src/Interpreters/ProcessList.cpp b/src/Interpreters/ProcessList.cpp\nindex a4583685a90e..67871c630d85 100644\n--- a/src/Interpreters/ProcessList.cpp\n+++ b/src/Interpreters/ProcessList.cpp\n@@ -411,9 +411,8 @@ QueryStatusInfo QueryStatus::getInfo(bool get_thread_list, bool get_profile_even\n     res.read_bytes        = progress_in.read_bytes;\n     res.total_rows        = progress_in.total_rows_to_read;\n \n-    /// TODO: Use written_rows and written_bytes when real time progress is implemented\n-    res.written_rows      = progress_out.read_rows;\n-    res.written_bytes     = progress_out.read_bytes;\n+    res.written_rows      = progress_out.written_rows;\n+    res.written_bytes     = progress_out.written_bytes;\n \n     if (thread_group)\n     {\ndiff --git a/src/Interpreters/ProcessList.h b/src/Interpreters/ProcessList.h\nindex 9c826bde0614..0b17874836fc 100644\n--- a/src/Interpreters/ProcessList.h\n+++ b/src/Interpreters/ProcessList.h\n@@ -94,7 +94,7 @@ class QueryStatus : public WithContext\n     ExecutionSpeedLimits limits;\n     OverflowMode overflow_mode;\n \n-    QueryPriorities::Handle priority_handle;\n+    QueryPriorities::Handle priority_handle = nullptr;\n \n     std::atomic<bool> is_killed { false };\n \ndiff --git a/src/Interpreters/ThreadStatusExt.cpp b/src/Interpreters/ThreadStatusExt.cpp\nindex fc6aa15a1e89..b3720b89eaa2 100644\n--- a/src/Interpreters/ThreadStatusExt.cpp\n+++ b/src/Interpreters/ThreadStatusExt.cpp\n@@ -24,12 +24,6 @@\n #   include <sys/resource.h>\n #endif\n \n-namespace ProfileEvents\n-{\n-    extern const Event InsertedRows;\n-    extern const Event InsertedBytes;\n-}\n-\n \n /// Implement some methods of ThreadStatus and CurrentThread here to avoid extra linking dependencies in clickhouse_common_io\n /// TODO It doesn't make sense.\n@@ -447,9 +441,8 @@ void ThreadStatus::logToQueryThreadLog(QueryThreadLog & thread_log, const String\n     elem.read_rows = progress_in.read_rows.load(std::memory_order_relaxed);\n     elem.read_bytes = progress_in.read_bytes.load(std::memory_order_relaxed);\n \n-    /// TODO: Use written_rows and written_bytes when run time progress is implemented\n-    elem.written_rows = progress_out.read_rows.load(std::memory_order_relaxed);\n-    elem.written_bytes = progress_out.read_bytes.load(std::memory_order_relaxed);\n+    elem.written_rows = progress_out.written_rows.load(std::memory_order_relaxed);\n+    elem.written_bytes = progress_out.written_bytes.load(std::memory_order_relaxed);\n     elem.memory_usage = memory_tracker.get();\n     elem.peak_memory_usage = memory_tracker.getPeak();\n \n@@ -520,8 +513,8 @@ void ThreadStatus::logToQueryViewsLog(const ViewRuntimeData & vinfo)\n     auto events = std::make_shared<ProfileEvents::Counters::Snapshot>(performance_counters.getPartiallyAtomicSnapshot());\n     element.read_rows = progress_in.read_rows.load(std::memory_order_relaxed);\n     element.read_bytes = progress_in.read_bytes.load(std::memory_order_relaxed);\n-    element.written_rows = (*events)[ProfileEvents::InsertedRows];\n-    element.written_bytes = (*events)[ProfileEvents::InsertedBytes];\n+    element.written_rows = progress_out.written_rows.load(std::memory_order_relaxed);\n+    element.written_bytes = progress_out.written_bytes.load(std::memory_order_relaxed);\n     element.peak_memory_usage = memory_tracker.getPeak() > 0 ? memory_tracker.getPeak() : 0;\n     if (query_context_ptr->getSettingsRef().log_profile_events != 0)\n     {\ndiff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp\nindex e177fd8e6b3b..65238da7d2ef 100644\n--- a/src/Interpreters/executeQuery.cpp\n+++ b/src/Interpreters/executeQuery.cpp\n@@ -819,8 +819,8 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n                 else /// will be used only for ordinary INSERT queries\n                 {\n                     auto progress_out = process_list_elem->getProgressOut();\n-                    elem.result_rows = progress_out.read_rows;\n-                    elem.result_bytes = progress_out.read_bytes;\n+                    elem.result_rows = progress_out.written_rows;\n+                    elem.result_bytes = progress_out.written_rows;\n                 }\n \n                 if (elem.read_rows != 0)\ndiff --git a/src/Processors/Executors/PipelineExecutor.h b/src/Processors/Executors/PipelineExecutor.h\nindex 12f2bd8b75bc..0b1fe5dedf6e 100644\n--- a/src/Processors/Executors/PipelineExecutor.h\n+++ b/src/Processors/Executors/PipelineExecutor.h\n@@ -26,7 +26,7 @@ class PipelineExecutor\n     /// During pipeline execution new processors can appear. They will be added to existing set.\n     ///\n     /// Explicit graph representation is built in constructor. Throws if graph is not correct.\n-    explicit PipelineExecutor(Processors & processors, QueryStatus * elem = nullptr);\n+    explicit PipelineExecutor(Processors & processors, QueryStatus * elem);\n     ~PipelineExecutor();\n \n     /// Execute pipeline in multiple threads. Must be called once.\ndiff --git a/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp b/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp\nindex 2480673d65ed..fb3ed7f80fc8 100644\n--- a/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp\n+++ b/src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp\n@@ -6,16 +6,13 @@\n namespace DB\n {\n \n-BuildQueryPipelineSettings BuildQueryPipelineSettings::fromSettings(const Settings & from)\n+BuildQueryPipelineSettings BuildQueryPipelineSettings::fromContext(ContextPtr from)\n {\n     BuildQueryPipelineSettings settings;\n-    settings.actions_settings = ExpressionActionsSettings::fromSettings(from, CompileExpressions::yes);\n+    settings.actions_settings = ExpressionActionsSettings::fromSettings(from->getSettingsRef(), CompileExpressions::yes);\n+    settings.process_list_element = from->getProcessListElement();\n+    settings.progress_callback = from->getProgressCallback();\n     return settings;\n }\n \n-BuildQueryPipelineSettings BuildQueryPipelineSettings::fromContext(ContextPtr from)\n-{\n-    return fromSettings(from->getSettingsRef());\n-}\n-\n }\ndiff --git a/src/Processors/QueryPlan/BuildQueryPipelineSettings.h b/src/Processors/QueryPlan/BuildQueryPipelineSettings.h\nindex c3282d43778e..fadbd061fbd5 100644\n--- a/src/Processors/QueryPlan/BuildQueryPipelineSettings.h\n+++ b/src/Processors/QueryPlan/BuildQueryPipelineSettings.h\n@@ -1,5 +1,6 @@\n #pragma once\n \n+#include <IO/Progress.h>\n #include <Interpreters/ExpressionActionsSettings.h>\n \n #include <cstddef>\n@@ -8,14 +9,15 @@ namespace DB\n {\n \n struct Settings;\n+class QueryStatus;\n \n struct BuildQueryPipelineSettings\n {\n     ExpressionActionsSettings actions_settings;\n+    QueryStatus * process_list_element = nullptr;\n+    ProgressCallback progress_callback = nullptr;\n \n     const ExpressionActionsSettings & getActionsSettings() const { return actions_settings; }\n-\n-    static BuildQueryPipelineSettings fromSettings(const Settings & from);\n     static BuildQueryPipelineSettings fromContext(ContextPtr from);\n };\n \ndiff --git a/src/Processors/QueryPlan/QueryPlan.cpp b/src/Processors/QueryPlan/QueryPlan.cpp\nindex f319e562bfbd..a271ef78dfaa 100644\n--- a/src/Processors/QueryPlan/QueryPlan.cpp\n+++ b/src/Processors/QueryPlan/QueryPlan.cpp\n@@ -180,6 +180,9 @@ QueryPipelineBuilderPtr QueryPlan::buildQueryPipeline(\n     for (auto & context : interpreter_context)\n         last_pipeline->addInterpreterContext(std::move(context));\n \n+    last_pipeline->setProgressCallback(build_pipeline_settings.progress_callback);\n+    last_pipeline->setProcessListElement(build_pipeline_settings.process_list_element);\n+\n     return last_pipeline;\n }\n \ndiff --git a/src/Processors/Sources/SourceWithProgress.cpp b/src/Processors/Sources/SourceWithProgress.cpp\nindex 9b7a5c6a762c..60c39c919f64 100644\n--- a/src/Processors/Sources/SourceWithProgress.cpp\n+++ b/src/Processors/Sources/SourceWithProgress.cpp\n@@ -26,6 +26,8 @@ SourceWithProgress::SourceWithProgress(Block header, bool enable_auto_progress)\n void SourceWithProgress::setProcessListElement(QueryStatus * elem)\n {\n     process_list_elem = elem;\n+    if (!elem)\n+        return;\n \n     /// Update total_rows_approx as soon as possible.\n     ///\ndiff --git a/src/Processors/Transforms/CountingTransform.cpp b/src/Processors/Transforms/CountingTransform.cpp\nindex 79b6360f22e5..eb191b36586a 100644\n--- a/src/Processors/Transforms/CountingTransform.cpp\n+++ b/src/Processors/Transforms/CountingTransform.cpp\n@@ -18,20 +18,21 @@ namespace DB\n \n void CountingTransform::onConsume(Chunk chunk)\n {\n-    Progress local_progress(chunk.getNumRows(), chunk.bytes(), 0);\n+    Progress local_progress{WriteProgress(chunk.getNumRows(), chunk.bytes())};\n     progress.incrementPiecewiseAtomically(local_progress);\n \n     //std::cerr << \"============ counting adding progress for \" << static_cast<const void *>(thread_status) << ' ' << chunk.getNumRows() << \" rows\\n\";\n \n     if (thread_status)\n     {\n-        thread_status->performance_counters.increment(ProfileEvents::InsertedRows, local_progress.read_rows);\n-        thread_status->performance_counters.increment(ProfileEvents::InsertedBytes, local_progress.read_bytes);\n+        thread_status->performance_counters.increment(ProfileEvents::InsertedRows, local_progress.written_rows);\n+        thread_status->performance_counters.increment(ProfileEvents::InsertedBytes, local_progress.written_bytes);\n+        thread_status->progress_out.incrementPiecewiseAtomically(local_progress);\n     }\n     else\n     {\n-        ProfileEvents::increment(ProfileEvents::InsertedRows, local_progress.read_rows);\n-        ProfileEvents::increment(ProfileEvents::InsertedBytes, local_progress.read_bytes);\n+        ProfileEvents::increment(ProfileEvents::InsertedRows, local_progress.written_rows);\n+        ProfileEvents::increment(ProfileEvents::InsertedBytes, local_progress.written_bytes);\n     }\n \n     if (process_elem)\ndiff --git a/src/Processors/Transforms/buildPushingToViewsChain.cpp b/src/Processors/Transforms/buildPushingToViewsChain.cpp\nindex 82c2a337a451..fdd0150536a9 100644\n--- a/src/Processors/Transforms/buildPushingToViewsChain.cpp\n+++ b/src/Processors/Transforms/buildPushingToViewsChain.cpp\n@@ -3,6 +3,7 @@\n #include <Interpreters/Context.h>\n #include <Interpreters/InterpreterInsertQuery.h>\n #include <Interpreters/InterpreterSelectQuery.h>\n+#include <Interpreters/ProcessList.h>\n #include <Parsers/ASTInsertQuery.h>\n #include <Processors/Transforms/SquashingChunksTransform.h>\n #include <Processors/Transforms/ExpressionTransform.h>\n@@ -14,6 +15,7 @@\n #include <Storages/StorageValues.h>\n #include <Common/CurrentThread.h>\n #include <Common/MemoryTracker.h>\n+#include <Common/ProfileEvents.h>\n #include <Common/ThreadProfileEvents.h>\n #include <Common/ThreadStatus.h>\n #include <Common/checkStackSize.h>\n@@ -23,6 +25,12 @@\n #include <atomic>\n #include <chrono>\n \n+namespace ProfileEvents\n+{\n+    extern const Event SelectedBytes;\n+    extern const Event SelectedRows;\n+}\n+\n namespace DB\n {\n \n@@ -451,13 +459,6 @@ static QueryPipeline process(Block block, ViewRuntimeData & view, const ViewsDat\n         pipeline.getHeader(),\n         std::make_shared<ExpressionActions>(std::move(converting))));\n \n-    pipeline.setProgressCallback([context](const Progress & progress)\n-    {\n-        CurrentThread::updateProgressIn(progress);\n-        if (auto callback = context->getProgressCallback())\n-            callback(progress);\n-    });\n-\n     return QueryPipelineBuilder::getPipeline(std::move(pipeline));\n }\n \n@@ -595,7 +596,11 @@ void PushingToLiveViewSink::consume(Chunk chunk)\n {\n     Progress local_progress(chunk.getNumRows(), chunk.bytes(), 0);\n     StorageLiveView::writeIntoLiveView(live_view, getHeader().cloneWithColumns(chunk.detachColumns()), context);\n-    CurrentThread::updateProgressIn(local_progress);\n+    auto process = context->getProcessListElement();\n+    if (process)\n+        process->updateProgressIn(local_progress);\n+    ProfileEvents::increment(ProfileEvents::SelectedRows, local_progress.read_rows);\n+    ProfileEvents::increment(ProfileEvents::SelectedBytes, local_progress.read_bytes);\n }\n \n \n@@ -614,7 +619,11 @@ void PushingToWindowViewSink::consume(Chunk chunk)\n     Progress local_progress(chunk.getNumRows(), chunk.bytes(), 0);\n     StorageWindowView::writeIntoWindowView(\n         window_view, getHeader().cloneWithColumns(chunk.detachColumns()), context);\n-    CurrentThread::updateProgressIn(local_progress);\n+    auto process = context->getProcessListElement();\n+    if (process)\n+        process->updateProgressIn(local_progress);\n+    ProfileEvents::increment(ProfileEvents::SelectedRows, local_progress.read_rows);\n+    ProfileEvents::increment(ProfileEvents::SelectedBytes, local_progress.read_bytes);\n }\n \n \ndiff --git a/src/QueryPipeline/QueryPipelineBuilder.cpp b/src/QueryPipeline/QueryPipelineBuilder.cpp\nindex 40c640465609..dba7c7cb8f74 100644\n--- a/src/QueryPipeline/QueryPipelineBuilder.cpp\n+++ b/src/QueryPipeline/QueryPipelineBuilder.cpp\n@@ -560,6 +560,7 @@ QueryPipeline QueryPipelineBuilder::getPipeline(QueryPipelineBuilder builder)\n {\n     QueryPipeline res(std::move(builder.pipe));\n     res.setNumThreads(builder.getNumThreads());\n+    res.setProcessListElement(builder.process_list_element);\n     return res;\n }\n \n",
  "test_patch": "diff --git a/src/Processors/tests/gtest_exception_on_incorrect_pipeline.cpp b/src/Processors/tests/gtest_exception_on_incorrect_pipeline.cpp\nindex df3901e2eb19..ee661b39fac7 100644\n--- a/src/Processors/tests/gtest_exception_on_incorrect_pipeline.cpp\n+++ b/src/Processors/tests/gtest_exception_on_incorrect_pipeline.cpp\n@@ -27,7 +27,8 @@ TEST(Processors, PortsConnected)\n     processors.emplace_back(std::move(source));\n     processors.emplace_back(std::move(sink));\n \n-    PipelineExecutor executor(processors);\n+    QueryStatus * element = nullptr;\n+    PipelineExecutor executor(processors, element);\n     executor.execute(1);\n }\n \n@@ -51,7 +52,8 @@ TEST(Processors, PortsNotConnected)\n \n     try\n     {\n-        PipelineExecutor executor(processors);\n+        QueryStatus * element = nullptr;\n+        PipelineExecutor executor(processors, element);\n         executor.execute(1);\n         ASSERT_TRUE(false) << \"Should have thrown.\";\n     }\ndiff --git a/tests/performance/set_index.xml b/tests/performance/set_index.xml\nindex 1fb7cf967f3f..631cad9986ef 100644\n--- a/tests/performance/set_index.xml\n+++ b/tests/performance/set_index.xml\n@@ -3,17 +3,17 @@\n     <fill_query>INSERT INTO test_in SELECT number FROM numbers(500000000)</fill_query>\n \n     <!-- IN is used at index analysis -->\n-    <query>SELECT count() FROM test_in WHERE a IN (SELECT rand(1) FROM numbers(200000)) SETTINGS max_rows_to_read = 1, read_overflow_mode = 'break'</query>\n+    <query short=\"1\">SELECT count() FROM test_in WHERE a IN (SELECT rand(1) FROM numbers(200000)) SETTINGS max_rows_to_read = 200001, read_overflow_mode = 'break'</query>\n \n-    <query>SELECT count() FROM test_in WHERE toInt64(a) IN (SELECT toInt64(rand(1)) FROM numbers(200000)) settings max_rows_to_read=1, read_overflow_mode='break'</query>\n+    <query short=\"1\">SELECT count() FROM test_in WHERE toInt64(a) IN (SELECT toInt64(rand(1)) FROM numbers(200000)) settings max_rows_to_read=200001, read_overflow_mode='break'</query>\n \n      <!-- Analyze only one range. The query is short because nothing is selected. -->\n-    <query short=\"1\">SELECT count() FROM test_in WHERE -toInt64(a) IN (SELECT toInt64(rand(1)) FROM numbers(200000)) settings max_rows_to_read=1, read_overflow_mode='break'</query>\n+    <query short=\"1\">SELECT count() FROM test_in WHERE -toInt64(a) IN (SELECT toInt64(rand(1)) FROM numbers(200000)) settings max_rows_to_read=200001, read_overflow_mode='break'</query>\n     <!-- Analyze all ranges. The query is short because nothing is selected. -->\n-    <query short=\"1\">SELECT count() FROM test_in WHERE -toInt64(a) NOT IN (SELECT toInt64(rand(1)) FROM numbers(200000)) settings max_rows_to_read=1, read_overflow_mode='break'</query>\n+    <query short=\"1\">SELECT count() FROM test_in WHERE -toInt64(a) NOT IN (SELECT toInt64(rand(1)) FROM numbers(200000)) settings max_rows_to_read=200001, read_overflow_mode='break'</query>\n \n     <!--\n-        Test with explicitly defined large set (10000 elemnets).\n+        Test with explicitly defined large set (10000 elements).\n         We test the speed of parsing the query and not the speed of lookup, so one\n         lookup is enough. This also keeps the query duration under 20 ms, which\n         means it is considered \"short\" and compared qualitatively, not quantitatively.\n@@ -64,7 +64,7 @@\n     4120, 11402, 91344, 95169]::Array(UInt32)</query>\n \n     <!--\n-        Test with explicitly defined large set (10000 elemnets), but with tuples.\n+        Test with explicitly defined large set (10000 elements), but with tuples.\n         Ditto the above comment.\n     -->\n     <query>SELECT (rand(), rand()) IN ((17258, 93148), (4508, 52749), (68660, 70017), (77797, 23528), (1136, 37393), (53237, 15379), (68370, 73211), (15782, 54962), (59432, 45415), (68396, 920), (96154, 21016), (12700, 26887), (88016, 43191), (68153, 51575), (91315, 40005), (18070, 73178), (86, 631), (77717, 20324), (3227, 76188), (74960, 43147), (77538, 19628), (82292, 6525), (24293, 12566), (85244, 96287), (93982, 1329), (38064, 54723), (83999, 45810), (71921, 53673), (88638, 9669), (1959, 39535), (82235, 95796), (27907, 90975), (42383, 91015), (9948, 91514), (81712, 47309), (400, 25808), (31791, 46948), (39740, 36098), (25943, 84598), (99598, 52939), (77134, 15845), (40313, 72174), (85017, 94036), (36595, 14303), (83961, 68078), (55792, 72759), (73574, 43606), (9853, 63560), (28580, 56721), (74804, 41025), (32095, 55657), (52881, 63416), (91368, 90310), (23922, 38883), (30592, 10758), (66448, 61183), (31880, 96697), (11362, 20633), (75331, 2015), (71129, 8785), (1115, 70955), (7886, 83698), (18961, 84556), (16677, 43028), (37347, 70220), (31699, 71244), (10578, 96159), (67600, 39041), (78791, 86687), (21545, 54174), (68774, 37637), (46132, 81768), (98413, 20605), (2960, 23665), (31507, 35719), (96209, 18368), (60558, 38035), (21952, 3264), (11834, 86458), (21651, 17650), (86276, 36087), (18818, 24849), (61951, 3390), (59637, 62545), (30346, 72253), (36281, 2992), (78340, 49872), (94326, 93723), (3416, 94405), (12272, 8741), (22600, 22095), (57636, 37106), (38702, 14889), (70238, 11276), (17325, 60648), (16492, 41271), (52100, 1304), (93416, 7795), (57209, 71008), (48010, 36078), (20384, 74420), (77440, 34439), (69224, 45099), (30374, 33884), (49038, 90140), (1154, 84725), (64926, 86985), (91746, 73472), (59757, 75755), (45860, 71557), (45833, 36526), (74618, 73598), (91360, 65168), (58029, 30793), (56332, 14973), (99943, 96877), (97454, 6450), (64502, 77301), (73182, 31853), (76809, 83964), (82916, 86188), (78736, 65427), (36495, 7422), (76196, 2804), (96117, 61093), (9177, 26099), (52942, 63007), (48578, 47876), (50638, 89903), (7113, 97316), (35301, 12750), (47807, 7254), (38217, 55418), (56970, 41687), (20527, 62886), (358, 14021), (64018, 18582), (91740, 21683), (81967, 53589), (45437, 38450), (45476, 67752), (76851, 72072), (7304, 60091), (40097, 12897), (39906, 29247), (84262, 58734), (30857, 43791), (56087, 78929), (20498, 45954), (48726, 500), (62723, 43763), (28368, 30756), (74048, 52403), (15045, 95926), (75542, 55384), (52543, 22525), (56001, 6935), (11431, 46745), (77731, 7310), (36718, 59909), (32235, 91254), (92417, 25917), (21782, 79277), (46378, 87536), (35324, 26075), (6310, 76915), (1551, 69473), (50642, 68865), (55190, 72934), (49780, 21873), (99466, 29686), (90761, 13179), (72959, 57033), (20020, 90200), (46186, 79105), (73871, 52382), (59559, 38801), (59916, 16082), (33610, 94966), (46001, 45225), (86679, 26469), (77245, 91929), (32887, 36623), (11179, 46898), (87881, 68087), (45438, 47991), (24950, 94525), (91664, 51656), (43914, 47805), (15736, 96156), (56346, 20283), (85053, 48931), (17790, 26179), (96195, 55728), (43765, 54807), (44988, 89269), (55911, 99411), (52446, 47397), (28346, 65442), (96669, 68226), (66194, 26848), (37276, 55864), (14116, 41583), (18058, 16317), (93136, 85318), (35616, 86252), (29222, 29969), (33386, 85372), (71094, 44238), (27733, 31838), (64626, 16692), (52904, 97899), (97619, 12663), (50165, 4688), (67557, 44053), (69184, 66269), (73164, 89705), (39822, 15169), (65499, 72808), (30068, 63697), (30154, 64235), (97016, 58716), (94366, 36592), (1592, 16261), (87985, 52102), (12554, 23652), (15909, 25292), (2527, 91531), (92139, 36031), (28986, 30032), (3038, 56314), (32239, 26707), (15973, 34901), (70246, 39680), (82529, 38132), (45827, 74783), (53665, 64111), (55218, 84170), (20466, 16130), (55734, 71203), (31438, 96906), (66338, 85858), (35988, 68511), (78391, 15191), (80747, 59213), (5357, 11546), (16822, 16607), (36607, 41106), (74949, 30739), (45726, 64887), (1524, 54847), (37371, 89195), (28726, 27788), (22600, 44777), (53999, 63625), (84304, 98338), (49260, 76480), (74564, 53907), (89867, 97096), (60157, 61299), (17165, 10146), (56334, 36268), (62114, 49222), (22715, 23620), (42830, 11539), (41091, 69151), (75471, 68364), (18681, 43249), (42738, 63219), (35474, 98454), (76815, 46024), (66310, 36521), (86095, 77013), (63693, 77319), (80731, 63031), (95478, 92387), (23787, 63724), (46299, 68994), (4800, 2460), (9663, 80639), (77231, 85814), (81615, 11311), (35638, 27340), (13598, 14322), (30657, 17238), (90957, 96846), (69962, 52140), (41681, 65962), (96836, 58177), (36190, 11623), (4231, 40500), (43049, 41949), (71177, 98492), (30193, 39750), (19744, 33204), (63358, 30210), (45638, 58918), (43641, 38741), (35598, 40932), (33238, 36236), (50835, 20968), (25099, 34071), (84986, 88456), (35333, 1529), (79771, 23985), (647, 61658), (9424, 11743), (77766, 31528), (77811, 86973), (76403, 74377), (55568, 79251), (68858, 20762), (68520, 66773), (93598, 89823), (8080, 82539), (87760, 52247), (25191, 16905), (17837, 8339), (85177, 59050), (51680, 77374), (3287, 43018), (43479, 62141), (34909, 46322), (11869, 5885), (96193, 58417), (101, 47460), (34937, 88582), (83216, 88388), (28571, 15292), (66683, 62613), (34478, 8924), (2680, 89973), (62438, 44460), (11724, 4791), (5383, 72888), (88206, 67586), (8124, 21690), (28779, 75789), (66791, 4757), (6176, 47760), (6403, 78084), (78122, 35446), (99494, 73608), (39691, 89098), (59182, 19484), (25389, 98963), (96487, 3692), (76222, 67381), (21199, 50358), (95998, 58137), (28777, 43913), (14176, 60117), (52257, 81703), (14604, 13438), (71301, 14401), (19758, 66914), (15506, 29873), (87205, 29449), (93295, 15930), (63651, 11287), (19785, 15966), (30795, 75112), (69462, 37655), (18793, 85764), (36240, 31236), (98153, 73724), (72491, 4223), (66930, 35048), (25686, 13269), (13940, 13259), (69163, 11235), (1183, 86961), (54323, 67315), (85044, 60872), (48875, 3683), (43052, 92861), (87574, 32969), (92552, 80564), (94832, 47682), (72011, 80994), (60182, 917), (97788, 34169), (66432, 47940), (87468, 80954), (35385, 68758), (50555, 63710), (55311, 44337), (87065, 26514), (84581, 98736), (23212, 56499), (75120, 72447), (56087, 38285), (58171, 45629), (28401, 44319), (70432, 27883), (18891, 14646), (26206, 49924), (79957, 44914), (56064, 27529), (99090, 29197), (49435, 340), (53525, 65601), (76998, 88349), (50416, 70860), (42506, 75290), (34024, 13295), (86663, 46523), (88814, 231), (57809, 21), (84914, 84771), (43042, 66892), (17288, 33908), (4934, 63195), (50590, 1516), (97843, 80208), (20091, 86717), (71566, 15929), (19531, 23634), (41646, 45549), (89226, 82902), (96683, 63386), (31072, 53788), (51135, 41099), (78912, 65609), (36094, 23603), (88403, 51455), (73795, 47066), (26448, 82852), (22829, 2894), (30041, 92548), (27733, 20608), (70180, 19892), (51650, 63440), (76328, 13666), (40514, 6677), (2786, 51059), (40809, 16499), (10857, 82541), (78221, 61067), (17982, 51969), (85369, 66965), (47153, 47149), (43965, 75796), (82725, 60767), (42407, 97249), (51475, 81224), (60957, 89414), (33065, 21663), (36601, 5290), (95842, 67301), (64630, 60398), (55212, 35638), (41750, 44235), (75260, 82400), (91291, 25843), (6477, 8311), (14919, 52306), (66220, 33180), (45736, 2313), (37450, 64444), (98614, 61344), (75007, 50946), (56701, 28117), (66632, 5174), (92323, 76613), (6796, 73695), (33696, 76280), (86876, 5614), (50863, 67993), (36068, 17049), (91912, 34271), (70706, 1904), (97798, 41117), (68154, 72483), (83862, 25578), (61643, 17204), (69974, 64232), (77926, 19637), (64901, 88988), (71424, 91703), (91655, 17147), (46872, 56530), (44189, 98087), (95939, 54420), (72651, 68785), (67624, 84875), (92587, 87663), (65275, 81256), (53798, 2506), (14702, 3638), (71291, 50452), (14909, 13903), (66965, 26606), (14127, 60345), (35306, 1738), (77234, 10468), (53521, 41218), (80681, 82583), (44227, 26521), (32263, 21482), (82270, 56963), (50580, 80567), (11593, 22346), (20074, 26867), (73126, 28667), (62996, 24317), (20295, 57163), (1506, 57668), (69567, 45236), (43366, 26001), (88052, 40181), (1599, 89349), (36789, 1579), (39895, 46673), (30381, 3206), (31723, 5625), (19252, 31317), (16932, 77149), (48794, 34409), (55986, 30328), (47551, 75088), (57363, 78365), (95221, 63385), (26449, 5733), (96588, 53077), (52980, 41140), (8187, 85947), (36723, 26520), (23579, 38909), (33350, 19275), (63930, 19357), (43536, 59941), (31117, 77322), (44638, 94812), (44730, 99097), (95108, 48170), (57813, 49503), (79959, 89436), (86980, 62031), (8275, 44009), (36666, 94645), (22064, 38882), (40471, 16939), (31156, 11337), (13101, 96977), (17906, 26835), (89861, 51405), (73369, 67946), (99141, 58572), (27131, 98703), (15900, 43412), (51768, 93125), (78579, 46689), (23029, 13895), (60870, 55830), (22553, 8236), (76449, 96207), (83766, 51024), (27630, 50614), (53484, 90104), (77626, 21944), (46755, 41583), (53616, 34240), (94159, 44415), (13914, 90059), (44387, 89012), (27499, 64579), (83415, 30809), (77558, 82619), (88880, 9814), (8466, 4424), (43598, 91921), (24695, 3349), (46295, 65208), (51256, 82461), (49126, 93012), (16186, 96585), (43284, 22655), (93130, 90393), (77495, 34372), (85509, 65856), (86662, 61906), (50988, 44393), (29828, 17737), (91651, 35308), (29796, 49716), (14019, 87751), (29688, 71207), (82845, 19100), (11989, 50132), (21158, 99905), (54732, 42547), (32314, 12851), (46405, 43794), (87849, 45643), (53524, 21212), (61925, 75491), (12498, 21937), (30185, 69475), (48421, 52487), (15112, 90935), (33187, 17801), (61704, 25514), (17889, 23917), (18758, 57197), (7693, 47232), (47905, 24618), (11494, 78950), (95662, 54561), (8075, 33909), (90427, 46065), (73962, 19821), (50691, 79400), (58218, 4881), (94106, 2509), (60633, 55169), (49600, 83054), (23339, 13270), (70262, 58946), (48417, 97266), (27629, 46905), (74465, 75514), (41687, 2564), (12814, 19492), (78899, 30168), (17745, 35206), (37972, 35296), (22288, 80001),\ndiff --git a/tests/queries/0_stateless/00945_bloom_filter_index.sql b/tests/queries/0_stateless/00945_bloom_filter_index.sql\nindex f45c4c042907..d72f5ad1c6da 100644\n--- a/tests/queries/0_stateless/00945_bloom_filter_index.sql\n+++ b/tests/queries/0_stateless/00945_bloom_filter_index.sql\n@@ -14,10 +14,10 @@ SELECT COUNT() FROM single_column_bloom_filter WHERE i32 IN (1, 2) SETTINGS max_\n SELECT COUNT() FROM single_column_bloom_filter WHERE (i32, i32) IN ((1, 2), (2, 3)) SETTINGS max_rows_to_read = 6;\n SELECT COUNT() FROM single_column_bloom_filter WHERE (i32, i64) IN ((1, 1), (2, 2)) SETTINGS max_rows_to_read = 6;\n SELECT COUNT() FROM single_column_bloom_filter WHERE (i64, (i64, i32)) IN ((1, (1, 1)), (2, (2, 2))) SETTINGS max_rows_to_read = 6;\n-SELECT COUNT() FROM single_column_bloom_filter WHERE i32 IN (SELECT arrayJoin([toInt32(1), toInt32(2)])) SETTINGS max_rows_to_read = 6;\n-SELECT COUNT() FROM single_column_bloom_filter WHERE (i32, i32) IN (SELECT arrayJoin([(toInt32(1), toInt32(2)), (toInt32(2), toInt32(3))])) SETTINGS max_rows_to_read = 6;\n-SELECT COUNT() FROM single_column_bloom_filter WHERE (i32, i64) IN (SELECT arrayJoin([(toInt32(1), toUInt64(1)), (toInt32(2), toUInt64(2))])) SETTINGS max_rows_to_read = 6;\n-SELECT COUNT() FROM single_column_bloom_filter WHERE (i64, (i64, i32)) IN (SELECT arrayJoin([(toUInt64(1), (toUInt64(1), toInt32(1))), (toUInt64(2), (toUInt64(2), toInt32(2)))])) SETTINGS max_rows_to_read = 6;\n+SELECT COUNT() FROM single_column_bloom_filter WHERE i32 IN (SELECT arrayJoin([toInt32(1), toInt32(2)])) SETTINGS max_rows_to_read = 7;\n+SELECT COUNT() FROM single_column_bloom_filter WHERE (i32, i32) IN (SELECT arrayJoin([(toInt32(1), toInt32(2)), (toInt32(2), toInt32(3))])) SETTINGS max_rows_to_read = 7;\n+SELECT COUNT() FROM single_column_bloom_filter WHERE (i32, i64) IN (SELECT arrayJoin([(toInt32(1), toUInt64(1)), (toInt32(2), toUInt64(2))])) SETTINGS max_rows_to_read = 7;\n+SELECT COUNT() FROM single_column_bloom_filter WHERE (i64, (i64, i32)) IN (SELECT arrayJoin([(toUInt64(1), (toUInt64(1), toInt32(1))), (toUInt64(2), (toUInt64(2), toInt32(2)))])) SETTINGS max_rows_to_read = 7;\n WITH (1, 2) AS liter_prepared_set SELECT COUNT() FROM single_column_bloom_filter WHERE i32 IN liter_prepared_set SETTINGS max_rows_to_read = 6;\n WITH ((1, 2), (2, 3)) AS liter_prepared_set SELECT COUNT() FROM single_column_bloom_filter WHERE (i32, i32) IN liter_prepared_set SETTINGS max_rows_to_read = 6;\n WITH ((1, 1), (2, 2)) AS liter_prepared_set SELECT COUNT() FROM single_column_bloom_filter WHERE (i32, i64) IN liter_prepared_set SETTINGS max_rows_to_read = 6;\ndiff --git a/tests/queries/0_stateless/01064_incremental_streaming_from_2_src_with_feedback.sql b/tests/queries/0_stateless/01064_incremental_streaming_from_2_src_with_feedback.sql\nindex a653206fe18f..0bc5fcd1db84 100644\n--- a/tests/queries/0_stateless/01064_incremental_streaming_from_2_src_with_feedback.sql\n+++ b/tests/queries/0_stateless/01064_incremental_streaming_from_2_src_with_feedback.sql\n@@ -89,8 +89,11 @@ INSERT INTO checkouts SELECT number as id, '2000-01-01 10:00:00' from numbers(50\n -- by this time we should have 3 parts for target_table because of prev inserts\n -- and we plan to make two more inserts. With index_granularity=128 and max id=1000\n -- we expect to read not more than:\n+--      1000 rows read from numbers(1000) in the INSERT itself\n+--      1000 rows in the `IN (SELECT id FROM table)` in the mat views\n --      (1000/128) marks per part * (3 + 2) parts * 128 granularity = 5120 rows\n-set max_rows_to_read = 5120;\n+--      Total: 7120\n+set max_rows_to_read = 7120;\n \n INSERT INTO logins    SELECT number as id, '2000-01-01 11:00:00' from numbers(1000);\n INSERT INTO checkouts SELECT number as id, '2000-01-01 11:10:00' from numbers(1000);\n@@ -98,8 +101,8 @@ INSERT INTO checkouts SELECT number as id, '2000-01-01 11:10:00' from numbers(10\n -- by this time we should have 5 parts for target_table because of prev inserts\n -- and we plan to make two more inserts. With index_granularity=128 and max id=1\n -- we expect to read not more than:\n---      1 mark per part * (5 + 2) parts * 128 granularity = 896 rows\n-set max_rows_to_read = 896;\n+--      1 mark per part * (5 + 2) parts * 128 granularity + 1 (numbers(1)) = 897 rows\n+set max_rows_to_read = 897;\n \n INSERT INTO logins    SELECT number+2 as id, '2001-01-01 11:10:01' from numbers(1);\n INSERT INTO checkouts SELECT number+2 as id, '2001-01-01 11:10:02' from numbers(1);\ndiff --git a/tests/queries/0_stateless/01504_rocksdb.sql b/tests/queries/0_stateless/01504_rocksdb.sql\nindex 9f9e6c3b1aca..f79f31139fee 100644\n--- a/tests/queries/0_stateless/01504_rocksdb.sql\n+++ b/tests/queries/0_stateless/01504_rocksdb.sql\n@@ -34,7 +34,7 @@ INSERT INTO 01504_test_memory SELECT number % 77 AS k, SUM(number) AS value, (1,\n \n SELECT  A.a = B.a, A.b = B.b, A.c = B.c, A.d = B.d, A.e = B.e FROM ( SELECT 0 AS a, groupBitmapMerge(bm) AS b , SUM(k) AS c, SUM(value) AS d, SUM(dummy.1) AS e FROM 01504_test) A  ANY LEFT JOIN  (SELECT 0 AS a, groupBitmapMerge(bm) AS b , SUM(k) AS c, SUM(value) AS d, SUM(dummy.1) AS e FROM 01504_test_memory) B USING a ORDER BY a;\n \n-CREATE TEMPORARY TABLE keys AS SELECT * FROM numbers(1000);\n+CREATE TEMPORARY TABLE keys AS SELECT * FROM system.numbers LIMIT 1 OFFSET 4;\n \n SET max_rows_to_read = 2;\n SELECT dummy == (1,1.2) FROM 01504_test WHERE k IN (1, 3) OR k IN (1) OR k IN (3, 1) OR k IN [1] OR k IN [1, 3] ;\ndiff --git a/tests/queries/0_stateless/01583_const_column_in_set_index.sql b/tests/queries/0_stateless/01583_const_column_in_set_index.sql\nindex e40249eaf081..b781efb0f133 100644\n--- a/tests/queries/0_stateless/01583_const_column_in_set_index.sql\n+++ b/tests/queries/0_stateless/01583_const_column_in_set_index.sql\n@@ -3,7 +3,7 @@ drop table if exists insub;\n create table insub (i int, j int) engine MergeTree order by i settings index_granularity = 1;\n insert into insub select number a, a + 2 from numbers(10);\n \n-SET max_rows_to_read = 2;\n+SET max_rows_to_read = 12; -- 10 from numbers + 2 from table\n select * from insub where i in (select toInt32(3) from numbers(10));\n \n drop table if exists insub;\ndiff --git a/tests/queries/0_stateless/01585_use_index_for_global_in.sql b/tests/queries/0_stateless/01585_use_index_for_global_in.sql\nindex a0a5b90ac1f7..1dd7609350fd 100644\n--- a/tests/queries/0_stateless/01585_use_index_for_global_in.sql\n+++ b/tests/queries/0_stateless/01585_use_index_for_global_in.sql\n@@ -8,10 +8,12 @@ create table xp_d as xp engine Distributed(test_shard_localhost, currentDatabase\n \n insert into xp select number, number + 2 from numbers(10);\n \n-set max_rows_to_read = 2;\n+set max_rows_to_read = 4; -- 2 from numbers, 2 from tables\n select * from xp where i in (select * from numbers(2));\n select * from xp where i global in (select * from numbers(2));\n select * from xp_d where i in (select * from numbers(2));\n+\n+set max_rows_to_read = 6; -- 2 from numbers, 2 from GLOBAL temp table (pushed from numbers), 2 from local xp\n select * from xp_d where i global in (select * from numbers(2));\n \n drop table if exists xp;\ndiff --git a/tests/queries/0_stateless/01585_use_index_for_global_in_with_null.reference b/tests/queries/0_stateless/01585_use_index_for_global_in_with_null.reference\nindex de0116f9eaa1..0cb1993057fd 100644\n--- a/tests/queries/0_stateless/01585_use_index_for_global_in_with_null.reference\n+++ b/tests/queries/0_stateless/01585_use_index_for_global_in_with_null.reference\n@@ -14,6 +14,14 @@\n 1\t3\n 0\t2\n 1\t3\n+0\t2\n+1\t3\n+0\t2\n+1\t3\n+0\t2\n+1\t3\n+0\t2\n+1\t3\n \\N\t100\n \\N\t100\n \\N\t100\ndiff --git a/tests/queries/0_stateless/01585_use_index_for_global_in_with_null.sql b/tests/queries/0_stateless/01585_use_index_for_global_in_with_null.sql\nindex 6129c92c888a..d4147a445ec3 100644\n--- a/tests/queries/0_stateless/01585_use_index_for_global_in_with_null.sql\n+++ b/tests/queries/0_stateless/01585_use_index_for_global_in_with_null.sql\n@@ -12,17 +12,29 @@ insert into xp select null, 100;\n optimize table xp final;\n \n set max_rows_to_read = 2;\n+select * from xp where i in [0, 1];\n+select * from xp where i global in [0, 1];\n+select * from xp_d where i in [0, 1];\n+select * from xp_d where i global in [0, 1];\n+\n+set max_rows_to_read = 4; -- 2 in the subquery, 2 in the query itself\n select * from xp where i in (select * from numbers(2));\n select * from xp where i global in (select * from numbers(2));\n select * from xp_d where i in (select * from numbers(2));\n+\n+set max_rows_to_read = 6; -- 2 subquery, 2 from global temp table (GLOBAL IN), 2 from local xp table\n select * from xp_d where i global in (select * from numbers(2));\n \n set transform_null_in = 1;\n+set max_rows_to_read = 4; -- 2 in the subquery, 2 in the query itself\n select * from xp where i in (select * from numbers(2));\n select * from xp where i global in (select * from numbers(2));\n select * from xp_d where i in (select * from numbers(2));\n+\n+set max_rows_to_read = 6; -- 2 subquery, 2 from global temp table (GLOBAL IN), 2 from local xp table\n select * from xp_d where i global in (select * from numbers(2));\n \n+set max_rows_to_read = 0; -- No rows should be read\n select * from xp where i in (null);\n select * from xp where i global in (null);\n select * from xp_d where i in (null);\ndiff --git a/tests/queries/0_stateless/01748_partition_id_pruning.sql b/tests/queries/0_stateless/01748_partition_id_pruning.sql\nindex 17a405e17ade..e0d45884c600 100644\n--- a/tests/queries/0_stateless/01748_partition_id_pruning.sql\n+++ b/tests/queries/0_stateless/01748_partition_id_pruning.sql\n@@ -8,12 +8,12 @@ set max_rows_to_read = 3;\n \n select * from x where _partition_id = partitionId(1);\n \n-set max_rows_to_read = 4; -- one row for subquery\n+set max_rows_to_read = 5; -- one row for subquery + subquery\n \n select * from x where _partition_id in (select partitionId(number + 1) from numbers(1));\n \n -- trivial count optimization test\n-set max_rows_to_read = 1; -- one row for subquery\n+set max_rows_to_read = 2; -- one row for subquery + subquery itself\n select count() from x where _partition_id in (select partitionId(number + 1) from numbers(1));\n \n drop table x;\ndiff --git a/tests/queries/0_stateless/01927_query_views_log_current_database.reference b/tests/queries/0_stateless/01927_query_views_log_current_database.reference\nindex ff9eca2d97fc..eaa1e98c55c3 100644\n--- a/tests/queries/0_stateless/01927_query_views_log_current_database.reference\n+++ b/tests/queries/0_stateless/01927_query_views_log_current_database.reference\n@@ -1,70 +1,94 @@\n Row 1:\n \u2500\u2500\u2500\u2500\u2500\u2500\n-stage:        Query log rows\n-read_rows:    100\n-written_rows: 201\n-databases:    ['_table_function','default']\n-tables:       ['_table_function.numbers','default.table_a','default.table_b','default.table_b_live_view','default.table_c']\n-views:        ['default.matview_a_to_b','default.matview_b_to_c','default.table_b_live_view']\n-sleep_calls:  200\n-sleep_us:     298\n+stage:                Query log rows\n+read_rows:            400\n+written_rows:         201\n+databases:            ['_table_function','default']\n+tables:               ['_table_function.numbers','default.table_a','default.table_b','default.table_b_live_view','default.table_c']\n+views:                ['default.matview_a_to_b','default.matview_b_to_c','default.table_b_live_view']\n+sleep_calls:          200\n+sleep_us:             298\n+profile_select_rows:  400\n+profile_select_bytes: 5200\n+profile_insert_rows:  201\n+profile_insert_bytes: 2808\n Row 1:\n \u2500\u2500\u2500\u2500\u2500\u2500\n-stage:        Depending views\n-view_name:    default.matview_a_to_b\n-view_type:    Materialized\n-status:       QueryFinish\n-view_target:  default.table_b\n-view_query:   SELECT toFloat64(a) AS a, b + sleepEachRow(0.000001) AS count FROM default.table_a\n-read_rows:    100\n-written_rows: 100\n-sleep_calls:  100\n-sleep_us:     99\n+stage:                Depending views\n+view_name:            default.matview_a_to_b\n+view_type:            Materialized\n+status:               QueryFinish\n+view_target:          default.table_b\n+view_query:           SELECT toFloat64(a) AS a, b + sleepEachRow(0.000001) AS count FROM default.table_a\n+read_rows:            100\n+written_rows:         100\n+sleep_calls:          100\n+sleep_us:             99\n+profile_select_rows:  100\n+profile_select_bytes: 2000\n+profile_insert_rows:  100\n+profile_insert_bytes: 800\n \n Row 2:\n \u2500\u2500\u2500\u2500\u2500\u2500\n-stage:        Depending views\n-view_name:    default.matview_b_to_c\n-view_type:    Materialized\n-status:       QueryFinish\n-view_target:  default.table_c\n-view_query:   SELECT sum(a + sleepEachRow(0.000002)) AS a FROM default.table_b\n-read_rows:    100\n-written_rows: 1\n-sleep_calls:  100\n-sleep_us:     199\n+stage:                Depending views\n+view_name:            default.matview_b_to_c\n+view_type:            Materialized\n+status:               QueryFinish\n+view_target:          default.table_c\n+view_query:           SELECT sum(a + sleepEachRow(0.000002)) AS a FROM default.table_b\n+read_rows:            100\n+written_rows:         1\n+sleep_calls:          100\n+sleep_us:             199\n+profile_select_rows:  100\n+profile_select_bytes: 800\n+profile_insert_rows:  1\n+profile_insert_bytes: 8\n \n Row 3:\n \u2500\u2500\u2500\u2500\u2500\u2500\n-stage:        Depending views\n-view_name:    default.table_b_live_view\n-view_type:    Live\n-status:       QueryFinish\n-view_target:  default.table_b_live_view\n-view_query:   SELECT sum(a + b) FROM default.table_b\n-read_rows:    100\n-written_rows: 0\n-sleep_calls:  0\n-sleep_us:     0\n+stage:                Depending views\n+view_name:            default.table_b_live_view\n+view_type:            Live\n+status:               QueryFinish\n+view_target:          default.table_b_live_view\n+view_query:           SELECT sum(a + b) FROM default.table_b\n+read_rows:            100\n+written_rows:         0\n+sleep_calls:          0\n+sleep_us:             0\n+profile_select_rows:  100\n+profile_select_bytes: 1600\n+profile_insert_rows:  0\n+profile_insert_bytes: 0\n Row 1:\n \u2500\u2500\u2500\u2500\u2500\u2500\n-stage:        Query log rows 2\n-read_rows:    50\n-written_rows: 100\n-databases:    ['_table_function','default']\n-tables:       ['_table_function.numbers','default.table_d','default.table_e','default.table_f']\n-views:        ['default.matview_join_d_e']\n-sleep_calls:  50\n-sleep_us:     150\n+stage:                Query log rows 2\n+read_rows:            100\n+written_rows:         100\n+databases:            ['_table_function','default']\n+tables:               ['_table_function.numbers','default.table_d','default.table_e','default.table_f']\n+views:                ['default.matview_join_d_e']\n+sleep_calls:          50\n+sleep_us:             150\n+profile_select_rows:  100\n+profile_select_bytes: 800\n+profile_insert_rows:  100\n+profile_insert_bytes: 1600\n Row 1:\n \u2500\u2500\u2500\u2500\u2500\u2500\n-stage:        Depending views 2\n-view_name:    default.matview_join_d_e\n-view_type:    Materialized\n-status:       QueryFinish\n-view_target:  default.table_f\n-view_query:   SELECT table_d.a AS a, table_e.count + sleepEachRow(0.000003) AS count FROM default.table_d LEFT JOIN default.table_e ON table_d.a = table_e.a\n-read_rows:    50\n-written_rows: 50\n-sleep_calls:  50\n-sleep_us:     150\n+stage:                Depending views 2\n+view_name:            default.matview_join_d_e\n+view_type:            Materialized\n+status:               QueryFinish\n+view_target:          default.table_f\n+view_query:           SELECT table_d.a AS a, table_e.count + sleepEachRow(0.000003) AS count FROM default.table_d LEFT JOIN default.table_e ON table_d.a = table_e.a\n+read_rows:            50\n+written_rows:         50\n+sleep_calls:          50\n+sleep_us:             150\n+profile_select_rows:  50\n+profile_select_bytes: 400\n+profile_insert_rows:  50\n+profile_insert_bytes: 800\ndiff --git a/tests/queries/0_stateless/01927_query_views_log_current_database.sql b/tests/queries/0_stateless/01927_query_views_log_current_database.sql\nindex 40ab8c8e16a3..fbfbeab01672 100644\n--- a/tests/queries/0_stateless/01927_query_views_log_current_database.sql\n+++ b/tests/queries/0_stateless/01927_query_views_log_current_database.sql\n@@ -45,7 +45,11 @@ SELECT\n     arraySort(tables) as tables,\n     arraySort(views) as views,\n     ProfileEvents['SleepFunctionCalls'] as sleep_calls,\n-    ProfileEvents['SleepFunctionMicroseconds'] as sleep_us\n+    ProfileEvents['SleepFunctionMicroseconds'] as sleep_us,\n+    ProfileEvents['SelectedRows'] as profile_select_rows,\n+    ProfileEvents['SelectedBytes'] as profile_select_bytes,\n+    ProfileEvents['InsertedRows'] as profile_insert_rows,\n+    ProfileEvents['InsertedBytes'] as profile_insert_bytes\n FROM system.query_log\n WHERE query like '-- INSERT 1%INSERT INTO table_a%'\n   AND current_database = currentDatabase()\n@@ -62,7 +66,11 @@ SELECT\n     read_rows,\n     written_rows,\n     ProfileEvents['SleepFunctionCalls'] as sleep_calls,\n-    ProfileEvents['SleepFunctionMicroseconds'] as sleep_us\n+    ProfileEvents['SleepFunctionMicroseconds'] as sleep_us,\n+    ProfileEvents['SelectedRows'] as profile_select_rows,\n+    ProfileEvents['SelectedBytes'] as profile_select_bytes,\n+    ProfileEvents['InsertedRows'] as profile_insert_rows,\n+    ProfileEvents['InsertedBytes'] as profile_insert_bytes\n FROM system.query_views_log\n WHERE initial_query_id =\n       (\n@@ -85,7 +93,11 @@ SELECT\n     arraySort(tables) as tables,\n     arraySort(views) as views,\n     ProfileEvents['SleepFunctionCalls'] as sleep_calls,\n-    ProfileEvents['SleepFunctionMicroseconds'] as sleep_us\n+    ProfileEvents['SleepFunctionMicroseconds'] as sleep_us,\n+    ProfileEvents['SelectedRows'] as profile_select_rows,\n+    ProfileEvents['SelectedBytes'] as profile_select_bytes,\n+    ProfileEvents['InsertedRows'] as profile_insert_rows,\n+    ProfileEvents['InsertedBytes'] as profile_insert_bytes\n FROM system.query_log\n WHERE query like '-- INSERT 2%INSERT INTO table_d%'\n   AND current_database = currentDatabase()\n@@ -102,7 +114,11 @@ SELECT\n     read_rows,\n     written_rows,\n     ProfileEvents['SleepFunctionCalls'] as sleep_calls,\n-    ProfileEvents['SleepFunctionMicroseconds'] as sleep_us\n+    ProfileEvents['SleepFunctionMicroseconds'] as sleep_us,\n+    ProfileEvents['SelectedRows'] as profile_select_rows,\n+    ProfileEvents['SelectedBytes'] as profile_select_bytes,\n+    ProfileEvents['InsertedRows'] as profile_insert_rows,\n+    ProfileEvents['InsertedBytes'] as profile_insert_bytes\n FROM system.query_views_log\n WHERE initial_query_id =\n       (\ndiff --git a/tests/queries/0_stateless/02125_query_views_log.reference b/tests/queries/0_stateless/02125_query_views_log.reference\nindex 3ae4af9b4d0f..fac70027113e 100644\n--- a/tests/queries/0_stateless/02125_query_views_log.reference\n+++ b/tests/queries/0_stateless/02125_query_views_log.reference\n@@ -18,7 +18,7 @@ written_bytes: 4000000\n select read_rows, read_bytes, written_rows, written_bytes from system.query_log where type = 'QueryFinish' and query_kind = 'Insert' and current_database = currentDatabase() format Vertical;\n Row 1:\n \u2500\u2500\u2500\u2500\u2500\u2500\n-read_rows:     1000000\n-read_bytes:    8000000\n+read_rows:     3000000\n+read_bytes:    16000000\n written_rows:  3000000\n written_bytes: 12000000\ndiff --git a/tests/queries/0_stateless/02136_kill_scalar_queries.reference b/tests/queries/0_stateless/02136_kill_scalar_queries.reference\nnew file mode 100644\nindex 000000000000..a598447cff52\n--- /dev/null\n+++ b/tests/queries/0_stateless/02136_kill_scalar_queries.reference\n@@ -0,0 +1,2 @@\n+finished\tdefault_TEST02132KILL_QUERY1\tdefault\tselect (SELECT max(number) from system.numbers) + 1;\n+finished\tdefault_TEST02132KILL_QUERY2\tdefault\tSELECT (SELECT number FROM system.numbers WHERE number = 1000000000000);\ndiff --git a/tests/queries/0_stateless/02136_kill_scalar_queries.sh b/tests/queries/0_stateless/02136_kill_scalar_queries.sh\nnew file mode 100755\nindex 000000000000..382f6555c667\n--- /dev/null\n+++ b/tests/queries/0_stateless/02136_kill_scalar_queries.sh\n@@ -0,0 +1,22 @@\n+#!/usr/bin/env bash\n+# Ref: https://github.com/ClickHouse/ClickHouse/issues/1576\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+function wait_for_query_to_start()\n+{\n+    while [[ $($CLICKHOUSE_CURL -sS \"$CLICKHOUSE_URL\" -d \"SELECT count() FROM system.processes WHERE query_id = '$1'\") == 0 ]]; do sleep 0.1; done\n+}\n+\n+QUERY_1_ID=\"${CLICKHOUSE_DATABASE}_TEST02132KILL_QUERY1\"\n+(${CLICKHOUSE_CLIENT} --query_id=\"${QUERY_1_ID}\" --query='select (SELECT max(number) from system.numbers) + 1;'  2>&1 | grep -q \"Code: 394.\" || echo 'FAIL') &\n+wait_for_query_to_start \"${QUERY_1_ID}\"\n+${CLICKHOUSE_CLIENT} --query=\"KILL QUERY WHERE query_id='${QUERY_1_ID}' SYNC\"\n+\n+QUERY_2_ID=\"${CLICKHOUSE_DATABASE}_TEST02132KILL_QUERY2\"\n+(${CLICKHOUSE_CLIENT} --query_id=\"${QUERY_2_ID}\" --query='SELECT (SELECT number FROM system.numbers WHERE number = 1000000000000);'  2>&1 | grep -q \"Code: 394.\" || echo 'FAIL') &\n+wait_for_query_to_start \"${QUERY_2_ID}\"\n+${CLICKHOUSE_CLIENT} --query=\"KILL QUERY WHERE query_id='${QUERY_2_ID}' SYNC\"\n+\n+wait\ndiff --git a/tests/queries/0_stateless/02136_scalar_progress.reference b/tests/queries/0_stateless/02136_scalar_progress.reference\nnew file mode 100644\nindex 000000000000..21f6d3e00432\n--- /dev/null\n+++ b/tests/queries/0_stateless/02136_scalar_progress.reference\n@@ -0,0 +1,6 @@\n+< X-ClickHouse-Progress: {\"read_rows\":\"0\",\"read_bytes\":\"0\",\"written_rows\":\"0\",\"written_bytes\":\"0\",\"total_rows_to_read\":\"100000\"}\r\n+< X-ClickHouse-Progress: {\"read_rows\":\"65505\",\"read_bytes\":\"524040\",\"written_rows\":\"0\",\"written_bytes\":\"0\",\"total_rows_to_read\":\"100000\"}\r\n+< X-ClickHouse-Progress: {\"read_rows\":\"131010\",\"read_bytes\":\"1048080\",\"written_rows\":\"0\",\"written_bytes\":\"0\",\"total_rows_to_read\":\"100000\"}\r\n+< X-ClickHouse-Progress: {\"read_rows\":\"131011\",\"read_bytes\":\"1048081\",\"written_rows\":\"0\",\"written_bytes\":\"0\",\"total_rows_to_read\":\"100000\"}\r\n+< X-ClickHouse-Progress: {\"read_rows\":\"131011\",\"read_bytes\":\"1048081\",\"written_rows\":\"0\",\"written_bytes\":\"0\",\"total_rows_to_read\":\"100000\"}\r\n+< X-ClickHouse-Summary: {\"read_rows\":\"131011\",\"read_bytes\":\"1048081\",\"written_rows\":\"0\",\"written_bytes\":\"0\",\"total_rows_to_read\":\"100000\"}\r\ndiff --git a/tests/queries/0_stateless/02136_scalar_progress.sh b/tests/queries/0_stateless/02136_scalar_progress.sh\nnew file mode 100755\nindex 000000000000..4608031f83d7\n--- /dev/null\n+++ b/tests/queries/0_stateless/02136_scalar_progress.sh\n@@ -0,0 +1,7 @@\n+#!/usr/bin/env bash\n+# Ref: https://github.com/ClickHouse/ClickHouse/issues/1576\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CURL -sS \"${CLICKHOUSE_URL}&wait_end_of_query=1&send_progress_in_http_headers=1&http_headers_progress_interval_ms=0\" -d \"SELECT (SELECT max(number), count(number) FROM numbers(100000));\" -v 2>&1 | grep -E \"X-ClickHouse-Summary|X-ClickHouse-Progress\"\ndiff --git a/tests/queries/0_stateless/02136_scalar_read_rows_json.reference b/tests/queries/0_stateless/02136_scalar_read_rows_json.reference\nnew file mode 100644\nindex 000000000000..49020a4432f9\n--- /dev/null\n+++ b/tests/queries/0_stateless/02136_scalar_read_rows_json.reference\n@@ -0,0 +1,50 @@\n+#1\n+{\n+\t\"meta\":\n+\t[\n+\t\t{\n+\t\t\t\"name\": \"count()\",\n+\t\t\t\"type\": \"UInt64\"\n+\t\t}\n+\t],\n+\n+\t\"data\":\n+\t[\n+\t\t{\n+\t\t\t\"count()\": \"100\"\n+\t\t}\n+\t],\n+\n+\t\"rows\": 1,\n+\n+\t\"rows_before_limit_at_least\": 100,\n+\n+\t\"statistics\":\n+\t{\n+\t\t\"rows_read\": 100,\n+\t\t\"bytes_read\": 800\n+\t}\n+}\n+#2\n+{\n+\t\"meta\":\n+\t[\n+\t\t{\n+\t\t\t\"type\": \"Tuple(UInt64, UInt64)\"\n+\t\t}\n+\t],\n+\n+\t\"data\":\n+\t[\n+\t\t{\n+\t\t}\n+\t],\n+\n+\t\"rows\": 1,\n+\n+\t\"statistics\":\n+\t{\n+\t\t\"rows_read\": 131011,\n+\t\t\"bytes_read\": 1048081\n+\t}\n+}\ndiff --git a/tests/queries/0_stateless/02136_scalar_read_rows_json.sh b/tests/queries/0_stateless/02136_scalar_read_rows_json.sh\nnew file mode 100755\nindex 000000000000..d589cb600868\n--- /dev/null\n+++ b/tests/queries/0_stateless/02136_scalar_read_rows_json.sh\n@@ -0,0 +1,10 @@\n+#!/usr/bin/env bash\n+# Ref: https://github.com/ClickHouse/ClickHouse/issues/1576\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+echo \"#1\"\n+${CLICKHOUSE_CLIENT} --query='SELECT count() FROM numbers(100) FORMAT JSON;' | grep -a -v \"elapsed\"\n+echo \"#2\"\n+${CLICKHOUSE_CLIENT} --query='SELECT (SELECT max(number), count(number) FROM numbers(100000) as n) FORMAT JSON;' | grep -a -v \"elapsed\" | grep -v \"_subquery\"\ndiff --git a/tests/queries/0_stateless/02136_scalar_subquery_metrics.reference b/tests/queries/0_stateless/02136_scalar_subquery_metrics.reference\nnew file mode 100644\nindex 000000000000..7bef11d008f6\n--- /dev/null\n+++ b/tests/queries/0_stateless/02136_scalar_subquery_metrics.reference\n@@ -0,0 +1,9 @@\n+#02136_scalar_subquery_1\t999\n+#02136_scalar_subquery_2\t999\t0\n+#02136_scalar_subquery_3\t999\t999\n+#02136_scalar_subquery_4\t999\n+#02136_scalar_subquery_4\t999\n+1001\tSELECT \\'#02136_scalar_subquery_1\\', (SELECT max(number) FROM numbers(1000)) as n;\n+2001\tSELECT \\'#02136_scalar_subquery_2\\', (SELECT max(number) FROM numbers(1000)) as n, (SELECT min(number) FROM numbers(1000)) as n2;\n+1001\tSELECT \\'#02136_scalar_subquery_3\\', (SELECT max(number) FROM numbers(1000)) as n, (SELECT max(number) FROM numbers(1000)) as n2;\n+1002\tSELECT \\'#02136_scalar_subquery_4\\', (SELECT max(number) FROM numbers(1000)) as n FROM system.numbers LIMIT 2;\ndiff --git a/tests/queries/0_stateless/02136_scalar_subquery_metrics.sql b/tests/queries/0_stateless/02136_scalar_subquery_metrics.sql\nnew file mode 100644\nindex 000000000000..180610288aaa\n--- /dev/null\n+++ b/tests/queries/0_stateless/02136_scalar_subquery_metrics.sql\n@@ -0,0 +1,13 @@\n+SELECT '#02136_scalar_subquery_1', (SELECT max(number) FROM numbers(1000)) as n;\n+SELECT '#02136_scalar_subquery_2', (SELECT max(number) FROM numbers(1000)) as n, (SELECT min(number) FROM numbers(1000)) as n2;\n+SELECT '#02136_scalar_subquery_3', (SELECT max(number) FROM numbers(1000)) as n, (SELECT max(number) FROM numbers(1000)) as n2; -- Cached\n+SELECT '#02136_scalar_subquery_4', (SELECT max(number) FROM numbers(1000)) as n FROM system.numbers LIMIT 2; -- Cached\n+\n+SYSTEM FLUSH LOGS;\n+SELECT read_rows, query FROM system.query_log\n+WHERE\n+      event_date > yesterday()\n+  AND type = 'QueryFinish'\n+  AND current_database == currentDatabase()\n+  AND query LIKE 'SELECT ''#02136_scalar_subquery_%'\n+ORDER BY query ASC;\n",
  "problem_statement": "[RFC] How to count read rows and bytes in scalar subqueries\nHi,\r\n\r\nAs you might be aware, ClickHouse currently doesn't count rows or bytes read/written in scalar subqueries, and it doesn't handle query cancellation or progress in them either.\r\n\r\nWhile working on being able to cancel scalar queries in https://github.com/ClickHouse/ClickHouse/pull/32271 it turns out that everything was related and once you are able to cancel them you get progress reports, rows read/written and so on all with the same change.\r\n\r\n@KochetovNicolai pointed out that we would be breaking backwards compatibility since some people might be relying in the fact that rows read by the scalar subqueries are not accounted in the final report or the limits, in fact there are many tests that needed to be changed for this reason.\r\n\r\nParaphrasing his comments, therea re a few things that we can do:\r\n```\r\n* Keep ignoring max_rows_to_read for subqueries and discuss possible changes in a separate pr. It's the easiest one, I would be happy to merge this pr. (There could be other settings which are not obvious, and we should be ready to default them too).\r\n* Mark this pr as backward incompatibly, and introduce another one setting to roll back to old behaviour (which we can remove probably in a few month). (I don't like new settings).\r\n* Also add a new setting, but keep current behaviour as default.\r\n* Separate settings for subqueries (which may be zero or same for query by default).\r\n```\r\n\r\nPersonally I would change the behaviour without any settings to turn it off for 2 reasons:\r\n* I think that this is a good improvement and something desirable in all cases. Reporting read rows indepedently of where they were read (CTE, main query, subqueries, scalar subqueries) should be the way to go.\r\n* It keeps the code clean. Adding more settings involves either complicating the code or breaking the ability to KILL scalar subqueries.\r\n\r\nWhat does the community think? Do somebody need to keep the old behaviour and wouldn't be able to handle the change?\n",
  "hints_text": "",
  "created_at": "2021-12-06T12:19:30Z",
  "modified_files": [
    "src/Core/ExternalTable.cpp",
    "src/Formats/FormatFactory.cpp",
    "src/Interpreters/ProcessList.cpp",
    "src/Interpreters/ProcessList.h",
    "src/Interpreters/ThreadStatusExt.cpp",
    "src/Interpreters/executeQuery.cpp",
    "src/Processors/Executors/PipelineExecutor.h",
    "src/Processors/QueryPlan/BuildQueryPipelineSettings.cpp",
    "src/Processors/QueryPlan/BuildQueryPipelineSettings.h",
    "src/Processors/QueryPlan/QueryPlan.cpp",
    "src/Processors/Sources/SourceWithProgress.cpp",
    "src/Processors/Transforms/CountingTransform.cpp",
    "src/Processors/Transforms/buildPushingToViewsChain.cpp",
    "src/QueryPipeline/QueryPipelineBuilder.cpp"
  ],
  "modified_test_files": [
    "src/Processors/tests/gtest_exception_on_incorrect_pipeline.cpp",
    "tests/performance/set_index.xml",
    "tests/queries/0_stateless/00945_bloom_filter_index.sql",
    "tests/queries/0_stateless/01064_incremental_streaming_from_2_src_with_feedback.sql",
    "tests/queries/0_stateless/01504_rocksdb.sql",
    "tests/queries/0_stateless/01583_const_column_in_set_index.sql",
    "tests/queries/0_stateless/01585_use_index_for_global_in.sql",
    "tests/queries/0_stateless/01585_use_index_for_global_in_with_null.reference",
    "tests/queries/0_stateless/01585_use_index_for_global_in_with_null.sql",
    "tests/queries/0_stateless/01748_partition_id_pruning.sql",
    "tests/queries/0_stateless/01927_query_views_log_current_database.reference",
    "tests/queries/0_stateless/01927_query_views_log_current_database.sql",
    "tests/queries/0_stateless/02125_query_views_log.reference",
    "b/tests/queries/0_stateless/02136_kill_scalar_queries.reference",
    "b/tests/queries/0_stateless/02136_kill_scalar_queries.sh",
    "b/tests/queries/0_stateless/02136_scalar_progress.reference",
    "b/tests/queries/0_stateless/02136_scalar_progress.sh",
    "b/tests/queries/0_stateless/02136_scalar_read_rows_json.reference",
    "b/tests/queries/0_stateless/02136_scalar_read_rows_json.sh",
    "b/tests/queries/0_stateless/02136_scalar_subquery_metrics.reference",
    "b/tests/queries/0_stateless/02136_scalar_subquery_metrics.sql"
  ]
}