{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 78505,
  "instance_id": "ClickHouse__ClickHouse-78505",
  "issue_numbers": [
    "78257"
  ],
  "base_commit": "6dc235fcd03e3a0fca44478c1f8c52054cfa1edd",
  "patch": "diff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp\nindex 99fb4f8040c0..12713604f8be 100644\n--- a/src/Interpreters/InterpreterSelectQuery.cpp\n+++ b/src/Interpreters/InterpreterSelectQuery.cpp\n@@ -2652,8 +2652,6 @@ void InterpreterSelectQuery::executeFetchColumns(QueryProcessingStage::Enum proc\n     else if (storage)\n     {\n         /// Table.\n-        if (max_streams == 0)\n-            max_streams = 1;\n \n         /// If necessary, we request more sources than the number of threads - to distribute the work evenly over the threads.\n         if (max_streams > 1 && !is_sync_remote)\n@@ -2668,6 +2666,9 @@ void InterpreterSelectQuery::executeFetchColumns(QueryProcessingStage::Enum proc\n                     streams_with_ratio);\n         }\n \n+        if (max_streams == 0)\n+            max_streams = 1;\n+\n         auto & prewhere_info = analysis_result.prewhere_info;\n \n         if (prewhere_info)\ndiff --git a/src/Planner/PlannerJoinTree.cpp b/src/Planner/PlannerJoinTree.cpp\nindex a87187af08c3..7eb96c06d6a0 100644\n--- a/src/Planner/PlannerJoinTree.cpp\n+++ b/src/Planner/PlannerJoinTree.cpp\n@@ -771,9 +771,6 @@ JoinTreeQueryPlan buildQueryPlanForTableExpression(QueryTreeNodePtr table_expres\n                     \"Setting 'max_block_size' cannot be zero\");\n         }\n \n-        if (max_streams == 0)\n-            max_streams = 1;\n-\n         /// If necessary, we request more sources than the number of threads - to distribute the work evenly over the threads\n         if (max_streams > 1 && !is_sync_remote)\n         {\n@@ -787,6 +784,9 @@ JoinTreeQueryPlan buildQueryPlanForTableExpression(QueryTreeNodePtr table_expres\n                     streams_with_ratio);\n         }\n \n+        if (max_streams == 0)\n+            max_streams = 1;\n+\n         if (table_node)\n             table_expression_query_info.table_expression_modifiers = table_node->getTableExpressionModifiers();\n         else\ndiff --git a/src/Processors/QueryPlan/ReadFromMergeTree.cpp b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\nindex 4b007f92a4fc..2435590950c0 100644\n--- a/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n+++ b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n@@ -1126,6 +1126,20 @@ Pipe ReadFromMergeTree::spreadMarkRangesAmongStreamsWithOrder(\n         return new_ranges;\n     };\n \n+    if (num_streams > 1)\n+    {\n+        /// Reduce num_streams if requested value is unnecessarily large.\n+        ///\n+        /// Additional increase of streams number in case of skewed parts, like it's\n+        /// done in `spreadMarkRangesAmongStreams` won't affect overall performance\n+        /// due to the single downstream `MergingSortedTransform`.\n+        if (info.sum_marks < num_streams * info.min_marks_for_concurrent_read && parts_with_ranges.size() < num_streams)\n+        {\n+            num_streams = std::max(\n+                (info.sum_marks + info.min_marks_for_concurrent_read - 1) / info.min_marks_for_concurrent_read, parts_with_ranges.size());\n+        }\n+    }\n+\n     const size_t min_marks_per_stream = (info.sum_marks - 1) / num_streams + 1;\n     bool need_preliminary_merge = (parts_with_ranges.size() > settings[Setting::read_in_order_two_level_merge_threshold]);\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03402_zero_streams_after_max_streams_to_max_threads_ratio.reference b/tests/queries/0_stateless/03402_zero_streams_after_max_streams_to_max_threads_ratio.reference\nnew file mode 100644\nindex 000000000000..e930be6a31bd\n--- /dev/null\n+++ b/tests/queries/0_stateless/03402_zero_streams_after_max_streams_to_max_threads_ratio.reference\n@@ -0,0 +1,7 @@\n+49.5\n+49.5\n+49.5\n+\n+0\n+0\n+0\ndiff --git a/tests/queries/0_stateless/03402_zero_streams_after_max_streams_to_max_threads_ratio.sql b/tests/queries/0_stateless/03402_zero_streams_after_max_streams_to_max_threads_ratio.sql\nnew file mode 100644\nindex 000000000000..c0a55d83d616\n--- /dev/null\n+++ b/tests/queries/0_stateless/03402_zero_streams_after_max_streams_to_max_threads_ratio.sql\n@@ -0,0 +1,16 @@\n+DROP TABLE IF EXISTS 03402_data;\n+\n+CREATE TABLE 03402_data (id UInt32) ENGINE = MergeTree ORDER BY id;\n+INSERT INTO 03402_data SELECT * FROM numbers(100);\n+\n+SELECT avg(id) FROM 03402_data SETTINGS max_threads = 4, max_streams_to_max_threads_ratio = 0;\n+SELECT avg(id) FROM 03402_data SETTINGS max_threads = 0, max_streams_to_max_threads_ratio = 0;\n+SELECT avg(id) FROM 03402_data SETTINGS max_threads = 2, max_streams_to_max_threads_ratio = 0.2;\n+\n+SELECT '';\n+\n+SELECT id FROM 03402_data ORDER BY id LIMIT 1 SETTINGS max_threads = 4, max_streams_to_max_threads_ratio = 0;\n+SELECT id FROM 03402_data ORDER BY id LIMIT 1 SETTINGS max_threads = 0, max_streams_to_max_threads_ratio = 0;\n+SELECT id FROM 03402_data ORDER BY id LIMIT 1 SETTINGS max_threads = 2, max_streams_to_max_threads_ratio = 0.2;\n+\n+DROP TABLE 03402_data;\ndiff --git a/tests/queries/0_stateless/03403_read_in_order_streams_memory_usage.reference b/tests/queries/0_stateless/03403_read_in_order_streams_memory_usage.reference\nnew file mode 100644\nindex 000000000000..d00491fd7e5b\n--- /dev/null\n+++ b/tests/queries/0_stateless/03403_read_in_order_streams_memory_usage.reference\n@@ -0,0 +1,1 @@\n+1\ndiff --git a/tests/queries/0_stateless/03403_read_in_order_streams_memory_usage.sql b/tests/queries/0_stateless/03403_read_in_order_streams_memory_usage.sql\nnew file mode 100644\nindex 000000000000..3e700fba9b90\n--- /dev/null\n+++ b/tests/queries/0_stateless/03403_read_in_order_streams_memory_usage.sql\n@@ -0,0 +1,20 @@\n+DROP TABLE IF EXISTS 03403_data;\n+CREATE TABLE 03403_data(id UInt32, val String) ENGINE = MergeTree ORDER BY id AS SELECT 1, 'test';\n+\n+SELECT *\n+FROM 03403_data\n+ORDER BY id\n+FORMAT Null\n+SETTINGS max_threads = 1024,\n+         max_streams_to_max_threads_ratio = 10000000;\n+\n+SYSTEM FLUSH LOGS query_log;\n+\n+SELECT memory_usage < 10_000_000\n+FROM system.query_log\n+WHERE Settings['max_streams_to_max_threads_ratio'] = '10000000'\n+  AND query like '%FROM 03403_data%'\n+  AND type = 'QueryFinish'\n+  AND current_database = currentDatabase();\n+\n+DROP TABLE 03403_data;\n",
  "problem_statement": "ReadFromMergeTree.cpp:1128:62: runtime error: division by zero\n### Describe the bug\n\nhttps://s3.amazonaws.com/clickhouse-test-reports/json.html?PR=77901&sha=26c5cf8fafb329471ae2a8105952b0125d8a993c&name_0=PR&name_1=AST%20fuzzer%20%28ubsan%29\n\n### How to reproduce\n\n```\nCREATE TABLE test_table__fuzz_5 (`id` UInt64, `value` Nullable(Date)) ENGINE = MergeTree ORDER BY id;\nINSERT INTO test_table__fuzz_5 Values (0, 0');\nSELECT DISTINCT * FROM test_table__fuzz_5 WHERE 1 % 60 SETTINGS max_threads = 1023, max_streams_to_max_threads_ratio = 0, enable_analyzer = 1;\n```\n\nSeems related to `max_streams_to_max_threads_ratio = 0`.\n\nFails since 24.10. `24.9.1.3278` is fine\n\n### Error message and/or stacktrace\n\n```\n$ clickhouse repro\n2025.03.25 18:57:41.099606 [ 518045 ] {} <Fatal> ClientBase: ########## Short fault info ############\n2025.03.25 18:57:41.123565 [ 518045 ] {} <Fatal> ClientBase: (version 25.4.1.1, build id: 989CB91466803EAFBCDD7AEE9B8CA271A31937BF, git hash: 6e9ca99bc754a2cedcef283dd6430dce93554e08, architecture: x86_64) (from thread 517475) Received signal 8\n2025.03.25 18:57:41.123572 [ 518045 ] {} <Fatal> ClientBase: Signal description: Arithmetic exception\n2025.03.25 18:57:41.123573 [ 518045 ] {} <Fatal> ClientBase: Integer divide by zero.\n2025.03.25 18:57:41.123578 [ 518045 ] {} <Fatal> ClientBase: Stack trace: 0x00005fe21c4f04e8 0x00005fe21c87f219 0x00007b5ab1003cd0 0x00005fe223fd2f2c 0x00005fe223fe4257 0x00005fe223fe61cf 0x00005fe223f790be 0x00005fe223faae1e 0x00005fe22167f6c7 0x00005fe22167f412 0x00005fe221a4b1b4 0x00005fe221a46773 0x00005fe2238e6b15 0x00005fe223871736 0x00005fe22386f8fb 0x00005fe22387ae38 0x00005fe22387c6bb 0x00005fe223885be4 0x00005fe21c75dfe2 0x00005fe22736aa94 0x00005fe21c76e1bd 0x00005fe2167ae28a 0x00007b5ab0fed488 0x00007b5ab0fed54c 0x00005fe2167ad02e\n2025.03.25 18:57:41.123582 [ 518045 ] {} <Fatal> ClientBase: ########################################\n2025.03.25 18:57:41.123624 [ 518045 ] {} <Fatal> ClientBase: (version 25.4.1.1, build id: 989CB91466803EAFBCDD7AEE9B8CA271A31937BF, git hash: 6e9ca99bc754a2cedcef283dd6430dce93554e08) (from thread 517475) (query_id: 80393d80-7edf-4159-870d-c54f384264d8) (query: SELECT DISTINCT * FROM test_table__fuzz_5 WHERE 1 % 60 SETTINGS max_threads = 1023, max_streams_to_max_threads_ratio = 0, enable_analyzer = 1;) Received signal Arithmetic exception (8)\n2025.03.25 18:57:41.123633 [ 518045 ] {} <Fatal> ClientBase: Integer divide by zero.\n2025.03.25 18:57:41.123638 [ 518045 ] {} <Fatal> ClientBase: Stack trace: 0x00005fe21c4f04e8 0x00005fe21c87f219 0x00007b5ab1003cd0 0x00005fe223fd2f2c 0x00005fe223fe4257 0x00005fe223fe61cf 0x00005fe223f790be 0x00005fe223faae1e 0x00005fe22167f6c7 0x00005fe22167f412 0x00005fe221a4b1b4 0x00005fe221a46773 0x00005fe2238e6b15 0x00005fe223871736 0x00005fe22386f8fb 0x00005fe22387ae38 0x00005fe22387c6bb 0x00005fe223885be4 0x00005fe21c75dfe2 0x00005fe22736aa94 0x00005fe21c76e1bd 0x00005fe2167ae28a 0x00007b5ab0fed488 0x00007b5ab0fed54c 0x00005fe2167ad02e\n2025.03.25 18:57:41.130119 [ 518045 ] {} <Fatal> ClientBase: 0.0. inlined from /mnt/ch/ClickHouse/src/Common/StackTrace.cpp:386: StackTrace::tryCapture()\n2025.03.25 18:57:41.130128 [ 518045 ] {} <Fatal> ClientBase: 0. /mnt/ch/ClickHouse/src/Common/StackTrace.cpp:355: StackTrace::StackTrace(ucontext_t const&) @ 0x000000000deec4e8\n2025.03.25 18:57:41.143007 [ 518045 ] {} <Fatal> ClientBase: 1. /mnt/ch/ClickHouse/src/Common/SignalHandlers.cpp:106: signalHandler(int, siginfo_t*, void*) @ 0x000000000e27b219\n2025.03.25 18:57:41.143014 [ 518045 ] {} <Fatal> ClientBase: 2. ? @ 0x00007b5ab1003cd0\n2025.03.25 18:57:41.193634 [ 518045 ] {} <Fatal> ClientBase: 3. /mnt/ch/ClickHouse/src/Processors/QueryPlan/ReadFromMergeTree.cpp:1123: DB::ReadFromMergeTree::spreadMarkRangesAmongStreamsWithOrder(DB::RangesInDataParts&&, unsigned long, std::vector<String, std::allocator<String>> const&, std::optional<DB::ActionsDAG>&, std::shared_ptr<DB::InputOrderInfo const> const&) @ 0x00000000159cef2c\n2025.03.25 18:57:41.255144 [ 518045 ] {} <Fatal> ClientBase: 4. /mnt/ch/ClickHouse/src/Processors/QueryPlan/ReadFromMergeTree.cpp:2143: DB::ReadFromMergeTree::spreadMarkRanges(DB::RangesInDataParts&&, unsigned long, DB::ReadFromMergeTree::AnalysisResult&, std::optional<DB::ActionsDAG>&) @ 0x00000000159e0257\n2025.03.25 18:57:41.304688 [ 518045 ] {} <Fatal> ClientBase: 5. /mnt/ch/ClickHouse/src/Processors/QueryPlan/ReadFromMergeTree.cpp:2245: DB::ReadFromMergeTree::initializePipeline(DB::QueryPipelineBuilder&, DB::BuildQueryPipelineSettings const&) @ 0x00000000159e21cf\n2025.03.25 18:57:41.307506 [ 518045 ] {} <Fatal> ClientBase: 6. /mnt/ch/ClickHouse/src/Processors/QueryPlan/ISourceStep.cpp:20: DB::ISourceStep::updatePipeline(std::vector<std::unique_ptr<DB::QueryPipelineBuilder, std::default_delete<DB::QueryPipelineBuilder>>, std::allocator<std::unique_ptr<DB::QueryPipelineBuilder, std::default_delete<DB::QueryPipelineBuilder>>>>, DB::BuildQueryPipelineSettings const&) @ 0x00000000159750be\n2025.03.25 18:57:41.316702 [ 518045 ] {} <Fatal> ClientBase: 7. /mnt/ch/ClickHouse/src/Processors/QueryPlan/QueryPlan.cpp:202: DB::QueryPlan::buildQueryPipeline(DB::QueryPlanOptimizationSettings const&, DB::BuildQueryPipelineSettings const&) @ 0x00000000159a6e1e\n2025.03.25 18:57:41.326352 [ 518045 ] {} <Fatal> ClientBase: 8. /mnt/ch/ClickHouse/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp:275: DB::InterpreterSelectQueryAnalyzer::buildQueryPipeline() @ 0x000000001307b6c7\n2025.03.25 18:57:41.335445 [ 518045 ] {} <Fatal> ClientBase: 9. /mnt/ch/ClickHouse/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp:242: DB::InterpreterSelectQueryAnalyzer::execute() @ 0x000000001307b412\n2025.03.25 18:57:41.360068 [ 518045 ] {} <Fatal> ClientBase: 10. /mnt/ch/ClickHouse/src/Interpreters/executeQuery.cpp:1458: DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000134471b4\n2025.03.25 18:57:41.388196 [ 518045 ] {} <Fatal> ClientBase: 11. /mnt/ch/ClickHouse/src/Interpreters/executeQuery.cpp:1625: DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000013442773\n2025.03.25 18:57:41.402567 [ 518045 ] {} <Fatal> ClientBase: 12. /mnt/ch/ClickHouse/src/Client/LocalConnection.cpp:262: DB::LocalConnection::sendQuery(DB::ConnectionTimeouts const&, String const&, std::unordered_map<String, String, std::hash<String>, std::equal_to<String>, std::allocator<std::pair<String const, String>>> const&, String const&, unsigned long, DB::Settings const*, DB::ClientInfo const*, bool, std::vector<String, std::allocator<String>> const&, std::function<void (DB::Progress const&)>) @ 0x00000000152e2b15\n2025.03.25 18:57:41.433882 [ 518045 ] {} <Fatal> ClientBase: 13. /mnt/ch/ClickHouse/src/Client/ClientBase.cpp:1276: DB::ClientBase::processOrdinaryQuery(String const&, std::shared_ptr<DB::IAST>) @ 0x000000001526d736\n2025.03.25 18:57:41.465866 [ 518045 ] {} <Fatal> ClientBase: 14. /mnt/ch/ClickHouse/src/Client/ClientBase.cpp:2267: DB::ClientBase::processParsedSingleQuery(String const&, String const&, std::shared_ptr<DB::IAST>, std::optional<bool>, bool) @ 0x000000001526b8fb\n2025.03.25 18:57:41.506808 [ 518045 ] {} <Fatal> ClientBase: 15. /mnt/ch/ClickHouse/src/Client/ClientBase.cpp:2628: DB::ClientBase::executeMultiQuery(String const&) @ 0x0000000015276e38\n2025.03.25 18:57:41.547689 [ 518045 ] {} <Fatal> ClientBase: 16. /mnt/ch/ClickHouse/src/Client/ClientBase.cpp:3408: DB::ClientBase::processMultiQueryFromFile(String const&) @ 0x00000000152786bb\n2025.03.25 18:57:41.592130 [ 518045 ] {} <Fatal> ClientBase: 17. /mnt/ch/ClickHouse/src/Client/ClientBase.cpp:3425: DB::ClientBase::runNonInteractive() @ 0x0000000015281be4\n2025.03.25 18:57:41.605870 [ 518045 ] {} <Fatal> ClientBase: 18. /mnt/ch/ClickHouse/programs/local/LocalServer.cpp:631: DB::LocalServer::main(std::vector<String, std::allocator<String>> const&) @ 0x000000000e159fe2\n2025.03.25 18:57:41.609841 [ 518045 ] {} <Fatal> ClientBase: 19. /mnt/ch/ClickHouse/base/poco/Util/src/Application.cpp:315: Poco::Util::Application::run() @ 0x0000000018d66a94\n2025.03.25 18:57:41.632120 [ 518045 ] {} <Fatal> ClientBase: 20. /mnt/ch/ClickHouse/programs/local/LocalServer.cpp:1085: mainEntryClickHouseLocal(int, char**) @ 0x000000000e16a1bd\n2025.03.25 18:57:41.634503 [ 518045 ] {} <Fatal> ClientBase: 21. /mnt/ch/ClickHouse/programs/main.cpp:295: main @ 0x00000000081aa28a\n2025.03.25 18:57:41.634511 [ 518045 ] {} <Fatal> ClientBase: 22. ? @ 0x00007b5ab0fed488\n2025.03.25 18:57:41.634516 [ 518045 ] {} <Fatal> ClientBase: 23. ? @ 0x00007b5ab0fed54c\n2025.03.25 18:57:41.665058 [ 518045 ] {} <Fatal> ClientBase: 24. _start @ 0x00000000081a902e\n2025.03.25 18:57:41.665080 [ 518045 ] {} <Fatal> ClientBase: This ClickHouse version is not official and should be upgraded to the official build.\n2025.03.25 18:57:41.665190 [ 518045 ] {} <Fatal> ClientBase: Changed settings: max_threads = 1023, max_streams_to_max_threads_ratio = 0., allow_introspection_functions = true, storage_file_read_method = 'mmap', parallel_replicas_for_cluster_engines = false, allow_experimental_analyzer = true, implicit_select = true\n```\n",
  "hints_text": "",
  "created_at": "2025-04-01T09:16:48Z",
  "modified_files": [
    "src/Interpreters/InterpreterSelectQuery.cpp",
    "src/Planner/PlannerJoinTree.cpp",
    "src/Processors/QueryPlan/ReadFromMergeTree.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/03402_zero_streams_after_max_streams_to_max_threads_ratio.reference",
    "b/tests/queries/0_stateless/03402_zero_streams_after_max_streams_to_max_threads_ratio.sql",
    "b/tests/queries/0_stateless/03403_read_in_order_streams_memory_usage.reference",
    "b/tests/queries/0_stateless/03403_read_in_order_streams_memory_usage.sql"
  ]
}