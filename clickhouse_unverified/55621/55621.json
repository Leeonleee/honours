{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 55621,
  "instance_id": "ClickHouse__ClickHouse-55621",
  "issue_numbers": [
    "52352"
  ],
  "base_commit": "17616ca3256c1b602980fab6277faf829b460cbf",
  "patch": "diff --git a/src/Storages/StorageSet.cpp b/src/Storages/StorageSet.cpp\nindex 79369ab4bcb5..1b0db1da8005 100644\n--- a/src/Storages/StorageSet.cpp\n+++ b/src/Storages/StorageSet.cpp\n@@ -156,12 +156,62 @@ StorageSet::StorageSet(\n }\n \n \n-void StorageSet::insertBlock(const Block & block, ContextPtr) { set->insertFromBlock(block.getColumnsWithTypeAndName()); }\n-void StorageSet::finishInsert() { set->finishInsert(); }\n+SetPtr StorageSet::getSet() const\n+{\n+    std::lock_guard lock(mutex);\n+    return set;\n+}\n+\n+\n+void StorageSet::insertBlock(const Block & block, ContextPtr)\n+{\n+    SetPtr current_set;\n+    {\n+        std::lock_guard lock(mutex);\n+        current_set = set;\n+    }\n+    current_set->insertFromBlock(block.getColumnsWithTypeAndName());\n+}\n \n-size_t StorageSet::getSize(ContextPtr) const { return set->getTotalRowCount(); }\n-std::optional<UInt64> StorageSet::totalRows(const Settings &) const { return set->getTotalRowCount(); }\n-std::optional<UInt64> StorageSet::totalBytes(const Settings &) const { return set->getTotalByteCount(); }\n+void StorageSet::finishInsert()\n+{\n+    SetPtr current_set;\n+    {\n+        std::lock_guard lock(mutex);\n+        current_set = set;\n+    }\n+    current_set->finishInsert();\n+}\n+\n+size_t StorageSet::getSize(ContextPtr) const\n+{\n+    SetPtr current_set;\n+    {\n+        std::lock_guard lock(mutex);\n+        current_set = set;\n+    }\n+    return current_set->getTotalRowCount();\n+}\n+\n+std::optional<UInt64> StorageSet::totalRows(const Settings &) const\n+{\n+    SetPtr current_set;\n+    {\n+        std::lock_guard lock(mutex);\n+        current_set = set;\n+    }\n+    return current_set->getTotalRowCount();\n+}\n+\n+std::optional<UInt64> StorageSet::totalBytes(const Settings &) const\n+{\n+    SetPtr current_set;\n+    {\n+        std::lock_guard lock(mutex);\n+        current_set = set;\n+    }\n+    return current_set->getTotalByteCount();\n+}\n \n void StorageSet::truncate(const ASTPtr &, const StorageMetadataPtr & metadata_snapshot, ContextPtr, TableExclusiveLockHolder &)\n {\n@@ -176,8 +226,13 @@ void StorageSet::truncate(const ASTPtr &, const StorageMetadataPtr & metadata_sn\n     Block header = metadata_snapshot->getSampleBlock();\n \n     increment = 0;\n-    set = std::make_shared<Set>(SizeLimits(), 0, true);\n-    set->setHeader(header.getColumnsWithTypeAndName());\n+\n+    auto new_set = std::make_shared<Set>(SizeLimits(), 0, true);\n+    new_set->setHeader(header.getColumnsWithTypeAndName());\n+    {\n+        std::lock_guard lock(mutex);\n+        set = new_set;\n+    }\n }\n \n \ndiff --git a/src/Storages/StorageSet.h b/src/Storages/StorageSet.h\nindex b310f817eb90..67a9528ff5e4 100644\n--- a/src/Storages/StorageSet.h\n+++ b/src/Storages/StorageSet.h\n@@ -79,7 +79,7 @@ class StorageSet final : public StorageSetOrJoinBase\n     String getName() const override { return \"Set\"; }\n \n     /// Access the insides.\n-    SetPtr & getSet() { return set; }\n+    SetPtr getSet() const;\n \n     void truncate(const ASTPtr &, const StorageMetadataPtr & metadata_snapshot, ContextPtr, TableExclusiveLockHolder &) override;\n \n@@ -87,7 +87,9 @@ class StorageSet final : public StorageSetOrJoinBase\n     std::optional<UInt64> totalBytes(const Settings & settings) const override;\n \n private:\n-    SetPtr set;\n+    /// Allows to concurrently truncate the set and work (read/fill) the existing set.\n+    mutable std::mutex mutex;\n+    SetPtr set TSA_GUARDED_BY(mutex);\n \n     void insertBlock(const Block & block, ContextPtr) override;\n     void finishInsert() override;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02867_storage_set_tsan.reference b/tests/queries/0_stateless/02867_storage_set_tsan.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/02867_storage_set_tsan.sh b/tests/queries/0_stateless/02867_storage_set_tsan.sh\nnew file mode 100755\nindex 000000000000..81ae5f0bda8c\n--- /dev/null\n+++ b/tests/queries/0_stateless/02867_storage_set_tsan.sh\n@@ -0,0 +1,42 @@\n+#!/usr/bin/env bash\n+# Tags: race, no-debug\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT -mn -q \"\"\"\n+DROP TABLE IF EXISTS t1_02867;\n+CREATE TABLE t1_02867 (x UInt64) ENGINE=Set();\n+\"\"\"\n+\n+function repeat_select() {\n+    n=0\n+    while [ \"$n\" -lt 20 ];\n+    do\n+        n=$(( n + 1 ))\n+        $CLICKHOUSE_CLIENT -q \"SELECT count() as a FROM numbers(10) WHERE number IN t1_02867\" > /dev/null 2> /dev/null || exit\n+    done\n+}\n+\n+function repeat_truncate_insert() {\n+    n=0\n+    while [ \"$n\" -lt 20 ];\n+    do\n+        n=$(( n + 1 ))\n+        $CLICKHOUSE_CLIENT -q \"TRUNCATE t1_02867;\" > /dev/null 2> /dev/null || exit\n+    done\n+}\n+\n+repeat_select &\n+repeat_truncate_insert &\n+repeat_select &\n+repeat_truncate_insert &\n+repeat_select &\n+repeat_truncate_insert &\n+repeat_select &\n+repeat_truncate_insert &\n+\n+sleep 10\n+\n+$CLICKHOUSE_CLIENT -mn -q \"DROP TABLE IF EXISTS t1_02867;\"\n",
  "problem_statement": "Make StorageSet::getSet() thread safe\nFound by TSan.\r\nHappened when CREATE TABLE ... ENGINE = Set()\r\nand TRUNCATE TABLE is called\r\n\r\n    DB::StorageSet::truncate\r\n    DB::InterpreterDropQuery::executeToTableImpl\r\n    ...\r\n    DB::InterpreterDropQuery::execute\r\n\r\nand mutations are happening\r\n\r\n    DB::ExpressionAnalyzer::isPlainStorageSetInSubquery calls `return storage_set->getSet();`    \r\n    DB::ExpressionAnalyzer::tryMakeSetForIndexFromSubquery \r\n    ...\r\n    DB::MergeTreeDataMergerMutator::mutatePartToTemporaryPart DB::StorageMergeTree::mutateSelectedPart\r\n    DB::StorageMergeTree::scheduleDataProcessingJob\r\n\r\n<!---\r\nA technical comment, you are free to remove or leave it as it is when PR is created\r\nThe following categories are used in the next scripts, update them accordingly\r\nutils/changelog/changelog.py\r\ntests/ci/cancel_and_rerun_workflow_lambda/app.py\r\n-->\r\n### Changelog category (leave one):\r\n- Improvement\r\n\r\n### Changelog category (leave one):\r\n- Not for changelog (changelog entry is not required)\r\n\r\n\r\n\r\n<!---\r\nDirectly edit documentation source files in the \"docs\" folder with the same pull-request as code changes\r\n\r\nor\r\n\r\nAdd a user-readable short description of the changes that should be added to docs.clickhouse.com below.\r\n\r\nAt a minimum, the following information should be added (but add more as needed).\r\n- Motivation: Why is this function, table engine, etc. useful to ClickHouse users?\r\n\r\n- Parameters: If the feature being added takes arguments, options or is influenced by settings, please list them below with a brief explanation.\r\n\r\n- Example use: A query or command.\r\n-->\r\n\r\n\r\n> Information about CI checks: https://clickhouse.com/docs/en/development/continuous-integration/\r\n\n",
  "hints_text": "<!-- automatic status comment for PR #52352 from valbok/ClickHouse:storage-set -->\nThis is an automated comment for commit 59874af11b7b4e48e32e64827e0116f8acf25640 with description of existing statuses. It's updated for the latest CI running\nThe full report is available [here](https://s3.amazonaws.com/clickhouse-test-reports/52352/59874af11b7b4e48e32e64827e0116f8acf25640/ci_running.html)\nThe overall status of the commit is \ud83d\udd34 failure\n\n<table><thead><tr><th>Check name</th><th>Description</th><th>Status</th></tr></thead>\n<tbody><tr><td>AST fuzzer</td><td>Runs randomly generated queries to catch program errors. The build type is optionally given in parenthesis. If it fails, ask a maintainer for help</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>CI running</td><td>A meta-check that indicates the running CI. Normally, it's in <b>success</b> or <b>pending</b> state. The failed status indicates some problems with the PR</td><td>\ud83d\udfe1 pending</td></tr>\n<tr><td>ClickHouse build check</td><td>Builds ClickHouse in various configurations for use in further steps. You have to fix the builds that fail. Build logs often has enough information to fix the error, but you might have to reproduce the failure locally. The <b>cmake</b> options can be found in the build log, grepping for <b>cmake</b>. Use these options and follow the <a href=\"https://clickhouse.com/docs/en/development/build\">general build process</a></td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Compatibility check</td><td>Checks that <b>clickhouse</b> binary runs on distributions with old libc versions. If it fails, ask a maintainer for help</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Docker image for servers</td><td>The check to build and optionally push the mentioned image to docker hub</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Fast test</td><td>Normally this is the first check that is ran for a PR. It builds ClickHouse and runs most of <a href=\"https://clickhouse.com/docs/en/development/tests#functional-tests\">stateless functional tests</a>, omitting some. If it fails, further checks are not started until it is fixed. Look at the report to see which tests fail, then reproduce the failure locally as described <a href=\"https://clickhouse.com/docs/en/development/tests#functional-test-locally\">here</a></td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Flaky tests</td><td>Checks if new added or modified tests are flaky by running them repeatedly, in parallel, with more randomization. Functional tests are run 100 times with address sanitizer, and additional randomization of thread scheduling. Integrational tests are run up to 10 times. If at least once a new test has failed, or was too long, this check will be red. We don't allow flaky tests, read <a href=\"https://clickhouse.com/blog/decorating-a-christmas-tree-with-the-help-of-flaky-tests/\">the doc</a></td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Install packages</td><td>Checks that the built packages are installable in a clear environment</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Integration tests</td><td>The integration tests report. In parenthesis the package type is given, and in square brackets are the optional part/total tests</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Mergeable Check</td><td>Checks if all other necessary checks are successful</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Performance Comparison</td><td>Measure changes in query performance. The performance test report is described in detail <a href=\"https://github.com/ClickHouse/ClickHouse/tree/master/docker/test/performance-comparison#how-to-read-the-report\">here</a>. In square brackets are the optional part/total tests</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Push to Dockerhub</td><td>The check for building and pushing the CI related docker images to docker hub</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>SQLTest</td><td>There's no description for the check yet, please add it to tests/ci/ci_config.py:CHECK_DESCRIPTIONS</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>SQLancer</td><td>Fuzzing tests that detect logical bugs with <a href=\"https://github.com/sqlancer/sqlancer\">SQLancer</a> tool</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Sqllogic</td><td>Run clickhouse on the <a href=\"https://www.sqlite.org/sqllogictest\">sqllogic</a> test set against sqlite and checks that all statements are passed</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Stateful tests</td><td>Runs stateful functional tests for ClickHouse binaries built in various configurations -- release, debug, with sanitizers, etc</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Stateless tests</td><td>Runs stateless functional tests for ClickHouse binaries built in various configurations -- release, debug, with sanitizers, etc</td><td>\ud83d\udd34 failure</td></tr>\n<tr><td>Stress test</td><td>Runs stateless functional tests concurrently from several clients to detect concurrency-related errors</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Style Check</td><td>Runs a set of checks to keep the code style clean. If some of tests failed, see the related log from the report</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Unit tests</td><td>Runs the unit tests for different release types</td><td>\ud83d\udfe2 success</td></tr>\n<tr><td>Upgrade check</td><td>Runs stress tests on server version from last release and then tries to upgrade it to the version from the PR. It checks if the new server can successfully startup without any errors, crashes or sanitizer asserts</td><td>\ud83d\udfe2 success</td></tr>\n</table>\nOk, but the code is difficult to understand because it does not explain why atomic_load is needed there.\r\n\r\nWe should:\r\n- add a test that has a chance to reproduce the issue more frequently under TSan, to ensure it will not be broken again;\r\n- add a comment before this method;\r\n- it's usually expected that every synchronization has two sides: add something into `truncate` method;\r\n- atomic_load, especially for shared_ptr, can be confusing - what about replacing everything with a mutex? We'll simply lock it inside `getSet` and `truncate`.\nAll integration tests with Thread Sanitizer have failed. You can check the results of the integration tests. Download the archive, and you can probably find a TSan report there.\nPS. I strongly advice replacing everything with a mutex to make the code easier to read.\nSuddenly tsan integration tests passed \\=)\n> All integration tests with Thread Sanitizer have failed. You can check the results of the integration tests. Download the archive, and you can probably find a TSan report there.\r\n\r\nLooks not related to PR\n> * add a test that has a chance to reproduce the issue more frequently under TSan, to ensure it will not be broken again;\r\n\r\nAll tests will be flaky since it is DR and very hard to reproduce.\r\n\r\n> * add a comment before this method;\r\n\r\nAdded `const` to the method to notify that it is read access.\r\n\r\n> * it's usually expected that every synchronization has two sides: add something into `truncate` method;\r\n> * atomic_load, especially for shared_ptr, can be confusing - what about replacing everything with a mutex? We'll simply lock it inside `getSet` and `truncate`.\r\n\r\nSince it is protecting only accessing to the member (set), I would suggest to use atomic_load/atomic_store instead of mutex, where it points that setting/loading the var is atomic and thread safe, SetPtr itself is not thread safe and every callers to getSet() should use it only for read access. This is why suggesting to make it `const`. When write access will be needed, second method could be added.\r\n\r\nAnd sorry for some delays and some mess-up in comments. First commit missed atomic_store and it was confusing, yes.\r\n\n> All tests will be flaky since it is DR and very hard to reproduce.\r\n\r\nWe have these tests, they are named `*race`. They are trying to run the suspected code more frequently. With Thread Fuzzer and Thread Sanitizer, it increases the chance of detecting failure. If we have a bug, these tests will usually succeed but fail, say, once a month. And if the test will ever fail again, I guarantee that all our engineers will scream, jump around, and investigate it.\n> > All tests will be flaky since it is DR and very hard to reproduce.\r\n> \r\n> We have these tests, they are named `*race`. They are trying to run the suspected code more frequently. With Thread Fuzzer and Thread Sanitizer, it increases the chance of detecting failure. If we have a bug, these tests will usually succeed but fail, say, once a month. And if the test will ever fail again, I guarantee that all our engineers will scream, jump around, and investigate it.\r\n\r\nAdded a functional test which reproduces DR issue quite often.\n\r\n    02845_storage_set_data_race | FAIL | 180.25\r\n                        -- | -- | --\r\n            2023-08-17 16:31:01 Settings used in the test: --max_insert_threads 16 --group_by_two_level_threshold 1000000 --group_by_two_level_threshold_bytes 50000000 --distributed_aggregation_memory_efficient 1 --fsync_metadata 0 --output_format_parallel_formatting 0 --input_format_parallel_parsing 1 --min_chunk_bytes_for_parallel_parsing 6154312 --max_read_buffer_size 734190 --prefer_localhost_replica 0 --max_block_size 77044 --max_threads 4 --optimize_or_like_chain 0 --optimize_read_in_order 0 --enable_multiple_prewhere_read_steps 1 --read_in_order_two_level_merge_threshold 65 --optimize_aggregation_in_order 1 --aggregation_in_order_max_block_bytes 18697544 --min_compress_block_size 2642615 --max_compress_block_size 2672198 --use_uncompressed_cache 0 --min_bytes_to_use_direct_io 10737418240 --min_bytes_to_use_mmap_io 1 --local_filesystem_read_method pread_threadpool --remote_filesystem_read_method read --local_filesystem_read_prefetch 0 --remote_filesystem_read_prefetch 1 --allow_prefetched_read_pool_for_remote_filesystem 0 --filesystem_prefetch_max_memory_usage 128Mi --filesystem_prefetches_limit 0 --filesystem_prefetch_min_bytes_for_single_read_task 8Mi --filesystem_prefetch_step_marks 0 --filesystem_prefetch_step_bytes 0 --compile_aggregate_expressions 1 --compile_sort_description 1 --merge_tree_coarse_index_granularity 8 --optimize_distinct_in_order 1 --optimize_sorting_by_input_stream_properties 0 --http_response_buffer_size 8321584 --http_wait_end_of_query False --enable_memory_bound_merging_of_aggregation_results 1 --min_count_to_compile_expression 3 --min_count_to_compile_aggregate_expression 0 --min_count_to_compile_sort_description 0 --session_timezone America/Mazatlan 2023-08-17 16:31:01  2023-08-17 16:31:01 MergeTree settings used in test: --ratio_of_defaults_for_sparse_serialization 1.0 --prefer_fetch_merged_part_size_threshold 10737418240 --vertical_merge_algorithm_min_rows_to_activate 1 --vertical_merge_algorithm_min_columns_to_activate 100 --allow_vertical_merges_from_compact_to_wide_parts 1 --min_merge_bytes_to_use_direct_io 10737418240 --index_granularity_bytes 14119326 --merge_max_block_size 5915 --index_granularity 34477 --min_bytes_for_wide_part 396064249 --marks_compress_block_size 75549 --primary_key_compress_block_size 51545 2023-08-17 16:31:01  2023-08-17 16:31:01 Database: test_46nis5vk\r\n            \r\n\nhttps://s3.amazonaws.com/clickhouse-test-reports/52352/fc198d575198a1461887a0b1664ddbda1b6bc644/stateless_tests__release__wide_parts_enabled_.html\r\n02845_storage_set_data_race | OK \r\n\r\n\nNot related to PR:\r\nhttps://s3.amazonaws.com/clickhouse-test-reports/52352/fc198d575198a1461887a0b1664ddbda1b6bc644/stateless_tests__release__wide_parts_enabled_.html\r\n\r\n00725_memory_tracking | FAIL\r\n-- | --\r\n\r\nhttps://s3.amazonaws.com/clickhouse-test-reports/52352/fc198d575198a1461887a0b1664ddbda1b6bc644/integration_tests__release__[2_4].html\r\n\r\ntest_storage_rabbitmq/test.py::test_block_based_formats_1 | ERROR\r\n-- | --\r\n\r\n\r\n\r\n@alexey-milovidov \r\n\r\n\r\n\n\r\n\r\n00002_log_and_exception_messages_formatting | FAIL\r\n-- | --\r\n\r\n\r\n\n@kssenii \nI remember (maybe I'm wrong) that atomic shared_ptrs in C++ are \"fake\", and while reading the diff, I'm thinking - maybe there is a mutex already inside this class, so we can just use it to make it obvious. But I didn't read the surrounding code.\nNevertheless, the requirement to have a comment in the code is not fulfilled...\nOk, I checked - we use atomic ops on shared_ptr in some other places.\r\nI don't understand - if we use atomic ops on the set object, then we should use them everywhere.\r\nAlso, we should hold the previous SetPtr, otherwise if any of these methods:\r\n```\r\nvoid StorageSet::insertBlock(const Block & block, ContextPtr) { set->insertFromBlock(block.getColumnsWithTypeAndName()); }\r\nvoid StorageSet::finishInsert() { set->finishInsert(); }\r\n\r\nsize_t StorageSet::getSize(ContextPtr) const { return set->getTotalRowCount(); }\r\nstd::optional<UInt64> StorageSet::totalRows(const Settings &) const { return set->getTotalRowCount(); }\r\nstd::optional<UInt64> StorageSet::totalBytes(const Settings &) const { return set->getTotalByteCount(); }\r\n```\r\nare called concurrently with `truncate` it will lead to use-after-free.\nIs there a link to TSan report?",
  "created_at": "2023-10-14T00:54:29Z",
  "modified_files": [
    "src/Storages/StorageSet.cpp",
    "src/Storages/StorageSet.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02867_storage_set_tsan.sh"
  ]
}