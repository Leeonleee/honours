{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 35687,
  "instance_id": "ClickHouse__ClickHouse-35687",
  "issue_numbers": [
    "35407"
  ],
  "base_commit": "093bdc2c1319af4c003d203ab727a9e82bf9b31f",
  "patch": "diff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\nindex 9028023dc809..6e1d73da4271 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n@@ -558,9 +558,10 @@ size_t IMergeTreeDataPart::getFileSizeOrZero(const String & file_name) const\n     return checksum->second.file_size;\n }\n \n-String IMergeTreeDataPart::getColumnNameWithMinimumCompressedSize(const StorageMetadataPtr & metadata_snapshot) const\n+String IMergeTreeDataPart::getColumnNameWithMinimumCompressedSize(const StorageSnapshotPtr & storage_snapshot) const\n {\n-    const auto & storage_columns = metadata_snapshot->getColumns().getAllPhysical();\n+    auto options = GetColumnsOptions(GetColumnsOptions::AllPhysical).withExtendedObjects().withSubcolumns();\n+    auto storage_columns = storage_snapshot->getColumns(options);\n     MergeTreeData::AlterConversions alter_conversions;\n     if (!parent_part)\n         alter_conversions = storage.getAlterConversionsForPart(shared_from_this());\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.h b/src/Storages/MergeTree/IMergeTreeDataPart.h\nindex 85088b10f70f..0dfac49bf306 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.h\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.h\n@@ -164,7 +164,7 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n \n     /// Returns the name of a column with minimum compressed size (as returned by getColumnSize()).\n     /// If no checksums are present returns the name of the first physically existing column.\n-    String getColumnNameWithMinimumCompressedSize(const StorageMetadataPtr & metadata_snapshot) const;\n+    String getColumnNameWithMinimumCompressedSize(const StorageSnapshotPtr & storage_snapshot) const;\n \n     bool contains(const IMergeTreeDataPart & other) const { return info.contains(other.info); }\n \ndiff --git a/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp b/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\nindex 6e72b843f101..97516ea06c6f 100644\n--- a/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\n+++ b/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\n@@ -24,7 +24,7 @@ namespace\n /// least one existing (physical) column in part.\n bool injectRequiredColumnsRecursively(\n     const String & column_name,\n-    const ColumnsDescription & storage_columns,\n+    const StorageSnapshotPtr & storage_snapshot,\n     const MergeTreeData::AlterConversions & alter_conversions,\n     const MergeTreeData::DataPartPtr & part,\n     Names & columns,\n@@ -36,7 +36,8 @@ bool injectRequiredColumnsRecursively(\n     /// stages.\n     checkStackSize();\n \n-    auto column_in_storage = storage_columns.tryGetColumnOrSubcolumn(GetColumnsOptions::AllPhysical, column_name);\n+    auto options = GetColumnsOptions(GetColumnsOptions::AllPhysical).withSubcolumns().withExtendedObjects();\n+    auto column_in_storage = storage_snapshot->tryGetColumn(options, column_name);\n     if (column_in_storage)\n     {\n         auto column_name_in_part = column_in_storage->getNameInStorage();\n@@ -63,7 +64,8 @@ bool injectRequiredColumnsRecursively(\n \n     /// Column doesn't have default value and don't exist in part\n     /// don't need to add to required set.\n-    const auto column_default = storage_columns.getDefault(column_name);\n+    auto metadata_snapshot = storage_snapshot->getMetadataForQuery();\n+    const auto column_default = metadata_snapshot->getColumns().getDefault(column_name);\n     if (!column_default)\n         return false;\n \n@@ -73,39 +75,36 @@ bool injectRequiredColumnsRecursively(\n \n     bool result = false;\n     for (const auto & identifier : identifiers)\n-        result |= injectRequiredColumnsRecursively(identifier, storage_columns, alter_conversions, part, columns, required_columns, injected_columns);\n+        result |= injectRequiredColumnsRecursively(identifier, storage_snapshot, alter_conversions, part, columns, required_columns, injected_columns);\n \n     return result;\n }\n \n }\n \n-NameSet injectRequiredColumns(const MergeTreeData & storage, const StorageMetadataPtr & metadata_snapshot, const MergeTreeData::DataPartPtr & part, Names & columns)\n+NameSet injectRequiredColumns(\n+    const MergeTreeData & storage,\n+    const StorageSnapshotPtr & storage_snapshot,\n+    const MergeTreeData::DataPartPtr & part,\n+    Names & columns)\n {\n     NameSet required_columns{std::begin(columns), std::end(columns)};\n     NameSet injected_columns;\n \n     bool have_at_least_one_physical_column = false;\n-\n-    const auto & storage_columns = metadata_snapshot->getColumns();\n     MergeTreeData::AlterConversions alter_conversions;\n     if (!part->isProjectionPart())\n         alter_conversions = storage.getAlterConversionsForPart(part);\n+\n     for (size_t i = 0; i < columns.size(); ++i)\n     {\n-        auto name_in_storage = Nested::extractTableName(columns[i]);\n-        if (storage_columns.has(name_in_storage) && isObject(storage_columns.get(name_in_storage).type))\n-        {\n-            have_at_least_one_physical_column = true;\n-            continue;\n-        }\n-\n         /// We are going to fetch only physical columns\n-        if (!storage_columns.hasColumnOrSubcolumn(GetColumnsOptions::AllPhysical, columns[i]))\n-            throw Exception(\"There is no physical column or subcolumn \" + columns[i] + \" in table.\", ErrorCodes::NO_SUCH_COLUMN_IN_TABLE);\n+        auto options = GetColumnsOptions(GetColumnsOptions::AllPhysical).withSubcolumns().withExtendedObjects();\n+        if (!storage_snapshot->tryGetColumn(options, columns[i]))\n+            throw Exception(ErrorCodes::NO_SUCH_COLUMN_IN_TABLE, \"There is no physical column or subcolumn {} in table\", columns[i]);\n \n         have_at_least_one_physical_column |= injectRequiredColumnsRecursively(\n-            columns[i], storage_columns, alter_conversions,\n+            columns[i], storage_snapshot, alter_conversions,\n             part, columns, required_columns, injected_columns);\n     }\n \n@@ -115,7 +114,7 @@ NameSet injectRequiredColumns(const MergeTreeData & storage, const StorageMetada\n         */\n     if (!have_at_least_one_physical_column)\n     {\n-        const auto minimum_size_column_name = part->getColumnNameWithMinimumCompressedSize(metadata_snapshot);\n+        const auto minimum_size_column_name = part->getColumnNameWithMinimumCompressedSize(storage_snapshot);\n         columns.push_back(minimum_size_column_name);\n         /// correctly report added column\n         injected_columns.insert(columns.back());\n@@ -271,7 +270,7 @@ MergeTreeReadTaskColumns getReadTaskColumns(\n     Names pre_column_names;\n \n     /// inject columns required for defaults evaluation\n-    bool should_reorder = !injectRequiredColumns(storage, storage_snapshot->getMetadataForQuery(), data_part, column_names).empty();\n+    bool should_reorder = !injectRequiredColumns(storage, storage_snapshot, data_part, column_names).empty();\n \n     if (prewhere_info)\n     {\n@@ -296,7 +295,7 @@ MergeTreeReadTaskColumns getReadTaskColumns(\n         if (pre_column_names.empty())\n             pre_column_names.push_back(column_names[0]);\n \n-        const auto injected_pre_columns = injectRequiredColumns(storage, storage_snapshot->getMetadataForQuery(), data_part, pre_column_names);\n+        const auto injected_pre_columns = injectRequiredColumns(storage, storage_snapshot, data_part, pre_column_names);\n         if (!injected_pre_columns.empty())\n             should_reorder = true;\n \ndiff --git a/src/Storages/MergeTree/MergeTreeBlockReadUtils.h b/src/Storages/MergeTree/MergeTreeBlockReadUtils.h\nindex 2373881f9548..b4293b4ce3d3 100644\n--- a/src/Storages/MergeTree/MergeTreeBlockReadUtils.h\n+++ b/src/Storages/MergeTree/MergeTreeBlockReadUtils.h\n@@ -22,7 +22,7 @@ using MergeTreeBlockSizePredictorPtr = std::shared_ptr<MergeTreeBlockSizePredict\n   * so that you can calculate the DEFAULT expression for these columns.\n   * Adds them to the `columns`.\n   */\n-NameSet injectRequiredColumns(const MergeTreeData & storage, const StorageMetadataPtr & metadata_snapshot, const MergeTreeData::DataPartPtr & part, Names & columns);\n+NameSet injectRequiredColumns(const MergeTreeData & storage, const StorageSnapshotPtr & storage_snapshot, const MergeTreeData::DataPartPtr & part, Names & columns);\n \n \n /// A batch of work for MergeTreeThreadSelectBlockInputStream\ndiff --git a/src/Storages/MergeTree/MergeTreeSequentialSource.cpp b/src/Storages/MergeTree/MergeTreeSequentialSource.cpp\nindex 5dbc59ba2d5d..c5a3b7935d97 100644\n--- a/src/Storages/MergeTree/MergeTreeSequentialSource.cpp\n+++ b/src/Storages/MergeTree/MergeTreeSequentialSource.cpp\n@@ -41,7 +41,7 @@ MergeTreeSequentialSource::MergeTreeSequentialSource(\n     addTotalRowsApprox(data_part->rows_count);\n \n     /// Add columns because we don't want to read empty blocks\n-    injectRequiredColumns(storage, storage_snapshot->metadata, data_part, columns_to_read);\n+    injectRequiredColumns(storage, storage_snapshot, data_part, columns_to_read);\n     NamesAndTypesList columns_for_reader;\n     if (take_column_types_from_storage)\n     {\ndiff --git a/src/Storages/StorageSnapshot.cpp b/src/Storages/StorageSnapshot.cpp\nindex e214afc6a90c..8a82c5387c5c 100644\n--- a/src/Storages/StorageSnapshot.cpp\n+++ b/src/Storages/StorageSnapshot.cpp\n@@ -51,40 +51,42 @@ NamesAndTypesList StorageSnapshot::getColumns(const GetColumnsOptions & options)\n NamesAndTypesList StorageSnapshot::getColumnsByNames(const GetColumnsOptions & options, const Names & names) const\n {\n     NamesAndTypesList res;\n-    const auto & columns = getMetadataForQuery()->getColumns();\n     for (const auto & name : names)\n-    {\n-        auto column = columns.tryGetColumn(options, name);\n-        if (column && !isObject(column->type))\n-        {\n-            res.emplace_back(std::move(*column));\n-            continue;\n-        }\n+        res.push_back(getColumn(options, name));\n+    return res;\n+}\n \n-        if (options.with_extended_objects)\n-        {\n-            auto object_column = object_columns.tryGetColumn(options, name);\n-            if (object_column)\n-            {\n-                res.emplace_back(std::move(*object_column));\n-                continue;\n-            }\n-        }\n+std::optional<NameAndTypePair> StorageSnapshot::tryGetColumn(const GetColumnsOptions & options, const String & column_name) const\n+{\n+    const auto & columns = getMetadataForQuery()->getColumns();\n+    auto column = columns.tryGetColumn(options, column_name);\n+    if (column && (!isObject(column->type) || !options.with_extended_objects))\n+        return column;\n \n-        if (options.with_virtuals)\n-        {\n-            auto it = virtual_columns.find(name);\n-            if (it != virtual_columns.end())\n-            {\n-                res.emplace_back(name, it->second);\n-                continue;\n-            }\n-        }\n+    if (options.with_extended_objects)\n+    {\n+        auto object_column = object_columns.tryGetColumn(options, column_name);\n+        if (object_column)\n+            return object_column;\n+    }\n \n-        throw Exception(ErrorCodes::NO_SUCH_COLUMN_IN_TABLE, \"There is no column {} in table\", name);\n+    if (options.with_virtuals)\n+    {\n+        auto it = virtual_columns.find(column_name);\n+        if (it != virtual_columns.end())\n+            return NameAndTypePair(column_name, it->second);\n     }\n \n-    return res;\n+    return {};\n+}\n+\n+NameAndTypePair StorageSnapshot::getColumn(const GetColumnsOptions & options, const String & column_name) const\n+{\n+    auto column = tryGetColumn(options, column_name);\n+    if (!column)\n+        throw Exception(ErrorCodes::NO_SUCH_COLUMN_IN_TABLE, \"There is no column {} in table\", column_name);\n+\n+    return *column;\n }\n \n Block StorageSnapshot::getSampleBlockForColumns(const Names & column_names) const\ndiff --git a/src/Storages/StorageSnapshot.h b/src/Storages/StorageSnapshot.h\nindex 46244827f6c1..909f4fd5cab3 100644\n--- a/src/Storages/StorageSnapshot.h\n+++ b/src/Storages/StorageSnapshot.h\n@@ -61,6 +61,10 @@ struct StorageSnapshot\n     /// Get columns with types according to options only for requested names.\n     NamesAndTypesList getColumnsByNames(const GetColumnsOptions & options, const Names & names) const;\n \n+    /// Get column with type according to options for requested name.\n+    std::optional<NameAndTypePair> tryGetColumn(const GetColumnsOptions & options, const String & column_name) const;\n+    NameAndTypePair getColumn(const GetColumnsOptions & options, const String & column_name) const;\n+\n     /// Block with ordinary + materialized + aliases + virtuals + subcolumns.\n     Block getSampleBlockForColumns(const Names & column_names) const;\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01825_type_json_missed_values.reference b/tests/queries/0_stateless/01825_type_json_missed_values.reference\nnew file mode 100644\nindex 000000000000..b480493995b5\n--- /dev/null\n+++ b/tests/queries/0_stateless/01825_type_json_missed_values.reference\n@@ -0,0 +1,2 @@\n+Tuple(foo Int8, k1 Int8, k2 Int8)\n+1\ndiff --git a/tests/queries/0_stateless/01825_type_json_missed_values.sql b/tests/queries/0_stateless/01825_type_json_missed_values.sql\nnew file mode 100644\nindex 000000000000..2420ab7cf34b\n--- /dev/null\n+++ b/tests/queries/0_stateless/01825_type_json_missed_values.sql\n@@ -0,0 +1,19 @@\n+-- Tags: no-fasttest\n+\n+DROP TABLE IF EXISTS t_json;\n+\n+SET allow_experimental_object_type = 1;\n+\n+CREATE TABLE t_json(id UInt64, obj JSON)\n+ENGINE = MergeTree ORDER BY id\n+SETTINGS min_bytes_for_wide_part = 0;\n+\n+SYSTEM STOP MERGES t_json;\n+\n+INSERT INTO t_json SELECT number, '{\"k1\": 1, \"k2\": 2}' FROM numbers(1000000);\n+INSERT INTO t_json VALUES (1000001, '{\"foo\": 1}');\n+\n+SELECT toTypeName(obj) FROM t_json LIMIT 1;\n+SELECT count() FROM t_json WHERE obj.foo != 0;\n+\n+DROP TABLE IF EXISTS t_json;\n",
  "problem_statement": "MergeTreeThread - Can't adjust last granule with Object('JSON') datatype\n**Describe what's wrong**\r\n\r\nWhen inserting data to a table with `Object('JSON')` datatype, querying it might raise an error from MergeTreeThread.\r\n\r\n\r\nAfter calling `OPTIMIZE TABLE test_json FINAL` the issue goes away.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nIt reproduces on `22.3.2 revision 54455.`\r\n\r\n\r\n**How to reproduce**\r\n\r\nCreate a table with an `Object('JSON')` datatype:\r\n\r\n```\r\ncreate table production.test_json (data Object('JSON')) ENGINE = MergeTree() ORDER BY tuple();\r\n```\r\n\r\nand inserted some data into it:\r\n\r\n```\r\ninsert into test_json SELECT replace(toString(m), '\\'', '\"') as data FROM (SELECT properties as m from production.events_v4 where notEmpty(properties) limit 100000000)\r\n```\r\n\r\nWhen you describe the table, we can see it has `data.reason`:\r\n\r\n```\r\n\u2502 data.reason               \u2502 String \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502            1 \u2502\r\n```\r\n\r\nHowever, querying for it raises an error:\r\n\r\n```\r\nec2.internal :) select data.reason from test_json where data.reason <> '' limit 10;\r\n\r\nSELECT data.reason\r\nFROM test_json\r\nWHERE data.reason != ''\r\nLIMIT 10\r\n\r\nQuery id: 91e682c1-2650-4f3b-99d8-5eafdd0e2839\r\n\r\n[ip-172-31-90-127] 2022.03.18 13:29:50.471519 [ 311286 ] {91e682c1-2650-4f3b-99d8-5eafdd0e2839} <Debug> executeQuery: (from 127.0.0.1:60630) select data.reason from test_json where data.reason <> '' limit 10;\r\n[ip-172-31-90-127] 2022.03.18 13:29:50.471953 [ 311286 ] {91e682c1-2650-4f3b-99d8-5eafdd0e2839} <Trace> ContextAccess (default): Access granted: SELECT(`data.reason`) ON production.test_json\r\n[ip-172-31-90-127] 2022.03.18 13:29:50.472015 [ 311286 ] {91e682c1-2650-4f3b-99d8-5eafdd0e2839} <Trace> ContextAccess (default): Access granted: SELECT(`data.reason`) ON production.test_json\r\n[ip-172-31-90-127] 2022.03.18 13:29:50.472041 [ 311286 ] {91e682c1-2650-4f3b-99d8-5eafdd0e2839} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n[ip-172-31-90-127] 2022.03.18 13:29:50.472134 [ 311286 ] {91e682c1-2650-4f3b-99d8-5eafdd0e2839} <Debug> production.test_json (463749c6-4417-490e-939b-66e00b80baa2) (SelectExecutor): Key condition: unknown\r\n[ip-172-31-90-127] 2022.03.18 13:29:50.472401 [ 311286 ] {91e682c1-2650-4f3b-99d8-5eafdd0e2839} <Debug> production.test_json (463749c6-4417-490e-939b-66e00b80baa2) (SelectExecutor): Selected 8/8 parts by partition key, 8 parts by primary key, 12453/12453 marks by primary key, 12453 marks to read from 8 ranges\r\n[ip-172-31-90-127] 2022.03.18 13:29:50.472457 [ 311286 ] {91e682c1-2650-4f3b-99d8-5eafdd0e2839} <Debug> production.test_json (463749c6-4417-490e-939b-66e00b80baa2) (SelectExecutor): Reading approx. 102000000 rows with 2 streams\r\n[ip-172-31-90-127] 2022.03.18 13:29:50.489145 [ 311286 ] {91e682c1-2650-4f3b-99d8-5eafdd0e2839} <Error> executeQuery: Code: 49. DB::Exception: Can't adjust last granule because it has 8161 rows, but try to subtract 65505 rows.: While executing MergeTreeThread. (LOGICAL_ERROR) (version 22.3.2.1) (from 127.0.0.1:60630) (in query: select data.reason from test_json where data.reason <> '' limit 10;), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xa4dde1a in /usr/bin/clickhouse\r\n1. DB::Exception::Exception<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >&&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >&&) @ 0xbeaf7d9 in /usr/bin/clickhouse\r\n2. DB::MergeTreeRangeReader::ReadResult::adjustLastGranule() @ 0x1577c250 in /usr/bin/clickhouse\r\n3. DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::__1::deque<DB::MarkRange, std::__1::allocator<DB::MarkRange> >&) @ 0x15780044 in /usr/bin/clickhouse\r\n4. DB::MergeTreeRangeReader::read(unsigned long, std::__1::deque<DB::MarkRange, std::__1::allocator<DB::MarkRange> >&) @ 0x1577e815 in /usr/bin/clickhouse\r\n5. DB::MergeTreeBaseSelectProcessor::readFromPartImpl() @ 0x15774028 in /usr/bin/clickhouse\r\n6. DB::MergeTreeBaseSelectProcessor::readFromPart() @ 0x1577512d in /usr/bin/clickhouse\r\n7. DB::MergeTreeBaseSelectProcessor::generate() @ 0x157738a0 in /usr/bin/clickhouse\r\n8. DB::ISource::tryGenerate() @ 0x1548cdf5 in /usr/bin/clickhouse\r\n9. DB::ISource::work() @ 0x1548c9ba in /usr/bin/clickhouse\r\n10. DB::SourceWithProgress::work() @ 0x156e4282 in /usr/bin/clickhouse\r\n11. DB::ExecutionThreadContext::executeTask() @ 0x154ad143 in /usr/bin/clickhouse\r\n12. DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) @ 0x154a0b9e in /usr/bin/clickhouse\r\n13. ? @ 0x154a2504 in /usr/bin/clickhouse\r\n14. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xa584c97 in /usr/bin/clickhouse\r\n15. ? @ 0xa58881d in /usr/bin/clickhouse\r\n16. ? @ 0x7f421c9c6609 in ?\r\n17. __clone @ 0x7f421c8eb163 in ?\r\n\r\n\r\n0 rows in set. Elapsed: 0.018 sec.\r\n\r\nReceived exception from server (version 22.3.2):\r\nCode: 49. DB::Exception: Received from localhost:9000. DB::Exception: Can't adjust last granule because it has 8161 rows, but try to subtract 65505 rows.: While executing MergeTreeThread. (LOGICAL_ERROR)\r\n```\r\n\r\n**Expected behavior**\r\n\r\nNo exception raised.\n",
  "hints_text": "",
  "created_at": "2022-03-28T17:24:50Z"
}