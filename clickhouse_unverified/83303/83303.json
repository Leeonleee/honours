{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 83303,
  "instance_id": "ClickHouse__ClickHouse-83303",
  "issue_numbers": [
    "82385"
  ],
  "base_commit": "426c86a652bc0eefc8ecbfa4bb440566cd9f2d80",
  "patch": "diff --git a/docs/en/engines/table-engines/mergetree-family/invertedindexes.md b/docs/en/engines/table-engines/mergetree-family/invertedindexes.md\nindex 401200c2c7ff..5ee32b88d9c1 100644\n--- a/docs/en/engines/table-engines/mergetree-family/invertedindexes.md\n+++ b/docs/en/engines/table-engines/mergetree-family/invertedindexes.md\n@@ -192,6 +192,20 @@ SELECT count() FROM hackernews WHERE hasToken(lower(comment), 'clickhouse');\n \n These functions are the most performant options to use with the `text` index.\n \n+#### searchAny and searchAll {#functions-example-searchany-searchall}\n+\n+Functions `searchAny` and `searchAll` check if the column contains rows which match any or all of search terms.\n+\n+Compared to `hasToken`, these functions accept multiple search terms.\n+\n+Example:\n+\n+```sql\n+SELECT count() FROM hackernews WHERE searchAny(lower(comment), 'clickhouse chdb');\n+\n+SELECT count() FROM hackernews WHERE searchAll(lower(comment), 'clickhouse chdb');\n+```\n+\n ## Full-text search of the Hacker News dataset {#full-text-search-of-the-hacker-news-dataset}\n \n Let's look at the performance improvements of text indexes on a large dataset with lots of text.\ndiff --git a/docs/en/engines/table-engines/mergetree-family/mergetree.md b/docs/en/engines/table-engines/mergetree-family/mergetree.md\nindex 4570125f6288..a7b75f505adf 100644\n--- a/docs/en/engines/table-engines/mergetree-family/mergetree.md\n+++ b/docs/en/engines/table-engines/mergetree-family/mergetree.md\n@@ -463,6 +463,8 @@ Indexes of type `set` can be utilized by all functions. The other index types ar\n | [hasTokenOrNull](/sql-reference/functions/string-search-functions.md/#hastokenornull)                                          | \u2717           | \u2717      | \u2717          | \u2714          | \u2717            | \u2714    |\n | [hasTokenCaseInsensitive (`*`)](/sql-reference/functions/string-search-functions.md/#hastokencaseinsensitive)                  | \u2717           | \u2717      | \u2717          | \u2714          | \u2717            | \u2717    |\n | [hasTokenCaseInsensitiveOrNull (`*`)](/sql-reference/functions/string-search-functions.md/#hastokencaseinsensitiveornull)      | \u2717           | \u2717      | \u2717          | \u2714          | \u2717            | \u2717    |\n+| [searchAny](/sql-reference/functions/string-search-functions.md/#searchany)                                                    | \u2717           | \u2717      | \u2717          | \u2717          | \u2717            | \u2714    |\n+| [searchAll](/sql-reference/functions/string-search-functions.md/#searchall)                                                    | \u2717           | \u2717      | \u2717          | \u2717          | \u2717            | \u2714    |\n \n Functions with a constant argument that is less than ngram size can't be used by `ngrambf_v1` for query optimization.\n \ndiff --git a/docs/en/sql-reference/functions/string-search-functions.md b/docs/en/sql-reference/functions/string-search-functions.md\nindex bb1c537dc2ac..0533f1384da9 100644\n--- a/docs/en/sql-reference/functions/string-search-functions.md\n+++ b/docs/en/sql-reference/functions/string-search-functions.md\n@@ -755,6 +755,124 @@ Result:\n 1\n ```\n \n+## searchAny {#searchany}\n+\n+:::note\n+This function can only be used if setting [allow_experimental_full_text_index](/operations/settings/settings#allow_experimental_full_text_index) is true.\n+:::\n+\n+Returns 1, if at least one string needle<sub>i</sub> matches the `input` column and 0 otherwise.\n+\n+**Syntax**\n+\n+```sql\n+searchAny(input, ['needle1', 'needle2', ..., 'needleN'])\n+```\n+\n+**Parameters**\n+\n+- `input` \u2014 The input column. [String](../data-types/string.md) or [FixedString](../data-types/fixedstring.md).\n+- `needles` \u2014 tokens to be searched and supports a max of 64 tokens. [Array](../data-types/array.md)([String](../data-types/string.md)).\n+\n+:::note\n+This function must be used only with a [full-text index][/engines/table-engines/mergetree-family/invertedindexes.md] column.\n+The input data is tokenized by the tokenizer from the index definition.\n+:::\n+\n+:::note\n+Each string needle<sub>i</sub> would be tokenized as `tokens(needle<sub>i</sub>, [tokenizer from the index definition])`.\n+This means both `['word1;word2']` and `['word1,word2']` would be tokenized as `['word1','word2']` in case of the `default` tokenizer.\n+Refer [tokens](splitting-merging-functions.md#tokens) for more information about the supported separators.\n+:::\n+\n+**Returned value**\n+\n+- 1, if there was at least one match.\n+- 0, otherwise.\n+\n+**Example**\n+\n+Query:\n+\n+```sql\n+CREATE TABLE text_table (\n+    id UInt32,\n+    msg String,\n+    INDEX idx(msg) TYPE text(tokenizer = 'split', separators = ['()', '\\\\'])\n+)\n+ENGINE = MergeTree\n+ORDER BY id;\n+\n+INSERT INTO text_table VALUES (1, '()a,\\\\bc()d'), (2, '()\\\\a()bc\\\\d'), (3, ',()a\\\\,bc,(),d,');\n+\n+SELECT count() FROM `text_table` WHERE searchAny(msg, ['a', 'd']);\n+```\n+\n+Result:\n+\n+```response\n+3\n+```\n+\n+## searchAll {#searchall}\n+\n+:::note\n+This function can only be used if setting [allow_experimental_full_text_index](/operations/settings/settings#allow_experimental_full_text_index) is true.\n+:::\n+\n+Like [searchAny](#searchany), but returns 1 only if all string needle<sub>i</sub> matches the `input` column and 0 otherwise.\n+\n+**Syntax**\n+\n+```sql\n+searchAll(input, ['needle1', 'needle2', ..., 'needleN'])\n+```\n+\n+**Parameters**\n+\n+- `input` \u2014 The input column. [String](../data-types/string.md) or [FixedString](../data-types/fixedstring.md).\n+- `needles` \u2014 tokens to be searched and supports a max of 64 tokens. [Array](../data-types/array.md)([String](../data-types/string.md)).\n+\n+:::note\n+This function must be used only with a [full-text index][/engines/table-engines/mergetree-family/invertedindexes.md] column.\n+The input data is tokenized by the tokenizer from the index definition.\n+:::\n+\n+:::note\n+Each string needle<sub>i</sub> would be tokenized as `tokens(needle<sub>i</sub>, [tokenizer from the index definition])`.\n+This means both `['word1;word2']` and `['word1,word2']` would be tokenized as `['word1','word2']` in case of the `default` tokenizer.\n+Refer [tokens](splitting-merging-functions.md#tokens) for more information about the supported separators.\n+:::\n+\n+**Returned value**\n+\n+- 1, if all needles match.\n+- 0, otherwise.\n+\n+**Example**\n+\n+Query:\n+\n+```sql\n+CREATE TABLE text_table (\n+    id UInt32,\n+    msg String,\n+    INDEX idx(msg) TYPE text(tokenizer = 'split', separators = ['()', '\\\\']) GRANULARITY 1\n+)\n+ENGINE = MergeTree\n+ORDER BY id;\n+\n+INSERT INTO `text_table` VALUES (1, '()a,\\\\bc()d'), (2, '()\\\\a()bc\\\\d'), (3, ',()a\\\\,bc,(),d,');\n+\n+SELECT count() FROM `text_table` WHERE searchAll(msg, ['a', 'd']);\n+```\n+\n+Result:\n+\n+```response\n+1\n+```\n+\n ## match {#match}\n \n Returns whether string `haystack` matches the regular expression `pattern` in [re2 regular expression syntax](https://github.com/google/re2/wiki/Syntax).\ndiff --git a/src/Functions/searchAnyAll.cpp b/src/Functions/searchAnyAll.cpp\nindex 0a2481a0622b..b8f1fa0ea2a5 100644\n--- a/src/Functions/searchAnyAll.cpp\n+++ b/src/Functions/searchAnyAll.cpp\n@@ -228,4 +228,22 @@ template class FunctionSearchImpl<traits::SearchAllTraits>;\n \n FunctionDocumentation::IntroducedIn introduced_in = {25, 7};\n FunctionDocumentation::Category category = FunctionDocumentation::Category::StringSearch;\n+\n+REGISTER_FUNCTION(SearchAny)\n+{\n+    factory.registerFunction<FunctionSearchImpl<traits::SearchAnyTraits>>(FunctionDocumentation{\n+        .description = \"Searches the needle tokens in the generated tokens from the text by a given tokenizer. Returns true if any needle \"\n+                       \"tokens exists in the text, otherwise false.\",\n+        .introduced_in = introduced_in,\n+        .category = category});\n+}\n+\n+REGISTER_FUNCTION(SearchAll)\n+{\n+    factory.registerFunction<FunctionSearchImpl<traits::SearchAllTraits>>(FunctionDocumentation{\n+        .description = \"Searches the needle tokens in the generated tokens from the text by a given tokenizer. Returns true if all needle \"\n+                       \"tokens exists in the text, otherwise false.\",\n+        .introduced_in = introduced_in,\n+        .category = category});\n+}\n }\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex 35281af6d860..6b9999cbb0cb 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -54,6 +54,7 @@\n #include <Interpreters/evaluateConstantExpression.h>\n #include <Interpreters/ExpressionAnalyzer.h>\n #include <Interpreters/ExpressionActions.h>\n+#include <Interpreters/GinFilter.h>\n #include <Interpreters/InterpreterSelectQuery.h>\n #include <Interpreters/MergeTreeTransaction.h>\n #include <Interpreters/PartLog.h>\n@@ -877,6 +878,7 @@ void MergeTreeData::checkProperties(\n     if (!new_metadata.secondary_indices.empty())\n     {\n         std::unordered_set<String> indices_names;\n+        std::unordered_set<String> columns_with_text_indexes;\n \n         for (const auto & index : new_metadata.secondary_indices)\n         {\n@@ -891,10 +893,25 @@ void MergeTreeData::checkProperties(\n \n             MergeTreeIndexFactory::instance().validate(index, attach);\n \n-            if (indices_names.find(index.name) != indices_names.end())\n+            if (indices_names.contains(index.name))\n                 throw Exception(ErrorCodes::LOGICAL_ERROR, \"Index with name {} already exists\", backQuote(index.name));\n \n             indices_names.insert(index.name);\n+\n+            /// Workaround for https://github.com/ClickHouse/ClickHouse/issues/82385 where functions searchAll/searchAny don't work\n+            /// on columns with more than one text index\n+            if (index.type == TEXT_INDEX_NAME)\n+            {\n+                const auto & column = index.column_names[0];\n+\n+                if (columns_with_text_indexes.contains(column))\n+                    throw Exception(\n+                        ErrorCodes::BAD_ARGUMENTS,\n+                        \"Column {} must not have more than one text index\",\n+                        backQuote(index.column_names[0]));\n+\n+                columns_with_text_indexes.insert(column);\n+            }\n         }\n     }\n \n@@ -914,7 +931,7 @@ void MergeTreeData::checkProperties(\n \n         for (const auto & projection : new_metadata.projections)\n         {\n-            if (projections_names.find(projection.name) != projections_names.end())\n+            if (projections_names.contains(projection.name))\n                 throw Exception(ErrorCodes::LOGICAL_ERROR, \"Projection with name {} already exists\", backQuote(projection.name));\n \n             const auto settings = getSettings();\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02346_text_index_creation.reference b/tests/queries/0_stateless/02346_text_index_creation.reference\nindex da9d56b5208f..beb711b93178 100644\n--- a/tests/queries/0_stateless/02346_text_index_creation.reference\n+++ b/tests/queries/0_stateless/02346_text_index_creation.reference\n@@ -13,4 +13,7 @@ Parameters are shuffled.\n Types are incorrect.\n Same argument appears >1 times.\n Must be created on single column.\n+A column must not have >1 text index\n+-- CREATE TABLE\n+-- ALTER TABLE\n Must be created on String or FixedString or LowCardinality(String) or LowCardinality(FixedString) columns.\ndiff --git a/tests/queries/0_stateless/02346_text_index_creation.sql b/tests/queries/0_stateless/02346_text_index_creation.sql\nindex ef159da3636b..5e657f3a8ee7 100644\n--- a/tests/queries/0_stateless/02346_text_index_creation.sql\n+++ b/tests/queries/0_stateless/02346_text_index_creation.sql\n@@ -267,6 +267,34 @@ CREATE TABLE tab\n )\n ENGINE = MergeTree ORDER BY key; -- { serverError INCORRECT_NUMBER_OF_COLUMNS }\n \n+SELECT 'A column must not have >1 text index';\n+\n+SELECT '-- CREATE TABLE';\n+\n+CREATE TABLE tab(\n+    s String,\n+    INDEX idx_1(s) TYPE text(tokenizer = 'default'),\n+    INDEX idx_2(s) TYPE text(tokenizer = 'ngram', ngram_size = 3)\n+)\n+Engine = MergeTree()\n+ORDER BY tuple(); -- { serverError BAD_ARGUMENTS }\n+\n+SELECT '-- ALTER TABLE';\n+\n+CREATE TABLE tab\n+(\n+    str String,\n+    INDEX idx_1 (str) TYPE text(tokenizer = 'default')\n+)\n+ENGINE = MergeTree ORDER BY tuple();\n+\n+ALTER TABLE tab ADD INDEX idx_2(str) TYPE text(tokenizer = 'ngram', ngram_size = 3); -- { serverError BAD_ARGUMENTS }\n+\n+-- It must still be possible to create a column on the same column with a different expression\n+ALTER TABLE tab ADD INDEX idx_3(lower(str)) TYPE text(tokenizer = 'ngram', ngram_size = 3);\n+\n+DROP TABLE tab;\n+\n SELECT 'Must be created on String or FixedString or LowCardinality(String) or LowCardinality(FixedString) columns.';\n \n CREATE TABLE tab\ndiff --git a/tests/queries/0_stateless/02346_text_index_function_search.reference b/tests/queries/0_stateless/02346_text_index_function_search.reference\nnew file mode 100644\nindex 000000000000..96ef0a2148e6\n--- /dev/null\n+++ b/tests/queries/0_stateless/02346_text_index_function_search.reference\n@@ -0,0 +1,199 @@\n+Negative tests\n+Default tokenizer\n+[1,2,3,4,5,6]\n+[]\n+[1,3,5]\n+[2,4,6]\n+[1,2,3,4,5,6]\n+[1,2,3,4,5,6]\n+[1,2,3,4,5,6]\n+[1,3,5]\n+[]\n+[1,2,3,4,5,6]\n+[1,2,3,4,5,6]\n+[1,2,3,4,5,6]\n+[1,3,5]\n+[]\n+[1,2,3,4,5,6]\n+[]\n+[1,3,5]\n+[2,4,6]\n+[1,3,5]\n+[2,4,6]\n+[]\n+[]\n+[1,3,5]\n+[2,4,6]\n+[]\n+[]\n+Ngram tokenizer\n+[3,4,5]\n+[]\n+[1,2,3]\n+[2,3,4]\n+[1,2,3,4]\n+[1,2,3,4,5]\n+[3,4,5]\n+[]\n+[1,2,3]\n+[2,3,4]\n+[2,3]\n+[3]\n+Split tokenizer\n+[2,3]\n+[2,4,5]\n+[2,5]\n+[2,3,4,5]\n+[2,3,5]\n+[2,4,5]\n+[2,3]\n+[2,4,5]\n+[2,5]\n+[2]\n+[2]\n+[2,5]\n+NoOp tokenizer\n+[]\n+[]\n+[]\n+[4]\n+[]\n+[]\n+[]\n+[4]\n+Text index analysis\n+searchAny is used during index analysis\n+Text index should choose none for non-existent term\n+Description: text GRANULARITY 1\n+Parts: 0/4\n+Granules: 0/4096\n+Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 1/4\n+Granules: 1024/4096\n+Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 1/4\n+Granules: 1024/4096\n+Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 1/4\n+Granules: 1024/4096\n+Text index should choose 2 parts and 2048 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 2/4\n+Granules: 2048/4096\n+Text index should choose 2 parts and 2048 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 2/4\n+Granules: 2048/4096\n+Text index should choose 2 parts and 2048 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 2/4\n+Granules: 2048/4096\n+Text index should choose 3 parts and 3072 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 3/4\n+Granules: 3072/4096\n+Text index should choose 3 parts and 3072 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 3/4\n+Granules: 3072/4096\n+Text index should choose all 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 4/4\n+Granules: 4096/4096\n+Text index should choose all 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 4/4\n+Granules: 4096/4096\n+searchAll is used during index analysis\n+Text index should choose none for non-existent term\n+Description: text GRANULARITY 1\n+Parts: 0/4\n+Granules: 0/4096\n+Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 1/4\n+Granules: 1024/4096\n+Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 1/4\n+Granules: 1024/4096\n+Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 1/4\n+Granules: 1024/4096\n+Text index should choose none if any term does not exists in dictionary\n+Description: text GRANULARITY 1\n+Parts: 0/4\n+Granules: 0/4096\n+Text index should choose none if any term does not exists in dictionary\n+Description: text GRANULARITY 1\n+Parts: 0/4\n+Granules: 0/4096\n+Text index should choose 2 parts and 2048 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 2/4\n+Granules: 2048/4096\n+Text index should choose none\n+Description: text GRANULARITY 1\n+Parts: 0/4\n+Granules: 0/4096\n+Text index should choose none\n+Description: text GRANULARITY 1\n+Parts: 0/4\n+Granules: 0/4096\n+Text index should choose none\n+Description: text GRANULARITY 1\n+Parts: 0/4\n+Granules: 0/4096\n+Text index should choose none\n+Description: text GRANULARITY 1\n+Parts: 0/4\n+Granules: 0/4096\n+Text index should choose 3 parts and 3072 granules out of 4 parts and 4096 granules\n+Description: text GRANULARITY 1\n+Parts: 3/4\n+Granules: 3072/4096\n+Text index should choose none\n+Description: text GRANULARITY 1\n+Parts: 0/4\n+Granules: 0/4096\n+Text index should choose none\n+Description: text GRANULARITY 1\n+Parts: 0/4\n+Granules: 0/4096\n+Chooses mixed granules inside part\n+Text index should choose 50% of granules\n+Description: text GRANULARITY 1\n+Parts: 1/1\n+Granules: 512/1024\n+Text index should choose 50% of granules\n+Description: text GRANULARITY 1\n+Parts: 1/1\n+Granules: 512/1024\n+Text index should choose all granules\n+Description: text GRANULARITY 1\n+Parts: 1/1\n+Granules: 1024/1024\n+Text index should choose all granules\n+Description: text GRANULARITY 1\n+Parts: 1/1\n+Granules: 1024/1024\n+Text index should choose 25% of granules\n+Description: text GRANULARITY 1\n+Parts: 1/1\n+Granules: 256/1024\n+Text index should choose 25% of granules\n+Description: text GRANULARITY 1\n+Parts: 1/1\n+Granules: 256/1024\n+Text index should choose 25% of granules\n+Description: text GRANULARITY 1\n+Parts: 1/1\n+Granules: 256/1024\n+Text index should choose 25% of granules\n+Description: text GRANULARITY 1\n+Parts: 1/1\n+Granules: 256/1024\ndiff --git a/tests/queries/0_stateless/02346_text_index_function_search.sql b/tests/queries/0_stateless/02346_text_index_function_search.sql\nnew file mode 100644\nindex 000000000000..da5a8f7e7e52\n--- /dev/null\n+++ b/tests/queries/0_stateless/02346_text_index_function_search.sql\n@@ -0,0 +1,509 @@\n+-- Tags: no-parallel-replicas\n+\n+SET enable_analyzer = 1;\n+SET allow_experimental_full_text_index = 1;\n+\n+DROP TABLE IF EXISTS tab;\n+\n+SELECT 'Negative tests';\n+\n+CREATE TABLE tab\n+(\n+    id UInt32,\n+    col_str String,\n+    message String,\n+    arr Array(String),\n+    INDEX idx(`message`) TYPE text(tokenizer = 'default'),\n+)\n+ENGINE = MergeTree\n+ORDER BY (id);\n+\n+INSERT INTO tab VALUES (1, 'b', 'b', ['c']);\n+\n+-- Must accept two arguments\n+SELECT id FROM tab WHERE searchAny(); -- { serverError NUMBER_OF_ARGUMENTS_DOESNT_MATCH }\n+SELECT id FROM tab WHERE searchAny('a', 'b', 'c'); -- { serverError NUMBER_OF_ARGUMENTS_DOESNT_MATCH }\n+SELECT id FROM tab WHERE searchAll(); -- { serverError NUMBER_OF_ARGUMENTS_DOESNT_MATCH }\n+SELECT id FROM tab WHERE searchAll('a', 'b', 'c'); -- { serverError NUMBER_OF_ARGUMENTS_DOESNT_MATCH }\n+-- 1st arg must be String or FixedString\n+SELECT id FROM tab WHERE searchAny(1, ['a']); -- { serverError ILLEGAL_TYPE_OF_ARGUMENT }\n+SELECT id FROM tab WHERE searchAll(1, ['a']); -- { serverError ILLEGAL_TYPE_OF_ARGUMENT }\n+-- 2nd arg must be const Array(String)\n+SELECT id FROM tab WHERE searchAny(message, 'b'); -- { serverError ILLEGAL_TYPE_OF_ARGUMENT }\n+SELECT id FROM tab WHERE searchAny(message, materialize('b')); -- { serverError ILLEGAL_TYPE_OF_ARGUMENT }\n+SELECT id FROM tab WHERE searchAny(message, materialize(['b'])); -- { serverError ILLEGAL_COLUMN }\n+SELECT id FROM tab WHERE searchAll(message, 'b'); -- { serverError ILLEGAL_TYPE_OF_ARGUMENT }\n+SELECT id FROM tab WHERE searchAll(message, materialize('b')); -- { serverError ILLEGAL_TYPE_OF_ARGUMENT }\n+SELECT id FROM tab WHERE searchAll(message, materialize(['b'])); -- { serverError ILLEGAL_COLUMN }\n+-- search functions must be called on a column with text index\n+SELECT id FROM tab WHERE searchAny('a', ['b']); -- { serverError BAD_ARGUMENTS }\n+SELECT id FROM tab WHERE searchAny(col_str, ['b']); -- { serverError BAD_ARGUMENTS }\n+SELECT id FROM tab WHERE searchAll('a', ['b']); -- { serverError BAD_ARGUMENTS }\n+SELECT id FROM tab WHERE searchAll(col_str, ['b']); -- { serverError BAD_ARGUMENTS }\n+-- search function supports a max of 64 needles\n+SELECT id FROM tab WHERE searchAny(message, ['a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j k l m']); -- { serverError BAD_ARGUMENTS }\n+SELECT id FROM tab WHERE searchAny(message, ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm']); -- { serverError BAD_ARGUMENTS }\n+\n+DROP TABLE tab;\n+\n+SELECT 'Default tokenizer';\n+\n+CREATE TABLE tab\n+(\n+    id UInt32,\n+    message String,\n+    INDEX idx(`message`) TYPE text(tokenizer = 'default'),\n+)\n+ENGINE = MergeTree\n+ORDER BY (id);\n+\n+INSERT INTO tab(id, message)\n+VALUES\n+    (1, 'abc+ def- foo!'),\n+    (2, 'abc+ def- bar?'),\n+    (3, 'abc+ baz- foo!'),\n+    (4, 'abc+ baz- bar?'),\n+    (5, 'abc+ zzz- foo!'),\n+    (6, 'abc+ zzz- bar?');\n+\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['abc']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['ab']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['foo']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['bar']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['abc foo!']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['abc bar?']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['foo bar']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['foo ba']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['fo ba']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['abc', 'foo!']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['abc', 'bar?']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['foo', 'bar']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['foo', 'ba']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['fo', 'ba']);\n+\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['abc']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['ab']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['foo']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['bar']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['abc foo!']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['abc bar?']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['foo bar']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['abc fo']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['abc', 'foo!']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['abc', 'bar?']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['foo', 'bar']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['abc', 'fo']);\n+\n+DROP TABLE tab;\n+\n+SELECT 'Ngram tokenizer';\n+\n+CREATE TABLE tab\n+(\n+    id UInt32,\n+    message String,\n+    INDEX idx(`message`) TYPE text(tokenizer = 'ngram', ngram_size = 4),\n+)\n+ENGINE = MergeTree\n+ORDER BY (id);\n+\n+INSERT INTO tab\n+VALUES\n+(1, 'abcdef'),\n+(2, 'bcdefg'),\n+(3, 'cdefgh'),\n+(4, 'defghi'),\n+(5, 'efghij');\n+\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['efgh']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['efg']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['cdef']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['defg']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['cdef', 'defg']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['efgh', 'cdef', 'defg']);\n+\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['efgh']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['efg']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['cdef']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['defg']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['cdef', 'defg']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['efgh', 'cdef', 'defg']);\n+\n+DROP TABLE tab;\n+\n+SELECT 'Split tokenizer';\n+\n+CREATE TABLE tab\n+(\n+    id UInt32,\n+    message String,\n+    INDEX idx(`message`) TYPE text(tokenizer = 'split', separators = ['()', '\\\\']),\n+)\n+ENGINE = MergeTree\n+ORDER BY (id);\n+\n+INSERT INTO tab\n+VALUES\n+(1, '  a  bc d'),\n+(2, '()()a()bc()d'),\n+(3, ',()a(),bc,(),d,'),\n+(4, '\\\\a\\n\\\\bc\\\\d\\n'),\n+(5, '\\na\\n\\\\bc\\\\d\\\\');\n+\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['a']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['bc']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['d']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['a', 'bc']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['a', 'd']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['bc', 'd']);\n+\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['a']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['bc']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['d']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['a', 'bc']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['a', 'd']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['bc', 'd']);\n+\n+DROP TABLE tab;\n+\n+SELECT 'NoOp tokenizer';\n+\n+CREATE TABLE tab\n+(\n+    id UInt32,\n+    message String,\n+    INDEX idx(`message`) TYPE text(tokenizer = 'no_op'),\n+)\n+ENGINE = MergeTree\n+ORDER BY (id);\n+\n+INSERT INTO tab\n+VALUES\n+(1, 'abc def'),\n+(2, 'abc fgh'),\n+(3, 'def efg'),\n+(4, 'abcdef');\n+\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['abc']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['def']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['abc', 'def']);\n+SELECT groupArray(id) FROM tab WHERE searchAny(message, ['abcdef']);\n+\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['abc']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['def']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['abc', 'def']);\n+SELECT groupArray(id) FROM tab WHERE searchAll(message, ['abcdef']);\n+\n+DROP TABLE tab;\n+\n+SELECT 'Text index analysis';\n+\n+DROP TABLE IF EXISTS tab;\n+CREATE TABLE tab\n+(\n+    id UInt32,\n+    message String,\n+    INDEX idx(`message`) TYPE text(tokenizer = 'default') GRANULARITY 1\n+)\n+ENGINE = MergeTree\n+ORDER BY (id)\n+SETTINGS index_granularity = 1;\n+\n+INSERT INTO tab SELECT number, 'Hello, ClickHouse' FROM numbers(1024);\n+INSERT INTO tab SELECT number, 'Hello, World' FROM numbers(1024);\n+INSERT INTO tab SELECT number, 'Hallo, ClickHouse' FROM numbers(1024);\n+INSERT INTO tab SELECT number, 'ClickHouse is the fast, really fast!' FROM numbers(1024);\n+\n+SELECT 'searchAny is used during index analysis';\n+\n+SELECT 'Text index should choose none for non-existent term';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Click'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3; -- Skip the primary index parts and granules.\n+\n+SELECT 'Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hallo'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hallo Word']) -- Word does not exist in terms\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hallo', 'Word']) -- Word does not exist in terms\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 2 parts and 2048 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hello Word'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 2 parts and 2048 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hello', 'Word'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 2 parts and 2048 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hallo', 'World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 3 parts and 3072 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hello', 'Hallo'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 3 parts and 3072 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['ClickHouse'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose all 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['ClickHouse World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose all 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['ClickHouse', 'World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'searchAll is used during index analysis';\n+\n+SELECT 'Text index should choose none for non-existent term';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Click'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hallo'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hello World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 1 part and 1024 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hello', 'World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose none if any term does not exists in dictionary';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hallo Word']) -- Word does not exist in terms\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose none if any term does not exists in dictionary';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hallo', 'Word']) -- Word does not exist in terms\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 2 parts and 2048 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hello'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose none';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hallo World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose none';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hallo', 'World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose none';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hello Hallo'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose none';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hello', 'Hallo'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 3 parts and 3072 granules out of 4 parts and 4096 granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['ClickHouse'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose none';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['ClickHouse World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose none';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['ClickHouse', 'World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+DROP TABLE tab;\n+\n+SELECT 'Chooses mixed granules inside part';\n+\n+DROP TABLE IF EXISTS tab;\n+CREATE TABLE tab\n+(\n+    id UInt32,\n+    message String,\n+    INDEX idx(`message`) TYPE text(tokenizer = 'default') GRANULARITY 1\n+)\n+ENGINE = MergeTree\n+ORDER BY (id)\n+SETTINGS index_granularity = 1;\n+\n+INSERT INTO tab\n+SELECT\n+    number,\n+    CASE\n+        WHEN modulo(number, 4) = 0 THEN 'Hello, ClickHouse'\n+        WHEN modulo(number, 4) = 1 THEN 'Hello, World'\n+        WHEN modulo(number, 4) = 2 THEN 'Hallo, ClickHouse'\n+        WHEN modulo(number, 4) = 3 THEN 'ClickHouse is the fast, really fast!'\n+    END\n+FROM numbers(1024);\n+\n+SELECT 'Text index should choose 50% of granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hello World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 50% of granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hello', 'World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose all granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hello ClickHouse'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose all granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAny(message, ['Hello', 'ClickHouse'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 25% of granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hello World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 25% of granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hello', 'World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 25% of granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hello World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n+\n+SELECT 'Text index should choose 25% of granules';\n+SELECT trimLeft(explain) AS explain FROM (\n+    EXPLAIN indexes=1\n+    SELECT count() FROM tab WHERE searchAll(message, ['Hello', 'World'])\n+)\n+WHERE explain LIKE '%Description:%' OR explain LIKE '%Parts:%' OR explain LIKE '%Granules:%'\n+LIMIT 2, 3;\n",
  "problem_statement": "Logical error: 'Function 'searchAll': Different index parameters are set.'\n### Describe the bug\n\nFrom this run: https://s3.amazonaws.com/clickhouse-test-reports/json.html?REF=master&sha=f3fb09bdc74ff0cdd69482e890712679b22fa1fb&name_0=MasterCI&name_1=AST%20fuzzer%20%28amd_ubsan%29\n\n### How to reproduce\n\nI tried to reduce the script, but had no success.\n\n### Error message and/or stacktrace\n\nStack trace:\n\n```\n10353681:[ip-172-31-16-219] 2025.06.23 03:39:40.658639 [ 690 ] {ca51a612-41e2-49c0-8ca2-109fac09e1af} <Fatal> : Logical error: 'Function 'searchAll': Different index parameters are set.'.\n10353682:[ip-172-31-16-219] 2025.06.23 03:39:40.693899 [ 690 ] {ca51a612-41e2-49c0-8ca2-109fac09e1af} <Fatal> : Stack trace (when copying this message, always include the lines below):\n10353717:[ip-172-31-16-219] 2025.06.23 03:43:41.229316 [ 2015 ] <Fatal> BaseDaemon: ########################################\n10353718:[ip-172-31-16-219] 2025.06.23 03:43:41.229354 [ 2015 ] <Fatal> BaseDaemon: (version 25.7.1.961 (official build), build id: 82784692F639DC3E6DA91085669A31370DDADDD0, git hash: f3fb09bdc74ff0cdd69482e890712679b22fa1fb) (from thread 690) (query_id: ca51a612-41e2-49c0-8ca2-109fac09e1af) (query: SELECT groupArray(id) FROM tab__fuzz_1 INNER JOIN (SELECT DISTINCT * FROM `03165_token_ft` PREWHERE endsWith('eady', message) WHERE endsWith('eady', message)) AS alias7439 ON alias7439.message = message WHERE searchAll(message, ['a', 'bc'])) Received signal Aborted (6)\n10353719:[ip-172-31-16-219] 2025.06.23 03:43:41.229390 [ 2015 ] <Fatal> BaseDaemon: \n10353720:[ip-172-31-16-219] 2025.06.23 03:43:41.229430 [ 2015 ] <Fatal> BaseDaemon: Stack trace: 0x00007ffa596129fd 0x00007ffa595be476 0x00007ffa595a47f3 0x000056419c1a5e57 0x000056419c1a687c 0x000056419c1a6d75 0x000056418e08a136 0x000056418e09e68f 0x000056419c14948e 0x00005641aa384064 0x00005641aa3815e0 0x00005641aa390092 0x00005641aa390359 0x00005641aa390359 0x00005641aa37e705 0x00005641aa39279f 0x00005641aa3925b4 0x00005641aa3869b4 0x00005641ab8af7b3 0x00005641ab8adc7d 0x00005641ab9bbc7c 0x00005641ab9bb312 0x00005641ab9b8041 0x00005641ab860e84 0x00005641ab860497 0x00005641a71af6d3 0x00005641a71af2a6 0x00005641a76797da 0x00005641a76732f4 0x00005641aac3b871 0x00005641aac6e00a 0x00005641aef34402 0x00005641aef350d2 0x00005641aee9a057 0x00005641aee95a4e 0x00007ffa59610ac3 0x00007ffa596a2850\n10353721:[ip-172-31-16-219] 2025.06.23 03:43:41.229499 [ 2015 ] <Fatal> BaseDaemon: 3. __GI___pthread_kill @ 0x00000000000969fd\n10353722:[ip-172-31-16-219] 2025.06.23 03:43:41.229534 [ 2015 ] <Fatal> BaseDaemon: 4. __GI_raise @ 0x0000000000042476\n10353723:[ip-172-31-16-219] 2025.06.23 03:43:41.229582 [ 2015 ] <Fatal> BaseDaemon: 5. __lgamma_r_finite@GLIBC_2.15 @ 0x00000000000287f3\n10353724:[ip-172-31-16-219] 2025.06.23 03:43:41.241621 [ 2015 ] <Fatal> BaseDaemon: 6. ci/tmp/build/./src/Common/Exception.cpp:50: DB::abortOnFailedAssertion(String const&, void* const*, unsigned long, unsigned long) @ 0x000000002736de57\n10353725:[ip-172-31-16-219] 2025.06.23 03:43:41.253202 [ 2015 ] <Fatal> BaseDaemon: 7. ci/tmp/build/./src/Common/Exception.cpp:73: DB::handle_error_code(String const&, std::basic_string_view<char, std::char_traits<char>>, int, bool, std::vector<void*, std::allocator<void*>> const&) @ 0x000000002736e87c\n10353726:[ip-172-31-16-219] 2025.06.23 03:43:41.264973 [ 2015 ] <Fatal> BaseDaemon: 8. ci/tmp/build/./src/Common/Exception.cpp:121: DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000002736ed75\n10353727:[ip-172-31-16-219] 2025.06.23 03:43:41.310972 [ 2015 ] <Fatal> BaseDaemon: 9. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000019252136\n10353728:[ip-172-31-16-219] 2025.06.23 03:43:41.341344 [ 2015 ] <Fatal> BaseDaemon: 10. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x000000001926668f\n10353729:[ip-172-31-16-219] 2025.06.23 03:43:41.372620 [ 2015 ] <Fatal> BaseDaemon: 11. DB::FunctionSearchImpl<DB::traits::SearchAllTraits>::setGinFilterParameters(DB::GinFilterParameters const&) @ 0x000000002731148e\n10353730:[ip-172-31-16-219] 2025.06.23 03:43:41.403292 [ 2015 ] <Fatal> BaseDaemon: 12. ci/tmp/build/./src/Storages/MergeTree/MergeTreeIndexGin.cpp:622: DB::MergeTreeIndexConditionGin::traverseASTEquals(DB::RPNBuilderFunctionTreeNode const&, DB::RPNBuilderTreeNode const&, std::shared_ptr<DB::IDataType const> const&, DB::Field const&, DB::MergeTreeIndexConditionGin::RPNElement&) @ 0x000000003554c064\n10353731:[ip-172-31-16-219] 2025.06.23 03:43:41.431312 [ 2015 ] <Fatal> BaseDaemon: 13. ci/tmp/build/./src/Storages/MergeTree/MergeTreeIndexGin.cpp:464: DB::MergeTreeIndexConditionGin::traverseAtomAST(DB::RPNBuilderTreeNode const&, DB::MergeTreeIndexConditionGin::RPNElement&) @ 0x00000000355495e0\n10353732:[ip-172-31-16-219] 2025.06.23 03:43:41.458099 [ 2015 ] <Fatal> BaseDaemon: 14.0. inlined from contrib/llvm-project/libcxx/include/__functional/function.h:716: ?\n10353733:[ip-172-31-16-219] 2025.06.23 03:43:41.458140 [ 2015 ] <Fatal> BaseDaemon: 14.1. inlined from contrib/llvm-project/libcxx/include/__functional/function.h:989: ?\n10353734:[ip-172-31-16-219] 2025.06.23 03:43:41.458190 [ 2015 ] <Fatal> BaseDaemon: 14. src/Storages/MergeTree/RPNBuilder.h:245: DB::RPNBuilder<DB::MergeTreeIndexConditionGin::RPNElement>::traverseTree(DB::RPNBuilderTreeNode const&) @ 0x0000000035558092\n10353735:[ip-172-31-16-219] 2025.06.23 03:43:41.484603 [ 2015 ] <Fatal> BaseDaemon: 15. src/Storages/MergeTree/RPNBuilder.h:226: DB::RPNBuilder<DB::MergeTreeIndexConditionGin::RPNElement>::traverseTree(DB::RPNBuilderTreeNode const&) @ 0x0000000035558359\n10353736:[ip-172-31-16-219] 2025.06.23 03:43:41.510968 [ 2015 ] <Fatal> BaseDaemon: 16. src/Storages/MergeTree/RPNBuilder.h:226: DB::RPNBuilder<DB::MergeTreeIndexConditionGin::RPNElement>::traverseTree(DB::RPNBuilderTreeNode const&) @ 0x0000000035558359\n10353737:[ip-172-31-16-219] 2025.06.23 03:43:41.533519 [ 2015 ] <Fatal> BaseDaemon: 17.0. inlined from src/Storages/MergeTree/RPNBuilder.h:205: RPNBuilder\n10353738:[ip-172-31-16-219] 2025.06.23 03:43:41.533578 [ 2015 ] <Fatal> BaseDaemon: 17. ci/tmp/build/./src/Storages/MergeTree/MergeTreeIndexGin.cpp:218: DB::MergeTreeIndexConditionGin::MergeTreeIndexConditionGin(DB::ActionsDAG::Node const*, std::shared_ptr<DB::Context const>, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor const*) @ 0x0000000035546705\n10353739:[ip-172-31-16-219] 2025.06.23 03:43:41.567978 [ 2015 ] <Fatal> BaseDaemon: 18.0. inlined from contrib/llvm-project/libcxx/include/__memory/construct_at.h:41: DB::MergeTreeIndexConditionGin* std::construct_at[abi:ne190107]<DB::MergeTreeIndexConditionGin, DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*, DB::MergeTreeIndexConditionGin*>(DB::MergeTreeIndexConditionGin*, DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*&&)\n10353740:[ip-172-31-16-219] 2025.06.23 03:43:41.568047 [ 2015 ] <Fatal> BaseDaemon: 18.1. inlined from contrib/llvm-project/libcxx/include/__memory/construct_at.h:49: DB::MergeTreeIndexConditionGin* std::__construct_at[abi:ne190107]<DB::MergeTreeIndexConditionGin, DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*, DB::MergeTreeIndexConditionGin*>(DB::MergeTreeIndexConditionGin*, DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*&&)\n10353741:[ip-172-31-16-219] 2025.06.23 03:43:41.568104 [ 2015 ] <Fatal> BaseDaemon: 18.2. inlined from contrib/llvm-project/libcxx/include/__memory/allocator_traits.h:328: void std::allocator_traits<std::allocator<DB::MergeTreeIndexConditionGin>>::construct[abi:ne190107]<DB::MergeTreeIndexConditionGin, DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*, void, 0>(std::allocator<DB::MergeTreeIndexConditionGin>&, DB::MergeTreeIndexConditionGin*, DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*&&)\n10353742:[ip-172-31-16-219] 2025.06.23 03:43:41.568135 [ 2015 ] <Fatal> BaseDaemon: 18. contrib/llvm-project/libcxx/include/__memory/shared_ptr.h:264: std::__shared_ptr_emplace<DB::MergeTreeIndexConditionGin, std::allocator<DB::MergeTreeIndexConditionGin>>::__shared_ptr_emplace[abi:ne190107]<DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*, std::allocator<DB::MergeTreeIndexConditionGin>, 0>(std::allocator<DB::MergeTreeIndexConditionGin>, DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*&&) @ 0x000000003555a79f\n10353743:[ip-172-31-16-219] 2025.06.23 03:43:41.602279 [ 2015 ] <Fatal> BaseDaemon: 19. contrib/llvm-project/libcxx/include/__memory/shared_ptr.h:843: std::shared_ptr<DB::MergeTreeIndexConditionGin> std::allocate_shared[abi:ne190107]<DB::MergeTreeIndexConditionGin, std::allocator<DB::MergeTreeIndexConditionGin>, DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*, 0>(std::allocator<DB::MergeTreeIndexConditionGin> const&, DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*&&) @ 0x000000003555a5b4\n10353744:[ip-172-31-16-219] 2025.06.23 03:43:41.631726 [ 2015 ] <Fatal> BaseDaemon: 20.0. inlined from contrib/llvm-project/libcxx/include/__memory/shared_ptr.h:851: std::shared_ptr<DB::MergeTreeIndexConditionGin> std::make_shared[abi:ne190107]<DB::MergeTreeIndexConditionGin, DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*, 0>(DB::ActionsDAG::Node const*&, std::shared_ptr<DB::Context const>&, DB::Block const&, DB::GinFilterParameters const&, DB::ITokenExtractor*&&)\n10353745:[ip-172-31-16-219] 2025.06.23 03:43:41.631781 [ 2015 ] <Fatal> BaseDaemon: 20. ci/tmp/build/./src/Storages/MergeTree/MergeTreeIndexGin.cpp:841: DB::MergeTreeIndexGin::createIndexCondition(DB::ActionsDAG::Node const*, std::shared_ptr<DB::Context const>) const @ 0x000000003554e9b4\n10353746:[ip-172-31-16-219] 2025.06.23 03:43:41.776384 [ 2015 ] <Fatal> BaseDaemon: 21. ci/tmp/build/./src/Processors/QueryPlan/ReadFromMergeTree.cpp:1839: DB::buildIndexes(std::optional<DB::ReadFromMergeTree::Indexes>&, DB::ActionsDAG const*, DB::MergeTreeData const&, DB::RangesInDataParts const&, std::shared_ptr<DB::MergeTreeData::IMutationsSnapshot const> const&, std::optional<DB::VectorSearchParameters> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryInfo const&, std::shared_ptr<DB::StorageInMemoryMetadata const> const&, std::shared_ptr<Poco::Logger> const&) @ 0x0000000036a777b3\n10353747:[ip-172-31-16-219] 2025.06.23 03:43:41.884575 [ 2015 ] <Fatal> BaseDaemon: 22. ci/tmp/build/./src/Processors/QueryPlan/ReadFromMergeTree.cpp:1885: DB::ReadFromMergeTree::applyFilters(DB::ActionDAGNodes) @ 0x0000000036a75c7d\n10353748:[ip-172-31-16-219] 2025.06.23 03:43:41.891345 [ 2015 ] <Fatal> BaseDaemon: 23. src/Processors/QueryPlan/SourceStepWithFilter.h:60: DB::SourceStepWithFilterBase::applyFilters() @ 0x0000000036b83c7c\n10353749:[ip-172-31-16-219] 2025.06.23 03:43:41.898520 [ 2015 ] <Fatal> BaseDaemon: 24. ci/tmp/build/./src/Processors/QueryPlan/Optimizations/optimizePrimaryKeyConditionAndLimit.cpp:50: DB::QueryPlanOptimizations::optimizePrimaryKeyConditionAndLimit(std::vector<DB::QueryPlanOptimizations::Frame, std::allocator<DB::QueryPlanOptimizations::Frame>> const&) @ 0x0000000036b83312\n10353750:[ip-172-31-16-219] 2025.06.23 03:43:41.908345 [ 2015 ] <Fatal> BaseDaemon: 25. ci/tmp/build/./src/Processors/QueryPlan/Optimizations/optimizeTree.cpp:134: DB::QueryPlanOptimizations::optimizeTreeSecondPass(DB::QueryPlanOptimizationSettings const&, DB::QueryPlan::Node&, std::list<DB::QueryPlan::Node, std::allocator<DB::QueryPlan::Node>>&, DB::QueryPlan&) @ 0x0000000036b80041\n10353751:[ip-172-31-16-219] 2025.06.23 03:43:41.934867 [ 2015 ] <Fatal> BaseDaemon: 26. ci/tmp/build/./src/Processors/QueryPlan/QueryPlan.cpp:496: DB::QueryPlan::optimize(DB::QueryPlanOptimizationSettings const&) @ 0x0000000036a28e84\n10353752:[ip-172-31-16-219] 2025.06.23 03:43:41.956824 [ 2015 ] <Fatal> BaseDaemon: 27. ci/tmp/build/./src/Processors/QueryPlan/QueryPlan.cpp:175: DB::QueryPlan::buildQueryPipeline(DB::QueryPlanOptimizationSettings const&, DB::BuildQueryPipelineSettings const&, bool) @ 0x0000000036a28497\n10353753:[ip-172-31-16-219] 2025.06.23 03:43:41.976168 [ 2015 ] <Fatal> BaseDaemon: 28. ci/tmp/build/./src/Interpreters/InterpreterSelectQueryAnalyzer.cpp:289: DB::InterpreterSelectQueryAnalyzer::buildQueryPipeline() @ 0x00000000323776d3\n10353754:[ip-172-31-16-219] 2025.06.23 03:43:41.995094 [ 2015 ] <Fatal> BaseDaemon: 29. ci/tmp/build/./src/Interpreters/InterpreterSelectQueryAnalyzer.cpp:256: DB::InterpreterSelectQueryAnalyzer::execute() @ 0x00000000323772a6\n10353755:[ip-172-31-16-219] 2025.06.23 03:43:42.032234 [ 2015 ] <Fatal> BaseDaemon: 30. ci/tmp/build/./src/Interpreters/executeQuery.cpp:1523: DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000328417da\n10353756:[ip-172-31-16-219] 2025.06.23 03:43:42.075960 [ 2015 ] <Fatal> BaseDaemon: 31. ci/tmp/build/./src/Interpreters/executeQuery.cpp:1715: DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x000000003283b2f4\n10353757:[ip-172-31-16-219] 2025.06.23 03:43:42.111039 [ 2015 ] <Fatal> BaseDaemon: 32. ci/tmp/build/./src/Server/TCPHandler.cpp:721: DB::TCPHandler::runImpl() @ 0x0000000035e03871\n10353758:[ip-172-31-16-219] 2025.06.23 03:43:42.166852 [ 2015 ] <Fatal> BaseDaemon: 33. ci/tmp/build/./src/Server/TCPHandler.cpp:2727: DB::TCPHandler::run() @ 0x0000000035e3600a\n10353759:[ip-172-31-16-219] 2025.06.23 03:43:42.169220 [ 2015 ] <Fatal> BaseDaemon: 34. ci/tmp/build/./base/poco/Net/src/TCPServerConnection.cpp:40: Poco::Net::TCPServerConnection::start() @ 0x000000003a0fc402\n10353760:[ip-172-31-16-219] 2025.06.23 03:43:42.172598 [ 2015 ] <Fatal> BaseDaemon: 35. ci/tmp/build/./base/poco/Net/src/TCPServerDispatcher.cpp:115: Poco::Net::TCPServerDispatcher::run() @ 0x000000003a0fd0d2\n10353761:[ip-172-31-16-219] 2025.06.23 03:43:42.175990 [ 2015 ] <Fatal> BaseDaemon: 36. ci/tmp/build/./base/poco/Foundation/src/ThreadPool.cpp:205: Poco::PooledThread::run() @ 0x000000003a062057\n10353762:[ip-172-31-16-219] 2025.06.23 03:43:42.179212 [ 2015 ] <Fatal> BaseDaemon: 37. base/poco/Foundation/src/Thread_POSIX.cpp:335: Poco::ThreadImpl::runnableEntry(void*) @ 0x000000003a05da4e\n10353763:[ip-172-31-16-219] 2025.06.23 03:43:42.179240 [ 2015 ] <Fatal> BaseDaemon: 38. start_thread @ 0x0000000000094ac3\n10353764:[ip-172-31-16-219] 2025.06.23 03:43:42.179264 [ 2015 ] <Fatal> BaseDaemon: 39. __GI___clone3 @ 0x0000000000126850\n10353765:[ip-172-31-16-219] 2025.06.23 03:43:42.455924 [ 2015 ] <Fatal> BaseDaemon: Integrity check of the executable successfully passed (checksum: 066DAD2A9B037806D102E8FA8E6213C3)\n10353766:[ip-172-31-16-219] 2025.06.23 03:43:44.499368 [ 2015 ] <Fatal> BaseDaemon: Report this error to https://github.com/ClickHouse/ClickHouse/issues\n10353767:[ip-172-31-16-219] 2025.06.23 03:43:44.499619 [ 2015 ] <Fatal> BaseDaemon: Changed settings: receive_timeout = 10., receive_data_timeout_ms = 10000, allow_suspicious_low_cardinality_types = true, log_queries = true, table_function_remote_max_addresses = 200, max_execution_time = 10., max_memory_usage = 10000000000, send_logs_level = 'fatal', allow_introspection_functions = true, parallel_replicas_for_cluster_engines = false, allow_experimental_analyzer = true, allow_experimental_full_text_index = true\n```\n",
  "hints_text": "@ahmadov, an error found by fuzzer is **an incident** requires immediate resolution. It's not optional to fix these bugs.\n#83117\n@alexey-milovidov @rschu1ze do we still need to revert the commit even if it is still an experimental feature?\n@ahmadov, we do one of two things for experimental features:\n1. Revert.\n2. Prevent the usage in CI, so the CI does not have false-positive red results.\n\nThe latter was applied for large experimental features, e.g., analyzer two years ago.\nAnyways, do not be afraid of reverting. We incentivize quick, fearless reverts.",
  "created_at": "2025-07-04T18:53:37Z"
}