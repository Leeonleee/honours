{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 4297,
  "instance_id": "ClickHouse__ClickHouse-4297",
  "issue_numbers": [
    "3469"
  ],
  "base_commit": "3d55e375ff4a303b2bc5d13e0456db2455980900",
  "patch": "diff --git a/dbms/src/DataStreams/ConcatBlockInputStream.h b/dbms/src/DataStreams/ConcatBlockInputStream.h\nindex baaa876e96d6..e2ab60a15099 100644\n--- a/dbms/src/DataStreams/ConcatBlockInputStream.h\n+++ b/dbms/src/DataStreams/ConcatBlockInputStream.h\n@@ -24,6 +24,9 @@ class ConcatBlockInputStream : public IBlockInputStream\n \n     Block getHeader() const override { return children.at(0)->getHeader(); }\n \n+    /// We call readSuffix prematurely by ourself. Suppress default behaviour.\n+    void readSuffix() override {}\n+\n protected:\n     Block readImpl() override\n     {\ndiff --git a/dbms/src/DataStreams/IBlockInputStream.cpp b/dbms/src/DataStreams/IBlockInputStream.cpp\nindex 31e6f9e1de84..a84a94b385ab 100644\n--- a/dbms/src/DataStreams/IBlockInputStream.cpp\n+++ b/dbms/src/DataStreams/IBlockInputStream.cpp\n@@ -96,6 +96,13 @@ Block IBlockInputStream::read()\n \n void IBlockInputStream::readPrefix()\n {\n+#ifndef NDEBUG\n+    if (!read_prefix_is_called)\n+        read_prefix_is_called = true;\n+    else\n+        throw Exception(\"readPrefix is called twice for \" + getName() + \" stream\", ErrorCodes::LOGICAL_ERROR);\n+#endif\n+\n     readPrefixImpl();\n \n     forEachChild([&] (IBlockInputStream & child)\n@@ -108,6 +115,13 @@ void IBlockInputStream::readPrefix()\n \n void IBlockInputStream::readSuffix()\n {\n+#ifndef NDEBUG\n+    if (!read_suffix_is_called)\n+        read_suffix_is_called = true;\n+    else\n+        throw Exception(\"readSuffix is called twice for \" + getName() + \" stream\", ErrorCodes::LOGICAL_ERROR);\n+#endif\n+\n     forEachChild([&] (IBlockInputStream & child)\n     {\n         child.readSuffix();\ndiff --git a/dbms/src/DataStreams/IBlockInputStream.h b/dbms/src/DataStreams/IBlockInputStream.h\nindex 6d2ddbfdf2c3..6475e46f03c5 100644\n--- a/dbms/src/DataStreams/IBlockInputStream.h\n+++ b/dbms/src/DataStreams/IBlockInputStream.h\n@@ -314,6 +314,11 @@ class IBlockInputStream\n             if (f(*child))\n                 return;\n     }\n+\n+#ifndef NDEBUG\n+    bool read_prefix_is_called = false;\n+    bool read_suffix_is_called = false;\n+#endif\n };\n \n }\ndiff --git a/dbms/src/DataStreams/LazyBlockInputStream.h b/dbms/src/DataStreams/LazyBlockInputStream.h\nindex 321778d30b31..37089c9bb5bc 100644\n--- a/dbms/src/DataStreams/LazyBlockInputStream.h\n+++ b/dbms/src/DataStreams/LazyBlockInputStream.h\n@@ -32,6 +32,9 @@ class LazyBlockInputStream : public IBlockInputStream\n         return header;\n     }\n \n+    /// We call readPrefix lazily. Suppress default behaviour.\n+    void readPrefix() override {}\n+\n protected:\n     Block readImpl() override\n     {\ndiff --git a/dbms/src/DataStreams/NullAndDoCopyBlockInputStream.h b/dbms/src/DataStreams/NullAndDoCopyBlockInputStream.h\nindex 435847978989..296f198b01a6 100644\n--- a/dbms/src/DataStreams/NullAndDoCopyBlockInputStream.h\n+++ b/dbms/src/DataStreams/NullAndDoCopyBlockInputStream.h\n@@ -26,6 +26,10 @@ class NullAndDoCopyBlockInputStream : public IBlockInputStream\n         children.push_back(input_);\n     }\n \n+    /// Suppress readPrefix and readSuffix, because they are called by copyData.\n+    void readPrefix() override {}\n+    void readSuffix() override {}\n+\n     String getName() const override { return \"NullAndDoCopy\"; }\n \n     Block getHeader() const override { return {}; }\n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/00837_insert_select_and_read_prefix.reference b/dbms/tests/queries/0_stateless/00837_insert_select_and_read_prefix.reference\nnew file mode 100644\nindex 000000000000..3bed4a019551\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00837_insert_select_and_read_prefix.reference\n@@ -0,0 +1,4 @@\n+hello\t1\n+world\t2\n+hello\t1\n+world\t2\ndiff --git a/dbms/tests/queries/0_stateless/00837_insert_select_and_read_prefix.sql b/dbms/tests/queries/0_stateless/00837_insert_select_and_read_prefix.sql\nnew file mode 100644\nindex 000000000000..576192e9d470\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00837_insert_select_and_read_prefix.sql\n@@ -0,0 +1,10 @@\n+DROP TABLE IF EXISTS test.file;\n+CREATE TABLE test.file (s String, n UInt32) ENGINE = File(CSVWithNames);\n+-- BTW, WithNames formats are totally unsuitable for more than a single INSERT\n+INSERT INTO test.file VALUES ('hello', 1), ('world', 2);\n+\n+SELECT * FROM test.file;\n+CREATE TEMPORARY TABLE file2 AS SELECT * FROM test.file;\n+SELECT * FROM file2;\n+\n+DROP TABLE test.file;\n",
  "problem_statement": "first data row is missing when inserting from file with format 'CSVWithNames'\n>ClickHouse client version 18.14.9.\r\n\r\nmy csv file\r\n`cat SLA1.csv`\r\n>Number,Has breached\r\n>INC8185669,FALSE\r\n>INC8162430,FALSE\r\n>INC8225693,FALSE\r\n>INC8146423,FALSE\r\n\r\n\r\nMy table looks like;\r\n```\r\nDROP TABLE IF EXISTS TICKETS_SLA; \r\nCREATE TABLE TICKETS_SLA  (CREATE_DATE Date, TICKET_NUMBER String, SLA String ) ENGINE=MergeTree(CREATE_DATE, (TICKET_NUMBER), 8192);\r\nDESCRIBE TABLE HRAI.TICKETS_SLA\r\n```\r\n\r\n>\u250c\u2500name\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500type\u2500\u2500\u2500\u252c\u2500default_type\u2500\u252c\u2500default_expression\u2500\u2510\r\n>\u2502 CREATE_DATE   \u2502 Date   \u2502              \u2502                    \u2502\r\n>\u2502 TICKET_NUMBER \u2502 String \u2502              \u2502                    \u2502\r\n>\u2502 SLA           \u2502 String  \u2502              \u2502                    \u2502\r\n>\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n>\r\n>3 rows in set. Elapsed: 0.009 sec.\r\n\r\n\r\nWhen select from this file, it reads total 4 records.\r\n`SELECT *   FROM file('SLA1.csv', 'CSVWithNames', 'TICKET_NUMBER String, SLA String');`\r\n\r\n>clickhouse :) SELECT * FROM file('SLA1.csv', 'CSVWithNames', 'TICKET_NUMBER String, SLA String');\r\n>\r\n>SELECT *\r\n>FROM file('SLA1.csv', 'CSVWithNames', 'TICKET_NUMBER String, SLA String')\r\n>\r\n>\u250c\u2500TICKET_NUMBER\u2500\u252c\u2500SLA\u2500\u2500\u2500\u2510\r\n>\u2502 INC8185669    \u2502 FALSE \u2502\r\n>\u2502 INC8162430    \u2502 FALSE \u2502\r\n>\u2502 INC8225693    \u2502 FALSE \u2502\r\n>\u2502 INC8146423    \u2502 FALSE \u2502\r\n>\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n>\r\n>4 rows in set. Elapsed: 0.016 sec.\r\n\r\nHowever, when inserting into table TICKETS_SLA, it only has 3 records.\r\n`insert into  TICKETS_SLA SELECT today(), TICKET_NUMBER, SLA FROM file('SLA1.csv', 'CSVWithNames', 'TICKET_NUMBER String, SLA String');`\r\n>clickhouse :) insert into  TICKETS_SLA SELECT today(), TICKET_NUMBER, SLA FROM file('SLA1.csv', 'CSVWithNames', 'TICKET_NUMBER String, SLA String');\r\n>\r\n>INSERT INTO TICKETS_SLA SELECT\r\n>    today(),\r\n>    TICKET_NUMBER,\r\n>    SLA\r\n>FROM file('SLA1.csv', 'CSVWithNames', 'TICKET_NUMBER String, SLA String')\r\n>\r\n>Ok.\r\n>\r\n>0 rows in set. Elapsed: 0.016 sec.\r\n\r\n\r\nFirst data row in CSV is missing.\r\n\r\n>clickhouse :) select * from TICKETS_SLA;\r\n>\r\n>SELECT *\r\n>FROM TICKETS_SLA\r\n>\r\n>\u250c\u2500CREATE_DATE\u2500\u252c\u2500TICKET_NUMBER\u2500\u252c\u2500SLA\u2500\u2500\u2500\u2510\r\n>\u2502  2018-10-26 \u2502 INC8146423    \u2502 FALSE \u2502\r\n>\u2502  2018-10-26 \u2502 INC8162430    \u2502 FALSE \u2502\r\n>\u2502  2018-10-26 \u2502 INC8225693    \u2502 FALSE \u2502\r\n>\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n>\r\n>3 rows in set. Elapsed: 0.007 sec.\r\n\r\n\r\nLooks like when inserting into tables, ClickHouse ignore the first two rows in the csv file when using format 'CSVWithNames' i/o the first row claimed in their [documentation\r\n](https://clickhouse.yandex/docs/en/interfaces/formats/#csvwithnames)\r\n\r\nPlease help to check what went wrong. Thanks. \r\n\r\n\n",
  "hints_text": "Confirmed. Internal detail: `CSVRowInputStream::readPrefix()` is called twice.",
  "created_at": "2019-02-06T21:43:06Z"
}