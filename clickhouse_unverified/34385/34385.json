{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 34385,
  "instance_id": "ClickHouse__ClickHouse-34385",
  "issue_numbers": [
    "34089"
  ],
  "base_commit": "12bd453a43819176d25ecf247033f6cb1af54beb",
  "patch": "diff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp\nindex a0d6fe67b396..5c096a7dbacc 100644\n--- a/src/Interpreters/InterpreterSelectQuery.cpp\n+++ b/src/Interpreters/InterpreterSelectQuery.cpp\n@@ -1777,6 +1777,7 @@ void InterpreterSelectQuery::executeFetchColumns(QueryProcessingStage::Enum proc\n     bool optimize_trivial_count =\n         syntax_analyzer_result->optimize_trivial_count\n         && (settings.max_parallel_replicas <= 1)\n+        && !settings.allow_experimental_query_deduplication\n         && storage\n         && storage->getName() != \"MaterializedMySQL\"\n         && !row_policy_filter\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex 25a0bf582aed..7bfff3b50884 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -4720,6 +4720,10 @@ std::optional<ProjectionCandidate> MergeTreeData::getQueryProcessingStageWithAgg\n     if (select_query->sampleSize())\n         return std::nullopt;\n \n+    // Currently projection don't support deduplication when moving parts between shards.\n+    if (settings.allow_experimental_query_deduplication)\n+        return std::nullopt;\n+\n     // Currently projections don't support ARRAY JOIN yet.\n     if (select_query->arrayJoinExpressionList().first)\n         return std::nullopt;\n",
  "test_patch": "diff --git a/tests/integration/test_part_moves_between_shards/test.py b/tests/integration/test_part_moves_between_shards/test.py\nindex ed7640e5f9ed..6009a9d2a44e 100644\n--- a/tests/integration/test_part_moves_between_shards/test.py\n+++ b/tests/integration/test_part_moves_between_shards/test.py\n@@ -133,6 +133,17 @@ def deduplication_invariant_test():\n                     settings={\"allow_experimental_query_deduplication\": 1})\n         ) == TSV(expected)\n \n+        # https://github.com/ClickHouse/ClickHouse/issues/34089\n+        assert TSV(\n+            n.query(\"SELECT count() FROM test_deduplication_d\",\n+                    settings={\"allow_experimental_query_deduplication\": 1})\n+        ) == TSV(\"2\")\n+\n+        assert TSV(\n+            n.query(\"SELECT count() FROM test_deduplication_d\",\n+                    settings={\"allow_experimental_query_deduplication\": 1, \"allow_experimental_projection_optimization\": 1})\n+        ) == TSV(\"2\")\n+\n     deduplication_invariant = ConcurrentInvariant(deduplication_invariant_test)\n     deduplication_invariant.start()\n \n",
  "problem_statement": "Data duplication in `PART MOVE TO SHARD` feature\nI wrote a test for  `PART MOVE TO SHARD` runs multiple times and received some unexpected behavior.\r\n\r\n**Test description:**\r\n1) Create a table\r\n2) Make 2 rows insert on one shard and 1 row insert on some other\r\n3) Stop Merges\r\n4) Create Distributed table\r\n5) Receive part UUID\r\n6) Move this part multiple times\r\n7) Make concurrent check on the number of rows\r\n\r\n**How to reproduce**\r\n1) CREATE TABLE IF NOT EXISTS {table_name} on CLUSTER {cluster_name}\r\n                                                (v UInt64) \"\r\n                                                ENGINE = {table_engine}('/clickhouse/tables/replicated/{shard}/{table_name}', '{replica}') \r\n                                                ORDER BY tuple() \r\n                                                SETTINGS assign_part_uuids=1,\r\n                                                part_moves_between_shards_enable=1,\r\n                                                part_moves_between_shards_delay_seconds=2;\r\n\r\n2) INSERT INTO {table_name} VALUES ({value}) - 2 rows  on one shard and 1 row on some other\r\n\r\n3) SYSTEM STOP MERGES {table_name} - on all nodes\r\n\r\n4) CREATE TABLE IF NOT EXISTS {table_name_d} as {table_name} \r\n                                                    ENGINE = Distributed({cluster_name}, currentDatabase(), {table_name})\r\n5) SELECT uuid FROM system.parts where name = 'all_0_0_0'\r\n\r\n6) SELECT name FROM system.parts where uuid = '{part_uuid}'\r\n    ALTER TABLE {table_name} MOVE PART name TO SHARD '/clickhouse/tables/replicated/{shard1}/{table_name}' - multiple times\r\n\r\n7) select count() from {table_name_d}\r\n\r\n* ClickHouse server version to use\r\n22.1.2\r\n* Queries to run that lead to an unexpected result\r\nselect count() from {table_name_d}\r\n\r\nResult: 4\r\n\r\n**Expected behavior**\r\nResult: 3\r\n\r\n**Additional information**\r\nIf make retries some time result becomes correct. The test gives the correct result if put part_moves_between_shards_delay_seconds=0.\r\n\n",
  "hints_text": "CC @nvartolomei \nThis experimental feature is going to be removed if this issue will not be addressed in 6 months (before July 2022).\n@AlmostIvanSidorov before trying to reproduce this may I ask if have you enabled the `allow_experimental_query_deduplication` setting?\r\n\r\n@alexey-milovidov we shall enable this by default and remove obsolete `experimental_query_deduplication_send_all_part_uuids`.\n@nvartolomei in my tests I used 3 cases for check:\r\n1) select * from {table_name} ORDER BY v ASC SETTINGS allow_experimental_query_deduplication = 1 FORMAT TSV\r\nseems this works correct (I didn't catch duplication in my tests)\r\n\r\n2) select * from {table_name} ORDER BY v ASC FORMAT TSV -  i received visual confirm of data duplication.\r\n\r\n3)But select count() from {table_name} SETTINGS allow_experimental_query_deduplication = 1 even with allow_experimental_query_deduplication still shows wrong result.\n@AlmostIvanSidorov can you also try with `optimize_trivial_count = false`?\n@nvartolomei  As I understood optimize_trivial_count_query* )\r\n\r\n`select count() from {table_name} SETTINGS allow_experimental_query_deduplication = 1,  optimize_trivial_count_query = false`\r\n\r\nPassed test x3 times, seems to work as it should.\r\n\r\n",
  "created_at": "2022-02-07T18:28:31Z",
  "modified_files": [
    "src/Interpreters/InterpreterSelectQuery.cpp",
    "src/Storages/MergeTree/MergeTreeData.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_part_moves_between_shards/test.py"
  ]
}