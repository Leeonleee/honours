{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 80360,
  "instance_id": "ClickHouse__ClickHouse-80360",
  "issue_numbers": [
    "79647",
    "77848"
  ],
  "base_commit": "d7710633a46f716b6e45071442eb6e6bfacfa3c9",
  "patch": "diff --git a/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp b/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp\nindex 5796ef5a610b..92a277474b46 100644\n--- a/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp\n+++ b/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp\n@@ -386,8 +386,33 @@ static size_t tryPushDownOverJoinStep(QueryPlan::Node * parent_node, QueryPlan::\n \n     size_t updated_steps = 0;\n \n+    /// For the logical join step, we need to merge pre-join actions to filter dag.\n+    /// TODO: this should be refactored and replaced with optimizations which\n+    /// 1. push filter/expression into JOIN (as post-filter)\n+    /// 2. move filter within JOIN step, potentially changing JoinKind\n+    /// 3. push filter/expression out of JOIN (from pre-filter)\n+    auto fix_predicate_for_join_logical_step = [&](ActionsDAG filter_dag, const ActionsDAG & side_dag)\n+    {\n+        filter_dag = ActionsDAG::merge(side_dag.clone(), std::move(filter_dag));\n+        auto & outputs = filter_dag.getOutputs();\n+        outputs.resize(1);\n+        outputs.insert(outputs.end(), filter_dag.getInputs().begin(), filter_dag.getInputs().end());\n+        filter_dag.removeUnusedActions();\n+        return filter_dag;\n+    };\n+\n     if (join_filter_push_down_actions.left_stream_filter_to_push_down)\n     {\n+        if (logical_join)\n+        {\n+\n+            join_filter_push_down_actions.left_stream_filter_to_push_down = fix_predicate_for_join_logical_step(\n+                std::move(*join_filter_push_down_actions.left_stream_filter_to_push_down),\n+                *logical_join->getExpressionActions().left_pre_join_actions\n+            );\n+            join_filter_push_down_actions.left_stream_filter_removes_filter = true;\n+        }\n+\n         const auto & result_name = join_filter_push_down_actions.left_stream_filter_to_push_down->getOutputs()[0]->result_name;\n         updated_steps += addNewFilterStepOrThrow(parent_node,\n             nodes,\n@@ -403,6 +428,16 @@ static size_t tryPushDownOverJoinStep(QueryPlan::Node * parent_node, QueryPlan::\n \n     if (join_filter_push_down_actions.right_stream_filter_to_push_down && allow_push_down_to_right)\n     {\n+        if (logical_join)\n+        {\n+\n+            join_filter_push_down_actions.right_stream_filter_to_push_down = fix_predicate_for_join_logical_step(\n+                std::move(*join_filter_push_down_actions.right_stream_filter_to_push_down),\n+                *logical_join->getExpressionActions().right_pre_join_actions\n+            );\n+            join_filter_push_down_actions.right_stream_filter_removes_filter = true;\n+        }\n+\n         const auto & result_name = join_filter_push_down_actions.right_stream_filter_to_push_down->getOutputs()[0]->result_name;\n         updated_steps += addNewFilterStepOrThrow(parent_node,\n             nodes,\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03393_join_bug_77848.reference b/tests/queries/0_stateless/03393_join_bug_77848.reference\nindex e69de29bb2d1..6ed281c757a9 100644\n--- a/tests/queries/0_stateless/03393_join_bug_77848.reference\n+++ b/tests/queries/0_stateless/03393_join_bug_77848.reference\n@@ -0,0 +1,2 @@\n+1\n+1\ndiff --git a/tests/queries/0_stateless/03393_join_bug_77848.sql b/tests/queries/0_stateless/03393_join_bug_77848.sql\nindex 762e32c3e06e..d085655e9760 100644\n--- a/tests/queries/0_stateless/03393_join_bug_77848.sql\n+++ b/tests/queries/0_stateless/03393_join_bug_77848.sql\n@@ -13,6 +13,6 @@ SET enable_analyzer = 1;\n -- TODO(@vdimir): NOT_FOUND_COLUMN_IN_BLOCK is a bug, should be fixed\n -- This tests ensures that query does not crash at least\n \n-SELECT 1 FROM BadTable i LEFT JOIN BadJoin c ON i.id_uint = toUInt128(c.id) WHERE equals(i.id_uint, 12); --  { serverError NOT_FOUND_COLUMN_IN_BLOCK}\n+SELECT 1 FROM BadTable i LEFT JOIN BadJoin c ON i.id_uint = toUInt128(c.id) WHERE equals(i.id_uint, 12);\n \n-SELECT equals(i.id_uint, 12) FROM BadTable i LEFT JOIN BadJoin c ON i.id_uint = toUInt128(c.id) WHERE equals(i.id_uint, 12); --  { serverError NOT_FOUND_COLUMN_IN_BLOCK}\n+SELECT equals(i.id_uint, 12) FROM BadTable i LEFT JOIN BadJoin c ON i.id_uint = toUInt128(c.id) WHERE equals(i.id_uint, 12);\ndiff --git a/tests/queries/0_stateless/03517_logical_join_predicate_push_down_with_pre_expression_bug.reference b/tests/queries/0_stateless/03517_logical_join_predicate_push_down_with_pre_expression_bug.reference\nnew file mode 100644\nindex 000000000000..acb8bbdaffcf\n--- /dev/null\n+++ b/tests/queries/0_stateless/03517_logical_join_predicate_push_down_with_pre_expression_bug.reference\n@@ -0,0 +1,5 @@\n+2025-04-01\n+2025-04-01\n+2025-04-01\n+2025-04-01\n+2025-04-01\ndiff --git a/tests/queries/0_stateless/03517_logical_join_predicate_push_down_with_pre_expression_bug.sql b/tests/queries/0_stateless/03517_logical_join_predicate_push_down_with_pre_expression_bug.sql\nnew file mode 100644\nindex 000000000000..a098ede0760e\n--- /dev/null\n+++ b/tests/queries/0_stateless/03517_logical_join_predicate_push_down_with_pre_expression_bug.sql\n@@ -0,0 +1,24 @@\n+drop table if exists td;\n+drop table if exists tdt;\n+\n+CREATE TABLE td (id Int16, d Date) ENGINE=MergeTree() order by id;\n+CREATE TABLE tdt (id Int16, dt DateTime) ENGINE=MergeTree() order by id;\n+\n+insert into td values (1,'2025-03-01'),(2,'2025-04-01');\n+insert into tdt values (1,'2025-03-01 01:01:01'),(2,'2025-03-01 02:01:01'),(3,'2025-04-01 03:01:01'),(4,'2025-04-01 04:01:01'),(5,'2025-04-01 05:01:01');\n+\n+SELECT td_d FROM (SELECT t.id td_id, t.d td_d, uniqExact(tdt.id) as cnt FROM td as t LEFT JOIN tdt ON toDate(tdt.dt) = t.d GROUP BY td_id, td_d) WHERE td_d = '2025-04-01';\n+SELECT td_d FROM (SELECT t.id td_id, t.d td_d, uniqExact(tdt.id) as cnt FROM tdt RIGHT JOIN td as t ON toDate(tdt.dt) = t.d GROUP BY td_id, td_d) WHERE td_d = '2025-04-01';\n+\n+SELECT td_d FROM (SELECT t.id td_id, t.d td_d, uniqExact(tdt.id) as cnt FROM td as t INNER JOIN tdt ON toDate(tdt.dt) = t.d GROUP BY td_id, td_d) WHERE td_d = '2025-04-01';\n+SELECT td_d FROM (SELECT t.id td_id, t.d td_d, uniqExact(tdt.id) as cnt FROM tdt INNER JOIN td as t ON toDate(tdt.dt) = t.d GROUP BY td_id, td_d) WHERE td_d = '2025-04-01';\n+\n+CREATE VIEW v AS\n+SELECT\n+  t.id td_id, t.d td_d, uniqExact(tdt.id) as cnt\n+FROM\n+  td as t\n+  LEFT JOIN tdt ON toDate(tdt.dt) = t.d\n+GROUP BY td_id, td_d;\n+\n+SELECT td_d FROM v WHERE td_d = '2025-04-01';\n",
  "problem_statement": "Exception: Not found column toDate(__table3.dt)\n### Company or project name\n\n_No response_\n\n### Describe what's wrong\n\nAn error occurs when using a view that connects tables with DateTime and Date type fields for JOIN without toDate function around Date type field and using this field in WHERE clause.\n\nCREATE VIEW v AS\nSELECT \n  t.id td_id, t.d td_d, uniqExact(tdt.id) as cnt \nFROM \n  td as t\n  LEFT JOIN tdt ON toDate(tdt.dt) = t.d\nGROUP BY td_id, td_d;\n\nSELECT td_d FROM v\nWHERE td_d = '2025-04-01';\n\n### Does it reproduce on the most recent release?\n\nYes\n\n### How to reproduce\n\nversions: 25.4.1 and 25.3.3\n\nhttps://fiddle.clickhouse.com/6c74e1a3-e961-4527-b3a8-419615db9e9d\n\n### Expected behavior\n\n_No response_\n\n### Error message and/or stacktrace\n\nReceived exception from server (version 25.4.1):\nCode: 10. DB::Exception: Received from localhost:9000. DB::Exception: Not found column toDate(__table3.dt): in block __table3.dt DateTime UInt32(size = 0). (NOT_FOUND_COLUMN_IN_BLOCK)\n(query: SELECT td_d FROM v\nWHERE td_d = '2025-04-01';)\n\n### Additional context\n\n_No response_\nUsing 'equals' on Uint128 column causes 'Unknown identifier' or segfault\n### Company or project name\n\nTensorZero\n\n### Describe what's wrong\n\nWhen using the following table schema:\n```\nCREATE TABLE IF NOT EXISTS BadTable (id_uint UInt128) ENGINE = MergeTree() ORDER BY id_uint;\nCREATE TABLE IF NOT EXISTS BadJoin (id UUID, name LowCardinality(String)) ENGINE = MergeTree() ORDER BY (name);\n```\n\nThe following query produces an 'Unknown identifier' error (https://fiddle.clickhouse.com/db9748e5-2a36-4799-a469-36356e9890ed):\n```\nSELECT 1 FROM BadTable i LEFT JOIN BadJoin c ON i.id_uint = toUInt128(c.id) WHERE equals(i.id_uint, 12);\n```\n\n```\nReceived exception from server (version 25.2.2):\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Unknown identifier: 'equals(__table1.id_uint, 12_UInt8)'. (UNKNOWN_IDENTIFIER)\n(query: SELECT 1 FROM BadTable i LEFT JOIN BadJoin c ON i.id_uint = toUInt128(c.id) WHERE equals(i.id_uint, 12);)\n```\n\nIf this query is modified slightly to use the 'equals' expression with 'SELECT', then ClickHouse segfaults (https://fiddle.clickhouse.com/249e450e-c002-413a-8c0c-f09c4f7a327f):\n\n```\nSELECT equals(i.id_uint, 12) FROM BadTable i LEFT JOIN BadJoin c ON i.id_uint = toUInt128(c.id) WHERE equals(i.id_uint, 12);\n```\n\n```\n\n[6c380d833e86] 2025.03.18 15:49:00.391517 [ 760 ] <Fatal> BaseDaemon: ########################################\n[6c380d833e86] 2025.03.18 15:49:00.391590 [ 760 ] <Fatal> BaseDaemon: (version 25.2.2.39 (official build), build id: 81BBAA4141094E1995BF244BFE32288EE7EE9049, git hash: a1200cff50a7ceb17f5fff71e47f5d20d9ada287) (from thread 83) (query_id: 1891cbce-16f4-4e67-9b39-5d27351859a9) (query: SELECT equals(i.id_uint, 12) FROM BadTable i LEFT JOIN BadJoin c ON i.id_uint = toUInt128(c.id) WHERE equals(i.id_uint, 12);) Received signal Segmentation fault (11)\n[6c380d833e86] 2025.03.18 15:49:00.391638 [ 760 ] <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Address not mapped to object.\n[6c380d833e86] 2025.03.18 15:49:00.391689 [ 760 ] <Fatal> BaseDaemon: Stack trace: 0x000000000f235a57 0x00007ca835368520 0x0000000014b4d172 0x00000000126360e7 0x0000000014b4a7d7 0x0000000014b4974e 0x0000000012f6851d 0x0000000012f67dfe 0x0000000013316a62 0x0000000013311c24 0x0000000014647a2c 0x0000000014665eb9 0x0000000017d1a4a7 0x0000000017d1a8f9 0x0000000017ce6c7b 0x0000000017ce515d 0x00007ca8353baac3 0x00007ca83544ba04\n[6c380d833e86] 2025.03.18 15:49:00.391788 [ 760 ] <Fatal> BaseDaemon: 0. signalHandler(int, siginfo_t*, void*) @ 0x000000000f235a57\n[6c380d833e86] 2025.03.18 15:49:00.391841 [ 760 ] <Fatal> BaseDaemon: 1. ? @ 0x00007ca835368520\n[6c380d833e86] 2025.03.18 15:49:00.391904 [ 760 ] <Fatal> BaseDaemon: 2. DB::QueryPlan::explainPlan(DB::WriteBuffer&, DB::ExplainPlanOptions const&, unsigned long) const @ 0x0000000014b4d172\n[6c380d833e86] 2025.03.18 15:49:00.391964 [ 760 ] <Fatal> BaseDaemon: 3. DB::dumpQueryPlan(DB::QueryPlan const&) @ 0x00000000126360e7\n[6c380d833e86] 2025.03.18 15:49:00.392020 [ 760 ] <Fatal> BaseDaemon: 4. DB::QueryPlan::optimize(DB::QueryPlanOptimizationSettings const&) @ 0x0000000014b4a7d7\n[6c380d833e86] 2025.03.18 15:49:00.392074 [ 760 ] <Fatal> BaseDaemon: 5. DB::QueryPlan::buildQueryPipeline(DB::QueryPlanOptimizationSettings const&, DB::BuildQueryPipelineSettings const&) @ 0x0000000014b4974e\n[6c380d833e86] 2025.03.18 15:49:00.392133 [ 760 ] <Fatal> BaseDaemon: 6. DB::InterpreterSelectQueryAnalyzer::buildQueryPipeline() @ 0x0000000012f6851d\n[6c380d833e86] 2025.03.18 15:49:00.392185 [ 760 ] <Fatal> BaseDaemon: 7. DB::InterpreterSelectQueryAnalyzer::execute() @ 0x0000000012f67dfe\n[6c380d833e86] 2025.03.18 15:49:00.392249 [ 760 ] <Fatal> BaseDaemon: 8. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x0000000013316a62\n[6c380d833e86] 2025.03.18 15:49:00.392314 [ 760 ] <Fatal> BaseDaemon: 9. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000013311c24\n[6c380d833e86] 2025.03.18 15:49:00.392393 [ 760 ] <Fatal> BaseDaemon: 10. DB::TCPHandler::runImpl() @ 0x0000000014647a2c\n[6c380d833e86] 2025.03.18 15:49:00.392450 [ 760 ] <Fatal> BaseDaemon: 11. DB::TCPHandler::run() @ 0x0000000014665eb9\n[6c380d833e86] 2025.03.18 15:49:00.392525 [ 760 ] <Fatal> BaseDaemon: 12. Poco::Net::TCPServerConnection::start() @ 0x0000000017d1a4a7\n[6c380d833e86] 2025.03.18 15:49:00.392581 [ 760 ] <Fatal> BaseDaemon: 13. Poco::Net::TCPServerDispatcher::run() @ 0x0000000017d1a8f9\n[6c380d833e86] 2025.03.18 15:49:00.392616 [ 760 ] <Fatal> BaseDaemon: 14. Poco::PooledThread::run() @ 0x0000000017ce6c7b\n[6c380d833e86] 2025.03.18 15:49:00.392648 [ 760 ] <Fatal> BaseDaemon: 15. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000017ce515d\n[6c380d833e86] 2025.03.18 15:49:00.392676 [ 760 ] <Fatal> BaseDaemon: 16. ? @ 0x00007ca8353baac3\n[6c380d833e86] 2025.03.18 15:49:00.392701 [ 760 ] <Fatal> BaseDaemon: 17. ? @ 0x00007ca83544ba04\n[6c380d833e86] 2025.03.18 15:49:00.535918 [ 760 ] <Fatal> BaseDaemon: Integrity check of the executable successfully passed (checksum: 4A7AC8F994A8E395EF3B3AAC3B417E0C)\n[6c380d833e86] 2025.03.18 15:49:00.536164 [ 760 ] <Fatal> BaseDaemon: Report this error to https://github.com/ClickHouse/ClickHouse/issues\n[6c380d833e86] 2025.03.18 15:49:00.536343 [ 760 ] <Fatal> BaseDaemon: Changed settings: output_format_pretty_color = 0, output_format_pretty_grid_charset = 'ASCII'\n```\n\nWithout a join, the query succeeds:\n```\nSELECT 1 FROM BadTable i WHERE equals(i.id_uint, 12);\n```\n\n### Does it reproduce on the most recent release?\n\nYes\n\n### How to reproduce\n\nThis was reproduced on ClickHouse 25.2.2. It occurs on ClickHouse fiddle without any data needed in any of the tables.\n\n### Expected behavior\n\nThe two 'JOIN' queries should succeed, instead of giving an 'Unknown Identifier' error or segfaulting\n\n### Error message and/or stacktrace\n\n_No response_\n\n### Additional context\n\n_No response_\n",
  "hints_text": "latest working version 25.1.8\nThis is a regression since v25.2\nWe need to bisect even more\nSome results from local builds I had predownloaded from previous bisects:\n\n* 25.1: All ok\n```\n$ for file in clickhouse_25_1_*; do echo $file; ( ./$file /tmp/repro.sql 2>/dev/null && echo OK) || echo KO ; done\nclickhouse_25_1_0431c657f5cc0605bb620cba98736bf6e6660285\nOK\nclickhouse_25_1_073d9f8521dd2105122cc52b6f3b146f5fb419c4\nOK\nclickhouse_25_1_1_3113_3de56117136398267d0e34234055f09d6c5a1978\nOK\nclickhouse_25_1_1_3119_5782a9400d935ba8eda99fbdd692c16f0a0a6172\nOK\nclickhouse_25_1_1_3184_e87c4140ce93ca62149e987bc2d232ccae02150f\nOK\nclickhouse_25_1_1_3187_2358e2962a3974d8ce8c8b0df4744ea0ed80c7db\nOK\nclickhouse_25_1_1_3215_f45543901f8150d13ff321eb7141190fd1d3b177\nOK\nclickhouse_25_1_1_3364_917a8961c06895e2982737da8763c545143fb680\nOK\nclickhouse_25_1_1_3577_fb84956b64b88ce504b2970f7419ff4a2a379476\nOK\nclickhouse_25_1_1beaa9cd8e3285aae1014a13efd89e5edcd132d7\nOK\nclickhouse_25_1_2eaae3a053de8db9e8d653c5e8560d009e8ef42b\nOK\nclickhouse_25_1_b92e191cf01b2760e4e27e415292539916b11903\nOK\nclickhouse_25_1_b99948340461fe0b809a0c72f4fb67c981ee48ad\nOK\nclickhouse_25_1_d31cec485d16748ebc134d0410cb21db6606bb00\nOK\nclickhouse_25_1_de2ff42fdd99edfde11da011031b305404499281\nOK\nclickhouse_25_1_f945405d4384d93cf4ffcb8781c4f1f0ce4b9fd2\nOK\n```\n\n* 25.2: One ok, many KOs:\n\n```\n$ for file in clickhouse_25_2_*; do echo $file; ( ./$file /tmp/repro.sql 2>/dev/null && echo OK) || echo KO ; done\nclickhouse_25_2_0aee5ec1a981a0ea230f6fe9efee0dcbfafcd15d\nKO\nclickhouse_25_2_2e99ebf9ab01d8e261c4336791fe3a2bd52af445\nKO\nclickhouse_25_2_306ebd292c40819659cf9ad85f0e94a78bf09b23\nKO\nclickhouse_25_2_33dfac471126636a035b81b12d81227c7fcb44a2\nKO\nclickhouse_25_2_502df3fd1c001b742a49f65b7499586b52162824\nKO\nclickhouse_25_2_66bfec8aaf8781638de1da8f2a659fa48ecbe827_0e\nKO\nclickhouse_25_2_6beff119d7dfcfa6787ae0af238920cbfd38bc89\nKO\nclickhouse_25_2_97a89efb768e426a6359e8e9030863ce2266ad39\nKO\nclickhouse_25_2_a561de2f97520e7cfa25f1b28c271bbe81a8d88a\nKO\nclickhouse_25_2_b2f6e1315a646e6d62ce382abac02788b6b963fe\nKO\nclickhouse_25_2_c655982f6e4135afef4e45270d229bf67b7b84a5\nKO\nclickhouse_25_2_d170a5abb6b666b48afc4a6b976f9fe32a8eb6ac\nKO\nclickhouse_25_2_d536a2c566bd343a4d1c2395ab47957aa4cac0b5\nKO\nclickhouse_25_2_dab0e93b8f0958d629d070a4d2d81bb7396efefd\nOK\nclickhouse_25_2_e7a9856d3b11034c9954c4fa6d8097aa94645327\nKO\nclickhouse_25_2_f1715a2720d848ce64b3b2f109f9d907e7b36c1c\nKO\nclickhouse_25_2_fbdb4717c5bc15708f50f9acb70937529488f2bd\nKO\n```\n\nI'll try to do the more extended bisect after this filter\n\n\n\n```\nThere are only 'skip'ped commits left to test.\nThe first bad commit could be any of:\n587e8a324319938957f91a818b89fa22259d2f34\nc1c6733f172fdb8ec655f4367bf62118102ef3df\nWe cannot bisect more!\n```\n\nhttps://github.com/ClickHouse/ClickHouse/pull/75198 or https://github.com/ClickHouse/ClickHouse/pull/74909\n\nEasy to verify:\n```\n$ clickhouse local /tmp/repro.sql \n2025.03.18 18:37:10.793237 [ 610652 ] {} <Fatal> ClientBase: ########## Short fault info ############\n```\n\n```\n/mnt/ch/ClickHouse $ clickhouse local --query_plan_use_new_logical_join_step=0 /tmp/repro.sql \n/mnt/ch/ClickHouse $ \n```\n\n`query_plan_use_new_logical_join_step` is the culprit and `query_plan_use_new_logical_join_step=0` a workaround.\n\ncc @vdimir  \nLet's start with https://github.com/ClickHouse/ClickHouse/pull/77854 which fixes segfault for such cases. And I'll start investigate `Unknown identifier`",
  "created_at": "2025-05-16T17:11:00Z"
}