{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 17423,
  "instance_id": "ClickHouse__ClickHouse-17423",
  "issue_numbers": [
    "16869"
  ],
  "base_commit": "fb3a69b29810586b65b0c4b1451dcfe49011036e",
  "patch": "diff --git a/src/AggregateFunctions/AggregateFunctionTimeSeriesGroupSum.cpp b/src/AggregateFunctions/AggregateFunctionTimeSeriesGroupSum.cpp\ndeleted file mode 100644\nindex c8711c257f84..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionTimeSeriesGroupSum.cpp\n+++ /dev/null\n@@ -1,35 +0,0 @@\n-#include \"AggregateFunctionTimeSeriesGroupSum.h\"\n-#include \"AggregateFunctionFactory.h\"\n-#include \"FactoryHelpers.h\"\n-#include \"Helpers.h\"\n-#include \"registerAggregateFunctions.h\"\n-\n-\n-namespace DB\n-{\n-namespace ErrorCodes\n-{\n-    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n-}\n-namespace\n-{\n-    template <bool rate>\n-    AggregateFunctionPtr createAggregateFunctionTimeSeriesGroupSum(const std::string & name, const DataTypes & arguments, const Array & params)\n-    {\n-        assertNoParameters(name, params);\n-\n-        if (arguments.size() < 3)\n-            throw Exception(\"Not enough event arguments for aggregate function \" + name, ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH);\n-\n-        return std::make_shared<AggregateFunctionTimeSeriesGroupSum<rate>>(arguments);\n-    }\n-\n-}\n-\n-void registerAggregateFunctionTimeSeriesGroupSum(AggregateFunctionFactory & factory)\n-{\n-    factory.registerFunction(\"timeSeriesGroupSum\", createAggregateFunctionTimeSeriesGroupSum<false>);\n-    factory.registerFunction(\"timeSeriesGroupRateSum\", createAggregateFunctionTimeSeriesGroupSum<true>);\n-}\n-\n-}\ndiff --git a/src/AggregateFunctions/AggregateFunctionTimeSeriesGroupSum.h b/src/AggregateFunctions/AggregateFunctionTimeSeriesGroupSum.h\ndeleted file mode 100644\nindex 63dde3f17387..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionTimeSeriesGroupSum.h\n+++ /dev/null\n@@ -1,291 +0,0 @@\n-#pragma once\n-\n-#include <bitset>\n-#include <map>\n-#include <queue>\n-#include <unordered_set>\n-#include <utility>\n-#include <Columns/ColumnArray.h>\n-#include <Columns/ColumnTuple.h>\n-#include <Columns/ColumnsNumber.h>\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypeTuple.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <IO/ReadHelpers.h>\n-#include <IO/WriteHelpers.h>\n-#include <Common/ArenaAllocator.h>\n-#include <Common/assert_cast.h>\n-#include <ext/range.h>\n-#include \"IAggregateFunction.h\"\n-\n-\n-namespace DB\n-{\n-\n-namespace ErrorCodes\n-{\n-    extern const int LOGICAL_ERROR;\n-    extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n-}\n-\n-template <bool rate>\n-struct AggregateFunctionTimeSeriesGroupSumData\n-{\n-    using DataPoint = std::pair<Int64, Float64>;\n-    struct Points\n-    {\n-        using Dps = std::queue<DataPoint>;\n-        Dps dps;\n-        void add(Int64 t, Float64 v)\n-        {\n-            dps.push(std::make_pair(t, v));\n-            if (dps.size() > 2)\n-                dps.pop();\n-        }\n-        Float64 getval(Int64 t)\n-        {\n-            Int64 t1, t2;\n-            Float64 v1, v2;\n-            if (rate)\n-            {\n-                if (dps.size() < 2)\n-                    return 0;\n-                t1 = dps.back().first;\n-                t2 = dps.front().first;\n-                v1 = dps.back().second;\n-                v2 = dps.front().second;\n-                return (v1 - v2) / Float64(t1 - t2);\n-            }\n-            else\n-            {\n-                if (dps.size() == 1 && t == dps.front().first)\n-                    return dps.front().second;\n-                t1 = dps.back().first;\n-                t2 = dps.front().first;\n-                v1 = dps.back().second;\n-                v2 = dps.front().second;\n-                return v2 + ((v1 - v2) * Float64(t - t2)) / Float64(t1 - t2);\n-            }\n-        }\n-    };\n-\n-    typedef std::map<UInt64, Points> Series;\n-    typedef PODArrayWithStackMemory<DataPoint, 128> AggSeries;\n-    Series ss;\n-    AggSeries result;\n-\n-    void add(UInt64 uid, Int64 t, Float64 v)\n-    { //suppose t is coming asc\n-        typename Series::iterator it_ss;\n-        if (ss.count(uid) == 0)\n-        { //time series not exist, insert new one\n-            Points tmp;\n-            tmp.add(t, v);\n-            ss.emplace(uid, tmp);\n-            it_ss = ss.find(uid);\n-        }\n-        else\n-        {\n-            it_ss = ss.find(uid);\n-            it_ss->second.add(t, v);\n-        }\n-        if (result.size() > 0 && t < result.back().first)\n-            throw Exception{\"timeSeriesGroupSum or timeSeriesGroupRateSum must order by timestamp asc.\", ErrorCodes::LOGICAL_ERROR};\n-        if (result.size() > 0 && t == result.back().first)\n-        {\n-            //do not add new point\n-            if (rate)\n-                result.back().second += it_ss->second.getval(t);\n-            else\n-                result.back().second += v;\n-        }\n-        else\n-        {\n-            if (rate)\n-                result.emplace_back(std::make_pair(t, it_ss->second.getval(t)));\n-            else\n-                result.emplace_back(std::make_pair(t, v));\n-        }\n-        ssize_t i = result.size() - 1;\n-        //reverse find out the index of timestamp that more than previous timestamp of t\n-        while (result[i].first > it_ss->second.dps.front().first && i >= 0)\n-            i--;\n-\n-        i++;\n-        while (i < ssize_t(result.size()) - 1)\n-        {\n-            result[i].second += it_ss->second.getval(result[i].first);\n-            i++;\n-        }\n-    }\n-\n-    void merge(const AggregateFunctionTimeSeriesGroupSumData & other)\n-    {\n-        //if ts has overlap, then aggregate two series by interpolation;\n-        AggSeries tmp;\n-        tmp.reserve(other.result.size() + result.size());\n-        size_t i = 0, j = 0;\n-        Int64 t1, t2;\n-        Float64 v1, v2;\n-        while (i < result.size() && j < other.result.size())\n-        {\n-            if (result[i].first < other.result[j].first)\n-            {\n-                if (j == 0)\n-                {\n-                    tmp.emplace_back(result[i]);\n-                }\n-                else\n-                {\n-                    t1 = other.result[j].first;\n-                    t2 = other.result[j - 1].first;\n-                    v1 = other.result[j].second;\n-                    v2 = other.result[j - 1].second;\n-                    Float64 value = result[i].second + v2 + (v1 - v2) * (Float64(result[i].first - t2)) / Float64(t1 - t2);\n-                    tmp.emplace_back(std::make_pair(result[i].first, value));\n-                }\n-                i++;\n-            }\n-            else if (result[i].first > other.result[j].first)\n-            {\n-                if (i == 0)\n-                {\n-                    tmp.emplace_back(other.result[j]);\n-                }\n-                else\n-                {\n-                    t1 = result[i].first;\n-                    t2 = result[i - 1].first;\n-                    v1 = result[i].second;\n-                    v2 = result[i - 1].second;\n-                    Float64 value = other.result[j].second + v2 + (v1 - v2) * (Float64(other.result[j].first - t2)) / Float64(t1 - t2);\n-                    tmp.emplace_back(std::make_pair(other.result[j].first, value));\n-                }\n-                j++;\n-            }\n-            else\n-            {\n-                tmp.emplace_back(std::make_pair(result[i].first, result[i].second + other.result[j].second));\n-                i++;\n-                j++;\n-            }\n-        }\n-        while (i < result.size())\n-        {\n-            tmp.emplace_back(result[i]);\n-            i++;\n-        }\n-        while (j < other.result.size())\n-        {\n-            tmp.push_back(other.result[j]);\n-            j++;\n-        }\n-        swap(result, tmp);\n-    }\n-\n-    void serialize(WriteBuffer & buf) const\n-    {\n-        size_t size = result.size();\n-        writeVarUInt(size, buf);\n-        if (size > 0)\n-        {\n-            buf.write(reinterpret_cast<const char *>(result.data()), size * sizeof(result[0]));\n-        }\n-    }\n-\n-    void deserialize(ReadBuffer & buf)\n-    {\n-        size_t size = 0;\n-        readVarUInt(size, buf);\n-        result.resize(size);\n-        if (size > 0)\n-        {\n-            buf.read(reinterpret_cast<char *>(result.data()), size * sizeof(result[0]));\n-        }\n-    }\n-};\n-template <bool rate>\n-class AggregateFunctionTimeSeriesGroupSum final\n-    : public IAggregateFunctionDataHelper<AggregateFunctionTimeSeriesGroupSumData<rate>, AggregateFunctionTimeSeriesGroupSum<rate>>\n-{\n-private:\n-public:\n-    String getName() const override { return rate ? \"timeSeriesGroupRateSum\" : \"timeSeriesGroupSum\"; }\n-\n-    AggregateFunctionTimeSeriesGroupSum(const DataTypes & arguments)\n-        : IAggregateFunctionDataHelper<AggregateFunctionTimeSeriesGroupSumData<rate>, AggregateFunctionTimeSeriesGroupSum<rate>>(arguments, {})\n-    {\n-        if (!WhichDataType(arguments[0].get()).isUInt64())\n-            throw Exception{\"Illegal type \" + arguments[0].get()->getName() + \" of argument 1 of aggregate function \" + getName()\n-                                + \", must be UInt64\",\n-                            ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT};\n-\n-        if (!WhichDataType(arguments[1].get()).isInt64())\n-            throw Exception{\"Illegal type \" + arguments[1].get()->getName() + \" of argument 2 of aggregate function \" + getName()\n-                                + \", must be Int64\",\n-                            ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT};\n-\n-        if (!WhichDataType(arguments[2].get()).isFloat64())\n-            throw Exception{\"Illegal type \" + arguments[2].get()->getName() + \" of argument 3 of aggregate function \" + getName()\n-                                + \", must be Float64\",\n-                            ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT};\n-    }\n-\n-    DataTypePtr getReturnType() const override\n-    {\n-        auto datatypes = std::vector<DataTypePtr>();\n-        datatypes.push_back(std::make_shared<DataTypeInt64>());\n-        datatypes.push_back(std::make_shared<DataTypeFloat64>());\n-\n-        return std::make_shared<DataTypeArray>(std::make_shared<DataTypeTuple>(datatypes));\n-    }\n-\n-    void add(AggregateDataPtr place, const IColumn ** columns, const size_t row_num, Arena *) const override\n-    {\n-        auto uid = assert_cast<const ColumnVector<UInt64> *>(columns[0])->getData()[row_num];\n-        auto ts = assert_cast<const ColumnVector<Int64> *>(columns[1])->getData()[row_num];\n-        auto val = assert_cast<const ColumnVector<Float64> *>(columns[2])->getData()[row_num];\n-        if (uid && ts && val)\n-        {\n-            this->data(place).add(uid, ts, val);\n-        }\n-    }\n-\n-    void merge(AggregateDataPtr place, ConstAggregateDataPtr rhs, Arena *) const override { this->data(place).merge(this->data(rhs)); }\n-\n-    void serialize(ConstAggregateDataPtr place, WriteBuffer & buf) const override { this->data(place).serialize(buf); }\n-\n-    void deserialize(AggregateDataPtr place, ReadBuffer & buf, Arena *) const override { this->data(place).deserialize(buf); }\n-\n-    void insertResultInto(AggregateDataPtr place, IColumn & to, Arena *) const override\n-    {\n-        const auto & value = this->data(place).result;\n-        size_t size = value.size();\n-\n-        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n-        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n-        size_t old_size = offsets_to.back();\n-\n-        offsets_to.push_back(offsets_to.back() + size);\n-\n-        if (size)\n-        {\n-            typename ColumnInt64::Container & ts_to\n-                = assert_cast<ColumnInt64 &>(assert_cast<ColumnTuple &>(arr_to.getData()).getColumn(0)).getData();\n-            typename ColumnFloat64::Container & val_to\n-                = assert_cast<ColumnFloat64 &>(assert_cast<ColumnTuple &>(arr_to.getData()).getColumn(1)).getData();\n-            ts_to.reserve(old_size + size);\n-            val_to.reserve(old_size + size);\n-            size_t i = 0;\n-            while (i < this->data(place).result.size())\n-            {\n-                ts_to.push_back(this->data(place).result[i].first);\n-                val_to.push_back(this->data(place).result[i].second);\n-                i++;\n-            }\n-        }\n-    }\n-\n-    bool allocatesMemoryInArena() const override { return true; }\n-};\n-}\ndiff --git a/src/AggregateFunctions/registerAggregateFunctions.cpp b/src/AggregateFunctions/registerAggregateFunctions.cpp\nindex 90109a984331..9e179ead0df1 100644\n--- a/src/AggregateFunctions/registerAggregateFunctions.cpp\n+++ b/src/AggregateFunctions/registerAggregateFunctions.cpp\n@@ -32,7 +32,6 @@ void registerAggregateFunctionsBitmap(AggregateFunctionFactory &);\n void registerAggregateFunctionsMaxIntersections(AggregateFunctionFactory &);\n void registerAggregateFunctionHistogram(AggregateFunctionFactory &);\n void registerAggregateFunctionRetention(AggregateFunctionFactory &);\n-void registerAggregateFunctionTimeSeriesGroupSum(AggregateFunctionFactory &);\n void registerAggregateFunctionMLMethod(AggregateFunctionFactory &);\n void registerAggregateFunctionEntropy(AggregateFunctionFactory &);\n void registerAggregateFunctionSimpleLinearRegression(AggregateFunctionFactory &);\n@@ -86,7 +85,6 @@ void registerAggregateFunctions()\n         registerAggregateFunctionsMaxIntersections(factory);\n         registerAggregateFunctionHistogram(factory);\n         registerAggregateFunctionRetention(factory);\n-        registerAggregateFunctionTimeSeriesGroupSum(factory);\n         registerAggregateFunctionMLMethod(factory);\n         registerAggregateFunctionEntropy(factory);\n         registerAggregateFunctionSimpleLinearRegression(factory);\ndiff --git a/src/AggregateFunctions/ya.make b/src/AggregateFunctions/ya.make\nindex f5e64f1471bf..8ba5655ace9b 100644\n--- a/src/AggregateFunctions/ya.make\n+++ b/src/AggregateFunctions/ya.make\n@@ -45,7 +45,6 @@ SRCS(\n     AggregateFunctionStatisticsSimple.cpp\n     AggregateFunctionSum.cpp\n     AggregateFunctionSumMap.cpp\n-    AggregateFunctionTimeSeriesGroupSum.cpp\n     AggregateFunctionTopK.cpp\n     AggregateFunctionUniq.cpp\n     AggregateFunctionUniqCombined.cpp\n",
  "test_patch": "diff --git a/tests/fuzz/ast.dict b/tests/fuzz/ast.dict\nindex fff02af1c4d5..8327f276b317 100644\n--- a/tests/fuzz/ast.dict\n+++ b/tests/fuzz/ast.dict\n@@ -344,8 +344,6 @@\n \"TABLE\"\n \"TABLES\"\n \"TEMPORARY\"\n-\"timeSeriesGroupRateSum\"\n-\"timeSeriesGroupSum\"\n \"TIMESTAMP\"\n \"TIMESTAMP_ADD\"\n \"TIMESTAMPADD\"\ndiff --git a/tests/queries/0_stateless/00910_aggregation_timeseriesgroupsum.reference b/tests/queries/0_stateless/00910_aggregation_timeseriesgroupsum.reference\ndeleted file mode 100644\nindex dbcad97e7430..000000000000\n--- a/tests/queries/0_stateless/00910_aggregation_timeseriesgroupsum.reference\n+++ /dev/null\n@@ -1,2 +0,0 @@\n-[(2,0.2),(3,0.8999999999999999),(7,2.0999999999999996),(8,2.4),(12,3.5999999999999996),(17,5.1000000000000005),(18,5.4),(24,7.199999999999999),(25,2.5)]\n-[(2,0),(3,0.09999999999999999),(7,0.3),(8,0.30000000000000004),(12,0.29999999999999993),(17,0.30000000000000004),(18,0.30000000000000004),(24,0.29999999999999993),(25,0.1)]\ndiff --git a/tests/queries/0_stateless/00910_aggregation_timeseriesgroupsum.sql b/tests/queries/0_stateless/00910_aggregation_timeseriesgroupsum.sql\ndeleted file mode 100644\nindex 3a1a334469c7..000000000000\n--- a/tests/queries/0_stateless/00910_aggregation_timeseriesgroupsum.sql\n+++ /dev/null\n@@ -1,10 +0,0 @@\n-drop table if exists tsgroupsum_test;\n-\n-create table tsgroupsum_test (uid UInt64, ts Int64, value Float64) engine=Memory;\n-insert into tsgroupsum_test values (1,2,0.2),(1,7,0.7),(1,12,1.2),(1,17,1.7),(1,25,2.5);\n-insert into tsgroupsum_test values (2,3,0.6),(2,8,1.6),(2,12,2.4),(2,18,3.6),(2,24,4.8);\n-\n-select timeSeriesGroupSum(uid, ts, value) from (select * from tsgroupsum_test order by ts asc);\n-select timeSeriesGroupRateSum(uid, ts, value) from (select * from tsgroupsum_test order by ts asc);\n-\n-drop table tsgroupsum_test;\ndiff --git a/tests/queries/0_stateless/01560_timeseriesgroupsum_segfault.reference b/tests/queries/0_stateless/01560_timeseriesgroupsum_segfault.reference\ndeleted file mode 100644\nindex 814095e78182..000000000000\n--- a/tests/queries/0_stateless/01560_timeseriesgroupsum_segfault.reference\n+++ /dev/null\n@@ -1,3 +0,0 @@\n-[]\n-1\n-server is still alive\ndiff --git a/tests/queries/0_stateless/01560_timeseriesgroupsum_segfault.sql b/tests/queries/0_stateless/01560_timeseriesgroupsum_segfault.sql\ndeleted file mode 100644\nindex eb7c91967e5a..000000000000\n--- a/tests/queries/0_stateless/01560_timeseriesgroupsum_segfault.sql\n+++ /dev/null\n@@ -1,23 +0,0 @@\n-DROP TABLE IF EXISTS tsgs_local;\n-DROP TABLE IF EXISTS tsgs;\n-\n-CREATE TABLE tsgs_local ENGINE = MergeTree ORDER BY tuple() AS\n-SELECT\n-    toUInt64(13820745146630357293) AS a,\n-    toInt64(1604422500000000000) AS b,\n-    toFloat64(0) AS c\n-FROM numbers(100);\n-\n--- the issue (https://github.com/ClickHouse/ClickHouse/issues/16862) happens during serialization of the state\n--- so happens only when Distributed tables are used or with -State modifier.\n-\n-CREATE TABLE tsgs AS tsgs_local ENGINE = Distributed(test_cluster_two_shards, currentDatabase(), tsgs_local);\n-\n-SELECT timeSeriesGroupSum(a, b, c) FROM tsgs;\n-\n-SELECT count() FROM ( SELECT timeSeriesGroupSumState(a, b, c) as x FROM tsgs_local) WHERE NOT ignore(*);\n-\n-SELECT 'server is still alive';\n-\n-DROP TABLE tsgs_local;\n-DROP TABLE tsgs;\n",
  "problem_statement": "TimeSeriesGroupSum algorithm is totally wrong \n... and code quality is very poor.\r\n\r\nImagine the 3 timeseries: the first is growing from 200 with rate `2*t`, and another two are decreasing starting from 200 with `t` rate. So sum should always be constant `600`.\r\n\r\n```\r\nWITH [200. + (2 * number), 200. - number, 200. - number] AS vals\r\nSELECT\r\n    arrayJoin(if((number = 0) OR (number >= 10), [1, 2, 3], [(number % 3) + 1])) AS ts_id,\r\n    number + 1000 AS timestamp,\r\n    vals[ts_id] AS value\r\nFROM numbers(11)\r\nORDER BY timestamp\r\n\r\n\u250c\u2500ts_id\u2500\u252c\u2500timestamp\u2500\u252c\u2500value\u2500\u2510\r\n\u2502     1 \u2502      1000 \u2502   200 \u2502\r\n\u2502     2 \u2502      1000 \u2502   200 \u2502\r\n\u2502     3 \u2502      1000 \u2502   200 \u2502\r\n\u2502     2 \u2502      1001 \u2502   199 \u2502\r\n\u2502     3 \u2502      1002 \u2502   198 \u2502\r\n\u2502     1 \u2502      1003 \u2502   206 \u2502\r\n\u2502     2 \u2502      1004 \u2502   196 \u2502\r\n\u2502     3 \u2502      1005 \u2502   195 \u2502\r\n\u2502     1 \u2502      1006 \u2502   212 \u2502\r\n\u2502     2 \u2502      1007 \u2502   193 \u2502\r\n\u2502     3 \u2502      1008 \u2502   192 \u2502\r\n\u2502     1 \u2502      1009 \u2502   218 \u2502\r\n\u2502     1 \u2502      1010 \u2502   220 \u2502\r\n\u2502     2 \u2502      1010 \u2502   190 \u2502\r\n\u2502     3 \u2502      1010 \u2502   190 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n15 rows in set. Elapsed: 0.003 sec. \r\n```\r\n\r\nI've added anchors at the beginning and at both ends of all 3 sequences to simplify the calculation. \r\n\r\nIt seems the function returns the proper result: \r\n```\r\nSELECT timeSeriesGroupSum(toUInt64(ts_id), toInt64(timestamp), value)\r\nFROM \r\n(\r\n    WITH [200. + (2 * number), 200. - number, 200. - number] AS vals\r\n    SELECT\r\n        arrayJoin(if((number = 0) OR (number >= 10), [1, 2, 3], [(number % 3) + 1])) AS ts_id,\r\n        number + 1000 AS timestamp,\r\n        vals[ts_id] AS value\r\n    FROM numbers(11)\r\n)\r\n\r\nQuery id: 526c8000-c02b-4677-b454-4a1916b1274b\r\n\r\n\u250c\u2500timeSeriesGroupSum(toUInt64(ts_id), toInt64(timestamp), value)\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 [(1000,600),(1001,600),(1002,600),(1003,600),(1004,600),(1005,600),(1006,600),(1007,600),(1008,600),(1009,600),(1010,600)] \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 0.003 sec. \r\n```\r\n\r\nBut actually they are correct only before state merges will start happening. If we will split our data into several chunks and process them in parallel, to force the states merging - the result will be completely wrong:\r\n\r\n```\r\nSET max_threads = 11, max_block_size = 1\r\n\r\nSELECT timeSeriesGroupSum(toUInt64(ts_id), toInt64(timestamp), value)\r\nFROM \r\n(\r\n    WITH [200. + (2 * number), 200. - number, 200. - number] AS vals\r\n    SELECT\r\n        arrayJoin(if((number = 0) OR (number >= 10), [1, 2, 3], [(number % 3) + 1])) AS ts_id,\r\n        number + 1000 AS timestamp,\r\n        vals[ts_id] AS value\r\n    FROM numbers_mt(11)\r\n)\r\n\r\nQuery id: 616ca5c1-95c9-4e4a-9a2a-0d5a8ea19188\r\n\r\n\u250c\u2500timeSeriesGroupSum(toUInt64(ts_id), toInt64(timestamp), value)\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 [(1000,600),(1001,199),(1002,441.55555555555554),(1003,765.3611111111111),(1004,677.1666666666666),(1005,1008.9055555555556),(1006,950.6444444444444),(1007,1103.7166666666667),(1008,1159.2888888888888),(1009,830.8611111111111),(1010,600)] \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 0.004 sec. \r\n\r\n```\r\n:scream:\r\n\r\n\r\nAlso there are other inconsistencies there like:\r\n```\r\nSELECT timeSeriesGroupSum(id, ts, val) FROM values('id UInt64, ts Int64, val Float64', (1, 1, 1))\r\n\u250c\u2500timeSeriesGroupSum(id, ts, val)\u2500\u2510\r\n\u2502 [(1,1)]                         \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nvs \r\n```\r\nSELECT timeSeriesGroupSum(id, ts, val) FROM values('id UInt64, ts Int64, val Float64', (1, 1, 0))\r\n\u250c\u2500timeSeriesGroupSum(id, ts, val)\u2500\u2510\r\n\u2502 []                              \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\n",
  "hints_text": "@filimonov If it is totally wrong, we can simply delete this function, and only then commit the replacement.\n> @filimonov If it is totally wrong, we can simply delete this function, and only then commit the replacement\r\n\r\nFrom one side can't imagine how that can be used on the bigger datasets in current implementation (and wondering why nobody complain on that), but for single block it should work ok.\r\n\r\nBut removing that may create compatibility issues (we still want people to be able to update). \nSince it works on single block - maybe we should hide it for now using the same setting as proposed here: https://github.com/ClickHouse/ClickHouse/issues/16484  ? \nIt's too obscure, let's remove it.\nAfter discussion in a telegram, we decided to remove docs right now, and the function itself will be removed / rewriten / replaced in future releases. \r\n\r\nhttps://github.com/ClickHouse/ClickHouse/pull/16901\nOne more test:\r\n```\r\nSELECT timeSeriesGroupSumMerge(x)\r\nFROM \r\n(\r\n    SELECT timeSeriesGroupSumState(id, ts, val) AS x\r\n    FROM values('id UInt64, ts Int64, val Float64', (1, 1, 1), (2, 50, -50), (1, 100, 100))\r\n    UNION ALL\r\n    SELECT timeSeriesGroupSumState(id, ts, val) AS x\r\n    FROM values('id UInt64, ts Int64, val Float64', (2, 150, -150))\r\n)\r\n\r\nQuery id: 6d61ecf5-2375-4f46-b661-1e1276a39402\r\n\r\n\u250c\u2500timeSeriesGroupSumMerge(x)\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 [(1,1),(50,0),(100,100),(150,-150)] \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\nvs \r\n```\r\nSELECT timeSeriesGroupSum(id, ts, val) AS x\r\nFROM values('id UInt64, ts Int64, val Float64', (1, 1, 1), (2, 50, -50), (1, 100, 100), (2, 150, -150))\r\n\r\nQuery id: 14b0e159-7a5b-4ddf-a143-79a24ed8b40c\r\n\r\n\u250c\u2500x\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 [(1,1),(50,0),(100,0),(150,-150)] \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```",
  "created_at": "2020-11-26T02:49:34Z"
}