You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
BFloat16 summing merge assertion
### Describe the bug

Easy to reproduce, run the following statements on a debug build.

### How to reproduce

Run:

```sql
SET allow_experimental_bfloat16_type = 1;
CREATE TABLE t0 (c0 BFloat16 PRIMARY KEY) ENGINE = SummingMergeTree();
INSERT INTO TABLE t0 (c0) VALUES (nan);
INSERT INTO TABLE t0 (c0) VALUES (nan);
SELECT c0 FROM t0 FINAL;
```

### Error message and/or stacktrace

Stack trace:
```
<Fatal> : Logical error: 'part_index_start_to_range.contains(current_part_range_index)'.
<Fatal> : Stack trace (when copying this message, always include the lines below):

0. src/Common/StackTrace.cpp:381: StackTrace::tryCapture() @ 0x000000000f84a252
1. src/Common/Exception.cpp:53: DB::abortOnFailedAssertion(String const&) @ 0x000000000f7c2b35
2. src/Processors/QueryPlan/PartsSplitter.cpp:603: (anonymous namespace)::splitPartsRanges(DB::RangesInDataParts, bool, std::shared_ptr<Poco::Logger> const&) @ 0x00000000169a6be9
3. src/Processors/QueryPlan/PartsSplitter.cpp:991: DB::splitPartsWithRangesByPrimaryKey(DB::KeyDescription const&, DB::KeyDescription const&, std::shared_ptr<DB::ExpressionActions>, DB::RangesInDataParts, unsigned long, std::shared_ptr<DB::Context const>, std::function<DB::Pipe (DB::RangesInDataParts)>&&, bool, bool) @ 0x00000000169a1ae0
4. src/Processors/QueryPlan/ReadFromMergeTree.cpp:1381: DB::ReadFromMergeTree::spreadMarkRangesAmongStreamsFinal(DB::RangesInDataParts&&, unsigned long, std::vector<String, std::allocator<String>> const&, std::vector<String, std::allocator<String>> const&, std::optional<DB::ActionsDAG>&) @ 0x000000001697106c
5. src/Processors/QueryPlan/ReadFromMergeTree.cpp:2044: DB::ReadFromMergeTree::spreadMarkRanges(DB::RangesInDataParts&&, unsigned long, DB::ReadFromMergeTree::AnalysisResult&, std::optional<DB::ActionsDAG>&) @ 0x000000001697b7df
6. src/Processors/QueryPlan/ReadFromMergeTree.cpp:2151: DB::ReadFromMergeTree::initializePipeline(DB::QueryPipelineBuilder&, DB::BuildQueryPipelineSettings const&) @ 0x000000001697ce5f
7. src/Processors/QueryPlan/ISourceStep.cpp:20: DB::ISourceStep::updatePipeline(std::vector<std::unique_ptr<DB::QueryPipelineBuilder, std::default_delete<DB::QueryPipelineBuilder>>, std::allocator<std::unique_ptr<DB::QueryPipelineBuilder, std::default_delete<DB::QueryPipelineBuilder>>>>, DB::BuildQueryPipelineSettings const&) @ 0x0000000016924330
8. src/Processors/QueryPlan/QueryPlan.cpp:202: DB::QueryPlan::buildQueryPipeline(DB::QueryPlanOptimizationSettings const&, DB::BuildQueryPipelineSettings const&) @ 0x000000001695194f
9. src/Interpreters/InterpreterSelectQueryAnalyzer.cpp:275: DB::InterpreterSelectQueryAnalyzer::buildQueryPipeline() @ 0x00000000144dd097
10. src/Interpreters/InterpreterSelectQueryAnalyzer.cpp:242: DB::InterpreterSelectQueryAnalyzer::execute() @ 0x00000000144dce1e
11. src/Interpreters/executeQuery.cpp:1458: DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000147f0349
12. src/Interpreters/executeQuery.cpp:1625: DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000147ebdeb
13. src/Server/TCPHandler.cpp:664: DB::TCPHandler::runImpl() @ 0x0000000016447d41
14. src/Server/TCPHandler.cpp:2629: DB::TCPHandler::run() @ 0x000000001645feb9
15. base/poco/Net/src/TCPServerConnection.cpp:40: Poco::Net::TCPServerConnection::start() @ 0x000000001a74eac7
16. base/poco/Net/src/TCPServerDispatcher.cpp:115: Poco::Net::TCPServerDispatcher::run() @ 0x000000001a74ef9e
17. base/poco/Foundation/src/ThreadPool.cpp:205: Poco::PooledThread::run() @ 0x000000001a6fc612
18. base/poco/Foundation/src/Thread_POSIX.cpp:335: Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001a6fa24f
19. ? @ 0x00007ffff7ca1e2e
20. ? @ 0x00007ffff7d33a4c
```
`03367_bfloat16_tuple_final` is flaky
I noticed today a sporadic failure of 03367_bfloat16_tuple_final.sql after #77000 added the test:

https://d1k2gkhrlfqv31.cloudfront.net/clickhouse-test-reports-private/json.html?REF=master&sha=ba3adc7c0bb172e3413b3da114ef0b5e778179e4&name_0=MasterCI&name_1=Stateless+tests+%28debug%2C+distributed+cache%2C+s3+storage%29&name_2=03367_bfloat16_tuple_final

```
2025-03-03 16:24:29 Reason: result differs with reference:
2025-03-03 16:24:29 --- /repo/tests/queries/0_stateless/03367_bfloat16_tuple_final.reference 2025-03-03 16:17:57.781727094 +0100
2025-03-03 16:24:29 +++ /repo/tests/queries/0_stateless/03367_bfloat16_tuple_final.stdout 2025-03-03 16:24:29.921444124 +0100
2025-03-03 16:24:29 @@ -126,21 +126,21 @@
2025-03-03 16:24:29 (-1.6953125)
2025-03-03 16:24:29 (-1.234375)
2025-03-03 16:24:29 (-1.09375)
2025-03-03 16:24:29 (-1.0859375)
2025-03-03 16:24:29 (-0.87890625)
2025-03-03 16:24:29 (-0.859375)
2025-03-03 16:24:29 (-0.703125)
2025-03-03 16:24:29 (-0.69921875)
2025-03-03 16:24:29 (-0.12792969)
2025-03-03 16:24:29 (-0.028198242)
2025-03-03 16:24:29 -(0)
2025-03-03 16:24:29 +(-0)
2025-03-03 16:24:29 (0.48242188)
2025-03-03 16:24:29 (1.5)
2025-03-03 16:24:29 (1.796875)
2025-03-03 16:24:29 (1.828125)
2025-03-03 16:24:29 (3.59375)
2025-03-03 16:24:29 (5.125)
2025-03-03 16:24:29 (7.90625)
2025-03-03 16:24:29 (7.96875)
2025-03-03 16:24:29 (8.625)
2025-03-03 16:24:29 (9)
2025-03-03 16:24:29
2025-03-03 16:24:29
2025-03-03 16:24:29
2025-03-03 16:24:29 MergeTree settings used in test: --ratio_of_defaults_for_sparse_serialization 1.0 --prefer_fetch_merged_part_size_threshold 1527210177 --vertical_merge_algorithm_min_rows_to_activate 1 --vertical_merge_algorithm_min_columns_to_activate 100 --allow_vertical_merges_from_compact_to_wide_parts 0 --min_merge_bytes_to_use_direct_io 10737418240 --index_granularity_bytes 22132302 --merge_max_block_size 8629 --index_granularity 24417 --min_bytes_for_wide_part 0 --marks_compress_block_size 40102 --primary_key_compress_block_size 51484 --replace_long_file_name_to_hash 0 --max_file_name_length 0 --min_bytes_for_full_part_storage 0 --compact_parts_max_bytes_to_buffer 188046474 --compact_parts_max_granules_to_buffer 113 --compact_parts_merge_max_bytes_to_prefetch_part 5307317 --cache_populated_by_fetch 1 --concurrent_part_removal_threshold 100 --old_parts_lifetime 10 --prewarm_mark_cache 1 --use_const_adaptive_granularity 0 --enable_index_granularity_compression 1 --enable_block_number_column 1 --enable_block_offset_column 0 --use_primary_key_cache 0 --prewarm_primary_key_cache 0
2025-03-03 16:24:29
2025-03-03 16:24:29 Database: test_gtmjqn7e
```

The failure is independent of merge tree settings. A smaller repro is:

```sql
DROP TABLE IF EXISTS t0;
CREATE TABLE t0 (c0 Tuple(BFloat16)) ENGINE = SummingMergeTree() ORDER BY (c0);
INSERT INTO TABLE t0 (c0) VALUES ((+0.0, )), ((nan, )), ((-0.0, ));
SELECT c0 FROM t0 FINAL;
DROP TABLE t0;
```

To reproduce, replace the test with the repro, then update expected results, then run the test in a loop (`--test-runs 10` will do). Symptoms are like in #75669 (`nan` is present).
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
