{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 36077,
  "instance_id": "ClickHouse__ClickHouse-36077",
  "issue_numbers": [
    "35960",
    "35996"
  ],
  "base_commit": "d8fa806fca1e2130ad43977db9b5bf16e8f94a2d",
  "patch": "diff --git a/base/base/StringRef.h b/base/base/StringRef.h\nindex f300a2d63df5..1ff6fbd3ee79 100644\n--- a/base/base/StringRef.h\n+++ b/base/base/StringRef.h\n@@ -51,6 +51,8 @@ struct StringRef\n     constexpr StringRef(const char * data_) : StringRef(std::string_view{data_}) {} /// NOLINT\n     constexpr StringRef() = default;\n \n+    bool empty() const { return size == 0; }\n+\n     std::string toString() const { return std::string(data, size); }\n \n     explicit operator std::string() const { return toString(); }\ndiff --git a/src/Columns/ColumnObject.cpp b/src/Columns/ColumnObject.cpp\nindex 64c7a84c263f..2152f446b52a 100644\n--- a/src/Columns/ColumnObject.cpp\n+++ b/src/Columns/ColumnObject.cpp\n@@ -58,9 +58,7 @@ class FieldVisitorReplaceNull : public StaticVisitor<Field>\n \n     Field operator()(const Null &) const\n     {\n-        return num_dimensions\n-            ? createEmptyArrayField(num_dimensions)\n-            : replacement;\n+        return num_dimensions ? Array() : replacement;\n     }\n \n     Field operator()(const Array & x) const\n@@ -81,38 +79,6 @@ class FieldVisitorReplaceNull : public StaticVisitor<Field>\n     size_t num_dimensions;\n };\n \n-/// Calculates number of dimensions in array field.\n-/// Returns 0 for scalar fields.\n-class FieldVisitorToNumberOfDimensions : public StaticVisitor<size_t>\n-{\n-public:\n-    size_t operator()(const Array & x) const\n-    {\n-        const size_t size = x.size();\n-        std::optional<size_t> dimensions;\n-\n-        for (size_t i = 0; i < size; ++i)\n-        {\n-            /// Do not count Nulls, because they will be replaced by default\n-            /// values with proper number of dimensions.\n-            if (x[i].isNull())\n-                continue;\n-\n-            size_t current_dimensions = applyVisitor(*this, x[i]);\n-            if (!dimensions)\n-                dimensions = current_dimensions;\n-            else if (current_dimensions != *dimensions)\n-                throw Exception(ErrorCodes::NUMBER_OF_DIMENSIONS_MISMATHED,\n-                    \"Number of dimensions mismatched among array elements\");\n-        }\n-\n-        return 1 + dimensions.value_or(0);\n-    }\n-\n-    template <typename T>\n-    size_t operator()(const T &) const { return 0; }\n-};\n-\n /// Visitor that allows to get type of scalar field\n /// or least common type of scalars in array.\n /// More optimized version of FieldToDataType.\n@@ -292,7 +258,7 @@ void ColumnObject::Subcolumn::insert(Field field, FieldInfo info)\n     if (isNothing(least_common_type.get()))\n         column_dim = value_dim;\n \n-    if (field.isNull())\n+    if (isNothing(base_type))\n         value_dim = column_dim;\n \n     if (value_dim != column_dim)\ndiff --git a/src/DataTypes/ObjectUtils.cpp b/src/DataTypes/ObjectUtils.cpp\nindex 044e03afd104..ab4ac847a1ce 100644\n--- a/src/DataTypes/ObjectUtils.cpp\n+++ b/src/DataTypes/ObjectUtils.cpp\n@@ -693,4 +693,26 @@ void finalizeObjectColumns(MutableColumns & columns)\n             column_object->finalize();\n }\n \n+Field FieldVisitorReplaceScalars::operator()(const Array & x) const\n+{\n+    if (num_dimensions_to_keep == 0)\n+        return replacement;\n+\n+    const size_t size = x.size();\n+    Array res(size);\n+    for (size_t i = 0; i < size; ++i)\n+        res[i] = applyVisitor(FieldVisitorReplaceScalars(replacement, num_dimensions_to_keep - 1), x[i]);\n+    return res;\n+}\n+\n+size_t FieldVisitorToNumberOfDimensions::operator()(const Array & x) const\n+{\n+    const size_t size = x.size();\n+    size_t dimensions = 0;\n+    for (size_t i = 0; i < size; ++i)\n+        dimensions = std::max(dimensions, applyVisitor(*this, x[i]));\n+\n+    return 1 + dimensions;\n+}\n+\n }\ndiff --git a/src/DataTypes/ObjectUtils.h b/src/DataTypes/ObjectUtils.h\nindex 1dbeac2b2443..8dc46ceecf5d 100644\n--- a/src/DataTypes/ObjectUtils.h\n+++ b/src/DataTypes/ObjectUtils.h\n@@ -5,7 +5,6 @@\n #include <Common/FieldVisitors.h>\n #include <Storages/ColumnsDescription.h>\n #include <DataTypes/DataTypeTuple.h>\n-#include <DataTypes/Serializations/JSONDataParser.h>\n #include <DataTypes/DataTypesNumber.h>\n #include <Columns/ColumnObject.h>\n \n@@ -87,6 +86,37 @@ void replaceMissedSubcolumnsByConstants(\n     const ColumnsDescription & available_columns,\n     ASTPtr query);\n \n+/// Visitor that keeps @num_dimensions_to_keep dimensions in arrays\n+/// and replaces all scalars or nested arrays to @replacement at that level.\n+class FieldVisitorReplaceScalars : public StaticVisitor<Field>\n+{\n+public:\n+    FieldVisitorReplaceScalars(const Field & replacement_, size_t num_dimensions_to_keep_)\n+        : replacement(replacement_), num_dimensions_to_keep(num_dimensions_to_keep_)\n+    {\n+    }\n+\n+    Field operator()(const Array & x) const;\n+\n+    template <typename T>\n+    Field operator()(const T &) const { return replacement; }\n+\n+private:\n+    const Field & replacement;\n+    size_t num_dimensions_to_keep;\n+};\n+\n+/// Calculates number of dimensions in array field.\n+/// Returns 0 for scalar fields.\n+class FieldVisitorToNumberOfDimensions : public StaticVisitor<size_t>\n+{\n+public:\n+    size_t operator()(const Array & x) const;\n+\n+    template <typename T>\n+    size_t operator()(const T &) const { return 0; }\n+};\n+\n /// Receives range of objects, which contains collections\n /// of columns-like objects (e.g. ColumnsDescription or NamesAndTypesList)\n /// and deduces the common types of object columns for all entries.\ndiff --git a/src/DataTypes/Serializations/JSONDataParser.cpp b/src/DataTypes/Serializations/JSONDataParser.cpp\nnew file mode 100644\nindex 000000000000..c3eefb4ab63f\n--- /dev/null\n+++ b/src/DataTypes/Serializations/JSONDataParser.cpp\n@@ -0,0 +1,267 @@\n+#include <DataTypes/Serializations/JSONDataParser.h>\n+#include <Common/JSONParsers/SimdJSONParser.h>\n+#include <Common/JSONParsers/RapidJSONParser.h>\n+#include <Common/checkStackSize.h>\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int LOGICAL_ERROR;\n+}\n+\n+template <typename ParserImpl>\n+std::optional<ParseResult> JSONDataParser<ParserImpl>::parse(const char * begin, size_t length)\n+{\n+    std::string_view json{begin, length};\n+    Element document;\n+    if (!parser.parse(json, document))\n+        return {};\n+\n+    ParseContext context;\n+    traverse(document, context);\n+\n+    ParseResult result;\n+    result.values = std::move(context.values);\n+    result.paths.reserve(context.paths.size());\n+\n+    for (auto && path : context.paths)\n+        result.paths.emplace_back(std::move(path));\n+\n+    return result;\n+}\n+\n+template <typename ParserImpl>\n+void JSONDataParser<ParserImpl>::traverse(const Element & element, ParseContext & ctx)\n+{\n+    checkStackSize();\n+\n+    if (element.isObject())\n+    {\n+        traverseObject(element.getObject(), ctx);\n+    }\n+    else if (element.isArray())\n+    {\n+        traverseArray(element.getArray(), ctx);\n+    }\n+    else\n+    {\n+        ctx.paths.push_back(ctx.builder.getParts());\n+        ctx.values.push_back(getValueAsField(element));\n+    }\n+}\n+\n+template <typename ParserImpl>\n+void JSONDataParser<ParserImpl>::traverseObject(const JSONObject & object, ParseContext & ctx)\n+{\n+    ctx.paths.reserve(ctx.paths.size() + object.size());\n+    ctx.values.reserve(ctx.values.size() + object.size());\n+\n+    for (auto it = object.begin(); it != object.end(); ++it)\n+    {\n+        const auto & [key, value] = *it;\n+        ctx.builder.append(key, false);\n+        traverse(value, ctx);\n+        ctx.builder.popBack();\n+    }\n+}\n+\n+template <typename ParserImpl>\n+void JSONDataParser<ParserImpl>::traverseArray(const JSONArray & array, ParseContext & ctx)\n+{\n+    /// Traverse elements of array and collect an array of fields by each path.\n+    ParseArrayContext array_ctx;\n+    array_ctx.total_size = array.size();\n+\n+    for (auto it = array.begin(); it != array.end(); ++it)\n+    {\n+        traverseArrayElement(*it, array_ctx);\n+        ++array_ctx.current_size;\n+    }\n+\n+    auto && arrays_by_path = array_ctx.arrays_by_path;\n+\n+    if (arrays_by_path.empty())\n+    {\n+        ctx.paths.push_back(ctx.builder.getParts());\n+        ctx.values.push_back(Array());\n+    }\n+    else\n+    {\n+        ctx.paths.reserve(ctx.paths.size() + arrays_by_path.size());\n+        ctx.values.reserve(ctx.values.size() + arrays_by_path.size());\n+\n+        for (auto && [_, value] : arrays_by_path)\n+        {\n+            auto && [path, path_array] = value;\n+\n+            /// Merge prefix path and path of array element.\n+            ctx.paths.push_back(ctx.builder.append(path, true).getParts());\n+            ctx.values.push_back(std::move(path_array));\n+            ctx.builder.popBack(path.size());\n+        }\n+    }\n+}\n+\n+template <typename ParserImpl>\n+void JSONDataParser<ParserImpl>::traverseArrayElement(const Element & element, ParseArrayContext & ctx)\n+{\n+    ParseContext element_ctx;\n+    traverse(element, element_ctx);\n+\n+    auto & [_, paths, values] = element_ctx;\n+    size_t size = paths.size();\n+    size_t keys_to_update = ctx.arrays_by_path.size();\n+\n+    for (size_t i = 0; i < size; ++i)\n+    {\n+        if (values[i].isNull())\n+            continue;\n+\n+        UInt128 hash = PathInData::getPartsHash(paths[i]);\n+        if (auto * found = ctx.arrays_by_path.find(hash))\n+        {\n+            auto & path_array = found->getMapped().second;\n+            assert(path_array.size() == ctx.current_size);\n+\n+            /// If current element of array is part of Nested,\n+            /// collect its size or check it if the size of\n+            /// the Nested has been already collected.\n+            auto nested_key = getNameOfNested(paths[i], values[i]);\n+            if (!nested_key.empty())\n+            {\n+                size_t array_size = get<const Array &>(values[i]).size();\n+                auto & current_nested_sizes = ctx.nested_sizes_by_key[nested_key];\n+\n+                if (current_nested_sizes.size() == ctx.current_size)\n+                    current_nested_sizes.push_back(array_size);\n+                else if (array_size != current_nested_sizes.back())\n+                    throw Exception(ErrorCodes::LOGICAL_ERROR,\n+                        \"Array sizes mismatched ({} and {})\", array_size, current_nested_sizes.back());\n+            }\n+\n+            path_array.push_back(std::move(values[i]));\n+            --keys_to_update;\n+        }\n+        else\n+        {\n+            /// We found a new key. Add and empty array with current size.\n+            Array path_array;\n+            path_array.reserve(ctx.total_size);\n+            path_array.resize(ctx.current_size);\n+\n+            auto nested_key = getNameOfNested(paths[i], values[i]);\n+            if (!nested_key.empty())\n+            {\n+                size_t array_size = get<const Array &>(values[i]).size();\n+                auto & current_nested_sizes = ctx.nested_sizes_by_key[nested_key];\n+\n+                if (current_nested_sizes.empty())\n+                {\n+                    current_nested_sizes.resize(ctx.current_size);\n+                }\n+                else\n+                {\n+                    /// If newly added element is part of the Nested then\n+                    /// resize its elements to keep correct sizes of Nested arrays.\n+                    for (size_t j = 0; j < ctx.current_size; ++j)\n+                        path_array[j] = Array(current_nested_sizes[j]);\n+                }\n+\n+                if (current_nested_sizes.size() == ctx.current_size)\n+                    current_nested_sizes.push_back(array_size);\n+                else if (array_size != current_nested_sizes.back())\n+                    throw Exception(ErrorCodes::LOGICAL_ERROR,\n+                        \"Array sizes mismatched ({} and {})\", array_size, current_nested_sizes.back());\n+            }\n+\n+            path_array.push_back(std::move(values[i]));\n+\n+            auto & elem = ctx.arrays_by_path[hash];\n+            elem.first = std::move(paths[i]);\n+            elem.second = std::move(path_array);\n+        }\n+    }\n+\n+    /// If some of the keys are missed in current element,\n+    /// add default values for them.\n+    if (keys_to_update)\n+        fillMissedValuesInArrays(ctx);\n+}\n+\n+template <typename ParserImpl>\n+void JSONDataParser<ParserImpl>::fillMissedValuesInArrays(ParseArrayContext & ctx)\n+{\n+    for (auto & [_, value] : ctx.arrays_by_path)\n+    {\n+        auto & [path, path_array] = value;\n+        assert(path_array.size() == ctx.current_size || path_array.size() == ctx.current_size + 1);\n+\n+        if (path_array.size() == ctx.current_size)\n+        {\n+            bool inserted = tryInsertDefaultFromNested(ctx, path, path_array);\n+            if (!inserted)\n+                path_array.emplace_back();\n+        }\n+    }\n+}\n+\n+template <typename ParserImpl>\n+bool JSONDataParser<ParserImpl>::tryInsertDefaultFromNested(\n+    ParseArrayContext & ctx, const PathInData::Parts & path, Array & array)\n+{\n+    /// If there is a collected size of current Nested\n+    /// then insert array of this size as a default value.\n+\n+    if (path.empty())\n+        return false;\n+\n+    StringRef nested_key{path[0].key};\n+    auto * mapped = ctx.nested_sizes_by_key.find(nested_key);\n+    if (!mapped)\n+        return false;\n+\n+    auto & current_nested_sizes = mapped->getMapped();\n+    assert(current_nested_sizes.size() == ctx.current_size || current_nested_sizes.size() == ctx.current_size + 1);\n+\n+    /// If all keys of Nested were missed then add a zero length.\n+    if (current_nested_sizes.size() == ctx.current_size)\n+        current_nested_sizes.push_back(0);\n+\n+    size_t array_size = current_nested_sizes.back();\n+    array.push_back(Array(array_size));\n+    return true;\n+}\n+\n+template <typename ParserImpl>\n+Field JSONDataParser<ParserImpl>::getValueAsField(const Element & element)\n+{\n+    if (element.isBool())   return element.getBool();\n+    if (element.isInt64())  return element.getInt64();\n+    if (element.isUInt64()) return element.getUInt64();\n+    if (element.isDouble()) return element.getDouble();\n+    if (element.isString()) return element.getString();\n+    if (element.isNull())   return Field();\n+\n+    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unsupported type of JSON field\");\n+}\n+\n+template <typename ParserImpl>\n+StringRef JSONDataParser<ParserImpl>::getNameOfNested(const PathInData::Parts & path, const Field & value)\n+{\n+    if (value.getType() != Field::Types::Array || path.empty())\n+        return {};\n+\n+    return StringRef{path[0].key};\n+}\n+\n+#if USE_SIMDJSON\n+    template class JSONDataParser<SimdJSONParser>;\n+#endif\n+\n+#if USE_RAPIDJSON\n+    template class JSONDataParser<RapidJSONParser>;\n+#endif\n+\n+}\ndiff --git a/src/DataTypes/Serializations/JSONDataParser.h b/src/DataTypes/Serializations/JSONDataParser.h\nindex 36abc9278d14..d956bfc612b1 100644\n--- a/src/DataTypes/Serializations/JSONDataParser.h\n+++ b/src/DataTypes/Serializations/JSONDataParser.h\n@@ -2,180 +2,61 @@\n \n #include <IO/ReadHelpers.h>\n #include <Common/HashTable/HashMap.h>\n-#include <Common/checkStackSize.h>\n #include <DataTypes/Serializations/PathInData.h>\n \n namespace DB\n {\n \n-namespace ErrorCodes\n-{\n-    extern const int LOGICAL_ERROR;\n-}\n-\n class ReadBuffer;\n-class WriteBuffer;\n-\n-template <typename Element>\n-static Field getValueAsField(const Element & element)\n-{\n-    if (element.isBool())   return element.getBool();\n-    if (element.isInt64())  return element.getInt64();\n-    if (element.isUInt64()) return element.getUInt64();\n-    if (element.isDouble()) return element.getDouble();\n-    if (element.isString()) return element.getString();\n-    if (element.isNull())   return Field();\n-\n-    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unsupported type of JSON field\");\n-}\n \n template <typename ParserImpl>\n class JSONDataParser\n {\n public:\n-    using Element = typename ParserImpl::Element;\n-\n     static void readJSON(String & s, ReadBuffer & buf)\n     {\n         readJSONObjectPossiblyInvalid(s, buf);\n     }\n \n-    std::optional<ParseResult> parse(const char * begin, size_t length)\n-    {\n-        std::string_view json{begin, length};\n-        Element document;\n-        if (!parser.parse(json, document))\n-            return {};\n+    std::optional<ParseResult> parse(const char * begin, size_t length);\n+\n+private:\n+    using Element = typename ParserImpl::Element;\n+    using JSONObject = typename ParserImpl::Object;\n+    using JSONArray = typename ParserImpl::Array;\n \n-        ParseResult result;\n+    struct ParseContext\n+    {\n         PathInDataBuilder builder;\n         std::vector<PathInData::Parts> paths;\n+        std::vector<Field> values;\n+    };\n \n-        traverse(document, builder, paths, result.values);\n-\n-        result.paths.reserve(paths.size());\n-        for (auto && path : paths)\n-            result.paths.emplace_back(std::move(path));\n-\n-        return result;\n-    }\n+    using PathPartsWithArray = std::pair<PathInData::Parts, Array>;\n+    using PathToArray = HashMapWithStackMemory<UInt128, PathPartsWithArray, UInt128TrivialHash, 5>;\n+    using KeyToSizes = HashMapWithStackMemory<StringRef, std::vector<size_t>, StringRefHash, 5>;\n \n-private:\n-    void traverse(\n-        const Element & element,\n-        PathInDataBuilder & builder,\n-        std::vector<PathInData::Parts> & paths,\n-        std::vector<Field> & values)\n+    struct ParseArrayContext\n     {\n-        checkStackSize();\n-\n-        if (element.isObject())\n-        {\n-            auto object = element.getObject();\n-\n-            paths.reserve(paths.size() + object.size());\n-            values.reserve(values.size() + object.size());\n-\n-            for (auto it = object.begin(); it != object.end(); ++it)\n-            {\n-                const auto & [key, value] = *it;\n-                traverse(value, builder.append(key, false), paths, values);\n-                builder.popBack();\n-            }\n-        }\n-        else if (element.isArray())\n-        {\n-            auto array = element.getArray();\n-\n-            using PathPartsWithArray = std::pair<PathInData::Parts, Array>;\n-            using PathToArray = HashMapWithStackMemory<UInt128, PathPartsWithArray, UInt128TrivialHash, 5>;\n-\n-            /// Traverse elements of array and collect an array\n-            /// of fields by each path.\n-\n-            PathToArray arrays_by_path;\n-            Arena strings_pool;\n+        size_t current_size = 0;\n+        size_t total_size = 0;\n \n-            size_t current_size = 0;\n-            for (auto it = array.begin(); it != array.end(); ++it)\n-            {\n-                std::vector<PathInData::Parts> element_paths;\n-                std::vector<Field> element_values;\n-                PathInDataBuilder element_builder;\n+        PathToArray arrays_by_path;\n+        KeyToSizes nested_sizes_by_key;\n+        Arena strings_pool;\n+    };\n \n-                traverse(*it, element_builder, element_paths, element_values);\n-                size_t size = element_paths.size();\n-                size_t keys_to_update = arrays_by_path.size();\n+    void traverse(const Element & element, ParseContext & ctx);\n+    void traverseObject(const JSONObject & object, ParseContext & ctx);\n+    void traverseArray(const JSONArray & array, ParseContext & ctx);\n+    void traverseArrayElement(const Element & element, ParseArrayContext & ctx);\n \n-                for (size_t i = 0; i < size; ++i)\n-                {\n-                    UInt128 hash = PathInData::getPartsHash(element_paths[i]);\n-                    if (auto * found = arrays_by_path.find(hash))\n-                    {\n-                        auto & path_array = found->getMapped().second;\n+    static void fillMissedValuesInArrays(ParseArrayContext & ctx);\n+    static bool tryInsertDefaultFromNested(\n+        ParseArrayContext & ctx, const PathInData::Parts & path, Array & array);\n \n-                        assert(path_array.size() == current_size);\n-                        path_array.push_back(std::move(element_values[i]));\n-                        --keys_to_update;\n-                    }\n-                    else\n-                    {\n-                        /// We found a new key. Add and empty array with current size.\n-                        Array path_array;\n-                        path_array.reserve(array.size());\n-                        path_array.resize(current_size);\n-                        path_array.push_back(std::move(element_values[i]));\n-\n-                        auto & elem = arrays_by_path[hash];\n-                        elem.first = std::move(element_paths[i]);\n-                        elem.second = std::move(path_array);\n-                    }\n-                }\n-\n-                /// If some of the keys are missed in current element,\n-                /// add default values for them.\n-                if (keys_to_update)\n-                {\n-                    for (auto & [_, value] : arrays_by_path)\n-                    {\n-                        auto & path_array = value.second;\n-                        assert(path_array.size() == current_size || path_array.size() == current_size + 1);\n-                        if (path_array.size() == current_size)\n-                            path_array.push_back(Field());\n-                    }\n-                }\n-\n-                ++current_size;\n-            }\n-\n-            if (arrays_by_path.empty())\n-            {\n-                paths.push_back(builder.getParts());\n-                values.push_back(Array());\n-            }\n-            else\n-            {\n-                paths.reserve(paths.size() + arrays_by_path.size());\n-                values.reserve(values.size() + arrays_by_path.size());\n-\n-                for (auto && [_, value] : arrays_by_path)\n-                {\n-                    auto && [path, path_array] = value;\n-\n-                    /// Merge prefix path and path of array element.\n-                    paths.push_back(builder.append(path, true).getParts());\n-                    values.push_back(std::move(path_array));\n-\n-                    builder.popBack(path.size());\n-                }\n-            }\n-        }\n-        else\n-        {\n-            paths.push_back(builder.getParts());\n-            values.push_back(getValueAsField(element));\n-        }\n-    }\n+    static Field getValueAsField(const Element & element);\n+    static StringRef getNameOfNested(const PathInData::Parts & path, const Field & value);\n \n     ParserImpl parser;\n };\ndiff --git a/src/DataTypes/Serializations/SerializationObject.cpp b/src/DataTypes/Serializations/SerializationObject.cpp\nindex 82f9552fb862..2d6555dcb43a 100644\n--- a/src/DataTypes/Serializations/SerializationObject.cpp\n+++ b/src/DataTypes/Serializations/SerializationObject.cpp\n@@ -30,39 +30,6 @@ namespace ErrorCodes\n namespace\n {\n \n-/// Visitor that keeps @num_dimensions_to_keep dimensions in arrays\n-/// and replaces all scalars or nested arrays to @replacement at that level.\n-class FieldVisitorReplaceScalars : public StaticVisitor<Field>\n-{\n-public:\n-    FieldVisitorReplaceScalars(const Field & replacement_, size_t num_dimensions_to_keep_)\n-        : replacement(replacement_), num_dimensions_to_keep(num_dimensions_to_keep_)\n-    {\n-    }\n-\n-    template <typename T>\n-    Field operator()(const T & x) const\n-    {\n-        if constexpr (std::is_same_v<T, Array>)\n-        {\n-            if (num_dimensions_to_keep == 0)\n-                return replacement;\n-\n-            const size_t size = x.size();\n-            Array res(size);\n-            for (size_t i = 0; i < size; ++i)\n-                res[i] = applyVisitor(FieldVisitorReplaceScalars(replacement, num_dimensions_to_keep - 1), x[i]);\n-            return res;\n-        }\n-        else\n-            return replacement;\n-    }\n-\n-private:\n-    const Field & replacement;\n-    size_t num_dimensions_to_keep;\n-};\n-\n using Node = typename ColumnObject::Subcolumns::Node;\n \n /// Finds a subcolumn from the same Nested type as @entry and inserts\n@@ -120,7 +87,6 @@ bool tryInsertDefaultFromNested(\n \n     auto default_field = applyVisitor(FieldVisitorReplaceScalars(default_scalar, num_dimensions_to_keep), last_field);\n     entry->data.insert(std::move(default_field));\n-\n     return true;\n }\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01825_type_json_10.reference b/tests/queries/0_stateless/01825_type_json_10.reference\nnew file mode 100644\nindex 000000000000..53fe604fa514\n--- /dev/null\n+++ b/tests/queries/0_stateless/01825_type_json_10.reference\n@@ -0,0 +1,9 @@\n+Tuple(a Tuple(b Int8, c Nested(d Int8, e Array(Int16), f Int8)))\n+{\"o\":{\"a\":{\"b\":1,\"c\":[{\"d\":10,\"e\":[31],\"f\":0},{\"d\":20,\"e\":[63,127],\"f\":0}]}}}\n+{\"o\":{\"a\":{\"b\":2,\"c\":[]}}}\n+{\"o\":{\"a\":{\"b\":3,\"c\":[{\"d\":0,\"e\":[32],\"f\":20},{\"d\":0,\"e\":[64,128],\"f\":30}]}}}\n+{\"o\":{\"a\":{\"b\":4,\"c\":[]}}}\n+1\t[10,20]\t[[31],[63,127]]\t[0,0]\n+2\t[]\t[]\t[]\n+3\t[0,0]\t[[32],[64,128]]\t[20,30]\n+4\t[]\t[]\t[]\ndiff --git a/tests/queries/0_stateless/01825_type_json_10.sql b/tests/queries/0_stateless/01825_type_json_10.sql\nnew file mode 100644\nindex 000000000000..98f1a766ed82\n--- /dev/null\n+++ b/tests/queries/0_stateless/01825_type_json_10.sql\n@@ -0,0 +1,16 @@\n+-- Tags: no-fasttest\n+\n+SET allow_experimental_object_type = 1;\n+SET output_format_json_named_tuples_as_objects = 1;\n+\n+DROP TABLE IF EXISTS t_json_10;\n+CREATE TABLE t_json_10 (o JSON) ENGINE = Memory;\n+\n+INSERT INTO t_json_10 FORMAT JSONAsObject {\"a\": {\"b\": 1, \"c\": [{\"d\": 10, \"e\": [31]}, {\"d\": 20, \"e\": [63, 127]}]}} {\"a\": {\"b\": 2, \"c\": []}}\n+INSERT INTO t_json_10 FORMAT JSONAsObject {\"a\": {\"b\": 3, \"c\": [{\"f\": 20, \"e\": [32]}, {\"f\": 30, \"e\": [64, 128]}]}} {\"a\": {\"b\": 4, \"c\": []}}\n+\n+SELECT DISTINCT toTypeName(o) FROM t_json_10;\n+SELECT o FROM t_json_10 ORDER BY o.a.b FORMAT JSONEachRow;\n+SELECT o.a.b, o.a.c.d, o.a.c.e, o.a.c.f FROM t_json_10 ORDER BY o.a.b;\n+\n+DROP TABLE t_json_10;\ndiff --git a/tests/queries/0_stateless/01825_type_json_11.reference b/tests/queries/0_stateless/01825_type_json_11.reference\nnew file mode 100644\nindex 000000000000..27569620cd7c\n--- /dev/null\n+++ b/tests/queries/0_stateless/01825_type_json_11.reference\n@@ -0,0 +1,7 @@\n+Tuple(id Int8, key_1 Nested(key_2 Int32, key_3 Nested(key_4 Nested(key_5 Int8), key_7 Int16)))\n+{\"obj\":{\"id\":1,\"key_1\":[{\"key_2\":100,\"key_3\":[{\"key_4\":[{\"key_5\":-2}],\"key_7\":257}]},{\"key_2\":65536,\"key_3\":[]}]}}\n+{\"obj\":{\"id\":2,\"key_1\":[{\"key_2\":101,\"key_3\":[{\"key_4\":[{\"key_5\":-2}],\"key_7\":0}]},{\"key_2\":102,\"key_3\":[{\"key_4\":[],\"key_7\":257}]},{\"key_2\":65536,\"key_3\":[]}]}}\n+{\"obj.key_1.key_3\":[[{\"key_4\":[{\"key_5\":-2}],\"key_7\":257}],[]]}\n+{\"obj.key_1.key_3\":[[{\"key_4\":[{\"key_5\":-2}],\"key_7\":0}],[{\"key_4\":[],\"key_7\":257}],[]]}\n+[[[-2]],[]]\t[[257],[]]\n+[[[-2]],[[]],[]]\t[[0],[257],[]]\ndiff --git a/tests/queries/0_stateless/01825_type_json_11.sh b/tests/queries/0_stateless/01825_type_json_11.sh\nnew file mode 100755\nindex 000000000000..dbed15c8bb93\n--- /dev/null\n+++ b/tests/queries/0_stateless/01825_type_json_11.sh\n@@ -0,0 +1,61 @@\n+#!/usr/bin/env bash\n+# Tags: no-fasttest\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS t_json_11\"\n+\n+$CLICKHOUSE_CLIENT -q \"CREATE TABLE t_json_11 (obj JSON) ENGINE = MergeTree ORDER BY tuple()\" --allow_experimental_object_type 1\n+\n+cat <<EOF | $CLICKHOUSE_CLIENT -q \"INSERT INTO t_json_11 FORMAT JSONAsObject\"\n+{\n+    \"id\": 1,\n+    \"key_1\":[\n+        {\n+            \"key_2\":100,\n+            \"key_3\": [\n+                {\n+                    \"key_7\":257,\n+                    \"key_4\":[{\"key_5\":-2}]\n+                }\n+            ]\n+        },\n+        {\n+            \"key_2\":65536\n+        }\n+    ]\n+}\n+{\n+    \"id\": 2,\n+    \"key_1\":[\n+        {\n+          \"key_2\":101,\n+          \"key_3\": [\n+              {\n+                  \"key_4\":[{\"key_5\":-2}]\n+              }\n+          ]\n+        },\n+        {\n+            \"key_2\":102,\n+            \"key_3\": [\n+                {\n+                    \"key_7\":257\n+                }\n+            ]\n+        },\n+        {\n+            \"key_2\":65536\n+        }\n+    ]\n+}\n+EOF\n+\n+$CLICKHOUSE_CLIENT -q \"SELECT DISTINCT toTypeName(obj) FROM t_json_11;\"\n+$CLICKHOUSE_CLIENT -q \"SELECT obj FROM t_json_11 ORDER BY obj.id FORMAT JSONEachRow\" --output_format_json_named_tuples_as_objects 1\n+$CLICKHOUSE_CLIENT -q \"SELECT obj.key_1.key_3 FROM t_json_11 ORDER BY obj.id FORMAT JSONEachRow\" --output_format_json_named_tuples_as_objects 1\n+$CLICKHOUSE_CLIENT -q \"SELECT obj.key_1.key_3.key_4.key_5, obj.key_1.key_3.key_7 FROM t_json_11 ORDER BY obj.id\"\n+\n+$CLICKHOUSE_CLIENT -q \"DROP TABLE t_json_11;\"\ndiff --git a/tests/queries/0_stateless/01825_type_json_12.reference b/tests/queries/0_stateless/01825_type_json_12.reference\nnew file mode 100644\nindex 000000000000..7f4f5bf190ef\n--- /dev/null\n+++ b/tests/queries/0_stateless/01825_type_json_12.reference\n@@ -0,0 +1,3 @@\n+Tuple(id Int8, key_0 Nested(key_1 Nested(key_3 Nested(key_4 String, key_5 Float64, key_6 String, key_7 Float64))))\n+{\"obj\":{\"id\":1,\"key_0\":[{\"key_1\":[{\"key_3\":[{\"key_4\":\"1048576\",\"key_5\":0.0001048576,\"key_6\":\"25.5\",\"key_7\":1025},{\"key_4\":\"\",\"key_5\":0,\"key_6\":\"\",\"key_7\":2}]}]},{\"key_1\":[]},{\"key_1\":[{\"key_3\":[{\"key_4\":\"\",\"key_5\":-1,\"key_6\":\"aqbjfiruu\",\"key_7\":-922337203685477600},{\"key_4\":\"\",\"key_5\":0,\"key_6\":\"\",\"key_7\":65537}]},{\"key_3\":[{\"key_4\":\"ghdqyeiom\",\"key_5\":1048575,\"key_6\":\"\",\"key_7\":21474836.48}]}]}]}}\n+[[['1048576','']],[],[['',''],['ghdqyeiom']]]\t[[[0.0001048576,0]],[],[[-1,0],[1048575]]]\t[[['25.5','']],[],[['aqbjfiruu',''],['']]]\t[[[1025,2]],[],[[-922337203685477600,65537],[21474836.48]]]\ndiff --git a/tests/queries/0_stateless/01825_type_json_12.sh b/tests/queries/0_stateless/01825_type_json_12.sh\nnew file mode 100755\nindex 000000000000..2db3f1c55dc5\n--- /dev/null\n+++ b/tests/queries/0_stateless/01825_type_json_12.sh\n@@ -0,0 +1,51 @@\n+#!/usr/bin/env bash\n+# Tags: no-fasttest\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS t_json_12\"\n+\n+$CLICKHOUSE_CLIENT -q \"CREATE TABLE t_json_12 (obj JSON) ENGINE = MergeTree ORDER BY tuple()\" --allow_experimental_object_type 1\n+\n+cat <<EOF | $CLICKHOUSE_CLIENT -q \"INSERT INTO t_json_12 FORMAT JSONAsObject\"\n+{\n+    \"id\": 1,\n+    \"key_0\":[\n+        {\n+            \"key_1\":[\n+                {\n+                    \"key_3\":[\n+                        {\"key_7\":1025,\"key_6\":25.5,\"key_4\":1048576,\"key_5\":0.0001048576},\n+                        {\"key_7\":2,\"key_6\":\"\",\"key_4\":null}\n+                    ]\n+                }\n+            ]\n+        },\n+        {},\n+        {\n+            \"key_1\":[\n+                {\n+                    \"key_3\":[\n+                        {\"key_7\":-922337203685477580.8,\"key_6\":\"aqbjfiruu\",\"key_5\":-1},\n+                        {\"key_7\":65537,\"key_6\":\"\",\"key_4\":\"\"}\n+                    ]\n+                },\n+                {\n+                    \"key_3\":[\n+                        {\"key_7\":21474836.48,\"key_4\":\"ghdqyeiom\",\"key_5\":1048575}\n+                    ]\n+                }\n+            ]\n+        }\n+    ]\n+}\n+EOF\n+\n+$CLICKHOUSE_CLIENT -q \"SELECT DISTINCT toTypeName(obj) FROM t_json_12;\"\n+$CLICKHOUSE_CLIENT -q \"SELECT obj FROM t_json_12 ORDER BY obj.id FORMAT JSONEachRow\" --output_format_json_named_tuples_as_objects 1\n+$CLICKHOUSE_CLIENT -q \"SELECT obj.key_0.key_1.key_3.key_4, obj.key_0.key_1.key_3.key_5, \\\n+    obj.key_0.key_1.key_3.key_6, obj.key_0.key_1.key_3.key_7 FROM t_json_12 ORDER BY obj.id\"\n+\n+$CLICKHOUSE_CLIENT -q \"DROP TABLE t_json_12;\"\ndiff --git a/tests/queries/0_stateless/01825_type_json_13.reference b/tests/queries/0_stateless/01825_type_json_13.reference\nnew file mode 100644\nindex 000000000000..e420021f406d\n--- /dev/null\n+++ b/tests/queries/0_stateless/01825_type_json_13.reference\n@@ -0,0 +1,3 @@\n+Tuple(id Int8, key_1 Nested(key_2 Nested(key_3 Nested(key_4 Nested(key_5 Float64, key_6 Int64, key_7 Int32), key_8 Int32))))\n+{\"obj\":{\"id\":1,\"key_1\":[{\"key_2\":[{\"key_3\":[{\"key_4\":[],\"key_8\":65537},{\"key_4\":[{\"key_5\":-0.02,\"key_6\":\"0\",\"key_7\":0},{\"key_5\":0,\"key_6\":\"0\",\"key_7\":1023},{\"key_5\":0,\"key_6\":\"9223372036854775807\",\"key_7\":1}],\"key_8\":0},{\"key_4\":[{\"key_5\":0,\"key_6\":\"0\",\"key_7\":65537}],\"key_8\":0}]}]}]}}\n+[[[65537,0,0]]]\t[[[[],[-0.02,0,0],[0]]]]\t[[[[],[0,0,9223372036854775807],[0]]]]\t[[[[],[0,1023,1],[65537]]]]\ndiff --git a/tests/queries/0_stateless/01825_type_json_13.sh b/tests/queries/0_stateless/01825_type_json_13.sh\nnew file mode 100755\nindex 000000000000..17c36c547eee\n--- /dev/null\n+++ b/tests/queries/0_stateless/01825_type_json_13.sh\n@@ -0,0 +1,48 @@\n+#!/usr/bin/env bash\n+# Tags: no-fasttest\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS t_json_13\"\n+\n+$CLICKHOUSE_CLIENT -q \"CREATE TABLE t_json_13 (obj JSON) ENGINE = MergeTree ORDER BY tuple()\" --allow_experimental_object_type 1\n+\n+cat <<EOF | $CLICKHOUSE_CLIENT -q \"INSERT INTO t_json_13 FORMAT JSONAsObject\"\n+{\n+    \"id\": 1,\n+    \"key_1\":[\n+        {\n+            \"key_2\":[\n+                {\n+                    \"key_3\":[\n+                        {\"key_8\":65537},\n+                        {\n+                            \"key_4\":[\n+                                {\"key_5\":-0.02},\n+                                {\"key_7\":1023},\n+                                {\"key_7\":1,\"key_6\":9223372036854775807}\n+                            ]\n+                        },\n+                        {\n+                            \"key_4\":[{\"key_7\":65537,\"key_6\":null}]\n+                        }\n+                    ]\n+                }\n+            ]\n+        }\n+    ]\n+}\n+EOF\n+\n+$CLICKHOUSE_CLIENT -q \"SELECT DISTINCT toTypeName(obj) FROM t_json_13;\"\n+$CLICKHOUSE_CLIENT -q \"SELECT obj FROM t_json_13 ORDER BY obj.id FORMAT JSONEachRow\" --output_format_json_named_tuples_as_objects 1\n+$CLICKHOUSE_CLIENT -q \"SELECT \\\n+    obj.key_1.key_2.key_3.key_8, \\\n+    obj.key_1.key_2.key_3.key_4.key_5, \\\n+    obj.key_1.key_2.key_3.key_4.key_6, \\\n+    obj.key_1.key_2.key_3.key_4.key_7 \\\n+FROM t_json_13 ORDER BY obj.id\"\n+\n+$CLICKHOUSE_CLIENT -q \"DROP TABLE t_json_13;\"\n",
  "problem_statement": "Error in insert to the column of type `Object`\n**How to reproduce**\r\n\r\n```\r\nclickhouse-client -q \"create table t_json(obj JSON) engine = Memory\" --allow_experimental_object_type 1\r\n```\r\n\r\nCreate a file with the following data:\r\n\r\n```json\r\n{\r\n    \"key_1\":[\r\n        {\r\n            \"key_2\":100,\r\n            \"key_3\": [\r\n                {\r\n                    \"key_7\":257,\r\n                    \"key_4\":[{\"key_5\":-2}]\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"key_2\":65536\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\nThe insertion fails:\r\n```\r\ncat some.json | clickhouse-client -q \"insert into t_json format JSONAsObject\"\r\n\r\nReceived exception from server (version 22.4.1):\r\nCode: 49. DB::Exception: Received from localhost:9000. DB::Exception: offsets_column has data inconsistent with nested_column. (LOGICAL_ERROR)\r\n(query: insert into t_json format JSONAsObject)\r\n```\nInsert with JSONAsObject format fails with NUMBER_OF_DIMENSIONS_MISMATHED error\n**How to reproduce**\r\n\r\nIt works as expected:\r\n```\r\nclickhouse-client --allow_experimental_object_type 1 \\\r\n  -q \"create table json_1 (o JSON) ENGINE = MergeTree ORDER BY tuple()\"\r\n\r\ncat - <<EOF | clickhouse-client -q \"insert into json_1 format JSONAsObject\"  \r\n{\"a\": {\"b\": 1, \"c\": [{\"d\": 10, \"e\": [31]}, {\"d\": 20, \"e\": [63, 127]}]}}  \r\n{\"a\": {\"b\": 2, \"c\": []}}  \r\nEOF\r\n```\r\n\r\nRenaming the a.c.d field to a.c.f clickhouse-client fails:\r\n```\r\nclickhouse-client --allow_experimental_object_type 1 \\\r\n  -q \"create table json_2 (o JSON) ENGINE = MergeTree ORDER BY tuple()\"\r\n\r\ncat - <<EOF | clickhouse-client -q \"insert into json_2 format JSONAsObject\"\r\n{\"a\": {\"b\": 1, \"c\": [{\"f\": 10, \"e\": [31]}, {\"f\": 20, \"e\": [63, 127]}]}}\r\n{\"a\": {\"b\": 2, \"c\": []}}\r\nEOF\r\nCode: 645. DB::Exception: Dimension of types mismatched between inserted value and column. Dimension of value: 1. Dimension of column: 2: While executing ParallelParsingBlockInputFormat: data for INSERT was parsed from stdin: (in query: insert into json_test format JSONAsObject). (NUMBER_OF_DIMENSIONS_MISMATHED)\r\n```\r\n\r\nTested versions:\r\n22.3.2.1\r\n22.4.1.1\n",
  "hints_text": "\n",
  "created_at": "2022-04-08T15:02:23Z"
}