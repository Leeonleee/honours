{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 73654,
  "instance_id": "ClickHouse__ClickHouse-73654",
  "issue_numbers": [
    "68209"
  ],
  "base_commit": "3c15bb2f803d0dd1decac78975b86847fdadf933",
  "patch": "diff --git a/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp b/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp\nindex 65b5e3bfe7ba..e5b54c5f8955 100644\n--- a/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp\n+++ b/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp\n@@ -522,6 +522,17 @@ static ColumnPtr readOffsetsFromArrowListColumn(const std::shared_ptr<arrow::Chu\n     return offsets_column;\n }\n \n+static ColumnPtr readOffsetsFromFixedArrowListColumn(const std::shared_ptr<arrow::ChunkedArray> & arrow_column, int32_t length)\n+{\n+    auto offsets_column = ColumnUInt64::create();\n+    ColumnArray::Offsets & offsets_data = assert_cast<ColumnVector<UInt64> &>(*offsets_column).getData();\n+    int64_t size = arrow_column->length();\n+    offsets_data.reserve(size);\n+    for (int64_t i = 0; i < size; ++i)\n+        offsets_data.emplace_back((i + 1) * length);\n+    return offsets_column;\n+}\n+\n /*\n  * Arrow Dictionary and ClickHouse LowCardinality types are a bit different.\n  * Dictionary(Nullable(X)) in ArrowColumn format is composed of a nullmap, dictionary and an index.\n@@ -908,8 +919,29 @@ static ColumnWithTypeAndName readNonNullableColumnFromArrowColumn(\n         }\n         case arrow::Type::LIST:\n         case arrow::Type::LARGE_LIST:\n+        case arrow::Type::FIXED_SIZE_LIST:\n         {\n-            bool is_large_list = arrow_column->type()->id() == arrow::Type::LARGE_LIST;\n+            enum class ListType\n+            {\n+                List,\n+                LargeList,\n+                FixedSizeList\n+            };\n+            ListType list_type = [&]\n+            {\n+                switch (arrow_column->type()->id())\n+                {\n+                    case arrow::Type::LIST:\n+                        return ListType::List;\n+                    case arrow::Type::LARGE_LIST:\n+                        return ListType::LargeList;\n+                    case arrow::Type::FIXED_SIZE_LIST:\n+                        return ListType::FixedSizeList;\n+                    default:\n+                        throw Exception(ErrorCodes::INCORRECT_DATA, \"Unexpected list type: {}\", arrow_column->type()->name());\n+                }\n+            }();\n+\n             DataTypePtr nested_type_hint;\n             if (type_hint)\n             {\n@@ -918,19 +950,41 @@ static ColumnWithTypeAndName readNonNullableColumnFromArrowColumn(\n                     nested_type_hint = array_type_hint->getNestedType();\n             }\n \n-            bool is_nested_nullable_column = false;\n-            if (is_large_list)\n+            bool is_nested_nullable_column = [&]\n             {\n-                auto * arrow_large_list_type = assert_cast<arrow::LargeListType *>(arrow_column->type().get());\n-                is_nested_nullable_column = arrow_large_list_type->value_field()->nullable();\n-            }\n-            else\n+                switch (list_type)\n+                {\n+                    case ListType::LargeList:\n+                    {\n+                        auto * arrow_large_list_type = assert_cast<arrow::LargeListType *>(arrow_column->type().get());\n+                        return arrow_large_list_type->value_field()->nullable();\n+                    }\n+                    case ListType::FixedSizeList:\n+                    {\n+                        auto * arrow_fixed_size_list_type = assert_cast<arrow::FixedSizeListType *>(arrow_column->type().get());\n+                        return arrow_fixed_size_list_type->value_field()->nullable();\n+                    }\n+                    case ListType::List:\n+                    {\n+                        auto * arrow_list_type = assert_cast<arrow::ListType *>(arrow_column->type().get());\n+                        return arrow_list_type->value_field()->nullable();\n+                    }\n+                }\n+            }();\n+\n+            auto arrow_nested_column = [&]\n             {\n-                auto * arrow_list_type = assert_cast<arrow::ListType *>(arrow_column->type().get());\n-                is_nested_nullable_column = arrow_list_type->value_field()->nullable();\n-            }\n+                switch (list_type)\n+                {\n+                    case ListType::LargeList:\n+                        return getNestedArrowColumn<arrow::LargeListArray>(arrow_column);\n+                    case ListType::FixedSizeList:\n+                        return getNestedArrowColumn<arrow::FixedSizeListArray>(arrow_column);\n+                    case ListType::List:\n+                        return getNestedArrowColumn<arrow::ListArray>(arrow_column);\n+                }\n+            }();\n \n-            auto arrow_nested_column = is_large_list ? getNestedArrowColumn<arrow::LargeListArray>(arrow_column) : getNestedArrowColumn<arrow::ListArray>(arrow_column);\n             auto nested_column = readColumnFromArrowColumn(arrow_nested_column,\n                 column_name,\n                 dictionary_infos,\n@@ -941,7 +995,21 @@ static ColumnWithTypeAndName readNonNullableColumnFromArrowColumn(\n             if (!nested_column.column)\n                 return {};\n \n-            auto offsets_column = is_large_list ? readOffsetsFromArrowListColumn<arrow::LargeListArray>(arrow_column) : readOffsetsFromArrowListColumn<arrow::ListArray>(arrow_column);\n+            auto offsets_column = [&]\n+            {\n+                switch (list_type)\n+                {\n+                    case ListType::LargeList:\n+                        return readOffsetsFromArrowListColumn<arrow::LargeListArray>(arrow_column);\n+                    case ListType::FixedSizeList:\n+                    {\n+                        auto fixed_length = assert_cast<arrow::FixedSizeListType *>(arrow_column->type().get())->list_size();\n+                        return readOffsetsFromFixedArrowListColumn(arrow_column, fixed_length);\n+                    }\n+                    case ListType::List:\n+                        return readOffsetsFromArrowListColumn<arrow::ListArray>(arrow_column);\n+                }\n+            }();\n             auto array_column = ColumnArray::create(nested_column.column, offsets_column);\n \n             DataTypePtr array_type;\n@@ -1136,6 +1204,7 @@ static ColumnWithTypeAndName readColumnFromArrowColumn(\n     if (read_as_nullable_column &&\n         arrow_column->type()->id() != arrow::Type::LIST &&\n         arrow_column->type()->id() != arrow::Type::LARGE_LIST &&\n+        arrow_column->type()->id() != arrow::Type::FIXED_SIZE_LIST &&\n         arrow_column->type()->id() != arrow::Type::MAP &&\n         arrow_column->type()->id() != arrow::Type::STRUCT &&\n         arrow_column->type()->id() != arrow::Type::DICTIONARY)\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/00900_long_parquet_load.reference b/tests/queries/0_stateless/00900_long_parquet_load.reference\nindex 50631bfab592..2316afeb2e70 100644\n--- a/tests/queries/0_stateless/00900_long_parquet_load.reference\n+++ b/tests/queries/0_stateless/00900_long_parquet_load.reference\n@@ -142,6 +142,39 @@ abc\t5\t2\t1\t[1,2]\n 1552\n 1552\n 1552\n+=== Try load data from fixed_array_int.parquet\n+idx1\t[73,33,88,34,94,96,11,90,20,17]\n+idx10\t[10,15,52,43,22,50,42,87,19,91]\n+idx2\t[10,18,74,39,2,55,13,41,6,42]\n+idx3\t[48,27,74,82,70,46,18,78,63,73]\n+idx4\t[87,56,32,98,25,18,66,21,20,2]\n+idx5\t[67,84,56,84,50,21,93,90,37,42]\n+idx6\t[53,14,44,96,40,71,26,74,27,25]\n+idx7\t[46,1,21,11,83,74,11,63,28,49]\n+idx8\t[55,30,50,19,12,95,5,83,71,34]\n+idx9\t[90,53,83,54,35,87,73,74,98,50]\n+=== Try load data from fixed_array_nested_list_int.parquet\n+idx1\t[[34,11,56,20,90,20,17,55,54,99],[22,18,15,77,68,51,30,76,9,40],[67,24,2,27,72,53,99,57,67,96],[95,77,60,47,68,56,91,28,90,38],[77,8,75,89,84,81,60,82,71,26],[41,89,60,15,43,81,31,68,71,65],[84,97,22,9,26,59,97,10,16,60],[13,82,16,47,32,74,34,78,90,15],[35,44,50,18,82,71,20,68,89,41],[60,59,7,65,18,23,24,37,48,45]]\n+idx10\t[[10,72,13,85,89,15,51,73,64,49],[78,28,54,57,10,1,3,35,23,15],[97,93,76,87,86,21,30,9,58,21],[27,23,35,71,4,68,90,14,93,87],[59,98,66,94,8,90,16,20,33,10],[73,84,79,37,75,50,64,74,79,31],[20,64,79,51,20,41,7,69,5,22],[37,60,1,99,45,43,56,26,15,83],[7,96,6,58,7,59,57,6,22,92],[97,11,71,55,32,79,88,20,58,31]]\n+idx2\t[[72,32,17,44,69,37,95,64,47,70],[15,4,28,31,80,63,40,93,17,87],[28,46,56,21,65,20,5,76,18,61],[66,44,5,66,71,73,26,70,47,22],[9,9,62,21,74,75,32,71,2,61],[66,81,43,46,10,78,66,31,34,17],[30,5,10,15,56,52,36,3,88,16],[45,84,39,12,39,13,43,66,67,16],[27,18,68,80,87,19,98,39,90,54],[48,96,24,67,66,91,3,10,7,66]]\n+idx3\t[[54,93,69,82,45,54,35,59,20,39],[80,3,15,33,45,22,45,11,28,94],[68,26,89,38,49,28,29,59,93,57],[11,62,53,12,16,83,2,55,65,6],[37,49,56,93,33,77,22,53,20,22],[4,75,2,5,34,5,90,67,2,79],[22,2,80,14,13,44,33,11,31,24],[11,54,75,33,60,20,10,51,56,33],[72,5,84,78,7,95,21,2,88,75],[69,88,52,85,70,96,51,69,48,20]]\n+idx4\t[[65,58,31,62,38,29,32,71,87,49],[66,89,59,83,29,32,59,49,68,34],[81,54,14,69,39,84,95,37,15,47],[15,51,15,38,90,61,76,51,11,24],[64,93,27,26,29,15,15,4,95,36],[60,61,57,66,61,25,21,97,34,36],[7,34,30,4,8,29,68,48,58,64],[77,19,92,77,81,21,52,1,86,92],[16,91,1,40,57,44,76,10,78,10],[88,13,70,61,2,76,78,69,90,24]]\n+idx5\t[[52,98,63,41,2,6,56,80,72,15],[11,64,89,57,65,92,63,39,76,51],[47,25,33,28,58,22,83,19,54,63],[61,8,20,24,83,44,33,32,65,90],[51,75,72,55,54,5,43,90,64,30],[86,87,48,65,84,67,82,94,2,9],[1,75,83,79,64,63,52,51,33,72],[12,84,92,27,66,32,40,48,34,55],[59,91,19,77,70,56,10,82,40,60],[79,83,14,82,42,22,72,54,12,9]]\n+idx6\t[[71,60,6,31,40,66,78,6,23,14],[62,88,38,68,37,37,63,18,57,3],[45,93,1,49,99,33,10,91,6,17],[13,40,57,85,48,14,74,89,43,49],[18,17,39,75,52,30,48,4,13,55],[3,34,73,71,75,58,6,73,73,31],[28,74,26,3,2,49,50,60,27,79],[35,28,12,10,1,21,61,70,65,37],[30,27,51,85,89,84,73,48,4,71],[1,86,23,68,82,9,6,95,14,25]]\n+idx7\t[[58,24,79,16,32,36,36,91,18,22],[85,29,36,16,75,79,71,70,6,39],[47,15,82,30,55,14,49,47,38,13],[28,54,95,82,25,16,44,82,33,11],[58,16,87,96,65,3,10,68,87,15],[94,84,65,50,21,78,8,78,89,72],[39,41,67,23,21,83,43,94,31,15],[67,58,73,87,58,71,52,10,30,90],[69,65,72,89,51,8,39,80,49,79],[32,36,76,11,88,87,75,55,33,74]]\n+idx8\t[[8,26,45,3,25,83,88,77,98,38],[52,76,79,94,6,74,73,31,93,53],[89,24,62,83,35,24,60,24,41,14],[52,13,13,32,87,77,19,20,52,47],[50,46,66,30,26,85,91,50,98,83],[87,44,5,11,25,52,9,55,15,37],[18,24,36,72,84,10,13,59,16,65],[93,4,19,13,75,64,73,29,81,25],[61,65,1,45,75,88,19,4,73,32],[23,20,27,55,13,34,97,80,8,19]]\n+idx9\t[[32,6,44,30,66,48,93,67,62,16],[49,67,73,32,86,78,28,88,25,60],[70,10,95,16,10,49,12,47,22,62],[95,86,63,43,4,96,3,34,60,53],[60,75,96,66,96,82,62,31,78,72],[17,44,13,7,45,54,27,84,10,68],[43,49,86,10,57,99,32,72,73,41],[57,79,15,62,79,87,67,69,75,59],[45,18,2,19,45,96,8,86,71,97],[20,20,11,15,82,29,16,12,87,87]]\n+=== Try load data from fixed_array_str.parquet\n+idx1\t['str10','str11','str12','str13','str14','str15','str16','str17','str18','str19']\n+idx10\t['str100','str101','str102','str103','str104','str105','str106','str107','str108','str109']\n+idx2\t['str20','str21','str22','str23','str24','str25','str26','str27','str28','str29']\n+idx3\t['str30','str31','str32','str33','str34','str35','str36','str37','str38','str39']\n+idx4\t['str40','str41','str42','str43','str44','str45','str46','str47','str48','str49']\n+idx5\t['str50','str51','str52','str53','str54','str55','str56','str57','str58','str59']\n+idx6\t['str60','str61','str62','str63','str64','str65','str66','str67','str68','str69']\n+idx7\t['str70','str71','str72','str73','str74','str75','str76','str77','str78','str79']\n+idx8\t['str80','str81','str82','str83','str84','str85','str86','str87','str88','str89']\n+idx9\t['str90','str91','str92','str93','str94','str95','str96','str97','str98','str99']\n === Try load data from fixed_length_decimal.parquet\n 1\n 2\ndiff --git a/tests/queries/0_stateless/data_parquet/fixed_array_int.parquet b/tests/queries/0_stateless/data_parquet/fixed_array_int.parquet\nnew file mode 100644\nindex 000000000000..835b05bbf56e\nBinary files /dev/null and b/tests/queries/0_stateless/data_parquet/fixed_array_int.parquet differ\ndiff --git a/tests/queries/0_stateless/data_parquet/fixed_array_int.parquet.columns b/tests/queries/0_stateless/data_parquet/fixed_array_int.parquet.columns\nnew file mode 100644\nindex 000000000000..2c383e8343f8\n--- /dev/null\n+++ b/tests/queries/0_stateless/data_parquet/fixed_array_int.parquet.columns\n@@ -0,0 +1,1 @@\n+`idx` String, `lst` Array(Int64)\n\\ No newline at end of file\ndiff --git a/tests/queries/0_stateless/data_parquet/fixed_array_nested_list_int.parquet b/tests/queries/0_stateless/data_parquet/fixed_array_nested_list_int.parquet\nnew file mode 100644\nindex 000000000000..8317f1d5d564\nBinary files /dev/null and b/tests/queries/0_stateless/data_parquet/fixed_array_nested_list_int.parquet differ\ndiff --git a/tests/queries/0_stateless/data_parquet/fixed_array_nested_list_int.parquet.columns b/tests/queries/0_stateless/data_parquet/fixed_array_nested_list_int.parquet.columns\nnew file mode 100644\nindex 000000000000..3e1c9533a324\n--- /dev/null\n+++ b/tests/queries/0_stateless/data_parquet/fixed_array_nested_list_int.parquet.columns\n@@ -0,0 +1,1 @@\n+`idx` String, `lst` Array(Array(Int64))\n\\ No newline at end of file\ndiff --git a/tests/queries/0_stateless/data_parquet/fixed_array_str.parquet b/tests/queries/0_stateless/data_parquet/fixed_array_str.parquet\nnew file mode 100644\nindex 000000000000..2a6bec05799a\nBinary files /dev/null and b/tests/queries/0_stateless/data_parquet/fixed_array_str.parquet differ\ndiff --git a/tests/queries/0_stateless/data_parquet/fixed_array_str.parquet.columns b/tests/queries/0_stateless/data_parquet/fixed_array_str.parquet.columns\nnew file mode 100644\nindex 000000000000..67a7b6bc04d5\n--- /dev/null\n+++ b/tests/queries/0_stateless/data_parquet/fixed_array_str.parquet.columns\n@@ -0,0 +1,1 @@\n+`idx` String, `lst` Array(String)\n\\ No newline at end of file\n",
  "problem_statement": "Support arrow::parquet fixed_size_list\n**Use case**\r\n\r\nI have a data processing pipeline that generates embeddings (fixed size arrays of floats) and stores them as parquet files. I want to read those parquet files and find closest matches with [cosine similarity](https://clickhouse.com/docs/knowledgebase/vector-search#3-search-for-related-embeddings).\r\n\r\nMy embedding generation pipeline currently generates data frames with [FixedSizeListArray arrow columns](https://arrow.apache.org/docs/python/generated/pyarrow.FixedSizeListArray.html), which when written as a parquet file cannot be read by ClickHouse.\r\n\r\nThe same data written with a [ListArray arrow column](https://arrow.apache.org/docs/python/generated/pyarrow.ListArray.html), the variable length list type, can be read by ClickHouse.\r\n\r\nSee \"Additional context\" (below) for repro.\r\n\r\n**Describe the solution you'd like**\r\n\r\nBoth FixedSizeListArray and ListArray are stored the same way in parquet, namely as a parquet list; they only differ in the additional parquet metadata the arrow library adds. Insofar as ClickHouse support for [parquet](https://clickhouse.com/docs/en/sql-reference/formats#data-types-matching-parquet) is about the parquet file format and not how arrow works, I would expect either parquet file to be readable by ClickHouse.\r\n\r\nOf course, I understand that ClickHouse uses the arrow library under the hood and the eventual in-memory arrow layout of ListArray and FixedSizeListArray are different.\r\n\r\nPossibly relevant:\r\n- Arrow's [fixed size list layout](https://arrow.apache.org/docs/format/Columnar.html#fixed-size-list-layout) is probably analogous to ClickHouse's FixedString, and\r\n- there is [current work](https://issues.apache.org/jira/browse/PARQUET-2474) by the arrow/parquet projects to substantially improve parquet's fixed size list support to better support machine learning workloads.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nFor now, I can write embeddings as variable length lists, but given the roadmap for fixed size lists in the arrow/parquet ecosystem, it would be nice to know what the ClickHouse project's roadmap is on more directly supporting this datatype.\r\n\r\n**Additional context**\r\n\r\nGenerating a fixed size list array:\r\n\r\n```python\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\n\r\n# FixedSizeListArray\r\ntyp = pa.list_(pa.field(\"values\", pa.int64()), 2)\r\nvalues = pa.array([1, 2, 3, 4])\r\ntbl = pa.Table.from_arrays([pa.FixedSizeListArray.from_arrays(values, type=typ)], names=[\"values\"])\r\n\r\npq.write_table(tbl, \"tbl.parquet\")\r\n```\r\n\r\nand then reading it with `clickhouse local` fails:\r\n\r\n```shell\r\n$ clickhouse local -q \"SELECT * FROM file('tbl.parquet')\"\r\nCode: 50. DB::Exception: Unsupported Parquet type 'fixed_size_list' of an input column 'values'. If it happens during schema inference and you want to skip columns with unsupported types, you can enable setting input_format_parquet_skip_columns_with_unsupported_types_in_schema_inference: (in file/uri /tmp/tbl.parquet): While executing ParquetBlockInputFormat: While executing File. (UNKNOWN_TYPE)\r\n```\r\n\r\nwhile generating a variable length list array\r\n\r\n```python\r\n# ListArray (variable length lists)\r\ntyp = pa.list_(pa.field(\"values\", pa.int64()))\r\noffsets = pa.array([0, 2])\r\ntbl = pa.Table.from_arrays([pa.ListArray.from_arrays(offsets, values, type=typ)], names=[\"values\"])\r\n```\r\n\r\nsucceeds\r\n\r\n```shell\r\n$ clickhouse local -q \"SELECT * FROM file('tbl.parquet')\"\r\n[1,2]\r\n```\r\n\r\nFrom a parquet perspective, both FixedSizeListArray and ListArray arrow columns are written as parquet lists. I.e., `pq.read_metadata.schema` returns the same thing for both:\r\n\r\n```\r\n> pq.read_metadata(\"tbl.parquet\").schema\r\nparquet schema: <pyarrow._parquet.ParquetSchema object at 0x107e11800>\r\nrequired group field_id=-1 schema {\r\n  optional group field_id=-1 values (List) {\r\n    repeated group field_id=-1 list {\r\n      optional int64 field_id=-1 element;\r\n    }\r\n  }\r\n}\r\n> pq.read_metadata(\"tbl.parquet\").metadata\r\n{b'ARROW:schema': b'[...]'}\r\n```\r\n\r\nThe only difference is the additional parquet metadata encoding the desired arrow schema.\r\n\n",
  "hints_text": "",
  "created_at": "2024-12-20T02:29:16Z"
}