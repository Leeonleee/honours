{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 74085,
  "instance_id": "ClickHouse__ClickHouse-74085",
  "issue_numbers": [
    "66878"
  ],
  "base_commit": "f2ca30902beb4eb7700c0fc722a0789566a0b968",
  "patch": "diff --git a/src/Analyzer/Resolve/QueryAnalyzer.cpp b/src/Analyzer/Resolve/QueryAnalyzer.cpp\nindex 58841d27477d..940b1c646978 100644\n--- a/src/Analyzer/Resolve/QueryAnalyzer.cpp\n+++ b/src/Analyzer/Resolve/QueryAnalyzer.cpp\n@@ -3507,7 +3507,8 @@ ProjectionNames QueryAnalyzer::resolveFunction(QueryTreeNodePtr & node, Identifi\n             SizeLimits size_limits_for_set = {settings[Setting::max_rows_in_set], settings[Setting::max_bytes_in_set], settings[Setting::set_overflow_mode]};\n \n             auto hash = function_arguments[1]->getTreeHash();\n-            auto future_set = std::make_shared<FutureSetFromTuple>(hash, std::move(result_block), settings[Setting::transform_null_in], size_limits_for_set);\n+            auto ast = function_arguments[1]->toAST();\n+            auto future_set = std::make_shared<FutureSetFromTuple>(hash, std::move(ast), std::move(result_block), settings[Setting::transform_null_in], size_limits_for_set);\n \n             /// Create constant set column for constant folding\n \ndiff --git a/src/Core/Settings.cpp b/src/Core/Settings.cpp\nindex 2904781bf07f..b482d2efa021 100644\n--- a/src/Core/Settings.cpp\n+++ b/src/Core/Settings.cpp\n@@ -2919,6 +2919,9 @@ Allow push predicate to final subquery.\n )\", 0) \\\n     DECLARE(Bool, allow_push_predicate_when_subquery_contains_with, true, R\"(\n Allows push predicate when subquery contains WITH clause\n+)\", 0) \\\n+    DECLARE(Bool, allow_push_predicate_ast_for_distributed_subqueries, true, R\"(\n+Allows push predicate on AST level for distributed subqueries with enabled anlyzer\n )\", 0) \\\n     \\\n     DECLARE(UInt64, low_cardinality_max_dictionary_size, 8192, R\"(\ndiff --git a/src/Core/SettingsChangesHistory.cpp b/src/Core/SettingsChangesHistory.cpp\nindex 51b261ffeb57..cf2949d60fa9 100644\n--- a/src/Core/SettingsChangesHistory.cpp\n+++ b/src/Core/SettingsChangesHistory.cpp\n@@ -85,6 +85,7 @@ const VersionToSettingsChangesMap & getSettingsChangesHistory()\n             {\"output_format_orc_writer_time_zone_name\", \"GMT\", \"GMT\", \"The time zone name for ORC writer, the default ORC writer's time zone is GMT.\"},\n             {\"output_format_pretty_highlight_trailing_spaces\", false, true, \"A new setting.\"},\n             {\"allow_experimental_bfloat16_type\", false, true, \"Add new BFloat16 type\"},\n+            {\"allow_push_predicate_ast_for_distributed_subqueries\", false, true, \"A new setting\"},\n             {\"output_format_pretty_squash_consecutive_ms\", 0, 50, \"Add new setting\"},\n             {\"output_format_pretty_squash_max_wait_ms\", 0, 1000, \"Add new setting\"},\n             {\"output_format_pretty_max_column_name_width_cut_to\", 0, 24, \"A new setting\"},\ndiff --git a/src/Interpreters/ActionsVisitor.cpp b/src/Interpreters/ActionsVisitor.cpp\nindex c83e619f001e..6f44af9b62ec 100644\n--- a/src/Interpreters/ActionsVisitor.cpp\n+++ b/src/Interpreters/ActionsVisitor.cpp\n@@ -484,7 +484,7 @@ FutureSetPtr makeExplicitSet(\n     else\n         block = createBlockForSet(left_arg_type, right_arg, set_element_types, context);\n \n-    return prepared_sets.addFromTuple(set_key, std::move(block), context->getSettingsRef());\n+    return prepared_sets.addFromTuple(set_key, right_arg_func, std::move(block), context->getSettingsRef());\n }\n \n class ScopeStack::Index\n@@ -1490,7 +1490,7 @@ FutureSetPtr ActionsMatcher::makeSet(const ASTFunction & node, Data & data, bool\n                     return set;\n \n                 if (StorageSet * storage_set = dynamic_cast<StorageSet *>(table.get()))\n-                    return data.prepared_sets->addFromStorage(set_key, storage_set->getSet(), table_id);\n+                    return data.prepared_sets->addFromStorage(set_key, right_in_operand, storage_set->getSet(), table_id);\n             }\n \n             if (!data.getContext()->isGlobalContext())\n@@ -1520,7 +1520,7 @@ FutureSetPtr ActionsMatcher::makeSet(const ASTFunction & node, Data & data, bool\n         }\n \n         return data.prepared_sets->addFromSubquery(\n-            set_key, std::move(source), nullptr, std::move(external_table_set), data.getContext()->getSettingsRef());\n+            set_key, right_in_operand, std::move(source), nullptr, std::move(external_table_set), data.getContext()->getSettingsRef());\n     }\n \n     const auto & last_actions = data.actions_stack.getLastActions();\ndiff --git a/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp b/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp\nindex 237a652269c0..e902d921a9a6 100644\n--- a/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp\n+++ b/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp\n@@ -172,14 +172,16 @@ void SelectStreamFactory::createForShardImpl(\n     auto emplace_remote_stream = [&](bool lazy = false, time_t local_delay = 0)\n     {\n         Block shard_header;\n+        PlannerContextPtr planner_context;\n         if (context->getSettingsRef()[Setting::allow_experimental_analyzer])\n-            shard_header = InterpreterSelectQueryAnalyzer::getSampleBlock(query_tree, context, SelectQueryOptions(processed_stage).analyze());\n+            std::tie(shard_header, planner_context) = InterpreterSelectQueryAnalyzer::getSampleBlockAndPlannerContext(query_tree, context, SelectQueryOptions(processed_stage).analyze());\n         else\n             shard_header = header;\n \n         remote_shards.emplace_back(Shard{\n             .query = query_ast,\n             .query_tree = query_tree,\n+            .planner_context = planner_context,\n             .main_table = main_table,\n             .header = shard_header,\n             .has_missing_objects = has_missing_objects,\ndiff --git a/src/Interpreters/ClusterProxy/SelectStreamFactory.h b/src/Interpreters/ClusterProxy/SelectStreamFactory.h\nindex 2e7b2445c6bb..1ad73a97de07 100644\n--- a/src/Interpreters/ClusterProxy/SelectStreamFactory.h\n+++ b/src/Interpreters/ClusterProxy/SelectStreamFactory.h\n@@ -28,6 +28,10 @@ struct StorageID;\n \n class PreparedSets;\n using PreparedSetsPtr = std::shared_ptr<PreparedSets>;\n+\n+class PlannerContext;\n+using PlannerContextPtr = std::shared_ptr<PlannerContext>;\n+\n namespace ClusterProxy\n {\n \n@@ -52,6 +56,7 @@ class SelectStreamFactory\n         /// Query and header may be changed depending on shard.\n         ASTPtr query;\n         QueryTreeNodePtr query_tree;\n+        PlannerContextPtr planner_context;\n \n         /// Used to check the table existence on remote node\n         StorageID main_table;\ndiff --git a/src/Interpreters/GlobalSubqueriesVisitor.h b/src/Interpreters/GlobalSubqueriesVisitor.h\nindex bfbc6152b380..cbf3f77373a4 100644\n--- a/src/Interpreters/GlobalSubqueriesVisitor.h\n+++ b/src/Interpreters/GlobalSubqueriesVisitor.h\n@@ -179,7 +179,7 @@ class GlobalSubqueriesMatcher\n                 std::unique_ptr<QueryPlan> source = std::make_unique<QueryPlan>();\n                 interpreter->buildQueryPlan(*source);\n \n-                auto future_set = prepared_sets->addFromSubquery(set_key, std::move(source), std::move(external_storage), nullptr, getContext()->getSettingsRef());\n+                auto future_set = prepared_sets->addFromSubquery(set_key, ast, std::move(source), std::move(external_storage), nullptr, getContext()->getSettingsRef());\n                 external_storage_holder->future_set = std::move(future_set);\n             }\n             else\ndiff --git a/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp b/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp\nindex 412cf55775c7..ef753502139e 100644\n--- a/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp\n+++ b/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp\n@@ -206,7 +206,7 @@ Block InterpreterSelectQueryAnalyzer::getSampleBlock(const ASTPtr & query,\n     return interpreter.getSampleBlock();\n }\n \n-Block InterpreterSelectQueryAnalyzer::getSampleBlock(const QueryTreeNodePtr & query_tree,\n+std::pair<Block, PlannerContextPtr> InterpreterSelectQueryAnalyzer::getSampleBlockAndPlannerContext(const QueryTreeNodePtr & query_tree,\n     const ContextPtr & context,\n     const SelectQueryOptions & select_query_options)\n {\n@@ -214,7 +214,14 @@ Block InterpreterSelectQueryAnalyzer::getSampleBlock(const QueryTreeNodePtr & qu\n     select_query_options_copy.only_analyze = true;\n     InterpreterSelectQueryAnalyzer interpreter(query_tree, context, select_query_options_copy);\n \n-    return interpreter.getSampleBlock();\n+    return interpreter.getSampleBlockAndPlannerContext();\n+}\n+\n+Block InterpreterSelectQueryAnalyzer::getSampleBlock(const QueryTreeNodePtr & query_tree,\n+    const ContextPtr & context,\n+    const SelectQueryOptions & select_query_options)\n+{\n+    return getSampleBlockAndPlannerContext(query_tree, context, select_query_options).first;\n }\n \n Block InterpreterSelectQueryAnalyzer::getSampleBlock()\n@@ -223,6 +230,12 @@ Block InterpreterSelectQueryAnalyzer::getSampleBlock()\n     return planner.getQueryPlan().getCurrentHeader();\n }\n \n+std::pair<Block, PlannerContextPtr> InterpreterSelectQueryAnalyzer::getSampleBlockAndPlannerContext()\n+{\n+    planner.buildQueryPlanIfNeeded();\n+    return {planner.getQueryPlan().getCurrentHeader(), planner.getPlannerContext()};\n+}\n+\n BlockIO InterpreterSelectQueryAnalyzer::execute()\n {\n     auto pipeline_builder = buildQueryPipeline();\ndiff --git a/src/Interpreters/InterpreterSelectQueryAnalyzer.h b/src/Interpreters/InterpreterSelectQueryAnalyzer.h\nindex 73c524cbe282..7e3f0ed121da 100644\n--- a/src/Interpreters/InterpreterSelectQueryAnalyzer.h\n+++ b/src/Interpreters/InterpreterSelectQueryAnalyzer.h\n@@ -42,6 +42,7 @@ class InterpreterSelectQueryAnalyzer : public IInterpreter\n     }\n \n     Block getSampleBlock();\n+    std::pair<Block, PlannerContextPtr> getSampleBlockAndPlannerContext();\n \n     static Block getSampleBlock(const ASTPtr & query,\n         const ContextPtr & context,\n@@ -51,6 +52,10 @@ class InterpreterSelectQueryAnalyzer : public IInterpreter\n         const ContextPtr & context_,\n         const SelectQueryOptions & select_query_options = {});\n \n+    static std::pair<Block, PlannerContextPtr> getSampleBlockAndPlannerContext(const QueryTreeNodePtr & query_tree,\n+        const ContextPtr & context_,\n+        const SelectQueryOptions & select_query_options = {});\n+\n     BlockIO execute() override;\n \n     QueryPlan & getQueryPlan();\ndiff --git a/src/Interpreters/PredicateRewriteVisitor.h b/src/Interpreters/PredicateRewriteVisitor.h\nindex d2b9ece9306a..0bfae8aa560e 100644\n--- a/src/Interpreters/PredicateRewriteVisitor.h\n+++ b/src/Interpreters/PredicateRewriteVisitor.h\n@@ -32,6 +32,8 @@ class PredicateRewriteVisitorData : WithContext\n         bool optimize_final_,\n         bool optimize_with_);\n \n+    bool rewriteSubquery(ASTSelectQuery & subquery, const Names & inner_columns);\n+\n private:\n     const ASTs & predicates;\n     const TableWithColumnNamesAndTypes & table_columns;\n@@ -44,8 +46,6 @@ class PredicateRewriteVisitorData : WithContext\n \n     void visit(ASTSelectIntersectExceptQuery & intersect_except_query, ASTPtr &);\n \n-    bool rewriteSubquery(ASTSelectQuery & subquery, const Names & inner_columns);\n-\n     void visitInternalSelect(size_t index, ASTSelectQuery & select_node, ASTPtr & node);\n };\n \ndiff --git a/src/Interpreters/PreparedSets.cpp b/src/Interpreters/PreparedSets.cpp\nindex 7642c642169c..b465558dfa3b 100644\n--- a/src/Interpreters/PreparedSets.cpp\n+++ b/src/Interpreters/PreparedSets.cpp\n@@ -59,8 +59,8 @@ static bool equals(const DataTypes & lhs, const DataTypes & rhs)\n }\n \n \n-FutureSetFromStorage::FutureSetFromStorage(Hash hash_, SetPtr set_, std::optional<StorageID> storage_id_)\n-    : hash(hash_), storage_id(std::move(storage_id_)), set(std::move(set_)) {}\n+FutureSetFromStorage::FutureSetFromStorage(Hash hash_, ASTPtr ast_, SetPtr set_, std::optional<StorageID> storage_id_)\n+    : hash(hash_), ast(std::move(ast_)), storage_id(std::move(storage_id_)), set(std::move(set_)) {}\n SetPtr FutureSetFromStorage::get() const { return set; }\n FutureSet::Hash FutureSetFromStorage::getHash() const { return hash; }\n DataTypes FutureSetFromStorage::getTypes() const { return set->getElementsTypes(); }\n@@ -72,9 +72,9 @@ SetPtr FutureSetFromStorage::buildOrderedSetInplace(const ContextPtr &)\n \n \n FutureSetFromTuple::FutureSetFromTuple(\n-    Hash hash_, ColumnsWithTypeAndName block,\n+    Hash hash_, ASTPtr ast_, ColumnsWithTypeAndName block,\n     bool transform_null_in, SizeLimits size_limits)\n-    : hash(hash_)\n+    : hash(hash_), ast(std::move(ast_))\n {\n     ColumnsWithTypeAndName header = block;\n     for (auto & elem : header)\n@@ -138,13 +138,14 @@ SetPtr FutureSetFromTuple::buildOrderedSetInplace(const ContextPtr & context)\n \n FutureSetFromSubquery::FutureSetFromSubquery(\n     Hash hash_,\n+    ASTPtr ast_,\n     std::unique_ptr<QueryPlan> source_,\n     StoragePtr external_table_,\n     std::shared_ptr<FutureSetFromSubquery> external_table_set_,\n     bool transform_null_in,\n     SizeLimits size_limits,\n     size_t max_size_for_index)\n-    : hash(hash_), external_table(std::move(external_table_)), external_table_set(std::move(external_table_set_)), source(std::move(source_))\n+    : hash(hash_), ast(std::move(ast_)), external_table(std::move(external_table_)), external_table_set(std::move(external_table_set_)), source(std::move(source_))\n {\n     set_and_key = std::make_shared<SetAndKey>();\n     set_and_key->key = PreparedSets::toString(hash_, {});\n@@ -155,11 +156,12 @@ FutureSetFromSubquery::FutureSetFromSubquery(\n \n FutureSetFromSubquery::FutureSetFromSubquery(\n     Hash hash_,\n+    ASTPtr ast_,\n     QueryTreeNodePtr query_tree_,\n     bool transform_null_in,\n     SizeLimits size_limits,\n     size_t max_size_for_index)\n-    : hash(hash_), query_tree(std::move(query_tree_))\n+    : hash(hash_), ast(std::move(ast_)), query_tree(std::move(query_tree_))\n {\n     set_and_key = std::make_shared<SetAndKey>();\n     set_and_key->key = PreparedSets::toString(hash_, {});\n@@ -182,6 +184,8 @@ void FutureSetFromSubquery::setQueryPlan(std::unique_ptr<QueryPlan> source_)\n     set_and_key->set->setHeader(source->getCurrentHeader().getColumnsWithTypeAndName());\n }\n \n+void FutureSetFromSubquery::setExternalTable(StoragePtr external_table_) { external_table = std::move(external_table_); }\n+\n DataTypes FutureSetFromSubquery::getTypes() const\n {\n     return set_and_key->set->getElementsTypes();\n@@ -297,11 +301,11 @@ String PreparedSets::toString(const PreparedSets::Hash & key, const DataTypes &\n     return buf.str();\n }\n \n-FutureSetFromTuplePtr PreparedSets::addFromTuple(const Hash & key, ColumnsWithTypeAndName block, const Settings & settings)\n+FutureSetFromTuplePtr PreparedSets::addFromTuple(const Hash & key, ASTPtr ast, ColumnsWithTypeAndName block, const Settings & settings)\n {\n     auto size_limits = getSizeLimitsForSet(settings);\n     auto from_tuple = std::make_shared<FutureSetFromTuple>(\n-        key, std::move(block),\n+        key, std::move(ast), std::move(block),\n         settings[Setting::transform_null_in], size_limits);\n \n     const auto & set_types = from_tuple->getTypes();\n@@ -315,9 +319,9 @@ FutureSetFromTuplePtr PreparedSets::addFromTuple(const Hash & key, ColumnsWithTy\n     return from_tuple;\n }\n \n-FutureSetFromStoragePtr PreparedSets::addFromStorage(const Hash & key, SetPtr set_, StorageID storage_id)\n+FutureSetFromStoragePtr PreparedSets::addFromStorage(const Hash & key, ASTPtr ast, SetPtr set_, StorageID storage_id)\n {\n-    auto from_storage = std::make_shared<FutureSetFromStorage>(key, std::move(set_), std::move(storage_id));\n+    auto from_storage = std::make_shared<FutureSetFromStorage>(key, std::move(ast), std::move(set_), std::move(storage_id));\n     auto [it, inserted] = sets_from_storage.emplace(key, from_storage);\n \n     if (!inserted)\n@@ -328,6 +332,7 @@ FutureSetFromStoragePtr PreparedSets::addFromStorage(const Hash & key, SetPtr se\n \n FutureSetFromSubqueryPtr PreparedSets::addFromSubquery(\n     const Hash & key,\n+    ASTPtr ast,\n     std::unique_ptr<QueryPlan> source,\n     StoragePtr external_table,\n     FutureSetFromSubqueryPtr external_table_set,\n@@ -335,7 +340,7 @@ FutureSetFromSubqueryPtr PreparedSets::addFromSubquery(\n {\n     auto size_limits = getSizeLimitsForSet(settings);\n     auto from_subquery = std::make_shared<FutureSetFromSubquery>(\n-        key, std::move(source), std::move(external_table), std::move(external_table_set),\n+        key, std::move(ast), std::move(source), std::move(external_table), std::move(external_table_set),\n         settings[Setting::transform_null_in], size_limits, settings[Setting::use_index_for_in_with_subqueries_max_values]);\n \n     auto [it, inserted] = sets_from_subqueries.emplace(key, from_subquery);\n@@ -348,12 +353,13 @@ FutureSetFromSubqueryPtr PreparedSets::addFromSubquery(\n \n FutureSetFromSubqueryPtr PreparedSets::addFromSubquery(\n     const Hash & key,\n+    ASTPtr ast,\n     QueryTreeNodePtr query_tree,\n     const Settings & settings)\n {\n     auto size_limits = getSizeLimitsForSet(settings);\n     auto from_subquery = std::make_shared<FutureSetFromSubquery>(\n-        key, std::move(query_tree),\n+        key, std::move(ast), std::move(query_tree),\n         settings[Setting::transform_null_in], size_limits, settings[Setting::use_index_for_in_with_subqueries_max_values]);\n \n     auto [it, inserted] = sets_from_subqueries.emplace(key, from_subquery);\ndiff --git a/src/Interpreters/PreparedSets.h b/src/Interpreters/PreparedSets.h\nindex 1e973d5ae8b4..2899aa81f1a0 100644\n--- a/src/Interpreters/PreparedSets.h\n+++ b/src/Interpreters/PreparedSets.h\n@@ -56,6 +56,8 @@ class FutureSet\n \n     using Hash = CityHash_v1_0_2::uint128;\n     virtual Hash getHash() const = 0;\n+\n+    virtual ASTPtr getSourceAST() const = 0;\n };\n \n using FutureSetPtr = std::shared_ptr<FutureSet>;\n@@ -65,16 +67,18 @@ using FutureSetPtr = std::shared_ptr<FutureSet>;\n class FutureSetFromStorage final : public FutureSet\n {\n public:\n-    explicit FutureSetFromStorage(Hash hash_, SetPtr set_, std::optional<StorageID> storage_id);\n+    explicit FutureSetFromStorage(Hash hash_, ASTPtr ast_, SetPtr set_, std::optional<StorageID> storage_id);\n \n     SetPtr get() const override;\n     DataTypes getTypes() const override;\n     SetPtr buildOrderedSetInplace(const ContextPtr &) override;\n     Hash getHash() const override;\n+    ASTPtr getSourceAST() const override { return ast; }\n \n     const std::optional<StorageID> & getStorageID() const { return storage_id; }\n private:\n     Hash hash;\n+    ASTPtr ast;\n     std::optional<StorageID> storage_id;\n     SetPtr set;\n };\n@@ -86,16 +90,18 @@ using FutureSetFromStoragePtr = std::shared_ptr<FutureSetFromStorage>;\n class FutureSetFromTuple final : public FutureSet\n {\n public:\n-    FutureSetFromTuple(Hash hash_, ColumnsWithTypeAndName block, bool transform_null_in, SizeLimits size_limits);\n+    FutureSetFromTuple(Hash hash_, ASTPtr ast_, ColumnsWithTypeAndName block, bool transform_null_in, SizeLimits size_limits);\n \n     SetPtr get() const override { return set; }\n     SetPtr buildOrderedSetInplace(const ContextPtr & context) override;\n \n     DataTypes getTypes() const override;\n     Hash getHash() const override;\n+    ASTPtr getSourceAST() const override { return ast; }\n     Columns getKeyColumns();\n private:\n     Hash hash;\n+    ASTPtr ast;\n     SetPtr set;\n     SetKeyColumns set_key_columns;\n };\n@@ -119,6 +125,7 @@ class FutureSetFromSubquery final : public FutureSet\n public:\n     FutureSetFromSubquery(\n         Hash hash_,\n+        ASTPtr ast_,\n         std::unique_ptr<QueryPlan> source_,\n         StoragePtr external_table_,\n         std::shared_ptr<FutureSetFromSubquery> external_table_set_,\n@@ -128,6 +135,7 @@ class FutureSetFromSubquery final : public FutureSet\n \n     FutureSetFromSubquery(\n         Hash hash_,\n+        ASTPtr ast_,\n         QueryTreeNodePtr query_tree_,\n         bool transform_null_in,\n         SizeLimits size_limits,\n@@ -138,6 +146,7 @@ class FutureSetFromSubquery final : public FutureSet\n     SetPtr get() const override;\n     DataTypes getTypes() const override;\n     Hash getHash() const override;\n+    ASTPtr getSourceAST() const override { return ast; }\n     SetPtr buildOrderedSetInplace(const ContextPtr & context) override;\n \n     std::unique_ptr<QueryPlan> build(const ContextPtr & context);\n@@ -145,12 +154,14 @@ class FutureSetFromSubquery final : public FutureSet\n \n     QueryTreeNodePtr detachQueryTree() { return std::move(query_tree); }\n     void setQueryPlan(std::unique_ptr<QueryPlan> source_);\n+    void setExternalTable(StoragePtr external_table_);\n \n     const QueryPlan * getQueryPlan() const { return source.get(); }\n     QueryPlan * getQueryPlan() { return source.get(); }\n \n private:\n     Hash hash;\n+    ASTPtr ast;\n     SetAndKeyPtr set_and_key;\n     StoragePtr external_table;\n     std::shared_ptr<FutureSetFromSubquery> external_table_set;\n@@ -176,11 +187,12 @@ class PreparedSets\n     using SetsFromStorage = std::unordered_map<Hash, FutureSetFromStoragePtr, Hashing>;\n     using SetsFromSubqueries = std::unordered_map<Hash, FutureSetFromSubqueryPtr, Hashing>;\n \n-    FutureSetFromStoragePtr addFromStorage(const Hash & key, SetPtr set_, StorageID storage_id);\n-    FutureSetFromTuplePtr addFromTuple(const Hash & key, ColumnsWithTypeAndName block, const Settings & settings);\n+    FutureSetFromStoragePtr addFromStorage(const Hash & key, ASTPtr ast, SetPtr set_, StorageID storage_id);\n+    FutureSetFromTuplePtr addFromTuple(const Hash & key, ASTPtr ast, ColumnsWithTypeAndName block, const Settings & settings);\n \n     FutureSetFromSubqueryPtr addFromSubquery(\n         const Hash & key,\n+        ASTPtr ast,\n         std::unique_ptr<QueryPlan> source,\n         StoragePtr external_table,\n         FutureSetFromSubqueryPtr external_table_set,\n@@ -188,6 +200,7 @@ class PreparedSets\n \n     FutureSetFromSubqueryPtr addFromSubquery(\n         const Hash & key,\n+        ASTPtr ast,\n         QueryTreeNodePtr query_tree,\n         const Settings & settings);\n \ndiff --git a/src/Planner/CollectSets.cpp b/src/Planner/CollectSets.cpp\nindex 4308c69523bc..39ec930845f0 100644\n--- a/src/Planner/CollectSets.cpp\n+++ b/src/Planner/CollectSets.cpp\n@@ -69,8 +69,8 @@ class CollectSetsVisitor : public ConstInDepthQueryTreeVisitor<CollectSetsVisito\n             auto set_key = in_second_argument->getTreeHash();\n             if (sets.findStorage(set_key))\n                 return;\n-\n-            sets.addFromStorage(set_key, storage_set->getSet(), second_argument_table->getStorageID());\n+            auto ast = in_second_argument->toAST();\n+            sets.addFromStorage(set_key, std::move(ast), storage_set->getSet(), second_argument_table->getStorageID());\n         }\n         else if (const auto * constant_node = in_second_argument->as<ConstantNode>())\n         {\n@@ -92,7 +92,8 @@ class CollectSetsVisitor : public ConstInDepthQueryTreeVisitor<CollectSetsVisito\n             if (sets.findTuple(set_key, set_element_types))\n                 return;\n \n-            sets.addFromTuple(set_key, std::move(set), settings);\n+            auto ast = in_second_argument->toAST();\n+            sets.addFromTuple(set_key, std::move(ast), std::move(set), settings);\n         }\n         else if (in_second_argument_node_type == QueryTreeNodeType::QUERY ||\n             in_second_argument_node_type == QueryTreeNodeType::UNION ||\n@@ -106,7 +107,8 @@ class CollectSetsVisitor : public ConstInDepthQueryTreeVisitor<CollectSetsVisito\n             if (in_second_argument->as<TableNode>())\n                 subquery_to_execute = buildSubqueryToReadColumnsFromTableExpression(subquery_to_execute, planner_context.getQueryContext());\n \n-            sets.addFromSubquery(set_key, std::move(subquery_to_execute), settings);\n+            auto ast = in_second_argument->toAST();\n+            sets.addFromSubquery(set_key, std::move(ast), std::move(subquery_to_execute), settings);\n         }\n         else\n         {\ndiff --git a/src/Processors/QueryPlan/Optimizations/optimizePrimaryKeyConditionAndLimit.cpp b/src/Processors/QueryPlan/Optimizations/optimizePrimaryKeyConditionAndLimit.cpp\nindex 490b79fbf8d3..ce36c7bddb43 100644\n--- a/src/Processors/QueryPlan/Optimizations/optimizePrimaryKeyConditionAndLimit.cpp\n+++ b/src/Processors/QueryPlan/Optimizations/optimizePrimaryKeyConditionAndLimit.cpp\n@@ -11,7 +11,7 @@ void optimizePrimaryKeyConditionAndLimit(const Stack & stack)\n {\n     const auto & frame = stack.back();\n \n-    auto * source_step_with_filter = dynamic_cast<SourceStepWithFilter *>(frame.node->step.get());\n+    auto * source_step_with_filter = dynamic_cast<SourceStepWithFilterBase *>(frame.node->step.get());\n     if (!source_step_with_filter)\n         return;\n \ndiff --git a/src/Processors/QueryPlan/ReadFromRemote.cpp b/src/Processors/QueryPlan/ReadFromRemote.cpp\nindex 28bf865a7b79..ba10ee8ab34c 100644\n--- a/src/Processors/QueryPlan/ReadFromRemote.cpp\n+++ b/src/Processors/QueryPlan/ReadFromRemote.cpp\n@@ -1,5 +1,8 @@\n #include <Processors/QueryPlan/ReadFromRemote.h>\n \n+#include <Analyzer/QueryNode.h>\n+#include <Analyzer/Utils.h>\n+#include <Planner/PlannerActionsVisitor.h>\n #include <DataTypes/DataTypesNumber.h>\n #include <DataTypes/DataTypeString.h>\n #include <Processors/QueryPlan/QueryPlan.h>\n@@ -8,7 +11,10 @@\n #include <Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h>\n #include <QueryPipeline/RemoteQueryExecutor.h>\n #include <Parsers/ASTSelectQuery.h>\n+#include <Parsers/ASTSelectWithUnionQuery.h>\n #include <Parsers/ASTExplainQuery.h>\n+#include <Parsers/ASTFunction.h>\n+#include <Parsers/ASTIdentifier.h>\n #include <Parsers/formatAST.h>\n #include <Processors/Sources/RemoteSource.h>\n #include <Processors/Sources/DelayedSource.h>\n@@ -16,6 +22,13 @@\n #include <Processors/Transforms/MaterializingTransform.h>\n #include <Processors/Executors/PullingPipelineExecutor.h>\n #include <Interpreters/ActionsDAG.h>\n+#include <Interpreters/PredicateRewriteVisitor.h>\n+#include <Interpreters/JoinedTables.h>\n+#include <Interpreters/PreparedSets.h>\n+#include <Interpreters/DatabaseCatalog.h>\n+#include <Interpreters/InterpreterSelectQueryAnalyzer.h>\n+#include <Columns/ColumnConst.h>\n+#include <Columns/ColumnSet.h>\n #include <Columns/ColumnString.h>\n #include <Common/logger_useful.h>\n #include <Common/checkStackSize.h>\n@@ -23,8 +36,9 @@\n #include <Core/Settings.h>\n #include <Client/ConnectionPool.h>\n #include <Client/ConnectionPoolWithFailover.h>\n+#include <Functions/IFunction.h>\n+#include <Functions/FunctionsMiscellaneous.h>\n #include <QueryPipeline/QueryPipelineBuilder.h>\n-#include <Parsers/ASTFunction.h>\n \n #include <fmt/format.h>\n \n@@ -39,6 +53,9 @@ namespace Setting\n     extern const SettingsSeconds max_execution_time;\n     extern const SettingsNonZeroUInt64 max_parallel_replicas;\n     extern const SettingsUInt64 parallel_replicas_mark_segment_size;\n+    extern const SettingsBool allow_push_predicate_when_subquery_contains_with;\n+    extern const SettingsBool enable_optimize_predicate_expression_to_final_subquery;\n+    extern const SettingsBool allow_push_predicate_ast_for_distributed_subqueries;\n }\n \n namespace ErrorCodes\n@@ -125,7 +142,7 @@ ReadFromRemote::ReadFromRemote(\n     UInt32 shard_count_,\n     std::shared_ptr<const StorageLimitsList> storage_limits_,\n     const String & cluster_name_)\n-    : ISourceStep(std::move(header_))\n+    : SourceStepWithFilterBase(std::move(header_))\n     , shards(std::move(shards_))\n     , stage(stage_)\n     , main_table(std::move(main_table_))\n@@ -151,6 +168,251 @@ void ReadFromRemote::enforceAggregationInOrder()\n     DB::enforceAggregationInOrder(stage, *context);\n }\n \n+ASTSelectQuery & getSelectQuery(ASTPtr ast)\n+{\n+    if (const auto * explain = ast->as<ASTExplainQuery>())\n+        ast = explain->getExplainedQuery();\n+\n+    return ast->as<ASTSelectQuery &>();\n+}\n+\n+/// This is an attempt to convert filters (pushed down from the plan optimizations) from ActionsDAG back to AST.\n+/// It should not be needed after we send a full plan for distributed queries.\n+static ASTPtr tryBuildAdditionalFilterAST(\n+    const ActionsDAG & dag,\n+    const std::unordered_set<std::string> & projection_names,\n+    const std::unordered_map<std::string, QueryTreeNodePtr> & execution_name_to_projection_query_tree,\n+    Tables * external_tables,\n+    const ContextPtr & context)\n+{\n+    std::unordered_map<const ActionsDAG::Node *, ASTPtr> node_to_ast;\n+\n+    struct Frame\n+    {\n+        const ActionsDAG::Node * node;\n+        size_t next_child = 0;\n+    };\n+    std::stack<Frame> stack;\n+    stack.push({dag.getOutputs().front()});\n+    while (!stack.empty())\n+    {\n+        auto & frame = stack.top();\n+        const auto * node = frame.node;\n+\n+        if (node_to_ast.contains(node))\n+        {\n+            stack.pop();\n+            continue;\n+        }\n+\n+        /// Labmdas are not supported (converting back to AST is complicated).\n+        /// We have two cases here cause function with no capture can be constant-folded.\n+        if (WhichDataType(node->result_type).isFunction()\n+            || (node->type == ActionsDAG::ActionType::FUNCTION\n+                && typeid_cast<const FunctionCapture *>(node->function_base.get())))\n+        {\n+            node_to_ast[node] = nullptr;\n+            stack.pop();\n+            continue;\n+        }\n+\n+        /// Support for IN. The stored AST from the Set is taken.\n+        if (WhichDataType(node->result_type).isSet())\n+        {\n+            auto maybe_set = node->column;\n+            if (const auto * col_const = typeid_cast<const ColumnConst *>(maybe_set.get()))\n+                maybe_set = col_const->getDataColumnPtr();\n+\n+            if (const auto * col_set = typeid_cast<const ColumnSet *>(maybe_set.get()))\n+                node_to_ast[node] = col_set->getData()->getSourceAST();\n+\n+            stack.pop();\n+            continue;\n+        }\n+\n+        if (node->column && isColumnConst(*node->column))\n+        {\n+            auto literal = std::make_shared<ASTLiteral>((*node->column)[0]);\n+            node_to_ast[node] = std::move(literal);\n+            stack.pop();\n+            continue;\n+        }\n+\n+        if (frame.next_child < node->children.size())\n+        {\n+            stack.push({node->children[frame.next_child]});\n+            ++frame.next_child;\n+            continue;\n+        }\n+\n+        stack.pop();\n+        auto & res = node_to_ast[node];\n+\n+        if (node->type == ActionsDAG::ActionType::INPUT)\n+        {\n+            /// The column name can be taken from the projection name, or from the projection expression.\n+            /// It depends on the predicate and query stage.\n+\n+            if (projection_names.contains(node->result_name))\n+            {\n+                /// The input name matches the projection name. Example:\n+                /// SELECT x FROM (SELECT number + 1 AS x FROM remote('127.0.0.2', numbers(3))) WHERE x = 1\n+                /// In this case, ReadFromRemote has header `x UInt64` and filter DAG has input column with name `x`.\n+                /// Here, filter is applied to the whole query, and checking for projection name is reasonable.\n+                res = std::make_shared<ASTIdentifier>(node->result_name);\n+            }\n+            else\n+            {\n+                /// The input name matches the execution name of the projection. Example:\n+                /// SELECT x, y FROM (\n+                ///     SELECT number + 1 AS x, sum(number) AS y FROM remote('127.0.0.{1,2}', numbers(3)) GROUP BY x\n+                /// ) WHERE x = 1\n+                /// In this case, ReadFromRemote has `plus(__table1.number, 1_UInt8) UInt64` in header,\n+                /// and filter DAG has input column with name `plus(__table1.number, 1_UInt8)`.\n+                /// Here, filter is pushed down before the aggregation, and projection name can't be used.\n+                /// However, we can match the input with the execution name of projection query tree.\n+                /// Note: this may not cover all the cases.\n+                auto it = execution_name_to_projection_query_tree.find(node->result_name);\n+                if (it != execution_name_to_projection_query_tree.end())\n+                    /// Append full expression as an AST.\n+                    /// We rely on plan optimization that the result is (expected to be) valid.\n+                    res = it->second->toAST();\n+            }\n+        }\n+\n+        if (node->type == ActionsDAG::ActionType::ALIAS)\n+            res = node_to_ast[node->children.at(0)];\n+\n+        if (node->type != ActionsDAG::ActionType::FUNCTION)\n+            continue;\n+\n+        if (!node->function_base->isDeterministic() || node->function_base->isStateful())\n+            continue;\n+\n+        bool has_all_args = true;\n+        ASTs arguments;\n+        for (const auto * child : node->children)\n+        {\n+            auto ast = node_to_ast[child];\n+            if (!ast)\n+                has_all_args = false;\n+            else\n+                arguments.push_back(std::move(ast));\n+        }\n+\n+        /// Allow to skip children only for AND function.\n+        auto func_name = node->function_base->getName();\n+        bool is_function_and = func_name == \"and\";\n+        if (!has_all_args && !is_function_and)\n+            continue;\n+\n+        if (is_function_and && arguments.empty())\n+            continue;\n+\n+        /// and() with 1 arg is not allowed. Make it AND(condition, 1)\n+        if (is_function_and && arguments.size() == 1)\n+            arguments.push_back(std::make_shared<ASTLiteral>(Field(1)));\n+\n+        /// Support for GLOBAL IN.\n+        if (external_tables && isNameOfGlobalInFunction(func_name))\n+        {\n+            const auto * second_arg = node->children.at(1);\n+            auto maybe_set = second_arg->column;\n+            if (const auto * col_const = typeid_cast<const ColumnConst *>(maybe_set.get()))\n+                maybe_set = col_const->getDataColumnPtr();\n+\n+            if (const auto * col_set = typeid_cast<const ColumnSet *>(maybe_set.get()))\n+            {\n+                auto future_set = col_set->getData();\n+                if (auto * set_from_subquery = typeid_cast<FutureSetFromSubquery *>(future_set.get()))\n+                {\n+                    const auto temporary_table_name = fmt::format(\"_data_{}\", toString(set_from_subquery->getHash()));\n+\n+                    auto & external_table = (*external_tables)[temporary_table_name];\n+                    if (!external_table)\n+                    {\n+                        /// Here we create a new temporary table and attach it to the FutureSetFromSubquery.\n+                        /// At the moment FutureSet is created, temporary table will be filled.\n+                        /// This should happen because filter expression on initiator needs the set as well,\n+                        /// and it should be built before sending the external tables.\n+\n+                        auto header = InterpreterSelectQueryAnalyzer::getSampleBlock(set_from_subquery->getSourceAST(), context);\n+                        NamesAndTypesList columns = header.getNamesAndTypesList();\n+\n+                        auto external_storage_holder = TemporaryTableHolder(\n+                            context,\n+                            ColumnsDescription{columns},\n+                            ConstraintsDescription{},\n+                            nullptr /*query*/,\n+                            true /*create_for_global_subquery*/);\n+\n+                        external_table = external_storage_holder.getTable();\n+                        set_from_subquery->setExternalTable(external_table);\n+                    }\n+\n+                    node_to_ast[second_arg] = std::make_shared<ASTIdentifier>(temporary_table_name);\n+                }\n+            }\n+        }\n+\n+        auto function = makeASTFunction(node->function_base->getName(), std::move(arguments));\n+        res = std::move(function);\n+    }\n+\n+    return node_to_ast[dag.getOutputs().front()];\n+}\n+\n+static void addFilters(\n+    Tables * external_tables,\n+    const ContextMutablePtr & context,\n+    const ASTPtr & query_ast,\n+    const QueryTreeNodePtr & query_tree,\n+    const PlannerContextPtr & planner_context,\n+    const ActionsDAG & pushed_down_filters)\n+{\n+    if (!query_tree || !planner_context)\n+        return;\n+\n+    const auto & settings = context->getSettingsRef();\n+    if (!settings[Setting::allow_push_predicate_ast_for_distributed_subqueries])\n+        return;\n+\n+    const auto * query_node = query_tree->as<QueryNode>();\n+    if (!query_node)\n+        return;\n+\n+    /// We are building a set with projection names and a map with execution names here.\n+    /// They are needed to substitute inputs in ActionsDAG. See comment in tryBuildAdditionalFilterAST.\n+\n+    std::unordered_set<std::string> projection_names;\n+    for (const auto & col : query_node->getProjectionColumns())\n+        projection_names.insert(col.name);\n+\n+    std::unordered_map<std::string, QueryTreeNodePtr> execution_name_to_projection_query_tree;\n+    for (const auto & node : query_node->getProjection())\n+        execution_name_to_projection_query_tree[calculateActionNodeName(node, *planner_context)] = node;\n+\n+    ASTPtr predicate = tryBuildAdditionalFilterAST(pushed_down_filters, projection_names, execution_name_to_projection_query_tree, external_tables, context);\n+    if (!predicate)\n+        return;\n+\n+    JoinedTables joined_tables(context, getSelectQuery(query_ast), false, false);\n+    joined_tables.resolveTables();\n+    const auto & tables_with_columns = joined_tables.tablesWithColumns();\n+\n+    /// Case with JOIN is not supported so far.\n+    if (tables_with_columns.size() != 1)\n+        return;\n+\n+    bool optimize_final = settings[Setting::enable_optimize_predicate_expression_to_final_subquery];\n+    bool optimize_with = settings[Setting::allow_push_predicate_when_subquery_contains_with];\n+\n+    ASTs predicates{predicate};\n+    PredicateRewriteVisitor::Data data(context, predicates, tables_with_columns.front(), optimize_final, optimize_with);\n+\n+    data.rewriteSubquery(getSelectQuery(query_ast), tables_with_columns.front().columns.getNames());\n+}\n+\n void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::SelectStreamFactory::Shard & shard, const Header & out_header)\n {\n     bool add_agg_info = stage == QueryProcessingStage::WithMergeableState;\n@@ -166,13 +428,19 @@ void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::SelectStream\n         add_extremes = context->getSettingsRef()[Setting::extremes];\n     }\n \n+    std::shared_ptr<const ActionsDAG> pushed_down_filters;\n+    if (filter_actions_dag)\n+        pushed_down_filters = std::make_shared<const ActionsDAG>(filter_actions_dag->clone());\n+\n     auto lazily_create_stream = [\n             my_shard = shard, my_shard_count = shard_count, query = shard.query, header = shard.header,\n             my_context = context, my_throttler = throttler,\n             my_main_table = main_table, my_table_func_ptr = table_func_ptr,\n             my_scalars = scalars, my_external_tables = external_tables,\n             my_stage = stage, local_delay = shard.local_delay,\n-            add_agg_info, add_totals, add_extremes, async_read, async_query_sending]() mutable\n+            add_agg_info, add_totals, add_extremes, async_read, async_query_sending,\n+            query_tree = shard.query_tree, planner_context = shard.planner_context,\n+            pushed_down_filters]() mutable\n         -> QueryPipelineBuilder\n     {\n         auto current_settings = my_context->getSettingsRef();\n@@ -218,6 +486,12 @@ void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::SelectStream\n         for (auto & try_result : try_results)\n             connections.emplace_back(std::move(try_result.entry));\n \n+        /// For the lazy case we are ignoring external tables.\n+        /// This is because the set could be build before the lambda call,\n+        /// and the temporary table which we are about to send would be empty.\n+        /// So that GLOBAL IN would work as local IN in the pushed-down predicate.\n+        if (pushed_down_filters)\n+            addFilters(nullptr, my_context, query, query_tree, planner_context, *pushed_down_filters);\n         String query_string = formattedAST(query);\n \n         my_scalars[\"_shard_num\"] = Block{\n@@ -235,14 +509,6 @@ void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::SelectStream\n     addConvertingActions(pipes.back(), out_header, shard.has_missing_objects);\n }\n \n-ASTSelectQuery & getSelectQuery(ASTPtr ast)\n-{\n-    if (const auto * explain = ast->as<ASTExplainQuery>())\n-        ast = explain->getExplainedQuery();\n-\n-    return ast->as<ASTSelectQuery &>();\n-}\n-\n void ReadFromRemote::addPipe(Pipes & pipes, const ClusterProxy::SelectStreamFactory::Shard & shard, const Header & out_header)\n {\n     bool add_agg_info = stage == QueryProcessingStage::WithMergeableState;\n@@ -327,6 +593,9 @@ void ReadFromRemote::addPipe(Pipes & pipes, const ClusterProxy::SelectStreamFact\n     }\n     else\n     {\n+        if (filter_actions_dag)\n+            addFilters(&external_tables, context, shard.query, shard.query_tree, shard.planner_context, *filter_actions_dag);\n+\n         const String query_string = formattedAST(shard.query);\n \n         auto remote_query_executor = std::make_shared<RemoteQueryExecutor>(\ndiff --git a/src/Processors/QueryPlan/ReadFromRemote.h b/src/Processors/QueryPlan/ReadFromRemote.h\nindex 65d6b48c97f3..035a4bcb81af 100644\n--- a/src/Processors/QueryPlan/ReadFromRemote.h\n+++ b/src/Processors/QueryPlan/ReadFromRemote.h\n@@ -1,5 +1,5 @@\n #pragma once\n-#include <Processors/QueryPlan/ISourceStep.h>\n+#include <Processors/QueryPlan/SourceStepWithFilter.h>\n #include <Core/QueryProcessingStage.h>\n #include <Client/IConnections.h>\n #include <Storages/IStorage_fwd.h>\n@@ -17,7 +17,7 @@ using ParallelReplicasReadingCoordinatorPtr = std::shared_ptr<ParallelReplicasRe\n \n /// Reading step from remote servers.\n /// Unite query results from several shards.\n-class ReadFromRemote final : public ISourceStep\n+class ReadFromRemote final : public SourceStepWithFilterBase\n {\n public:\n     /// @param main_table_ if Shards contains main_table then this parameter will be ignored\ndiff --git a/src/Processors/QueryPlan/SetsSerialization.cpp b/src/Processors/QueryPlan/SetsSerialization.cpp\nindex 87939522b952..3a3e83c718d0 100644\n--- a/src/Processors/QueryPlan/SetsSerialization.cpp\n+++ b/src/Processors/QueryPlan/SetsSerialization.cpp\n@@ -208,7 +208,7 @@ static void makeSetsFromStorage(std::list<QueryPlanAndSets::SetFromStorage> sets\n         if (!storage_set)\n             throw Exception(ErrorCodes::INCORRECT_DATA, \"Table {} is not a StorageSet\", set.storage_name);\n \n-        auto future_set = std::make_shared<FutureSetFromStorage>(set.hash, storage_set->getSet(), table_node->getStorageID());\n+        auto future_set = std::make_shared<FutureSetFromStorage>(set.hash, nullptr, storage_set->getSet(), table_node->getStorageID());\n         for (auto * column : set.columns)\n             column->setData(future_set);\n     }\n@@ -222,7 +222,7 @@ static void makeSetsFromTuple(std::list<QueryPlanAndSets::SetFromTuple> sets, co\n         SizeLimits size_limits = PreparedSets::getSizeLimitsForSet(settings);\n         bool transform_null_in = settings[Setting::transform_null_in];\n \n-        auto future_set = std::make_shared<FutureSetFromTuple>(set.hash, std::move(set.set_columns), transform_null_in, size_limits);\n+        auto future_set = std::make_shared<FutureSetFromTuple>(set.hash, nullptr, std::move(set.set_columns), transform_null_in, size_limits);\n         for (auto * column : set.columns)\n             column->setData(future_set);\n     }\n@@ -246,7 +246,7 @@ static void makeSetsFromSubqueries(QueryPlan & plan, std::list<QueryPlanAndSets:\n         size_t max_size_for_index = settings[Setting::use_index_for_in_with_subqueries_max_values];\n \n         auto future_set = std::make_shared<FutureSetFromSubquery>(\n-            set.hash, std::make_unique<QueryPlan>(std::move(subquery_plan)),\n+            set.hash, nullptr, std::make_unique<QueryPlan>(std::move(subquery_plan)),\n             nullptr, nullptr,\n             transform_null_in, size_limits, max_size_for_index);\n \ndiff --git a/src/Processors/QueryPlan/SourceStepWithFilter.cpp b/src/Processors/QueryPlan/SourceStepWithFilter.cpp\nindex f55d5ccddce3..ad4b54dc260c 100644\n--- a/src/Processors/QueryPlan/SourceStepWithFilter.cpp\n+++ b/src/Processors/QueryPlan/SourceStepWithFilter.cpp\n@@ -77,6 +77,11 @@ Block SourceStepWithFilter::applyPrewhereActions(Block block, const PrewhereInfo\n     return block;\n }\n \n+void SourceStepWithFilterBase::applyFilters(ActionDAGNodes added_filter_nodes)\n+{\n+    filter_actions_dag = ActionsDAG::buildFilterActionsDAG(added_filter_nodes.nodes, {});\n+}\n+\n void SourceStepWithFilter::applyFilters(ActionDAGNodes added_filter_nodes)\n {\n     filter_actions_dag = ActionsDAG::buildFilterActionsDAG(added_filter_nodes.nodes, query_info.buildNodeNameToInputNodeColumn());\ndiff --git a/src/Processors/QueryPlan/SourceStepWithFilter.h b/src/Processors/QueryPlan/SourceStepWithFilter.h\nindex a650cdc3211e..4718ad78947f 100644\n--- a/src/Processors/QueryPlan/SourceStepWithFilter.h\n+++ b/src/Processors/QueryPlan/SourceStepWithFilter.h\n@@ -8,43 +8,17 @@\n namespace DB\n {\n \n-/** Source step that can use filters and limit for more efficient pipeline initialization.\n-  * Filters must be added before pipeline initialization.\n-  * Limit must be set before pipeline initialization.\n-  */\n-class SourceStepWithFilter : public ISourceStep\n+class SourceStepWithFilterBase : public ISourceStep\n {\n public:\n     using Base = ISourceStep;\n     using Base::Base;\n \n-    SourceStepWithFilter(\n-        Header output_header_,\n-        const Names & column_names_,\n-        const SelectQueryInfo & query_info_,\n-        const StorageSnapshotPtr & storage_snapshot_,\n-        const ContextPtr & context_)\n+    explicit SourceStepWithFilterBase(Header output_header_)\n         : ISourceStep(std::move(output_header_))\n-        , required_source_columns(column_names_)\n-        , query_info(query_info_)\n-        , prewhere_info(query_info.prewhere_info)\n-        , storage_snapshot(storage_snapshot_)\n-        , context(context_)\n     {\n     }\n \n-    const std::optional<ActionsDAG> & getFilterActionsDAG() const { return filter_actions_dag; }\n-    std::optional<ActionsDAG> detachFilterActionsDAG() { return std::move(filter_actions_dag); }\n-\n-    const SelectQueryInfo & getQueryInfo() const { return query_info; }\n-    const PrewhereInfoPtr & getPrewhereInfo() const { return prewhere_info; }\n-    ContextPtr getContext() const { return context; }\n-    const StorageSnapshotPtr & getStorageSnapshot() const { return storage_snapshot; }\n-\n-    bool isQueryWithFinal() const { return query_info.isFinal(); }\n-\n-    const Names & requiredSourceColumns() const { return required_source_columns; }\n-\n     void addFilter(ActionsDAG filter_dag, std::string column_name)\n     {\n         filter_nodes.nodes.push_back(&filter_dag.findInOutputs(column_name));\n@@ -67,6 +41,56 @@ class SourceStepWithFilter : public ISourceStep\n     }\n \n     virtual void applyFilters(ActionDAGNodes added_filter_nodes);\n+    virtual PrewhereInfoPtr getPrewhereInfo() const { return nullptr; }\n+\n+    const std::optional<ActionsDAG> & getFilterActionsDAG() const { return filter_actions_dag; }\n+    std::optional<ActionsDAG> detachFilterActionsDAG() { return std::move(filter_actions_dag); }\n+\n+private:\n+    /// Will be cleared after applyFilters() is called.\n+    ActionDAGNodes filter_nodes;\n+    std::vector<ActionsDAG> filter_dags;\n+\n+protected:\n+    std::optional<size_t> limit;\n+    std::optional<ActionsDAG> filter_actions_dag;\n+};\n+\n+/** Source step that can use filters and limit for more efficient pipeline initialization.\n+  * Filters must be added before pipeline initialization.\n+  * Limit must be set before pipeline initialization.\n+  */\n+class SourceStepWithFilter : public SourceStepWithFilterBase\n+{\n+public:\n+    using Base = SourceStepWithFilterBase;\n+    using Base::Base;\n+\n+    SourceStepWithFilter(\n+        Header output_header_,\n+        const Names & column_names_,\n+        const SelectQueryInfo & query_info_,\n+        const StorageSnapshotPtr & storage_snapshot_,\n+        const ContextPtr & context_)\n+        : SourceStepWithFilterBase(std::move(output_header_))\n+        , required_source_columns(column_names_)\n+        , query_info(query_info_)\n+        , prewhere_info(query_info.prewhere_info)\n+        , storage_snapshot(storage_snapshot_)\n+        , context(context_)\n+    {\n+    }\n+\n+    const SelectQueryInfo & getQueryInfo() const { return query_info; }\n+    PrewhereInfoPtr getPrewhereInfo() const override { return prewhere_info; }\n+    ContextPtr getContext() const { return context; }\n+    const StorageSnapshotPtr & getStorageSnapshot() const { return storage_snapshot; }\n+\n+    bool isQueryWithFinal() const { return query_info.isFinal(); }\n+\n+    const Names & requiredSourceColumns() const { return required_source_columns; }\n+\n+    void applyFilters(ActionDAGNodes added_filter_nodes) override;\n \n     virtual void updatePrewhereInfo(const PrewhereInfoPtr & prewhere_info_value);\n \n@@ -82,14 +106,6 @@ class SourceStepWithFilter : public ISourceStep\n     PrewhereInfoPtr prewhere_info;\n     StorageSnapshotPtr storage_snapshot;\n     ContextPtr context;\n-    std::optional<size_t> limit;\n-\n-    std::optional<ActionsDAG> filter_actions_dag;\n-\n-private:\n-    /// Will be cleared after applyFilters() is called.\n-    ActionDAGNodes filter_nodes;\n-    std::vector<ActionsDAG> filter_dags;\n };\n \n }\ndiff --git a/utils/check-style/experimental_settings_ignore.txt b/utils/check-style/experimental_settings_ignore.txt\nindex 0bd9f5bc4f4d..2502cdfff4ac 100644\n--- a/utils/check-style/experimental_settings_ignore.txt\n+++ b/utils/check-style/experimental_settings_ignore.txt\n@@ -45,6 +45,7 @@ allow_nondeterministic_optimize_skip_unused_shards\n allow_prefetched_read_pool_for_local_filesystem\n allow_prefetched_read_pool_for_remote_filesystem\n allow_push_predicate_when_subquery_contains_with\n+allow_push_predicate_ast_for_distributed_subqueries\n allow_settings_after_format_in_insert\n allow_statistic_optimize\n allow_statistics_optimize\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03302_analyzer_distributed_filter_push_down.reference b/tests/queries/0_stateless/03302_analyzer_distributed_filter_push_down.reference\nnew file mode 100644\nindex 000000000000..3e336d7aac53\n--- /dev/null\n+++ b/tests/queries/0_stateless/03302_analyzer_distributed_filter_push_down.reference\n@@ -0,0 +1,575 @@\n+============ #66878\n+Union\n+  Expression ((Project names + Projection))\n+  Actions: INPUT : 0 -> __table1.x UInt32 : 0\n+           INPUT : 1 -> __table1.y UInt32 : 1\n+           ALIAS __table1.x :: 0 -> x UInt32 : 2\n+           ALIAS __table1.y :: 1 -> y UInt32 : 0\n+  Positions: 2 0\n+    Expression\n+    Actions: INPUT : 1 -> y UInt32 : 0\n+             INPUT : 0 -> x UInt32 : 1\n+             ALIAS y :: 0 -> __table1.y UInt32 : 2\n+             ALIAS x :: 1 -> __table1.x UInt32 : 0\n+             ALIAS __table1.y :: 2 -> y UInt32 : 1\n+             ALIAS __table1.x :: 0 -> x UInt32 : 2\n+             ALIAS y :: 1 -> __table1.y UInt32 : 0\n+             ALIAS x :: 2 -> __table1.x UInt32 : 1\n+    Positions: 1 0\n+      ReadFromMergeTree (default.tab0)\n+      ReadType: Default\n+      Parts: 1\n+      Granules: 1\n+      Prewhere info\n+      Need filter: 1\n+        Prewhere filter\n+        Prewhere filter column: equals(__table1.x, 42_UInt8) (removed)\n+        Actions: INPUT : 0 -> x UInt32 : 0\n+                 COLUMN Const(UInt8) -> 42_UInt8 UInt8 : 1\n+                 FUNCTION equals(x : 0, 42_UInt8 :: 1) -> equals(__table1.x, 42_UInt8) UInt8 : 2\n+        Positions: 0 2\n+      Indexes:\n+        PrimaryKey\n+          Keys: \n+            x\n+          Condition: (x in [42, 42])\n+          Parts: 1/1\n+          Granules: 1/123\n+  Expression ((Project names + Projection))\n+  Actions: INPUT : 0 -> __table1.x UInt32 : 0\n+           INPUT : 1 -> __table1.y UInt32 : 1\n+           ALIAS __table1.x :: 0 -> x UInt32 : 2\n+           ALIAS __table1.y :: 1 -> y UInt32 : 0\n+  Positions: 2 0\n+    Filter (( + Change column names to column identifiers))\n+    Filter column: equals(__table1.x, 42_UInt8) (removed)\n+    Actions: INPUT : 0 -> x UInt32 : 0\n+             INPUT : 1 -> y UInt32 : 1\n+             COLUMN Const(UInt8) -> 42_UInt8 UInt8 : 2\n+             ALIAS x : 0 -> __table1.x UInt32 : 3\n+             ALIAS y :: 1 -> __table1.y UInt32 : 4\n+             FUNCTION equals(x :: 0, 42_UInt8 :: 2) -> equals(__table1.x, 42_UInt8) UInt8 : 1\n+    Positions: 1 3 4\n+      ReadFromRemote (Read from remote replica)\n+        Expression ((Project names + Projection))\n+        Actions: INPUT : 0 -> __table1.x UInt32 : 0\n+                 INPUT : 1 -> __table1.y UInt32 : 1\n+                 ALIAS __table1.x :: 0 -> x UInt32 : 2\n+                 ALIAS __table1.y :: 1 -> y UInt32 : 0\n+        Positions: 2 0\n+          Expression\n+          Actions: INPUT : 1 -> y UInt32 : 0\n+                   INPUT : 0 -> x UInt32 : 1\n+                   ALIAS y :: 0 -> __table1.y UInt32 : 2\n+                   ALIAS x :: 1 -> __table1.x UInt32 : 0\n+          Positions: 0 2\n+            ReadFromMergeTree (default.tab0)\n+            ReadType: Default\n+            Parts: 1\n+            Granules: 1\n+            Prewhere info\n+            Need filter: 1\n+              Prewhere filter\n+              Prewhere filter column: equals(__table1.x, 42_UInt8) (removed)\n+              Actions: INPUT : 0 -> x UInt32 : 0\n+                       COLUMN Const(UInt8) -> 42_UInt8 UInt8 : 1\n+                       FUNCTION equals(x : 0, 42_UInt8 :: 1) -> equals(__table1.x, 42_UInt8) UInt8 : 2\n+              Positions: 0 2\n+            Indexes:\n+              PrimaryKey\n+                Keys: \n+                  x\n+                Condition: (x in [42, 42])\n+                Parts: 1/1\n+                Granules: 1/123\n+============ lambdas\n+41\t41\n+41\t41\n+20\t20\n+20\t20\n+============ #69472\n+Expression ((Project names + Projection))\n+Actions: INPUT : 0 -> sum(__table1.y) UInt64 : 0\n+         ALIAS sum(__table1.y) :: 0 -> sum(y) UInt64 : 1\n+Positions: 1\n+  Aggregating\n+  Keys:\n+  Aggregates:\n+      sum(__table1.y)\n+        Function: sum(UInt32) \u2192 UInt64\n+        Arguments: __table1.y\n+  Skip merging: 0\n+    Union\n+      Expression (Before GROUP BY)\n+      Actions: INPUT :: 0 -> __table1.y UInt32 : 0\n+      Positions: 0\n+        Expression\n+        Actions: INPUT : 0 -> y UInt32 : 0\n+                 INPUT :: 1 -> x UInt32 : 1\n+                 ALIAS y :: 0 -> __table1.y UInt32 : 2\n+                 ALIAS __table1.y :: 2 -> y UInt32 : 0\n+                 ALIAS y :: 0 -> __table1.y UInt32 : 2\n+        Positions: 2\n+          ReadFromMergeTree (default.tab0)\n+          ReadType: Default\n+          Parts: 1\n+          Granules: 1\n+          Prewhere info\n+          Need filter: 1\n+            Prewhere filter\n+            Prewhere filter column: equals(__table1.x, 42_UInt8) (removed)\n+            Actions: INPUT : 0 -> x UInt32 : 0\n+                     COLUMN Const(UInt8) -> 42_UInt8 UInt8 : 1\n+                     FUNCTION equals(x : 0, 42_UInt8 :: 1) -> equals(__table1.x, 42_UInt8) UInt8 : 2\n+            Positions: 0 2\n+          Indexes:\n+            PrimaryKey\n+              Keys: \n+                x\n+              Condition: (x in [42, 42])\n+              Parts: 1/1\n+              Granules: 1/123\n+      Expression (Before GROUP BY)\n+      Actions: INPUT :: 0 -> __table1.y UInt32 : 0\n+      Positions: 0\n+        Filter (( + Change column names to column identifiers))\n+        Filter column: equals(__table1.x, 42_UInt8) (removed)\n+        Actions: INPUT : 0 -> x UInt32 : 0\n+                 INPUT : 1 -> y UInt32 : 1\n+                 COLUMN Const(UInt8) -> 42_UInt8 UInt8 : 2\n+                 ALIAS y :: 1 -> __table1.y UInt32 : 3\n+                 FUNCTION equals(x :: 0, 42_UInt8 :: 2) -> equals(__table1.x, 42_UInt8) UInt8 : 1\n+        Positions: 1 3\n+          ReadFromRemote (Read from remote replica)\n+            Expression ((Project names + Projection))\n+            Actions: INPUT : 0 -> __table1.x UInt32 : 0\n+                     INPUT : 1 -> __table1.y UInt32 : 1\n+                     ALIAS __table1.x :: 0 -> x UInt32 : 2\n+                     ALIAS __table1.y :: 1 -> y UInt32 : 0\n+            Positions: 2 0\n+              Expression\n+              Actions: INPUT : 1 -> y UInt32 : 0\n+                       INPUT : 0 -> x UInt32 : 1\n+                       ALIAS y :: 0 -> __table1.y UInt32 : 2\n+                       ALIAS x :: 1 -> __table1.x UInt32 : 0\n+              Positions: 0 2\n+                ReadFromMergeTree (default.tab0)\n+                ReadType: Default\n+                Parts: 1\n+                Granules: 1\n+                Prewhere info\n+                Need filter: 1\n+                  Prewhere filter\n+                  Prewhere filter column: equals(__table1.x, 42_UInt8) (removed)\n+                  Actions: INPUT : 0 -> x UInt32 : 0\n+                           COLUMN Const(UInt8) -> 42_UInt8 UInt8 : 1\n+                           FUNCTION equals(x : 0, 42_UInt8 :: 1) -> equals(__table1.x, 42_UInt8) UInt8 : 2\n+                  Positions: 0 2\n+                Indexes:\n+                  PrimaryKey\n+                    Keys: \n+                      x\n+                    Condition: (x in [42, 42])\n+                    Parts: 1/1\n+                    Granules: 1/123\n+Expression ((Project names + (Projection + )))\n+Actions: INPUT : 0 -> sum(__table2.y) UInt64 : 0\n+         INPUT : 1 -> __table2.x UInt32 : 1\n+         ALIAS sum(__table2.y) :: 0 -> sum(y) UInt64 : 2\n+         ALIAS __table2.x :: 1 -> x UInt32 : 0\n+         ALIAS sum(y) :: 2 -> __table1.sum(y) UInt64 : 1\n+         ALIAS x :: 0 -> __table1.x UInt32 : 2\n+         ALIAS __table1.sum(y) :: 1 -> sum(y) UInt64 : 0\n+         ALIAS __table1.x :: 2 -> x UInt32 : 1\n+Positions: 1 0\n+  MergingAggregated\n+  Keys: __table2.x\n+  Aggregates:\n+      sum(__table2.y)\n+        Function: sum(UInt32) \u2192 UInt64\n+        Arguments: __table2.y\n+    Union\n+      Expression\n+      Actions: INPUT : 0 -> __table1.x UInt32 : 0\n+               INPUT : 1 -> sum(__table1.y) AggregateFunction(sum, UInt32) : 1\n+               ALIAS __table1.x :: 0 -> __table2.x UInt32 : 2\n+               ALIAS sum(__table1.y) :: 1 -> sum(__table2.y) AggregateFunction(sum, UInt32) : 0\n+      Positions: 2 0\n+        Aggregating\n+        Keys: __table1.x\n+        Aggregates:\n+            sum(__table1.y)\n+              Function: sum(UInt32) \u2192 UInt64\n+              Arguments: __table1.y\n+        Skip merging: 0\n+          Expression\n+          Actions: INPUT : 1 -> y UInt32 : 0\n+                   INPUT : 0 -> x UInt32 : 1\n+                   ALIAS y :: 0 -> __table1.y UInt32 : 2\n+                   ALIAS x :: 1 -> __table1.x UInt32 : 0\n+          Positions: 0 2\n+            ReadFromMergeTree (default.tab0)\n+            ReadType: Default\n+            Parts: 1\n+            Granules: 1\n+            Prewhere info\n+            Need filter: 1\n+              Prewhere filter\n+              Prewhere filter column: equals(__table1.x, 42_UInt8) (removed)\n+              Actions: INPUT : 0 -> x UInt32 : 0\n+                       COLUMN Const(UInt8) -> 42_UInt8 UInt8 : 1\n+                       FUNCTION equals(x : 0, 42_UInt8 :: 1) -> equals(__table1.x, 42_UInt8) UInt8 : 2\n+              Positions: 0 2\n+            Indexes:\n+              PrimaryKey\n+                Keys: \n+                  x\n+                Condition: (x in [42, 42])\n+                Parts: 1/1\n+                Granules: 1/123\n+      Filter (( + Change remote column names to local column names))\n+      Filter column: equals(__table1.x, 42_UInt8) (removed)\n+      Actions: INPUT : 0 -> __table1.x UInt32 : 0\n+               INPUT : 1 -> sum(__table1.y) AggregateFunction(sum, UInt32) : 1\n+               COLUMN Const(UInt8) -> 42_UInt8 UInt8 : 2\n+               ALIAS __table1.x : 0 -> __table2.x UInt32 : 3\n+               ALIAS sum(__table1.y) :: 1 -> sum(__table2.y) AggregateFunction(sum, UInt32) : 4\n+               FUNCTION equals(__table1.x :: 0, 42_UInt8 :: 2) -> equals(__table1.x, 42_UInt8) UInt8 : 1\n+      Positions: 1 3 4\n+        ReadFromRemote (Read from remote replica)\n+          Expression ((Project names + (Projection + )))\n+          Actions: INPUT : 0 -> sum(__table1.y) UInt64 : 0\n+                   INPUT : 1 -> __table1.x UInt32 : 1\n+                   ALIAS sum(__table1.y) :: 0 -> sum(y) UInt64 : 2\n+                   ALIAS __table1.x :: 1 -> x UInt32 : 0\n+          Positions: 0 2\n+            Aggregating\n+            Keys: __table1.x\n+            Aggregates:\n+                sum(__table1.y)\n+                  Function: sum(UInt32) \u2192 UInt64\n+                  Arguments: __table1.y\n+            Skip merging: 0\n+              Expression\n+              Actions: INPUT : 1 -> y UInt32 : 0\n+                       INPUT : 0 -> x UInt32 : 1\n+                       ALIAS y :: 0 -> __table1.y UInt32 : 2\n+                       ALIAS x :: 1 -> __table1.x UInt32 : 0\n+              Positions: 0 2\n+                ReadFromMergeTree (default.tab0)\n+                ReadType: Default\n+                Parts: 1\n+                Granules: 1\n+                Prewhere info\n+                Need filter: 1\n+                  Prewhere filter\n+                  Prewhere filter column: equals(__table1.x, 42_UInt8) (removed)\n+                  Actions: INPUT : 0 -> x UInt32 : 0\n+                           COLUMN Const(UInt8) -> 42_UInt8 UInt8 : 1\n+                           FUNCTION equals(x : 0, 42_UInt8 :: 1) -> equals(__table1.x, 42_UInt8) UInt8 : 2\n+                  Positions: 0 2\n+                Indexes:\n+                  PrimaryKey\n+                    Keys: \n+                      x\n+                    Condition: (x in [42, 42])\n+                    Parts: 1/1\n+                    Granules: 1/123\n+============ in / global in\n+CreatingSets (Create sets before main query execution)\n+  Expression ((Project names + Projection))\n+    Aggregating\n+      Union\n+        Expression (Before GROUP BY)\n+          Expression\n+            ReadFromMergeTree (default.tab0)\n+            Indexes:\n+              PrimaryKey\n+                Keys: \n+                  x\n+                Condition: (x in 1-element set)\n+                Parts: 1/1\n+                Granules: 1/123\n+        Expression (Before GROUP BY)\n+          Filter (( + Change column names to column identifiers))\n+            ReadFromRemote (Read from remote replica)\n+              CreatingSets (Create sets before main query execution)\n+                Expression ((Project names + Projection))\n+                  Expression\n+                    ReadFromMergeTree (default.tab0)\n+                    Indexes:\n+                      PrimaryKey\n+                        Keys: \n+                          x\n+                        Condition: (x in 1-element set)\n+                        Parts: 1/1\n+                        Granules: 1/123\n+42\n+CreatingSets (Create sets before main query execution)\n+  Expression ((Project names + Projection))\n+    Aggregating\n+      Expression (Before GROUP BY)\n+        Filter ((WHERE + Change column names to column identifiers))\n+          ReadFromRemote (Read from remote replica)\n+            CreatingSets (Create sets before main query execution)\n+              Expression ((Project names + Projection))\n+                Filter ((WHERE + Change column names to column identifiers))\n+                  ReadFromMergeTree (default.tab0)\n+                  Indexes:\n+                    PrimaryKey\n+                      Keys: \n+                        x\n+                      Condition: (x in 1-element set)\n+                      Parts: 1/1\n+                      Granules: 1/123\n+  CreatingSet (Create set for subquery)\n+    Expression ((Project names + (Projection + Change column names to column identifiers)))\n+      ReadFromSystemNumbers\n+42\n+CreatingSets (Create sets before main query execution)\n+  Expression ((Project names + Projection))\n+    Aggregating\n+      Expression (Before GROUP BY)\n+        Filter ((WHERE + (Change column names to column identifiers + (Project names + (Projection + Change column names to column identifiers)))))\n+          ReadFromMergeTree (default.tab0)\n+          Indexes:\n+            PrimaryKey\n+              Keys: \n+                x\n+              Condition: (x in 1-element set)\n+              Parts: 1/1\n+              Granules: 1/123\n+84\n+CreatingSets (Create sets before main query execution)\n+  Expression ((Project names + Projection))\n+    Aggregating\n+      Expression (Before GROUP BY)\n+        Filter ((WHERE + Change column names to column identifiers))\n+          ReadFromRemote (Read from remote replica)\n+            CreatingSets (Create sets before main query execution)\n+              Expression ((Project names + Projection))\n+                Filter ((WHERE + Change column names to column identifiers))\n+                  ReadFromMergeTree (default.tab0)\n+                  Indexes:\n+                    PrimaryKey\n+                      Keys: \n+                        x\n+                      Condition: (x in 1-element set)\n+                      Parts: 1/1\n+                      Granules: 1/123\n+            CreatingSets (Create sets before main query execution)\n+              Expression ((Project names + Projection))\n+                Filter ((WHERE + Change column names to column identifiers))\n+                  ReadFromMergeTree (default.tab0)\n+                  Indexes:\n+                    PrimaryKey\n+                      Keys: \n+                        x\n+                      Condition: (x in 1-element set)\n+                      Parts: 1/1\n+                      Granules: 1/123\n+  CreatingSet (Create set for subquery)\n+    Expression ((Project names + (Projection + Change column names to column identifiers)))\n+      ReadFromSystemNumbers\n+84\n+CreatingSets (Create sets before main query execution)\n+  Expression ((Project names + Projection))\n+    Aggregating\n+      Union\n+        Expression (Before GROUP BY)\n+          Filter ((WHERE + (Change column names to column identifiers + (Project names + (Projection + Change column names to column identifiers)))))\n+            ReadFromMergeTree (default.tab0)\n+            Indexes:\n+              PrimaryKey\n+                Keys: \n+                  x\n+                Condition: (x in 1-element set)\n+                Parts: 1/1\n+                Granules: 1/123\n+        Expression (Before GROUP BY)\n+          Filter (( + Change column names to column identifiers))\n+            ReadFromRemote (Read from remote replica)\n+              CreatingSets (Create sets before main query execution)\n+                Expression ((Project names + Projection))\n+                  Filter ((WHERE + Change column names to column identifiers))\n+                    ReadFromMergeTree (default.tab0)\n+                    Indexes:\n+                      PrimaryKey\n+                        Keys: \n+                          x\n+                        Condition: (x in 1-element set)\n+                        Parts: 1/1\n+                        Granules: 1/123\n+126\n+CreatingSets (Create sets before main query execution)\n+  Expression ((Project names + Projection))\n+    Aggregating\n+      Union\n+        Expression (Before GROUP BY)\n+          Filter ((WHERE + (Change column names to column identifiers + (Project names + (Projection + Change column names to column identifiers)))))\n+            ReadFromMergeTree (default.tab0)\n+            Indexes:\n+              PrimaryKey\n+                Keys: \n+                  x\n+                Condition: (x in 1-element set)\n+                Parts: 1/1\n+                Granules: 1/123\n+        Expression (Before GROUP BY)\n+          Filter (( + Change column names to column identifiers))\n+            ReadFromRemote (Read from remote replica)\n+              CreatingSets (Create sets before main query execution)\n+                Expression ((Project names + Projection))\n+                  Filter ((WHERE + Change column names to column identifiers))\n+                    ReadFromMergeTree (default.tab0)\n+                    Indexes:\n+                      PrimaryKey\n+                        Keys: \n+                          x\n+                        Condition: (x in 1-element set)\n+                        Parts: 1/1\n+                        Granules: 1/123\n+              CreatingSets (Create sets before main query execution)\n+                Expression ((Project names + Projection))\n+                  Filter ((WHERE + Change column names to column identifiers))\n+                    ReadFromMergeTree (default.tab0)\n+                    Indexes:\n+                      PrimaryKey\n+                        Keys: \n+                          x\n+                        Condition: (x in 1-element set)\n+                        Parts: 1/1\n+                        Granules: 1/123\n+126\n+CreatingSets (Create sets before main query execution)\n+  Expression ((Project names + Projection))\n+    Aggregating\n+      Union\n+        Expression (Before GROUP BY)\n+          Filter ((WHERE + (Change column names to column identifiers + (Project names + (Projection + Change column names to column identifiers)))))\n+            ReadFromMergeTree (default.tab0)\n+            Indexes:\n+              PrimaryKey\n+                Condition: true\n+                Parts: 1/1\n+                Granules: 123/123\n+        Expression (Before GROUP BY)\n+          Filter (( + Change column names to column identifiers))\n+            ReadFromRemote (Read from remote replica)\n+              CreatingSets (Create sets before main query execution)\n+                Expression ((Project names + Projection))\n+                  Filter ((WHERE + Change column names to column identifiers))\n+                    ReadFromMergeTree (default.tab0)\n+                    Indexes:\n+                      PrimaryKey\n+                        Condition: true\n+                        Parts: 1/1\n+                        Granules: 123/123\n+                CreatingSet (Create set for subquery)\n+                  Expression ((Project names + (Projection + Change column names to column identifiers)))\n+                    ReadFromSystemNumbers\n+              CreatingSets (Create sets before main query execution)\n+                Expression ((Project names + Projection))\n+                  Filter ((WHERE + Change column names to column identifiers))\n+                    ReadFromMergeTree (default.tab0)\n+                    Indexes:\n+                      PrimaryKey\n+                        Condition: true\n+                        Parts: 1/1\n+                        Granules: 123/123\n+                CreatingSet (Create set for subquery)\n+                  Expression ((Project names + (Projection + Change column names to column identifiers)))\n+                    ReadFromSystemNumbers\n+  CreatingSet (Create set for subquery)\n+    Expression ((Project names + (Projection + Change column names to column identifiers)))\n+      ReadFromSystemNumbers\n+============ #65638\n+CreatingSets (Create sets before main query execution)\n+  Union\n+    Expression ((Project names + Projection))\n+      Expression\n+        ReadFromMergeTree (default.tab1)\n+        Indexes:\n+          PrimaryKey\n+            Keys: \n+              recordTimestamp\n+            Condition: (recordTimestamp in 0-element set)\n+            Parts: 0/1\n+            Granules: 0/1\n+    Expression ((Project names + Projection))\n+      Filter (( + Change column names to column identifiers))\n+        ReadFromRemote (Read from remote replica)\n+          CreatingSets (Create sets before main query execution)\n+            Expression ((Project names + Projection))\n+              Expression\n+                ReadFromMergeTree (default.tab1)\n+                Indexes:\n+                  PrimaryKey\n+                    Keys: \n+                      recordTimestamp\n+                    Condition: (recordTimestamp in 0-element set)\n+                    Parts: 0/1\n+                    Granules: 0/1\n+============ #68030\n+Union\n+  Expression ((Project names + Projection))\n+  Actions: INPUT : 0 -> __table1.n UInt64 : 0\n+           ALIAS __table1.n :: 0 -> n UInt64 : 1\n+  Positions: 1\n+    Filter ((WHERE + (Change column names to column identifiers + (Convert VIEW subquery result to VIEW table structure + (Materialize constants after VIEW subquery + (Project names + (Projection + (Change column names to column identifiers + (Project names + (Projection + Change column names to column identifiers))))))))))\n+    Filter column: equals(__table1.n, 100_UInt8) (removed)\n+    Actions: INPUT : 0 -> n UInt64 : 0\n+             COLUMN Const(UInt8) -> 100_UInt8 UInt8 : 1\n+             FUNCTION materialize(n :: 0) -> materialize(n) UInt64 : 2\n+             ALIAS materialize(n) : 2 -> n UInt64 : 0\n+             FUNCTION equals(materialize(n) :: 2, 100_UInt8 :: 1) -> equals(__table1.n, 100_UInt8) UInt8 : 3\n+             ALIAS n :: 0 -> __table1.n UInt64 : 1\n+    Positions: 3 1\n+      ReadFromMergeTree (default.tab2)\n+      ReadType: Default\n+      Parts: 1\n+      Granules: 1\n+      Indexes:\n+        PrimaryKey\n+          Keys: \n+            n\n+          Condition: (materialize(n) in [100, 100])\n+          Parts: 1/1\n+          Granules: 1/62\n+  Expression ((Project names + Projection))\n+  Actions: INPUT : 0 -> __table1.n UInt64 : 0\n+           ALIAS __table1.n :: 0 -> n UInt64 : 1\n+  Positions: 1\n+    Filter (( + (Change column names to column identifiers + (Convert VIEW subquery result to VIEW table structure + (Materialize constants after VIEW subquery + (Project names + (Projection + Change column names to column identifiers)))))))\n+    Filter column: equals(__table1.n, 100_UInt8) (removed)\n+    Actions: INPUT : 0 -> n UInt64 : 0\n+             COLUMN Const(UInt8) -> 100_UInt8 UInt8 : 1\n+             FUNCTION materialize(n :: 0) -> materialize(n) UInt64 : 2\n+             ALIAS materialize(n) : 2 -> n UInt64 : 0\n+             FUNCTION equals(materialize(n) :: 2, 100_UInt8 :: 1) -> equals(__table1.n, 100_UInt8) UInt8 : 3\n+             ALIAS n :: 0 -> __table1.n UInt64 : 1\n+    Positions: 3 1\n+      ReadFromRemote (Read from remote replica)\n+        Expression ((Project names + Projection))\n+        Actions: INPUT : 0 -> __table1.n UInt64 : 0\n+                 ALIAS __table1.n :: 0 -> n UInt64 : 1\n+        Positions: 1\n+          Filter ((WHERE + Change column names to column identifiers))\n+          Filter column: equals(materialize(__table1.n), 100_UInt8) (removed)\n+          Actions: INPUT : 0 -> n UInt64 : 0\n+                   COLUMN Const(UInt8) -> 100_UInt8 UInt8 : 1\n+                   ALIAS n : 0 -> __table1.n UInt64 : 2\n+                   FUNCTION materialize(n :: 0) -> materialize(__table1.n) UInt64 : 3\n+                   FUNCTION equals(materialize(__table1.n) :: 3, 100_UInt8 :: 1) -> equals(materialize(__table1.n), 100_UInt8) UInt8 : 0\n+          Positions: 0 2\n+            ReadFromMergeTree (default.tab2)\n+            ReadType: Default\n+            Parts: 1\n+            Granules: 1\n+            Indexes:\n+              PrimaryKey\n+                Keys: \n+                  n\n+                Condition: (materialize(n) in [100, 100])\n+                Parts: 1/1\n+                Granules: 1/62\ndiff --git a/tests/queries/0_stateless/03302_analyzer_distributed_filter_push_down.sql b/tests/queries/0_stateless/03302_analyzer_distributed_filter_push_down.sql\nnew file mode 100644\nindex 000000000000..88a6cea54c35\n--- /dev/null\n+++ b/tests/queries/0_stateless/03302_analyzer_distributed_filter_push_down.sql\n@@ -0,0 +1,100 @@\n+-- Tags: no-random-merge-tree-settings\n+\n+set enable_analyzer=1;\n+set enable_parallel_replicas = 0;\n+set prefer_localhost_replica=1;\n+set optimize_aggregation_in_order=0, optimize_read_in_order=0;\n+\n+select '============ #66878';\n+\n+CREATE TABLE tab0 (x UInt32, y UInt32) engine = MergeTree order by x;\n+insert into tab0 select number, number from numbers(8192 * 123);\n+\n+\n+select * from (explain indexes=1, actions=1, distributed=1\n+    select * from (select * from remote('127.0.0.{1,2}', currentDatabase(), tab0)) where x = 42\n+);\n+\n+select '============ lambdas';\n+\n+--- lambdas are not supported\n+select * from (select * from remote('127.0.0.{1,2}', currentDatabase(), tab0)) where arraySum(arrayMap(y -> y + 1, [x])) = 42;\n+select * from (select * from remote('127.0.0.{1,2}', currentDatabase(), tab0)) where arraySum(arrayMap(y -> x + y + 2, [x])) = 42;\n+\n+select '============ #69472';\n+\n+select * from (explain indexes=1, actions=1, distributed=1\n+    select sum(y) from (select * from remote('127.0.0.{1,2}', currentDatabase(), tab0)) where x = 42\n+);\n+\n+select * from (explain indexes=1, actions=1, distributed=1\n+    select * from (select x, sum(y) from remote('127.0.0.{1,2}', currentDatabase(), tab0) group by x) where x = 42\n+);\n+\n+select '============ in / global in';\n+\n+--- IN is supported\n+select * from (explain indexes=1, distributed=1\n+    select sum(y) from (select * from remote('127.0.0.{1,2}', currentDatabase(), tab0)) where x in (select number + 42 from numbers(1))\n+);\n+\n+--- GLOBAL IN is replaced to temporary table\n+\n+select sum(y) from (select * from remote('127.0.0.2', currentDatabase(), tab0)) where x global in (select number + 42 from numbers(1));\n+select * from (explain indexes=1, distributed=1\n+    select sum(y) from (select * from remote('127.0.0.2', currentDatabase(), tab0)) where x global in (select number + 42 from numbers(1))\n+);\n+\n+select sum(y) from (select * from remote('127.0.0.1', currentDatabase(), tab0)) where x global in (select number + 42 from numbers(1));\n+select * from (explain indexes=1, distributed=1\n+    select sum(y) from (select * from remote('127.0.0.1', currentDatabase(), tab0)) where x global in (select number + 42 from numbers(1))\n+);\n+\n+select sum(y) from (select * from remote('127.0.0.{2,3}', currentDatabase(), tab0)) where x global in (select number + 42 from numbers(1));\n+select * from (explain indexes=1, distributed=1\n+    select sum(y) from (select * from remote('127.0.0.{2,3}', currentDatabase(), tab0)) where x global in (select number + 42 from numbers(1))\n+);\n+\n+select sum(y) from (select * from remote('127.0.0.{1,2}', currentDatabase(), tab0)) where x global in (select number + 42 from numbers(1));\n+select * from (explain indexes=1, distributed=1\n+    select sum(y) from (select * from remote('127.0.0.{1,2}', currentDatabase(), tab0)) where x global in (select number + 42 from numbers(1))\n+);\n+\n+select sum(y) from (select * from remote('127.0.0.{1,2,3}', currentDatabase(), tab0)) where x global in (select number + 42 from numbers(1));\n+select * from (explain indexes=1, distributed=1\n+    select sum(y) from (select * from remote('127.0.0.{1,2,3}', currentDatabase(), tab0)) where x global in (select number + 42 from numbers(1))\n+);\n+\n+select sum(x) from (select * from remote('127.0.0.{1,2,3}', currentDatabase(), tab0)) where y global in (select number + 42 from numbers(1));\n+select * from (explain indexes=1, distributed=1\n+    select sum(x) from (select * from remote('127.0.0.{1,2,3}', currentDatabase(), tab0)) where y global in (select number + 42 from numbers(1))\n+);\n+\n+select '============ #65638';\n+\n+CREATE TABLE tab1\n+(\n+    `tenant` String,\n+    `recordTimestamp` Int64,\n+    `responseBody` String,\n+    `colAlias` String ALIAS responseBody || 'something else',\n+    INDEX ngrams colAlias TYPE ngrambf_v1(3, 2097152, 3, 0) GRANULARITY 10,\n+)\n+ENGINE = MergeTree ORDER BY recordTimestamp;\n+\n+INSERT INTO tab1 SELECT * FROM generateRandom('tenant String, recordTimestamp Int64, responseBody String') LIMIT 10;\n+\n+\n+select * from (explain indexes=1, distributed=1\n+    select * from (select * from remote('127.0.0.{1,2}', currentDatabase(), tab1)) where (tenant,recordTimestamp) IN (\n+    select tenant,recordTimestamp from remote('127.0.0.{1,2}', currentDatabase(), tab1) where colAlias like '%abcd%'\n+));\n+\n+select '============ #68030';\n+\n+CREATE TABLE tab2 ENGINE=ReplacingMergeTree ORDER BY n AS SELECT intDiv(number,2) as n from numbers(8192 * 123);\n+CREATE VIEW test_view AS SELECT * FROM remote('127.0.0.{1,2}', currentDatabase(), tab2);\n+\n+select * from (explain indexes=1, actions=1, distributed=1\n+    SELECT * from test_view WHERE n=100\n+);\n",
  "problem_statement": "A query is too slow when using enable_analyzer=1 (by default)\n**Describe the situation**\r\nThe same query works differently with settings allow_experimental_analyzer=1 and 0.\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use\r\nClickHouse version 24.3.5.46\r\n\r\n* `CREATE TABLE` statements for all tables involved\r\n\r\nThe DDL of Distributed table:\r\n```sql\r\ncreate table dis_TABLEA\r\n( \r\n    CTIME DateTime,\r\n    AAA   String,\r\n    BBB   Nullable(String),\r\n    CCC   Nullable(String),\r\n    DDD   Nullable(String),\r\n    EEE   Nullable(String),\r\n    FFF   Nullable(String),\r\n    GGG   Nullable(String),\r\n    HHH   Nullable(String),\r\n---Nearly 100 columns are Nullable String\r\n    DT    UInt32\r\n)\r\n    engine = Distributed('CLUSTERA', 'DATABASE', 'TABLEA', toUInt64OrZero('AAA'));\r\n```\r\n\r\n\r\nThe DDL of the underlying base table:\r\n```\r\ncreate table TABLEA\r\n(\r\n    CTIME DateTime,\r\n    AAA   String,\r\n    BBB   Nullable(String),\r\n    CCC   Nullable(String),\r\n    DDD   Nullable(String),\r\n    EEE   Nullable(String),\r\n    FFF   Nullable(String),\r\n    GGG   Nullable(String),\r\n    HHH   Nullable(String),\r\n---Nearly 100 columns are Nullable String\r\n    DT    UInt32\r\n)\r\n    engine = MergeTree PARTITION BY toUInt32(DT / 7)\r\n        ORDER BY AAA\r\n        SETTINGS index_granularity = 8192;\r\n```\r\n\r\n\r\n* Queries to run that lead to slow performance\r\n\r\n```sql\r\nselect count(1)\r\nfrom (select *\r\n      from (select toDateTime(CTIME) ,\r\n                   BBB,\r\n                   AAA,\r\n                   CCC,\r\n                   DDD,\r\n                   EEE,\r\n                   FFF,\r\n                   GGG,\r\n                   HHH,\r\n                   DT\r\n            from DATABASE.dis_TABLEA) t\r\n      WHERE \"AAA\" = '123456789') t1\r\n```\r\n\r\n**Expected performance**\r\nWhen allow_experimental_analyzer = 0, the query can finish in less than 3 seconds.When allow_experimental_analyzer = 1, the query will last for at least 5 minute. with the network load monitor, I can see that allow_experimental_analyzer = 1 causes too much network traffic, seems like that it's reading the whole table content.\r\n\r\n**Additional context**\r\nThe explain with allow_experimental_analyzer = 0:\r\n\r\n```sql\r\nexplain\r\nselect count(1)\r\nfrom (select *\r\n      from (select toDateTime(CTIME) ,\r\n                   BBB,\r\n                   AAA,\r\n                   CCC,\r\n                   DDD,\r\n                   EEE,\r\n                   FFF,\r\n                   GGG,\r\n                   HHH,\r\n                   DT\r\n            from DATABASE.dis_TABLEA) t\r\n      WHERE \"AAA\" = '123456789') t1 SETTINGS allow_experimental_analyzer = 0;\r\n\r\n    \u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n 1. \u2502 Expression ((Projection + Before ORDER BY))                           \u2502\r\n 2. \u2502   Aggregating                                                         \u2502\r\n 3. \u2502     Union                                                             \u2502\r\n 4. \u2502       Expression ((Before GROUP BY + (Projection + Before ORDER BY))) \u2502\r\n 5. \u2502         Filter ((WHERE + (Projection + Before ORDER BY)))             \u2502\r\n 6. \u2502           Filter (WHERE)                                              \u2502\r\n 7. \u2502             ReadFromPreparedSource (Read from NullSource)             \u2502\r\n 8. \u2502       Expression (( + ( + )))                                         \u2502\r\n 9. \u2502         Filter                                                        \u2502\r\n10. \u2502           ReadFromRemote (Read from remote replica)                   \u2502\r\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nThe explain with allow_experimental_analyzer = 1:\r\n\r\n```sql\r\nexplain\r\nselect count(1)\r\nfrom (select *\r\n      from (select toDateTime(CTIME) ,\r\n                   BBB,\r\n                   AAA,\r\n                   CCC,\r\n                   DDD,\r\n                   EEE,\r\n                   FFF,\r\n                   GGG,\r\n                   HHH,\r\n                   dt\r\n            from DATABASE.dis_TABLEA) t\r\n      WHERE \"AAA\" = '123456789') t1 SETTINGS allow_experimental_analyzer = 1;\r\n\r\n\r\n\r\n   \u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n1. \u2502 Expression ((Project names + Projection))                                                                                                                                                                                                                \u2502\r\n2. \u2502   Aggregating                                                                                                                                                                                                                                            \u2502\r\n3. \u2502     Union                                                                                                                                                                                                                                                \u2502\r\n4. \u2502       Expression ((Before GROUP BY + (Change column names to column identifiers + (Project names + (Projection + (WHERE + (Change column names to column identifiers + (Project names + (Projection + Change column names to column identifiers))))))))) \u2502\r\n5. \u2502         Filter (((WHERE + (Change column names to column identifiers + (Project names + (Projection + Change column names to column identifiers)))))[split])                                                                                             \u2502\r\n6. \u2502           ReadFromPreparedSource (Read from NullSource)                                                                                                                                                                                                  \u2502\r\n7. \u2502       Expression (( + ( + ( + ))))                                                                                                                                                                                                                       \u2502\r\n8. \u2502         Filter (( + ))                                                                                                                                                                                                                                   \u2502\r\n9. \u2502           ReadFromRemote (Read from remote replica)                                                                                                                                                                                                      \u2502\r\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\n",
  "hints_text": "Could you please share the `EXPLAIN PLAN INDEXES = 1` output?\r\nAlso, it'd be useful if you share logs for these queries. \n> Could you please share the `EXPLAIN PLAN INDEXES = 1` output? Also, it'd be useful if you share logs for these queries.\r\n\r\nWhat log? Do you mean outputs in clickhouse-server.log? But there are so many rows per second, how can I filter the query log?\n@Tiaonmmn The whole server log is not required. Only logs for a specific query are enough. Each query has a unique `query_id`. It's printed out in `clickhouse-client` when you run the query. Afterward, you can filter server logs using `query_id`.\nPlease set this parameter in **clickhouse-client** before running your query(SQL):\r\n`:)  set send_logs_level='trace';`\r\nThen the following output is what @novikd wants. :)\nI think this is related to: https://github.com/ClickHouse/ClickHouse/issues/69472\r\n\r\nAnd seems to be WIP here: \r\nhttps://github.com/ClickHouse/ClickHouse/pull/69652\r\n\r\nWe can also replicate this trivially in latest clickhouse.\r\n\r\n@KochetovNicolai Please let us know if we can help with testing in anyway.\n**Predicate pushdown does not work on distributed table with analyzer enabled**\r\n\r\n### Minimal replication with EXPLAIN PLAN indexes=1\r\n\r\nCreated a minimal example that shows the issue.\r\nThe problem is that the WHERE statement should have predicate_push down when it doesn't.\r\nIf we manually add the predicate pushdown to the subqueries by copy pasting the where query or we disable analyzer,\r\nthe queries are near instant and the EXPLAIN PLAN looks like it should.\r\nNote that the distributed tables are in the current DB (`somedb`), and point to `ReplicatedMergeTree` tables in another DB `somedb_shard`. All data is in 1 cluster with 2 shards and 2 replicas for each.\r\n<details>\r\n\r\n<summary> No predicate pushdown when enable_analyzer=1 and the tables are distributed </summary>\r\n\r\n```SQL\r\n-- WHY NOT PREDICATE PUSHDOWN?\r\nSET enable_analyzer=1;\r\nEXPLAIN PLAN indexes=1 (\r\nSELECT count(*) AS count\r\nFROM\r\n(\r\n    WITH\r\n        bigtable_data AS\r\n        (\r\n            SELECT *\r\n            FROM bigtable\r\n        ),\r\n        smallertable_data AS\r\n        (\r\n            SELECT\r\n                dimension_field,\r\n                time_field,\r\n                unused_field\r\n            FROM smallertable\r\n        )\r\n    SELECT *\r\n    FROM bigtable_data\r\n    INNER JOIN smallertable_data USING (dimension_field, time_field)\r\n) AS virtual_table\r\nWHERE\r\n    (time_field >= toDateTime('2024-11-26 08:03:32')) AND\r\n    (time_field < toDateTime('2024-11-26 15:03:32')) AND\r\n    (major_filter_field_name = 'TEST')\r\nLIMIT 50000\r\n);\r\n```\r\n\r\n\r\n```C++\r\n    \u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n 1. \u2502 Expression ((Project names + Projection))                                                                                                       \u2502\r\n 2. \u2502   Limit (preliminary LIMIT (without OFFSET))                                                                                                    \u2502\r\n 3. \u2502     Aggregating                                                                                                                                 \u2502\r\n 4. \u2502       Expression ((Before GROUP BY + ))                                                                                                         \u2502\r\n 5. \u2502         Join (JOIN FillRightFirst)                                                                                                              \u2502\r\n 6. \u2502           Union                                                                                                                                 \u2502\r\n 7. \u2502             Expression                                                                                                                          \u2502\r\n 8. \u2502               ReadFromMergeTree (somedb_shard.bigtable)                                                                                              \u2502\r\n 9. \u2502               Indexes:                                                                                                                          \u2502\r\n1.  \u2502                 MinMax                                                                                                                          \u2502\r\n2.  \u2502                   Keys:                                                                                                                         \u2502\r\n3.  \u2502                     time_field                                                                                                                   \u2502\r\n4.  \u2502                   Condition: and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf)))                                          \u2502\r\n5.  \u2502                   Parts: 6/121                                                                                                                  \u2502\r\n6.  \u2502                   Granules: 76553/1843207                                                                                                       \u2502\r\n7.  \u2502                 Partition                                                                                                                       \u2502\r\n8.  \u2502                   Keys:                                                                                                                         \u2502\r\n9.  \u2502                     toYYYYMM(time_field)                                                                                                         \u2502\r\n10. \u2502                   Condition: and((toYYYYMM(time_field) in (-Inf, 202411]), (toYYYYMM(time_field) in [202411, +Inf)))                              \u2502\r\n11. \u2502                   Parts: 6/6                                                                                                                    \u2502\r\n12. \u2502                   Granules: 76553/76553                                                                                                         \u2502\r\n13. \u2502                 PrimaryKey                                                                                                                      \u2502\r\n14. \u2502                   Keys:                                                                                                                         \u2502\r\n15. \u2502                     major_filter_field_name                                                                                                                \u2502\r\n16. \u2502                     time_field                                                                                                                   \u2502\r\n17. \u2502                   Condition: and((major_filter_field_name in ['TEST', 'TEST']), and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf)))) \u2502\r\n18. \u2502                   Parts: 4/6                                                                                                                    \u2502\r\n19. \u2502                   Granules: 4/76553                                                                                                             \u2502\r\n20. \u2502             Filter (( + Change column names to column identifiers))                                                                             \u2502\r\n21. \u2502               ReadFromRemote (Read from remote replica)                                                                                         \u2502\r\n22. \u2502           Union                                                                                                                                 \u2502\r\n23. \u2502             Expression                                                                                                                          \u2502\r\n24. \u2502               ReadFromMergeTree (somedb_shard.smallertable)                                                                                           \u2502\r\n25. \u2502               Indexes:                                                                                                                          \u2502\r\n26. \u2502                 MinMax                                                                                                                          \u2502\r\n27. \u2502                   Keys:                                                                                                                         \u2502\r\n28. \u2502                     time_field                                                                                                                   \u2502\r\n29. \u2502                   Condition: and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf)))                                          \u2502\r\n30. \u2502                   Parts: 1/56                                                                                                                   \u2502\r\n31. \u2502                   Granules: 1/382                                                                                                               \u2502\r\n32. \u2502                 Partition                                                                                                                       \u2502\r\n33. \u2502                   Keys:                                                                                                                         \u2502\r\n34. \u2502                     toYYYYMM(time_field)                                                                                                         \u2502\r\n35. \u2502                   Condition: and((toYYYYMM(time_field) in (-Inf, 202411]), (toYYYYMM(time_field) in [202411, +Inf)))                              \u2502\r\n36. \u2502                   Parts: 1/1                                                                                                                    \u2502\r\n37. \u2502                   Granules: 1/1                                                                                                                 \u2502\r\n38. \u2502                 PrimaryKey                                                                                                                      \u2502\r\n39. \u2502                   Keys:                                                                                                                         \u2502\r\n40. \u2502                     time_field                                                                                                                   \u2502\r\n41. \u2502                   Condition: and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf)))                                          \u2502\r\n42. \u2502                   Parts: 1/1                                                                                                                    \u2502\r\n43. \u2502                   Granules: 1/1                                                                                                                 \u2502\r\n44. \u2502             Filter (( + Change column names to column identifiers))                                                                             \u2502\r\n45. \u2502               ReadFromRemote (Read from remote replica)                                                                                         \u2502\r\n    \u2514\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n</details>\r\n\r\n\r\n<details>\r\n\r\n<summary> Manually adding the predicate pushdown works even with analyzer enabled </summary>\r\n\r\n```SQL\r\n-- MANUAL PREDICATE PUSHDOWN\r\nSET enable_analyzer=1;\r\nEXPLAIN PLAN indexes=1 (\r\nSELECT count(*) AS count\r\nFROM\r\n(\r\n    WITH\r\n        bigtable_data AS\r\n        (\r\n            SELECT *\r\n            FROM bigtable\r\n\t\t\tWHERE\r\n\t\t\t\t(time_field >= toDateTime('2024-11-26 08:03:32')) AND\r\n\t\t\t\t(time_field < toDateTime('2024-11-26 15:03:32')) AND\r\n\t\t\t\t(major_filter_field_name = 'TEST')\r\n        ),\r\n        smallertable_data AS\r\n        (\r\n            SELECT\r\n                dimension_field,\r\n                time_field,\r\n                unused_field\r\n            FROM smallertable\r\n\t\t\tWHERE\r\n\t\t\t\t(time_field >= toDateTime('2024-11-26 08:03:32')) AND\r\n\t\t\t\t(time_field < toDateTime('2024-11-26 15:03:32')) AND\r\n\t\t\t\t(major_filter_field_name = 'TEST')\r\n        )\r\n    SELECT *\r\n    FROM bigtable_data\r\n    INNER JOIN smallertable_data USING (dimension_field, time_field)\r\n) AS virtual_table\r\nWHERE\r\n    (time_field >= toDateTime('2024-11-26 08:03:32')) AND\r\n    (time_field < toDateTime('2024-11-26 15:03:32')) AND\r\n    (major_filter_field_name = 'TEST')\r\nLIMIT 50000\r\n);\r\n```\r\n\r\n```C++\r\n \u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n 1. \u2502 Expression ((Project names + Projection))                                                                                                                                                                                                                  \u2502\r\n 2. \u2502   Limit (preliminary LIMIT (without OFFSET))                                                                                                                                                                                                               \u2502\r\n 3. \u2502     Aggregating                                                                                                                                                                                                                                            \u2502\r\n 4. \u2502       Expression ((Before GROUP BY + ))                                                                                                                                                                                                                    \u2502\r\n 5. \u2502         Join (JOIN FillRightFirst)                                                                                                                                                                                                                         \u2502\r\n 6. \u2502           Union                                                                                                                                                                                                                                            \u2502\r\n 7. \u2502             Filter (( + (Change column names to column identifiers + (Project names + Projection))))                                                                                                                                                       \u2502\r\n 8. \u2502               Expression                                                                                                                                                                                                                                   \u2502\r\n 9. \u2502                 ReadFromMergeTree (somedb_shard.bigtable)                                                                                                                                                                                                       \u2502\r\n10. \u2502                 Indexes:                                                                                                                                                                                                                                   \u2502\r\n11. \u2502                   MinMax                                                                                                                                                                                                                                   \u2502\r\n12. \u2502                     Keys:                                                                                                                                                                                                                                  \u2502\r\n13. \u2502                       time_field                                                                                                                                                                                                                            \u2502\r\n14. \u2502                     Condition: and(and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf))), and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf))))                                                                   \u2502\r\n15. \u2502                     Parts: 6/121                                                                                                                                                                                                                           \u2502\r\n16. \u2502                     Granules: 76553/1843207                                                                                                                                                                                                                \u2502\r\n17. \u2502                   Partition                                                                                                                                                                                                                                \u2502\r\n18. \u2502                     Keys:                                                                                                                                                                                                                                  \u2502\r\n19. \u2502                       toYYYYMM(time_field)                                                                                                                                                                                                                  \u2502\r\n20. \u2502                     Condition: and(and((toYYYYMM(time_field) in (-Inf, 202411]), (toYYYYMM(time_field) in [202411, +Inf))), and((toYYYYMM(time_field) in (-Inf, 202411]), (toYYYYMM(time_field) in [202411, +Inf))))                                           \u2502\r\n21. \u2502                     Parts: 6/6                                                                                                                                                                                                                             \u2502\r\n22. \u2502                     Granules: 76553/76553                                                                                                                                                                                                                  \u2502\r\n23. \u2502                   PrimaryKey                                                                                                                                                                                                                               \u2502\r\n24. \u2502                     Keys:                                                                                                                                                                                                                                  \u2502\r\n25. \u2502                       major_filter_field_name                                                                                                                                                                                                                         \u2502\r\n26. \u2502                       time_field                                                                                                                                                                                                                            \u2502\r\n27. \u2502                     Condition: and(and((major_filter_field_name in ['TEST', 'TEST']), and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf)))), and((major_filter_field_name in ['TEST', 'TEST']), and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf))))) \u2502\r\n28. \u2502                     Parts: 4/6                                                                                                                                                                                                                             \u2502\r\n29. \u2502                     Granules: 4/76553                                                                                                                                                                                                                      \u2502\r\n30. \u2502             Filter (( + Change column names to column identifiers))                                                                                                                                                                                        \u2502\r\n31. \u2502               ReadFromRemote (Read from remote replica)                                                                                                                                                                                                    \u2502\r\n32. \u2502           Union                                                                                                                                                                                                                                            \u2502\r\n33. \u2502             Filter (( + (Change column names to column identifiers + (Project names + Projection))))                                                                                                                                                       \u2502\r\n34. \u2502               Expression                                                                                                                                                                                                                                   \u2502\r\n35. \u2502                 ReadFromMergeTree (somedb_shard.smallertable)                                                                                                                                                                                                    \u2502\r\n36. \u2502                 Indexes:                                                                                                                                                                                                                                   \u2502\r\n37. \u2502                   MinMax                                                                                                                                                                                                                                   \u2502\r\n38. \u2502                     Keys:                                                                                                                                                                                                                                  \u2502\r\n39. \u2502                       time_field                                                                                                                                                                                                                            \u2502\r\n40. \u2502                     Condition: and(and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf))), and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf))))                                                                   \u2502\r\n41. \u2502                     Parts: 1/56                                                                                                                                                                                                                            \u2502\r\n42. \u2502                     Granules: 1/382                                                                                                                                                                                                                        \u2502\r\n43. \u2502                   Partition                                                                                                                                                                                                                                \u2502\r\n44. \u2502                     Keys:                                                                                                                                                                                                                                  \u2502\r\n45. \u2502                       toYYYYMM(time_field)                                                                                                                                                                                                                  \u2502\r\n46. \u2502                     Condition: and(and((toYYYYMM(time_field) in (-Inf, 202411]), (toYYYYMM(time_field) in [202411, +Inf))), and((toYYYYMM(time_field) in (-Inf, 202411]), (toYYYYMM(time_field) in [202411, +Inf))))                                           \u2502\r\n47. \u2502                     Parts: 1/1                                                                                                                                                                                                                             \u2502\r\n48. \u2502                     Granules: 1/1                                                                                                                                                                                                                          \u2502\r\n49. \u2502                   PrimaryKey                                                                                                                                                                                                                               \u2502\r\n50. \u2502                     Keys:                                                                                                                                                                                                                                  \u2502\r\n51. \u2502                       major_filter_field_name                                                                                                                                                                                                                         \u2502\r\n52. \u2502                       time_field                                                                                                                                                                                                                            \u2502\r\n53. \u2502                     Condition: and(and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf))), and((major_filter_field_name in ['TEST', 'TEST']), and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf)))))                          \u2502\r\n54. \u2502                     Parts: 1/1                                                                                                                                                                                                                             \u2502\r\n55. \u2502                     Granules: 1/1                                                                                                                                                                                                                          \u2502\r\n56. \u2502             Filter (( + Change column names to column identifiers))                                                                                                                                                                                        \u2502\r\n57. \u2502               ReadFromRemote (Read from remote replica)                                                                                                                                                                                                    \u2502\r\n    \u2514\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n</details>\r\n\r\n\r\n<details>\r\n\r\n<summary> Disabling the analyzer also works (no need for manual predicate pushdown) </summary>\r\n\r\n```SQL\r\n-- disable analyzer and the query is very fast.\r\nSET enable_analyzer=0;\r\nEXPLAIN PLAN indexes=1 (\r\nSELECT count(*) AS count\r\nFROM\r\n(\r\n    WITH\r\n        bigtable_data AS\r\n        (\r\n            SELECT *\r\n            FROM bigtable\r\n        ),\r\n        smallertable_data AS\r\n        (\r\n            SELECT\r\n                dimension_field,\r\n                time_field,\r\n                unused_field\r\n            FROM smallertable\r\n        )\r\n    SELECT *\r\n    FROM bigtable_data\r\n    INNER JOIN smallertable_data USING (dimension_field, time_field)\r\n) AS virtual_table\r\nWHERE\r\n    (time_field >= toDateTime('2024-11-26 08:03:32')) AND\r\n    (time_field < toDateTime('2024-11-26 15:03:32')) AND\r\n    (major_filter_field_name = 'TEST')\r\nLIMIT 50000\r\n);\r\n```\r\n\r\n```C++\r\n    \u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n 1. \u2502 Expression ((Projection + Before ORDER BY))                                                                                                                                                                                                                \u2502\r\n 2. \u2502   Limit (preliminary LIMIT (without OFFSET))                                                                                                                                                                                                               \u2502\r\n 3. \u2502     Aggregating                                                                                                                                                                                                                                            \u2502\r\n 4. \u2502       Expression ((Before GROUP BY + ))                                                                                                                                                                                                                    \u2502\r\n 5. \u2502         Join (JOIN FillRightFirst)                                                                                                                                                                                                                         \u2502\r\n 6. \u2502           Union                                                                                                                                                                                                                                            \u2502\r\n 7. \u2502             Filter                                                                                                                                                                                                                                         \u2502\r\n 8. \u2502               Filter (( + (Before JOIN + (Projection + Before ORDER BY))))                                                                                                                                                                                 \u2502\r\n 9. \u2502                 Expression                                                                                                                                                                                                                                 \u2502\r\n10. \u2502                   ReadFromMergeTree (somedb_shard.bigtable)                                                                                                                                                                                                     \u2502\r\n11. \u2502                   Indexes:                                                                                                                                                                                                                                 \u2502\r\n12. \u2502                     MinMax                                                                                                                                                                                                                                 \u2502\r\n13. \u2502                       Keys:                                                                                                                                                                                                                                \u2502\r\n14. \u2502                         time_field                                                                                                                                                                                                                          \u2502\r\n15. \u2502                       Condition: and(and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf))), and(and((time_field in [1732608212, +Inf)), (time_field in (-Inf, 1732633411])), and((time_field in [1732608212, +Inf)), (time_field in (-Inf, 1732633411])))) \u2502\r\n16. \u2502                       Parts: 6/121                                                                                                                                                                                                                         \u2502\r\n17. \u2502                       Granules: 76553/1843207                                                                                                                                                                                                              \u2502\r\n18. \u2502                     Partition                                                                                                                                                                                                                              \u2502\r\n19. \u2502                       Keys:                                                                                                                                                                                                                                \u2502\r\n20. \u2502                         toYYYYMM(time_field)                                                                                                                                                                                                                \u2502\r\n21. \u2502                       Condition: and(and((toYYYYMM(time_field) in (-Inf, 202411]), (toYYYYMM(time_field) in [202411, +Inf))), and(and((toYYYYMM(time_field) in [202411, +Inf)), (toYYYYMM(time_field) in (-Inf, 202411])), and((toYYYYMM(time_field) in [202411, +Inf)), (toYYYYMM(time_field) in (-Inf, 202411])))) \u2502\r\n22. \u2502                       Parts: 6/6                                                                                                                                                                                                                           \u2502\r\n23. \u2502                       Granules: 76553/76553                                                                                                                                                                                                                \u2502\r\n24. \u2502                     PrimaryKey                                                                                                                                                                                                                             \u2502\r\n25. \u2502                       Keys:                                                                                                                                                                                                                                \u2502\r\n26. \u2502                         major_filter_field_name                                                                                                                                                                                                                       \u2502\r\n27. \u2502                         time_field                                                                                                                                                                                                                          \u2502\r\n28. \u2502                       Condition: and(and((major_filter_field_name in ['TEST', 'TEST']), and((time_field in (-Inf, 1732633411]), (time_field in [1732608212, +Inf)))), and(and((time_field in [1732608212, +Inf)), and((time_field in (-Inf, 1732633411]), (major_filter_field_name in ['TEST', 'TEST']))), and((time_field in [1732608212, +Inf)), and((major_filter_field_name in ['TEST', 'TEST']), (time_field in (-Inf, 1732633411]))))) \u2502\r\n29. \u2502                       Parts: 4/6                                                                                                                                                                                                                           \u2502\r\n30. \u2502                       Granules: 4/76553                                                                                                                                                                                                                    \u2502\r\n31. \u2502             Filter                                                                                                                                                                                                                                         \u2502\r\n32. \u2502               Filter (( + Before JOIN))                                                                                                                                                                                                                    \u2502\r\n33. \u2502                 ReadFromRemote (Read from remote replica)                                                                                                                                                                                                  \u2502\r\n34. \u2502           Union                                                                                                                                                                                                                                            \u2502\r\n35. \u2502             Filter                                                                                                                                                                                                                                         \u2502\r\n36. \u2502               Expression                                                                                                                                                                                                                                   \u2502\r\n37. \u2502                 ReadFromMergeTree (somedb_shard.smallertable)                                                                                                                                                                                                    \u2502\r\n38. \u2502                 Indexes:                                                                                                                                                                                                                                   \u2502\r\n39. \u2502                   MinMax                                                                                                                                                                                                                                   \u2502\r\n40. \u2502                     Keys:                                                                                                                                                                                                                                  \u2502\r\n41. \u2502                       time_field                                                                                                                                                                                                                            \u2502\r\n42. \u2502                     Condition: and((time_field in [1732608212, +Inf)), (time_field in (-Inf, 1732633411]))                                                                                                                                                   \u2502\r\n43. \u2502                     Parts: 1/56                                                                                                                                                                                                                            \u2502\r\n44. \u2502                     Granules: 1/382                                                                                                                                                                                                                        \u2502\r\n45. \u2502                   Partition                                                                                                                                                                                                                                \u2502\r\n46. \u2502                     Keys:                                                                                                                                                                                                                                  \u2502\r\n47. \u2502                       toYYYYMM(time_field)                                                                                                                                                                                                                  \u2502\r\n48. \u2502                     Condition: and((toYYYYMM(time_field) in [202411, +Inf)), (toYYYYMM(time_field) in (-Inf, 202411]))                                                                                                                                       \u2502\r\n49. \u2502                     Parts: 1/1                                                                                                                                                                                                                             \u2502\r\n50. \u2502                     Granules: 1/1                                                                                                                                                                                                                          \u2502\r\n51. \u2502                   PrimaryKey                                                                                                                                                                                                                               \u2502\r\n52. \u2502                     Keys:                                                                                                                                                                                                                                  \u2502\r\n53. \u2502                       time_field                                                                                                                                                                                                                            \u2502\r\n54. \u2502                     Condition: and((time_field in [1732608212, +Inf)), (time_field in (-Inf, 1732633411]))                                                                                                                                                   \u2502\r\n55. \u2502                     Parts: 1/1                                                                                                                                                                                                                             \u2502\r\n56. \u2502                     Granules: 1/1                                                                                                                                                                                                                          \u2502\r\n57. \u2502             Filter                                                                                                                                                                                                                                         \u2502\r\n58. \u2502               Filter (( + (Joined actions + Rename joined columns)))                                                                                                                                                                                       \u2502\r\n59. \u2502                 ReadFromRemote (Read from remote replica)                                                                                                                                                                                                  \u2502\r\n    \u2514\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n</details>\r\n",
  "created_at": "2025-01-02T17:04:39Z"
}