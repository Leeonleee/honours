{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 58729,
  "instance_id": "ClickHouse__ClickHouse-58729",
  "issue_numbers": [
    "52069"
  ],
  "base_commit": "7ded82e51f7a758fb6f3dffd25b91cd284d2d9f2",
  "patch": "diff --git a/src/DataTypes/DataTypeTuple.cpp b/src/DataTypes/DataTypeTuple.cpp\nindex db8a14c537a8..9cce59b0dca4 100644\n--- a/src/DataTypes/DataTypeTuple.cpp\n+++ b/src/DataTypes/DataTypeTuple.cpp\n@@ -320,7 +320,7 @@ SerializationPtr DataTypeTuple::doGetDefaultSerialization() const\n     {\n         String elem_name = have_explicit_names ? names[i] : toString(i + 1);\n         auto serialization = elems[i]->getDefaultSerialization();\n-        serializations[i] = std::make_shared<SerializationNamed>(serialization, elem_name);\n+        serializations[i] = std::make_shared<SerializationNamed>(serialization, elem_name, SubstreamType::TupleElement);\n     }\n \n     return std::make_shared<SerializationTuple>(std::move(serializations), have_explicit_names);\n@@ -335,7 +335,7 @@ SerializationPtr DataTypeTuple::getSerialization(const SerializationInfo & info)\n     {\n         String elem_name = have_explicit_names ? names[i] : toString(i + 1);\n         auto serialization = elems[i]->getSerialization(*info_tuple.getElementInfo(i));\n-        serializations[i] = std::make_shared<SerializationNamed>(serialization, elem_name);\n+        serializations[i] = std::make_shared<SerializationNamed>(serialization, elem_name, SubstreamType::TupleElement);\n     }\n \n     return std::make_shared<SerializationTuple>(std::move(serializations), have_explicit_names);\ndiff --git a/src/DataTypes/NestedUtils.cpp b/src/DataTypes/NestedUtils.cpp\nindex a7cc1b21389c..6a56f8855037 100644\n--- a/src/DataTypes/NestedUtils.cpp\n+++ b/src/DataTypes/NestedUtils.cpp\n@@ -16,6 +16,7 @@\n #include <Columns/ColumnConst.h>\n \n #include <Parsers/IAST.h>\n+#include <Storages/ColumnsDescription.h>\n \n #include <boost/algorithm/string/case_conv.hpp>\n \n@@ -294,6 +295,12 @@ Names getAllNestedColumnsForTable(const Block & block, const std::string & table\n     return names;\n }\n \n+bool isSubcolumnOfNested(const String & column_name, const ColumnsDescription & columns)\n+{\n+    auto nested_subcolumn = columns.tryGetColumnOrSubcolumn(GetColumnsOptions::AllPhysical, column_name);\n+    return nested_subcolumn && isNested(nested_subcolumn->getTypeInStorage()) && nested_subcolumn->isSubcolumn() && isArray(nested_subcolumn->type);\n+}\n+\n }\n \n NestedColumnExtractHelper::NestedColumnExtractHelper(const Block & block_, bool case_insentive_)\ndiff --git a/src/DataTypes/NestedUtils.h b/src/DataTypes/NestedUtils.h\nindex 85c29d2c08fb..a0f630acc55f 100644\n--- a/src/DataTypes/NestedUtils.h\n+++ b/src/DataTypes/NestedUtils.h\n@@ -7,6 +7,8 @@\n namespace DB\n {\n \n+class ColumnsDescription;\n+\n namespace Nested\n {\n     std::string concatenateName(const std::string & nested_table_name, const std::string & nested_field_name);\n@@ -40,6 +42,9 @@ namespace Nested\n \n     /// Extract all column names that are nested for specifying table.\n     Names getAllNestedColumnsForTable(const Block & block, const std::string & table_name);\n+\n+    /// Returns true if @column_name is a subcolumn (of Array type) of any Nested column in @columns.\n+    bool isSubcolumnOfNested(const String & column_name, const ColumnsDescription & columns);\n }\n \n /// Use this class to extract element columns from columns of nested type in a block, e.g. named Tuple.\ndiff --git a/src/DataTypes/Serializations/ISerialization.cpp b/src/DataTypes/Serializations/ISerialization.cpp\nindex e70dc6a2380a..80d498de38ae 100644\n--- a/src/DataTypes/Serializations/ISerialization.cpp\n+++ b/src/DataTypes/Serializations/ISerialization.cpp\n@@ -49,11 +49,17 @@ ISerialization::Kind ISerialization::stringToKind(const String & str)\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unknown serialization kind '{}'\", str);\n }\n \n+const std::set<SubstreamType> ISerialization::Substream::named_types\n+{\n+    TupleElement,\n+    NamedOffsets,\n+    NamedNullMap,\n+};\n+\n String ISerialization::Substream::toString() const\n {\n-    if (type == TupleElement)\n-        return fmt::format(\"TupleElement({}, escape_tuple_delimiter = {})\",\n-            tuple_element_name, escape_tuple_delimiter ? \"true\" : \"false\");\n+    if (named_types.contains(type))\n+        return fmt::format(\"{}({})\", type, name_of_substream);\n \n     return String(magic_enum::enum_name(type));\n }\n@@ -110,8 +116,10 @@ void ISerialization::serializeBinaryBulkWithMultipleStreams(\n     SerializeBinaryBulkSettings & settings,\n     SerializeBinaryBulkStatePtr & /* state */) const\n {\n+    settings.path.push_back(Substream::Regular);\n     if (WriteBuffer * stream = settings.getter(settings.path))\n         serializeBinaryBulk(column, *stream, offset, limit);\n+    settings.path.pop_back();\n }\n \n void ISerialization::deserializeBinaryBulkWithMultipleStreams(\n@@ -121,6 +129,8 @@ void ISerialization::deserializeBinaryBulkWithMultipleStreams(\n     DeserializeBinaryBulkStatePtr & /* state */,\n     SubstreamsCache * cache) const\n {\n+    settings.path.push_back(Substream::Regular);\n+\n     auto cached_column = getFromSubstreamsCache(cache, settings.path);\n     if (cached_column)\n     {\n@@ -133,6 +143,8 @@ void ISerialization::deserializeBinaryBulkWithMultipleStreams(\n         column = std::move(mutable_column);\n         addToSubstreamsCache(cache, settings.path, column);\n     }\n+\n+    settings.path.pop_back();\n }\n \n namespace\n@@ -161,16 +173,18 @@ String getNameForSubstreamPath(\n             stream_name += \".dict\";\n         else if (it->type == Substream::SparseOffsets)\n             stream_name += \".sparse.idx\";\n-        else if (it->type == Substream::TupleElement)\n+        else if (Substream::named_types.contains(it->type))\n         {\n+            auto substream_name = \".\" + it->name_of_substream;\n+\n             /// For compatibility reasons, we use %2E (escaped dot) instead of dot.\n             /// Because nested data may be represented not by Array of Tuple,\n-            ///  but by separate Array columns with names in a form of a.b,\n-            ///  and name is encoded as a whole.\n-            if (escape_tuple_delimiter && it->escape_tuple_delimiter)\n-                stream_name += escapeForFileName(\".\" + it->tuple_element_name);\n+            /// but by separate Array columns with names in a form of a.b,\n+            /// and name is encoded as a whole.\n+            if (it->type == Substream::TupleElement && escape_tuple_delimiter)\n+                stream_name += escapeForFileName(substream_name);\n             else\n-                stream_name += \".\" + it->tuple_element_name;\n+                stream_name += substream_name;\n         }\n     }\n \n@@ -184,23 +198,31 @@ String ISerialization::getFileNameForStream(const NameAndTypePair & column, cons\n     return getFileNameForStream(column.getNameInStorage(), path);\n }\n \n-bool isOffsetsOfNested(const ISerialization::SubstreamPath & path)\n+static bool isPossibleOffsetsOfNested(const ISerialization::SubstreamPath & path)\n {\n-    if (path.empty())\n-        return false;\n-\n-    for (const auto & elem : path)\n-        if (elem.type == ISerialization::Substream::ArrayElements)\n-            return false;\n-\n-    return path.back().type == ISerialization::Substream::ArraySizes;\n+    /// Arrays of Nested cannot be inside other types.\n+    /// So it's ok to check only first element of path.\n+\n+    /// Array offsets as a part of serialization of Array type.\n+    if (path.size() == 1\n+        && path[0].type == ISerialization::Substream::ArraySizes)\n+        return true;\n+\n+    /// Array offsets as a separate subcolumn.\n+    if (path.size() == 2\n+        && path[0].type == ISerialization::Substream::NamedOffsets\n+        && path[1].type == ISerialization::Substream::Regular\n+        && path[0].name_of_substream == \"size0\")\n+        return true;\n+\n+    return false;\n }\n \n String ISerialization::getFileNameForStream(const String & name_in_storage, const SubstreamPath & path)\n {\n     String stream_name;\n     auto nested_storage_name = Nested::extractTableName(name_in_storage);\n-    if (name_in_storage != nested_storage_name && isOffsetsOfNested(path))\n+    if (name_in_storage != nested_storage_name && isPossibleOffsetsOfNested(path))\n         stream_name = escapeForFileName(nested_storage_name);\n     else\n         stream_name = escapeForFileName(name_in_storage);\ndiff --git a/src/DataTypes/Serializations/ISerialization.h b/src/DataTypes/Serializations/ISerialization.h\nindex 030c3c6d81ed..dcddd6a81613 100644\n--- a/src/DataTypes/Serializations/ISerialization.h\n+++ b/src/DataTypes/Serializations/ISerialization.h\n@@ -9,7 +9,7 @@\n #include <boost/noncopyable.hpp>\n #include <unordered_map>\n #include <memory>\n-#include <variant>\n+#include <set>\n \n namespace DB\n {\n@@ -142,6 +142,8 @@ class ISerialization : private boost::noncopyable, public std::enable_shared_fro\n             NullMap,\n \n             TupleElement,\n+            NamedOffsets,\n+            NamedNullMap,\n \n             DictionaryKeys,\n             DictionaryIndexes,\n@@ -155,13 +157,13 @@ class ISerialization : private boost::noncopyable, public std::enable_shared_fro\n             Regular,\n         };\n \n-        Type type;\n+        /// Types of substreams that can have arbitrary name.\n+        static const std::set<Type> named_types;\n \n-        /// Index of tuple element, starting at 1 or name.\n-        String tuple_element_name;\n+        Type type;\n \n-        /// Do we need to escape a dot in filenames for tuple elements.\n-        bool escape_tuple_delimiter = true;\n+        /// Name of substream for type from 'named_types'.\n+        String name_of_substream;\n \n         /// Data for current substream.\n         SubstreamData data;\n@@ -173,7 +175,6 @@ class ISerialization : private boost::noncopyable, public std::enable_shared_fro\n         mutable bool visited = false;\n \n         Substream(Type type_) : type(type_) {} /// NOLINT\n-\n         String toString() const;\n     };\n \n@@ -393,6 +394,7 @@ class ISerialization : private boost::noncopyable, public std::enable_shared_fro\n using SerializationPtr = std::shared_ptr<const ISerialization>;\n using Serializations = std::vector<SerializationPtr>;\n using SerializationByName = std::unordered_map<String, SerializationPtr>;\n+using SubstreamType = ISerialization::Substream::Type;\n \n template <typename State, typename StatePtr>\n State * ISerialization::checkAndGetState(const StatePtr & state) const\n@@ -415,6 +417,4 @@ State * ISerialization::checkAndGetState(const StatePtr & state) const\n     return state_concrete;\n }\n \n-bool isOffsetsOfNested(const ISerialization::SubstreamPath & path);\n-\n }\ndiff --git a/src/DataTypes/Serializations/SerializationArray.cpp b/src/DataTypes/Serializations/SerializationArray.cpp\nindex 0d99b741a232..6b597f2e699d 100644\n--- a/src/DataTypes/Serializations/SerializationArray.cpp\n+++ b/src/DataTypes/Serializations/SerializationArray.cpp\n@@ -230,10 +230,10 @@ void SerializationArray::enumerateStreams(\n     const auto * column_array = data.column ? &assert_cast<const ColumnArray &>(*data.column) : nullptr;\n     auto offsets = column_array ? column_array->getOffsetsPtr() : nullptr;\n \n-    auto offsets_serialization =\n-        std::make_shared<SerializationNamed>(\n-            std::make_shared<SerializationNumber<UInt64>>(),\n-                \"size\" + std::to_string(getArrayLevel(settings.path)), false);\n+    auto subcolumn_name = \"size\" + std::to_string(getArrayLevel(settings.path));\n+    auto offsets_serialization = std::make_shared<SerializationNamed>(\n+        std::make_shared<SerializationNumber<UInt64>>(),\n+        subcolumn_name, SubstreamType::NamedOffsets);\n \n     auto offsets_column = offsets && !settings.position_independent_encoding\n         ? arrayOffsetsToSizes(*offsets)\ndiff --git a/src/DataTypes/Serializations/SerializationNamed.cpp b/src/DataTypes/Serializations/SerializationNamed.cpp\nindex ca60948ce687..2792827e690e 100644\n--- a/src/DataTypes/Serializations/SerializationNamed.cpp\n+++ b/src/DataTypes/Serializations/SerializationNamed.cpp\n@@ -3,6 +3,23 @@\n namespace DB\n {\n \n+namespace ErrorCodes\n+{\n+    extern const int LOGICAL_ERROR;\n+}\n+\n+SerializationNamed::SerializationNamed(\n+    const SerializationPtr & nested_,\n+    const String & name_,\n+    SubstreamType substream_type_)\n+    : SerializationWrapper(nested_)\n+    , name(name_)\n+    , substream_type(substream_type_)\n+{\n+    if (!ISerialization::Substream::named_types.contains(substream_type))\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"SerializationNamed doesn't support substream type {}\", substream_type);\n+}\n+\n void SerializationNamed::enumerateStreams(\n     EnumerateStreamsSettings & settings,\n     const StreamCallback & callback,\n@@ -10,7 +27,7 @@ void SerializationNamed::enumerateStreams(\n {\n     addToPath(settings.path);\n     settings.path.back().data = data;\n-    settings.path.back().creator = std::make_shared<SubcolumnCreator>(name, escape_delimiter);\n+    settings.path.back().creator = std::make_shared<SubcolumnCreator>(name, substream_type);\n \n     nested_serialization->enumerateStreams(settings, callback, data);\n     settings.path.pop_back();\n@@ -70,9 +87,8 @@ void SerializationNamed::deserializeBinaryBulkWithMultipleStreams(\n \n void SerializationNamed::addToPath(SubstreamPath & path) const\n {\n-    path.push_back(Substream::TupleElement);\n-    path.back().tuple_element_name = name;\n-    path.back().escape_tuple_delimiter = escape_delimiter;\n+    path.push_back(substream_type);\n+    path.back().name_of_substream = name;\n }\n \n }\ndiff --git a/src/DataTypes/Serializations/SerializationNamed.h b/src/DataTypes/Serializations/SerializationNamed.h\nindex 52bbb0394421..0633ba2ea6f5 100644\n--- a/src/DataTypes/Serializations/SerializationNamed.h\n+++ b/src/DataTypes/Serializations/SerializationNamed.h\n@@ -1,5 +1,4 @@\n #pragma once\n-\n #include <DataTypes/Serializations/SerializationWrapper.h>\n \n namespace DB\n@@ -14,14 +13,10 @@ class SerializationNamed final : public SerializationWrapper\n {\n private:\n     String name;\n-    bool escape_delimiter;\n+    SubstreamType substream_type;\n \n public:\n-    SerializationNamed(const SerializationPtr & nested_, const String & name_, bool escape_delimiter_ = true)\n-        : SerializationWrapper(nested_)\n-        , name(name_), escape_delimiter(escape_delimiter_)\n-    {\n-    }\n+    SerializationNamed(const SerializationPtr & nested_, const String & name_, SubstreamType substream_type_);\n \n     const String & getElementName() const { return name; }\n \n@@ -61,16 +56,18 @@ class SerializationNamed final : public SerializationWrapper\n     struct SubcolumnCreator : public ISubcolumnCreator\n     {\n         const String name;\n-        const bool escape_delimiter;\n+        SubstreamType substream_type;\n \n-        SubcolumnCreator(const String & name_, bool escape_delimiter_)\n-            : name(name_), escape_delimiter(escape_delimiter_) {}\n+        SubcolumnCreator(const String & name_, SubstreamType substream_type_)\n+            : name(name_), substream_type(substream_type_)\n+        {\n+        }\n \n         DataTypePtr create(const DataTypePtr & prev) const override { return prev; }\n         ColumnPtr create(const ColumnPtr & prev) const override { return prev; }\n         SerializationPtr create(const SerializationPtr & prev) const override\n         {\n-            return std::make_shared<SerializationNamed>(prev, name, escape_delimiter);\n+            return std::make_shared<SerializationNamed>(prev, name, substream_type);\n         }\n     };\n \ndiff --git a/src/DataTypes/Serializations/SerializationNullable.cpp b/src/DataTypes/Serializations/SerializationNullable.cpp\nindex d9efc6fff107..4b0ad0b54ba0 100644\n--- a/src/DataTypes/Serializations/SerializationNullable.cpp\n+++ b/src/DataTypes/Serializations/SerializationNullable.cpp\n@@ -45,7 +45,9 @@ void SerializationNullable::enumerateStreams(\n     const auto * type_nullable = data.type ? &assert_cast<const DataTypeNullable &>(*data.type) : nullptr;\n     const auto * column_nullable = data.column ? &assert_cast<const ColumnNullable &>(*data.column) : nullptr;\n \n-    auto null_map_serialization = std::make_shared<SerializationNamed>(std::make_shared<SerializationNumber<UInt8>>(), \"null\", false);\n+    auto null_map_serialization = std::make_shared<SerializationNamed>(\n+        std::make_shared<SerializationNumber<UInt8>>(),\n+        \"null\", SubstreamType::NamedNullMap);\n \n     settings.path.push_back(Substream::NullMap);\n     auto null_map_data = SubstreamData(null_map_serialization)\ndiff --git a/src/Storages/MergeTree/IMergeTreeReader.cpp b/src/Storages/MergeTree/IMergeTreeReader.cpp\nindex 120edd81e302..63ed8021f58b 100644\n--- a/src/Storages/MergeTree/IMergeTreeReader.cpp\n+++ b/src/Storages/MergeTree/IMergeTreeReader.cpp\n@@ -1,6 +1,7 @@\n #include <Storages/MergeTree/IMergeTreeReader.h>\n #include <DataTypes/NestedUtils.h>\n #include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypeNested.h>\n #include <Common/escapeForFileName.h>\n #include <Compression/CachedCompressedReadBuffer.h>\n #include <Columns/ColumnArray.h>\n@@ -140,16 +141,29 @@ void IMergeTreeReader::evaluateMissingDefaults(Block additional_columns, Columns\n     }\n }\n \n+bool IMergeTreeReader::isSubcolumnOffsetsOfNested(const String & name_in_storage, const String & subcolumn_name) const\n+{\n+    /// We cannot read separate subcolumn with offsets from compact parts.\n+    if (!data_part_info_for_read->isWidePart() || subcolumn_name != \"size0\")\n+        return false;\n+\n+    return Nested::isSubcolumnOfNested(name_in_storage, part_columns);\n+}\n+\n String IMergeTreeReader::getColumnNameInPart(const NameAndTypePair & required_column) const\n {\n     auto name_in_storage = required_column.getNameInStorage();\n+    auto subcolumn_name = required_column.getSubcolumnName();\n+\n     if (alter_conversions->isColumnRenamed(name_in_storage))\n-    {\n         name_in_storage = alter_conversions->getColumnOldName(name_in_storage);\n-        return Nested::concatenateName(name_in_storage, required_column.getSubcolumnName());\n-    }\n \n-    return required_column.name;\n+    /// A special case when we read subcolumn of shared offsets of Nested.\n+    /// E.g. instead of requested column \"n.arr1.size0\" we must read column \"n.size0\" from disk.\n+    if (isSubcolumnOffsetsOfNested(name_in_storage, subcolumn_name))\n+        name_in_storage = Nested::splitName(name_in_storage).first;\n+\n+    return Nested::concatenateName(name_in_storage, subcolumn_name);\n }\n \n NameAndTypePair IMergeTreeReader::getColumnInPart(const NameAndTypePair & required_column) const\ndiff --git a/src/Storages/MergeTree/IMergeTreeReader.h b/src/Storages/MergeTree/IMergeTreeReader.h\nindex f3ea0c6c361b..997be064f280 100644\n--- a/src/Storages/MergeTree/IMergeTreeReader.h\n+++ b/src/Storages/MergeTree/IMergeTreeReader.h\n@@ -65,14 +65,14 @@ class IMergeTreeReader : private boost::noncopyable\n protected:\n     /// Returns actual column name in part, which can differ from table metadata.\n     String getColumnNameInPart(const NameAndTypePair & required_column) const;\n-\n     /// Returns actual column name and type in part, which can differ from table metadata.\n     NameAndTypePair getColumnInPart(const NameAndTypePair & required_column) const;\n     /// Returns actual serialization in part, which can differ from table metadata.\n     SerializationPtr getSerializationInPart(const NameAndTypePair & required_column) const;\n+    /// Returns true if requested column is a subcolumn with offsets of Array which is part of Nested column.\n+    bool isSubcolumnOffsetsOfNested(const String & name_in_storage, const String & subcolumn_name) const;\n \n     void checkNumberOfColumns(size_t num_columns_to_read) const;\n-\n     String getMessageForDiagnosticOfBrokenPart(size_t from_mark, size_t max_rows_to_read) const;\n \n     /// avg_value_size_hints are used to reduce the number of reallocations when creating columns of variable size.\ndiff --git a/src/Storages/StorageLog.cpp b/src/Storages/StorageLog.cpp\nindex fda628079c05..c7b0a9d06448 100644\n--- a/src/Storages/StorageLog.cpp\n+++ b/src/Storages/StorageLog.cpp\n@@ -104,6 +104,8 @@ class LogSource final : public ISource\n     Chunk generate() override;\n \n private:\n+    NameAndTypePair getColumnOnDisk(const NameAndTypePair & column) const;\n+\n     const size_t block_size;\n     const NamesAndTypesList columns;\n     const StorageLog & storage;\n@@ -149,6 +151,22 @@ class LogSource final : public ISource\n     bool isFinished();\n };\n \n+NameAndTypePair LogSource::getColumnOnDisk(const NameAndTypePair & column) const\n+{\n+    const auto & storage_columns = storage.columns_with_collected_nested;\n+\n+    /// A special case when we read subcolumn of shared offsets of Nested.\n+    /// E.g. instead of requested column \"n.arr1.size0\" we must read column \"n.size0\" from disk.\n+    auto name_in_storage = column.getNameInStorage();\n+    if (column.getSubcolumnName() == \"size0\" && Nested::isSubcolumnOfNested(name_in_storage, storage_columns))\n+    {\n+        auto nested_name_in_storage = Nested::splitName(name_in_storage).first;\n+        auto new_name = Nested::concatenateName(nested_name_in_storage, column.getSubcolumnName());\n+        return storage_columns.getColumnOrSubcolumn(GetColumnsOptions::All, new_name);\n+    }\n+\n+    return column;\n+}\n \n Chunk LogSource::generate()\n {\n@@ -169,19 +187,21 @@ Chunk LogSource::generate()\n     for (const auto & name_type : columns)\n     {\n         ColumnPtr column;\n+        auto name_type_on_disk = getColumnOnDisk(name_type);\n+\n         try\n         {\n-            column = name_type.type->createColumn();\n-            readData(name_type, column, max_rows_to_read, caches[name_type.getNameInStorage()]);\n+            column = name_type_on_disk.type->createColumn();\n+            readData(name_type_on_disk, column, max_rows_to_read, caches[name_type_on_disk.getNameInStorage()]);\n         }\n         catch (Exception & e)\n         {\n-            e.addMessage(\"while reading column \" + name_type.name + \" at \" + fullPath(storage.disk, storage.table_path));\n+            e.addMessage(\"while reading column \" + name_type_on_disk.name + \" at \" + fullPath(storage.disk, storage.table_path));\n             throw;\n         }\n \n         if (!column->empty())\n-            res.insert(ColumnWithTypeAndName(column, name_type.type, name_type.name));\n+            res.insert(ColumnWithTypeAndName(column, name_type_on_disk.type, name_type_on_disk.name));\n     }\n \n     if (res)\n@@ -600,6 +620,7 @@ StorageLog::StorageLog(\n         }\n     }\n \n+    columns_with_collected_nested = ColumnsDescription{Nested::collect(columns_.getAll())};\n     total_bytes = file_checker.getTotalSize();\n }\n \n@@ -820,10 +841,6 @@ Pipe StorageLog::read(\n     if (num_streams > max_streams)\n         num_streams = max_streams;\n \n-    auto options = GetColumnsOptions(GetColumnsOptions::All).withSubcolumns();\n-    auto all_columns = storage_snapshot->getColumnsByNames(options, column_names);\n-    all_columns = Nested::convertToSubcolumns(all_columns);\n-\n     std::vector<size_t> offsets;\n     offsets.resize(num_data_files, 0);\n \n@@ -840,6 +857,12 @@ Pipe StorageLog::read(\n     ReadSettings read_settings = local_context->getReadSettings();\n     Pipes pipes;\n \n+    /// Converting to subcolumns of Nested is needed for\n+    /// correct reading of parts of Nested with shared offsets.\n+    auto options = GetColumnsOptions(GetColumnsOptions::All).withSubcolumns();\n+    auto all_columns = storage_snapshot->getColumnsByNames(options, column_names);\n+    all_columns = Nested::convertToSubcolumns(all_columns);\n+\n     for (size_t stream = 0; stream < num_streams; ++stream)\n     {\n         if (use_marks_file)\ndiff --git a/src/Storages/StorageLog.h b/src/Storages/StorageLog.h\nindex 5c699b0bb459..d5daed21b3c6 100644\n--- a/src/Storages/StorageLog.h\n+++ b/src/Storages/StorageLog.h\n@@ -133,6 +133,9 @@ class StorageLog final : public IStorage, public WithMutableContext\n     size_t num_data_files = 0;\n     std::map<String, DataFile *> data_files_by_names;\n \n+    /// The same as metadata->columns but after call of Nested::collect().\n+    ColumnsDescription columns_with_collected_nested;\n+\n     /// The Log engine uses the marks file, and the TinyLog engine doesn't.\n     const bool use_marks_file;\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02240_get_type_serialization_streams.reference b/tests/queries/0_stateless/02240_get_type_serialization_streams.reference\nindex 3537720214f2..15e9bf875625 100644\n--- a/tests/queries/0_stateless/02240_get_type_serialization_streams.reference\n+++ b/tests/queries/0_stateless/02240_get_type_serialization_streams.reference\n@@ -1,8 +1,8 @@\n ['{ArraySizes}','{ArrayElements, Regular}']\n-['{ArraySizes}','{ArrayElements, TupleElement(keys, escape_tuple_delimiter = true), Regular}','{ArrayElements, TupleElement(values, escape_tuple_delimiter = true), Regular}']\n-['{TupleElement(1, escape_tuple_delimiter = true), Regular}','{TupleElement(2, escape_tuple_delimiter = true), Regular}','{TupleElement(3, escape_tuple_delimiter = true), Regular}']\n+['{ArraySizes}','{ArrayElements, TupleElement(keys), Regular}','{ArrayElements, TupleElement(values), Regular}']\n+['{TupleElement(1), Regular}','{TupleElement(2), Regular}','{TupleElement(3), Regular}']\n ['{DictionaryKeys, Regular}','{DictionaryIndexes}']\n ['{NullMap}','{NullableElements, Regular}']\n ['{ArraySizes}','{ArrayElements, Regular}']\n-['{ArraySizes}','{ArrayElements, TupleElement(keys, escape_tuple_delimiter = true), Regular}','{ArrayElements, TupleElement(values, escape_tuple_delimiter = true), Regular}']\n-['{TupleElement(1, escape_tuple_delimiter = true), Regular}','{TupleElement(2, escape_tuple_delimiter = true), Regular}','{TupleElement(3, escape_tuple_delimiter = true), Regular}','{TupleElement(4, escape_tuple_delimiter = true), Regular}']\n+['{ArraySizes}','{ArrayElements, TupleElement(keys), Regular}','{ArrayElements, TupleElement(values), Regular}']\n+['{TupleElement(1), Regular}','{TupleElement(2), Regular}','{TupleElement(3), Regular}','{TupleElement(4), Regular}']\ndiff --git a/tests/queries/0_stateless/02966_nested_offsets_subcolumn.reference.j2 b/tests/queries/0_stateless/02966_nested_offsets_subcolumn.reference.j2\nnew file mode 100644\nindex 000000000000..055b0466ee21\n--- /dev/null\n+++ b/tests/queries/0_stateless/02966_nested_offsets_subcolumn.reference.j2\n@@ -0,0 +1,11 @@\n+{% for engine in ['Memory', 'Log', 'TinyLog', 'MergeTree ORDER BY (a) SETTINGS min_bytes_for_wide_part = 0, min_rows_for_wide_part = 2000'] -%}\n+--- {{ engine }} ---\n+4500\n+4500\t4500\n+4500\n+4500\t4500\n+94500\n+94500\t94500\n+94500\n+94500\t94500\n+{% endfor -%}\ndiff --git a/tests/queries/0_stateless/02966_nested_offsets_subcolumn.sql.j2 b/tests/queries/0_stateless/02966_nested_offsets_subcolumn.sql.j2\nnew file mode 100644\nindex 000000000000..f9be206e3e70\n--- /dev/null\n+++ b/tests/queries/0_stateless/02966_nested_offsets_subcolumn.sql.j2\n@@ -0,0 +1,36 @@\n+\n+{% for engine in ['Memory', 'Log', 'TinyLog', 'MergeTree ORDER BY (a) SETTINGS min_bytes_for_wide_part = 0, min_rows_for_wide_part = 2000'] -%}\n+\n+SELECT '--- {{ engine }} ---';\n+\n+DROP TABLE IF EXISTS t_nested_offsets;\n+\n+CREATE TABLE t_nested_offsets\n+(\n+    `a` String,\n+    `e.n` Array(String),\n+    `e.t` Array(Int64)\n+)\n+ENGINE = Log;\n+\n+SYSTEM STOP MERGES t_nested_offsets;\n+\n+INSERT INTO t_nested_offsets SELECT number, range(number % 10), range(number % 10) FROM numbers(1000);\n+\n+SELECT sum(e.n.size0) FROM t_nested_offsets;\n+SELECT sum(e.n.size0), sum(e.t.size0) FROM t_nested_offsets;\n+\n+SELECT sum(length(e.n)) FROM t_nested_offsets SETTINGS optimize_functions_to_subcolumns = 1;\n+SELECT sum(length(e.n)), sum(length(e.t)) FROM t_nested_offsets SETTINGS optimize_functions_to_subcolumns = 1;\n+\n+INSERT INTO t_nested_offsets SELECT number, range(number % 10), range(number % 10) FROM numbers(20000);\n+\n+SELECT sum(e.n.size0) FROM t_nested_offsets;\n+SELECT sum(e.n.size0), sum(e.t.size0) FROM t_nested_offsets;\n+\n+SELECT sum(length(e.n)) FROM t_nested_offsets SETTINGS optimize_functions_to_subcolumns = 1;\n+SELECT sum(length(e.n)), sum(length(e.t)) FROM t_nested_offsets SETTINGS optimize_functions_to_subcolumns = 1;\n+\n+DROP TABLE t_nested_offsets;\n+\n+{% endfor -%}\n",
  "problem_statement": "size0 sometimes is incorrect\nhttps://fiddle.clickhouse.com/317cc498-98d5-448e-92f7-662d71fb8121\r\n\r\n```sql\r\nCREATE TABLE testx\r\n(\r\n    `a` String,\r\n    `e.n` Array(String),\r\n    `e.t` Array(Int64)\r\n)\r\nENGINE = MergeTree\r\nORDER BY (a)\r\nSETTINGS min_bytes_for_wide_part = 0\r\nas select '1', ['a'], [0];\r\n\r\nselect `e.n` from testx;\r\n\u250c\u2500e.n\u2500\u2500\u2500\u2510\r\n\u2502 ['a'] \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nselect `e.n`.size0 from testx;\r\n0 rows in set. Elapsed: 0.001 sec.  ----<<<<<<<<<<<<<<<- expected 1\r\n\r\n\r\nselect  max(length(`e.n`)) from testx settings optimize_functions_to_subcolumns=0;\r\n\u250c\u2500max(length(e.n))\u2500\u2510\r\n\u2502                1 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nselect  max(length(`e.n`)) from testx settings optimize_functions_to_subcolumns=1;\r\n\u250c\u2500max(e.n.size0)\u2500\u2510\r\n\u2502              0 \u2502  ----<<<<<<<<<<<<<<<- expected 1\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n\r\n\n",
  "hints_text": "related to https://github.com/ClickHouse/ClickHouse/issues/33546",
  "created_at": "2024-01-11T21:57:42Z"
}