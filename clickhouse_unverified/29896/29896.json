{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 29896,
  "instance_id": "ClickHouse__ClickHouse-29896",
  "issue_numbers": [
    "29697"
  ],
  "base_commit": "a9a7fd94cd665581b3e99714c5e982cff351e0bb",
  "patch": "diff --git a/docs/en/operations/system-tables/data_skipping_indices.md b/docs/en/operations/system-tables/data_skipping_indices.md\nindex 683666e1f77a..add89ae91446 100644\n--- a/docs/en/operations/system-tables/data_skipping_indices.md\n+++ b/docs/en/operations/system-tables/data_skipping_indices.md\n@@ -10,6 +10,9 @@ Columns:\n -   `type` ([String](../../sql-reference/data-types/string.md)) \u2014 Index type.\n -   `expr` ([String](../../sql-reference/data-types/string.md)) \u2014 Expression for the index calculation.\n -   `granularity` ([UInt64](../../sql-reference/data-types/int-uint.md)) \u2014 The number of granules in the block.\n+-   `data_compressed_bytes` ([UInt64](../../sql-reference/data-types/int-uint.md)) \u2014 The size of compressed data, in bytes.\n+-   `data_uncompressed_bytes` ([UInt64](../../sql-reference/data-types/int-uint.md)) \u2014 The size of decompressed data, in bytes.\n+-   `marks_bytes` ([UInt64](../../sql-reference/data-types/int-uint.md)) \u2014 The size of marks, in bytes.\n \n **Example**\n \n@@ -26,6 +29,9 @@ name:        clicks_idx\n type:        minmax\n expr:        clicks\n granularity: 1\n+data_compressed_bytes:   58\n+data_uncompressed_bytes: 6\n+marks:                   48\n \n Row 2:\n \u2500\u2500\u2500\u2500\u2500\u2500\n@@ -35,4 +41,7 @@ name:        contacts_null_idx\n type:        minmax\n expr:        assumeNotNull(contacts_null)\n granularity: 1\n+data_compressed_bytes:   58\n+data_uncompressed_bytes: 6\n+marks:                   48\n ```\ndiff --git a/docs/en/operations/system-tables/parts.md b/docs/en/operations/system-tables/parts.md\nindex 51a0a1180f31..45fdcc404513 100644\n--- a/docs/en/operations/system-tables/parts.md\n+++ b/docs/en/operations/system-tables/parts.md\n@@ -38,6 +38,12 @@ Columns:\n \n -   `marks_bytes` ([UInt64](../../sql-reference/data-types/int-uint.md)) \u2013 The size of the file with marks.\n \n+-   `secondary_indices_compressed_bytes` ([UInt64](../../sql-reference/data-types/int-uint.md)) \u2013 Total size of compressed data for secondary indices in the data part. All the auxiliary files (for example, files with marks) are not included.\n+\n+-   `secondary_indices_uncompressed_bytes` ([UInt64](../../sql-reference/data-types/int-uint.md)) \u2013 Total size of uncompressed data for secondary indices in the data part. All the auxiliary files (for example, files with marks) are not included.\n+\n+-   `secondary_indices_marks_bytes` ([UInt64](../../sql-reference/data-types/int-uint.md)) \u2013 The size of the file with marks for secondary indices.\n+\n -   `modification_time` ([DateTime](../../sql-reference/data-types/datetime.md)) \u2013 The time the directory with the data part was modified. This usually corresponds to the time of data part creation.\n \n -   `remove_time` ([DateTime](../../sql-reference/data-types/datetime.md)) \u2013 The time when the data part became inactive.\n@@ -119,6 +125,9 @@ rows:                                  6\n bytes_on_disk:                         310\n data_compressed_bytes:                 157\n data_uncompressed_bytes:               91\n+secondary_indices_compressed_bytes:    58\n+secondary_indices_uncompressed_bytes:  6\n+secondary_indices_marks_bytes:         48\n marks_bytes:                           144\n modification_time:                     2020-06-18 13:01:49\n remove_time:                           1970-01-01 00:00:00\ndiff --git a/src/Storages/IStorage.h b/src/Storages/IStorage.h\nindex 6ce17552ba11..0a9d11136017 100644\n--- a/src/Storages/IStorage.h\n+++ b/src/Storages/IStorage.h\n@@ -87,6 +87,8 @@ struct ColumnSize\n     }\n };\n \n+using IndexSize = ColumnSize;\n+\n /** Storage. Describes the table. Responsible for\n   * - storage of the table data;\n   * - the definition in which files (or not in files) the data is stored;\n@@ -163,6 +165,11 @@ class IStorage : public std::enable_shared_from_this<IStorage>, public TypePromo\n     using ColumnSizeByName = std::unordered_map<std::string, ColumnSize>;\n     virtual ColumnSizeByName getColumnSizes() const { return {}; }\n \n+    /// Optional size information of each secondary index.\n+    /// Valid only for MergeTree family.\n+    using IndexSizeByName = std::unordered_map<std::string, IndexSize>;\n+    virtual IndexSizeByName getSecondaryIndexSizes() const { return {}; }\n+\n     /// Get mutable version (snapshot) of storage metadata. Metadata object is\n     /// multiversion, so it can be concurrently changed, but returned copy can be\n     /// used without any locks.\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\nindex dc2c5f8185d1..0f701cc4adfe 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n@@ -584,7 +584,7 @@ void IMergeTreeDataPart::loadColumnsChecksumsIndexes(bool require_columns_checks\n     loadColumns(require_columns_checksums);\n     loadChecksums(require_columns_checksums);\n     loadIndexGranularity();\n-    calculateColumnsSizesOnDisk();\n+    calculateColumnsAndSecondaryIndicesSizesOnDisk();\n     loadIndex();     /// Must be called after loadIndexGranularity as it uses the value of `index_granularity`\n     loadRowsCount(); /// Must be called after loadIndexGranularity() as it uses the value of `index_granularity`.\n     loadPartitionAndMinMaxIndex();\n@@ -1420,6 +1420,11 @@ void IMergeTreeDataPart::checkConsistency(bool /* require_part_metadata */) cons\n     throw Exception(\"Method 'checkConsistency' is not implemented for part with type \" + getType().toString(), ErrorCodes::NOT_IMPLEMENTED);\n }\n \n+void IMergeTreeDataPart::calculateColumnsAndSecondaryIndicesSizesOnDisk()\n+{\n+    calculateColumnsSizesOnDisk();\n+    calculateSecondaryIndicesSizesOnDisk();\n+}\n \n void IMergeTreeDataPart::calculateColumnsSizesOnDisk()\n {\n@@ -1429,6 +1434,41 @@ void IMergeTreeDataPart::calculateColumnsSizesOnDisk()\n     calculateEachColumnSizes(columns_sizes, total_columns_size);\n }\n \n+void IMergeTreeDataPart::calculateSecondaryIndicesSizesOnDisk()\n+{\n+    if (checksums.empty())\n+        throw Exception(\"Cannot calculate secondary indexes sizes when columns or checksums are not initialized\", ErrorCodes::LOGICAL_ERROR);\n+\n+    auto secondary_indices_descriptions = storage.getInMemoryMetadataPtr()->secondary_indices;\n+\n+    for (auto & index_description : secondary_indices_descriptions)\n+    {\n+        ColumnSize index_size;\n+\n+        auto index_ptr = MergeTreeIndexFactory::instance().get(index_description);\n+        auto index_name = index_ptr->getFileName();\n+        auto index_name_escaped = escapeForFileName(index_name);\n+\n+        auto index_file_name = index_name_escaped + index_ptr->getSerializedFileExtension();\n+        auto index_marks_file_name = index_name_escaped + index_granularity_info.marks_file_extension;\n+\n+        /// If part does not contain index\n+        auto bin_checksum = checksums.files.find(index_file_name);\n+        if (bin_checksum != checksums.files.end())\n+        {\n+            index_size.data_compressed = bin_checksum->second.file_size;\n+            index_size.data_uncompressed = bin_checksum->second.uncompressed_size;\n+        }\n+\n+        auto mrk_checksum = checksums.files.find(index_marks_file_name);\n+        if (mrk_checksum != checksums.files.end())\n+            index_size.marks = mrk_checksum->second.file_size;\n+\n+        total_secondary_indices_size.add(index_size);\n+        secondary_index_sizes[index_description.name] = index_size;\n+    }\n+}\n+\n ColumnSize IMergeTreeDataPart::getColumnSize(const String & column_name, const IDataType & /* type */) const\n {\n     /// For some types of parts columns_size maybe not calculated\n@@ -1439,6 +1479,15 @@ ColumnSize IMergeTreeDataPart::getColumnSize(const String & column_name, const I\n     return ColumnSize{};\n }\n \n+IndexSize IMergeTreeDataPart::getSecondaryIndexSize(const String & secondary_index_name) const\n+{\n+    auto it = secondary_index_sizes.find(secondary_index_name);\n+    if (it != secondary_index_sizes.end())\n+        return it->second;\n+\n+    return ColumnSize{};\n+}\n+\n void IMergeTreeDataPart::accumulateColumnSizes(ColumnToSize & column_to_size) const\n {\n     for (const auto & [column_name, size] : columns_sizes)\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.h b/src/Storages/MergeTree/IMergeTreeDataPart.h\nindex be48aed5c8b1..ceb3ed641706 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.h\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.h\n@@ -55,6 +55,8 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     using ColumnSizeByName = std::unordered_map<std::string, ColumnSize>;\n     using NameToNumber = std::unordered_map<std::string, size_t>;\n \n+    using IndexSizeByName = std::unordered_map<std::string, ColumnSize>;\n+\n     using Type = MergeTreeDataPartType;\n \n \n@@ -101,9 +103,16 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     /// Otherwise return information about column size on disk.\n     ColumnSize getColumnSize(const String & column_name, const IDataType & /* type */) const;\n \n+    /// NOTE: Returns zeros if secondary indexes are not found in checksums.\n+    /// Otherwise return information about secondary index size on disk.\n+    IndexSize getSecondaryIndexSize(const String & secondary_index_name) const;\n+\n     /// Return information about column size on disk for all columns in part\n     ColumnSize getTotalColumnsSize() const { return total_columns_size; }\n \n+    /// Return information about secondary indexes size on disk for all indexes in part\n+    IndexSize getTotalSeconaryIndicesSize() const { return total_secondary_indices_size; }\n+\n     virtual String getFileNameForColumn(const NameAndTypePair & column) const = 0;\n \n     virtual ~IMergeTreeDataPart();\n@@ -341,7 +350,9 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n \n     /// Calculate the total size of the entire directory with all the files\n     static UInt64 calculateTotalSizeOnDisk(const DiskPtr & disk_, const String & from);\n-    void calculateColumnsSizesOnDisk();\n+\n+    /// Calculate column and secondary indices sizes on disk.\n+    void calculateColumnsAndSecondaryIndicesSizesOnDisk();\n \n     String getRelativePathForPrefix(const String & prefix) const;\n \n@@ -396,6 +407,10 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     /// Size for each column, calculated once in calcuateColumnSizesOnDisk\n     ColumnSizeByName columns_sizes;\n \n+    ColumnSize total_secondary_indices_size;\n+\n+    IndexSizeByName secondary_index_sizes;\n+\n     /// Total size on disk, not only columns. May not contain size of\n     /// checksums.txt and columns.txt. 0 - if not counted;\n     UInt64 bytes_on_disk{0};\n@@ -450,6 +465,10 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n \n     void loadPartitionAndMinMaxIndex();\n \n+    void calculateColumnsSizesOnDisk();\n+\n+    void calculateSecondaryIndicesSizesOnDisk();\n+\n     /// Load default compression codec from file default_compression_codec.txt\n     /// if it not exists tries to deduce codec from compressed column without\n     /// any specifial compression.\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex c04e0d2e38ff..f9c262254407 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -1167,7 +1167,7 @@ void MergeTreeData::loadDataParts(bool skip_sanity_checks)\n         }\n     }\n \n-    calculateColumnSizesImpl();\n+    calculateColumnAndSecondaryIndexSizesImpl();\n \n \n     LOG_DEBUG(log, \"Loaded data parts ({} items)\", data_parts_indexes.size());\n@@ -2352,7 +2352,7 @@ bool MergeTreeData::renameTempPartAndReplace(\n         {\n             covered_part->remove_time.store(current_time, std::memory_order_relaxed);\n             modifyPartState(covered_part, DataPartState::Outdated);\n-            removePartContributionToColumnSizes(covered_part);\n+            removePartContributionToColumnAndSecondaryIndexSizes(covered_part);\n             reduce_bytes += covered_part->getBytesOnDisk();\n             reduce_rows += covered_part->rows_count;\n             ++reduce_parts;\n@@ -2361,7 +2361,7 @@ bool MergeTreeData::renameTempPartAndReplace(\n         decreaseDataVolume(reduce_bytes, reduce_rows, reduce_parts);\n \n         modifyPartState(part_it, DataPartState::Committed);\n-        addPartContributionToColumnSizes(part);\n+        addPartContributionToColumnAndSecondaryIndexSizes(part);\n         addPartContributionToDataVolume(part);\n     }\n \n@@ -2404,7 +2404,7 @@ void MergeTreeData::removePartsFromWorkingSet(const MergeTreeData::DataPartsVect\n     {\n         if (part->getState() == IMergeTreeDataPart::State::Committed)\n         {\n-            removePartContributionToColumnSizes(part);\n+            removePartContributionToColumnAndSecondaryIndexSizes(part);\n             removePartContributionToDataVolume(part);\n         }\n \n@@ -2542,7 +2542,7 @@ restore_covered)\n     if (part->getState() == DataPartState::Committed)\n     {\n         removePartContributionToDataVolume(part);\n-        removePartContributionToColumnSizes(part);\n+        removePartContributionToColumnAndSecondaryIndexSizes(part);\n     }\n     modifyPartState(it_part, DataPartState::Deleting);\n \n@@ -2590,7 +2590,7 @@ restore_covered)\n \n                 if ((*it)->getState() != DataPartState::Committed)\n                 {\n-                    addPartContributionToColumnSizes(*it);\n+                    addPartContributionToColumnAndSecondaryIndexSizes(*it);\n                     addPartContributionToDataVolume(*it);\n                     modifyPartState(it, DataPartState::Committed); // iterator is not invalidated here\n                 }\n@@ -2621,7 +2621,7 @@ restore_covered)\n \n             if ((*it)->getState() != DataPartState::Committed)\n             {\n-                addPartContributionToColumnSizes(*it);\n+                addPartContributionToColumnAndSecondaryIndexSizes(*it);\n                 addPartContributionToDataVolume(*it);\n                 modifyPartState(it, DataPartState::Committed);\n             }\n@@ -2973,17 +2973,17 @@ static void loadPartAndFixMetadataImpl(MergeTreeData::MutableDataPartPtr part)\n     part->modification_time = disk->getLastModified(full_part_path).epochTime();\n }\n \n-void MergeTreeData::calculateColumnSizesImpl()\n+void MergeTreeData::calculateColumnAndSecondaryIndexSizesImpl()\n {\n     column_sizes.clear();\n \n     /// Take into account only committed parts\n     auto committed_parts_range = getDataPartsStateRange(DataPartState::Committed);\n     for (const auto & part : committed_parts_range)\n-        addPartContributionToColumnSizes(part);\n+        addPartContributionToColumnAndSecondaryIndexSizes(part);\n }\n \n-void MergeTreeData::addPartContributionToColumnSizes(const DataPartPtr & part)\n+void MergeTreeData::addPartContributionToColumnAndSecondaryIndexSizes(const DataPartPtr & part)\n {\n     for (const auto & column : part->getColumns())\n     {\n@@ -2991,9 +2991,17 @@ void MergeTreeData::addPartContributionToColumnSizes(const DataPartPtr & part)\n         ColumnSize part_column_size = part->getColumnSize(column.name, *column.type);\n         total_column_size.add(part_column_size);\n     }\n+\n+    auto indexes_descriptions = getInMemoryMetadataPtr()->secondary_indices;\n+    for (const auto & index : indexes_descriptions)\n+    {\n+        IndexSize & total_secondary_index_size = secondary_index_sizes[index.name];\n+        IndexSize part_index_size = part->getSecondaryIndexSize(index.name);\n+        total_secondary_index_size.add(part_index_size);\n+    }\n }\n \n-void MergeTreeData::removePartContributionToColumnSizes(const DataPartPtr & part)\n+void MergeTreeData::removePartContributionToColumnAndSecondaryIndexSizes(const DataPartPtr & part)\n {\n     for (const auto & column : part->getColumns())\n     {\n@@ -3013,6 +3021,26 @@ void MergeTreeData::removePartContributionToColumnSizes(const DataPartPtr & part\n         log_subtract(total_column_size.data_uncompressed, part_column_size.data_uncompressed, \".data_uncompressed\");\n         log_subtract(total_column_size.marks, part_column_size.marks, \".marks\");\n     }\n+\n+    auto indexes_descriptions = getInMemoryMetadataPtr()->secondary_indices;\n+    for (const auto & index : indexes_descriptions)\n+    {\n+        IndexSize & total_secondary_index_size = secondary_index_sizes[index.name];\n+        IndexSize part_secondary_index_size = part->getSecondaryIndexSize(index.name);\n+\n+        auto log_subtract = [&](size_t & from, size_t value, const char * field)\n+        {\n+            if (value > from)\n+                LOG_ERROR(log, \"Possibly incorrect index size subtraction: {} - {} = {}, index: {}, field: {}\",\n+                    from, value, from - value, index.name, field);\n+\n+            from -= value;\n+        };\n+\n+        log_subtract(total_secondary_index_size.data_compressed, part_secondary_index_size.data_compressed, \".data_compressed\");\n+        log_subtract(total_secondary_index_size.data_uncompressed, part_secondary_index_size.data_uncompressed, \".data_uncompressed\");\n+        log_subtract(total_secondary_index_size.marks, part_secondary_index_size.marks, \".marks\");\n+    }\n }\n \n void MergeTreeData::checkAlterPartitionIsPossible(\n@@ -4043,7 +4071,7 @@ MergeTreeData::DataPartsVector MergeTreeData::Transaction::commit(MergeTreeData:\n                     reduce_rows += covered_part->rows_count;\n \n                     data.modifyPartState(covered_part, DataPartState::Outdated);\n-                    data.removePartContributionToColumnSizes(covered_part);\n+                    data.removePartContributionToColumnAndSecondaryIndexSizes(covered_part);\n                 }\n                 reduce_parts += covered_parts.size();\n \n@@ -4052,7 +4080,7 @@ MergeTreeData::DataPartsVector MergeTreeData::Transaction::commit(MergeTreeData:\n                 ++add_parts;\n \n                 data.modifyPartState(part, DataPartState::Committed);\n-                data.addPartContributionToColumnSizes(part);\n+                data.addPartContributionToColumnAndSecondaryIndexSizes(part);\n             }\n         }\n         data.decreaseDataVolume(reduce_bytes, reduce_rows, reduce_parts);\ndiff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h\nindex bdebd5e9187b..0e0e84d011b5 100644\n--- a/src/Storages/MergeTree/MergeTreeData.h\n+++ b/src/Storages/MergeTree/MergeTreeData.h\n@@ -654,6 +654,12 @@ class MergeTreeData : public IStorage, public WithMutableContext\n         return column_sizes;\n     }\n \n+    IndexSizeByName getSecondaryIndexSizes() const override\n+    {\n+        auto lock = lockParts();\n+        return secondary_index_sizes;\n+    }\n+\n     /// For ATTACH/DETACH/DROP PARTITION.\n     String getPartitionIDFromQuery(const ASTPtr & ast, ContextPtr context) const;\n     std::unordered_set<String> getPartitionIDsFromQuery(const ASTs & asts, ContextPtr context) const;\n@@ -873,6 +879,9 @@ class MergeTreeData : public IStorage, public WithMutableContext\n     /// Current column sizes in compressed and uncompressed form.\n     ColumnSizeByName column_sizes;\n \n+    /// Current secondary index sizes in compressed and uncompressed form.\n+    IndexSizeByName secondary_index_sizes;\n+\n     /// Engine-specific methods\n     BrokenPartCallback broken_part_callback;\n \n@@ -1005,11 +1014,12 @@ class MergeTreeData : public IStorage, public WithMutableContext\n \n     void checkStoragePolicy(const StoragePolicyPtr & new_storage_policy) const;\n \n-    /// Calculates column sizes in compressed form for the current state of data_parts. Call with data_parts mutex locked.\n-    void calculateColumnSizesImpl();\n-    /// Adds or subtracts the contribution of the part to compressed column sizes.\n-    void addPartContributionToColumnSizes(const DataPartPtr & part);\n-    void removePartContributionToColumnSizes(const DataPartPtr & part);\n+    /// Calculates column and secondary indexes sizes in compressed form for the current state of data_parts. Call with data_parts mutex locked.\n+    void calculateColumnAndSecondaryIndexSizesImpl();\n+\n+    /// Adds or subtracts the contribution of the part to compressed column and secondary indexes sizes.\n+    void addPartContributionToColumnAndSecondaryIndexSizes(const DataPartPtr & part);\n+    void removePartContributionToColumnAndSecondaryIndexSizes(const DataPartPtr & part);\n \n     /// If there is no part in the partition with ID `partition_id`, returns empty ptr. Should be called under the lock.\n     DataPartPtr getAnyPartInPartition(const String & partition_id, DataPartsLock & data_parts_lock) const;\ndiff --git a/src/Storages/MergeTree/MergedBlockOutputStream.cpp b/src/Storages/MergeTree/MergedBlockOutputStream.cpp\nindex 5206f77290bd..431467096865 100644\n--- a/src/Storages/MergeTree/MergedBlockOutputStream.cpp\n+++ b/src/Storages/MergeTree/MergedBlockOutputStream.cpp\n@@ -87,7 +87,8 @@ void MergedBlockOutputStream::writeSuffixAndFinalizePart(\n     new_part->checksums = checksums;\n     new_part->setBytesOnDisk(checksums.getTotalSizeOnDisk());\n     new_part->index_granularity = writer->getIndexGranularity();\n-    new_part->calculateColumnsSizesOnDisk();\n+    new_part->calculateColumnsAndSecondaryIndicesSizesOnDisk();\n+\n     if (default_codec != nullptr)\n         new_part->default_codec = default_codec;\n     new_part->storage.lockSharedData(*new_part);\ndiff --git a/src/Storages/MergeTree/MutateTask.cpp b/src/Storages/MergeTree/MutateTask.cpp\nindex b8941fc9d84c..115de043cd24 100644\n--- a/src/Storages/MergeTree/MutateTask.cpp\n+++ b/src/Storages/MergeTree/MutateTask.cpp\n@@ -475,7 +475,7 @@ void finalizeMutatedPart(\n     new_data_part->setBytesOnDisk(\n         MergeTreeData::DataPart::calculateTotalSizeOnDisk(new_data_part->volume->getDisk(), new_data_part->getFullRelativePath()));\n     new_data_part->default_codec = codec;\n-    new_data_part->calculateColumnsSizesOnDisk();\n+    new_data_part->calculateColumnsAndSecondaryIndicesSizesOnDisk();\n     new_data_part->storage.lockSharedData(*new_data_part);\n }\n \ndiff --git a/src/Storages/System/StorageSystemDataSkippingIndices.cpp b/src/Storages/System/StorageSystemDataSkippingIndices.cpp\nindex 7a6ce4ec5198..d7fc06da9534 100644\n--- a/src/Storages/System/StorageSystemDataSkippingIndices.cpp\n+++ b/src/Storages/System/StorageSystemDataSkippingIndices.cpp\n@@ -25,6 +25,9 @@ StorageSystemDataSkippingIndices::StorageSystemDataSkippingIndices(const Storage\n             { \"type\", std::make_shared<DataTypeString>() },\n             { \"expr\", std::make_shared<DataTypeString>() },\n             { \"granularity\", std::make_shared<DataTypeUInt64>() },\n+            { \"data_compressed_bytes\", std::make_shared<DataTypeUInt64>() },\n+            { \"data_uncompressed_bytes\", std::make_shared<DataTypeUInt64>() },\n+            { \"marks\", std::make_shared<DataTypeUInt64>()}\n         }));\n     setInMemoryMetadata(storage_metadata);\n }\n@@ -97,6 +100,7 @@ class DataSkippingIndicesSource : public SourceWithProgress\n                     continue;\n                 const auto indices = metadata_snapshot->getSecondaryIndices();\n \n+                auto secondary_index_sizes = table->getSecondaryIndexSizes();\n                 for (const auto & index : indices)\n                 {\n                     ++rows_count;\n@@ -127,6 +131,21 @@ class DataSkippingIndicesSource : public SourceWithProgress\n                     // 'granularity' column\n                     if (column_mask[src_index++])\n                         res_columns[res_index++]->insert(index.granularity);\n+\n+                    auto & secondary_index_size = secondary_index_sizes[index.name];\n+\n+                    // 'compressed bytes' column\n+                    if (column_mask[src_index++])\n+                        res_columns[res_index++]->insert(secondary_index_size.data_compressed);\n+\n+                    // 'uncompressed bytes' column\n+\n+                    if (column_mask[src_index++])\n+                        res_columns[res_index++]->insert(secondary_index_size.data_uncompressed);\n+\n+                    /// 'marks' column\n+                    if (column_mask[src_index++])\n+                        res_columns[res_index++]->insert(secondary_index_size.marks);\n                 }\n             }\n         }\ndiff --git a/src/Storages/System/StorageSystemParts.cpp b/src/Storages/System/StorageSystemParts.cpp\nindex e79978463dda..6826082ef1db 100644\n--- a/src/Storages/System/StorageSystemParts.cpp\n+++ b/src/Storages/System/StorageSystemParts.cpp\n@@ -30,6 +30,9 @@ StorageSystemParts::StorageSystemParts(const StorageID & table_id_)\n         {\"data_compressed_bytes\",                       std::make_shared<DataTypeUInt64>()},\n         {\"data_uncompressed_bytes\",                     std::make_shared<DataTypeUInt64>()},\n         {\"marks_bytes\",                                 std::make_shared<DataTypeUInt64>()},\n+        {\"secondary_indices_compressed_bytes\",          std::make_shared<DataTypeUInt64>()},\n+        {\"secondary_indices_uncompressed_bytes\",        std::make_shared<DataTypeUInt64>()},\n+        {\"secondary_indices_marks_bytes\",               std::make_shared<DataTypeUInt64>()},\n         {\"modification_time\",                           std::make_shared<DataTypeDateTime>()},\n         {\"remove_time\",                                 std::make_shared<DataTypeDateTime>()},\n         {\"refcount\",                                    std::make_shared<DataTypeUInt32>()},\n@@ -98,6 +101,7 @@ void StorageSystemParts::processNextStorage(\n         auto part_state = all_parts_state[part_number];\n \n         ColumnSize columns_size = part->getTotalColumnsSize();\n+        ColumnSize secondary_indexes_size = part->getTotalSeconaryIndicesSize();\n \n         size_t src_index = 0, res_index = 0;\n         if (columns_mask[src_index++])\n@@ -126,6 +130,12 @@ void StorageSystemParts::processNextStorage(\n             columns[res_index++]->insert(columns_size.data_uncompressed);\n         if (columns_mask[src_index++])\n             columns[res_index++]->insert(columns_size.marks);\n+        if (columns_mask[src_index++])\n+            columns[res_index++]->insert(secondary_indexes_size.data_compressed);\n+        if (columns_mask[src_index++])\n+            columns[res_index++]->insert(secondary_indexes_size.data_uncompressed);\n+        if (columns_mask[src_index++])\n+            columns[res_index++]->insert(secondary_indexes_size.marks);\n         if (columns_mask[src_index++])\n             columns[res_index++]->insert(static_cast<UInt64>(part->modification_time));\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01917_system_data_skipping_indices.reference b/tests/queries/0_stateless/01917_system_data_skipping_indices.reference\nindex b5a4b596a97e..115d60f60ccc 100644\n--- a/tests/queries/0_stateless/01917_system_data_skipping_indices.reference\n+++ b/tests/queries/0_stateless/01917_system_data_skipping_indices.reference\n@@ -1,8 +1,8 @@\n-default\tdata_01917\td1_idx\tminmax\td1\t1\n-default\tdata_01917\td1_null_idx\tminmax\tassumeNotNull(d1_null)\t1\n-default\tdata_01917_2\tmemory\tset\tfrequency * length(name)\t5\n-default\tdata_01917_2\tsample_index1\tminmax\tlength(name), name\t4\n-default\tdata_01917_2\tsample_index2\tngrambf_v1\tlower(name), name\t4\n+default\tdata_01917\td1_idx\tminmax\td1\t1\t0\t0\t0\n+default\tdata_01917\td1_null_idx\tminmax\tassumeNotNull(d1_null)\t1\t0\t0\t0\n+default\tdata_01917_2\tmemory\tset\tfrequency * length(name)\t5\t0\t0\t0\n+default\tdata_01917_2\tsample_index1\tminmax\tlength(name), name\t4\t0\t0\t0\n+default\tdata_01917_2\tsample_index2\tngrambf_v1\tlower(name), name\t4\t0\t0\t0\n 2\n 3\n d1_idx\ndiff --git a/tests/queries/0_stateless/01932_alter_index_with_order.reference b/tests/queries/0_stateless/01932_alter_index_with_order.reference\nindex 07e1aab3df9f..eff9ea7da0e9 100644\n--- a/tests/queries/0_stateless/01932_alter_index_with_order.reference\n+++ b/tests/queries/0_stateless/01932_alter_index_with_order.reference\n@@ -1,9 +1,9 @@\n-default\talter_index_test\tindex_a\tset\ta\t1\n-default\talter_index_test\tindex_b\tminmax\tb\t1\n-default\talter_index_test\tindex_c\tset\tc\t2\n-default\talter_index_test\tindex_a\tset\ta\t1\n-default\talter_index_test\tindex_d\tset\td\t1\n-default\talter_index_test\tindex_b\tminmax\tb\t1\n-default\talter_index_test\tindex_c\tset\tc\t2\n-default\talter_index_test\tindex_a\tset\ta\t1\n-default\talter_index_test\tindex_d\tset\td\t1\n+default\talter_index_test\tindex_a\tset\ta\t1\t0\t0\t0\n+default\talter_index_test\tindex_b\tminmax\tb\t1\t0\t0\t0\n+default\talter_index_test\tindex_c\tset\tc\t2\t0\t0\t0\n+default\talter_index_test\tindex_a\tset\ta\t1\t0\t0\t0\n+default\talter_index_test\tindex_d\tset\td\t1\t0\t0\t0\n+default\talter_index_test\tindex_b\tminmax\tb\t1\t0\t0\t0\n+default\talter_index_test\tindex_c\tset\tc\t2\t0\t0\t0\n+default\talter_index_test\tindex_a\tset\ta\t1\t0\t0\t0\n+default\talter_index_test\tindex_d\tset\td\t1\t0\t0\t0\ndiff --git a/tests/queries/0_stateless/2028_system_data_skipping_indices_size.reference b/tests/queries/0_stateless/2028_system_data_skipping_indices_size.reference\nnew file mode 100644\nindex 000000000000..d03785118509\n--- /dev/null\n+++ b/tests/queries/0_stateless/2028_system_data_skipping_indices_size.reference\n@@ -0,0 +1,1 @@\n+default\ttest_table\tvalue_index\tminmax\tvalue\t1\t38\t12\t24\ndiff --git a/tests/queries/0_stateless/2028_system_data_skipping_indices_size.sql b/tests/queries/0_stateless/2028_system_data_skipping_indices_size.sql\nnew file mode 100644\nindex 000000000000..e77f88aa36f4\n--- /dev/null\n+++ b/tests/queries/0_stateless/2028_system_data_skipping_indices_size.sql\n@@ -0,0 +1,15 @@\n+DROP TABLE IF EXISTS test_table;\n+\n+CREATE TABLE test_table\n+(\n+    key UInt64,\n+    value String,\n+    INDEX value_index value TYPE minmax GRANULARITY 1\n+)\n+Engine=MergeTree()\n+ORDER BY key;\n+\n+INSERT INTO test_table VALUES (0, 'Value');\n+SELECT * FROM system.data_skipping_indices WHERE database = currentDatabase();\n+\n+DROP TABLE test_table;\n",
  "problem_statement": "There is no info about the size of the index in the `system.data_skipping_indices` table.\n**Use case**\r\n\r\n```\r\ngithub-explorer.ru-central1.internal :) SELECT * FROM system.data_skipping_indices \\G\r\n\r\nSELECT *\r\nFROM system.data_skipping_indices\r\n\r\nQuery id: 78c8170b-9cf0-40be-970f-31cb3ccf6573\r\n\r\nRow 1:\r\n\u2500\u2500\u2500\u2500\u2500\u2500\r\ndatabase:    default\r\ntable:       hackernews\r\nname:        text_pentagram\r\ntype:        ngrambf_v1\r\nexpr:        text\r\ngranularity: 1\r\n\r\n1 rows in set. Elapsed: 0.002 sec.\r\n```\r\n\r\nI want to know what is the size.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd the columns about compressed and uncompressed size.\n",
  "hints_text": "",
  "created_at": "2021-10-08T13:14:49Z"
}