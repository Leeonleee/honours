{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 74289,
  "instance_id": "ClickHouse__ClickHouse-74289",
  "issue_numbers": [
    "74083"
  ],
  "base_commit": "a4678063b3cba453b39a0bd689821ad72ff74f32",
  "patch": "diff --git a/src/Storages/System/StorageSystemDetachedTables.cpp b/src/Storages/System/StorageSystemDetachedTables.cpp\nindex a1ed491aff3f..e423aec53f94 100644\n--- a/src/Storages/System/StorageSystemDetachedTables.cpp\n+++ b/src/Storages/System/StorageSystemDetachedTables.cpp\n@@ -93,7 +93,11 @@ class DetachedTablesBlockSource : public ISource\n             }\n \n              if (rows_count == max_block_size)\n+             {\n+                if (!detached_tables_it->isValid())\n+                    ++database_idx;\n                 break;\n+             }\n         }\n \n         if (databases->size() == database_idx)\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03172_system_detached_tables_no_loop.reference b/tests/queries/0_stateless/03172_system_detached_tables_no_loop.reference\nindex 7c727227ef38..879eede31b49 100644\n--- a/tests/queries/0_stateless/03172_system_detached_tables_no_loop.reference\n+++ b/tests/queries/0_stateless/03172_system_detached_tables_no_loop.reference\n@@ -1,3 +1,6 @@\n -----------------------\n detached table no loop\n 9\n+-----------------------\n+max_block_size is equal to the amount of tables\n+3\ndiff --git a/tests/queries/0_stateless/03172_system_detached_tables_no_loop.sql b/tests/queries/0_stateless/03172_system_detached_tables_no_loop.sql\nindex 96043dd0ea37..7bc39543d834 100644\n--- a/tests/queries/0_stateless/03172_system_detached_tables_no_loop.sql\n+++ b/tests/queries/0_stateless/03172_system_detached_tables_no_loop.sql\n@@ -28,3 +28,20 @@ DETACH TABLE test_no_loop.t8;\n SELECT count(*) FROM system.detached_tables WHERE database='test_no_loop';\n \n DROP DATABASE test_no_loop;\n+\n+SELECT '-----------------------';\n+SELECT 'max_block_size is equal to the amount of tables';\n+\n+DROP DATABASE IF EXISTS test_no_loop_2;\n+CREATE DATABASE test_no_loop_2;\n+\n+SET max_block_size = 3;\n+CREATE TABLE test_no_loop_2.t0 (c0 Int) ENGINE = MergeTree ORDER BY c0;\n+CREATE TABLE test_no_loop_2.t1 (c0 Int) ENGINE = MergeTree ORDER BY c0;\n+CREATE TABLE test_no_loop_2.t2 (c0 Int) ENGINE = MergeTree ORDER BY c0;\n+DETACH TABLE test_no_loop_2.t0;\n+DETACH TABLE test_no_loop_2.t1;\n+DETACH TABLE test_no_loop_2.t2;\n+SELECT count(*) FROM system.detached_tables WHERE database='test_no_loop_2';\n+\n+DROP DATABASE test_no_loop_2;\n",
  "problem_statement": "system.detached_tables infinite loop?\n**Describe the bug**\r\nNot sure if this is a bug, but I don't expect a simple read from `system.detached_tables` table to take forever.\r\n\r\n**How to reproduce**\r\nRun:\r\n```sql\r\nSET max_block_size = 8;\r\nCREATE TABLE t0 (c0 Int) ENGINE = Memory;\r\nCREATE TABLE t1 (c0 Int) ENGINE = Memory;\r\nCREATE TABLE t2 (c0 Int) ENGINE = Memory;\r\nCREATE TABLE t3 (c0 Int) ENGINE = Memory;\r\nCREATE TABLE t4 (c0 Int) ENGINE = Memory;\r\nCREATE TABLE t5 (c0 Int) ENGINE = Memory;\r\nCREATE TABLE t6 (c0 Int) ENGINE = Memory;\r\nCREATE TABLE t7 (c0 Int) ENGINE = Memory;\r\nDROP TABLE t0;\r\nDROP TABLE t1;\r\nDROP TABLE t2;\r\nDROP TABLE t3;\r\nDROP TABLE t4;\r\nDROP TABLE t5;\r\nDROP TABLE t6;\r\nDROP TABLE t7;\r\nSELECT 1 FROM system.detached_tables; --infinite loop?\r\n```\n",
  "hints_text": "Attach GDB and check what server is doing \ud83d\ude04 \n[This](https://github.com/ClickHouse/ClickHouse/blob/fe35e6d3def4c73755e7bd20b65ebe2a2e0a52a4/src/Storages/System/StorageSystemDetachedTables.cpp#L79-L80) code is just wrong. It doesn't increment the database iterator but resets the table iterator, and iteration starts again. \nI always disliked `system.detached_tables`, as well as `DROP DETACHED`, because, according to the initial intent, the server should know nothing about detached tables or parts, neither control or monitor them.\r\n\r\nWe can remove this feature.\nAnd we should not wait for an external contributor to wake up, we can proactively remove it.\nThe infinite loop still happens on my setup",
  "created_at": "2025-01-08T11:06:26Z"
}