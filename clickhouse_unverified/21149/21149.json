{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 21149,
  "instance_id": "ClickHouse__ClickHouse-21149",
  "issue_numbers": [
    "21085"
  ],
  "base_commit": "a2bedd592ec34be2e409fe6960a34780da04aa5c",
  "patch": "diff --git a/src/Processors/Formats/IInputFormat.cpp b/src/Processors/Formats/IInputFormat.cpp\nindex 0fbc78ea8c09..069d25564b16 100644\n--- a/src/Processors/Formats/IInputFormat.cpp\n+++ b/src/Processors/Formats/IInputFormat.cpp\n@@ -13,6 +13,7 @@ namespace ErrorCodes\n IInputFormat::IInputFormat(Block header, ReadBuffer & in_)\n     : ISource(std::move(header)), in(in_)\n {\n+    column_mapping = std::make_shared<ColumnMapping>();\n }\n \n void IInputFormat::resetParser()\ndiff --git a/src/Processors/Formats/IInputFormat.h b/src/Processors/Formats/IInputFormat.h\nindex e1537aff6c56..95910bf51e5b 100644\n--- a/src/Processors/Formats/IInputFormat.h\n+++ b/src/Processors/Formats/IInputFormat.h\n@@ -2,9 +2,29 @@\n \n #include <Processors/ISource.h>\n \n+#include <memory>\n+\n \n namespace DB\n {\n+/// Used to pass info from header between different InputFormats in ParallelParsing\n+struct ColumnMapping\n+{\n+    /// Non-atomic because there is strict `happens-before` between read and write access\n+    /// See InputFormatParallelParsing\n+    bool is_set;\n+    /// Maps indexes of columns in the input file to indexes of table columns\n+    using OptionalIndexes = std::vector<std::optional<size_t>>;\n+    OptionalIndexes column_indexes_for_input_fields;\n+\n+    /// Tracks which columns we have read in a single read() call.\n+    /// For columns that are never read, it is initialized to false when we\n+    /// read the file header, and never changed afterwards.\n+    /// For other columns, it is updated on each read() call.\n+    std::vector<UInt8> read_columns;\n+};\n+\n+using ColumnMappingPtr = std::shared_ptr<ColumnMapping>;\n \n class ReadBuffer;\n \n@@ -39,9 +59,17 @@ class IInputFormat : public ISource\n         return none;\n     }\n \n+    /// Must be called from ParallelParsingInputFormat after readSuffix\n+    ColumnMappingPtr getColumnMapping() const { return column_mapping; }\n+    /// Must be called from ParallelParsingInputFormat before readPrefix\n+    void setColumnMapping(ColumnMappingPtr column_mapping_) { column_mapping = column_mapping_; }\n+\n     size_t getCurrentUnitNumber() const { return current_unit_number; }\n     void setCurrentUnitNumber(size_t current_unit_number_) { current_unit_number = current_unit_number_; }\n \n+protected:\n+    ColumnMappingPtr column_mapping{};\n+\n private:\n     /// Number of currently parsed chunk (if parallel parsing is enabled)\n     size_t current_unit_number = 0;\ndiff --git a/src/Processors/Formats/Impl/CSVRowInputFormat.cpp b/src/Processors/Formats/Impl/CSVRowInputFormat.cpp\nindex f7f08411dfa0..4cec07f38dc5 100644\n--- a/src/Processors/Formats/Impl/CSVRowInputFormat.cpp\n+++ b/src/Processors/Formats/Impl/CSVRowInputFormat.cpp\n@@ -55,13 +55,13 @@ void CSVRowInputFormat::addInputColumn(const String & column_name)\n     {\n         if (format_settings.skip_unknown_fields)\n         {\n-            column_indexes_for_input_fields.push_back(std::nullopt);\n+            column_mapping->column_indexes_for_input_fields.push_back(std::nullopt);\n             return;\n         }\n \n         throw Exception(\n                 \"Unknown field found in CSV header: '\" + column_name + \"' \" +\n-                \"at position \" + std::to_string(column_indexes_for_input_fields.size()) +\n+                \"at position \" + std::to_string(column_mapping->column_indexes_for_input_fields.size()) +\n                 \"\\nSet the 'input_format_skip_unknown_fields' parameter explicitly to ignore and proceed\",\n                 ErrorCodes::INCORRECT_DATA\n         );\n@@ -69,11 +69,11 @@ void CSVRowInputFormat::addInputColumn(const String & column_name)\n \n     const auto column_index = column_it->second;\n \n-    if (read_columns[column_index])\n+    if (column_mapping->read_columns[column_index])\n         throw Exception(\"Duplicate field found while parsing CSV header: \" + column_name, ErrorCodes::INCORRECT_DATA);\n \n-    read_columns[column_index] = true;\n-    column_indexes_for_input_fields.emplace_back(column_index);\n+    column_mapping->read_columns[column_index] = true;\n+    column_mapping->column_indexes_for_input_fields.emplace_back(column_index);\n }\n \n static void skipEndOfLine(ReadBuffer & in)\n@@ -145,6 +145,16 @@ static void skipRow(ReadBuffer & in, const FormatSettings::CSV & settings, size_\n     }\n }\n \n+void CSVRowInputFormat::setupAllColumnsByTableSchema()\n+{\n+    const auto & header = getPort().getHeader();\n+    column_mapping->read_columns.assign(header.columns(), true);\n+    column_mapping->column_indexes_for_input_fields.resize(header.columns());\n+\n+    for (size_t i = 0; i < column_mapping->column_indexes_for_input_fields.size(); ++i)\n+        column_mapping->column_indexes_for_input_fields[i] = i;\n+}\n+\n \n void CSVRowInputFormat::readPrefix()\n {\n@@ -155,7 +165,9 @@ void CSVRowInputFormat::readPrefix()\n     size_t num_columns = data_types.size();\n     const auto & header = getPort().getHeader();\n \n-    if (with_names)\n+    /// This is a bit of abstraction leakage, but we have almost the same code in other places.\n+    /// Thus, we check if this InputFormat is working with the \"real\" beginning of the data in case of parallel parsing.\n+    if (with_names && getCurrentUnitNumber() == 0)\n     {\n         /// This CSV file has a header row with column names. Depending on the\n         /// settings, use it or skip it.\n@@ -163,7 +175,7 @@ void CSVRowInputFormat::readPrefix()\n         {\n             /// Look at the file header to see which columns we have there.\n             /// The missing columns are filled with defaults.\n-            read_columns.assign(header.columns(), false);\n+            column_mapping->read_columns.assign(header.columns(), false);\n             do\n             {\n                 String column_name;\n@@ -177,7 +189,7 @@ void CSVRowInputFormat::readPrefix()\n \n             skipDelimiter(in, format_settings.csv.delimiter, true);\n \n-            for (auto read_column : read_columns)\n+            for (auto read_column : column_mapping->read_columns)\n             {\n                 if (!read_column)\n                 {\n@@ -191,16 +203,8 @@ void CSVRowInputFormat::readPrefix()\n         else\n             skipRow(in, format_settings.csv, num_columns);\n     }\n-\n-    /// The default: map each column of the file to the column of the table with\n-    /// the same index.\n-    read_columns.assign(header.columns(), true);\n-    column_indexes_for_input_fields.resize(header.columns());\n-\n-    for (size_t i = 0; i < column_indexes_for_input_fields.size(); ++i)\n-    {\n-        column_indexes_for_input_fields[i] = i;\n-    }\n+    else if (!column_mapping->is_set)\n+        setupAllColumnsByTableSchema();\n }\n \n \n@@ -216,12 +220,12 @@ bool CSVRowInputFormat::readRow(MutableColumns & columns, RowReadExtension & ext\n     /// it doesn't have to check it.\n     bool have_default_columns = have_always_default_columns;\n \n-    ext.read_columns.assign(read_columns.size(), true);\n+    ext.read_columns.assign(column_mapping->read_columns.size(), true);\n     const auto delimiter = format_settings.csv.delimiter;\n-    for (size_t file_column = 0; file_column < column_indexes_for_input_fields.size(); ++file_column)\n+    for (size_t file_column = 0; file_column < column_mapping->column_indexes_for_input_fields.size(); ++file_column)\n     {\n-        const auto & table_column = column_indexes_for_input_fields[file_column];\n-        const bool is_last_file_column = file_column + 1 == column_indexes_for_input_fields.size();\n+        const auto & table_column = column_mapping->column_indexes_for_input_fields[file_column];\n+        const bool is_last_file_column = file_column + 1 == column_mapping->column_indexes_for_input_fields.size();\n \n         if (table_column)\n         {\n@@ -243,9 +247,9 @@ bool CSVRowInputFormat::readRow(MutableColumns & columns, RowReadExtension & ext\n \n     if (have_default_columns)\n     {\n-        for (size_t i = 0; i < read_columns.size(); i++)\n+        for (size_t i = 0; i < column_mapping->read_columns.size(); i++)\n         {\n-            if (!read_columns[i])\n+            if (!column_mapping->read_columns[i])\n             {\n                 /// The column value for this row is going to be overwritten\n                 /// with default by the caller, but the general assumption is\n@@ -266,7 +270,7 @@ bool CSVRowInputFormat::parseRowAndPrintDiagnosticInfo(MutableColumns & columns,\n {\n     const char delimiter = format_settings.csv.delimiter;\n \n-    for (size_t file_column = 0; file_column < column_indexes_for_input_fields.size(); ++file_column)\n+    for (size_t file_column = 0; file_column < column_mapping->column_indexes_for_input_fields.size(); ++file_column)\n     {\n         if (file_column == 0 && in.eof())\n         {\n@@ -275,10 +279,10 @@ bool CSVRowInputFormat::parseRowAndPrintDiagnosticInfo(MutableColumns & columns,\n         }\n \n         skipWhitespacesAndTabs(in);\n-        if (column_indexes_for_input_fields[file_column].has_value())\n+        if (column_mapping->column_indexes_for_input_fields[file_column].has_value())\n         {\n             const auto & header = getPort().getHeader();\n-            size_t col_idx = column_indexes_for_input_fields[file_column].value();\n+            size_t col_idx = column_mapping->column_indexes_for_input_fields[file_column].value();\n             if (!deserializeFieldAndPrintDiagnosticInfo(header.getByPosition(col_idx).name, data_types[col_idx], *columns[col_idx],\n                                                         out, file_column))\n                 return false;\n@@ -294,7 +298,7 @@ bool CSVRowInputFormat::parseRowAndPrintDiagnosticInfo(MutableColumns & columns,\n         skipWhitespacesAndTabs(in);\n \n         /// Delimiters\n-        if (file_column + 1 == column_indexes_for_input_fields.size())\n+        if (file_column + 1 == column_mapping->column_indexes_for_input_fields.size())\n         {\n             if (in.eof())\n                 return false;\n@@ -356,9 +360,9 @@ void CSVRowInputFormat::syncAfterError()\n \n void CSVRowInputFormat::tryDeserializeField(const DataTypePtr & type, IColumn & column, size_t file_column)\n {\n-    if (column_indexes_for_input_fields[file_column])\n+    if (column_mapping->column_indexes_for_input_fields[file_column])\n     {\n-        const bool is_last_file_column = file_column + 1 == column_indexes_for_input_fields.size();\n+        const bool is_last_file_column = file_column + 1 == column_mapping->column_indexes_for_input_fields.size();\n         readField(column, type, is_last_file_column);\n     }\n     else\n@@ -404,8 +408,8 @@ bool CSVRowInputFormat::readField(IColumn & column, const DataTypePtr & type, bo\n void CSVRowInputFormat::resetParser()\n {\n     RowInputFormatWithDiagnosticInfo::resetParser();\n-    column_indexes_for_input_fields.clear();\n-    read_columns.clear();\n+    column_mapping->column_indexes_for_input_fields.clear();\n+    column_mapping->read_columns.clear();\n     have_always_default_columns = false;\n }\n \n@@ -492,6 +496,7 @@ static std::pair<bool, size_t> fileSegmentationEngineCSVImpl(ReadBuffer & in, DB\n void registerFileSegmentationEngineCSV(FormatFactory & factory)\n {\n     factory.registerFileSegmentationEngine(\"CSV\", &fileSegmentationEngineCSVImpl);\n+    factory.registerFileSegmentationEngine(\"CSVWithNames\", &fileSegmentationEngineCSVImpl);\n }\n \n }\ndiff --git a/src/Processors/Formats/Impl/CSVRowInputFormat.h b/src/Processors/Formats/Impl/CSVRowInputFormat.h\nindex c884eb6c3db5..86e41cf0a43b 100644\n--- a/src/Processors/Formats/Impl/CSVRowInputFormat.h\n+++ b/src/Processors/Formats/Impl/CSVRowInputFormat.h\n@@ -38,22 +38,13 @@ class CSVRowInputFormat : public RowInputFormatWithDiagnosticInfo\n     using IndexesMap = std::unordered_map<String, size_t>;\n     IndexesMap column_indexes_by_names;\n \n-    /// Maps indexes of columns in the input file to indexes of table columns\n-    using OptionalIndexes = std::vector<std::optional<size_t>>;\n-    OptionalIndexes column_indexes_for_input_fields;\n-\n-    /// Tracks which columns we have read in a single read() call.\n-    /// For columns that are never read, it is initialized to false when we\n-    /// read the file header, and never changed afterwards.\n-    /// For other columns, it is updated on each read() call.\n-    std::vector<UInt8> read_columns;\n-\n     /// Whether we have any columns that are not read from file at all,\n     /// and must be always initialized with defaults.\n     bool have_always_default_columns = false;\n \n     void addInputColumn(const String & column_name);\n \n+    void setupAllColumnsByTableSchema();\n     bool parseRowAndPrintDiagnosticInfo(MutableColumns & columns, WriteBuffer & out) override;\n     void tryDeserializeField(const DataTypePtr & type, IColumn & column, size_t file_column) override;\n     bool isGarbageAfterField(size_t, ReadBuffer::Position pos) override\ndiff --git a/src/Processors/Formats/Impl/ParallelParsingInputFormat.cpp b/src/Processors/Formats/Impl/ParallelParsingInputFormat.cpp\nindex d1660b530190..1ad913a1a59e 100644\n--- a/src/Processors/Formats/Impl/ParallelParsingInputFormat.cpp\n+++ b/src/Processors/Formats/Impl/ParallelParsingInputFormat.cpp\n@@ -89,6 +89,11 @@ void ParallelParsingInputFormat::parserThreadFunction(ThreadGroupStatusPtr threa\n         unit.chunk_ext.chunk.clear();\n         unit.chunk_ext.block_missing_values.clear();\n \n+        /// Propagate column_mapping to other parsers.\n+        /// Note: column_mapping is used only for *WithNames types\n+        if (current_ticket_number != 0)\n+            input_format->setColumnMapping(column_mapping);\n+\n         // We don't know how many blocks will be. So we have to read them all\n         // until an empty block occurred.\n         Chunk chunk;\n@@ -100,6 +105,14 @@ void ParallelParsingInputFormat::parserThreadFunction(ThreadGroupStatusPtr threa\n             unit.chunk_ext.block_missing_values.emplace_back(parser.getMissingValues());\n         }\n \n+        /// Extract column_mapping from first parser to propagate it to others\n+        if (current_ticket_number == 0)\n+        {\n+            column_mapping = input_format->getColumnMapping();\n+            column_mapping->is_set = true;\n+            first_parser_finished.set();\n+        }\n+\n         // We suppose we will get at least some blocks for a non-empty buffer,\n         // except at the end of file. Also see a matching assert in readImpl().\n         assert(unit.is_last || !unit.chunk_ext.chunk.empty() || parsing_finished);\n@@ -117,8 +130,6 @@ void ParallelParsingInputFormat::parserThreadFunction(ThreadGroupStatusPtr threa\n \n void ParallelParsingInputFormat::onBackgroundException(size_t offset)\n {\n-    tryLogCurrentException(__PRETTY_FUNCTION__);\n-\n     std::unique_lock<std::mutex> lock(mutex);\n     if (!background_exception)\n     {\n@@ -129,6 +140,7 @@ void ParallelParsingInputFormat::onBackgroundException(size_t offset)\n     }\n     tryLogCurrentException(__PRETTY_FUNCTION__);\n     parsing_finished = true;\n+    first_parser_finished.set();\n     reader_condvar.notify_all();\n     segmentator_condvar.notify_all();\n }\ndiff --git a/src/Processors/Formats/Impl/ParallelParsingInputFormat.h b/src/Processors/Formats/Impl/ParallelParsingInputFormat.h\nindex 9dda2dfe55d0..559507055b9c 100644\n--- a/src/Processors/Formats/Impl/ParallelParsingInputFormat.h\n+++ b/src/Processors/Formats/Impl/ParallelParsingInputFormat.h\n@@ -10,6 +10,8 @@\n #include <IO/ReadBuffer.h>\n #include <Processors/Formats/IRowInputFormat.h>\n #include <Interpreters/Context.h>\n+#include <common/logger_useful.h>\n+#include <Poco/Event.h>\n \n namespace DB\n {\n@@ -97,6 +99,8 @@ class ParallelParsingInputFormat : public IInputFormat\n \n         segmentator_thread = ThreadFromGlobalPool(\n             &ParallelParsingInputFormat::segmentatorThreadFunction, this, CurrentThread::getGroup());\n+\n+        LOG_TRACE(&Poco::Logger::get(\"ParallelParsingInputFormat\"), \"Parallel parsing is used\");\n     }\n \n     ~ParallelParsingInputFormat() override\n@@ -199,6 +203,8 @@ class ParallelParsingInputFormat : public IInputFormat\n     std::condition_variable reader_condvar;\n     std::condition_variable segmentator_condvar;\n \n+    Poco::Event first_parser_finished;\n+\n     std::atomic<bool> parsing_finished{false};\n \n     /// There are multiple \"parsers\", that's why we use thread pool.\n@@ -250,6 +256,9 @@ class ParallelParsingInputFormat : public IInputFormat\n         {\n             parserThreadFunction(group, ticket_number);\n         });\n+        /// We have to wait here to possibly extract ColumnMappingPtr from the first parser.\n+        if (ticket_number == 0)\n+            first_parser_finished.wait();\n     }\n \n     void finishAndWait()\ndiff --git a/src/Processors/Formats/Impl/TabSeparatedRowInputFormat.cpp b/src/Processors/Formats/Impl/TabSeparatedRowInputFormat.cpp\nindex 96b01a5bd9b4..ffb1b96f70e3 100644\n--- a/src/Processors/Formats/Impl/TabSeparatedRowInputFormat.cpp\n+++ b/src/Processors/Formats/Impl/TabSeparatedRowInputFormat.cpp\n@@ -62,19 +62,19 @@ TabSeparatedRowInputFormat::TabSeparatedRowInputFormat(const Block & header_, Re\n         column_indexes_by_names.emplace(column_info.name, i);\n     }\n \n-    column_indexes_for_input_fields.reserve(num_columns);\n-    read_columns.assign(num_columns, false);\n+    column_mapping->column_indexes_for_input_fields.reserve(num_columns);\n+    column_mapping->read_columns.assign(num_columns, false);\n }\n \n \n void TabSeparatedRowInputFormat::setupAllColumnsByTableSchema()\n {\n     const auto & header = getPort().getHeader();\n-    read_columns.assign(header.columns(), true);\n-    column_indexes_for_input_fields.resize(header.columns());\n+    column_mapping->read_columns.assign(header.columns(), true);\n+    column_mapping->column_indexes_for_input_fields.resize(header.columns());\n \n-    for (size_t i = 0; i < column_indexes_for_input_fields.size(); ++i)\n-        column_indexes_for_input_fields[i] = i;\n+    for (size_t i = 0; i < column_mapping->column_indexes_for_input_fields.size(); ++i)\n+        column_mapping->column_indexes_for_input_fields[i] = i;\n }\n \n \n@@ -85,13 +85,13 @@ void TabSeparatedRowInputFormat::addInputColumn(const String & column_name)\n     {\n         if (format_settings.skip_unknown_fields)\n         {\n-            column_indexes_for_input_fields.push_back(std::nullopt);\n+            column_mapping->column_indexes_for_input_fields.push_back(std::nullopt);\n             return;\n         }\n \n         throw Exception(\n                 \"Unknown field found in TSV header: '\" + column_name + \"' \" +\n-                \"at position \" + std::to_string(column_indexes_for_input_fields.size()) +\n+                \"at position \" + std::to_string(column_mapping->column_indexes_for_input_fields.size()) +\n                 \"\\nSet the 'input_format_skip_unknown_fields' parameter explicitly to ignore and proceed\",\n                 ErrorCodes::INCORRECT_DATA\n         );\n@@ -99,11 +99,11 @@ void TabSeparatedRowInputFormat::addInputColumn(const String & column_name)\n \n     const auto column_index = column_it->second;\n \n-    if (read_columns[column_index])\n+    if (column_mapping->read_columns[column_index])\n         throw Exception(\"Duplicate field found while parsing TSV header: \" + column_name, ErrorCodes::INCORRECT_DATA);\n \n-    read_columns[column_index] = true;\n-    column_indexes_for_input_fields.emplace_back(column_index);\n+    column_mapping->read_columns[column_index] = true;\n+    column_mapping->column_indexes_for_input_fields.emplace_back(column_index);\n }\n \n \n@@ -113,8 +113,8 @@ void TabSeparatedRowInputFormat::fillUnreadColumnsWithDefaults(MutableColumns &\n     if (unlikely(row_num == 1))\n     {\n         columns_to_fill_with_default_values.clear();\n-        for (size_t index = 0; index < read_columns.size(); ++index)\n-            if (read_columns[index] == 0)\n+        for (size_t index = 0; index < column_mapping->read_columns.size(); ++index)\n+            if (column_mapping->read_columns[index] == 0)\n                 columns_to_fill_with_default_values.push_back(index);\n     }\n \n@@ -136,7 +136,9 @@ void TabSeparatedRowInputFormat::readPrefix()\n         skipBOMIfExists(in);\n     }\n \n-    if (with_names)\n+    /// This is a bit of abstraction leakage, but we have almost the same code in other places.\n+    /// Thus, we check if this InputFormat is working with the \"real\" beginning of the data in case of parallel parsing.\n+    if (with_names && getCurrentUnitNumber() == 0)\n     {\n         if (format_settings.with_names_use_header)\n         {\n@@ -165,15 +167,15 @@ void TabSeparatedRowInputFormat::readPrefix()\n         else\n         {\n             setupAllColumnsByTableSchema();\n-            skipTSVRow(in, column_indexes_for_input_fields.size());\n+            skipTSVRow(in, column_mapping->column_indexes_for_input_fields.size());\n         }\n     }\n-    else\n+    else if (!column_mapping->is_set)\n         setupAllColumnsByTableSchema();\n \n     if (with_types)\n     {\n-        skipTSVRow(in, column_indexes_for_input_fields.size());\n+        skipTSVRow(in, column_mapping->column_indexes_for_input_fields.size());\n     }\n }\n \n@@ -185,11 +187,11 @@ bool TabSeparatedRowInputFormat::readRow(MutableColumns & columns, RowReadExtens\n \n     updateDiagnosticInfo();\n \n-    ext.read_columns.assign(read_columns.size(), true);\n-    for (size_t file_column = 0; file_column < column_indexes_for_input_fields.size(); ++file_column)\n+    ext.read_columns.assign(column_mapping->read_columns.size(), true);\n+    for (size_t file_column = 0; file_column < column_mapping->column_indexes_for_input_fields.size(); ++file_column)\n     {\n-        const auto & column_index = column_indexes_for_input_fields[file_column];\n-        const bool is_last_file_column = file_column + 1 == column_indexes_for_input_fields.size();\n+        const auto & column_index = column_mapping->column_indexes_for_input_fields[file_column];\n+        const bool is_last_file_column = file_column + 1 == column_mapping->column_indexes_for_input_fields.size();\n         if (column_index)\n         {\n             const auto & type = data_types[*column_index];\n@@ -202,7 +204,7 @@ bool TabSeparatedRowInputFormat::readRow(MutableColumns & columns, RowReadExtens\n         }\n \n         /// skip separators\n-        if (file_column + 1 < column_indexes_for_input_fields.size())\n+        if (file_column + 1 < column_mapping->column_indexes_for_input_fields.size())\n         {\n             assertChar('\\t', in);\n         }\n@@ -238,7 +240,7 @@ bool TabSeparatedRowInputFormat::readField(IColumn & column, const DataTypePtr &\n \n bool TabSeparatedRowInputFormat::parseRowAndPrintDiagnosticInfo(MutableColumns & columns, WriteBuffer & out)\n {\n-    for (size_t file_column = 0; file_column < column_indexes_for_input_fields.size(); ++file_column)\n+    for (size_t file_column = 0; file_column < column_mapping->column_indexes_for_input_fields.size(); ++file_column)\n     {\n         if (file_column == 0 && in.eof())\n         {\n@@ -246,10 +248,10 @@ bool TabSeparatedRowInputFormat::parseRowAndPrintDiagnosticInfo(MutableColumns &\n             return false;\n         }\n \n-        if (column_indexes_for_input_fields[file_column].has_value())\n+        if (column_mapping->column_indexes_for_input_fields[file_column].has_value())\n         {\n             const auto & header = getPort().getHeader();\n-            size_t col_idx = column_indexes_for_input_fields[file_column].value();\n+            size_t col_idx = column_mapping->column_indexes_for_input_fields[file_column].value();\n             if (!deserializeFieldAndPrintDiagnosticInfo(header.getByPosition(col_idx).name, data_types[col_idx], *columns[col_idx],\n                                                         out, file_column))\n                 return false;\n@@ -264,7 +266,7 @@ bool TabSeparatedRowInputFormat::parseRowAndPrintDiagnosticInfo(MutableColumns &\n         }\n \n         /// Delimiters\n-        if (file_column + 1 == column_indexes_for_input_fields.size())\n+        if (file_column + 1 == column_mapping->column_indexes_for_input_fields.size())\n         {\n             if (!in.eof())\n             {\n@@ -330,7 +332,7 @@ bool TabSeparatedRowInputFormat::parseRowAndPrintDiagnosticInfo(MutableColumns &\n \n void TabSeparatedRowInputFormat::tryDeserializeField(const DataTypePtr & type, IColumn & column, size_t file_column)\n {\n-    if (column_indexes_for_input_fields[file_column])\n+    if (column_mapping->column_indexes_for_input_fields[file_column])\n     {\n         // check null value for type is not nullable. don't cross buffer bound for simplicity, so maybe missing some case\n         if (!type->isNullable() && !in.eof())\n@@ -349,7 +351,7 @@ void TabSeparatedRowInputFormat::tryDeserializeField(const DataTypePtr & type, I\n                 }\n             }\n         }\n-        const bool is_last_file_column = file_column + 1 == column_indexes_for_input_fields.size();\n+        const bool is_last_file_column = file_column + 1 == column_mapping->column_indexes_for_input_fields.size();\n         readField(column, type, is_last_file_column);\n     }\n     else\n@@ -368,8 +370,8 @@ void TabSeparatedRowInputFormat::resetParser()\n {\n     RowInputFormatWithDiagnosticInfo::resetParser();\n     const auto & sample = getPort().getHeader();\n-    read_columns.assign(sample.columns(), false);\n-    column_indexes_for_input_fields.clear();\n+    column_mapping->read_columns.assign(sample.columns(), false);\n+    column_mapping->column_indexes_for_input_fields.clear();\n     columns_to_fill_with_default_values.clear();\n }\n \n@@ -463,7 +465,7 @@ static std::pair<bool, size_t> fileSegmentationEngineTabSeparatedImpl(ReadBuffer\n void registerFileSegmentationEngineTabSeparated(FormatFactory & factory)\n {\n     // We can use the same segmentation engine for TSKV.\n-    for (const auto * name : {\"TabSeparated\", \"TSV\", \"TSKV\"})\n+    for (const auto & name : {\"TabSeparated\", \"TSV\", \"TSKV\", \"TabSeparatedWithNames\", \"TSVWithNames\"})\n     {\n         factory.registerFileSegmentationEngine(name, &fileSegmentationEngineTabSeparatedImpl);\n     }\ndiff --git a/src/Processors/Formats/Impl/TabSeparatedRowInputFormat.h b/src/Processors/Formats/Impl/TabSeparatedRowInputFormat.h\nindex 0141d87403ab..db70b4d3fea6 100644\n--- a/src/Processors/Formats/Impl/TabSeparatedRowInputFormat.h\n+++ b/src/Processors/Formats/Impl/TabSeparatedRowInputFormat.h\n@@ -41,10 +41,6 @@ class TabSeparatedRowInputFormat : public RowInputFormatWithDiagnosticInfo\n     using IndexesMap = std::unordered_map<String, size_t>;\n     IndexesMap column_indexes_by_names;\n \n-    using OptionalIndexes = std::vector<std::optional<size_t>>;\n-    OptionalIndexes column_indexes_for_input_fields;\n-\n-    std::vector<UInt8> read_columns;\n     std::vector<size_t> columns_to_fill_with_default_values;\n \n     void addInputColumn(const String & column_name);\ndiff --git a/src/Processors/ISource.h b/src/Processors/ISource.h\nindex b7e2b5dce8e2..db91c0c5bceb 100644\n--- a/src/Processors/ISource.h\n+++ b/src/Processors/ISource.h\n@@ -19,7 +19,7 @@ class ISource : public IProcessor\n     virtual std::optional<Chunk> tryGenerate();\n \n public:\n-    ISource(Block header);\n+    explicit ISource(Block header);\n \n     Status prepare() override;\n     void work() override;\ndiff --git a/src/Server/GRPCServer.cpp b/src/Server/GRPCServer.cpp\nindex ede9bbff0630..52a2c1064888 100644\n--- a/src/Server/GRPCServer.cpp\n+++ b/src/Server/GRPCServer.cpp\n@@ -783,8 +783,6 @@ namespace\n         if (!io.out)\n             return;\n \n-        initializeBlockInputStream(io.out->getHeader());\n-\n         bool has_data_to_insert = (insert_query && insert_query->data)\n                                   || !query_info.input_data().empty() || query_info.next_query_info();\n         if (!has_data_to_insert)\n@@ -795,6 +793,10 @@ namespace\n                 throw Exception(\"No data to insert\", ErrorCodes::NO_DATA_TO_INSERT);\n         }\n \n+        /// This is significant, because parallel parsing may be used.\n+        /// So we mustn't touch the input stream from other thread.\n+        initializeBlockInputStream(io.out->getHeader());\n+\n         block_input_stream->readPrefix();\n         io.out->writePrefix();\n \n",
  "test_patch": "diff --git a/tests/queries/1_stateful/00161_parallel_parsing_with_names.reference b/tests/queries/1_stateful/00161_parallel_parsing_with_names.reference\nnew file mode 100644\nindex 000000000000..fb0ba75c1485\n--- /dev/null\n+++ b/tests/queries/1_stateful/00161_parallel_parsing_with_names.reference\n@@ -0,0 +1,8 @@\n+TSVWithNames, false\n+29caf86494f169d6339f6c5610b20731  -\n+TSVWithNames, true\n+29caf86494f169d6339f6c5610b20731  -\n+CSVWithNames, false\n+29caf86494f169d6339f6c5610b20731  -\n+CSVWithNames, true\n+29caf86494f169d6339f6c5610b20731  -\ndiff --git a/tests/queries/1_stateful/00161_parallel_parsing_with_names.sh b/tests/queries/1_stateful/00161_parallel_parsing_with_names.sh\nnew file mode 100755\nindex 000000000000..ca9984900e19\n--- /dev/null\n+++ b/tests/queries/1_stateful/00161_parallel_parsing_with_names.sh\n@@ -0,0 +1,32 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+FORMATS=('TSVWithNames' 'CSVWithNames')\n+$CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS parsing_with_names\"\n+\n+for format in \"${FORMATS[@]}\"\n+do\n+    # Columns are permuted\n+    $CLICKHOUSE_CLIENT -q \"CREATE TABLE parsing_with_names(c FixedString(16), a DateTime,  b String) ENGINE=Memory()\"\n+    \n+    echo \"$format, false\";\n+    $CLICKHOUSE_CLIENT --output_format_parallel_formatting=false -q \\\n+    \"SELECT URLRegions as d, ClientEventTime as a, MobilePhoneModel as b, ParamPrice as e, ClientIP6 as c FROM test.hits LIMIT 50000 Format $format\" | \\\n+    $CLICKHOUSE_CLIENT --input_format_skip_unknown_fields=1 --input_format_parallel_parsing=false -q \"INSERT INTO parsing_with_names FORMAT $format\"\n+\n+    $CLICKHOUSE_CLIENT -q \"SELECT * FROM parsing_with_names;\" | md5sum\n+    $CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS parsing_with_names\"\n+\n+    \n+    $CLICKHOUSE_CLIENT -q \"CREATE TABLE parsing_with_names(c FixedString(16), a DateTime,  b String) ENGINE=Memory()\"\n+    echo \"$format, true\";\n+    $CLICKHOUSE_CLIENT --output_format_parallel_formatting=false -q \\\n+    \"SELECT URLRegions as d, ClientEventTime as a, MobilePhoneModel as b, ParamPrice as e, ClientIP6 as c FROM test.hits LIMIT 50000 Format $format\" | \\\n+    $CLICKHOUSE_CLIENT --input_format_skip_unknown_fields=1 --input_format_parallel_parsing=true -q \"INSERT INTO parsing_with_names FORMAT $format\"\n+\n+    $CLICKHOUSE_CLIENT -q \"SELECT * FROM parsing_with_names;\" | md5sum\n+    $CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS parsing_with_names\"\n+done\n\\ No newline at end of file\n",
  "problem_statement": "Parallel parsing does not work for CSVWithNames\nIt's being parsed sequentially.\n",
  "hints_text": "",
  "created_at": "2021-02-24T17:06:54Z"
}