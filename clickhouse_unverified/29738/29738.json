{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 29738,
  "instance_id": "ClickHouse__ClickHouse-29738",
  "issue_numbers": [
    "29699"
  ],
  "base_commit": "e2551e8cb02b8f57ca2afb131fd7cd23a2a9e091",
  "patch": "diff --git a/src/DataTypes/DataTypeFixedString.h b/src/DataTypes/DataTypeFixedString.h\nindex d82ea9824f35..f88d2f5337ab 100644\n--- a/src/DataTypes/DataTypeFixedString.h\n+++ b/src/DataTypes/DataTypeFixedString.h\n@@ -2,6 +2,7 @@\n \n #include <DataTypes/IDataType.h>\n #include <Common/PODArray_fwd.h>\n+#include <Common/Exception.h>\n \n #define MAX_FIXEDSTRING_SIZE 0xFFFFFF\n \ndiff --git a/src/Functions/ngrams.cpp b/src/Functions/ngrams.cpp\nnew file mode 100644\nindex 000000000000..c5ce65537cb1\n--- /dev/null\n+++ b/src/Functions/ngrams.cpp\n@@ -0,0 +1,126 @@\n+#include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypeFixedString.h>\n+#include <Columns/ColumnString.h>\n+#include <Columns/ColumnFixedString.h>\n+#include <Columns/ColumnArray.h>\n+#include <Interpreters/Context_fwd.h>\n+#include <Interpreters/ITokenExtractor.h>\n+#include <Functions/IFunction.h>\n+#include <Functions/FunctionHelpers.h>\n+#include <Functions/FunctionFactory.h>\n+\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int BAD_ARGUMENTS;\n+}\n+\n+class FunctionNgrams : public IFunction\n+{\n+public:\n+\n+    static constexpr auto name = \"ngrams\";\n+\n+    static FunctionPtr create(ContextPtr)\n+    {\n+        return std::make_shared<FunctionNgrams>();\n+    }\n+\n+    String getName() const override { return name; }\n+\n+    size_t getNumberOfArguments() const override { return 2; }\n+    bool isVariadic() const override { return false; }\n+    ColumnNumbers getArgumentsThatAreAlwaysConstant() const override { return {1}; }\n+\n+    bool useDefaultImplementationForNulls() const override { return true; }\n+    bool useDefaultImplementationForConstants() const override { return true; }\n+    bool useDefaultImplementationForLowCardinalityColumns() const override { return true; }\n+    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }\n+\n+    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override\n+    {\n+        auto ngram_input_argument_type = WhichDataType(arguments[0].type);\n+        if (!ngram_input_argument_type.isStringOrFixedString())\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS,\n+                \"Function {} second argument type should be String or FixedString. Actual {}\",\n+                getName(),\n+                arguments[0].type->getName());\n+\n+        const auto & column_with_type = arguments[1];\n+        const auto & ngram_argument_column = arguments[1].column;\n+        auto ngram_argument_type = WhichDataType(column_with_type.type);\n+\n+        if (!ngram_argument_type.isNativeUInt() || !ngram_argument_column || !isColumnConst(*ngram_argument_column))\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS,\n+                \"Function {} second argument type should be constant UInt. Actual {}\",\n+                getName(),\n+                arguments[1].type->getName());\n+\n+        Field ngram_argument_value;\n+        ngram_argument_column->get(0, ngram_argument_value);\n+        auto ngram_value = ngram_argument_value.safeGet<UInt64>();\n+\n+        return std::make_shared<DataTypeArray>(std::make_shared<DataTypeFixedString>(ngram_value));\n+    }\n+\n+    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t) const override\n+    {\n+        Field ngram_argument_value;\n+        arguments[1].column->get(0, ngram_argument_value);\n+        auto ngram_value = ngram_argument_value.safeGet<UInt64>();\n+\n+        NgramTokenExtractor extractor(ngram_value);\n+\n+        auto result_column_fixed_string = ColumnFixedString::create(ngram_value);\n+        auto column_offsets = ColumnArray::ColumnOffsets::create();\n+\n+        auto input_column = arguments[0].column;\n+        if (const auto * column_string = checkAndGetColumn<ColumnString>(input_column.get()))\n+            executeImpl(extractor, *column_string, *result_column_fixed_string, *column_offsets);\n+        else if (const auto * column_fixed_string = checkAndGetColumn<ColumnFixedString>(input_column.get()))\n+            executeImpl(extractor, *column_fixed_string, *result_column_fixed_string, *column_offsets);\n+\n+        return ColumnArray::create(std::move(result_column_fixed_string), std::move(column_offsets));\n+    }\n+\n+private:\n+\n+    template <typename StringColumnType>\n+    inline void executeImpl(const NgramTokenExtractor & extractor, StringColumnType & input_data_column, ColumnFixedString & result_data_column, ColumnArray::ColumnOffsets & offsets_column) const\n+    {\n+        size_t current_tokens_size = 0;\n+        auto & offsets_data = offsets_column.getData();\n+\n+        size_t column_size = input_data_column.size();\n+        offsets_data.resize(column_size);\n+\n+        for (size_t i = 0; i < column_size; ++i)\n+        {\n+            auto data = input_data_column.getDataAt(i);\n+\n+            size_t cur = 0;\n+            size_t token_start = 0;\n+            size_t token_length = 0;\n+\n+            while (cur < data.size && extractor.nextInString(data.data, data.size, &cur, &token_start, &token_length))\n+            {\n+                result_data_column.insertData(data.data + token_start, token_length);\n+                ++current_tokens_size;\n+            }\n+\n+            offsets_data[i] = current_tokens_size;\n+        }\n+    }\n+};\n+\n+void registerFunctionNgrams(FunctionFactory & factory)\n+{\n+    factory.registerFunction<FunctionNgrams>();\n+}\n+\n+}\n+\n+\ndiff --git a/src/Functions/registerFunctions.cpp b/src/Functions/registerFunctions.cpp\nindex 4733829de56a..35193e9be8d0 100644\n--- a/src/Functions/registerFunctions.cpp\n+++ b/src/Functions/registerFunctions.cpp\n@@ -37,6 +37,7 @@ void registerFunctionsStringArray(FunctionFactory &);\n void registerFunctionsStringSearch(FunctionFactory &);\n void registerFunctionsStringRegexp(FunctionFactory &);\n void registerFunctionsStringSimilarity(FunctionFactory &);\n+void registerFunctionNgrams(FunctionFactory &);\n void registerFunctionsURL(FunctionFactory &);\n void registerFunctionsVisitParam(FunctionFactory &);\n void registerFunctionsMath(FunctionFactory &);\n@@ -103,6 +104,7 @@ void registerFunctions()\n     registerFunctionsStringSearch(factory);\n     registerFunctionsStringRegexp(factory);\n     registerFunctionsStringSimilarity(factory);\n+    registerFunctionNgrams(factory);\n     registerFunctionsURL(factory);\n     registerFunctionsVisitParam(factory);\n     registerFunctionsMath(factory);\ndiff --git a/src/Interpreters/ITokenExtractor.cpp b/src/Interpreters/ITokenExtractor.cpp\nnew file mode 100644\nindex 000000000000..83166079e898\n--- /dev/null\n+++ b/src/Interpreters/ITokenExtractor.cpp\n@@ -0,0 +1,242 @@\n+#include \"ITokenExtractor.h\"\n+\n+#include <boost/algorithm/string.hpp>\n+\n+#include <Common/StringUtils/StringUtils.h>\n+#include <Common/UTF8Helpers.h>\n+\n+#if defined(__SSE2__)\n+#include <immintrin.h>\n+\n+#if defined(__SSE4_2__)\n+#include <nmmintrin.h>\n+#endif\n+\n+#endif\n+\n+\n+namespace DB\n+{\n+\n+bool NgramTokenExtractor::nextInString(const char * data, size_t length, size_t * __restrict pos, size_t * __restrict token_start, size_t * __restrict token_length) const\n+{\n+    *token_start = *pos;\n+    *token_length = 0;\n+    size_t code_points = 0;\n+    for (; code_points < n && *token_start + *token_length < length; ++code_points)\n+    {\n+        size_t sz = UTF8::seqLength(static_cast<UInt8>(data[*token_start + *token_length]));\n+        *token_length += sz;\n+    }\n+    *pos += UTF8::seqLength(static_cast<UInt8>(data[*pos]));\n+    return code_points == n;\n+}\n+\n+bool NgramTokenExtractor::nextInStringLike(const char * data, size_t length, size_t * pos, String & token) const\n+{\n+    token.clear();\n+\n+    size_t code_points = 0;\n+    bool escaped = false;\n+    for (size_t i = *pos; i < length;)\n+    {\n+        if (escaped && (data[i] == '%' || data[i] == '_' || data[i] == '\\\\'))\n+        {\n+            token += data[i];\n+            ++code_points;\n+            escaped = false;\n+            ++i;\n+        }\n+        else if (!escaped && (data[i] == '%' || data[i] == '_'))\n+        {\n+            /// This token is too small, go to the next.\n+            token.clear();\n+            code_points = 0;\n+            escaped = false;\n+            *pos = ++i;\n+        }\n+        else if (!escaped && data[i] == '\\\\')\n+        {\n+            escaped = true;\n+            ++i;\n+        }\n+        else\n+        {\n+            const size_t sz = UTF8::seqLength(static_cast<UInt8>(data[i]));\n+            for (size_t j = 0; j < sz; ++j)\n+                token += data[i + j];\n+            i += sz;\n+            ++code_points;\n+            escaped = false;\n+        }\n+\n+        if (code_points == n)\n+        {\n+            *pos += UTF8::seqLength(static_cast<UInt8>(data[*pos]));\n+            return true;\n+        }\n+    }\n+\n+    return false;\n+}\n+\n+bool SplitTokenExtractor::nextInString(const char * data, size_t length, size_t * __restrict pos, size_t * __restrict token_start, size_t * __restrict token_length) const\n+{\n+    *token_start = *pos;\n+    *token_length = 0;\n+\n+    while (*pos < length)\n+    {\n+        if (isASCII(data[*pos]) && !isAlphaNumericASCII(data[*pos]))\n+        {\n+            /// Finish current token if any\n+            if (*token_length > 0)\n+                return true;\n+            *token_start = ++*pos;\n+        }\n+        else\n+        {\n+            /// Note that UTF-8 sequence is completely consisted of non-ASCII bytes.\n+            ++*pos;\n+            ++*token_length;\n+        }\n+    }\n+\n+    return *token_length > 0;\n+}\n+\n+bool SplitTokenExtractor::nextInStringPadded(const char * data, size_t length, size_t * __restrict pos, size_t * __restrict token_start, size_t * __restrict token_length) const\n+{\n+    *token_start = *pos;\n+    *token_length = 0;\n+\n+    while (*pos < length)\n+    {\n+#if defined(__SSE2__) && !defined(MEMORY_SANITIZER) /// We read uninitialized bytes and decide on the calculated mask\n+        // NOTE: we assume that `data` string is padded from the right with 15 bytes.\n+        const __m128i haystack = _mm_loadu_si128(reinterpret_cast<const __m128i *>(data + *pos));\n+        const size_t haystack_length = 16;\n+\n+#if defined(__SSE4_2__)\n+        // With the help of https://www.strchr.com/strcmp_and_strlen_using_sse_4.2\n+        const auto alnum_chars_ranges = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0,\n+                '\\xFF', '\\x80', 'z', 'a', 'Z', 'A', '9', '0');\n+        // Every bit represents if `haystack` character is in the ranges (1) or not (0)\n+        const int result_bitmask = _mm_cvtsi128_si32(_mm_cmpestrm(alnum_chars_ranges, 8, haystack, haystack_length, _SIDD_CMP_RANGES));\n+#else\n+        // NOTE: -1 and +1 required since SSE2 has no `>=` and `<=` instructions on packed 8-bit integers (epi8).\n+        const auto number_begin =      _mm_set1_epi8('0' - 1);\n+        const auto number_end =        _mm_set1_epi8('9' + 1);\n+        const auto alpha_lower_begin = _mm_set1_epi8('a' - 1);\n+        const auto alpha_lower_end =   _mm_set1_epi8('z' + 1);\n+        const auto alpha_upper_begin = _mm_set1_epi8('A' - 1);\n+        const auto alpha_upper_end =   _mm_set1_epi8('Z' + 1);\n+        const auto zero =              _mm_set1_epi8(0);\n+\n+        // every bit represents if `haystack` character `c` satisfies condition:\n+        // (c < 0) || (c > '0' - 1 && c < '9' + 1) || (c > 'a' - 1 && c < 'z' + 1) || (c > 'A' - 1 && c < 'Z' + 1)\n+        // < 0 since _mm_cmplt_epi8 threats chars as SIGNED, and so all chars > 0x80 are negative.\n+        const int result_bitmask = _mm_movemask_epi8(_mm_or_si128(_mm_or_si128(_mm_or_si128(\n+                _mm_cmplt_epi8(haystack, zero),\n+                _mm_and_si128(_mm_cmpgt_epi8(haystack, number_begin),      _mm_cmplt_epi8(haystack, number_end))),\n+                _mm_and_si128(_mm_cmpgt_epi8(haystack, alpha_lower_begin), _mm_cmplt_epi8(haystack, alpha_lower_end))),\n+                _mm_and_si128(_mm_cmpgt_epi8(haystack, alpha_upper_begin), _mm_cmplt_epi8(haystack, alpha_upper_end))));\n+#endif\n+        if (result_bitmask == 0)\n+        {\n+            if (*token_length != 0)\n+                // end of token started on previous haystack\n+                return true;\n+\n+            *pos += haystack_length;\n+            continue;\n+        }\n+\n+        const auto token_start_pos_in_current_haystack = getTrailingZeroBitsUnsafe(result_bitmask);\n+        if (*token_length == 0)\n+            // new token\n+            *token_start = *pos + token_start_pos_in_current_haystack;\n+        else if (token_start_pos_in_current_haystack != 0)\n+            // end of token starting in one of previous haystacks\n+            return true;\n+\n+        const auto token_bytes_in_current_haystack = getTrailingZeroBitsUnsafe(~(result_bitmask >> token_start_pos_in_current_haystack));\n+        *token_length += token_bytes_in_current_haystack;\n+\n+        *pos += token_start_pos_in_current_haystack + token_bytes_in_current_haystack;\n+        if (token_start_pos_in_current_haystack + token_bytes_in_current_haystack == haystack_length)\n+            // check if there are leftovers in next `haystack`\n+            continue;\n+\n+        break;\n+#else\n+        if (isASCII(data[*pos]) && !isAlphaNumericASCII(data[*pos]))\n+        {\n+            /// Finish current token if any\n+            if (*token_length > 0)\n+                return true;\n+            *token_start = ++*pos;\n+        }\n+        else\n+        {\n+            /// Note that UTF-8 sequence is completely consisted of non-ASCII bytes.\n+            ++*pos;\n+            ++*token_length;\n+        }\n+#endif\n+    }\n+\n+#if defined(__SSE2__) && !defined(MEMORY_SANITIZER)\n+    // Could happen only if string is not padded with zeros, and we accidentally hopped over the end of data.\n+    if (*token_start > length)\n+        return false;\n+    *token_length = std::min(length - *token_start, *token_length);\n+#endif\n+\n+    return *token_length > 0;\n+}\n+\n+bool SplitTokenExtractor::nextInStringLike(const char * data, size_t length, size_t * pos, String & token) const\n+{\n+    token.clear();\n+    bool bad_token = false; // % or _ before token\n+    bool escaped = false;\n+    while (*pos < length)\n+    {\n+        if (!escaped && (data[*pos] == '%' || data[*pos] == '_'))\n+        {\n+            token.clear();\n+            bad_token = true;\n+            ++*pos;\n+        }\n+        else if (!escaped && data[*pos] == '\\\\')\n+        {\n+            escaped = true;\n+            ++*pos;\n+        }\n+        else if (isASCII(data[*pos]) && !isAlphaNumericASCII(data[*pos]))\n+        {\n+            if (!bad_token && !token.empty())\n+                return true;\n+\n+            token.clear();\n+            bad_token = false;\n+            escaped = false;\n+            ++*pos;\n+        }\n+        else\n+        {\n+            const size_t sz = UTF8::seqLength(static_cast<UInt8>(data[*pos]));\n+            for (size_t j = 0; j < sz; ++j)\n+            {\n+                token += data[*pos];\n+                ++*pos;\n+            }\n+            escaped = false;\n+        }\n+    }\n+\n+    return !bad_token && !token.empty();\n+}\n+\n+}\ndiff --git a/src/Interpreters/ITokenExtractor.h b/src/Interpreters/ITokenExtractor.h\nnew file mode 100644\nindex 000000000000..afcc8442d583\n--- /dev/null\n+++ b/src/Interpreters/ITokenExtractor.h\n@@ -0,0 +1,108 @@\n+#pragma once\n+\n+#include <base/types.h>\n+\n+#include <Interpreters/BloomFilter.h>\n+\n+\n+namespace DB\n+{\n+\n+/// Interface for string parsers.\n+struct ITokenExtractor\n+{\n+    virtual ~ITokenExtractor() = default;\n+\n+    /// Fast inplace implementation for regular use.\n+    /// Gets string (data ptr and len) and start position for extracting next token (state of extractor).\n+    /// Returns false if parsing is finished, otherwise returns true.\n+    virtual bool nextInString(const char * data, size_t length, size_t * __restrict pos, size_t * __restrict token_start, size_t * __restrict token_length) const = 0;\n+\n+    /// Optimized version that can assume at least 15 padding bytes after data + len (as our Columns provide).\n+    virtual bool nextInStringPadded(const char * data, size_t length, size_t * __restrict pos, size_t * __restrict token_start, size_t * __restrict token_length) const\n+    {\n+        return nextInString(data, length, pos, token_start, token_length);\n+    }\n+\n+    /// Special implementation for creating bloom filter for LIKE function.\n+    /// It skips unescaped `%` and `_` and supports escaping symbols, but it is less lightweight.\n+    virtual bool nextInStringLike(const char * data, size_t length, size_t * pos, String & out) const = 0;\n+\n+    virtual void stringToBloomFilter(const char * data, size_t length, BloomFilter & bloom_filter) const = 0;\n+\n+    virtual void stringPaddedToBloomFilter(const char * data, size_t length, BloomFilter & bloom_filter) const\n+    {\n+        return stringToBloomFilter(data, length, bloom_filter);\n+    }\n+\n+    virtual void stringLikeToBloomFilter(const char * data, size_t length, BloomFilter & bloom_filter) const = 0;\n+\n+};\n+\n+using TokenExtractorPtr = const ITokenExtractor *;\n+\n+template <typename Derived>\n+class ITokenExtractorHelper : public ITokenExtractor\n+{\n+    void stringToBloomFilter(const char * data, size_t length, BloomFilter & bloom_filter) const override\n+    {\n+        size_t cur = 0;\n+        size_t token_start = 0;\n+        size_t token_len = 0;\n+\n+        while (cur < length && static_cast<const Derived *>(this)->nextInString(data, length, &cur, &token_start, &token_len))\n+            bloom_filter.add(data + token_start, token_len);\n+    }\n+\n+    void stringPaddedToBloomFilter(const char * data, size_t length, BloomFilter & bloom_filter) const override\n+    {\n+        size_t cur = 0;\n+        size_t token_start = 0;\n+        size_t token_len = 0;\n+\n+        while (cur < length && static_cast<const Derived *>(this)->nextInStringPadded(data, length, &cur, &token_start, &token_len))\n+            bloom_filter.add(data + token_start, token_len);\n+    }\n+\n+    void stringLikeToBloomFilter(const char * data, size_t length, BloomFilter & bloom_filter) const override\n+    {\n+        size_t cur = 0;\n+        String token;\n+        while (cur < length && static_cast<const Derived *>(this)->nextInStringLike(data, length, &cur, token))\n+            bloom_filter.add(token.c_str(), token.size());\n+    }\n+};\n+\n+\n+/// Parser extracting all ngrams from string.\n+struct NgramTokenExtractor final : public ITokenExtractorHelper<NgramTokenExtractor>\n+{\n+    explicit NgramTokenExtractor(size_t n_) : n(n_) {}\n+\n+    static const char * getName() { return \"ngrambf_v1\"; }\n+\n+    bool nextInString(const char * data, size_t length, size_t *  __restrict pos, size_t * __restrict token_start, size_t * __restrict token_length) const override;\n+\n+    bool nextInStringLike(const char * data, size_t length, size_t * pos, String & token) const override;\n+\n+    size_t getN() const { return n; }\n+\n+private:\n+\n+    size_t n;\n+};\n+\n+/// Parser extracting tokens (sequences of numbers and ascii letters).\n+struct SplitTokenExtractor final : public ITokenExtractorHelper<SplitTokenExtractor>\n+{\n+    static const char * getName() { return \"tokenbf_v1\"; }\n+\n+    bool nextInString(const char * data, size_t length, size_t * __restrict pos, size_t * __restrict token_start, size_t * __restrict token_length) const override;\n+\n+    bool nextInStringPadded(const char * data, size_t length, size_t * __restrict pos, size_t * __restrict token_start, size_t * __restrict token_length) const override;\n+\n+    bool nextInStringLike(const char * data, size_t length, size_t * __restrict pos, String & token) const override;\n+\n+};\n+\n+}\ndiff --git a/src/Storages/MergeTree/MergeTreeIndexFullText.cpp b/src/Storages/MergeTree/MergeTreeIndexFullText.cpp\nindex beaef6a10806..a8820b3f6d4e 100644\n--- a/src/Storages/MergeTree/MergeTreeIndexFullText.cpp\n+++ b/src/Storages/MergeTree/MergeTreeIndexFullText.cpp\n@@ -1,7 +1,5 @@\n #include <Storages/MergeTree/MergeTreeIndexFullText.h>\n \n-#include <Common/StringUtils/StringUtils.h>\n-#include <Common/UTF8Helpers.h>\n #include <DataTypes/DataTypesNumber.h>\n #include <DataTypes/DataTypeArray.h>\n #include <IO/WriteHelpers.h>\n@@ -19,17 +17,6 @@\n \n #include <Poco/Logger.h>\n \n-#include <boost/algorithm/string.hpp>\n-\n-#if defined(__SSE2__)\n-#include <immintrin.h>\n-\n-#if defined(__SSE4_2__)\n-#include <nmmintrin.h>\n-#endif\n-\n-#endif\n-\n \n namespace DB\n {\n@@ -41,52 +28,6 @@ namespace ErrorCodes\n     extern const int BAD_ARGUMENTS;\n }\n \n-\n-/// Adds all tokens from string to bloom filter.\n-static void stringToBloomFilter(\n-    const String & string, TokenExtractorPtr token_extractor, BloomFilter & bloom_filter)\n-{\n-    const char * data = string.data();\n-    size_t size = string.size();\n-\n-    size_t cur = 0;\n-    size_t token_start = 0;\n-    size_t token_len = 0;\n-    while (cur < size && token_extractor->nextInField(data, size, &cur, &token_start, &token_len))\n-        bloom_filter.add(data + token_start, token_len);\n-}\n-\n-static void columnToBloomFilter(\n-    const char * data, size_t size, TokenExtractorPtr token_extractor, BloomFilter & bloom_filter)\n-{\n-    size_t cur = 0;\n-    size_t token_start = 0;\n-    size_t token_len = 0;\n-    while (cur < size && token_extractor->nextInColumn(data, size, &cur, &token_start, &token_len))\n-        bloom_filter.add(data + token_start, token_len);\n-}\n-\n-\n-/// Adds all tokens from like pattern string to bloom filter. (Because like pattern can contain `\\%` and `\\_`.)\n-static void likeStringToBloomFilter(\n-    const String & data, TokenExtractorPtr token_extractor, BloomFilter & bloom_filter)\n-{\n-    size_t cur = 0;\n-    String token;\n-    while (cur < data.size() && token_extractor->nextLike(data, &cur, token))\n-        bloom_filter.add(token.c_str(), token.size());\n-}\n-\n-/// Unified condition for equals, startsWith and endsWith\n-bool MergeTreeConditionFullText::createFunctionEqualsCondition(\n-    RPNElement & out, const Field & value, const BloomFilterParameters & params, TokenExtractorPtr token_extractor)\n-{\n-    out.function = RPNElement::FUNCTION_EQUALS;\n-    out.bloom_filter = std::make_unique<BloomFilter>(params);\n-    stringToBloomFilter(value.get<String>(), token_extractor, *out.bloom_filter);\n-    return true;\n-}\n-\n MergeTreeIndexGranuleFullText::MergeTreeIndexGranuleFullText(\n     const String & index_name_,\n     size_t columns_number,\n@@ -174,7 +115,7 @@ void MergeTreeIndexAggregatorFullText::update(const Block & block, size_t * pos,\n                 for (size_t row_num = 0; row_num < elements_size; row_num++)\n                 {\n                     auto ref = column_key.getDataAt(element_start_row + row_num);\n-                    columnToBloomFilter(ref.data, ref.size, token_extractor, granule->bloom_filters[col]);\n+                    token_extractor->stringPaddedToBloomFilter(ref.data, ref.size, granule->bloom_filters[col]);\n                 }\n \n                 current_position += 1;\n@@ -185,7 +126,7 @@ void MergeTreeIndexAggregatorFullText::update(const Block & block, size_t * pos,\n             for (size_t i = 0; i < rows_read; ++i)\n             {\n                 auto ref = column->getDataAt(current_position + i);\n-                columnToBloomFilter(ref.data, ref.size, token_extractor, granule->bloom_filters[col]);\n+                token_extractor->stringPaddedToBloomFilter(ref.data, ref.size, granule->bloom_filters[col]);\n             }\n         }\n     }\n@@ -194,7 +135,6 @@ void MergeTreeIndexAggregatorFullText::update(const Block & block, size_t * pos,\n     *pos += rows_read;\n }\n \n-\n MergeTreeConditionFullText::MergeTreeConditionFullText(\n     const SelectQueryInfo & query_info,\n     ContextPtr context,\n@@ -454,9 +394,6 @@ bool MergeTreeConditionFullText::traverseASTEquals(\n     if (!value_data_type.isStringOrFixedString() && !value_data_type.isArray())\n         return false;\n \n-    if (!token_extractor->supportLike() && (function_name == \"like\" || function_name == \"notLike\"))\n-        return false;\n-\n     Field const_value = value_field;\n \n     size_t key_column_num = 0;\n@@ -527,8 +464,8 @@ bool MergeTreeConditionFullText::traverseASTEquals(\n         out.key_column = key_column_num;\n         out.function = RPNElement::FUNCTION_HAS;\n         out.bloom_filter = std::make_unique<BloomFilter>(params);\n-        stringToBloomFilter(const_value.get<String>(), token_extractor, *out.bloom_filter);\n-\n+        auto & value = const_value.get<String>();\n+        token_extractor->stringToBloomFilter(value.data(), value.size(), *out.bloom_filter);\n         return true;\n     }\n     else if (function_name == \"has\")\n@@ -536,8 +473,8 @@ bool MergeTreeConditionFullText::traverseASTEquals(\n         out.key_column = key_column_num;\n         out.function = RPNElement::FUNCTION_HAS;\n         out.bloom_filter = std::make_unique<BloomFilter>(params);\n-        stringToBloomFilter(const_value.get<String>(), token_extractor, *out.bloom_filter);\n-\n+        auto & value = const_value.get<String>();\n+        token_extractor->stringToBloomFilter(value.data(), value.size(), *out.bloom_filter);\n         return true;\n     }\n \n@@ -546,20 +483,26 @@ bool MergeTreeConditionFullText::traverseASTEquals(\n         out.key_column = key_column_num;\n         out.function = RPNElement::FUNCTION_NOT_EQUALS;\n         out.bloom_filter = std::make_unique<BloomFilter>(params);\n-        stringToBloomFilter(const_value.get<String>(), token_extractor, *out.bloom_filter);\n+        const auto & value = const_value.get<String>();\n+        token_extractor->stringToBloomFilter(value.data(), value.size(), *out.bloom_filter);\n         return true;\n     }\n     else if (function_name == \"equals\")\n     {\n         out.key_column = key_column_num;\n-        return createFunctionEqualsCondition(out, const_value, params, token_extractor);\n+        out.function = RPNElement::FUNCTION_EQUALS;\n+        out.bloom_filter = std::make_unique<BloomFilter>(params);\n+        const auto & value = const_value.get<String>();\n+        token_extractor->stringToBloomFilter(value.data(), value.size(), *out.bloom_filter);\n+        return true;\n     }\n     else if (function_name == \"like\")\n     {\n         out.key_column = key_column_num;\n         out.function = RPNElement::FUNCTION_EQUALS;\n         out.bloom_filter = std::make_unique<BloomFilter>(params);\n-        likeStringToBloomFilter(const_value.get<String>(), token_extractor, *out.bloom_filter);\n+        const auto & value = const_value.get<String>();\n+        token_extractor->stringLikeToBloomFilter(value.data(), value.size(), *out.bloom_filter);\n         return true;\n     }\n     else if (function_name == \"notLike\")\n@@ -567,7 +510,8 @@ bool MergeTreeConditionFullText::traverseASTEquals(\n         out.key_column = key_column_num;\n         out.function = RPNElement::FUNCTION_NOT_EQUALS;\n         out.bloom_filter = std::make_unique<BloomFilter>(params);\n-        likeStringToBloomFilter(const_value.get<String>(), token_extractor, *out.bloom_filter);\n+        const auto & value = const_value.get<String>();\n+        token_extractor->stringLikeToBloomFilter(value.data(), value.size(), *out.bloom_filter);\n         return true;\n     }\n     else if (function_name == \"hasToken\")\n@@ -575,18 +519,27 @@ bool MergeTreeConditionFullText::traverseASTEquals(\n         out.key_column = key_column_num;\n         out.function = RPNElement::FUNCTION_EQUALS;\n         out.bloom_filter = std::make_unique<BloomFilter>(params);\n-        stringToBloomFilter(const_value.get<String>(), token_extractor, *out.bloom_filter);\n+        const auto & value = const_value.get<String>();\n+        token_extractor->stringToBloomFilter(value.data(), value.size(), *out.bloom_filter);\n         return true;\n     }\n     else if (function_name == \"startsWith\")\n     {\n         out.key_column = key_column_num;\n-        return createFunctionEqualsCondition(out, const_value, params, token_extractor);\n+        out.function = RPNElement::FUNCTION_EQUALS;\n+        out.bloom_filter = std::make_unique<BloomFilter>(params);\n+        const auto & value = const_value.get<String>();\n+        token_extractor->stringToBloomFilter(value.data(), value.size(), *out.bloom_filter);\n+        return true;\n     }\n     else if (function_name == \"endsWith\")\n     {\n         out.key_column = key_column_num;\n-        return createFunctionEqualsCondition(out, const_value, params, token_extractor);\n+        out.function = RPNElement::FUNCTION_EQUALS;\n+        out.bloom_filter = std::make_unique<BloomFilter>(params);\n+        const auto & value = const_value.get<String>();\n+        token_extractor->stringToBloomFilter(value.data(), value.size(), *out.bloom_filter);\n+        return true;\n     }\n     else if (function_name == \"multiSearchAny\")\n     {\n@@ -602,7 +555,8 @@ bool MergeTreeConditionFullText::traverseASTEquals(\n                 return false;\n \n             bloom_filters.back().emplace_back(params);\n-            stringToBloomFilter(element.get<String>(), token_extractor, bloom_filters.back().back());\n+            const auto & value = element.get<String>();\n+            token_extractor->stringToBloomFilter(value.data(), value.size(), bloom_filters.back().back());\n         }\n         out.set_bloom_filters = std::move(bloom_filters);\n         return true;\n@@ -681,7 +635,7 @@ bool MergeTreeConditionFullText::tryPrepareSetBloomFilter(\n         {\n             bloom_filters.back().emplace_back(params);\n             auto ref = column->getDataAt(row);\n-            columnToBloomFilter(ref.data, ref.size, token_extractor, bloom_filters.back().back());\n+            token_extractor->stringPaddedToBloomFilter(ref.data, ref.size, bloom_filters.back().back());\n         }\n     }\n \n@@ -712,230 +666,6 @@ bool MergeTreeIndexFullText::mayBenefitFromIndexForIn(const ASTPtr & node) const\n     return std::find(std::cbegin(index.column_names), std::cend(index.column_names), node->getColumnName()) != std::cend(index.column_names);\n }\n \n-\n-bool NgramTokenExtractor::nextInField(const char * data, size_t len, size_t * pos, size_t * token_start, size_t * token_len) const\n-{\n-    *token_start = *pos;\n-    *token_len = 0;\n-    size_t code_points = 0;\n-    for (; code_points < n && *token_start + *token_len < len; ++code_points)\n-    {\n-        size_t sz = UTF8::seqLength(static_cast<UInt8>(data[*token_start + *token_len]));\n-        *token_len += sz;\n-    }\n-    *pos += UTF8::seqLength(static_cast<UInt8>(data[*pos]));\n-    return code_points == n;\n-}\n-\n-bool NgramTokenExtractor::nextLike(const String & str, size_t * pos, String & token) const\n-{\n-    token.clear();\n-\n-    size_t code_points = 0;\n-    bool escaped = false;\n-    for (size_t i = *pos; i < str.size();)\n-    {\n-        if (escaped && (str[i] == '%' || str[i] == '_' || str[i] == '\\\\'))\n-        {\n-            token += str[i];\n-            ++code_points;\n-            escaped = false;\n-            ++i;\n-        }\n-        else if (!escaped && (str[i] == '%' || str[i] == '_'))\n-        {\n-            /// This token is too small, go to the next.\n-            token.clear();\n-            code_points = 0;\n-            escaped = false;\n-            *pos = ++i;\n-        }\n-        else if (!escaped && str[i] == '\\\\')\n-        {\n-            escaped = true;\n-            ++i;\n-        }\n-        else\n-        {\n-            const size_t sz = UTF8::seqLength(static_cast<UInt8>(str[i]));\n-            for (size_t j = 0; j < sz; ++j)\n-                token += str[i + j];\n-            i += sz;\n-            ++code_points;\n-            escaped = false;\n-        }\n-\n-        if (code_points == n)\n-        {\n-            *pos += UTF8::seqLength(static_cast<UInt8>(str[*pos]));\n-            return true;\n-        }\n-    }\n-\n-    return false;\n-}\n-\n-\n-bool SplitTokenExtractor::nextInField(const char * data, size_t len, size_t * pos, size_t * token_start, size_t * token_len) const\n-{\n-    *token_start = *pos;\n-    *token_len = 0;\n-\n-    while (*pos < len)\n-    {\n-        if (isASCII(data[*pos]) && !isAlphaNumericASCII(data[*pos]))\n-        {\n-            /// Finish current token if any\n-            if (*token_len > 0)\n-                return true;\n-            *token_start = ++*pos;\n-        }\n-        else\n-        {\n-            /// Note that UTF-8 sequence is completely consisted of non-ASCII bytes.\n-            ++*pos;\n-            ++*token_len;\n-        }\n-    }\n-\n-    return *token_len > 0;\n-}\n-\n-bool SplitTokenExtractor::nextInColumn(const char * data, size_t len, size_t * pos, size_t * token_start, size_t * token_len) const\n-{\n-    *token_start = *pos;\n-    *token_len = 0;\n-\n-    while (*pos < len)\n-    {\n-#if defined(__SSE2__) && !defined(MEMORY_SANITIZER) /// We read uninitialized bytes and decide on the calculated mask\n-        // NOTE: we assume that `data` string is padded from the right with 15 bytes.\n-        const __m128i haystack = _mm_loadu_si128(reinterpret_cast<const __m128i *>(data + *pos));\n-        const size_t haystack_length = 16;\n-\n-#if defined(__SSE4_2__)\n-        // With the help of https://www.strchr.com/strcmp_and_strlen_using_sse_4.2\n-        const auto alnum_chars_ranges = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0,\n-                '\\xFF', '\\x80', 'z', 'a', 'Z', 'A', '9', '0');\n-        // Every bit represents if `haystack` character is in the ranges (1) or not (0)\n-        const int result_bitmask = _mm_cvtsi128_si32(_mm_cmpestrm(alnum_chars_ranges, 8, haystack, haystack_length, _SIDD_CMP_RANGES));\n-#else\n-        // NOTE: -1 and +1 required since SSE2 has no `>=` and `<=` instructions on packed 8-bit integers (epi8).\n-        const auto number_begin =      _mm_set1_epi8('0' - 1);\n-        const auto number_end =        _mm_set1_epi8('9' + 1);\n-        const auto alpha_lower_begin = _mm_set1_epi8('a' - 1);\n-        const auto alpha_lower_end =   _mm_set1_epi8('z' + 1);\n-        const auto alpha_upper_begin = _mm_set1_epi8('A' - 1);\n-        const auto alpha_upper_end =   _mm_set1_epi8('Z' + 1);\n-        const auto zero =              _mm_set1_epi8(0);\n-\n-        // every bit represents if `haystack` character `c` satisfies condition:\n-        // (c < 0) || (c > '0' - 1 && c < '9' + 1) || (c > 'a' - 1 && c < 'z' + 1) || (c > 'A' - 1 && c < 'Z' + 1)\n-        // < 0 since _mm_cmplt_epi8 threats chars as SIGNED, and so all chars > 0x80 are negative.\n-        const int result_bitmask = _mm_movemask_epi8(_mm_or_si128(_mm_or_si128(_mm_or_si128(\n-                _mm_cmplt_epi8(haystack, zero),\n-                _mm_and_si128(_mm_cmpgt_epi8(haystack, number_begin),      _mm_cmplt_epi8(haystack, number_end))),\n-                _mm_and_si128(_mm_cmpgt_epi8(haystack, alpha_lower_begin), _mm_cmplt_epi8(haystack, alpha_lower_end))),\n-                _mm_and_si128(_mm_cmpgt_epi8(haystack, alpha_upper_begin), _mm_cmplt_epi8(haystack, alpha_upper_end))));\n-#endif\n-        if (result_bitmask == 0)\n-        {\n-            if (*token_len != 0)\n-                // end of token started on previous haystack\n-                return true;\n-\n-            *pos += haystack_length;\n-            continue;\n-        }\n-\n-        const auto token_start_pos_in_current_haystack = getTrailingZeroBitsUnsafe(result_bitmask);\n-        if (*token_len == 0)\n-            // new token\n-            *token_start = *pos + token_start_pos_in_current_haystack;\n-        else if (token_start_pos_in_current_haystack != 0)\n-            // end of token starting in one of previous haystacks\n-            return true;\n-\n-        const auto token_bytes_in_current_haystack = getTrailingZeroBitsUnsafe(~(result_bitmask >> token_start_pos_in_current_haystack));\n-        *token_len += token_bytes_in_current_haystack;\n-\n-        *pos += token_start_pos_in_current_haystack + token_bytes_in_current_haystack;\n-        if (token_start_pos_in_current_haystack + token_bytes_in_current_haystack == haystack_length)\n-            // check if there are leftovers in next `haystack`\n-            continue;\n-\n-        break;\n-#else\n-        if (isASCII(data[*pos]) && !isAlphaNumericASCII(data[*pos]))\n-        {\n-            /// Finish current token if any\n-            if (*token_len > 0)\n-                return true;\n-            *token_start = ++*pos;\n-        }\n-        else\n-        {\n-            /// Note that UTF-8 sequence is completely consisted of non-ASCII bytes.\n-            ++*pos;\n-            ++*token_len;\n-        }\n-#endif\n-    }\n-\n-#if defined(__SSE2__) && !defined(MEMORY_SANITIZER)\n-    // Could happen only if string is not padded with zeros, and we accidentally hopped over the end of data.\n-    if (*token_start > len)\n-        return false;\n-    *token_len = std::min(len - *token_start, *token_len);\n-#endif\n-\n-    return *token_len > 0;\n-}\n-\n-bool SplitTokenExtractor::nextLike(const String & str, size_t * pos, String & token) const\n-{\n-    token.clear();\n-    bool bad_token = false; // % or _ before token\n-    bool escaped = false;\n-    while (*pos < str.size())\n-    {\n-        if (!escaped && (str[*pos] == '%' || str[*pos] == '_'))\n-        {\n-            token.clear();\n-            bad_token = true;\n-            ++*pos;\n-        }\n-        else if (!escaped && str[*pos] == '\\\\')\n-        {\n-            escaped = true;\n-            ++*pos;\n-        }\n-        else if (isASCII(str[*pos]) && !isAlphaNumericASCII(str[*pos]))\n-        {\n-            if (!bad_token && !token.empty())\n-                return true;\n-\n-            token.clear();\n-            bad_token = false;\n-            escaped = false;\n-            ++*pos;\n-        }\n-        else\n-        {\n-            const size_t sz = UTF8::seqLength(static_cast<UInt8>(str[*pos]));\n-            for (size_t j = 0; j < sz; ++j)\n-            {\n-                token += str[*pos];\n-                ++*pos;\n-            }\n-            escaped = false;\n-        }\n-    }\n-\n-    return !bad_token && !token.empty();\n-}\n-\n-\n MergeTreeIndexPtr bloomFilterIndexCreator(\n     const IndexDescription & index)\n {\ndiff --git a/src/Storages/MergeTree/MergeTreeIndexFullText.h b/src/Storages/MergeTree/MergeTreeIndexFullText.h\nindex f8e35fd84da7..1826719df0bd 100644\n--- a/src/Storages/MergeTree/MergeTreeIndexFullText.h\n+++ b/src/Storages/MergeTree/MergeTreeIndexFullText.h\n@@ -1,40 +1,16 @@\n #pragma once\n \n-#include <Interpreters/BloomFilter.h>\n+#include <memory>\n+\n #include <Storages/MergeTree/MergeTreeIndices.h>\n #include <Storages/MergeTree/KeyCondition.h>\n-\n-#include <memory>\n+#include <Interpreters/BloomFilter.h>\n+#include <Interpreters/ITokenExtractor.h>\n \n \n namespace DB\n {\n \n-/// Interface for string parsers.\n-struct ITokenExtractor\n-{\n-    virtual ~ITokenExtractor() = default;\n-\n-    /// Fast inplace implementation for regular use.\n-    /// Gets string (data ptr and len) and start position for extracting next token (state of extractor).\n-    /// Returns false if parsing is finished, otherwise returns true.\n-    virtual bool nextInField(const char * data, size_t len, size_t * pos, size_t * token_start, size_t * token_len) const = 0;\n-\n-    /// Optimized version that can assume at least 15 padding bytes after data + len (as our Columns provide).\n-    virtual bool nextInColumn(const char * data, size_t len, size_t * pos, size_t * token_start, size_t * token_len) const\n-    {\n-        return nextInField(data, len, pos, token_start, token_len);\n-    }\n-\n-    /// Special implementation for creating bloom filter for LIKE function.\n-    /// It skips unescaped `%` and `_` and supports escaping symbols, but it is less lightweight.\n-    virtual bool nextLike(const String & str, size_t * pos, String & out) const = 0;\n-\n-    virtual bool supportLike() const = 0;\n-};\n-\n-using TokenExtractorPtr = const ITokenExtractor *;\n-\n struct MergeTreeIndexGranuleFullText final : public IMergeTreeIndexGranule\n {\n     explicit MergeTreeIndexGranuleFullText(\n@@ -170,35 +146,6 @@ class MergeTreeConditionFullText final : public IMergeTreeIndexCondition\n     PreparedSets prepared_sets;\n };\n \n-\n-/// Parser extracting all ngrams from string.\n-struct NgramTokenExtractor final : public ITokenExtractor\n-{\n-    NgramTokenExtractor(size_t n_) : n(n_) {}\n-\n-    static String getName() { return \"ngrambf_v1\"; }\n-\n-    bool nextInField(const char * data, size_t len, size_t * pos, size_t * token_start, size_t * token_len) const override;\n-    bool nextLike(const String & str, size_t * pos, String & token) const override;\n-\n-    bool supportLike() const override { return true; }\n-\n-    size_t n;\n-};\n-\n-/// Parser extracting tokens (sequences of numbers and ascii letters).\n-struct SplitTokenExtractor final : public ITokenExtractor\n-{\n-    static String getName() { return \"tokenbf_v1\"; }\n-\n-    bool nextInField(const char * data, size_t len, size_t * pos, size_t * token_start, size_t * token_len) const override;\n-    bool nextInColumn(const char * data, size_t len, size_t * pos, size_t * token_start, size_t * token_len) const override;\n-    bool nextLike(const String & str, size_t * pos, String & token) const override;\n-\n-    bool supportLike() const override { return true; }\n-};\n-\n-\n class MergeTreeIndexFullText final : public IMergeTreeIndex\n {\n public:\n",
  "test_patch": "diff --git a/src/Storages/tests/gtest_SplitTokenExtractor.cpp b/src/Storages/tests/gtest_SplitTokenExtractor.cpp\nindex ee6a55f50b88..62389639c114 100644\n--- a/src/Storages/tests/gtest_SplitTokenExtractor.cpp\n+++ b/src/Storages/tests/gtest_SplitTokenExtractor.cpp\n@@ -61,12 +61,12 @@ TEST_P(SplitTokenExtractorTest, next)\n     for (const auto & expected_token : param.tokens)\n     {\n         SCOPED_TRACE(++i);\n-        ASSERT_TRUE(token_extractor.nextInColumn(data->data(), data->size(), &pos, &token_start, &token_len));\n+        ASSERT_TRUE(token_extractor.nextInStringPadded(data->data(), data->size(), &pos, &token_start, &token_len));\n \n         EXPECT_EQ(expected_token, std::string_view(data->data() + token_start, token_len))\n                 << \" token_start:\" << token_start << \" token_len: \" << token_len;\n     }\n-    ASSERT_FALSE(token_extractor.nextInColumn(data->data(), data->size(), &pos, &token_start, &token_len))\n+    ASSERT_FALSE(token_extractor.nextInStringPadded(data->data(), data->size(), &pos, &token_start, &token_len))\n             << \"\\n\\t=> \\\"\" << param.source.substr(token_start, token_len) << \"\\\"\"\n             << \"\\n\\t\" << token_start << \", \" << token_len << \", \" << pos << \", \" << data->size();\n }\ndiff --git a/tests/queries/0_stateless/2027_ngrams.reference b/tests/queries/0_stateless/2027_ngrams.reference\nnew file mode 100644\nindex 000000000000..4ddc2a96c421\n--- /dev/null\n+++ b/tests/queries/0_stateless/2027_ngrams.reference\n@@ -0,0 +1,20 @@\n+['T','e','s','t']\n+['Te','es','st']\n+['Tes','est']\n+['Tes','est']\n+[]\n+['T','e','s','t']\n+['Te','es','st']\n+['Tes','est']\n+['Tes','est']\n+[]\n+['T','e','s','t']\n+['Te','es','st']\n+['Tes','est']\n+['Tes','est']\n+[]\n+['T','e','s','t']\n+['Te','es','st']\n+['Tes','est']\n+['Tes','est']\n+[]\ndiff --git a/tests/queries/0_stateless/2027_ngrams.sql b/tests/queries/0_stateless/2027_ngrams.sql\nnew file mode 100644\nindex 000000000000..b2ea9facf647\n--- /dev/null\n+++ b/tests/queries/0_stateless/2027_ngrams.sql\n@@ -0,0 +1,23 @@\n+SELECT ngrams('Test', 1);\n+SELECT ngrams('Test', 2);\n+SELECT ngrams('Test', 3);\n+SELECT ngrams('Test', 3);\n+SELECT ngrams('Test', 5);\n+\n+SELECT ngrams(materialize('Test'), 1);\n+SELECT ngrams(materialize('Test'), 2);\n+SELECT ngrams(materialize('Test'), 3);\n+SELECT ngrams(materialize('Test'), 3);\n+SELECT ngrams(materialize('Test'), 5);\n+\n+SELECT ngrams(toFixedString('Test', 4), 1);\n+SELECT ngrams(toFixedString('Test', 4), 2);\n+SELECT ngrams(toFixedString('Test', 4), 3);\n+SELECT ngrams(toFixedString('Test', 4), 3);\n+SELECT ngrams(toFixedString('Test', 4), 5);\n+\n+SELECT ngrams(materialize(toFixedString('Test', 4)), 1);\n+SELECT ngrams(materialize(toFixedString('Test', 4)), 2);\n+SELECT ngrams(materialize(toFixedString('Test', 4)), 3);\n+SELECT ngrams(materialize(toFixedString('Test', 4)), 3);\n+SELECT ngrams(materialize(toFixedString('Test', 4)), 5);\n",
  "problem_statement": "A function to extract ngrams from string\n**Use case**\r\n\r\nI want to estimate better parameters for fulltext (`ngrambf_v1`) index.\r\n\r\n**Describe the solution you'd like**\r\n\r\nImplement it as SQL function:\r\n\r\n`ngrams(string, N)`\r\n\r\nthat returns array of FixedString.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nIt can be done with less efficient and more cumbersome way:\r\n\r\n```\r\nWITH 3 AS n, extractAll(text, '.') AS chars \r\nSELECT \r\n  arrayMap(x -> arrayStringConcat(x), \r\n    arrayFilter(x -> length(x) = n, \r\n      arrayMap(x, i -> arraySlice(chars, i, n), \r\n        chars, arrayEnumerate(chars)))) AS ngrams\r\n```\r\n\r\n**Additional context**\r\n\r\n`ngramsUTF8` can also be implemented to extract ngrams of Unicode code points.\n",
  "hints_text": "",
  "created_at": "2021-10-04T16:20:55Z"
}