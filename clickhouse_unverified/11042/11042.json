{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 11042,
  "instance_id": "ClickHouse__ClickHouse-11042",
  "issue_numbers": [
    "6451",
    "6462"
  ],
  "base_commit": "06d18a43784b8e16c46250400059f78eda22de5a",
  "patch": "diff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex eda76584f0b2..c3ab99bed49d 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -421,6 +421,7 @@ struct Settings : public SettingsCollection<Settings>\n     M(SettingBool, transform_null_in, false, \"If enabled, NULL values will be matched with 'IN' operator as if they are considered equal.\", 0) \\\n     M(SettingBool, allow_nondeterministic_mutations, false, \"Allow non-deterministic functions in ALTER UPDATE/ALTER DELETE statements\", 0) \\\n     M(SettingSeconds, lock_acquire_timeout, DBMS_DEFAULT_LOCK_ACQUIRE_TIMEOUT_SEC, \"How long locking request should wait before failing\", 0) \\\n+    M(SettingBool, materialize_ttl_after_modify, true, \"Apply TTL for old data, after ALTER MODIFY TTL query\", 0) \\\n     \\\n     /** Obsolete settings that do nothing but left for compatibility reasons. Remove each one after half a year of obsolescence. */ \\\n     \\\ndiff --git a/src/DataStreams/TTLBlockInputStream.cpp b/src/DataStreams/TTLBlockInputStream.cpp\nindex 692d2c0d5cfb..c9a407681663 100644\n--- a/src/DataStreams/TTLBlockInputStream.cpp\n+++ b/src/DataStreams/TTLBlockInputStream.cpp\n@@ -34,22 +34,25 @@ TTLBlockInputStream::TTLBlockInputStream(\n \n     const auto & storage_columns = storage.getColumns();\n     const auto & column_defaults = storage_columns.getDefaults();\n+\n     ASTPtr default_expr_list = std::make_shared<ASTExpressionList>();\n+    for (const auto & [name, _] : storage.column_ttl_entries_by_name)\n+    {\n+        auto it = column_defaults.find(name);\n+        if (it != column_defaults.end())\n+        {\n+            auto column = storage_columns.get(name);\n+            auto expression = it->second.expression->clone();\n+            default_expr_list->children.emplace_back(setAlias(addTypeConversionToAST(std::move(expression), column.type->getName()), it->first));\n+        }\n+    }\n+\n     for (const auto & [name, ttl_info] : old_ttl_infos.columns_ttl)\n     {\n         if (force || isTTLExpired(ttl_info.min))\n         {\n             new_ttl_infos.columns_ttl.emplace(name, IMergeTreeDataPart::TTLInfo{});\n             empty_columns.emplace(name);\n-\n-            auto it = column_defaults.find(name);\n-\n-            if (it != column_defaults.end())\n-            {\n-                auto column = storage_columns.get(name);\n-                auto expression = it->second.expression->clone();\n-                default_expr_list->children.emplace_back(setAlias(addTypeConversionToAST(std::move(expression), column.type->getName()), it->first));\n-            }\n         }\n         else\n             new_ttl_infos.columns_ttl.emplace(name, ttl_info);\ndiff --git a/src/Storages/AlterCommands.cpp b/src/Storages/AlterCommands.cpp\nindex 1921177d0d40..6ffaf0750d3d 100644\n--- a/src/Storages/AlterCommands.cpp\n+++ b/src/Storages/AlterCommands.cpp\n@@ -594,6 +594,27 @@ bool AlterCommand::isCommentAlter() const\n     return false;\n }\n \n+bool AlterCommand::isTTLAlter(const StorageInMemoryMetadata & metadata) const\n+{\n+    if (type == MODIFY_TTL)\n+        return true;\n+\n+    if (!ttl || type != MODIFY_COLUMN)\n+        return false;\n+\n+    bool ttl_changed = true;\n+    for (const auto & [name, ttl_ast] : metadata.columns.getColumnTTLs())\n+    {\n+        if (name == column_name && queryToString(*ttl) == queryToString(*ttl_ast))\n+        {\n+            ttl_changed = false;\n+            break;\n+        }\n+    }\n+\n+    return ttl_changed;\n+}\n+\n std::optional<MutationCommand> AlterCommand::tryConvertToMutationCommand(StorageInMemoryMetadata & metadata) const\n {\n     if (!isRequireMutationStage(metadata))\n@@ -944,13 +965,35 @@ bool AlterCommands::isCommentAlter() const\n     return std::all_of(begin(), end(), [](const AlterCommand & c) { return c.isCommentAlter(); });\n }\n \n+static MutationCommand createMaterializeTTLCommand()\n+{\n+    MutationCommand command;\n+    auto ast = std::make_shared<ASTAlterCommand>();\n+    ast->type = ASTAlterCommand::MATERIALIZE_TTL;\n+    command.type = MutationCommand::MATERIALIZE_TTL;\n+    command.ast = std::move(ast);\n+    return command;\n+}\n \n-MutationCommands AlterCommands::getMutationCommands(StorageInMemoryMetadata metadata) const\n+MutationCommands AlterCommands::getMutationCommands(StorageInMemoryMetadata metadata, bool materialize_ttl) const\n {\n     MutationCommands result;\n     for (const auto & alter_cmd : *this)\n         if (auto mutation_cmd = alter_cmd.tryConvertToMutationCommand(metadata); mutation_cmd)\n             result.push_back(*mutation_cmd);\n+\n+    if (materialize_ttl)\n+    {\n+        for (const auto & alter_cmd : *this)\n+        {\n+            if (alter_cmd.isTTLAlter(metadata))\n+            {\n+                result.push_back(createMaterializeTTLCommand());\n+                break;\n+            }\n+        }\n+    }\n+\n     return result;\n }\n \ndiff --git a/src/Storages/AlterCommands.h b/src/Storages/AlterCommands.h\nindex 94cf2a2ba37c..a42e7cce6465 100644\n--- a/src/Storages/AlterCommands.h\n+++ b/src/Storages/AlterCommands.h\n@@ -118,6 +118,9 @@ struct AlterCommand\n     /// Checks that only comment changed by alter\n     bool isCommentAlter() const;\n \n+    /// Checks that any TTL changed by alter\n+    bool isTTLAlter(const StorageInMemoryMetadata & metadata) const;\n+\n     /// If possible, convert alter command to mutation command. In other case\n     /// return empty optional. Some storages may execute mutations after\n     /// metadata changes.\n@@ -162,7 +165,7 @@ class AlterCommands : public std::vector<AlterCommand>\n     /// Return mutation commands which some storages may execute as part of\n     /// alter. If alter can be performed is pure metadata update, than result is\n     /// empty.\n-    MutationCommands getMutationCommands(StorageInMemoryMetadata metadata) const;\n+    MutationCommands getMutationCommands(StorageInMemoryMetadata metadata, bool materialize_ttl) const;\n };\n \n }\ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex e22e81d50413..35785c82d683 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -229,7 +229,7 @@ void StorageMergeTree::alter(\n     auto table_id = getStorageID();\n \n     StorageInMemoryMetadata metadata = getInMemoryMetadata();\n-    auto maybe_mutation_commands = commands.getMutationCommands(metadata);\n+    auto maybe_mutation_commands = commands.getMutationCommands(metadata, context.getSettingsRef().materialize_ttl_after_modify);\n     commands.apply(metadata);\n \n     /// This alter can be performed at metadata level only\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex e6fc32ecbf9b..854f9e7d4201 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -3388,7 +3388,7 @@ void StorageReplicatedMergeTree::alter(\n         alter_entry->alter_version = new_metadata_version;\n         alter_entry->create_time = time(nullptr);\n \n-        auto maybe_mutation_commands = params.getMutationCommands(current_metadata);\n+        auto maybe_mutation_commands = params.getMutationCommands(current_metadata, query_context.getSettingsRef().materialize_ttl_after_modify);\n         alter_entry->have_mutation = !maybe_mutation_commands.empty();\n \n         ops.emplace_back(zkutil::makeCreateRequest(zookeeper_path + \"/log/log-\", alter_entry->toString(), zkutil::CreateMode::PersistentSequential));\n",
  "test_patch": "diff --git a/tests/integration/test_ttl_move/test.py b/tests/integration/test_ttl_move/test.py\nindex ab348ea0cb1b..243268260d03 100644\n--- a/tests/integration/test_ttl_move/test.py\n+++ b/tests/integration/test_ttl_move/test.py\n@@ -626,7 +626,7 @@ def test_materialize_ttl_in_partition(started_cluster, name, engine):\n         node1.query(\"\"\"\n                 ALTER TABLE {name}\n                     MODIFY TTL\n-                    d1 TO DISK 'external'\n+                    d1 TO DISK 'external' SETTINGS materialize_ttl_after_modify = 0\n             \"\"\".format(name=name))\n \n         time.sleep(0.5)\ndiff --git a/tests/integration/test_ttl_replicated/test.py b/tests/integration/test_ttl_replicated/test.py\nindex 78ff703f0ecd..29169ad3c0e7 100644\n--- a/tests/integration/test_ttl_replicated/test.py\n+++ b/tests/integration/test_ttl_replicated/test.py\n@@ -109,6 +109,50 @@ def test_ttl_table(started_cluster, delete_suffix):\n     assert TSV(node1.query(\"SELECT * FROM test_ttl\")) == TSV(\"\")\n     assert TSV(node2.query(\"SELECT * FROM test_ttl\")) == TSV(\"\")\n \n+def test_modify_ttl(started_cluster):\n+    drop_table([node1, node2], \"test_ttl\")\n+    for node in [node1, node2]:\n+        node.query(\n+        '''\n+            CREATE TABLE test_ttl(d DateTime, id UInt32)\n+            ENGINE = ReplicatedMergeTree('/clickhouse/tables/test/test_ttl', '{replica}')\n+            ORDER BY id\n+        '''.format(replica=node.name))\n+\n+    node1.query(\"INSERT INTO test_ttl VALUES (now() - INTERVAL 5 HOUR, 1), (now() - INTERVAL 3 HOUR, 2), (now() - INTERVAL 1 HOUR, 3)\")\n+    node2.query(\"SYSTEM SYNC REPLICA test_ttl\", timeout=20)\n+\n+    node1.query(\"ALTER TABLE test_ttl MODIFY TTL d + INTERVAL 4 HOUR SETTINGS mutations_sync = 2\")\n+    assert node2.query(\"SELECT id FROM test_ttl\") == \"2\\n3\\n\"\n+\n+    node2.query(\"ALTER TABLE test_ttl MODIFY TTL d + INTERVAL 2 HOUR SETTINGS mutations_sync = 2\")\n+    assert node1.query(\"SELECT id FROM test_ttl\") == \"3\\n\"\n+\n+    node1.query(\"ALTER TABLE test_ttl MODIFY TTL d + INTERVAL 30 MINUTE SETTINGS mutations_sync = 2\")\n+    assert node2.query(\"SELECT id FROM test_ttl\") == \"\"\n+\n+def test_modify_column_ttl(started_cluster):\n+    drop_table([node1, node2], \"test_ttl\")\n+    for node in [node1, node2]:\n+        node.query(\n+        '''\n+            CREATE TABLE test_ttl(d DateTime, id UInt32 DEFAULT 42)\n+            ENGINE = ReplicatedMergeTree('/clickhouse/tables/test/test_ttl', '{replica}')\n+            ORDER BY d\n+        '''.format(replica=node.name))\n+\n+    node1.query(\"INSERT INTO test_ttl VALUES (now() - INTERVAL 5 HOUR, 1), (now() - INTERVAL 3 HOUR, 2), (now() - INTERVAL 1 HOUR, 3)\")\n+    node2.query(\"SYSTEM SYNC REPLICA test_ttl\", timeout=20)\n+\n+    node1.query(\"ALTER TABLE test_ttl MODIFY COLUMN id UInt32 TTL d + INTERVAL 4 HOUR SETTINGS mutations_sync = 2\")\n+    assert node2.query(\"SELECT id FROM test_ttl\") == \"42\\n2\\n3\\n\"\n+\n+    node1.query(\"ALTER TABLE test_ttl MODIFY COLUMN id UInt32 TTL d + INTERVAL 2 HOUR SETTINGS mutations_sync = 2\")\n+    assert node1.query(\"SELECT id FROM test_ttl\") == \"42\\n42\\n3\\n\"\n+\n+    node1.query(\"ALTER TABLE test_ttl MODIFY COLUMN id UInt32 TTL d + INTERVAL 30 MINUTE SETTINGS mutations_sync = 2\")\n+    assert node2.query(\"SELECT id FROM test_ttl\") == \"42\\n42\\n42\\n\"\n+\n def test_ttl_double_delete_rule_returns_error(started_cluster):\n     drop_table([node1, node2], \"test_ttl\")\n     try:\ndiff --git a/tests/queries/0_stateless/01070_materialize_ttl.reference b/tests/queries/0_stateless/01070_materialize_ttl.reference\nindex b4a9947a521f..af1b3a4459b4 100644\n--- a/tests/queries/0_stateless/01070_materialize_ttl.reference\n+++ b/tests/queries/0_stateless/01070_materialize_ttl.reference\n@@ -1,7 +1,15 @@\n+2000-10-10\t1\n+2000-10-10\t2\n 2100-10-10\t3\n 2100-10-10\t4\n+2100-10-10\t3\n+2100-10-10\t4\n+1\ta\n+3\tc\n 1\ta\n+2\tb\n 3\tc\n+4\td\n 1\ta\n 2\t\n 3\tc\ndiff --git a/tests/queries/0_stateless/01070_materialize_ttl.sql b/tests/queries/0_stateless/01070_materialize_ttl.sql\nindex 6696fbc980ac..2521ae35edf7 100755\n--- a/tests/queries/0_stateless/01070_materialize_ttl.sql\n+++ b/tests/queries/0_stateless/01070_materialize_ttl.sql\n@@ -6,9 +6,14 @@ insert into ttl values (toDateTime('2000-10-10 00:00:00'), 2);\n insert into ttl values (toDateTime('2100-10-10 00:00:00'), 3);\n insert into ttl values (toDateTime('2100-10-10 00:00:00'), 4);\n \n+set materialize_ttl_after_modify = 0;\n+\n alter table ttl materialize ttl; -- { serverError 80 }\n \n alter table ttl modify ttl d + interval 1 day;\n+-- TTL should not be applied\n+select * from ttl order by a;\n+\n alter table ttl materialize ttl settings mutations_sync=2;\n select * from ttl order by a;\n \n@@ -31,6 +36,9 @@ create table ttl (i Int, s String) engine = MergeTree order by i;\n insert into ttl values (1, 'a') (2, 'b') (3, 'c') (4, 'd');\n \n alter table ttl modify column s String ttl i % 2 = 0 ? today() - 10 : toDate('2100-01-01');\n+-- TTL should not be applied\n+select * from ttl order by i;\n+\n alter table ttl materialize ttl settings mutations_sync=2;\n select * from ttl order by i;\n \ndiff --git a/tests/queries/0_stateless/01070_modify_ttl.reference b/tests/queries/0_stateless/01070_modify_ttl.reference\nnew file mode 100644\nindex 000000000000..d64c1a4edc22\n--- /dev/null\n+++ b/tests/queries/0_stateless/01070_modify_ttl.reference\n@@ -0,0 +1,32 @@\n+2100-10-10\t3\n+2100-10-10\t4\n+=============\n+1\ta\n+3\tc\n+=============\n+=============\n+1\ta\n+2\t\n+3\tc\n+4\t\n+=============\n+1\t\n+2\t\n+3\t\n+4\t\n+=============\n+1\ta\n+2\tb\n+4\td\n+=============\n+1\t\n+2\t\n+4\td\n+=============\n+1\ta\t\n+2\tb\tbb\n+3\t\tcc\n+4\td\t\n+1\n+=============\n+0\ndiff --git a/tests/queries/0_stateless/01070_modify_ttl.sql b/tests/queries/0_stateless/01070_modify_ttl.sql\nnew file mode 100644\nindex 000000000000..4e842948afe2\n--- /dev/null\n+++ b/tests/queries/0_stateless/01070_modify_ttl.sql\n@@ -0,0 +1,74 @@\n+drop table if exists ttl;\n+\n+create table ttl (d Date, a Int) engine = MergeTree order by a partition by toDayOfMonth(d);\n+insert into ttl values (toDateTime('2000-10-10 00:00:00'), 1);\n+insert into ttl values (toDateTime('2000-10-10 00:00:00'), 2);\n+insert into ttl values (toDateTime('2100-10-10 00:00:00'), 3);\n+insert into ttl values (toDateTime('2100-10-10 00:00:00'), 4);\n+\n+set mutations_sync = 2;\n+\n+alter table ttl modify ttl d + interval 1 day;\n+select * from ttl order by a;\n+select '=============';\n+\n+drop table if exists ttl;\n+\n+create table ttl (i Int, s String) engine = MergeTree order by i;\n+insert into ttl values (1, 'a') (2, 'b') (3, 'c') (4, 'd');\n+\n+alter table ttl modify ttl i % 2 = 0 ? today() - 10 : toDate('2100-01-01');\n+select * from ttl order by i;\n+select '=============';\n+\n+alter table ttl modify ttl toDate('2000-01-01');\n+select * from ttl order by i;\n+select '=============';\n+\n+drop table if exists ttl;\n+\n+create table ttl (i Int, s String) engine = MergeTree order by i;\n+insert into ttl values (1, 'a') (2, 'b') (3, 'c') (4, 'd');\n+\n+alter table ttl modify column s String ttl i % 2 = 0 ? today() - 10 : toDate('2100-01-01');\n+select * from ttl order by i;\n+select '=============';\n+\n+alter table ttl modify column s String ttl toDate('2000-01-01');\n+select * from ttl order by i;\n+select '=============';\n+\n+drop table if exists ttl;\n+\n+create table ttl (d Date, i Int, s String) engine = MergeTree order by i;\n+insert into ttl values (toDate('2000-01-02'), 1, 'a') (toDate('2000-01-03'), 2, 'b') (toDate('2080-01-01'), 3, 'c') (toDate('2080-01-03'), 4, 'd');\n+\n+alter table ttl modify ttl i % 3 = 0 ? today() - 10 : toDate('2100-01-01');\n+select i, s from ttl order by i;\n+select '=============';\n+\n+alter table ttl modify column s String ttl d + interval 1 month;\n+select i, s from ttl order by i;\n+select '=============';\n+\n+drop table if exists ttl;\n+\n+create table ttl (i Int, s String, t String) engine = MergeTree order by i;\n+insert into ttl values (1, 'a', 'aa') (2, 'b', 'bb') (3, 'c', 'cc') (4, 'd', 'dd');\n+\n+alter table ttl modify column s String ttl i % 3 = 0 ? today() - 10 : toDate('2100-01-01'),\n+                modify column t String ttl i % 3 = 1 ? today() - 10 : toDate('2100-01-01');\n+\n+select i, s, t from ttl order by i;\n+-- MATERIALIZE TTL ran only once\n+select count() from system.mutations where table = 'ttl' and is_done;\n+select '=============';\n+\n+drop table if exists ttl;\n+\n+-- Nothing changed, don't run mutation\n+create table ttl (i Int, s String ttl toDate('2000-01-02')) engine = MergeTree order by i;\n+alter table ttl modify column s String ttl toDate('2000-01-02');\n+select count() from system.mutations where table = 'ttl' and is_done;\n+\n+drop table if exists ttl;\n",
  "problem_statement": "alter table ttl doesn't work\n**Describe the bug**\r\nALTER TABLE ontime MODIFY TTL doesn't work, the outdated data is not deleted\r\n\r\n**How to reproduce**\r\nversion: 19.8.3.8.\r\n* `CREATE TABLE` statements for all tables involved\r\n\r\n> CREATE TABLE `ontime` (\\\r\n  `Year` UInt16,\\\r\n  `Quarter` UInt8,\\\r\n  `Month` UInt8,\\\r\n  `DayofMonth` UInt8,\\\r\n  `DayOfWeek` UInt8,\\\r\n  FlightDate Date,\\\r\n  `UniqueCarrier` FixedString(7),\\\r\n  `AirlineID` Int32,\\\r\n  `Carrier` FixedString(2),\\\r\n  `TailNum` String,\\\r\n  `FlightNum` String,\\\r\n  `OriginAirportID` Int32,\\\r\n  `OriginAirportSeqID` Int32,\\\r\n  `OriginCityMarketID` Int32,\\\r\n  `Origin` FixedString(5),\\\r\n  `OriginCityName` String,\\\r\n  `OriginState` FixedString(2),\\\r\n  `OriginStateFips` String,\\\r\n  `OriginStateName` String,\\\r\n  `OriginWac` Int32,\\\r\n  `DestAirportID` Int32,\\\r\n  `DestAirportSeqID` Int32,\\\r\n  `DestCityMarketID` Int32,\\\r\n  `Dest` FixedString(5),\\\r\n  `DestCityName` String,\\\r\n  `DestState` FixedString(2),\\\r\n  `DestStateFips` String,\\\r\n  `DestStateName` String,\\\r\n  `DestWac` Int32,\\\r\n  `CRSDepTime` Int32,\\\r\n  `DepTime` Int32,\\\r\n  `DepDelay` Int32,\\\r\n  `DepDelayMinutes` Int32,\\\r\n  `DepDel15` Int32,\\\r\n  `DepartureDelayGroups` String,\\\r\n  `DepTimeBlk` String,\\\r\n  `TaxiOut` Int32,\\\r\n  `WheelsOff` Int32,\\\r\n  `WheelsOn` Int32,\\\r\n  `TaxiIn` Int32,\\\r\n  `CRSArrTime` Int32,\\\r\n  `ArrTime` Int32,\\\r\n  `ArrDelay` Int32,\\\r\n  `ArrDelayMinutes` Int32,\\\r\n  `ArrDel15` Int32,\\\r\n  `ArrivalDelayGroups` Int32,\\\r\n  `ArrTimeBlk` String,\\\r\n  `Cancelled` UInt8,\\\r\n  `CancellationCode` FixedString(1),\\\r\n  `Diverted` UInt8,\\\r\n  `CRSElapsedTime` Int32,\\\r\n  `ActualElapsedTime` Int32,\\\r\n  `AirTime` Int32,\\\r\n  `Flights` Int32,\\\r\n  `Distance` Int32,\\\r\n  `DistanceGroup` UInt8,\\\r\n  `CarrierDelay` Int32,\\\r\n  `WeatherDelay` Int32,\\\r\n  `NASDelay` Int32,\\\r\n  `SecurityDelay` Int32,\\\r\n  `LateAircraftDelay` Int32,\\\r\n  `FirstDepTime` String,\\\r\n  `TotalAddGTime` String,\\\r\n  `LongestAddGTime` String,\\\r\n  `DivAirportLandings` String,\\\r\n  `DivReachedDest` String,\\\r\n  `DivActualElapsedTime` String,\\\r\n  `DivArrDelay` String,\\\r\n  `DivDistance` String,\\\r\n  `Div1Airport` String,\\\r\n  `Div1AirportID` Int32,\\\r\n  `Div1AirportSeqID` Int32,\\\r\n  `Div1WheelsOn` String,\\\r\n  `Div1TotalGTime` String,\\\r\n  `Div1LongestGTime` String,\\\r\n  `Div1WheelsOff` String,\\\r\n  `Div1TailNum` String,\\\r\n  `Div2Airport` String,\\\r\n  `Div2AirportID` Int32,\\\r\n  `Div2AirportSeqID` Int32,\\\r\n  `Div2WheelsOn` String,\\\r\n  `Div2TotalGTime` String,\\\r\n  `Div2LongestGTime` String,\\\r\n  `Div2WheelsOff` String,\\\r\n  `Div2TailNum` String,\\\r\n  `Div3Airport` String,\\\r\n  `Div3AirportID` Int32,\\\r\n  `Div3AirportSeqID` Int32,\\\r\n  `Div3WheelsOn` String,\\\r\n  `Div3TotalGTime` String,\\\r\n  `Div3LongestGTime` String,\\\r\n  `Div3WheelsOff` String,\\\r\n  `Div3TailNum` String,\\\r\n  `Div4Airport` String,\\\r\n  `Div4AirportID` Int32,\\\r\n  `Div4AirportSeqID` Int32,\\\r\n  `Div4WheelsOn` String,\\\r\n  `Div4TotalGTime` String,\\\r\n  `Div4LongestGTime` String,\\\r\n  `Div4WheelsOff` String,\\\r\n  `Div4TailNum` String,\\\r\n  `Div5Airport` String,\\\r\n  `Div5AirportID` Int32,\\\r\n  `Div5AirportSeqID` Int32,\\\r\n  `Div5WheelsOn` String,\\\r\n  `Div5TotalGTime` String,\\\r\n  `Div5LongestGTime` String,\\\r\n  `Div5WheelsOff` String,\\\r\n  `Div5TailNum` String\\\r\n) ENGINE = \\\r\nReplicatedMergeTree('/clickhouse-test/tables/{shard}/ontime', '{replica}') \\\r\nPARTITION BY toYYYYMM(FlightDate) \\\r\nORDER BY (Year, Quarter, Month, DayofMonth, DayOfWeek, FlightDate) \\\r\nSETTINGS index_granularity = 8192\r\n\r\n* Sample data for all these tables\r\nthe ontime table data\r\n* Queries to run that lead to unexpected result\r\nALTER TABLE ontime MODIFY TTL FlightDate + INTERVAL 12 Month\r\nthen to force do merge by\r\nOPTIMIZE table ontime final;\r\n\r\n**Expected behavior**\r\nselect count(*) from ontime\r\nthe number of rows reduced\r\n\r\n**Additional context**\r\nThe show create table query shows that the ttl is actually modified, so it is not same bug as #5494\r\n\r\nWhen table is created with ttl, after import data into the table, and run the OPTIMIZE query, the number of rows is reduced\r\n\nTTL not dropping data\nI think I have TTL properly configured\r\n\r\n```sql\r\nENGINE = MergeTree \r\n    PARTITION BY toDate(received_at) \r\n    ORDER BY received_at \r\n    TTL received_at + toIntervalDay(1)\r\n```\r\n\r\nHowever my table already contains 13 days of data. \r\n\r\n```\r\nmerge_with_ttl_timeout\t86400\r\n```\r\n\r\nAm I doing something wrong?\r\n\r\nVersion 19.13.1.11\n",
  "hints_text": "Initially TTL was implemented with (maybe a bit confusing) logic, that parts created before `ALTER TABLE ... MODIFY TTL` would never be dropped by TTL. It was changed in PR #6274 and now those old parts can be filtered by TTL with `OPTIMIZE ... FINAL` query. This patch will be available in 19.14 release.\r\nNOTE: Even now extra merges with TTL won't assign automatically for parts, created before `ALTER` query. That data can be deleted only manually with `OPTIMIZE ... FINAL` query.\n@CurtizJ I think the new ttl behavior is still not good enough and is still confusing. It's better to purge out-dated data automatically. Maybe a new background scanner thread to scan parts to do the purge periodically. A part should have statistics about min/max value of a Date/Datetime column, so the scanner should not cost lots of resources to do the scan\nThis issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n\nIs it new table or altered (to add TTL) ?\r\n\r\nTTL works only for new parts after alter.\nIt\u2019s altered but like month ago. Still had to delete them manually. So I created the table from scratch with TTL set on creation. It\u2019s not dropping old parts anyway \ud83e\udd14\n\n> On Aug 13, 2019, at 5:05 PM, Denis Zhuravlev <notifications@github.com> wrote:\n> \n> Is it new table or altered (to add TTL) ?\n> \n> TTL works only for new parts after alter.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub <https://github.com/yandex/ClickHouse/issues/6462?email_source=notifications&email_token=AACQAJNZF26AYDH6DLTD5T3QELERZA5CNFSM4ILH7X62YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4F6RPQ#issuecomment-520874174>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AACQAJPN3ZW2P7USSJTQFCTQELERZANCNFSM4ILH7X6Q>.\n> \n\n\nI don't think that's related at all.\nEDIT. Yeah. I'll make my own issue and the devs can link\nThe delete works for me.\nThe mechanics of ALTER DELETE and TTLs is different.\nHello! I can confirm the bug for ClickHouse server version 19.11.3.\r\n\r\n**Scenario to reproduce the problem (current ts is 2019-08-26 14:45:00) :**\r\n```sql\r\nCREATE TABLE default.ttl_test10 (`ts` DateTime, `param` UInt32) ENGINE = MergeTree() PARTITION BY toYYYYMM(ts) ORDER BY ts TTL ts + toIntervalDay(2) ;\r\n\r\nINSERT INTO default.ttl_test10 SELECT NOW() - INTERVAL number HOUR, rand() FROM numbers(1000);\r\nOPTIMIZE TABLE default.ttl_test10;\r\n\r\nSELECT ts FROM default.ttl_test10 ORDER BY ts ASC; \r\n```\r\n\r\n**Actual result:** Select returns 433 rows in set (records for a period more than 1 month, records from 2019-07-15  till 2019-07-31 and records from 2019-08-24 till 2019-08-26). Records partially deleted (deleted period starts from 2019-08-01 till 2019-08-23).\r\n\r\n**Expected result:** Select returns only records from 2019-08-24 till 2019-08-26. Period till 2019-08-23 should be deleted.\r\n\r\nI've repeated the test several times and some time everyting works correctly.\n@santonuk your testcase is incorrect. You need to use \r\n```sql\r\nOPTIMIZE TABLE default.ttl_test10 FINAL;\r\n```\r\ninstead of\r\n```sql\r\nOPTIMIZE TABLE default.ttl_test10;\r\n```\n> It\u2019s altered but like month ago. Still had to delete them manually. So I created the table from scratch with TTL set on creation. It\u2019s not dropping old parts anyway thinking\r\n\r\nmerge_with_ttl_timeout  - that says how often cleanups happen. Did you wait such amount of time?\r\n\r\n\nBTW: this feature can be helpful for that too: https://github.com/yandex/ClickHouse/issues/5486\n> Did you wait such amount of time?\r\n\r\n\ud83e\udd14 Yes, it's 86400 (I suppose seconds, 1 day). \r\n\r\nStill deleting data from time to time by hand (script) now.\n> @santonuk your testcase is incorrect. You need to use\r\n> \r\n> ```sql\r\n> OPTIMIZE TABLE default.ttl_test10 FINAL;\r\n> ```\r\n> \r\n> instead of\r\n> \r\n> ```sql\r\n> OPTIMIZE TABLE default.ttl_test10;\r\n> ```\r\n\r\nThank you. I agree, OPTIMIZE with FINAL keyword deletes the records. \r\n\r\nThe problem persists also for another huge test table: I didn't try OPTIMIZE FINAL, but OPTIMIZE and waiting several days (merge_with_ttl_timeout = 86400) but nothing happens. I'll try to simplify it as a test scenario.\n.\nI can confirm that partitions are not dropped in:\r\nClickHouse client version 19.16.3.6.\r\nConnected to ClickHouse server version 19.16.3 revision 54427.\r\n\r\nWhen you look at system.parts table, you can see a lot of old partitions (before 2020-01-09) that doesn't have any rows, but they remain in system.parts table as well as on file system (daily directory is of size 28k).\r\nLooks like TTL empties old partitions but doesn't delete them (all partition prior 2020-01-09 should be dropped).\r\n\r\noptimize table ... final is not helping.\r\n\r\n![image](https://user-images.githubusercontent.com/15207713/72140484-2c04ad80-3391-11ea-9ff2-d61e134eb185.png)\r\n\r\nWhy TTL doesn't drop old partitions?\nI'm also seeing not dropped partitions.\r\n\r\nClickHouse server version 19.14.7 revision 54425.\r\n\r\nHere is the Engine part of the output from the 'show create table' command for the table in question\r\n\r\nCREATE TABLE default.annotated_flow_local (`timestamp` DateTime,\r\n...snip....\r\n ENGINE = MergeTree() PARTITION BY toStartOfHour(timestamp) ORDER BY (intHash64(timestamp), timestamp) SAMPLE BY intHash64(timestamp) TTL timestamp + toIntervalHour(24) SETTINGS index_granularity = 8192 \u2502\r\n\r\nAnd \r\n\r\n```\r\nSELECT \r\n    partition, \r\n    sum(rows) AS rows\r\nFROM system.parts\r\nWHERE active AND (database = currentDatabase()) AND (table = 'annotated_flow_local')\r\nGROUP BY \r\n    database, \r\n    table, \r\n    partition\r\nORDER BY \r\n    database ASC, \r\n    table ASC, \r\n    partition ASC\r\n\r\n\u250c\u2500partition\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500rows\u2500\u2510\r\n\u2502 2020-01-10 17:00:00 \u2502         0 \u2502\r\n\u2502 2020-01-10 18:00:00 \u2502 198384510 \u2502\r\n\u2502 2020-01-10 19:00:00 \u2502 195576430 \u2502\r\n\u2502 2020-01-10 20:00:00 \u2502 198362850 \u2502\r\n\u2502 2020-01-10 21:00:00 \u2502 197716732 \u2502\r\n\u2502 2020-01-10 22:00:00 \u2502 198377670 \u2502\r\n\u2502 2020-01-10 23:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-11 00:00:00 \u2502 198361140 \u2502\r\n\u2502 2020-01-11 01:00:00 \u2502 194946786 \u2502\r\n\u2502 2020-01-11 02:00:00 \u2502 198377100 \u2502\r\n\u2502 2020-01-11 03:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-11 04:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-11 05:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-11 06:00:00 \u2502 198377670 \u2502\r\n\u2502 2020-01-11 07:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-11 08:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-11 09:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-11 10:00:00 \u2502 198378240 \u2502\r\n\u2502 2020-01-11 11:00:00 \u2502 198361140 \u2502\r\n\u2502 2020-01-11 12:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-11 13:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-11 14:00:00 \u2502 197343120 \u2502\r\n\u2502 2020-01-11 15:00:00 \u2502 198302430 \u2502\r\n\u2502 2020-01-11 16:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-11 17:00:00 \u2502 198361140 \u2502\r\n\u2502 2020-01-11 18:00:00 \u2502 198378810 \u2502\r\n\u2502 2020-01-11 19:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-11 20:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-11 21:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-11 22:00:00 \u2502 198377670 \u2502\r\n\u2502 2020-01-11 23:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-12 00:00:00 \u2502 198362850 \u2502\r\n\u2502 2020-01-12 01:00:00 \u2502 198361140 \u2502\r\n\u2502 2020-01-12 02:00:00 \u2502 198378240 \u2502\r\n\u2502 2020-01-12 03:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-12 04:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-12 05:00:00 \u2502 198361140 \u2502\r\n\u2502 2020-01-12 06:00:00 \u2502 198385080 \u2502\r\n\u2502 2020-01-12 07:00:00 \u2502 198361140 \u2502\r\n\u2502 2020-01-12 08:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-12 09:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-12 10:00:00 \u2502 198378240 \u2502\r\n\u2502 2020-01-12 11:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-12 12:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-12 13:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-12 14:00:00 \u2502 198378240 \u2502\r\n\u2502 2020-01-12 15:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-12 16:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-12 17:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-12 18:00:00 \u2502 198378240 \u2502\r\n\u2502 2020-01-12 19:00:00 \u2502 198361140 \u2502\r\n\u2502 2020-01-12 20:00:00 \u2502 198361710 \u2502\r\n\u2502 2020-01-12 21:00:00 \u2502 198362850 \u2502\r\n\u2502 2020-01-12 22:00:00 \u2502 198377100 \u2502\r\n\u2502 2020-01-12 23:00:00 \u2502 198362280 \u2502\r\n\u2502 2020-01-13 00:00:00 \u2502  48690382 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n56 rows in set. Elapsed: 0.243 sec. \r\n```\nHello,\r\n\r\nUpgraded a test cluster from 19.7.3.9 (with some data) to 19.14.10.16-lts, then added some more data in existing partitions.\r\nHere is what I tried to use the TTL feature:\r\n- `ALTER TABLE analytics.vme1_shard ON CLUSTER analytics_cluster MODIFY TTL date + INTERVAL 1 DAY;`\r\n- set merge_with_ttl_timeout to 60 in the config file, restart everything\r\n- `OPTIMIZE TABLE analytics.vme1_shard ON CLUSTER analytics_cluster FINAL;` number of part goes to 1 per partition but expired partitions are still not deleted\r\n- `SYSTEM START TTL MERGES`\r\n- `OPTIMIZE TABLE analytics.vme1_shard ON CLUSTER analytics_cluster FINAL;` \r\n- tried to alter the table again\r\n\r\n```\r\nSHOW CREATE TABLE analytics.vme1_shard\r\nCREATE TABLE analytics.vme1_shard (`date` Date, `datetime` DateTime, ........ ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/{shard}/{table}', '{replica}') PARTITION BY date ORDER BY (date, toStartOfMinute(datetime), request_file, clientip) TTL date + toIntervalDay(1) SETTINGS index_granularity = 8192\r\n```\r\n\r\n```\r\nSELECT \r\n    table, \r\n    partition, \r\n    formatReadableSize(sum(bytes)) AS size, \r\n    sum(rows) AS nbrows, \r\n    formatReadableSize(sum(bytes) / sum(rows)) AS SizePerRow, \r\n    count(*)\r\nFROM system.parts\r\nWHERE active\r\nGROUP BY \r\n    table, \r\n    partition\r\nORDER BY partition ASC\r\n\r\n\u250c\u2500table\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500partition\u2500\u2500\u252c\u2500size\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500nbrows\u2500\u252c\u2500SizePerRow\u2500\u252c\u2500count()\u2500\u2510\r\n\u2502 vme1_shard \u2502 2020-01-26 \u2502 1.00 GiB   \u2502 192532594 \u2502 5.59 B     \u2502       1 \u2502\r\n\u2502 vme1_shard \u2502 2020-01-27 \u2502 600.59 MiB \u2502  94576631 \u2502 6.66 B     \u2502       1 \u2502\r\n\u2502 vme1_shard \u2502 2020-01-28 \u2502 1.78 GiB   \u2502 281076422 \u2502 6.79 B     \u2502       1 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\nWe are the 30 so all partition are expired\r\n\r\n@den-crane when you say it only works for new parts, should OPTIMIZE FINAL work (it doesn't)?\r\nOr does it only work for new partition ?\r\nAlso If I set my TTL to 6 month but then instruction change and I need to keep the data for 1 year, will the partition created when the setting was 6 months be deleted after 6 months even if I altered the table TTL to 1 year in time ?\r\nie is the TTL expression copied and stored with each part ?\n```\r\n# cat ./20200126_5946_5946_0/ttl.txt\r\nttl format version: 1\r\n{\"table\":{\"min\":1580083200,\"max\":1580083200}}\r\n```\r\nSo what we would need is a query to update the TTL of existing parts/partitions\nI also encountered the same problem. I modified the ttl of the original table to shorten it, and then used OPTIMIZE FINAL, but the expired data was not deleted\n> I also encountered the same problem. I modified the ttl of the original table to shorten it, and then used OPTIMIZE FINAL, but the expired data was not deleted\r\n\r\nSo do I ,  how about make friend In weixin or QQ, then we can talk about this problem",
  "created_at": "2020-05-19T13:18:07Z",
  "modified_files": [
    "src/Core/Settings.h",
    "src/DataStreams/TTLBlockInputStream.cpp",
    "src/Storages/AlterCommands.cpp",
    "src/Storages/AlterCommands.h",
    "src/Storages/StorageMergeTree.cpp",
    "src/Storages/StorageReplicatedMergeTree.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_ttl_move/test.py",
    "tests/integration/test_ttl_replicated/test.py",
    "tests/queries/0_stateless/01070_materialize_ttl.reference",
    "tests/queries/0_stateless/01070_materialize_ttl.sql",
    "b/tests/queries/0_stateless/01070_modify_ttl.reference",
    "b/tests/queries/0_stateless/01070_modify_ttl.sql"
  ]
}