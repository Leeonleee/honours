{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 66532,
  "instance_id": "ClickHouse__ClickHouse-66532",
  "issue_numbers": [
    "40012"
  ],
  "base_commit": "eb42cddde4087cec5b911dc32781e38c941956aa",
  "patch": "diff --git a/docs/en/operations/server-configuration-parameters/settings.md b/docs/en/operations/server-configuration-parameters/settings.md\nindex b62384877250..bb40e55133a0 100644\n--- a/docs/en/operations/server-configuration-parameters/settings.md\n+++ b/docs/en/operations/server-configuration-parameters/settings.md\n@@ -2217,6 +2217,39 @@ If the table does not exist, ClickHouse will create it. If the structure of the\n </query_log>\n ```\n \n+# query_metric_log {#query_metric_log}\n+\n+It is disabled by default.\n+\n+**Enabling**\n+\n+To manually turn on metrics history collection [`system.query_metric_log`](../../operations/system-tables/query_metric_log.md), create `/etc/clickhouse-server/config.d/query_metric_log.xml` with the following content:\n+\n+``` xml\n+<clickhouse>\n+    <query_metric_log>\n+        <database>system</database>\n+        <table>query_metric_log</table>\n+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n+        <max_size_rows>1048576</max_size_rows>\n+        <reserved_size_rows>8192</reserved_size_rows>\n+        <buffer_size_rows_flush_threshold>524288</buffer_size_rows_flush_threshold>\n+        <flush_on_crash>false</flush_on_crash>\n+    </query_metric_log>\n+</clickhouse>\n+```\n+\n+**Disabling**\n+\n+To disable `query_metric_log` setting, you should create the following file `/etc/clickhouse-server/config.d/disable_query_metric_log.xml` with the following content:\n+\n+``` xml\n+<clickhouse>\n+<query_metric_log remove=\"1\" />\n+</clickhouse>\n+```\n+\n ## query_cache {#server_configuration_parameters_query-cache}\n \n [Query cache](../query-cache.md) configuration.\n@@ -3109,7 +3142,7 @@ By default, tunneling (i.e, `HTTP CONNECT`) is used to make `HTTPS` requests ove\n \n ### no_proxy\n By default, all requests will go through the proxy. In order to disable it for specific hosts, the `no_proxy` variable must be set.\n-It can be set inside the `<proxy>` clause for list and remote resolvers and as an environment variable for environment resolver. \n+It can be set inside the `<proxy>` clause for list and remote resolvers and as an environment variable for environment resolver.\n It supports IP addresses, domains, subdomains and `'*'` wildcard for full bypass. Leading dots are stripped just like curl does.\n \n Example:\ndiff --git a/docs/en/operations/system-tables/query_metric_log.md b/docs/en/operations/system-tables/query_metric_log.md\nnew file mode 100644\nindex 000000000000..38d44c0e19ad\n--- /dev/null\n+++ b/docs/en/operations/system-tables/query_metric_log.md\n@@ -0,0 +1,49 @@\n+---\n+slug: /en/operations/system-tables/query_metric_log\n+---\n+# query_metric_log\n+\n+Contains history of memory and metric values from table `system.events` for individual queries, periodically flushed to disk.\n+\n+Once a query starts, data is collected at periodic intervals of `query_metric_log_interval` milliseconds (which is set to 1000\n+by default). The data is also collected when the query finishes if the query takes longer than `query_metric_log_interval`.\n+\n+Columns:\n+- `query_id` ([String](../../sql-reference/data-types/string.md)) \u2014 ID of the query.\n+- `hostname` ([LowCardinality(String)](../../sql-reference/data-types/string.md)) \u2014 Hostname of the server executing the query.\n+- `event_date` ([Date](../../sql-reference/data-types/date.md)) \u2014 Event date.\n+- `event_time` ([DateTime](../../sql-reference/data-types/datetime.md)) \u2014 Event time.\n+- `event_time_microseconds` ([DateTime64](../../sql-reference/data-types/datetime64.md)) \u2014 Event time with microseconds resolution.\n+\n+**Example**\n+\n+``` sql\n+SELECT * FROM system.query_metric_log LIMIT 1 FORMAT Vertical;\n+```\n+\n+``` text\n+Row 1:\n+\u2500\u2500\u2500\u2500\u2500\u2500\n+query_id:                                                        97c8ba04-b6d4-4bd7-b13e-6201c5c6e49d\n+hostname:                                                        clickhouse.eu-central1.internal\n+event_date:                                                      2020-09-05\n+event_time:                                                      2020-09-05 16:22:33\n+event_time_microseconds:                                         2020-09-05 16:22:33.196807\n+memory_usage:                                                    313434219\n+peak_memory_usage:                                               598951986\n+ProfileEvent_Query:                                              0\n+ProfileEvent_SelectQuery:                                        0\n+ProfileEvent_InsertQuery:                                        0\n+ProfileEvent_FailedQuery:                                        0\n+ProfileEvent_FailedSelectQuery:                                  0\n+...\n+```\n+\n+**See also**\n+\n+- [query_metric_log setting](../../operations/server-configuration-parameters/settings.md#query_metric_log) \u2014 Enabling and disabling the setting.\n+- [query_metric_log_interval](../../operations/settings/settings.md#query_metric_log_interval)\n+- [system.asynchronous_metrics](../../operations/system-tables/asynchronous_metrics.md) \u2014 Contains periodically calculated metrics.\n+- [system.events](../../operations/system-tables/events.md#system_tables-events) \u2014 Contains a number of events that occurred.\n+- [system.metrics](../../operations/system-tables/metrics.md) \u2014 Contains instantly calculated metrics.\n+- [Monitoring](../../operations/monitoring.md) \u2014 Base concepts of ClickHouse monitoring.\ndiff --git a/programs/server/config.xml b/programs/server/config.xml\nindex 10ad831465ac..28f1f465c719 100644\n--- a/programs/server/config.xml\n+++ b/programs/server/config.xml\n@@ -1195,6 +1195,19 @@\n         <flush_on_crash>false</flush_on_crash>\n     </error_log>\n \n+    <!-- Query metric log contains rows Contains history of memory and metric values from table system.events for individual queries, periodically flushed to disk\n+    every \"collect_interval_milliseconds\" interval-->\n+    <query_metric_log>\n+        <database>system</database>\n+        <table>query_metric_log</table>\n+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n+        <max_size_rows>1048576</max_size_rows>\n+        <reserved_size_rows>8192</reserved_size_rows>\n+        <buffer_size_rows_flush_threshold>524288</buffer_size_rows_flush_threshold>\n+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n+        <flush_on_crash>false</flush_on_crash>\n+    </query_metric_log>\n+\n     <!--\n         Asynchronous metric log contains values of metrics from\n         system.asynchronous_metrics.\ndiff --git a/programs/server/config.yaml.example b/programs/server/config.yaml.example\nindex 5d5499f876c7..5b0330df5725 100644\n--- a/programs/server/config.yaml.example\n+++ b/programs/server/config.yaml.example\n@@ -743,6 +743,13 @@ error_log:\n     flush_interval_milliseconds: 7500\n     collect_interval_milliseconds: 1000\n \n+# Query metric log contains history of memory and metric values from table system.events for individual queries, periodically flushed to disk.\n+query_metric_log:\n+    database: system\n+    table: query_metric_log\n+    flush_interval_milliseconds: 7500\n+    collect_interval_milliseconds: 1000\n+\n # Asynchronous metric log contains values of metrics from\n # system.asynchronous_metrics.\n asynchronous_metric_log:\ndiff --git a/src/Common/CurrentMetrics.cpp b/src/Common/CurrentMetrics.cpp\nindex e9d5e07c9144..c4318fb0fda6 100644\n--- a/src/Common/CurrentMetrics.cpp\n+++ b/src/Common/CurrentMetrics.cpp\n@@ -27,8 +27,8 @@\n     M(BackgroundBufferFlushSchedulePoolSize, \"Limit on number of tasks in BackgroundBufferFlushSchedulePool\") \\\n     M(BackgroundDistributedSchedulePoolTask, \"Number of active tasks in BackgroundDistributedSchedulePool. This pool is used for distributed sends that is done in background.\") \\\n     M(BackgroundDistributedSchedulePoolSize, \"Limit on number of tasks in BackgroundDistributedSchedulePool\") \\\n-    M(BackgroundMessageBrokerSchedulePoolTask, \"Number of active tasks in BackgroundProcessingPool for message streaming\") \\\n-    M(BackgroundMessageBrokerSchedulePoolSize, \"Limit on number of tasks in BackgroundProcessingPool for message streaming\") \\\n+    M(BackgroundMessageBrokerSchedulePoolTask, \"Number of active tasks in BackgroundMessageBrokerSchedulePool for message streaming\") \\\n+    M(BackgroundMessageBrokerSchedulePoolSize, \"Limit on number of tasks in BackgroundMessageBrokerSchedulePool for message streaming\") \\\n     M(CacheDictionaryUpdateQueueBatches, \"Number of 'batches' (a set of keys) in update queue in CacheDictionaries.\") \\\n     M(CacheDictionaryUpdateQueueKeys, \"Exact number of keys in update queue in CacheDictionaries.\") \\\n     M(DiskSpaceReservedForMerge, \"Disk space reserved for currently running background merges. It is slightly more than the total size of currently merging parts.\") \\\ndiff --git a/src/Common/CurrentMetrics.h b/src/Common/CurrentMetrics.h\nindex 2c64fd29bbb6..1c0de91a0bf4 100644\n--- a/src/Common/CurrentMetrics.h\n+++ b/src/Common/CurrentMetrics.h\n@@ -1,7 +1,6 @@\n #pragma once\n \n #include <cstddef>\n-#include <cstdint>\n #include <utility>\n #include <atomic>\n #include <cassert>\ndiff --git a/src/Common/LockGuard.h b/src/Common/LockGuard.h\nnew file mode 100644\nindex 000000000000..8a98c5f553a4\n--- /dev/null\n+++ b/src/Common/LockGuard.h\n@@ -0,0 +1,37 @@\n+#pragma once\n+\n+#include <Common/OvercommitTracker.h>\n+#include <base/defines.h>\n+\n+namespace DB\n+{\n+\n+/** LockGuard provides RAII-style locking mechanism for a mutex.\n+ ** It's intended to be used like std::unique_ptr but with TSA annotations\n+  */\n+template <typename Mutex>\n+class TSA_SCOPED_LOCKABLE LockGuard\n+{\n+public:\n+    explicit LockGuard(Mutex & mutex_) TSA_ACQUIRE(mutex_) : mutex(mutex_) { mutex.lock(); }\n+    ~LockGuard() TSA_RELEASE() { mutex.unlock(); }\n+\n+private:\n+    Mutex & mutex;\n+};\n+\n+template <template<typename> typename TLockGuard, typename Mutex>\n+class TSA_SCOPED_LOCKABLE LockAndOverCommitTrackerBlocker\n+{\n+public:\n+    explicit LockAndOverCommitTrackerBlocker(Mutex & mutex_) TSA_ACQUIRE(mutex_) : lock(TLockGuard(mutex_)) {}\n+    ~LockAndOverCommitTrackerBlocker() TSA_RELEASE() = default;\n+\n+    TLockGuard<Mutex> & getUnderlyingLock() { return lock; }\n+\n+private:\n+    TLockGuard<Mutex> lock;\n+    OvercommitTrackerBlockerInThread blocker = {};\n+};\n+\n+}\ndiff --git a/src/Common/OvercommitTracker.cpp b/src/Common/OvercommitTracker.cpp\nindex 2a453596dab7..751a61b7a41d 100644\n--- a/src/Common/OvercommitTracker.cpp\n+++ b/src/Common/OvercommitTracker.cpp\n@@ -45,7 +45,7 @@ OvercommitResult OvercommitTracker::needToStopQuery(MemoryTracker * tracker, Int\n     // method OvercommitTracker::onQueryStop(MemoryTracker *) is\n     // always called with already acquired global mutex in\n     // ProcessListEntry::~ProcessListEntry().\n-    auto global_lock = process_list->unsafeLock();\n+    DB::ProcessList::Lock global_lock(process_list->getMutex());\n     std::unique_lock<std::mutex> lk(overcommit_m);\n \n     size_t id = next_id++;\ndiff --git a/src/Common/SharedLockGuard.h b/src/Common/SharedLockGuard.h\nindex 93d2f42e9076..92af93d6b37c 100644\n--- a/src/Common/SharedLockGuard.h\n+++ b/src/Common/SharedLockGuard.h\n@@ -5,7 +5,7 @@\n namespace DB\n {\n \n-/** SharedLockGuard provide RAII-style locking mechanism for acquiring shared ownership of the implementation\n+/** SharedLockGuard provides RAII-style locking mechanism for acquiring shared ownership of the implementation\n   * of the SharedLockable concept (for example std::shared_mutex or ContextSharedMutex) supplied as the\n   * constructor argument. Think of it as std::lock_guard which locks shared.\n   *\ndiff --git a/src/Common/SystemLogBase.cpp b/src/Common/SystemLogBase.cpp\nindex 1bd79999cd7f..656e4fce2c50 100644\n--- a/src/Common/SystemLogBase.cpp\n+++ b/src/Common/SystemLogBase.cpp\n@@ -4,6 +4,7 @@\n #include <Interpreters/MetricLog.h>\n #include <Interpreters/OpenTelemetrySpanLog.h>\n #include <Interpreters/PartLog.h>\n+#include <Interpreters/QueryMetricLog.h>\n #include <Interpreters/QueryLog.h>\n #include <Interpreters/QueryThreadLog.h>\n #include <Interpreters/QueryViewsLog.h>\n@@ -18,6 +19,7 @@\n #include <Interpreters/TransactionsInfoLog.h>\n #include <Interpreters/AsynchronousInsertLog.h>\n #include <Interpreters/BackupLog.h>\n+#include <Interpreters/PeriodicLog.h>\n #include <IO/S3/BlobStorageLogWriter.h>\n \n #include <Common/MemoryTrackerBlockerInThread.h>\n@@ -299,8 +301,10 @@ void SystemLogBase<LogElement>::add(LogElement element)\n \n #define INSTANTIATE_SYSTEM_LOG_BASE(ELEMENT) template class SystemLogBase<ELEMENT>;\n SYSTEM_LOG_ELEMENTS(INSTANTIATE_SYSTEM_LOG_BASE)\n+SYSTEM_PERIODIC_LOG_ELEMENTS(INSTANTIATE_SYSTEM_LOG_BASE)\n \n #define INSTANTIATE_SYSTEM_LOG_QUEUE(ELEMENT) template class SystemLogQueue<ELEMENT>;\n SYSTEM_LOG_ELEMENTS(INSTANTIATE_SYSTEM_LOG_QUEUE)\n+SYSTEM_PERIODIC_LOG_ELEMENTS(INSTANTIATE_SYSTEM_LOG_QUEUE)\n \n }\ndiff --git a/src/Common/SystemLogBase.h b/src/Common/SystemLogBase.h\nindex 0942e920a42e..0bf5570f1228 100644\n--- a/src/Common/SystemLogBase.h\n+++ b/src/Common/SystemLogBase.h\n@@ -14,7 +14,6 @@\n #define SYSTEM_LOG_ELEMENTS(M) \\\n     M(AsynchronousMetricLogElement) \\\n     M(CrashLogElement) \\\n-    M(MetricLogElement) \\\n     M(OpenTelemetrySpanLogElement) \\\n     M(PartLogElement) \\\n     M(QueryLogElement) \\\n@@ -32,7 +31,7 @@\n     M(AsynchronousInsertLogElement) \\\n     M(BackupLogElement) \\\n     M(BlobStorageLogElement) \\\n-    M(ErrorLogElement)\n+    M(QueryMetricLogElement)\n \n namespace Poco\n {\ndiff --git a/src/Core/Settings.cpp b/src/Core/Settings.cpp\nindex 925c2b38b4c0..d29f60f692dc 100644\n--- a/src/Core/Settings.cpp\n+++ b/src/Core/Settings.cpp\n@@ -2762,6 +2762,15 @@ SELECT type, query FROM system.query_log WHERE log_comment = 'log_comment test'\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n ```\n )\", 0) \\\n+    DECLARE(Int64, query_metric_log_interval, -1, R\"(\n+The interval in milliseconds at which the [query_metric_log](../../operations/system-tables/query_metric_log.md) for individual queries is collected.\n+\n+If set to any negative value, it will take the value `collect_interval_milliseconds` from the [query_metric_log setting](../../operations/server-configuration-parameters/settings.md#query_metric_log) or default to 1000 if not present.\n+\n+To disable the collection of a single query, set `query_metric_log_interval` to 0.\n+\n+Default value: -1\n+    )\", 0) \\\n     DECLARE(LogsLevel, send_logs_level, LogsLevel::fatal, R\"(\n Send server text logs with specified minimum level to client. Valid values: 'trace', 'debug', 'information', 'warning', 'error', 'fatal', 'none'\n )\", 0) \\\ndiff --git a/src/Core/SettingsChangesHistory.cpp b/src/Core/SettingsChangesHistory.cpp\nindex d958d0919754..88d39d6d3938 100644\n--- a/src/Core/SettingsChangesHistory.cpp\n+++ b/src/Core/SettingsChangesHistory.cpp\n@@ -68,6 +68,7 @@ static std::initializer_list<std::pair<ClickHouseVersion, SettingsChangesHistory\n     },\n     {\"24.10\",\n         {\n+            {\"query_metric_log_interval\", 0, -1, \"New setting.\"},\n             {\"enforce_strict_identifier_format\", false, false, \"New setting.\"},\n             {\"enable_parsing_to_custom_serialization\", false, true, \"New setting\"},\n             {\"mongodb_throw_on_unsupported_query\", false, true, \"New setting.\"},\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex d0adf2102a14..b8e178e402bd 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -4249,6 +4249,16 @@ std::shared_ptr<QueryLog> Context::getQueryLog() const\n     return shared->system_logs->query_log;\n }\n \n+std::shared_ptr<QueryMetricLog> Context::getQueryMetricLog() const\n+{\n+    SharedLockGuard lock(shared->mutex);\n+\n+    if (!shared->system_logs)\n+        return {};\n+\n+    return shared->system_logs->query_metric_log;\n+}\n+\n std::shared_ptr<QueryThreadLog> Context::getQueryThreadLog() const\n {\n     SharedLockGuard lock(shared->mutex);\ndiff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h\nindex b3af82bcc54b..c62c16098e5c 100644\n--- a/src/Interpreters/Context.h\n+++ b/src/Interpreters/Context.h\n@@ -101,6 +101,7 @@ class Clusters;\n class QueryCache;\n class ISystemLog;\n class QueryLog;\n+class QueryMetricLog;\n class QueryThreadLog;\n class QueryViewsLog;\n class PartLog;\n@@ -1174,6 +1175,7 @@ class Context: public ContextData, public std::enable_shared_from_this<Context>\n     std::shared_ptr<AsynchronousInsertLog> getAsynchronousInsertLog() const;\n     std::shared_ptr<BackupLog> getBackupLog() const;\n     std::shared_ptr<BlobStorageLog> getBlobStorageLog() const;\n+    std::shared_ptr<QueryMetricLog> getQueryMetricLog() const;\n \n     SystemLogs getSystemLogs() const;\n \ndiff --git a/src/Interpreters/ErrorLog.cpp b/src/Interpreters/ErrorLog.cpp\nindex 42616f13e24d..efee1c359ad2 100644\n--- a/src/Interpreters/ErrorLog.cpp\n+++ b/src/Interpreters/ErrorLog.cpp\n@@ -1,3 +1,6 @@\n+#include <base/getFQDNOrHostName.h>\n+#include <Common/DateLUTImpl.h>\n+#include <Common/ErrorCodes.h>\n #include <DataTypes/DataTypeDate.h>\n #include <DataTypes/DataTypeDateTime.h>\n #include <DataTypes/DataTypeDateTime64.h>\n@@ -5,10 +8,6 @@\n #include <DataTypes/DataTypeString.h>\n #include <DataTypes/DataTypesNumber.h>\n #include <Interpreters/ErrorLog.h>\n-#include <base/getFQDNOrHostName.h>\n-#include <Common/DateLUTImpl.h>\n-#include <Common/ThreadPool.h>\n-#include <Common/ErrorCodes.h>\n #include <Parsers/ExpressionElementParsers.h>\n #include <Parsers/parseQuery.h>\n \n@@ -114,7 +113,7 @@ void ErrorLog::stepFunction(TimePoint current_time)\n                 .value=error.remote.count - previous_values.at(code).remote,\n                 .remote=true\n             };\n-            this->add(std::move(remote_elem));\n+            add(std::move(remote_elem));\n             previous_values[code].remote = error.remote.count;\n         }\n     }\ndiff --git a/src/Interpreters/ErrorLog.h b/src/Interpreters/ErrorLog.h\nindex 4afe334d4de3..69db549f45e8 100644\n--- a/src/Interpreters/ErrorLog.h\n+++ b/src/Interpreters/ErrorLog.h\n@@ -1,6 +1,5 @@\n #pragma once\n \n-#include <Interpreters/SystemLog.h>\n #include <Interpreters/PeriodicLog.h>\n #include <Common/ErrorCodes.h>\n #include <Core/NamesAndTypes.h>\ndiff --git a/src/Interpreters/MetricLog.cpp b/src/Interpreters/MetricLog.cpp\nindex 596b0e4f96c9..16a88b976ba1 100644\n--- a/src/Interpreters/MetricLog.cpp\n+++ b/src/Interpreters/MetricLog.cpp\n@@ -1,3 +1,5 @@\n+#include <base/getFQDNOrHostName.h>\n+#include <Common/DateLUTImpl.h>\n #include <DataTypes/DataTypeDate.h>\n #include <DataTypes/DataTypeDateTime.h>\n #include <DataTypes/DataTypeDateTime64.h>\n@@ -5,9 +7,6 @@\n #include <DataTypes/DataTypeString.h>\n #include <DataTypes/DataTypesNumber.h>\n #include <Interpreters/MetricLog.h>\n-#include <base/getFQDNOrHostName.h>\n-#include <Common/DateLUTImpl.h>\n-#include <Common/ThreadPool.h>\n \n \n namespace DB\n@@ -81,7 +80,7 @@ void MetricLog::stepFunction(const std::chrono::system_clock::time_point current\n         elem.current_metrics[i] = CurrentMetrics::values[i];\n     }\n \n-    this->add(std::move(elem));\n+    add(std::move(elem));\n }\n \n }\ndiff --git a/src/Interpreters/MetricLog.h b/src/Interpreters/MetricLog.h\nindex a6fd3ecfcd3d..ffb5464916a2 100644\n--- a/src/Interpreters/MetricLog.h\n+++ b/src/Interpreters/MetricLog.h\n@@ -1,6 +1,5 @@\n #pragma once\n \n-#include <Interpreters/SystemLog.h>\n #include <Interpreters/PeriodicLog.h>\n #include <Common/ProfileEvents.h>\n #include <Common/CurrentMetrics.h>\ndiff --git a/src/Interpreters/PartLog.cpp b/src/Interpreters/PartLog.cpp\nindex 7a4c563e7024..b7b3a16473f9 100644\n--- a/src/Interpreters/PartLog.cpp\n+++ b/src/Interpreters/PartLog.cpp\n@@ -284,9 +284,9 @@ bool PartLog::addNewParts(\n     return true;\n }\n \n-bool PartLog::addNewPart(ContextPtr context, const PartLog::PartLogEntry & part, const ExecutionStatus & execution_status)\n+bool PartLog::addNewPart(ContextPtr context_, const PartLog::PartLogEntry & part, const ExecutionStatus & execution_status)\n {\n-    return addNewParts(context, {part}, execution_status);\n+    return addNewParts(context_, {part}, execution_status);\n }\n \n \ndiff --git a/src/Interpreters/PeriodicLog.cpp b/src/Interpreters/PeriodicLog.cpp\nindex 22bc14856c47..4222c2f90adc 100644\n--- a/src/Interpreters/PeriodicLog.cpp\n+++ b/src/Interpreters/PeriodicLog.cpp\n@@ -1,16 +1,22 @@\n-#include <Interpreters/PeriodicLog.h>\n+#include <Common/setThreadName.h>\n+#include <Common/SystemLogBase.h>\n #include <Interpreters/ErrorLog.h>\n #include <Interpreters/MetricLog.h>\n+#include <Interpreters/PeriodicLog.h>\n+#include <Interpreters/QueryMetricLog.h>\n \n namespace DB\n {\n \n template <typename LogElement>\n-void PeriodicLog<LogElement>::startCollect(size_t collect_interval_milliseconds_)\n+void PeriodicLog<LogElement>::startCollect(const String & thread_name, size_t collect_interval_milliseconds_)\n {\n     collect_interval_milliseconds = collect_interval_milliseconds_;\n     is_shutdown_metric_thread = false;\n-    collecting_thread = std::make_unique<ThreadFromGlobalPool>([this] { threadFunction(); });\n+    collecting_thread = std::make_unique<ThreadFromGlobalPool>([this, thread_name] {\n+        setThreadName(thread_name.c_str());\n+        threadFunction();\n+    });\n }\n \n template <typename LogElement>\n@@ -56,7 +62,7 @@ void PeriodicLog<LogElement>::threadFunction()\n     }\n }\n \n-#define INSTANTIATE_SYSTEM_LOG(ELEMENT) template class PeriodicLog<ELEMENT>;\n-SYSTEM_PERIODIC_LOG_ELEMENTS(INSTANTIATE_SYSTEM_LOG)\n+#define INSTANTIATE_PERIODIC_SYSTEM_LOG(ELEMENT) template class PeriodicLog<ELEMENT>;\n+SYSTEM_PERIODIC_LOG_ELEMENTS(INSTANTIATE_PERIODIC_SYSTEM_LOG)\n \n }\ndiff --git a/src/Interpreters/PeriodicLog.h b/src/Interpreters/PeriodicLog.h\nindex 8254a02434a0..16faeea8ff69 100644\n--- a/src/Interpreters/PeriodicLog.h\n+++ b/src/Interpreters/PeriodicLog.h\n@@ -22,8 +22,8 @@ class PeriodicLog : public SystemLog<LogElement>\n public:\n     using TimePoint = std::chrono::system_clock::time_point;\n \n-    /// Launches a background thread to collect metrics with interval\n-    void startCollect(size_t collect_interval_milliseconds_);\n+    /// Launches a background thread to collect metrics with periodic interval\n+    void startCollect(const String & thread_name, size_t collect_interval_milliseconds_);\n \n     void shutdown() final;\n \ndiff --git a/src/Interpreters/ProcessList.cpp b/src/Interpreters/ProcessList.cpp\nindex 0860e94c45eb..177468f1c8b0 100644\n--- a/src/Interpreters/ProcessList.cpp\n+++ b/src/Interpreters/ProcessList.cpp\n@@ -106,7 +106,8 @@ ProcessList::insert(const String & query_, const IAST * ast, ContextMutablePtr q\n     bool is_unlimited_query = isUnlimitedQuery(ast);\n \n     {\n-        auto [lock, overcommit_blocker] = safeLock(); // To avoid deadlock in case of OOM\n+        LockAndOverCommitTrackerBlocker<std::unique_lock, Mutex> locker(mutex); // To avoid deadlock in case of OOM\n+        auto & lock = locker.getUnderlyingLock();\n         IAST::QueryKind query_kind = ast->getQueryKind();\n \n         const auto queue_max_wait_ms = settings[Setting::queue_max_wait_ms].totalMilliseconds();\n@@ -333,7 +334,7 @@ ProcessList::insert(const String & query_, const IAST * ast, ContextMutablePtr q\n \n ProcessListEntry::~ProcessListEntry()\n {\n-    auto lock = parent.safeLock();\n+    LockAndOverCommitTrackerBlocker<std::unique_lock, ProcessList::Mutex> lock(parent.getMutex());\n \n     String user = (*it)->getClientInfo().current_user;\n     String query_id = (*it)->getClientInfo().current_query_id;\n@@ -362,7 +363,7 @@ ProcessListEntry::~ProcessListEntry()\n     }\n \n     /// Wait for the query if it is in the cancellation right now.\n-    parent.cancelled_cv.wait(lock.lock, [&]() { return process_list_element_ptr->is_cancelling == false; });\n+    parent.cancelled_cv.wait(lock.getUnderlyingLock(), [&]() { return process_list_element_ptr->is_cancelling == false; });\n \n     if (auto query_user = parent.queries_to_user.find(query_id); query_user != parent.queries_to_user.end())\n         parent.queries_to_user.erase(query_user);\n@@ -588,7 +589,7 @@ CancellationCode ProcessList::sendCancelToQuery(const String & current_query_id,\n     /// So here we first set is_cancelling, and later reset it.\n     /// The ProcessListEntry cannot be destroy if is_cancelling is true.\n     {\n-        auto lock = safeLock();\n+        LockAndBlocker lock(mutex);\n         elem = tryGetProcessListElement(current_query_id, current_user);\n         if (!elem)\n             return CancellationCode::NotFound;\n@@ -598,7 +599,7 @@ CancellationCode ProcessList::sendCancelToQuery(const String & current_query_id,\n     SCOPE_EXIT({\n         DENY_ALLOCATIONS_IN_SCOPE;\n \n-        auto lock = unsafeLock();\n+        Lock lock(mutex);\n         elem->is_cancelling = false;\n         cancelled_cv.notify_all();\n     });\n@@ -613,14 +614,14 @@ CancellationCode ProcessList::sendCancelToQuery(QueryStatusPtr elem, bool kill)\n     /// So here we first set is_cancelling, and later reset it.\n     /// The ProcessListEntry cannot be destroy if is_cancelling is true.\n     {\n-        auto lock = safeLock();\n+        LockAndBlocker lock(mutex);\n         elem->is_cancelling = true;\n     }\n \n     SCOPE_EXIT({\n         DENY_ALLOCATIONS_IN_SCOPE;\n \n-        auto lock = unsafeLock();\n+        Lock lock(mutex);\n         elem->is_cancelling = false;\n         cancelled_cv.notify_all();\n     });\n@@ -634,14 +635,14 @@ void ProcessList::killAllQueries()\n     std::vector<QueryStatusPtr> cancelled_processes;\n \n     SCOPE_EXIT({\n-        auto lock = safeLock();\n+        LockAndBlocker lock(mutex);\n         for (auto & cancelled_process : cancelled_processes)\n             cancelled_process->is_cancelling = false;\n         cancelled_cv.notify_all();\n     });\n \n     {\n-        auto lock = safeLock();\n+        LockAndBlocker lock(mutex);\n         cancelled_processes.reserve(processes.size());\n         for (auto & process : processes)\n         {\n@@ -707,7 +708,7 @@ ProcessList::Info ProcessList::getInfo(bool get_thread_list, bool get_profile_ev\n     std::vector<QueryStatusPtr> processes_copy;\n \n     {\n-        auto lock = safeLock();\n+        LockAndBlocker lock(mutex);\n         processes_copy.assign(processes.begin(), processes.end());\n     }\n \n@@ -719,6 +720,26 @@ ProcessList::Info ProcessList::getInfo(bool get_thread_list, bool get_profile_ev\n     return per_query_infos;\n }\n \n+QueryStatusPtr ProcessList::getProcessListElement(const String & query_id) const\n+{\n+    LockAndBlocker lock(mutex);\n+    for (const auto & process : processes)\n+    {\n+        if (process->client_info.current_query_id == query_id)\n+            return process;\n+    }\n+\n+    return nullptr;\n+}\n+\n+QueryStatusInfoPtr ProcessList::getQueryInfo(const String & query_id, bool get_thread_list, bool get_profile_events, bool get_settings) const\n+{\n+    auto process = getProcessListElement(query_id);\n+    if (process)\n+        return std::make_shared<QueryStatusInfo>(process->getInfo(get_thread_list, get_profile_events, get_settings));\n+\n+    return nullptr;\n+}\n \n ProcessListForUser::ProcessListForUser(ProcessList * global_process_list)\n     : ProcessListForUser(nullptr, global_process_list)\n@@ -762,7 +783,7 @@ ProcessList::UserInfo ProcessList::getUserInfo(bool get_profile_events) const\n {\n     UserInfo per_user_infos;\n \n-    auto lock = safeLock();\n+    LockAndBlocker lock(mutex);\n \n     per_user_infos.reserve(user_to_queries.size());\n \ndiff --git a/src/Interpreters/ProcessList.h b/src/Interpreters/ProcessList.h\nindex accb73e12df9..b2583e74d9bf 100644\n--- a/src/Interpreters/ProcessList.h\n+++ b/src/Interpreters/ProcessList.h\n@@ -14,15 +14,16 @@\n #include <Parsers/IAST.h>\n #include <Common/CurrentMetrics.h>\n #include <Common/CurrentThread.h>\n+#include <Common/LockGuard.h>\n #include <Common/MemoryTracker.h>\n #include <Common/ProfileEvents.h>\n #include <Common/Stopwatch.h>\n #include <Common/Throttler.h>\n #include <Common/OvercommitTracker.h>\n+#include <base/defines.h>\n \n #include <condition_variable>\n #include <list>\n-#include <map>\n #include <memory>\n #include <mutex>\n #include <unordered_map>\n@@ -69,6 +70,8 @@ struct QueryStatusInfo\n     std::string current_database;\n };\n \n+using QueryStatusInfoPtr = std::shared_ptr<const QueryStatusInfo>;\n+\n /// Query and information about its execution.\n class QueryStatus : public WithContext\n {\n@@ -164,7 +167,6 @@ class QueryStatus : public WithContext\n     /// This field is unused in this class, but it\n     /// increments/decrements metric in constructor/destructor.\n     CurrentMetrics::Increment num_queries_increment;\n-\n public:\n     QueryStatus(\n         ContextPtr context_,\n@@ -325,30 +327,10 @@ class ProcessListEntry\n     QueryStatusPtr getQueryStatus() const { return *it; }\n };\n \n-\n-class ProcessListBase\n-{\n-    mutable std::mutex mutex;\n-\n-protected:\n-    using Lock = std::unique_lock<std::mutex>;\n-    struct LockAndBlocker\n-    {\n-        Lock lock;\n-        OvercommitTrackerBlockerInThread blocker;\n-    };\n-\n-    // It is forbidden to do allocations/deallocations with acquired mutex and\n-    // enabled OvercommitTracker. This leads to deadlock in the case of OOM.\n-    LockAndBlocker safeLock() const noexcept { return { std::unique_lock{mutex}, {} }; }\n-    Lock unsafeLock() const noexcept { return std::unique_lock{mutex}; }\n-};\n-\n-\n /** List of currently executing queries.\n   * Also implements limit on their number.\n   */\n-class ProcessList : public ProcessListBase\n+class ProcessList\n {\n public:\n     using Element = QueryStatusPtr;\n@@ -367,6 +349,10 @@ class ProcessList : public ProcessListBase\n \n     using QueryKindAmounts = std::unordered_map<IAST::QueryKind, QueryAmount>;\n \n+    using Mutex = std::mutex;\n+    using Lock = std::unique_lock<Mutex>;\n+    using LockAndBlocker = LockAndOverCommitTrackerBlocker<LockGuard, Mutex>;\n+\n protected:\n     friend class ProcessListEntry;\n     friend struct ::OvercommitTracker;\n@@ -374,6 +360,7 @@ class ProcessList : public ProcessListBase\n     friend struct ::GlobalOvercommitTracker;\n \n     mutable std::condition_variable have_space;        /// Number of currently running queries has become less than maximum.\n+    mutable Mutex mutex;\n \n     /// List of queries\n     Container processes;\n@@ -395,7 +382,10 @@ class ProcessList : public ProcessListBase\n     ThrottlerPtr total_network_throttler;\n \n     /// Call under lock. Finds process with specified current_user and current_query_id.\n-    QueryStatusPtr tryGetProcessListElement(const String & current_query_id, const String & current_user);\n+    QueryStatusPtr tryGetProcessListElement(const String & current_query_id, const String & current_user) TSA_REQUIRES(mutex);\n+\n+    /// Finds process with specified query_id.\n+    QueryStatusPtr getProcessListElement(const String & query_id) const;\n \n     /// limit for insert. 0 means no limit. Otherwise, when limit exceeded, an exception is thrown.\n     size_t max_insert_queries_amount = 0;\n@@ -437,42 +427,50 @@ class ProcessList : public ProcessListBase\n     /// Get current state of process list.\n     Info getInfo(bool get_thread_list = false, bool get_profile_events = false, bool get_settings = false) const;\n \n+    // Get current state of a particular process.\n+    QueryStatusInfoPtr getQueryInfo(const String & query_id, bool get_thread_list = false, bool get_profile_events = false, bool get_settings = false) const;\n+\n     /// Get current state of process list per user.\n     UserInfo getUserInfo(bool get_profile_events = false) const;\n \n+    Mutex & getMutex()\n+    {\n+        return mutex;\n+    }\n+\n     void setMaxSize(size_t max_size_)\n     {\n-        auto lock = unsafeLock();\n+        Lock lock(mutex);\n         max_size = max_size_;\n     }\n \n     size_t getMaxSize() const\n     {\n-        auto lock = unsafeLock();\n+        Lock lock(mutex);\n         return max_size;\n     }\n \n     void setMaxInsertQueriesAmount(size_t max_insert_queries_amount_)\n     {\n-        auto lock = unsafeLock();\n+        Lock lock(mutex);\n         max_insert_queries_amount = max_insert_queries_amount_;\n     }\n \n     size_t getMaxInsertQueriesAmount() const\n     {\n-        auto lock = unsafeLock();\n+        Lock lock(mutex);\n         return max_insert_queries_amount;\n     }\n \n     void setMaxSelectQueriesAmount(size_t max_select_queries_amount_)\n     {\n-        auto lock = unsafeLock();\n+        Lock lock(mutex);\n         max_select_queries_amount = max_select_queries_amount_;\n     }\n \n     size_t getMaxSelectQueriesAmount() const\n     {\n-        auto lock = unsafeLock();\n+        Lock lock(mutex);\n         return max_select_queries_amount;\n     }\n \ndiff --git a/src/Interpreters/QueryMetricLog.cpp b/src/Interpreters/QueryMetricLog.cpp\nnew file mode 100644\nindex 000000000000..fea2024d3e4f\n--- /dev/null\n+++ b/src/Interpreters/QueryMetricLog.cpp\n@@ -0,0 +1,200 @@\n+#include <base/getFQDNOrHostName.h>\n+#include <Common/DateLUT.h>\n+#include <Common/DateLUTImpl.h>\n+#include <DataTypes/DataTypeDate.h>\n+#include <DataTypes/DataTypeDateTime.h>\n+#include <DataTypes/DataTypeDateTime64.h>\n+#include <DataTypes/DataTypeLowCardinality.h>\n+#include <DataTypes/DataTypeString.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <Interpreters/Context.h>\n+#include <Interpreters/QueryMetricLog.h>\n+#include <Interpreters/PeriodicLog.h>\n+#include <Interpreters/ProcessList.h>\n+#include <Parsers/ExpressionElementParsers.h>\n+#include <Parsers/parseQuery.h>\n+\n+#include <chrono>\n+#include <mutex>\n+\n+\n+namespace DB\n+{\n+\n+static auto logger = getLogger(\"QueryMetricLog\");\n+\n+ColumnsDescription QueryMetricLogElement::getColumnsDescription()\n+{\n+    ColumnsDescription result;\n+    ParserCodec codec_parser;\n+\n+    result.add({\"query_id\",\n+                std::make_shared<DataTypeString>(),\n+                parseQuery(codec_parser, \"(ZSTD(1))\", 0, DBMS_DEFAULT_MAX_PARSER_DEPTH, DBMS_DEFAULT_MAX_PARSER_BACKTRACKS),\n+                \"Query ID.\"});\n+    result.add({\"hostname\",\n+                std::make_shared<DataTypeLowCardinality>(std::make_shared<DataTypeString>()),\n+                parseQuery(codec_parser, \"(ZSTD(1))\", 0, DBMS_DEFAULT_MAX_PARSER_DEPTH, DBMS_DEFAULT_MAX_PARSER_BACKTRACKS),\n+                \"Hostname of the server executing the query.\"});\n+    result.add({\"event_date\",\n+                std::make_shared<DataTypeDate>(),\n+                parseQuery(codec_parser, \"(Delta(2), ZSTD(1))\", 0, DBMS_DEFAULT_MAX_PARSER_DEPTH, DBMS_DEFAULT_MAX_PARSER_BACKTRACKS),\n+                \"Event date.\"});\n+    result.add({\"event_time\",\n+                std::make_shared<DataTypeDateTime>(),\n+                parseQuery(codec_parser, \"(Delta(4), ZSTD(1))\", 0, DBMS_DEFAULT_MAX_PARSER_DEPTH, DBMS_DEFAULT_MAX_PARSER_BACKTRACKS),\n+                \"Event time.\"});\n+    result.add({\"event_time_microseconds\",\n+                std::make_shared<DataTypeDateTime64>(6),\n+                parseQuery(codec_parser, \"(Delta(4), ZSTD(1))\", 0, DBMS_DEFAULT_MAX_PARSER_DEPTH, DBMS_DEFAULT_MAX_PARSER_BACKTRACKS),\n+                \"Event time with microseconds resolution.\"});\n+    result.add({\"memory_usage\",\n+                std::make_shared<DataTypeUInt64>(),\n+                \"Amount of RAM the query uses. It might not include some types of dedicated memory.\"});\n+    result.add({\"peak_memory_usage\",\n+                std::make_shared<DataTypeUInt64>(),\n+                \"Maximum amount of RAM the query used.\"});\n+\n+    for (size_t i = 0, end = ProfileEvents::end(); i < end; ++i)\n+    {\n+        auto name = fmt::format(\"ProfileEvent_{}\", ProfileEvents::getName(ProfileEvents::Event(i)));\n+        const auto * comment = ProfileEvents::getDocumentation(ProfileEvents::Event(i));\n+        result.add({std::move(name), std::make_shared<DataTypeUInt64>(), comment});\n+    }\n+\n+    return result;\n+}\n+\n+void QueryMetricLogElement::appendToBlock(MutableColumns & columns) const\n+{\n+    size_t column_idx = 0;\n+\n+    columns[column_idx++]->insert(query_id);\n+    columns[column_idx++]->insert(getFQDNOrHostName());\n+    columns[column_idx++]->insert(DateLUT::instance().toDayNum(event_time).toUnderType());\n+    columns[column_idx++]->insert(event_time);\n+    columns[column_idx++]->insert(event_time_microseconds);\n+    columns[column_idx++]->insert(memory_usage);\n+    columns[column_idx++]->insert(peak_memory_usage);\n+\n+    for (size_t i = 0, end = ProfileEvents::end(); i < end; ++i)\n+        columns[column_idx++]->insert(profile_events[i]);\n+}\n+\n+void QueryMetricLog::shutdown()\n+{\n+    Base::shutdown();\n+}\n+\n+void QueryMetricLog::startQuery(const String & query_id, TimePoint query_start_time, UInt64 interval_milliseconds)\n+{\n+    QueryMetricLogStatus status;\n+    status.interval_milliseconds = interval_milliseconds;\n+    status.next_collect_time = query_start_time + std::chrono::milliseconds(interval_milliseconds);\n+\n+    auto context = getContext();\n+    const auto & process_list = context->getProcessList();\n+    status.task = context->getSchedulePool().createTask(\"QueryMetricLog\", [this, &process_list, query_id] {\n+        auto current_time = std::chrono::system_clock::now();\n+        const auto query_info = process_list.getQueryInfo(query_id, false, true, false);\n+        if (!query_info)\n+        {\n+            LOG_TRACE(logger, \"Query {} is not running anymore, so we couldn't get its QueryInfo\", query_id);\n+            return;\n+        }\n+\n+        auto elem = createLogMetricElement(query_id, *query_info, current_time);\n+        if (elem)\n+            add(std::move(elem.value()));\n+        else\n+            LOG_TRACE(logger, \"Query {} finished already while this collecting task was running\", query_id);\n+    });\n+\n+    status.task->scheduleAfter(interval_milliseconds);\n+\n+    std::lock_guard lock(queries_mutex);\n+    queries.emplace(query_id, std::move(status));\n+}\n+\n+void QueryMetricLog::finishQuery(const String & query_id, QueryStatusInfoPtr query_info)\n+{\n+    std::unique_lock lock(queries_mutex);\n+    auto it = queries.find(query_id);\n+\n+    /// finishQuery may be called from logExceptionBeforeStart when the query has not even started\n+    /// yet, so its corresponding startQuery is never called.\n+    if (it == queries.end())\n+        return;\n+\n+    if (query_info)\n+    {\n+        auto elem = createLogMetricElement(query_id, *query_info, std::chrono::system_clock::now(), false);\n+        if (elem)\n+            add(std::move(elem.value()));\n+    }\n+\n+    /// The task has an `exec_mutex` locked while being executed. This same mutex is locked when\n+    /// deactivating the task, which happens automatically on its destructor. Thus, we cannot\n+    /// deactivate/destroy the task while it's running. Now, the task locks `queries_mutex` to\n+    /// prevent concurrent edition of the queries. In short, the mutex order is: exec_mutex ->\n+    /// queries_mutex. Thus, to prevent a deadblock we need to make sure that we always lock them in\n+    /// that order.\n+    {\n+        /// Take ownership of the task so that we can destroy it in this scope after unlocking `queries_lock`.\n+        auto task = std::move(it->second.task);\n+\n+        /// Build an empty task for the old task to make sure it does not lock any mutex on its destruction.\n+        it->second.task = {};\n+\n+        /// Ensure `queries_mutex` is unlocked before calling task's destructor at the end of this\n+        /// scope which will lock `exec_mutex`.\n+        lock.unlock();\n+    }\n+\n+    lock.lock();\n+    queries.erase(query_id);\n+}\n+\n+std::optional<QueryMetricLogElement> QueryMetricLog::createLogMetricElement(const String & query_id, const QueryStatusInfo & query_info, TimePoint current_time, bool schedule_next)\n+{\n+    LOG_DEBUG(logger, \"Collecting query_metric_log for query {}. Schedule next: {}\", query_id, schedule_next);\n+    std::lock_guard lock(queries_mutex);\n+    auto query_status_it = queries.find(query_id);\n+\n+    /// The query might have finished while the scheduled task is running.\n+    if (query_status_it == queries.end())\n+        return {};\n+\n+    QueryMetricLogElement elem;\n+    elem.event_time = timeInSeconds(current_time);\n+    elem.event_time_microseconds = timeInMicroseconds(current_time);\n+    elem.query_id = query_status_it->first;\n+    elem.memory_usage = query_info.memory_usage > 0 ? query_info.memory_usage : 0;\n+    elem.peak_memory_usage = query_info.peak_memory_usage > 0 ? query_info.peak_memory_usage : 0;\n+\n+    auto & query_status = query_status_it->second;\n+    if (query_info.profile_counters)\n+    {\n+        for (ProfileEvents::Event i = ProfileEvents::Event(0), end = ProfileEvents::end(); i < end; ++i)\n+        {\n+            const auto & new_value = (*(query_info.profile_counters))[i];\n+            elem.profile_events[i] = new_value - query_status.last_profile_events[i];\n+            query_status.last_profile_events[i] = new_value;\n+        }\n+    }\n+    else\n+    {\n+        elem.profile_events = query_status.last_profile_events;\n+    }\n+\n+    if (query_status.task && schedule_next)\n+    {\n+        query_status.next_collect_time += std::chrono::milliseconds(query_status.interval_milliseconds);\n+        const auto wait_time = std::chrono::duration_cast<std::chrono::milliseconds>(query_status.next_collect_time - std::chrono::system_clock::now()).count();\n+        query_status.task->scheduleAfter(wait_time);\n+    }\n+\n+    return elem;\n+}\n+\n+}\ndiff --git a/src/Interpreters/QueryMetricLog.h b/src/Interpreters/QueryMetricLog.h\nnew file mode 100644\nindex 000000000000..d7642bf0ab14\n--- /dev/null\n+++ b/src/Interpreters/QueryMetricLog.h\n@@ -0,0 +1,65 @@\n+#pragma once\n+\n+#include <Common/ProfileEvents.h>\n+#include <Common/CurrentMetrics.h>\n+#include <Core/BackgroundSchedulePool.h>\n+#include <Core/NamesAndTypes.h>\n+#include <Core/NamesAndAliases.h>\n+#include <Interpreters/PeriodicLog.h>\n+#include <Interpreters/ProcessList.h>\n+#include <Storages/ColumnsDescription.h>\n+\n+#include <chrono>\n+#include <ctime>\n+\n+\n+namespace DB\n+{\n+\n+/** QueryMetricLogElement is a log of query metric values measured at regular time interval.\n+  */\n+\n+struct QueryMetricLogElement\n+{\n+    time_t event_time{};\n+    Decimal64 event_time_microseconds{};\n+    String query_id{};\n+    UInt64 memory_usage{};\n+    UInt64 peak_memory_usage{};\n+    std::vector<ProfileEvents::Count> profile_events = std::vector<ProfileEvents::Count>(ProfileEvents::end());\n+\n+    static std::string name() { return \"QueryMetricLog\"; }\n+    static ColumnsDescription getColumnsDescription();\n+    static NamesAndAliases getNamesAndAliases() { return {}; }\n+    void appendToBlock(MutableColumns & columns) const;\n+};\n+\n+struct QueryMetricLogStatus\n+{\n+    UInt64 interval_milliseconds;\n+    std::chrono::system_clock::time_point next_collect_time;\n+    std::vector<ProfileEvents::Count> last_profile_events = std::vector<ProfileEvents::Count>(ProfileEvents::end());\n+    BackgroundSchedulePool::TaskHolder task;\n+};\n+\n+class QueryMetricLog : public SystemLog<QueryMetricLogElement>\n+{\n+    using SystemLog<QueryMetricLogElement>::SystemLog;\n+    using TimePoint = std::chrono::system_clock::time_point;\n+    using Base = SystemLog<QueryMetricLogElement>;\n+\n+public:\n+    void shutdown() final;\n+\n+    // Both startQuery and finishQuery are called from the thread that executes the query\n+    void startQuery(const String & query_id, TimePoint query_start_time, UInt64 interval_milliseconds);\n+    void finishQuery(const String & query_id, QueryStatusInfoPtr query_info = nullptr);\n+\n+private:\n+    std::optional<QueryMetricLogElement> createLogMetricElement(const String & query_id, const QueryStatusInfo & query_info, TimePoint current_time, bool schedule_next = true);\n+\n+    std::recursive_mutex queries_mutex;\n+    std::unordered_map<String, QueryMetricLogStatus> queries;\n+};\n+\n+}\ndiff --git a/src/Interpreters/SystemLog.cpp b/src/Interpreters/SystemLog.cpp\nindex 7e21caa59c93..bbdeb4567af4 100644\n--- a/src/Interpreters/SystemLog.cpp\n+++ b/src/Interpreters/SystemLog.cpp\n@@ -25,6 +25,7 @@\n #include <Interpreters/PartLog.h>\n #include <Interpreters/ProcessorsProfileLog.h>\n #include <Interpreters/QueryLog.h>\n+#include <Interpreters/QueryMetricLog.h>\n #include <Interpreters/QueryThreadLog.h>\n #include <Interpreters/QueryViewsLog.h>\n #include <Interpreters/ObjectStorageQueueLog.h>\n@@ -321,14 +322,14 @@ SystemLogs::SystemLogs(ContextPtr global_context, const Poco::Util::AbstractConf\n     {\n         size_t collect_interval_milliseconds = config.getUInt64(\"metric_log.collect_interval_milliseconds\",\n                                                                 DEFAULT_METRIC_LOG_COLLECT_INTERVAL_MILLISECONDS);\n-        metric_log->startCollect(collect_interval_milliseconds);\n+        metric_log->startCollect(\"MetricLog\", collect_interval_milliseconds);\n     }\n \n     if (error_log)\n     {\n         size_t collect_interval_milliseconds = config.getUInt64(\"error_log.collect_interval_milliseconds\",\n                                                                 DEFAULT_ERROR_LOG_COLLECT_INTERVAL_MILLISECONDS);\n-        error_log->startCollect(collect_interval_milliseconds);\n+        error_log->startCollect(\"ErrorLog\", collect_interval_milliseconds);\n     }\n \n     if (crash_log)\ndiff --git a/src/Interpreters/SystemLog.h b/src/Interpreters/SystemLog.h\nindex c03f93700680..61e6988e43dc 100644\n--- a/src/Interpreters/SystemLog.h\n+++ b/src/Interpreters/SystemLog.h\n@@ -5,7 +5,6 @@\n #include <Parsers/IAST.h>\n \n #include <boost/noncopyable.hpp>\n-#include <vector>\n \n #define LIST_OF_ALL_SYSTEM_LOGS(M) \\\n     M(QueryLog,              query_log,            \"Contains information about executed queries, for example, start time, duration of processing, error messages.\") \\\n@@ -30,6 +29,7 @@\n     M(AsynchronousInsertLog, asynchronous_insert_log, \"Contains a history for all asynchronous inserts executed on current server.\") \\\n     M(BackupLog,             backup_log,           \"Contains logging entries with the information about BACKUP and RESTORE operations.\") \\\n     M(BlobStorageLog,        blob_storage_log,     \"Contains logging entries with information about various blob storage operations such as uploads and deletes.\") \\\n+    M(QueryMetricLog,        query_metric_log,     \"Contains history of memory and metric values from table system.events for individual queries, periodically flushed to disk.\") \\\n \n \n namespace DB\n@@ -68,7 +68,6 @@ LIST_OF_ALL_SYSTEM_LOGS(FORWARD_DECLARATION)\n #undef FORWARD_DECLARATION\n /// NOLINTEND(bugprone-macro-parentheses)\n \n-\n /// System logs should be destroyed in destructor of the last Context and before tables,\n ///  because SystemLog destruction makes insert query while flushing data into underlying tables\n class SystemLogs\n@@ -101,7 +100,7 @@ struct SystemLogSettings\n };\n \n template <typename LogElement>\n-class SystemLog : public SystemLogBase<LogElement>, private boost::noncopyable, WithContext\n+class SystemLog : public SystemLogBase<LogElement>, private boost::noncopyable, public WithContext\n {\n public:\n     using Self = SystemLog;\ndiff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp\nindex 2ce921967ba5..a8fcfff65adc 100644\n--- a/src/Interpreters/executeQuery.cpp\n+++ b/src/Interpreters/executeQuery.cpp\n@@ -61,6 +61,7 @@\n #include <Interpreters/ProcessList.h>\n #include <Interpreters/ProcessorsProfileLog.h>\n #include <Interpreters/QueryLog.h>\n+#include <Interpreters/QueryMetricLog.h>\n #include <Interpreters/ReplaceQueryParameterVisitor.h>\n #include <Interpreters/SelectIntersectExceptQueryVisitor.h>\n #include <Interpreters/SelectQueryOptions.h>\n@@ -143,6 +144,7 @@ namespace Setting\n     extern const SettingsBool query_cache_squash_partial_results;\n     extern const SettingsQueryCacheSystemTableHandling query_cache_system_table_handling;\n     extern const SettingsSeconds query_cache_ttl;\n+    extern const SettingsInt64 query_metric_log_interval;\n     extern const SettingsOverflowMode read_overflow_mode;\n     extern const SettingsOverflowMode read_overflow_mode_leaf;\n     extern const SettingsOverflowMode result_overflow_mode;\n@@ -367,6 +369,15 @@ addStatusInfoToQueryLogElement(QueryLogElement & element, const QueryStatusInfo\n     addPrivilegesInfoToQueryLogElement(element, context_ptr);\n }\n \n+static UInt64 getQueryMetricLogInterval(ContextPtr context)\n+{\n+    const auto & settings = context->getSettingsRef();\n+    auto interval_milliseconds = settings[Setting::query_metric_log_interval];\n+    if (interval_milliseconds < 0)\n+        interval_milliseconds = context->getConfigRef().getUInt64(\"query_metric_log.collect_interval_milliseconds\", 1000);\n+\n+    return interval_milliseconds;\n+}\n \n QueryLogElement logQueryStart(\n     const std::chrono::time_point<std::chrono::system_clock> & query_start_time,\n@@ -439,9 +450,40 @@ QueryLogElement logQueryStart(\n         }\n     }\n \n+    if (auto query_metric_log = context->getQueryMetricLog(); query_metric_log && !internal)\n+    {\n+        auto interval_milliseconds = getQueryMetricLogInterval(context);\n+        if (interval_milliseconds > 0)\n+            query_metric_log->startQuery(elem.client_info.current_query_id, query_start_time, interval_milliseconds);\n+    }\n+\n     return elem;\n }\n \n+void logQueryMetricLogFinish(ContextPtr context, bool internal, String query_id, QueryStatusInfoPtr info)\n+{\n+    if (auto query_metric_log = context->getQueryMetricLog(); query_metric_log && !internal)\n+    {\n+        auto interval_milliseconds = getQueryMetricLogInterval(context);\n+        if (info && interval_milliseconds > 0)\n+        {\n+            /// Only collect data on query finish if the elapsed time exceeds the interval to collect.\n+            /// If we don't do this, it's counter-intuitive to have a single entry for every quick query\n+            /// where the data is basically a subset of the query_log.\n+            /// On the other hand, it's very convenient to have a new entry whenever the query finishes\n+            /// so that we can get nice time-series querying only query_metric_log without the need\n+            /// to query the final state in query_log.\n+            auto collect_on_finish = info->elapsed_microseconds > interval_milliseconds * 1000;\n+            auto query_info = collect_on_finish ? info : nullptr;\n+            query_metric_log->finishQuery(query_id, query_info);\n+        }\n+        else\n+        {\n+            query_metric_log->finishQuery(query_id, nullptr);\n+        }\n+    }\n+}\n+\n void logQueryFinish(\n     QueryLogElement & elem,\n     const ContextMutablePtr & context,\n@@ -554,6 +596,8 @@ void logQueryFinish(\n                 }\n             }\n         }\n+\n+        logQueryMetricLogFinish(context, internal, elem.client_info.current_query_id, std::make_shared<QueryStatusInfo>(info));\n     }\n \n     if (query_span)\n@@ -613,10 +657,11 @@ void logQueryException(\n     elem.event_time = timeInSeconds(time_now);\n     elem.event_time_microseconds = timeInMicroseconds(time_now);\n \n+    QueryStatusInfoPtr info;\n     if (process_list_elem)\n     {\n-        QueryStatusInfo info = process_list_elem->getInfo(true, settings[Setting::log_profile_events], false);\n-        addStatusInfoToQueryLogElement(elem, info, query_ast, context);\n+        info = std::make_shared<QueryStatusInfo>(process_list_elem->getInfo(true, settings[Setting::log_profile_events], false));\n+        addStatusInfoToQueryLogElement(elem, *info, query_ast, context);\n     }\n     else\n     {\n@@ -651,6 +696,8 @@ void logQueryException(\n         query_span->addAttribute(\"clickhouse.exception_code\", elem.exception_code);\n         query_span->finish();\n     }\n+\n+    logQueryMetricLogFinish(context, internal, elem.client_info.current_query_id, info);\n }\n \n void logExceptionBeforeStart(\n@@ -748,6 +795,8 @@ void logExceptionBeforeStart(\n             ProfileEvents::increment(ProfileEvents::FailedInsertQuery);\n         }\n     }\n+\n+    logQueryMetricLogFinish(context, false, elem.client_info.current_query_id, nullptr);\n }\n \n void validateAnalyzerSettings(ASTPtr ast, bool context_value)\ndiff --git a/src/Processors/Transforms/WindowTransform.cpp b/src/Processors/Transforms/WindowTransform.cpp\nindex 37948cd55e7f..597a6861eeb7 100644\n--- a/src/Processors/Transforms/WindowTransform.cpp\n+++ b/src/Processors/Transforms/WindowTransform.cpp\n@@ -2469,7 +2469,7 @@ struct WindowFunctionNthValue final : public StatelessWindowFunction\n         if (offset <= 0)\n         {\n             throw Exception(ErrorCodes::BAD_ARGUMENTS,\n-                \"The offset for function {} must be in (0, {}], {} given\",\n+                \"The offset for function {} must be in (1, {}], {} given\",\n                 getName(), INT64_MAX, offset);\n         }\n \ndiff --git a/utils/check-style/check-style b/utils/check-style/check-style\nindex e15d4ef92cc3..c3b42be1519e 100755\n--- a/utils/check-style/check-style\n+++ b/utils/check-style/check-style\n@@ -85,6 +85,8 @@ EXTERN_TYPES_EXCLUDES=(\n     CurrentMetrics::add\n     CurrentMetrics::sub\n     CurrentMetrics::get\n+    CurrentMetrics::getDocumentation\n+    CurrentMetrics::getName\n     CurrentMetrics::set\n     CurrentMetrics::end\n     CurrentMetrics::Increment\n@@ -174,7 +176,7 @@ find $ROOT_PATH/tests/queries -iname '*fail*' |\n # NOTE: it is not that accurate, but at least something.\n tests_with_query_log=( $(\n     find $ROOT_PATH/tests/queries -iname '*.sql' -or -iname '*.sh' -or -iname '*.py' -or -iname '*.j2' |\n-        xargs grep --with-filename -e system.query_log -e system.query_thread_log | cut -d: -f1 | sort -u\n+        xargs grep --with-filename -e 'system.query_log\\b' -e 'system.query_thread_log\\b' | cut -d: -f1 | sort -u\n ) )\n for test_case in \"${tests_with_query_log[@]}\"; do\n     grep -qE current_database.*currentDatabase \"$test_case\" || {\n",
  "test_patch": "diff --git a/tests/docker_scripts/stateless_runner.sh b/tests/docker_scripts/stateless_runner.sh\nindex 1677092c6c6a..e9b32c905e07 100755\n--- a/tests/docker_scripts/stateless_runner.sh\n+++ b/tests/docker_scripts/stateless_runner.sh\n@@ -351,7 +351,7 @@ logs_saver_client_options=\"--max_block_size 8192 --max_memory_usage 10G --max_th\n \n # Try to get logs while server is running\n failed_to_save_logs=0\n-for table in query_log zookeeper_log trace_log transactions_info_log metric_log blob_storage_log error_log\n+for table in query_log zookeeper_log trace_log transactions_info_log metric_log blob_storage_log error_log query_metric_log\n do\n     if ! clickhouse-client ${logs_saver_client_options} -q \"select * from system.$table into outfile '/test_output/$table.tsv.zst' format TSVWithNamesAndTypes\"; then\n         failed_to_save_logs=1\n@@ -418,7 +418,7 @@ if [ $failed_to_save_logs -ne 0 ]; then\n     #   directly\n     # - even though ci auto-compress some files (but not *.tsv) it does this only\n     #   for files >64MB, we want this files to be compressed explicitly\n-    for table in query_log zookeeper_log trace_log transactions_info_log metric_log blob_storage_log error_log\n+    for table in query_log zookeeper_log trace_log transactions_info_log metric_log blob_storage_log error_log query_metric_log\n     do\n         clickhouse-local ${logs_saver_client_options} \"$data_path_config\" --only-system-tables --stacktrace -q \"select * from system.$table format TSVWithNamesAndTypes\" | zstd --threads=0 > /test_output/$table.tsv.zst ||:\n \ndiff --git a/tests/integration/test_MemoryTracking/configs/no_system_log.xml b/tests/integration/test_MemoryTracking/configs/no_system_log.xml\nindex 7d80c7fbf78b..739734bd3df6 100644\n--- a/tests/integration/test_MemoryTracking/configs/no_system_log.xml\n+++ b/tests/integration/test_MemoryTracking/configs/no_system_log.xml\n@@ -3,6 +3,7 @@\n \n     <query_thread_log remove=\"remove\"/>\n     <query_log remove=\"remove\" />\n+    <query_metric_log remove=\"remove\" />\n     <query_views_log remove=\"remove\" />\n     <metric_log remove=\"remove\"/>\n     <error_log remove=\"remove\"/>\ndiff --git a/tests/integration/test_backup_restore_new/test.py b/tests/integration/test_backup_restore_new/test.py\nindex eca425b5dcc3..a7a22be1cf8d 100644\n--- a/tests/integration/test_backup_restore_new/test.py\n+++ b/tests/integration/test_backup_restore_new/test.py\n@@ -1502,6 +1502,7 @@ def test_backup_all(exclude_system_log_tables):\n         # See the list of log tables in src/Interpreters/SystemLog.cpp\n         log_tables = [\n             \"query_log\",\n+            \"query_metric_log\",\n             \"query_thread_log\",\n             \"part_log\",\n             \"trace_log\",\ndiff --git a/tests/integration/test_config_xml_full/configs/config.d/query_metric_log.xml b/tests/integration/test_config_xml_full/configs/config.d/query_metric_log.xml\nnew file mode 100644\nindex 000000000000..0d3ba22fdddb\n--- /dev/null\n+++ b/tests/integration/test_config_xml_full/configs/config.d/query_metric_log.xml\n@@ -0,0 +1,8 @@\n+<clickhouse>\n+    <query_metric_log>\n+        <database>system</database>\n+        <table>query_metric_log</table>\n+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n+    </query_metric_log>\n+</clickhouse>\ndiff --git a/tests/integration/test_config_xml_full/configs/config.xml b/tests/integration/test_config_xml_full/configs/config.xml\nindex 61aa0a5c7245..80b6a702032e 100644\n--- a/tests/integration/test_config_xml_full/configs/config.xml\n+++ b/tests/integration/test_config_xml_full/configs/config.xml\n@@ -748,22 +748,6 @@\n     </text_log>\n     -->\n \n-    <!-- Metric log contains rows with current values of ProfileEvents, CurrentMetrics collected with \"collect_interval_milliseconds\" interval. -->\n-    <metric_log>\n-        <database>system</database>\n-        <table>metric_log</table>\n-        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n-        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n-    </metric_log>\n-\n-    <!-- Error log contains rows with current values of errors collected with \"collect_interval_milliseconds\" interval. -->\n-    <error_log>\n-        <database>system</database>\n-        <table>error_log</table>\n-        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n-        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n-    </error_log>\n-\n     <!--\n         Asynchronous metric log contains values of metrics from\n         system.asynchronous_metrics.\ndiff --git a/tests/integration/test_config_xml_full/test.py b/tests/integration/test_config_xml_full/test.py\nindex 8513792f3b3f..036a6ca02ada 100644\n--- a/tests/integration/test_config_xml_full/test.py\n+++ b/tests/integration/test_config_xml_full/test.py\n@@ -19,6 +19,7 @@ def test_xml_full_conf():\n         \"configs/config.d/part_log.xml\",\n         \"configs/config.d/path.xml\",\n         \"configs/config.d/query_masking_rules.xml\",\n+        \"configs/config.d/query_metric_log.xml\",\n         \"configs/config.d/tcp_with_proxy.xml\",\n         \"configs/config.d/text_log.xml\",\n         \"configs/config.d/zookeeper.xml\",\ndiff --git a/tests/integration/test_config_xml_main/configs/config.d/error_log.yaml b/tests/integration/test_config_xml_main/configs/config.d/error_log.yaml\nindex f115989d203e..0ba80776dda2 100644\n--- a/tests/integration/test_config_xml_main/configs/config.d/error_log.yaml\n+++ b/tests/integration/test_config_xml_main/configs/config.d/error_log.yaml\n@@ -1,6 +1,6 @@\n error_log:\n   database: system\n-  table: error_log \n+  table: error_log\n   flush_interval_milliseconds: 7500\n   collect_interval_milliseconds: 1000\n \ndiff --git a/tests/integration/test_config_xml_main/configs/config.d/query_metric_log.yaml b/tests/integration/test_config_xml_main/configs/config.d/query_metric_log.yaml\nnew file mode 100644\nindex 000000000000..0f6fae95dc32\n--- /dev/null\n+++ b/tests/integration/test_config_xml_main/configs/config.d/query_metric_log.yaml\n@@ -0,0 +1,6 @@\n+query_metric_log:\n+  database: system\n+  table: query_metric_log\n+  flush_interval_milliseconds: 7500\n+  collect_interval_milliseconds: 1000\n+\ndiff --git a/tests/integration/test_config_xml_main/configs/config.xml b/tests/integration/test_config_xml_main/configs/config.xml\nindex 54fc590fc245..7f951e449028 100644\n--- a/tests/integration/test_config_xml_main/configs/config.xml\n+++ b/tests/integration/test_config_xml_main/configs/config.xml\n@@ -26,7 +26,7 @@\n         <verbose_logs>false</verbose_logs>\n     </grpc>\n     <openSSL>\n-        <server> \n+        <server>\n             <certificateFile>/etc/clickhouse-server/server.crt</certificateFile>\n             <privateKeyFile>/etc/clickhouse-server/server.key</privateKeyFile>\n             <dhParamsFile>/etc/clickhouse-server/dhparam.pem</dhParamsFile>\n@@ -101,9 +101,9 @@\n     <query_log>\n         <database>system</database>\n         <table>query_log</table>\n-        \n+\n         <partition_by>toYYYYMM(event_date)</partition_by>\n-        \n+\n         <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n     </query_log>\n \n@@ -122,20 +122,6 @@\n         <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n     </query_thread_log>\n \n-    <metric_log>\n-        <database>system</database>\n-        <table>metric_log</table>\n-        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n-        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n-    </metric_log>\n-\n-    <error_log>\n-        <database>system</database>\n-        <table>error_log</table>\n-        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n-        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n-    </error_log>\n-\n     <asynchronous_metric_log>\n         <database>system</database>\n         <table>asynchronous_metric_log</table>\ndiff --git a/tests/integration/test_config_xml_main/test.py b/tests/integration/test_config_xml_main/test.py\nindex 4d74edfa01e3..c3ccd0eb556b 100644\n--- a/tests/integration/test_config_xml_main/test.py\n+++ b/tests/integration/test_config_xml_main/test.py\n@@ -19,6 +19,7 @@ def test_xml_main_conf():\n         \"configs/config.d/part_log.yaml\",\n         \"configs/config.d/path.yaml\",\n         \"configs/config.d/query_masking_rules.yaml\",\n+        \"configs/config.d/query_metric_log.yaml\",\n         \"configs/config.d/tcp_with_proxy.yaml\",\n         \"configs/config.d/test_cluster_with_incorrect_pw.yaml\",\n         \"configs/config.d/text_log.yaml\",\ndiff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/query_metric_log.xml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/query_metric_log.xml\nnew file mode 100644\nindex 000000000000..0d3ba22fdddb\n--- /dev/null\n+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/query_metric_log.xml\n@@ -0,0 +1,8 @@\n+<clickhouse>\n+    <query_metric_log>\n+        <database>system</database>\n+        <table>query_metric_log</table>\n+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n+    </query_metric_log>\n+</clickhouse>\ndiff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.xml b/tests/integration/test_config_xml_yaml_mix/configs/config.xml\nindex 13e51581ba4d..f1e5137ac001 100644\n--- a/tests/integration/test_config_xml_yaml_mix/configs/config.xml\n+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.xml\n@@ -26,7 +26,7 @@\n         <verbose_logs>false</verbose_logs>\n     </grpc>\n     <openSSL>\n-        <server> \n+        <server>\n             <certificateFile>/etc/clickhouse-server/server.crt</certificateFile>\n             <privateKeyFile>/etc/clickhouse-server/server.key</privateKeyFile>\n             <dhParamsFile>/etc/clickhouse-server/dhparam.pem</dhParamsFile>\n@@ -101,9 +101,9 @@\n     <query_log>\n         <database>system</database>\n         <table>query_log</table>\n-        \n+\n         <partition_by>toYYYYMM(event_date)</partition_by>\n-        \n+\n         <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n     </query_log>\n \n@@ -122,20 +122,6 @@\n         <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n     </query_thread_log>\n \n-    <metric_log>\n-        <database>system</database>\n-        <table>metric_log</table>\n-        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n-        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n-    </metric_log>\n-\n-    <error_log>\n-        <database>system</database>\n-        <table>error_log</table>\n-        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n-        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n-    </error_log>\n-\n     <asynchronous_metric_log>\n         <database>system</database>\n         <table>asynchronous_metric_log</table>\ndiff --git a/tests/integration/test_config_xml_yaml_mix/test.py b/tests/integration/test_config_xml_yaml_mix/test.py\nindex df1eaa9ded7c..ecfabc01f5c7 100644\n--- a/tests/integration/test_config_xml_yaml_mix/test.py\n+++ b/tests/integration/test_config_xml_yaml_mix/test.py\n@@ -21,6 +21,7 @@ def test_extra_yaml_mix():\n         \"configs/config.d/part_log.xml\",\n         \"configs/config.d/path.yaml\",\n         \"configs/config.d/query_masking_rules.xml\",\n+        \"configs/config.d/query_metric_log.xml\",\n         \"configs/config.d/tcp_with_proxy.yaml\",\n         \"configs/config.d/test_cluster_with_incorrect_pw.xml\",\n         \"configs/config.d/text_log.yaml\",\ndiff --git a/tests/integration/test_config_yaml_full/configs/config.d/query_metric_log.yaml b/tests/integration/test_config_yaml_full/configs/config.d/query_metric_log.yaml\nnew file mode 100644\nindex 000000000000..0f6fae95dc32\n--- /dev/null\n+++ b/tests/integration/test_config_yaml_full/configs/config.d/query_metric_log.yaml\n@@ -0,0 +1,6 @@\n+query_metric_log:\n+  database: system\n+  table: query_metric_log\n+  flush_interval_milliseconds: 7500\n+  collect_interval_milliseconds: 1000\n+\ndiff --git a/tests/integration/test_config_yaml_full/configs/config.yaml b/tests/integration/test_config_yaml_full/configs/config.yaml\nindex 3bc8ccdf6019..894f1a374676 100644\n--- a/tests/integration/test_config_yaml_full/configs/config.yaml\n+++ b/tests/integration/test_config_yaml_full/configs/config.yaml\n@@ -85,16 +85,6 @@ query_thread_log:\n   table: query_thread_log\n   partition_by: toYYYYMM(event_date)\n   flush_interval_milliseconds: 7500\n-metric_log:\n-  database: system\n-  table: metric_log\n-  flush_interval_milliseconds: 7500\n-  collect_interval_milliseconds: 1000\n-error_log:\n-  database: system\n-  table: error_log\n-  flush_interval_milliseconds: 7500\n-  collect_interval_milliseconds: 1000\n asynchronous_metric_log:\n   database: system\n   table: asynchronous_metric_log\ndiff --git a/tests/integration/test_config_yaml_full/test.py b/tests/integration/test_config_yaml_full/test.py\nindex 986199fd2284..2bc7be3f2eab 100644\n--- a/tests/integration/test_config_yaml_full/test.py\n+++ b/tests/integration/test_config_yaml_full/test.py\n@@ -20,6 +20,7 @@ def test_yaml_full_conf():\n         \"configs/config.d/part_log.yaml\",\n         \"configs/config.d/path.yaml\",\n         \"configs/config.d/query_masking_rules.yaml\",\n+        \"configs/config.d/query_metric_log.yaml\",\n         \"configs/config.d/tcp_with_proxy.yaml\",\n         \"configs/config.d/test_cluster_with_incorrect_pw.yaml\",\n         \"configs/config.d/text_log.yaml\",\ndiff --git a/tests/integration/test_config_yaml_main/configs/config.d/query_metric_log.xml b/tests/integration/test_config_yaml_main/configs/config.d/query_metric_log.xml\nnew file mode 100644\nindex 000000000000..0d3ba22fdddb\n--- /dev/null\n+++ b/tests/integration/test_config_yaml_main/configs/config.d/query_metric_log.xml\n@@ -0,0 +1,8 @@\n+<clickhouse>\n+    <query_metric_log>\n+        <database>system</database>\n+        <table>query_metric_log</table>\n+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n+    </query_metric_log>\n+</clickhouse>\ndiff --git a/tests/integration/test_config_yaml_main/configs/config.yaml b/tests/integration/test_config_yaml_main/configs/config.yaml\nindex 6e62b13a0eeb..e8483f95bb0e 100644\n--- a/tests/integration/test_config_yaml_main/configs/config.yaml\n+++ b/tests/integration/test_config_yaml_main/configs/config.yaml\n@@ -85,16 +85,6 @@ query_thread_log:\n   table: query_thread_log\n   partition_by: toYYYYMM(event_date)\n   flush_interval_milliseconds: 7500\n-metric_log:\n-  database: system\n-  table: metric_log\n-  flush_interval_milliseconds: 7500\n-  collect_interval_milliseconds: 1000\n-error_log:\n-  database: system\n-  table: error_log\n-  flush_interval_milliseconds: 7500\n-  collect_interval_milliseconds: 1000\n asynchronous_metric_log:\n   database: system\n   table: asynchronous_metric_log\ndiff --git a/tests/integration/test_config_yaml_main/test.py b/tests/integration/test_config_yaml_main/test.py\nindex fb1d62b8cc78..1ee6c3298620 100644\n--- a/tests/integration/test_config_yaml_main/test.py\n+++ b/tests/integration/test_config_yaml_main/test.py\n@@ -20,6 +20,7 @@ def test_yaml_main_conf():\n         \"configs/config.d/part_log.xml\",\n         \"configs/config.d/path.xml\",\n         \"configs/config.d/query_masking_rules.xml\",\n+        \"configs/config.d/query_metric_log.xml\",\n         \"configs/config.d/tcp_with_proxy.xml\",\n         \"configs/config.d/test_cluster_with_incorrect_pw.xml\",\n         \"configs/config.d/text_log.xml\",\ndiff --git a/tests/integration/test_input_format_parallel_parsing_memory_tracking/configs/conf.xml b/tests/integration/test_input_format_parallel_parsing_memory_tracking/configs/conf.xml\nindex 4dceb11e2cdf..76ecddfe5d91 100644\n--- a/tests/integration/test_input_format_parallel_parsing_memory_tracking/configs/conf.xml\n+++ b/tests/integration/test_input_format_parallel_parsing_memory_tracking/configs/conf.xml\n@@ -4,6 +4,7 @@\n \n     <query_thread_log remove=\"remove\"/>\n     <query_log remove=\"remove\" />\n+    <query_metric_log remove=\"remove\" />\n     <query_views_log remove=\"remove\" />\n     <metric_log remove=\"remove\"/>\n     <error_log remove=\"remove\"/>\ndiff --git a/tests/integration/test_memory_limit/configs/async_metrics_no.xml b/tests/integration/test_memory_limit/configs/async_metrics_no.xml\nindex 96cae3bf387b..15ebbe9e0bd1 100644\n--- a/tests/integration/test_memory_limit/configs/async_metrics_no.xml\n+++ b/tests/integration/test_memory_limit/configs/async_metrics_no.xml\n@@ -5,6 +5,7 @@\n \n     <query_thread_log remove=\"remove\"/>\n     <query_log remove=\"remove\" />\n+    <query_metric_log remove=\"remove\" />\n     <query_views_log remove=\"remove\" />\n     <metric_log remove=\"remove\"/>\n     <error_log remove=\"remove\"/>\ndiff --git a/tests/integration/test_system_flush_logs/test.py b/tests/integration/test_system_flush_logs/test.py\nindex 8519a1e94e90..b99081283ff7 100644\n--- a/tests/integration/test_system_flush_logs/test.py\n+++ b/tests/integration/test_system_flush_logs/test.py\n@@ -27,6 +27,7 @@ def test_system_logs_exists():\n     system_logs = [\n         (\"system.text_log\", 1),\n         (\"system.query_log\", 1),\n+        (\"system.query_metric_log\", 1),\n         (\"system.query_thread_log\", 1),\n         (\"system.part_log\", 1),\n         (\"system.trace_log\", 1),\ndiff --git a/tests/integration/test_system_logs_recreate/test.py b/tests/integration/test_system_logs_recreate/test.py\nindex cb68028b42e9..cdc29ca108d4 100644\n--- a/tests/integration/test_system_logs_recreate/test.py\n+++ b/tests/integration/test_system_logs_recreate/test.py\n@@ -27,6 +27,7 @@ def test_system_logs_recreate():\n     system_logs = [\n         # enabled by default\n         \"query_log\",\n+        \"query_metric_log\",\n         \"query_thread_log\",\n         \"part_log\",\n         \"trace_log\",\ndiff --git a/tests/queries/0_stateless/03203_system_query_metric_log.reference b/tests/queries/0_stateless/03203_system_query_metric_log.reference\nnew file mode 100644\nindex 000000000000..d761659fce24\n--- /dev/null\n+++ b/tests/queries/0_stateless/03203_system_query_metric_log.reference\n@@ -0,0 +1,12 @@\n+number_of_metrics_1000_ok\ttimestamp_diff_in_metrics_1000_ok\n+initial_data_1000_ok\n+data_1000_ok\n+number_of_metrics_1234_ok\ttimestamp_diff_in_metrics_1234_ok\n+initial_data_1234_ok\n+data_1234_ok\n+number_of_metrics_123_ok\ttimestamp_diff_in_metrics_123_ok\n+initial_data_123_ok\n+data_123_ok\n+0\n+0\n+3\ndiff --git a/tests/queries/0_stateless/03203_system_query_metric_log.sh b/tests/queries/0_stateless/03203_system_query_metric_log.sh\nnew file mode 100755\nindex 000000000000..1c189c6ce419\n--- /dev/null\n+++ b/tests/queries/0_stateless/03203_system_query_metric_log.sh\n@@ -0,0 +1,81 @@\n+#!/bin/bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+readonly query_prefix=$CLICKHOUSE_DATABASE\n+\n+$CLICKHOUSE_CLIENT --query-id=\"${query_prefix}_1000\" -q \"SELECT sleep(2.5) FORMAT Null\" &\n+$CLICKHOUSE_CLIENT --query-id=\"${query_prefix}_1234\" -q \"SELECT sleep(2.5) SETTINGS query_metric_log_interval=1234 FORMAT Null\" &\n+$CLICKHOUSE_CLIENT --query-id=\"${query_prefix}_123\" -q \"SELECT sleep(2.5) SETTINGS query_metric_log_interval=123 FORMAT Null\" &\n+$CLICKHOUSE_CLIENT --query-id=\"${query_prefix}_0\" -q \"SELECT sleep(2.5) SETTINGS query_metric_log_interval=0 FORMAT Null\" &\n+$CLICKHOUSE_CLIENT --query-id=\"${query_prefix}_fast\" -q \"SELECT sleep(0.1) FORMAT Null\" &\n+\n+wait\n+\n+$CLICKHOUSE_CLIENT -q \"SYSTEM FLUSH LOGS\"\n+\n+function check_log()\n+{\n+    interval=$1\n+\n+    # We calculate the diff of each row with its previous row to check whether the intervals at\n+    # which data is collected is right. The first row is always skipped because the diff with the\n+    # preceding one (itself) is 0. The last row is also skipped, because it doesn't contain a full\n+    # interval.\n+    $CLICKHOUSE_CLIENT --max_threads=1 -m -q \"\"\"\n+    WITH diff AS (\n+        SELECT\n+            row_number() OVER () AS row,\n+            count() OVER () as total_rows,\n+            event_time_microseconds,\n+            first_value(event_time_microseconds) OVER (ORDER BY event_time_microseconds ROWS BETWEEN 1 PRECEDING AND 0 FOLLOWING) as prev,\n+            dateDiff('ms', prev, event_time_microseconds) AS diff\n+        FROM system.query_metric_log\n+        WHERE event_date >= yesterday() AND query_id = '${query_prefix}_${interval}'\n+        ORDER BY event_time_microseconds\n+        OFFSET 1\n+    )\n+    SELECT if(count() BETWEEN ((ceil(2500 / $interval) - 2) * 0.8) AND ((ceil(2500 / $interval) - 2) * 1.2), 'number_of_metrics_${interval}_ok', 'number_of_metrics_${interval}_error'),\n+           if(avg(diff) BETWEEN $interval * 0.8 AND $interval * 1.2, 'timestamp_diff_in_metrics_${interval}_ok', 'timestamp_diff_in_metrics_${interval}_error')\n+    FROM diff WHERE row < total_rows\n+    \"\"\"\n+\n+    # Check that the first event contains information from the beginning of the query.\n+    # Notice the rest of the events won't contain these because the diff will be 0.\n+    $CLICKHOUSE_CLIENT -m -q \"\"\"\n+        SELECT if(ProfileEvent_Query = 1 AND ProfileEvent_SelectQuery = 1 AND ProfileEvent_InitialQuery = 1, 'initial_data_${interval}_ok', 'initial_data_${interval}_error')\n+        FROM system.query_metric_log\n+        WHERE event_date >= yesterday() AND query_id = '${query_prefix}_${interval}'\n+        ORDER BY event_time_microseconds\n+        LIMIT 1\n+    \"\"\"\n+\n+    # Also check that it contains some data that we know it's going to be there.\n+    # Notice the Sleep events can be in any of the rows, not only in the first one.\n+    $CLICKHOUSE_CLIENT -m -q \"\"\"\n+        SELECT if(sum(ProfileEvent_SleepFunctionCalls) = 1 AND\n+                  sum(ProfileEvent_SleepFunctionMicroseconds) = 2500000 AND\n+                  sum(ProfileEvent_SleepFunctionElapsedMicroseconds) = 2500000 AND\n+                  sum(ProfileEvent_Query) = 1 AND\n+                  sum(ProfileEvent_SelectQuery) = 1 AND\n+                  sum(ProfileEvent_InitialQuery) = 1,\n+                  'data_${interval}_ok', 'data_${interval}_error')\n+        FROM system.query_metric_log\n+        WHERE event_date >= yesterday() AND query_id = '${query_prefix}_${interval}'\n+    \"\"\"\n+}\n+\n+check_log 1000\n+check_log 1234\n+check_log 123\n+\n+# query_metric_log_interval=0 disables the collection altogether\n+$CLICKHOUSE_CLIENT -m -q \"\"\"SELECT count() FROM system.query_metric_log WHERE event_date >= yesterday() AND query_id = '${query_prefix}_0'\"\"\"\n+\n+# a quick query that takes less than query_metric_log_interval is never collected\n+$CLICKHOUSE_CLIENT -m -q \"\"\"SELECT count() FROM system.query_metric_log WHERE event_date >= yesterday() AND query_id = '${query_prefix}_fast'\"\"\"\n+\n+# a query that takes more than query_metric_log_interval is collected including the final row\n+$CLICKHOUSE_CLIENT -m -q \"\"\"SELECT count() FROM system.query_metric_log WHERE event_date >= yesterday() AND query_id = '${query_prefix}_1000'\"\"\"\n",
  "problem_statement": "`system.query_metric_log` table.\n**Use case**\r\n\r\nIt is similar to `metric_log` but contains per-query data and can have tuneable time resolution per query.\r\nFor example, it will let you record query metrics with 1ms resolution for some selected queries.\r\n\r\n**Additional context**\r\n\r\nEven with one-second resolution, the data looks really nice:\r\n\r\n![Screenshot_20220809_031040](https://user-images.githubusercontent.com/18581488/183541459-c80c07c1-49cf-4b78-b212-98c17aa8cd15.png)\r\n\r\nIt will be even better if we will be able to record the metrics with 1000 times more resolution.\r\n\n",
  "hints_text": "",
  "created_at": "2024-07-15T14:30:20Z",
  "modified_files": [
    "docs/en/operations/server-configuration-parameters/settings.md",
    "b/docs/en/operations/system-tables/query_metric_log.md",
    "programs/server/config.xml",
    "programs/server/config.yaml.example",
    "src/Common/CurrentMetrics.cpp",
    "src/Common/CurrentMetrics.h",
    "b/src/Common/LockGuard.h",
    "src/Common/OvercommitTracker.cpp",
    "src/Common/SharedLockGuard.h",
    "src/Common/SystemLogBase.cpp",
    "src/Common/SystemLogBase.h",
    "src/Core/Settings.cpp",
    "src/Core/SettingsChangesHistory.cpp",
    "src/Interpreters/Context.cpp",
    "src/Interpreters/Context.h",
    "src/Interpreters/ErrorLog.cpp",
    "src/Interpreters/ErrorLog.h",
    "src/Interpreters/MetricLog.cpp",
    "src/Interpreters/MetricLog.h",
    "src/Interpreters/PartLog.cpp",
    "src/Interpreters/PeriodicLog.cpp",
    "src/Interpreters/PeriodicLog.h",
    "src/Interpreters/ProcessList.cpp",
    "src/Interpreters/ProcessList.h",
    "b/src/Interpreters/QueryMetricLog.cpp",
    "b/src/Interpreters/QueryMetricLog.h",
    "src/Interpreters/SystemLog.cpp",
    "src/Interpreters/SystemLog.h",
    "src/Interpreters/executeQuery.cpp",
    "src/Processors/Transforms/WindowTransform.cpp",
    "utils/check-style/check-style"
  ],
  "modified_test_files": [
    "tests/docker_scripts/stateless_runner.sh",
    "tests/integration/test_MemoryTracking/configs/no_system_log.xml",
    "tests/integration/test_backup_restore_new/test.py",
    "b/tests/integration/test_config_xml_full/configs/config.d/query_metric_log.xml",
    "tests/integration/test_config_xml_full/configs/config.xml",
    "tests/integration/test_config_xml_full/test.py",
    "tests/integration/test_config_xml_main/configs/config.d/error_log.yaml",
    "b/tests/integration/test_config_xml_main/configs/config.d/query_metric_log.yaml",
    "tests/integration/test_config_xml_main/configs/config.xml",
    "tests/integration/test_config_xml_main/test.py",
    "b/tests/integration/test_config_xml_yaml_mix/configs/config.d/query_metric_log.xml",
    "tests/integration/test_config_xml_yaml_mix/configs/config.xml",
    "tests/integration/test_config_xml_yaml_mix/test.py",
    "b/tests/integration/test_config_yaml_full/configs/config.d/query_metric_log.yaml",
    "tests/integration/test_config_yaml_full/configs/config.yaml",
    "tests/integration/test_config_yaml_full/test.py",
    "b/tests/integration/test_config_yaml_main/configs/config.d/query_metric_log.xml",
    "tests/integration/test_config_yaml_main/configs/config.yaml",
    "tests/integration/test_config_yaml_main/test.py",
    "tests/integration/test_input_format_parallel_parsing_memory_tracking/configs/conf.xml",
    "tests/integration/test_memory_limit/configs/async_metrics_no.xml",
    "tests/integration/test_system_flush_logs/test.py",
    "tests/integration/test_system_logs_recreate/test.py",
    "b/tests/queries/0_stateless/03203_system_query_metric_log.reference",
    "b/tests/queries/0_stateless/03203_system_query_metric_log.sh"
  ]
}