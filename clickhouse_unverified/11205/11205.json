{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 11205,
  "instance_id": "ClickHouse__ClickHouse-11205",
  "issue_numbers": [
    "11181"
  ],
  "base_commit": "e9d348ebf9f3a0ab0f01c16c3b6aec194aa55326",
  "patch": "diff --git a/src/Processors/Pipe.h b/src/Processors/Pipe.h\nindex 984fa7605c63..ec5514915a73 100644\n--- a/src/Processors/Pipe.h\n+++ b/src/Processors/Pipe.h\n@@ -23,7 +23,7 @@ class Pipe\n     /// Will connect pipes outputs with transform inputs automatically.\n     Pipe(Pipes && pipes, ProcessorPtr transform);\n     /// Create pipe from output port. If pipe was created that way, it possibly will not have tree shape.\n-    Pipe(OutputPort * port);\n+    explicit Pipe(OutputPort * port);\n \n     Pipe(const Pipe & other) = delete;\n     Pipe(Pipe && other) = default;\ndiff --git a/src/Processors/QueryPipeline.cpp b/src/Processors/QueryPipeline.cpp\nindex 13787a3fd3b0..267366724125 100644\n--- a/src/Processors/QueryPipeline.cpp\n+++ b/src/Processors/QueryPipeline.cpp\n@@ -703,6 +703,11 @@ void QueryPipeline::initRowsBeforeLimit()\n Pipe QueryPipeline::getPipe() &&\n {\n     resize(1);\n+    return std::move(std::move(*this).getPipes()[0]);\n+}\n+\n+Pipes QueryPipeline::getPipes() &&\n+{\n     Pipe pipe(std::move(processors), streams.at(0), totals_having_port, extremes_port);\n     pipe.max_parallel_streams = streams.maxParallelStreams();\n \n@@ -721,7 +726,13 @@ Pipe QueryPipeline::getPipe() &&\n     if (extremes_port)\n         pipe.setExtremesPort(extremes_port);\n \n-    return pipe;\n+    Pipes pipes;\n+    pipes.emplace_back(std::move(pipe));\n+\n+    for (size_t i = 1; i < streams.size(); ++i)\n+        pipes.emplace_back(Pipe(streams[i]));\n+\n+    return pipes;\n }\n \n PipelineExecutorPtr QueryPipeline::execute()\ndiff --git a/src/Processors/QueryPipeline.h b/src/Processors/QueryPipeline.h\nindex 45e38ffa7152..d248853131c2 100644\n--- a/src/Processors/QueryPipeline.h\n+++ b/src/Processors/QueryPipeline.h\n@@ -155,8 +155,9 @@ class QueryPipeline\n     /// Set upper limit for the recommend number of threads\n     void setMaxThreads(size_t max_threads_) { max_threads = max_threads_; }\n \n-    /// Convert query pipeline to single pipe.\n+    /// Convert query pipeline to single or several pipes.\n     Pipe getPipe() &&;\n+    Pipes getPipes() &&;\n \n private:\n     /// Destruction order: processors, header, locks, temporary storages, local contexts\ndiff --git a/src/Storages/StorageView.cpp b/src/Storages/StorageView.cpp\nindex 636c7f9d64d1..01c85c5238a0 100644\n--- a/src/Storages/StorageView.cpp\n+++ b/src/Storages/StorageView.cpp\n@@ -19,6 +19,8 @@\n #include <Processors/Sources/SourceFromInputStream.h>\n #include <Processors/Transforms/MaterializingTransform.h>\n #include <Processors/Transforms/ConvertingTransform.h>\n+#include <DataStreams/MaterializingBlockInputStream.h>\n+#include <DataStreams/ConvertingBlockInputStream.h>\n \n \n namespace DB\n@@ -62,29 +64,42 @@ Pipes StorageView::read(\n     if (context.getSettings().enable_optimize_predicate_expression)\n         current_inner_query = getRuntimeViewQuery(*query_info.query->as<const ASTSelectQuery>(), context);\n \n-    QueryPipeline pipeline;\n     InterpreterSelectWithUnionQuery interpreter(current_inner_query, context, {}, column_names);\n     /// FIXME res may implicitly use some objects owned be pipeline, but them will be destructed after return\n     if (query_info.force_tree_shaped_pipeline)\n     {\n+        QueryPipeline pipeline;\n         BlockInputStreams streams = interpreter.executeWithMultipleStreams(pipeline);\n+\n+        for (auto & stream : streams)\n+        {\n+            stream = std::make_shared<MaterializingBlockInputStream>(stream);\n+            stream = std::make_shared<ConvertingBlockInputStream>(stream, getSampleBlockForColumns(column_names),\n+                                                                  ConvertingBlockInputStream::MatchColumnsMode::Name);\n+        }\n+\n         for (auto & stream : streams)\n             pipes.emplace_back(std::make_shared<SourceFromInputStream>(std::move(stream)));\n     }\n     else\n-        /// TODO: support multiple streams here. Need more general interface than pipes.\n-        pipes.emplace_back(interpreter.executeWithProcessors().getPipe());\n-\n-    /// It's expected that the columns read from storage are not constant.\n-    /// Because method 'getSampleBlockForColumns' is used to obtain a structure of result in InterpreterSelectQuery.\n-    for (auto & pipe : pipes)\n     {\n-        pipe.addSimpleTransform(std::make_shared<MaterializingTransform>(pipe.getHeader()));\n+        auto pipeline = interpreter.executeWithProcessors();\n+\n+        /// It's expected that the columns read from storage are not constant.\n+        /// Because method 'getSampleBlockForColumns' is used to obtain a structure of result in InterpreterSelectQuery.\n+        pipeline.addSimpleTransform([](const Block & header)\n+        {\n+            return std::make_shared<MaterializingTransform>(header);\n+        });\n \n         /// And also convert to expected structure.\n-        pipe.addSimpleTransform(std::make_shared<ConvertingTransform>(\n-            pipe.getHeader(), getSampleBlockForColumns(column_names),\n-            ConvertingTransform::MatchColumnsMode::Name));\n+        pipeline.addSimpleTransform([&](const Block & header)\n+        {\n+            return std::make_shared<ConvertingTransform>(header, getSampleBlockForColumns(column_names),\n+                                                         ConvertingTransform::MatchColumnsMode::Name);\n+        });\n+\n+        pipes = std::move(pipeline).getPipes();\n     }\n \n     return pipes;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01284_view_and_extremes_bug.reference b/tests/queries/0_stateless/01284_view_and_extremes_bug.reference\nnew file mode 100644\nindex 000000000000..216e97ce0822\n--- /dev/null\n+++ b/tests/queries/0_stateless/01284_view_and_extremes_bug.reference\n@@ -0,0 +1,1 @@\n+World\ndiff --git a/tests/queries/0_stateless/01284_view_and_extremes_bug.sql b/tests/queries/0_stateless/01284_view_and_extremes_bug.sql\nnew file mode 100644\nindex 000000000000..c444441a2585\n--- /dev/null\n+++ b/tests/queries/0_stateless/01284_view_and_extremes_bug.sql\n@@ -0,0 +1,4 @@\n+drop table if exists view_bug_const;\n+CREATE VIEW view_bug_const AS SELECT 'World' AS hello FROM (SELECT number FROM system.numbers LIMIT 1) AS n1 JOIN (SELECT number FROM system.numbers LIMIT 1) AS n2 USING (number);\n+select * from view_bug_const;\n+drop table if exists view_bug_const;\n",
  "problem_statement": "DB::Exception: Block structure mismatch in QueryPipeline stream: different columns (Const)\nThis simple view:\r\n\r\n```\r\nCREATE VIEW test.bug_const AS\r\nSELECT 'World' AS hello\r\nFROM (SELECT number FROM system.numbers LIMIT 1) AS n1\r\nJOIN (SELECT number FROM system.numbers LIMIT 1) AS n2 USING (number)\r\n```\r\n\r\nis created ok, but at SELECT time throws the following exception:\r\n\r\n> Received exception from server (version 20.4.3):\r\n> Code: 171. DB::Exception: Received from localhost:9000. DB::Exception: Block structure mismatch in QueryPipeline stream: different columns:\r\n> hello String String(size = 0)\r\n> hello String Const(size = 0, String(size = 1)). \r\n\r\nIf I execute the SELECT part as as standalone query, it works, but in a VIEW it does not.\r\n\r\nOn complex views, joining other views many levels deep, this bug appears on all 20.3 and 20.4 versions of Clickhouse I tried, including 20.3.10.75, 20.4.2.9 and 20.4.3.16. But the simple way to reproduce it that I posted above only triggers the bug on 20.4 versions.\r\n\r\nBranch 20.1 and previous ones seem to be OK.\n",
  "hints_text": "@KochetovNicolai ",
  "created_at": "2020-05-26T13:38:31Z"
}