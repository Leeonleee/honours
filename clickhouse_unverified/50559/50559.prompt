You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
file/(hdfs?) globs allow to have patterns across different directories
**Use case**

We want to read only specific files in each directory, and do not have access to other files.

**Describe the solution you'd like**

```
SELECT
    *,
    _path,
    _file
FROM file('{a/1,b/2}.csv', CSV)


0 rows in set. Elapsed: 0.050 sec.

Received exception:
Code: 636. DB::Exception: Cannot extract table structure from CSV format file, because there are no files with provided path. You must specify table structure manually. (CANNOT_EXTRACT_TABLE_STRUCTURE)

SELECT
    *,
    _path,
    _file
FROM file('a/1.csv', CSV)

┌─c1─┬─c2─┬─_path────────────────┬─_file─┐
│  1 │  2 │ /home/xxxxxxx/a/1.csv │ 1.csv │
└────┴────┴──────────────────────┴───────┘

SELECT
    *,
    _path,
    _file
FROM file('b/2.csv', CSV)

┌─c1─┬─c2─┬─_path────────────────┬─_file─┐
│  3 │  4 │ /home/xxxxxxx/b/2.csv │ 2.csv │
└────┴────┴──────────────────────┴───────┘
```

It's already working in such way for s3(because there is no real directories here, but still)

So you can write something like:

```
SELECT     *, _path, _file
FROM s3('https://clickhouse-public-datasets.s3.amazonaws.com/my-test-bucket-768/{some/some_file_1,another/another_file_3}.csv',   NOSIGN, CSVWithNames);
```

Related https://github.com/ClickHouse/ClickHouse/issues/16682
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
