{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 26900,
  "instance_id": "ClickHouse__ClickHouse-26900",
  "issue_numbers": [
    "26591"
  ],
  "base_commit": "fc9a2591001cd5407fad17872808d8194f6fb073",
  "patch": "diff --git a/src/Interpreters/inplaceBlockConversions.cpp b/src/Interpreters/inplaceBlockConversions.cpp\nindex ff16c7b3ff6c..26cf6912bc7e 100644\n--- a/src/Interpreters/inplaceBlockConversions.cpp\n+++ b/src/Interpreters/inplaceBlockConversions.cpp\n@@ -53,6 +53,7 @@ void addDefaultRequiredExpressionsRecursively(\n         NameSet required_columns_names = columns_context.requiredColumns();\n \n         auto expr = makeASTFunction(\"CAST\", column_default_expr, std::make_shared<ASTLiteral>(columns.get(required_column_name).type->getName()));\n+\n         if (is_column_in_query && convert_null_to_default)\n             expr = makeASTFunction(\"ifNull\", std::make_shared<ASTIdentifier>(required_column_name), std::move(expr));\n         default_expr_list_accum->children.emplace_back(setAlias(expr, required_column_name));\n@@ -62,6 +63,15 @@ void addDefaultRequiredExpressionsRecursively(\n         for (const auto & next_required_column_name : required_columns_names)\n             addDefaultRequiredExpressionsRecursively(block, next_required_column_name, required_column_type, columns, default_expr_list_accum, added_columns, null_as_default);\n     }\n+    else\n+    {\n+        /// This column is required, but doesn't have default expression, so lets use \"default default\"\n+        auto column = columns.get(required_column_name);\n+        auto default_value = column.type->getDefault();\n+        auto default_ast = std::make_shared<ASTLiteral>(default_value);\n+        default_expr_list_accum->children.emplace_back(setAlias(default_ast, required_column_name));\n+        added_columns.emplace(required_column_name);\n+    }\n }\n \n ASTPtr defaultRequiredExpressions(const Block & block, const NamesAndTypesList & required_columns, const ColumnsDescription & columns, bool null_as_default)\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02000_default_from_default_empty_column.reference b/tests/queries/0_stateless/02000_default_from_default_empty_column.reference\nnew file mode 100644\nindex 000000000000..bb48d0eda852\n--- /dev/null\n+++ b/tests/queries/0_stateless/02000_default_from_default_empty_column.reference\n@@ -0,0 +1,1 @@\n+1\t\t\ndiff --git a/tests/queries/0_stateless/02000_default_from_default_empty_column.sql b/tests/queries/0_stateless/02000_default_from_default_empty_column.sql\nnew file mode 100644\nindex 000000000000..5ca642628d49\n--- /dev/null\n+++ b/tests/queries/0_stateless/02000_default_from_default_empty_column.sql\n@@ -0,0 +1,17 @@\n+DROP TABLE IF EXISTS test;\n+\n+CREATE TABLE test (col Int8) ENGINE=MergeTree ORDER BY tuple()\n+SETTINGS vertical_merge_algorithm_min_rows_to_activate=1,\n+         vertical_merge_algorithm_min_columns_to_activate=1,\n+         min_bytes_for_wide_part = 0;\n+\n+\n+INSERT INTO test VALUES (1);\n+ALTER TABLE test ADD COLUMN s1 String;\n+ALTER TABLE test ADD COLUMN s2 String DEFAULT s1;\n+\n+OPTIMIZE TABLE test FINAL;\n+\n+SELECT * FROM test;\n+\n+DROP TABLE IF EXISTS test;\n",
  "problem_statement": "A non-materialized column cannot be retrieved if its default expression depends on another non-materialized column\nI get an exception when I query a column that tries to calculate its default from a column that does not exist either.\r\nHere is a reproducible example:\r\n```\r\ncreate table test (col Int8) engine=MergeTree order by tuple();\r\n\r\ninsert into test values (1);\r\n\r\nalter table test add column s1 String;\r\nalter table test add column s2 String default s1;\r\n\r\n-- requesting both columns\r\nselect * from test;\r\n\r\ncol | s1 | s2\r\n----+----+---\r\n  1 |    |   \r\n\r\n-- requesting only one column\r\nselect s2 from test;\r\n\r\nDB::Exception: Missing columns: 's1' while processing query: 'CAST(s1, 'String') AS s2', \r\nrequired columns: 's1' 's1': (while reading from part /var/lib/clickhouse/data/dw/test/all_1_1_0/): \r\nWhile executing MergeTree (version 21.7.3.14 (official build))\r\n```\r\n\r\nThe same thing happens with a merge.\r\nI set up 30 day TTL for two arrays, 'names' and 'values'.\r\nMATERIALIZE TTL cleaned the data.\r\nWhen a merge for an old partition (20210418) got scheduled it could not proceed, because one of the recently added columns (`v3h_fixed`) had its default value pointing to the 'names' and 'values' columns: `CAST(values[indexOf(names, '3hFixed')], 'String')`\r\n\r\nHere is the exception:\r\nCode: 47, e.displayText() = DB::Exception: Missing columns: 'names' 'values' while processing query: 'CAST(values[indexOf(names, '3hFixed')], 'String') AS v3h_fixed', required columns: 'values' 'names' 'values' 'names': (while reading from part /var/lib/clickhouse/data/db/table/20210418_238_238_0_248/): While executing MergeTreeSequentialSource: Cannot fetch required block. Stream PipelineExecuting, part 2 (version 21.7.3.14 (official build))\r\n\r\nThe merge was able to proceed and completed successfully after I removed the default expression from the `v3h_fixed` column.\r\n\r\nI could not reproduce this on a test table.\r\nWeird.\r\n\r\n```\r\n[ 7095 ] {} <Error> db.table: auto DB::StorageReplicatedMergeTree::processQueueEntry(ReplicatedMergeTreeQueue::SelectedEntryPtr)::(anonymous class)::operator() \r\n(DB::StorageReplicatedMergeTree::LogEntryPtr &) const: Code: 47, e.displayText() = DB::Exception: \r\nMissing columns: 'names' 'values' while processing query: 'CAST(values[indexOf(names, '3hFixed')], 'String') AS v3h_fixed', \r\nrequired columns: 'values' 'names' 'values' 'names': (while reading from part /var/lib/clickhouse/data/db/table/20210418_238_238_0_248/): \r\nWhile executing MergeTreeSequentialSource: Cannot fetch required block. Stream PipelineExecuting, part 2, \r\nStack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >\r\n const&, int, bool) @ 0x8d31b5a in /usr/bin/clickhouse\r\n1. DB::TreeRewriterResult::collectUsedColumns(std::__1::shared_ptr<DB::IAST> const&, bool) @ 0xfdb2470 in /usr/bi\r\nn/clickhouse\r\n2. DB::TreeRewriter::analyze(std::__1::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::__1::shared_ptr<\r\nDB::IStorage const>, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, bool, bool) const @ 0xfdbb40\r\nc in /usr/bin/clickhouse\r\n3. ? @ 0xfe370e9 in /usr/bin/clickhouse\r\n4. DB::evaluateMissingDefaults(DB::Block const&, DB::NamesAndTypesList const&, DB::ColumnsDescription const&, std\r\n::__1::shared_ptr<DB::Context const>, bool, bool) @ 0xfe379c9 in /usr/bin/clickhouse\r\n5. DB::IMergeTreeReader::evaluateMissingDefaults(DB::Block, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::\r\nIColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0x104bf3ed in /usr/bin/clickho\r\nuse\r\n6. DB::MergeTreeSequentialSource::generate() @ 0x104d098b in /usr/bin/clickhouse\r\n7. DB::ISource::tryGenerate() @ 0x106dfe35 in /usr/bin/clickhouse\r\n8. DB::ISource::work() @ 0x106dfa1a in /usr/bin/clickhouse\r\n9. DB::SourceWithProgress::work() @ 0x108b098a in /usr/bin/clickhouse\r\n10. ? @ 0x1071a4dd in /usr/bin/clickhouse\r\n11. DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) @ 0x10717071 in\r\n/usr/bin/clickhouse\r\n12. DB::PipelineExecutor::executeStep(std::__1::atomic<bool>*) @ 0x10715a9c in /usr/bin/clickhouse\r\n13. DB::PullingPipelineExecutor::pull(DB::Chunk&) @ 0x1072308a in /usr/bin/clickhouse\r\n14. DB::PullingPipelineExecutor::pull(DB::Block&) @ 0x10723290 in /usr/bin/clickhouse\r\n15. DB::PipelineExecutingBlockInputStream::readImpl() @ 0x10711f14 in /usr/bin/clickhouse\r\n16. DB::IBlockInputStream::read() @ 0xf51c6a4 in /usr/bin/clickhouse\r\n17. DB::ColumnGathererStream::fetchNewBlock(DB::ColumnGathererStream::Source&, unsigned long) @ 0xfe72412 in /usr\r\n/bin/clickhouse\r\n18. void DB::ColumnGathererStream::gather<DB::ColumnString>(DB::ColumnString&) @ 0xff06ef1 in /usr/bin/clickhouse\r\n19. DB::ColumnGathererStream::readImpl() @ 0xfe72244 in /usr/bin/clickhouse\r\n20. DB::IBlockInputStream::read() @ 0xf51c6a4 in /usr/bin/clickhouse\r\n21. DB::MergeTreeDataMergerMutator::mergePartsToTemporaryPart(DB::FutureMergedMutatedPart const&, std::__1::share\r\nd_ptr<DB::StorageInMemoryMetadata const> const&, DB::BackgroundProcessListEntry<DB::MergeListElement, DB::MergeIn\r\nfo>&, std::__1::shared_ptr<DB::RWLockImpl::LockHolderImpl>&, long, std::__1::shared_ptr<DB::Context const>, std::\r\n__1::unique_ptr<DB::IReservation, std::__1::default_delete<DB::IReservation> > const&, bool, std::__1::vector<std\r\n::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1:\r\n:basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, DB::MergeTreeData::Mergi\r\nngParams const&, DB::IMergeTreeDataPart const*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__\r\n1::allocator<char> > const&) @ 0x103eeb62 in /usr/bin/clickhouse\r\n22. DB::StorageReplicatedMergeTree::tryExecuteMerge(DB::ReplicatedMergeTreeLogEntry const&) @ 0x10123346 in /usr/\r\nbin/clickhouse\r\n23. DB::StorageReplicatedMergeTree::executeLogEntry(DB::ReplicatedMergeTreeLogEntry&) @ 0x10115054 in /usr/bin/cl\r\nickhouse\r\n24. ? @ 0x101c9c3f in /usr/bin/clickhouse\r\n25. DB::ReplicatedMergeTreeQueue::processEntry(std::__1::function<std::__1::shared_ptr<zkutil::ZooKeeper> ()>, st\r\nd::__1::shared_ptr<DB::ReplicatedMergeTreeLogEntry>&, std::__1::function<bool (std::__1::shared_ptr<DB::Replicate\r\ndMergeTreeLogEntry>&)>) @ 0x1055e38c in /usr/bin/clickhouse\r\n26. DB::StorageReplicatedMergeTree::processQueueEntry(std::__1::shared_ptr<DB::ReplicatedMergeTreeQueue::Selected\r\nEntry>) @ 0x1015e49d in /usr/bin/clickhouse\r\n27. ? @ 0x103130b7 in /usr/bin/clickhouse\r\n28. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8d75\r\n738 in /usr/bin/clickhouse\r\n29. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std:\r\n:__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>(void&&, void ThreadPoolImpl<Thread\r\nFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda\r\n0'()&&...)::'lambda'()::operator()() @ 0x8d772df in /usr/bin/clickhouse\r\n30. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8d72a1f in /\r\nusr/bin/clickhouse\r\n31. ? @ 0x8d76303 in /usr/bin/clickhouse\r\n (version 21.7.3.14 (official build))\r\n```\n",
  "hints_text": "Some more details.\r\nJust before the exception a ReplicatedMergeTreePartCheckThread comes to check one of the source parts:\r\n```\r\n2021.07.18 15:18:52.983678 [ 14758 ] {} <Debug> MergeTreeSequentialSource: Reading 5 marks from part 20210418_236_236_0_248, total 39596 rows starting from the beginning of the part, column names\r\n2021.07.18 15:18:52.984805 [ 14758 ] {} <Debug> MergeTreeSequentialSource: Reading 24 marks from part 20210418_237_237_0_248, total 194437 rows starting from the beginning of the part, column names\r\n2021.07.18 15:18:52.985954 [ 14758 ] {} <Debug> MergeTreeSequentialSource: Reading 1 marks from part 20210418_238_238_0_248, total 8 rows starting from the beginning of the part, column names\r\n2021.07.18 15:18:52.987108 [ 14758 ] {} <Debug> MergeTreeSequentialSource: Reading 10 marks from part 20210418_239_239_0_248, total 79888 rows starting from the beginning of the part, column names\r\n2021.07.18 15:18:53.116832 [ 14758 ] {} <Debug> MergeTreeSequentialSource: Reading 5 marks from part 20210418_236_236_0_248, total 39596 rows starting from the beginning of the part, column values\r\n2021.07.18 15:18:53.117974 [ 14758 ] {} <Debug> MergeTreeSequentialSource: Reading 24 marks from part 20210418_237_237_0_248, total 194437 rows starting from the beginning of the part, column values\r\n2021.07.18 15:18:53.119091 [ 14758 ] {} <Debug> MergeTreeSequentialSource: Reading 1 marks from part 20210418_238_238_0_248, total 8 rows starting from the beginning of the part, column values\r\n2021.07.18 15:18:53.120228 [ 14758 ] {} <Debug> MergeTreeSequentialSource: Reading 10 marks from part 20210418_239_239_0_248, total 79888 rows starting from the beginning of the part, column values\r\n...\r\n2021.07.18 15:19:12.617741 [ 14758 ] {} <Debug> MergeTreeSequentialSource: Reading 1 marks from part 20210418_238_238_0_248, total 8 rows starting from the beginning of the part, column v3h_fixed\r\n2021.07.18 15:19:12.618763 [ 14758 ] {} <Debug> MergeTreeSequentialSource: Reading 10 marks from part 20210418_239_239_0_248, total 79888 rows starting from the beginning of the part, column v3h_fixed\r\n2021.07.18 15:19:12.647324 [ 3746 ] {} <Warning> db.table (ReplicatedMergeTreePartCheckThread): Checking part 20210418_238_238_0_248\r\n2021.07.18 15:19:12.647877 [ 3746 ] {} <Trace> db.table (ReplicatedMergeTreePartCheckThread): Part 20210418_238_238_0_248 in zookeeper: true, locally: true\r\n2021.07.18 15:19:12.648657 [ 3746 ] {} <Warning> db.table (ReplicatedMergeTreePartCheckThread): Checking data of part 20210418_238_238_0_248.\r\n2021.07.18 15:19:12.680246 [ 14758 ] {} <Debug> MemoryTracker: Peak memory usage: 42.79 MiB.\r\n2021.07.18 15:19:12.739380 [ 14758 ] {} <Error> db.table: auto DB::StorageReplicatedMergeTree::processQueueEntry(ReplicatedMergeTreeQueue::SelectedEntryPtr)::(anonymous class)::operator()(DB::StorageReplicatedMergeTree::LogEntryPtr &) const: Code: 47, e.displayText() = DB::Exception: Missing columns: 'names' 'values' while processing query: 'CAST(values[indexOf(names, '3hFixed')], 'String') AS v3h_fixed', required columns: 'values' 'names' 'values' 'names': (while reading from part /var/lib/clickhouse/data/db/table/20210418_238_238_0_248/): While executing MergeTreeSequentialSource: Cannot fetch required block. Stream PipelineExecuting, part 2\r\n```\nI ran an optimize for a partition in which the `names` and `values` columns have been cleared by TTL and the recently added column (`v3h_fixed`) has not been materialized.\r\nThe merge generated both `names` and `values` columns for the new part, but when it was trying to calculate `v3h_fixed` it wanted to use the data from the source parts, and the source parts did not have those columns, so the merge failed.\r\n```\r\n2021.07.21 17:43:25.225388 [ 7075 ] {} <Debug> MergeTreeSequentialSource: Reading 8058 marks from part 20210412_0_252_3_265, total 66005113 rows starting from the beginning of the part, column names\r\n2021.07.21 17:43:25.226622 [ 7075 ] {} <Debug> MergeTreeSequentialSource: Reading 106 marks from part 20210412_253_256_1_265, total 860336 rows starting from the beginning of the part, column names\r\n2021.07.21 17:43:44.983375 [ 7075 ] {} <Debug> ColumnGathererStream: Gathered column names (8.001066156005324 bytes/elem.) in 19.756172489 sec., 3384534.582152989 rows/sec., 25.83 MiB/sec.\r\n2021.07.21 17:43:44.984366 [ 7075 ] {} <Debug> MergeTreeSequentialSource: Reading 8058 marks from part 20210412_0_252_3_265, total 66005113 rows starting from the beginning of the part, column values\r\n2021.07.21 17:43:44.985605 [ 7075 ] {} <Debug> MergeTreeSequentialSource: Reading 106 marks from part 20210412_253_256_1_265, total 860336 rows starting from the beginning of the part, column values\r\n2021.07.21 17:44:04.852531 [ 7075 ] {} <Debug> ColumnGathererStream: Gathered column values (8.001066156005324 bytes/elem.) in 19.864173421 sec., 3366132.9662633333 rows/sec., 25.68 MiB/sec.\r\n...\r\n2021.07.21 17:49:26.334457 [ 7075 ] {} <Debug> MergeTreeSequentialSource: Reading 8058 marks from part 20210412_0_252_3_265, total 66005113 rows starting from the beginning of the part, v3h_fixed\r\n2021.07.21 17:49:26.335684 [ 7075 ] {} <Debug> MergeTreeSequentialSource: Reading 106 marks from part 20210412_253_256_1_265, total 860336 rows starting from the beginning of the part, column v3h_fixed\r\n2021.07.21 17:49:26.337293 [ 3791 ] {} <Warning> db.table (ReplicatedMergeTreePartCheckThread): Checking part 20210412_0_252_3_265\r\n2021.07.21 17:49:26.347484 [ 3791 ] {} <Trace> db.table (ReplicatedMergeTreePartCheckThread): Part 20210412_0_252_3_265 in zookeeper: true, locally: true\r\n2021.07.21 17:49:26.348245 [ 3791 ] {} <Warning> db.table (ReplicatedMergeTreePartCheckThread): Checking data of part 20210412_0_252_3_265.\r\n2021.07.21 17:49:27.331241 [ 7075 ] {} <Debug> MemoryTracker: Peak memory usage: 47.41 MiB.\r\n2021.07.21 17:49:27.331318 [ 7075 ] {} <Error> db.table: auto DB::StorageReplicatedMergeTree::processQueueEntry(ReplicatedMergeTreeQueue::SelectedEntryPtr)::(anonymous class)::operator()(DB::StorageReplicatedMergeTree::LogEntryPtr &) const: Code: 47, e.displayText() = DB::Exception: Missing columns: 'names' 'values' while processing query: 'CAST(values[indexOf(names, '3hFixed')], 'String') AS v3h_fixed', required columns: 'values' 'names' 'values' 'names': (while reading from part /var/lib/clickhouse/data/db/table/20210412_0_252_3_265/): While executing MergeTreeSequentialSource: Cannot fetch required block. Stream PipelineExecuting, part 0\r\n```\r\n\nActually the same thing happens when I query a column that tries to calculate its default from a column that does not exist either.\r\nI could not reproduce the issue at first because I was running `select *`.\r\nHere is a reproducible example:\r\n```\r\ncreate table test (col Int8) engine=MergeTree order by tuple();\r\n\r\ninsert into test values (1);\r\n\r\nalter table test add column s1 String;\r\nalter table test add column s2 String default s1;\r\n\r\n-- requesting both columns\r\nselect * from test;\r\n\r\ncol | s1 | s2\r\n----+----+---\r\n  1 |    |   \r\n\r\n-- requesting only one column\r\nselect s2 from test;\r\n\r\nCode: 47, e.displayText() = DB::Exception: Missing columns: 's1' while processing query: 'CAST(s1, 'String') AS s2', required columns: 's1' 's1': (while reading from part /var/lib/clickhouse/data/dw/test/all_1_1_0/): While executing MergeTree (version 21.7.3.14 (official build)) [DB Errorcode=47]\r\n```\nThe same issue #21076\nIt worked at least in 18.14.\r\n```\r\nConnected to ClickHouse server version 18.14.19 revision 54409.\r\n\r\ncreate table test (col Int8) engine=MergeTree order by tuple();\r\ninsert into test values (1);\r\nalter table test add column s1 String;\r\nalter table test add column s2 String default s1;\r\n\r\nselect s2 from test;\r\n\u250c\u2500s2\u2500\u2510\r\n\u2502    \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 0.001 sec.\r\n\r\n\r\nselect * from test;\r\n\r\n\u250c\u2500col\u2500\u252c\u2500s1\u2500\u252c\u2500s2\u2500\u2510\r\n\u2502   1 \u2502    \u2502    \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2518\nThere is no exception on 20.3!\nThere is no exception on 20.6!\nThere is an exception on 20.9!\n```sql\r\ncreate table test (col Int8) engine=MergeTree order by tuple()\r\nsettings vertical_merge_algorithm_min_rows_to_activate=1, \r\n         vertical_merge_algorithm_min_columns_to_activate=1, \r\n         index_granularity_bytes = 0;\r\n\r\ninsert into test values (1);\r\nalter table test add column s1 String;\r\nalter table test add column s2 String default s1;\r\n\r\noptimize table test final;\r\n\r\n(version 21.8.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: 's1' \r\nwhile processing query: 'CAST(s1, 'String') AS s2', required columns: 's1' 's1': \r\n(while reading from part /var/lib/clickhouse/data/dw/test/all_1_1_0/): \r\nWhile executing MergeTreeSequentialSource: Cannot fetch required block. Stream PipelineExecuting, part 0.\r\n\r\n```\r\n\r\nindex_granularity_bytes = 0 -- to produce WIDE part.",
  "created_at": "2021-07-28T12:06:29Z"
}