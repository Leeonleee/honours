{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 38335,
  "instance_id": "ClickHouse__ClickHouse-38335",
  "issue_numbers": [
    "38312"
  ],
  "base_commit": "0bb036dd211a488e5ff9a05458006fd1639debc7",
  "patch": "diff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex 476725c5627c..621c40c31bf7 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -1488,6 +1488,7 @@ int Server::main(const std::vector<std::string> & /*args*/)\n         /// We load temporary database first, because projections need it.\n         database_catalog.initializeAndLoadTemporaryDatabase();\n         loadMetadataSystem(global_context);\n+        maybeConvertOrdinaryDatabaseToAtomic(global_context, DatabaseCatalog::instance().getSystemDatabase());\n         /// After attaching system databases we can initialize system log.\n         global_context->initializeSystemLogs();\n         global_context->setSystemZooKeeperLogAfterInitializationIfNeeded();\ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex a446c1a77689..f1f7bc7f2ab1 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -445,7 +445,6 @@ static constexpr UInt64 operator\"\"_GiB(unsigned long long value)\n     M(Seconds, wait_for_window_view_fire_signal_timeout, 10, \"Timeout for waiting for window view fire signal in event time processing\", 0) \\\n     M(UInt64, min_free_disk_space_for_temporary_data, 0, \"The minimum disk space to keep while writing temporary data used in external sorting and aggregation.\", 0) \\\n     \\\n-    M(DefaultDatabaseEngine, default_database_engine, DefaultDatabaseEngine::Atomic, \"Default database engine.\", 0) \\\n     M(DefaultTableEngine, default_table_engine, DefaultTableEngine::None, \"Default table engine used when ENGINE is not set in CREATE statement.\",0) \\\n     M(Bool, show_table_uuid_in_table_create_query_if_not_nil, false, \"For tables in databases with Engine=Atomic show UUID of the table in its CREATE query.\", 0) \\\n     M(Bool, database_atomic_wait_for_drop_and_detach_synchronously, false, \"When executing DROP or DETACH TABLE in Atomic database, wait for table data to be finally dropped or detached.\", 0) \\\n@@ -640,6 +639,7 @@ static constexpr UInt64 operator\"\"_GiB(unsigned long long value)\n     MAKE_OBSOLETE(M, UInt64, background_schedule_pool_size, 128) \\\n     MAKE_OBSOLETE(M, UInt64, background_message_broker_schedule_pool_size, 16) \\\n     MAKE_OBSOLETE(M, UInt64, background_distributed_schedule_pool_size, 16) \\\n+    MAKE_OBSOLETE(M, DefaultDatabaseEngine, default_database_engine, DefaultDatabaseEngine::Atomic) \\\n     /** The section above is for obsolete settings. Do not add anything there. */\n \n \ndiff --git a/src/Databases/DatabaseAtomic.cpp b/src/Databases/DatabaseAtomic.cpp\nindex a4fa1fa267b8..be53512a608b 100644\n--- a/src/Databases/DatabaseAtomic.cpp\n+++ b/src/Databases/DatabaseAtomic.cpp\n@@ -109,13 +109,13 @@ StoragePtr DatabaseAtomic::detachTable(ContextPtr /* context */, const String &\n     return table;\n }\n \n-void DatabaseAtomic::dropTable(ContextPtr local_context, const String & table_name, bool no_delay)\n+void DatabaseAtomic::dropTable(ContextPtr local_context, const String & table_name, bool sync)\n {\n     auto table = tryGetTable(table_name, local_context);\n     /// Remove the inner table (if any) to avoid deadlock\n     /// (due to attempt to execute DROP from the worker thread)\n     if (table)\n-        table->dropInnerTableIfAny(no_delay, local_context);\n+        table->dropInnerTableIfAny(sync, local_context);\n     else\n         throw Exception(ErrorCodes::UNKNOWN_TABLE, \"Table {}.{} doesn't exist\",\n                         backQuote(database_name), backQuote(table_name));\n@@ -145,7 +145,7 @@ void DatabaseAtomic::dropTable(ContextPtr local_context, const String & table_na\n \n     /// Notify DatabaseCatalog that table was dropped. It will remove table data in background.\n     /// Cleanup is performed outside of database to allow easily DROP DATABASE without waiting for cleanup to complete.\n-    DatabaseCatalog::instance().enqueueDroppedTableCleanup(table->getStorageID(), table, table_metadata_path_drop, no_delay);\n+    DatabaseCatalog::instance().enqueueDroppedTableCleanup(table->getStorageID(), table, table_metadata_path_drop, sync);\n }\n \n void DatabaseAtomic::renameTable(ContextPtr local_context, const String & table_name, IDatabase & to_database,\ndiff --git a/src/Databases/DatabaseAtomic.h b/src/Databases/DatabaseAtomic.h\nindex b748e53244dd..cba9593a6019 100644\n--- a/src/Databases/DatabaseAtomic.h\n+++ b/src/Databases/DatabaseAtomic.h\n@@ -35,7 +35,7 @@ class DatabaseAtomic : public DatabaseOrdinary\n             bool exchange,\n             bool dictionary) override;\n \n-    void dropTable(ContextPtr context, const String & table_name, bool no_delay) override;\n+    void dropTable(ContextPtr context, const String & table_name, bool sync) override;\n \n     void attachTable(ContextPtr context, const String & name, const StoragePtr & table, const String & relative_table_path) override;\n     StoragePtr detachTable(ContextPtr context, const String & name) override;\ndiff --git a/src/Databases/DatabaseFactory.cpp b/src/Databases/DatabaseFactory.cpp\nindex 5c7c1dedf9b7..af82d3820634 100644\n--- a/src/Databases/DatabaseFactory.cpp\n+++ b/src/Databases/DatabaseFactory.cpp\n@@ -62,36 +62,19 @@ namespace ErrorCodes\n \n DatabasePtr DatabaseFactory::get(const ASTCreateQuery & create, const String & metadata_path, ContextPtr context)\n {\n-    bool created = false;\n+    /// Creates store/xxx/ for Atomic\n+    fs::create_directories(fs::path(metadata_path).parent_path());\n \n-    try\n-    {\n-        /// Creates store/xxx/ for Atomic\n-        fs::create_directories(fs::path(metadata_path).parent_path());\n-\n-        /// Before 20.7 it's possible that .sql metadata file does not exist for some old database.\n-        /// In this case Ordinary database is created on server startup if the corresponding metadata directory exists.\n-        /// So we should remove metadata directory if database creation failed.\n-        /// TODO remove this code\n-        created = fs::create_directory(metadata_path);\n-\n-        DatabasePtr impl = getImpl(create, metadata_path, context);\n+    DatabasePtr impl = getImpl(create, metadata_path, context);\n \n-        if (impl && context->hasQueryContext() && context->getSettingsRef().log_queries)\n-            context->getQueryContext()->addQueryFactoriesInfo(Context::QueryLogFactories::Database, impl->getEngineName());\n+    if (impl && context->hasQueryContext() && context->getSettingsRef().log_queries)\n+        context->getQueryContext()->addQueryFactoriesInfo(Context::QueryLogFactories::Database, impl->getEngineName());\n \n-        // Attach database metadata\n-        if (impl && create.comment)\n-            impl->setDatabaseComment(create.comment->as<ASTLiteral>()->value.safeGet<String>());\n+    /// Attach database metadata\n+    if (impl && create.comment)\n+        impl->setDatabaseComment(create.comment->as<ASTLiteral>()->value.safeGet<String>());\n \n-        return impl;\n-    }\n-    catch (...)\n-    {\n-        if (created && fs::exists(metadata_path))\n-            fs::remove_all(metadata_path);\n-        throw;\n-    }\n+    return impl;\n }\n \n template <typename ValueType>\n@@ -139,8 +122,14 @@ DatabasePtr DatabaseFactory::getImpl(const ASTCreateQuery & create, const String\n         throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Database engine `{}` cannot have table overrides\", engine_name);\n \n     if (engine_name == \"Ordinary\")\n+    {\n+        if (!create.attach && !context->getSettingsRef().allow_deprecated_database_ordinary)\n+            throw Exception(ErrorCodes::UNKNOWN_DATABASE_ENGINE,\n+                            \"Ordinary database engine is deprecated (see also allow_deprecated_database_ordinary setting)\");\n         return std::make_shared<DatabaseOrdinary>(database_name, metadata_path, context);\n-    else if (engine_name == \"Atomic\")\n+    }\n+\n+    if (engine_name == \"Atomic\")\n         return std::make_shared<DatabaseAtomic>(database_name, metadata_path, uuid, context);\n     else if (engine_name == \"Memory\")\n         return std::make_shared<DatabaseMemory>(database_name, context);\ndiff --git a/src/Databases/DatabaseLazy.cpp b/src/Databases/DatabaseLazy.cpp\nindex b024c73d5783..84e1a1326699 100644\n--- a/src/Databases/DatabaseLazy.cpp\n+++ b/src/Databases/DatabaseLazy.cpp\n@@ -77,10 +77,10 @@ void DatabaseLazy::createTable(\n void DatabaseLazy::dropTable(\n     ContextPtr local_context,\n     const String & table_name,\n-    bool no_delay)\n+    bool sync)\n {\n     SCOPE_EXIT_MEMORY_SAFE({ clearExpiredTables(); });\n-    DatabaseOnDisk::dropTable(local_context, table_name, no_delay);\n+    DatabaseOnDisk::dropTable(local_context, table_name, sync);\n }\n \n void DatabaseLazy::renameTable(\ndiff --git a/src/Databases/DatabaseLazy.h b/src/Databases/DatabaseLazy.h\nindex 3a7d7b14be1d..8d4799945fb8 100644\n--- a/src/Databases/DatabaseLazy.h\n+++ b/src/Databases/DatabaseLazy.h\n@@ -37,7 +37,7 @@ class DatabaseLazy final : public DatabaseOnDisk\n     void dropTable(\n         ContextPtr context,\n         const String & table_name,\n-        bool no_delay) override;\n+        bool sync) override;\n \n     void renameTable(\n         ContextPtr context,\ndiff --git a/src/Databases/DatabaseMemory.cpp b/src/Databases/DatabaseMemory.cpp\nindex 6df5b70c8277..664bb015925d 100644\n--- a/src/Databases/DatabaseMemory.cpp\n+++ b/src/Databases/DatabaseMemory.cpp\n@@ -52,7 +52,7 @@ void DatabaseMemory::createTable(\n void DatabaseMemory::dropTable(\n     ContextPtr /*context*/,\n     const String & table_name,\n-    bool /*no_delay*/)\n+    bool /*sync*/)\n {\n     std::unique_lock lock{mutex};\n     auto table = detachTableUnlocked(table_name, lock);\ndiff --git a/src/Databases/DatabaseMemory.h b/src/Databases/DatabaseMemory.h\nindex b854d9be1f34..6b22b5a4ec21 100644\n--- a/src/Databases/DatabaseMemory.h\n+++ b/src/Databases/DatabaseMemory.h\n@@ -32,7 +32,7 @@ class DatabaseMemory final : public DatabaseWithOwnTablesBase\n     void dropTable(\n         ContextPtr context,\n         const String & table_name,\n-        bool no_delay) override;\n+        bool sync) override;\n \n     ASTPtr getCreateTableQueryImpl(const String & name, ContextPtr context, bool throw_on_error) const override;\n     ASTPtr getCreateDatabaseQuery() const override;\ndiff --git a/src/Databases/DatabaseOnDisk.cpp b/src/Databases/DatabaseOnDisk.cpp\nindex 64bc9a4a0946..1895cb12a0e9 100644\n--- a/src/Databases/DatabaseOnDisk.cpp\n+++ b/src/Databases/DatabaseOnDisk.cpp\n@@ -281,7 +281,7 @@ void DatabaseOnDisk::detachTablePermanently(ContextPtr query_context, const Stri\n     }\n }\n \n-void DatabaseOnDisk::dropTable(ContextPtr local_context, const String & table_name, bool /*no_delay*/)\n+void DatabaseOnDisk::dropTable(ContextPtr local_context, const String & table_name, bool /*sync*/)\n {\n     String table_metadata_path = getObjectMetadataPath(table_name);\n     String table_metadata_path_drop = table_metadata_path + drop_suffix;\ndiff --git a/src/Databases/DatabaseOnDisk.h b/src/Databases/DatabaseOnDisk.h\nindex a118c8da6782..462b602a8b81 100644\n--- a/src/Databases/DatabaseOnDisk.h\n+++ b/src/Databases/DatabaseOnDisk.h\n@@ -43,7 +43,7 @@ class DatabaseOnDisk : public DatabaseWithOwnTablesBase\n     void dropTable(\n         ContextPtr context,\n         const String & table_name,\n-        bool no_delay) override;\n+        bool sync) override;\n \n     void renameTable(\n         ContextPtr context,\ndiff --git a/src/Databases/DatabaseReplicated.cpp b/src/Databases/DatabaseReplicated.cpp\nindex 5c701c8d90c8..7067746cf716 100644\n--- a/src/Databases/DatabaseReplicated.cpp\n+++ b/src/Databases/DatabaseReplicated.cpp\n@@ -608,6 +608,7 @@ void DatabaseReplicated::recoverLostReplica(const ZooKeeperPtr & current_zookeep\n         /// and make possible creation of new table with the same UUID.\n         String query = fmt::format(\"CREATE DATABASE IF NOT EXISTS {} ENGINE=Ordinary\", backQuoteIfNeed(to_db_name));\n         auto query_context = Context::createCopy(getContext());\n+        query_context->setSetting(\"allow_deprecated_database_ordinary\", 1);\n         executeQuery(query, query_context, true);\n \n         /// But we want to avoid discarding UUID of ReplicatedMergeTree tables, because it will not work\n@@ -811,7 +812,7 @@ void DatabaseReplicated::shutdown()\n }\n \n \n-void DatabaseReplicated::dropTable(ContextPtr local_context, const String & table_name, bool no_delay)\n+void DatabaseReplicated::dropTable(ContextPtr local_context, const String & table_name, bool sync)\n {\n     auto txn = local_context->getZooKeeperMetadataTransaction();\n     assert(!ddl_worker->isCurrentlyActive() || txn || startsWith(table_name, \".inner_id.\"));\n@@ -820,7 +821,7 @@ void DatabaseReplicated::dropTable(ContextPtr local_context, const String & tabl\n         String metadata_zk_path = zookeeper_path + \"/metadata/\" + escapeForFileName(table_name);\n         txn->addOp(zkutil::makeRemoveRequest(metadata_zk_path, -1));\n     }\n-    DatabaseAtomic::dropTable(local_context, table_name, no_delay);\n+    DatabaseAtomic::dropTable(local_context, table_name, sync);\n }\n \n void DatabaseReplicated::renameTable(ContextPtr local_context, const String & table_name, IDatabase & to_database,\ndiff --git a/src/Databases/DatabaseReplicated.h b/src/Databases/DatabaseReplicated.h\nindex 45a9d12981c9..3aa2aa378b7e 100644\n--- a/src/Databases/DatabaseReplicated.h\n+++ b/src/Databases/DatabaseReplicated.h\n@@ -30,7 +30,7 @@ class DatabaseReplicated : public DatabaseAtomic\n     String getEngineName() const override { return \"Replicated\"; }\n \n     /// If current query is initial, then the following methods add metadata updating ZooKeeper operations to current ZooKeeperMetadataTransaction.\n-    void dropTable(ContextPtr, const String & table_name, bool no_delay) override;\n+    void dropTable(ContextPtr, const String & table_name, bool sync) override;\n     void renameTable(ContextPtr context, const String & table_name, IDatabase & to_database,\n                      const String & to_table_name, bool exchange, bool dictionary) override;\n     void commitCreateTable(const ASTCreateQuery & query, const StoragePtr & table,\ndiff --git a/src/Databases/IDatabase.h b/src/Databases/IDatabase.h\nindex a81df0a389af..1a0ffa7bcf0a 100644\n--- a/src/Databases/IDatabase.h\n+++ b/src/Databases/IDatabase.h\n@@ -198,7 +198,7 @@ class IDatabase : public std::enable_shared_from_this<IDatabase>\n     virtual void dropTable( /// NOLINT\n         ContextPtr /*context*/,\n         const String & /*name*/,\n-        [[maybe_unused]] bool no_delay = false)\n+        [[maybe_unused]] bool sync = false)\n     {\n         throw Exception(\"There is no DROP TABLE query for Database\" + getEngineName(), ErrorCodes::NOT_IMPLEMENTED);\n     }\ndiff --git a/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp b/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp\nindex 13f55eab9e2f..a81e07f01732 100644\n--- a/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp\n+++ b/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp\n@@ -80,10 +80,10 @@ void DatabaseMaterializedMySQL::createTable(ContextPtr context_, const String &\n     DatabaseAtomic::createTable(context_, name, table, query);\n }\n \n-void DatabaseMaterializedMySQL::dropTable(ContextPtr context_, const String & name, bool no_delay)\n+void DatabaseMaterializedMySQL::dropTable(ContextPtr context_, const String & name, bool sync)\n {\n     checkIsInternalQuery(context_, \"DROP TABLE\");\n-    DatabaseAtomic::dropTable(context_, name, no_delay);\n+    DatabaseAtomic::dropTable(context_, name, sync);\n }\n \n void DatabaseMaterializedMySQL::attachTable(ContextPtr context_, const String & name, const StoragePtr & table, const String & relative_table_path)\ndiff --git a/src/Databases/MySQL/DatabaseMaterializedMySQL.h b/src/Databases/MySQL/DatabaseMaterializedMySQL.h\nindex 32686784f2a1..a6810f29d87c 100644\n--- a/src/Databases/MySQL/DatabaseMaterializedMySQL.h\n+++ b/src/Databases/MySQL/DatabaseMaterializedMySQL.h\n@@ -52,7 +52,7 @@ class DatabaseMaterializedMySQL : public DatabaseAtomic\n \n     void createTable(ContextPtr context_, const String & name, const StoragePtr & table, const ASTPtr & query) override;\n \n-    void dropTable(ContextPtr context_, const String & name, bool no_delay) override;\n+    void dropTable(ContextPtr context_, const String & name, bool sync) override;\n \n     void attachTable(ContextPtr context_, const String & name, const StoragePtr & table, const String & relative_table_path) override;\n \ndiff --git a/src/Databases/MySQL/DatabaseMySQL.cpp b/src/Databases/MySQL/DatabaseMySQL.cpp\nindex 58be682bd736..95098ba9cbd8 100644\n--- a/src/Databases/MySQL/DatabaseMySQL.cpp\n+++ b/src/Databases/MySQL/DatabaseMySQL.cpp\n@@ -447,7 +447,7 @@ void DatabaseMySQL::detachTablePermanently(ContextPtr, const String & table_name\n     table_iter->second.second->is_dropped = true;\n }\n \n-void DatabaseMySQL::dropTable(ContextPtr local_context, const String & table_name, bool /*no_delay*/)\n+void DatabaseMySQL::dropTable(ContextPtr local_context, const String & table_name, bool /*sync*/)\n {\n     detachTablePermanently(local_context, table_name);\n }\ndiff --git a/src/Databases/MySQL/DatabaseMySQL.h b/src/Databases/MySQL/DatabaseMySQL.h\nindex 1ee090ecd524..6a5105e2dba6 100644\n--- a/src/Databases/MySQL/DatabaseMySQL.h\n+++ b/src/Databases/MySQL/DatabaseMySQL.h\n@@ -82,7 +82,7 @@ class DatabaseMySQL final : public IDatabase, WithContext\n \n     void detachTablePermanently(ContextPtr context, const String & table_name) override;\n \n-    void dropTable(ContextPtr context, const String & table_name, bool no_delay) override;\n+    void dropTable(ContextPtr context, const String & table_name, bool sync) override;\n \n     void attachTable(ContextPtr context, const String & table_name, const StoragePtr & storage, const String & relative_table_path) override;\n \ndiff --git a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp\nindex db184342a97a..10b109630c73 100644\n--- a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp\n+++ b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp\n@@ -390,10 +390,10 @@ void DatabaseMaterializedPostgreSQL::stopReplication()\n }\n \n \n-void DatabaseMaterializedPostgreSQL::dropTable(ContextPtr local_context, const String & table_name, bool no_delay)\n+void DatabaseMaterializedPostgreSQL::dropTable(ContextPtr local_context, const String & table_name, bool sync)\n {\n     /// Modify context into nested_context and pass query to Atomic database.\n-    DatabaseAtomic::dropTable(StorageMaterializedPostgreSQL::makeNestedTableContext(local_context), table_name, no_delay);\n+    DatabaseAtomic::dropTable(StorageMaterializedPostgreSQL::makeNestedTableContext(local_context), table_name, sync);\n }\n \n \ndiff --git a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h\nindex 08420f4ba5ee..ac2bcedca608 100644\n--- a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h\n+++ b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h\n@@ -55,7 +55,7 @@ class DatabaseMaterializedPostgreSQL : public DatabaseAtomic\n \n     StoragePtr detachTable(ContextPtr context, const String & table_name) override;\n \n-    void dropTable(ContextPtr local_context, const String & name, bool no_delay) override;\n+    void dropTable(ContextPtr local_context, const String & name, bool sync) override;\n \n     void drop(ContextPtr local_context) override;\n \ndiff --git a/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp b/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp\nindex 1bcc203beb92..fed4d1ee64d7 100644\n--- a/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp\n+++ b/src/Databases/PostgreSQL/DatabasePostgreSQL.cpp\n@@ -264,7 +264,7 @@ void DatabasePostgreSQL::createTable(ContextPtr local_context, const String & ta\n }\n \n \n-void DatabasePostgreSQL::dropTable(ContextPtr, const String & table_name, bool /* no_delay */)\n+void DatabasePostgreSQL::dropTable(ContextPtr, const String & table_name, bool /* sync */)\n {\n     std::lock_guard<std::mutex> lock{mutex};\n \ndiff --git a/src/Databases/PostgreSQL/DatabasePostgreSQL.h b/src/Databases/PostgreSQL/DatabasePostgreSQL.h\nindex 3397dcc80766..3d5e7bd444e8 100644\n--- a/src/Databases/PostgreSQL/DatabasePostgreSQL.h\n+++ b/src/Databases/PostgreSQL/DatabasePostgreSQL.h\n@@ -53,7 +53,7 @@ class DatabasePostgreSQL final : public IDatabase, WithContext\n     StoragePtr tryGetTable(const String & name, ContextPtr context) const override;\n \n     void createTable(ContextPtr, const String & table_name, const StoragePtr & storage, const ASTPtr & create_query) override;\n-    void dropTable(ContextPtr, const String & table_name, bool no_delay) override;\n+    void dropTable(ContextPtr, const String & table_name, bool sync) override;\n \n     void attachTable(ContextPtr context, const String & table_name, const StoragePtr & storage, const String & relative_table_path) override;\n     StoragePtr detachTable(ContextPtr context, const String & table_name) override;\ndiff --git a/src/Interpreters/AsynchronousInsertQueue.h b/src/Interpreters/AsynchronousInsertQueue.h\nindex db3cb3049fd4..8a4e8dad8dd1 100644\n--- a/src/Interpreters/AsynchronousInsertQueue.h\n+++ b/src/Interpreters/AsynchronousInsertQueue.h\n@@ -1,7 +1,6 @@\n #pragma once\n \n #include <Parsers/IAST_fwd.h>\n-#include <Common/RWLock.h>\n #include <Common/ThreadPool.h>\n #include <Core/Settings.h>\n #include <Poco/Logger.h>\ndiff --git a/src/Interpreters/HashJoin.h b/src/Interpreters/HashJoin.h\nindex b2a7aedaa5af..17d09b25ea16 100644\n--- a/src/Interpreters/HashJoin.h\n+++ b/src/Interpreters/HashJoin.h\n@@ -16,7 +16,7 @@\n #include <Common/ColumnsHashing.h>\n #include <Common/HashTable/HashMap.h>\n #include <Common/HashTable/FixedHashMap.h>\n-#include <Common/RWLock.h>\n+#include <Storages/TableLockHolder.h>\n \n #include <Columns/ColumnString.h>\n #include <Columns/ColumnFixedString.h>\n@@ -339,7 +339,7 @@ class HashJoin : public IJoin\n \n     /// We keep correspondence between used_flags and hash table internal buffer.\n     /// Hash table cannot be modified during HashJoin lifetime and must be protected with lock.\n-    void setLock(RWLockImpl::LockHolder rwlock_holder)\n+    void setLock(TableLockHolder rwlock_holder)\n     {\n         storage_join_lock = rwlock_holder;\n     }\n@@ -394,7 +394,7 @@ class HashJoin : public IJoin\n \n     /// Should be set via setLock to protect hash table from modification from StorageJoin\n     /// If set HashJoin instance is not available for modification (addJoinedBlock)\n-    RWLockImpl::LockHolder storage_join_lock = nullptr;\n+    TableLockHolder storage_join_lock = nullptr;\n \n     void dataMapInit(MapsVariant &);\n \ndiff --git a/src/Interpreters/InterpreterCreateQuery.cpp b/src/Interpreters/InterpreterCreateQuery.cpp\nindex 75d00fcb8a75..20d88c91709b 100644\n--- a/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -150,10 +150,9 @@ BlockIO InterpreterCreateQuery::createDatabase(ASTCreateQuery & create)\n         /// When attaching old-style database during server startup, we must always use Ordinary engine\n         if (create.attach)\n             throw Exception(\"Database engine must be specified for ATTACH DATABASE query\", ErrorCodes::UNKNOWN_DATABASE_ENGINE);\n-        bool old_style_database = getContext()->getSettingsRef().default_database_engine.value == DefaultDatabaseEngine::Ordinary;\n         auto engine = std::make_shared<ASTFunction>();\n         auto storage = std::make_shared<ASTStorage>();\n-        engine->name = old_style_database ? \"Ordinary\" : \"Atomic\";\n+        engine->name = \"Atomic\";\n         engine->no_empty_args = true;\n         storage->set(storage->engine, engine);\n         create.set(create.storage, storage);\n@@ -196,8 +195,7 @@ BlockIO InterpreterCreateQuery::createDatabase(ASTCreateQuery & create)\n \n         if (create_from_user)\n         {\n-            const auto & default_engine = getContext()->getSettingsRef().default_database_engine.value;\n-            if (create.uuid == UUIDHelpers::Nil && default_engine == DefaultDatabaseEngine::Atomic)\n+            if (create.uuid == UUIDHelpers::Nil)\n                 create.uuid = UUIDHelpers::generateV4();    /// Will enable Atomic engine for nested database\n         }\n         else if (attach_from_user && create.uuid == UUIDHelpers::Nil)\ndiff --git a/src/Interpreters/InterpreterDropQuery.cpp b/src/Interpreters/InterpreterDropQuery.cpp\nindex 41b65e73efa2..ac731ec6f4b6 100644\n--- a/src/Interpreters/InterpreterDropQuery.cpp\n+++ b/src/Interpreters/InterpreterDropQuery.cpp\n@@ -62,7 +62,7 @@ BlockIO InterpreterDropQuery::execute()\n     }\n \n     if (getContext()->getSettingsRef().database_atomic_wait_for_drop_and_detach_synchronously)\n-        drop.no_delay = true;\n+        drop.sync = true;\n \n     if (drop.table)\n         return executeToTable(drop);\n@@ -89,7 +89,7 @@ BlockIO InterpreterDropQuery::executeToTable(ASTDropQuery & query)\n     DatabasePtr database;\n     UUID table_to_wait_on = UUIDHelpers::Nil;\n     auto res = executeToTableImpl(getContext(), query, database, table_to_wait_on);\n-    if (query.no_delay)\n+    if (query.sync)\n         waitForTableToBeActuallyDroppedOrDetached(query, database, table_to_wait_on);\n     return res;\n }\n@@ -244,7 +244,7 @@ BlockIO InterpreterDropQuery::executeToTableImpl(ContextPtr context_, ASTDropQue\n \n             DatabaseCatalog::instance().tryRemoveLoadingDependencies(table_id, getContext()->getSettingsRef().check_table_dependencies,\n                                                                      is_drop_or_detach_database);\n-            database->dropTable(context_, table_id.table_name, query.no_delay);\n+            database->dropTable(context_, table_id.table_name, query.sync);\n         }\n \n         db = database;\n@@ -300,7 +300,7 @@ BlockIO InterpreterDropQuery::executeToDatabase(const ASTDropQuery & query)\n     }\n     catch (...)\n     {\n-        if (query.no_delay)\n+        if (query.sync)\n         {\n             for (const auto & table_uuid : tables_to_wait)\n                 waitForTableToBeActuallyDroppedOrDetached(query, database, table_uuid);\n@@ -308,7 +308,7 @@ BlockIO InterpreterDropQuery::executeToDatabase(const ASTDropQuery & query)\n         throw;\n     }\n \n-    if (query.no_delay)\n+    if (query.sync)\n     {\n         for (const auto & table_uuid : tables_to_wait)\n             waitForTableToBeActuallyDroppedOrDetached(query, database, table_uuid);\n@@ -345,7 +345,7 @@ BlockIO InterpreterDropQuery::executeToDatabaseImpl(const ASTDropQuery & query,\n                 query_for_table.kind = query.kind;\n                 query_for_table.if_exists = true;\n                 query_for_table.setDatabase(database_name);\n-                query_for_table.no_delay = query.no_delay;\n+                query_for_table.sync = query.sync;\n \n                 /// Flush should not be done if shouldBeEmptyOnDetach() == false,\n                 /// since in this case getTablesIterator() may do some additional work,\n@@ -368,7 +368,7 @@ BlockIO InterpreterDropQuery::executeToDatabaseImpl(const ASTDropQuery & query,\n                 }\n             }\n \n-            if (!drop && query.no_delay)\n+            if (!drop && query.sync)\n             {\n                 /// Avoid \"some tables are still in use\" when sync mode is enabled\n                 for (const auto & table_uuid : uuids_to_wait)\n@@ -428,7 +428,7 @@ void InterpreterDropQuery::extendQueryLogElemImpl(QueryLogElement & elem, const\n     elem.query_kind = \"Drop\";\n }\n \n-void InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind kind, ContextPtr global_context, ContextPtr current_context, const StorageID & target_table_id, bool no_delay)\n+void InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind kind, ContextPtr global_context, ContextPtr current_context, const StorageID & target_table_id, bool sync)\n {\n     if (DatabaseCatalog::instance().tryGetTable(target_table_id, current_context))\n     {\n@@ -437,7 +437,7 @@ void InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind kind, ContextPtr\n         drop_query->setDatabase(target_table_id.database_name);\n         drop_query->setTable(target_table_id.table_name);\n         drop_query->kind = kind;\n-        drop_query->no_delay = no_delay;\n+        drop_query->sync = sync;\n         drop_query->if_exists = true;\n         ASTPtr ast_drop_query = drop_query;\n         /// FIXME We have to use global context to execute DROP query for inner table\ndiff --git a/src/Interpreters/InterpreterDropQuery.h b/src/Interpreters/InterpreterDropQuery.h\nindex 1a38abcdff9a..2b65039954be 100644\n--- a/src/Interpreters/InterpreterDropQuery.h\n+++ b/src/Interpreters/InterpreterDropQuery.h\n@@ -26,7 +26,7 @@ class InterpreterDropQuery : public IInterpreter, WithMutableContext\n \n     void extendQueryLogElemImpl(QueryLogElement & elem, const ASTPtr &, ContextPtr) const override;\n \n-    static void executeDropQuery(ASTDropQuery::Kind kind, ContextPtr global_context, ContextPtr current_context, const StorageID & target_table_id, bool no_delay);\n+    static void executeDropQuery(ASTDropQuery::Kind kind, ContextPtr global_context, ContextPtr current_context, const StorageID & target_table_id, bool sync);\n \n private:\n     AccessRightsElements getRequiredAccessForDDLOnCluster() const;\ndiff --git a/src/Interpreters/loadMetadata.cpp b/src/Interpreters/loadMetadata.cpp\nindex de920eaddbfe..15d4f7929f87 100644\n--- a/src/Interpreters/loadMetadata.cpp\n+++ b/src/Interpreters/loadMetadata.cpp\n@@ -9,6 +9,7 @@\n #include <Interpreters/InterpreterCreateQuery.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/loadMetadata.h>\n+#include <Interpreters/executeQuery.h>\n \n #include <Databases/DatabaseOrdinary.h>\n #include <Databases/TablesLoader.h>\n@@ -18,7 +19,6 @@\n #include <Common/escapeForFileName.h>\n \n #include <Common/typeid_cast.h>\n-#include <Common/StringUtils/StringUtils.h>\n #include <filesystem>\n #include <Common/logger_useful.h>\n \n@@ -27,6 +27,12 @@ namespace fs = std::filesystem;\n namespace DB\n {\n \n+namespace ErrorCodes\n+{\n+    extern const int NOT_IMPLEMENTED;\n+    extern const int LOGICAL_ERROR;\n+}\n+\n static void executeCreateQuery(\n     const String & query,\n     ContextMutablePtr context,\n@@ -71,12 +77,6 @@ static void loadDatabase(\n         ReadBufferFromFile in(database_metadata_file, 1024);\n         readStringUntilEOF(database_attach_query, in);\n     }\n-    else if (fs::exists(fs::path(database_path)))\n-    {\n-        /// TODO Remove this code (it's required for compatibility with versions older than 20.7)\n-        /// Database exists, but .sql file is absent. It's old-style Ordinary database (e.g. system or default)\n-        database_attach_query = \"ATTACH DATABASE \" + backQuoteIfNeed(database) + \" ENGINE = Ordinary\";\n-    }\n     else\n     {\n         /// It's first server run and we need create default and system databases.\n@@ -95,6 +95,15 @@ static void loadDatabase(\n     }\n }\n \n+static void checkUnsupportedVersion(ContextMutablePtr context, const String & database_name)\n+{\n+    /// Produce better exception message\n+    String metadata_path = context->getPath() + \"metadata/\" + database_name;\n+    if (fs::exists(fs::path(metadata_path)))\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Data directory for {} database exists, but metadata file does not. \"\n+                                                     \"Probably you are trying to upgrade from version older than 20.7. \"\n+                                                     \"If so, you should upgrade through intermediate version.\", database_name);\n+}\n \n void loadMetadata(ContextMutablePtr context, const String & default_database_name)\n {\n@@ -118,43 +127,33 @@ void loadMetadata(ContextMutablePtr context, const String & default_database_nam\n         if (it->is_symlink())\n             continue;\n \n+        if (it->is_directory())\n+            continue;\n+\n         const auto current_file = it->path().filename().string();\n-        if (!it->is_directory())\n+\n+        /// TODO: DETACH DATABASE PERMANENTLY ?\n+        if (fs::path(current_file).extension() == \".sql\")\n         {\n-            /// TODO: DETACH DATABASE PERMANENTLY ?\n-            if (fs::path(current_file).extension() == \".sql\")\n+            String db_name = fs::path(current_file).stem();\n+            if (!isSystemOrInformationSchema(db_name))\n+                databases.emplace(unescapeForFileName(db_name), fs::path(path) / db_name);\n+        }\n+\n+        /// Temporary fails may be left from previous server runs.\n+        if (fs::path(current_file).extension() == \".tmp\")\n+        {\n+            LOG_WARNING(log, \"Removing temporary file {}\", it->path().string());\n+            try\n             {\n-                String db_name = fs::path(current_file).stem();\n-                if (!isSystemOrInformationSchema(db_name))\n-                    databases.emplace(unescapeForFileName(db_name), fs::path(path) / db_name);\n+                fs::remove(it->path());\n             }\n-\n-            /// Temporary fails may be left from previous server runs.\n-            if (fs::path(current_file).extension() == \".tmp\")\n+            catch (...)\n             {\n-                LOG_WARNING(log, \"Removing temporary file {}\", it->path().string());\n-                try\n-                {\n-                    fs::remove(it->path());\n-                }\n-                catch (...)\n-                {\n-                    /// It does not prevent server to startup.\n-                    tryLogCurrentException(log);\n-                }\n+                /// It does not prevent server to startup.\n+                tryLogCurrentException(log);\n             }\n-\n-            continue;\n         }\n-\n-        /// For '.svn', '.gitignore' directory and similar.\n-        if (current_file.at(0) == '.')\n-            continue;\n-\n-        if (isSystemOrInformationSchema(current_file))\n-            continue;\n-\n-        databases.emplace(unescapeForFileName(current_file), it->path().string());\n     }\n \n     /// clickhouse-local creates DatabaseMemory as default database by itself\n@@ -162,7 +161,10 @@ void loadMetadata(ContextMutablePtr context, const String & default_database_nam\n     bool create_default_db_if_not_exists = !default_database_name.empty();\n     bool metadata_dir_for_default_db_already_exists = databases.contains(default_database_name);\n     if (create_default_db_if_not_exists && !metadata_dir_for_default_db_already_exists)\n+    {\n+        checkUnsupportedVersion(context, default_database_name);\n         databases.emplace(default_database_name, std::filesystem::path(path) / escapeForFileName(default_database_name));\n+    }\n \n     TablesLoader::Databases loaded_databases;\n     for (const auto & [name, db_path] : databases)\n@@ -192,13 +194,14 @@ static void loadSystemDatabaseImpl(ContextMutablePtr context, const String & dat\n {\n     String path = context->getPath() + \"metadata/\" + database_name;\n     String metadata_file = path + \".sql\";\n-    if (fs::exists(fs::path(path)) || fs::exists(fs::path(metadata_file)))\n+    if (fs::exists(fs::path(metadata_file)))\n     {\n         /// 'has_force_restore_data_flag' is true, to not fail on loading query_log table, if it is corrupted.\n         loadDatabase(context, database_name, path, true);\n     }\n     else\n     {\n+        checkUnsupportedVersion(context, database_name);\n         /// Initialize system database manually\n         String database_create_query = \"CREATE DATABASE \";\n         database_create_query += database_name;\n@@ -208,6 +211,122 @@ static void loadSystemDatabaseImpl(ContextMutablePtr context, const String & dat\n     }\n }\n \n+static void convertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const DatabasePtr & database)\n+{\n+    /// It's kind of C++ script that creates temporary database with Atomic engine,\n+    /// moves all tables to it, drops old database and then renames new one to old name.\n+\n+    Poco::Logger * log = &Poco::Logger::get(\"loadMetadata\");\n+\n+    String name = database->getDatabaseName();\n+\n+    String tmp_name = fmt::format(\".tmp_convert.{}.{}\", name, thread_local_rng());\n+\n+    String name_quoted = backQuoteIfNeed(name);\n+    String tmp_name_quoted = backQuoteIfNeed(tmp_name);\n+\n+    LOG_INFO(log, \"Will convert database {} from Ordinary to Atomic\", name_quoted);\n+\n+    String create_database_query = fmt::format(\"CREATE DATABASE IF NOT EXISTS {}\", tmp_name_quoted);\n+    auto res = executeQuery(create_database_query, context, true);\n+    executeTrivialBlockIO(res, context);\n+    res = {};\n+    auto tmp_database = DatabaseCatalog::instance().getDatabase(tmp_name);\n+    assert(tmp_database->getEngineName() == \"Atomic\");\n+\n+    size_t num_tables = 0;\n+    for (auto iterator = database->getTablesIterator(context); iterator->isValid(); iterator->next())\n+    {\n+        ++num_tables;\n+        auto id = iterator->table()->getStorageID();\n+        id.database_name = tmp_name;\n+        iterator->table()->checkTableCanBeRenamed(id);\n+    }\n+\n+    LOG_INFO(log, \"Will move {} tables to {}\", num_tables, tmp_name_quoted);\n+\n+    for (auto iterator = database->getTablesIterator(context); iterator->isValid(); iterator->next())\n+    {\n+        auto id = iterator->table()->getStorageID();\n+        String qualified_quoted_name = id.getFullTableName();\n+        id.database_name = tmp_name;\n+        String tmp_qualified_quoted_name = id.getFullTableName();\n+\n+        String move_table_query = fmt::format(\"RENAME TABLE {} TO {}\", qualified_quoted_name, tmp_qualified_quoted_name);\n+        res = executeQuery(move_table_query, context, true);\n+        executeTrivialBlockIO(res, context);\n+        res = {};\n+    }\n+\n+    LOG_INFO(log, \"Moved all tables from {} to {}\", name_quoted, tmp_name_quoted);\n+\n+    if (!database->empty())\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Database {} is not empty after moving tables\", name_quoted);\n+\n+    String drop_query = fmt::format(\"DROP DATABASE {}\", name_quoted);\n+    res = executeQuery(drop_query, context, true);\n+    executeTrivialBlockIO(res, context);\n+    res = {};\n+\n+    String rename_query = fmt::format(\"RENAME DATABASE {} TO {}\", tmp_name_quoted, name_quoted);\n+    res = executeQuery(rename_query, context, true);\n+    executeTrivialBlockIO(res, context);\n+\n+    LOG_INFO(log, \"Finished database engine conversion of {}\", name_quoted);\n+}\n+\n+void maybeConvertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const DatabasePtr & database)\n+{\n+    if (database->getEngineName() != \"Ordinary\")\n+        return;\n+\n+    if (context->getSettingsRef().allow_deprecated_database_ordinary)\n+        return;\n+\n+    try\n+    {\n+        /// It's not quite correct to run DDL queries while database is not started up.\n+        startupSystemTables();\n+\n+        auto local_context = Context::createCopy(context);\n+        local_context->setSetting(\"check_table_dependencies\", false);\n+        convertOrdinaryDatabaseToAtomic(local_context, database);\n+\n+        auto new_database = DatabaseCatalog::instance().getDatabase(DatabaseCatalog::SYSTEM_DATABASE);\n+        UUID db_uuid = new_database->getUUID();\n+        std::vector<UUID> tables_uuids;\n+        for (auto iterator = new_database->getTablesIterator(context); iterator->isValid(); iterator->next())\n+            tables_uuids.push_back(iterator->uuid());\n+\n+        /// Reload database just in case (and update logger name)\n+        String detach_query = fmt::format(\"DETACH DATABASE {}\", backQuoteIfNeed(DatabaseCatalog::SYSTEM_DATABASE));\n+        auto res = executeQuery(detach_query, context, true);\n+        executeTrivialBlockIO(res, context);\n+        res = {};\n+\n+        /// Unlock UUID mapping, because it will be locked again on database reload.\n+        /// It's safe to do during metadata loading, because cleanup task is not started yet.\n+        DatabaseCatalog::instance().removeUUIDMappingFinally(db_uuid);\n+        for (const auto & uuid : tables_uuids)\n+            DatabaseCatalog::instance().removeUUIDMappingFinally(uuid);\n+\n+        loadSystemDatabaseImpl(context, DatabaseCatalog::SYSTEM_DATABASE, \"Atomic\");\n+        TablesLoader::Databases databases =\n+        {\n+            {DatabaseCatalog::SYSTEM_DATABASE, DatabaseCatalog::instance().getSystemDatabase()},\n+        };\n+        TablesLoader loader{context, databases, /* force_restore */ true, /* force_attach */ true};\n+        loader.loadTables();\n+\n+        /// Will startup tables usual way\n+    }\n+    catch (Exception & e)\n+    {\n+        e.addMessage(\"While trying to convert {} to Atomic\", database->getDatabaseName());\n+        throw;\n+    }\n+}\n+\n \n void startupSystemTables()\n {\ndiff --git a/src/Interpreters/loadMetadata.h b/src/Interpreters/loadMetadata.h\nindex e918b5f530c7..8dc332defc53 100644\n--- a/src/Interpreters/loadMetadata.h\n+++ b/src/Interpreters/loadMetadata.h\n@@ -19,4 +19,8 @@ void loadMetadata(ContextMutablePtr context, const String & default_database_nam\n /// so we startup system tables after all databases are loaded.\n void startupSystemTables();\n \n+/// Converts database with Ordinary engine to Atomic. Does nothing if database is not Ordinary.\n+/// Can be called only during server startup when there are no queries from users.\n+void maybeConvertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const DatabasePtr & database);\n+\n }\ndiff --git a/src/Parsers/ASTDropQuery.cpp b/src/Parsers/ASTDropQuery.cpp\nindex 9e815ee75deb..11c1dd4c47a5 100644\n--- a/src/Parsers/ASTDropQuery.cpp\n+++ b/src/Parsers/ASTDropQuery.cpp\n@@ -72,8 +72,8 @@ void ASTDropQuery::formatQueryImpl(const FormatSettings & settings, FormatState\n     if (permanently)\n         settings.ostr << \" PERMANENTLY\";\n \n-    if (no_delay)\n-        settings.ostr << (settings.hilite ? hilite_keyword : \"\") << \" NO DELAY\" << (settings.hilite ? hilite_none : \"\");\n+    if (sync)\n+        settings.ostr << (settings.hilite ? hilite_keyword : \"\") << \" SYNC\" << (settings.hilite ? hilite_none : \"\");\n }\n \n }\ndiff --git a/src/Parsers/ASTDropQuery.h b/src/Parsers/ASTDropQuery.h\nindex ef2b609fbac1..b4c96353a09b 100644\n--- a/src/Parsers/ASTDropQuery.h\n+++ b/src/Parsers/ASTDropQuery.h\n@@ -31,7 +31,7 @@ class ASTDropQuery : public ASTQueryWithTableAndOutput, public ASTQueryWithOnClu\n     /// Same as above\n     bool is_view{false};\n \n-    bool no_delay{false};\n+    bool sync{false};\n \n     // We detach the object permanently, so it will not be reattached back during server restart.\n     bool permanently{false};\ndiff --git a/src/Parsers/ParserDropQuery.cpp b/src/Parsers/ParserDropQuery.cpp\nindex e7263aa47f55..f40a39e6b2ff 100644\n--- a/src/Parsers/ParserDropQuery.cpp\n+++ b/src/Parsers/ParserDropQuery.cpp\n@@ -31,7 +31,7 @@ bool parseDropQuery(IParser::Pos & pos, ASTPtr & node, Expected & expected, cons\n     bool temporary = false;\n     bool is_dictionary = false;\n     bool is_view = false;\n-    bool no_delay = false;\n+    bool sync = false;\n     bool permanently = false;\n \n     if (s_database.ignore(pos, expected))\n@@ -83,7 +83,7 @@ bool parseDropQuery(IParser::Pos & pos, ASTPtr & node, Expected & expected, cons\n \n     /// actually for TRUNCATE NO DELAY / SYNC means nothing\n     if (s_no_delay.ignore(pos, expected) || s_sync.ignore(pos, expected))\n-        no_delay = true;\n+        sync = true;\n \n     auto query = std::make_shared<ASTDropQuery>();\n     node = query;\n@@ -93,7 +93,7 @@ bool parseDropQuery(IParser::Pos & pos, ASTPtr & node, Expected & expected, cons\n     query->temporary = temporary;\n     query->is_dictionary = is_dictionary;\n     query->is_view = is_view;\n-    query->no_delay = no_delay;\n+    query->sync = sync;\n     query->permanently = permanently;\n     query->database = database;\n     query->table = table;\ndiff --git a/src/Storages/IStorage.h b/src/Storages/IStorage.h\nindex a655da4473b4..6dd329db02bb 100644\n--- a/src/Storages/IStorage.h\n+++ b/src/Storages/IStorage.h\n@@ -396,7 +396,7 @@ class IStorage : public std::enable_shared_from_this<IStorage>, public TypePromo\n       */\n     virtual void drop() {}\n \n-    virtual void dropInnerTableIfAny(bool /* no_delay */, ContextPtr /* context */) {}\n+    virtual void dropInnerTableIfAny(bool /* sync */, ContextPtr /* context */) {}\n \n     /** Clear the table data and leave it empty.\n       * Must be called under exclusive lock (lockExclusively).\ndiff --git a/src/Storages/MergeTree/registerStorageMergeTree.cpp b/src/Storages/MergeTree/registerStorageMergeTree.cpp\nindex 73b9b364f7ff..e52a0fed6742 100644\n--- a/src/Storages/MergeTree/registerStorageMergeTree.cpp\n+++ b/src/Storages/MergeTree/registerStorageMergeTree.cpp\n@@ -304,12 +304,22 @@ static StoragePtr create(const StorageFactory::Arguments & args)\n                             arg_idx, e.message(), getMergeTreeVerboseHelp(is_extended_storage_def));\n         }\n     }\n+    else if (!args.attach && !args.getLocalContext()->getSettingsRef().allow_deprecated_syntax_for_merge_tree)\n+    {\n+        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"This syntax for *MergeTree engine is deprecated. \"\n+                                                   \"Use extended storage definition syntax with ORDER BY/PRIMARY KEY clause.\"\n+                                                   \"See also allow_deprecated_syntax_for_merge_tree setting.\");\n+    }\n \n     /// For Replicated.\n     String zookeeper_path;\n     String replica_name;\n     StorageReplicatedMergeTree::RenamingRestrictions renaming_restrictions = StorageReplicatedMergeTree::RenamingRestrictions::ALLOW_ANY;\n \n+    bool is_on_cluster = args.getLocalContext()->getClientInfo().query_kind == ClientInfo::QueryKind::SECONDARY_QUERY;\n+    bool is_replicated_database = args.getLocalContext()->getClientInfo().query_kind == ClientInfo::QueryKind::SECONDARY_QUERY &&\n+        DatabaseCatalog::instance().getDatabase(args.table_id.database_name)->getEngineName() == \"Replicated\";\n+\n     if (replicated)\n     {\n         bool has_arguments = arg_num + 2 <= arg_cnt;\n@@ -372,17 +382,11 @@ static StoragePtr create(const StorageFactory::Arguments & args)\n             throw Exception(\"Expected two string literal arguments: zookeeper_path and replica_name\", ErrorCodes::BAD_ARGUMENTS);\n \n         /// Allow implicit {uuid} macros only for zookeeper_path in ON CLUSTER queries\n-        bool is_on_cluster = args.getLocalContext()->getClientInfo().query_kind == ClientInfo::QueryKind::SECONDARY_QUERY;\n-        bool is_replicated_database = args.getLocalContext()->getClientInfo().query_kind == ClientInfo::QueryKind::SECONDARY_QUERY &&\n-                                      DatabaseCatalog::instance().getDatabase(args.table_id.database_name)->getEngineName() == \"Replicated\";\n         bool allow_uuid_macro = is_on_cluster || is_replicated_database || args.query.attach;\n \n         /// Unfold {database} and {table} macro on table creation, so table can be renamed.\n         if (!args.attach)\n         {\n-            if (is_replicated_database && !is_extended_storage_def)\n-                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Old syntax is not allowed for ReplicatedMergeTree tables in Replicated databases\");\n-\n             Macros::MacroExpansionInfo info;\n             /// NOTE: it's not recursive\n             info.expand_special_macros_only = true;\ndiff --git a/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.cpp b/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.cpp\nindex 190ffabe2c11..cc80d567d1da 100644\n--- a/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.cpp\n+++ b/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.cpp\n@@ -240,7 +240,7 @@ void StorageMaterializedPostgreSQL::shutdown()\n }\n \n \n-void StorageMaterializedPostgreSQL::dropInnerTableIfAny(bool no_delay, ContextPtr local_context)\n+void StorageMaterializedPostgreSQL::dropInnerTableIfAny(bool sync, ContextPtr local_context)\n {\n     /// If it is a table with database engine MaterializedPostgreSQL - return, because delition of\n     /// internal tables is managed there.\n@@ -252,7 +252,7 @@ void StorageMaterializedPostgreSQL::dropInnerTableIfAny(bool no_delay, ContextPt\n \n     auto nested_table = tryGetNested() != nullptr;\n     if (nested_table)\n-        InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind::Drop, getContext(), local_context, getNestedStorageID(), no_delay);\n+        InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind::Drop, getContext(), local_context, getNestedStorageID(), sync);\n }\n \n \ndiff --git a/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.h b/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.h\nindex bb3836a88530..f1eea33d4b0b 100644\n--- a/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.h\n+++ b/src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.h\n@@ -84,7 +84,7 @@ class StorageMaterializedPostgreSQL final : public IStorage, WithContext\n     void shutdown() override;\n \n     /// Used only for single MaterializedPostgreSQL storage.\n-    void dropInnerTableIfAny(bool no_delay, ContextPtr local_context) override;\n+    void dropInnerTableIfAny(bool sync, ContextPtr local_context) override;\n \n     NamesAndTypesList getVirtuals() const override;\n \ndiff --git a/src/Storages/StorageMaterializedView.cpp b/src/Storages/StorageMaterializedView.cpp\nindex d0685c263f84..2ece0af33599 100644\n--- a/src/Storages/StorageMaterializedView.cpp\n+++ b/src/Storages/StorageMaterializedView.cpp\n@@ -215,10 +215,10 @@ void StorageMaterializedView::drop()\n     dropInnerTableIfAny(true, getContext());\n }\n \n-void StorageMaterializedView::dropInnerTableIfAny(bool no_delay, ContextPtr local_context)\n+void StorageMaterializedView::dropInnerTableIfAny(bool sync, ContextPtr local_context)\n {\n     if (has_inner_table && tryGetTargetTable())\n-        InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind::Drop, getContext(), local_context, target_table_id, no_delay);\n+        InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind::Drop, getContext(), local_context, target_table_id, sync);\n }\n \n void StorageMaterializedView::truncate(const ASTPtr &, const StorageMetadataPtr &, ContextPtr local_context, TableExclusiveLockHolder &)\ndiff --git a/src/Storages/StorageMaterializedView.h b/src/Storages/StorageMaterializedView.h\nindex 8aec0313ecbd..0adf394876c3 100644\n--- a/src/Storages/StorageMaterializedView.h\n+++ b/src/Storages/StorageMaterializedView.h\n@@ -42,7 +42,7 @@ class StorageMaterializedView final : public IStorage, WithMutableContext\n     SinkToStoragePtr write(const ASTPtr & query, const StorageMetadataPtr & /*metadata_snapshot*/, ContextPtr context) override;\n \n     void drop() override;\n-    void dropInnerTableIfAny(bool no_delay, ContextPtr local_context) override;\n+    void dropInnerTableIfAny(bool sync, ContextPtr local_context) override;\n \n     void truncate(const ASTPtr &, const StorageMetadataPtr &, ContextPtr, TableExclusiveLockHolder &) override;\n \ndiff --git a/src/Storages/WindowView/StorageWindowView.cpp b/src/Storages/WindowView/StorageWindowView.cpp\nindex cfb198690740..d9780eb84462 100644\n--- a/src/Storages/WindowView/StorageWindowView.cpp\n+++ b/src/Storages/WindowView/StorageWindowView.cpp\n@@ -1606,7 +1606,7 @@ void StorageWindowView::drop()\n     dropInnerTableIfAny(true, getContext());\n }\n \n-void StorageWindowView::dropInnerTableIfAny(bool no_delay, ContextPtr local_context)\n+void StorageWindowView::dropInnerTableIfAny(bool sync, ContextPtr local_context)\n {\n     if (!std::exchange(has_inner_table, false))\n         return;\n@@ -1614,10 +1614,10 @@ void StorageWindowView::dropInnerTableIfAny(bool no_delay, ContextPtr local_cont\n     try\n     {\n         InterpreterDropQuery::executeDropQuery(\n-            ASTDropQuery::Kind::Drop, getContext(), local_context, inner_table_id, no_delay);\n+            ASTDropQuery::Kind::Drop, getContext(), local_context, inner_table_id, sync);\n \n         if (has_inner_target_table)\n-            InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind::Drop, getContext(), local_context, target_table_id, no_delay);\n+            InterpreterDropQuery::executeDropQuery(ASTDropQuery::Kind::Drop, getContext(), local_context, target_table_id, sync);\n     }\n     catch (...)\n     {\ndiff --git a/src/Storages/WindowView/StorageWindowView.h b/src/Storages/WindowView/StorageWindowView.h\nindex 86cc80ee8eaf..96c034b95907 100644\n--- a/src/Storages/WindowView/StorageWindowView.h\n+++ b/src/Storages/WindowView/StorageWindowView.h\n@@ -120,7 +120,7 @@ class StorageWindowView final : public IStorage, WithContext\n \n     void checkTableCanBeDropped() const override;\n \n-    void dropInnerTableIfAny(bool no_delay, ContextPtr context) override;\n+    void dropInnerTableIfAny(bool sync, ContextPtr context) override;\n \n     void drop() override;\n \n",
  "test_patch": "diff --git a/docker/test/stateful/run.sh b/docker/test/stateful/run.sh\nindex 5f55bb9fa21c..d77978c904b2 100755\n--- a/docker/test/stateful/run.sh\n+++ b/docker/test/stateful/run.sh\n@@ -120,6 +120,10 @@ function run_tests()\n         ADDITIONAL_OPTIONS+=('--replicated-database')\n     fi\n \n+    if [[ -n \"$USE_DATABASE_ORDINARY\" ]] && [[ \"$USE_DATABASE_ORDINARY\" -eq 1 ]]; then\n+        ADDITIONAL_OPTIONS+=('--db-engine=Ordinary')\n+    fi\n+\n     set +e\n     clickhouse-test -j 2 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \\\n         --skip 00168_parallel_processing_on_replicas \"${ADDITIONAL_OPTIONS[@]}\" \\\ndiff --git a/docker/test/stateless/run.sh b/docker/test/stateless/run.sh\nindex 52bf8a60669d..075f588cae30 100755\n--- a/docker/test/stateless/run.sh\n+++ b/docker/test/stateless/run.sh\n@@ -115,6 +115,10 @@ function run_tests()\n         ADDITIONAL_OPTIONS+=(\"$RUN_BY_HASH_TOTAL\")\n     fi\n \n+    if [[ -n \"$USE_DATABASE_ORDINARY\" ]] && [[ \"$USE_DATABASE_ORDINARY\" -eq 1 ]]; then\n+        ADDITIONAL_OPTIONS+=('--db-engine=Ordinary')\n+    fi\n+\n     set +e\n     clickhouse-test --testname --shard --zookeeper --check-zookeeper-session --hung-check --print-time \\\n             --test-runs \"$NUM_TRIES\" \"${ADDITIONAL_OPTIONS[@]}\" 2>&1 \\\ndiff --git a/docker/test/stress/run.sh b/docker/test/stress/run.sh\nindex f0f5d21c0b8e..119ea04080fb 100755\n--- a/docker/test/stress/run.sh\n+++ b/docker/test/stress/run.sh\n@@ -284,6 +284,11 @@ then\n \n     rm -rf /var/lib/clickhouse/*\n \n+    # Make BC check more funny by forcing Ordinary engine for system database\n+    # New version will try to convert it to Atomic on startup\n+    mkdir /var/lib/clickhouse/metadata\n+    echo \"ATTACH DATABASE system ENGINE=Ordinary\" > /var/lib/clickhouse/metadata/system.sql\n+\n     # Install previous release packages\n     install_packages previous_release_package_folder\n \ndiff --git a/tests/clickhouse-test b/tests/clickhouse-test\nindex 22c6816eec20..8744e8bf95bd 100755\n--- a/tests/clickhouse-test\n+++ b/tests/clickhouse-test\n@@ -1490,9 +1490,9 @@ def collect_build_flags(args):\n         result.append(BuildFlags.RELEASE)\n \n     value = clickhouse_execute(\n-        args, \"SELECT value FROM system.settings WHERE name = 'default_database_engine'\"\n+        args, \"SELECT value FROM system.settings WHERE name = 'allow_deprecated_database_ordinary'\"\n     )\n-    if value == b\"Ordinary\":\n+    if value == b\"1\":\n         result.append(BuildFlags.ORDINARY_DATABASE)\n \n     value = int(\ndiff --git a/tests/config/users.d/database_ordinary.xml b/tests/config/users.d/database_ordinary.xml\nindex b3b81ee25ffa..8ffd2f27a626 100644\n--- a/tests/config/users.d/database_ordinary.xml\n+++ b/tests/config/users.d/database_ordinary.xml\n@@ -1,7 +1,7 @@\n <clickhouse>\n     <profiles>\n         <default>\n-            <default_database_engine>Ordinary</default_database_engine>\n+            <allow_deprecated_database_ordinary>1</allow_deprecated_database_ordinary>\n         </default>\n     </profiles>\n </clickhouse>\ndiff --git a/tests/integration/helpers/cluster.py b/tests/integration/helpers/cluster.py\nindex e917e5a18855..0d32547358cb 100644\n--- a/tests/integration/helpers/cluster.py\n+++ b/tests/integration/helpers/cluster.py\n@@ -3390,14 +3390,6 @@ def restart_with_original_version(\n             ],\n             user=\"root\",\n         )\n-        self.exec_in_container(\n-            [\n-                \"bash\",\n-                \"-c\",\n-                \"cp /usr/share/clickhouse-odbc-bridge_fresh /usr/bin/clickhouse-odbc-bridge && chmod 777 /usr/bin/clickhouse\",\n-            ],\n-            user=\"root\",\n-        )\n         self.exec_in_container(\n             [\"bash\", \"-c\", \"{} --daemon\".format(self.clickhouse_start_command)],\n             user=str(os.getuid()),\n@@ -3411,7 +3403,11 @@ def restart_with_original_version(\n             self.wait_start(time_left)\n \n     def restart_with_latest_version(\n-        self, stop_start_wait_sec=300, callback_onstop=None, signal=15\n+        self,\n+        stop_start_wait_sec=300,\n+        callback_onstop=None,\n+        signal=15,\n+        fix_metadata=False,\n     ):\n         begin_time = time.time()\n         if not self.stay_alive:\n@@ -3458,14 +3454,23 @@ def restart_with_latest_version(\n                 \"echo 'restart_with_latest_version: From version' && /usr/share/clickhouse_original server --version && echo 'To version' /usr/share/clickhouse_fresh server --version\",\n             ]\n         )\n-        self.exec_in_container(\n-            [\n-                \"bash\",\n-                \"-c\",\n-                \"cp /usr/share/clickhouse-odbc-bridge_fresh /usr/bin/clickhouse-odbc-bridge && chmod 777 /usr/bin/clickhouse\",\n-            ],\n-            user=\"root\",\n-        )\n+        if fix_metadata:\n+            # Versions older than 20.7 might not create .sql file for system and default database\n+            # Create it manually if upgrading from older version\n+            self.exec_in_container(\n+                [\n+                    \"bash\",\n+                    \"-c\",\n+                    \"echo 'ATTACH DATABASE system ENGINE=Ordinary' > /var/lib/clickhouse/metadata/system.sql\",\n+                ],\n+            )\n+            self.exec_in_container(\n+                [\n+                    \"bash\",\n+                    \"-c\",\n+                    \"echo 'ATTACH DATABASE system ENGINE=Ordinary' > /var/lib/clickhouse/metadata/default.sql\",\n+                ],\n+            )\n         self.exec_in_container(\n             [\"bash\", \"-c\", \"{} --daemon\".format(self.clickhouse_start_command)],\n             user=str(os.getuid()),\ndiff --git a/tests/integration/test_atomic_drop_table/test.py b/tests/integration/test_atomic_drop_table/test.py\nindex 1fe88dde099c..6ffa60de7b52 100644\n--- a/tests/integration/test_atomic_drop_table/test.py\n+++ b/tests/integration/test_atomic_drop_table/test.py\n@@ -20,7 +20,8 @@ def start_cluster():\n     try:\n         cluster.start()\n         node1.query(\n-            \"CREATE DATABASE zktest ENGINE=Ordinary;\"\n+            \"CREATE DATABASE zktest ENGINE=Ordinary;\",\n+            settings={\"allow_deprecated_database_ordinary\": 1},\n         )  # Different behaviour with Atomic\n         node1.query(\n             \"\"\"\ndiff --git a/tests/integration/test_attach_partition_with_large_destination/test.py b/tests/integration/test_attach_partition_with_large_destination/test.py\nindex 0a4ab9fada13..a82e63bb7ba6 100644\n--- a/tests/integration/test_attach_partition_with_large_destination/test.py\n+++ b/tests/integration/test_attach_partition_with_large_destination/test.py\n@@ -34,7 +34,10 @@ def create_force_drop_flag(node):\n @pytest.mark.parametrize(\"engine\", [\"Ordinary\", \"Atomic\"])\n def test_attach_partition_with_large_destination(started_cluster, engine):\n     # Initialize\n-    node.query(\"CREATE DATABASE db ENGINE={}\".format(engine))\n+    node.query(\n+        \"CREATE DATABASE db ENGINE={}\".format(engine),\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n+    )\n     node.query(\n         \"CREATE TABLE db.destination (n UInt64) ENGINE=ReplicatedMergeTree('/test/destination', 'r1') ORDER BY n PARTITION BY n % 2\"\n     )\ndiff --git a/tests/integration/test_backup_restore/test.py b/tests/integration/test_backup_restore/test.py\nindex 905abef05b0c..193e638186ca 100644\n--- a/tests/integration/test_backup_restore/test.py\n+++ b/tests/integration/test_backup_restore/test.py\n@@ -15,7 +15,8 @@ def started_cluster():\n     try:\n         cluster.start()\n         instance.query(\n-            \"CREATE DATABASE test ENGINE = Ordinary\"\n+            \"CREATE DATABASE test ENGINE = Ordinary\",\n+            settings={\"allow_deprecated_database_ordinary\": 1},\n         )  # Different path in shadow/ with Atomic\n         instance.query(\"DROP TABLE IF EXISTS test.tbl\")\n         instance.query(\ndiff --git a/tests/integration/test_backup_with_other_granularity/test.py b/tests/integration/test_backup_with_other_granularity/test.py\nindex 9cb998fb5051..d30c45c3691a 100644\n--- a/tests/integration/test_backup_with_other_granularity/test.py\n+++ b/tests/integration/test_backup_with_other_granularity/test.py\n@@ -54,7 +54,7 @@ def test_backup_from_old_version(started_cluster):\n \n     node1.query(\"ALTER TABLE source_table FREEZE PARTITION tuple();\")\n \n-    node1.restart_with_latest_version()\n+    node1.restart_with_latest_version(fix_metadata=True)\n \n     node1.query(\n         \"CREATE TABLE dest_table (A Int64,  B String,  Y String) ENGINE = ReplicatedMergeTree('/test/dest_table1', '1')  ORDER BY tuple()\"\n@@ -107,7 +107,7 @@ def test_backup_from_old_version_setting(started_cluster):\n \n     node2.query(\"ALTER TABLE source_table FREEZE PARTITION tuple();\")\n \n-    node2.restart_with_latest_version()\n+    node2.restart_with_latest_version(fix_metadata=True)\n \n     node2.query(\n         \"CREATE TABLE dest_table (A Int64,  B String,  Y String) ENGINE = ReplicatedMergeTree('/test/dest_table2', '1')  ORDER BY tuple() SETTINGS enable_mixed_granularity_parts = 1\"\n@@ -163,7 +163,7 @@ def callback(n):\n             \"<clickhouse><merge_tree><enable_mixed_granularity_parts>1</enable_mixed_granularity_parts></merge_tree></clickhouse>\",\n         )\n \n-    node3.restart_with_latest_version(callback_onstop=callback)\n+    node3.restart_with_latest_version(callback_onstop=callback, fix_metadata=True)\n \n     node3.query(\n         \"CREATE TABLE dest_table (A Int64,  B String,  Y String) ENGINE = ReplicatedMergeTree('/test/dest_table3', '1')  ORDER BY tuple() SETTINGS enable_mixed_granularity_parts = 1\"\n@@ -202,7 +202,8 @@ def callback(n):\n \n def test_backup_and_alter(started_cluster):\n     node4.query(\n-        \"CREATE DATABASE test ENGINE=Ordinary\"\n+        \"CREATE DATABASE test ENGINE=Ordinary\",\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n     )  # Different path in shadow/ with Atomic\n \n     node4.query(\ndiff --git a/tests/integration/test_backward_compatibility/test_aggregate_function_state_avg.py b/tests/integration/test_backward_compatibility/test_aggregate_function_state_avg.py\nindex b3ad90112399..13dd28ee8af6 100644\n--- a/tests/integration/test_backward_compatibility/test_aggregate_function_state_avg.py\n+++ b/tests/integration/test_backward_compatibility/test_aggregate_function_state_avg.py\n@@ -71,7 +71,7 @@ def test_backward_compatability(start_cluster):\n \n     assert node1.query(\"SELECT avgMerge(x) FROM state\") == \"2.5\\n\"\n \n-    node1.restart_with_latest_version()\n+    node1.restart_with_latest_version(fix_metadata=True)\n \n     assert node1.query(\"SELECT avgMerge(x) FROM state\") == \"2.5\\n\"\n \ndiff --git a/tests/integration/test_backward_compatibility/test_convert_ordinary.py b/tests/integration/test_backward_compatibility/test_convert_ordinary.py\nnew file mode 100644\nindex 000000000000..59ceca23a51d\n--- /dev/null\n+++ b/tests/integration/test_backward_compatibility/test_convert_ordinary.py\n@@ -0,0 +1,77 @@\n+import pytest\n+from helpers.cluster import ClickHouseCluster\n+\n+cluster = ClickHouseCluster(__file__, name=\"convert_ordinary\")\n+node = cluster.add_instance(\n+    \"node\",\n+    image=\"yandex/clickhouse-server\",\n+    tag=\"19.17.8.54\",\n+    stay_alive=True,\n+    with_installed_binary=True,\n+)\n+\n+\n+@pytest.fixture(scope=\"module\")\n+def start_cluster():\n+    try:\n+        cluster.start()\n+        yield cluster\n+\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def q(query):\n+    return node.query(query, settings={\"log_queries\": 1})\n+\n+\n+def test_convert_system_db_to_atomic(start_cluster):\n+    q(\n+        \"CREATE TABLE t(date Date, id UInt32) ENGINE = MergeTree PARTITION BY toYYYYMM(date) ORDER BY id\"\n+    )\n+    q(\"INSERT INTO t VALUES (today(), 1)\")\n+    q(\"INSERT INTO t SELECT number % 1000, number FROM system.numbers LIMIT 1000000\")\n+\n+    assert \"1000001\\n\" == q(\"SELECT count() FROM t\")\n+    assert \"499999500001\\n\" == q(\"SELECT sum(id) FROM t\")\n+    assert \"1970-01-01\\t1000\\t499500000\\n1970-01-02\\t1000\\t499501000\\n\" == q(\n+        \"SELECT date, count(), sum(id) FROM t GROUP BY date ORDER BY date LIMIT 2\"\n+    )\n+    q(\"SYSTEM FLUSH LOGS\")\n+\n+    assert \"query_log\" in q(\"SHOW TABLES FROM system\")\n+    assert \"part_log\" in q(\"SHOW TABLES FROM system\")\n+    q(\"SYSTEM FLUSH LOGS\")\n+    assert \"1\\n\" == q(\"SELECT count() != 0 FROM system.query_log\")\n+    assert \"1\\n\" == q(\"SELECT count() != 0 FROM system.part_log\")\n+\n+    node.restart_with_latest_version(fix_metadata=True)\n+\n+    assert \"Ordinary\" in node.query(\"SHOW CREATE DATABASE default\")\n+    assert \"Atomic\" in node.query(\"SHOW CREATE DATABASE system\")\n+    assert \"query_log\" in node.query(\"SHOW TABLES FROM system\")\n+    assert \"part_log\" in node.query(\"SHOW TABLES FROM system\")\n+    node.query(\"SYSTEM FLUSH LOGS\")\n+\n+    assert \"query_log_0\" in node.query(\"SHOW TABLES FROM system\")\n+    assert \"part_log_0\" in node.query(\"SHOW TABLES FROM system\")\n+    assert \"1\\n\" == node.query(\"SELECT count() != 0 FROM system.query_log_0\")\n+    assert \"1\\n\" == node.query(\"SELECT count() != 0 FROM system.part_log_0\")\n+    assert \"1970-01-01\\t1000\\t499500000\\n1970-01-02\\t1000\\t499501000\\n\" == node.query(\n+        \"SELECT date, count(), sum(id) FROM t GROUP BY date ORDER BY date LIMIT 2\"\n+    )\n+    assert \"INFORMATION_SCHEMA\\ndefault\\ninformation_schema\\nsystem\\n\" == node.query(\n+        \"SELECT name FROM system.databases ORDER BY name\"\n+    )\n+\n+    errors_count = node.count_in_log(\"<Error>\")\n+    assert \"0\\n\" == errors_count or (\n+        \"1\\n\" == errors_count\n+        and \"1\\n\" == node.count_in_log(\"Can't receive Netlink response\")\n+    )\n+    assert \"0\\n\" == node.count_in_log(\"<Warning> Database\")\n+    errors_count = node.count_in_log(\"always include the lines below\")\n+    assert \"0\\n\" == errors_count or (\n+        \"1\\n\" == errors_count\n+        and \"1\\n\" == node.count_in_log(\"Can't receive Netlink response\")\n+    )\ndiff --git a/tests/integration/test_cluster_copier/configs/users.xml b/tests/integration/test_cluster_copier/configs/users.xml\nindex 492cf4d7ee60..2542642f6df7 100644\n--- a/tests/integration/test_cluster_copier/configs/users.xml\n+++ b/tests/integration/test_cluster_copier/configs/users.xml\n@@ -5,6 +5,7 @@\n             <log_queries>1</log_queries>\n             <!-- Just to test settings_pull -->\n             <max_rows_in_distinct>5</max_rows_in_distinct>\n+            <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n         </default>\n     </profiles>\n \ndiff --git a/tests/integration/test_cluster_copier/configs_three_nodes/users.xml b/tests/integration/test_cluster_copier/configs_three_nodes/users.xml\nindex ce3538a31b82..f017daff9746 100644\n--- a/tests/integration/test_cluster_copier/configs_three_nodes/users.xml\n+++ b/tests/integration/test_cluster_copier/configs_three_nodes/users.xml\n@@ -3,6 +3,7 @@\n     <profiles>\n         <default>\n             <log_queries>1</log_queries>\n+            <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n         </default>\n     </profiles>\n \ndiff --git a/tests/integration/test_cluster_copier/configs_two_nodes/users.xml b/tests/integration/test_cluster_copier/configs_two_nodes/users.xml\nindex ce3538a31b82..f017daff9746 100644\n--- a/tests/integration/test_cluster_copier/configs_two_nodes/users.xml\n+++ b/tests/integration/test_cluster_copier/configs_two_nodes/users.xml\n@@ -3,6 +3,7 @@\n     <profiles>\n         <default>\n             <log_queries>1</log_queries>\n+            <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n         </default>\n     </profiles>\n \ndiff --git a/tests/integration/test_config_substitutions/configs/config_allow_databases.xml b/tests/integration/test_config_substitutions/configs/config_allow_databases.xml\nindex 98008306787d..be727360dcf3 100644\n--- a/tests/integration/test_config_substitutions/configs/config_allow_databases.xml\n+++ b/tests/integration/test_config_substitutions/configs/config_allow_databases.xml\n@@ -1,4 +1,9 @@\n <clickhouse>\n+    <profiles>\n+        <default>\n+            <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n+        </default>\n+    </profiles>\n     <users>\n         <default>\n             <password></password>\ndiff --git a/tests/integration/test_cross_replication/test.py b/tests/integration/test_cross_replication/test.py\nindex 143b8823bf23..2a73acadafd8 100644\n--- a/tests/integration/test_cross_replication/test.py\n+++ b/tests/integration/test_cross_replication/test.py\n@@ -37,7 +37,7 @@ def started_cluster():\n CREATE DATABASE shard_{shard};\n \n CREATE TABLE shard_{shard}.replicated(date Date, id UInt32, shard_id UInt32)\n-    ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/replicated', '{replica}', date, id, 8192);\n+    ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/replicated', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id;\n                 \"\"\".format(\n                         shard=shard, replica=node.name\n                     )\ndiff --git a/tests/integration/test_default_compression_codec/test.py b/tests/integration/test_default_compression_codec/test.py\nindex 4af276b97282..5d033ac8f7ec 100644\n--- a/tests/integration/test_default_compression_codec/test.py\n+++ b/tests/integration/test_default_compression_codec/test.py\n@@ -421,7 +421,7 @@ def test_default_codec_version_update(start_cluster):\n     )\n \n     old_version = node3.query(\"SELECT version()\")\n-    node3.restart_with_latest_version()\n+    node3.restart_with_latest_version(fix_metadata=True)\n     new_version = node3.query(\"SELECT version()\")\n     logging.debug(f\"Updated from {old_version} to {new_version}\")\n     assert (\ndiff --git a/tests/integration/test_delayed_replica_failover/test.py b/tests/integration/test_delayed_replica_failover/test.py\nindex 387d6a12f482..a480ee3f2788 100644\n--- a/tests/integration/test_delayed_replica_failover/test.py\n+++ b/tests/integration/test_delayed_replica_failover/test.py\n@@ -32,7 +32,7 @@ def started_cluster():\n                 node.query(\n                     \"\"\"\n CREATE TABLE replicated (d Date, x UInt32) ENGINE =\n-    ReplicatedMergeTree('/clickhouse/tables/{shard}/replicated', '{instance}', d, d, 8192)\"\"\".format(\n+    ReplicatedMergeTree('/clickhouse/tables/{shard}/replicated', '{instance}') PARTITION BY toYYYYMM(d) ORDER BY d\"\"\".format(\n                         shard=shard, instance=node.name\n                     )\n                 )\ndiff --git a/tests/integration/test_dictionaries_dependency/test.py b/tests/integration/test_dictionaries_dependency/test.py\nindex f57d4e428133..2042db69fa2d 100644\n--- a/tests/integration/test_dictionaries_dependency/test.py\n+++ b/tests/integration/test_dictionaries_dependency/test.py\n@@ -16,7 +16,10 @@ def start_cluster():\n         for node in nodes:\n             node.query(\"CREATE DATABASE IF NOT EXISTS test\")\n             # Different internal dictionary name with Atomic\n-            node.query(\"CREATE DATABASE IF NOT EXISTS test_ordinary ENGINE=Ordinary\")\n+            node.query(\n+                \"CREATE DATABASE IF NOT EXISTS test_ordinary ENGINE=Ordinary\",\n+                settings={\"allow_deprecated_database_ordinary\": 1},\n+            )\n             node.query(\"CREATE DATABASE IF NOT EXISTS atest\")\n             node.query(\"CREATE DATABASE IF NOT EXISTS ztest\")\n             node.query(\"CREATE TABLE test.source(x UInt64, y UInt64) ENGINE=Log\")\ndiff --git a/tests/integration/test_distributed_ddl/configs/users.d/query_log.xml b/tests/integration/test_distributed_ddl/configs/users.d/query_log.xml\nindex 26db7f545142..ef8abbd91741 100644\n--- a/tests/integration/test_distributed_ddl/configs/users.d/query_log.xml\n+++ b/tests/integration/test_distributed_ddl/configs/users.d/query_log.xml\n@@ -3,6 +3,7 @@\n         <!-- Default profile settings. -->\n         <default>\n             <log_queries>1</log_queries>\n+            <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n         </default>\n     </profiles>\n </clickhouse>\ndiff --git a/tests/integration/test_distributed_ddl/configs_secure/users.d/query_log.xml b/tests/integration/test_distributed_ddl/configs_secure/users.d/query_log.xml\nindex 26db7f545142..ef8abbd91741 100644\n--- a/tests/integration/test_distributed_ddl/configs_secure/users.d/query_log.xml\n+++ b/tests/integration/test_distributed_ddl/configs_secure/users.d/query_log.xml\n@@ -3,6 +3,7 @@\n         <!-- Default profile settings. -->\n         <default>\n             <log_queries>1</log_queries>\n+            <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n         </default>\n     </profiles>\n </clickhouse>\ndiff --git a/tests/integration/test_distributed_ddl/test.py b/tests/integration/test_distributed_ddl/test.py\nindex 2789541b519d..85d0a5f0999d 100755\n--- a/tests/integration/test_distributed_ddl/test.py\n+++ b/tests/integration/test_distributed_ddl/test.py\n@@ -552,7 +552,9 @@ def test_replicated_without_arguments(test_cluster):\n     )\n \n     test_cluster.ddl_check_query(\n-        instance, \"CREATE DATABASE test_ordinary ON CLUSTER cluster ENGINE=Ordinary\"\n+        instance,\n+        \"CREATE DATABASE test_ordinary ON CLUSTER cluster ENGINE=Ordinary\",\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n     )\n     assert (\n         \"are supported only for ON CLUSTER queries with Atomic database engine\"\ndiff --git a/tests/integration/test_distributed_storage_configuration/test.py b/tests/integration/test_distributed_storage_configuration/test.py\nindex fa4e01bb7b37..950ce1034fe9 100644\n--- a/tests/integration/test_distributed_storage_configuration/test.py\n+++ b/tests/integration/test_distributed_storage_configuration/test.py\n@@ -20,7 +20,8 @@ def start_cluster():\n     try:\n         cluster.start()\n         node.query(\n-            \"CREATE DATABASE IF NOT EXISTS test ENGINE=Ordinary\"\n+            \"CREATE DATABASE IF NOT EXISTS test ENGINE=Ordinary\",\n+            settings={\"allow_deprecated_database_ordinary\": 1},\n         )  # Different paths with Atomic\n         yield cluster\n     finally:\ndiff --git a/tests/integration/test_extreme_deduplication/test.py b/tests/integration/test_extreme_deduplication/test.py\nindex 2c8772aad4e0..71f783d37c91 100644\n--- a/tests/integration/test_extreme_deduplication/test.py\n+++ b/tests/integration/test_extreme_deduplication/test.py\n@@ -40,7 +40,7 @@ def test_deduplication_window_in_seconds(started_cluster):\n     node1.query(\n         \"\"\"\n         CREATE TABLE simple ON CLUSTER test_cluster (date Date, id UInt32)\n-        ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/simple', '{replica}', date, id, 8192)\"\"\"\n+        ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/simple', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id\"\"\"\n     )\n \n     node.query(\"INSERT INTO simple VALUES (0, 0)\")\n@@ -77,7 +77,7 @@ def test_deduplication_works_in_case_of_intensive_inserts(started_cluster):\n     node1.query(\n         \"\"\"\n         CREATE TABLE simple ON CLUSTER test_cluster (date Date, id UInt32)\n-        ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/simple', '{replica}', date, id, 8192)\"\"\"\n+        ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/simple', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id\"\"\"\n     )\n \n     node1.query(\"INSERT INTO simple VALUES (0, 0)\")\ndiff --git a/tests/integration/test_filesystem_layout/test.py b/tests/integration/test_filesystem_layout/test.py\nindex 34e377e0ae4d..898bbc40eb97 100644\n--- a/tests/integration/test_filesystem_layout/test.py\n+++ b/tests/integration/test_filesystem_layout/test.py\n@@ -16,7 +16,10 @@ def started_cluster():\n \n \n def test_file_path_escaping(started_cluster):\n-    node.query(\"CREATE DATABASE IF NOT EXISTS test ENGINE = Ordinary\")\n+    node.query(\n+        \"CREATE DATABASE IF NOT EXISTS test ENGINE = Ordinary\",\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n+    )\n     node.query(\n         \"\"\"\n         CREATE TABLE test.`T.a_b,l-e!` (`~Id` UInt32)\ndiff --git a/tests/integration/test_force_drop_table/test.py b/tests/integration/test_force_drop_table/test.py\nindex c1eec1cd2778..ae6c7a1a3bf5 100644\n--- a/tests/integration/test_force_drop_table/test.py\n+++ b/tests/integration/test_force_drop_table/test.py\n@@ -33,7 +33,10 @@ def create_force_drop_flag(node):\n \n @pytest.mark.parametrize(\"engine\", [\"Ordinary\", \"Atomic\"])\n def test_drop_materialized_view(started_cluster, engine):\n-    node.query(\"CREATE DATABASE d ENGINE={}\".format(engine))\n+    node.query(\n+        \"CREATE DATABASE d ENGINE={}\".format(engine),\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n+    )\n     node.query(\n         \"CREATE TABLE d.rmt (n UInt64) ENGINE=ReplicatedMergeTree('/test/rmt', 'r1') ORDER BY n PARTITION BY n % 2\"\n     )\ndiff --git a/tests/integration/test_https_replication/test.py b/tests/integration/test_https_replication/test.py\nindex 4cf9f19b870d..301487aa6cf9 100644\n--- a/tests/integration/test_https_replication/test.py\n+++ b/tests/integration/test_https_replication/test.py\n@@ -19,7 +19,7 @@ def _fill_nodes(nodes, shard):\n                 CREATE DATABASE test;\n     \n                 CREATE TABLE test_table(date Date, id UInt32, dummy UInt32)\n-                ENGINE = ReplicatedMergeTree('/clickhouse/tables/test{shard}/replicated', '{replica}', date, id, 8192);\n+                ENGINE = ReplicatedMergeTree('/clickhouse/tables/test{shard}/replicated', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id;\n             \"\"\".format(\n                 shard=shard, replica=node.name\n             )\ndiff --git a/tests/integration/test_insert_into_distributed/test.py b/tests/integration/test_insert_into_distributed/test.py\nindex b8d94d2a0437..a52809f817c1 100644\n--- a/tests/integration/test_insert_into_distributed/test.py\n+++ b/tests/integration/test_insert_into_distributed/test.py\n@@ -52,7 +52,7 @@ def started_cluster():\n         )\n \n         remote.query(\n-            \"CREATE TABLE local2 (d Date, x UInt32, s String) ENGINE = MergeTree(d, x, 8192)\"\n+            \"CREATE TABLE local2 (d Date, x UInt32, s String) ENGINE = MergeTree PARTITION BY toYYYYMM(d) ORDER BY x\"\n         )\n         instance_test_inserts_batching.query(\n             \"\"\"\n@@ -61,7 +61,7 @@ def started_cluster():\n         )\n \n         instance_test_inserts_local_cluster.query(\n-            \"CREATE TABLE local (d Date, x UInt32) ENGINE = MergeTree(d, x, 8192)\"\n+            \"CREATE TABLE local (d Date, x UInt32) ENGINE = MergeTree PARTITION BY toYYYYMM(d) ORDER BY x\"\n         )\n         instance_test_inserts_local_cluster.query(\n             \"\"\"\n@@ -71,12 +71,12 @@ def started_cluster():\n \n         node1.query(\n             \"\"\"\n-CREATE TABLE replicated(date Date, id UInt32) ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/replicated', 'node1', date, id, 8192)\n+CREATE TABLE replicated(date Date, id UInt32) ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/replicated', 'node1') PARTITION BY toYYYYMM(date) ORDER BY id\n \"\"\"\n         )\n         node2.query(\n             \"\"\"\n-CREATE TABLE replicated(date Date, id UInt32) ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/replicated', 'node2', date, id, 8192)\n+CREATE TABLE replicated(date Date, id UInt32) ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/replicated', 'node2') PARTITION BY toYYYYMM(date) ORDER BY id\n \"\"\"\n         )\n \n@@ -94,12 +94,12 @@ def started_cluster():\n \n         shard1.query(\n             \"\"\"\n-CREATE TABLE low_cardinality (d Date, x UInt32, s LowCardinality(String)) ENGINE = MergeTree(d, x, 8192)\"\"\"\n+CREATE TABLE low_cardinality (d Date, x UInt32, s LowCardinality(String)) ENGINE = MergeTree PARTITION BY toYYYYMM(d) ORDER BY x\"\"\"\n         )\n \n         shard2.query(\n             \"\"\"\n-CREATE TABLE low_cardinality (d Date, x UInt32, s LowCardinality(String)) ENGINE = MergeTree(d, x, 8192)\"\"\"\n+CREATE TABLE low_cardinality (d Date, x UInt32, s LowCardinality(String)) ENGINE = MergeTree PARTITION BY toYYYYMM(d) ORDER BY x\"\"\"\n         )\n \n         shard1.query(\n@@ -143,7 +143,7 @@ def started_cluster():\n \n         node2.query(\n             \"\"\"\n-CREATE TABLE single_replicated(date Date, id UInt32) ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/single_replicated', 'node2', date, id, 8192)\n+CREATE TABLE single_replicated(date Date, id UInt32) ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/single_replicated', 'node2') PARTITION BY toYYYYMM(date) ORDER BY id\n \"\"\"\n         )\n \n@@ -228,11 +228,11 @@ def test_inserts_batching(started_cluster):\n     # 4. Full batch of inserts after ALTER (that have different block structure).\n     # 5. What was left to insert with the column structure before ALTER.\n     expected = \"\"\"\\\n-20000101_20000101_1_1_0\\t[1]\n-20000101_20000101_2_2_0\\t[2,3,4]\n-20000101_20000101_3_3_0\\t[5,6,7]\n-20000101_20000101_4_4_0\\t[10,11,12]\n-20000101_20000101_5_5_0\\t[8,9]\n+200001_1_1_0\\t[1]\n+200001_2_2_0\\t[2,3,4]\n+200001_3_3_0\\t[5,6,7]\n+200001_4_4_0\\t[10,11,12]\n+200001_5_5_0\\t[8,9]\n \"\"\"\n     assert TSV(result) == TSV(expected)\n \ndiff --git a/tests/integration/test_insert_into_distributed_sync_async/test.py b/tests/integration/test_insert_into_distributed_sync_async/test.py\nindex e0c454feee64..12423cc47472 100755\n--- a/tests/integration/test_insert_into_distributed_sync_async/test.py\n+++ b/tests/integration/test_insert_into_distributed_sync_async/test.py\n@@ -23,7 +23,7 @@ def started_cluster():\n         for node in (node1, node2):\n             node.query(\n                 \"\"\"\n-CREATE TABLE local_table(date Date, val UInt64) ENGINE = MergeTree(date, (date, val), 8192);\n+CREATE TABLE local_table(date Date, val UInt64) ENGINE = MergeTree() PARTITION BY toYYYYMM(date) ORDER BY (date, val);\n \"\"\"\n             )\n \ndiff --git a/tests/integration/test_insert_into_distributed_through_materialized_view/configs/enable_distributed_inserts_batching.xml b/tests/integration/test_insert_into_distributed_through_materialized_view/configs/enable_distributed_inserts_batching.xml\nindex de0c930b8ab3..295d1c8d3ccd 100644\n--- a/tests/integration/test_insert_into_distributed_through_materialized_view/configs/enable_distributed_inserts_batching.xml\n+++ b/tests/integration/test_insert_into_distributed_through_materialized_view/configs/enable_distributed_inserts_batching.xml\n@@ -3,6 +3,7 @@\n         <default>\n             <distributed_directory_monitor_batch_inserts>1</distributed_directory_monitor_batch_inserts>\n             <min_insert_block_size_rows>3</min_insert_block_size_rows>\n+            <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n         </default>\n     </profiles>\n </clickhouse>\ndiff --git a/tests/integration/test_insert_into_distributed_through_materialized_view/test.py b/tests/integration/test_insert_into_distributed_through_materialized_view/test.py\nindex 7c2ce9f05f2b..a5f92002450a 100644\n--- a/tests/integration/test_insert_into_distributed_through_materialized_view/test.py\n+++ b/tests/integration/test_insert_into_distributed_through_materialized_view/test.py\n@@ -44,7 +44,8 @@ def started_cluster():\n         )\n \n         remote.query(\n-            \"CREATE TABLE local2 (d Date, x UInt32, s String) ENGINE = MergeTree(d, x, 8192)\"\n+            \"CREATE TABLE local2 (d Date, x UInt32, s String) ENGINE = MergeTree(d, x, 8192)\",\n+            settings={\"allow_deprecated_syntax_for_merge_tree\": 1},\n         )\n         instance_test_inserts_batching.query(\n             \"\"\"\n@@ -65,7 +66,8 @@ def started_cluster():\n             \"CREATE MATERIALIZED VIEW local_view to distributed_on_local AS SELECT d,x FROM local_source\"\n         )\n         instance_test_inserts_local_cluster.query(\n-            \"CREATE TABLE local (d Date, x UInt32) ENGINE = MergeTree(d, x, 8192)\"\n+            \"CREATE TABLE local (d Date, x UInt32) ENGINE = MergeTree(d, x, 8192)\",\n+            settings={\"allow_deprecated_syntax_for_merge_tree\": 1},\n         )\n         instance_test_inserts_local_cluster.query(\n             \"\"\"\ndiff --git a/tests/integration/test_keeper_multinode_blocade_leader/test.py b/tests/integration/test_keeper_multinode_blocade_leader/test.py\nindex c2d4039e1223..d6d01a5d0a64 100644\n--- a/tests/integration/test_keeper_multinode_blocade_leader/test.py\n+++ b/tests/integration/test_keeper_multinode_blocade_leader/test.py\n@@ -95,7 +95,10 @@ def test_blocade_leader(started_cluster):\n         wait_nodes()\n         try:\n             for i, node in enumerate([node1, node2, node3]):\n-                node.query(\"CREATE DATABASE IF NOT EXISTS ordinary ENGINE=Ordinary\")\n+                node.query(\n+                    \"CREATE DATABASE IF NOT EXISTS ordinary ENGINE=Ordinary\",\n+                    settings={\"allow_deprecated_database_ordinary\": 1},\n+                )\n                 node.query(\n                     \"CREATE TABLE IF NOT EXISTS ordinary.t1 (value UInt64) ENGINE = ReplicatedMergeTree('/clickhouse/t1', '{}') ORDER BY tuple()\".format(\n                         i + 1\n@@ -296,7 +299,10 @@ def test_blocade_leader_twice(started_cluster):\n         wait_nodes()\n         try:\n             for i, node in enumerate([node1, node2, node3]):\n-                node.query(\"CREATE DATABASE IF NOT EXISTS ordinary ENGINE=Ordinary\")\n+                node.query(\n+                    \"CREATE DATABASE IF NOT EXISTS ordinary ENGINE=Ordinary\",\n+                    settings={\"allow_deprecated_database_ordinary\": 1},\n+                )\n                 node.query(\n                     \"CREATE TABLE IF NOT EXISTS ordinary.t2 (value UInt64) ENGINE = ReplicatedMergeTree('/clickhouse/t2', '{}') ORDER BY tuple()\".format(\n                         i + 1\ndiff --git a/tests/integration/test_materialized_mysql_database/configs/users.xml b/tests/integration/test_materialized_mysql_database/configs/users.xml\nindex 4b7f5a1b109f..0e116f115fea 100644\n--- a/tests/integration/test_materialized_mysql_database/configs/users.xml\n+++ b/tests/integration/test_materialized_mysql_database/configs/users.xml\n@@ -3,7 +3,6 @@\n     <profiles>\n         <default>\n             <allow_experimental_database_materialized_mysql>1</allow_experimental_database_materialized_mysql>\n-            <default_database_engine>Atomic</default_database_engine>\n             <allow_introspection_functions>1</allow_introspection_functions>\n             <optimize_on_insert>0</optimize_on_insert>\n         </default>\ndiff --git a/tests/integration/test_materialized_mysql_database/configs/users_disable_bytes_settings.xml b/tests/integration/test_materialized_mysql_database/configs/users_disable_bytes_settings.xml\nindex f590ebff6b41..a00b6ca6b9ad 100644\n--- a/tests/integration/test_materialized_mysql_database/configs/users_disable_bytes_settings.xml\n+++ b/tests/integration/test_materialized_mysql_database/configs/users_disable_bytes_settings.xml\n@@ -3,7 +3,6 @@\n     <profiles>\n         <default>\n             <allow_experimental_database_materialized_mysql>1</allow_experimental_database_materialized_mysql>\n-            <default_database_engine>Atomic</default_database_engine>\n             <external_storage_max_read_rows>1</external_storage_max_read_rows>\n             <external_storage_max_read_bytes>0</external_storage_max_read_bytes>\n         </default>\ndiff --git a/tests/integration/test_materialized_mysql_database/configs/users_disable_rows_settings.xml b/tests/integration/test_materialized_mysql_database/configs/users_disable_rows_settings.xml\nindex e0fa0a9097b6..3a7cc2537e59 100644\n--- a/tests/integration/test_materialized_mysql_database/configs/users_disable_rows_settings.xml\n+++ b/tests/integration/test_materialized_mysql_database/configs/users_disable_rows_settings.xml\n@@ -3,7 +3,6 @@\n     <profiles>\n         <default>\n             <allow_experimental_database_materialized_mysql>1</allow_experimental_database_materialized_mysql>\n-            <default_database_engine>Atomic</default_database_engine>\n             <external_storage_max_read_rows>0</external_storage_max_read_rows>\n             <external_storage_max_read_bytes>1</external_storage_max_read_bytes>\n         </default>\ndiff --git a/tests/integration/test_merge_tree_empty_parts/test.py b/tests/integration/test_merge_tree_empty_parts/test.py\nindex 7ca275e96de0..57bf49e68038 100644\n--- a/tests/integration/test_merge_tree_empty_parts/test.py\n+++ b/tests/integration/test_merge_tree_empty_parts/test.py\n@@ -25,7 +25,7 @@ def started_cluster():\n def test_empty_parts_alter_delete(started_cluster):\n     node1.query(\n         \"CREATE TABLE empty_parts_delete (d Date, key UInt64, value String) \\\n-        ENGINE = ReplicatedMergeTree('/clickhouse/tables/empty_parts_delete', 'r1', d, key, 8192)\"\n+        ENGINE = ReplicatedMergeTree('/clickhouse/tables/empty_parts_delete', 'r1') PARTITION BY toYYYYMM(d) ORDER BY key\"\n     )\n \n     node1.query(\"INSERT INTO empty_parts_delete VALUES (toDate('2020-10-10'), 1, 'a')\")\n@@ -44,7 +44,7 @@ def test_empty_parts_alter_delete(started_cluster):\n def test_empty_parts_summing(started_cluster):\n     node1.query(\n         \"CREATE TABLE empty_parts_summing (d Date, key UInt64, value Int64) \\\n-        ENGINE = ReplicatedSummingMergeTree('/clickhouse/tables/empty_parts_summing', 'r1', d, key, 8192)\"\n+        ENGINE = ReplicatedSummingMergeTree('/clickhouse/tables/empty_parts_summing', 'r1') PARTITION BY toYYYYMM(d) ORDER BY key\"\n     )\n \n     node1.query(\"INSERT INTO empty_parts_summing VALUES (toDate('2020-10-10'), 1, 1)\")\ndiff --git a/tests/integration/test_merge_tree_s3_restore/test.py b/tests/integration/test_merge_tree_s3_restore/test.py\nindex e6ca4a78c255..f4acc4ac91ef 100644\n--- a/tests/integration/test_merge_tree_s3_restore/test.py\n+++ b/tests/integration/test_merge_tree_s3_restore/test.py\n@@ -93,7 +93,8 @@ def create_table(\n     node.query(\n         \"CREATE DATABASE IF NOT EXISTS s3 ENGINE = {engine}\".format(\n             engine=\"Atomic\" if db_atomic else \"Ordinary\"\n-        )\n+        ),\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n     )\n \n     create_table_statement = \"\"\"\ndiff --git a/tests/integration/test_mutations_with_merge_tree/test.py b/tests/integration/test_mutations_with_merge_tree/test.py\nindex d1843017b9f6..7831cde7dea6 100644\n--- a/tests/integration/test_mutations_with_merge_tree/test.py\n+++ b/tests/integration/test_mutations_with_merge_tree/test.py\n@@ -17,7 +17,7 @@ def started_cluster():\n     try:\n         cluster.start()\n         instance_test_mutations.query(\n-            \"\"\"CREATE TABLE test_mutations_with_ast_elements(date Date, a UInt64, b String) ENGINE = MergeTree(date, (a, date), 8192)\"\"\"\n+            \"\"\"CREATE TABLE test_mutations_with_ast_elements(date Date, a UInt64, b String) ENGINE = MergeTree PARTITION BY toYYYYMM(date) ORDER BY (a, date)\"\"\"\n         )\n         instance_test_mutations.query(\n             \"\"\"INSERT INTO test_mutations_with_ast_elements SELECT '2019-07-29' AS date, 1, toString(number) FROM numbers(1) SETTINGS force_index_by_date = 0, force_primary_key = 0\"\"\"\ndiff --git a/tests/integration/test_partition/test.py b/tests/integration/test_partition/test.py\nindex b396b58df101..f3df66631a5c 100644\n--- a/tests/integration/test_partition/test.py\n+++ b/tests/integration/test_partition/test.py\n@@ -14,7 +14,8 @@ def started_cluster():\n     try:\n         cluster.start()\n         q(\n-            \"CREATE DATABASE test ENGINE = Ordinary\"\n+            \"CREATE DATABASE test ENGINE = Ordinary\",\n+            settings={\"allow_deprecated_database_ordinary\": 1},\n         )  # Different path in shadow/ with Atomic\n \n         yield cluster\ndiff --git a/tests/integration/test_polymorphic_parts/configs/users.d/not_optimize_count.xml b/tests/integration/test_polymorphic_parts/configs/users.d/not_optimize_count.xml\nindex 7f8036c4f879..c654cf0791a5 100644\n--- a/tests/integration/test_polymorphic_parts/configs/users.d/not_optimize_count.xml\n+++ b/tests/integration/test_polymorphic_parts/configs/users.d/not_optimize_count.xml\n@@ -2,6 +2,7 @@\n     <profiles>\n         <default>\n             <optimize_trivial_count_query>0</optimize_trivial_count_query>\n+            <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n         </default>\n     </profiles>\n </clickhouse>\ndiff --git a/tests/integration/test_polymorphic_parts/test.py b/tests/integration/test_polymorphic_parts/test.py\nindex edd65ec002c7..32b5e531fa8e 100644\n--- a/tests/integration/test_polymorphic_parts/test.py\n+++ b/tests/integration/test_polymorphic_parts/test.py\n@@ -66,7 +66,8 @@ def create_tables_old_format(name, nodes, shard):\n             ENGINE = ReplicatedMergeTree('/clickhouse/tables/test/{shard}/{name}', '{repl}', date, id, 64)\n             \"\"\".format(\n                 name=name, shard=shard, repl=i\n-            )\n+            ),\n+            settings={\"allow_deprecated_syntax_for_merge_tree\": 1},\n         )\n \n \n@@ -495,7 +496,7 @@ def test_polymorphic_parts_diff_versions_2(start_cluster_diff_versions):\n     with pytest.raises(Exception):\n         node_old.query(\"SYSTEM SYNC REPLICA polymorphic_table_2\", timeout=3)\n \n-    node_old.restart_with_latest_version()\n+    node_old.restart_with_latest_version(fix_metadata=True)\n \n     node_old.query(\"SYSTEM SYNC REPLICA polymorphic_table_2\", timeout=20)\n \n@@ -720,7 +721,8 @@ def check_parts_type(parts_num):\n \n def test_polymorphic_parts_index(start_cluster):\n     node1.query(\n-        \"CREATE DATABASE test_index ENGINE=Ordinary\"\n+        \"CREATE DATABASE test_index ENGINE=Ordinary\",\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n     )  # Different paths with Atomic\n     node1.query(\n         \"\"\"\ndiff --git a/tests/integration/test_random_inserts/test.py b/tests/integration/test_random_inserts/test.py\nindex 4d6aaa9276d3..9ac0c5b024ca 100644\n--- a/tests/integration/test_random_inserts/test.py\n+++ b/tests/integration/test_random_inserts/test.py\n@@ -44,7 +44,7 @@ def test_random_inserts(started_cluster):\n     node1.query(\n         \"\"\"\n         CREATE TABLE simple ON CLUSTER test_cluster (date Date, i UInt32, s String)\n-        ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/simple', '{replica}', date, i, 8192)\"\"\"\n+        ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/simple', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY i\"\"\"\n     )\n \n     with PartitionManager() as pm_random_drops:\ndiff --git a/tests/integration/test_replace_partition/test.py b/tests/integration/test_replace_partition/test.py\nindex 7ce79d9aca8a..579b22286b90 100644\n--- a/tests/integration/test_replace_partition/test.py\n+++ b/tests/integration/test_replace_partition/test.py\n@@ -20,13 +20,13 @@ def _fill_nodes(nodes, shard):\n                 CREATE DATABASE test;\n \n                 CREATE TABLE real_table(date Date, id UInt32, dummy UInt32)\n-                ENGINE = MergeTree(date, id, 8192);\n+                ENGINE = MergeTree PARTITION BY toYYYYMM(date) ORDER BY id;\n \n                 CREATE TABLE other_table(date Date, id UInt32, dummy UInt32)\n-                ENGINE = MergeTree(date, id, 8192);\n+                ENGINE = MergeTree PARTITION BY toYYYYMM(date) ORDER BY id;\n \n                 CREATE TABLE test_table(date Date, id UInt32, dummy UInt32)\n-                ENGINE = ReplicatedMergeTree('/clickhouse/tables/test{shard}/replicated', '{replica}', date, id, 8192);\n+                ENGINE = ReplicatedMergeTree('/clickhouse/tables/test{shard}/replicated', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id;\n             \"\"\".format(\n                 shard=shard, replica=node.name\n             )\ndiff --git a/tests/integration/test_replicated_database/test.py b/tests/integration/test_replicated_database/test.py\nindex 92c109974e14..11ca0d2f9620 100644\n--- a/tests/integration/test_replicated_database/test.py\n+++ b/tests/integration/test_replicated_database/test.py\n@@ -96,13 +96,16 @@ def test_create_replicated_table(started_cluster):\n         \"Explicit zookeeper_path and replica_name are specified\"\n         in main_node.query_and_get_error(\n             \"CREATE TABLE testdb.replicated_table (d Date, k UInt64, i32 Int32) \"\n-            \"ENGINE=ReplicatedMergeTree('/test/tmp', 'r', d, k, 8192);\"\n+            \"ENGINE=ReplicatedMergeTree('/test/tmp', 'r') ORDER BY k PARTITION BY toYYYYMM(d);\"\n         )\n     )\n \n-    assert \"Old syntax is not allowed\" in main_node.query_and_get_error(\n-        \"CREATE TABLE testdb.replicated_table (d Date, k UInt64, i32 Int32) \"\n-        \"ENGINE=ReplicatedMergeTree('/test/tmp/{shard}', '{replica}', d, k, 8192);\"\n+    assert (\n+        \"This syntax for *MergeTree engine is deprecated\"\n+        in main_node.query_and_get_error(\n+            \"CREATE TABLE testdb.replicated_table (d Date, k UInt64, i32 Int32) \"\n+            \"ENGINE=ReplicatedMergeTree('/test/tmp/{shard}', '{replica}', d, k, 8192);\"\n+        )\n     )\n \n     main_node.query(\n@@ -393,7 +396,7 @@ def test_alters_from_different_replicas(started_cluster):\n     main_node.query(\n         \"CREATE TABLE testdb.concurrent_test \"\n         \"(CounterID UInt32, StartDate Date, UserID UInt32, VisitID UInt32, NestedColumn Nested(A UInt8, S String), ToDrop UInt32) \"\n-        \"ENGINE = MergeTree(StartDate, intHash32(UserID), (CounterID, StartDate, intHash32(UserID), VisitID), 8192);\"\n+        \"ENGINE = MergeTree PARTITION BY toYYYYMM(StartDate) ORDER BY (CounterID, StartDate, intHash32(UserID), VisitID);\"\n     )\n \n     main_node.query(\n@@ -443,7 +446,7 @@ def test_alters_from_different_replicas(started_cluster):\n         \"    `Added0` UInt32,\\\\n    `Added1` UInt32,\\\\n    `Added2` UInt32,\\\\n    `AddedNested1.A` Array(UInt32),\\\\n\"\n         \"    `AddedNested1.B` Array(UInt64),\\\\n    `AddedNested1.C` Array(String),\\\\n    `AddedNested2.A` Array(UInt32),\\\\n\"\n         \"    `AddedNested2.B` Array(UInt64)\\\\n)\\\\n\"\n-        \"ENGINE = MergeTree(StartDate, intHash32(UserID), (CounterID, StartDate, intHash32(UserID), VisitID), 8192)\"\n+        \"ENGINE = MergeTree\\\\nPARTITION BY toYYYYMM(StartDate)\\\\nORDER BY (CounterID, StartDate, intHash32(UserID), VisitID)\\\\nSETTINGS index_granularity = 8192\"\n     )\n \n     assert_create_query([main_node, competing_node], \"testdb.concurrent_test\", expected)\ndiff --git a/tests/integration/test_replicated_merge_tree_compatibility/test.py b/tests/integration/test_replicated_merge_tree_compatibility/test.py\nindex 00367daad331..eb2b14ffb1a6 100644\n--- a/tests/integration/test_replicated_merge_tree_compatibility/test.py\n+++ b/tests/integration/test_replicated_merge_tree_compatibility/test.py\n@@ -52,7 +52,10 @@ def test_replicated_merge_tree_defaults_compatibility(started_cluster):\n     \"\"\"\n \n     for node in (node1, node2):\n-        node.query(\"CREATE DATABASE test ENGINE = Ordinary\")\n+        node.query(\n+            \"CREATE DATABASE test ENGINE = Ordinary\",\n+            settings={\"allow_deprecated_database_ordinary\": 1},\n+        )\n         node.query(create_query.format(replica=node.name))\n \n     node1.query(\"DETACH TABLE test.table\")\ndiff --git a/tests/integration/test_replicated_merge_tree_s3_restore/test.py b/tests/integration/test_replicated_merge_tree_s3_restore/test.py\nindex 904bcfa42801..d743dedbdde3 100644\n--- a/tests/integration/test_replicated_merge_tree_s3_restore/test.py\n+++ b/tests/integration/test_replicated_merge_tree_s3_restore/test.py\n@@ -76,7 +76,8 @@ def create_table(node, table_name, schema, attach=False, db_atomic=False, uuid=\"\n         \"CREATE DATABASE IF NOT EXISTS s3 {on_cluster} ENGINE = {engine}\".format(\n             engine=\"Atomic\" if db_atomic else \"Ordinary\",\n             on_cluster=\"ON CLUSTER '{cluster}'\",\n-        )\n+        ),\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n     )\n \n     create_table_statement = \"\"\"\ndiff --git a/tests/integration/test_replication_credentials/test.py b/tests/integration/test_replication_credentials/test.py\nindex e5313cb6bd4a..79588fcd38bc 100644\n--- a/tests/integration/test_replication_credentials/test.py\n+++ b/tests/integration/test_replication_credentials/test.py\n@@ -10,7 +10,7 @@ def _fill_nodes(nodes, shard):\n             \"\"\"\n                 CREATE DATABASE test;\n                 CREATE TABLE test_table(date Date, id UInt32, dummy UInt32)\n-                ENGINE = ReplicatedMergeTree('/clickhouse/tables/test{shard}/replicated', '{replica}', date, id, 8192);\n+                ENGINE = ReplicatedMergeTree('/clickhouse/tables/test{shard}/replicated', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id;\n             \"\"\".format(\n                 shard=shard, replica=node.name\n             )\ndiff --git a/tests/integration/test_send_request_to_leader_replica/test.py b/tests/integration/test_send_request_to_leader_replica/test.py\nindex 60df18bf7d39..b56e1315672d 100644\n--- a/tests/integration/test_send_request_to_leader_replica/test.py\n+++ b/tests/integration/test_send_request_to_leader_replica/test.py\n@@ -40,7 +40,7 @@ def started_cluster():\n             node.query(\n                 \"\"\"\n             CREATE TABLE sometable(date Date, id UInt32, value Int32)\n-    ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/sometable', '{replica}', date, id, 8192);\n+    ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/sometable', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id;\n                 \"\"\".format(\n                     replica=node.name\n                 ),\n@@ -51,7 +51,7 @@ def started_cluster():\n             node.query(\n                 \"\"\"\n             CREATE TABLE someothertable(date Date, id UInt32, value Int32)\n-    ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/someothertable', '{replica}', date, id, 8192);\n+    ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/someothertable', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id;\n                 \"\"\".format(\n                     replica=node.name\n                 ),\ndiff --git a/tests/integration/test_server_initialization/clickhouse_path/metadata/default.sql b/tests/integration/test_server_initialization/clickhouse_path/metadata/default.sql\nnew file mode 100644\nindex 000000000000..9fae1d577266\n--- /dev/null\n+++ b/tests/integration/test_server_initialization/clickhouse_path/metadata/default.sql\n@@ -0,0 +1,1 @@\n+ATTACH DATABASE default ENGINE=Ordinary\n\\ No newline at end of file\ndiff --git a/tests/integration/test_system_merges/test.py b/tests/integration/test_system_merges/test.py\nindex 775706f4df67..b908ba0eb330 100644\n--- a/tests/integration/test_system_merges/test.py\n+++ b/tests/integration/test_system_merges/test.py\n@@ -26,9 +26,13 @@ def started_cluster():\n     try:\n         cluster.start()\n         node1.query(\n-            \"CREATE DATABASE test ENGINE=Ordinary\"\n+            \"CREATE DATABASE test ENGINE=Ordinary\",\n+            settings={\"allow_deprecated_database_ordinary\": 1},\n         )  # Different paths with Atomic\n-        node2.query(\"CREATE DATABASE test ENGINE=Ordinary\")\n+        node2.query(\n+            \"CREATE DATABASE test ENGINE=Ordinary\",\n+            settings={\"allow_deprecated_database_ordinary\": 1},\n+        )\n         yield cluster\n \n     finally:\ndiff --git a/tests/integration/test_union_header/test.py b/tests/integration/test_union_header/test.py\nindex f883057c1d83..2e7f6cb399a2 100644\n--- a/tests/integration/test_union_header/test.py\n+++ b/tests/integration/test_union_header/test.py\n@@ -27,7 +27,7 @@ def started_cluster():\n                 log_type UInt32,\n                 account_id String\n             )\n-            ENGINE = MergeTree(event_date, (event_time, account_id), 8192);\n+            ENGINE = MergeTree PARTITION BY toYYYYMM(event_date) ORDER BY (event_time, account_id);\n             \"\"\"\n             )\n \ndiff --git a/tests/integration/test_version_update_after_mutation/test.py b/tests/integration/test_version_update_after_mutation/test.py\nindex 2971cbc97929..a21186bba8d5 100644\n--- a/tests/integration/test_version_update_after_mutation/test.py\n+++ b/tests/integration/test_version_update_after_mutation/test.py\n@@ -58,8 +58,8 @@ def test_mutate_and_upgrade(start_cluster):\n \n     node2.query(\"DETACH TABLE mt\")  # stop being leader\n     node1.query(\"DETACH TABLE mt\")  # stop being leader\n-    node1.restart_with_latest_version(signal=9)\n-    node2.restart_with_latest_version(signal=9)\n+    node1.restart_with_latest_version(signal=9, fix_metadata=True)\n+    node2.restart_with_latest_version(signal=9, fix_metadata=True)\n \n     # After hard restart table can be in readonly mode\n     exec_query_with_retry(\n@@ -111,7 +111,7 @@ def test_upgrade_while_mutation(start_cluster):\n     node3.query(\"ALTER TABLE mt1 DELETE WHERE id % 2 == 0\")\n \n     node3.query(\"DETACH TABLE mt1\")  # stop being leader\n-    node3.restart_with_latest_version(signal=9)\n+    node3.restart_with_latest_version(signal=9, fix_metadata=True)\n \n     # checks for readonly\n     exec_query_with_retry(node3, \"OPTIMIZE TABLE mt1\", sleep_time=5, retry_count=60)\ndiff --git a/tests/integration/test_zookeeper_config/test.py b/tests/integration/test_zookeeper_config/test.py\nindex d3d90ca0d4f6..65f82c2286b1 100644\n--- a/tests/integration/test_zookeeper_config/test.py\n+++ b/tests/integration/test_zookeeper_config/test.py\n@@ -48,7 +48,7 @@ def test_chroot_with_same_root(started_cluster):\n         node.query(\n             \"\"\"\n         CREATE TABLE simple (date Date, id UInt32)\n-        ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/simple', '{replica}', date, id, 8192);\n+        ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/simple', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id;\n         \"\"\".format(\n                 replica=node.name\n             )\n@@ -68,7 +68,7 @@ def test_chroot_with_different_root(started_cluster):\n         node.query(\n             \"\"\"\n         CREATE TABLE simple_different (date Date, id UInt32)\n-        ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/simple_different', '{replica}', date, id, 8192);\n+        ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/simple_different', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id;\n         \"\"\".format(\n                 replica=node.name\n             )\ndiff --git a/tests/integration/test_zookeeper_config/test_password.py b/tests/integration/test_zookeeper_config/test_password.py\nindex 580b426db6fd..71f059b3277c 100644\n--- a/tests/integration/test_zookeeper_config/test_password.py\n+++ b/tests/integration/test_zookeeper_config/test_password.py\n@@ -35,7 +35,7 @@ def test_identity(started_cluster):\n     node1.query(\n         \"\"\"\n     CREATE TABLE simple (date Date, id UInt32)\n-    ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/simple', '{replica}', date, id, 8192);\n+    ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/simple', '{replica}') PARTITION BY toYYYYMM(date) ORDER BY id;\n     \"\"\".format(\n             replica=node1.name\n         )\n@@ -45,6 +45,6 @@ def test_identity(started_cluster):\n         node2.query(\n             \"\"\"\n         CREATE TABLE simple (date Date, id UInt32)\n-        ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/simple', '1', date, id, 8192);\n+        ENGINE = ReplicatedMergeTree('/clickhouse/tables/0/simple', '1') PARTITION BY toYYYYMM(date) ORDER BY id;\n         \"\"\"\n         )\ndiff --git a/tests/performance/merge_table_streams.xml b/tests/performance/merge_table_streams.xml\nindex efeb4547f379..1e053c987389 100644\n--- a/tests/performance/merge_table_streams.xml\n+++ b/tests/performance/merge_table_streams.xml\n@@ -1,6 +1,7 @@\n <test>\n <settings>\n     <max_threads>5</max_threads>\n+    <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n </settings>\n \n <!-- Create four empty tables. We will test select from Merge table involving one real table and four empty tables. \ndiff --git a/tests/performance/parallel_final.xml b/tests/performance/parallel_final.xml\nindex ca84ed52a046..d7ea0240105e 100644\n--- a/tests/performance/parallel_final.xml\n+++ b/tests/performance/parallel_final.xml\n@@ -4,6 +4,7 @@\n         <max_partitions_per_insert_block>1024</max_partitions_per_insert_block>\n         <max_insert_threads>1</max_insert_threads>\n         <max_memory_usage>20G</max_memory_usage>\n+        <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n     </settings>\n \n     <substitutions>\ndiff --git a/tests/performance/scalar2.xml b/tests/performance/scalar2.xml\nindex eb4275366462..7a122dbec952 100644\n--- a/tests/performance/scalar2.xml\n+++ b/tests/performance/scalar2.xml\n@@ -1,4 +1,8 @@\n <test>\n+    <settings>\n+        <allow_deprecated_syntax_for_merge_tree>1</allow_deprecated_syntax_for_merge_tree>\n+    </settings>\n+\n     <create_query>CREATE TABLE tbl0 (`ds` Date, `x1` String, `x2` UInt32, `x3` UInt32, `x4` UInt32, `bm` AggregateFunction(groupBitmap, UInt32)) ENGINE = MergeTree PARTITION BY (ds, x1) ORDER BY (x2, x3, x4) SETTINGS index_granularity = 1</create_query>\n \n     <create_query>CREATE TABLE tbl (`ds` Date, `y1` UInt32, `x4` UInt32, `y2` UInt32, `y3` UInt32, `bm` AggregateFunction(groupBitmap, UInt32), `y4` UInt32 DEFAULT 0) ENGINE = MergeTree PARTITION BY (ds) ORDER BY (x4, y2, y3) SETTINGS index_granularity = 8192, max_parts_in_total = 10000000</create_query>\ndiff --git a/tests/queries/0_stateless/00030_alter_table.sql b/tests/queries/0_stateless/00030_alter_table.sql\nindex 5fc45575a4a6..fb9b3de40678 100644\n--- a/tests/queries/0_stateless/00030_alter_table.sql\n+++ b/tests/queries/0_stateless/00030_alter_table.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS alter_test;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE alter_test (CounterID UInt32, StartDate Date, UserID UInt32, VisitID UInt32, NestedColumn Nested(A UInt8, S String), ToDrop UInt32) ENGINE = MergeTree(StartDate, intHash32(UserID), (CounterID, StartDate, intHash32(UserID), VisitID), 8192);\n \n INSERT INTO alter_test VALUES (1, '2014-01-01', 2, 3, [1,2,3], ['a','b','c'], 4);\ndiff --git a/tests/queries/0_stateless/00043_summing_empty_part.sql b/tests/queries/0_stateless/00043_summing_empty_part.sql\nindex 68fc4b5b1c45..40cecabf3781 100644\n--- a/tests/queries/0_stateless/00043_summing_empty_part.sql\n+++ b/tests/queries/0_stateless/00043_summing_empty_part.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS empty_summing;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE empty_summing (d Date, k UInt64, v Int8) ENGINE=SummingMergeTree(d, k, 8192);\n \n INSERT INTO empty_summing VALUES ('2015-01-01', 1, 10);\ndiff --git a/tests/queries/0_stateless/00046_stored_aggregates_simple.sql b/tests/queries/0_stateless/00046_stored_aggregates_simple.sql\nindex 8b1ef5ba48dd..2a4ee9fa5d3a 100644\n--- a/tests/queries/0_stateless/00046_stored_aggregates_simple.sql\n+++ b/tests/queries/0_stateless/00046_stored_aggregates_simple.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS stored_aggregates;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE stored_aggregates\n (\n     d Date,\ndiff --git a/tests/queries/0_stateless/00047_stored_aggregates_complex.sql b/tests/queries/0_stateless/00047_stored_aggregates_complex.sql\nindex 63728f131b02..2e416f91d5de 100644\n--- a/tests/queries/0_stateless/00047_stored_aggregates_complex.sql\n+++ b/tests/queries/0_stateless/00047_stored_aggregates_complex.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS stored_aggregates;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE stored_aggregates\n (\n \td\tDate,\ndiff --git a/tests/queries/0_stateless/00048_a_stored_aggregates_merge.sql b/tests/queries/0_stateless/00048_a_stored_aggregates_merge.sql\nindex 0138a75c19ab..0213ebf46d61 100644\n--- a/tests/queries/0_stateless/00048_a_stored_aggregates_merge.sql\n+++ b/tests/queries/0_stateless/00048_a_stored_aggregates_merge.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS stored_aggregates;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE stored_aggregates\n (\n     d   Date,\ndiff --git a/tests/queries/0_stateless/00048_b_stored_aggregates_merge.sql b/tests/queries/0_stateless/00048_b_stored_aggregates_merge.sql\nindex 79617692ebd7..708794eabff1 100644\n--- a/tests/queries/0_stateless/00048_b_stored_aggregates_merge.sql\n+++ b/tests/queries/0_stateless/00048_b_stored_aggregates_merge.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS stored_aggregates;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE stored_aggregates\n (\n \td\tDate,\ndiff --git a/tests/queries/0_stateless/00061_merge_tree_alter.sql b/tests/queries/0_stateless/00061_merge_tree_alter.sql\nindex 822386baa472..ee5694518d9f 100644\n--- a/tests/queries/0_stateless/00061_merge_tree_alter.sql\n+++ b/tests/queries/0_stateless/00061_merge_tree_alter.sql\n@@ -1,6 +1,7 @@\n -- Tags: no-backward-compatibility-check\n \n DROP TABLE IF EXISTS alter_00061;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE alter_00061 (d Date, k UInt64, i32 Int32) ENGINE=MergeTree(d, k, 8192);\n \n INSERT INTO alter_00061 VALUES ('2015-01-01', 10, 42);\ndiff --git a/tests/queries/0_stateless/00062_replicated_merge_tree_alter_zookeeper_long.sql b/tests/queries/0_stateless/00062_replicated_merge_tree_alter_zookeeper_long.sql\nindex e8d1a713c21a..4475421d36f5 100644\n--- a/tests/queries/0_stateless/00062_replicated_merge_tree_alter_zookeeper_long.sql\n+++ b/tests/queries/0_stateless/00062_replicated_merge_tree_alter_zookeeper_long.sql\n@@ -6,6 +6,7 @@ DROP TABLE IF EXISTS replicated_alter2;\n \n SET replication_alter_partitions_sync = 2;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE replicated_alter1 (d Date, k UInt64, i32 Int32) ENGINE=ReplicatedMergeTree('/clickhouse/tables/{database}/test_00062/alter', 'r1', d, k, 8192);\n CREATE TABLE replicated_alter2 (d Date, k UInt64, i32 Int32) ENGINE=ReplicatedMergeTree('/clickhouse/tables/{database}/test_00062/alter', 'r2', d, k, 8192);\n \ndiff --git a/tests/queries/0_stateless/00079_defaulted_columns.sql b/tests/queries/0_stateless/00079_defaulted_columns.sql\nindex 617dc2435c48..04dfb7057d2a 100644\n--- a/tests/queries/0_stateless/00079_defaulted_columns.sql\n+++ b/tests/queries/0_stateless/00079_defaulted_columns.sql\n@@ -13,6 +13,7 @@ drop table defaulted;\n \n create table defaulted (col1 Int8, col2 UInt64 default (SELECT dummy+99 from system.one)) engine=Memory; --{serverError 116}\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table defaulted (payload String, date materialized today(), key materialized 0 * rand()) engine=MergeTree(date, key, 8192);\n desc table defaulted;\n insert into defaulted (payload) values ('hello clickhouse');\ndiff --git a/tests/queries/0_stateless/00083_create_merge_tree_zookeeper_long.sql b/tests/queries/0_stateless/00083_create_merge_tree_zookeeper_long.sql\nindex 3418d093f709..583fc6d58268 100644\n--- a/tests/queries/0_stateless/00083_create_merge_tree_zookeeper_long.sql\n+++ b/tests/queries/0_stateless/00083_create_merge_tree_zookeeper_long.sql\n@@ -33,6 +33,7 @@ DROP TABLE IF EXISTS replicated_summing_merge_tree_with_sampling_with_list_of_co\n DROP TABLE IF EXISTS replicated_aggregating_merge_tree_with_sampling;\n \n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE merge_tree\n \t(d Date, a String, b UInt8, x String, y Int8, z UInt32) ENGINE = MergeTree(d, (a, b), 111);\n CREATE TABLE collapsing_merge_tree\ndiff --git a/tests/queries/0_stateless/00084_summing_merge_tree.sql b/tests/queries/0_stateless/00084_summing_merge_tree.sql\nindex 5be1371fbcc6..429fde5c2b56 100644\n--- a/tests/queries/0_stateless/00084_summing_merge_tree.sql\n+++ b/tests/queries/0_stateless/00084_summing_merge_tree.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS summing_merge_tree;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE summing_merge_tree (d Date, a String, x UInt32, y UInt64, z Float64) ENGINE = SummingMergeTree(d, a, 8192);\n \n INSERT INTO summing_merge_tree VALUES ('2000-01-01', 'Hello', 1, 2, 3);\ndiff --git a/tests/queries/0_stateless/00090_union_race_conditions_1.sh b/tests/queries/0_stateless/00090_union_race_conditions_1.sh\nindex 241436369b18..f7483b741c42 100755\n--- a/tests/queries/0_stateless/00090_union_race_conditions_1.sh\n+++ b/tests/queries/0_stateless/00090_union_race_conditions_1.sh\n@@ -10,6 +10,7 @@ set -o pipefail\n \n echo \"\n     DROP TABLE IF EXISTS two_blocks;\n+    set allow_deprecated_syntax_for_merge_tree=1;\n     CREATE TABLE two_blocks (d Date) ENGINE = MergeTree(d, d, 1);\n     INSERT INTO two_blocks VALUES ('2000-01-01');\n     INSERT INTO two_blocks VALUES ('2000-01-02');\ndiff --git a/tests/queries/0_stateless/00098_shard_i_union_all.sql b/tests/queries/0_stateless/00098_shard_i_union_all.sql\nindex 5151f9ad0e5b..58db30a8f9a9 100644\n--- a/tests/queries/0_stateless/00098_shard_i_union_all.sql\n+++ b/tests/queries/0_stateless/00098_shard_i_union_all.sql\n@@ -3,6 +3,7 @@\n DROP TABLE IF EXISTS report1;\n DROP TABLE IF EXISTS report2;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE report1(id UInt32, event_date Date, priority UInt32, description String) ENGINE = MergeTree(event_date, intHash32(id), (id, event_date, intHash32(id)), 8192);\n CREATE TABLE report2(id UInt32, event_date Date, priority UInt32, description String) ENGINE = MergeTree(event_date, intHash32(id), (id, event_date, intHash32(id)), 8192);\n \ndiff --git a/tests/queries/0_stateless/00101_materialized_views_and_insert_without_explicit_database.sql b/tests/queries/0_stateless/00101_materialized_views_and_insert_without_explicit_database.sql\nindex b05b49ba33a4..95d460326016 100644\n--- a/tests/queries/0_stateless/00101_materialized_views_and_insert_without_explicit_database.sql\n+++ b/tests/queries/0_stateless/00101_materialized_views_and_insert_without_explicit_database.sql\n@@ -8,6 +8,7 @@ DROP TABLE IF EXISTS test_table;\n DROP TABLE IF EXISTS test_view;\n DROP TABLE IF EXISTS test_view_filtered;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test_table (EventDate Date, CounterID UInt32,  UserID UInt64,  EventTime DateTime('America/Los_Angeles'), UTCEventTime DateTime('UTC')) ENGINE = MergeTree(EventDate, CounterID, 8192);\n CREATE MATERIALIZED VIEW test_view (Rows UInt64,  MaxHitTime DateTime('America/Los_Angeles')) ENGINE = Memory AS SELECT count() AS Rows, max(UTCEventTime) AS MaxHitTime FROM test_table;\n CREATE MATERIALIZED VIEW test_view_filtered (EventDate Date, CounterID UInt32) ENGINE = Memory POPULATE AS SELECT CounterID, EventDate FROM test_table WHERE EventDate < '2013-01-01';\ndiff --git a/tests/queries/0_stateless/00121_drop_column_zookeeper.sql b/tests/queries/0_stateless/00121_drop_column_zookeeper.sql\nindex fd32f3d32d2d..f62f11c60fde 100644\n--- a/tests/queries/0_stateless/00121_drop_column_zookeeper.sql\n+++ b/tests/queries/0_stateless/00121_drop_column_zookeeper.sql\n@@ -2,6 +2,7 @@\n -- Tag no-replicated-database: Old syntax is not allowed\n \n DROP TABLE IF EXISTS alter_00121;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE alter_00121 (d Date, x UInt8) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/test/alter_00121/t1', 'r1', d, (d), 8192);\n \n INSERT INTO alter_00121 VALUES ('2014-01-01', 1);\ndiff --git a/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql b/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql\nindex e29a166c1eed..901b818cbc06 100644\n--- a/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql\n+++ b/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql\n@@ -4,6 +4,7 @@ SET allow_experimental_parallel_reading_from_replicas = 0;\n SET max_parallel_replicas = 2;\n DROP TABLE IF EXISTS report;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE report(id UInt32, event_date Date, priority UInt32, description String) ENGINE = MergeTree(event_date, intHash32(id), (id, event_date, intHash32(id)), 8192);\n \n INSERT INTO report(id,event_date,priority,description) VALUES (1, '2015-01-01', 1, 'foo')(2, '2015-02-01', 2, 'bar')(3, '2015-03-01', 3, 'foo')(4, '2015-04-01', 4, 'bar')(5, '2015-05-01', 5, 'foo');\ndiff --git a/tests/queries/0_stateless/00140_prewhere_column_order.sql b/tests/queries/0_stateless/00140_prewhere_column_order.sql\nindex d949b6f780b2..61c2fbcf39cf 100644\n--- a/tests/queries/0_stateless/00140_prewhere_column_order.sql\n+++ b/tests/queries/0_stateless/00140_prewhere_column_order.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS prewhere;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE prewhere (d Date, a String, b String) ENGINE = MergeTree(d, d, 8192);\n INSERT INTO prewhere VALUES ('2015-01-01', 'hello', 'world');\n \ndiff --git a/tests/queries/0_stateless/00141_parse_timestamp_as_datetime.sql b/tests/queries/0_stateless/00141_parse_timestamp_as_datetime.sql\nindex 4780884ca02d..dbd251f878c7 100644\n--- a/tests/queries/0_stateless/00141_parse_timestamp_as_datetime.sql\n+++ b/tests/queries/0_stateless/00141_parse_timestamp_as_datetime.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS default;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE default (d Date DEFAULT toDate(t), t DateTime) ENGINE = MergeTree(d, t, 8192);\n INSERT INTO default (t) VALUES ('1234567890');\n SELECT toStartOfMonth(d), toUInt32(t) FROM default;\ndiff --git a/tests/queries/0_stateless/00146_summing_merge_tree_nested_map.sql b/tests/queries/0_stateless/00146_summing_merge_tree_nested_map.sql\nindex ab9e8c9b177e..e759fbd85d4a 100644\n--- a/tests/queries/0_stateless/00146_summing_merge_tree_nested_map.sql\n+++ b/tests/queries/0_stateless/00146_summing_merge_tree_nested_map.sql\n@@ -1,5 +1,6 @@\n drop table if exists nested_map;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table nested_map (d default today(), k UInt64, payload default rand(), SomeMap Nested(ID UInt32, Num Int64)) engine=SummingMergeTree(d, k, 8192);\n \n insert into nested_map (k, `SomeMap.ID`, `SomeMap.Num`) values (0,[1],[100]),(1,[1],[100]),(2,[1],[100]),(3,[1,2],[100,150]);\ndiff --git a/tests/queries/0_stateless/00147_alter_nested_default.sql b/tests/queries/0_stateless/00147_alter_nested_default.sql\nindex 54c99545364a..070204aef659 100644\n--- a/tests/queries/0_stateless/00147_alter_nested_default.sql\n+++ b/tests/queries/0_stateless/00147_alter_nested_default.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS alter_00147;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE alter_00147 (d Date DEFAULT toDate('2015-01-01'), n Nested(x String)) ENGINE = MergeTree(d, d, 8192);\n \n INSERT INTO alter_00147 (`n.x`) VALUES (['Hello', 'World']);\ndiff --git a/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.sql b/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.sql\nindex eab6b9da4651..649c09dbbf17 100644\n--- a/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.sql\n+++ b/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.sql\n@@ -2,6 +2,7 @@ drop table if exists summing_merge_tree_aggregate_function;\n drop table if exists summing_merge_tree_null;\n \n ---- partition merge\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table summing_merge_tree_aggregate_function (\n     d Date,\n     k UInt64,\n@@ -29,6 +30,7 @@ select count() from summing_merge_tree_aggregate_function;\n drop table summing_merge_tree_aggregate_function;\n \n ---- sum + uniq + uniqExact\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table summing_merge_tree_aggregate_function (\n     d materialized today(),\n     k UInt64,\ndiff --git a/tests/queries/0_stateless/00148_summing_merge_tree_nested_map_multiple_values.sql b/tests/queries/0_stateless/00148_summing_merge_tree_nested_map_multiple_values.sql\nindex 68c27cd726fa..7c5757cd526f 100644\n--- a/tests/queries/0_stateless/00148_summing_merge_tree_nested_map_multiple_values.sql\n+++ b/tests/queries/0_stateless/00148_summing_merge_tree_nested_map_multiple_values.sql\n@@ -1,5 +1,6 @@\n drop table if exists nested_map_multiple_values;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table nested_map_multiple_values (d materialized today(), k UInt64, payload materialized rand(), SomeMap Nested(ID UInt32, Num1 Int64, Num2 Float64)) engine=SummingMergeTree(d, k, 8192);\n \n insert into nested_map_multiple_values values (0,[1],[100],[1.0]),(1,[1],[100],[1.0]),(2,[1],[100],[1.0]),(3,[1,2],[100,150],[1.0,1.5]);\ndiff --git a/tests/queries/0_stateless/00155_long_merges.sh b/tests/queries/0_stateless/00155_long_merges.sh\nindex 15ad0892a42c..83d89c57cfaa 100755\n--- a/tests/queries/0_stateless/00155_long_merges.sh\n+++ b/tests/queries/0_stateless/00155_long_merges.sh\n@@ -11,10 +11,10 @@ function create {\n     $CLICKHOUSE_CLIENT --query=\"DROP TABLE IF EXISTS aggregating_00155\"\n     $CLICKHOUSE_CLIENT --query=\"DROP TABLE IF EXISTS replacing_00155\"\n \n-    $CLICKHOUSE_CLIENT --query=\"CREATE TABLE summing_00155 (d Date DEFAULT today(), x UInt64, s UInt64 DEFAULT 1) ENGINE = SummingMergeTree(d, x, 8192)\"\n-    $CLICKHOUSE_CLIENT --query=\"CREATE TABLE collapsing_00155 (d Date DEFAULT today(), x UInt64, s Int8 DEFAULT 1) ENGINE = CollapsingMergeTree(d, x, 8192, s)\"\n-    $CLICKHOUSE_CLIENT --query=\"CREATE TABLE aggregating_00155 (d Date DEFAULT today(), x UInt64, s AggregateFunction(sum, UInt64)) ENGINE = AggregatingMergeTree(d, x, 8192)\"\n-    $CLICKHOUSE_CLIENT --query=\"CREATE TABLE replacing_00155 (d Date DEFAULT today(), x UInt64, s Int8 DEFAULT 1, v UInt64) ENGINE = ReplacingMergeTree(d, (x), 8192, v)\"\n+    $CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 --query=\"CREATE TABLE summing_00155 (d Date DEFAULT today(), x UInt64, s UInt64 DEFAULT 1) ENGINE = SummingMergeTree(d, x, 8192)\"\n+    $CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 --query=\"CREATE TABLE collapsing_00155 (d Date DEFAULT today(), x UInt64, s Int8 DEFAULT 1) ENGINE = CollapsingMergeTree(d, x, 8192, s)\"\n+    $CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 --query=\"CREATE TABLE aggregating_00155 (d Date DEFAULT today(), x UInt64, s AggregateFunction(sum, UInt64)) ENGINE = AggregatingMergeTree(d, x, 8192)\"\n+    $CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 --query=\"CREATE TABLE replacing_00155 (d Date DEFAULT today(), x UInt64, s Int8 DEFAULT 1, v UInt64) ENGINE = ReplacingMergeTree(d, (x), 8192, v)\"\n }\n \n \ndiff --git a/tests/queries/0_stateless/00168_buffer_defaults.sql b/tests/queries/0_stateless/00168_buffer_defaults.sql\nindex 8e0008adf4de..ce1dea8aaa89 100644\n--- a/tests/queries/0_stateless/00168_buffer_defaults.sql\n+++ b/tests/queries/0_stateless/00168_buffer_defaults.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS mt_00168;\n DROP TABLE IF EXISTS mt_00168_buffer;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE mt_00168 (EventDate Date, UTCEventTime DateTime, MoscowEventDate Date DEFAULT toDate(UTCEventTime)) ENGINE = MergeTree(EventDate, UTCEventTime, 8192);\n CREATE TABLE mt_00168_buffer AS mt_00168 ENGINE = Buffer(currentDatabase(), mt_00168, 16, 10, 100, 10000, 1000000, 10000000, 100000000);\n DESC TABLE mt_00168;\ndiff --git a/tests/queries/0_stateless/00191_aggregating_merge_tree_and_final.sql b/tests/queries/0_stateless/00191_aggregating_merge_tree_and_final.sql\nindex 776edeeb43cc..8160d4dee9e2 100644\n--- a/tests/queries/0_stateless/00191_aggregating_merge_tree_and_final.sql\n+++ b/tests/queries/0_stateless/00191_aggregating_merge_tree_and_final.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS aggregating_00191;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE aggregating_00191 (d Date DEFAULT '2000-01-01', k UInt64, u AggregateFunction(uniq, UInt64)) ENGINE = AggregatingMergeTree(d, k, 8192);\n \n INSERT INTO aggregating_00191 (k, u) SELECT intDiv(number, 100) AS k, uniqState(toUInt64(number % 100)) AS u FROM (SELECT * FROM system.numbers LIMIT 1000) GROUP BY k;\ndiff --git a/tests/queries/0_stateless/00193_parallel_replicas.sql b/tests/queries/0_stateless/00193_parallel_replicas.sql\nindex 6c5b50972cc1..2549ada2a78a 100644\n--- a/tests/queries/0_stateless/00193_parallel_replicas.sql\n+++ b/tests/queries/0_stateless/00193_parallel_replicas.sql\n@@ -3,6 +3,7 @@\n DROP TABLE IF EXISTS parallel_replicas;\n DROP TABLE IF EXISTS parallel_replicas_backup;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE parallel_replicas (d Date DEFAULT today(), x UInt32, u UInt64, s String) ENGINE = MergeTree(d, cityHash64(u, s), (x, d, cityHash64(u, s)), 8192);\n INSERT INTO parallel_replicas (x, u, s) VALUES (1, 2, 'A'),(3, 4, 'B'),(5, 6, 'C'),(7, 8, 'D'),(9,10,'E');\n INSERT INTO parallel_replicas (x, u, s) VALUES (11, 12, 'F'),(13, 14, 'G'),(15, 16, 'H'),(17, 18, 'I'),(19,20,'J');\ndiff --git a/tests/queries/0_stateless/00214_primary_key_order.sql b/tests/queries/0_stateless/00214_primary_key_order.sql\nindex 3c751e63e6db..e8a3be5f8dc2 100644\n--- a/tests/queries/0_stateless/00214_primary_key_order.sql\n+++ b/tests/queries/0_stateless/00214_primary_key_order.sql\n@@ -1,4 +1,6 @@\n DROP TABLE IF EXISTS primary_key;\n+\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE primary_key (d Date DEFAULT today(), x Int8) ENGINE = MergeTree(d, -x, 1);\n \n INSERT INTO primary_key (x) VALUES (1), (2), (3);\ndiff --git a/tests/queries/0_stateless/00215_primary_key_order_zookeeper_long.sql b/tests/queries/0_stateless/00215_primary_key_order_zookeeper_long.sql\nindex d50f0daeb144..f031ae7f54fb 100644\n--- a/tests/queries/0_stateless/00215_primary_key_order_zookeeper_long.sql\n+++ b/tests/queries/0_stateless/00215_primary_key_order_zookeeper_long.sql\n@@ -2,6 +2,7 @@\n -- Tag no-replicated-database: Old syntax is not allowed\n \n DROP TABLE IF EXISTS primary_key;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE primary_key (d Date DEFAULT today(), x Int8) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/test_00215/primary_key', 'r1', d, -x, 1);\n \n INSERT INTO primary_key (x) VALUES (1), (2), (3);\ndiff --git a/tests/queries/0_stateless/00226_zookeeper_deduplication_and_unexpected_parts_long.sql b/tests/queries/0_stateless/00226_zookeeper_deduplication_and_unexpected_parts_long.sql\nindex 0dec3ca05bc8..727c793efb03 100644\n--- a/tests/queries/0_stateless/00226_zookeeper_deduplication_and_unexpected_parts_long.sql\n+++ b/tests/queries/0_stateless/00226_zookeeper_deduplication_and_unexpected_parts_long.sql\n@@ -2,6 +2,7 @@\n -- Tag no-replicated-database: Old syntax is not allowed\n \n DROP TABLE IF EXISTS deduplication;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE deduplication (d Date DEFAULT '2015-01-01', x Int8) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/test_00226/deduplication', 'r1', d, x, 1);\n \n INSERT INTO deduplication (x) VALUES (1);\ndiff --git a/tests/queries/0_stateless/00229_prewhere_column_missing.sql b/tests/queries/0_stateless/00229_prewhere_column_missing.sql\nindex 324e37bfce7b..1fb74b04af0c 100644\n--- a/tests/queries/0_stateless/00229_prewhere_column_missing.sql\n+++ b/tests/queries/0_stateless/00229_prewhere_column_missing.sql\n@@ -1,5 +1,6 @@\n drop table if exists prewhere_column_missing;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table prewhere_column_missing (d Date default '2015-01-01', x UInt64) engine=MergeTree(d, x, 1);\n \n insert into prewhere_column_missing (x) values (0);\ndiff --git a/tests/queries/0_stateless/00236_replicated_drop_on_non_leader_zookeeper_long.sql b/tests/queries/0_stateless/00236_replicated_drop_on_non_leader_zookeeper_long.sql\nindex f6eb4b2f8c1d..78319c3edd4b 100644\n--- a/tests/queries/0_stateless/00236_replicated_drop_on_non_leader_zookeeper_long.sql\n+++ b/tests/queries/0_stateless/00236_replicated_drop_on_non_leader_zookeeper_long.sql\n@@ -6,6 +6,7 @@ SET replication_alter_partitions_sync = 2;\n DROP TABLE IF EXISTS attach_r1;\n DROP TABLE IF EXISTS attach_r2;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE attach_r1 (d Date) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/test_00236/01/attach', 'r1', d, d, 8192);\n CREATE TABLE attach_r2 (d Date) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/test_00236/01/attach', 'r2', d, d, 8192);\n \ndiff --git a/tests/queries/0_stateless/00253_insert_recursive_defaults.sql b/tests/queries/0_stateless/00253_insert_recursive_defaults.sql\nindex 37bfe0aa1880..c0edc4471254 100644\n--- a/tests/queries/0_stateless/00253_insert_recursive_defaults.sql\n+++ b/tests/queries/0_stateless/00253_insert_recursive_defaults.sql\n@@ -5,6 +5,7 @@ SELECT * FROM defaults;\n DROP TABLE defaults;\n \n DROP TABLE IF EXISTS elog_cut;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE elog_cut\n (\n     date Date DEFAULT toDate(uts),\ndiff --git a/tests/queries/0_stateless/00261_storage_aliases_and_array_join.sql b/tests/queries/0_stateless/00261_storage_aliases_and_array_join.sql\nindex 71562ffd6fa1..bb3376a9e61b 100644\n--- a/tests/queries/0_stateless/00261_storage_aliases_and_array_join.sql\n+++ b/tests/queries/0_stateless/00261_storage_aliases_and_array_join.sql\n@@ -1,5 +1,6 @@\n drop table if exists aliases_test;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table aliases_test (\n date Date, id UInt64,\n array default ['zero','one','two'],\ndiff --git a/tests/queries/0_stateless/00262_alter_alias.sql b/tests/queries/0_stateless/00262_alter_alias.sql\nindex 56dbda65be7e..1c19f8636d1a 100644\n--- a/tests/queries/0_stateless/00262_alter_alias.sql\n+++ b/tests/queries/0_stateless/00262_alter_alias.sql\n@@ -1,5 +1,6 @@\n drop table if exists aliases_test;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table aliases_test (date default today(), id default rand(), array default [0, 1, 2]) engine=MergeTree(date, id, 1);\n \n insert into aliases_test (id) values (0);\ndiff --git a/tests/queries/0_stateless/00276_sample.sql b/tests/queries/0_stateless/00276_sample.sql\nindex cd28f18b2b80..b75ed188ec4a 100644\n--- a/tests/queries/0_stateless/00276_sample.sql\n+++ b/tests/queries/0_stateless/00276_sample.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS sample_00276;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n SET min_insert_block_size_rows = 0, min_insert_block_size_bytes = 0;\n SET max_block_size = 10;\n \ndiff --git a/tests/queries/0_stateless/00278_insert_already_sorted.sql b/tests/queries/0_stateless/00278_insert_already_sorted.sql\nindex 735b46d22ddb..b3de48dc1552 100644\n--- a/tests/queries/0_stateless/00278_insert_already_sorted.sql\n+++ b/tests/queries/0_stateless/00278_insert_already_sorted.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS sorted;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE sorted (d Date DEFAULT '2000-01-01', x UInt64) ENGINE = MergeTree(d, x, 8192);\n \n INSERT INTO sorted (x) SELECT intDiv(number, 100000) AS x FROM system.numbers LIMIT 1000000;\ndiff --git a/tests/queries/0_stateless/00282_merging.sql b/tests/queries/0_stateless/00282_merging.sql\nindex 30aec1bc4394..f4a3708eedf3 100644\n--- a/tests/queries/0_stateless/00282_merging.sql\n+++ b/tests/queries/0_stateless/00282_merging.sql\n@@ -1,4 +1,6 @@\n DROP TABLE IF EXISTS merge;\n+\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE IF NOT EXISTS merge (d Date DEFAULT '2000-01-01', x UInt64) ENGINE = MergeTree(d, x, 5);\n \n INSERT INTO merge (x) VALUES (1), (2), (3);\n@@ -73,6 +75,7 @@ SELECT * FROM merge ORDER BY _part_index, x;\n DROP TABLE merge;\n \n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE IF NOT EXISTS merge (d Date DEFAULT '2000-01-01', x UInt64) ENGINE = MergeTree(d, x, 8192);\n \n SET min_insert_block_size_rows = 0, min_insert_block_size_bytes = 0;\ndiff --git a/tests/queries/0_stateless/00294_shard_enums.sql b/tests/queries/0_stateless/00294_shard_enums.sql\nindex 414b9cfad030..dcd74ac3e3a7 100644\n--- a/tests/queries/0_stateless/00294_shard_enums.sql\n+++ b/tests/queries/0_stateless/00294_shard_enums.sql\n@@ -3,6 +3,7 @@\n set max_threads = 1;\n drop table if exists enums;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table enums (\n     d Date default '2015-12-29', k default 0,\n     e Enum8('world' = 2, 'hello' = 1), sign Enum8('minus' = -1, 'plus' = 1),\ndiff --git a/tests/queries/0_stateless/00311_array_primary_key.sql b/tests/queries/0_stateless/00311_array_primary_key.sql\nindex f6e21beab9b2..348ef2d1c6ff 100644\n--- a/tests/queries/0_stateless/00311_array_primary_key.sql\n+++ b/tests/queries/0_stateless/00311_array_primary_key.sql\n@@ -1,5 +1,6 @@\n -- Tags: no-parallel\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n DROP TABLE IF EXISTS array_pk;\n CREATE TABLE array_pk (key Array(UInt8), s String, n UInt64, d Date MATERIALIZED '2000-01-01') ENGINE = MergeTree(d, (key, s, n), 1);\n \ndiff --git a/tests/queries/0_stateless/00314_sample_factor_virtual_column.sql b/tests/queries/0_stateless/00314_sample_factor_virtual_column.sql\nindex b0ed4fdedcba..6e3dc0190695 100644\n--- a/tests/queries/0_stateless/00314_sample_factor_virtual_column.sql\n+++ b/tests/queries/0_stateless/00314_sample_factor_virtual_column.sql\n@@ -2,6 +2,7 @@ DROP TABLE IF EXISTS sample_00314_1;\n DROP TABLE IF EXISTS sample_00314_2;\n DROP TABLE IF EXISTS sample_merge_00314;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE sample_00314_1 (x UInt64, d Date DEFAULT today()) ENGINE = MergeTree(d, intHash64(x), intHash64(x), 10);\n CREATE TABLE sample_00314_2 (x UInt64, d Date DEFAULT today()) ENGINE = MergeTree(d, intHash64(x), intHash64(x), 10);\n \ndiff --git a/tests/queries/0_stateless/00318_pk_tuple_order.sql b/tests/queries/0_stateless/00318_pk_tuple_order.sql\nindex 8e2992167ee5..585f35d2f3ca 100644\n--- a/tests/queries/0_stateless/00318_pk_tuple_order.sql\n+++ b/tests/queries/0_stateless/00318_pk_tuple_order.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS pk;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE pk (d Date DEFAULT '2000-01-01', x UInt64, y UInt64, z UInt64) ENGINE = MergeTree(d, (x, y, z), 1);\n \n INSERT INTO pk (x, y, z) VALUES (1, 11, 1235), (1, 11, 4395), (1, 22, 3545), (1, 22, 6984), (1, 33, 4596), (2, 11, 4563), (2, 11, 4578), (2, 11, 3572), (2, 22, 5786), (2, 22, 5786), (2, 22, 2791), (2, 22, 2791), (3, 33, 2791), (3, 33, 2791), (3, 33, 1235), (3, 44, 4935), (3, 44, 4578), (3, 55, 5786), (3, 55, 2791), (3, 55, 1235);\ndiff --git a/tests/queries/0_stateless/00319_index_for_like.sql b/tests/queries/0_stateless/00319_index_for_like.sql\nindex 57ebce439f33..e490e5951421 100644\n--- a/tests/queries/0_stateless/00319_index_for_like.sql\n+++ b/tests/queries/0_stateless/00319_index_for_like.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS index_for_like;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE index_for_like (s String, d Date DEFAULT today()) ENGINE = MergeTree(d, (s, d), 1);\n \n INSERT INTO index_for_like (s) VALUES ('Hello'), ('Hello, World'), ('Hello, World 1'), ('Hello 1'), ('Goodbye'), ('Goodbye, World'), ('Goodbye 1'), ('Goodbye, World 1'); \ndiff --git a/tests/queries/0_stateless/00321_pk_set.sql b/tests/queries/0_stateless/00321_pk_set.sql\nindex 073a87a6e13b..bf61a684ac7e 100644\n--- a/tests/queries/0_stateless/00321_pk_set.sql\n+++ b/tests/queries/0_stateless/00321_pk_set.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS pk_set;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE pk_set (d Date, n UInt64, host String, code UInt64) ENGINE = MergeTree(d, (n, host, code), 1);\n INSERT INTO pk_set (n, host, code) VALUES (1, 'market', 100), (11, 'news', 100);\n \ndiff --git a/tests/queries/0_stateless/00327_summing_composite_nested.sql b/tests/queries/0_stateless/00327_summing_composite_nested.sql\nindex f9b251ebd8fa..701735a71684 100644\n--- a/tests/queries/0_stateless/00327_summing_composite_nested.sql\n+++ b/tests/queries/0_stateless/00327_summing_composite_nested.sql\n@@ -1,6 +1,7 @@\n SET optimize_on_insert = 0;\n \n DROP TABLE IF EXISTS summing_composite_key;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE summing_composite_key (d Date, k UInt64, FirstMap Nested(k1 UInt32, k2ID Int8, s Float64), SecondMap Nested(k1ID UInt64, k2Key String, k3Type Int32, s Int64)) ENGINE = SummingMergeTree(d, k, 1);\n \n INSERT INTO summing_composite_key VALUES ('2000-01-01', 1, [1,2], ['3','4'], [10,11], [0,1,2], [3,4,5], [-1,-2,-3], [1,10,100]), ('2000-01-01', 1, [2,1], ['4','3'], [20,22], [2,2,1], [5,5,0], [-3,-3,-33], [10,100,1000]), ('2000-01-01', 2, [1,2], ['3','4'], [10,11], [0,1,2], [3,4,5], [-1,-2,-3], [1,10,100]), ('2000-01-01', 2, [2,1,1], ['4','3','3'], [20,22,33], [2,2], [5,5], [-3,-3], [10,100]), ('2000-01-01', 2, [1,2], ['3','4'], [10,11], [0,1,2], [3,4,5], [-1,-2,-3], [1,10,100]);\ndiff --git a/tests/queries/0_stateless/00331_final_and_prewhere.sql b/tests/queries/0_stateless/00331_final_and_prewhere.sql\nindex 02af6d9b4500..5d0b80d63630 100644\n--- a/tests/queries/0_stateless/00331_final_and_prewhere.sql\n+++ b/tests/queries/0_stateless/00331_final_and_prewhere.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS replace;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE replace ( EventDate Date,  Id UInt64,  Data String,  Version UInt32) ENGINE = ReplacingMergeTree(EventDate, Id, 8192, Version);\n INSERT INTO replace VALUES ('2016-06-02', 1, 'version 1', 1);\n INSERT INTO replace VALUES ('2016-06-02', 2, 'version 1', 1);\ndiff --git a/tests/queries/0_stateless/00345_index_accurate_comparison.sql b/tests/queries/0_stateless/00345_index_accurate_comparison.sql\nindex 138a93990cf3..aafe2a0ae69f 100644\n--- a/tests/queries/0_stateless/00345_index_accurate_comparison.sql\n+++ b/tests/queries/0_stateless/00345_index_accurate_comparison.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS index;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE index\n (\n     key Int32,\ndiff --git a/tests/queries/0_stateless/00361_shared_array_offsets_and_squash_blocks.sql b/tests/queries/0_stateless/00361_shared_array_offsets_and_squash_blocks.sql\nindex 6160edd05b7c..7815a35259a6 100644\n--- a/tests/queries/0_stateless/00361_shared_array_offsets_and_squash_blocks.sql\n+++ b/tests/queries/0_stateless/00361_shared_array_offsets_and_squash_blocks.sql\n@@ -1,6 +1,7 @@\n DROP TABLE IF EXISTS nested1;\n DROP TABLE IF EXISTS nested2;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE nested1 (d Date DEFAULT '2000-01-01', x UInt64, n Nested(a String, b String)) ENGINE = MergeTree(d, x, 1);\n INSERT INTO nested1 (x, n.a, n.b) VALUES (1, ['Hello', 'World'], ['abc', 'def']), (2, [], []);\n \ndiff --git a/tests/queries/0_stateless/00363_defaults.sql b/tests/queries/0_stateless/00363_defaults.sql\nindex 4ebcc7b0f61c..1ec3b13a130d 100644\n--- a/tests/queries/0_stateless/00363_defaults.sql\n+++ b/tests/queries/0_stateless/00363_defaults.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS prewhere_defaults;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE prewhere_defaults (d Date DEFAULT '2000-01-01', k UInt64 DEFAULT 0, x UInt16) ENGINE = MergeTree(d, k, 1);\n \n INSERT INTO prewhere_defaults (x) VALUES (1);\ndiff --git a/tests/queries/0_stateless/00384_column_aggregate_function_insert_from.sql b/tests/queries/0_stateless/00384_column_aggregate_function_insert_from.sql\nindex 0c6146028668..a723bc9b59cf 100644\n--- a/tests/queries/0_stateless/00384_column_aggregate_function_insert_from.sql\n+++ b/tests/queries/0_stateless/00384_column_aggregate_function_insert_from.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS aggregates;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE aggregates (d Date, s AggregateFunction(uniq, UInt64)) ENGINE = MergeTree(d, d, 8192);\n \n INSERT INTO aggregates\ndiff --git a/tests/queries/0_stateless/00386_enum_in_pk.sql b/tests/queries/0_stateless/00386_enum_in_pk.sql\nindex 75b8a1665235..4fc79b5ef1be 100644\n--- a/tests/queries/0_stateless/00386_enum_in_pk.sql\n+++ b/tests/queries/0_stateless/00386_enum_in_pk.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS enum_pk;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE enum_pk (date Date DEFAULT '0000-00-00', x Enum8('0' = 0, '1' = 1, '2' = 2), d Enum8('0' = 0, '1' = 1, '2' = 2)) ENGINE = MergeTree(date, x, 1);\n INSERT INTO enum_pk (x, d) VALUES ('0', '0')('1', '1')('0', '0')('1', '1')('1', '1')('0', '0')('0', '0')('2', '2')('0', '0')('1', '1')('1', '1')('1', '1')('1', '1')('0', '0');\n \ndiff --git a/tests/queries/0_stateless/00392_enum_nested_alter.sql b/tests/queries/0_stateless/00392_enum_nested_alter.sql\nindex 205b9a7fec04..b5989885de47 100644\n--- a/tests/queries/0_stateless/00392_enum_nested_alter.sql\n+++ b/tests/queries/0_stateless/00392_enum_nested_alter.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS enum_nested_alter;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE enum_nested_alter\n (d Date DEFAULT '2000-01-01', x UInt64, n Nested(a String, e Enum8('Hello' = 1), b UInt8)) \n ENGINE = MergeTree(d, x, 1);\ndiff --git a/tests/queries/0_stateless/00394_new_nested_column_keeps_offsets.sql b/tests/queries/0_stateless/00394_new_nested_column_keeps_offsets.sql\nindex 7c3775294168..f058a852e918 100644\n--- a/tests/queries/0_stateless/00394_new_nested_column_keeps_offsets.sql\n+++ b/tests/queries/0_stateless/00394_new_nested_column_keeps_offsets.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS alter_00394;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE alter_00394 (d Date, k UInt64, i32 Int32, n Nested(ui8 UInt8, s String)) ENGINE=MergeTree(d, k, 8192);\n \n INSERT INTO alter_00394 VALUES ('2015-01-01', 3, 30, [1,2,3], ['1','12','123']);\ndiff --git a/tests/queries/0_stateless/00394_replaceall_vector_fixed.sql b/tests/queries/0_stateless/00394_replaceall_vector_fixed.sql\nindex 47ab3fe4a1c9..ada48add4033 100644\n--- a/tests/queries/0_stateless/00394_replaceall_vector_fixed.sql\n+++ b/tests/queries/0_stateless/00394_replaceall_vector_fixed.sql\n@@ -14,6 +14,7 @@ ORDER BY str ASC;\n \n DROP TABLE replaceall;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE replaceall (date Date DEFAULT today(), fs FixedString(16)) ENGINE = MergeTree(date, (date, fs), 8192);\n INSERT INTO replaceall (fs) VALUES ('54db0d43009d\\0\\0\\0\\0'), ('fe2b58224766cf10'), ('54db0d43009d\\0\\0\\0\\0'), ('fe2b58224766cf10');\n \ndiff --git a/tests/queries/0_stateless/00395_nullable.sql b/tests/queries/0_stateless/00395_nullable.sql\nindex 71dc045ad098..83d27830f4ee 100644\n--- a/tests/queries/0_stateless/00395_nullable.sql\n+++ b/tests/queries/0_stateless/00395_nullable.sql\n@@ -8,6 +8,7 @@ SELECT NULL + NULL;\n SELECT '----- MergeTree engine -----';\n \n DROP TABLE IF EXISTS test1_00395;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test1_00395(\n col1 UInt64, col2 Nullable(UInt64),\n col3 String, col4 Nullable(String),\ndiff --git a/tests/queries/0_stateless/00411_merge_tree_where_const_in_set.sql b/tests/queries/0_stateless/00411_merge_tree_where_const_in_set.sql\nindex 614f838c2ebc..22779509a3db 100644\n--- a/tests/queries/0_stateless/00411_merge_tree_where_const_in_set.sql\n+++ b/tests/queries/0_stateless/00411_merge_tree_where_const_in_set.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS const_in_const;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE const_in_const (id UInt64, date Date, uid UInt32, name String, Sign Int8) ENGINE = CollapsingMergeTree(date, intHash32(uid), (id, date, intHash32(uid)), 8192, Sign);\n INSERT INTO const_in_const VALUES(1, now(), 1, 'test1', 1);\n INSERT INTO const_in_const VALUES(2, now(), 1, 'test2', 1);\ndiff --git a/tests/queries/0_stateless/00412_logical_expressions_optimizer.sql b/tests/queries/0_stateless/00412_logical_expressions_optimizer.sql\nindex 5f8b15e980a7..c4fad7d50647 100644\n--- a/tests/queries/0_stateless/00412_logical_expressions_optimizer.sql\n+++ b/tests/queries/0_stateless/00412_logical_expressions_optimizer.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS merge_tree;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE merge_tree (x UInt64, date Date) ENGINE = MergeTree(date, x, 1);\n \n INSERT INTO merge_tree VALUES (1, '2000-01-01');\ndiff --git a/tests/queries/0_stateless/00427_alter_primary_key.sh b/tests/queries/0_stateless/00427_alter_primary_key.sh\nindex 4ad1166bfa4b..1269e2ad6e3f 100755\n--- a/tests/queries/0_stateless/00427_alter_primary_key.sh\n+++ b/tests/queries/0_stateless/00427_alter_primary_key.sh\n@@ -8,6 +8,7 @@ function perform()\n {\n     local query=$1\n     TZ=UTC $CLICKHOUSE_CLIENT \\\n+         --allow_deprecated_syntax_for_merge_tree=1 \\\n         --use_client_time_zone=1 \\\n         --input_format_values_interpret_expressions=0 \\\n         --query \"$query\" 2>/dev/null\ndiff --git a/tests/queries/0_stateless/00432_aggregate_function_scalars_and_constants.sql b/tests/queries/0_stateless/00432_aggregate_function_scalars_and_constants.sql\nindex c74b4f03371f..a6f31b9357cb 100644\n--- a/tests/queries/0_stateless/00432_aggregate_function_scalars_and_constants.sql\n+++ b/tests/queries/0_stateless/00432_aggregate_function_scalars_and_constants.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS agg_func_col;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE agg_func_col (p Date, k UInt8, d AggregateFunction(sum, UInt64) DEFAULT arrayReduce('sumState', [toUInt64(200)])) ENGINE = AggregatingMergeTree(p, k, 1);\n INSERT INTO agg_func_col (k) VALUES (0);\n INSERT INTO agg_func_col (k, d) SELECT 1 AS k, arrayReduce('sumState', [toUInt64(100)]) AS d;\ndiff --git a/tests/queries/0_stateless/00440_nulls_merge_tree.sql b/tests/queries/0_stateless/00440_nulls_merge_tree.sql\nindex 7281f9605097..dd9473027b45 100644\n--- a/tests/queries/0_stateless/00440_nulls_merge_tree.sql\n+++ b/tests/queries/0_stateless/00440_nulls_merge_tree.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS nulls;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE nulls (d Date, x Nullable(UInt64)) ENGINE = MergeTree(d, d, 8192);\n INSERT INTO nulls SELECT toDate('2000-01-01'), number % 10 != 0 ? number : NULL FROM system.numbers LIMIT 10000;\n SELECT count() FROM nulls WHERE x IS NULL;\ndiff --git a/tests/queries/0_stateless/00443_optimize_final_vertical_merge.sh b/tests/queries/0_stateless/00443_optimize_final_vertical_merge.sh\nindex a32dde581649..3bdc5892ceda 100755\n--- a/tests/queries/0_stateless/00443_optimize_final_vertical_merge.sh\n+++ b/tests/queries/0_stateless/00443_optimize_final_vertical_merge.sh\n@@ -16,7 +16,7 @@ function get_num_parts {\n \n $CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS $name\"\n \n-$CLICKHOUSE_CLIENT -q \"CREATE TABLE $name (\n+$CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 -q \"CREATE TABLE $name (\n date Date,\n Sign Int8,\n ki UInt64,\ndiff --git a/tests/queries/0_stateless/00446_clear_column_in_partition_concurrent_zookeeper.sh b/tests/queries/0_stateless/00446_clear_column_in_partition_concurrent_zookeeper.sh\nindex a441c9a6761a..2f79365f756d 100755\n--- a/tests/queries/0_stateless/00446_clear_column_in_partition_concurrent_zookeeper.sh\n+++ b/tests/queries/0_stateless/00446_clear_column_in_partition_concurrent_zookeeper.sh\n@@ -6,7 +6,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n . \"$CURDIR\"/../shell_config.sh\n \n-ch=\"$CLICKHOUSE_CLIENT --stacktrace -q\"\n+ch=\"$CLICKHOUSE_CLIENT  --allow_deprecated_syntax_for_merge_tree=1 --stacktrace -q\"\n \n $ch \"DROP TABLE IF EXISTS clear_column1\"\n $ch \"DROP TABLE IF EXISTS clear_column2\"\ndiff --git a/tests/queries/0_stateless/00453_cast_enum.sql b/tests/queries/0_stateless/00453_cast_enum.sql\nindex 70b7e2b1d6d7..384db50c7c45 100644\n--- a/tests/queries/0_stateless/00453_cast_enum.sql\n+++ b/tests/queries/0_stateless/00453_cast_enum.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS cast_enums;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE cast_enums\n (\n     type Enum8('session' = 1, 'pageview' = 2, 'click' = 3),\ndiff --git a/tests/queries/0_stateless/00456_alter_nullable.sql b/tests/queries/0_stateless/00456_alter_nullable.sql\nindex 703d1a551a7d..0fa3837767de 100644\n--- a/tests/queries/0_stateless/00456_alter_nullable.sql\n+++ b/tests/queries/0_stateless/00456_alter_nullable.sql\n@@ -1,4 +1,6 @@\n DROP TABLE IF EXISTS nullable_alter;\n+\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE nullable_alter (d Date DEFAULT '2000-01-01', x String) ENGINE = MergeTree(d, d, 1);\n \n INSERT INTO nullable_alter (x) VALUES ('Hello'), ('World');\ndiff --git a/tests/queries/0_stateless/00481_reading_from_last_granula.sql b/tests/queries/0_stateless/00481_reading_from_last_granula.sql\nindex 29d42e41e141..c98068e466b7 100644\n--- a/tests/queries/0_stateless/00481_reading_from_last_granula.sql\n+++ b/tests/queries/0_stateless/00481_reading_from_last_granula.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS tab_00481;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE tab_00481 (date Date, value UInt64, s String, m FixedString(16)) ENGINE = MergeTree(date, (date, value), 8);\n INSERT INTO tab_00481 SELECT today() as date, number as value, '' as s, toFixedString('', 16) as m from system.numbers limit 42;\n SET preferred_max_column_in_block_size_bytes = 32;\ndiff --git a/tests/queries/0_stateless/00483_reading_from_array_structure.sql b/tests/queries/0_stateless/00483_reading_from_array_structure.sql\nindex 5ba152ef9b64..bab0dcd37072 100644\n--- a/tests/queries/0_stateless/00483_reading_from_array_structure.sql\n+++ b/tests/queries/0_stateless/00483_reading_from_array_structure.sql\n@@ -1,4 +1,6 @@\n drop table if exists `table_00483`;\n+\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table `table_00483` (date Date, `Struct.Key1` Array(UInt64), `Struct.Key2` Array(UInt64), padding FixedString(16)) engine = MergeTree(date, (date), 16);\n insert into `table_00483` select today() as date, [number], [number + 1], toFixedString('', 16) from system.numbers limit 100;\n set preferred_max_column_in_block_size_bytes = 96;\ndiff --git a/tests/queries/0_stateless/00489_pk_subexpression.sql b/tests/queries/0_stateless/00489_pk_subexpression.sql\nindex 41499f0bd1ba..6f76a13609ca 100644\n--- a/tests/queries/0_stateless/00489_pk_subexpression.sql\n+++ b/tests/queries/0_stateless/00489_pk_subexpression.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS pk;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE pk (d Date DEFAULT '2000-01-01', x DateTime, y UInt64, z UInt64) ENGINE = MergeTree(d, (toStartOfMinute(x), y, z), 1);\n \n INSERT INTO pk (x, y, z) VALUES (1, 11, 1235), (2, 11, 4395), (3, 22, 3545), (4, 22, 6984), (5, 33, 4596), (61, 11, 4563), (62, 11, 4578), (63, 11, 3572), (64, 22, 5786), (65, 22, 5786), (66, 22, 2791), (67, 22, 2791), (121, 33, 2791), (122, 33, 2791), (123, 33, 1235), (124, 44, 4935), (125, 44, 4578), (126, 55, 5786), (127, 55, 2791), (128, 55, 1235);\ndiff --git a/tests/queries/0_stateless/00495_reading_const_zero_column.sql b/tests/queries/0_stateless/00495_reading_const_zero_column.sql\nindex da529c5b9b75..0af201b66e90 100644\n--- a/tests/queries/0_stateless/00495_reading_const_zero_column.sql\n+++ b/tests/queries/0_stateless/00495_reading_const_zero_column.sql\n@@ -1,4 +1,5 @@\n drop table if exists one_table;\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table one_table (date Date, one UInt64) engine = MergeTree(date, (date, one), 8192);\n insert into one_table select today(), toUInt64(1) from system.numbers limit 100000;\n SET preferred_block_size_bytes = 8192;\ndiff --git a/tests/queries/0_stateless/00504_insert_miss_columns.sh b/tests/queries/0_stateless/00504_insert_miss_columns.sh\nindex ea699ab58a5e..fa2cc9d0b22c 100755\n--- a/tests/queries/0_stateless/00504_insert_miss_columns.sh\n+++ b/tests/queries/0_stateless/00504_insert_miss_columns.sh\n@@ -8,8 +8,8 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n $CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS advertiser\";\n $CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS advertiser_test\";\n-$CLICKHOUSE_CLIENT -q \"CREATE TABLE advertiser ( action_date Date, adblock UInt8, imps Int64 ) Engine = SummingMergeTree( action_date, ( adblock ), 8192, ( imps ) )\";\n-$CLICKHOUSE_CLIENT -q \"CREATE TABLE advertiser_test ( action_date Date, adblock UInt8, imps Int64, Hash UInt64 ) Engine = SummingMergeTree( action_date, ( adblock, Hash ), 8192, ( imps ) )\";\n+$CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 -q \"CREATE TABLE advertiser ( action_date Date, adblock UInt8, imps Int64 ) Engine = SummingMergeTree( action_date, ( adblock ), 8192, ( imps ) )\";\n+$CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 -q \"CREATE TABLE advertiser_test ( action_date Date, adblock UInt8, imps Int64, Hash UInt64 ) Engine = SummingMergeTree( action_date, ( adblock, Hash ), 8192, ( imps ) )\";\n \n # This test will fail. It's ok.\n $CLICKHOUSE_CLIENT -q \"INSERT INTO advertiser_test SELECT *, sipHash64( CAST(adblock  AS String) ), CAST(1 AS Int8) FROM advertiser;\" 2>/dev/null\ndiff --git a/tests/queries/0_stateless/00504_mergetree_arrays_rw.sql b/tests/queries/0_stateless/00504_mergetree_arrays_rw.sql\nindex 766f9dfb3680..7c939d060eae 100644\n--- a/tests/queries/0_stateless/00504_mergetree_arrays_rw.sql\n+++ b/tests/queries/0_stateless/00504_mergetree_arrays_rw.sql\n@@ -1,4 +1,5 @@\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n drop table if exists test_ins_arr;\n create table test_ins_arr (date Date, val Array(UInt64)) engine = MergeTree(date, (date), 8192);\n insert into test_ins_arr select toDate('2017-10-02'), [number, 42] from system.numbers limit 10000;\ndiff --git a/tests/queries/0_stateless/00505_distributed_secure.data b/tests/queries/0_stateless/00505_distributed_secure.data\nindex 96a96ef4b686..7f73c803ec2d 100644\n--- a/tests/queries/0_stateless/00505_distributed_secure.data\n+++ b/tests/queries/0_stateless/00505_distributed_secure.data\n@@ -2,6 +2,7 @@ DROP TABLE IF EXISTS secure1;\n DROP TABLE IF EXISTS secure2;\n DROP TABLE IF EXISTS secure3;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE secure1 ( date Date, a Int32, b Int32, c Int32, d Int32) ENGINE = MergeTree(date, (a, date), 8192);\n CREATE TABLE secure2 ( date Date, a Int32, b Int32, c Int32, d Int32) ENGINE = Distributed(test_shard_localhost_secure, currentDatabase(), 'secure1');\n CREATE TABLE secure3 ( date Date, a Int32, b Int32, c Int32, d Int32) ENGINE = Distributed(test_shard_localhost_secure, currentDatabase(), 'secure2');\ndiff --git a/tests/queries/0_stateless/00506_union_distributed.sql b/tests/queries/0_stateless/00506_union_distributed.sql\nindex 08282d94d8b8..8a5dba00c272 100644\n--- a/tests/queries/0_stateless/00506_union_distributed.sql\n+++ b/tests/queries/0_stateless/00506_union_distributed.sql\n@@ -8,6 +8,7 @@ DROP TABLE IF EXISTS union1;\n DROP TABLE IF EXISTS union2;\n DROP TABLE IF EXISTS union3;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE union1 ( date Date, a Int32, b Int32, c Int32, d Int32) ENGINE = MergeTree(date, (a, date), 8192);\n CREATE TABLE union2 ( date Date, a Int32, b Int32, c Int32, d Int32) ENGINE = Distributed(test_shard_localhost, currentDatabase(), 'union1');\n CREATE TABLE union3 ( date Date, a Int32, b Int32, c Int32, d Int32) ENGINE = Distributed(test_shard_localhost, currentDatabase(), 'union2');\ndiff --git a/tests/queries/0_stateless/00515_shard_desc_table_functions_and_subqueries.sql b/tests/queries/0_stateless/00515_shard_desc_table_functions_and_subqueries.sql\nindex 64ceb394b17e..e358072248a4 100644\n--- a/tests/queries/0_stateless/00515_shard_desc_table_functions_and_subqueries.sql\n+++ b/tests/queries/0_stateless/00515_shard_desc_table_functions_and_subqueries.sql\n@@ -1,6 +1,7 @@\n -- Tags: shard\n \n drop table if exists tab;\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table tab (date Date, val UInt64, val2 UInt8 default 42, val3 UInt8 default val2 + 1, val4 UInt64 alias val) engine = MergeTree(date, (date, val), 8192);\n desc tab;\n select '-';\ndiff --git a/tests/queries/0_stateless/00516_deduplication_after_drop_partition_zookeeper.sql b/tests/queries/0_stateless/00516_deduplication_after_drop_partition_zookeeper.sql\nindex 6c76adb86d08..08dccac9d255 100644\n--- a/tests/queries/0_stateless/00516_deduplication_after_drop_partition_zookeeper.sql\n+++ b/tests/queries/0_stateless/00516_deduplication_after_drop_partition_zookeeper.sql\n@@ -2,6 +2,7 @@\n -- Tag no-replicated-database: Old syntax is not allowed\n \n DROP TABLE IF EXISTS deduplication_by_partition;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE deduplication_by_partition(d Date, x UInt32) ENGINE =\n     ReplicatedMergeTree('/clickhouse/tables/{database}/test_00516/deduplication_by_partition', 'r1', d, x, 8192);\n \ndiff --git a/tests/queries/0_stateless/00531_aggregate_over_nullable.sql b/tests/queries/0_stateless/00531_aggregate_over_nullable.sql\nindex ff485b4251ab..1680bb90bb10 100644\n--- a/tests/queries/0_stateless/00531_aggregate_over_nullable.sql\n+++ b/tests/queries/0_stateless/00531_aggregate_over_nullable.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS agg_over_nullable;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE agg_over_nullable (\n \tpartition Date,\n \ttimestamp DateTime,\ndiff --git a/tests/queries/0_stateless/00542_materialized_view_and_time_zone_tag.sql b/tests/queries/0_stateless/00542_materialized_view_and_time_zone_tag.sql\nindex 5e9277c90b66..88808ac20f92 100644\n--- a/tests/queries/0_stateless/00542_materialized_view_and_time_zone_tag.sql\n+++ b/tests/queries/0_stateless/00542_materialized_view_and_time_zone_tag.sql\n@@ -2,6 +2,7 @@ DROP TABLE IF EXISTS m3;\n DROP TABLE IF EXISTS m1;\n DROP TABLE IF EXISTS x;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE x (d Date, t DateTime) ENGINE = MergeTree(d, (d, t), 1);\n \n CREATE MATERIALIZED VIEW m1 (d Date, t DateTime, c UInt64) ENGINE = SummingMergeTree(d, (d, t), 1) AS SELECT d, toStartOfMinute(x.t) as t, count() as c FROM x GROUP BY d, t;\ndiff --git a/tests/queries/0_stateless/00543_null_and_prewhere.sql b/tests/queries/0_stateless/00543_null_and_prewhere.sql\nindex 793d65925a1d..5f50397862a3 100644\n--- a/tests/queries/0_stateless/00543_null_and_prewhere.sql\n+++ b/tests/queries/0_stateless/00543_null_and_prewhere.sql\n@@ -1,3 +1,5 @@\n+\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test\n (\n     dt Date,\ndiff --git a/tests/queries/0_stateless/00561_storage_join.sql b/tests/queries/0_stateless/00561_storage_join.sql\nindex 913ecec6f4af..9927592465a2 100644\n--- a/tests/queries/0_stateless/00561_storage_join.sql\n+++ b/tests/queries/0_stateless/00561_storage_join.sql\n@@ -1,5 +1,6 @@\n drop table IF EXISTS joinbug;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE joinbug (\n   event_date Date MATERIALIZED toDate(created, 'Asia/Istanbul'),\n   id UInt64,\ndiff --git a/tests/queries/0_stateless/00563_complex_in_expression.sql b/tests/queries/0_stateless/00563_complex_in_expression.sql\nindex cd80b9c3a7a5..bd053e0d0205 100644\n--- a/tests/queries/0_stateless/00563_complex_in_expression.sql\n+++ b/tests/queries/0_stateless/00563_complex_in_expression.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS test_00563;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test_00563 ( dt Date, site_id Int32, site_key String ) ENGINE = MergeTree(dt, (site_id, site_key, dt), 8192);\n INSERT INTO test_00563 (dt,site_id, site_key) VALUES ('2018-1-29', 100, 'key');\n SELECT * FROM test_00563 WHERE toInt32(site_id) IN (100);\ndiff --git a/tests/queries/0_stateless/00564_initial_column_values_with_default_expression.sql b/tests/queries/0_stateless/00564_initial_column_values_with_default_expression.sql\nindex d26621dce7a8..3fff20a1fe16 100644\n--- a/tests/queries/0_stateless/00564_initial_column_values_with_default_expression.sql\n+++ b/tests/queries/0_stateless/00564_initial_column_values_with_default_expression.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS test;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE IF NOT EXISTS test( id UInt32, track UInt8, codec String, content String, rdate Date DEFAULT '2018-02-03', track_id String DEFAULT concat(concat(concat(toString(track), '-'), codec), content) ) ENGINE=MergeTree(rdate, (id, track_id), 8192);\n \n INSERT INTO test(id, track, codec) VALUES(1, 0, 'h264');\ndiff --git a/tests/queries/0_stateless/00564_versioned_collapsing_merge_tree.sql b/tests/queries/0_stateless/00564_versioned_collapsing_merge_tree.sql\nindex 66bbb02183c1..fdee9390642c 100644\n--- a/tests/queries/0_stateless/00564_versioned_collapsing_merge_tree.sql\n+++ b/tests/queries/0_stateless/00564_versioned_collapsing_merge_tree.sql\n@@ -1,5 +1,6 @@\n -- Tags: no-parallel\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n set optimize_on_insert = 0;\n \n drop table if exists mult_tab;\ndiff --git a/tests/queries/0_stateless/00565_enum_order.sh b/tests/queries/0_stateless/00565_enum_order.sh\nindex 6958a403246e..fedd81b91f81 100755\n--- a/tests/queries/0_stateless/00565_enum_order.sh\n+++ b/tests/queries/0_stateless/00565_enum_order.sh\n@@ -10,7 +10,7 @@ $CLICKHOUSE_CLIENT <<\"EOF\"\n DROP TABLE IF EXISTS `test_log`\n EOF\n \n-$CLICKHOUSE_CLIENT <<\"EOF\"\n+$CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 <<\"EOF\"\n CREATE TABLE `test_log` (\n     date Date,\n     datetime DateTime,\ndiff --git a/tests/queries/0_stateless/00571_non_exist_database_when_create_materializ_view.sql b/tests/queries/0_stateless/00571_non_exist_database_when_create_materializ_view.sql\nindex c384ef37fc7b..46fc0dd586dd 100644\n--- a/tests/queries/0_stateless/00571_non_exist_database_when_create_materializ_view.sql\n+++ b/tests/queries/0_stateless/00571_non_exist_database_when_create_materializ_view.sql\n@@ -8,6 +8,7 @@ DROP DATABASE IF EXISTS none;\n DROP TABLE IF EXISTS test_00571;\n DROP TABLE IF EXISTS test_materialized_00571;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE DATABASE none;\n CREATE TABLE test_00571 ( date Date, platform Enum8('a' = 0, 'b' = 1, 'c' = 2), app Enum8('a' = 0, 'b' = 1) ) ENGINE = MergeTree(date, (platform, app), 8192);\n CREATE MATERIALIZED VIEW test_materialized_00571 ENGINE = MergeTree(date, (platform, app), 8192) POPULATE AS SELECT date, platform, app FROM (SELECT * FROM test_00571);\ndiff --git a/tests/queries/0_stateless/00575_illegal_column_exception_when_drop_depen_column.sh b/tests/queries/0_stateless/00575_illegal_column_exception_when_drop_depen_column.sh\nindex 42bf37cbda53..706c08191258 100755\n--- a/tests/queries/0_stateless/00575_illegal_column_exception_when_drop_depen_column.sh\n+++ b/tests/queries/0_stateless/00575_illegal_column_exception_when_drop_depen_column.sh\n@@ -9,7 +9,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n exception_pattern=\"Code: 44.*Cannot drop column \\`id\\`, because column \\`id2\\` depends on it\"\n \n ${CLICKHOUSE_CLIENT} --query \"DROP TABLE IF EXISTS test_00575;\"\n-${CLICKHOUSE_CLIENT} --query \"CREATE TABLE test_00575 (dt Date DEFAULT now(), id UInt32, id2 UInt32 DEFAULT id + 1) ENGINE = MergeTree(dt, dt, 8192);\"\n+${CLICKHOUSE_CLIENT} --allow_deprecated_syntax_for_merge_tree=1 --query \"CREATE TABLE test_00575 (dt Date DEFAULT now(), id UInt32, id2 UInt32 DEFAULT id + 1) ENGINE = MergeTree(dt, dt, 8192);\"\n ${CLICKHOUSE_CLIENT} --query \"INSERT INTO test_00575(dt,id) VALUES ('2018-02-22',3), ('2018-02-22',4), ('2018-02-22',5);\"\n ${CLICKHOUSE_CLIENT} --query \"SELECT * FROM test_00575 ORDER BY id;\"\n echo \"$(${CLICKHOUSE_CLIENT} --query \"ALTER TABLE test_00575 DROP COLUMN id;\" --server_logs_file=/dev/null 2>&1 | grep -c \"$exception_pattern\")\"\ndiff --git a/tests/queries/0_stateless/00575_merge_and_index_with_function_in_in.sql b/tests/queries/0_stateless/00575_merge_and_index_with_function_in_in.sql\nindex e491ef37adac..6f0ddd9fae30 100644\n--- a/tests/queries/0_stateless/00575_merge_and_index_with_function_in_in.sql\n+++ b/tests/queries/0_stateless/00575_merge_and_index_with_function_in_in.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS t_00575;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table t_00575(d Date) engine MergeTree(d, d, 8192);\n \n insert into t_00575 values ('2018-02-20');\ndiff --git a/tests/queries/0_stateless/00579_virtual_column_and_lazy.sql b/tests/queries/0_stateless/00579_virtual_column_and_lazy.sql\nindex b1f1ec4cfb21..ca58a5fc93bb 100644\n--- a/tests/queries/0_stateless/00579_virtual_column_and_lazy.sql\n+++ b/tests/queries/0_stateless/00579_virtual_column_and_lazy.sql\n@@ -2,6 +2,7 @@ DROP TABLE IF EXISTS sample_00579_1;\n DROP TABLE IF EXISTS sample_00579_2;\n DROP TABLE IF EXISTS sample_merge_00579;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE sample_00579_1 (x UInt64, d Date DEFAULT today()) ENGINE = MergeTree(d, intHash64(x), intHash64(x), 10);\n CREATE TABLE sample_00579_2 (x UInt64, d Date DEFAULT today()) ENGINE = MergeTree(d, intHash64(x), intHash64(x), 10);\n \ndiff --git a/tests/queries/0_stateless/00584_view_union_all.sql b/tests/queries/0_stateless/00584_view_union_all.sql\nindex 2e4d7ea66db7..a86dfaec6c85 100644\n--- a/tests/queries/0_stateless/00584_view_union_all.sql\n+++ b/tests/queries/0_stateless/00584_view_union_all.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS Test_00584;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE Test_00584 (\n     createdDate Date,\n     str String,\ndiff --git a/tests/queries/0_stateless/00594_alias_in_distributed.sql b/tests/queries/0_stateless/00594_alias_in_distributed.sql\nindex b75dfdf79670..250ede2bb10a 100644\n--- a/tests/queries/0_stateless/00594_alias_in_distributed.sql\n+++ b/tests/queries/0_stateless/00594_alias_in_distributed.sql\n@@ -3,6 +3,7 @@\n DROP TABLE IF EXISTS alias_local10;\n DROP TABLE IF EXISTS alias10;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE alias_local10 (\n   Id Int8,\n   EventDate Date DEFAULT '2000-01-01',\ndiff --git a/tests/queries/0_stateless/00597_push_down_predicate_long.sql b/tests/queries/0_stateless/00597_push_down_predicate_long.sql\nindex 40ea8b48caab..a77f3730ac24 100644\n--- a/tests/queries/0_stateless/00597_push_down_predicate_long.sql\n+++ b/tests/queries/0_stateless/00597_push_down_predicate_long.sql\n@@ -7,6 +7,7 @@ SET joined_subquery_requires_alias = 0;\n DROP TABLE IF EXISTS test_00597;\n DROP TABLE IF EXISTS test_view_00597;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test_00597(date Date, id Int8, name String, value Int64) ENGINE = MergeTree(date, (id, date), 8192);\n CREATE VIEW test_view_00597 AS SELECT * FROM test_00597;\n \ndiff --git a/tests/queries/0_stateless/00609_mv_index_in_in.sql b/tests/queries/0_stateless/00609_mv_index_in_in.sql\nindex 002c94dd576e..bd9f35350c1f 100644\n--- a/tests/queries/0_stateless/00609_mv_index_in_in.sql\n+++ b/tests/queries/0_stateless/00609_mv_index_in_in.sql\n@@ -6,6 +6,7 @@ DROP TABLE IF EXISTS test_mv_00609;\n create table test_00609 (a Int8) engine=Memory;\n \n insert into test_00609 values (1);\n+set allow_deprecated_syntax_for_merge_tree=1;\n create materialized view test_mv_00609 uuid '00000609-1000-4000-8000-000000000001' Engine=MergeTree(date, (a), 8192) populate as select a, toDate('2000-01-01') date from test_00609;\n \n select * from test_mv_00609; -- OK\ndiff --git a/tests/queries/0_stateless/00610_materialized_view_forward_alter_partition_statements.sql b/tests/queries/0_stateless/00610_materialized_view_forward_alter_partition_statements.sql\nindex 6f5ba07e5dbf..8830204ecb59 100644\n--- a/tests/queries/0_stateless/00610_materialized_view_forward_alter_partition_statements.sql\n+++ b/tests/queries/0_stateless/00610_materialized_view_forward_alter_partition_statements.sql\n@@ -1,6 +1,7 @@\n DROP TABLE IF EXISTS tab_00610;\n DROP TABLE IF EXISTS mv_00610;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE tab_00610(d Date, x UInt32) ENGINE MergeTree(d, x, 8192);\n CREATE MATERIALIZED VIEW mv_00610(d Date, y UInt64) ENGINE MergeTree(d, y, 8192) AS SELECT d, x + 1 AS y FROM tab_00610;\n \ndiff --git a/tests/queries/0_stateless/00614_array_nullable.sql b/tests/queries/0_stateless/00614_array_nullable.sql\nindex d62ddb8242c4..1cbfbf128cbe 100644\n--- a/tests/queries/0_stateless/00614_array_nullable.sql\n+++ b/tests/queries/0_stateless/00614_array_nullable.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS test;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test(date Date, keys Array(Nullable(UInt8))) ENGINE = MergeTree(date, date, 1);\n INSERT INTO test VALUES ('2017-09-10', [1, 2, 3, 4, 5, 6, 7, NULL]);\n SELECT * FROM test LIMIT 1;\ndiff --git a/tests/queries/0_stateless/00614_shard_same_header_for_local_and_remote_node_in_distributed_query.sql b/tests/queries/0_stateless/00614_shard_same_header_for_local_and_remote_node_in_distributed_query.sql\nindex 5d3739277148..17cc76670b34 100644\n--- a/tests/queries/0_stateless/00614_shard_same_header_for_local_and_remote_node_in_distributed_query.sql\n+++ b/tests/queries/0_stateless/00614_shard_same_header_for_local_and_remote_node_in_distributed_query.sql\n@@ -1,6 +1,7 @@\n -- Tags: distributed\n \n drop table if exists tab;\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table tab (date Date,  time DateTime, data String) ENGINE = MergeTree(date, (time, data), 8192);\n insert into tab values ('2018-01-21','2018-01-21 15:12:13','test');\n select time FROM remote('127.0.0.{1,2}', currentDatabase(), tab)  WHERE date = '2018-01-21' limit 2;\ndiff --git a/tests/queries/0_stateless/00615_nullable_alter_optimize.sql b/tests/queries/0_stateless/00615_nullable_alter_optimize.sql\nindex 5c0a192e8268..26ff3b78d5e7 100644\n--- a/tests/queries/0_stateless/00615_nullable_alter_optimize.sql\n+++ b/tests/queries/0_stateless/00615_nullable_alter_optimize.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS test_00615;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test_00615\n (\n     dt Date,\ndiff --git a/tests/queries/0_stateless/00616_final_single_part.sql b/tests/queries/0_stateless/00616_final_single_part.sql\nindex 6618d0b12524..8c7720f89601 100644\n--- a/tests/queries/0_stateless/00616_final_single_part.sql\n+++ b/tests/queries/0_stateless/00616_final_single_part.sql\n@@ -3,6 +3,7 @@ SET optimize_on_insert = 0;\n DROP TABLE IF EXISTS test_00616;\n DROP TABLE IF EXISTS replacing_00616;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test_00616\n (\n     date Date,\n@@ -12,6 +13,7 @@ CREATE TABLE test_00616\n ENGINE = MergeTree(date, x, 4096);\n \n INSERT INTO test_00616 VALUES ('2018-03-21', 1, 1), ('2018-03-21', 1, 2);\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE replacing_00616 ENGINE = ReplacingMergeTree(date, x, 4096, ver) AS SELECT * FROM test_00616;\n \n SELECT * FROM test_00616 ORDER BY ver;\ndiff --git a/tests/queries/0_stateless/00621_regression_for_in_operator.sql b/tests/queries/0_stateless/00621_regression_for_in_operator.sql\nindex 84355a04df43..273f930a90fb 100644\n--- a/tests/queries/0_stateless/00621_regression_for_in_operator.sql\n+++ b/tests/queries/0_stateless/00621_regression_for_in_operator.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS regression_for_in_operator_view;\n DROP TABLE IF EXISTS regression_for_in_operator;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE regression_for_in_operator (d Date, v UInt32, g String) ENGINE=MergeTree(d, d, 8192);\n CREATE MATERIALIZED VIEW regression_for_in_operator_view ENGINE=AggregatingMergeTree(d, (d,g), 8192) AS SELECT d, g, maxState(v) FROM regression_for_in_operator GROUP BY d, g;\n \ndiff --git a/tests/queries/0_stateless/00623_in_partition_key.sql b/tests/queries/0_stateless/00623_in_partition_key.sql\nindex 0141151e369a..6cb33f96f130 100644\n--- a/tests/queries/0_stateless/00623_in_partition_key.sql\n+++ b/tests/queries/0_stateless/00623_in_partition_key.sql\n@@ -1,4 +1,5 @@\n drop table if exists test54378;\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table test54378 (part_date Date, pk_date Date, date Date) Engine=MergeTree(part_date, pk_date, 8192);\n insert into test54378 values ('2018-04-19', '2018-04-19', '2018-04-19');\n \ndiff --git a/tests/queries/0_stateless/00623_replicated_truncate_table_zookeeper_long.sql b/tests/queries/0_stateless/00623_replicated_truncate_table_zookeeper_long.sql\nindex 4a3640e2dd7c..44a7d8ca60f5 100644\n--- a/tests/queries/0_stateless/00623_replicated_truncate_table_zookeeper_long.sql\n+++ b/tests/queries/0_stateless/00623_replicated_truncate_table_zookeeper_long.sql\n@@ -4,6 +4,7 @@\n DROP TABLE IF EXISTS replicated_truncate1;\n DROP TABLE IF EXISTS replicated_truncate2;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE replicated_truncate1 (d Date, k UInt64, i32 Int32) ENGINE=ReplicatedMergeTree('/clickhouse/tables/{database}/test_00623/truncate', 'r1', d, k, 8192);\n CREATE TABLE replicated_truncate2 (d Date, k UInt64, i32 Int32) ENGINE=ReplicatedMergeTree('/clickhouse/tables/{database}/test_00623/truncate', 'r2', d, k, 8192);\n \ndiff --git a/tests/queries/0_stateless/00623_truncate_table.sql b/tests/queries/0_stateless/00623_truncate_table.sql\nindex 80369ff2bbc4..16bc87ea2130 100644\n--- a/tests/queries/0_stateless/00623_truncate_table.sql\n+++ b/tests/queries/0_stateless/00623_truncate_table.sql\n@@ -1,5 +1,7 @@\n -- Tags: no-parallel\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n+\n DROP DATABASE IF EXISTS truncate_test;\n DROP TABLE IF EXISTS truncate_test_log;\n DROP TABLE IF EXISTS truncate_test_memory;\ndiff --git a/tests/queries/0_stateless/00625_summing_merge_tree_merge.sql b/tests/queries/0_stateless/00625_summing_merge_tree_merge.sql\nindex a214347a3a77..235048ad18b8 100644\n--- a/tests/queries/0_stateless/00625_summing_merge_tree_merge.sql\n+++ b/tests/queries/0_stateless/00625_summing_merge_tree_merge.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS tab_00625;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE tab_00625\n (\n     date Date,\ndiff --git a/tests/queries/0_stateless/00632_get_sample_block_cache.sql b/tests/queries/0_stateless/00632_get_sample_block_cache.sql\nindex f9b241bbf1e9..cbb89387dd1a 100644\n--- a/tests/queries/0_stateless/00632_get_sample_block_cache.sql\n+++ b/tests/queries/0_stateless/00632_get_sample_block_cache.sql\n@@ -7,6 +7,7 @@ DROP TABLE IF EXISTS dict_string;\n DROP TABLE IF EXISTS dict_ui64;\n DROP TABLE IF EXISTS video_views;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE video_views\n (\n     entityIri String,\ndiff --git a/tests/queries/0_stateless/00648_replacing_empty_set_from_prewhere.sql b/tests/queries/0_stateless/00648_replacing_empty_set_from_prewhere.sql\nindex 1f873c94b18f..bbeb4dd31483 100644\n--- a/tests/queries/0_stateless/00648_replacing_empty_set_from_prewhere.sql\n+++ b/tests/queries/0_stateless/00648_replacing_empty_set_from_prewhere.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS final_test;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE final_test (id String, version Date) ENGINE = ReplacingMergeTree(version, id, 8192);\n INSERT INTO final_test (id, version) VALUES ('2018-01-01', '2018-01-01');\n SELECT * FROM final_test FINAL PREWHERE id == '2018-01-02';\ndiff --git a/tests/queries/0_stateless/00652_mergetree_mutations.sh b/tests/queries/0_stateless/00652_mergetree_mutations.sh\nindex 0cba8b940408..535cbe99dfe9 100755\n--- a/tests/queries/0_stateless/00652_mergetree_mutations.sh\n+++ b/tests/queries/0_stateless/00652_mergetree_mutations.sh\n@@ -10,7 +10,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n ${CLICKHOUSE_CLIENT} --query=\"DROP TABLE IF EXISTS mutations\"\n \n-${CLICKHOUSE_CLIENT} --query=\"CREATE TABLE mutations(d Date, x UInt32, s String, a UInt32 ALIAS x + 1, m MATERIALIZED x + 2) ENGINE MergeTree(d, intDiv(x, 10), 8192)\"\n+${CLICKHOUSE_CLIENT} --allow_deprecated_syntax_for_merge_tree=1 --query=\"CREATE TABLE mutations(d Date, x UInt32, s String, a UInt32 ALIAS x + 1, m MATERIALIZED x + 2) ENGINE MergeTree(d, intDiv(x, 10), 8192)\"\n \n # Test a mutation on empty table\n ${CLICKHOUSE_CLIENT} --query=\"ALTER TABLE mutations DELETE WHERE x = 1\"\ndiff --git a/tests/queries/0_stateless/00652_replicated_mutations_zookeeper.sh b/tests/queries/0_stateless/00652_replicated_mutations_zookeeper.sh\nindex f070e34f2a1b..7a6c76096608 100755\n--- a/tests/queries/0_stateless/00652_replicated_mutations_zookeeper.sh\n+++ b/tests/queries/0_stateless/00652_replicated_mutations_zookeeper.sh\n@@ -12,8 +12,8 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n ${CLICKHOUSE_CLIENT} --query=\"DROP TABLE IF EXISTS mutations_r1\"\n ${CLICKHOUSE_CLIENT} --query=\"DROP TABLE IF EXISTS mutations_r2\"\n \n-${CLICKHOUSE_CLIENT} --query=\"CREATE TABLE mutations_r1(d Date, x UInt32, s String, m MATERIALIZED x + 2) ENGINE ReplicatedMergeTree('/clickhouse/tables/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX/mutations', 'r1', d, intDiv(x, 10), 8192)\"\n-${CLICKHOUSE_CLIENT} --query=\"CREATE TABLE mutations_r2(d Date, x UInt32, s String, m MATERIALIZED x + 2) ENGINE ReplicatedMergeTree('/clickhouse/tables/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX/mutations', 'r2', d, intDiv(x, 10), 8192)\"\n+${CLICKHOUSE_CLIENT} --allow_deprecated_syntax_for_merge_tree=1 --query=\"CREATE TABLE mutations_r1(d Date, x UInt32, s String, m MATERIALIZED x + 2) ENGINE ReplicatedMergeTree('/clickhouse/tables/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX/mutations', 'r1', d, intDiv(x, 10), 8192)\"\n+${CLICKHOUSE_CLIENT} --allow_deprecated_syntax_for_merge_tree=1 --query=\"CREATE TABLE mutations_r2(d Date, x UInt32, s String, m MATERIALIZED x + 2) ENGINE ReplicatedMergeTree('/clickhouse/tables/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX/mutations', 'r2', d, intDiv(x, 10), 8192)\"\n \n # Test a mutation on empty table\n ${CLICKHOUSE_CLIENT} --query=\"ALTER TABLE mutations_r1 DELETE WHERE x = 1 SETTINGS mutations_sync = 2\"\ndiff --git a/tests/queries/0_stateless/00678_shard_funnel_window.sql b/tests/queries/0_stateless/00678_shard_funnel_window.sql\nindex 8ea07a1c4ba7..73e489232839 100644\n--- a/tests/queries/0_stateless/00678_shard_funnel_window.sql\n+++ b/tests/queries/0_stateless/00678_shard_funnel_window.sql\n@@ -1,6 +1,7 @@\n -- Tags: shard\n \n DROP TABLE IF EXISTS remote_test;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE remote_test(uid String, its UInt32,  action_code String, day Date) ENGINE = MergeTree(day, (uid, its), 8192);\n INSERT INTO remote_test SELECT toString(number) AS uid, number % 3 AS its, toString(number % 3) AS action_code, '2000-01-01' FROM system.numbers LIMIT 10000;\n SELECT level, COUNT() FROM (SELECT uid, windowFunnel(3600)(toUInt32(its), action_code != '', action_code = '2') AS level FROM remote('127.0.0.{2,3}', currentDatabase(), remote_test) GROUP BY uid) GROUP BY level;\ndiff --git a/tests/queries/0_stateless/00709_virtual_column_partition_id.sql b/tests/queries/0_stateless/00709_virtual_column_partition_id.sql\nindex 084ab904d871..48a3a3fad6a3 100644\n--- a/tests/queries/0_stateless/00709_virtual_column_partition_id.sql\n+++ b/tests/queries/0_stateless/00709_virtual_column_partition_id.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS partition_id;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE IF NOT EXISTS partition_id (d Date DEFAULT '2000-01-01', x UInt64) ENGINE = MergeTree(d, x, 5);\n \n INSERT INTO partition_id VALUES (100, 1), (200, 2), (300, 3);\ndiff --git a/tests/queries/0_stateless/00712_prewhere_with_alias_bug_2.sql b/tests/queries/0_stateless/00712_prewhere_with_alias_bug_2.sql\nindex 97d5e33633a7..beb986adebc4 100644\n--- a/tests/queries/0_stateless/00712_prewhere_with_alias_bug_2.sql\n+++ b/tests/queries/0_stateless/00712_prewhere_with_alias_bug_2.sql\n@@ -1,5 +1,6 @@\n drop table if exists table;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE table (a UInt32,  date Date, b UInt64,  c UInt64, str String, d Int8, arr Array(UInt64), arr_alias Array(UInt64) ALIAS arr) ENGINE = MergeTree(date, intHash32(c), (a, date, intHash32(c), b), 8192);\n \n SELECT alias2 AS alias3\ndiff --git a/tests/queries/0_stateless/00712_prewhere_with_final.sql b/tests/queries/0_stateless/00712_prewhere_with_final.sql\nindex 4528d4f61f05..6b49e523f70c 100644\n--- a/tests/queries/0_stateless/00712_prewhere_with_final.sql\n+++ b/tests/queries/0_stateless/00712_prewhere_with_final.sql\n@@ -1,4 +1,5 @@\n drop table if exists trepl;\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table trepl(d Date,a Int32, b Int32) engine = ReplacingMergeTree(d, (a,b), 8192);\n insert into trepl values ('2018-09-19', 1, 1);\n select b from trepl FINAL prewhere a < 1000;\ndiff --git a/tests/queries/0_stateless/00712_prewhere_with_sampling_and_alias.sql b/tests/queries/0_stateless/00712_prewhere_with_sampling_and_alias.sql\nindex d011e1b368d9..7c8ae4eed7c7 100644\n--- a/tests/queries/0_stateless/00712_prewhere_with_sampling_and_alias.sql\n+++ b/tests/queries/0_stateless/00712_prewhere_with_sampling_and_alias.sql\n@@ -1,4 +1,5 @@\n drop table if exists t_00712_2;\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table t_00712_2 (date Date, counter UInt64, sampler UInt64, alias_col alias date + 1) engine = MergeTree(date, intHash32(sampler), (counter, date, intHash32(sampler)), 8192);\n insert into t_00712_2 values ('2018-01-01', 1, 1);\n select alias_col from t_00712_2 sample 1 / 2 where date = '2018-01-01' and counter = 1 and sampler = 1;\ndiff --git a/tests/queries/0_stateless/00717_merge_and_distributed.sql b/tests/queries/0_stateless/00717_merge_and_distributed.sql\nindex f7b4a2b24d3c..f27f6a756889 100644\n--- a/tests/queries/0_stateless/00717_merge_and_distributed.sql\n+++ b/tests/queries/0_stateless/00717_merge_and_distributed.sql\n@@ -7,6 +7,7 @@ DROP TABLE IF EXISTS test_local_2;\n DROP TABLE IF EXISTS test_distributed_1;\n DROP TABLE IF EXISTS test_distributed_2;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test_local_1 (date Date, value UInt32) ENGINE = MergeTree(date, date, 8192);\n CREATE TABLE test_local_2 (date Date, value UInt32) ENGINE = MergeTree(date, date, 8192);\n CREATE TABLE test_distributed_1 AS test_local_1 ENGINE = Distributed('test_shard_localhost', currentDatabase(), test_local_1, rand());\ndiff --git a/tests/queries/0_stateless/00729_prewhere_array_join.sql b/tests/queries/0_stateless/00729_prewhere_array_join.sql\nindex ba10dd38bd2c..5ac79c150c6a 100644\n--- a/tests/queries/0_stateless/00729_prewhere_array_join.sql\n+++ b/tests/queries/0_stateless/00729_prewhere_array_join.sql\n@@ -1,6 +1,7 @@\n SET send_logs_level = 'fatal';\n \n drop table if exists t1_00729;\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table t1_00729 (id UInt64, val Array(String),nid UInt64, eDate Date)ENGINE = MergeTree(eDate, (id, eDate), 8192);\n \n insert into t1_00729 (id,val,nid,eDate) values (1,['background','foreground','heading','image'],1,'2018-09-27');\ndiff --git a/tests/queries/0_stateless/00731_long_merge_tree_select_opened_files.sh b/tests/queries/0_stateless/00731_long_merge_tree_select_opened_files.sh\nindex d9a3631a7ddc..2510517a7404 100755\n--- a/tests/queries/0_stateless/00731_long_merge_tree_select_opened_files.sh\n+++ b/tests/queries/0_stateless/00731_long_merge_tree_select_opened_files.sh\n@@ -7,7 +7,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n . \"$CURDIR\"/../shell_config.sh\n \n-settings=\"--log_queries=1 --log_query_threads=1 --log_profile_events=1 --log_query_settings=1\"\n+settings=\"--log_queries=1 --log_query_threads=1 --log_profile_events=1 --log_query_settings=1 --allow_deprecated_syntax_for_merge_tree=1\"\n \n # Test insert logging on each block and checkPacket() method\n \ndiff --git a/tests/queries/0_stateless/00732_decimal_summing_merge_tree.sql b/tests/queries/0_stateless/00732_decimal_summing_merge_tree.sql\nindex 1524776c16e5..96e16a1300e2 100644\n--- a/tests/queries/0_stateless/00732_decimal_summing_merge_tree.sql\n+++ b/tests/queries/0_stateless/00732_decimal_summing_merge_tree.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS decimal_sum;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE decimal_sum\n (\n     date Date,\ndiff --git a/tests/queries/0_stateless/00748_insert_array_with_null.sql b/tests/queries/0_stateless/00748_insert_array_with_null.sql\nindex 78c564abad37..ca36352c2cfa 100644\n--- a/tests/queries/0_stateless/00748_insert_array_with_null.sql\n+++ b/tests/queries/0_stateless/00748_insert_array_with_null.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS arraytest;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE arraytest ( created_date Date DEFAULT toDate(created_at), created_at DateTime DEFAULT now(), strings Array(String) DEFAULT emptyArrayString()) ENGINE = MergeTree(created_date, cityHash64(created_at), (created_date, cityHash64(created_at)), 8192);\n \n INSERT INTO arraytest (created_at, strings) VALUES (now(), ['aaaaa', 'bbbbb', 'ccccc']);\ndiff --git a/tests/queries/0_stateless/00752_low_cardinality_mv_2.sql b/tests/queries/0_stateless/00752_low_cardinality_mv_2.sql\nindex 71950469a470..83c6b1c1a6b5 100644\n--- a/tests/queries/0_stateless/00752_low_cardinality_mv_2.sql\n+++ b/tests/queries/0_stateless/00752_low_cardinality_mv_2.sql\n@@ -1,6 +1,7 @@\n drop table if exists radacct;\n drop table if exists mv_traffic_by_tadig15min;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE radacct ( radacctid UInt64, f3gppchargingid Nullable(String), f3gppggsnaddress Nullable(String), f3gppggsnmccmnc Nullable(String), f3gppgprsqos Nullable(String), f3gppimeisv Nullable(String), f3gppimsi Nullable(UInt64), f3gppimsimccmnc Nullable(String), f3gpploci Nullable(String), f3gppnsapi Nullable(String), f3gpprattype Nullable(String), f3gppsgsnaddress Nullable(String), f3gppsgsnmccmnc Nullable(String), acctdelaytime Nullable(UInt32), acctinputoctets Nullable(UInt64), acctinputpackets Nullable(UInt64), acctoutputoctets Nullable(UInt64), acctoutputpackets Nullable(UInt64), acctsessionid String, acctstatustype Nullable(String), acctuniqueid String, calledstationid Nullable(String), callingstationid Nullable(String), framedipaddress Nullable(String), nasidentifier Nullable(String), nasipaddress Nullable(String), acctstarttime Nullable(DateTime), acctstoptime Nullable(DateTime), acctsessiontime Nullable(UInt32), acctterminatecause Nullable(String), acctstartdelay Nullable(UInt32), acctstopdelay Nullable(UInt32), connectinfo_start Nullable(String), connectinfo_stop Nullable(String), timestamp DateTime, username Nullable(String), realm Nullable(String), f3gppimsi_int UInt64, f3gppsgsnaddress_int Nullable(UInt32), timestamp_date Date, tac Nullable(String), mnc Nullable(String), tadig LowCardinality(String), country LowCardinality(String), tadig_op_ip Nullable(String) DEFAULT CAST('TADIG NOT FOUND', 'Nullable(String)'), mcc Nullable(UInt16) MATERIALIZED toUInt16OrNull(substring(f3gppsgsnmccmnc, 1, 6))) ENGINE = MergeTree(timestamp_date, (timestamp, radacctid, acctuniqueid), 8192);\n \n insert into radacct values (1, 'a', 'b', 'c', 'd', 'e', 2, 'a', 'b', 'c', 'd', 'e', 'f', 3, 4, 5, 6, 7, 'a', 'Stop', 'c', 'd', 'e', 'f', 'g', 'h', '2018-10-10 15:54:21', '2018-10-10 15:54:21', 8, 'a', 9, 10, 'a', 'b', '2018-10-10 15:54:21', 'a', 'b', 11, 12, '2018-10-10', 'a', 'b', 'c', 'd', 'e');\ndiff --git a/tests/queries/0_stateless/00753_system_columns_and_system_tables_long.sql b/tests/queries/0_stateless/00753_system_columns_and_system_tables_long.sql\nindex a2d19c225005..e1392d299dc4 100644\n--- a/tests/queries/0_stateless/00753_system_columns_and_system_tables_long.sql\n+++ b/tests/queries/0_stateless/00753_system_columns_and_system_tables_long.sql\n@@ -49,6 +49,7 @@ FORMAT PrettyCompactNoEscapes;\n DROP TABLE IF EXISTS check_system_tables;\n \n -- Check MergeTree declaration in old format\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE check_system_tables\n   (\n     Event Date,\ndiff --git a/tests/queries/0_stateless/00754_alter_modify_order_by.sql b/tests/queries/0_stateless/00754_alter_modify_order_by.sql\nindex cb81f868e7b4..234bd61902b2 100644\n--- a/tests/queries/0_stateless/00754_alter_modify_order_by.sql\n+++ b/tests/queries/0_stateless/00754_alter_modify_order_by.sql\n@@ -2,6 +2,7 @@ SET send_logs_level = 'fatal';\n SET optimize_on_insert = 0;\n \n DROP TABLE IF EXISTS old_style;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE old_style(d Date, x UInt32) ENGINE MergeTree(d, x, 8192);\n ALTER TABLE old_style ADD COLUMN y UInt32, MODIFY ORDER BY (x, y); -- { serverError 36}\n DROP TABLE old_style;\ndiff --git a/tests/queries/0_stateless/00754_alter_modify_order_by_replicated_zookeeper_long.sql b/tests/queries/0_stateless/00754_alter_modify_order_by_replicated_zookeeper_long.sql\nindex c859c7b99212..29d0ef79b915 100644\n--- a/tests/queries/0_stateless/00754_alter_modify_order_by_replicated_zookeeper_long.sql\n+++ b/tests/queries/0_stateless/00754_alter_modify_order_by_replicated_zookeeper_long.sql\n@@ -6,6 +6,7 @@ SET optimize_on_insert = 0;\n SET send_logs_level = 'fatal';\n \n DROP TABLE IF EXISTS old_style;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE old_style(d Date, x UInt32) ENGINE ReplicatedMergeTree('/clickhouse/tables/{database}/test_00754/old_style', 'r1', d, x, 8192);\n ALTER TABLE old_style ADD COLUMN y UInt32, MODIFY ORDER BY (x, y); -- { serverError 36 }\n DROP TABLE old_style;\ndiff --git a/tests/queries/0_stateless/00794_materialized_view_with_column_defaults.sql b/tests/queries/0_stateless/00794_materialized_view_with_column_defaults.sql\nindex a756f5c35376..43dcb322f1c3 100644\n--- a/tests/queries/0_stateless/00794_materialized_view_with_column_defaults.sql\n+++ b/tests/queries/0_stateless/00794_materialized_view_with_column_defaults.sql\n@@ -1,6 +1,7 @@\n DROP TABLE IF EXISTS table_view;\n DROP TABLE IF EXISTS source_table;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE source_table (\n   date Date,\n   datetime DateTime,\ndiff --git a/tests/queries/0_stateless/00800_low_cardinality_distributed_insert.sql b/tests/queries/0_stateless/00800_low_cardinality_distributed_insert.sql\nindex 600793853ca1..7ddf1caa85fb 100644\n--- a/tests/queries/0_stateless/00800_low_cardinality_distributed_insert.sql\n+++ b/tests/queries/0_stateless/00800_low_cardinality_distributed_insert.sql\n@@ -5,6 +5,7 @@ SET insert_distributed_sync = 1;\n DROP TABLE IF EXISTS low_cardinality;\n DROP TABLE IF EXISTS low_cardinality_all;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE low_cardinality (d Date, x UInt32, s LowCardinality(String)) ENGINE = MergeTree(d, x, 8192);\n CREATE TABLE low_cardinality_all (d Date, x UInt32, s LowCardinality(String)) ENGINE = Distributed(test_shard_localhost, currentDatabase(), low_cardinality, sipHash64(s));\n \ndiff --git a/tests/queries/0_stateless/00806_alter_update.sql b/tests/queries/0_stateless/00806_alter_update.sql\nindex c4fe3969df3a..c9b1bfb2d9d7 100644\n--- a/tests/queries/0_stateless/00806_alter_update.sql\n+++ b/tests/queries/0_stateless/00806_alter_update.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS alter_update_00806;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE alter_update_00806 (d Date, e Enum8('foo'=1, 'bar'=2)) Engine = MergeTree(d, (d), 8192);\n INSERT INTO alter_update_00806 (d, e) VALUES ('2018-01-01', 'foo');\n INSERT INTO alter_update_00806 (d, e) VALUES ('2018-01-02', 'bar');\ndiff --git a/tests/queries/0_stateless/00829_bitmap_function.sql b/tests/queries/0_stateless/00829_bitmap_function.sql\nindex fde0176de5b5..6a21f5caf0ff 100644\n--- a/tests/queries/0_stateless/00829_bitmap_function.sql\n+++ b/tests/queries/0_stateless/00829_bitmap_function.sql\n@@ -71,6 +71,7 @@ SELECT bitmapToArray(bitmapAnd(groupBitmapState(uid), bitmapBuild(CAST([1, 2, 3]\n \n -- bitmap state test\n DROP TABLE IF EXISTS bitmap_state_test;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE bitmap_state_test\n (\n \tpickup_date Date,\ndiff --git a/tests/queries/0_stateless/00834_hints_for_type_function_typos.sh b/tests/queries/0_stateless/00834_hints_for_type_function_typos.sh\nindex 6640e0003cdb..41a35d908d1d 100755\n--- a/tests/queries/0_stateless/00834_hints_for_type_function_typos.sh\n+++ b/tests/queries/0_stateless/00834_hints_for_type_function_typos.sh\n@@ -26,5 +26,5 @@ $CLICKHOUSE_CLIENT -q \"select * FROM numberss(10);\" 2>&1 | grep \"Maybe you meant\n $CLICKHOUSE_CLIENT -q \"select * FROM anothernumbers(10);\" 2>&1 | grep -v \"Maybe you meant: \\['numbers'\\,'numbers_mt'\\].\" &>/dev/null\n $CLICKHOUSE_CLIENT -q \"select * FROM mynumbers(10);\" 2>&1 | grep \"Maybe you meant: \\['numbers'\\].\" &>/dev/null\n \n-$CLICKHOUSE_CLIENT -q \"CREATE TABLE stored_aggregates (d Date, Uniq AggregateFunction(uniq, UInt64)) ENGINE = MergeTre(d, d, 8192);\" 2>&1 | grep \"Maybe you meant: \\['MergeTree'\\].\" &>/dev/null\n-$CLICKHOUSE_CLIENT -q \"CREATE TABLE stored_aggregates (d Date, Uniq AgregateFunction(uniq, UInt64)) ENGINE = MergeTree(d, d, 8192);\" 2>&1 | grep \"Maybe you meant: \\['AggregateFunction'\\].\" &>/dev/null\n+$CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 -q \"CREATE TABLE stored_aggregates (d Date, Uniq AggregateFunction(uniq, UInt64)) ENGINE = MergeTre(d, d, 8192);\" 2>&1 | grep \"Maybe you meant: \\['MergeTree'\\].\" &>/dev/null\n+$CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 -q \"CREATE TABLE stored_aggregates (d Date, Uniq AgregateFunction(uniq, UInt64)) ENGINE = MergeTree(d, d, 8192);\" 2>&1 | grep \"Maybe you meant: \\['AggregateFunction'\\].\" &>/dev/null\ndiff --git a/tests/queries/0_stateless/00910_crash_when_distributed_modify_order_by.sql b/tests/queries/0_stateless/00910_crash_when_distributed_modify_order_by.sql\nindex 6dea97d1f277..00811d8ab89e 100644\n--- a/tests/queries/0_stateless/00910_crash_when_distributed_modify_order_by.sql\n+++ b/tests/queries/0_stateless/00910_crash_when_distributed_modify_order_by.sql\n@@ -2,6 +2,7 @@\n \n DROP TABLE IF EXISTS union1;\n DROP TABLE IF EXISTS union2;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE union1 ( date Date, a Int32, b Int32, c Int32, d Int32) ENGINE = MergeTree(date, (a, date), 8192);\n CREATE TABLE union2 ( date Date, a Int32, b Int32, c Int32, d Int32) ENGINE = Distributed(test_shard_localhost, currentDatabase(), 'union1');\n ALTER TABLE union2 MODIFY ORDER BY a; -- { serverError 48 }\ndiff --git a/tests/queries/0_stateless/00925_zookeeper_empty_replicated_merge_tree_optimize_final_long.sh b/tests/queries/0_stateless/00925_zookeeper_empty_replicated_merge_tree_optimize_final_long.sh\nindex b07578294249..9e82cb4d30bf 100755\n--- a/tests/queries/0_stateless/00925_zookeeper_empty_replicated_merge_tree_optimize_final_long.sh\n+++ b/tests/queries/0_stateless/00925_zookeeper_empty_replicated_merge_tree_optimize_final_long.sh\n@@ -8,8 +8,8 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n $CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS replicated_optimize1;\"\n $CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS replicated_optimize2;\"\n-$CLICKHOUSE_CLIENT -q \"CREATE TABLE replicated_optimize1 (d Date, k UInt64, i32 Int32) ENGINE=ReplicatedMergeTree('/clickhouse/tables/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX/test_00925/optimize', 'r1', d, k, 8192);\"\n-$CLICKHOUSE_CLIENT -q \"CREATE TABLE replicated_optimize2 (d Date, k UInt64, i32 Int32) ENGINE=ReplicatedMergeTree('/clickhouse/tables/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX/test_00925/optimize', 'r2', d, k, 8192);\"\n+$CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 -q \"CREATE TABLE replicated_optimize1 (d Date, k UInt64, i32 Int32) ENGINE=ReplicatedMergeTree('/clickhouse/tables/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX/test_00925/optimize', 'r1', d, k, 8192);\"\n+$CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 -q \"CREATE TABLE replicated_optimize2 (d Date, k UInt64, i32 Int32) ENGINE=ReplicatedMergeTree('/clickhouse/tables/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX/test_00925/optimize', 'r2', d, k, 8192);\"\n \n num_tries=0\n while [[ $($CLICKHOUSE_CLIENT -q \"SELECT is_leader FROM system.replicas WHERE database=currentDatabase() AND table='replicated_optimize1'\") -ne 1 ]]; do\ndiff --git a/tests/queries/0_stateless/00952_insert_into_distributed_with_materialized_column.sql b/tests/queries/0_stateless/00952_insert_into_distributed_with_materialized_column.sql\nindex 3a9a9154abe3..05382b855b19 100644\n--- a/tests/queries/0_stateless/00952_insert_into_distributed_with_materialized_column.sql\n+++ b/tests/queries/0_stateless/00952_insert_into_distributed_with_materialized_column.sql\n@@ -15,6 +15,7 @@ SET insert_allow_materialized_columns=0;\n SELECT 'insert_distributed_sync=0';\n SET insert_distributed_sync=0;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE local_00952 (date Date, value Date MATERIALIZED toDate('2017-08-01')) ENGINE = MergeTree(date, date, 8192);\n CREATE TABLE distributed_00952 AS local_00952 ENGINE = Distributed('test_cluster_two_shards', currentDatabase(), local_00952, rand());\n \ndiff --git a/tests/queries/0_stateless/00974_final_predicate_push_down.sql b/tests/queries/0_stateless/00974_final_predicate_push_down.sql\nindex 96bcbf9aae66..7a6378692f28 100644\n--- a/tests/queries/0_stateless/00974_final_predicate_push_down.sql\n+++ b/tests/queries/0_stateless/00974_final_predicate_push_down.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS test_00974;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test_00974\n (\n     date Date,\ndiff --git a/tests/queries/0_stateless/00981_in_subquery_with_tuple.sh b/tests/queries/0_stateless/00981_in_subquery_with_tuple.sh\nindex 99173062595f..a899886e4637 100755\n--- a/tests/queries/0_stateless/00981_in_subquery_with_tuple.sh\n+++ b/tests/queries/0_stateless/00981_in_subquery_with_tuple.sh\n@@ -5,7 +5,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n . \"$CURDIR\"/../shell_config.sh\n \n $CLICKHOUSE_CLIENT --query=\"DROP TABLE IF EXISTS bug\";\n-$CLICKHOUSE_CLIENT --query=\"CREATE TABLE bug (d Date, s String) ENGINE = MergeTree(d, s, 8192)\";\n+$CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 --query=\"CREATE TABLE bug (d Date, s String) ENGINE = MergeTree(d, s, 8192)\";\n $CLICKHOUSE_CLIENT --query=\"INSERT INTO bug VALUES ('2019-08-09', 'hello'), ('2019-08-10', 'world'), ('2019-08-11', 'world'), ('2019-08-12', 'hello')\";\n \n #SET force_primary_key = 1;\ndiff --git a/tests/queries/0_stateless/01008_materialized_view_henyihanwobushi.sql b/tests/queries/0_stateless/01008_materialized_view_henyihanwobushi.sql\nindex 8def546cd2ec..1e91f6daf65e 100644\n--- a/tests/queries/0_stateless/01008_materialized_view_henyihanwobushi.sql\n+++ b/tests/queries/0_stateless/01008_materialized_view_henyihanwobushi.sql\n@@ -2,6 +2,7 @@ DROP TABLE IF EXISTS foo;\n DROP TABLE IF EXISTS bar;\n DROP TABLE IF EXISTS view_foo_bar;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table foo (ddate Date, id Int64, n String) ENGINE = ReplacingMergeTree(ddate, (id), 8192);\n create table bar (ddate Date, id Int64, n String, foo_id Int64) ENGINE = ReplacingMergeTree(ddate, (id), 8192);\n insert into bar (id, n, foo_id) values (1, 'bar_n_1', 1);\ndiff --git a/tests/queries/0_stateless/01047_window_view_parser_inner_table.sql b/tests/queries/0_stateless/01047_window_view_parser_inner_table.sql\nindex 8b978e6094c6..2d9911287a3a 100644\n--- a/tests/queries/0_stateless/01047_window_view_parser_inner_table.sql\n+++ b/tests/queries/0_stateless/01047_window_view_parser_inner_table.sql\n@@ -2,6 +2,7 @@\n \n SET allow_experimental_window_view = 1;\n DROP DATABASE IF EXISTS test_01047;\n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE test_01047 ENGINE=Ordinary;\n \n DROP TABLE IF EXISTS test_01047.mt;\ndiff --git a/tests/queries/0_stateless/01048_window_view_parser.sql b/tests/queries/0_stateless/01048_window_view_parser.sql\nindex 95190ddafa11..4c329f99f6ee 100644\n--- a/tests/queries/0_stateless/01048_window_view_parser.sql\n+++ b/tests/queries/0_stateless/01048_window_view_parser.sql\n@@ -2,6 +2,7 @@\n \n SET allow_experimental_window_view = 1;\n DROP DATABASE IF EXISTS test_01048;\n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE test_01048 ENGINE=Ordinary;\n \n DROP TABLE IF EXISTS test_01048.mt;\ndiff --git a/tests/queries/0_stateless/01053_drop_database_mat_view.sql b/tests/queries/0_stateless/01053_drop_database_mat_view.sql\nindex 67a488f7245e..7651ac4885cb 100644\n--- a/tests/queries/0_stateless/01053_drop_database_mat_view.sql\n+++ b/tests/queries/0_stateless/01053_drop_database_mat_view.sql\n@@ -1,8 +1,10 @@\n -- Tags: no-parallel\n \n DROP DATABASE IF EXISTS some_tests;\n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE some_tests ENGINE=Ordinary; -- Different inner table name with Atomic\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table some_tests.my_table ENGINE = MergeTree(day, (day), 8192) as select today() as day, 'mystring' as str;\n show tables from some_tests;\n create materialized view some_tests.my_materialized_view ENGINE = MergeTree(day, (day), 8192) as select * from some_tests.my_table;\ndiff --git a/tests/queries/0_stateless/01053_ssd_dictionary.sh b/tests/queries/0_stateless/01053_ssd_dictionary.sh\nindex dc5002eaf173..cf1a55b29420 100755\n--- a/tests/queries/0_stateless/01053_ssd_dictionary.sh\n+++ b/tests/queries/0_stateless/01053_ssd_dictionary.sh\n@@ -8,7 +8,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n USER_FILES_PATH=$(clickhouse-client --query \"select _path,_file from file('nonexist.txt', 'CSV', 'val1 char')\" 2>&1 | grep Exception | awk '{gsub(\"/nonexist.txt\",\"\",$9); print $9}')\n \n-$CLICKHOUSE_CLIENT -n --query=\"\n+$CLICKHOUSE_CLIENT --allow_deprecated_database_ordinary=1 -n --query=\"\n   DROP DATABASE IF EXISTS 01053_db;\n \n   CREATE DATABASE 01053_db Engine = Ordinary;\ndiff --git a/tests/queries/0_stateless/01062_alter_on_mutataion_zookeeper_long.sql b/tests/queries/0_stateless/01062_alter_on_mutataion_zookeeper_long.sql\nindex aba84f43033a..3777ebb1af37 100644\n--- a/tests/queries/0_stateless/01062_alter_on_mutataion_zookeeper_long.sql\n+++ b/tests/queries/0_stateless/01062_alter_on_mutataion_zookeeper_long.sql\n@@ -61,6 +61,7 @@ DROP TABLE IF EXISTS test_alter_on_mutation;\n \n DROP TABLE IF EXISTS nested_alter;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE nested_alter (`d` Date, `k` UInt64, `i32` Int32, `dt` DateTime, `n.ui8` Array(UInt8), `n.s` Array(String), `n.d` Array(Date), `s` String DEFAULT '0') ENGINE = ReplicatedMergeTree('/clickhouse/tables/{database}/test_01062/nested_alter', 'r2', d, k, 8192);\n \n INSERT INTO nested_alter VALUES ('2015-01-01', 6,38,'2014-07-15 13:26:50',[10,20,30],['asd','qwe','qwe'],['2000-01-01','2000-01-01','2000-01-03'],'100500');\ndiff --git a/tests/queries/0_stateless/01071_prohibition_secondary_index_with_old_format_merge_tree.sql b/tests/queries/0_stateless/01071_prohibition_secondary_index_with_old_format_merge_tree.sql\nindex bbb607fe89f9..992973c97e8c 100644\n--- a/tests/queries/0_stateless/01071_prohibition_secondary_index_with_old_format_merge_tree.sql\n+++ b/tests/queries/0_stateless/01071_prohibition_secondary_index_with_old_format_merge_tree.sql\n@@ -1,5 +1,6 @@\n -- Tags: no-parallel\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE old_syntax_01071_test (date Date, id UInt8) ENGINE = MergeTree(date, id, 8192);\n ALTER TABLE old_syntax_01071_test ADD INDEX  id_minmax id TYPE minmax GRANULARITY 1; -- { serverError 36 }\n CREATE TABLE new_syntax_01071_test (date Date, id UInt8) ENGINE = MergeTree() ORDER BY id;\ndiff --git a/tests/queries/0_stateless/01076_predicate_optimizer_with_view.sql b/tests/queries/0_stateless/01076_predicate_optimizer_with_view.sql\nindex d652cbeea5dd..cfa25179d057 100644\n--- a/tests/queries/0_stateless/01076_predicate_optimizer_with_view.sql\n+++ b/tests/queries/0_stateless/01076_predicate_optimizer_with_view.sql\n@@ -1,6 +1,7 @@\n DROP TABLE IF EXISTS test;\n DROP TABLE IF EXISTS test_view;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test(date Date, id Int8, name String, value Int64) ENGINE = MergeTree(date, (id, date), 8192);\n CREATE VIEW test_view AS SELECT * FROM test;\n \ndiff --git a/tests/queries/0_stateless/01085_window_view_attach.sql b/tests/queries/0_stateless/01085_window_view_attach.sql\nindex 604bf5dd1989..bb47e0dc6b99 100644\n--- a/tests/queries/0_stateless/01085_window_view_attach.sql\n+++ b/tests/queries/0_stateless/01085_window_view_attach.sql\n@@ -3,6 +3,7 @@\n SET allow_experimental_window_view = 1;\n \n DROP DATABASE IF EXISTS test_01085;\n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE test_01085 ENGINE=Ordinary;\n \n DROP TABLE IF EXISTS test_01085.mt;\ndiff --git a/tests/queries/0_stateless/01086_window_view_cleanup.sh b/tests/queries/0_stateless/01086_window_view_cleanup.sh\nindex a7b976bf4e02..c85455616e1c 100755\n--- a/tests/queries/0_stateless/01086_window_view_cleanup.sh\n+++ b/tests/queries/0_stateless/01086_window_view_cleanup.sh\n@@ -5,7 +5,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n . \"$CURDIR\"/../shell_config.sh\n \n-$CLICKHOUSE_CLIENT --multiquery <<EOF\n+$CLICKHOUSE_CLIENT --allow_deprecated_database_ordinary=1 --multiquery <<EOF\n SET allow_experimental_window_view = 1;\n SET window_view_clean_interval = 1;\n \ndiff --git a/tests/queries/0_stateless/01089_alter_settings_old_format.sql b/tests/queries/0_stateless/01089_alter_settings_old_format.sql\nindex 15d3ac508cbb..7e7674f4d438 100644\n--- a/tests/queries/0_stateless/01089_alter_settings_old_format.sql\n+++ b/tests/queries/0_stateless/01089_alter_settings_old_format.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS old_format_mt;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE old_format_mt (\n   event_date Date,\n   key UInt64,\ndiff --git a/tests/queries/0_stateless/01101_prewhere_after_alter.sql b/tests/queries/0_stateless/01101_prewhere_after_alter.sql\nindex 11ebac7448df..976eb586a9a9 100644\n--- a/tests/queries/0_stateless/01101_prewhere_after_alter.sql\n+++ b/tests/queries/0_stateless/01101_prewhere_after_alter.sql\n@@ -1,6 +1,7 @@\n DROP TABLE IF EXISTS test_a;\n DROP TABLE IF EXISTS test_b;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test_a\n (\n     OldColumn String DEFAULT '',\ndiff --git a/tests/queries/0_stateless/01109_exchange_tables.sql b/tests/queries/0_stateless/01109_exchange_tables.sql\nindex 09edf4a1de4f..c118945887be 100644\n--- a/tests/queries/0_stateless/01109_exchange_tables.sql\n+++ b/tests/queries/0_stateless/01109_exchange_tables.sql\n@@ -29,10 +29,9 @@ SELECT * FROM t2;\n \n DROP DATABASE IF EXISTS test_01109_other_atomic;\n DROP DATABASE IF EXISTS test_01109_ordinary;\n-SET default_database_engine='Atomic';\n CREATE DATABASE test_01109_other_atomic;\n-SET default_database_engine='Ordinary';\n-CREATE DATABASE test_01109_ordinary;\n+set allow_deprecated_database_ordinary=1;\n+CREATE DATABASE test_01109_ordinary ENGINE=Ordinary;\n \n CREATE TABLE test_01109_other_atomic.t3 ENGINE=MergeTree() ORDER BY tuple()\n     AS SELECT rowNumberInAllBlocks() + (SELECT max((*,*).1.1) + 1 FROM (SELECT (*,) FROM t1 UNION ALL SELECT (*,) FROM t2)), *\ndiff --git a/tests/queries/0_stateless/01114_database_atomic.sh b/tests/queries/0_stateless/01114_database_atomic.sh\nindex b21f88ea2156..e31841b27a0c 100755\n--- a/tests/queries/0_stateless/01114_database_atomic.sh\n+++ b/tests/queries/0_stateless/01114_database_atomic.sh\n@@ -14,8 +14,8 @@ DROP DATABASE IF EXISTS test_01114_3;\n \"\n \n $CLICKHOUSE_CLIENT -q \"CREATE DATABASE test_01114_1 ENGINE=Atomic\"\n-$CLICKHOUSE_CLIENT --default_database_engine=Atomic -q \"CREATE DATABASE test_01114_2\"\n-$CLICKHOUSE_CLIENT --default_database_engine=Ordinary -q \"CREATE DATABASE test_01114_3\"\n+$CLICKHOUSE_CLIENT -q \"CREATE DATABASE test_01114_2\"\n+$CLICKHOUSE_CLIENT --allow_deprecated_database_ordinary=1 -q \"CREATE DATABASE test_01114_3 ENGINE=Ordinary\"\n \n $CLICKHOUSE_CLIENT --show_table_uuid_in_table_create_query_if_not_nil=0 -q \"SHOW CREATE DATABASE test_01114_1\"\n $CLICKHOUSE_CLIENT --show_table_uuid_in_table_create_query_if_not_nil=0 -q \"SHOW CREATE DATABASE test_01114_2\"\ndiff --git a/tests/queries/0_stateless/01125_generate_random_qoega.sql b/tests/queries/0_stateless/01125_generate_random_qoega.sql\nindex 7fb586ad2b5e..9088e411a80d 100644\n--- a/tests/queries/0_stateless/01125_generate_random_qoega.sql\n+++ b/tests/queries/0_stateless/01125_generate_random_qoega.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS mass_table_117;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE mass_table_117 (`dt` Date, `site_id` Int32, `site_key` String) ENGINE = MergeTree(dt, (site_id, site_key, dt), 8192);\n INSERT INTO mass_table_117 SELECT * FROM generateRandom('`dt` Date,`site_id` Int32,`site_key` String', 1, 10, 2) LIMIT 100;\n SELECT count(), sum(cityHash64(*)) FROM mass_table_117;\ndiff --git a/tests/queries/0_stateless/01126_month_partitioning_consistent_code.sql b/tests/queries/0_stateless/01126_month_partitioning_consistent_code.sql\nindex c9bfbbe5111b..f5f04178d5eb 100644\n--- a/tests/queries/0_stateless/01126_month_partitioning_consistent_code.sql\n+++ b/tests/queries/0_stateless/01126_month_partitioning_consistent_code.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS mt;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE mt (d Date, x UInt8) ENGINE = MergeTree(d, x, 8192);\n INSERT INTO mt VALUES (52392, 1), (62677, 2);\n DROP TABLE mt;\ndiff --git a/tests/queries/0_stateless/01127_month_partitioning_consistency_select.sql b/tests/queries/0_stateless/01127_month_partitioning_consistency_select.sql\nindex eb5ea091ca3b..2a1d04e60740 100644\n--- a/tests/queries/0_stateless/01127_month_partitioning_consistency_select.sql\n+++ b/tests/queries/0_stateless/01127_month_partitioning_consistency_select.sql\n@@ -1,6 +1,7 @@\n -- Tags: no-parallel\n \n DROP TABLE IF EXISTS mt;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE mt (d Date, x String) ENGINE = MergeTree(d, x, 8192);\n INSERT INTO mt VALUES ('2106-02-07', 'Hello'), ('1970-01-01', 'World');\n \ndiff --git a/tests/queries/0_stateless/01128_generate_random_nested.sql b/tests/queries/0_stateless/01128_generate_random_nested.sql\nindex 2af52e69893e..8098db894915 100644\n--- a/tests/queries/0_stateless/01128_generate_random_nested.sql\n+++ b/tests/queries/0_stateless/01128_generate_random_nested.sql\n@@ -1,4 +1,6 @@\n DROP TABLE IF EXISTS mass_table_312;\n+\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE mass_table_312 (d Date DEFAULT '2000-01-01', x UInt64, n Nested(a String, b String)) ENGINE = MergeTree(d, x, 1);\n INSERT INTO mass_table_312 SELECT * FROM generateRandom('`d` Date,`x` UInt64,`n.a` Array(String),`n.b` Array(String)', 1, 10, 2) LIMIT 100;\n \ndiff --git a/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.sql b/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.sql\nindex 16d3dc741138..7234cee96e0e 100644\n--- a/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.sql\n+++ b/tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.sql\n@@ -31,6 +31,7 @@ RENAME TABLE test_01148_atomic.rmt4 to test_01148_atomic.rmt3;\n SHOW CREATE TABLE test_01148_atomic.rmt3;\n \n DROP DATABASE IF EXISTS test_01148_ordinary;\n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE test_01148_ordinary ENGINE=Ordinary;\n RENAME TABLE test_01148_atomic.rmt3 to test_01148_ordinary.rmt3; -- { serverError 48 }\n DROP DATABASE test_01148_ordinary;\ndiff --git a/tests/queries/0_stateless/01155_rename_move_materialized_view.sql b/tests/queries/0_stateless/01155_rename_move_materialized_view.sql\nindex e0546ec8117f..b3234e03a8f6 100644\n--- a/tests/queries/0_stateless/01155_rename_move_materialized_view.sql\n+++ b/tests/queries/0_stateless/01155_rename_move_materialized_view.sql\n@@ -5,6 +5,7 @@ SET prefer_localhost_replica = 1;\n DROP DATABASE IF EXISTS test_01155_ordinary;\n DROP DATABASE IF EXISTS test_01155_atomic;\n \n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE test_01155_ordinary ENGINE=Ordinary;\n CREATE DATABASE test_01155_atomic ENGINE=Atomic;\n \n@@ -66,6 +67,7 @@ SELECT database, substr(name, 1, 10) FROM system.tables WHERE database like 'tes\n -- Move tables back\n RENAME DATABASE test_01155_ordinary TO test_01155_atomic;\n \n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE test_01155_ordinary ENGINE=Ordinary;\n SHOW CREATE DATABASE test_01155_atomic;\n \ndiff --git a/tests/queries/0_stateless/01162_strange_mutations.sh b/tests/queries/0_stateless/01162_strange_mutations.sh\nindex e480a653b74c..eea9ea5f7e5d 100755\n--- a/tests/queries/0_stateless/01162_strange_mutations.sh\n+++ b/tests/queries/0_stateless/01162_strange_mutations.sh\n@@ -28,15 +28,15 @@ do\n     $CLICKHOUSE_CLIENT -q \"CREATE TABLE test ENGINE=$engine AS SELECT number + 100 AS n, 0 AS test FROM numbers(50)\" 2>&1| grep -Ev \"Removing leftovers from table|removed by another replica\"\n     $CLICKHOUSE_CLIENT -q \"select count(), sum(n), sum(test) from test\"\n     if [[ $engine == *\"ReplicatedMergeTree\"* ]]; then\n-        $CLICKHOUSE_CLIENT --enable_positional_arguments 0 -q \"ALTER TABLE test\n-            UPDATE test = (SELECT groupArray(id) FROM t1)[n - 99] WHERE 1\" 2>&1| grep -Fa \"DB::Exception: \" | grep -Fv \"statement with subquery may be nondeterministic\"\n-        $CLICKHOUSE_CLIENT --enable_positional_arguments 0 --allow_nondeterministic_mutations=1 --mutations_sync=1 -q \"ALTER TABLE test\n+        $CLICKHOUSE_CLIENT -q \"ALTER TABLE test\n+            UPDATE test = (SELECT groupArray(id) FROM t1 GROUP BY 'dummy')[n - 99] WHERE 1\" 2>&1| grep -Fa \"DB::Exception: \" | grep -Fv \"statement with subquery may be nondeterministic\"\n+        $CLICKHOUSE_CLIENT --allow_nondeterministic_mutations=1 --mutations_sync=1 -q \"ALTER TABLE test\n                     UPDATE test = (SELECT groupArray(id) FROM t1)[n - 99] WHERE 1\"\n     elif [[ $engine == *\"Join\"* ]]; then\n-        $CLICKHOUSE_CLIENT --enable_positional_arguments 0 -q \"ALTER TABLE test\n+        $CLICKHOUSE_CLIENT -q \"ALTER TABLE test\n             UPDATE test = (SELECT groupArray(id) FROM t1)[n - 99] WHERE 1\" 2>&1| grep -Fa \"DB::Exception: \" | grep -Fv \"Table engine Join supports only DELETE mutations\"\n     else\n-        $CLICKHOUSE_CLIENT --enable_positional_arguments 0 --mutations_sync=1 -q \"ALTER TABLE test\n+        $CLICKHOUSE_CLIENT --mutations_sync=1 -q \"ALTER TABLE test\n             UPDATE test = (SELECT groupArray(id) FROM t1)[n - 99] WHERE 1\"\n     fi\n     $CLICKHOUSE_CLIENT -q \"select count(), sum(n), sum(test) from test\"\ndiff --git a/tests/queries/0_stateless/01190_full_attach_syntax.sql b/tests/queries/0_stateless/01190_full_attach_syntax.sql\nindex ed05950ff983..e66978e22e1d 100644\n--- a/tests/queries/0_stateless/01190_full_attach_syntax.sql\n+++ b/tests/queries/0_stateless/01190_full_attach_syntax.sql\n@@ -1,6 +1,8 @@\n -- Tags: no-parallel\n \n DROP DATABASE IF EXISTS test_01190;\n+set allow_deprecated_database_ordinary=1;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE DATABASE test_01190 ENGINE=Ordinary;     -- Full ATTACH requires UUID with Atomic\n USE test_01190;\n \ndiff --git a/tests/queries/0_stateless/01192_rename_database_zookeeper.sh b/tests/queries/0_stateless/01192_rename_database_zookeeper.sh\nindex c6686bde6723..641e26870d4d 100755\n--- a/tests/queries/0_stateless/01192_rename_database_zookeeper.sh\n+++ b/tests/queries/0_stateless/01192_rename_database_zookeeper.sh\n@@ -11,8 +11,8 @@ $CLICKHOUSE_CLIENT --check_table_dependencies=0 -q \"DROP DATABASE IF EXISTS test\n $CLICKHOUSE_CLIENT --check_table_dependencies=0 -q \"DROP DATABASE IF EXISTS test_01192_renamed\"\n $CLICKHOUSE_CLIENT --check_table_dependencies=0 -q \"DROP DATABASE IF EXISTS test_01192_atomic\"\n \n-$CLICKHOUSE_CLIENT --default_database_engine=Ordinary -q \"CREATE DATABASE test_01192 UUID '00001192-0000-4000-8000-000000000001'\" 2>&1| grep -F \"does not support\" > /dev/null && echo \"ok\"\n-$CLICKHOUSE_CLIENT --default_database_engine=Atomic -q \"CREATE DATABASE test_01192 UUID '00001192-0000-4000-8000-000000000001'\"\n+$CLICKHOUSE_CLIENT --allow_deprecated_database_ordinary=1 -q \"CREATE DATABASE test_01192 UUID '00001192-0000-4000-8000-000000000001' ENGINE=Ordinary\" 2>&1| grep -F \"does not support\" > /dev/null && echo \"ok\"\n+$CLICKHOUSE_CLIENT -q \"CREATE DATABASE test_01192 UUID '00001192-0000-4000-8000-000000000001'\"\n \n # 2. check metadata\n $CLICKHOUSE_CLIENT --show_table_uuid_in_table_create_query_if_not_nil=1 -q \"SHOW CREATE DATABASE test_01192\"\n@@ -35,14 +35,14 @@ $CLICKHOUSE_CLIENT -q \"SHOW CREATE DATABASE test_01192_renamed\"\n $CLICKHOUSE_CLIENT -q \"SELECT count(n), sum(n) FROM test_01192_renamed.mt\"\n \n # 5. check moving tables from Ordinary to Atomic (can be used to \"alter\" database engine)\n-$CLICKHOUSE_CLIENT --default_database_engine=Ordinary -q \"CREATE DATABASE test_01192\"\n+$CLICKHOUSE_CLIENT --allow_deprecated_database_ordinary=1 -q \"CREATE DATABASE test_01192 ENGINE=Ordinary\"\n $CLICKHOUSE_CLIENT -q \"CREATE TABLE test_01192.mt AS test_01192_renamed.mt ENGINE=MergeTree ORDER BY n\"\n $CLICKHOUSE_CLIENT -q \"CREATE TABLE test_01192.rmt AS test_01192_renamed.mt ENGINE=ReplicatedMergeTree('/test/$CLICKHOUSE_TEST_ZOOKEEPER_PREFIX/', '1') ORDER BY n\"\n $CLICKHOUSE_CLIENT -q \"CREATE MATERIALIZED VIEW test_01192.mv TO test_01192.rmt AS SELECT * FROM test_01192.mt\"\n \n $CLICKHOUSE_CLIENT -q \"INSERT INTO test_01192.mt SELECT number FROM numbers(10)\" && echo \"inserted\"\n \n-$CLICKHOUSE_CLIENT --default_database_engine=Atomic -q \"CREATE DATABASE test_01192_atomic\"\n+$CLICKHOUSE_CLIENT -q \"CREATE DATABASE test_01192_atomic\"\n $CLICKHOUSE_CLIENT -q \"DROP DATABASE test_01192_renamed\"\n # it's blocking\n $CLICKHOUSE_CLIENT -q \"RENAME TABLE test_01192.mt TO test_01192_atomic.mt, test_01192.rmt TO test_01192_atomic.rmt, test_01192.mv TO test_01192_atomic.mv\" && echo \"renamed\"\ndiff --git a/tests/queries/0_stateless/01224_no_superfluous_dict_reload.sql b/tests/queries/0_stateless/01224_no_superfluous_dict_reload.sql\nindex 6f5deb91ee46..5db92e706509 100644\n--- a/tests/queries/0_stateless/01224_no_superfluous_dict_reload.sql\n+++ b/tests/queries/0_stateless/01224_no_superfluous_dict_reload.sql\n@@ -2,6 +2,7 @@\n \n DROP DATABASE IF EXISTS dict_db_01224;\n DROP DATABASE IF EXISTS dict_db_01224_dictionary;\n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE dict_db_01224 ENGINE=Ordinary;  -- Different internal dictionary name with Atomic\n CREATE DATABASE dict_db_01224_dictionary Engine=Dictionary;\n \ndiff --git a/tests/queries/0_stateless/01225_show_create_table_from_dictionary.sql b/tests/queries/0_stateless/01225_show_create_table_from_dictionary.sql\nindex 006ff952ee9a..09cde642ed22 100644\n--- a/tests/queries/0_stateless/01225_show_create_table_from_dictionary.sql\n+++ b/tests/queries/0_stateless/01225_show_create_table_from_dictionary.sql\n@@ -2,6 +2,7 @@\n \n DROP DATABASE IF EXISTS dict_db_01225;\n DROP DATABASE IF EXISTS dict_db_01225_dictionary;\n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE dict_db_01225 ENGINE=Ordinary;    -- Different internal dictionary name with Atomic\n CREATE DATABASE dict_db_01225_dictionary Engine=Dictionary;\n \ndiff --git a/tests/queries/0_stateless/01233_check_table_with_metadata_cache.sh b/tests/queries/0_stateless/01233_check_table_with_metadata_cache.sh\nindex 68b62b623515..8736bc474b15 100755\n--- a/tests/queries/0_stateless/01233_check_table_with_metadata_cache.sh\n+++ b/tests/queries/0_stateless/01233_check_table_with_metadata_cache.sh\n@@ -24,7 +24,7 @@ for table_engine in \"${table_engines[@]}\"; do\n \n                     ${CLICKHOUSE_CLIENT} --query \"DROP TABLE IF EXISTS test_metadata_cache.check_part_metadata_cache SYNC;\"\n                     ${CLICKHOUSE_CLIENT} --query \"DROP DATABASE IF EXISTS test_metadata_cache;\"\n-                    ${CLICKHOUSE_CLIENT} --query \"CREATE DATABASE test_metadata_cache ENGINE = ${database_engine};\"\n+                    ${CLICKHOUSE_CLIENT} --allow_deprecated_database_ordinary=1 --query \"CREATE DATABASE test_metadata_cache ENGINE = ${database_engine};\"\n \n                     table_engine_clause=\"\"\n                     if [[ \"$table_engine\" == \"ReplicatedMergeTree\" ]]; then\ndiff --git a/tests/queries/0_stateless/01249_bad_arguments_for_bloom_filter.sql b/tests/queries/0_stateless/01249_bad_arguments_for_bloom_filter.sql\nindex c2be4d04e5f2..d187a2e4d4ec 100644\n--- a/tests/queries/0_stateless/01249_bad_arguments_for_bloom_filter.sql\n+++ b/tests/queries/0_stateless/01249_bad_arguments_for_bloom_filter.sql\n@@ -1,6 +1,7 @@\n -- Tags: no-parallel\n \n DROP DATABASE IF EXISTS test_01249;\n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE test_01249 ENGINE=Ordinary;     -- Full ATTACH requires UUID with Atomic\n USE test_01249;\n \ndiff --git a/tests/queries/0_stateless/01253_subquery_in_aggregate_function_JustStranger.sql b/tests/queries/0_stateless/01253_subquery_in_aggregate_function_JustStranger.sql\nindex 9659db7973dd..97b0182f06f3 100644\n--- a/tests/queries/0_stateless/01253_subquery_in_aggregate_function_JustStranger.sql\n+++ b/tests/queries/0_stateless/01253_subquery_in_aggregate_function_JustStranger.sql\n@@ -1,6 +1,7 @@\n DROP TABLE IF EXISTS test_table;\n DROP TABLE IF EXISTS test_table_sharded;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table\n   test_table_sharded(\n     date Date,\ndiff --git a/tests/queries/0_stateless/01280_ssd_complex_key_dictionary.sh b/tests/queries/0_stateless/01280_ssd_complex_key_dictionary.sh\nindex 0de8b3a1a25f..28e8e8386cf2 100755\n--- a/tests/queries/0_stateless/01280_ssd_complex_key_dictionary.sh\n+++ b/tests/queries/0_stateless/01280_ssd_complex_key_dictionary.sh\n@@ -8,6 +8,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n USER_FILES_PATH=$(clickhouse-client --query \"select _path,_file from file('nonexist.txt', 'CSV', 'val1 char')\" 2>&1 | grep Exception | awk '{gsub(\"/nonexist.txt\",\"\",$9); print $9}')\n \n $CLICKHOUSE_CLIENT -n --query=\"\n+    set allow_deprecated_database_ordinary=1;\n     DROP DATABASE IF EXISTS 01280_db;\n     CREATE DATABASE 01280_db Engine = Ordinary;\n     DROP TABLE IF EXISTS 01280_db.table_for_dict;\ndiff --git a/tests/queries/0_stateless/01297_alter_distributed.sql b/tests/queries/0_stateless/01297_alter_distributed.sql\nindex cec64278d478..c79d98b7b3bf 100644\n--- a/tests/queries/0_stateless/01297_alter_distributed.sql\n+++ b/tests/queries/0_stateless/01297_alter_distributed.sql\n@@ -3,6 +3,7 @@\n drop table if exists merge_distributed;\n drop table if exists merge_distributed1;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table merge_distributed1 ( CounterID UInt32,  StartDate Date,  Sign Int8,  VisitID UInt64,  UserID UInt64,  StartTime DateTime,   ClickLogID UInt64) ENGINE = CollapsingMergeTree(StartDate, intHash32(UserID), tuple(CounterID, StartDate, intHash32(UserID), VisitID, ClickLogID), 8192, Sign);\n insert into merge_distributed1 values (1, '2013-09-19', 1, 0, 2, '2013-09-19 12:43:06', 3);\n \ndiff --git a/tests/queries/0_stateless/01298_alter_merge.sql b/tests/queries/0_stateless/01298_alter_merge.sql\nindex 86c89c38c8ce..24547086e0b6 100644\n--- a/tests/queries/0_stateless/01298_alter_merge.sql\n+++ b/tests/queries/0_stateless/01298_alter_merge.sql\n@@ -2,6 +2,7 @@ drop table if exists merge;\n drop table if exists merge1;\n drop table if exists merge2;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table merge1 ( CounterID UInt32,  StartDate Date,  Sign Int8,  VisitID UInt64,  UserID UInt64,  StartTime DateTime,   ClickLogID UInt64) ENGINE = CollapsingMergeTree(StartDate, intHash32(UserID), tuple(CounterID, StartDate, intHash32(UserID), VisitID, ClickLogID), 8192, Sign);\n insert into merge1 values (1, '2013-09-19', 1, 0, 2, '2013-09-19 12:43:06', 3);\n \ndiff --git a/tests/queries/0_stateless/01299_alter_merge_tree.sql b/tests/queries/0_stateless/01299_alter_merge_tree.sql\nindex 87608e6d15a8..3c4467926f85 100644\n--- a/tests/queries/0_stateless/01299_alter_merge_tree.sql\n+++ b/tests/queries/0_stateless/01299_alter_merge_tree.sql\n@@ -1,5 +1,6 @@\n drop table if exists merge_tree;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n create table merge_tree ( CounterID UInt32,  StartDate Date,  Sign Int8,  VisitID UInt64,  UserID UInt64,  StartTime DateTime,   ClickLogID UInt64) ENGINE = CollapsingMergeTree(StartDate, intHash32(UserID), tuple(CounterID, StartDate, intHash32(UserID), VisitID, ClickLogID), 8192, Sign);\n \n insert into merge_tree values (1, '2013-09-19', 1, 0, 2, '2013-09-19 12:43:06', 3)\ndiff --git a/tests/queries/0_stateless/01320_create_sync_race_condition_zookeeper.sh b/tests/queries/0_stateless/01320_create_sync_race_condition_zookeeper.sh\nindex 758ec4825e0d..ef45e8e63bc6 100755\n--- a/tests/queries/0_stateless/01320_create_sync_race_condition_zookeeper.sh\n+++ b/tests/queries/0_stateless/01320_create_sync_race_condition_zookeeper.sh\n@@ -8,7 +8,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n set -e\n \n $CLICKHOUSE_CLIENT --query \"DROP DATABASE IF EXISTS test_01320\"\n-$CLICKHOUSE_CLIENT --query \"CREATE DATABASE test_01320 ENGINE=Ordinary\"   # Different bahaviour of DROP with Atomic\n+$CLICKHOUSE_CLIENT --allow_deprecated_database_ordinary=1 --query \"CREATE DATABASE test_01320 ENGINE=Ordinary\"   # Different bahaviour of DROP with Atomic\n \n function thread1()\n {\ndiff --git a/tests/queries/0_stateless/01355_alter_column_with_order.sql b/tests/queries/0_stateless/01355_alter_column_with_order.sql\nindex c0c85e389ea8..0b1b4c42ccee 100644\n--- a/tests/queries/0_stateless/01355_alter_column_with_order.sql\n+++ b/tests/queries/0_stateless/01355_alter_column_with_order.sql\n@@ -2,6 +2,7 @@\n \n DROP TABLE IF EXISTS alter_test;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE alter_test (CounterID UInt32, StartDate Date, UserID UInt32, VisitID UInt32, NestedColumn Nested(A UInt8, S String), ToDrop UInt32) ENGINE = MergeTree(StartDate, intHash32(UserID), (CounterID, StartDate, intHash32(UserID), VisitID), 8192);\n \n ALTER TABLE alter_test ADD COLUMN Added1 UInt32 FIRST;\ndiff --git a/tests/queries/0_stateless/01387_clear_column_default_depends.sql b/tests/queries/0_stateless/01387_clear_column_default_depends.sql\nindex 21a41f09df6c..733daafa91c8 100644\n--- a/tests/queries/0_stateless/01387_clear_column_default_depends.sql\n+++ b/tests/queries/0_stateless/01387_clear_column_default_depends.sql\n@@ -31,6 +31,7 @@ DROP TABLE test;\n \n -- The original report from Mikhail Petrov\n DROP TABLE IF EXISTS Test;\n+set allow_deprecated_syntax_for_merge_tree=1;\n create table Test (impression_id String,impression_id_compressed FixedString(16) DEFAULT UUIDStringToNum(substring(impression_id, 1, 36)), impression_id_hashed UInt16 DEFAULT reinterpretAsUInt16(impression_id_compressed), event_date Date ) ENGINE = MergeTree(event_date, impression_id_hashed, (event_date, impression_id_hashed), 8192);\n alter table Test clear column impression_id in partition '202001';\n DROP TABLE Test;\ndiff --git a/tests/queries/0_stateless/01417_freeze_partition_verbose.sh b/tests/queries/0_stateless/01417_freeze_partition_verbose.sh\nindex 1f67100a4b67..12f104b53379 100755\n--- a/tests/queries/0_stateless/01417_freeze_partition_verbose.sh\n+++ b/tests/queries/0_stateless/01417_freeze_partition_verbose.sh\n@@ -17,7 +17,7 @@ ${CLICKHOUSE_CLIENT} --query \"INSERT INTO table_for_freeze SELECT number, toStri\n \n # also for old syntax\n ${CLICKHOUSE_CLIENT} --query \"DROP TABLE IF EXISTS table_for_freeze_old_syntax;\"\n-${CLICKHOUSE_CLIENT} --query \"CREATE TABLE table_for_freeze_old_syntax (dt Date, value String) ENGINE = MergeTree(dt, (value), 8192);\"\n+${CLICKHOUSE_CLIENT} --allow_deprecated_syntax_for_merge_tree=1 --query \"CREATE TABLE table_for_freeze_old_syntax (dt Date, value String) ENGINE = MergeTree(dt, (value), 8192);\"\n ${CLICKHOUSE_CLIENT} --query \"INSERT INTO table_for_freeze_old_syntax SELECT toDate('2021-03-01'), toString(number) from numbers(10);\"\n \n ${CLICKHOUSE_CLIENT} --query \"ALTER TABLE table_for_freeze FREEZE WITH NAME 'test_01417' FORMAT TSVWithNames SETTINGS alter_partition_verbose_result = 1;\" \\\ndiff --git a/tests/queries/0_stateless/01430_modify_sample_by_zookeeper_long.sql b/tests/queries/0_stateless/01430_modify_sample_by_zookeeper_long.sql\nindex 223c27804df2..752bc6b377fb 100644\n--- a/tests/queries/0_stateless/01430_modify_sample_by_zookeeper_long.sql\n+++ b/tests/queries/0_stateless/01430_modify_sample_by_zookeeper_long.sql\n@@ -37,6 +37,7 @@ ATTACH TABLE modify_sample_replicated;\n \n SELECT count(), min(y), max(y), sum(y), uniqExact(y) FROM modify_sample_replicated SAMPLE 0.1;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE modify_sample_old (d Date DEFAULT '2000-01-01', x UInt8, y UInt64) ENGINE = MergeTree(d, (x, y), 8192);\n \n ALTER TABLE modify_sample_old MODIFY SAMPLE BY x; -- { serverError 36 }\ndiff --git a/tests/queries/0_stateless/01455_shard_leaf_max_rows_bytes_to_read.sql b/tests/queries/0_stateless/01455_shard_leaf_max_rows_bytes_to_read.sql\nindex a271295a0cd0..620daeb9f358 100644\n--- a/tests/queries/0_stateless/01455_shard_leaf_max_rows_bytes_to_read.sql\n+++ b/tests/queries/0_stateless/01455_shard_leaf_max_rows_bytes_to_read.sql\n@@ -20,6 +20,7 @@ SELECT count() FROM (SELECT * FROM remote('127.0.0.2', system.numbers) LIMIT 100\n DROP TABLE IF EXISTS test_local;\n DROP TABLE IF EXISTS test_distributed;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test_local (date Date, value UInt32) ENGINE = MergeTree(date, date, 8192);\n CREATE TABLE test_distributed AS test_local ENGINE = Distributed(test_cluster_two_shards, currentDatabase(), test_local, rand());\n \ndiff --git a/tests/queries/0_stateless/01516_create_table_primary_key.sql b/tests/queries/0_stateless/01516_create_table_primary_key.sql\nindex b3c4acd50ffa..b2b9f288eab1 100644\n--- a/tests/queries/0_stateless/01516_create_table_primary_key.sql\n+++ b/tests/queries/0_stateless/01516_create_table_primary_key.sql\n@@ -1,6 +1,7 @@\n -- Tags: no-parallel\n \n DROP DATABASE IF EXISTS test_01516;\n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE test_01516 ENGINE=Ordinary;     -- Full ATTACH requires UUID with Atomic\n USE test_01516;\n \ndiff --git a/tests/queries/0_stateless/01517_drop_mv_with_inner_table.sql b/tests/queries/0_stateless/01517_drop_mv_with_inner_table.sql\nindex 5e31faa70da1..67a2009b913c 100644\n--- a/tests/queries/0_stateless/01517_drop_mv_with_inner_table.sql\n+++ b/tests/queries/0_stateless/01517_drop_mv_with_inner_table.sql\n@@ -32,6 +32,7 @@ show tables from db_01517_atomic_sync;\n -- Ordinary\n ---\n drop database if exists db_01517_ordinary;\n+set allow_deprecated_database_ordinary=1;\n create database db_01517_ordinary Engine=Ordinary;\n \n create table db_01517_ordinary.source (key Int) engine=Null;\ndiff --git a/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.sh b/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.sh\nindex 95ecbf09cf54..538d712ad9cf 100755\n--- a/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.sh\n+++ b/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.sh\n@@ -8,7 +8,7 @@ WORKING_FOLDER_01528=\"${CLICKHOUSE_TMP}/01528_clickhouse_local_prepare_parts\"\n rm -rf \"${WORKING_FOLDER_01528}\"\n \n mkdir -p \"${WORKING_FOLDER_01528}/metadata/local\"\n-\n+echo \"ATTACH DATABASE local ENGINE=Ordinary\" > \"${WORKING_FOLDER_01528}/metadata/local.sql\"\n ## Checks scenario of preparing parts offline by clickhouse-local\n \n ## that is the metadata for the table we want to fill\ndiff --git a/tests/queries/0_stateless/01600_detach_permanently.sh b/tests/queries/0_stateless/01600_detach_permanently.sh\nindex 949fe0e6ea27..c32a255448e0 100755\n--- a/tests/queries/0_stateless/01600_detach_permanently.sh\n+++ b/tests/queries/0_stateless/01600_detach_permanently.sh\n@@ -15,7 +15,7 @@ mkdir -p \"${WORKING_FOLDER_01600}\"\n clickhouse_local() {\n     local query=\"$1\"\n     shift\n-    ${CLICKHOUSE_LOCAL} --query \"$query\" \"$@\" --path=\"${WORKING_FOLDER_01600}\"\n+    ${CLICKHOUSE_LOCAL} --allow_deprecated_database_ordinary=1 --query \"$query\" \"$@\" --path=\"${WORKING_FOLDER_01600}\"\n }\n \n test_detach_attach_sequence() {\ndiff --git a/tests/queries/0_stateless/01601_detach_permanently.sql b/tests/queries/0_stateless/01601_detach_permanently.sql\nindex 97797a59af55..95c80e77213e 100644\n--- a/tests/queries/0_stateless/01601_detach_permanently.sql\n+++ b/tests/queries/0_stateless/01601_detach_permanently.sql\n@@ -72,6 +72,7 @@ SELECT '-----------------------';\n SELECT 'database ordinary tests';\n \n DROP DATABASE IF EXISTS test1601_detach_permanently_ordinary;\n+set allow_deprecated_database_ordinary=1;\n CREATE DATABASE test1601_detach_permanently_ordinary Engine=Ordinary;\n \n create table test1601_detach_permanently_ordinary.test_name_reuse (number UInt64) engine=MergeTree order by tuple();\ndiff --git a/tests/queries/0_stateless/01603_rename_overwrite_bug.sql b/tests/queries/0_stateless/01603_rename_overwrite_bug.sql\nindex 82f9996991f9..acf9f5207092 100644\n--- a/tests/queries/0_stateless/01603_rename_overwrite_bug.sql\n+++ b/tests/queries/0_stateless/01603_rename_overwrite_bug.sql\n@@ -1,6 +1,7 @@\n -- Tags: no-parallel\n \n DROP database IF EXISTS test_1603_rename_bug_ordinary;\n+set allow_deprecated_database_ordinary=1;\n create database test_1603_rename_bug_ordinary engine=Ordinary;\n create table test_1603_rename_bug_ordinary.foo engine=Memory as select * from numbers(100);\n create table test_1603_rename_bug_ordinary.bar engine=Log as select * from numbers(200);\ndiff --git a/tests/queries/0_stateless/01648_mutations_and_escaping.sql b/tests/queries/0_stateless/01648_mutations_and_escaping.sql\nindex 689da842f163..18bd0b8ee3b6 100644\n--- a/tests/queries/0_stateless/01648_mutations_and_escaping.sql\n+++ b/tests/queries/0_stateless/01648_mutations_and_escaping.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS mutations_and_escaping_1648;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE mutations_and_escaping_1648 (d Date, e Enum8('foo'=1, 'bar'=2)) Engine = MergeTree(d, (d), 8192);\n INSERT INTO mutations_and_escaping_1648 (d, e) VALUES ('2018-01-01', 'foo');\n INSERT INTO mutations_and_escaping_1648 (d, e) VALUES ('2018-01-02', 'bar');\ndiff --git a/tests/queries/0_stateless/01652_ttl_old_syntax.sql b/tests/queries/0_stateless/01652_ttl_old_syntax.sql\nindex 05c391b85e5e..7b11247d9686 100644\n--- a/tests/queries/0_stateless/01652_ttl_old_syntax.sql\n+++ b/tests/queries/0_stateless/01652_ttl_old_syntax.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS ttl_old_syntax;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE ttl_old_syntax (d Date, i Int) ENGINE = MergeTree(d, i, 8291);\n ALTER TABLE ttl_old_syntax MODIFY TTL toDate('2020-01-01'); -- { serverError 36 }\n \ndiff --git a/tests/queries/0_stateless/01713_table_ttl_old_syntax_zookeeper.sql b/tests/queries/0_stateless/01713_table_ttl_old_syntax_zookeeper.sql\nindex 1709a2d412a5..11346a812f23 100644\n--- a/tests/queries/0_stateless/01713_table_ttl_old_syntax_zookeeper.sql\n+++ b/tests/queries/0_stateless/01713_table_ttl_old_syntax_zookeeper.sql\n@@ -2,6 +2,7 @@\n \n DROP TABLE IF EXISTS ttl_table;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE ttl_table\n (\n     date Date,\ndiff --git a/tests/queries/0_stateless/01778_test_LowCardinality_FixedString_pk.sql b/tests/queries/0_stateless/01778_test_LowCardinality_FixedString_pk.sql\nindex 1a0a1d35f763..78a9b35a40e6 100644\n--- a/tests/queries/0_stateless/01778_test_LowCardinality_FixedString_pk.sql\n+++ b/tests/queries/0_stateless/01778_test_LowCardinality_FixedString_pk.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS test_01778;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test_01778\n (\n     `key` LowCardinality(FixedString(3)),\ndiff --git a/tests/queries/0_stateless/01798_uniq_theta_sketch.sql b/tests/queries/0_stateless/01798_uniq_theta_sketch.sql\nindex eace83d5cfa0..59d5888c0a11 100644\n--- a/tests/queries/0_stateless/01798_uniq_theta_sketch.sql\n+++ b/tests/queries/0_stateless/01798_uniq_theta_sketch.sql\n@@ -107,6 +107,7 @@ EXPLAIN SYNTAX select uniqTheta(-bitNot(-x)) from (select number % 2 as x from n\n DROP TABLE IF EXISTS stored_aggregates;\n \n -- simple\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE stored_aggregates\n (\n     d Date,\ndiff --git a/tests/queries/0_stateless/01810_max_part_removal_threads_long.sh b/tests/queries/0_stateless/01810_max_part_removal_threads_long.sh\nindex f5ab71d8d348..b1f30a419247 100755\n--- a/tests/queries/0_stateless/01810_max_part_removal_threads_long.sh\n+++ b/tests/queries/0_stateless/01810_max_part_removal_threads_long.sh\n@@ -10,7 +10,7 @@ CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n . \"$CUR_DIR\"/../shell_config.sh\n \n-$CLICKHOUSE_CLIENT -nm -q \"create database ordinary_$CLICKHOUSE_DATABASE engine=Ordinary\"\n+$CLICKHOUSE_CLIENT --allow_deprecated_database_ordinary=1 -nm -q \"create database ordinary_$CLICKHOUSE_DATABASE engine=Ordinary\"\n \n # MergeTree\n $CLICKHOUSE_CLIENT -nm -q \"\"\"\ndiff --git a/tests/queries/0_stateless/01907_multiple_aliases.sql b/tests/queries/0_stateless/01907_multiple_aliases.sql\nindex 611960a52052..5e8efba7ab7a 100644\n--- a/tests/queries/0_stateless/01907_multiple_aliases.sql\n+++ b/tests/queries/0_stateless/01907_multiple_aliases.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS t;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE t (d Date, z UInt32) ENGINE = MergeTree(d, (z), 1);\n \n INSERT INTO t VALUES ('2017-01-01', 1);\ndiff --git a/tests/queries/0_stateless/01925_broken_partition_id_zookeeper.sql b/tests/queries/0_stateless/01925_broken_partition_id_zookeeper.sql\nindex 7d151f063e1c..9c6aa3146ee4 100644\n--- a/tests/queries/0_stateless/01925_broken_partition_id_zookeeper.sql\n+++ b/tests/queries/0_stateless/01925_broken_partition_id_zookeeper.sql\n@@ -19,6 +19,7 @@ DROP TABLE IF EXISTS broken_partition;\n \n DROP TABLE IF EXISTS old_partition_key;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE old_partition_key (sd Date, dh UInt64, ak UInt32, ed Date) ENGINE=MergeTree(sd, dh, (ak, ed, dh), 8192);\n \n ALTER TABLE old_partition_key DROP PARTITION ID '20210325_0_13241_6_12747'; --{serverError 248}\ndiff --git a/tests/queries/0_stateless/02021_create_database_with_comment.sh b/tests/queries/0_stateless/02021_create_database_with_comment.sh\nindex ce7a7bef0661..11e62e790b7b 100755\n--- a/tests/queries/0_stateless/02021_create_database_with_comment.sh\n+++ b/tests/queries/0_stateless/02021_create_database_with_comment.sh\n@@ -18,7 +18,7 @@ function test_db_comments()\n     local ENGINE_NAME=\"$1\"\n     echo \"engine : ${ENGINE_NAME}\"\n \n-    $CLICKHOUSE_CLIENT -nm <<EOF\n+    $CLICKHOUSE_CLIENT --allow_deprecated_database_ordinary=1 -nm <<EOF\n DROP DATABASE IF EXISTS ${DB_NAME};\n CREATE DATABASE ${DB_NAME} ENGINE = ${ENGINE_NAME} COMMENT 'Test DB with comment';\n EOF\ndiff --git a/tests/queries/0_stateless/02096_rename_atomic_hang.sql b/tests/queries/0_stateless/02096_rename_atomic_hang.sql\nindex 96261bfe127c..dec5f3f95067 100644\n--- a/tests/queries/0_stateless/02096_rename_atomic_hang.sql\n+++ b/tests/queries/0_stateless/02096_rename_atomic_hang.sql\n@@ -2,6 +2,7 @@\n \n drop database if exists db_hang;\n drop database if exists db_hang_temp;\n+set allow_deprecated_database_ordinary=1;\n create database db_hang engine=Ordinary;\n use db_hang;\n create table db_hang.test(A Int64) Engine=MergeTree order by A;\ndiff --git a/tests/queries/0_stateless/02135_local_create_db.sh b/tests/queries/0_stateless/02135_local_create_db.sh\nindex 2a0105e554e1..5004cd35f993 100755\n--- a/tests/queries/0_stateless/02135_local_create_db.sh\n+++ b/tests/queries/0_stateless/02135_local_create_db.sh\n@@ -5,7 +5,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n . \"$CURDIR\"/../shell_config.sh\n \n for Engine in Atomic Ordinary; do\n-    $CLICKHOUSE_LOCAL --query \"\"\"\n+    $CLICKHOUSE_LOCAL --allow_deprecated_database_ordinary=1 --query \"\"\"\n     CREATE DATABASE foo_$Engine Engine=$Engine;\n     DROP DATABASE foo_$Engine;\n     \"\"\"\ndiff --git a/tests/queries/0_stateless/02250_hints_for_columns.sh b/tests/queries/0_stateless/02250_hints_for_columns.sh\nindex 45fd2f238b1d..ea08d8c55351 100755\n--- a/tests/queries/0_stateless/02250_hints_for_columns.sh\n+++ b/tests/queries/0_stateless/02250_hints_for_columns.sh\n@@ -6,7 +6,7 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n \n $CLICKHOUSE_CLIENT --query=\"DROP TABLE IF EXISTS t\"\n \n-$CLICKHOUSE_CLIENT --query=\"CREATE TABLE t (CounterID UInt32, StartDate Date, UserID UInt32, VisitID UInt32, NestedColumn Nested(A UInt8, S String), ToDrop UInt32) ENGINE = MergeTree(StartDate, intHash32(UserID), (CounterID, StartDate, intHash32(UserID), VisitID), 8192)\"\n+$CLICKHOUSE_CLIENT --allow_deprecated_syntax_for_merge_tree=1 --query=\"CREATE TABLE t (CounterID UInt32, StartDate Date, UserID UInt32, VisitID UInt32, NestedColumn Nested(A UInt8, S String), ToDrop UInt32) ENGINE = MergeTree(StartDate, intHash32(UserID), (CounterID, StartDate, intHash32(UserID), VisitID), 8192)\"\n \n $CLICKHOUSE_CLIENT --query=\"ALTER TABLE t DROP COLUMN ToDro\" 2>&1 | grep -q \"Maybe you meant: \\['ToDrop'\\]\" && echo 'OK' || echo 'FAIL'\n \ndiff --git a/tests/queries/0_stateless/02265_rename_join_ordinary_to_atomic.sql b/tests/queries/0_stateless/02265_rename_join_ordinary_to_atomic.sql\nindex 3ec995a6a245..041cb8876479 100644\n--- a/tests/queries/0_stateless/02265_rename_join_ordinary_to_atomic.sql\n+++ b/tests/queries/0_stateless/02265_rename_join_ordinary_to_atomic.sql\n@@ -1,5 +1,6 @@\n -- Tags: no-parallel\n \n+set allow_deprecated_database_ordinary=1;\n DROP DATABASE IF EXISTS 02265_atomic_db;\n DROP DATABASE IF EXISTS 02265_ordinary_db;\n \ndiff --git a/tests/queries/1_stateful/00040_aggregating_materialized_view.sql b/tests/queries/1_stateful/00040_aggregating_materialized_view.sql\nindex 555a8b64d752..99fed62683f0 100644\n--- a/tests/queries/1_stateful/00040_aggregating_materialized_view.sql\n+++ b/tests/queries/1_stateful/00040_aggregating_materialized_view.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS test.basic_00040;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE MATERIALIZED VIEW test.basic_00040\n ENGINE = AggregatingMergeTree(StartDate, (CounterID, StartDate), 8192)\n POPULATE AS\ndiff --git a/tests/queries/1_stateful/00041_aggregating_materialized_view.sql b/tests/queries/1_stateful/00041_aggregating_materialized_view.sql\nindex 0e59d2a88a9c..ea99b78902cd 100644\n--- a/tests/queries/1_stateful/00041_aggregating_materialized_view.sql\n+++ b/tests/queries/1_stateful/00041_aggregating_materialized_view.sql\n@@ -9,6 +9,7 @@ CREATE TABLE test.visits_null\n     UserID UInt64\n ) ENGINE = Null;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE MATERIALIZED VIEW test.basic\n ENGINE = AggregatingMergeTree(StartDate, (CounterID, StartDate), 8192)\n AS SELECT\ndiff --git a/tests/queries/1_stateful/00054_merge_tree_partitions.sql b/tests/queries/1_stateful/00054_merge_tree_partitions.sql\nindex 730209529774..33f7e4e8666f 100644\n--- a/tests/queries/1_stateful/00054_merge_tree_partitions.sql\n+++ b/tests/queries/1_stateful/00054_merge_tree_partitions.sql\n@@ -1,4 +1,5 @@\n DROP TABLE IF EXISTS test.partitions;\n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test.partitions (EventDate Date, CounterID UInt32) ENGINE = MergeTree(EventDate, CounterID, 8192);\n INSERT INTO test.partitions SELECT EventDate + UserID % 365 AS EventDate, CounterID FROM test.hits WHERE CounterID = 1704509;\n \ndiff --git a/tests/queries/1_stateful/00071_merge_tree_optimize_aio.sql b/tests/queries/1_stateful/00071_merge_tree_optimize_aio.sql\nindex 16c0097bf216..e05751226442 100644\n--- a/tests/queries/1_stateful/00071_merge_tree_optimize_aio.sql\n+++ b/tests/queries/1_stateful/00071_merge_tree_optimize_aio.sql\n@@ -1,5 +1,6 @@\n DROP TABLE IF EXISTS test.hits_snippet;\n \n+set allow_deprecated_syntax_for_merge_tree=1;\n CREATE TABLE test.hits_snippet(EventTime DateTime('Asia/Dubai'),  EventDate Date,  CounterID UInt32,  UserID UInt64,  URL String,  Referer String) ENGINE = MergeTree(EventDate, intHash32(UserID), (CounterID, EventDate, intHash32(UserID), EventTime), 8192);\n \n SET min_insert_block_size_rows = 0, min_insert_block_size_bytes = 0;\n",
  "problem_statement": "Setting to forbid creation of Ordinary databases\nOrdinary databases are deprecated in favor of Atomic databases. The setting will help to enforce usage of the recommended database engine Atomic.\r\n\n",
  "hints_text": "",
  "created_at": "2022-06-23T09:37:06Z",
  "modified_files": [
    "programs/server/Server.cpp",
    "src/Core/Settings.h",
    "src/Databases/DatabaseAtomic.cpp",
    "src/Databases/DatabaseAtomic.h",
    "src/Databases/DatabaseFactory.cpp",
    "src/Databases/DatabaseLazy.cpp",
    "src/Databases/DatabaseLazy.h",
    "src/Databases/DatabaseMemory.cpp",
    "src/Databases/DatabaseMemory.h",
    "src/Databases/DatabaseOnDisk.cpp",
    "src/Databases/DatabaseOnDisk.h",
    "src/Databases/DatabaseReplicated.cpp",
    "src/Databases/DatabaseReplicated.h",
    "src/Databases/IDatabase.h",
    "src/Databases/MySQL/DatabaseMaterializedMySQL.cpp",
    "src/Databases/MySQL/DatabaseMaterializedMySQL.h",
    "src/Databases/MySQL/DatabaseMySQL.cpp",
    "src/Databases/MySQL/DatabaseMySQL.h",
    "src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp",
    "src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h",
    "src/Databases/PostgreSQL/DatabasePostgreSQL.cpp",
    "src/Databases/PostgreSQL/DatabasePostgreSQL.h",
    "src/Interpreters/AsynchronousInsertQueue.h",
    "src/Interpreters/HashJoin.h",
    "src/Interpreters/InterpreterCreateQuery.cpp",
    "src/Interpreters/InterpreterDropQuery.cpp",
    "src/Interpreters/InterpreterDropQuery.h",
    "src/Interpreters/loadMetadata.cpp",
    "src/Interpreters/loadMetadata.h",
    "src/Parsers/ASTDropQuery.cpp",
    "src/Parsers/ASTDropQuery.h",
    "src/Parsers/ParserDropQuery.cpp",
    "src/Storages/IStorage.h",
    "src/Storages/MergeTree/registerStorageMergeTree.cpp",
    "src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.cpp",
    "src/Storages/PostgreSQL/StorageMaterializedPostgreSQL.h",
    "src/Storages/StorageMaterializedView.cpp",
    "src/Storages/StorageMaterializedView.h",
    "src/Storages/WindowView/StorageWindowView.cpp",
    "src/Storages/WindowView/StorageWindowView.h"
  ],
  "modified_test_files": [
    "docker/test/stateful/run.sh",
    "docker/test/stateless/run.sh",
    "docker/test/stress/run.sh",
    "tests/clickhouse-test",
    "tests/config/users.d/database_ordinary.xml",
    "tests/integration/helpers/cluster.py",
    "tests/integration/test_atomic_drop_table/test.py",
    "tests/integration/test_attach_partition_with_large_destination/test.py",
    "tests/integration/test_backup_restore/test.py",
    "tests/integration/test_backup_with_other_granularity/test.py",
    "tests/integration/test_backward_compatibility/test_aggregate_function_state_avg.py",
    "b/tests/integration/test_backward_compatibility/test_convert_ordinary.py",
    "tests/integration/test_cluster_copier/configs/users.xml",
    "tests/integration/test_cluster_copier/configs_three_nodes/users.xml",
    "tests/integration/test_cluster_copier/configs_two_nodes/users.xml",
    "tests/integration/test_config_substitutions/configs/config_allow_databases.xml",
    "tests/integration/test_cross_replication/test.py",
    "tests/integration/test_default_compression_codec/test.py",
    "tests/integration/test_delayed_replica_failover/test.py",
    "tests/integration/test_dictionaries_dependency/test.py",
    "tests/integration/test_distributed_ddl/configs/users.d/query_log.xml",
    "tests/integration/test_distributed_ddl/configs_secure/users.d/query_log.xml",
    "tests/integration/test_distributed_ddl/test.py",
    "tests/integration/test_distributed_storage_configuration/test.py",
    "tests/integration/test_extreme_deduplication/test.py",
    "tests/integration/test_filesystem_layout/test.py",
    "tests/integration/test_force_drop_table/test.py",
    "tests/integration/test_https_replication/test.py",
    "tests/integration/test_insert_into_distributed/test.py",
    "tests/integration/test_insert_into_distributed_sync_async/test.py",
    "tests/integration/test_insert_into_distributed_through_materialized_view/configs/enable_distributed_inserts_batching.xml",
    "tests/integration/test_insert_into_distributed_through_materialized_view/test.py",
    "tests/integration/test_keeper_multinode_blocade_leader/test.py",
    "tests/integration/test_materialized_mysql_database/configs/users.xml",
    "tests/integration/test_materialized_mysql_database/configs/users_disable_bytes_settings.xml",
    "tests/integration/test_materialized_mysql_database/configs/users_disable_rows_settings.xml",
    "tests/integration/test_merge_tree_empty_parts/test.py",
    "tests/integration/test_merge_tree_s3_restore/test.py",
    "tests/integration/test_mutations_with_merge_tree/test.py",
    "tests/integration/test_partition/test.py",
    "tests/integration/test_polymorphic_parts/configs/users.d/not_optimize_count.xml",
    "tests/integration/test_polymorphic_parts/test.py",
    "tests/integration/test_random_inserts/test.py",
    "tests/integration/test_replace_partition/test.py",
    "tests/integration/test_replicated_database/test.py",
    "tests/integration/test_replicated_merge_tree_compatibility/test.py",
    "tests/integration/test_replicated_merge_tree_s3_restore/test.py",
    "tests/integration/test_replication_credentials/test.py",
    "tests/integration/test_send_request_to_leader_replica/test.py",
    "b/tests/integration/test_server_initialization/clickhouse_path/metadata/default.sql",
    "tests/integration/test_system_merges/test.py",
    "tests/integration/test_union_header/test.py",
    "tests/integration/test_version_update_after_mutation/test.py",
    "tests/integration/test_zookeeper_config/test.py",
    "tests/integration/test_zookeeper_config/test_password.py",
    "tests/performance/merge_table_streams.xml",
    "tests/performance/parallel_final.xml",
    "tests/performance/scalar2.xml",
    "tests/queries/0_stateless/00030_alter_table.sql",
    "tests/queries/0_stateless/00043_summing_empty_part.sql",
    "tests/queries/0_stateless/00046_stored_aggregates_simple.sql",
    "tests/queries/0_stateless/00047_stored_aggregates_complex.sql",
    "tests/queries/0_stateless/00048_a_stored_aggregates_merge.sql",
    "tests/queries/0_stateless/00048_b_stored_aggregates_merge.sql",
    "tests/queries/0_stateless/00061_merge_tree_alter.sql",
    "tests/queries/0_stateless/00062_replicated_merge_tree_alter_zookeeper_long.sql",
    "tests/queries/0_stateless/00079_defaulted_columns.sql",
    "tests/queries/0_stateless/00083_create_merge_tree_zookeeper_long.sql",
    "tests/queries/0_stateless/00084_summing_merge_tree.sql",
    "tests/queries/0_stateless/00090_union_race_conditions_1.sh",
    "tests/queries/0_stateless/00098_shard_i_union_all.sql",
    "tests/queries/0_stateless/00101_materialized_views_and_insert_without_explicit_database.sql",
    "tests/queries/0_stateless/00121_drop_column_zookeeper.sql",
    "tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql",
    "tests/queries/0_stateless/00140_prewhere_column_order.sql",
    "tests/queries/0_stateless/00141_parse_timestamp_as_datetime.sql",
    "tests/queries/0_stateless/00146_summing_merge_tree_nested_map.sql",
    "tests/queries/0_stateless/00147_alter_nested_default.sql",
    "tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.sql",
    "tests/queries/0_stateless/00148_summing_merge_tree_nested_map_multiple_values.sql",
    "tests/queries/0_stateless/00155_long_merges.sh",
    "tests/queries/0_stateless/00168_buffer_defaults.sql",
    "tests/queries/0_stateless/00191_aggregating_merge_tree_and_final.sql",
    "tests/queries/0_stateless/00193_parallel_replicas.sql",
    "tests/queries/0_stateless/00214_primary_key_order.sql",
    "tests/queries/0_stateless/00215_primary_key_order_zookeeper_long.sql",
    "tests/queries/0_stateless/00226_zookeeper_deduplication_and_unexpected_parts_long.sql",
    "tests/queries/0_stateless/00229_prewhere_column_missing.sql",
    "tests/queries/0_stateless/00236_replicated_drop_on_non_leader_zookeeper_long.sql",
    "tests/queries/0_stateless/00253_insert_recursive_defaults.sql",
    "tests/queries/0_stateless/00261_storage_aliases_and_array_join.sql",
    "tests/queries/0_stateless/00262_alter_alias.sql",
    "tests/queries/0_stateless/00276_sample.sql",
    "tests/queries/0_stateless/00278_insert_already_sorted.sql",
    "tests/queries/0_stateless/00282_merging.sql",
    "tests/queries/0_stateless/00294_shard_enums.sql",
    "tests/queries/0_stateless/00311_array_primary_key.sql",
    "tests/queries/0_stateless/00314_sample_factor_virtual_column.sql",
    "tests/queries/0_stateless/00318_pk_tuple_order.sql",
    "tests/queries/0_stateless/00319_index_for_like.sql",
    "tests/queries/0_stateless/00321_pk_set.sql",
    "tests/queries/0_stateless/00327_summing_composite_nested.sql",
    "tests/queries/0_stateless/00331_final_and_prewhere.sql",
    "tests/queries/0_stateless/00345_index_accurate_comparison.sql",
    "tests/queries/0_stateless/00361_shared_array_offsets_and_squash_blocks.sql",
    "tests/queries/0_stateless/00363_defaults.sql",
    "tests/queries/0_stateless/00384_column_aggregate_function_insert_from.sql",
    "tests/queries/0_stateless/00386_enum_in_pk.sql",
    "tests/queries/0_stateless/00392_enum_nested_alter.sql",
    "tests/queries/0_stateless/00394_new_nested_column_keeps_offsets.sql",
    "tests/queries/0_stateless/00394_replaceall_vector_fixed.sql",
    "tests/queries/0_stateless/00395_nullable.sql",
    "tests/queries/0_stateless/00411_merge_tree_where_const_in_set.sql",
    "tests/queries/0_stateless/00412_logical_expressions_optimizer.sql",
    "tests/queries/0_stateless/00427_alter_primary_key.sh",
    "tests/queries/0_stateless/00432_aggregate_function_scalars_and_constants.sql",
    "tests/queries/0_stateless/00440_nulls_merge_tree.sql",
    "tests/queries/0_stateless/00443_optimize_final_vertical_merge.sh",
    "tests/queries/0_stateless/00446_clear_column_in_partition_concurrent_zookeeper.sh",
    "tests/queries/0_stateless/00453_cast_enum.sql",
    "tests/queries/0_stateless/00456_alter_nullable.sql",
    "tests/queries/0_stateless/00481_reading_from_last_granula.sql",
    "tests/queries/0_stateless/00483_reading_from_array_structure.sql",
    "tests/queries/0_stateless/00489_pk_subexpression.sql",
    "tests/queries/0_stateless/00495_reading_const_zero_column.sql",
    "tests/queries/0_stateless/00504_insert_miss_columns.sh",
    "tests/queries/0_stateless/00504_mergetree_arrays_rw.sql",
    "tests/queries/0_stateless/00505_distributed_secure.data",
    "tests/queries/0_stateless/00506_union_distributed.sql",
    "tests/queries/0_stateless/00515_shard_desc_table_functions_and_subqueries.sql",
    "tests/queries/0_stateless/00516_deduplication_after_drop_partition_zookeeper.sql",
    "tests/queries/0_stateless/00531_aggregate_over_nullable.sql",
    "tests/queries/0_stateless/00542_materialized_view_and_time_zone_tag.sql",
    "tests/queries/0_stateless/00543_null_and_prewhere.sql",
    "tests/queries/0_stateless/00561_storage_join.sql",
    "tests/queries/0_stateless/00563_complex_in_expression.sql",
    "tests/queries/0_stateless/00564_initial_column_values_with_default_expression.sql",
    "tests/queries/0_stateless/00564_versioned_collapsing_merge_tree.sql",
    "tests/queries/0_stateless/00565_enum_order.sh",
    "tests/queries/0_stateless/00571_non_exist_database_when_create_materializ_view.sql",
    "tests/queries/0_stateless/00575_illegal_column_exception_when_drop_depen_column.sh",
    "tests/queries/0_stateless/00575_merge_and_index_with_function_in_in.sql",
    "tests/queries/0_stateless/00579_virtual_column_and_lazy.sql",
    "tests/queries/0_stateless/00584_view_union_all.sql",
    "tests/queries/0_stateless/00594_alias_in_distributed.sql",
    "tests/queries/0_stateless/00597_push_down_predicate_long.sql",
    "tests/queries/0_stateless/00609_mv_index_in_in.sql",
    "tests/queries/0_stateless/00610_materialized_view_forward_alter_partition_statements.sql",
    "tests/queries/0_stateless/00614_array_nullable.sql",
    "tests/queries/0_stateless/00614_shard_same_header_for_local_and_remote_node_in_distributed_query.sql",
    "tests/queries/0_stateless/00615_nullable_alter_optimize.sql",
    "tests/queries/0_stateless/00616_final_single_part.sql",
    "tests/queries/0_stateless/00621_regression_for_in_operator.sql",
    "tests/queries/0_stateless/00623_in_partition_key.sql",
    "tests/queries/0_stateless/00623_replicated_truncate_table_zookeeper_long.sql",
    "tests/queries/0_stateless/00623_truncate_table.sql",
    "tests/queries/0_stateless/00625_summing_merge_tree_merge.sql",
    "tests/queries/0_stateless/00632_get_sample_block_cache.sql",
    "tests/queries/0_stateless/00648_replacing_empty_set_from_prewhere.sql",
    "tests/queries/0_stateless/00652_mergetree_mutations.sh",
    "tests/queries/0_stateless/00652_replicated_mutations_zookeeper.sh",
    "tests/queries/0_stateless/00678_shard_funnel_window.sql",
    "tests/queries/0_stateless/00709_virtual_column_partition_id.sql",
    "tests/queries/0_stateless/00712_prewhere_with_alias_bug_2.sql",
    "tests/queries/0_stateless/00712_prewhere_with_final.sql",
    "tests/queries/0_stateless/00712_prewhere_with_sampling_and_alias.sql",
    "tests/queries/0_stateless/00717_merge_and_distributed.sql",
    "tests/queries/0_stateless/00729_prewhere_array_join.sql",
    "tests/queries/0_stateless/00731_long_merge_tree_select_opened_files.sh",
    "tests/queries/0_stateless/00732_decimal_summing_merge_tree.sql",
    "tests/queries/0_stateless/00748_insert_array_with_null.sql",
    "tests/queries/0_stateless/00752_low_cardinality_mv_2.sql",
    "tests/queries/0_stateless/00753_system_columns_and_system_tables_long.sql",
    "tests/queries/0_stateless/00754_alter_modify_order_by.sql",
    "tests/queries/0_stateless/00754_alter_modify_order_by_replicated_zookeeper_long.sql",
    "tests/queries/0_stateless/00794_materialized_view_with_column_defaults.sql",
    "tests/queries/0_stateless/00800_low_cardinality_distributed_insert.sql",
    "tests/queries/0_stateless/00806_alter_update.sql",
    "tests/queries/0_stateless/00829_bitmap_function.sql",
    "tests/queries/0_stateless/00834_hints_for_type_function_typos.sh",
    "tests/queries/0_stateless/00910_crash_when_distributed_modify_order_by.sql",
    "tests/queries/0_stateless/00925_zookeeper_empty_replicated_merge_tree_optimize_final_long.sh",
    "tests/queries/0_stateless/00952_insert_into_distributed_with_materialized_column.sql",
    "tests/queries/0_stateless/00974_final_predicate_push_down.sql",
    "tests/queries/0_stateless/00981_in_subquery_with_tuple.sh",
    "tests/queries/0_stateless/01008_materialized_view_henyihanwobushi.sql",
    "tests/queries/0_stateless/01047_window_view_parser_inner_table.sql",
    "tests/queries/0_stateless/01048_window_view_parser.sql",
    "tests/queries/0_stateless/01053_drop_database_mat_view.sql",
    "tests/queries/0_stateless/01053_ssd_dictionary.sh",
    "tests/queries/0_stateless/01062_alter_on_mutataion_zookeeper_long.sql",
    "tests/queries/0_stateless/01071_prohibition_secondary_index_with_old_format_merge_tree.sql",
    "tests/queries/0_stateless/01076_predicate_optimizer_with_view.sql",
    "tests/queries/0_stateless/01085_window_view_attach.sql",
    "tests/queries/0_stateless/01086_window_view_cleanup.sh",
    "tests/queries/0_stateless/01089_alter_settings_old_format.sql",
    "tests/queries/0_stateless/01101_prewhere_after_alter.sql",
    "tests/queries/0_stateless/01109_exchange_tables.sql",
    "tests/queries/0_stateless/01114_database_atomic.sh",
    "tests/queries/0_stateless/01125_generate_random_qoega.sql",
    "tests/queries/0_stateless/01126_month_partitioning_consistent_code.sql",
    "tests/queries/0_stateless/01127_month_partitioning_consistency_select.sql",
    "tests/queries/0_stateless/01128_generate_random_nested.sql",
    "tests/queries/0_stateless/01148_zookeeper_path_macros_unfolding.sql",
    "tests/queries/0_stateless/01155_rename_move_materialized_view.sql",
    "tests/queries/0_stateless/01162_strange_mutations.sh",
    "tests/queries/0_stateless/01190_full_attach_syntax.sql",
    "tests/queries/0_stateless/01192_rename_database_zookeeper.sh",
    "tests/queries/0_stateless/01224_no_superfluous_dict_reload.sql",
    "tests/queries/0_stateless/01225_show_create_table_from_dictionary.sql",
    "tests/queries/0_stateless/01233_check_table_with_metadata_cache.sh",
    "tests/queries/0_stateless/01249_bad_arguments_for_bloom_filter.sql",
    "tests/queries/0_stateless/01253_subquery_in_aggregate_function_JustStranger.sql",
    "tests/queries/0_stateless/01280_ssd_complex_key_dictionary.sh",
    "tests/queries/0_stateless/01297_alter_distributed.sql",
    "tests/queries/0_stateless/01298_alter_merge.sql",
    "tests/queries/0_stateless/01299_alter_merge_tree.sql",
    "tests/queries/0_stateless/01320_create_sync_race_condition_zookeeper.sh",
    "tests/queries/0_stateless/01355_alter_column_with_order.sql",
    "tests/queries/0_stateless/01387_clear_column_default_depends.sql",
    "tests/queries/0_stateless/01417_freeze_partition_verbose.sh",
    "tests/queries/0_stateless/01430_modify_sample_by_zookeeper_long.sql",
    "tests/queries/0_stateless/01455_shard_leaf_max_rows_bytes_to_read.sql",
    "tests/queries/0_stateless/01516_create_table_primary_key.sql",
    "tests/queries/0_stateless/01517_drop_mv_with_inner_table.sql",
    "tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.sh",
    "tests/queries/0_stateless/01600_detach_permanently.sh",
    "tests/queries/0_stateless/01601_detach_permanently.sql",
    "tests/queries/0_stateless/01603_rename_overwrite_bug.sql",
    "tests/queries/0_stateless/01648_mutations_and_escaping.sql",
    "tests/queries/0_stateless/01652_ttl_old_syntax.sql",
    "tests/queries/0_stateless/01713_table_ttl_old_syntax_zookeeper.sql",
    "tests/queries/0_stateless/01778_test_LowCardinality_FixedString_pk.sql",
    "tests/queries/0_stateless/01798_uniq_theta_sketch.sql",
    "tests/queries/0_stateless/01810_max_part_removal_threads_long.sh",
    "tests/queries/0_stateless/01907_multiple_aliases.sql",
    "tests/queries/0_stateless/01925_broken_partition_id_zookeeper.sql",
    "tests/queries/0_stateless/02021_create_database_with_comment.sh",
    "tests/queries/0_stateless/02096_rename_atomic_hang.sql",
    "tests/queries/0_stateless/02135_local_create_db.sh",
    "tests/queries/0_stateless/02250_hints_for_columns.sh",
    "tests/queries/0_stateless/02265_rename_join_ordinary_to_atomic.sql",
    "tests/queries/1_stateful/00040_aggregating_materialized_view.sql",
    "tests/queries/1_stateful/00041_aggregating_materialized_view.sql",
    "tests/queries/1_stateful/00054_merge_tree_partitions.sql",
    "tests/queries/1_stateful/00071_merge_tree_optimize_aio.sql"
  ]
}