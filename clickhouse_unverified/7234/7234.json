{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 7234,
  "instance_id": "ClickHouse__ClickHouse-7234",
  "issue_numbers": [
    "7113"
  ],
  "base_commit": "ef75b0f50d3efcc6e5b6ff4a64e38873c1170dca",
  "patch": "diff --git a/dbms/src/DataTypes/DataTypeNullable.cpp b/dbms/src/DataTypes/DataTypeNullable.cpp\nindex 376b4b6dad05..fb75f1c7b624 100644\n--- a/dbms/src/DataTypes/DataTypeNullable.cpp\n+++ b/dbms/src/DataTypes/DataTypeNullable.cpp\n@@ -118,6 +118,33 @@ void DataTypeNullable::deserializeBinaryBulkWithMultipleStreams(\n }\n \n \n+void DataTypeNullable::serializeBinary(const Field & field, WriteBuffer & ostr) const\n+{\n+    if (field.isNull())\n+    {\n+        writeBinary(true, ostr);\n+    }\n+    else\n+    {\n+        writeBinary(false, ostr);\n+        nested_data_type->serializeBinary(field, ostr);\n+    }\n+}\n+\n+void DataTypeNullable::deserializeBinary(Field & field, ReadBuffer & istr) const\n+{\n+    bool is_null = false;\n+    readBinary(is_null, istr);\n+    if (!is_null)\n+    {\n+        nested_data_type->deserializeBinary(field, istr);\n+    }\n+    else\n+    {\n+        field = Null();\n+    }\n+}\n+\n void DataTypeNullable::serializeBinary(const IColumn & column, size_t row_num, WriteBuffer & ostr) const\n {\n     const ColumnNullable & col = assert_cast<const ColumnNullable &>(column);\n@@ -416,6 +443,10 @@ MutableColumnPtr DataTypeNullable::createColumn() const\n     return ColumnNullable::create(nested_data_type->createColumn(), ColumnUInt8::create());\n }\n \n+Field DataTypeNullable::getDefault() const\n+{\n+    return Null();\n+}\n \n size_t DataTypeNullable::getSizeOfValueInMemory() const\n {\ndiff --git a/dbms/src/DataTypes/DataTypeNullable.h b/dbms/src/DataTypes/DataTypeNullable.h\nindex 5bacdb39ff4a..49b14eefc6c1 100644\n--- a/dbms/src/DataTypes/DataTypeNullable.h\n+++ b/dbms/src/DataTypes/DataTypeNullable.h\n@@ -45,8 +45,8 @@ class DataTypeNullable final : public IDataType\n             DeserializeBinaryBulkSettings & settings,\n             DeserializeBinaryBulkStatePtr & state) const override;\n \n-    void serializeBinary(const Field & field, WriteBuffer & ostr) const override { nested_data_type->serializeBinary(field, ostr); }\n-    void deserializeBinary(Field & field, ReadBuffer & istr) const override { nested_data_type->deserializeBinary(field, istr); }\n+    void serializeBinary(const Field & field, WriteBuffer & ostr) const override;\n+    void deserializeBinary(Field & field, ReadBuffer & istr) const override;\n     void serializeBinary(const IColumn & column, size_t row_num, WriteBuffer & ostr) const override;\n     void deserializeBinary(IColumn & column, ReadBuffer & istr) const override;\n     void serializeTextEscaped(const IColumn & column, size_t row_num, WriteBuffer & ostr, const FormatSettings &) const override;\n@@ -77,7 +77,7 @@ class DataTypeNullable final : public IDataType\n \n     MutableColumnPtr createColumn() const override;\n \n-    Field getDefault() const override { return Null(); }\n+    Field getDefault() const override;\n \n     bool equals(const IDataType & rhs) const override;\n \n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/01016_null_part_minmax.reference b/dbms/tests/queries/0_stateless/01016_null_part_minmax.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/dbms/tests/queries/0_stateless/01016_null_part_minmax.sql b/dbms/tests/queries/0_stateless/01016_null_part_minmax.sql\nnew file mode 100644\nindex 000000000000..3d471a33a331\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/01016_null_part_minmax.sql\n@@ -0,0 +1,5 @@\n+-- this test checks that null values are correctly serialized inside minmax index (issue #7113)\n+drop table if exists null_01016;\n+create table if not exists null_01016 (x Nullable(String)) engine MergeTree order by ifNull(x, 'order-null') partition by ifNull(x, 'partition-null');\n+insert into null_01016 values (null);\n+drop table null_01016;\n",
  "problem_statement": "Inserting rows from CSV\n**version 19.14.6.12 (official build)**\r\n\r\nI have a ruby script to import rows from production table to clickhouse.\r\n\r\nEach time I ran it script, the server unexpectedly it restart.\r\n\r\nI ran other ruby script (with the same gem version) without problems.\r\n\r\nHere a log capture.\r\n\r\n```\r\n2019.09.26 13:43:37.704581 [ 43 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: GET, Address: [::1]:50926, User-Agent: Faraday v0.15.4, Content Type: , Transfer Encoding: identity\r\n2019.09.26 13:43:37.705674 [ 43 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: GET, Address: [::1]:50928, User-Agent: Faraday v0.15.4, Content Type: , Transfer Encoding: identity\r\n2019.09.26 13:43:37.705746 [ 43 ] {} <Trace> HTTPHandler: Request URI: /?database=production&query=SELECT+MAX%28id%29%0AFROM+production_cdr+FORMAT+JSONCompact\r\n2019.09.26 13:43:37.705917 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Debug> executeQuery: (from [::1]:50928) SELECT MAX(id) FROM production_cdr FORMAT JSONCompact \r\n2019.09.26 13:43:37.706556 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Debug> production.production_cdr (SelectExecutor): Key condition: unknown\r\n2019.09.26 13:43:37.706570 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Debug> production.production_cdr (SelectExecutor): MinMax index condition: unknown\r\n2019.09.26 13:43:37.706578 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Debug> production.production_cdr (SelectExecutor): Selected 0 parts by date, 0 parts by key, 0 marks to read from 0 ranges\r\n2019.09.26 13:43:37.706619 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2019.09.26 13:43:37.706701 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Debug> executeQuery: Query pipeline:\r\nExpression\r\n Expression\r\n  Aggregating\r\n   Concat\r\n    Expression\r\n     Null\r\n\r\n2019.09.26 13:43:37.706796 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Trace> Aggregator: Aggregating\r\n2019.09.26 13:43:37.706814 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Trace> Aggregator: Aggregation method: without_key\r\n2019.09.26 13:43:37.706840 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Trace> Aggregator: Aggregated. 0 to 1 rows (from 0.000 MiB) in 0.000 sec. (0.000 rows/sec., 0.000 MiB/sec.)\r\n2019.09.26 13:43:37.706851 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Trace> Aggregator: Merging aggregated data\r\n2019.09.26 13:43:37.706948 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Trace> virtual DB::MergingAndConvertingBlockInputStream::~MergingAndConvertingBlockInputStream(): Waiting for threads to finish\r\n2019.09.26 13:43:37.706984 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Debug> MemoryTracker: Peak memory usage (total): 0.00 B.\r\n2019.09.26 13:43:37.707003 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\r\n2019.09.26 13:43:37.707014 [ 43 ] {039e320d-55e6-4f6d-a91d-7ddddbd06bbd} <Information> HTTPHandler: Done processing query\r\n2019.09.26 13:43:37.707816 [ 43 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: GET, Address: [::1]:50930, User-Agent: Faraday v0.15.4, Content Type: , Transfer Encoding: identity\r\n2019.09.26 13:43:37.707850 [ 43 ] {} <Trace> HTTPHandler: Request URI: /?database=production&query=DESCRIBE+TABLE+production_cdr+FORMAT+JSONCompact\r\n2019.09.26 13:43:37.707917 [ 43 ] {283c2920-12af-4692-b85d-1393a797eaa4} <Debug> executeQuery: (from [::1]:50930) DESCRIBE TABLE production_cdr FORMAT JSONCompact \r\n2019.09.26 13:43:37.708070 [ 43 ] {283c2920-12af-4692-b85d-1393a797eaa4} <Debug> executeQuery: Query pipeline:\r\nOne\r\n\r\n2019.09.26 13:43:37.708214 [ 43 ] {283c2920-12af-4692-b85d-1393a797eaa4} <Information> executeQuery: Read 84 rows, 7.79 KiB in 0.000 sec., 308247 rows/sec., 27.90 MiB/sec.\r\n2019.09.26 13:43:37.708236 [ 43 ] {283c2920-12af-4692-b85d-1393a797eaa4} <Debug> MemoryTracker: Peak memory usage (total): 0.00 B.\r\n2019.09.26 13:43:37.708248 [ 43 ] {283c2920-12af-4692-b85d-1393a797eaa4} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\r\n2019.09.26 13:43:37.708257 [ 43 ] {283c2920-12af-4692-b85d-1393a797eaa4} <Information> HTTPHandler: Done processing query\r\n2019.09.26 13:43:37.810276 [ 43 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: POST, Address: [::1]:50934, User-Agent: Faraday v0.15.4, Length: 2547, Content Type: application/x-www-form-urlencoded, Transfer Encoding: identity\r\n2019.09.26 13:43:37.810320 [ 43 ] {} <Trace> HTTPHandler: Request URI: /?database=production&query=INSERT+INTO+production_cdr+FORMAT+CSVWithNames\r\n2019.09.26 13:43:37.810452 [ 43 ] {93cd812a-6871-40bd-ae21-5a9d5948d3b1} <Debug> executeQuery: (from [::1]:50934) INSERT INTO production_cdr FORMAT CSVWithNames \r\n2019.09.26 13:43:37.810828 [ 43 ] {93cd812a-6871-40bd-ae21-5a9d5948d3b1} <Debug> executeQuery: Query pipeline:\r\nNullAndDoCopy\r\n InputStreamFromASTInsertQuery\r\n\r\n2019.09.26 13:43:37.861924 [ 44 ] {} <Fatal> BaseDaemon: ########################################\r\n2019.09.26 13:43:37.861972 [ 44 ] {} <Fatal> BaseDaemon: (version 19.14.6.12 (official build)) (from thread 43) Received signal Segmentation fault (11).\r\n2019.09.26 13:43:37.861993 [ 44 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Unknown si_code.\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.861924 [ 44 ] {} <Fatal> BaseDaemon: ########################################\r\n2019.09.26 13:43:37.861972 [ 44 ] {} <Fatal> BaseDaemon: (version 19.14.6.12 (official build)) (from thread 43) Received signal Segmentation fault (11).\r\n2019.09.26 13:43:37.861993 [ 44 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Unknown si_code.\r\n2019.09.26 13:43:37.862020 [ 44 ] {} <Fatal> BaseDaemon: Stack trace: 0x557ec0003a8f 0x557ebddad707 0x557ebe185519 0x557ebe1e6fe6 0x557ebe1ae5f8 0x557ebe142604 0x557ebe469df1 0x557ebe474193 0x557ebe4743c1 0x557ebdd20627 0x557ebde481b5 0x557ebdd03537 0x557ebdd1ff8b 0x557ebdf94707 0x557ebac4ae1e 0x557ebac4d1c9 0x557ebeab5da9 0x557ebeab0b80 0x557ebeab129d 0x557ec00ffb31 0x557ec00fd8dc 0x557ec0873120 0x7f19424a54a4 0x7f1941ddbd0f\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862020 [ 44 ] {} <Fatal> BaseDaemon: Stack trace: 0x557ec0003a8f 0x557ebddad707 0x557ebe185519 0x557ebe1e6fe6 0x557ebe1ae5f8 0x557ebe142604 0x557ebe469df1 0x557ebe474193 0x557ebe4743c1 0x557ebdd20627 0x557ebde481b5 0x557ebdd03537 0x557ebdd1ff8b 0x557ebdf94707 0x557ebac4ae1e 0x557ebac4d1c9 0x557ebeab5da9 0x557ebeab0b80 0x557ebeab129d 0x557ec00ffb31 0x557ec00fd8dc 0x557ec0873120 0x7f19424a54a4 0x7f1941ddbd0f\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862069 [ 44 ] {} <Fatal> BaseDaemon: 3. 0x557ec0003a8f memcpy /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862069 [ 44 ] {} <Fatal> BaseDaemon: 3. 0x557ec0003a8f memcpy /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862126 [ 44 ] {} <Fatal> BaseDaemon: 4. 0x557ebddad707 DB::DataTypeString::serializeBinary(DB::Field const&, DB::WriteBuffer&) const /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862126 [ 44 ] {} <Fatal> BaseDaemon: 4. 0x557ebddad707 DB::DataTypeString::serializeBinary(DB::Field const&, DB::WriteBuffer&) const /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862177 [ 44 ] {} <Fatal> BaseDaemon: 5. 0x557ebe185519 DB::MergeTreeDataPart::MinMaxIndex::store(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::shared_ptr<DB::IDataType const>, std::allocator<std::shared_ptr<DB::IDataType const> > > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, DB::MergeTreeDataPartChecksums&) const /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862177 [ 44 ] {} <Fatal> BaseDaemon: 5. 0x557ebe185519 DB::MergeTreeDataPart::MinMaxIndex::store(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::shared_ptr<DB::IDataType const>, std::allocator<std::shared_ptr<DB::IDataType const> > > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, DB::MergeTreeDataPartChecksums&) const /usr/bin/clickhouse\r\n2019.09.26 13:43:37.862208 [ 44 ] {} <Fatal> BaseDaemon: 6. 0x557ebe1e6fe6 DB::MergedBlockOutputStream::writeSuffixAndFinalizePart(std::shared_ptr<DB::MergeTreeDataPart>&, DB::NamesAndTypesList const*, DB::MergeTreeDataPartChecksums*) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862208 [ 44 ] {} <Fatal> BaseDaemon: 6. 0x557ebe1e6fe6 DB::MergedBlockOutputStream::writeSuffixAndFinalizePart(std::shared_ptr<DB::MergeTreeDataPart>&, DB::NamesAndTypesList const*, DB::MergeTreeDataPartChecksums*) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862239 [ 44 ] {} <Fatal> BaseDaemon: 7. 0x557ebe1ae5f8 DB::MergeTreeDataWriter::writeTempPart(DB::BlockWithPartition&) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862239 [ 44 ] {} <Fatal> BaseDaemon: 7. 0x557ebe1ae5f8 DB::MergeTreeDataWriter::writeTempPart(DB::BlockWithPartition&) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862259 [ 44 ] {} <Fatal> BaseDaemon: 8. 0x557ebe142604 DB::MergeTreeBlockOutputStream::write(DB::Block const&) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862259 [ 44 ] {} <Fatal> BaseDaemon: 8. 0x557ebe142604 DB::MergeTreeBlockOutputStream::write(DB::Block const&) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862283 [ 44 ] {} <Fatal> BaseDaemon: 9. 0x557ebe469df1 DB::PushingToViewsBlockOutputStream::write(DB::Block const&) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862283 [ 44 ] {} <Fatal> BaseDaemon: 9. 0x557ebe469df1 DB::PushingToViewsBlockOutputStream::write(DB::Block const&) /usr/bin/clickhouse\r\n2019.09.26 13:43:37.862299 [ 44 ] {} <Fatal> BaseDaemon: 10. 0x557ebe474193 DB::SquashingBlockOutputStream::finalize() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862299 [ 44 ] {} <Fatal> BaseDaemon: 10. 0x557ebe474193 DB::SquashingBlockOutputStream::finalize() /usr/bin/clickhouse\r\n2019.09.26 13:43:37.862313 [ 44 ] {} <Fatal> BaseDaemon: 11. 0x557ebe4743c1 DB::SquashingBlockOutputStream::writeSuffix() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862313 [ 44 ] {} <Fatal> BaseDaemon: 11. 0x557ebe4743c1 DB::SquashingBlockOutputStream::writeSuffix() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862331 [ 44 ] {} <Fatal> BaseDaemon: 12. 0x557ebdd20627 DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::atomic<bool>*) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862331 [ 44 ] {} <Fatal> BaseDaemon: 12. 0x557ebdd20627 DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::atomic<bool>*) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862351 [ 44 ] {} <Fatal> BaseDaemon: 13. 0x557ebde481b5 DB::NullAndDoCopyBlockInputStream::readImpl() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862351 [ 44 ] {} <Fatal> BaseDaemon: 13. 0x557ebde481b5 DB::NullAndDoCopyBlockInputStream::readImpl() /usr/bin/clickhouse\r\n2019.09.26 13:43:37.862367 [ 44 ] {} <Fatal> BaseDaemon: 14. 0x557ebdd03537 DB::IBlockInputStream::read() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862367 [ 44 ] {} <Fatal> BaseDaemon: 14. 0x557ebdd03537 DB::IBlockInputStream::read() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862389 [ 44 ] {} <Fatal> BaseDaemon: 15. 0x557ebdd1ff8b DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::atomic<bool>*) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862389 [ 44 ] {} <Fatal> BaseDaemon: 15. 0x557ebdd1ff8b DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::atomic<bool>*) /usr/bin/clickhouse\r\n2019.09.26 13:43:37.862408 [ 44 ] {} <Fatal> BaseDaemon: 16. 0x557ebdf94707 DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, DB::Context&, std::function<void (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)>, std::function<void (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)>) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862408 [ 44 ] {} <Fatal> BaseDaemon: 16. 0x557ebdf94707 DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, DB::Context&, std::function<void (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)>, std::function<void (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)>) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862425 [ 44 ] {} <Fatal> BaseDaemon: 17. 0x557ebac4ae1e DB::HTTPHandler::processQuery(Poco::Net::HTTPServerRequest&, HTMLForm&, Poco::Net::HTTPServerResponse&, DB::HTTPHandler::Output&) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862425 [ 44 ] {} <Fatal> BaseDaemon: 17. 0x557ebac4ae1e DB::HTTPHandler::processQuery(Poco::Net::HTTPServerRequest&, HTMLForm&, Poco::Net::HTTPServerResponse&, DB::HTTPHandler::Output&) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862448 [ 44 ] {} <Fatal> BaseDaemon: 18. 0x557ebac4d1c9 DB::HTTPHandler::handleRequest(Poco::Net::HTTPServerRequest&, Poco::Net::HTTPServerResponse&) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862448 [ 44 ] {} <Fatal> BaseDaemon: 18. 0x557ebac4d1c9 DB::HTTPHandler::handleRequest(Poco::Net::HTTPServerRequest&, Poco::Net::HTTPServerResponse&) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862472 [ 44 ] {} <Fatal> BaseDaemon: 19. 0x557ebeab5da9 Poco::Net::HTTPServerConnection::run() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862472 [ 44 ] {} <Fatal> BaseDaemon: 19. 0x557ebeab5da9 Poco::Net::HTTPServerConnection::run() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862493 [ 44 ] {} <Fatal> BaseDaemon: 20. 0x557ebeab0b80 Poco::Net::TCPServerConnection::start() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862493 [ 44 ] {} <Fatal> BaseDaemon: 20. 0x557ebeab0b80 Poco::Net::TCPServerConnection::start() /usr/bin/clickhouse\r\n2019.09.26 13:43:37.862507 [ 44 ] {} <Fatal> BaseDaemon: 21. 0x557ebeab129d Poco::Net::TCPServerDispatcher::run() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862507 [ 44 ] {} <Fatal> BaseDaemon: 21. 0x557ebeab129d Poco::Net::TCPServerDispatcher::run() /usr/bin/clickhouse\r\n2019.09.26 13:43:37.862524 [ 44 ] {} <Fatal> BaseDaemon: 22. 0x557ec00ffb31 Poco::PooledThread::run() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862524 [ 44 ] {} <Fatal> BaseDaemon: 22. 0x557ec00ffb31 Poco::PooledThread::run() /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862544 [ 44 ] {} <Fatal> BaseDaemon: 23. 0x557ec00fd8dc Poco::ThreadImpl::runnableEntry(void*) /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862544 [ 44 ] {} <Fatal> BaseDaemon: 23. 0x557ec00fd8dc Poco::ThreadImpl::runnableEntry(void*) /usr/bin/clickhouse\r\n2019.09.26 13:43:37.862557 [ 44 ] {} <Fatal> BaseDaemon: 24. 0x557ec0873120 ? /usr/bin/clickhouse\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862557 [ 44 ] {} <Fatal> BaseDaemon: 24. 0x557ec0873120 ? /usr/bin/clickhouse\r\n2019.09.26 13:43:37.862573 [ 44 ] {} <Fatal> BaseDaemon: 25. 0x7f19424a54a4 start_thread /lib/x86_64-linux-gnu/libpthread-2.24.so\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862573 [ 44 ] {} <Fatal> BaseDaemon: 25. 0x7f19424a54a4 start_thread /lib/x86_64-linux-gnu/libpthread-2.24.so\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n2019.09.26 13:43:37.862589 [ 44 ] {} <Fatal> BaseDaemon: 26. 0x7f1941ddbd0f clone /lib/x86_64-linux-gnu/libc-2.24.so\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n2019.09.26 13:43:37.862589 [ 44 ] {} <Fatal> BaseDaemon: 26. 0x7f1941ddbd0f clone /lib/x86_64-linux-gnu/libc-2.24.so\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.log <==\r\n\r\n==> /var/log/clickhouse-server/clickhouse-server.err.log <==\r\n\r\n```\n",
  "hints_text": "Looks like a bug, it would help if we could reproduce it locally. Is it possible to share the table definition and a sample of data for which the restart reproduces?\nYes of course, tell me where I sent the information in a private way.\nYou can send data and queries to clickhouse-feedback@yandex-team.ru. \nSend it!\nNeed more data?\nThanks for the data, I could reproduce it locally, will investigate.\nLooks like it's already fixed here: https://github.com/ClickHouse/ClickHouse/pull/7135\r\n\r\nNow that I know the cause, I'll try to create a simple test case.\nHere it is:\r\n\r\n```\r\ncreate table p (x Nullable(String)) engine MergeTree order by ifNull(x, 'order-null') partition by ifNull(x, 'partition-null');\r\n\r\ninsert into p values (null);\r\n```\r\n\r\nThe segfault occurs when we try to serialize min/max values of partitioning columns, one such value unexpectedly turns out to be NULL, and this leads to memory access by an uninitialized pointer.\r\nThe PR I mentioned fixed the segfault itself, but apparently something else is broken, because the NULL value shouldn't get past the ifNull function.\n> because the NULL value shouldn't get past the ifNull function.\r\n\r\nIt works as expected. For minmax of partition expression, values of source columns are tracked, not the value of full expression.\n@akuzm You can add this example as a test.",
  "created_at": "2019-10-08T18:23:51Z"
}