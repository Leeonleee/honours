{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 18775,
  "instance_id": "ClickHouse__ClickHouse-18775",
  "issue_numbers": [
    "14571"
  ],
  "base_commit": "176358f0b4bfcafa12887b2b6cd8e7fb397a56e3",
  "patch": "diff --git a/src/Storages/Distributed/DistributedBlockOutputStream.cpp b/src/Storages/Distributed/DistributedBlockOutputStream.cpp\nindex 040f33ea02ee..369f07cac4ee 100644\n--- a/src/Storages/Distributed/DistributedBlockOutputStream.cpp\n+++ b/src/Storages/Distributed/DistributedBlockOutputStream.cpp\n@@ -299,6 +299,10 @@ DistributedBlockOutputStream::runWritingJob(DistributedBlockOutputStream::JobRep\n         const Block & shard_block = (num_shards > 1) ? job.current_shard_block : current_block;\n         const Settings & settings = context.getSettingsRef();\n \n+        /// Do not initiate INSERT for empty block.\n+        if (shard_block.rows() == 0)\n+            return;\n+\n         if (!job.is_local_job || !settings.prefer_localhost_replica)\n         {\n             if (!job.stream)\n@@ -368,7 +372,8 @@ void DistributedBlockOutputStream::writeSync(const Block & block)\n     const Settings & settings = context.getSettingsRef();\n     const auto & shards_info = cluster->getShardsInfo();\n     bool random_shard_insert = settings.insert_distributed_one_random_shard && !storage.has_sharding_key;\n-    size_t start = 0, end = shards_info.size();\n+    size_t start = 0;\n+    size_t end = shards_info.size();\n     if (random_shard_insert)\n     {\n         start = storage.getRandomShardIndex(shards_info);\ndiff --git a/src/Storages/StorageDistributed.cpp b/src/Storages/StorageDistributed.cpp\nindex 4ce7efb60b4d..1390455edb11 100644\n--- a/src/Storages/StorageDistributed.cpp\n+++ b/src/Storages/StorageDistributed.cpp\n@@ -540,7 +540,7 @@ BlockOutputStreamPtr StorageDistributed::write(const ASTPtr &, const StorageMeta\n     /// Ban an attempt to make async insert into the table belonging to DatabaseMemory\n     if (!storage_policy && !owned_cluster && !settings.insert_distributed_sync)\n     {\n-        throw Exception(\"Storage \" + getName() + \" must has own data directory to enable asynchronous inserts\",\n+        throw Exception(\"Storage \" + getName() + \" must have own data directory to enable asynchronous inserts\",\n                         ErrorCodes::BAD_ARGUMENTS);\n     }\n \n@@ -558,8 +558,10 @@ BlockOutputStreamPtr StorageDistributed::write(const ASTPtr &, const StorageMeta\n \n     /// DistributedBlockOutputStream will not own cluster, but will own ConnectionPools of the cluster\n     return std::make_shared<DistributedBlockOutputStream>(\n-        context, *this, metadata_snapshot, createInsertToRemoteTableQuery(remote_database, remote_table, metadata_snapshot->getSampleBlockNonMaterialized()), cluster,\n-        insert_sync, timeout);\n+        context, *this, metadata_snapshot,\n+        createInsertToRemoteTableQuery(\n+            remote_database, remote_table, metadata_snapshot->getSampleBlockNonMaterialized()),\n+        cluster, insert_sync, timeout);\n }\n \n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01639_distributed_sync_insert_zero_rows.reference b/tests/queries/0_stateless/01639_distributed_sync_insert_zero_rows.reference\nnew file mode 100644\nindex 000000000000..ad86be865c1d\n--- /dev/null\n+++ b/tests/queries/0_stateless/01639_distributed_sync_insert_zero_rows.reference\n@@ -0,0 +1,6 @@\n+128\n+256\n+128\n+256\n+128\n+256\ndiff --git a/tests/queries/0_stateless/01639_distributed_sync_insert_zero_rows.sql b/tests/queries/0_stateless/01639_distributed_sync_insert_zero_rows.sql\nnew file mode 100644\nindex 000000000000..7fb81efaac88\n--- /dev/null\n+++ b/tests/queries/0_stateless/01639_distributed_sync_insert_zero_rows.sql\n@@ -0,0 +1,24 @@\n+DROP TABLE IF EXISTS local;\n+DROP TABLE IF EXISTS distributed;\n+\n+CREATE TABLE local (x UInt8) ENGINE = Memory;\n+CREATE TABLE distributed AS local ENGINE = Distributed(test_cluster_two_shards, currentDatabase(), local, x);\n+\n+SET insert_distributed_sync = 1;\n+\n+INSERT INTO distributed SELECT number FROM numbers(256) WHERE number % 2 = 0;\n+SELECT count() FROM local;\n+SELECT count() FROM distributed;\n+\n+TRUNCATE TABLE local;\n+INSERT INTO distributed SELECT number FROM numbers(256) WHERE number % 2 = 1;\n+SELECT count() FROM local;\n+SELECT count() FROM distributed;\n+\n+TRUNCATE TABLE local;\n+INSERT INTO distributed SELECT number FROM numbers(256) WHERE number < 128;\n+SELECT count() FROM local;\n+SELECT count() FROM distributed;\n+\n+DROP TABLE local;\n+DROP TABLE distributed;\ndiff --git a/tests/queries/0_stateless/arcadia_skip_list.txt b/tests/queries/0_stateless/arcadia_skip_list.txt\nindex 3d9b70a621e1..6c6636b923db 100644\n--- a/tests/queries/0_stateless/arcadia_skip_list.txt\n+++ b/tests/queries/0_stateless/arcadia_skip_list.txt\n@@ -181,3 +181,4 @@\n 01561_mann_whitney_scipy\n 01601_custom_tld\n 01636_nullable_fuzz2\n+01639_distributed_sync_insert_zero_rows\n",
  "problem_statement": "INSERT to Distributed sent to a shard with zero weight\nNo rows are written, though. Still, this may be problematic when this insert fails due to the `too many parts` error, which leads to the parent insert also failing. I haven't reproduced this failure exactly (complicated to do on localhost), but seen it happen for a ClickHouse user in Yandex.\r\n\r\nApparently this only happens with `insert_distributed_sync = 1`.\r\n\r\nCluster config:\r\n```\r\n        <weighted>\r\n            <shard>\r\n                <weight>100</weight>\r\n                <replica>\r\n                    <host>127.0.0.2</host>\r\n                    <port>9000</port>\r\n                </replica>\r\n            </shard>\r\n            <shard>\r\n                <weight>0</weight>\r\n                <replica>\r\n                    <host>127.0.0.3</host>\r\n                    <port>9000</port>\r\n                </replica>\r\n            </shard>\r\n            <shard>\r\n                <weight>100</weight>\r\n                <replica>\r\n                    <host>127.0.0.4</host>\r\n                    <port>9000</port>\r\n                </replica>\r\n            </shard>\r\n        </weighted>\r\n```\r\n\r\nQueries:\r\n\r\n```\r\ncreate table t_local (a int) engine MergeTree order by (a);\r\n\r\ncreate table t_dist (a int) engine Distributed(weighted, 'default', 't_local', cityHash64(a));\r\n\r\nset insert_distributed_sync = 1;\r\n\r\nselect written_rows, query_id from system.query_log where initial_query_id = '4c93852e-bdcb-436a-9ad3-4953ccedfcdc' and type != 1;\r\n```\r\n\r\nIn the query log we see that the query is sent to all three shards, including the one with zero weight, but no rows are sent there.\r\n```\r\nSELECT \r\n    written_rows,\r\n    query_id\r\nFROM system.query_log\r\nWHERE (initial_query_id = '4c93852e-bdcb-436a-9ad3-4953ccedfcdc') AND (type != 1)\r\n\r\n\u250c\u2500written_rows\u2500\u252c\u2500query_id\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502            0 \u2502 177294a7-5612-45ef-bb57-2b36b73d709f \u2502\r\n\u2502       499720 \u2502 02d724ae-5840-4805-9e5f-747a85332545 \u2502\r\n\u2502       500280 \u2502 a4692444-5409-4aec-a821-d9095e912ca1 \u2502\r\n\u2502      1000000 \u2502 4c93852e-bdcb-436a-9ad3-4953ccedfcdc \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nFor more fun, try the `Log` engine for `t_local` -- the insert deadlocks: https://github.com/ClickHouse/ClickHouse/issues/14570\n",
  "hints_text": "The stack trace of a child query failing with `too many parts` looks like this:\r\n```\r\nstack_trace:          0. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Exception.cpp:27: Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x110c8ef0 in /usr/lib/debug/usr/bin/clickhouse\r\n1. /build/obj-x86_64-linux-gnu/../src/Common/Exception.cpp:32: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x998893d in /usr/lib/debug/usr/bin/clickhouse\r\n2. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/string:2134: DB::MergeTreeData::throwInsertIfNeeded() const (.cold) @ 0xe555134 in /usr/lib/debug/usr/bin/clickhouse\r\n3. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/vector:1516: DB::PushingToViewsBlockOutputStream::writePrefix() @ 0xde7099c in /usr/lib/debug/usr/bin/clickhouse\r\n4. /build/obj-x86_64-linux-gnu/../programs/server/TCPHandler.cpp:464: DB::TCPHandler::processInsertQuery(DB::Settings const&) @ 0x9a8e24a in /usr/lib/debug/usr/bin/clickhouse\r\n5. /build/obj-x86_64-linux-gnu/../programs/server/TCPHandler.cpp:262: DB::TCPHandler::runImpl() @ 0x9a8f977 in /usr/lib/debug/usr/bin/clickhouse\r\n6. /build/obj-x86_64-linux-gnu/../programs/server/TCPHandler.cpp:1242: DB::TCPHandler::run() @ 0x9a8ffa0 in /usr/lib/debug/usr/bin/clickhouse\r\n7. /build/obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerConnection.cpp:57: Poco::Net::TCPServerConnection::start() @ 0x10fb4c6b in /usr/lib/debug/usr/bin/clickhouse\r\n8. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/atomic:856: Poco::Net::TCPServerDispatcher::run() @ 0x10fb50fb in /usr/lib/debug/usr/bin/clickhouse\r\n9. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/Mutex_POSIX.h:59: Poco::PooledThread::run() @ 0x11162cc6 in /usr/lib/debug/usr/bin/clickhouse\r\n10. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/AutoPtr.h:223: Poco::ThreadImpl::runnableEntry(void*) @ 0x1115df80 in /usr/lib/debug/usr/bin/clickhouse\r\n11. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n12. __clone @ 0x121a3f in /lib/x86_64-linux-gnu/libc-2.27.so\r\n```\r\n\r\nThe exception happens in `writePrefix`, which we do before we even receive any data.",
  "created_at": "2021-01-05T23:55:45Z"
}