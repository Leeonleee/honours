{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 27927,
  "instance_id": "ClickHouse__ClickHouse-27927",
  "issue_numbers": [
    "27832"
  ],
  "base_commit": "3bf412c656795199c5ef3a7aa291bb4ea99bf56b",
  "patch": "diff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex a634c19dcd61..3058132dc364 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -1821,8 +1821,8 @@ std::shared_ptr<Cluster> Context::getCluster(const std::string & cluster_name) c\n     auto res = getClusters()->getCluster(cluster_name);\n     if (res)\n         return res;\n-\n-    res = tryGetReplicatedDatabaseCluster(cluster_name);\n+    if (!cluster_name.empty())\n+        res = tryGetReplicatedDatabaseCluster(cluster_name);\n     if (res)\n         return res;\n \ndiff --git a/src/Storages/StorageDistributed.cpp b/src/Storages/StorageDistributed.cpp\nindex fcd0e255e5c9..df7d568deb95 100644\n--- a/src/Storages/StorageDistributed.cpp\n+++ b/src/Storages/StorageDistributed.cpp\n@@ -327,11 +327,13 @@ StorageDistributed::StorageDistributed(\n     const String & relative_data_path_,\n     const DistributedSettings & distributed_settings_,\n     bool attach_,\n-    ClusterPtr owned_cluster_)\n+    ClusterPtr owned_cluster_,\n+    ASTPtr remote_table_function_ptr_)\n     : IStorage(id_)\n     , WithContext(context_->getGlobalContext())\n     , remote_database(remote_database_)\n     , remote_table(remote_table_)\n+    , remote_table_function_ptr(remote_table_function_ptr_)\n     , log(&Poco::Logger::get(\"StorageDistributed (\" + id_.table_name + \")\"))\n     , owned_cluster(std::move(owned_cluster_))\n     , cluster_name(getContext()->getMacros()->expand(cluster_name_))\n@@ -363,10 +365,13 @@ StorageDistributed::StorageDistributed(\n     }\n \n     /// Sanity check. Skip check if the table is already created to allow the server to start.\n-    if (!attach_ && !cluster_name.empty())\n+    if (!attach_)\n     {\n-        size_t num_local_shards = getContext()->getCluster(cluster_name)->getLocalShardCount();\n-        if (num_local_shards && remote_database == id_.database_name && remote_table == id_.table_name)\n+        if (remote_database.empty() && !remote_table_function_ptr && !getCluster()->maybeCrossReplication())\n+            LOG_WARNING(log, \"Name of remote database is empty. Default database will be used implicitly.\");\n+\n+        size_t num_local_shards = getCluster()->getLocalShardCount();\n+        if (num_local_shards && (remote_database.empty() || remote_database == id_.database_name) && remote_table == id_.table_name)\n             throw Exception(\"Distributed table \" + id_.table_name + \" looks at itself\", ErrorCodes::INFINITE_LOOP);\n     }\n }\n@@ -399,9 +404,9 @@ StorageDistributed::StorageDistributed(\n         relative_data_path_,\n         distributed_settings_,\n         attach,\n-        std::move(owned_cluster_))\n+        std::move(owned_cluster_),\n+        remote_table_function_ptr_)\n {\n-    remote_table_function_ptr = std::move(remote_table_function_ptr_);\n }\n \n QueryProcessingStage::Enum StorageDistributed::getQueryProcessingStage(\n@@ -810,9 +815,6 @@ void StorageDistributed::alter(const AlterCommands & params, ContextPtr local_co\n \n void StorageDistributed::startup()\n {\n-    if (remote_database.empty() && !remote_table_function_ptr && !getCluster()->maybeCrossReplication())\n-        LOG_WARNING(log, \"Name of remote database is empty. Default database will be used implicitly.\");\n-\n     if (!storage_policy)\n         return;\n \ndiff --git a/src/Storages/StorageDistributed.h b/src/Storages/StorageDistributed.h\nindex b6a26467a3fd..b003f8c64867 100644\n--- a/src/Storages/StorageDistributed.h\n+++ b/src/Storages/StorageDistributed.h\n@@ -136,7 +136,8 @@ class StorageDistributed final : public shared_ptr_helper<StorageDistributed>, p\n         const String & relative_data_path_,\n         const DistributedSettings & distributed_settings_,\n         bool attach_,\n-        ClusterPtr owned_cluster_ = {});\n+        ClusterPtr owned_cluster_ = {},\n+        ASTPtr remote_table_function_ptr_ = {});\n \n     StorageDistributed(\n         const StorageID & id_,\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/00987_distributed_stack_overflow.sql b/tests/queries/0_stateless/00987_distributed_stack_overflow.sql\nindex d2e2b8f37ef6..1ef7c5432526 100644\n--- a/tests/queries/0_stateless/00987_distributed_stack_overflow.sql\n+++ b/tests/queries/0_stateless/00987_distributed_stack_overflow.sql\n@@ -4,8 +4,7 @@ DROP TABLE IF EXISTS distr2;\n \n CREATE TABLE distr (x UInt8) ENGINE = Distributed(test_shard_localhost, currentDatabase(), distr); -- { serverError 269 }\n \n-CREATE TABLE distr0 (x UInt8) ENGINE = Distributed(test_shard_localhost, '', distr0);\n-SELECT * FROM distr0; -- { serverError 581 }\n+CREATE TABLE distr0 (x UInt8) ENGINE = Distributed(test_shard_localhost, '', distr0); -- { serverError 269 }\n \n CREATE TABLE distr1 (x UInt8) ENGINE = Distributed(test_shard_localhost, currentDatabase(), distr2);\n CREATE TABLE distr2 (x UInt8) ENGINE = Distributed(test_shard_localhost, currentDatabase(), distr1);\n@@ -13,6 +12,5 @@ CREATE TABLE distr2 (x UInt8) ENGINE = Distributed(test_shard_localhost, current\n SELECT * FROM distr1; -- { serverError 581 }\n SELECT * FROM distr2; -- { serverError 581 }\n \n-DROP TABLE distr0;\n DROP TABLE distr1;\n DROP TABLE distr2;\ndiff --git a/tests/queries/0_stateless/01763_max_distributed_depth.sql b/tests/queries/0_stateless/01763_max_distributed_depth.sql\nindex d1bb9e4be90d..89909a3bd8dd 100644\n--- a/tests/queries/0_stateless/01763_max_distributed_depth.sql\n+++ b/tests/queries/0_stateless/01763_max_distributed_depth.sql\n@@ -9,7 +9,9 @@ CREATE TABLE tt6\n \t`status` String\n \n )\n-ENGINE = Distributed('test_shard_localhost', '', 'tt6', rand());\n+ENGINE = Distributed('test_shard_localhost', '', 'tt7', rand());\n+\n+CREATE TABLE tt7 as tt6 ENGINE = Distributed('test_shard_localhost', '', 'tt6', rand());\n \n INSERT INTO tt6 VALUES (1, 1, 1, 1, 'ok'); -- { serverError 581 }\n \n",
  "problem_statement": "DDL creation of a distributed table with empty cluster '' returns exception but with wrong table created, restart will fail.\nWhen I tried to create a distributed table with empty cluster '', the create statement failed with exception \"Code: 170. DB::Exception: Received from localhost:9000. DB::Exception: Requested cluster '' not found.\". However, show tables can see the WRONG table.\r\nLater when CH restarted, unable to start due to unable to attach this wrong table.\r\n\r\nThe question is: When we try to startup the new created table during creation, if error happens, this new table should be dropped? OR we should add some special check on the cluster for Distributed engine to avoid this kind of error? OR we can just ignore this error during start up to allow CK server to start, not failed?\r\n\r\nCH version: 21.7.3.14 (official build).\r\nHow to reproduce:\r\n1. Create wrong table:\r\n    create table t_empty(a int) engine=Distributed('','','');\r\n2. Force CH to restart, and check the status\r\nservice clickhouse-server forcerestart\r\nservice clickhouse-server status\r\nNow there is no clickhouse-server process.\r\n\r\n**##### output ###** \r\nnode236 :) create table t_empty(a int) engine=Distributed('','','');\r\n\r\nCREATE TABLE t_empty\r\n(\r\n    `a` int\r\n)\r\nENGINE = Distributed('', '', '')\r\n\r\nQuery id: c9eb24ea-f87d-4431-9bdc-18d21fbb5636\r\n\r\n\r\n0 rows in set. Elapsed: 0.054 sec.\r\n\r\nReceived exception from server (version 21.7.3):\r\n**Code: 170. DB::Exception: Received from localhost:9000. DB::Exception: Requested cluster '' not found.**\r\n\r\nnode236 :) show tables;\r\n\r\nSHOW TABLES\r\n\r\nQuery id: 0d9e2398-26c5-46eb-baf2-a02111bc770e\r\n\r\n\u250c\u2500name\u2500\u2500\u2500\u2500\u2510\r\n\u2502 people  \u2502\r\n\u2502 **t_empty** \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n2 rows in set. Elapsed: 0.001 sec.\r\n\r\nnode236 :) show create table t_empty;\r\n\r\nSHOW CREATE TABLE t_empty\r\n\r\nQuery id: 8c489c90-dfe0-4392-9742-17a43a075c12\r\n\r\n\u250c\u2500statement\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 CREATE TABLE default.t_empty\r\n(\r\n    `a` Int32\r\n)\r\nENGINE = **Distributed('', '', '')** \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n==== clickhouse-server.err.log ===\r\n### backtrace for DDL ###\r\n2021.08.19 12:12:03.150990 [ 19900 ] {c9eb24ea-f87d-4431-9bdc-18d21fbb5636} <Error> TCPHandler: Code: 170, e.displayText() = DB::Exception: Requested cluster '' n\r\not found, Stack trace:\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8d31b5a in /usr/bin/click\r\nhouse\r\n1. DB::Context::getCluster(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const @ 0xf73b378 in /usr/bin/clickhouse\r\n2. DB::StorageDistributed::getCluster() const @ 0x100081f7 in /usr/bin/clickhouse\r\n3. DB::StorageDistributed::startup() @ 0x1000e5b2 in /usr/bin/clickhouse\r\n4. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&) @ 0xf875226 in /usr/bin/clickhouse\r\n5. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0xf8711e3 in /usr/bin/clickhouse\r\n6. DB::InterpreterCreateQuery::execute() @ 0xf87735c in /usr/bin/clickhouse\r\n7. ? @ 0xfe22253 in /usr/bin/clickhouse\r\n8. DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::Context>, bool, DB::Que\r\nryProcessingStage::Enum, bool) @ 0xfe208e3 in /usr/bin/clickhouse\r\n9. DB::TCPHandler::runImpl() @ 0x1069f6c2 in /usr/bin/clickhouse\r\n10. DB::TCPHandler::run() @ 0x106b25d9 in /usr/bin/clickhouse\r\n11. Poco::Net::TCPServerConnection::start() @ 0x1338b30f in /usr/bin/clickhouse\r\n12. Poco::Net::TCPServerDispatcher::run() @ 0x1338cd9a in /usr/bin/clickhouse\r\n13. Poco::PooledThread::run() @ 0x134bfc19 in /usr/bin/clickhouse\r\n14. Poco::ThreadImpl::runnableEntry(void*) @ 0x134bbeaa in /usr/bin/clickhouse\r\n15. start_thread @ 0x7ea5 in /usr/lib64/libpthread-2.17.so\r\n16. __clone @ 0xfe9fd in /usr/lib64/libc-2.17.so\r\n\r\n### backtrace for start up of CH ### \r\n2021.08.19 12:22:47.254734 [ 25174 ] {} <Error> Application: Caught exception while loading metadata: Code: 170, e.displayText() = DB::Exception: Requested cluster '' not found: while loading database `default` from path /var/lib/clickhouse/metadata/default, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8d31b5a in /usr/bin/clickhouse\r\n1. DB::Context::getCluster(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const @ 0xf73b378 in /usr/bin/clickhouse\r\n2. DB::StorageDistributed::getCluster() const @ 0x100081f7 in /usr/bin/clickhouse\r\n3. DB::StorageDistributed::startup() @ 0x1000e5b2 in /usr/bin/clickhouse\r\n4. ? @ 0xf646a3b in /usr/bin/clickhouse\r\n5. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8d75738 in /usr/bin/clickhouse\r\n6. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()&&...)::'lambda'()::operator()() @ 0x8d772df in /usr/bin/clickhouse\r\n7. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8d72a1f in /usr/bin/clickhouse\r\n8. ? @ 0x8d76303 in /usr/bin/clickhouse\r\n9. start_thread @ 0x7ea5 in /usr/lib64/libpthread-2.17.so\r\n10. __clone @ 0xfe9fd in /usr/lib64/libc-2.17.so\r\n (version 21.7.3.14 (official build))\r\n2021.08.19 12:22:48.260957 [ 25174 ] {} <Error> Application: DB::Exception: Requested cluster '' not found: while loading database `default` from path /var/lib/clickhouse/metadata/default\r\n\r\n\n",
  "hints_text": "",
  "created_at": "2021-08-20T12:12:07Z"
}