{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 31182,
  "instance_id": "ClickHouse__ClickHouse-31182",
  "issue_numbers": [
    "28375"
  ],
  "base_commit": "309af644750ec8895fe2f088727edb309992f226",
  "patch": "diff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex 9fa36e3de89d..79837310ec4a 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -22,6 +22,7 @@\n #include <base/getMemoryAmount.h>\n #include <base/errnoToString.h>\n #include <base/coverage.h>\n+#include <Common/MemoryTracker.h>\n #include <Common/ClickHouseRevision.h>\n #include <Common/DNSResolver.h>\n #include <Common/CurrentMetrics.h>\n@@ -925,6 +926,14 @@ if (ThreadFuzzer::instance().isEffective())\n             total_memory_tracker.setDescription(\"(total)\");\n             total_memory_tracker.setMetric(CurrentMetrics::MemoryTracking);\n \n+            auto * global_overcommit_tracker = global_context->getGlobalOvercommitTracker();\n+            if (config->has(\"global_memory_usage_overcommit_max_wait_microseconds\"))\n+            {\n+                UInt64 max_overcommit_wait_time = config->getUInt64(\"global_memory_usage_overcommit_max_wait_microseconds\", 0);\n+                global_overcommit_tracker->setMaxWaitTime(max_overcommit_wait_time);\n+            }\n+            total_memory_tracker.setOvercommitTracker(global_overcommit_tracker);\n+\n             // FIXME logging-related things need synchronization -- see the 'Logger * log' saved\n             // in a lot of places. For now, disable updating log configuration without server restart.\n             //setTextLog(global_context->getTextLog());\ndiff --git a/src/Common/MemoryTracker.cpp b/src/Common/MemoryTracker.cpp\nindex ba98ede221a7..4c8af23791eb 100644\n--- a/src/Common/MemoryTracker.cpp\n+++ b/src/Common/MemoryTracker.cpp\n@@ -1,6 +1,7 @@\n #include \"MemoryTracker.h\"\n \n #include <IO/WriteHelpers.h>\n+#include <Common/VariableContext.h>\n #include <Interpreters/TraceCollector.h>\n #include <Common/Exception.h>\n #include <Common/LockMemoryExceptionInThread.h>\n@@ -8,6 +9,7 @@\n #include <Common/formatReadable.h>\n #include <Common/ProfileEvents.h>\n #include <Common/thread_local_rng.h>\n+#include <Common/OvercommitTracker.h>\n #include <base/logger_useful.h>\n \n #include <atomic>\n@@ -95,7 +97,7 @@ void MemoryTracker::logMemoryUsage(Int64 current) const\n }\n \n \n-void MemoryTracker::allocImpl(Int64 size, bool throw_if_memory_exceeded)\n+void MemoryTracker::allocImpl(Int64 size, bool throw_if_memory_exceeded, MemoryTracker * query_tracker)\n {\n     if (size < 0)\n         throw DB::Exception(DB::ErrorCodes::LOGICAL_ERROR, \"Negative size ({}) is passed to MemoryTracker. It is a bug.\", size);\n@@ -104,7 +106,8 @@ void MemoryTracker::allocImpl(Int64 size, bool throw_if_memory_exceeded)\n     {\n         /// Since the MemoryTrackerBlockerInThread should respect the level, we should go to the next parent.\n         if (auto * loaded_next = parent.load(std::memory_order_relaxed))\n-            loaded_next->allocImpl(size, throw_if_memory_exceeded);\n+            loaded_next->allocImpl(size, throw_if_memory_exceeded,\n+                level == VariableContext::Process ? this : query_tracker);\n         return;\n     }\n \n@@ -186,18 +189,30 @@ void MemoryTracker::allocImpl(Int64 size, bool throw_if_memory_exceeded)\n \n     if (unlikely(current_hard_limit && will_be > current_hard_limit) && memoryTrackerCanThrow(level, false) && throw_if_memory_exceeded)\n     {\n-        /// Prevent recursion. Exception::ctor -> std::string -> new[] -> MemoryTracker::alloc\n-        MemoryTrackerBlockerInThread untrack_lock(VariableContext::Global);\n-        ProfileEvents::increment(ProfileEvents::QueryMemoryLimitExceeded);\n-        const auto * description = description_ptr.load(std::memory_order_relaxed);\n-        throw DB::Exception(\n-            DB::ErrorCodes::MEMORY_LIMIT_EXCEEDED,\n-            \"Memory limit{}{} exceeded: would use {} (attempt to allocate chunk of {} bytes), maximum: {}\",\n-            description ? \" \" : \"\",\n-            description ? description : \"\",\n-            formatReadableSizeWithBinarySuffix(will_be),\n-            size,\n-            formatReadableSizeWithBinarySuffix(current_hard_limit));\n+        bool need_to_throw = true;\n+        bool try_to_free_memory = overcommit_tracker != nullptr && query_tracker != nullptr;\n+        if (try_to_free_memory)\n+            need_to_throw = overcommit_tracker->needToStopQuery(query_tracker);\n+\n+        if (need_to_throw)\n+        {\n+            /// Prevent recursion. Exception::ctor -> std::string -> new[] -> MemoryTracker::alloc\n+            MemoryTrackerBlockerInThread untrack_lock(VariableContext::Global);\n+            ProfileEvents::increment(ProfileEvents::QueryMemoryLimitExceeded);\n+            const auto * description = description_ptr.load(std::memory_order_relaxed);\n+            throw DB::Exception(\n+                DB::ErrorCodes::MEMORY_LIMIT_EXCEEDED,\n+                \"Memory limit{}{} exceeded: would use {} (attempt to allocate chunk of {} bytes), maximum: {}\",\n+                description ? \" \" : \"\",\n+                description ? description : \"\",\n+                formatReadableSizeWithBinarySuffix(will_be),\n+                size,\n+                formatReadableSizeWithBinarySuffix(current_hard_limit));\n+        }\n+        else\n+        {\n+            will_be = amount.load(std::memory_order_relaxed);\n+        }\n     }\n \n     bool peak_updated;\n@@ -221,7 +236,8 @@ void MemoryTracker::allocImpl(Int64 size, bool throw_if_memory_exceeded)\n     }\n \n     if (auto * loaded_next = parent.load(std::memory_order_relaxed))\n-        loaded_next->allocImpl(size, throw_if_memory_exceeded);\n+        loaded_next->allocImpl(size, throw_if_memory_exceeded,\n+            level == VariableContext::Process ? this : query_tracker);\n }\n \n void MemoryTracker::alloc(Int64 size)\n@@ -302,10 +318,23 @@ void MemoryTracker::free(Int64 size)\n }\n \n \n+OvercommitRatio MemoryTracker::getOvercommitRatio()\n+{\n+    return { amount.load(std::memory_order_relaxed), soft_limit.load(std::memory_order_relaxed) };\n+}\n+\n+\n+OvercommitRatio MemoryTracker::getOvercommitRatio(Int64 limit)\n+{\n+    return { amount.load(std::memory_order_relaxed), limit };\n+}\n+\n+\n void MemoryTracker::resetCounters()\n {\n     amount.store(0, std::memory_order_relaxed);\n     peak.store(0, std::memory_order_relaxed);\n+    soft_limit.store(0, std::memory_order_relaxed);\n     hard_limit.store(0, std::memory_order_relaxed);\n     profiler_limit.store(0, std::memory_order_relaxed);\n }\n@@ -330,6 +359,12 @@ void MemoryTracker::set(Int64 to)\n }\n \n \n+void MemoryTracker::setSoftLimit(Int64 value)\n+{\n+    soft_limit.store(value, std::memory_order_relaxed);\n+}\n+\n+\n void MemoryTracker::setHardLimit(Int64 value)\n {\n     hard_limit.store(value, std::memory_order_relaxed);\ndiff --git a/src/Common/MemoryTracker.h b/src/Common/MemoryTracker.h\nindex a0138b25b5f7..780a869acad4 100644\n--- a/src/Common/MemoryTracker.h\n+++ b/src/Common/MemoryTracker.h\n@@ -28,6 +28,9 @@ extern thread_local bool memory_tracker_always_throw_logical_error_on_allocation\n #define ALLOW_ALLOCATIONS_IN_SCOPE static_assert(true)\n #endif\n \n+struct OvercommitRatio;\n+struct OvercommitTracker;\n+\n /** Tracks memory consumption.\n   * It throws an exception if amount of consumed memory become greater than certain limit.\n   * The same memory tracker could be simultaneously used in different threads.\n@@ -40,6 +43,7 @@ class MemoryTracker\n private:\n     std::atomic<Int64> amount {0};\n     std::atomic<Int64> peak {0};\n+    std::atomic<Int64> soft_limit {0};\n     std::atomic<Int64> hard_limit {0};\n     std::atomic<Int64> profiler_limit {0};\n \n@@ -61,6 +65,8 @@ class MemoryTracker\n     /// This description will be used as prefix into log messages (if isn't nullptr)\n     std::atomic<const char *> description_ptr = nullptr;\n \n+    OvercommitTracker * overcommit_tracker = nullptr;\n+\n     bool updatePeak(Int64 will_be, bool log_memory_usage);\n     void logMemoryUsage(Int64 current) const;\n \n@@ -83,7 +89,7 @@ class MemoryTracker\n \n     void allocNoThrow(Int64 size);\n \n-    void allocImpl(Int64 size, bool throw_if_memory_exceeded);\n+    void allocImpl(Int64 size, bool throw_if_memory_exceeded, MemoryTracker * query_tracker = nullptr);\n \n     void realloc(Int64 old_size, Int64 new_size)\n     {\n@@ -108,8 +114,14 @@ class MemoryTracker\n         return peak.load(std::memory_order_relaxed);\n     }\n \n+    void setSoftLimit(Int64 value);\n     void setHardLimit(Int64 value);\n \n+    Int64 getSoftLimit() const\n+    {\n+        return soft_limit.load(std::memory_order_relaxed);\n+    }\n+\n     /** Set limit if it was not set.\n       * Otherwise, set limit to new value, if new value is greater than previous limit.\n       */\n@@ -159,6 +171,14 @@ class MemoryTracker\n         description_ptr.store(description, std::memory_order_relaxed);\n     }\n \n+    OvercommitRatio getOvercommitRatio();\n+    OvercommitRatio getOvercommitRatio(Int64 limit);\n+\n+    void setOvercommitTracker(OvercommitTracker * tracker) noexcept\n+    {\n+        overcommit_tracker = tracker;\n+    }\n+\n     /// Reset the accumulated data\n     void resetCounters();\n \ndiff --git a/src/Common/OvercommitTracker.cpp b/src/Common/OvercommitTracker.cpp\nnew file mode 100644\nindex 000000000000..4be7096aa607\n--- /dev/null\n+++ b/src/Common/OvercommitTracker.cpp\n@@ -0,0 +1,119 @@\n+#include \"OvercommitTracker.h\"\n+\n+#include <chrono>\n+#include <mutex>\n+#include <Interpreters/ProcessList.h>\n+\n+using namespace std::chrono_literals;\n+\n+OvercommitTracker::OvercommitTracker()\n+    : max_wait_time(0us)\n+    , picked_tracker(nullptr)\n+    , cancelation_state(QueryCancelationState::NONE)\n+{}\n+\n+void OvercommitTracker::setMaxWaitTime(UInt64 wait_time)\n+{\n+    std::lock_guard guard(overcommit_m);\n+    max_wait_time = wait_time * 1us;\n+}\n+\n+bool OvercommitTracker::needToStopQuery(MemoryTracker * tracker)\n+{\n+    std::unique_lock<std::mutex> lk(overcommit_m);\n+\n+    pickQueryToExclude();\n+    assert(cancelation_state == QueryCancelationState::RUNNING);\n+\n+    // If no query was chosen we need to stop current query.\n+    // This may happen if no soft limit is set.\n+    if (picked_tracker == nullptr)\n+    {\n+        cancelation_state = QueryCancelationState::NONE;\n+        return true;\n+    }\n+    if (picked_tracker == tracker)\n+        return true;\n+    return !cv.wait_for(lk, max_wait_time, [this]()\n+    {\n+        return cancelation_state == QueryCancelationState::NONE;\n+    });\n+}\n+\n+void OvercommitTracker::unsubscribe(MemoryTracker * tracker)\n+{\n+    std::unique_lock<std::mutex> lk(overcommit_m);\n+    if (picked_tracker == tracker)\n+    {\n+        LOG_DEBUG(getLogger(), \"Picked query stopped\");\n+\n+        picked_tracker = nullptr;\n+        cancelation_state = QueryCancelationState::NONE;\n+        cv.notify_all();\n+    }\n+}\n+\n+UserOvercommitTracker::UserOvercommitTracker(DB::ProcessListForUser * user_process_list_)\n+    : user_process_list(user_process_list_)\n+{}\n+\n+void UserOvercommitTracker::pickQueryToExcludeImpl()\n+{\n+    MemoryTracker * query_tracker = nullptr;\n+    OvercommitRatio current_ratio{0, 0};\n+    // At this moment query list must be read only.\n+    // BlockQueryIfMemoryLimit is used in ProcessList to guarantee this.\n+    auto & queries = user_process_list->queries;\n+    LOG_DEBUG(logger, \"Trying to choose query to stop from {} queries\", queries.size());\n+    for (auto const & query : queries)\n+    {\n+        if (query.second->isKilled())\n+            continue;\n+\n+        auto * memory_tracker = query.second->getMemoryTracker();\n+        if (!memory_tracker)\n+            continue;\n+\n+        auto ratio = memory_tracker->getOvercommitRatio();\n+        LOG_DEBUG(logger, \"Query has ratio {}/{}\", ratio.committed, ratio.soft_limit);\n+        if (ratio.soft_limit != 0 && current_ratio < ratio)\n+        {\n+            query_tracker = memory_tracker;\n+            current_ratio   = ratio;\n+        }\n+    }\n+    LOG_DEBUG(logger, \"Selected to stop query with overcommit ratio {}/{}\",\n+        current_ratio.committed, current_ratio.soft_limit);\n+    picked_tracker = query_tracker;\n+}\n+\n+void GlobalOvercommitTracker::pickQueryToExcludeImpl()\n+{\n+    MemoryTracker * query_tracker = nullptr;\n+    OvercommitRatio current_ratio{0, 0};\n+    process_list->processEachQueryStatus([&](DB::QueryStatus const & query)\n+    {\n+        if (query.isKilled())\n+            return;\n+\n+        Int64 user_soft_limit = 0;\n+        if (auto const * user_process_list = query.getUserProcessList())\n+            user_soft_limit = user_process_list->user_memory_tracker.getSoftLimit();\n+        if (user_soft_limit == 0)\n+            return;\n+\n+        auto * memory_tracker = query.getMemoryTracker();\n+        if (!memory_tracker)\n+            return;\n+        auto ratio = memory_tracker->getOvercommitRatio(user_soft_limit);\n+        LOG_DEBUG(logger, \"Query has ratio {}/{}\", ratio.committed, ratio.soft_limit);\n+        if (current_ratio < ratio)\n+        {\n+            query_tracker = memory_tracker;\n+            current_ratio   = ratio;\n+        }\n+    });\n+    LOG_DEBUG(logger, \"Selected to stop query with overcommit ratio {}/{}\",\n+        current_ratio.committed, current_ratio.soft_limit);\n+    picked_tracker = query_tracker;\n+}\ndiff --git a/src/Common/OvercommitTracker.h b/src/Common/OvercommitTracker.h\nnew file mode 100644\nindex 000000000000..2286ad4bde20\n--- /dev/null\n+++ b/src/Common/OvercommitTracker.h\n@@ -0,0 +1,155 @@\n+#pragma once\n+\n+#include <base/logger_useful.h>\n+#include <base/types.h>\n+#include <boost/core/noncopyable.hpp>\n+#include <Poco/Logger.h>\n+#include <cassert>\n+#include <chrono>\n+#include <condition_variable>\n+#include <mutex>\n+#include <unordered_map>\n+\n+// This struct is used for the comparison of query memory usage.\n+struct OvercommitRatio\n+{\n+    OvercommitRatio(Int64 committed_, Int64 soft_limit_)\n+        : committed(committed_)\n+        , soft_limit(soft_limit_)\n+    {}\n+\n+    friend bool operator<(OvercommitRatio const & lhs, OvercommitRatio const & rhs) noexcept\n+    {\n+        // (a / b < c / d) <=> (a * d < c * b)\n+        return (lhs.committed * rhs.soft_limit) < (rhs.committed * lhs.soft_limit)\n+            || (lhs.soft_limit == 0 && rhs.soft_limit > 0)\n+            || (lhs.committed == 0 && rhs.committed == 0 && lhs.soft_limit > rhs.soft_limit);\n+    }\n+\n+    // actual query memory usage\n+    Int64 committed;\n+    // guaranteed amount of memory query can use\n+    Int64 soft_limit;\n+};\n+\n+class MemoryTracker;\n+\n+// Usually it's hard to set some reasonable hard memory limit\n+// (especially, the default value). This class introduces new\n+// mechanisim for the limiting of memory usage.\n+// Soft limit represents guaranteed amount of memory query/user\n+// may use. It's allowed to exceed this limit. But if hard limit\n+// is reached, query with the biggest overcommit ratio\n+// is killed to free memory.\n+struct OvercommitTracker : boost::noncopyable\n+{\n+    OvercommitTracker();\n+\n+    void setMaxWaitTime(UInt64 wait_time);\n+\n+    bool needToStopQuery(MemoryTracker * tracker);\n+\n+    void unsubscribe(MemoryTracker * tracker);\n+\n+    virtual ~OvercommitTracker() = default;\n+\n+protected:\n+    virtual void pickQueryToExcludeImpl() = 0;\n+\n+    mutable std::mutex overcommit_m;\n+    mutable std::condition_variable cv;\n+\n+    std::chrono::microseconds max_wait_time;\n+\n+    enum class QueryCancelationState\n+    {\n+        NONE,\n+        RUNNING,\n+    };\n+\n+    // Specifies memory tracker of the chosen to stop query.\n+    // If soft limit is not set, all the queries which reach hard limit must stop.\n+    // This case is represented as picked tracker pointer is set to nullptr and\n+    // overcommit tracker is in RUNNING state.\n+    MemoryTracker * picked_tracker;\n+    QueryCancelationState cancelation_state;\n+\n+    virtual Poco::Logger * getLogger() = 0;\n+\n+private:\n+\n+    void pickQueryToExclude()\n+    {\n+        if (cancelation_state != QueryCancelationState::RUNNING)\n+        {\n+            pickQueryToExcludeImpl();\n+            cancelation_state = QueryCancelationState::RUNNING;\n+        }\n+    }\n+\n+    friend struct BlockQueryIfMemoryLimit;\n+};\n+\n+namespace DB\n+{\n+    class ProcessList;\n+    struct ProcessListForUser;\n+}\n+\n+struct UserOvercommitTracker : OvercommitTracker\n+{\n+    explicit UserOvercommitTracker(DB::ProcessListForUser * user_process_list_);\n+\n+    ~UserOvercommitTracker() override = default;\n+\n+protected:\n+    void pickQueryToExcludeImpl() override final;\n+\n+    Poco::Logger * getLogger() override final { return logger; }\n+private:\n+    DB::ProcessListForUser * user_process_list;\n+    Poco::Logger * logger = &Poco::Logger::get(\"UserOvercommitTracker\");\n+};\n+\n+struct GlobalOvercommitTracker : OvercommitTracker\n+{\n+    explicit GlobalOvercommitTracker(DB::ProcessList * process_list_)\n+        : process_list(process_list_)\n+    {}\n+\n+    ~GlobalOvercommitTracker() override = default;\n+\n+protected:\n+    void pickQueryToExcludeImpl() override final;\n+\n+    Poco::Logger * getLogger() override final { return logger; }\n+private:\n+    DB::ProcessList * process_list;\n+    Poco::Logger * logger = &Poco::Logger::get(\"GlobalOvercommitTracker\");\n+};\n+\n+// UserOvercommitTracker requires to check the whole list of user's queries\n+// to pick one to stop. BlockQueryIfMemoryLimit struct allows to wait until\n+// query selection is finished. It's used in ProcessList to make user query\n+// list immutable when UserOvercommitTracker reads it.\n+struct BlockQueryIfMemoryLimit\n+{\n+    BlockQueryIfMemoryLimit(OvercommitTracker const & overcommit_tracker)\n+        : mutex(overcommit_tracker.overcommit_m)\n+        , lk(mutex)\n+    {\n+        if (overcommit_tracker.cancelation_state == OvercommitTracker::QueryCancelationState::RUNNING)\n+        {\n+            overcommit_tracker.cv.wait_for(lk, overcommit_tracker.max_wait_time, [&overcommit_tracker]()\n+            {\n+                return overcommit_tracker.cancelation_state == OvercommitTracker::QueryCancelationState::NONE;\n+            });\n+        }\n+    }\n+\n+    ~BlockQueryIfMemoryLimit() = default;\n+\n+private:\n+    std::mutex & mutex;\n+    std::unique_lock<std::mutex> lk;\n+};\ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex cd29ef959adc..7dc2aada25bd 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -358,11 +358,15 @@ class IColumn;\n     M(OverflowMode, distinct_overflow_mode, OverflowMode::THROW, \"What to do when the limit is exceeded.\", 0) \\\n     \\\n     M(UInt64, max_memory_usage, 0, \"Maximum memory usage for processing of single query. Zero means unlimited.\", 0) \\\n+    M(UInt64, max_guaranteed_memory_usage, 0, \"Maximum guaranteed memory usage for processing of single query. It represents soft limit. Zero means unlimited.\", 0) \\\n     M(UInt64, max_memory_usage_for_user, 0, \"Maximum memory usage for processing all concurrently running queries for the user. Zero means unlimited.\", 0) \\\n+    M(UInt64, max_guaranteed_memory_usage_for_user, 0, \"Maximum guaranteed memory usage for processing all concurrently running queries for the user. It represents soft limit. Zero means unlimited.\", 0) \\\n     M(UInt64, max_untracked_memory, (4 * 1024 * 1024), \"Small allocations and deallocations are grouped in thread local variable and tracked or profiled only when amount (in absolute value) becomes larger than specified value. If the value is higher than 'memory_profiler_step' it will be effectively lowered to 'memory_profiler_step'.\", 0) \\\n     M(UInt64, memory_profiler_step, (4 * 1024 * 1024), \"Whenever query memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace. Zero means disabled memory profiler. Values lower than a few megabytes will slow down query processing.\", 0) \\\n     M(Float, memory_profiler_sample_probability, 0., \"Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Note that sampling happens only when the amount of untracked memory exceeds 'max_untracked_memory'. You may want to set 'max_untracked_memory' to 0 for extra fine grained sampling.\", 0) \\\n     \\\n+    M(UInt64, memory_usage_overcommit_max_wait_microseconds, 0, \"Maximum time thread will wait for memory to be freed in the case of memory overcommit. If timeout is reached and memory is not freed, exception is thrown\", 0) \\\n+    \\\n     M(UInt64, max_network_bandwidth, 0, \"The maximum speed of data exchange over the network in bytes per second for a query. Zero means unlimited.\", 0) \\\n     M(UInt64, max_network_bytes, 0, \"The maximum number of bytes (compressed) to receive or transmit over the network for execution of the query.\", 0) \\\n     M(UInt64, max_network_bandwidth_for_user, 0, \"The maximum speed of data exchange over the network in bytes per second for all concurrently running user queries. Zero means unlimited.\", 0)\\\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex 822f1dcb534e..e8115c384bbe 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -208,6 +208,7 @@ struct ContextSharedPart\n     mutable MarkCachePtr index_mark_cache;                  /// Cache of marks in compressed files of MergeTree indices.\n     mutable MMappedFileCachePtr mmap_cache; /// Cache of mmapped files to avoid frequent open/map/unmap/close and to reuse from several threads.\n     ProcessList process_list;                               /// Executing queries at the moment.\n+    GlobalOvercommitTracker global_overcommit_tracker;\n     MergeList merge_list;                                   /// The list of executable merge (for (Replicated)?MergeTree)\n     ReplicatedFetchList replicated_fetch_list;\n     ConfigurationPtr users_config;                          /// Config with the users, profiles and quotas sections.\n@@ -275,7 +276,9 @@ struct ContextSharedPart\n     Context::ConfigReloadCallback config_reload_callback;\n \n     ContextSharedPart()\n-        : access_control(std::make_unique<AccessControl>()), macros(std::make_unique<Macros>())\n+        : access_control(std::make_unique<AccessControl>())\n+        , global_overcommit_tracker(&process_list)\n+        , macros(std::make_unique<Macros>())\n     {\n         /// TODO: make it singleton (?)\n         static std::atomic<size_t> num_calls{0};\n@@ -474,6 +477,7 @@ std::unique_lock<std::recursive_mutex> Context::getLock() const\n \n ProcessList & Context::getProcessList() { return shared->process_list; }\n const ProcessList & Context::getProcessList() const { return shared->process_list; }\n+OvercommitTracker * Context::getGlobalOvercommitTracker() const { return &shared->global_overcommit_tracker; }\n MergeList & Context::getMergeList() { return shared->merge_list; }\n const MergeList & Context::getMergeList() const { return shared->merge_list; }\n ReplicatedFetchList & Context::getReplicatedFetchList() { return shared->replicated_fetch_list; }\ndiff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h\nindex 6b0a4671efb1..2a2783603a27 100644\n--- a/src/Interpreters/Context.h\n+++ b/src/Interpreters/Context.h\n@@ -29,6 +29,7 @@\n namespace Poco::Net { class IPAddress; }\n namespace zkutil { class ZooKeeper; }\n \n+struct OvercommitTracker;\n \n namespace DB\n {\n@@ -657,6 +658,8 @@ class Context: public std::enable_shared_from_this<Context>\n     ProcessList & getProcessList();\n     const ProcessList & getProcessList() const;\n \n+    OvercommitTracker * getGlobalOvercommitTracker() const;\n+\n     MergeList & getMergeList();\n     const MergeList & getMergeList() const;\n \ndiff --git a/src/Interpreters/ProcessList.cpp b/src/Interpreters/ProcessList.cpp\nindex 3c91f00ebf4c..d17d8e4972a5 100644\n--- a/src/Interpreters/ProcessList.cpp\n+++ b/src/Interpreters/ProcessList.cpp\n@@ -195,33 +195,21 @@ ProcessList::EntryPtr ProcessList::insert(const String & query_, const IAST * as\n                     ErrorCodes::QUERY_WITH_SAME_ID_IS_ALREADY_RUNNING);\n         }\n \n-        auto process_it = processes.emplace(processes.end(),\n-            query_context, query_, client_info, priorities.insert(settings.priority), query_kind);\n-\n-        increaseQueryKindAmount(query_kind);\n-\n-        res = std::make_shared<Entry>(*this, process_it);\n-\n         ProcessListForUser & user_process_list = user_to_queries[client_info.current_user];\n-        user_process_list.queries.emplace(client_info.current_query_id, &res->get());\n-\n-        process_it->setUserProcessList(&user_process_list);\n-\n-        /// Track memory usage for all simultaneously running queries from single user.\n-        user_process_list.user_memory_tracker.setOrRaiseHardLimit(settings.max_memory_usage_for_user);\n-        user_process_list.user_memory_tracker.setDescription(\"(for user)\");\n \n         /// Actualize thread group info\n-        if (auto thread_group = CurrentThread::getGroup())\n+        auto thread_group = CurrentThread::getGroup();\n+        if (thread_group)\n         {\n             std::lock_guard lock_thread_group(thread_group->mutex);\n             thread_group->performance_counters.setParent(&user_process_list.user_performance_counters);\n             thread_group->memory_tracker.setParent(&user_process_list.user_memory_tracker);\n-            thread_group->query = process_it->query;\n-            thread_group->normalized_query_hash = normalizedQueryHash<false>(process_it->query);\n+            thread_group->query = query_;\n+            thread_group->normalized_query_hash = normalizedQueryHash<false>(query_);\n \n             /// Set query-level memory trackers\n             thread_group->memory_tracker.setOrRaiseHardLimit(settings.max_memory_usage);\n+            thread_group->memory_tracker.setSoftLimit(settings.max_guaranteed_memory_usage);\n \n             if (query_context->hasTraceCollector())\n             {\n@@ -236,10 +224,28 @@ ProcessList::EntryPtr ProcessList::insert(const String & query_, const IAST * as\n \n             /// NOTE: Do not set the limit for thread-level memory tracker since it could show unreal values\n             ///  since allocation and deallocation could happen in different threads\n+        }\n+\n+        auto process_it = processes.emplace(processes.end(),\n+            query_context, query_, client_info, priorities.insert(settings.priority), std::move(thread_group), query_kind);\n+\n+        increaseQueryKindAmount(query_kind);\n+\n+        res = std::make_shared<Entry>(*this, process_it);\n \n-            process_it->thread_group = std::move(thread_group);\n+        process_it->setUserProcessList(&user_process_list);\n+\n+        {\n+            BlockQueryIfMemoryLimit block_query{user_process_list.user_overcommit_tracker};\n+            user_process_list.queries.emplace(client_info.current_query_id, &res->get());\n         }\n \n+        /// Track memory usage for all simultaneously running queries from single user.\n+        user_process_list.user_memory_tracker.setOrRaiseHardLimit(settings.max_memory_usage_for_user);\n+        user_process_list.user_memory_tracker.setSoftLimit(settings.max_guaranteed_memory_usage_for_user);\n+        user_process_list.user_memory_tracker.setDescription(\"(for user)\");\n+        user_process_list.user_overcommit_tracker.setMaxWaitTime(settings.memory_usage_overcommit_max_wait_microseconds);\n+\n         if (!user_process_list.user_throttler)\n         {\n             if (settings.max_network_bandwidth_for_user)\n@@ -268,9 +274,6 @@ ProcessListEntry::~ProcessListEntry()\n \n     const QueryStatus * process_list_element_ptr = &*it;\n \n-    /// This removes the memory_tracker of one request.\n-    parent.processes.erase(it);\n-\n     auto user_process_list_it = parent.user_to_queries.find(user);\n     if (user_process_list_it == parent.user_to_queries.end())\n     {\n@@ -286,11 +289,15 @@ ProcessListEntry::~ProcessListEntry()\n     {\n         if (running_query->second == process_list_element_ptr)\n         {\n+            BlockQueryIfMemoryLimit block_query{user_process_list.user_overcommit_tracker};\n             user_process_list.queries.erase(running_query->first);\n             found = true;\n         }\n     }\n \n+    /// This removes the memory_tracker of one request.\n+    parent.processes.erase(it);\n+\n     if (!found)\n     {\n         LOG_ERROR(&Poco::Logger::get(\"ProcessList\"), \"Logical error: cannot find query by query_id and pointer to ProcessListElement in ProcessListForUser\");\n@@ -312,10 +319,16 @@ ProcessListEntry::~ProcessListEntry()\n \n \n QueryStatus::QueryStatus(\n-    ContextPtr context_, const String & query_, const ClientInfo & client_info_, QueryPriorities::Handle && priority_handle_, IAST::QueryKind query_kind_)\n+    ContextPtr context_,\n+    const String & query_,\n+    const ClientInfo & client_info_,\n+    QueryPriorities::Handle && priority_handle_,\n+    ThreadGroupStatusPtr && thread_group_,\n+    IAST::QueryKind query_kind_)\n     : WithContext(context_)\n     , query(query_)\n     , client_info(client_info_)\n+    , thread_group(std::move(thread_group_))\n     , priority_handle(std::move(priority_handle_))\n     , query_kind(query_kind_)\n     , num_queries_increment(CurrentMetrics::Query)\n@@ -328,6 +341,14 @@ QueryStatus::QueryStatus(\n QueryStatus::~QueryStatus()\n {\n     assert(executors.empty());\n+\n+    if (auto * memory_tracker = getMemoryTracker())\n+    {\n+        if (user_process_list)\n+            user_process_list->user_overcommit_tracker.unsubscribe(memory_tracker);\n+        if (auto shared_context = getContext())\n+            shared_context->getGlobalOvercommitTracker()->unsubscribe(memory_tracker);\n+    }\n }\n \n CancellationCode QueryStatus::cancelQuery(bool)\n@@ -481,7 +502,11 @@ ProcessList::Info ProcessList::getInfo(bool get_thread_list, bool get_profile_ev\n }\n \n \n-ProcessListForUser::ProcessListForUser() = default;\n+ProcessListForUser::ProcessListForUser()\n+    : user_overcommit_tracker(this)\n+{\n+    user_memory_tracker.setOvercommitTracker(&user_overcommit_tracker);\n+}\n \n \n ProcessListForUserInfo ProcessListForUser::getInfo(bool get_profile_events) const\ndiff --git a/src/Interpreters/ProcessList.h b/src/Interpreters/ProcessList.h\nindex 2ba0b0814ee9..5fb4bca7e13f 100644\n--- a/src/Interpreters/ProcessList.h\n+++ b/src/Interpreters/ProcessList.h\n@@ -16,6 +16,7 @@\n #include <Common/ProfileEvents.h>\n #include <Common/Stopwatch.h>\n #include <Common/Throttler.h>\n+#include <Common/OvercommitTracker.h>\n \n #include <condition_variable>\n #include <list>\n@@ -76,6 +77,7 @@ class QueryStatus : public WithContext\n     friend class ThreadStatus;\n     friend class CurrentThread;\n     friend class ProcessListEntry;\n+    friend struct ::GlobalOvercommitTracker;\n \n     String query;\n     ClientInfo client_info;\n@@ -132,6 +134,7 @@ class QueryStatus : public WithContext\n         const String & query_,\n         const ClientInfo & client_info_,\n         QueryPriorities::Handle && priority_handle_,\n+        ThreadGroupStatusPtr && thread_group_,\n         IAST::QueryKind query_kind_\n         );\n \n@@ -154,6 +157,13 @@ class QueryStatus : public WithContext\n \n     ThrottlerPtr getUserNetworkThrottler();\n \n+    MemoryTracker * getMemoryTracker() const\n+    {\n+        if (!thread_group)\n+            return nullptr;\n+        return &thread_group->memory_tracker;\n+    }\n+\n     bool updateProgressIn(const Progress & value)\n     {\n         CurrentThread::updateProgressIn(value);\n@@ -216,6 +226,8 @@ struct ProcessListForUser\n     /// Limit and counter for memory of all simultaneously running queries of single user.\n     MemoryTracker user_memory_tracker{VariableContext::User};\n \n+    UserOvercommitTracker user_overcommit_tracker;\n+\n     /// Count network usage for all simultaneously running queries of single user.\n     ThrottlerPtr user_throttler;\n \n@@ -337,6 +349,14 @@ class ProcessList\n         max_size = max_size_;\n     }\n \n+    template <typename F>\n+    void processEachQueryStatus(F && func) const\n+    {\n+        std::lock_guard lk(mutex);\n+        for (auto && query : processes)\n+            func(query);\n+    }\n+\n     void setMaxInsertQueriesAmount(size_t max_insert_queries_amount_)\n     {\n         std::lock_guard lock(mutex);\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02104_overcommit_memory.reference b/tests/queries/0_stateless/02104_overcommit_memory.reference\nnew file mode 100644\nindex 000000000000..b108f48e0fac\n--- /dev/null\n+++ b/tests/queries/0_stateless/02104_overcommit_memory.reference\n@@ -0,0 +1,1 @@\n+OVERCOMMITED WITH USER LIMIT WAS KILLED\ndiff --git a/tests/queries/0_stateless/02104_overcommit_memory.sh b/tests/queries/0_stateless/02104_overcommit_memory.sh\nnew file mode 100755\nindex 000000000000..140557304c61\n--- /dev/null\n+++ b/tests/queries/0_stateless/02104_overcommit_memory.sh\n@@ -0,0 +1,48 @@\n+#!/usr/bin/env bash\n+# Tags: no-parallel\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT -q 'CREATE USER IF NOT EXISTS u1 IDENTIFIED WITH no_password'\n+$CLICKHOUSE_CLIENT -q 'GRANT ALL ON *.* TO u1'\n+\n+function overcommited()\n+{\n+    while true; do\n+        $CLICKHOUSE_CLIENT -u u1 -q 'SELECT number FROM numbers(130000) GROUP BY number SETTINGS max_guaranteed_memory_usage=1,memory_usage_overcommit_max_wait_microseconds=500' 2>&1 | grep -F -q \"MEMORY_LIMIT_EXCEEDED\" && echo \"OVERCOMMITED WITH USER LIMIT IS KILLED\"\n+    done\n+}\n+\n+function expect_execution()\n+{\n+    while true; do\n+        $CLICKHOUSE_CLIENT -u u1 -q 'SELECT number FROM numbers(130000) GROUP BY number SETTINGS max_memory_usage_for_user=5000000,max_guaranteed_memory_usage=2,memory_usage_overcommit_max_wait_microseconds=500' >/dev/null 2>/dev/null\n+    done\n+}\n+\n+export -f overcommited\n+export -f expect_execution\n+\n+function user_test()\n+{\n+    for _ in {1..10};\n+    do\n+        timeout 10 bash -c overcommited &\n+        timeout 10 bash -c expect_execution &\n+    done;\n+\n+    wait\n+}\n+\n+output=$(user_test)\n+\n+if test -z \"$output\"\n+then\n+    echo \"OVERCOMMITED WITH USER LIMIT WAS NOT KILLED\"\n+else\n+    echo \"OVERCOMMITED WITH USER LIMIT WAS KILLED\"\n+fi\n+\n+$CLICKHOUSE_CLIENT -q 'DROP USER IF EXISTS u1'\n",
  "problem_statement": "Memory overcommit for queries.\n**Use case**\r\n\r\nAllow query to use more memory than it's guaranteed if free memory is available while providing guarantees on possible memory usage for other queries.\r\n\r\nE.g. a server has 512 GiB of memory and limiting every query to default 10 GiB just in case is unreasonable.\r\nBut simply raising the max_memory_usage to 500 GiB is also unreasonable.\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd setting `max_guaranteed_memory_usage` to accompany with the existing `max_memory_usage`\r\nand `max_guaranteed_memory_usage_for_user` to accompany with the existing `max_memory_usage_for_user`.\r\n\r\n`max_guaranteed_memory_usage` will denote soft memory limit while `max_memory_usage` will remain for hard memory limit.\r\n\r\nIf `max_memory_usage` is reached, exception will be thrown (the same as current behaviour).\r\n\r\nIf `max_memory_usage_for_user` or `max_server_memory_usage` is reached, we will take the ratio of the query memory usage to the `max_guaranteed_memory_usage` or `max_guaranteed_memory_usage_for_user` (overcommit ratio), of our query and all other running queries in a group (of all queries from the same user or all running queries), sort by this value, and if current query is at the top, we immediately throw exception and signal condvar on query finish. Other queries will wait on condvar but no more than specified amount of time, and continue if memory is freed. In case of timeout, an exception is thrown as usual.\r\n\r\nAdd setting `memory_usage_overcommit_max_wait_microseconds` to limit waiting time.\r\n\r\nThe overcommit_ratio should be exposed in system.processes table.\r\n\r\n\r\n**Notes**\r\n\r\nThe idea is to add waiting on condvar inside MemoryTracker.\r\nI'm not 100% sure if it will work ok, especially in dynamics. But at least it looks fairly easy.\r\n\r\nNo deadlocks should be possible as the most hungry query will throw exception, free resources and signal condvar. Then if memory limit is reached again, the next most hungry query will throw exception and so on.\r\n\r\nTo avoid unnecessary waiting we can force the most hungry query (by overcommit ratio) to throw exception slightly earlier than reaching user/total memory limit (e.g. if it is 90% or one GB to reach the limit).\r\n\r\nWaiting inside (almost) arbitrary place in code can prevent proper utilization of CPU in presense of single query execution pipeline. But it should not be a concern as this wait is guaranteed to be short.\r\n\r\nOne of the goals of this task is to enable fallback to external sorting and external aggregation by default. But it is slightly more difficult because it has to be activated before reaching memory limit (the fallback itself requires some extra memory). To solve it, we can provide settings similar to `max_bytes_before_external_group_by` but in form of ratio or delta related to the memory limit. So, it will be activated before memory limit is reached.\r\n\r\n\r\n**Alternative solutions**\r\n\r\nAnother way is to simply specify limits in form of ratio to free memory. Like every query can use 50% of the remaining memory.\r\nThen single query can occupy half of all RAM and concurrent queries will line up in beutiful geometric sequence. But it does not solve the task.\r\n\r\n\r\n**Additional context**\r\n\r\nSee also #8449.\r\n\n",
  "hints_text": "",
  "created_at": "2021-11-09T13:08:38Z",
  "modified_files": [
    "programs/server/Server.cpp",
    "src/Common/MemoryTracker.cpp",
    "src/Common/MemoryTracker.h",
    "b/src/Common/OvercommitTracker.cpp",
    "b/src/Common/OvercommitTracker.h",
    "src/Core/Settings.h",
    "src/Interpreters/Context.cpp",
    "src/Interpreters/Context.h",
    "src/Interpreters/ProcessList.cpp",
    "src/Interpreters/ProcessList.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02104_overcommit_memory.reference",
    "b/tests/queries/0_stateless/02104_overcommit_memory.sh"
  ]
}