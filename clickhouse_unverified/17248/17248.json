{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 17248,
  "instance_id": "ClickHouse__ClickHouse-17248",
  "issue_numbers": [
    "15235"
  ],
  "base_commit": "8de415861f541f9295907734c32b972f158fbf08",
  "patch": "diff --git a/programs/copier/ClusterCopier.cpp b/programs/copier/ClusterCopier.cpp\nindex a129dc7efcc5..3b8d97f63e28 100644\n--- a/programs/copier/ClusterCopier.cpp\n+++ b/programs/copier/ClusterCopier.cpp\n@@ -605,7 +605,7 @@ TaskStatus ClusterCopier::tryMoveAllPiecesToDestinationTable(const TaskTable & t\n         settings_push.replication_alter_partitions_sync = 2;\n \n         query_alter_ast_string += \" ALTER TABLE \" + getQuotedTable(original_table) +\n-                                  \" ATTACH PARTITION \" + partition_name +\n+                                  ((partition_name == \"'all'\") ? \" ATTACH PARTITION ID \" : \" ATTACH PARTITION \") + partition_name +\n                                   \" FROM \" + getQuotedTable(helping_table);\n \n         LOG_DEBUG(log, \"Executing ALTER query: {}\", query_alter_ast_string);\n@@ -636,7 +636,7 @@ TaskStatus ClusterCopier::tryMoveAllPiecesToDestinationTable(const TaskTable & t\n             if (!task_table.isReplicatedTable())\n             {\n                 query_deduplicate_ast_string += \" OPTIMIZE TABLE \" + getQuotedTable(original_table) +\n-                                                \" PARTITION \" + partition_name + \" DEDUPLICATE;\";\n+                                                ((partition_name == \"'all'\") ? \" PARTITION ID \" : \" PARTITION \") + partition_name + \" DEDUPLICATE;\";\n \n                 LOG_DEBUG(log, \"Executing OPTIMIZE DEDUPLICATE query: {}\", query_alter_ast_string);\n \n@@ -807,7 +807,7 @@ bool ClusterCopier::tryDropPartitionPiece(\n         DatabaseAndTableName helping_table = DatabaseAndTableName(original_table.first, original_table.second + \"_piece_\" + toString(current_piece_number));\n \n         String query = \"ALTER TABLE \" + getQuotedTable(helping_table);\n-        query += \" DROP PARTITION \" + task_partition.name + \"\";\n+        query += ((task_partition.name == \"'all'\") ? \" DROP PARTITION ID \" : \" DROP PARTITION \")  + task_partition.name + \"\";\n \n         /// TODO: use this statement after servers will be updated up to 1.1.54310\n         // query += \" DROP PARTITION ID '\" + task_partition.name + \"'\";\n@@ -1567,7 +1567,7 @@ void ClusterCopier::dropParticularPartitionPieceFromAllHelpingTables(const TaskT\n         DatabaseAndTableName original_table = task_table.table_push;\n         DatabaseAndTableName helping_table = DatabaseAndTableName(original_table.first, original_table.second + \"_piece_\" + toString(current_piece_number));\n \n-        String query = \"ALTER TABLE \" + getQuotedTable(helping_table) + \" DROP PARTITION \" + partition_name;\n+        String query = \"ALTER TABLE \" + getQuotedTable(helping_table) + ((partition_name == \"'all'\") ? \" DROP PARTITION ID \" : \" DROP PARTITION \") + partition_name;\n \n         const ClusterPtr & cluster_push = task_table.cluster_push;\n         Settings settings_push = task_cluster->settings_push;\n@@ -1670,14 +1670,24 @@ void ClusterCopier::createShardInternalTables(const ConnectionTimeouts & timeout\n \n std::set<String> ClusterCopier::getShardPartitions(const ConnectionTimeouts & timeouts, TaskShard & task_shard)\n {\n+    std::set<String> res;\n+\n     createShardInternalTables(timeouts, task_shard, false);\n \n     TaskTable & task_table = task_shard.task_table;\n \n+    const String & partition_name = queryToString(task_table.engine_push_partition_key_ast);\n+\n+    if (partition_name == \"'all'\")\n+    {\n+        res.emplace(\"'all'\");\n+        return res;\n+    }\n+\n     String query;\n     {\n         WriteBufferFromOwnString wb;\n-        wb << \"SELECT DISTINCT \" << queryToString(task_table.engine_push_partition_key_ast) << \" AS partition FROM\"\n+        wb << \"SELECT DISTINCT \" << partition_name << \" AS partition FROM\"\n            << \" \" << getQuotedTable(task_shard.table_read_shard) << \" ORDER BY partition DESC\";\n         query = wb.str();\n     }\n@@ -1692,7 +1702,6 @@ std::set<String> ClusterCopier::getShardPartitions(const ConnectionTimeouts & ti\n     local_context.setSettings(task_cluster->settings_pull);\n     Block block = getBlockWithAllStreamData(InterpreterFactory::get(query_ast, local_context)->execute().getInputStream());\n \n-    std::set<String> res;\n     if (block)\n     {\n         ColumnWithTypeAndName & column = block.getByPosition(0);\n",
  "test_patch": "diff --git a/tests/integration/test_cluster_copier/task_non_partitioned_table.xml b/tests/integration/test_cluster_copier/task_non_partitioned_table.xml\nnew file mode 100644\nindex 000000000000..499c54ae46e9\n--- /dev/null\n+++ b/tests/integration/test_cluster_copier/task_non_partitioned_table.xml\n@@ -0,0 +1,39 @@\n+<yandex>\n+    <remote_servers>   \n+       <source_cluster>\n+          <shard>\n+              <weight>1</weight>\n+              <replica>\n+                  <host>s0_0_0</host>\n+                  <port>9000</port>\n+              </replica>\n+          </shard>\n+      </source_cluster>     \n+      <default_cluster>\n+      \n+        <shard>\n+          <weight>1</weight>\n+          <replica>\n+              <host>s1_1_0</host>\n+              <port>9000</port>\n+          </replica>\n+        </shard>\n+            \n+      </default_cluster>     \n+    </remote_servers>\n+    <max_workers>1</max_workers>\n+\n+    <tables>\n+      <table_copier_test1>\n+        <cluster_pull>source_cluster</cluster_pull>\n+        <database_pull>default</database_pull>\n+        <table_pull>copier_test1</table_pull>\n+\n+        <cluster_push>default_cluster</cluster_push>\n+        <database_push>default</database_push>\n+        <table_push>copier_test1_1</table_push>\n+        <engine>ENGINE = MergeTree ORDER BY date SETTINGS index_granularity = 8192</engine>\n+        <sharding_key>rand()</sharding_key>\n+      </table_copier_test1>\n+    </tables>\n+</yandex>\ndiff --git a/tests/integration/test_cluster_copier/test.py b/tests/integration/test_cluster_copier/test.py\nindex 6a922dbfca72..d87969630cd0 100644\n--- a/tests/integration/test_cluster_copier/test.py\n+++ b/tests/integration/test_cluster_copier/test.py\n@@ -230,6 +230,27 @@ def check(self):\n         instance = cluster.instances['s1_1_0']\n         instance.query(\"DROP TABLE copier_test1_1\")\n \n+class Task_non_partitioned_table:\n+\n+    def __init__(self, cluster):\n+        self.cluster = cluster\n+        self.zk_task_path = \"/clickhouse-copier/task_non_partitoned_table\"\n+        self.copier_task_config = open(os.path.join(CURRENT_TEST_DIR, 'task_non_partitioned_table.xml'), 'r').read()\n+        self.rows = 1000000\n+\n+    def start(self):\n+        instance = cluster.instances['s0_0_0']\n+        instance.query(\n+            \"create table copier_test1 (date Date, id UInt32) engine = MergeTree ORDER BY date SETTINGS index_granularity = 8192\")\n+        instance.query(\"insert into copier_test1 values ('2016-01-01', 10);\")\n+\n+    def check(self):\n+        assert TSV(self.cluster.instances['s1_1_0'].query(\"SELECT date FROM copier_test1_1\")) == TSV(\"2016-01-01\\n\")\n+        instance = cluster.instances['s0_0_0']\n+        instance.query(\"DROP TABLE copier_test1\")\n+        instance = cluster.instances['s1_1_0']\n+        instance.query(\"DROP TABLE copier_test1_1\")\n+\n \n def execute_task(task, cmd_options):\n     task.start()\n@@ -359,6 +380,8 @@ def test_no_index(started_cluster):\n def test_no_arg(started_cluster):\n     execute_task(Task_no_arg(started_cluster), [])\n \n+def test_non_partitioned_table(started_cluster):\n+    execute_task(Task_non_partitioned_table(started_cluster), [])\n \n if __name__ == '__main__':\n     with contextmanager(started_cluster)() as cluster:\n",
  "problem_statement": "20.6.6.7 clickhouse-copier segfault\n```\r\n2020.09.24 13:54:06.581506 [ 17189 ] {} <Debug> StorageDistributed (.read_shard_0.destination_cluster.dwh._dim_customer_local): Auto-increment is 0\r\n2020.09.24 13:54:06.581537 [ 17192 ] {} <Debug> StorageDistributed (.read_shard_3.destination_cluster.dwh._dim_customer_local): Auto-increment is 0\r\n2020.09.24 13:54:06.581681 [ 17189 ] {} <Debug> ClusterCopier: Computing destination partition set, executing query: SELECT DISTINCT 'all' AS partition FROM _local.`.read_shard_0.destination_cluster.dwh._dim_customer_local` ORDER BY partition DESC\r\n2020.09.24 13:54:06.581804 [ 17192 ] {} <Debug> ClusterCopier: Computing destination partition set, executing query: SELECT DISTINCT 'all' AS partition FROM _local.`.read_shard_3.destination_cluster.dwh._dim_customer_local` ORDER BY partition DESC\r\n2020.09.24 13:54:06.581929 [ 17191 ] {} <Debug> StorageDistributed (.read_shard_4.destination_cluster.dwh._dim_customer_local): Auto-increment is 0\r\n2020.09.24 13:54:06.582132 [ 17191 ] {} <Debug> ClusterCopier: Computing destination partition set, executing query: SELECT DISTINCT 'all' AS partition FROM _local.`.read_shard_4.destination_cluster.dwh._dim_customer_local` ORDER BY partition DESC\r\n2020.09.24 13:54:06.582538 [ 17189 ] {} <Trace> InterpreterSelectQuery: Complete -> Complete\r\n2020.09.24 13:54:06.582997 [ 17191 ] {} <Trace> InterpreterSelectQuery: Complete -> Complete\r\n2020.09.24 13:54:06.583306 [ 17190 ] {} <Debug> StorageDistributed (.read_shard_1.destination_cluster.dwh._dim_customer_local): Auto-increment is 0\r\n2020.09.24 13:54:06.583470 [ 17190 ] {} <Debug> ClusterCopier: Computing destination partition set, executing query: SELECT DISTINCT 'all' AS partition FROM _local.`.read_shard_1.destination_cluster.dwh._dim_customer_local` ORDER BY partition DESC\r\n2020.09.24 13:54:06.583989 [ 17192 ] {} <Trace> InterpreterSelectQuery: Complete -> Complete\r\n2020.09.24 13:54:06.584162 [ 17190 ] {} <Trace> InterpreterSelectQuery: Complete -> Complete\r\n2020.09.24 13:54:06.585082 [ 17188 ] {} <Debug> StorageDistributed (.read_shard_2.destination_cluster.dwh._dim_customer_local): Auto-increment is 0\r\n2020.09.24 13:54:06.585215 [ 17188 ] {} <Debug> ClusterCopier: Computing destination partition set, executing query: SELECT DISTINCT 'all' AS partition FROM _local.`.read_shard_2.destination_cluster.dwh._dim_customer_local` ORDER BY partition DESC\r\n2020.09.24 13:54:06.585858 [ 17188 ] {} <Trace> InterpreterSelectQuery: Complete -> Complete\r\n2020.09.24 13:54:06.587341 [ 17171 ] {} <Trace> BaseDaemon: Received signal 11\r\n\r\n\r\n\r\n2020.09.24 13:54:06.587515 [ 17193 ] {} <Fatal> BaseDaemon: ########################################\r\n2020.09.24 13:54:06.587579 [ 17193 ] {} <Fatal> BaseDaemon: (version 20.6.6.7, no build id) (from thread 17191) (no query) Received signal Segmentation fault (11)\r\n2020.09.24 13:54:06.587693 [ 17193 ] {} <Fatal> BaseDaemon: Address: 0x7f5b55deff4f Access: read. Address not mapped to object.\r\n2020.09.24 13:54:06.587710 [ 17193 ] {} <Fatal> BaseDaemon: Stack trace: 0xd2380e1 0x5d048ff 0xa2a53ef 0x5dfc737 0x5dfd2c7 0x5d0d06d 0x5d0d753 0x5d0c60d 0x5d0acdf 0x7f5b07ba5e65 0x7f5b074c288d\r\n2020.09.24 13:54:06.587767 [ 17193 ] {} <Fatal> BaseDaemon: 3. memcpy @ 0xd2380e1 in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.587836 [ 17193 ] {} <Fatal> BaseDaemon: 4. void DB::writeAnyEscapedString<(char)39, false>(char const*, char const*, DB::WriteBuffer&) @ 0x5d048ff in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.587870 [ 17193 ] {} <Fatal> BaseDaemon: 5. DB::DataTypeString::serializeTextQuoted(DB::IColumn const&, unsigned long, DB::WriteBuffer&, DB::FormatSettings const&) const @ 0xa2a53ef in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.587890 [ 17193 ] {} <Fatal> BaseDaemon: 6. DB::ClusterCopier::getShardPartitions(DB::ConnectionTimeouts const&, DB::TaskShard&) @ 0x5dfc737 in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.587933 [ 17193 ] {} <Fatal> BaseDaemon: 7. DB::ClusterCopier::discoverShardPartitions(DB::ConnectionTimeouts const&, std::__1::shared_ptr<DB::TaskShard> const&) @ 0x5dfd2c7 in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.588043 [ 17193 ] {} <Fatal> BaseDaemon: 8. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x5d0d06d in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.588105 [ 17193 ] {} <Fatal> BaseDaemon: 9. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const @ 0x5d0d753 in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.588134 [ 17193 ] {} <Fatal> BaseDaemon: 10. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x5d0c60d in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.588149 [ 17193 ] {} <Fatal> BaseDaemon: 11. ? @ 0x5d0acdf in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.588176 [ 17193 ] {} <Fatal> BaseDaemon: 12. start_thread @ 0x7e65 in /usr/lib64/libpthread-2.17.so\r\n2020.09.24 13:54:06.588195 [ 17193 ] {} <Fatal> BaseDaemon: 13. __clone @ 0xfe88d in /usr/lib64/libc-2.17.so\r\n\r\n\r\n2020.09.24 13:54:06.587723 [ 17194 ] {} <Fatal> BaseDaemon: ########################################\r\n2020.09.24 13:54:06.587773 [ 17194 ] {} <Fatal> BaseDaemon: (version 20.6.6.7, no build id) (from thread 17192) (no query) Received signal Segmentation fault (11)\r\n2020.09.24 13:54:06.587786 [ 17194 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Unknown si_code.\r\n2020.09.24 13:54:06.587808 [ 17194 ] {} <Fatal> BaseDaemon: Stack trace: 0xd2380e1 0x5d048ff 0xa2a53ef 0x5dfc737 0x5dfd2c7 0x5d0d06d 0x5d0d753 0x5d0c60d 0x5d0acdf 0x7f5b07ba5e65 0x7f5b074c288d\r\n2020.09.24 13:54:06.587877 [ 17194 ] {} <Fatal> BaseDaemon: 3. memcpy @ 0xd2380e1 in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.587930 [ 17194 ] {} <Fatal> BaseDaemon: 4. void DB::writeAnyEscapedString<(char)39, false>(char const*, char const*, DB::WriteBuffer&) @ 0x5d048ff in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.587962 [ 17194 ] {} <Fatal> BaseDaemon: 5. DB::DataTypeString::serializeTextQuoted(DB::IColumn const&, unsigned long, DB::WriteBuffer&, DB::FormatSettings const&) const @ 0xa2a53ef in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.587984 [ 17194 ] {} <Fatal> BaseDaemon: 6. DB::ClusterCopier::getShardPartitions(DB::ConnectionTimeouts const&, DB::TaskShard&) @ 0x5dfc737 in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.587995 [ 17194 ] {} <Fatal> BaseDaemon: 7. DB::ClusterCopier::discoverShardPartitions(DB::ConnectionTimeouts const&, std::__1::shared_ptr<DB::TaskShard> const&) @ 0x5dfd2c7 in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.588008 [ 17194 ] {} <Fatal> BaseDaemon: 8. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x5d0d06d in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.588036 [ 17194 ] {} <Fatal> BaseDaemon: 9. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const @ 0x5d0d753 in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.588064 [ 17194 ] {} <Fatal> BaseDaemon: 10. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x5d0c60d in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.588080 [ 17194 ] {} <Fatal> BaseDaemon: 11. ? @ 0x5d0acdf in /usr/bin/clickhouse\r\n2020.09.24 13:54:06.588118 [ 17194 ] {} <Fatal> BaseDaemon: 12. start_thread @ 0x7e65 in /usr/lib64/libpthread-2.17.so\r\n2020.09.24 13:54:06.588142 [ 17194 ] {} <Fatal> BaseDaemon: 13. __clone @ 0xfe88d in /usr/lib64/libc-2.17.so\r\n```\r\n\r\nThe destination cluster consists of single shard / single replica. \n",
  "hints_text": "I've added some tests. Everything works fine with existing partition key. Will try to make copier work with absent partition key in destination table. (Or will add human readable error.)\nSeeing the same issue, used clickhouse-copier v20.11.2.1\r\n\r\n```\r\n2020.11.12 06:53:53.336132 [ 5343 ] {} <Debug> ClusterCopier: DROP TABLE query was successfully executed on 4 nodes.\r\n2020.11.12 06:53:53.336148 [ 5343 ] {} <Information> ClusterCopier: Process table task target_cluster.data.stats_hourly_1 with 1 shards, 1 of them are local ones\r\n2020.11.12 06:53:53.336169 [ 5343 ] {} <Debug> ClusterCopier: Waiting for 1 setup jobs\r\n2020.11.12 06:53:53.336197 [ 5350 ] {} <Information> ClusterCopier: Discover partitions of shard N1 (having a replica 172.10.32.22:9000, pull table data.stats_hourly of cluster source_cluster)\r\n2020.11.12 06:53:53.346460 [ 5350 ] {} <Debug> StorageDistributed (.inner..read_shard_0.target_cluster.data.stats_hourly_1): Auto-increment is 0\r\n2020.11.12 06:53:53.346783 [ 5350 ] {} <Debug> ClusterCopier: Computing destination partition set, executing query: SELECT DISTINCT 'all' AS partition FROM _local.`.read_shard_0.target_cluster.data.stats_hourly_1` ORDER BY partition DESC\r\n2020.11.12 06:53:53.347252 [ 5350 ] {} <Trace> InterpreterSelectQuery: Complete -> Complete\r\n2020.11.12 06:53:53.353019 [ 5346 ] {} <Trace> BaseDaemon: Received signal 11\r\n2020.11.12 06:53:53.353371 [ 5363 ] {} <Fatal> BaseDaemon: ########################################\r\n2020.11.12 06:53:53.353500 [ 5363 ] {} <Fatal> BaseDaemon: (version 20.8.4.11 (official build), no build id) (from thread 5350) (no query) Received signal Segmentation fault (11)\r\n2020.11.12 06:53:53.353524 [ 5363 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Unknown si_code.\r\n2020.11.12 06:53:53.353546 [ 5363 ] {} <Fatal> BaseDaemon: Stack trace: 0x18a48af2 0xe60b5ff 0x1553f7b3 0xe769fb8 0xe76aaa4 0xe6350a7 0xe63581a 0xe6345b7 0xe632b03 0x7f9963284ea5 0x7f9962ba18dd\r\n2020.11.12 06:53:53.354744 [ 5363 ] {} <Fatal> BaseDaemon: 3. memcpy @ 0x18a48af2 in /usr/bin/clickhouse\r\n2020.11.12 06:53:53.355462 [ 5363 ] {} <Fatal> BaseDaemon: 4. void DB::writeAnyEscapedString<(char)39, false>(char const*, char const*, DB::WriteBuffer&) @ 0xe60b5ff in /usr/bin/clickhouse\r\n2020.11.12 06:53:53.355558 [ 5363 ] {} <Fatal> BaseDaemon: 5. DB::DataTypeString::serializeTextQuoted(DB::IColumn const&, unsigned long, DB::WriteBuffer&, DB::FormatSettings const&) const @ 0x1553f7b3 in /usr/bin/clickhouse\r\n2020.11.12 06:53:53.355588 [ 5363 ] {} <Fatal> BaseDaemon: 6. DB::ClusterCopier::getShardPartitions(DB::ConnectionTimeouts const&, DB::TaskShard&) @ 0xe769fb8 in /usr/bin/clickhouse\r\n2020.11.12 06:53:53.355612 [ 5363 ] {} <Fatal> BaseDaemon: 7. DB::ClusterCopier::discoverShardPartitions(DB::ConnectionTimeouts const&, std::__1::shared_ptr<DB::TaskShard> const&) @ 0xe76aaa4 in /usr/bin/clickhouse\r\n2020.11.12 06:53:53.355644 [ 5363 ] {} <Fatal> BaseDaemon: 8. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0xe6350a7 in /usr/bin/clickhouse\r\n2020.11.12 06:53:53.355705 [ 5363 ] {} <Fatal> BaseDaemon: 9. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const @ 0xe63581a in /usr/bin/clickhouse\r\n2020.11.12 06:53:53.355816 [ 5363 ] {} <Fatal> BaseDaemon: 10. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xe6345b7 in /usr/bin/clickhouse\r\n2020.11.12 06:53:53.355833 [ 5363 ] {} <Fatal> BaseDaemon: 11. ? @ 0xe632b03 in /usr/bin/clickhouse\r\n2020.11.12 06:53:53.355868 [ 5363 ] {} <Fatal> BaseDaemon: 12. start_thread @ 0x7ea5 in /usr/lib64/libpthread-2.17.so\r\n2020.11.12 06:53:53.355891 [ 5363 ] {} <Fatal> BaseDaemon: 13. clone @ 0xfe8dd in /usr/lib64/libc-2.17.so\r\n2020.11.12 06:53:53.355917 [ 5363 ] {} <Information> SentryWriter: Not sending crash report\r\n```\nI have the same issue too.",
  "created_at": "2020-11-21T04:43:43Z",
  "modified_files": [
    "programs/copier/ClusterCopier.cpp"
  ],
  "modified_test_files": [
    "b/tests/integration/test_cluster_copier/task_non_partitioned_table.xml",
    "tests/integration/test_cluster_copier/test.py"
  ]
}