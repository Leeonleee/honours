{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 11346,
  "instance_id": "ClickHouse__ClickHouse-11346",
  "issue_numbers": [
    "11309",
    "11322"
  ],
  "base_commit": "8e5d6725635be2d9866734d22f93cc872ec979d4",
  "patch": "diff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex c6af41cc1632..983508e77eb1 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -365,6 +365,8 @@ struct CurrentlyMergingPartsTagger\n                 entry.latest_fail_reason = exception_message;\n             }\n         }\n+\n+        storage.currently_processing_in_background_condition.notify_all();\n     }\n };\n \n@@ -566,7 +568,7 @@ bool StorageMergeTree::merge(\n     std::optional<CurrentlyMergingPartsTagger> merging_tagger;\n \n     {\n-        std::lock_guard lock(currently_processing_in_background_mutex);\n+        std::unique_lock lock(currently_processing_in_background_mutex);\n \n         auto can_merge = [this, &lock] (const DataPartPtr & left, const DataPartPtr & right, String *) -> bool\n         {\n@@ -590,8 +592,33 @@ bool StorageMergeTree::merge(\n         }\n         else\n         {\n-            UInt64 disk_space = getStoragePolicy()->getMaxUnreservedFreeSpace();\n-            selected = merger_mutator.selectAllPartsToMergeWithinPartition(future_part, disk_space, can_merge, partition_id, final, out_disable_reason);\n+            while (true)\n+            {\n+                UInt64 disk_space = getStoragePolicy()->getMaxUnreservedFreeSpace();\n+                selected = merger_mutator.selectAllPartsToMergeWithinPartition(\n+                    future_part, disk_space, can_merge, partition_id, final, out_disable_reason);\n+\n+                /// If final - we will wait for currently processing merges to finish and continue.\n+                /// TODO Respect query settings for timeout\n+                if (final\n+                    && !selected\n+                    && !currently_merging_mutating_parts.empty()\n+                    && out_disable_reason\n+                    && out_disable_reason->empty())\n+                {\n+                    LOG_DEBUG(log, \"Waiting for currently running merges ({} parts are merging right now) to perform OPTIMIZE FINAL\",\n+                        currently_merging_mutating_parts.size());\n+\n+                    if (std::cv_status::timeout == currently_processing_in_background_condition.wait_for(\n+                        lock, std::chrono::seconds(DBMS_DEFAULT_LOCK_ACQUIRE_TIMEOUT_SEC)))\n+                    {\n+                        *out_disable_reason = \"Timeout while waiting for already running merges before running OPTIMIZE with FINAL\";\n+                        break;\n+                    }\n+                }\n+                else\n+                    break;\n+            }\n         }\n \n         if (!selected)\n@@ -847,7 +874,7 @@ BackgroundProcessingPoolTaskResult StorageMergeTree::mergeMutateTask()\n \n Int64 StorageMergeTree::getCurrentMutationVersion(\n     const DataPartPtr & part,\n-    std::lock_guard<std::mutex> & /* currently_processing_in_background_mutex_lock */) const\n+    std::unique_lock<std::mutex> & /* currently_processing_in_background_mutex_lock */) const\n {\n     auto it = current_mutations_by_version.upper_bound(part->info.getDataVersion());\n     if (it == current_mutations_by_version.begin())\ndiff --git a/src/Storages/StorageMergeTree.h b/src/Storages/StorageMergeTree.h\nindex 473177abf1e7..c6c8f99a62a3 100644\n--- a/src/Storages/StorageMergeTree.h\n+++ b/src/Storages/StorageMergeTree.h\n@@ -95,6 +95,7 @@ class StorageMergeTree final : public ext::shared_ptr_helper<StorageMergeTree>,\n     /// Mutex for parts currently processing in background\n     /// merging (also with TTL), mutating or moving.\n     mutable std::mutex currently_processing_in_background_mutex;\n+    mutable std::condition_variable currently_processing_in_background_condition;\n \n     /// Parts that currently participate in merge or mutation.\n     /// This set have to be used with `currently_processing_in_background_mutex`.\n@@ -133,7 +134,7 @@ class StorageMergeTree final : public ext::shared_ptr_helper<StorageMergeTree>,\n \n     Int64 getCurrentMutationVersion(\n         const DataPartPtr & part,\n-        std::lock_guard<std::mutex> & /* currently_processing_in_background_mutex_lock */) const;\n+        std::unique_lock<std::mutex> & /* currently_processing_in_background_mutex_lock */) const;\n \n     void clearOldMutations(bool truncate = false);\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01293_optimize_final_force.reference b/tests/queries/0_stateless/01293_optimize_final_force.reference\nnew file mode 100644\nindex 000000000000..b0b9422adf01\n--- /dev/null\n+++ b/tests/queries/0_stateless/01293_optimize_final_force.reference\n@@ -0,0 +1,100 @@\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\n+55\t0\ndiff --git a/tests/queries/0_stateless/01293_optimize_final_force.sh b/tests/queries/0_stateless/01293_optimize_final_force.sh\nnew file mode 100755\nindex 000000000000..50cba1e75344\n--- /dev/null\n+++ b/tests/queries/0_stateless/01293_optimize_final_force.sh\n@@ -0,0 +1,25 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+for i in {1..100}; do $CLICKHOUSE_CLIENT --multiquery --query \"\n+DROP TABLE IF EXISTS mt;\n+CREATE TABLE mt (x UInt8, k UInt8 DEFAULT 0) ENGINE = SummingMergeTree ORDER BY k;\n+\n+INSERT INTO mt (x) VALUES (1);\n+INSERT INTO mt (x) VALUES (2);\n+INSERT INTO mt (x) VALUES (3);\n+INSERT INTO mt (x) VALUES (4);\n+INSERT INTO mt (x) VALUES (5);\n+INSERT INTO mt (x) VALUES (6);\n+INSERT INTO mt (x) VALUES (7);\n+INSERT INTO mt (x) VALUES (8);\n+INSERT INTO mt (x) VALUES (9);\n+INSERT INTO mt (x) VALUES (10);\n+\n+OPTIMIZE TABLE mt FINAL;\n+SELECT * FROM mt;\n+\n+DROP TABLE mt;\n+\"; done\n",
  "problem_statement": "OPTIMIZE with FINAL should wait for already running merges.\nOtherwise it can just exit quickly and be effectively no-op.\r\nWe cannot reliably write tests with this behaviour.\nOPTIMIZE FINAL should force merge even if concurrent merges are performed (experimental)\nChangelog category (leave one):\r\n- Improvement\r\n\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\nOPTIMIZE FINAL will force merge even if concurrent merges are performed. This closes #11309\r\n\r\n\r\nDetailed description / Documentation draft:\r\nThis is needed mostly to make tests more reliable. It can also improve user experience.\n",
  "hints_text": "We can simply assign the merge regardless to the already running merges.\r\nThis is perfectly legal when we are merging whole partition (so no intersecting parts were created).\nYes, it works.\r\n\r\nBefore:\r\n```\r\nfor i in {1..1000}; do clickhouse-client -n < 01292_optimize_final_force_.sql; done\r\n10      0\r\n45      0\r\n45      0\r\n10      0\r\n10      0\r\n45      0\r\n45      0\r\n10      0\r\n55      0\r\n55      0\r\n55      0\r\n45      0\r\n10      0\r\n45      0\r\n10      0\r\n45      0\r\n10      0\r\n10      0\r\n```\r\n\r\nAfter:\r\n```\r\n55      0\r\n55      0\r\n55      0\r\n55      0\r\n55      0\r\n55      0\r\n55      0\r\n55      0\r\n55      0\r\n55      0\r\n55      0\r\n55      0\r\n...\r\n```\r\n\r\nBut the way of implementation is too tricky.",
  "created_at": "2020-06-02T00:43:00Z"
}