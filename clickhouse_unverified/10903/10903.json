{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 10903,
  "instance_id": "ClickHouse__ClickHouse-10903",
  "issue_numbers": [
    "10896"
  ],
  "base_commit": "623b2e5a43a9860cfc290e8daa19e973be5f1411",
  "patch": "diff --git a/src/Common/StringUtils/StringUtils.h b/src/Common/StringUtils/StringUtils.h\nindex b8aa023eb3aa..390015f3d2b1 100644\n--- a/src/Common/StringUtils/StringUtils.h\n+++ b/src/Common/StringUtils/StringUtils.h\n@@ -3,6 +3,7 @@\n #include <string>\n #include <cstring>\n #include <cstddef>\n+#include <cstdint>\n #include <type_traits>\n \n \n@@ -131,6 +132,69 @@ inline char alternateCaseIfAlphaASCII(char c)\n     return c ^ 0x20;\n }\n \n+inline const char * skipWhitespacesUTF8(const char * pos, const char * end)\n+{\n+    /// https://en.wikipedia.org/wiki/Whitespace_character\n+    /// with some adjustments.\n+\n+    /// Code points: 0085 00A0 180E 2000..200A 2028..2029 200B..200D 202F 205F 2060 3000 FEFF\n+    /// The corresponding UTF-8 is: C285 C2A0 E1A08E E28080..E2808A E280A8..E280A9 E2808B..E2808D E280AF E2819F E281A0 E38080 EFBBBF\n+\n+    /// We check for these bytes directly in UTF8 for simplicity reasons.\n+\n+    /** C2\n+      *    85\n+      *    A0\n+      * E1 A0 8E\n+      * E2\n+      *    80\n+      *       80..8A\n+      *       A8..A9\n+      *       8B..8D\n+      *       AF\n+      *    81\n+      *       9F\n+      *       A0\n+      * E3 80 80\n+      * EF BB BF\n+      */\n+\n+    while (pos < end)\n+    {\n+        if (isWhitespaceASCII(*pos))\n+        {\n+            ++pos;\n+        }\n+        else\n+        {\n+            const uint8_t * upos = reinterpret_cast<const uint8_t *>(pos);\n+\n+            if (pos + 1 < end && upos[0] == 0xC2 && (upos[1] == 0x85 || upos[1] == 0xA0))\n+            {\n+                pos += 2;\n+            }\n+            else if (pos + 2 < end\n+                &&    ((upos[0] == 0xE1 && upos[1] == 0xA0 && upos[2] == 0x8E)\n+                    || (upos[0] == 0xE2\n+                        &&    ((upos[1] == 0x80\n+                            &&    ((upos[2] >= 0x80 && upos[2] <= 0x8A)\n+                                || (upos[2] >= 0xA8 && upos[2] <= 0xA9)\n+                                || (upos[2] >= 0x8B && upos[2] <= 0x8D)\n+                                || (upos[2] == 0xAF)))\n+                            || (upos[1] == 0x81 && (upos[2] == 0x9F || upos[2] == 0xA0))))\n+                    || (upos[0] == 0xE3 && upos[1] == 0x80 && upos[2] == 0x80)\n+                    || (upos[0] == 0xEF && upos[1] == 0xBB && upos[2] == 0xBF)))\n+            {\n+                pos += 3;\n+            }\n+            else\n+                break;\n+        }\n+    }\n+\n+    return pos;\n+}\n+\n inline bool equalsCaseInsensitive(char a, char b)\n {\n     return a == b || (isAlphaASCII(a) && alternateCaseIfAlphaASCII(a) == b);\ndiff --git a/src/Parsers/Lexer.cpp b/src/Parsers/Lexer.cpp\nindex c5017870d821..7efc86634160 100644\n--- a/src/Parsers/Lexer.cpp\n+++ b/src/Parsers/Lexer.cpp\n@@ -316,7 +316,14 @@ Token Lexer::nextTokenImpl()\n                 return Token(TokenType::BareWord, token_begin, pos);\n             }\n             else\n-                return Token(TokenType::Error, token_begin, ++pos);\n+            {\n+                /// We will also skip unicode whitespaces in UTF-8 to support for queries copy-pasted from MS Word and similar.\n+                pos = skipWhitespacesUTF8(pos, end);\n+                if (pos > token_begin)\n+                    return Token(TokenType::Whitespace, token_begin, pos);\n+                else\n+                    return Token(TokenType::Error, token_begin, ++pos);\n+            }\n     }\n }\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01280_unicode_whitespaces_lexer.reference b/tests/queries/0_stateless/01280_unicode_whitespaces_lexer.reference\nnew file mode 100644\nindex 000000000000..01e79c32a8c9\n--- /dev/null\n+++ b/tests/queries/0_stateless/01280_unicode_whitespaces_lexer.reference\n@@ -0,0 +1,3 @@\n+1\n+2\n+3\ndiff --git a/tests/queries/0_stateless/01280_unicode_whitespaces_lexer.sql b/tests/queries/0_stateless/01280_unicode_whitespaces_lexer.sql\nnew file mode 100644\nindex 000000000000..e3292b509336\n--- /dev/null\n+++ b/tests/queries/0_stateless/01280_unicode_whitespaces_lexer.sql\n@@ -0,0 +1,3 @@\n+SELECT\ufeff1;\n+SELECT\u00a02;\n+\u0085\u00a0\u2000\u200a\u2028SELECT\u2029\u202f\u205f1\u3000\u180e\u200b+\u200c\u200d2\u2060\ufeff;\n",
  "problem_statement": "Support for more unicode whitespace characters in query lexer\nWhen people copy-pasting a query from MS Word or from HTML page where a query was reformatted by some blog engine, unexpected whitespace characters (like non-breaking space, soft hypen...) are polluting it.\n",
  "hints_text": "",
  "created_at": "2020-05-13T21:38:48Z",
  "modified_files": [
    "src/Common/StringUtils/StringUtils.h",
    "src/Parsers/Lexer.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/01280_unicode_whitespaces_lexer.reference",
    "b/tests/queries/0_stateless/01280_unicode_whitespaces_lexer.sql"
  ]
}