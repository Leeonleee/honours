{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 26241,
  "instance_id": "ClickHouse__ClickHouse-26241",
  "issue_numbers": [
    "9001"
  ],
  "base_commit": "10fc871de95eec8be158c43b277783f81ce3238d",
  "patch": "diff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp\nindex d820cbbae45b..bd9d7516f0f2 100644\n--- a/src/Interpreters/InterpreterSelectQuery.cpp\n+++ b/src/Interpreters/InterpreterSelectQuery.cpp\n@@ -399,7 +399,7 @@ InterpreterSelectQuery::InterpreterSelectQuery(\n             view = nullptr;\n         }\n \n-        if (try_move_to_prewhere && storage && query.where() && !query.prewhere())\n+        if (try_move_to_prewhere && storage && storage->supportsPrewhere() && query.where() && !query.prewhere())\n         {\n             /// PREWHERE optimization: transfer some condition from WHERE to PREWHERE if enabled and viable\n             if (const auto & column_sizes = storage->getColumnSizes(); !column_sizes.empty())\ndiff --git a/src/Storages/StorageLog.cpp b/src/Storages/StorageLog.cpp\nindex 61fbbbc3086e..b43cb6d71a0d 100644\n--- a/src/Storages/StorageLog.cpp\n+++ b/src/Storages/StorageLog.cpp\n@@ -28,6 +28,7 @@\n #include <Processors/Pipe.h>\n \n #include <cassert>\n+#include <chrono>\n \n \n #define DBMS_STORAGE_LOG_DATA_FILE_EXTENSION \".bin\"\n@@ -719,6 +720,34 @@ CheckResults StorageLog::checkData(const ASTPtr & /* query */, ContextPtr contex\n }\n \n \n+IStorage::ColumnSizeByName StorageLog::getColumnSizes() const\n+{\n+    std::shared_lock lock(rwlock, std::chrono::seconds(DBMS_DEFAULT_LOCK_ACQUIRE_TIMEOUT_SEC));\n+    if (!lock)\n+        throw Exception(\"Lock timeout exceeded\", ErrorCodes::TIMEOUT_EXCEEDED);\n+\n+    ColumnSizeByName column_sizes;\n+    FileChecker::Map file_sizes = file_checker.getFileSizes();\n+\n+    for (const auto & column : getInMemoryMetadata().getColumns().getAllPhysical())\n+    {\n+        ISerialization::StreamCallback stream_callback = [&, this] (const ISerialization::SubstreamPath & substream_path)\n+        {\n+            String stream_name = ISerialization::getFileNameForStream(column, substream_path);\n+            ColumnSize & size = column_sizes[column.name];\n+            auto it = files.find(stream_name);\n+            if (it != files.end())\n+                size.data_compressed += file_sizes[fileName(it->second.data_file_path)];\n+        };\n+\n+        ISerialization::SubstreamPath substream_path;\n+        auto serialization = column.type->getDefaultSerialization();\n+        serialization->enumerateStreams(stream_callback, substream_path);\n+    }\n+\n+    return column_sizes;\n+}\n+\n void registerStorageLog(StorageFactory & factory)\n {\n     StorageFactory::StorageFeatures features{\ndiff --git a/src/Storages/StorageLog.h b/src/Storages/StorageLog.h\nindex 6fea00edefdd..799bad26c7cf 100644\n--- a/src/Storages/StorageLog.h\n+++ b/src/Storages/StorageLog.h\n@@ -45,6 +45,7 @@ class StorageLog final : public shared_ptr_helper<StorageLog>, public IStorage\n     bool storesDataOnDisk() const override { return true; }\n     Strings getDataPaths() const override { return {DB::fullPath(disk, table_path)}; }\n     bool supportsSubcolumns() const override { return true; }\n+    ColumnSizeByName getColumnSizes() const override;\n \n protected:\n     /** Attach the table with the appropriate name, along the appropriate path (with / at the end),\n@@ -87,7 +88,7 @@ class StorageLog final : public shared_ptr_helper<StorageLog>, public IStorage\n     DiskPtr disk;\n     String table_path;\n \n-    std::shared_timed_mutex rwlock;\n+    mutable std::shared_timed_mutex rwlock;\n \n     Files files;\n \ndiff --git a/src/Storages/StorageTinyLog.cpp b/src/Storages/StorageTinyLog.cpp\nindex 689b1307f4d7..342101d91cc9 100644\n--- a/src/Storages/StorageTinyLog.cpp\n+++ b/src/Storages/StorageTinyLog.cpp\n@@ -4,6 +4,7 @@\n \n #include <map>\n #include <cassert>\n+#include <chrono>\n \n #include <Poco/Util/XMLConfiguration.h>\n \n@@ -523,6 +524,34 @@ CheckResults StorageTinyLog::checkData(const ASTPtr & /* query */, ContextPtr co\n     return file_checker.check();\n }\n \n+IStorage::ColumnSizeByName StorageTinyLog::getColumnSizes() const\n+{\n+    std::shared_lock lock(rwlock, std::chrono::seconds(DBMS_DEFAULT_LOCK_ACQUIRE_TIMEOUT_SEC));\n+    if (!lock)\n+        throw Exception(\"Lock timeout exceeded\", ErrorCodes::TIMEOUT_EXCEEDED);\n+\n+    ColumnSizeByName column_sizes;\n+    FileChecker::Map file_sizes = file_checker.getFileSizes();\n+\n+    for (const auto & column : getInMemoryMetadata().getColumns().getAllPhysical())\n+    {\n+        ISerialization::StreamCallback stream_callback = [&, this] (const ISerialization::SubstreamPath & substream_path)\n+        {\n+            String stream_name = ISerialization::getFileNameForStream(column, substream_path);\n+            ColumnSize & size = column_sizes[column.name];\n+            auto it = files.find(stream_name);\n+            if (it != files.end())\n+                size.data_compressed += file_sizes[fileName(it->second.data_file_path)];\n+        };\n+\n+        ISerialization::SubstreamPath substream_path;\n+        auto serialization = column.type->getDefaultSerialization();\n+        serialization->enumerateStreams(stream_callback, substream_path);\n+    }\n+\n+    return column_sizes;\n+}\n+\n void StorageTinyLog::truncate(\n     const ASTPtr &, const StorageMetadataPtr & metadata_snapshot, ContextPtr, TableExclusiveLockHolder &)\n {\ndiff --git a/src/Storages/StorageTinyLog.h b/src/Storages/StorageTinyLog.h\nindex 71763a6403e5..849b0731a475 100644\n--- a/src/Storages/StorageTinyLog.h\n+++ b/src/Storages/StorageTinyLog.h\n@@ -45,6 +45,7 @@ class StorageTinyLog final : public shared_ptr_helper<StorageTinyLog>, public IS\n \n     void truncate(const ASTPtr &, const StorageMetadataPtr & metadata_snapshot, ContextPtr, TableExclusiveLockHolder &) override;\n \n+    ColumnSizeByName getColumnSizes() const override;\n protected:\n     StorageTinyLog(\n         DiskPtr disk_,\n@@ -71,7 +72,7 @@ class StorageTinyLog final : public shared_ptr_helper<StorageTinyLog>, public IS\n     Files files;\n \n     FileChecker file_checker;\n-    std::shared_timed_mutex rwlock;\n+    mutable std::shared_timed_mutex rwlock;\n \n     Poco::Logger * log;\n \ndiff --git a/src/Storages/System/StorageSystemColumns.cpp b/src/Storages/System/StorageSystemColumns.cpp\nindex 8f65147bb11e..0058b58f5377 100644\n--- a/src/Storages/System/StorageSystemColumns.cpp\n+++ b/src/Storages/System/StorageSystemColumns.cpp\n@@ -98,7 +98,7 @@ class ColumnsSource : public SourceWithProgress\n             Names cols_required_for_sorting_key;\n             Names cols_required_for_primary_key;\n             Names cols_required_for_sampling;\n-            MergeTreeData::ColumnSizeByName column_sizes;\n+            IStorage::ColumnSizeByName column_sizes;\n \n             {\n                 StoragePtr storage = storages.at(std::make_pair(database_name, table_name));\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01943_log_column_sizes.reference b/tests/queries/0_stateless/01943_log_column_sizes.reference\nnew file mode 100644\nindex 000000000000..91ae12e38ce7\n--- /dev/null\n+++ b/tests/queries/0_stateless/01943_log_column_sizes.reference\n@@ -0,0 +1,6 @@\n+27\n+33\n+105\n+27\n+33\n+105\ndiff --git a/tests/queries/0_stateless/01943_log_column_sizes.sql b/tests/queries/0_stateless/01943_log_column_sizes.sql\nnew file mode 100644\nindex 000000000000..c6cd48c33d97\n--- /dev/null\n+++ b/tests/queries/0_stateless/01943_log_column_sizes.sql\n@@ -0,0 +1,14 @@\n+DROP TABLE IF EXISTS test_log;\n+DROP TABLE IF EXISTS test_tiny_log;\n+\n+CREATE TABLE test_log (x UInt8, s String, a Array(Nullable(String))) ENGINE = Log;\n+CREATE TABLE test_tiny_log (x UInt8, s String, a Array(Nullable(String))) ENGINE = TinyLog;\n+\n+INSERT INTO test_log VALUES (64, 'Value1', ['Value2', 'Value3', NULL]);\n+INSERT INTO test_tiny_log VALUES (64, 'Value1', ['Value2', 'Value3', NULL]);\n+\n+SELECT data_compressed_bytes FROM system.columns WHERE table = 'test_log' AND database = currentDatabase();\n+SELECT data_compressed_bytes FROM system.columns WHERE table = 'test_tiny_log' AND database = currentDatabase();\n+\n+DROP TABLE test_log;\n+DROP TABLE test_tiny_log;\n\\ No newline at end of file\n",
  "problem_statement": "system.columns returns zero size for columns of Log-family table engine\nIt needs to define the size of columns Log-family table.\r\n\r\n*data_uncompressed_bytes*-field is a zero in *system.column*-table. Is it intended behaviour?\r\n\r\nFound the once way to define size is to request the file system:\r\n1. find out the location of table files\r\n```sql\r\nSELECT *\r\nFROM system.tables\r\nWHERE name = '{table name}'\r\nFORMAT Vertical\r\n\r\n/* Result:\r\nRow 1:\r\n\u2500\u2500\u2500\u2500\u2500\u2500\r\n..\r\ndata_paths:                 ['/var/lib/clickhouse/data/test/log_engine_001/']\r\n..\r\n*/\r\n```\r\n2. list all files in this directory\r\n```bash\r\nsudo ls -lsh /var/lib/clickhouse/data/test/log_engine_001\r\n\r\n# Result:\r\n# total 88K\r\n# 4.0K -rw-r----- 1 clickhouse clickhouse  64 Feb  3 20:28 __marks.mrk\r\n#  40K -rw-r----- 1 clickhouse clickhouse 40K Feb  3 20:28 id.bin\r\n#  40K -rw-r----- 1 clickhouse clickhouse 40K Feb  3 20:28 name.bin\r\n# 4.0K -rw-r----- 1 clickhouse clickhouse 100 Feb  3 20:28 sizes.json\r\n```\r\n\r\nThis way requires to have access to the server file system that can be restricted.\r\n\r\n[ClickHouse server version 19.17.5 revision 54428]\n",
  "hints_text": "Not sure if it's always easy (i.e. StripeLog)\nIt can be implemented for Log and TinyLog in trivial way.\r\nAnd also for StripeLog - because it has an index to seek for specific column.",
  "created_at": "2021-07-12T10:07:57Z"
}