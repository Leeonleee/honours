{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 49122,
  "instance_id": "ClickHouse__ClickHouse-49122",
  "issue_numbers": [
    "48493"
  ],
  "base_commit": "7902a1415eac73393388969cbc8cd8e4f3888219",
  "patch": "diff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex aa5e69ce571f..46cfb7dedc5e 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -648,7 +648,7 @@ class IColumn;\n     M(UInt64, remote_read_min_bytes_for_seek, 4 * DBMS_DEFAULT_BUFFER_SIZE, \"Min bytes required for remote read (url, s3) to do seek, instead of read with ignore.\", 0) \\\n     \\\n     M(UInt64, async_insert_threads, 16, \"Maximum number of threads to actually parse and insert data in background. Zero means asynchronous mode is disabled\", 0) \\\n-    M(Bool, async_insert, false, \"If true, data from INSERT query is stored in queue and later flushed to table in background. Makes sense only for inserts via HTTP protocol. If wait_for_async_insert is false, INSERT query is processed almost instantly, otherwise client will wait until data will be flushed to table\", 0) \\\n+    M(Bool, async_insert, false, \"If true, data from INSERT query is stored in queue and later flushed to table in background. If wait_for_async_insert is false, INSERT query is processed almost instantly, otherwise client will wait until data will be flushed to table\", 0) \\\n     M(Bool, wait_for_async_insert, true, \"If true wait for processing of asynchronous insertion\", 0) \\\n     M(Seconds, wait_for_async_insert_timeout, DBMS_DEFAULT_LOCK_ACQUIRE_TIMEOUT_SEC, \"Timeout for waiting for processing asynchronous insertion\", 0) \\\n     M(UInt64, async_insert_max_data_size, 1000000, \"Maximum size in bytes of unparsed data collected per query before being inserted\", 0) \\\ndiff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp\nindex 00a5d0ed1d89..7852f4cefa82 100644\n--- a/src/Interpreters/executeQuery.cpp\n+++ b/src/Interpreters/executeQuery.cpp\n@@ -57,6 +57,7 @@\n #include <Interpreters/SelectQueryOptions.h>\n #include <Interpreters/TransactionLog.h>\n #include <Interpreters/executeQuery.h>\n+#include <Interpreters/DatabaseCatalog.h>\n #include <Common/ProfileEvents.h>\n \n #include <IO/CompressionMethod.h>\n@@ -526,6 +527,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n         context->initializeExternalTablesIfSet();\n \n         auto * insert_query = ast->as<ASTInsertQuery>();\n+        bool async_insert_enabled = settings.async_insert;\n \n         /// Resolve database before trying to use async insert feature - to properly hash the query.\n         if (insert_query)\n@@ -534,6 +536,10 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n                 insert_query->table_id = context->resolveStorageID(insert_query->table_id);\n             else if (auto table = insert_query->getTable(); !table.empty())\n                 insert_query->table_id = context->resolveStorageID(StorageID{insert_query->getDatabase(), table});\n+\n+            if (insert_query->table_id)\n+                if (auto table = DatabaseCatalog::instance().tryGetTable(insert_query->table_id, context))\n+                    async_insert_enabled |= table->areAsynchronousInsertsEnabled();\n         }\n \n         if (insert_query && insert_query->select)\n@@ -568,7 +574,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n         auto * queue = context->getAsynchronousInsertQueue();\n         auto * logger = &Poco::Logger::get(\"executeQuery\");\n \n-        if (insert_query && settings.async_insert)\n+        if (insert_query && async_insert_enabled)\n         {\n             String reason;\n \ndiff --git a/src/Storages/IStorage.h b/src/Storages/IStorage.h\nindex a2e827d98309..5743d9036304 100644\n--- a/src/Storages/IStorage.h\n+++ b/src/Storages/IStorage.h\n@@ -178,6 +178,8 @@ class IStorage : public std::enable_shared_from_this<IStorage>, public TypePromo\n     /// Returns true if the storage is for system, which cannot be target of SHOW CREATE TABLE.\n     virtual bool isSystemStorage() const { return false; }\n \n+    /// Returns true if asynchronous inserts are enabled for table.\n+    virtual bool areAsynchronousInsertsEnabled() const { return false; }\n \n     /// Optional size information of each physical column.\n     /// Currently it's only used by the MergeTree family for query optimizations.\ndiff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h\nindex 42cbd311b868..a0a6407aee04 100644\n--- a/src/Storages/MergeTree/MergeTreeData.h\n+++ b/src/Storages/MergeTree/MergeTreeData.h\n@@ -431,6 +431,8 @@ class MergeTreeData : public IStorage, public WithMutableContext\n \n     bool supportsLightweightDelete() const override;\n \n+    bool areAsynchronousInsertsEnabled() const override { return getSettings()->async_insert; }\n+\n     NamesAndTypesList getVirtuals() const override;\n \n     bool mayBenefitFromIndexForIn(const ASTPtr & left_in_operand, ContextPtr, const StorageMetadataPtr & metadata_snapshot) const override;\ndiff --git a/src/Storages/MergeTree/MergeTreeSettings.h b/src/Storages/MergeTree/MergeTreeSettings.h\nindex ba98fca2f508..9bdca422c447 100644\n--- a/src/Storages/MergeTree/MergeTreeSettings.h\n+++ b/src/Storages/MergeTree/MergeTreeSettings.h\n@@ -83,6 +83,7 @@ struct Settings;\n     M(UInt64, max_delay_to_insert, 1, \"Max delay of inserting data into MergeTree table in seconds, if there are a lot of unmerged parts in single partition.\", 0) \\\n     M(UInt64, min_delay_to_insert_ms, 10, \"Min delay of inserting data into MergeTree table in milliseconds, if there are a lot of unmerged parts in single partition.\", 0) \\\n     M(UInt64, max_parts_in_total, 100000, \"If more than this number active parts in all partitions in total, throw 'Too many parts ...' exception.\", 0) \\\n+    M(Bool, async_insert, false, \"If true, data from INSERT query is stored in queue and later flushed to table in background.\", 0) \\\n     \\\n     /* Part removal settings. */ \\\n     M(UInt64, simultaneous_parts_removal_limit, 0, \"Maximum number of parts to remove during one CleanupThread iteration (0 means unlimited).\", 0) \\\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02725_async_insert_table_setting.reference b/tests/queries/0_stateless/02725_async_insert_table_setting.reference\nnew file mode 100644\nindex 000000000000..5f5235c569f7\n--- /dev/null\n+++ b/tests/queries/0_stateless/02725_async_insert_table_setting.reference\n@@ -0,0 +1,4 @@\n+2\n+2\n+default.t_mt_async_insert\t1\n+default.t_mt_sync_insert\t0\ndiff --git a/tests/queries/0_stateless/02725_async_insert_table_setting.sh b/tests/queries/0_stateless/02725_async_insert_table_setting.sh\nnew file mode 100755\nindex 000000000000..13911e8d6778\n--- /dev/null\n+++ b/tests/queries/0_stateless/02725_async_insert_table_setting.sh\n@@ -0,0 +1,35 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+${CLICKHOUSE_CLIENT} -n --query \"\n+DROP TABLE IF EXISTS t_mt_async_insert;\n+DROP TABLE IF EXISTS t_mt_sync_insert;\n+\n+CREATE TABLE t_mt_async_insert (id UInt64, s String)\n+ENGINE = MergeTree ORDER BY id SETTINGS async_insert = 1;\n+\n+CREATE TABLE t_mt_sync_insert (id UInt64, s String)\n+ENGINE = MergeTree ORDER BY id SETTINGS async_insert = 0;\"\n+\n+url=\"${CLICKHOUSE_URL}&async_insert=0&wait_for_async_insert=1\"\n+\n+${CLICKHOUSE_CURL} -sS \"$url\" -d \"INSERT INTO t_mt_async_insert VALUES (1, 'aa'), (2, 'bb')\"\n+${CLICKHOUSE_CURL} -sS \"$url\" -d \"INSERT INTO t_mt_sync_insert VALUES (1, 'aa'), (2, 'bb')\"\n+\n+${CLICKHOUSE_CLIENT} -n --query \"\n+SELECT count() FROM t_mt_async_insert;\n+SELECT count() FROM t_mt_sync_insert;\n+\n+SYSTEM FLUSH LOGS;\n+SELECT tables[1], ProfileEvents['AsyncInsertQuery'] FROM system.query_log\n+WHERE\n+    type = 'QueryFinish' AND\n+    current_database = currentDatabase() AND\n+    query ILIKE 'INSERT INTO t_mt_%sync_insert%'\n+ORDER BY tables[1];\n+\n+DROP TABLE IF EXISTS t_mt_async_insert;\n+DROP TABLE IF EXISTS t_mt_sync_insert;\"\n",
  "problem_statement": "Makes Async Inserts a merge tree level setting\n\r\n**Use case**\r\n\r\nOne of the main challenges of supporting ClickHouse. This is the optimal user experience - rare for users need to mix insert workload types on the same table.\r\n\r\n**Describe the solution you'd like**\r\n\r\nMerge Tree level setting. Set on table creation time.\r\n\r\n\r\n\n",
  "hints_text": "",
  "created_at": "2023-04-25T01:17:08Z"
}