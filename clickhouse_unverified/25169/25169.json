{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 25169,
  "instance_id": "ClickHouse__ClickHouse-25169",
  "issue_numbers": [
    "25129"
  ],
  "base_commit": "993870c951f998f5d2d92d48bb55844944852e20",
  "patch": "diff --git a/src/Processors/Formats/IInputFormat.h b/src/Processors/Formats/IInputFormat.h\nindex 95910bf51e5b..f8811962260c 100644\n--- a/src/Processors/Formats/IInputFormat.h\n+++ b/src/Processors/Formats/IInputFormat.h\n@@ -12,7 +12,7 @@ struct ColumnMapping\n {\n     /// Non-atomic because there is strict `happens-before` between read and write access\n     /// See InputFormatParallelParsing\n-    bool is_set;\n+    bool is_set{false};\n     /// Maps indexes of columns in the input file to indexes of table columns\n     using OptionalIndexes = std::vector<std::optional<size_t>>;\n     OptionalIndexes column_indexes_for_input_fields;\n@@ -22,6 +22,11 @@ struct ColumnMapping\n     /// read the file header, and never changed afterwards.\n     /// For other columns, it is updated on each read() call.\n     std::vector<UInt8> read_columns;\n+\n+\n+    /// Whether we have any columns that are not read from file at all,\n+    /// and must be always initialized with defaults.\n+    bool have_always_default_columns{false};\n };\n \n using ColumnMappingPtr = std::shared_ptr<ColumnMapping>;\ndiff --git a/src/Processors/Formats/Impl/CSVRowInputFormat.cpp b/src/Processors/Formats/Impl/CSVRowInputFormat.cpp\nindex 4ccc0db4cfed..93c39995e34b 100644\n--- a/src/Processors/Formats/Impl/CSVRowInputFormat.cpp\n+++ b/src/Processors/Formats/Impl/CSVRowInputFormat.cpp\n@@ -193,7 +193,7 @@ void CSVRowInputFormat::readPrefix()\n             {\n                 if (!read_column)\n                 {\n-                    have_always_default_columns = true;\n+                    column_mapping->have_always_default_columns = true;\n                     break;\n                 }\n             }\n@@ -221,7 +221,7 @@ bool CSVRowInputFormat::readRow(MutableColumns & columns, RowReadExtension & ext\n     /// Track whether we have to fill any columns in this row with default\n     /// values. If not, we return an empty column mask to the caller, so that\n     /// it doesn't have to check it.\n-    bool have_default_columns = have_always_default_columns;\n+    bool have_default_columns = column_mapping->have_always_default_columns;\n \n     ext.read_columns.assign(column_mapping->read_columns.size(), true);\n     const auto delimiter = format_settings.csv.delimiter;\n@@ -416,7 +416,7 @@ void CSVRowInputFormat::resetParser()\n     RowInputFormatWithDiagnosticInfo::resetParser();\n     column_mapping->column_indexes_for_input_fields.clear();\n     column_mapping->read_columns.clear();\n-    have_always_default_columns = false;\n+    column_mapping->have_always_default_columns = false;\n }\n \n \ndiff --git a/src/Processors/Formats/Impl/CSVRowInputFormat.h b/src/Processors/Formats/Impl/CSVRowInputFormat.h\nindex 230acc512686..b6075745b39b 100644\n--- a/src/Processors/Formats/Impl/CSVRowInputFormat.h\n+++ b/src/Processors/Formats/Impl/CSVRowInputFormat.h\n@@ -31,17 +31,13 @@ class CSVRowInputFormat : public RowInputFormatWithDiagnosticInfo\n     void resetParser() override;\n \n private:\n+    /// There fields are computed in constructor.\n     bool with_names;\n     const FormatSettings format_settings;\n     DataTypes data_types;\n-\n     using IndexesMap = std::unordered_map<String, size_t>;\n     IndexesMap column_indexes_by_names;\n \n-    /// Whether we have any columns that are not read from file at all,\n-    /// and must be always initialized with defaults.\n-    bool have_always_default_columns = false;\n-\n     void addInputColumn(const String & column_name);\n \n     void setupAllColumnsByTableSchema();\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01903_csvwithnames_subset_of_columns.reference b/tests/queries/0_stateless/01903_csvwithnames_subset_of_columns.reference\nnew file mode 100644\nindex 000000000000..1e008a436cc6\n--- /dev/null\n+++ b/tests/queries/0_stateless/01903_csvwithnames_subset_of_columns.reference\n@@ -0,0 +1,3 @@\n+1000000\n+2000000\n+3000000\ndiff --git a/tests/queries/0_stateless/01903_csvwithnames_subset_of_columns.sh b/tests/queries/0_stateless/01903_csvwithnames_subset_of_columns.sh\nnew file mode 100755\nindex 000000000000..17d2c4a47d5e\n--- /dev/null\n+++ b/tests/queries/0_stateless/01903_csvwithnames_subset_of_columns.sh\n@@ -0,0 +1,23 @@\n+#!/usr/bin/env bash\n+\n+CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CUR_DIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS test_01903\"\n+\n+$CLICKHOUSE_CLIENT -q \"CREATE TABLE test_01903 (col0 Date, col1 Nullable(UInt8)) ENGINE MergeTree() PARTITION BY toYYYYMM(col0) ORDER BY col0;\"\n+\n+(echo col0,col1; for _ in `seq 1 1000000`; do echo '2021-05-05',1; done) | $CLICKHOUSE_CLIENT -q \"INSERT INTO test_01903 FORMAT CSVWithNames\"\n+\n+$CLICKHOUSE_CLIENT -q \"SELECT count() FROM test_01903\"\n+\n+(echo col0; for _ in `seq 1 1000000`; do echo '2021-05-05'; done) | $CLICKHOUSE_CLIENT -q \"INSERT INTO test_01903 (col0) FORMAT CSVWithNames\"\n+\n+$CLICKHOUSE_CLIENT -q \"SELECT count() FROM test_01903\"\n+\n+(echo col0; for _ in `seq 1 1000000`; do echo '2021-05-05'; done) | $CLICKHOUSE_CLIENT -q \"INSERT INTO test_01903 (col0) FORMAT TSVWithNames\"\n+\n+$CLICKHOUSE_CLIENT -q \"SELECT count() FROM test_01903\"\n+\n+$CLICKHOUSE_CLIENT -q \"DROP TABLE IF EXISTS test_01903\"\n",
  "problem_statement": "Input format `CSVWithNames` not working properly without all columns in data\nClickHouse version: 21.4.7.3\r\nUbuntu: 18.04.4\r\n\r\n**Describe the bug**\r\n\r\nData insertion using `CSVWithNames` not working properly if `Nullable` columns aren't presented in input data.\r\nSeems ClickHouse adds a full column list to insert query itself if trying to insert data from stdin with the query `INSERT INTO test FORMAT CSVWithNames` without specifying the exact columns list. ClickHouse inserts some part of data before error raises. But strictly specifying columns list from input data makes it work.\r\n\r\n**Error**\r\n```\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x87e86ca in /usr/bin/clickhouse\r\n1. DB::Chunk::checkNumRowsIsConsistent() @ 0xff10545 in /usr/bin/clickhouse\r\n2. DB::Chunk::Chunk(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >, unsigned long) @ 0xff109f6 in /usr/bin/clickhouse\r\n3. DB::IRowInputFormat::generate() @ 0xff89925 in /usr/bin/clickhouse\r\n4. DB::ISource::tryGenerate() @ 0xff18685 in /usr/bin/clickhouse\r\n5. DB::ISource::work() @ 0xff1827a in /usr/bin/clickhouse\r\n6. DB::ParallelParsingInputFormat::InternalParser::getChunk() @ 0xffdf07e in /usr/bin/clickhouse\r\n7. DB::ParallelParsingInputFormat::parserThreadFunction(std::__1::shared_ptr<DB::ThreadGroupStatus>, unsigned long) @ 0xffde5ee in /usr/bin/clickhouse\r\n8. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x882b2f8 in /usr/bin/clickhouse\r\n9. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() @ 0x882d2bf in /usr/bin/clickhouse\r\n10. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x882883f in /usr/bin/clickhouse\r\n11. ? @ 0x882c363 in /usr/bin/clickhouse\r\n12. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n13. clone @ 0x121a3f in /lib/x86_64-linux-gnu/libc-2.27.so\r\n (version 21.4.7.3 (official build))\r\nCode: 49. DB::Exception: Invalid number of rows in Chunk column Nullable(UInt8) position 1: expected 193403, got 0: data for INSERT was parsed from stdin\r\n\r\n```\r\n\r\n**Logs**\r\n\r\nNo new logs appear in `clickhouse-server.err.log`.\r\n\r\nBut `clickhouse-server.log` shows that ClickHouse specifying full column list itself:\r\n```\r\n<Trace> ContextAccess (default): Access granted: INSERT(col0, col1) ON db.test;\r\n```\r\n\r\n**How to reproduce**\r\n\r\n* ClickHouse: 21.4.7.3\r\n* Client: clickhouse-client\r\n* Default settings\r\n```\r\nCREATE TABLE db.test (\r\n    col0 Date,\r\n    col1 Nullable(UInt8)\r\n)\r\nENGINE MergeTree()\r\nPARTITION BY toYYYYMM(col0)\r\nORDER BY col0;\r\n```\r\nCommand to insert 1.000.000 rows into `test` table only with `col0` column:\r\n```\r\n(echo col0; for _ in `seq 1 1000000`; do echo '2021-05-05'; done) | clickhouse-client -q \"INSERT INTO test FORMAT CSVWithNames\" \r\n```\r\nCommands to insert 1.000.000 rows into `test` that works:\r\nAll columns from table are presented in input data\r\n```\r\n(echo col0,col1; for _ in `seq 1 1000000`; do echo '2021-05-05',1; done) | clickhouse-client -q \"INSERT INTO test FORMAT CSVWithNames\" \r\n```\r\nOnly one column presented in input data but the column list is strictly specified in the insert query.\r\n```\r\n(echo col0; for _ in `seq 1 1000000`; do echo '2021-05-05'; done) | clickhouse-client -q \"INSERT INTO test (col0) FORMAT CSVWithNames\" \r\n```\r\n\r\n**Expected behavior**\r\n`*WithNames` formats should work without specifying the actual column list from input data even if input data doesn't have all table columns.\r\n\r\n\n",
  "hints_text": "@nikitamikhaylov It looks unexpected, could you please take a look?",
  "created_at": "2021-06-10T13:59:29Z"
}