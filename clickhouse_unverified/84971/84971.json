{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 84971,
  "instance_id": "ClickHouse__ClickHouse-84971",
  "issue_numbers": [
    "80789"
  ],
  "base_commit": "aed8ba35bd87c7c43032145bb681874ae31f7892",
  "patch": "diff --git a/src/Processors/QueryPlan/ParallelReplicasLocalPlan.cpp b/src/Processors/QueryPlan/ParallelReplicasLocalPlan.cpp\nindex d6bed228fdf3..df152b039e99 100644\n--- a/src/Processors/QueryPlan/ParallelReplicasLocalPlan.cpp\n+++ b/src/Processors/QueryPlan/ParallelReplicasLocalPlan.cpp\n@@ -99,7 +99,7 @@ std::pair<QueryPlanPtr, bool> createLocalPlanForParallelReplicas(\n     { return coordinator->handleRequest(std::move(req)); };\n \n     auto read_from_merge_tree_parallel_replicas = reading->createLocalParallelReplicasReadingStep(\n-        analyzed_result_ptr, std::move(all_ranges_cb), std::move(read_task_cb), replica_number);\n+        context, analyzed_result_ptr, std::move(all_ranges_cb), std::move(read_task_cb), replica_number);\n     node->step = std::move(read_from_merge_tree_parallel_replicas);\n \n     addConvertingActions(*query_plan, header, /*has_missing_objects=*/false);\ndiff --git a/src/Processors/QueryPlan/ReadFromMergeTree.cpp b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\nindex c9f944221461..f088b1ed5842 100644\n--- a/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n+++ b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n@@ -416,6 +416,7 @@ ReadFromMergeTree::ReadFromMergeTree(\n }\n \n std::unique_ptr<ReadFromMergeTree> ReadFromMergeTree::createLocalParallelReplicasReadingStep(\n+    ContextPtr & context_,\n     AnalysisResultPtr analyzed_result_ptr_,\n     MergeTreeAllRangesCallback all_ranges_callback_,\n     MergeTreeReadTaskCallback read_task_callback_,\n@@ -429,7 +430,7 @@ std::unique_ptr<ReadFromMergeTree> ReadFromMergeTree::createLocalParallelReplica\n         data,\n         getQueryInfo(),\n         getStorageSnapshot(),\n-        getContext(),\n+        context_,\n         block_size.max_block_size_rows,\n         requested_num_streams,\n         max_block_numbers_to_read,\n@@ -643,9 +644,7 @@ Pipe ReadFromMergeTree::readInOrder(\n     /// If parallel replicas enabled, set total rows in progress here only on initiator with local plan\n     /// Otherwise rows will counted multiple times\n     const UInt64 in_order_limit = query_info.input_order_info ? query_info.input_order_info->limit : 0;\n-    const bool parallel_replicas_local_plan_for_initiator = is_parallel_reading_from_replicas\n-        && context->getSettingsRef()[Setting::parallel_replicas_local_plan] && context->canUseParallelReplicasOnInitiator();\n-    const bool set_total_rows_approx = !is_parallel_reading_from_replicas || parallel_replicas_local_plan_for_initiator;\n+    const bool set_total_rows_approx = !is_parallel_reading_from_replicas || isParallelReplicasLocalPlanForInitiator();\n \n     Pipes pipes;\n     for (size_t i = 0; i < parts_with_ranges.size(); ++i)\n@@ -2079,6 +2078,12 @@ void ReadFromMergeTree::updateSortDescription()\n         enable_vertical_final);\n }\n \n+bool ReadFromMergeTree::isParallelReplicasLocalPlanForInitiator() const\n+{\n+    return is_parallel_reading_from_replicas && context->getSettingsRef()[Setting::parallel_replicas_local_plan]\n+        && context->canUseParallelReplicasOnInitiator();\n+}\n+\n bool ReadFromMergeTree::requestReadingInOrder(size_t prefix_size, int direction, size_t read_limit, std::optional<ActionsDAG> virtual_row_conversion_)\n {\n     /// if dirction is not set, use current one\n@@ -2417,6 +2422,22 @@ void ReadFromMergeTree::initializePipeline(QueryPipelineBuilder & pipeline, cons\n     if (reader_settings.use_query_condition_cache && !query_info.prewhere_info && !query_info.filter_actions_dag)\n         reader_settings.use_query_condition_cache = false;\n \n+    /// Initializing parallel replicas coordinator with empty ranges to read in case of\n+    /// local plan for initiator to prevent coordinator initialization by other replicas\n+    /// (which may skip index analysis).\n+    if (result.parts_with_ranges.empty() && isParallelReplicasLocalPlanForInitiator())\n+    {\n+        const auto & client_info = context->getClientInfo();\n+\n+        auto extension = ParallelReadingExtension{\n+            all_ranges_callback.value(),\n+            read_task_callback.value(),\n+            number_of_current_replica.value_or(client_info.number_of_current_replica),\n+            context->getClusterForParallelReplicas()->getShardsInfo().at(0).getAllNodeCount()};\n+\n+        extension.sendInitialRequest(CoordinationMode::Default, result.parts_with_ranges, /*mark_segment_size=*/1);\n+    }\n+\n     if (result.parts_with_ranges.empty())\n     {\n         pipeline.init(Pipe(std::make_shared<NullSource>(getOutputHeader())));\ndiff --git a/src/Processors/QueryPlan/ReadFromMergeTree.h b/src/Processors/QueryPlan/ReadFromMergeTree.h\nindex 22691674d2a8..3940bd58c573 100644\n--- a/src/Processors/QueryPlan/ReadFromMergeTree.h\n+++ b/src/Processors/QueryPlan/ReadFromMergeTree.h\n@@ -157,6 +157,7 @@ class ReadFromMergeTree final : public SourceStepWithFilter\n     ReadFromMergeTree(ReadFromMergeTree &&) noexcept = default;\n \n     std::unique_ptr<ReadFromMergeTree> createLocalParallelReplicasReadingStep(\n+        ContextPtr & context_,\n         AnalysisResultPtr analyzed_result_ptr_,\n         MergeTreeAllRangesCallback all_ranges_callback_,\n         MergeTreeReadTaskCallback read_task_callback_,\n@@ -325,6 +326,8 @@ class ReadFromMergeTree final : public SourceStepWithFilter\n     int getSortDirection() const;\n     void updateSortDescription();\n \n+    bool isParallelReplicasLocalPlanForInitiator() const;\n+\n     mutable AnalysisResultPtr analyzed_result_ptr;\n     VirtualFields shared_virtual_fields;\n \ndiff --git a/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp\nindex 8f5e45200125..08990b720bed 100644\n--- a/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp\n+++ b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp\n@@ -188,6 +188,7 @@ class ParallelReplicasReadingCoordinator::ImplInterface\n     virtual void doHandleInitialAllRangesAnnouncement(InitialAllRangesAnnouncement announcement) = 0;\n     virtual void markReplicaAsUnavailable(size_t replica_number) = 0;\n     virtual bool isReadingCompleted() const { return false; }\n+    virtual bool initializedWithEmptyRanges() const { return false; }\n \n     void handleInitialAllRangesAnnouncement(InitialAllRangesAnnouncement announcement)\n     {\n@@ -236,6 +237,8 @@ class DefaultCoordinator : public ParallelReplicasReadingCoordinator::ImplInterf\n \n     bool isReadingCompleted() const override;\n \n+    bool initializedWithEmptyRanges() const override { return state_initialized && all_parts_to_read.empty(); }\n+\n private:\n     /// This many granules will represent a single segment of marks that will be assigned to a replica\n     size_t mark_segment_size{0};\n@@ -1175,7 +1178,9 @@ ParallelReadResponse ParallelReplicasReadingCoordinator::handleRequest(ParallelR\n                 \"All ranges for reading has been assigned to replicas. Cancelling execution for unused replicas. Used replicas: {}\",\n                 replicas);\n \n-            chassert(!replicas_used.empty());\n+            if (pimpl && !pimpl->initializedWithEmptyRanges())\n+                chassert(!replicas_used.empty());\n+\n             (*read_completed_callback)(replicas_to_exclude);\n             read_completed_callback.reset();\n         }\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03581_parallel_replicas_read_empty_ranges.reference b/tests/queries/0_stateless/03581_parallel_replicas_read_empty_ranges.reference\nnew file mode 100644\nindex 000000000000..b3e7b00c0a0f\n--- /dev/null\n+++ b/tests/queries/0_stateless/03581_parallel_replicas_read_empty_ranges.reference\n@@ -0,0 +1,8 @@\n+Primary key:\t0\n+Skip index MinMax:\t0\n+Skip index Set:\t0\n+\n+Rows read:\n+0\n+0\n+0\ndiff --git a/tests/queries/0_stateless/03581_parallel_replicas_read_empty_ranges.sql b/tests/queries/0_stateless/03581_parallel_replicas_read_empty_ranges.sql\nnew file mode 100644\nindex 000000000000..1e9af5e2b7a1\n--- /dev/null\n+++ b/tests/queries/0_stateless/03581_parallel_replicas_read_empty_ranges.sql\n@@ -0,0 +1,38 @@\n+set allow_experimental_parallel_reading_from_replicas = 1,\n+    parallel_replicas_for_non_replicated_merge_tree = 1,\n+    cluster_for_parallel_replicas = 'test_cluster_one_shard_three_replicas_localhost';\n+\n+drop table if exists 03581_data;\n+\n+create table 03581_data (\n+    key UInt32,\n+\n+    val_minmax UInt32,\n+    val_set UInt32,\n+\n+    index skip_minmax val_minmax type set(0) granularity 1,\n+    index skip_set val_set type set(0) granularity 1,\n+)\n+engine = MergeTree\n+order by key\n+settings index_granularity = 10;\n+\n+insert into 03581_data select number, number, number from numbers(1000);\n+\n+select 'Primary key:', count() from 03581_data where key = 2000;\n+select 'Skip index MinMax:', count() from 03581_data where val_minmax = 2000;\n+select 'Skip index Set:', count() from 03581_data where val_set = 2000;\n+\n+select '';\n+select 'Rows read:';\n+\n+system flush logs query_log;\n+\n+select read_rows\n+from system.query_log\n+where current_database = currentDatabase()\n+  and type = 'QueryFinish'\n+  and query ilike '% from 03581_data where %'\n+order by event_time_microseconds desc;\n+\n+drop table 03581_data;\n",
  "problem_statement": "When using parallel replicas, index analysis does not cut off the data using the final mark.\n### Company or project name\n\nClickHouse\n\n### Describe the situation\n\n.\n\n### Which ClickHouse versions are affected?\n\n25.4\n\n### How to reproduce\n\n```\nCREATE TABLE strings (s String) ORDER BY s;\nINSERT INTO strings SELECT randomPrintableASCII(10) AS s\nFROM numbers_mt(1e8) WHERE s <= 'x';\n\nSET max_rows_to_read = 10000000, max_parallel_replicas = 1;\nSELECT count(), sum(length(s)) FROM strings WHERE s LIKE 'a%';\nSELECT count(), sum(length(s)) FROM strings WHERE s LIKE 'z%';\n\nSET max_rows_to_read = 10000000, max_parallel_replicas = 100;\nSELECT count(), sum(length(s)) FROM strings WHERE s LIKE 'a%';\nSELECT count(), sum(length(s)) FROM strings WHERE s LIKE 'z%';\n```\n\nHere we insert some data with strings starting from `a` to `x`.\nThere will be no strings staring from `z`, so the query `LIKE 'z%'` should quickly return zero.\nIt works because we have a \"final mark\" in the primary key, designating the maximum value in the data part.\n\nHowever, the final mark is ignored if parallel replicas are on.\nAll queries except the last one succeeded, but the last one wanted to do a full scan.\n\n### Expected performance\n\n_No response_\n\n### Additional context\n\n_No response_\n",
  "hints_text": "",
  "created_at": "2025-08-03T14:30:02Z",
  "modified_files": [
    "src/Processors/QueryPlan/ParallelReplicasLocalPlan.cpp",
    "src/Processors/QueryPlan/ReadFromMergeTree.cpp",
    "src/Processors/QueryPlan/ReadFromMergeTree.h",
    "src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/03581_parallel_replicas_read_empty_ranges.reference",
    "b/tests/queries/0_stateless/03581_parallel_replicas_read_empty_ranges.sql"
  ]
}