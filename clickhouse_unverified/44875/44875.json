{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 44875,
  "instance_id": "ClickHouse__ClickHouse-44875",
  "issue_numbers": [
    "44709"
  ],
  "base_commit": "bdd3ef89206054b7f26b8727bccc66dd3fd7bdd6",
  "patch": "diff --git a/src/Formats/MarkInCompressedFile.h b/src/Formats/MarkInCompressedFile.h\nindex 1cd545e1a034..287d3f7909d7 100644\n--- a/src/Formats/MarkInCompressedFile.h\n+++ b/src/Formats/MarkInCompressedFile.h\n@@ -28,6 +28,11 @@ struct MarkInCompressedFile\n         return !(*this == rhs);\n     }\n \n+    auto asTuple() const\n+    {\n+        return std::make_tuple(offset_in_compressed_file, offset_in_decompressed_block);\n+    }\n+\n     String toString() const\n     {\n         return \"(\" + DB::toString(offset_in_compressed_file) + \",\" + DB::toString(offset_in_decompressed_block) + \")\";\ndiff --git a/src/Storages/MergeTree/MergeTreeReaderStream.cpp b/src/Storages/MergeTree/MergeTreeReaderStream.cpp\nindex 47f8b0f6008b..cdca5aa1247d 100644\n--- a/src/Storages/MergeTree/MergeTreeReaderStream.cpp\n+++ b/src/Storages/MergeTree/MergeTreeReaderStream.cpp\n@@ -135,7 +135,7 @@ void MergeTreeReaderStream::init()\n }\n \n \n-size_t MergeTreeReaderStream::getRightOffset(size_t right_mark_non_included)\n+size_t MergeTreeReaderStream::getRightOffset(size_t right_mark)\n {\n     /// NOTE: if we are reading the whole file, then right_mark == marks_count\n     /// and we will use max_read_buffer_size for buffer size, thus avoiding the need to load marks.\n@@ -144,70 +144,83 @@ size_t MergeTreeReaderStream::getRightOffset(size_t right_mark_non_included)\n     if (marks_count == 0)\n         return 0;\n \n-    assert(right_mark_non_included <= marks_count);\n+    assert(right_mark <= marks_count);\n \n-    size_t result_right_offset;\n-    if (0 < right_mark_non_included && right_mark_non_included < marks_count)\n+    if (0 < right_mark && right_mark < marks_count)\n     {\n         /// Find the right border of the last mark we need to read.\n         /// To do that let's find the upper bound of the offset of the last\n         /// included mark.\n \n-        /// In LowCardinality dictionary and in values of Sparse columns\n-        /// several consecutive marks can point to the same offset.\n-        ///\n-        /// Example:\n-        ///  Mark 186, points to [2003111, 0]\n-        ///  Mark 187, points to [2003111, 0]\n-        ///  Mark 188, points to [2003111, 0] <--- for example need to read until 188\n-        ///  Mark 189, points to [2003111, 0] <--- not suitable, because have same offset\n-        ///  Mark 190, points to [2003111, 0]\n-        ///  Mark 191, points to [2003111, 0]\n-        ///  Mark 192, points to [2081424, 0] <--- what we are looking for\n-        ///  Mark 193, points to [2081424, 0]\n-        ///  Mark 194, points to [2081424, 0]\n-\n-        /// Also, in some cases, when one granule is not-atomically written (which is possible at merges)\n-        /// one granule may require reading of two dictionaries which starts from different marks.\n-        /// The only correct way is to take offset from at least next different granule from the right one.\n-        /// So, that's why we have to read one extra granule to the right,\n-        /// while reading dictionary of LowCardinality.\n-\n-        /// If right_mark_non_included has non-zero offset in decompressed block, we have to\n-        /// read its compressed block in a whole, because it may consist data from previous granule.\n+        if (is_low_cardinality_dictionary)\n+        {\n+\n+            /// In LowCardinality dictionary several consecutive marks can point to the same offset.\n+            ///\n+            /// Also, in some cases, when one granule is not-atomically written (which is possible at merges)\n+            /// one granule may require reading of two dictionaries which starts from different marks.\n+            /// The only correct way is to take offset from at least next different granule from the right one.\n+            /// So, that's why we have to read one extra granule to the right,\n+            /// while reading dictionary of LowCardinality.\n+            ///\n+            /// Example:\n+            /// Mark 0, points to [0, 8]\n+            /// Mark 1, points to [0, 8]\n+            /// Mark 2, points to [0, 8]\n+            /// Mark 3, points to [0, 8]\n+            /// Mark 4, points to [42336, 2255]\n+            /// Mark 5, points to [42336, 2255]  <--- for example need to read until 5\n+            /// Mark 6, points to [42336, 2255]  <--- not suitable, because have same offset\n+            /// Mark 7, points to [84995, 7738]  <--- next different mark\n+            /// Mark 8, points to [84995, 7738]\n+            /// Mark 9, points to [126531, 8637] <--- what we are looking for\n+\n+            auto indices = collections::range(right_mark, marks_count);\n+            auto next_different_mark = [&](auto lhs, auto rhs)\n+            {\n+                return marks_loader.getMark(lhs).asTuple() < marks_loader.getMark(rhs).asTuple();\n+            };\n+            auto it = std::upper_bound(indices.begin(), indices.end(), right_mark, std::move(next_different_mark));\n+\n+            if (it == indices.end())\n+                return file_size;\n+\n+            right_mark = *it;\n+        }\n+\n+        /// This is a good scenario. The compressed block is finished within the right mark,\n+        /// and previous mark was different.\n+        if (marks_loader.getMark(right_mark).offset_in_decompressed_block == 0\n+            && marks_loader.getMark(right_mark) != marks_loader.getMark(right_mark - 1))\n+            return marks_loader.getMark(right_mark).offset_in_compressed_file;\n+\n+        /// If right_mark has non-zero offset in decompressed block, we have to\n+        /// read its compressed block in a whole, because it may consist of data from previous granule.\n         ///\n         /// For example:\n-        /// Mark 10: (758287, 0)      <--- right_mark_included\n-        /// Mark 11: (908457, 53477)  <--- right_mark_non_included\n-        /// Mark 12: (1064746, 20742) <--- what we are looking for\n-        /// Mark 13: (2009333, 40123)\n+        /// Mark 6, points to [42336, 2255]\n+        /// Mark 7, points to [84995, 7738]  <--- right_mark\n+        /// Mark 8, points to [84995, 7738]\n+        /// Mark 9, points to [126531, 8637] <--- what we are looking for\n         ///\n-        /// Since mark 11 starts from offset in decompressed block 53477,\n-        /// it has some data from mark 10 and we have to read\n-        /// compressed block  [908457; 1064746 in a whole.\n-\n-        size_t right_mark_included = right_mark_non_included - 1;\n-        if (is_low_cardinality_dictionary || marks_loader.getMark(right_mark_non_included).offset_in_decompressed_block != 0)\n-            ++right_mark_included;\n+        /// Since mark 7 starts from offset in decompressed block 7738,\n+        /// it has some data from mark 6 and we have to read\n+        /// compressed block  [84995; 126531 in a whole.\n \n-        auto indices = collections::range(right_mark_included, marks_count);\n-        auto it = std::upper_bound(indices.begin(), indices.end(), right_mark_included,\n-            [&](auto lhs, auto rhs)\n-            {\n-                return marks_loader.getMark(lhs).offset_in_compressed_file < marks_loader.getMark(rhs).offset_in_compressed_file;\n-            });\n+        auto indices = collections::range(right_mark, marks_count);\n+        auto next_different_compressed_offset = [&](auto lhs, auto rhs)\n+        {\n+            return marks_loader.getMark(lhs).offset_in_compressed_file < marks_loader.getMark(rhs).offset_in_compressed_file;\n+        };\n+        auto it = std::upper_bound(indices.begin(), indices.end(), right_mark, std::move(next_different_compressed_offset));\n \n         if (it != indices.end())\n-            result_right_offset = marks_loader.getMark(*it).offset_in_compressed_file;\n-        else\n-            result_right_offset = file_size;\n+            return marks_loader.getMark(*it).offset_in_compressed_file;\n     }\n-    else if (right_mark_non_included == 0)\n-        result_right_offset = marks_loader.getMark(right_mark_non_included).offset_in_compressed_file;\n-    else\n-        result_right_offset = file_size;\n+    else if (right_mark == 0)\n+        return marks_loader.getMark(right_mark).offset_in_compressed_file;\n \n-    return result_right_offset;\n+    return file_size;\n }\n \n void MergeTreeReaderStream::seekToMark(size_t index)\ndiff --git a/src/Storages/MergeTree/MergeTreeReaderStream.h b/src/Storages/MergeTree/MergeTreeReaderStream.h\nindex 83e314eef428..f3785e175df3 100644\n--- a/src/Storages/MergeTree/MergeTreeReaderStream.h\n+++ b/src/Storages/MergeTree/MergeTreeReaderStream.h\n@@ -49,7 +49,7 @@ class MergeTreeReaderStream\n \n private:\n     void init();\n-    size_t getRightOffset(size_t right_mark_non_included);\n+    size_t getRightOffset(size_t right_mark);\n \n     const MergeTreeReaderSettings settings;\n     const ReadBufferFromFileBase::ProfileCallback profile_callback;\n",
  "test_patch": "diff --git a/tests/integration/test_s3_low_cardinality_right_border/test.py b/tests/integration/test_s3_low_cardinality_right_border/test.py\nindex 14476719c5fe..e54e6783b3d9 100644\n--- a/tests/integration/test_s3_low_cardinality_right_border/test.py\n+++ b/tests/integration/test_s3_low_cardinality_right_border/test.py\n@@ -132,3 +132,31 @@ def test_s3_right_border_2(started_cluster):\n     node1.query(\"optimize table s3_low_cardinality final\")\n     res = node1.query(\"select * from s3_low_cardinality where key = 9000\")\n     assert res == \"9000\\t9000\\n\"\n+\n+\n+def test_s3_right_border_3(started_cluster):\n+    node1.query(\"drop table if exists s3_low_cardinality\")\n+    node1.query(\n+        \"create table s3_low_cardinality (x LowCardinality(String)) engine = MergeTree order by tuple() settings min_bytes_for_wide_part=0, storage_policy = 's3', max_compress_block_size=10000\"\n+    )\n+    node1.query(\n+        \"insert into s3_low_cardinality select toString(number % 8000) || if(number < 8192 * 3, 'aaaaaaaaaaaaaaaa', if(number < 8192 * 6, 'bbbbbbbbbbbbbbbbbbbbbbbb', 'ccccccccccccccccccc')) from numbers(8192 * 9)\"\n+    )\n+    # Marks are:\n+    # Mark 0, points to 0, 8, has rows after 8192, decompressed size 0.\n+    # Mark 1, points to 0, 8, has rows after 8192, decompressed size 0.\n+    # Mark 2, points to 0, 8, has rows after 8192, decompressed size 0.\n+    # Mark 3, points to 0, 8, has rows after 8192, decompressed size 0.\n+    # Mark 4, points to 42336, 2255, has rows after 8192, decompressed size 0.\n+    # Mark 5, points to 42336, 2255, has rows after 8192, decompressed size 0.\n+    # Mark 6, points to 42336, 2255, has rows after 8192, decompressed size 0.\n+    # Mark 7, points to 84995, 7738, has rows after 8192, decompressed size 0.\n+    # Mark 8, points to 84995, 7738, has rows after 8192, decompressed size 0.\n+    # Mark 9, points to 126531, 8637, has rows after 0, decompressed size 0.\n+\n+    res = node1.query(\n+        \"select uniq(x) from s3_low_cardinality settings max_threads=2, merge_tree_min_rows_for_concurrent_read_for_remote_filesystem=1, merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem=1\"\n+    )\n+    # Reading ranges [0, 5) and [5, 9)\n+\n+    assert res == \"23999\\n\"\n",
  "problem_statement": "CANNOT_READ_ALL_DATA / LowCardinality /  S3 threadpool\n        @den-crane Thanks for the reply, we faced similar issue in few of our instances, where remote storage is S3. below is the stack trace. `operationName` column is of type LowCardinality.\r\n\r\n```\r\n2022.12.22 06:43:31.949698 [ 16873 ] {f33b0bd4-95db-4330-89d9-f18f24f3ac51} <Error> executeQuery: Code: 33. DB::Exception: Cannot read all data. Bytes read: 114. Bytes expected: 266.: (while reading column operationName): (while reading from part /var/lib/clickhouse/disks/s3_disk/store/961/961a395d-04ae-4f43-bf90-45a6c041b49e/1670889600_0_33677_2140/ from mark 26 with max_rows_to_read = 8192): While executing MergeTreeThread. (CANNOT_READ_ALL_DATA) (version 22.10.1.1877 (official build)) (from x.x.x.x:48908) (in query: SELECT operationName FROM <db>.<table_name> WHERE serviceName = 'xxx-xxx-xxx-xxx' GROUP BY operationName ORDER BY operationName LIMIT 10000), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xce3f35a in /usr/bin/clickhouse\r\n1. ? @ 0xce9e494 in /usr/bin/clickhouse\r\n2. ? @ 0x11a065b1 in /usr/bin/clickhouse\r\n3. DB::SerializationLowCardinality::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::__1::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >*) const @ 0x119e63e7 in /usr/bin/clickhouse\r\n4. DB::MergeTreeReaderWide::readData(DB::NameAndTypePair const&, std::__1::shared_ptr<DB::ISerialization const> const&, COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, bool, unsigned long, unsigned long, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >&, bool) @ 0x1322673b in /usr/bin/clickhouse\r\n5. DB::MergeTreeReaderWide::readRows(unsigned long, unsigned long, bool, unsigned long, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0x132259b8 in /usr/bin/clickhouse\r\n6. DB::MergeTreeRangeReader::DelayedStream::finalize(std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0x139167e3 in /usr/bin/clickhouse\r\n7. DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::__1::deque<DB::MarkRange, std::__1::allocator<DB::MarkRange> >&) @ 0x1391c4a9 in /usr/bin/clickhouse\r\n8. DB::MergeTreeRangeReader::read(unsigned long, std::__1::deque<DB::MarkRange, std::__1::allocator<DB::MarkRange> >&) @ 0x13919f95 in /usr/bin/clickhouse\r\n9. DB::MergeTreeBaseSelectProcessor::readFromPartImpl() @ 0x13911c2e in /usr/bin/clickhouse\r\n10. DB::MergeTreeBaseSelectProcessor::readFromPart() @ 0x139127b9 in /usr/bin/clickhouse\r\n11. DB::MergeTreeBaseSelectProcessor::generate() @ 0x1390de31 in /usr/bin/clickhouse\r\n12. DB::ISource::tryGenerate() @ 0x13590475 in /usr/bin/clickhouse\r\n13. DB::ISource::work() @ 0x13590006 in /usr/bin/clickhouse\r\n14. DB::ExecutionThreadContext::executeTask() @ 0x135ac186 in /usr/bin/clickhouse\r\n15. DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) @ 0x135a02dc in /usr/bin/clickhouse\r\n16. ? @ 0x135a293d in /usr/bin/clickhouse\r\n17. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xcefa04c in /usr/bin/clickhouse\r\n18. ? @ 0xceff7be in /usr/bin/clickhouse\r\n19. start_thread @ 0x7de5 in /lib64/libpthread-2.17.so\r\n20. __clone @ 0xfebad in /lib64/libc-2.17.so\r\n```\r\n\r\nAny idea/suggestions on this one? Clickhouse version: `22.10.1.1877`\r\n\r\n_Originally posted by @Dileep-Dora in https://github.com/ClickHouse/ClickHouse/issues/41756#issuecomment-1366388814_\r\n      \n",
  "hints_text": "Reading LowCardinality columns is able to cause CANNOT_READ_ALL_DATA if the part at S3 disk and `remote_filesystem_read_method=threadpool`\r\n\r\nSwitching to `remote_filesystem_read_method=read` fixes the issue.\r\n\r\nIt happens in very rare cases, seems need to create a special combination of uncompressed data.\r\n\r\n```sql\r\nCREATE TABLE bug_s3(e String, o Int64, f LowCardinality(String))\r\nENGINE = MergeTree ORDER BY (e,o) SETTINGS storage_policy = 's3_tiered'\r\n\r\nSELECT uniq(f) from bug_s3\r\nDB::Exception: Cannot read all data. Bytes read: 416. Bytes expected: 1191.: (while reading\r\n```\r\n\r\n```\r\n<Error> TCPHandler: Code: 33. DB::Exception: Cannot read all data. Bytes read: 416. Bytes expected: 1191.: (while reading column f): (while reading from part /var/lib/clickhouse/disks/s3_disk/store/372/37286f58-2fdf-4a95-8056-2e7e2e741977/all_1_6_2/ from mark 354 with max_rows_\r\nto_read = 65409): While executing MergeTreeThread. (CANNOT_READ_ALL_DATA), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(DB::Exception::MessageMasked const&, int, bool) @ 0xc56bd88 in /usr/bin/clickhouse\r\n1. ? @ 0x71fdabc in /usr/bin/clickhouse\r\n2. ? @ 0xc5be67c in /usr/bin/clickhouse\r\n3. ? @ 0x1084eab0 in /usr/bin/clickhouse\r\n4. DB::SerializationLowCardinality::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::__1::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::a\r\nllocator<char>>, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_trait\r\ns<char>, std::__1::allocator<char>> const, COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>>*) const @ 0x1083024c in /usr/bin/clickhouse\r\n5. DB::MergeTreeReaderWide::readData(DB::NameAndTypePair const&, std::__1::shared_ptr<DB::ISerialization const> const&, COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, bool, unsigned long, unsigned long, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, COW<DB::IColumn>::immutable\r\n_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, C\r\nOW<DB::IColumn>::immutable_ptr<DB::IColumn>>>>&, bool) @ 0x11c3f42c in /usr/bin/clickhouse\r\n6. DB::MergeTreeReaderWide::readRows(unsigned long, unsigned long, bool, unsigned long, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>&) @ 0x11c3e8e0 in /usr/bin/clickhouse\r\n7. DB::MergeTreeRangeReader::DelayedStream::finalize(std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn>>>&) @ 0x1232c568 in /usr/bin/clickhouse\r\n8. DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::__1::deque<DB::MarkRange, std::__1::allocator<DB::MarkRange>>&) @ 0x123318ec in /usr/bin/clickhouse\r\n9. DB::MergeTreeRangeReader::read(unsigned long, std::__1::deque<DB::MarkRange, std::__1::allocator<DB::MarkRange>>&) @ 0x1232f950 in /usr/bin/clickhouse\r\n10. DB::IMergeTreeSelectAlgorithm::readFromPartImpl() @ 0x12326b54 in /usr/bin/clickhouse\r\n11. DB::IMergeTreeSelectAlgorithm::read() @ 0x12324d90 in /usr/bin/clickhouse\r\n12. DB::MergeTreeSource::tryGenerate() @ 0x12348ed8 in /usr/bin/clickhouse\r\n13. DB::ISource::work() @ 0x11fe9010 in /usr/bin/clickhouse\r\n14. DB::ExecutionThreadContext::executeTask() @ 0x12000e00 in /usr/bin/clickhouse\r\n15. DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) @ 0x11ff6c6c in /usr/bin/clickhouse\r\n16. ? @ 0x11ff9468 in /usr/bin/clickhouse\r\n17. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xc60eaa8 in /usr/bin/clickhouse\r\n18. ? @ 0xc613608 in /usr/bin/clickhouse\r\n19. start_thread @ 0x7624 in /usr/lib/aarch64-linux-gnu/libpthread-2.31.so\r\n20. ? @ 0xd149c in /usr/lib/aarch64-linux-gnu/libc-2.31.so\r\n```\nVersion 22.10 has received patches after 22.10.1:\r\nhttps://github.com/ClickHouse/ClickHouse/blob/master/utils/list-versions/version_date.tsv\n@KochetovNicolai has a reproducer , it reproduces with master\r\n\r\nmy stacktrace is from 22.12.1.985.\n@den-crane `show create table`\r\n```CREATE TABLE db.table\r\n(\r\n    `time` Date,\r\n    `serviceName` LowCardinality(String),\r\n    `operationName` LowCardinality(String),\r\n    `count` UInt64\r\n)\r\nENGINE = ReplicatedSummingMergeTree('/clickhouse/tables/db/db.table/{shard}', '{replica}')\r\nPARTITION BY toStartOfInterval(time, toIntervalDay(1))\r\nORDER BY (serviceName, operationName, time)\r\nTTL toDateTime(time) + toIntervalDay(30)\r\nSETTINGS index_granularity = 8192\r\n```\r\n\r\nWe're inserting data into this table using a MaterializedView\n@den-crane Please make a pull request with the failing test case.\n@ Dileep-Dora Right, I think your issue is exactly this issue. \n> @den-crane Please make a pull request with the failing test case.\r\n\r\nI will not. I have reproducer only with sensitive data.\nThanks for the confirmation @den-crane , so what do you suggest here continue with `remote_filesystem_read_method=read` option or wait for the fix?\r\n\r\nif second case any ETA on the fix for this?",
  "created_at": "2023-01-03T18:22:35Z",
  "modified_files": [
    "src/Formats/MarkInCompressedFile.h",
    "src/Storages/MergeTree/MergeTreeReaderStream.cpp",
    "src/Storages/MergeTree/MergeTreeReaderStream.h"
  ],
  "modified_test_files": [
    "tests/integration/test_s3_low_cardinality_right_border/test.py"
  ]
}