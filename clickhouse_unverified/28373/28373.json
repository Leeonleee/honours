{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 28373,
  "instance_id": "ClickHouse__ClickHouse-28373",
  "issue_numbers": [
    "8004",
    "15170"
  ],
  "base_commit": "2bf47bb0ba2c79294ad63f721f2c9948c4eab6d0",
  "patch": "diff --git a/programs/local/LocalServer.cpp b/programs/local/LocalServer.cpp\nindex d2661874beb9..99197f42f25d 100644\n--- a/programs/local/LocalServer.cpp\n+++ b/programs/local/LocalServer.cpp\n@@ -306,6 +306,7 @@ try\n         attachInformationSchema(global_context, *createMemoryDatabaseIfNotExists(global_context, DatabaseCatalog::INFORMATION_SCHEMA));\n         attachInformationSchema(global_context, *createMemoryDatabaseIfNotExists(global_context, DatabaseCatalog::INFORMATION_SCHEMA_UPPERCASE));\n         loadMetadata(global_context);\n+        startupSystemTables();\n         DatabaseCatalog::instance().loadDatabases();\n         LOG_DEBUG(log, \"Loaded metadata.\");\n     }\ndiff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex 2d09495c3384..befce98f30ff 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -1108,6 +1108,7 @@ if (ThreadFuzzer::instance().isEffective())\n         database_catalog.loadMarkedAsDroppedTables();\n         /// Then, load remaining databases\n         loadMetadata(global_context, default_database);\n+        startupSystemTables();\n         database_catalog.loadDatabases();\n         /// After loading validate that default database exists\n         database_catalog.assertDatabaseExists(default_database);\ndiff --git a/src/Backups/renameInCreateQuery.cpp b/src/Backups/renameInCreateQuery.cpp\nindex a36995654ee6..4c78844d2662 100644\n--- a/src/Backups/renameInCreateQuery.cpp\n+++ b/src/Backups/renameInCreateQuery.cpp\n@@ -160,26 +160,29 @@ namespace\n             if (args.size() <= db_name_index)\n                 return;\n \n-            String db_name = evaluateConstantExpressionForDatabaseName(args[db_name_index], data.context)->as<ASTLiteral &>().value.safeGet<String>();\n+            String name = evaluateConstantExpressionForDatabaseName(args[db_name_index], data.context)->as<ASTLiteral &>().value.safeGet<String>();\n \n-            String table_name;\n             size_t table_name_index = static_cast<size_t>(-1);\n-            size_t dot = String::npos;\n-            if (function.name != \"Distributed\")\n-                dot = db_name.find('.');\n-            if (dot != String::npos)\n-            {\n-                table_name = db_name.substr(dot + 1);\n-                db_name.resize(dot);\n-            }\n+\n+            QualifiedTableName qualified_name;\n+\n+            if (function.name == \"Distributed\")\n+                qualified_name.table = name;\n             else\n+                qualified_name = QualifiedTableName::parseFromString(name);\n+\n+            if (qualified_name.database.empty())\n             {\n+                std::swap(qualified_name.database, qualified_name.table);\n                 table_name_index = 2;\n                 if (args.size() <= table_name_index)\n                     return;\n-                table_name = evaluateConstantExpressionForDatabaseName(args[table_name_index], data.context)->as<ASTLiteral &>().value.safeGet<String>();\n+                qualified_name.table = evaluateConstantExpressionForDatabaseName(args[table_name_index], data.context)->as<ASTLiteral &>().value.safeGet<String>();\n             }\n \n+            const String & db_name = qualified_name.database;\n+            const String & table_name = qualified_name.table;\n+\n             if (db_name.empty() || table_name.empty())\n                 return;\n \ndiff --git a/src/Core/QualifiedTableName.h b/src/Core/QualifiedTableName.h\nindex 453d55d85c72..c1cb9b27d15a 100644\n--- a/src/Core/QualifiedTableName.h\n+++ b/src/Core/QualifiedTableName.h\n@@ -2,11 +2,20 @@\n \n #include <string>\n #include <tuple>\n+#include <optional>\n+#include <Common/Exception.h>\n #include <Common/SipHash.h>\n+#include <Common/quoteString.h>\n+#include <fmt/format.h>\n \n namespace DB\n {\n \n+namespace ErrorCodes\n+{\n+extern const int SYNTAX_ERROR;\n+}\n+\n //TODO replace with StorageID\n struct QualifiedTableName\n {\n@@ -30,6 +39,46 @@ struct QualifiedTableName\n         hash_state.update(table.data(), table.size());\n         return hash_state.get64();\n     }\n+\n+    /// NOTE: It's different from compound identifier parsing and does not support escaping and dots in name.\n+    /// Usually it's better to use ParserIdentifier instead,\n+    /// but we parse DDL dictionary name (and similar things) this way for historical reasons.\n+    static std::optional<QualifiedTableName> tryParseFromString(const String & maybe_qualified_name)\n+    {\n+        if (maybe_qualified_name.empty())\n+            return {};\n+\n+        /// Do not allow dot at the beginning and at the end\n+        auto pos = maybe_qualified_name.find('.');\n+        if (pos == 0 || pos == (maybe_qualified_name.size() - 1))\n+            return {};\n+\n+        QualifiedTableName name;\n+        if (pos == std::string::npos)\n+        {\n+            name.table = std::move(maybe_qualified_name);\n+        }\n+        else if (maybe_qualified_name.find('.', pos + 1) != std::string::npos)\n+        {\n+            /// Do not allow multiple dots\n+            return {};\n+        }\n+        else\n+        {\n+            name.database = maybe_qualified_name.substr(0, pos);\n+            name.table = maybe_qualified_name.substr(pos + 1);\n+        }\n+\n+        return name;\n+    }\n+\n+    static QualifiedTableName parseFromString(const String & maybe_qualified_name)\n+    {\n+        auto name = tryParseFromString(maybe_qualified_name);\n+        if (!name)\n+            throw Exception(ErrorCodes::SYNTAX_ERROR, \"Invalid qualified name: {}\", maybe_qualified_name);\n+        return *name;\n+    }\n };\n \n }\n@@ -47,5 +96,23 @@ template <> struct hash<DB::QualifiedTableName>\n         return qualified_table.hash();\n     }\n };\n+}\n \n+namespace fmt\n+{\n+    template <>\n+    struct formatter<DB::QualifiedTableName>\n+    {\n+        constexpr auto parse(format_parse_context & ctx)\n+        {\n+            return ctx.begin();\n+        }\n+\n+        template <typename FormatContext>\n+        auto format(const DB::QualifiedTableName & name, FormatContext & ctx)\n+        {\n+            return format_to(ctx.out(), \"{}.{}\", DB::backQuoteIfNeed(name.database), DB::backQuoteIfNeed(name.table));\n+        }\n+    };\n }\n+\ndiff --git a/src/Databases/DDLDependencyVisitor.cpp b/src/Databases/DDLDependencyVisitor.cpp\nnew file mode 100644\nindex 000000000000..0399ec59b161\n--- /dev/null\n+++ b/src/Databases/DDLDependencyVisitor.cpp\n@@ -0,0 +1,103 @@\n+#include <Databases/DDLDependencyVisitor.h>\n+#include <Parsers/ASTFunction.h>\n+#include <Parsers/ASTCreateQuery.h>\n+#include <Parsers/ASTLiteral.h>\n+#include <Parsers/ASTIdentifier.h>\n+#include <Dictionaries/getDictionaryConfigurationFromAST.h>\n+#include <Poco/String.h>\n+\n+namespace DB\n+{\n+\n+void DDLDependencyVisitor::visit(const ASTPtr & ast, Data & data)\n+{\n+    /// Looking for functions in column default expressions and dictionary source definition\n+    if (const auto * function = ast->as<ASTFunction>())\n+        visit(*function, data);\n+    else if (const auto * dict_source = ast->as<ASTFunctionWithKeyValueArguments>())\n+        visit(*dict_source, data);\n+}\n+\n+bool DDLDependencyVisitor::needChildVisit(const ASTPtr & node, const ASTPtr & /*child*/)\n+{\n+    return !node->as<ASTStorage>();\n+}\n+\n+void DDLDependencyVisitor::visit(const ASTFunction & function, Data & data)\n+{\n+    if (function.name == \"joinGet\" ||\n+        function.name == \"dictHas\" ||\n+        function.name == \"dictIsIn\" ||\n+        function.name.starts_with(\"dictGet\"))\n+    {\n+        extractTableNameFromArgument(function, data, 0);\n+    }\n+    else if (Poco::toLower(function.name) == \"in\")\n+    {\n+        extractTableNameFromArgument(function, data, 1);\n+    }\n+\n+}\n+\n+void DDLDependencyVisitor::visit(const ASTFunctionWithKeyValueArguments & dict_source, Data & data)\n+{\n+    if (dict_source.name != \"clickhouse\")\n+        return;\n+    if (!dict_source.elements)\n+        return;\n+\n+    auto config = getDictionaryConfigurationFromAST(data.create_query->as<ASTCreateQuery &>(), data.global_context);\n+    auto info = getInfoIfClickHouseDictionarySource(config, data.global_context);\n+\n+    if (!info || !info->is_local)\n+        return;\n+\n+    if (info->table_name.database.empty())\n+        info->table_name.database = data.default_database;\n+    data.dependencies.emplace(std::move(info->table_name));\n+}\n+\n+\n+void DDLDependencyVisitor::extractTableNameFromArgument(const ASTFunction & function, Data & data, size_t arg_idx)\n+{\n+    /// Just ignore incorrect arguments, proper exception will be thrown later\n+    if (!function.arguments || function.arguments->children.size() <= arg_idx)\n+        return;\n+\n+    QualifiedTableName qualified_name;\n+\n+    const auto * arg = function.arguments->as<ASTExpressionList>()->children[arg_idx].get();\n+    if (const auto * literal = arg->as<ASTLiteral>())\n+    {\n+        if (literal->value.getType() != Field::Types::String)\n+            return;\n+\n+        auto maybe_qualified_name = QualifiedTableName::tryParseFromString(literal->value.get<String>());\n+        /// Just return if name if invalid\n+        if (!maybe_qualified_name)\n+            return;\n+\n+        qualified_name = std::move(*maybe_qualified_name);\n+    }\n+    else if (const auto * identifier = arg->as<ASTIdentifier>())\n+    {\n+        auto table_identifier = identifier->createTable();\n+        /// Just return if table identified is invalid\n+        if (!table_identifier)\n+            return;\n+\n+        qualified_name.database = table_identifier->getDatabaseName();\n+        qualified_name.table = table_identifier->shortName();\n+    }\n+    else\n+    {\n+        assert(false);\n+        return;\n+    }\n+\n+    if (qualified_name.database.empty())\n+        qualified_name.database = data.default_database;\n+    data.dependencies.emplace(std::move(qualified_name));\n+}\n+\n+}\ndiff --git a/src/Databases/DDLDependencyVisitor.h b/src/Databases/DDLDependencyVisitor.h\nnew file mode 100644\nindex 000000000000..c0b39d70b081\n--- /dev/null\n+++ b/src/Databases/DDLDependencyVisitor.h\n@@ -0,0 +1,42 @@\n+#pragma once\n+#include <Core/QualifiedTableName.h>\n+#include <Parsers/IAST_fwd.h>\n+#include <Interpreters/InDepthNodeVisitor.h>\n+\n+namespace DB\n+{\n+\n+class ASTFunction;\n+class ASTFunctionWithKeyValueArguments;\n+\n+/// Visits ASTCreateQuery and extracts names of table (or dictionary) dependencies\n+/// from column default expressions (joinGet, dictGet, etc)\n+/// or dictionary source (for dictionaries from local ClickHouse table).\n+/// Does not validate AST, works a best-effort way.\n+class DDLDependencyVisitor\n+{\n+public:\n+    struct Data\n+    {\n+        using TableNamesSet = std::set<QualifiedTableName>;\n+        String default_database;\n+        TableNamesSet dependencies;\n+        ContextPtr global_context;\n+        ASTPtr create_query;\n+    };\n+\n+    using Visitor = ConstInDepthNodeVisitor<DDLDependencyVisitor, true>;\n+\n+    static void visit(const ASTPtr & ast, Data & data);\n+    static bool needChildVisit(const ASTPtr & node, const ASTPtr & child);\n+\n+private:\n+    static void visit(const ASTFunction & function, Data & data);\n+    static void visit(const ASTFunctionWithKeyValueArguments & dict_source, Data & data);\n+\n+    static void extractTableNameFromArgument(const ASTFunction & function, Data & data, size_t arg_idx);\n+};\n+\n+using TableLoadingDependenciesVisitor = DDLDependencyVisitor::Visitor;\n+\n+}\ndiff --git a/src/Databases/DatabaseAtomic.cpp b/src/Databases/DatabaseAtomic.cpp\nindex 2dbcd652004b..5c75f6f1036b 100644\n--- a/src/Databases/DatabaseAtomic.cpp\n+++ b/src/Databases/DatabaseAtomic.cpp\n@@ -416,38 +416,47 @@ UUID DatabaseAtomic::tryGetTableUUID(const String & table_name) const\n     return UUIDHelpers::Nil;\n }\n \n-void DatabaseAtomic::loadStoredObjects(\n-    ContextMutablePtr local_context, bool has_force_restore_data_flag, bool force_attach, bool skip_startup_tables)\n+void DatabaseAtomic::beforeLoadingMetadata(ContextMutablePtr /*context*/, bool force_restore, bool /*force_attach*/)\n {\n+    if (!force_restore)\n+        return;\n+\n     /// Recreate symlinks to table data dirs in case of force restore, because some of them may be broken\n-    if (has_force_restore_data_flag)\n+    for (const auto & table_path : fs::directory_iterator(path_to_table_symlinks))\n     {\n-        for (const auto & table_path : fs::directory_iterator(path_to_table_symlinks))\n+        if (!fs::is_symlink(table_path))\n         {\n-            if (!fs::is_symlink(table_path))\n-            {\n-                throw Exception(ErrorCodes::ABORTED,\n-                    \"'{}' is not a symlink. Atomic database should contains only symlinks.\", std::string(table_path.path()));\n-            }\n-\n-            fs::remove(table_path);\n+            throw Exception(ErrorCodes::ABORTED,\n+                \"'{}' is not a symlink. Atomic database should contains only symlinks.\", std::string(table_path.path()));\n         }\n+\n+        fs::remove(table_path);\n     }\n+}\n \n-    DatabaseOrdinary::loadStoredObjects(local_context, has_force_restore_data_flag, force_attach, skip_startup_tables);\n+void DatabaseAtomic::loadStoredObjects(\n+    ContextMutablePtr local_context, bool force_restore, bool force_attach, bool skip_startup_tables)\n+{\n+    beforeLoadingMetadata(local_context, force_restore, force_attach);\n+    DatabaseOrdinary::loadStoredObjects(local_context, force_restore, force_attach, skip_startup_tables);\n+}\n \n-    if (has_force_restore_data_flag)\n-    {\n-        NameToPathMap table_names;\n-        {\n-            std::lock_guard lock{mutex};\n-            table_names = table_name_to_path;\n-        }\n+void DatabaseAtomic::startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach)\n+{\n+    DatabaseOrdinary::startupTables(thread_pool, force_restore, force_attach);\n \n-        fs::create_directories(path_to_table_symlinks);\n-        for (const auto & table : table_names)\n-            tryCreateSymlink(table.first, table.second, true);\n+    if (!force_restore)\n+        return;\n+\n+    NameToPathMap table_names;\n+    {\n+        std::lock_guard lock{mutex};\n+        table_names = table_name_to_path;\n     }\n+\n+    fs::create_directories(path_to_table_symlinks);\n+    for (const auto & table : table_names)\n+        tryCreateSymlink(table.first, table.second, true);\n }\n \n void DatabaseAtomic::tryCreateSymlink(const String & table_name, const String & actual_data_path, bool if_data_path_exist)\ndiff --git a/src/Databases/DatabaseAtomic.h b/src/Databases/DatabaseAtomic.h\nindex 8be009cd6ca4..1fe13f8b27fc 100644\n--- a/src/Databases/DatabaseAtomic.h\n+++ b/src/Databases/DatabaseAtomic.h\n@@ -47,7 +47,11 @@ class DatabaseAtomic : public DatabaseOrdinary\n \n     DatabaseTablesIteratorPtr getTablesIterator(ContextPtr context, const FilterByNameFunction & filter_by_table_name) const override;\n \n-    void loadStoredObjects(ContextMutablePtr context, bool has_force_restore_data_flag, bool force_attach, bool skip_startup_tables) override;\n+    void loadStoredObjects(ContextMutablePtr context, bool force_restore, bool force_attach, bool skip_startup_tables) override;\n+\n+    void beforeLoadingMetadata(ContextMutablePtr context, bool force_restore, bool force_attach) override;\n+\n+    void startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach) override;\n \n     /// Atomic database cannot be detached if there is detached table which still in use\n     void assertCanBeDetached(bool cleanup) override;\ndiff --git a/src/Databases/DatabaseLazy.cpp b/src/Databases/DatabaseLazy.cpp\nindex 7e0e1b7aa433..384c5ff47dd6 100644\n--- a/src/Databases/DatabaseLazy.cpp\n+++ b/src/Databases/DatabaseLazy.cpp\n@@ -36,7 +36,7 @@ DatabaseLazy::DatabaseLazy(const String & name_, const String & metadata_path_,\n \n \n void DatabaseLazy::loadStoredObjects(\n-    ContextMutablePtr local_context, bool /* has_force_restore_data_flag */, bool /*force_attach*/, bool /* skip_startup_tables */)\n+    ContextMutablePtr local_context, bool /* force_restore */, bool /*force_attach*/, bool /* skip_startup_tables */)\n {\n     iterateMetadataFiles(local_context, [this](const String & file_name)\n     {\ndiff --git a/src/Databases/DatabaseLazy.h b/src/Databases/DatabaseLazy.h\nindex bc79a49b2fec..45c816c2e762 100644\n--- a/src/Databases/DatabaseLazy.h\n+++ b/src/Databases/DatabaseLazy.h\n@@ -26,7 +26,7 @@ class DatabaseLazy final : public DatabaseOnDisk\n \n     bool canContainDistributedTables() const override { return false; }\n \n-    void loadStoredObjects(ContextMutablePtr context, bool has_force_restore_data_flag, bool force_attach, bool skip_startup_tables) override;\n+    void loadStoredObjects(ContextMutablePtr context, bool force_restore, bool force_attach, bool skip_startup_tables) override;\n \n     void createTable(\n         ContextPtr context,\ndiff --git a/src/Databases/DatabaseOnDisk.cpp b/src/Databases/DatabaseOnDisk.cpp\nindex 620e560b64cd..40edeb5cd27f 100644\n--- a/src/Databases/DatabaseOnDisk.cpp\n+++ b/src/Databases/DatabaseOnDisk.cpp\n@@ -46,7 +46,7 @@ std::pair<String, StoragePtr> createTableFromAST(\n     const String & database_name,\n     const String & table_data_path_relative,\n     ContextMutablePtr context,\n-    bool has_force_restore_data_flag)\n+    bool force_restore)\n {\n     ast_create_query.attach = true;\n     ast_create_query.database = database_name;\n@@ -88,7 +88,7 @@ std::pair<String, StoragePtr> createTableFromAST(\n             context->getGlobalContext(),\n             columns,\n             constraints,\n-            has_force_restore_data_flag)\n+            force_restore)\n     };\n }\n \ndiff --git a/src/Databases/DatabaseOnDisk.h b/src/Databases/DatabaseOnDisk.h\nindex e7dda7cb36bc..74056d887aef 100644\n--- a/src/Databases/DatabaseOnDisk.h\n+++ b/src/Databases/DatabaseOnDisk.h\n@@ -16,7 +16,7 @@ std::pair<String, StoragePtr> createTableFromAST(\n     const String & database_name,\n     const String & table_data_path_relative,\n     ContextMutablePtr context,\n-    bool has_force_restore_data_flag);\n+    bool force_restore);\n \n /** Get the string with the table definition based on the CREATE query.\n   * It is an ATTACH query that you can execute to create a table from the correspondent database.\ndiff --git a/src/Databases/DatabaseOrdinary.cpp b/src/Databases/DatabaseOrdinary.cpp\nindex bfe5de4c95fb..1bdb273c9fb6 100644\n--- a/src/Databases/DatabaseOrdinary.cpp\n+++ b/src/Databases/DatabaseOrdinary.cpp\n@@ -4,6 +4,8 @@\n #include <Databases/DatabaseOnDisk.h>\n #include <Databases/DatabaseOrdinary.h>\n #include <Databases/DatabasesCommon.h>\n+#include <Databases/DDLDependencyVisitor.h>\n+#include <Databases/TablesLoader.h>\n #include <IO/ReadBufferFromFile.h>\n #include <IO/ReadHelpers.h>\n #include <IO/WriteBufferFromFile.h>\n@@ -27,8 +29,6 @@ namespace fs = std::filesystem;\n \n namespace DB\n {\n-static constexpr size_t PRINT_MESSAGE_EACH_N_OBJECTS = 256;\n-static constexpr size_t PRINT_MESSAGE_EACH_N_SECONDS = 5;\n static constexpr size_t METADATA_FILE_BUFFER_SIZE = 32768;\n \n namespace\n@@ -39,7 +39,7 @@ namespace\n         DatabaseOrdinary & database,\n         const String & database_name,\n         const String & metadata_path,\n-        bool has_force_restore_data_flag)\n+        bool force_restore)\n     {\n         try\n         {\n@@ -48,7 +48,7 @@ namespace\n                 database_name,\n                 database.getTableDataPath(query),\n                 context,\n-                has_force_restore_data_flag);\n+                force_restore);\n \n             database.attachTable(table_name, table, database.getTableDataPath(query));\n         }\n@@ -60,15 +60,6 @@ namespace\n             throw;\n         }\n     }\n-\n-    void logAboutProgress(Poco::Logger * log, size_t processed, size_t total, AtomicStopwatch & watch)\n-    {\n-        if (processed % PRINT_MESSAGE_EACH_N_OBJECTS == 0 || watch.compareAndRestart(PRINT_MESSAGE_EACH_N_SECONDS))\n-        {\n-            LOG_INFO(log, \"{}%\", processed * 100.0 / total);\n-            watch.restart();\n-        }\n-    }\n }\n \n \n@@ -84,63 +75,20 @@ DatabaseOrdinary::DatabaseOrdinary(\n }\n \n void DatabaseOrdinary::loadStoredObjects(\n-    ContextMutablePtr local_context, bool has_force_restore_data_flag, bool /*force_attach*/, bool skip_startup_tables)\n+    ContextMutablePtr local_context, bool force_restore, bool force_attach, bool skip_startup_tables)\n {\n     /** Tables load faster if they are loaded in sorted (by name) order.\n       * Otherwise (for the ext4 filesystem), `DirectoryIterator` iterates through them in some order,\n       *  which does not correspond to order tables creation and does not correspond to order of their location on disk.\n       */\n-    using FileNames = std::map<std::string, ASTPtr>;\n-    std::mutex file_names_mutex;\n-    FileNames file_names;\n-\n-    size_t total_dictionaries = 0;\n-\n-    auto process_metadata = [&file_names, &total_dictionaries, &file_names_mutex, this](\n-                                const String & file_name)\n-    {\n-        fs::path path(getMetadataPath());\n-        fs::path file_path(file_name);\n-        fs::path full_path = path / file_path;\n-\n-        try\n-        {\n-            auto ast = parseQueryFromMetadata(log, getContext(), full_path.string(), /*throw_on_error*/ true, /*remove_empty*/ false);\n-            if (ast)\n-            {\n-                auto * create_query = ast->as<ASTCreateQuery>();\n-                create_query->database = database_name;\n-\n-                if (fs::exists(full_path.string() + detached_suffix))\n-                {\n-                    /// FIXME: even if we don't load the table we can still mark the uuid of it as taken.\n-                    /// if (create_query->uuid != UUIDHelpers::Nil)\n-                    ///     DatabaseCatalog::instance().addUUIDMapping(create_query->uuid);\n-\n-                    const std::string table_name = file_name.substr(0, file_name.size() - 4);\n-                    LOG_DEBUG(log, \"Skipping permanently detached table {}.\", backQuote(table_name));\n-                    return;\n-                }\n-\n-                std::lock_guard lock{file_names_mutex};\n-                file_names[file_name] = ast;\n-                total_dictionaries += create_query->is_dictionary;\n-            }\n-        }\n-        catch (Exception & e)\n-        {\n-            e.addMessage(\"Cannot parse definition from metadata file \" + full_path.string());\n-            throw;\n-        }\n-    };\n \n-    iterateMetadataFiles(local_context, process_metadata);\n-\n-    size_t total_tables = file_names.size() - total_dictionaries;\n+    ParsedTablesMetadata metadata;\n+    loadTablesMetadata(local_context, metadata);\n \n-    LOG_INFO(log, \"Total {} tables and {} dictionaries.\", total_tables, total_dictionaries);\n+    size_t total_tables = metadata.parsed_tables.size() - metadata.total_dictionaries;\n \n     AtomicStopwatch watch;\n+    std::atomic<size_t> dictionaries_processed{0};\n     std::atomic<size_t> tables_processed{0};\n \n     ThreadPool pool;\n@@ -153,24 +101,21 @@ void DatabaseOrdinary::loadStoredObjects(\n     /// loading of its config only, it doesn't involve loading the dictionary itself.\n \n     /// Attach dictionaries.\n-    for (const auto & name_with_query : file_names)\n+    for (const auto & name_with_path_and_query : metadata.parsed_tables)\n     {\n-        const auto & create_query = name_with_query.second->as<const ASTCreateQuery &>();\n+        const auto & name = name_with_path_and_query.first;\n+        const auto & path = name_with_path_and_query.second.path;\n+        const auto & ast = name_with_path_and_query.second.ast;\n+        const auto & create_query = ast->as<const ASTCreateQuery &>();\n \n         if (create_query.is_dictionary)\n         {\n             pool.scheduleOrThrowOnError([&]()\n             {\n-                tryAttachTable(\n-                    local_context,\n-                    create_query,\n-                    *this,\n-                    database_name,\n-                    getMetadataPath() + name_with_query.first,\n-                    has_force_restore_data_flag);\n+                loadTableFromMetadata(local_context, path, name, ast, force_restore);\n \n                 /// Messages, so that it's not boring to wait for the server to load for a long time.\n-                logAboutProgress(log, ++tables_processed, total_tables, watch);\n+                logAboutProgress(log, ++dictionaries_processed, metadata.total_dictionaries, watch);\n             });\n         }\n     }\n@@ -178,21 +123,18 @@ void DatabaseOrdinary::loadStoredObjects(\n     pool.wait();\n \n     /// Attach tables.\n-    for (const auto & name_with_query : file_names)\n+    for (const auto & name_with_path_and_query : metadata.parsed_tables)\n     {\n-        const auto & create_query = name_with_query.second->as<const ASTCreateQuery &>();\n+        const auto & name = name_with_path_and_query.first;\n+        const auto & path = name_with_path_and_query.second.path;\n+        const auto & ast = name_with_path_and_query.second.ast;\n+        const auto & create_query = ast->as<const ASTCreateQuery &>();\n \n         if (!create_query.is_dictionary)\n         {\n             pool.scheduleOrThrowOnError([&]()\n             {\n-                tryAttachTable(\n-                    local_context,\n-                    create_query,\n-                    *this,\n-                    database_name,\n-                    getMetadataPath() + name_with_query.first,\n-                    has_force_restore_data_flag);\n+                loadTableFromMetadata(local_context, path, name, ast, force_restore);\n \n                 /// Messages, so that it's not boring to wait for the server to load for a long time.\n                 logAboutProgress(log, ++tables_processed, total_tables, watch);\n@@ -205,17 +147,97 @@ void DatabaseOrdinary::loadStoredObjects(\n     if (!skip_startup_tables)\n     {\n         /// After all tables was basically initialized, startup them.\n-        startupTablesImpl(pool);\n+        startupTables(pool, force_restore, force_attach);\n     }\n }\n \n-void DatabaseOrdinary::startupTables()\n+void DatabaseOrdinary::loadTablesMetadata(ContextPtr local_context, ParsedTablesMetadata & metadata)\n {\n-    ThreadPool pool;\n-    startupTablesImpl(pool);\n+    size_t prev_tables_count = metadata.parsed_tables.size();\n+    size_t prev_total_dictionaries = metadata.total_dictionaries;\n+\n+    auto process_metadata = [&metadata, this](const String & file_name)\n+    {\n+        fs::path path(getMetadataPath());\n+        fs::path file_path(file_name);\n+        fs::path full_path = path / file_path;\n+\n+        try\n+        {\n+            auto ast = parseQueryFromMetadata(log, getContext(), full_path.string(), /*throw_on_error*/ true, /*remove_empty*/ false);\n+            if (ast)\n+            {\n+                auto * create_query = ast->as<ASTCreateQuery>();\n+                create_query->database = database_name;\n+\n+                if (fs::exists(full_path.string() + detached_suffix))\n+                {\n+                    /// FIXME: even if we don't load the table we can still mark the uuid of it as taken.\n+                    /// if (create_query->uuid != UUIDHelpers::Nil)\n+                    ///     DatabaseCatalog::instance().addUUIDMapping(create_query->uuid);\n+\n+                    const std::string table_name = file_name.substr(0, file_name.size() - 4);\n+                    LOG_DEBUG(log, \"Skipping permanently detached table {}.\", backQuote(table_name));\n+                    return;\n+                }\n+\n+                TableLoadingDependenciesVisitor::Data data;\n+                data.default_database = metadata.default_database;\n+                data.create_query = ast;\n+                data.global_context = getContext();\n+                TableLoadingDependenciesVisitor visitor{data};\n+                visitor.visit(ast);\n+                QualifiedTableName qualified_name{database_name, create_query->table};\n+\n+                std::lock_guard lock{metadata.mutex};\n+                metadata.parsed_tables[qualified_name] = ParsedTableMetadata{full_path.string(), ast};\n+                if (data.dependencies.empty())\n+                {\n+                    metadata.independent_database_objects.emplace_back(std::move(qualified_name));\n+                }\n+                else\n+                {\n+                    for (const auto & dependency : data.dependencies)\n+                    {\n+                        metadata.dependencies_info[dependency].dependent_database_objects.push_back(qualified_name);\n+                        ++metadata.dependencies_info[qualified_name].dependencies_count;\n+                    }\n+                }\n+                metadata.total_dictionaries += create_query->is_dictionary;\n+            }\n+        }\n+        catch (Exception & e)\n+        {\n+            e.addMessage(\"Cannot parse definition from metadata file \" + full_path.string());\n+            throw;\n+        }\n+    };\n+\n+    iterateMetadataFiles(local_context, process_metadata);\n+\n+    size_t objects_in_database = metadata.parsed_tables.size() - prev_tables_count;\n+    size_t dictionaries_in_database = metadata.total_dictionaries - prev_total_dictionaries;\n+    size_t tables_in_database = objects_in_database - dictionaries_in_database;\n+\n+    LOG_INFO(log, \"Metadata processed, database {} has {} tables and {} dictionaries in total.\",\n+             database_name, tables_in_database, dictionaries_in_database);\n+}\n+\n+void DatabaseOrdinary::loadTableFromMetadata(ContextMutablePtr local_context, const String & file_path, const QualifiedTableName & name, const ASTPtr & ast, bool force_restore)\n+{\n+    assert(name.database == database_name);\n+    const auto & create_query = ast->as<const ASTCreateQuery &>();\n+\n+    tryAttachTable(\n+        local_context,\n+        create_query,\n+        *this,\n+        name.database,\n+        file_path,\n+        force_restore);\n }\n \n-void DatabaseOrdinary::startupTablesImpl(ThreadPool & thread_pool)\n+void DatabaseOrdinary::startupTables(ThreadPool & thread_pool, bool /*force_restore*/, bool /*force_attach*/)\n {\n     LOG_INFO(log, \"Starting up tables.\");\n \n@@ -240,6 +262,7 @@ void DatabaseOrdinary::startupTablesImpl(ThreadPool & thread_pool)\n     }\n     catch (...)\n     {\n+        /// We have to wait for jobs to finish here, because job function has reference to variables on the stack of current thread.\n         thread_pool.wait();\n         throw;\n     }\ndiff --git a/src/Databases/DatabaseOrdinary.h b/src/Databases/DatabaseOrdinary.h\nindex 7832377ccae8..5f6d9a303859 100644\n--- a/src/Databases/DatabaseOrdinary.h\n+++ b/src/Databases/DatabaseOrdinary.h\n@@ -20,9 +20,15 @@ class DatabaseOrdinary : public DatabaseOnDisk\n \n     String getEngineName() const override { return \"Ordinary\"; }\n \n-    void loadStoredObjects(ContextMutablePtr context, bool has_force_restore_data_flag, bool force_attach, bool skip_startup_tables) override;\n+    void loadStoredObjects(ContextMutablePtr context, bool force_restore, bool force_attach, bool skip_startup_tables) override;\n \n-    void startupTables() override;\n+    bool supportsLoadingInTopologicalOrder() const override { return true; }\n+\n+    void loadTablesMetadata(ContextPtr context, ParsedTablesMetadata & metadata) override;\n+\n+    void loadTableFromMetadata(ContextMutablePtr local_context, const String & file_path, const QualifiedTableName & name, const ASTPtr & ast, bool force_restore) override;\n+\n+    void startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach) override;\n \n     void alterTable(\n         ContextPtr context,\n@@ -36,8 +42,6 @@ class DatabaseOrdinary : public DatabaseOnDisk\n         const String & table_metadata_path,\n         const String & statement,\n         ContextPtr query_context);\n-\n-    void startupTablesImpl(ThreadPool & thread_pool);\n };\n \n }\ndiff --git a/src/Databases/DatabaseReplicated.cpp b/src/Databases/DatabaseReplicated.cpp\nindex da03eb6aba6e..c2ff002ea36b 100644\n--- a/src/Databases/DatabaseReplicated.cpp\n+++ b/src/Databases/DatabaseReplicated.cpp\n@@ -305,13 +305,21 @@ void DatabaseReplicated::createReplicaNodesInZooKeeper(const zkutil::ZooKeeperPt\n     createEmptyLogEntry(current_zookeeper);\n }\n \n-void DatabaseReplicated::loadStoredObjects(\n-    ContextMutablePtr local_context, bool has_force_restore_data_flag, bool force_attach, bool skip_startup_tables)\n+void DatabaseReplicated::beforeLoadingMetadata(ContextMutablePtr /*context*/, bool /*force_restore*/, bool force_attach)\n {\n     tryConnectToZooKeeperAndInitDatabase(force_attach);\n+}\n \n-    DatabaseAtomic::loadStoredObjects(local_context, has_force_restore_data_flag, force_attach, skip_startup_tables);\n+void DatabaseReplicated::loadStoredObjects(\n+    ContextMutablePtr local_context, bool force_restore, bool force_attach, bool skip_startup_tables)\n+{\n+    beforeLoadingMetadata(local_context, force_restore, force_attach);\n+    DatabaseAtomic::loadStoredObjects(local_context, force_restore, force_attach, skip_startup_tables);\n+}\n \n+void DatabaseReplicated::startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach)\n+{\n+    DatabaseAtomic::startupTables(thread_pool, force_restore, force_attach);\n     ddl_worker = std::make_unique<DatabaseReplicatedDDLWorker>(this, getContext());\n     ddl_worker->startup();\n }\ndiff --git a/src/Databases/DatabaseReplicated.h b/src/Databases/DatabaseReplicated.h\nindex 1e0daeed07ea..60526a1e5b0f 100644\n--- a/src/Databases/DatabaseReplicated.h\n+++ b/src/Databases/DatabaseReplicated.h\n@@ -57,7 +57,12 @@ class DatabaseReplicated : public DatabaseAtomic\n \n     void drop(ContextPtr /*context*/) override;\n \n-    void loadStoredObjects(ContextMutablePtr context, bool has_force_restore_data_flag, bool force_attach, bool skip_startup_tables) override;\n+    void loadStoredObjects(ContextMutablePtr context, bool force_restore, bool force_attach, bool skip_startup_tables) override;\n+\n+    void beforeLoadingMetadata(ContextMutablePtr context, bool force_restore, bool force_attach) override;\n+\n+    void startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach) override;\n+\n     void shutdown() override;\n \n     friend struct DatabaseReplicatedTask;\ndiff --git a/src/Databases/IDatabase.h b/src/Databases/IDatabase.h\nindex bd9605dca711..19279e545eb9 100644\n--- a/src/Databases/IDatabase.h\n+++ b/src/Databases/IDatabase.h\n@@ -5,6 +5,7 @@\n #include <Storages/IStorage_fwd.h>\n #include <Interpreters/Context_fwd.h>\n #include <Common/Exception.h>\n+#include <Common/ThreadPool.h>\n #include <Core/UUID.h>\n \n #include <ctime>\n@@ -25,11 +26,14 @@ struct StorageInMemoryMetadata;\n struct StorageID;\n class ASTCreateQuery;\n using DictionariesWithID = std::vector<std::pair<String, UUID>>;\n+struct ParsedTablesMetadata;\n+struct QualifiedTableName;\n \n namespace ErrorCodes\n {\n     extern const int NOT_IMPLEMENTED;\n     extern const int CANNOT_GET_CREATE_TABLE_QUERY;\n+    extern const int LOGICAL_ERROR;\n }\n \n class IDatabaseTablesIterator\n@@ -125,13 +129,32 @@ class IDatabase : public std::enable_shared_from_this<IDatabase>\n     /// You can call only once, right after the object is created.\n     virtual void loadStoredObjects(\n         ContextMutablePtr /*context*/,\n-        bool /*has_force_restore_data_flag*/,\n+        bool /*force_restore*/,\n         bool /*force_attach*/ = false,\n         bool /* skip_startup_tables */ = false)\n     {\n     }\n \n-    virtual void startupTables() {}\n+    virtual bool supportsLoadingInTopologicalOrder() const { return false; }\n+\n+    virtual void beforeLoadingMetadata(\n+        ContextMutablePtr /*context*/,\n+        bool /*force_restore*/,\n+        bool /*force_attach*/)\n+    {\n+    }\n+\n+    virtual void loadTablesMetadata(ContextPtr /*local_context*/, ParsedTablesMetadata & /*metadata*/)\n+    {\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Not implemented\");\n+    }\n+\n+    virtual void loadTableFromMetadata(ContextMutablePtr /*local_context*/, const String & /*file_path*/, const QualifiedTableName & /*name*/, const ASTPtr & /*ast*/, bool /*force_restore*/)\n+    {\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Not implemented\");\n+    }\n+\n+    virtual void startupTables(ThreadPool & /*thread_pool*/, bool /*force_restore*/, bool /*force_attach*/) {}\n \n     /// Check the existence of the table.\n     virtual bool isTableExist(const String & name, ContextPtr context) const = 0;\ndiff --git a/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp b/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp\nindex 0d81a4e1a98e..2b4649c275a7 100644\n--- a/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp\n+++ b/src/Databases/MySQL/DatabaseMaterializedMySQL.cpp\n@@ -94,10 +94,10 @@ void DatabaseMaterializedMySQL<Base>::setException(const std::exception_ptr & ex\n }\n \n template <typename Base>\n-void DatabaseMaterializedMySQL<Base>::loadStoredObjects(\n-    ContextMutablePtr context_, bool has_force_restore_data_flag, bool force_attach, bool skip_startup_tables)\n+void DatabaseMaterializedMySQL<Base>::startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach)\n {\n-    Base::loadStoredObjects(context_, has_force_restore_data_flag, force_attach, skip_startup_tables);\n+    Base::startupTables(thread_pool, force_restore, force_attach);\n+\n     if (!force_attach)\n         materialize_thread.assertMySQLAvailable();\n \ndiff --git a/src/Databases/MySQL/DatabaseMaterializedMySQL.h b/src/Databases/MySQL/DatabaseMaterializedMySQL.h\nindex 292edc97878a..ac32607a22c4 100644\n--- a/src/Databases/MySQL/DatabaseMaterializedMySQL.h\n+++ b/src/Databases/MySQL/DatabaseMaterializedMySQL.h\n@@ -43,7 +43,7 @@ class DatabaseMaterializedMySQL : public Base\n public:\n     String getEngineName() const override { return \"MaterializedMySQL\"; }\n \n-    void loadStoredObjects(ContextMutablePtr context_, bool has_force_restore_data_flag, bool force_attach, bool skip_startup_tables) override;\n+    void startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach) override;\n \n     void createTable(ContextPtr context_, const String & name, const StoragePtr & table, const ASTPtr & query) override;\n \ndiff --git a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp\nindex 218dda94d31d..bceed2f9a3e0 100644\n--- a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp\n+++ b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp\n@@ -107,11 +107,9 @@ void DatabaseMaterializedPostgreSQL::startSynchronization()\n }\n \n \n-void DatabaseMaterializedPostgreSQL::loadStoredObjects(\n-    ContextMutablePtr local_context, bool has_force_restore_data_flag, bool force_attach, bool skip_startup_tables)\n+void DatabaseMaterializedPostgreSQL::startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach)\n {\n-    DatabaseAtomic::loadStoredObjects(local_context, has_force_restore_data_flag, force_attach, skip_startup_tables);\n-\n+    DatabaseAtomic::startupTables(thread_pool, force_restore, force_attach);\n     try\n     {\n         startSynchronization();\ndiff --git a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h\nindex 915bf44f1f2e..c5b3c9fcede1 100644\n--- a/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h\n+++ b/src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h\n@@ -43,7 +43,7 @@ class DatabaseMaterializedPostgreSQL : public DatabaseAtomic\n \n     String getMetadataPath() const override { return metadata_path; }\n \n-    void loadStoredObjects(ContextMutablePtr, bool, bool force_attach, bool skip_startup_tables) override;\n+    void startupTables(ThreadPool & thread_pool, bool force_restore, bool force_attach) override;\n \n     DatabaseTablesIteratorPtr\n     getTablesIterator(ContextPtr context, const DatabaseOnDisk::FilterByNameFunction & filter_by_table_name) const override;\ndiff --git a/src/Databases/TablesLoader.cpp b/src/Databases/TablesLoader.cpp\nnew file mode 100644\nindex 000000000000..48d751b57957\n--- /dev/null\n+++ b/src/Databases/TablesLoader.cpp\n@@ -0,0 +1,255 @@\n+#include <Databases/TablesLoader.h>\n+#include <Databases/IDatabase.h>\n+#include <Interpreters/DatabaseCatalog.h>\n+#include <Interpreters/Context.h>\n+#include <Interpreters/ExternalDictionariesLoader.h>\n+#include <Poco/Util/AbstractConfiguration.h>\n+#include <common/logger_useful.h>\n+#include <Common/ThreadPool.h>\n+#include <numeric>\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int INFINITE_LOOP;\n+    extern const int LOGICAL_ERROR;\n+}\n+\n+static constexpr size_t PRINT_MESSAGE_EACH_N_OBJECTS = 256;\n+static constexpr size_t PRINT_MESSAGE_EACH_N_SECONDS = 5;\n+\n+\n+void logAboutProgress(Poco::Logger * log, size_t processed, size_t total, AtomicStopwatch & watch)\n+{\n+    if (processed % PRINT_MESSAGE_EACH_N_OBJECTS == 0 || watch.compareAndRestart(PRINT_MESSAGE_EACH_N_SECONDS))\n+    {\n+        LOG_INFO(log, \"{}%\", processed * 100.0 / total);\n+        watch.restart();\n+    }\n+}\n+\n+TablesLoader::TablesLoader(ContextMutablePtr global_context_, Databases databases_, bool force_restore_, bool force_attach_)\n+: global_context(global_context_)\n+, databases(std::move(databases_))\n+, force_restore(force_restore_)\n+, force_attach(force_attach_)\n+{\n+    metadata.default_database = global_context->getCurrentDatabase();\n+    log = &Poco::Logger::get(\"TablesLoader\");\n+}\n+\n+\n+void TablesLoader::loadTables()\n+{\n+    bool need_resolve_dependencies = !global_context->getConfigRef().has(\"ignore_table_dependencies_on_metadata_loading\");\n+\n+    /// Load all Lazy, MySQl, PostgreSQL, SQLite, etc databases first.\n+    for (auto & database : databases)\n+    {\n+        if (need_resolve_dependencies && database.second->supportsLoadingInTopologicalOrder())\n+            databases_to_load.push_back(database.first);\n+        else\n+            database.second->loadStoredObjects(global_context, force_restore, force_attach, true);\n+    }\n+\n+    if (databases_to_load.empty())\n+        return;\n+\n+    /// Read and parse metadata from Ordinary, Atomic, Materialized*, Replicated, etc databases. Build dependency graph.\n+    for (auto & database_name : databases_to_load)\n+    {\n+        databases[database_name]->beforeLoadingMetadata(global_context, force_restore, force_attach);\n+        databases[database_name]->loadTablesMetadata(global_context, metadata);\n+    }\n+\n+    LOG_INFO(log, \"Parsed metadata of {} tables in {} databases in {} sec\",\n+             metadata.parsed_tables.size(), databases_to_load.size(), stopwatch.elapsedSeconds());\n+\n+    stopwatch.restart();\n+\n+    logDependencyGraph();\n+\n+    /// Some tables were loaded by database with loadStoredObjects(...). Remove them from graph if necessary.\n+    removeUnresolvableDependencies();\n+\n+    loadTablesInTopologicalOrder(pool);\n+}\n+\n+void TablesLoader::startupTables()\n+{\n+    /// Startup tables after all tables are loaded. Background tasks (merges, mutations, etc) may slow down data parts loading.\n+    for (auto & database : databases)\n+        database.second->startupTables(pool, force_restore, force_attach);\n+}\n+\n+\n+void TablesLoader::removeUnresolvableDependencies()\n+{\n+    auto need_exclude_dependency = [this](const QualifiedTableName & dependency_name, const DependenciesInfo & info)\n+    {\n+        /// Table exists and will be loaded\n+        if (metadata.parsed_tables.contains(dependency_name))\n+            return false;\n+        /// Table exists and it's already loaded\n+        if (DatabaseCatalog::instance().isTableExist(StorageID(dependency_name.database, dependency_name.table), global_context))\n+            return true;\n+        /// It's XML dictionary. It was loaded before tables and DDL dictionaries.\n+        if (dependency_name.database == metadata.default_database &&\n+            global_context->getExternalDictionariesLoader().has(dependency_name.table))\n+            return true;\n+\n+        /// Some tables depends on table \"dependency_name\", but there is no such table in DatabaseCatalog and we don't have its metadata.\n+        /// We will ignore it and try to load dependent tables without \"dependency_name\"\n+        /// (but most likely dependent tables will fail to load).\n+        LOG_WARNING(log, \"Tables {} depend on {}, but seems like the it does not exist. Will ignore it and try to load existing tables\",\n+                    fmt::join(info.dependent_database_objects, \", \"), dependency_name);\n+\n+        if (info.dependencies_count)\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Table {} does not exist, but we have seen its AST and found {} dependencies.\"\n+                                                       \"It's a bug\", dependency_name, info.dependencies_count);\n+        if (info.dependent_database_objects.empty())\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Table {} does not have dependencies and dependent tables as it expected to.\"\n+                                                       \"It's a bug\", dependency_name);\n+\n+        return true;\n+    };\n+\n+    auto table_it = metadata.dependencies_info.begin();\n+    while (table_it != metadata.dependencies_info.end())\n+    {\n+        auto & info = table_it->second;\n+        if (need_exclude_dependency(table_it->first, info))\n+            table_it = removeResolvedDependency(table_it, metadata.independent_database_objects);\n+        else\n+            ++table_it;\n+    }\n+}\n+\n+void TablesLoader::loadTablesInTopologicalOrder(ThreadPool & pool)\n+{\n+    /// Load independent tables in parallel.\n+    /// Then remove loaded tables from dependency graph, find tables/dictionaries that do not have unresolved dependencies anymore,\n+    /// move them to the list of independent tables and load.\n+    /// Repeat until we have some tables to load.\n+    /// If we do not, then either all objects are loaded or there is cyclic dependency.\n+    /// Complexity: O(V + E)\n+    size_t level = 0;\n+    do\n+    {\n+        assert(metadata.parsed_tables.size() == tables_processed + metadata.independent_database_objects.size() + getNumberOfTablesWithDependencies());\n+        logDependencyGraph();\n+\n+        startLoadingIndependentTables(pool, level);\n+\n+        TableNames new_independent_database_objects;\n+        for (const auto & table_name : metadata.independent_database_objects)\n+        {\n+            auto info_it = metadata.dependencies_info.find(table_name);\n+            if (info_it == metadata.dependencies_info.end())\n+            {\n+                /// No tables depend on table_name and it was not even added to dependencies_info\n+                continue;\n+            }\n+            removeResolvedDependency(info_it, new_independent_database_objects);\n+        }\n+\n+        pool.wait();\n+\n+        metadata.independent_database_objects = std::move(new_independent_database_objects);\n+        ++level;\n+    } while (!metadata.independent_database_objects.empty());\n+\n+    checkCyclicDependencies();\n+}\n+\n+DependenciesInfosIter TablesLoader::removeResolvedDependency(const DependenciesInfosIter & info_it, TableNames & independent_database_objects)\n+{\n+    auto & info = info_it->second;\n+    if (info.dependencies_count)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Table {} is in list of independent tables, but dependencies count is {}.\"\n+                                                   \"It's a bug\", info_it->first, info.dependencies_count);\n+    if (info.dependent_database_objects.empty())\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Table {} does not have dependent tables. It's a bug\", info_it->first);\n+\n+    /// Decrement number of dependencies for each dependent table\n+    for (auto & dependent_table : info.dependent_database_objects)\n+    {\n+        auto & dependent_info = metadata.dependencies_info[dependent_table];\n+        auto & dependencies_count = dependent_info.dependencies_count;\n+        if (dependencies_count == 0)\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Trying to decrement 0 dependencies counter for {}. It's a bug\", dependent_table);\n+        --dependencies_count;\n+        if (dependencies_count == 0)\n+        {\n+            independent_database_objects.push_back(dependent_table);\n+            if (dependent_info.dependent_database_objects.empty())\n+                metadata.dependencies_info.erase(dependent_table);\n+        }\n+    }\n+\n+    return metadata.dependencies_info.erase(info_it);\n+}\n+\n+void TablesLoader::startLoadingIndependentTables(ThreadPool & pool, size_t level)\n+{\n+    size_t total_tables = metadata.parsed_tables.size();\n+\n+    LOG_INFO(log, \"Loading {} tables with {} dependency level\", metadata.independent_database_objects.size(), level);\n+\n+    for (const auto & table_name : metadata.independent_database_objects)\n+    {\n+        pool.scheduleOrThrowOnError([this, total_tables, &table_name]()\n+        {\n+            const auto & path_and_query = metadata.parsed_tables[table_name];\n+            databases[table_name.database]->loadTableFromMetadata(global_context, path_and_query.path, table_name, path_and_query.ast, force_restore);\n+            logAboutProgress(log, ++tables_processed, total_tables, stopwatch);\n+        });\n+    }\n+}\n+\n+size_t TablesLoader::getNumberOfTablesWithDependencies() const\n+{\n+    size_t number_of_tables_with_dependencies = 0;\n+    for (const auto & info : metadata.dependencies_info)\n+        if (info.second.dependencies_count)\n+            ++number_of_tables_with_dependencies;\n+    return number_of_tables_with_dependencies;\n+}\n+\n+void TablesLoader::checkCyclicDependencies() const\n+{\n+    /// Loading is finished if all dependencies are resolved\n+    if (metadata.dependencies_info.empty())\n+        return;\n+\n+    for (const auto & info : metadata.dependencies_info)\n+    {\n+        LOG_WARNING(log, \"Cannot resolve dependencies: Table {} have {} dependencies and {} dependent tables. List of dependent tables: {}\",\n+                    info.first, info.second.dependencies_count,\n+                    info.second.dependent_database_objects.size(), fmt::join(info.second.dependent_database_objects, \", \"));\n+        assert(info.second.dependencies_count == 0);\n+    }\n+\n+    throw Exception(ErrorCodes::INFINITE_LOOP, \"Cannot attach {} tables due to cyclic dependencies. \"\n+                                               \"See server log for details.\", metadata.dependencies_info.size());\n+}\n+\n+void TablesLoader::logDependencyGraph() const\n+{\n+    LOG_TEST(log, \"Have {} independent tables: {}\",\n+              metadata.independent_database_objects.size(),\n+              fmt::join(metadata.independent_database_objects, \", \"));\n+    for (const auto & dependencies : metadata.dependencies_info)\n+    {\n+        LOG_TEST(log,\n+            \"Table {} have {} dependencies and {} dependent tables. List of dependent tables: {}\",\n+            dependencies.first,\n+            dependencies.second.dependencies_count,\n+            dependencies.second.dependent_database_objects.size(),\n+            fmt::join(dependencies.second.dependent_database_objects, \", \"));\n+    }\n+}\n+\n+}\ndiff --git a/src/Databases/TablesLoader.h b/src/Databases/TablesLoader.h\nnew file mode 100644\nindex 000000000000..12f6c2e86a5e\n--- /dev/null\n+++ b/src/Databases/TablesLoader.h\n@@ -0,0 +1,112 @@\n+#pragma once\n+#include <Core/Types.h>\n+#include <Core/QualifiedTableName.h>\n+#include <Parsers/IAST_fwd.h>\n+#include <Interpreters/Context_fwd.h>\n+#include <Common/ThreadPool.h>\n+#include <Common/Stopwatch.h>\n+#include <map>\n+#include <unordered_map>\n+#include <unordered_set>\n+#include <mutex>\n+\n+namespace Poco\n+{\n+    class Logger;\n+}\n+\n+class AtomicStopwatch;\n+\n+namespace DB\n+{\n+\n+void logAboutProgress(Poco::Logger * log, size_t processed, size_t total, AtomicStopwatch & watch);\n+\n+\n+class IDatabase;\n+using DatabasePtr = std::shared_ptr<IDatabase>;\n+\n+struct ParsedTableMetadata\n+{\n+    String path;\n+    ASTPtr ast;\n+};\n+\n+using ParsedMetadata = std::map<QualifiedTableName, ParsedTableMetadata>;\n+using TableNames = std::vector<QualifiedTableName>;\n+\n+struct DependenciesInfo\n+{\n+    /// How many dependencies this table have\n+    size_t dependencies_count = 0;\n+    /// List of tables/dictionaries which depend on this table/dictionary\n+    TableNames dependent_database_objects;\n+};\n+\n+using DependenciesInfos = std::unordered_map<QualifiedTableName, DependenciesInfo>;\n+using DependenciesInfosIter = std::unordered_map<QualifiedTableName, DependenciesInfo>::iterator;\n+\n+struct ParsedTablesMetadata\n+{\n+    String default_database;\n+\n+    std::mutex mutex;\n+    ParsedMetadata parsed_tables;\n+\n+    /// For logging\n+    size_t total_dictionaries = 0;\n+\n+    /// List of tables/dictionaries that do not have any dependencies and can be loaded\n+    TableNames independent_database_objects;\n+\n+    /// Actually it contains two different maps (with, probably, intersecting keys):\n+    /// 1. table/dictionary name -> number of dependencies\n+    /// 2. table/dictionary name -> dependent tables/dictionaries list (adjacency list of dependencies graph).\n+    /// If table A depends on table B, then there is an edge B --> A, i.e. dependencies_info[B].dependent_database_objects contains A.\n+    /// And dependencies_info[C].dependencies_count is a number of incoming edges for vertex C (how many tables we have to load before C).\n+    DependenciesInfos dependencies_info;\n+};\n+\n+/// Loads tables (and dictionaries) from specified databases\n+/// taking into account dependencies between them.\n+class TablesLoader\n+{\n+public:\n+    using Databases = std::map<String, DatabasePtr>;\n+\n+    TablesLoader(ContextMutablePtr global_context_, Databases databases_, bool force_restore_ = false, bool force_attach_ = false);\n+    TablesLoader() = delete;\n+\n+    void loadTables();\n+    void startupTables();\n+\n+private:\n+    ContextMutablePtr global_context;\n+    Databases databases;\n+    bool force_restore;\n+    bool force_attach;\n+\n+    Strings databases_to_load;\n+    ParsedTablesMetadata metadata;\n+    Poco::Logger * log;\n+    std::atomic<size_t> tables_processed{0};\n+    AtomicStopwatch stopwatch;\n+\n+    ThreadPool pool;\n+\n+    void removeUnresolvableDependencies();\n+\n+    void loadTablesInTopologicalOrder(ThreadPool & pool);\n+\n+    DependenciesInfosIter removeResolvedDependency(const DependenciesInfosIter & info_it, TableNames & independent_database_objects);\n+\n+    void startLoadingIndependentTables(ThreadPool & pool, size_t level);\n+\n+    void checkCyclicDependencies() const;\n+\n+    size_t getNumberOfTablesWithDependencies() const;\n+\n+    void logDependencyGraph() const;\n+};\n+\n+}\ndiff --git a/src/Dictionaries/PostgreSQLDictionarySource.cpp b/src/Dictionaries/PostgreSQLDictionarySource.cpp\nindex 3fe9e899cd91..ae153eaed536 100644\n--- a/src/Dictionaries/PostgreSQLDictionarySource.cpp\n+++ b/src/Dictionaries/PostgreSQLDictionarySource.cpp\n@@ -1,6 +1,7 @@\n #include \"PostgreSQLDictionarySource.h\"\n \n #include <Poco/Util/AbstractConfiguration.h>\n+#include <Core/QualifiedTableName.h>\n #include \"DictionarySourceFactory.h\"\n #include \"registerDictionaries.h\"\n \n@@ -29,19 +30,13 @@ namespace\n {\n     ExternalQueryBuilder makeExternalQueryBuilder(const DictionaryStructure & dict_struct, const String & schema, const String & table, const String & query, const String & where)\n     {\n-        auto schema_value = schema;\n-        auto table_value = table;\n+        QualifiedTableName qualified_name{schema, table};\n+\n+        if (qualified_name.database.empty() && !qualified_name.table.empty())\n+            qualified_name = QualifiedTableName::parseFromString(qualified_name.table);\n \n-        if (schema_value.empty())\n-        {\n-            if (auto pos = table_value.find('.'); pos != std::string::npos)\n-            {\n-                schema_value = table_value.substr(0, pos);\n-                table_value = table_value.substr(pos + 1);\n-            }\n-        }\n         /// Do not need db because it is already in a connection string.\n-        return {dict_struct, \"\", schema_value, table_value, query, where, IdentifierQuotingStyle::DoubleQuotes};\n+        return {dict_struct, \"\", qualified_name.database, qualified_name.table, query, where, IdentifierQuotingStyle::DoubleQuotes};\n     }\n }\n \ndiff --git a/src/Dictionaries/XDBCDictionarySource.cpp b/src/Dictionaries/XDBCDictionarySource.cpp\nindex 9fc7e92634b6..bf7526580c07 100644\n--- a/src/Dictionaries/XDBCDictionarySource.cpp\n+++ b/src/Dictionaries/XDBCDictionarySource.cpp\n@@ -38,29 +38,22 @@ namespace\n                                                   const std::string & where_,\n                                                   IXDBCBridgeHelper & bridge_)\n     {\n-        std::string schema = schema_;\n-        std::string table = table_;\n+        QualifiedTableName qualified_name{schema_, table_};\n \n         if (bridge_.isSchemaAllowed())\n         {\n-            if (schema.empty())\n-            {\n-                if (auto pos = table.find('.'); pos != std::string::npos)\n-                {\n-                    schema = table.substr(0, pos);\n-                    table = table.substr(pos + 1);\n-                }\n-            }\n+            if (qualified_name.database.empty())\n+                qualified_name = QualifiedTableName::parseFromString(qualified_name.table);\n         }\n         else\n         {\n-            if (!schema.empty())\n+            if (!qualified_name.database.empty())\n                 throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,\n                     \"Dictionary source of type {} specifies a schema but schema is not supported by {}-driver\",\n                     bridge_.getName());\n         }\n \n-        return {dict_struct_, db_, schema, table, query_, where_, bridge_.getIdentifierQuotingStyle()};\n+        return {dict_struct_, db_, qualified_name.database, qualified_name.table, query_, where_, bridge_.getIdentifierQuotingStyle()};\n     }\n }\n \ndiff --git a/src/Dictionaries/getDictionaryConfigurationFromAST.cpp b/src/Dictionaries/getDictionaryConfigurationFromAST.cpp\nindex c77ac36ade69..0ed5b3af83de 100644\n--- a/src/Dictionaries/getDictionaryConfigurationFromAST.cpp\n+++ b/src/Dictionaries/getDictionaryConfigurationFromAST.cpp\n@@ -4,7 +4,6 @@\n #include <Poco/DOM/Document.h>\n #include <Poco/DOM/Element.h>\n #include <Poco/DOM/Text.h>\n-#include <Poco/Util/AbstractConfiguration.h>\n #include <Poco/Util/XMLConfiguration.h>\n #include <IO/WriteHelpers.h>\n #include <Parsers/queryToString.h>\n@@ -16,6 +15,8 @@\n #include <Parsers/ASTDictionaryAttributeDeclaration.h>\n #include <Dictionaries/DictionaryFactory.h>\n #include <Functions/FunctionFactory.h>\n+#include <Common/isLocalAddress.h>\n+#include <Interpreters/Context.h>\n \n \n namespace DB\n@@ -576,4 +577,28 @@ getDictionaryConfigurationFromAST(const ASTCreateQuery & query, ContextPtr conte\n     return conf;\n }\n \n+std::optional<ClickHouseDictionarySourceInfo>\n+getInfoIfClickHouseDictionarySource(DictionaryConfigurationPtr & config, ContextPtr global_context)\n+{\n+    ClickHouseDictionarySourceInfo info;\n+\n+    String host = config->getString(\"dictionary.source.clickhouse.host\", \"\");\n+    UInt16 port = config->getUInt(\"dictionary.source.clickhouse.port\", 0);\n+    String database = config->getString(\"dictionary.source.clickhouse.db\", \"\");\n+    String table = config->getString(\"dictionary.source.clickhouse.table\", \"\");\n+    bool secure = config->getBool(\"dictionary.source.clickhouse.secure\", false);\n+\n+    if (host.empty() || port == 0 || table.empty())\n+        return {};\n+\n+    info.table_name = {database, table};\n+\n+    UInt16 default_port = secure ? global_context->getTCPPortSecure().value_or(0) : global_context->getTCPPort();\n+    if (!isLocalAddress({host, port}, default_port))\n+        return info;\n+\n+    info.is_local = true;\n+    return info;\n+}\n+\n }\ndiff --git a/src/Dictionaries/getDictionaryConfigurationFromAST.h b/src/Dictionaries/getDictionaryConfigurationFromAST.h\nindex b464fdf1d8c1..ec44b9815fff 100644\n--- a/src/Dictionaries/getDictionaryConfigurationFromAST.h\n+++ b/src/Dictionaries/getDictionaryConfigurationFromAST.h\n@@ -15,4 +15,13 @@ using DictionaryConfigurationPtr = Poco::AutoPtr<Poco::Util::AbstractConfigurati\n DictionaryConfigurationPtr\n getDictionaryConfigurationFromAST(const ASTCreateQuery & query, ContextPtr context, const std::string & database_ = \"\");\n \n+struct ClickHouseDictionarySourceInfo\n+{\n+    QualifiedTableName table_name;\n+    bool is_local = false;\n+};\n+\n+std::optional<ClickHouseDictionarySourceInfo>\n+getInfoIfClickHouseDictionarySource(DictionaryConfigurationPtr & config, ContextPtr global_context);\n+\n }\ndiff --git a/src/Functions/FunctionJoinGet.cpp b/src/Functions/FunctionJoinGet.cpp\nindex ee1736074373..f0dff0ac7e43 100644\n--- a/src/Functions/FunctionJoinGet.cpp\n+++ b/src/Functions/FunctionJoinGet.cpp\n@@ -48,22 +48,11 @@ getJoin(const ColumnsWithTypeAndName & arguments, ContextPtr context)\n             \"Illegal type \" + arguments[0].type->getName() + \" of first argument of function joinGet, expected a const string.\",\n             ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT);\n \n-    size_t dot = join_name.find('.');\n-    String database_name;\n-    if (dot == String::npos)\n-    {\n-        database_name = context->getCurrentDatabase();\n-        dot = 0;\n-    }\n-    else\n-    {\n-        database_name = join_name.substr(0, dot);\n-        ++dot;\n-    }\n-    String table_name = join_name.substr(dot);\n-    if (table_name.empty())\n-        throw Exception(\"joinGet does not allow empty table name\", ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT);\n-    auto table = DatabaseCatalog::instance().getTable({database_name, table_name}, std::const_pointer_cast<Context>(context));\n+    auto qualified_name = QualifiedTableName::parseFromString(join_name);\n+    if (qualified_name.database.empty())\n+        qualified_name.database = context->getCurrentDatabase();\n+\n+    auto table = DatabaseCatalog::instance().getTable({qualified_name.database, qualified_name.table}, std::const_pointer_cast<Context>(context));\n     auto storage_join = std::dynamic_pointer_cast<StorageJoin>(table);\n     if (!storage_join)\n         throw Exception(\"Table \" + join_name + \" should have engine StorageJoin\", ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT);\ndiff --git a/src/Interpreters/DatabaseCatalog.cpp b/src/Interpreters/DatabaseCatalog.cpp\nindex 20ebc0a9ee5b..0cf85fdde681 100644\n--- a/src/Interpreters/DatabaseCatalog.cpp\n+++ b/src/Interpreters/DatabaseCatalog.cpp\n@@ -156,15 +156,6 @@ void DatabaseCatalog::loadDatabases()\n     /// Another background thread which drops temporary LiveViews.\n     /// We should start it after loadMarkedAsDroppedTables() to avoid race condition.\n     TemporaryLiveViewCleaner::instance().startup();\n-\n-    /// Start up tables after all databases are loaded.\n-    for (const auto & [database_name, database] : databases)\n-    {\n-        if (database_name == DatabaseCatalog::TEMPORARY_DATABASE)\n-            continue;\n-\n-        database->startupTables();\n-    }\n }\n \n void DatabaseCatalog::shutdownImpl()\ndiff --git a/src/Interpreters/ExternalDictionariesLoader.cpp b/src/Interpreters/ExternalDictionariesLoader.cpp\nindex cbb0e52b91bc..fdd371c5038a 100644\n--- a/src/Interpreters/ExternalDictionariesLoader.cpp\n+++ b/src/Interpreters/ExternalDictionariesLoader.cpp\n@@ -89,47 +89,40 @@ DictionaryStructure ExternalDictionariesLoader::getDictionaryStructure(const std\n \n std::string ExternalDictionariesLoader::resolveDictionaryName(const std::string & dictionary_name, const std::string & current_database_name) const\n {\n-    bool has_dictionary = has(dictionary_name);\n-    if (has_dictionary)\n+    if (has(dictionary_name))\n         return dictionary_name;\n \n-    std::string resolved_name = resolveDictionaryNameFromDatabaseCatalog(dictionary_name);\n-    has_dictionary = has(resolved_name);\n+    std::string resolved_name = resolveDictionaryNameFromDatabaseCatalog(dictionary_name, current_database_name);\n \n-    if (!has_dictionary)\n-    {\n-        /// If dictionary not found. And database was not implicitly specified\n-        /// we can qualify dictionary name with current database name.\n-        /// It will help if dictionary is created with DDL and is in current database.\n-        if (dictionary_name.find('.') == std::string::npos)\n-        {\n-            String dictionary_name_with_database = current_database_name + '.' + dictionary_name;\n-            resolved_name = resolveDictionaryNameFromDatabaseCatalog(dictionary_name_with_database);\n-            has_dictionary = has(resolved_name);\n-        }\n-    }\n-\n-    if (!has_dictionary)\n-        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Dictionary ({}) not found\", backQuote(dictionary_name));\n+    if (has(resolved_name))\n+        return resolved_name;\n \n-    return resolved_name;\n+    throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Dictionary ({}) not found\", backQuote(dictionary_name));\n }\n \n-std::string ExternalDictionariesLoader::resolveDictionaryNameFromDatabaseCatalog(const std::string & name) const\n+std::string ExternalDictionariesLoader::resolveDictionaryNameFromDatabaseCatalog(const std::string & name, const std::string & current_database_name) const\n {\n     /// If it's dictionary from Atomic database, then we need to convert qualified name to UUID.\n     /// Try to split name and get id from associated StorageDictionary.\n     /// If something went wrong, return name as is.\n \n-    auto pos = name.find('.');\n-    if (pos == std::string::npos || name.find('.', pos + 1) != std::string::npos)\n+    auto qualified_name = QualifiedTableName::tryParseFromString(name);\n+    if (!qualified_name)\n         return name;\n \n-    std::string maybe_database_name = name.substr(0, pos);\n-    std::string maybe_table_name = name.substr(pos + 1);\n+    if (qualified_name->database.empty())\n+    {\n+        /// Ether database name is not specified and we should use current one\n+        /// or it's an XML dictionary.\n+        bool is_xml_dictionary = has(name);\n+        if (is_xml_dictionary)\n+            return name;\n+        else\n+            qualified_name->database = current_database_name;\n+    }\n \n     auto [db, table] = DatabaseCatalog::instance().tryGetDatabaseAndTable(\n-        {maybe_database_name, maybe_table_name},\n+        {qualified_name->database, qualified_name->table},\n         const_pointer_cast<Context>(getContext()));\n \n     if (!db)\ndiff --git a/src/Interpreters/ExternalDictionariesLoader.h b/src/Interpreters/ExternalDictionariesLoader.h\nindex 06f64ef30c50..f748d75d9084 100644\n--- a/src/Interpreters/ExternalDictionariesLoader.h\n+++ b/src/Interpreters/ExternalDictionariesLoader.h\n@@ -42,7 +42,7 @@ class ExternalDictionariesLoader : public ExternalLoader, WithContext\n     std::string resolveDictionaryName(const std::string & dictionary_name, const std::string & current_database_name) const;\n \n     /// Try convert qualified dictionary name to persistent UUID\n-    std::string resolveDictionaryNameFromDatabaseCatalog(const std::string & name) const;\n+    std::string resolveDictionaryNameFromDatabaseCatalog(const std::string & name, const std::string & current_database_name) const;\n \n     friend class StorageSystemDictionaries;\n     friend class DatabaseDictionary;\ndiff --git a/src/Interpreters/InterpreterCreateQuery.cpp b/src/Interpreters/InterpreterCreateQuery.cpp\nindex 7e061662534b..db4b8a72a7db 100644\n--- a/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -53,6 +53,7 @@\n #include <Databases/DatabaseReplicated.h>\n #include <Databases/IDatabase.h>\n #include <Databases/DatabaseOnDisk.h>\n+#include <Databases/TablesLoader.h>\n \n #include <Compression/CompressionFactory.h>\n \n@@ -271,9 +272,13 @@ BlockIO InterpreterCreateQuery::createDatabase(ASTCreateQuery & create)\n             renamed = true;\n         }\n \n-        /// We use global context here, because storages lifetime is bigger than query context lifetime\n-        database->loadStoredObjects(\n-            getContext()->getGlobalContext(), has_force_restore_data_flag, create.attach && force_attach, skip_startup_tables); //-V560\n+        if (!load_database_without_tables)\n+        {\n+            /// We use global context here, because storages lifetime is bigger than query context lifetime\n+            TablesLoader loader{getContext()->getGlobalContext(), {{database_name, database}}, has_force_restore_data_flag, create.attach && force_attach}; //-V560\n+            loader.loadTables();\n+            loader.startupTables();\n+        }\n     }\n     catch (...)\n     {\ndiff --git a/src/Interpreters/InterpreterCreateQuery.h b/src/Interpreters/InterpreterCreateQuery.h\nindex 1ef5e0470fcc..89d27a30555d 100644\n--- a/src/Interpreters/InterpreterCreateQuery.h\n+++ b/src/Interpreters/InterpreterCreateQuery.h\n@@ -52,9 +52,9 @@ class InterpreterCreateQuery : public IInterpreter, WithMutableContext\n         force_attach = force_attach_;\n     }\n \n-    void setSkipStartupTables(bool skip_startup_tables_)\n+    void setLoadDatabaseWithoutTables(bool load_database_without_tables_)\n     {\n-        skip_startup_tables = skip_startup_tables_;\n+        load_database_without_tables = load_database_without_tables_;\n     }\n \n     /// Obtain information about columns, their types, default values and column comments,\n@@ -99,7 +99,7 @@ class InterpreterCreateQuery : public IInterpreter, WithMutableContext\n     /// Is this an internal query - not from the user.\n     bool internal = false;\n     bool force_attach = false;\n-    bool skip_startup_tables = false;\n+    bool load_database_without_tables = false;\n \n     mutable String as_database_saved;\n     mutable String as_table_saved;\ndiff --git a/src/Interpreters/InterpreterDropQuery.cpp b/src/Interpreters/InterpreterDropQuery.cpp\nindex 608bd615e6a8..0afb3d68a39b 100644\n--- a/src/Interpreters/InterpreterDropQuery.cpp\n+++ b/src/Interpreters/InterpreterDropQuery.cpp\n@@ -357,6 +357,13 @@ BlockIO InterpreterDropQuery::executeToDatabaseImpl(const ASTDropQuery & query,\n                 }\n             }\n \n+            if (!drop && query.no_delay)\n+            {\n+                /// Avoid \"some tables are still in use\" when sync mode is enabled\n+                for (const auto & table_uuid : uuids_to_wait)\n+                    database->waitDetachedTableNotInUse(table_uuid);\n+            }\n+\n             /// Protects from concurrent CREATE TABLE queries\n             auto db_guard = DatabaseCatalog::instance().getExclusiveDDLGuardForDatabase(database_name);\n \ndiff --git a/src/Interpreters/loadMetadata.cpp b/src/Interpreters/loadMetadata.cpp\nindex 230831a66741..858b4281f5a8 100644\n--- a/src/Interpreters/loadMetadata.cpp\n+++ b/src/Interpreters/loadMetadata.cpp\n@@ -11,6 +11,7 @@\n #include <Interpreters/loadMetadata.h>\n \n #include <Databases/DatabaseOrdinary.h>\n+#include <Databases/TablesLoader.h>\n \n #include <IO/ReadBufferFromFile.h>\n #include <IO/ReadHelpers.h>\n@@ -43,7 +44,7 @@ static void executeCreateQuery(\n     interpreter.setInternal(true);\n     interpreter.setForceAttach(true);\n     interpreter.setForceRestoreData(has_force_restore_data_flag);\n-    interpreter.setSkipStartupTables(true);\n+    interpreter.setLoadDatabaseWithoutTables(true);\n     interpreter.execute();\n }\n \n@@ -161,8 +162,16 @@ void loadMetadata(ContextMutablePtr context, const String & default_database_nam\n     if (create_default_db_if_not_exists && !metadata_dir_for_default_db_already_exists)\n         databases.emplace(default_database_name, path + \"/\" + escapeForFileName(default_database_name));\n \n+    TablesLoader::Databases loaded_databases;\n     for (const auto & [name, db_path] : databases)\n+    {\n         loadDatabase(context, name, db_path, has_force_restore_data_flag);\n+        loaded_databases.insert({name, DatabaseCatalog::instance().getDatabase(name)});\n+    }\n+\n+    TablesLoader loader{context, std::move(loaded_databases), has_force_restore_data_flag, /* force_attach */ true};\n+    loader.loadTables();\n+    loader.startupTables();\n \n     if (has_force_restore_data_flag)\n     {\n@@ -197,11 +206,28 @@ static void loadSystemDatabaseImpl(ContextMutablePtr context, const String & dat\n     }\n }\n \n+\n+void startupSystemTables()\n+{\n+    ThreadPool pool;\n+    DatabaseCatalog::instance().getSystemDatabase()->startupTables(pool, /* force_restore */ true, /* force_attach */ true);\n+}\n+\n void loadMetadataSystem(ContextMutablePtr context)\n {\n     loadSystemDatabaseImpl(context, DatabaseCatalog::SYSTEM_DATABASE, \"Atomic\");\n     loadSystemDatabaseImpl(context, DatabaseCatalog::INFORMATION_SCHEMA, \"Memory\");\n     loadSystemDatabaseImpl(context, DatabaseCatalog::INFORMATION_SCHEMA_UPPERCASE, \"Memory\");\n+\n+    TablesLoader::Databases databases =\n+    {\n+        {DatabaseCatalog::SYSTEM_DATABASE, DatabaseCatalog::instance().getSystemDatabase()},\n+        {DatabaseCatalog::INFORMATION_SCHEMA, DatabaseCatalog::instance().getDatabase(DatabaseCatalog::INFORMATION_SCHEMA)},\n+        {DatabaseCatalog::INFORMATION_SCHEMA_UPPERCASE, DatabaseCatalog::instance().getDatabase(DatabaseCatalog::INFORMATION_SCHEMA_UPPERCASE)},\n+    };\n+    TablesLoader loader{context, databases, /* force_restore */ true, /* force_attach */ true};\n+    loader.loadTables();\n+    /// Will startup tables in system database after all databases are loaded.\n }\n \n }\ndiff --git a/src/Interpreters/loadMetadata.h b/src/Interpreters/loadMetadata.h\nindex 529d2e43fc8a..e918b5f530c7 100644\n--- a/src/Interpreters/loadMetadata.h\n+++ b/src/Interpreters/loadMetadata.h\n@@ -1,6 +1,7 @@\n #pragma once\n \n #include <Interpreters/Context_fwd.h>\n+#include <Databases/TablesLoader.h>\n \n \n namespace DB\n@@ -14,4 +15,8 @@ void loadMetadataSystem(ContextMutablePtr context);\n /// Use separate function to load system tables.\n void loadMetadata(ContextMutablePtr context, const String & default_database_name = {});\n \n+/// Background operations in system tables may slowdown loading of the rest tables,\n+/// so we startup system tables after all databases are loaded.\n+void startupSystemTables();\n+\n }\ndiff --git a/src/TableFunctions/TableFunctionRemote.cpp b/src/TableFunctions/TableFunctionRemote.cpp\nindex 08f61a49fa5e..3c39e3f2ec00 100644\n--- a/src/TableFunctions/TableFunctionRemote.cpp\n+++ b/src/TableFunctions/TableFunctionRemote.cpp\n@@ -93,14 +93,8 @@ void TableFunctionRemote::parseArguments(const ASTPtr & ast_function, ContextPtr\n \n         ++arg_num;\n \n-        size_t dot = remote_database.find('.');\n-        if (dot != String::npos)\n-        {\n-            /// NOTE Bad - do not support identifiers in backquotes.\n-            remote_table = remote_database.substr(dot + 1);\n-            remote_database = remote_database.substr(0, dot);\n-        }\n-        else\n+        auto qualified_name = QualifiedTableName::parseFromString(remote_database);\n+        if (qualified_name.database.empty())\n         {\n             if (arg_num >= args.size())\n             {\n@@ -108,11 +102,15 @@ void TableFunctionRemote::parseArguments(const ASTPtr & ast_function, ContextPtr\n             }\n             else\n             {\n+                std::swap(qualified_name.database, qualified_name.table);\n                 args[arg_num] = evaluateConstantExpressionOrIdentifierAsLiteral(args[arg_num], context);\n-                remote_table = args[arg_num]->as<ASTLiteral &>().value.safeGet<String>();\n+                qualified_name.table = args[arg_num]->as<ASTLiteral &>().value.safeGet<String>();\n                 ++arg_num;\n             }\n         }\n+\n+        remote_database = std::move(qualified_name.database);\n+        remote_table = std::move(qualified_name.table);\n     }\n \n     /// Cluster function may have sharding key for insert\n",
  "test_patch": "diff --git a/tests/integration/test_dictionaries_dependency_xml/test.py b/tests/integration/test_dictionaries_dependency_xml/test.py\nindex cfd7d58d574f..849fdf579804 100644\n--- a/tests/integration/test_dictionaries_dependency_xml/test.py\n+++ b/tests/integration/test_dictionaries_dependency_xml/test.py\n@@ -6,7 +6,7 @@\n                     'configs/dictionaries/dep_z.xml']\n \n cluster = ClickHouseCluster(__file__)\n-instance = cluster.add_instance('instance', dictionaries=DICTIONARY_FILES)\n+instance = cluster.add_instance('instance', dictionaries=DICTIONARY_FILES, stay_alive=True)\n \n \n @pytest.fixture(scope=\"module\")\n@@ -73,3 +73,45 @@ def test_get_data(started_cluster):\n     assert query(\"SELECT dictGetString('dep_x', 'a', toUInt64(4))\") == \"ether\\n\"\n     assert query(\"SELECT dictGetString('dep_y', 'a', toUInt64(4))\") == \"ether\\n\"\n     assert query(\"SELECT dictGetString('dep_z', 'a', toUInt64(4))\") == \"ether\\n\"\n+\n+def dependent_tables_assert():\n+    res = instance.query(\"select database || '.' || name from system.tables\")\n+    assert \"system.join\" in res\n+    assert \"default.src\" in res\n+    assert \"dict.dep_y\" in res\n+    assert \"lazy.log\" in res\n+    assert \"test.d\" in res\n+    assert \"default.join\" in res\n+    assert \"a.t\" in res\n+\n+def test_dependent_tables(started_cluster):\n+    query = instance.query\n+    query(\"create database lazy engine=Lazy(10)\")\n+    query(\"create database a\")\n+    query(\"create table lazy.src (n int, m int) engine=Log\")\n+    query(\"create dictionary a.d (n int default 0, m int default 42) primary key n \"\n+          \"source(clickhouse(host 'localhost' port tcpPort() user 'default' table 'src' password '' db 'lazy'))\"\n+          \"lifetime(min 1 max 10) layout(flat())\")\n+    query(\"create table system.join (n int, m int) engine=Join(any, left, n)\")\n+    query(\"insert into system.join values (1, 1)\")\n+    query(\"create table src (n int, m default joinGet('system.join', 'm', 1::int),\"\n+                                   \"t default dictGetOrNull('a.d', 'm', toUInt64(3)),\"\n+                                   \"k default dictGet('a.d', 'm', toUInt64(4))) engine=MergeTree order by n\")\n+    query(\"create dictionary test.d (n int default 0, m int default 42) primary key n \"\n+          \"source(clickhouse(host 'localhost' port tcpPort() user 'default' table 'src' password '' db 'default'))\"\n+          \"lifetime(min 1 max 10) layout(flat())\")\n+    query(\"create table join (n int, m default dictGet('a.d', 'm', toUInt64(3)),\"\n+                                    \"k default dictGet('test.d', 'm', toUInt64(0))) engine=Join(any, left, n)\")\n+    query(\"create table lazy.log (n default dictGet(test.d, 'm', toUInt64(0))) engine=Log\")\n+    query(\"create table a.t (n default joinGet('system.join', 'm', 1::int),\"\n+                            \"m default dictGet('test.d', 'm', toUInt64(3)),\"\n+                            \"k default joinGet(join, 'm', 1::int)) engine=MergeTree order by n\")\n+\n+    dependent_tables_assert()\n+    instance.restart_clickhouse()\n+    dependent_tables_assert()\n+    query(\"drop database a\")\n+    query(\"drop database lazy\")\n+    query(\"drop table src\")\n+    query(\"drop table join\")\n+    query(\"drop table system.join\")\ndiff --git a/tests/queries/0_stateless/01160_table_dependencies.reference b/tests/queries/0_stateless/01160_table_dependencies.reference\nnew file mode 100644\nindex 000000000000..39a58b06076a\n--- /dev/null\n+++ b/tests/queries/0_stateless/01160_table_dependencies.reference\n@@ -0,0 +1,6 @@\n+dict1\n+dict2\n+dict_src\n+join\n+s\n+t\ndiff --git a/tests/queries/0_stateless/01160_table_dependencies.sh b/tests/queries/0_stateless/01160_table_dependencies.sh\nnew file mode 100755\nindex 000000000000..149439f2981e\n--- /dev/null\n+++ b/tests/queries/0_stateless/01160_table_dependencies.sh\n@@ -0,0 +1,45 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+\n+$CLICKHOUSE_CLIENT -q \"drop table if exists dict_src;\"\n+$CLICKHOUSE_CLIENT -q \"drop dictionary if exists dict1;\"\n+$CLICKHOUSE_CLIENT -q \"drop dictionary if exists dict2;\"\n+$CLICKHOUSE_CLIENT -q \"drop table if exists join;\"\n+$CLICKHOUSE_CLIENT -q \"drop table if exists t;\"\n+\n+$CLICKHOUSE_CLIENT -q \"create table dict_src (n int, m int, s String) engine=MergeTree order by n;\"\n+\n+$CLICKHOUSE_CLIENT -q \"create dictionary dict1 (n int default 0, m int default 1, s String default 'qqq')\n+PRIMARY KEY n\n+SOURCE(CLICKHOUSE(HOST 'localhost' PORT tcpPort() USER 'default' TABLE 'dict_src' PASSWORD '' DB '$CLICKHOUSE_DATABASE'))\n+LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT());\"\n+\n+$CLICKHOUSE_CLIENT -q \"create table join(n int, m int default dictGet('$CLICKHOUSE_DATABASE.dict1', 'm', 42::UInt64)) engine=Join(any, left, n);\"\n+\n+$CLICKHOUSE_CLIENT -q \"create dictionary dict2 (n int default 0, m int DEFAULT 2, s String default 'asd')\n+PRIMARY KEY n\n+SOURCE(CLICKHOUSE(HOST 'localhost' PORT tcpPort() USER 'default' TABLE 'join' PASSWORD '' DB '$CLICKHOUSE_DATABASE'))\n+LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT());\"\n+\n+$CLICKHOUSE_CLIENT -q \"create table s (x default joinGet($CLICKHOUSE_DATABASE.join, 'm', 42::int)) engine=Set\"\n+\n+$CLICKHOUSE_CLIENT -q \"create table t (n int, m int default joinGet($CLICKHOUSE_DATABASE.join, 'm', 42::int),\n+s String default dictGet($CLICKHOUSE_DATABASE.dict1, 's', 42::UInt64), x default in(1, $CLICKHOUSE_DATABASE.s)) engine=MergeTree order by n;\"\n+\n+CLICKHOUSE_CLIENT_DEFAULT_DB=$(echo ${CLICKHOUSE_CLIENT} | sed 's/'\"--database=${CLICKHOUSE_DATABASE}\"'/--database=default/g')\n+\n+for _ in {1..10}; do\n+  $CLICKHOUSE_CLIENT_DEFAULT_DB -q \"detach database $CLICKHOUSE_DATABASE;\"\n+  $CLICKHOUSE_CLIENT_DEFAULT_DB -q \"attach database $CLICKHOUSE_DATABASE;\"\n+done\n+$CLICKHOUSE_CLIENT -q \"show tables from $CLICKHOUSE_DATABASE;\"\n+\n+$CLICKHOUSE_CLIENT -q \"drop table dict_src;\"\n+$CLICKHOUSE_CLIENT -q \"drop dictionary dict1;\"\n+$CLICKHOUSE_CLIENT -q \"drop dictionary dict2;\"\n+$CLICKHOUSE_CLIENT -q \"drop table join;\"\n+$CLICKHOUSE_CLIENT -q \"drop table t;\"\ndiff --git a/tests/queries/0_stateless/01372_remote_table_function_empty_table.sql b/tests/queries/0_stateless/01372_remote_table_function_empty_table.sql\nindex 4153dc632f3f..55c9d3f63d35 100644\n--- a/tests/queries/0_stateless/01372_remote_table_function_empty_table.sql\n+++ b/tests/queries/0_stateless/01372_remote_table_function_empty_table.sql\n@@ -1,4 +1,4 @@\n-SELECT * FROM remote('127..2', 'a.'); -- { serverError 36 }\n+SELECT * FROM remote('127..2', 'a.'); -- { serverError 62 }\n \n -- Clear cache to avoid future errors in the logs\n SYSTEM DROP DNS CACHE\n",
  "problem_statement": "Table dependancies with ALIAS joinGet column\nHaven't provided an example/steps to reproduce but I've noticed that tables that use a joinGet call in an alias column cause the server to fail to startup due to dependency issues. Only work around is to either edit the metadata SQL file and remove the column (then re-add on startup) or move the metadata SQL file out of the way until the source table has loaded then attach it.\r\n\r\nIs there a workaround for this?\n[RFC] Tables and dictionaries loading order on server startup and related issues\n**It's just a draft, I will complete the description later**\r\n\r\n**Use case**\r\nIf some table depends on another table or dictionary (for example, expression in `MATERIALIZED`, `ALIAS` or `DEFAULT` contains `joinGet(...)` or `dictGet(...)` or `IN` operator with `StorageSet`, maybe there are some other scenarios), then clickhouse-server may fail to start because it doesn't take into account such dependencies. \r\n\r\n**Describe the solution you'd like**\r\nSee https://github.com/ClickHouse/ClickHouse/pull/15157#issuecomment-696924255\r\n\r\n\r\n**Additional context**\r\nIt would be great to collect all related issues here to choose the proper solution.\r\n#8004 #13613 #13059 #15157 #13359\n",
  "hints_text": "> Haven't provided an example/steps to reproduce\r\n\r\nA test case is very appreciated.\nI recently tried upgrading from 19.13.3.26 to 20.1 and had a similar issue. Looks like this also happens if table has dictGet() in alias expression. I tried setting `dictionaries_lazy_load ` to false, but it didn't help.\r\n\r\ndata.sql:\r\n```\r\nATTACH TABLE events.data\r\n(\r\n\ttimestamp DateTime,\r\n\tEventID UInt16,\r\n\tHostname String,\r\n\tMessage String,\r\n\tcategory String alias dictGetOrDefault('events', 'category', toUInt64(EventID), toString(EventID)),\r\n\tdesc String alias dictGetOrDefault('events', 'description', toUInt64(EventID), toString(EventID))\r\n)\r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/events_data', '{replica}') \r\nPARTITION BY toYYYYMMDD(timestamp)\r\nORDER BY (EventID, timestamp)\r\nSAMPLE BY EventID;\r\n```\r\n\r\nServer fails to start with the following message:\r\n```\r\n2020.02.03 10:52:08.923282 [ 1 ] {} <Error> Application: Caught exception while loading metadata: Code: 36, e.displayText() = DB::Exception: external dictionary 'events' not found: Cannot attach table '`data`' from query ATTACH TABLE data (`timestamp` DateTime, `EventID` UInt16, `Hostname` String, `Message` String, `category` String ALIAS dictGetOrDefault('events', 'category', toUInt64(EventID), toString(EventID)), `desc` String ALIAS dictGetOrDefault('events', 'description', toUInt64(EventID), toString(EventID))) ENGINE = ReplicatedMergeTree('/clickhouse/tables/events_data', '{replica}') PARTITION BY toYYYYMMDD(timestamp) ORDER BY (EventID, timestamp) SAMPLE BY EventID, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. 0xbc31d9c Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int)  in /usr/bin/clickhouse\r\n1. 0x4f6ccd9 DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int)  in /usr/bin/clickhouse\r\n2. 0x4b84c83 ?  in /usr/bin/clickhouse\r\n3. 0x8bc783f std::__1::shared_ptr<DB::IExternalLoadable const> DB::ExternalLoader::load<std::__1::shared_ptr<DB::IExternalLoadable const>, void>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const  in /usr/bin/clickhouse\r\n4. 0x54f9a2c DB::FunctionDictGetNoTypeOrDefault::getReturnTypeImpl(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&) const  in /usr/bin/clickhouse\r\n5. 0x514e5f5 DB::DefaultOverloadResolver::getReturnType(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&) const  in /usr/bin/clickhouse\r\n6. 0x584ceb6 DB::FunctionOverloadResolverAdaptor::getReturnTypeWithoutLowCardinality(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&) const  in /usr/bin/clickhouse\r\n7. 0x584d28e DB::FunctionOverloadResolverAdaptor::getReturnType(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&) const  in /usr/bin/clickhouse\r\n8. 0x5386036 DB::FunctionOverloadResolverAdaptor::build(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&) const  in /usr/bin/clickhouse\r\n9. 0x967affe DB::ExpressionActions::addImpl(DB::ExpressionAction, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >&)  in /usr/bin/clickhouse\r\n10. 0x967b1e9 DB::ExpressionActions::add(DB::ExpressionAction const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >&)  in /usr/bin/clickhouse\r\n11. 0x9817c41 DB::ScopeStack::addAction(DB::ExpressionAction const&)  in /usr/bin/clickhouse\r\n12. 0x981d795 DB::ActionsMatcher::visit(DB::ASTFunction const&, std::__1::shared_ptr<DB::IAST> const&, DB::ActionsMatcher::Data&)  in /usr/bin/clickhouse\r\n13. 0x981bff6 DB::ActionsMatcher::visit(DB::ASTFunction const&, std::__1::shared_ptr<DB::IAST> const&, DB::ActionsMatcher::Data&)  in /usr/bin/clickhouse\r\n14. 0x96902f5 DB::InDepthNodeVisitor<DB::ActionsMatcher, true, std::__1::shared_ptr<DB::IAST> const>::visit(std::__1::shared_ptr<DB::IAST> const&)  in /usr/bin/clickhouse\r\n15. 0x9687b11 ?  in /usr/bin/clickhouse\r\n16. 0x9689ab5 DB::ExpressionAnalyzer::getActions(bool, bool)  in /usr/bin/clickhouse\r\n17. 0x8bd7e2c DB::InterpreterCreateQuery::getColumnsDescription(DB::ASTExpressionList const&, DB::Context const&)  in /usr/bin/clickhouse\r\n18. 0x9549a6a DB::createTableFromAST(DB::ASTCreateQuery, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool)  in /usr/bin/clickhouse\r\n19. 0x954f395 ?  in /usr/bin/clickhouse\r\n20. 0x954fab7 ?  in /usr/bin/clickhouse\r\n21. 0x4fa4657 ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>)  in /usr/bin/clickhouse\r\n22. 0x4fa4c84 ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const  in /usr/bin/clickhouse\r\n23. 0x4fa3b77 ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>)  in /usr/bin/clickhouse\r\n24. 0x4fa212f ?  in /usr/bin/clickhouse\r\n25. 0x76db start_thread  in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n26. 0x12188f clone  in /lib/x86_64-linux-gnu/libc-2.27.so\r\n (version 20.1.2.4 (official build))\r\n```\r\n\n@Relecto thanks for the test case. Could you try `dictGetOrDefault` with `db.table` for the first argument? It might be related to https://github.com/ClickHouse/ClickHouse/pull/8329 . \nWhich db and table should I specify? The dictionary is defined in configuration file, do I have to create it with DDL first?\nlook like bug have same reason as https://github.com/ClickHouse/ClickHouse/issues/10397\ntopological sorting/dependencies analysis is a very good option, but relatively big/complicated.\r\n\r\nThat will allow solving issues like https://github.com/ClickHouse/ClickHouse/issues/7944 (needed for example to backup recovery) and will require to detect all possible dependencies between tables (there are a lot of non-obvious) - nice for schema static analysis\r\n\r\nThere is also the 'naive' option that is easy to implement: https://github.com/ClickHouse/ClickHouse/issues/13059#issuecomment-694127022 (good enough for most of the simple cases) \r\n\r\nSome side nodes: IMHO it's stupid we need to LOAD dictionary data to get the type of the fields which exist in dict definition in explicit form - see https://github.com/ClickHouse/ClickHouse/issues/10729 (if it would work we would be able to init dictionaries w/o loading their data, and after that, we should be able to ATTACH tables which depends on that. \r\n\r\n\nSee also https://github.com/ClickHouse/ClickHouse/issues/4717#issuecomment-736346712 \n#13359",
  "created_at": "2021-08-30T19:35:53Z",
  "modified_files": [
    "programs/local/LocalServer.cpp",
    "programs/server/Server.cpp",
    "src/Backups/renameInCreateQuery.cpp",
    "src/Core/QualifiedTableName.h",
    "b/src/Databases/DDLDependencyVisitor.cpp",
    "b/src/Databases/DDLDependencyVisitor.h",
    "src/Databases/DatabaseAtomic.cpp",
    "src/Databases/DatabaseAtomic.h",
    "src/Databases/DatabaseLazy.cpp",
    "src/Databases/DatabaseLazy.h",
    "src/Databases/DatabaseOnDisk.cpp",
    "src/Databases/DatabaseOnDisk.h",
    "src/Databases/DatabaseOrdinary.cpp",
    "src/Databases/DatabaseOrdinary.h",
    "src/Databases/DatabaseReplicated.cpp",
    "src/Databases/DatabaseReplicated.h",
    "src/Databases/IDatabase.h",
    "src/Databases/MySQL/DatabaseMaterializedMySQL.cpp",
    "src/Databases/MySQL/DatabaseMaterializedMySQL.h",
    "src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.cpp",
    "src/Databases/PostgreSQL/DatabaseMaterializedPostgreSQL.h",
    "b/src/Databases/TablesLoader.cpp",
    "b/src/Databases/TablesLoader.h",
    "src/Dictionaries/PostgreSQLDictionarySource.cpp",
    "src/Dictionaries/XDBCDictionarySource.cpp",
    "src/Dictionaries/getDictionaryConfigurationFromAST.cpp",
    "src/Dictionaries/getDictionaryConfigurationFromAST.h",
    "src/Functions/FunctionJoinGet.cpp",
    "src/Interpreters/DatabaseCatalog.cpp",
    "src/Interpreters/ExternalDictionariesLoader.cpp",
    "src/Interpreters/ExternalDictionariesLoader.h",
    "src/Interpreters/InterpreterCreateQuery.cpp",
    "src/Interpreters/InterpreterCreateQuery.h",
    "src/Interpreters/InterpreterDropQuery.cpp",
    "src/Interpreters/loadMetadata.cpp",
    "src/Interpreters/loadMetadata.h",
    "src/TableFunctions/TableFunctionRemote.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_dictionaries_dependency_xml/test.py",
    "b/tests/queries/0_stateless/01160_table_dependencies.reference",
    "b/tests/queries/0_stateless/01160_table_dependencies.sh",
    "tests/queries/0_stateless/01372_remote_table_function_empty_table.sql"
  ]
}