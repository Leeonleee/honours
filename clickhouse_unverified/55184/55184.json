{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 55184,
  "instance_id": "ClickHouse__ClickHouse-55184",
  "issue_numbers": [
    "55174"
  ],
  "base_commit": "9aaab2737335911bae09233096c35828d4707215",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex acaea8b086de..14366ff7a43d 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -2628,97 +2628,6 @@ void MergeTreeData::clearPartsFromFilesystemImpl(const DataPartsVector & parts_t\n                         \"({} != {} + {}), it's a bug\", parts_to_remove.size(), sum_of_ranges, excluded_parts.size());\n }\n \n-size_t MergeTreeData::clearOldBrokenPartsFromDetachedDirectory()\n-{\n-    /**\n-     * Remove old (configured by setting) broken detached parts.\n-     * Only parts with certain prefixes are removed. These prefixes\n-     * are such that it is guaranteed that they will never be needed\n-     * and need to be cleared. ctime is used to check when file was\n-     * moved to detached/ directory (see https://unix.stackexchange.com/a/211134)\n-     */\n-\n-    DetachedPartsInfo detached_parts = getDetachedParts();\n-    if (detached_parts.empty())\n-        return 0;\n-\n-    auto get_last_touched_time = [&](const DetachedPartInfo & part_info) -> time_t\n-    {\n-        auto path = fs::path(relative_data_path) / \"detached\" / part_info.dir_name;\n-        time_t last_change_time = part_info.disk->getLastChanged(path);\n-        time_t last_modification_time = part_info.disk->getLastModified(path).epochTime();\n-        return std::max(last_change_time, last_modification_time);\n-    };\n-\n-    time_t ttl_seconds = getSettings()->merge_tree_clear_old_broken_detached_parts_ttl_timeout_seconds;\n-\n-    size_t unfinished_deleting_parts = 0;\n-    time_t current_time = time(nullptr);\n-    for (const auto & part_info : detached_parts)\n-    {\n-        if (!part_info.dir_name.starts_with(\"deleting_\"))\n-            continue;\n-\n-        time_t startup_time = current_time - static_cast<time_t>(Context::getGlobalContextInstance()->getUptimeSeconds());\n-        time_t last_touch_time = get_last_touched_time(part_info);\n-\n-        /// Maybe it's being deleted right now (for example, in ALTER DROP DETACHED)\n-        bool had_restart = last_touch_time < startup_time;\n-        bool ttl_expired = last_touch_time + ttl_seconds <= current_time;\n-        if (!had_restart && !ttl_expired)\n-            continue;\n-\n-        /// We were trying to delete this detached part but did not finish deleting, probably because the server crashed\n-        LOG_INFO(log, \"Removing detached part {} that we failed to remove previously\", part_info.dir_name);\n-        try\n-        {\n-            removeDetachedPart(part_info.disk, fs::path(relative_data_path) / \"detached\" / part_info.dir_name / \"\", part_info.dir_name);\n-            ++unfinished_deleting_parts;\n-        }\n-        catch (...)\n-        {\n-            tryLogCurrentException(log);\n-        }\n-    }\n-\n-    if (!getSettings()->merge_tree_enable_clear_old_broken_detached)\n-        return unfinished_deleting_parts;\n-\n-    const auto full_path = fs::path(relative_data_path) / \"detached\";\n-    size_t removed_count = 0;\n-    for (const auto & part_info : detached_parts)\n-    {\n-        if (!part_info.valid_name || part_info.prefix.empty())\n-            continue;\n-\n-        const auto & removable_detached_parts_prefixes = DetachedPartInfo::DETACHED_REASONS_REMOVABLE_BY_TIMEOUT;\n-        bool can_be_removed_by_timeout = std::find(\n-            removable_detached_parts_prefixes.begin(),\n-            removable_detached_parts_prefixes.end(),\n-            part_info.prefix) != removable_detached_parts_prefixes.end();\n-\n-        if (!can_be_removed_by_timeout)\n-            continue;\n-\n-        ssize_t threshold = current_time - ttl_seconds;\n-        time_t last_touch_time = get_last_touched_time(part_info);\n-\n-        if (last_touch_time == 0 || last_touch_time >= threshold)\n-            continue;\n-\n-        const String & old_name = part_info.dir_name;\n-        String new_name = \"deleting_\" + part_info.dir_name;\n-        part_info.disk->moveFile(fs::path(full_path) / old_name, fs::path(full_path) / new_name);\n-\n-        removeDetachedPart(part_info.disk, fs::path(relative_data_path) / \"detached\" / new_name / \"\", old_name);\n-        LOG_WARNING(log, \"Removed broken detached part {} due to a timeout for broken detached parts\", old_name);\n-        ++removed_count;\n-    }\n-\n-    LOG_INFO(log, \"Cleaned up {} detached parts\", removed_count);\n-\n-    return removed_count + unfinished_deleting_parts;\n-}\n \n size_t MergeTreeData::clearOldWriteAheadLogs()\n {\ndiff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h\nindex 63508fff9eb1..5fb26f9a057b 100644\n--- a/src/Storages/MergeTree/MergeTreeData.h\n+++ b/src/Storages/MergeTree/MergeTreeData.h\n@@ -692,8 +692,6 @@ class MergeTreeData : public IStorage, public WithMutableContext\n     /// Delete WAL files containing parts, that all already stored on disk.\n     size_t clearOldWriteAheadLogs();\n \n-    size_t clearOldBrokenPartsFromDetachedDirectory();\n-\n     /// Delete all directories which names begin with \"tmp\"\n     /// Must be called with locked lockForShare() because it's using relative_data_path.\n     size_t clearOldTemporaryDirectories(size_t custom_directories_lifetime_seconds, const NameSet & valid_prefixes = {\"tmp_\", \"tmp-fetch_\"});\ndiff --git a/src/Storages/MergeTree/MergeTreeSettings.h b/src/Storages/MergeTree/MergeTreeSettings.h\nindex cee910dc185a..dbae87b0c5e7 100644\n--- a/src/Storages/MergeTree/MergeTreeSettings.h\n+++ b/src/Storages/MergeTree/MergeTreeSettings.h\n@@ -63,11 +63,9 @@ struct Settings;\n     M(Float, merge_selecting_sleep_slowdown_factor, 1.2f, \"The sleep time for merge selecting task is multiplied by this factor when there's nothing to merge and divided when a merge was assigned\", 0) \\\n     M(UInt64, merge_tree_clear_old_temporary_directories_interval_seconds, 60, \"The period of executing the clear old temporary directories operation in background.\", 0) \\\n     M(UInt64, merge_tree_clear_old_parts_interval_seconds, 1, \"The period of executing the clear old parts operation in background.\", 0) \\\n-    M(UInt64, merge_tree_clear_old_broken_detached_parts_ttl_timeout_seconds, 1ULL * 3600 * 24 * 30, \"Remove old broken detached parts in the background if they remained intouched for a specified by this setting period of time.\", 0) \\\n     M(UInt64, min_age_to_force_merge_seconds, 0, \"If all parts in a certain range are older than this value, range will be always eligible for merging. Set to 0 to disable.\", 0) \\\n     M(Bool, min_age_to_force_merge_on_partition_only, false, \"Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.\", false) \\\n     M(UInt64, number_of_free_entries_in_pool_to_execute_optimize_entire_partition, 25, \"When there is less than specified number of free entries in pool, do not try to execute optimize entire partition with a merge (this merge is created when set min_age_to_force_merge_seconds > 0 and min_age_to_force_merge_on_partition_only = true). This is to leave free threads for regular merges and avoid \\\"Too many parts\\\"\", 0) \\\n-    M(UInt64, merge_tree_enable_clear_old_broken_detached, false, \"Enable clearing old broken detached parts operation in background.\", 0) \\\n     M(Bool, remove_rolled_back_parts_immediately, 1, \"Setting for an incomplete experimental feature.\", 0) \\\n     M(CleanDeletedRows, clean_deleted_rows, CleanDeletedRows::Never, \"Is the Replicated Merge cleanup has to be done automatically at each merge or manually (possible values are 'Always'/'Never' (default))\", 0) \\\n     M(UInt64, replicated_max_mutations_in_one_entry, 10000, \"Max number of mutation commands that can be merged together and executed in one MUTATE_PART entry (0 means unlimited)\", 0) \\\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp\nindex 5de3c9f5d403..c425e11419d3 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp\n@@ -155,7 +155,6 @@ Float32 ReplicatedMergeTreeCleanupThread::iterate()\n         /// do it under share lock\n         cleaned_other += storage.clearOldWriteAheadLogs();\n         cleaned_part_like += storage.clearOldTemporaryDirectories(storage.getSettings()->temporary_directories_lifetime.totalSeconds());\n-        cleaned_part_like += storage.clearOldBrokenPartsFromDetachedDirectory();\n     }\n \n     /// This is loose condition: no problem if we actually had lost leadership at this moment\ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex e32fff79adca..6ae3cdef2a76 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -1385,7 +1385,6 @@ bool StorageMergeTree::scheduleDataProcessingJob(BackgroundJobsAssignee & assign\n                 cleared_count += clearOldWriteAheadLogs();\n                 cleared_count += clearOldMutations();\n                 cleared_count += clearEmptyParts();\n-                cleared_count += clearOldBrokenPartsFromDetachedDirectory();\n                 return cleared_count;\n                 /// TODO maybe take into account number of cleared objects when calculating backoff\n             }, common_assignee_trigger, getStorageID()), /* need_trigger */ false);\n",
  "test_patch": "diff --git a/tests/integration/test_broken_detached_part_clean_up/__init__.py b/tests/integration/test_broken_detached_part_clean_up/__init__.py\ndeleted file mode 100644\nindex e69de29bb2d1..000000000000\ndiff --git a/tests/integration/test_broken_detached_part_clean_up/configs/store_cleanup.xml b/tests/integration/test_broken_detached_part_clean_up/configs/store_cleanup.xml\ndeleted file mode 100644\nindex 5fbe87cce006..000000000000\n--- a/tests/integration/test_broken_detached_part_clean_up/configs/store_cleanup.xml\n+++ /dev/null\n@@ -1,11 +0,0 @@\n-<clickhouse>\n-    <database_catalog_unused_dir_hide_timeout_sec>0</database_catalog_unused_dir_hide_timeout_sec>\n-    <database_catalog_unused_dir_rm_timeout_sec>60</database_catalog_unused_dir_rm_timeout_sec>\n-    <database_catalog_unused_dir_cleanup_period_sec>1</database_catalog_unused_dir_cleanup_period_sec>\n-\n-    <!-- We don't really need [Zoo]Keeper for this test.\n-    And it makes sense to have at least one test with TestKeeper. -->\n-    <zookeeper>\n-        <implementation>testkeeper</implementation>\n-    </zookeeper>\n-</clickhouse>\n\\ No newline at end of file\ndiff --git a/tests/integration/test_broken_detached_part_clean_up/test.py b/tests/integration/test_broken_detached_part_clean_up/test.py\ndeleted file mode 100644\nindex bdf993ddedfe..000000000000\n--- a/tests/integration/test_broken_detached_part_clean_up/test.py\n+++ /dev/null\n@@ -1,360 +0,0 @@\n-import pytest\n-\n-from helpers.cluster import ClickHouseCluster\n-from helpers.corrupt_part_data_on_disk import corrupt_part_data_on_disk\n-from helpers.corrupt_part_data_on_disk import break_part\n-import time\n-\n-cluster = ClickHouseCluster(__file__)\n-\n-node1 = cluster.add_instance(\n-    \"node1\", stay_alive=True, main_configs=[\"configs/store_cleanup.xml\"]\n-)\n-\n-path_to_data = \"/var/lib/clickhouse/\"\n-\n-\n-@pytest.fixture(scope=\"module\")\n-def started_cluster():\n-    try:\n-        cluster.start()\n-        yield cluster\n-\n-    finally:\n-        cluster.shutdown()\n-\n-\n-def remove_broken_detached_part_impl(table, node, expect_broken_prefix):\n-    assert (\n-        node.query(\n-            f\"SELECT COUNT() FROM system.parts WHERE table='{table}' AND active=1\"\n-        )\n-        == \"4\\n\"\n-    )\n-\n-    path_to_detached = path_to_data + f\"data/default/{table}/detached/\"\n-\n-    result = node.exec_in_container([\"ls\", path_to_detached])\n-    assert result.strip() == \"\"\n-\n-    corrupt_part_data_on_disk(node, table, \"all_3_3_0\")\n-    break_part(node, table, \"all_3_3_0\")\n-    node.query(f\"ALTER TABLE {table} DETACH PART 'all_1_1_0'\")\n-    result = node.exec_in_container([\"touch\", f\"{path_to_detached}trash\"])\n-\n-    node.exec_in_container([\"mkdir\", f\"{path_to_detached}../broken_all_fake\"])\n-    node.exec_in_container(\n-        [\"touch\", \"-t\", \"1312031429.30\", f\"{path_to_detached}../broken_all_fake\"]\n-    )\n-    result = node.exec_in_container([\"stat\", f\"{path_to_detached}../broken_all_fake\"])\n-    print(result)\n-    assert \"Modify: 2013-12-03\" in result\n-    node.exec_in_container(\n-        [\n-            \"mv\",\n-            f\"{path_to_detached}../broken_all_fake\",\n-            f\"{path_to_detached}broken_all_fake\",\n-        ]\n-    )\n-\n-    for name in [\n-        \"unexpected_all_42_1337_5\",\n-        \"deleting_all_123_456_7\",\n-        \"covered-by-broken_all_12_34_5\",\n-    ]:\n-        node.exec_in_container([\"mkdir\", f\"{path_to_detached}../{name}\"])\n-        node.exec_in_container(\n-            [\n-                \"touch\",\n-                \"-t\",\n-                \"1312031429.30\",\n-                f\"{path_to_detached}../{name}\",\n-            ]\n-        )\n-        result = node.exec_in_container([\"stat\", f\"{path_to_detached}../{name}\"])\n-        print(result)\n-        assert \"Modify: 2013-12-03\" in result\n-        node.exec_in_container(\n-            [\n-                \"mv\",\n-                f\"{path_to_detached}../{name}\",\n-                f\"{path_to_detached}{name}\",\n-            ]\n-        )\n-\n-    result = node.query(\n-        f\"CHECK TABLE {table}\", settings={\"check_query_single_value_result\": 0}\n-    )\n-    assert \"all_3_3_0\\t0\" in result\n-\n-    node.query(f\"DETACH TABLE {table}\")\n-    node.query(f\"ATTACH TABLE {table}\")\n-\n-    node.wait_for_log_line(\n-        \"Removing detached part deleting_all_123_456_7\",\n-        timeout=90,\n-        look_behind_lines=1000000,\n-    )\n-    node.wait_for_log_line(\n-        f\"Removed broken detached part {expect_broken_prefix}_all_3_3_0 due to a timeout\",\n-        timeout=10,\n-        look_behind_lines=1000000,\n-    )\n-    node.wait_for_log_line(\n-        \"Removed broken detached part unexpected_all_42_1337_5 due to a timeout\",\n-        timeout=10,\n-        look_behind_lines=1000000,\n-    )\n-\n-    result = node.exec_in_container([\"ls\", path_to_detached])\n-    print(result)\n-    assert f\"{expect_broken_prefix}_all_3_3_0\" not in result\n-    assert \"all_1_1_0\" in result\n-    assert \"trash\" in result\n-    assert \"broken_all_fake\" in result\n-    assert \"covered-by-broken_all_12_34_5\" in result\n-    assert \"unexpected_all_42_1337_5\" not in result\n-    assert \"deleting_all_123_456_7\" not in result\n-\n-    node.query(\n-        f\"ALTER TABLE {table} DROP DETACHED PART 'covered-by-broken_all_12_34_5'\",\n-        settings={\"allow_drop_detached\": 1},\n-    )\n-    result = node.exec_in_container([\"ls\", path_to_detached])\n-    assert \"covered-by-broken_all_12_34_5\" not in result\n-\n-    node.query(f\"DROP TABLE {table} SYNC\")\n-\n-\n-def test_remove_broken_detached_part_merge_tree(started_cluster):\n-    node1.query(\n-        \"\"\"\n-        CREATE TABLE\n-            mt(id UInt32, value Int32)\n-        ENGINE = MergeTree() ORDER BY id\n-        SETTINGS\n-            merge_tree_enable_clear_old_broken_detached=1,\n-            merge_tree_clear_old_broken_detached_parts_ttl_timeout_seconds=5;\n-        \"\"\"\n-    )\n-\n-    for i in range(4):\n-        node1.query(\n-            f\"INSERT INTO mt SELECT number, number * number FROM numbers ({i * 100000}, 100000)\"\n-        )\n-\n-    remove_broken_detached_part_impl(\"mt\", node1, \"broken-on-start\")\n-\n-\n-def test_remove_broken_detached_part_replicated_merge_tree(started_cluster):\n-    node1.query(\n-        f\"\"\"\n-        CREATE TABLE\n-            replicated_mt(date Date, id UInt32, value Int32)\n-        ENGINE = ReplicatedMergeTree('/clickhouse/tables/replicated_mt', '{node1.name}') ORDER BY id\n-        SETTINGS\n-            merge_tree_enable_clear_old_broken_detached=1,\n-            merge_tree_clear_old_broken_detached_parts_ttl_timeout_seconds=5,\n-            cleanup_delay_period=1,\n-            cleanup_delay_period_random_add=0,\n-            cleanup_thread_preferred_points_per_iteration=0;\n-        \"\"\"\n-    )\n-\n-    for i in range(4):\n-        node1.query(\n-            f\"INSERT INTO replicated_mt SELECT toDate('2019-10-01'), number, number * number FROM numbers ({i * 100000}, 100000)\"\n-        )\n-\n-    remove_broken_detached_part_impl(\"replicated_mt\", node1, \"broken\")\n-\n-\n-def test_store_cleanup(started_cluster):\n-    node1.query(\"CREATE DATABASE db UUID '10000000-1000-4000-8000-000000000001'\")\n-    node1.query(\n-        \"CREATE TABLE db.log UUID '10000000-1000-4000-8000-000000000002' ENGINE=Log AS SELECT 1\"\n-    )\n-    node1.query(\n-        \"CREATE TABLE db.mt UUID '10000000-1000-4000-8000-000000000003' ENGINE=MergeTree ORDER BY tuple() AS SELECT 1\"\n-    )\n-    node1.query(\n-        \"CREATE TABLE db.mem UUID '10000000-1000-4000-8000-000000000004' ENGINE=Memory AS SELECT 1\"\n-    )\n-\n-    node1.query(\"CREATE DATABASE db2 UUID '20000000-1000-4000-8000-000000000001'\")\n-    node1.query(\n-        \"CREATE TABLE db2.log UUID '20000000-1000-4000-8000-000000000002' ENGINE=Log AS SELECT 1\"\n-    )\n-    node1.query(\"DETACH DATABASE db2\")\n-\n-    node1.query(\"CREATE DATABASE db3 UUID '30000000-1000-4000-8000-000000000001'\")\n-    node1.query(\n-        \"CREATE TABLE db3.log UUID '30000000-1000-4000-8000-000000000002' ENGINE=Log AS SELECT 1\"\n-    )\n-    node1.query(\n-        \"CREATE TABLE db3.log2 UUID '30000000-1000-4000-8000-000000000003' ENGINE=Log AS SELECT 1\"\n-    )\n-    node1.query(\"DETACH TABLE db3.log\")\n-    node1.query(\"DETACH TABLE db3.log2 PERMANENTLY\")\n-\n-    assert \"d---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store\"]\n-    )\n-    assert \"d---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/100\"]\n-    )\n-    assert \"d---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/200\"]\n-    )\n-    assert \"d---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/300\"]\n-    )\n-\n-    node1.stop_clickhouse(kill=True)\n-    # All dirs related to `db` will be removed\n-    node1.exec_in_container([\"rm\", f\"{path_to_data}/metadata/db.sql\"])\n-\n-    node1.exec_in_container([\"mkdir\", f\"{path_to_data}/store/kek\"])\n-    node1.exec_in_container([\"touch\", f\"{path_to_data}/store/12\"])\n-    try:\n-        node1.exec_in_container([\"mkdir\", f\"{path_to_data}/store/456\"])\n-    except Exception as e:\n-        print(\"Failed to create 456/:\", str(e))\n-    node1.exec_in_container([\"mkdir\", f\"{path_to_data}/store/456/testgarbage\"])\n-    node1.exec_in_container(\n-        [\"mkdir\", f\"{path_to_data}/store/456/30000000-1000-4000-8000-000000000003\"]\n-    )\n-    node1.exec_in_container(\n-        [\"touch\", f\"{path_to_data}/store/456/45600000-1000-4000-8000-000000000003\"]\n-    )\n-    node1.exec_in_container(\n-        [\"mkdir\", f\"{path_to_data}/store/456/45600000-1000-4000-8000-000000000004\"]\n-    )\n-\n-    node1.start_clickhouse()\n-    node1.query(\"DETACH DATABASE db2\")\n-    node1.query(\"DETACH TABLE db3.log\")\n-\n-    node1.wait_for_log_line(\n-        \"Removing access rights for unused directory\",\n-        timeout=60,\n-        look_behind_lines=1000000,\n-    )\n-    node1.wait_for_log_line(\n-        \"directories from store\", timeout=60, look_behind_lines=1000000\n-    )\n-\n-    store = node1.exec_in_container([\"ls\", f\"{path_to_data}/store\"])\n-    assert \"100\" in store\n-    assert \"200\" in store\n-    assert \"300\" in store\n-    assert \"456\" in store\n-    assert \"kek\" in store\n-    assert \"12\" in store\n-    assert \"d---------\" in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store\"]\n-    )\n-    assert \"d---------\" in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/456\"]\n-    )\n-\n-    # Metadata is removed, so store/100 contains garbage\n-    store100 = node1.exec_in_container([\"ls\", f\"{path_to_data}/store/100\"])\n-    assert \"10000000-1000-4000-8000-000000000001\" in store100\n-    assert \"10000000-1000-4000-8000-000000000002\" in store100\n-    assert \"10000000-1000-4000-8000-000000000003\" in store100\n-    assert \"d---------\" in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/100\"]\n-    )\n-\n-    # Database is detached, nothing to clean up\n-    store200 = node1.exec_in_container([\"ls\", f\"{path_to_data}/store/200\"])\n-    assert \"20000000-1000-4000-8000-000000000001\" in store200\n-    assert \"20000000-1000-4000-8000-000000000002\" in store200\n-    assert \"d---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/200\"]\n-    )\n-\n-    # Tables are detached, nothing to clean up\n-    store300 = node1.exec_in_container([\"ls\", f\"{path_to_data}/store/300\"])\n-    assert \"30000000-1000-4000-8000-000000000001\" in store300\n-    assert \"30000000-1000-4000-8000-000000000002\" in store300\n-    assert \"30000000-1000-4000-8000-000000000003\" in store300\n-    assert \"d---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/300\"]\n-    )\n-\n-    # Manually created garbage\n-    store456 = node1.exec_in_container([\"ls\", f\"{path_to_data}/store/456\"])\n-    assert \"30000000-1000-4000-8000-000000000003\" in store456\n-    assert \"45600000-1000-4000-8000-000000000003\" in store456\n-    assert \"45600000-1000-4000-8000-000000000004\" in store456\n-    assert \"testgarbage\" in store456\n-    assert \"----------\" in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/456\"]\n-    )\n-\n-    node1.wait_for_log_line(\n-        \"Removing unused directory\", timeout=90, look_behind_lines=1000000\n-    )\n-    node1.wait_for_log_line(\n-        \"directories from store\", timeout=90, look_behind_lines=1000000\n-    )\n-    node1.wait_for_log_line(\n-        \"Nothing to clean up from store/\", timeout=90, look_behind_lines=1000000\n-    )\n-\n-    store = node1.exec_in_container([\"ls\", f\"{path_to_data}/store\"])\n-    assert \"100\" in store\n-    assert \"200\" in store\n-    assert \"300\" in store\n-    assert \"456\" in store\n-    assert \"kek\" not in store  # changed\n-    assert \"\\n12\\n\" not in store  # changed\n-    assert \"d---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store\"]\n-    )  # changed\n-\n-    # Metadata is removed, so store/100 contains garbage\n-    store100 = node1.exec_in_container([\"ls\", f\"{path_to_data}/store/100\"])  # changed\n-    assert \"10000000-1000-4000-8000-000000000001\" not in store100  # changed\n-    assert \"10000000-1000-4000-8000-000000000002\" not in store100  # changed\n-    assert \"10000000-1000-4000-8000-000000000003\" not in store100  # changed\n-    assert \"d---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/100\"]\n-    )  # changed\n-\n-    # Database is detached, nothing to clean up\n-    store200 = node1.exec_in_container([\"ls\", f\"{path_to_data}/store/200\"])\n-    assert \"20000000-1000-4000-8000-000000000001\" in store200\n-    assert \"20000000-1000-4000-8000-000000000002\" in store200\n-    assert \"d---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/200\"]\n-    )\n-\n-    # Tables are detached, nothing to clean up\n-    store300 = node1.exec_in_container([\"ls\", f\"{path_to_data}/store/300\"])\n-    assert \"30000000-1000-4000-8000-000000000001\" in store300\n-    assert \"30000000-1000-4000-8000-000000000002\" in store300\n-    assert \"30000000-1000-4000-8000-000000000003\" in store300\n-    assert \"d---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/300\"]\n-    )\n-\n-    # Manually created garbage\n-    store456 = node1.exec_in_container([\"ls\", f\"{path_to_data}/store/456\"])\n-    assert \"30000000-1000-4000-8000-000000000003\" not in store456  # changed\n-    assert \"45600000-1000-4000-8000-000000000003\" not in store456  # changed\n-    assert \"45600000-1000-4000-8000-000000000004\" not in store456  # changed\n-    assert \"testgarbage\" not in store456  # changed\n-    assert \"---------\" not in node1.exec_in_container(\n-        [\"ls\", \"-l\", f\"{path_to_data}/store/456\"]\n-    )  # changed\n-\n-    node1.query(\"ATTACH TABLE db3.log2\")\n-    node1.query(\"ATTACH DATABASE db2\")\n-    node1.query(\"ATTACH TABLE db3.log\")\n-\n-    assert \"1\\n\" == node1.query(\"SELECT * FROM db3.log\")\n-    assert \"1\\n\" == node1.query(\"SELECT * FROM db3.log2\")\n-    assert \"1\\n\" == node1.query(\"SELECT * FROM db2.log\")\n",
  "problem_statement": "Remove the removal of broken detached parts\nThis is a harmful feature - it has to be removed.\r\nIf there are broken parts, it requires immediate attention of an engineer.\r\nThey should never be deleted.\r\n\r\nI remember this feature was added by one customer because they asked too many times.\r\nBut the truth is - the introduction of this feature is harmful even for that customer.\n",
  "hints_text": "",
  "created_at": "2023-09-29T23:48:44Z",
  "modified_files": [
    "src/Storages/MergeTree/MergeTreeData.cpp",
    "src/Storages/MergeTree/MergeTreeData.h",
    "src/Storages/MergeTree/MergeTreeSettings.h",
    "src/Storages/MergeTree/ReplicatedMergeTreeCleanupThread.cpp",
    "src/Storages/StorageMergeTree.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_broken_detached_part_clean_up/configs/store_cleanup.xml",
    "tests/integration/test_broken_detached_part_clean_up/test.py"
  ]
}