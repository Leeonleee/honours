{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 32751,
  "instance_id": "ClickHouse__ClickHouse-32751",
  "issue_numbers": [
    "32668"
  ],
  "base_commit": "ebdf4d2702bcf773b01aec59780211d207073727",
  "patch": "diff --git a/src/Interpreters/SelectQueryOptions.h b/src/Interpreters/SelectQueryOptions.h\nindex 709ecdc239ce..bc95a940c18a 100644\n--- a/src/Interpreters/SelectQueryOptions.h\n+++ b/src/Interpreters/SelectQueryOptions.h\n@@ -41,6 +41,9 @@ struct SelectQueryOptions\n     /// It is needed because lazy normal projections require special planning in FetchColumns stage, such as adding WHERE transform.\n     /// It is also used to avoid adding aggregating step when aggregate projection is chosen.\n     bool is_projection_query = false;\n+    /// This flag is needed for projection description.\n+    /// Otherwise, keys for GROUP BY may be removed as constants.\n+    bool ignore_ast_optimizations = false;\n     bool ignore_alias = false;\n     bool is_internal = false;\n     bool is_subquery = false; // non-subquery can also have subquery_depth > 0, e.g. insert select\n@@ -120,6 +123,12 @@ struct SelectQueryOptions\n         return *this;\n     }\n \n+    SelectQueryOptions & ignoreASTOptimizationsAlias(bool value = true)\n+    {\n+        ignore_ast_optimizations = value;\n+        return *this;\n+    }\n+\n     SelectQueryOptions & setInternal(bool value = false)\n     {\n         is_internal = value;\ndiff --git a/src/Interpreters/TreeRewriter.cpp b/src/Interpreters/TreeRewriter.cpp\nindex 6b3a50d88e2a..0cb4597230ba 100644\n--- a/src/Interpreters/TreeRewriter.cpp\n+++ b/src/Interpreters/TreeRewriter.cpp\n@@ -1121,7 +1121,7 @@ TreeRewriterResultPtr TreeRewriter::analyzeSelect(\n     result.rewrite_subqueries = PredicateExpressionsOptimizer(getContext(), tables_with_columns, settings).optimize(*select_query);\n \n     /// Only apply AST optimization for initial queries.\n-    if (getContext()->getClientInfo().query_kind == ClientInfo::QueryKind::INITIAL_QUERY)\n+    if (getContext()->getClientInfo().query_kind != ClientInfo::QueryKind::SECONDARY_QUERY && !select_options.ignore_ast_optimizations)\n         TreeOptimizer::apply(query, result, tables_with_columns, getContext());\n \n     /// array_join_alias_to_name, array_join_result_to_source.\ndiff --git a/src/Storages/ProjectionsDescription.cpp b/src/Storages/ProjectionsDescription.cpp\nindex f1a0372a07d1..791583e24958 100644\n--- a/src/Storages/ProjectionsDescription.cpp\n+++ b/src/Storages/ProjectionsDescription.cpp\n@@ -201,7 +201,7 @@ ProjectionDescription ProjectionDescription::getMinMaxCountProjection(\n     select_expression_list->children.push_back(makeASTFunction(\"count\"));\n     select_query->setExpression(ASTProjectionSelectQuery::Expression::SELECT, std::move(select_expression_list));\n \n-    if (partition_columns)\n+    if (partition_columns && !partition_columns->children.empty())\n         select_query->setExpression(ASTProjectionSelectQuery::Expression::GROUP_BY, partition_columns->clone());\n \n     result.definition_ast = select_query;\n@@ -211,7 +211,9 @@ ProjectionDescription ProjectionDescription::getMinMaxCountProjection(\n     auto external_storage_holder = std::make_shared<TemporaryTableHolder>(query_context, columns, ConstraintsDescription{});\n     StoragePtr storage = external_storage_holder->getTable();\n     InterpreterSelectQuery select(\n-        result.query_ast, query_context, storage, {}, SelectQueryOptions{QueryProcessingStage::WithMergeableState}.modify().ignoreAlias());\n+        result.query_ast, query_context, storage, {},\n+        /// Here we ignore ast optimizations because otherwise aggregation keys may be removed from result header as constants.\n+        SelectQueryOptions{QueryProcessingStage::WithMergeableState}.modify().ignoreAlias().ignoreASTOptimizationsAlias());\n     result.required_columns = select.getRequiredColumns();\n     result.sample_block = select.getSampleBlock();\n \n",
  "test_patch": "diff --git a/tests/integration/test_storage_rabbitmq/test.py b/tests/integration/test_storage_rabbitmq/test.py\nindex 66ec97ac0279..5342473aefa6 100644\n--- a/tests/integration/test_storage_rabbitmq/test.py\n+++ b/tests/integration/test_storage_rabbitmq/test.py\n@@ -284,6 +284,12 @@ def test_rabbitmq_materialized_view(rabbitmq_cluster):\n             ORDER BY key;\n         CREATE MATERIALIZED VIEW test.consumer TO test.view AS\n             SELECT * FROM test.rabbitmq;\n+\n+        CREATE TABLE test.view2 (key UInt64, value UInt64)\n+            ENGINE = MergeTree()\n+            ORDER BY key;\n+        CREATE MATERIALIZED VIEW test.consumer2 TO test.view2 AS\n+            SELECT * FROM test.rabbitmq group by (key, value);\n     ''')\n \n     credentials = pika.PlainCredentials('root', 'clickhouse')\n@@ -297,14 +303,26 @@ def test_rabbitmq_materialized_view(rabbitmq_cluster):\n     for message in messages:\n         channel.basic_publish(exchange='mv', routing_key='', body=message)\n \n-    while True:\n+    time_limit_sec = 60\n+    deadline = time.monotonic() + time_limit_sec\n+\n+    while time.monotonic() < deadline:\n         result = instance.query('SELECT * FROM test.view ORDER BY key')\n         if (rabbitmq_check_result(result)):\n             break\n \n-    connection.close()\n     rabbitmq_check_result(result, True)\n \n+    deadline = time.monotonic() + time_limit_sec\n+\n+    while time.monotonic() < deadline:\n+        result = instance.query('SELECT * FROM test.view2 ORDER BY key')\n+        if (rabbitmq_check_result(result)):\n+            break\n+\n+    rabbitmq_check_result(result, True)\n+    connection.close()\n+\n \n def test_rabbitmq_materialized_view_with_subquery(rabbitmq_cluster):\n     instance.query('''\n",
  "problem_statement": "ReplacingMergeTree Materialized view based on kafka topics becoming empty after migrating to 21.11\n**Describe what's wrong**\r\n\r\nAfter Moving to 21.11, [ReplacingMergeTree-style Materialized view](https://github.com/tiniumv/clickhouse_bug/blob/main/migrations/add_view.sql) which is getting data from [two other views](https://github.com/tiniumv/clickhouse_bug/blob/main/migrations/basic.sql) based on kafka topics stopped to receive any data.\r\n\r\nSame requst ```select * from causing_problems_mv;```\r\non 21.10\r\n```\r\n\u250c\u2500field_a\u2500\u252c\u2500field_b\u2500\u252c\u2500field_c\u2500\u252c\u2500\u2500max_field_datetime\u2500\u2510\r\n\u2502 1       \u2502 type_a  \u2502       1 \u2502 2021-12-01 14:00:00 \u2502\r\n\u2502 2       \u2502 type_a  \u2502       2 \u2502 2021-12-01 13:00:00 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\nand on 21.11\r\n```\r\n0 rows in set. Elapsed: 0.002 sec.\r\n```\r\n\r\nMoreover, one of the source view (the one from left part of ```LEFT JOIN``` expression) went broken too. That was isolated - I tried to not create final view under 21.11, and it resulted in basic views working normally.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nYes.\r\n\r\n**How to reproduce**\r\n\r\nRepository with everything needed to replicate bug: https://github.com/tiniumv/clickhouse_bug . There are two branches, main (with 21.10 CH) and 21.11\r\n\r\n**Expected behavior**\r\n\r\nI was expecting result of provided queries to be identical independently from ClickHouse version.\r\n\r\n**Error message and/or stacktrace**\r\n\r\n[I have collected all logs](https://raw.githubusercontent.com/tiniumv/clickhouse_bug/21.11/logs/clickhouse-server.err.log)\r\nit says that ```Column `field_a` is not under aggregate function and not in GROUP BY: While processing field_a, field_b, argMax(field_c, field_datetime) AS field_c, max(field_datetime) AS max_field_datetime.```, but it clearly is\r\n\r\n**Additional context**\r\n\r\nWhile request ```select * from table_ii;``` returns nothing, ```select * from table_ii_queue;``` spits out all lost messages\r\n\n",
  "hints_text": "Try to replace\r\n\r\nGROUP BY    (field_b, field_a);\r\n\r\nwith\r\n\r\nGROUP BY    field_b, field_a;\n@SaltTan Thank you, it worked!\r\n\r\n",
  "created_at": "2021-12-14T14:23:28Z"
}