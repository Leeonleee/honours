{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 2665,
  "instance_id": "ClickHouse__ClickHouse-2665",
  "issue_numbers": [
    "2645"
  ],
  "base_commit": "02f7b9648429fc34e03eab01ed3c858b6adf69a3",
  "patch": "diff --git a/dbms/src/DataStreams/SummingSortedBlockInputStream.cpp b/dbms/src/DataStreams/SummingSortedBlockInputStream.cpp\nindex 85b8d70f2964..a56b2928fc54 100644\n--- a/dbms/src/DataStreams/SummingSortedBlockInputStream.cpp\n+++ b/dbms/src/DataStreams/SummingSortedBlockInputStream.cpp\n@@ -323,22 +323,24 @@ void SummingSortedBlockInputStream::merge(MutableColumns & merged_columns, std::\n \n         if (current_key.empty())    /// The first key encountered.\n         {\n-            setPrimaryKeyRef(current_key, current);\n             key_differs = true;\n+            current_row_is_zero = true;\n         }\n         else\n             key_differs = next_key != current_key;\n \n-        /// if there are enough rows and the last one is calculated completely\n-        if (key_differs && merged_rows >= max_block_size)\n-            return;\n-\n-        queue.pop();\n-\n         if (key_differs)\n         {\n-            /// Write the data for the previous group.\n-            insertCurrentRowIfNeeded(merged_columns, false);\n+            if (!current_key.empty())\n+                /// Write the data for the previous group.\n+                insertCurrentRowIfNeeded(merged_columns, false);\n+\n+            if (merged_rows >= max_block_size)\n+            {\n+                /// The block is now full and the last row is calculated completely.\n+                current_key.reset();\n+                return;\n+            }\n \n             current_key.swap(next_key);\n \n@@ -375,6 +377,8 @@ void SummingSortedBlockInputStream::merge(MutableColumns & merged_columns, std::\n                     current_row_is_zero = false;\n         }\n \n+        queue.pop();\n+\n         if (!current->isLast())\n         {\n             current->next();\n@@ -481,6 +485,9 @@ void SummingSortedBlockInputStream::addRow(SortCursor & cursor)\n {\n     for (auto & desc : columns_to_aggregate)\n     {\n+        if (!desc.created)\n+            throw Exception(\"Logical error in SummingSortedBlockInputStream, there are no description\", ErrorCodes::LOGICAL_ERROR);\n+\n         if (desc.is_agg_func_type)\n         {\n             // desc.state is not used for AggregateFunction types\n@@ -489,9 +496,6 @@ void SummingSortedBlockInputStream::addRow(SortCursor & cursor)\n         }\n         else\n         {\n-            if (!desc.created)\n-                throw Exception(\"Logical error in SummingSortedBlockInputStream, there are no description\", ErrorCodes::LOGICAL_ERROR);\n-\n             // Specialized case for unary functions\n             if (desc.column_numbers.size() == 1)\n             {\n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.reference b/dbms/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.reference\nindex b6979ab566fb..fa222b7b8115 100644\n--- a/dbms/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.reference\n+++ b/dbms/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.reference\n@@ -1,3 +1,5 @@\n+10000\n+10000\n 1\t6\t3\t3\n 1\t6\t3\t3\n 1\t6\t[3,2]\ndiff --git a/dbms/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.sql b/dbms/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.sql\nindex 3a9883605f78..71068e0f74f6 100644\n--- a/dbms/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.sql\n+++ b/dbms/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.sql\n@@ -1,6 +1,33 @@\n drop table if exists test.summing_merge_tree_aggregate_function;\n drop table if exists test.summing_merge_tree_null;\n \n+---- partition merge\n+create table test.summing_merge_tree_aggregate_function (\n+\td Date,\n+\tk UInt64,\n+\tu AggregateFunction(uniq, UInt64)\n+) engine=SummingMergeTree(d, k, 1);\n+\n+insert into test.summing_merge_tree_aggregate_function\n+select today() as d,\n+       number as k,\n+       uniqState(toUInt64(number % 500))\n+from numbers(5000)\n+group by d, k;\n+\n+insert into test.summing_merge_tree_aggregate_function\n+select today() as d,\n+       number + 5000 as k,\n+       uniqState(toUInt64(number % 500))\n+from numbers(5000)\n+group by d, k;\n+\n+select count() from test.summing_merge_tree_aggregate_function;\n+optimize table test.summing_merge_tree_aggregate_function;\n+select count() from test.summing_merge_tree_aggregate_function;\n+\n+drop table test.summing_merge_tree_aggregate_function;\n+\n ---- sum + uniq + uniqExact\n create table test.summing_merge_tree_aggregate_function (\n \td materialized today(),\n",
  "problem_statement": "DB::Exception: Sizes of columns doesn't match\nI'm seeing a lot of error when trying to use SummingMergeTree\r\n\r\n```\r\n2018.07.13 17:12:28.242090 [ 6 ] <Error> void DB::BackgroundProcessingPool::threadFunction(): Code: 9, e.displayText() = DB::Exception: Sizes of columns doesn't match: date: 8192, clientipv4_state: 8193, e.what() = DB::Exception, Stack trace:\r\n\r\n0. ./clickhouse-server(StackTrace::StackTrace()+0x16) [0x49f1136]\r\n1. ./clickhouse-server(DB::Exception::Exception(std::string const&, int)+0x1f) [0x2576b8f]\r\n2. ./clickhouse-server(DB::Block::checkNumberOfRows() const+0x1d8) [0x3cc7538]\r\n3. ./clickhouse-server(DB::MergedBlockOutputStream::write(DB::Block const&)+0x22) [0x45cdd42]\r\n4. ./clickhouse-server(DB::MergeTreeDataMergerMutator::mergePartsToTemporaryPart(DB::MergeTreeDataMergerMutator::FuturePart const&, DB::MergeListEntry&, unsigned long, long, DB::DiskSpaceMonitor::Reservation*, bool)+0x2eb8) [0x457cff8]\r\n5. ./clickhouse-server(DB::StorageMergeTree::merge(unsigned long, bool, std::string const&, bool, bool, std::string*)+0x511) [0x44e1421]\r\n6. ./clickhouse-server(DB::StorageMergeTree::mergeTask()+0x9a) [0x44e194a]\r\n7. ./clickhouse-server(DB::BackgroundProcessingPool::threadFunction()+0x436) [0x4538636]\r\n8. ./clickhouse-server() [0x50013cf]\r\n9. /lib64/libpthread.so.0(+0x7e25) [0x7fd6c140ee25]\r\n10. /lib64/libc.so.6(clone+0x6d) [0x7fd6c0c32bad]\r\n```\r\n\r\n```\r\nCREATE TABLE vme4\r\n(\r\n    date Date,\r\n    datetime DateTime,\r\n    request_method Enum8('GET'=1, 'POST'=2, 'HEAD'=3, 'PUT'=4, 'DELETE'=5, 'OPTIONS'=6, 'TRACE'=7, 'CONNECT'=8),\r\n    request_host String,\r\n    server String,\r\n    user_agent String,\r\n    clientipv4 Nullable(UInt32),\r\n    clientipv6 Nullable(FixedString(16)),\r\n\r\n    backend String,\r\n    response_code UInt16,\r\n    mime String,\r\n    response_time UInt32,\r\n    response_size UInt32,\r\n\r\n    request_type Nullable(Enum8('live'=1, 'nPVR'=2, 'vod'=3)),\r\n    request_asset Nullable(String),\r\n    request_file Nullable(String),\r\n    request_uri Nullable(String),\r\n    stream_protocol Nullable(Enum8('unknow'=0, 'hls'=1, 'dash'=2, 'ss'=3, 'fmp4'=4)),\r\n    video_bitrate Nullable(UInt32),\r\n    is_hit Nullable(UInt8),\r\n\r\n    geoip_geoname_id Nullable(UInt32),\r\n    hub Nullable(String)\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY date\r\nORDER BY (date, user_agent)\r\nSETTINGS index_granularity = 8192;\r\n```\r\n\r\n```\r\nDROP TABLE vmeagg;\r\n\r\nCREATE TABLE vmeagg\r\n(\r\n    date Date,\r\n    datetime DateTime,\r\n    request_method Enum8('GET'=1, 'POST'=2, 'HEAD'=3, 'PUT'=4, 'DELETE'=5, 'OPTIONS'=6, 'TRACE'=7, 'CONNECT'=8),\r\n    request_host String,\r\n    server String,\r\n    user_agent String,\r\n    clientipv4_state AggregateFunction(uniqCombined, UInt32),\r\n    clientipv6_state AggregateFunction(uniqCombined, FixedString(16)),\r\n\r\n    backend String,\r\n    response_code UInt16,\r\n    mime String,\r\n    response_time_td AggregateFunction(quantilesTDigest(0.5,0.9,0.99), UInt32),\r\n    response_size_td AggregateFunction(quantilesTDigest(0.5,0.9,0.99), UInt32),\r\n    response_time_tot UInt64,\r\n    response_size_tot UInt64,\r\n\r\n    request_type Enum8('live'=1, 'nPVR'=2, 'vod'=3),\r\n    request_asset String,\r\n    stream_protocol Enum8('unknow'=0, 'hls'=1, 'dash'=2, 'ss'=3, 'fmp4'=4),\r\n    video_bitrate UInt32,\r\n    is_hit UInt8,\r\n\r\n    geoip_geoname_id UInt32,\r\n\r\n    count UInt32\r\n)\r\nENGINE = SummingMergeTree\r\nPARTITION BY date\r\nORDER BY (date, datetime, request_method, response_code, backend, user_agent, server, request_host, mime, request_type, request_asset, stream_protocol, video_bitrate, is_hit, geoip_geoname_id)\r\nSETTINGS index_granularity = 8192;\r\n\r\n\r\nINSERT INTO vmeagg SELECT\r\ndate,\r\ntoStartOfMinute(datetime),\r\nrequest_method,\r\nrequest_host,\r\nserver,\r\nuser_agent,\r\nuniqCombinedState(clientipv4),\r\nuniqCombinedState(clientipv6),\r\nbackend,\r\nresponse_code,\r\nmime,\r\nquantilesTDigestState(0.5,0.9,0.99)(response_time),\r\nquantilesTDigestState(0.5,0.9,0.99)(response_size),\r\nsum(response_time),\r\nsum(response_size),\r\nrequest_type,\r\nrequest_asset,\r\nstream_protocol,\r\nvideo_bitrate,\r\nis_hit,\r\ngeoip_geoname_id,\r\ncount(*)\r\nFROM vme4\r\nWHERE toStartOfMinute(datetime) = '2018-07-09 03:00:00' AND geoip_geoname_id IS NOT NULL AND video_bitrate IS NOT NULL\r\nGROUP BY date,\r\ntoStartOfMinute(datetime),\r\nrequest_method,\r\nrequest_host,\r\nserver,\r\nuser_agent,\r\nbackend,\r\nresponse_code,\r\nmime,\r\nrequest_type,\r\nrequest_asset,\r\nstream_protocol,\r\nvideo_bitrate,\r\nis_hit,\r\ngeoip_geoname_id;\r\n```\r\n\r\nWith the data currently loaded in table `vme4` I can reproduce the issue 100% of the time     (DROP / CREATE / INSERT error)\r\nI'm using Clickhouse 1.1.54390 (stable branch) on CentOS7\r\n\r\nI'll try to make a minimal repro case next week\r\n\r\n\n",
  "hints_text": "Looks like that the bug was introduced in #2566\nI did some more tests, no problem using a `MergeTree` or `AggregatingMergeTree`\nThat's my bad, the fix is on the way.",
  "created_at": "2018-07-17T13:07:20Z",
  "modified_files": [
    "dbms/src/DataStreams/SummingSortedBlockInputStream.cpp"
  ],
  "modified_test_files": [
    "dbms/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.reference",
    "dbms/tests/queries/0_stateless/00148_summing_merge_tree_aggregate_function.sql"
  ]
}