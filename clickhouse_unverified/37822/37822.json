{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 37822,
  "instance_id": "ClickHouse__ClickHouse-37822",
  "issue_numbers": [
    "37920"
  ],
  "base_commit": "f6692c34e68ab7adae80374860c3a43ceb4914dc",
  "patch": "diff --git a/src/Common/noexcept_scope.h b/src/Common/noexcept_scope.h\nnew file mode 100644\nindex 000000000000..56fb44ff0bf6\n--- /dev/null\n+++ b/src/Common/noexcept_scope.h\n@@ -0,0 +1,36 @@\n+#pragma once\n+#include <base/scope_guard.h>\n+#include <Common/Exception.h>\n+#include <Common/LockMemoryExceptionInThread.h>\n+\n+\n+#define NOEXCEPT_SCOPE_IMPL_CONCAT(n, expected) \\\n+    LockMemoryExceptionInThread lock_memory_tracker##n(VariableContext::Global);   \\\n+    SCOPE_EXIT(                                                                    \\\n+        {                                                                          \\\n+            const auto uncaught = std::uncaught_exceptions();                      \\\n+            assert((expected) == uncaught || (expected) + 1 == uncaught);          \\\n+            if ((expected) < uncaught)                                             \\\n+            {                                                                      \\\n+                tryLogCurrentException(\"NOEXCEPT_SCOPE\");                          \\\n+                abort();                                                           \\\n+            }                                                                      \\\n+        }                                                                          \\\n+    )\n+\n+#define NOEXCEPT_SCOPE_IMPL(n, expected) NOEXCEPT_SCOPE_IMPL_CONCAT(n, expected)\n+\n+#define NOEXCEPT_SCOPE_CONCAT(n)                                                   \\\n+    const auto num_curr_exceptions##n = std::uncaught_exceptions();                \\\n+    NOEXCEPT_SCOPE_IMPL(n, num_curr_exceptions##n)\n+\n+#define NOEXCEPT_SCOPE_FWD(n) NOEXCEPT_SCOPE_CONCAT(n)\n+\n+\n+/// It can be used in critical places to exit on unexpected exceptions.\n+/// SIGABRT is usually better that broken in-memory state with unpredictable consequences.\n+/// It also temporarily disables exception from memory tracker in current thread.\n+/// Strict version does not take into account nested exception (i.e. it aborts even when we're in catch block).\n+\n+#define NOEXCEPT_SCOPE_STRICT NOEXCEPT_SCOPE_IMPL(__LINE__, 0)\n+#define NOEXCEPT_SCOPE NOEXCEPT_SCOPE_FWD(__LINE__)\ndiff --git a/src/Daemon/BaseDaemon.cpp b/src/Daemon/BaseDaemon.cpp\nindex 62fcebb10bbd..e731787a5c13 100644\n--- a/src/Daemon/BaseDaemon.cpp\n+++ b/src/Daemon/BaseDaemon.cpp\n@@ -397,6 +397,7 @@ extern \"C\" void __sanitizer_set_death_callback(void (*)());\n \n static void sanitizerDeathCallback()\n {\n+    DENY_ALLOCATIONS_IN_SCOPE;\n     /// Also need to send data via pipe. Otherwise it may lead to deadlocks or failures in printing diagnostic info.\n \n     char buf[signal_pipe_buf_size];\ndiff --git a/src/Interpreters/InterpreterTransactionControlQuery.cpp b/src/Interpreters/InterpreterTransactionControlQuery.cpp\nindex 1e4868788ba1..bdb523de8800 100644\n--- a/src/Interpreters/InterpreterTransactionControlQuery.cpp\n+++ b/src/Interpreters/InterpreterTransactionControlQuery.cpp\n@@ -67,6 +67,7 @@ BlockIO InterpreterTransactionControlQuery::executeCommit(ContextMutablePtr sess\n         if (e.code() == ErrorCodes::UNKNOWN_STATUS_OF_TRANSACTION)\n         {\n             /// Detach transaction from current context if connection was lost and its status is unknown\n+            /// (so it will be possible to start new one)\n             session_context->setCurrentTransaction(NO_TRANSACTION_PTR);\n         }\n         throw;\n@@ -80,6 +81,16 @@ BlockIO InterpreterTransactionControlQuery::executeCommit(ContextMutablePtr sess\n         /// It's useful for testing. It allows to enable fault injection (after commit) without breaking tests.\n         txn->waitStateChange(Tx::CommittingCSN);\n \n+        CSN csn_changed_state = txn->getCSN();\n+        if (csn_changed_state == Tx::UnknownCSN)\n+        {\n+            /// CommittingCSN -> UnknownCSN -> RolledBackCSN\n+            /// It's possible if connection was lost before commit\n+            /// (maybe we should get rid of intermediate UnknownCSN in this transition)\n+            txn->waitStateChange(Tx::UnknownCSN);\n+            chassert(txn->getCSN() == Tx::RolledBackCSN);\n+        }\n+\n         if (txn->getState() == MergeTreeTransaction::ROLLED_BACK)\n             throw Exception(ErrorCodes::INVALID_TRANSACTION, \"Transaction {} was rolled back\", txn->tid);\n         if (txn->getState() != MergeTreeTransaction::COMMITTED)\ndiff --git a/src/Interpreters/MergeTreeTransaction.cpp b/src/Interpreters/MergeTreeTransaction.cpp\nindex cab40f3c6db4..e6b4818b4d78 100644\n--- a/src/Interpreters/MergeTreeTransaction.cpp\n+++ b/src/Interpreters/MergeTreeTransaction.cpp\n@@ -3,6 +3,7 @@\n #include <Storages/MergeTree/MergeTreeData.h>\n #include <Interpreters/TransactionLog.h>\n #include <Interpreters/TransactionsInfoLog.h>\n+#include <Common/noexcept_scope.h>\n \n namespace DB\n {\n@@ -146,8 +147,8 @@ void MergeTreeTransaction::removeOldPart(const StoragePtr & storage, const DataP\n         std::lock_guard lock{mutex};\n         checkIsNotCancelled();\n \n-        LockMemoryExceptionInThread lock_memory_tracker(VariableContext::Global);\n         part_to_remove->version.lockRemovalTID(tid, context);\n+        NOEXCEPT_SCOPE;\n         storages.insert(storage);\n         if (maybe_lock)\n             table_read_locks_for_ordinary_db.emplace_back(std::move(maybe_lock));\ndiff --git a/src/Interpreters/ThreadStatusExt.cpp b/src/Interpreters/ThreadStatusExt.cpp\nindex 2c83a3bfcdba..42db91f47c0f 100644\n--- a/src/Interpreters/ThreadStatusExt.cpp\n+++ b/src/Interpreters/ThreadStatusExt.cpp\n@@ -16,7 +16,7 @@\n #include <Common/SensitiveDataMasker.h>\n #include <Common/ThreadProfileEvents.h>\n #include <Common/setThreadName.h>\n-#include <Common/LockMemoryExceptionInThread.h>\n+#include <Common/noexcept_scope.h>\n #include <base/errnoToString.h>\n \n #if defined(OS_LINUX)\n@@ -343,7 +343,7 @@ void ThreadStatus::finalizeQueryProfiler()\n \n void ThreadStatus::detachQuery(bool exit_if_already_detached, bool thread_exits)\n {\n-    LockMemoryExceptionInThread lock(VariableContext::Global);\n+    NOEXCEPT_SCOPE;\n \n     if (exit_if_already_detached && thread_state == ThreadState::DetachedFromQuery)\n     {\ndiff --git a/src/Interpreters/TransactionLog.cpp b/src/Interpreters/TransactionLog.cpp\nindex 0ddc726ff7f6..e6bd47eed443 100644\n--- a/src/Interpreters/TransactionLog.cpp\n+++ b/src/Interpreters/TransactionLog.cpp\n@@ -9,12 +9,9 @@\n #include <Common/ZooKeeper/KeeperException.h>\n #include <Core/ServerUUID.h>\n #include <Common/logger_useful.h>\n+#include <Common/noexcept_scope.h>\n \n \n-/// It's used in critical places to exit on unexpected exceptions.\n-/// SIGABRT is usually better that broken state in memory with unpredictable consequences.\n-#define NOEXCEPT_SCOPE SCOPE_EXIT({ if (std::uncaught_exceptions()) { tryLogCurrentException(\"NOEXCEPT_SCOPE\"); abort(); } })\n-\n namespace DB\n {\n \n@@ -146,8 +143,7 @@ void TransactionLog::loadEntries(Strings::const_iterator beg, Strings::const_ite\n     }\n     futures.clear();\n \n-    NOEXCEPT_SCOPE;\n-    LockMemoryExceptionInThread lock_memory_tracker(VariableContext::Global);\n+    NOEXCEPT_SCOPE_STRICT;\n     {\n         std::lock_guard lock{mutex};\n         for (const auto & entry : loaded)\n@@ -453,7 +449,7 @@ CSN TransactionLog::commitTransaction(const MergeTreeTransactionPtr & txn, bool\n \n         /// Do not allow exceptions between commit point and the and of transaction finalization\n         /// (otherwise it may stuck in COMMITTING state holding snapshot).\n-        NOEXCEPT_SCOPE;\n+        NOEXCEPT_SCOPE_STRICT;\n         /// FIXME Transactions: Sequential node numbers in ZooKeeper are Int32, but 31 bit is not enough for production use\n         /// (overflow is possible in a several weeks/months of active usage)\n         allocated_csn = deserializeCSN(csn_path_created.substr(zookeeper_path_log.size() + 1));\ndiff --git a/src/Interpreters/TransactionVersionMetadata.cpp b/src/Interpreters/TransactionVersionMetadata.cpp\nindex 36a4fb9cc5be..5f46b86508c6 100644\n--- a/src/Interpreters/TransactionVersionMetadata.cpp\n+++ b/src/Interpreters/TransactionVersionMetadata.cpp\n@@ -95,12 +95,8 @@ bool VersionMetadata::tryLockRemovalTID(const TransactionID & tid, const Transac\n     bool locked = removal_tid_lock.compare_exchange_strong(expected_removal_lock_value, removal_lock_value);\n     if (!locked)\n     {\n-        if (tid == Tx::PrehistoricTID && expected_removal_lock_value == Tx::PrehistoricTID.getHash())\n-        {\n-            /// Don't need to lock part for queries without transaction\n-            LOG_TEST(log, \"Assuming removal_tid is locked by {}, table: {}, part: {}\", tid, context.table.getNameForLogs(), context.part_name);\n-            return true;\n-        }\n+        if (expected_removal_lock_value == removal_lock_value)\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Tried to lock part {} for removal second time by {}\", context.part_name, tid);\n \n         if (locked_by_id)\n             *locked_by_id = expected_removal_lock_value;\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex fb761ed1ae5b..dc94266bc956 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -65,6 +65,7 @@\n #include <Common/escapeForFileName.h>\n #include <Common/quoteString.h>\n #include <Common/typeid_cast.h>\n+#include <Common/noexcept_scope.h>\n #include <Processors/QueryPlan/ReadFromMergeTree.h>\n #include <Processors/Formats/IInputFormat.h>\n #include <AggregateFunctions/AggregateFunctionCount.h>\n@@ -2907,16 +2908,18 @@ bool MergeTreeData::renameTempPartAndReplace(\n     part->renameTo(part_name, true);\n \n     auto part_it = data_parts_indexes.insert(part).first;\n-    /// FIXME Transactions: it's not the best place for checking and setting removal_tid,\n-    /// because it's too optimistic. We should lock removal_tid of covered parts at the beginning of operation.\n-    MergeTreeTransaction::addNewPartAndRemoveCovered(shared_from_this(), part, covered_parts, txn);\n \n     if (out_transaction)\n     {\n+        chassert(out_transaction->txn == txn);\n         out_transaction->precommitted_parts.insert(part);\n     }\n     else\n     {\n+        /// FIXME Transactions: it's not the best place for checking and setting removal_tid,\n+        /// because it's too optimistic. We should lock removal_tid of covered parts at the beginning of operation.\n+        MergeTreeTransaction::addNewPartAndRemoveCovered(shared_from_this(), part, covered_parts, txn);\n+\n         size_t reduce_bytes = 0;\n         size_t reduce_rows = 0;\n         size_t reduce_parts = 0;\n@@ -3579,6 +3582,13 @@ MergeTreeData::DataPartsVector MergeTreeData::getVisibleDataPartsVectorInPartiti\n     return getVisibleDataPartsVectorInPartition(local_context->getCurrentTransaction().get(), partition_id);\n }\n \n+\n+MergeTreeData::DataPartsVector MergeTreeData::getVisibleDataPartsVectorInPartition(\n+    ContextPtr local_context, const String & partition_id, DataPartsLock & lock) const\n+{\n+    return getVisibleDataPartsVectorInPartition(local_context->getCurrentTransaction().get(), partition_id, &lock);\n+}\n+\n MergeTreeData::DataPartsVector MergeTreeData::getVisibleDataPartsVectorInPartition(\n     MergeTreeTransaction * txn, const String & partition_id, DataPartsLock * acquired_lock) const\n {\n@@ -4250,7 +4260,7 @@ void MergeTreeData::restorePartFromBackup(std::shared_ptr<RestoredPartsHolder> r\n }\n \n \n-String MergeTreeData::getPartitionIDFromQuery(const ASTPtr & ast, ContextPtr local_context) const\n+String MergeTreeData::getPartitionIDFromQuery(const ASTPtr & ast, ContextPtr local_context, DataPartsLock * acquired_lock) const\n {\n     const auto & partition_ast = ast->as<ASTPartition &>();\n \n@@ -4334,7 +4344,7 @@ String MergeTreeData::getPartitionIDFromQuery(const ASTPtr & ast, ContextPtr loc\n     String partition_id = partition.getID(*this);\n \n     {\n-        auto data_parts_lock = lockParts();\n+        auto data_parts_lock = (acquired_lock) ? DataPartsLock() : lockParts();\n         DataPartPtr existing_part_in_partition = getAnyPartInPartition(partition_id, data_parts_lock);\n         if (existing_part_in_partition && existing_part_in_partition->partition.value != partition.value)\n         {\n@@ -4922,18 +4932,6 @@ void MergeTreeData::Transaction::rollback()\n         buf << \".\";\n         LOG_DEBUG(data.log, \"Undoing transaction.{}\", buf.str());\n \n-        if (!txn)\n-        {\n-            auto lock = data.lockParts();\n-            for (const auto & part : precommitted_parts)\n-            {\n-                DataPartPtr covering_part;\n-                DataPartsVector covered_parts = data.getActivePartsToReplace(part->info, part->name, covering_part, lock);\n-                for (auto & covered : covered_parts)\n-                    covered->version.unlockRemovalTID(Tx::PrehistoricTID, TransactionInfoContext{data.getStorageID(), covered->name});\n-            }\n-        }\n-\n         data.removePartsFromWorkingSet(txn,\n             DataPartsVector(precommitted_parts.begin(), precommitted_parts.end()),\n             /* clear_without_timeout = */ true);\n@@ -4951,6 +4949,18 @@ MergeTreeData::DataPartsVector MergeTreeData::Transaction::commit(MergeTreeData:\n         auto parts_lock = acquired_parts_lock ? MergeTreeData::DataPartsLock() : data.lockParts();\n         auto * owing_parts_lock = acquired_parts_lock ? acquired_parts_lock : &parts_lock;\n \n+        if (txn)\n+        {\n+            for (const DataPartPtr & part : precommitted_parts)\n+            {\n+                DataPartPtr covering_part;\n+                DataPartsVector covered_parts = data.getActivePartsToReplace(part->info, part->name, covering_part, *owing_parts_lock);\n+                MergeTreeTransaction::addNewPartAndRemoveCovered(data.shared_from_this(), part, covered_parts, txn);\n+            }\n+        }\n+\n+        NOEXCEPT_SCOPE;\n+\n         auto current_time = time(nullptr);\n \n         size_t add_bytes = 0;\n@@ -4974,6 +4984,9 @@ MergeTreeData::DataPartsVector MergeTreeData::Transaction::commit(MergeTreeData:\n             }\n             else\n             {\n+                if (!txn)\n+                    MergeTreeTransaction::addNewPartAndRemoveCovered(data.shared_from_this(), part, covered_parts, NO_TRANSACTION_RAW);\n+\n                 total_covered_parts.insert(total_covered_parts.end(), covered_parts.begin(), covered_parts.end());\n                 for (const auto & covered_part : covered_parts)\n                 {\ndiff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h\nindex d531fc9f3398..80921a4ef0c4 100644\n--- a/src/Storages/MergeTree/MergeTreeData.h\n+++ b/src/Storages/MergeTree/MergeTreeData.h\n@@ -282,6 +282,7 @@ class MergeTreeData : public IStorage, public WithMutableContext\n         MergeTreeData & data;\n         MergeTreeTransaction * txn;\n         DataParts precommitted_parts;\n+        DataParts locked_parts;\n \n         void clear() { precommitted_parts.clear(); }\n     };\n@@ -501,6 +502,7 @@ class MergeTreeData : public IStorage, public WithMutableContext\n \n     /// Returns all parts in specified partition\n     DataPartsVector getVisibleDataPartsVectorInPartition(MergeTreeTransaction * txn, const String & partition_id, DataPartsLock * acquired_lock = nullptr) const;\n+    DataPartsVector getVisibleDataPartsVectorInPartition(ContextPtr local_context, const String & partition_id, DataPartsLock & lock) const;\n     DataPartsVector getVisibleDataPartsVectorInPartition(ContextPtr local_context, const String & partition_id) const;\n     DataPartsVector getVisibleDataPartsVectorInPartitions(ContextPtr local_context, const std::unordered_set<String> & partition_ids) const;\n \n@@ -767,7 +769,7 @@ class MergeTreeData : public IStorage, public WithMutableContext\n     }\n \n     /// For ATTACH/DETACH/DROP PARTITION.\n-    String getPartitionIDFromQuery(const ASTPtr & ast, ContextPtr context) const;\n+    String getPartitionIDFromQuery(const ASTPtr & ast, ContextPtr context, DataPartsLock * acquired_lock = nullptr) const;\n     std::unordered_set<String> getPartitionIDsFromQuery(const ASTs & asts, ContextPtr context) const;\n     std::set<String> getPartitionIdsAffectedByCommands(const MutationCommands & commands, ContextPtr query_context) const;\n \ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeAltersSequence.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeAltersSequence.cpp\nindex 6e57fe558782..37d04541dfd3 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeAltersSequence.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeAltersSequence.cpp\n@@ -4,7 +4,7 @@\n namespace DB\n {\n \n-int ReplicatedMergeTreeAltersSequence::getHeadAlterVersion(std::lock_guard<std::mutex> & /*state_lock*/) const\n+int ReplicatedMergeTreeAltersSequence::getHeadAlterVersion(std::unique_lock<std::mutex> & /*state_lock*/) const\n {\n     /// If queue empty, than we don't have version\n     if (!queue_state.empty())\n@@ -66,7 +66,7 @@ void ReplicatedMergeTreeAltersSequence::finishDataAlter(int alter_version, std::\n     }\n }\n \n-bool ReplicatedMergeTreeAltersSequence::canExecuteDataAlter(int alter_version, std::lock_guard<std::mutex> & /*state_lock*/) const\n+bool ReplicatedMergeTreeAltersSequence::canExecuteDataAlter(int alter_version, std::unique_lock<std::mutex> & /*state_lock*/) const\n {\n     /// Queue maybe empty when we start after server shutdown\n     /// and have some MUTATE_PART records in queue\n@@ -80,7 +80,7 @@ bool ReplicatedMergeTreeAltersSequence::canExecuteDataAlter(int alter_version, s\n     return queue_state.at(alter_version).metadata_finished;\n }\n \n-bool ReplicatedMergeTreeAltersSequence::canExecuteMetaAlter(int alter_version, std::lock_guard<std::mutex> & /*state_lock*/) const\n+bool ReplicatedMergeTreeAltersSequence::canExecuteMetaAlter(int alter_version, std::unique_lock<std::mutex> & /*state_lock*/) const\n {\n     assert(!queue_state.empty());\n \ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeAltersSequence.h b/src/Storages/MergeTree/ReplicatedMergeTreeAltersSequence.h\nindex aa58e16a716e..c104109bd4cb 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeAltersSequence.h\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeAltersSequence.h\n@@ -49,13 +49,13 @@ class ReplicatedMergeTreeAltersSequence\n     void finishDataAlter(int alter_version, std::lock_guard<std::mutex> & /*state_lock*/);\n \n     /// Check that we can execute this data alter. If it's metadata stage finished.\n-    bool canExecuteDataAlter(int alter_version, std::lock_guard<std::mutex> & /*state_lock*/) const;\n+    bool canExecuteDataAlter(int alter_version, std::unique_lock<std::mutex> & /*state_lock*/) const;\n \n     /// Check that we can execute metadata alter with version.\n-    bool canExecuteMetaAlter(int alter_version, std::lock_guard<std::mutex> & /*state_lock*/) const;\n+    bool canExecuteMetaAlter(int alter_version, std::unique_lock<std::mutex> & /*state_lock*/) const;\n \n     /// Just returns smallest alter version in sequence (first entry)\n-    int getHeadAlterVersion(std::lock_guard<std::mutex> & /*state_lock*/) const;\n+    int getHeadAlterVersion(std::unique_lock<std::mutex> & /*state_lock*/) const;\n };\n \n }\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\nindex 9f679f121b88..add1ba875aa6 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\n@@ -1066,8 +1066,9 @@ void ReplicatedMergeTreeQueue::removePartProducingOpsInRange(\n }\n \n \n-bool ReplicatedMergeTreeQueue::isNotCoveredByFuturePartsImpl(const LogEntry & entry, const String & new_part_name,\n-                                                             String & out_reason, std::lock_guard<std::mutex> & /* queue_lock */) const\n+bool ReplicatedMergeTreeQueue::isCoveredByFuturePartsImpl(const LogEntry & entry, const String & new_part_name,\n+                                                          String & out_reason, std::unique_lock<std::mutex> & /* queue_lock */,\n+                                                          std::vector<LogEntryPtr> * covered_entries_to_wait) const\n {\n     /// Let's check if the same part is now being created by another action.\n     auto entry_for_same_part_it = future_parts.find(new_part_name);\n@@ -1080,7 +1081,7 @@ bool ReplicatedMergeTreeQueue::isNotCoveredByFuturePartsImpl(const LogEntry & en\n             entry.znode_name, entry.type, entry.new_part_name,\n             another_entry.znode_name, another_entry.type, another_entry.new_part_name);\n         LOG_INFO(log, fmt::runtime(out_reason));\n-        return false;\n+        return true;\n \n         /** When the corresponding action is completed, then `isNotCoveredByFuturePart` next time, will succeed,\n             *  and queue element will be processed.\n@@ -1098,24 +1099,50 @@ bool ReplicatedMergeTreeQueue::isNotCoveredByFuturePartsImpl(const LogEntry & en\n     {\n         auto future_part = MergeTreePartInfo::fromPartName(future_part_elem.first, format_version);\n \n-        if (future_part.contains(result_part))\n+        if (future_part.isDisjoint(result_part))\n+            continue;\n+\n+        /// Parts are not disjoint, so new_part_name either contains or covers future_part.\n+        chassert(future_part.contains(result_part) || result_part.contains(future_part));\n+        /// We cannot execute `entry` (or upgrade its actual_part_name to `new_part_name`)\n+        /// while any covered or covering parts are processed.\n+        /// But we also cannot simply return true and postpone entry processing, because it may lead to kind of livelock.\n+        /// Since queue is processed in multiple threads, it's likely that there will be at least one thread\n+        /// executing faulty entry for some small part, so bigger covering part will never be processed.\n+        /// That's why it's better to wait for covered entry to be executed (does not matter successfully or not)\n+        /// instead of exiting and postponing covering entry.\n+\n+        if (covered_entries_to_wait)\n         {\n-            out_reason = fmt::format(\n-                \"Not executing log entry {} for part {} \"\n-                \"because it is covered by part {} that is currently executing.\",\n-                entry.znode_name, new_part_name, future_part_elem.first);\n-            LOG_TRACE(log, fmt::runtime(out_reason));\n-            return false;\n+            if (entry.znode_name < future_part_elem.second->znode_name)\n+            {\n+                out_reason = fmt::format(\n+                    \"Not executing log entry {} for part {} \"\n+                    \"because it is not disjoint with part {} that is currently executing and another entry {} is newer.\",\n+                    entry.znode_name, new_part_name, future_part_elem.first, future_part_elem.second->znode_name);\n+                LOG_TRACE(log, fmt::runtime(out_reason));\n+                return true;\n+            }\n+\n+            covered_entries_to_wait->push_back(future_part_elem.second);\n+            continue;\n         }\n+\n+        out_reason = fmt::format(\n+            \"Not executing log entry {} for part {} \"\n+            \"because it is not disjoint with part {} that is currently executing.\",\n+            entry.znode_name, new_part_name, future_part_elem.first);\n+        LOG_TRACE(log, fmt::runtime(out_reason));\n+        return true;\n     }\n \n-    return true;\n+    return false;\n }\n \n bool ReplicatedMergeTreeQueue::addFuturePartIfNotCoveredByThem(const String & part_name, LogEntry & entry, String & reject_reason)\n {\n     /// We have found `part_name` on some replica and are going to fetch it instead of covered `entry->new_part_name`.\n-    std::lock_guard lock(state_mutex);\n+    std::unique_lock lock(state_mutex);\n \n     if (virtual_parts.getContainingPart(part_name).empty())\n     {\n@@ -1137,13 +1164,13 @@ bool ReplicatedMergeTreeQueue::addFuturePartIfNotCoveredByThem(const String & pa\n     if (drop_ranges.isAffectedByDropRange(part_name, reject_reason))\n         return false;\n \n-    if (isNotCoveredByFuturePartsImpl(entry, part_name, reject_reason, lock))\n-    {\n-        CurrentlyExecuting::setActualPartName(entry, part_name, *this, lock);\n-        return true;\n-    }\n+    std::vector<LogEntryPtr> covered_entries_to_wait;\n+    if (isCoveredByFuturePartsImpl(entry, part_name, reject_reason, lock, &covered_entries_to_wait))\n+        return false;\n+\n+    CurrentlyExecuting::setActualPartName(entry, part_name, *this, lock, covered_entries_to_wait);\n+    return true;\n \n-    return false;\n }\n \n \n@@ -1152,13 +1179,15 @@ bool ReplicatedMergeTreeQueue::shouldExecuteLogEntry(\n     String & out_postpone_reason,\n     MergeTreeDataMergerMutator & merger_mutator,\n     MergeTreeData & data,\n-    std::lock_guard<std::mutex> & state_lock) const\n+    std::unique_lock<std::mutex> & state_lock) const\n {\n     /// If our entry produce part which is already covered by\n     /// some other entry which is currently executing, then we can postpone this entry.\n     for (const String & new_part_name : entry.getVirtualPartNames(format_version))\n     {\n-        if (!isNotCoveredByFuturePartsImpl(entry, new_part_name, out_postpone_reason, state_lock))\n+        /// Do not wait for any entries here, because we have only one thread that scheduling queue entries.\n+        /// We can wait in worker threads, but not in scheduler.\n+        if (isCoveredByFuturePartsImpl(entry, new_part_name, out_postpone_reason, state_lock, /* covered_entries_to_wait */ nullptr))\n             return false;\n     }\n \n@@ -1409,7 +1438,7 @@ Int64 ReplicatedMergeTreeQueue::getCurrentMutationVersion(const String & partiti\n \n \n ReplicatedMergeTreeQueue::CurrentlyExecuting::CurrentlyExecuting(\n-    const ReplicatedMergeTreeQueue::LogEntryPtr & entry_, ReplicatedMergeTreeQueue & queue_, std::lock_guard<std::mutex> & /* state_lock */)\n+    const ReplicatedMergeTreeQueue::LogEntryPtr & entry_, ReplicatedMergeTreeQueue & queue_, std::unique_lock<std::mutex> & /* state_lock */)\n     : entry(entry_), queue(queue_)\n {\n     if (entry->type == ReplicatedMergeTreeLogEntry::DROP_RANGE || entry->type == ReplicatedMergeTreeLogEntry::REPLACE_RANGE)\n@@ -1435,7 +1464,8 @@ void ReplicatedMergeTreeQueue::CurrentlyExecuting::setActualPartName(\n     ReplicatedMergeTreeQueue::LogEntry & entry,\n     const String & actual_part_name,\n     ReplicatedMergeTreeQueue & queue,\n-    std::lock_guard<std::mutex> & /* state_lock */)\n+    std::unique_lock<std::mutex> & state_lock,\n+    std::vector<LogEntryPtr> & covered_entries_to_wait)\n {\n     if (!entry.actual_new_part_name.empty())\n         throw Exception(\"Entry actual part isn't empty yet. This is a bug.\", ErrorCodes::LOGICAL_ERROR);\n@@ -1450,6 +1480,15 @@ void ReplicatedMergeTreeQueue::CurrentlyExecuting::setActualPartName(\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Attaching already existing future part {}. This is a bug. \"\n                                                    \"It happened on attempt to execute {}: {}\",\n                                                    entry.actual_new_part_name, entry.znode_name, entry.toString());\n+\n+    for (LogEntryPtr & covered_entry : covered_entries_to_wait)\n+    {\n+        if (&entry == covered_entry.get())\n+            continue;\n+        LOG_TRACE(queue.log, \"Waiting for {} producing {} to finish before executing {} producing not disjoint part {}\",\n+                  covered_entry->znode_name, covered_entry->new_part_name, entry.znode_name, entry.new_part_name);\n+        covered_entry->execution_complete.wait(state_lock, [&covered_entry] { return !covered_entry->currently_executing; });\n+    }\n }\n \n \n@@ -1491,7 +1530,7 @@ ReplicatedMergeTreeQueue::SelectedEntryPtr ReplicatedMergeTreeQueue::selectEntry\n {\n     LogEntryPtr entry;\n \n-    std::lock_guard lock(state_mutex);\n+    std::unique_lock lock(state_mutex);\n \n     for (auto it = queue.begin(); it != queue.end(); ++it)\n     {\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h\nindex dea4d0573db2..a88d9182bbf0 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h\n@@ -202,17 +202,18 @@ class ReplicatedMergeTreeQueue\n     bool shouldExecuteLogEntry(\n         const LogEntry & entry, String & out_postpone_reason,\n         MergeTreeDataMergerMutator & merger_mutator, MergeTreeData & data,\n-        std::lock_guard<std::mutex> & state_lock) const;\n+        std::unique_lock<std::mutex> & state_lock) const;\n \n     Int64 getCurrentMutationVersionImpl(const String & partition_id, Int64 data_version, std::lock_guard<std::mutex> & /* state_lock */) const;\n \n     /** Check that part isn't in currently generating parts and isn't covered by them.\n       * Should be called under state_mutex.\n       */\n-    bool isNotCoveredByFuturePartsImpl(\n+    bool isCoveredByFuturePartsImpl(\n         const LogEntry & entry,\n         const String & new_part_name, String & out_reason,\n-        std::lock_guard<std::mutex> & state_lock) const;\n+        std::unique_lock<std::mutex> & state_lock,\n+        std::vector<LogEntryPtr> * covered_entries_to_wait) const;\n \n     /// After removing the queue element, update the insertion times in the RAM. Running under state_mutex.\n     /// Returns information about what times have changed - this information can be passed to updateTimesInZooKeeper.\n@@ -254,14 +255,15 @@ class ReplicatedMergeTreeQueue\n         CurrentlyExecuting(\n             const ReplicatedMergeTreeQueue::LogEntryPtr & entry_,\n             ReplicatedMergeTreeQueue & queue_,\n-            std::lock_guard<std::mutex> & state_lock);\n+            std::unique_lock<std::mutex> & state_lock);\n \n         /// In case of fetch, we determine actual part during the execution, so we need to update entry. It is called under state_mutex.\n         static void setActualPartName(\n             ReplicatedMergeTreeQueue::LogEntry & entry,\n             const String & actual_part_name,\n             ReplicatedMergeTreeQueue & queue,\n-            std::lock_guard<std::mutex> & state_lock);\n+            std::unique_lock<std::mutex> & state_lock,\n+            std::vector<LogEntryPtr> & covered_entries_to_wait);\n \n     public:\n         ~CurrentlyExecuting();\ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex ab538ce8fd7d..070c55d3015e 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -278,8 +278,9 @@ void StorageMergeTree::truncate(const ASTPtr &, const StorageMetadataPtr &, Cont\n         /// This protects against \"revival\" of data for a removed partition after completion of merge.\n         auto merge_blocker = stopMergesAndWait();\n \n-        auto parts_to_remove = getVisibleDataPartsVector(local_context);\n-        removePartsFromWorkingSet(local_context->getCurrentTransaction().get(), parts_to_remove, true);\n+        auto data_parts_lock = lockParts();\n+        auto parts_to_remove = getVisibleDataPartsVectorUnlocked(local_context, data_parts_lock);\n+        removePartsFromWorkingSet(local_context->getCurrentTransaction().get(), parts_to_remove, true, data_parts_lock);\n \n         LOG_INFO(log, \"Removed {} parts.\", parts_to_remove.size());\n     }\n@@ -1469,16 +1470,17 @@ void StorageMergeTree::dropPartition(const ASTPtr & partition, bool detach, Cont\n         /// Asks to complete merges and does not allow them to start.\n         /// This protects against \"revival\" of data for a removed partition after completion of merge.\n         auto merge_blocker = stopMergesAndWait();\n+        auto data_parts_lock = lockParts();\n         const auto * partition_ast = partition->as<ASTPartition>();\n         if (partition_ast && partition_ast->all)\n-            parts_to_remove = getVisibleDataPartsVector(local_context);\n+            parts_to_remove = getVisibleDataPartsVectorUnlocked(local_context, data_parts_lock);\n         else\n         {\n-            String partition_id = getPartitionIDFromQuery(partition, local_context);\n-            parts_to_remove = getVisibleDataPartsVectorInPartition(local_context, partition_id);\n+            String partition_id = getPartitionIDFromQuery(partition, local_context, &data_parts_lock);\n+            parts_to_remove = getVisibleDataPartsVectorInPartition(local_context, partition_id, data_parts_lock);\n         }\n         /// TODO should we throw an exception if parts_to_remove is empty?\n-        removePartsFromWorkingSet(local_context->getCurrentTransaction().get(), parts_to_remove, true);\n+        removePartsFromWorkingSet(local_context->getCurrentTransaction().get(), parts_to_remove, true, data_parts_lock);\n     }\n \n     dropPartsImpl(std::move(parts_to_remove), detach);\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01169_alter_partition_isolation_stress.sh b/tests/queries/0_stateless/01169_alter_partition_isolation_stress.sh\nindex 653333dcb964..3657a93f1fdc 100755\n--- a/tests/queries/0_stateless/01169_alter_partition_isolation_stress.sh\n+++ b/tests/queries/0_stateless/01169_alter_partition_isolation_stress.sh\n@@ -18,9 +18,7 @@ function thread_insert()\n {\n     set -e\n     val=1\n-    trap \"STOP_THE_LOOP=1\" INT\n-    STOP_THE_LOOP=0\n-    while [[ $STOP_THE_LOOP != 1 ]]; do\n+    while true; do\n         $CLICKHOUSE_CLIENT --multiquery --query \"\n         BEGIN TRANSACTION;\n         INSERT INTO src VALUES /* ($val, 1) */ ($val, 1);\n@@ -93,9 +91,7 @@ function thread_partition_dst_to_src()\n function thread_select()\n {\n     set -e\n-    trap \"STOP_THE_LOOP=1\" INT\n-    STOP_THE_LOOP=0\n-    while [[ $STOP_THE_LOOP != 1 ]]; do\n+    while true; do\n         $CLICKHOUSE_CLIENT --multiquery --query \"\n         BEGIN TRANSACTION;\n         -- no duplicates\n@@ -122,9 +118,10 @@ thread_partition_src_to_dst & PID_3=$!\n thread_partition_dst_to_src & PID_4=$!\n wait $PID_3 && wait $PID_4\n \n-kill -INT $PID_1\n-kill -INT $PID_2\n+kill -TERM $PID_1\n+kill -TERM $PID_2\n wait\n+wait_for_queries_to_finish\n \n $CLICKHOUSE_CLIENT -q \"SELECT type, count(n) = countDistinct(n) FROM merge(currentDatabase(), '') GROUP BY type ORDER BY type\"\n $CLICKHOUSE_CLIENT -q \"SELECT DISTINCT arraySort(groupArrayIf(n, type=1)) = arraySort(groupArrayIf(n, type=2)) FROM merge(currentDatabase(), '') GROUP BY _table ORDER BY _table\"\ndiff --git a/tests/queries/0_stateless/01171_mv_select_insert_isolation_long.sh b/tests/queries/0_stateless/01171_mv_select_insert_isolation_long.sh\nindex 261fa4804915..30dbab6073ca 100755\n--- a/tests/queries/0_stateless/01171_mv_select_insert_isolation_long.sh\n+++ b/tests/queries/0_stateless/01171_mv_select_insert_isolation_long.sh\n@@ -50,9 +50,7 @@ function thread_insert_rollback()\n function thread_optimize()\n {\n     set -e\n-    trap \"STOP_THE_LOOP=1\" INT\n-    STOP_THE_LOOP=0\n-    while [[ $STOP_THE_LOOP != 1 ]]; do\n+    while true; do\n         optimize_query=\"OPTIMIZE TABLE src\"\n         partition_id=$(( RANDOM % 2 ))\n         if (( RANDOM % 2 )); then\n@@ -82,7 +80,6 @@ function thread_optimize()\n function thread_select()\n {\n     set -e\n-    trap \"exit 0\" INT\n     while true; do\n         $CLICKHOUSE_CLIENT --multiquery --query \"\n         BEGIN TRANSACTION;\n@@ -103,9 +100,7 @@ function thread_select()\n function thread_select_insert()\n {\n     set -e\n-    trap \"STOP_THE_LOOP=1\" INT\n-    STOP_THE_LOOP=0\n-    while [[ $STOP_THE_LOOP != 1 ]]; do\n+    while true; do\n         $CLICKHOUSE_CLIENT --multiquery --query \"\n         BEGIN TRANSACTION;\n         SELECT throwIf((SELECT count() FROM tmp) != 0) FORMAT Null;\n@@ -139,12 +134,13 @@ thread_select & PID_7=$!\n thread_select_insert & PID_8=$!\n \n wait $PID_1 && wait $PID_2 && wait $PID_3\n-kill -INT $PID_4\n-kill -INT $PID_5\n-kill -INT $PID_6\n-kill -INT $PID_7\n-kill -INT $PID_8\n+kill -TERM $PID_4\n+kill -TERM $PID_5\n+kill -TERM $PID_6\n+kill -TERM $PID_7\n+kill -TERM $PID_8\n wait\n+wait_for_queries_to_finish\n \n $CLICKHOUSE_CLIENT --multiquery --query \"\n BEGIN TRANSACTION;\ndiff --git a/tests/queries/0_stateless/01174_select_insert_isolation.sh b/tests/queries/0_stateless/01174_select_insert_isolation.sh\nindex 4bce09cf1d5c..5de42cbc4c58 100755\n--- a/tests/queries/0_stateless/01174_select_insert_isolation.sh\n+++ b/tests/queries/0_stateless/01174_select_insert_isolation.sh\n@@ -35,9 +35,7 @@ function thread_insert_rollback()\n \n function thread_select()\n {\n-    trap \"STOP_THE_LOOP=1\" INT\n-    STOP_THE_LOOP=0\n-    while [[ $STOP_THE_LOOP != 1 ]]; do\n+    while true; do\n         # Result of `uniq | wc -l` must be 1 if the first and the last queries got the same result\n         $CLICKHOUSE_CLIENT --multiquery --query \"\n         BEGIN TRANSACTION;\n@@ -55,8 +53,9 @@ thread_insert_commit 2 & PID_2=$!\n thread_insert_rollback 3 & PID_3=$!\n thread_select & PID_4=$!\n wait $PID_1 && wait $PID_2 && wait $PID_3\n-kill -INT $PID_4\n+kill -TERM $PID_4\n wait\n+wait_for_queries_to_finish\n \n $CLICKHOUSE_CLIENT --multiquery --query \"\n BEGIN TRANSACTION;\ndiff --git a/tests/queries/0_stateless/replication.lib b/tests/queries/0_stateless/replication.lib\nindex 61491630f46d..6bf3c35f3441 100755\n--- a/tests/queries/0_stateless/replication.lib\n+++ b/tests/queries/0_stateless/replication.lib\n@@ -44,7 +44,7 @@ function check_replication_consistency()\n     num_tries=0\n     while [[ $($CLICKHOUSE_CLIENT -q \"SELECT count() FROM system.processes WHERE current_database=currentDatabase() AND query LIKE '%$table_name_prefix%'\") -ne 1 ]]; do\n         sleep 0.5;\n-        num_tries=$((num_tries-1))\n+        num_tries=$((num_tries+1))\n         if [ $num_tries -eq 100 ]; then\n             $CLICKHOUSE_CLIENT -q \"SELECT count() FROM system.processes WHERE current_database=currentDatabase() AND query LIKE '%$table_name_prefix%' FORMAT Vertical\"\n             break\ndiff --git a/tests/queries/shell_config.sh b/tests/queries/shell_config.sh\nindex ce5947d95ed4..8e9b9c2ac209 100644\n--- a/tests/queries/shell_config.sh\n+++ b/tests/queries/shell_config.sh\n@@ -129,3 +129,17 @@ function clickhouse_client_removed_host_parameter()\n     # bash regex magic is arcane, but version dependant and weak; sed or awk are not really portable.\n     $(echo \"$CLICKHOUSE_CLIENT\"  | python3 -c \"import sys, re; print(re.sub('--host(\\s+|=)[^\\s]+', '', sys.stdin.read()))\") \"$@\"\n }\n+\n+function wait_for_queries_to_finish()\n+{\n+    # Wait for all queries to finish (query may still be running if thread is killed by timeout)\n+    num_tries=0\n+    while [[ $($CLICKHOUSE_CLIENT -q \"SELECT count() FROM system.processes WHERE current_database=currentDatabase() AND query NOT LIKE '%system.processes%'\") -ne 0 ]]; do\n+        sleep 0.5;\n+        num_tries=$((num_tries+1))\n+        if [ $num_tries -eq 20 ]; then\n+            $CLICKHOUSE_CLIENT -q \"SELECT count() FROM system.processes WHERE current_database=currentDatabase() AND query NOT LIKE '%system.processes%' FORMAT Vertical\"\n+            break\n+        fi\n+    done\n+}\n",
  "problem_statement": "Logical error: 'Cannot unlock removal_tid, it's a bug'\nhttps://s3.amazonaws.com/clickhouse-test-reports/37837/d39e72411288ca572deebf98bc14c29e09546f66/stateless_tests__thread__actions__[1/3].html\r\n\r\n```\r\n2022.06.08 07:44:28.764640 [ 695 ] {} <Fatal> : Logical error: 'Cannot unlock removal_tid, it's a bug. Current: 15317705874040209379 (1, 1, 00000000-0000-0000-0000-000000000000), actual: 0 (0, 0, 00000000-0000-0000-0000-000000000000)'.\r\n2022.06.08 07:44:29.174959 [ 51544 ] {} <Fatal> BaseDaemon: ########################################\r\n2022.06.08 07:44:29.175070 [ 51544 ] {} <Fatal> BaseDaemon: (version 22.6.1.1, build id: 52E4307A00A9C93F) (from thread 695) (no query) Received signal Aborted (6)\r\n2022.06.08 07:44:29.175129 [ 51544 ] {} <Fatal> BaseDaemon: \r\n2022.06.08 07:44:29.175235 [ 51544 ] {} <Fatal> BaseDaemon: Stack trace: 0x7f432d4a800b 0x7f432d487859 0xb2a03fb 0xb36037a 0xb3605ad 0x1abe320f 0x1abe2fdf 0x1b7162bd 0x1b441821 0x1b8af9fb 0x1b455529 0x1b6c6834 0x1b6c7706 0x1b6cce82 0xb3f2d52 0xb3f5b39 0xb3f59e2 0xb3f0658 0xb3f3d91 0xb29ab19 0x7f432d65f609 0x7f432d584133\r\n2022.06.08 07:44:29.175372 [ 51544 ] {} <Fatal> BaseDaemon: 5. gsignal @ 0x7f432d4a800b in ?\r\n2022.06.08 07:44:29.175447 [ 51544 ] {} <Fatal> BaseDaemon: 6. abort @ 0x7f432d487859 in ?\r\n2022.06.08 07:44:49.762942 [ 625 ] {} <Fatal> Application: Child process was terminated by signal 6.\r\n```\n",
  "hints_text": "",
  "created_at": "2022-06-03T10:52:24Z",
  "modified_files": [
    "b/src/Common/noexcept_scope.h",
    "src/Daemon/BaseDaemon.cpp",
    "src/Interpreters/InterpreterTransactionControlQuery.cpp",
    "src/Interpreters/MergeTreeTransaction.cpp",
    "src/Interpreters/ThreadStatusExt.cpp",
    "src/Interpreters/TransactionLog.cpp",
    "src/Interpreters/TransactionVersionMetadata.cpp",
    "src/Storages/MergeTree/MergeTreeData.cpp",
    "src/Storages/MergeTree/MergeTreeData.h",
    "src/Storages/MergeTree/ReplicatedMergeTreeAltersSequence.cpp",
    "src/Storages/MergeTree/ReplicatedMergeTreeAltersSequence.h",
    "src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp",
    "src/Storages/MergeTree/ReplicatedMergeTreeQueue.h",
    "src/Storages/StorageMergeTree.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/01169_alter_partition_isolation_stress.sh",
    "tests/queries/0_stateless/01171_mv_select_insert_isolation_long.sh",
    "tests/queries/0_stateless/01174_select_insert_isolation.sh",
    "tests/queries/0_stateless/replication.lib",
    "tests/queries/shell_config.sh"
  ]
}