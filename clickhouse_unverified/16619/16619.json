{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 16619,
  "instance_id": "ClickHouse__ClickHouse-16619",
  "issue_numbers": [
    "3178"
  ],
  "base_commit": "70982fdc540ae0be874811c9c0b88ed36c297286",
  "patch": "diff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp\nindex 5feff841ca96..7697bbda36ba 100644\n--- a/src/Interpreters/executeQuery.cpp\n+++ b/src/Interpreters/executeQuery.cpp\n@@ -17,6 +17,7 @@\n \n #include <Parsers/ASTInsertQuery.h>\n #include <Parsers/ASTSelectQuery.h>\n+#include <Parsers/ASTSelectWithUnionQuery.h>\n #include <Parsers/ASTShowProcesslistQuery.h>\n #include <Parsers/ASTIdentifier.h>\n #include <Parsers/ASTLiteral.h>\n@@ -337,6 +338,27 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n         /// TODO Parser should fail early when max_query_size limit is reached.\n         ast = parseQuery(parser, begin, end, \"\", max_query_size, settings.max_parser_depth);\n \n+        /// Interpret SETTINGS clauses as early as possible (before invoking the corresponding interpreter),\n+        /// to allow settings to take effect.\n+        if (const auto * select_query = ast->as<ASTSelectQuery>())\n+        {\n+            if (auto new_settings = select_query->settings())\n+                InterpreterSetQuery(new_settings, context).executeForCurrentContext();\n+        }\n+        else if (const auto * select_with_union_query = ast->as<ASTSelectWithUnionQuery>())\n+        {\n+            if (!select_with_union_query->list_of_selects->children.empty())\n+            {\n+                if (auto new_settings = select_with_union_query->list_of_selects->children.back()->as<ASTSelectQuery>()->settings())\n+                    InterpreterSetQuery(new_settings, context).executeForCurrentContext();\n+            }\n+        }\n+        else if (const auto * query_with_output = dynamic_cast<const ASTQueryWithOutput *>(ast.get()))\n+        {\n+            if (query_with_output->settings_ast)\n+                InterpreterSetQuery(query_with_output->settings_ast, context).executeForCurrentContext();\n+        }\n+\n         auto * insert_query = ast->as<ASTInsertQuery>();\n \n         if (insert_query && insert_query->settings_ast)\n@@ -802,12 +824,12 @@ BlockIO executeQuery(\n }\n \n BlockIO executeQuery(\n-        const String & query,\n-        Context & context,\n-        bool internal,\n-        QueryProcessingStage::Enum stage,\n-        bool may_have_embedded_data,\n-        bool allow_processors)\n+    const String & query,\n+    Context & context,\n+    bool internal,\n+    QueryProcessingStage::Enum stage,\n+    bool may_have_embedded_data,\n+    bool allow_processors)\n {\n     BlockIO res = executeQuery(query, context, internal, stage, may_have_embedded_data);\n \n@@ -876,7 +898,6 @@ void executeQuery(\n         }\n         else if (streams.in)\n         {\n-            /// FIXME: try to prettify this cast using `as<>()`\n             const auto * ast_query_with_output = dynamic_cast<const ASTQueryWithOutput *>(ast.get());\n \n             WriteBuffer * out_buf = &ostr;\n@@ -895,9 +916,6 @@ void executeQuery(\n                 ? getIdentifierName(ast_query_with_output->format)\n                 : context.getDefaultFormat();\n \n-            if (ast_query_with_output && ast_query_with_output->settings_ast)\n-                InterpreterSetQuery(ast_query_with_output->settings_ast, context).executeForCurrentContext();\n-\n             BlockOutputStreamPtr out = context.getOutputFormat(format_name, *out_buf, streams.in->getHeader());\n \n             /// Save previous progress callback if any. TODO Do it more conveniently.\n@@ -936,9 +954,6 @@ void executeQuery(\n                                  ? getIdentifierName(ast_query_with_output->format)\n                                  : context.getDefaultFormat();\n \n-            if (ast_query_with_output && ast_query_with_output->settings_ast)\n-                InterpreterSetQuery(ast_query_with_output->settings_ast, context).executeForCurrentContext();\n-\n             if (!pipeline.isCompleted())\n             {\n                 pipeline.addSimpleTransform([](const Block & header)\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01553_settings_early_apply.reference b/tests/queries/0_stateless/01553_settings_early_apply.reference\nnew file mode 100644\nindex 000000000000..3dad208be5d2\n--- /dev/null\n+++ b/tests/queries/0_stateless/01553_settings_early_apply.reference\n@@ -0,0 +1,43 @@\n+ number\n+\n+      0 \n+ number\n+\n+      1 \n+0\n+1\n+2\n+3\n+4\n+5\n+6\n+7\n+8\n+9\n+{\n+\t\"meta\":\n+\t[\n+\t\t{\n+\t\t\t\"name\": \"number\",\n+\t\t\t\"type\": \"UInt64\"\n+\t\t}\n+\t],\n+\n+\t\"data\":\n+\t[\n+\t\t[\"0\"],\n+\t\t[\"1\"],\n+\t\t[\"2\"],\n+\t\t[\"3\"],\n+\t\t[\"4\"],\n+\t\t[\"5\"],\n+\t\t[\"6\"],\n+\t\t[\"7\"],\n+\t\t[\"8\"],\n+\t\t[\"9\"]\n+\t],\n+\n+\t\"rows\": 10,\n+\n+\t\"rows_before_limit_at_least\": 10\n+}\ndiff --git a/tests/queries/0_stateless/01553_settings_early_apply.sql b/tests/queries/0_stateless/01553_settings_early_apply.sql\nnew file mode 100644\nindex 000000000000..48178c38f334\n--- /dev/null\n+++ b/tests/queries/0_stateless/01553_settings_early_apply.sql\n@@ -0,0 +1,8 @@\n+select * from numbers(100) settings max_result_rows = 1; -- { serverError 396 }\n+select * from numbers(100) FORMAT JSON settings max_result_rows = 1; -- { serverError 396 }\n+\n+SET max_result_rows = 1;\n+select * from numbers(10); -- { serverError 396 }\n+select * from numbers(10) SETTINGS result_overflow_mode = 'break', max_block_size = 1 FORMAT PrettySpaceNoEscapes;\n+select * from numbers(10) settings max_result_rows = 10;\n+select * from numbers(10) FORMAT JSONCompact settings max_result_rows = 10, output_format_write_statistics = 0;\n",
  "problem_statement": "SETTING clause for selects interpreted too late?\nThat works as expected\r\n```\r\nSET max_result_rows=1;\r\nSELECT * from numbers(100);\r\n-- DB::Exception: Limit for result exceeded, max rows: 1.00, current rows: 100.00.\r\n```\r\n\r\nAnd that - parse query properly and return 100 rows instead of Excpetion.\r\n```\r\nselect * from numbers(100) settings  max_result_rows=1;\r\n```\r\n\n",
  "hints_text": "I don't know if it's connected, but log_queries=1 does not work in SETTINGS either",
  "created_at": "2020-11-02T19:25:26Z"
}