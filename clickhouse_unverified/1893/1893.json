{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 1893,
  "instance_id": "ClickHouse__ClickHouse-1893",
  "issue_numbers": [
    "1863"
  ],
  "base_commit": "ce03a8e48084244da2b8cafba69c50f7afd1d2c0",
  "patch": "diff --git a/dbms/src/Interpreters/DDLWorker.cpp b/dbms/src/Interpreters/DDLWorker.cpp\nindex e89476115a8a..f01bd8424e6d 100644\n--- a/dbms/src/Interpreters/DDLWorker.cpp\n+++ b/dbms/src/Interpreters/DDLWorker.cpp\n@@ -1097,15 +1097,9 @@ class DDLQueryStatusInputSream : public IProfilingBlockInputStream\n \n BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr_, const Context & context)\n {\n+    /// Remove FORMAT <fmt> and INTO OUTFILE <file> if exists\n     ASTPtr query_ptr = query_ptr_->clone();\n-\n-    /// Remove FORMAT ... INTO OUTFILE if exists\n-    if (dynamic_cast<const ASTQueryWithOutput *>(query_ptr_.get()))\n-    {\n-        auto query_with_output = dynamic_cast<ASTQueryWithOutput *>(query_ptr.get());\n-        query_with_output->out_file = nullptr;\n-        query_with_output->format = nullptr;\n-    }\n+    ASTQueryWithOutput::resetOutputASTIfExist(*query_ptr);\n \n     auto query = dynamic_cast<ASTQueryWithOnCluster *>(query_ptr.get());\n     if (!query)\ndiff --git a/dbms/src/Interpreters/InterpreterCreateQuery.cpp b/dbms/src/Interpreters/InterpreterCreateQuery.cpp\nindex 8e803a39f7de..853d42c5ccfd 100644\n--- a/dbms/src/Interpreters/InterpreterCreateQuery.cpp\n+++ b/dbms/src/Interpreters/InterpreterCreateQuery.cpp\n@@ -587,6 +587,7 @@ BlockIO InterpreterCreateQuery::execute()\n {\n     ASTCreateQuery & create = typeid_cast<ASTCreateQuery &>(*query_ptr);\n     checkAccess(create);\n+    ASTQueryWithOutput::resetOutputASTIfExist(create);\n \n     /// CREATE|ATTACH DATABASE\n     if (!create.database.empty() && create.table.empty())\ndiff --git a/dbms/src/Parsers/ASTQueryWithOutput.cpp b/dbms/src/Parsers/ASTQueryWithOutput.cpp\nindex 7548ac0cc54c..62abe5de9e11 100644\n--- a/dbms/src/Parsers/ASTQueryWithOutput.cpp\n+++ b/dbms/src/Parsers/ASTQueryWithOutput.cpp\n@@ -36,4 +36,17 @@ void ASTQueryWithOutput::formatImpl(const FormatSettings & s, FormatState & stat\n     }\n }\n \n+bool ASTQueryWithOutput::resetOutputASTIfExist(IAST & ast)\n+{\n+    if (auto ast_with_output = dynamic_cast<ASTQueryWithOutput *>(&ast))\n+    {\n+        ast_with_output->format.reset();\n+        ast_with_output->out_file.reset();\n+        return true;\n+    }\n+\n+    return false;\n+}\n+\n+\n }\ndiff --git a/dbms/src/Parsers/ASTQueryWithOutput.h b/dbms/src/Parsers/ASTQueryWithOutput.h\nindex 8f2482ddeb7b..40ac02380e5b 100644\n--- a/dbms/src/Parsers/ASTQueryWithOutput.h\n+++ b/dbms/src/Parsers/ASTQueryWithOutput.h\n@@ -19,6 +19,9 @@ class ASTQueryWithOutput : public IAST\n \n     void formatImpl(const FormatSettings & s, FormatState & state, FormatStateStacked frame) const final;\n \n+    /// Remove 'FORMAT <fmt> and INTO OUTFILE <file>' if exists\n+    static bool resetOutputASTIfExist(IAST & ast);\n+\n protected:\n     /// NOTE: call this helper at the end of the clone() method of descendant class.\n     void cloneOutputOptions(ASTQueryWithOutput & cloned) const;\ndiff --git a/dbms/src/Storages/StorageMaterializedView.cpp b/dbms/src/Storages/StorageMaterializedView.cpp\nindex f1326a52933f..820ccdb969ea 100644\n--- a/dbms/src/Storages/StorageMaterializedView.cpp\n+++ b/dbms/src/Storages/StorageMaterializedView.cpp\n@@ -190,6 +190,12 @@ StoragePtr StorageMaterializedView::getTargetTable() const\n     return global_context.getTable(target_database_name, target_table_name);\n }\n \n+bool StorageMaterializedView::checkTableCanBeDropped() const\n+{\n+    /// Don't drop the target table if it was created manually via 'TO inner_table' statement\n+    return has_inner_table ? getTargetTable()->checkTableCanBeDropped() : true;\n+}\n+\n \n void registerStorageMaterializedView(StorageFactory & factory)\n {\ndiff --git a/dbms/src/Storages/StorageMaterializedView.h b/dbms/src/Storages/StorageMaterializedView.h\nindex b2a2069166aa..9b9b538b31f1 100644\n--- a/dbms/src/Storages/StorageMaterializedView.h\n+++ b/dbms/src/Storages/StorageMaterializedView.h\n@@ -33,6 +33,7 @@ class StorageMaterializedView : public ext::shared_ptr_helper<StorageMaterialize\n     void drop() override;\n     bool optimize(const ASTPtr & query, const ASTPtr & partition, bool final, bool deduplicate, const Context & context) override;\n     void shutdown() override;\n+    bool checkTableCanBeDropped() const override;\n \n     BlockInputStreams read(\n         const Names & column_names,\ndiff --git a/dbms/src/TableFunctions/TableFunctionRemote.cpp b/dbms/src/TableFunctions/TableFunctionRemote.cpp\nindex 63c917b6832c..58537492e530 100644\n--- a/dbms/src/TableFunctions/TableFunctionRemote.cpp\n+++ b/dbms/src/TableFunctions/TableFunctionRemote.cpp\n@@ -185,18 +185,18 @@ StoragePtr TableFunctionRemote::execute(const ASTPtr & ast_function, const Conte\n {\n     ASTs & args_func = typeid_cast<ASTFunction &>(*ast_function).children;\n \n-    const char * err = \"Table function 'remote' requires from 2 to 5 parameters: \"\n-        \"addresses pattern, name of remote database, name of remote table, [username, [password]].\";\n+    const size_t max_args = is_cluster_function ? 3 : 5;\n \n     if (args_func.size() != 1)\n-        throw Exception(err, ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH);\n+        throw Exception(help_message, ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH);\n \n     ASTs & args = typeid_cast<ASTExpressionList &>(*args_func.at(0)).children;\n \n-    if (args.size() < 2 || args.size() > 5)\n-        throw Exception(err, ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH);\n+    if (args.size() < 2 || args.size() > max_args)\n+        throw Exception(help_message, ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH);\n \n-    String description;\n+    String cluster_name;\n+    String cluster_description;\n     String remote_database;\n     String remote_table;\n     String username;\n@@ -216,7 +216,18 @@ StoragePtr TableFunctionRemote::execute(const ASTPtr & ast_function, const Conte\n         return safeGet<const String &>(lit->value);\n     };\n \n-    description = getStringLiteral(*args[arg_num], \"Hosts pattern\");\n+    if (is_cluster_function)\n+    {\n+        ASTPtr ast_name = evaluateConstantExpressionOrIdentifierAsLiteral(args[arg_num], context);\n+        cluster_name = static_cast<const ASTLiteral &>(*ast_name).value.safeGet<const String &>();\n+    }\n+    else\n+    {\n+        if (auto ast_cluster = typeid_cast<const ASTIdentifier *>(args[arg_num].get()))\n+            cluster_name = ast_cluster->name;\n+        else\n+            cluster_description = getStringLiteral(*args[arg_num], \"Hosts pattern\");\n+    }\n     ++arg_num;\n \n     args[arg_num] = evaluateConstantExpressionOrIdentifierAsLiteral(args[arg_num], context);\n@@ -233,29 +244,33 @@ StoragePtr TableFunctionRemote::execute(const ASTPtr & ast_function, const Conte\n     else\n     {\n         if (arg_num >= args.size())\n-            throw Exception(err, ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH);\n+            throw Exception(help_message, ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH);\n \n         args[arg_num] = evaluateConstantExpressionOrIdentifierAsLiteral(args[arg_num], context);\n         remote_table = static_cast<const ASTLiteral &>(*args[arg_num]).value.safeGet<String>();\n         ++arg_num;\n     }\n \n-    if (arg_num < args.size())\n+    /// Username and password parameters are prohibited in cluster version of the function\n+    if (!is_cluster_function)\n     {\n-        username = getStringLiteral(*args[arg_num], \"Username\");\n-        ++arg_num;\n-    }\n-    else\n-        username = \"default\";\n+        if (arg_num < args.size())\n+        {\n+            username = getStringLiteral(*args[arg_num], \"Username\");\n+            ++arg_num;\n+        }\n+        else\n+            username = \"default\";\n \n-    if (arg_num < args.size())\n-    {\n-        password = getStringLiteral(*args[arg_num], \"Password\");\n-        ++arg_num;\n+        if (arg_num < args.size())\n+        {\n+            password = getStringLiteral(*args[arg_num], \"Password\");\n+            ++arg_num;\n+        }\n     }\n \n     if (arg_num < args.size())\n-        throw Exception(err, ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH);\n+        throw Exception(help_message, ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH);\n \n     /// ExpressionAnalyzer will be created in InterpreterSelectQuery that will meet these `Identifier` when processing the request.\n     /// We need to mark them as the name of the database or table, because the default value is column.\n@@ -265,16 +280,26 @@ StoragePtr TableFunctionRemote::execute(const ASTPtr & ast_function, const Conte\n \n     size_t max_addresses = context.getSettingsRef().table_function_remote_max_addresses;\n \n-    std::vector<std::vector<String>> names;\n-    std::vector<String> shards = parseDescription(description, 0, description.size(), ',', max_addresses);\n+    ClusterPtr cluster;\n+    if (!cluster_name.empty())\n+    {\n+        /// Use an existing cluster from the main config\n+        cluster = context.getCluster(cluster_name);\n+    }\n+    else\n+    {\n+        /// Create new cluster from the scratch\n+        std::vector<String> shards = parseDescription(cluster_description, 0, cluster_description.size(), ',', max_addresses);\n \n-    for (size_t i = 0; i < shards.size(); ++i)\n-        names.push_back(parseDescription(shards[i], 0, shards[i].size(), '|', max_addresses));\n+        std::vector<std::vector<String>> names;\n+        for (size_t i = 0; i < shards.size(); ++i)\n+            names.push_back(parseDescription(shards[i], 0, shards[i].size(), '|', max_addresses));\n \n-    if (names.empty())\n-        throw Exception(\"Shard list is empty after parsing first argument\", ErrorCodes::BAD_ARGUMENTS);\n+        if (names.empty())\n+            throw Exception(\"Shard list is empty after parsing first argument\", ErrorCodes::BAD_ARGUMENTS);\n \n-    auto cluster = std::make_shared<Cluster>(context.getSettings(), names, username, password, context.getTCPPort());\n+        cluster = std::make_shared<Cluster>(context.getSettings(), names, username, password, context.getTCPPort());\n+    }\n \n     auto res = StorageDistributed::createWithOwnCluster(\n         getName(),\n@@ -288,9 +313,23 @@ StoragePtr TableFunctionRemote::execute(const ASTPtr & ast_function, const Conte\n }\n \n \n+TableFunctionRemote::TableFunctionRemote(const std::string & name_)\n+    : name(name_)\n+{\n+    is_cluster_function = name == \"cluster\";\n+\n+    std::stringstream ss;\n+    ss << \"Table function '\" << name + \"' requires from 2 to \" << (is_cluster_function ? 3 : 5) << \" parameters\"\n+       << \": <addresses pattern or cluster name>, <name of remote database>, <name of remote table>\"\n+       << (is_cluster_function ? \"\" : \", [username, [password]].\");\n+    help_message = ss.str();\n+}\n+\n+\n void registerTableFunctionRemote(TableFunctionFactory & factory)\n {\n-    factory.registerFunction<TableFunctionRemote>();\n+    factory.registerFunction(\"remote\", [] () -> TableFunctionPtr { return std::make_shared<TableFunctionRemote>(\"remote\"); });\n+    factory.registerFunction(\"cluster\", [] () -> TableFunctionPtr { return std::make_shared<TableFunctionRemote>(\"cluster\"); });\n }\n \n }\ndiff --git a/dbms/src/TableFunctions/TableFunctionRemote.h b/dbms/src/TableFunctions/TableFunctionRemote.h\nindex 1891dbd3795a..d1cce5999036 100644\n--- a/dbms/src/TableFunctions/TableFunctionRemote.h\n+++ b/dbms/src/TableFunctions/TableFunctionRemote.h\n@@ -11,13 +11,23 @@ namespace DB\n  * For example\n  * SELECT count() FROM remote('example01-01-1', merge, hits) - go to `example01-01-1`, in the merge database, the hits table.\n  * An expression that generates a set of shards and replicas can also be specified as the host name - see below.\n+ * Also, there is a cluster version of the function: cluster('existing_cluster_name', 'db', 'table')\n  */\n class TableFunctionRemote : public ITableFunction\n {\n public:\n-    static constexpr auto name = \"remote\";\n+\n+    explicit TableFunctionRemote(const std::string & name_ = \"remote\");\n+\n     std::string getName() const override { return name; }\n+\n     StoragePtr execute(const ASTPtr & ast_function, const Context & context) const override;\n+\n+private:\n+\n+    std::string name;\n+    bool is_cluster_function;\n+    std::string help_message;\n };\n \n }\n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/00557_remote_port.reference b/dbms/tests/queries/0_stateless/00557_remote_port.reference\nindex 405d33487754..c4f459c5fe7a 100644\n--- a/dbms/tests/queries/0_stateless/00557_remote_port.reference\n+++ b/dbms/tests/queries/0_stateless/00557_remote_port.reference\n@@ -6,3 +6,6 @@\n 0\n 0\n 0\n+0\n+0\n+0\ndiff --git a/dbms/tests/queries/0_stateless/00557_remote_port.sh b/dbms/tests/queries/0_stateless/00557_remote_port.sh\nindex 9cb3c29e3adb..e2a736f02a83 100755\n--- a/dbms/tests/queries/0_stateless/00557_remote_port.sh\n+++ b/dbms/tests/queries/0_stateless/00557_remote_port.sh\n@@ -20,3 +20,7 @@ fi\n \n $CLICKHOUSE_CLIENT -q \"SELECT * FROM remote('${CLICKHOUSE_HOST}',          system, one);\"\n $CLICKHOUSE_CLIENT -q \"SELECT * FROM remote('${CLICKHOUSE_HOST}:${CLICKHOUSE_PORT_TCP}',     system, one);\"\n+\n+$CLICKHOUSE_CLIENT -q \"SELECT * FROM remote(test_shard_localhost, system, one);\"\n+$CLICKHOUSE_CLIENT -q \"SELECT * FROM remote(test_shard_localhost, system, one, 'default', '');\"\n+$CLICKHOUSE_CLIENT -q \"SELECT * FROM cluster('test_shard_localhost', system, one);\"\n",
  "problem_statement": "Fail on dropping materialised view removes alias but not inner table\nWhen a drop table on a materialised view X fails because of this 50GB-limitation, the alias X get's deleted anyway but not the \"real table\" .inner.X. \r\n\r\nIs this behaviour intended?\n",
  "hints_text": "Indeed, there is some inconsistency here. If you drop a MV (which size is 0), a real table should be dropped and checked also, but the size of the MV is only checked.",
  "created_at": "2018-02-12T19:27:37Z"
}