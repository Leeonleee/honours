{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 44533,
  "instance_id": "ClickHouse__ClickHouse-44533",
  "issue_numbers": [
    "40951"
  ],
  "base_commit": "c646048af96691bfffea75141fb322237bf3909a",
  "patch": "diff --git a/src/Coordination/KeeperDispatcher.cpp b/src/Coordination/KeeperDispatcher.cpp\nindex f6973b30fb2e..92aeac425d5e 100644\n--- a/src/Coordination/KeeperDispatcher.cpp\n+++ b/src/Coordination/KeeperDispatcher.cpp\n@@ -296,7 +296,7 @@ bool KeeperDispatcher::putRequest(const Coordination::ZooKeeperRequestPtr & requ\n     return true;\n }\n \n-void KeeperDispatcher::initialize(const Poco::Util::AbstractConfiguration & config, bool standalone_keeper, bool start_async)\n+void KeeperDispatcher::initialize(const Poco::Util::AbstractConfiguration & config, bool standalone_keeper, bool start_async, const MultiVersion<Macros>::Version & macros)\n {\n     LOG_DEBUG(log, \"Initializing storage dispatcher\");\n \n@@ -307,7 +307,7 @@ void KeeperDispatcher::initialize(const Poco::Util::AbstractConfiguration & conf\n     responses_thread = ThreadFromGlobalPool([this] { responseThread(); });\n     snapshot_thread = ThreadFromGlobalPool([this] { snapshotThread(); });\n \n-    snapshot_s3.startup(config);\n+    snapshot_s3.startup(config, macros);\n \n     server = std::make_unique<KeeperServer>(configuration_and_settings, config, responses_queue, snapshots_queue, snapshot_s3);\n \n@@ -687,7 +687,7 @@ bool KeeperDispatcher::isServerActive() const\n     return checkInit() && hasLeader() && !server->isRecovering();\n }\n \n-void KeeperDispatcher::updateConfiguration(const Poco::Util::AbstractConfiguration & config)\n+void KeeperDispatcher::updateConfiguration(const Poco::Util::AbstractConfiguration & config, const MultiVersion<Macros>::Version & macros)\n {\n     auto diff = server->getConfigurationDiff(config);\n     if (diff.empty())\n@@ -704,7 +704,7 @@ void KeeperDispatcher::updateConfiguration(const Poco::Util::AbstractConfigurati\n             throw Exception(ErrorCodes::SYSTEM_ERROR, \"Cannot push configuration update to queue\");\n     }\n \n-    snapshot_s3.updateS3Configuration(config);\n+    snapshot_s3.updateS3Configuration(config, macros);\n }\n \n void KeeperDispatcher::updateKeeperStatLatency(uint64_t process_time_ms)\ndiff --git a/src/Coordination/KeeperDispatcher.h b/src/Coordination/KeeperDispatcher.h\nindex 632e5e65e5fe..ff902d8e0366 100644\n--- a/src/Coordination/KeeperDispatcher.h\n+++ b/src/Coordination/KeeperDispatcher.h\n@@ -15,6 +15,8 @@\n #include <Coordination/Keeper4LWInfo.h>\n #include <Coordination/KeeperConnectionStats.h>\n #include <Coordination/KeeperSnapshotManagerS3.h>\n+#include <Common/MultiVersion.h>\n+#include <Common/Macros.h>\n \n namespace DB\n {\n@@ -109,7 +111,8 @@ class KeeperDispatcher\n \n     /// Initialization from config.\n     /// standalone_keeper -- we are standalone keeper application (not inside clickhouse server)\n-    void initialize(const Poco::Util::AbstractConfiguration & config, bool standalone_keeper, bool start_async);\n+    /// 'macros' are used to substitute macros in endpoint of disks\n+    void initialize(const Poco::Util::AbstractConfiguration & config, bool standalone_keeper, bool start_async, const MultiVersion<Macros>::Version & macros);\n \n     void startServer();\n \n@@ -124,7 +127,8 @@ class KeeperDispatcher\n \n     /// Registered in ConfigReloader callback. Add new configuration changes to\n     /// update_configuration_queue. Keeper Dispatcher apply them asynchronously.\n-    void updateConfiguration(const Poco::Util::AbstractConfiguration & config);\n+    /// 'macros' are used to substitute macros in endpoint of disks\n+    void updateConfiguration(const Poco::Util::AbstractConfiguration & config, const MultiVersion<Macros>::Version & macros);\n \n     /// Shutdown internal keeper parts (server, state machine, log storage, etc)\n     void shutdown();\ndiff --git a/src/Coordination/KeeperSnapshotManagerS3.cpp b/src/Coordination/KeeperSnapshotManagerS3.cpp\nindex 361265e382a0..b793cef4b94d 100644\n--- a/src/Coordination/KeeperSnapshotManagerS3.cpp\n+++ b/src/Coordination/KeeperSnapshotManagerS3.cpp\n@@ -14,6 +14,7 @@\n #include <IO/S3/PocoHTTPClient.h>\n #include <IO/WriteHelpers.h>\n #include <IO/copyData.h>\n+#include <Common/Macros.h>\n \n #include <aws/core/auth/AWSCredentials.h>\n #include <aws/s3/S3Client.h>\n@@ -47,7 +48,7 @@ KeeperSnapshotManagerS3::KeeperSnapshotManagerS3()\n     , uuid(UUIDHelpers::generateV4())\n {}\n \n-void KeeperSnapshotManagerS3::updateS3Configuration(const Poco::Util::AbstractConfiguration & config)\n+void KeeperSnapshotManagerS3::updateS3Configuration(const Poco::Util::AbstractConfiguration & config, const MultiVersion<Macros>::Version & macros)\n {\n     try\n     {\n@@ -64,7 +65,7 @@ void KeeperSnapshotManagerS3::updateS3Configuration(const Poco::Util::AbstractCo\n \n         auto auth_settings = S3::AuthSettings::loadFromConfig(config_prefix, config);\n \n-        auto endpoint = config.getString(config_prefix + \".endpoint\");\n+        String endpoint = macros->expand(config.getString(config_prefix + \".endpoint\"));\n         auto new_uri = S3::URI{endpoint};\n \n         {\n@@ -261,9 +262,9 @@ void KeeperSnapshotManagerS3::uploadSnapshot(const std::string & path, bool asyn\n     uploadSnapshotImpl(path);\n }\n \n-void KeeperSnapshotManagerS3::startup(const Poco::Util::AbstractConfiguration & config)\n+void KeeperSnapshotManagerS3::startup(const Poco::Util::AbstractConfiguration & config, const MultiVersion<Macros>::Version & macros)\n {\n-    updateS3Configuration(config);\n+    updateS3Configuration(config, macros);\n     snapshot_s3_thread = ThreadFromGlobalPool([this] { snapshotS3Thread(); });\n }\n \ndiff --git a/src/Coordination/KeeperSnapshotManagerS3.h b/src/Coordination/KeeperSnapshotManagerS3.h\nindex 5b62d114aae6..197f528b1927 100644\n--- a/src/Coordination/KeeperSnapshotManagerS3.h\n+++ b/src/Coordination/KeeperSnapshotManagerS3.h\n@@ -3,6 +3,8 @@\n #include \"config.h\"\n \n #include <Poco/Util/AbstractConfiguration.h>\n+#include <Common/MultiVersion.h>\n+#include <Common/Macros.h>\n \n #if USE_AWS_S3\n #include <Common/ConcurrentBoundedQueue.h>\n@@ -21,10 +23,12 @@ class KeeperSnapshotManagerS3\n public:\n     KeeperSnapshotManagerS3();\n \n-    void updateS3Configuration(const Poco::Util::AbstractConfiguration & config);\n+    /// 'macros' are used to substitute macros in endpoint of disks\n+    void updateS3Configuration(const Poco::Util::AbstractConfiguration & config, const MultiVersion<Macros>::Version & macros);\n     void uploadSnapshot(const std::string & path, bool async_upload = true);\n \n-    void startup(const Poco::Util::AbstractConfiguration & config);\n+    /// 'macros' are used to substitute macros in endpoint of disks\n+    void startup(const Poco::Util::AbstractConfiguration & config, const MultiVersion<Macros>::Version & macros);\n     void shutdown();\n private:\n     using SnapshotS3Queue = ConcurrentBoundedQueue<std::string>;\n@@ -56,10 +60,10 @@ class KeeperSnapshotManagerS3\n public:\n     KeeperSnapshotManagerS3() = default;\n \n-    void updateS3Configuration(const Poco::Util::AbstractConfiguration &) {}\n+    void updateS3Configuration(const Poco::Util::AbstractConfiguration &, const MultiVersion<Macros>::Version &) {}\n     void uploadSnapshot(const std::string &, [[maybe_unused]] bool async_upload = true) {}\n \n-    void startup(const Poco::Util::AbstractConfiguration &) {}\n+    void startup(const Poco::Util::AbstractConfiguration &, const MultiVersion<Macros>::Version &) {}\n \n     void shutdown() {}\n };\ndiff --git a/src/Coordination/TinyContext.cpp b/src/Coordination/TinyContext.cpp\nindex 967e6b23d70a..47b0a48dcdaa 100644\n--- a/src/Coordination/TinyContext.cpp\n+++ b/src/Coordination/TinyContext.cpp\n@@ -36,7 +36,12 @@ void TinyContext::initializeKeeperDispatcher([[maybe_unused]] bool start_async)\n     if (config_ref.has(\"keeper_server\"))\n     {\n         keeper_dispatcher = std::make_shared<KeeperDispatcher>();\n-        keeper_dispatcher->initialize(config_ref, true, start_async);\n+\n+        MultiVersion<Macros>::Version macros;\n+\n+        if (config_ref.has(\"macros\"))\n+            macros = std::make_unique<Macros>(config_ref, \"macros\", &Poco::Logger::get(\"TinyContext\"));\n+        keeper_dispatcher->initialize(config_ref, true, start_async, macros);\n     }\n }\n \n@@ -71,7 +76,12 @@ void TinyContext::updateKeeperConfiguration([[maybe_unused]] const Poco::Util::A\n     if (!keeper_dispatcher)\n         return;\n \n-    keeper_dispatcher->updateConfiguration(config_);\n+    MultiVersion<Macros>::Version macros;\n+\n+    if (config_.has(\"macros\"))\n+        macros = std::make_unique<Macros>(config_, \"macros\", &Poco::Logger::get(\"TinyContext\"));\n+\n+    keeper_dispatcher->updateConfiguration(config_, macros);\n }\n \n }\ndiff --git a/src/Disks/ObjectStorages/HDFS/registerDiskHDFS.cpp b/src/Disks/ObjectStorages/HDFS/registerDiskHDFS.cpp\nindex 4e4d35a07f81..db134f3dcbac 100644\n--- a/src/Disks/ObjectStorages/HDFS/registerDiskHDFS.cpp\n+++ b/src/Disks/ObjectStorages/HDFS/registerDiskHDFS.cpp\n@@ -4,6 +4,7 @@\n #include <Disks/ObjectStorages/MetadataStorageFromDisk.h>\n #include <Disks/DiskFactory.h>\n #include <Storages/HDFS/HDFSCommon.h>\n+#include <Common/Macros.h>\n \n namespace DB\n {\n@@ -22,7 +23,8 @@ void registerDiskHDFS(DiskFactory & factory, bool global_skip_access_check)\n         ContextPtr context,\n         const DisksMap & /*map*/) -> DiskPtr\n     {\n-        String uri{config.getString(config_prefix + \".endpoint\")};\n+        String endpoint = context->getMacros()->expand(config.getString(config_prefix + \".endpoint\"));\n+        String uri{endpoint};\n         checkHDFSURL(uri);\n \n         if (uri.back() != '/')\ndiff --git a/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp b/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp\nindex d655fd374587..3c620ca819ea 100644\n--- a/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp\n+++ b/src/Disks/ObjectStorages/S3/S3ObjectStorage.cpp\n@@ -1,5 +1,7 @@\n #include <Disks/ObjectStorages/S3/S3ObjectStorage.h>\n #include <Common/ProfileEvents.h>\n+#include <Interpreters/Context.h>\n+\n \n #if USE_AWS_S3\n \n@@ -31,6 +33,7 @@\n #include <Common/StringUtils/StringUtils.h>\n #include <Common/logger_useful.h>\n #include <Common/MultiVersion.h>\n+#include <Common/Macros.h>\n \n \n namespace ProfileEvents\n@@ -634,10 +637,11 @@ std::unique_ptr<IObjectStorage> S3ObjectStorage::cloneObjectStorage(\n {\n     auto new_s3_settings = getSettings(config, config_prefix, context);\n     auto new_client = getClient(config, config_prefix, context, *new_s3_settings);\n+    String endpoint = context->getMacros()->expand(config.getString(config_prefix + \".endpoint\"));\n     return std::make_unique<S3ObjectStorage>(\n         std::move(new_client), std::move(new_s3_settings),\n         version_id, s3_capabilities, new_namespace,\n-        config.getString(config_prefix + \".endpoint\"));\n+        endpoint);\n }\n \n }\ndiff --git a/src/Disks/ObjectStorages/S3/diskSettings.cpp b/src/Disks/ObjectStorages/S3/diskSettings.cpp\nindex 87533a5a4e04..d5c6b03082f8 100644\n--- a/src/Disks/ObjectStorages/S3/diskSettings.cpp\n+++ b/src/Disks/ObjectStorages/S3/diskSettings.cpp\n@@ -21,6 +21,7 @@\n #include <Disks/ObjectStorages/S3/ProxyResolverConfiguration.h>\n #include <Disks/ObjectStorages/DiskObjectStorageCommon.h>\n #include <Disks/DiskLocal.h>\n+#include <Common/Macros.h>\n \n namespace DB\n {\n@@ -121,7 +122,8 @@ std::unique_ptr<Aws::S3::S3Client> getClient(\n         settings.request_settings.get_request_throttler,\n         settings.request_settings.put_request_throttler);\n \n-    S3::URI uri(config.getString(config_prefix + \".endpoint\"));\n+    String endpoint = context->getMacros()->expand(config.getString(config_prefix + \".endpoint\"));\n+    S3::URI uri(endpoint);\n     if (uri.key.back() != '/')\n         throw Exception(\"S3 path must ends with '/', but '\" + uri.key + \"' doesn't.\", ErrorCodes::BAD_ARGUMENTS);\n \ndiff --git a/src/Disks/ObjectStorages/S3/registerDiskS3.cpp b/src/Disks/ObjectStorages/S3/registerDiskS3.cpp\nindex 236662a7b5ef..1c192a0d89cc 100644\n--- a/src/Disks/ObjectStorages/S3/registerDiskS3.cpp\n+++ b/src/Disks/ObjectStorages/S3/registerDiskS3.cpp\n@@ -23,6 +23,7 @@\n \n #include <Storages/StorageS3Settings.h>\n #include <Core/ServerUUID.h>\n+#include <Common/Macros.h>\n \n \n namespace DB\n@@ -104,7 +105,8 @@ void registerDiskS3(DiskFactory & factory, bool global_skip_access_check)\n         ContextPtr context,\n         const DisksMap & /*map*/) -> DiskPtr\n     {\n-        S3::URI uri(config.getString(config_prefix + \".endpoint\"));\n+        String endpoint = context->getMacros()->expand(config.getString(config_prefix + \".endpoint\"));\n+        S3::URI uri(endpoint);\n \n         if (uri.key.empty())\n             throw Exception(ErrorCodes::BAD_ARGUMENTS, \"No key in S3 uri: {}\", uri.uri.toString());\ndiff --git a/src/Disks/ObjectStorages/Web/registerDiskWebServer.cpp b/src/Disks/ObjectStorages/Web/registerDiskWebServer.cpp\nindex 253d32ceb14a..8a54de81815a 100644\n--- a/src/Disks/ObjectStorages/Web/registerDiskWebServer.cpp\n+++ b/src/Disks/ObjectStorages/Web/registerDiskWebServer.cpp\n@@ -5,6 +5,9 @@\n #include <Disks/ObjectStorages/Web/MetadataStorageFromStaticFilesWebServer.h>\n #include <Disks/ObjectStorages/DiskObjectStorage.h>\n #include <Common/assert_cast.h>\n+#include <Common/Macros.h>\n+#include <Interpreters/Context.h>\n+\n \n namespace DB\n {\n@@ -23,7 +26,7 @@ void registerDiskWebServer(DiskFactory & factory, bool global_skip_access_check)\n         ContextPtr context,\n         const DisksMap & /*map*/) -> DiskPtr\n     {\n-        String uri{config.getString(config_prefix + \".endpoint\")};\n+        String uri = context->getMacros()->expand(config.getString(config_prefix + \".endpoint\"));\n         bool skip_access_check = global_skip_access_check || config.getBool(config_prefix + \".skip_access_check\", false);\n \n         if (!uri.ends_with('/'))\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex f97fd422662f..22c1dbb09c69 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -2356,7 +2356,7 @@ void Context::initializeKeeperDispatcher([[maybe_unused]] bool start_async) cons\n         }\n \n         shared->keeper_dispatcher = std::make_shared<KeeperDispatcher>();\n-        shared->keeper_dispatcher->initialize(config, is_standalone_app, start_async);\n+        shared->keeper_dispatcher->initialize(config, is_standalone_app, start_async, getMacros());\n     }\n #endif\n }\n@@ -2398,7 +2398,7 @@ void Context::updateKeeperConfiguration([[maybe_unused]] const Poco::Util::Abstr\n     if (!shared->keeper_dispatcher)\n         return;\n \n-    shared->keeper_dispatcher->updateConfiguration(config);\n+    shared->keeper_dispatcher->updateConfiguration(config, getMacros());\n #endif\n }\n \n",
  "test_patch": "diff --git a/tests/integration/test_endpoint_macro_substitution/__init__.py b/tests/integration/test_endpoint_macro_substitution/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_endpoint_macro_substitution/configs/config.xml b/tests/integration/test_endpoint_macro_substitution/configs/config.xml\nnew file mode 100644\nindex 000000000000..d4a2a9cf3674\n--- /dev/null\n+++ b/tests/integration/test_endpoint_macro_substitution/configs/config.xml\n@@ -0,0 +1,26 @@\n+<clickhouse>\n+    <logger>\n+        <level>trace</level>\n+        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\n+        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>\n+        <size>1000M</size>\n+        <count>10</count>\n+    </logger>\n+\n+    <tcp_port>9000</tcp_port>\n+    <listen_host>127.0.0.1</listen_host>\n+\n+    <openSSL>\n+        <client>\n+            <cacheSessions>true</cacheSessions>\n+            <verificationMode>none</verificationMode>\n+            <invalidCertificateHandler>\n+                <name>AcceptCertificateHandler</name>\n+            </invalidCertificateHandler>\n+        </client>\n+    </openSSL>\n+\n+    <max_concurrent_queries>500</max_concurrent_queries>\n+    <path>./clickhouse/</path>\n+    <users_config>users.xml</users_config>\n+</clickhouse>\ndiff --git a/tests/integration/test_endpoint_macro_substitution/configs/macros.xml b/tests/integration/test_endpoint_macro_substitution/configs/macros.xml\nnew file mode 100644\nindex 000000000000..ee21a24c3ba6\n--- /dev/null\n+++ b/tests/integration/test_endpoint_macro_substitution/configs/macros.xml\n@@ -0,0 +1,12 @@\n+<clickhouse>\n+    <macros>\n+        <test>Hello, world!</test>\n+        <default_cluster_macro>test_shard_localhost</default_cluster_macro>\n+        <shard>s1</shard>\n+        <replica>r1</replica>\n+        <endpoint_substitution>data</endpoint_substitution>\n+        <hdfs_endpoint_substitution>clickhouse</hdfs_endpoint_substitution>\n+        <default_path_test>/clickhouse/tables/{database}/{shard}/</default_path_test>\n+        <default_name_test>table_{table}</default_name_test>\n+    </macros>\n+</clickhouse>\ndiff --git a/tests/integration/test_endpoint_macro_substitution/configs/storage.xml b/tests/integration/test_endpoint_macro_substitution/configs/storage.xml\nnew file mode 100644\nindex 000000000000..4c6320b2e488\n--- /dev/null\n+++ b/tests/integration/test_endpoint_macro_substitution/configs/storage.xml\n@@ -0,0 +1,24 @@\n+<clickhouse>\n+    <macros incl=\"macros\" optional=\"true\" replace=\"replace\"/>\n+    <storage_configuration>\n+        <disks>\n+            <disk_s3>\n+                <type>s3</type>\n+                <endpoint>http://minio1:9001/root/{endpoint_substitution}/</endpoint>\n+                <access_key_id>minio</access_key_id>\n+                <secret_access_key>minio123</secret_access_key>\n+            </disk_s3>\n+            <disk_hdfs>\n+                <type>hdfs</type>\n+                <endpoint>hdfs://hdfs1:9000/{hdfs_endpoint_substitution}/</endpoint>\n+                <!-- FIXME: chicken and egg problem with current cluster.py -->\n+                <skip_access_check>true</skip_access_check>\n+            </disk_hdfs>\n+            <disk_encrypted>\n+                <type>encrypted</type>\n+                <disk>disk_s3</disk>\n+                <key>1234567812345678</key>\n+            </disk_encrypted>\n+        </disks>\n+    </storage_configuration>\n+</clickhouse>\ndiff --git a/tests/integration/test_endpoint_macro_substitution/configs/users.xml b/tests/integration/test_endpoint_macro_substitution/configs/users.xml\nnew file mode 100644\nindex 000000000000..4555a2ed4945\n--- /dev/null\n+++ b/tests/integration/test_endpoint_macro_substitution/configs/users.xml\n@@ -0,0 +1,22 @@\n+<clickhouse>\n+    <profiles>\n+        <default>\n+        </default>\n+    </profiles>\n+\n+    <users>\n+        <default>\n+            <password></password>\n+            <networks incl=\"networks\" replace=\"replace\">\n+                <ip>::/0</ip>\n+            </networks>\n+            <profile>default</profile>\n+            <quota>default</quota>\n+        </default>\n+    </users>\n+\n+    <quotas>\n+        <default>\n+        </default>\n+    </quotas>\n+</clickhouse>\ndiff --git a/tests/integration/test_endpoint_macro_substitution/test.py b/tests/integration/test_endpoint_macro_substitution/test.py\nnew file mode 100644\nindex 000000000000..42a8ddbda84a\n--- /dev/null\n+++ b/tests/integration/test_endpoint_macro_substitution/test.py\n@@ -0,0 +1,81 @@\n+import pytest\n+from helpers.cluster import ClickHouseCluster\n+from helpers.test_tools import TSV\n+from pyhdfs import HdfsClient\n+\n+disk_types = {\n+    \"default\": \"local\",\n+    \"disk_s3\": \"s3\",\n+    \"disk_hdfs\": \"hdfs\",\n+    \"disk_encrypted\": \"s3\",\n+}\n+\n+\n+@pytest.fixture(scope=\"module\")\n+def cluster():\n+    try:\n+        cluster = ClickHouseCluster(__file__)\n+        cluster.add_instance(\n+            \"node\",\n+            main_configs=[\"configs/storage.xml\", \"configs/macros.xml\"],\n+            with_minio=True,\n+            with_hdfs=True,\n+        )\n+        cluster.start()\n+\n+        fs = HdfsClient(hosts=cluster.hdfs_ip)\n+        fs.mkdirs(\"/clickhouse\")\n+\n+        yield cluster\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def test_different_types(cluster):\n+    node = cluster.instances[\"node\"]\n+    fs = HdfsClient(hosts=cluster.hdfs_ip)\n+\n+    response = TSV.toMat(node.query(\"SELECT * FROM system.disks FORMAT TSVWithNames\"))\n+\n+    assert len(response) > len(disk_types)  # at least one extra line for header\n+\n+    name_col_ix = response[0].index(\"name\")\n+    type_col_ix = response[0].index(\"type\")\n+    encrypted_col_ix = response[0].index(\"is_encrypted\")\n+\n+    for fields in response[1:]:  # skip header\n+        assert len(fields) >= 7\n+        assert (\n+            disk_types.get(fields[name_col_ix], \"UNKNOWN\") == fields[type_col_ix]\n+        ), f\"Wrong type ({fields[type_col_ix]}) for disk {fields[name_col_ix]}!\"\n+        if \"encrypted\" in fields[name_col_ix]:\n+            assert (\n+                fields[encrypted_col_ix] == \"1\"\n+            ), f\"{fields[name_col_ix]} expected to be encrypted!\"\n+        else:\n+            assert (\n+                fields[encrypted_col_ix] == \"0\"\n+            ), f\"{fields[name_col_ix]} expected to be non-encrypted!\"\n+\n+\n+def test_select_by_type(cluster):\n+    node = cluster.instances[\"node\"]\n+    fs = HdfsClient(hosts=cluster.hdfs_ip)\n+\n+    for name, disk_type in list(disk_types.items()):\n+        if disk_type != \"s3\":\n+            assert (\n+                node.query(\n+                    \"SELECT name FROM system.disks WHERE type='\" + disk_type + \"'\"\n+                )\n+                == name + \"\\n\"\n+            )\n+        else:\n+            assert (\n+                node.query(\n+                    \"SELECT name FROM system.disks WHERE type='\"\n+                    + disk_type\n+                    + \"' ORDER BY name\"\n+                )\n+                == \"disk_encrypted\\ndisk_s3\\n\"\n+            )\n",
  "problem_statement": "Allow macro substitution in endpoint config parameter in storage_configuration section\nIt is convenient for managing huge clusters to allow using macros in endpoint config parameter in storage_configuration section similar to zookeeper paths - https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/replication#creating-replicated-tables\r\n\r\nThis will allow to place files in S3 buckets on per shard basis for example.\n",
  "hints_text": "can you provide several examples what you exactly want (config, create query and so on)\nConfig fragment same for all hosts in cluster should look like this, contains secret credentials:\r\n```\r\n<yandex>\r\n     <macros incl=\"macros\" optional=\"true\" replace=\"true\" />\r\n    <storage_configuration>\r\n        <disks>\r\n            <s3_some_disk>\r\n                <type>s3</type>\r\n                <endpoint>https://s3-host.net/<bucket-name>/some-sub-dir/{shard}/</endpoint>\r\n                <access_key_id>xxxxxxxxx</access_key_id>\r\n                <secret_access_key>xxxxxxxxxxx</secret_access_key>\r\n            </s3_some_disk>\r\n        </disks>\r\n        <policies>\r\n ...\r\n        </policies>\r\n    </storage_configuration>\r\n</yandex>\r\n```\r\n\r\nIncluded file - autogenerated on each host in huge cluster with its own values in shard and replica tags:\r\n```\r\n<yandex>\r\n        <macros>\r\n                <shard>001</shard>\r\n                <replica>somehost001-1.somedomain.net</replica>\r\n        </macros>\r\n</yandex>\r\n```\r\n\r\nThis will allow us to place files for different shards in different folders in S3 or even in different buckets - one per shard.",
  "created_at": "2022-12-23T14:12:16Z"
}