{
  "repo": "ydb-platform/ydb",
  "pull_number": 15961,
  "instance_id": "ydb-platform__ydb-15961",
  "issue_numbers": [
    "15615"
  ],
  "base_commit": "8ab3977fbc41e6a9c5f6deafcf2a7bc1eba65712",
  "patch": "diff --git a/ydb/core/kqp/runtime/kqp_stream_lookup_actor.cpp b/ydb/core/kqp/runtime/kqp_stream_lookup_actor.cpp\nindex ade6644ab882..5f5a51d47622 100644\n--- a/ydb/core/kqp/runtime/kqp_stream_lookup_actor.cpp\n+++ b/ydb/core/kqp/runtime/kqp_stream_lookup_actor.cpp\n@@ -118,6 +118,7 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n     enum class EReadState {\n         Initial,\n         Running,\n+        Blocked, // Read can't accept new data, but not finished yet\n         Finished,\n     };\n \n@@ -125,6 +126,7 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n         switch (state) {\n             case EReadState::Initial: return \"Initial\"sv;\n             case EReadState::Running: return \"Running\"sv;\n+            case EReadState::Blocked: return \"Blocked\"sv;\n             case EReadState::Finished: return \"Finished\"sv;\n         }\n     }\n@@ -143,6 +145,10 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n             return (State == EReadState::Finished);\n         }\n \n+        void SetBlocked() {\n+            State = EReadState::Blocked;\n+        }\n+\n         const ui64 Id;\n         const ui64 ShardId;\n         EReadState State;\n@@ -277,6 +283,7 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n     }\n \n     void Handle(TEvTxProxySchemeCache::TEvResolveKeySetResult::TPtr& ev) {\n+        ResoleShardsInProgress = false;\n         CA_LOG_D(\"TEvResolveKeySetResult was received for table: \" << StreamLookupWorker->GetTablePath());\n         if (ev->Get()->Request->ErrorCount > 0) {\n             TString errorMsg = TStringBuilder() << \"Failed to get partitioning for table: \"\n@@ -301,7 +308,7 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n \n         auto readIt = Reads.find(record.GetReadId());\n         if (readIt == Reads.end() || readIt->second.State != EReadState::Running) {\n-            CA_LOG_D(\"Drop read with readId: \" << record.GetReadId() << \", because it's already completed\");\n+            CA_LOG_D(\"Drop read with readId: \" << record.GetReadId() << \", because it's already completed or blocked\");\n             return;\n         }\n \n@@ -309,7 +316,8 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n \n         CA_LOG_D(\"Recv TEvReadResult (stream lookup) from ShardID=\" << read.ShardId\n             << \", Table = \" << StreamLookupWorker->GetTablePath()\n-            << \", ReadId=\" << record.GetReadId()\n+            << \", ReadId=\" << record.GetReadId() << \" (current ReadId=\" << ReadId << \")\"\n+            << \", SeqNo=\" << record.GetSeqNo()\n             << \", Status=\" << Ydb::StatusIds::StatusCode_Name(record.GetStatus().GetCode())\n             << \", Finished=\" << record.GetFinished()\n             << \", RowCount=\" << record.GetRowCount()\n@@ -345,18 +353,25 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n             Counters->DataShardIteratorFails->Inc();\n         }\n \n-        auto replyError = [&](auto message, auto status) {\n+        auto getIssues = [&record]() {\n             NYql::TIssues issues;\n             NYql::IssuesFromMessage(record.GetStatus().GetIssues(), issues);\n-            return RuntimeError(message, status, issues);\n+            return issues;\n+        };\n+\n+        auto replyError = [&](auto message, auto status) {\n+            return RuntimeError(message, status, getIssues());\n         };\n \n         switch (record.GetStatus().GetCode()) {\n             case Ydb::StatusIds::SUCCESS:\n                 break;\n-            case Ydb::StatusIds::NOT_FOUND: {\n+            case Ydb::StatusIds::NOT_FOUND:\n+            {\n                 StreamLookupWorker->ResetRowsProcessing(read.Id, read.FirstUnprocessedQuery, read.LastProcessedKey);\n                 read.SetFinished();\n+                CA_LOG_D(\"NOT_FOUND was received from tablet: \" << read.ShardId << \". \"\n+                    << getIssues().ToOneLineString());\n                 return ResolveTableShards();\n             }\n             case Ydb::StatusIds::OVERLOADED: {\n@@ -365,6 +380,9 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n                         TStringBuilder() << \"Table '\" << StreamLookupWorker->GetTablePath() << \"' retry limit exceeded.\",\n                         NYql::NDqProto::StatusIds::OVERLOADED);\n                 }\n+                CA_LOG_D(\"OVERLOADED was received from tablet: \" << read.ShardId << \".\"\n+                    << getIssues().ToOneLineString());\n+                read.SetBlocked();\n                 return RetryTableRead(read, /*allowInstantRetry = */false);\n             }\n             case Ydb::StatusIds::INTERNAL_ERROR: {\n@@ -373,6 +391,9 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n                         TStringBuilder() << \"Table '\" << StreamLookupWorker->GetTablePath() << \"' retry limit exceeded.\",\n                         NYql::NDqProto::StatusIds::INTERNAL_ERROR);\n                 }\n+                CA_LOG_D(\"INTERNAL_ERROR was received from tablet: \" << read.ShardId << \".\"\n+                    << getIssues().ToOneLineString());\n+                read.SetBlocked();\n                 return RetryTableRead(read);\n             }\n             default: {\n@@ -380,6 +401,7 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n             }\n         }\n \n+        YQL_ENSURE(read.LastSeqNo < record.GetSeqNo());\n         read.LastSeqNo = record.GetSeqNo();\n \n         if (record.GetFinished()) {\n@@ -394,6 +416,8 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n             if (continuationToken.HasLastProcessedKey()) {\n                 TSerializedCellVec lastKey(continuationToken.GetLastProcessedKey());\n                 read.LastProcessedKey = TOwnedCellVec(lastKey.GetCells());\n+            } else {\n+                read.LastProcessedKey.Clear();\n             }\n \n             Counters->SentIteratorAcks->Inc();\n@@ -439,6 +463,7 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n             }\n         }\n         for (auto* read : toRetry) {\n+            read->SetBlocked();\n             RetryTableRead(*read);\n         }\n     }\n@@ -450,6 +475,7 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n         if (!Partitioning) {\n             LookupActorStateSpan.EndError(\"timeout exceeded\");\n             CA_LOG_D(\"Retry attempt to resolve shards for table: \" << StreamLookupWorker->GetTablePath());\n+            ResoleShardsInProgress = false;\n             ResolveTableShards();\n         }\n     }\n@@ -459,7 +485,9 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n         YQL_ENSURE(readIt != Reads.end(), \"Unexpected readId: \" << ev->Get()->ReadId);\n         auto& read = readIt->second;\n \n-        if (read.State == EReadState::Running && read.LastSeqNo <= ev->Get()->LastSeqNo) {\n+        YQL_ENSURE(read.State != EReadState::Blocked || read.LastSeqNo <= ev->Get()->LastSeqNo);\n+\n+        if ((read.State == EReadState::Running && read.LastSeqNo <= ev->Get()->LastSeqNo) || read.State == EReadState::Blocked) {\n             if (ev->Get()->InstantStart) {\n                 read.SetFinished();\n                 auto requests = StreamLookupWorker->RebuildRequest(read.Id, read.FirstUnprocessedQuery, read.LastProcessedKey, ReadId);\n@@ -596,12 +624,17 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n     }\n \n     void ResolveTableShards() {\n+        if (ResoleShardsInProgress) {\n+            return;\n+        }\n+\n         if (++TotalResolveShardsAttempts > MaxShardResolves()) {\n             return RuntimeError(TStringBuilder() << \"Table '\" << StreamLookupWorker->GetTablePath() << \"' resolve attempts limit exceeded\",\n                 NYql::NDqProto::StatusIds::UNAVAILABLE);\n         }\n \n         CA_LOG_D(\"Resolve shards for table: \" << StreamLookupWorker->GetTablePath());\n+        ResoleShardsInProgress = true;\n \n         Partitioning.reset();\n \n@@ -681,6 +714,7 @@ class TKqpStreamLookupActor : public NActors::TActorBootstrapped<TKqpStreamLooku\n     ui64 ReadId = 0;\n     size_t TotalRetryAttempts = 0;\n     size_t TotalResolveShardsAttempts = 0;\n+    bool ResoleShardsInProgress = false;\n \n     // stats\n     ui64 ReadRowsCount = 0;\n",
  "test_patch": "diff --git a/ydb/tests/functional/compatibility/ya.make b/ydb/tests/functional/compatibility/ya.make\nindex 41f809b3e175..637be3ea2e58 100644\n--- a/ydb/tests/functional/compatibility/ya.make\n+++ b/ydb/tests/functional/compatibility/ya.make\n@@ -10,6 +10,7 @@ TEST_SRCS(\n \n SIZE(LARGE)\n REQUIREMENTS(cpu:all)\n+REQUIREMENTS(ram:all)\n INCLUDE(${ARCADIA_ROOT}/ydb/tests/large.inc)\n \n DEPENDS(\n",
  "problem_statement": "Data duplication in TKqpStreamLookupActor in case of DS errors\nTPC-H (row) scale 1 with mixed cluster 24-4 + 25-1 \n\n\u0418\u0437 \u0442\u0435\u0441\u0442\u0430 https://github.com/ydb-platform/ydb/pull/15612/files \n`test_stress.py::TestStress::test_tpch1[mixed-row]`\n\n\u041f\u0440\u0438 \u044d\u0442\u043e\u043c \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e 24-4 \u0438 25-1 \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0442 \u0431\u0435\u0437 \u0434\u0438\u0444\u0444\u043e\u0432\n\n```\n\nQuery10:\n\n\u001b[K|Progress: 2.75M rows read, 80M B read.\n\u001b[K\titeration 0:\tok\t7.542340s seconds\nResult 0 has diff in results: \n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Line \u2502 c_custkey       \u2502 c_name                                      \u2502 revenue                         \u2502 c_acctbal               \u2502 n_name             \u2502 c_address                                     \u2502 c_phone                               \u2502 c_comment                                                                                                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 0    \u2502 [49696] (57040) \u2502 [\"Customer#000049696\"] (Customer#000057040) \u2502 [1023524.379] (734235.24+-0.01) \u2502 [-773.6] (632.87+-0.01) \u2502 [\"CANADA\"] (JAPAN) \u2502 [\"7i1F6lORR4ajtMx6Eg53oBjlqnr1\"] (Eioyzjf4pp) \u2502 [\"13-431-497-3286\"] (22-895-641-3466) \u2502 [\"equests. slyly regular sentiments are. carefully bol\"] (sits. slyly regular requests sleep alongside of the regular inst) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n```\n",
  "hints_text": "1. Only first iteration in the batch may produce invalid result (seems to be startup problem, only 1 of few runs fails)\n2. Incorrect results are produced in Precompute_1, Stage ( 1 ). Correct results is 114.70K Rows, buggy iteration produces more records, this affects upstream calcualtions. All invalid results are larger than correct ones.\n3. It's NOT problem of mixed cluster and may be reproduced in stable-25-1 or main (never observed in 24-4)\nCorrect iteration:\n\n![Image](https://github.com/user-attachments/assets/1e1b98cc-a624-48de-a1ff-d200f0e08f3c)\nIncorrect iteration:\n\n![Image](https://github.com/user-attachments/assets/fbc2f0ad-bdab-4360-a0cb-a8df505000e4)\nSide by side comparison of correct stage (left) anf incorrect one (right)\n\n<img width=\"939\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/164d6a7a-66c0-4e09-b20a-b866552f9e1b\" />\n\nInput from other precompute is the same. Problem is observed in MapJoin which is actually LookupJoin on lineitem table\nQ12 always fails error, if executed outside of the batch\n\n```\niteration 0:\n<main>: Warning: Execution, code: 1060\n    <main>:9:29: Warning: Cost Based Optimizer could not be applied to this query: couldn't load statistics, code: 8001\n<main>: Error: Table '/Root/tpch/s1/lineitem' retry limit exceeded.\n    <main>: Error: Shard splitted\n```\nSimple bash script for easy reproduce\n\n```\n#!/usr/bin/env bash\nfile=\"test-results/py3test/testing_out_stuff/test_stress.py.TestStress.test_tpch1.current-row/out.log\"\nwhile [ 1 ]\ndo\n~/ydb/ya make -r -tA -F test_stress.py::TestStress::test_tpch1[current-row] --keep-temps\nif grep \"diff in results\" $file; then\n    break\nfi\ndone\n```\n\nRecommended test run params:\n\n```\n        run_command = [\n            yatest.common.binary_path(os.getenv(\"YDB_CLI_BINARY\")),\n            \"--verbose\",\n            \"--endpoint\",\n            \"grpc://localhost:%d\" % self.cluster.nodes[1].grpc_port,\n            \"--database=/Root\",\n            \"workload\",\n            \"tpch\",\n            \"-p\",\n            \"tpch/s1\",\n            \"run\",\n            \"--scale=1\",\n            \"--include\",\n            \"10\",\n            \"--iterations\",\n            \"2\",\n            \"--plan\",\n            \"plan\",\n            \"--check-canonical\",\n            \"--output\",\n            self.results_out_path,\n        ]\n```\nQuick'n'dirty logs in TKqpStreamLookupActor produces following - retries and larger traffic in the very first (incorrect) iteration:\n\n```\nTKqpStreamLookupActor AllowInconsistentReads 0\nTKqpStreamLookupActor RetryRead\nTKqpStreamLookupActor RetryRead\nTKqpStreamLookupActor FillExtraStats 3387207 84680175B\nTKqpStreamLookupActor AllowInconsistentReads 0\nTKqpStreamLookupActor FillExtraStats 25 277B\n\nTKqpStreamLookupActor AllowInconsistentReads 0\nTKqpStreamLookupActor FillExtraStats 228772 5719300B\nTKqpStreamLookupActor AllowInconsistentReads 0\nTKqpStreamLookupActor FillExtraStats 25 277B\n\nTKqpStreamLookupActor AllowInconsistentReads 0\nTKqpStreamLookupActor FillExtraStats 228772 5719300B\nTKqpStreamLookupActor AllowInconsistentReads 0\nTKqpStreamLookupActor FillExtraStats 25 277B\n\nTKqpStreamLookupActor AllowInconsistentReads 0\nTKqpStreamLookupActor FillExtraStats 228772 5719300B\nTKqpStreamLookupActor AllowInconsistentReads 0\nTKqpStreamLookupActor FillExtraStats 25 277B\n```\n@gridnevvvit @nikvas0 pls take a look.\nwith feature flag EnableKqpDataQueryStreamIdxLookupJoin = true (default is false) following error occurs from time to time\n\n```\n10:\niteration 1\n<main>: Warning: Execution, code: 1060\n    <main>:56:15: Warning: Cost Based Optimizer could not be applied to this query: couldn't load statistics, code: 8001\n<main>: Error: ydb/core/kqp/runtime/kqp_stream_lookup_worker.cpp:616  BuildRequests(): requirement rowIt != PendingLeftRowsByKey.end() failed\n```\nwith feature flag EnableKqpDataQueryStreamLookup = false (default is true) following error occurs from time to time\n\n```\n10:\niteration 1\n<main>: Warning: Execution, code: 1060\n    <main>:56:15: Warning: Cost Based Optimizer could not be applied to this query: couldn't load statistics, code: 8001\n<main>: Error: Kikimr cluster or one of its subsystems was unavailable., code: 2005\n    <main>: Error: Tx state unknown for shard 72075186224037898, txid 281474976715670, code: 200506\n```",
  "created_at": "2025-03-19T13:24:03Z"
}