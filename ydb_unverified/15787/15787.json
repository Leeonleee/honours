{
  "repo": "ydb-platform/ydb",
  "pull_number": 15787,
  "instance_id": "ydb-platform__ydb-15787",
  "issue_numbers": [
    "2810"
  ],
  "base_commit": "42b62e5de4490e38a99bdb95850661901c5ad95d",
  "patch": "diff --git a/build/conf/compilers/gnu_compiler.conf b/build/conf/compilers/gnu_compiler.conf\nindex 045374757f2f..7ce38f66aed8 100644\n--- a/build/conf/compilers/gnu_compiler.conf\n+++ b/build/conf/compilers/gnu_compiler.conf\n@@ -74,8 +74,7 @@ when ($CLANG16 == \"yes\") {\n when ($CLANG18 == \"yes\") {\n     CFLAGS+=-Wno-array-parameter -Wno-deprecate-lax-vec-conv-all -Wno-unqualified-std-cast-call -Wno-unused-but-set-parameter -Wno-implicit-function-declaration -Wno-int-conversion -Wno-incompatible-function-pointer-types -Wno-address-of-packed-member\n     CFLAGS+=-Wno-deprecated-this-capture -Wno-c++11-narrowing-const-reference -Wno-missing-designated-field-initializers \\\n-            -Wno-packed-non-pod -Wno-format -Wno-vla-cxx-extension -Wno-invalid-offsetof \\\n-            -Wno-include-angled-in-module-purview\n+            -Wno-packed-non-pod -Wno-format -Wno-vla-cxx-extension -Wno-invalid-offsetof\n     when ($MAPSMOBI_BUILD_TARGET == \"yes\") {\n         CFLAGS+=-Wno-deprecated-declarations\n     }\ndiff --git a/build/export_generators/cmake/cmake/FindCython.cmake b/build/export_generators/cmake/cmake/FindCython.cmake\nnew file mode 100644\nindex 000000000000..ae72094934e6\n--- /dev/null\n+++ b/build/export_generators/cmake/cmake/FindCython.cmake\n@@ -0,0 +1,47 @@\n+# Copyright (c) Meta Platforms, Inc. and affiliates.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Find Cython\n+#\n+# This module sets the following variables:\n+# - Cython_FOUND\n+# - CYTHON_EXE\n+# - CYTHON_VERSION_STRING\n+#\n+find_program(CYTHON_EXE\n+             NAMES cython cython3)\n+if (CYTHON_EXE)\n+  execute_process(COMMAND ${CYTHON_EXE} --version\n+                  RESULT_VARIABLE _cython_retcode\n+                  OUTPUT_VARIABLE _cython_output\n+                  ERROR_VARIABLE _cython_output\n+                  OUTPUT_STRIP_TRAILING_WHITESPACE)\n+\n+  if (${_cython_retcode} EQUAL 0)\n+    separate_arguments(_cython_output)\n+    list(GET _cython_output -1 CYTHON_VERSION_STRING)\n+    message(STATUS \"Found Cython Version ${CYTHON_VERSION_STRING}\")\n+  else ()\n+    message(STATUS \"Failed to get Cython version\")\n+  endif ()\n+else ()\n+  message(STATUS \"Cython not found\")\n+endif ()\n+\n+include(FindPackageHandleStandardArgs)\n+find_package_handle_standard_args(\n+  Cython\n+  REQUIRED_VARS CYTHON_EXE CYTHON_VERSION_STRING\n+  VERSION_VAR CYTHON_VERSION_STRING\n+)\ndiff --git a/build/export_generators/cmake/cmake/cython.cmake b/build/export_generators/cmake/cmake/cython.cmake\nindex 055c742055cf..0b6f469048cc 100644\n--- a/build/export_generators/cmake/cmake/cython.cmake\n+++ b/build/export_generators/cmake/cmake/cython.cmake\n@@ -1,3 +1,8 @@\n+if (NOT USE_INTERNAL_CYTHON)\n+  include(FindCython)\n+endif()\n+\n+\n function(target_cython_include_directories Tgt)\n   set_property(TARGET ${Tgt} APPEND PROPERTY\n     CYTHON_INCLUDE_DIRS ${ARGN}\n@@ -25,12 +30,19 @@ macro(set_python_type_for_cython Tgt Type)\n endmacro()\n \n function(target_cython_sources Tgt Scope)\n+  if (USE_INTERNAL_CYTHON)\n+    set(CYTHON_CMD_PREFIX $<TARGET_GENEX_EVAL:${Tgt},$<TARGET_PROPERTY:${Tgt},CYTHON_PYTHON_INTERPRETER>> ${PROJECT_SOURCE_DIR}/contrib/tools/cython/cython.py)\n+  else()\n+    find_package(Cython REQUIRED)\n+    set(CYTHON_CMD_PREFIX ${CYTHON_EXE})\n+  endif()\n+\n   foreach(Input ${ARGN})\n     get_filename_component(OutputBase ${Input} NAME)\n     set(CppCythonOutput ${CMAKE_CURRENT_BINARY_DIR}/${OutputBase}.cpp)\n     add_custom_command(\n       OUTPUT ${CppCythonOutput}\n-      COMMAND $<TARGET_GENEX_EVAL:${Tgt},$<TARGET_PROPERTY:${Tgt},CYTHON_PYTHON_INTERPRETER>> ${PROJECT_SOURCE_DIR}/contrib/tools/cython/cython.py ${Input} -o ${CppCythonOutput}\n+      COMMAND ${CYTHON_CMD_PREFIX} ${Input} -o ${CppCythonOutput}\n         \"$<JOIN:$<TARGET_GENEX_EVAL:${Tgt},$<TARGET_PROPERTY:${Tgt},CYTHON_OPTIONS>>,$<SEMICOLON>>\"\n         \"-I$<JOIN:$<TARGET_GENEX_EVAL:${Tgt},$<TARGET_PROPERTY:${Tgt},CYTHON_INCLUDE_DIRS>>,$<SEMICOLON>-I>\"\n       COMMAND_EXPAND_LISTS\ndiff --git a/build/export_generators/cmake/generator.toml b/build/export_generators/cmake/generator.toml\nindex b25cf88c35fb..2f4c039b55aa 100644\n--- a/build/export_generators/cmake/generator.toml\n+++ b/build/export_generators/cmake/generator.toml\n@@ -329,7 +329,10 @@ attrs=[\n     \"target_macroses-macro=target_cython_include_directories\",\n     \"target_macroses-macro=set_python_type_for_cython\",\n ]\n-copy=[\"cmake/cython.cmake\"]\n+copy=[\n+    \"cmake/cython.cmake\",\n+    \"cmake/FindCython.cmake\"\n+]\n add_values=[{attr=\"includes\", values=[\"cmake/cython.cmake\"]}]\n \n [[rules]]\ndiff --git a/contrib/libs/croaring/.yandex_meta/override.nix b/contrib/libs/croaring/.yandex_meta/override.nix\nindex 60171a848a4e..616330eb5adc 100644\n--- a/contrib/libs/croaring/.yandex_meta/override.nix\n+++ b/contrib/libs/croaring/.yandex_meta/override.nix\n@@ -1,12 +1,12 @@\n pkgs: attrs: with pkgs; with attrs; rec {\n   pname = \"croaring\";\n-  version = \"4.2.3\";\n+  version = \"4.3.0\";\n \n   src = fetchFromGitHub {\n     owner = \"RoaringBitmap\";\n     repo = \"CRoaring\";\n     rev = \"v${version}\";\n-    hash = \"sha256-1yklwZj12yeGg8a/oss4EUHj8eezhKuo4PUltVdaXaM=\";\n+    hash = \"sha256-Se/m+qcYwZu1Bp5F2dcWacHYe4awX7EclB1iChTBkYE=\";\n   };\n \n   patches = [];\ndiff --git a/contrib/libs/croaring/include/roaring/art/art.h b/contrib/libs/croaring/include/roaring/art/art.h\nindex e191c1eedaa3..16b1e5516b0c 100644\n--- a/contrib/libs/croaring/include/roaring/art/art.h\n+++ b/contrib/libs/croaring/include/roaring/art/art.h\n@@ -19,8 +19,8 @@\n  *    chunks _differ_. This means that if there are two entries with different\n  *    high 48 bits, then there is only one inner node containing the common key\n  *    prefix, and two leaves.\n- *  * Intrusive leaves: the leaf struct is included in user values. This removes\n- *    a layer of indirection.\n+ *  * Mostly pointer-free: nodes are referred to by index rather than pointer,\n+ *    so that the structure can be deserialized with a backing buffer.\n  */\n \n // Fixed length of keys in the ART. All keys are assumed to be of this length.\n@@ -33,25 +33,33 @@ namespace internal {\n #endif\n \n typedef uint8_t art_key_chunk_t;\n-typedef struct art_node_s art_node_t;\n+\n+// Internal node reference type. Contains the node typecode in the low 8 bits,\n+// and the index in the relevant node array in the high 48 bits. Has a value of\n+// CROARING_ART_NULL_REF when pointing to a non-existent node.\n+typedef uint64_t art_ref_t;\n+\n+typedef void art_node_t;\n \n /**\n- * Wrapper to allow an empty tree.\n+ * The ART is empty when root is a null ref.\n+ *\n+ * Each node type has its own dynamic array of node structs, indexed by\n+ * art_ref_t. The arrays are expanded as needed, and shrink only when\n+ * `shrink_to_fit` is called.\n  */\n typedef struct art_s {\n-    art_node_t *root;\n+    art_ref_t root;\n+\n+    // Indexed by node typecode, thus 1 larger than they need to be for\n+    // convenience. `first_free` indicates the index where the first free node\n+    // lives, which may be equal to the capacity.\n+    uint64_t first_free[6];\n+    uint64_t capacities[6];\n+    art_node_t *nodes[6];\n } art_t;\n \n-/**\n- * Values inserted into the tree have to be cast-able to art_val_t. This\n- * improves performance by reducing indirection.\n- *\n- * NOTE: Value pointers must be unique! This is because each value struct\n- * contains the key corresponding to the value.\n- */\n-typedef struct art_val_s {\n-    art_key_chunk_t key[ART_KEY_BYTES];\n-} art_val_t;\n+typedef uint64_t art_val_t;\n \n /**\n  * Compares two keys, returns their relative order:\n@@ -63,14 +71,21 @@ int art_compare_keys(const art_key_chunk_t key1[],\n                      const art_key_chunk_t key2[]);\n \n /**\n- * Inserts the given key and value.\n+ * Initializes the ART.\n+ */\n+void art_init_cleared(art_t *art);\n+\n+/**\n+ * Inserts the given key and value. Returns a pointer to the value inserted,\n+ * valid as long as the ART is not modified.\n  */\n-void art_insert(art_t *art, const art_key_chunk_t *key, art_val_t *val);\n+art_val_t *art_insert(art_t *art, const art_key_chunk_t *key, art_val_t val);\n \n /**\n- * Returns the value erased, NULL if not found.\n+ * Returns true if a value was erased. Sets `*erased_val` to the value erased,\n+ * if any.\n  */\n-art_val_t *art_erase(art_t *art, const art_key_chunk_t *key);\n+bool art_erase(art_t *art, const art_key_chunk_t *key, art_val_t *erased_val);\n \n /**\n  * Returns the value associated with the given key, NULL if not found.\n@@ -83,42 +98,39 @@ art_val_t *art_find(const art_t *art, const art_key_chunk_t *key);\n bool art_is_empty(const art_t *art);\n \n /**\n- * Frees the nodes of the ART except the values, which the user is expected to\n- * free.\n+ * Frees the contents of the ART. Should not be called when using\n+ * `art_deserialize_frozen_safe`.\n  */\n void art_free(art_t *art);\n \n-/**\n- * Returns the size in bytes of the ART. Includes size of pointers to values,\n- * but not the values themselves.\n- */\n-size_t art_size_in_bytes(const art_t *art);\n-\n /**\n  * Prints the ART using printf, useful for debugging.\n  */\n void art_printf(const art_t *art);\n \n /**\n- * Callback for validating the value stored in a leaf.\n+ * Callback for validating the value stored in a leaf. `context` is a\n+ * user-provided value passed to the callback without modification.\n  *\n  * Should return true if the value is valid, false otherwise\n  * If false is returned, `*reason` should be set to a static string describing\n  * the reason for the failure.\n  */\n-typedef bool (*art_validate_cb_t)(const art_val_t *val, const char **reason);\n+typedef bool (*art_validate_cb_t)(const art_val_t val, const char **reason,\n+                                  void *context);\n \n /**\n- * Validate the ART tree, ensuring it is internally consistent.\n+ * Validate the ART tree, ensuring it is internally consistent. `context` is a\n+ * user-provided value passed to the callback without modification.\n  */\n bool art_internal_validate(const art_t *art, const char **reason,\n-                           art_validate_cb_t validate_cb);\n+                           art_validate_cb_t validate_cb, void *context);\n \n /**\n  * ART-internal iterator bookkeeping. Users should treat this as an opaque type.\n  */\n typedef struct art_iterator_frame_s {\n-    art_node_t *node;\n+    art_ref_t ref;\n     uint8_t index_in_node;\n } art_iterator_frame_t;\n \n@@ -130,6 +142,8 @@ typedef struct art_iterator_s {\n     art_key_chunk_t key[ART_KEY_BYTES];\n     art_val_t *value;\n \n+    art_t *art;\n+\n     uint8_t depth;  // Key depth\n     uint8_t frame;  // Node depth\n \n@@ -143,19 +157,19 @@ typedef struct art_iterator_s {\n  * depending on `first`. The iterator is not valid if there are no entries in\n  * the ART.\n  */\n-art_iterator_t art_init_iterator(const art_t *art, bool first);\n+art_iterator_t art_init_iterator(art_t *art, bool first);\n \n /**\n  * Returns an initialized iterator positioned at a key equal to or greater than\n  * the given key, if it exists.\n  */\n-art_iterator_t art_lower_bound(const art_t *art, const art_key_chunk_t *key);\n+art_iterator_t art_lower_bound(art_t *art, const art_key_chunk_t *key);\n \n /**\n  * Returns an initialized iterator positioned at a key greater than the given\n  * key, if it exists.\n  */\n-art_iterator_t art_upper_bound(const art_t *art, const art_key_chunk_t *key);\n+art_iterator_t art_upper_bound(art_t *art, const art_key_chunk_t *key);\n \n /**\n  * The following iterator movement functions return true if a new entry was\n@@ -174,14 +188,49 @@ bool art_iterator_lower_bound(art_iterator_t *iterator,\n /**\n  * Insert the value and positions the iterator at the key.\n  */\n-void art_iterator_insert(art_t *art, art_iterator_t *iterator,\n-                         const art_key_chunk_t *key, art_val_t *val);\n+void art_iterator_insert(art_iterator_t *iterator, const art_key_chunk_t *key,\n+                         art_val_t val);\n \n /**\n  * Erase the value pointed at by the iterator. Moves the iterator to the next\n- * leaf. Returns the value erased or NULL if nothing was erased.\n+ * leaf.\n+ * Returns true if a value was erased. Sets `*erased_val` to the value erased,\n+ * if any.\n+ */\n+bool art_iterator_erase(art_iterator_t *iterator, art_val_t *erased_val);\n+\n+/**\n+ * Shrinks the internal arrays in the ART to remove any unused elements. Returns\n+ * the number of bytes freed.\n+ */\n+size_t art_shrink_to_fit(art_t *art);\n+\n+/**\n+ * Returns true if the ART has no unused elements.\n+ */\n+bool art_is_shrunken(const art_t *art);\n+\n+/**\n+ * Returns the serialized size in bytes.\n+ * Requires `art_shrink_to_fit` to be called first.\n+ */\n+size_t art_size_in_bytes(const art_t *art);\n+\n+/**\n+ * Serializes the ART and returns the number of bytes written. Returns 0 on\n+ * error. Requires `art_shrink_to_fit` to be called first.\n+ */\n+size_t art_serialize(const art_t *art, char *buf);\n+\n+/**\n+ * Deserializes the ART from a serialized buffer, reading up to `maxbytes`\n+ * bytes. Returns 0 on error. Requires `buf` to be 8 byte aligned.\n+ *\n+ * An ART deserialized in this way should only be used in a readonly context.The\n+ * underlying buffer must not be freed before the ART. `art_free` should not be\n+ * called on the ART deserialized in this way.\n  */\n-art_val_t *art_iterator_erase(art_t *art, art_iterator_t *iterator);\n+size_t art_frozen_view(const char *buf, size_t maxbytes, art_t *art);\n \n #ifdef __cplusplus\n }  // extern \"C\"\ndiff --git a/contrib/libs/croaring/include/roaring/portability.h b/contrib/libs/croaring/include/roaring/portability.h\nindex 8c6d3c2bac72..8e326bc9cb07 100644\n--- a/contrib/libs/croaring/include/roaring/portability.h\n+++ b/contrib/libs/croaring/include/roaring/portability.h\n@@ -49,20 +49,6 @@\n #define CROARING_REGULAR_VISUAL_STUDIO 0\n #endif\n \n-#if defined(_POSIX_C_SOURCE) && (_POSIX_C_SOURCE < 200809L)\n-#undef _POSIX_C_SOURCE\n-#endif\n-\n-#ifndef _POSIX_C_SOURCE\n-#define _POSIX_C_SOURCE 200809L\n-#endif  // !(defined(_POSIX_C_SOURCE)) || (_POSIX_C_SOURCE < 200809L)\n-\n-#ifdef __illumos__\n-#ifndef __EXTENSIONS__\n-#define __EXTENSIONS__\n-#endif  // __EXTENSIONS__\n-#endif\n-\n #include <stdbool.h>\n #include <stdint.h>\n #include <stdlib.h>  // will provide posix_memalign with _POSIX_C_SOURCE as defined above\ndiff --git a/contrib/libs/croaring/include/roaring/roaring64.h b/contrib/libs/croaring/include/roaring/roaring64.h\nindex 8022f160dd44..e185b48aaea4 100644\n--- a/contrib/libs/croaring/include/roaring/roaring64.h\n+++ b/contrib/libs/croaring/include/roaring/roaring64.h\n@@ -17,7 +17,7 @@ namespace api {\n #endif\n \n typedef struct roaring64_bitmap_s roaring64_bitmap_t;\n-typedef struct roaring64_leaf_s roaring64_leaf_t;\n+typedef uint64_t roaring64_leaf_t;\n typedef struct roaring64_iterator_s roaring64_iterator_t;\n \n /**\n@@ -312,6 +312,12 @@ uint64_t roaring64_bitmap_maximum(const roaring64_bitmap_t *r);\n  */\n bool roaring64_bitmap_run_optimize(roaring64_bitmap_t *r);\n \n+/**\n+ * Shrinks internal arrays to eliminate any unused capacity. Returns the number\n+ * of bytes freed.\n+ */\n+size_t roaring64_bitmap_shrink_to_fit(roaring64_bitmap_t *r);\n+\n /**\n  *  (For advanced users.)\n  * Collect statistics about the bitmap\n@@ -564,6 +570,53 @@ size_t roaring64_bitmap_portable_deserialize_size(const char *buf,\n roaring64_bitmap_t *roaring64_bitmap_portable_deserialize_safe(const char *buf,\n                                                                size_t maxbytes);\n \n+/**\n+ * Returns the number of bytes required to serialize this bitmap in a \"frozen\"\n+ * format. This is not compatible with any other serialization formats.\n+ *\n+ * `roaring64_bitmap_shrink_to_fit()` must be called before this method.\n+ */\n+size_t roaring64_bitmap_frozen_size_in_bytes(const roaring64_bitmap_t *r);\n+\n+/**\n+ * Serializes the bitmap in a \"frozen\" format. The given buffer must be at least\n+ * `roaring64_bitmap_frozen_size_in_bytes()` in size. Returns the number of\n+ * bytes used for serialization.\n+ *\n+ * `roaring64_bitmap_shrink_to_fit()` must be called before this method.\n+ *\n+ * The frozen format is optimized for speed of (de)serialization, as well as\n+ * allowing the user to create a bitmap based on a memory mapped file, which is\n+ * possible because the format mimics the memory layout of the bitmap.\n+ *\n+ * Because the format mimics the memory layout of the bitmap, the format is not\n+ * fixed across releases of Roaring Bitmaps, and may change in future releases.\n+ *\n+ * This function is endian-sensitive. If you have a big-endian system (e.g., a\n+ * mainframe IBM s390x), the data format is going to be big-endian and not\n+ * compatible with little-endian systems.\n+ */\n+size_t roaring64_bitmap_frozen_serialize(const roaring64_bitmap_t *r,\n+                                         char *buf);\n+\n+/**\n+ * Creates a readonly bitmap that is a view of the given buffer. The buffer\n+ * must be created with `roaring64_bitmap_frozen_serialize()`, and must be\n+ * aligned by 64 bytes.\n+ *\n+ * Returns NULL if deserialization fails.\n+ *\n+ * The returned bitmap must only be used in a readonly manner. The bitmap must\n+ * be freed using `roaring64_bitmap_free()` as normal. The backing buffer must\n+ * only be freed after the bitmap.\n+ *\n+ * This function is endian-sensitive. If you have a big-endian system (e.g., a\n+ * mainframe IBM s390x), the data format is going to be big-endian and not\n+ * compatible with little-endian systems.\n+ */\n+roaring64_bitmap_t *roaring64_bitmap_frozen_view(const char *buf,\n+                                                 size_t maxbytes);\n+\n /**\n  * Iterate over the bitmap elements. The function `iterator` is called once for\n  * all the values with `ptr` (can be NULL) as the second parameter of each call.\ndiff --git a/contrib/libs/croaring/include/roaring/roaring_version.h b/contrib/libs/croaring/include/roaring/roaring_version.h\nindex 98819566a8dd..a6c5b01b4169 100644\n--- a/contrib/libs/croaring/include/roaring/roaring_version.h\n+++ b/contrib/libs/croaring/include/roaring/roaring_version.h\n@@ -2,11 +2,11 @@\n // /include/roaring/roaring_version.h automatically generated by release.py, do not change by hand\n #ifndef ROARING_INCLUDE_ROARING_VERSION\n #define ROARING_INCLUDE_ROARING_VERSION\n-#define ROARING_VERSION \"4.2.3\"\n+#define ROARING_VERSION \"4.3.0\"\n enum {\n     ROARING_VERSION_MAJOR = 4,\n-    ROARING_VERSION_MINOR = 2,\n-    ROARING_VERSION_REVISION = 3\n+    ROARING_VERSION_MINOR = 3,\n+    ROARING_VERSION_REVISION = 0\n };\n #endif // ROARING_INCLUDE_ROARING_VERSION\n // clang-format on\n\\ No newline at end of file\ndiff --git a/contrib/libs/croaring/src/art/art.c b/contrib/libs/croaring/src/art/art.c\nindex 7bca7eb2c981..8e54d4353e2f 100644\n--- a/contrib/libs/croaring/src/art/art.c\n+++ b/contrib/libs/croaring/src/art/art.c\n@@ -1,4 +1,5 @@\n #include <assert.h>\n+#include <stdalign.h>\n #include <stdio.h>\n #include <string.h>\n \n@@ -6,33 +7,31 @@\n #include <roaring/memory.h>\n #include <roaring/portability.h>\n \n-#define CROARING_ART_NODE4_TYPE 0\n-#define CROARING_ART_NODE16_TYPE 1\n-#define CROARING_ART_NODE48_TYPE 2\n-#define CROARING_ART_NODE256_TYPE 3\n-#define CROARING_ART_NUM_TYPES 4\n+#define CROARING_ART_NULL_REF 0\n+\n+#define CROARING_ART_LEAF_TYPE 1\n+#define CROARING_ART_NODE4_TYPE 2\n+#define CROARING_ART_NODE16_TYPE 3\n+#define CROARING_ART_NODE48_TYPE 4\n+#define CROARING_ART_NODE256_TYPE 5\n+\n+#define CROARING_ART_MIN_TYPE CROARING_ART_LEAF_TYPE\n+#define CROARING_ART_MAX_TYPE CROARING_ART_NODE256_TYPE\n \n // Node48 placeholder value to indicate no child is present at this key index.\n #define CROARING_ART_NODE48_EMPTY_VAL 48\n+#define CROARING_NODE48_AVAILABLE_CHILDREN_MASK ((UINT64_C(1) << 48) - 1)\n \n-// We use the least significant bit of node pointers to indicate whether a node\n-// is a leaf or an inner node. This is never surfaced to the user.\n-//\n-// Using pointer tagging to indicate leaves not only saves a bit of memory by\n-// sparing the typecode, but also allows us to use an intrusive leaf struct.\n-// Using an intrusive leaf struct leaves leaf allocation up to the user. Upon\n-// deallocation of the ART, we know not to free the leaves without having to\n-// dereference the leaf pointers.\n-//\n-// All internal operations on leaves should use CROARING_CAST_LEAF before using\n-// the leaf. The only places that use CROARING_SET_LEAF are locations where a\n-// field is directly assigned to a leaf pointer. After using CROARING_SET_LEAF,\n-// the leaf should be treated as a node of unknown type.\n-#define CROARING_IS_LEAF(p) (((uintptr_t)(p) & 1))\n-#define CROARING_SET_LEAF(p) ((art_node_t *)((uintptr_t)(p) | 1))\n-#define CROARING_CAST_LEAF(p) ((art_leaf_t *)((void *)((uintptr_t)(p) & ~1)))\n+#define CROARING_ART_ALIGN_BUF(buf, alignment)      \\\n+    (char *)(((uintptr_t)(buf) + ((alignment)-1)) & \\\n+             (ptrdiff_t)(~((alignment)-1)))\n \n-#define CROARING_NODE48_AVAILABLE_CHILDREN_MASK ((UINT64_C(1) << 48) - 1)\n+// Gives the byte difference needed to align the current buffer to the\n+// alignment, relative to the start of the buffer.\n+#define CROARING_ART_ALIGN_SIZE_RELATIVE(buf_cur, buf_start, alignment) \\\n+    ((((ptrdiff_t)((buf_cur) - (buf_start)) + ((alignment)-1)) &        \\\n+      (ptrdiff_t)(~((alignment)-1))) -                                  \\\n+     (ptrdiff_t)((buf_cur) - (buf_start)))\n \n #ifdef __cplusplus\n extern \"C\" {\n@@ -42,30 +41,20 @@ namespace internal {\n \n typedef uint8_t art_typecode_t;\n \n-// Aliasing with a \"leaf\" naming so that its purpose is clearer in the context\n-// of the trie internals.\n-typedef art_val_t art_leaf_t;\n-\n-typedef struct art_internal_validate_s {\n-    const char **reason;\n-    art_validate_cb_t validate_cb;\n-\n-    int depth;\n-    art_key_chunk_t current_key[ART_KEY_BYTES];\n-} art_internal_validate_t;\n-\n-// Set the reason message, and return false for convenience.\n-static inline bool art_validate_fail(const art_internal_validate_t *validate,\n-                                     const char *msg) {\n-    *validate->reason = msg;\n-    return false;\n-}\n+typedef struct art_leaf_s {\n+    union {\n+        struct {\n+            art_key_chunk_t key[ART_KEY_BYTES];\n+            art_val_t val;\n+        };\n+        uint64_t next_free;\n+    };\n+} art_leaf_t;\n \n // Inner node, with prefix.\n //\n // We use a fixed-length array as a pointer would be larger than the array.\n typedef struct art_inner_node_s {\n-    art_typecode_t typecode;\n     uint8_t prefix_size;\n     uint8_t prefix[ART_KEY_BYTES - 1];\n } art_inner_node_t;\n@@ -74,119 +63,232 @@ typedef struct art_inner_node_s {\n \n // Node4: key[i] corresponds with children[i]. Keys are sorted.\n typedef struct art_node4_s {\n-    art_inner_node_t base;\n-    uint8_t count;\n-    uint8_t keys[4];\n-    art_node_t *children[4];\n+    union {\n+        struct {\n+            art_inner_node_t base;\n+            uint8_t count;\n+            uint8_t keys[4];\n+            art_ref_t children[4];\n+        };\n+        uint64_t next_free;\n+    };\n } art_node4_t;\n \n // Node16: key[i] corresponds with children[i]. Keys are sorted.\n typedef struct art_node16_s {\n-    art_inner_node_t base;\n-    uint8_t count;\n-    uint8_t keys[16];\n-    art_node_t *children[16];\n+    union {\n+        struct {\n+            art_inner_node_t base;\n+            uint8_t count;\n+            uint8_t keys[16];\n+            art_ref_t children[16];\n+        };\n+        uint64_t next_free;\n+    };\n } art_node16_t;\n \n // Node48: key[i] corresponds with children[key[i]] if key[i] !=\n // CROARING_ART_NODE48_EMPTY_VAL. Keys are naturally sorted due to direct\n // indexing.\n typedef struct art_node48_s {\n-    art_inner_node_t base;\n-    uint8_t count;\n-    // Bitset where the ith bit is set if children[i] is available\n-    // Because there are at most 48 children, only the bottom 48 bits are used.\n-    uint64_t available_children;\n-    uint8_t keys[256];\n-    art_node_t *children[48];\n+    union {\n+        struct {\n+            art_inner_node_t base;\n+            uint8_t count;\n+            // Bitset where the ith bit is set if children[i] is available\n+            // Because there are at most 48 children, only the bottom 48 bits\n+            // are used.\n+            uint64_t available_children;\n+            uint8_t keys[256];\n+            art_ref_t children[48];\n+        };\n+        uint64_t next_free;\n+    };\n } art_node48_t;\n \n // Node256: children[i] is directly indexed by key chunk. A child is present if\n // children[i] != NULL.\n typedef struct art_node256_s {\n-    art_inner_node_t base;\n-    uint16_t count;\n-    art_node_t *children[256];\n+    union {\n+        struct {\n+            art_inner_node_t base;\n+            uint16_t count;\n+            art_ref_t children[256];\n+        };\n+        uint64_t next_free;\n+    };\n } art_node256_t;\n \n+// Size of each node type, indexed by typecode for convenience.\n+static const size_t ART_NODE_SIZES[] = {\n+    0,\n+    sizeof(art_leaf_t),\n+    sizeof(art_node4_t),\n+    sizeof(art_node16_t),\n+    sizeof(art_node48_t),\n+    sizeof(art_node256_t),\n+};\n+\n // Helper struct to refer to a child within a node at a specific index.\n typedef struct art_indexed_child_s {\n-    art_node_t *child;\n+    art_ref_t child;\n     uint8_t index;\n     art_key_chunk_t key_chunk;\n } art_indexed_child_t;\n \n-static inline bool art_is_leaf(const art_node_t *node) {\n-    return CROARING_IS_LEAF(node);\n+typedef struct art_internal_validate_s {\n+    const char **reason;\n+    art_validate_cb_t validate_cb;\n+    void *context;\n+\n+    int depth;\n+    art_key_chunk_t current_key[ART_KEY_BYTES];\n+} art_internal_validate_t;\n+\n+// Set the reason message, and return false for convenience.\n+static inline bool art_validate_fail(const art_internal_validate_t *validate,\n+                                     const char *msg) {\n+    *validate->reason = msg;\n+    return false;\n }\n \n-static void art_leaf_populate(art_leaf_t *leaf, const art_key_chunk_t key[]) {\n-    memcpy(leaf->key, key, ART_KEY_BYTES);\n+static inline art_ref_t art_to_ref(uint64_t index, art_typecode_t typecode) {\n+    return ((art_ref_t)index) << 16 | typecode;\n+}\n+\n+static inline uint64_t art_ref_index(art_ref_t ref) {\n+    return ((uint64_t)ref) >> 16;\n+}\n+\n+static inline art_typecode_t art_ref_typecode(art_ref_t ref) {\n+    return (art_typecode_t)ref;\n+}\n+\n+/**\n+ * Gets a pointer to a node from its reference. The pointer only remains valid\n+ * under non-mutating operations. If any mutating operations occur, this\n+ * function should be called again to get a valid pointer to the node.\n+ */\n+static art_node_t *art_deref(const art_t *art, art_ref_t ref) {\n+    assert(ref != CROARING_ART_NULL_REF);\n+    art_typecode_t typecode = art_ref_typecode(ref);\n+    return (art_node_t *)((char *)art->nodes[typecode] +\n+                          art_ref_index(ref) * ART_NODE_SIZES[typecode]);\n+}\n+\n+static inline art_node_t *art_get_node(const art_t *art, uint64_t index,\n+                                       art_typecode_t typecode) {\n+    return art_deref(art, art_to_ref(index, typecode));\n }\n \n-static inline uint8_t art_get_type(const art_inner_node_t *node) {\n-    return node->typecode;\n+static inline uint64_t art_get_index(const art_t *art, const art_node_t *node,\n+                                     art_typecode_t typecode) {\n+    art_node_t *nodes = art->nodes[typecode];\n+    switch (typecode) {\n+        case CROARING_ART_LEAF_TYPE:\n+            return (art_leaf_t *)node - (art_leaf_t *)nodes;\n+        case CROARING_ART_NODE4_TYPE:\n+            return (art_node4_t *)node - (art_node4_t *)nodes;\n+        case CROARING_ART_NODE16_TYPE:\n+            return (art_node16_t *)node - (art_node16_t *)nodes;\n+        case CROARING_ART_NODE48_TYPE:\n+            return (art_node48_t *)node - (art_node48_t *)nodes;\n+        case CROARING_ART_NODE256_TYPE:\n+            return (art_node256_t *)node - (art_node256_t *)nodes;\n+        default:\n+            assert(false);\n+            return 0;\n+    }\n+}\n+\n+/**\n+ * Creates a reference from a pointer.\n+ */\n+static inline art_ref_t art_get_ref(const art_t *art, const art_node_t *node,\n+                                    art_typecode_t typecode) {\n+    return art_to_ref(art_get_index(art, node, typecode), typecode);\n+}\n+\n+static inline bool art_is_leaf(art_ref_t ref) {\n+    return art_ref_typecode(ref) == CROARING_ART_LEAF_TYPE;\n }\n \n static inline void art_init_inner_node(art_inner_node_t *node,\n-                                       art_typecode_t typecode,\n                                        const art_key_chunk_t prefix[],\n                                        uint8_t prefix_size) {\n-    node->typecode = typecode;\n     node->prefix_size = prefix_size;\n     memcpy(node->prefix, prefix, prefix_size * sizeof(art_key_chunk_t));\n }\n \n-static void art_free_node(art_node_t *node);\n+static void art_node_free(art_t *art, art_node_t *node,\n+                          art_typecode_t typecode);\n+\n+static uint64_t art_allocate_index(art_t *art, art_typecode_t typecode);\n \n // ===================== Start of node-specific functions ======================\n \n-static art_node4_t *art_node4_create(const art_key_chunk_t prefix[],\n+static art_ref_t art_leaf_create(art_t *art, const art_key_chunk_t key[],\n+                                 art_val_t val) {\n+    uint64_t index = art_allocate_index(art, CROARING_ART_LEAF_TYPE);\n+    art_leaf_t *leaf =\n+        ((art_leaf_t *)art->nodes[CROARING_ART_LEAF_TYPE]) + index;\n+    memcpy(leaf->key, key, ART_KEY_BYTES);\n+    leaf->val = val;\n+    return art_to_ref(index, CROARING_ART_LEAF_TYPE);\n+}\n+\n+static inline void art_leaf_clear(art_leaf_t *leaf, art_ref_t next_free) {\n+    leaf->next_free = next_free;\n+}\n+\n+static art_node4_t *art_node4_create(art_t *art, const art_key_chunk_t prefix[],\n                                      uint8_t prefix_size);\n-static art_node16_t *art_node16_create(const art_key_chunk_t prefix[],\n+static art_node16_t *art_node16_create(art_t *art,\n+                                       const art_key_chunk_t prefix[],\n                                        uint8_t prefix_size);\n-static art_node48_t *art_node48_create(const art_key_chunk_t prefix[],\n+static art_node48_t *art_node48_create(art_t *art,\n+                                       const art_key_chunk_t prefix[],\n                                        uint8_t prefix_size);\n-static art_node256_t *art_node256_create(const art_key_chunk_t prefix[],\n+static art_node256_t *art_node256_create(art_t *art,\n+                                         const art_key_chunk_t prefix[],\n                                          uint8_t prefix_size);\n \n-static art_node_t *art_node4_insert(art_node4_t *node, art_node_t *child,\n-                                    uint8_t key);\n-static art_node_t *art_node16_insert(art_node16_t *node, art_node_t *child,\n-                                     uint8_t key);\n-static art_node_t *art_node48_insert(art_node48_t *node, art_node_t *child,\n-                                     uint8_t key);\n-static art_node_t *art_node256_insert(art_node256_t *node, art_node_t *child,\n-                                      uint8_t key);\n+static art_ref_t art_node4_insert(art_t *art, art_node4_t *node,\n+                                  art_ref_t child, uint8_t key);\n+static art_ref_t art_node16_insert(art_t *art, art_node16_t *node,\n+                                   art_ref_t child, uint8_t key);\n+static art_ref_t art_node48_insert(art_t *art, art_node48_t *node,\n+                                   art_ref_t child, uint8_t key);\n+static art_ref_t art_node256_insert(art_t *art, art_node256_t *node,\n+                                    art_ref_t child, uint8_t key);\n \n-static art_node4_t *art_node4_create(const art_key_chunk_t prefix[],\n+static art_node4_t *art_node4_create(art_t *art, const art_key_chunk_t prefix[],\n                                      uint8_t prefix_size) {\n-    art_node4_t *node = (art_node4_t *)roaring_malloc(sizeof(art_node4_t));\n-    art_init_inner_node(&node->base, CROARING_ART_NODE4_TYPE, prefix,\n-                        prefix_size);\n+    uint64_t index = art_allocate_index(art, CROARING_ART_NODE4_TYPE);\n+    art_node4_t *node =\n+        ((art_node4_t *)art->nodes[CROARING_ART_NODE4_TYPE]) + index;\n+    art_init_inner_node(&node->base, prefix, prefix_size);\n     node->count = 0;\n     return node;\n }\n \n-static void art_free_node4(art_node4_t *node) {\n-    for (size_t i = 0; i < node->count; ++i) {\n-        art_free_node(node->children[i]);\n-    }\n-    roaring_free(node);\n+static inline void art_node4_clear(art_node4_t *node, art_ref_t next_free) {\n+    node->count = 0;\n+    node->next_free = next_free;\n }\n \n-static inline art_node_t *art_node4_find_child(const art_node4_t *node,\n-                                               art_key_chunk_t key) {\n+static inline art_ref_t art_node4_find_child(const art_node4_t *node,\n+                                             art_key_chunk_t key) {\n     for (size_t i = 0; i < node->count; ++i) {\n         if (node->keys[i] == key) {\n             return node->children[i];\n         }\n     }\n-    return NULL;\n+    return CROARING_ART_NULL_REF;\n }\n \n-static art_node_t *art_node4_insert(art_node4_t *node, art_node_t *child,\n-                                    uint8_t key) {\n+static art_ref_t art_node4_insert(art_t *art, art_node4_t *node,\n+                                  art_ref_t child, uint8_t key) {\n     if (node->count < 4) {\n         size_t idx = 0;\n         for (; idx < node->count; ++idx) {\n@@ -199,26 +301,26 @@ static art_node_t *art_node4_insert(art_node4_t *node, art_node_t *child,\n         memmove(node->keys + idx + 1, node->keys + idx,\n                 after * sizeof(art_key_chunk_t));\n         memmove(node->children + idx + 1, node->children + idx,\n-                after * sizeof(art_node_t *));\n+                after * sizeof(art_ref_t));\n \n         node->children[idx] = child;\n         node->keys[idx] = key;\n         node->count++;\n-        return (art_node_t *)node;\n+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE4_TYPE);\n     }\n     art_node16_t *new_node =\n-        art_node16_create(node->base.prefix, node->base.prefix_size);\n+        art_node16_create(art, node->base.prefix, node->base.prefix_size);\n     // Instead of calling insert, this could be specialized to 2x memcpy and\n     // setting the count.\n     for (size_t i = 0; i < 4; ++i) {\n-        art_node16_insert(new_node, node->children[i], node->keys[i]);\n+        art_node16_insert(art, new_node, node->children[i], node->keys[i]);\n     }\n-    roaring_free(node);\n-    return art_node16_insert(new_node, child, key);\n+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE4_TYPE);\n+    return art_node16_insert(art, new_node, child, key);\n }\n \n-static inline art_node_t *art_node4_erase(art_node4_t *node,\n-                                          art_key_chunk_t key_chunk) {\n+static inline art_ref_t art_node4_erase(art_t *art, art_node4_t *node,\n+                                        art_key_chunk_t key_chunk) {\n     int idx = -1;\n     for (size_t i = 0; i < node->count; ++i) {\n         if (node->keys[i] == key_chunk) {\n@@ -226,17 +328,18 @@ static inline art_node_t *art_node4_erase(art_node4_t *node,\n         }\n     }\n     if (idx == -1) {\n-        return (art_node_t *)node;\n+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE4_TYPE);\n     }\n     if (node->count == 2) {\n         // Only one child remains after erasing, so compress the path by\n         // removing this node.\n         uint8_t other_idx = idx ^ 1;\n-        art_node_t *remaining_child = node->children[other_idx];\n+        art_ref_t remaining_child = node->children[other_idx];\n         art_key_chunk_t remaining_child_key = node->keys[other_idx];\n         if (!art_is_leaf(remaining_child)) {\n             // Correct the prefix of the child node.\n-            art_inner_node_t *inner_node = (art_inner_node_t *)remaining_child;\n+            art_inner_node_t *inner_node =\n+                (art_inner_node_t *)art_deref(art, remaining_child);\n             memmove(inner_node->prefix + node->base.prefix_size + 1,\n                     inner_node->prefix, inner_node->prefix_size);\n             memcpy(inner_node->prefix, node->base.prefix,\n@@ -244,7 +347,7 @@ static inline art_node_t *art_node4_erase(art_node4_t *node,\n             inner_node->prefix[node->base.prefix_size] = remaining_child_key;\n             inner_node->prefix_size += node->base.prefix_size + 1;\n         }\n-        roaring_free(node);\n+        art_node_free(art, (art_node_t *)node, CROARING_ART_NODE4_TYPE);\n         return remaining_child;\n     }\n     // Shift other keys to maintain sorted order.\n@@ -252,14 +355,14 @@ static inline art_node_t *art_node4_erase(art_node4_t *node,\n     memmove(node->keys + idx, node->keys + idx + 1,\n             after_next * sizeof(art_key_chunk_t));\n     memmove(node->children + idx, node->children + idx + 1,\n-            after_next * sizeof(art_node_t *));\n+            after_next * sizeof(art_ref_t));\n     node->count--;\n-    return (art_node_t *)node;\n+    return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE4_TYPE);\n }\n \n static inline void art_node4_replace(art_node4_t *node,\n                                      art_key_chunk_t key_chunk,\n-                                     art_node_t *new_child) {\n+                                     art_ref_t new_child) {\n     for (size_t i = 0; i < node->count; ++i) {\n         if (node->keys[i] == key_chunk) {\n             node->children[i] = new_child;\n@@ -273,7 +376,7 @@ static inline art_indexed_child_t art_node4_next_child(const art_node4_t *node,\n     art_indexed_child_t indexed_child;\n     index++;\n     if (index >= node->count) {\n-        indexed_child.child = NULL;\n+        indexed_child.child = CROARING_ART_NULL_REF;\n         return indexed_child;\n     }\n     indexed_child.index = index;\n@@ -290,7 +393,7 @@ static inline art_indexed_child_t art_node4_prev_child(const art_node4_t *node,\n     index--;\n     art_indexed_child_t indexed_child;\n     if (index < 0) {\n-        indexed_child.child = NULL;\n+        indexed_child.child = CROARING_ART_NULL_REF;\n         return indexed_child;\n     }\n     indexed_child.index = index;\n@@ -303,7 +406,7 @@ static inline art_indexed_child_t art_node4_child_at(const art_node4_t *node,\n                                                      int index) {\n     art_indexed_child_t indexed_child;\n     if (index < 0 || index >= node->count) {\n-        indexed_child.child = NULL;\n+        indexed_child.child = CROARING_ART_NULL_REF;\n         return indexed_child;\n     }\n     indexed_child.index = index;\n@@ -323,14 +426,15 @@ static inline art_indexed_child_t art_node4_lower_bound(\n             return indexed_child;\n         }\n     }\n-    indexed_child.child = NULL;\n+    indexed_child.child = CROARING_ART_NULL_REF;\n     return indexed_child;\n }\n \n-static bool art_internal_validate_at(const art_node_t *node,\n+static bool art_internal_validate_at(const art_t *art, art_ref_t ref,\n                                      art_internal_validate_t validator);\n \n-static bool art_node4_internal_validate(const art_node4_t *node,\n+static bool art_node4_internal_validate(const art_t *art,\n+                                        const art_node4_t *node,\n                                         art_internal_validate_t validator) {\n     if (node->count == 0) {\n         return art_validate_fail(&validator, \"Node4 has no children\");\n@@ -357,41 +461,41 @@ static bool art_node4_internal_validate(const art_node4_t *node,\n             }\n         }\n         validator.current_key[validator.depth - 1] = node->keys[i];\n-        if (!art_internal_validate_at(node->children[i], validator)) {\n+        if (!art_internal_validate_at(art, node->children[i], validator)) {\n             return false;\n         }\n     }\n     return true;\n }\n \n-static art_node16_t *art_node16_create(const art_key_chunk_t prefix[],\n+static art_node16_t *art_node16_create(art_t *art,\n+                                       const art_key_chunk_t prefix[],\n                                        uint8_t prefix_size) {\n-    art_node16_t *node = (art_node16_t *)roaring_malloc(sizeof(art_node16_t));\n-    art_init_inner_node(&node->base, CROARING_ART_NODE16_TYPE, prefix,\n-                        prefix_size);\n+    uint64_t index = art_allocate_index(art, CROARING_ART_NODE16_TYPE);\n+    art_node16_t *node =\n+        ((art_node16_t *)art->nodes[CROARING_ART_NODE16_TYPE]) + index;\n+    art_init_inner_node(&node->base, prefix, prefix_size);\n     node->count = 0;\n     return node;\n }\n \n-static void art_free_node16(art_node16_t *node) {\n-    for (size_t i = 0; i < node->count; ++i) {\n-        art_free_node(node->children[i]);\n-    }\n-    roaring_free(node);\n+static inline void art_node16_clear(art_node16_t *node, art_ref_t next_free) {\n+    node->count = 0;\n+    node->next_free = next_free;\n }\n \n-static inline art_node_t *art_node16_find_child(const art_node16_t *node,\n-                                                art_key_chunk_t key) {\n+static inline art_ref_t art_node16_find_child(const art_node16_t *node,\n+                                              art_key_chunk_t key) {\n     for (size_t i = 0; i < node->count; ++i) {\n         if (node->keys[i] == key) {\n             return node->children[i];\n         }\n     }\n-    return NULL;\n+    return CROARING_ART_NULL_REF;\n }\n \n-static art_node_t *art_node16_insert(art_node16_t *node, art_node_t *child,\n-                                     uint8_t key) {\n+static art_ref_t art_node16_insert(art_t *art, art_node16_t *node,\n+                                   art_ref_t child, uint8_t key) {\n     if (node->count < 16) {\n         size_t idx = 0;\n         for (; idx < node->count; ++idx) {\n@@ -404,24 +508,24 @@ static art_node_t *art_node16_insert(art_node16_t *node, art_node_t *child,\n         memmove(node->keys + idx + 1, node->keys + idx,\n                 after * sizeof(art_key_chunk_t));\n         memmove(node->children + idx + 1, node->children + idx,\n-                after * sizeof(art_node_t *));\n+                after * sizeof(art_ref_t));\n \n         node->children[idx] = child;\n         node->keys[idx] = key;\n         node->count++;\n-        return (art_node_t *)node;\n+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE16_TYPE);\n     }\n     art_node48_t *new_node =\n-        art_node48_create(node->base.prefix, node->base.prefix_size);\n+        art_node48_create(art, node->base.prefix, node->base.prefix_size);\n     for (size_t i = 0; i < 16; ++i) {\n-        art_node48_insert(new_node, node->children[i], node->keys[i]);\n+        art_node48_insert(art, new_node, node->children[i], node->keys[i]);\n     }\n-    roaring_free(node);\n-    return art_node48_insert(new_node, child, key);\n+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE16_TYPE);\n+    return art_node48_insert(art, new_node, child, key);\n }\n \n-static inline art_node_t *art_node16_erase(art_node16_t *node,\n-                                           uint8_t key_chunk) {\n+static inline art_ref_t art_node16_erase(art_t *art, art_node16_t *node,\n+                                         uint8_t key_chunk) {\n     for (size_t i = 0; i < node->count; ++i) {\n         if (node->keys[i] == key_chunk) {\n             // Shift other keys to maintain sorted order.\n@@ -429,28 +533,28 @@ static inline art_node_t *art_node16_erase(art_node16_t *node,\n             memmove(node->keys + i, node->keys + i + 1,\n                     after_next * sizeof(key_chunk));\n             memmove(node->children + i, node->children + i + 1,\n-                    after_next * sizeof(art_node_t *));\n+                    after_next * sizeof(art_ref_t));\n             node->count--;\n             break;\n         }\n     }\n     if (node->count > 4) {\n-        return (art_node_t *)node;\n+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE16_TYPE);\n     }\n     art_node4_t *new_node =\n-        art_node4_create(node->base.prefix, node->base.prefix_size);\n+        art_node4_create(art, node->base.prefix, node->base.prefix_size);\n     // Instead of calling insert, this could be specialized to 2x memcpy and\n     // setting the count.\n     for (size_t i = 0; i < 4; ++i) {\n-        art_node4_insert(new_node, node->children[i], node->keys[i]);\n+        art_node4_insert(art, new_node, node->children[i], node->keys[i]);\n     }\n-    roaring_free(node);\n-    return (art_node_t *)new_node;\n+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE16_TYPE);\n+    return art_get_ref(art, (art_node_t *)new_node, CROARING_ART_NODE4_TYPE);\n }\n \n static inline void art_node16_replace(art_node16_t *node,\n                                       art_key_chunk_t key_chunk,\n-                                      art_node_t *new_child) {\n+                                      art_ref_t new_child) {\n     for (uint8_t i = 0; i < node->count; ++i) {\n         if (node->keys[i] == key_chunk) {\n             node->children[i] = new_child;\n@@ -464,7 +568,7 @@ static inline art_indexed_child_t art_node16_next_child(\n     art_indexed_child_t indexed_child;\n     index++;\n     if (index >= node->count) {\n-        indexed_child.child = NULL;\n+        indexed_child.child = CROARING_ART_NULL_REF;\n         return indexed_child;\n     }\n     indexed_child.index = index;\n@@ -481,7 +585,7 @@ static inline art_indexed_child_t art_node16_prev_child(\n     index--;\n     art_indexed_child_t indexed_child;\n     if (index < 0) {\n-        indexed_child.child = NULL;\n+        indexed_child.child = CROARING_ART_NULL_REF;\n         return indexed_child;\n     }\n     indexed_child.index = index;\n@@ -494,7 +598,7 @@ static inline art_indexed_child_t art_node16_child_at(const art_node16_t *node,\n                                                       int index) {\n     art_indexed_child_t indexed_child;\n     if (index < 0 || index >= node->count) {\n-        indexed_child.child = NULL;\n+        indexed_child.child = CROARING_ART_NULL_REF;\n         return indexed_child;\n     }\n     indexed_child.index = index;\n@@ -514,11 +618,12 @@ static inline art_indexed_child_t art_node16_lower_bound(\n             return indexed_child;\n         }\n     }\n-    indexed_child.child = NULL;\n+    indexed_child.child = CROARING_ART_NULL_REF;\n     return indexed_child;\n }\n \n-static bool art_node16_internal_validate(const art_node16_t *node,\n+static bool art_node16_internal_validate(const art_t *art,\n+                                         const art_node16_t *node,\n                                          art_internal_validate_t validator) {\n     if (node->count <= 4) {\n         return art_validate_fail(&validator, \"Node16 has too few children\");\n@@ -541,18 +646,20 @@ static bool art_node16_internal_validate(const art_node16_t *node,\n             }\n         }\n         validator.current_key[validator.depth - 1] = node->keys[i];\n-        if (!art_internal_validate_at(node->children[i], validator)) {\n+        if (!art_internal_validate_at(art, node->children[i], validator)) {\n             return false;\n         }\n     }\n     return true;\n }\n \n-static art_node48_t *art_node48_create(const art_key_chunk_t prefix[],\n+static art_node48_t *art_node48_create(art_t *art,\n+                                       const art_key_chunk_t prefix[],\n                                        uint8_t prefix_size) {\n-    art_node48_t *node = (art_node48_t *)roaring_malloc(sizeof(art_node48_t));\n-    art_init_inner_node(&node->base, CROARING_ART_NODE48_TYPE, prefix,\n-                        prefix_size);\n+    uint64_t index = art_allocate_index(art, CROARING_ART_NODE48_TYPE);\n+    art_node48_t *node =\n+        ((art_node48_t *)art->nodes[CROARING_ART_NODE48_TYPE]) + index;\n+    art_init_inner_node(&node->base, prefix, prefix_size);\n     node->count = 0;\n     node->available_children = CROARING_NODE48_AVAILABLE_CHILDREN_MASK;\n     for (size_t i = 0; i < 256; ++i) {\n@@ -561,29 +668,22 @@ static art_node48_t *art_node48_create(const art_key_chunk_t prefix[],\n     return node;\n }\n \n-static void art_free_node48(art_node48_t *node) {\n-    uint64_t used_children =\n-        (node->available_children) ^ CROARING_NODE48_AVAILABLE_CHILDREN_MASK;\n-    while (used_children != 0) {\n-        // We checked above that used_children is not zero\n-        uint8_t child_idx = roaring_trailing_zeroes(used_children);\n-        art_free_node(node->children[child_idx]);\n-        used_children &= ~(UINT64_C(1) << child_idx);\n-    }\n-    roaring_free(node);\n+static inline void art_node48_clear(art_node48_t *node, art_ref_t next_free) {\n+    node->count = 0;\n+    node->next_free = next_free;\n }\n \n-static inline art_node_t *art_node48_find_child(const art_node48_t *node,\n-                                                art_key_chunk_t key) {\n+static inline art_ref_t art_node48_find_child(const art_node48_t *node,\n+                                              art_key_chunk_t key) {\n     uint8_t val_idx = node->keys[key];\n     if (val_idx != CROARING_ART_NODE48_EMPTY_VAL) {\n         return node->children[val_idx];\n     }\n-    return NULL;\n+    return CROARING_ART_NULL_REF;\n }\n \n-static art_node_t *art_node48_insert(art_node48_t *node, art_node_t *child,\n-                                     uint8_t key) {\n+static art_ref_t art_node48_insert(art_t *art, art_node48_t *node,\n+                                   art_ref_t child, uint8_t key) {\n     if (node->count < 48) {\n         // node->available_children is only zero when the node is full (count ==\n         // 48), we just checked count < 48\n@@ -592,48 +692,48 @@ static art_node_t *art_node48_insert(art_node48_t *node, art_node_t *child,\n         node->children[val_idx] = child;\n         node->count++;\n         node->available_children &= ~(UINT64_C(1) << val_idx);\n-        return (art_node_t *)node;\n+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE48_TYPE);\n     }\n     art_node256_t *new_node =\n-        art_node256_create(node->base.prefix, node->base.prefix_size);\n+        art_node256_create(art, node->base.prefix, node->base.prefix_size);\n     for (size_t i = 0; i < 256; ++i) {\n         uint8_t val_idx = node->keys[i];\n         if (val_idx != CROARING_ART_NODE48_EMPTY_VAL) {\n-            art_node256_insert(new_node, node->children[val_idx], i);\n+            art_node256_insert(art, new_node, node->children[val_idx], i);\n         }\n     }\n-    roaring_free(node);\n-    return art_node256_insert(new_node, child, key);\n+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE48_TYPE);\n+    return art_node256_insert(art, new_node, child, key);\n }\n \n-static inline art_node_t *art_node48_erase(art_node48_t *node,\n-                                           uint8_t key_chunk) {\n+static inline art_ref_t art_node48_erase(art_t *art, art_node48_t *node,\n+                                         uint8_t key_chunk) {\n     uint8_t val_idx = node->keys[key_chunk];\n     if (val_idx == CROARING_ART_NODE48_EMPTY_VAL) {\n-        return (art_node_t *)node;\n+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE48_TYPE);\n     }\n     node->keys[key_chunk] = CROARING_ART_NODE48_EMPTY_VAL;\n     node->available_children |= UINT64_C(1) << val_idx;\n     node->count--;\n     if (node->count > 16) {\n-        return (art_node_t *)node;\n+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE48_TYPE);\n     }\n \n     art_node16_t *new_node =\n-        art_node16_create(node->base.prefix, node->base.prefix_size);\n+        art_node16_create(art, node->base.prefix, node->base.prefix_size);\n     for (size_t i = 0; i < 256; ++i) {\n         val_idx = node->keys[i];\n         if (val_idx != CROARING_ART_NODE48_EMPTY_VAL) {\n-            art_node16_insert(new_node, node->children[val_idx], i);\n+            art_node16_insert(art, new_node, node->children[val_idx], i);\n         }\n     }\n-    roaring_free(node);\n-    return (art_node_t *)new_node;\n+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE48_TYPE);\n+    return art_get_ref(art, (art_node_t *)new_node, CROARING_ART_NODE16_TYPE);\n }\n \n static inline void art_node48_replace(art_node48_t *node,\n                                       art_key_chunk_t key_chunk,\n-                                      art_node_t *new_child) {\n+                                      art_ref_t new_child) {\n     uint8_t val_idx = node->keys[key_chunk];\n     assert(val_idx != CROARING_ART_NODE48_EMPTY_VAL);\n     node->children[val_idx] = new_child;\n@@ -651,7 +751,7 @@ static inline art_indexed_child_t art_node48_next_child(\n             return indexed_child;\n         }\n     }\n-    indexed_child.child = NULL;\n+    indexed_child.child = CROARING_ART_NULL_REF;\n     return indexed_child;\n }\n \n@@ -670,7 +770,7 @@ static inline art_indexed_child_t art_node48_prev_child(\n             return indexed_child;\n         }\n     }\n-    indexed_child.child = NULL;\n+    indexed_child.child = CROARING_ART_NULL_REF;\n     return indexed_child;\n }\n \n@@ -678,7 +778,7 @@ static inline art_indexed_child_t art_node48_child_at(const art_node48_t *node,\n                                                       int index) {\n     art_indexed_child_t indexed_child;\n     if (index < 0 || index >= 256) {\n-        indexed_child.child = NULL;\n+        indexed_child.child = CROARING_ART_NULL_REF;\n         return indexed_child;\n     }\n     indexed_child.index = index;\n@@ -698,11 +798,12 @@ static inline art_indexed_child_t art_node48_lower_bound(\n             return indexed_child;\n         }\n     }\n-    indexed_child.child = NULL;\n+    indexed_child.child = CROARING_ART_NULL_REF;\n     return indexed_child;\n }\n \n-static bool art_node48_internal_validate(const art_node48_t *node,\n+static bool art_node48_internal_validate(const art_t *art,\n+                                         const art_node48_t *node,\n                                          art_internal_validate_t validator) {\n     if (node->count <= 16) {\n         return art_validate_fail(&validator, \"Node48 has too few children\");\n@@ -719,8 +820,8 @@ static bool art_node48_internal_validate(const art_node48_t *node,\n                     &validator, \"Node48 keys point to the same child index\");\n             }\n \n-            art_node_t *child = node->children[child_idx];\n-            if (child == NULL) {\n+            art_ref_t child = node->children[child_idx];\n+            if (child == CROARING_ART_NULL_REF) {\n                 return art_validate_fail(&validator, \"Node48 has a NULL child\");\n             }\n             used_children |= UINT64_C(1) << child_idx;\n@@ -752,7 +853,7 @@ static bool art_node48_internal_validate(const art_node48_t *node,\n     for (int i = 0; i < 256; ++i) {\n         if (node->keys[i] != CROARING_ART_NODE48_EMPTY_VAL) {\n             validator.current_key[validator.depth - 1] = i;\n-            if (!art_internal_validate_at(node->children[node->keys[i]],\n+            if (!art_internal_validate_at(art, node->children[node->keys[i]],\n                                           validator)) {\n                 return false;\n             }\n@@ -761,62 +862,59 @@ static bool art_node48_internal_validate(const art_node48_t *node,\n     return true;\n }\n \n-static art_node256_t *art_node256_create(const art_key_chunk_t prefix[],\n+static art_node256_t *art_node256_create(art_t *art,\n+                                         const art_key_chunk_t prefix[],\n                                          uint8_t prefix_size) {\n+    uint64_t index = art_allocate_index(art, CROARING_ART_NODE256_TYPE);\n     art_node256_t *node =\n-        (art_node256_t *)roaring_malloc(sizeof(art_node256_t));\n-    art_init_inner_node(&node->base, CROARING_ART_NODE256_TYPE, prefix,\n-                        prefix_size);\n+        ((art_node256_t *)art->nodes[CROARING_ART_NODE256_TYPE]) + index;\n+    art_init_inner_node(&node->base, prefix, prefix_size);\n     node->count = 0;\n     for (size_t i = 0; i < 256; ++i) {\n-        node->children[i] = NULL;\n+        node->children[i] = CROARING_ART_NULL_REF;\n     }\n     return node;\n }\n \n-static void art_free_node256(art_node256_t *node) {\n-    for (size_t i = 0; i < 256; ++i) {\n-        if (node->children[i] != NULL) {\n-            art_free_node(node->children[i]);\n-        }\n-    }\n-    roaring_free(node);\n+static inline void art_node256_clear(art_node256_t *node, art_ref_t next_free) {\n+    node->count = 0;\n+    node->next_free = next_free;\n }\n \n-static inline art_node_t *art_node256_find_child(const art_node256_t *node,\n-                                                 art_key_chunk_t key) {\n+static inline art_ref_t art_node256_find_child(const art_node256_t *node,\n+                                               art_key_chunk_t key) {\n     return node->children[key];\n }\n \n-static art_node_t *art_node256_insert(art_node256_t *node, art_node_t *child,\n-                                      uint8_t key) {\n+static art_ref_t art_node256_insert(art_t *art, art_node256_t *node,\n+                                    art_ref_t child, uint8_t key) {\n     node->children[key] = child;\n     node->count++;\n-    return (art_node_t *)node;\n+    return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE256_TYPE);\n }\n \n-static inline art_node_t *art_node256_erase(art_node256_t *node,\n-                                            uint8_t key_chunk) {\n-    node->children[key_chunk] = NULL;\n+static inline art_ref_t art_node256_erase(art_t *art, art_node256_t *node,\n+                                          uint8_t key_chunk) {\n+    node->children[key_chunk] = CROARING_ART_NULL_REF;\n     node->count--;\n     if (node->count > 48) {\n-        return (art_node_t *)node;\n+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE256_TYPE);\n     }\n \n     art_node48_t *new_node =\n-        art_node48_create(node->base.prefix, node->base.prefix_size);\n+        art_node48_create(art, node->base.prefix, node->base.prefix_size);\n     for (size_t i = 0; i < 256; ++i) {\n-        if (node->children[i] != NULL) {\n-            art_node48_insert(new_node, node->children[i], i);\n+        if (node->children[i] != CROARING_ART_NULL_REF) {\n+            art_node48_insert(art, new_node, node->children[i], i);\n         }\n     }\n-    roaring_free(node);\n-    return (art_node_t *)new_node;\n+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE256_TYPE);\n+    return art_get_ref(art, (art_node_t *)new_node, CROARING_ART_NODE48_TYPE);\n }\n \n static inline void art_node256_replace(art_node256_t *node,\n                                        art_key_chunk_t key_chunk,\n-                                       art_node_t *new_child) {\n+                                       art_ref_t new_child) {\n     node->children[key_chunk] = new_child;\n }\n \n@@ -825,14 +923,14 @@ static inline art_indexed_child_t art_node256_next_child(\n     art_indexed_child_t indexed_child;\n     index++;\n     for (size_t i = index; i < 256; ++i) {\n-        if (node->children[i] != NULL) {\n+        if (node->children[i] != CROARING_ART_NULL_REF) {\n             indexed_child.index = i;\n             indexed_child.child = node->children[i];\n             indexed_child.key_chunk = i;\n             return indexed_child;\n         }\n     }\n-    indexed_child.child = NULL;\n+    indexed_child.child = CROARING_ART_NULL_REF;\n     return indexed_child;\n }\n \n@@ -844,14 +942,14 @@ static inline art_indexed_child_t art_node256_prev_child(\n     index--;\n     art_indexed_child_t indexed_child;\n     for (int i = index; i >= 0; --i) {\n-        if (node->children[i] != NULL) {\n+        if (node->children[i] != CROARING_ART_NULL_REF) {\n             indexed_child.index = i;\n             indexed_child.child = node->children[i];\n             indexed_child.key_chunk = i;\n             return indexed_child;\n         }\n     }\n-    indexed_child.child = NULL;\n+    indexed_child.child = CROARING_ART_NULL_REF;\n     return indexed_child;\n }\n \n@@ -859,7 +957,7 @@ static inline art_indexed_child_t art_node256_child_at(\n     const art_node256_t *node, int index) {\n     art_indexed_child_t indexed_child;\n     if (index < 0 || index >= 256) {\n-        indexed_child.child = NULL;\n+        indexed_child.child = CROARING_ART_NULL_REF;\n         return indexed_child;\n     }\n     indexed_child.index = index;\n@@ -872,18 +970,19 @@ static inline art_indexed_child_t art_node256_lower_bound(\n     art_node256_t *node, art_key_chunk_t key_chunk) {\n     art_indexed_child_t indexed_child;\n     for (size_t i = key_chunk; i < 256; ++i) {\n-        if (node->children[i] != NULL) {\n+        if (node->children[i] != CROARING_ART_NULL_REF) {\n             indexed_child.index = i;\n             indexed_child.child = node->children[i];\n             indexed_child.key_chunk = i;\n             return indexed_child;\n         }\n     }\n-    indexed_child.child = NULL;\n+    indexed_child.child = CROARING_ART_NULL_REF;\n     return indexed_child;\n }\n \n-static bool art_node256_internal_validate(const art_node256_t *node,\n+static bool art_node256_internal_validate(const art_t *art,\n+                                          const art_node256_t *node,\n                                           art_internal_validate_t validator) {\n     if (node->count <= 48) {\n         return art_validate_fail(&validator, \"Node256 has too few children\");\n@@ -894,7 +993,7 @@ static bool art_node256_internal_validate(const art_node256_t *node,\n     validator.depth++;\n     int actual_count = 0;\n     for (int i = 0; i < 256; ++i) {\n-        if (node->children[i] != NULL) {\n+        if (node->children[i] != CROARING_ART_NULL_REF) {\n             actual_count++;\n \n             for (int j = i + 1; j < 256; ++j) {\n@@ -905,7 +1004,7 @@ static bool art_node256_internal_validate(const art_node256_t *node,\n             }\n \n             validator.current_key[validator.depth - 1] = i;\n-            if (!art_internal_validate_at(node->children[i], validator)) {\n+            if (!art_internal_validate_at(art, node->children[i], validator)) {\n                 return false;\n             }\n         }\n@@ -919,9 +1018,10 @@ static bool art_node256_internal_validate(const art_node256_t *node,\n \n // Finds the child with the given key chunk in the inner node, returns NULL if\n // no such child is found.\n-static art_node_t *art_find_child(const art_inner_node_t *node,\n-                                  art_key_chunk_t key_chunk) {\n-    switch (art_get_type(node)) {\n+static art_ref_t art_find_child(const art_inner_node_t *node,\n+                                art_typecode_t typecode,\n+                                art_key_chunk_t key_chunk) {\n+    switch (typecode) {\n         case CROARING_ART_NODE4_TYPE:\n             return art_node4_find_child((art_node4_t *)node, key_chunk);\n         case CROARING_ART_NODE16_TYPE:\n@@ -932,14 +1032,14 @@ static art_node_t *art_find_child(const art_inner_node_t *node,\n             return art_node256_find_child((art_node256_t *)node, key_chunk);\n         default:\n             assert(false);\n-            return NULL;\n+            return CROARING_ART_NULL_REF;\n     }\n }\n \n // Replaces the child with the given key chunk in the inner node.\n-static void art_replace(art_inner_node_t *node, art_key_chunk_t key_chunk,\n-                        art_node_t *new_child) {\n-    switch (art_get_type(node)) {\n+static void art_replace(art_inner_node_t *node, art_typecode_t typecode,\n+                        art_key_chunk_t key_chunk, art_ref_t new_child) {\n+    switch (typecode) {\n         case CROARING_ART_NODE4_TYPE:\n             art_node4_replace((art_node4_t *)node, key_chunk, new_child);\n             break;\n@@ -959,78 +1059,112 @@ static void art_replace(art_inner_node_t *node, art_key_chunk_t key_chunk,\n \n // Erases the child with the given key chunk from the inner node, returns the\n // updated node (the same as the initial node if it was not shrunk).\n-static art_node_t *art_node_erase(art_inner_node_t *node,\n-                                  art_key_chunk_t key_chunk) {\n-    switch (art_get_type(node)) {\n+static art_ref_t art_node_erase(art_t *art, art_inner_node_t *node,\n+                                art_typecode_t typecode,\n+                                art_key_chunk_t key_chunk) {\n+    switch (typecode) {\n         case CROARING_ART_NODE4_TYPE:\n-            return art_node4_erase((art_node4_t *)node, key_chunk);\n+            return art_node4_erase(art, (art_node4_t *)node, key_chunk);\n         case CROARING_ART_NODE16_TYPE:\n-            return art_node16_erase((art_node16_t *)node, key_chunk);\n+            return art_node16_erase(art, (art_node16_t *)node, key_chunk);\n         case CROARING_ART_NODE48_TYPE:\n-            return art_node48_erase((art_node48_t *)node, key_chunk);\n+            return art_node48_erase(art, (art_node48_t *)node, key_chunk);\n         case CROARING_ART_NODE256_TYPE:\n-            return art_node256_erase((art_node256_t *)node, key_chunk);\n+            return art_node256_erase(art, (art_node256_t *)node, key_chunk);\n         default:\n             assert(false);\n-            return NULL;\n+            return CROARING_ART_NULL_REF;\n     }\n }\n \n // Inserts the leaf with the given key chunk in the inner node, returns a\n // pointer to the (possibly expanded) node.\n-static art_node_t *art_node_insert_leaf(art_inner_node_t *node,\n-                                        art_key_chunk_t key_chunk,\n-                                        art_leaf_t *leaf) {\n-    art_node_t *child = (art_node_t *)(CROARING_SET_LEAF(leaf));\n-    switch (art_get_type(node)) {\n+static art_ref_t art_node_insert_leaf(art_t *art, art_inner_node_t *node,\n+                                      art_typecode_t typecode,\n+                                      art_key_chunk_t key_chunk,\n+                                      art_ref_t leaf) {\n+    switch (typecode) {\n         case CROARING_ART_NODE4_TYPE:\n-            return art_node4_insert((art_node4_t *)node, child, key_chunk);\n+            return art_node4_insert(art, (art_node4_t *)node, leaf, key_chunk);\n         case CROARING_ART_NODE16_TYPE:\n-            return art_node16_insert((art_node16_t *)node, child, key_chunk);\n+            return art_node16_insert(art, (art_node16_t *)node, leaf,\n+                                     key_chunk);\n         case CROARING_ART_NODE48_TYPE:\n-            return art_node48_insert((art_node48_t *)node, child, key_chunk);\n+            return art_node48_insert(art, (art_node48_t *)node, leaf,\n+                                     key_chunk);\n         case CROARING_ART_NODE256_TYPE:\n-            return art_node256_insert((art_node256_t *)node, child, key_chunk);\n+            return art_node256_insert(art, (art_node256_t *)node, leaf,\n+                                      key_chunk);\n         default:\n             assert(false);\n-            return NULL;\n+            return CROARING_ART_NULL_REF;\n     }\n }\n \n-// Frees the node and its children. Leaves are freed by the user.\n-static void art_free_node(art_node_t *node) {\n-    if (art_is_leaf(node)) {\n-        // We leave it up to the user to free leaves.\n-        return;\n+static uint64_t art_node_get_next_free(const art_t *art, art_ref_t ref) {\n+    art_node_t *node = art_deref(art, ref);\n+    art_typecode_t typecode = art_ref_typecode(ref);\n+    switch (typecode) {\n+        case CROARING_ART_LEAF_TYPE:\n+            return ((art_leaf_t *)node)->next_free;\n+        case CROARING_ART_NODE4_TYPE:\n+            return ((art_node4_t *)node)->next_free;\n+        case CROARING_ART_NODE16_TYPE:\n+            return ((art_node16_t *)node)->next_free;\n+        case CROARING_ART_NODE48_TYPE:\n+            return ((art_node48_t *)node)->next_free;\n+        case CROARING_ART_NODE256_TYPE:\n+            return ((art_node256_t *)node)->next_free;\n+        default:\n+            assert(false);\n+            return 0;\n     }\n-    switch (art_get_type((art_inner_node_t *)node)) {\n+}\n+\n+static void art_node_set_next_free(art_node_t *node, art_typecode_t typecode,\n+                                   uint64_t next_free) {\n+    switch (typecode) {\n+        case CROARING_ART_LEAF_TYPE:\n+            ((art_leaf_t *)node)->next_free = next_free;\n+            break;\n         case CROARING_ART_NODE4_TYPE:\n-            art_free_node4((art_node4_t *)node);\n+            ((art_node4_t *)node)->next_free = next_free;\n             break;\n         case CROARING_ART_NODE16_TYPE:\n-            art_free_node16((art_node16_t *)node);\n+            ((art_node16_t *)node)->next_free = next_free;\n             break;\n         case CROARING_ART_NODE48_TYPE:\n-            art_free_node48((art_node48_t *)node);\n+            ((art_node48_t *)node)->next_free = next_free;\n             break;\n         case CROARING_ART_NODE256_TYPE:\n-            art_free_node256((art_node256_t *)node);\n+            ((art_node256_t *)node)->next_free = next_free;\n             break;\n         default:\n             assert(false);\n     }\n }\n \n+// Marks the node as unoccopied and frees its index.\n+static void art_node_free(art_t *art, art_node_t *node,\n+                          art_typecode_t typecode) {\n+    uint64_t index = art_get_index(art, node, typecode);\n+    uint64_t next_free = art->first_free[typecode];\n+    art_node_set_next_free(node, typecode, next_free);\n+    art->first_free[typecode] = index;\n+}\n+\n // Returns the next child in key order, or NULL if called on a leaf.\n // Provided index may be in the range [-1, 255].\n static art_indexed_child_t art_node_next_child(const art_node_t *node,\n+                                               art_typecode_t typecode,\n                                                int index) {\n-    if (art_is_leaf(node)) {\n-        art_indexed_child_t indexed_child;\n-        indexed_child.child = NULL;\n-        return indexed_child;\n-    }\n-    switch (art_get_type((art_inner_node_t *)node)) {\n+    switch (typecode) {\n+        case CROARING_ART_LEAF_TYPE:\n+            return (art_indexed_child_t){\n+                .child = CROARING_ART_NULL_REF,\n+                .index = 0,\n+                .key_chunk = 0,\n+            };\n         case CROARING_ART_NODE4_TYPE:\n             return art_node4_next_child((art_node4_t *)node, index);\n         case CROARING_ART_NODE16_TYPE:\n@@ -1048,13 +1182,15 @@ static art_indexed_child_t art_node_next_child(const art_node_t *node,\n // Returns the previous child in key order, or NULL if called on a leaf.\n // Provided index may be in the range [0, 256].\n static art_indexed_child_t art_node_prev_child(const art_node_t *node,\n+                                               art_typecode_t typecode,\n                                                int index) {\n-    if (art_is_leaf(node)) {\n-        art_indexed_child_t indexed_child;\n-        indexed_child.child = NULL;\n-        return indexed_child;\n-    }\n-    switch (art_get_type((art_inner_node_t *)node)) {\n+    switch (typecode) {\n+        case CROARING_ART_LEAF_TYPE:\n+            return (art_indexed_child_t){\n+                .child = CROARING_ART_NULL_REF,\n+                .index = 0,\n+                .key_chunk = 0,\n+            };\n         case CROARING_ART_NODE4_TYPE:\n             return art_node4_prev_child((art_node4_t *)node, index);\n         case CROARING_ART_NODE16_TYPE:\n@@ -1069,16 +1205,19 @@ static art_indexed_child_t art_node_prev_child(const art_node_t *node,\n     }\n }\n \n-// Returns the child found at the provided index, or NULL if called on a leaf.\n-// Provided index is only valid if returned by art_node_(next|prev)_child.\n+// Returns the child found at the provided index, or NULL if called on a\n+// leaf. Provided index is only valid if returned by\n+// art_node_(next|prev)_child.\n static art_indexed_child_t art_node_child_at(const art_node_t *node,\n+                                             art_typecode_t typecode,\n                                              int index) {\n-    if (art_is_leaf(node)) {\n-        art_indexed_child_t indexed_child;\n-        indexed_child.child = NULL;\n-        return indexed_child;\n-    }\n-    switch (art_get_type((art_inner_node_t *)node)) {\n+    switch (typecode) {\n+        case CROARING_ART_LEAF_TYPE:\n+            return (art_indexed_child_t){\n+                .child = CROARING_ART_NULL_REF,\n+                .index = 0,\n+                .key_chunk = 0,\n+            };\n         case CROARING_ART_NODE4_TYPE:\n             return art_node4_child_at((art_node4_t *)node, index);\n         case CROARING_ART_NODE16_TYPE:\n@@ -1093,16 +1232,18 @@ static art_indexed_child_t art_node_child_at(const art_node_t *node,\n     }\n }\n \n-// Returns the child with the smallest key equal to or greater than the given\n-// key chunk, NULL if called on a leaf or no such child was found.\n+// Returns the child with the smallest key equal to or greater than the\n+// given key chunk, NULL if called on a leaf or no such child was found.\n static art_indexed_child_t art_node_lower_bound(const art_node_t *node,\n+                                                art_typecode_t typecode,\n                                                 art_key_chunk_t key_chunk) {\n-    if (art_is_leaf(node)) {\n-        art_indexed_child_t indexed_child;\n-        indexed_child.child = NULL;\n-        return indexed_child;\n-    }\n-    switch (art_get_type((art_inner_node_t *)node)) {\n+    switch (typecode) {\n+        case CROARING_ART_LEAF_TYPE:\n+            return (art_indexed_child_t){\n+                .child = CROARING_ART_NULL_REF,\n+                .index = 0,\n+                .key_chunk = 0,\n+            };\n         case CROARING_ART_NODE4_TYPE:\n             return art_node4_lower_bound((art_node4_t *)node, key_chunk);\n         case CROARING_ART_NODE16_TYPE:\n@@ -1117,7 +1258,7 @@ static art_indexed_child_t art_node_lower_bound(const art_node_t *node,\n     }\n }\n \n-// ====================== End of node-specific functions =======================\n+// ====================== End of node-specific functions ======================\n \n // Compares the given ranges of two keys, returns their relative order:\n // * Key range 1 <  key range 2: a negative value\n@@ -1155,45 +1296,112 @@ static uint8_t art_common_prefix(const art_key_chunk_t key1[],\n     return offset;\n }\n \n-// Returns a pointer to the rootmost node where the value was inserted, may not\n-// be equal to `node`.\n-static art_node_t *art_insert_at(art_node_t *node, const art_key_chunk_t key[],\n-                                 uint8_t depth, art_leaf_t *new_leaf) {\n-    if (art_is_leaf(node)) {\n-        art_leaf_t *leaf = CROARING_CAST_LEAF(node);\n+/**\n+ * Extends the array of nodes of the given typecode. Invalidates pointers into\n+ * the array obtained by `art_deref`.\n+ */\n+static void art_extend(art_t *art, art_typecode_t typecode) {\n+    uint64_t size = art->first_free[typecode];\n+    uint64_t capacity = art->capacities[typecode];\n+    if (size < capacity) {\n+        return;\n+    }\n+    uint64_t new_capacity;\n+    if (capacity == 0) {\n+        new_capacity = 2;\n+    } else if (capacity < 1024) {\n+        new_capacity = 2 * capacity;\n+    } else {\n+        new_capacity = 5 * capacity / 4;\n+    }\n+    art->capacities[typecode] = new_capacity;\n+    art->nodes[typecode] = roaring_realloc(\n+        art->nodes[typecode], new_capacity * ART_NODE_SIZES[typecode]);\n+    uint64_t increase = new_capacity - capacity;\n+    memset(art_get_node(art, capacity, typecode), 0,\n+           increase * ART_NODE_SIZES[typecode]);\n+    for (uint64_t i = capacity; i < new_capacity; ++i) {\n+        art_node_set_next_free(art_get_node(art, i, typecode), typecode, i + 1);\n+    }\n+}\n+\n+/**\n+ * Returns the next free index for the given typecode, may be equal to the\n+ * capacity of the array.\n+ */\n+static uint64_t art_next_free(const art_t *art, art_typecode_t typecode) {\n+    uint64_t index = art->first_free[typecode];\n+    return art_node_get_next_free(art, art_to_ref(index, typecode));\n+}\n+\n+/**\n+ * Marks an index for the given typecode as used, expanding the relevant node\n+ * array if necessary.\n+ */\n+static uint64_t art_allocate_index(art_t *art, art_typecode_t typecode) {\n+    uint64_t first_free = art->first_free[typecode];\n+    if (first_free == art->capacities[typecode]) {\n+        art_extend(art, typecode);\n+        art->first_free[typecode]++;\n+        return first_free;\n+    }\n+    art->first_free[typecode] = art_next_free(art, typecode);\n+    return first_free;\n+}\n+\n+// Returns a pointer to the rootmost node where the value was inserted, may\n+// not be equal to `node`.\n+static art_ref_t art_insert_at(art_t *art, art_ref_t ref,\n+                               const art_key_chunk_t key[], uint8_t depth,\n+                               art_ref_t new_leaf) {\n+    if (art_is_leaf(ref)) {\n+        art_leaf_t *leaf = (art_leaf_t *)art_deref(art, ref);\n         uint8_t common_prefix = art_common_prefix(\n             leaf->key, depth, ART_KEY_BYTES, key, depth, ART_KEY_BYTES);\n \n-        // Previously this was a leaf, create an inner node instead and add both\n-        // the existing and new leaf to it.\n+        // Previously this was a leaf, create an inner node instead and add\n+        // both the existing and new leaf to it.\n         art_node_t *new_node =\n-            (art_node_t *)art_node4_create(key + depth, common_prefix);\n+            (art_node_t *)art_node4_create(art, key + depth, common_prefix);\n \n-        new_node = art_node_insert_leaf((art_inner_node_t *)new_node,\n-                                        leaf->key[depth + common_prefix], leaf);\n-        new_node = art_node_insert_leaf((art_inner_node_t *)new_node,\n-                                        key[depth + common_prefix], new_leaf);\n+        art_ref_t new_ref = art_node_insert_leaf(\n+            art, (art_inner_node_t *)new_node, CROARING_ART_NODE4_TYPE,\n+            leaf->key[depth + common_prefix], ref);\n+        new_ref = art_node_insert_leaf(art, (art_inner_node_t *)new_node,\n+                                       CROARING_ART_NODE4_TYPE,\n+                                       key[depth + common_prefix], new_leaf);\n \n         // The new inner node is now the rootmost node.\n-        return new_node;\n+        return new_ref;\n     }\n-    art_inner_node_t *inner_node = (art_inner_node_t *)node;\n+    art_inner_node_t *inner_node = (art_inner_node_t *)art_deref(art, ref);\n     // Not a leaf: inner node\n     uint8_t common_prefix =\n         art_common_prefix(inner_node->prefix, 0, inner_node->prefix_size, key,\n                           depth, ART_KEY_BYTES);\n     if (common_prefix != inner_node->prefix_size) {\n-        // Partial prefix match.  Create a new internal node to hold the common\n+        // Partial prefix match. Create a new internal node to hold the common\n         // prefix.\n-        art_node4_t *node4 =\n-            art_node4_create(inner_node->prefix, common_prefix);\n+        // We create a copy of the node's prefix as the creation of a new\n+        // node may invalidate the prefix pointer.\n+        art_key_chunk_t *prefix_copy = (art_key_chunk_t *)roaring_malloc(\n+            common_prefix * sizeof(art_key_chunk_t));\n+        memcpy(prefix_copy, inner_node->prefix,\n+               common_prefix * sizeof(art_key_chunk_t));\n+        art_node4_t *node4 = art_node4_create(art, prefix_copy, common_prefix);\n+        roaring_free(prefix_copy);\n+\n+        // Deref as a new node was created.\n+        inner_node = (art_inner_node_t *)art_deref(art, ref);\n \n         // Make the existing internal node a child of the new internal node.\n-        node4 = (art_node4_t *)art_node4_insert(\n-            node4, node, inner_node->prefix[common_prefix]);\n+        art_node4_insert(art, node4, ref, inner_node->prefix[common_prefix]);\n \n-        // Correct the prefix of the moved internal node, trimming off the chunk\n-        // inserted into the new internal node.\n+        // Deref again as a new node was created.\n+        inner_node = (art_inner_node_t *)art_deref(art, ref);\n+\n+        // Correct the prefix of the moved internal node, trimming off the\n+        // chunk inserted into the new internal node.\n         inner_node->prefix_size = inner_node->prefix_size - common_prefix - 1;\n         if (inner_node->prefix_size > 0) {\n             // Move the remaining prefix to the correct position.\n@@ -1202,55 +1410,67 @@ static art_node_t *art_insert_at(art_node_t *node, const art_key_chunk_t key[],\n         }\n \n         // Insert the value in the new internal node.\n-        return art_node_insert_leaf(&node4->base, key[common_prefix + depth],\n-                                    new_leaf);\n+        return art_node_insert_leaf(art, (art_inner_node_t *)node4,\n+                                    CROARING_ART_NODE4_TYPE,\n+                                    key[common_prefix + depth], new_leaf);\n     }\n     // Prefix matches entirely or node has no prefix. Look for an existing\n     // child.\n     art_key_chunk_t key_chunk = key[depth + common_prefix];\n-    art_node_t *child = art_find_child(inner_node, key_chunk);\n-    if (child != NULL) {\n-        art_node_t *new_child =\n-            art_insert_at(child, key, depth + common_prefix + 1, new_leaf);\n+    art_ref_t child =\n+        art_find_child(inner_node, art_ref_typecode(ref), key_chunk);\n+    if (child != CROARING_ART_NULL_REF) {\n+        art_ref_t new_child =\n+            art_insert_at(art, child, key, depth + common_prefix + 1, new_leaf);\n         if (new_child != child) {\n+            // Deref again as a new node may have been created.\n+            inner_node = (art_inner_node_t *)art_deref(art, ref);\n             // Node type changed.\n-            art_replace(inner_node, key_chunk, new_child);\n+            art_replace(inner_node, art_ref_typecode(ref), key_chunk,\n+                        new_child);\n         }\n-        return node;\n+        return ref;\n     }\n-    return art_node_insert_leaf(inner_node, key_chunk, new_leaf);\n+    return art_node_insert_leaf(art, inner_node, art_ref_typecode(ref),\n+                                key_chunk, new_leaf);\n }\n \n // Erase helper struct.\n typedef struct art_erase_result_s {\n-    // The rootmost node where the value was erased, may not be equal to `node`.\n-    // If no value was removed, this is null.\n-    art_node_t *rootmost_node;\n+    // The rootmost node where the value was erased, may not be equal to\n+    // the original node. If no value was removed, this is\n+    // CROARING_ART_NULL_REF.\n+    art_ref_t rootmost_node;\n+\n+    // True if a value was erased.\n+    bool erased;\n \n-    // Value removed, null if not removed.\n-    art_val_t *value_erased;\n+    // Value removed, if any.\n+    art_val_t value_erased;\n } art_erase_result_t;\n \n // Searches for the given key starting at `node`, erases it if found.\n-static art_erase_result_t art_erase_at(art_node_t *node,\n+static art_erase_result_t art_erase_at(art_t *art, art_ref_t ref,\n                                        const art_key_chunk_t *key,\n                                        uint8_t depth) {\n     art_erase_result_t result;\n-    result.rootmost_node = NULL;\n-    result.value_erased = NULL;\n+    result.rootmost_node = CROARING_ART_NULL_REF;\n+    result.erased = false;\n \n-    if (art_is_leaf(node)) {\n-        art_leaf_t *leaf = CROARING_CAST_LEAF(node);\n+    if (art_is_leaf(ref)) {\n+        art_leaf_t *leaf = (art_leaf_t *)art_deref(art, ref);\n         uint8_t common_prefix = art_common_prefix(leaf->key, 0, ART_KEY_BYTES,\n                                                   key, 0, ART_KEY_BYTES);\n         if (common_prefix != ART_KEY_BYTES) {\n             // Leaf key mismatch.\n             return result;\n         }\n-        result.value_erased = (art_val_t *)leaf;\n+        result.erased = true;\n+        result.value_erased = leaf->val;\n+        art_node_free(art, (art_node_t *)leaf, CROARING_ART_LEAF_TYPE);\n         return result;\n     }\n-    art_inner_node_t *inner_node = (art_inner_node_t *)node;\n+    art_inner_node_t *inner_node = (art_inner_node_t *)art_deref(art, ref);\n     uint8_t common_prefix =\n         art_common_prefix(inner_node->prefix, 0, inner_node->prefix_size, key,\n                           depth, ART_KEY_BYTES);\n@@ -1259,101 +1479,76 @@ static art_erase_result_t art_erase_at(art_node_t *node,\n         return result;\n     }\n     art_key_chunk_t key_chunk = key[depth + common_prefix];\n-    art_node_t *child = art_find_child(inner_node, key_chunk);\n-    if (child == NULL) {\n+    art_ref_t child =\n+        art_find_child(inner_node, art_ref_typecode(ref), key_chunk);\n+    if (child == CROARING_ART_NULL_REF) {\n         // No child with key chunk.\n         return result;\n     }\n-    // Try to erase the key further down. Skip the key chunk associated with the\n-    // child in the node.\n+    // Try to erase the key further down. Skip the key chunk associated with\n+    // the child in the node.\n     art_erase_result_t child_result =\n-        art_erase_at(child, key, depth + common_prefix + 1);\n-    if (child_result.value_erased == NULL) {\n+        art_erase_at(art, child, key, depth + common_prefix + 1);\n+    if (!child_result.erased) {\n         return result;\n     }\n+    result.erased = true;\n     result.value_erased = child_result.value_erased;\n-    result.rootmost_node = node;\n-    if (child_result.rootmost_node == NULL) {\n+    result.rootmost_node = ref;\n+\n+    // Deref again as nodes may have changed location.\n+    inner_node = (art_inner_node_t *)art_deref(art, ref);\n+    if (child_result.rootmost_node == CROARING_ART_NULL_REF) {\n         // Child node was fully erased, erase it from this node's children.\n-        result.rootmost_node = art_node_erase(inner_node, key_chunk);\n+        result.rootmost_node =\n+            art_node_erase(art, inner_node, art_ref_typecode(ref), key_chunk);\n     } else if (child_result.rootmost_node != child) {\n         // Child node was not fully erased, update the pointer to it in this\n         // node.\n-        art_replace(inner_node, key_chunk, child_result.rootmost_node);\n+        art_replace(inner_node, art_ref_typecode(ref), key_chunk,\n+                    child_result.rootmost_node);\n     }\n     return result;\n }\n \n-// Searches for the given key starting at `node`, returns NULL if the key was\n-// not found.\n-static art_val_t *art_find_at(const art_node_t *node,\n+// Searches for the given key starting at `node`, returns NULL if the key\n+// was not found.\n+static art_val_t *art_find_at(const art_t *art, art_ref_t ref,\n                               const art_key_chunk_t *key, uint8_t depth) {\n-    while (!art_is_leaf(node)) {\n-        art_inner_node_t *inner_node = (art_inner_node_t *)node;\n+    while (!art_is_leaf(ref)) {\n+        art_inner_node_t *inner_node = (art_inner_node_t *)art_deref(art, ref);\n         uint8_t common_prefix =\n             art_common_prefix(inner_node->prefix, 0, inner_node->prefix_size,\n                               key, depth, ART_KEY_BYTES);\n         if (common_prefix != inner_node->prefix_size) {\n             return NULL;\n         }\n-        art_node_t *child =\n-            art_find_child(inner_node, key[depth + inner_node->prefix_size]);\n-        if (child == NULL) {\n+        art_ref_t child = art_find_child(inner_node, art_ref_typecode(ref),\n+                                         key[depth + inner_node->prefix_size]);\n+        if (child == CROARING_ART_NULL_REF) {\n             return NULL;\n         }\n-        node = child;\n+        ref = child;\n         // Include both the prefix and the child key chunk in the depth.\n         depth += inner_node->prefix_size + 1;\n     }\n-    art_leaf_t *leaf = CROARING_CAST_LEAF(node);\n+    art_leaf_t *leaf = (art_leaf_t *)art_deref(art, ref);\n     if (depth >= ART_KEY_BYTES) {\n-        return (art_val_t *)leaf;\n+        return &leaf->val;\n     }\n     uint8_t common_prefix =\n         art_common_prefix(leaf->key, 0, ART_KEY_BYTES, key, 0, ART_KEY_BYTES);\n     if (common_prefix == ART_KEY_BYTES) {\n-        return (art_val_t *)leaf;\n+        return &leaf->val;\n     }\n     return NULL;\n }\n \n-// Returns the size in bytes of the subtrie.\n-static size_t art_size_in_bytes_at(const art_node_t *node) {\n-    if (art_is_leaf(node)) {\n-        return 0;\n-    }\n-    size_t size = 0;\n-    switch (art_get_type((art_inner_node_t *)node)) {\n-        case CROARING_ART_NODE4_TYPE: {\n-            size += sizeof(art_node4_t);\n-        } break;\n-        case CROARING_ART_NODE16_TYPE: {\n-            size += sizeof(art_node16_t);\n-        } break;\n-        case CROARING_ART_NODE48_TYPE: {\n-            size += sizeof(art_node48_t);\n-        } break;\n-        case CROARING_ART_NODE256_TYPE: {\n-            size += sizeof(art_node256_t);\n-        } break;\n-        default:\n-            assert(false);\n-            break;\n-    }\n-    art_indexed_child_t indexed_child = art_node_next_child(node, -1);\n-    while (indexed_child.child != NULL) {\n-        size += art_size_in_bytes_at(indexed_child.child);\n-        indexed_child = art_node_next_child(node, indexed_child.index);\n-    }\n-    return size;\n-}\n-\n-static void art_node_print_type(const art_node_t *node) {\n-    if (art_is_leaf(node)) {\n-        printf(\"Leaf\");\n-        return;\n-    }\n-    switch (art_get_type((art_inner_node_t *)node)) {\n+static void art_node_print_type(art_ref_t ref) {\n+    switch (art_ref_typecode(ref)) {\n+        case CROARING_ART_LEAF_TYPE:\n+            printf(\"Leaf\");\n+            return;\n         case CROARING_ART_NODE4_TYPE:\n             printf(\"Node4\");\n             return;\n@@ -1372,10 +1567,10 @@ static void art_node_print_type(const art_node_t *node) {\n     }\n }\n \n-static void art_node_printf(const art_node_t *node, uint8_t depth) {\n-    if (art_is_leaf(node)) {\n+void art_node_printf(const art_t *art, art_ref_t ref, uint8_t depth) {\n+    if (art_is_leaf(ref)) {\n         printf(\"{ type: Leaf, key: \");\n-        art_leaf_t *leaf = CROARING_CAST_LEAF(node);\n+        art_leaf_t *leaf = (art_leaf_t *)art_deref(art, ref);\n         for (size_t i = 0; i < ART_KEY_BYTES; ++i) {\n             printf(\"%02x\", leaf->key[i]);\n         }\n@@ -1387,10 +1582,10 @@ static void art_node_printf(const art_node_t *node, uint8_t depth) {\n \n     printf(\"%*s\", depth, \"\");\n     printf(\"type: \");\n-    art_node_print_type(node);\n+    art_node_print_type(ref);\n     printf(\"\\n\");\n \n-    art_inner_node_t *inner_node = (art_inner_node_t *)node;\n+    art_inner_node_t *inner_node = (art_inner_node_t *)art_deref(art, ref);\n     printf(\"%*s\", depth, \"\");\n     printf(\"prefix_size: %d\\n\", inner_node->prefix_size);\n \n@@ -1401,41 +1596,42 @@ static void art_node_printf(const art_node_t *node, uint8_t depth) {\n     }\n     printf(\"\\n\");\n \n-    switch (art_get_type(inner_node)) {\n+    switch (art_ref_typecode(ref)) {\n         case CROARING_ART_NODE4_TYPE: {\n-            art_node4_t *node4 = (art_node4_t *)node;\n+            art_node4_t *node4 = (art_node4_t *)inner_node;\n             for (uint8_t i = 0; i < node4->count; ++i) {\n                 printf(\"%*s\", depth, \"\");\n                 printf(\"key: %02x \", node4->keys[i]);\n-                art_node_printf(node4->children[i], depth);\n+                art_node_printf(art, node4->children[i], depth);\n             }\n         } break;\n         case CROARING_ART_NODE16_TYPE: {\n-            art_node16_t *node16 = (art_node16_t *)node;\n+            art_node16_t *node16 = (art_node16_t *)inner_node;\n             for (uint8_t i = 0; i < node16->count; ++i) {\n                 printf(\"%*s\", depth, \"\");\n                 printf(\"key: %02x \", node16->keys[i]);\n-                art_node_printf(node16->children[i], depth);\n+                art_node_printf(art, node16->children[i], depth);\n             }\n         } break;\n         case CROARING_ART_NODE48_TYPE: {\n-            art_node48_t *node48 = (art_node48_t *)node;\n+            art_node48_t *node48 = (art_node48_t *)inner_node;\n             for (int i = 0; i < 256; ++i) {\n                 if (node48->keys[i] != CROARING_ART_NODE48_EMPTY_VAL) {\n                     printf(\"%*s\", depth, \"\");\n                     printf(\"key: %02x \", i);\n                     printf(\"child: %02x \", node48->keys[i]);\n-                    art_node_printf(node48->children[node48->keys[i]], depth);\n+                    art_node_printf(art, node48->children[node48->keys[i]],\n+                                    depth);\n                 }\n             }\n         } break;\n         case CROARING_ART_NODE256_TYPE: {\n-            art_node256_t *node256 = (art_node256_t *)node;\n+            art_node256_t *node256 = (art_node256_t *)inner_node;\n             for (int i = 0; i < 256; ++i) {\n-                if (node256->children[i] != NULL) {\n+                if (node256->children[i] != CROARING_ART_NULL_REF) {\n                     printf(\"%*s\", depth, \"\");\n                     printf(\"key: %02x \", i);\n-                    art_node_printf(node256->children[i], depth);\n+                    art_node_printf(art, node256->children[i], depth);\n                 }\n             }\n         } break;\n@@ -1448,118 +1644,310 @@ static void art_node_printf(const art_node_t *node, uint8_t depth) {\n     printf(\"}\\n\");\n }\n \n-void art_insert(art_t *art, const art_key_chunk_t *key, art_val_t *val) {\n-    art_leaf_t *leaf = (art_leaf_t *)val;\n-    art_leaf_populate(leaf, key);\n-    if (art->root == NULL) {\n-        art->root = (art_node_t *)CROARING_SET_LEAF(leaf);\n+/**\n+ * Moves the node at `ref` to the earliest free index before it (if any),\n+ * returns the new ref. Assumes `art->first_free[typecode]` points to the\n+ * smallest free index.\n+ */\n+static art_ref_t art_move_node_to_shrink(art_t *art, art_ref_t ref) {\n+    uint64_t idx = art_ref_index(ref);\n+    art_typecode_t typecode = art_ref_typecode(ref);\n+    uint64_t first_free = art->first_free[typecode];\n+    assert(idx != first_free);\n+    if (idx < first_free) {\n+        return ref;\n+    }\n+    uint64_t from = idx;\n+    uint64_t to = first_free;\n+    uint64_t next_free = art_node_get_next_free(art, art_to_ref(to, typecode));\n+    memcpy(art_get_node(art, to, typecode), art_get_node(art, from, typecode),\n+           ART_NODE_SIZES[typecode]);\n+\n+    // With an integer representing the next free index, and an `x` representing\n+    // an occupied index, assume the following scenario at the start of this\n+    // function:\n+    //     nodes = [1,2,5,x,x]\n+    //     first_free = 0\n+    //\n+    // We just moved a node from index 3 to 0:\n+    //     nodes = [x,2,5,?,x]\n+    //\n+    // We need to modify the free list so that the free indices are ascending.\n+    // This can be done by traversing the list until we find a node with a\n+    // `next_free` greater than the index we copied the node from, and inserting\n+    // the new index in between. This leads to the following:\n+    //     nodes = [x,2,3,5,x]\n+    //     first_free = 1\n+    uint64_t initial_next_free = next_free;\n+    uint64_t current = next_free;\n+    while (next_free < from) {\n+        current = next_free;\n+        next_free =\n+            art_node_get_next_free(art, art_to_ref(next_free, typecode));\n+    }\n+    art_node_set_next_free(art_deref(art, ref), typecode, next_free);\n+    if (current < from) {\n+        art_node_set_next_free(art_get_node(art, current, typecode), typecode,\n+                               from);\n+    }\n+    art->first_free[typecode] =\n+        from < initial_next_free ? from : initial_next_free;\n+    return art_to_ref(to, typecode);\n+}\n+\n+/**\n+ * Sorts the free lists pointed to by art->first_free in ascending index order.\n+ */\n+static void art_sort_free_lists(art_t *art) {\n+    for (art_typecode_t type = CROARING_ART_LEAF_TYPE;\n+         type <= CROARING_ART_NODE256_TYPE; ++type) {\n+        bool *free_indices =\n+            (bool *)roaring_calloc(art->capacities[type], sizeof(bool));\n+\n+        for (uint64_t i = art->first_free[type]; i < art->capacities[type];\n+             i = art_node_get_next_free(art, art_to_ref(i, type))) {\n+            free_indices[i] = true;\n+        }\n+\n+        uint64_t first_free = art->capacities[type];\n+        for (uint64_t i = art->capacities[type]; i > 0; --i) {\n+            uint64_t index = i - 1;\n+            if (free_indices[index]) {\n+                art_node_set_next_free(art_get_node(art, index, type), type,\n+                                       first_free);\n+                first_free = index;\n+            }\n+        }\n+        art->first_free[type] = first_free;\n+        roaring_free(free_indices);\n+    }\n+}\n+\n+/**\n+ * Shrinks all node arrays to `first_free`. Assumes all indices after\n+ * `first_free` are unused.\n+ */\n+static size_t art_shrink_node_arrays(art_t *art) {\n+    size_t freed = 0;\n+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;\n+         ++t) {\n+        if (art->first_free[t] < art->capacities[t]) {\n+            uint64_t new_capacity = art->first_free[t];\n+            art->nodes[t] = roaring_realloc(art->nodes[t],\n+                                            new_capacity * ART_NODE_SIZES[t]);\n+            freed += (art->capacities[t] - new_capacity) * ART_NODE_SIZES[t];\n+            art->capacities[t] = new_capacity;\n+        }\n+    }\n+    return freed;\n+}\n+\n+/**\n+ * Traverses the ART, moving nodes to earlier free indices and modifying their\n+ * references along the way.\n+ */\n+static void art_shrink_at(art_t *art, art_ref_t ref) {\n+    if (art_is_leaf(ref)) {\n         return;\n     }\n-    art->root = art_insert_at(art->root, key, 0, leaf);\n+    switch (art_ref_typecode(ref)) {\n+        case CROARING_ART_NODE4_TYPE: {\n+            art_node4_t *node4 = (art_node4_t *)art_deref(art, ref);\n+            for (uint8_t i = 0; i < node4->count; ++i) {\n+                node4->children[i] =\n+                    art_move_node_to_shrink(art, node4->children[i]);\n+                art_shrink_at(art, node4->children[i]);\n+            }\n+        } break;\n+        case CROARING_ART_NODE16_TYPE: {\n+            art_node16_t *node16 = (art_node16_t *)art_deref(art, ref);\n+            for (uint8_t i = 0; i < node16->count; ++i) {\n+                node16->children[i] =\n+                    art_move_node_to_shrink(art, node16->children[i]);\n+                art_shrink_at(art, node16->children[i]);\n+            }\n+        } break;\n+        case CROARING_ART_NODE48_TYPE: {\n+            art_node48_t *node48 = (art_node48_t *)art_deref(art, ref);\n+            for (int i = 0; i < 256; ++i) {\n+                if (node48->keys[i] != CROARING_ART_NODE48_EMPTY_VAL) {\n+                    uint8_t idx = node48->keys[i];\n+                    node48->children[idx] =\n+                        art_move_node_to_shrink(art, node48->children[idx]);\n+                    art_shrink_at(art, node48->children[idx]);\n+                }\n+            }\n+        } break;\n+        case CROARING_ART_NODE256_TYPE: {\n+            art_node256_t *node256 = (art_node256_t *)art_deref(art, ref);\n+            for (int i = 0; i < 256; ++i) {\n+                if (node256->children[i] != CROARING_ART_NULL_REF) {\n+                    node256->children[i] =\n+                        art_move_node_to_shrink(art, node256->children[i]);\n+                    art_shrink_at(art, node256->children[i]);\n+                }\n+            }\n+        } break;\n+        default:\n+            assert(false);\n+            break;\n+    }\n }\n \n-art_val_t *art_erase(art_t *art, const art_key_chunk_t *key) {\n-    if (art->root == NULL) {\n-        return NULL;\n+void art_init_cleared(art_t *art) {\n+    art->root = CROARING_ART_NULL_REF;\n+    memset(art->first_free, 0, sizeof(art->first_free));\n+    memset(art->capacities, 0, sizeof(art->capacities));\n+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;\n+         ++t) {\n+        art->nodes[t] = NULL;\n     }\n-    art_erase_result_t result = art_erase_at(art->root, key, 0);\n-    if (result.value_erased == NULL) {\n-        return NULL;\n+}\n+\n+size_t art_shrink_to_fit(art_t *art) {\n+    if (art_is_shrunken(art)) {\n+        return 0;\n+    }\n+    if (art->root != CROARING_ART_NULL_REF) {\n+        art_sort_free_lists(art);\n+        art->root = art_move_node_to_shrink(art, art->root);\n+        art_shrink_at(art, art->root);\n+    }\n+    return art_shrink_node_arrays(art);\n+}\n+\n+bool art_is_shrunken(const art_t *art) {\n+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;\n+         ++t) {\n+        if (art->first_free[t] != art->capacities[t]) {\n+            return false;\n+        }\n+    }\n+    return true;\n+}\n+\n+art_val_t *art_insert(art_t *art, const art_key_chunk_t *key, art_val_t val) {\n+    art_ref_t leaf = art_leaf_create(art, key, val);\n+    if (art->root == CROARING_ART_NULL_REF) {\n+        art->root = leaf;\n+        return &((art_leaf_t *)art_deref(art, leaf))->val;\n+    }\n+    art->root = art_insert_at(art, art->root, key, 0, leaf);\n+    return &((art_leaf_t *)art_deref(art, leaf))->val;\n+}\n+\n+bool art_erase(art_t *art, const art_key_chunk_t *key, art_val_t *erased_val) {\n+    art_val_t erased_val_local;\n+    if (erased_val == NULL) {\n+        erased_val = &erased_val_local;\n+    }\n+    if (art->root == CROARING_ART_NULL_REF) {\n+        return false;\n+    }\n+    art_erase_result_t result = art_erase_at(art, art->root, key, 0);\n+    if (!result.erased) {\n+        return false;\n     }\n     art->root = result.rootmost_node;\n-    return result.value_erased;\n+    *erased_val = result.value_erased;\n+    return true;\n }\n \n art_val_t *art_find(const art_t *art, const art_key_chunk_t *key) {\n-    if (art->root == NULL) {\n+    if (art->root == CROARING_ART_NULL_REF) {\n         return NULL;\n     }\n-    return art_find_at(art->root, key, 0);\n+    return art_find_at(art, art->root, key, 0);\n }\n \n-bool art_is_empty(const art_t *art) { return art->root == NULL; }\n-\n-void art_free(art_t *art) {\n-    if (art->root == NULL) {\n-        return;\n-    }\n-    art_free_node(art->root);\n+bool art_is_empty(const art_t *art) {\n+    return art->root == CROARING_ART_NULL_REF;\n }\n \n-size_t art_size_in_bytes(const art_t *art) {\n-    size_t size = sizeof(art_t);\n-    if (art->root != NULL) {\n-        size += art_size_in_bytes_at(art->root);\n+void art_free(art_t *art) {\n+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;\n+         ++t) {\n+        roaring_free(art->nodes[t]);\n     }\n-    return size;\n }\n \n void art_printf(const art_t *art) {\n-    if (art->root == NULL) {\n+    if (art->root == CROARING_ART_NULL_REF) {\n         return;\n     }\n-    art_node_printf(art->root, 0);\n+    art_node_printf(art, art->root, 0);\n+}\n+\n+// Returns a reference to the current node that the iterator is positioned\n+// at.\n+static inline art_ref_t art_iterator_ref(art_iterator_t *iterator) {\n+    return iterator->frames[iterator->frame].ref;\n }\n \n // Returns the current node that the iterator is positioned at.\n static inline art_node_t *art_iterator_node(art_iterator_t *iterator) {\n-    return iterator->frames[iterator->frame].node;\n+    return art_deref(iterator->art, art_iterator_ref(iterator));\n }\n \n-// Sets the iterator key and value to the leaf's key and value. Always returns\n-// true for convenience.\n+// Sets the iterator key and value to the leaf's key and value. Always\n+// returns true for convenience.\n static inline bool art_iterator_valid_loc(art_iterator_t *iterator,\n-                                          art_leaf_t *leaf) {\n-    iterator->frames[iterator->frame].node = CROARING_SET_LEAF(leaf);\n+                                          art_ref_t leaf_ref) {\n+    iterator->frames[iterator->frame].ref = leaf_ref;\n     iterator->frames[iterator->frame].index_in_node = 0;\n+    art_leaf_t *leaf = (art_leaf_t *)art_deref(iterator->art, leaf_ref);\n     memcpy(iterator->key, leaf->key, ART_KEY_BYTES);\n-    iterator->value = (art_val_t *)leaf;\n+    iterator->value = &leaf->val;\n     return true;\n }\n \n-// Invalidates the iterator key and value. Always returns false for convenience.\n+// Invalidates the iterator key and value. Always returns false for\n+// convenience.\n static inline bool art_iterator_invalid_loc(art_iterator_t *iterator) {\n     memset(iterator->key, 0, ART_KEY_BYTES);\n     iterator->value = NULL;\n     return false;\n }\n \n-// Moves the iterator one level down in the tree, given a node at the current\n-// level and the index of the child that we're going down to.\n+// Moves the iterator one level down in the tree, given a node at the\n+// current level and the index of the child that we're going down to.\n //\n // Note: does not set the index at the new level.\n-static void art_iterator_down(art_iterator_t *iterator,\n-                              const art_inner_node_t *node,\n+static void art_iterator_down(art_iterator_t *iterator, art_ref_t ref,\n                               uint8_t index_in_node) {\n-    iterator->frames[iterator->frame].node = (art_node_t *)node;\n+    iterator->frames[iterator->frame].ref = ref;\n     iterator->frames[iterator->frame].index_in_node = index_in_node;\n     iterator->frame++;\n-    art_indexed_child_t indexed_child =\n-        art_node_child_at((art_node_t *)node, index_in_node);\n-    assert(indexed_child.child != NULL);\n-    iterator->frames[iterator->frame].node = indexed_child.child;\n+    art_inner_node_t *node = (art_inner_node_t *)art_deref(iterator->art, ref);\n+    art_indexed_child_t indexed_child = art_node_child_at(\n+        (art_node_t *)node, art_ref_typecode(ref), index_in_node);\n+    assert(indexed_child.child != CROARING_ART_NULL_REF);\n+    iterator->frames[iterator->frame].ref = indexed_child.child;\n     iterator->depth += node->prefix_size + 1;\n }\n \n-// Moves the iterator to the next/previous child of the current node. Returns\n-// the child moved to, or NULL if there is no neighboring child.\n-static art_node_t *art_iterator_neighbor_child(\n-    art_iterator_t *iterator, const art_inner_node_t *inner_node,\n-    bool forward) {\n+// Moves the iterator to the next/previous child of the current node.\n+// Returns the child moved to, or NULL if there is no neighboring child.\n+static art_ref_t art_iterator_neighbor_child(art_iterator_t *iterator,\n+                                             bool forward) {\n     art_iterator_frame_t frame = iterator->frames[iterator->frame];\n+    art_node_t *node = art_deref(iterator->art, frame.ref);\n     art_indexed_child_t indexed_child;\n     if (forward) {\n-        indexed_child = art_node_next_child(frame.node, frame.index_in_node);\n+        indexed_child = art_node_next_child(node, art_ref_typecode(frame.ref),\n+                                            frame.index_in_node);\n     } else {\n-        indexed_child = art_node_prev_child(frame.node, frame.index_in_node);\n+        indexed_child = art_node_prev_child(node, art_ref_typecode(frame.ref),\n+                                            frame.index_in_node);\n     }\n-    if (indexed_child.child != NULL) {\n-        art_iterator_down(iterator, inner_node, indexed_child.index);\n+    if (indexed_child.child != CROARING_ART_NULL_REF) {\n+        art_iterator_down(iterator, frame.ref, indexed_child.index);\n     }\n     return indexed_child.child;\n }\n \n-// Moves the iterator one level up in the tree, returns false if not possible.\n+// Moves the iterator one level up in the tree, returns false if not\n+// possible.\n static bool art_iterator_up(art_iterator_t *iterator) {\n     if (iterator->frame == 0) {\n         return false;\n@@ -1571,8 +1959,8 @@ static bool art_iterator_up(art_iterator_t *iterator) {\n     return true;\n }\n \n-// Moves the iterator one level, followed by a move to the next / previous leaf.\n-// Sets the status of the iterator.\n+// Moves the iterator one level, followed by a move to the next / previous\n+// leaf. Sets the status of the iterator.\n static bool art_iterator_up_and_move(art_iterator_t *iterator, bool forward) {\n     if (!art_iterator_up(iterator)) {\n         // We're at the root.\n@@ -1583,27 +1971,29 @@ static bool art_iterator_up_and_move(art_iterator_t *iterator, bool forward) {\n \n // Initializes the iterator at the first / last leaf of the given node.\n // Returns true for convenience.\n-static bool art_node_init_iterator(const art_node_t *node,\n-                                   art_iterator_t *iterator, bool first) {\n-    while (!art_is_leaf(node)) {\n+static bool art_node_init_iterator(art_ref_t ref, art_iterator_t *iterator,\n+                                   bool first) {\n+    while (!art_is_leaf(ref)) {\n+        art_node_t *node = art_deref(iterator->art, ref);\n         art_indexed_child_t indexed_child;\n         if (first) {\n-            indexed_child = art_node_next_child(node, -1);\n+            indexed_child =\n+                art_node_next_child(node, art_ref_typecode(ref), -1);\n         } else {\n-            indexed_child = art_node_prev_child(node, 256);\n+            indexed_child =\n+                art_node_prev_child(node, art_ref_typecode(ref), 256);\n         }\n-        art_iterator_down(iterator, (art_inner_node_t *)node,\n-                          indexed_child.index);\n-        node = indexed_child.child;\n+        art_iterator_down(iterator, ref, indexed_child.index);\n+        ref = indexed_child.child;\n     }\n     // We're at a leaf.\n-    iterator->frames[iterator->frame].node = (art_node_t *)node;\n+    iterator->frames[iterator->frame].ref = ref;\n     iterator->frames[iterator->frame].index_in_node = 0;  // Should not matter.\n-    return art_iterator_valid_loc(iterator, CROARING_CAST_LEAF(node));\n+    return art_iterator_valid_loc(iterator, ref);\n }\n \n bool art_iterator_move(art_iterator_t *iterator, bool forward) {\n-    if (art_is_leaf(art_iterator_node(iterator))) {\n+    if (art_is_leaf(art_iterator_ref(iterator))) {\n         bool went_up = art_iterator_up(iterator);\n         if (!went_up) {\n             // This leaf is the root, we're done.\n@@ -1611,67 +2001,69 @@ bool art_iterator_move(art_iterator_t *iterator, bool forward) {\n         }\n     }\n     // Advance within inner node.\n-    art_node_t *neighbor_child = art_iterator_neighbor_child(\n-        iterator, (art_inner_node_t *)art_iterator_node(iterator), forward);\n-    if (neighbor_child != NULL) {\n-        // There is another child at this level, go down to the first or last\n-        // leaf.\n+    art_ref_t neighbor_child = art_iterator_neighbor_child(iterator, forward);\n+    if (neighbor_child != CROARING_ART_NULL_REF) {\n+        // There is another child at this level, go down to the first or\n+        // last leaf.\n         return art_node_init_iterator(neighbor_child, iterator, forward);\n     }\n     // No more children at this level, go up.\n     return art_iterator_up_and_move(iterator, forward);\n }\n \n-// Assumes the iterator is positioned at a node with an equal prefix path up to\n-// the depth of the iterator.\n-static bool art_node_iterator_lower_bound(const art_node_t *node,\n+// Assumes the iterator is positioned at a node with an equal prefix path up\n+// to the depth of the iterator.\n+static bool art_node_iterator_lower_bound(art_ref_t ref,\n                                           art_iterator_t *iterator,\n                                           const art_key_chunk_t key[]) {\n-    while (!art_is_leaf(node)) {\n-        art_inner_node_t *inner_node = (art_inner_node_t *)node;\n+    while (!art_is_leaf(ref)) {\n+        art_inner_node_t *inner_node =\n+            (art_inner_node_t *)art_deref(iterator->art, ref);\n         int prefix_comparison =\n             art_compare_prefix(inner_node->prefix, 0, key, iterator->depth,\n                                inner_node->prefix_size);\n         if (prefix_comparison < 0) {\n             // Prefix so far has been equal, but we've found a smaller key.\n-            // Since we take the lower bound within each node, we can return the\n-            // next leaf.\n+            // Since we take the lower bound within each node, we can return\n+            // the next leaf.\n             return art_iterator_up_and_move(iterator, true);\n         } else if (prefix_comparison > 0) {\n-            // No key equal to the key we're looking for, return the first leaf.\n-            return art_node_init_iterator(node, iterator, true);\n+            // No key equal to the key we're looking for, return the first\n+            // leaf.\n+            return art_node_init_iterator(ref, iterator, true);\n         }\n         // Prefix is equal, move to lower bound child.\n         art_key_chunk_t key_chunk =\n             key[iterator->depth + inner_node->prefix_size];\n-        art_indexed_child_t indexed_child =\n-            art_node_lower_bound(node, key_chunk);\n-        if (indexed_child.child == NULL) {\n+        art_indexed_child_t indexed_child = art_node_lower_bound(\n+            (art_node_t *)inner_node, art_ref_typecode(ref), key_chunk);\n+        if (indexed_child.child == CROARING_ART_NULL_REF) {\n             // Only smaller keys among children.\n             return art_iterator_up_and_move(iterator, true);\n         }\n         if (indexed_child.key_chunk > key_chunk) {\n             // Only larger children, return the first larger child.\n-            art_iterator_down(iterator, inner_node, indexed_child.index);\n+            art_iterator_down(iterator, ref, indexed_child.index);\n             return art_node_init_iterator(indexed_child.child, iterator, true);\n         }\n         // We found a child with an equal prefix.\n-        art_iterator_down(iterator, inner_node, indexed_child.index);\n-        node = indexed_child.child;\n+        art_iterator_down(iterator, ref, indexed_child.index);\n+        ref = indexed_child.child;\n     }\n-    art_leaf_t *leaf = CROARING_CAST_LEAF(node);\n+    art_leaf_t *leaf = (art_leaf_t *)art_deref(iterator->art, ref);\n     if (art_compare_keys(leaf->key, key) >= 0) {\n         // Leaf has an equal or larger key.\n-        return art_iterator_valid_loc(iterator, leaf);\n+        return art_iterator_valid_loc(iterator, ref);\n     }\n-    // Leaf has an equal prefix, but the full key is smaller. Move to the next\n-    // leaf.\n+    // Leaf has an equal prefix, but the full key is smaller. Move to the\n+    // next leaf.\n     return art_iterator_up_and_move(iterator, true);\n }\n \n-art_iterator_t art_init_iterator(const art_t *art, bool first) {\n+art_iterator_t art_init_iterator(art_t *art, bool first) {\n     art_iterator_t iterator = CROARING_ZERO_INITIALIZER;\n-    if (art->root == NULL) {\n+    iterator.art = art;\n+    if (art->root == CROARING_ART_NULL_REF) {\n         return iterator;\n     }\n     art_node_init_iterator(art->root, &iterator, first);\n@@ -1689,12 +2081,12 @@ bool art_iterator_prev(art_iterator_t *iterator) {\n bool art_iterator_lower_bound(art_iterator_t *iterator,\n                               const art_key_chunk_t *key) {\n     if (iterator->value == NULL) {\n-        // We're beyond the end / start of the ART so the iterator does not have\n-        // a valid key. Start from the root.\n+        // We're beyond the end / start of the ART so the iterator does not\n+        // have a valid key. Start from the root.\n         iterator->frame = 0;\n         iterator->depth = 0;\n-        art_node_t *root = art_iterator_node(iterator);\n-        if (root == NULL) {\n+        art_ref_t root = art_iterator_ref(iterator);\n+        if (root == CROARING_ART_NULL_REF) {\n             return false;\n         }\n         return art_node_iterator_lower_bound(root, iterator, key);\n@@ -1709,7 +2101,7 @@ bool art_iterator_lower_bound(art_iterator_t *iterator,\n                 // Only smaller keys found.\n                 return art_iterator_invalid_loc(iterator);\n             } else {\n-                return art_node_init_iterator(art_iterator_node(iterator),\n+                return art_node_init_iterator(art_iterator_ref(iterator),\n                                               iterator, true);\n             }\n         }\n@@ -1722,24 +2114,26 @@ bool art_iterator_lower_bound(art_iterator_t *iterator,\n                                iterator->depth + inner_node->prefix_size);\n     }\n     if (compare_result > 0) {\n-        return art_node_init_iterator(art_iterator_node(iterator), iterator,\n+        return art_node_init_iterator(art_iterator_ref(iterator), iterator,\n                                       true);\n     }\n-    return art_node_iterator_lower_bound(art_iterator_node(iterator), iterator,\n+    return art_node_iterator_lower_bound(art_iterator_ref(iterator), iterator,\n                                          key);\n }\n \n-art_iterator_t art_lower_bound(const art_t *art, const art_key_chunk_t *key) {\n+art_iterator_t art_lower_bound(art_t *art, const art_key_chunk_t *key) {\n     art_iterator_t iterator = CROARING_ZERO_INITIALIZER;\n-    if (art->root != NULL) {\n+    iterator.art = art;\n+    if (art->root != CROARING_ART_NULL_REF) {\n         art_node_iterator_lower_bound(art->root, &iterator, key);\n     }\n     return iterator;\n }\n \n-art_iterator_t art_upper_bound(const art_t *art, const art_key_chunk_t *key) {\n+art_iterator_t art_upper_bound(art_t *art, const art_key_chunk_t *key) {\n     art_iterator_t iterator = CROARING_ZERO_INITIALIZER;\n-    if (art->root != NULL) {\n+    iterator.art = art;\n+    if (art->root != CROARING_ART_NULL_REF) {\n         if (art_node_iterator_lower_bound(art->root, &iterator, key) &&\n             art_compare_keys(iterator.key, key) == 0) {\n             art_iterator_next(&iterator);\n@@ -1748,90 +2142,100 @@ art_iterator_t art_upper_bound(const art_t *art, const art_key_chunk_t *key) {\n     return iterator;\n }\n \n-void art_iterator_insert(art_t *art, art_iterator_t *iterator,\n-                         const art_key_chunk_t *key, art_val_t *val) {\n+void art_iterator_insert(art_iterator_t *iterator, const art_key_chunk_t *key,\n+                         art_val_t val) {\n     // TODO: This can likely be faster.\n-    art_insert(art, key, val);\n-    assert(art->root != NULL);\n+    art_insert(iterator->art, key, val);\n+    assert(iterator->art->root != CROARING_ART_NULL_REF);\n     iterator->frame = 0;\n     iterator->depth = 0;\n-    art_node_iterator_lower_bound(art->root, iterator, key);\n+    art_node_iterator_lower_bound(iterator->art->root, iterator, key);\n }\n \n-// TODO: consider keeping `art_t *art` in the iterator.\n-art_val_t *art_iterator_erase(art_t *art, art_iterator_t *iterator) {\n+bool art_iterator_erase(art_iterator_t *iterator, art_val_t *erased_val) {\n+    art_val_t erased_val_local;\n+    if (erased_val == NULL) {\n+        erased_val = &erased_val_local;\n+    }\n     if (iterator->value == NULL) {\n-        return NULL;\n+        return false;\n     }\n     art_key_chunk_t initial_key[ART_KEY_BYTES];\n     memcpy(initial_key, iterator->key, ART_KEY_BYTES);\n \n-    art_val_t *value_erased = iterator->value;\n+    *erased_val = *iterator->value;\n+    // Erase the leaf.\n+    art_node_free(iterator->art, art_iterator_node(iterator),\n+                  art_ref_typecode(art_iterator_ref(iterator)));\n     bool went_up = art_iterator_up(iterator);\n     if (!went_up) {\n         // We're erasing the root.\n-        art->root = NULL;\n+        iterator->art->root = CROARING_ART_NULL_REF;\n         art_iterator_invalid_loc(iterator);\n-        return value_erased;\n+        return true;\n     }\n \n-    // Erase the leaf.\n+    // Erase the leaf in its parent.\n+    art_ref_t parent_ref = art_iterator_ref(iterator);\n     art_inner_node_t *parent_node =\n         (art_inner_node_t *)art_iterator_node(iterator);\n     art_key_chunk_t key_chunk_in_parent =\n         iterator->key[iterator->depth + parent_node->prefix_size];\n-    art_node_t *new_parent_node =\n-        art_node_erase(parent_node, key_chunk_in_parent);\n+    art_ref_t new_parent_ref =\n+        art_node_erase(iterator->art, parent_node, art_ref_typecode(parent_ref),\n+                       key_chunk_in_parent);\n \n-    if (new_parent_node != ((art_node_t *)parent_node)) {\n+    if (new_parent_ref != parent_ref) {\n         // Replace the pointer to the inner node we erased from in its\n         // parent (it may be a leaf now).\n-        iterator->frames[iterator->frame].node = new_parent_node;\n+        iterator->frames[iterator->frame].ref = new_parent_ref;\n         went_up = art_iterator_up(iterator);\n         if (went_up) {\n+            art_ref_t grandparent_ref = art_iterator_ref(iterator);\n             art_inner_node_t *grandparent_node =\n                 (art_inner_node_t *)art_iterator_node(iterator);\n             art_key_chunk_t key_chunk_in_grandparent =\n                 iterator->key[iterator->depth + grandparent_node->prefix_size];\n-            art_replace(grandparent_node, key_chunk_in_grandparent,\n-                        new_parent_node);\n+            art_replace(grandparent_node, art_ref_typecode(grandparent_ref),\n+                        key_chunk_in_grandparent, new_parent_ref);\n         } else {\n             // We were already at the rootmost node.\n-            art->root = new_parent_node;\n+            iterator->art->root = new_parent_ref;\n         }\n     }\n \n     iterator->frame = 0;\n     iterator->depth = 0;\n-    // Do a lower bound search for the initial key, which will find the first\n-    // greater key if it exists. This can likely be mildly faster if we instead\n-    // start from the current position.\n-    art_node_iterator_lower_bound(art->root, iterator, initial_key);\n-    return value_erased;\n+    // Do a lower bound search for the initial key, which will find the\n+    // first greater key if it exists. This can likely be mildly faster if\n+    // we instead start from the current position.\n+    art_node_iterator_lower_bound(iterator->art->root, iterator, initial_key);\n+    return true;\n }\n \n-static bool art_internal_validate_at(const art_node_t *node,\n+static bool art_internal_validate_at(const art_t *art, art_ref_t ref,\n                                      art_internal_validate_t validator) {\n-    if (node == NULL) {\n+    if (ref == CROARING_ART_NULL_REF) {\n         return art_validate_fail(&validator, \"node is null\");\n     }\n-    if (art_is_leaf(node)) {\n-        art_leaf_t *leaf = CROARING_CAST_LEAF(node);\n+    if (art_is_leaf(ref)) {\n+        art_leaf_t *leaf = (art_leaf_t *)art_deref(art, ref);\n         if (art_compare_prefix(leaf->key, 0, validator.current_key, 0,\n                                validator.depth) != 0) {\n-            return art_validate_fail(\n-                &validator,\n-                \"leaf key does not match its position's prefix in the tree\");\n+            return art_validate_fail(&validator,\n+                                     \"leaf key does not match its \"\n+                                     \"position's prefix in the tree\");\n         }\n         if (validator.validate_cb != NULL &&\n-            !validator.validate_cb(leaf, validator.reason)) {\n+            !validator.validate_cb(leaf->val, validator.reason,\n+                                   validator.context)) {\n             if (*validator.reason == NULL) {\n                 *validator.reason = \"leaf validation failed\";\n             }\n             return false;\n         }\n     } else {\n-        art_inner_node_t *inner_node = (art_inner_node_t *)node;\n+        art_inner_node_t *inner_node = (art_inner_node_t *)art_deref(art, ref);\n \n         if (validator.depth + inner_node->prefix_size + 1 > ART_KEY_BYTES) {\n             return art_validate_fail(&validator,\n@@ -1841,28 +2245,28 @@ static bool art_internal_validate_at(const art_node_t *node,\n                inner_node->prefix_size);\n         validator.depth += inner_node->prefix_size;\n \n-        switch (inner_node->typecode) {\n+        switch (art_ref_typecode(ref)) {\n             case CROARING_ART_NODE4_TYPE:\n-                if (!art_node4_internal_validate((art_node4_t *)inner_node,\n+                if (!art_node4_internal_validate(art, (art_node4_t *)inner_node,\n                                                  validator)) {\n                     return false;\n                 }\n                 break;\n             case CROARING_ART_NODE16_TYPE:\n-                if (!art_node16_internal_validate((art_node16_t *)inner_node,\n-                                                  validator)) {\n+                if (!art_node16_internal_validate(\n+                        art, (art_node16_t *)inner_node, validator)) {\n                     return false;\n                 }\n                 break;\n             case CROARING_ART_NODE48_TYPE:\n-                if (!art_node48_internal_validate((art_node48_t *)inner_node,\n-                                                  validator)) {\n+                if (!art_node48_internal_validate(\n+                        art, (art_node48_t *)inner_node, validator)) {\n                     return false;\n                 }\n                 break;\n             case CROARING_ART_NODE256_TYPE:\n-                if (!art_node256_internal_validate((art_node256_t *)inner_node,\n-                                                   validator)) {\n+                if (!art_node256_internal_validate(\n+                        art, (art_node256_t *)inner_node, validator)) {\n                     return false;\n                 }\n                 break;\n@@ -1874,23 +2278,143 @@ static bool art_internal_validate_at(const art_node_t *node,\n }\n \n bool art_internal_validate(const art_t *art, const char **reason,\n-                           art_validate_cb_t validate_cb) {\n+                           art_validate_cb_t validate_cb, void *context) {\n     const char *reason_local;\n     if (reason == NULL) {\n         // Always allow assigning through *reason\n         reason = &reason_local;\n     }\n     *reason = NULL;\n-    if (art->root == NULL) {\n+    if (art->root == CROARING_ART_NULL_REF) {\n         return true;\n     }\n     art_internal_validate_t validator = {\n         .reason = reason,\n         .validate_cb = validate_cb,\n+        .context = context,\n         .depth = 0,\n-        .current_key = {0},\n+        .current_key = CROARING_ZERO_INITIALIZER,\n     };\n-    return art_internal_validate_at(art->root, validator);\n+    for (art_typecode_t type = CROARING_ART_LEAF_TYPE;\n+         type <= CROARING_ART_NODE256_TYPE; ++type) {\n+        uint64_t capacity = art->capacities[type];\n+        for (uint64_t i = 0; i < capacity; ++i) {\n+            uint64_t first_free = art->first_free[type];\n+            if (first_free > capacity) {\n+                return art_validate_fail(&validator, \"first_free > capacity\");\n+            }\n+        }\n+    }\n+    return art_internal_validate_at(art, art->root, validator);\n+}\n+\n+_Static_assert(alignof(art_leaf_t) == alignof(art_node4_t),\n+               \"Serialization assumes node type alignment is equal\");\n+_Static_assert(alignof(art_leaf_t) == alignof(art_node16_t),\n+               \"Serialization assumes node type alignment is equal\");\n+_Static_assert(alignof(art_leaf_t) == alignof(art_node48_t),\n+               \"Serialization assumes node type alignment is equal\");\n+_Static_assert(alignof(art_leaf_t) == alignof(art_node256_t),\n+               \"Serialization assumes node type alignment is equal\");\n+\n+size_t art_size_in_bytes(const art_t *art) {\n+    if (!art_is_shrunken(art)) {\n+        return 0;\n+    }\n+    // Root.\n+    size_t size = sizeof(art->root);\n+    // Node counts.\n+    size += sizeof(art->capacities);\n+    // Alignment for leaves. The rest of the nodes are aligned the same way.\n+    size +=\n+        ((size + alignof(art_leaf_t) - 1) & ~(alignof(art_leaf_t) - 1)) - size;\n+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;\n+         ++t) {\n+        size += art->capacities[t] * ART_NODE_SIZES[t];\n+    }\n+    return size;\n+}\n+\n+size_t art_serialize(const art_t *art, char *buf) {\n+    if (buf == NULL) {\n+        return 0;\n+    }\n+    if (!art_is_shrunken(art)) {\n+        return 0;\n+    }\n+    const char *initial_buf = buf;\n+\n+    // Root.\n+    memcpy(buf, &art->root, sizeof(art->root));\n+    buf += sizeof(art->root);\n+\n+    // Node counts.\n+    memcpy(buf, art->capacities, sizeof(art->capacities));\n+    buf += sizeof(art->capacities);\n+\n+    // Alignment for leaves. The rest of the nodes are aligned the same way.\n+    size_t align_bytes =\n+        CROARING_ART_ALIGN_SIZE_RELATIVE(buf, initial_buf, alignof(art_leaf_t));\n+    memset(buf, 0, align_bytes);\n+    buf += align_bytes;\n+\n+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;\n+         ++t) {\n+        if (art->capacities[t] > 0) {\n+            size_t size = art->capacities[t] * ART_NODE_SIZES[t];\n+            memcpy(buf, art->nodes[t], size);\n+            buf += size;\n+        }\n+    }\n+\n+    return buf - initial_buf;\n+}\n+\n+size_t art_frozen_view(const char *buf, size_t maxbytes, art_t *art) {\n+    if (buf == NULL || art == NULL) {\n+        return 0;\n+    }\n+    const char *initial_buf = buf;\n+    art_init_cleared(art);\n+\n+    if (maxbytes < sizeof(art->root)) {\n+        return 0;\n+    }\n+    memcpy(&art->root, buf, sizeof(art->root));\n+    buf += sizeof(art->root);\n+    maxbytes -= sizeof(art->root);\n+\n+    if (maxbytes < sizeof(art->capacities)) {\n+        return 0;\n+    }\n+    _Static_assert(sizeof(art->first_free) == sizeof(art->capacities),\n+                   \"first_free is read from capacities\");\n+    memcpy(art->first_free, buf, sizeof(art->capacities));\n+    memcpy(art->capacities, buf, sizeof(art->capacities));\n+    buf += sizeof(art->capacities);\n+    maxbytes -= sizeof(art->capacities);\n+\n+    // Alignment for leaves. The rest of the nodes are aligned the same way.\n+    const char *before_align = buf;\n+    buf = CROARING_ART_ALIGN_BUF(buf, alignof(art_leaf_t));\n+    if (maxbytes < (size_t)(buf - before_align)) {\n+        return 0;\n+    }\n+    maxbytes -= buf - before_align;\n+\n+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;\n+         ++t) {\n+        if (art->capacities[t] > 0) {\n+            size_t size = art->capacities[t] * ART_NODE_SIZES[t];\n+            if (maxbytes < size) {\n+                return 0;\n+            }\n+            art->nodes[t] = (char *)buf;\n+            buf += size;\n+            maxbytes -= size;\n+        }\n+    }\n+    return buf - initial_buf;\n }\n \n #ifdef __cplusplus\ndiff --git a/contrib/libs/croaring/src/containers/bitset.c b/contrib/libs/croaring/src/containers/bitset.c\nindex 7a38d072b360..b66f8807b0d8 100644\n--- a/contrib/libs/croaring/src/containers/bitset.c\n+++ b/contrib/libs/croaring/src/containers/bitset.c\n@@ -2,9 +2,6 @@\n  * bitset.c\n  *\n  */\n-#ifndef _POSIX_C_SOURCE\n-#define _POSIX_C_SOURCE 200809L\n-#endif\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/contrib/libs/croaring/src/roaring64.c b/contrib/libs/croaring/src/roaring64.c\nindex 208c198de7f8..bc65e8b0e5b9 100644\n--- a/contrib/libs/croaring/src/roaring64.c\n+++ b/contrib/libs/croaring/src/roaring64.c\n@@ -1,4 +1,5 @@\n #include <assert.h>\n+#include <stdalign.h>\n #include <stdarg.h>\n #include <stdint.h>\n #include <string.h>\n@@ -8,11 +9,20 @@\n #include <roaring/roaring64.h>\n \n // For serialization / deserialization\n+#include <roaring/containers/array.h>\n+#include <roaring/containers/bitset.h>\n+#include <roaring/containers/run.h>\n #include <roaring/roaring.h>\n #include <roaring/roaring_array.h>\n // containers.h last to avoid conflict with ROARING_CONTAINER_T.\n #include <roaring/containers/containers.h>\n \n+#define CROARING_ALIGN_BUF(buf, alignment)          \\\n+    (char *)(((uintptr_t)(buf) + ((alignment)-1)) & \\\n+             (ptrdiff_t)(~((alignment)-1)))\n+\n+#define CROARING_BITSET_ALIGNMENT 64\n+\n #ifdef __cplusplus\n using namespace ::roaring::internal;\n \n@@ -27,22 +37,19 @@ namespace api {\n typedef struct roaring64_bitmap_s {\n     art_t art;\n     uint8_t flags;\n+    uint64_t first_free;\n+    uint64_t capacity;\n+    container_t **containers;\n } roaring64_bitmap_t;\n \n // Leaf type of the ART used to keep the high 48 bits of each entry.\n-typedef struct roaring64_leaf_s {\n-    art_val_t _pad;\n-    uint8_t typecode;\n-    container_t *container;\n-} roaring64_leaf_t;\n-\n-// Alias to make it easier to work with, since it's an internal-only type\n-// anyway.\n-typedef struct roaring64_leaf_s leaf_t;\n+// Low 8 bits: typecode\n+// High 56 bits: container index\n+typedef roaring64_leaf_t leaf_t;\n \n // Iterator struct to hold iteration state.\n typedef struct roaring64_iterator_s {\n-    const roaring64_bitmap_t *parent;\n+    const roaring64_bitmap_t *r;\n     art_iterator_t art_it;\n     roaring_container_iterator_t container_it;\n     uint64_t high48;  // Key that art_it points to.\n@@ -57,6 +64,10 @@ typedef struct roaring64_iterator_s {\n     bool saturated_forward;\n } roaring64_iterator_t;\n \n+static inline bool is_frozen64(const roaring64_bitmap_t *r) {\n+    return r->flags & ROARING_FLAG_FROZEN;\n+}\n+\n // Splits the given uint64 key into high 48 bit and low 16 bit components.\n // Expects high48_out to be of length ART_KEY_BYTES.\n static inline uint16_t split_key(uint64_t key, uint8_t high48_out[]) {\n@@ -77,23 +88,95 @@ static inline uint64_t minimum(uint64_t a, uint64_t b) {\n     return (a < b) ? a : b;\n }\n \n-static inline leaf_t *create_leaf(container_t *container, uint8_t typecode) {\n-    leaf_t *leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));\n-    leaf->container = container;\n-    leaf->typecode = typecode;\n-    return leaf;\n+static inline leaf_t create_leaf(uint64_t container_index, uint8_t typecode) {\n+    return (container_index << 8) | typecode;\n }\n \n-static inline leaf_t *copy_leaf_container(const leaf_t *leaf) {\n-    leaf_t *result_leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));\n-    result_leaf->typecode = leaf->typecode;\n-    // get_copy_of_container modifies the typecode passed in.\n-    result_leaf->container = get_copy_of_container(\n-        leaf->container, &result_leaf->typecode, /*copy_on_write=*/false);\n-    return result_leaf;\n+static inline uint8_t get_typecode(leaf_t leaf) { return (uint8_t)leaf; }\n+\n+static inline uint64_t get_index(leaf_t leaf) { return leaf >> 8; }\n+\n+static inline container_t *get_container(const roaring64_bitmap_t *r,\n+                                         leaf_t leaf) {\n+    return r->containers[get_index(leaf)];\n }\n \n-static inline void free_leaf(leaf_t *leaf) { roaring_free(leaf); }\n+// Replaces the container of `leaf` with the given container. Returns the\n+// modified leaf for convenience.\n+static inline leaf_t replace_container(roaring64_bitmap_t *r, leaf_t *leaf,\n+                                       container_t *container,\n+                                       uint8_t typecode) {\n+    uint64_t index = get_index(*leaf);\n+    r->containers[index] = container;\n+    *leaf = create_leaf(index, typecode);\n+    return *leaf;\n+}\n+\n+/**\n+ * Extends the array of container pointers.\n+ */\n+static void extend_containers(roaring64_bitmap_t *r) {\n+    uint64_t size = r->first_free;\n+    if (size < r->capacity) {\n+        return;\n+    }\n+    uint64_t new_capacity;\n+    if (r->capacity == 0) {\n+        new_capacity = 2;\n+    } else if (r->capacity < 1024) {\n+        new_capacity = 2 * r->capacity;\n+    } else {\n+        new_capacity = 5 * r->capacity / 4;\n+    }\n+    uint64_t increase = new_capacity - r->capacity;\n+    r->containers =\n+        roaring_realloc(r->containers, new_capacity * sizeof(container_t *));\n+    memset(r->containers + r->capacity, 0, increase * sizeof(container_t *));\n+    r->capacity = new_capacity;\n+}\n+\n+static uint64_t next_free_container_idx(const roaring64_bitmap_t *r) {\n+    for (uint64_t i = r->first_free + 1; i < r->capacity; ++i) {\n+        if (r->containers[i] == NULL) {\n+            return i;\n+        }\n+    }\n+    return r->capacity;\n+}\n+\n+static uint64_t allocate_index(roaring64_bitmap_t *r) {\n+    uint64_t first_free = r->first_free;\n+    if (first_free == r->capacity) {\n+        extend_containers(r);\n+    }\n+    r->first_free = next_free_container_idx(r);\n+    return first_free;\n+}\n+\n+static leaf_t add_container(roaring64_bitmap_t *r, container_t *container,\n+                            uint8_t typecode) {\n+    uint64_t index = allocate_index(r);\n+    r->containers[index] = container;\n+    return create_leaf(index, typecode);\n+}\n+\n+static void remove_container(roaring64_bitmap_t *r, leaf_t leaf) {\n+    uint64_t index = get_index(leaf);\n+    r->containers[index] = NULL;\n+    if (index < r->first_free) {\n+        r->first_free = index;\n+    }\n+}\n+\n+// Copies the container referenced by `leaf` from `r1` to `r2`.\n+static inline leaf_t copy_leaf_container(const roaring64_bitmap_t *r1,\n+                                         roaring64_bitmap_t *r2, leaf_t leaf) {\n+    uint8_t typecode = get_typecode(leaf);\n+    // get_copy_of_container modifies the typecode passed in.\n+    container_t *container = get_copy_of_container(\n+        get_container(r1, leaf), &typecode, /*copy_on_write=*/false);\n+    return add_container(r2, container, typecode);\n+}\n \n static inline int compare_high48(art_key_chunk_t key1[],\n                                  art_key_chunk_t key2[]) {\n@@ -103,10 +186,10 @@ static inline int compare_high48(art_key_chunk_t key1[],\n static inline bool roaring64_iterator_init_at_leaf_first(\n     roaring64_iterator_t *it) {\n     it->high48 = combine_key(it->art_it.key, 0);\n-    leaf_t *leaf = (leaf_t *)it->art_it.value;\n+    leaf_t leaf = (leaf_t)*it->art_it.value;\n     uint16_t low16 = 0;\n-    it->container_it =\n-        container_init_iterator(leaf->container, leaf->typecode, &low16);\n+    it->container_it = container_init_iterator(get_container(it->r, leaf),\n+                                               get_typecode(leaf), &low16);\n     it->value = it->high48 | low16;\n     return (it->has_value = true);\n }\n@@ -114,18 +197,18 @@ static inline bool roaring64_iterator_init_at_leaf_first(\n static inline bool roaring64_iterator_init_at_leaf_last(\n     roaring64_iterator_t *it) {\n     it->high48 = combine_key(it->art_it.key, 0);\n-    leaf_t *leaf = (leaf_t *)it->art_it.value;\n+    leaf_t leaf = (leaf_t)*it->art_it.value;\n     uint16_t low16 = 0;\n-    it->container_it =\n-        container_init_iterator_last(leaf->container, leaf->typecode, &low16);\n+    it->container_it = container_init_iterator_last(get_container(it->r, leaf),\n+                                                    get_typecode(leaf), &low16);\n     it->value = it->high48 | low16;\n     return (it->has_value = true);\n }\n \n static inline roaring64_iterator_t *roaring64_iterator_init_at(\n     const roaring64_bitmap_t *r, roaring64_iterator_t *it, bool first) {\n-    it->parent = r;\n-    it->art_it = art_init_iterator(&r->art, first);\n+    it->r = r;\n+    it->art_it = art_init_iterator((art_t *)&r->art, first);\n     it->has_value = it->art_it.value != NULL;\n     if (it->has_value) {\n         if (first) {\n@@ -142,8 +225,11 @@ static inline roaring64_iterator_t *roaring64_iterator_init_at(\n roaring64_bitmap_t *roaring64_bitmap_create(void) {\n     roaring64_bitmap_t *r =\n         (roaring64_bitmap_t *)roaring_malloc(sizeof(roaring64_bitmap_t));\n-    r->art.root = NULL;\n+    art_init_cleared(&r->art);\n     r->flags = 0;\n+    r->capacity = 0;\n+    r->first_free = 0;\n+    r->containers = NULL;\n     return r;\n }\n \n@@ -153,26 +239,35 @@ void roaring64_bitmap_free(roaring64_bitmap_t *r) {\n     }\n     art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n     while (it.value != NULL) {\n-        leaf_t *leaf = (leaf_t *)it.value;\n-        container_free(leaf->container, leaf->typecode);\n-        free_leaf(leaf);\n+        leaf_t leaf = (leaf_t)*it.value;\n+        if (is_frozen64(r)) {\n+            // Only free the container itself, not the buffer-backed contents\n+            // within.\n+            roaring_free(get_container(r, leaf));\n+        } else {\n+            container_free(get_container(r, leaf), get_typecode(leaf));\n+        }\n         art_iterator_next(&it);\n     }\n-    art_free(&r->art);\n+    if (!is_frozen64(r)) {\n+        art_free(&r->art);\n+    }\n+    roaring_free(r->containers);\n     roaring_free(r);\n }\n \n roaring64_bitmap_t *roaring64_bitmap_copy(const roaring64_bitmap_t *r) {\n     roaring64_bitmap_t *result = roaring64_bitmap_create();\n \n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n     while (it.value != NULL) {\n-        leaf_t *leaf = (leaf_t *)it.value;\n-        uint8_t result_typecode = leaf->typecode;\n+        leaf_t leaf = (leaf_t)*it.value;\n+        uint8_t result_typecode = get_typecode(leaf);\n         container_t *result_container = get_copy_of_container(\n-            leaf->container, &result_typecode, /*copy_on_write=*/false);\n-        leaf_t *result_leaf = create_leaf(result_container, result_typecode);\n-        art_insert(&result->art, it.key, (art_val_t *)result_leaf);\n+            get_container(r, leaf), &result_typecode, /*copy_on_write=*/false);\n+        leaf_t result_leaf =\n+            add_container(result, result_container, result_typecode);\n+        art_insert(&result->art, it.key, (art_val_t)result_leaf);\n         art_iterator_next(&it);\n     }\n     return result;\n@@ -199,8 +294,8 @@ static void move_from_roaring32_offset(roaring64_bitmap_t *dst,\n         uint8_t high48[ART_KEY_BYTES];\n         uint64_t high48_bits = key_base | ((uint64_t)key << 16);\n         split_key(high48_bits, high48);\n-        leaf_t *leaf = create_leaf(container, typecode);\n-        art_insert(&dst->art, high48, (art_val_t *)leaf);\n+        leaf_t leaf = add_container(dst, container, typecode);\n+        art_insert(&dst->art, high48, (art_val_t)leaf);\n     }\n     // We stole all the containers, so leave behind a size of zero\n     src->high_low_container.size = 0;\n@@ -242,8 +337,8 @@ roaring64_bitmap_t *roaring64_bitmap_from_range(uint64_t min, uint64_t max,\n \n         uint8_t high48[ART_KEY_BYTES];\n         split_key(min, high48);\n-        leaf_t *leaf = create_leaf(container, typecode);\n-        art_insert(&r->art, high48, (art_val_t *)leaf);\n+        leaf_t leaf = add_container(r, container, typecode);\n+        art_insert(&r->art, high48, (art_val_t)leaf);\n \n         uint64_t gap = container_max - container_min + step - 1;\n         uint64_t increment = gap - (gap % step);\n@@ -267,13 +362,14 @@ static inline leaf_t *containerptr_roaring64_bitmap_add(roaring64_bitmap_t *r,\n                                                         uint16_t low16,\n                                                         leaf_t *leaf) {\n     if (leaf != NULL) {\n+        uint8_t typecode = get_typecode(*leaf);\n+        container_t *container = get_container(r, *leaf);\n         uint8_t typecode2;\n         container_t *container2 =\n-            container_add(leaf->container, low16, leaf->typecode, &typecode2);\n-        if (container2 != leaf->container) {\n-            container_free(leaf->container, leaf->typecode);\n-            leaf->container = container2;\n-            leaf->typecode = typecode2;\n+            container_add(container, low16, typecode, &typecode2);\n+        if (container2 != container) {\n+            container_free(container, typecode);\n+            replace_container(r, leaf, container2, typecode2);\n         }\n         return leaf;\n     } else {\n@@ -282,9 +378,8 @@ static inline leaf_t *containerptr_roaring64_bitmap_add(roaring64_bitmap_t *r,\n         container_t *container =\n             container_add(ac, low16, ARRAY_CONTAINER_TYPE, &typecode);\n         assert(ac == container);\n-        leaf = create_leaf(container, typecode);\n-        art_insert(&r->art, high48, (art_val_t *)leaf);\n-        return leaf;\n+        leaf_t new_leaf = add_container(r, container, typecode);\n+        return (leaf_t *)art_insert(&r->art, high48, (art_val_t)new_leaf);\n     }\n }\n \n@@ -302,12 +397,12 @@ bool roaring64_bitmap_add_checked(roaring64_bitmap_t *r, uint64_t val) {\n \n     int old_cardinality = 0;\n     if (leaf != NULL) {\n-        old_cardinality =\n-            container_get_cardinality(leaf->container, leaf->typecode);\n+        old_cardinality = container_get_cardinality(get_container(r, *leaf),\n+                                                    get_typecode(*leaf));\n     }\n     leaf = containerptr_roaring64_bitmap_add(r, high48, low16, leaf);\n     int new_cardinality =\n-        container_get_cardinality(leaf->container, leaf->typecode);\n+        container_get_cardinality(get_container(r, *leaf), get_typecode(*leaf));\n     return old_cardinality != new_cardinality;\n }\n \n@@ -316,22 +411,22 @@ void roaring64_bitmap_add_bulk(roaring64_bitmap_t *r,\n                                uint64_t val) {\n     uint8_t high48[ART_KEY_BYTES];\n     uint16_t low16 = split_key(val, high48);\n-    if (context->leaf != NULL &&\n-        compare_high48(context->high_bytes, high48) == 0) {\n+    leaf_t *leaf = context->leaf;\n+    if (leaf != NULL && compare_high48(context->high_bytes, high48) == 0) {\n         // We're at a container with the correct high bits.\n+        uint8_t typecode1 = get_typecode(*leaf);\n+        container_t *container1 = get_container(r, *leaf);\n         uint8_t typecode2;\n         container_t *container2 =\n-            container_add(context->leaf->container, low16,\n-                          context->leaf->typecode, &typecode2);\n-        if (container2 != context->leaf->container) {\n-            container_free(context->leaf->container, context->leaf->typecode);\n-            context->leaf->container = container2;\n-            context->leaf->typecode = typecode2;\n+            container_add(container1, low16, typecode1, &typecode2);\n+        if (container2 != container1) {\n+            container_free(container1, typecode1);\n+            replace_container(r, leaf, container2, typecode2);\n         }\n     } else {\n         // We're not positioned anywhere yet or the high bits of the key\n         // differ.\n-        leaf_t *leaf = (leaf_t *)art_find(&r->art, high48);\n+        leaf = (leaf_t *)art_find(&r->art, high48);\n         context->leaf =\n             containerptr_roaring64_bitmap_add(r, high48, low16, leaf);\n         memcpy(context->high_bytes, high48, ART_KEY_BYTES);\n@@ -351,17 +446,19 @@ void roaring64_bitmap_add_many(roaring64_bitmap_t *r, size_t n_args,\n     }\n }\n \n-static inline void add_range_closed_at(art_t *art, uint8_t *high48,\n-                                       uint16_t min, uint16_t max) {\n+static inline void add_range_closed_at(roaring64_bitmap_t *r, art_t *art,\n+                                       uint8_t *high48, uint16_t min,\n+                                       uint16_t max) {\n     leaf_t *leaf = (leaf_t *)art_find(art, high48);\n     if (leaf != NULL) {\n+        uint8_t typecode1 = get_typecode(*leaf);\n+        container_t *container1 = get_container(r, *leaf);\n         uint8_t typecode2;\n-        container_t *container2 = container_add_range(\n-            leaf->container, leaf->typecode, min, max, &typecode2);\n-        if (container2 != leaf->container) {\n-            container_free(leaf->container, leaf->typecode);\n-            leaf->container = container2;\n-            leaf->typecode = typecode2;\n+        container_t *container2 =\n+            container_add_range(container1, typecode1, min, max, &typecode2);\n+        if (container2 != container1) {\n+            container_free(container1, typecode1);\n+            replace_container(r, leaf, container2, typecode2);\n         }\n         return;\n     }\n@@ -369,8 +466,8 @@ static inline void add_range_closed_at(art_t *art, uint8_t *high48,\n     // container_add_range is inclusive, but `container_range_of_ones` is\n     // exclusive.\n     container_t *container = container_range_of_ones(min, max + 1, &typecode);\n-    leaf = create_leaf(container, typecode);\n-    art_insert(art, high48, (art_val_t *)leaf);\n+    leaf_t new_leaf = add_container(r, container, typecode);\n+    art_insert(art, high48, (art_val_t)new_leaf);\n }\n \n void roaring64_bitmap_add_range(roaring64_bitmap_t *r, uint64_t min,\n@@ -394,22 +491,22 @@ void roaring64_bitmap_add_range_closed(roaring64_bitmap_t *r, uint64_t min,\n     uint16_t max_low16 = split_key(max, max_high48);\n     if (compare_high48(min_high48, max_high48) == 0) {\n         // Only populate range within one container.\n-        add_range_closed_at(art, min_high48, min_low16, max_low16);\n+        add_range_closed_at(r, art, min_high48, min_low16, max_low16);\n         return;\n     }\n \n     // Populate a range across containers. Fill intermediate containers\n     // entirely.\n-    add_range_closed_at(art, min_high48, min_low16, 0xffff);\n+    add_range_closed_at(r, art, min_high48, min_low16, 0xffff);\n     uint64_t min_high_bits = min >> 16;\n     uint64_t max_high_bits = max >> 16;\n     for (uint64_t current = min_high_bits + 1; current < max_high_bits;\n          ++current) {\n         uint8_t current_high48[ART_KEY_BYTES];\n         split_key(current << 16, current_high48);\n-        add_range_closed_at(art, current_high48, 0, 0xffff);\n+        add_range_closed_at(r, art, current_high48, 0, 0xffff);\n     }\n-    add_range_closed_at(art, max_high48, 0, max_low16);\n+    add_range_closed_at(r, art, max_high48, 0, max_low16);\n }\n \n bool roaring64_bitmap_contains(const roaring64_bitmap_t *r, uint64_t val) {\n@@ -417,7 +514,8 @@ bool roaring64_bitmap_contains(const roaring64_bitmap_t *r, uint64_t val) {\n     uint16_t low16 = split_key(val, high48);\n     leaf_t *leaf = (leaf_t *)art_find(&r->art, high48);\n     if (leaf != NULL) {\n-        return container_contains(leaf->container, low16, leaf->typecode);\n+        return container_contains(get_container(r, *leaf), low16,\n+                                  get_typecode(*leaf));\n     }\n     return false;\n }\n@@ -434,7 +532,7 @@ bool roaring64_bitmap_contains_range(const roaring64_bitmap_t *r, uint64_t min,\n     uint16_t max_low16 = split_key(max, max_high48);\n     uint64_t max_high48_bits = (max - 1) & 0xFFFFFFFFFFFF0000;  // Inclusive\n \n-    art_iterator_t it = art_lower_bound(&r->art, min_high48);\n+    art_iterator_t it = art_lower_bound((art_t *)&r->art, min_high48);\n     if (it.value == NULL || combine_key(it.key, 0) > min) {\n         return false;\n     }\n@@ -451,7 +549,7 @@ bool roaring64_bitmap_contains_range(const roaring64_bitmap_t *r, uint64_t min,\n             return false;\n         }\n \n-        leaf_t *leaf = (leaf_t *)it.value;\n+        leaf_t leaf = (leaf_t)*it.value;\n         uint32_t container_min = 0;\n         if (compare_high48(it.key, min_high48) == 0) {\n             container_min = min_low16;\n@@ -464,11 +562,13 @@ bool roaring64_bitmap_contains_range(const roaring64_bitmap_t *r, uint64_t min,\n         // For the first and last containers we use container_contains_range,\n         // for the intermediate containers we can use container_is_full.\n         if (container_min == 0 && container_max == 0xFFFF + 1) {\n-            if (!container_is_full(leaf->container, leaf->typecode)) {\n+            if (!container_is_full(get_container(r, leaf),\n+                                   get_typecode(leaf))) {\n                 return false;\n             }\n-        } else if (!container_contains_range(leaf->container, container_min,\n-                                             container_max, leaf->typecode)) {\n+        } else if (!container_contains_range(get_container(r, leaf),\n+                                             container_min, container_max,\n+                                             get_typecode(leaf))) {\n             return false;\n         }\n         prev_high48_bits = current_high48_bits;\n@@ -494,24 +594,24 @@ bool roaring64_bitmap_contains_bulk(const roaring64_bitmap_t *r,\n         context->leaf = leaf;\n         memcpy(context->high_bytes, high48, ART_KEY_BYTES);\n     }\n-    return container_contains(context->leaf->container, low16,\n-                              context->leaf->typecode);\n+    return container_contains(get_container(r, *context->leaf), low16,\n+                              get_typecode(*context->leaf));\n }\n \n bool roaring64_bitmap_select(const roaring64_bitmap_t *r, uint64_t rank,\n                              uint64_t *element) {\n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n     uint64_t start_rank = 0;\n     while (it.value != NULL) {\n-        leaf_t *leaf = (leaf_t *)it.value;\n-        uint64_t cardinality =\n-            container_get_cardinality(leaf->container, leaf->typecode);\n+        leaf_t leaf = (leaf_t)*it.value;\n+        uint64_t cardinality = container_get_cardinality(get_container(r, leaf),\n+                                                         get_typecode(leaf));\n         if (start_rank + cardinality > rank) {\n             uint32_t uint32_start = 0;\n             uint32_t uint32_rank = rank - start_rank;\n             uint32_t uint32_element = 0;\n-            if (container_select(leaf->container, leaf->typecode, &uint32_start,\n-                                 uint32_rank, &uint32_element)) {\n+            if (container_select(get_container(r, leaf), get_typecode(leaf),\n+                                 &uint32_start, uint32_rank, &uint32_element)) {\n                 *element = combine_key(it.key, (uint16_t)uint32_element);\n                 return true;\n             }\n@@ -527,16 +627,17 @@ uint64_t roaring64_bitmap_rank(const roaring64_bitmap_t *r, uint64_t val) {\n     uint8_t high48[ART_KEY_BYTES];\n     uint16_t low16 = split_key(val, high48);\n \n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n     uint64_t rank = 0;\n     while (it.value != NULL) {\n-        leaf_t *leaf = (leaf_t *)it.value;\n+        leaf_t leaf = (leaf_t)*it.value;\n         int compare_result = compare_high48(it.key, high48);\n         if (compare_result < 0) {\n-            rank += container_get_cardinality(leaf->container, leaf->typecode);\n+            rank += container_get_cardinality(get_container(r, leaf),\n+                                              get_typecode(leaf));\n         } else if (compare_result == 0) {\n-            return rank +\n-                   container_rank(leaf->container, leaf->typecode, low16);\n+            return rank + container_rank(get_container(r, leaf),\n+                                         get_typecode(leaf), low16);\n         } else {\n             return rank;\n         }\n@@ -550,16 +651,17 @@ bool roaring64_bitmap_get_index(const roaring64_bitmap_t *r, uint64_t val,\n     uint8_t high48[ART_KEY_BYTES];\n     uint16_t low16 = split_key(val, high48);\n \n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n     uint64_t index = 0;\n     while (it.value != NULL) {\n-        leaf_t *leaf = (leaf_t *)it.value;\n+        leaf_t leaf = (leaf_t)*it.value;\n         int compare_result = compare_high48(it.key, high48);\n         if (compare_result < 0) {\n-            index += container_get_cardinality(leaf->container, leaf->typecode);\n+            index += container_get_cardinality(get_container(r, leaf),\n+                                               get_typecode(leaf));\n         } else if (compare_result == 0) {\n-            int index16 =\n-                container_get_index(leaf->container, leaf->typecode, low16);\n+            int index16 = container_get_index(get_container(r, leaf),\n+                                              get_typecode(leaf), low16);\n             if (index16 < 0) {\n                 return false;\n             }\n@@ -573,31 +675,31 @@ bool roaring64_bitmap_get_index(const roaring64_bitmap_t *r, uint64_t val,\n     return false;\n }\n \n-static inline leaf_t *containerptr_roaring64_bitmap_remove(\n-    roaring64_bitmap_t *r, uint8_t *high48, uint16_t low16, leaf_t *leaf) {\n+// Returns true if a container was removed.\n+static inline bool containerptr_roaring64_bitmap_remove(roaring64_bitmap_t *r,\n+                                                        uint8_t *high48,\n+                                                        uint16_t low16,\n+                                                        leaf_t *leaf) {\n     if (leaf == NULL) {\n-        return NULL;\n+        return false;\n     }\n \n-    container_t *container = leaf->container;\n-    uint8_t typecode = leaf->typecode;\n+    uint8_t typecode = get_typecode(*leaf);\n+    container_t *container = get_container(r, *leaf);\n     uint8_t typecode2;\n     container_t *container2 =\n         container_remove(container, low16, typecode, &typecode2);\n     if (container2 != container) {\n         container_free(container, typecode);\n-        leaf->container = container2;\n-        leaf->typecode = typecode2;\n+        replace_container(r, leaf, container2, typecode2);\n     }\n     if (!container_nonzero_cardinality(container2, typecode2)) {\n         container_free(container2, typecode2);\n-        leaf = (leaf_t *)art_erase(&r->art, high48);\n-        if (leaf != NULL) {\n-            free_leaf(leaf);\n-        }\n-        return NULL;\n+        bool erased = art_erase(&r->art, high48, (art_val_t *)leaf);\n+        assert(erased);\n+        return true;\n     }\n-    return leaf;\n+    return false;\n }\n \n void roaring64_bitmap_remove(roaring64_bitmap_t *r, uint64_t val) {\n@@ -619,13 +721,12 @@ bool roaring64_bitmap_remove_checked(roaring64_bitmap_t *r, uint64_t val) {\n         return false;\n     }\n     int old_cardinality =\n-        container_get_cardinality(leaf->container, leaf->typecode);\n-    leaf = containerptr_roaring64_bitmap_remove(r, high48, low16, leaf);\n-    if (leaf == NULL) {\n+        container_get_cardinality(get_container(r, *leaf), get_typecode(*leaf));\n+    if (containerptr_roaring64_bitmap_remove(r, high48, low16, leaf)) {\n         return true;\n     }\n     int new_cardinality =\n-        container_get_cardinality(leaf->container, leaf->typecode);\n+        container_get_cardinality(get_container(r, *leaf), get_typecode(*leaf));\n     return new_cardinality != old_cardinality;\n }\n \n@@ -638,26 +739,28 @@ void roaring64_bitmap_remove_bulk(roaring64_bitmap_t *r,\n     if (context->leaf != NULL &&\n         compare_high48(context->high_bytes, high48) == 0) {\n         // We're at a container with the correct high bits.\n+        uint8_t typecode = get_typecode(*context->leaf);\n+        container_t *container = get_container(r, *context->leaf);\n         uint8_t typecode2;\n         container_t *container2 =\n-            container_remove(context->leaf->container, low16,\n-                             context->leaf->typecode, &typecode2);\n-        if (container2 != context->leaf->container) {\n-            container_free(context->leaf->container, context->leaf->typecode);\n-            context->leaf->container = container2;\n-            context->leaf->typecode = typecode2;\n+            container_remove(container, low16, typecode, &typecode2);\n+        if (container2 != container) {\n+            container_free(container, typecode);\n+            replace_container(r, context->leaf, container2, typecode2);\n         }\n         if (!container_nonzero_cardinality(container2, typecode2)) {\n-            leaf_t *leaf = (leaf_t *)art_erase(art, high48);\n             container_free(container2, typecode2);\n-            free_leaf(leaf);\n+            leaf_t leaf;\n+            bool erased = art_erase(art, high48, (art_val_t *)&leaf);\n+            assert(erased);\n+            remove_container(r, leaf);\n         }\n     } else {\n         // We're not positioned anywhere yet or the high bits of the key\n         // differ.\n         leaf_t *leaf = (leaf_t *)art_find(art, high48);\n-        context->leaf =\n-            containerptr_roaring64_bitmap_remove(r, high48, low16, leaf);\n+        containerptr_roaring64_bitmap_remove(r, high48, low16, leaf);\n+        context->leaf = leaf;\n         memcpy(context->high_bytes, high48, ART_KEY_BYTES);\n     }\n }\n@@ -675,23 +778,26 @@ void roaring64_bitmap_remove_many(roaring64_bitmap_t *r, size_t n_args,\n     }\n }\n \n-static inline void remove_range_closed_at(art_t *art, uint8_t *high48,\n-                                          uint16_t min, uint16_t max) {\n+static inline void remove_range_closed_at(roaring64_bitmap_t *r, art_t *art,\n+                                          uint8_t *high48, uint16_t min,\n+                                          uint16_t max) {\n     leaf_t *leaf = (leaf_t *)art_find(art, high48);\n     if (leaf == NULL) {\n         return;\n     }\n+    uint8_t typecode = get_typecode(*leaf);\n+    container_t *container = get_container(r, *leaf);\n     uint8_t typecode2;\n-    container_t *container2 = container_remove_range(\n-        leaf->container, leaf->typecode, min, max, &typecode2);\n-    if (container2 != leaf->container) {\n-        container_free(leaf->container, leaf->typecode);\n+    container_t *container2 =\n+        container_remove_range(container, typecode, min, max, &typecode2);\n+    if (container2 != container) {\n+        container_free(container, typecode);\n         if (container2 != NULL) {\n-            leaf->container = container2;\n-            leaf->typecode = typecode2;\n+            replace_container(r, leaf, container2, typecode2);\n         } else {\n-            art_erase(art, high48);\n-            free_leaf(leaf);\n+            bool erased = art_erase(art, high48, NULL);\n+            assert(erased);\n+            remove_container(r, *leaf);\n         }\n     }\n }\n@@ -717,21 +823,23 @@ void roaring64_bitmap_remove_range_closed(roaring64_bitmap_t *r, uint64_t min,\n     uint16_t max_low16 = split_key(max, max_high48);\n     if (compare_high48(min_high48, max_high48) == 0) {\n         // Only remove a range within one container.\n-        remove_range_closed_at(art, min_high48, min_low16, max_low16);\n+        remove_range_closed_at(r, art, min_high48, min_low16, max_low16);\n         return;\n     }\n \n     // Remove a range across containers. Remove intermediate containers\n     // entirely.\n-    remove_range_closed_at(art, min_high48, min_low16, 0xffff);\n+    remove_range_closed_at(r, art, min_high48, min_low16, 0xffff);\n \n     art_iterator_t it = art_upper_bound(art, min_high48);\n     while (it.value != NULL && art_compare_keys(it.key, max_high48) < 0) {\n-        leaf_t *leaf = (leaf_t *)art_iterator_erase(art, &it);\n-        container_free(leaf->container, leaf->typecode);\n-        free_leaf(leaf);\n+        leaf_t leaf;\n+        bool erased = art_iterator_erase(&it, (art_val_t *)&leaf);\n+        assert(erased);\n+        container_free(get_container(r, leaf), get_typecode(leaf));\n+        remove_container(r, leaf);\n     }\n-    remove_range_closed_at(art, max_high48, 0, max_low16);\n+    remove_range_closed_at(r, art, max_high48, 0, max_low16);\n }\n \n void roaring64_bitmap_clear(roaring64_bitmap_t *r) {\n@@ -739,12 +847,12 @@ void roaring64_bitmap_clear(roaring64_bitmap_t *r) {\n }\n \n uint64_t roaring64_bitmap_get_cardinality(const roaring64_bitmap_t *r) {\n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n     uint64_t cardinality = 0;\n     while (it.value != NULL) {\n-        leaf_t *leaf = (leaf_t *)it.value;\n-        cardinality +=\n-            container_get_cardinality(leaf->container, leaf->typecode);\n+        leaf_t leaf = (leaf_t)*it.value;\n+        cardinality += container_get_cardinality(get_container(r, leaf),\n+                                                 get_typecode(leaf));\n         art_iterator_next(&it);\n     }\n     return cardinality;\n@@ -773,7 +881,7 @@ uint64_t roaring64_bitmap_range_closed_cardinality(const roaring64_bitmap_t *r,\n     uint8_t max_high48[ART_KEY_BYTES];\n     uint16_t max_low16 = split_key(max, max_high48);\n \n-    art_iterator_t it = art_lower_bound(&r->art, min_high48);\n+    art_iterator_t it = art_lower_bound((art_t *)&r->art, min_high48);\n     while (it.value != NULL) {\n         int max_compare_result = compare_high48(it.key, max_high48);\n         if (max_compare_result > 0) {\n@@ -781,23 +889,22 @@ uint64_t roaring64_bitmap_range_closed_cardinality(const roaring64_bitmap_t *r,\n             break;\n         }\n \n-        leaf_t *leaf = (leaf_t *)it.value;\n+        leaf_t leaf = (leaf_t)*it.value;\n+        uint8_t typecode = get_typecode(leaf);\n+        container_t *container = get_container(r, leaf);\n         if (max_compare_result == 0) {\n             // We're at the max high key, add only the range up to the low\n             // 16 bits of max.\n-            cardinality +=\n-                container_rank(leaf->container, leaf->typecode, max_low16);\n+            cardinality += container_rank(container, typecode, max_low16);\n         } else {\n             // We're not yet at the max high key, add the full container\n             // range.\n-            cardinality +=\n-                container_get_cardinality(leaf->container, leaf->typecode);\n+            cardinality += container_get_cardinality(container, typecode);\n         }\n         if (compare_high48(it.key, min_high48) == 0 && min_low16 > 0) {\n             // We're at the min high key, remove the range up to the low 16\n             // bits of min.\n-            cardinality -=\n-                container_rank(leaf->container, leaf->typecode, min_low16 - 1);\n+            cardinality -= container_rank(container, typecode, min_low16 - 1);\n         }\n         art_iterator_next(&it);\n     }\n@@ -809,23 +916,23 @@ bool roaring64_bitmap_is_empty(const roaring64_bitmap_t *r) {\n }\n \n uint64_t roaring64_bitmap_minimum(const roaring64_bitmap_t *r) {\n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n     if (it.value == NULL) {\n         return UINT64_MAX;\n     }\n-    leaf_t *leaf = (leaf_t *)it.value;\n-    return combine_key(it.key,\n-                       container_minimum(leaf->container, leaf->typecode));\n+    leaf_t leaf = (leaf_t)*it.value;\n+    return combine_key(\n+        it.key, container_minimum(get_container(r, leaf), get_typecode(leaf)));\n }\n \n uint64_t roaring64_bitmap_maximum(const roaring64_bitmap_t *r) {\n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/false);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/false);\n     if (it.value == NULL) {\n         return 0;\n     }\n-    leaf_t *leaf = (leaf_t *)it.value;\n-    return combine_key(it.key,\n-                       container_maximum(leaf->container, leaf->typecode));\n+    leaf_t leaf = (leaf_t)*it.value;\n+    return combine_key(\n+        it.key, container_maximum(get_container(r, leaf), get_typecode(leaf)));\n }\n \n bool roaring64_bitmap_run_optimize(roaring64_bitmap_t *r) {\n@@ -836,15 +943,53 @@ bool roaring64_bitmap_run_optimize(roaring64_bitmap_t *r) {\n         uint8_t new_typecode;\n         // We don't need to free the existing container if a new one was\n         // created, convert_run_optimize does that internally.\n-        leaf->container = convert_run_optimize(leaf->container, leaf->typecode,\n-                                               &new_typecode);\n-        leaf->typecode = new_typecode;\n+        container_t *new_container = convert_run_optimize(\n+            get_container(r, *leaf), get_typecode(*leaf), &new_typecode);\n+        replace_container(r, leaf, new_container, new_typecode);\n         has_run_container |= new_typecode == RUN_CONTAINER_TYPE;\n         art_iterator_next(&it);\n     }\n     return has_run_container;\n }\n \n+static void move_to_shrink(roaring64_bitmap_t *r, leaf_t *leaf) {\n+    uint64_t idx = get_index(*leaf);\n+    if (idx < r->first_free) {\n+        return;\n+    }\n+    r->containers[r->first_free] = get_container(r, *leaf);\n+    r->containers[idx] = NULL;\n+    *leaf = create_leaf(r->first_free, get_typecode(*leaf));\n+    r->first_free = next_free_container_idx(r);\n+}\n+\n+static inline bool is_shrunken(const roaring64_bitmap_t *r) {\n+    return art_is_shrunken(&r->art) && r->first_free == r->capacity;\n+}\n+\n+size_t roaring64_bitmap_shrink_to_fit(roaring64_bitmap_t *r) {\n+    size_t freed = art_shrink_to_fit(&r->art);\n+    art_iterator_t it = art_init_iterator(&r->art, true);\n+    while (it.value != NULL) {\n+        leaf_t *leaf = (leaf_t *)it.value;\n+        freed += container_shrink_to_fit(get_container(r, *leaf),\n+                                         get_typecode(*leaf));\n+        move_to_shrink(r, leaf);\n+        art_iterator_next(&it);\n+    }\n+    if (is_shrunken(r)) {\n+        return freed;\n+    }\n+    uint64_t new_capacity = r->first_free;\n+    if (new_capacity < r->capacity) {\n+        r->containers = roaring_realloc(r->containers,\n+                                        new_capacity * sizeof(container_t *));\n+        freed += (r->capacity - new_capacity) * sizeof(container_t *);\n+        r->capacity = new_capacity;\n+    }\n+    return freed;\n+}\n+\n /**\n  *  (For advanced users.)\n  * Collect statistics about the bitmap\n@@ -855,15 +1000,16 @@ void roaring64_bitmap_statistics(const roaring64_bitmap_t *r,\n     stat->min_value = roaring64_bitmap_minimum(r);\n     stat->max_value = roaring64_bitmap_maximum(r);\n \n-    art_iterator_t it = art_init_iterator(&r->art, true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, true);\n     while (it.value != NULL) {\n-        leaf_t *leaf = (leaf_t *)it.value;\n+        leaf_t leaf = (leaf_t)*it.value;\n         stat->n_containers++;\n-        uint8_t truetype = get_container_type(leaf->container, leaf->typecode);\n-        uint32_t card =\n-            container_get_cardinality(leaf->container, leaf->typecode);\n+        uint8_t truetype =\n+            get_container_type(get_container(r, leaf), get_typecode(leaf));\n+        uint32_t card = container_get_cardinality(get_container(r, leaf),\n+                                                  get_typecode(leaf));\n         uint32_t sbytes =\n-            container_size_in_bytes(leaf->container, leaf->typecode);\n+            container_size_in_bytes(get_container(r, leaf), get_typecode(leaf));\n         stat->cardinality += card;\n         switch (truetype) {\n             case BITSET_CONTAINER_TYPE:\n@@ -889,31 +1035,34 @@ void roaring64_bitmap_statistics(const roaring64_bitmap_t *r,\n     }\n }\n \n-static bool roaring64_leaf_internal_validate(const art_val_t *val,\n-                                             const char **reason) {\n-    leaf_t *leaf = (leaf_t *)val;\n-    return container_internal_validate(leaf->container, leaf->typecode, reason);\n+static bool roaring64_leaf_internal_validate(const art_val_t val,\n+                                             const char **reason,\n+                                             void *context) {\n+    leaf_t leaf = (leaf_t)val;\n+    roaring64_bitmap_t *r = (roaring64_bitmap_t *)context;\n+    return container_internal_validate(get_container(r, leaf),\n+                                       get_typecode(leaf), reason);\n }\n \n bool roaring64_bitmap_internal_validate(const roaring64_bitmap_t *r,\n                                         const char **reason) {\n     return art_internal_validate(&r->art, reason,\n-                                 roaring64_leaf_internal_validate);\n+                                 roaring64_leaf_internal_validate, (void *)r);\n }\n \n bool roaring64_bitmap_equals(const roaring64_bitmap_t *r1,\n                              const roaring64_bitmap_t *r2) {\n-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL && it2.value != NULL) {\n         if (compare_high48(it1.key, it2.key) != 0) {\n             return false;\n         }\n-        leaf_t *leaf1 = (leaf_t *)it1.value;\n-        leaf_t *leaf2 = (leaf_t *)it2.value;\n-        if (!container_equals(leaf1->container, leaf1->typecode,\n-                              leaf2->container, leaf2->typecode)) {\n+        leaf_t leaf1 = (leaf_t)*it1.value;\n+        leaf_t leaf2 = (leaf_t)*it2.value;\n+        if (!container_equals(get_container(r1, leaf1), get_typecode(leaf1),\n+                              get_container(r2, leaf2), get_typecode(leaf2))) {\n             return false;\n         }\n         art_iterator_next(&it1);\n@@ -924,8 +1073,8 @@ bool roaring64_bitmap_equals(const roaring64_bitmap_t *r1,\n \n bool roaring64_bitmap_is_subset(const roaring64_bitmap_t *r1,\n                                 const roaring64_bitmap_t *r2) {\n-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL) {\n         bool it2_present = it2.value != NULL;\n@@ -934,10 +1083,11 @@ bool roaring64_bitmap_is_subset(const roaring64_bitmap_t *r1,\n         if (it2_present) {\n             compare_result = compare_high48(it1.key, it2.key);\n             if (compare_result == 0) {\n-                leaf_t *leaf1 = (leaf_t *)it1.value;\n-                leaf_t *leaf2 = (leaf_t *)it2.value;\n-                if (!container_is_subset(leaf1->container, leaf1->typecode,\n-                                         leaf2->container, leaf2->typecode)) {\n+                leaf_t leaf1 = (leaf_t)*it1.value;\n+                leaf_t leaf2 = (leaf_t)*it2.value;\n+                if (!container_is_subset(\n+                        get_container(r1, leaf1), get_typecode(leaf1),\n+                        get_container(r2, leaf2), get_typecode(leaf2))) {\n                     return false;\n                 }\n                 art_iterator_next(&it1);\n@@ -964,8 +1114,8 @@ roaring64_bitmap_t *roaring64_bitmap_and(const roaring64_bitmap_t *r1,\n                                          const roaring64_bitmap_t *r2) {\n     roaring64_bitmap_t *result = roaring64_bitmap_create();\n \n-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL && it2.value != NULL) {\n         // Cases:\n@@ -975,19 +1125,20 @@ roaring64_bitmap_t *roaring64_bitmap_and(const roaring64_bitmap_t *r1,\n         int compare_result = compare_high48(it1.key, it2.key);\n         if (compare_result == 0) {\n             // Case 2: iterators at the same high key position.\n-            leaf_t *result_leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));\n-            leaf_t *leaf1 = (leaf_t *)it1.value;\n-            leaf_t *leaf2 = (leaf_t *)it2.value;\n-            result_leaf->container = container_and(\n-                leaf1->container, leaf1->typecode, leaf2->container,\n-                leaf2->typecode, &result_leaf->typecode);\n-\n-            if (container_nonzero_cardinality(result_leaf->container,\n-                                              result_leaf->typecode)) {\n-                art_insert(&result->art, it1.key, (art_val_t *)result_leaf);\n+            leaf_t leaf1 = (leaf_t)*it1.value;\n+            leaf_t leaf2 = (leaf_t)*it2.value;\n+            uint8_t result_typecode;\n+            container_t *result_container =\n+                container_and(get_container(r1, leaf1), get_typecode(leaf1),\n+                              get_container(r2, leaf2), get_typecode(leaf2),\n+                              &result_typecode);\n+            if (container_nonzero_cardinality(result_container,\n+                                              result_typecode)) {\n+                leaf_t result_leaf =\n+                    add_container(result, result_container, result_typecode);\n+                art_insert(&result->art, it1.key, (art_val_t)result_leaf);\n             } else {\n-                container_free(result_leaf->container, result_leaf->typecode);\n-                free_leaf(result_leaf);\n+                container_free(result_container, result_typecode);\n             }\n             art_iterator_next(&it1);\n             art_iterator_next(&it2);\n@@ -1006,8 +1157,8 @@ uint64_t roaring64_bitmap_and_cardinality(const roaring64_bitmap_t *r1,\n                                           const roaring64_bitmap_t *r2) {\n     uint64_t result = 0;\n \n-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL && it2.value != NULL) {\n         // Cases:\n@@ -1017,11 +1168,11 @@ uint64_t roaring64_bitmap_and_cardinality(const roaring64_bitmap_t *r1,\n         int compare_result = compare_high48(it1.key, it2.key);\n         if (compare_result == 0) {\n             // Case 2: iterators at the same high key position.\n-            leaf_t *leaf1 = (leaf_t *)it1.value;\n-            leaf_t *leaf2 = (leaf_t *)it2.value;\n-            result +=\n-                container_and_cardinality(leaf1->container, leaf1->typecode,\n-                                          leaf2->container, leaf2->typecode);\n+            leaf_t leaf1 = (leaf_t)*it1.value;\n+            leaf_t leaf2 = (leaf_t)*it2.value;\n+            result += container_and_cardinality(\n+                get_container(r1, leaf1), get_typecode(leaf1),\n+                get_container(r2, leaf2), get_typecode(leaf2));\n             art_iterator_next(&it1);\n             art_iterator_next(&it2);\n         } else if (compare_result < 0) {\n@@ -1042,7 +1193,7 @@ void roaring64_bitmap_and_inplace(roaring64_bitmap_t *r1,\n         return;\n     }\n     art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL) {\n         // Cases:\n@@ -1058,7 +1209,7 @@ void roaring64_bitmap_and_inplace(roaring64_bitmap_t *r1,\n             if (compare_result == 0) {\n                 // Case 2a: iterators at the same high key position.\n                 leaf_t *leaf1 = (leaf_t *)it1.value;\n-                leaf_t *leaf2 = (leaf_t *)it2.value;\n+                leaf_t leaf2 = (leaf_t)*it2.value;\n \n                 // We do the computation \"in place\" only when c1 is not a\n                 // shared container. Rationale: using a shared container\n@@ -1066,28 +1217,31 @@ void roaring64_bitmap_and_inplace(roaring64_bitmap_t *r1,\n                 // copy and then doing the computation in place which is\n                 // likely less efficient than avoiding in place entirely and\n                 // always generating a new container.\n+                uint8_t typecode = get_typecode(*leaf1);\n+                container_t *container = get_container(r1, *leaf1);\n                 uint8_t typecode2;\n                 container_t *container2;\n-                if (leaf1->typecode == SHARED_CONTAINER_TYPE) {\n-                    container2 = container_and(\n-                        leaf1->container, leaf1->typecode, leaf2->container,\n-                        leaf2->typecode, &typecode2);\n+                if (typecode == SHARED_CONTAINER_TYPE) {\n+                    container2 = container_and(container, typecode,\n+                                               get_container(r2, leaf2),\n+                                               get_typecode(leaf2), &typecode2);\n                 } else {\n                     container2 = container_iand(\n-                        leaf1->container, leaf1->typecode, leaf2->container,\n-                        leaf2->typecode, &typecode2);\n+                        container, typecode, get_container(r2, leaf2),\n+                        get_typecode(leaf2), &typecode2);\n                 }\n \n-                if (container2 != leaf1->container) {\n-                    container_free(leaf1->container, leaf1->typecode);\n-                    leaf1->container = container2;\n-                    leaf1->typecode = typecode2;\n+                if (container2 != container) {\n+                    container_free(container, typecode);\n                 }\n                 if (!container_nonzero_cardinality(container2, typecode2)) {\n                     container_free(container2, typecode2);\n-                    art_iterator_erase(&r1->art, &it1);\n-                    free_leaf(leaf1);\n+                    art_iterator_erase(&it1, NULL);\n+                    remove_container(r1, *leaf1);\n                 } else {\n+                    if (container2 != container) {\n+                        replace_container(r1, leaf1, container2, typecode2);\n+                    }\n                     // Only advance the iterator if we didn't delete the\n                     // leaf, as erasing advances by itself.\n                     art_iterator_next(&it1);\n@@ -1098,10 +1252,11 @@ void roaring64_bitmap_and_inplace(roaring64_bitmap_t *r1,\n \n         if (!it2_present || compare_result < 0) {\n             // Cases 1 and 3a: it1 is the only iterator or is before it2.\n-            leaf_t *leaf = (leaf_t *)art_iterator_erase(&r1->art, &it1);\n-            assert(leaf != NULL);\n-            container_free(leaf->container, leaf->typecode);\n-            free_leaf(leaf);\n+            leaf_t leaf;\n+            bool erased = art_iterator_erase(&it1, (art_val_t *)&leaf);\n+            assert(erased);\n+            container_free(get_container(r1, leaf), get_typecode(leaf));\n+            remove_container(r1, leaf);\n         } else if (compare_result > 0) {\n             // Case 2c: it1 is after it2.\n             art_iterator_lower_bound(&it2, it1.key);\n@@ -1112,8 +1267,8 @@ void roaring64_bitmap_and_inplace(roaring64_bitmap_t *r1,\n bool roaring64_bitmap_intersect(const roaring64_bitmap_t *r1,\n                                 const roaring64_bitmap_t *r2) {\n     bool intersect = false;\n-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL && it2.value != NULL) {\n         // Cases:\n@@ -1123,10 +1278,11 @@ bool roaring64_bitmap_intersect(const roaring64_bitmap_t *r1,\n         int compare_result = compare_high48(it1.key, it2.key);\n         if (compare_result == 0) {\n             // Case 2: iterators at the same high key position.\n-            leaf_t *leaf1 = (leaf_t *)it1.value;\n-            leaf_t *leaf2 = (leaf_t *)it2.value;\n-            intersect |= container_intersect(leaf1->container, leaf1->typecode,\n-                                             leaf2->container, leaf2->typecode);\n+            leaf_t leaf1 = (leaf_t)*it1.value;\n+            leaf_t leaf2 = (leaf_t)*it2.value;\n+            intersect |= container_intersect(\n+                get_container(r1, leaf1), get_typecode(leaf1),\n+                get_container(r2, leaf2), get_typecode(leaf2));\n             art_iterator_next(&it1);\n             art_iterator_next(&it2);\n         } else if (compare_result < 0) {\n@@ -1166,8 +1322,8 @@ roaring64_bitmap_t *roaring64_bitmap_or(const roaring64_bitmap_t *r1,\n                                         const roaring64_bitmap_t *r2) {\n     roaring64_bitmap_t *result = roaring64_bitmap_create();\n \n-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL || it2.value != NULL) {\n         bool it1_present = it1.value != NULL;\n@@ -1185,26 +1341,31 @@ roaring64_bitmap_t *roaring64_bitmap_or(const roaring64_bitmap_t *r1,\n             compare_result = compare_high48(it1.key, it2.key);\n             if (compare_result == 0) {\n                 // Case 3b: iterators at the same high key position.\n-                leaf_t *leaf1 = (leaf_t *)it1.value;\n-                leaf_t *leaf2 = (leaf_t *)it2.value;\n-                leaf_t *result_leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));\n-                result_leaf->container = container_or(\n-                    leaf1->container, leaf1->typecode, leaf2->container,\n-                    leaf2->typecode, &result_leaf->typecode);\n-                art_insert(&result->art, it1.key, (art_val_t *)result_leaf);\n+                leaf_t leaf1 = (leaf_t)*it1.value;\n+                leaf_t leaf2 = (leaf_t)*it2.value;\n+                uint8_t result_typecode;\n+                container_t *result_container =\n+                    container_or(get_container(r1, leaf1), get_typecode(leaf1),\n+                                 get_container(r2, leaf2), get_typecode(leaf2),\n+                                 &result_typecode);\n+                leaf_t result_leaf =\n+                    add_container(result, result_container, result_typecode);\n+                art_insert(&result->art, it1.key, (art_val_t)result_leaf);\n                 art_iterator_next(&it1);\n                 art_iterator_next(&it2);\n             }\n         }\n         if ((it1_present && !it2_present) || compare_result < 0) {\n             // Cases 1 and 3a: it1 is the only iterator or is before it2.\n-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it1.value);\n-            art_insert(&result->art, it1.key, (art_val_t *)result_leaf);\n+            leaf_t result_leaf =\n+                copy_leaf_container(r1, result, (leaf_t)*it1.value);\n+            art_insert(&result->art, it1.key, (art_val_t)result_leaf);\n             art_iterator_next(&it1);\n         } else if ((!it1_present && it2_present) || compare_result > 0) {\n             // Cases 2 and 3c: it2 is the only iterator or is before it1.\n-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it2.value);\n-            art_insert(&result->art, it2.key, (art_val_t *)result_leaf);\n+            leaf_t result_leaf =\n+                copy_leaf_container(r2, result, (leaf_t)*it2.value);\n+            art_insert(&result->art, it2.key, (art_val_t)result_leaf);\n             art_iterator_next(&it2);\n         }\n     }\n@@ -1225,7 +1386,7 @@ void roaring64_bitmap_or_inplace(roaring64_bitmap_t *r1,\n         return;\n     }\n     art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL || it2.value != NULL) {\n         bool it1_present = it1.value != NULL;\n@@ -1244,22 +1405,23 @@ void roaring64_bitmap_or_inplace(roaring64_bitmap_t *r1,\n             if (compare_result == 0) {\n                 // Case 3b: iterators at the same high key position.\n                 leaf_t *leaf1 = (leaf_t *)it1.value;\n-                leaf_t *leaf2 = (leaf_t *)it2.value;\n+                leaf_t leaf2 = (leaf_t)*it2.value;\n+                uint8_t typecode1 = get_typecode(*leaf1);\n+                container_t *container1 = get_container(r1, *leaf1);\n                 uint8_t typecode2;\n                 container_t *container2;\n-                if (leaf1->typecode == SHARED_CONTAINER_TYPE) {\n-                    container2 = container_or(leaf1->container, leaf1->typecode,\n-                                              leaf2->container, leaf2->typecode,\n-                                              &typecode2);\n+                if (get_typecode(*leaf1) == SHARED_CONTAINER_TYPE) {\n+                    container2 = container_or(container1, typecode1,\n+                                              get_container(r2, leaf2),\n+                                              get_typecode(leaf2), &typecode2);\n                 } else {\n-                    container2 = container_ior(\n-                        leaf1->container, leaf1->typecode, leaf2->container,\n-                        leaf2->typecode, &typecode2);\n+                    container2 = container_ior(container1, typecode1,\n+                                               get_container(r2, leaf2),\n+                                               get_typecode(leaf2), &typecode2);\n                 }\n-                if (container2 != leaf1->container) {\n-                    container_free(leaf1->container, leaf1->typecode);\n-                    leaf1->container = container2;\n-                    leaf1->typecode = typecode2;\n+                if (container2 != container1) {\n+                    container_free(container1, typecode1);\n+                    replace_container(r1, leaf1, container2, typecode2);\n                 }\n                 art_iterator_next(&it1);\n                 art_iterator_next(&it2);\n@@ -1270,9 +1432,9 @@ void roaring64_bitmap_or_inplace(roaring64_bitmap_t *r1,\n             art_iterator_next(&it1);\n         } else if ((!it1_present && it2_present) || compare_result > 0) {\n             // Cases 2 and 3c: it2 is the only iterator or is before it1.\n-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it2.value);\n-            art_iterator_insert(&r1->art, &it1, it2.key,\n-                                (art_val_t *)result_leaf);\n+            leaf_t result_leaf =\n+                copy_leaf_container(r2, r1, (leaf_t)*it2.value);\n+            art_iterator_insert(&it1, it2.key, (art_val_t)result_leaf);\n             art_iterator_next(&it2);\n         }\n     }\n@@ -1282,8 +1444,8 @@ roaring64_bitmap_t *roaring64_bitmap_xor(const roaring64_bitmap_t *r1,\n                                          const roaring64_bitmap_t *r2) {\n     roaring64_bitmap_t *result = roaring64_bitmap_create();\n \n-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL || it2.value != NULL) {\n         bool it1_present = it1.value != NULL;\n@@ -1301,19 +1463,20 @@ roaring64_bitmap_t *roaring64_bitmap_xor(const roaring64_bitmap_t *r1,\n             compare_result = compare_high48(it1.key, it2.key);\n             if (compare_result == 0) {\n                 // Case 3b: iterators at the same high key position.\n-                leaf_t *leaf1 = (leaf_t *)it1.value;\n-                leaf_t *leaf2 = (leaf_t *)it2.value;\n-                leaf_t *result_leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));\n-                result_leaf->container = container_xor(\n-                    leaf1->container, leaf1->typecode, leaf2->container,\n-                    leaf2->typecode, &result_leaf->typecode);\n-                if (container_nonzero_cardinality(result_leaf->container,\n-                                                  result_leaf->typecode)) {\n-                    art_insert(&result->art, it1.key, (art_val_t *)result_leaf);\n+                leaf_t leaf1 = (leaf_t)*it1.value;\n+                leaf_t leaf2 = (leaf_t)*it2.value;\n+                uint8_t result_typecode;\n+                container_t *result_container =\n+                    container_xor(get_container(r1, leaf1), get_typecode(leaf1),\n+                                  get_container(r2, leaf2), get_typecode(leaf2),\n+                                  &result_typecode);\n+                if (container_nonzero_cardinality(result_container,\n+                                                  result_typecode)) {\n+                    leaf_t result_leaf = add_container(result, result_container,\n+                                                       result_typecode);\n+                    art_insert(&result->art, it1.key, (art_val_t)result_leaf);\n                 } else {\n-                    container_free(result_leaf->container,\n-                                   result_leaf->typecode);\n-                    free_leaf(result_leaf);\n+                    container_free(result_container, result_typecode);\n                 }\n                 art_iterator_next(&it1);\n                 art_iterator_next(&it2);\n@@ -1321,13 +1484,15 @@ roaring64_bitmap_t *roaring64_bitmap_xor(const roaring64_bitmap_t *r1,\n         }\n         if ((it1_present && !it2_present) || compare_result < 0) {\n             // Cases 1 and 3a: it1 is the only iterator or is before it2.\n-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it1.value);\n-            art_insert(&result->art, it1.key, (art_val_t *)result_leaf);\n+            leaf_t result_leaf =\n+                copy_leaf_container(r1, result, (leaf_t)*it1.value);\n+            art_insert(&result->art, it1.key, (art_val_t)result_leaf);\n             art_iterator_next(&it1);\n         } else if ((!it1_present && it2_present) || compare_result > 0) {\n             // Cases 2 and 3c: it2 is the only iterator or is before it1.\n-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it2.value);\n-            art_insert(&result->art, it2.key, (art_val_t *)result_leaf);\n+            leaf_t result_leaf =\n+                copy_leaf_container(r2, result, (leaf_t)*it2.value);\n+            art_insert(&result->art, it2.key, (art_val_t)result_leaf);\n             art_iterator_next(&it2);\n         }\n     }\n@@ -1346,7 +1511,7 @@ void roaring64_bitmap_xor_inplace(roaring64_bitmap_t *r1,\n                                   const roaring64_bitmap_t *r2) {\n     assert(r1 != r2);\n     art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL || it2.value != NULL) {\n         bool it1_present = it1.value != NULL;\n@@ -1365,15 +1530,15 @@ void roaring64_bitmap_xor_inplace(roaring64_bitmap_t *r1,\n             if (compare_result == 0) {\n                 // Case 3b: iterators at the same high key position.\n                 leaf_t *leaf1 = (leaf_t *)it1.value;\n-                leaf_t *leaf2 = (leaf_t *)it2.value;\n-                container_t *container1 = leaf1->container;\n-                uint8_t typecode1 = leaf1->typecode;\n+                leaf_t leaf2 = (leaf_t)*it2.value;\n+                uint8_t typecode1 = get_typecode(*leaf1);\n+                container_t *container1 = get_container(r1, *leaf1);\n                 uint8_t typecode2;\n                 container_t *container2;\n-                if (leaf1->typecode == SHARED_CONTAINER_TYPE) {\n-                    container2 = container_xor(\n-                        leaf1->container, leaf1->typecode, leaf2->container,\n-                        leaf2->typecode, &typecode2);\n+                if (typecode1 == SHARED_CONTAINER_TYPE) {\n+                    container2 = container_xor(container1, typecode1,\n+                                               get_container(r2, leaf2),\n+                                               get_typecode(leaf2), &typecode2);\n                     if (container2 != container1) {\n                         // We only free when doing container_xor, not\n                         // container_ixor, as ixor frees the original\n@@ -1382,17 +1547,19 @@ void roaring64_bitmap_xor_inplace(roaring64_bitmap_t *r1,\n                     }\n                 } else {\n                     container2 = container_ixor(\n-                        leaf1->container, leaf1->typecode, leaf2->container,\n-                        leaf2->typecode, &typecode2);\n+                        container1, typecode1, get_container(r2, leaf2),\n+                        get_typecode(leaf2), &typecode2);\n                 }\n-                leaf1->container = container2;\n-                leaf1->typecode = typecode2;\n \n                 if (!container_nonzero_cardinality(container2, typecode2)) {\n                     container_free(container2, typecode2);\n-                    art_iterator_erase(&r1->art, &it1);\n-                    free_leaf(leaf1);\n+                    bool erased = art_iterator_erase(&it1, NULL);\n+                    assert(erased);\n+                    remove_container(r1, *leaf1);\n                 } else {\n+                    if (container2 != container1) {\n+                        replace_container(r1, leaf1, container2, typecode2);\n+                    }\n                     // Only advance the iterator if we didn't delete the\n                     // leaf, as erasing advances by itself.\n                     art_iterator_next(&it1);\n@@ -1405,13 +1572,13 @@ void roaring64_bitmap_xor_inplace(roaring64_bitmap_t *r1,\n             art_iterator_next(&it1);\n         } else if ((!it1_present && it2_present) || compare_result > 0) {\n             // Cases 2 and 3c: it2 is the only iterator or is before it1.\n-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it2.value);\n+            leaf_t result_leaf =\n+                copy_leaf_container(r2, r1, (leaf_t)*it2.value);\n             if (it1_present) {\n-                art_iterator_insert(&r1->art, &it1, it2.key,\n-                                    (art_val_t *)result_leaf);\n+                art_iterator_insert(&it1, it2.key, (art_val_t)result_leaf);\n                 art_iterator_next(&it1);\n             } else {\n-                art_insert(&r1->art, it2.key, (art_val_t *)result_leaf);\n+                art_insert(&r1->art, it2.key, (art_val_t)result_leaf);\n             }\n             art_iterator_next(&it2);\n         }\n@@ -1422,8 +1589,8 @@ roaring64_bitmap_t *roaring64_bitmap_andnot(const roaring64_bitmap_t *r1,\n                                             const roaring64_bitmap_t *r2) {\n     roaring64_bitmap_t *result = roaring64_bitmap_create();\n \n-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL) {\n         // Cases:\n@@ -1438,20 +1605,21 @@ roaring64_bitmap_t *roaring64_bitmap_andnot(const roaring64_bitmap_t *r1,\n             compare_result = compare_high48(it1.key, it2.key);\n             if (compare_result == 0) {\n                 // Case 2b: iterators at the same high key position.\n-                leaf_t *result_leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));\n                 leaf_t *leaf1 = (leaf_t *)it1.value;\n-                leaf_t *leaf2 = (leaf_t *)it2.value;\n-                result_leaf->container = container_andnot(\n-                    leaf1->container, leaf1->typecode, leaf2->container,\n-                    leaf2->typecode, &result_leaf->typecode);\n-\n-                if (container_nonzero_cardinality(result_leaf->container,\n-                                                  result_leaf->typecode)) {\n-                    art_insert(&result->art, it1.key, (art_val_t *)result_leaf);\n+                leaf_t leaf2 = (leaf_t)*it2.value;\n+                uint8_t result_typecode;\n+                container_t *result_container = container_andnot(\n+                    get_container(r1, *leaf1), get_typecode(*leaf1),\n+                    get_container(r2, leaf2), get_typecode(leaf2),\n+                    &result_typecode);\n+\n+                if (container_nonzero_cardinality(result_container,\n+                                                  result_typecode)) {\n+                    leaf_t result_leaf = add_container(result, result_container,\n+                                                       result_typecode);\n+                    art_insert(&result->art, it1.key, (art_val_t)result_leaf);\n                 } else {\n-                    container_free(result_leaf->container,\n-                                   result_leaf->typecode);\n-                    free_leaf(result_leaf);\n+                    container_free(result_container, result_typecode);\n                 }\n                 art_iterator_next(&it1);\n                 art_iterator_next(&it2);\n@@ -1459,8 +1627,9 @@ roaring64_bitmap_t *roaring64_bitmap_andnot(const roaring64_bitmap_t *r1,\n         }\n         if (!it2_present || compare_result < 0) {\n             // Cases 1 and 2a: it1 is the only iterator or is before it2.\n-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it1.value);\n-            art_insert(&result->art, it1.key, (art_val_t *)result_leaf);\n+            leaf_t result_leaf =\n+                copy_leaf_container(r1, result, (leaf_t)*it1.value);\n+            art_insert(&result->art, it1.key, (art_val_t)result_leaf);\n             art_iterator_next(&it1);\n         } else if (compare_result > 0) {\n             // Case 2c: it1 is after it2.\n@@ -1480,7 +1649,7 @@ uint64_t roaring64_bitmap_andnot_cardinality(const roaring64_bitmap_t *r1,\n void roaring64_bitmap_andnot_inplace(roaring64_bitmap_t *r1,\n                                      const roaring64_bitmap_t *r2) {\n     art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);\n-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);\n+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);\n \n     while (it1.value != NULL) {\n         // Cases:\n@@ -1496,15 +1665,15 @@ void roaring64_bitmap_andnot_inplace(roaring64_bitmap_t *r1,\n             if (compare_result == 0) {\n                 // Case 2b: iterators at the same high key position.\n                 leaf_t *leaf1 = (leaf_t *)it1.value;\n-                leaf_t *leaf2 = (leaf_t *)it2.value;\n-                container_t *container1 = leaf1->container;\n-                uint8_t typecode1 = leaf1->typecode;\n+                leaf_t leaf2 = (leaf_t)*it2.value;\n+                uint8_t typecode1 = get_typecode(*leaf1);\n+                container_t *container1 = get_container(r1, *leaf1);\n                 uint8_t typecode2;\n                 container_t *container2;\n-                if (leaf1->typecode == SHARED_CONTAINER_TYPE) {\n+                if (typecode1 == SHARED_CONTAINER_TYPE) {\n                     container2 = container_andnot(\n-                        leaf1->container, leaf1->typecode, leaf2->container,\n-                        leaf2->typecode, &typecode2);\n+                        container1, typecode1, get_container(r2, leaf2),\n+                        get_typecode(leaf2), &typecode2);\n                     if (container2 != container1) {\n                         // We only free when doing container_andnot, not\n                         // container_iandnot, as iandnot frees the original\n@@ -1513,19 +1682,19 @@ void roaring64_bitmap_andnot_inplace(roaring64_bitmap_t *r1,\n                     }\n                 } else {\n                     container2 = container_iandnot(\n-                        leaf1->container, leaf1->typecode, leaf2->container,\n-                        leaf2->typecode, &typecode2);\n-                }\n-                if (container2 != container1) {\n-                    leaf1->container = container2;\n-                    leaf1->typecode = typecode2;\n+                        container1, typecode1, get_container(r2, leaf2),\n+                        get_typecode(leaf2), &typecode2);\n                 }\n \n                 if (!container_nonzero_cardinality(container2, typecode2)) {\n                     container_free(container2, typecode2);\n-                    art_iterator_erase(&r1->art, &it1);\n-                    free_leaf(leaf1);\n+                    bool erased = art_iterator_erase(&it1, NULL);\n+                    assert(erased);\n+                    remove_container(r1, *leaf1);\n                 } else {\n+                    if (container2 != container1) {\n+                        replace_container(r1, leaf1, container2, typecode2);\n+                    }\n                     // Only advance the iterator if we didn't delete the\n                     // leaf, as erasing advances by itself.\n                     art_iterator_next(&it1);\n@@ -1544,38 +1713,39 @@ void roaring64_bitmap_andnot_inplace(roaring64_bitmap_t *r1,\n }\n \n /**\n- * Flips the leaf at high48 in the range [min, max), returning a new leaf with a\n- * new container. If the high48 key is not found in the existing bitmap, a new\n- * container is created. Returns null if the negation results in an empty range.\n+ * Flips the leaf at high48 in the range [min, max), adding the result to\n+ * `r2`. If the high48 key is not found in `r1`, a new container is created.\n  */\n-static leaf_t *roaring64_flip_leaf(const roaring64_bitmap_t *r,\n-                                   uint8_t high48[], uint32_t min,\n-                                   uint32_t max) {\n-    leaf_t *leaf1 = (leaf_t *)art_find(&r->art, high48);\n-    container_t *container2;\n+static void roaring64_flip_leaf(const roaring64_bitmap_t *r1,\n+                                roaring64_bitmap_t *r2, uint8_t high48[],\n+                                uint32_t min, uint32_t max) {\n+    leaf_t *leaf1 = (leaf_t *)art_find(&r1->art, high48);\n     uint8_t typecode2;\n+    container_t *container2;\n     if (leaf1 == NULL) {\n         // No container at this key, create a full container.\n         container2 = container_range_of_ones(min, max, &typecode2);\n     } else if (min == 0 && max > 0xFFFF) {\n         // Flip whole container.\n-        container2 =\n-            container_not(leaf1->container, leaf1->typecode, &typecode2);\n+        container2 = container_not(get_container(r1, *leaf1),\n+                                   get_typecode(*leaf1), &typecode2);\n     } else {\n         // Partially flip a container.\n-        container2 = container_not_range(leaf1->container, leaf1->typecode, min,\n-                                         max, &typecode2);\n+        container2 =\n+            container_not_range(get_container(r1, *leaf1), get_typecode(*leaf1),\n+                                min, max, &typecode2);\n     }\n     if (container_nonzero_cardinality(container2, typecode2)) {\n-        return create_leaf(container2, typecode2);\n+        leaf_t leaf2 = add_container(r2, container2, typecode2);\n+        art_insert(&r2->art, high48, (art_val_t)leaf2);\n+    } else {\n+        container_free(container2, typecode2);\n     }\n-    container_free(container2, typecode2);\n-    return NULL;\n }\n \n /**\n- * Flips the leaf at high48 in the range [min, max). If the high48 key is not\n- * found in the bitmap, a new container is created. Deletes the leaf and\n+ * Flips the leaf at high48 in the range [min, max). If the high48 key is\n+ * not found in the bitmap, a new container is created. Deletes the leaf and\n  * associated container if the negation results in an empty range.\n  */\n static void roaring64_flip_leaf_inplace(roaring64_bitmap_t *r, uint8_t high48[],\n@@ -1586,28 +1756,28 @@ static void roaring64_flip_leaf_inplace(roaring64_bitmap_t *r, uint8_t high48[],\n     if (leaf == NULL) {\n         // No container at this key, insert a full container.\n         container2 = container_range_of_ones(min, max, &typecode2);\n-        art_insert(&r->art, high48,\n-                   (art_val_t *)create_leaf(container2, typecode2));\n+        leaf_t new_leaf = add_container(r, container2, typecode2);\n+        art_insert(&r->art, high48, (art_val_t)new_leaf);\n         return;\n     }\n \n     if (min == 0 && max > 0xFFFF) {\n         // Flip whole container.\n-        container2 =\n-            container_inot(leaf->container, leaf->typecode, &typecode2);\n+        container2 = container_inot(get_container(r, *leaf),\n+                                    get_typecode(*leaf), &typecode2);\n     } else {\n         // Partially flip a container.\n-        container2 = container_inot_range(leaf->container, leaf->typecode, min,\n-                                          max, &typecode2);\n+        container2 = container_inot_range(\n+            get_container(r, *leaf), get_typecode(*leaf), min, max, &typecode2);\n     }\n \n-    leaf->container = container2;\n-    leaf->typecode = typecode2;\n-\n-    if (!container_nonzero_cardinality(leaf->container, leaf->typecode)) {\n-        art_erase(&r->art, high48);\n-        container_free(leaf->container, leaf->typecode);\n-        free_leaf(leaf);\n+    if (container_nonzero_cardinality(container2, typecode2)) {\n+        replace_container(r, leaf, container2, typecode2);\n+    } else {\n+        bool erased = art_erase(&r->art, high48, NULL);\n+        assert(erased);\n+        container_free(container2, typecode2);\n+        remove_container(r, *leaf);\n     }\n }\n \n@@ -1632,20 +1802,21 @@ roaring64_bitmap_t *roaring64_bitmap_flip_closed(const roaring64_bitmap_t *r1,\n     uint64_t max_high48_bits = (max & 0xFFFFFFFFFFFF0000ULL) >> 16;\n \n     roaring64_bitmap_t *r2 = roaring64_bitmap_create();\n-    art_iterator_t it = art_init_iterator(&r1->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r1->art, /*first=*/true);\n \n     // Copy the containers before min unchanged.\n     while (it.value != NULL && compare_high48(it.key, min_high48_key) < 0) {\n-        leaf_t *leaf1 = (leaf_t *)it.value;\n-        uint8_t typecode2 = leaf1->typecode;\n+        leaf_t leaf1 = (leaf_t)*it.value;\n+        uint8_t typecode2 = get_typecode(leaf1);\n         container_t *container2 = get_copy_of_container(\n-            leaf1->container, &typecode2, /*copy_on_write=*/false);\n-        art_insert(&r2->art, it.key,\n-                   (art_val_t *)create_leaf(container2, typecode2));\n+            get_container(r1, leaf1), &typecode2, /*copy_on_write=*/false);\n+        leaf_t leaf2 = add_container(r2, container2, typecode2);\n+        art_insert(&r2->art, it.key, (art_val_t)leaf2);\n         art_iterator_next(&it);\n     }\n \n-    // Flip the range (including non-existent containers!) between min and max.\n+    // Flip the range (including non-existent containers!) between min and\n+    // max.\n     for (uint64_t high48_bits = min_high48_bits; high48_bits <= max_high48_bits;\n          high48_bits++) {\n         uint8_t current_high48_key[ART_KEY_BYTES];\n@@ -1660,22 +1831,19 @@ roaring64_bitmap_t *roaring64_bitmap_flip_closed(const roaring64_bitmap_t *r1,\n             max_container = max_low16 + 1;  // Exclusive.\n         }\n \n-        leaf_t *leaf = roaring64_flip_leaf(r1, current_high48_key,\n-                                           min_container, max_container);\n-        if (leaf != NULL) {\n-            art_insert(&r2->art, current_high48_key, (art_val_t *)leaf);\n-        }\n+        roaring64_flip_leaf(r1, r2, current_high48_key, min_container,\n+                            max_container);\n     }\n \n     // Copy the containers after max unchanged.\n-    it = art_upper_bound(&r1->art, max_high48_key);\n+    it = art_upper_bound((art_t *)&r1->art, max_high48_key);\n     while (it.value != NULL) {\n-        leaf_t *leaf1 = (leaf_t *)it.value;\n-        uint8_t typecode2 = leaf1->typecode;\n+        leaf_t leaf1 = (leaf_t)*it.value;\n+        uint8_t typecode2 = get_typecode(leaf1);\n         container_t *container2 = get_copy_of_container(\n-            leaf1->container, &typecode2, /*copy_on_write=*/false);\n-        art_insert(&r2->art, it.key,\n-                   (art_val_t *)create_leaf(container2, typecode2));\n+            get_container(r1, leaf1), &typecode2, /*copy_on_write=*/false);\n+        leaf_t leaf2 = add_container(r2, container2, typecode2);\n+        art_insert(&r2->art, it.key, (art_val_t)leaf2);\n         art_iterator_next(&it);\n     }\n \n@@ -1700,7 +1868,8 @@ void roaring64_bitmap_flip_closed_inplace(roaring64_bitmap_t *r, uint64_t min,\n     uint64_t min_high48_bits = (min & 0xFFFFFFFFFFFF0000ULL) >> 16;\n     uint64_t max_high48_bits = (max & 0xFFFFFFFFFFFF0000ULL) >> 16;\n \n-    // Flip the range (including non-existent containers!) between min and max.\n+    // Flip the range (including non-existent containers!) between min and\n+    // max.\n     for (uint64_t high48_bits = min_high48_bits; high48_bits <= max_high48_bits;\n          high48_bits++) {\n         uint8_t current_high48_key[ART_KEY_BYTES];\n@@ -1722,7 +1891,7 @@ void roaring64_bitmap_flip_closed_inplace(roaring64_bitmap_t *r, uint64_t min,\n \n // Returns the number of distinct high 32-bit entries in the bitmap.\n static inline uint64_t count_high32(const roaring64_bitmap_t *r) {\n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n     uint64_t high32_count = 0;\n     uint32_t prev_high32 = 0;\n     while (it.value != NULL) {\n@@ -1751,7 +1920,7 @@ size_t roaring64_bitmap_portable_size_in_bytes(const roaring64_bitmap_t *r) {\n     uint64_t high32_count;\n     size += sizeof(high32_count);\n \n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n     uint32_t prev_high32 = 0;\n     roaring_bitmap_t *bitmap32 = NULL;\n \n@@ -1760,7 +1929,8 @@ size_t roaring64_bitmap_portable_size_in_bytes(const roaring64_bitmap_t *r) {\n         uint32_t current_high32 = (uint32_t)(combine_key(it.key, 0) >> 32);\n         if (bitmap32 == NULL || prev_high32 != current_high32) {\n             if (bitmap32 != NULL) {\n-                // Write as uint32 the most significant 32 bits of the bucket.\n+                // Write as uint32 the most significant 32 bits of the\n+                // bucket.\n                 size += sizeof(prev_high32);\n \n                 // Write the 32-bit Roaring bitmaps representing the least\n@@ -1782,10 +1952,10 @@ size_t roaring64_bitmap_portable_size_in_bytes(const roaring64_bitmap_t *r) {\n \n             prev_high32 = current_high32;\n         }\n-        leaf_t *leaf = (leaf_t *)it.value;\n+        leaf_t leaf = (leaf_t)*it.value;\n         ra_append(&bitmap32->high_low_container,\n-                  (uint16_t)(current_high32 >> 16), leaf->container,\n-                  leaf->typecode);\n+                  (uint16_t)(current_high32 >> 16), get_container(r, leaf),\n+                  get_typecode(leaf));\n         art_iterator_next(&it);\n     }\n \n@@ -1816,7 +1986,7 @@ size_t roaring64_bitmap_portable_serialize(const roaring64_bitmap_t *r,\n     memcpy(buf, &high32_count, sizeof(high32_count));\n     buf += sizeof(high32_count);\n \n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n     uint32_t prev_high32 = 0;\n     roaring_bitmap_t *bitmap32 = NULL;\n \n@@ -1826,7 +1996,8 @@ size_t roaring64_bitmap_portable_serialize(const roaring64_bitmap_t *r,\n         uint32_t current_high32 = (uint32_t)(current_high48 >> 32);\n         if (bitmap32 == NULL || prev_high32 != current_high32) {\n             if (bitmap32 != NULL) {\n-                // Write as uint32 the most significant 32 bits of the bucket.\n+                // Write as uint32 the most significant 32 bits of the\n+                // bucket.\n                 memcpy(buf, &prev_high32, sizeof(prev_high32));\n                 buf += sizeof(prev_high32);\n \n@@ -1849,10 +2020,10 @@ size_t roaring64_bitmap_portable_serialize(const roaring64_bitmap_t *r,\n \n             prev_high32 = current_high32;\n         }\n-        leaf_t *leaf = (leaf_t *)it.value;\n+        leaf_t leaf = (leaf_t)*it.value;\n         ra_append(&bitmap32->high_low_container,\n-                  (uint16_t)(current_high48 >> 16), leaf->container,\n-                  leaf->typecode);\n+                  (uint16_t)(current_high48 >> 16), get_container(r, leaf),\n+                  get_typecode(leaf));\n         art_iterator_next(&it);\n     }\n \n@@ -1903,8 +2074,8 @@ size_t roaring64_bitmap_portable_deserialize_size(const char *buf,\n         buf += sizeof(high32);\n         read_bytes += sizeof(high32);\n \n-        // Read the 32-bit Roaring bitmaps representing the least significant\n-        // bits of a set of elements.\n+        // Read the 32-bit Roaring bitmaps representing the least\n+        // significant bits of a set of elements.\n         size_t bitmap32_size = roaring_bitmap_portable_deserialize_size(\n             buf, maxbytes - read_bytes);\n         if (bitmap32_size == 0) {\n@@ -1959,8 +2130,8 @@ roaring64_bitmap_t *roaring64_bitmap_portable_deserialize_safe(\n         }\n         previous_high32 = high32;\n \n-        // Read the 32-bit Roaring bitmaps representing the least significant\n-        // bits of a set of elements.\n+        // Read the 32-bit Roaring bitmaps representing the least\n+        // significant bits of a set of elements.\n         size_t bitmap32_size = roaring_bitmap_portable_deserialize_size(\n             buf, maxbytes - read_bytes);\n         if (bitmap32_size == 0) {\n@@ -2002,16 +2173,364 @@ roaring64_bitmap_t *roaring64_bitmap_portable_deserialize_safe(\n     return r;\n }\n \n+// Returns an \"element count\" for the given container. This has a different\n+// meaning for each container type, but the purpose is the minimal information\n+// required to serialize the container metadata.\n+static inline uint32_t container_get_element_count(const container_t *c,\n+                                                   uint8_t typecode) {\n+    switch (typecode) {\n+        case BITSET_CONTAINER_TYPE: {\n+            return ((bitset_container_t *)c)->cardinality;\n+        }\n+        case ARRAY_CONTAINER_TYPE: {\n+            return ((array_container_t *)c)->cardinality;\n+        }\n+        case RUN_CONTAINER_TYPE: {\n+            return ((run_container_t *)c)->n_runs;\n+        }\n+        default: {\n+            assert(false);\n+            roaring_unreachable;\n+            return 0;\n+        }\n+    }\n+}\n+\n+static inline size_t container_get_frozen_size(const container_t *c,\n+                                               uint8_t typecode) {\n+    switch (typecode) {\n+        case BITSET_CONTAINER_TYPE: {\n+            return BITSET_CONTAINER_SIZE_IN_WORDS * sizeof(uint64_t);\n+        }\n+        case ARRAY_CONTAINER_TYPE: {\n+            return container_get_element_count(c, typecode) * sizeof(uint16_t);\n+        }\n+        case RUN_CONTAINER_TYPE: {\n+            return container_get_element_count(c, typecode) * sizeof(rle16_t);\n+        }\n+        default: {\n+            assert(false);\n+            roaring_unreachable;\n+            return 0;\n+        }\n+    }\n+}\n+\n+uint64_t align_size(uint64_t size, uint64_t alignment) {\n+    return (size + alignment - 1) & ~(alignment - 1);\n+}\n+\n+size_t roaring64_bitmap_frozen_size_in_bytes(const roaring64_bitmap_t *r) {\n+    if (!is_shrunken(r)) {\n+        return 0;\n+    }\n+    // Flags.\n+    uint64_t size = sizeof(r->flags);\n+    // Container count.\n+    size += sizeof(r->capacity);\n+    // Container element counts.\n+    size += r->capacity * sizeof(uint16_t);\n+    // Total container sizes.\n+    size += 3 * sizeof(uint64_t);\n+    // ART (8 byte aligned).\n+    size = align_size(size, 8);\n+    size += art_size_in_bytes(&r->art);\n+\n+    uint64_t total_sizes[4] =\n+        CROARING_ZERO_INITIALIZER;  // Indexed by typecode.\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n+    while (it.value != NULL) {\n+        leaf_t leaf = (leaf_t)*it.value;\n+        uint8_t typecode = get_typecode(leaf);\n+        total_sizes[typecode] +=\n+            container_get_frozen_size(get_container(r, leaf), typecode);\n+        art_iterator_next(&it);\n+    }\n+    // Containers (aligned).\n+    size = align_size(size, CROARING_BITSET_ALIGNMENT);\n+    size += total_sizes[BITSET_CONTAINER_TYPE];\n+    size = align_size(size, alignof(rle16_t));\n+    size += total_sizes[ARRAY_CONTAINER_TYPE];\n+    size = align_size(size, alignof(uint16_t));\n+    size += total_sizes[RUN_CONTAINER_TYPE];\n+    // Padding to make overall size a multiple of required alignment.\n+    size = align_size(size, CROARING_BITSET_ALIGNMENT);\n+    return size;\n+}\n+\n+static inline void container_frozen_serialize(const container_t *container,\n+                                              uint8_t typecode,\n+                                              uint64_t **bitsets,\n+                                              uint16_t **arrays,\n+                                              rle16_t **runs) {\n+    size_t size = container_get_frozen_size(container, typecode);\n+    switch (typecode) {\n+        case BITSET_CONTAINER_TYPE: {\n+            bitset_container_t *bitset = (bitset_container_t *)container;\n+            memcpy(*bitsets, bitset->words, size);\n+            *bitsets += BITSET_CONTAINER_SIZE_IN_WORDS;\n+            break;\n+        }\n+        case ARRAY_CONTAINER_TYPE: {\n+            array_container_t *array = (array_container_t *)container;\n+            memcpy(*arrays, array->array, size);\n+            *arrays += container_get_element_count(container, typecode);\n+            break;\n+        }\n+        case RUN_CONTAINER_TYPE: {\n+            run_container_t *run = (run_container_t *)container;\n+            memcpy(*runs, run->runs, size);\n+            *runs += container_get_element_count(container, typecode);\n+            break;\n+        }\n+        default: {\n+            assert(false);\n+            roaring_unreachable;\n+        }\n+    }\n+}\n+\n+static inline char *pad_align(char *buf, const char *initial_buf,\n+                              size_t alignment) {\n+    uint64_t buf_size = buf - initial_buf;\n+    uint64_t pad = align_size(buf_size, alignment) - buf_size;\n+    memset(buf, 0, pad);\n+    return buf + pad;\n+}\n+\n+size_t roaring64_bitmap_frozen_serialize(const roaring64_bitmap_t *r,\n+                                         char *buf) {\n+    if (buf == NULL) {\n+        return 0;\n+    }\n+    if (!is_shrunken(r)) {\n+        return 0;\n+    }\n+    const char *initial_buf = buf;\n+\n+    // Flags.\n+    memcpy(buf, &r->flags, sizeof(r->flags));\n+    buf += sizeof(r->flags);\n+\n+    // Container count.\n+    memcpy(buf, &r->capacity, sizeof(r->capacity));\n+    buf += sizeof(r->capacity);\n+\n+    // Container element counts.\n+    uint64_t total_sizes[4] =\n+        CROARING_ZERO_INITIALIZER;  // Indexed by typecode.\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n+    while (it.value != NULL) {\n+        leaf_t leaf = (leaf_t)*it.value;\n+        uint8_t typecode = get_typecode(leaf);\n+        container_t *container = get_container(r, leaf);\n+\n+        uint32_t elem_count = container_get_element_count(container, typecode);\n+        uint16_t compressed_elem_count = (uint16_t)(elem_count - 1);\n+        memcpy(buf, &compressed_elem_count, sizeof(compressed_elem_count));\n+        buf += sizeof(compressed_elem_count);\n+\n+        total_sizes[typecode] += container_get_frozen_size(container, typecode);\n+        art_iterator_next(&it);\n+    }\n+\n+    // Total container sizes.\n+    memcpy(buf, &(total_sizes[BITSET_CONTAINER_TYPE]), sizeof(uint64_t));\n+    buf += sizeof(uint64_t);\n+    memcpy(buf, &(total_sizes[RUN_CONTAINER_TYPE]), sizeof(uint64_t));\n+    buf += sizeof(uint64_t);\n+    memcpy(buf, &(total_sizes[ARRAY_CONTAINER_TYPE]), sizeof(uint64_t));\n+    buf += sizeof(uint64_t);\n+\n+    // ART.\n+    buf = pad_align(buf, initial_buf, 8);\n+    buf += art_serialize(&r->art, buf);\n+\n+    // Containers (aligned).\n+    // Runs before arrays as run elements are larger than array elements and\n+    // smaller than bitset elements.\n+    buf = pad_align(buf, initial_buf, CROARING_BITSET_ALIGNMENT);\n+    uint64_t *bitsets = (uint64_t *)buf;\n+    buf += total_sizes[BITSET_CONTAINER_TYPE];\n+    buf = pad_align(buf, initial_buf, alignof(rle16_t));\n+    rle16_t *runs = (rle16_t *)buf;\n+    buf += total_sizes[RUN_CONTAINER_TYPE];\n+    buf = pad_align(buf, initial_buf, alignof(uint16_t));\n+    uint16_t *arrays = (uint16_t *)buf;\n+    buf += total_sizes[ARRAY_CONTAINER_TYPE];\n+\n+    it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n+    while (it.value != NULL) {\n+        leaf_t leaf = (leaf_t)*it.value;\n+        uint8_t typecode = get_typecode(leaf);\n+        container_t *container = get_container(r, leaf);\n+        container_frozen_serialize(container, typecode, &bitsets, &arrays,\n+                                   &runs);\n+        art_iterator_next(&it);\n+    }\n+\n+    // Padding to make overall size a multiple of required alignment.\n+    buf = pad_align(buf, initial_buf, CROARING_BITSET_ALIGNMENT);\n+\n+    return buf - initial_buf;\n+}\n+\n+static container_t *container_frozen_view(uint8_t typecode, uint32_t elem_count,\n+                                          const uint64_t **bitsets,\n+                                          const uint16_t **arrays,\n+                                          const rle16_t **runs) {\n+    switch (typecode) {\n+        case BITSET_CONTAINER_TYPE: {\n+            bitset_container_t *c = (bitset_container_t *)roaring_malloc(\n+                sizeof(bitset_container_t));\n+            c->cardinality = elem_count;\n+            c->words = (uint64_t *)*bitsets;\n+            *bitsets += BITSET_CONTAINER_SIZE_IN_WORDS;\n+            return (container_t *)c;\n+        }\n+        case ARRAY_CONTAINER_TYPE: {\n+            array_container_t *c =\n+                (array_container_t *)roaring_malloc(sizeof(array_container_t));\n+            c->cardinality = elem_count;\n+            c->capacity = elem_count;\n+            c->array = (uint16_t *)*arrays;\n+            *arrays += elem_count;\n+            return (container_t *)c;\n+        }\n+        case RUN_CONTAINER_TYPE: {\n+            run_container_t *c =\n+                (run_container_t *)roaring_malloc(sizeof(run_container_t));\n+            c->n_runs = elem_count;\n+            c->capacity = elem_count;\n+            c->runs = (rle16_t *)*runs;\n+            *runs += elem_count;\n+            return (container_t *)c;\n+        }\n+        default: {\n+            assert(false);\n+            roaring_unreachable;\n+            return NULL;\n+        }\n+    }\n+}\n+\n+roaring64_bitmap_t *roaring64_bitmap_frozen_view(const char *buf,\n+                                                 size_t maxbytes) {\n+    if (buf == NULL) {\n+        return NULL;\n+    }\n+\n+    roaring64_bitmap_t *r = roaring64_bitmap_create();\n+\n+    // Flags.\n+    if (maxbytes < sizeof(r->flags)) {\n+        roaring64_bitmap_free(r);\n+        return NULL;\n+    }\n+    memcpy(&r->flags, buf, sizeof(r->flags));\n+    buf += sizeof(r->flags);\n+    maxbytes -= sizeof(r->flags);\n+    r->flags |= ROARING_FLAG_FROZEN;\n+\n+    // Container count.\n+    if (maxbytes < sizeof(r->capacity)) {\n+        roaring64_bitmap_free(r);\n+        return NULL;\n+    }\n+    memcpy(&r->capacity, buf, sizeof(r->capacity));\n+    buf += sizeof(r->capacity);\n+    maxbytes -= sizeof(r->capacity);\n+\n+    r->containers =\n+        (container_t *)roaring_malloc(r->capacity * sizeof(container_t *));\n+\n+    // Container element counts.\n+    if (maxbytes < r->capacity * sizeof(uint16_t)) {\n+        roaring64_bitmap_free(r);\n+        return NULL;\n+    }\n+    const char *elem_counts = buf;\n+    buf += r->capacity * sizeof(uint16_t);\n+    maxbytes -= r->capacity * sizeof(uint16_t);\n+\n+    // Total container sizes.\n+    uint64_t total_sizes[4];\n+    if (maxbytes < sizeof(uint64_t) * 3) {\n+        roaring64_bitmap_free(r);\n+        return NULL;\n+    }\n+    memcpy(&(total_sizes[BITSET_CONTAINER_TYPE]), buf, sizeof(uint64_t));\n+    buf += sizeof(uint64_t);\n+    maxbytes -= sizeof(uint64_t);\n+    memcpy(&(total_sizes[RUN_CONTAINER_TYPE]), buf, sizeof(uint64_t));\n+    buf += sizeof(uint64_t);\n+    maxbytes -= sizeof(uint64_t);\n+    memcpy(&(total_sizes[ARRAY_CONTAINER_TYPE]), buf, sizeof(uint64_t));\n+    buf += sizeof(uint64_t);\n+    maxbytes -= sizeof(uint64_t);\n+\n+    // ART (8 byte aligned).\n+    buf = CROARING_ALIGN_BUF(buf, 8);\n+    size_t art_size = art_frozen_view(buf, maxbytes, &r->art);\n+    if (art_size == 0) {\n+        roaring64_bitmap_free(r);\n+        return NULL;\n+    }\n+    buf += art_size;\n+    maxbytes -= art_size;\n+\n+    // Containers (aligned).\n+    const char *before_containers = buf;\n+    buf = CROARING_ALIGN_BUF(buf, CROARING_BITSET_ALIGNMENT);\n+    const uint64_t *bitsets = (const uint64_t *)buf;\n+    buf += total_sizes[BITSET_CONTAINER_TYPE];\n+    buf = CROARING_ALIGN_BUF(buf, alignof(rle16_t));\n+    const rle16_t *runs = (const rle16_t *)buf;\n+    buf += total_sizes[RUN_CONTAINER_TYPE];\n+    buf = CROARING_ALIGN_BUF(buf, alignof(uint16_t));\n+    const uint16_t *arrays = (const uint16_t *)buf;\n+    buf += total_sizes[ARRAY_CONTAINER_TYPE];\n+    if (maxbytes < (uint64_t)(buf - before_containers)) {\n+        roaring64_bitmap_free(r);\n+        return NULL;\n+    }\n+    maxbytes -= buf - before_containers;\n+\n+    // Deserialize in ART iteration order.\n+    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    for (size_t i = 0; it.value != NULL; ++i) {\n+        leaf_t leaf = (leaf_t)*it.value;\n+        uint8_t typecode = get_typecode(leaf);\n+\n+        uint16_t compressed_elem_count;\n+        memcpy(&compressed_elem_count, elem_counts + (i * sizeof(uint16_t)),\n+               sizeof(compressed_elem_count));\n+        uint32_t elem_count = (uint32_t)(compressed_elem_count) + 1;\n+\n+        // The container index is unrelated to the iteration order.\n+        uint64_t index = get_index(leaf);\n+        r->containers[index] = container_frozen_view(typecode, elem_count,\n+                                                     &bitsets, &arrays, &runs);\n+\n+        art_iterator_next(&it);\n+    }\n+\n+    // Padding to make overall size a multiple of required alignment.\n+    buf = CROARING_ALIGN_BUF(buf, CROARING_BITSET_ALIGNMENT);\n+\n+    return r;\n+}\n+\n bool roaring64_bitmap_iterate(const roaring64_bitmap_t *r,\n                               roaring_iterator64 iterator, void *ptr) {\n-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);\n+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);\n     while (it.value != NULL) {\n         uint64_t high48 = combine_key(it.key, 0);\n         uint64_t high32 = high48 & 0xFFFFFFFF00000000ULL;\n         uint32_t low32 = high48;\n-        leaf_t *leaf = (leaf_t *)it.value;\n-        if (!container_iterate64(leaf->container, leaf->typecode, low32,\n-                                 iterator, high32, ptr)) {\n+        leaf_t leaf = (leaf_t)*it.value;\n+        if (!container_iterate64(get_container(r, leaf), get_typecode(leaf),\n+                                 low32, iterator, high32, ptr)) {\n             return false;\n         }\n         art_iterator_next(&it);\n@@ -2071,12 +2590,12 @@ bool roaring64_iterator_advance(roaring64_iterator_t *it) {\n         if (it->saturated_forward) {\n             return (it->has_value = false);\n         }\n-        roaring64_iterator_init_at(it->parent, it, /*first=*/true);\n+        roaring64_iterator_init_at(it->r, it, /*first=*/true);\n         return it->has_value;\n     }\n-    leaf_t *leaf = (leaf_t *)it->art_it.value;\n+    leaf_t leaf = (leaf_t)*it->art_it.value;\n     uint16_t low16 = (uint16_t)it->value;\n-    if (container_iterator_next(leaf->container, leaf->typecode,\n+    if (container_iterator_next(get_container(it->r, leaf), get_typecode(leaf),\n                                 &it->container_it, &low16)) {\n         it->value = it->high48 | low16;\n         return (it->has_value = true);\n@@ -2094,12 +2613,12 @@ bool roaring64_iterator_previous(roaring64_iterator_t *it) {\n             // Saturated backward.\n             return (it->has_value = false);\n         }\n-        roaring64_iterator_init_at(it->parent, it, /*first=*/false);\n+        roaring64_iterator_init_at(it->r, it, /*first=*/false);\n         return it->has_value;\n     }\n-    leaf_t *leaf = (leaf_t *)it->art_it.value;\n+    leaf_t leaf = (leaf_t)*it->art_it.value;\n     uint16_t low16 = (uint16_t)it->value;\n-    if (container_iterator_prev(leaf->container, leaf->typecode,\n+    if (container_iterator_prev(get_container(it->r, leaf), get_typecode(leaf),\n                                 &it->container_it, &low16)) {\n         it->value = it->high48 | low16;\n         return (it->has_value = true);\n@@ -2117,8 +2636,8 @@ bool roaring64_iterator_move_equalorlarger(roaring64_iterator_t *it,\n     uint16_t val_low16 = split_key(val, val_high48);\n     if (!it->has_value || it->high48 != (val & 0xFFFFFFFFFFFF0000)) {\n         // The ART iterator is before or after the high48 bits of `val` (or\n-        // beyond the ART altogether), so we need to move to a leaf with a key\n-        // equal or greater.\n+        // beyond the ART altogether), so we need to move to a leaf with a\n+        // key equal or greater.\n         if (!art_iterator_lower_bound(&it->art_it, val_high48)) {\n             // Only smaller keys found.\n             it->saturated_forward = true;\n@@ -2129,13 +2648,13 @@ bool roaring64_iterator_move_equalorlarger(roaring64_iterator_t *it,\n     }\n \n     if (it->high48 == (val & 0xFFFFFFFFFFFF0000)) {\n-        // We're at equal high bits, check if a suitable value can be found in\n-        // this container.\n-        leaf_t *leaf = (leaf_t *)it->art_it.value;\n+        // We're at equal high bits, check if a suitable value can be found\n+        // in this container.\n+        leaf_t leaf = (leaf_t)*it->art_it.value;\n         uint16_t low16 = (uint16_t)it->value;\n-        if (container_iterator_lower_bound(leaf->container, leaf->typecode,\n-                                           &it->container_it, &low16,\n-                                           val_low16)) {\n+        if (container_iterator_lower_bound(\n+                get_container(it->r, leaf), get_typecode(leaf),\n+                &it->container_it, &low16, val_low16)) {\n             it->value = it->high48 | low16;\n             return (it->has_value = true);\n         }\n@@ -2146,8 +2665,8 @@ bool roaring64_iterator_move_equalorlarger(roaring64_iterator_t *it,\n         }\n     }\n \n-    // We're at a leaf with high bits greater than `val`, so the first entry in\n-    // this container is our result.\n+    // We're at a leaf with high bits greater than `val`, so the first entry\n+    // in this container is our result.\n     return roaring64_iterator_init_at_leaf_first(it);\n }\n \n@@ -2156,15 +2675,15 @@ uint64_t roaring64_iterator_read(roaring64_iterator_t *it, uint64_t *buf,\n     uint64_t consumed = 0;\n     while (it->has_value && consumed < count) {\n         uint32_t container_consumed;\n-        leaf_t *leaf = (leaf_t *)it->art_it.value;\n+        leaf_t leaf = (leaf_t)*it->art_it.value;\n         uint16_t low16 = (uint16_t)it->value;\n         uint32_t container_count = UINT32_MAX;\n         if (count - consumed < (uint64_t)UINT32_MAX) {\n             container_count = count - consumed;\n         }\n         bool has_value = container_iterator_read_into_uint64(\n-            leaf->container, leaf->typecode, &it->container_it, it->high48, buf,\n-            container_count, &container_consumed, &low16);\n+            get_container(it->r, leaf), get_typecode(leaf), &it->container_it,\n+            it->high48, buf, container_count, &container_consumed, &low16);\n         consumed += container_consumed;\n         buf += container_consumed;\n         if (has_value) {\ndiff --git a/contrib/libs/croaring/ya.make b/contrib/libs/croaring/ya.make\nindex b50e7eaa5e36..90f16b7b3d28 100644\n--- a/contrib/libs/croaring/ya.make\n+++ b/contrib/libs/croaring/ya.make\n@@ -10,9 +10,9 @@ LICENSE(\n \n LICENSE_TEXTS(.yandex_meta/licenses.list.txt)\n \n-VERSION(4.2.3)\n+VERSION(4.3.0)\n \n-ORIGINAL_SOURCE(https://github.com/RoaringBitmap/CRoaring/archive/v4.2.3.tar.gz)\n+ORIGINAL_SOURCE(https://github.com/RoaringBitmap/CRoaring/archive/v4.3.0.tar.gz)\n \n ADDINCL(\n     GLOBAL contrib/libs/croaring/include\ndiff --git a/contrib/libs/cxxsupp/builtins/.yandex_meta/build.ym b/contrib/libs/cxxsupp/builtins/.yandex_meta/build.ym\nindex c2747e3d677f..04bc79b0c71c 100644\n--- a/contrib/libs/cxxsupp/builtins/.yandex_meta/build.ym\n+++ b/contrib/libs/cxxsupp/builtins/.yandex_meta/build.ym\n@@ -1,6 +1,6 @@\n {% extends '//builtin/bag.ym' %}\n \n-{% block current_version %}19.1.7{% endblock %}\n+{% block current_version %}20.1.0{% endblock %}\n \n {% block current_url %}\n https://github.com/llvm/llvm-project/releases/download/llvmorg-{{self.version().strip()}}/compiler-rt-{{self.version().strip()}}.src.tar.xz\n@@ -12,6 +12,7 @@ rm CMakeLists.txt\n cd lib/builtins\n rm CMakeLists.txt\n rm aarch64/lse.S\n+sed -e 's|.*#include.*ptrauth.h.*||' -i crtbegin.c\n sed -e 's|.*#include.*sys/byteorder.h.*||' -i int_endianness.h\n sed -e 's|.*#include.*zircon/features.h.*||' -i cpu_model/aarch64/fmv/fuchsia.inc\n sed -e 's|.*#include.*zircon/features.h.*||' -i cpu_model/aarch64/lse_atomics/fuchsia.inc\n@@ -87,7 +88,7 @@ def name(n):\n sset = frozenset([name(x) for x in special])\n scrt = frozenset(['crtbegin', 'crtend'])\n # x86_80_BIT_SOURCES\n-x86_not_win = frozenset(['divxc3', 'extendxftf2', 'fixxfdi', 'fixxfti', 'fixunsxfdi', 'fixunsxfsi', 'fixunsxfti', 'floatdixf', 'floattixf', 'floatundixf', 'floatuntixf', 'mulxc3', 'powixf2', 'trunctfxf2'])\n+x86_not_win = frozenset(['divxc3', 'extendhfxf2', 'extendxftf2', 'fixxfdi', 'fixxfti', 'fixunsxfdi', 'fixunsxfsi', 'fixunsxfti', 'floatdixf', 'floattixf', 'floatundixf', 'floatuntixf', 'mulxc3', 'powixf2', 'trunctfxf2', 'truncxfhf2'])\n other_not_emscripten = frozenset([\n     'clear_cache',\n     'emutls',\n@@ -142,9 +143,9 @@ IF (ARCH_ARM64 OR ARCH_X86_64)\n             # NB: sources that were commented out were added in llvm-20\n             extendbfsf2.c\n             truncdfbf2.c\n-            # truncxfbf2.c\n+            truncxfbf2.c\n             truncsfbf2.c\n-            # trunctfbf2.c\n+            trunctfbf2.c\n         )\n     ENDIF()\n ENDIF()\ndiff --git a/contrib/libs/cxxsupp/builtins/.yandex_meta/devtools.licenses.report b/contrib/libs/cxxsupp/builtins/.yandex_meta/devtools.licenses.report\nindex 874c592edd9e..abc5575fe213 100644\n--- a/contrib/libs/cxxsupp/builtins/.yandex_meta/devtools.licenses.report\n+++ b/contrib/libs/cxxsupp/builtins/.yandex_meta/devtools.licenses.report\n@@ -102,8 +102,7 @@ BELONGS ya.make\n     Files with this license:\n         aarch64/chkstk.S [1:2]\n         aarch64/fp_mode.c [3:4]\n-        aarch64/sme-abi-init.c [1:2]\n-        aarch64/sme-abi-vg.c [1:2]\n+        aarch64/sme-abi-assert.c [1:2]\n         aarch64/sme-abi.S [1:2]\n         aarch64/sme-libc-mem-routines.S [1:2]\n         absvdi2.c [3:4]\n@@ -243,6 +242,7 @@ BELONGS ya.make\n         cpu_model/aarch64.c [3:4]\n         cpu_model/aarch64.h [3:4]\n         cpu_model/cpu_model.h [3:4]\n+        cpu_model/riscv.c [3:4]\n         cpu_model/x86.c [3:4]\n         crtbegin.c [3:4]\n         crtend.c [3:4]\n@@ -268,6 +268,7 @@ BELONGS ya.make\n         extendbfsf2.c [3:4]\n         extenddftf2.c [3:4]\n         extendhfsf2.c [3:4]\n+        extendhfxf2.c [3:4]\n         extendsfdf2.c [3:4]\n         extendsftf2.c [3:4]\n         extendxftf2.c [3:4]\n@@ -458,9 +459,12 @@ BELONGS ya.make\n         truncdfsf2.c [3:4]\n         truncsfbf2.c [3:4]\n         truncsfhf2.c [3:4]\n+        trunctfbf2.c [3:4]\n         trunctfdf2.c [3:4]\n         trunctfsf2.c [3:4]\n         trunctfxf2.c [3:4]\n+        truncxfbf2.c [3:4]\n+        truncxfhf2.c [3:4]\n         ucmpdi2.c [3:4]\n         ucmpti2.c [3:4]\n         udivdi3.c [3:4]\n@@ -490,8 +494,7 @@ BELONGS ya.make\n     Files with this license:\n         aarch64/chkstk.S [1:2]\n         aarch64/fp_mode.c [3:4]\n-        aarch64/sme-abi-init.c [1:2]\n-        aarch64/sme-abi-vg.c [1:2]\n+        aarch64/sme-abi-assert.c [1:2]\n         aarch64/sme-abi.S [1:2]\n         aarch64/sme-libc-mem-routines.S [1:2]\n         absvdi2.c [3:4]\n@@ -631,6 +634,7 @@ BELONGS ya.make\n         cpu_model/aarch64.c [3:4]\n         cpu_model/aarch64.h [3:4]\n         cpu_model/cpu_model.h [3:4]\n+        cpu_model/riscv.c [3:4]\n         cpu_model/x86.c [3:4]\n         crtbegin.c [3:4]\n         crtend.c [3:4]\n@@ -656,6 +660,7 @@ BELONGS ya.make\n         extendbfsf2.c [3:4]\n         extenddftf2.c [3:4]\n         extendhfsf2.c [3:4]\n+        extendhfxf2.c [3:4]\n         extendsfdf2.c [3:4]\n         extendsftf2.c [3:4]\n         extendxftf2.c [3:4]\n@@ -846,9 +851,12 @@ BELONGS ya.make\n         truncdfsf2.c [3:4]\n         truncsfbf2.c [3:4]\n         truncsfhf2.c [3:4]\n+        trunctfbf2.c [3:4]\n         trunctfdf2.c [3:4]\n         trunctfsf2.c [3:4]\n         trunctfxf2.c [3:4]\n+        truncxfbf2.c [3:4]\n+        truncxfhf2.c [3:4]\n         ucmpdi2.c [3:4]\n         ucmpti2.c [3:4]\n         udivdi3.c [3:4]\n@@ -936,8 +944,7 @@ BELONGS ya.make\n     Files with this license:\n         aarch64/chkstk.S [3:3]\n         aarch64/fp_mode.c [5:5]\n-        aarch64/sme-abi-init.c [3:3]\n-        aarch64/sme-abi-vg.c [3:3]\n+        aarch64/sme-abi-assert.c [3:3]\n         aarch64/sme-abi.S [3:3]\n         aarch64/sme-libc-mem-routines.S [3:3]\n         absvdi2.c [5:5]\n@@ -1077,6 +1084,7 @@ BELONGS ya.make\n         cpu_model/aarch64.c [5:5]\n         cpu_model/aarch64.h [5:5]\n         cpu_model/cpu_model.h [5:5]\n+        cpu_model/riscv.c [5:5]\n         cpu_model/x86.c [5:5]\n         crtbegin.c [5:5]\n         crtend.c [5:5]\n@@ -1102,6 +1110,7 @@ BELONGS ya.make\n         extendbfsf2.c [5:5]\n         extenddftf2.c [5:5]\n         extendhfsf2.c [5:5]\n+        extendhfxf2.c [5:5]\n         extendsfdf2.c [5:5]\n         extendsftf2.c [5:5]\n         extendxftf2.c [5:5]\n@@ -1292,9 +1301,12 @@ BELONGS ya.make\n         truncdfsf2.c [5:5]\n         truncsfbf2.c [5:5]\n         truncsfhf2.c [5:5]\n+        trunctfbf2.c [5:5]\n         trunctfdf2.c [5:5]\n         trunctfsf2.c [5:5]\n         trunctfxf2.c [5:5]\n+        truncxfbf2.c [5:5]\n+        truncxfhf2.c [5:5]\n         ucmpdi2.c [5:5]\n         ucmpti2.c [5:5]\n         udivdi3.c [5:5]\n@@ -1324,8 +1336,7 @@ BELONGS ya.make\n     Files with this license:\n         aarch64/chkstk.S [3:3]\n         aarch64/fp_mode.c [5:5]\n-        aarch64/sme-abi-init.c [3:3]\n-        aarch64/sme-abi-vg.c [3:3]\n+        aarch64/sme-abi-assert.c [3:3]\n         aarch64/sme-abi.S [3:3]\n         aarch64/sme-libc-mem-routines.S [3:3]\n         absvdi2.c [5:5]\n@@ -1465,6 +1476,7 @@ BELONGS ya.make\n         cpu_model/aarch64.c [5:5]\n         cpu_model/aarch64.h [5:5]\n         cpu_model/cpu_model.h [5:5]\n+        cpu_model/riscv.c [5:5]\n         cpu_model/x86.c [5:5]\n         crtbegin.c [5:5]\n         crtend.c [5:5]\n@@ -1490,6 +1502,7 @@ BELONGS ya.make\n         extendbfsf2.c [5:5]\n         extenddftf2.c [5:5]\n         extendhfsf2.c [5:5]\n+        extendhfxf2.c [5:5]\n         extendsfdf2.c [5:5]\n         extendsftf2.c [5:5]\n         extendxftf2.c [5:5]\n@@ -1680,9 +1693,12 @@ BELONGS ya.make\n         truncdfsf2.c [5:5]\n         truncsfbf2.c [5:5]\n         truncsfhf2.c [5:5]\n+        trunctfbf2.c [5:5]\n         trunctfdf2.c [5:5]\n         trunctfsf2.c [5:5]\n         trunctfxf2.c [5:5]\n+        truncxfbf2.c [5:5]\n+        truncxfhf2.c [5:5]\n         ucmpdi2.c [5:5]\n         ucmpti2.c [5:5]\n         udivdi3.c [5:5]\ndiff --git a/contrib/libs/cxxsupp/builtins/CODE_OWNERS.TXT b/contrib/libs/cxxsupp/builtins/CODE_OWNERS.TXT\ndeleted file mode 100644\nindex bd51a1073cc3..000000000000\n--- a/contrib/libs/cxxsupp/builtins/CODE_OWNERS.TXT\n+++ /dev/null\n@@ -1,77 +0,0 @@\n-This file is a list of the people responsible for ensuring that patches for a\n-particular part of compiler-rt are reviewed, either by themself or by\n-someone else. They are also the gatekeepers for their part of compiler-rt, with\n-the final word on what goes in or not.\n-\n-The list is sorted by surname and formatted to allow easy grepping and\n-beautification by scripts. The fields are: name (N), email (E), web-address\n-(W), PGP key ID and fingerprint (P), description (D), and snail-mail address\n-(S).\n-\n-N: Saleem Abdulrasool\n-E: compnerd@compnerd.org\n-D: builtins library\n-\n-N: Andrew Browne\n-E: browneee@google.com\n-D: DataFlowSanitizer\n-\n-N: Vitaly Buka\n-E: vitalybuka@google.com\n-D: Sanitizers\n-\n-N: Peter Collingbourne\n-E: peter@pcc.me.uk\n-D: CFI, SafeStack\n-\n-N: Lang Hames\n-E: lhames@gmail.com\n-D: ORC\n-\n-N: Petr Hosek\n-E: phosek@google.com\n-D: CRT, CMake build\n-\n-N: Teresa Johnson\n-E: tejohnson@google.com\n-D: MemProf\n-\n-N: Kostya Kortchinsky\n-E: kostya.kortchinsky@gmail.com\n-D: SCUDO\n-\n-N: Mitch Phillips\n-E: mitchp@google.com\n-D: GWP ASAN\n-\n-N: Alexander Potapenko\n-E: glider@google.com\n-D: Sanitizers\n-\n-N: Kostya Serebryany\n-E: kcc@google.com\n-D: AddressSanitizer, sanitizer_common, LeakSanitizer, LibFuzzer\n-\n-N: Richard Smith\n-E: richard-llvm@metafoo.co.uk\n-D: UndefinedBehaviorSanitizer\n-\n-N: Evgeniy Stepanov\n-E: eugenis@google.com\n-D: MemorySanitizer, Android port of sanitizers\n-\n-N: Dmitry Vyukov\n-E: dvyukov@google.com\n-D: ThreadSanitizer\n-\n-N: Bill Wendling\n-E: isanbard@gmail.com\n-D: Profile runtime library\n-\n-N: Christopher Apple, David Trevelyan\n-E: cja-private@pm.me, realtime.sanitizer@gmail.com\n-D: Realtime Sanitizer (RTSan)\n-\n-N: Alexander Shaposhnikov\n-E: alexander.v.shaposhnikov@gmail.com\n-D: Numerical Sanitizer (NSAN)\ndiff --git a/contrib/libs/cxxsupp/builtins/Maintainers.md b/contrib/libs/cxxsupp/builtins/Maintainers.md\nnew file mode 100644\nindex 000000000000..5faf6741c467\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/Maintainers.md\n@@ -0,0 +1,110 @@\n+# Compiler-rt maintainers\n+\n+This file is a list of the\n+[maintainers](https://llvm.org/docs/DeveloperPolicy.html#maintainers) for\n+LLVM compiler-rt.\n+\n+## Current Maintainers\n+\n+The following people are the active maintainers for the project. Please reach\n+out to them for code reviews, questions about their area of expertise, or other\n+assistance.\n+\n+### Builtins Library\n+\n+Saleem Abdulrasool \\\n+compnerd@compnerd.org (email), [compnerd](https://github.com/compnerd) (GitHub)\n+\n+### CFI\n+\n+Peter Collingbourne \\\n+peter@pcc.me.uk (email), [pcc](https://github.com/pcc) (GitHub)\n+\n+### CMake build\n+\n+Petr Hosek \\\n+phosek@google.com (email), [petrhosek](https://github.com/petrhosek) (GitHub)\n+\n+### CRT\n+\n+Petr Hosek \\\n+phosek@google.com (email), [petrhosek](https://github.com/petrhosek) (GitHub)\n+\n+### GWP ASAN\n+\n+Christopher Ferris \\\n+cferris@google.com (email), [cferris1000](https://github.com/cferris1000) (GitHub)\n+\n+### MemProfiling\n+\n+Teresa Johnson \\\n+tejohnson@google.com (email), [teresajohnson](https://github.com/teresajohnson) (GitHub)\n+\n+### SafeStack\n+\n+Peter Collingbourne \\\n+peter@pcc.me.uk (email), [pcc](https://github.com/pcc) (GitHub)\n+\n+### Sanitizers\n+\n+#### Sanitizers not covered by someone else\n+\n+Vitaly Buka \\\n+vitalybuka@google.com (email), [vitalybuka](https://github.com/vitalybuka) (GitHub) \\\n+Alexander Potapenko \\\n+glider@google.com (email), [ramosian-glider](https://github.com/ramosian-glider) (GitHub)\n+\n+#### Data Flow Sanitizer\n+\n+Andrew Browne \\\n+browneee@google.com (email), [browneee](https://github.com/browneee) (GitHub)\n+\n+#### Numerical Sanitizer (NSAN)\n+\n+Alexander Shaposhnikov \\\n+alexander.v.shaposhnikov@gmail.com (email), [alexander-shaposhnikov](https://github.com/alexander-shaposhnikov) (GitHub)\n+\n+#### Realtime Sanitizer (RTSan)\n+\n+Christopher Apple \\\n+cja-private@pm.me (email), [cjappl](https://github.com/cjappl) (GitHub) \\\n+David Trevelyan \\\n+david.trevelyan@gmail.com (email), [davidtrevelyan](https://github.com/davidtrevelyan) (GitHub)\n+\n+#### Thread Sanitizer\n+\n+Dmitry Vyukov \\\n+dvyukov@google.com (email), [dvyukov](https://github.com/dvyukov) (GitHub)\n+\n+#### Undefined Behavior Sanitizer\n+\n+Richard Smith \\\n+richard-llvm@metafoo.co.uk (email), [zygoloid](https://github.com/zygoloid) (GitHub)\n+\n+### ORC\n+\n+Lang Hames \\\n+lhames@gmail.com (email), [lhames](https://github.com/lhames) (GitHub)\n+\n+### Profile runtime library\n+\n+Bill Wendling \\\n+isanbard@gmail.com (email), [isanbard](https://github.com/isanbard) (GitHub)\n+\n+### SCUDO\n+\n+Christopher Ferris \\\n+cferris@google.com (email), [cferris1000](https://github.com/cferris1000) (GitHub)\n+\n+## Inactive Maintainers\n+\n+The following people have graciously spent time performing maintainer\n+responsibilities but are no longer active in that role. Thank you for all your\n+help with the success of the project!\n+\n+### Inactive or former component maintainers\n+\n+Kostya Serebryany ([kcc](https://github.com/kcc)) -- Sanitizers \\\n+Evgeniy Stepanov ([eugenis](https://github.com/eugenis)) -- Sanitizers \\\n+Kostya Kortchinsky ([cryptoad](https://github.com/cryptoad)) -- SCUDO \\\n+Mitch Phillips ([hctim](https://github.com/hctim)) -- GWP ASAN\ndiff --git a/contrib/libs/cxxsupp/builtins/aarch64/arm_apple_sme_abi.s b/contrib/libs/cxxsupp/builtins/aarch64/arm_apple_sme_abi.s\nnew file mode 100644\nindex 000000000000..f0ccaaf4cdbc\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/aarch64/arm_apple_sme_abi.s\n@@ -0,0 +1,129 @@\n+#include \"../assembly.h\"\n+\n+.arch armv8-a+sme2\n+\n+// For Apple platforms at the moment, we just call abort() directly\n+// after stopping SM mode unconditionally.\n+.p2align 2\n+DEFINE_COMPILERRT_PRIVATE_FUNCTION(do_abort)\n+.cfi_startproc\n+\t.variant_pcs\tSYMBOL_NAME(do_abort)\n+\tstp\tx29, x30, [sp, #-32]!\n+  .cfi_def_cfa_offset 32\n+  .cfi_offset w30, -24\n+  .cfi_offset w29, -32\n+\tsmstop sm\n+\tbl\tSYMBOL_NAME(abort)\n+.cfi_endproc\n+END_COMPILERRT_FUNCTION(do_abort)\n+\n+DEFINE_COMPILERRT_FUNCTION(__arm_tpidr2_save)\n+  // If TPIDR2_EL0 is null, the subroutine does nothing.\n+  mrs x16, TPIDR2_EL0\n+  cbz x16, 1f\n+\n+  // If any of the reserved bytes in the first 16 bytes of the TPIDR2 block are\n+  // nonzero, the subroutine [..] aborts in some platform-defined manner.\n+  ldrh  w14, [x16, #10]\n+  cbnz  w14, 2f\n+  ldr w14, [x16, #12]\n+  cbnz  w14, 2f\n+\n+  // If za_save_buffer is NULL, the subroutine does nothing.\n+  ldr x14, [x16]\n+  cbz x14, 1f\n+\n+  // If num_za_save_slices is zero, the subroutine does nothing.\n+  ldrh  w14, [x16, #8]\n+  cbz x14, 1f\n+\n+  mov x15, xzr\n+  ldr x16, [x16]\n+0:\n+  str za[w15,0], [x16]\n+  addsvl x16, x16, #1\n+  add x15, x15, #1\n+  cmp x14, x15\n+  b.ne  0b\n+1:\n+  ret\n+2:\n+  b  SYMBOL_NAME(do_abort)\n+END_COMPILERRT_FUNCTION(__arm_tpidr2_save)\n+\n+.p2align 2\n+DEFINE_COMPILERRT_FUNCTION(__arm_za_disable)\n+.cfi_startproc\n+  // Otherwise, the subroutine behaves as if it did the following:\n+  // * Call __arm_tpidr2_save.\n+  stp x29, x30, [sp, #-16]!\n+  .cfi_def_cfa_offset 16\n+  mov x29, sp\n+  .cfi_def_cfa w29, 16\n+  .cfi_offset w30, -8\n+  .cfi_offset w29, -16\n+  bl  SYMBOL_NAME(__arm_tpidr2_save)\n+\n+  // * Set TPIDR2_EL0 to null.\n+  msr TPIDR2_EL0, xzr\n+\n+  // * Set PSTATE.ZA to 0.\n+  smstop za\n+\n+  .cfi_def_cfa wsp, 16\n+  ldp x29, x30, [sp], #16\n+  .cfi_def_cfa_offset 0\n+  .cfi_restore w30\n+  .cfi_restore w29\n+0:\n+  ret\n+.cfi_endproc\n+END_COMPILERRT_FUNCTION(__arm_za_disable)\n+\n+.p2align 2\n+DEFINE_COMPILERRT_FUNCTION(__arm_tpidr2_restore)\n+.cfi_startproc\n+  .variant_pcs\tSYMBOL_NAME(__arm_tpidr2_restore)\n+  // If TPIDR2_EL0 is nonnull, the subroutine aborts in some platform-specific\n+  // manner.\n+  mrs x14, TPIDR2_EL0\n+  cbnz  x14, 2f\n+\n+  // If any of the reserved bytes in the first 16 bytes of BLK are nonzero,\n+  // the subroutine [..] aborts in some platform-defined manner.\n+  ldrh  w14, [x0, #10]\n+  cbnz  w14, 2f\n+  ldr w14, [x0, #12]\n+  cbnz  w14, 2f\n+\n+  // If BLK.za_save_buffer is NULL, the subroutine does nothing.\n+  ldr x16, [x0]\n+  cbz x16, 1f\n+\n+  // If BLK.num_za_save_slices is zero, the subroutine does nothing.\n+  ldrh  w14, [x0, #8]\n+  cbz x14, 1f\n+\n+  mov x15, xzr\n+0:\n+  ldr za[w15,0], [x16]\n+  addsvl x16, x16, #1\n+  add x15, x15, #1\n+  cmp x14, x15\n+  b.ne  0b\n+1:\n+  ret\n+2:\n+  b  SYMBOL_NAME(do_abort)\n+.cfi_endproc\n+END_COMPILERRT_FUNCTION(__arm_tpidr2_restore)\n+\n+.p2align 2\n+DEFINE_COMPILERRT_FUNCTION(__arm_sme_state)\n+\t.variant_pcs\tSYMBOL_NAME(__arm_sme_state)\n+  orr x0, x0, #0xC000000000000000\n+  mrs x16, SVCR\n+  bfxil x0, x16, #0, #2\n+  mrs x1, TPIDR2_EL0\n+  ret\n+END_COMPILERRT_FUNCTION(__arm_sme_state)\ndiff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-assert.c b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-assert.c\nnew file mode 100644\nindex 000000000000..37305ceb39c5\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-assert.c\n@@ -0,0 +1,11 @@\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+\n+// We rely on the FMV __aarch64_cpu_features mechanism to determine\n+// which features are set at runtime.\n+\n+#include \"../cpu_model/AArch64CPUFeatures.inc\"\n+_Static_assert(FEAT_SVE == 30, \"sme-abi.S assumes FEAT_SVE = 30\");\n+_Static_assert(FEAT_SME == 42, \"sme-abi.S assumes FEAT_SME = 42\");\n+_Static_assert(FEAT_SME2 == 57, \"sme-abi.S assumes FEAT_SME2 = 57\");\ndiff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-init.c b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-init.c\ndeleted file mode 100644\nindex b6ee12170d56..000000000000\n--- a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-init.c\n+++ /dev/null\n@@ -1,52 +0,0 @@\n-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n-// See https://llvm.org/LICENSE.txt for license information.\n-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n-\n-__attribute__((visibility(\"hidden\"), nocommon))\n-_Bool __aarch64_has_sme_and_tpidr2_el0;\n-\n-// We have multiple ways to check that the function has SME, depending on our\n-// target.\n-// * For Linux we can use __getauxval().\n-// * For newlib we can use __aarch64_sme_accessible().\n-\n-#if defined(__linux__)\n-\n-#ifndef AT_HWCAP2\n-#define AT_HWCAP2 26\n-#endif\n-\n-#ifndef HWCAP2_SME\n-#define HWCAP2_SME (1 << 23)\n-#endif\n-\n-extern unsigned long int __getauxval (unsigned long int);\n-\n-static _Bool has_sme(void) {\n-  return __getauxval(AT_HWCAP2) & HWCAP2_SME;\n-}\n-\n-#else  // defined(__linux__)\n-\n-#if defined(COMPILER_RT_SHARED_LIB)\n-__attribute__((weak))\n-#endif\n-extern _Bool __aarch64_sme_accessible(void);\n-\n-static _Bool has_sme(void)  {\n-#if defined(COMPILER_RT_SHARED_LIB)\n-  if (!__aarch64_sme_accessible)\n-    return 0;\n-#endif\n-  return __aarch64_sme_accessible();\n-}\n-\n-#endif // defined(__linux__)\n-\n-#if __GNUC__ >= 9\n-#pragma GCC diagnostic ignored \"-Wprio-ctor-dtor\"\n-#endif\n-__attribute__((constructor(90)))\n-static void init_aarch64_has_sme(void) {\n-  __aarch64_has_sme_and_tpidr2_el0 = has_sme();\n-}\ndiff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-vg.c b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-vg.c\ndeleted file mode 100644\nindex 20061012e16c..000000000000\n--- a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-vg.c\n+++ /dev/null\n@@ -1,21 +0,0 @@\n-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n-// See https://llvm.org/LICENSE.txt for license information.\n-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n-\n-#include \"../cpu_model/aarch64.h\"\n-\n-struct FEATURES {\n-  unsigned long long features;\n-};\n-\n-extern struct FEATURES __aarch64_cpu_features;\n-\n-#if __GNUC__ >= 9\n-#pragma GCC diagnostic ignored \"-Wprio-ctor-dtor\"\n-#endif\n-__attribute__((constructor(90))) static void get_aarch64_cpu_features(void) {\n-  if (__atomic_load_n(&__aarch64_cpu_features.features, __ATOMIC_RELAXED))\n-    return;\n-\n-  __init_cpu_features();\n-}\ndiff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi.S b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi.S\nindex cd8153f60670..8dbbe061edb9 100644\n--- a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi.S\n+++ b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi.S\n@@ -8,22 +8,23 @@\n \n #include \"../assembly.h\"\n \n+.set FEAT_SVE_BIT, 30\n+.set FEAT_SME_BIT, 42\n+.set FEAT_SME2_BIT, 57\n+.set FEAT_SME2_MASK, 1 << 57\n+.set SVCR_PSTATE_SM_BIT, 0\n \n #if !defined(__APPLE__)\n-#define TPIDR2_SYMBOL SYMBOL_NAME(__aarch64_has_sme_and_tpidr2_el0)\n-#define TPIDR2_SYMBOL_OFFSET :lo12:SYMBOL_NAME(__aarch64_has_sme_and_tpidr2_el0)\n #define CPU_FEATS_SYMBOL SYMBOL_NAME(__aarch64_cpu_features)\n #define CPU_FEATS_SYMBOL_OFFSET :lo12:SYMBOL_NAME(__aarch64_cpu_features)\n #else\n // MachO requires @page/@pageoff directives because the global is defined\n // in a different file. Otherwise this file may fail to build.\n-#define TPIDR2_SYMBOL SYMBOL_NAME(__aarch64_has_sme_and_tpidr2_el0)@page\n-#define TPIDR2_SYMBOL_OFFSET SYMBOL_NAME(__aarch64_has_sme_and_tpidr2_el0)@pageoff\n #define CPU_FEATS_SYMBOL SYMBOL_NAME(__aarch64_cpu_features)@page\n #define CPU_FEATS_SYMBOL_OFFSET SYMBOL_NAME(__aarch64_cpu_features)@pageoff\n #endif\n \n-.arch armv9-a+sme\n+.arch armv9-a+sme2\n \n // Utility function which calls a system's abort() routine. Because the function\n // is streaming-compatible it should disable streaming-SVE mode before calling\n@@ -41,7 +42,7 @@ DEFINE_COMPILERRT_PRIVATE_FUNCTION(do_abort)\n   .cfi_offset w30, -24\n   .cfi_offset w29, -32\n   .cfi_offset 46, -16\n-  bl  __arm_sme_state\n+  bl  SYMBOL_NAME(__arm_sme_state)\n   tbz  x0, #0, 2f\n 1:\n   smstop sm\n@@ -55,15 +56,15 @@ END_COMPILERRT_FUNCTION(do_abort)\n // __arm_sme_state fills the result registers based on a local\n // that is set as part of the compiler-rt startup code.\n //   __aarch64_has_sme_and_tpidr2_el0\n-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sme_state)\n+DEFINE_COMPILERRT_FUNCTION(__arm_sme_state)\n   .variant_pcs __arm_sme_state\n   BTI_C\n   mov x0, xzr\n   mov x1, xzr\n \n-  adrp  x16, TPIDR2_SYMBOL\n-  ldrb w16, [x16, TPIDR2_SYMBOL_OFFSET]\n-  cbz w16, 1f\n+  adrp x16, CPU_FEATS_SYMBOL\n+  ldr x16, [x16, CPU_FEATS_SYMBOL_OFFSET]\n+  tbz x16, #FEAT_SME_BIT, 1f\n 0:\n   orr x0, x0, #0xC000000000000000\n   mrs x16, SVCR\n@@ -71,9 +72,9 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sme_state)\n   mrs x1, TPIDR2_EL0\n 1:\n   ret\n-END_COMPILERRT_OUTLINE_FUNCTION(__arm_sme_state)\n+END_COMPILERRT_FUNCTION(__arm_sme_state)\n \n-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_tpidr2_restore)\n+DEFINE_COMPILERRT_FUNCTION(__arm_tpidr2_restore)\n   .variant_pcs __arm_tpidr2_restore\n   BTI_C\n   // If TPIDR2_EL0 is nonnull, the subroutine aborts in some platform-specific\n@@ -107,16 +108,16 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_tpidr2_restore)\n   ret\n 2:\n   b  SYMBOL_NAME(do_abort)\n-END_COMPILERRT_OUTLINE_FUNCTION(__arm_tpidr2_restore)\n+END_COMPILERRT_FUNCTION(__arm_tpidr2_restore)\n \n-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_tpidr2_save)\n-  .variant_pcs __arm_tpidr2_restore\n+DEFINE_COMPILERRT_FUNCTION(__arm_tpidr2_save)\n+  .variant_pcs __arm_tpidr2_save\n   BTI_C\n   // If the current thread does not have access to TPIDR2_EL0, the subroutine\n   // does nothing.\n-  adrp  x14, TPIDR2_SYMBOL\n-  ldrb w14, [x14, TPIDR2_SYMBOL_OFFSET]\n-  cbz w14, 1f\n+  adrp x14, CPU_FEATS_SYMBOL\n+  ldr x14, [x14, CPU_FEATS_SYMBOL_OFFSET]\n+  tbz x14, #FEAT_SME_BIT, 1f\n \n   // If TPIDR2_EL0 is null, the subroutine does nothing.\n   mrs x16, TPIDR2_EL0\n@@ -148,16 +149,17 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_tpidr2_save)\n   ret\n 2:\n   b  SYMBOL_NAME(do_abort)\n-END_COMPILERRT_OUTLINE_FUNCTION(__arm_tpidr2_save)\n+END_COMPILERRT_FUNCTION(__arm_tpidr2_save)\n \n-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_za_disable)\n-  .variant_pcs __arm_tpidr2_restore\n+DEFINE_COMPILERRT_FUNCTION(__arm_za_disable)\n+  .cfi_startproc\n+  .variant_pcs __arm_za_disable\n   BTI_C\n   // If the current thread does not have access to SME, the subroutine does\n   // nothing.\n-  adrp  x14, TPIDR2_SYMBOL\n-  ldrb w14, [x14, TPIDR2_SYMBOL_OFFSET]\n-  cbz w14, 0f\n+  adrp x14, CPU_FEATS_SYMBOL\n+  ldr x14, [x14, CPU_FEATS_SYMBOL_OFFSET]\n+  tbz x14, #FEAT_SME_BIT, 0f\n \n   // Otherwise, the subroutine behaves as if it did the following:\n   // * Call __arm_tpidr2_save.\n@@ -167,7 +169,7 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_za_disable)\n   .cfi_def_cfa w29, 16\n   .cfi_offset w30, -8\n   .cfi_offset w29, -16\n-  bl  __arm_tpidr2_save\n+  bl  SYMBOL_NAME(__arm_tpidr2_save)\n \n   // * Set TPIDR2_EL0 to null.\n   msr TPIDR2_EL0, xzr\n@@ -182,47 +184,190 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_za_disable)\n   .cfi_restore w29\n 0:\n   ret\n-END_COMPILERRT_OUTLINE_FUNCTION(__arm_za_disable)\n+  .cfi_endproc\n+END_COMPILERRT_FUNCTION(__arm_za_disable)\n \n-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_get_current_vg)\n+DEFINE_COMPILERRT_FUNCTION(__arm_get_current_vg)\n   .variant_pcs __arm_get_current_vg\n   BTI_C\n \n+  adrp    x17, CPU_FEATS_SYMBOL\n+  ldr     x17, [x17, CPU_FEATS_SYMBOL_OFFSET]\n+  tbnz    w17, #FEAT_SVE_BIT, 1f\n+  tbz     x17, #FEAT_SME_BIT, 2f\n+0:\n+  mrs     x17, SVCR\n+  tbz     x17, #SVCR_PSTATE_SM_BIT, 2f\n+1:\n+  cntd    x0\n+  ret\n+2:\n+  mov     x0, xzr\n+  ret\n+END_COMPILERRT_FUNCTION(__arm_get_current_vg)\n+\n+// The diagram below describes the layout used in the following routines:\n+// * __arm_sme_state_size\n+// * __arm_sme_save\n+// * __arm_sme_restore\n+//\n+// +---------------------------------+\n+// |             ...                 |\n+// |           ZA buffer             |\n+// |             ...                 |\n+// +---------------------------------+ <- @96\n+// |         ZT0 contents            |\n+// +---------------------------------+ <- @32\n+// | byte 15-10: zero (reserved)     |\n+// | byte   9-8: num_za_save_slices  |           TPIDR2 block\n+// | byte   7-0: za_save_buffer      |\n+// +---------------------------------+ <- @16\n+// | bit  127-1: zero (reserved)     |           Internal state for __arm_sme_save/restore\n+// | bit      0: VALID               |\n+// +---------------------------------+ <- @0\n+\n+DEFINE_COMPILERRT_FUNCTION(__arm_sme_state_size)\n+  .variant_pcs __arm_sme_state_size\n+  BTI_C\n+\n+  // Test if SME is available and ZA state is 'active'.\n+  adrp    x17, CPU_FEATS_SYMBOL\n+  ldr     x17, [x17, CPU_FEATS_SYMBOL_OFFSET]\n+  tbz     x17, #FEAT_SME_BIT, 0f\n+  mrs     x16, SVCR\n+  tbz     x16, #1, 0f\n+  mrs     x16, TPIDR2_EL0\n+  cbnz    x16, 0f\n+\n+  // Size = HAS_FEAT_SME2 ? 96 : 32\n+  tst     x17, #FEAT_SME2_MASK\n+  mov     w17, #32\n+  mov     w16, #96\n+  csel    x16, x17, x16, eq\n+\n+  // Size = Size + (SVLB * SVLB)\n+  rdsvl   x17, #1\n+  madd    x0, x17, x17, x16\n+  ret\n+\n+0:\n+  // Default case, 16 bytes is minimum (to encode VALID bit, multiple of 16 bytes)\n+  mov w0, #16\n+  ret\n+END_COMPILERRT_FUNCTION(__arm_sme_state_size)\n+\n+DEFINE_COMPILERRT_FUNCTION(__arm_sme_save)\n+  .variant_pcs __arm_sme_save\n+  BTI_C\n+\n+  // If PTR is not 16-byte aligned, abort.\n+  tst     x0, #0xF\n+  b.ne    3f\n+\n+  // Clear internal state bits\n+  stp     xzr, xzr, [x0]\n+\n+  // If SME is not available, PSTATE.ZA = 0 or TPIDR2_EL0 != 0, return.\n+  adrp    x17, CPU_FEATS_SYMBOL\n+  ldr     x17, [x17, CPU_FEATS_SYMBOL_OFFSET]\n+  tbz     x17, #FEAT_SME_BIT, 2f\n+  mrs     x16, SVCR\n+  tbz     x16, #1, 2f\n+  mrs     x16, TPIDR2_EL0\n+  cbnz    x16, 2f\n+\n+  # ZA or ZT0 need saving, we can now set internal VALID bit to 1\n+  mov     w16, #1\n+  str     x16, [x0]\n+\n+  add     x18, x0, #32\n+  tbz     x17, #FEAT_SME2_BIT, 1f\n+\n+  // Store ZT0\n+  str     zt0, [x18]\n+  add     x18, x18, #64\n+\n+1:\n+  // Set up lazy-save (x18 = pointer to buffer)\n+  rdsvl   x17, #1\n+  str     x18, [x0, #16]!\n+  strh    w17, [x0, #8]\n+  strh    wzr, [x0, #10]\n+  str     wzr, [x0, #12]\n+  msr     TPIDR2_EL0, x0\n+\n+2:\n+  // Do nothing\n+  ret\n+\n+3:\n+  b       SYMBOL_NAME(do_abort)\n+END_COMPILERRT_FUNCTION(__arm_sme_save)\n+\n+DEFINE_COMPILERRT_FUNCTION(__arm_sme_restore)\n+  .cfi_startproc\n+  .variant_pcs __arm_sme_restore\n+  BTI_C\n+\n   stp     x29, x30, [sp, #-16]!\n   .cfi_def_cfa_offset 16\n   mov     x29, sp\n   .cfi_def_cfa w29, 16\n   .cfi_offset w30, -8\n   .cfi_offset w29, -16\n+\n+  // If PTR is not 16-byte aligned, abort.\n+  tst     x0, #0xF\n+  b.ne    3f\n+\n+  // If the VALID bit is 0, return early.\n+  ldr     x16, [x0]\n+  cbz     x16, 2f\n+\n+  // If SME is not available, abort.\n   adrp    x17, CPU_FEATS_SYMBOL\n-  ldr     w17, [x17, CPU_FEATS_SYMBOL_OFFSET]\n-  tbnz    w17, #30, 0f\n-  adrp    x16, TPIDR2_SYMBOL\n-  ldrb    w16, [x16, TPIDR2_SYMBOL_OFFSET]\n-  cbz     w16, 1f\n-0:\n-  mov     x18, x1\n-  bl      __arm_sme_state\n-  mov     x1, x18\n-  and     x17, x17, #0x40000000\n-  bfxil   x17, x0, #0, #1\n-  cbz     x17, 1f\n-  cntd    x0\n-  .cfi_def_cfa wsp, 16\n-  ldp     x29, x30, [sp], #16\n-  .cfi_def_cfa_offset 0\n-  .cfi_restore w30\n-  .cfi_restore w29\n-  ret\n+  ldr     x17, [x17, CPU_FEATS_SYMBOL_OFFSET]\n+  tbz     x17, #FEAT_SME_BIT, 3f\n+\n+  // If TPIDR2_EL0 != nullptr, no lazy-save was committed, try to reload zt0.\n+  mrs     x16, TPIDR2_EL0\n+  cbnz    x16, 1f\n+\n+  // If TPIDR2_EL0 == nullptr and PSTATE.ZA = 1 (<=> ZA state is 'active'),\n+  // abort.\n+  mrs     x16, SVCR\n+  tbnz    x16, #1, 3f\n+\n+  // Restore za.\n+  smstart za\n+  add     x0, x0, #16\n+  bl      __arm_tpidr2_restore\n+  sub     x0, x0, #16\n+\n 1:\n-  mov     x0, xzr\n+  smstart za\n+  msr     TPIDR2_EL0, xzr\n+\n+  // Check if zt0 needs restoring.\n+  tbz     x17, #FEAT_SME2_BIT, 2f\n+\n+  // Restore zt0.\n+  add     x16, x0, #32\n+  ldr     zt0, [x16]\n+\n+2:\n+  // Do nothing\n   .cfi_def_cfa wsp, 16\n   ldp     x29, x30, [sp], #16\n   .cfi_def_cfa_offset 0\n   .cfi_restore w30\n   .cfi_restore w29\n   ret\n-END_COMPILERRT_OUTLINE_FUNCTION(__arm_get_current_vg)\n+\n+3:\n+  b       SYMBOL_NAME(do_abort)\n+  .cfi_endproc\n+END_COMPILERRT_FUNCTION(__arm_sme_restore)\n \n NO_EXEC_STACK_DIRECTIVE\n \ndiff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-mem-routines.S b/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-mem-routines.S\nindex 0318d9a6f1eb..e736829967c0 100644\n--- a/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-mem-routines.S\n+++ b/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-mem-routines.S\n@@ -6,10 +6,6 @@\n \n #include \"../assembly.h\"\n \n-#ifdef __aarch64__\n-\n-#define L(l) .L ## l\n-\n //\n //  __arm_sc_memcpy / __arm_sc_memmove\n //\n@@ -54,17 +50,17 @@\n    The loop tail is handled by always copying 64 bytes from the end.\n */\n \n-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sc_memcpy)\n+DEFINE_COMPILERRT_FUNCTION(__arm_sc_memcpy)\n         add     srcend1, src, count\n         add     dstend1, dstin, count\n         cmp     count, 128\n-        b.hi    L(copy_long)\n+        b.hi    7f  // copy_long\n         cmp     count, 32\n-        b.hi    L(copy32_128)\n+        b.hi    4f  // copy32_128\n \n         /* Small copies: 0..32 bytes.  */\n         cmp     count, 16\n-        b.lo    L(copy16)\n+        b.lo    0f  // copy16\n         ldp     A_l, A_h, [src]\n         ldp     D_l, D_h, [srcend1, -16]\n         stp     A_l, A_h, [dstin]\n@@ -72,8 +68,8 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sc_memcpy)\n         ret\n \n         /* Copy 8-15 bytes.  */\n-L(copy16):\n-        tbz     count, 3, L(copy8)\n+0:  // copy16\n+        tbz     count, 3, 1f  // copy8\n         ldr     A_l, [src]\n         ldr     A_h, [srcend1, -8]\n         str     A_l, [dstin]\n@@ -82,8 +78,8 @@ L(copy16):\n \n         .p2align 3\n         /* Copy 4-7 bytes.  */\n-L(copy8):\n-        tbz     count, 2, L(copy4)\n+1:  // copy8\n+        tbz     count, 2, 2f  // copy4\n         ldr     A_lw, [src]\n         ldr     B_lw, [srcend1, -4]\n         str     A_lw, [dstin]\n@@ -91,8 +87,8 @@ L(copy8):\n         ret\n \n         /* Copy 0..3 bytes using a branchless sequence.  */\n-L(copy4):\n-        cbz     count, L(copy0)\n+2:  // copy4\n+        cbz     count, 3f // copy0\n         lsr     tmp1, count, 1\n         ldrb    A_lw, [src]\n         ldrb    C_lw, [srcend1, -1]\n@@ -100,18 +96,18 @@ L(copy4):\n         strb    A_lw, [dstin]\n         strb    B_lw, [dstin, tmp1]\n         strb    C_lw, [dstend1, -1]\n-L(copy0):\n+3:  // copy0\n         ret\n \n         .p2align 4\n         /* Medium copies: 33..128 bytes.  */\n-L(copy32_128):\n+4:  // copy32_128\n         ldp     A_l, A_h, [src]\n         ldp     B_l, B_h, [src, 16]\n         ldp     C_l, C_h, [srcend1, -32]\n         ldp     D_l, D_h, [srcend1, -16]\n         cmp     count, 64\n-        b.hi    L(copy128)\n+        b.hi    5f  // copy128\n         stp     A_l, A_h, [dstin]\n         stp     B_l, B_h, [dstin, 16]\n         stp     C_l, C_h, [dstend1, -32]\n@@ -120,16 +116,16 @@ L(copy32_128):\n \n         .p2align 4\n         /* Copy 65..128 bytes.  */\n-L(copy128):\n+5:  // copy128\n         ldp     E_l, E_h, [src, 32]\n         ldp     F_l, F_h, [src, 48]\n         cmp     count, 96\n-        b.ls    L(copy96)\n+        b.ls    6f  // copy96\n         ldp     G_l, G_h, [srcend1, -64]\n         ldp     H_l, H_h, [srcend1, -48]\n         stp     G_l, G_h, [dstend1, -64]\n         stp     H_l, H_h, [dstend1, -48]\n-L(copy96):\n+6:  // copy96\n         stp     A_l, A_h, [dstin]\n         stp     B_l, B_h, [dstin, 16]\n         stp     E_l, E_h, [dstin, 32]\n@@ -140,12 +136,12 @@ L(copy96):\n \n         .p2align 4\n         /* Copy more than 128 bytes.  */\n-L(copy_long):\n+7:  // copy_long\n         /* Use backwards copy if there is an overlap.  */\n         sub     tmp1, dstin, src\n-        cbz     tmp1, L(copy0)\n+        cbz     tmp1, 3b  // copy0\n         cmp     tmp1, count\n-        b.lo    L(copy_long_backwards)\n+        b.lo    10f //copy_long_backwards\n \n         /* Copy 16 bytes and then align dst to 16-byte alignment.  */\n \n@@ -160,8 +156,8 @@ L(copy_long):\n         ldp     C_l, C_h, [src, 48]\n         ldp     D_l, D_h, [src, 64]!\n         subs    count, count, 128 + 16  /* Test and readjust count.  */\n-        b.ls    L(copy64_from_end)\n-L(loop64):\n+        b.ls    9f  // copy64_from_end\n+8:  // loop64\n         stp     A_l, A_h, [dst, 16]\n         ldp     A_l, A_h, [src, 16]\n         stp     B_l, B_h, [dst, 32]\n@@ -171,10 +167,10 @@ L(loop64):\n         stp     D_l, D_h, [dst, 64]!\n         ldp     D_l, D_h, [src, 64]!\n         subs    count, count, 64\n-        b.hi    L(loop64)\n+        b.hi    8b  // loop64\n \n         /* Write the last iteration and copy 64 bytes from the end.  */\n-L(copy64_from_end):\n+9:  // copy64_from_end\n         ldp     E_l, E_h, [srcend1, -64]\n         stp     A_l, A_h, [dst, 16]\n         ldp     A_l, A_h, [srcend1, -48]\n@@ -193,7 +189,7 @@ L(copy64_from_end):\n \n         /* Large backwards copy for overlapping copies.\n            Copy 16 bytes and then align dst to 16-byte alignment.  */\n-L(copy_long_backwards):\n+10: // copy_long_backwards\n         ldp     D_l, D_h, [srcend1, -16]\n         and     tmp1, dstend1, 15\n         sub     srcend1, srcend1, tmp1\n@@ -205,9 +201,9 @@ L(copy_long_backwards):\n         ldp     D_l, D_h, [srcend1, -64]!\n         sub     dstend1, dstend1, tmp1\n         subs    count, count, 128\n-        b.ls    L(copy64_from_start)\n+        b.ls    12f // copy64_from_start\n \n-L(loop64_backwards):\n+11: // loop64_backwards\n         stp     A_l, A_h, [dstend1, -16]\n         ldp     A_l, A_h, [srcend1, -16]\n         stp     B_l, B_h, [dstend1, -32]\n@@ -217,10 +213,10 @@ L(loop64_backwards):\n         stp     D_l, D_h, [dstend1, -64]!\n         ldp     D_l, D_h, [srcend1, -64]!\n         subs    count, count, 64\n-        b.hi    L(loop64_backwards)\n+        b.hi    11b // loop64_backwards\n \n         /* Write the last iteration and copy 64 bytes from the start.  */\n-L(copy64_from_start):\n+12: // copy64_from_start\n         ldp     G_l, G_h, [src, 48]\n         stp     A_l, A_h, [dstend1, -16]\n         ldp     A_l, A_h, [src, 32]\n@@ -234,11 +230,12 @@ L(copy64_from_start):\n         stp     B_l, B_h, [dstin, 16]\n         stp     C_l, C_h, [dstin]\n         ret\n-END_COMPILERRT_OUTLINE_FUNCTION(__arm_sc_memcpy)\n+END_COMPILERRT_FUNCTION(__arm_sc_memcpy)\n \n DEFINE_COMPILERRT_FUNCTION_ALIAS(__arm_sc_memmove, __arm_sc_memcpy)\n \n-\n+// This version uses FP registers. Use this only on targets with them\n+#if defined(__aarch64__) && __ARM_FP != 0\n //\n //  __arm_sc_memset\n //\n@@ -251,7 +248,7 @@ DEFINE_COMPILERRT_FUNCTION_ALIAS(__arm_sc_memmove, __arm_sc_memcpy)\n #define dstend2  x4\n #define zva_val  x5\n \n-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sc_memset)\n+DEFINE_COMPILERRT_FUNCTION(__arm_sc_memset)\n #ifdef __ARM_FEATURE_SVE\n         mov     z0.b, valw\n #else\n@@ -264,9 +261,9 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sc_memset)\n         add     dstend2, dstin, count\n \n         cmp     count, 96\n-        b.hi    L(set_long)\n+        b.hi    7f  // set_long\n         cmp     count, 16\n-        b.hs    L(set_medium)\n+        b.hs    4f  // set_medium\n         mov     val, v0.D[0]\n \n         /* Set 0..15 bytes.  */\n@@ -286,38 +283,38 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sc_memset)\n 3:      ret\n \n         /* Set 17..96 bytes.  */\n-L(set_medium):\n+4:  // set_medium\n         str     q0, [dstin]\n-        tbnz    count, 6, L(set96)\n+        tbnz    count, 6, 6f  // set96\n         str     q0, [dstend2, -16]\n-        tbz     count, 5, 1f\n+        tbz     count, 5, 5f\n         str     q0, [dstin, 16]\n         str     q0, [dstend2, -32]\n-1:      ret\n+5:      ret\n \n         .p2align 4\n         /* Set 64..96 bytes.  Write 64 bytes from the start and\n            32 bytes from the end.  */\n-L(set96):\n+6:  // set96\n         str     q0, [dstin, 16]\n         stp     q0, q0, [dstin, 32]\n         stp     q0, q0, [dstend2, -32]\n         ret\n \n         .p2align 4\n-L(set_long):\n+7:  // set_long\n         and     valw, valw, 255\n         bic     dst, dstin, 15\n         str     q0, [dstin]\n         cmp     count, 160\n         ccmp    valw, 0, 0, hs\n-        b.ne    L(no_zva)\n+        b.ne    9f  // no_zva\n \n #ifndef SKIP_ZVA_CHECK\n         mrs     zva_val, dczid_el0\n         and     zva_val, zva_val, 31\n         cmp     zva_val, 4              /* ZVA size is 64 bytes.  */\n-        b.ne    L(no_zva)\n+        b.ne    9f  // no_zva\n #endif\n         str     q0, [dst, 16]\n         stp     q0, q0, [dst, 32]\n@@ -326,27 +323,27 @@ L(set_long):\n         sub     count, count, 128       /* Adjust count and bias for loop.  */\n \n         .p2align 4\n-L(zva_loop):\n+8:  // zva_loop\n         add     dst, dst, 64\n         dc      zva, dst\n         subs    count, count, 64\n-        b.hi    L(zva_loop)\n+        b.hi    8b  // zva_loop\n         stp     q0, q0, [dstend2, -64]\n         stp     q0, q0, [dstend2, -32]\n         ret\n \n-L(no_zva):\n+9:  // no_zva\n         sub     count, dstend2, dst      /* Count is 16 too large.  */\n         sub     dst, dst, 16            /* Dst is biased by -32.  */\n         sub     count, count, 64 + 16   /* Adjust count and bias for loop.  */\n-L(no_zva_loop):\n+10: // no_zva_loop\n         stp     q0, q0, [dst, 32]\n         stp     q0, q0, [dst, 64]!\n         subs    count, count, 64\n-        b.hi    L(no_zva_loop)\n+        b.hi    10b  // no_zva_loop\n         stp     q0, q0, [dstend2, -64]\n         stp     q0, q0, [dstend2, -32]\n         ret\n-END_COMPILERRT_OUTLINE_FUNCTION(__arm_sc_memset)\n+END_COMPILERRT_FUNCTION(__arm_sc_memset)\n \n #endif // __aarch64__\ndiff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-routines.c b/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-routines.c\nindex 315490e73ea2..07d668148555 100644\n--- a/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-routines.c\n+++ b/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-routines.c\n@@ -1,5 +1,17 @@\n #include <stddef.h>\n \n+/* The asm version uses FP registers. Use this on targets without them */\n+#if __ARM_FP == 0\n+void *__arm_sc_memset(void *dest, int c, size_t n) __arm_streaming_compatible {\n+  unsigned char *destp = (unsigned char *)dest;\n+  unsigned char c8 = (unsigned char)c;\n+  for (size_t i = 0; i < n; ++i)\n+    destp[i] = c8;\n+\n+  return dest;\n+}\n+#endif\n+\n const void *__arm_sc_memchr(const void *src, int c,\n                             size_t n) __arm_streaming_compatible {\n   const unsigned char *srcp = (const unsigned char *)src;\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/adddf3vfp.S b/contrib/libs/cxxsupp/builtins/arm/adddf3vfp.S\nindex 1a271db0847c..280f5ab07563 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/adddf3vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/adddf3vfp.S\n@@ -19,10 +19,10 @@ DEFINE_COMPILERRT_FUNCTION(__adddf3vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvadd.f64 d0, d0, d1\n #else\n-\tvmov\td6, r0, r1\t\t// move first param from r0/r1 pair into d6\n-\tvmov\td7, r2, r3\t\t// move second param from r2/r3 pair into d7\n+\tVMOV_TO_DOUBLE(d6, r0, r1)\t\t// move first param from r0/r1 pair into d6\n+\tVMOV_TO_DOUBLE(d7, r2, r3)\t\t// move second param from r2/r3 pair into d7\n \tvadd.f64 d6, d6, d7\n-\tvmov\tr0, r1, d6\t\t// move result back to r0/r1 pair\n+\tVMOV_FROM_DOUBLE(r0, r1, d6)\t\t// move result back to r0/r1 pair\n #endif\n \tbx\tlr\n END_COMPILERRT_FUNCTION(__adddf3vfp)\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/aeabi_dcmp.S b/contrib/libs/cxxsupp/builtins/arm/aeabi_dcmp.S\nindex 5f720670ddd7..bee14b3ff8af 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/aeabi_dcmp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/aeabi_dcmp.S\n@@ -18,9 +18,9 @@\n // }\n \n #if defined(COMPILER_RT_ARMHF_TARGET)\n-#  define CONVERT_DCMP_ARGS_TO_DF2_ARGS                    \\\n-        vmov      d0, r0, r1                     SEPARATOR \\\n-        vmov      d1, r2, r3\n+#  define CONVERT_DCMP_ARGS_TO_DF2_ARGS \\\n+     VMOV_TO_DOUBLE(d0, r0, r1)         \\\n+     VMOV_TO_DOUBLE(d1, r2, r3)\n #else\n #  define CONVERT_DCMP_ARGS_TO_DF2_ARGS\n #endif\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/divdf3vfp.S b/contrib/libs/cxxsupp/builtins/arm/divdf3vfp.S\nindex ad50b57a651d..c8c0aa84c192 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/divdf3vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/divdf3vfp.S\n@@ -20,10 +20,10 @@ DEFINE_COMPILERRT_FUNCTION(__divdf3vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvdiv.f64 d0, d0, d1\n #else\n-\tvmov\td6, r0, r1\t\t// move first param from r0/r1 pair into d6\n-\tvmov\td7, r2, r3\t\t// move second param from r2/r3 pair into d7\n+\tVMOV_TO_DOUBLE(d6, r0, r1)\t\t// move first param from r0/r1 pair into d6\n+\tVMOV_TO_DOUBLE(d7, r2, r3)\t\t// move second param from r2/r3 pair into d7\n \tvdiv.f64 d5, d6, d7\n-\tvmov\tr0, r1, d5\t\t// move result back to r0/r1 pair\n+\tVMOV_FROM_DOUBLE(r0, r1, d5)\t\t// move result back to r0/r1 pair\n #endif\n \tbx\tlr\n END_COMPILERRT_FUNCTION(__divdf3vfp)\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/eqdf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/eqdf2vfp.S\nindex 2a0a64b97e7d..a6f341dc1f46 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/eqdf2vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/eqdf2vfp.S\n@@ -20,8 +20,8 @@ DEFINE_COMPILERRT_FUNCTION(__eqdf2vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvcmp.f64 d0, d1\n #else\n-\tvmov\td6, r0, r1\t// load r0/r1 pair in double register\n-\tvmov\td7, r2, r3\t// load r2/r3 pair in double register\n+\tVMOV_TO_DOUBLE(d6, r0, r1)\t// load r0/r1 pair in double register\n+\tVMOV_TO_DOUBLE(d7, r2, r3)\t// load r2/r3 pair in double register\n \tvcmp.f64 d6, d7\n #endif\n \tvmrs\tapsr_nzcv, fpscr\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/extendsfdf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/extendsfdf2vfp.S\nindex 37c8be8dcd9c..815be830003a 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/extendsfdf2vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/extendsfdf2vfp.S\n@@ -23,7 +23,7 @@ DEFINE_COMPILERRT_FUNCTION(__extendsfdf2vfp)\n #else\n \tvmov\ts15, r0      // load float register from R0\n \tvcvt.f64.f32 d7, s15 // convert single to double\n-\tvmov\tr0, r1, d7   // return result in r0/r1 pair\n+\tVMOV_FROM_DOUBLE(r0, r1, d7)   // return result in r0/r1 pair\n #endif\n \tbx\tlr\n END_COMPILERRT_FUNCTION(__extendsfdf2vfp)\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/fixdfsivfp.S b/contrib/libs/cxxsupp/builtins/arm/fixdfsivfp.S\nindex af1d4f4fa5f5..d708f3f4d805 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/fixdfsivfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/fixdfsivfp.S\n@@ -22,7 +22,7 @@ DEFINE_COMPILERRT_FUNCTION(__fixdfsivfp)\n \tvcvt.s32.f64 s0, d0\n \tvmov r0, s0\n #else\n-\tvmov\td7, r0, r1    // load double register from R0/R1\n+\tVMOV_TO_DOUBLE(d7, r0, r1)    // load double register from R0/R1\n \tvcvt.s32.f64 s15, d7  // convert double to 32-bit int into s15\n \tvmov\tr0, s15\t      // move s15 to result register\n #endif\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/fixunsdfsivfp.S b/contrib/libs/cxxsupp/builtins/arm/fixunsdfsivfp.S\nindex 44e6dbd4989e..a3dda15e8c04 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/fixunsdfsivfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/fixunsdfsivfp.S\n@@ -23,7 +23,7 @@ DEFINE_COMPILERRT_FUNCTION(__fixunsdfsivfp)\n \tvcvt.u32.f64 s0, d0\n \tvmov r0, s0\n #else\n-\tvmov\td7, r0, r1    // load double register from R0/R1\n+\tVMOV_TO_DOUBLE(d7, r0, r1)    // load double register from R0/R1\n \tvcvt.u32.f64 s15, d7  // convert double to 32-bit int into s15\n \tvmov\tr0, s15\t      // move s15 to result register\n #endif\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/floatsidfvfp.S b/contrib/libs/cxxsupp/builtins/arm/floatsidfvfp.S\nindex ae8d2465889c..d0fc5e8a4480 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/floatsidfvfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/floatsidfvfp.S\n@@ -24,7 +24,7 @@ DEFINE_COMPILERRT_FUNCTION(__floatsidfvfp)\n #else\n \tvmov\ts15, r0        // move int to float register s15\n \tvcvt.f64.s32 d7, s15   // convert 32-bit int in s15 to double in d7\n-\tvmov\tr0, r1, d7     // move d7 to result register pair r0/r1\n+\tVMOV_FROM_DOUBLE(r0, r1, d7)     // move d7 to result register pair r0/r1\n #endif\n \tbx\tlr\n END_COMPILERRT_FUNCTION(__floatsidfvfp)\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/floatunssidfvfp.S b/contrib/libs/cxxsupp/builtins/arm/floatunssidfvfp.S\nindex 0932dab2bdb9..5acc2d5c0b25 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/floatunssidfvfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/floatunssidfvfp.S\n@@ -24,7 +24,7 @@ DEFINE_COMPILERRT_FUNCTION(__floatunssidfvfp)\n #else\n \tvmov\ts15, r0        // move int to float register s15\n \tvcvt.f64.u32 d7, s15   // convert 32-bit int in s15 to double in d7\n-\tvmov\tr0, r1, d7     // move d7 to result register pair r0/r1\n+\tVMOV_FROM_DOUBLE(r0, r1, d7) // move d7 to result register pair r0/r1\n #endif\n \tbx\tlr\n END_COMPILERRT_FUNCTION(__floatunssidfvfp)\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/gedf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/gedf2vfp.S\nindex 2af9d909967b..00746b891c99 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/gedf2vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/gedf2vfp.S\n@@ -21,8 +21,8 @@ DEFINE_COMPILERRT_FUNCTION(__gedf2vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvcmp.f64 d0, d1\n #else\n-\tvmov \td6, r0, r1\t// load r0/r1 pair in double register\n-\tvmov \td7, r2, r3\t// load r2/r3 pair in double register\n+\tVMOV_TO_DOUBLE(d6, r0, r1)\t// load r0/r1 pair in double register\n+\tVMOV_TO_DOUBLE(d7, r2, r3)\t// load r2/r3 pair in double register\n \tvcmp.f64 d6, d7\n #endif\n \tvmrs\tapsr_nzcv, fpscr\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/gtdf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/gtdf2vfp.S\nindex 782ad8cac013..980a09eb24b0 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/gtdf2vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/gtdf2vfp.S\n@@ -21,8 +21,8 @@ DEFINE_COMPILERRT_FUNCTION(__gtdf2vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvcmp.f64 d0, d1\n #else\n-\tvmov \td6, r0, r1\t// load r0/r1 pair in double register\n-\tvmov \td7, r2, r3\t// load r2/r3 pair in double register\n+\tVMOV_TO_DOUBLE(d6, r0, r1)\t// load r0/r1 pair in double register\n+\tVMOV_TO_DOUBLE(d7, r2, r3)\t// load r2/r3 pair in double register\n \tvcmp.f64 d6, d7\n #endif\n \tvmrs\tapsr_nzcv, fpscr\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/ledf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/ledf2vfp.S\nindex 0097e4b6c129..c7fe6d84535a 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/ledf2vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/ledf2vfp.S\n@@ -21,8 +21,8 @@ DEFINE_COMPILERRT_FUNCTION(__ledf2vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvcmp.f64 d0, d1\n #else\n-\tvmov \td6, r0, r1\t// load r0/r1 pair in double register\n-\tvmov \td7, r2, r3\t// load r2/r3 pair in double register\n+\tVMOV_TO_DOUBLE(d6, r0, r1)\t// load r0/r1 pair in double register\n+\tVMOV_TO_DOUBLE(d7, r2, r3)\t// load r2/r3 pair in double register\n \tvcmp.f64 d6, d7\n #endif\n \tvmrs\tapsr_nzcv, fpscr\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/ltdf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/ltdf2vfp.S\nindex a126aa9e0536..be5827075f99 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/ltdf2vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/ltdf2vfp.S\n@@ -21,8 +21,8 @@ DEFINE_COMPILERRT_FUNCTION(__ltdf2vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvcmp.f64 d0, d1\n #else\n-\tvmov \td6, r0, r1\t// load r0/r1 pair in double register\n-\tvmov \td7, r2, r3\t// load r2/r3 pair in double register\n+\tVMOV_TO_DOUBLE(d6, r0, r1)\t// load r0/r1 pair in double register\n+\tVMOV_TO_DOUBLE(d7, r2, r3)\t// load r2/r3 pair in double register\n \tvcmp.f64 d6, d7\n #endif\n \tvmrs\tapsr_nzcv, fpscr\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/muldf3vfp.S b/contrib/libs/cxxsupp/builtins/arm/muldf3vfp.S\nindex 9adc937bcb3f..97daf7363787 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/muldf3vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/muldf3vfp.S\n@@ -20,10 +20,10 @@ DEFINE_COMPILERRT_FUNCTION(__muldf3vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvmul.f64 d0, d0, d1\n #else\n-\tvmov \td6, r0, r1         // move first param from r0/r1 pair into d6\n-\tvmov \td7, r2, r3         // move second param from r2/r3 pair into d7\n+\tVMOV_TO_DOUBLE(d6, r0, r1)         // move first param from r0/r1 pair into d6\n+\tVMOV_TO_DOUBLE(d7, r2, r3)         // move second param from r2/r3 pair into d7\n \tvmul.f64 d6, d6, d7\n-\tvmov \tr0, r1, d6         // move result back to r0/r1 pair\n+\tVMOV_FROM_DOUBLE(r0, r1, d6)         // move result back to r0/r1 pair\n #endif\n \tbx\tlr\n END_COMPILERRT_FUNCTION(__muldf3vfp)\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/nedf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/nedf2vfp.S\nindex 32d35c41d466..5edafc25988d 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/nedf2vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/nedf2vfp.S\n@@ -20,8 +20,8 @@ DEFINE_COMPILERRT_FUNCTION(__nedf2vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvcmp.f64 d0, d1\n #else\n-\tvmov \td6, r0, r1\t// load r0/r1 pair in double register\n-\tvmov \td7, r2, r3\t// load r2/r3 pair in double register\n+\tVMOV_TO_DOUBLE(d6, r0, r1)\t// load r0/r1 pair in double register\n+\tVMOV_TO_DOUBLE(d7, r2, r3)\t// load r2/r3 pair in double register\n \tvcmp.f64 d6, d7\n #endif\n \tvmrs\tapsr_nzcv, fpscr\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/subdf3vfp.S b/contrib/libs/cxxsupp/builtins/arm/subdf3vfp.S\nindex f4eaf9af1afe..2a7b1d38b577 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/subdf3vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/subdf3vfp.S\n@@ -20,10 +20,10 @@ DEFINE_COMPILERRT_FUNCTION(__subdf3vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvsub.f64 d0, d0, d1\n #else\n-\tvmov \td6, r0, r1         // move first param from r0/r1 pair into d6\n-\tvmov \td7, r2, r3         // move second param from r2/r3 pair into d7\n+\tVMOV_TO_DOUBLE(d6, r0, r1)         // move first param from r0/r1 pair into d6\n+\tVMOV_TO_DOUBLE(d7, r2, r3)         // move second param from r2/r3 pair into d7\n \tvsub.f64 d6, d6, d7\n-\tvmov \tr0, r1, d6         // move result back to r0/r1 pair\n+\tVMOV_FROM_DOUBLE(r0, r1, d6)         // move result back to r0/r1 pair\n #endif\n \tbx\tlr\n END_COMPILERRT_FUNCTION(__subdf3vfp)\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/truncdfsf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/truncdfsf2vfp.S\nindex e1c171262a78..541d025b4f92 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/truncdfsf2vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/truncdfsf2vfp.S\n@@ -21,7 +21,7 @@ DEFINE_COMPILERRT_FUNCTION(__truncdfsf2vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvcvt.f32.f64 s0, d0\n #else\n-\tvmov \td7, r0, r1   // load double from r0/r1 pair\n+\tVMOV_TO_DOUBLE(d7, r0, r1)   // load double from r0/r1 pair\n \tvcvt.f32.f64 s15, d7 // convert double to single (trucate precision)\n \tvmov \tr0, s15      // return result in r0\n #endif\ndiff --git a/contrib/libs/cxxsupp/builtins/arm/unorddf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/unorddf2vfp.S\nindex ea36a1cb5594..3abb622c81ec 100644\n--- a/contrib/libs/cxxsupp/builtins/arm/unorddf2vfp.S\n+++ b/contrib/libs/cxxsupp/builtins/arm/unorddf2vfp.S\n@@ -21,8 +21,8 @@ DEFINE_COMPILERRT_FUNCTION(__unorddf2vfp)\n #if defined(COMPILER_RT_ARMHF_TARGET)\n \tvcmp.f64 d0, d1\n #else\n-\tvmov \td6, r0, r1\t// load r0/r1 pair in double register\n-\tvmov \td7, r2, r3\t// load r2/r3 pair in double register\n+\tVMOV_TO_DOUBLE(d6, r0, r1)\t// load r0/r1 pair in double register\n+\tVMOV_TO_DOUBLE(d7, r2, r3)\t// load r2/r3 pair in double register\n \tvcmp.f64 d6, d7\n #endif\n \tvmrs\tapsr_nzcv, fpscr\ndiff --git a/contrib/libs/cxxsupp/builtins/assembly.h b/contrib/libs/cxxsupp/builtins/assembly.h\nindex 8c42fc773483..34c71241524d 100644\n--- a/contrib/libs/cxxsupp/builtins/assembly.h\n+++ b/contrib/libs/cxxsupp/builtins/assembly.h\n@@ -290,4 +290,16 @@\n   CFI_END\n #endif\n \n+#ifdef __arm__\n+#include \"int_endianness.h\"\n+\n+#if _YUGA_BIG_ENDIAN\n+#define VMOV_TO_DOUBLE(dst, src0, src1) vmov dst, src1, src0 SEPARATOR\n+#define VMOV_FROM_DOUBLE(dst0, dst1, src) vmov dst1, dst0, src SEPARATOR\n+#else\n+#define VMOV_TO_DOUBLE(dst, src0, src1) vmov dst, src0, src1 SEPARATOR\n+#define VMOV_FROM_DOUBLE(dst0, dst1, src) vmov dst0, dst1, src SEPARATOR\n+#endif\n+#endif\n+\n #endif // COMPILERRT_ASSEMBLY_H\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/AArch64CPUFeatures.inc b/contrib/libs/cxxsupp/builtins/cpu_model/AArch64CPUFeatures.inc\nindex e78bb88cfedf..778f568c95c5 100644\n--- a/contrib/libs/cxxsupp/builtins/cpu_model/AArch64CPUFeatures.inc\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/AArch64CPUFeatures.inc\n@@ -33,10 +33,10 @@ enum CPUFeatures {\n   FEAT_FP,\n   FEAT_SIMD,\n   FEAT_CRC,\n-  FEAT_SHA1,\n+  RESERVED_FEAT_SHA1, // previously used and now ABI legacy\n   FEAT_SHA2,\n   FEAT_SHA3,\n-  FEAT_AES,\n+  RESERVED_FEAT_AES, // previously used and now ABI legacy\n   FEAT_PMULL,\n   FEAT_FP16,\n   FEAT_DIT,\n@@ -47,35 +47,35 @@ enum CPUFeatures {\n   FEAT_RCPC,\n   FEAT_RCPC2,\n   FEAT_FRINTTS,\n-  FEAT_DGH,\n+  RESERVED_FEAT_DGH, // previously used and now ABI legacy\n   FEAT_I8MM,\n   FEAT_BF16,\n-  FEAT_EBF16,\n-  FEAT_RPRES,\n+  RESERVED_FEAT_EBF16, // previously used and now ABI legacy\n+  RESERVED_FEAT_RPRES, // previously used and now ABI legacy\n   FEAT_SVE,\n-  FEAT_SVE_BF16,\n-  FEAT_SVE_EBF16,\n-  FEAT_SVE_I8MM,\n+  RESERVED_FEAT_SVE_BF16,  // previously used and now ABI legacy\n+  RESERVED_FEAT_SVE_EBF16, // previously used and now ABI legacy\n+  RESERVED_FEAT_SVE_I8MM,  // previously used and now ABI legacy\n   FEAT_SVE_F32MM,\n   FEAT_SVE_F64MM,\n   FEAT_SVE2,\n-  FEAT_SVE_AES,\n+  RESERVED_FEAT_SVE_AES, // previously used and now ABI legacy\n   FEAT_SVE_PMULL128,\n   FEAT_SVE_BITPERM,\n   FEAT_SVE_SHA3,\n   FEAT_SVE_SM4,\n   FEAT_SME,\n-  FEAT_MEMTAG,\n+  RESERVED_FEAT_MEMTAG, // previously used and now ABI legacy\n   FEAT_MEMTAG2,\n-  FEAT_MEMTAG3,\n+  RESERVED_FEAT_MEMTAG3, // previously used and now ABI legacy\n   FEAT_SB,\n-  FEAT_PREDRES,\n-  FEAT_SSBS,\n+  RESERVED_FEAT_PREDRES, // previously used and now ABI legacy\n+  RESERVED_FEAT_SSBS,    // previously used and now ABI legacy\n   FEAT_SSBS2,\n   FEAT_BTI,\n-  FEAT_LS64,\n-  FEAT_LS64_V,\n-  FEAT_LS64_ACCDATA,\n+  RESERVED_FEAT_LS64,         // previously used and now ABI legacy\n+  RESERVED_FEAT_LS64_V,       // previously used and now ABI legacy\n+  RESERVED_FEAT_LS64_ACCDATA, // previously used and now ABI legacy\n   FEAT_WFXT,\n   FEAT_SME_F64,\n   FEAT_SME_I64,\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.c b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.c\nindex b868caa991b2..4082fd62ea11 100644\n--- a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.c\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.c\n@@ -14,7 +14,7 @@\n \n #include \"aarch64.h\"\n \n-#if !defined(__aarch64__)\n+#if !defined(__aarch64__) && !defined(__arm64__) && !defined(_M_ARM64)\n #error This file is intended only for aarch64-based targets\n #endif\n \n@@ -45,9 +45,11 @@ _Bool __aarch64_have_lse_atomics\n #elif defined(__ANDROID__)\n #include \"aarch64/hwcap.inc\"\n #include \"aarch64/lse_atomics/android.inc\"\n-#elif __has_include(<sys/auxv.h>)\n+#elif defined(__linux__) && __has_include(<sys/auxv.h>)\n #include \"aarch64/hwcap.inc\"\n-#include \"aarch64/lse_atomics/sysauxv.inc\"\n+#include \"aarch64/lse_atomics/getauxval.inc\"\n+#elif defined(_WIN32)\n+#include \"aarch64/lse_atomics/windows.inc\"\n #else\n // When unimplemented, we leave __aarch64_have_lse_atomics initialized to false.\n #endif\n@@ -73,9 +75,13 @@ struct {\n #elif defined(__ANDROID__)\n #include \"aarch64/fmv/mrs.inc\"\n #include \"aarch64/fmv/android.inc\"\n-#elif __has_include(<sys/auxv.h>)\n+#elif defined(__linux__) && __has_include(<sys/auxv.h>)\n #include \"aarch64/fmv/mrs.inc\"\n-#include \"aarch64/fmv/sysauxv.inc\"\n+#include \"aarch64/fmv/getauxval.inc\"\n+#elif defined(_WIN32)\n+#include \"aarch64/fmv/windows.inc\"\n+#elif defined(ENABLE_BAREMETAL_AARCH64_FMV)\n+#include \"aarch64/fmv/baremetal.inc\"\n #else\n #include \"aarch64/fmv/unimplemented.inc\"\n #endif\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.h b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.h\nindex f6cbf75d582f..2a734b02b7c9 100644\n--- a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.h\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.h\n@@ -8,7 +8,7 @@\n \n #include \"cpu_model.h\"\n \n-#if !defined(__aarch64__)\n+#if !defined(__aarch64__) && !defined(__arm64__) && !defined(_M_ARM64)\n #error This file is intended only for aarch64-based targets\n #endif\n \ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/apple.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/apple.inc\nindex f0694900f231..d5c85701ad1a 100644\n--- a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/apple.inc\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/apple.inc\n@@ -31,10 +31,6 @@ static bool isKnownAndSupported(const char *name) {\n }\n \n static uint64_t deriveImplicitFeatures(uint64_t features) {\n-  // FEAT_SSBS2 implies FEAT_SSBS\n-  if ((1ULL << FEAT_SSBS2) & features)\n-    features |= (1ULL << FEAT_SSBS);\n-\n   // FEAT_FP is always enabled\n   features |= (1ULL << FEAT_FP);\n \n@@ -77,10 +73,7 @@ void __init_cpu_features_resolver(void) {\n     CHECK_BIT(CAP_BIT_FEAT_RDM, FEAT_RDM);\n     CHECK_BIT(CAP_BIT_FEAT_LSE, FEAT_LSE);\n     CHECK_BIT(CAP_BIT_FEAT_SHA256, FEAT_SHA2);\n-    CHECK_BIT(CAP_BIT_FEAT_SHA1, FEAT_SHA1);\n-    CHECK_BIT(CAP_BIT_FEAT_AES, FEAT_AES);\n     CHECK_BIT(CAP_BIT_FEAT_PMULL, FEAT_PMULL);\n-    CHECK_BIT(CAP_BIT_FEAT_SPECRES, FEAT_PREDRES);\n     CHECK_BIT(CAP_BIT_FEAT_SB, FEAT_SB);\n     CHECK_BIT(CAP_BIT_FEAT_FRINTTS, FEAT_FRINTTS);\n     CHECK_BIT(CAP_BIT_FEAT_LRCPC, FEAT_RCPC);\n@@ -123,10 +116,8 @@ void __init_cpu_features_resolver(void) {\n       {\"hw.optional.arm.FEAT_LSE\", FEAT_LSE},\n       {\"hw.optional.AdvSIMD\", FEAT_SIMD},\n       {\"hw.optional.armv8_crc32\", FEAT_CRC},\n-      {\"hw.optional.arm.FEAT_SHA1\", FEAT_SHA1},\n       {\"hw.optional.arm.FEAT_SHA256\", FEAT_SHA2},\n       {\"hw.optional.arm.FEAT_SHA3\", FEAT_SHA3},\n-      {\"hw.optional.arm.FEAT_AES\", FEAT_AES},\n       {\"hw.optional.arm.FEAT_PMULL\", FEAT_PMULL},\n       {\"hw.optional.arm.FEAT_FP16\", FEAT_FP16},\n       {\"hw.optional.arm.FEAT_DIT\", FEAT_DIT},\n@@ -140,7 +131,6 @@ void __init_cpu_features_resolver(void) {\n       {\"hw.optional.arm.FEAT_I8MM\", FEAT_I8MM},\n       {\"hw.optional.arm.FEAT_BF16\", FEAT_BF16},\n       {\"hw.optional.arm.FEAT_SB\", FEAT_SB},\n-      {\"hw.optional.arm.FEAT_SPECRES\", FEAT_PREDRES},\n       {\"hw.optional.arm.FEAT_SSBS\", FEAT_SSBS2},\n       {\"hw.optional.arm.FEAT_BTI\", FEAT_BTI},\n   };\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/baremetal.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/baremetal.inc\nnew file mode 100644\nindex 000000000000..f188e84808e0\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/baremetal.inc\n@@ -0,0 +1,31 @@\n+// For baremetal platforms, we don't really initialise '__aarch64_cpu_features',\n+// with exception of FEAT_SME that we can get from '__aarch64_sme_accessible'.\n+\n+#if defined(COMPILER_RT_SHARED_LIB)\n+__attribute__((weak))\n+#endif\n+extern _Bool\n+__aarch64_sme_accessible(void);\n+\n+static _Bool has_sme(void) {\n+#if defined(COMPILER_RT_SHARED_LIB)\n+  if (!__aarch64_sme_accessible)\n+    return 0;\n+#endif\n+  return __aarch64_sme_accessible();\n+}\n+\n+void __init_cpu_features_resolver(unsigned long hwcap,\n+                                  const __ifunc_arg_t *arg) {}\n+\n+void CONSTRUCTOR_ATTRIBUTE __init_cpu_features(void) {\n+  // CPU features already initialized.\n+  if (__atomic_load_n(&__aarch64_cpu_features.features, __ATOMIC_RELAXED))\n+    return;\n+\n+  unsigned long long feat = 0;\n+  if (has_sme())\n+    feat |= 1ULL << FEAT_SME;\n+\n+  __atomic_store_n(&__aarch64_cpu_features.features, feat, __ATOMIC_RELAXED);\n+}\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/fuchsia.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/fuchsia.inc\nindex fd0800dd11e7..9851e5e38394 100644\n--- a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/fuchsia.inc\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/fuchsia.inc\n@@ -20,12 +20,8 @@ void __init_cpu_features_resolver() {\n     setCPUFeature(FEAT_FP);\n   if (features & ZX_ARM64_FEATURE_ISA_ASIMD)\n     setCPUFeature(FEAT_SIMD);\n-  if (features & ZX_ARM64_FEATURE_ISA_AES)\n-    setCPUFeature(FEAT_AES);\n   if (features & ZX_ARM64_FEATURE_ISA_PMULL)\n     setCPUFeature(FEAT_PMULL);\n-  if (features & ZX_ARM64_FEATURE_ISA_SHA1)\n-    setCPUFeature(FEAT_SHA1);\n   if (features & ZX_ARM64_FEATURE_ISA_SHA256)\n     setCPUFeature(FEAT_SHA2);\n   if (features & ZX_ARM64_FEATURE_ISA_CRC32)\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/sysauxv.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/getauxval.inc\nsimilarity index 100%\nrename from contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/sysauxv.inc\nrename to contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/getauxval.inc\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/mrs.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/mrs.inc\nindex e4d5e7f2bd7e..6d46fccdc79d 100644\n--- a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/mrs.inc\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/mrs.inc\n@@ -33,10 +33,6 @@ static void __init_cpu_features_constructor(unsigned long hwcap,\n     setCPUFeature(FEAT_DIT);\n   if (hwcap & HWCAP_ASIMDRDM)\n     setCPUFeature(FEAT_RDM);\n-  if (hwcap & HWCAP_AES)\n-    setCPUFeature(FEAT_AES);\n-  if (hwcap & HWCAP_SHA1)\n-    setCPUFeature(FEAT_SHA1);\n   if (hwcap & HWCAP_SHA2)\n     setCPUFeature(FEAT_SHA2);\n   if (hwcap & HWCAP_JSCVT)\n@@ -45,18 +41,10 @@ static void __init_cpu_features_constructor(unsigned long hwcap,\n     setCPUFeature(FEAT_FCMA);\n   if (hwcap & HWCAP_SB)\n     setCPUFeature(FEAT_SB);\n-  if (hwcap & HWCAP_SSBS) {\n-    setCPUFeature(FEAT_SSBS);\n+  if (hwcap & HWCAP_SSBS)\n     setCPUFeature(FEAT_SSBS2);\n-  }\n-  if (hwcap2 & HWCAP2_MTE) {\n-    setCPUFeature(FEAT_MEMTAG);\n+  if (hwcap2 & HWCAP2_MTE)\n     setCPUFeature(FEAT_MEMTAG2);\n-  }\n-  if (hwcap2 & HWCAP2_MTE3)\n-    setCPUFeature(FEAT_MEMTAG3);\n-  if (hwcap2 & HWCAP2_SVEAES)\n-    setCPUFeature(FEAT_SVE_AES);\n   if (hwcap2 & HWCAP2_SVEPMULL)\n     setCPUFeature(FEAT_SVE_PMULL128);\n   if (hwcap2 & HWCAP2_SVEBITPERM)\n@@ -73,24 +61,14 @@ static void __init_cpu_features_constructor(unsigned long hwcap,\n     setCPUFeature(FEAT_RNG);\n   if (hwcap2 & HWCAP2_I8MM)\n     setCPUFeature(FEAT_I8MM);\n-  if (hwcap2 & HWCAP2_EBF16)\n-    setCPUFeature(FEAT_EBF16);\n-  if (hwcap2 & HWCAP2_SVE_EBF16)\n-    setCPUFeature(FEAT_SVE_EBF16);\n-  if (hwcap2 & HWCAP2_DGH)\n-    setCPUFeature(FEAT_DGH);\n   if (hwcap2 & HWCAP2_FRINT)\n     setCPUFeature(FEAT_FRINTTS);\n-  if (hwcap2 & HWCAP2_SVEI8MM)\n-    setCPUFeature(FEAT_SVE_I8MM);\n   if (hwcap2 & HWCAP2_SVEF32MM)\n     setCPUFeature(FEAT_SVE_F32MM);\n   if (hwcap2 & HWCAP2_SVEF64MM)\n     setCPUFeature(FEAT_SVE_F64MM);\n   if (hwcap2 & HWCAP2_BTI)\n     setCPUFeature(FEAT_BTI);\n-  if (hwcap2 & HWCAP2_RPRES)\n-    setCPUFeature(FEAT_RPRES);\n   if (hwcap2 & HWCAP2_WFXT)\n     setCPUFeature(FEAT_WFXT);\n   if (hwcap2 & HWCAP2_SME)\n@@ -103,23 +81,6 @@ static void __init_cpu_features_constructor(unsigned long hwcap,\n     setCPUFeature(FEAT_SME_F64);\n   if (hwcap2 & HWCAP2_MOPS)\n     setCPUFeature(FEAT_MOPS);\n-  if (hwcap & HWCAP_CPUID) {\n-    unsigned long ftr;\n-\n-    getCPUFeature(ID_AA64ISAR1_EL1, ftr);\n-    /* ID_AA64ISAR1_EL1.SPECRES >= 0b0001  */\n-    if (extractBits(ftr, 40, 4) >= 0x1)\n-      setCPUFeature(FEAT_PREDRES);\n-    /* ID_AA64ISAR1_EL1.LS64 >= 0b0001  */\n-    if (extractBits(ftr, 60, 4) >= 0x1)\n-      setCPUFeature(FEAT_LS64);\n-    /* ID_AA64ISAR1_EL1.LS64 >= 0b0010  */\n-    if (extractBits(ftr, 60, 4) >= 0x2)\n-      setCPUFeature(FEAT_LS64_V);\n-    /* ID_AA64ISAR1_EL1.LS64 >= 0b0011  */\n-    if (extractBits(ftr, 60, 4) >= 0x3)\n-      setCPUFeature(FEAT_LS64_ACCDATA);\n-  }\n   if (hwcap & HWCAP_FP) {\n     setCPUFeature(FEAT_FP);\n     // FP and AdvSIMD fields have the same value\n@@ -135,8 +96,6 @@ static void __init_cpu_features_constructor(unsigned long hwcap,\n     setCPUFeature(FEAT_RCPC3);\n   if (hwcap2 & HWCAP2_BF16)\n     setCPUFeature(FEAT_BF16);\n-  if (hwcap2 & HWCAP2_SVEBF16)\n-    setCPUFeature(FEAT_SVE_BF16);\n   if (hwcap & HWCAP_SVE)\n     setCPUFeature(FEAT_SVE);\n   if (hwcap2 & HWCAP2_SVE2)\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/windows.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/windows.inc\nnew file mode 100644\nindex 000000000000..2ca18242fba3\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/windows.inc\n@@ -0,0 +1,85 @@\n+#define WIN32_LEAN_AND_MEAN\n+#include <windows.h>\n+#include <processthreadsapi.h>\n+#include <stdint.h>\n+\n+#ifndef PF_ARM_V82_DP_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_V82_DP_INSTRUCTIONS_AVAILABLE 43 \n+#endif\n+#ifndef PF_ARM_V83_JSCVT_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_V83_JSCVT_INSTRUCTIONS_AVAILABLE 44\n+#endif\n+#ifndef PF_ARM_V83_LRCPC_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_V83_LRCPC_INSTRUCTIONS_AVAILABLE 45\n+#endif\n+#ifndef PF_ARM_SVE_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_SVE_INSTRUCTIONS_AVAILABLE 46\n+#endif\n+#ifndef PF_ARM_SVE2_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_SVE2_INSTRUCTIONS_AVAILABLE 47\n+#endif\n+#ifndef PF_ARM_SVE_PMULL128_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_SVE_PMULL128_INSTRUCTIONS_AVAILABLE 50\n+#endif\n+#ifndef PF_ARM_SVE_SHA3_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_SVE_SHA3_INSTRUCTIONS_AVAILABLE 55\n+#endif\n+#ifndef PF_ARM_SVE_SM4_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_SVE_SM4_INSTRUCTIONS_AVAILABLE 56\n+#endif\n+#ifndef PF_ARM_SVE_I8MM_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_SVE_I8MM_INSTRUCTIONS_AVAILABLE 57\n+#endif\n+#ifndef PF_ARM_SVE_F32MM_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_SVE_F32MM_INSTRUCTIONS_AVAILABLE 58\n+#endif\n+#ifndef PF_ARM_SVE_F64MM_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_SVE_F64MM_INSTRUCTIONS_AVAILABLE 59\n+#endif\n+\n+void __init_cpu_features_resolver(unsigned long hwcap,\n+                                  const __ifunc_arg_t *arg) {}\n+\n+void CONSTRUCTOR_ATTRIBUTE __init_cpu_features(void) {\n+  if (__atomic_load_n(&__aarch64_cpu_features.features, __ATOMIC_RELAXED))\n+    return;\n+\n+#define setCPUFeature(F) features |= 1ULL << F\n+\n+  uint64_t features = 0;\n+\n+  setCPUFeature(FEAT_INIT);\n+  setCPUFeature(FEAT_FP);\n+\n+  // https://learn.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-isprocessorfeaturepresent\n+  if (IsProcessorFeaturePresent(PF_ARM_V8_CRYPTO_INSTRUCTIONS_AVAILABLE)) {\n+    setCPUFeature(FEAT_SHA2);\n+    setCPUFeature(FEAT_PMULL);\n+  }\n+\n+  static const struct ProcessFeatureToFeatMap_t {\n+    int WinApiFeature;\n+    enum CPUFeatures CPUFeature;\n+  } FeatMap[] = {\n+      {PF_ARM_V8_CRC32_INSTRUCTIONS_AVAILABLE, FEAT_CRC},\n+      {PF_ARM_V81_ATOMIC_INSTRUCTIONS_AVAILABLE, FEAT_LSE},\n+      {PF_ARM_V82_DP_INSTRUCTIONS_AVAILABLE, FEAT_DOTPROD},\n+      {PF_ARM_V83_JSCVT_INSTRUCTIONS_AVAILABLE, FEAT_JSCVT},\n+      {PF_ARM_V83_LRCPC_INSTRUCTIONS_AVAILABLE, FEAT_RCPC},\n+      {PF_ARM_SVE_INSTRUCTIONS_AVAILABLE, FEAT_SVE},\n+      {PF_ARM_SVE2_INSTRUCTIONS_AVAILABLE, FEAT_SVE2},\n+      {PF_ARM_SVE_PMULL128_INSTRUCTIONS_AVAILABLE, FEAT_SVE_PMULL128},\n+      {PF_ARM_SVE_SHA3_INSTRUCTIONS_AVAILABLE, FEAT_SVE_SHA3},\n+      {PF_ARM_SVE_SM4_INSTRUCTIONS_AVAILABLE, FEAT_SVE_SM4},\n+      {PF_ARM_SVE_F32MM_INSTRUCTIONS_AVAILABLE, FEAT_SVE_F32MM},\n+      {PF_ARM_SVE_F64MM_INSTRUCTIONS_AVAILABLE, FEAT_SVE_F64MM},\n+      // There is no I8MM flag, but when SVE_I8MM is available, I8MM is too.\n+      {PF_ARM_SVE_I8MM_INSTRUCTIONS_AVAILABLE, FEAT_I8MM},\n+  };\n+\n+  for (size_t I = 0, E = sizeof(FeatMap) / sizeof(FeatMap[0]); I != E; ++I)\n+    if (IsProcessorFeaturePresent(FeatMap[I].WinApiFeature))\n+      setCPUFeature(FeatMap[I].CPUFeature);\n+\n+  __atomic_store(&__aarch64_cpu_features.features, &features, __ATOMIC_RELAXED);\n+}\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/sysauxv.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/getauxval.inc\nsimilarity index 100%\nrename from contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/sysauxv.inc\nrename to contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/getauxval.inc\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/windows.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/windows.inc\nnew file mode 100644\nindex 000000000000..fff1593e1fac\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/windows.inc\n@@ -0,0 +1,12 @@\n+#define WIN32_LEAN_AND_MEAN\n+#include <windows.h>\n+#include <processthreadsapi.h>\n+\n+#ifndef PF_ARM_V81_ATOMIC_INSTRUCTIONS_AVAILABLE\n+#define PF_ARM_V81_ATOMIC_INSTRUCTIONS_AVAILABLE 34\n+#endif\n+\n+static void CONSTRUCTOR_ATTRIBUTE init_have_lse_atomics(void) {\n+  if (IsProcessorFeaturePresent(PF_ARM_V81_ATOMIC_INSTRUCTIONS_AVAILABLE))\n+    __aarch64_have_lse_atomics = true;\n+}\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/cpu_model.h b/contrib/libs/cxxsupp/builtins/cpu_model/cpu_model.h\nindex 924ca89cf60f..3bc4e63c4f25 100644\n--- a/contrib/libs/cxxsupp/builtins/cpu_model/cpu_model.h\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/cpu_model.h\n@@ -31,7 +31,15 @@\n // We're choosing init priority 90 to force our constructors to run before any\n // constructors in the end user application (starting at priority 101). This\n // value matches the libgcc choice for the same functions.\n-#define CONSTRUCTOR_ATTRIBUTE __attribute__((constructor(90)))\n+#ifdef _WIN32\n+// Contructor that replaces the ifunc runs currently with prio 10, see\n+// the LowerIFuncPass. The resolver of FMV depends on the cpu features so set\n+// the priority to 9.\n+#define CONSTRUCTOR_PRIORITY 9\n+#else\n+#define CONSTRUCTOR_PRIORITY 90\n+#endif\n+#define CONSTRUCTOR_ATTRIBUTE __attribute__((constructor(CONSTRUCTOR_PRIORITY)))\n #else\n // FIXME: For MSVC, we should make a function pointer global in .CRT$X?? so that\n // this runs during initialization.\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/riscv.c b/contrib/libs/cxxsupp/builtins/cpu_model/riscv.c\nnew file mode 100644\nindex 000000000000..6879c2ad4826\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/riscv.c\n@@ -0,0 +1,368 @@\n+//=== cpu_model/riscv.c - Update RISC-V Feature Bits Structure -*- C -*-======//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#include \"cpu_model.h\"\n+\n+#define RISCV_FEATURE_BITS_LENGTH 2\n+struct {\n+  unsigned length;\n+  unsigned long long features[RISCV_FEATURE_BITS_LENGTH];\n+} __riscv_feature_bits __attribute__((visibility(\"hidden\"), nocommon));\n+\n+struct {\n+  unsigned mvendorid;\n+  unsigned long long marchid;\n+  unsigned long long mimpid;\n+} __riscv_cpu_model __attribute__((visibility(\"hidden\"), nocommon));\n+\n+// NOTE: Should sync-up with RISCVFeatures.td\n+// TODO: Maybe generate a header from tablegen then include it.\n+#define A_GROUPID 0\n+#define A_BITMASK (1ULL << 0)\n+#define C_GROUPID 0\n+#define C_BITMASK (1ULL << 2)\n+#define D_GROUPID 0\n+#define D_BITMASK (1ULL << 3)\n+#define F_GROUPID 0\n+#define F_BITMASK (1ULL << 5)\n+#define I_GROUPID 0\n+#define I_BITMASK (1ULL << 8)\n+#define M_GROUPID 0\n+#define M_BITMASK (1ULL << 12)\n+#define V_GROUPID 0\n+#define V_BITMASK (1ULL << 21)\n+#define ZACAS_GROUPID 0\n+#define ZACAS_BITMASK (1ULL << 26)\n+#define ZBA_GROUPID 0\n+#define ZBA_BITMASK (1ULL << 27)\n+#define ZBB_GROUPID 0\n+#define ZBB_BITMASK (1ULL << 28)\n+#define ZBC_GROUPID 0\n+#define ZBC_BITMASK (1ULL << 29)\n+#define ZBKB_GROUPID 0\n+#define ZBKB_BITMASK (1ULL << 30)\n+#define ZBKC_GROUPID 0\n+#define ZBKC_BITMASK (1ULL << 31)\n+#define ZBKX_GROUPID 0\n+#define ZBKX_BITMASK (1ULL << 32)\n+#define ZBS_GROUPID 0\n+#define ZBS_BITMASK (1ULL << 33)\n+#define ZFA_GROUPID 0\n+#define ZFA_BITMASK (1ULL << 34)\n+#define ZFH_GROUPID 0\n+#define ZFH_BITMASK (1ULL << 35)\n+#define ZFHMIN_GROUPID 0\n+#define ZFHMIN_BITMASK (1ULL << 36)\n+#define ZICBOZ_GROUPID 0\n+#define ZICBOZ_BITMASK (1ULL << 37)\n+#define ZICOND_GROUPID 0\n+#define ZICOND_BITMASK (1ULL << 38)\n+#define ZIHINTNTL_GROUPID 0\n+#define ZIHINTNTL_BITMASK (1ULL << 39)\n+#define ZIHINTPAUSE_GROUPID 0\n+#define ZIHINTPAUSE_BITMASK (1ULL << 40)\n+#define ZKND_GROUPID 0\n+#define ZKND_BITMASK (1ULL << 41)\n+#define ZKNE_GROUPID 0\n+#define ZKNE_BITMASK (1ULL << 42)\n+#define ZKNH_GROUPID 0\n+#define ZKNH_BITMASK (1ULL << 43)\n+#define ZKSED_GROUPID 0\n+#define ZKSED_BITMASK (1ULL << 44)\n+#define ZKSH_GROUPID 0\n+#define ZKSH_BITMASK (1ULL << 45)\n+#define ZKT_GROUPID 0\n+#define ZKT_BITMASK (1ULL << 46)\n+#define ZTSO_GROUPID 0\n+#define ZTSO_BITMASK (1ULL << 47)\n+#define ZVBB_GROUPID 0\n+#define ZVBB_BITMASK (1ULL << 48)\n+#define ZVBC_GROUPID 0\n+#define ZVBC_BITMASK (1ULL << 49)\n+#define ZVFH_GROUPID 0\n+#define ZVFH_BITMASK (1ULL << 50)\n+#define ZVFHMIN_GROUPID 0\n+#define ZVFHMIN_BITMASK (1ULL << 51)\n+#define ZVKB_GROUPID 0\n+#define ZVKB_BITMASK (1ULL << 52)\n+#define ZVKG_GROUPID 0\n+#define ZVKG_BITMASK (1ULL << 53)\n+#define ZVKNED_GROUPID 0\n+#define ZVKNED_BITMASK (1ULL << 54)\n+#define ZVKNHA_GROUPID 0\n+#define ZVKNHA_BITMASK (1ULL << 55)\n+#define ZVKNHB_GROUPID 0\n+#define ZVKNHB_BITMASK (1ULL << 56)\n+#define ZVKSED_GROUPID 0\n+#define ZVKSED_BITMASK (1ULL << 57)\n+#define ZVKSH_GROUPID 0\n+#define ZVKSH_BITMASK (1ULL << 58)\n+#define ZVKT_GROUPID 0\n+#define ZVKT_BITMASK (1ULL << 59)\n+#define ZVE32X_GROUPID 0\n+#define ZVE32X_BITMASK (1ULL << 60)\n+#define ZVE32F_GROUPID 0\n+#define ZVE32F_BITMASK (1ULL << 61)\n+#define ZVE64X_GROUPID 0\n+#define ZVE64X_BITMASK (1ULL << 62)\n+#define ZVE64F_GROUPID 0\n+#define ZVE64F_BITMASK (1ULL << 63)\n+#define ZVE64D_GROUPID 1\n+#define ZVE64D_BITMASK (1ULL << 0)\n+#define ZIMOP_GROUPID 1\n+#define ZIMOP_BITMASK (1ULL << 1)\n+#define ZCA_GROUPID 1\n+#define ZCA_BITMASK (1ULL << 2)\n+#define ZCB_GROUPID 1\n+#define ZCB_BITMASK (1ULL << 3)\n+#define ZCD_GROUPID 1\n+#define ZCD_BITMASK (1ULL << 4)\n+#define ZCF_GROUPID 1\n+#define ZCF_BITMASK (1ULL << 5)\n+#define ZCMOP_GROUPID 1\n+#define ZCMOP_BITMASK (1ULL << 6)\n+#define ZAWRS_GROUPID 1\n+#define ZAWRS_BITMASK (1ULL << 7)\n+\n+#if defined(__linux__)\n+\n+// The RISC-V hwprobe interface is documented here:\n+// <https://docs.kernel.org/arch/riscv/hwprobe.html>.\n+\n+static long syscall_impl_5_args(long number, long arg1, long arg2, long arg3,\n+                                long arg4, long arg5) {\n+  register long a7 __asm__(\"a7\") = number;\n+  register long a0 __asm__(\"a0\") = arg1;\n+  register long a1 __asm__(\"a1\") = arg2;\n+  register long a2 __asm__(\"a2\") = arg3;\n+  register long a3 __asm__(\"a3\") = arg4;\n+  register long a4 __asm__(\"a4\") = arg5;\n+  __asm__ __volatile__(\"ecall\\n\\t\"\n+                       : \"=r\"(a0)\n+                       : \"r\"(a7), \"r\"(a0), \"r\"(a1), \"r\"(a2), \"r\"(a3), \"r\"(a4)\n+                       : \"memory\");\n+  return a0;\n+}\n+\n+#define RISCV_HWPROBE_KEY_MVENDORID 0\n+#define RISCV_HWPROBE_KEY_MARCHID 1\n+#define RISCV_HWPROBE_KEY_MIMPID 2\n+#define RISCV_HWPROBE_KEY_BASE_BEHAVIOR 3\n+#define RISCV_HWPROBE_BASE_BEHAVIOR_IMA (1ULL << 0)\n+#define RISCV_HWPROBE_KEY_IMA_EXT_0 4\n+#define RISCV_HWPROBE_IMA_FD (1ULL << 0)\n+#define RISCV_HWPROBE_IMA_C (1ULL << 1)\n+#define RISCV_HWPROBE_IMA_V (1ULL << 2)\n+#define RISCV_HWPROBE_EXT_ZBA (1ULL << 3)\n+#define RISCV_HWPROBE_EXT_ZBB (1ULL << 4)\n+#define RISCV_HWPROBE_EXT_ZBS (1ULL << 5)\n+#define RISCV_HWPROBE_EXT_ZICBOZ (1ULL << 6)\n+#define RISCV_HWPROBE_EXT_ZBC (1ULL << 7)\n+#define RISCV_HWPROBE_EXT_ZBKB (1ULL << 8)\n+#define RISCV_HWPROBE_EXT_ZBKC (1ULL << 9)\n+#define RISCV_HWPROBE_EXT_ZBKX (1ULL << 10)\n+#define RISCV_HWPROBE_EXT_ZKND (1ULL << 11)\n+#define RISCV_HWPROBE_EXT_ZKNE (1ULL << 12)\n+#define RISCV_HWPROBE_EXT_ZKNH (1ULL << 13)\n+#define RISCV_HWPROBE_EXT_ZKSED (1ULL << 14)\n+#define RISCV_HWPROBE_EXT_ZKSH (1ULL << 15)\n+#define RISCV_HWPROBE_EXT_ZKT (1ULL << 16)\n+#define RISCV_HWPROBE_EXT_ZVBB (1ULL << 17)\n+#define RISCV_HWPROBE_EXT_ZVBC (1ULL << 18)\n+#define RISCV_HWPROBE_EXT_ZVKB (1ULL << 19)\n+#define RISCV_HWPROBE_EXT_ZVKG (1ULL << 20)\n+#define RISCV_HWPROBE_EXT_ZVKNED (1ULL << 21)\n+#define RISCV_HWPROBE_EXT_ZVKNHA (1ULL << 22)\n+#define RISCV_HWPROBE_EXT_ZVKNHB (1ULL << 23)\n+#define RISCV_HWPROBE_EXT_ZVKSED (1ULL << 24)\n+#define RISCV_HWPROBE_EXT_ZVKSH (1ULL << 25)\n+#define RISCV_HWPROBE_EXT_ZVKT (1ULL << 26)\n+#define RISCV_HWPROBE_EXT_ZFH (1ULL << 27)\n+#define RISCV_HWPROBE_EXT_ZFHMIN (1ULL << 28)\n+#define RISCV_HWPROBE_EXT_ZIHINTNTL (1ULL << 29)\n+#define RISCV_HWPROBE_EXT_ZVFH (1ULL << 30)\n+#define RISCV_HWPROBE_EXT_ZVFHMIN (1ULL << 31)\n+#define RISCV_HWPROBE_EXT_ZFA (1ULL << 32)\n+#define RISCV_HWPROBE_EXT_ZTSO (1ULL << 33)\n+#define RISCV_HWPROBE_EXT_ZACAS (1ULL << 34)\n+#define RISCV_HWPROBE_EXT_ZICOND (1ULL << 35)\n+#define RISCV_HWPROBE_EXT_ZIHINTPAUSE (1ULL << 36)\n+#define RISCV_HWPROBE_EXT_ZVE32X (1ULL << 37)\n+#define RISCV_HWPROBE_EXT_ZVE32F (1ULL << 38)\n+#define RISCV_HWPROBE_EXT_ZVE64X (1ULL << 39)\n+#define RISCV_HWPROBE_EXT_ZVE64F (1ULL << 40)\n+#define RISCV_HWPROBE_EXT_ZVE64D (1ULL << 41)\n+#define RISCV_HWPROBE_EXT_ZIMOP (1ULL << 42)\n+#define RISCV_HWPROBE_EXT_ZCA (1ULL << 43)\n+#define RISCV_HWPROBE_EXT_ZCB (1ULL << 44)\n+#define RISCV_HWPROBE_EXT_ZCD (1ULL << 45)\n+#define RISCV_HWPROBE_EXT_ZCF (1ULL << 46)\n+#define RISCV_HWPROBE_EXT_ZCMOP (1ULL << 47)\n+#define RISCV_HWPROBE_EXT_ZAWRS (1ULL << 48)\n+#define RISCV_HWPROBE_KEY_CPUPERF_0 5\n+#define RISCV_HWPROBE_MISALIGNED_UNKNOWN (0 << 0)\n+#define RISCV_HWPROBE_MISALIGNED_EMULATED (1ULL << 0)\n+#define RISCV_HWPROBE_MISALIGNED_SLOW (2 << 0)\n+#define RISCV_HWPROBE_MISALIGNED_FAST (3 << 0)\n+#define RISCV_HWPROBE_MISALIGNED_UNSUPPORTED (4 << 0)\n+#define RISCV_HWPROBE_MISALIGNED_MASK (7 << 0)\n+#define RISCV_HWPROBE_KEY_ZICBOZ_BLOCK_SIZE 6\n+/* Increase RISCV_HWPROBE_MAX_KEY when adding items. */\n+\n+struct riscv_hwprobe {\n+  long long key;\n+  unsigned long long value;\n+};\n+\n+#define __NR_riscv_hwprobe 258\n+static long initHwProbe(struct riscv_hwprobe *Hwprobes, int len) {\n+  return syscall_impl_5_args(__NR_riscv_hwprobe, (long)Hwprobes, len, 0, 0, 0);\n+}\n+\n+#define SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(EXTNAME)                    \\\n+  SET_SINGLE_IMAEXT_RISCV_FEATURE(RISCV_HWPROBE_EXT_##EXTNAME, EXTNAME)\n+\n+#define SET_SINGLE_IMAEXT_RISCV_FEATURE(HWPROBE_BITMASK, EXT)                  \\\n+  SET_SINGLE_RISCV_FEATURE(IMAEXT0Value &HWPROBE_BITMASK, EXT)\n+\n+#define SET_SINGLE_RISCV_FEATURE(COND, EXT)                                    \\\n+  if (COND) {                                                                  \\\n+    SET_RISCV_FEATURE(EXT);                                                    \\\n+  }\n+\n+#define SET_RISCV_FEATURE(EXT) features[EXT##_GROUPID] |= EXT##_BITMASK\n+\n+static void initRISCVFeature(struct riscv_hwprobe Hwprobes[]) {\n+\n+  // Note: If a hwprobe key is unknown to the kernel, its key field\n+  // will be cleared to -1, and its value set to 0.\n+  // This unsets all extension bitmask bits.\n+\n+  // Init VendorID, ArchID, ImplID\n+  __riscv_cpu_model.mvendorid = Hwprobes[2].value;\n+  __riscv_cpu_model.marchid = Hwprobes[3].value;\n+  __riscv_cpu_model.mimpid = Hwprobes[4].value;\n+\n+  // Init standard extension\n+  // TODO: Maybe Extension implied generate from tablegen?\n+\n+  unsigned long long features[RISCV_FEATURE_BITS_LENGTH];\n+  int i;\n+\n+  for (i = 0; i < RISCV_FEATURE_BITS_LENGTH; i++)\n+    features[i] = 0;\n+\n+  // Check RISCV_HWPROBE_KEY_BASE_BEHAVIOR\n+  unsigned long long BaseValue = Hwprobes[0].value;\n+  if (BaseValue & RISCV_HWPROBE_BASE_BEHAVIOR_IMA) {\n+    SET_RISCV_FEATURE(I);\n+    SET_RISCV_FEATURE(M);\n+    SET_RISCV_FEATURE(A);\n+  }\n+\n+  // Check RISCV_HWPROBE_KEY_IMA_EXT_0\n+  unsigned long long IMAEXT0Value = Hwprobes[1].value;\n+  if (IMAEXT0Value & RISCV_HWPROBE_IMA_FD) {\n+    SET_RISCV_FEATURE(F);\n+    SET_RISCV_FEATURE(D);\n+  }\n+\n+  SET_SINGLE_IMAEXT_RISCV_FEATURE(RISCV_HWPROBE_IMA_C, C);\n+  SET_SINGLE_IMAEXT_RISCV_FEATURE(RISCV_HWPROBE_IMA_V, V);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBA);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBB);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBS);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZICBOZ);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBC);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBKB);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBKC);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBKX);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKND);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKNE);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKNH);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKSED);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKSH);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKT);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVBB);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVBC);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKB);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKG);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKNED);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKNHA);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKNHB);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKSED);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKSH);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKT);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZFH);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZFHMIN);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZIHINTNTL);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZIHINTPAUSE);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVFH);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVFHMIN);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZFA);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZTSO);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZACAS);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZICOND);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVE32X);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVE32F);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVE64X);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVE64F);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVE64D);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZIMOP);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZCA);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZCB);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZCD);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZCF);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZCMOP);\n+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZAWRS);\n+\n+  for (i = 0; i < RISCV_FEATURE_BITS_LENGTH; i++)\n+    __riscv_feature_bits.features[i] = features[i];\n+}\n+\n+#endif // defined(__linux__)\n+\n+static int FeaturesBitCached = 0;\n+\n+void __init_riscv_feature_bits(void *);\n+static void __init_riscv_feature_bits_ctor(void) CONSTRUCTOR_ATTRIBUTE;\n+\n+// A constructor function that sets __riscv_feature_bits\n+// to the right values.  This needs to run only once.  This constructor is given\n+// the highest priority and it should run before constructors without the\n+// priority set.  However, it still runs after ifunc initializers and needs to\n+// be called explicitly there.\n+\n+static void CONSTRUCTOR_ATTRIBUTE __init_riscv_feature_bits_ctor(void) {\n+  __init_riscv_feature_bits(0);\n+}\n+\n+// PlatformArgs allows the platform to provide pre-computed data and access it\n+// without extra effort. For example, Linux could pass the vDSO object to avoid\n+// an extra system call.\n+void __init_riscv_feature_bits(void *PlatformArgs) {\n+\n+  if (FeaturesBitCached)\n+    return;\n+\n+  __riscv_feature_bits.length = RISCV_FEATURE_BITS_LENGTH;\n+\n+#if defined(__linux__)\n+  struct riscv_hwprobe Hwprobes[] = {\n+      {RISCV_HWPROBE_KEY_BASE_BEHAVIOR, 0}, {RISCV_HWPROBE_KEY_IMA_EXT_0, 0},\n+      {RISCV_HWPROBE_KEY_MVENDORID, 0},     {RISCV_HWPROBE_KEY_MARCHID, 0},\n+      {RISCV_HWPROBE_KEY_MIMPID, 0},\n+  };\n+  if (initHwProbe(Hwprobes, sizeof(Hwprobes) / sizeof(Hwprobes[0])))\n+    return;\n+\n+  initRISCVFeature(Hwprobes);\n+#endif // defined(__linux__)\n+\n+  FeaturesBitCached = 1;\n+}\ndiff --git a/contrib/libs/cxxsupp/builtins/cpu_model/x86.c b/contrib/libs/cxxsupp/builtins/cpu_model/x86.c\nindex b1c4abd9d11d..606571d52750 100644\n--- a/contrib/libs/cxxsupp/builtins/cpu_model/x86.c\n+++ b/contrib/libs/cxxsupp/builtins/cpu_model/x86.c\n@@ -23,6 +23,10 @@\n \n #include <assert.h>\n \n+#if (defined(__GNUC__) || defined(__clang__)) && !defined(_MSC_VER)\n+#include <cpuid.h>\n+#endif\n+\n #ifdef _MSC_VER\n #include <intrin.h>\n #endif\n@@ -99,6 +103,7 @@ enum ProcessorSubtypes {\n   INTEL_COREI7_ARROWLAKE_S,\n   INTEL_COREI7_PANTHERLAKE,\n   AMDFAM1AH_ZNVER5,\n+  INTEL_COREI7_DIAMONDRAPIDS,\n   CPU_SUBTYPE_MAX\n };\n \n@@ -223,41 +228,12 @@ enum ProcessorFeatures {\n   FEATURE_USERMSR,\n   FEATURE_AVX10_1_256,\n   FEATURE_AVX10_1_512,\n+  FEATURE_AVX10_2_256,\n+  FEATURE_AVX10_2_512,\n+  FEATURE_MOVRS,\n   CPU_FEATURE_MAX\n };\n \n-// The check below for i386 was copied from clang's cpuid.h (__get_cpuid_max).\n-// Check motivated by bug reports for OpenSSL crashing on CPUs without CPUID\n-// support. Consequently, for i386, the presence of CPUID is checked first\n-// via the corresponding eflags bit.\n-static bool isCpuIdSupported(void) {\n-#if defined(__GNUC__) || defined(__clang__)\n-#if defined(__i386__)\n-  int __cpuid_supported;\n-  __asm__(\"  pushfl\\n\"\n-          \"  popl   %%eax\\n\"\n-          \"  movl   %%eax,%%ecx\\n\"\n-          \"  xorl   $0x00200000,%%eax\\n\"\n-          \"  pushl  %%eax\\n\"\n-          \"  popfl\\n\"\n-          \"  pushfl\\n\"\n-          \"  popl   %%eax\\n\"\n-          \"  movl   $0,%0\\n\"\n-          \"  cmpl   %%eax,%%ecx\\n\"\n-          \"  je     1f\\n\"\n-          \"  movl   $1,%0\\n\"\n-          \"1:\"\n-          : \"=r\"(__cpuid_supported)\n-          :\n-          : \"eax\", \"ecx\");\n-  if (!__cpuid_supported)\n-    return false;\n-#endif\n-  return true;\n-#endif\n-  return true;\n-}\n-\n // This code is copied from lib/Support/Host.cpp.\n // Changes to either file should be mirrored in the other.\n \n@@ -265,26 +241,8 @@ static bool isCpuIdSupported(void) {\n /// the specified arguments.  If we can't run cpuid on the host, return true.\n static bool getX86CpuIDAndInfo(unsigned value, unsigned *rEAX, unsigned *rEBX,\n                                unsigned *rECX, unsigned *rEDX) {\n-#if defined(__GNUC__) || defined(__clang__)\n-#if defined(__x86_64__)\n-  // gcc doesn't know cpuid would clobber ebx/rbx. Preserve it manually.\n-  // FIXME: should we save this for Clang?\n-  __asm__(\"movq\\t%%rbx, %%rsi\\n\\t\"\n-          \"cpuid\\n\\t\"\n-          \"xchgq\\t%%rbx, %%rsi\\n\\t\"\n-          : \"=a\"(*rEAX), \"=S\"(*rEBX), \"=c\"(*rECX), \"=d\"(*rEDX)\n-          : \"a\"(value));\n-  return false;\n-#elif defined(__i386__)\n-  __asm__(\"movl\\t%%ebx, %%esi\\n\\t\"\n-          \"cpuid\\n\\t\"\n-          \"xchgl\\t%%ebx, %%esi\\n\\t\"\n-          : \"=a\"(*rEAX), \"=S\"(*rEBX), \"=c\"(*rECX), \"=d\"(*rEDX)\n-          : \"a\"(value));\n-  return false;\n-#else\n-  return true;\n-#endif\n+#if (defined(__GNUC__) || defined(__clang__)) && !defined(_MSC_VER)\n+  return !__get_cpuid(value, rEAX, rEBX, rECX, rEDX);\n #elif defined(_MSC_VER)\n   // The MSVC intrinsic is portable across x86 and x64.\n   int registers[4];\n@@ -305,26 +263,12 @@ static bool getX86CpuIDAndInfo(unsigned value, unsigned *rEAX, unsigned *rEBX,\n static bool getX86CpuIDAndInfoEx(unsigned value, unsigned subleaf,\n                                  unsigned *rEAX, unsigned *rEBX, unsigned *rECX,\n                                  unsigned *rEDX) {\n-#if defined(__GNUC__) || defined(__clang__)\n-#if defined(__x86_64__)\n-  // gcc doesn't know cpuid would clobber ebx/rbx. Preserve it manually.\n-  // FIXME: should we save this for Clang?\n-  __asm__(\"movq\\t%%rbx, %%rsi\\n\\t\"\n-          \"cpuid\\n\\t\"\n-          \"xchgq\\t%%rbx, %%rsi\\n\\t\"\n-          : \"=a\"(*rEAX), \"=S\"(*rEBX), \"=c\"(*rECX), \"=d\"(*rEDX)\n-          : \"a\"(value), \"c\"(subleaf));\n-  return false;\n-#elif defined(__i386__)\n-  __asm__(\"movl\\t%%ebx, %%esi\\n\\t\"\n-          \"cpuid\\n\\t\"\n-          \"xchgl\\t%%ebx, %%esi\\n\\t\"\n-          : \"=a\"(*rEAX), \"=S\"(*rEBX), \"=c\"(*rECX), \"=d\"(*rEDX)\n-          : \"a\"(value), \"c\"(subleaf));\n-  return false;\n-#else\n-  return true;\n-#endif\n+  // TODO(boomanaiden154): When the minimum toolchain versions for gcc and clang\n+  // are such that __cpuidex is defined within cpuid.h for both, we can remove\n+  // the __get_cpuid_count function and share the MSVC implementation between\n+  // all three.\n+#if (defined(__GNUC__) || defined(__clang__)) && !defined(_MSC_VER)\n+  return !__get_cpuid_count(value, subleaf, rEAX, rEBX, rECX, rEDX);\n #elif defined(_MSC_VER)\n   int registers[4];\n   __cpuidex(registers, value, subleaf);\n@@ -340,6 +284,9 @@ static bool getX86CpuIDAndInfoEx(unsigned value, unsigned subleaf,\n \n // Read control register 0 (XCR0). Used to detect features such as AVX.\n static bool getX86XCR0(unsigned *rEAX, unsigned *rEDX) {\n+  // TODO(boomanaiden154): When the minimum toolchain versions for gcc and clang\n+  // are such that _xgetbv is supported by both, we can unify the implementation\n+  // with MSVC and remove all inline assembly.\n #if defined(__GNUC__) || defined(__clang__)\n   // Check xgetbv; this uses a .byte sequence instead of the instruction\n   // directly because older assemblers do not include support for xgetbv and\n@@ -514,22 +461,39 @@ static const char *getIntelProcessorTypeAndSubtype(unsigned Family,\n     // Alderlake:\n     case 0x97:\n     case 0x9a:\n+      CPU = \"alderlake\";\n+      *Type = INTEL_COREI7;\n+      *Subtype = INTEL_COREI7_ALDERLAKE;\n+      break;\n+\n     // Raptorlake:\n     case 0xb7:\n     case 0xba:\n     case 0xbf:\n+      CPU = \"raptorlake\";\n+      *Type = INTEL_COREI7;\n+      *Subtype = INTEL_COREI7_ALDERLAKE;\n+      break;\n+\n     // Meteorlake:\n     case 0xaa:\n     case 0xac:\n+      CPU = \"meteorlake\";\n+      *Type = INTEL_COREI7;\n+      *Subtype = INTEL_COREI7_ALDERLAKE;\n+      break;\n+\n     // Gracemont:\n     case 0xbe:\n-      CPU = \"alderlake\";\n+      CPU = \"gracemont\";\n       *Type = INTEL_COREI7;\n       *Subtype = INTEL_COREI7_ALDERLAKE;\n       break;\n \n     // Arrowlake:\n     case 0xc5:\n+    // Arrowlake U:\n+    case 0xb5:\n       CPU = \"arrowlake\";\n       *Type = INTEL_COREI7;\n       *Subtype = INTEL_COREI7_ARROWLAKE;\n@@ -537,9 +501,14 @@ static const char *getIntelProcessorTypeAndSubtype(unsigned Family,\n \n     // Arrowlake S:\n     case 0xc6:\n+      CPU = \"arrowlake-s\";\n+      *Type = INTEL_COREI7;\n+      *Subtype = INTEL_COREI7_ARROWLAKE_S;\n+      break;\n+\n     // Lunarlake:\n     case 0xbd:\n-      CPU = \"arrowlake-s\";\n+      CPU = \"lunarlake\";\n       *Type = INTEL_COREI7;\n       *Subtype = INTEL_COREI7_ARROWLAKE_S;\n       break;\n@@ -561,6 +530,11 @@ static const char *getIntelProcessorTypeAndSubtype(unsigned Family,\n \n     // Emerald Rapids:\n     case 0xcf:\n+      CPU = \"emeraldrapids\";\n+      *Type = INTEL_COREI7;\n+      *Subtype = INTEL_COREI7_SAPPHIRERAPIDS;\n+      break;\n+\n     // Sapphire Rapids:\n     case 0x8f:\n       CPU = \"sapphirerapids\";\n@@ -652,6 +626,19 @@ static const char *getIntelProcessorTypeAndSubtype(unsigned Family,\n       break;\n     }\n     break;\n+  case 19:\n+    switch (Model) {\n+    // Diamond Rapids:\n+    case 0x01:\n+      CPU = \"diamondrapids\";\n+      *Type = INTEL_COREI7;\n+      *Subtype = INTEL_COREI7_DIAMONDRAPIDS;\n+      break;\n+\n+    default: // Unknown family 19 CPU.\n+      break;\n+    }\n+    break;\n   default:\n     break; // Unknown.\n   }\n@@ -704,6 +691,7 @@ static const char *getAMDProcessorTypeAndSubtype(unsigned Family,\n     CPU = \"k8\";\n     break;\n   case 16:\n+  case 18:\n     CPU = \"amdfam10\";\n     *Type = AMDFAM10H; // \"amdfam10\"\n     switch (Model) {\n@@ -1024,6 +1012,8 @@ static void getAvailableFeatures(unsigned ECX, unsigned EDX, unsigned MaxLeaf,\n     setFeature(FEATURE_HRESET);\n   if (HasLeaf7Subleaf1 && ((EAX >> 23) & 1) && HasAVXSave)\n     setFeature(FEATURE_AVXIFMA);\n+  if (HasLeaf7Subleaf1 && ((EAX >> 31) & 1))\n+    setFeature(FEATURE_MOVRS);\n \n   if (HasLeaf7Subleaf1 && ((EDX >> 4) & 1) && HasAVXSave)\n     setFeature(FEATURE_AVXVNNIINT8);\n@@ -1037,12 +1027,10 @@ static void getAvailableFeatures(unsigned ECX, unsigned EDX, unsigned MaxLeaf,\n     setFeature(FEATURE_PREFETCHI);\n   if (HasLeaf7Subleaf1 && ((EDX >> 15) & 1))\n     setFeature(FEATURE_USERMSR);\n-  if (HasLeaf7Subleaf1 && ((EDX >> 19) & 1))\n-    setFeature(FEATURE_AVX10_1_256);\n   if (HasLeaf7Subleaf1 && ((EDX >> 21) & 1))\n     setFeature(FEATURE_APXF);\n \n-  unsigned MaxLevel;\n+  unsigned MaxLevel = 0;\n   getX86CpuIDAndInfo(0, &MaxLevel, &EBX, &ECX, &EDX);\n   bool HasLeafD = MaxLevel >= 0xd &&\n                   !getX86CpuIDAndInfoEx(0xd, 0x1, &EAX, &EBX, &ECX, &EDX);\n@@ -1055,10 +1043,22 @@ static void getAvailableFeatures(unsigned ECX, unsigned EDX, unsigned MaxLeaf,\n \n   bool HasLeaf24 =\n       MaxLevel >= 0x24 && !getX86CpuIDAndInfo(0x24, &EAX, &EBX, &ECX, &EDX);\n-  if (HasLeaf7Subleaf1 && ((EDX >> 19) & 1) && HasLeaf24 && ((EBX >> 18) & 1))\n-    setFeature(FEATURE_AVX10_1_512);\n+  if (HasLeaf7Subleaf1 && ((EDX >> 19) & 1) && HasLeaf24) {\n+    bool Has512Len = (EBX >> 18) & 1;\n+    int AVX10Ver = EBX & 0xff;\n+    if (AVX10Ver >= 2) {\n+      setFeature(FEATURE_AVX10_2_256);\n+      if (Has512Len)\n+        setFeature(FEATURE_AVX10_2_512);\n+    }\n+    if (AVX10Ver >= 1) {\n+      setFeature(FEATURE_AVX10_1_256);\n+      if (Has512Len)\n+        setFeature(FEATURE_AVX10_1_512);\n+    }\n+  }\n \n-  unsigned MaxExtLevel;\n+  unsigned MaxExtLevel = 0;\n   getX86CpuIDAndInfo(0x80000000, &MaxExtLevel, &EBX, &ECX, &EDX);\n \n   bool HasExtLeaf1 = MaxExtLevel >= 0x80000001 &&\n@@ -1152,7 +1152,7 @@ unsigned __cpu_features2[(CPU_FEATURE_MAX - 1) / 32];\n // needs to be called explicitly there.\n \n int CONSTRUCTOR_ATTRIBUTE __cpu_indicator_init(void) {\n-  unsigned EAX, EBX, ECX, EDX;\n+  unsigned EAX = 0, EBX = 0, ECX = 0, EDX = 0;\n   unsigned MaxLeaf = 5;\n   unsigned Vendor;\n   unsigned Model, Family;\n@@ -1164,8 +1164,7 @@ int CONSTRUCTOR_ATTRIBUTE __cpu_indicator_init(void) {\n   if (__cpu_model.__cpu_vendor)\n     return 0;\n \n-  if (!isCpuIdSupported() ||\n-      getX86CpuIDAndInfo(0, &MaxLeaf, &Vendor, &ECX, &EDX) || MaxLeaf < 1) {\n+  if (getX86CpuIDAndInfo(0, &MaxLeaf, &Vendor, &ECX, &EDX) || MaxLeaf < 1) {\n     __cpu_model.__cpu_vendor = VENDOR_OTHER;\n     return -1;\n   }\ndiff --git a/contrib/libs/cxxsupp/builtins/crtbegin.c b/contrib/libs/cxxsupp/builtins/crtbegin.c\nindex a0860ca12ea0..67d8d3fbbd78 100644\n--- a/contrib/libs/cxxsupp/builtins/crtbegin.c\n+++ b/contrib/libs/cxxsupp/builtins/crtbegin.c\n@@ -8,6 +8,14 @@\n \n #include <stddef.h>\n \n+#ifndef __has_feature\n+# define __has_feature(x) 0\n+#endif\n+\n+#if __has_feature(ptrauth_init_fini)\n+\n+#endif\n+\n __attribute__((visibility(\"hidden\"))) void *__dso_handle = &__dso_handle;\n \n #ifdef EH_USE_FRAME_REGISTRY\n@@ -46,8 +54,22 @@ static void __attribute__((used)) __do_init(void) {\n }\n \n #ifdef CRT_HAS_INITFINI_ARRAY\n+#if __has_feature(ptrauth_init_fini)\n+// TODO: use __ptrauth-qualified pointers when they are supported on clang side\n+#if __has_feature(ptrauth_init_fini_address_discrimination)\n+__attribute__((section(\".init_array\"), used)) static void *__init =\n+    ptrauth_sign_constant(&__do_init, ptrauth_key_init_fini_pointer,\n+                          ptrauth_blend_discriminator(\n+                              &__init, __ptrauth_init_fini_discriminator));\n+#else\n+__attribute__((section(\".init_array\"), used)) static void *__init =\n+    ptrauth_sign_constant(&__do_init, ptrauth_key_init_fini_pointer,\n+                          __ptrauth_init_fini_discriminator);\n+#endif\n+#else\n __attribute__((section(\".init_array\"),\n                used)) static void (*__init)(void) = __do_init;\n+#endif\n #elif defined(__i386__) || defined(__x86_64__)\n __asm__(\".pushsection .init,\\\"ax\\\",@progbits\\n\\t\"\n         \"call __do_init\\n\\t\"\n@@ -103,8 +125,22 @@ static void __attribute__((used)) __do_fini(void) {\n }\n \n #ifdef CRT_HAS_INITFINI_ARRAY\n+#if __has_feature(ptrauth_init_fini)\n+// TODO: use __ptrauth-qualified pointers when they are supported on clang side\n+#if __has_feature(ptrauth_init_fini_address_discrimination)\n+__attribute__((section(\".fini_array\"), used)) static void *__fini =\n+    ptrauth_sign_constant(&__do_fini, ptrauth_key_init_fini_pointer,\n+                          ptrauth_blend_discriminator(\n+                              &__fini, __ptrauth_init_fini_discriminator));\n+#else\n+__attribute__((section(\".fini_array\"), used)) static void *__fini =\n+    ptrauth_sign_constant(&__do_fini, ptrauth_key_init_fini_pointer,\n+                          __ptrauth_init_fini_discriminator);\n+#endif\n+#else\n __attribute__((section(\".fini_array\"),\n                used)) static void (*__fini)(void) = __do_fini;\n+#endif\n #elif defined(__i386__) || defined(__x86_64__)\n __asm__(\".pushsection .fini,\\\"ax\\\",@progbits\\n\\t\"\n         \"call __do_fini\\n\\t\"\ndiff --git a/contrib/libs/cxxsupp/builtins/divsc3.c b/contrib/libs/cxxsupp/builtins/divsc3.c\nindex aa4fd8e79e0c..6529651252c5 100644\n--- a/contrib/libs/cxxsupp/builtins/divsc3.c\n+++ b/contrib/libs/cxxsupp/builtins/divsc3.c\n@@ -20,7 +20,7 @@\n COMPILER_RT_ABI Fcomplex __divsc3(float __a, float __b, float __c, float __d) {\n   int __ilogbw = 0;\n   float __logbw =\n-      __compiler_rt_logbf(__compiler_rt_fmaxf(crt_fabsf(__c), crt_fabsf(__d)));\n+      __compiler_rt_logbf(__compiler_rt_fmaxX(crt_fabsf(__c), crt_fabsf(__d)));\n   if (crt_isfinite(__logbw)) {\n     __ilogbw = (int)__logbw;\n     __c = __compiler_rt_scalbnf(__c, -__ilogbw);\ndiff --git a/contrib/libs/cxxsupp/builtins/extendhfxf2.c b/contrib/libs/cxxsupp/builtins/extendhfxf2.c\nnew file mode 100644\nindex 000000000000..a2cd106e1c1b\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/extendhfxf2.c\n@@ -0,0 +1,16 @@\n+//===-- lib/extendhfxf2.c - half -> long double conversion --------*- C -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+#include \"int_lib.h\"\n+#define SRC_HALF\n+#define DST_DOUBLE\n+#include \"fp_extend_impl.inc\"\n+\n+// Long double are expected to be as precise as double.\n+COMPILER_RT_ABI xf_float __extendhfxf2(src_t a) {\n+  return (xf_float)__extendXfYf2__(a);\n+}\ndiff --git a/contrib/libs/cxxsupp/builtins/fp_div_impl.inc b/contrib/libs/cxxsupp/builtins/fp_div_impl.inc\nindex 29bcd1920edf..de61e55cd083 100644\n--- a/contrib/libs/cxxsupp/builtins/fp_div_impl.inc\n+++ b/contrib/libs/cxxsupp/builtins/fp_div_impl.inc\n@@ -334,7 +334,6 @@ static __inline fp_t __divXf3__(fp_t a, fp_t b) {\n   // Suppose 1/b - P * 2^-W < x < 1/b + P * 2^-W\n   x_UQ0 -= RECIPROCAL_PRECISION;\n   // Now 1/b - (2*P) * 2^-W < x < 1/b\n-  // FIXME Is x_UQ0 still >= 0.5?\n \n   rep_t quotient_UQ1, dummy;\n   wideMultiply(x_UQ0, aSignificand << 1, &quotient_UQ1, &dummy);\n@@ -344,6 +343,12 @@ static __inline fp_t __divXf3__(fp_t a, fp_t b) {\n   // adjust it to be in [1.0, 2.0) as UQ1.SB.\n   rep_t residualLo;\n   if (quotient_UQ1 < (implicitBit << 1)) {\n+    if (quotient_UQ1 < implicitBit) {\n+      // In a rare case where quotient is < 0.5, we can adjust the quotient and\n+      // the written exponent, and then treat them the same way as in [0.5, 1.0)\n+      quotient_UQ1 <<= 1;\n+      writtenExponent -= 1;\n+    }\n     // Highest bit is 0, so just reinterpret quotient_UQ1 as UQ1.SB,\n     // effectively doubling its value as well as its error estimation.\n     residualLo = (aSignificand << (significandBits + 1)) - quotient_UQ1 * bSignificand;\ndiff --git a/contrib/libs/cxxsupp/builtins/fp_lib.h b/contrib/libs/cxxsupp/builtins/fp_lib.h\nindex b2a89506135b..fae58497a8f8 100644\n--- a/contrib/libs/cxxsupp/builtins/fp_lib.h\n+++ b/contrib/libs/cxxsupp/builtins/fp_lib.h\n@@ -171,8 +171,11 @@ static __inline void wideMultiply(rep_t a, rep_t b, rep_t *hi, rep_t *lo) {\n                          (sum2 & Word_FullMask) + ((sum3 << 32) & Word_HiMask);\n \n   *lo = r0 + (r1 << 64);\n+  // The addition above can overflow, in which case `*lo` will be less than\n+  // `r0`. Carry any overflow into `hi`.\n+  const bool carry = *lo < r0;\n   *hi = (r1 >> 64) + (sum1 >> 96) + (sum2 >> 64) + (sum3 >> 32) + sum4 +\n-        (sum5 << 32) + (sum6 << 64);\n+        (sum5 << 32) + (sum6 << 64) + carry;\n }\n #undef Word_1\n #undef Word_2\n@@ -346,15 +349,6 @@ static __inline fp_t __compiler_rt_logbf(fp_t x) {\n static __inline fp_t __compiler_rt_scalbnf(fp_t x, int y) {\n   return __compiler_rt_scalbnX(x, y);\n }\n-static __inline fp_t __compiler_rt_fmaxf(fp_t x, fp_t y) {\n-#if defined(__aarch64__)\n-  // Use __builtin_fmaxf which turns into an fmaxnm instruction on AArch64.\n-  return __builtin_fmaxf(x, y);\n-#else\n-  // __builtin_fmaxf frequently turns into a libm call, so inline the function.\n-  return __compiler_rt_fmaxX(x, y);\n-#endif\n-}\n \n #elif defined(DOUBLE_PRECISION)\n \ndiff --git a/contrib/libs/cxxsupp/builtins/fp_trunc.h b/contrib/libs/cxxsupp/builtins/fp_trunc.h\nindex 141fe63e132d..a1bd881eb57c 100644\n--- a/contrib/libs/cxxsupp/builtins/fp_trunc.h\n+++ b/contrib/libs/cxxsupp/builtins/fp_trunc.h\n@@ -35,6 +35,18 @@ static const int srcSigFracBits = 52;\n // srcBits - srcSigFracBits - 1\n static const int srcExpBits = 11;\n \n+#elif defined SRC_80\n+typedef xf_float src_t;\n+typedef __uint128_t src_rep_t;\n+#define SRC_REP_C (__uint128_t)\n+// sign bit, exponent and significand occupy the lower 80 bits.\n+static const int srcBits = 80;\n+static const int srcSigFracBits = 63;\n+// -1 accounts for the sign bit.\n+// -1 accounts for the explicitly stored integer bit.\n+// srcBits - srcSigFracBits - 1 - 1\n+static const int srcExpBits = 15;\n+\n #elif defined SRC_QUAD\n typedef tf_float src_t;\n typedef __uint128_t src_rep_t;\ndiff --git a/contrib/libs/cxxsupp/builtins/os_version_check.c b/contrib/libs/cxxsupp/builtins/os_version_check.c\nindex 01fae834ab21..b10f23a81a9c 100644\n--- a/contrib/libs/cxxsupp/builtins/os_version_check.c\n+++ b/contrib/libs/cxxsupp/builtins/os_version_check.c\n@@ -14,6 +14,7 @@\n #ifdef __APPLE__\n \n #include <TargetConditionals.h>\n+#include <assert.h>\n #include <dispatch/dispatch.h>\n #include <dlfcn.h>\n #include <stdint.h>\n@@ -270,6 +271,8 @@ static inline uint32_t ConstructVersion(uint32_t Major, uint32_t Minor,\n   return ((Major & 0xffff) << 16) | ((Minor & 0xff) << 8) | (Subminor & 0xff);\n }\n \n+#define PLATFORM_MACOS 1\n+\n int32_t __isPlatformVersionAtLeast(uint32_t Platform, uint32_t Major,\n                                    uint32_t Minor, uint32_t Subminor) {\n   dispatch_once_f(&DispatchOnceCounter, NULL, initializeAvailabilityCheck);\n@@ -282,6 +285,29 @@ int32_t __isPlatformVersionAtLeast(uint32_t Platform, uint32_t Major,\n   return AvailabilityVersionCheck(1, Versions);\n }\n \n+#if TARGET_OS_OSX\n+\n+int32_t __isPlatformOrVariantPlatformVersionAtLeast(\n+    uint32_t Platform, uint32_t Major, uint32_t Minor, uint32_t Subminor,\n+    uint32_t Platform2, uint32_t Major2, uint32_t Minor2, uint32_t Subminor2) {\n+  dispatch_once_f(&DispatchOnceCounter, NULL, initializeAvailabilityCheck);\n+\n+  if (!AvailabilityVersionCheck) {\n+    // Handle case of back-deployment for older macOS.\n+    if (Platform == PLATFORM_MACOS) {\n+      return __isOSVersionAtLeast(Major, Minor, Subminor);\n+    }\n+    assert(Platform2 == PLATFORM_MACOS && \"unexpected platform\");\n+    return __isOSVersionAtLeast(Major2, Minor2, Subminor2);\n+  }\n+  dyld_build_version_t Versions[] = {\n+      {Platform, ConstructVersion(Major, Minor, Subminor)},\n+      {Platform2, ConstructVersion(Major2, Minor2, Subminor2)}};\n+  return AvailabilityVersionCheck(2, Versions);\n+}\n+\n+#endif\n+\n #elif __ANDROID__\n \n #include <pthread.h>\ndiff --git a/contrib/libs/cxxsupp/builtins/trunctfbf2.c b/contrib/libs/cxxsupp/builtins/trunctfbf2.c\nnew file mode 100644\nindex 000000000000..cd3c761aa62f\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/trunctfbf2.c\n@@ -0,0 +1,18 @@\n+//===--------- lib/trunctfbf2.c - quad -> bfloat conversion -------*- C -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+#define QUAD_PRECISION\n+#include \"fp_lib.h\"\n+\n+#if defined(CRT_HAS_TF_MODE) && defined(__x86_64__)\n+#define SRC_QUAD\n+#define DST_BFLOAT\n+#include \"fp_trunc_impl.inc\"\n+\n+COMPILER_RT_ABI dst_t __trunctfbf2(src_t a) { return __truncXfYf2__(a); }\n+\n+#endif\ndiff --git a/contrib/libs/cxxsupp/builtins/truncxfbf2.c b/contrib/libs/cxxsupp/builtins/truncxfbf2.c\nnew file mode 100644\nindex 000000000000..5a389abdf0d5\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/truncxfbf2.c\n@@ -0,0 +1,19 @@\n+//===-- lib/truncxfbf2.c - long double -> bfloat conversion -------*- C -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#if defined(CRT_HAS_TF_MODE) && __LDBL_MANT_DIG__ == 64 && defined(__x86_64__)\n+#define SRC_80\n+#define DST_BFLOAT\n+#include \"fp_trunc_impl.inc\"\n+\n+COMPILER_RT_ABI dst_t __truncxfbf2(long double a) { return __truncXfYf2__(a); }\n+\n+#endif\n+\n+// Have at least one declaration to suppress warnings.\n+enum Unused { ReallyUnused };\ndiff --git a/contrib/libs/cxxsupp/builtins/truncxfhf2.c b/contrib/libs/cxxsupp/builtins/truncxfhf2.c\nnew file mode 100644\nindex 000000000000..0f0639865dbf\n--- /dev/null\n+++ b/contrib/libs/cxxsupp/builtins/truncxfhf2.c\n@@ -0,0 +1,15 @@\n+//===-- lib/truncsfhf2.c - long double -> half conversion ---------*- C -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#define SRC_SINGLE\n+#define DST_HALF\n+#include \"fp_trunc_impl.inc\"\n+\n+COMPILER_RT_ABI dst_t __truncxfhf2(xf_float a) {\n+  return __truncXfYf2__((float)a);\n+}\ndiff --git a/contrib/libs/cxxsupp/builtins/ya.make b/contrib/libs/cxxsupp/builtins/ya.make\nindex f6bee5e713a2..dce2f27201ad 100644\n--- a/contrib/libs/cxxsupp/builtins/ya.make\n+++ b/contrib/libs/cxxsupp/builtins/ya.make\n@@ -12,9 +12,9 @@ LICENSE(\n \n LICENSE_TEXTS(.yandex_meta/licenses.list.txt)\n \n-VERSION(19.1.7)\n+VERSION(20.1.0)\n \n-ORIGINAL_SOURCE(https://github.com/llvm/llvm-project/releases/download/llvmorg-19.1.7/compiler-rt-19.1.7.src.tar.xz)\n+ORIGINAL_SOURCE(https://github.com/llvm/llvm-project/releases/download/llvmorg-20.1.0/compiler-rt-20.1.0.src.tar.xz)\n \n NO_COMPILER_WARNINGS()\n \n@@ -79,9 +79,9 @@ IF (ARCH_ARM64 OR ARCH_X86_64)\n             # NB: sources that were commented out were added in llvm-20\n             extendbfsf2.c\n             truncdfbf2.c\n-            # truncxfbf2.c\n+            truncxfbf2.c\n             truncsfbf2.c\n-            # trunctfbf2.c\n+            trunctfbf2.c\n         )\n     ENDIF()\n ENDIF()\n@@ -323,8 +323,7 @@ ELSEIF (ARCH_AARCH64)\n     SRCS(\n         aarch64/chkstk.S\n         aarch64/fp_mode.c\n-        aarch64/sme-abi-init.c\n-        aarch64/sme-abi-vg.c\n+        aarch64/sme-abi-assert.c\n         aarch64/sme-abi.S\n         aarch64/sme-libc-mem-routines.S\n         absvdi2.c\n@@ -645,6 +644,7 @@ ELSEIF (ARCH_X86_64)\n         SRCS(\n             x86_64/floatdixf.c\n             divxc3.c\n+            extendhfxf2.c\n             extendxftf2.c\n             fixunsxfdi.c\n             fixunsxfsi.c\n@@ -656,6 +656,7 @@ ELSEIF (ARCH_X86_64)\n             mulxc3.c\n             powixf2.c\n             trunctfxf2.c\n+            truncxfhf2.c\n         )\n     ENDIF()\n ELSE()\ndiff --git a/ydb/ci/rightlib.txt b/ydb/ci/rightlib.txt\nindex 23981d2eb738..de62b3ba5ab7 100644\n--- a/ydb/ci/rightlib.txt\n+++ b/ydb/ci/rightlib.txt\n@@ -1,1 +1,1 @@\n-2ff6c17bf66cd3580cf4f4746870518f071864d6\n+0ce7de46ae24b3b80ffd51c6f100d22ef8aba7d6\ndiff --git a/yt/yt/client/kafka/protocol.cpp b/yt/yt/client/kafka/protocol.cpp\nindex 47ab8b170f08..edac56e7a98f 100644\n--- a/yt/yt/client/kafka/protocol.cpp\n+++ b/yt/yt/client/kafka/protocol.cpp\n@@ -2,6 +2,8 @@\n \n #include <yt/yt/core/misc/error.h>\n \n+#include <library/cpp/digest/crc32c/crc32c.h>\n+\n #include <library/cpp/yt/coding/varint.h>\n \n #include <library/cpp/yt/string/guid.h>\n@@ -10,6 +12,10 @@ namespace NYT::NKafka {\n \n ////////////////////////////////////////////////////////////////////////////////\n \n+static constexpr auto& Logger = KafkaLogger;\n+\n+////////////////////////////////////////////////////////////////////////////////\n+\n class TKafkaProtocolReader\n     : public IKafkaProtocolReader\n {\n@@ -20,37 +26,44 @@ class TKafkaProtocolReader\n \n     bool ReadBool() override\n     {\n+        YT_LOG_TRACE(\"Reading bool\");\n         auto value = ReadByte();\n         return value > 0;\n     }\n \n     char ReadByte() override\n     {\n+        YT_LOG_TRACE(\"Reading byte\");\n         return DoReadInt<char>();\n     }\n \n     i16 ReadInt16() override\n     {\n+        YT_LOG_TRACE(\"Reading int16\");\n         return DoReadInt<i16>();\n     }\n \n     i32 ReadInt32() override\n     {\n+        YT_LOG_TRACE(\"Reading int32\");\n         return DoReadInt<i32>();\n     }\n \n     i64 ReadInt64() override\n     {\n+        YT_LOG_TRACE(\"Reading int64\");\n         return DoReadInt<i64>();\n     }\n \n     ui32 ReadUint32() override\n     {\n+        YT_LOG_TRACE(\"Reading uint32\");\n         return DoReadInt<ui32>();\n     }\n \n     i32 ReadVarInt() override\n     {\n+        YT_LOG_TRACE(\"Reading varint\");\n         i32 result;\n         Offset_ += ReadVarInt32(Data_.begin() + Offset_, &result);\n         return result;\n@@ -58,6 +71,7 @@ class TKafkaProtocolReader\n \n     i64 ReadVarLong() override\n     {\n+        YT_LOG_TRACE(\"Reading varlong\");\n         i64 result;\n         Offset_ += ReadVarInt64(Data_.begin() + Offset_, &result);\n         return result;\n@@ -65,6 +79,7 @@ class TKafkaProtocolReader\n \n     ui32 ReadUnsignedVarInt() override\n     {\n+        YT_LOG_TRACE(\"Reading unsigned varint\");\n         ui32 result;\n         Offset_ += ReadVarUint32(Data_.begin() + Offset_, &result);\n         return result;\n@@ -72,6 +87,7 @@ class TKafkaProtocolReader\n \n     std::optional<TString> ReadNullableString() override\n     {\n+        YT_LOG_TRACE(\"Reading nullable string\");\n         auto length = ReadInt16();\n         if (length == -1) {\n             return {};\n@@ -84,6 +100,7 @@ class TKafkaProtocolReader\n \n     std::optional<TString> ReadCompactNullableString() override\n     {\n+        YT_LOG_TRACE(\"Reading compact nullable string\");\n         auto length = ReadUnsignedVarInt();\n         if (length == 0) {\n             return {};\n@@ -97,6 +114,7 @@ class TKafkaProtocolReader\n \n     TString ReadCompactString() override\n     {\n+        YT_LOG_TRACE(\"Reading compact string\");\n         TString result;\n \n         auto length = ReadUnsignedVarInt();\n@@ -111,6 +129,7 @@ class TKafkaProtocolReader\n \n     TString ReadString() override\n     {\n+        YT_LOG_TRACE(\"Reading string\");\n         TString result;\n \n         auto length = ReadInt16();\n@@ -125,6 +144,7 @@ class TKafkaProtocolReader\n \n     TString ReadBytes() override\n     {\n+        YT_LOG_TRACE(\"Reading bytes\");\n         TString result;\n \n         auto length = ReadInt32();\n@@ -139,6 +159,7 @@ class TKafkaProtocolReader\n \n     TGuid ReadUuid() override\n     {\n+        YT_LOG_TRACE(\"Reading uuid\");\n         TString value;\n         ReadString(&value, 16);\n         return TGuid::FromString(value);\n@@ -146,6 +167,10 @@ class TKafkaProtocolReader\n \n     void ReadString(TString* result, int length) override\n     {\n+        YT_LOG_TRACE(\"Reading string with length (Length: %v, DataSize: %v, Offset: %v)\",\n+            length,\n+            Data_.size(),\n+            Offset_);\n         ValidateSizeAvailable(length);\n \n         result->resize(length);\n@@ -156,6 +181,7 @@ class TKafkaProtocolReader\n \n     TString ReadCompactBytes() override\n     {\n+        YT_LOG_TRACE(\"Reading compact bytes\");\n         TString result;\n \n         auto length = ReadUnsignedVarInt();\n@@ -169,6 +195,7 @@ class TKafkaProtocolReader\n \n     i32 StartReadBytes(bool needReadCount) override\n     {\n+        YT_LOG_TRACE(\"Start reading bytes\");\n         i32 size = 0;\n         if (needReadCount) {\n             size = ReadInt32();\n@@ -179,6 +206,7 @@ class TKafkaProtocolReader\n \n     i32 StartReadCompactBytes(bool needReadCount) override\n     {\n+        YT_LOG_TRACE(\"Start reading compact bytes\");\n         i32 size = 0;\n         if (needReadCount) {\n             size = ReadUnsignedVarInt() - 1;\n@@ -197,6 +225,7 @@ class TKafkaProtocolReader\n \n     void FinishReadBytes() override\n     {\n+        YT_LOG_TRACE(\"Finish reading bytes\");\n         if (!BytesOffsets_.empty()) {\n             return BytesOffsets_.pop_back();\n         }\n@@ -247,7 +276,9 @@ class TKafkaProtocolReader\n     void ValidateSizeAvailable(i64 size)\n     {\n         if (std::ssize(Data_) - Offset_ < size) {\n-            THROW_ERROR_EXCEPTION(\"Premature end of stream while reading %v bytes\", size);\n+            THROW_ERROR_EXCEPTION(\"Premature end of stream while reading %v bytes\", size)\n+                << TErrorAttribute(\"data_size\", std::ssize(Data_))\n+                << TErrorAttribute(\"offset\", Offset_);\n         }\n     }\n };\n@@ -392,10 +423,28 @@ class TKafkaProtocolWriter\n     void FinishBytes() override\n     {\n         YT_VERIFY(!BytesOffsets_.empty());\n-        DoWriteInt<int32_t>(Size_ - BytesOffsets_.back(), BytesOffsets_.back() - sizeof(int32_t));\n+        DoWriteInt<i32>(Size_ - BytesOffsets_.back(), BytesOffsets_.back() - sizeof(i32));\n         BytesOffsets_.pop_back();\n     }\n \n+    void StartCalculateChecksum() override\n+    {\n+        WriteInt32(0);\n+        ChecksumOffsets_.push_back(Size_);\n+    }\n+\n+    void FinishCalculateChecksum() override\n+    {\n+        YT_VERIFY(!ChecksumOffsets_.empty());\n+        auto offset = ChecksumOffsets_.back();\n+        ChecksumOffsets_.pop_back();\n+\n+        auto data = Buffer_.Slice(offset, Size_);\n+        auto checksum = Crc32c(data.begin(), data.size());\n+\n+        DoWriteInt<ui32>(checksum, offset - sizeof(ui32));\n+    }\n+\n     TSharedRef Finish() override\n     {\n         return Buffer_.Slice(0, Size_);\n@@ -417,6 +466,7 @@ class TKafkaProtocolWriter\n     i64 Size_ = 0;\n \n     std::vector<i64> BytesOffsets_;\n+    std::vector<i64> ChecksumOffsets_;\n \n     template <typename T>\n     void DoWriteInt(T value, std::optional<i64> position = std::nullopt)\ndiff --git a/yt/yt/client/kafka/protocol.h b/yt/yt/client/kafka/protocol.h\nindex 135464b55420..deaffbc6067b 100644\n--- a/yt/yt/client/kafka/protocol.h\n+++ b/yt/yt/client/kafka/protocol.h\n@@ -10,6 +10,17 @@ namespace NYT::NKafka {\n \n ////////////////////////////////////////////////////////////////////////////////\n \n+#define READ_KAFKA_FIELD(field, method)                                                    \\\n+    YT_LOG_TRACE(\"Parsing kafka data (Field: %v)\", #field);                                \\\n+    field = reader->method();                                                              \\\n+    YT_LOG_TRACE(\"Parsing kafka data, value read (Field: %v, Value: %v)\", #field, field);\n+\n+#define WRITE_KAFKA_FIELD(kafkaWriter, method, field)                                             \\\n+    YT_LOG_TRACE(\"Writing kafka data (Field: %v, Value: %v)\", #field, field);                     \\\n+    kafkaWriter->method(field);\n+\n+////////////////////////////////////////////////////////////////////////////////\n+\n struct IKafkaProtocolReader\n {\n     virtual ~IKafkaProtocolReader() = default;\n@@ -86,6 +97,9 @@ struct IKafkaProtocolWriter\n     virtual void StartBytes() = 0;\n     virtual void FinishBytes() = 0;\n \n+    virtual void StartCalculateChecksum() = 0;\n+    virtual void FinishCalculateChecksum() = 0;\n+\n     virtual i64 GetSize() const = 0;\n \n     virtual TSharedRef Finish() = 0;\ndiff --git a/yt/yt/client/kafka/public.h b/yt/yt/client/kafka/public.h\nindex fbdce4d12461..fddafe428bad 100644\n--- a/yt/yt/client/kafka/public.h\n+++ b/yt/yt/client/kafka/public.h\n@@ -1,7 +1,15 @@\n #pragma once\n \n+#include <yt/yt/core/logging/log_manager.h>\n+\n #include <yt/yt/core/misc/public.h>\n \n namespace NYT::NKafka {\n \n+////////////////////////////////////////////////////////////////////////////////\n+\n+YT_DEFINE_GLOBAL(const NLogging::TLogger, KafkaLogger, \"Kafka\");\n+\n+////////////////////////////////////////////////////////////////////////////////\n+\n } // namespace NYT::NKafka\ndiff --git a/yt/yt/client/kafka/requests.cpp b/yt/yt/client/kafka/requests.cpp\nindex d94a0f6a82b5..179d17670edc 100644\n--- a/yt/yt/client/kafka/requests.cpp\n+++ b/yt/yt/client/kafka/requests.cpp\n@@ -6,6 +6,10 @@ namespace NYT::NKafka {\n \n ////////////////////////////////////////////////////////////////////////////////\n \n+static constexpr auto& Logger = KafkaLogger;\n+\n+////////////////////////////////////////////////////////////////////////////////\n+\n int GetRequestHeaderVersion(ERequestType requestType, i16 apiVersion)\n {\n     switch (requestType) {\n@@ -100,24 +104,24 @@ void TRecord::Serialize(IKafkaProtocolWriter* writer, int version) const\n     if (version == 2) {\n         auto recordWriter = CreateKafkaProtocolWriter();\n \n-        recordWriter->WriteByte(Attributes);\n-        recordWriter->WriteVarLong(TimestampDelta);\n-        recordWriter->WriteVarInt(OffsetDelta);\n+        WRITE_KAFKA_FIELD(recordWriter, WriteByte, Attributes)\n+        WRITE_KAFKA_FIELD(recordWriter, WriteVarLong, TimestampDelta)\n+        WRITE_KAFKA_FIELD(recordWriter, WriteVarInt, OffsetDelta)\n \n-        recordWriter->WriteVarInt(Key.size());\n-        recordWriter->WriteData(Key);\n+        WRITE_KAFKA_FIELD(recordWriter, WriteVarInt, Key.size())\n+        WRITE_KAFKA_FIELD(recordWriter, WriteData, Key)\n \n-        recordWriter->WriteVarInt(Value.size());\n-        recordWriter->WriteData(Value);\n+        WRITE_KAFKA_FIELD(recordWriter, WriteVarInt, Value.size())\n+        WRITE_KAFKA_FIELD(recordWriter, WriteData, Value)\n \n-        recordWriter->WriteVarInt(Headers.size());\n+        WRITE_KAFKA_FIELD(recordWriter, WriteVarInt, Headers.size())\n         for (const auto& header : Headers) {\n             header.Serialize(recordWriter.get(), version);\n         }\n \n         auto record = recordWriter->Finish();\n \n-        writer->WriteVarInt(record.Size());\n+        WRITE_KAFKA_FIELD(writer, WriteVarInt, record.size())\n         writer->WriteData(record);\n     } else if (version == 1 || version == 0) {\n         writer->WriteByte(Attributes);\n@@ -135,29 +139,46 @@ void TRecord::Serialize(IKafkaProtocolWriter* writer, int version) const\n \n void TRecord::Deserialize(IKafkaProtocolReader* reader, int version)\n {\n+    std::optional<i32> length;\n     if (version == 2) {\n-        reader->ReadVarInt();  // Length, not used.\n+        READ_KAFKA_FIELD(length, ReadVarInt);\n+        reader->StartReadBytes(/*needReadSize*/ false);\n     }\n-    Attributes = reader->ReadByte();\n+    READ_KAFKA_FIELD(Attributes, ReadByte)\n \n     if (version == 2) {\n-        TimestampDelta = reader->ReadVarLong();\n-        OffsetDelta = reader->ReadVarInt();\n+        READ_KAFKA_FIELD(TimestampDelta, ReadVarLong)\n+        READ_KAFKA_FIELD(OffsetDelta, ReadVarInt)\n \n         auto keySize = reader->ReadVarInt();\n+        YT_LOG_TRACE(\"Parsing Record (KeySize: %v)\", keySize);\n         reader->ReadString(&Key, keySize);\n \n-        auto valueSize = reader->ReadVarInt();\n-        reader->ReadString(&Value, valueSize);\n+        i32 valueSize;\n+        READ_KAFKA_FIELD(valueSize, ReadVarInt);\n+\n+        if (valueSize > 0) {\n+            YT_LOG_TRACE(\"Parsing Record (ValueSize: %v)\", valueSize);\n+            reader->ReadString(&Value, valueSize);\n+        }\n \n-        auto headerCount = reader->ReadVarInt();\n-        Headers.resize(headerCount);\n-        for (auto& header : Headers) {\n-            header.Deserialize(reader, version);\n+        i32 headerCount;\n+        READ_KAFKA_FIELD(headerCount, ReadVarInt);\n+        if (headerCount > 0) {\n+            Headers.resize(headerCount);\n+            for (auto& header : Headers) {\n+                header.Deserialize(reader, version);\n+            }\n+        }\n+\n+        reader->FinishReadBytes();\n+\n+        if (length && reader->GetReadBytesCount() != length) {\n+            YT_LOG_ERROR(\"Not all record bytes were read (Expected: %v, Actual: %v)\", *length, reader->GetReadBytesCount());\n         }\n     } else if (version == 1 || version == 0) {\n         if (version == 1) {\n-            TimestampDelta = reader->ReadInt64();\n+            READ_KAFKA_FIELD(TimestampDelta, ReadInt64)\n         }\n         Key = reader->ReadBytes();\n         Value = reader->ReadBytes();\n@@ -168,32 +189,34 @@ void TRecord::Deserialize(IKafkaProtocolReader* reader, int version)\n \n void TRecordBatch::Serialize(IKafkaProtocolWriter* writer) const\n {\n-    writer->WriteInt64(BaseOffset);\n+    WRITE_KAFKA_FIELD(writer, WriteInt64, BaseOffset)\n \n     writer->StartBytes();  // Write Length.\n \n     if (MagicByte == 0 || MagicByte == 1) {\n-        writer->WriteInt32(CrcOld);\n-        writer->WriteByte(MagicByte);\n+        // TODO(nadya73): implement it via [Start/Finish]CalculateChecksum and crc32.\n+        WRITE_KAFKA_FIELD(writer, WriteUint32, CrcOld)\n+        WRITE_KAFKA_FIELD(writer, WriteByte, MagicByte)\n \n         YT_VERIFY(Records.size() == 1);\n         Records[0].Serialize(writer, MagicByte);\n     } else if (MagicByte == 2) {\n-        writer->WriteInt32(PartitionLeaderEpoch);\n-        writer->WriteByte(MagicByte);\n-        writer->WriteUint32(Crc);\n-        writer->WriteInt16(Attributes);\n-        writer->WriteInt32(LastOffsetDelta);\n-        writer->WriteInt64(FirstTimestamp);\n-        writer->WriteInt64(MaxTimestamp);\n-        writer->WriteInt64(ProducerId);\n-        writer->WriteInt16(ProducerEpoch);\n-        writer->WriteInt32(BaseSequence);\n-\n-        writer->WriteInt32(Records.size());\n+        WRITE_KAFKA_FIELD(writer, WriteInt32, PartitionLeaderEpoch)\n+        WRITE_KAFKA_FIELD(writer, WriteByte, MagicByte)\n+        writer->StartCalculateChecksum();\n+        WRITE_KAFKA_FIELD(writer, WriteInt16, Attributes)\n+        WRITE_KAFKA_FIELD(writer, WriteInt32, LastOffsetDelta)\n+        WRITE_KAFKA_FIELD(writer, WriteInt64, FirstTimestamp)\n+        WRITE_KAFKA_FIELD(writer, WriteInt64, MaxTimestamp)\n+        WRITE_KAFKA_FIELD(writer, WriteInt64, ProducerId)\n+        WRITE_KAFKA_FIELD(writer, WriteInt16, ProducerEpoch)\n+        WRITE_KAFKA_FIELD(writer, WriteInt32, BaseSequence)\n+\n+        WRITE_KAFKA_FIELD(writer, WriteInt32, Records.size())\n         for (const auto& record : Records) {\n             record.Serialize(writer, MagicByte);\n         }\n+        writer->FinishCalculateChecksum();\n     } else {\n         THROW_ERROR_EXCEPTION(\"Unsupported MagicByte %v in RecordBatch serialization\", static_cast<int>(MagicByte));\n     }\n@@ -202,14 +225,13 @@ void TRecordBatch::Serialize(IKafkaProtocolWriter* writer) const\n \n void TRecordBatch::Deserialize(IKafkaProtocolReader* reader)\n {\n-    BaseOffset = reader->ReadInt64();\n-    Length = reader->ReadInt32();\n+    READ_KAFKA_FIELD(BaseOffset, ReadInt64)\n+    READ_KAFKA_FIELD(Length, ReadInt32)\n \n     reader->StartReadBytes(/*needReadSize*/ false);\n \n-    PartitionLeaderEpoch = reader->ReadInt32();\n-\n-    MagicByte = reader->ReadByte();\n+    READ_KAFKA_FIELD(PartitionLeaderEpoch, ReadInt32)\n+    READ_KAFKA_FIELD(MagicByte, ReadByte)\n \n     if (MagicByte == 0 || MagicByte == 1) {\n         // In v0/v1 CRC is before MagicByte and there is no PartitionLeaderEpoch;\n@@ -218,22 +240,30 @@ void TRecordBatch::Deserialize(IKafkaProtocolReader* reader)\n \n         // It's a message in v0/v1.\n         auto& record = Records.emplace_back();\n+        YT_LOG_TRACE(\"Parsing RecordBatch, reading Record\");\n         record.Deserialize(reader, MagicByte);\n     } else if (MagicByte == 2) {\n-        Crc = reader->ReadUint32();\n-\n-        Attributes = reader->ReadInt16();\n-        LastOffsetDelta = reader->ReadInt32();\n-        FirstTimestamp = reader->ReadInt64();\n-        MaxTimestamp = reader->ReadInt64();\n-        ProducerId = reader->ReadInt64();\n-        ProducerEpoch = reader->ReadInt16();\n-        BaseSequence = reader->ReadInt32();\n-\n-        while (reader->GetReadBytesCount() < Length) {\n-            TRecord record;\n-            record.Deserialize(reader, MagicByte);\n-            Records.push_back(std::move(record));\n+        READ_KAFKA_FIELD(Crc, ReadUint32)\n+        READ_KAFKA_FIELD(Attributes, ReadInt16)\n+        READ_KAFKA_FIELD(LastOffsetDelta, ReadInt32)\n+        READ_KAFKA_FIELD(FirstTimestamp, ReadInt64)\n+        READ_KAFKA_FIELD(MaxTimestamp, ReadInt64)\n+        READ_KAFKA_FIELD(ProducerId, ReadInt64)\n+        READ_KAFKA_FIELD(ProducerEpoch, ReadInt16)\n+        READ_KAFKA_FIELD(BaseSequence, ReadInt32)\n+\n+        i32 recordCount = 0;\n+        READ_KAFKA_FIELD(recordCount, ReadInt32)\n+        if (recordCount > 0) {\n+            Records.reserve(recordCount);\n+            for (i32 recordIndex = 0; recordIndex < recordCount; ++recordIndex) {\n+                TRecord record;\n+                record.Deserialize(reader, MagicByte);\n+                Records.push_back(std::move(record));\n+            }\n+        }\n+        if (reader->GetReadBytesCount() != Length) {\n+            THROW_ERROR_EXCEPTION(\"Unexpected record batch length (Expected: %v, Actual: %v)\", Length, reader->GetReadBytesCount());\n         }\n     } else {\n         THROW_ERROR_EXCEPTION(\"Unsupported MagicByte %v in RecordBatch deserialization\", static_cast<int>(MagicByte));\n@@ -481,6 +511,19 @@ void TRspHeartbeat::Serialize(IKafkaProtocolWriter* writer, int /*apiVersion*/)\n \n ////////////////////////////////////////////////////////////////////////////////\n \n+void TReqLeaveGroup::Deserialize(IKafkaProtocolReader* reader, int /*apiVersion*/)\n+{\n+    GroupId = reader->ReadString();\n+    MemberId = reader->ReadString();\n+}\n+\n+void TRspLeaveGroup::Serialize(IKafkaProtocolWriter* writer, int /*apiVersion*/) const\n+{\n+    writer->WriteErrorCode(ErrorCode);\n+}\n+\n+////////////////////////////////////////////////////////////////////////////////\n+\n void TReqOffsetCommitTopicPartition::Deserialize(IKafkaProtocolReader* reader, int /*apiVersion*/)\n {\n     PartitionIndex = reader->ReadInt32();\n@@ -598,12 +641,13 @@ void TReqFetch::Deserialize(IKafkaProtocolReader* reader, int apiVersion)\n \n void TRspFetchResponsePartition::Serialize(IKafkaProtocolWriter* writer, int /*apiVersion*/) const\n {\n-    writer->WriteInt32(PartitionIndex);\n-    writer->WriteErrorCode(ErrorCode);\n-    writer->WriteInt64(HighWatermark);\n+    WRITE_KAFKA_FIELD(writer, WriteInt32, PartitionIndex)\n+    WRITE_KAFKA_FIELD(writer, WriteErrorCode, ErrorCode)\n+    WRITE_KAFKA_FIELD(writer, WriteInt64, HighWatermark)\n \n     if (!RecordBatches) {\n-        writer->WriteInt32(-1);\n+        i32 recordBatchesSize = -1;\n+        WRITE_KAFKA_FIELD(writer, WriteInt32, recordBatchesSize)\n     } else {\n         writer->StartBytes();\n         for (const auto& recordBatch : *RecordBatches) {\n@@ -615,9 +659,9 @@ void TRspFetchResponsePartition::Serialize(IKafkaProtocolWriter* writer, int /*a\n \n void TRspFetchResponse::Serialize(IKafkaProtocolWriter* writer, int apiVersion) const\n {\n-    writer->WriteString(Topic);\n+    WRITE_KAFKA_FIELD(writer, WriteString, Topic)\n \n-    writer->WriteInt32(Partitions.size());\n+    WRITE_KAFKA_FIELD(writer, WriteInt32, Partitions.size())\n     for (const auto& partition : Partitions) {\n         partition.Serialize(writer, apiVersion);\n     }\n@@ -626,9 +670,9 @@ void TRspFetchResponse::Serialize(IKafkaProtocolWriter* writer, int apiVersion)\n void TRspFetch::Serialize(IKafkaProtocolWriter* writer, int apiVersion) const\n {\n     if (apiVersion >= 2) {\n-        writer->WriteInt32(ThrottleTimeMs);\n+        WRITE_KAFKA_FIELD(writer, WriteInt32, ThrottleTimeMs)\n     }\n-    writer->WriteInt32(Responses.size());\n+    WRITE_KAFKA_FIELD(writer, WriteInt32, Responses.size())\n \n     for (const auto& response : Responses) {\n         response.Serialize(writer, apiVersion);\n@@ -671,7 +715,7 @@ void TRspSaslAuthenticate::Serialize(IKafkaProtocolWriter* writer, int /*apiVers\n \n void TReqProduceTopicDataPartitionData::Deserialize(IKafkaProtocolReader* reader, int apiVersion)\n {\n-    Index = reader->ReadInt32();\n+    READ_KAFKA_FIELD(Index, ReadInt32)\n \n     i32 bytesCount;\n     if (apiVersion < 9) {\n@@ -695,9 +739,9 @@ void TReqProduceTopicDataPartitionData::Deserialize(IKafkaProtocolReader* reader\n void TReqProduceTopicData::Deserialize(IKafkaProtocolReader* reader, int apiVersion)\n {\n     if (apiVersion < 9) {\n-        Name = reader->ReadString();\n+        READ_KAFKA_FIELD(Name, ReadString)\n     } else {\n-        Name = reader->ReadCompactString();\n+        READ_KAFKA_FIELD(Name, ReadCompactString)\n     }\n \n     NKafka::Deserialize(PartitionData, reader, /*isCompact*/ apiVersion >= 9, apiVersion);\n@@ -711,13 +755,13 @@ void TReqProduce::Deserialize(IKafkaProtocolReader* reader, int apiVersion)\n {\n     if (apiVersion >= 3) {\n         if (apiVersion < 9) {\n-            TransactionalId = reader->ReadNullableString();\n+            READ_KAFKA_FIELD(TransactionalId, ReadNullableString)\n         } else {\n-            TransactionalId = reader->ReadCompactNullableString();\n+            READ_KAFKA_FIELD(TransactionalId, ReadCompactNullableString)\n         }\n     }\n-    Acks = reader->ReadInt16();\n-    TimeoutMs = reader->ReadInt32();\n+    READ_KAFKA_FIELD(Acks, ReadInt16)\n+    READ_KAFKA_FIELD(TimeoutMs, ReadInt32)\n \n     NKafka::Deserialize(TopicData, reader, /*isCompact*/ apiVersion >= 9, apiVersion);\n \n@@ -815,10 +859,14 @@ void TReqListOffsets::Deserialize(IKafkaProtocolReader* reader, int apiVersion)\n     }\n }\n \n-void TRspListOffsetsTopicPartition::Serialize(IKafkaProtocolWriter* writer, int /*apiVersion*/) const\n+void TRspListOffsetsTopicPartition::Serialize(IKafkaProtocolWriter* writer, int apiVersion) const\n {\n     writer->WriteInt32(PartitionIndex);\n     writer->WriteErrorCode(ErrorCode);\n+\n+    if (apiVersion <= 0) {\n+        writer->WriteInt32(1); // Size of 'old_style_offsets'.\n+    }\n     writer->WriteInt64(Offset);\n }\n \ndiff --git a/yt/yt/client/kafka/requests.h b/yt/yt/client/kafka/requests.h\nindex bdd2a7ba992b..87943acb253f 100644\n--- a/yt/yt/client/kafka/requests.h\n+++ b/yt/yt/client/kafka/requests.h\n@@ -128,11 +128,11 @@ struct TRecordBatch\n \n     i32 LastOffsetDelta = 0;\n     // BaseTimestamp in v2 and ... TODO in v1.\n-    i64 FirstTimestamp = 0;\n-    i64 MaxTimestamp = 0;\n+    i64 FirstTimestamp = -1;\n+    i64 MaxTimestamp = -1;\n \n-    i64 ProducerId = 0;\n-    i16 ProducerEpoch = 0;\n+    i64 ProducerId = -1;\n+    i16 ProducerEpoch = -1;\n     // Same as BaseSequence in v2 and TODO.\n     i32 BaseSequence = 0;\n \n@@ -374,6 +374,25 @@ struct TRspHeartbeat\n \n ////////////////////////////////////////////////////////////////////////////////\n \n+struct TReqLeaveGroup\n+{\n+    static constexpr ERequestType RequestType = ERequestType::LeaveGroup;\n+\n+    TGroupId GroupId;\n+    TMemberId MemberId;\n+\n+    void Deserialize(IKafkaProtocolReader* reader, int apiVersion);\n+};\n+\n+struct TRspLeaveGroup\n+{\n+    NKafka::EErrorCode ErrorCode = NKafka::EErrorCode::None;\n+\n+    void Serialize(IKafkaProtocolWriter* writer, int apiVersion) const;\n+};\n+\n+////////////////////////////////////////////////////////////////////////////////\n+\n struct TReqOffsetCommitTopicPartition\n {\n     i32 PartitionIndex = 0;\ndiff --git a/yt/yt/client/ya.make b/yt/yt/client/ya.make\nindex a1ca7c303d6c..c660a2bd979c 100644\n--- a/yt/yt/client/ya.make\n+++ b/yt/yt/client/ya.make\n@@ -221,6 +221,7 @@ PEERDIR(\n     yt/yt/library/numeric\n     yt/yt/library/quantile_digest\n     yt/yt_proto/yt/client\n+    library/cpp/digest/crc32c\n     library/cpp/json\n     library/cpp/string_utils/base64\n     contrib/libs/pfr\ndiff --git a/yt/yt/core/actions/future-inl.h b/yt/yt/core/actions/future-inl.h\nindex 090ac8a72749..30254e77d0d3 100644\n--- a/yt/yt/core/actions/future-inl.h\n+++ b/yt/yt/core/actions/future-inl.h\n@@ -1421,7 +1421,7 @@ bool TPromiseBase<T>::TrySet(NYT::TErrorOr<T>&& value) const\n \n template <class T>\n template <class U>\n-inline void TPromiseBase<T>::TrySetFrom(TFuture<U> another) const\n+inline void TPromiseBase<T>::TrySetFrom(const TFuture<U>& another) const\n {\n     YT_ASSERT(Impl_);\n \ndiff --git a/yt/yt/core/actions/future.h b/yt/yt/core/actions/future.h\nindex 768cf930ec2b..944174b40d15 100644\n--- a/yt/yt/core/actions/future.h\n+++ b/yt/yt/core/actions/future.h\n@@ -456,7 +456,7 @@ class TPromiseBase\n \n     //! Similar to #SetFrom but calls #TrySet instead of #Set.\n     template <class U>\n-    void TrySetFrom(TFuture<U> another) const;\n+    void TrySetFrom(const TFuture<U>& another) const;\n \n     //! Gets the value.\n     /*!\ndiff --git a/yt/yt/core/concurrency/config.cpp b/yt/yt/core/concurrency/config.cpp\nindex 9a1c63bf185e..fffc2d0d693e 100644\n--- a/yt/yt/core/concurrency/config.cpp\n+++ b/yt/yt/core/concurrency/config.cpp\n@@ -1,5 +1,7 @@\n #include \"config.h\"\n \n+#include <yt/yt/core/misc/jitter.h>\n+\n namespace NYT::NConcurrency {\n \n using namespace NYTree;\n@@ -14,6 +16,20 @@ TPeriodicExecutorOptions TPeriodicExecutorOptions::WithJitter(TDuration period)\n     };\n }\n \n+TDuration TPeriodicExecutorOptions::GenerateDelay() const\n+{\n+    if (!Period) {\n+        return TDuration::Max();\n+    }\n+\n+    auto randomGenerator = [] {\n+        return 2.0 * RandomNumber<double>() - 1.0;\n+    };\n+\n+    // Jitter is divided by 2 for historical reasons.\n+    return ApplyJitter(*Period, Jitter / 2.0, randomGenerator);\n+}\n+\n ////////////////////////////////////////////////////////////////////////////////\n \n namespace NDetail {\ndiff --git a/yt/yt/core/concurrency/config.h b/yt/yt/core/concurrency/config.h\nindex 6a93edc642df..20639a7be2ef 100644\n--- a/yt/yt/core/concurrency/config.h\n+++ b/yt/yt/core/concurrency/config.h\n@@ -22,8 +22,11 @@ struct TPeriodicExecutorOptions\n \n     bool operator==(const TPeriodicExecutorOptions& other) const = default;\n \n-    //! Sets #Period and Applies set#DefaultJitter.\n+    //! Sets #Period and applies #DefaultJitter.\n     static TPeriodicExecutorOptions WithJitter(TDuration period);\n+\n+    //! Generates the delay for the next invocation from #Period and #Jitter.\n+    TDuration GenerateDelay() const;\n };\n \n ////////////////////////////////////////////////////////////////////////////////\ndiff --git a/yt/yt/core/concurrency/periodic_executor.cpp b/yt/yt/core/concurrency/periodic_executor.cpp\nindex 74470806863a..d4e88932cd5e 100644\n--- a/yt/yt/core/concurrency/periodic_executor.cpp\n+++ b/yt/yt/core/concurrency/periodic_executor.cpp\n@@ -25,7 +25,7 @@ TDefaultInvocationTimePolicy::TDefaultInvocationTimePolicy(\n void TDefaultInvocationTimePolicy::ProcessResult()\n { }\n \n-TInstant TDefaultInvocationTimePolicy::KickstartDeadline()\n+TInstant TDefaultInvocationTimePolicy::GenerateKickstartDeadline()\n {\n     return TInstant::Now() + RandomDuration(Splay);\n }\n@@ -54,18 +54,12 @@ void TDefaultInvocationTimePolicy::SetOptions(std::optional<TDuration> period)\n {\n     Period = period;\n }\n-\n-TInstant TDefaultInvocationTimePolicy::NextDeadline()\n+TInstant TDefaultInvocationTimePolicy::GenerateNextDeadline()\n {\n-    auto randomGenerator = [] {\n-        double rand = RandomNumber<double>();\n+    return TInstant::Now() + GenerateDelay();\n+}\n \n-        return 2.0 * rand - 1.0;\n-    };\n \n-    //! Jitter is divided by 2 for historical reasons.\n-    return TInstant::Now() + ApplyJitter(*Period, Jitter / 2.0, randomGenerator);\n-}\n \n bool TDefaultInvocationTimePolicy::IsOutOfBandProhibited()\n {\ndiff --git a/yt/yt/core/concurrency/periodic_executor.h b/yt/yt/core/concurrency/periodic_executor.h\nindex b28a70c8ae24..59f1114384ca 100644\n--- a/yt/yt/core/concurrency/periodic_executor.h\n+++ b/yt/yt/core/concurrency/periodic_executor.h\n@@ -26,7 +26,7 @@ class TDefaultInvocationTimePolicy\n \n     void ProcessResult();\n \n-    TInstant KickstartDeadline();\n+    TInstant GenerateKickstartDeadline();\n \n     bool IsEnabled();\n \n@@ -38,7 +38,7 @@ class TDefaultInvocationTimePolicy\n \n     void SetOptions(std::optional<TDuration> period);\n \n-    TInstant NextDeadline();\n+    TInstant GenerateNextDeadline();\n \n     bool IsOutOfBandProhibited();\n \ndiff --git a/yt/yt/core/concurrency/periodic_executor_base-inl.h b/yt/yt/core/concurrency/periodic_executor_base-inl.h\nindex 022dadf503a4..56cf6b037671 100644\n--- a/yt/yt/core/concurrency/periodic_executor_base-inl.h\n+++ b/yt/yt/core/concurrency/periodic_executor_base-inl.h\n@@ -39,7 +39,7 @@ TFuture<void> TPeriodicExecutorBase<TInvocationTimePolicy>::StartAndGetFirstExec\n         IdlePromise_ = TPromise<void>();\n         Started_ = true;\n         if (TInvocationTimePolicy::IsEnabled()) {\n-            PostDelayedCallback(TInvocationTimePolicy::KickstartDeadline());\n+            PostDelayedCallback(TInvocationTimePolicy::GenerateKickstartDeadline());\n         }\n     }\n \n@@ -251,7 +251,7 @@ void TPeriodicExecutorBase<TInvocationTimePolicy>::RunCallback()\n             guard.Release();\n             PostCallback();\n         } else if (TInvocationTimePolicy::IsEnabled()) {\n-            PostDelayedCallback(TInvocationTimePolicy::NextDeadline());\n+            PostDelayedCallback(TInvocationTimePolicy::GenerateNextDeadline());\n         }\n     };\n \n@@ -282,7 +282,7 @@ void TPeriodicExecutorBase<TInvocationTimePolicy>::OnCallbackCancelled()\n     }\n \n     if (TInvocationTimePolicy::IsEnabled()) {\n-        PostDelayedCallback(TInvocationTimePolicy::NextDeadline());\n+        PostDelayedCallback(TInvocationTimePolicy::GenerateNextDeadline());\n     }\n }\n \n@@ -299,7 +299,7 @@ void TPeriodicExecutorBase<TInvocationTimePolicy>::SetOptions(TPartialOptions...\n     if (Started_ && !Busy_ && TInvocationTimePolicy::ShouldKickstart(options...)) {\n         TInvocationTimePolicy::SetOptions(std::move(options)...);\n \n-        PostDelayedCallback(TInvocationTimePolicy::KickstartDeadline());\n+        PostDelayedCallback(TInvocationTimePolicy::GenerateKickstartDeadline());\n     } else {\n         TInvocationTimePolicy::SetOptions(std::move(options)...);\n     }\ndiff --git a/yt/yt/core/concurrency/periodic_executor_base.h b/yt/yt/core/concurrency/periodic_executor_base.h\nindex 32ce9522e8a7..8f53792dd164 100644\n--- a/yt/yt/core/concurrency/periodic_executor_base.h\n+++ b/yt/yt/core/concurrency/periodic_executor_base.h\n@@ -50,9 +50,9 @@ concept CInvocationTimePolicy = CCallbackResultProcessor<T> &&\n     { policy.SetOptions(options) } -> std::same_as<void>;\n \n     { policy.ShouldKickstart(options) } -> std::same_as<bool>;\n-    { policy.KickstartDeadline() } -> std::same_as<TInstant>;\n+    { policy.GenerateKickstartDeadline() } -> std::same_as<TInstant>;\n \n-    { policy.NextDeadline() } -> std::same_as<TInstant>;\n+    { policy.GenerateNextDeadline() } -> std::same_as<TInstant>;\n     { policy.IsOutOfBandProhibited() } -> std::same_as<bool>;\n     { policy.Reset() } -> std::same_as<void>;\n };\ndiff --git a/yt/yt/core/concurrency/retrying_periodic_executor.cpp b/yt/yt/core/concurrency/retrying_periodic_executor.cpp\nindex c20caadf5f84..dc812df8de6b 100644\n--- a/yt/yt/core/concurrency/retrying_periodic_executor.cpp\n+++ b/yt/yt/core/concurrency/retrying_periodic_executor.cpp\n@@ -89,13 +89,13 @@ void TRetryingInvocationTimePolicy::SetOptions(\n     }\n }\n \n-TInstant TRetryingInvocationTimePolicy::NextDeadline()\n+TInstant TRetryingInvocationTimePolicy::GenerateNextDeadline()\n {\n     if (IsInBackoffMode()) {\n         return TInstant::Now() + Backoff_.GetBackoff();\n     }\n \n-    return TDefaultInvocationTimePolicy::NextDeadline();\n+    return TDefaultInvocationTimePolicy::GenerateNextDeadline();\n }\n \n bool TRetryingInvocationTimePolicy::IsOutOfBandProhibited()\ndiff --git a/yt/yt/core/concurrency/retrying_periodic_executor.h b/yt/yt/core/concurrency/retrying_periodic_executor.h\nindex af7916e681de..3701b94226a2 100644\n--- a/yt/yt/core/concurrency/retrying_periodic_executor.h\n+++ b/yt/yt/core/concurrency/retrying_periodic_executor.h\n@@ -25,7 +25,7 @@ class TRetryingInvocationTimePolicy\n \n     void ProcessResult(TCallbackResult result);\n \n-    using TDefaultInvocationTimePolicy::KickstartDeadline;\n+    using TDefaultInvocationTimePolicy::GenerateKickstartDeadline;\n \n     using TDefaultInvocationTimePolicy::IsEnabled;\n \n@@ -41,7 +41,7 @@ class TRetryingInvocationTimePolicy\n         std::optional<NConcurrency::TPeriodicExecutorOptions> periodicOptions,\n         std::optional<TExponentialBackoffOptions> backofOptions);\n \n-    TInstant NextDeadline();\n+    TInstant GenerateNextDeadline();\n \n     bool IsOutOfBandProhibited();\n \ndiff --git a/yt/yt/core/concurrency/scheduled_executor.cpp b/yt/yt/core/concurrency/scheduled_executor.cpp\nindex f906e5545d1d..36e771ab6da8 100644\n--- a/yt/yt/core/concurrency/scheduled_executor.cpp\n+++ b/yt/yt/core/concurrency/scheduled_executor.cpp\n@@ -28,9 +28,9 @@ TScheduledInvocationTimePolicy::TScheduledInvocationTimePolicy(\n void TScheduledInvocationTimePolicy::ProcessResult()\n { }\n \n-TInstant TScheduledInvocationTimePolicy::KickstartDeadline()\n+TInstant TScheduledInvocationTimePolicy::GenerateKickstartDeadline()\n {\n-    return NextDeadline();\n+    return GenerateNextDeadline();\n }\n \n bool TScheduledInvocationTimePolicy::IsEnabled()\n@@ -53,7 +53,7 @@ void TScheduledInvocationTimePolicy::SetOptions(TOptions interval)\n //! Returns the next time instant which is a multiple of the configured interval.\n //! NB: If the current instant is itself a multiple of the configured interval, this method will return the next\n //! suitable instant.\n-TInstant TScheduledInvocationTimePolicy::NextDeadline()\n+TInstant TScheduledInvocationTimePolicy::GenerateNextDeadline()\n {\n     YT_VERIFY(Interval_);\n \ndiff --git a/yt/yt/core/concurrency/scheduled_executor.h b/yt/yt/core/concurrency/scheduled_executor.h\nindex cde105ae8960..025c5ece2dc7 100644\n--- a/yt/yt/core/concurrency/scheduled_executor.h\n+++ b/yt/yt/core/concurrency/scheduled_executor.h\n@@ -22,7 +22,7 @@ class TScheduledInvocationTimePolicy\n \n     void ProcessResult();\n \n-    TInstant KickstartDeadline();\n+    TInstant GenerateKickstartDeadline();\n \n     bool IsEnabled();\n \n@@ -33,7 +33,7 @@ class TScheduledInvocationTimePolicy\n     //! Returns the next time instant which is a multiple of the configured interval.\n     //! NB: If the current instant is itself a multiple of the configured interval, this method will return the next\n     //! suitable instant.\n-    TInstant NextDeadline();\n+    TInstant GenerateNextDeadline();\n \n     bool IsOutOfBandProhibited();\n \ndiff --git a/yt/yt/library/formats/arrow_writer.h b/yt/yt/library/formats/arrow_writer.h\nindex 0a3dd225348c..020090152ccd 100644\n--- a/yt/yt/library/formats/arrow_writer.h\n+++ b/yt/yt/library/formats/arrow_writer.h\n@@ -24,6 +24,3 @@ ISchemalessFormatWriterPtr CreateWriterForArrow(\n ////////////////////////////////////////////////////////////////////////////////\n \n } // namespace NYT::NFormat\n-\n-\n-\n",
  "test_patch": "diff --git a/yt/yt/core/actions/unittests/future_ut.cpp b/yt/yt/core/actions/unittests/future_ut.cpp\nindex 6f5debceb722..de1f661e1dcd 100644\n--- a/yt/yt/core/actions/unittests/future_ut.cpp\n+++ b/yt/yt/core/actions/unittests/future_ut.cpp\n@@ -33,6 +33,15 @@ struct TNonAssignable\n     const int Value = 0;\n };\n \n+// void Foo()\n+// {\n+//     auto a = NYT::MakeFuture<std::string>({})\n+//     .ApplyUnique(BIND([](std::string&&) {\n+//         return NYT::MakeFuture(std::make_unique<int>(42));\n+//     }))\n+//     .GetUnique();\n+// }\n+\n TEST_F(TFutureTest, NoncopyableGet)\n {\n     auto f = MakeFuture<std::unique_ptr<int>>(std::make_unique<int>(1));\n",
  "problem_statement": "Implemented selector allowing for several request types\n### Implemented selector allowing for several request types <!-- a user-readable short description of changes introduced in this PR -->\r\n\r\n...\r\n\r\n### Changelog category <!-- remove all except one -->\r\n\r\n* Improvement\r\n\r\n### Additional information\r\n\r\n...\r\n\n",
  "hints_text": "<!-- status pr=2810, preset=linux-x86_64-release-cmake14, run=5649 -->\n:white_circle: `2024-03-15 11:10:51 UTC` Pre-commit [check](https://github.com/ydb-platform/ydb/actions/runs/8295239590/job/22701882880) for ec8d6fb752b3137b5793948a844fa1421583d617 has started.\n:white_circle: `2024-03-15 11:10:54 UTC` Build **linux-x86_64-release-cmake14** is running...\n:green_circle: `2024-03-15 11:44:20 UTC` Build successful.\n<!-- status pr=2810, preset=linux-x86_64-relwithdebinfo, run=5649 -->\n:white_circle: `2024-03-15 11:10:57 UTC` Pre-commit [check](https://github.com/ydb-platform/ydb/actions/runs/8295239590/job/22701883179) for ec8d6fb752b3137b5793948a844fa1421583d617 has started.\n:white_circle: `2024-03-15 11:11:00 UTC` Build **linux-x86_64-relwithdebinfo** is running...\n:green_circle: `2024-03-15 11:47:07 UTC` Build successful.\n:white_circle: `2024-03-15 11:47:24 UTC` Tests are running...\n:red_circle: `2024-03-15 13:26:53 UTC` Some tests failed, follow the links below.\n\n[Test history](https://nebius.testmo.net/automation/runs/view/18733)\n| TESTS | PASSED | ERRORS | FAILED | SKIPPED | MUTED<sup>[?](https://github.com/ydb-platform/ydb/tree/main/.github/config/muted_ya.txt \"All mute rules are defined here\")</sup> |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| [68379](https://storage.yandexcloud.net/ydb-gh-logs/ydb-platform/ydb/PR-check/8295239590/ya-x86-64/summary/ya-test.html) | [57422](https://storage.yandexcloud.net/ydb-gh-logs/ydb-platform/ydb/PR-check/8295239590/ya-x86-64/summary/ya-test.html#PASS) | 0 | [2](https://storage.yandexcloud.net/ydb-gh-logs/ydb-platform/ydb/PR-check/8295239590/ya-x86-64/summary/ya-test.html#FAIL) | [10930](https://storage.yandexcloud.net/ydb-gh-logs/ydb-platform/ydb/PR-check/8295239590/ya-x86-64/summary/ya-test.html#SKIP) | [25](https://storage.yandexcloud.net/ydb-gh-logs/ydb-platform/ydb/PR-check/8295239590/ya-x86-64/summary/ya-test.html#MUTE) |\n<!-- status pr=2810, preset=linux-x86_64-release-asan, run=5649 -->\n:white_circle: `2024-03-15 11:17:25 UTC` Pre-commit [check](https://github.com/ydb-platform/ydb/actions/runs/8295239590/job/22701883435) for ec8d6fb752b3137b5793948a844fa1421583d617 has started.\n:white_circle: `2024-03-15 11:17:27 UTC` Build **linux-x86_64-release-asan** is running...\n:green_circle: `2024-03-15 11:51:51 UTC` Build successful.\n:white_circle: `2024-03-15 11:52:03 UTC` Tests are running...\n:red_circle: `2024-03-15 13:52:31 UTC` Some tests failed, follow the links below.\n\n[Test history](https://nebius.testmo.net/automation/runs/view/18736)\n| TESTS | PASSED | ERRORS | FAILED | SKIPPED | MUTED<sup>[?](https://github.com/ydb-platform/ydb/tree/main/.github/config/muted_ya.txt \"All mute rules are defined here\")</sup> |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| [15065](https://storage.yandexcloud.net/ydb-gh-logs/ydb-platform/ydb/PR-check/8295239590/ya-x86-64-asan/summary/ya-test.html) | [14478](https://storage.yandexcloud.net/ydb-gh-logs/ydb-platform/ydb/PR-check/8295239590/ya-x86-64-asan/summary/ya-test.html#PASS) | 0 | [63](https://storage.yandexcloud.net/ydb-gh-logs/ydb-platform/ydb/PR-check/8295239590/ya-x86-64-asan/summary/ya-test.html#FAIL) | [495](https://storage.yandexcloud.net/ydb-gh-logs/ydb-platform/ydb/PR-check/8295239590/ya-x86-64-asan/summary/ya-test.html#SKIP) | [29](https://storage.yandexcloud.net/ydb-gh-logs/ydb-platform/ydb/PR-check/8295239590/ya-x86-64-asan/summary/ya-test.html#MUTE) |",
  "created_at": "2025-03-16T00:52:00Z"
}