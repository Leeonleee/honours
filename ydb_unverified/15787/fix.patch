diff --git a/build/conf/compilers/gnu_compiler.conf b/build/conf/compilers/gnu_compiler.conf
index 045374757f2f..7ce38f66aed8 100644
--- a/build/conf/compilers/gnu_compiler.conf
+++ b/build/conf/compilers/gnu_compiler.conf
@@ -74,8 +74,7 @@ when ($CLANG16 == "yes") {
 when ($CLANG18 == "yes") {
     CFLAGS+=-Wno-array-parameter -Wno-deprecate-lax-vec-conv-all -Wno-unqualified-std-cast-call -Wno-unused-but-set-parameter -Wno-implicit-function-declaration -Wno-int-conversion -Wno-incompatible-function-pointer-types -Wno-address-of-packed-member
     CFLAGS+=-Wno-deprecated-this-capture -Wno-c++11-narrowing-const-reference -Wno-missing-designated-field-initializers \
-            -Wno-packed-non-pod -Wno-format -Wno-vla-cxx-extension -Wno-invalid-offsetof \
-            -Wno-include-angled-in-module-purview
+            -Wno-packed-non-pod -Wno-format -Wno-vla-cxx-extension -Wno-invalid-offsetof
     when ($MAPSMOBI_BUILD_TARGET == "yes") {
         CFLAGS+=-Wno-deprecated-declarations
     }
diff --git a/build/export_generators/cmake/cmake/FindCython.cmake b/build/export_generators/cmake/cmake/FindCython.cmake
new file mode 100644
index 000000000000..ae72094934e6
--- /dev/null
+++ b/build/export_generators/cmake/cmake/FindCython.cmake
@@ -0,0 +1,47 @@
+# Copyright (c) Meta Platforms, Inc. and affiliates.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# Find Cython
+#
+# This module sets the following variables:
+# - Cython_FOUND
+# - CYTHON_EXE
+# - CYTHON_VERSION_STRING
+#
+find_program(CYTHON_EXE
+             NAMES cython cython3)
+if (CYTHON_EXE)
+  execute_process(COMMAND ${CYTHON_EXE} --version
+                  RESULT_VARIABLE _cython_retcode
+                  OUTPUT_VARIABLE _cython_output
+                  ERROR_VARIABLE _cython_output
+                  OUTPUT_STRIP_TRAILING_WHITESPACE)
+
+  if (${_cython_retcode} EQUAL 0)
+    separate_arguments(_cython_output)
+    list(GET _cython_output -1 CYTHON_VERSION_STRING)
+    message(STATUS "Found Cython Version ${CYTHON_VERSION_STRING}")
+  else ()
+    message(STATUS "Failed to get Cython version")
+  endif ()
+else ()
+  message(STATUS "Cython not found")
+endif ()
+
+include(FindPackageHandleStandardArgs)
+find_package_handle_standard_args(
+  Cython
+  REQUIRED_VARS CYTHON_EXE CYTHON_VERSION_STRING
+  VERSION_VAR CYTHON_VERSION_STRING
+)
diff --git a/build/export_generators/cmake/cmake/cython.cmake b/build/export_generators/cmake/cmake/cython.cmake
index 055c742055cf..0b6f469048cc 100644
--- a/build/export_generators/cmake/cmake/cython.cmake
+++ b/build/export_generators/cmake/cmake/cython.cmake
@@ -1,3 +1,8 @@
+if (NOT USE_INTERNAL_CYTHON)
+  include(FindCython)
+endif()
+
+
 function(target_cython_include_directories Tgt)
   set_property(TARGET ${Tgt} APPEND PROPERTY
     CYTHON_INCLUDE_DIRS ${ARGN}
@@ -25,12 +30,19 @@ macro(set_python_type_for_cython Tgt Type)
 endmacro()
 
 function(target_cython_sources Tgt Scope)
+  if (USE_INTERNAL_CYTHON)
+    set(CYTHON_CMD_PREFIX $<TARGET_GENEX_EVAL:${Tgt},$<TARGET_PROPERTY:${Tgt},CYTHON_PYTHON_INTERPRETER>> ${PROJECT_SOURCE_DIR}/contrib/tools/cython/cython.py)
+  else()
+    find_package(Cython REQUIRED)
+    set(CYTHON_CMD_PREFIX ${CYTHON_EXE})
+  endif()
+
   foreach(Input ${ARGN})
     get_filename_component(OutputBase ${Input} NAME)
     set(CppCythonOutput ${CMAKE_CURRENT_BINARY_DIR}/${OutputBase}.cpp)
     add_custom_command(
       OUTPUT ${CppCythonOutput}
-      COMMAND $<TARGET_GENEX_EVAL:${Tgt},$<TARGET_PROPERTY:${Tgt},CYTHON_PYTHON_INTERPRETER>> ${PROJECT_SOURCE_DIR}/contrib/tools/cython/cython.py ${Input} -o ${CppCythonOutput}
+      COMMAND ${CYTHON_CMD_PREFIX} ${Input} -o ${CppCythonOutput}
         "$<JOIN:$<TARGET_GENEX_EVAL:${Tgt},$<TARGET_PROPERTY:${Tgt},CYTHON_OPTIONS>>,$<SEMICOLON>>"
         "-I$<JOIN:$<TARGET_GENEX_EVAL:${Tgt},$<TARGET_PROPERTY:${Tgt},CYTHON_INCLUDE_DIRS>>,$<SEMICOLON>-I>"
       COMMAND_EXPAND_LISTS
diff --git a/build/export_generators/cmake/generator.toml b/build/export_generators/cmake/generator.toml
index b25cf88c35fb..2f4c039b55aa 100644
--- a/build/export_generators/cmake/generator.toml
+++ b/build/export_generators/cmake/generator.toml
@@ -329,7 +329,10 @@ attrs=[
     "target_macroses-macro=target_cython_include_directories",
     "target_macroses-macro=set_python_type_for_cython",
 ]
-copy=["cmake/cython.cmake"]
+copy=[
+    "cmake/cython.cmake",
+    "cmake/FindCython.cmake"
+]
 add_values=[{attr="includes", values=["cmake/cython.cmake"]}]
 
 [[rules]]
diff --git a/contrib/libs/croaring/.yandex_meta/override.nix b/contrib/libs/croaring/.yandex_meta/override.nix
index 60171a848a4e..616330eb5adc 100644
--- a/contrib/libs/croaring/.yandex_meta/override.nix
+++ b/contrib/libs/croaring/.yandex_meta/override.nix
@@ -1,12 +1,12 @@
 pkgs: attrs: with pkgs; with attrs; rec {
   pname = "croaring";
-  version = "4.2.3";
+  version = "4.3.0";
 
   src = fetchFromGitHub {
     owner = "RoaringBitmap";
     repo = "CRoaring";
     rev = "v${version}";
-    hash = "sha256-1yklwZj12yeGg8a/oss4EUHj8eezhKuo4PUltVdaXaM=";
+    hash = "sha256-Se/m+qcYwZu1Bp5F2dcWacHYe4awX7EclB1iChTBkYE=";
   };
 
   patches = [];
diff --git a/contrib/libs/croaring/include/roaring/art/art.h b/contrib/libs/croaring/include/roaring/art/art.h
index e191c1eedaa3..16b1e5516b0c 100644
--- a/contrib/libs/croaring/include/roaring/art/art.h
+++ b/contrib/libs/croaring/include/roaring/art/art.h
@@ -19,8 +19,8 @@
  *    chunks _differ_. This means that if there are two entries with different
  *    high 48 bits, then there is only one inner node containing the common key
  *    prefix, and two leaves.
- *  * Intrusive leaves: the leaf struct is included in user values. This removes
- *    a layer of indirection.
+ *  * Mostly pointer-free: nodes are referred to by index rather than pointer,
+ *    so that the structure can be deserialized with a backing buffer.
  */
 
 // Fixed length of keys in the ART. All keys are assumed to be of this length.
@@ -33,25 +33,33 @@ namespace internal {
 #endif
 
 typedef uint8_t art_key_chunk_t;
-typedef struct art_node_s art_node_t;
+
+// Internal node reference type. Contains the node typecode in the low 8 bits,
+// and the index in the relevant node array in the high 48 bits. Has a value of
+// CROARING_ART_NULL_REF when pointing to a non-existent node.
+typedef uint64_t art_ref_t;
+
+typedef void art_node_t;
 
 /**
- * Wrapper to allow an empty tree.
+ * The ART is empty when root is a null ref.
+ *
+ * Each node type has its own dynamic array of node structs, indexed by
+ * art_ref_t. The arrays are expanded as needed, and shrink only when
+ * `shrink_to_fit` is called.
  */
 typedef struct art_s {
-    art_node_t *root;
+    art_ref_t root;
+
+    // Indexed by node typecode, thus 1 larger than they need to be for
+    // convenience. `first_free` indicates the index where the first free node
+    // lives, which may be equal to the capacity.
+    uint64_t first_free[6];
+    uint64_t capacities[6];
+    art_node_t *nodes[6];
 } art_t;
 
-/**
- * Values inserted into the tree have to be cast-able to art_val_t. This
- * improves performance by reducing indirection.
- *
- * NOTE: Value pointers must be unique! This is because each value struct
- * contains the key corresponding to the value.
- */
-typedef struct art_val_s {
-    art_key_chunk_t key[ART_KEY_BYTES];
-} art_val_t;
+typedef uint64_t art_val_t;
 
 /**
  * Compares two keys, returns their relative order:
@@ -63,14 +71,21 @@ int art_compare_keys(const art_key_chunk_t key1[],
                      const art_key_chunk_t key2[]);
 
 /**
- * Inserts the given key and value.
+ * Initializes the ART.
+ */
+void art_init_cleared(art_t *art);
+
+/**
+ * Inserts the given key and value. Returns a pointer to the value inserted,
+ * valid as long as the ART is not modified.
  */
-void art_insert(art_t *art, const art_key_chunk_t *key, art_val_t *val);
+art_val_t *art_insert(art_t *art, const art_key_chunk_t *key, art_val_t val);
 
 /**
- * Returns the value erased, NULL if not found.
+ * Returns true if a value was erased. Sets `*erased_val` to the value erased,
+ * if any.
  */
-art_val_t *art_erase(art_t *art, const art_key_chunk_t *key);
+bool art_erase(art_t *art, const art_key_chunk_t *key, art_val_t *erased_val);
 
 /**
  * Returns the value associated with the given key, NULL if not found.
@@ -83,42 +98,39 @@ art_val_t *art_find(const art_t *art, const art_key_chunk_t *key);
 bool art_is_empty(const art_t *art);
 
 /**
- * Frees the nodes of the ART except the values, which the user is expected to
- * free.
+ * Frees the contents of the ART. Should not be called when using
+ * `art_deserialize_frozen_safe`.
  */
 void art_free(art_t *art);
 
-/**
- * Returns the size in bytes of the ART. Includes size of pointers to values,
- * but not the values themselves.
- */
-size_t art_size_in_bytes(const art_t *art);
-
 /**
  * Prints the ART using printf, useful for debugging.
  */
 void art_printf(const art_t *art);
 
 /**
- * Callback for validating the value stored in a leaf.
+ * Callback for validating the value stored in a leaf. `context` is a
+ * user-provided value passed to the callback without modification.
  *
  * Should return true if the value is valid, false otherwise
  * If false is returned, `*reason` should be set to a static string describing
  * the reason for the failure.
  */
-typedef bool (*art_validate_cb_t)(const art_val_t *val, const char **reason);
+typedef bool (*art_validate_cb_t)(const art_val_t val, const char **reason,
+                                  void *context);
 
 /**
- * Validate the ART tree, ensuring it is internally consistent.
+ * Validate the ART tree, ensuring it is internally consistent. `context` is a
+ * user-provided value passed to the callback without modification.
  */
 bool art_internal_validate(const art_t *art, const char **reason,
-                           art_validate_cb_t validate_cb);
+                           art_validate_cb_t validate_cb, void *context);
 
 /**
  * ART-internal iterator bookkeeping. Users should treat this as an opaque type.
  */
 typedef struct art_iterator_frame_s {
-    art_node_t *node;
+    art_ref_t ref;
     uint8_t index_in_node;
 } art_iterator_frame_t;
 
@@ -130,6 +142,8 @@ typedef struct art_iterator_s {
     art_key_chunk_t key[ART_KEY_BYTES];
     art_val_t *value;
 
+    art_t *art;
+
     uint8_t depth;  // Key depth
     uint8_t frame;  // Node depth
 
@@ -143,19 +157,19 @@ typedef struct art_iterator_s {
  * depending on `first`. The iterator is not valid if there are no entries in
  * the ART.
  */
-art_iterator_t art_init_iterator(const art_t *art, bool first);
+art_iterator_t art_init_iterator(art_t *art, bool first);
 
 /**
  * Returns an initialized iterator positioned at a key equal to or greater than
  * the given key, if it exists.
  */
-art_iterator_t art_lower_bound(const art_t *art, const art_key_chunk_t *key);
+art_iterator_t art_lower_bound(art_t *art, const art_key_chunk_t *key);
 
 /**
  * Returns an initialized iterator positioned at a key greater than the given
  * key, if it exists.
  */
-art_iterator_t art_upper_bound(const art_t *art, const art_key_chunk_t *key);
+art_iterator_t art_upper_bound(art_t *art, const art_key_chunk_t *key);
 
 /**
  * The following iterator movement functions return true if a new entry was
@@ -174,14 +188,49 @@ bool art_iterator_lower_bound(art_iterator_t *iterator,
 /**
  * Insert the value and positions the iterator at the key.
  */
-void art_iterator_insert(art_t *art, art_iterator_t *iterator,
-                         const art_key_chunk_t *key, art_val_t *val);
+void art_iterator_insert(art_iterator_t *iterator, const art_key_chunk_t *key,
+                         art_val_t val);
 
 /**
  * Erase the value pointed at by the iterator. Moves the iterator to the next
- * leaf. Returns the value erased or NULL if nothing was erased.
+ * leaf.
+ * Returns true if a value was erased. Sets `*erased_val` to the value erased,
+ * if any.
+ */
+bool art_iterator_erase(art_iterator_t *iterator, art_val_t *erased_val);
+
+/**
+ * Shrinks the internal arrays in the ART to remove any unused elements. Returns
+ * the number of bytes freed.
+ */
+size_t art_shrink_to_fit(art_t *art);
+
+/**
+ * Returns true if the ART has no unused elements.
+ */
+bool art_is_shrunken(const art_t *art);
+
+/**
+ * Returns the serialized size in bytes.
+ * Requires `art_shrink_to_fit` to be called first.
+ */
+size_t art_size_in_bytes(const art_t *art);
+
+/**
+ * Serializes the ART and returns the number of bytes written. Returns 0 on
+ * error. Requires `art_shrink_to_fit` to be called first.
+ */
+size_t art_serialize(const art_t *art, char *buf);
+
+/**
+ * Deserializes the ART from a serialized buffer, reading up to `maxbytes`
+ * bytes. Returns 0 on error. Requires `buf` to be 8 byte aligned.
+ *
+ * An ART deserialized in this way should only be used in a readonly context.The
+ * underlying buffer must not be freed before the ART. `art_free` should not be
+ * called on the ART deserialized in this way.
  */
-art_val_t *art_iterator_erase(art_t *art, art_iterator_t *iterator);
+size_t art_frozen_view(const char *buf, size_t maxbytes, art_t *art);
 
 #ifdef __cplusplus
 }  // extern "C"
diff --git a/contrib/libs/croaring/include/roaring/portability.h b/contrib/libs/croaring/include/roaring/portability.h
index 8c6d3c2bac72..8e326bc9cb07 100644
--- a/contrib/libs/croaring/include/roaring/portability.h
+++ b/contrib/libs/croaring/include/roaring/portability.h
@@ -49,20 +49,6 @@
 #define CROARING_REGULAR_VISUAL_STUDIO 0
 #endif
 
-#if defined(_POSIX_C_SOURCE) && (_POSIX_C_SOURCE < 200809L)
-#undef _POSIX_C_SOURCE
-#endif
-
-#ifndef _POSIX_C_SOURCE
-#define _POSIX_C_SOURCE 200809L
-#endif  // !(defined(_POSIX_C_SOURCE)) || (_POSIX_C_SOURCE < 200809L)
-
-#ifdef __illumos__
-#ifndef __EXTENSIONS__
-#define __EXTENSIONS__
-#endif  // __EXTENSIONS__
-#endif
-
 #include <stdbool.h>
 #include <stdint.h>
 #include <stdlib.h>  // will provide posix_memalign with _POSIX_C_SOURCE as defined above
diff --git a/contrib/libs/croaring/include/roaring/roaring64.h b/contrib/libs/croaring/include/roaring/roaring64.h
index 8022f160dd44..e185b48aaea4 100644
--- a/contrib/libs/croaring/include/roaring/roaring64.h
+++ b/contrib/libs/croaring/include/roaring/roaring64.h
@@ -17,7 +17,7 @@ namespace api {
 #endif
 
 typedef struct roaring64_bitmap_s roaring64_bitmap_t;
-typedef struct roaring64_leaf_s roaring64_leaf_t;
+typedef uint64_t roaring64_leaf_t;
 typedef struct roaring64_iterator_s roaring64_iterator_t;
 
 /**
@@ -312,6 +312,12 @@ uint64_t roaring64_bitmap_maximum(const roaring64_bitmap_t *r);
  */
 bool roaring64_bitmap_run_optimize(roaring64_bitmap_t *r);
 
+/**
+ * Shrinks internal arrays to eliminate any unused capacity. Returns the number
+ * of bytes freed.
+ */
+size_t roaring64_bitmap_shrink_to_fit(roaring64_bitmap_t *r);
+
 /**
  *  (For advanced users.)
  * Collect statistics about the bitmap
@@ -564,6 +570,53 @@ size_t roaring64_bitmap_portable_deserialize_size(const char *buf,
 roaring64_bitmap_t *roaring64_bitmap_portable_deserialize_safe(const char *buf,
                                                                size_t maxbytes);
 
+/**
+ * Returns the number of bytes required to serialize this bitmap in a "frozen"
+ * format. This is not compatible with any other serialization formats.
+ *
+ * `roaring64_bitmap_shrink_to_fit()` must be called before this method.
+ */
+size_t roaring64_bitmap_frozen_size_in_bytes(const roaring64_bitmap_t *r);
+
+/**
+ * Serializes the bitmap in a "frozen" format. The given buffer must be at least
+ * `roaring64_bitmap_frozen_size_in_bytes()` in size. Returns the number of
+ * bytes used for serialization.
+ *
+ * `roaring64_bitmap_shrink_to_fit()` must be called before this method.
+ *
+ * The frozen format is optimized for speed of (de)serialization, as well as
+ * allowing the user to create a bitmap based on a memory mapped file, which is
+ * possible because the format mimics the memory layout of the bitmap.
+ *
+ * Because the format mimics the memory layout of the bitmap, the format is not
+ * fixed across releases of Roaring Bitmaps, and may change in future releases.
+ *
+ * This function is endian-sensitive. If you have a big-endian system (e.g., a
+ * mainframe IBM s390x), the data format is going to be big-endian and not
+ * compatible with little-endian systems.
+ */
+size_t roaring64_bitmap_frozen_serialize(const roaring64_bitmap_t *r,
+                                         char *buf);
+
+/**
+ * Creates a readonly bitmap that is a view of the given buffer. The buffer
+ * must be created with `roaring64_bitmap_frozen_serialize()`, and must be
+ * aligned by 64 bytes.
+ *
+ * Returns NULL if deserialization fails.
+ *
+ * The returned bitmap must only be used in a readonly manner. The bitmap must
+ * be freed using `roaring64_bitmap_free()` as normal. The backing buffer must
+ * only be freed after the bitmap.
+ *
+ * This function is endian-sensitive. If you have a big-endian system (e.g., a
+ * mainframe IBM s390x), the data format is going to be big-endian and not
+ * compatible with little-endian systems.
+ */
+roaring64_bitmap_t *roaring64_bitmap_frozen_view(const char *buf,
+                                                 size_t maxbytes);
+
 /**
  * Iterate over the bitmap elements. The function `iterator` is called once for
  * all the values with `ptr` (can be NULL) as the second parameter of each call.
diff --git a/contrib/libs/croaring/include/roaring/roaring_version.h b/contrib/libs/croaring/include/roaring/roaring_version.h
index 98819566a8dd..a6c5b01b4169 100644
--- a/contrib/libs/croaring/include/roaring/roaring_version.h
+++ b/contrib/libs/croaring/include/roaring/roaring_version.h
@@ -2,11 +2,11 @@
 // /include/roaring/roaring_version.h automatically generated by release.py, do not change by hand
 #ifndef ROARING_INCLUDE_ROARING_VERSION
 #define ROARING_INCLUDE_ROARING_VERSION
-#define ROARING_VERSION "4.2.3"
+#define ROARING_VERSION "4.3.0"
 enum {
     ROARING_VERSION_MAJOR = 4,
-    ROARING_VERSION_MINOR = 2,
-    ROARING_VERSION_REVISION = 3
+    ROARING_VERSION_MINOR = 3,
+    ROARING_VERSION_REVISION = 0
 };
 #endif // ROARING_INCLUDE_ROARING_VERSION
 // clang-format on
\ No newline at end of file
diff --git a/contrib/libs/croaring/src/art/art.c b/contrib/libs/croaring/src/art/art.c
index 7bca7eb2c981..8e54d4353e2f 100644
--- a/contrib/libs/croaring/src/art/art.c
+++ b/contrib/libs/croaring/src/art/art.c
@@ -1,4 +1,5 @@
 #include <assert.h>
+#include <stdalign.h>
 #include <stdio.h>
 #include <string.h>
 
@@ -6,33 +7,31 @@
 #include <roaring/memory.h>
 #include <roaring/portability.h>
 
-#define CROARING_ART_NODE4_TYPE 0
-#define CROARING_ART_NODE16_TYPE 1
-#define CROARING_ART_NODE48_TYPE 2
-#define CROARING_ART_NODE256_TYPE 3
-#define CROARING_ART_NUM_TYPES 4
+#define CROARING_ART_NULL_REF 0
+
+#define CROARING_ART_LEAF_TYPE 1
+#define CROARING_ART_NODE4_TYPE 2
+#define CROARING_ART_NODE16_TYPE 3
+#define CROARING_ART_NODE48_TYPE 4
+#define CROARING_ART_NODE256_TYPE 5
+
+#define CROARING_ART_MIN_TYPE CROARING_ART_LEAF_TYPE
+#define CROARING_ART_MAX_TYPE CROARING_ART_NODE256_TYPE
 
 // Node48 placeholder value to indicate no child is present at this key index.
 #define CROARING_ART_NODE48_EMPTY_VAL 48
+#define CROARING_NODE48_AVAILABLE_CHILDREN_MASK ((UINT64_C(1) << 48) - 1)
 
-// We use the least significant bit of node pointers to indicate whether a node
-// is a leaf or an inner node. This is never surfaced to the user.
-//
-// Using pointer tagging to indicate leaves not only saves a bit of memory by
-// sparing the typecode, but also allows us to use an intrusive leaf struct.
-// Using an intrusive leaf struct leaves leaf allocation up to the user. Upon
-// deallocation of the ART, we know not to free the leaves without having to
-// dereference the leaf pointers.
-//
-// All internal operations on leaves should use CROARING_CAST_LEAF before using
-// the leaf. The only places that use CROARING_SET_LEAF are locations where a
-// field is directly assigned to a leaf pointer. After using CROARING_SET_LEAF,
-// the leaf should be treated as a node of unknown type.
-#define CROARING_IS_LEAF(p) (((uintptr_t)(p) & 1))
-#define CROARING_SET_LEAF(p) ((art_node_t *)((uintptr_t)(p) | 1))
-#define CROARING_CAST_LEAF(p) ((art_leaf_t *)((void *)((uintptr_t)(p) & ~1)))
+#define CROARING_ART_ALIGN_BUF(buf, alignment)      \
+    (char *)(((uintptr_t)(buf) + ((alignment)-1)) & \
+             (ptrdiff_t)(~((alignment)-1)))
 
-#define CROARING_NODE48_AVAILABLE_CHILDREN_MASK ((UINT64_C(1) << 48) - 1)
+// Gives the byte difference needed to align the current buffer to the
+// alignment, relative to the start of the buffer.
+#define CROARING_ART_ALIGN_SIZE_RELATIVE(buf_cur, buf_start, alignment) \
+    ((((ptrdiff_t)((buf_cur) - (buf_start)) + ((alignment)-1)) &        \
+      (ptrdiff_t)(~((alignment)-1))) -                                  \
+     (ptrdiff_t)((buf_cur) - (buf_start)))
 
 #ifdef __cplusplus
 extern "C" {
@@ -42,30 +41,20 @@ namespace internal {
 
 typedef uint8_t art_typecode_t;
 
-// Aliasing with a "leaf" naming so that its purpose is clearer in the context
-// of the trie internals.
-typedef art_val_t art_leaf_t;
-
-typedef struct art_internal_validate_s {
-    const char **reason;
-    art_validate_cb_t validate_cb;
-
-    int depth;
-    art_key_chunk_t current_key[ART_KEY_BYTES];
-} art_internal_validate_t;
-
-// Set the reason message, and return false for convenience.
-static inline bool art_validate_fail(const art_internal_validate_t *validate,
-                                     const char *msg) {
-    *validate->reason = msg;
-    return false;
-}
+typedef struct art_leaf_s {
+    union {
+        struct {
+            art_key_chunk_t key[ART_KEY_BYTES];
+            art_val_t val;
+        };
+        uint64_t next_free;
+    };
+} art_leaf_t;
 
 // Inner node, with prefix.
 //
 // We use a fixed-length array as a pointer would be larger than the array.
 typedef struct art_inner_node_s {
-    art_typecode_t typecode;
     uint8_t prefix_size;
     uint8_t prefix[ART_KEY_BYTES - 1];
 } art_inner_node_t;
@@ -74,119 +63,232 @@ typedef struct art_inner_node_s {
 
 // Node4: key[i] corresponds with children[i]. Keys are sorted.
 typedef struct art_node4_s {
-    art_inner_node_t base;
-    uint8_t count;
-    uint8_t keys[4];
-    art_node_t *children[4];
+    union {
+        struct {
+            art_inner_node_t base;
+            uint8_t count;
+            uint8_t keys[4];
+            art_ref_t children[4];
+        };
+        uint64_t next_free;
+    };
 } art_node4_t;
 
 // Node16: key[i] corresponds with children[i]. Keys are sorted.
 typedef struct art_node16_s {
-    art_inner_node_t base;
-    uint8_t count;
-    uint8_t keys[16];
-    art_node_t *children[16];
+    union {
+        struct {
+            art_inner_node_t base;
+            uint8_t count;
+            uint8_t keys[16];
+            art_ref_t children[16];
+        };
+        uint64_t next_free;
+    };
 } art_node16_t;
 
 // Node48: key[i] corresponds with children[key[i]] if key[i] !=
 // CROARING_ART_NODE48_EMPTY_VAL. Keys are naturally sorted due to direct
 // indexing.
 typedef struct art_node48_s {
-    art_inner_node_t base;
-    uint8_t count;
-    // Bitset where the ith bit is set if children[i] is available
-    // Because there are at most 48 children, only the bottom 48 bits are used.
-    uint64_t available_children;
-    uint8_t keys[256];
-    art_node_t *children[48];
+    union {
+        struct {
+            art_inner_node_t base;
+            uint8_t count;
+            // Bitset where the ith bit is set if children[i] is available
+            // Because there are at most 48 children, only the bottom 48 bits
+            // are used.
+            uint64_t available_children;
+            uint8_t keys[256];
+            art_ref_t children[48];
+        };
+        uint64_t next_free;
+    };
 } art_node48_t;
 
 // Node256: children[i] is directly indexed by key chunk. A child is present if
 // children[i] != NULL.
 typedef struct art_node256_s {
-    art_inner_node_t base;
-    uint16_t count;
-    art_node_t *children[256];
+    union {
+        struct {
+            art_inner_node_t base;
+            uint16_t count;
+            art_ref_t children[256];
+        };
+        uint64_t next_free;
+    };
 } art_node256_t;
 
+// Size of each node type, indexed by typecode for convenience.
+static const size_t ART_NODE_SIZES[] = {
+    0,
+    sizeof(art_leaf_t),
+    sizeof(art_node4_t),
+    sizeof(art_node16_t),
+    sizeof(art_node48_t),
+    sizeof(art_node256_t),
+};
+
 // Helper struct to refer to a child within a node at a specific index.
 typedef struct art_indexed_child_s {
-    art_node_t *child;
+    art_ref_t child;
     uint8_t index;
     art_key_chunk_t key_chunk;
 } art_indexed_child_t;
 
-static inline bool art_is_leaf(const art_node_t *node) {
-    return CROARING_IS_LEAF(node);
+typedef struct art_internal_validate_s {
+    const char **reason;
+    art_validate_cb_t validate_cb;
+    void *context;
+
+    int depth;
+    art_key_chunk_t current_key[ART_KEY_BYTES];
+} art_internal_validate_t;
+
+// Set the reason message, and return false for convenience.
+static inline bool art_validate_fail(const art_internal_validate_t *validate,
+                                     const char *msg) {
+    *validate->reason = msg;
+    return false;
 }
 
-static void art_leaf_populate(art_leaf_t *leaf, const art_key_chunk_t key[]) {
-    memcpy(leaf->key, key, ART_KEY_BYTES);
+static inline art_ref_t art_to_ref(uint64_t index, art_typecode_t typecode) {
+    return ((art_ref_t)index) << 16 | typecode;
+}
+
+static inline uint64_t art_ref_index(art_ref_t ref) {
+    return ((uint64_t)ref) >> 16;
+}
+
+static inline art_typecode_t art_ref_typecode(art_ref_t ref) {
+    return (art_typecode_t)ref;
+}
+
+/**
+ * Gets a pointer to a node from its reference. The pointer only remains valid
+ * under non-mutating operations. If any mutating operations occur, this
+ * function should be called again to get a valid pointer to the node.
+ */
+static art_node_t *art_deref(const art_t *art, art_ref_t ref) {
+    assert(ref != CROARING_ART_NULL_REF);
+    art_typecode_t typecode = art_ref_typecode(ref);
+    return (art_node_t *)((char *)art->nodes[typecode] +
+                          art_ref_index(ref) * ART_NODE_SIZES[typecode]);
+}
+
+static inline art_node_t *art_get_node(const art_t *art, uint64_t index,
+                                       art_typecode_t typecode) {
+    return art_deref(art, art_to_ref(index, typecode));
 }
 
-static inline uint8_t art_get_type(const art_inner_node_t *node) {
-    return node->typecode;
+static inline uint64_t art_get_index(const art_t *art, const art_node_t *node,
+                                     art_typecode_t typecode) {
+    art_node_t *nodes = art->nodes[typecode];
+    switch (typecode) {
+        case CROARING_ART_LEAF_TYPE:
+            return (art_leaf_t *)node - (art_leaf_t *)nodes;
+        case CROARING_ART_NODE4_TYPE:
+            return (art_node4_t *)node - (art_node4_t *)nodes;
+        case CROARING_ART_NODE16_TYPE:
+            return (art_node16_t *)node - (art_node16_t *)nodes;
+        case CROARING_ART_NODE48_TYPE:
+            return (art_node48_t *)node - (art_node48_t *)nodes;
+        case CROARING_ART_NODE256_TYPE:
+            return (art_node256_t *)node - (art_node256_t *)nodes;
+        default:
+            assert(false);
+            return 0;
+    }
+}
+
+/**
+ * Creates a reference from a pointer.
+ */
+static inline art_ref_t art_get_ref(const art_t *art, const art_node_t *node,
+                                    art_typecode_t typecode) {
+    return art_to_ref(art_get_index(art, node, typecode), typecode);
+}
+
+static inline bool art_is_leaf(art_ref_t ref) {
+    return art_ref_typecode(ref) == CROARING_ART_LEAF_TYPE;
 }
 
 static inline void art_init_inner_node(art_inner_node_t *node,
-                                       art_typecode_t typecode,
                                        const art_key_chunk_t prefix[],
                                        uint8_t prefix_size) {
-    node->typecode = typecode;
     node->prefix_size = prefix_size;
     memcpy(node->prefix, prefix, prefix_size * sizeof(art_key_chunk_t));
 }
 
-static void art_free_node(art_node_t *node);
+static void art_node_free(art_t *art, art_node_t *node,
+                          art_typecode_t typecode);
+
+static uint64_t art_allocate_index(art_t *art, art_typecode_t typecode);
 
 // ===================== Start of node-specific functions ======================
 
-static art_node4_t *art_node4_create(const art_key_chunk_t prefix[],
+static art_ref_t art_leaf_create(art_t *art, const art_key_chunk_t key[],
+                                 art_val_t val) {
+    uint64_t index = art_allocate_index(art, CROARING_ART_LEAF_TYPE);
+    art_leaf_t *leaf =
+        ((art_leaf_t *)art->nodes[CROARING_ART_LEAF_TYPE]) + index;
+    memcpy(leaf->key, key, ART_KEY_BYTES);
+    leaf->val = val;
+    return art_to_ref(index, CROARING_ART_LEAF_TYPE);
+}
+
+static inline void art_leaf_clear(art_leaf_t *leaf, art_ref_t next_free) {
+    leaf->next_free = next_free;
+}
+
+static art_node4_t *art_node4_create(art_t *art, const art_key_chunk_t prefix[],
                                      uint8_t prefix_size);
-static art_node16_t *art_node16_create(const art_key_chunk_t prefix[],
+static art_node16_t *art_node16_create(art_t *art,
+                                       const art_key_chunk_t prefix[],
                                        uint8_t prefix_size);
-static art_node48_t *art_node48_create(const art_key_chunk_t prefix[],
+static art_node48_t *art_node48_create(art_t *art,
+                                       const art_key_chunk_t prefix[],
                                        uint8_t prefix_size);
-static art_node256_t *art_node256_create(const art_key_chunk_t prefix[],
+static art_node256_t *art_node256_create(art_t *art,
+                                         const art_key_chunk_t prefix[],
                                          uint8_t prefix_size);
 
-static art_node_t *art_node4_insert(art_node4_t *node, art_node_t *child,
-                                    uint8_t key);
-static art_node_t *art_node16_insert(art_node16_t *node, art_node_t *child,
-                                     uint8_t key);
-static art_node_t *art_node48_insert(art_node48_t *node, art_node_t *child,
-                                     uint8_t key);
-static art_node_t *art_node256_insert(art_node256_t *node, art_node_t *child,
-                                      uint8_t key);
+static art_ref_t art_node4_insert(art_t *art, art_node4_t *node,
+                                  art_ref_t child, uint8_t key);
+static art_ref_t art_node16_insert(art_t *art, art_node16_t *node,
+                                   art_ref_t child, uint8_t key);
+static art_ref_t art_node48_insert(art_t *art, art_node48_t *node,
+                                   art_ref_t child, uint8_t key);
+static art_ref_t art_node256_insert(art_t *art, art_node256_t *node,
+                                    art_ref_t child, uint8_t key);
 
-static art_node4_t *art_node4_create(const art_key_chunk_t prefix[],
+static art_node4_t *art_node4_create(art_t *art, const art_key_chunk_t prefix[],
                                      uint8_t prefix_size) {
-    art_node4_t *node = (art_node4_t *)roaring_malloc(sizeof(art_node4_t));
-    art_init_inner_node(&node->base, CROARING_ART_NODE4_TYPE, prefix,
-                        prefix_size);
+    uint64_t index = art_allocate_index(art, CROARING_ART_NODE4_TYPE);
+    art_node4_t *node =
+        ((art_node4_t *)art->nodes[CROARING_ART_NODE4_TYPE]) + index;
+    art_init_inner_node(&node->base, prefix, prefix_size);
     node->count = 0;
     return node;
 }
 
-static void art_free_node4(art_node4_t *node) {
-    for (size_t i = 0; i < node->count; ++i) {
-        art_free_node(node->children[i]);
-    }
-    roaring_free(node);
+static inline void art_node4_clear(art_node4_t *node, art_ref_t next_free) {
+    node->count = 0;
+    node->next_free = next_free;
 }
 
-static inline art_node_t *art_node4_find_child(const art_node4_t *node,
-                                               art_key_chunk_t key) {
+static inline art_ref_t art_node4_find_child(const art_node4_t *node,
+                                             art_key_chunk_t key) {
     for (size_t i = 0; i < node->count; ++i) {
         if (node->keys[i] == key) {
             return node->children[i];
         }
     }
-    return NULL;
+    return CROARING_ART_NULL_REF;
 }
 
-static art_node_t *art_node4_insert(art_node4_t *node, art_node_t *child,
-                                    uint8_t key) {
+static art_ref_t art_node4_insert(art_t *art, art_node4_t *node,
+                                  art_ref_t child, uint8_t key) {
     if (node->count < 4) {
         size_t idx = 0;
         for (; idx < node->count; ++idx) {
@@ -199,26 +301,26 @@ static art_node_t *art_node4_insert(art_node4_t *node, art_node_t *child,
         memmove(node->keys + idx + 1, node->keys + idx,
                 after * sizeof(art_key_chunk_t));
         memmove(node->children + idx + 1, node->children + idx,
-                after * sizeof(art_node_t *));
+                after * sizeof(art_ref_t));
 
         node->children[idx] = child;
         node->keys[idx] = key;
         node->count++;
-        return (art_node_t *)node;
+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE4_TYPE);
     }
     art_node16_t *new_node =
-        art_node16_create(node->base.prefix, node->base.prefix_size);
+        art_node16_create(art, node->base.prefix, node->base.prefix_size);
     // Instead of calling insert, this could be specialized to 2x memcpy and
     // setting the count.
     for (size_t i = 0; i < 4; ++i) {
-        art_node16_insert(new_node, node->children[i], node->keys[i]);
+        art_node16_insert(art, new_node, node->children[i], node->keys[i]);
     }
-    roaring_free(node);
-    return art_node16_insert(new_node, child, key);
+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE4_TYPE);
+    return art_node16_insert(art, new_node, child, key);
 }
 
-static inline art_node_t *art_node4_erase(art_node4_t *node,
-                                          art_key_chunk_t key_chunk) {
+static inline art_ref_t art_node4_erase(art_t *art, art_node4_t *node,
+                                        art_key_chunk_t key_chunk) {
     int idx = -1;
     for (size_t i = 0; i < node->count; ++i) {
         if (node->keys[i] == key_chunk) {
@@ -226,17 +328,18 @@ static inline art_node_t *art_node4_erase(art_node4_t *node,
         }
     }
     if (idx == -1) {
-        return (art_node_t *)node;
+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE4_TYPE);
     }
     if (node->count == 2) {
         // Only one child remains after erasing, so compress the path by
         // removing this node.
         uint8_t other_idx = idx ^ 1;
-        art_node_t *remaining_child = node->children[other_idx];
+        art_ref_t remaining_child = node->children[other_idx];
         art_key_chunk_t remaining_child_key = node->keys[other_idx];
         if (!art_is_leaf(remaining_child)) {
             // Correct the prefix of the child node.
-            art_inner_node_t *inner_node = (art_inner_node_t *)remaining_child;
+            art_inner_node_t *inner_node =
+                (art_inner_node_t *)art_deref(art, remaining_child);
             memmove(inner_node->prefix + node->base.prefix_size + 1,
                     inner_node->prefix, inner_node->prefix_size);
             memcpy(inner_node->prefix, node->base.prefix,
@@ -244,7 +347,7 @@ static inline art_node_t *art_node4_erase(art_node4_t *node,
             inner_node->prefix[node->base.prefix_size] = remaining_child_key;
             inner_node->prefix_size += node->base.prefix_size + 1;
         }
-        roaring_free(node);
+        art_node_free(art, (art_node_t *)node, CROARING_ART_NODE4_TYPE);
         return remaining_child;
     }
     // Shift other keys to maintain sorted order.
@@ -252,14 +355,14 @@ static inline art_node_t *art_node4_erase(art_node4_t *node,
     memmove(node->keys + idx, node->keys + idx + 1,
             after_next * sizeof(art_key_chunk_t));
     memmove(node->children + idx, node->children + idx + 1,
-            after_next * sizeof(art_node_t *));
+            after_next * sizeof(art_ref_t));
     node->count--;
-    return (art_node_t *)node;
+    return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE4_TYPE);
 }
 
 static inline void art_node4_replace(art_node4_t *node,
                                      art_key_chunk_t key_chunk,
-                                     art_node_t *new_child) {
+                                     art_ref_t new_child) {
     for (size_t i = 0; i < node->count; ++i) {
         if (node->keys[i] == key_chunk) {
             node->children[i] = new_child;
@@ -273,7 +376,7 @@ static inline art_indexed_child_t art_node4_next_child(const art_node4_t *node,
     art_indexed_child_t indexed_child;
     index++;
     if (index >= node->count) {
-        indexed_child.child = NULL;
+        indexed_child.child = CROARING_ART_NULL_REF;
         return indexed_child;
     }
     indexed_child.index = index;
@@ -290,7 +393,7 @@ static inline art_indexed_child_t art_node4_prev_child(const art_node4_t *node,
     index--;
     art_indexed_child_t indexed_child;
     if (index < 0) {
-        indexed_child.child = NULL;
+        indexed_child.child = CROARING_ART_NULL_REF;
         return indexed_child;
     }
     indexed_child.index = index;
@@ -303,7 +406,7 @@ static inline art_indexed_child_t art_node4_child_at(const art_node4_t *node,
                                                      int index) {
     art_indexed_child_t indexed_child;
     if (index < 0 || index >= node->count) {
-        indexed_child.child = NULL;
+        indexed_child.child = CROARING_ART_NULL_REF;
         return indexed_child;
     }
     indexed_child.index = index;
@@ -323,14 +426,15 @@ static inline art_indexed_child_t art_node4_lower_bound(
             return indexed_child;
         }
     }
-    indexed_child.child = NULL;
+    indexed_child.child = CROARING_ART_NULL_REF;
     return indexed_child;
 }
 
-static bool art_internal_validate_at(const art_node_t *node,
+static bool art_internal_validate_at(const art_t *art, art_ref_t ref,
                                      art_internal_validate_t validator);
 
-static bool art_node4_internal_validate(const art_node4_t *node,
+static bool art_node4_internal_validate(const art_t *art,
+                                        const art_node4_t *node,
                                         art_internal_validate_t validator) {
     if (node->count == 0) {
         return art_validate_fail(&validator, "Node4 has no children");
@@ -357,41 +461,41 @@ static bool art_node4_internal_validate(const art_node4_t *node,
             }
         }
         validator.current_key[validator.depth - 1] = node->keys[i];
-        if (!art_internal_validate_at(node->children[i], validator)) {
+        if (!art_internal_validate_at(art, node->children[i], validator)) {
             return false;
         }
     }
     return true;
 }
 
-static art_node16_t *art_node16_create(const art_key_chunk_t prefix[],
+static art_node16_t *art_node16_create(art_t *art,
+                                       const art_key_chunk_t prefix[],
                                        uint8_t prefix_size) {
-    art_node16_t *node = (art_node16_t *)roaring_malloc(sizeof(art_node16_t));
-    art_init_inner_node(&node->base, CROARING_ART_NODE16_TYPE, prefix,
-                        prefix_size);
+    uint64_t index = art_allocate_index(art, CROARING_ART_NODE16_TYPE);
+    art_node16_t *node =
+        ((art_node16_t *)art->nodes[CROARING_ART_NODE16_TYPE]) + index;
+    art_init_inner_node(&node->base, prefix, prefix_size);
     node->count = 0;
     return node;
 }
 
-static void art_free_node16(art_node16_t *node) {
-    for (size_t i = 0; i < node->count; ++i) {
-        art_free_node(node->children[i]);
-    }
-    roaring_free(node);
+static inline void art_node16_clear(art_node16_t *node, art_ref_t next_free) {
+    node->count = 0;
+    node->next_free = next_free;
 }
 
-static inline art_node_t *art_node16_find_child(const art_node16_t *node,
-                                                art_key_chunk_t key) {
+static inline art_ref_t art_node16_find_child(const art_node16_t *node,
+                                              art_key_chunk_t key) {
     for (size_t i = 0; i < node->count; ++i) {
         if (node->keys[i] == key) {
             return node->children[i];
         }
     }
-    return NULL;
+    return CROARING_ART_NULL_REF;
 }
 
-static art_node_t *art_node16_insert(art_node16_t *node, art_node_t *child,
-                                     uint8_t key) {
+static art_ref_t art_node16_insert(art_t *art, art_node16_t *node,
+                                   art_ref_t child, uint8_t key) {
     if (node->count < 16) {
         size_t idx = 0;
         for (; idx < node->count; ++idx) {
@@ -404,24 +508,24 @@ static art_node_t *art_node16_insert(art_node16_t *node, art_node_t *child,
         memmove(node->keys + idx + 1, node->keys + idx,
                 after * sizeof(art_key_chunk_t));
         memmove(node->children + idx + 1, node->children + idx,
-                after * sizeof(art_node_t *));
+                after * sizeof(art_ref_t));
 
         node->children[idx] = child;
         node->keys[idx] = key;
         node->count++;
-        return (art_node_t *)node;
+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE16_TYPE);
     }
     art_node48_t *new_node =
-        art_node48_create(node->base.prefix, node->base.prefix_size);
+        art_node48_create(art, node->base.prefix, node->base.prefix_size);
     for (size_t i = 0; i < 16; ++i) {
-        art_node48_insert(new_node, node->children[i], node->keys[i]);
+        art_node48_insert(art, new_node, node->children[i], node->keys[i]);
     }
-    roaring_free(node);
-    return art_node48_insert(new_node, child, key);
+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE16_TYPE);
+    return art_node48_insert(art, new_node, child, key);
 }
 
-static inline art_node_t *art_node16_erase(art_node16_t *node,
-                                           uint8_t key_chunk) {
+static inline art_ref_t art_node16_erase(art_t *art, art_node16_t *node,
+                                         uint8_t key_chunk) {
     for (size_t i = 0; i < node->count; ++i) {
         if (node->keys[i] == key_chunk) {
             // Shift other keys to maintain sorted order.
@@ -429,28 +533,28 @@ static inline art_node_t *art_node16_erase(art_node16_t *node,
             memmove(node->keys + i, node->keys + i + 1,
                     after_next * sizeof(key_chunk));
             memmove(node->children + i, node->children + i + 1,
-                    after_next * sizeof(art_node_t *));
+                    after_next * sizeof(art_ref_t));
             node->count--;
             break;
         }
     }
     if (node->count > 4) {
-        return (art_node_t *)node;
+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE16_TYPE);
     }
     art_node4_t *new_node =
-        art_node4_create(node->base.prefix, node->base.prefix_size);
+        art_node4_create(art, node->base.prefix, node->base.prefix_size);
     // Instead of calling insert, this could be specialized to 2x memcpy and
     // setting the count.
     for (size_t i = 0; i < 4; ++i) {
-        art_node4_insert(new_node, node->children[i], node->keys[i]);
+        art_node4_insert(art, new_node, node->children[i], node->keys[i]);
     }
-    roaring_free(node);
-    return (art_node_t *)new_node;
+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE16_TYPE);
+    return art_get_ref(art, (art_node_t *)new_node, CROARING_ART_NODE4_TYPE);
 }
 
 static inline void art_node16_replace(art_node16_t *node,
                                       art_key_chunk_t key_chunk,
-                                      art_node_t *new_child) {
+                                      art_ref_t new_child) {
     for (uint8_t i = 0; i < node->count; ++i) {
         if (node->keys[i] == key_chunk) {
             node->children[i] = new_child;
@@ -464,7 +568,7 @@ static inline art_indexed_child_t art_node16_next_child(
     art_indexed_child_t indexed_child;
     index++;
     if (index >= node->count) {
-        indexed_child.child = NULL;
+        indexed_child.child = CROARING_ART_NULL_REF;
         return indexed_child;
     }
     indexed_child.index = index;
@@ -481,7 +585,7 @@ static inline art_indexed_child_t art_node16_prev_child(
     index--;
     art_indexed_child_t indexed_child;
     if (index < 0) {
-        indexed_child.child = NULL;
+        indexed_child.child = CROARING_ART_NULL_REF;
         return indexed_child;
     }
     indexed_child.index = index;
@@ -494,7 +598,7 @@ static inline art_indexed_child_t art_node16_child_at(const art_node16_t *node,
                                                       int index) {
     art_indexed_child_t indexed_child;
     if (index < 0 || index >= node->count) {
-        indexed_child.child = NULL;
+        indexed_child.child = CROARING_ART_NULL_REF;
         return indexed_child;
     }
     indexed_child.index = index;
@@ -514,11 +618,12 @@ static inline art_indexed_child_t art_node16_lower_bound(
             return indexed_child;
         }
     }
-    indexed_child.child = NULL;
+    indexed_child.child = CROARING_ART_NULL_REF;
     return indexed_child;
 }
 
-static bool art_node16_internal_validate(const art_node16_t *node,
+static bool art_node16_internal_validate(const art_t *art,
+                                         const art_node16_t *node,
                                          art_internal_validate_t validator) {
     if (node->count <= 4) {
         return art_validate_fail(&validator, "Node16 has too few children");
@@ -541,18 +646,20 @@ static bool art_node16_internal_validate(const art_node16_t *node,
             }
         }
         validator.current_key[validator.depth - 1] = node->keys[i];
-        if (!art_internal_validate_at(node->children[i], validator)) {
+        if (!art_internal_validate_at(art, node->children[i], validator)) {
             return false;
         }
     }
     return true;
 }
 
-static art_node48_t *art_node48_create(const art_key_chunk_t prefix[],
+static art_node48_t *art_node48_create(art_t *art,
+                                       const art_key_chunk_t prefix[],
                                        uint8_t prefix_size) {
-    art_node48_t *node = (art_node48_t *)roaring_malloc(sizeof(art_node48_t));
-    art_init_inner_node(&node->base, CROARING_ART_NODE48_TYPE, prefix,
-                        prefix_size);
+    uint64_t index = art_allocate_index(art, CROARING_ART_NODE48_TYPE);
+    art_node48_t *node =
+        ((art_node48_t *)art->nodes[CROARING_ART_NODE48_TYPE]) + index;
+    art_init_inner_node(&node->base, prefix, prefix_size);
     node->count = 0;
     node->available_children = CROARING_NODE48_AVAILABLE_CHILDREN_MASK;
     for (size_t i = 0; i < 256; ++i) {
@@ -561,29 +668,22 @@ static art_node48_t *art_node48_create(const art_key_chunk_t prefix[],
     return node;
 }
 
-static void art_free_node48(art_node48_t *node) {
-    uint64_t used_children =
-        (node->available_children) ^ CROARING_NODE48_AVAILABLE_CHILDREN_MASK;
-    while (used_children != 0) {
-        // We checked above that used_children is not zero
-        uint8_t child_idx = roaring_trailing_zeroes(used_children);
-        art_free_node(node->children[child_idx]);
-        used_children &= ~(UINT64_C(1) << child_idx);
-    }
-    roaring_free(node);
+static inline void art_node48_clear(art_node48_t *node, art_ref_t next_free) {
+    node->count = 0;
+    node->next_free = next_free;
 }
 
-static inline art_node_t *art_node48_find_child(const art_node48_t *node,
-                                                art_key_chunk_t key) {
+static inline art_ref_t art_node48_find_child(const art_node48_t *node,
+                                              art_key_chunk_t key) {
     uint8_t val_idx = node->keys[key];
     if (val_idx != CROARING_ART_NODE48_EMPTY_VAL) {
         return node->children[val_idx];
     }
-    return NULL;
+    return CROARING_ART_NULL_REF;
 }
 
-static art_node_t *art_node48_insert(art_node48_t *node, art_node_t *child,
-                                     uint8_t key) {
+static art_ref_t art_node48_insert(art_t *art, art_node48_t *node,
+                                   art_ref_t child, uint8_t key) {
     if (node->count < 48) {
         // node->available_children is only zero when the node is full (count ==
         // 48), we just checked count < 48
@@ -592,48 +692,48 @@ static art_node_t *art_node48_insert(art_node48_t *node, art_node_t *child,
         node->children[val_idx] = child;
         node->count++;
         node->available_children &= ~(UINT64_C(1) << val_idx);
-        return (art_node_t *)node;
+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE48_TYPE);
     }
     art_node256_t *new_node =
-        art_node256_create(node->base.prefix, node->base.prefix_size);
+        art_node256_create(art, node->base.prefix, node->base.prefix_size);
     for (size_t i = 0; i < 256; ++i) {
         uint8_t val_idx = node->keys[i];
         if (val_idx != CROARING_ART_NODE48_EMPTY_VAL) {
-            art_node256_insert(new_node, node->children[val_idx], i);
+            art_node256_insert(art, new_node, node->children[val_idx], i);
         }
     }
-    roaring_free(node);
-    return art_node256_insert(new_node, child, key);
+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE48_TYPE);
+    return art_node256_insert(art, new_node, child, key);
 }
 
-static inline art_node_t *art_node48_erase(art_node48_t *node,
-                                           uint8_t key_chunk) {
+static inline art_ref_t art_node48_erase(art_t *art, art_node48_t *node,
+                                         uint8_t key_chunk) {
     uint8_t val_idx = node->keys[key_chunk];
     if (val_idx == CROARING_ART_NODE48_EMPTY_VAL) {
-        return (art_node_t *)node;
+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE48_TYPE);
     }
     node->keys[key_chunk] = CROARING_ART_NODE48_EMPTY_VAL;
     node->available_children |= UINT64_C(1) << val_idx;
     node->count--;
     if (node->count > 16) {
-        return (art_node_t *)node;
+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE48_TYPE);
     }
 
     art_node16_t *new_node =
-        art_node16_create(node->base.prefix, node->base.prefix_size);
+        art_node16_create(art, node->base.prefix, node->base.prefix_size);
     for (size_t i = 0; i < 256; ++i) {
         val_idx = node->keys[i];
         if (val_idx != CROARING_ART_NODE48_EMPTY_VAL) {
-            art_node16_insert(new_node, node->children[val_idx], i);
+            art_node16_insert(art, new_node, node->children[val_idx], i);
         }
     }
-    roaring_free(node);
-    return (art_node_t *)new_node;
+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE48_TYPE);
+    return art_get_ref(art, (art_node_t *)new_node, CROARING_ART_NODE16_TYPE);
 }
 
 static inline void art_node48_replace(art_node48_t *node,
                                       art_key_chunk_t key_chunk,
-                                      art_node_t *new_child) {
+                                      art_ref_t new_child) {
     uint8_t val_idx = node->keys[key_chunk];
     assert(val_idx != CROARING_ART_NODE48_EMPTY_VAL);
     node->children[val_idx] = new_child;
@@ -651,7 +751,7 @@ static inline art_indexed_child_t art_node48_next_child(
             return indexed_child;
         }
     }
-    indexed_child.child = NULL;
+    indexed_child.child = CROARING_ART_NULL_REF;
     return indexed_child;
 }
 
@@ -670,7 +770,7 @@ static inline art_indexed_child_t art_node48_prev_child(
             return indexed_child;
         }
     }
-    indexed_child.child = NULL;
+    indexed_child.child = CROARING_ART_NULL_REF;
     return indexed_child;
 }
 
@@ -678,7 +778,7 @@ static inline art_indexed_child_t art_node48_child_at(const art_node48_t *node,
                                                       int index) {
     art_indexed_child_t indexed_child;
     if (index < 0 || index >= 256) {
-        indexed_child.child = NULL;
+        indexed_child.child = CROARING_ART_NULL_REF;
         return indexed_child;
     }
     indexed_child.index = index;
@@ -698,11 +798,12 @@ static inline art_indexed_child_t art_node48_lower_bound(
             return indexed_child;
         }
     }
-    indexed_child.child = NULL;
+    indexed_child.child = CROARING_ART_NULL_REF;
     return indexed_child;
 }
 
-static bool art_node48_internal_validate(const art_node48_t *node,
+static bool art_node48_internal_validate(const art_t *art,
+                                         const art_node48_t *node,
                                          art_internal_validate_t validator) {
     if (node->count <= 16) {
         return art_validate_fail(&validator, "Node48 has too few children");
@@ -719,8 +820,8 @@ static bool art_node48_internal_validate(const art_node48_t *node,
                     &validator, "Node48 keys point to the same child index");
             }
 
-            art_node_t *child = node->children[child_idx];
-            if (child == NULL) {
+            art_ref_t child = node->children[child_idx];
+            if (child == CROARING_ART_NULL_REF) {
                 return art_validate_fail(&validator, "Node48 has a NULL child");
             }
             used_children |= UINT64_C(1) << child_idx;
@@ -752,7 +853,7 @@ static bool art_node48_internal_validate(const art_node48_t *node,
     for (int i = 0; i < 256; ++i) {
         if (node->keys[i] != CROARING_ART_NODE48_EMPTY_VAL) {
             validator.current_key[validator.depth - 1] = i;
-            if (!art_internal_validate_at(node->children[node->keys[i]],
+            if (!art_internal_validate_at(art, node->children[node->keys[i]],
                                           validator)) {
                 return false;
             }
@@ -761,62 +862,59 @@ static bool art_node48_internal_validate(const art_node48_t *node,
     return true;
 }
 
-static art_node256_t *art_node256_create(const art_key_chunk_t prefix[],
+static art_node256_t *art_node256_create(art_t *art,
+                                         const art_key_chunk_t prefix[],
                                          uint8_t prefix_size) {
+    uint64_t index = art_allocate_index(art, CROARING_ART_NODE256_TYPE);
     art_node256_t *node =
-        (art_node256_t *)roaring_malloc(sizeof(art_node256_t));
-    art_init_inner_node(&node->base, CROARING_ART_NODE256_TYPE, prefix,
-                        prefix_size);
+        ((art_node256_t *)art->nodes[CROARING_ART_NODE256_TYPE]) + index;
+    art_init_inner_node(&node->base, prefix, prefix_size);
     node->count = 0;
     for (size_t i = 0; i < 256; ++i) {
-        node->children[i] = NULL;
+        node->children[i] = CROARING_ART_NULL_REF;
     }
     return node;
 }
 
-static void art_free_node256(art_node256_t *node) {
-    for (size_t i = 0; i < 256; ++i) {
-        if (node->children[i] != NULL) {
-            art_free_node(node->children[i]);
-        }
-    }
-    roaring_free(node);
+static inline void art_node256_clear(art_node256_t *node, art_ref_t next_free) {
+    node->count = 0;
+    node->next_free = next_free;
 }
 
-static inline art_node_t *art_node256_find_child(const art_node256_t *node,
-                                                 art_key_chunk_t key) {
+static inline art_ref_t art_node256_find_child(const art_node256_t *node,
+                                               art_key_chunk_t key) {
     return node->children[key];
 }
 
-static art_node_t *art_node256_insert(art_node256_t *node, art_node_t *child,
-                                      uint8_t key) {
+static art_ref_t art_node256_insert(art_t *art, art_node256_t *node,
+                                    art_ref_t child, uint8_t key) {
     node->children[key] = child;
     node->count++;
-    return (art_node_t *)node;
+    return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE256_TYPE);
 }
 
-static inline art_node_t *art_node256_erase(art_node256_t *node,
-                                            uint8_t key_chunk) {
-    node->children[key_chunk] = NULL;
+static inline art_ref_t art_node256_erase(art_t *art, art_node256_t *node,
+                                          uint8_t key_chunk) {
+    node->children[key_chunk] = CROARING_ART_NULL_REF;
     node->count--;
     if (node->count > 48) {
-        return (art_node_t *)node;
+        return art_get_ref(art, (art_node_t *)node, CROARING_ART_NODE256_TYPE);
     }
 
     art_node48_t *new_node =
-        art_node48_create(node->base.prefix, node->base.prefix_size);
+        art_node48_create(art, node->base.prefix, node->base.prefix_size);
     for (size_t i = 0; i < 256; ++i) {
-        if (node->children[i] != NULL) {
-            art_node48_insert(new_node, node->children[i], i);
+        if (node->children[i] != CROARING_ART_NULL_REF) {
+            art_node48_insert(art, new_node, node->children[i], i);
         }
     }
-    roaring_free(node);
-    return (art_node_t *)new_node;
+    art_node_free(art, (art_node_t *)node, CROARING_ART_NODE256_TYPE);
+    return art_get_ref(art, (art_node_t *)new_node, CROARING_ART_NODE48_TYPE);
 }
 
 static inline void art_node256_replace(art_node256_t *node,
                                        art_key_chunk_t key_chunk,
-                                       art_node_t *new_child) {
+                                       art_ref_t new_child) {
     node->children[key_chunk] = new_child;
 }
 
@@ -825,14 +923,14 @@ static inline art_indexed_child_t art_node256_next_child(
     art_indexed_child_t indexed_child;
     index++;
     for (size_t i = index; i < 256; ++i) {
-        if (node->children[i] != NULL) {
+        if (node->children[i] != CROARING_ART_NULL_REF) {
             indexed_child.index = i;
             indexed_child.child = node->children[i];
             indexed_child.key_chunk = i;
             return indexed_child;
         }
     }
-    indexed_child.child = NULL;
+    indexed_child.child = CROARING_ART_NULL_REF;
     return indexed_child;
 }
 
@@ -844,14 +942,14 @@ static inline art_indexed_child_t art_node256_prev_child(
     index--;
     art_indexed_child_t indexed_child;
     for (int i = index; i >= 0; --i) {
-        if (node->children[i] != NULL) {
+        if (node->children[i] != CROARING_ART_NULL_REF) {
             indexed_child.index = i;
             indexed_child.child = node->children[i];
             indexed_child.key_chunk = i;
             return indexed_child;
         }
     }
-    indexed_child.child = NULL;
+    indexed_child.child = CROARING_ART_NULL_REF;
     return indexed_child;
 }
 
@@ -859,7 +957,7 @@ static inline art_indexed_child_t art_node256_child_at(
     const art_node256_t *node, int index) {
     art_indexed_child_t indexed_child;
     if (index < 0 || index >= 256) {
-        indexed_child.child = NULL;
+        indexed_child.child = CROARING_ART_NULL_REF;
         return indexed_child;
     }
     indexed_child.index = index;
@@ -872,18 +970,19 @@ static inline art_indexed_child_t art_node256_lower_bound(
     art_node256_t *node, art_key_chunk_t key_chunk) {
     art_indexed_child_t indexed_child;
     for (size_t i = key_chunk; i < 256; ++i) {
-        if (node->children[i] != NULL) {
+        if (node->children[i] != CROARING_ART_NULL_REF) {
             indexed_child.index = i;
             indexed_child.child = node->children[i];
             indexed_child.key_chunk = i;
             return indexed_child;
         }
     }
-    indexed_child.child = NULL;
+    indexed_child.child = CROARING_ART_NULL_REF;
     return indexed_child;
 }
 
-static bool art_node256_internal_validate(const art_node256_t *node,
+static bool art_node256_internal_validate(const art_t *art,
+                                          const art_node256_t *node,
                                           art_internal_validate_t validator) {
     if (node->count <= 48) {
         return art_validate_fail(&validator, "Node256 has too few children");
@@ -894,7 +993,7 @@ static bool art_node256_internal_validate(const art_node256_t *node,
     validator.depth++;
     int actual_count = 0;
     for (int i = 0; i < 256; ++i) {
-        if (node->children[i] != NULL) {
+        if (node->children[i] != CROARING_ART_NULL_REF) {
             actual_count++;
 
             for (int j = i + 1; j < 256; ++j) {
@@ -905,7 +1004,7 @@ static bool art_node256_internal_validate(const art_node256_t *node,
             }
 
             validator.current_key[validator.depth - 1] = i;
-            if (!art_internal_validate_at(node->children[i], validator)) {
+            if (!art_internal_validate_at(art, node->children[i], validator)) {
                 return false;
             }
         }
@@ -919,9 +1018,10 @@ static bool art_node256_internal_validate(const art_node256_t *node,
 
 // Finds the child with the given key chunk in the inner node, returns NULL if
 // no such child is found.
-static art_node_t *art_find_child(const art_inner_node_t *node,
-                                  art_key_chunk_t key_chunk) {
-    switch (art_get_type(node)) {
+static art_ref_t art_find_child(const art_inner_node_t *node,
+                                art_typecode_t typecode,
+                                art_key_chunk_t key_chunk) {
+    switch (typecode) {
         case CROARING_ART_NODE4_TYPE:
             return art_node4_find_child((art_node4_t *)node, key_chunk);
         case CROARING_ART_NODE16_TYPE:
@@ -932,14 +1032,14 @@ static art_node_t *art_find_child(const art_inner_node_t *node,
             return art_node256_find_child((art_node256_t *)node, key_chunk);
         default:
             assert(false);
-            return NULL;
+            return CROARING_ART_NULL_REF;
     }
 }
 
 // Replaces the child with the given key chunk in the inner node.
-static void art_replace(art_inner_node_t *node, art_key_chunk_t key_chunk,
-                        art_node_t *new_child) {
-    switch (art_get_type(node)) {
+static void art_replace(art_inner_node_t *node, art_typecode_t typecode,
+                        art_key_chunk_t key_chunk, art_ref_t new_child) {
+    switch (typecode) {
         case CROARING_ART_NODE4_TYPE:
             art_node4_replace((art_node4_t *)node, key_chunk, new_child);
             break;
@@ -959,78 +1059,112 @@ static void art_replace(art_inner_node_t *node, art_key_chunk_t key_chunk,
 
 // Erases the child with the given key chunk from the inner node, returns the
 // updated node (the same as the initial node if it was not shrunk).
-static art_node_t *art_node_erase(art_inner_node_t *node,
-                                  art_key_chunk_t key_chunk) {
-    switch (art_get_type(node)) {
+static art_ref_t art_node_erase(art_t *art, art_inner_node_t *node,
+                                art_typecode_t typecode,
+                                art_key_chunk_t key_chunk) {
+    switch (typecode) {
         case CROARING_ART_NODE4_TYPE:
-            return art_node4_erase((art_node4_t *)node, key_chunk);
+            return art_node4_erase(art, (art_node4_t *)node, key_chunk);
         case CROARING_ART_NODE16_TYPE:
-            return art_node16_erase((art_node16_t *)node, key_chunk);
+            return art_node16_erase(art, (art_node16_t *)node, key_chunk);
         case CROARING_ART_NODE48_TYPE:
-            return art_node48_erase((art_node48_t *)node, key_chunk);
+            return art_node48_erase(art, (art_node48_t *)node, key_chunk);
         case CROARING_ART_NODE256_TYPE:
-            return art_node256_erase((art_node256_t *)node, key_chunk);
+            return art_node256_erase(art, (art_node256_t *)node, key_chunk);
         default:
             assert(false);
-            return NULL;
+            return CROARING_ART_NULL_REF;
     }
 }
 
 // Inserts the leaf with the given key chunk in the inner node, returns a
 // pointer to the (possibly expanded) node.
-static art_node_t *art_node_insert_leaf(art_inner_node_t *node,
-                                        art_key_chunk_t key_chunk,
-                                        art_leaf_t *leaf) {
-    art_node_t *child = (art_node_t *)(CROARING_SET_LEAF(leaf));
-    switch (art_get_type(node)) {
+static art_ref_t art_node_insert_leaf(art_t *art, art_inner_node_t *node,
+                                      art_typecode_t typecode,
+                                      art_key_chunk_t key_chunk,
+                                      art_ref_t leaf) {
+    switch (typecode) {
         case CROARING_ART_NODE4_TYPE:
-            return art_node4_insert((art_node4_t *)node, child, key_chunk);
+            return art_node4_insert(art, (art_node4_t *)node, leaf, key_chunk);
         case CROARING_ART_NODE16_TYPE:
-            return art_node16_insert((art_node16_t *)node, child, key_chunk);
+            return art_node16_insert(art, (art_node16_t *)node, leaf,
+                                     key_chunk);
         case CROARING_ART_NODE48_TYPE:
-            return art_node48_insert((art_node48_t *)node, child, key_chunk);
+            return art_node48_insert(art, (art_node48_t *)node, leaf,
+                                     key_chunk);
         case CROARING_ART_NODE256_TYPE:
-            return art_node256_insert((art_node256_t *)node, child, key_chunk);
+            return art_node256_insert(art, (art_node256_t *)node, leaf,
+                                      key_chunk);
         default:
             assert(false);
-            return NULL;
+            return CROARING_ART_NULL_REF;
     }
 }
 
-// Frees the node and its children. Leaves are freed by the user.
-static void art_free_node(art_node_t *node) {
-    if (art_is_leaf(node)) {
-        // We leave it up to the user to free leaves.
-        return;
+static uint64_t art_node_get_next_free(const art_t *art, art_ref_t ref) {
+    art_node_t *node = art_deref(art, ref);
+    art_typecode_t typecode = art_ref_typecode(ref);
+    switch (typecode) {
+        case CROARING_ART_LEAF_TYPE:
+            return ((art_leaf_t *)node)->next_free;
+        case CROARING_ART_NODE4_TYPE:
+            return ((art_node4_t *)node)->next_free;
+        case CROARING_ART_NODE16_TYPE:
+            return ((art_node16_t *)node)->next_free;
+        case CROARING_ART_NODE48_TYPE:
+            return ((art_node48_t *)node)->next_free;
+        case CROARING_ART_NODE256_TYPE:
+            return ((art_node256_t *)node)->next_free;
+        default:
+            assert(false);
+            return 0;
     }
-    switch (art_get_type((art_inner_node_t *)node)) {
+}
+
+static void art_node_set_next_free(art_node_t *node, art_typecode_t typecode,
+                                   uint64_t next_free) {
+    switch (typecode) {
+        case CROARING_ART_LEAF_TYPE:
+            ((art_leaf_t *)node)->next_free = next_free;
+            break;
         case CROARING_ART_NODE4_TYPE:
-            art_free_node4((art_node4_t *)node);
+            ((art_node4_t *)node)->next_free = next_free;
             break;
         case CROARING_ART_NODE16_TYPE:
-            art_free_node16((art_node16_t *)node);
+            ((art_node16_t *)node)->next_free = next_free;
             break;
         case CROARING_ART_NODE48_TYPE:
-            art_free_node48((art_node48_t *)node);
+            ((art_node48_t *)node)->next_free = next_free;
             break;
         case CROARING_ART_NODE256_TYPE:
-            art_free_node256((art_node256_t *)node);
+            ((art_node256_t *)node)->next_free = next_free;
             break;
         default:
             assert(false);
     }
 }
 
+// Marks the node as unoccopied and frees its index.
+static void art_node_free(art_t *art, art_node_t *node,
+                          art_typecode_t typecode) {
+    uint64_t index = art_get_index(art, node, typecode);
+    uint64_t next_free = art->first_free[typecode];
+    art_node_set_next_free(node, typecode, next_free);
+    art->first_free[typecode] = index;
+}
+
 // Returns the next child in key order, or NULL if called on a leaf.
 // Provided index may be in the range [-1, 255].
 static art_indexed_child_t art_node_next_child(const art_node_t *node,
+                                               art_typecode_t typecode,
                                                int index) {
-    if (art_is_leaf(node)) {
-        art_indexed_child_t indexed_child;
-        indexed_child.child = NULL;
-        return indexed_child;
-    }
-    switch (art_get_type((art_inner_node_t *)node)) {
+    switch (typecode) {
+        case CROARING_ART_LEAF_TYPE:
+            return (art_indexed_child_t){
+                .child = CROARING_ART_NULL_REF,
+                .index = 0,
+                .key_chunk = 0,
+            };
         case CROARING_ART_NODE4_TYPE:
             return art_node4_next_child((art_node4_t *)node, index);
         case CROARING_ART_NODE16_TYPE:
@@ -1048,13 +1182,15 @@ static art_indexed_child_t art_node_next_child(const art_node_t *node,
 // Returns the previous child in key order, or NULL if called on a leaf.
 // Provided index may be in the range [0, 256].
 static art_indexed_child_t art_node_prev_child(const art_node_t *node,
+                                               art_typecode_t typecode,
                                                int index) {
-    if (art_is_leaf(node)) {
-        art_indexed_child_t indexed_child;
-        indexed_child.child = NULL;
-        return indexed_child;
-    }
-    switch (art_get_type((art_inner_node_t *)node)) {
+    switch (typecode) {
+        case CROARING_ART_LEAF_TYPE:
+            return (art_indexed_child_t){
+                .child = CROARING_ART_NULL_REF,
+                .index = 0,
+                .key_chunk = 0,
+            };
         case CROARING_ART_NODE4_TYPE:
             return art_node4_prev_child((art_node4_t *)node, index);
         case CROARING_ART_NODE16_TYPE:
@@ -1069,16 +1205,19 @@ static art_indexed_child_t art_node_prev_child(const art_node_t *node,
     }
 }
 
-// Returns the child found at the provided index, or NULL if called on a leaf.
-// Provided index is only valid if returned by art_node_(next|prev)_child.
+// Returns the child found at the provided index, or NULL if called on a
+// leaf. Provided index is only valid if returned by
+// art_node_(next|prev)_child.
 static art_indexed_child_t art_node_child_at(const art_node_t *node,
+                                             art_typecode_t typecode,
                                              int index) {
-    if (art_is_leaf(node)) {
-        art_indexed_child_t indexed_child;
-        indexed_child.child = NULL;
-        return indexed_child;
-    }
-    switch (art_get_type((art_inner_node_t *)node)) {
+    switch (typecode) {
+        case CROARING_ART_LEAF_TYPE:
+            return (art_indexed_child_t){
+                .child = CROARING_ART_NULL_REF,
+                .index = 0,
+                .key_chunk = 0,
+            };
         case CROARING_ART_NODE4_TYPE:
             return art_node4_child_at((art_node4_t *)node, index);
         case CROARING_ART_NODE16_TYPE:
@@ -1093,16 +1232,18 @@ static art_indexed_child_t art_node_child_at(const art_node_t *node,
     }
 }
 
-// Returns the child with the smallest key equal to or greater than the given
-// key chunk, NULL if called on a leaf or no such child was found.
+// Returns the child with the smallest key equal to or greater than the
+// given key chunk, NULL if called on a leaf or no such child was found.
 static art_indexed_child_t art_node_lower_bound(const art_node_t *node,
+                                                art_typecode_t typecode,
                                                 art_key_chunk_t key_chunk) {
-    if (art_is_leaf(node)) {
-        art_indexed_child_t indexed_child;
-        indexed_child.child = NULL;
-        return indexed_child;
-    }
-    switch (art_get_type((art_inner_node_t *)node)) {
+    switch (typecode) {
+        case CROARING_ART_LEAF_TYPE:
+            return (art_indexed_child_t){
+                .child = CROARING_ART_NULL_REF,
+                .index = 0,
+                .key_chunk = 0,
+            };
         case CROARING_ART_NODE4_TYPE:
             return art_node4_lower_bound((art_node4_t *)node, key_chunk);
         case CROARING_ART_NODE16_TYPE:
@@ -1117,7 +1258,7 @@ static art_indexed_child_t art_node_lower_bound(const art_node_t *node,
     }
 }
 
-// ====================== End of node-specific functions =======================
+// ====================== End of node-specific functions ======================
 
 // Compares the given ranges of two keys, returns their relative order:
 // * Key range 1 <  key range 2: a negative value
@@ -1155,45 +1296,112 @@ static uint8_t art_common_prefix(const art_key_chunk_t key1[],
     return offset;
 }
 
-// Returns a pointer to the rootmost node where the value was inserted, may not
-// be equal to `node`.
-static art_node_t *art_insert_at(art_node_t *node, const art_key_chunk_t key[],
-                                 uint8_t depth, art_leaf_t *new_leaf) {
-    if (art_is_leaf(node)) {
-        art_leaf_t *leaf = CROARING_CAST_LEAF(node);
+/**
+ * Extends the array of nodes of the given typecode. Invalidates pointers into
+ * the array obtained by `art_deref`.
+ */
+static void art_extend(art_t *art, art_typecode_t typecode) {
+    uint64_t size = art->first_free[typecode];
+    uint64_t capacity = art->capacities[typecode];
+    if (size < capacity) {
+        return;
+    }
+    uint64_t new_capacity;
+    if (capacity == 0) {
+        new_capacity = 2;
+    } else if (capacity < 1024) {
+        new_capacity = 2 * capacity;
+    } else {
+        new_capacity = 5 * capacity / 4;
+    }
+    art->capacities[typecode] = new_capacity;
+    art->nodes[typecode] = roaring_realloc(
+        art->nodes[typecode], new_capacity * ART_NODE_SIZES[typecode]);
+    uint64_t increase = new_capacity - capacity;
+    memset(art_get_node(art, capacity, typecode), 0,
+           increase * ART_NODE_SIZES[typecode]);
+    for (uint64_t i = capacity; i < new_capacity; ++i) {
+        art_node_set_next_free(art_get_node(art, i, typecode), typecode, i + 1);
+    }
+}
+
+/**
+ * Returns the next free index for the given typecode, may be equal to the
+ * capacity of the array.
+ */
+static uint64_t art_next_free(const art_t *art, art_typecode_t typecode) {
+    uint64_t index = art->first_free[typecode];
+    return art_node_get_next_free(art, art_to_ref(index, typecode));
+}
+
+/**
+ * Marks an index for the given typecode as used, expanding the relevant node
+ * array if necessary.
+ */
+static uint64_t art_allocate_index(art_t *art, art_typecode_t typecode) {
+    uint64_t first_free = art->first_free[typecode];
+    if (first_free == art->capacities[typecode]) {
+        art_extend(art, typecode);
+        art->first_free[typecode]++;
+        return first_free;
+    }
+    art->first_free[typecode] = art_next_free(art, typecode);
+    return first_free;
+}
+
+// Returns a pointer to the rootmost node where the value was inserted, may
+// not be equal to `node`.
+static art_ref_t art_insert_at(art_t *art, art_ref_t ref,
+                               const art_key_chunk_t key[], uint8_t depth,
+                               art_ref_t new_leaf) {
+    if (art_is_leaf(ref)) {
+        art_leaf_t *leaf = (art_leaf_t *)art_deref(art, ref);
         uint8_t common_prefix = art_common_prefix(
             leaf->key, depth, ART_KEY_BYTES, key, depth, ART_KEY_BYTES);
 
-        // Previously this was a leaf, create an inner node instead and add both
-        // the existing and new leaf to it.
+        // Previously this was a leaf, create an inner node instead and add
+        // both the existing and new leaf to it.
         art_node_t *new_node =
-            (art_node_t *)art_node4_create(key + depth, common_prefix);
+            (art_node_t *)art_node4_create(art, key + depth, common_prefix);
 
-        new_node = art_node_insert_leaf((art_inner_node_t *)new_node,
-                                        leaf->key[depth + common_prefix], leaf);
-        new_node = art_node_insert_leaf((art_inner_node_t *)new_node,
-                                        key[depth + common_prefix], new_leaf);
+        art_ref_t new_ref = art_node_insert_leaf(
+            art, (art_inner_node_t *)new_node, CROARING_ART_NODE4_TYPE,
+            leaf->key[depth + common_prefix], ref);
+        new_ref = art_node_insert_leaf(art, (art_inner_node_t *)new_node,
+                                       CROARING_ART_NODE4_TYPE,
+                                       key[depth + common_prefix], new_leaf);
 
         // The new inner node is now the rootmost node.
-        return new_node;
+        return new_ref;
     }
-    art_inner_node_t *inner_node = (art_inner_node_t *)node;
+    art_inner_node_t *inner_node = (art_inner_node_t *)art_deref(art, ref);
     // Not a leaf: inner node
     uint8_t common_prefix =
         art_common_prefix(inner_node->prefix, 0, inner_node->prefix_size, key,
                           depth, ART_KEY_BYTES);
     if (common_prefix != inner_node->prefix_size) {
-        // Partial prefix match.  Create a new internal node to hold the common
+        // Partial prefix match. Create a new internal node to hold the common
         // prefix.
-        art_node4_t *node4 =
-            art_node4_create(inner_node->prefix, common_prefix);
+        // We create a copy of the node's prefix as the creation of a new
+        // node may invalidate the prefix pointer.
+        art_key_chunk_t *prefix_copy = (art_key_chunk_t *)roaring_malloc(
+            common_prefix * sizeof(art_key_chunk_t));
+        memcpy(prefix_copy, inner_node->prefix,
+               common_prefix * sizeof(art_key_chunk_t));
+        art_node4_t *node4 = art_node4_create(art, prefix_copy, common_prefix);
+        roaring_free(prefix_copy);
+
+        // Deref as a new node was created.
+        inner_node = (art_inner_node_t *)art_deref(art, ref);
 
         // Make the existing internal node a child of the new internal node.
-        node4 = (art_node4_t *)art_node4_insert(
-            node4, node, inner_node->prefix[common_prefix]);
+        art_node4_insert(art, node4, ref, inner_node->prefix[common_prefix]);
 
-        // Correct the prefix of the moved internal node, trimming off the chunk
-        // inserted into the new internal node.
+        // Deref again as a new node was created.
+        inner_node = (art_inner_node_t *)art_deref(art, ref);
+
+        // Correct the prefix of the moved internal node, trimming off the
+        // chunk inserted into the new internal node.
         inner_node->prefix_size = inner_node->prefix_size - common_prefix - 1;
         if (inner_node->prefix_size > 0) {
             // Move the remaining prefix to the correct position.
@@ -1202,55 +1410,67 @@ static art_node_t *art_insert_at(art_node_t *node, const art_key_chunk_t key[],
         }
 
         // Insert the value in the new internal node.
-        return art_node_insert_leaf(&node4->base, key[common_prefix + depth],
-                                    new_leaf);
+        return art_node_insert_leaf(art, (art_inner_node_t *)node4,
+                                    CROARING_ART_NODE4_TYPE,
+                                    key[common_prefix + depth], new_leaf);
     }
     // Prefix matches entirely or node has no prefix. Look for an existing
     // child.
     art_key_chunk_t key_chunk = key[depth + common_prefix];
-    art_node_t *child = art_find_child(inner_node, key_chunk);
-    if (child != NULL) {
-        art_node_t *new_child =
-            art_insert_at(child, key, depth + common_prefix + 1, new_leaf);
+    art_ref_t child =
+        art_find_child(inner_node, art_ref_typecode(ref), key_chunk);
+    if (child != CROARING_ART_NULL_REF) {
+        art_ref_t new_child =
+            art_insert_at(art, child, key, depth + common_prefix + 1, new_leaf);
         if (new_child != child) {
+            // Deref again as a new node may have been created.
+            inner_node = (art_inner_node_t *)art_deref(art, ref);
             // Node type changed.
-            art_replace(inner_node, key_chunk, new_child);
+            art_replace(inner_node, art_ref_typecode(ref), key_chunk,
+                        new_child);
         }
-        return node;
+        return ref;
     }
-    return art_node_insert_leaf(inner_node, key_chunk, new_leaf);
+    return art_node_insert_leaf(art, inner_node, art_ref_typecode(ref),
+                                key_chunk, new_leaf);
 }
 
 // Erase helper struct.
 typedef struct art_erase_result_s {
-    // The rootmost node where the value was erased, may not be equal to `node`.
-    // If no value was removed, this is null.
-    art_node_t *rootmost_node;
+    // The rootmost node where the value was erased, may not be equal to
+    // the original node. If no value was removed, this is
+    // CROARING_ART_NULL_REF.
+    art_ref_t rootmost_node;
+
+    // True if a value was erased.
+    bool erased;
 
-    // Value removed, null if not removed.
-    art_val_t *value_erased;
+    // Value removed, if any.
+    art_val_t value_erased;
 } art_erase_result_t;
 
 // Searches for the given key starting at `node`, erases it if found.
-static art_erase_result_t art_erase_at(art_node_t *node,
+static art_erase_result_t art_erase_at(art_t *art, art_ref_t ref,
                                        const art_key_chunk_t *key,
                                        uint8_t depth) {
     art_erase_result_t result;
-    result.rootmost_node = NULL;
-    result.value_erased = NULL;
+    result.rootmost_node = CROARING_ART_NULL_REF;
+    result.erased = false;
 
-    if (art_is_leaf(node)) {
-        art_leaf_t *leaf = CROARING_CAST_LEAF(node);
+    if (art_is_leaf(ref)) {
+        art_leaf_t *leaf = (art_leaf_t *)art_deref(art, ref);
         uint8_t common_prefix = art_common_prefix(leaf->key, 0, ART_KEY_BYTES,
                                                   key, 0, ART_KEY_BYTES);
         if (common_prefix != ART_KEY_BYTES) {
             // Leaf key mismatch.
             return result;
         }
-        result.value_erased = (art_val_t *)leaf;
+        result.erased = true;
+        result.value_erased = leaf->val;
+        art_node_free(art, (art_node_t *)leaf, CROARING_ART_LEAF_TYPE);
         return result;
     }
-    art_inner_node_t *inner_node = (art_inner_node_t *)node;
+    art_inner_node_t *inner_node = (art_inner_node_t *)art_deref(art, ref);
     uint8_t common_prefix =
         art_common_prefix(inner_node->prefix, 0, inner_node->prefix_size, key,
                           depth, ART_KEY_BYTES);
@@ -1259,101 +1479,76 @@ static art_erase_result_t art_erase_at(art_node_t *node,
         return result;
     }
     art_key_chunk_t key_chunk = key[depth + common_prefix];
-    art_node_t *child = art_find_child(inner_node, key_chunk);
-    if (child == NULL) {
+    art_ref_t child =
+        art_find_child(inner_node, art_ref_typecode(ref), key_chunk);
+    if (child == CROARING_ART_NULL_REF) {
         // No child with key chunk.
         return result;
     }
-    // Try to erase the key further down. Skip the key chunk associated with the
-    // child in the node.
+    // Try to erase the key further down. Skip the key chunk associated with
+    // the child in the node.
     art_erase_result_t child_result =
-        art_erase_at(child, key, depth + common_prefix + 1);
-    if (child_result.value_erased == NULL) {
+        art_erase_at(art, child, key, depth + common_prefix + 1);
+    if (!child_result.erased) {
         return result;
     }
+    result.erased = true;
     result.value_erased = child_result.value_erased;
-    result.rootmost_node = node;
-    if (child_result.rootmost_node == NULL) {
+    result.rootmost_node = ref;
+
+    // Deref again as nodes may have changed location.
+    inner_node = (art_inner_node_t *)art_deref(art, ref);
+    if (child_result.rootmost_node == CROARING_ART_NULL_REF) {
         // Child node was fully erased, erase it from this node's children.
-        result.rootmost_node = art_node_erase(inner_node, key_chunk);
+        result.rootmost_node =
+            art_node_erase(art, inner_node, art_ref_typecode(ref), key_chunk);
     } else if (child_result.rootmost_node != child) {
         // Child node was not fully erased, update the pointer to it in this
         // node.
-        art_replace(inner_node, key_chunk, child_result.rootmost_node);
+        art_replace(inner_node, art_ref_typecode(ref), key_chunk,
+                    child_result.rootmost_node);
     }
     return result;
 }
 
-// Searches for the given key starting at `node`, returns NULL if the key was
-// not found.
-static art_val_t *art_find_at(const art_node_t *node,
+// Searches for the given key starting at `node`, returns NULL if the key
+// was not found.
+static art_val_t *art_find_at(const art_t *art, art_ref_t ref,
                               const art_key_chunk_t *key, uint8_t depth) {
-    while (!art_is_leaf(node)) {
-        art_inner_node_t *inner_node = (art_inner_node_t *)node;
+    while (!art_is_leaf(ref)) {
+        art_inner_node_t *inner_node = (art_inner_node_t *)art_deref(art, ref);
         uint8_t common_prefix =
             art_common_prefix(inner_node->prefix, 0, inner_node->prefix_size,
                               key, depth, ART_KEY_BYTES);
         if (common_prefix != inner_node->prefix_size) {
             return NULL;
         }
-        art_node_t *child =
-            art_find_child(inner_node, key[depth + inner_node->prefix_size]);
-        if (child == NULL) {
+        art_ref_t child = art_find_child(inner_node, art_ref_typecode(ref),
+                                         key[depth + inner_node->prefix_size]);
+        if (child == CROARING_ART_NULL_REF) {
             return NULL;
         }
-        node = child;
+        ref = child;
         // Include both the prefix and the child key chunk in the depth.
         depth += inner_node->prefix_size + 1;
     }
-    art_leaf_t *leaf = CROARING_CAST_LEAF(node);
+    art_leaf_t *leaf = (art_leaf_t *)art_deref(art, ref);
     if (depth >= ART_KEY_BYTES) {
-        return (art_val_t *)leaf;
+        return &leaf->val;
     }
     uint8_t common_prefix =
         art_common_prefix(leaf->key, 0, ART_KEY_BYTES, key, 0, ART_KEY_BYTES);
     if (common_prefix == ART_KEY_BYTES) {
-        return (art_val_t *)leaf;
+        return &leaf->val;
     }
     return NULL;
 }
 
-// Returns the size in bytes of the subtrie.
-static size_t art_size_in_bytes_at(const art_node_t *node) {
-    if (art_is_leaf(node)) {
-        return 0;
-    }
-    size_t size = 0;
-    switch (art_get_type((art_inner_node_t *)node)) {
-        case CROARING_ART_NODE4_TYPE: {
-            size += sizeof(art_node4_t);
-        } break;
-        case CROARING_ART_NODE16_TYPE: {
-            size += sizeof(art_node16_t);
-        } break;
-        case CROARING_ART_NODE48_TYPE: {
-            size += sizeof(art_node48_t);
-        } break;
-        case CROARING_ART_NODE256_TYPE: {
-            size += sizeof(art_node256_t);
-        } break;
-        default:
-            assert(false);
-            break;
-    }
-    art_indexed_child_t indexed_child = art_node_next_child(node, -1);
-    while (indexed_child.child != NULL) {
-        size += art_size_in_bytes_at(indexed_child.child);
-        indexed_child = art_node_next_child(node, indexed_child.index);
-    }
-    return size;
-}
-
-static void art_node_print_type(const art_node_t *node) {
-    if (art_is_leaf(node)) {
-        printf("Leaf");
-        return;
-    }
-    switch (art_get_type((art_inner_node_t *)node)) {
+static void art_node_print_type(art_ref_t ref) {
+    switch (art_ref_typecode(ref)) {
+        case CROARING_ART_LEAF_TYPE:
+            printf("Leaf");
+            return;
         case CROARING_ART_NODE4_TYPE:
             printf("Node4");
             return;
@@ -1372,10 +1567,10 @@ static void art_node_print_type(const art_node_t *node) {
     }
 }
 
-static void art_node_printf(const art_node_t *node, uint8_t depth) {
-    if (art_is_leaf(node)) {
+void art_node_printf(const art_t *art, art_ref_t ref, uint8_t depth) {
+    if (art_is_leaf(ref)) {
         printf("{ type: Leaf, key: ");
-        art_leaf_t *leaf = CROARING_CAST_LEAF(node);
+        art_leaf_t *leaf = (art_leaf_t *)art_deref(art, ref);
         for (size_t i = 0; i < ART_KEY_BYTES; ++i) {
             printf("%02x", leaf->key[i]);
         }
@@ -1387,10 +1582,10 @@ static void art_node_printf(const art_node_t *node, uint8_t depth) {
 
     printf("%*s", depth, "");
     printf("type: ");
-    art_node_print_type(node);
+    art_node_print_type(ref);
     printf("
");
 
-    art_inner_node_t *inner_node = (art_inner_node_t *)node;
+    art_inner_node_t *inner_node = (art_inner_node_t *)art_deref(art, ref);
     printf("%*s", depth, "");
     printf("prefix_size: %d
", inner_node->prefix_size);
 
@@ -1401,41 +1596,42 @@ static void art_node_printf(const art_node_t *node, uint8_t depth) {
     }
     printf("
");
 
-    switch (art_get_type(inner_node)) {
+    switch (art_ref_typecode(ref)) {
         case CROARING_ART_NODE4_TYPE: {
-            art_node4_t *node4 = (art_node4_t *)node;
+            art_node4_t *node4 = (art_node4_t *)inner_node;
             for (uint8_t i = 0; i < node4->count; ++i) {
                 printf("%*s", depth, "");
                 printf("key: %02x ", node4->keys[i]);
-                art_node_printf(node4->children[i], depth);
+                art_node_printf(art, node4->children[i], depth);
             }
         } break;
         case CROARING_ART_NODE16_TYPE: {
-            art_node16_t *node16 = (art_node16_t *)node;
+            art_node16_t *node16 = (art_node16_t *)inner_node;
             for (uint8_t i = 0; i < node16->count; ++i) {
                 printf("%*s", depth, "");
                 printf("key: %02x ", node16->keys[i]);
-                art_node_printf(node16->children[i], depth);
+                art_node_printf(art, node16->children[i], depth);
             }
         } break;
         case CROARING_ART_NODE48_TYPE: {
-            art_node48_t *node48 = (art_node48_t *)node;
+            art_node48_t *node48 = (art_node48_t *)inner_node;
             for (int i = 0; i < 256; ++i) {
                 if (node48->keys[i] != CROARING_ART_NODE48_EMPTY_VAL) {
                     printf("%*s", depth, "");
                     printf("key: %02x ", i);
                     printf("child: %02x ", node48->keys[i]);
-                    art_node_printf(node48->children[node48->keys[i]], depth);
+                    art_node_printf(art, node48->children[node48->keys[i]],
+                                    depth);
                 }
             }
         } break;
         case CROARING_ART_NODE256_TYPE: {
-            art_node256_t *node256 = (art_node256_t *)node;
+            art_node256_t *node256 = (art_node256_t *)inner_node;
             for (int i = 0; i < 256; ++i) {
-                if (node256->children[i] != NULL) {
+                if (node256->children[i] != CROARING_ART_NULL_REF) {
                     printf("%*s", depth, "");
                     printf("key: %02x ", i);
-                    art_node_printf(node256->children[i], depth);
+                    art_node_printf(art, node256->children[i], depth);
                 }
             }
         } break;
@@ -1448,118 +1644,310 @@ static void art_node_printf(const art_node_t *node, uint8_t depth) {
     printf("}
");
 }
 
-void art_insert(art_t *art, const art_key_chunk_t *key, art_val_t *val) {
-    art_leaf_t *leaf = (art_leaf_t *)val;
-    art_leaf_populate(leaf, key);
-    if (art->root == NULL) {
-        art->root = (art_node_t *)CROARING_SET_LEAF(leaf);
+/**
+ * Moves the node at `ref` to the earliest free index before it (if any),
+ * returns the new ref. Assumes `art->first_free[typecode]` points to the
+ * smallest free index.
+ */
+static art_ref_t art_move_node_to_shrink(art_t *art, art_ref_t ref) {
+    uint64_t idx = art_ref_index(ref);
+    art_typecode_t typecode = art_ref_typecode(ref);
+    uint64_t first_free = art->first_free[typecode];
+    assert(idx != first_free);
+    if (idx < first_free) {
+        return ref;
+    }
+    uint64_t from = idx;
+    uint64_t to = first_free;
+    uint64_t next_free = art_node_get_next_free(art, art_to_ref(to, typecode));
+    memcpy(art_get_node(art, to, typecode), art_get_node(art, from, typecode),
+           ART_NODE_SIZES[typecode]);
+
+    // With an integer representing the next free index, and an `x` representing
+    // an occupied index, assume the following scenario at the start of this
+    // function:
+    //     nodes = [1,2,5,x,x]
+    //     first_free = 0
+    //
+    // We just moved a node from index 3 to 0:
+    //     nodes = [x,2,5,?,x]
+    //
+    // We need to modify the free list so that the free indices are ascending.
+    // This can be done by traversing the list until we find a node with a
+    // `next_free` greater than the index we copied the node from, and inserting
+    // the new index in between. This leads to the following:
+    //     nodes = [x,2,3,5,x]
+    //     first_free = 1
+    uint64_t initial_next_free = next_free;
+    uint64_t current = next_free;
+    while (next_free < from) {
+        current = next_free;
+        next_free =
+            art_node_get_next_free(art, art_to_ref(next_free, typecode));
+    }
+    art_node_set_next_free(art_deref(art, ref), typecode, next_free);
+    if (current < from) {
+        art_node_set_next_free(art_get_node(art, current, typecode), typecode,
+                               from);
+    }
+    art->first_free[typecode] =
+        from < initial_next_free ? from : initial_next_free;
+    return art_to_ref(to, typecode);
+}
+
+/**
+ * Sorts the free lists pointed to by art->first_free in ascending index order.
+ */
+static void art_sort_free_lists(art_t *art) {
+    for (art_typecode_t type = CROARING_ART_LEAF_TYPE;
+         type <= CROARING_ART_NODE256_TYPE; ++type) {
+        bool *free_indices =
+            (bool *)roaring_calloc(art->capacities[type], sizeof(bool));
+
+        for (uint64_t i = art->first_free[type]; i < art->capacities[type];
+             i = art_node_get_next_free(art, art_to_ref(i, type))) {
+            free_indices[i] = true;
+        }
+
+        uint64_t first_free = art->capacities[type];
+        for (uint64_t i = art->capacities[type]; i > 0; --i) {
+            uint64_t index = i - 1;
+            if (free_indices[index]) {
+                art_node_set_next_free(art_get_node(art, index, type), type,
+                                       first_free);
+                first_free = index;
+            }
+        }
+        art->first_free[type] = first_free;
+        roaring_free(free_indices);
+    }
+}
+
+/**
+ * Shrinks all node arrays to `first_free`. Assumes all indices after
+ * `first_free` are unused.
+ */
+static size_t art_shrink_node_arrays(art_t *art) {
+    size_t freed = 0;
+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;
+         ++t) {
+        if (art->first_free[t] < art->capacities[t]) {
+            uint64_t new_capacity = art->first_free[t];
+            art->nodes[t] = roaring_realloc(art->nodes[t],
+                                            new_capacity * ART_NODE_SIZES[t]);
+            freed += (art->capacities[t] - new_capacity) * ART_NODE_SIZES[t];
+            art->capacities[t] = new_capacity;
+        }
+    }
+    return freed;
+}
+
+/**
+ * Traverses the ART, moving nodes to earlier free indices and modifying their
+ * references along the way.
+ */
+static void art_shrink_at(art_t *art, art_ref_t ref) {
+    if (art_is_leaf(ref)) {
         return;
     }
-    art->root = art_insert_at(art->root, key, 0, leaf);
+    switch (art_ref_typecode(ref)) {
+        case CROARING_ART_NODE4_TYPE: {
+            art_node4_t *node4 = (art_node4_t *)art_deref(art, ref);
+            for (uint8_t i = 0; i < node4->count; ++i) {
+                node4->children[i] =
+                    art_move_node_to_shrink(art, node4->children[i]);
+                art_shrink_at(art, node4->children[i]);
+            }
+        } break;
+        case CROARING_ART_NODE16_TYPE: {
+            art_node16_t *node16 = (art_node16_t *)art_deref(art, ref);
+            for (uint8_t i = 0; i < node16->count; ++i) {
+                node16->children[i] =
+                    art_move_node_to_shrink(art, node16->children[i]);
+                art_shrink_at(art, node16->children[i]);
+            }
+        } break;
+        case CROARING_ART_NODE48_TYPE: {
+            art_node48_t *node48 = (art_node48_t *)art_deref(art, ref);
+            for (int i = 0; i < 256; ++i) {
+                if (node48->keys[i] != CROARING_ART_NODE48_EMPTY_VAL) {
+                    uint8_t idx = node48->keys[i];
+                    node48->children[idx] =
+                        art_move_node_to_shrink(art, node48->children[idx]);
+                    art_shrink_at(art, node48->children[idx]);
+                }
+            }
+        } break;
+        case CROARING_ART_NODE256_TYPE: {
+            art_node256_t *node256 = (art_node256_t *)art_deref(art, ref);
+            for (int i = 0; i < 256; ++i) {
+                if (node256->children[i] != CROARING_ART_NULL_REF) {
+                    node256->children[i] =
+                        art_move_node_to_shrink(art, node256->children[i]);
+                    art_shrink_at(art, node256->children[i]);
+                }
+            }
+        } break;
+        default:
+            assert(false);
+            break;
+    }
 }
 
-art_val_t *art_erase(art_t *art, const art_key_chunk_t *key) {
-    if (art->root == NULL) {
-        return NULL;
+void art_init_cleared(art_t *art) {
+    art->root = CROARING_ART_NULL_REF;
+    memset(art->first_free, 0, sizeof(art->first_free));
+    memset(art->capacities, 0, sizeof(art->capacities));
+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;
+         ++t) {
+        art->nodes[t] = NULL;
     }
-    art_erase_result_t result = art_erase_at(art->root, key, 0);
-    if (result.value_erased == NULL) {
-        return NULL;
+}
+
+size_t art_shrink_to_fit(art_t *art) {
+    if (art_is_shrunken(art)) {
+        return 0;
+    }
+    if (art->root != CROARING_ART_NULL_REF) {
+        art_sort_free_lists(art);
+        art->root = art_move_node_to_shrink(art, art->root);
+        art_shrink_at(art, art->root);
+    }
+    return art_shrink_node_arrays(art);
+}
+
+bool art_is_shrunken(const art_t *art) {
+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;
+         ++t) {
+        if (art->first_free[t] != art->capacities[t]) {
+            return false;
+        }
+    }
+    return true;
+}
+
+art_val_t *art_insert(art_t *art, const art_key_chunk_t *key, art_val_t val) {
+    art_ref_t leaf = art_leaf_create(art, key, val);
+    if (art->root == CROARING_ART_NULL_REF) {
+        art->root = leaf;
+        return &((art_leaf_t *)art_deref(art, leaf))->val;
+    }
+    art->root = art_insert_at(art, art->root, key, 0, leaf);
+    return &((art_leaf_t *)art_deref(art, leaf))->val;
+}
+
+bool art_erase(art_t *art, const art_key_chunk_t *key, art_val_t *erased_val) {
+    art_val_t erased_val_local;
+    if (erased_val == NULL) {
+        erased_val = &erased_val_local;
+    }
+    if (art->root == CROARING_ART_NULL_REF) {
+        return false;
+    }
+    art_erase_result_t result = art_erase_at(art, art->root, key, 0);
+    if (!result.erased) {
+        return false;
     }
     art->root = result.rootmost_node;
-    return result.value_erased;
+    *erased_val = result.value_erased;
+    return true;
 }
 
 art_val_t *art_find(const art_t *art, const art_key_chunk_t *key) {
-    if (art->root == NULL) {
+    if (art->root == CROARING_ART_NULL_REF) {
         return NULL;
     }
-    return art_find_at(art->root, key, 0);
+    return art_find_at(art, art->root, key, 0);
 }
 
-bool art_is_empty(const art_t *art) { return art->root == NULL; }
-
-void art_free(art_t *art) {
-    if (art->root == NULL) {
-        return;
-    }
-    art_free_node(art->root);
+bool art_is_empty(const art_t *art) {
+    return art->root == CROARING_ART_NULL_REF;
 }
 
-size_t art_size_in_bytes(const art_t *art) {
-    size_t size = sizeof(art_t);
-    if (art->root != NULL) {
-        size += art_size_in_bytes_at(art->root);
+void art_free(art_t *art) {
+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;
+         ++t) {
+        roaring_free(art->nodes[t]);
     }
-    return size;
 }
 
 void art_printf(const art_t *art) {
-    if (art->root == NULL) {
+    if (art->root == CROARING_ART_NULL_REF) {
         return;
     }
-    art_node_printf(art->root, 0);
+    art_node_printf(art, art->root, 0);
+}
+
+// Returns a reference to the current node that the iterator is positioned
+// at.
+static inline art_ref_t art_iterator_ref(art_iterator_t *iterator) {
+    return iterator->frames[iterator->frame].ref;
 }
 
 // Returns the current node that the iterator is positioned at.
 static inline art_node_t *art_iterator_node(art_iterator_t *iterator) {
-    return iterator->frames[iterator->frame].node;
+    return art_deref(iterator->art, art_iterator_ref(iterator));
 }
 
-// Sets the iterator key and value to the leaf's key and value. Always returns
-// true for convenience.
+// Sets the iterator key and value to the leaf's key and value. Always
+// returns true for convenience.
 static inline bool art_iterator_valid_loc(art_iterator_t *iterator,
-                                          art_leaf_t *leaf) {
-    iterator->frames[iterator->frame].node = CROARING_SET_LEAF(leaf);
+                                          art_ref_t leaf_ref) {
+    iterator->frames[iterator->frame].ref = leaf_ref;
     iterator->frames[iterator->frame].index_in_node = 0;
+    art_leaf_t *leaf = (art_leaf_t *)art_deref(iterator->art, leaf_ref);
     memcpy(iterator->key, leaf->key, ART_KEY_BYTES);
-    iterator->value = (art_val_t *)leaf;
+    iterator->value = &leaf->val;
     return true;
 }
 
-// Invalidates the iterator key and value. Always returns false for convenience.
+// Invalidates the iterator key and value. Always returns false for
+// convenience.
 static inline bool art_iterator_invalid_loc(art_iterator_t *iterator) {
     memset(iterator->key, 0, ART_KEY_BYTES);
     iterator->value = NULL;
     return false;
 }
 
-// Moves the iterator one level down in the tree, given a node at the current
-// level and the index of the child that we're going down to.
+// Moves the iterator one level down in the tree, given a node at the
+// current level and the index of the child that we're going down to.
 //
 // Note: does not set the index at the new level.
-static void art_iterator_down(art_iterator_t *iterator,
-                              const art_inner_node_t *node,
+static void art_iterator_down(art_iterator_t *iterator, art_ref_t ref,
                               uint8_t index_in_node) {
-    iterator->frames[iterator->frame].node = (art_node_t *)node;
+    iterator->frames[iterator->frame].ref = ref;
     iterator->frames[iterator->frame].index_in_node = index_in_node;
     iterator->frame++;
-    art_indexed_child_t indexed_child =
-        art_node_child_at((art_node_t *)node, index_in_node);
-    assert(indexed_child.child != NULL);
-    iterator->frames[iterator->frame].node = indexed_child.child;
+    art_inner_node_t *node = (art_inner_node_t *)art_deref(iterator->art, ref);
+    art_indexed_child_t indexed_child = art_node_child_at(
+        (art_node_t *)node, art_ref_typecode(ref), index_in_node);
+    assert(indexed_child.child != CROARING_ART_NULL_REF);
+    iterator->frames[iterator->frame].ref = indexed_child.child;
     iterator->depth += node->prefix_size + 1;
 }
 
-// Moves the iterator to the next/previous child of the current node. Returns
-// the child moved to, or NULL if there is no neighboring child.
-static art_node_t *art_iterator_neighbor_child(
-    art_iterator_t *iterator, const art_inner_node_t *inner_node,
-    bool forward) {
+// Moves the iterator to the next/previous child of the current node.
+// Returns the child moved to, or NULL if there is no neighboring child.
+static art_ref_t art_iterator_neighbor_child(art_iterator_t *iterator,
+                                             bool forward) {
     art_iterator_frame_t frame = iterator->frames[iterator->frame];
+    art_node_t *node = art_deref(iterator->art, frame.ref);
     art_indexed_child_t indexed_child;
     if (forward) {
-        indexed_child = art_node_next_child(frame.node, frame.index_in_node);
+        indexed_child = art_node_next_child(node, art_ref_typecode(frame.ref),
+                                            frame.index_in_node);
     } else {
-        indexed_child = art_node_prev_child(frame.node, frame.index_in_node);
+        indexed_child = art_node_prev_child(node, art_ref_typecode(frame.ref),
+                                            frame.index_in_node);
     }
-    if (indexed_child.child != NULL) {
-        art_iterator_down(iterator, inner_node, indexed_child.index);
+    if (indexed_child.child != CROARING_ART_NULL_REF) {
+        art_iterator_down(iterator, frame.ref, indexed_child.index);
     }
     return indexed_child.child;
 }
 
-// Moves the iterator one level up in the tree, returns false if not possible.
+// Moves the iterator one level up in the tree, returns false if not
+// possible.
 static bool art_iterator_up(art_iterator_t *iterator) {
     if (iterator->frame == 0) {
         return false;
@@ -1571,8 +1959,8 @@ static bool art_iterator_up(art_iterator_t *iterator) {
     return true;
 }
 
-// Moves the iterator one level, followed by a move to the next / previous leaf.
-// Sets the status of the iterator.
+// Moves the iterator one level, followed by a move to the next / previous
+// leaf. Sets the status of the iterator.
 static bool art_iterator_up_and_move(art_iterator_t *iterator, bool forward) {
     if (!art_iterator_up(iterator)) {
         // We're at the root.
@@ -1583,27 +1971,29 @@ static bool art_iterator_up_and_move(art_iterator_t *iterator, bool forward) {
 
 // Initializes the iterator at the first / last leaf of the given node.
 // Returns true for convenience.
-static bool art_node_init_iterator(const art_node_t *node,
-                                   art_iterator_t *iterator, bool first) {
-    while (!art_is_leaf(node)) {
+static bool art_node_init_iterator(art_ref_t ref, art_iterator_t *iterator,
+                                   bool first) {
+    while (!art_is_leaf(ref)) {
+        art_node_t *node = art_deref(iterator->art, ref);
         art_indexed_child_t indexed_child;
         if (first) {
-            indexed_child = art_node_next_child(node, -1);
+            indexed_child =
+                art_node_next_child(node, art_ref_typecode(ref), -1);
         } else {
-            indexed_child = art_node_prev_child(node, 256);
+            indexed_child =
+                art_node_prev_child(node, art_ref_typecode(ref), 256);
         }
-        art_iterator_down(iterator, (art_inner_node_t *)node,
-                          indexed_child.index);
-        node = indexed_child.child;
+        art_iterator_down(iterator, ref, indexed_child.index);
+        ref = indexed_child.child;
     }
     // We're at a leaf.
-    iterator->frames[iterator->frame].node = (art_node_t *)node;
+    iterator->frames[iterator->frame].ref = ref;
     iterator->frames[iterator->frame].index_in_node = 0;  // Should not matter.
-    return art_iterator_valid_loc(iterator, CROARING_CAST_LEAF(node));
+    return art_iterator_valid_loc(iterator, ref);
 }
 
 bool art_iterator_move(art_iterator_t *iterator, bool forward) {
-    if (art_is_leaf(art_iterator_node(iterator))) {
+    if (art_is_leaf(art_iterator_ref(iterator))) {
         bool went_up = art_iterator_up(iterator);
         if (!went_up) {
             // This leaf is the root, we're done.
@@ -1611,67 +2001,69 @@ bool art_iterator_move(art_iterator_t *iterator, bool forward) {
         }
     }
     // Advance within inner node.
-    art_node_t *neighbor_child = art_iterator_neighbor_child(
-        iterator, (art_inner_node_t *)art_iterator_node(iterator), forward);
-    if (neighbor_child != NULL) {
-        // There is another child at this level, go down to the first or last
-        // leaf.
+    art_ref_t neighbor_child = art_iterator_neighbor_child(iterator, forward);
+    if (neighbor_child != CROARING_ART_NULL_REF) {
+        // There is another child at this level, go down to the first or
+        // last leaf.
         return art_node_init_iterator(neighbor_child, iterator, forward);
     }
     // No more children at this level, go up.
     return art_iterator_up_and_move(iterator, forward);
 }
 
-// Assumes the iterator is positioned at a node with an equal prefix path up to
-// the depth of the iterator.
-static bool art_node_iterator_lower_bound(const art_node_t *node,
+// Assumes the iterator is positioned at a node with an equal prefix path up
+// to the depth of the iterator.
+static bool art_node_iterator_lower_bound(art_ref_t ref,
                                           art_iterator_t *iterator,
                                           const art_key_chunk_t key[]) {
-    while (!art_is_leaf(node)) {
-        art_inner_node_t *inner_node = (art_inner_node_t *)node;
+    while (!art_is_leaf(ref)) {
+        art_inner_node_t *inner_node =
+            (art_inner_node_t *)art_deref(iterator->art, ref);
         int prefix_comparison =
             art_compare_prefix(inner_node->prefix, 0, key, iterator->depth,
                                inner_node->prefix_size);
         if (prefix_comparison < 0) {
             // Prefix so far has been equal, but we've found a smaller key.
-            // Since we take the lower bound within each node, we can return the
-            // next leaf.
+            // Since we take the lower bound within each node, we can return
+            // the next leaf.
             return art_iterator_up_and_move(iterator, true);
         } else if (prefix_comparison > 0) {
-            // No key equal to the key we're looking for, return the first leaf.
-            return art_node_init_iterator(node, iterator, true);
+            // No key equal to the key we're looking for, return the first
+            // leaf.
+            return art_node_init_iterator(ref, iterator, true);
         }
         // Prefix is equal, move to lower bound child.
         art_key_chunk_t key_chunk =
             key[iterator->depth + inner_node->prefix_size];
-        art_indexed_child_t indexed_child =
-            art_node_lower_bound(node, key_chunk);
-        if (indexed_child.child == NULL) {
+        art_indexed_child_t indexed_child = art_node_lower_bound(
+            (art_node_t *)inner_node, art_ref_typecode(ref), key_chunk);
+        if (indexed_child.child == CROARING_ART_NULL_REF) {
             // Only smaller keys among children.
             return art_iterator_up_and_move(iterator, true);
         }
         if (indexed_child.key_chunk > key_chunk) {
             // Only larger children, return the first larger child.
-            art_iterator_down(iterator, inner_node, indexed_child.index);
+            art_iterator_down(iterator, ref, indexed_child.index);
             return art_node_init_iterator(indexed_child.child, iterator, true);
         }
         // We found a child with an equal prefix.
-        art_iterator_down(iterator, inner_node, indexed_child.index);
-        node = indexed_child.child;
+        art_iterator_down(iterator, ref, indexed_child.index);
+        ref = indexed_child.child;
     }
-    art_leaf_t *leaf = CROARING_CAST_LEAF(node);
+    art_leaf_t *leaf = (art_leaf_t *)art_deref(iterator->art, ref);
     if (art_compare_keys(leaf->key, key) >= 0) {
         // Leaf has an equal or larger key.
-        return art_iterator_valid_loc(iterator, leaf);
+        return art_iterator_valid_loc(iterator, ref);
     }
-    // Leaf has an equal prefix, but the full key is smaller. Move to the next
-    // leaf.
+    // Leaf has an equal prefix, but the full key is smaller. Move to the
+    // next leaf.
     return art_iterator_up_and_move(iterator, true);
 }
 
-art_iterator_t art_init_iterator(const art_t *art, bool first) {
+art_iterator_t art_init_iterator(art_t *art, bool first) {
     art_iterator_t iterator = CROARING_ZERO_INITIALIZER;
-    if (art->root == NULL) {
+    iterator.art = art;
+    if (art->root == CROARING_ART_NULL_REF) {
         return iterator;
     }
     art_node_init_iterator(art->root, &iterator, first);
@@ -1689,12 +2081,12 @@ bool art_iterator_prev(art_iterator_t *iterator) {
 bool art_iterator_lower_bound(art_iterator_t *iterator,
                               const art_key_chunk_t *key) {
     if (iterator->value == NULL) {
-        // We're beyond the end / start of the ART so the iterator does not have
-        // a valid key. Start from the root.
+        // We're beyond the end / start of the ART so the iterator does not
+        // have a valid key. Start from the root.
         iterator->frame = 0;
         iterator->depth = 0;
-        art_node_t *root = art_iterator_node(iterator);
-        if (root == NULL) {
+        art_ref_t root = art_iterator_ref(iterator);
+        if (root == CROARING_ART_NULL_REF) {
             return false;
         }
         return art_node_iterator_lower_bound(root, iterator, key);
@@ -1709,7 +2101,7 @@ bool art_iterator_lower_bound(art_iterator_t *iterator,
                 // Only smaller keys found.
                 return art_iterator_invalid_loc(iterator);
             } else {
-                return art_node_init_iterator(art_iterator_node(iterator),
+                return art_node_init_iterator(art_iterator_ref(iterator),
                                               iterator, true);
             }
         }
@@ -1722,24 +2114,26 @@ bool art_iterator_lower_bound(art_iterator_t *iterator,
                                iterator->depth + inner_node->prefix_size);
     }
     if (compare_result > 0) {
-        return art_node_init_iterator(art_iterator_node(iterator), iterator,
+        return art_node_init_iterator(art_iterator_ref(iterator), iterator,
                                       true);
     }
-    return art_node_iterator_lower_bound(art_iterator_node(iterator), iterator,
+    return art_node_iterator_lower_bound(art_iterator_ref(iterator), iterator,
                                          key);
 }
 
-art_iterator_t art_lower_bound(const art_t *art, const art_key_chunk_t *key) {
+art_iterator_t art_lower_bound(art_t *art, const art_key_chunk_t *key) {
     art_iterator_t iterator = CROARING_ZERO_INITIALIZER;
-    if (art->root != NULL) {
+    iterator.art = art;
+    if (art->root != CROARING_ART_NULL_REF) {
         art_node_iterator_lower_bound(art->root, &iterator, key);
     }
     return iterator;
 }
 
-art_iterator_t art_upper_bound(const art_t *art, const art_key_chunk_t *key) {
+art_iterator_t art_upper_bound(art_t *art, const art_key_chunk_t *key) {
     art_iterator_t iterator = CROARING_ZERO_INITIALIZER;
-    if (art->root != NULL) {
+    iterator.art = art;
+    if (art->root != CROARING_ART_NULL_REF) {
         if (art_node_iterator_lower_bound(art->root, &iterator, key) &&
             art_compare_keys(iterator.key, key) == 0) {
             art_iterator_next(&iterator);
@@ -1748,90 +2142,100 @@ art_iterator_t art_upper_bound(const art_t *art, const art_key_chunk_t *key) {
     return iterator;
 }
 
-void art_iterator_insert(art_t *art, art_iterator_t *iterator,
-                         const art_key_chunk_t *key, art_val_t *val) {
+void art_iterator_insert(art_iterator_t *iterator, const art_key_chunk_t *key,
+                         art_val_t val) {
     // TODO: This can likely be faster.
-    art_insert(art, key, val);
-    assert(art->root != NULL);
+    art_insert(iterator->art, key, val);
+    assert(iterator->art->root != CROARING_ART_NULL_REF);
     iterator->frame = 0;
     iterator->depth = 0;
-    art_node_iterator_lower_bound(art->root, iterator, key);
+    art_node_iterator_lower_bound(iterator->art->root, iterator, key);
 }
 
-// TODO: consider keeping `art_t *art` in the iterator.
-art_val_t *art_iterator_erase(art_t *art, art_iterator_t *iterator) {
+bool art_iterator_erase(art_iterator_t *iterator, art_val_t *erased_val) {
+    art_val_t erased_val_local;
+    if (erased_val == NULL) {
+        erased_val = &erased_val_local;
+    }
     if (iterator->value == NULL) {
-        return NULL;
+        return false;
     }
     art_key_chunk_t initial_key[ART_KEY_BYTES];
     memcpy(initial_key, iterator->key, ART_KEY_BYTES);
 
-    art_val_t *value_erased = iterator->value;
+    *erased_val = *iterator->value;
+    // Erase the leaf.
+    art_node_free(iterator->art, art_iterator_node(iterator),
+                  art_ref_typecode(art_iterator_ref(iterator)));
     bool went_up = art_iterator_up(iterator);
     if (!went_up) {
         // We're erasing the root.
-        art->root = NULL;
+        iterator->art->root = CROARING_ART_NULL_REF;
         art_iterator_invalid_loc(iterator);
-        return value_erased;
+        return true;
     }
 
-    // Erase the leaf.
+    // Erase the leaf in its parent.
+    art_ref_t parent_ref = art_iterator_ref(iterator);
     art_inner_node_t *parent_node =
         (art_inner_node_t *)art_iterator_node(iterator);
     art_key_chunk_t key_chunk_in_parent =
         iterator->key[iterator->depth + parent_node->prefix_size];
-    art_node_t *new_parent_node =
-        art_node_erase(parent_node, key_chunk_in_parent);
+    art_ref_t new_parent_ref =
+        art_node_erase(iterator->art, parent_node, art_ref_typecode(parent_ref),
+                       key_chunk_in_parent);
 
-    if (new_parent_node != ((art_node_t *)parent_node)) {
+    if (new_parent_ref != parent_ref) {
         // Replace the pointer to the inner node we erased from in its
         // parent (it may be a leaf now).
-        iterator->frames[iterator->frame].node = new_parent_node;
+        iterator->frames[iterator->frame].ref = new_parent_ref;
         went_up = art_iterator_up(iterator);
         if (went_up) {
+            art_ref_t grandparent_ref = art_iterator_ref(iterator);
             art_inner_node_t *grandparent_node =
                 (art_inner_node_t *)art_iterator_node(iterator);
             art_key_chunk_t key_chunk_in_grandparent =
                 iterator->key[iterator->depth + grandparent_node->prefix_size];
-            art_replace(grandparent_node, key_chunk_in_grandparent,
-                        new_parent_node);
+            art_replace(grandparent_node, art_ref_typecode(grandparent_ref),
+                        key_chunk_in_grandparent, new_parent_ref);
         } else {
             // We were already at the rootmost node.
-            art->root = new_parent_node;
+            iterator->art->root = new_parent_ref;
         }
     }
 
     iterator->frame = 0;
     iterator->depth = 0;
-    // Do a lower bound search for the initial key, which will find the first
-    // greater key if it exists. This can likely be mildly faster if we instead
-    // start from the current position.
-    art_node_iterator_lower_bound(art->root, iterator, initial_key);
-    return value_erased;
+    // Do a lower bound search for the initial key, which will find the
+    // first greater key if it exists. This can likely be mildly faster if
+    // we instead start from the current position.
+    art_node_iterator_lower_bound(iterator->art->root, iterator, initial_key);
+    return true;
 }
 
-static bool art_internal_validate_at(const art_node_t *node,
+static bool art_internal_validate_at(const art_t *art, art_ref_t ref,
                                      art_internal_validate_t validator) {
-    if (node == NULL) {
+    if (ref == CROARING_ART_NULL_REF) {
         return art_validate_fail(&validator, "node is null");
     }
-    if (art_is_leaf(node)) {
-        art_leaf_t *leaf = CROARING_CAST_LEAF(node);
+    if (art_is_leaf(ref)) {
+        art_leaf_t *leaf = (art_leaf_t *)art_deref(art, ref);
         if (art_compare_prefix(leaf->key, 0, validator.current_key, 0,
                                validator.depth) != 0) {
-            return art_validate_fail(
-                &validator,
-                "leaf key does not match its position's prefix in the tree");
+            return art_validate_fail(&validator,
+                                     "leaf key does not match its "
+                                     "position's prefix in the tree");
         }
         if (validator.validate_cb != NULL &&
-            !validator.validate_cb(leaf, validator.reason)) {
+            !validator.validate_cb(leaf->val, validator.reason,
+                                   validator.context)) {
             if (*validator.reason == NULL) {
                 *validator.reason = "leaf validation failed";
             }
             return false;
         }
     } else {
-        art_inner_node_t *inner_node = (art_inner_node_t *)node;
+        art_inner_node_t *inner_node = (art_inner_node_t *)art_deref(art, ref);
 
         if (validator.depth + inner_node->prefix_size + 1 > ART_KEY_BYTES) {
             return art_validate_fail(&validator,
@@ -1841,28 +2245,28 @@ static bool art_internal_validate_at(const art_node_t *node,
                inner_node->prefix_size);
         validator.depth += inner_node->prefix_size;
 
-        switch (inner_node->typecode) {
+        switch (art_ref_typecode(ref)) {
             case CROARING_ART_NODE4_TYPE:
-                if (!art_node4_internal_validate((art_node4_t *)inner_node,
+                if (!art_node4_internal_validate(art, (art_node4_t *)inner_node,
                                                  validator)) {
                     return false;
                 }
                 break;
             case CROARING_ART_NODE16_TYPE:
-                if (!art_node16_internal_validate((art_node16_t *)inner_node,
-                                                  validator)) {
+                if (!art_node16_internal_validate(
+                        art, (art_node16_t *)inner_node, validator)) {
                     return false;
                 }
                 break;
             case CROARING_ART_NODE48_TYPE:
-                if (!art_node48_internal_validate((art_node48_t *)inner_node,
-                                                  validator)) {
+                if (!art_node48_internal_validate(
+                        art, (art_node48_t *)inner_node, validator)) {
                     return false;
                 }
                 break;
             case CROARING_ART_NODE256_TYPE:
-                if (!art_node256_internal_validate((art_node256_t *)inner_node,
-                                                   validator)) {
+                if (!art_node256_internal_validate(
+                        art, (art_node256_t *)inner_node, validator)) {
                     return false;
                 }
                 break;
@@ -1874,23 +2278,143 @@ static bool art_internal_validate_at(const art_node_t *node,
 }
 
 bool art_internal_validate(const art_t *art, const char **reason,
-                           art_validate_cb_t validate_cb) {
+                           art_validate_cb_t validate_cb, void *context) {
     const char *reason_local;
     if (reason == NULL) {
         // Always allow assigning through *reason
         reason = &reason_local;
     }
     *reason = NULL;
-    if (art->root == NULL) {
+    if (art->root == CROARING_ART_NULL_REF) {
         return true;
     }
     art_internal_validate_t validator = {
         .reason = reason,
         .validate_cb = validate_cb,
+        .context = context,
         .depth = 0,
-        .current_key = {0},
+        .current_key = CROARING_ZERO_INITIALIZER,
     };
-    return art_internal_validate_at(art->root, validator);
+    for (art_typecode_t type = CROARING_ART_LEAF_TYPE;
+         type <= CROARING_ART_NODE256_TYPE; ++type) {
+        uint64_t capacity = art->capacities[type];
+        for (uint64_t i = 0; i < capacity; ++i) {
+            uint64_t first_free = art->first_free[type];
+            if (first_free > capacity) {
+                return art_validate_fail(&validator, "first_free > capacity");
+            }
+        }
+    }
+    return art_internal_validate_at(art, art->root, validator);
+}
+
+_Static_assert(alignof(art_leaf_t) == alignof(art_node4_t),
+               "Serialization assumes node type alignment is equal");
+_Static_assert(alignof(art_leaf_t) == alignof(art_node16_t),
+               "Serialization assumes node type alignment is equal");
+_Static_assert(alignof(art_leaf_t) == alignof(art_node48_t),
+               "Serialization assumes node type alignment is equal");
+_Static_assert(alignof(art_leaf_t) == alignof(art_node256_t),
+               "Serialization assumes node type alignment is equal");
+
+size_t art_size_in_bytes(const art_t *art) {
+    if (!art_is_shrunken(art)) {
+        return 0;
+    }
+    // Root.
+    size_t size = sizeof(art->root);
+    // Node counts.
+    size += sizeof(art->capacities);
+    // Alignment for leaves. The rest of the nodes are aligned the same way.
+    size +=
+        ((size + alignof(art_leaf_t) - 1) & ~(alignof(art_leaf_t) - 1)) - size;
+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;
+         ++t) {
+        size += art->capacities[t] * ART_NODE_SIZES[t];
+    }
+    return size;
+}
+
+size_t art_serialize(const art_t *art, char *buf) {
+    if (buf == NULL) {
+        return 0;
+    }
+    if (!art_is_shrunken(art)) {
+        return 0;
+    }
+    const char *initial_buf = buf;
+
+    // Root.
+    memcpy(buf, &art->root, sizeof(art->root));
+    buf += sizeof(art->root);
+
+    // Node counts.
+    memcpy(buf, art->capacities, sizeof(art->capacities));
+    buf += sizeof(art->capacities);
+
+    // Alignment for leaves. The rest of the nodes are aligned the same way.
+    size_t align_bytes =
+        CROARING_ART_ALIGN_SIZE_RELATIVE(buf, initial_buf, alignof(art_leaf_t));
+    memset(buf, 0, align_bytes);
+    buf += align_bytes;
+
+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;
+         ++t) {
+        if (art->capacities[t] > 0) {
+            size_t size = art->capacities[t] * ART_NODE_SIZES[t];
+            memcpy(buf, art->nodes[t], size);
+            buf += size;
+        }
+    }
+
+    return buf - initial_buf;
+}
+
+size_t art_frozen_view(const char *buf, size_t maxbytes, art_t *art) {
+    if (buf == NULL || art == NULL) {
+        return 0;
+    }
+    const char *initial_buf = buf;
+    art_init_cleared(art);
+
+    if (maxbytes < sizeof(art->root)) {
+        return 0;
+    }
+    memcpy(&art->root, buf, sizeof(art->root));
+    buf += sizeof(art->root);
+    maxbytes -= sizeof(art->root);
+
+    if (maxbytes < sizeof(art->capacities)) {
+        return 0;
+    }
+    _Static_assert(sizeof(art->first_free) == sizeof(art->capacities),
+                   "first_free is read from capacities");
+    memcpy(art->first_free, buf, sizeof(art->capacities));
+    memcpy(art->capacities, buf, sizeof(art->capacities));
+    buf += sizeof(art->capacities);
+    maxbytes -= sizeof(art->capacities);
+
+    // Alignment for leaves. The rest of the nodes are aligned the same way.
+    const char *before_align = buf;
+    buf = CROARING_ART_ALIGN_BUF(buf, alignof(art_leaf_t));
+    if (maxbytes < (size_t)(buf - before_align)) {
+        return 0;
+    }
+    maxbytes -= buf - before_align;
+
+    for (art_typecode_t t = CROARING_ART_MIN_TYPE; t <= CROARING_ART_MAX_TYPE;
+         ++t) {
+        if (art->capacities[t] > 0) {
+            size_t size = art->capacities[t] * ART_NODE_SIZES[t];
+            if (maxbytes < size) {
+                return 0;
+            }
+            art->nodes[t] = (char *)buf;
+            buf += size;
+            maxbytes -= size;
+        }
+    }
+    return buf - initial_buf;
 }
 
 #ifdef __cplusplus
diff --git a/contrib/libs/croaring/src/containers/bitset.c b/contrib/libs/croaring/src/containers/bitset.c
index 7a38d072b360..b66f8807b0d8 100644
--- a/contrib/libs/croaring/src/containers/bitset.c
+++ b/contrib/libs/croaring/src/containers/bitset.c
@@ -2,9 +2,6 @@
  * bitset.c
  *
  */
-#ifndef _POSIX_C_SOURCE
-#define _POSIX_C_SOURCE 200809L
-#endif
 #include <assert.h>
 #include <stdio.h>
 #include <stdlib.h>
diff --git a/contrib/libs/croaring/src/roaring64.c b/contrib/libs/croaring/src/roaring64.c
index 208c198de7f8..bc65e8b0e5b9 100644
--- a/contrib/libs/croaring/src/roaring64.c
+++ b/contrib/libs/croaring/src/roaring64.c
@@ -1,4 +1,5 @@
 #include <assert.h>
+#include <stdalign.h>
 #include <stdarg.h>
 #include <stdint.h>
 #include <string.h>
@@ -8,11 +9,20 @@
 #include <roaring/roaring64.h>
 
 // For serialization / deserialization
+#include <roaring/containers/array.h>
+#include <roaring/containers/bitset.h>
+#include <roaring/containers/run.h>
 #include <roaring/roaring.h>
 #include <roaring/roaring_array.h>
 // containers.h last to avoid conflict with ROARING_CONTAINER_T.
 #include <roaring/containers/containers.h>
 
+#define CROARING_ALIGN_BUF(buf, alignment)          \
+    (char *)(((uintptr_t)(buf) + ((alignment)-1)) & \
+             (ptrdiff_t)(~((alignment)-1)))
+
+#define CROARING_BITSET_ALIGNMENT 64
+
 #ifdef __cplusplus
 using namespace ::roaring::internal;
 
@@ -27,22 +37,19 @@ namespace api {
 typedef struct roaring64_bitmap_s {
     art_t art;
     uint8_t flags;
+    uint64_t first_free;
+    uint64_t capacity;
+    container_t **containers;
 } roaring64_bitmap_t;
 
 // Leaf type of the ART used to keep the high 48 bits of each entry.
-typedef struct roaring64_leaf_s {
-    art_val_t _pad;
-    uint8_t typecode;
-    container_t *container;
-} roaring64_leaf_t;
-
-// Alias to make it easier to work with, since it's an internal-only type
-// anyway.
-typedef struct roaring64_leaf_s leaf_t;
+// Low 8 bits: typecode
+// High 56 bits: container index
+typedef roaring64_leaf_t leaf_t;
 
 // Iterator struct to hold iteration state.
 typedef struct roaring64_iterator_s {
-    const roaring64_bitmap_t *parent;
+    const roaring64_bitmap_t *r;
     art_iterator_t art_it;
     roaring_container_iterator_t container_it;
     uint64_t high48;  // Key that art_it points to.
@@ -57,6 +64,10 @@ typedef struct roaring64_iterator_s {
     bool saturated_forward;
 } roaring64_iterator_t;
 
+static inline bool is_frozen64(const roaring64_bitmap_t *r) {
+    return r->flags & ROARING_FLAG_FROZEN;
+}
+
 // Splits the given uint64 key into high 48 bit and low 16 bit components.
 // Expects high48_out to be of length ART_KEY_BYTES.
 static inline uint16_t split_key(uint64_t key, uint8_t high48_out[]) {
@@ -77,23 +88,95 @@ static inline uint64_t minimum(uint64_t a, uint64_t b) {
     return (a < b) ? a : b;
 }
 
-static inline leaf_t *create_leaf(container_t *container, uint8_t typecode) {
-    leaf_t *leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));
-    leaf->container = container;
-    leaf->typecode = typecode;
-    return leaf;
+static inline leaf_t create_leaf(uint64_t container_index, uint8_t typecode) {
+    return (container_index << 8) | typecode;
 }
 
-static inline leaf_t *copy_leaf_container(const leaf_t *leaf) {
-    leaf_t *result_leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));
-    result_leaf->typecode = leaf->typecode;
-    // get_copy_of_container modifies the typecode passed in.
-    result_leaf->container = get_copy_of_container(
-        leaf->container, &result_leaf->typecode, /*copy_on_write=*/false);
-    return result_leaf;
+static inline uint8_t get_typecode(leaf_t leaf) { return (uint8_t)leaf; }
+
+static inline uint64_t get_index(leaf_t leaf) { return leaf >> 8; }
+
+static inline container_t *get_container(const roaring64_bitmap_t *r,
+                                         leaf_t leaf) {
+    return r->containers[get_index(leaf)];
 }
 
-static inline void free_leaf(leaf_t *leaf) { roaring_free(leaf); }
+// Replaces the container of `leaf` with the given container. Returns the
+// modified leaf for convenience.
+static inline leaf_t replace_container(roaring64_bitmap_t *r, leaf_t *leaf,
+                                       container_t *container,
+                                       uint8_t typecode) {
+    uint64_t index = get_index(*leaf);
+    r->containers[index] = container;
+    *leaf = create_leaf(index, typecode);
+    return *leaf;
+}
+
+/**
+ * Extends the array of container pointers.
+ */
+static void extend_containers(roaring64_bitmap_t *r) {
+    uint64_t size = r->first_free;
+    if (size < r->capacity) {
+        return;
+    }
+    uint64_t new_capacity;
+    if (r->capacity == 0) {
+        new_capacity = 2;
+    } else if (r->capacity < 1024) {
+        new_capacity = 2 * r->capacity;
+    } else {
+        new_capacity = 5 * r->capacity / 4;
+    }
+    uint64_t increase = new_capacity - r->capacity;
+    r->containers =
+        roaring_realloc(r->containers, new_capacity * sizeof(container_t *));
+    memset(r->containers + r->capacity, 0, increase * sizeof(container_t *));
+    r->capacity = new_capacity;
+}
+
+static uint64_t next_free_container_idx(const roaring64_bitmap_t *r) {
+    for (uint64_t i = r->first_free + 1; i < r->capacity; ++i) {
+        if (r->containers[i] == NULL) {
+            return i;
+        }
+    }
+    return r->capacity;
+}
+
+static uint64_t allocate_index(roaring64_bitmap_t *r) {
+    uint64_t first_free = r->first_free;
+    if (first_free == r->capacity) {
+        extend_containers(r);
+    }
+    r->first_free = next_free_container_idx(r);
+    return first_free;
+}
+
+static leaf_t add_container(roaring64_bitmap_t *r, container_t *container,
+                            uint8_t typecode) {
+    uint64_t index = allocate_index(r);
+    r->containers[index] = container;
+    return create_leaf(index, typecode);
+}
+
+static void remove_container(roaring64_bitmap_t *r, leaf_t leaf) {
+    uint64_t index = get_index(leaf);
+    r->containers[index] = NULL;
+    if (index < r->first_free) {
+        r->first_free = index;
+    }
+}
+
+// Copies the container referenced by `leaf` from `r1` to `r2`.
+static inline leaf_t copy_leaf_container(const roaring64_bitmap_t *r1,
+                                         roaring64_bitmap_t *r2, leaf_t leaf) {
+    uint8_t typecode = get_typecode(leaf);
+    // get_copy_of_container modifies the typecode passed in.
+    container_t *container = get_copy_of_container(
+        get_container(r1, leaf), &typecode, /*copy_on_write=*/false);
+    return add_container(r2, container, typecode);
+}
 
 static inline int compare_high48(art_key_chunk_t key1[],
                                  art_key_chunk_t key2[]) {
@@ -103,10 +186,10 @@ static inline int compare_high48(art_key_chunk_t key1[],
 static inline bool roaring64_iterator_init_at_leaf_first(
     roaring64_iterator_t *it) {
     it->high48 = combine_key(it->art_it.key, 0);
-    leaf_t *leaf = (leaf_t *)it->art_it.value;
+    leaf_t leaf = (leaf_t)*it->art_it.value;
     uint16_t low16 = 0;
-    it->container_it =
-        container_init_iterator(leaf->container, leaf->typecode, &low16);
+    it->container_it = container_init_iterator(get_container(it->r, leaf),
+                                               get_typecode(leaf), &low16);
     it->value = it->high48 | low16;
     return (it->has_value = true);
 }
@@ -114,18 +197,18 @@ static inline bool roaring64_iterator_init_at_leaf_first(
 static inline bool roaring64_iterator_init_at_leaf_last(
     roaring64_iterator_t *it) {
     it->high48 = combine_key(it->art_it.key, 0);
-    leaf_t *leaf = (leaf_t *)it->art_it.value;
+    leaf_t leaf = (leaf_t)*it->art_it.value;
     uint16_t low16 = 0;
-    it->container_it =
-        container_init_iterator_last(leaf->container, leaf->typecode, &low16);
+    it->container_it = container_init_iterator_last(get_container(it->r, leaf),
+                                                    get_typecode(leaf), &low16);
     it->value = it->high48 | low16;
     return (it->has_value = true);
 }
 
 static inline roaring64_iterator_t *roaring64_iterator_init_at(
     const roaring64_bitmap_t *r, roaring64_iterator_t *it, bool first) {
-    it->parent = r;
-    it->art_it = art_init_iterator(&r->art, first);
+    it->r = r;
+    it->art_it = art_init_iterator((art_t *)&r->art, first);
     it->has_value = it->art_it.value != NULL;
     if (it->has_value) {
         if (first) {
@@ -142,8 +225,11 @@ static inline roaring64_iterator_t *roaring64_iterator_init_at(
 roaring64_bitmap_t *roaring64_bitmap_create(void) {
     roaring64_bitmap_t *r =
         (roaring64_bitmap_t *)roaring_malloc(sizeof(roaring64_bitmap_t));
-    r->art.root = NULL;
+    art_init_cleared(&r->art);
     r->flags = 0;
+    r->capacity = 0;
+    r->first_free = 0;
+    r->containers = NULL;
     return r;
 }
 
@@ -153,26 +239,35 @@ void roaring64_bitmap_free(roaring64_bitmap_t *r) {
     }
     art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
     while (it.value != NULL) {
-        leaf_t *leaf = (leaf_t *)it.value;
-        container_free(leaf->container, leaf->typecode);
-        free_leaf(leaf);
+        leaf_t leaf = (leaf_t)*it.value;
+        if (is_frozen64(r)) {
+            // Only free the container itself, not the buffer-backed contents
+            // within.
+            roaring_free(get_container(r, leaf));
+        } else {
+            container_free(get_container(r, leaf), get_typecode(leaf));
+        }
         art_iterator_next(&it);
     }
-    art_free(&r->art);
+    if (!is_frozen64(r)) {
+        art_free(&r->art);
+    }
+    roaring_free(r->containers);
     roaring_free(r);
 }
 
 roaring64_bitmap_t *roaring64_bitmap_copy(const roaring64_bitmap_t *r) {
     roaring64_bitmap_t *result = roaring64_bitmap_create();
 
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
     while (it.value != NULL) {
-        leaf_t *leaf = (leaf_t *)it.value;
-        uint8_t result_typecode = leaf->typecode;
+        leaf_t leaf = (leaf_t)*it.value;
+        uint8_t result_typecode = get_typecode(leaf);
         container_t *result_container = get_copy_of_container(
-            leaf->container, &result_typecode, /*copy_on_write=*/false);
-        leaf_t *result_leaf = create_leaf(result_container, result_typecode);
-        art_insert(&result->art, it.key, (art_val_t *)result_leaf);
+            get_container(r, leaf), &result_typecode, /*copy_on_write=*/false);
+        leaf_t result_leaf =
+            add_container(result, result_container, result_typecode);
+        art_insert(&result->art, it.key, (art_val_t)result_leaf);
         art_iterator_next(&it);
     }
     return result;
@@ -199,8 +294,8 @@ static void move_from_roaring32_offset(roaring64_bitmap_t *dst,
         uint8_t high48[ART_KEY_BYTES];
         uint64_t high48_bits = key_base | ((uint64_t)key << 16);
         split_key(high48_bits, high48);
-        leaf_t *leaf = create_leaf(container, typecode);
-        art_insert(&dst->art, high48, (art_val_t *)leaf);
+        leaf_t leaf = add_container(dst, container, typecode);
+        art_insert(&dst->art, high48, (art_val_t)leaf);
     }
     // We stole all the containers, so leave behind a size of zero
     src->high_low_container.size = 0;
@@ -242,8 +337,8 @@ roaring64_bitmap_t *roaring64_bitmap_from_range(uint64_t min, uint64_t max,
 
         uint8_t high48[ART_KEY_BYTES];
         split_key(min, high48);
-        leaf_t *leaf = create_leaf(container, typecode);
-        art_insert(&r->art, high48, (art_val_t *)leaf);
+        leaf_t leaf = add_container(r, container, typecode);
+        art_insert(&r->art, high48, (art_val_t)leaf);
 
         uint64_t gap = container_max - container_min + step - 1;
         uint64_t increment = gap - (gap % step);
@@ -267,13 +362,14 @@ static inline leaf_t *containerptr_roaring64_bitmap_add(roaring64_bitmap_t *r,
                                                         uint16_t low16,
                                                         leaf_t *leaf) {
     if (leaf != NULL) {
+        uint8_t typecode = get_typecode(*leaf);
+        container_t *container = get_container(r, *leaf);
         uint8_t typecode2;
         container_t *container2 =
-            container_add(leaf->container, low16, leaf->typecode, &typecode2);
-        if (container2 != leaf->container) {
-            container_free(leaf->container, leaf->typecode);
-            leaf->container = container2;
-            leaf->typecode = typecode2;
+            container_add(container, low16, typecode, &typecode2);
+        if (container2 != container) {
+            container_free(container, typecode);
+            replace_container(r, leaf, container2, typecode2);
         }
         return leaf;
     } else {
@@ -282,9 +378,8 @@ static inline leaf_t *containerptr_roaring64_bitmap_add(roaring64_bitmap_t *r,
         container_t *container =
             container_add(ac, low16, ARRAY_CONTAINER_TYPE, &typecode);
         assert(ac == container);
-        leaf = create_leaf(container, typecode);
-        art_insert(&r->art, high48, (art_val_t *)leaf);
-        return leaf;
+        leaf_t new_leaf = add_container(r, container, typecode);
+        return (leaf_t *)art_insert(&r->art, high48, (art_val_t)new_leaf);
     }
 }
 
@@ -302,12 +397,12 @@ bool roaring64_bitmap_add_checked(roaring64_bitmap_t *r, uint64_t val) {
 
     int old_cardinality = 0;
     if (leaf != NULL) {
-        old_cardinality =
-            container_get_cardinality(leaf->container, leaf->typecode);
+        old_cardinality = container_get_cardinality(get_container(r, *leaf),
+                                                    get_typecode(*leaf));
     }
     leaf = containerptr_roaring64_bitmap_add(r, high48, low16, leaf);
     int new_cardinality =
-        container_get_cardinality(leaf->container, leaf->typecode);
+        container_get_cardinality(get_container(r, *leaf), get_typecode(*leaf));
     return old_cardinality != new_cardinality;
 }
 
@@ -316,22 +411,22 @@ void roaring64_bitmap_add_bulk(roaring64_bitmap_t *r,
                                uint64_t val) {
     uint8_t high48[ART_KEY_BYTES];
     uint16_t low16 = split_key(val, high48);
-    if (context->leaf != NULL &&
-        compare_high48(context->high_bytes, high48) == 0) {
+    leaf_t *leaf = context->leaf;
+    if (leaf != NULL && compare_high48(context->high_bytes, high48) == 0) {
         // We're at a container with the correct high bits.
+        uint8_t typecode1 = get_typecode(*leaf);
+        container_t *container1 = get_container(r, *leaf);
         uint8_t typecode2;
         container_t *container2 =
-            container_add(context->leaf->container, low16,
-                          context->leaf->typecode, &typecode2);
-        if (container2 != context->leaf->container) {
-            container_free(context->leaf->container, context->leaf->typecode);
-            context->leaf->container = container2;
-            context->leaf->typecode = typecode2;
+            container_add(container1, low16, typecode1, &typecode2);
+        if (container2 != container1) {
+            container_free(container1, typecode1);
+            replace_container(r, leaf, container2, typecode2);
         }
     } else {
         // We're not positioned anywhere yet or the high bits of the key
         // differ.
-        leaf_t *leaf = (leaf_t *)art_find(&r->art, high48);
+        leaf = (leaf_t *)art_find(&r->art, high48);
         context->leaf =
             containerptr_roaring64_bitmap_add(r, high48, low16, leaf);
         memcpy(context->high_bytes, high48, ART_KEY_BYTES);
@@ -351,17 +446,19 @@ void roaring64_bitmap_add_many(roaring64_bitmap_t *r, size_t n_args,
     }
 }
 
-static inline void add_range_closed_at(art_t *art, uint8_t *high48,
-                                       uint16_t min, uint16_t max) {
+static inline void add_range_closed_at(roaring64_bitmap_t *r, art_t *art,
+                                       uint8_t *high48, uint16_t min,
+                                       uint16_t max) {
     leaf_t *leaf = (leaf_t *)art_find(art, high48);
     if (leaf != NULL) {
+        uint8_t typecode1 = get_typecode(*leaf);
+        container_t *container1 = get_container(r, *leaf);
         uint8_t typecode2;
-        container_t *container2 = container_add_range(
-            leaf->container, leaf->typecode, min, max, &typecode2);
-        if (container2 != leaf->container) {
-            container_free(leaf->container, leaf->typecode);
-            leaf->container = container2;
-            leaf->typecode = typecode2;
+        container_t *container2 =
+            container_add_range(container1, typecode1, min, max, &typecode2);
+        if (container2 != container1) {
+            container_free(container1, typecode1);
+            replace_container(r, leaf, container2, typecode2);
         }
         return;
     }
@@ -369,8 +466,8 @@ static inline void add_range_closed_at(art_t *art, uint8_t *high48,
     // container_add_range is inclusive, but `container_range_of_ones` is
     // exclusive.
     container_t *container = container_range_of_ones(min, max + 1, &typecode);
-    leaf = create_leaf(container, typecode);
-    art_insert(art, high48, (art_val_t *)leaf);
+    leaf_t new_leaf = add_container(r, container, typecode);
+    art_insert(art, high48, (art_val_t)new_leaf);
 }
 
 void roaring64_bitmap_add_range(roaring64_bitmap_t *r, uint64_t min,
@@ -394,22 +491,22 @@ void roaring64_bitmap_add_range_closed(roaring64_bitmap_t *r, uint64_t min,
     uint16_t max_low16 = split_key(max, max_high48);
     if (compare_high48(min_high48, max_high48) == 0) {
         // Only populate range within one container.
-        add_range_closed_at(art, min_high48, min_low16, max_low16);
+        add_range_closed_at(r, art, min_high48, min_low16, max_low16);
         return;
     }
 
     // Populate a range across containers. Fill intermediate containers
     // entirely.
-    add_range_closed_at(art, min_high48, min_low16, 0xffff);
+    add_range_closed_at(r, art, min_high48, min_low16, 0xffff);
     uint64_t min_high_bits = min >> 16;
     uint64_t max_high_bits = max >> 16;
     for (uint64_t current = min_high_bits + 1; current < max_high_bits;
          ++current) {
         uint8_t current_high48[ART_KEY_BYTES];
         split_key(current << 16, current_high48);
-        add_range_closed_at(art, current_high48, 0, 0xffff);
+        add_range_closed_at(r, art, current_high48, 0, 0xffff);
     }
-    add_range_closed_at(art, max_high48, 0, max_low16);
+    add_range_closed_at(r, art, max_high48, 0, max_low16);
 }
 
 bool roaring64_bitmap_contains(const roaring64_bitmap_t *r, uint64_t val) {
@@ -417,7 +514,8 @@ bool roaring64_bitmap_contains(const roaring64_bitmap_t *r, uint64_t val) {
     uint16_t low16 = split_key(val, high48);
     leaf_t *leaf = (leaf_t *)art_find(&r->art, high48);
     if (leaf != NULL) {
-        return container_contains(leaf->container, low16, leaf->typecode);
+        return container_contains(get_container(r, *leaf), low16,
+                                  get_typecode(*leaf));
     }
     return false;
 }
@@ -434,7 +532,7 @@ bool roaring64_bitmap_contains_range(const roaring64_bitmap_t *r, uint64_t min,
     uint16_t max_low16 = split_key(max, max_high48);
     uint64_t max_high48_bits = (max - 1) & 0xFFFFFFFFFFFF0000;  // Inclusive
 
-    art_iterator_t it = art_lower_bound(&r->art, min_high48);
+    art_iterator_t it = art_lower_bound((art_t *)&r->art, min_high48);
     if (it.value == NULL || combine_key(it.key, 0) > min) {
         return false;
     }
@@ -451,7 +549,7 @@ bool roaring64_bitmap_contains_range(const roaring64_bitmap_t *r, uint64_t min,
             return false;
         }
 
-        leaf_t *leaf = (leaf_t *)it.value;
+        leaf_t leaf = (leaf_t)*it.value;
         uint32_t container_min = 0;
         if (compare_high48(it.key, min_high48) == 0) {
             container_min = min_low16;
@@ -464,11 +562,13 @@ bool roaring64_bitmap_contains_range(const roaring64_bitmap_t *r, uint64_t min,
         // For the first and last containers we use container_contains_range,
         // for the intermediate containers we can use container_is_full.
         if (container_min == 0 && container_max == 0xFFFF + 1) {
-            if (!container_is_full(leaf->container, leaf->typecode)) {
+            if (!container_is_full(get_container(r, leaf),
+                                   get_typecode(leaf))) {
                 return false;
             }
-        } else if (!container_contains_range(leaf->container, container_min,
-                                             container_max, leaf->typecode)) {
+        } else if (!container_contains_range(get_container(r, leaf),
+                                             container_min, container_max,
+                                             get_typecode(leaf))) {
             return false;
         }
         prev_high48_bits = current_high48_bits;
@@ -494,24 +594,24 @@ bool roaring64_bitmap_contains_bulk(const roaring64_bitmap_t *r,
         context->leaf = leaf;
         memcpy(context->high_bytes, high48, ART_KEY_BYTES);
     }
-    return container_contains(context->leaf->container, low16,
-                              context->leaf->typecode);
+    return container_contains(get_container(r, *context->leaf), low16,
+                              get_typecode(*context->leaf));
 }
 
 bool roaring64_bitmap_select(const roaring64_bitmap_t *r, uint64_t rank,
                              uint64_t *element) {
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
     uint64_t start_rank = 0;
     while (it.value != NULL) {
-        leaf_t *leaf = (leaf_t *)it.value;
-        uint64_t cardinality =
-            container_get_cardinality(leaf->container, leaf->typecode);
+        leaf_t leaf = (leaf_t)*it.value;
+        uint64_t cardinality = container_get_cardinality(get_container(r, leaf),
+                                                         get_typecode(leaf));
         if (start_rank + cardinality > rank) {
             uint32_t uint32_start = 0;
             uint32_t uint32_rank = rank - start_rank;
             uint32_t uint32_element = 0;
-            if (container_select(leaf->container, leaf->typecode, &uint32_start,
-                                 uint32_rank, &uint32_element)) {
+            if (container_select(get_container(r, leaf), get_typecode(leaf),
+                                 &uint32_start, uint32_rank, &uint32_element)) {
                 *element = combine_key(it.key, (uint16_t)uint32_element);
                 return true;
             }
@@ -527,16 +627,17 @@ uint64_t roaring64_bitmap_rank(const roaring64_bitmap_t *r, uint64_t val) {
     uint8_t high48[ART_KEY_BYTES];
     uint16_t low16 = split_key(val, high48);
 
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
     uint64_t rank = 0;
     while (it.value != NULL) {
-        leaf_t *leaf = (leaf_t *)it.value;
+        leaf_t leaf = (leaf_t)*it.value;
         int compare_result = compare_high48(it.key, high48);
         if (compare_result < 0) {
-            rank += container_get_cardinality(leaf->container, leaf->typecode);
+            rank += container_get_cardinality(get_container(r, leaf),
+                                              get_typecode(leaf));
         } else if (compare_result == 0) {
-            return rank +
-                   container_rank(leaf->container, leaf->typecode, low16);
+            return rank + container_rank(get_container(r, leaf),
+                                         get_typecode(leaf), low16);
         } else {
             return rank;
         }
@@ -550,16 +651,17 @@ bool roaring64_bitmap_get_index(const roaring64_bitmap_t *r, uint64_t val,
     uint8_t high48[ART_KEY_BYTES];
     uint16_t low16 = split_key(val, high48);
 
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
     uint64_t index = 0;
     while (it.value != NULL) {
-        leaf_t *leaf = (leaf_t *)it.value;
+        leaf_t leaf = (leaf_t)*it.value;
         int compare_result = compare_high48(it.key, high48);
         if (compare_result < 0) {
-            index += container_get_cardinality(leaf->container, leaf->typecode);
+            index += container_get_cardinality(get_container(r, leaf),
+                                               get_typecode(leaf));
         } else if (compare_result == 0) {
-            int index16 =
-                container_get_index(leaf->container, leaf->typecode, low16);
+            int index16 = container_get_index(get_container(r, leaf),
+                                              get_typecode(leaf), low16);
             if (index16 < 0) {
                 return false;
             }
@@ -573,31 +675,31 @@ bool roaring64_bitmap_get_index(const roaring64_bitmap_t *r, uint64_t val,
     return false;
 }
 
-static inline leaf_t *containerptr_roaring64_bitmap_remove(
-    roaring64_bitmap_t *r, uint8_t *high48, uint16_t low16, leaf_t *leaf) {
+// Returns true if a container was removed.
+static inline bool containerptr_roaring64_bitmap_remove(roaring64_bitmap_t *r,
+                                                        uint8_t *high48,
+                                                        uint16_t low16,
+                                                        leaf_t *leaf) {
     if (leaf == NULL) {
-        return NULL;
+        return false;
     }
 
-    container_t *container = leaf->container;
-    uint8_t typecode = leaf->typecode;
+    uint8_t typecode = get_typecode(*leaf);
+    container_t *container = get_container(r, *leaf);
     uint8_t typecode2;
     container_t *container2 =
         container_remove(container, low16, typecode, &typecode2);
     if (container2 != container) {
         container_free(container, typecode);
-        leaf->container = container2;
-        leaf->typecode = typecode2;
+        replace_container(r, leaf, container2, typecode2);
     }
     if (!container_nonzero_cardinality(container2, typecode2)) {
         container_free(container2, typecode2);
-        leaf = (leaf_t *)art_erase(&r->art, high48);
-        if (leaf != NULL) {
-            free_leaf(leaf);
-        }
-        return NULL;
+        bool erased = art_erase(&r->art, high48, (art_val_t *)leaf);
+        assert(erased);
+        return true;
     }
-    return leaf;
+    return false;
 }
 
 void roaring64_bitmap_remove(roaring64_bitmap_t *r, uint64_t val) {
@@ -619,13 +721,12 @@ bool roaring64_bitmap_remove_checked(roaring64_bitmap_t *r, uint64_t val) {
         return false;
     }
     int old_cardinality =
-        container_get_cardinality(leaf->container, leaf->typecode);
-    leaf = containerptr_roaring64_bitmap_remove(r, high48, low16, leaf);
-    if (leaf == NULL) {
+        container_get_cardinality(get_container(r, *leaf), get_typecode(*leaf));
+    if (containerptr_roaring64_bitmap_remove(r, high48, low16, leaf)) {
         return true;
     }
     int new_cardinality =
-        container_get_cardinality(leaf->container, leaf->typecode);
+        container_get_cardinality(get_container(r, *leaf), get_typecode(*leaf));
     return new_cardinality != old_cardinality;
 }
 
@@ -638,26 +739,28 @@ void roaring64_bitmap_remove_bulk(roaring64_bitmap_t *r,
     if (context->leaf != NULL &&
         compare_high48(context->high_bytes, high48) == 0) {
         // We're at a container with the correct high bits.
+        uint8_t typecode = get_typecode(*context->leaf);
+        container_t *container = get_container(r, *context->leaf);
         uint8_t typecode2;
         container_t *container2 =
-            container_remove(context->leaf->container, low16,
-                             context->leaf->typecode, &typecode2);
-        if (container2 != context->leaf->container) {
-            container_free(context->leaf->container, context->leaf->typecode);
-            context->leaf->container = container2;
-            context->leaf->typecode = typecode2;
+            container_remove(container, low16, typecode, &typecode2);
+        if (container2 != container) {
+            container_free(container, typecode);
+            replace_container(r, context->leaf, container2, typecode2);
         }
         if (!container_nonzero_cardinality(container2, typecode2)) {
-            leaf_t *leaf = (leaf_t *)art_erase(art, high48);
             container_free(container2, typecode2);
-            free_leaf(leaf);
+            leaf_t leaf;
+            bool erased = art_erase(art, high48, (art_val_t *)&leaf);
+            assert(erased);
+            remove_container(r, leaf);
         }
     } else {
         // We're not positioned anywhere yet or the high bits of the key
         // differ.
         leaf_t *leaf = (leaf_t *)art_find(art, high48);
-        context->leaf =
-            containerptr_roaring64_bitmap_remove(r, high48, low16, leaf);
+        containerptr_roaring64_bitmap_remove(r, high48, low16, leaf);
+        context->leaf = leaf;
         memcpy(context->high_bytes, high48, ART_KEY_BYTES);
     }
 }
@@ -675,23 +778,26 @@ void roaring64_bitmap_remove_many(roaring64_bitmap_t *r, size_t n_args,
     }
 }
 
-static inline void remove_range_closed_at(art_t *art, uint8_t *high48,
-                                          uint16_t min, uint16_t max) {
+static inline void remove_range_closed_at(roaring64_bitmap_t *r, art_t *art,
+                                          uint8_t *high48, uint16_t min,
+                                          uint16_t max) {
     leaf_t *leaf = (leaf_t *)art_find(art, high48);
     if (leaf == NULL) {
         return;
     }
+    uint8_t typecode = get_typecode(*leaf);
+    container_t *container = get_container(r, *leaf);
     uint8_t typecode2;
-    container_t *container2 = container_remove_range(
-        leaf->container, leaf->typecode, min, max, &typecode2);
-    if (container2 != leaf->container) {
-        container_free(leaf->container, leaf->typecode);
+    container_t *container2 =
+        container_remove_range(container, typecode, min, max, &typecode2);
+    if (container2 != container) {
+        container_free(container, typecode);
         if (container2 != NULL) {
-            leaf->container = container2;
-            leaf->typecode = typecode2;
+            replace_container(r, leaf, container2, typecode2);
         } else {
-            art_erase(art, high48);
-            free_leaf(leaf);
+            bool erased = art_erase(art, high48, NULL);
+            assert(erased);
+            remove_container(r, *leaf);
         }
     }
 }
@@ -717,21 +823,23 @@ void roaring64_bitmap_remove_range_closed(roaring64_bitmap_t *r, uint64_t min,
     uint16_t max_low16 = split_key(max, max_high48);
     if (compare_high48(min_high48, max_high48) == 0) {
         // Only remove a range within one container.
-        remove_range_closed_at(art, min_high48, min_low16, max_low16);
+        remove_range_closed_at(r, art, min_high48, min_low16, max_low16);
         return;
     }
 
     // Remove a range across containers. Remove intermediate containers
     // entirely.
-    remove_range_closed_at(art, min_high48, min_low16, 0xffff);
+    remove_range_closed_at(r, art, min_high48, min_low16, 0xffff);
 
     art_iterator_t it = art_upper_bound(art, min_high48);
     while (it.value != NULL && art_compare_keys(it.key, max_high48) < 0) {
-        leaf_t *leaf = (leaf_t *)art_iterator_erase(art, &it);
-        container_free(leaf->container, leaf->typecode);
-        free_leaf(leaf);
+        leaf_t leaf;
+        bool erased = art_iterator_erase(&it, (art_val_t *)&leaf);
+        assert(erased);
+        container_free(get_container(r, leaf), get_typecode(leaf));
+        remove_container(r, leaf);
     }
-    remove_range_closed_at(art, max_high48, 0, max_low16);
+    remove_range_closed_at(r, art, max_high48, 0, max_low16);
 }
 
 void roaring64_bitmap_clear(roaring64_bitmap_t *r) {
@@ -739,12 +847,12 @@ void roaring64_bitmap_clear(roaring64_bitmap_t *r) {
 }
 
 uint64_t roaring64_bitmap_get_cardinality(const roaring64_bitmap_t *r) {
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
     uint64_t cardinality = 0;
     while (it.value != NULL) {
-        leaf_t *leaf = (leaf_t *)it.value;
-        cardinality +=
-            container_get_cardinality(leaf->container, leaf->typecode);
+        leaf_t leaf = (leaf_t)*it.value;
+        cardinality += container_get_cardinality(get_container(r, leaf),
+                                                 get_typecode(leaf));
         art_iterator_next(&it);
     }
     return cardinality;
@@ -773,7 +881,7 @@ uint64_t roaring64_bitmap_range_closed_cardinality(const roaring64_bitmap_t *r,
     uint8_t max_high48[ART_KEY_BYTES];
     uint16_t max_low16 = split_key(max, max_high48);
 
-    art_iterator_t it = art_lower_bound(&r->art, min_high48);
+    art_iterator_t it = art_lower_bound((art_t *)&r->art, min_high48);
     while (it.value != NULL) {
         int max_compare_result = compare_high48(it.key, max_high48);
         if (max_compare_result > 0) {
@@ -781,23 +889,22 @@ uint64_t roaring64_bitmap_range_closed_cardinality(const roaring64_bitmap_t *r,
             break;
         }
 
-        leaf_t *leaf = (leaf_t *)it.value;
+        leaf_t leaf = (leaf_t)*it.value;
+        uint8_t typecode = get_typecode(leaf);
+        container_t *container = get_container(r, leaf);
         if (max_compare_result == 0) {
             // We're at the max high key, add only the range up to the low
             // 16 bits of max.
-            cardinality +=
-                container_rank(leaf->container, leaf->typecode, max_low16);
+            cardinality += container_rank(container, typecode, max_low16);
         } else {
             // We're not yet at the max high key, add the full container
             // range.
-            cardinality +=
-                container_get_cardinality(leaf->container, leaf->typecode);
+            cardinality += container_get_cardinality(container, typecode);
         }
         if (compare_high48(it.key, min_high48) == 0 && min_low16 > 0) {
             // We're at the min high key, remove the range up to the low 16
             // bits of min.
-            cardinality -=
-                container_rank(leaf->container, leaf->typecode, min_low16 - 1);
+            cardinality -= container_rank(container, typecode, min_low16 - 1);
         }
         art_iterator_next(&it);
     }
@@ -809,23 +916,23 @@ bool roaring64_bitmap_is_empty(const roaring64_bitmap_t *r) {
 }
 
 uint64_t roaring64_bitmap_minimum(const roaring64_bitmap_t *r) {
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
     if (it.value == NULL) {
         return UINT64_MAX;
     }
-    leaf_t *leaf = (leaf_t *)it.value;
-    return combine_key(it.key,
-                       container_minimum(leaf->container, leaf->typecode));
+    leaf_t leaf = (leaf_t)*it.value;
+    return combine_key(
+        it.key, container_minimum(get_container(r, leaf), get_typecode(leaf)));
 }
 
 uint64_t roaring64_bitmap_maximum(const roaring64_bitmap_t *r) {
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/false);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/false);
     if (it.value == NULL) {
         return 0;
     }
-    leaf_t *leaf = (leaf_t *)it.value;
-    return combine_key(it.key,
-                       container_maximum(leaf->container, leaf->typecode));
+    leaf_t leaf = (leaf_t)*it.value;
+    return combine_key(
+        it.key, container_maximum(get_container(r, leaf), get_typecode(leaf)));
 }
 
 bool roaring64_bitmap_run_optimize(roaring64_bitmap_t *r) {
@@ -836,15 +943,53 @@ bool roaring64_bitmap_run_optimize(roaring64_bitmap_t *r) {
         uint8_t new_typecode;
         // We don't need to free the existing container if a new one was
         // created, convert_run_optimize does that internally.
-        leaf->container = convert_run_optimize(leaf->container, leaf->typecode,
-                                               &new_typecode);
-        leaf->typecode = new_typecode;
+        container_t *new_container = convert_run_optimize(
+            get_container(r, *leaf), get_typecode(*leaf), &new_typecode);
+        replace_container(r, leaf, new_container, new_typecode);
         has_run_container |= new_typecode == RUN_CONTAINER_TYPE;
         art_iterator_next(&it);
     }
     return has_run_container;
 }
 
+static void move_to_shrink(roaring64_bitmap_t *r, leaf_t *leaf) {
+    uint64_t idx = get_index(*leaf);
+    if (idx < r->first_free) {
+        return;
+    }
+    r->containers[r->first_free] = get_container(r, *leaf);
+    r->containers[idx] = NULL;
+    *leaf = create_leaf(r->first_free, get_typecode(*leaf));
+    r->first_free = next_free_container_idx(r);
+}
+
+static inline bool is_shrunken(const roaring64_bitmap_t *r) {
+    return art_is_shrunken(&r->art) && r->first_free == r->capacity;
+}
+
+size_t roaring64_bitmap_shrink_to_fit(roaring64_bitmap_t *r) {
+    size_t freed = art_shrink_to_fit(&r->art);
+    art_iterator_t it = art_init_iterator(&r->art, true);
+    while (it.value != NULL) {
+        leaf_t *leaf = (leaf_t *)it.value;
+        freed += container_shrink_to_fit(get_container(r, *leaf),
+                                         get_typecode(*leaf));
+        move_to_shrink(r, leaf);
+        art_iterator_next(&it);
+    }
+    if (is_shrunken(r)) {
+        return freed;
+    }
+    uint64_t new_capacity = r->first_free;
+    if (new_capacity < r->capacity) {
+        r->containers = roaring_realloc(r->containers,
+                                        new_capacity * sizeof(container_t *));
+        freed += (r->capacity - new_capacity) * sizeof(container_t *);
+        r->capacity = new_capacity;
+    }
+    return freed;
+}
+
 /**
  *  (For advanced users.)
  * Collect statistics about the bitmap
@@ -855,15 +1000,16 @@ void roaring64_bitmap_statistics(const roaring64_bitmap_t *r,
     stat->min_value = roaring64_bitmap_minimum(r);
     stat->max_value = roaring64_bitmap_maximum(r);
 
-    art_iterator_t it = art_init_iterator(&r->art, true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, true);
     while (it.value != NULL) {
-        leaf_t *leaf = (leaf_t *)it.value;
+        leaf_t leaf = (leaf_t)*it.value;
         stat->n_containers++;
-        uint8_t truetype = get_container_type(leaf->container, leaf->typecode);
-        uint32_t card =
-            container_get_cardinality(leaf->container, leaf->typecode);
+        uint8_t truetype =
+            get_container_type(get_container(r, leaf), get_typecode(leaf));
+        uint32_t card = container_get_cardinality(get_container(r, leaf),
+                                                  get_typecode(leaf));
         uint32_t sbytes =
-            container_size_in_bytes(leaf->container, leaf->typecode);
+            container_size_in_bytes(get_container(r, leaf), get_typecode(leaf));
         stat->cardinality += card;
         switch (truetype) {
             case BITSET_CONTAINER_TYPE:
@@ -889,31 +1035,34 @@ void roaring64_bitmap_statistics(const roaring64_bitmap_t *r,
     }
 }
 
-static bool roaring64_leaf_internal_validate(const art_val_t *val,
-                                             const char **reason) {
-    leaf_t *leaf = (leaf_t *)val;
-    return container_internal_validate(leaf->container, leaf->typecode, reason);
+static bool roaring64_leaf_internal_validate(const art_val_t val,
+                                             const char **reason,
+                                             void *context) {
+    leaf_t leaf = (leaf_t)val;
+    roaring64_bitmap_t *r = (roaring64_bitmap_t *)context;
+    return container_internal_validate(get_container(r, leaf),
+                                       get_typecode(leaf), reason);
 }
 
 bool roaring64_bitmap_internal_validate(const roaring64_bitmap_t *r,
                                         const char **reason) {
     return art_internal_validate(&r->art, reason,
-                                 roaring64_leaf_internal_validate);
+                                 roaring64_leaf_internal_validate, (void *)r);
 }
 
 bool roaring64_bitmap_equals(const roaring64_bitmap_t *r1,
                              const roaring64_bitmap_t *r2) {
-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL && it2.value != NULL) {
         if (compare_high48(it1.key, it2.key) != 0) {
             return false;
         }
-        leaf_t *leaf1 = (leaf_t *)it1.value;
-        leaf_t *leaf2 = (leaf_t *)it2.value;
-        if (!container_equals(leaf1->container, leaf1->typecode,
-                              leaf2->container, leaf2->typecode)) {
+        leaf_t leaf1 = (leaf_t)*it1.value;
+        leaf_t leaf2 = (leaf_t)*it2.value;
+        if (!container_equals(get_container(r1, leaf1), get_typecode(leaf1),
+                              get_container(r2, leaf2), get_typecode(leaf2))) {
             return false;
         }
         art_iterator_next(&it1);
@@ -924,8 +1073,8 @@ bool roaring64_bitmap_equals(const roaring64_bitmap_t *r1,
 
 bool roaring64_bitmap_is_subset(const roaring64_bitmap_t *r1,
                                 const roaring64_bitmap_t *r2) {
-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL) {
         bool it2_present = it2.value != NULL;
@@ -934,10 +1083,11 @@ bool roaring64_bitmap_is_subset(const roaring64_bitmap_t *r1,
         if (it2_present) {
             compare_result = compare_high48(it1.key, it2.key);
             if (compare_result == 0) {
-                leaf_t *leaf1 = (leaf_t *)it1.value;
-                leaf_t *leaf2 = (leaf_t *)it2.value;
-                if (!container_is_subset(leaf1->container, leaf1->typecode,
-                                         leaf2->container, leaf2->typecode)) {
+                leaf_t leaf1 = (leaf_t)*it1.value;
+                leaf_t leaf2 = (leaf_t)*it2.value;
+                if (!container_is_subset(
+                        get_container(r1, leaf1), get_typecode(leaf1),
+                        get_container(r2, leaf2), get_typecode(leaf2))) {
                     return false;
                 }
                 art_iterator_next(&it1);
@@ -964,8 +1114,8 @@ roaring64_bitmap_t *roaring64_bitmap_and(const roaring64_bitmap_t *r1,
                                          const roaring64_bitmap_t *r2) {
     roaring64_bitmap_t *result = roaring64_bitmap_create();
 
-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL && it2.value != NULL) {
         // Cases:
@@ -975,19 +1125,20 @@ roaring64_bitmap_t *roaring64_bitmap_and(const roaring64_bitmap_t *r1,
         int compare_result = compare_high48(it1.key, it2.key);
         if (compare_result == 0) {
             // Case 2: iterators at the same high key position.
-            leaf_t *result_leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));
-            leaf_t *leaf1 = (leaf_t *)it1.value;
-            leaf_t *leaf2 = (leaf_t *)it2.value;
-            result_leaf->container = container_and(
-                leaf1->container, leaf1->typecode, leaf2->container,
-                leaf2->typecode, &result_leaf->typecode);
-
-            if (container_nonzero_cardinality(result_leaf->container,
-                                              result_leaf->typecode)) {
-                art_insert(&result->art, it1.key, (art_val_t *)result_leaf);
+            leaf_t leaf1 = (leaf_t)*it1.value;
+            leaf_t leaf2 = (leaf_t)*it2.value;
+            uint8_t result_typecode;
+            container_t *result_container =
+                container_and(get_container(r1, leaf1), get_typecode(leaf1),
+                              get_container(r2, leaf2), get_typecode(leaf2),
+                              &result_typecode);
+            if (container_nonzero_cardinality(result_container,
+                                              result_typecode)) {
+                leaf_t result_leaf =
+                    add_container(result, result_container, result_typecode);
+                art_insert(&result->art, it1.key, (art_val_t)result_leaf);
             } else {
-                container_free(result_leaf->container, result_leaf->typecode);
-                free_leaf(result_leaf);
+                container_free(result_container, result_typecode);
             }
             art_iterator_next(&it1);
             art_iterator_next(&it2);
@@ -1006,8 +1157,8 @@ uint64_t roaring64_bitmap_and_cardinality(const roaring64_bitmap_t *r1,
                                           const roaring64_bitmap_t *r2) {
     uint64_t result = 0;
 
-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL && it2.value != NULL) {
         // Cases:
@@ -1017,11 +1168,11 @@ uint64_t roaring64_bitmap_and_cardinality(const roaring64_bitmap_t *r1,
         int compare_result = compare_high48(it1.key, it2.key);
         if (compare_result == 0) {
             // Case 2: iterators at the same high key position.
-            leaf_t *leaf1 = (leaf_t *)it1.value;
-            leaf_t *leaf2 = (leaf_t *)it2.value;
-            result +=
-                container_and_cardinality(leaf1->container, leaf1->typecode,
-                                          leaf2->container, leaf2->typecode);
+            leaf_t leaf1 = (leaf_t)*it1.value;
+            leaf_t leaf2 = (leaf_t)*it2.value;
+            result += container_and_cardinality(
+                get_container(r1, leaf1), get_typecode(leaf1),
+                get_container(r2, leaf2), get_typecode(leaf2));
             art_iterator_next(&it1);
             art_iterator_next(&it2);
         } else if (compare_result < 0) {
@@ -1042,7 +1193,7 @@ void roaring64_bitmap_and_inplace(roaring64_bitmap_t *r1,
         return;
     }
     art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL) {
         // Cases:
@@ -1058,7 +1209,7 @@ void roaring64_bitmap_and_inplace(roaring64_bitmap_t *r1,
             if (compare_result == 0) {
                 // Case 2a: iterators at the same high key position.
                 leaf_t *leaf1 = (leaf_t *)it1.value;
-                leaf_t *leaf2 = (leaf_t *)it2.value;
+                leaf_t leaf2 = (leaf_t)*it2.value;
 
                 // We do the computation "in place" only when c1 is not a
                 // shared container. Rationale: using a shared container
@@ -1066,28 +1217,31 @@ void roaring64_bitmap_and_inplace(roaring64_bitmap_t *r1,
                 // copy and then doing the computation in place which is
                 // likely less efficient than avoiding in place entirely and
                 // always generating a new container.
+                uint8_t typecode = get_typecode(*leaf1);
+                container_t *container = get_container(r1, *leaf1);
                 uint8_t typecode2;
                 container_t *container2;
-                if (leaf1->typecode == SHARED_CONTAINER_TYPE) {
-                    container2 = container_and(
-                        leaf1->container, leaf1->typecode, leaf2->container,
-                        leaf2->typecode, &typecode2);
+                if (typecode == SHARED_CONTAINER_TYPE) {
+                    container2 = container_and(container, typecode,
+                                               get_container(r2, leaf2),
+                                               get_typecode(leaf2), &typecode2);
                 } else {
                     container2 = container_iand(
-                        leaf1->container, leaf1->typecode, leaf2->container,
-                        leaf2->typecode, &typecode2);
+                        container, typecode, get_container(r2, leaf2),
+                        get_typecode(leaf2), &typecode2);
                 }
 
-                if (container2 != leaf1->container) {
-                    container_free(leaf1->container, leaf1->typecode);
-                    leaf1->container = container2;
-                    leaf1->typecode = typecode2;
+                if (container2 != container) {
+                    container_free(container, typecode);
                 }
                 if (!container_nonzero_cardinality(container2, typecode2)) {
                     container_free(container2, typecode2);
-                    art_iterator_erase(&r1->art, &it1);
-                    free_leaf(leaf1);
+                    art_iterator_erase(&it1, NULL);
+                    remove_container(r1, *leaf1);
                 } else {
+                    if (container2 != container) {
+                        replace_container(r1, leaf1, container2, typecode2);
+                    }
                     // Only advance the iterator if we didn't delete the
                     // leaf, as erasing advances by itself.
                     art_iterator_next(&it1);
@@ -1098,10 +1252,11 @@ void roaring64_bitmap_and_inplace(roaring64_bitmap_t *r1,
 
         if (!it2_present || compare_result < 0) {
             // Cases 1 and 3a: it1 is the only iterator or is before it2.
-            leaf_t *leaf = (leaf_t *)art_iterator_erase(&r1->art, &it1);
-            assert(leaf != NULL);
-            container_free(leaf->container, leaf->typecode);
-            free_leaf(leaf);
+            leaf_t leaf;
+            bool erased = art_iterator_erase(&it1, (art_val_t *)&leaf);
+            assert(erased);
+            container_free(get_container(r1, leaf), get_typecode(leaf));
+            remove_container(r1, leaf);
         } else if (compare_result > 0) {
             // Case 2c: it1 is after it2.
             art_iterator_lower_bound(&it2, it1.key);
@@ -1112,8 +1267,8 @@ void roaring64_bitmap_and_inplace(roaring64_bitmap_t *r1,
 bool roaring64_bitmap_intersect(const roaring64_bitmap_t *r1,
                                 const roaring64_bitmap_t *r2) {
     bool intersect = false;
-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL && it2.value != NULL) {
         // Cases:
@@ -1123,10 +1278,11 @@ bool roaring64_bitmap_intersect(const roaring64_bitmap_t *r1,
         int compare_result = compare_high48(it1.key, it2.key);
         if (compare_result == 0) {
             // Case 2: iterators at the same high key position.
-            leaf_t *leaf1 = (leaf_t *)it1.value;
-            leaf_t *leaf2 = (leaf_t *)it2.value;
-            intersect |= container_intersect(leaf1->container, leaf1->typecode,
-                                             leaf2->container, leaf2->typecode);
+            leaf_t leaf1 = (leaf_t)*it1.value;
+            leaf_t leaf2 = (leaf_t)*it2.value;
+            intersect |= container_intersect(
+                get_container(r1, leaf1), get_typecode(leaf1),
+                get_container(r2, leaf2), get_typecode(leaf2));
             art_iterator_next(&it1);
             art_iterator_next(&it2);
         } else if (compare_result < 0) {
@@ -1166,8 +1322,8 @@ roaring64_bitmap_t *roaring64_bitmap_or(const roaring64_bitmap_t *r1,
                                         const roaring64_bitmap_t *r2) {
     roaring64_bitmap_t *result = roaring64_bitmap_create();
 
-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL || it2.value != NULL) {
         bool it1_present = it1.value != NULL;
@@ -1185,26 +1341,31 @@ roaring64_bitmap_t *roaring64_bitmap_or(const roaring64_bitmap_t *r1,
             compare_result = compare_high48(it1.key, it2.key);
             if (compare_result == 0) {
                 // Case 3b: iterators at the same high key position.
-                leaf_t *leaf1 = (leaf_t *)it1.value;
-                leaf_t *leaf2 = (leaf_t *)it2.value;
-                leaf_t *result_leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));
-                result_leaf->container = container_or(
-                    leaf1->container, leaf1->typecode, leaf2->container,
-                    leaf2->typecode, &result_leaf->typecode);
-                art_insert(&result->art, it1.key, (art_val_t *)result_leaf);
+                leaf_t leaf1 = (leaf_t)*it1.value;
+                leaf_t leaf2 = (leaf_t)*it2.value;
+                uint8_t result_typecode;
+                container_t *result_container =
+                    container_or(get_container(r1, leaf1), get_typecode(leaf1),
+                                 get_container(r2, leaf2), get_typecode(leaf2),
+                                 &result_typecode);
+                leaf_t result_leaf =
+                    add_container(result, result_container, result_typecode);
+                art_insert(&result->art, it1.key, (art_val_t)result_leaf);
                 art_iterator_next(&it1);
                 art_iterator_next(&it2);
             }
         }
         if ((it1_present && !it2_present) || compare_result < 0) {
             // Cases 1 and 3a: it1 is the only iterator or is before it2.
-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it1.value);
-            art_insert(&result->art, it1.key, (art_val_t *)result_leaf);
+            leaf_t result_leaf =
+                copy_leaf_container(r1, result, (leaf_t)*it1.value);
+            art_insert(&result->art, it1.key, (art_val_t)result_leaf);
             art_iterator_next(&it1);
         } else if ((!it1_present && it2_present) || compare_result > 0) {
             // Cases 2 and 3c: it2 is the only iterator or is before it1.
-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it2.value);
-            art_insert(&result->art, it2.key, (art_val_t *)result_leaf);
+            leaf_t result_leaf =
+                copy_leaf_container(r2, result, (leaf_t)*it2.value);
+            art_insert(&result->art, it2.key, (art_val_t)result_leaf);
             art_iterator_next(&it2);
         }
     }
@@ -1225,7 +1386,7 @@ void roaring64_bitmap_or_inplace(roaring64_bitmap_t *r1,
         return;
     }
     art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL || it2.value != NULL) {
         bool it1_present = it1.value != NULL;
@@ -1244,22 +1405,23 @@ void roaring64_bitmap_or_inplace(roaring64_bitmap_t *r1,
             if (compare_result == 0) {
                 // Case 3b: iterators at the same high key position.
                 leaf_t *leaf1 = (leaf_t *)it1.value;
-                leaf_t *leaf2 = (leaf_t *)it2.value;
+                leaf_t leaf2 = (leaf_t)*it2.value;
+                uint8_t typecode1 = get_typecode(*leaf1);
+                container_t *container1 = get_container(r1, *leaf1);
                 uint8_t typecode2;
                 container_t *container2;
-                if (leaf1->typecode == SHARED_CONTAINER_TYPE) {
-                    container2 = container_or(leaf1->container, leaf1->typecode,
-                                              leaf2->container, leaf2->typecode,
-                                              &typecode2);
+                if (get_typecode(*leaf1) == SHARED_CONTAINER_TYPE) {
+                    container2 = container_or(container1, typecode1,
+                                              get_container(r2, leaf2),
+                                              get_typecode(leaf2), &typecode2);
                 } else {
-                    container2 = container_ior(
-                        leaf1->container, leaf1->typecode, leaf2->container,
-                        leaf2->typecode, &typecode2);
+                    container2 = container_ior(container1, typecode1,
+                                               get_container(r2, leaf2),
+                                               get_typecode(leaf2), &typecode2);
                 }
-                if (container2 != leaf1->container) {
-                    container_free(leaf1->container, leaf1->typecode);
-                    leaf1->container = container2;
-                    leaf1->typecode = typecode2;
+                if (container2 != container1) {
+                    container_free(container1, typecode1);
+                    replace_container(r1, leaf1, container2, typecode2);
                 }
                 art_iterator_next(&it1);
                 art_iterator_next(&it2);
@@ -1270,9 +1432,9 @@ void roaring64_bitmap_or_inplace(roaring64_bitmap_t *r1,
             art_iterator_next(&it1);
         } else if ((!it1_present && it2_present) || compare_result > 0) {
             // Cases 2 and 3c: it2 is the only iterator or is before it1.
-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it2.value);
-            art_iterator_insert(&r1->art, &it1, it2.key,
-                                (art_val_t *)result_leaf);
+            leaf_t result_leaf =
+                copy_leaf_container(r2, r1, (leaf_t)*it2.value);
+            art_iterator_insert(&it1, it2.key, (art_val_t)result_leaf);
             art_iterator_next(&it2);
         }
     }
@@ -1282,8 +1444,8 @@ roaring64_bitmap_t *roaring64_bitmap_xor(const roaring64_bitmap_t *r1,
                                          const roaring64_bitmap_t *r2) {
     roaring64_bitmap_t *result = roaring64_bitmap_create();
 
-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL || it2.value != NULL) {
         bool it1_present = it1.value != NULL;
@@ -1301,19 +1463,20 @@ roaring64_bitmap_t *roaring64_bitmap_xor(const roaring64_bitmap_t *r1,
             compare_result = compare_high48(it1.key, it2.key);
             if (compare_result == 0) {
                 // Case 3b: iterators at the same high key position.
-                leaf_t *leaf1 = (leaf_t *)it1.value;
-                leaf_t *leaf2 = (leaf_t *)it2.value;
-                leaf_t *result_leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));
-                result_leaf->container = container_xor(
-                    leaf1->container, leaf1->typecode, leaf2->container,
-                    leaf2->typecode, &result_leaf->typecode);
-                if (container_nonzero_cardinality(result_leaf->container,
-                                                  result_leaf->typecode)) {
-                    art_insert(&result->art, it1.key, (art_val_t *)result_leaf);
+                leaf_t leaf1 = (leaf_t)*it1.value;
+                leaf_t leaf2 = (leaf_t)*it2.value;
+                uint8_t result_typecode;
+                container_t *result_container =
+                    container_xor(get_container(r1, leaf1), get_typecode(leaf1),
+                                  get_container(r2, leaf2), get_typecode(leaf2),
+                                  &result_typecode);
+                if (container_nonzero_cardinality(result_container,
+                                                  result_typecode)) {
+                    leaf_t result_leaf = add_container(result, result_container,
+                                                       result_typecode);
+                    art_insert(&result->art, it1.key, (art_val_t)result_leaf);
                 } else {
-                    container_free(result_leaf->container,
-                                   result_leaf->typecode);
-                    free_leaf(result_leaf);
+                    container_free(result_container, result_typecode);
                 }
                 art_iterator_next(&it1);
                 art_iterator_next(&it2);
@@ -1321,13 +1484,15 @@ roaring64_bitmap_t *roaring64_bitmap_xor(const roaring64_bitmap_t *r1,
         }
         if ((it1_present && !it2_present) || compare_result < 0) {
             // Cases 1 and 3a: it1 is the only iterator or is before it2.
-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it1.value);
-            art_insert(&result->art, it1.key, (art_val_t *)result_leaf);
+            leaf_t result_leaf =
+                copy_leaf_container(r1, result, (leaf_t)*it1.value);
+            art_insert(&result->art, it1.key, (art_val_t)result_leaf);
             art_iterator_next(&it1);
         } else if ((!it1_present && it2_present) || compare_result > 0) {
             // Cases 2 and 3c: it2 is the only iterator or is before it1.
-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it2.value);
-            art_insert(&result->art, it2.key, (art_val_t *)result_leaf);
+            leaf_t result_leaf =
+                copy_leaf_container(r2, result, (leaf_t)*it2.value);
+            art_insert(&result->art, it2.key, (art_val_t)result_leaf);
             art_iterator_next(&it2);
         }
     }
@@ -1346,7 +1511,7 @@ void roaring64_bitmap_xor_inplace(roaring64_bitmap_t *r1,
                                   const roaring64_bitmap_t *r2) {
     assert(r1 != r2);
     art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL || it2.value != NULL) {
         bool it1_present = it1.value != NULL;
@@ -1365,15 +1530,15 @@ void roaring64_bitmap_xor_inplace(roaring64_bitmap_t *r1,
             if (compare_result == 0) {
                 // Case 3b: iterators at the same high key position.
                 leaf_t *leaf1 = (leaf_t *)it1.value;
-                leaf_t *leaf2 = (leaf_t *)it2.value;
-                container_t *container1 = leaf1->container;
-                uint8_t typecode1 = leaf1->typecode;
+                leaf_t leaf2 = (leaf_t)*it2.value;
+                uint8_t typecode1 = get_typecode(*leaf1);
+                container_t *container1 = get_container(r1, *leaf1);
                 uint8_t typecode2;
                 container_t *container2;
-                if (leaf1->typecode == SHARED_CONTAINER_TYPE) {
-                    container2 = container_xor(
-                        leaf1->container, leaf1->typecode, leaf2->container,
-                        leaf2->typecode, &typecode2);
+                if (typecode1 == SHARED_CONTAINER_TYPE) {
+                    container2 = container_xor(container1, typecode1,
+                                               get_container(r2, leaf2),
+                                               get_typecode(leaf2), &typecode2);
                     if (container2 != container1) {
                         // We only free when doing container_xor, not
                         // container_ixor, as ixor frees the original
@@ -1382,17 +1547,19 @@ void roaring64_bitmap_xor_inplace(roaring64_bitmap_t *r1,
                     }
                 } else {
                     container2 = container_ixor(
-                        leaf1->container, leaf1->typecode, leaf2->container,
-                        leaf2->typecode, &typecode2);
+                        container1, typecode1, get_container(r2, leaf2),
+                        get_typecode(leaf2), &typecode2);
                 }
-                leaf1->container = container2;
-                leaf1->typecode = typecode2;
 
                 if (!container_nonzero_cardinality(container2, typecode2)) {
                     container_free(container2, typecode2);
-                    art_iterator_erase(&r1->art, &it1);
-                    free_leaf(leaf1);
+                    bool erased = art_iterator_erase(&it1, NULL);
+                    assert(erased);
+                    remove_container(r1, *leaf1);
                 } else {
+                    if (container2 != container1) {
+                        replace_container(r1, leaf1, container2, typecode2);
+                    }
                     // Only advance the iterator if we didn't delete the
                     // leaf, as erasing advances by itself.
                     art_iterator_next(&it1);
@@ -1405,13 +1572,13 @@ void roaring64_bitmap_xor_inplace(roaring64_bitmap_t *r1,
             art_iterator_next(&it1);
         } else if ((!it1_present && it2_present) || compare_result > 0) {
             // Cases 2 and 3c: it2 is the only iterator or is before it1.
-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it2.value);
+            leaf_t result_leaf =
+                copy_leaf_container(r2, r1, (leaf_t)*it2.value);
             if (it1_present) {
-                art_iterator_insert(&r1->art, &it1, it2.key,
-                                    (art_val_t *)result_leaf);
+                art_iterator_insert(&it1, it2.key, (art_val_t)result_leaf);
                 art_iterator_next(&it1);
             } else {
-                art_insert(&r1->art, it2.key, (art_val_t *)result_leaf);
+                art_insert(&r1->art, it2.key, (art_val_t)result_leaf);
             }
             art_iterator_next(&it2);
         }
@@ -1422,8 +1589,8 @@ roaring64_bitmap_t *roaring64_bitmap_andnot(const roaring64_bitmap_t *r1,
                                             const roaring64_bitmap_t *r2) {
     roaring64_bitmap_t *result = roaring64_bitmap_create();
 
-    art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it1 = art_init_iterator((art_t *)&r1->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL) {
         // Cases:
@@ -1438,20 +1605,21 @@ roaring64_bitmap_t *roaring64_bitmap_andnot(const roaring64_bitmap_t *r1,
             compare_result = compare_high48(it1.key, it2.key);
             if (compare_result == 0) {
                 // Case 2b: iterators at the same high key position.
-                leaf_t *result_leaf = (leaf_t *)roaring_malloc(sizeof(leaf_t));
                 leaf_t *leaf1 = (leaf_t *)it1.value;
-                leaf_t *leaf2 = (leaf_t *)it2.value;
-                result_leaf->container = container_andnot(
-                    leaf1->container, leaf1->typecode, leaf2->container,
-                    leaf2->typecode, &result_leaf->typecode);
-
-                if (container_nonzero_cardinality(result_leaf->container,
-                                                  result_leaf->typecode)) {
-                    art_insert(&result->art, it1.key, (art_val_t *)result_leaf);
+                leaf_t leaf2 = (leaf_t)*it2.value;
+                uint8_t result_typecode;
+                container_t *result_container = container_andnot(
+                    get_container(r1, *leaf1), get_typecode(*leaf1),
+                    get_container(r2, leaf2), get_typecode(leaf2),
+                    &result_typecode);
+
+                if (container_nonzero_cardinality(result_container,
+                                                  result_typecode)) {
+                    leaf_t result_leaf = add_container(result, result_container,
+                                                       result_typecode);
+                    art_insert(&result->art, it1.key, (art_val_t)result_leaf);
                 } else {
-                    container_free(result_leaf->container,
-                                   result_leaf->typecode);
-                    free_leaf(result_leaf);
+                    container_free(result_container, result_typecode);
                 }
                 art_iterator_next(&it1);
                 art_iterator_next(&it2);
@@ -1459,8 +1627,9 @@ roaring64_bitmap_t *roaring64_bitmap_andnot(const roaring64_bitmap_t *r1,
         }
         if (!it2_present || compare_result < 0) {
             // Cases 1 and 2a: it1 is the only iterator or is before it2.
-            leaf_t *result_leaf = copy_leaf_container((leaf_t *)it1.value);
-            art_insert(&result->art, it1.key, (art_val_t *)result_leaf);
+            leaf_t result_leaf =
+                copy_leaf_container(r1, result, (leaf_t)*it1.value);
+            art_insert(&result->art, it1.key, (art_val_t)result_leaf);
             art_iterator_next(&it1);
         } else if (compare_result > 0) {
             // Case 2c: it1 is after it2.
@@ -1480,7 +1649,7 @@ uint64_t roaring64_bitmap_andnot_cardinality(const roaring64_bitmap_t *r1,
 void roaring64_bitmap_andnot_inplace(roaring64_bitmap_t *r1,
                                      const roaring64_bitmap_t *r2) {
     art_iterator_t it1 = art_init_iterator(&r1->art, /*first=*/true);
-    art_iterator_t it2 = art_init_iterator(&r2->art, /*first=*/true);
+    art_iterator_t it2 = art_init_iterator((art_t *)&r2->art, /*first=*/true);
 
     while (it1.value != NULL) {
         // Cases:
@@ -1496,15 +1665,15 @@ void roaring64_bitmap_andnot_inplace(roaring64_bitmap_t *r1,
             if (compare_result == 0) {
                 // Case 2b: iterators at the same high key position.
                 leaf_t *leaf1 = (leaf_t *)it1.value;
-                leaf_t *leaf2 = (leaf_t *)it2.value;
-                container_t *container1 = leaf1->container;
-                uint8_t typecode1 = leaf1->typecode;
+                leaf_t leaf2 = (leaf_t)*it2.value;
+                uint8_t typecode1 = get_typecode(*leaf1);
+                container_t *container1 = get_container(r1, *leaf1);
                 uint8_t typecode2;
                 container_t *container2;
-                if (leaf1->typecode == SHARED_CONTAINER_TYPE) {
+                if (typecode1 == SHARED_CONTAINER_TYPE) {
                     container2 = container_andnot(
-                        leaf1->container, leaf1->typecode, leaf2->container,
-                        leaf2->typecode, &typecode2);
+                        container1, typecode1, get_container(r2, leaf2),
+                        get_typecode(leaf2), &typecode2);
                     if (container2 != container1) {
                         // We only free when doing container_andnot, not
                         // container_iandnot, as iandnot frees the original
@@ -1513,19 +1682,19 @@ void roaring64_bitmap_andnot_inplace(roaring64_bitmap_t *r1,
                     }
                 } else {
                     container2 = container_iandnot(
-                        leaf1->container, leaf1->typecode, leaf2->container,
-                        leaf2->typecode, &typecode2);
-                }
-                if (container2 != container1) {
-                    leaf1->container = container2;
-                    leaf1->typecode = typecode2;
+                        container1, typecode1, get_container(r2, leaf2),
+                        get_typecode(leaf2), &typecode2);
                 }
 
                 if (!container_nonzero_cardinality(container2, typecode2)) {
                     container_free(container2, typecode2);
-                    art_iterator_erase(&r1->art, &it1);
-                    free_leaf(leaf1);
+                    bool erased = art_iterator_erase(&it1, NULL);
+                    assert(erased);
+                    remove_container(r1, *leaf1);
                 } else {
+                    if (container2 != container1) {
+                        replace_container(r1, leaf1, container2, typecode2);
+                    }
                     // Only advance the iterator if we didn't delete the
                     // leaf, as erasing advances by itself.
                     art_iterator_next(&it1);
@@ -1544,38 +1713,39 @@ void roaring64_bitmap_andnot_inplace(roaring64_bitmap_t *r1,
 }
 
 /**
- * Flips the leaf at high48 in the range [min, max), returning a new leaf with a
- * new container. If the high48 key is not found in the existing bitmap, a new
- * container is created. Returns null if the negation results in an empty range.
+ * Flips the leaf at high48 in the range [min, max), adding the result to
+ * `r2`. If the high48 key is not found in `r1`, a new container is created.
  */
-static leaf_t *roaring64_flip_leaf(const roaring64_bitmap_t *r,
-                                   uint8_t high48[], uint32_t min,
-                                   uint32_t max) {
-    leaf_t *leaf1 = (leaf_t *)art_find(&r->art, high48);
-    container_t *container2;
+static void roaring64_flip_leaf(const roaring64_bitmap_t *r1,
+                                roaring64_bitmap_t *r2, uint8_t high48[],
+                                uint32_t min, uint32_t max) {
+    leaf_t *leaf1 = (leaf_t *)art_find(&r1->art, high48);
     uint8_t typecode2;
+    container_t *container2;
     if (leaf1 == NULL) {
         // No container at this key, create a full container.
         container2 = container_range_of_ones(min, max, &typecode2);
     } else if (min == 0 && max > 0xFFFF) {
         // Flip whole container.
-        container2 =
-            container_not(leaf1->container, leaf1->typecode, &typecode2);
+        container2 = container_not(get_container(r1, *leaf1),
+                                   get_typecode(*leaf1), &typecode2);
     } else {
         // Partially flip a container.
-        container2 = container_not_range(leaf1->container, leaf1->typecode, min,
-                                         max, &typecode2);
+        container2 =
+            container_not_range(get_container(r1, *leaf1), get_typecode(*leaf1),
+                                min, max, &typecode2);
     }
     if (container_nonzero_cardinality(container2, typecode2)) {
-        return create_leaf(container2, typecode2);
+        leaf_t leaf2 = add_container(r2, container2, typecode2);
+        art_insert(&r2->art, high48, (art_val_t)leaf2);
+    } else {
+        container_free(container2, typecode2);
     }
-    container_free(container2, typecode2);
-    return NULL;
 }
 
 /**
- * Flips the leaf at high48 in the range [min, max). If the high48 key is not
- * found in the bitmap, a new container is created. Deletes the leaf and
+ * Flips the leaf at high48 in the range [min, max). If the high48 key is
+ * not found in the bitmap, a new container is created. Deletes the leaf and
  * associated container if the negation results in an empty range.
  */
 static void roaring64_flip_leaf_inplace(roaring64_bitmap_t *r, uint8_t high48[],
@@ -1586,28 +1756,28 @@ static void roaring64_flip_leaf_inplace(roaring64_bitmap_t *r, uint8_t high48[],
     if (leaf == NULL) {
         // No container at this key, insert a full container.
         container2 = container_range_of_ones(min, max, &typecode2);
-        art_insert(&r->art, high48,
-                   (art_val_t *)create_leaf(container2, typecode2));
+        leaf_t new_leaf = add_container(r, container2, typecode2);
+        art_insert(&r->art, high48, (art_val_t)new_leaf);
         return;
     }
 
     if (min == 0 && max > 0xFFFF) {
         // Flip whole container.
-        container2 =
-            container_inot(leaf->container, leaf->typecode, &typecode2);
+        container2 = container_inot(get_container(r, *leaf),
+                                    get_typecode(*leaf), &typecode2);
     } else {
         // Partially flip a container.
-        container2 = container_inot_range(leaf->container, leaf->typecode, min,
-                                          max, &typecode2);
+        container2 = container_inot_range(
+            get_container(r, *leaf), get_typecode(*leaf), min, max, &typecode2);
     }
 
-    leaf->container = container2;
-    leaf->typecode = typecode2;
-
-    if (!container_nonzero_cardinality(leaf->container, leaf->typecode)) {
-        art_erase(&r->art, high48);
-        container_free(leaf->container, leaf->typecode);
-        free_leaf(leaf);
+    if (container_nonzero_cardinality(container2, typecode2)) {
+        replace_container(r, leaf, container2, typecode2);
+    } else {
+        bool erased = art_erase(&r->art, high48, NULL);
+        assert(erased);
+        container_free(container2, typecode2);
+        remove_container(r, *leaf);
     }
 }
 
@@ -1632,20 +1802,21 @@ roaring64_bitmap_t *roaring64_bitmap_flip_closed(const roaring64_bitmap_t *r1,
     uint64_t max_high48_bits = (max & 0xFFFFFFFFFFFF0000ULL) >> 16;
 
     roaring64_bitmap_t *r2 = roaring64_bitmap_create();
-    art_iterator_t it = art_init_iterator(&r1->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r1->art, /*first=*/true);
 
     // Copy the containers before min unchanged.
     while (it.value != NULL && compare_high48(it.key, min_high48_key) < 0) {
-        leaf_t *leaf1 = (leaf_t *)it.value;
-        uint8_t typecode2 = leaf1->typecode;
+        leaf_t leaf1 = (leaf_t)*it.value;
+        uint8_t typecode2 = get_typecode(leaf1);
         container_t *container2 = get_copy_of_container(
-            leaf1->container, &typecode2, /*copy_on_write=*/false);
-        art_insert(&r2->art, it.key,
-                   (art_val_t *)create_leaf(container2, typecode2));
+            get_container(r1, leaf1), &typecode2, /*copy_on_write=*/false);
+        leaf_t leaf2 = add_container(r2, container2, typecode2);
+        art_insert(&r2->art, it.key, (art_val_t)leaf2);
         art_iterator_next(&it);
     }
 
-    // Flip the range (including non-existent containers!) between min and max.
+    // Flip the range (including non-existent containers!) between min and
+    // max.
     for (uint64_t high48_bits = min_high48_bits; high48_bits <= max_high48_bits;
          high48_bits++) {
         uint8_t current_high48_key[ART_KEY_BYTES];
@@ -1660,22 +1831,19 @@ roaring64_bitmap_t *roaring64_bitmap_flip_closed(const roaring64_bitmap_t *r1,
             max_container = max_low16 + 1;  // Exclusive.
         }
 
-        leaf_t *leaf = roaring64_flip_leaf(r1, current_high48_key,
-                                           min_container, max_container);
-        if (leaf != NULL) {
-            art_insert(&r2->art, current_high48_key, (art_val_t *)leaf);
-        }
+        roaring64_flip_leaf(r1, r2, current_high48_key, min_container,
+                            max_container);
     }
 
     // Copy the containers after max unchanged.
-    it = art_upper_bound(&r1->art, max_high48_key);
+    it = art_upper_bound((art_t *)&r1->art, max_high48_key);
     while (it.value != NULL) {
-        leaf_t *leaf1 = (leaf_t *)it.value;
-        uint8_t typecode2 = leaf1->typecode;
+        leaf_t leaf1 = (leaf_t)*it.value;
+        uint8_t typecode2 = get_typecode(leaf1);
         container_t *container2 = get_copy_of_container(
-            leaf1->container, &typecode2, /*copy_on_write=*/false);
-        art_insert(&r2->art, it.key,
-                   (art_val_t *)create_leaf(container2, typecode2));
+            get_container(r1, leaf1), &typecode2, /*copy_on_write=*/false);
+        leaf_t leaf2 = add_container(r2, container2, typecode2);
+        art_insert(&r2->art, it.key, (art_val_t)leaf2);
         art_iterator_next(&it);
     }
 
@@ -1700,7 +1868,8 @@ void roaring64_bitmap_flip_closed_inplace(roaring64_bitmap_t *r, uint64_t min,
     uint64_t min_high48_bits = (min & 0xFFFFFFFFFFFF0000ULL) >> 16;
     uint64_t max_high48_bits = (max & 0xFFFFFFFFFFFF0000ULL) >> 16;
 
-    // Flip the range (including non-existent containers!) between min and max.
+    // Flip the range (including non-existent containers!) between min and
+    // max.
     for (uint64_t high48_bits = min_high48_bits; high48_bits <= max_high48_bits;
          high48_bits++) {
         uint8_t current_high48_key[ART_KEY_BYTES];
@@ -1722,7 +1891,7 @@ void roaring64_bitmap_flip_closed_inplace(roaring64_bitmap_t *r, uint64_t min,
 
 // Returns the number of distinct high 32-bit entries in the bitmap.
 static inline uint64_t count_high32(const roaring64_bitmap_t *r) {
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
     uint64_t high32_count = 0;
     uint32_t prev_high32 = 0;
     while (it.value != NULL) {
@@ -1751,7 +1920,7 @@ size_t roaring64_bitmap_portable_size_in_bytes(const roaring64_bitmap_t *r) {
     uint64_t high32_count;
     size += sizeof(high32_count);
 
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
     uint32_t prev_high32 = 0;
     roaring_bitmap_t *bitmap32 = NULL;
 
@@ -1760,7 +1929,8 @@ size_t roaring64_bitmap_portable_size_in_bytes(const roaring64_bitmap_t *r) {
         uint32_t current_high32 = (uint32_t)(combine_key(it.key, 0) >> 32);
         if (bitmap32 == NULL || prev_high32 != current_high32) {
             if (bitmap32 != NULL) {
-                // Write as uint32 the most significant 32 bits of the bucket.
+                // Write as uint32 the most significant 32 bits of the
+                // bucket.
                 size += sizeof(prev_high32);
 
                 // Write the 32-bit Roaring bitmaps representing the least
@@ -1782,10 +1952,10 @@ size_t roaring64_bitmap_portable_size_in_bytes(const roaring64_bitmap_t *r) {
 
             prev_high32 = current_high32;
         }
-        leaf_t *leaf = (leaf_t *)it.value;
+        leaf_t leaf = (leaf_t)*it.value;
         ra_append(&bitmap32->high_low_container,
-                  (uint16_t)(current_high32 >> 16), leaf->container,
-                  leaf->typecode);
+                  (uint16_t)(current_high32 >> 16), get_container(r, leaf),
+                  get_typecode(leaf));
         art_iterator_next(&it);
     }
 
@@ -1816,7 +1986,7 @@ size_t roaring64_bitmap_portable_serialize(const roaring64_bitmap_t *r,
     memcpy(buf, &high32_count, sizeof(high32_count));
     buf += sizeof(high32_count);
 
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
     uint32_t prev_high32 = 0;
     roaring_bitmap_t *bitmap32 = NULL;
 
@@ -1826,7 +1996,8 @@ size_t roaring64_bitmap_portable_serialize(const roaring64_bitmap_t *r,
         uint32_t current_high32 = (uint32_t)(current_high48 >> 32);
         if (bitmap32 == NULL || prev_high32 != current_high32) {
             if (bitmap32 != NULL) {
-                // Write as uint32 the most significant 32 bits of the bucket.
+                // Write as uint32 the most significant 32 bits of the
+                // bucket.
                 memcpy(buf, &prev_high32, sizeof(prev_high32));
                 buf += sizeof(prev_high32);
 
@@ -1849,10 +2020,10 @@ size_t roaring64_bitmap_portable_serialize(const roaring64_bitmap_t *r,
 
             prev_high32 = current_high32;
         }
-        leaf_t *leaf = (leaf_t *)it.value;
+        leaf_t leaf = (leaf_t)*it.value;
         ra_append(&bitmap32->high_low_container,
-                  (uint16_t)(current_high48 >> 16), leaf->container,
-                  leaf->typecode);
+                  (uint16_t)(current_high48 >> 16), get_container(r, leaf),
+                  get_typecode(leaf));
         art_iterator_next(&it);
     }
 
@@ -1903,8 +2074,8 @@ size_t roaring64_bitmap_portable_deserialize_size(const char *buf,
         buf += sizeof(high32);
         read_bytes += sizeof(high32);
 
-        // Read the 32-bit Roaring bitmaps representing the least significant
-        // bits of a set of elements.
+        // Read the 32-bit Roaring bitmaps representing the least
+        // significant bits of a set of elements.
         size_t bitmap32_size = roaring_bitmap_portable_deserialize_size(
             buf, maxbytes - read_bytes);
         if (bitmap32_size == 0) {
@@ -1959,8 +2130,8 @@ roaring64_bitmap_t *roaring64_bitmap_portable_deserialize_safe(
         }
         previous_high32 = high32;
 
-        // Read the 32-bit Roaring bitmaps representing the least significant
-        // bits of a set of elements.
+        // Read the 32-bit Roaring bitmaps representing the least
+        // significant bits of a set of elements.
         size_t bitmap32_size = roaring_bitmap_portable_deserialize_size(
             buf, maxbytes - read_bytes);
         if (bitmap32_size == 0) {
@@ -2002,16 +2173,364 @@ roaring64_bitmap_t *roaring64_bitmap_portable_deserialize_safe(
     return r;
 }
 
+// Returns an "element count" for the given container. This has a different
+// meaning for each container type, but the purpose is the minimal information
+// required to serialize the container metadata.
+static inline uint32_t container_get_element_count(const container_t *c,
+                                                   uint8_t typecode) {
+    switch (typecode) {
+        case BITSET_CONTAINER_TYPE: {
+            return ((bitset_container_t *)c)->cardinality;
+        }
+        case ARRAY_CONTAINER_TYPE: {
+            return ((array_container_t *)c)->cardinality;
+        }
+        case RUN_CONTAINER_TYPE: {
+            return ((run_container_t *)c)->n_runs;
+        }
+        default: {
+            assert(false);
+            roaring_unreachable;
+            return 0;
+        }
+    }
+}
+
+static inline size_t container_get_frozen_size(const container_t *c,
+                                               uint8_t typecode) {
+    switch (typecode) {
+        case BITSET_CONTAINER_TYPE: {
+            return BITSET_CONTAINER_SIZE_IN_WORDS * sizeof(uint64_t);
+        }
+        case ARRAY_CONTAINER_TYPE: {
+            return container_get_element_count(c, typecode) * sizeof(uint16_t);
+        }
+        case RUN_CONTAINER_TYPE: {
+            return container_get_element_count(c, typecode) * sizeof(rle16_t);
+        }
+        default: {
+            assert(false);
+            roaring_unreachable;
+            return 0;
+        }
+    }
+}
+
+uint64_t align_size(uint64_t size, uint64_t alignment) {
+    return (size + alignment - 1) & ~(alignment - 1);
+}
+
+size_t roaring64_bitmap_frozen_size_in_bytes(const roaring64_bitmap_t *r) {
+    if (!is_shrunken(r)) {
+        return 0;
+    }
+    // Flags.
+    uint64_t size = sizeof(r->flags);
+    // Container count.
+    size += sizeof(r->capacity);
+    // Container element counts.
+    size += r->capacity * sizeof(uint16_t);
+    // Total container sizes.
+    size += 3 * sizeof(uint64_t);
+    // ART (8 byte aligned).
+    size = align_size(size, 8);
+    size += art_size_in_bytes(&r->art);
+
+    uint64_t total_sizes[4] =
+        CROARING_ZERO_INITIALIZER;  // Indexed by typecode.
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
+    while (it.value != NULL) {
+        leaf_t leaf = (leaf_t)*it.value;
+        uint8_t typecode = get_typecode(leaf);
+        total_sizes[typecode] +=
+            container_get_frozen_size(get_container(r, leaf), typecode);
+        art_iterator_next(&it);
+    }
+    // Containers (aligned).
+    size = align_size(size, CROARING_BITSET_ALIGNMENT);
+    size += total_sizes[BITSET_CONTAINER_TYPE];
+    size = align_size(size, alignof(rle16_t));
+    size += total_sizes[ARRAY_CONTAINER_TYPE];
+    size = align_size(size, alignof(uint16_t));
+    size += total_sizes[RUN_CONTAINER_TYPE];
+    // Padding to make overall size a multiple of required alignment.
+    size = align_size(size, CROARING_BITSET_ALIGNMENT);
+    return size;
+}
+
+static inline void container_frozen_serialize(const container_t *container,
+                                              uint8_t typecode,
+                                              uint64_t **bitsets,
+                                              uint16_t **arrays,
+                                              rle16_t **runs) {
+    size_t size = container_get_frozen_size(container, typecode);
+    switch (typecode) {
+        case BITSET_CONTAINER_TYPE: {
+            bitset_container_t *bitset = (bitset_container_t *)container;
+            memcpy(*bitsets, bitset->words, size);
+            *bitsets += BITSET_CONTAINER_SIZE_IN_WORDS;
+            break;
+        }
+        case ARRAY_CONTAINER_TYPE: {
+            array_container_t *array = (array_container_t *)container;
+            memcpy(*arrays, array->array, size);
+            *arrays += container_get_element_count(container, typecode);
+            break;
+        }
+        case RUN_CONTAINER_TYPE: {
+            run_container_t *run = (run_container_t *)container;
+            memcpy(*runs, run->runs, size);
+            *runs += container_get_element_count(container, typecode);
+            break;
+        }
+        default: {
+            assert(false);
+            roaring_unreachable;
+        }
+    }
+}
+
+static inline char *pad_align(char *buf, const char *initial_buf,
+                              size_t alignment) {
+    uint64_t buf_size = buf - initial_buf;
+    uint64_t pad = align_size(buf_size, alignment) - buf_size;
+    memset(buf, 0, pad);
+    return buf + pad;
+}
+
+size_t roaring64_bitmap_frozen_serialize(const roaring64_bitmap_t *r,
+                                         char *buf) {
+    if (buf == NULL) {
+        return 0;
+    }
+    if (!is_shrunken(r)) {
+        return 0;
+    }
+    const char *initial_buf = buf;
+
+    // Flags.
+    memcpy(buf, &r->flags, sizeof(r->flags));
+    buf += sizeof(r->flags);
+
+    // Container count.
+    memcpy(buf, &r->capacity, sizeof(r->capacity));
+    buf += sizeof(r->capacity);
+
+    // Container element counts.
+    uint64_t total_sizes[4] =
+        CROARING_ZERO_INITIALIZER;  // Indexed by typecode.
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
+    while (it.value != NULL) {
+        leaf_t leaf = (leaf_t)*it.value;
+        uint8_t typecode = get_typecode(leaf);
+        container_t *container = get_container(r, leaf);
+
+        uint32_t elem_count = container_get_element_count(container, typecode);
+        uint16_t compressed_elem_count = (uint16_t)(elem_count - 1);
+        memcpy(buf, &compressed_elem_count, sizeof(compressed_elem_count));
+        buf += sizeof(compressed_elem_count);
+
+        total_sizes[typecode] += container_get_frozen_size(container, typecode);
+        art_iterator_next(&it);
+    }
+
+    // Total container sizes.
+    memcpy(buf, &(total_sizes[BITSET_CONTAINER_TYPE]), sizeof(uint64_t));
+    buf += sizeof(uint64_t);
+    memcpy(buf, &(total_sizes[RUN_CONTAINER_TYPE]), sizeof(uint64_t));
+    buf += sizeof(uint64_t);
+    memcpy(buf, &(total_sizes[ARRAY_CONTAINER_TYPE]), sizeof(uint64_t));
+    buf += sizeof(uint64_t);
+
+    // ART.
+    buf = pad_align(buf, initial_buf, 8);
+    buf += art_serialize(&r->art, buf);
+
+    // Containers (aligned).
+    // Runs before arrays as run elements are larger than array elements and
+    // smaller than bitset elements.
+    buf = pad_align(buf, initial_buf, CROARING_BITSET_ALIGNMENT);
+    uint64_t *bitsets = (uint64_t *)buf;
+    buf += total_sizes[BITSET_CONTAINER_TYPE];
+    buf = pad_align(buf, initial_buf, alignof(rle16_t));
+    rle16_t *runs = (rle16_t *)buf;
+    buf += total_sizes[RUN_CONTAINER_TYPE];
+    buf = pad_align(buf, initial_buf, alignof(uint16_t));
+    uint16_t *arrays = (uint16_t *)buf;
+    buf += total_sizes[ARRAY_CONTAINER_TYPE];
+
+    it = art_init_iterator((art_t *)&r->art, /*first=*/true);
+    while (it.value != NULL) {
+        leaf_t leaf = (leaf_t)*it.value;
+        uint8_t typecode = get_typecode(leaf);
+        container_t *container = get_container(r, leaf);
+        container_frozen_serialize(container, typecode, &bitsets, &arrays,
+                                   &runs);
+        art_iterator_next(&it);
+    }
+
+    // Padding to make overall size a multiple of required alignment.
+    buf = pad_align(buf, initial_buf, CROARING_BITSET_ALIGNMENT);
+
+    return buf - initial_buf;
+}
+
+static container_t *container_frozen_view(uint8_t typecode, uint32_t elem_count,
+                                          const uint64_t **bitsets,
+                                          const uint16_t **arrays,
+                                          const rle16_t **runs) {
+    switch (typecode) {
+        case BITSET_CONTAINER_TYPE: {
+            bitset_container_t *c = (bitset_container_t *)roaring_malloc(
+                sizeof(bitset_container_t));
+            c->cardinality = elem_count;
+            c->words = (uint64_t *)*bitsets;
+            *bitsets += BITSET_CONTAINER_SIZE_IN_WORDS;
+            return (container_t *)c;
+        }
+        case ARRAY_CONTAINER_TYPE: {
+            array_container_t *c =
+                (array_container_t *)roaring_malloc(sizeof(array_container_t));
+            c->cardinality = elem_count;
+            c->capacity = elem_count;
+            c->array = (uint16_t *)*arrays;
+            *arrays += elem_count;
+            return (container_t *)c;
+        }
+        case RUN_CONTAINER_TYPE: {
+            run_container_t *c =
+                (run_container_t *)roaring_malloc(sizeof(run_container_t));
+            c->n_runs = elem_count;
+            c->capacity = elem_count;
+            c->runs = (rle16_t *)*runs;
+            *runs += elem_count;
+            return (container_t *)c;
+        }
+        default: {
+            assert(false);
+            roaring_unreachable;
+            return NULL;
+        }
+    }
+}
+
+roaring64_bitmap_t *roaring64_bitmap_frozen_view(const char *buf,
+                                                 size_t maxbytes) {
+    if (buf == NULL) {
+        return NULL;
+    }
+
+    roaring64_bitmap_t *r = roaring64_bitmap_create();
+
+    // Flags.
+    if (maxbytes < sizeof(r->flags)) {
+        roaring64_bitmap_free(r);
+        return NULL;
+    }
+    memcpy(&r->flags, buf, sizeof(r->flags));
+    buf += sizeof(r->flags);
+    maxbytes -= sizeof(r->flags);
+    r->flags |= ROARING_FLAG_FROZEN;
+
+    // Container count.
+    if (maxbytes < sizeof(r->capacity)) {
+        roaring64_bitmap_free(r);
+        return NULL;
+    }
+    memcpy(&r->capacity, buf, sizeof(r->capacity));
+    buf += sizeof(r->capacity);
+    maxbytes -= sizeof(r->capacity);
+
+    r->containers =
+        (container_t *)roaring_malloc(r->capacity * sizeof(container_t *));
+
+    // Container element counts.
+    if (maxbytes < r->capacity * sizeof(uint16_t)) {
+        roaring64_bitmap_free(r);
+        return NULL;
+    }
+    const char *elem_counts = buf;
+    buf += r->capacity * sizeof(uint16_t);
+    maxbytes -= r->capacity * sizeof(uint16_t);
+
+    // Total container sizes.
+    uint64_t total_sizes[4];
+    if (maxbytes < sizeof(uint64_t) * 3) {
+        roaring64_bitmap_free(r);
+        return NULL;
+    }
+    memcpy(&(total_sizes[BITSET_CONTAINER_TYPE]), buf, sizeof(uint64_t));
+    buf += sizeof(uint64_t);
+    maxbytes -= sizeof(uint64_t);
+    memcpy(&(total_sizes[RUN_CONTAINER_TYPE]), buf, sizeof(uint64_t));
+    buf += sizeof(uint64_t);
+    maxbytes -= sizeof(uint64_t);
+    memcpy(&(total_sizes[ARRAY_CONTAINER_TYPE]), buf, sizeof(uint64_t));
+    buf += sizeof(uint64_t);
+    maxbytes -= sizeof(uint64_t);
+
+    // ART (8 byte aligned).
+    buf = CROARING_ALIGN_BUF(buf, 8);
+    size_t art_size = art_frozen_view(buf, maxbytes, &r->art);
+    if (art_size == 0) {
+        roaring64_bitmap_free(r);
+        return NULL;
+    }
+    buf += art_size;
+    maxbytes -= art_size;
+
+    // Containers (aligned).
+    const char *before_containers = buf;
+    buf = CROARING_ALIGN_BUF(buf, CROARING_BITSET_ALIGNMENT);
+    const uint64_t *bitsets = (const uint64_t *)buf;
+    buf += total_sizes[BITSET_CONTAINER_TYPE];
+    buf = CROARING_ALIGN_BUF(buf, alignof(rle16_t));
+    const rle16_t *runs = (const rle16_t *)buf;
+    buf += total_sizes[RUN_CONTAINER_TYPE];
+    buf = CROARING_ALIGN_BUF(buf, alignof(uint16_t));
+    const uint16_t *arrays = (const uint16_t *)buf;
+    buf += total_sizes[ARRAY_CONTAINER_TYPE];
+    if (maxbytes < (uint64_t)(buf - before_containers)) {
+        roaring64_bitmap_free(r);
+        return NULL;
+    }
+    maxbytes -= buf - before_containers;
+
+    // Deserialize in ART iteration order.
+    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    for (size_t i = 0; it.value != NULL; ++i) {
+        leaf_t leaf = (leaf_t)*it.value;
+        uint8_t typecode = get_typecode(leaf);
+
+        uint16_t compressed_elem_count;
+        memcpy(&compressed_elem_count, elem_counts + (i * sizeof(uint16_t)),
+               sizeof(compressed_elem_count));
+        uint32_t elem_count = (uint32_t)(compressed_elem_count) + 1;
+
+        // The container index is unrelated to the iteration order.
+        uint64_t index = get_index(leaf);
+        r->containers[index] = container_frozen_view(typecode, elem_count,
+                                                     &bitsets, &arrays, &runs);
+
+        art_iterator_next(&it);
+    }
+
+    // Padding to make overall size a multiple of required alignment.
+    buf = CROARING_ALIGN_BUF(buf, CROARING_BITSET_ALIGNMENT);
+
+    return r;
+}
+
 bool roaring64_bitmap_iterate(const roaring64_bitmap_t *r,
                               roaring_iterator64 iterator, void *ptr) {
-    art_iterator_t it = art_init_iterator(&r->art, /*first=*/true);
+    art_iterator_t it = art_init_iterator((art_t *)&r->art, /*first=*/true);
     while (it.value != NULL) {
         uint64_t high48 = combine_key(it.key, 0);
         uint64_t high32 = high48 & 0xFFFFFFFF00000000ULL;
         uint32_t low32 = high48;
-        leaf_t *leaf = (leaf_t *)it.value;
-        if (!container_iterate64(leaf->container, leaf->typecode, low32,
-                                 iterator, high32, ptr)) {
+        leaf_t leaf = (leaf_t)*it.value;
+        if (!container_iterate64(get_container(r, leaf), get_typecode(leaf),
+                                 low32, iterator, high32, ptr)) {
             return false;
         }
         art_iterator_next(&it);
@@ -2071,12 +2590,12 @@ bool roaring64_iterator_advance(roaring64_iterator_t *it) {
         if (it->saturated_forward) {
             return (it->has_value = false);
         }
-        roaring64_iterator_init_at(it->parent, it, /*first=*/true);
+        roaring64_iterator_init_at(it->r, it, /*first=*/true);
         return it->has_value;
     }
-    leaf_t *leaf = (leaf_t *)it->art_it.value;
+    leaf_t leaf = (leaf_t)*it->art_it.value;
     uint16_t low16 = (uint16_t)it->value;
-    if (container_iterator_next(leaf->container, leaf->typecode,
+    if (container_iterator_next(get_container(it->r, leaf), get_typecode(leaf),
                                 &it->container_it, &low16)) {
         it->value = it->high48 | low16;
         return (it->has_value = true);
@@ -2094,12 +2613,12 @@ bool roaring64_iterator_previous(roaring64_iterator_t *it) {
             // Saturated backward.
             return (it->has_value = false);
         }
-        roaring64_iterator_init_at(it->parent, it, /*first=*/false);
+        roaring64_iterator_init_at(it->r, it, /*first=*/false);
         return it->has_value;
     }
-    leaf_t *leaf = (leaf_t *)it->art_it.value;
+    leaf_t leaf = (leaf_t)*it->art_it.value;
     uint16_t low16 = (uint16_t)it->value;
-    if (container_iterator_prev(leaf->container, leaf->typecode,
+    if (container_iterator_prev(get_container(it->r, leaf), get_typecode(leaf),
                                 &it->container_it, &low16)) {
         it->value = it->high48 | low16;
         return (it->has_value = true);
@@ -2117,8 +2636,8 @@ bool roaring64_iterator_move_equalorlarger(roaring64_iterator_t *it,
     uint16_t val_low16 = split_key(val, val_high48);
     if (!it->has_value || it->high48 != (val & 0xFFFFFFFFFFFF0000)) {
         // The ART iterator is before or after the high48 bits of `val` (or
-        // beyond the ART altogether), so we need to move to a leaf with a key
-        // equal or greater.
+        // beyond the ART altogether), so we need to move to a leaf with a
+        // key equal or greater.
         if (!art_iterator_lower_bound(&it->art_it, val_high48)) {
             // Only smaller keys found.
             it->saturated_forward = true;
@@ -2129,13 +2648,13 @@ bool roaring64_iterator_move_equalorlarger(roaring64_iterator_t *it,
     }
 
     if (it->high48 == (val & 0xFFFFFFFFFFFF0000)) {
-        // We're at equal high bits, check if a suitable value can be found in
-        // this container.
-        leaf_t *leaf = (leaf_t *)it->art_it.value;
+        // We're at equal high bits, check if a suitable value can be found
+        // in this container.
+        leaf_t leaf = (leaf_t)*it->art_it.value;
         uint16_t low16 = (uint16_t)it->value;
-        if (container_iterator_lower_bound(leaf->container, leaf->typecode,
-                                           &it->container_it, &low16,
-                                           val_low16)) {
+        if (container_iterator_lower_bound(
+                get_container(it->r, leaf), get_typecode(leaf),
+                &it->container_it, &low16, val_low16)) {
             it->value = it->high48 | low16;
             return (it->has_value = true);
         }
@@ -2146,8 +2665,8 @@ bool roaring64_iterator_move_equalorlarger(roaring64_iterator_t *it,
         }
     }
 
-    // We're at a leaf with high bits greater than `val`, so the first entry in
-    // this container is our result.
+    // We're at a leaf with high bits greater than `val`, so the first entry
+    // in this container is our result.
     return roaring64_iterator_init_at_leaf_first(it);
 }
 
@@ -2156,15 +2675,15 @@ uint64_t roaring64_iterator_read(roaring64_iterator_t *it, uint64_t *buf,
     uint64_t consumed = 0;
     while (it->has_value && consumed < count) {
         uint32_t container_consumed;
-        leaf_t *leaf = (leaf_t *)it->art_it.value;
+        leaf_t leaf = (leaf_t)*it->art_it.value;
         uint16_t low16 = (uint16_t)it->value;
         uint32_t container_count = UINT32_MAX;
         if (count - consumed < (uint64_t)UINT32_MAX) {
             container_count = count - consumed;
         }
         bool has_value = container_iterator_read_into_uint64(
-            leaf->container, leaf->typecode, &it->container_it, it->high48, buf,
-            container_count, &container_consumed, &low16);
+            get_container(it->r, leaf), get_typecode(leaf), &it->container_it,
+            it->high48, buf, container_count, &container_consumed, &low16);
         consumed += container_consumed;
         buf += container_consumed;
         if (has_value) {
diff --git a/contrib/libs/croaring/ya.make b/contrib/libs/croaring/ya.make
index b50e7eaa5e36..90f16b7b3d28 100644
--- a/contrib/libs/croaring/ya.make
+++ b/contrib/libs/croaring/ya.make
@@ -10,9 +10,9 @@ LICENSE(
 
 LICENSE_TEXTS(.yandex_meta/licenses.list.txt)
 
-VERSION(4.2.3)
+VERSION(4.3.0)
 
-ORIGINAL_SOURCE(https://github.com/RoaringBitmap/CRoaring/archive/v4.2.3.tar.gz)
+ORIGINAL_SOURCE(https://github.com/RoaringBitmap/CRoaring/archive/v4.3.0.tar.gz)
 
 ADDINCL(
     GLOBAL contrib/libs/croaring/include
diff --git a/contrib/libs/cxxsupp/builtins/.yandex_meta/build.ym b/contrib/libs/cxxsupp/builtins/.yandex_meta/build.ym
index c2747e3d677f..04bc79b0c71c 100644
--- a/contrib/libs/cxxsupp/builtins/.yandex_meta/build.ym
+++ b/contrib/libs/cxxsupp/builtins/.yandex_meta/build.ym
@@ -1,6 +1,6 @@
 {% extends '//builtin/bag.ym' %}
 
-{% block current_version %}19.1.7{% endblock %}
+{% block current_version %}20.1.0{% endblock %}
 
 {% block current_url %}
 https://github.com/llvm/llvm-project/releases/download/llvmorg-{{self.version().strip()}}/compiler-rt-{{self.version().strip()}}.src.tar.xz
@@ -12,6 +12,7 @@ rm CMakeLists.txt
 cd lib/builtins
 rm CMakeLists.txt
 rm aarch64/lse.S
+sed -e 's|.*#include.*ptrauth.h.*||' -i crtbegin.c
 sed -e 's|.*#include.*sys/byteorder.h.*||' -i int_endianness.h
 sed -e 's|.*#include.*zircon/features.h.*||' -i cpu_model/aarch64/fmv/fuchsia.inc
 sed -e 's|.*#include.*zircon/features.h.*||' -i cpu_model/aarch64/lse_atomics/fuchsia.inc
@@ -87,7 +88,7 @@ def name(n):
 sset = frozenset([name(x) for x in special])
 scrt = frozenset(['crtbegin', 'crtend'])
 # x86_80_BIT_SOURCES
-x86_not_win = frozenset(['divxc3', 'extendxftf2', 'fixxfdi', 'fixxfti', 'fixunsxfdi', 'fixunsxfsi', 'fixunsxfti', 'floatdixf', 'floattixf', 'floatundixf', 'floatuntixf', 'mulxc3', 'powixf2', 'trunctfxf2'])
+x86_not_win = frozenset(['divxc3', 'extendhfxf2', 'extendxftf2', 'fixxfdi', 'fixxfti', 'fixunsxfdi', 'fixunsxfsi', 'fixunsxfti', 'floatdixf', 'floattixf', 'floatundixf', 'floatuntixf', 'mulxc3', 'powixf2', 'trunctfxf2', 'truncxfhf2'])
 other_not_emscripten = frozenset([
     'clear_cache',
     'emutls',
@@ -142,9 +143,9 @@ IF (ARCH_ARM64 OR ARCH_X86_64)
             # NB: sources that were commented out were added in llvm-20
             extendbfsf2.c
             truncdfbf2.c
-            # truncxfbf2.c
+            truncxfbf2.c
             truncsfbf2.c
-            # trunctfbf2.c
+            trunctfbf2.c
         )
     ENDIF()
 ENDIF()
diff --git a/contrib/libs/cxxsupp/builtins/.yandex_meta/devtools.licenses.report b/contrib/libs/cxxsupp/builtins/.yandex_meta/devtools.licenses.report
index 874c592edd9e..abc5575fe213 100644
--- a/contrib/libs/cxxsupp/builtins/.yandex_meta/devtools.licenses.report
+++ b/contrib/libs/cxxsupp/builtins/.yandex_meta/devtools.licenses.report
@@ -102,8 +102,7 @@ BELONGS ya.make
     Files with this license:
         aarch64/chkstk.S [1:2]
         aarch64/fp_mode.c [3:4]
-        aarch64/sme-abi-init.c [1:2]
-        aarch64/sme-abi-vg.c [1:2]
+        aarch64/sme-abi-assert.c [1:2]
         aarch64/sme-abi.S [1:2]
         aarch64/sme-libc-mem-routines.S [1:2]
         absvdi2.c [3:4]
@@ -243,6 +242,7 @@ BELONGS ya.make
         cpu_model/aarch64.c [3:4]
         cpu_model/aarch64.h [3:4]
         cpu_model/cpu_model.h [3:4]
+        cpu_model/riscv.c [3:4]
         cpu_model/x86.c [3:4]
         crtbegin.c [3:4]
         crtend.c [3:4]
@@ -268,6 +268,7 @@ BELONGS ya.make
         extendbfsf2.c [3:4]
         extenddftf2.c [3:4]
         extendhfsf2.c [3:4]
+        extendhfxf2.c [3:4]
         extendsfdf2.c [3:4]
         extendsftf2.c [3:4]
         extendxftf2.c [3:4]
@@ -458,9 +459,12 @@ BELONGS ya.make
         truncdfsf2.c [3:4]
         truncsfbf2.c [3:4]
         truncsfhf2.c [3:4]
+        trunctfbf2.c [3:4]
         trunctfdf2.c [3:4]
         trunctfsf2.c [3:4]
         trunctfxf2.c [3:4]
+        truncxfbf2.c [3:4]
+        truncxfhf2.c [3:4]
         ucmpdi2.c [3:4]
         ucmpti2.c [3:4]
         udivdi3.c [3:4]
@@ -490,8 +494,7 @@ BELONGS ya.make
     Files with this license:
         aarch64/chkstk.S [1:2]
         aarch64/fp_mode.c [3:4]
-        aarch64/sme-abi-init.c [1:2]
-        aarch64/sme-abi-vg.c [1:2]
+        aarch64/sme-abi-assert.c [1:2]
         aarch64/sme-abi.S [1:2]
         aarch64/sme-libc-mem-routines.S [1:2]
         absvdi2.c [3:4]
@@ -631,6 +634,7 @@ BELONGS ya.make
         cpu_model/aarch64.c [3:4]
         cpu_model/aarch64.h [3:4]
         cpu_model/cpu_model.h [3:4]
+        cpu_model/riscv.c [3:4]
         cpu_model/x86.c [3:4]
         crtbegin.c [3:4]
         crtend.c [3:4]
@@ -656,6 +660,7 @@ BELONGS ya.make
         extendbfsf2.c [3:4]
         extenddftf2.c [3:4]
         extendhfsf2.c [3:4]
+        extendhfxf2.c [3:4]
         extendsfdf2.c [3:4]
         extendsftf2.c [3:4]
         extendxftf2.c [3:4]
@@ -846,9 +851,12 @@ BELONGS ya.make
         truncdfsf2.c [3:4]
         truncsfbf2.c [3:4]
         truncsfhf2.c [3:4]
+        trunctfbf2.c [3:4]
         trunctfdf2.c [3:4]
         trunctfsf2.c [3:4]
         trunctfxf2.c [3:4]
+        truncxfbf2.c [3:4]
+        truncxfhf2.c [3:4]
         ucmpdi2.c [3:4]
         ucmpti2.c [3:4]
         udivdi3.c [3:4]
@@ -936,8 +944,7 @@ BELONGS ya.make
     Files with this license:
         aarch64/chkstk.S [3:3]
         aarch64/fp_mode.c [5:5]
-        aarch64/sme-abi-init.c [3:3]
-        aarch64/sme-abi-vg.c [3:3]
+        aarch64/sme-abi-assert.c [3:3]
         aarch64/sme-abi.S [3:3]
         aarch64/sme-libc-mem-routines.S [3:3]
         absvdi2.c [5:5]
@@ -1077,6 +1084,7 @@ BELONGS ya.make
         cpu_model/aarch64.c [5:5]
         cpu_model/aarch64.h [5:5]
         cpu_model/cpu_model.h [5:5]
+        cpu_model/riscv.c [5:5]
         cpu_model/x86.c [5:5]
         crtbegin.c [5:5]
         crtend.c [5:5]
@@ -1102,6 +1110,7 @@ BELONGS ya.make
         extendbfsf2.c [5:5]
         extenddftf2.c [5:5]
         extendhfsf2.c [5:5]
+        extendhfxf2.c [5:5]
         extendsfdf2.c [5:5]
         extendsftf2.c [5:5]
         extendxftf2.c [5:5]
@@ -1292,9 +1301,12 @@ BELONGS ya.make
         truncdfsf2.c [5:5]
         truncsfbf2.c [5:5]
         truncsfhf2.c [5:5]
+        trunctfbf2.c [5:5]
         trunctfdf2.c [5:5]
         trunctfsf2.c [5:5]
         trunctfxf2.c [5:5]
+        truncxfbf2.c [5:5]
+        truncxfhf2.c [5:5]
         ucmpdi2.c [5:5]
         ucmpti2.c [5:5]
         udivdi3.c [5:5]
@@ -1324,8 +1336,7 @@ BELONGS ya.make
     Files with this license:
         aarch64/chkstk.S [3:3]
         aarch64/fp_mode.c [5:5]
-        aarch64/sme-abi-init.c [3:3]
-        aarch64/sme-abi-vg.c [3:3]
+        aarch64/sme-abi-assert.c [3:3]
         aarch64/sme-abi.S [3:3]
         aarch64/sme-libc-mem-routines.S [3:3]
         absvdi2.c [5:5]
@@ -1465,6 +1476,7 @@ BELONGS ya.make
         cpu_model/aarch64.c [5:5]
         cpu_model/aarch64.h [5:5]
         cpu_model/cpu_model.h [5:5]
+        cpu_model/riscv.c [5:5]
         cpu_model/x86.c [5:5]
         crtbegin.c [5:5]
         crtend.c [5:5]
@@ -1490,6 +1502,7 @@ BELONGS ya.make
         extendbfsf2.c [5:5]
         extenddftf2.c [5:5]
         extendhfsf2.c [5:5]
+        extendhfxf2.c [5:5]
         extendsfdf2.c [5:5]
         extendsftf2.c [5:5]
         extendxftf2.c [5:5]
@@ -1680,9 +1693,12 @@ BELONGS ya.make
         truncdfsf2.c [5:5]
         truncsfbf2.c [5:5]
         truncsfhf2.c [5:5]
+        trunctfbf2.c [5:5]
         trunctfdf2.c [5:5]
         trunctfsf2.c [5:5]
         trunctfxf2.c [5:5]
+        truncxfbf2.c [5:5]
+        truncxfhf2.c [5:5]
         ucmpdi2.c [5:5]
         ucmpti2.c [5:5]
         udivdi3.c [5:5]
diff --git a/contrib/libs/cxxsupp/builtins/CODE_OWNERS.TXT b/contrib/libs/cxxsupp/builtins/CODE_OWNERS.TXT
deleted file mode 100644
index bd51a1073cc3..000000000000
--- a/contrib/libs/cxxsupp/builtins/CODE_OWNERS.TXT
+++ /dev/null
@@ -1,77 +0,0 @@
-This file is a list of the people responsible for ensuring that patches for a
-particular part of compiler-rt are reviewed, either by themself or by
-someone else. They are also the gatekeepers for their part of compiler-rt, with
-the final word on what goes in or not.
-
-The list is sorted by surname and formatted to allow easy grepping and
-beautification by scripts. The fields are: name (N), email (E), web-address
-(W), PGP key ID and fingerprint (P), description (D), and snail-mail address
-(S).
-
-N: Saleem Abdulrasool
-E: compnerd@compnerd.org
-D: builtins library
-
-N: Andrew Browne
-E: browneee@google.com
-D: DataFlowSanitizer
-
-N: Vitaly Buka
-E: vitalybuka@google.com
-D: Sanitizers
-
-N: Peter Collingbourne
-E: peter@pcc.me.uk
-D: CFI, SafeStack
-
-N: Lang Hames
-E: lhames@gmail.com
-D: ORC
-
-N: Petr Hosek
-E: phosek@google.com
-D: CRT, CMake build
-
-N: Teresa Johnson
-E: tejohnson@google.com
-D: MemProf
-
-N: Kostya Kortchinsky
-E: kostya.kortchinsky@gmail.com
-D: SCUDO
-
-N: Mitch Phillips
-E: mitchp@google.com
-D: GWP ASAN
-
-N: Alexander Potapenko
-E: glider@google.com
-D: Sanitizers
-
-N: Kostya Serebryany
-E: kcc@google.com
-D: AddressSanitizer, sanitizer_common, LeakSanitizer, LibFuzzer
-
-N: Richard Smith
-E: richard-llvm@metafoo.co.uk
-D: UndefinedBehaviorSanitizer
-
-N: Evgeniy Stepanov
-E: eugenis@google.com
-D: MemorySanitizer, Android port of sanitizers
-
-N: Dmitry Vyukov
-E: dvyukov@google.com
-D: ThreadSanitizer
-
-N: Bill Wendling
-E: isanbard@gmail.com
-D: Profile runtime library
-
-N: Christopher Apple, David Trevelyan
-E: cja-private@pm.me, realtime.sanitizer@gmail.com
-D: Realtime Sanitizer (RTSan)
-
-N: Alexander Shaposhnikov
-E: alexander.v.shaposhnikov@gmail.com
-D: Numerical Sanitizer (NSAN)
diff --git a/contrib/libs/cxxsupp/builtins/Maintainers.md b/contrib/libs/cxxsupp/builtins/Maintainers.md
new file mode 100644
index 000000000000..5faf6741c467
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/Maintainers.md
@@ -0,0 +1,110 @@
+# Compiler-rt maintainers
+
+This file is a list of the
+[maintainers](https://llvm.org/docs/DeveloperPolicy.html#maintainers) for
+LLVM compiler-rt.
+
+## Current Maintainers
+
+The following people are the active maintainers for the project. Please reach
+out to them for code reviews, questions about their area of expertise, or other
+assistance.
+
+### Builtins Library
+
+Saleem Abdulrasool \
+compnerd@compnerd.org (email), [compnerd](https://github.com/compnerd) (GitHub)
+
+### CFI
+
+Peter Collingbourne \
+peter@pcc.me.uk (email), [pcc](https://github.com/pcc) (GitHub)
+
+### CMake build
+
+Petr Hosek \
+phosek@google.com (email), [petrhosek](https://github.com/petrhosek) (GitHub)
+
+### CRT
+
+Petr Hosek \
+phosek@google.com (email), [petrhosek](https://github.com/petrhosek) (GitHub)
+
+### GWP ASAN
+
+Christopher Ferris \
+cferris@google.com (email), [cferris1000](https://github.com/cferris1000) (GitHub)
+
+### MemProfiling
+
+Teresa Johnson \
+tejohnson@google.com (email), [teresajohnson](https://github.com/teresajohnson) (GitHub)
+
+### SafeStack
+
+Peter Collingbourne \
+peter@pcc.me.uk (email), [pcc](https://github.com/pcc) (GitHub)
+
+### Sanitizers
+
+#### Sanitizers not covered by someone else
+
+Vitaly Buka \
+vitalybuka@google.com (email), [vitalybuka](https://github.com/vitalybuka) (GitHub) \
+Alexander Potapenko \
+glider@google.com (email), [ramosian-glider](https://github.com/ramosian-glider) (GitHub)
+
+#### Data Flow Sanitizer
+
+Andrew Browne \
+browneee@google.com (email), [browneee](https://github.com/browneee) (GitHub)
+
+#### Numerical Sanitizer (NSAN)
+
+Alexander Shaposhnikov \
+alexander.v.shaposhnikov@gmail.com (email), [alexander-shaposhnikov](https://github.com/alexander-shaposhnikov) (GitHub)
+
+#### Realtime Sanitizer (RTSan)
+
+Christopher Apple \
+cja-private@pm.me (email), [cjappl](https://github.com/cjappl) (GitHub) \
+David Trevelyan \
+david.trevelyan@gmail.com (email), [davidtrevelyan](https://github.com/davidtrevelyan) (GitHub)
+
+#### Thread Sanitizer
+
+Dmitry Vyukov \
+dvyukov@google.com (email), [dvyukov](https://github.com/dvyukov) (GitHub)
+
+#### Undefined Behavior Sanitizer
+
+Richard Smith \
+richard-llvm@metafoo.co.uk (email), [zygoloid](https://github.com/zygoloid) (GitHub)
+
+### ORC
+
+Lang Hames \
+lhames@gmail.com (email), [lhames](https://github.com/lhames) (GitHub)
+
+### Profile runtime library
+
+Bill Wendling \
+isanbard@gmail.com (email), [isanbard](https://github.com/isanbard) (GitHub)
+
+### SCUDO
+
+Christopher Ferris \
+cferris@google.com (email), [cferris1000](https://github.com/cferris1000) (GitHub)
+
+## Inactive Maintainers
+
+The following people have graciously spent time performing maintainer
+responsibilities but are no longer active in that role. Thank you for all your
+help with the success of the project!
+
+### Inactive or former component maintainers
+
+Kostya Serebryany ([kcc](https://github.com/kcc)) -- Sanitizers \
+Evgeniy Stepanov ([eugenis](https://github.com/eugenis)) -- Sanitizers \
+Kostya Kortchinsky ([cryptoad](https://github.com/cryptoad)) -- SCUDO \
+Mitch Phillips ([hctim](https://github.com/hctim)) -- GWP ASAN
diff --git a/contrib/libs/cxxsupp/builtins/aarch64/arm_apple_sme_abi.s b/contrib/libs/cxxsupp/builtins/aarch64/arm_apple_sme_abi.s
new file mode 100644
index 000000000000..f0ccaaf4cdbc
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/aarch64/arm_apple_sme_abi.s
@@ -0,0 +1,129 @@
+#include "../assembly.h"
+
+.arch armv8-a+sme2
+
+// For Apple platforms at the moment, we just call abort() directly
+// after stopping SM mode unconditionally.
+.p2align 2
+DEFINE_COMPILERRT_PRIVATE_FUNCTION(do_abort)
+.cfi_startproc
+	.variant_pcs	SYMBOL_NAME(do_abort)
+	stp	x29, x30, [sp, #-32]!
+  .cfi_def_cfa_offset 32
+  .cfi_offset w30, -24
+  .cfi_offset w29, -32
+	smstop sm
+	bl	SYMBOL_NAME(abort)
+.cfi_endproc
+END_COMPILERRT_FUNCTION(do_abort)
+
+DEFINE_COMPILERRT_FUNCTION(__arm_tpidr2_save)
+  // If TPIDR2_EL0 is null, the subroutine does nothing.
+  mrs x16, TPIDR2_EL0
+  cbz x16, 1f
+
+  // If any of the reserved bytes in the first 16 bytes of the TPIDR2 block are
+  // nonzero, the subroutine [..] aborts in some platform-defined manner.
+  ldrh  w14, [x16, #10]
+  cbnz  w14, 2f
+  ldr w14, [x16, #12]
+  cbnz  w14, 2f
+
+  // If za_save_buffer is NULL, the subroutine does nothing.
+  ldr x14, [x16]
+  cbz x14, 1f
+
+  // If num_za_save_slices is zero, the subroutine does nothing.
+  ldrh  w14, [x16, #8]
+  cbz x14, 1f
+
+  mov x15, xzr
+  ldr x16, [x16]
+0:
+  str za[w15,0], [x16]
+  addsvl x16, x16, #1
+  add x15, x15, #1
+  cmp x14, x15
+  b.ne  0b
+1:
+  ret
+2:
+  b  SYMBOL_NAME(do_abort)
+END_COMPILERRT_FUNCTION(__arm_tpidr2_save)
+
+.p2align 2
+DEFINE_COMPILERRT_FUNCTION(__arm_za_disable)
+.cfi_startproc
+  // Otherwise, the subroutine behaves as if it did the following:
+  // * Call __arm_tpidr2_save.
+  stp x29, x30, [sp, #-16]!
+  .cfi_def_cfa_offset 16
+  mov x29, sp
+  .cfi_def_cfa w29, 16
+  .cfi_offset w30, -8
+  .cfi_offset w29, -16
+  bl  SYMBOL_NAME(__arm_tpidr2_save)
+
+  // * Set TPIDR2_EL0 to null.
+  msr TPIDR2_EL0, xzr
+
+  // * Set PSTATE.ZA to 0.
+  smstop za
+
+  .cfi_def_cfa wsp, 16
+  ldp x29, x30, [sp], #16
+  .cfi_def_cfa_offset 0
+  .cfi_restore w30
+  .cfi_restore w29
+0:
+  ret
+.cfi_endproc
+END_COMPILERRT_FUNCTION(__arm_za_disable)
+
+.p2align 2
+DEFINE_COMPILERRT_FUNCTION(__arm_tpidr2_restore)
+.cfi_startproc
+  .variant_pcs	SYMBOL_NAME(__arm_tpidr2_restore)
+  // If TPIDR2_EL0 is nonnull, the subroutine aborts in some platform-specific
+  // manner.
+  mrs x14, TPIDR2_EL0
+  cbnz  x14, 2f
+
+  // If any of the reserved bytes in the first 16 bytes of BLK are nonzero,
+  // the subroutine [..] aborts in some platform-defined manner.
+  ldrh  w14, [x0, #10]
+  cbnz  w14, 2f
+  ldr w14, [x0, #12]
+  cbnz  w14, 2f
+
+  // If BLK.za_save_buffer is NULL, the subroutine does nothing.
+  ldr x16, [x0]
+  cbz x16, 1f
+
+  // If BLK.num_za_save_slices is zero, the subroutine does nothing.
+  ldrh  w14, [x0, #8]
+  cbz x14, 1f
+
+  mov x15, xzr
+0:
+  ldr za[w15,0], [x16]
+  addsvl x16, x16, #1
+  add x15, x15, #1
+  cmp x14, x15
+  b.ne  0b
+1:
+  ret
+2:
+  b  SYMBOL_NAME(do_abort)
+.cfi_endproc
+END_COMPILERRT_FUNCTION(__arm_tpidr2_restore)
+
+.p2align 2
+DEFINE_COMPILERRT_FUNCTION(__arm_sme_state)
+	.variant_pcs	SYMBOL_NAME(__arm_sme_state)
+  orr x0, x0, #0xC000000000000000
+  mrs x16, SVCR
+  bfxil x0, x16, #0, #2
+  mrs x1, TPIDR2_EL0
+  ret
+END_COMPILERRT_FUNCTION(__arm_sme_state)
diff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-assert.c b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-assert.c
new file mode 100644
index 000000000000..37305ceb39c5
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-assert.c
@@ -0,0 +1,11 @@
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+
+// We rely on the FMV __aarch64_cpu_features mechanism to determine
+// which features are set at runtime.
+
+#include "../cpu_model/AArch64CPUFeatures.inc"
+_Static_assert(FEAT_SVE == 30, "sme-abi.S assumes FEAT_SVE = 30");
+_Static_assert(FEAT_SME == 42, "sme-abi.S assumes FEAT_SME = 42");
+_Static_assert(FEAT_SME2 == 57, "sme-abi.S assumes FEAT_SME2 = 57");
diff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-init.c b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-init.c
deleted file mode 100644
index b6ee12170d56..000000000000
--- a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-init.c
+++ /dev/null
@@ -1,52 +0,0 @@
-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
-// See https://llvm.org/LICENSE.txt for license information.
-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
-
-__attribute__((visibility("hidden"), nocommon))
-_Bool __aarch64_has_sme_and_tpidr2_el0;
-
-// We have multiple ways to check that the function has SME, depending on our
-// target.
-// * For Linux we can use __getauxval().
-// * For newlib we can use __aarch64_sme_accessible().
-
-#if defined(__linux__)
-
-#ifndef AT_HWCAP2
-#define AT_HWCAP2 26
-#endif
-
-#ifndef HWCAP2_SME
-#define HWCAP2_SME (1 << 23)
-#endif
-
-extern unsigned long int __getauxval (unsigned long int);
-
-static _Bool has_sme(void) {
-  return __getauxval(AT_HWCAP2) & HWCAP2_SME;
-}
-
-#else  // defined(__linux__)
-
-#if defined(COMPILER_RT_SHARED_LIB)
-__attribute__((weak))
-#endif
-extern _Bool __aarch64_sme_accessible(void);
-
-static _Bool has_sme(void)  {
-#if defined(COMPILER_RT_SHARED_LIB)
-  if (!__aarch64_sme_accessible)
-    return 0;
-#endif
-  return __aarch64_sme_accessible();
-}
-
-#endif // defined(__linux__)
-
-#if __GNUC__ >= 9
-#pragma GCC diagnostic ignored "-Wprio-ctor-dtor"
-#endif
-__attribute__((constructor(90)))
-static void init_aarch64_has_sme(void) {
-  __aarch64_has_sme_and_tpidr2_el0 = has_sme();
-}
diff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-vg.c b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-vg.c
deleted file mode 100644
index 20061012e16c..000000000000
--- a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi-vg.c
+++ /dev/null
@@ -1,21 +0,0 @@
-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
-// See https://llvm.org/LICENSE.txt for license information.
-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
-
-#include "../cpu_model/aarch64.h"
-
-struct FEATURES {
-  unsigned long long features;
-};
-
-extern struct FEATURES __aarch64_cpu_features;
-
-#if __GNUC__ >= 9
-#pragma GCC diagnostic ignored "-Wprio-ctor-dtor"
-#endif
-__attribute__((constructor(90))) static void get_aarch64_cpu_features(void) {
-  if (__atomic_load_n(&__aarch64_cpu_features.features, __ATOMIC_RELAXED))
-    return;
-
-  __init_cpu_features();
-}
diff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi.S b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi.S
index cd8153f60670..8dbbe061edb9 100644
--- a/contrib/libs/cxxsupp/builtins/aarch64/sme-abi.S
+++ b/contrib/libs/cxxsupp/builtins/aarch64/sme-abi.S
@@ -8,22 +8,23 @@
 
 #include "../assembly.h"
 
+.set FEAT_SVE_BIT, 30
+.set FEAT_SME_BIT, 42
+.set FEAT_SME2_BIT, 57
+.set FEAT_SME2_MASK, 1 << 57
+.set SVCR_PSTATE_SM_BIT, 0
 
 #if !defined(__APPLE__)
-#define TPIDR2_SYMBOL SYMBOL_NAME(__aarch64_has_sme_and_tpidr2_el0)
-#define TPIDR2_SYMBOL_OFFSET :lo12:SYMBOL_NAME(__aarch64_has_sme_and_tpidr2_el0)
 #define CPU_FEATS_SYMBOL SYMBOL_NAME(__aarch64_cpu_features)
 #define CPU_FEATS_SYMBOL_OFFSET :lo12:SYMBOL_NAME(__aarch64_cpu_features)
 #else
 // MachO requires @page/@pageoff directives because the global is defined
 // in a different file. Otherwise this file may fail to build.
-#define TPIDR2_SYMBOL SYMBOL_NAME(__aarch64_has_sme_and_tpidr2_el0)@page
-#define TPIDR2_SYMBOL_OFFSET SYMBOL_NAME(__aarch64_has_sme_and_tpidr2_el0)@pageoff
 #define CPU_FEATS_SYMBOL SYMBOL_NAME(__aarch64_cpu_features)@page
 #define CPU_FEATS_SYMBOL_OFFSET SYMBOL_NAME(__aarch64_cpu_features)@pageoff
 #endif
 
-.arch armv9-a+sme
+.arch armv9-a+sme2
 
 // Utility function which calls a system's abort() routine. Because the function
 // is streaming-compatible it should disable streaming-SVE mode before calling
@@ -41,7 +42,7 @@ DEFINE_COMPILERRT_PRIVATE_FUNCTION(do_abort)
   .cfi_offset w30, -24
   .cfi_offset w29, -32
   .cfi_offset 46, -16
-  bl  __arm_sme_state
+  bl  SYMBOL_NAME(__arm_sme_state)
   tbz  x0, #0, 2f
 1:
   smstop sm
@@ -55,15 +56,15 @@ END_COMPILERRT_FUNCTION(do_abort)
 // __arm_sme_state fills the result registers based on a local
 // that is set as part of the compiler-rt startup code.
 //   __aarch64_has_sme_and_tpidr2_el0
-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sme_state)
+DEFINE_COMPILERRT_FUNCTION(__arm_sme_state)
   .variant_pcs __arm_sme_state
   BTI_C
   mov x0, xzr
   mov x1, xzr
 
-  adrp  x16, TPIDR2_SYMBOL
-  ldrb w16, [x16, TPIDR2_SYMBOL_OFFSET]
-  cbz w16, 1f
+  adrp x16, CPU_FEATS_SYMBOL
+  ldr x16, [x16, CPU_FEATS_SYMBOL_OFFSET]
+  tbz x16, #FEAT_SME_BIT, 1f
 0:
   orr x0, x0, #0xC000000000000000
   mrs x16, SVCR
@@ -71,9 +72,9 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sme_state)
   mrs x1, TPIDR2_EL0
 1:
   ret
-END_COMPILERRT_OUTLINE_FUNCTION(__arm_sme_state)
+END_COMPILERRT_FUNCTION(__arm_sme_state)
 
-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_tpidr2_restore)
+DEFINE_COMPILERRT_FUNCTION(__arm_tpidr2_restore)
   .variant_pcs __arm_tpidr2_restore
   BTI_C
   // If TPIDR2_EL0 is nonnull, the subroutine aborts in some platform-specific
@@ -107,16 +108,16 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_tpidr2_restore)
   ret
 2:
   b  SYMBOL_NAME(do_abort)
-END_COMPILERRT_OUTLINE_FUNCTION(__arm_tpidr2_restore)
+END_COMPILERRT_FUNCTION(__arm_tpidr2_restore)
 
-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_tpidr2_save)
-  .variant_pcs __arm_tpidr2_restore
+DEFINE_COMPILERRT_FUNCTION(__arm_tpidr2_save)
+  .variant_pcs __arm_tpidr2_save
   BTI_C
   // If the current thread does not have access to TPIDR2_EL0, the subroutine
   // does nothing.
-  adrp  x14, TPIDR2_SYMBOL
-  ldrb w14, [x14, TPIDR2_SYMBOL_OFFSET]
-  cbz w14, 1f
+  adrp x14, CPU_FEATS_SYMBOL
+  ldr x14, [x14, CPU_FEATS_SYMBOL_OFFSET]
+  tbz x14, #FEAT_SME_BIT, 1f
 
   // If TPIDR2_EL0 is null, the subroutine does nothing.
   mrs x16, TPIDR2_EL0
@@ -148,16 +149,17 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_tpidr2_save)
   ret
 2:
   b  SYMBOL_NAME(do_abort)
-END_COMPILERRT_OUTLINE_FUNCTION(__arm_tpidr2_save)
+END_COMPILERRT_FUNCTION(__arm_tpidr2_save)
 
-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_za_disable)
-  .variant_pcs __arm_tpidr2_restore
+DEFINE_COMPILERRT_FUNCTION(__arm_za_disable)
+  .cfi_startproc
+  .variant_pcs __arm_za_disable
   BTI_C
   // If the current thread does not have access to SME, the subroutine does
   // nothing.
-  adrp  x14, TPIDR2_SYMBOL
-  ldrb w14, [x14, TPIDR2_SYMBOL_OFFSET]
-  cbz w14, 0f
+  adrp x14, CPU_FEATS_SYMBOL
+  ldr x14, [x14, CPU_FEATS_SYMBOL_OFFSET]
+  tbz x14, #FEAT_SME_BIT, 0f
 
   // Otherwise, the subroutine behaves as if it did the following:
   // * Call __arm_tpidr2_save.
@@ -167,7 +169,7 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_za_disable)
   .cfi_def_cfa w29, 16
   .cfi_offset w30, -8
   .cfi_offset w29, -16
-  bl  __arm_tpidr2_save
+  bl  SYMBOL_NAME(__arm_tpidr2_save)
 
   // * Set TPIDR2_EL0 to null.
   msr TPIDR2_EL0, xzr
@@ -182,47 +184,190 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_za_disable)
   .cfi_restore w29
 0:
   ret
-END_COMPILERRT_OUTLINE_FUNCTION(__arm_za_disable)
+  .cfi_endproc
+END_COMPILERRT_FUNCTION(__arm_za_disable)
 
-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_get_current_vg)
+DEFINE_COMPILERRT_FUNCTION(__arm_get_current_vg)
   .variant_pcs __arm_get_current_vg
   BTI_C
 
+  adrp    x17, CPU_FEATS_SYMBOL
+  ldr     x17, [x17, CPU_FEATS_SYMBOL_OFFSET]
+  tbnz    w17, #FEAT_SVE_BIT, 1f
+  tbz     x17, #FEAT_SME_BIT, 2f
+0:
+  mrs     x17, SVCR
+  tbz     x17, #SVCR_PSTATE_SM_BIT, 2f
+1:
+  cntd    x0
+  ret
+2:
+  mov     x0, xzr
+  ret
+END_COMPILERRT_FUNCTION(__arm_get_current_vg)
+
+// The diagram below describes the layout used in the following routines:
+// * __arm_sme_state_size
+// * __arm_sme_save
+// * __arm_sme_restore
+//
+// +---------------------------------+
+// |             ...                 |
+// |           ZA buffer             |
+// |             ...                 |
+// +---------------------------------+ <- @96
+// |         ZT0 contents            |
+// +---------------------------------+ <- @32
+// | byte 15-10: zero (reserved)     |
+// | byte   9-8: num_za_save_slices  |           TPIDR2 block
+// | byte   7-0: za_save_buffer      |
+// +---------------------------------+ <- @16
+// | bit  127-1: zero (reserved)     |           Internal state for __arm_sme_save/restore
+// | bit      0: VALID               |
+// +---------------------------------+ <- @0
+
+DEFINE_COMPILERRT_FUNCTION(__arm_sme_state_size)
+  .variant_pcs __arm_sme_state_size
+  BTI_C
+
+  // Test if SME is available and ZA state is 'active'.
+  adrp    x17, CPU_FEATS_SYMBOL
+  ldr     x17, [x17, CPU_FEATS_SYMBOL_OFFSET]
+  tbz     x17, #FEAT_SME_BIT, 0f
+  mrs     x16, SVCR
+  tbz     x16, #1, 0f
+  mrs     x16, TPIDR2_EL0
+  cbnz    x16, 0f
+
+  // Size = HAS_FEAT_SME2 ? 96 : 32
+  tst     x17, #FEAT_SME2_MASK
+  mov     w17, #32
+  mov     w16, #96
+  csel    x16, x17, x16, eq
+
+  // Size = Size + (SVLB * SVLB)
+  rdsvl   x17, #1
+  madd    x0, x17, x17, x16
+  ret
+
+0:
+  // Default case, 16 bytes is minimum (to encode VALID bit, multiple of 16 bytes)
+  mov w0, #16
+  ret
+END_COMPILERRT_FUNCTION(__arm_sme_state_size)
+
+DEFINE_COMPILERRT_FUNCTION(__arm_sme_save)
+  .variant_pcs __arm_sme_save
+  BTI_C
+
+  // If PTR is not 16-byte aligned, abort.
+  tst     x0, #0xF
+  b.ne    3f
+
+  // Clear internal state bits
+  stp     xzr, xzr, [x0]
+
+  // If SME is not available, PSTATE.ZA = 0 or TPIDR2_EL0 != 0, return.
+  adrp    x17, CPU_FEATS_SYMBOL
+  ldr     x17, [x17, CPU_FEATS_SYMBOL_OFFSET]
+  tbz     x17, #FEAT_SME_BIT, 2f
+  mrs     x16, SVCR
+  tbz     x16, #1, 2f
+  mrs     x16, TPIDR2_EL0
+  cbnz    x16, 2f
+
+  # ZA or ZT0 need saving, we can now set internal VALID bit to 1
+  mov     w16, #1
+  str     x16, [x0]
+
+  add     x18, x0, #32
+  tbz     x17, #FEAT_SME2_BIT, 1f
+
+  // Store ZT0
+  str     zt0, [x18]
+  add     x18, x18, #64
+
+1:
+  // Set up lazy-save (x18 = pointer to buffer)
+  rdsvl   x17, #1
+  str     x18, [x0, #16]!
+  strh    w17, [x0, #8]
+  strh    wzr, [x0, #10]
+  str     wzr, [x0, #12]
+  msr     TPIDR2_EL0, x0
+
+2:
+  // Do nothing
+  ret
+
+3:
+  b       SYMBOL_NAME(do_abort)
+END_COMPILERRT_FUNCTION(__arm_sme_save)
+
+DEFINE_COMPILERRT_FUNCTION(__arm_sme_restore)
+  .cfi_startproc
+  .variant_pcs __arm_sme_restore
+  BTI_C
+
   stp     x29, x30, [sp, #-16]!
   .cfi_def_cfa_offset 16
   mov     x29, sp
   .cfi_def_cfa w29, 16
   .cfi_offset w30, -8
   .cfi_offset w29, -16
+
+  // If PTR is not 16-byte aligned, abort.
+  tst     x0, #0xF
+  b.ne    3f
+
+  // If the VALID bit is 0, return early.
+  ldr     x16, [x0]
+  cbz     x16, 2f
+
+  // If SME is not available, abort.
   adrp    x17, CPU_FEATS_SYMBOL
-  ldr     w17, [x17, CPU_FEATS_SYMBOL_OFFSET]
-  tbnz    w17, #30, 0f
-  adrp    x16, TPIDR2_SYMBOL
-  ldrb    w16, [x16, TPIDR2_SYMBOL_OFFSET]
-  cbz     w16, 1f
-0:
-  mov     x18, x1
-  bl      __arm_sme_state
-  mov     x1, x18
-  and     x17, x17, #0x40000000
-  bfxil   x17, x0, #0, #1
-  cbz     x17, 1f
-  cntd    x0
-  .cfi_def_cfa wsp, 16
-  ldp     x29, x30, [sp], #16
-  .cfi_def_cfa_offset 0
-  .cfi_restore w30
-  .cfi_restore w29
-  ret
+  ldr     x17, [x17, CPU_FEATS_SYMBOL_OFFSET]
+  tbz     x17, #FEAT_SME_BIT, 3f
+
+  // If TPIDR2_EL0 != nullptr, no lazy-save was committed, try to reload zt0.
+  mrs     x16, TPIDR2_EL0
+  cbnz    x16, 1f
+
+  // If TPIDR2_EL0 == nullptr and PSTATE.ZA = 1 (<=> ZA state is 'active'),
+  // abort.
+  mrs     x16, SVCR
+  tbnz    x16, #1, 3f
+
+  // Restore za.
+  smstart za
+  add     x0, x0, #16
+  bl      __arm_tpidr2_restore
+  sub     x0, x0, #16
+
 1:
-  mov     x0, xzr
+  smstart za
+  msr     TPIDR2_EL0, xzr
+
+  // Check if zt0 needs restoring.
+  tbz     x17, #FEAT_SME2_BIT, 2f
+
+  // Restore zt0.
+  add     x16, x0, #32
+  ldr     zt0, [x16]
+
+2:
+  // Do nothing
   .cfi_def_cfa wsp, 16
   ldp     x29, x30, [sp], #16
   .cfi_def_cfa_offset 0
   .cfi_restore w30
   .cfi_restore w29
   ret
-END_COMPILERRT_OUTLINE_FUNCTION(__arm_get_current_vg)
+
+3:
+  b       SYMBOL_NAME(do_abort)
+  .cfi_endproc
+END_COMPILERRT_FUNCTION(__arm_sme_restore)
 
 NO_EXEC_STACK_DIRECTIVE
 
diff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-mem-routines.S b/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-mem-routines.S
index 0318d9a6f1eb..e736829967c0 100644
--- a/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-mem-routines.S
+++ b/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-mem-routines.S
@@ -6,10 +6,6 @@
 
 #include "../assembly.h"
 
-#ifdef __aarch64__
-
-#define L(l) .L ## l
-
 //
 //  __arm_sc_memcpy / __arm_sc_memmove
 //
@@ -54,17 +50,17 @@
    The loop tail is handled by always copying 64 bytes from the end.
 */
 
-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sc_memcpy)
+DEFINE_COMPILERRT_FUNCTION(__arm_sc_memcpy)
         add     srcend1, src, count
         add     dstend1, dstin, count
         cmp     count, 128
-        b.hi    L(copy_long)
+        b.hi    7f  // copy_long
         cmp     count, 32
-        b.hi    L(copy32_128)
+        b.hi    4f  // copy32_128
 
         /* Small copies: 0..32 bytes.  */
         cmp     count, 16
-        b.lo    L(copy16)
+        b.lo    0f  // copy16
         ldp     A_l, A_h, [src]
         ldp     D_l, D_h, [srcend1, -16]
         stp     A_l, A_h, [dstin]
@@ -72,8 +68,8 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sc_memcpy)
         ret
 
         /* Copy 8-15 bytes.  */
-L(copy16):
-        tbz     count, 3, L(copy8)
+0:  // copy16
+        tbz     count, 3, 1f  // copy8
         ldr     A_l, [src]
         ldr     A_h, [srcend1, -8]
         str     A_l, [dstin]
@@ -82,8 +78,8 @@ L(copy16):
 
         .p2align 3
         /* Copy 4-7 bytes.  */
-L(copy8):
-        tbz     count, 2, L(copy4)
+1:  // copy8
+        tbz     count, 2, 2f  // copy4
         ldr     A_lw, [src]
         ldr     B_lw, [srcend1, -4]
         str     A_lw, [dstin]
@@ -91,8 +87,8 @@ L(copy8):
         ret
 
         /* Copy 0..3 bytes using a branchless sequence.  */
-L(copy4):
-        cbz     count, L(copy0)
+2:  // copy4
+        cbz     count, 3f // copy0
         lsr     tmp1, count, 1
         ldrb    A_lw, [src]
         ldrb    C_lw, [srcend1, -1]
@@ -100,18 +96,18 @@ L(copy4):
         strb    A_lw, [dstin]
         strb    B_lw, [dstin, tmp1]
         strb    C_lw, [dstend1, -1]
-L(copy0):
+3:  // copy0
         ret
 
         .p2align 4
         /* Medium copies: 33..128 bytes.  */
-L(copy32_128):
+4:  // copy32_128
         ldp     A_l, A_h, [src]
         ldp     B_l, B_h, [src, 16]
         ldp     C_l, C_h, [srcend1, -32]
         ldp     D_l, D_h, [srcend1, -16]
         cmp     count, 64
-        b.hi    L(copy128)
+        b.hi    5f  // copy128
         stp     A_l, A_h, [dstin]
         stp     B_l, B_h, [dstin, 16]
         stp     C_l, C_h, [dstend1, -32]
@@ -120,16 +116,16 @@ L(copy32_128):
 
         .p2align 4
         /* Copy 65..128 bytes.  */
-L(copy128):
+5:  // copy128
         ldp     E_l, E_h, [src, 32]
         ldp     F_l, F_h, [src, 48]
         cmp     count, 96
-        b.ls    L(copy96)
+        b.ls    6f  // copy96
         ldp     G_l, G_h, [srcend1, -64]
         ldp     H_l, H_h, [srcend1, -48]
         stp     G_l, G_h, [dstend1, -64]
         stp     H_l, H_h, [dstend1, -48]
-L(copy96):
+6:  // copy96
         stp     A_l, A_h, [dstin]
         stp     B_l, B_h, [dstin, 16]
         stp     E_l, E_h, [dstin, 32]
@@ -140,12 +136,12 @@ L(copy96):
 
         .p2align 4
         /* Copy more than 128 bytes.  */
-L(copy_long):
+7:  // copy_long
         /* Use backwards copy if there is an overlap.  */
         sub     tmp1, dstin, src
-        cbz     tmp1, L(copy0)
+        cbz     tmp1, 3b  // copy0
         cmp     tmp1, count
-        b.lo    L(copy_long_backwards)
+        b.lo    10f //copy_long_backwards
 
         /* Copy 16 bytes and then align dst to 16-byte alignment.  */
 
@@ -160,8 +156,8 @@ L(copy_long):
         ldp     C_l, C_h, [src, 48]
         ldp     D_l, D_h, [src, 64]!
         subs    count, count, 128 + 16  /* Test and readjust count.  */
-        b.ls    L(copy64_from_end)
-L(loop64):
+        b.ls    9f  // copy64_from_end
+8:  // loop64
         stp     A_l, A_h, [dst, 16]
         ldp     A_l, A_h, [src, 16]
         stp     B_l, B_h, [dst, 32]
@@ -171,10 +167,10 @@ L(loop64):
         stp     D_l, D_h, [dst, 64]!
         ldp     D_l, D_h, [src, 64]!
         subs    count, count, 64
-        b.hi    L(loop64)
+        b.hi    8b  // loop64
 
         /* Write the last iteration and copy 64 bytes from the end.  */
-L(copy64_from_end):
+9:  // copy64_from_end
         ldp     E_l, E_h, [srcend1, -64]
         stp     A_l, A_h, [dst, 16]
         ldp     A_l, A_h, [srcend1, -48]
@@ -193,7 +189,7 @@ L(copy64_from_end):
 
         /* Large backwards copy for overlapping copies.
            Copy 16 bytes and then align dst to 16-byte alignment.  */
-L(copy_long_backwards):
+10: // copy_long_backwards
         ldp     D_l, D_h, [srcend1, -16]
         and     tmp1, dstend1, 15
         sub     srcend1, srcend1, tmp1
@@ -205,9 +201,9 @@ L(copy_long_backwards):
         ldp     D_l, D_h, [srcend1, -64]!
         sub     dstend1, dstend1, tmp1
         subs    count, count, 128
-        b.ls    L(copy64_from_start)
+        b.ls    12f // copy64_from_start
 
-L(loop64_backwards):
+11: // loop64_backwards
         stp     A_l, A_h, [dstend1, -16]
         ldp     A_l, A_h, [srcend1, -16]
         stp     B_l, B_h, [dstend1, -32]
@@ -217,10 +213,10 @@ L(loop64_backwards):
         stp     D_l, D_h, [dstend1, -64]!
         ldp     D_l, D_h, [srcend1, -64]!
         subs    count, count, 64
-        b.hi    L(loop64_backwards)
+        b.hi    11b // loop64_backwards
 
         /* Write the last iteration and copy 64 bytes from the start.  */
-L(copy64_from_start):
+12: // copy64_from_start
         ldp     G_l, G_h, [src, 48]
         stp     A_l, A_h, [dstend1, -16]
         ldp     A_l, A_h, [src, 32]
@@ -234,11 +230,12 @@ L(copy64_from_start):
         stp     B_l, B_h, [dstin, 16]
         stp     C_l, C_h, [dstin]
         ret
-END_COMPILERRT_OUTLINE_FUNCTION(__arm_sc_memcpy)
+END_COMPILERRT_FUNCTION(__arm_sc_memcpy)
 
 DEFINE_COMPILERRT_FUNCTION_ALIAS(__arm_sc_memmove, __arm_sc_memcpy)
 
-
+// This version uses FP registers. Use this only on targets with them
+#if defined(__aarch64__) && __ARM_FP != 0
 //
 //  __arm_sc_memset
 //
@@ -251,7 +248,7 @@ DEFINE_COMPILERRT_FUNCTION_ALIAS(__arm_sc_memmove, __arm_sc_memcpy)
 #define dstend2  x4
 #define zva_val  x5
 
-DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sc_memset)
+DEFINE_COMPILERRT_FUNCTION(__arm_sc_memset)
 #ifdef __ARM_FEATURE_SVE
         mov     z0.b, valw
 #else
@@ -264,9 +261,9 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sc_memset)
         add     dstend2, dstin, count
 
         cmp     count, 96
-        b.hi    L(set_long)
+        b.hi    7f  // set_long
         cmp     count, 16
-        b.hs    L(set_medium)
+        b.hs    4f  // set_medium
         mov     val, v0.D[0]
 
         /* Set 0..15 bytes.  */
@@ -286,38 +283,38 @@ DEFINE_COMPILERRT_OUTLINE_FUNCTION_UNMANGLED(__arm_sc_memset)
 3:      ret
 
         /* Set 17..96 bytes.  */
-L(set_medium):
+4:  // set_medium
         str     q0, [dstin]
-        tbnz    count, 6, L(set96)
+        tbnz    count, 6, 6f  // set96
         str     q0, [dstend2, -16]
-        tbz     count, 5, 1f
+        tbz     count, 5, 5f
         str     q0, [dstin, 16]
         str     q0, [dstend2, -32]
-1:      ret
+5:      ret
 
         .p2align 4
         /* Set 64..96 bytes.  Write 64 bytes from the start and
            32 bytes from the end.  */
-L(set96):
+6:  // set96
         str     q0, [dstin, 16]
         stp     q0, q0, [dstin, 32]
         stp     q0, q0, [dstend2, -32]
         ret
 
         .p2align 4
-L(set_long):
+7:  // set_long
         and     valw, valw, 255
         bic     dst, dstin, 15
         str     q0, [dstin]
         cmp     count, 160
         ccmp    valw, 0, 0, hs
-        b.ne    L(no_zva)
+        b.ne    9f  // no_zva
 
 #ifndef SKIP_ZVA_CHECK
         mrs     zva_val, dczid_el0
         and     zva_val, zva_val, 31
         cmp     zva_val, 4              /* ZVA size is 64 bytes.  */
-        b.ne    L(no_zva)
+        b.ne    9f  // no_zva
 #endif
         str     q0, [dst, 16]
         stp     q0, q0, [dst, 32]
@@ -326,27 +323,27 @@ L(set_long):
         sub     count, count, 128       /* Adjust count and bias for loop.  */
 
         .p2align 4
-L(zva_loop):
+8:  // zva_loop
         add     dst, dst, 64
         dc      zva, dst
         subs    count, count, 64
-        b.hi    L(zva_loop)
+        b.hi    8b  // zva_loop
         stp     q0, q0, [dstend2, -64]
         stp     q0, q0, [dstend2, -32]
         ret
 
-L(no_zva):
+9:  // no_zva
         sub     count, dstend2, dst      /* Count is 16 too large.  */
         sub     dst, dst, 16            /* Dst is biased by -32.  */
         sub     count, count, 64 + 16   /* Adjust count and bias for loop.  */
-L(no_zva_loop):
+10: // no_zva_loop
         stp     q0, q0, [dst, 32]
         stp     q0, q0, [dst, 64]!
         subs    count, count, 64
-        b.hi    L(no_zva_loop)
+        b.hi    10b  // no_zva_loop
         stp     q0, q0, [dstend2, -64]
         stp     q0, q0, [dstend2, -32]
         ret
-END_COMPILERRT_OUTLINE_FUNCTION(__arm_sc_memset)
+END_COMPILERRT_FUNCTION(__arm_sc_memset)
 
 #endif // __aarch64__
diff --git a/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-routines.c b/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-routines.c
index 315490e73ea2..07d668148555 100644
--- a/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-routines.c
+++ b/contrib/libs/cxxsupp/builtins/aarch64/sme-libc-routines.c
@@ -1,5 +1,17 @@
 #include <stddef.h>
 
+/* The asm version uses FP registers. Use this on targets without them */
+#if __ARM_FP == 0
+void *__arm_sc_memset(void *dest, int c, size_t n) __arm_streaming_compatible {
+  unsigned char *destp = (unsigned char *)dest;
+  unsigned char c8 = (unsigned char)c;
+  for (size_t i = 0; i < n; ++i)
+    destp[i] = c8;
+
+  return dest;
+}
+#endif
+
 const void *__arm_sc_memchr(const void *src, int c,
                             size_t n) __arm_streaming_compatible {
   const unsigned char *srcp = (const unsigned char *)src;
diff --git a/contrib/libs/cxxsupp/builtins/arm/adddf3vfp.S b/contrib/libs/cxxsupp/builtins/arm/adddf3vfp.S
index 1a271db0847c..280f5ab07563 100644
--- a/contrib/libs/cxxsupp/builtins/arm/adddf3vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/adddf3vfp.S
@@ -19,10 +19,10 @@ DEFINE_COMPILERRT_FUNCTION(__adddf3vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vadd.f64 d0, d0, d1
 #else
-	vmov	d6, r0, r1		// move first param from r0/r1 pair into d6
-	vmov	d7, r2, r3		// move second param from r2/r3 pair into d7
+	VMOV_TO_DOUBLE(d6, r0, r1)		// move first param from r0/r1 pair into d6
+	VMOV_TO_DOUBLE(d7, r2, r3)		// move second param from r2/r3 pair into d7
 	vadd.f64 d6, d6, d7
-	vmov	r0, r1, d6		// move result back to r0/r1 pair
+	VMOV_FROM_DOUBLE(r0, r1, d6)		// move result back to r0/r1 pair
 #endif
 	bx	lr
 END_COMPILERRT_FUNCTION(__adddf3vfp)
diff --git a/contrib/libs/cxxsupp/builtins/arm/aeabi_dcmp.S b/contrib/libs/cxxsupp/builtins/arm/aeabi_dcmp.S
index 5f720670ddd7..bee14b3ff8af 100644
--- a/contrib/libs/cxxsupp/builtins/arm/aeabi_dcmp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/aeabi_dcmp.S
@@ -18,9 +18,9 @@
 // }
 
 #if defined(COMPILER_RT_ARMHF_TARGET)
-#  define CONVERT_DCMP_ARGS_TO_DF2_ARGS                    \
-        vmov      d0, r0, r1                     SEPARATOR \
-        vmov      d1, r2, r3
+#  define CONVERT_DCMP_ARGS_TO_DF2_ARGS \
+     VMOV_TO_DOUBLE(d0, r0, r1)         \
+     VMOV_TO_DOUBLE(d1, r2, r3)
 #else
 #  define CONVERT_DCMP_ARGS_TO_DF2_ARGS
 #endif
diff --git a/contrib/libs/cxxsupp/builtins/arm/divdf3vfp.S b/contrib/libs/cxxsupp/builtins/arm/divdf3vfp.S
index ad50b57a651d..c8c0aa84c192 100644
--- a/contrib/libs/cxxsupp/builtins/arm/divdf3vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/divdf3vfp.S
@@ -20,10 +20,10 @@ DEFINE_COMPILERRT_FUNCTION(__divdf3vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vdiv.f64 d0, d0, d1
 #else
-	vmov	d6, r0, r1		// move first param from r0/r1 pair into d6
-	vmov	d7, r2, r3		// move second param from r2/r3 pair into d7
+	VMOV_TO_DOUBLE(d6, r0, r1)		// move first param from r0/r1 pair into d6
+	VMOV_TO_DOUBLE(d7, r2, r3)		// move second param from r2/r3 pair into d7
 	vdiv.f64 d5, d6, d7
-	vmov	r0, r1, d5		// move result back to r0/r1 pair
+	VMOV_FROM_DOUBLE(r0, r1, d5)		// move result back to r0/r1 pair
 #endif
 	bx	lr
 END_COMPILERRT_FUNCTION(__divdf3vfp)
diff --git a/contrib/libs/cxxsupp/builtins/arm/eqdf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/eqdf2vfp.S
index 2a0a64b97e7d..a6f341dc1f46 100644
--- a/contrib/libs/cxxsupp/builtins/arm/eqdf2vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/eqdf2vfp.S
@@ -20,8 +20,8 @@ DEFINE_COMPILERRT_FUNCTION(__eqdf2vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vcmp.f64 d0, d1
 #else
-	vmov	d6, r0, r1	// load r0/r1 pair in double register
-	vmov	d7, r2, r3	// load r2/r3 pair in double register
+	VMOV_TO_DOUBLE(d6, r0, r1)	// load r0/r1 pair in double register
+	VMOV_TO_DOUBLE(d7, r2, r3)	// load r2/r3 pair in double register
 	vcmp.f64 d6, d7
 #endif
 	vmrs	apsr_nzcv, fpscr
diff --git a/contrib/libs/cxxsupp/builtins/arm/extendsfdf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/extendsfdf2vfp.S
index 37c8be8dcd9c..815be830003a 100644
--- a/contrib/libs/cxxsupp/builtins/arm/extendsfdf2vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/extendsfdf2vfp.S
@@ -23,7 +23,7 @@ DEFINE_COMPILERRT_FUNCTION(__extendsfdf2vfp)
 #else
 	vmov	s15, r0      // load float register from R0
 	vcvt.f64.f32 d7, s15 // convert single to double
-	vmov	r0, r1, d7   // return result in r0/r1 pair
+	VMOV_FROM_DOUBLE(r0, r1, d7)   // return result in r0/r1 pair
 #endif
 	bx	lr
 END_COMPILERRT_FUNCTION(__extendsfdf2vfp)
diff --git a/contrib/libs/cxxsupp/builtins/arm/fixdfsivfp.S b/contrib/libs/cxxsupp/builtins/arm/fixdfsivfp.S
index af1d4f4fa5f5..d708f3f4d805 100644
--- a/contrib/libs/cxxsupp/builtins/arm/fixdfsivfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/fixdfsivfp.S
@@ -22,7 +22,7 @@ DEFINE_COMPILERRT_FUNCTION(__fixdfsivfp)
 	vcvt.s32.f64 s0, d0
 	vmov r0, s0
 #else
-	vmov	d7, r0, r1    // load double register from R0/R1
+	VMOV_TO_DOUBLE(d7, r0, r1)    // load double register from R0/R1
 	vcvt.s32.f64 s15, d7  // convert double to 32-bit int into s15
 	vmov	r0, s15	      // move s15 to result register
 #endif
diff --git a/contrib/libs/cxxsupp/builtins/arm/fixunsdfsivfp.S b/contrib/libs/cxxsupp/builtins/arm/fixunsdfsivfp.S
index 44e6dbd4989e..a3dda15e8c04 100644
--- a/contrib/libs/cxxsupp/builtins/arm/fixunsdfsivfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/fixunsdfsivfp.S
@@ -23,7 +23,7 @@ DEFINE_COMPILERRT_FUNCTION(__fixunsdfsivfp)
 	vcvt.u32.f64 s0, d0
 	vmov r0, s0
 #else
-	vmov	d7, r0, r1    // load double register from R0/R1
+	VMOV_TO_DOUBLE(d7, r0, r1)    // load double register from R0/R1
 	vcvt.u32.f64 s15, d7  // convert double to 32-bit int into s15
 	vmov	r0, s15	      // move s15 to result register
 #endif
diff --git a/contrib/libs/cxxsupp/builtins/arm/floatsidfvfp.S b/contrib/libs/cxxsupp/builtins/arm/floatsidfvfp.S
index ae8d2465889c..d0fc5e8a4480 100644
--- a/contrib/libs/cxxsupp/builtins/arm/floatsidfvfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/floatsidfvfp.S
@@ -24,7 +24,7 @@ DEFINE_COMPILERRT_FUNCTION(__floatsidfvfp)
 #else
 	vmov	s15, r0        // move int to float register s15
 	vcvt.f64.s32 d7, s15   // convert 32-bit int in s15 to double in d7
-	vmov	r0, r1, d7     // move d7 to result register pair r0/r1
+	VMOV_FROM_DOUBLE(r0, r1, d7)     // move d7 to result register pair r0/r1
 #endif
 	bx	lr
 END_COMPILERRT_FUNCTION(__floatsidfvfp)
diff --git a/contrib/libs/cxxsupp/builtins/arm/floatunssidfvfp.S b/contrib/libs/cxxsupp/builtins/arm/floatunssidfvfp.S
index 0932dab2bdb9..5acc2d5c0b25 100644
--- a/contrib/libs/cxxsupp/builtins/arm/floatunssidfvfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/floatunssidfvfp.S
@@ -24,7 +24,7 @@ DEFINE_COMPILERRT_FUNCTION(__floatunssidfvfp)
 #else
 	vmov	s15, r0        // move int to float register s15
 	vcvt.f64.u32 d7, s15   // convert 32-bit int in s15 to double in d7
-	vmov	r0, r1, d7     // move d7 to result register pair r0/r1
+	VMOV_FROM_DOUBLE(r0, r1, d7) // move d7 to result register pair r0/r1
 #endif
 	bx	lr
 END_COMPILERRT_FUNCTION(__floatunssidfvfp)
diff --git a/contrib/libs/cxxsupp/builtins/arm/gedf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/gedf2vfp.S
index 2af9d909967b..00746b891c99 100644
--- a/contrib/libs/cxxsupp/builtins/arm/gedf2vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/gedf2vfp.S
@@ -21,8 +21,8 @@ DEFINE_COMPILERRT_FUNCTION(__gedf2vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vcmp.f64 d0, d1
 #else
-	vmov 	d6, r0, r1	// load r0/r1 pair in double register
-	vmov 	d7, r2, r3	// load r2/r3 pair in double register
+	VMOV_TO_DOUBLE(d6, r0, r1)	// load r0/r1 pair in double register
+	VMOV_TO_DOUBLE(d7, r2, r3)	// load r2/r3 pair in double register
 	vcmp.f64 d6, d7
 #endif
 	vmrs	apsr_nzcv, fpscr
diff --git a/contrib/libs/cxxsupp/builtins/arm/gtdf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/gtdf2vfp.S
index 782ad8cac013..980a09eb24b0 100644
--- a/contrib/libs/cxxsupp/builtins/arm/gtdf2vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/gtdf2vfp.S
@@ -21,8 +21,8 @@ DEFINE_COMPILERRT_FUNCTION(__gtdf2vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vcmp.f64 d0, d1
 #else
-	vmov 	d6, r0, r1	// load r0/r1 pair in double register
-	vmov 	d7, r2, r3	// load r2/r3 pair in double register
+	VMOV_TO_DOUBLE(d6, r0, r1)	// load r0/r1 pair in double register
+	VMOV_TO_DOUBLE(d7, r2, r3)	// load r2/r3 pair in double register
 	vcmp.f64 d6, d7
 #endif
 	vmrs	apsr_nzcv, fpscr
diff --git a/contrib/libs/cxxsupp/builtins/arm/ledf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/ledf2vfp.S
index 0097e4b6c129..c7fe6d84535a 100644
--- a/contrib/libs/cxxsupp/builtins/arm/ledf2vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/ledf2vfp.S
@@ -21,8 +21,8 @@ DEFINE_COMPILERRT_FUNCTION(__ledf2vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vcmp.f64 d0, d1
 #else
-	vmov 	d6, r0, r1	// load r0/r1 pair in double register
-	vmov 	d7, r2, r3	// load r2/r3 pair in double register
+	VMOV_TO_DOUBLE(d6, r0, r1)	// load r0/r1 pair in double register
+	VMOV_TO_DOUBLE(d7, r2, r3)	// load r2/r3 pair in double register
 	vcmp.f64 d6, d7
 #endif
 	vmrs	apsr_nzcv, fpscr
diff --git a/contrib/libs/cxxsupp/builtins/arm/ltdf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/ltdf2vfp.S
index a126aa9e0536..be5827075f99 100644
--- a/contrib/libs/cxxsupp/builtins/arm/ltdf2vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/ltdf2vfp.S
@@ -21,8 +21,8 @@ DEFINE_COMPILERRT_FUNCTION(__ltdf2vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vcmp.f64 d0, d1
 #else
-	vmov 	d6, r0, r1	// load r0/r1 pair in double register
-	vmov 	d7, r2, r3	// load r2/r3 pair in double register
+	VMOV_TO_DOUBLE(d6, r0, r1)	// load r0/r1 pair in double register
+	VMOV_TO_DOUBLE(d7, r2, r3)	// load r2/r3 pair in double register
 	vcmp.f64 d6, d7
 #endif
 	vmrs	apsr_nzcv, fpscr
diff --git a/contrib/libs/cxxsupp/builtins/arm/muldf3vfp.S b/contrib/libs/cxxsupp/builtins/arm/muldf3vfp.S
index 9adc937bcb3f..97daf7363787 100644
--- a/contrib/libs/cxxsupp/builtins/arm/muldf3vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/muldf3vfp.S
@@ -20,10 +20,10 @@ DEFINE_COMPILERRT_FUNCTION(__muldf3vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vmul.f64 d0, d0, d1
 #else
-	vmov 	d6, r0, r1         // move first param from r0/r1 pair into d6
-	vmov 	d7, r2, r3         // move second param from r2/r3 pair into d7
+	VMOV_TO_DOUBLE(d6, r0, r1)         // move first param from r0/r1 pair into d6
+	VMOV_TO_DOUBLE(d7, r2, r3)         // move second param from r2/r3 pair into d7
 	vmul.f64 d6, d6, d7
-	vmov 	r0, r1, d6         // move result back to r0/r1 pair
+	VMOV_FROM_DOUBLE(r0, r1, d6)         // move result back to r0/r1 pair
 #endif
 	bx	lr
 END_COMPILERRT_FUNCTION(__muldf3vfp)
diff --git a/contrib/libs/cxxsupp/builtins/arm/nedf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/nedf2vfp.S
index 32d35c41d466..5edafc25988d 100644
--- a/contrib/libs/cxxsupp/builtins/arm/nedf2vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/nedf2vfp.S
@@ -20,8 +20,8 @@ DEFINE_COMPILERRT_FUNCTION(__nedf2vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vcmp.f64 d0, d1
 #else
-	vmov 	d6, r0, r1	// load r0/r1 pair in double register
-	vmov 	d7, r2, r3	// load r2/r3 pair in double register
+	VMOV_TO_DOUBLE(d6, r0, r1)	// load r0/r1 pair in double register
+	VMOV_TO_DOUBLE(d7, r2, r3)	// load r2/r3 pair in double register
 	vcmp.f64 d6, d7
 #endif
 	vmrs	apsr_nzcv, fpscr
diff --git a/contrib/libs/cxxsupp/builtins/arm/subdf3vfp.S b/contrib/libs/cxxsupp/builtins/arm/subdf3vfp.S
index f4eaf9af1afe..2a7b1d38b577 100644
--- a/contrib/libs/cxxsupp/builtins/arm/subdf3vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/subdf3vfp.S
@@ -20,10 +20,10 @@ DEFINE_COMPILERRT_FUNCTION(__subdf3vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vsub.f64 d0, d0, d1
 #else
-	vmov 	d6, r0, r1         // move first param from r0/r1 pair into d6
-	vmov 	d7, r2, r3         // move second param from r2/r3 pair into d7
+	VMOV_TO_DOUBLE(d6, r0, r1)         // move first param from r0/r1 pair into d6
+	VMOV_TO_DOUBLE(d7, r2, r3)         // move second param from r2/r3 pair into d7
 	vsub.f64 d6, d6, d7
-	vmov 	r0, r1, d6         // move result back to r0/r1 pair
+	VMOV_FROM_DOUBLE(r0, r1, d6)         // move result back to r0/r1 pair
 #endif
 	bx	lr
 END_COMPILERRT_FUNCTION(__subdf3vfp)
diff --git a/contrib/libs/cxxsupp/builtins/arm/truncdfsf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/truncdfsf2vfp.S
index e1c171262a78..541d025b4f92 100644
--- a/contrib/libs/cxxsupp/builtins/arm/truncdfsf2vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/truncdfsf2vfp.S
@@ -21,7 +21,7 @@ DEFINE_COMPILERRT_FUNCTION(__truncdfsf2vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vcvt.f32.f64 s0, d0
 #else
-	vmov 	d7, r0, r1   // load double from r0/r1 pair
+	VMOV_TO_DOUBLE(d7, r0, r1)   // load double from r0/r1 pair
 	vcvt.f32.f64 s15, d7 // convert double to single (trucate precision)
 	vmov 	r0, s15      // return result in r0
 #endif
diff --git a/contrib/libs/cxxsupp/builtins/arm/unorddf2vfp.S b/contrib/libs/cxxsupp/builtins/arm/unorddf2vfp.S
index ea36a1cb5594..3abb622c81ec 100644
--- a/contrib/libs/cxxsupp/builtins/arm/unorddf2vfp.S
+++ b/contrib/libs/cxxsupp/builtins/arm/unorddf2vfp.S
@@ -21,8 +21,8 @@ DEFINE_COMPILERRT_FUNCTION(__unorddf2vfp)
 #if defined(COMPILER_RT_ARMHF_TARGET)
 	vcmp.f64 d0, d1
 #else
-	vmov 	d6, r0, r1	// load r0/r1 pair in double register
-	vmov 	d7, r2, r3	// load r2/r3 pair in double register
+	VMOV_TO_DOUBLE(d6, r0, r1)	// load r0/r1 pair in double register
+	VMOV_TO_DOUBLE(d7, r2, r3)	// load r2/r3 pair in double register
 	vcmp.f64 d6, d7
 #endif
 	vmrs	apsr_nzcv, fpscr
diff --git a/contrib/libs/cxxsupp/builtins/assembly.h b/contrib/libs/cxxsupp/builtins/assembly.h
index 8c42fc773483..34c71241524d 100644
--- a/contrib/libs/cxxsupp/builtins/assembly.h
+++ b/contrib/libs/cxxsupp/builtins/assembly.h
@@ -290,4 +290,16 @@
   CFI_END
 #endif
 
+#ifdef __arm__
+#include "int_endianness.h"
+
+#if _YUGA_BIG_ENDIAN
+#define VMOV_TO_DOUBLE(dst, src0, src1) vmov dst, src1, src0 SEPARATOR
+#define VMOV_FROM_DOUBLE(dst0, dst1, src) vmov dst1, dst0, src SEPARATOR
+#else
+#define VMOV_TO_DOUBLE(dst, src0, src1) vmov dst, src0, src1 SEPARATOR
+#define VMOV_FROM_DOUBLE(dst0, dst1, src) vmov dst0, dst1, src SEPARATOR
+#endif
+#endif
+
 #endif // COMPILERRT_ASSEMBLY_H
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/AArch64CPUFeatures.inc b/contrib/libs/cxxsupp/builtins/cpu_model/AArch64CPUFeatures.inc
index e78bb88cfedf..778f568c95c5 100644
--- a/contrib/libs/cxxsupp/builtins/cpu_model/AArch64CPUFeatures.inc
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/AArch64CPUFeatures.inc
@@ -33,10 +33,10 @@ enum CPUFeatures {
   FEAT_FP,
   FEAT_SIMD,
   FEAT_CRC,
-  FEAT_SHA1,
+  RESERVED_FEAT_SHA1, // previously used and now ABI legacy
   FEAT_SHA2,
   FEAT_SHA3,
-  FEAT_AES,
+  RESERVED_FEAT_AES, // previously used and now ABI legacy
   FEAT_PMULL,
   FEAT_FP16,
   FEAT_DIT,
@@ -47,35 +47,35 @@ enum CPUFeatures {
   FEAT_RCPC,
   FEAT_RCPC2,
   FEAT_FRINTTS,
-  FEAT_DGH,
+  RESERVED_FEAT_DGH, // previously used and now ABI legacy
   FEAT_I8MM,
   FEAT_BF16,
-  FEAT_EBF16,
-  FEAT_RPRES,
+  RESERVED_FEAT_EBF16, // previously used and now ABI legacy
+  RESERVED_FEAT_RPRES, // previously used and now ABI legacy
   FEAT_SVE,
-  FEAT_SVE_BF16,
-  FEAT_SVE_EBF16,
-  FEAT_SVE_I8MM,
+  RESERVED_FEAT_SVE_BF16,  // previously used and now ABI legacy
+  RESERVED_FEAT_SVE_EBF16, // previously used and now ABI legacy
+  RESERVED_FEAT_SVE_I8MM,  // previously used and now ABI legacy
   FEAT_SVE_F32MM,
   FEAT_SVE_F64MM,
   FEAT_SVE2,
-  FEAT_SVE_AES,
+  RESERVED_FEAT_SVE_AES, // previously used and now ABI legacy
   FEAT_SVE_PMULL128,
   FEAT_SVE_BITPERM,
   FEAT_SVE_SHA3,
   FEAT_SVE_SM4,
   FEAT_SME,
-  FEAT_MEMTAG,
+  RESERVED_FEAT_MEMTAG, // previously used and now ABI legacy
   FEAT_MEMTAG2,
-  FEAT_MEMTAG3,
+  RESERVED_FEAT_MEMTAG3, // previously used and now ABI legacy
   FEAT_SB,
-  FEAT_PREDRES,
-  FEAT_SSBS,
+  RESERVED_FEAT_PREDRES, // previously used and now ABI legacy
+  RESERVED_FEAT_SSBS,    // previously used and now ABI legacy
   FEAT_SSBS2,
   FEAT_BTI,
-  FEAT_LS64,
-  FEAT_LS64_V,
-  FEAT_LS64_ACCDATA,
+  RESERVED_FEAT_LS64,         // previously used and now ABI legacy
+  RESERVED_FEAT_LS64_V,       // previously used and now ABI legacy
+  RESERVED_FEAT_LS64_ACCDATA, // previously used and now ABI legacy
   FEAT_WFXT,
   FEAT_SME_F64,
   FEAT_SME_I64,
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.c b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.c
index b868caa991b2..4082fd62ea11 100644
--- a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.c
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.c
@@ -14,7 +14,7 @@
 
 #include "aarch64.h"
 
-#if !defined(__aarch64__)
+#if !defined(__aarch64__) && !defined(__arm64__) && !defined(_M_ARM64)
 #error This file is intended only for aarch64-based targets
 #endif
 
@@ -45,9 +45,11 @@ _Bool __aarch64_have_lse_atomics
 #elif defined(__ANDROID__)
 #include "aarch64/hwcap.inc"
 #include "aarch64/lse_atomics/android.inc"
-#elif __has_include(<sys/auxv.h>)
+#elif defined(__linux__) && __has_include(<sys/auxv.h>)
 #include "aarch64/hwcap.inc"
-#include "aarch64/lse_atomics/sysauxv.inc"
+#include "aarch64/lse_atomics/getauxval.inc"
+#elif defined(_WIN32)
+#include "aarch64/lse_atomics/windows.inc"
 #else
 // When unimplemented, we leave __aarch64_have_lse_atomics initialized to false.
 #endif
@@ -73,9 +75,13 @@ struct {
 #elif defined(__ANDROID__)
 #include "aarch64/fmv/mrs.inc"
 #include "aarch64/fmv/android.inc"
-#elif __has_include(<sys/auxv.h>)
+#elif defined(__linux__) && __has_include(<sys/auxv.h>)
 #include "aarch64/fmv/mrs.inc"
-#include "aarch64/fmv/sysauxv.inc"
+#include "aarch64/fmv/getauxval.inc"
+#elif defined(_WIN32)
+#include "aarch64/fmv/windows.inc"
+#elif defined(ENABLE_BAREMETAL_AARCH64_FMV)
+#include "aarch64/fmv/baremetal.inc"
 #else
 #include "aarch64/fmv/unimplemented.inc"
 #endif
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.h b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.h
index f6cbf75d582f..2a734b02b7c9 100644
--- a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.h
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64.h
@@ -8,7 +8,7 @@
 
 #include "cpu_model.h"
 
-#if !defined(__aarch64__)
+#if !defined(__aarch64__) && !defined(__arm64__) && !defined(_M_ARM64)
 #error This file is intended only for aarch64-based targets
 #endif
 
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/apple.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/apple.inc
index f0694900f231..d5c85701ad1a 100644
--- a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/apple.inc
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/apple.inc
@@ -31,10 +31,6 @@ static bool isKnownAndSupported(const char *name) {
 }
 
 static uint64_t deriveImplicitFeatures(uint64_t features) {
-  // FEAT_SSBS2 implies FEAT_SSBS
-  if ((1ULL << FEAT_SSBS2) & features)
-    features |= (1ULL << FEAT_SSBS);
-
   // FEAT_FP is always enabled
   features |= (1ULL << FEAT_FP);
 
@@ -77,10 +73,7 @@ void __init_cpu_features_resolver(void) {
     CHECK_BIT(CAP_BIT_FEAT_RDM, FEAT_RDM);
     CHECK_BIT(CAP_BIT_FEAT_LSE, FEAT_LSE);
     CHECK_BIT(CAP_BIT_FEAT_SHA256, FEAT_SHA2);
-    CHECK_BIT(CAP_BIT_FEAT_SHA1, FEAT_SHA1);
-    CHECK_BIT(CAP_BIT_FEAT_AES, FEAT_AES);
     CHECK_BIT(CAP_BIT_FEAT_PMULL, FEAT_PMULL);
-    CHECK_BIT(CAP_BIT_FEAT_SPECRES, FEAT_PREDRES);
     CHECK_BIT(CAP_BIT_FEAT_SB, FEAT_SB);
     CHECK_BIT(CAP_BIT_FEAT_FRINTTS, FEAT_FRINTTS);
     CHECK_BIT(CAP_BIT_FEAT_LRCPC, FEAT_RCPC);
@@ -123,10 +116,8 @@ void __init_cpu_features_resolver(void) {
       {"hw.optional.arm.FEAT_LSE", FEAT_LSE},
       {"hw.optional.AdvSIMD", FEAT_SIMD},
       {"hw.optional.armv8_crc32", FEAT_CRC},
-      {"hw.optional.arm.FEAT_SHA1", FEAT_SHA1},
       {"hw.optional.arm.FEAT_SHA256", FEAT_SHA2},
       {"hw.optional.arm.FEAT_SHA3", FEAT_SHA3},
-      {"hw.optional.arm.FEAT_AES", FEAT_AES},
       {"hw.optional.arm.FEAT_PMULL", FEAT_PMULL},
       {"hw.optional.arm.FEAT_FP16", FEAT_FP16},
       {"hw.optional.arm.FEAT_DIT", FEAT_DIT},
@@ -140,7 +131,6 @@ void __init_cpu_features_resolver(void) {
       {"hw.optional.arm.FEAT_I8MM", FEAT_I8MM},
       {"hw.optional.arm.FEAT_BF16", FEAT_BF16},
       {"hw.optional.arm.FEAT_SB", FEAT_SB},
-      {"hw.optional.arm.FEAT_SPECRES", FEAT_PREDRES},
       {"hw.optional.arm.FEAT_SSBS", FEAT_SSBS2},
       {"hw.optional.arm.FEAT_BTI", FEAT_BTI},
   };
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/baremetal.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/baremetal.inc
new file mode 100644
index 000000000000..f188e84808e0
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/baremetal.inc
@@ -0,0 +1,31 @@
+// For baremetal platforms, we don't really initialise '__aarch64_cpu_features',
+// with exception of FEAT_SME that we can get from '__aarch64_sme_accessible'.
+
+#if defined(COMPILER_RT_SHARED_LIB)
+__attribute__((weak))
+#endif
+extern _Bool
+__aarch64_sme_accessible(void);
+
+static _Bool has_sme(void) {
+#if defined(COMPILER_RT_SHARED_LIB)
+  if (!__aarch64_sme_accessible)
+    return 0;
+#endif
+  return __aarch64_sme_accessible();
+}
+
+void __init_cpu_features_resolver(unsigned long hwcap,
+                                  const __ifunc_arg_t *arg) {}
+
+void CONSTRUCTOR_ATTRIBUTE __init_cpu_features(void) {
+  // CPU features already initialized.
+  if (__atomic_load_n(&__aarch64_cpu_features.features, __ATOMIC_RELAXED))
+    return;
+
+  unsigned long long feat = 0;
+  if (has_sme())
+    feat |= 1ULL << FEAT_SME;
+
+  __atomic_store_n(&__aarch64_cpu_features.features, feat, __ATOMIC_RELAXED);
+}
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/fuchsia.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/fuchsia.inc
index fd0800dd11e7..9851e5e38394 100644
--- a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/fuchsia.inc
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/fuchsia.inc
@@ -20,12 +20,8 @@ void __init_cpu_features_resolver() {
     setCPUFeature(FEAT_FP);
   if (features & ZX_ARM64_FEATURE_ISA_ASIMD)
     setCPUFeature(FEAT_SIMD);
-  if (features & ZX_ARM64_FEATURE_ISA_AES)
-    setCPUFeature(FEAT_AES);
   if (features & ZX_ARM64_FEATURE_ISA_PMULL)
     setCPUFeature(FEAT_PMULL);
-  if (features & ZX_ARM64_FEATURE_ISA_SHA1)
-    setCPUFeature(FEAT_SHA1);
   if (features & ZX_ARM64_FEATURE_ISA_SHA256)
     setCPUFeature(FEAT_SHA2);
   if (features & ZX_ARM64_FEATURE_ISA_CRC32)
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/sysauxv.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/getauxval.inc
similarity index 100%
rename from contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/sysauxv.inc
rename to contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/getauxval.inc
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/mrs.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/mrs.inc
index e4d5e7f2bd7e..6d46fccdc79d 100644
--- a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/mrs.inc
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/mrs.inc
@@ -33,10 +33,6 @@ static void __init_cpu_features_constructor(unsigned long hwcap,
     setCPUFeature(FEAT_DIT);
   if (hwcap & HWCAP_ASIMDRDM)
     setCPUFeature(FEAT_RDM);
-  if (hwcap & HWCAP_AES)
-    setCPUFeature(FEAT_AES);
-  if (hwcap & HWCAP_SHA1)
-    setCPUFeature(FEAT_SHA1);
   if (hwcap & HWCAP_SHA2)
     setCPUFeature(FEAT_SHA2);
   if (hwcap & HWCAP_JSCVT)
@@ -45,18 +41,10 @@ static void __init_cpu_features_constructor(unsigned long hwcap,
     setCPUFeature(FEAT_FCMA);
   if (hwcap & HWCAP_SB)
     setCPUFeature(FEAT_SB);
-  if (hwcap & HWCAP_SSBS) {
-    setCPUFeature(FEAT_SSBS);
+  if (hwcap & HWCAP_SSBS)
     setCPUFeature(FEAT_SSBS2);
-  }
-  if (hwcap2 & HWCAP2_MTE) {
-    setCPUFeature(FEAT_MEMTAG);
+  if (hwcap2 & HWCAP2_MTE)
     setCPUFeature(FEAT_MEMTAG2);
-  }
-  if (hwcap2 & HWCAP2_MTE3)
-    setCPUFeature(FEAT_MEMTAG3);
-  if (hwcap2 & HWCAP2_SVEAES)
-    setCPUFeature(FEAT_SVE_AES);
   if (hwcap2 & HWCAP2_SVEPMULL)
     setCPUFeature(FEAT_SVE_PMULL128);
   if (hwcap2 & HWCAP2_SVEBITPERM)
@@ -73,24 +61,14 @@ static void __init_cpu_features_constructor(unsigned long hwcap,
     setCPUFeature(FEAT_RNG);
   if (hwcap2 & HWCAP2_I8MM)
     setCPUFeature(FEAT_I8MM);
-  if (hwcap2 & HWCAP2_EBF16)
-    setCPUFeature(FEAT_EBF16);
-  if (hwcap2 & HWCAP2_SVE_EBF16)
-    setCPUFeature(FEAT_SVE_EBF16);
-  if (hwcap2 & HWCAP2_DGH)
-    setCPUFeature(FEAT_DGH);
   if (hwcap2 & HWCAP2_FRINT)
     setCPUFeature(FEAT_FRINTTS);
-  if (hwcap2 & HWCAP2_SVEI8MM)
-    setCPUFeature(FEAT_SVE_I8MM);
   if (hwcap2 & HWCAP2_SVEF32MM)
     setCPUFeature(FEAT_SVE_F32MM);
   if (hwcap2 & HWCAP2_SVEF64MM)
     setCPUFeature(FEAT_SVE_F64MM);
   if (hwcap2 & HWCAP2_BTI)
     setCPUFeature(FEAT_BTI);
-  if (hwcap2 & HWCAP2_RPRES)
-    setCPUFeature(FEAT_RPRES);
   if (hwcap2 & HWCAP2_WFXT)
     setCPUFeature(FEAT_WFXT);
   if (hwcap2 & HWCAP2_SME)
@@ -103,23 +81,6 @@ static void __init_cpu_features_constructor(unsigned long hwcap,
     setCPUFeature(FEAT_SME_F64);
   if (hwcap2 & HWCAP2_MOPS)
     setCPUFeature(FEAT_MOPS);
-  if (hwcap & HWCAP_CPUID) {
-    unsigned long ftr;
-
-    getCPUFeature(ID_AA64ISAR1_EL1, ftr);
-    /* ID_AA64ISAR1_EL1.SPECRES >= 0b0001  */
-    if (extractBits(ftr, 40, 4) >= 0x1)
-      setCPUFeature(FEAT_PREDRES);
-    /* ID_AA64ISAR1_EL1.LS64 >= 0b0001  */
-    if (extractBits(ftr, 60, 4) >= 0x1)
-      setCPUFeature(FEAT_LS64);
-    /* ID_AA64ISAR1_EL1.LS64 >= 0b0010  */
-    if (extractBits(ftr, 60, 4) >= 0x2)
-      setCPUFeature(FEAT_LS64_V);
-    /* ID_AA64ISAR1_EL1.LS64 >= 0b0011  */
-    if (extractBits(ftr, 60, 4) >= 0x3)
-      setCPUFeature(FEAT_LS64_ACCDATA);
-  }
   if (hwcap & HWCAP_FP) {
     setCPUFeature(FEAT_FP);
     // FP and AdvSIMD fields have the same value
@@ -135,8 +96,6 @@ static void __init_cpu_features_constructor(unsigned long hwcap,
     setCPUFeature(FEAT_RCPC3);
   if (hwcap2 & HWCAP2_BF16)
     setCPUFeature(FEAT_BF16);
-  if (hwcap2 & HWCAP2_SVEBF16)
-    setCPUFeature(FEAT_SVE_BF16);
   if (hwcap & HWCAP_SVE)
     setCPUFeature(FEAT_SVE);
   if (hwcap2 & HWCAP2_SVE2)
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/windows.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/windows.inc
new file mode 100644
index 000000000000..2ca18242fba3
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/fmv/windows.inc
@@ -0,0 +1,85 @@
+#define WIN32_LEAN_AND_MEAN
+#include <windows.h>
+#include <processthreadsapi.h>
+#include <stdint.h>
+
+#ifndef PF_ARM_V82_DP_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_V82_DP_INSTRUCTIONS_AVAILABLE 43 
+#endif
+#ifndef PF_ARM_V83_JSCVT_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_V83_JSCVT_INSTRUCTIONS_AVAILABLE 44
+#endif
+#ifndef PF_ARM_V83_LRCPC_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_V83_LRCPC_INSTRUCTIONS_AVAILABLE 45
+#endif
+#ifndef PF_ARM_SVE_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_SVE_INSTRUCTIONS_AVAILABLE 46
+#endif
+#ifndef PF_ARM_SVE2_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_SVE2_INSTRUCTIONS_AVAILABLE 47
+#endif
+#ifndef PF_ARM_SVE_PMULL128_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_SVE_PMULL128_INSTRUCTIONS_AVAILABLE 50
+#endif
+#ifndef PF_ARM_SVE_SHA3_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_SVE_SHA3_INSTRUCTIONS_AVAILABLE 55
+#endif
+#ifndef PF_ARM_SVE_SM4_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_SVE_SM4_INSTRUCTIONS_AVAILABLE 56
+#endif
+#ifndef PF_ARM_SVE_I8MM_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_SVE_I8MM_INSTRUCTIONS_AVAILABLE 57
+#endif
+#ifndef PF_ARM_SVE_F32MM_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_SVE_F32MM_INSTRUCTIONS_AVAILABLE 58
+#endif
+#ifndef PF_ARM_SVE_F64MM_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_SVE_F64MM_INSTRUCTIONS_AVAILABLE 59
+#endif
+
+void __init_cpu_features_resolver(unsigned long hwcap,
+                                  const __ifunc_arg_t *arg) {}
+
+void CONSTRUCTOR_ATTRIBUTE __init_cpu_features(void) {
+  if (__atomic_load_n(&__aarch64_cpu_features.features, __ATOMIC_RELAXED))
+    return;
+
+#define setCPUFeature(F) features |= 1ULL << F
+
+  uint64_t features = 0;
+
+  setCPUFeature(FEAT_INIT);
+  setCPUFeature(FEAT_FP);
+
+  // https://learn.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-isprocessorfeaturepresent
+  if (IsProcessorFeaturePresent(PF_ARM_V8_CRYPTO_INSTRUCTIONS_AVAILABLE)) {
+    setCPUFeature(FEAT_SHA2);
+    setCPUFeature(FEAT_PMULL);
+  }
+
+  static const struct ProcessFeatureToFeatMap_t {
+    int WinApiFeature;
+    enum CPUFeatures CPUFeature;
+  } FeatMap[] = {
+      {PF_ARM_V8_CRC32_INSTRUCTIONS_AVAILABLE, FEAT_CRC},
+      {PF_ARM_V81_ATOMIC_INSTRUCTIONS_AVAILABLE, FEAT_LSE},
+      {PF_ARM_V82_DP_INSTRUCTIONS_AVAILABLE, FEAT_DOTPROD},
+      {PF_ARM_V83_JSCVT_INSTRUCTIONS_AVAILABLE, FEAT_JSCVT},
+      {PF_ARM_V83_LRCPC_INSTRUCTIONS_AVAILABLE, FEAT_RCPC},
+      {PF_ARM_SVE_INSTRUCTIONS_AVAILABLE, FEAT_SVE},
+      {PF_ARM_SVE2_INSTRUCTIONS_AVAILABLE, FEAT_SVE2},
+      {PF_ARM_SVE_PMULL128_INSTRUCTIONS_AVAILABLE, FEAT_SVE_PMULL128},
+      {PF_ARM_SVE_SHA3_INSTRUCTIONS_AVAILABLE, FEAT_SVE_SHA3},
+      {PF_ARM_SVE_SM4_INSTRUCTIONS_AVAILABLE, FEAT_SVE_SM4},
+      {PF_ARM_SVE_F32MM_INSTRUCTIONS_AVAILABLE, FEAT_SVE_F32MM},
+      {PF_ARM_SVE_F64MM_INSTRUCTIONS_AVAILABLE, FEAT_SVE_F64MM},
+      // There is no I8MM flag, but when SVE_I8MM is available, I8MM is too.
+      {PF_ARM_SVE_I8MM_INSTRUCTIONS_AVAILABLE, FEAT_I8MM},
+  };
+
+  for (size_t I = 0, E = sizeof(FeatMap) / sizeof(FeatMap[0]); I != E; ++I)
+    if (IsProcessorFeaturePresent(FeatMap[I].WinApiFeature))
+      setCPUFeature(FeatMap[I].CPUFeature);
+
+  __atomic_store(&__aarch64_cpu_features.features, &features, __ATOMIC_RELAXED);
+}
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/sysauxv.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/getauxval.inc
similarity index 100%
rename from contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/sysauxv.inc
rename to contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/getauxval.inc
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/windows.inc b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/windows.inc
new file mode 100644
index 000000000000..fff1593e1fac
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/aarch64/lse_atomics/windows.inc
@@ -0,0 +1,12 @@
+#define WIN32_LEAN_AND_MEAN
+#include <windows.h>
+#include <processthreadsapi.h>
+
+#ifndef PF_ARM_V81_ATOMIC_INSTRUCTIONS_AVAILABLE
+#define PF_ARM_V81_ATOMIC_INSTRUCTIONS_AVAILABLE 34
+#endif
+
+static void CONSTRUCTOR_ATTRIBUTE init_have_lse_atomics(void) {
+  if (IsProcessorFeaturePresent(PF_ARM_V81_ATOMIC_INSTRUCTIONS_AVAILABLE))
+    __aarch64_have_lse_atomics = true;
+}
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/cpu_model.h b/contrib/libs/cxxsupp/builtins/cpu_model/cpu_model.h
index 924ca89cf60f..3bc4e63c4f25 100644
--- a/contrib/libs/cxxsupp/builtins/cpu_model/cpu_model.h
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/cpu_model.h
@@ -31,7 +31,15 @@
 // We're choosing init priority 90 to force our constructors to run before any
 // constructors in the end user application (starting at priority 101). This
 // value matches the libgcc choice for the same functions.
-#define CONSTRUCTOR_ATTRIBUTE __attribute__((constructor(90)))
+#ifdef _WIN32
+// Contructor that replaces the ifunc runs currently with prio 10, see
+// the LowerIFuncPass. The resolver of FMV depends on the cpu features so set
+// the priority to 9.
+#define CONSTRUCTOR_PRIORITY 9
+#else
+#define CONSTRUCTOR_PRIORITY 90
+#endif
+#define CONSTRUCTOR_ATTRIBUTE __attribute__((constructor(CONSTRUCTOR_PRIORITY)))
 #else
 // FIXME: For MSVC, we should make a function pointer global in .CRT$X?? so that
 // this runs during initialization.
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/riscv.c b/contrib/libs/cxxsupp/builtins/cpu_model/riscv.c
new file mode 100644
index 000000000000..6879c2ad4826
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/riscv.c
@@ -0,0 +1,368 @@
+//=== cpu_model/riscv.c - Update RISC-V Feature Bits Structure -*- C -*-======//
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#include "cpu_model.h"
+
+#define RISCV_FEATURE_BITS_LENGTH 2
+struct {
+  unsigned length;
+  unsigned long long features[RISCV_FEATURE_BITS_LENGTH];
+} __riscv_feature_bits __attribute__((visibility("hidden"), nocommon));
+
+struct {
+  unsigned mvendorid;
+  unsigned long long marchid;
+  unsigned long long mimpid;
+} __riscv_cpu_model __attribute__((visibility("hidden"), nocommon));
+
+// NOTE: Should sync-up with RISCVFeatures.td
+// TODO: Maybe generate a header from tablegen then include it.
+#define A_GROUPID 0
+#define A_BITMASK (1ULL << 0)
+#define C_GROUPID 0
+#define C_BITMASK (1ULL << 2)
+#define D_GROUPID 0
+#define D_BITMASK (1ULL << 3)
+#define F_GROUPID 0
+#define F_BITMASK (1ULL << 5)
+#define I_GROUPID 0
+#define I_BITMASK (1ULL << 8)
+#define M_GROUPID 0
+#define M_BITMASK (1ULL << 12)
+#define V_GROUPID 0
+#define V_BITMASK (1ULL << 21)
+#define ZACAS_GROUPID 0
+#define ZACAS_BITMASK (1ULL << 26)
+#define ZBA_GROUPID 0
+#define ZBA_BITMASK (1ULL << 27)
+#define ZBB_GROUPID 0
+#define ZBB_BITMASK (1ULL << 28)
+#define ZBC_GROUPID 0
+#define ZBC_BITMASK (1ULL << 29)
+#define ZBKB_GROUPID 0
+#define ZBKB_BITMASK (1ULL << 30)
+#define ZBKC_GROUPID 0
+#define ZBKC_BITMASK (1ULL << 31)
+#define ZBKX_GROUPID 0
+#define ZBKX_BITMASK (1ULL << 32)
+#define ZBS_GROUPID 0
+#define ZBS_BITMASK (1ULL << 33)
+#define ZFA_GROUPID 0
+#define ZFA_BITMASK (1ULL << 34)
+#define ZFH_GROUPID 0
+#define ZFH_BITMASK (1ULL << 35)
+#define ZFHMIN_GROUPID 0
+#define ZFHMIN_BITMASK (1ULL << 36)
+#define ZICBOZ_GROUPID 0
+#define ZICBOZ_BITMASK (1ULL << 37)
+#define ZICOND_GROUPID 0
+#define ZICOND_BITMASK (1ULL << 38)
+#define ZIHINTNTL_GROUPID 0
+#define ZIHINTNTL_BITMASK (1ULL << 39)
+#define ZIHINTPAUSE_GROUPID 0
+#define ZIHINTPAUSE_BITMASK (1ULL << 40)
+#define ZKND_GROUPID 0
+#define ZKND_BITMASK (1ULL << 41)
+#define ZKNE_GROUPID 0
+#define ZKNE_BITMASK (1ULL << 42)
+#define ZKNH_GROUPID 0
+#define ZKNH_BITMASK (1ULL << 43)
+#define ZKSED_GROUPID 0
+#define ZKSED_BITMASK (1ULL << 44)
+#define ZKSH_GROUPID 0
+#define ZKSH_BITMASK (1ULL << 45)
+#define ZKT_GROUPID 0
+#define ZKT_BITMASK (1ULL << 46)
+#define ZTSO_GROUPID 0
+#define ZTSO_BITMASK (1ULL << 47)
+#define ZVBB_GROUPID 0
+#define ZVBB_BITMASK (1ULL << 48)
+#define ZVBC_GROUPID 0
+#define ZVBC_BITMASK (1ULL << 49)
+#define ZVFH_GROUPID 0
+#define ZVFH_BITMASK (1ULL << 50)
+#define ZVFHMIN_GROUPID 0
+#define ZVFHMIN_BITMASK (1ULL << 51)
+#define ZVKB_GROUPID 0
+#define ZVKB_BITMASK (1ULL << 52)
+#define ZVKG_GROUPID 0
+#define ZVKG_BITMASK (1ULL << 53)
+#define ZVKNED_GROUPID 0
+#define ZVKNED_BITMASK (1ULL << 54)
+#define ZVKNHA_GROUPID 0
+#define ZVKNHA_BITMASK (1ULL << 55)
+#define ZVKNHB_GROUPID 0
+#define ZVKNHB_BITMASK (1ULL << 56)
+#define ZVKSED_GROUPID 0
+#define ZVKSED_BITMASK (1ULL << 57)
+#define ZVKSH_GROUPID 0
+#define ZVKSH_BITMASK (1ULL << 58)
+#define ZVKT_GROUPID 0
+#define ZVKT_BITMASK (1ULL << 59)
+#define ZVE32X_GROUPID 0
+#define ZVE32X_BITMASK (1ULL << 60)
+#define ZVE32F_GROUPID 0
+#define ZVE32F_BITMASK (1ULL << 61)
+#define ZVE64X_GROUPID 0
+#define ZVE64X_BITMASK (1ULL << 62)
+#define ZVE64F_GROUPID 0
+#define ZVE64F_BITMASK (1ULL << 63)
+#define ZVE64D_GROUPID 1
+#define ZVE64D_BITMASK (1ULL << 0)
+#define ZIMOP_GROUPID 1
+#define ZIMOP_BITMASK (1ULL << 1)
+#define ZCA_GROUPID 1
+#define ZCA_BITMASK (1ULL << 2)
+#define ZCB_GROUPID 1
+#define ZCB_BITMASK (1ULL << 3)
+#define ZCD_GROUPID 1
+#define ZCD_BITMASK (1ULL << 4)
+#define ZCF_GROUPID 1
+#define ZCF_BITMASK (1ULL << 5)
+#define ZCMOP_GROUPID 1
+#define ZCMOP_BITMASK (1ULL << 6)
+#define ZAWRS_GROUPID 1
+#define ZAWRS_BITMASK (1ULL << 7)
+
+#if defined(__linux__)
+
+// The RISC-V hwprobe interface is documented here:
+// <https://docs.kernel.org/arch/riscv/hwprobe.html>.
+
+static long syscall_impl_5_args(long number, long arg1, long arg2, long arg3,
+                                long arg4, long arg5) {
+  register long a7 __asm__("a7") = number;
+  register long a0 __asm__("a0") = arg1;
+  register long a1 __asm__("a1") = arg2;
+  register long a2 __asm__("a2") = arg3;
+  register long a3 __asm__("a3") = arg4;
+  register long a4 __asm__("a4") = arg5;
+  __asm__ __volatile__("ecall
\t"
+                       : "=r"(a0)
+                       : "r"(a7), "r"(a0), "r"(a1), "r"(a2), "r"(a3), "r"(a4)
+                       : "memory");
+  return a0;
+}
+
+#define RISCV_HWPROBE_KEY_MVENDORID 0
+#define RISCV_HWPROBE_KEY_MARCHID 1
+#define RISCV_HWPROBE_KEY_MIMPID 2
+#define RISCV_HWPROBE_KEY_BASE_BEHAVIOR 3
+#define RISCV_HWPROBE_BASE_BEHAVIOR_IMA (1ULL << 0)
+#define RISCV_HWPROBE_KEY_IMA_EXT_0 4
+#define RISCV_HWPROBE_IMA_FD (1ULL << 0)
+#define RISCV_HWPROBE_IMA_C (1ULL << 1)
+#define RISCV_HWPROBE_IMA_V (1ULL << 2)
+#define RISCV_HWPROBE_EXT_ZBA (1ULL << 3)
+#define RISCV_HWPROBE_EXT_ZBB (1ULL << 4)
+#define RISCV_HWPROBE_EXT_ZBS (1ULL << 5)
+#define RISCV_HWPROBE_EXT_ZICBOZ (1ULL << 6)
+#define RISCV_HWPROBE_EXT_ZBC (1ULL << 7)
+#define RISCV_HWPROBE_EXT_ZBKB (1ULL << 8)
+#define RISCV_HWPROBE_EXT_ZBKC (1ULL << 9)
+#define RISCV_HWPROBE_EXT_ZBKX (1ULL << 10)
+#define RISCV_HWPROBE_EXT_ZKND (1ULL << 11)
+#define RISCV_HWPROBE_EXT_ZKNE (1ULL << 12)
+#define RISCV_HWPROBE_EXT_ZKNH (1ULL << 13)
+#define RISCV_HWPROBE_EXT_ZKSED (1ULL << 14)
+#define RISCV_HWPROBE_EXT_ZKSH (1ULL << 15)
+#define RISCV_HWPROBE_EXT_ZKT (1ULL << 16)
+#define RISCV_HWPROBE_EXT_ZVBB (1ULL << 17)
+#define RISCV_HWPROBE_EXT_ZVBC (1ULL << 18)
+#define RISCV_HWPROBE_EXT_ZVKB (1ULL << 19)
+#define RISCV_HWPROBE_EXT_ZVKG (1ULL << 20)
+#define RISCV_HWPROBE_EXT_ZVKNED (1ULL << 21)
+#define RISCV_HWPROBE_EXT_ZVKNHA (1ULL << 22)
+#define RISCV_HWPROBE_EXT_ZVKNHB (1ULL << 23)
+#define RISCV_HWPROBE_EXT_ZVKSED (1ULL << 24)
+#define RISCV_HWPROBE_EXT_ZVKSH (1ULL << 25)
+#define RISCV_HWPROBE_EXT_ZVKT (1ULL << 26)
+#define RISCV_HWPROBE_EXT_ZFH (1ULL << 27)
+#define RISCV_HWPROBE_EXT_ZFHMIN (1ULL << 28)
+#define RISCV_HWPROBE_EXT_ZIHINTNTL (1ULL << 29)
+#define RISCV_HWPROBE_EXT_ZVFH (1ULL << 30)
+#define RISCV_HWPROBE_EXT_ZVFHMIN (1ULL << 31)
+#define RISCV_HWPROBE_EXT_ZFA (1ULL << 32)
+#define RISCV_HWPROBE_EXT_ZTSO (1ULL << 33)
+#define RISCV_HWPROBE_EXT_ZACAS (1ULL << 34)
+#define RISCV_HWPROBE_EXT_ZICOND (1ULL << 35)
+#define RISCV_HWPROBE_EXT_ZIHINTPAUSE (1ULL << 36)
+#define RISCV_HWPROBE_EXT_ZVE32X (1ULL << 37)
+#define RISCV_HWPROBE_EXT_ZVE32F (1ULL << 38)
+#define RISCV_HWPROBE_EXT_ZVE64X (1ULL << 39)
+#define RISCV_HWPROBE_EXT_ZVE64F (1ULL << 40)
+#define RISCV_HWPROBE_EXT_ZVE64D (1ULL << 41)
+#define RISCV_HWPROBE_EXT_ZIMOP (1ULL << 42)
+#define RISCV_HWPROBE_EXT_ZCA (1ULL << 43)
+#define RISCV_HWPROBE_EXT_ZCB (1ULL << 44)
+#define RISCV_HWPROBE_EXT_ZCD (1ULL << 45)
+#define RISCV_HWPROBE_EXT_ZCF (1ULL << 46)
+#define RISCV_HWPROBE_EXT_ZCMOP (1ULL << 47)
+#define RISCV_HWPROBE_EXT_ZAWRS (1ULL << 48)
+#define RISCV_HWPROBE_KEY_CPUPERF_0 5
+#define RISCV_HWPROBE_MISALIGNED_UNKNOWN (0 << 0)
+#define RISCV_HWPROBE_MISALIGNED_EMULATED (1ULL << 0)
+#define RISCV_HWPROBE_MISALIGNED_SLOW (2 << 0)
+#define RISCV_HWPROBE_MISALIGNED_FAST (3 << 0)
+#define RISCV_HWPROBE_MISALIGNED_UNSUPPORTED (4 << 0)
+#define RISCV_HWPROBE_MISALIGNED_MASK (7 << 0)
+#define RISCV_HWPROBE_KEY_ZICBOZ_BLOCK_SIZE 6
+/* Increase RISCV_HWPROBE_MAX_KEY when adding items. */
+
+struct riscv_hwprobe {
+  long long key;
+  unsigned long long value;
+};
+
+#define __NR_riscv_hwprobe 258
+static long initHwProbe(struct riscv_hwprobe *Hwprobes, int len) {
+  return syscall_impl_5_args(__NR_riscv_hwprobe, (long)Hwprobes, len, 0, 0, 0);
+}
+
+#define SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(EXTNAME)                    \
+  SET_SINGLE_IMAEXT_RISCV_FEATURE(RISCV_HWPROBE_EXT_##EXTNAME, EXTNAME)
+
+#define SET_SINGLE_IMAEXT_RISCV_FEATURE(HWPROBE_BITMASK, EXT)                  \
+  SET_SINGLE_RISCV_FEATURE(IMAEXT0Value &HWPROBE_BITMASK, EXT)
+
+#define SET_SINGLE_RISCV_FEATURE(COND, EXT)                                    \
+  if (COND) {                                                                  \
+    SET_RISCV_FEATURE(EXT);                                                    \
+  }
+
+#define SET_RISCV_FEATURE(EXT) features[EXT##_GROUPID] |= EXT##_BITMASK
+
+static void initRISCVFeature(struct riscv_hwprobe Hwprobes[]) {
+
+  // Note: If a hwprobe key is unknown to the kernel, its key field
+  // will be cleared to -1, and its value set to 0.
+  // This unsets all extension bitmask bits.
+
+  // Init VendorID, ArchID, ImplID
+  __riscv_cpu_model.mvendorid = Hwprobes[2].value;
+  __riscv_cpu_model.marchid = Hwprobes[3].value;
+  __riscv_cpu_model.mimpid = Hwprobes[4].value;
+
+  // Init standard extension
+  // TODO: Maybe Extension implied generate from tablegen?
+
+  unsigned long long features[RISCV_FEATURE_BITS_LENGTH];
+  int i;
+
+  for (i = 0; i < RISCV_FEATURE_BITS_LENGTH; i++)
+    features[i] = 0;
+
+  // Check RISCV_HWPROBE_KEY_BASE_BEHAVIOR
+  unsigned long long BaseValue = Hwprobes[0].value;
+  if (BaseValue & RISCV_HWPROBE_BASE_BEHAVIOR_IMA) {
+    SET_RISCV_FEATURE(I);
+    SET_RISCV_FEATURE(M);
+    SET_RISCV_FEATURE(A);
+  }
+
+  // Check RISCV_HWPROBE_KEY_IMA_EXT_0
+  unsigned long long IMAEXT0Value = Hwprobes[1].value;
+  if (IMAEXT0Value & RISCV_HWPROBE_IMA_FD) {
+    SET_RISCV_FEATURE(F);
+    SET_RISCV_FEATURE(D);
+  }
+
+  SET_SINGLE_IMAEXT_RISCV_FEATURE(RISCV_HWPROBE_IMA_C, C);
+  SET_SINGLE_IMAEXT_RISCV_FEATURE(RISCV_HWPROBE_IMA_V, V);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBA);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBB);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBS);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZICBOZ);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBC);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBKB);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBKC);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZBKX);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKND);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKNE);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKNH);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKSED);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKSH);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZKT);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVBB);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVBC);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKB);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKG);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKNED);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKNHA);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKNHB);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKSED);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKSH);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVKT);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZFH);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZFHMIN);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZIHINTNTL);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZIHINTPAUSE);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVFH);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVFHMIN);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZFA);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZTSO);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZACAS);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZICOND);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVE32X);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVE32F);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVE64X);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVE64F);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZVE64D);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZIMOP);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZCA);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZCB);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZCD);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZCF);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZCMOP);
+  SET_RISCV_HWPROBE_EXT_SINGLE_RISCV_FEATURE(ZAWRS);
+
+  for (i = 0; i < RISCV_FEATURE_BITS_LENGTH; i++)
+    __riscv_feature_bits.features[i] = features[i];
+}
+
+#endif // defined(__linux__)
+
+static int FeaturesBitCached = 0;
+
+void __init_riscv_feature_bits(void *);
+static void __init_riscv_feature_bits_ctor(void) CONSTRUCTOR_ATTRIBUTE;
+
+// A constructor function that sets __riscv_feature_bits
+// to the right values.  This needs to run only once.  This constructor is given
+// the highest priority and it should run before constructors without the
+// priority set.  However, it still runs after ifunc initializers and needs to
+// be called explicitly there.
+
+static void CONSTRUCTOR_ATTRIBUTE __init_riscv_feature_bits_ctor(void) {
+  __init_riscv_feature_bits(0);
+}
+
+// PlatformArgs allows the platform to provide pre-computed data and access it
+// without extra effort. For example, Linux could pass the vDSO object to avoid
+// an extra system call.
+void __init_riscv_feature_bits(void *PlatformArgs) {
+
+  if (FeaturesBitCached)
+    return;
+
+  __riscv_feature_bits.length = RISCV_FEATURE_BITS_LENGTH;
+
+#if defined(__linux__)
+  struct riscv_hwprobe Hwprobes[] = {
+      {RISCV_HWPROBE_KEY_BASE_BEHAVIOR, 0}, {RISCV_HWPROBE_KEY_IMA_EXT_0, 0},
+      {RISCV_HWPROBE_KEY_MVENDORID, 0},     {RISCV_HWPROBE_KEY_MARCHID, 0},
+      {RISCV_HWPROBE_KEY_MIMPID, 0},
+  };
+  if (initHwProbe(Hwprobes, sizeof(Hwprobes) / sizeof(Hwprobes[0])))
+    return;
+
+  initRISCVFeature(Hwprobes);
+#endif // defined(__linux__)
+
+  FeaturesBitCached = 1;
+}
diff --git a/contrib/libs/cxxsupp/builtins/cpu_model/x86.c b/contrib/libs/cxxsupp/builtins/cpu_model/x86.c
index b1c4abd9d11d..606571d52750 100644
--- a/contrib/libs/cxxsupp/builtins/cpu_model/x86.c
+++ b/contrib/libs/cxxsupp/builtins/cpu_model/x86.c
@@ -23,6 +23,10 @@
 
 #include <assert.h>
 
+#if (defined(__GNUC__) || defined(__clang__)) && !defined(_MSC_VER)
+#include <cpuid.h>
+#endif
+
 #ifdef _MSC_VER
 #include <intrin.h>
 #endif
@@ -99,6 +103,7 @@ enum ProcessorSubtypes {
   INTEL_COREI7_ARROWLAKE_S,
   INTEL_COREI7_PANTHERLAKE,
   AMDFAM1AH_ZNVER5,
+  INTEL_COREI7_DIAMONDRAPIDS,
   CPU_SUBTYPE_MAX
 };
 
@@ -223,41 +228,12 @@ enum ProcessorFeatures {
   FEATURE_USERMSR,
   FEATURE_AVX10_1_256,
   FEATURE_AVX10_1_512,
+  FEATURE_AVX10_2_256,
+  FEATURE_AVX10_2_512,
+  FEATURE_MOVRS,
   CPU_FEATURE_MAX
 };
 
-// The check below for i386 was copied from clang's cpuid.h (__get_cpuid_max).
-// Check motivated by bug reports for OpenSSL crashing on CPUs without CPUID
-// support. Consequently, for i386, the presence of CPUID is checked first
-// via the corresponding eflags bit.
-static bool isCpuIdSupported(void) {
-#if defined(__GNUC__) || defined(__clang__)
-#if defined(__i386__)
-  int __cpuid_supported;
-  __asm__("  pushfl
"
-          "  popl   %%eax
"
-          "  movl   %%eax,%%ecx
"
-          "  xorl   $0x00200000,%%eax
"
-          "  pushl  %%eax
"
-          "  popfl
"
-          "  pushfl
"
-          "  popl   %%eax
"
-          "  movl   $0,%0
"
-          "  cmpl   %%eax,%%ecx
"
-          "  je     1f
"
-          "  movl   $1,%0
"
-          "1:"
-          : "=r"(__cpuid_supported)
-          :
-          : "eax", "ecx");
-  if (!__cpuid_supported)
-    return false;
-#endif
-  return true;
-#endif
-  return true;
-}
-
 // This code is copied from lib/Support/Host.cpp.
 // Changes to either file should be mirrored in the other.
 
@@ -265,26 +241,8 @@ static bool isCpuIdSupported(void) {
 /// the specified arguments.  If we can't run cpuid on the host, return true.
 static bool getX86CpuIDAndInfo(unsigned value, unsigned *rEAX, unsigned *rEBX,
                                unsigned *rECX, unsigned *rEDX) {
-#if defined(__GNUC__) || defined(__clang__)
-#if defined(__x86_64__)
-  // gcc doesn't know cpuid would clobber ebx/rbx. Preserve it manually.
-  // FIXME: should we save this for Clang?
-  __asm__("movq\t%%rbx, %%rsi
\t"
-          "cpuid
\t"
-          "xchgq\t%%rbx, %%rsi
\t"
-          : "=a"(*rEAX), "=S"(*rEBX), "=c"(*rECX), "=d"(*rEDX)
-          : "a"(value));
-  return false;
-#elif defined(__i386__)
-  __asm__("movl\t%%ebx, %%esi
\t"
-          "cpuid
\t"
-          "xchgl\t%%ebx, %%esi
\t"
-          : "=a"(*rEAX), "=S"(*rEBX), "=c"(*rECX), "=d"(*rEDX)
-          : "a"(value));
-  return false;
-#else
-  return true;
-#endif
+#if (defined(__GNUC__) || defined(__clang__)) && !defined(_MSC_VER)
+  return !__get_cpuid(value, rEAX, rEBX, rECX, rEDX);
 #elif defined(_MSC_VER)
   // The MSVC intrinsic is portable across x86 and x64.
   int registers[4];
@@ -305,26 +263,12 @@ static bool getX86CpuIDAndInfo(unsigned value, unsigned *rEAX, unsigned *rEBX,
 static bool getX86CpuIDAndInfoEx(unsigned value, unsigned subleaf,
                                  unsigned *rEAX, unsigned *rEBX, unsigned *rECX,
                                  unsigned *rEDX) {
-#if defined(__GNUC__) || defined(__clang__)
-#if defined(__x86_64__)
-  // gcc doesn't know cpuid would clobber ebx/rbx. Preserve it manually.
-  // FIXME: should we save this for Clang?
-  __asm__("movq\t%%rbx, %%rsi
\t"
-          "cpuid
\t"
-          "xchgq\t%%rbx, %%rsi
\t"
-          : "=a"(*rEAX), "=S"(*rEBX), "=c"(*rECX), "=d"(*rEDX)
-          : "a"(value), "c"(subleaf));
-  return false;
-#elif defined(__i386__)
-  __asm__("movl\t%%ebx, %%esi
\t"
-          "cpuid
\t"
-          "xchgl\t%%ebx, %%esi
\t"
-          : "=a"(*rEAX), "=S"(*rEBX), "=c"(*rECX), "=d"(*rEDX)
-          : "a"(value), "c"(subleaf));
-  return false;
-#else
-  return true;
-#endif
+  // TODO(boomanaiden154): When the minimum toolchain versions for gcc and clang
+  // are such that __cpuidex is defined within cpuid.h for both, we can remove
+  // the __get_cpuid_count function and share the MSVC implementation between
+  // all three.
+#if (defined(__GNUC__) || defined(__clang__)) && !defined(_MSC_VER)
+  return !__get_cpuid_count(value, subleaf, rEAX, rEBX, rECX, rEDX);
 #elif defined(_MSC_VER)
   int registers[4];
   __cpuidex(registers, value, subleaf);
@@ -340,6 +284,9 @@ static bool getX86CpuIDAndInfoEx(unsigned value, unsigned subleaf,
 
 // Read control register 0 (XCR0). Used to detect features such as AVX.
 static bool getX86XCR0(unsigned *rEAX, unsigned *rEDX) {
+  // TODO(boomanaiden154): When the minimum toolchain versions for gcc and clang
+  // are such that _xgetbv is supported by both, we can unify the implementation
+  // with MSVC and remove all inline assembly.
 #if defined(__GNUC__) || defined(__clang__)
   // Check xgetbv; this uses a .byte sequence instead of the instruction
   // directly because older assemblers do not include support for xgetbv and
@@ -514,22 +461,39 @@ static const char *getIntelProcessorTypeAndSubtype(unsigned Family,
     // Alderlake:
     case 0x97:
     case 0x9a:
+      CPU = "alderlake";
+      *Type = INTEL_COREI7;
+      *Subtype = INTEL_COREI7_ALDERLAKE;
+      break;
+
     // Raptorlake:
     case 0xb7:
     case 0xba:
     case 0xbf:
+      CPU = "raptorlake";
+      *Type = INTEL_COREI7;
+      *Subtype = INTEL_COREI7_ALDERLAKE;
+      break;
+
     // Meteorlake:
     case 0xaa:
     case 0xac:
+      CPU = "meteorlake";
+      *Type = INTEL_COREI7;
+      *Subtype = INTEL_COREI7_ALDERLAKE;
+      break;
+
     // Gracemont:
     case 0xbe:
-      CPU = "alderlake";
+      CPU = "gracemont";
       *Type = INTEL_COREI7;
       *Subtype = INTEL_COREI7_ALDERLAKE;
       break;
 
     // Arrowlake:
     case 0xc5:
+    // Arrowlake U:
+    case 0xb5:
       CPU = "arrowlake";
       *Type = INTEL_COREI7;
       *Subtype = INTEL_COREI7_ARROWLAKE;
@@ -537,9 +501,14 @@ static const char *getIntelProcessorTypeAndSubtype(unsigned Family,
 
     // Arrowlake S:
     case 0xc6:
+      CPU = "arrowlake-s";
+      *Type = INTEL_COREI7;
+      *Subtype = INTEL_COREI7_ARROWLAKE_S;
+      break;
+
     // Lunarlake:
     case 0xbd:
-      CPU = "arrowlake-s";
+      CPU = "lunarlake";
       *Type = INTEL_COREI7;
       *Subtype = INTEL_COREI7_ARROWLAKE_S;
       break;
@@ -561,6 +530,11 @@ static const char *getIntelProcessorTypeAndSubtype(unsigned Family,
 
     // Emerald Rapids:
     case 0xcf:
+      CPU = "emeraldrapids";
+      *Type = INTEL_COREI7;
+      *Subtype = INTEL_COREI7_SAPPHIRERAPIDS;
+      break;
+
     // Sapphire Rapids:
     case 0x8f:
       CPU = "sapphirerapids";
@@ -652,6 +626,19 @@ static const char *getIntelProcessorTypeAndSubtype(unsigned Family,
       break;
     }
     break;
+  case 19:
+    switch (Model) {
+    // Diamond Rapids:
+    case 0x01:
+      CPU = "diamondrapids";
+      *Type = INTEL_COREI7;
+      *Subtype = INTEL_COREI7_DIAMONDRAPIDS;
+      break;
+
+    default: // Unknown family 19 CPU.
+      break;
+    }
+    break;
   default:
     break; // Unknown.
   }
@@ -704,6 +691,7 @@ static const char *getAMDProcessorTypeAndSubtype(unsigned Family,
     CPU = "k8";
     break;
   case 16:
+  case 18:
     CPU = "amdfam10";
     *Type = AMDFAM10H; // "amdfam10"
     switch (Model) {
@@ -1024,6 +1012,8 @@ static void getAvailableFeatures(unsigned ECX, unsigned EDX, unsigned MaxLeaf,
     setFeature(FEATURE_HRESET);
   if (HasLeaf7Subleaf1 && ((EAX >> 23) & 1) && HasAVXSave)
     setFeature(FEATURE_AVXIFMA);
+  if (HasLeaf7Subleaf1 && ((EAX >> 31) & 1))
+    setFeature(FEATURE_MOVRS);
 
   if (HasLeaf7Subleaf1 && ((EDX >> 4) & 1) && HasAVXSave)
     setFeature(FEATURE_AVXVNNIINT8);
@@ -1037,12 +1027,10 @@ static void getAvailableFeatures(unsigned ECX, unsigned EDX, unsigned MaxLeaf,
     setFeature(FEATURE_PREFETCHI);
   if (HasLeaf7Subleaf1 && ((EDX >> 15) & 1))
     setFeature(FEATURE_USERMSR);
-  if (HasLeaf7Subleaf1 && ((EDX >> 19) & 1))
-    setFeature(FEATURE_AVX10_1_256);
   if (HasLeaf7Subleaf1 && ((EDX >> 21) & 1))
     setFeature(FEATURE_APXF);
 
-  unsigned MaxLevel;
+  unsigned MaxLevel = 0;
   getX86CpuIDAndInfo(0, &MaxLevel, &EBX, &ECX, &EDX);
   bool HasLeafD = MaxLevel >= 0xd &&
                   !getX86CpuIDAndInfoEx(0xd, 0x1, &EAX, &EBX, &ECX, &EDX);
@@ -1055,10 +1043,22 @@ static void getAvailableFeatures(unsigned ECX, unsigned EDX, unsigned MaxLeaf,
 
   bool HasLeaf24 =
       MaxLevel >= 0x24 && !getX86CpuIDAndInfo(0x24, &EAX, &EBX, &ECX, &EDX);
-  if (HasLeaf7Subleaf1 && ((EDX >> 19) & 1) && HasLeaf24 && ((EBX >> 18) & 1))
-    setFeature(FEATURE_AVX10_1_512);
+  if (HasLeaf7Subleaf1 && ((EDX >> 19) & 1) && HasLeaf24) {
+    bool Has512Len = (EBX >> 18) & 1;
+    int AVX10Ver = EBX & 0xff;
+    if (AVX10Ver >= 2) {
+      setFeature(FEATURE_AVX10_2_256);
+      if (Has512Len)
+        setFeature(FEATURE_AVX10_2_512);
+    }
+    if (AVX10Ver >= 1) {
+      setFeature(FEATURE_AVX10_1_256);
+      if (Has512Len)
+        setFeature(FEATURE_AVX10_1_512);
+    }
+  }
 
-  unsigned MaxExtLevel;
+  unsigned MaxExtLevel = 0;
   getX86CpuIDAndInfo(0x80000000, &MaxExtLevel, &EBX, &ECX, &EDX);
 
   bool HasExtLeaf1 = MaxExtLevel >= 0x80000001 &&
@@ -1152,7 +1152,7 @@ unsigned __cpu_features2[(CPU_FEATURE_MAX - 1) / 32];
 // needs to be called explicitly there.
 
 int CONSTRUCTOR_ATTRIBUTE __cpu_indicator_init(void) {
-  unsigned EAX, EBX, ECX, EDX;
+  unsigned EAX = 0, EBX = 0, ECX = 0, EDX = 0;
   unsigned MaxLeaf = 5;
   unsigned Vendor;
   unsigned Model, Family;
@@ -1164,8 +1164,7 @@ int CONSTRUCTOR_ATTRIBUTE __cpu_indicator_init(void) {
   if (__cpu_model.__cpu_vendor)
     return 0;
 
-  if (!isCpuIdSupported() ||
-      getX86CpuIDAndInfo(0, &MaxLeaf, &Vendor, &ECX, &EDX) || MaxLeaf < 1) {
+  if (getX86CpuIDAndInfo(0, &MaxLeaf, &Vendor, &ECX, &EDX) || MaxLeaf < 1) {
     __cpu_model.__cpu_vendor = VENDOR_OTHER;
     return -1;
   }
diff --git a/contrib/libs/cxxsupp/builtins/crtbegin.c b/contrib/libs/cxxsupp/builtins/crtbegin.c
index a0860ca12ea0..67d8d3fbbd78 100644
--- a/contrib/libs/cxxsupp/builtins/crtbegin.c
+++ b/contrib/libs/cxxsupp/builtins/crtbegin.c
@@ -8,6 +8,14 @@
 
 #include <stddef.h>
 
+#ifndef __has_feature
+# define __has_feature(x) 0
+#endif
+
+#if __has_feature(ptrauth_init_fini)
+
+#endif
+
 __attribute__((visibility("hidden"))) void *__dso_handle = &__dso_handle;
 
 #ifdef EH_USE_FRAME_REGISTRY
@@ -46,8 +54,22 @@ static void __attribute__((used)) __do_init(void) {
 }
 
 #ifdef CRT_HAS_INITFINI_ARRAY
+#if __has_feature(ptrauth_init_fini)
+// TODO: use __ptrauth-qualified pointers when they are supported on clang side
+#if __has_feature(ptrauth_init_fini_address_discrimination)
+__attribute__((section(".init_array"), used)) static void *__init =
+    ptrauth_sign_constant(&__do_init, ptrauth_key_init_fini_pointer,
+                          ptrauth_blend_discriminator(
+                              &__init, __ptrauth_init_fini_discriminator));
+#else
+__attribute__((section(".init_array"), used)) static void *__init =
+    ptrauth_sign_constant(&__do_init, ptrauth_key_init_fini_pointer,
+                          __ptrauth_init_fini_discriminator);
+#endif
+#else
 __attribute__((section(".init_array"),
                used)) static void (*__init)(void) = __do_init;
+#endif
 #elif defined(__i386__) || defined(__x86_64__)
 __asm__(".pushsection .init,\"ax\",@progbits
\t"
         "call __do_init
\t"
@@ -103,8 +125,22 @@ static void __attribute__((used)) __do_fini(void) {
 }
 
 #ifdef CRT_HAS_INITFINI_ARRAY
+#if __has_feature(ptrauth_init_fini)
+// TODO: use __ptrauth-qualified pointers when they are supported on clang side
+#if __has_feature(ptrauth_init_fini_address_discrimination)
+__attribute__((section(".fini_array"), used)) static void *__fini =
+    ptrauth_sign_constant(&__do_fini, ptrauth_key_init_fini_pointer,
+                          ptrauth_blend_discriminator(
+                              &__fini, __ptrauth_init_fini_discriminator));
+#else
+__attribute__((section(".fini_array"), used)) static void *__fini =
+    ptrauth_sign_constant(&__do_fini, ptrauth_key_init_fini_pointer,
+                          __ptrauth_init_fini_discriminator);
+#endif
+#else
 __attribute__((section(".fini_array"),
                used)) static void (*__fini)(void) = __do_fini;
+#endif
 #elif defined(__i386__) || defined(__x86_64__)
 __asm__(".pushsection .fini,\"ax\",@progbits
\t"
         "call __do_fini
\t"
diff --git a/contrib/libs/cxxsupp/builtins/divsc3.c b/contrib/libs/cxxsupp/builtins/divsc3.c
index aa4fd8e79e0c..6529651252c5 100644
--- a/contrib/libs/cxxsupp/builtins/divsc3.c
+++ b/contrib/libs/cxxsupp/builtins/divsc3.c
@@ -20,7 +20,7 @@
 COMPILER_RT_ABI Fcomplex __divsc3(float __a, float __b, float __c, float __d) {
   int __ilogbw = 0;
   float __logbw =
-      __compiler_rt_logbf(__compiler_rt_fmaxf(crt_fabsf(__c), crt_fabsf(__d)));
+      __compiler_rt_logbf(__compiler_rt_fmaxX(crt_fabsf(__c), crt_fabsf(__d)));
   if (crt_isfinite(__logbw)) {
     __ilogbw = (int)__logbw;
     __c = __compiler_rt_scalbnf(__c, -__ilogbw);
diff --git a/contrib/libs/cxxsupp/builtins/extendhfxf2.c b/contrib/libs/cxxsupp/builtins/extendhfxf2.c
new file mode 100644
index 000000000000..a2cd106e1c1b
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/extendhfxf2.c
@@ -0,0 +1,16 @@
+//===-- lib/extendhfxf2.c - half -> long double conversion --------*- C -*-===//
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+#include "int_lib.h"
+#define SRC_HALF
+#define DST_DOUBLE
+#include "fp_extend_impl.inc"
+
+// Long double are expected to be as precise as double.
+COMPILER_RT_ABI xf_float __extendhfxf2(src_t a) {
+  return (xf_float)__extendXfYf2__(a);
+}
diff --git a/contrib/libs/cxxsupp/builtins/fp_div_impl.inc b/contrib/libs/cxxsupp/builtins/fp_div_impl.inc
index 29bcd1920edf..de61e55cd083 100644
--- a/contrib/libs/cxxsupp/builtins/fp_div_impl.inc
+++ b/contrib/libs/cxxsupp/builtins/fp_div_impl.inc
@@ -334,7 +334,6 @@ static __inline fp_t __divXf3__(fp_t a, fp_t b) {
   // Suppose 1/b - P * 2^-W < x < 1/b + P * 2^-W
   x_UQ0 -= RECIPROCAL_PRECISION;
   // Now 1/b - (2*P) * 2^-W < x < 1/b
-  // FIXME Is x_UQ0 still >= 0.5?
 
   rep_t quotient_UQ1, dummy;
   wideMultiply(x_UQ0, aSignificand << 1, &quotient_UQ1, &dummy);
@@ -344,6 +343,12 @@ static __inline fp_t __divXf3__(fp_t a, fp_t b) {
   // adjust it to be in [1.0, 2.0) as UQ1.SB.
   rep_t residualLo;
   if (quotient_UQ1 < (implicitBit << 1)) {
+    if (quotient_UQ1 < implicitBit) {
+      // In a rare case where quotient is < 0.5, we can adjust the quotient and
+      // the written exponent, and then treat them the same way as in [0.5, 1.0)
+      quotient_UQ1 <<= 1;
+      writtenExponent -= 1;
+    }
     // Highest bit is 0, so just reinterpret quotient_UQ1 as UQ1.SB,
     // effectively doubling its value as well as its error estimation.
     residualLo = (aSignificand << (significandBits + 1)) - quotient_UQ1 * bSignificand;
diff --git a/contrib/libs/cxxsupp/builtins/fp_lib.h b/contrib/libs/cxxsupp/builtins/fp_lib.h
index b2a89506135b..fae58497a8f8 100644
--- a/contrib/libs/cxxsupp/builtins/fp_lib.h
+++ b/contrib/libs/cxxsupp/builtins/fp_lib.h
@@ -171,8 +171,11 @@ static __inline void wideMultiply(rep_t a, rep_t b, rep_t *hi, rep_t *lo) {
                          (sum2 & Word_FullMask) + ((sum3 << 32) & Word_HiMask);
 
   *lo = r0 + (r1 << 64);
+  // The addition above can overflow, in which case `*lo` will be less than
+  // `r0`. Carry any overflow into `hi`.
+  const bool carry = *lo < r0;
   *hi = (r1 >> 64) + (sum1 >> 96) + (sum2 >> 64) + (sum3 >> 32) + sum4 +
-        (sum5 << 32) + (sum6 << 64);
+        (sum5 << 32) + (sum6 << 64) + carry;
 }
 #undef Word_1
 #undef Word_2
@@ -346,15 +349,6 @@ static __inline fp_t __compiler_rt_logbf(fp_t x) {
 static __inline fp_t __compiler_rt_scalbnf(fp_t x, int y) {
   return __compiler_rt_scalbnX(x, y);
 }
-static __inline fp_t __compiler_rt_fmaxf(fp_t x, fp_t y) {
-#if defined(__aarch64__)
-  // Use __builtin_fmaxf which turns into an fmaxnm instruction on AArch64.
-  return __builtin_fmaxf(x, y);
-#else
-  // __builtin_fmaxf frequently turns into a libm call, so inline the function.
-  return __compiler_rt_fmaxX(x, y);
-#endif
-}
 
 #elif defined(DOUBLE_PRECISION)
 
diff --git a/contrib/libs/cxxsupp/builtins/fp_trunc.h b/contrib/libs/cxxsupp/builtins/fp_trunc.h
index 141fe63e132d..a1bd881eb57c 100644
--- a/contrib/libs/cxxsupp/builtins/fp_trunc.h
+++ b/contrib/libs/cxxsupp/builtins/fp_trunc.h
@@ -35,6 +35,18 @@ static const int srcSigFracBits = 52;
 // srcBits - srcSigFracBits - 1
 static const int srcExpBits = 11;
 
+#elif defined SRC_80
+typedef xf_float src_t;
+typedef __uint128_t src_rep_t;
+#define SRC_REP_C (__uint128_t)
+// sign bit, exponent and significand occupy the lower 80 bits.
+static const int srcBits = 80;
+static const int srcSigFracBits = 63;
+// -1 accounts for the sign bit.
+// -1 accounts for the explicitly stored integer bit.
+// srcBits - srcSigFracBits - 1 - 1
+static const int srcExpBits = 15;
+
 #elif defined SRC_QUAD
 typedef tf_float src_t;
 typedef __uint128_t src_rep_t;
diff --git a/contrib/libs/cxxsupp/builtins/os_version_check.c b/contrib/libs/cxxsupp/builtins/os_version_check.c
index 01fae834ab21..b10f23a81a9c 100644
--- a/contrib/libs/cxxsupp/builtins/os_version_check.c
+++ b/contrib/libs/cxxsupp/builtins/os_version_check.c
@@ -14,6 +14,7 @@
 #ifdef __APPLE__
 
 #include <TargetConditionals.h>
+#include <assert.h>
 #include <dispatch/dispatch.h>
 #include <dlfcn.h>
 #include <stdint.h>
@@ -270,6 +271,8 @@ static inline uint32_t ConstructVersion(uint32_t Major, uint32_t Minor,
   return ((Major & 0xffff) << 16) | ((Minor & 0xff) << 8) | (Subminor & 0xff);
 }
 
+#define PLATFORM_MACOS 1
+
 int32_t __isPlatformVersionAtLeast(uint32_t Platform, uint32_t Major,
                                    uint32_t Minor, uint32_t Subminor) {
   dispatch_once_f(&DispatchOnceCounter, NULL, initializeAvailabilityCheck);
@@ -282,6 +285,29 @@ int32_t __isPlatformVersionAtLeast(uint32_t Platform, uint32_t Major,
   return AvailabilityVersionCheck(1, Versions);
 }
 
+#if TARGET_OS_OSX
+
+int32_t __isPlatformOrVariantPlatformVersionAtLeast(
+    uint32_t Platform, uint32_t Major, uint32_t Minor, uint32_t Subminor,
+    uint32_t Platform2, uint32_t Major2, uint32_t Minor2, uint32_t Subminor2) {
+  dispatch_once_f(&DispatchOnceCounter, NULL, initializeAvailabilityCheck);
+
+  if (!AvailabilityVersionCheck) {
+    // Handle case of back-deployment for older macOS.
+    if (Platform == PLATFORM_MACOS) {
+      return __isOSVersionAtLeast(Major, Minor, Subminor);
+    }
+    assert(Platform2 == PLATFORM_MACOS && "unexpected platform");
+    return __isOSVersionAtLeast(Major2, Minor2, Subminor2);
+  }
+  dyld_build_version_t Versions[] = {
+      {Platform, ConstructVersion(Major, Minor, Subminor)},
+      {Platform2, ConstructVersion(Major2, Minor2, Subminor2)}};
+  return AvailabilityVersionCheck(2, Versions);
+}
+
+#endif
+
 #elif __ANDROID__
 
 #include <pthread.h>
diff --git a/contrib/libs/cxxsupp/builtins/trunctfbf2.c b/contrib/libs/cxxsupp/builtins/trunctfbf2.c
new file mode 100644
index 000000000000..cd3c761aa62f
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/trunctfbf2.c
@@ -0,0 +1,18 @@
+//===--------- lib/trunctfbf2.c - quad -> bfloat conversion -------*- C -*-===//
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+#define QUAD_PRECISION
+#include "fp_lib.h"
+
+#if defined(CRT_HAS_TF_MODE) && defined(__x86_64__)
+#define SRC_QUAD
+#define DST_BFLOAT
+#include "fp_trunc_impl.inc"
+
+COMPILER_RT_ABI dst_t __trunctfbf2(src_t a) { return __truncXfYf2__(a); }
+
+#endif
diff --git a/contrib/libs/cxxsupp/builtins/truncxfbf2.c b/contrib/libs/cxxsupp/builtins/truncxfbf2.c
new file mode 100644
index 000000000000..5a389abdf0d5
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/truncxfbf2.c
@@ -0,0 +1,19 @@
+//===-- lib/truncxfbf2.c - long double -> bfloat conversion -------*- C -*-===//
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#if defined(CRT_HAS_TF_MODE) && __LDBL_MANT_DIG__ == 64 && defined(__x86_64__)
+#define SRC_80
+#define DST_BFLOAT
+#include "fp_trunc_impl.inc"
+
+COMPILER_RT_ABI dst_t __truncxfbf2(long double a) { return __truncXfYf2__(a); }
+
+#endif
+
+// Have at least one declaration to suppress warnings.
+enum Unused { ReallyUnused };
diff --git a/contrib/libs/cxxsupp/builtins/truncxfhf2.c b/contrib/libs/cxxsupp/builtins/truncxfhf2.c
new file mode 100644
index 000000000000..0f0639865dbf
--- /dev/null
+++ b/contrib/libs/cxxsupp/builtins/truncxfhf2.c
@@ -0,0 +1,15 @@
+//===-- lib/truncsfhf2.c - long double -> half conversion ---------*- C -*-===//
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#define SRC_SINGLE
+#define DST_HALF
+#include "fp_trunc_impl.inc"
+
+COMPILER_RT_ABI dst_t __truncxfhf2(xf_float a) {
+  return __truncXfYf2__((float)a);
+}
diff --git a/contrib/libs/cxxsupp/builtins/ya.make b/contrib/libs/cxxsupp/builtins/ya.make
index f6bee5e713a2..dce2f27201ad 100644
--- a/contrib/libs/cxxsupp/builtins/ya.make
+++ b/contrib/libs/cxxsupp/builtins/ya.make
@@ -12,9 +12,9 @@ LICENSE(
 
 LICENSE_TEXTS(.yandex_meta/licenses.list.txt)
 
-VERSION(19.1.7)
+VERSION(20.1.0)
 
-ORIGINAL_SOURCE(https://github.com/llvm/llvm-project/releases/download/llvmorg-19.1.7/compiler-rt-19.1.7.src.tar.xz)
+ORIGINAL_SOURCE(https://github.com/llvm/llvm-project/releases/download/llvmorg-20.1.0/compiler-rt-20.1.0.src.tar.xz)
 
 NO_COMPILER_WARNINGS()
 
@@ -79,9 +79,9 @@ IF (ARCH_ARM64 OR ARCH_X86_64)
             # NB: sources that were commented out were added in llvm-20
             extendbfsf2.c
             truncdfbf2.c
-            # truncxfbf2.c
+            truncxfbf2.c
             truncsfbf2.c
-            # trunctfbf2.c
+            trunctfbf2.c
         )
     ENDIF()
 ENDIF()
@@ -323,8 +323,7 @@ ELSEIF (ARCH_AARCH64)
     SRCS(
         aarch64/chkstk.S
         aarch64/fp_mode.c
-        aarch64/sme-abi-init.c
-        aarch64/sme-abi-vg.c
+        aarch64/sme-abi-assert.c
         aarch64/sme-abi.S
         aarch64/sme-libc-mem-routines.S
         absvdi2.c
@@ -645,6 +644,7 @@ ELSEIF (ARCH_X86_64)
         SRCS(
             x86_64/floatdixf.c
             divxc3.c
+            extendhfxf2.c
             extendxftf2.c
             fixunsxfdi.c
             fixunsxfsi.c
@@ -656,6 +656,7 @@ ELSEIF (ARCH_X86_64)
             mulxc3.c
             powixf2.c
             trunctfxf2.c
+            truncxfhf2.c
         )
     ENDIF()
 ELSE()
diff --git a/ydb/ci/rightlib.txt b/ydb/ci/rightlib.txt
index 23981d2eb738..de62b3ba5ab7 100644
--- a/ydb/ci/rightlib.txt
+++ b/ydb/ci/rightlib.txt
@@ -1,1 +1,1 @@
-2ff6c17bf66cd3580cf4f4746870518f071864d6
+0ce7de46ae24b3b80ffd51c6f100d22ef8aba7d6
diff --git a/yt/yt/client/kafka/protocol.cpp b/yt/yt/client/kafka/protocol.cpp
index 47ab8b170f08..edac56e7a98f 100644
--- a/yt/yt/client/kafka/protocol.cpp
+++ b/yt/yt/client/kafka/protocol.cpp
@@ -2,6 +2,8 @@
 
 #include <yt/yt/core/misc/error.h>
 
+#include <library/cpp/digest/crc32c/crc32c.h>
+
 #include <library/cpp/yt/coding/varint.h>
 
 #include <library/cpp/yt/string/guid.h>
@@ -10,6 +12,10 @@ namespace NYT::NKafka {
 
 ////////////////////////////////////////////////////////////////////////////////
 
+static constexpr auto& Logger = KafkaLogger;
+
+////////////////////////////////////////////////////////////////////////////////
+
 class TKafkaProtocolReader
     : public IKafkaProtocolReader
 {
@@ -20,37 +26,44 @@ class TKafkaProtocolReader
 
     bool ReadBool() override
     {
+        YT_LOG_TRACE("Reading bool");
         auto value = ReadByte();
         return value > 0;
     }
 
     char ReadByte() override
     {
+        YT_LOG_TRACE("Reading byte");
         return DoReadInt<char>();
     }
 
     i16 ReadInt16() override
     {
+        YT_LOG_TRACE("Reading int16");
         return DoReadInt<i16>();
     }
 
     i32 ReadInt32() override
     {
+        YT_LOG_TRACE("Reading int32");
         return DoReadInt<i32>();
     }
 
     i64 ReadInt64() override
     {
+        YT_LOG_TRACE("Reading int64");
         return DoReadInt<i64>();
     }
 
     ui32 ReadUint32() override
     {
+        YT_LOG_TRACE("Reading uint32");
         return DoReadInt<ui32>();
     }
 
     i32 ReadVarInt() override
     {
+        YT_LOG_TRACE("Reading varint");
         i32 result;
         Offset_ += ReadVarInt32(Data_.begin() + Offset_, &result);
         return result;
@@ -58,6 +71,7 @@ class TKafkaProtocolReader
 
     i64 ReadVarLong() override
     {
+        YT_LOG_TRACE("Reading varlong");
         i64 result;
         Offset_ += ReadVarInt64(Data_.begin() + Offset_, &result);
         return result;
@@ -65,6 +79,7 @@ class TKafkaProtocolReader
 
     ui32 ReadUnsignedVarInt() override
     {
+        YT_LOG_TRACE("Reading unsigned varint");
         ui32 result;
         Offset_ += ReadVarUint32(Data_.begin() + Offset_, &result);
         return result;
@@ -72,6 +87,7 @@ class TKafkaProtocolReader
 
     std::optional<TString> ReadNullableString() override
     {
+        YT_LOG_TRACE("Reading nullable string");
         auto length = ReadInt16();
         if (length == -1) {
             return {};
@@ -84,6 +100,7 @@ class TKafkaProtocolReader
 
     std::optional<TString> ReadCompactNullableString() override
     {
+        YT_LOG_TRACE("Reading compact nullable string");
         auto length = ReadUnsignedVarInt();
         if (length == 0) {
             return {};
@@ -97,6 +114,7 @@ class TKafkaProtocolReader
 
     TString ReadCompactString() override
     {
+        YT_LOG_TRACE("Reading compact string");
         TString result;
 
         auto length = ReadUnsignedVarInt();
@@ -111,6 +129,7 @@ class TKafkaProtocolReader
 
     TString ReadString() override
     {
+        YT_LOG_TRACE("Reading string");
         TString result;
 
         auto length = ReadInt16();
@@ -125,6 +144,7 @@ class TKafkaProtocolReader
 
     TString ReadBytes() override
     {
+        YT_LOG_TRACE("Reading bytes");
         TString result;
 
         auto length = ReadInt32();
@@ -139,6 +159,7 @@ class TKafkaProtocolReader
 
     TGuid ReadUuid() override
     {
+        YT_LOG_TRACE("Reading uuid");
         TString value;
         ReadString(&value, 16);
         return TGuid::FromString(value);
@@ -146,6 +167,10 @@ class TKafkaProtocolReader
 
     void ReadString(TString* result, int length) override
     {
+        YT_LOG_TRACE("Reading string with length (Length: %v, DataSize: %v, Offset: %v)",
+            length,
+            Data_.size(),
+            Offset_);
         ValidateSizeAvailable(length);
 
         result->resize(length);
@@ -156,6 +181,7 @@ class TKafkaProtocolReader
 
     TString ReadCompactBytes() override
     {
+        YT_LOG_TRACE("Reading compact bytes");
         TString result;
 
         auto length = ReadUnsignedVarInt();
@@ -169,6 +195,7 @@ class TKafkaProtocolReader
 
     i32 StartReadBytes(bool needReadCount) override
     {
+        YT_LOG_TRACE("Start reading bytes");
         i32 size = 0;
         if (needReadCount) {
             size = ReadInt32();
@@ -179,6 +206,7 @@ class TKafkaProtocolReader
 
     i32 StartReadCompactBytes(bool needReadCount) override
     {
+        YT_LOG_TRACE("Start reading compact bytes");
         i32 size = 0;
         if (needReadCount) {
             size = ReadUnsignedVarInt() - 1;
@@ -197,6 +225,7 @@ class TKafkaProtocolReader
 
     void FinishReadBytes() override
     {
+        YT_LOG_TRACE("Finish reading bytes");
         if (!BytesOffsets_.empty()) {
             return BytesOffsets_.pop_back();
         }
@@ -247,7 +276,9 @@ class TKafkaProtocolReader
     void ValidateSizeAvailable(i64 size)
     {
         if (std::ssize(Data_) - Offset_ < size) {
-            THROW_ERROR_EXCEPTION("Premature end of stream while reading %v bytes", size);
+            THROW_ERROR_EXCEPTION("Premature end of stream while reading %v bytes", size)
+                << TErrorAttribute("data_size", std::ssize(Data_))
+                << TErrorAttribute("offset", Offset_);
         }
     }
 };
@@ -392,10 +423,28 @@ class TKafkaProtocolWriter
     void FinishBytes() override
     {
         YT_VERIFY(!BytesOffsets_.empty());
-        DoWriteInt<int32_t>(Size_ - BytesOffsets_.back(), BytesOffsets_.back() - sizeof(int32_t));
+        DoWriteInt<i32>(Size_ - BytesOffsets_.back(), BytesOffsets_.back() - sizeof(i32));
         BytesOffsets_.pop_back();
     }
 
+    void StartCalculateChecksum() override
+    {
+        WriteInt32(0);
+        ChecksumOffsets_.push_back(Size_);
+    }
+
+    void FinishCalculateChecksum() override
+    {
+        YT_VERIFY(!ChecksumOffsets_.empty());
+        auto offset = ChecksumOffsets_.back();
+        ChecksumOffsets_.pop_back();
+
+        auto data = Buffer_.Slice(offset, Size_);
+        auto checksum = Crc32c(data.begin(), data.size());
+
+        DoWriteInt<ui32>(checksum, offset - sizeof(ui32));
+    }
+
     TSharedRef Finish() override
     {
         return Buffer_.Slice(0, Size_);
@@ -417,6 +466,7 @@ class TKafkaProtocolWriter
     i64 Size_ = 0;
 
     std::vector<i64> BytesOffsets_;
+    std::vector<i64> ChecksumOffsets_;
 
     template <typename T>
     void DoWriteInt(T value, std::optional<i64> position = std::nullopt)
diff --git a/yt/yt/client/kafka/protocol.h b/yt/yt/client/kafka/protocol.h
index 135464b55420..deaffbc6067b 100644
--- a/yt/yt/client/kafka/protocol.h
+++ b/yt/yt/client/kafka/protocol.h
@@ -10,6 +10,17 @@ namespace NYT::NKafka {
 
 ////////////////////////////////////////////////////////////////////////////////
 
+#define READ_KAFKA_FIELD(field, method)                                                    \
+    YT_LOG_TRACE("Parsing kafka data (Field: %v)", #field);                                \
+    field = reader->method();                                                              \
+    YT_LOG_TRACE("Parsing kafka data, value read (Field: %v, Value: %v)", #field, field);
+
+#define WRITE_KAFKA_FIELD(kafkaWriter, method, field)                                             \
+    YT_LOG_TRACE("Writing kafka data (Field: %v, Value: %v)", #field, field);                     \
+    kafkaWriter->method(field);
+
+////////////////////////////////////////////////////////////////////////////////
+
 struct IKafkaProtocolReader
 {
     virtual ~IKafkaProtocolReader() = default;
@@ -86,6 +97,9 @@ struct IKafkaProtocolWriter
     virtual void StartBytes() = 0;
     virtual void FinishBytes() = 0;
 
+    virtual void StartCalculateChecksum() = 0;
+    virtual void FinishCalculateChecksum() = 0;
+
     virtual i64 GetSize() const = 0;
 
     virtual TSharedRef Finish() = 0;
diff --git a/yt/yt/client/kafka/public.h b/yt/yt/client/kafka/public.h
index fbdce4d12461..fddafe428bad 100644
--- a/yt/yt/client/kafka/public.h
+++ b/yt/yt/client/kafka/public.h
@@ -1,7 +1,15 @@
 #pragma once
 
+#include <yt/yt/core/logging/log_manager.h>
+
 #include <yt/yt/core/misc/public.h>
 
 namespace NYT::NKafka {
 
+////////////////////////////////////////////////////////////////////////////////
+
+YT_DEFINE_GLOBAL(const NLogging::TLogger, KafkaLogger, "Kafka");
+
+////////////////////////////////////////////////////////////////////////////////
+
 } // namespace NYT::NKafka
diff --git a/yt/yt/client/kafka/requests.cpp b/yt/yt/client/kafka/requests.cpp
index d94a0f6a82b5..179d17670edc 100644
--- a/yt/yt/client/kafka/requests.cpp
+++ b/yt/yt/client/kafka/requests.cpp
@@ -6,6 +6,10 @@ namespace NYT::NKafka {
 
 ////////////////////////////////////////////////////////////////////////////////
 
+static constexpr auto& Logger = KafkaLogger;
+
+////////////////////////////////////////////////////////////////////////////////
+
 int GetRequestHeaderVersion(ERequestType requestType, i16 apiVersion)
 {
     switch (requestType) {
@@ -100,24 +104,24 @@ void TRecord::Serialize(IKafkaProtocolWriter* writer, int version) const
     if (version == 2) {
         auto recordWriter = CreateKafkaProtocolWriter();
 
-        recordWriter->WriteByte(Attributes);
-        recordWriter->WriteVarLong(TimestampDelta);
-        recordWriter->WriteVarInt(OffsetDelta);
+        WRITE_KAFKA_FIELD(recordWriter, WriteByte, Attributes)
+        WRITE_KAFKA_FIELD(recordWriter, WriteVarLong, TimestampDelta)
+        WRITE_KAFKA_FIELD(recordWriter, WriteVarInt, OffsetDelta)
 
-        recordWriter->WriteVarInt(Key.size());
-        recordWriter->WriteData(Key);
+        WRITE_KAFKA_FIELD(recordWriter, WriteVarInt, Key.size())
+        WRITE_KAFKA_FIELD(recordWriter, WriteData, Key)
 
-        recordWriter->WriteVarInt(Value.size());
-        recordWriter->WriteData(Value);
+        WRITE_KAFKA_FIELD(recordWriter, WriteVarInt, Value.size())
+        WRITE_KAFKA_FIELD(recordWriter, WriteData, Value)
 
-        recordWriter->WriteVarInt(Headers.size());
+        WRITE_KAFKA_FIELD(recordWriter, WriteVarInt, Headers.size())
         for (const auto& header : Headers) {
             header.Serialize(recordWriter.get(), version);
         }
 
         auto record = recordWriter->Finish();
 
-        writer->WriteVarInt(record.Size());
+        WRITE_KAFKA_FIELD(writer, WriteVarInt, record.size())
         writer->WriteData(record);
     } else if (version == 1 || version == 0) {
         writer->WriteByte(Attributes);
@@ -135,29 +139,46 @@ void TRecord::Serialize(IKafkaProtocolWriter* writer, int version) const
 
 void TRecord::Deserialize(IKafkaProtocolReader* reader, int version)
 {
+    std::optional<i32> length;
     if (version == 2) {
-        reader->ReadVarInt();  // Length, not used.
+        READ_KAFKA_FIELD(length, ReadVarInt);
+        reader->StartReadBytes(/*needReadSize*/ false);
     }
-    Attributes = reader->ReadByte();
+    READ_KAFKA_FIELD(Attributes, ReadByte)
 
     if (version == 2) {
-        TimestampDelta = reader->ReadVarLong();
-        OffsetDelta = reader->ReadVarInt();
+        READ_KAFKA_FIELD(TimestampDelta, ReadVarLong)
+        READ_KAFKA_FIELD(OffsetDelta, ReadVarInt)
 
         auto keySize = reader->ReadVarInt();
+        YT_LOG_TRACE("Parsing Record (KeySize: %v)", keySize);
         reader->ReadString(&Key, keySize);
 
-        auto valueSize = reader->ReadVarInt();
-        reader->ReadString(&Value, valueSize);
+        i32 valueSize;
+        READ_KAFKA_FIELD(valueSize, ReadVarInt);
+
+        if (valueSize > 0) {
+            YT_LOG_TRACE("Parsing Record (ValueSize: %v)", valueSize);
+            reader->ReadString(&Value, valueSize);
+        }
 
-        auto headerCount = reader->ReadVarInt();
-        Headers.resize(headerCount);
-        for (auto& header : Headers) {
-            header.Deserialize(reader, version);
+        i32 headerCount;
+        READ_KAFKA_FIELD(headerCount, ReadVarInt);
+        if (headerCount > 0) {
+            Headers.resize(headerCount);
+            for (auto& header : Headers) {
+                header.Deserialize(reader, version);
+            }
+        }
+
+        reader->FinishReadBytes();
+
+        if (length && reader->GetReadBytesCount() != length) {
+            YT_LOG_ERROR("Not all record bytes were read (Expected: %v, Actual: %v)", *length, reader->GetReadBytesCount());
         }
     } else if (version == 1 || version == 0) {
         if (version == 1) {
-            TimestampDelta = reader->ReadInt64();
+            READ_KAFKA_FIELD(TimestampDelta, ReadInt64)
         }
         Key = reader->ReadBytes();
         Value = reader->ReadBytes();
@@ -168,32 +189,34 @@ void TRecord::Deserialize(IKafkaProtocolReader* reader, int version)
 
 void TRecordBatch::Serialize(IKafkaProtocolWriter* writer) const
 {
-    writer->WriteInt64(BaseOffset);
+    WRITE_KAFKA_FIELD(writer, WriteInt64, BaseOffset)
 
     writer->StartBytes();  // Write Length.
 
     if (MagicByte == 0 || MagicByte == 1) {
-        writer->WriteInt32(CrcOld);
-        writer->WriteByte(MagicByte);
+        // TODO(nadya73): implement it via [Start/Finish]CalculateChecksum and crc32.
+        WRITE_KAFKA_FIELD(writer, WriteUint32, CrcOld)
+        WRITE_KAFKA_FIELD(writer, WriteByte, MagicByte)
 
         YT_VERIFY(Records.size() == 1);
         Records[0].Serialize(writer, MagicByte);
     } else if (MagicByte == 2) {
-        writer->WriteInt32(PartitionLeaderEpoch);
-        writer->WriteByte(MagicByte);
-        writer->WriteUint32(Crc);
-        writer->WriteInt16(Attributes);
-        writer->WriteInt32(LastOffsetDelta);
-        writer->WriteInt64(FirstTimestamp);
-        writer->WriteInt64(MaxTimestamp);
-        writer->WriteInt64(ProducerId);
-        writer->WriteInt16(ProducerEpoch);
-        writer->WriteInt32(BaseSequence);
-
-        writer->WriteInt32(Records.size());
+        WRITE_KAFKA_FIELD(writer, WriteInt32, PartitionLeaderEpoch)
+        WRITE_KAFKA_FIELD(writer, WriteByte, MagicByte)
+        writer->StartCalculateChecksum();
+        WRITE_KAFKA_FIELD(writer, WriteInt16, Attributes)
+        WRITE_KAFKA_FIELD(writer, WriteInt32, LastOffsetDelta)
+        WRITE_KAFKA_FIELD(writer, WriteInt64, FirstTimestamp)
+        WRITE_KAFKA_FIELD(writer, WriteInt64, MaxTimestamp)
+        WRITE_KAFKA_FIELD(writer, WriteInt64, ProducerId)
+        WRITE_KAFKA_FIELD(writer, WriteInt16, ProducerEpoch)
+        WRITE_KAFKA_FIELD(writer, WriteInt32, BaseSequence)
+
+        WRITE_KAFKA_FIELD(writer, WriteInt32, Records.size())
         for (const auto& record : Records) {
             record.Serialize(writer, MagicByte);
         }
+        writer->FinishCalculateChecksum();
     } else {
         THROW_ERROR_EXCEPTION("Unsupported MagicByte %v in RecordBatch serialization", static_cast<int>(MagicByte));
     }
@@ -202,14 +225,13 @@ void TRecordBatch::Serialize(IKafkaProtocolWriter* writer) const
 
 void TRecordBatch::Deserialize(IKafkaProtocolReader* reader)
 {
-    BaseOffset = reader->ReadInt64();
-    Length = reader->ReadInt32();
+    READ_KAFKA_FIELD(BaseOffset, ReadInt64)
+    READ_KAFKA_FIELD(Length, ReadInt32)
 
     reader->StartReadBytes(/*needReadSize*/ false);
 
-    PartitionLeaderEpoch = reader->ReadInt32();
-
-    MagicByte = reader->ReadByte();
+    READ_KAFKA_FIELD(PartitionLeaderEpoch, ReadInt32)
+    READ_KAFKA_FIELD(MagicByte, ReadByte)
 
     if (MagicByte == 0 || MagicByte == 1) {
         // In v0/v1 CRC is before MagicByte and there is no PartitionLeaderEpoch;
@@ -218,22 +240,30 @@ void TRecordBatch::Deserialize(IKafkaProtocolReader* reader)
 
         // It's a message in v0/v1.
         auto& record = Records.emplace_back();
+        YT_LOG_TRACE("Parsing RecordBatch, reading Record");
         record.Deserialize(reader, MagicByte);
     } else if (MagicByte == 2) {
-        Crc = reader->ReadUint32();
-
-        Attributes = reader->ReadInt16();
-        LastOffsetDelta = reader->ReadInt32();
-        FirstTimestamp = reader->ReadInt64();
-        MaxTimestamp = reader->ReadInt64();
-        ProducerId = reader->ReadInt64();
-        ProducerEpoch = reader->ReadInt16();
-        BaseSequence = reader->ReadInt32();
-
-        while (reader->GetReadBytesCount() < Length) {
-            TRecord record;
-            record.Deserialize(reader, MagicByte);
-            Records.push_back(std::move(record));
+        READ_KAFKA_FIELD(Crc, ReadUint32)
+        READ_KAFKA_FIELD(Attributes, ReadInt16)
+        READ_KAFKA_FIELD(LastOffsetDelta, ReadInt32)
+        READ_KAFKA_FIELD(FirstTimestamp, ReadInt64)
+        READ_KAFKA_FIELD(MaxTimestamp, ReadInt64)
+        READ_KAFKA_FIELD(ProducerId, ReadInt64)
+        READ_KAFKA_FIELD(ProducerEpoch, ReadInt16)
+        READ_KAFKA_FIELD(BaseSequence, ReadInt32)
+
+        i32 recordCount = 0;
+        READ_KAFKA_FIELD(recordCount, ReadInt32)
+        if (recordCount > 0) {
+            Records.reserve(recordCount);
+            for (i32 recordIndex = 0; recordIndex < recordCount; ++recordIndex) {
+                TRecord record;
+                record.Deserialize(reader, MagicByte);
+                Records.push_back(std::move(record));
+            }
+        }
+        if (reader->GetReadBytesCount() != Length) {
+            THROW_ERROR_EXCEPTION("Unexpected record batch length (Expected: %v, Actual: %v)", Length, reader->GetReadBytesCount());
         }
     } else {
         THROW_ERROR_EXCEPTION("Unsupported MagicByte %v in RecordBatch deserialization", static_cast<int>(MagicByte));
@@ -481,6 +511,19 @@ void TRspHeartbeat::Serialize(IKafkaProtocolWriter* writer, int /*apiVersion*/)
 
 ////////////////////////////////////////////////////////////////////////////////
 
+void TReqLeaveGroup::Deserialize(IKafkaProtocolReader* reader, int /*apiVersion*/)
+{
+    GroupId = reader->ReadString();
+    MemberId = reader->ReadString();
+}
+
+void TRspLeaveGroup::Serialize(IKafkaProtocolWriter* writer, int /*apiVersion*/) const
+{
+    writer->WriteErrorCode(ErrorCode);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
 void TReqOffsetCommitTopicPartition::Deserialize(IKafkaProtocolReader* reader, int /*apiVersion*/)
 {
     PartitionIndex = reader->ReadInt32();
@@ -598,12 +641,13 @@ void TReqFetch::Deserialize(IKafkaProtocolReader* reader, int apiVersion)
 
 void TRspFetchResponsePartition::Serialize(IKafkaProtocolWriter* writer, int /*apiVersion*/) const
 {
-    writer->WriteInt32(PartitionIndex);
-    writer->WriteErrorCode(ErrorCode);
-    writer->WriteInt64(HighWatermark);
+    WRITE_KAFKA_FIELD(writer, WriteInt32, PartitionIndex)
+    WRITE_KAFKA_FIELD(writer, WriteErrorCode, ErrorCode)
+    WRITE_KAFKA_FIELD(writer, WriteInt64, HighWatermark)
 
     if (!RecordBatches) {
-        writer->WriteInt32(-1);
+        i32 recordBatchesSize = -1;
+        WRITE_KAFKA_FIELD(writer, WriteInt32, recordBatchesSize)
     } else {
         writer->StartBytes();
         for (const auto& recordBatch : *RecordBatches) {
@@ -615,9 +659,9 @@ void TRspFetchResponsePartition::Serialize(IKafkaProtocolWriter* writer, int /*a
 
 void TRspFetchResponse::Serialize(IKafkaProtocolWriter* writer, int apiVersion) const
 {
-    writer->WriteString(Topic);
+    WRITE_KAFKA_FIELD(writer, WriteString, Topic)
 
-    writer->WriteInt32(Partitions.size());
+    WRITE_KAFKA_FIELD(writer, WriteInt32, Partitions.size())
     for (const auto& partition : Partitions) {
         partition.Serialize(writer, apiVersion);
     }
@@ -626,9 +670,9 @@ void TRspFetchResponse::Serialize(IKafkaProtocolWriter* writer, int apiVersion)
 void TRspFetch::Serialize(IKafkaProtocolWriter* writer, int apiVersion) const
 {
     if (apiVersion >= 2) {
-        writer->WriteInt32(ThrottleTimeMs);
+        WRITE_KAFKA_FIELD(writer, WriteInt32, ThrottleTimeMs)
     }
-    writer->WriteInt32(Responses.size());
+    WRITE_KAFKA_FIELD(writer, WriteInt32, Responses.size())
 
     for (const auto& response : Responses) {
         response.Serialize(writer, apiVersion);
@@ -671,7 +715,7 @@ void TRspSaslAuthenticate::Serialize(IKafkaProtocolWriter* writer, int /*apiVers
 
 void TReqProduceTopicDataPartitionData::Deserialize(IKafkaProtocolReader* reader, int apiVersion)
 {
-    Index = reader->ReadInt32();
+    READ_KAFKA_FIELD(Index, ReadInt32)
 
     i32 bytesCount;
     if (apiVersion < 9) {
@@ -695,9 +739,9 @@ void TReqProduceTopicDataPartitionData::Deserialize(IKafkaProtocolReader* reader
 void TReqProduceTopicData::Deserialize(IKafkaProtocolReader* reader, int apiVersion)
 {
     if (apiVersion < 9) {
-        Name = reader->ReadString();
+        READ_KAFKA_FIELD(Name, ReadString)
     } else {
-        Name = reader->ReadCompactString();
+        READ_KAFKA_FIELD(Name, ReadCompactString)
     }
 
     NKafka::Deserialize(PartitionData, reader, /*isCompact*/ apiVersion >= 9, apiVersion);
@@ -711,13 +755,13 @@ void TReqProduce::Deserialize(IKafkaProtocolReader* reader, int apiVersion)
 {
     if (apiVersion >= 3) {
         if (apiVersion < 9) {
-            TransactionalId = reader->ReadNullableString();
+            READ_KAFKA_FIELD(TransactionalId, ReadNullableString)
         } else {
-            TransactionalId = reader->ReadCompactNullableString();
+            READ_KAFKA_FIELD(TransactionalId, ReadCompactNullableString)
         }
     }
-    Acks = reader->ReadInt16();
-    TimeoutMs = reader->ReadInt32();
+    READ_KAFKA_FIELD(Acks, ReadInt16)
+    READ_KAFKA_FIELD(TimeoutMs, ReadInt32)
 
     NKafka::Deserialize(TopicData, reader, /*isCompact*/ apiVersion >= 9, apiVersion);
 
@@ -815,10 +859,14 @@ void TReqListOffsets::Deserialize(IKafkaProtocolReader* reader, int apiVersion)
     }
 }
 
-void TRspListOffsetsTopicPartition::Serialize(IKafkaProtocolWriter* writer, int /*apiVersion*/) const
+void TRspListOffsetsTopicPartition::Serialize(IKafkaProtocolWriter* writer, int apiVersion) const
 {
     writer->WriteInt32(PartitionIndex);
     writer->WriteErrorCode(ErrorCode);
+
+    if (apiVersion <= 0) {
+        writer->WriteInt32(1); // Size of 'old_style_offsets'.
+    }
     writer->WriteInt64(Offset);
 }
 
diff --git a/yt/yt/client/kafka/requests.h b/yt/yt/client/kafka/requests.h
index bdd2a7ba992b..87943acb253f 100644
--- a/yt/yt/client/kafka/requests.h
+++ b/yt/yt/client/kafka/requests.h
@@ -128,11 +128,11 @@ struct TRecordBatch
 
     i32 LastOffsetDelta = 0;
     // BaseTimestamp in v2 and ... TODO in v1.
-    i64 FirstTimestamp = 0;
-    i64 MaxTimestamp = 0;
+    i64 FirstTimestamp = -1;
+    i64 MaxTimestamp = -1;
 
-    i64 ProducerId = 0;
-    i16 ProducerEpoch = 0;
+    i64 ProducerId = -1;
+    i16 ProducerEpoch = -1;
     // Same as BaseSequence in v2 and TODO.
     i32 BaseSequence = 0;
 
@@ -374,6 +374,25 @@ struct TRspHeartbeat
 
 ////////////////////////////////////////////////////////////////////////////////
 
+struct TReqLeaveGroup
+{
+    static constexpr ERequestType RequestType = ERequestType::LeaveGroup;
+
+    TGroupId GroupId;
+    TMemberId MemberId;
+
+    void Deserialize(IKafkaProtocolReader* reader, int apiVersion);
+};
+
+struct TRspLeaveGroup
+{
+    NKafka::EErrorCode ErrorCode = NKafka::EErrorCode::None;
+
+    void Serialize(IKafkaProtocolWriter* writer, int apiVersion) const;
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
 struct TReqOffsetCommitTopicPartition
 {
     i32 PartitionIndex = 0;
diff --git a/yt/yt/client/ya.make b/yt/yt/client/ya.make
index a1ca7c303d6c..c660a2bd979c 100644
--- a/yt/yt/client/ya.make
+++ b/yt/yt/client/ya.make
@@ -221,6 +221,7 @@ PEERDIR(
     yt/yt/library/numeric
     yt/yt/library/quantile_digest
     yt/yt_proto/yt/client
+    library/cpp/digest/crc32c
     library/cpp/json
     library/cpp/string_utils/base64
     contrib/libs/pfr
diff --git a/yt/yt/core/actions/future-inl.h b/yt/yt/core/actions/future-inl.h
index 090ac8a72749..30254e77d0d3 100644
--- a/yt/yt/core/actions/future-inl.h
+++ b/yt/yt/core/actions/future-inl.h
@@ -1421,7 +1421,7 @@ bool TPromiseBase<T>::TrySet(NYT::TErrorOr<T>&& value) const
 
 template <class T>
 template <class U>
-inline void TPromiseBase<T>::TrySetFrom(TFuture<U> another) const
+inline void TPromiseBase<T>::TrySetFrom(const TFuture<U>& another) const
 {
     YT_ASSERT(Impl_);
 
diff --git a/yt/yt/core/actions/future.h b/yt/yt/core/actions/future.h
index 768cf930ec2b..944174b40d15 100644
--- a/yt/yt/core/actions/future.h
+++ b/yt/yt/core/actions/future.h
@@ -456,7 +456,7 @@ class TPromiseBase
 
     //! Similar to #SetFrom but calls #TrySet instead of #Set.
     template <class U>
-    void TrySetFrom(TFuture<U> another) const;
+    void TrySetFrom(const TFuture<U>& another) const;
 
     //! Gets the value.
     /*!
diff --git a/yt/yt/core/concurrency/config.cpp b/yt/yt/core/concurrency/config.cpp
index 9a1c63bf185e..fffc2d0d693e 100644
--- a/yt/yt/core/concurrency/config.cpp
+++ b/yt/yt/core/concurrency/config.cpp
@@ -1,5 +1,7 @@
 #include "config.h"
 
+#include <yt/yt/core/misc/jitter.h>
+
 namespace NYT::NConcurrency {
 
 using namespace NYTree;
@@ -14,6 +16,20 @@ TPeriodicExecutorOptions TPeriodicExecutorOptions::WithJitter(TDuration period)
     };
 }
 
+TDuration TPeriodicExecutorOptions::GenerateDelay() const
+{
+    if (!Period) {
+        return TDuration::Max();
+    }
+
+    auto randomGenerator = [] {
+        return 2.0 * RandomNumber<double>() - 1.0;
+    };
+
+    // Jitter is divided by 2 for historical reasons.
+    return ApplyJitter(*Period, Jitter / 2.0, randomGenerator);
+}
+
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace NDetail {
diff --git a/yt/yt/core/concurrency/config.h b/yt/yt/core/concurrency/config.h
index 6a93edc642df..20639a7be2ef 100644
--- a/yt/yt/core/concurrency/config.h
+++ b/yt/yt/core/concurrency/config.h
@@ -22,8 +22,11 @@ struct TPeriodicExecutorOptions
 
     bool operator==(const TPeriodicExecutorOptions& other) const = default;
 
-    //! Sets #Period and Applies set#DefaultJitter.
+    //! Sets #Period and applies #DefaultJitter.
     static TPeriodicExecutorOptions WithJitter(TDuration period);
+
+    //! Generates the delay for the next invocation from #Period and #Jitter.
+    TDuration GenerateDelay() const;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
diff --git a/yt/yt/core/concurrency/periodic_executor.cpp b/yt/yt/core/concurrency/periodic_executor.cpp
index 74470806863a..d4e88932cd5e 100644
--- a/yt/yt/core/concurrency/periodic_executor.cpp
+++ b/yt/yt/core/concurrency/periodic_executor.cpp
@@ -25,7 +25,7 @@ TDefaultInvocationTimePolicy::TDefaultInvocationTimePolicy(
 void TDefaultInvocationTimePolicy::ProcessResult()
 { }
 
-TInstant TDefaultInvocationTimePolicy::KickstartDeadline()
+TInstant TDefaultInvocationTimePolicy::GenerateKickstartDeadline()
 {
     return TInstant::Now() + RandomDuration(Splay);
 }
@@ -54,18 +54,12 @@ void TDefaultInvocationTimePolicy::SetOptions(std::optional<TDuration> period)
 {
     Period = period;
 }
-
-TInstant TDefaultInvocationTimePolicy::NextDeadline()
+TInstant TDefaultInvocationTimePolicy::GenerateNextDeadline()
 {
-    auto randomGenerator = [] {
-        double rand = RandomNumber<double>();
+    return TInstant::Now() + GenerateDelay();
+}
 
-        return 2.0 * rand - 1.0;
-    };
 
-    //! Jitter is divided by 2 for historical reasons.
-    return TInstant::Now() + ApplyJitter(*Period, Jitter / 2.0, randomGenerator);
-}
 
 bool TDefaultInvocationTimePolicy::IsOutOfBandProhibited()
 {
diff --git a/yt/yt/core/concurrency/periodic_executor.h b/yt/yt/core/concurrency/periodic_executor.h
index b28a70c8ae24..59f1114384ca 100644
--- a/yt/yt/core/concurrency/periodic_executor.h
+++ b/yt/yt/core/concurrency/periodic_executor.h
@@ -26,7 +26,7 @@ class TDefaultInvocationTimePolicy
 
     void ProcessResult();
 
-    TInstant KickstartDeadline();
+    TInstant GenerateKickstartDeadline();
 
     bool IsEnabled();
 
@@ -38,7 +38,7 @@ class TDefaultInvocationTimePolicy
 
     void SetOptions(std::optional<TDuration> period);
 
-    TInstant NextDeadline();
+    TInstant GenerateNextDeadline();
 
     bool IsOutOfBandProhibited();
 
diff --git a/yt/yt/core/concurrency/periodic_executor_base-inl.h b/yt/yt/core/concurrency/periodic_executor_base-inl.h
index 022dadf503a4..56cf6b037671 100644
--- a/yt/yt/core/concurrency/periodic_executor_base-inl.h
+++ b/yt/yt/core/concurrency/periodic_executor_base-inl.h
@@ -39,7 +39,7 @@ TFuture<void> TPeriodicExecutorBase<TInvocationTimePolicy>::StartAndGetFirstExec
         IdlePromise_ = TPromise<void>();
         Started_ = true;
         if (TInvocationTimePolicy::IsEnabled()) {
-            PostDelayedCallback(TInvocationTimePolicy::KickstartDeadline());
+            PostDelayedCallback(TInvocationTimePolicy::GenerateKickstartDeadline());
         }
     }
 
@@ -251,7 +251,7 @@ void TPeriodicExecutorBase<TInvocationTimePolicy>::RunCallback()
             guard.Release();
             PostCallback();
         } else if (TInvocationTimePolicy::IsEnabled()) {
-            PostDelayedCallback(TInvocationTimePolicy::NextDeadline());
+            PostDelayedCallback(TInvocationTimePolicy::GenerateNextDeadline());
         }
     };
 
@@ -282,7 +282,7 @@ void TPeriodicExecutorBase<TInvocationTimePolicy>::OnCallbackCancelled()
     }
 
     if (TInvocationTimePolicy::IsEnabled()) {
-        PostDelayedCallback(TInvocationTimePolicy::NextDeadline());
+        PostDelayedCallback(TInvocationTimePolicy::GenerateNextDeadline());
     }
 }
 
@@ -299,7 +299,7 @@ void TPeriodicExecutorBase<TInvocationTimePolicy>::SetOptions(TPartialOptions...
     if (Started_ && !Busy_ && TInvocationTimePolicy::ShouldKickstart(options...)) {
         TInvocationTimePolicy::SetOptions(std::move(options)...);
 
-        PostDelayedCallback(TInvocationTimePolicy::KickstartDeadline());
+        PostDelayedCallback(TInvocationTimePolicy::GenerateKickstartDeadline());
     } else {
         TInvocationTimePolicy::SetOptions(std::move(options)...);
     }
diff --git a/yt/yt/core/concurrency/periodic_executor_base.h b/yt/yt/core/concurrency/periodic_executor_base.h
index 32ce9522e8a7..8f53792dd164 100644
--- a/yt/yt/core/concurrency/periodic_executor_base.h
+++ b/yt/yt/core/concurrency/periodic_executor_base.h
@@ -50,9 +50,9 @@ concept CInvocationTimePolicy = CCallbackResultProcessor<T> &&
     { policy.SetOptions(options) } -> std::same_as<void>;
 
     { policy.ShouldKickstart(options) } -> std::same_as<bool>;
-    { policy.KickstartDeadline() } -> std::same_as<TInstant>;
+    { policy.GenerateKickstartDeadline() } -> std::same_as<TInstant>;
 
-    { policy.NextDeadline() } -> std::same_as<TInstant>;
+    { policy.GenerateNextDeadline() } -> std::same_as<TInstant>;
     { policy.IsOutOfBandProhibited() } -> std::same_as<bool>;
     { policy.Reset() } -> std::same_as<void>;
 };
diff --git a/yt/yt/core/concurrency/retrying_periodic_executor.cpp b/yt/yt/core/concurrency/retrying_periodic_executor.cpp
index c20caadf5f84..dc812df8de6b 100644
--- a/yt/yt/core/concurrency/retrying_periodic_executor.cpp
+++ b/yt/yt/core/concurrency/retrying_periodic_executor.cpp
@@ -89,13 +89,13 @@ void TRetryingInvocationTimePolicy::SetOptions(
     }
 }
 
-TInstant TRetryingInvocationTimePolicy::NextDeadline()
+TInstant TRetryingInvocationTimePolicy::GenerateNextDeadline()
 {
     if (IsInBackoffMode()) {
         return TInstant::Now() + Backoff_.GetBackoff();
     }
 
-    return TDefaultInvocationTimePolicy::NextDeadline();
+    return TDefaultInvocationTimePolicy::GenerateNextDeadline();
 }
 
 bool TRetryingInvocationTimePolicy::IsOutOfBandProhibited()
diff --git a/yt/yt/core/concurrency/retrying_periodic_executor.h b/yt/yt/core/concurrency/retrying_periodic_executor.h
index af7916e681de..3701b94226a2 100644
--- a/yt/yt/core/concurrency/retrying_periodic_executor.h
+++ b/yt/yt/core/concurrency/retrying_periodic_executor.h
@@ -25,7 +25,7 @@ class TRetryingInvocationTimePolicy
 
     void ProcessResult(TCallbackResult result);
 
-    using TDefaultInvocationTimePolicy::KickstartDeadline;
+    using TDefaultInvocationTimePolicy::GenerateKickstartDeadline;
 
     using TDefaultInvocationTimePolicy::IsEnabled;
 
@@ -41,7 +41,7 @@ class TRetryingInvocationTimePolicy
         std::optional<NConcurrency::TPeriodicExecutorOptions> periodicOptions,
         std::optional<TExponentialBackoffOptions> backofOptions);
 
-    TInstant NextDeadline();
+    TInstant GenerateNextDeadline();
 
     bool IsOutOfBandProhibited();
 
diff --git a/yt/yt/core/concurrency/scheduled_executor.cpp b/yt/yt/core/concurrency/scheduled_executor.cpp
index f906e5545d1d..36e771ab6da8 100644
--- a/yt/yt/core/concurrency/scheduled_executor.cpp
+++ b/yt/yt/core/concurrency/scheduled_executor.cpp
@@ -28,9 +28,9 @@ TScheduledInvocationTimePolicy::TScheduledInvocationTimePolicy(
 void TScheduledInvocationTimePolicy::ProcessResult()
 { }
 
-TInstant TScheduledInvocationTimePolicy::KickstartDeadline()
+TInstant TScheduledInvocationTimePolicy::GenerateKickstartDeadline()
 {
-    return NextDeadline();
+    return GenerateNextDeadline();
 }
 
 bool TScheduledInvocationTimePolicy::IsEnabled()
@@ -53,7 +53,7 @@ void TScheduledInvocationTimePolicy::SetOptions(TOptions interval)
 //! Returns the next time instant which is a multiple of the configured interval.
 //! NB: If the current instant is itself a multiple of the configured interval, this method will return the next
 //! suitable instant.
-TInstant TScheduledInvocationTimePolicy::NextDeadline()
+TInstant TScheduledInvocationTimePolicy::GenerateNextDeadline()
 {
     YT_VERIFY(Interval_);
 
diff --git a/yt/yt/core/concurrency/scheduled_executor.h b/yt/yt/core/concurrency/scheduled_executor.h
index cde105ae8960..025c5ece2dc7 100644
--- a/yt/yt/core/concurrency/scheduled_executor.h
+++ b/yt/yt/core/concurrency/scheduled_executor.h
@@ -22,7 +22,7 @@ class TScheduledInvocationTimePolicy
 
     void ProcessResult();
 
-    TInstant KickstartDeadline();
+    TInstant GenerateKickstartDeadline();
 
     bool IsEnabled();
 
@@ -33,7 +33,7 @@ class TScheduledInvocationTimePolicy
     //! Returns the next time instant which is a multiple of the configured interval.
     //! NB: If the current instant is itself a multiple of the configured interval, this method will return the next
     //! suitable instant.
-    TInstant NextDeadline();
+    TInstant GenerateNextDeadline();
 
     bool IsOutOfBandProhibited();
 
diff --git a/yt/yt/library/formats/arrow_writer.h b/yt/yt/library/formats/arrow_writer.h
index 0a3dd225348c..020090152ccd 100644
--- a/yt/yt/library/formats/arrow_writer.h
+++ b/yt/yt/library/formats/arrow_writer.h
@@ -24,6 +24,3 @@ ISchemalessFormatWriterPtr CreateWriterForArrow(
 ////////////////////////////////////////////////////////////////////////////////
 
 } // namespace NYT::NFormat
-
-
-
