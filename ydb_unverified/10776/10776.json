{
  "repo": "ydb-platform/ydb",
  "pull_number": 10776,
  "instance_id": "ydb-platform__ydb-10776",
  "issue_numbers": [
    "10621"
  ],
  "base_commit": "0ea658ab6edb7971ea29254cb58bfcb210e4bf05",
  "patch": "diff --git a/.github/config/muted_ya.txt b/.github/config/muted_ya.txt\nindex 8ae4cd55ae93..ef2c4e4bd59b 100644\n--- a/.github/config/muted_ya.txt\n+++ b/.github/config/muted_ya.txt\n@@ -52,8 +52,6 @@ ydb/library/actors/http/ut HttpProxy.TooLongHeader\n ydb/library/actors/http/ut sole chunk chunk\n ydb/library/actors/http/ut sole+chunk+chunk\n ydb/library/actors/interconnect/ut_huge_cluster HugeCluster.AllToAll\n-ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse test.py.test_select_datetime[datetime_string_NATIVE-dqrun]\n-ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse test.py.test_select_datetime[datetime_string_NATIVE-kqprun]\n ydb/library/yql/providers/generic/connector/tests/join test.py.test_join[join_ch_ch-dqrun]\n ydb/library/yql/tests/sql/hybrid_file/part1 test.py.test[in-in_noansi_join--Debug]\n ydb/public/sdk/cpp/client/ydb_persqueue_public/ut/with_offset_ranges_mode_ut [*/*] chunk chunk\n",
  "test_patch": "diff --git a/ydb/library/yql/providers/generic/connector/tests/common_test_cases/base.py b/ydb/library/yql/providers/generic/connector/tests/common_test_cases/base.py\nindex 9e224f30b5ca..6292077391c4 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/common_test_cases/base.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/common_test_cases/base.py\n@@ -66,7 +66,7 @@ def table_name(self) -> str:\n         '''\n         match self.data_source_kind:\n             case EDataSourceKind.CLICKHOUSE:\n-                return 't' + make_random_string(8)\n+                return self.name_  # without protocol\n             case EDataSourceKind.MS_SQL_SERVER:\n                 return self.name\n             case EDataSourceKind.MYSQL:\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/common_test_cases/select_positive_common.py b/ydb/library/yql/providers/generic/connector/tests/common_test_cases/select_positive_common.py\nindex 7bfb35d0de2c..99da19b19aae 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/common_test_cases/select_positive_common.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/common_test_cases/select_positive_common.py\n@@ -18,6 +18,7 @@\n     DataSourceType,\n     SelectWhat,\n     SelectWhere,\n+    makeYdbTypeFromTypeID,\n )\n \n from ydb.library.yql.providers.generic.connector.tests.common_test_cases.base import BaseTestCase\n@@ -246,46 +247,65 @@ def _large_table(self) -> Sequence[TestCase]:\n         schema = Schema(\n             columns=ColumnList(\n                 Column(\n-                    name='col_01_int64',\n-                    ydb_type=Type.INT64,\n-                    data_source_type=DataSourceType(ch=clickhouse.Int32(), pg=postgresql.Int8()),\n+                    name='col_00_int32',\n+                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),\n+                    data_source_type=DataSourceType(ch=clickhouse.Int64(), pg=postgresql.Int8()),\n                 ),\n                 Column(\n-                    name='col_02_utf8',\n-                    ydb_type=Type.UTF8,\n+                    name='col_01_string',\n+                    ydb_type=makeYdbTypeFromTypeID(Type.STRING),\n                     data_source_type=DataSourceType(ch=clickhouse.String(), pg=postgresql.Text()),\n                 ),\n             )\n         )\n \n-        data_in = generate_table_data(schema=schema, bytes_soft_limit=table_size)\n-\n-        # Assuming that request will look something like:\n-        #\n-        # SELECT * FROM table WHERE id = (SELECT MAX(id) FROM table)\n-        #\n-        # We expect last line to be the answer\n-        data_out = [data_in[-1]]\n-\n-        data_source_kinds = [EDataSourceKind.CLICKHOUSE, EDataSourceKind.POSTGRESQL]\n-\n-        test_case_name = 'large_table'\n+        data_source_kinds = (\n+            EDataSourceKind.CLICKHOUSE,\n+            EDataSourceKind.POSTGRESQL,\n+        )\n \n+        test_case_name = 'large'\n         test_cases = []\n+\n         for data_source_kind in data_source_kinds:\n-            tc = TestCase(\n-                name_=test_case_name,\n-                data_source_kind=data_source_kind,\n-                protocol=EProtocol.NATIVE,\n-                data_in=data_in,\n-                data_out_=data_out,\n-                select_what=SelectWhat.asterisk(schema.columns),\n-                select_where=SelectWhere(\n-                    expression_='col_01_int64 IN (SELECT MAX(col_01_int64) FROM {cluster_name}.{table_name})'\n-                ),\n-                schema=schema,\n-                pragmas=dict(),\n-            )\n+            match data_source_kind:\n+                case EDataSourceKind.CLICKHOUSE:\n+                    tc = TestCase(\n+                        name_=test_case_name,\n+                        data_source_kind=data_source_kind,\n+                        protocol=EProtocol.NATIVE,\n+                        data_in=None,\n+                        data_out_=[[999999]],  # We put 1M of rows in the large table\n+                        select_what=SelectWhat(SelectWhat.Item(name='MAX(col_00_int32)', kind='expr')),\n+                        select_where=None,\n+                        schema=schema,\n+                        pragmas=dict(),\n+                    )\n+\n+                case EDataSourceKind.POSTGRESQL:\n+                    # Assuming that request will look something like:\n+                    # `SELECT * FROM table WHERE id = (SELECT MAX(id) FROM table)`\n+                    # We expect last line to be the answer\n+                    data_in = generate_table_data(schema=schema, bytes_soft_limit=table_size)\n+                    data_out = [data_in[-1]]\n+                    data_source_kinds = [EDataSourceKind.CLICKHOUSE, EDataSourceKind.POSTGRESQL]\n+\n+                    tc = TestCase(\n+                        name_=test_case_name,\n+                        data_source_kind=data_source_kind,\n+                        protocol=EProtocol.NATIVE,\n+                        data_in=data_in,\n+                        data_out_=data_out,\n+                        select_what=SelectWhat.asterisk(schema.columns),\n+                        select_where=SelectWhere(\n+                            expression_='col_00_int32 IN (SELECT MAX(col_00_int32) FROM {cluster_name}.{table_name})'\n+                        ),\n+                        schema=schema,\n+                        pragmas=dict(),\n+                    )\n+\n+                case _:\n+                    raise ValueError(f'Unknown data source kind: {data_source_kind}')\n \n             test_cases.append(tc)\n \ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/conftest.py b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/conftest.py\nindex 6f31ef8d80cd..b2869f8d1f5f 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/conftest.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/conftest.py\n@@ -5,7 +5,6 @@\n \n from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n-from ydb.library.yql.providers.generic.connector.tests.utils.clients.clickhouse import Client, make_client\n \n docker_compose_dir: Final = pathlib.Path(\"ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse\")\n \n@@ -13,10 +12,3 @@\n @pytest.fixture\n def settings() -> Settings:\n     return Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.CLICKHOUSE])\n-\n-\n-@pytest.fixture\n-def clickhouse_client(settings) -> Client:\n-    cl = make_client(settings.clickhouse)\n-    yield cl\n-    cl.close()\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/docker-compose.yml b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/docker-compose.yml\nindex cfc34aa8fbd8..5d8a46469ae2 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/docker-compose.yml\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/docker-compose.yml\n@@ -6,19 +6,18 @@ services:\n       CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1\n       CLICKHOUSE_PASSWORD: password\n       CLICKHOUSE_USER: user\n-    image: mirror.gcr.io/clickhouse/clickhouse-server:23-alpine@sha256:d75017307e76d1bca81a5ac7ada94620567782c0610541f525d1e443e23f76e3\n+      CLICKHOUSE_ALWAYS_RUN_INITDB_SCRIPTS: 1\n+    image: mirror.gcr.io/clickhouse/clickhouse-server:24.3.12-alpine@sha256:65e5846a0d9672714f2625502b27846563f6d01ec226304cf851aa49004ffde8\n+    volumes:\n+      - ./init:/docker-entrypoint-initdb.d\n     ports:\n-      - 9000\n-      - 8123\n-    tmpfs:\n-      - /run\n-      - /tmp\n-      - /var\n+    - 9000\n+    - 8123\n   fq-connector-go:\n     container_name: fq-tests-ch-fq-connector-go\n     image: ghcr.io/ydb-platform/fq-connector-go:v0.5.11-rc.5@sha256:c17f67aea314366690545aea1db9f2bf4391ae1269044ebbac7ea2316972e7ff\n     ports:\n-      - 2130\n+    - 2130\n     volumes:\n-      - ../../fq-connector-go/:/opt/ydb/cfg/\n+    - ../../fq-connector-go/:/opt/ydb/cfg/\n version: \"3.4\"\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/init/init_db.sh b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/init/init_db.sh\nnew file mode 100644\nindex 000000000000..3b16991b246e\n--- /dev/null\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/init/init_db.sh\n@@ -0,0 +1,217 @@\n+#!/bin/bash\n+set -ex\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.primitive_types_non_nullable;\n+    CREATE TABLE db.primitive_types_non_nullable (\n+        col_00_id Int32,\n+        col_01_boolean Boolean,\n+        col_02_int8 Int8,\n+        col_03_uint8 UInt8,\n+        col_04_int16 Int16,\n+        col_05_uint16 UInt16,\n+        col_06_int32 Int32,\n+        col_07_uint32 UInt32,\n+        col_08_int64 Int64,\n+        col_09_uint64 UInt64,\n+        col_10_float32 Float32,\n+        col_11_float64 Float64,\n+        col_12_string String,\n+        col_13_fixed_string FixedString(13),\n+        col_14_date Date,\n+        col_15_date32 Date32,\n+        col_16_datetime DateTime,\n+        col_17_datetime64 DateTime64(3)\n+    ) ENGINE = MergeTree ORDER BY col_00_id;\n+    INSERT INTO db.primitive_types_non_nullable (*) VALUES\n+        (1, False, 2, 3, 4, 5, 6, 7, 8, 9, 10.10, 11.11, 'az', 'az', '1988-11-20', '1988-11-20', '1988-11-20 12:55:28', '1988-11-20 12:55:28.123') \\\n+        (2, True, -2, 3, -4, 5, -6, 7, -8, 9, -10.10, -11.11, '\u0431\u0443\u043a\u0438', '\u0431\u0443\u043a\u0438', '2023-03-21', '2023-03-21', '2023-03-21 11:21:31', '2023-03-21 11:21:31.456');\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.primitive_types_nullable;\n+    CREATE TABLE db.primitive_types_nullable (\n+        col_00_id Int32,\n+        col_01_boolean Nullable(Boolean),\n+        col_02_int8 Nullable(Int8),\n+        col_03_uint8 Nullable(UInt8),\n+        col_04_int16 Nullable(Int16),\n+        col_05_uint16 Nullable(UInt16),\n+        col_06_int32 Nullable(Int32),\n+        col_07_uint32 Nullable(UInt32),\n+        col_08_int64 Nullable(Int64),\n+        col_09_uint64 Nullable(UInt64),\n+        col_10_float32 Nullable(Float32),\n+        col_11_float64 Nullable(Float64),\n+        col_12_string Nullable(String),\n+        col_13_fixed_string Nullable(FixedString(13)),\n+        col_14_date Nullable(Date),\n+        col_15_date32 Nullable(Date32),\n+        col_16_datetime Nullable(DateTime('UTC')),\n+        col_17_datetime64 Nullable(DateTime64(6, 'UTC'))\n+    ) ENGINE = MergeTree ORDER BY col_00_id;\n+    INSERT INTO db.primitive_types_nullable (*) VALUES\n+        (1, False, 2, 3, 4, 5, 6, 7, 8, 9, 10.10, 11.11, 'az', 'az', '1988-11-20', '1988-11-20', '1988-11-20 12:55:28', '1988-11-20 12:55:28.123') \\\n+        (2, NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL) \\\n+        (3, True, -2, 3, -4, 5, -6, 7, -8, 9, -10.10, -11.11, '\u0431\u0443\u043a\u0438', '\u0431\u0443\u043a\u0438', '2023-03-21', '2023-03-21', '2023-03-21 11:21:31', '2023-03-21 11:21:31.456');\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.datetime_string;\n+    CREATE TABLE db.datetime_string (\n+        col_00_id Int32,\n+        col_01_date Date,\n+        col_02_date32 Date32,\n+        col_03_datetime DateTime,\n+        col_04_datetime64 DateTime64(8)\n+    ) ENGINE = MergeTree ORDER BY col_00_id;\n+/*\n+    Value is too early for both CH and YQL\n+    In this case ClickHouse behaviour is undefined\n+    For Datetime Clickhouse returns bottom bound and\n+    cuts off only date part of value along ClickHouse bottom bound for other types\n+*/\n+    INSERT INTO db.datetime_string (*) VALUES\n+        (1, '1950-01-10', '1850-01-10', '1950-01-10 12:23:45', '1950-01-10 12:23:45.678910');\n+\n+    /* Value is OK for CH, but can be too early for YQL */\n+    INSERT INTO db.datetime_string (*) VALUES\n+        (2, '1970-01-10', '1950-01-10', '1980-01-10 12:23:45', '1950-01-10 12:23:45.678910');\n+\n+    /* Value is OK for both CH and YQL */\n+    INSERT INTO db.datetime_string (*) VALUES\n+        (3, '2004-01-10', '2004-01-10', '2004-01-10 12:23:45', '2004-01-10 12:23:45.678910');\n+\n+    /* Value is OK for CH, but too late for YQL */\n+    INSERT INTO db.datetime_string (*) VALUES\n+        (4, '2110-01-10', '2110-01-10', '2106-01-10 12:23:45', '2110-01-10 12:23:45.678910');\n+       \n+    /*\n+    Value is too late for both YQL and CH.\n+    In this case ClickHouse behaviour is undefined.\n+    */\n+    INSERT INTO db.datetime_string (*) VALUES\n+        (5, '2150-01-10', '2300-01-10', '2107-01-10 12:23:45', '2300-01-10 12:23:45.678910');\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.datetime_YQL;\n+    CREATE TABLE db.datetime_YQL (\n+        col_00_id Int32,\n+        col_01_date Date,\n+        col_02_date32 Date32,\n+        col_03_datetime DateTime,\n+        col_04_datetime64 DateTime64(8)\n+    ) ENGINE = MergeTree ORDER BY col_00_id;\n+    INSERT INTO db.datetime_YQL (*) VALUES\n+        (1, '1950-01-10', '1850-01-10', '1950-01-10 12:23:45', '1950-01-10 12:23:45.678910') \\\n+        (2, '1970-01-10', '1950-01-10', '1980-01-10 12:23:45', '1950-01-10 12:23:45.678910') \\\n+        (3, '2004-01-10', '2004-01-10', '2004-01-10 12:23:45', '2004-01-10 12:23:45.678910') \\\n+        (4, '2110-01-10', '2110-01-10', '2106-01-10 12:23:45', '2110-01-10 12:23:45.678910') \\\n+        (5, '2150-01-10', '2300-01-10', '2107-01-10 12:23:45', '2300-01-10 12:23:45.678910');\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.constant;\n+    CREATE TABLE db.constant (\n+        id Int32,\n+    ) ENGINE = MergeTree ORDER BY id;\n+    INSERT INTO db.constant (*) VALUES\n+        (1) \\\n+        (2) \\\n+        (3);\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.counts;\n+    CREATE TABLE db.counts (\n+        col Float64,\n+    ) ENGINE = MergeTree ORDER BY col;\n+    INSERT INTO db.counts (*) VALUES\n+        (3.14) \\\n+        (1.0) \\\n+        (2.718) \\\n+        (-0.0);\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.pushdown;\n+    CREATE TABLE db.pushdown (\n+        col_00_int32 Int32,\n+        col_01_string Nullable(String)\n+    ) ENGINE = MergeTree ORDER BY col_00_int32;\n+    INSERT INTO db.pushdown (*) VALUES\n+        (1, 'one') \\\n+        (2, 'two') \\\n+        (3, 'three') \\\n+        (4, NULL);\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.large;\n+    CREATE TABLE db.large (\n+        col_00_int32 Int32,\n+        col_01_string Nullable(String)\n+    ) ENGINE = MergeTree ORDER BY col_00_int32;\n+\n+    INSERT INTO db.large\n+    SELECT\n+        number AS col_00_int32,\n+        substring(randomPrintableASCII(32), 1, 32) AS col_01_string\n+    FROM\n+        numbers(1000000);\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.column_selection_A_b_C_d_E;\n+    CREATE TABLE db.column_selection_A_b_C_d_E (COL1 Int32, col2 Int32) \n+        ENGINE = MergeTree ORDER BY COL1;\n+    INSERT INTO db.column_selection_A_b_C_d_E (*) VALUES\n+        (1, 2) \\\n+        (10, 20);\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.column_selection_COL1;\n+    CREATE TABLE db.column_selection_COL1 (COL1 Int32, col2 Int32) \n+        ENGINE = MergeTree ORDER BY COL1;\n+    INSERT INTO db.column_selection_COL1 (*) VALUES\n+        (1, 2) \\\n+        (10, 20);\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.column_selection_asterisk;\n+    CREATE TABLE db.column_selection_asterisk (COL1 Int32, col2 Int32) \n+        ENGINE = MergeTree ORDER BY COL1;\n+    INSERT INTO db.column_selection_asterisk (*) VALUES\n+        (1, 2) \\\n+        (10, 20);\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.column_selection_col2_COL1;\n+    CREATE TABLE db.column_selection_col2_COL1 (COL1 Int32, col2 Int32) \n+        ENGINE = MergeTree ORDER BY COL1;\n+    INSERT INTO db.column_selection_col2_COL1 (*) VALUES\n+        (1, 2) \\\n+        (10, 20);\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.column_selection_col2;\n+    CREATE TABLE db.column_selection_col2 (COL1 Int32, col2 Int32) \n+        ENGINE = MergeTree ORDER BY COL1;\n+    INSERT INTO db.column_selection_col2 (*) VALUES\n+        (1, 2) \\\n+        (10, 20);\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.column_selection_col3;\n+    CREATE TABLE db.column_selection_col3 (COL1 Int32, col2 Int32) \n+        ENGINE = MergeTree ORDER BY COL1;\n+    INSERT INTO db.column_selection_col3 (*) VALUES\n+        (1, 2) \\\n+        (10, 20);\n+EOSQL\n\\ No newline at end of file\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_datetime.py b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_datetime.py\nindex 95c390cf2507..1057054a4b92 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_datetime.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_datetime.py\n@@ -14,6 +14,8 @@\n     ColumnList,\n     DataSourceType,\n     SelectWhat,\n+    makeYdbTypeFromTypeID,\n+    makeOptionalYdbTypeFromTypeID,\n )\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import GenericSettings\n \n@@ -36,95 +38,47 @@ def generic_settings(self) -> GenericSettings:\n class Factory:\n     _name = 'datetime'\n \n-    def _make_test_yql_clickhouse(self) -> TestCase:\n+    '''\n+    ClickHouse values' bounds:\n+    Date                    [1970-01-01, 2149-06-06]\n+    Date32                  [1900-01-01, 2299-12-31]\n+    Datetime                [1970-01-01 00:00:00, 2106-02-07 06:28:15]\n+    Datetime64              [1900-01-01 00:00:00, 2299-12-31 23:59:59.99999999]\n+\n+    YQL datetime bounds:    [1970-01-01 00:00:00, 2106-01-01 00:00:00]\n+    '''\n+\n+    def _make_test_yql(self) -> TestCase:\n         schema = Schema(\n             columns=ColumnList(\n                 Column(\n-                    name='col_0_id',\n-                    ydb_type=Type.UINT8,\n-                    data_source_type=DataSourceType(ch=clickhouse.UInt8()),\n+                    name='col_00_id',\n+                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),\n+                    data_source_type=DataSourceType(ch=clickhouse.Int32()),\n                 ),\n                 Column(\n-                    name='col_1_date',\n-                    ydb_type=Type.DATE,\n+                    name='col_01_date',\n+                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),\n                     data_source_type=DataSourceType(ch=clickhouse.Date()),\n                 ),\n                 Column(\n-                    name='col_2_date32',\n-                    ydb_type=Type.DATE,\n+                    name='col_02_date32',\n+                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),\n                     data_source_type=DataSourceType(ch=clickhouse.Date32()),\n                 ),\n                 Column(\n-                    name='col_3_datetime',\n-                    ydb_type=Type.DATETIME,\n+                    name='col_03_datetime',\n+                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATETIME),\n                     data_source_type=DataSourceType(ch=clickhouse.DateTime()),\n                 ),\n                 Column(\n-                    name='col_4_datetime64',\n-                    ydb_type=Type.TIMESTAMP,\n+                    name='col_04_datetime64',\n+                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.TIMESTAMP),\n                     data_source_type=DataSourceType(ch=clickhouse.DateTime64()),\n                 ),\n             ),\n         )\n \n-        '''\n-        ClickHouse values' bounds:\n-        Date                    [1970-01-01, 2149-06-06]\n-        Date32                  [1900-01-01, 2299-12-31]\n-        Datetime                [1970-01-01 00:00:00, 2106-02-07 06:28:15]\n-        Datetime64              [1900-01-01 00:00:00, 2299-12-31 23:59:59.99999999]\n-\n-        YQL datetime bounds:    [1970-01-01 00:00:00, 2106-01-01 00:00:00]\n-        '''\n-\n-        data_in = [\n-            # Value is too early for both CH and YQL\n-            # In this case ClickHouse behaviour is undefined\n-            # Clickhouse cuts off only date part of value along ClickHouse bottom bound\n-            [\n-                1,\n-                '1950-01-10',\n-                '1850-01-10',\n-                '1950-01-10 12:23:45',\n-                '1850-01-10 12:23:45.678910',\n-            ],\n-            # Value is OK for CH, but can be too early for YQL\n-            [\n-                2,\n-                '1970-01-10',\n-                '1950-01-10',\n-                '1980-01-10 12:23:45',\n-                '1950-01-10 12:23:45.678910',\n-            ],\n-            # Value is OK for both CH and YQL\n-            [\n-                3,\n-                '2004-01-10',\n-                '2004-01-10',\n-                '2004-01-10 12:23:45',\n-                '2004-01-10 12:23:45.678910',\n-            ],\n-            # Value is OK for CH, but too late for YQL\n-            [\n-                4,\n-                '2110-01-10',\n-                '2110-01-10',\n-                '2106-01-10 12:23:45',\n-                '2110-01-10 12:23:45.678910',\n-            ],\n-            # Value is too late for both OK for CH\n-            # In this case ClickHouse behaviour is undefined\n-            # \"Natural\" overflow for Datetime\n-            # Cutting off along ClickHouse top bound for other types\n-            [\n-                5,\n-                '2150-01-10',\n-                '2300-01-10',\n-                '2107-01-10 12:23:45',\n-                '2300-01-10 12:23:45.678910',\n-            ],\n-        ]\n-\n         data_out = [\n             [\n                 1,\n@@ -162,7 +116,7 @@ def _make_test_yql_clickhouse(self) -> TestCase:\n         return TestCase(\n             name_=test_case_name,\n             date_time_format=EDateTimeFormat.YQL_FORMAT,\n-            data_in=data_in,\n+            data_in=None,\n             data_out_=data_out,\n             select_what=SelectWhat.asterisk(schema.columns),\n             select_where=None,\n@@ -170,90 +124,42 @@ def _make_test_yql_clickhouse(self) -> TestCase:\n             protocol=EProtocol.NATIVE,\n             schema=schema,\n             pragmas=dict(),\n+            check_output_schema=True,\n         )\n \n-    def _make_test_string_clickhouse(self) -> TestCase:\n+    def _make_test_string(self) -> TestCase:\n         schema = Schema(\n             columns=ColumnList(\n                 Column(\n-                    name='col_0_id',\n-                    ydb_type=Type.UINT8,\n-                    data_source_type=DataSourceType(ch=clickhouse.UInt8()),\n+                    name='col_00_id',\n+                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),\n+                    data_source_type=DataSourceType(ch=clickhouse.Int32()),\n                 ),\n                 Column(\n-                    name='col_1_date',\n-                    ydb_type=Type.DATE,\n+                    name='col_01_date',\n+                    ydb_type=makeYdbTypeFromTypeID(Type.UTF8),\n                     data_source_type=DataSourceType(ch=clickhouse.Date()),\n                 ),\n                 Column(\n-                    name='col_2_date32',\n-                    ydb_type=Type.DATE,\n+                    name='col_02_date32',\n+                    ydb_type=makeYdbTypeFromTypeID(Type.UTF8),\n                     data_source_type=DataSourceType(ch=clickhouse.Date32()),\n                 ),\n                 Column(\n-                    name='col_3_datetime',\n-                    ydb_type=Type.DATETIME,\n+                    name='col_03_datetime',\n+                    ydb_type=makeYdbTypeFromTypeID(Type.UTF8),\n                     data_source_type=DataSourceType(ch=clickhouse.DateTime()),\n                 ),\n                 Column(\n-                    name='col_4_datetime64',\n-                    ydb_type=Type.TIMESTAMP,\n+                    name='col_04_datetime64',\n+                    ydb_type=makeYdbTypeFromTypeID(Type.UTF8),\n                     data_source_type=DataSourceType(ch=clickhouse.DateTime64()),\n                 ),\n             ),\n         )\n \n-        data_in = [\n-            # Value is too early for both CH and YQL\n-            # In this case ClickHouse behaviour is undefined\n-            # For Datetime Clickhouse returns bottom bound and\n-            # cuts off only date part of value along ClickHouse bottom bound for other types\n-            [\n-                1,\n-                '1950-01-10',\n-                '1850-01-10',\n-                '1950-01-10 12:23:45',\n-                '1850-01-10 12:23:45.678910',\n-            ],\n-            # Value is OK for CH, but can be too early for YQL\n-            [\n-                2,\n-                '1970-01-10',\n-                '1950-01-10',\n-                '1980-01-10 12:23:45',\n-                '1950-01-10 12:23:45.678910',\n-            ],\n-            # Value is OK for both CH and YQL\n-            [\n-                3,\n-                '2004-01-10',\n-                '2004-01-10',\n-                '2004-01-10 12:23:45',\n-                '2004-01-10 12:23:45.678910',\n-            ],\n-            # Value is OK for CH, but too late for YQL\n-            [\n-                4,\n-                '2110-01-10',\n-                '2110-01-10',\n-                '2106-01-10 12:23:45',\n-                '2110-01-10 12:23:45.678910',\n-            ],\n-            # Value is too late for both OK for CH\n-            # In this case ClickHouse behaviour is undefined\n-            # \"Natural\" overflow for Datetime\n-            # Cutting off along ClickHouse top bound for other types\n-            [\n-                5,\n-                '2150-01-10',\n-                '2300-01-10',\n-                '2107-01-10 12:23:45',\n-                '2300-01-10 12:23:45.678910',\n-            ],\n-        ]\n-\n         data_out = [\n-            [1, '1970-01-01', '1900-01-01', '1970-01-01T00:00:00Z', '1900-01-01T12:23:45.67891Z'],\n+            [1, '1970-01-01', '1900-01-01', '1970-01-01T00:00:00Z', '1950-01-10T12:23:45.67891Z'],\n             [2, '1970-01-10', '1950-01-10', '1980-01-10T12:23:45Z', '1950-01-10T12:23:45.67891Z'],\n             [3, '2004-01-10', '2004-01-10', '2004-01-10T12:23:45Z', '2004-01-10T12:23:45.67891Z'],\n             [4, '2110-01-10', '2110-01-10', '2106-01-10T12:23:45Z', '2110-01-10T12:23:45.67891Z'],\n@@ -262,7 +168,7 @@ def _make_test_string_clickhouse(self) -> TestCase:\n                 '2149-06-06',\n                 '2299-12-31',\n                 '1970-12-04T05:55:29Z',\n-                '1900-01-01T00:00:00Z',  # TODO: strange overflow under bottom bound for datetime64\n+                '1900-01-01T00:00:00Z',  # strange overflow issue with DateTime64 in ClickHouse\n             ],\n         ]\n \n@@ -272,17 +178,18 @@ def _make_test_string_clickhouse(self) -> TestCase:\n             name_=test_case_name,\n             date_time_format=EDateTimeFormat.STRING_FORMAT,\n             protocol=EProtocol.NATIVE,\n-            data_in=data_in,\n+            data_in=None,\n             data_out_=data_out,\n             select_what=SelectWhat.asterisk(schema.columns),\n             select_where=None,\n             data_source_kind=EDataSourceKind.CLICKHOUSE,\n             schema=schema,\n             pragmas=dict(),\n+            check_output_schema=True,\n         )\n \n     def make_test_cases(self) -> Sequence[TestCase]:\n         return [\n-            self._make_test_yql_clickhouse(),\n-            self._make_test_string_clickhouse(),\n+            self._make_test_yql(),\n+            self._make_test_string(),\n         ]\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_positive.py b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_positive.py\nindex de6af3d7cc51..da75133e3432 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_positive.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_positive.py\n@@ -1,7 +1,7 @@\n import datetime\n import itertools\n from dataclasses import replace\n-from typing import Sequence\n+from typing import Sequence, Final\n \n from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind, EProtocol\n from ydb.public.api.protos.ydb_value_pb2 import Type\n@@ -23,106 +23,113 @@\n \n \n class Factory:\n-    def _primitive_types(self) -> Sequence[TestCase]:\n-        schema = Schema(\n-            columns=ColumnList(\n-                Column(\n-                    name='col_01_boolean',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.BOOL),\n-                    data_source_type=DataSourceType(ch=clickhouse.Boolean()),\n-                ),\n-                Column(\n-                    name='col_02_int8',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.INT8),\n-                    data_source_type=DataSourceType(ch=clickhouse.Int8()),\n-                ),\n-                Column(\n-                    name='col_03_uint8',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.UINT8),\n-                    data_source_type=DataSourceType(ch=clickhouse.UInt8()),\n-                ),\n-                Column(\n-                    name='col_04_int16',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.INT16),\n-                    data_source_type=DataSourceType(ch=clickhouse.Int16()),\n-                ),\n-                Column(\n-                    name='col_05_uint16',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.UINT16),\n-                    data_source_type=DataSourceType(ch=clickhouse.UInt16()),\n-                ),\n-                Column(\n-                    name='col_06_int32',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),\n-                    data_source_type=DataSourceType(ch=clickhouse.Int32()),\n-                ),\n-                Column(\n-                    name='col_07_uint32',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.UINT32),\n-                    data_source_type=DataSourceType(ch=clickhouse.UInt32()),\n-                ),\n-                Column(\n-                    name='col_08_int64',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.INT64),\n-                    data_source_type=DataSourceType(ch=clickhouse.Int64()),\n-                ),\n-                Column(\n-                    name='col_09_uint64',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.UINT64),\n-                    data_source_type=DataSourceType(ch=clickhouse.UInt64()),\n-                ),\n-                Column(\n-                    name='col_10_float32',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.FLOAT),\n-                    data_source_type=DataSourceType(ch=clickhouse.Float32()),\n-                ),\n-                Column(\n-                    name='col_11_float64',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.DOUBLE),\n-                    data_source_type=DataSourceType(ch=clickhouse.Float64()),\n-                ),\n-                Column(\n-                    name='col_12_string',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.STRING),\n-                    data_source_type=DataSourceType(ch=clickhouse.String()),\n-                ),\n-                Column(\n-                    name='col_13_fixed_string',\n-                    ydb_type=makeYdbTypeFromTypeID(Type.STRING),\n-                    data_source_type=DataSourceType(ch=clickhouse.FixedString()),\n-                ),\n-                Column(\n-                    name='col_14_date',\n-                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),\n-                    data_source_type=DataSourceType(ch=clickhouse.Date()),\n-                ),\n-                Column(\n-                    name='col_15_date32',\n-                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),\n-                    data_source_type=DataSourceType(ch=clickhouse.Date32()),\n-                ),\n-                Column(\n-                    name='col_16_datetime',\n-                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATETIME),\n-                    data_source_type=DataSourceType(ch=clickhouse.DateTime()),\n-                ),\n-                Column(\n-                    name='col_17_datetime64',\n-                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.TIMESTAMP),\n-                    data_source_type=DataSourceType(ch=clickhouse.DateTime64()),\n-                ),\n+    __primitive_types_schema: Final = Schema(\n+        columns=ColumnList(\n+            Column(\n+                name='col_00_id',\n+                ydb_type=makeYdbTypeFromTypeID(Type.INT32),\n+                data_source_type=DataSourceType(ch=clickhouse.Int32()),\n             ),\n-        )\n+            Column(\n+                name='col_01_boolean',\n+                ydb_type=makeYdbTypeFromTypeID(Type.BOOL),\n+                data_source_type=DataSourceType(ch=clickhouse.Boolean()),\n+            ),\n+            Column(\n+                name='col_02_int8',\n+                ydb_type=makeYdbTypeFromTypeID(Type.INT8),\n+                data_source_type=DataSourceType(ch=clickhouse.Int8()),\n+            ),\n+            Column(\n+                name='col_03_uint8',\n+                ydb_type=makeYdbTypeFromTypeID(Type.UINT8),\n+                data_source_type=DataSourceType(ch=clickhouse.UInt8()),\n+            ),\n+            Column(\n+                name='col_04_int16',\n+                ydb_type=makeYdbTypeFromTypeID(Type.INT16),\n+                data_source_type=DataSourceType(ch=clickhouse.Int16()),\n+            ),\n+            Column(\n+                name='col_05_uint16',\n+                ydb_type=makeYdbTypeFromTypeID(Type.UINT16),\n+                data_source_type=DataSourceType(ch=clickhouse.UInt16()),\n+            ),\n+            Column(\n+                name='col_06_int32',\n+                ydb_type=makeYdbTypeFromTypeID(Type.INT32),\n+                data_source_type=DataSourceType(ch=clickhouse.Int32()),\n+            ),\n+            Column(\n+                name='col_07_uint32',\n+                ydb_type=makeYdbTypeFromTypeID(Type.UINT32),\n+                data_source_type=DataSourceType(ch=clickhouse.UInt32()),\n+            ),\n+            Column(\n+                name='col_08_int64',\n+                ydb_type=makeYdbTypeFromTypeID(Type.INT64),\n+                data_source_type=DataSourceType(ch=clickhouse.Int64()),\n+            ),\n+            Column(\n+                name='col_09_uint64',\n+                ydb_type=makeYdbTypeFromTypeID(Type.UINT64),\n+                data_source_type=DataSourceType(ch=clickhouse.UInt64()),\n+            ),\n+            Column(\n+                name='col_10_float32',\n+                ydb_type=makeYdbTypeFromTypeID(Type.FLOAT),\n+                data_source_type=DataSourceType(ch=clickhouse.Float32()),\n+            ),\n+            Column(\n+                name='col_11_float64',\n+                ydb_type=makeYdbTypeFromTypeID(Type.DOUBLE),\n+                data_source_type=DataSourceType(ch=clickhouse.Float64()),\n+            ),\n+            Column(\n+                name='col_12_string',\n+                ydb_type=makeYdbTypeFromTypeID(Type.STRING),\n+                data_source_type=DataSourceType(ch=clickhouse.String()),\n+            ),\n+            Column(\n+                name='col_13_fixed_string',\n+                ydb_type=makeYdbTypeFromTypeID(Type.STRING),\n+                data_source_type=DataSourceType(ch=clickhouse.FixedString()),\n+            ),\n+            Column(\n+                name='col_14_date',\n+                ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),\n+                data_source_type=DataSourceType(ch=clickhouse.Date()),\n+            ),\n+            Column(\n+                name='col_15_date32',\n+                ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),\n+                data_source_type=DataSourceType(ch=clickhouse.Date32()),\n+            ),\n+            Column(\n+                name='col_16_datetime',\n+                ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATETIME),\n+                data_source_type=DataSourceType(ch=clickhouse.DateTime()),\n+            ),\n+            Column(\n+                name='col_17_datetime64',\n+                ydb_type=makeOptionalYdbTypeFromTypeID(Type.TIMESTAMP),\n+                data_source_type=DataSourceType(ch=clickhouse.DateTime64()),\n+            ),\n+        ),\n+    )\n \n-        test_case_name = 'primitive_types'\n+    def _primitive_types_non_nullable(self) -> Sequence[TestCase]:\n+        schema = self.__primitive_types_schema\n \n         tc = TestCase(\n-            name_=test_case_name,\n+            name_='primitive_types_non_nullable',\n             schema=schema,\n             select_what=SelectWhat.asterisk(schema.columns),\n             select_where=None,\n-            data_in=[\n+            data_in=None,\n+            data_out_=[\n                 [\n+                    1,\n                     False,\n                     2,\n                     3,\n@@ -135,13 +142,14 @@ def _primitive_types(self) -> Sequence[TestCase]:\n                     10.10,\n                     11.11,\n                     'az',\n-                    'az   ',\n-                    '2023-01-09',\n-                    '2023-01-09',\n-                    '2023-01-09 13:19:11',\n-                    '2023-01-09 13:19:11.123456',\n+                    'az\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n+                    datetime.date(1988, 11, 20),\n+                    datetime.date(1988, 11, 20),\n+                    datetime.datetime(1988, 11, 20, 12, 55, 28),\n+                    datetime.datetime(1988, 11, 20, 12, 55, 28, 123000),\n                 ],\n                 [\n+                    2,\n                     True,\n                     -2,\n                     3,\n@@ -153,16 +161,57 @@ def _primitive_types(self) -> Sequence[TestCase]:\n                     9,\n                     -10.10,\n                     -11.11,\n-                    'buki',\n-                    'buki ',\n-                    '1988-11-20',\n-                    '1988-11-20',\n-                    '1988-11-20 12:00:00',\n-                    '1988-11-20 12:00:00.100000',\n+                    '\u0431\u0443\u043a\u0438',\n+                    '\u0431\u0443\u043a\u0438\\x00\\x00\\x00\\x00\\x00',\n+                    datetime.date(2023, 3, 21),\n+                    datetime.date(2023, 3, 21),\n+                    datetime.datetime(2023, 3, 21, 11, 21, 31),\n+                    datetime.datetime(2023, 3, 21, 11, 21, 31, 456000),\n                 ],\n             ],\n+            data_source_kind=EDataSourceKind.CLICKHOUSE,\n+            protocol=EProtocol.NATIVE,\n+            pragmas=dict(),\n+            check_output_schema=True,\n+        )\n+\n+        return [\n+            tc,\n+        ]\n+\n+    def _make_primitive_types_nullable_schema(self) -> Schema:\n+        schema = self.__primitive_types_schema\n+        schema_nullable = Schema(columns=ColumnList())\n+\n+        for i, col in enumerate(schema.columns):\n+            # do not convert first column to nullable as it contains primary key\n+            if i == 0:\n+                schema_nullable.columns.append(col)\n+                continue\n+\n+            ch_type = col.data_source_type.ch\n+            schema_nullable.columns.append(\n+                Column(\n+                    name=col.name,\n+                    ydb_type=makeOptionalYdbTypeFromYdbType(col.ydb_type),\n+                    data_source_type=DataSourceType(ch=ch_type.to_nullable()),\n+                )\n+            )\n+\n+        return schema_nullable\n+\n+    def _primitive_types_nullable(self) -> Sequence[TestCase]:\n+        schema = self._make_primitive_types_nullable_schema()\n+\n+        tc = TestCase(\n+            name_='primitive_types_nullable',\n+            schema=schema,\n+            select_what=SelectWhat.asterisk(schema.columns),\n+            select_where=None,\n+            data_in=None,\n             data_out_=[\n                 [\n+                    1,\n                     False,\n                     2,\n                     3,\n@@ -175,13 +224,34 @@ def _primitive_types(self) -> Sequence[TestCase]:\n                     10.10,\n                     11.11,\n                     'az',\n-                    'az   ',\n-                    datetime.date(2023, 1, 9),\n-                    datetime.date(2023, 1, 9),\n-                    datetime.datetime(2023, 1, 9, 13, 19, 11),\n-                    datetime.datetime(2023, 1, 9, 13, 19, 11, 123456),\n+                    'az\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n+                    datetime.date(1988, 11, 20),\n+                    datetime.date(1988, 11, 20),\n+                    datetime.datetime(1988, 11, 20, 12, 55, 28),\n+                    datetime.datetime(1988, 11, 20, 12, 55, 28, 123000),\n                 ],\n                 [\n+                    2,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                    None,\n+                ],\n+                [\n+                    3,\n                     True,\n                     -2,\n                     3,\n@@ -193,12 +263,12 @@ def _primitive_types(self) -> Sequence[TestCase]:\n                     9,\n                     -10.10,\n                     -11.11,\n-                    'buki',\n-                    'buki ',\n-                    datetime.date(1988, 11, 20),\n-                    datetime.date(1988, 11, 20),\n-                    datetime.datetime(1988, 11, 20, 12, 00, 00),\n-                    datetime.datetime(1988, 11, 20, 12, 00, 00, 100000),\n+                    '\u0431\u0443\u043a\u0438',\n+                    '\u0431\u0443\u043a\u0438\\x00\\x00\\x00\\x00\\x00',\n+                    datetime.date(2023, 3, 21),\n+                    datetime.date(2023, 3, 21),\n+                    datetime.datetime(2023, 3, 21, 11, 21, 31),\n+                    datetime.datetime(2023, 3, 21, 11, 21, 31, 456000),\n                 ],\n             ],\n             data_source_kind=EDataSourceKind.CLICKHOUSE,\n@@ -207,50 +277,8 @@ def _primitive_types(self) -> Sequence[TestCase]:\n             check_output_schema=True,\n         )\n \n-        # ClickHouse returns different data if columns are Nullable\n-        schema_nullable = Schema(columns=ColumnList())\n-        data_in_nullable = [[]]\n-        data_out_nullable = [[]]\n-\n-        for i, col in enumerate(schema.columns):\n-            ch_type = col.data_source_type.ch\n-\n-            # copy type and example value to new TestCase\n-            schema_nullable.columns.append(\n-                Column(\n-                    name=col.name,\n-                    ydb_type=makeOptionalYdbTypeFromYdbType(col.ydb_type),\n-                    data_source_type=DataSourceType(ch=ch_type.to_nullable()),\n-                )\n-            )\n-            data_in_nullable[0].append(tc.data_in[0][i])\n-            data_out_nullable[0].append(tc.data_out_[0][i])\n-\n-        # Add row containing only NULL values\n-        data_in_nullable.append([None] * len(data_in_nullable[0]))\n-        data_out_nullable.append([None] * len(data_out_nullable[0]))\n-\n-        # for the sake of CH output sorting\n-        data_in_nullable[1][0] = data_out_nullable[1][0] = True\n-\n-        test_case_name_nullable = 'primitive_types_nullable'\n-\n-        tc_nullable = TestCase(\n-            name_=test_case_name_nullable,\n-            schema=schema_nullable,\n-            select_what=SelectWhat.asterisk(schema_nullable.columns),\n-            select_where=None,\n-            data_source_kind=EDataSourceKind.CLICKHOUSE,\n-            data_in=data_in_nullable,\n-            data_out_=data_out_nullable,\n-            protocol=EProtocol.NATIVE,\n-            pragmas=dict(),\n-            check_output_schema=True,\n-        )\n-\n         return [\n             tc,\n-            tc_nullable,\n         ]\n \n     def _constant(self) -> Sequence[TestCase]:\n@@ -261,9 +289,9 @@ def _constant(self) -> Sequence[TestCase]:\n         schema = Schema(\n             columns=ColumnList(\n                 Column(\n-                    name='col',\n-                    ydb_type=Type.INT64,\n-                    data_source_type=DataSourceType(ch=clickhouse.Int64()),\n+                    name='id',\n+                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),\n+                    data_source_type=DataSourceType(ch=clickhouse.Int32()),\n                 ),\n             )\n         )\n@@ -275,17 +303,7 @@ def _constant(self) -> Sequence[TestCase]:\n             schema=schema,\n             select_what=SelectWhat(SelectWhat.Item(name='42', kind='expr')),\n             select_where=None,\n-            data_in=[\n-                [\n-                    1,\n-                ],\n-                [\n-                    2,\n-                ],\n-                [\n-                    3,\n-                ],\n-            ],\n+            data_in=None,\n             data_out_=[\n                 [\n                     42,\n@@ -304,7 +322,7 @@ def _constant(self) -> Sequence[TestCase]:\n \n         return [tc]\n \n-    def _count(self) -> Sequence[TestCase]:\n+    def _counts(self) -> Sequence[TestCase]:\n         '''\n         In this test case set we check SELECT COUNT(*) from a ch table.\n         '''\n@@ -313,33 +331,20 @@ def _count(self) -> Sequence[TestCase]:\n             columns=ColumnList(\n                 Column(\n                     name='col',\n-                    ydb_type=Type.FLOAT,\n+                    ydb_type=makeYdbTypeFromTypeID(Type.FLOAT),\n                     data_source_type=DataSourceType(ch=clickhouse.Float64()),\n                 ),\n             )\n         )\n \n-        test_case_name = 'count'\n+        test_case_name = 'counts'\n \n         tc = TestCase(\n             name_=test_case_name,\n             schema=schema,\n             select_what=SelectWhat(SelectWhat.Item(name='COUNT(*)', kind='expr')),\n             select_where=None,\n-            data_in=[\n-                [\n-                    3.14,\n-                ],\n-                [\n-                    1.0,\n-                ],\n-                [\n-                    2.718,\n-                ],\n-                [\n-                    -0.0,\n-                ],\n-            ],\n+            data_in=None,\n             data_out_=[\n                 [\n                     4,\n@@ -348,6 +353,7 @@ def _count(self) -> Sequence[TestCase]:\n             protocol=EProtocol.NATIVE,\n             data_source_kind=EDataSourceKind.CLICKHOUSE,\n             pragmas=dict(),\n+            check_output_schema=False,  # because the aggregate's value has other type\n         )\n \n         return [tc]\n@@ -356,33 +362,18 @@ def _pushdown(self) -> TestCase:\n         schema = Schema(\n             columns=ColumnList(\n                 Column(\n-                    name='col_int32',\n-                    ydb_type=Type.INT32,\n+                    name='col_00_int32',\n+                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),\n                     data_source_type=DataSourceType(ch=clickhouse.Int32()),\n                 ),\n                 Column(\n-                    name='col_string',\n-                    ydb_type=Type.UTF8,\n+                    name='col_01_string',\n+                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.STRING),\n                     data_source_type=DataSourceType(ch=clickhouse.String()),\n                 ),\n             ),\n         )\n \n-        data_in = [\n-            [\n-                1,\n-                'one',\n-            ],\n-            [\n-                2,\n-                'two',\n-            ],\n-            [\n-                3,\n-                'three',\n-            ],\n-        ]\n-\n         data_out = [\n             ['one'],\n         ]\n@@ -393,14 +384,16 @@ def _pushdown(self) -> TestCase:\n         return [\n             TestCase(\n                 name_=test_case_name,\n-                data_in=data_in,\n+                data_in=None,\n                 data_out_=data_out,\n                 pragmas=dict({'generic.UsePredicatePushdown': 'true'}),\n-                select_what=SelectWhat(SelectWhat.Item(name='col_string')),\n-                select_where=SelectWhere('col_int32 = 1'),\n+                select_what=SelectWhat(SelectWhat.Item(name='col_01_string')),\n+                select_where=SelectWhere('col_00_int32 = 1'),\n                 data_source_kind=data_source_kind,\n                 protocol=EProtocol.NATIVE,\n                 schema=schema,\n+                # TODO: implement schema checkswhen selecting only one column\n+                check_output_schema=False,\n             )\n         ]\n \n@@ -409,9 +402,10 @@ def make_test_cases(self) -> Sequence[TestCase]:\n \n         base_test_cases = list(\n             itertools.chain(\n-                self._primitive_types(),\n+                self._primitive_types_non_nullable(),\n+                self._primitive_types_nullable(),\n                 self._constant(),\n-                self._count(),\n+                self._counts(),\n                 self._pushdown(),\n             )\n         )\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/test.py b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/test.py\nindex 91f0d5bde55e..ab690a43f2d7 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/test.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/test.py\n@@ -1,10 +1,10 @@\n import pytest\n \n from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n-from ydb.library.yql.providers.generic.connector.tests.utils.clients.clickhouse import Client\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n from ydb.library.yql.providers.generic.connector.tests.utils.run.runners import runner_types, configure_runner\n import ydb.library.yql.providers.generic.connector.tests.utils.scenario.clickhouse as scenario\n+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter\n \n from conftest import docker_compose_dir\n from collection import Collection\n@@ -13,6 +13,26 @@\n import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_missing_table as select_missing_table\n import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_positive_common as select_positive_common\n \n+one_time_waiter = OneTimeWaiter(\n+    data_source_kind=EDataSourceKind.CLICKHOUSE,\n+    docker_compose_file_path=str(docker_compose_dir / 'docker-compose.yml'),\n+    expected_tables=[\n+        \"column_selection_A_b_C_d_E\",\n+        \"column_selection_COL1\",\n+        \"column_selection_asterisk\",\n+        \"column_selection_col2\",\n+        \"column_selection_col2_COL1\",\n+        \"column_selection_col3\",\n+        \"constant\",\n+        \"counts\",\n+        \"datetime_YQL\",\n+        \"datetime_string\",\n+        \"large\",\n+        \"primitive_types_non_nullable\",\n+        \"primitive_types_nullable\",\n+        \"pushdown\",\n+    ],\n+)\n \n # Global collection of test cases dependent on environment\n tc_collection = Collection(\n@@ -23,18 +43,14 @@\n @pytest.mark.parametrize(\"runner_type\", runner_types)\n @pytest.mark.parametrize(\"test_case\", tc_collection.get('select_positive'), ids=tc_collection.ids('select_positive'))\n @pytest.mark.usefixtures(\"settings\")\n-@pytest.mark.usefixtures(\"clickhouse_client\")\n def test_select_positive(\n     request: pytest.FixtureRequest,\n     settings: Settings,\n     runner_type: str,\n-    clickhouse_client: Client,\n     test_case: select_positive_common.TestCase,\n ):\n     runner = configure_runner(runner_type=runner_type, settings=settings)\n-    scenario.select_positive(\n-        test_name=request.node.name, settings=settings, runner=runner, client=clickhouse_client, test_case=test_case\n-    )\n+    scenario.select_positive(test_name=request.node.name, settings=settings, runner=runner, test_case=test_case)\n \n \n @pytest.mark.parametrize(\"runner_type\", runner_types)\n@@ -49,7 +65,7 @@ def test_select_missing_database(\n     test_case: select_missing_database.TestCase,\n ):\n     runner = configure_runner(runner_type=runner_type, settings=settings)\n-    scenario.select_missing_database(\n+    scenario.select_missing_table(\n         settings=settings,\n         runner=runner,\n         test_case=test_case,\n@@ -62,12 +78,10 @@ def test_select_missing_database(\n     \"test_case\", tc_collection.get('select_missing_table'), ids=tc_collection.ids('select_missing_table')\n )\n @pytest.mark.usefixtures(\"settings\")\n-@pytest.mark.usefixtures(\"clickhouse_client\")\n def test_select_missing_table(\n     request: pytest.FixtureRequest,\n     settings: Settings,\n     runner_type: str,\n-    clickhouse_client: Client,\n     test_case: select_missing_table.TestCase,\n ):\n     runner = configure_runner(runner_type=runner_type, settings=settings)\n@@ -75,7 +89,6 @@ def test_select_missing_table(\n         test_name=request.node.name,\n         settings=settings,\n         runner=runner,\n-        client=clickhouse_client,\n         test_case=test_case,\n     )\n \n@@ -83,12 +96,10 @@ def test_select_missing_table(\n @pytest.mark.parametrize(\"runner_type\", runner_types)\n @pytest.mark.parametrize(\"test_case\", tc_collection.get('select_datetime'), ids=tc_collection.ids('select_datetime'))\n @pytest.mark.usefixtures(\"settings\")\n-@pytest.mark.usefixtures(\"clickhouse_client\")\n def test_select_datetime(\n     request: pytest.FixtureRequest,\n     settings: Settings,\n     runner_type: str,\n-    clickhouse_client: Client,\n     test_case: select_positive_common.TestCase,\n ):\n     runner = configure_runner(runner_type=runner_type, settings=settings)\n@@ -97,5 +108,4 @@ def test_select_datetime(\n         test_case=test_case,\n         settings=settings,\n         runner=runner,\n-        client=clickhouse_client,\n     )\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_datetime.py b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_datetime.py\nindex ae90599fca27..21db4ef79157 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_datetime.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_datetime.py\n@@ -80,7 +80,13 @@ def _make_test_yql(self) -> TestCase:\n                 datetime.datetime(2023, 3, 21, 11, 21, 31, 0),\n                 datetime.datetime(2023, 3, 21, 11, 21, 31, 0),\n             ],\n-            [3, None, None, None, None],\n+            [\n+                3,\n+                datetime.date(2079, 6, 6),\n+                datetime.datetime(2079, 6, 6, 23, 59),\n+                datetime.datetime(2079, 6, 7, 0, 0),\n+                None,\n+            ],\n         ]\n \n         return TestCase(\n@@ -112,7 +118,13 @@ def _make_test_string(self) -> TestCase:\n                 '2023-03-21T11:21:31Z',\n                 '2023-03-21T11:21:31Z',\n             ],\n-            [3, '2079-06-06', '2079-06-06T23:59:00Z', '2079-06-06T23:59:59.999Z', '2079-06-06T23:59:59.9999999Z'],\n+            [\n+                3,\n+                '2079-06-06',\n+                '2079-06-06T23:59:00Z',\n+                '2079-06-07T00:00:00Z',  # For a some reason server rounds it to the first second of the next day\n+                '9999-12-31T23:59:59.9999999Z',\n+            ],\n         ]\n \n         return TestCase(\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_positive.py b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_positive.py\nindex e179687b649f..ce729a234ab7 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_positive.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_positive.py\n@@ -197,10 +197,10 @@ def _primitive_types(self) -> Sequence[TestCase]:\n                     -5,\n                     -6.6,\n                     -7.7,\n-                    '\u0431\u0443\u043a\u0438',\n-                    '\u0431\u0443\u043a\u0438',\n-                    '\u0431\u0443\u043a\u0438',\n-                    '\u0431\u0443\u043a\u0438',\n+                    '????    ',\n+                    '????',\n+                    '????',\n+                    '\u0431\u0443\u043a\u0438    ',\n                     '\u0431\u0443\u043a\u0438',\n                     '\u0431\u0443\u043a\u0438',\n                     'b\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/test.py b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/test.py\nindex efaa5377a4e4..57ac2806b79b 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/test.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/test.py\n@@ -1,13 +1,7 @@\n-from typing import Set\n-from datetime import datetime\n-import time\n-\n import pytest\n \n-import yatest.common\n-\n from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n-from ydb.library.yql.providers.generic.connector.tests.utils.docker_compose import DockerComposeHelper\n+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter\n from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger\n from ydb.library.yql.providers.generic.connector.tests.utils.run.runners import runner_types, configure_runner\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n@@ -28,11 +22,10 @@\n     Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.MS_SQL_SERVER])\n )\n \n-\n-class OneTimeWaiter:\n-    __launched: bool = False\n-\n-    __expected_tables: Set[str] = {\n+one_time_waiter = OneTimeWaiter(\n+    data_source_kind=EDataSourceKind.MS_SQL_SERVER,\n+    docker_compose_file_path=str(docker_compose_dir / 'docker-compose.yml'),\n+    expected_tables=[\n         'column_selection_A_b_C_d_E',\n         'column_selection_col1',\n         'column_selection_asterisk',\n@@ -44,36 +37,8 @@ class OneTimeWaiter:\n         'count_rows',\n         'pushdown',\n         'datetimes',\n-    }\n-\n-    def __init__(self):\n-        docker_compose_file_relative_path = str(docker_compose_dir / 'docker-compose.yml')\n-        docker_compose_file_abs_path = yatest.common.source_path(docker_compose_file_relative_path)\n-        self.docker_compose_helper = DockerComposeHelper(docker_compose_yml_path=docker_compose_file_abs_path)\n-\n-    def wait(self):\n-        if self.__launched:\n-            return\n-\n-        start = datetime.now()\n-        actual_tables: Set[str] = None\n-        timeout = 600\n-\n-        while (datetime.now() - start).total_seconds() < timeout:\n-            try:\n-                actual_tables = set(self.docker_compose_helper.list_ms_sql_server_tables())\n-            except Exception as e:\n-                LOGGER.error(f\"list ms_sql_server tables error: {e}\")\n-                time.sleep(5)\n-            else:\n-                if self.__expected_tables.issubset(actual_tables):\n-                    self.__launched = True\n-                    return\n-\n-        raise RuntimeError(f\"No expected tables in ms_sql_server. Latest result: {actual_tables}\")\n-\n-\n-one_time_waiter = OneTimeWaiter()\n+    ],\n+)\n \n \n @pytest.mark.parametrize(\"runner_type\", runner_types)\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/select_datetime.py b/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/select_datetime.py\nindex 3b6c95cdd99e..8cad456b187a 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/select_datetime.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/select_datetime.py\n@@ -76,9 +76,9 @@ def _make_test_yql(self) -> TestCase:\n             # [3, '2038-01-19', '2038-01-19T03:14:07.000000Z', '2038-01-19T03:14:07.000009Z'],\n             [\n                 3,\n-                datetime.date(2038, 1, 18),\n-                datetime.datetime(2038, 1, 19, 3, 14, 7, 0),\n+                datetime.date(2038, 1, 19),\n                 datetime.datetime(2038, 1, 19, 3, 14, 7, 0),\n+                datetime.datetime(2038, 1, 19, 3, 14, 7, 9),\n             ],\n             [4, None, None, None],\n         ]\n@@ -107,10 +107,10 @@ def _make_test_string(self) -> TestCase:\n             [\n                 2,\n                 '1988-11-20',\n-                '1988-11-20T12:23:45.67891',\n-                '1988-11-20T12:23:45.67891Z',\n+                '1988-11-20T12:55:28.123',\n+                '1988-11-20T12:55:28.123Z',\n             ],\n-            [3, '2038-01-19', '2038-01-19T03:14:07.000000', '2038-01-19T03:14:07.000009Z'],\n+            [3, '2038-01-19', '2038-01-19T03:14:07', '2038-01-19T03:14:07.000009Z'],\n             [4, '9999-12-31', '9999-12-31T23:59:59.999999', None],\n         ]\n \ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/test.py b/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/test.py\nindex b1d192dc8aa2..78203acf53fe 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/test.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/test.py\n@@ -1,13 +1,7 @@\n-from typing import Set\n-from datetime import datetime\n-import time\n-\n import pytest\n \n-import yatest.common\n-\n from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n-from ydb.library.yql.providers.generic.connector.tests.utils.docker_compose import DockerComposeHelper\n+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter\n from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger\n from ydb.library.yql.providers.generic.connector.tests.utils.run.runners import runner_types, configure_runner\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n@@ -22,17 +16,10 @@\n \n LOGGER = make_logger(__name__)\n \n-\n-# Global collection of test cases dependent on environment\n-tc_collection = Collection(\n-    Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.MYSQL])\n-)\n-\n-\n-class OneTimeWaiter:\n-    __launched: bool = False\n-\n-    __expected_tables: Set[str] = {\n+one_time_waiter = OneTimeWaiter(\n+    data_source_kind=EDataSourceKind.MYSQL,\n+    docker_compose_file_path=str(docker_compose_dir / 'docker-compose.yml'),\n+    expected_tables=[\n         'column_selection_A_b_C_d_E',\n         'column_selection_COL1',\n         'column_selection_col1',\n@@ -47,36 +34,13 @@ class OneTimeWaiter:\n         'pushdown',\n         'json',\n         'datetimes',\n-    }\n-\n-    def __init__(self):\n-        docker_compose_file_relative_path = str(docker_compose_dir / 'docker-compose.yml')\n-        docker_compose_file_abs_path = yatest.common.source_path(docker_compose_file_relative_path)\n-        self.docker_compose_helper = DockerComposeHelper(docker_compose_yml_path=docker_compose_file_abs_path)\n-\n-    def wait(self):\n-        if self.__launched:\n-            return\n-\n-        start = datetime.now()\n-        actual_tables: Set[str] = None\n-        timeout = 600\n-\n-        while (datetime.now() - start).total_seconds() < timeout:\n-            try:\n-                actual_tables = set(self.docker_compose_helper.list_mysql_tables())\n-            except Exception as e:\n-                LOGGER.error(f\"list mysql tables error: {e}\")\n-                time.sleep(5)\n-            else:\n-                if self.__expected_tables.issubset(actual_tables):\n-                    self.__launched = True\n-                    return\n-\n-        raise RuntimeError(f\"No expected tables in MySQL. Latest result: {actual_tables}\")\n-\n+    ],\n+)\n \n-one_time_waiter = OneTimeWaiter()\n+# Global collection of test cases dependent on environment\n+tc_collection = Collection(\n+    Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.MYSQL])\n+)\n \n \n @pytest.mark.parametrize(\"runner_type\", runner_types)\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_datetime_with_service_name.py b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_datetime_with_service_name.py\nindex b3784d3e6efd..cf0cca4ec14f 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_datetime_with_service_name.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_datetime_with_service_name.py\n@@ -108,9 +108,9 @@ def _make_test_string(self) -> TestCase:\n             [\n                 2,\n                 '1988-11-20T12:55:28Z',\n-                '1988-11-20T12:55:28.123000Z',\n+                '1988-11-20T12:55:28.123Z',\n             ],\n-            [3, '2038-01-19T03:14:07Z', '2038-01-19T03:14:07.000000Z'],\n+            [3, '2038-01-19T03:14:07Z', '2038-01-19T03:14:07Z'],\n             [4, '9999-12-31T23:59:59Z', '9999-12-31T23:59:59.999999Z'],\n         ]\n \ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_positive_with_service_name.py b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_positive_with_service_name.py\nindex 0b8bbb22c83f..54b4a9be3383 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_positive_with_service_name.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_positive_with_service_name.py\n@@ -246,7 +246,7 @@ def _primitive_types(self) -> Sequence[TestCase]:\n                     datetime.datetime(1970, 1, 1, 0, 0, 0, 000000),\n                     datetime.datetime(1970, 1, 1, 1, 1, 1, 111111),\n                     datetime.datetime(1970, 1, 1, 2, 1, 1, 111111),\n-                    datetime.datetime(1970, 1, 1, 2, 2, 12, 111111),\n+                    datetime.datetime(1970, 1, 1, 2, 12, 1, 111111),\n                     '{ \"TODO\" : \"unicode\" }',\n                 ],\n             ],\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/test.py b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/test.py\nindex 2787be4cd138..8c57b8bce1a9 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/test.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/test.py\n@@ -1,13 +1,7 @@\n-from typing import Set\n-from datetime import datetime\n-import time\n-\n import pytest\n \n-import yatest.common\n-\n from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n-from ydb.library.yql.providers.generic.connector.tests.utils.docker_compose import DockerComposeHelper\n+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter\n from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger\n from ydb.library.yql.providers.generic.connector.tests.utils.run.runners import runner_types, configure_runner\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n@@ -29,11 +23,10 @@\n     Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.ORACLE])\n )\n \n-\n-class OneTimeWaiter:\n-    __launched: bool = False\n-\n-    __expected_tables: Set[str] = {\n+one_time_waiter = OneTimeWaiter(\n+    data_source_kind=EDataSourceKind.ORACLE,\n+    docker_compose_file_path=str(docker_compose_dir / 'docker-compose.yml'),\n+    expected_tables=[\n         'column_selection_A_b_C_d_E',\n         'column_selection_COL1',\n         'column_selection_col1',\n@@ -50,40 +43,8 @@ class OneTimeWaiter:\n         'DATETIMES',\n         'LONGRAW',\n         'LONG_TABLE',\n-    }\n-\n-    def __init__(self):\n-        docker_compose_file_relative_path = str(docker_compose_dir / 'docker-compose.yml')\n-        docker_compose_file_abs_path = yatest.common.source_path(docker_compose_file_relative_path)\n-        self.docker_compose_helper = DockerComposeHelper(docker_compose_yml_path=docker_compose_file_abs_path)\n-\n-    def wait(self):\n-        if self.__launched:\n-            return\n-\n-        start = datetime.now()\n-        actual_tables: Set[str] = None\n-        timeout = 600\n-\n-        while (datetime.now() - start).total_seconds() < timeout:\n-            try:\n-                actual_tables = set(self.docker_compose_helper.list_oracle_tables())\n-            except Exception as e:\n-                LOGGER.error(f\"list oracle tables error: {e}\")\n-                time.sleep(5)\n-            else:\n-                if self.__expected_tables.issubset(actual_tables):\n-                    self.__launched = True\n-                    return\n-\n-        raise RuntimeError(\n-            f\"No expected tables in Oracle. Latest result: {actual_tables},  \"\n-            + f\"extra tables loaded: {actual_tables - set(self.__expected_tables)}, \"\n-            + f\"did not found tables: {set(self.__expected_tables) - actual_tables}\"\n-        )\n-\n-\n-one_time_waiter = OneTimeWaiter()\n+    ],\n+)\n \n \n @pytest.mark.parametrize(\"runner_type\", runner_types)\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/ydb/test.py b/ydb/library/yql/providers/generic/connector/tests/datasource/ydb/test.py\nindex 4749559fdb82..f47c08a0e733 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/datasource/ydb/test.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/ydb/test.py\n@@ -3,6 +3,7 @@\n from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n from ydb.library.yql.providers.generic.connector.tests.utils.run.runners import runner_types, configure_runner\n+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter\n import ydb.library.yql.providers.generic.connector.tests.utils.scenario.ydb as scenario\n import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_positive_common as select_positive_common\n \n@@ -12,7 +13,8 @@\n from conftest import docker_compose_dir\n from collection import Collection\n \n-one_time_waiter = scenario.OneTimeWaiter(\n+one_time_waiter = OneTimeWaiter(\n+    data_source_kind=EDataSourceKind.YDB,\n     docker_compose_file_path=str(docker_compose_dir / 'docker-compose.yml'),\n     expected_tables=[\n         \"column_selection_A_b_C_d_E\",\n@@ -29,7 +31,7 @@\n         \"unsupported_types\",\n         \"json\",\n         \"dummy_table\",\n-    ]\n+    ],\n )\n \n settings = Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.YDB])\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/join/conftest.py b/ydb/library/yql/providers/generic/connector/tests/join/conftest.py\nindex 19caea7afe9f..a2d90087ea6e 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/join/conftest.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/join/conftest.py\n@@ -5,10 +5,6 @@\n import pytest\n \n from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n-from ydb.library.yql.providers.generic.connector.tests.utils.clients.clickhouse import (\n-    make_client as make_clickhouse_client,\n-    Client as ClickHouseClient,\n-)\n from ydb.library.yql.providers.generic.connector.tests.utils.clients.postgresql import Client as PostgreSQLClient\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n \n@@ -24,15 +20,14 @@ def settings() -> Settings:\n     )\n \n \n+# TODO: avoid using clients, initialize\n @dataclasses.dataclass\n class Clients:\n-    ClickHouse: ClickHouseClient\n     PostgreSQL: PostgreSQLClient\n \n \n @pytest.fixture\n def clients(settings):\n     return Clients(\n-        ClickHouse=make_clickhouse_client(settings=settings.clickhouse),\n         PostgreSQL=PostgreSQLClient(settings=settings.postgresql),\n     )\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/join/docker-compose.yml b/ydb/library/yql/providers/generic/connector/tests/join/docker-compose.yml\nindex 0759c852a759..25da5dd1dfd8 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/join/docker-compose.yml\n+++ b/ydb/library/yql/providers/generic/connector/tests/join/docker-compose.yml\n@@ -6,7 +6,10 @@ services:\n       CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1\n       CLICKHOUSE_PASSWORD: password\n       CLICKHOUSE_USER: user\n-    image: mirror.gcr.io/clickhouse/clickhouse-server:23-alpine@sha256:d75017307e76d1bca81a5ac7ada94620567782c0610541f525d1e443e23f76e3\n+      CLICKHOUSE_ALWAYS_RUN_INITDB_SCRIPTS: 1\n+    image: mirror.gcr.io/clickhouse/clickhouse-server:24.3.12-alpine@sha256:65e5846a0d9672714f2625502b27846563f6d01ec226304cf851aa49004ffde8\n+    volumes:\n+      - ./init/clickhouse:/docker-entrypoint-initdb.d\n     ports:\n       - 9000\n       - 8123\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/join/init/clickhouse/init_db.sh b/ydb/library/yql/providers/generic/connector/tests/join/init/clickhouse/init_db.sh\nnew file mode 100644\nindex 000000000000..4f0454966a39\n--- /dev/null\n+++ b/ydb/library/yql/providers/generic/connector/tests/join/init/clickhouse/init_db.sh\n@@ -0,0 +1,45 @@\n+#!/bin/bash\n+set -ex\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.example_1;\n+    CREATE TABLE db.example_1 (\n+        id Int32,\n+        col1 String,\n+        col2 Int32\n+    ) ENGINE = MergeTree ORDER BY id;\n+    INSERT INTO db.example_1 (*) VALUES\n+        (1, 'example_1_a', 10) \\\n+        (2, 'example_1_b', 20) \\\n+        (3, 'example_1_c', 30) \\\n+        (4, 'example_1_d', 40) \\\n+        (5, 'example_1_e', 50);\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.example_2;\n+    CREATE TABLE db.example_2 (\n+        id Int32,\n+        col2 Int32,\n+        col1 String\n+    ) ENGINE = MergeTree ORDER BY id;\n+    INSERT INTO db.example_2 (*) VALUES\n+        (1, 2, 'example_2_a') \\\n+        (2, 4, 'example_2_b') \\\n+        (3, 8, 'example_2_c') \\\n+        (4, 16, 'example_2_d') \\\n+        (5, 32, 'example_2_e');\n+EOSQL\n+\n+clickhouse-client -n <<-EOSQL\n+    DROP TABLE IF EXISTS db.test_1;\n+    CREATE TABLE db.test_1 (\n+        id Int32,\n+    ) ENGINE = MergeTree ORDER BY id;\n+    INSERT INTO db.test_1 (*) VALUES\n+        (1) \\\n+        (2) \\\n+        (3) \\\n+        (4) \\\n+        (5);\n+EOSQL\n\\ No newline at end of file\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/join/scenario.py b/ydb/library/yql/providers/generic/connector/tests/join/scenario.py\nindex 2b8941d1fcc2..156ceb8cabd6 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/join/scenario.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/join/scenario.py\n@@ -4,8 +4,6 @@\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n from ydb.library.yql.providers.generic.connector.tests.utils.run.parent import Runner\n \n-from ydb.library.yql.providers.generic.connector.tests.utils.clients.clickhouse import Client as ClickHouseClient\n-import ydb.library.yql.providers.generic.connector.tests.utils.scenario.clickhouse as clickhouse_scenario\n from ydb.library.yql.providers.generic.connector.tests.utils.clients.postgresql import Client as PostgreSQLClient\n import ydb.library.yql.providers.generic.connector.tests.utils.scenario.postgresql as postgresql_scenario\n \n@@ -19,21 +17,14 @@ def join(\n     test_case: TestCase,\n     settings: Settings,\n     runner: Runner,\n-    clickhouse_client: ClickHouseClient,\n     postgresql_client: PostgreSQLClient,\n ):\n     # prepare tables\n     for data_source in test_case.data_sources:\n         match data_source.kind:\n             case EDataSourceKind.CLICKHOUSE:\n-                clickhouse_scenario.prepare_table(\n-                    test_name=test_name,\n-                    client=clickhouse_client,\n-                    database=data_source.database,\n-                    table_name=data_source.table.name,\n-                    data_in=data_source.table.data_in,\n-                    schema=data_source.table.schema,\n-                )\n+                # do nothing as tables are initialized via init scripts\n+                continue\n             case EDataSourceKind.POSTGRESQL:\n                 postgresql_scenario.prepare_table(\n                     test_name=test_name,\n@@ -44,14 +35,14 @@ def join(\n                     schema=data_source.table.schema,\n                 )\n             case _:\n-                raise Exception(f'invalid data source: {test_case.data_source_kind}')\n+                raise Exception(f'invalid data source: {data_source.kind}')\n \n     # run join\n     yql_script = test_case.make_sql(settings)\n \n     result = runner.run(test_name=test_name, script=yql_script, generic_settings=test_case.generic_settings)\n \n-    assert result.returncode == 0, result.stderr\n+    assert result.returncode == 0, result.output\n \n     assert_data_outs_equal(test_case.data_out, result.data_out_with_types), (\n         test_case.data_out,\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/join/test.py b/ydb/library/yql/providers/generic/connector/tests/join/test.py\nindex 8af6b76f5a2a..7623c10922ff 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/join/test.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/join/test.py\n@@ -32,7 +32,6 @@ def test_join(\n     runner = configure_runner(runner_type=runner_type, settings=settings)\n     scenario.join(\n         test_name=request.node.name,\n-        clickhouse_client=clients.ClickHouse,\n         postgresql_client=clients.PostgreSQL,\n         runner=runner,\n         settings=settings,\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/join/test_case.py b/ydb/library/yql/providers/generic/connector/tests/join/test_case.py\nindex e10bad53372c..ca0d0a0474ed 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/join/test_case.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/join/test_case.py\n@@ -1,6 +1,6 @@\n import itertools\n from dataclasses import dataclass\n-from typing import Sequence\n+from typing import Sequence, Final\n \n from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind, EProtocol\n from ydb.library.yql.providers.generic.connector.api.service.protos.connector_pb2 import EDateTimeFormat\n@@ -119,7 +119,7 @@ def make_sql(self, settings: Settings) -> str:\n \n \n class Factory:\n-    _id_column: Column = Column(\n+    _id_column: Final = Column(\n         name='id',\n         ydb_type=Type.INT32,\n         data_source_type=DataSourceType(ch=clickhouse.Int32(), pg=postgresql.Serial()),\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/clients/clickhouse.py b/ydb/library/yql/providers/generic/connector/tests/utils/clients/clickhouse.py\ndeleted file mode 100644\nindex c23aa6f2cf9b..000000000000\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/clients/clickhouse.py\n+++ /dev/null\n@@ -1,32 +0,0 @@\n-from typing import TypeAlias\n-from datetime import datetime\n-import sys\n-import time\n-\n-import clickhouse_connect\n-from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n-\n-Client: TypeAlias = clickhouse_connect.driver.client.Client\n-\n-\n-def make_client(settings: Settings.ClickHouse) -> Client:\n-    start = datetime.now()\n-    attempt = 0\n-\n-    while (datetime.now() - start).total_seconds() < 60:\n-        attempt += 1\n-        try:\n-            client = clickhouse_connect.get_client(\n-                host=settings.host_external,\n-                port=settings.http_port_external,\n-                username=settings.username,\n-                password=settings.password,\n-            )\n-        except Exception as e:\n-            sys.stderr.write(f\"attempt #{attempt}: {e}\\n\")\n-            time.sleep(5)\n-            continue\n-\n-        return client\n-\n-    raise Exception(f\"Failed to connect ClickHouse in {attempt} attempt(s)\")\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/clients/ya.make b/ydb/library/yql/providers/generic/connector/tests/utils/clients/ya.make\nindex e70e7d084f2d..bfce2117a13c 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/clients/ya.make\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/clients/ya.make\n@@ -6,15 +6,11 @@ IF (AUTOCHECK)\n ENDIF()\n \n PY_SRCS(\n-    clickhouse.py\n     postgresql.py\n-    ydb.py\n )\n \n PEERDIR(\n-    contrib/python/clickhouse-connect\n     contrib/python/pg8000\n-    ydb/public/sdk/python\n     ydb/library/yql/providers/generic/connector/tests/utils\n )\n \ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/clients/ydb.py b/ydb/library/yql/providers/generic/connector/tests/utils/clients/ydb.py\ndeleted file mode 100644\nindex f4e2345789ed..000000000000\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/clients/ydb.py\n+++ /dev/null\n@@ -1,10 +0,0 @@\n-import ydb\n-from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n-\n-\n-def make_client(s: Settings.Ydb) -> ydb.Driver:\n-    endpoint = f\"grpc://{s.host_external}:{s.port_external}\"\n-\n-    driver = ydb.Driver(endpoint=endpoint, database=s.dbname, credentials=ydb.AnonymousCredentials())\n-    driver.wait(timeout=5)\n-    return driver\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/comparator.py b/ydb/library/yql/providers/generic/connector/tests/utils/comparator.py\nindex 56ccc85e6120..7a02fb2b5506 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/comparator.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/comparator.py\n@@ -21,6 +21,9 @@ def jsons_are_equal(lhs: str, rhs: str) -> bool:\n \n \n def assert_rows_equal(expected: List, actual: List):\n+    if not isinstance(expected, list) or not isinstance(actual, list):\n+        raise ValueError(f'Expected two lists, got {expected} and {actual}')\n+\n     assert len(expected) == len(actual), (\n         f'Columns amount mismatch expected: {len(expected)} actual: {len(actual)}',\n         expected,\n@@ -29,7 +32,7 @@ def assert_rows_equal(expected: List, actual: List):\n \n     for i in range(len(expected)):\n         if type(expected[i]) is float:\n-            assert isclose(expected[i], actual[i], abs_tol=1e-5), (expected[i], actual[i])\n+            assert isclose(expected[i], actual[i], abs_tol=1e-4), (expected[i], actual[i])\n             continue\n \n         if is_json(expected[i]):\n@@ -43,8 +46,9 @@ def assert_data_outs_equal(\n     expected: List,\n     actual: List,\n ):\n-    assert len(expected) == len(actual)\n-    all(map(assert_rows_equal, expected, actual))\n+    assert len(expected) == len(actual), (\"Row size mismatch\", expected, actual)\n+    for i in range(len(expected)):\n+        assert_rows_equal(expected[i], actual[i]), (f\"Error at row {i}\", expected[i], actual[i])\n \n \n def assert_schemas_equal(expected: Schema, actual: Schema):\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/database.py b/ydb/library/yql/providers/generic/connector/tests/utils/database.py\nindex 3a6a711b3c3b..82b2f50139a7 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/database.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/database.py\n@@ -16,7 +16,8 @@ def __init__(self, name: str, kind: EDataSourceKind.ValueType):\n                 # so we'd better make it first on our own\n                 self.name = name[:63].lower()\n             case EDataSourceKind.CLICKHOUSE:\n-                self.name = name[:255]\n+                # We use preinitialized database when working with ClickHouse.\n+                self.name = \"db\"\n             case EDataSourceKind.MS_SQL_SERVER:\n                 # For this kind of database this name is provided by the external logic\n                 self.name = name\n@@ -28,31 +29,32 @@ def __init__(self, name: str, kind: EDataSourceKind.ValueType):\n                 # therefore, we'd better use uppercase for ease of testing\n                 self.name = name[:127].upper()  # TODO: is it needed? max length of Oracle table name is 128 bytes/chars\n             case EDataSourceKind.YDB:\n-                # For this kind of database this name is provided by the external logic\n-                self.name = name\n+                # We use preinitialized database when working with YDB.\n+                self.name = \"local\"\n             case _:\n                 raise Exception(f'invalid data source: {self.kind}')\n \n-    def query_exists(self) -> str:\n+    def exists(self) -> str:\n         match self.kind:\n             case EDataSourceKind.POSTGRESQL:\n                 return f\"SELECT 1 FROM pg_database WHERE datname = '{self.name}'\"\n             case _:\n                 raise Exception(f'invalid data source: {self.kind}')\n \n-    def query_create(self) -> str:\n+    def create(self) -> str:\n         match self.kind:\n-            case EDataSourceKind.CLICKHOUSE:\n-                return f\"CREATE DATABASE IF NOT EXISTS {self.name} ENGINE = Memory\"\n             case EDataSourceKind.POSTGRESQL:\n                 return f\"CREATE DATABASE {self.name}\"\n             case _:\n                 raise Exception(f'invalid data source: {self.kind}')\n \n+    def sql_table_name(self, table_name: str) -> str:\n+        return table_name\n+\n     def missing_database_msg(self) -> str:\n         match self.kind:\n             case EDataSourceKind.CLICKHOUSE:\n-                return f\"Database {self.name} does not exist\"\n+                return f\"Database {self.name} doesn't exist\"\n             case EDataSourceKind.POSTGRESQL:\n                 return f'database \"{self.name}\" does not exist'\n             case EDataSourceKind.YDB:\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/docker_compose.py b/ydb/library/yql/providers/generic/connector/tests/utils/docker_compose.py\nindex 0a32a963178b..19d308744e20 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/docker_compose.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/docker_compose.py\n@@ -9,6 +9,7 @@\n \n import yatest.common\n \n+from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger\n \n LOGGER = make_logger(__name__)\n@@ -110,7 +111,22 @@ def get_internal_ip(self, service_name: str) -> str:\n     def get_container_name(self, service_name: str) -> str:\n         return self.docker_compose_yml_data['services'][service_name]['container_name']\n \n-    def list_ydb_tables(self) -> Sequence[str]:\n+    def list_tables(self, dataSourceKind: EDataSourceKind) -> Sequence[str]:\n+        match dataSourceKind:\n+            case EDataSourceKind.CLICKHOUSE:\n+                return self.list_clickhouse_tables()\n+            case EDataSourceKind.YDB:\n+                return self._list_ydb_tables()\n+            case EDataSourceKind.MYSQL:\n+                return self._list_mysql_tables()\n+            case EDataSourceKind.MS_SQL_SERVER:\n+                return self._list_ms_sql_server_tables()\n+            case EDataSourceKind.ORACLE:\n+                return self._list_oracle_tables()\n+            case _:\n+                raise ValueError(\"invalid data source kind: {dataSourceKind}\")\n+\n+    def _list_ydb_tables(self) -> Sequence[str]:\n         cmd = [\n             self.docker_bin_path,\n             'exec',\n@@ -158,7 +174,7 @@ def list_ydb_tables(self) -> Sequence[str]:\n \n         return result\n \n-    def list_mysql_tables(self) -> Sequence[str]:\n+    def _list_mysql_tables(self) -> Sequence[str]:\n         params = self.docker_compose_yml_data[\"services\"][\"mysql\"]\n         password = params[\"environment\"][\"MYSQL_ROOT_PASSWORD\"]\n         db = params[\"environment\"][\"MYSQL_DATABASE\"]\n@@ -180,11 +196,12 @@ def list_mysql_tables(self) -> Sequence[str]:\n         try:\n             out = subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode('utf8')\n         except subprocess.CalledProcessError as e:\n-            raise RuntimeError(f\"docker cmd failed: {e.output} (code {e.returncode})\")\n+            LOGGER.error(f\"docker cmd failed: {e.output} (code {e.returncode})\")\n+            return []\n         else:\n             return out.splitlines()[2:]\n \n-    def list_oracle_tables(self) -> Sequence[str]:\n+    def _list_oracle_tables(self) -> Sequence[str]:\n         params = self.docker_compose_yml_data[\"services\"][\"oracle\"]\n         password = params[\"environment\"][\"ORACLE_PWD\"]\n         username = params[\"environment\"][\"TEST_USER_NAME\"]  # also serves as default sceheme name for user\n@@ -199,12 +216,13 @@ def list_oracle_tables(self) -> Sequence[str]:\n         try:\n             out = subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode('utf8')\n         except subprocess.CalledProcessError as e:\n-            raise RuntimeError(f\"docker cmd failed: {e.output} (code {e.returncode})\")\n+            LOGGER.error(f\"docker cmd failed: {e.output} (code {e.returncode})\")\n+            return []\n         else:\n             lines = out.splitlines()\n             return lines[3 : len(lines) - 3]\n \n-    def list_ms_sql_server_tables(self) -> Sequence[str]:\n+    def _list_ms_sql_server_tables(self) -> Sequence[str]:\n         params = self.docker_compose_yml_data[\"services\"][\"ms_sql_server\"]\n         password = params[\"environment\"][\"SA_PASSWORD\"]\n         db = 'master'\n@@ -233,7 +251,35 @@ def list_ms_sql_server_tables(self) -> Sequence[str]:\n         try:\n             out = subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode('utf8')\n         except subprocess.CalledProcessError as e:\n-            raise RuntimeError(f\"docker cmd failed: {e.output} (code {e.returncode})\")\n+            LOGGER.error(f\"docker cmd failed: {e.output} (code {e.returncode})\")\n+            return []\n         else:\n             lines = [x.strip() for x in out.splitlines()]\n             return lines[3:]\n+\n+    def _list_clickhouse_server_tables(self) -> Sequence[str]:\n+        params = self.docker_compose_yml_data[\"services\"][\"clickhouse\"]\n+        db = 'db'\n+        cmd = [\n+            self.docker_bin_path,\n+            'exec',\n+            params[\"container_name\"],\n+            'clickhouse-client',\n+            '--database',\n+            db,\n+            '--query',\n+            \"SHOW TABLES;\",\n+        ]\n+\n+        LOGGER.debug(\"calling command: \" + \" \".join(cmd))\n+\n+        out = None\n+\n+        try:\n+            out = subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode('utf8')\n+        except subprocess.CalledProcessError as e:\n+            LOGGER.error(f\"docker cmd failed: {e.output} (code {e.returncode})\")\n+            return []\n+        else:\n+            lines = [x.strip() for x in out.splitlines()]\n+            return lines\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/generate.py b/ydb/library/yql/providers/generic/connector/tests/utils/generate.py\nindex 879c7f43140e..f5bed5b67486 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/generate.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/generate.py\n@@ -16,11 +16,11 @@ def generate_table_data(schema: Schema, bytes_soft_limit: int) -> Sequence[Seque\n         row = []\n \n         for col in schema.columns:\n-            match col.ydb_type:\n-                case Type.INT64:\n+            match col.ydb_type.type_id:\n+                case Type.INT32:\n                     row.append(ix)\n-                    actual_size += 8\n-                case Type.UTF8:\n+                    actual_size += 4\n+                case Type.STRING:\n                     value = hashlib.md5(str(ix).encode('ascii')).hexdigest()\n                     row.append(value)\n                     actual_size += len(value)\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/one_time_waiter.py b/ydb/library/yql/providers/generic/connector/tests/utils/one_time_waiter.py\nnew file mode 100644\nindex 000000000000..3659b095beca\n--- /dev/null\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/one_time_waiter.py\n@@ -0,0 +1,49 @@\n+from datetime import datetime\n+from typing import Sequence\n+import time\n+\n+import yatest.common\n+\n+from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n+from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger\n+from ydb.library.yql.providers.generic.connector.tests.utils.docker_compose import DockerComposeHelper\n+\n+LOGGER = make_logger(__name__)\n+\n+\n+class OneTimeWaiter:\n+    __launched: bool = False\n+\n+    def __init__(\n+        self,\n+        docker_compose_file_path: str,\n+        data_source_kind: EDataSourceKind,\n+        expected_tables: Sequence[str],\n+    ):\n+        docker_compose_file_abs_path = yatest.common.source_path(docker_compose_file_path)\n+        self.docker_compose_helper = DockerComposeHelper(docker_compose_yml_path=docker_compose_file_abs_path)\n+        self.expected_tables = set(expected_tables)\n+        self.data_source_kind = data_source_kind\n+\n+    def wait(self):\n+        if self.__launched:\n+            return\n+\n+        # This should be enough for tables to initialize\n+        start = datetime.now()\n+\n+        timeout = 600\n+        while (datetime.now() - start).total_seconds() < timeout:\n+            self.actual_tables = set(self.docker_compose_helper.list_tables(self.data_source_kind))\n+\n+            # check if all the required tables have been created\n+            if self.expected_tables <= self.actual_tables:\n+                self.__launched = True\n+                return\n+\n+            LOGGER.warning(f\"Not enough tables: expected={self.expected_tables}, actual={self.actual_tables}\")\n+            time.sleep(5)\n+\n+        raise ValueError(\n+            f\"Datasource failed to initialize in {timeout} seconds, latest table set: {self.actual_tables}\"\n+        )\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/clickhouse.py b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/clickhouse.py\nindex 0043c9f8bf8e..6495e024cd57 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/clickhouse.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/clickhouse.py\n@@ -1,16 +1,10 @@\n-from typing import Sequence\n-\n-import ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 as data_source_pb2\n-\n-import ydb.library.yql.providers.generic.connector.tests.utils.artifacts as artifacts\n-from ydb.library.yql.providers.generic.connector.tests.utils.comparator import assert_data_outs_equal\n-from ydb.library.yql.providers.generic.connector.tests.utils.database import Database\n-from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger, debug_with_limit\n-from ydb.library.yql.providers.generic.connector.tests.utils.schema import Schema\n+from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger\n+from ydb.library.yql.providers.generic.connector.tests.utils.comparator import (\n+    assert_data_outs_equal,\n+    assert_schemas_equal,\n+)\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n from ydb.library.yql.providers.generic.connector.tests.utils.run.parent import Runner\n-from ydb.library.yql.providers.generic.connector.tests.utils.sql import format_values_for_bulk_sql_insert\n-from ydb.library.yql.providers.generic.connector.tests.utils.clients.clickhouse import Client\n \n import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_missing_database as tc_select_missing_database\n import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_missing_table as tc_select_missing_table\n@@ -19,61 +13,12 @@\n LOGGER = make_logger(__name__)\n \n \n-def prepare_table(\n-    test_name: str,\n-    client: Client,\n-    database: Database,\n-    table_name: str,\n-    schema: Schema,\n-    data_in: Sequence,\n-):\n-    dbTable = f\"{database.name}.{table_name}\"\n-\n-    # create database\n-    create_database_stmt = database.query_create()\n-    LOGGER.debug(create_database_stmt)\n-    client.command(create_database_stmt)\n-\n-    # check if table exists\n-    check_table_stmt = f\"EXISTS TABLE {dbTable}\"\n-    LOGGER.debug(check_table_stmt)\n-    res = client.command(check_table_stmt)\n-    assert res in (0, 1), res\n-    if res == 1:\n-        # no need to create table\n-        return\n-\n-    # create table\n-    create_table_stmt = f\"CREATE TABLE {dbTable} ({schema.yql_column_list(data_source_pb2.CLICKHOUSE)}) ENGINE = Memory\"\n-    LOGGER.debug(create_table_stmt)\n-    client.command(create_table_stmt)\n-\n-    # write data\n-    values = format_values_for_bulk_sql_insert(data_in)\n-    insert_stmt = f\"INSERT INTO {dbTable} (*) VALUES {values}\"\n-    # NOTE: these statement may be too big when working with big tables,\n-    # so with truncate logs and put full statement into directory with artifacts\n-    debug_with_limit(LOGGER, insert_stmt)\n-    artifacts.dump_str(insert_stmt, test_name, 'insert.sql')\n-    client.command(insert_stmt)\n-\n-\n def select_positive(\n     test_name: str,\n     test_case: tc_select_positive_common.TestCase,\n     settings: Settings,\n     runner: Runner,\n-    client: Client,\n ):\n-    prepare_table(\n-        test_name=test_name,\n-        client=client,\n-        database=test_case.database,\n-        table_name=test_case.table_name,\n-        schema=test_case.schema,\n-        data_in=test_case.data_in,\n-    )\n-\n     where_statement = \"\"\n     if test_case.select_where is not None:\n         where_statement = \"WHERE \" + test_case.select_where.render(\n@@ -108,7 +53,7 @@ def select_positive(\n         result.data_out_with_types,\n     )\n     if test_case.check_output_schema:\n-        assert test_case.schema == result.schema, (test_case.schema, result.schema)\n+        assert_schemas_equal(test_case.schema, result.schema)\n \n \n def select_missing_database(\n@@ -139,13 +84,7 @@ def select_missing_table(\n     test_case: tc_select_missing_table.TestCase,\n     settings: Settings,\n     runner: Runner,\n-    client: Client,\n ):\n-    # create database, but don't create table\n-    create_database_stmt = test_case.database.query_create()\n-    LOGGER.debug(create_database_stmt)\n-    client.command(create_database_stmt)\n-\n     yql_script = f\"\"\"\n         SELECT *\n         FROM {settings.clickhouse.cluster_name}.{test_case.table_name}\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/postgresql.py b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/postgresql.py\nindex e3d75a401b4f..91e0522bdcfc 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/postgresql.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/postgresql.py\n@@ -30,13 +30,13 @@ def prepare_table(\n ):\n     # create database\n     with client.get_cursor(\"postgres\") as (conn, cur):\n-        database_exists_stmt = database.query_exists()\n+        database_exists_stmt = database.exists()\n         debug_with_limit(LOGGER, database_exists_stmt)\n         cur.execute(database_exists_stmt)\n \n         # database doesn't exist\n         if not cur.fetchone():\n-            create_database_stmt = database.query_create()\n+            create_database_stmt = database.create()\n             LOGGER.debug(create_database_stmt)\n             cur.execute(create_database_stmt)\n \n@@ -159,13 +159,13 @@ def select_missing_table(\n ):\n     # create database but don't create table\n     with client.get_cursor(\"postgres\") as (conn, cur):\n-        database_exists_stmt = test_case.database.query_exists()\n+        database_exists_stmt = test_case.database.exists()\n         debug_with_limit(LOGGER, database_exists_stmt)\n         cur.execute(database_exists_stmt)\n \n         # database doesn't exist\n         if not cur.fetchone():\n-            create_database_stmt = test_case.database.query_create()\n+            create_database_stmt = test_case.database.create()\n             debug_with_limit(LOGGER, create_database_stmt)\n             cur.execute(create_database_stmt)\n \ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/ydb.py b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/ydb.py\nindex da06c7ddb987..2bdbf4b6dd1c 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/ydb.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/ydb.py\n@@ -1,10 +1,4 @@\n-from datetime import datetime\n-import time\n-from typing import Sequence\n-\n-import yatest.common\n from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger\n-from ydb.library.yql.providers.generic.connector.tests.utils.docker_compose import DockerComposeHelper\n \n from ydb.library.yql.providers.generic.connector.tests.utils.comparator import assert_data_outs_equal\n from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings\n@@ -15,37 +9,8 @@\n \n # import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_missing_database as tc_select_missing_database\n \n-LOGGER = make_logger(__name__)\n-\n-\n-class OneTimeWaiter:\n-    __launched: bool = False\n-\n-    def __init__(self, docker_compose_file_path: str, expected_tables: Sequence[str]):\n-        docker_compose_file_abs_path = yatest.common.source_path(docker_compose_file_path)\n-        self.docker_compose_helper = DockerComposeHelper(docker_compose_yml_path=docker_compose_file_abs_path)\n-        self.expected_tables = set(expected_tables)\n-\n-    def wait(self):\n-        if self.__launched:\n-            return\n \n-        # This should be enough for tables to initialize\n-        start = datetime.now()\n-\n-        timeout = 600\n-        while (datetime.now() - start).total_seconds() < timeout:\n-            self.actual_tables = set(self.docker_compose_helper.list_ydb_tables())\n-\n-            # check if all the required tables have been created\n-            if self.expected_tables <= self.actual_tables:\n-                self.__launched = True\n-                return\n-\n-            LOGGER.warning(f\"Not enough YDB tables: expected={self.expected_tables}, actual={self.actual_tables}\")\n-            time.sleep(5)\n-\n-        raise ValueError(f\"YDB was not able to initialize in {timeout} seconds, latest table set: {self.actual_tables}\")\n+LOGGER = make_logger(__name__)\n \n \n def select_positive(\ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/schema.py b/ydb/library/yql/providers/generic/connector/tests/utils/schema.py\nindex 688a830ba341..d931f31730a1 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/schema.py\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/schema.py\n@@ -362,6 +362,9 @@ def select_every_column(self) -> SelectWhat:\n         return SelectWhat(*items)\n \n \n+# FIXME: switch to snake case in function names\n+\n+\n def makeYdbTypeFromTypeID(type_id: Type.PrimitiveTypeId) -> Type:\n     return Type(type_id=type_id)\n \ndiff --git a/ydb/library/yql/providers/generic/connector/tests/utils/ya.make b/ydb/library/yql/providers/generic/connector/tests/utils/ya.make\nindex 136e67d3cd6b..d0dea697ee67 100644\n--- a/ydb/library/yql/providers/generic/connector/tests/utils/ya.make\n+++ b/ydb/library/yql/providers/generic/connector/tests/utils/ya.make\n@@ -8,6 +8,7 @@ PY_SRCS(\n     docker_compose.py\n     generate.py\n     log.py\n+    one_time_waiter.py\n     schema.py\n     settings.py\n     sql.py\ndiff --git a/ydb/tests/fq/generic/analytics/test_join.py b/ydb/tests/fq/generic/analytics/test_join.py\nindex 8791594172f1..2e8d442b2f22 100644\n--- a/ydb/tests/fq/generic/analytics/test_join.py\n+++ b/ydb/tests/fq/generic/analytics/test_join.py\n@@ -6,11 +6,13 @@\n \n from ydb.tests.tools.fq_runner.fq_client import FederatedQueryClient\n from ydb.tests.fq.generic.utils.settings import Settings\n-from ydb.library.yql.providers.generic.connector.tests.utils.scenario.ydb import OneTimeWaiter\n+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter\n+from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n import conftest\n \n \n one_time_waiter = OneTimeWaiter(\n+    data_source_kind=EDataSourceKind.YDB,\n     docker_compose_file_path=conftest.docker_compose_file_path,\n     expected_tables=[\"join_table\", \"dummy_table\"],\n )\ndiff --git a/ydb/tests/fq/generic/analytics/test_ydb.py b/ydb/tests/fq/generic/analytics/test_ydb.py\nindex d3bb7ff8ec61..0bddcc30fe66 100644\n--- a/ydb/tests/fq/generic/analytics/test_ydb.py\n+++ b/ydb/tests/fq/generic/analytics/test_ydb.py\n@@ -7,11 +7,13 @@\n \n from ydb.tests.tools.fq_runner.fq_client import FederatedQueryClient\n from ydb.tests.fq.generic.utils.settings import Settings\n-from ydb.library.yql.providers.generic.connector.tests.utils.scenario.ydb import OneTimeWaiter\n+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter\n+from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n import conftest\n \n \n one_time_waiter = OneTimeWaiter(\n+    data_source_kind=EDataSourceKind.YDB,\n     docker_compose_file_path=conftest.docker_compose_file_path,\n     expected_tables=[\"simple_table\", \"dummy_table\"],\n )\ndiff --git a/ydb/tests/fq/generic/analytics/ya.make b/ydb/tests/fq/generic/analytics/ya.make\nindex 225f87b0575e..35ae8c110e0a 100644\n--- a/ydb/tests/fq/generic/analytics/ya.make\n+++ b/ydb/tests/fq/generic/analytics/ya.make\n@@ -52,7 +52,8 @@ IF (OPENSOURCE)\n ENDIF()\n \n PEERDIR(\n-    ydb/library/yql/providers/generic/connector/tests/utils/scenario\n+    ydb/library/yql/providers/generic/connector/api/common\n+    ydb/library/yql/providers/generic/connector/tests/utils\n     ydb/tests/fq/generic/utils\n     library/python/testing/recipe\n     library/python/testing/yatest_common\ndiff --git a/ydb/tests/fq/generic/streaming/test_join.py b/ydb/tests/fq/generic/streaming/test_join.py\nindex de79fd66962e..b61e6a86f572 100644\n--- a/ydb/tests/fq/generic/streaming/test_join.py\n+++ b/ydb/tests/fq/generic/streaming/test_join.py\n@@ -10,7 +10,10 @@\n \n from ydb.tests.tools.fq_runner.fq_client import FederatedQueryClient\n from ydb.tests.tools.datastreams_helpers.test_yds_base import TestYdsBase\n-from ydb.library.yql.providers.generic.connector.tests.utils.scenario.ydb import OneTimeWaiter\n+\n+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter\n+from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind\n+\n import conftest\n \n DEBUG = 0\n@@ -407,6 +410,7 @@ def freeze(json):\n \n \n one_time_waiter = OneTimeWaiter(\n+    data_source_kind=EDataSourceKind.YDB,\n     docker_compose_file_path=conftest.docker_compose_file_path,\n     expected_tables=[\"simple_table\", \"join_table\", \"dummy_table\"],\n )\ndiff --git a/ydb/tests/fq/generic/streaming/ya.make b/ydb/tests/fq/generic/streaming/ya.make\nindex e5056765b6a1..8cc0bfe63b7b 100644\n--- a/ydb/tests/fq/generic/streaming/ya.make\n+++ b/ydb/tests/fq/generic/streaming/ya.make\n@@ -54,7 +54,8 @@ DEPENDS(\n )\n \n PEERDIR(\n-    ydb/library/yql/providers/generic/connector/tests/utils/scenario\n+    ydb/library/yql/providers/generic/connector/api/common\n+    ydb/library/yql/providers/generic/connector/tests/utils\n     ydb/tests/fq/generic/utils\n     ydb/tests/tools/datastreams_helpers\n     library/python/testing/recipe\n",
  "problem_statement": "Mute ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse test.py.test_select_datetime[datetime_string_NATIVE-*]\nydb/library/yql/providers/generic/connector/tests/datasource/clickhouse test.py.test_select_datetime[datetime_string_NATIVE-*]\r\n\r\nThe problem appeared in contrib sync: https://github.com/ydb-platform/ydb/pull/10502\r\n\r\n@vitalyisaev2 : \"\u041a\u043e\u0440\u043e\u0447\u0435 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f \u043f\u0440\u043e\u0438\u0437\u043e\u0448\u043b\u0430 \u043f\u0440\u0438 \u043f\u0435\u0440\u0435\u0445\u043e\u0434\u0435 \u0441 \u0432\u0435\u0440\u0441\u0438\u0438 7.19 \u043d\u0430 8.0 (https://github.com/ClickHouse/clickhouse-connect/releases/tag/v0.8.0). \u041f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u044e \u043d\u0430 \u044d\u0442\u043e\u043c \u043d\u0435 \u0431\u043b\u043e\u043a\u0438\u0440\u043e\u0432\u0430\u0442\u044c\u0441\u044f, \u0442\u0435\u0441\u0442\u044b \u0437\u0430\u043c\u044c\u044e\u0442\u0438\u0442\u044c, \u043f\u043e\u0447\u0438\u043d\u043a\u0430 \u0437\u0430\u043a\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044f \u0432 \u0442\u043e\u043c, \u0447\u0442\u043e \u044f \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u044e \u0432\u044b\u043f\u0438\u043b\u0438\u0442\u044c \u044d\u0442\u0443 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0443 \u043f\u043e\u0437\u0436\u0435.\"\r\n\r\n**Add line to [muted_ya.txt](https://github.com/ydb-platform/ydb/blob/main/.github/config/muted_ya.txt):**\r\n`ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse test.py.test_select_datetime[datetime_string_NATIVE-*]`\r\n\r\n Owner: [TEAM:@ydb-platform/fq](https://github.com/orgs/ydb-platform/teams/fq)\r\n\r\n**Read more in [mute_rules.md](https://github.com/ydb-platform/ydb/blob/main/.github/config/mute_rules.md)**  \r\n\r\n**Summary history:**\r\n Success rate **100%**\r\nPass:5 Fail:0 \r\n\r\n**Test run history:** [link](https://datalens.yandex/34xnbsom67hcq?full_name=ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/test.py.test_select_datetime[datetime_string_NATIVE-dqrun])\r\n\r\nMore info in [dashboard](https://datalens.yandex/4un3zdm0zcnyr)\n",
  "hints_text": "",
  "created_at": "2024-10-23T12:09:25Z",
  "modified_files": [
    ".github/config/muted_ya.txt"
  ],
  "modified_test_files": [
    "ydb/library/yql/providers/generic/connector/tests/common_test_cases/base.py",
    "ydb/library/yql/providers/generic/connector/tests/common_test_cases/select_positive_common.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/conftest.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/docker-compose.yml",
    "b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/init/init_db.sh",
    "ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_datetime.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_positive.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/test.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_datetime.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_positive.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/test.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/mysql/select_datetime.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/mysql/test.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_datetime_with_service_name.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_positive_with_service_name.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/oracle/test.py",
    "ydb/library/yql/providers/generic/connector/tests/datasource/ydb/test.py",
    "ydb/library/yql/providers/generic/connector/tests/join/conftest.py",
    "ydb/library/yql/providers/generic/connector/tests/join/docker-compose.yml",
    "b/ydb/library/yql/providers/generic/connector/tests/join/init/clickhouse/init_db.sh",
    "ydb/library/yql/providers/generic/connector/tests/join/scenario.py",
    "ydb/library/yql/providers/generic/connector/tests/join/test.py",
    "ydb/library/yql/providers/generic/connector/tests/join/test_case.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/clients/clickhouse.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/clients/ya.make",
    "ydb/library/yql/providers/generic/connector/tests/utils/clients/ydb.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/comparator.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/database.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/docker_compose.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/generate.py",
    "b/ydb/library/yql/providers/generic/connector/tests/utils/one_time_waiter.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/scenario/clickhouse.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/scenario/postgresql.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/scenario/ydb.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/schema.py",
    "ydb/library/yql/providers/generic/connector/tests/utils/ya.make",
    "ydb/tests/fq/generic/analytics/test_join.py",
    "ydb/tests/fq/generic/analytics/test_ydb.py",
    "ydb/tests/fq/generic/analytics/ya.make",
    "ydb/tests/fq/generic/streaming/test_join.py",
    "ydb/tests/fq/generic/streaming/ya.make"
  ]
}