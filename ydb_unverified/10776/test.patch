diff --git a/ydb/library/yql/providers/generic/connector/tests/common_test_cases/base.py b/ydb/library/yql/providers/generic/connector/tests/common_test_cases/base.py
index 9e224f30b5ca..6292077391c4 100644
--- a/ydb/library/yql/providers/generic/connector/tests/common_test_cases/base.py
+++ b/ydb/library/yql/providers/generic/connector/tests/common_test_cases/base.py
@@ -66,7 +66,7 @@ def table_name(self) -> str:
         '''
         match self.data_source_kind:
             case EDataSourceKind.CLICKHOUSE:
-                return 't' + make_random_string(8)
+                return self.name_  # without protocol
             case EDataSourceKind.MS_SQL_SERVER:
                 return self.name
             case EDataSourceKind.MYSQL:
diff --git a/ydb/library/yql/providers/generic/connector/tests/common_test_cases/select_positive_common.py b/ydb/library/yql/providers/generic/connector/tests/common_test_cases/select_positive_common.py
index 7bfb35d0de2c..99da19b19aae 100644
--- a/ydb/library/yql/providers/generic/connector/tests/common_test_cases/select_positive_common.py
+++ b/ydb/library/yql/providers/generic/connector/tests/common_test_cases/select_positive_common.py
@@ -18,6 +18,7 @@
     DataSourceType,
     SelectWhat,
     SelectWhere,
+    makeYdbTypeFromTypeID,
 )
 
 from ydb.library.yql.providers.generic.connector.tests.common_test_cases.base import BaseTestCase
@@ -246,46 +247,65 @@ def _large_table(self) -> Sequence[TestCase]:
         schema = Schema(
             columns=ColumnList(
                 Column(
-                    name='col_01_int64',
-                    ydb_type=Type.INT64,
-                    data_source_type=DataSourceType(ch=clickhouse.Int32(), pg=postgresql.Int8()),
+                    name='col_00_int32',
+                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),
+                    data_source_type=DataSourceType(ch=clickhouse.Int64(), pg=postgresql.Int8()),
                 ),
                 Column(
-                    name='col_02_utf8',
-                    ydb_type=Type.UTF8,
+                    name='col_01_string',
+                    ydb_type=makeYdbTypeFromTypeID(Type.STRING),
                     data_source_type=DataSourceType(ch=clickhouse.String(), pg=postgresql.Text()),
                 ),
             )
         )
 
-        data_in = generate_table_data(schema=schema, bytes_soft_limit=table_size)
-
-        # Assuming that request will look something like:
-        #
-        # SELECT * FROM table WHERE id = (SELECT MAX(id) FROM table)
-        #
-        # We expect last line to be the answer
-        data_out = [data_in[-1]]
-
-        data_source_kinds = [EDataSourceKind.CLICKHOUSE, EDataSourceKind.POSTGRESQL]
-
-        test_case_name = 'large_table'
+        data_source_kinds = (
+            EDataSourceKind.CLICKHOUSE,
+            EDataSourceKind.POSTGRESQL,
+        )
 
+        test_case_name = 'large'
         test_cases = []
+
         for data_source_kind in data_source_kinds:
-            tc = TestCase(
-                name_=test_case_name,
-                data_source_kind=data_source_kind,
-                protocol=EProtocol.NATIVE,
-                data_in=data_in,
-                data_out_=data_out,
-                select_what=SelectWhat.asterisk(schema.columns),
-                select_where=SelectWhere(
-                    expression_='col_01_int64 IN (SELECT MAX(col_01_int64) FROM {cluster_name}.{table_name})'
-                ),
-                schema=schema,
-                pragmas=dict(),
-            )
+            match data_source_kind:
+                case EDataSourceKind.CLICKHOUSE:
+                    tc = TestCase(
+                        name_=test_case_name,
+                        data_source_kind=data_source_kind,
+                        protocol=EProtocol.NATIVE,
+                        data_in=None,
+                        data_out_=[[999999]],  # We put 1M of rows in the large table
+                        select_what=SelectWhat(SelectWhat.Item(name='MAX(col_00_int32)', kind='expr')),
+                        select_where=None,
+                        schema=schema,
+                        pragmas=dict(),
+                    )
+
+                case EDataSourceKind.POSTGRESQL:
+                    # Assuming that request will look something like:
+                    # `SELECT * FROM table WHERE id = (SELECT MAX(id) FROM table)`
+                    # We expect last line to be the answer
+                    data_in = generate_table_data(schema=schema, bytes_soft_limit=table_size)
+                    data_out = [data_in[-1]]
+                    data_source_kinds = [EDataSourceKind.CLICKHOUSE, EDataSourceKind.POSTGRESQL]
+
+                    tc = TestCase(
+                        name_=test_case_name,
+                        data_source_kind=data_source_kind,
+                        protocol=EProtocol.NATIVE,
+                        data_in=data_in,
+                        data_out_=data_out,
+                        select_what=SelectWhat.asterisk(schema.columns),
+                        select_where=SelectWhere(
+                            expression_='col_00_int32 IN (SELECT MAX(col_00_int32) FROM {cluster_name}.{table_name})'
+                        ),
+                        schema=schema,
+                        pragmas=dict(),
+                    )
+
+                case _:
+                    raise ValueError(f'Unknown data source kind: {data_source_kind}')
 
             test_cases.append(tc)
 
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/conftest.py b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/conftest.py
index 6f31ef8d80cd..b2869f8d1f5f 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/conftest.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/conftest.py
@@ -5,7 +5,6 @@
 
 from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
-from ydb.library.yql.providers.generic.connector.tests.utils.clients.clickhouse import Client, make_client
 
 docker_compose_dir: Final = pathlib.Path("ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse")
 
@@ -13,10 +12,3 @@
 @pytest.fixture
 def settings() -> Settings:
     return Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.CLICKHOUSE])
-
-
-@pytest.fixture
-def clickhouse_client(settings) -> Client:
-    cl = make_client(settings.clickhouse)
-    yield cl
-    cl.close()
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/docker-compose.yml b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/docker-compose.yml
index cfc34aa8fbd8..5d8a46469ae2 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/docker-compose.yml
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/docker-compose.yml
@@ -6,19 +6,18 @@ services:
       CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
       CLICKHOUSE_PASSWORD: password
       CLICKHOUSE_USER: user
-    image: mirror.gcr.io/clickhouse/clickhouse-server:23-alpine@sha256:d75017307e76d1bca81a5ac7ada94620567782c0610541f525d1e443e23f76e3
+      CLICKHOUSE_ALWAYS_RUN_INITDB_SCRIPTS: 1
+    image: mirror.gcr.io/clickhouse/clickhouse-server:24.3.12-alpine@sha256:65e5846a0d9672714f2625502b27846563f6d01ec226304cf851aa49004ffde8
+    volumes:
+      - ./init:/docker-entrypoint-initdb.d
     ports:
-      - 9000
-      - 8123
-    tmpfs:
-      - /run
-      - /tmp
-      - /var
+    - 9000
+    - 8123
   fq-connector-go:
     container_name: fq-tests-ch-fq-connector-go
     image: ghcr.io/ydb-platform/fq-connector-go:v0.5.11-rc.5@sha256:c17f67aea314366690545aea1db9f2bf4391ae1269044ebbac7ea2316972e7ff
     ports:
-      - 2130
+    - 2130
     volumes:
-      - ../../fq-connector-go/:/opt/ydb/cfg/
+    - ../../fq-connector-go/:/opt/ydb/cfg/
 version: "3.4"
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/init/init_db.sh b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/init/init_db.sh
new file mode 100644
index 000000000000..3b16991b246e
--- /dev/null
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/init/init_db.sh
@@ -0,0 +1,217 @@
+#!/bin/bash
+set -ex
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.primitive_types_non_nullable;
+    CREATE TABLE db.primitive_types_non_nullable (
+        col_00_id Int32,
+        col_01_boolean Boolean,
+        col_02_int8 Int8,
+        col_03_uint8 UInt8,
+        col_04_int16 Int16,
+        col_05_uint16 UInt16,
+        col_06_int32 Int32,
+        col_07_uint32 UInt32,
+        col_08_int64 Int64,
+        col_09_uint64 UInt64,
+        col_10_float32 Float32,
+        col_11_float64 Float64,
+        col_12_string String,
+        col_13_fixed_string FixedString(13),
+        col_14_date Date,
+        col_15_date32 Date32,
+        col_16_datetime DateTime,
+        col_17_datetime64 DateTime64(3)
+    ) ENGINE = MergeTree ORDER BY col_00_id;
+    INSERT INTO db.primitive_types_non_nullable (*) VALUES
+        (1, False, 2, 3, 4, 5, 6, 7, 8, 9, 10.10, 11.11, 'az', 'az', '1988-11-20', '1988-11-20', '1988-11-20 12:55:28', '1988-11-20 12:55:28.123') \
+        (2, True, -2, 3, -4, 5, -6, 7, -8, 9, -10.10, -11.11, 'буки', 'буки', '2023-03-21', '2023-03-21', '2023-03-21 11:21:31', '2023-03-21 11:21:31.456');
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.primitive_types_nullable;
+    CREATE TABLE db.primitive_types_nullable (
+        col_00_id Int32,
+        col_01_boolean Nullable(Boolean),
+        col_02_int8 Nullable(Int8),
+        col_03_uint8 Nullable(UInt8),
+        col_04_int16 Nullable(Int16),
+        col_05_uint16 Nullable(UInt16),
+        col_06_int32 Nullable(Int32),
+        col_07_uint32 Nullable(UInt32),
+        col_08_int64 Nullable(Int64),
+        col_09_uint64 Nullable(UInt64),
+        col_10_float32 Nullable(Float32),
+        col_11_float64 Nullable(Float64),
+        col_12_string Nullable(String),
+        col_13_fixed_string Nullable(FixedString(13)),
+        col_14_date Nullable(Date),
+        col_15_date32 Nullable(Date32),
+        col_16_datetime Nullable(DateTime('UTC')),
+        col_17_datetime64 Nullable(DateTime64(6, 'UTC'))
+    ) ENGINE = MergeTree ORDER BY col_00_id;
+    INSERT INTO db.primitive_types_nullable (*) VALUES
+        (1, False, 2, 3, 4, 5, 6, 7, 8, 9, 10.10, 11.11, 'az', 'az', '1988-11-20', '1988-11-20', '1988-11-20 12:55:28', '1988-11-20 12:55:28.123') \
+        (2, NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL) \
+        (3, True, -2, 3, -4, 5, -6, 7, -8, 9, -10.10, -11.11, 'буки', 'буки', '2023-03-21', '2023-03-21', '2023-03-21 11:21:31', '2023-03-21 11:21:31.456');
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.datetime_string;
+    CREATE TABLE db.datetime_string (
+        col_00_id Int32,
+        col_01_date Date,
+        col_02_date32 Date32,
+        col_03_datetime DateTime,
+        col_04_datetime64 DateTime64(8)
+    ) ENGINE = MergeTree ORDER BY col_00_id;
+/*
+    Value is too early for both CH and YQL
+    In this case ClickHouse behaviour is undefined
+    For Datetime Clickhouse returns bottom bound and
+    cuts off only date part of value along ClickHouse bottom bound for other types
+*/
+    INSERT INTO db.datetime_string (*) VALUES
+        (1, '1950-01-10', '1850-01-10', '1950-01-10 12:23:45', '1950-01-10 12:23:45.678910');
+
+    /* Value is OK for CH, but can be too early for YQL */
+    INSERT INTO db.datetime_string (*) VALUES
+        (2, '1970-01-10', '1950-01-10', '1980-01-10 12:23:45', '1950-01-10 12:23:45.678910');
+
+    /* Value is OK for both CH and YQL */
+    INSERT INTO db.datetime_string (*) VALUES
+        (3, '2004-01-10', '2004-01-10', '2004-01-10 12:23:45', '2004-01-10 12:23:45.678910');
+
+    /* Value is OK for CH, but too late for YQL */
+    INSERT INTO db.datetime_string (*) VALUES
+        (4, '2110-01-10', '2110-01-10', '2106-01-10 12:23:45', '2110-01-10 12:23:45.678910');
+       
+    /*
+    Value is too late for both YQL and CH.
+    In this case ClickHouse behaviour is undefined.
+    */
+    INSERT INTO db.datetime_string (*) VALUES
+        (5, '2150-01-10', '2300-01-10', '2107-01-10 12:23:45', '2300-01-10 12:23:45.678910');
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.datetime_YQL;
+    CREATE TABLE db.datetime_YQL (
+        col_00_id Int32,
+        col_01_date Date,
+        col_02_date32 Date32,
+        col_03_datetime DateTime,
+        col_04_datetime64 DateTime64(8)
+    ) ENGINE = MergeTree ORDER BY col_00_id;
+    INSERT INTO db.datetime_YQL (*) VALUES
+        (1, '1950-01-10', '1850-01-10', '1950-01-10 12:23:45', '1950-01-10 12:23:45.678910') \
+        (2, '1970-01-10', '1950-01-10', '1980-01-10 12:23:45', '1950-01-10 12:23:45.678910') \
+        (3, '2004-01-10', '2004-01-10', '2004-01-10 12:23:45', '2004-01-10 12:23:45.678910') \
+        (4, '2110-01-10', '2110-01-10', '2106-01-10 12:23:45', '2110-01-10 12:23:45.678910') \
+        (5, '2150-01-10', '2300-01-10', '2107-01-10 12:23:45', '2300-01-10 12:23:45.678910');
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.constant;
+    CREATE TABLE db.constant (
+        id Int32,
+    ) ENGINE = MergeTree ORDER BY id;
+    INSERT INTO db.constant (*) VALUES
+        (1) \
+        (2) \
+        (3);
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.counts;
+    CREATE TABLE db.counts (
+        col Float64,
+    ) ENGINE = MergeTree ORDER BY col;
+    INSERT INTO db.counts (*) VALUES
+        (3.14) \
+        (1.0) \
+        (2.718) \
+        (-0.0);
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.pushdown;
+    CREATE TABLE db.pushdown (
+        col_00_int32 Int32,
+        col_01_string Nullable(String)
+    ) ENGINE = MergeTree ORDER BY col_00_int32;
+    INSERT INTO db.pushdown (*) VALUES
+        (1, 'one') \
+        (2, 'two') \
+        (3, 'three') \
+        (4, NULL);
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.large;
+    CREATE TABLE db.large (
+        col_00_int32 Int32,
+        col_01_string Nullable(String)
+    ) ENGINE = MergeTree ORDER BY col_00_int32;
+
+    INSERT INTO db.large
+    SELECT
+        number AS col_00_int32,
+        substring(randomPrintableASCII(32), 1, 32) AS col_01_string
+    FROM
+        numbers(1000000);
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.column_selection_A_b_C_d_E;
+    CREATE TABLE db.column_selection_A_b_C_d_E (COL1 Int32, col2 Int32) 
+        ENGINE = MergeTree ORDER BY COL1;
+    INSERT INTO db.column_selection_A_b_C_d_E (*) VALUES
+        (1, 2) \
+        (10, 20);
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.column_selection_COL1;
+    CREATE TABLE db.column_selection_COL1 (COL1 Int32, col2 Int32) 
+        ENGINE = MergeTree ORDER BY COL1;
+    INSERT INTO db.column_selection_COL1 (*) VALUES
+        (1, 2) \
+        (10, 20);
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.column_selection_asterisk;
+    CREATE TABLE db.column_selection_asterisk (COL1 Int32, col2 Int32) 
+        ENGINE = MergeTree ORDER BY COL1;
+    INSERT INTO db.column_selection_asterisk (*) VALUES
+        (1, 2) \
+        (10, 20);
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.column_selection_col2_COL1;
+    CREATE TABLE db.column_selection_col2_COL1 (COL1 Int32, col2 Int32) 
+        ENGINE = MergeTree ORDER BY COL1;
+    INSERT INTO db.column_selection_col2_COL1 (*) VALUES
+        (1, 2) \
+        (10, 20);
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.column_selection_col2;
+    CREATE TABLE db.column_selection_col2 (COL1 Int32, col2 Int32) 
+        ENGINE = MergeTree ORDER BY COL1;
+    INSERT INTO db.column_selection_col2 (*) VALUES
+        (1, 2) \
+        (10, 20);
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.column_selection_col3;
+    CREATE TABLE db.column_selection_col3 (COL1 Int32, col2 Int32) 
+        ENGINE = MergeTree ORDER BY COL1;
+    INSERT INTO db.column_selection_col3 (*) VALUES
+        (1, 2) \
+        (10, 20);
+EOSQL
\ No newline at end of file
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_datetime.py b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_datetime.py
index 95c390cf2507..1057054a4b92 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_datetime.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_datetime.py
@@ -14,6 +14,8 @@
     ColumnList,
     DataSourceType,
     SelectWhat,
+    makeYdbTypeFromTypeID,
+    makeOptionalYdbTypeFromTypeID,
 )
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import GenericSettings
 
@@ -36,95 +38,47 @@ def generic_settings(self) -> GenericSettings:
 class Factory:
     _name = 'datetime'
 
-    def _make_test_yql_clickhouse(self) -> TestCase:
+    '''
+    ClickHouse values' bounds:
+    Date                    [1970-01-01, 2149-06-06]
+    Date32                  [1900-01-01, 2299-12-31]
+    Datetime                [1970-01-01 00:00:00, 2106-02-07 06:28:15]
+    Datetime64              [1900-01-01 00:00:00, 2299-12-31 23:59:59.99999999]
+
+    YQL datetime bounds:    [1970-01-01 00:00:00, 2106-01-01 00:00:00]
+    '''
+
+    def _make_test_yql(self) -> TestCase:
         schema = Schema(
             columns=ColumnList(
                 Column(
-                    name='col_0_id',
-                    ydb_type=Type.UINT8,
-                    data_source_type=DataSourceType(ch=clickhouse.UInt8()),
+                    name='col_00_id',
+                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),
+                    data_source_type=DataSourceType(ch=clickhouse.Int32()),
                 ),
                 Column(
-                    name='col_1_date',
-                    ydb_type=Type.DATE,
+                    name='col_01_date',
+                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),
                     data_source_type=DataSourceType(ch=clickhouse.Date()),
                 ),
                 Column(
-                    name='col_2_date32',
-                    ydb_type=Type.DATE,
+                    name='col_02_date32',
+                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),
                     data_source_type=DataSourceType(ch=clickhouse.Date32()),
                 ),
                 Column(
-                    name='col_3_datetime',
-                    ydb_type=Type.DATETIME,
+                    name='col_03_datetime',
+                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATETIME),
                     data_source_type=DataSourceType(ch=clickhouse.DateTime()),
                 ),
                 Column(
-                    name='col_4_datetime64',
-                    ydb_type=Type.TIMESTAMP,
+                    name='col_04_datetime64',
+                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.TIMESTAMP),
                     data_source_type=DataSourceType(ch=clickhouse.DateTime64()),
                 ),
             ),
         )
 
-        '''
-        ClickHouse values' bounds:
-        Date                    [1970-01-01, 2149-06-06]
-        Date32                  [1900-01-01, 2299-12-31]
-        Datetime                [1970-01-01 00:00:00, 2106-02-07 06:28:15]
-        Datetime64              [1900-01-01 00:00:00, 2299-12-31 23:59:59.99999999]
-
-        YQL datetime bounds:    [1970-01-01 00:00:00, 2106-01-01 00:00:00]
-        '''
-
-        data_in = [
-            # Value is too early for both CH and YQL
-            # In this case ClickHouse behaviour is undefined
-            # Clickhouse cuts off only date part of value along ClickHouse bottom bound
-            [
-                1,
-                '1950-01-10',
-                '1850-01-10',
-                '1950-01-10 12:23:45',
-                '1850-01-10 12:23:45.678910',
-            ],
-            # Value is OK for CH, but can be too early for YQL
-            [
-                2,
-                '1970-01-10',
-                '1950-01-10',
-                '1980-01-10 12:23:45',
-                '1950-01-10 12:23:45.678910',
-            ],
-            # Value is OK for both CH and YQL
-            [
-                3,
-                '2004-01-10',
-                '2004-01-10',
-                '2004-01-10 12:23:45',
-                '2004-01-10 12:23:45.678910',
-            ],
-            # Value is OK for CH, but too late for YQL
-            [
-                4,
-                '2110-01-10',
-                '2110-01-10',
-                '2106-01-10 12:23:45',
-                '2110-01-10 12:23:45.678910',
-            ],
-            # Value is too late for both OK for CH
-            # In this case ClickHouse behaviour is undefined
-            # "Natural" overflow for Datetime
-            # Cutting off along ClickHouse top bound for other types
-            [
-                5,
-                '2150-01-10',
-                '2300-01-10',
-                '2107-01-10 12:23:45',
-                '2300-01-10 12:23:45.678910',
-            ],
-        ]
-
         data_out = [
             [
                 1,
@@ -162,7 +116,7 @@ def _make_test_yql_clickhouse(self) -> TestCase:
         return TestCase(
             name_=test_case_name,
             date_time_format=EDateTimeFormat.YQL_FORMAT,
-            data_in=data_in,
+            data_in=None,
             data_out_=data_out,
             select_what=SelectWhat.asterisk(schema.columns),
             select_where=None,
@@ -170,90 +124,42 @@ def _make_test_yql_clickhouse(self) -> TestCase:
             protocol=EProtocol.NATIVE,
             schema=schema,
             pragmas=dict(),
+            check_output_schema=True,
         )
 
-    def _make_test_string_clickhouse(self) -> TestCase:
+    def _make_test_string(self) -> TestCase:
         schema = Schema(
             columns=ColumnList(
                 Column(
-                    name='col_0_id',
-                    ydb_type=Type.UINT8,
-                    data_source_type=DataSourceType(ch=clickhouse.UInt8()),
+                    name='col_00_id',
+                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),
+                    data_source_type=DataSourceType(ch=clickhouse.Int32()),
                 ),
                 Column(
-                    name='col_1_date',
-                    ydb_type=Type.DATE,
+                    name='col_01_date',
+                    ydb_type=makeYdbTypeFromTypeID(Type.UTF8),
                     data_source_type=DataSourceType(ch=clickhouse.Date()),
                 ),
                 Column(
-                    name='col_2_date32',
-                    ydb_type=Type.DATE,
+                    name='col_02_date32',
+                    ydb_type=makeYdbTypeFromTypeID(Type.UTF8),
                     data_source_type=DataSourceType(ch=clickhouse.Date32()),
                 ),
                 Column(
-                    name='col_3_datetime',
-                    ydb_type=Type.DATETIME,
+                    name='col_03_datetime',
+                    ydb_type=makeYdbTypeFromTypeID(Type.UTF8),
                     data_source_type=DataSourceType(ch=clickhouse.DateTime()),
                 ),
                 Column(
-                    name='col_4_datetime64',
-                    ydb_type=Type.TIMESTAMP,
+                    name='col_04_datetime64',
+                    ydb_type=makeYdbTypeFromTypeID(Type.UTF8),
                     data_source_type=DataSourceType(ch=clickhouse.DateTime64()),
                 ),
             ),
         )
 
-        data_in = [
-            # Value is too early for both CH and YQL
-            # In this case ClickHouse behaviour is undefined
-            # For Datetime Clickhouse returns bottom bound and
-            # cuts off only date part of value along ClickHouse bottom bound for other types
-            [
-                1,
-                '1950-01-10',
-                '1850-01-10',
-                '1950-01-10 12:23:45',
-                '1850-01-10 12:23:45.678910',
-            ],
-            # Value is OK for CH, but can be too early for YQL
-            [
-                2,
-                '1970-01-10',
-                '1950-01-10',
-                '1980-01-10 12:23:45',
-                '1950-01-10 12:23:45.678910',
-            ],
-            # Value is OK for both CH and YQL
-            [
-                3,
-                '2004-01-10',
-                '2004-01-10',
-                '2004-01-10 12:23:45',
-                '2004-01-10 12:23:45.678910',
-            ],
-            # Value is OK for CH, but too late for YQL
-            [
-                4,
-                '2110-01-10',
-                '2110-01-10',
-                '2106-01-10 12:23:45',
-                '2110-01-10 12:23:45.678910',
-            ],
-            # Value is too late for both OK for CH
-            # In this case ClickHouse behaviour is undefined
-            # "Natural" overflow for Datetime
-            # Cutting off along ClickHouse top bound for other types
-            [
-                5,
-                '2150-01-10',
-                '2300-01-10',
-                '2107-01-10 12:23:45',
-                '2300-01-10 12:23:45.678910',
-            ],
-        ]
-
         data_out = [
-            [1, '1970-01-01', '1900-01-01', '1970-01-01T00:00:00Z', '1900-01-01T12:23:45.67891Z'],
+            [1, '1970-01-01', '1900-01-01', '1970-01-01T00:00:00Z', '1950-01-10T12:23:45.67891Z'],
             [2, '1970-01-10', '1950-01-10', '1980-01-10T12:23:45Z', '1950-01-10T12:23:45.67891Z'],
             [3, '2004-01-10', '2004-01-10', '2004-01-10T12:23:45Z', '2004-01-10T12:23:45.67891Z'],
             [4, '2110-01-10', '2110-01-10', '2106-01-10T12:23:45Z', '2110-01-10T12:23:45.67891Z'],
@@ -262,7 +168,7 @@ def _make_test_string_clickhouse(self) -> TestCase:
                 '2149-06-06',
                 '2299-12-31',
                 '1970-12-04T05:55:29Z',
-                '1900-01-01T00:00:00Z',  # TODO: strange overflow under bottom bound for datetime64
+                '1900-01-01T00:00:00Z',  # strange overflow issue with DateTime64 in ClickHouse
             ],
         ]
 
@@ -272,17 +178,18 @@ def _make_test_string_clickhouse(self) -> TestCase:
             name_=test_case_name,
             date_time_format=EDateTimeFormat.STRING_FORMAT,
             protocol=EProtocol.NATIVE,
-            data_in=data_in,
+            data_in=None,
             data_out_=data_out,
             select_what=SelectWhat.asterisk(schema.columns),
             select_where=None,
             data_source_kind=EDataSourceKind.CLICKHOUSE,
             schema=schema,
             pragmas=dict(),
+            check_output_schema=True,
         )
 
     def make_test_cases(self) -> Sequence[TestCase]:
         return [
-            self._make_test_yql_clickhouse(),
-            self._make_test_string_clickhouse(),
+            self._make_test_yql(),
+            self._make_test_string(),
         ]
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_positive.py b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_positive.py
index de6af3d7cc51..da75133e3432 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_positive.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/select_positive.py
@@ -1,7 +1,7 @@
 import datetime
 import itertools
 from dataclasses import replace
-from typing import Sequence
+from typing import Sequence, Final
 
 from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind, EProtocol
 from ydb.public.api.protos.ydb_value_pb2 import Type
@@ -23,106 +23,113 @@
 
 
 class Factory:
-    def _primitive_types(self) -> Sequence[TestCase]:
-        schema = Schema(
-            columns=ColumnList(
-                Column(
-                    name='col_01_boolean',
-                    ydb_type=makeYdbTypeFromTypeID(Type.BOOL),
-                    data_source_type=DataSourceType(ch=clickhouse.Boolean()),
-                ),
-                Column(
-                    name='col_02_int8',
-                    ydb_type=makeYdbTypeFromTypeID(Type.INT8),
-                    data_source_type=DataSourceType(ch=clickhouse.Int8()),
-                ),
-                Column(
-                    name='col_03_uint8',
-                    ydb_type=makeYdbTypeFromTypeID(Type.UINT8),
-                    data_source_type=DataSourceType(ch=clickhouse.UInt8()),
-                ),
-                Column(
-                    name='col_04_int16',
-                    ydb_type=makeYdbTypeFromTypeID(Type.INT16),
-                    data_source_type=DataSourceType(ch=clickhouse.Int16()),
-                ),
-                Column(
-                    name='col_05_uint16',
-                    ydb_type=makeYdbTypeFromTypeID(Type.UINT16),
-                    data_source_type=DataSourceType(ch=clickhouse.UInt16()),
-                ),
-                Column(
-                    name='col_06_int32',
-                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),
-                    data_source_type=DataSourceType(ch=clickhouse.Int32()),
-                ),
-                Column(
-                    name='col_07_uint32',
-                    ydb_type=makeYdbTypeFromTypeID(Type.UINT32),
-                    data_source_type=DataSourceType(ch=clickhouse.UInt32()),
-                ),
-                Column(
-                    name='col_08_int64',
-                    ydb_type=makeYdbTypeFromTypeID(Type.INT64),
-                    data_source_type=DataSourceType(ch=clickhouse.Int64()),
-                ),
-                Column(
-                    name='col_09_uint64',
-                    ydb_type=makeYdbTypeFromTypeID(Type.UINT64),
-                    data_source_type=DataSourceType(ch=clickhouse.UInt64()),
-                ),
-                Column(
-                    name='col_10_float32',
-                    ydb_type=makeYdbTypeFromTypeID(Type.FLOAT),
-                    data_source_type=DataSourceType(ch=clickhouse.Float32()),
-                ),
-                Column(
-                    name='col_11_float64',
-                    ydb_type=makeYdbTypeFromTypeID(Type.DOUBLE),
-                    data_source_type=DataSourceType(ch=clickhouse.Float64()),
-                ),
-                Column(
-                    name='col_12_string',
-                    ydb_type=makeYdbTypeFromTypeID(Type.STRING),
-                    data_source_type=DataSourceType(ch=clickhouse.String()),
-                ),
-                Column(
-                    name='col_13_fixed_string',
-                    ydb_type=makeYdbTypeFromTypeID(Type.STRING),
-                    data_source_type=DataSourceType(ch=clickhouse.FixedString()),
-                ),
-                Column(
-                    name='col_14_date',
-                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),
-                    data_source_type=DataSourceType(ch=clickhouse.Date()),
-                ),
-                Column(
-                    name='col_15_date32',
-                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),
-                    data_source_type=DataSourceType(ch=clickhouse.Date32()),
-                ),
-                Column(
-                    name='col_16_datetime',
-                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATETIME),
-                    data_source_type=DataSourceType(ch=clickhouse.DateTime()),
-                ),
-                Column(
-                    name='col_17_datetime64',
-                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.TIMESTAMP),
-                    data_source_type=DataSourceType(ch=clickhouse.DateTime64()),
-                ),
+    __primitive_types_schema: Final = Schema(
+        columns=ColumnList(
+            Column(
+                name='col_00_id',
+                ydb_type=makeYdbTypeFromTypeID(Type.INT32),
+                data_source_type=DataSourceType(ch=clickhouse.Int32()),
             ),
-        )
+            Column(
+                name='col_01_boolean',
+                ydb_type=makeYdbTypeFromTypeID(Type.BOOL),
+                data_source_type=DataSourceType(ch=clickhouse.Boolean()),
+            ),
+            Column(
+                name='col_02_int8',
+                ydb_type=makeYdbTypeFromTypeID(Type.INT8),
+                data_source_type=DataSourceType(ch=clickhouse.Int8()),
+            ),
+            Column(
+                name='col_03_uint8',
+                ydb_type=makeYdbTypeFromTypeID(Type.UINT8),
+                data_source_type=DataSourceType(ch=clickhouse.UInt8()),
+            ),
+            Column(
+                name='col_04_int16',
+                ydb_type=makeYdbTypeFromTypeID(Type.INT16),
+                data_source_type=DataSourceType(ch=clickhouse.Int16()),
+            ),
+            Column(
+                name='col_05_uint16',
+                ydb_type=makeYdbTypeFromTypeID(Type.UINT16),
+                data_source_type=DataSourceType(ch=clickhouse.UInt16()),
+            ),
+            Column(
+                name='col_06_int32',
+                ydb_type=makeYdbTypeFromTypeID(Type.INT32),
+                data_source_type=DataSourceType(ch=clickhouse.Int32()),
+            ),
+            Column(
+                name='col_07_uint32',
+                ydb_type=makeYdbTypeFromTypeID(Type.UINT32),
+                data_source_type=DataSourceType(ch=clickhouse.UInt32()),
+            ),
+            Column(
+                name='col_08_int64',
+                ydb_type=makeYdbTypeFromTypeID(Type.INT64),
+                data_source_type=DataSourceType(ch=clickhouse.Int64()),
+            ),
+            Column(
+                name='col_09_uint64',
+                ydb_type=makeYdbTypeFromTypeID(Type.UINT64),
+                data_source_type=DataSourceType(ch=clickhouse.UInt64()),
+            ),
+            Column(
+                name='col_10_float32',
+                ydb_type=makeYdbTypeFromTypeID(Type.FLOAT),
+                data_source_type=DataSourceType(ch=clickhouse.Float32()),
+            ),
+            Column(
+                name='col_11_float64',
+                ydb_type=makeYdbTypeFromTypeID(Type.DOUBLE),
+                data_source_type=DataSourceType(ch=clickhouse.Float64()),
+            ),
+            Column(
+                name='col_12_string',
+                ydb_type=makeYdbTypeFromTypeID(Type.STRING),
+                data_source_type=DataSourceType(ch=clickhouse.String()),
+            ),
+            Column(
+                name='col_13_fixed_string',
+                ydb_type=makeYdbTypeFromTypeID(Type.STRING),
+                data_source_type=DataSourceType(ch=clickhouse.FixedString()),
+            ),
+            Column(
+                name='col_14_date',
+                ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),
+                data_source_type=DataSourceType(ch=clickhouse.Date()),
+            ),
+            Column(
+                name='col_15_date32',
+                ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATE),
+                data_source_type=DataSourceType(ch=clickhouse.Date32()),
+            ),
+            Column(
+                name='col_16_datetime',
+                ydb_type=makeOptionalYdbTypeFromTypeID(Type.DATETIME),
+                data_source_type=DataSourceType(ch=clickhouse.DateTime()),
+            ),
+            Column(
+                name='col_17_datetime64',
+                ydb_type=makeOptionalYdbTypeFromTypeID(Type.TIMESTAMP),
+                data_source_type=DataSourceType(ch=clickhouse.DateTime64()),
+            ),
+        ),
+    )
 
-        test_case_name = 'primitive_types'
+    def _primitive_types_non_nullable(self) -> Sequence[TestCase]:
+        schema = self.__primitive_types_schema
 
         tc = TestCase(
-            name_=test_case_name,
+            name_='primitive_types_non_nullable',
             schema=schema,
             select_what=SelectWhat.asterisk(schema.columns),
             select_where=None,
-            data_in=[
+            data_in=None,
+            data_out_=[
                 [
+                    1,
                     False,
                     2,
                     3,
@@ -135,13 +142,14 @@ def _primitive_types(self) -> Sequence[TestCase]:
                     10.10,
                     11.11,
                     'az',
-                    'az   ',
-                    '2023-01-09',
-                    '2023-01-09',
-                    '2023-01-09 13:19:11',
-                    '2023-01-09 13:19:11.123456',
+                    'az\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00',
+                    datetime.date(1988, 11, 20),
+                    datetime.date(1988, 11, 20),
+                    datetime.datetime(1988, 11, 20, 12, 55, 28),
+                    datetime.datetime(1988, 11, 20, 12, 55, 28, 123000),
                 ],
                 [
+                    2,
                     True,
                     -2,
                     3,
@@ -153,16 +161,57 @@ def _primitive_types(self) -> Sequence[TestCase]:
                     9,
                     -10.10,
                     -11.11,
-                    'buki',
-                    'buki ',
-                    '1988-11-20',
-                    '1988-11-20',
-                    '1988-11-20 12:00:00',
-                    '1988-11-20 12:00:00.100000',
+                    'буки',
+                    'буки\x00\x00\x00\x00\x00',
+                    datetime.date(2023, 3, 21),
+                    datetime.date(2023, 3, 21),
+                    datetime.datetime(2023, 3, 21, 11, 21, 31),
+                    datetime.datetime(2023, 3, 21, 11, 21, 31, 456000),
                 ],
             ],
+            data_source_kind=EDataSourceKind.CLICKHOUSE,
+            protocol=EProtocol.NATIVE,
+            pragmas=dict(),
+            check_output_schema=True,
+        )
+
+        return [
+            tc,
+        ]
+
+    def _make_primitive_types_nullable_schema(self) -> Schema:
+        schema = self.__primitive_types_schema
+        schema_nullable = Schema(columns=ColumnList())
+
+        for i, col in enumerate(schema.columns):
+            # do not convert first column to nullable as it contains primary key
+            if i == 0:
+                schema_nullable.columns.append(col)
+                continue
+
+            ch_type = col.data_source_type.ch
+            schema_nullable.columns.append(
+                Column(
+                    name=col.name,
+                    ydb_type=makeOptionalYdbTypeFromYdbType(col.ydb_type),
+                    data_source_type=DataSourceType(ch=ch_type.to_nullable()),
+                )
+            )
+
+        return schema_nullable
+
+    def _primitive_types_nullable(self) -> Sequence[TestCase]:
+        schema = self._make_primitive_types_nullable_schema()
+
+        tc = TestCase(
+            name_='primitive_types_nullable',
+            schema=schema,
+            select_what=SelectWhat.asterisk(schema.columns),
+            select_where=None,
+            data_in=None,
             data_out_=[
                 [
+                    1,
                     False,
                     2,
                     3,
@@ -175,13 +224,34 @@ def _primitive_types(self) -> Sequence[TestCase]:
                     10.10,
                     11.11,
                     'az',
-                    'az   ',
-                    datetime.date(2023, 1, 9),
-                    datetime.date(2023, 1, 9),
-                    datetime.datetime(2023, 1, 9, 13, 19, 11),
-                    datetime.datetime(2023, 1, 9, 13, 19, 11, 123456),
+                    'az\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00',
+                    datetime.date(1988, 11, 20),
+                    datetime.date(1988, 11, 20),
+                    datetime.datetime(1988, 11, 20, 12, 55, 28),
+                    datetime.datetime(1988, 11, 20, 12, 55, 28, 123000),
                 ],
                 [
+                    2,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                ],
+                [
+                    3,
                     True,
                     -2,
                     3,
@@ -193,12 +263,12 @@ def _primitive_types(self) -> Sequence[TestCase]:
                     9,
                     -10.10,
                     -11.11,
-                    'buki',
-                    'buki ',
-                    datetime.date(1988, 11, 20),
-                    datetime.date(1988, 11, 20),
-                    datetime.datetime(1988, 11, 20, 12, 00, 00),
-                    datetime.datetime(1988, 11, 20, 12, 00, 00, 100000),
+                    'буки',
+                    'буки\x00\x00\x00\x00\x00',
+                    datetime.date(2023, 3, 21),
+                    datetime.date(2023, 3, 21),
+                    datetime.datetime(2023, 3, 21, 11, 21, 31),
+                    datetime.datetime(2023, 3, 21, 11, 21, 31, 456000),
                 ],
             ],
             data_source_kind=EDataSourceKind.CLICKHOUSE,
@@ -207,50 +277,8 @@ def _primitive_types(self) -> Sequence[TestCase]:
             check_output_schema=True,
         )
 
-        # ClickHouse returns different data if columns are Nullable
-        schema_nullable = Schema(columns=ColumnList())
-        data_in_nullable = [[]]
-        data_out_nullable = [[]]
-
-        for i, col in enumerate(schema.columns):
-            ch_type = col.data_source_type.ch
-
-            # copy type and example value to new TestCase
-            schema_nullable.columns.append(
-                Column(
-                    name=col.name,
-                    ydb_type=makeOptionalYdbTypeFromYdbType(col.ydb_type),
-                    data_source_type=DataSourceType(ch=ch_type.to_nullable()),
-                )
-            )
-            data_in_nullable[0].append(tc.data_in[0][i])
-            data_out_nullable[0].append(tc.data_out_[0][i])
-
-        # Add row containing only NULL values
-        data_in_nullable.append([None] * len(data_in_nullable[0]))
-        data_out_nullable.append([None] * len(data_out_nullable[0]))
-
-        # for the sake of CH output sorting
-        data_in_nullable[1][0] = data_out_nullable[1][0] = True
-
-        test_case_name_nullable = 'primitive_types_nullable'
-
-        tc_nullable = TestCase(
-            name_=test_case_name_nullable,
-            schema=schema_nullable,
-            select_what=SelectWhat.asterisk(schema_nullable.columns),
-            select_where=None,
-            data_source_kind=EDataSourceKind.CLICKHOUSE,
-            data_in=data_in_nullable,
-            data_out_=data_out_nullable,
-            protocol=EProtocol.NATIVE,
-            pragmas=dict(),
-            check_output_schema=True,
-        )
-
         return [
             tc,
-            tc_nullable,
         ]
 
     def _constant(self) -> Sequence[TestCase]:
@@ -261,9 +289,9 @@ def _constant(self) -> Sequence[TestCase]:
         schema = Schema(
             columns=ColumnList(
                 Column(
-                    name='col',
-                    ydb_type=Type.INT64,
-                    data_source_type=DataSourceType(ch=clickhouse.Int64()),
+                    name='id',
+                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),
+                    data_source_type=DataSourceType(ch=clickhouse.Int32()),
                 ),
             )
         )
@@ -275,17 +303,7 @@ def _constant(self) -> Sequence[TestCase]:
             schema=schema,
             select_what=SelectWhat(SelectWhat.Item(name='42', kind='expr')),
             select_where=None,
-            data_in=[
-                [
-                    1,
-                ],
-                [
-                    2,
-                ],
-                [
-                    3,
-                ],
-            ],
+            data_in=None,
             data_out_=[
                 [
                     42,
@@ -304,7 +322,7 @@ def _constant(self) -> Sequence[TestCase]:
 
         return [tc]
 
-    def _count(self) -> Sequence[TestCase]:
+    def _counts(self) -> Sequence[TestCase]:
         '''
         In this test case set we check SELECT COUNT(*) from a ch table.
         '''
@@ -313,33 +331,20 @@ def _count(self) -> Sequence[TestCase]:
             columns=ColumnList(
                 Column(
                     name='col',
-                    ydb_type=Type.FLOAT,
+                    ydb_type=makeYdbTypeFromTypeID(Type.FLOAT),
                     data_source_type=DataSourceType(ch=clickhouse.Float64()),
                 ),
             )
         )
 
-        test_case_name = 'count'
+        test_case_name = 'counts'
 
         tc = TestCase(
             name_=test_case_name,
             schema=schema,
             select_what=SelectWhat(SelectWhat.Item(name='COUNT(*)', kind='expr')),
             select_where=None,
-            data_in=[
-                [
-                    3.14,
-                ],
-                [
-                    1.0,
-                ],
-                [
-                    2.718,
-                ],
-                [
-                    -0.0,
-                ],
-            ],
+            data_in=None,
             data_out_=[
                 [
                     4,
@@ -348,6 +353,7 @@ def _count(self) -> Sequence[TestCase]:
             protocol=EProtocol.NATIVE,
             data_source_kind=EDataSourceKind.CLICKHOUSE,
             pragmas=dict(),
+            check_output_schema=False,  # because the aggregate's value has other type
         )
 
         return [tc]
@@ -356,33 +362,18 @@ def _pushdown(self) -> TestCase:
         schema = Schema(
             columns=ColumnList(
                 Column(
-                    name='col_int32',
-                    ydb_type=Type.INT32,
+                    name='col_00_int32',
+                    ydb_type=makeYdbTypeFromTypeID(Type.INT32),
                     data_source_type=DataSourceType(ch=clickhouse.Int32()),
                 ),
                 Column(
-                    name='col_string',
-                    ydb_type=Type.UTF8,
+                    name='col_01_string',
+                    ydb_type=makeOptionalYdbTypeFromTypeID(Type.STRING),
                     data_source_type=DataSourceType(ch=clickhouse.String()),
                 ),
             ),
         )
 
-        data_in = [
-            [
-                1,
-                'one',
-            ],
-            [
-                2,
-                'two',
-            ],
-            [
-                3,
-                'three',
-            ],
-        ]
-
         data_out = [
             ['one'],
         ]
@@ -393,14 +384,16 @@ def _pushdown(self) -> TestCase:
         return [
             TestCase(
                 name_=test_case_name,
-                data_in=data_in,
+                data_in=None,
                 data_out_=data_out,
                 pragmas=dict({'generic.UsePredicatePushdown': 'true'}),
-                select_what=SelectWhat(SelectWhat.Item(name='col_string')),
-                select_where=SelectWhere('col_int32 = 1'),
+                select_what=SelectWhat(SelectWhat.Item(name='col_01_string')),
+                select_where=SelectWhere('col_00_int32 = 1'),
                 data_source_kind=data_source_kind,
                 protocol=EProtocol.NATIVE,
                 schema=schema,
+                # TODO: implement schema checkswhen selecting only one column
+                check_output_schema=False,
             )
         ]
 
@@ -409,9 +402,10 @@ def make_test_cases(self) -> Sequence[TestCase]:
 
         base_test_cases = list(
             itertools.chain(
-                self._primitive_types(),
+                self._primitive_types_non_nullable(),
+                self._primitive_types_nullable(),
                 self._constant(),
-                self._count(),
+                self._counts(),
                 self._pushdown(),
             )
         )
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/test.py b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/test.py
index 91f0d5bde55e..ab690a43f2d7 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/test.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/clickhouse/test.py
@@ -1,10 +1,10 @@
 import pytest
 
 from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
-from ydb.library.yql.providers.generic.connector.tests.utils.clients.clickhouse import Client
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
 from ydb.library.yql.providers.generic.connector.tests.utils.run.runners import runner_types, configure_runner
 import ydb.library.yql.providers.generic.connector.tests.utils.scenario.clickhouse as scenario
+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter
 
 from conftest import docker_compose_dir
 from collection import Collection
@@ -13,6 +13,26 @@
 import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_missing_table as select_missing_table
 import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_positive_common as select_positive_common
 
+one_time_waiter = OneTimeWaiter(
+    data_source_kind=EDataSourceKind.CLICKHOUSE,
+    docker_compose_file_path=str(docker_compose_dir / 'docker-compose.yml'),
+    expected_tables=[
+        "column_selection_A_b_C_d_E",
+        "column_selection_COL1",
+        "column_selection_asterisk",
+        "column_selection_col2",
+        "column_selection_col2_COL1",
+        "column_selection_col3",
+        "constant",
+        "counts",
+        "datetime_YQL",
+        "datetime_string",
+        "large",
+        "primitive_types_non_nullable",
+        "primitive_types_nullable",
+        "pushdown",
+    ],
+)
 
 # Global collection of test cases dependent on environment
 tc_collection = Collection(
@@ -23,18 +43,14 @@
 @pytest.mark.parametrize("runner_type", runner_types)
 @pytest.mark.parametrize("test_case", tc_collection.get('select_positive'), ids=tc_collection.ids('select_positive'))
 @pytest.mark.usefixtures("settings")
-@pytest.mark.usefixtures("clickhouse_client")
 def test_select_positive(
     request: pytest.FixtureRequest,
     settings: Settings,
     runner_type: str,
-    clickhouse_client: Client,
     test_case: select_positive_common.TestCase,
 ):
     runner = configure_runner(runner_type=runner_type, settings=settings)
-    scenario.select_positive(
-        test_name=request.node.name, settings=settings, runner=runner, client=clickhouse_client, test_case=test_case
-    )
+    scenario.select_positive(test_name=request.node.name, settings=settings, runner=runner, test_case=test_case)
 
 
 @pytest.mark.parametrize("runner_type", runner_types)
@@ -49,7 +65,7 @@ def test_select_missing_database(
     test_case: select_missing_database.TestCase,
 ):
     runner = configure_runner(runner_type=runner_type, settings=settings)
-    scenario.select_missing_database(
+    scenario.select_missing_table(
         settings=settings,
         runner=runner,
         test_case=test_case,
@@ -62,12 +78,10 @@ def test_select_missing_database(
     "test_case", tc_collection.get('select_missing_table'), ids=tc_collection.ids('select_missing_table')
 )
 @pytest.mark.usefixtures("settings")
-@pytest.mark.usefixtures("clickhouse_client")
 def test_select_missing_table(
     request: pytest.FixtureRequest,
     settings: Settings,
     runner_type: str,
-    clickhouse_client: Client,
     test_case: select_missing_table.TestCase,
 ):
     runner = configure_runner(runner_type=runner_type, settings=settings)
@@ -75,7 +89,6 @@ def test_select_missing_table(
         test_name=request.node.name,
         settings=settings,
         runner=runner,
-        client=clickhouse_client,
         test_case=test_case,
     )
 
@@ -83,12 +96,10 @@ def test_select_missing_table(
 @pytest.mark.parametrize("runner_type", runner_types)
 @pytest.mark.parametrize("test_case", tc_collection.get('select_datetime'), ids=tc_collection.ids('select_datetime'))
 @pytest.mark.usefixtures("settings")
-@pytest.mark.usefixtures("clickhouse_client")
 def test_select_datetime(
     request: pytest.FixtureRequest,
     settings: Settings,
     runner_type: str,
-    clickhouse_client: Client,
     test_case: select_positive_common.TestCase,
 ):
     runner = configure_runner(runner_type=runner_type, settings=settings)
@@ -97,5 +108,4 @@ def test_select_datetime(
         test_case=test_case,
         settings=settings,
         runner=runner,
-        client=clickhouse_client,
     )
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_datetime.py b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_datetime.py
index ae90599fca27..21db4ef79157 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_datetime.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_datetime.py
@@ -80,7 +80,13 @@ def _make_test_yql(self) -> TestCase:
                 datetime.datetime(2023, 3, 21, 11, 21, 31, 0),
                 datetime.datetime(2023, 3, 21, 11, 21, 31, 0),
             ],
-            [3, None, None, None, None],
+            [
+                3,
+                datetime.date(2079, 6, 6),
+                datetime.datetime(2079, 6, 6, 23, 59),
+                datetime.datetime(2079, 6, 7, 0, 0),
+                None,
+            ],
         ]
 
         return TestCase(
@@ -112,7 +118,13 @@ def _make_test_string(self) -> TestCase:
                 '2023-03-21T11:21:31Z',
                 '2023-03-21T11:21:31Z',
             ],
-            [3, '2079-06-06', '2079-06-06T23:59:00Z', '2079-06-06T23:59:59.999Z', '2079-06-06T23:59:59.9999999Z'],
+            [
+                3,
+                '2079-06-06',
+                '2079-06-06T23:59:00Z',
+                '2079-06-07T00:00:00Z',  # For a some reason server rounds it to the first second of the next day
+                '9999-12-31T23:59:59.9999999Z',
+            ],
         ]
 
         return TestCase(
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_positive.py b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_positive.py
index e179687b649f..ce729a234ab7 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_positive.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/select_positive.py
@@ -197,10 +197,10 @@ def _primitive_types(self) -> Sequence[TestCase]:
                     -5,
                     -6.6,
                     -7.7,
-                    'буки',
-                    'буки',
-                    'буки',
-                    'буки',
+                    '????    ',
+                    '????',
+                    '????',
+                    'буки    ',
                     'буки',
                     'буки',
                     'b\x00\x00\x00\x00\x00\x00\x00',
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/test.py b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/test.py
index efaa5377a4e4..57ac2806b79b 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/test.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/ms_sql_server/test.py
@@ -1,13 +1,7 @@
-from typing import Set
-from datetime import datetime
-import time
-
 import pytest
 
-import yatest.common
-
 from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
-from ydb.library.yql.providers.generic.connector.tests.utils.docker_compose import DockerComposeHelper
+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter
 from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger
 from ydb.library.yql.providers.generic.connector.tests.utils.run.runners import runner_types, configure_runner
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
@@ -28,11 +22,10 @@
     Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.MS_SQL_SERVER])
 )
 
-
-class OneTimeWaiter:
-    __launched: bool = False
-
-    __expected_tables: Set[str] = {
+one_time_waiter = OneTimeWaiter(
+    data_source_kind=EDataSourceKind.MS_SQL_SERVER,
+    docker_compose_file_path=str(docker_compose_dir / 'docker-compose.yml'),
+    expected_tables=[
         'column_selection_A_b_C_d_E',
         'column_selection_col1',
         'column_selection_asterisk',
@@ -44,36 +37,8 @@ class OneTimeWaiter:
         'count_rows',
         'pushdown',
         'datetimes',
-    }
-
-    def __init__(self):
-        docker_compose_file_relative_path = str(docker_compose_dir / 'docker-compose.yml')
-        docker_compose_file_abs_path = yatest.common.source_path(docker_compose_file_relative_path)
-        self.docker_compose_helper = DockerComposeHelper(docker_compose_yml_path=docker_compose_file_abs_path)
-
-    def wait(self):
-        if self.__launched:
-            return
-
-        start = datetime.now()
-        actual_tables: Set[str] = None
-        timeout = 600
-
-        while (datetime.now() - start).total_seconds() < timeout:
-            try:
-                actual_tables = set(self.docker_compose_helper.list_ms_sql_server_tables())
-            except Exception as e:
-                LOGGER.error(f"list ms_sql_server tables error: {e}")
-                time.sleep(5)
-            else:
-                if self.__expected_tables.issubset(actual_tables):
-                    self.__launched = True
-                    return
-
-        raise RuntimeError(f"No expected tables in ms_sql_server. Latest result: {actual_tables}")
-
-
-one_time_waiter = OneTimeWaiter()
+    ],
+)
 
 
 @pytest.mark.parametrize("runner_type", runner_types)
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/select_datetime.py b/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/select_datetime.py
index 3b6c95cdd99e..8cad456b187a 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/select_datetime.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/select_datetime.py
@@ -76,9 +76,9 @@ def _make_test_yql(self) -> TestCase:
             # [3, '2038-01-19', '2038-01-19T03:14:07.000000Z', '2038-01-19T03:14:07.000009Z'],
             [
                 3,
-                datetime.date(2038, 1, 18),
-                datetime.datetime(2038, 1, 19, 3, 14, 7, 0),
+                datetime.date(2038, 1, 19),
                 datetime.datetime(2038, 1, 19, 3, 14, 7, 0),
+                datetime.datetime(2038, 1, 19, 3, 14, 7, 9),
             ],
             [4, None, None, None],
         ]
@@ -107,10 +107,10 @@ def _make_test_string(self) -> TestCase:
             [
                 2,
                 '1988-11-20',
-                '1988-11-20T12:23:45.67891',
-                '1988-11-20T12:23:45.67891Z',
+                '1988-11-20T12:55:28.123',
+                '1988-11-20T12:55:28.123Z',
             ],
-            [3, '2038-01-19', '2038-01-19T03:14:07.000000', '2038-01-19T03:14:07.000009Z'],
+            [3, '2038-01-19', '2038-01-19T03:14:07', '2038-01-19T03:14:07.000009Z'],
             [4, '9999-12-31', '9999-12-31T23:59:59.999999', None],
         ]
 
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/test.py b/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/test.py
index b1d192dc8aa2..78203acf53fe 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/test.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/mysql/test.py
@@ -1,13 +1,7 @@
-from typing import Set
-from datetime import datetime
-import time
-
 import pytest
 
-import yatest.common
-
 from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
-from ydb.library.yql.providers.generic.connector.tests.utils.docker_compose import DockerComposeHelper
+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter
 from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger
 from ydb.library.yql.providers.generic.connector.tests.utils.run.runners import runner_types, configure_runner
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
@@ -22,17 +16,10 @@
 
 LOGGER = make_logger(__name__)
 
-
-# Global collection of test cases dependent on environment
-tc_collection = Collection(
-    Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.MYSQL])
-)
-
-
-class OneTimeWaiter:
-    __launched: bool = False
-
-    __expected_tables: Set[str] = {
+one_time_waiter = OneTimeWaiter(
+    data_source_kind=EDataSourceKind.MYSQL,
+    docker_compose_file_path=str(docker_compose_dir / 'docker-compose.yml'),
+    expected_tables=[
         'column_selection_A_b_C_d_E',
         'column_selection_COL1',
         'column_selection_col1',
@@ -47,36 +34,13 @@ class OneTimeWaiter:
         'pushdown',
         'json',
         'datetimes',
-    }
-
-    def __init__(self):
-        docker_compose_file_relative_path = str(docker_compose_dir / 'docker-compose.yml')
-        docker_compose_file_abs_path = yatest.common.source_path(docker_compose_file_relative_path)
-        self.docker_compose_helper = DockerComposeHelper(docker_compose_yml_path=docker_compose_file_abs_path)
-
-    def wait(self):
-        if self.__launched:
-            return
-
-        start = datetime.now()
-        actual_tables: Set[str] = None
-        timeout = 600
-
-        while (datetime.now() - start).total_seconds() < timeout:
-            try:
-                actual_tables = set(self.docker_compose_helper.list_mysql_tables())
-            except Exception as e:
-                LOGGER.error(f"list mysql tables error: {e}")
-                time.sleep(5)
-            else:
-                if self.__expected_tables.issubset(actual_tables):
-                    self.__launched = True
-                    return
-
-        raise RuntimeError(f"No expected tables in MySQL. Latest result: {actual_tables}")
-
+    ],
+)
 
-one_time_waiter = OneTimeWaiter()
+# Global collection of test cases dependent on environment
+tc_collection = Collection(
+    Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.MYSQL])
+)
 
 
 @pytest.mark.parametrize("runner_type", runner_types)
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_datetime_with_service_name.py b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_datetime_with_service_name.py
index b3784d3e6efd..cf0cca4ec14f 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_datetime_with_service_name.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_datetime_with_service_name.py
@@ -108,9 +108,9 @@ def _make_test_string(self) -> TestCase:
             [
                 2,
                 '1988-11-20T12:55:28Z',
-                '1988-11-20T12:55:28.123000Z',
+                '1988-11-20T12:55:28.123Z',
             ],
-            [3, '2038-01-19T03:14:07Z', '2038-01-19T03:14:07.000000Z'],
+            [3, '2038-01-19T03:14:07Z', '2038-01-19T03:14:07Z'],
             [4, '9999-12-31T23:59:59Z', '9999-12-31T23:59:59.999999Z'],
         ]
 
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_positive_with_service_name.py b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_positive_with_service_name.py
index 0b8bbb22c83f..54b4a9be3383 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_positive_with_service_name.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/select_positive_with_service_name.py
@@ -246,7 +246,7 @@ def _primitive_types(self) -> Sequence[TestCase]:
                     datetime.datetime(1970, 1, 1, 0, 0, 0, 000000),
                     datetime.datetime(1970, 1, 1, 1, 1, 1, 111111),
                     datetime.datetime(1970, 1, 1, 2, 1, 1, 111111),
-                    datetime.datetime(1970, 1, 1, 2, 2, 12, 111111),
+                    datetime.datetime(1970, 1, 1, 2, 12, 1, 111111),
                     '{ "TODO" : "unicode" }',
                 ],
             ],
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/test.py b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/test.py
index 2787be4cd138..8c57b8bce1a9 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/test.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/oracle/test.py
@@ -1,13 +1,7 @@
-from typing import Set
-from datetime import datetime
-import time
-
 import pytest
 
-import yatest.common
-
 from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
-from ydb.library.yql.providers.generic.connector.tests.utils.docker_compose import DockerComposeHelper
+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter
 from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger
 from ydb.library.yql.providers.generic.connector.tests.utils.run.runners import runner_types, configure_runner
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
@@ -29,11 +23,10 @@
     Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.ORACLE])
 )
 
-
-class OneTimeWaiter:
-    __launched: bool = False
-
-    __expected_tables: Set[str] = {
+one_time_waiter = OneTimeWaiter(
+    data_source_kind=EDataSourceKind.ORACLE,
+    docker_compose_file_path=str(docker_compose_dir / 'docker-compose.yml'),
+    expected_tables=[
         'column_selection_A_b_C_d_E',
         'column_selection_COL1',
         'column_selection_col1',
@@ -50,40 +43,8 @@ class OneTimeWaiter:
         'DATETIMES',
         'LONGRAW',
         'LONG_TABLE',
-    }
-
-    def __init__(self):
-        docker_compose_file_relative_path = str(docker_compose_dir / 'docker-compose.yml')
-        docker_compose_file_abs_path = yatest.common.source_path(docker_compose_file_relative_path)
-        self.docker_compose_helper = DockerComposeHelper(docker_compose_yml_path=docker_compose_file_abs_path)
-
-    def wait(self):
-        if self.__launched:
-            return
-
-        start = datetime.now()
-        actual_tables: Set[str] = None
-        timeout = 600
-
-        while (datetime.now() - start).total_seconds() < timeout:
-            try:
-                actual_tables = set(self.docker_compose_helper.list_oracle_tables())
-            except Exception as e:
-                LOGGER.error(f"list oracle tables error: {e}")
-                time.sleep(5)
-            else:
-                if self.__expected_tables.issubset(actual_tables):
-                    self.__launched = True
-                    return
-
-        raise RuntimeError(
-            f"No expected tables in Oracle. Latest result: {actual_tables},  "
-            + f"extra tables loaded: {actual_tables - set(self.__expected_tables)}, "
-            + f"did not found tables: {set(self.__expected_tables) - actual_tables}"
-        )
-
-
-one_time_waiter = OneTimeWaiter()
+    ],
+)
 
 
 @pytest.mark.parametrize("runner_type", runner_types)
diff --git a/ydb/library/yql/providers/generic/connector/tests/datasource/ydb/test.py b/ydb/library/yql/providers/generic/connector/tests/datasource/ydb/test.py
index 4749559fdb82..f47c08a0e733 100644
--- a/ydb/library/yql/providers/generic/connector/tests/datasource/ydb/test.py
+++ b/ydb/library/yql/providers/generic/connector/tests/datasource/ydb/test.py
@@ -3,6 +3,7 @@
 from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
 from ydb.library.yql.providers.generic.connector.tests.utils.run.runners import runner_types, configure_runner
+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter
 import ydb.library.yql.providers.generic.connector.tests.utils.scenario.ydb as scenario
 import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_positive_common as select_positive_common
 
@@ -12,7 +13,8 @@
 from conftest import docker_compose_dir
 from collection import Collection
 
-one_time_waiter = scenario.OneTimeWaiter(
+one_time_waiter = OneTimeWaiter(
+    data_source_kind=EDataSourceKind.YDB,
     docker_compose_file_path=str(docker_compose_dir / 'docker-compose.yml'),
     expected_tables=[
         "column_selection_A_b_C_d_E",
@@ -29,7 +31,7 @@
         "unsupported_types",
         "json",
         "dummy_table",
-    ]
+    ],
 )
 
 settings = Settings.from_env(docker_compose_dir=docker_compose_dir, data_source_kinds=[EDataSourceKind.YDB])
diff --git a/ydb/library/yql/providers/generic/connector/tests/join/conftest.py b/ydb/library/yql/providers/generic/connector/tests/join/conftest.py
index 19caea7afe9f..a2d90087ea6e 100644
--- a/ydb/library/yql/providers/generic/connector/tests/join/conftest.py
+++ b/ydb/library/yql/providers/generic/connector/tests/join/conftest.py
@@ -5,10 +5,6 @@
 import pytest
 
 from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
-from ydb.library.yql.providers.generic.connector.tests.utils.clients.clickhouse import (
-    make_client as make_clickhouse_client,
-    Client as ClickHouseClient,
-)
 from ydb.library.yql.providers.generic.connector.tests.utils.clients.postgresql import Client as PostgreSQLClient
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
 
@@ -24,15 +20,14 @@ def settings() -> Settings:
     )
 
 
+# TODO: avoid using clients, initialize
 @dataclasses.dataclass
 class Clients:
-    ClickHouse: ClickHouseClient
     PostgreSQL: PostgreSQLClient
 
 
 @pytest.fixture
 def clients(settings):
     return Clients(
-        ClickHouse=make_clickhouse_client(settings=settings.clickhouse),
         PostgreSQL=PostgreSQLClient(settings=settings.postgresql),
     )
diff --git a/ydb/library/yql/providers/generic/connector/tests/join/docker-compose.yml b/ydb/library/yql/providers/generic/connector/tests/join/docker-compose.yml
index 0759c852a759..25da5dd1dfd8 100644
--- a/ydb/library/yql/providers/generic/connector/tests/join/docker-compose.yml
+++ b/ydb/library/yql/providers/generic/connector/tests/join/docker-compose.yml
@@ -6,7 +6,10 @@ services:
       CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
       CLICKHOUSE_PASSWORD: password
       CLICKHOUSE_USER: user
-    image: mirror.gcr.io/clickhouse/clickhouse-server:23-alpine@sha256:d75017307e76d1bca81a5ac7ada94620567782c0610541f525d1e443e23f76e3
+      CLICKHOUSE_ALWAYS_RUN_INITDB_SCRIPTS: 1
+    image: mirror.gcr.io/clickhouse/clickhouse-server:24.3.12-alpine@sha256:65e5846a0d9672714f2625502b27846563f6d01ec226304cf851aa49004ffde8
+    volumes:
+      - ./init/clickhouse:/docker-entrypoint-initdb.d
     ports:
       - 9000
       - 8123
diff --git a/ydb/library/yql/providers/generic/connector/tests/join/init/clickhouse/init_db.sh b/ydb/library/yql/providers/generic/connector/tests/join/init/clickhouse/init_db.sh
new file mode 100644
index 000000000000..4f0454966a39
--- /dev/null
+++ b/ydb/library/yql/providers/generic/connector/tests/join/init/clickhouse/init_db.sh
@@ -0,0 +1,45 @@
+#!/bin/bash
+set -ex
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.example_1;
+    CREATE TABLE db.example_1 (
+        id Int32,
+        col1 String,
+        col2 Int32
+    ) ENGINE = MergeTree ORDER BY id;
+    INSERT INTO db.example_1 (*) VALUES
+        (1, 'example_1_a', 10) \
+        (2, 'example_1_b', 20) \
+        (3, 'example_1_c', 30) \
+        (4, 'example_1_d', 40) \
+        (5, 'example_1_e', 50);
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.example_2;
+    CREATE TABLE db.example_2 (
+        id Int32,
+        col2 Int32,
+        col1 String
+    ) ENGINE = MergeTree ORDER BY id;
+    INSERT INTO db.example_2 (*) VALUES
+        (1, 2, 'example_2_a') \
+        (2, 4, 'example_2_b') \
+        (3, 8, 'example_2_c') \
+        (4, 16, 'example_2_d') \
+        (5, 32, 'example_2_e');
+EOSQL
+
+clickhouse-client -n <<-EOSQL
+    DROP TABLE IF EXISTS db.test_1;
+    CREATE TABLE db.test_1 (
+        id Int32,
+    ) ENGINE = MergeTree ORDER BY id;
+    INSERT INTO db.test_1 (*) VALUES
+        (1) \
+        (2) \
+        (3) \
+        (4) \
+        (5);
+EOSQL
\ No newline at end of file
diff --git a/ydb/library/yql/providers/generic/connector/tests/join/scenario.py b/ydb/library/yql/providers/generic/connector/tests/join/scenario.py
index 2b8941d1fcc2..156ceb8cabd6 100644
--- a/ydb/library/yql/providers/generic/connector/tests/join/scenario.py
+++ b/ydb/library/yql/providers/generic/connector/tests/join/scenario.py
@@ -4,8 +4,6 @@
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
 from ydb.library.yql.providers.generic.connector.tests.utils.run.parent import Runner
 
-from ydb.library.yql.providers.generic.connector.tests.utils.clients.clickhouse import Client as ClickHouseClient
-import ydb.library.yql.providers.generic.connector.tests.utils.scenario.clickhouse as clickhouse_scenario
 from ydb.library.yql.providers.generic.connector.tests.utils.clients.postgresql import Client as PostgreSQLClient
 import ydb.library.yql.providers.generic.connector.tests.utils.scenario.postgresql as postgresql_scenario
 
@@ -19,21 +17,14 @@ def join(
     test_case: TestCase,
     settings: Settings,
     runner: Runner,
-    clickhouse_client: ClickHouseClient,
     postgresql_client: PostgreSQLClient,
 ):
     # prepare tables
     for data_source in test_case.data_sources:
         match data_source.kind:
             case EDataSourceKind.CLICKHOUSE:
-                clickhouse_scenario.prepare_table(
-                    test_name=test_name,
-                    client=clickhouse_client,
-                    database=data_source.database,
-                    table_name=data_source.table.name,
-                    data_in=data_source.table.data_in,
-                    schema=data_source.table.schema,
-                )
+                # do nothing as tables are initialized via init scripts
+                continue
             case EDataSourceKind.POSTGRESQL:
                 postgresql_scenario.prepare_table(
                     test_name=test_name,
@@ -44,14 +35,14 @@ def join(
                     schema=data_source.table.schema,
                 )
             case _:
-                raise Exception(f'invalid data source: {test_case.data_source_kind}')
+                raise Exception(f'invalid data source: {data_source.kind}')
 
     # run join
     yql_script = test_case.make_sql(settings)
 
     result = runner.run(test_name=test_name, script=yql_script, generic_settings=test_case.generic_settings)
 
-    assert result.returncode == 0, result.stderr
+    assert result.returncode == 0, result.output
 
     assert_data_outs_equal(test_case.data_out, result.data_out_with_types), (
         test_case.data_out,
diff --git a/ydb/library/yql/providers/generic/connector/tests/join/test.py b/ydb/library/yql/providers/generic/connector/tests/join/test.py
index 8af6b76f5a2a..7623c10922ff 100644
--- a/ydb/library/yql/providers/generic/connector/tests/join/test.py
+++ b/ydb/library/yql/providers/generic/connector/tests/join/test.py
@@ -32,7 +32,6 @@ def test_join(
     runner = configure_runner(runner_type=runner_type, settings=settings)
     scenario.join(
         test_name=request.node.name,
-        clickhouse_client=clients.ClickHouse,
         postgresql_client=clients.PostgreSQL,
         runner=runner,
         settings=settings,
diff --git a/ydb/library/yql/providers/generic/connector/tests/join/test_case.py b/ydb/library/yql/providers/generic/connector/tests/join/test_case.py
index e10bad53372c..ca0d0a0474ed 100644
--- a/ydb/library/yql/providers/generic/connector/tests/join/test_case.py
+++ b/ydb/library/yql/providers/generic/connector/tests/join/test_case.py
@@ -1,6 +1,6 @@
 import itertools
 from dataclasses import dataclass
-from typing import Sequence
+from typing import Sequence, Final
 
 from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind, EProtocol
 from ydb.library.yql.providers.generic.connector.api.service.protos.connector_pb2 import EDateTimeFormat
@@ -119,7 +119,7 @@ def make_sql(self, settings: Settings) -> str:
 
 
 class Factory:
-    _id_column: Column = Column(
+    _id_column: Final = Column(
         name='id',
         ydb_type=Type.INT32,
         data_source_type=DataSourceType(ch=clickhouse.Int32(), pg=postgresql.Serial()),
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/clients/clickhouse.py b/ydb/library/yql/providers/generic/connector/tests/utils/clients/clickhouse.py
deleted file mode 100644
index c23aa6f2cf9b..000000000000
--- a/ydb/library/yql/providers/generic/connector/tests/utils/clients/clickhouse.py
+++ /dev/null
@@ -1,32 +0,0 @@
-from typing import TypeAlias
-from datetime import datetime
-import sys
-import time
-
-import clickhouse_connect
-from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
-
-Client: TypeAlias = clickhouse_connect.driver.client.Client
-
-
-def make_client(settings: Settings.ClickHouse) -> Client:
-    start = datetime.now()
-    attempt = 0
-
-    while (datetime.now() - start).total_seconds() < 60:
-        attempt += 1
-        try:
-            client = clickhouse_connect.get_client(
-                host=settings.host_external,
-                port=settings.http_port_external,
-                username=settings.username,
-                password=settings.password,
-            )
-        except Exception as e:
-            sys.stderr.write(f"attempt #{attempt}: {e}
")
-            time.sleep(5)
-            continue
-
-        return client
-
-    raise Exception(f"Failed to connect ClickHouse in {attempt} attempt(s)")
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/clients/ya.make b/ydb/library/yql/providers/generic/connector/tests/utils/clients/ya.make
index e70e7d084f2d..bfce2117a13c 100644
--- a/ydb/library/yql/providers/generic/connector/tests/utils/clients/ya.make
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/clients/ya.make
@@ -6,15 +6,11 @@ IF (AUTOCHECK)
 ENDIF()
 
 PY_SRCS(
-    clickhouse.py
     postgresql.py
-    ydb.py
 )
 
 PEERDIR(
-    contrib/python/clickhouse-connect
     contrib/python/pg8000
-    ydb/public/sdk/python
     ydb/library/yql/providers/generic/connector/tests/utils
 )
 
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/clients/ydb.py b/ydb/library/yql/providers/generic/connector/tests/utils/clients/ydb.py
deleted file mode 100644
index f4e2345789ed..000000000000
--- a/ydb/library/yql/providers/generic/connector/tests/utils/clients/ydb.py
+++ /dev/null
@@ -1,10 +0,0 @@
-import ydb
-from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
-
-
-def make_client(s: Settings.Ydb) -> ydb.Driver:
-    endpoint = f"grpc://{s.host_external}:{s.port_external}"
-
-    driver = ydb.Driver(endpoint=endpoint, database=s.dbname, credentials=ydb.AnonymousCredentials())
-    driver.wait(timeout=5)
-    return driver
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/comparator.py b/ydb/library/yql/providers/generic/connector/tests/utils/comparator.py
index 56ccc85e6120..7a02fb2b5506 100644
--- a/ydb/library/yql/providers/generic/connector/tests/utils/comparator.py
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/comparator.py
@@ -21,6 +21,9 @@ def jsons_are_equal(lhs: str, rhs: str) -> bool:
 
 
 def assert_rows_equal(expected: List, actual: List):
+    if not isinstance(expected, list) or not isinstance(actual, list):
+        raise ValueError(f'Expected two lists, got {expected} and {actual}')
+
     assert len(expected) == len(actual), (
         f'Columns amount mismatch expected: {len(expected)} actual: {len(actual)}',
         expected,
@@ -29,7 +32,7 @@ def assert_rows_equal(expected: List, actual: List):
 
     for i in range(len(expected)):
         if type(expected[i]) is float:
-            assert isclose(expected[i], actual[i], abs_tol=1e-5), (expected[i], actual[i])
+            assert isclose(expected[i], actual[i], abs_tol=1e-4), (expected[i], actual[i])
             continue
 
         if is_json(expected[i]):
@@ -43,8 +46,9 @@ def assert_data_outs_equal(
     expected: List,
     actual: List,
 ):
-    assert len(expected) == len(actual)
-    all(map(assert_rows_equal, expected, actual))
+    assert len(expected) == len(actual), ("Row size mismatch", expected, actual)
+    for i in range(len(expected)):
+        assert_rows_equal(expected[i], actual[i]), (f"Error at row {i}", expected[i], actual[i])
 
 
 def assert_schemas_equal(expected: Schema, actual: Schema):
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/database.py b/ydb/library/yql/providers/generic/connector/tests/utils/database.py
index 3a6a711b3c3b..82b2f50139a7 100644
--- a/ydb/library/yql/providers/generic/connector/tests/utils/database.py
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/database.py
@@ -16,7 +16,8 @@ def __init__(self, name: str, kind: EDataSourceKind.ValueType):
                 # so we'd better make it first on our own
                 self.name = name[:63].lower()
             case EDataSourceKind.CLICKHOUSE:
-                self.name = name[:255]
+                # We use preinitialized database when working with ClickHouse.
+                self.name = "db"
             case EDataSourceKind.MS_SQL_SERVER:
                 # For this kind of database this name is provided by the external logic
                 self.name = name
@@ -28,31 +29,32 @@ def __init__(self, name: str, kind: EDataSourceKind.ValueType):
                 # therefore, we'd better use uppercase for ease of testing
                 self.name = name[:127].upper()  # TODO: is it needed? max length of Oracle table name is 128 bytes/chars
             case EDataSourceKind.YDB:
-                # For this kind of database this name is provided by the external logic
-                self.name = name
+                # We use preinitialized database when working with YDB.
+                self.name = "local"
             case _:
                 raise Exception(f'invalid data source: {self.kind}')
 
-    def query_exists(self) -> str:
+    def exists(self) -> str:
         match self.kind:
             case EDataSourceKind.POSTGRESQL:
                 return f"SELECT 1 FROM pg_database WHERE datname = '{self.name}'"
             case _:
                 raise Exception(f'invalid data source: {self.kind}')
 
-    def query_create(self) -> str:
+    def create(self) -> str:
         match self.kind:
-            case EDataSourceKind.CLICKHOUSE:
-                return f"CREATE DATABASE IF NOT EXISTS {self.name} ENGINE = Memory"
             case EDataSourceKind.POSTGRESQL:
                 return f"CREATE DATABASE {self.name}"
             case _:
                 raise Exception(f'invalid data source: {self.kind}')
 
+    def sql_table_name(self, table_name: str) -> str:
+        return table_name
+
     def missing_database_msg(self) -> str:
         match self.kind:
             case EDataSourceKind.CLICKHOUSE:
-                return f"Database {self.name} does not exist"
+                return f"Database {self.name} doesn't exist"
             case EDataSourceKind.POSTGRESQL:
                 return f'database "{self.name}" does not exist'
             case EDataSourceKind.YDB:
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/docker_compose.py b/ydb/library/yql/providers/generic/connector/tests/utils/docker_compose.py
index 0a32a963178b..19d308744e20 100644
--- a/ydb/library/yql/providers/generic/connector/tests/utils/docker_compose.py
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/docker_compose.py
@@ -9,6 +9,7 @@
 
 import yatest.common
 
+from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
 from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger
 
 LOGGER = make_logger(__name__)
@@ -110,7 +111,22 @@ def get_internal_ip(self, service_name: str) -> str:
     def get_container_name(self, service_name: str) -> str:
         return self.docker_compose_yml_data['services'][service_name]['container_name']
 
-    def list_ydb_tables(self) -> Sequence[str]:
+    def list_tables(self, dataSourceKind: EDataSourceKind) -> Sequence[str]:
+        match dataSourceKind:
+            case EDataSourceKind.CLICKHOUSE:
+                return self.list_clickhouse_tables()
+            case EDataSourceKind.YDB:
+                return self._list_ydb_tables()
+            case EDataSourceKind.MYSQL:
+                return self._list_mysql_tables()
+            case EDataSourceKind.MS_SQL_SERVER:
+                return self._list_ms_sql_server_tables()
+            case EDataSourceKind.ORACLE:
+                return self._list_oracle_tables()
+            case _:
+                raise ValueError("invalid data source kind: {dataSourceKind}")
+
+    def _list_ydb_tables(self) -> Sequence[str]:
         cmd = [
             self.docker_bin_path,
             'exec',
@@ -158,7 +174,7 @@ def list_ydb_tables(self) -> Sequence[str]:
 
         return result
 
-    def list_mysql_tables(self) -> Sequence[str]:
+    def _list_mysql_tables(self) -> Sequence[str]:
         params = self.docker_compose_yml_data["services"]["mysql"]
         password = params["environment"]["MYSQL_ROOT_PASSWORD"]
         db = params["environment"]["MYSQL_DATABASE"]
@@ -180,11 +196,12 @@ def list_mysql_tables(self) -> Sequence[str]:
         try:
             out = subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode('utf8')
         except subprocess.CalledProcessError as e:
-            raise RuntimeError(f"docker cmd failed: {e.output} (code {e.returncode})")
+            LOGGER.error(f"docker cmd failed: {e.output} (code {e.returncode})")
+            return []
         else:
             return out.splitlines()[2:]
 
-    def list_oracle_tables(self) -> Sequence[str]:
+    def _list_oracle_tables(self) -> Sequence[str]:
         params = self.docker_compose_yml_data["services"]["oracle"]
         password = params["environment"]["ORACLE_PWD"]
         username = params["environment"]["TEST_USER_NAME"]  # also serves as default sceheme name for user
@@ -199,12 +216,13 @@ def list_oracle_tables(self) -> Sequence[str]:
         try:
             out = subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode('utf8')
         except subprocess.CalledProcessError as e:
-            raise RuntimeError(f"docker cmd failed: {e.output} (code {e.returncode})")
+            LOGGER.error(f"docker cmd failed: {e.output} (code {e.returncode})")
+            return []
         else:
             lines = out.splitlines()
             return lines[3 : len(lines) - 3]
 
-    def list_ms_sql_server_tables(self) -> Sequence[str]:
+    def _list_ms_sql_server_tables(self) -> Sequence[str]:
         params = self.docker_compose_yml_data["services"]["ms_sql_server"]
         password = params["environment"]["SA_PASSWORD"]
         db = 'master'
@@ -233,7 +251,35 @@ def list_ms_sql_server_tables(self) -> Sequence[str]:
         try:
             out = subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode('utf8')
         except subprocess.CalledProcessError as e:
-            raise RuntimeError(f"docker cmd failed: {e.output} (code {e.returncode})")
+            LOGGER.error(f"docker cmd failed: {e.output} (code {e.returncode})")
+            return []
         else:
             lines = [x.strip() for x in out.splitlines()]
             return lines[3:]
+
+    def _list_clickhouse_server_tables(self) -> Sequence[str]:
+        params = self.docker_compose_yml_data["services"]["clickhouse"]
+        db = 'db'
+        cmd = [
+            self.docker_bin_path,
+            'exec',
+            params["container_name"],
+            'clickhouse-client',
+            '--database',
+            db,
+            '--query',
+            "SHOW TABLES;",
+        ]
+
+        LOGGER.debug("calling command: " + " ".join(cmd))
+
+        out = None
+
+        try:
+            out = subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode('utf8')
+        except subprocess.CalledProcessError as e:
+            LOGGER.error(f"docker cmd failed: {e.output} (code {e.returncode})")
+            return []
+        else:
+            lines = [x.strip() for x in out.splitlines()]
+            return lines
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/generate.py b/ydb/library/yql/providers/generic/connector/tests/utils/generate.py
index 879c7f43140e..f5bed5b67486 100644
--- a/ydb/library/yql/providers/generic/connector/tests/utils/generate.py
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/generate.py
@@ -16,11 +16,11 @@ def generate_table_data(schema: Schema, bytes_soft_limit: int) -> Sequence[Seque
         row = []
 
         for col in schema.columns:
-            match col.ydb_type:
-                case Type.INT64:
+            match col.ydb_type.type_id:
+                case Type.INT32:
                     row.append(ix)
-                    actual_size += 8
-                case Type.UTF8:
+                    actual_size += 4
+                case Type.STRING:
                     value = hashlib.md5(str(ix).encode('ascii')).hexdigest()
                     row.append(value)
                     actual_size += len(value)
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/one_time_waiter.py b/ydb/library/yql/providers/generic/connector/tests/utils/one_time_waiter.py
new file mode 100644
index 000000000000..3659b095beca
--- /dev/null
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/one_time_waiter.py
@@ -0,0 +1,49 @@
+from datetime import datetime
+from typing import Sequence
+import time
+
+import yatest.common
+
+from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
+from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger
+from ydb.library.yql.providers.generic.connector.tests.utils.docker_compose import DockerComposeHelper
+
+LOGGER = make_logger(__name__)
+
+
+class OneTimeWaiter:
+    __launched: bool = False
+
+    def __init__(
+        self,
+        docker_compose_file_path: str,
+        data_source_kind: EDataSourceKind,
+        expected_tables: Sequence[str],
+    ):
+        docker_compose_file_abs_path = yatest.common.source_path(docker_compose_file_path)
+        self.docker_compose_helper = DockerComposeHelper(docker_compose_yml_path=docker_compose_file_abs_path)
+        self.expected_tables = set(expected_tables)
+        self.data_source_kind = data_source_kind
+
+    def wait(self):
+        if self.__launched:
+            return
+
+        # This should be enough for tables to initialize
+        start = datetime.now()
+
+        timeout = 600
+        while (datetime.now() - start).total_seconds() < timeout:
+            self.actual_tables = set(self.docker_compose_helper.list_tables(self.data_source_kind))
+
+            # check if all the required tables have been created
+            if self.expected_tables <= self.actual_tables:
+                self.__launched = True
+                return
+
+            LOGGER.warning(f"Not enough tables: expected={self.expected_tables}, actual={self.actual_tables}")
+            time.sleep(5)
+
+        raise ValueError(
+            f"Datasource failed to initialize in {timeout} seconds, latest table set: {self.actual_tables}"
+        )
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/clickhouse.py b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/clickhouse.py
index 0043c9f8bf8e..6495e024cd57 100644
--- a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/clickhouse.py
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/clickhouse.py
@@ -1,16 +1,10 @@
-from typing import Sequence
-
-import ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 as data_source_pb2
-
-import ydb.library.yql.providers.generic.connector.tests.utils.artifacts as artifacts
-from ydb.library.yql.providers.generic.connector.tests.utils.comparator import assert_data_outs_equal
-from ydb.library.yql.providers.generic.connector.tests.utils.database import Database
-from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger, debug_with_limit
-from ydb.library.yql.providers.generic.connector.tests.utils.schema import Schema
+from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger
+from ydb.library.yql.providers.generic.connector.tests.utils.comparator import (
+    assert_data_outs_equal,
+    assert_schemas_equal,
+)
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
 from ydb.library.yql.providers.generic.connector.tests.utils.run.parent import Runner
-from ydb.library.yql.providers.generic.connector.tests.utils.sql import format_values_for_bulk_sql_insert
-from ydb.library.yql.providers.generic.connector.tests.utils.clients.clickhouse import Client
 
 import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_missing_database as tc_select_missing_database
 import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_missing_table as tc_select_missing_table
@@ -19,61 +13,12 @@
 LOGGER = make_logger(__name__)
 
 
-def prepare_table(
-    test_name: str,
-    client: Client,
-    database: Database,
-    table_name: str,
-    schema: Schema,
-    data_in: Sequence,
-):
-    dbTable = f"{database.name}.{table_name}"
-
-    # create database
-    create_database_stmt = database.query_create()
-    LOGGER.debug(create_database_stmt)
-    client.command(create_database_stmt)
-
-    # check if table exists
-    check_table_stmt = f"EXISTS TABLE {dbTable}"
-    LOGGER.debug(check_table_stmt)
-    res = client.command(check_table_stmt)
-    assert res in (0, 1), res
-    if res == 1:
-        # no need to create table
-        return
-
-    # create table
-    create_table_stmt = f"CREATE TABLE {dbTable} ({schema.yql_column_list(data_source_pb2.CLICKHOUSE)}) ENGINE = Memory"
-    LOGGER.debug(create_table_stmt)
-    client.command(create_table_stmt)
-
-    # write data
-    values = format_values_for_bulk_sql_insert(data_in)
-    insert_stmt = f"INSERT INTO {dbTable} (*) VALUES {values}"
-    # NOTE: these statement may be too big when working with big tables,
-    # so with truncate logs and put full statement into directory with artifacts
-    debug_with_limit(LOGGER, insert_stmt)
-    artifacts.dump_str(insert_stmt, test_name, 'insert.sql')
-    client.command(insert_stmt)
-
-
 def select_positive(
     test_name: str,
     test_case: tc_select_positive_common.TestCase,
     settings: Settings,
     runner: Runner,
-    client: Client,
 ):
-    prepare_table(
-        test_name=test_name,
-        client=client,
-        database=test_case.database,
-        table_name=test_case.table_name,
-        schema=test_case.schema,
-        data_in=test_case.data_in,
-    )
-
     where_statement = ""
     if test_case.select_where is not None:
         where_statement = "WHERE " + test_case.select_where.render(
@@ -108,7 +53,7 @@ def select_positive(
         result.data_out_with_types,
     )
     if test_case.check_output_schema:
-        assert test_case.schema == result.schema, (test_case.schema, result.schema)
+        assert_schemas_equal(test_case.schema, result.schema)
 
 
 def select_missing_database(
@@ -139,13 +84,7 @@ def select_missing_table(
     test_case: tc_select_missing_table.TestCase,
     settings: Settings,
     runner: Runner,
-    client: Client,
 ):
-    # create database, but don't create table
-    create_database_stmt = test_case.database.query_create()
-    LOGGER.debug(create_database_stmt)
-    client.command(create_database_stmt)
-
     yql_script = f"""
         SELECT *
         FROM {settings.clickhouse.cluster_name}.{test_case.table_name}
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/postgresql.py b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/postgresql.py
index e3d75a401b4f..91e0522bdcfc 100644
--- a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/postgresql.py
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/postgresql.py
@@ -30,13 +30,13 @@ def prepare_table(
 ):
     # create database
     with client.get_cursor("postgres") as (conn, cur):
-        database_exists_stmt = database.query_exists()
+        database_exists_stmt = database.exists()
         debug_with_limit(LOGGER, database_exists_stmt)
         cur.execute(database_exists_stmt)
 
         # database doesn't exist
         if not cur.fetchone():
-            create_database_stmt = database.query_create()
+            create_database_stmt = database.create()
             LOGGER.debug(create_database_stmt)
             cur.execute(create_database_stmt)
 
@@ -159,13 +159,13 @@ def select_missing_table(
 ):
     # create database but don't create table
     with client.get_cursor("postgres") as (conn, cur):
-        database_exists_stmt = test_case.database.query_exists()
+        database_exists_stmt = test_case.database.exists()
         debug_with_limit(LOGGER, database_exists_stmt)
         cur.execute(database_exists_stmt)
 
         # database doesn't exist
         if not cur.fetchone():
-            create_database_stmt = test_case.database.query_create()
+            create_database_stmt = test_case.database.create()
             debug_with_limit(LOGGER, create_database_stmt)
             cur.execute(create_database_stmt)
 
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/ydb.py b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/ydb.py
index da06c7ddb987..2bdbf4b6dd1c 100644
--- a/ydb/library/yql/providers/generic/connector/tests/utils/scenario/ydb.py
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/scenario/ydb.py
@@ -1,10 +1,4 @@
-from datetime import datetime
-import time
-from typing import Sequence
-
-import yatest.common
 from ydb.library.yql.providers.generic.connector.tests.utils.log import make_logger
-from ydb.library.yql.providers.generic.connector.tests.utils.docker_compose import DockerComposeHelper
 
 from ydb.library.yql.providers.generic.connector.tests.utils.comparator import assert_data_outs_equal
 from ydb.library.yql.providers.generic.connector.tests.utils.settings import Settings
@@ -15,37 +9,8 @@
 
 # import ydb.library.yql.providers.generic.connector.tests.common_test_cases.select_missing_database as tc_select_missing_database
 
-LOGGER = make_logger(__name__)
-
-
-class OneTimeWaiter:
-    __launched: bool = False
-
-    def __init__(self, docker_compose_file_path: str, expected_tables: Sequence[str]):
-        docker_compose_file_abs_path = yatest.common.source_path(docker_compose_file_path)
-        self.docker_compose_helper = DockerComposeHelper(docker_compose_yml_path=docker_compose_file_abs_path)
-        self.expected_tables = set(expected_tables)
-
-    def wait(self):
-        if self.__launched:
-            return
 
-        # This should be enough for tables to initialize
-        start = datetime.now()
-
-        timeout = 600
-        while (datetime.now() - start).total_seconds() < timeout:
-            self.actual_tables = set(self.docker_compose_helper.list_ydb_tables())
-
-            # check if all the required tables have been created
-            if self.expected_tables <= self.actual_tables:
-                self.__launched = True
-                return
-
-            LOGGER.warning(f"Not enough YDB tables: expected={self.expected_tables}, actual={self.actual_tables}")
-            time.sleep(5)
-
-        raise ValueError(f"YDB was not able to initialize in {timeout} seconds, latest table set: {self.actual_tables}")
+LOGGER = make_logger(__name__)
 
 
 def select_positive(
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/schema.py b/ydb/library/yql/providers/generic/connector/tests/utils/schema.py
index 688a830ba341..d931f31730a1 100644
--- a/ydb/library/yql/providers/generic/connector/tests/utils/schema.py
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/schema.py
@@ -362,6 +362,9 @@ def select_every_column(self) -> SelectWhat:
         return SelectWhat(*items)
 
 
+# FIXME: switch to snake case in function names
+
+
 def makeYdbTypeFromTypeID(type_id: Type.PrimitiveTypeId) -> Type:
     return Type(type_id=type_id)
 
diff --git a/ydb/library/yql/providers/generic/connector/tests/utils/ya.make b/ydb/library/yql/providers/generic/connector/tests/utils/ya.make
index 136e67d3cd6b..d0dea697ee67 100644
--- a/ydb/library/yql/providers/generic/connector/tests/utils/ya.make
+++ b/ydb/library/yql/providers/generic/connector/tests/utils/ya.make
@@ -8,6 +8,7 @@ PY_SRCS(
     docker_compose.py
     generate.py
     log.py
+    one_time_waiter.py
     schema.py
     settings.py
     sql.py
diff --git a/ydb/tests/fq/generic/analytics/test_join.py b/ydb/tests/fq/generic/analytics/test_join.py
index 8791594172f1..2e8d442b2f22 100644
--- a/ydb/tests/fq/generic/analytics/test_join.py
+++ b/ydb/tests/fq/generic/analytics/test_join.py
@@ -6,11 +6,13 @@
 
 from ydb.tests.tools.fq_runner.fq_client import FederatedQueryClient
 from ydb.tests.fq.generic.utils.settings import Settings
-from ydb.library.yql.providers.generic.connector.tests.utils.scenario.ydb import OneTimeWaiter
+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter
+from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
 import conftest
 
 
 one_time_waiter = OneTimeWaiter(
+    data_source_kind=EDataSourceKind.YDB,
     docker_compose_file_path=conftest.docker_compose_file_path,
     expected_tables=["join_table", "dummy_table"],
 )
diff --git a/ydb/tests/fq/generic/analytics/test_ydb.py b/ydb/tests/fq/generic/analytics/test_ydb.py
index d3bb7ff8ec61..0bddcc30fe66 100644
--- a/ydb/tests/fq/generic/analytics/test_ydb.py
+++ b/ydb/tests/fq/generic/analytics/test_ydb.py
@@ -7,11 +7,13 @@
 
 from ydb.tests.tools.fq_runner.fq_client import FederatedQueryClient
 from ydb.tests.fq.generic.utils.settings import Settings
-from ydb.library.yql.providers.generic.connector.tests.utils.scenario.ydb import OneTimeWaiter
+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter
+from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
 import conftest
 
 
 one_time_waiter = OneTimeWaiter(
+    data_source_kind=EDataSourceKind.YDB,
     docker_compose_file_path=conftest.docker_compose_file_path,
     expected_tables=["simple_table", "dummy_table"],
 )
diff --git a/ydb/tests/fq/generic/analytics/ya.make b/ydb/tests/fq/generic/analytics/ya.make
index 225f87b0575e..35ae8c110e0a 100644
--- a/ydb/tests/fq/generic/analytics/ya.make
+++ b/ydb/tests/fq/generic/analytics/ya.make
@@ -52,7 +52,8 @@ IF (OPENSOURCE)
 ENDIF()
 
 PEERDIR(
-    ydb/library/yql/providers/generic/connector/tests/utils/scenario
+    ydb/library/yql/providers/generic/connector/api/common
+    ydb/library/yql/providers/generic/connector/tests/utils
     ydb/tests/fq/generic/utils
     library/python/testing/recipe
     library/python/testing/yatest_common
diff --git a/ydb/tests/fq/generic/streaming/test_join.py b/ydb/tests/fq/generic/streaming/test_join.py
index de79fd66962e..b61e6a86f572 100644
--- a/ydb/tests/fq/generic/streaming/test_join.py
+++ b/ydb/tests/fq/generic/streaming/test_join.py
@@ -10,7 +10,10 @@
 
 from ydb.tests.tools.fq_runner.fq_client import FederatedQueryClient
 from ydb.tests.tools.datastreams_helpers.test_yds_base import TestYdsBase
-from ydb.library.yql.providers.generic.connector.tests.utils.scenario.ydb import OneTimeWaiter
+
+from ydb.library.yql.providers.generic.connector.tests.utils.one_time_waiter import OneTimeWaiter
+from ydb.library.yql.providers.generic.connector.api.common.data_source_pb2 import EDataSourceKind
+
 import conftest
 
 DEBUG = 0
@@ -407,6 +410,7 @@ def freeze(json):
 
 
 one_time_waiter = OneTimeWaiter(
+    data_source_kind=EDataSourceKind.YDB,
     docker_compose_file_path=conftest.docker_compose_file_path,
     expected_tables=["simple_table", "join_table", "dummy_table"],
 )
diff --git a/ydb/tests/fq/generic/streaming/ya.make b/ydb/tests/fq/generic/streaming/ya.make
index e5056765b6a1..8cc0bfe63b7b 100644
--- a/ydb/tests/fq/generic/streaming/ya.make
+++ b/ydb/tests/fq/generic/streaming/ya.make
@@ -54,7 +54,8 @@ DEPENDS(
 )
 
 PEERDIR(
-    ydb/library/yql/providers/generic/connector/tests/utils/scenario
+    ydb/library/yql/providers/generic/connector/api/common
+    ydb/library/yql/providers/generic/connector/tests/utils
     ydb/tests/fq/generic/utils
     ydb/tests/tools/datastreams_helpers
     library/python/testing/recipe
