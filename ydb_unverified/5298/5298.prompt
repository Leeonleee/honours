You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
LocalDB: erase cache doesn't work with volatile transactions
When table is used to store some deadline queue, i.e. new events are inserted into the table and current head is queried using a range query, we have a problem with skipping tombstones:

* A large deleted range at the front is cached until some key `K` (the last known deleted key)
* When a new event is inserted just before `K` it invalidates the whole range, i.e. when events are inserted just a little bit "out of order" it makes erase cache useless
* Worse, when datashard uses uncommitted changes (e.g. volatile transactions), it also specifies a custom transaction map, which disables erase cache (since it cannot be reliably updated and cannot be fully trusted due to possible changes by a custom transaction map).

We need a way for erase cache to reflect a fully committed state that cannot be modified by custom transaction maps, as well as make it possible to partially invalidate cached ranges. Some edge cases:

* We only cache non-trivial ranges (e.g. those that allow skipping more than 16 keys), but it is possible that a truncated range would become trivial, slowing down iteration instead of helping. We need a way to measure whether a range actually helped to skip enough rows, and remove useless ranges.
* We need a way to detect whether iteration encounters any non-persistent uncommitted changes at the top of a merged state, and skip those keys even when the final state is a tombstone. However LocalDB also uses tx map for committed changes until they are compacted internally, and those we want to cache. So we might need to use multiple tx maps (i.e. check internal map first, and only then use custom maps), which may be a bit slower.
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
