diff --git a/ydb/core/kqp/ut/common/kqp_ut_common.cpp b/ydb/core/kqp/ut/common/kqp_ut_common.cpp
index 9997745b5da9..2f7e5668acce 100644
--- a/ydb/core/kqp/ut/common/kqp_ut_common.cpp
+++ b/ydb/core/kqp/ut/common/kqp_ut_common.cpp
@@ -1289,7 +1289,6 @@ THolder<NSchemeCache::TSchemeCacheNavigate> Navigate(TTestActorRuntime& runtime,
 {
     auto &runtime = *server->GetRuntime();
     TAutoPtr<IEventHandle> handle;
-    TVector<ui64> shards;
 
     auto request = MakeHolder<TEvTxUserProxy::TEvNavigate>();
     request->Record.MutableDescribePath()->SetPath(path);
diff --git a/ydb/core/scheme/scheme_tablecell.cpp b/ydb/core/scheme/scheme_tablecell.cpp
index c2b541bb7984..77c0e3319196 100644
--- a/ydb/core/scheme/scheme_tablecell.cpp
+++ b/ydb/core/scheme/scheme_tablecell.cpp
@@ -349,13 +349,7 @@ size_t TOwnedCellVecBatch::Append(TConstArrayRef<TCell> cells) {
         return 0;
     }
 
-    size_t size = sizeof(TCell) * cellsSize;
-    for (auto& cell : cells) {
-        if (!cell.IsNull() && !cell.IsInline()) {
-            const size_t cellSize = cell.Size();
-            size += AlignUp(cellSize);
-        }
-    }
+    size_t size = EstimateSize(cells);
 
     char * allocatedBuffer = reinterpret_cast<char *>(Pool->Allocate(size));
 
diff --git a/ydb/core/scheme/scheme_tablecell.h b/ydb/core/scheme/scheme_tablecell.h
index d2abd9f5d548..752be860abc6 100644
--- a/ydb/core/scheme/scheme_tablecell.h
+++ b/ydb/core/scheme/scheme_tablecell.h
@@ -169,6 +169,20 @@ struct TCell {
 static_assert(sizeof(TCell) == 12, "TCell must be 12 bytes");
 using TCellsRef = TConstArrayRef<const TCell>;
 
+inline size_t EstimateSize(TCellsRef cells) {
+    size_t cellsSize = cells.size();
+
+    size_t size = sizeof(TCell) * cellsSize;
+    for (auto& cell : cells) {
+        if (!cell.IsNull() && !cell.IsInline()) {
+            const size_t cellSize = cell.Size();
+            size += AlignUp(cellSize);
+        }
+    }
+    
+    return size;
+}
+
 inline int CompareCellsAsByteString(const TCell& a, const TCell& b, bool isDescending) {
     const char* pa = (const char*)a.Data();
     const char* pb = (const char*)b.Data();
diff --git a/ydb/core/tablet_flat/flat_executor_tx_env.h b/ydb/core/tablet_flat/flat_executor_tx_env.h
index 48d5a1c41ccf..31e26deb3d8d 100644
--- a/ydb/core/tablet_flat/flat_executor_tx_env.h
+++ b/ydb/core/tablet_flat/flat_executor_tx_env.h
@@ -29,7 +29,13 @@ namespace NTabletFlatExecutor {
         {
             auto *partStore = CheckedCast<const NTable::TPartStore*>(part);
 
-            return { true, Lookup(partStore->Locate(lob, ref), ref) };
+            const TSharedData* page = Lookup(partStore->Locate(lob, ref), ref);
+
+            if (!page && ReadMissingReferences) {
+                MissingReferencesSize_ += Max<ui64>(1, part->GetPageSize(lob, ref));
+            }
+
+            return { !ReadMissingReferences, page };
         }
 
         const TSharedData* TryGetPage(const TPart* part, TPageId page, TGroupId groupId) override
@@ -39,6 +45,20 @@ namespace NTabletFlatExecutor {
             return Lookup(partStore->PageCollections.at(groupId.Index).Get(), page);
         }
 
+        void EnableReadMissingReferences() noexcept {
+            ReadMissingReferences = true;
+        }
+
+        void DisableReadMissingReferences() noexcept {
+            ReadMissingReferences = false;
+            MissingReferencesSize_ = 0;
+        }
+
+        ui64 MissingReferencesSize() const noexcept
+        { 
+            return MissingReferencesSize_;
+        }
+
     private:
         const TSharedData* Lookup(TPrivatePageCache::TInfo *info, TPageId pageId) noexcept
         {
@@ -47,6 +67,11 @@ namespace NTabletFlatExecutor {
 
     public:
         TPrivatePageCache& Cache;
+    
+    private:
+        bool ReadMissingReferences = false;
+
+        ui64 MissingReferencesSize_ = 0;
     };
 
     struct TPageCollectionTxEnv : public TPageCollectionReadEnv, public IExecuting {
@@ -187,6 +212,20 @@ namespace NTabletFlatExecutor {
             LoanConfirmation.insert(std::make_pair(bundle, TLoanConfirmation{borrow}));
         }
 
+        void EnableReadMissingReferences() noexcept override
+        {
+            TPageCollectionReadEnv::EnableReadMissingReferences();
+        }
+
+        void DisableReadMissingReferences() noexcept override
+        {
+            TPageCollectionReadEnv::DisableReadMissingReferences();
+        }
+
+        ui64 MissingReferencesSize() const noexcept override
+        {
+            return TPageCollectionReadEnv::MissingReferencesSize();
+        }
     protected:
         NTable::TDatabase& DB;
 
diff --git a/ydb/core/tablet_flat/flat_part_iter.h b/ydb/core/tablet_flat/flat_part_iter.h
index 84c2843a4c14..42171084fe2b 100644
--- a/ydb/core/tablet_flat/flat_part_iter.h
+++ b/ydb/core/tablet_flat/flat_part_iter.h
@@ -1319,6 +1319,7 @@ namespace NTable {
 
                 if (ref >> (sizeof(ui32) * 8))
                     Y_ABORT("Upper bits of ELargeObj ref now isn't used");
+
                 if (auto blob = Env->Locate(Part, ref, op)) {
                     const auto got = NPage::TLabelWrapper().Read(**blob);
 
@@ -1332,13 +1333,12 @@ namespace NTable {
                 } else {
                     Y_ABORT_UNLESS(ref < (*Part->Blobs)->size(), "out of blobs catalog");
 
+                    op = TCellOp(blob.Need ? ECellOp::Null : ECellOp(op), ELargeObj::GlobId);
+
                     /* Have to preserve reference to memory with TGlobId until
                         of next iterator alteration method invocation. This is
                         why here direct array of TGlobId is used.
                     */
-
-                    op = TCellOp(blob.Need ? ECellOp::Null : ECellOp(op), ELargeObj::GlobId);
-
                     row.Set(pin.To, op, TCell::Make((**Part->Blobs)[ref]));
                 }
             } else {
diff --git a/ydb/core/tablet_flat/flat_part_store.h b/ydb/core/tablet_flat/flat_part_store.h
index daa26955e5b8..34facda3de8a 100644
--- a/ydb/core/tablet_flat/flat_part_store.h
+++ b/ydb/core/tablet_flat/flat_part_store.h
@@ -79,6 +79,13 @@ class TPartStore : public TPart, public IBundle {
         return PageCollections[groupId.Index]->GetPageSize(pageId);
     }
 
+    ui64 GetPageSize(ELargeObj lob, ui64 ref) const override
+    {
+        auto* cache = Locate(lob, ref);
+
+        return cache->PageCollection->Page(ref).Size;
+    }
+
     NPage::EPage GetPageType(NPage::TPageId pageId, NPage::TGroupId groupId) const override
     {
         Y_ABORT_UNLESS(groupId.Index < PageCollections.size());
diff --git a/ydb/core/tablet_flat/flat_table_part.h b/ydb/core/tablet_flat/flat_table_part.h
index 83e5f15e4f2a..917390be358b 100644
--- a/ydb/core/tablet_flat/flat_table_part.h
+++ b/ydb/core/tablet_flat/flat_table_part.h
@@ -156,6 +156,7 @@ namespace NTable {
         virtual ui64 DataSize() const = 0;
         virtual ui64 BackingSize() const = 0;
         virtual ui64 GetPageSize(NPage::TPageId pageId, NPage::TGroupId groupId) const = 0;
+        virtual ui64 GetPageSize(ELargeObj lob, ui64 ref) const = 0;
         virtual NPage::EPage GetPageType(NPage::TPageId pageId, NPage::TGroupId groupId) const = 0;
         virtual ui8 GetGroupChannel(NPage::TGroupId groupId) const = 0;
         virtual ui8 GetPageChannel(ELargeObj lob, ui64 ref) const = 0;
diff --git a/ydb/core/tablet_flat/tablet_flat_executor.h b/ydb/core/tablet_flat/tablet_flat_executor.h
index 761d7ebe8a02..439d181362d5 100644
--- a/ydb/core/tablet_flat/tablet_flat_executor.h
+++ b/ydb/core/tablet_flat/tablet_flat_executor.h
@@ -103,6 +103,9 @@ struct IExecuting {
     virtual void LoanTable(ui32 tableId, const TString &partsInfo) = 0; // attach table parts to table (called on part destination)
     virtual void CleanupLoan(const TLogoBlobID &bundleId, ui64 from) = 0; // mark loan completion (called on part source)
     virtual void ConfirmLoan(const TLogoBlobID &bundleId, const TLogoBlobID &borrowId) = 0; // confirm loan update delivery (called on part destination)
+    virtual void EnableReadMissingReferences() noexcept = 0;
+    virtual void DisableReadMissingReferences() noexcept = 0;
+    virtual ui64 MissingReferencesSize() const noexcept = 0;
 };
 
 class TTxMemoryProviderBase : TNonCopyable {
diff --git a/ydb/core/tx/datashard/datashard__read_iterator.cpp b/ydb/core/tx/datashard/datashard__read_iterator.cpp
index 6be261d99bee..b056c481688f 100644
--- a/ydb/core/tx/datashard/datashard__read_iterator.cpp
+++ b/ydb/core/tx/datashard/datashard__read_iterator.cpp
@@ -220,15 +220,15 @@ std::pair<std::unique_ptr<IBlockBuilder>, TString> CreateBlockBuilder(
 }
 
 std::vector<TRawTypeValue> ToRawTypeValue(
-    const TSerializedCellVec& keyCells,
+    TArrayRef<const TCell> keyCells,
     const TShortTableInfo& tableInfo,
     bool addNulls)
 {
     std::vector<TRawTypeValue> result;
-    result.reserve(keyCells.GetCells().size());
+    result.reserve(keyCells.size());
 
-    for (ui32 i = 0; i < keyCells.GetCells().size(); ++i) {
-        result.push_back(TRawTypeValue(keyCells.GetCells()[i].AsRef(), tableInfo.KeyColumnTypes[i]));
+    for (ui32 i = 0; i < keyCells.size(); ++i) {
+        result.push_back(TRawTypeValue(keyCells[i].AsRef(), tableInfo.KeyColumnTypes[i]));
     }
 
     // note that currently without nulls it is [prefix, +inf, +inf],
@@ -298,9 +298,9 @@ class TReader {
     bool VolatileWaitForCommit = false;
 
     enum class EReadStatus {
-        Done = 0,
+        Done,
         NeedData,
-        StoppedByLimit,
+        NeedContinue,
     };
 
 public:
@@ -325,7 +325,6 @@ class TReader {
 
     EReadStatus ReadRange(
         TTransactionContext& txc,
-        const TActorContext& ctx,
         const TSerializedTableRange& range)
     {
         bool fromInclusive;
@@ -355,8 +354,8 @@ class TReader {
             toInclusive = range.ToInclusive;
         }
 
-        const auto keyFrom = ToRawTypeValue(keyFromCells, TableInfo, fromInclusive);
-        const auto keyTo = ToRawTypeValue(keyToCells, TableInfo, !toInclusive);
+        const auto keyFrom = ToRawTypeValue(keyFromCells.GetCells(), TableInfo, fromInclusive);
+        const auto keyTo = ToRawTypeValue(keyToCells.GetCells(), TableInfo, !toInclusive);
 
         // TODO: split range into parts like in read_columns
 
@@ -367,7 +366,7 @@ class TReader {
         iterRange.MaxInclusive = toInclusive;
         const bool reverse = State.Reverse;
 
-        if (TArrayRef<const TCell> cells = keyFromCells.GetCells()) {
+        if (TArrayRef<const TCell> cells = (reverse ? keyToCells.GetCells() : keyFromCells.GetCells())) {
             if (!fromInclusive || cells.size() >= TableInfo.KeyColumnTypes.size()) {
                 Self->GetKeyAccessSampler()->AddSample(TableId, cells);
             } else {
@@ -378,31 +377,24 @@ class TReader {
         }
 
         EReadStatus result;
+
+        txc.Env.EnableReadMissingReferences();
+
         if (!reverse) {
             auto iter = txc.DB.IterateRange(TableInfo.LocalTid, iterRange, State.Columns, State.ReadVersion, GetReadTxMap(), GetReadTxObserver());
-            result = IterateRange(iter.Get(), ctx);
+            result = IterateRange(iter.Get(), iterRange, txc);
         } else {
             auto iter = txc.DB.IterateRangeReverse(TableInfo.LocalTid, iterRange, State.Columns, State.ReadVersion, GetReadTxMap(), GetReadTxObserver());
-            result = IterateRange(iter.Get(), ctx);
+            result = IterateRange(iter.Get(), iterRange, txc);
         }
 
-        if (result == EReadStatus::NeedData && !(RowsProcessed && CanResume())) {
-            if (LastProcessedKey) {
-                keyFromCells = TSerializedCellVec(LastProcessedKey);
-                const auto keyFrom = ToRawTypeValue(keyFromCells, TableInfo, false);
-                Precharge(txc.DB, keyFrom, iterRange.MaxKey, reverse);
-            } else {
-                Precharge(txc.DB, iterRange.MinKey, iterRange.MaxKey, reverse);
-            }
-            return EReadStatus::NeedData;
-        }
+        txc.Env.DisableReadMissingReferences();
 
         return result;
     }
 
     EReadStatus ReadKey(
         TTransactionContext& txc,
-        const TActorContext& ctx,
         const TSerializedCellVec& keyCells,
         size_t keyIndex)
     {
@@ -413,7 +405,7 @@ class TReader {
             range.To = keyCells;
             range.ToInclusive = true;
             range.FromInclusive = true;
-            return ReadRange(txc, ctx, range);
+            return ReadRange(txc, range);
         }
 
         if (ColumnTypes.empty()) {
@@ -424,13 +416,16 @@ class TReader {
             }
         }
 
-        const auto key = ToRawTypeValue(keyCells, TableInfo, true);
+        const auto key = ToRawTypeValue(keyCells.GetCells(), TableInfo, true);
 
         NTable::TRowState rowState;
         rowState.Init(State.Columns.size());
         NTable::TSelectStats stats;
         auto ready = txc.DB.Select(TableInfo.LocalTid, key, State.Columns, rowState, stats, 0, State.ReadVersion, GetReadTxMap(), GetReadTxObserver());
         if (ready == NTable::EReady::Page) {
+            if (RowsProcessed && CanResume()) {
+                return EReadStatus::NeedContinue;
+            }
             return EReadStatus::NeedData;
         }
 
@@ -462,11 +457,11 @@ class TReader {
     {
         if (keyCells.GetCells().size() != TableInfo.KeyColumnCount) {
             // key prefix, treat it as range [prefix, null, null] - [prefix, +inf, +inf]
-            auto minKey = ToRawTypeValue(keyCells, TableInfo, true);
-            auto maxKey = ToRawTypeValue(keyCells, TableInfo, false);
+            auto minKey = ToRawTypeValue(keyCells.GetCells(), TableInfo, true);
+            auto maxKey = ToRawTypeValue(keyCells.GetCells(), TableInfo, false);
             return Precharge(txc.DB, minKey, maxKey, State.Reverse);
         } else {
-            auto key = ToRawTypeValue(keyCells, TableInfo, true);
+            auto key = ToRawTypeValue(keyCells.GetCells(), TableInfo, true);
             return Precharge(txc.DB, key, key, State.Reverse);
         }
     }
@@ -497,7 +492,7 @@ class TReader {
 
     // TODO: merge ReadRanges and ReadKeys to single template Read?
 
-    bool ReadRanges(TTransactionContext& txc, const TActorContext& ctx) {
+    bool ReadRanges(TTransactionContext& txc) {
         // note that FirstUnprocessedQuery is unsigned and if we do reverse iteration,
         // then it will also become less than size() when finished
         while (FirstUnprocessedQuery < State.Request->Ranges.size()) {
@@ -511,19 +506,16 @@ class TReader {
                 return true;
 
             const auto& range = State.Request->Ranges[FirstUnprocessedQuery];
-            auto status = ReadRange(txc, ctx, range);
+            auto status = ReadRange(txc, range);
             switch (status) {
             case EReadStatus::Done:
                 break;
-            case EReadStatus::StoppedByLimit:
-                return true;
             case EReadStatus::NeedData:
-                if (RowsProcessed && CanResume())
-                    return true;
-
                 // Note: ReadRange has already precharged current range and
                 //       we don't precharge multiple ranges as opposed to keys
                 return false;
+            case EReadStatus::NeedContinue:
+                return true;
             }
 
             if (!State.Reverse)
@@ -536,7 +528,7 @@ class TReader {
         return true;
     }
 
-    bool ReadKeys(TTransactionContext& txc, const TActorContext& ctx) {
+    bool ReadKeys(TTransactionContext& txc) {
         // note that FirstUnprocessedQuery is unsigned and if we do reverse iteration,
         // then it will also become less than size() when finished
         while (FirstUnprocessedQuery < State.Request->Keys.size()) {
@@ -550,18 +542,15 @@ class TReader {
                 return true;
 
             const auto& key = State.Request->Keys[FirstUnprocessedQuery];
-            auto status = ReadKey(txc, ctx, key, FirstUnprocessedQuery);
+            auto status = ReadKey(txc, key, FirstUnprocessedQuery);
             switch (status) {
             case EReadStatus::Done:
                 break;
-            case EReadStatus::StoppedByLimit:
-                return true;
             case EReadStatus::NeedData:
-                if (RowsProcessed && CanResume())
-                    return true;
-
                 PrechargeKeysAfter(txc, FirstUnprocessedQuery);
                 return false;
+            case EReadStatus::NeedContinue:
+                return true;
             }
 
             if (!State.Reverse)
@@ -575,16 +564,16 @@ class TReader {
     }
 
     // return semantics the same as in the Execute()
-    bool Read(TTransactionContext& txc, const TActorContext& ctx) {
+    bool Read(TTransactionContext& txc) {
         // TODO: consider trying to precharge multiple records at once in case
         // when first precharge fails?
 
         if (!State.Request->Keys.empty()) {
-            return ReadKeys(txc, ctx);
+            return ReadKeys(txc);
         }
 
         // since no keys, then we must have ranges (has been checked initially)
-        return ReadRanges(txc, ctx);
+        return ReadRanges(txc);
     }
 
     bool HasUnreadQueries() const {
@@ -784,22 +773,22 @@ class TReader {
         return true;
     }
 
-    bool OutOfQuota() const {
-        return RowsRead >= State.Quota.Rows ||
-            BlockBuilder.Bytes() >= State.Quota.Bytes||
-            BytesInResult >= State.Quota.Bytes;
+    bool OutOfQuota(ui64 prechargedCount = 0, ui64 bytesPrecharged = 0) const {
+        return RowsRead + prechargedCount >= State.Quota.Rows ||
+            BlockBuilder.Bytes() + bytesPrecharged >= State.Quota.Bytes ||
+            BytesInResult + bytesPrecharged >= State.Quota.Bytes;
     }
 
-    bool HasMaxRowsInResult() const {
-        return RowsRead >= State.MaxRowsInResult;
+    bool HasMaxRowsInResult(ui64 prechargedCount = 0) const {
+        return RowsRead + prechargedCount >= State.MaxRowsInResult;
     }
 
-    bool ReachedTotalRowsLimit() const {
+    bool ReachedTotalRowsLimit(ui64 prechargedCount = 0) const {
         if (State.TotalRowsLimit == Max<ui64>()) {
             return false;
         }
 
-        return State.TotalRows + RowsRead >= State.TotalRowsLimit;
+        return State.TotalRows + RowsRead + prechargedCount >= State.TotalRowsLimit;
     }
 
     ui64 GetTotalRowsLeft() const {
@@ -815,12 +804,12 @@ class TReader {
         return State.TotalRowsLimit - State.TotalRows - RowsRead;
     }
 
-    bool ShouldStop() {
+    bool ShouldStop(ui64 prechargedCount = 0, ui64 bytesPrecharged = 0) {
         if (!CanResume()) {
             return false;
         }
 
-        return OutOfQuota() || HasMaxRowsInResult() || ShouldStopByElapsedTime();
+        return OutOfQuota(prechargedCount, bytesPrecharged) || HasMaxRowsInResult(prechargedCount) || ShouldStopByElapsedTime();
     }
 
     ui64 GetRowsLeft() {
@@ -847,8 +836,8 @@ class TReader {
 
     bool Precharge(
         NTable::TDatabase& db,
-        NTable::TRawVals keyFrom,
-        NTable::TRawVals keyTo,
+        NTable::TRawVals minKey,
+        NTable::TRawVals maxKey,
         bool reverse)
     {
         ui64 rowsLeft = GetRowsLeft();
@@ -856,8 +845,8 @@ class TReader {
 
         auto direction = reverse ? NTable::EDirection::Reverse : NTable::EDirection::Forward;
         return db.Precharge(TableInfo.LocalTid,
-                            keyFrom,
-                            keyTo,
+                            minKey,
+                            maxKey,
                             State.Columns,
                             0,
                             rowsLeft,
@@ -867,26 +856,50 @@ class TReader {
     }
 
     template <typename TIterator>
-    EReadStatus IterateRange(TIterator* iter, const TActorContext& ctx) {
-        Y_UNUSED(ctx);
-
+    EReadStatus IterateRange(TIterator* iter, NTable::TKeyRange& iterRange, TTransactionContext& txc) {
         auto keyAccessSampler = Self->GetKeyAccessSampler();
 
         bool advanced = false;
+
+        bool precharging = false;
+        ui64 prechargedCount = 0;
+        ui64 prechargedRowsSize = 0; // Without referenced blobs (external, outer)
+
         while (iter->Next(NTable::ENext::Data) == NTable::EReady::Data) {
+            TDbTupleRef rowKey = iter->GetKey();
+            TDbTupleRef rowValues = iter->GetValues();
+
+            if (!precharging && txc.Env.MissingReferencesSize()) {
+                // Note: the current key must be returned to reader, but the
+                // previous key is lost, and we cannot safely resume. We can
+                // only restart query from the beginning, and don't want to
+                // keep track of any stats.
+                precharging = true;
+            }
+
+            if (precharging) {
+                // Note: RowsProcessed, RowsSinceLastCheck and LastProcessed key are not updated,
+                // so we will restart the transaction from the exact same key we started iterating from.
+                prechargedCount++;
+                prechargedRowsSize += EstimateSize(rowValues.Cells());
+
+                if (ReachedTotalRowsLimit(prechargedCount) || ShouldStop(prechargedCount, prechargedRowsSize + txc.Env.MissingReferencesSize())) {
+                    break;
+                }
+
+                continue;
+            }
+
             advanced = true;
+
             DeletedRowSkips += iter->Stats.DeletedRowSkips;
             InvisibleRowSkips += iter->Stats.InvisibleRowSkips;
 
-            TDbTupleRef rowKey = iter->GetKey();
-
             keyAccessSampler->AddSample(TableId, rowKey.Cells());
             const ui64 processedRecords = 1 + ResetRowSkips(iter->Stats);
             RowsSinceLastCheck += processedRecords;
             RowsProcessed += processedRecords;
 
-            TDbTupleRef rowValues = iter->GetValues();
-
             // note that if user requests key columns then they will be in
             // rowValues and we don't have to add rowKey columns
             BlockBuilder.AddRow(TDbTupleRef(), rowValues);
@@ -900,7 +913,7 @@ class TReader {
             if (ShouldStop()) {
                 LastProcessedKey = TSerializedCellVec::Serialize(rowKey.Cells());
                 LastProcessedKeyErased = false;
-                return EReadStatus::StoppedByLimit;
+                return EReadStatus::NeedContinue;
             }
         }
 
@@ -913,6 +926,27 @@ class TReader {
         // the same transaction, instead of starting a new one, in which case
         // we will not update stats and will not update RowsProcessed.
         auto lastKey = iter->GetKey().Cells();
+
+        auto prechargeFromLastKey = [&]() {
+            if (lastKey) {
+                const auto key = ToRawTypeValue(lastKey, TableInfo, false);
+                if (!State.Reverse) {
+                    Precharge(txc.DB, key, iterRange.MaxKey, State.Reverse);
+                } else {
+                    Precharge(txc.DB, iterRange.MinKey, key, State.Reverse);
+                }
+            } else {
+                Precharge(txc.DB, iterRange.MinKey, iterRange.MaxKey, State.Reverse);
+            }
+        };
+
+        if (precharging) {
+            if (iter->Last() == NTable::EReady::Page) {
+                prechargeFromLastKey();
+            }
+            return EReadStatus::NeedData;
+        }
+
         if (lastKey && (advanced || iter->Stats.DeletedRowSkips >= 4) && iter->Last() == NTable::EReady::Page) {
             LastProcessedKey = TSerializedCellVec::Serialize(lastKey);
             LastProcessedKeyErased = iter->GetKeyState() == NTable::ERowOp::Erase;
@@ -930,9 +964,14 @@ class TReader {
             RowsProcessed += processedRecords;
         }
 
-        // TODO: consider restart when Page and too few data read
-        // (how much is too few, less than user's limit?)
         if (iter->Last() == NTable::EReady::Page) {
+            // TODO: consider restart when Page and too few data read
+            // (how much is too few, less than user's limit?)
+            if (RowsProcessed && CanResume()) {
+                return EReadStatus::NeedContinue;
+            }
+
+            prechargeFromLastKey();
             return EReadStatus::NeedData;
         }
 
@@ -1773,7 +1812,7 @@ class TDataShard::TReadOperation : public TOperation, public IReadOperation {
             AppData()->MonotonicTimeProvider->Now(),
             Self));
 
-        return Reader->Read(txc, ctx);
+        return Reader->Read(txc);
     }
 
     void PrepareValidationInfo(const TActorContext&, const TReadIteratorState& state) {
@@ -2430,7 +2469,8 @@ class TDataShard::TTxReadContinue : public NTabletFlatExecutor::TTransactionBase
             Self));
 
         LWTRACK(ReadExecute, state.Orbit);
-        if (Reader->Read(txc, ctx)) {
+
+        if (Reader->Read(txc)) {
             // Retry later when dependencies are resolved
             if (!Reader->GetVolatileReadDependencies().empty()) {
                 state.ReadContinuePending = true;
diff --git a/ydb/core/tx/datashard/datashard_ut_read_iterator_ext_blobs.cpp b/ydb/core/tx/datashard/datashard_ut_read_iterator_ext_blobs.cpp
new file mode 100644
index 000000000000..8b845b0f4b6a
--- /dev/null
+++ b/ydb/core/tx/datashard/datashard_ut_read_iterator_ext_blobs.cpp
@@ -0,0 +1,705 @@
+#include <ydb/core/tx/datashard/ut_common/datashard_ut_common.h>
+#include "datashard_ut_common_kqp.h"
+
+#include <ydb/core/testlib/tablet_helpers.h>
+#include <ydb/core/formats/arrow/arrow_helpers.h>
+#include <ydb/core/formats/arrow/converter.h>
+#include <ydb/core/kqp/ut/common/kqp_ut_common.h>
+#include <ydb/core/tablet_flat/shared_cache_events.h>
+#include <ydb/core/tx/tx_proxy/proxy.h>
+#include <ydb/core/tx/tx_proxy/read_table.h>
+#include <ydb/core/tx/long_tx_service/public/lock_handle.h>
+
+#include <ydb/core/tx/data_events/events.h>
+#include <ydb/core/tx/data_events/payload_helper.h>
+
+#include <ydb/public/sdk/cpp/client/ydb_result/result.h>
+
+namespace NKikimr {
+
+using namespace NKikimr::NDataShard;
+using namespace NKikimr::NDataShard::NKqpHelpers;
+using namespace NSchemeShard;
+using namespace Tests;
+
+Y_UNIT_TEST_SUITE(ReadIteratorExternalBlobs) {
+
+    struct TReadIteratorCounter {
+        int Reads = 0;
+        int Continues = 0;
+        int EvGets = 0;
+        int BlobsRequested = 0;
+
+        bool operator==(const TReadIteratorCounter&) const = default;
+
+        friend inline IOutputStream& operator<<(IOutputStream& out, const TReadIteratorCounter& c) {
+            out << "{ " << c.Reads << ", " << c.Continues << ", " << c.EvGets << ", " << c.BlobsRequested << " }";
+            return out;
+        }
+    };
+
+    std::unique_ptr<TReadIteratorCounter> SetupReadIteratorObserver(TTestActorRuntime& runtime) {
+        std::unique_ptr<TReadIteratorCounter> iteratorCounter = std::make_unique<TReadIteratorCounter>();
+
+        auto captureEvents = [&](TAutoPtr<IEventHandle> &event) -> auto {
+            switch (event->GetTypeRewrite()) {
+                case TEvDataShard::EvRead: {
+                    iteratorCounter->Reads++;
+                    break;
+                }
+                case TEvDataShard::EvReadContinue: {
+                    iteratorCounter->Continues++;
+                    break;
+                }
+                case TEvBlobStorage::EvGet: {
+                    auto* msg = event->Get<TEvBlobStorage::TEvGet>();
+                    iteratorCounter->EvGets++;
+                    iteratorCounter->BlobsRequested += msg->QuerySize;
+                    break;
+                }
+            }
+            return TTestActorRuntime::EEventAction::PROCESS;
+        };
+
+        auto prevObserverFunc = runtime.SetObserverFunc(captureEvents);
+
+        return iteratorCounter;
+    }
+
+    struct TNode {
+        TPortManager Pm;
+        TServerSettings ServerSettings;
+        TServer::TPtr Server;
+        ui64 Shard;
+        TTableId TableId;
+        TActorId Sender;
+        TTestActorRuntime* Runtime;
+
+        TNode(bool useExternalBlobs, int externalBlobColumns = 1) : ServerSettings(Pm.GetPort(2134)) {
+            ServerSettings.SetDomainName("Root")
+                .SetUseRealThreads(false)
+                .AddStoragePool("ssd")
+                .AddStoragePool("hdd")
+                .AddStoragePool("ext")
+                .SetEnableUuidAsPrimaryKey(true);
+
+            Server = new TServer(ServerSettings);
+            
+            Runtime = Server->GetRuntime();
+
+            Sender = Runtime->AllocateEdgeActor();
+        
+            InitRoot(Server, Sender);
+            
+            TShardedTableOptions::TFamily fam;
+            
+            if (useExternalBlobs) {
+                fam = {.Name = "default", .LogPoolKind = "ssd", .SysLogPoolKind = "ssd", .DataPoolKind = "ssd", 
+                        .ExternalPoolKind = "ext", .DataThreshold = 100u, .ExternalThreshold = 512_KB};
+            } else {
+                fam = {.Name = "default", .LogPoolKind = "ssd", .SysLogPoolKind = "ssd", .DataPoolKind = "ssd", .DataThreshold = 100u};
+            }
+            
+            TVector<TShardedTableOptions::TColumn> columns = {
+                    {"blob_id", "Uuid", true, false}, 
+                    {"chunk_num", "Int32", true, false}
+            };
+
+            for (int i = 0; i < externalBlobColumns; i++) {
+                columns.push_back({"data" + ToString(i), "String", false, false});
+            }
+
+            auto opts = TShardedTableOptions()
+                .Columns(columns)
+                .Families({fam});
+
+            CreateShardedTable(Server, Sender, "/Root", "table-1", opts);
+
+            Shard = GetTableShards(Server, Sender, "/Root/table-1").at(0);
+            TableId = ResolveTableId(Server, Sender, "/Root/table-1");
+        }
+    };
+
+    void ValidateReadResult(TTestActorRuntime& runtime,
+            NThreading::TFuture<Ydb::Table::ExecuteDataQueryResponse> readFuture,
+            int rowsCount,
+            int firstBlobChunkNum = 0,
+            int extBlobColumnCount = 1)
+    {
+        Ydb::Table::ExecuteDataQueryResponse res = AwaitResponse(runtime, std::move(readFuture));
+        auto& operation = res.Getoperation();
+        UNIT_ASSERT_VALUES_EQUAL(operation.status(), Ydb::StatusIds::SUCCESS);
+        Ydb::Table::ExecuteQueryResult result;
+        operation.result().UnpackTo(&result);
+        UNIT_ASSERT_EQUAL(result.result_sets().size(), 1);
+        auto& resultSet = result.result_sets()[0];
+        UNIT_ASSERT_EQUAL(resultSet.rows_size(), rowsCount);
+
+        for (int i = 0; i < resultSet.rows_size(); i++) {
+            auto& row = resultSet.get_idx_rows(i);
+
+            UNIT_ASSERT_EQUAL(row.items_size(), 2 + extBlobColumnCount);
+
+            auto& chunkNumValue = row.get_idx_items(1);
+
+            UNIT_ASSERT(chunkNumValue.has_int32_value());
+            UNIT_ASSERT_EQUAL(chunkNumValue.Getint32_value(), firstBlobChunkNum + i);
+
+            for (int j = 0; j < extBlobColumnCount; j++) {
+                auto& dataValue = row.get_idx_items(2 + j);
+                UNIT_ASSERT(dataValue.has_bytes_value());
+                UNIT_ASSERT_EQUAL(dataValue.bytes_value().size(), 1_MB);
+            }
+        }
+    }
+    
+    void ValidateReadResult(TTestActorRuntime& runtime,
+            NThreading::TFuture<Ydb::Table::ExecuteDataQueryResponse> readFuture,
+            const std::vector<i32>& expectedResult)
+    {
+        Ydb::Table::ExecuteDataQueryResponse res = AwaitResponse(runtime, std::move(readFuture));
+        auto& operation = res.Getoperation();
+        UNIT_ASSERT_VALUES_EQUAL(operation.status(), Ydb::StatusIds::SUCCESS);
+        Ydb::Table::ExecuteQueryResult result;
+        operation.result().UnpackTo(&result);
+        UNIT_ASSERT_EQUAL(result.result_sets().size(), 1);
+        auto& resultSet = result.result_sets()[0];
+        UNIT_ASSERT_EQUAL(size_t(resultSet.rows_size()), expectedResult.size());
+
+        for (int i = 0; i < resultSet.rows_size(); i++) {
+            auto& row = resultSet.get_idx_rows(i);
+
+            UNIT_ASSERT_EQUAL(row.items_size(), 3);
+
+            auto& chunkNumValue = row.get_idx_items(1);
+
+            UNIT_ASSERT(chunkNumValue.has_int32_value());
+            UNIT_ASSERT_EQUAL(chunkNumValue.Getint32_value(), expectedResult[i]);
+
+            auto& dataValue = row.get_idx_items(2);
+            UNIT_ASSERT(dataValue.has_bytes_value());
+            UNIT_ASSERT_EQUAL(dataValue.bytes_value().size(), 1_MB);
+        }
+    }
+
+    Y_UNIT_TEST(ExtBlobs) {
+        TNode node(true);
+
+        auto server = node.Server;
+        auto& runtime = *node.Runtime;
+        auto& sender = node.Sender;
+        auto shard1 = node.Shard;
+        auto tableId1 = node.TableId;
+
+        TString largeValue(1_MB, 'L');
+
+        for (int i = 0; i < 10; i++) {
+            TString chunkNum = ToString(i);
+            TString query = R"___(
+                UPSERT INTO `/Root/table-1` (blob_id, chunk_num, data0) VALUES
+                    (Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c"), )___" + chunkNum + ", \"" + largeValue + "\");";
+            
+            ExecSQL(server, sender, query);    
+        }
+
+        {
+            Cerr << "... waiting for stats after upsert" << Endl;
+            auto stats = WaitTableStats(runtime, shard1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetDatashardId(), shard1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetRowCount(), 10);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetPartCount(), 0);
+        }
+
+        CompactTable(runtime, shard1, tableId1, false);
+
+        {
+            Cerr << "... waiting for stats after compaction" << Endl;
+            auto stats = WaitTableStats(runtime, shard1, 1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetDatashardId(), shard1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetRowCount(), 10);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetPartCount(), 1);
+        }
+
+        auto iteratorCounter = SetupReadIteratorObserver(runtime);
+
+        auto readFuture = KqpSimpleSend(runtime, R"(SELECT blob_id, chunk_num, data0
+                FROM `/Root/table-1`
+                WHERE
+                    blob_id = Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") AND
+                    chunk_num >= 0
+                ORDER BY blob_id, chunk_num ASC
+                LIMIT 100;)");
+
+        ValidateReadResult(runtime, std::move(readFuture), 10);
+
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->Reads, 1);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->Continues, 2);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->EvGets, 2);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->BlobsRequested, 10);
+    }
+
+    Y_UNIT_TEST(ExtBlobsWithDeletesInTheBeginning) {
+        TNode node(true);
+
+        auto server = node.Server;
+        auto& runtime = *node.Runtime;
+        auto& sender = node.Sender;
+        auto shard1 = node.Shard;
+        auto tableId1 = node.TableId;
+
+        TString largeValue(1_MB, 'L');
+
+        for (int i = 0; i < 10; i++) {
+            TString chunkNum = ToString(i);
+            TString query = R"___(
+                UPSERT INTO `/Root/table-1` (blob_id, chunk_num, data0) VALUES
+                    (Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c"), )___" + chunkNum + ", \"" + largeValue + "\");";
+            
+            ExecSQL(server, sender, query);    
+        }
+
+        CompactTable(runtime, shard1, tableId1, false);
+
+        for (int i = 0; i < 7; i++) {
+            TString chunkNum = ToString(i);
+            TString query = R"___(
+                DELETE FROM `/Root/table-1` WHERE blob_id=Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") and chunk_num=)___"
+                + chunkNum + ";";
+            
+            ExecSQL(server, sender, query);    
+        }
+
+        auto iteratorCounter = SetupReadIteratorObserver(runtime);
+
+        auto readFuture = KqpSimpleSend(runtime, R"(SELECT blob_id, chunk_num, data0
+                FROM `/Root/table-1`
+                WHERE
+                    blob_id = Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") AND
+                    chunk_num >= 0
+                ORDER BY blob_id, chunk_num ASC
+                LIMIT 100;)");
+
+        ValidateReadResult(runtime, std::move(readFuture), 3, 7);
+
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->Reads, 1);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->Continues, 0);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->EvGets, 1);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->BlobsRequested, 3);
+    }
+
+    Y_UNIT_TEST(ExtBlobsWithDeletesInTheEnd) {
+        TNode node(true);
+
+        auto server = node.Server;
+        auto& runtime = *node.Runtime;
+        auto& sender = node.Sender;
+        auto shard1 = node.Shard;
+        auto tableId1 = node.TableId;
+
+        TString largeValue(1_MB, 'L');
+
+        for (int i = 0; i < 10; i++) {
+            TString chunkNum = ToString(i);
+            TString query = R"___(
+                UPSERT INTO `/Root/table-1` (blob_id, chunk_num, data0) VALUES
+                    (Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c"), )___" + chunkNum + ", \"" + largeValue + "\");";
+            
+            ExecSQL(server, sender, query);    
+        }
+        
+        CompactTable(runtime, shard1, tableId1, false);
+
+        for (int i = 3; i < 10; i++) {
+            TString chunkNum = ToString(i);
+            TString query = R"___(
+                DELETE FROM `/Root/table-1` WHERE blob_id=Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") and chunk_num=)___"
+                + chunkNum + ";";
+            
+            ExecSQL(server, sender, query);    
+        }
+
+        auto iteratorCounter = SetupReadIteratorObserver(runtime);
+
+        auto readFuture = KqpSimpleSend(runtime, R"(SELECT blob_id, chunk_num, data0
+                FROM `/Root/table-1`
+                WHERE
+                    blob_id = Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") AND
+                    chunk_num >= 0
+                ORDER BY blob_id, chunk_num ASC
+                LIMIT 100;)");
+
+        ValidateReadResult(runtime, std::move(readFuture), 3);
+
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->Reads, 1);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->Continues, 0);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->EvGets, 1);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->BlobsRequested, 3);
+    }
+
+    Y_UNIT_TEST(ExtBlobsWithDeletesInTheMiddle) {
+        TNode node(true);
+
+        auto server = node.Server;
+        auto& runtime = *node.Runtime;
+        auto& sender = node.Sender;
+        auto shard1 = node.Shard;
+        auto tableId1 = node.TableId;
+
+        TString largeValue(1_MB, 'L');
+
+        for (int i = 0; i < 10; i++) {
+            TString chunkNum = ToString(i);
+            TString query = R"___(
+                UPSERT INTO `/Root/table-1` (blob_id, chunk_num, data0) VALUES
+                    (Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c"), )___" + chunkNum + ", \"" + largeValue + "\");";
+            
+            ExecSQL(server, sender, query);    
+        }
+
+        CompactTable(runtime, shard1, tableId1, false);
+
+        {
+            TString query = R"___(
+                DELETE FROM `/Root/table-1` WHERE blob_id=Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") and chunk_num=0;)___";
+            
+            ExecSQL(server, sender, query);    
+        }
+
+        for (int i = 2; i < 5; i++) {
+            TString chunkNum = ToString(i);
+            TString query = R"___(
+                DELETE FROM `/Root/table-1` WHERE blob_id=Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") and chunk_num=)___"
+                + chunkNum + ";";
+            
+            ExecSQL(server, sender, query);    
+        }
+
+        auto iteratorCounter = SetupReadIteratorObserver(runtime);
+
+        auto readFuture = KqpSimpleSend(runtime, R"(SELECT blob_id, chunk_num, data0
+                FROM `/Root/table-1`
+                WHERE
+                    blob_id = Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") AND
+                    chunk_num >= 0
+                ORDER BY blob_id, chunk_num ASC
+                LIMIT 100;)");
+
+        ValidateReadResult(runtime, std::move(readFuture), {1, 5, 6, 7, 8, 9});
+
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->Reads, 1);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->Continues, 1);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->EvGets, 2);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->BlobsRequested, 6);
+    }
+
+    void DoExtBlobsWithFirstRowPreloaded(bool withReboot) {
+        TNode node(true);
+
+        auto server = node.Server;
+        auto& runtime = *node.Runtime;
+        auto& sender = node.Sender;
+        auto shard1 = node.Shard;
+        auto tableId1 = node.TableId;
+
+        TString largeValue(1_MB, 'L');
+
+        for (int i = 0; i < 10; i++) {
+            TString chunkNum = ToString(i);
+            TString query = R"___(
+                UPSERT INTO `/Root/table-1` (blob_id, chunk_num, data0) VALUES
+                    (Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c"), )___" + chunkNum + ", \"" + largeValue + "\");";
+            ExecSQL(server, sender, query);
+        }
+
+        CompactTable(runtime, shard1, tableId1, false);
+
+        runtime.SimulateSleep(TDuration::Seconds(1));
+
+        auto preloadFuture = KqpSimpleSend(runtime, R"(
+                SELECT blob_id, chunk_num, data0
+                FROM `/Root/table-1`
+                WHERE
+                    blob_id = Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") AND
+                    chunk_num = 0;
+            )");
+
+        ValidateReadResult(runtime, std::move(preloadFuture), 1);
+
+        size_t passedRows = 0;
+        bool finished = false;
+        std::vector<TEvDataShard::TEvReadResult::TPtr> blockedResults;
+        std::optional<std::pair<TActorId, ui64>> dropReadId;
+        auto blockResults = runtime.AddObserver<TEvDataShard::TEvReadResult>(
+            [&](TEvDataShard::TEvReadResult::TPtr& ev) {
+                auto* msg = ev->Get();
+                if (dropReadId) {
+                    if (*dropReadId == std::make_pair(ev->GetRecipientRewrite(), msg->Record.GetReadId())) {
+                        ev.Reset();
+                    }
+                    return;
+                }
+                if (passedRows > 0) {
+                    blockedResults.push_back(std::move(ev));
+                    return;
+                }
+                passedRows += msg->GetRowsCount();
+                if (msg->Record.GetFinished()) {
+                    finished = true;
+                }
+            });
+
+        auto readFuture = KqpSimpleSend(runtime, R"(
+                SELECT blob_id, chunk_num, data0
+                FROM `/Root/table-1`
+                WHERE
+                    blob_id = Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") AND
+                    chunk_num >= 0
+                ORDER BY blob_id, chunk_num ASC
+                LIMIT 5;
+            )");
+
+        runtime.WaitFor("blocked results", [&]{ return blockedResults.size() > 0 || finished; });
+
+        if (!finished) {
+            UNIT_ASSERT_VALUES_EQUAL(passedRows, 1u);
+
+            if (withReboot) {
+                dropReadId.emplace(
+                    blockedResults[0]->GetRecipientRewrite(),
+                    blockedResults[0]->Get()->Record.GetReadId());
+
+                RebootTablet(runtime, shard1, sender);
+            } else {
+                blockResults.Remove();
+                for (auto& ev : blockedResults) {
+                    runtime.Send(ev.Release(), 0, true);
+                }
+                blockedResults.clear();
+            }
+        }
+
+        ValidateReadResult(runtime, std::move(readFuture), 5);
+    }
+
+    Y_UNIT_TEST(ExtBlobsWithFirstRowPreloaded) {
+        DoExtBlobsWithFirstRowPreloaded(false);
+    }
+
+    Y_UNIT_TEST(ExtBlobsWithFirstRowPreloadedWithReboot) {
+        DoExtBlobsWithFirstRowPreloaded(true);
+    }
+
+    Y_UNIT_TEST(ExtBlobsMultipleColumns) {
+        TNode node(true, 2);
+
+        auto server = node.Server;
+        auto& runtime = *node.Runtime;
+        auto& sender = node.Sender;
+        auto shard1 = node.Shard;
+        auto tableId1 = node.TableId;
+
+        TString largeValue(1_MB, 'L');
+
+        for (int i = 0; i < 10; i++) {
+            TString chunkNum = ToString(i);
+            TString query = R"___(
+                UPSERT INTO `/Root/table-1` (blob_id, chunk_num, data0, data1) VALUES
+                    (Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c"), )___"
+                     + chunkNum + ", \"" + largeValue + "\", \"" + largeValue + "\");";
+            
+            ExecSQL(server, sender, query);    
+        }
+
+        {
+            Cerr << "... waiting for stats after upsert" << Endl;
+            auto stats = WaitTableStats(runtime, shard1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetDatashardId(), shard1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetRowCount(), 10);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetPartCount(), 1);
+        }
+
+        CompactTable(runtime, shard1, tableId1, false);
+
+        {
+            Cerr << "... waiting for stats after compaction" << Endl;
+            auto stats = WaitTableStats(runtime, shard1, 1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetDatashardId(), shard1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetRowCount(), 10);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetPartCount(), 1);
+        }
+
+        auto iteratorCounter = SetupReadIteratorObserver(runtime);
+
+        auto readFuture = KqpSimpleSend(runtime, R"(SELECT blob_id, chunk_num, data0, data1
+                FROM `/Root/table-1`
+                WHERE
+                    blob_id = Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") AND
+                    chunk_num >= 0
+                ORDER BY blob_id, chunk_num ASC
+                LIMIT 100;)");
+
+        ValidateReadResult(runtime, std::move(readFuture), 10, 0, 2);
+
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->Reads, 1);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->Continues, 3);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->EvGets, 4);
+        UNIT_ASSERT_VALUES_EQUAL(iteratorCounter->BlobsRequested, 20);
+    }
+
+    Y_UNIT_TEST(ExtBlobsWithCompactingMiddleRows) {
+        std::unordered_map<int, TReadIteratorCounter> expectedResults;
+        expectedResults[1] = {1, 4, 4, 18};
+        expectedResults[2] = {1, 4, 4, 16};
+        expectedResults[3] = {1, 4, 4, 14};
+        expectedResults[4] = {1, 4, 4, 12};
+        expectedResults[5] = {1, 4, 2, 10};
+
+        // We write 20 rows, some of them are compacted, then we write some more rows "before" and "after" and read all of them
+        // The quantity of rows before, in the middle and after is different for each test. For example the first one is
+        // 1 row before, 18 rows in the middle and 1 row after.
+        for (int test = 1; test < 6; test++) {
+            int compactedPart = 20 - (test * 2);
+
+            TNode node(true);
+
+            auto server = node.Server;
+            auto& runtime = *node.Runtime;
+            auto& sender = node.Sender;
+            auto shard1 = node.Shard;
+            auto tableId1 = node.TableId;
+
+            TString largeValue(1_MB, 'L');
+
+            for (int i = 0; i < compactedPart; i++) {
+                TString chunkNum = ToString(test + i);
+
+                TString query = R"___(
+                    UPSERT INTO `/Root/table-1` (blob_id, chunk_num, data0) VALUES
+                        (Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c"), )___" + chunkNum + ", \"" + largeValue + "\");";
+                
+                ExecSQL(server, sender, query);    
+            }
+
+            {
+                Cerr << "... waiting for stats after upsert" << Endl;
+                auto stats = WaitTableStats(runtime, shard1);
+                UNIT_ASSERT_VALUES_EQUAL(stats.GetDatashardId(), shard1);
+                UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetRowCount(), compactedPart);
+            }
+
+            CompactTable(runtime, shard1, tableId1, false);
+
+            {
+                Cerr << "... waiting for stats after compaction" << Endl;
+                auto stats = WaitTableStats(runtime, shard1, 1);
+                UNIT_ASSERT_VALUES_EQUAL(stats.GetDatashardId(), shard1);
+                UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetRowCount(), compactedPart);
+                UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetPartCount(), 1);
+            }
+
+            for (int i = 0; i < test; i++) {
+                TString chunkNum = ToString(i);
+
+                TString query = R"___(
+                    UPSERT INTO `/Root/table-1` (blob_id, chunk_num, data0) VALUES
+                        (Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c"), )___" + chunkNum + ", \"" + largeValue + "\");";
+                
+                ExecSQL(server, sender, query);    
+            }
+
+            for (int i = compactedPart + test; i < 20; i++) {
+                TString chunkNum = ToString(i);
+
+                TString query = R"___(
+                    UPSERT INTO `/Root/table-1` (blob_id, chunk_num, data0) VALUES
+                        (Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c"), )___" + chunkNum + ", \"" + largeValue + "\");";
+                
+                ExecSQL(server, sender, query);    
+            }
+
+            auto iteratorCounter = SetupReadIteratorObserver(runtime);
+
+            auto readFuture = KqpSimpleSend(runtime, R"(SELECT blob_id, chunk_num, data0
+                    FROM `/Root/table-1`
+                    WHERE
+                        blob_id = Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") AND
+                        chunk_num >= 0
+                    ORDER BY blob_id, chunk_num ASC
+                    LIMIT 100;)");
+
+            ValidateReadResult(runtime, std::move(readFuture), 20);
+
+            auto& expectedResult = expectedResults[test];
+
+            UNIT_ASSERT_VALUES_EQUAL_C(*iteratorCounter, expectedResult, "test " << test);
+        }
+    }
+
+    Y_UNIT_TEST(ExtBlobsEmptyTable) {
+        TNode node(true);
+
+        auto& runtime = *node.Runtime;
+
+        auto readFuture = KqpSimpleSend(runtime, R"(SELECT blob_id, chunk_num, data0
+                FROM `/Root/table-1`
+                WHERE
+                    blob_id = Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") AND
+                    chunk_num >= 0
+                ORDER BY blob_id, chunk_num ASC
+                LIMIT 100;)");
+
+        ValidateReadResult(runtime, std::move(readFuture), 0);
+    }
+
+    Y_UNIT_TEST(NotExtBlobs) {
+        TNode node(false);
+
+        auto server = node.Server;
+        auto& runtime = *node.Runtime;
+        auto& sender = node.Sender;
+        auto shard1 = node.Shard;
+        auto tableId1 = node.TableId;
+
+        TString largeValue(1_MB, 'L');
+
+        for (int i = 0; i < 10; i++) {
+            TString chunkNum = ToString(i);
+            TString query = R"___(
+                UPSERT INTO `/Root/table-1` (blob_id, chunk_num, data0) VALUES
+                    (Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c"), )___" + chunkNum + ", \"" + largeValue + "\");";
+            
+            ExecSQL(server, sender, query);    
+        }
+
+        {
+            Cerr << "... waiting for stats after upsert" << Endl;
+            auto stats = WaitTableStats(runtime, shard1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetDatashardId(), shard1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetRowCount(), 10);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetPartCount(), 0);
+        }
+
+        CompactTable(runtime, shard1, tableId1, false);
+
+        {
+            Cerr << "... waiting for stats after compaction" << Endl;
+            auto stats = WaitTableStats(runtime, shard1, 1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetDatashardId(), shard1);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetRowCount(), 10);
+            UNIT_ASSERT_VALUES_EQUAL(stats.GetTableStats().GetPartCount(), 1);
+        }
+
+        auto readFuture = KqpSimpleSend(runtime, R"(SELECT blob_id, chunk_num, data0
+                FROM `/Root/table-1`
+                WHERE
+                    blob_id = Uuid("65df1ec1-a97d-47b2-ae56-3c023da6ee8c") AND
+                    chunk_num >= 0
+                ORDER BY blob_id, chunk_num ASC
+                LIMIT 100;)");
+        
+        ValidateReadResult(runtime, std::move(readFuture), 10);
+    }
+
+}
+
+} // namespace NKikimr
diff --git a/ydb/core/tx/datashard/ut_read_iterator/ya.make b/ydb/core/tx/datashard/ut_read_iterator/ya.make
index 04c4c9f3b718..e252560145a6 100644
--- a/ydb/core/tx/datashard/ut_read_iterator/ya.make
+++ b/ydb/core/tx/datashard/ut_read_iterator/ya.make
@@ -31,6 +31,7 @@ YQL_LAST_ABI_VERSION()
 
 SRCS(
     datashard_ut_read_iterator.cpp
+    datashard_ut_read_iterator_ext_blobs.cpp
 )
 
 REQUIREMENTS(ram:32)
