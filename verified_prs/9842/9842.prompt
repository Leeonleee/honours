You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
Error: INTERNAL Error: Calling DefaultValue() on a generated column
### What happens?

I clone the package and build the latest release. When executing `pragma_table_info` on a table with generated columns through the DuckDB CLI, an error is returned, ` Error: INTERNAL Error: Calling DefaultValue() on a generated column`.

I've noticed that a similar bug that has been fixed in https://github.com/duckdb/duckdb/issues/8833.
Since we can properly return the stringified generated expression.
A suggested Fix may be removing the IF branch in the following code.
```c++
// in src/parser/column_definition.cpp
// Remove the IF branch
const unique_ptr<ParsedExpression> &ColumnDefinition::DefaultValue() const {
	if (Generated()) {
		throw InternalException("Calling DefaultValue() on a generated column");
	}
	return expression;
}
```

### To Reproduce

```SQL
create table t1 (c1 int, c2 int generated always as (c1 + 1));
SELECT * FROM pragma_table_info(t1); -- Error: INTERNAL Error: Calling DefaultValue() on a generated column
```

### OS:

Ubuntu 22.04LTS x86

### DuckDB Version:

v0.9.3-dev668 802c71dafc

### DuckDB Client:

CLI

### Full Name:

Jiansen Song

### Affiliation:

Institute of Software Chinese Academy of Sciences

### Have you tried this on the latest `main` branch?

I have tested with a main build

### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/logo-dl/DuckDB_Logo-stacked.svg" height="120">
3: </div>
4: <br>
5: 
6: 
7: 
8: 
9: <p align="center">
10:   <a href="https://github.com/duckdb/duckdb/actions">
11:     <img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge">
12:   </a>
13:   <a href="https://discord.gg/tcvwpjfnZx">
14:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
15:   </a>
16:   <a href="https://github.com/duckdb/duckdb/releases/">
17:     <img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release">
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The detail of benchmarks is in our [Benchmark Guide](benchmark/README.md).
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
[end of README.md]
[start of src/catalog/catalog_entry/table_catalog_entry.cpp]
1: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
2: 
3: #include "duckdb/catalog/catalog.hpp"
4: #include "duckdb/catalog/catalog_entry/schema_catalog_entry.hpp"
5: #include "duckdb/common/algorithm.hpp"
6: #include "duckdb/common/exception.hpp"
7: #include "duckdb/main/database.hpp"
8: #include "duckdb/parser/constraints/list.hpp"
9: #include "duckdb/parser/parsed_data/create_table_info.hpp"
10: #include "duckdb/storage/table_storage_info.hpp"
11: #include "duckdb/planner/operator/logical_update.hpp"
12: #include "duckdb/planner/operator/logical_get.hpp"
13: #include "duckdb/planner/constraints/bound_check_constraint.hpp"
14: #include "duckdb/planner/operator/logical_projection.hpp"
15: 
16: #include <sstream>
17: 
18: namespace duckdb {
19: 
20: TableCatalogEntry::TableCatalogEntry(Catalog &catalog, SchemaCatalogEntry &schema, CreateTableInfo &info)
21:     : StandardEntry(CatalogType::TABLE_ENTRY, schema, catalog, info.table), columns(std::move(info.columns)),
22:       constraints(std::move(info.constraints)) {
23: 	this->temporary = info.temporary;
24: }
25: 
26: bool TableCatalogEntry::HasGeneratedColumns() const {
27: 	return columns.LogicalColumnCount() != columns.PhysicalColumnCount();
28: }
29: 
30: LogicalIndex TableCatalogEntry::GetColumnIndex(string &column_name, bool if_exists) {
31: 	auto entry = columns.GetColumnIndex(column_name);
32: 	if (!entry.IsValid()) {
33: 		if (if_exists) {
34: 			return entry;
35: 		}
36: 		throw BinderException("Table \"%s\" does not have a column with name \"%s\"", name, column_name);
37: 	}
38: 	return entry;
39: }
40: 
41: bool TableCatalogEntry::ColumnExists(const string &name) {
42: 	return columns.ColumnExists(name);
43: }
44: 
45: const ColumnDefinition &TableCatalogEntry::GetColumn(const string &name) {
46: 	return columns.GetColumn(name);
47: }
48: 
49: vector<LogicalType> TableCatalogEntry::GetTypes() {
50: 	vector<LogicalType> types;
51: 	for (auto &col : columns.Physical()) {
52: 		types.push_back(col.Type());
53: 	}
54: 	return types;
55: }
56: 
57: unique_ptr<CreateInfo> TableCatalogEntry::GetInfo() const {
58: 	auto result = make_uniq<CreateTableInfo>();
59: 	result->catalog = catalog.GetName();
60: 	result->schema = schema.name;
61: 	result->table = name;
62: 	result->columns = columns.Copy();
63: 	result->constraints.reserve(constraints.size());
64: 	std::for_each(constraints.begin(), constraints.end(),
65: 	              [&result](const unique_ptr<Constraint> &c) { result->constraints.emplace_back(c->Copy()); });
66: 	return std::move(result);
67: }
68: 
69: string TableCatalogEntry::ColumnsToSQL(const ColumnList &columns, const vector<unique_ptr<Constraint>> &constraints) {
70: 	std::stringstream ss;
71: 
72: 	ss << "(";
73: 
74: 	// find all columns that have NOT NULL specified, but are NOT primary key columns
75: 	logical_index_set_t not_null_columns;
76: 	logical_index_set_t unique_columns;
77: 	logical_index_set_t pk_columns;
78: 	unordered_set<string> multi_key_pks;
79: 	vector<string> extra_constraints;
80: 	for (auto &constraint : constraints) {
81: 		if (constraint->type == ConstraintType::NOT_NULL) {
82: 			auto &not_null = constraint->Cast<NotNullConstraint>();
83: 			not_null_columns.insert(not_null.index);
84: 		} else if (constraint->type == ConstraintType::UNIQUE) {
85: 			auto &pk = constraint->Cast<UniqueConstraint>();
86: 			vector<string> constraint_columns = pk.columns;
87: 			if (pk.index.index != DConstants::INVALID_INDEX) {
88: 				// no columns specified: single column constraint
89: 				if (pk.is_primary_key) {
90: 					pk_columns.insert(pk.index);
91: 				} else {
92: 					unique_columns.insert(pk.index);
93: 				}
94: 			} else {
95: 				// multi-column constraint, this constraint needs to go at the end after all columns
96: 				if (pk.is_primary_key) {
97: 					// multi key pk column: insert set of columns into multi_key_pks
98: 					for (auto &col : pk.columns) {
99: 						multi_key_pks.insert(col);
100: 					}
101: 				}
102: 				extra_constraints.push_back(constraint->ToString());
103: 			}
104: 		} else if (constraint->type == ConstraintType::FOREIGN_KEY) {
105: 			auto &fk = constraint->Cast<ForeignKeyConstraint>();
106: 			if (fk.info.type == ForeignKeyType::FK_TYPE_FOREIGN_KEY_TABLE ||
107: 			    fk.info.type == ForeignKeyType::FK_TYPE_SELF_REFERENCE_TABLE) {
108: 				extra_constraints.push_back(constraint->ToString());
109: 			}
110: 		} else {
111: 			extra_constraints.push_back(constraint->ToString());
112: 		}
113: 	}
114: 
115: 	for (auto &column : columns.Logical()) {
116: 		if (column.Oid() > 0) {
117: 			ss << ", ";
118: 		}
119: 		ss << KeywordHelper::WriteOptionallyQuoted(column.Name()) << " ";
120: 		ss << column.Type().ToString();
121: 		bool not_null = not_null_columns.find(column.Logical()) != not_null_columns.end();
122: 		bool is_single_key_pk = pk_columns.find(column.Logical()) != pk_columns.end();
123: 		bool is_multi_key_pk = multi_key_pks.find(column.Name()) != multi_key_pks.end();
124: 		bool is_unique = unique_columns.find(column.Logical()) != unique_columns.end();
125: 		if (not_null && !is_single_key_pk && !is_multi_key_pk) {
126: 			// NOT NULL but not a primary key column
127: 			ss << " NOT NULL";
128: 		}
129: 		if (is_single_key_pk) {
130: 			// single column pk: insert constraint here
131: 			ss << " PRIMARY KEY";
132: 		}
133: 		if (is_unique) {
134: 			// single column unique: insert constraint here
135: 			ss << " UNIQUE";
136: 		}
137: 		if (column.Generated()) {
138: 			ss << " GENERATED ALWAYS AS(" << column.GeneratedExpression().ToString() << ")";
139: 		} else if (column.DefaultValue()) {
140: 			ss << " DEFAULT(" << column.DefaultValue()->ToString() << ")";
141: 		}
142: 	}
143: 	// print any extra constraints that still need to be printed
144: 	for (auto &extra_constraint : extra_constraints) {
145: 		ss << ", ";
146: 		ss << extra_constraint;
147: 	}
148: 
149: 	ss << ")";
150: 	return ss.str();
151: }
152: 
153: string TableCatalogEntry::ToSQL() const {
154: 	auto create_info = GetInfo();
155: 	return create_info->ToString();
156: }
157: 
158: const ColumnList &TableCatalogEntry::GetColumns() const {
159: 	return columns;
160: }
161: 
162: const ColumnDefinition &TableCatalogEntry::GetColumn(LogicalIndex idx) {
163: 	return columns.GetColumn(idx);
164: }
165: 
166: const vector<unique_ptr<Constraint>> &TableCatalogEntry::GetConstraints() {
167: 	return constraints;
168: }
169: 
170: // LCOV_EXCL_START
171: DataTable &TableCatalogEntry::GetStorage() {
172: 	throw InternalException("Calling GetStorage on a TableCatalogEntry that is not a DuckTableEntry");
173: }
174: 
175: const vector<unique_ptr<BoundConstraint>> &TableCatalogEntry::GetBoundConstraints() {
176: 	throw InternalException("Calling GetBoundConstraints on a TableCatalogEntry that is not a DuckTableEntry");
177: }
178: 
179: // LCOV_EXCL_STOP
180: 
181: static void BindExtraColumns(TableCatalogEntry &table, LogicalGet &get, LogicalProjection &proj, LogicalUpdate &update,
182:                              physical_index_set_t &bound_columns) {
183: 	if (bound_columns.size() <= 1) {
184: 		return;
185: 	}
186: 	idx_t found_column_count = 0;
187: 	physical_index_set_t found_columns;
188: 	for (idx_t i = 0; i < update.columns.size(); i++) {
189: 		if (bound_columns.find(update.columns[i]) != bound_columns.end()) {
190: 			// this column is referenced in the CHECK constraint
191: 			found_column_count++;
192: 			found_columns.insert(update.columns[i]);
193: 		}
194: 	}
195: 	if (found_column_count > 0 && found_column_count != bound_columns.size()) {
196: 		// columns in this CHECK constraint were referenced, but not all were part of the UPDATE
197: 		// add them to the scan and update set
198: 		for (auto &check_column_id : bound_columns) {
199: 			if (found_columns.find(check_column_id) != found_columns.end()) {
200: 				// column is already projected
201: 				continue;
202: 			}
203: 			// column is not projected yet: project it by adding the clause "i=i" to the set of updated columns
204: 			auto &column = table.GetColumns().GetColumn(check_column_id);
205: 			update.expressions.push_back(make_uniq<BoundColumnRefExpression>(
206: 			    column.Type(), ColumnBinding(proj.table_index, proj.expressions.size())));
207: 			proj.expressions.push_back(make_uniq<BoundColumnRefExpression>(
208: 			    column.Type(), ColumnBinding(get.table_index, get.column_ids.size())));
209: 			get.column_ids.push_back(check_column_id.index);
210: 			update.columns.push_back(check_column_id);
211: 		}
212: 	}
213: }
214: 
215: static bool TypeSupportsRegularUpdate(const LogicalType &type) {
216: 	switch (type.id()) {
217: 	case LogicalTypeId::LIST:
218: 	case LogicalTypeId::MAP:
219: 	case LogicalTypeId::UNION:
220: 		// lists and maps and unions don't support updates directly
221: 		return false;
222: 	case LogicalTypeId::STRUCT: {
223: 		auto &child_types = StructType::GetChildTypes(type);
224: 		for (auto &entry : child_types) {
225: 			if (!TypeSupportsRegularUpdate(entry.second)) {
226: 				return false;
227: 			}
228: 		}
229: 		return true;
230: 	}
231: 	default:
232: 		return true;
233: 	}
234: }
235: 
236: vector<ColumnSegmentInfo> TableCatalogEntry::GetColumnSegmentInfo() {
237: 	return {};
238: }
239: 
240: void TableCatalogEntry::BindUpdateConstraints(LogicalGet &get, LogicalProjection &proj, LogicalUpdate &update,
241:                                               ClientContext &context) {
242: 	// check the constraints and indexes of the table to see if we need to project any additional columns
243: 	// we do this for indexes with multiple columns and CHECK constraints in the UPDATE clause
244: 	// suppose we have a constraint CHECK(i + j < 10); now we need both i and j to check the constraint
245: 	// if we are only updating one of the two columns we add the other one to the UPDATE set
246: 	// with a "useless" update (i.e. i=i) so we can verify that the CHECK constraint is not violated
247: 	for (auto &constraint : GetBoundConstraints()) {
248: 		if (constraint->type == ConstraintType::CHECK) {
249: 			auto &check = constraint->Cast<BoundCheckConstraint>();
250: 			// check constraint! check if we need to add any extra columns to the UPDATE clause
251: 			BindExtraColumns(*this, get, proj, update, check.bound_columns);
252: 		}
253: 	}
254: 	if (update.return_chunk) {
255: 		physical_index_set_t all_columns;
256: 		for (auto &column : GetColumns().Physical()) {
257: 			all_columns.insert(column.Physical());
258: 		}
259: 		BindExtraColumns(*this, get, proj, update, all_columns);
260: 	}
261: 	// for index updates we always turn any update into an insert and a delete
262: 	// we thus need all the columns to be available, hence we check if the update touches any index columns
263: 	// If the returning keyword is used, we need access to the whole row in case the user requests it.
264: 	// Therefore switch the update to a delete and insert.
265: 	update.update_is_del_and_insert = false;
266: 	TableStorageInfo table_storage_info = GetStorageInfo(context);
267: 	for (auto index : table_storage_info.index_info) {
268: 		for (auto &column : update.columns) {
269: 			if (index.column_set.find(column.index) != index.column_set.end()) {
270: 				update.update_is_del_and_insert = true;
271: 				break;
272: 			}
273: 		}
274: 	};
275: 
276: 	// we also convert any updates on LIST columns into delete + insert
277: 	for (auto &col_index : update.columns) {
278: 		auto &column = GetColumns().GetColumn(col_index);
279: 		if (!TypeSupportsRegularUpdate(column.Type())) {
280: 			update.update_is_del_and_insert = true;
281: 			break;
282: 		}
283: 	}
284: 
285: 	if (update.update_is_del_and_insert) {
286: 		// the update updates a column required by an index or requires returning the updated rows,
287: 		// push projections for all columns
288: 		physical_index_set_t all_columns;
289: 		for (auto &column : GetColumns().Physical()) {
290: 			all_columns.insert(column.Physical());
291: 		}
292: 		BindExtraColumns(*this, get, proj, update, all_columns);
293: 	}
294: }
295: 
296: } // namespace duckdb
[end of src/catalog/catalog_entry/table_catalog_entry.cpp]
[start of src/function/table/system/duckdb_columns.cpp]
1: #include "duckdb/function/table/system_functions.hpp"
2: 
3: #include "duckdb/catalog/catalog.hpp"
4: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
5: #include "duckdb/catalog/catalog_entry/view_catalog_entry.hpp"
6: #include "duckdb/common/exception.hpp"
7: #include "duckdb/main/client_context.hpp"
8: #include "duckdb/main/client_data.hpp"
9: #include "duckdb/parser/constraints/not_null_constraint.hpp"
10: 
11: #include <set>
12: 
13: namespace duckdb {
14: 
15: struct DuckDBColumnsData : public GlobalTableFunctionState {
16: 	DuckDBColumnsData() : offset(0), column_offset(0) {
17: 	}
18: 
19: 	vector<reference<CatalogEntry>> entries;
20: 	idx_t offset;
21: 	idx_t column_offset;
22: };
23: 
24: static unique_ptr<FunctionData> DuckDBColumnsBind(ClientContext &context, TableFunctionBindInput &input,
25:                                                   vector<LogicalType> &return_types, vector<string> &names) {
26: 	names.emplace_back("database_name");
27: 	return_types.emplace_back(LogicalType::VARCHAR);
28: 
29: 	names.emplace_back("database_oid");
30: 	return_types.emplace_back(LogicalType::BIGINT);
31: 
32: 	names.emplace_back("schema_name");
33: 	return_types.emplace_back(LogicalType::VARCHAR);
34: 
35: 	names.emplace_back("schema_oid");
36: 	return_types.emplace_back(LogicalType::BIGINT);
37: 
38: 	names.emplace_back("table_name");
39: 	return_types.emplace_back(LogicalType::VARCHAR);
40: 
41: 	names.emplace_back("table_oid");
42: 	return_types.emplace_back(LogicalType::BIGINT);
43: 
44: 	names.emplace_back("column_name");
45: 	return_types.emplace_back(LogicalType::VARCHAR);
46: 
47: 	names.emplace_back("column_index");
48: 	return_types.emplace_back(LogicalType::INTEGER);
49: 
50: 	names.emplace_back("internal");
51: 	return_types.emplace_back(LogicalType::BOOLEAN);
52: 
53: 	names.emplace_back("column_default");
54: 	return_types.emplace_back(LogicalType::VARCHAR);
55: 
56: 	names.emplace_back("is_nullable");
57: 	return_types.emplace_back(LogicalType::BOOLEAN);
58: 
59: 	names.emplace_back("data_type");
60: 	return_types.emplace_back(LogicalType::VARCHAR);
61: 
62: 	names.emplace_back("data_type_id");
63: 	return_types.emplace_back(LogicalType::BIGINT);
64: 
65: 	names.emplace_back("character_maximum_length");
66: 	return_types.emplace_back(LogicalType::INTEGER);
67: 
68: 	names.emplace_back("numeric_precision");
69: 	return_types.emplace_back(LogicalType::INTEGER);
70: 
71: 	names.emplace_back("numeric_precision_radix");
72: 	return_types.emplace_back(LogicalType::INTEGER);
73: 
74: 	names.emplace_back("numeric_scale");
75: 	return_types.emplace_back(LogicalType::INTEGER);
76: 
77: 	return nullptr;
78: }
79: 
80: unique_ptr<GlobalTableFunctionState> DuckDBColumnsInit(ClientContext &context, TableFunctionInitInput &input) {
81: 	auto result = make_uniq<DuckDBColumnsData>();
82: 
83: 	// scan all the schemas for tables and views and collect them
84: 	auto schemas = Catalog::GetAllSchemas(context);
85: 	for (auto &schema : schemas) {
86: 		schema.get().Scan(context, CatalogType::TABLE_ENTRY,
87: 		                  [&](CatalogEntry &entry) { result->entries.push_back(entry); });
88: 	}
89: 	return std::move(result);
90: }
91: 
92: class ColumnHelper {
93: public:
94: 	static unique_ptr<ColumnHelper> Create(CatalogEntry &entry);
95: 
96: 	virtual ~ColumnHelper() {
97: 	}
98: 
99: 	virtual StandardEntry &Entry() = 0;
100: 	virtual idx_t NumColumns() = 0;
101: 	virtual const string &ColumnName(idx_t col) = 0;
102: 	virtual const LogicalType &ColumnType(idx_t col) = 0;
103: 	virtual const Value ColumnDefault(idx_t col) = 0;
104: 	virtual bool IsNullable(idx_t col) = 0;
105: 
106: 	void WriteColumns(idx_t index, idx_t start_col, idx_t end_col, DataChunk &output);
107: };
108: 
109: class TableColumnHelper : public ColumnHelper {
110: public:
111: 	explicit TableColumnHelper(TableCatalogEntry &entry) : entry(entry) {
112: 		for (auto &constraint : entry.GetConstraints()) {
113: 			if (constraint->type == ConstraintType::NOT_NULL) {
114: 				auto &not_null = *reinterpret_cast<NotNullConstraint *>(constraint.get());
115: 				not_null_cols.insert(not_null.index.index);
116: 			}
117: 		}
118: 	}
119: 
120: 	StandardEntry &Entry() override {
121: 		return entry;
122: 	}
123: 	idx_t NumColumns() override {
124: 		return entry.GetColumns().LogicalColumnCount();
125: 	}
126: 	const string &ColumnName(idx_t col) override {
127: 		return entry.GetColumn(LogicalIndex(col)).Name();
128: 	}
129: 	const LogicalType &ColumnType(idx_t col) override {
130: 		return entry.GetColumn(LogicalIndex(col)).Type();
131: 	}
132: 	const Value ColumnDefault(idx_t col) override {
133: 		auto &column = entry.GetColumn(LogicalIndex(col));
134: 		if (column.Generated()) {
135: 			return Value(column.GeneratedExpression().ToString());
136: 		} else if (column.DefaultValue()) {
137: 			return Value(column.DefaultValue()->ToString());
138: 		}
139: 		return Value();
140: 	}
141: 	bool IsNullable(idx_t col) override {
142: 		return not_null_cols.find(col) == not_null_cols.end();
143: 	}
144: 
145: private:
146: 	TableCatalogEntry &entry;
147: 	std::set<idx_t> not_null_cols;
148: };
149: 
150: class ViewColumnHelper : public ColumnHelper {
151: public:
152: 	explicit ViewColumnHelper(ViewCatalogEntry &entry) : entry(entry) {
153: 	}
154: 
155: 	StandardEntry &Entry() override {
156: 		return entry;
157: 	}
158: 	idx_t NumColumns() override {
159: 		return entry.types.size();
160: 	}
161: 	const string &ColumnName(idx_t col) override {
162: 		return entry.aliases[col];
163: 	}
164: 	const LogicalType &ColumnType(idx_t col) override {
165: 		return entry.types[col];
166: 	}
167: 	const Value ColumnDefault(idx_t col) override {
168: 		return Value();
169: 	}
170: 	bool IsNullable(idx_t col) override {
171: 		return true;
172: 	}
173: 
174: private:
175: 	ViewCatalogEntry &entry;
176: };
177: 
178: unique_ptr<ColumnHelper> ColumnHelper::Create(CatalogEntry &entry) {
179: 	switch (entry.type) {
180: 	case CatalogType::TABLE_ENTRY:
181: 		return make_uniq<TableColumnHelper>(entry.Cast<TableCatalogEntry>());
182: 	case CatalogType::VIEW_ENTRY:
183: 		return make_uniq<ViewColumnHelper>(entry.Cast<ViewCatalogEntry>());
184: 	default:
185: 		throw NotImplementedException("Unsupported catalog type for duckdb_columns");
186: 	}
187: }
188: 
189: void ColumnHelper::WriteColumns(idx_t start_index, idx_t start_col, idx_t end_col, DataChunk &output) {
190: 	for (idx_t i = start_col; i < end_col; i++) {
191: 		auto index = start_index + (i - start_col);
192: 		auto &entry = Entry();
193: 
194: 		idx_t col = 0;
195: 		// database_name, VARCHAR
196: 		output.SetValue(col++, index, entry.catalog.GetName());
197: 		// database_oid, BIGINT
198: 		output.SetValue(col++, index, Value::BIGINT(entry.catalog.GetOid()));
199: 		// schema_name, VARCHAR
200: 		output.SetValue(col++, index, entry.schema.name);
201: 		// schema_oid, BIGINT
202: 		output.SetValue(col++, index, Value::BIGINT(entry.schema.oid));
203: 		// table_name, VARCHAR
204: 		output.SetValue(col++, index, entry.name);
205: 		// table_oid, BIGINT
206: 		output.SetValue(col++, index, Value::BIGINT(entry.oid));
207: 		// column_name, VARCHAR
208: 		output.SetValue(col++, index, Value(ColumnName(i)));
209: 		// column_index, INTEGER
210: 		output.SetValue(col++, index, Value::INTEGER(i + 1));
211: 		// internal, BOOLEAN
212: 		output.SetValue(col++, index, Value::BOOLEAN(entry.internal));
213: 		// column_default, VARCHAR
214: 		output.SetValue(col++, index, Value(ColumnDefault(i)));
215: 		// is_nullable, BOOLEAN
216: 		output.SetValue(col++, index, Value::BOOLEAN(IsNullable(i)));
217: 		// data_type, VARCHAR
218: 		const LogicalType &type = ColumnType(i);
219: 		output.SetValue(col++, index, Value(type.ToString()));
220: 		// data_type_id, BIGINT
221: 		output.SetValue(col++, index, Value::BIGINT(int(type.id())));
222: 		if (type == LogicalType::VARCHAR) {
223: 			// FIXME: need check constraints in place to set this correctly
224: 			// character_maximum_length, INTEGER
225: 			output.SetValue(col++, index, Value());
226: 		} else {
227: 			// "character_maximum_length", PhysicalType::INTEGER
228: 			output.SetValue(col++, index, Value());
229: 		}
230: 
231: 		Value numeric_precision, numeric_scale, numeric_precision_radix;
232: 		switch (type.id()) {
233: 		case LogicalTypeId::DECIMAL:
234: 			numeric_precision = Value::INTEGER(DecimalType::GetWidth(type));
235: 			numeric_scale = Value::INTEGER(DecimalType::GetScale(type));
236: 			numeric_precision_radix = Value::INTEGER(10);
237: 			break;
238: 		case LogicalTypeId::HUGEINT:
239: 			numeric_precision = Value::INTEGER(128);
240: 			numeric_scale = Value::INTEGER(0);
241: 			numeric_precision_radix = Value::INTEGER(2);
242: 			break;
243: 		case LogicalTypeId::BIGINT:
244: 			numeric_precision = Value::INTEGER(64);
245: 			numeric_scale = Value::INTEGER(0);
246: 			numeric_precision_radix = Value::INTEGER(2);
247: 			break;
248: 		case LogicalTypeId::INTEGER:
249: 			numeric_precision = Value::INTEGER(32);
250: 			numeric_scale = Value::INTEGER(0);
251: 			numeric_precision_radix = Value::INTEGER(2);
252: 			break;
253: 		case LogicalTypeId::SMALLINT:
254: 			numeric_precision = Value::INTEGER(16);
255: 			numeric_scale = Value::INTEGER(0);
256: 			numeric_precision_radix = Value::INTEGER(2);
257: 			break;
258: 		case LogicalTypeId::TINYINT:
259: 			numeric_precision = Value::INTEGER(8);
260: 			numeric_scale = Value::INTEGER(0);
261: 			numeric_precision_radix = Value::INTEGER(2);
262: 			break;
263: 		case LogicalTypeId::FLOAT:
264: 			numeric_precision = Value::INTEGER(24);
265: 			numeric_scale = Value::INTEGER(0);
266: 			numeric_precision_radix = Value::INTEGER(2);
267: 			break;
268: 		case LogicalTypeId::DOUBLE:
269: 			numeric_precision = Value::INTEGER(53);
270: 			numeric_scale = Value::INTEGER(0);
271: 			numeric_precision_radix = Value::INTEGER(2);
272: 			break;
273: 		default:
274: 			numeric_precision = Value();
275: 			numeric_scale = Value();
276: 			numeric_precision_radix = Value();
277: 			break;
278: 		}
279: 
280: 		// numeric_precision, INTEGER
281: 		output.SetValue(col++, index, numeric_precision);
282: 		// numeric_precision_radix, INTEGER
283: 		output.SetValue(col++, index, numeric_precision_radix);
284: 		// numeric_scale, INTEGER
285: 		output.SetValue(col++, index, numeric_scale);
286: 	}
287: }
288: 
289: void DuckDBColumnsFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &output) {
290: 	auto &data = data_p.global_state->Cast<DuckDBColumnsData>();
291: 	if (data.offset >= data.entries.size()) {
292: 		// finished returning values
293: 		return;
294: 	}
295: 
296: 	// We need to track the offset of the relation we're writing as well as the last column
297: 	// we wrote from that relation (if any); it's possible that we can fill up the output
298: 	// with a partial list of columns from a relation and will need to pick up processing the
299: 	// next chunk at the same spot.
300: 	idx_t next = data.offset;
301: 	idx_t column_offset = data.column_offset;
302: 	idx_t index = 0;
303: 	while (next < data.entries.size() && index < STANDARD_VECTOR_SIZE) {
304: 		auto column_helper = ColumnHelper::Create(data.entries[next].get());
305: 		idx_t columns = column_helper->NumColumns();
306: 
307: 		// Check to see if we are going to exceed the maximum index for a DataChunk
308: 		if (index + (columns - column_offset) > STANDARD_VECTOR_SIZE) {
309: 			idx_t column_limit = column_offset + (STANDARD_VECTOR_SIZE - index);
310: 			output.SetCardinality(STANDARD_VECTOR_SIZE);
311: 			column_helper->WriteColumns(index, column_offset, column_limit, output);
312: 
313: 			// Make the current column limit the column offset when we process the next chunk
314: 			column_offset = column_limit;
315: 			break;
316: 		} else {
317: 			// Otherwise, write all of the columns from the current relation and
318: 			// then move on to the next one.
319: 			output.SetCardinality(index + (columns - column_offset));
320: 			column_helper->WriteColumns(index, column_offset, columns, output);
321: 			index += columns - column_offset;
322: 			next++;
323: 			column_offset = 0;
324: 		}
325: 	}
326: 	data.offset = next;
327: 	data.column_offset = column_offset;
328: }
329: 
330: void DuckDBColumnsFun::RegisterFunction(BuiltinFunctions &set) {
331: 	set.AddFunction(TableFunction("duckdb_columns", {}, DuckDBColumnsFunction, DuckDBColumnsBind, DuckDBColumnsInit));
332: }
333: 
334: } // namespace duckdb
[end of src/function/table/system/duckdb_columns.cpp]
[start of src/function/table/system/pragma_table_info.cpp]
1: #include "duckdb/function/table/system_functions.hpp"
2: 
3: #include "duckdb/catalog/catalog.hpp"
4: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
5: #include "duckdb/catalog/catalog_entry/view_catalog_entry.hpp"
6: #include "duckdb/parser/qualified_name.hpp"
7: #include "duckdb/parser/constraints/not_null_constraint.hpp"
8: #include "duckdb/parser/constraints/unique_constraint.hpp"
9: #include "duckdb/planner/expression/bound_parameter_expression.hpp"
10: #include "duckdb/planner/binder.hpp"
11: 
12: #include "duckdb/common/exception.hpp"
13: #include "duckdb/common/limits.hpp"
14: 
15: #include <algorithm>
16: 
17: namespace duckdb {
18: 
19: struct PragmaTableFunctionData : public TableFunctionData {
20: 	explicit PragmaTableFunctionData(CatalogEntry &entry_p) : entry(entry_p) {
21: 	}
22: 
23: 	CatalogEntry &entry;
24: };
25: 
26: struct PragmaTableOperatorData : public GlobalTableFunctionState {
27: 	PragmaTableOperatorData() : offset(0) {
28: 	}
29: 	idx_t offset;
30: };
31: 
32: static unique_ptr<FunctionData> PragmaTableInfoBind(ClientContext &context, TableFunctionBindInput &input,
33:                                                     vector<LogicalType> &return_types, vector<string> &names) {
34: 
35: 	names.emplace_back("cid");
36: 	return_types.emplace_back(LogicalType::INTEGER);
37: 
38: 	names.emplace_back("name");
39: 	return_types.emplace_back(LogicalType::VARCHAR);
40: 
41: 	names.emplace_back("type");
42: 	return_types.emplace_back(LogicalType::VARCHAR);
43: 
44: 	names.emplace_back("notnull");
45: 	return_types.emplace_back(LogicalType::BOOLEAN);
46: 
47: 	names.emplace_back("dflt_value");
48: 	return_types.emplace_back(LogicalType::VARCHAR);
49: 
50: 	names.emplace_back("pk");
51: 	return_types.emplace_back(LogicalType::BOOLEAN);
52: 
53: 	auto qname = QualifiedName::Parse(input.inputs[0].GetValue<string>());
54: 
55: 	// look up the table name in the catalog
56: 	Binder::BindSchemaOrCatalog(context, qname.catalog, qname.schema);
57: 	auto &entry = Catalog::GetEntry(context, CatalogType::TABLE_ENTRY, qname.catalog, qname.schema, qname.name);
58: 	return make_uniq<PragmaTableFunctionData>(entry);
59: }
60: 
61: unique_ptr<GlobalTableFunctionState> PragmaTableInfoInit(ClientContext &context, TableFunctionInitInput &input) {
62: 	return make_uniq<PragmaTableOperatorData>();
63: }
64: 
65: static void CheckConstraints(TableCatalogEntry &table, const ColumnDefinition &column, bool &out_not_null,
66:                              bool &out_pk) {
67: 	out_not_null = false;
68: 	out_pk = false;
69: 	// check all constraints
70: 	// FIXME: this is pretty inefficient, it probably doesn't matter
71: 	for (auto &constraint : table.GetConstraints()) {
72: 		switch (constraint->type) {
73: 		case ConstraintType::NOT_NULL: {
74: 			auto &not_null = constraint->Cast<NotNullConstraint>();
75: 			if (not_null.index == column.Logical()) {
76: 				out_not_null = true;
77: 			}
78: 			break;
79: 		}
80: 		case ConstraintType::UNIQUE: {
81: 			auto &unique = constraint->Cast<UniqueConstraint>();
82: 			if (unique.is_primary_key) {
83: 				if (unique.index == column.Logical()) {
84: 					out_pk = true;
85: 				}
86: 				if (std::find(unique.columns.begin(), unique.columns.end(), column.GetName()) != unique.columns.end()) {
87: 					out_pk = true;
88: 				}
89: 			}
90: 			break;
91: 		}
92: 		default:
93: 			break;
94: 		}
95: 	}
96: }
97: 
98: static void PragmaTableInfoTable(PragmaTableOperatorData &data, TableCatalogEntry &table, DataChunk &output) {
99: 	if (data.offset >= table.GetColumns().LogicalColumnCount()) {
100: 		// finished returning values
101: 		return;
102: 	}
103: 	// start returning values
104: 	// either fill up the chunk or return all the remaining columns
105: 	idx_t next = MinValue<idx_t>(data.offset + STANDARD_VECTOR_SIZE, table.GetColumns().LogicalColumnCount());
106: 	output.SetCardinality(next - data.offset);
107: 
108: 	for (idx_t i = data.offset; i < next; i++) {
109: 		bool not_null, pk;
110: 		auto index = i - data.offset;
111: 		auto &column = table.GetColumn(LogicalIndex(i));
112: 		D_ASSERT(column.Oid() < (idx_t)NumericLimits<int32_t>::Maximum());
113: 		CheckConstraints(table, column, not_null, pk);
114: 
115: 		// return values:
116: 		// "cid", PhysicalType::INT32
117: 		output.SetValue(0, index, Value::INTEGER((int32_t)column.Oid()));
118: 		// "name", PhysicalType::VARCHAR
119: 		output.SetValue(1, index, Value(column.Name()));
120: 		// "type", PhysicalType::VARCHAR
121: 		output.SetValue(2, index, Value(column.Type().ToString()));
122: 		// "notnull", PhysicalType::BOOL
123: 		output.SetValue(3, index, Value::BOOLEAN(not_null));
124: 		// "dflt_value", PhysicalType::VARCHAR
125: 		Value def_value = column.DefaultValue() ? Value(column.DefaultValue()->ToString()) : Value();
126: 		output.SetValue(4, index, def_value);
127: 		// "pk", PhysicalType::BOOL
128: 		output.SetValue(5, index, Value::BOOLEAN(pk));
129: 	}
130: 	data.offset = next;
131: }
132: 
133: static void PragmaTableInfoView(PragmaTableOperatorData &data, ViewCatalogEntry &view, DataChunk &output) {
134: 	if (data.offset >= view.types.size()) {
135: 		// finished returning values
136: 		return;
137: 	}
138: 	// start returning values
139: 	// either fill up the chunk or return all the remaining columns
140: 	idx_t next = MinValue<idx_t>(data.offset + STANDARD_VECTOR_SIZE, view.types.size());
141: 	output.SetCardinality(next - data.offset);
142: 
143: 	for (idx_t i = data.offset; i < next; i++) {
144: 		auto index = i - data.offset;
145: 		auto type = view.types[i];
146: 		auto &name = view.aliases[i];
147: 		// return values:
148: 		// "cid", PhysicalType::INT32
149: 
150: 		output.SetValue(0, index, Value::INTEGER((int32_t)i));
151: 		// "name", PhysicalType::VARCHAR
152: 		output.SetValue(1, index, Value(name));
153: 		// "type", PhysicalType::VARCHAR
154: 		output.SetValue(2, index, Value(type.ToString()));
155: 		// "notnull", PhysicalType::BOOL
156: 		output.SetValue(3, index, Value::BOOLEAN(false));
157: 		// "dflt_value", PhysicalType::VARCHAR
158: 		output.SetValue(4, index, Value());
159: 		// "pk", PhysicalType::BOOL
160: 		output.SetValue(5, index, Value::BOOLEAN(false));
161: 	}
162: 	data.offset = next;
163: }
164: 
165: static void PragmaTableInfoFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &output) {
166: 	auto &bind_data = data_p.bind_data->Cast<PragmaTableFunctionData>();
167: 	auto &state = data_p.global_state->Cast<PragmaTableOperatorData>();
168: 	switch (bind_data.entry.type) {
169: 	case CatalogType::TABLE_ENTRY:
170: 		PragmaTableInfoTable(state, bind_data.entry.Cast<TableCatalogEntry>(), output);
171: 		break;
172: 	case CatalogType::VIEW_ENTRY:
173: 		PragmaTableInfoView(state, bind_data.entry.Cast<ViewCatalogEntry>(), output);
174: 		break;
175: 	default:
176: 		throw NotImplementedException("Unimplemented catalog type for pragma_table_info");
177: 	}
178: }
179: 
180: void PragmaTableInfo::RegisterFunction(BuiltinFunctions &set) {
181: 	set.AddFunction(TableFunction("pragma_table_info", {LogicalType::VARCHAR}, PragmaTableInfoFunction,
182: 	                              PragmaTableInfoBind, PragmaTableInfoInit));
183: }
184: 
185: } // namespace duckdb
[end of src/function/table/system/pragma_table_info.cpp]
[start of src/include/duckdb/parser/column_definition.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/parser/column_definition.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/common.hpp"
12: #include "duckdb/common/types/value.hpp"
13: #include "duckdb/parser/parsed_expression.hpp"
14: #include "duckdb/common/enums/compression_type.hpp"
15: #include "duckdb/catalog/catalog_entry/table_column_type.hpp"
16: #include "duckdb/common/case_insensitive_map.hpp"
17: 
18: namespace duckdb {
19: 
20: struct RenameColumnInfo;
21: struct RenameTableInfo;
22: 
23: class ColumnDefinition;
24: 
25: //! A column of a table.
26: class ColumnDefinition {
27: public:
28: 	DUCKDB_API ColumnDefinition(string name, LogicalType type);
29: 	DUCKDB_API ColumnDefinition(string name, LogicalType type, unique_ptr<ParsedExpression> expression,
30: 	                            TableColumnType category);
31: 
32: public:
33: 	//! default_value
34: 	const unique_ptr<ParsedExpression> &DefaultValue() const;
35: 	void SetDefaultValue(unique_ptr<ParsedExpression> default_value);
36: 
37: 	//! type
38: 	DUCKDB_API const LogicalType &Type() const;
39: 	LogicalType &TypeMutable();
40: 	void SetType(const LogicalType &type);
41: 
42: 	//! name
43: 	DUCKDB_API const string &Name() const;
44: 	void SetName(const string &name);
45: 
46: 	//! compression_type
47: 	const duckdb::CompressionType &CompressionType() const;
48: 	void SetCompressionType(duckdb::CompressionType compression_type);
49: 
50: 	//! storage_oid
51: 	const storage_t &StorageOid() const;
52: 	void SetStorageOid(storage_t storage_oid);
53: 
54: 	LogicalIndex Logical() const;
55: 	PhysicalIndex Physical() const;
56: 
57: 	//! oid
58: 	const column_t &Oid() const;
59: 	void SetOid(column_t oid);
60: 
61: 	//! category
62: 	const TableColumnType &Category() const;
63: 	//! Whether this column is a Generated Column
64: 	bool Generated() const;
65: 	DUCKDB_API ColumnDefinition Copy() const;
66: 
67: 	DUCKDB_API void Serialize(Serializer &serializer) const;
68: 	DUCKDB_API static ColumnDefinition Deserialize(Deserializer &deserializer);
69: 
70: 	//===--------------------------------------------------------------------===//
71: 	// Generated Columns (VIRTUAL)
72: 	//===--------------------------------------------------------------------===//
73: 
74: 	ParsedExpression &GeneratedExpressionMutable();
75: 	const ParsedExpression &GeneratedExpression() const;
76: 	void SetGeneratedExpression(unique_ptr<ParsedExpression> expression);
77: 	void ChangeGeneratedExpressionType(const LogicalType &type);
78: 	void GetListOfDependencies(vector<string> &dependencies) const;
79: 
80: 	string GetName() const;
81: 
82: 	LogicalType GetType() const;
83: 
84: private:
85: 	//! The name of the entry
86: 	string name;
87: 	//! The type of the column
88: 	LogicalType type;
89: 	//! Compression Type used for this column
90: 	duckdb::CompressionType compression_type = duckdb::CompressionType::COMPRESSION_AUTO;
91: 	//! The index of the column in the storage of the table
92: 	storage_t storage_oid = DConstants::INVALID_INDEX;
93: 	//! The index of the column in the table
94: 	idx_t oid = DConstants::INVALID_INDEX;
95: 	//! The category of the column
96: 	TableColumnType category = TableColumnType::STANDARD;
97: 	//! The default value of the column (for non-generated columns)
98: 	//! The generated column expression (for generated columns)
99: 	unique_ptr<ParsedExpression> expression;
100: };
101: 
102: } // namespace duckdb
[end of src/include/duckdb/parser/column_definition.hpp]
[start of src/parser/column_definition.cpp]
1: #include "duckdb/parser/column_definition.hpp"
2: #include "duckdb/parser/parsed_expression_iterator.hpp"
3: #include "duckdb/parser/expression/columnref_expression.hpp"
4: #include "duckdb/parser/parsed_data/alter_table_info.hpp"
5: #include "duckdb/parser/expression/cast_expression.hpp"
6: 
7: namespace duckdb {
8: 
9: ColumnDefinition::ColumnDefinition(string name_p, LogicalType type_p)
10:     : name(std::move(name_p)), type(std::move(type_p)) {
11: }
12: 
13: ColumnDefinition::ColumnDefinition(string name_p, LogicalType type_p, unique_ptr<ParsedExpression> expression,
14:                                    TableColumnType category)
15:     : name(std::move(name_p)), type(std::move(type_p)), category(category), expression(std::move(expression)) {
16: }
17: 
18: ColumnDefinition ColumnDefinition::Copy() const {
19: 	ColumnDefinition copy(name, type);
20: 	copy.oid = oid;
21: 	copy.storage_oid = storage_oid;
22: 	copy.expression = expression ? expression->Copy() : nullptr;
23: 	copy.compression_type = compression_type;
24: 	copy.category = category;
25: 	return copy;
26: }
27: 
28: const unique_ptr<ParsedExpression> &ColumnDefinition::DefaultValue() const {
29: 	if (Generated()) {
30: 		throw InternalException("Calling DefaultValue() on a generated column");
31: 	}
32: 	return expression;
33: }
34: 
35: void ColumnDefinition::SetDefaultValue(unique_ptr<ParsedExpression> default_value) {
36: 	if (Generated()) {
37: 		throw InternalException("Calling SetDefaultValue() on a generated column");
38: 	}
39: 	this->expression = std::move(default_value);
40: }
41: 
42: const LogicalType &ColumnDefinition::Type() const {
43: 	return type;
44: }
45: 
46: LogicalType &ColumnDefinition::TypeMutable() {
47: 	return type;
48: }
49: 
50: void ColumnDefinition::SetType(const LogicalType &type) {
51: 	this->type = type;
52: }
53: 
54: const string &ColumnDefinition::Name() const {
55: 	return name;
56: }
57: 
58: void ColumnDefinition::SetName(const string &name) {
59: 	this->name = name;
60: }
61: 
62: const duckdb::CompressionType &ColumnDefinition::CompressionType() const {
63: 	return compression_type;
64: }
65: 
66: void ColumnDefinition::SetCompressionType(duckdb::CompressionType compression_type) {
67: 	this->compression_type = compression_type;
68: }
69: 
70: const storage_t &ColumnDefinition::StorageOid() const {
71: 	return storage_oid;
72: }
73: 
74: LogicalIndex ColumnDefinition::Logical() const {
75: 	return LogicalIndex(oid);
76: }
77: 
78: PhysicalIndex ColumnDefinition::Physical() const {
79: 	return PhysicalIndex(storage_oid);
80: }
81: 
82: void ColumnDefinition::SetStorageOid(storage_t storage_oid) {
83: 	this->storage_oid = storage_oid;
84: }
85: 
86: const column_t &ColumnDefinition::Oid() const {
87: 	return oid;
88: }
89: 
90: void ColumnDefinition::SetOid(column_t oid) {
91: 	this->oid = oid;
92: }
93: 
94: const TableColumnType &ColumnDefinition::Category() const {
95: 	return category;
96: }
97: 
98: bool ColumnDefinition::Generated() const {
99: 	return category == TableColumnType::GENERATED;
100: }
101: 
102: //===--------------------------------------------------------------------===//
103: // Generated Columns (VIRTUAL)
104: //===--------------------------------------------------------------------===//
105: 
106: static void VerifyColumnRefs(ParsedExpression &expr) {
107: 	if (expr.type == ExpressionType::COLUMN_REF) {
108: 		auto &column_ref = expr.Cast<ColumnRefExpression>();
109: 		if (column_ref.IsQualified()) {
110: 			throw ParserException(
111: 			    "Qualified (tbl.name) column references are not allowed inside of generated column expressions");
112: 		}
113: 	}
114: 	ParsedExpressionIterator::EnumerateChildren(
115: 	    expr, [&](const ParsedExpression &child) { VerifyColumnRefs((ParsedExpression &)child); });
116: }
117: 
118: static void InnerGetListOfDependencies(ParsedExpression &expr, vector<string> &dependencies) {
119: 	if (expr.type == ExpressionType::COLUMN_REF) {
120: 		auto columnref = expr.Cast<ColumnRefExpression>();
121: 		auto &name = columnref.GetColumnName();
122: 		dependencies.push_back(name);
123: 	}
124: 	ParsedExpressionIterator::EnumerateChildren(expr, [&](const ParsedExpression &child) {
125: 		if (expr.type == ExpressionType::LAMBDA) {
126: 			throw NotImplementedException("Lambda functions are currently not supported in generated columns.");
127: 		}
128: 		InnerGetListOfDependencies((ParsedExpression &)child, dependencies);
129: 	});
130: }
131: 
132: void ColumnDefinition::GetListOfDependencies(vector<string> &dependencies) const {
133: 	D_ASSERT(Generated());
134: 	InnerGetListOfDependencies(*expression, dependencies);
135: }
136: 
137: string ColumnDefinition::GetName() const {
138: 	return name;
139: }
140: 
141: LogicalType ColumnDefinition::GetType() const {
142: 	return type;
143: }
144: 
145: void ColumnDefinition::SetGeneratedExpression(unique_ptr<ParsedExpression> new_expr) {
146: 	category = TableColumnType::GENERATED;
147: 
148: 	if (new_expr->HasSubquery()) {
149: 		throw ParserException("Expression of generated column \"%s\" contains a subquery, which isn't allowed", name);
150: 	}
151: 
152: 	VerifyColumnRefs(*new_expr);
153: 	if (type.id() == LogicalTypeId::ANY) {
154: 		expression = std::move(new_expr);
155: 		return;
156: 	}
157: 	// Always wrap the expression in a cast, that way we can always update the cast when we change the type
158: 	// Except if the type is LogicalType::ANY (no type specified)
159: 	expression = make_uniq_base<ParsedExpression, CastExpression>(type, std::move(new_expr));
160: }
161: 
162: void ColumnDefinition::ChangeGeneratedExpressionType(const LogicalType &type) {
163: 	D_ASSERT(Generated());
164: 	// First time the type is set, add a cast around the expression
165: 	D_ASSERT(this->type.id() == LogicalTypeId::ANY);
166: 	expression = make_uniq_base<ParsedExpression, CastExpression>(type, std::move(expression));
167: 	// Every generated expression should be wrapped in a cast on creation
168: 	// D_ASSERT(generated_expression->type == ExpressionType::OPERATOR_CAST);
169: 	// auto &cast_expr = generated_expression->Cast<CastExpression>();
170: 	// auto base_expr = std::move(cast_expr.child);
171: 	// generated_expression = make_uniq_base<ParsedExpression, CastExpression>(type, std::move(base_expr));
172: }
173: 
174: const ParsedExpression &ColumnDefinition::GeneratedExpression() const {
175: 	D_ASSERT(Generated());
176: 	return *expression;
177: }
178: 
179: ParsedExpression &ColumnDefinition::GeneratedExpressionMutable() {
180: 	D_ASSERT(Generated());
181: 	return *expression;
182: }
183: 
184: } // namespace duckdb
[end of src/parser/column_definition.cpp]
[start of src/parser/transform/constraint/transform_constraint.cpp]
1: #include "duckdb/parser/column_definition.hpp"
2: #include "duckdb/parser/constraint.hpp"
3: #include "duckdb/parser/constraints/list.hpp"
4: #include "duckdb/parser/transformer.hpp"
5: 
6: namespace duckdb {
7: 
8: static void ParseSchemaTableNameFK(duckdb_libpgquery::PGRangeVar *input, ForeignKeyInfo &fk_info) {
9: 	if (input->catalogname) {
10: 		throw ParserException("FOREIGN KEY constraints cannot be defined cross-database");
11: 	}
12: 	if (input->schemaname) {
13: 		fk_info.schema = input->schemaname;
14: 	} else {
15: 		fk_info.schema = "";
16: 	};
17: 	fk_info.table = input->relname;
18: }
19: 
20: static bool ForeignKeyActionSupported(char action) {
21: 	switch (action) {
22: 	case PG_FKCONSTR_ACTION_NOACTION:
23: 	case PG_FKCONSTR_ACTION_RESTRICT:
24: 		return true;
25: 	case PG_FKCONSTR_ACTION_CASCADE:
26: 	case PG_FKCONSTR_ACTION_SETDEFAULT:
27: 	case PG_FKCONSTR_ACTION_SETNULL:
28: 		return false;
29: 	default:
30: 		D_ASSERT(false);
31: 	}
32: 	return false;
33: }
34: 
35: static unique_ptr<ForeignKeyConstraint>
36: TransformForeignKeyConstraint(duckdb_libpgquery::PGConstraint *constraint,
37:                               optional_ptr<const string> override_fk_column = nullptr) {
38: 	D_ASSERT(constraint);
39: 	if (!ForeignKeyActionSupported(constraint->fk_upd_action) ||
40: 	    !ForeignKeyActionSupported(constraint->fk_del_action)) {
41: 		throw ParserException("FOREIGN KEY constraints cannot use CASCADE, SET NULL or SET DEFAULT");
42: 	}
43: 	ForeignKeyInfo fk_info;
44: 	fk_info.type = ForeignKeyType::FK_TYPE_FOREIGN_KEY_TABLE;
45: 	ParseSchemaTableNameFK(constraint->pktable, fk_info);
46: 	vector<string> pk_columns, fk_columns;
47: 	if (override_fk_column) {
48: 		D_ASSERT(!constraint->fk_attrs);
49: 		fk_columns.emplace_back(*override_fk_column);
50: 	} else if (constraint->fk_attrs) {
51: 		for (auto kc = constraint->fk_attrs->head; kc; kc = kc->next) {
52: 			fk_columns.emplace_back(reinterpret_cast<duckdb_libpgquery::PGValue *>(kc->data.ptr_value)->val.str);
53: 		}
54: 	}
55: 	if (constraint->pk_attrs) {
56: 		for (auto kc = constraint->pk_attrs->head; kc; kc = kc->next) {
57: 			pk_columns.emplace_back(reinterpret_cast<duckdb_libpgquery::PGValue *>(kc->data.ptr_value)->val.str);
58: 		}
59: 	}
60: 	if (!pk_columns.empty() && pk_columns.size() != fk_columns.size()) {
61: 		throw ParserException("The number of referencing and referenced columns for foreign keys must be the same");
62: 	}
63: 	if (fk_columns.empty()) {
64: 		throw ParserException("The set of referencing and referenced columns for foreign keys must be not empty");
65: 	}
66: 	return make_uniq<ForeignKeyConstraint>(pk_columns, fk_columns, std::move(fk_info));
67: }
68: 
69: unique_ptr<Constraint> Transformer::TransformConstraint(duckdb_libpgquery::PGListCell *cell) {
70: 	auto constraint = reinterpret_cast<duckdb_libpgquery::PGConstraint *>(cell->data.ptr_value);
71: 	D_ASSERT(constraint);
72: 	switch (constraint->contype) {
73: 	case duckdb_libpgquery::PG_CONSTR_UNIQUE:
74: 	case duckdb_libpgquery::PG_CONSTR_PRIMARY: {
75: 		bool is_primary_key = constraint->contype == duckdb_libpgquery::PG_CONSTR_PRIMARY;
76: 		if (!constraint->keys) {
77: 			throw ParserException("UNIQUE USING INDEX is not supported");
78: 		}
79: 		vector<string> columns;
80: 		for (auto kc = constraint->keys->head; kc; kc = kc->next) {
81: 			columns.emplace_back(reinterpret_cast<duckdb_libpgquery::PGValue *>(kc->data.ptr_value)->val.str);
82: 		}
83: 		return make_uniq<UniqueConstraint>(columns, is_primary_key);
84: 	}
85: 	case duckdb_libpgquery::PG_CONSTR_CHECK: {
86: 		auto expression = TransformExpression(constraint->raw_expr);
87: 		if (expression->HasSubquery()) {
88: 			throw ParserException("subqueries prohibited in CHECK constraints");
89: 		}
90: 		return make_uniq<CheckConstraint>(TransformExpression(constraint->raw_expr));
91: 	}
92: 	case duckdb_libpgquery::PG_CONSTR_FOREIGN:
93: 		return TransformForeignKeyConstraint(constraint);
94: 
95: 	default:
96: 		throw NotImplementedException("Constraint type not handled yet!");
97: 	}
98: }
99: 
100: unique_ptr<Constraint> Transformer::TransformConstraint(duckdb_libpgquery::PGListCell *cell, ColumnDefinition &column,
101:                                                         idx_t index) {
102: 	auto constraint = reinterpret_cast<duckdb_libpgquery::PGConstraint *>(cell->data.ptr_value);
103: 	D_ASSERT(constraint);
104: 	switch (constraint->contype) {
105: 	case duckdb_libpgquery::PG_CONSTR_NOTNULL:
106: 		return make_uniq<NotNullConstraint>(LogicalIndex(index));
107: 	case duckdb_libpgquery::PG_CONSTR_CHECK:
108: 		return TransformConstraint(cell);
109: 	case duckdb_libpgquery::PG_CONSTR_PRIMARY:
110: 		return make_uniq<UniqueConstraint>(LogicalIndex(index), true);
111: 	case duckdb_libpgquery::PG_CONSTR_UNIQUE:
112: 		return make_uniq<UniqueConstraint>(LogicalIndex(index), false);
113: 	case duckdb_libpgquery::PG_CONSTR_NULL:
114: 		return nullptr;
115: 	case duckdb_libpgquery::PG_CONSTR_GENERATED_VIRTUAL: {
116: 		if (column.DefaultValue()) {
117: 			throw InvalidInputException("DEFAULT constraint on GENERATED column \"%s\" is not allowed", column.Name());
118: 		}
119: 		column.SetGeneratedExpression(TransformExpression(constraint->raw_expr));
120: 		return nullptr;
121: 	}
122: 	case duckdb_libpgquery::PG_CONSTR_GENERATED_STORED:
123: 		throw InvalidInputException("Can not create a STORED generated column!");
124: 	case duckdb_libpgquery::PG_CONSTR_DEFAULT:
125: 		column.SetDefaultValue(TransformExpression(constraint->raw_expr));
126: 		return nullptr;
127: 	case duckdb_libpgquery::PG_CONSTR_COMPRESSION:
128: 		column.SetCompressionType(CompressionTypeFromString(constraint->compression_name));
129: 		if (column.CompressionType() == CompressionType::COMPRESSION_AUTO) {
130: 			throw ParserException("Unrecognized option for column compression, expected none, uncompressed, rle, "
131: 			                      "dictionary, pfor, bitpacking or fsst");
132: 		}
133: 		return nullptr;
134: 	case duckdb_libpgquery::PG_CONSTR_FOREIGN:
135: 		return TransformForeignKeyConstraint(constraint, &column.Name());
136: 	default:
137: 		throw NotImplementedException("Constraint not implemented!");
138: 	}
139: }
140: 
141: } // namespace duckdb
[end of src/parser/transform/constraint/transform_constraint.cpp]
[start of src/planner/binder/statement/bind_create_table.cpp]
1: #include "duckdb/parser/constraints/list.hpp"
2: #include "duckdb/parser/expression/cast_expression.hpp"
3: #include "duckdb/planner/binder.hpp"
4: #include "duckdb/planner/constraints/list.hpp"
5: #include "duckdb/planner/expression/bound_constant_expression.hpp"
6: #include "duckdb/planner/expression/bound_function_expression.hpp"
7: #include "duckdb/planner/expression_binder/check_binder.hpp"
8: #include "duckdb/planner/expression_binder/constant_binder.hpp"
9: #include "duckdb/planner/parsed_data/bound_create_table_info.hpp"
10: #include "duckdb/catalog/catalog_entry/type_catalog_entry.hpp"
11: #include "duckdb/catalog/dependency_manager.hpp"
12: #include "duckdb/function/table/table_scan.hpp"
13: #include "duckdb/planner/operator/logical_get.hpp"
14: #include "duckdb/parser/parsed_expression_iterator.hpp"
15: #include "duckdb/common/string.hpp"
16: #include "duckdb/common/queue.hpp"
17: #include "duckdb/parser/expression/list.hpp"
18: #include "duckdb/common/index_map.hpp"
19: #include "duckdb/planner/expression_iterator.hpp"
20: #include "duckdb/planner/expression_binder/index_binder.hpp"
21: #include "duckdb/parser/parsed_data/create_index_info.hpp"
22: #include "duckdb/catalog/catalog_entry/schema_catalog_entry.hpp"
23: 
24: #include <algorithm>
25: 
26: namespace duckdb {
27: 
28: static void CreateColumnDependencyManager(BoundCreateTableInfo &info) {
29: 	auto &base = info.base->Cast<CreateTableInfo>();
30: 	for (auto &col : base.columns.Logical()) {
31: 		if (!col.Generated()) {
32: 			continue;
33: 		}
34: 		info.column_dependency_manager.AddGeneratedColumn(col, base.columns);
35: 	}
36: }
37: 
38: static void BindCheckConstraint(Binder &binder, BoundCreateTableInfo &info, const unique_ptr<Constraint> &cond) {
39: 	auto &base = info.base->Cast<CreateTableInfo>();
40: 
41: 	auto bound_constraint = make_uniq<BoundCheckConstraint>();
42: 	// check constraint: bind the expression
43: 	CheckBinder check_binder(binder, binder.context, base.table, base.columns, bound_constraint->bound_columns);
44: 	auto &check = cond->Cast<CheckConstraint>();
45: 	// create a copy of the unbound expression because the binding destroys the constraint
46: 	auto unbound_expression = check.expression->Copy();
47: 	// now bind the constraint and create a new BoundCheckConstraint
48: 	bound_constraint->expression = check_binder.Bind(check.expression);
49: 	info.bound_constraints.push_back(std::move(bound_constraint));
50: 	// move the unbound constraint back into the original check expression
51: 	check.expression = std::move(unbound_expression);
52: }
53: 
54: static void BindConstraints(Binder &binder, BoundCreateTableInfo &info) {
55: 	auto &base = info.base->Cast<CreateTableInfo>();
56: 
57: 	bool has_primary_key = false;
58: 	logical_index_set_t not_null_columns;
59: 	vector<LogicalIndex> primary_keys;
60: 	for (idx_t i = 0; i < base.constraints.size(); i++) {
61: 		auto &cond = base.constraints[i];
62: 		switch (cond->type) {
63: 		case ConstraintType::CHECK: {
64: 			BindCheckConstraint(binder, info, cond);
65: 			break;
66: 		}
67: 		case ConstraintType::NOT_NULL: {
68: 			auto &not_null = cond->Cast<NotNullConstraint>();
69: 			auto &col = base.columns.GetColumn(LogicalIndex(not_null.index));
70: 			info.bound_constraints.push_back(make_uniq<BoundNotNullConstraint>(PhysicalIndex(col.StorageOid())));
71: 			not_null_columns.insert(not_null.index);
72: 			break;
73: 		}
74: 		case ConstraintType::UNIQUE: {
75: 			auto &unique = cond->Cast<UniqueConstraint>();
76: 			// have to resolve columns of the unique constraint
77: 			vector<LogicalIndex> keys;
78: 			logical_index_set_t key_set;
79: 			if (unique.index.index != DConstants::INVALID_INDEX) {
80: 				D_ASSERT(unique.index.index < base.columns.LogicalColumnCount());
81: 				// unique constraint is given by single index
82: 				unique.columns.push_back(base.columns.GetColumn(unique.index).Name());
83: 				keys.push_back(unique.index);
84: 				key_set.insert(unique.index);
85: 			} else {
86: 				// unique constraint is given by list of names
87: 				// have to resolve names
88: 				D_ASSERT(!unique.columns.empty());
89: 				for (auto &keyname : unique.columns) {
90: 					if (!base.columns.ColumnExists(keyname)) {
91: 						throw ParserException("column \"%s\" named in key does not exist", keyname);
92: 					}
93: 					auto &column = base.columns.GetColumn(keyname);
94: 					auto column_index = column.Logical();
95: 					if (key_set.find(column_index) != key_set.end()) {
96: 						throw ParserException("column \"%s\" appears twice in "
97: 						                      "primary key constraint",
98: 						                      keyname);
99: 					}
100: 					keys.push_back(column_index);
101: 					key_set.insert(column_index);
102: 				}
103: 			}
104: 
105: 			if (unique.is_primary_key) {
106: 				// we can only have one primary key per table
107: 				if (has_primary_key) {
108: 					throw ParserException("table \"%s\" has more than one primary key", base.table);
109: 				}
110: 				has_primary_key = true;
111: 				primary_keys = keys;
112: 			}
113: 			info.bound_constraints.push_back(
114: 			    make_uniq<BoundUniqueConstraint>(std::move(keys), std::move(key_set), unique.is_primary_key));
115: 			break;
116: 		}
117: 		case ConstraintType::FOREIGN_KEY: {
118: 			auto &fk = cond->Cast<ForeignKeyConstraint>();
119: 			D_ASSERT((fk.info.type == ForeignKeyType::FK_TYPE_FOREIGN_KEY_TABLE && !fk.info.pk_keys.empty()) ||
120: 			         (fk.info.type == ForeignKeyType::FK_TYPE_PRIMARY_KEY_TABLE && !fk.info.pk_keys.empty()) ||
121: 			         fk.info.type == ForeignKeyType::FK_TYPE_SELF_REFERENCE_TABLE);
122: 			physical_index_set_t fk_key_set, pk_key_set;
123: 			for (idx_t i = 0; i < fk.info.pk_keys.size(); i++) {
124: 				if (pk_key_set.find(fk.info.pk_keys[i]) != pk_key_set.end()) {
125: 					throw BinderException("Duplicate primary key referenced in FOREIGN KEY constraint");
126: 				}
127: 				pk_key_set.insert(fk.info.pk_keys[i]);
128: 			}
129: 			for (idx_t i = 0; i < fk.info.fk_keys.size(); i++) {
130: 				if (fk_key_set.find(fk.info.fk_keys[i]) != fk_key_set.end()) {
131: 					throw BinderException("Duplicate key specified in FOREIGN KEY constraint");
132: 				}
133: 				fk_key_set.insert(fk.info.fk_keys[i]);
134: 			}
135: 			info.bound_constraints.push_back(
136: 			    make_uniq<BoundForeignKeyConstraint>(fk.info, std::move(pk_key_set), std::move(fk_key_set)));
137: 			break;
138: 		}
139: 		default:
140: 			throw NotImplementedException("unrecognized constraint type in bind");
141: 		}
142: 	}
143: 	if (has_primary_key) {
144: 		// if there is a primary key index, also create a NOT NULL constraint for each of the columns
145: 		for (auto &column_index : primary_keys) {
146: 			if (not_null_columns.count(column_index)) {
147: 				//! No need to create a NotNullConstraint, it's already present
148: 				continue;
149: 			}
150: 			auto physical_index = base.columns.LogicalToPhysical(column_index);
151: 			base.constraints.push_back(make_uniq<NotNullConstraint>(column_index));
152: 			info.bound_constraints.push_back(make_uniq<BoundNotNullConstraint>(physical_index));
153: 		}
154: 	}
155: }
156: 
157: void Binder::BindGeneratedColumns(BoundCreateTableInfo &info) {
158: 	auto &base = info.base->Cast<CreateTableInfo>();
159: 
160: 	vector<string> names;
161: 	vector<LogicalType> types;
162: 
163: 	D_ASSERT(base.type == CatalogType::TABLE_ENTRY);
164: 	for (auto &col : base.columns.Logical()) {
165: 		names.push_back(col.Name());
166: 		types.push_back(col.Type());
167: 	}
168: 	auto table_index = GenerateTableIndex();
169: 
170: 	// Create a new binder because we dont need (or want) these bindings in this scope
171: 	auto binder = Binder::CreateBinder(context);
172: 	binder->bind_context.AddGenericBinding(table_index, base.table, names, types);
173: 	auto expr_binder = ExpressionBinder(*binder, context);
174: 	string ignore;
175: 	auto table_binding = binder->bind_context.GetBinding(base.table, ignore);
176: 	D_ASSERT(table_binding && ignore.empty());
177: 
178: 	auto bind_order = info.column_dependency_manager.GetBindOrder(base.columns);
179: 	logical_index_set_t bound_indices;
180: 
181: 	while (!bind_order.empty()) {
182: 		auto i = bind_order.top();
183: 		bind_order.pop();
184: 		auto &col = base.columns.GetColumnMutable(i);
185: 
186: 		//! Already bound this previously
187: 		//! This can not be optimized out of the GetBindOrder function
188: 		//! These occurrences happen because we need to make sure that ALL dependencies of a column are resolved before
189: 		//! it gets resolved
190: 		if (bound_indices.count(i)) {
191: 			continue;
192: 		}
193: 		D_ASSERT(col.Generated());
194: 		auto expression = col.GeneratedExpression().Copy();
195: 
196: 		auto bound_expression = expr_binder.Bind(expression);
197: 		D_ASSERT(bound_expression);
198: 		D_ASSERT(!bound_expression->HasSubquery());
199: 		if (col.Type().id() == LogicalTypeId::ANY) {
200: 			// Do this before changing the type, so we know it's the first time the type is set
201: 			col.ChangeGeneratedExpressionType(bound_expression->return_type);
202: 			col.SetType(bound_expression->return_type);
203: 
204: 			// Update the type in the binding, for future expansions
205: 			string ignore;
206: 			table_binding->types[i.index] = col.Type();
207: 		}
208: 		bound_indices.insert(i);
209: 	}
210: }
211: 
212: void Binder::BindDefaultValues(const ColumnList &columns, vector<unique_ptr<Expression>> &bound_defaults) {
213: 	for (auto &column : columns.Physical()) {
214: 		unique_ptr<Expression> bound_default;
215: 		if (column.DefaultValue()) {
216: 			// we bind a copy of the DEFAULT value because binding is destructive
217: 			// and we want to keep the original expression around for serialization
218: 			auto default_copy = column.DefaultValue()->Copy();
219: 			ConstantBinder default_binder(*this, context, "DEFAULT value");
220: 			default_binder.target_type = column.Type();
221: 			bound_default = default_binder.Bind(default_copy);
222: 		} else {
223: 			// no default value specified: push a default value of constant null
224: 			bound_default = make_uniq<BoundConstantExpression>(Value(column.Type()));
225: 		}
226: 		bound_defaults.push_back(std::move(bound_default));
227: 	}
228: }
229: 
230: static void ExtractExpressionDependencies(Expression &expr, DependencyList &dependencies) {
231: 	if (expr.type == ExpressionType::BOUND_FUNCTION) {
232: 		auto &function = expr.Cast<BoundFunctionExpression>();
233: 		if (function.function.dependency) {
234: 			function.function.dependency(function, dependencies);
235: 		}
236: 	}
237: 	ExpressionIterator::EnumerateChildren(
238: 	    expr, [&](Expression &child) { ExtractExpressionDependencies(child, dependencies); });
239: }
240: 
241: static void ExtractDependencies(BoundCreateTableInfo &info) {
242: 	for (auto &default_value : info.bound_defaults) {
243: 		if (default_value) {
244: 			ExtractExpressionDependencies(*default_value, info.dependencies);
245: 		}
246: 	}
247: 	for (auto &constraint : info.bound_constraints) {
248: 		if (constraint->type == ConstraintType::CHECK) {
249: 			auto &bound_check = constraint->Cast<BoundCheckConstraint>();
250: 			ExtractExpressionDependencies(*bound_check.expression, info.dependencies);
251: 		}
252: 	}
253: }
254: unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateInfo> info, SchemaCatalogEntry &schema) {
255: 	auto &base = info->Cast<CreateTableInfo>();
256: 	auto result = make_uniq<BoundCreateTableInfo>(schema, std::move(info));
257: 	if (base.query) {
258: 		// construct the result object
259: 		auto query_obj = Bind(*base.query);
260: 		base.query.reset();
261: 		result->query = std::move(query_obj.plan);
262: 
263: 		// construct the set of columns based on the names and types of the query
264: 		auto &names = query_obj.names;
265: 		auto &sql_types = query_obj.types;
266: 		D_ASSERT(names.size() == sql_types.size());
267: 		base.columns.SetAllowDuplicates(true);
268: 		for (idx_t i = 0; i < names.size(); i++) {
269: 			base.columns.AddColumn(ColumnDefinition(names[i], sql_types[i]));
270: 		}
271: 		CreateColumnDependencyManager(*result);
272: 		// bind the generated column expressions
273: 		BindGeneratedColumns(*result);
274: 	} else {
275: 		CreateColumnDependencyManager(*result);
276: 		// bind the generated column expressions
277: 		BindGeneratedColumns(*result);
278: 		// bind any constraints
279: 		BindConstraints(*this, *result);
280: 		// bind the default values
281: 		BindDefaultValues(base.columns, result->bound_defaults);
282: 	}
283: 	// extract dependencies from any default values or CHECK constraints
284: 	ExtractDependencies(*result);
285: 
286: 	if (base.columns.PhysicalColumnCount() == 0) {
287: 		throw BinderException("Creating a table without physical (non-generated) columns is not supported");
288: 	}
289: 	// bind collations to detect any unsupported collation errors
290: 	for (idx_t i = 0; i < base.columns.PhysicalColumnCount(); i++) {
291: 		auto &column = base.columns.GetColumnMutable(PhysicalIndex(i));
292: 		if (column.Type().id() == LogicalTypeId::VARCHAR) {
293: 			ExpressionBinder::TestCollation(context, StringType::GetCollation(column.Type()));
294: 		}
295: 		BindLogicalType(context, column.TypeMutable(), &result->schema.catalog);
296: 	}
297: 	result->dependencies.VerifyDependencies(schema.catalog, result->Base().table);
298: 	properties.allow_stream_result = false;
299: 	return result;
300: }
301: 
302: unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateInfo> info) {
303: 	auto &base = info->Cast<CreateTableInfo>();
304: 	auto &schema = BindCreateSchema(base);
305: 	return BindCreateTableInfo(std::move(info), schema);
306: }
307: 
308: vector<unique_ptr<Expression>> Binder::BindCreateIndexExpressions(TableCatalogEntry &table, CreateIndexInfo &info) {
309: 	auto index_binder = IndexBinder(*this, this->context, &table, &info);
310: 	vector<unique_ptr<Expression>> expressions;
311: 	expressions.reserve(info.expressions.size());
312: 	for (auto &expr : info.expressions) {
313: 		expressions.push_back(index_binder.Bind(expr));
314: 	}
315: 
316: 	return expressions;
317: }
318: 
319: } // namespace duckdb
[end of src/planner/binder/statement/bind_create_table.cpp]
[start of src/planner/binder/statement/bind_insert.cpp]
1: #include "duckdb/catalog/catalog.hpp"
2: #include "duckdb/parser/expression/constant_expression.hpp"
3: #include "duckdb/parser/statement/insert_statement.hpp"
4: #include "duckdb/parser/query_node/select_node.hpp"
5: #include "duckdb/parser/tableref/expressionlistref.hpp"
6: #include "duckdb/planner/binder.hpp"
7: #include "duckdb/planner/expression_binder/insert_binder.hpp"
8: #include "duckdb/planner/operator/logical_insert.hpp"
9: #include "duckdb/planner/operator/logical_get.hpp"
10: #include "duckdb/common/string_util.hpp"
11: #include "duckdb/function/table/table_scan.hpp"
12: #include "duckdb/planner/operator/logical_dummy_scan.hpp"
13: #include "duckdb/planner/operator/logical_projection.hpp"
14: #include "duckdb/planner/expression_iterator.hpp"
15: #include "duckdb/planner/expression_binder/returning_binder.hpp"
16: #include "duckdb/planner/expression_binder/where_binder.hpp"
17: #include "duckdb/planner/expression_binder/update_binder.hpp"
18: #include "duckdb/planner/operator/logical_filter.hpp"
19: #include "duckdb/parser/statement/update_statement.hpp"
20: #include "duckdb/planner/expression/bound_default_expression.hpp"
21: #include "duckdb/storage/data_table.hpp"
22: #include "duckdb/catalog/catalog_entry/index_catalog_entry.hpp"
23: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
24: #include "duckdb/planner/bound_tableref.hpp"
25: #include "duckdb/planner/tableref/bound_basetableref.hpp"
26: #include "duckdb/planner/tableref/bound_dummytableref.hpp"
27: #include "duckdb/parser/parsed_expression_iterator.hpp"
28: #include "duckdb/storage/table_storage_info.hpp"
29: #include "duckdb/parser/tableref/basetableref.hpp"
30: 
31: namespace duckdb {
32: 
33: static void CheckInsertColumnCountMismatch(int64_t expected_columns, int64_t result_columns, bool columns_provided,
34:                                            const char *tname) {
35: 	if (result_columns != expected_columns) {
36: 		string msg = StringUtil::Format(!columns_provided ? "table %s has %lld columns but %lld values were supplied"
37: 		                                                  : "Column name/value mismatch for insert on %s: "
38: 		                                                    "expected %lld columns but %lld values were supplied",
39: 		                                tname, expected_columns, result_columns);
40: 		throw BinderException(msg);
41: 	}
42: }
43: 
44: unique_ptr<ParsedExpression> ExpandDefaultExpression(const ColumnDefinition &column) {
45: 	if (column.DefaultValue()) {
46: 		return column.DefaultValue()->Copy();
47: 	} else {
48: 		return make_uniq<ConstantExpression>(Value(column.Type()));
49: 	}
50: }
51: 
52: void ReplaceDefaultExpression(unique_ptr<ParsedExpression> &expr, const ColumnDefinition &column) {
53: 	D_ASSERT(expr->type == ExpressionType::VALUE_DEFAULT);
54: 	expr = ExpandDefaultExpression(column);
55: }
56: 
57: void QualifyColumnReferences(unique_ptr<ParsedExpression> &expr, const string &table_name) {
58: 	// To avoid ambiguity with 'excluded', we explicitly qualify all column references
59: 	if (expr->type == ExpressionType::COLUMN_REF) {
60: 		auto &column_ref = expr->Cast<ColumnRefExpression>();
61: 		if (column_ref.IsQualified()) {
62: 			return;
63: 		}
64: 		auto column_name = column_ref.GetColumnName();
65: 		expr = make_uniq<ColumnRefExpression>(column_name, table_name);
66: 	}
67: 	ParsedExpressionIterator::EnumerateChildren(
68: 	    *expr, [&](unique_ptr<ParsedExpression> &child) { QualifyColumnReferences(child, table_name); });
69: }
70: 
71: // Replace binding.table_index with 'dest' if it's 'source'
72: void ReplaceColumnBindings(Expression &expr, idx_t source, idx_t dest) {
73: 	if (expr.type == ExpressionType::BOUND_COLUMN_REF) {
74: 		auto &bound_columnref = expr.Cast<BoundColumnRefExpression>();
75: 		if (bound_columnref.binding.table_index == source) {
76: 			bound_columnref.binding.table_index = dest;
77: 		}
78: 	}
79: 	ExpressionIterator::EnumerateChildren(
80: 	    expr, [&](unique_ptr<Expression> &child) { ReplaceColumnBindings(*child, source, dest); });
81: }
82: 
83: void Binder::BindDoUpdateSetExpressions(const string &table_alias, LogicalInsert &insert, UpdateSetInfo &set_info,
84:                                         TableCatalogEntry &table, TableStorageInfo &storage_info) {
85: 	D_ASSERT(insert.children.size() == 1);
86: 	D_ASSERT(insert.children[0]->type == LogicalOperatorType::LOGICAL_PROJECTION);
87: 
88: 	vector<column_t> logical_column_ids;
89: 	vector<string> column_names;
90: 	D_ASSERT(set_info.columns.size() == set_info.expressions.size());
91: 
92: 	for (idx_t i = 0; i < set_info.columns.size(); i++) {
93: 		auto &colname = set_info.columns[i];
94: 		auto &expr = set_info.expressions[i];
95: 		if (!table.ColumnExists(colname)) {
96: 			throw BinderException("Referenced update column %s not found in table!", colname);
97: 		}
98: 		auto &column = table.GetColumn(colname);
99: 		if (column.Generated()) {
100: 			throw BinderException("Cant update column \"%s\" because it is a generated column!", column.Name());
101: 		}
102: 		if (std::find(insert.set_columns.begin(), insert.set_columns.end(), column.Physical()) !=
103: 		    insert.set_columns.end()) {
104: 			throw BinderException("Multiple assignments to same column \"%s\"", colname);
105: 		}
106: 		insert.set_columns.push_back(column.Physical());
107: 		logical_column_ids.push_back(column.Oid());
108: 		insert.set_types.push_back(column.Type());
109: 		column_names.push_back(colname);
110: 		if (expr->type == ExpressionType::VALUE_DEFAULT) {
111: 			expr = ExpandDefaultExpression(column);
112: 		}
113: 		UpdateBinder binder(*this, context);
114: 		binder.target_type = column.Type();
115: 
116: 		// Avoid ambiguity issues
117: 		QualifyColumnReferences(expr, table_alias);
118: 
119: 		auto bound_expr = binder.Bind(expr);
120: 		D_ASSERT(bound_expr);
121: 		if (bound_expr->expression_class == ExpressionClass::BOUND_SUBQUERY) {
122: 			throw BinderException("Expression in the DO UPDATE SET clause can not be a subquery");
123: 		}
124: 
125: 		insert.expressions.push_back(std::move(bound_expr));
126: 	}
127: 
128: 	// Figure out which columns are indexed on
129: 	unordered_set<column_t> indexed_columns;
130: 	for (auto &index : storage_info.index_info) {
131: 		for (auto &column_id : index.column_set) {
132: 			indexed_columns.insert(column_id);
133: 		}
134: 	}
135: 
136: 	// Verify that none of the columns that are targeted with a SET expression are indexed on
137: 	for (idx_t i = 0; i < logical_column_ids.size(); i++) {
138: 		auto &column = logical_column_ids[i];
139: 		if (indexed_columns.count(column)) {
140: 			throw BinderException("Can not assign to column '%s' because it has a UNIQUE/PRIMARY KEY constraint",
141: 			                      column_names[i]);
142: 		}
143: 	}
144: }
145: 
146: unique_ptr<UpdateSetInfo> CreateSetInfoForReplace(TableCatalogEntry &table, InsertStatement &insert,
147:                                                   TableStorageInfo &storage_info) {
148: 	auto set_info = make_uniq<UpdateSetInfo>();
149: 
150: 	auto &columns = set_info->columns;
151: 	// Figure out which columns are indexed on
152: 
153: 	unordered_set<column_t> indexed_columns;
154: 	for (auto &index : storage_info.index_info) {
155: 		for (auto &column_id : index.column_set) {
156: 			indexed_columns.insert(column_id);
157: 		}
158: 	}
159: 
160: 	auto &column_list = table.GetColumns();
161: 	if (insert.columns.empty()) {
162: 		for (auto &column : column_list.Physical()) {
163: 			auto &name = column.Name();
164: 			// FIXME: can these column names be aliased somehow?
165: 			if (indexed_columns.count(column.Oid())) {
166: 				continue;
167: 			}
168: 			columns.push_back(name);
169: 		}
170: 	} else {
171: 		// a list of columns was explicitly supplied, only update those
172: 		for (auto &name : insert.columns) {
173: 			auto &column = column_list.GetColumn(name);
174: 			if (indexed_columns.count(column.Oid())) {
175: 				continue;
176: 			}
177: 			columns.push_back(name);
178: 		}
179: 	}
180: 
181: 	// Create 'excluded' qualified column references of these columns
182: 	for (auto &column : columns) {
183: 		set_info->expressions.push_back(make_uniq<ColumnRefExpression>(column, "excluded"));
184: 	}
185: 
186: 	return set_info;
187: }
188: 
189: void Binder::BindOnConflictClause(LogicalInsert &insert, TableCatalogEntry &table, InsertStatement &stmt) {
190: 	if (!stmt.on_conflict_info) {
191: 		insert.action_type = OnConflictAction::THROW;
192: 		return;
193: 	}
194: 	D_ASSERT(stmt.table_ref->type == TableReferenceType::BASE_TABLE);
195: 
196: 	// visit the table reference
197: 	auto bound_table = Bind(*stmt.table_ref);
198: 	if (bound_table->type != TableReferenceType::BASE_TABLE) {
199: 		throw BinderException("Can only update base table!");
200: 	}
201: 
202: 	auto &table_ref = stmt.table_ref->Cast<BaseTableRef>();
203: 	const string &table_alias = !table_ref.alias.empty() ? table_ref.alias : table_ref.table_name;
204: 
205: 	auto &on_conflict = *stmt.on_conflict_info;
206: 	D_ASSERT(on_conflict.action_type != OnConflictAction::THROW);
207: 	insert.action_type = on_conflict.action_type;
208: 
209: 	// obtain the table storage info
210: 	auto storage_info = table.GetStorageInfo(context);
211: 
212: 	auto &columns = table.GetColumns();
213: 	if (!on_conflict.indexed_columns.empty()) {
214: 		// Bind the ON CONFLICT (<columns>)
215: 
216: 		// create a mapping of (list index) -> (column index)
217: 		case_insensitive_map_t<idx_t> specified_columns;
218: 		for (idx_t i = 0; i < on_conflict.indexed_columns.size(); i++) {
219: 			specified_columns[on_conflict.indexed_columns[i]] = i;
220: 			auto column_index = table.GetColumnIndex(on_conflict.indexed_columns[i]);
221: 			if (column_index.index == COLUMN_IDENTIFIER_ROW_ID) {
222: 				throw BinderException("Cannot specify ROWID as ON CONFLICT target");
223: 			}
224: 			auto &col = columns.GetColumn(column_index);
225: 			if (col.Generated()) {
226: 				throw BinderException("Cannot specify a generated column as ON CONFLICT target");
227: 			}
228: 		}
229: 		for (auto &col : columns.Physical()) {
230: 			auto entry = specified_columns.find(col.Name());
231: 			if (entry != specified_columns.end()) {
232: 				// column was specified, set to the index
233: 				insert.on_conflict_filter.insert(col.Oid());
234: 			}
235: 		}
236: 		bool index_references_columns = false;
237: 		for (auto &index : storage_info.index_info) {
238: 			if (!index.is_unique) {
239: 				continue;
240: 			}
241: 			bool index_matches = insert.on_conflict_filter == index.column_set;
242: 			if (index_matches) {
243: 				index_references_columns = true;
244: 				break;
245: 			}
246: 		}
247: 		if (!index_references_columns) {
248: 			// Same as before, this is essentially a no-op, turning this into a DO THROW instead
249: 			// But since this makes no logical sense, it's probably better to throw an error
250: 			throw BinderException(
251: 			    "The specified columns as conflict target are not referenced by a UNIQUE/PRIMARY KEY CONSTRAINT");
252: 		}
253: 	} else {
254: 		// When omitting the conflict target, the ON CONFLICT applies to every UNIQUE/PRIMARY KEY on the table
255: 
256: 		// We check if there are any constraints on the table, if there aren't we throw an error.
257: 		idx_t found_matching_indexes = 0;
258: 		for (auto &index : storage_info.index_info) {
259: 			if (!index.is_unique) {
260: 				continue;
261: 			}
262: 			// does this work with multi-column indexes?
263: 			auto &indexed_columns = index.column_set;
264: 			for (auto &column : table.GetColumns().Physical()) {
265: 				if (indexed_columns.count(column.Physical().index)) {
266: 					found_matching_indexes++;
267: 				}
268: 			}
269: 		}
270: 		if (!found_matching_indexes) {
271: 			throw BinderException(
272: 			    "There are no UNIQUE/PRIMARY KEY Indexes that refer to this table, ON CONFLICT is a no-op");
273: 		} else if (storage_info.index_info.size() != 1) {
274: 			if (insert.action_type != OnConflictAction::NOTHING) {
275: 				// When no conflict target is provided, and the action type is UPDATE,
276: 				// we only allow the operation when only a single Index exists
277: 				throw BinderException("Conflict target has to be provided for a DO UPDATE operation when the table has "
278: 				                      "multiple UNIQUE/PRIMARY KEY constraints");
279: 			}
280: 		}
281: 	}
282: 
283: 	// add the 'excluded' dummy table binding
284: 	AddTableName("excluded");
285: 	// add a bind context entry for it
286: 	auto excluded_index = GenerateTableIndex();
287: 	insert.excluded_table_index = excluded_index;
288: 	auto table_column_names = columns.GetColumnNames();
289: 	auto table_column_types = columns.GetColumnTypes();
290: 	bind_context.AddGenericBinding(excluded_index, "excluded", table_column_names, table_column_types);
291: 
292: 	if (on_conflict.condition) {
293: 		// Avoid ambiguity between <table_name> binding and 'excluded'
294: 		QualifyColumnReferences(on_conflict.condition, table_alias);
295: 		// Bind the ON CONFLICT ... WHERE clause
296: 		WhereBinder where_binder(*this, context);
297: 		auto condition = where_binder.Bind(on_conflict.condition);
298: 		if (condition && condition->expression_class == ExpressionClass::BOUND_SUBQUERY) {
299: 			throw BinderException("conflict_target WHERE clause can not be a subquery");
300: 		}
301: 		insert.on_conflict_condition = std::move(condition);
302: 	}
303: 
304: 	auto bindings = insert.children[0]->GetColumnBindings();
305: 	idx_t projection_index = DConstants::INVALID_INDEX;
306: 	vector<unique_ptr<LogicalOperator>> *insert_child_operators;
307: 	insert_child_operators = &insert.children;
308: 	while (projection_index == DConstants::INVALID_INDEX) {
309: 		if (insert_child_operators->empty()) {
310: 			// No further children to visit
311: 			break;
312: 		}
313: 		D_ASSERT(insert_child_operators->size() >= 1);
314: 		auto &current_child = (*insert_child_operators)[0];
315: 		auto table_indices = current_child->GetTableIndex();
316: 		if (table_indices.empty()) {
317: 			// This operator does not have a table index to refer to, we have to visit its children
318: 			insert_child_operators = &current_child->children;
319: 			continue;
320: 		}
321: 		projection_index = table_indices[0];
322: 	}
323: 	if (projection_index == DConstants::INVALID_INDEX) {
324: 		throw InternalException("Could not locate a table_index from the children of the insert");
325: 	}
326: 
327: 	string unused;
328: 	auto original_binding = bind_context.GetBinding(table_alias, unused);
329: 	D_ASSERT(original_binding);
330: 
331: 	auto table_index = original_binding->index;
332: 
333: 	// Replace any column bindings to refer to the projection table_index, rather than the source table
334: 	if (insert.on_conflict_condition) {
335: 		ReplaceColumnBindings(*insert.on_conflict_condition, table_index, projection_index);
336: 	}
337: 
338: 	if (insert.action_type == OnConflictAction::REPLACE) {
339: 		D_ASSERT(on_conflict.set_info == nullptr);
340: 		on_conflict.set_info = CreateSetInfoForReplace(table, stmt, storage_info);
341: 		insert.action_type = OnConflictAction::UPDATE;
342: 	}
343: 	if (on_conflict.set_info && on_conflict.set_info->columns.empty()) {
344: 		// if we are doing INSERT OR REPLACE on a table with no columns outside of the primary key column
345: 		// convert to INSERT OR IGNORE
346: 		insert.action_type = OnConflictAction::NOTHING;
347: 	}
348: 	if (insert.action_type == OnConflictAction::NOTHING) {
349: 		if (!insert.on_conflict_condition) {
350: 			return;
351: 		}
352: 		// Get the column_ids we need to fetch later on from the conflicting tuples
353: 		// of the original table, to execute the expressions
354: 		D_ASSERT(original_binding->binding_type == BindingType::TABLE);
355: 		auto &table_binding = original_binding->Cast<TableBinding>();
356: 		insert.columns_to_fetch = table_binding.GetBoundColumnIds();
357: 		return;
358: 	}
359: 
360: 	D_ASSERT(on_conflict.set_info);
361: 	auto &set_info = *on_conflict.set_info;
362: 	D_ASSERT(set_info.columns.size() == set_info.expressions.size());
363: 
364: 	if (set_info.condition) {
365: 		// Avoid ambiguity between <table_name> binding and 'excluded'
366: 		QualifyColumnReferences(set_info.condition, table_alias);
367: 		// Bind the SET ... WHERE clause
368: 		WhereBinder where_binder(*this, context);
369: 		auto condition = where_binder.Bind(set_info.condition);
370: 		if (condition && condition->expression_class == ExpressionClass::BOUND_SUBQUERY) {
371: 			throw BinderException("conflict_target WHERE clause can not be a subquery");
372: 		}
373: 		insert.do_update_condition = std::move(condition);
374: 	}
375: 
376: 	BindDoUpdateSetExpressions(table_alias, insert, set_info, table, storage_info);
377: 
378: 	// Get the column_ids we need to fetch later on from the conflicting tuples
379: 	// of the original table, to execute the expressions
380: 	D_ASSERT(original_binding->binding_type == BindingType::TABLE);
381: 	auto &table_binding = original_binding->Cast<TableBinding>();
382: 	insert.columns_to_fetch = table_binding.GetBoundColumnIds();
383: 
384: 	// Replace the column bindings to refer to the child operator
385: 	for (auto &expr : insert.expressions) {
386: 		// Change the non-excluded column references to refer to the projection index
387: 		ReplaceColumnBindings(*expr, table_index, projection_index);
388: 	}
389: 	// Do the same for the (optional) DO UPDATE condition
390: 	if (insert.do_update_condition) {
391: 		ReplaceColumnBindings(*insert.do_update_condition, table_index, projection_index);
392: 	}
393: }
394: 
395: BoundStatement Binder::Bind(InsertStatement &stmt) {
396: 	BoundStatement result;
397: 	result.names = {"Count"};
398: 	result.types = {LogicalType::BIGINT};
399: 
400: 	BindSchemaOrCatalog(stmt.catalog, stmt.schema);
401: 	auto &table = Catalog::GetEntry<TableCatalogEntry>(context, stmt.catalog, stmt.schema, stmt.table);
402: 	if (!table.temporary) {
403: 		// inserting into a non-temporary table: alters underlying database
404: 		properties.modified_databases.insert(table.catalog.GetName());
405: 	}
406: 
407: 	auto insert = make_uniq<LogicalInsert>(table, GenerateTableIndex());
408: 	// Add CTEs as bindable
409: 	AddCTEMap(stmt.cte_map);
410: 
411: 	auto values_list = stmt.GetValuesList();
412: 
413: 	// bind the root select node (if any)
414: 	BoundStatement root_select;
415: 	if (stmt.column_order == InsertColumnOrder::INSERT_BY_NAME) {
416: 		if (values_list) {
417: 			throw BinderException("INSERT BY NAME can only be used when inserting from a SELECT statement");
418: 		}
419: 		if (!stmt.columns.empty()) {
420: 			throw BinderException("INSERT BY NAME cannot be combined with an explicit column list");
421: 		}
422: 		D_ASSERT(stmt.select_statement);
423: 		// INSERT BY NAME - generate the columns from the names of the SELECT statement
424: 		auto select_binder = Binder::CreateBinder(context, this);
425: 		root_select = select_binder->Bind(*stmt.select_statement);
426: 		MoveCorrelatedExpressions(*select_binder);
427: 
428: 		stmt.columns = root_select.names;
429: 	}
430: 
431: 	vector<LogicalIndex> named_column_map;
432: 	if (!stmt.columns.empty() || stmt.default_values) {
433: 		// insertion statement specifies column list
434: 
435: 		// create a mapping of (list index) -> (column index)
436: 		case_insensitive_map_t<idx_t> column_name_map;
437: 		for (idx_t i = 0; i < stmt.columns.size(); i++) {
438: 			auto entry = column_name_map.insert(make_pair(stmt.columns[i], i));
439: 			if (!entry.second) {
440: 				throw BinderException("Duplicate column name \"%s\" in INSERT", stmt.columns[i]);
441: 			}
442: 			column_name_map[stmt.columns[i]] = i;
443: 			auto column_index = table.GetColumnIndex(stmt.columns[i]);
444: 			if (column_index.index == COLUMN_IDENTIFIER_ROW_ID) {
445: 				throw BinderException("Cannot explicitly insert values into rowid column");
446: 			}
447: 			auto &col = table.GetColumn(column_index);
448: 			if (col.Generated()) {
449: 				throw BinderException("Cannot insert into a generated column");
450: 			}
451: 			insert->expected_types.push_back(col.Type());
452: 			named_column_map.push_back(column_index);
453: 		}
454: 		for (auto &col : table.GetColumns().Physical()) {
455: 			auto entry = column_name_map.find(col.Name());
456: 			if (entry == column_name_map.end()) {
457: 				// column not specified, set index to DConstants::INVALID_INDEX
458: 				insert->column_index_map.push_back(DConstants::INVALID_INDEX);
459: 			} else {
460: 				// column was specified, set to the index
461: 				insert->column_index_map.push_back(entry->second);
462: 			}
463: 		}
464: 	} else {
465: 		// insert by position and no columns specified - insertion into all columns of the table
466: 		// intentionally don't populate 'column_index_map' as an indication of this
467: 		for (auto &col : table.GetColumns().Physical()) {
468: 			named_column_map.push_back(col.Logical());
469: 			insert->expected_types.push_back(col.Type());
470: 		}
471: 	}
472: 
473: 	// bind the default values
474: 	BindDefaultValues(table.GetColumns(), insert->bound_defaults);
475: 	if (!stmt.select_statement && !stmt.default_values) {
476: 		result.plan = std::move(insert);
477: 		return result;
478: 	}
479: 	// Exclude the generated columns from this amount
480: 	idx_t expected_columns = stmt.columns.empty() ? table.GetColumns().PhysicalColumnCount() : stmt.columns.size();
481: 
482: 	// special case: check if we are inserting from a VALUES statement
483: 	if (values_list) {
484: 		auto &expr_list = values_list->Cast<ExpressionListRef>();
485: 		expr_list.expected_types.resize(expected_columns);
486: 		expr_list.expected_names.resize(expected_columns);
487: 
488: 		D_ASSERT(expr_list.values.size() > 0);
489: 		CheckInsertColumnCountMismatch(expected_columns, expr_list.values[0].size(), !stmt.columns.empty(),
490: 		                               table.name.c_str());
491: 
492: 		// VALUES list!
493: 		for (idx_t col_idx = 0; col_idx < expected_columns; col_idx++) {
494: 			D_ASSERT(named_column_map.size() >= col_idx);
495: 			auto &table_col_idx = named_column_map[col_idx];
496: 
497: 			// set the expected types as the types for the INSERT statement
498: 			auto &column = table.GetColumn(table_col_idx);
499: 			expr_list.expected_types[col_idx] = column.Type();
500: 			expr_list.expected_names[col_idx] = column.Name();
501: 
502: 			// now replace any DEFAULT values with the corresponding default expression
503: 			for (idx_t list_idx = 0; list_idx < expr_list.values.size(); list_idx++) {
504: 				if (expr_list.values[list_idx][col_idx]->type == ExpressionType::VALUE_DEFAULT) {
505: 					// DEFAULT value! replace the entry
506: 					ReplaceDefaultExpression(expr_list.values[list_idx][col_idx], column);
507: 				}
508: 			}
509: 		}
510: 	}
511: 
512: 	// parse select statement and add to logical plan
513: 	unique_ptr<LogicalOperator> root;
514: 	if (stmt.select_statement) {
515: 		if (stmt.column_order == InsertColumnOrder::INSERT_BY_POSITION) {
516: 			auto select_binder = Binder::CreateBinder(context, this);
517: 			root_select = select_binder->Bind(*stmt.select_statement);
518: 			MoveCorrelatedExpressions(*select_binder);
519: 		}
520: 		// inserting from a select - check if the column count matches
521: 		CheckInsertColumnCountMismatch(expected_columns, root_select.types.size(), !stmt.columns.empty(),
522: 		                               table.name.c_str());
523: 
524: 		root = CastLogicalOperatorToTypes(root_select.types, insert->expected_types, std::move(root_select.plan));
525: 	} else {
526: 		root = make_uniq<LogicalDummyScan>(GenerateTableIndex());
527: 	}
528: 	insert->AddChild(std::move(root));
529: 
530: 	BindOnConflictClause(*insert, table, stmt);
531: 
532: 	if (!stmt.returning_list.empty()) {
533: 		insert->return_chunk = true;
534: 		result.types.clear();
535: 		result.names.clear();
536: 		auto insert_table_index = GenerateTableIndex();
537: 		insert->table_index = insert_table_index;
538: 		unique_ptr<LogicalOperator> index_as_logicaloperator = std::move(insert);
539: 
540: 		return BindReturning(std::move(stmt.returning_list), table, stmt.table_ref ? stmt.table_ref->alias : string(),
541: 		                     insert_table_index, std::move(index_as_logicaloperator), std::move(result));
542: 	}
543: 
544: 	D_ASSERT(result.types.size() == result.names.size());
545: 	result.plan = std::move(insert);
546: 	properties.allow_stream_result = false;
547: 	properties.return_type = StatementReturnType::CHANGED_ROWS;
548: 	return result;
549: }
550: 
551: } // namespace duckdb
[end of src/planner/binder/statement/bind_insert.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: