You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
Multiple unnests in lateral join error - failed to bind column reference
### What happens?

Using multiple `UNNEST` clauses in a lateral join will cause a "failed to bind column reference" error.


### To Reproduce


```sql
D CREATE TABLE with_array(foo INT, arr DOUBLE[]);
D INSERT INTO with_array VALUES(1, [1,2,3]), (2, [4,5,6]);
D SELECT * FROM with_array, (SELECT UNNEST(with_array.arr), UNNEST(generate_series(1, len(with_array.arr), 1)));
-- Failed to bind column reference "UNNEST(generate_series(CAST(1 AS BIGINT), len(arr), CAST(1 AS BIGINT)))" [8.1] (bindings: [0.0 0.1 8.0])
```

Disabling the optimizer makes this work as intended - it is likely related to the unnest rewriter optimizer.

```sql
pragma disable_optimizer;
D CREATE TABLE with_array(foo INT, arr DOUBLE[]);
D INSERT INTO with_array VALUES(1, [1,2,3]), (2, [4,5,6]);
D SELECT * FROM with_array, (SELECT UNNEST(with_array.arr), UNNEST(generate_series(1, len(with_array.arr), 1)));
┌───────┬─────────────────┬────────────────────────┬────────────────────────────────────────────────────┐
│  foo  │       arr       │ unnest(with_array.arr) │ unnest(generate_series(1, len(with_array.arr), 1)) │
│ int32 │    double[]     │         double         │                       int64                        │
├───────┼─────────────────┼────────────────────────┼────────────────────────────────────────────────────┤
│     1 │ [1.0, 2.0, 3.0] │                    3.0 │                                                  3 │
│     2 │ [4.0, 5.0, 6.0] │                    6.0 │                                                  3 │
│     1 │ [1.0, 2.0, 3.0] │                    2.0 │                                                  2 │
│     2 │ [4.0, 5.0, 6.0] │                    5.0 │                                                  2 │
│     1 │ [1.0, 2.0, 3.0] │                    1.0 │                                                  1 │
│     2 │ [4.0, 5.0, 6.0] │                    4.0 │                                                  1 │
└───────┴─────────────────┴────────────────────────┴────────────────────────────────────────────────────┘
```


### OS:

MacOS

### DuckDB Version:

Latest

### DuckDB Client:

CLI

### Full Name:

Mark Raasveldt

### Affiliation:

DuckDB Labs

### Have you tried this on the latest `master` branch?

- [X] I agree

### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?

- [X] I agree

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=master" alt="Github Actions Badge">
9:   </a>
10:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
11:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
12:   </a>
13:   <a href="https://discord.gg/tcvwpjfnZx">
14:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
15:   </a>
16:   <a href="https://github.com/duckdb/duckdb/releases/">
17:     <img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release">
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The detail of benchmarks is in our [Benchmark Guide](benchmark/README.md).
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
[end of README.md]
[start of src/optimizer/unnest_rewriter.cpp]
1: #include "duckdb/optimizer/unnest_rewriter.hpp"
2: 
3: #include "duckdb/common/pair.hpp"
4: #include "duckdb/planner/operator/logical_delim_get.hpp"
5: #include "duckdb/planner/operator/logical_delim_join.hpp"
6: #include "duckdb/planner/operator/logical_unnest.hpp"
7: #include "duckdb/planner/operator/logical_projection.hpp"
8: #include "duckdb/planner/operator/logical_window.hpp"
9: #include "duckdb/planner/expression/bound_unnest_expression.hpp"
10: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
11: 
12: namespace duckdb {
13: 
14: void UnnestRewriterPlanUpdater::VisitOperator(LogicalOperator &op) {
15: 	VisitOperatorChildren(op);
16: 	VisitOperatorExpressions(op);
17: }
18: 
19: void UnnestRewriterPlanUpdater::VisitExpression(unique_ptr<Expression> *expression) {
20: 
21: 	auto &expr = *expression;
22: 
23: 	if (expr->expression_class == ExpressionClass::BOUND_COLUMN_REF) {
24: 
25: 		auto &bound_column_ref = expr->Cast<BoundColumnRefExpression>();
26: 		for (idx_t i = 0; i < replace_bindings.size(); i++) {
27: 			if (bound_column_ref.binding == replace_bindings[i].old_binding) {
28: 				bound_column_ref.binding = replace_bindings[i].new_binding;
29: 			}
30: 			// previously pointing to the LOGICAL_DELIM_GET
31: 			if (bound_column_ref.binding.table_index == replace_bindings[i].old_binding.table_index &&
32: 			    replace_bindings[i].old_binding.column_index == DConstants::INVALID_INDEX) {
33: 				bound_column_ref.binding = replace_bindings[i].new_binding;
34: 			}
35: 		}
36: 	}
37: 
38: 	VisitExpressionChildren(**expression);
39: }
40: 
41: unique_ptr<LogicalOperator> UnnestRewriter::Optimize(unique_ptr<LogicalOperator> op) {
42: 
43: 	UnnestRewriterPlanUpdater updater;
44: 	vector<unique_ptr<LogicalOperator> *> candidates;
45: 	FindCandidates(&op, candidates);
46: 
47: 	// rewrite the plan and update the bindings
48: 	for (auto &candidate : candidates) {
49: 
50: 		// rearrange the logical operators
51: 		if (RewriteCandidate(candidate)) {
52: 			// update the bindings of the BOUND_UNNEST expression
53: 			UpdateBoundUnnestBindings(updater, candidate);
54: 			// update the sequence of LOGICAL_PROJECTION(s)
55: 			UpdateRHSBindings(&op, candidate, updater);
56: 			// reset
57: 			delim_columns.clear();
58: 			lhs_bindings.clear();
59: 		}
60: 	}
61: 
62: 	return op;
63: }
64: 
65: void UnnestRewriter::FindCandidates(unique_ptr<LogicalOperator> *op_ptr,
66:                                     vector<unique_ptr<LogicalOperator> *> &candidates) {
67: 	auto op = op_ptr->get();
68: 	// search children before adding, so that we add candidates bottom-up
69: 	for (auto &child : op->children) {
70: 		FindCandidates(&child, candidates);
71: 	}
72: 
73: 	// search for operator that has a LOGICAL_DELIM_JOIN as its child
74: 	if (op->children.size() != 1) {
75: 		return;
76: 	}
77: 	if (op->children[0]->type != LogicalOperatorType::LOGICAL_DELIM_JOIN) {
78: 		return;
79: 	}
80: 
81: 	// found a delim join
82: 	auto &delim_join = op->children[0]->Cast<LogicalDelimJoin>();
83: 	// only support INNER delim joins
84: 	if (delim_join.join_type != JoinType::INNER) {
85: 		return;
86: 	}
87: 	// INNER delim join must have exactly one condition
88: 	if (delim_join.conditions.size() != 1) {
89: 		return;
90: 	}
91: 
92: 	// LHS child is a window
93: 	if (delim_join.children[0]->type != LogicalOperatorType::LOGICAL_WINDOW) {
94: 		return;
95: 	}
96: 
97: 	// RHS child must be projection(s) followed by an UNNEST
98: 	auto curr_op = &delim_join.children[1];
99: 	while (curr_op->get()->type == LogicalOperatorType::LOGICAL_PROJECTION) {
100: 		if (curr_op->get()->children.size() != 1) {
101: 			break;
102: 		}
103: 		curr_op = &curr_op->get()->children[0];
104: 	}
105: 
106: 	if (curr_op->get()->type == LogicalOperatorType::LOGICAL_UNNEST) {
107: 		candidates.push_back(op_ptr);
108: 	}
109: 	return;
110: }
111: 
112: bool UnnestRewriter::RewriteCandidate(unique_ptr<LogicalOperator> *candidate) {
113: 
114: 	auto &topmost_op = (LogicalOperator &)**candidate;
115: 	if (topmost_op.type != LogicalOperatorType::LOGICAL_PROJECTION &&
116: 	    topmost_op.type != LogicalOperatorType::LOGICAL_WINDOW &&
117: 	    topmost_op.type != LogicalOperatorType::LOGICAL_FILTER &&
118: 	    topmost_op.type != LogicalOperatorType::LOGICAL_AGGREGATE_AND_GROUP_BY &&
119: 	    topmost_op.type != LogicalOperatorType::LOGICAL_UNNEST) {
120: 		return false;
121: 	}
122: 
123: 	// get the LOGICAL_DELIM_JOIN, which is a child of the candidate
124: 	D_ASSERT(topmost_op.children.size() == 1);
125: 	auto &delim_join = *(topmost_op.children[0]);
126: 	D_ASSERT(delim_join.type == LogicalOperatorType::LOGICAL_DELIM_JOIN);
127: 	GetDelimColumns(delim_join);
128: 
129: 	// LHS of the LOGICAL_DELIM_JOIN is a LOGICAL_WINDOW that contains a LOGICAL_PROJECTION
130: 	// this lhs_proj later becomes the child of the UNNEST
131: 	auto &window = *delim_join.children[0];
132: 	auto &lhs_op = window.children[0];
133: 	GetLHSExpressions(*lhs_op);
134: 
135: 	// find the LOGICAL_UNNEST
136: 	// and get the path down to the LOGICAL_UNNEST
137: 	vector<unique_ptr<LogicalOperator> *> path_to_unnest;
138: 	auto curr_op = &(delim_join.children[1]);
139: 	while (curr_op->get()->type == LogicalOperatorType::LOGICAL_PROJECTION) {
140: 		path_to_unnest.push_back(curr_op);
141: 		curr_op = &curr_op->get()->children[0];
142: 	}
143: 
144: 	// store the table index of the child of the LOGICAL_UNNEST
145: 	// then update the plan by making the lhs_proj the child of the LOGICAL_UNNEST
146: 	D_ASSERT(curr_op->get()->type == LogicalOperatorType::LOGICAL_UNNEST);
147: 	auto &unnest = curr_op->get()->Cast<LogicalUnnest>();
148: 	D_ASSERT(unnest.children[0]->type == LogicalOperatorType::LOGICAL_DELIM_GET);
149: 	overwritten_tbl_idx = unnest.children[0]->Cast<LogicalDelimGet>().table_index;
150: 	unnest.children[0] = std::move(lhs_op);
151: 
152: 	// replace the LOGICAL_DELIM_JOIN with its RHS child operator
153: 	topmost_op.children[0] = std::move(*path_to_unnest.front());
154: 	return true;
155: }
156: 
157: void UnnestRewriter::UpdateRHSBindings(unique_ptr<LogicalOperator> *plan_ptr, unique_ptr<LogicalOperator> *candidate,
158:                                        UnnestRewriterPlanUpdater &updater) {
159: 
160: 	auto &topmost_op = (LogicalOperator &)**candidate;
161: 	idx_t shift = lhs_bindings.size();
162: 
163: 	vector<unique_ptr<LogicalOperator> *> path_to_unnest;
164: 	auto curr_op = &(topmost_op.children[0]);
165: 	while (curr_op->get()->type == LogicalOperatorType::LOGICAL_PROJECTION) {
166: 
167: 		path_to_unnest.push_back(curr_op);
168: 		D_ASSERT(curr_op->get()->type == LogicalOperatorType::LOGICAL_PROJECTION);
169: 		auto &proj = curr_op->get()->Cast<LogicalProjection>();
170: 
171: 		// pop the two last expressions from all projections (delim_idx and UNNEST column)
172: 		D_ASSERT(proj.expressions.size() > 2);
173: 		proj.expressions.pop_back();
174: 		proj.expressions.pop_back();
175: 
176: 		// store all shifted current bindings
177: 		idx_t tbl_idx = proj.table_index;
178: 		for (idx_t i = 0; i < proj.expressions.size(); i++) {
179: 			ReplaceBinding replace_binding(ColumnBinding(tbl_idx, i), ColumnBinding(tbl_idx, i + shift));
180: 			updater.replace_bindings.push_back(replace_binding);
181: 		}
182: 
183: 		curr_op = &curr_op->get()->children[0];
184: 	}
185: 
186: 	// update all bindings by shifting them
187: 	updater.VisitOperator(*plan_ptr->get());
188: 	updater.replace_bindings.clear();
189: 
190: 	// update all bindings coming from the LHS to RHS bindings
191: 	D_ASSERT(topmost_op.children[0]->type == LogicalOperatorType::LOGICAL_PROJECTION);
192: 	auto &top_proj = topmost_op.children[0]->Cast<LogicalProjection>();
193: 	for (idx_t i = 0; i < lhs_bindings.size(); i++) {
194: 		ReplaceBinding replace_binding(lhs_bindings[i].binding, ColumnBinding(top_proj.table_index, i));
195: 		updater.replace_bindings.push_back(replace_binding);
196: 	}
197: 
198: 	// temporarily remove the BOUND_UNNEST and the child of the LOGICAL_UNNEST from the plan
199: 	D_ASSERT(curr_op->get()->type == LogicalOperatorType::LOGICAL_UNNEST);
200: 	auto &unnest = curr_op->get()->Cast<LogicalUnnest>();
201: 	auto temp_bound_unnest = std::move(unnest.expressions[0]);
202: 	auto temp_unnest_child = std::move(unnest.children[0]);
203: 	unnest.expressions.clear();
204: 	unnest.children.clear();
205: 	// update the bindings of the plan
206: 	updater.VisitOperator(*plan_ptr->get());
207: 	updater.replace_bindings.clear();
208: 	// add the child again
209: 	unnest.expressions.push_back(std::move(temp_bound_unnest));
210: 	unnest.children.push_back(std::move(temp_unnest_child));
211: 
212: 	// add the LHS expressions to each LOGICAL_PROJECTION
213: 	for (idx_t i = path_to_unnest.size(); i > 0; i--) {
214: 
215: 		D_ASSERT(path_to_unnest[i - 1]->get()->type == LogicalOperatorType::LOGICAL_PROJECTION);
216: 		auto &proj = path_to_unnest[i - 1]->get()->Cast<LogicalProjection>();
217: 
218: 		// temporarily store the existing expressions
219: 		vector<unique_ptr<Expression>> existing_expressions;
220: 		for (idx_t expr_idx = 0; expr_idx < proj.expressions.size(); expr_idx++) {
221: 			existing_expressions.push_back(std::move(proj.expressions[expr_idx]));
222: 		}
223: 
224: 		proj.expressions.clear();
225: 
226: 		// add the new expressions
227: 		for (idx_t expr_idx = 0; expr_idx < lhs_bindings.size(); expr_idx++) {
228: 			auto new_expr = make_uniq<BoundColumnRefExpression>(
229: 			    lhs_bindings[expr_idx].alias, lhs_bindings[expr_idx].type, lhs_bindings[expr_idx].binding);
230: 			proj.expressions.push_back(std::move(new_expr));
231: 
232: 			// update the table index
233: 			lhs_bindings[expr_idx].binding.table_index = proj.table_index;
234: 			lhs_bindings[expr_idx].binding.column_index = expr_idx;
235: 		}
236: 
237: 		// add the existing expressions again
238: 		for (idx_t expr_idx = 0; expr_idx < existing_expressions.size(); expr_idx++) {
239: 			proj.expressions.push_back(std::move(existing_expressions[expr_idx]));
240: 		}
241: 	}
242: }
243: 
244: void UnnestRewriter::UpdateBoundUnnestBindings(UnnestRewriterPlanUpdater &updater,
245:                                                unique_ptr<LogicalOperator> *candidate) {
246: 
247: 	auto &topmost_op = (LogicalOperator &)**candidate;
248: 
249: 	// traverse LOGICAL_PROJECTION(s)
250: 	auto curr_op = &(topmost_op.children[0]);
251: 	while (curr_op->get()->type == LogicalOperatorType::LOGICAL_PROJECTION) {
252: 		curr_op = &curr_op->get()->children[0];
253: 	}
254: 
255: 	// found the LOGICAL_UNNEST
256: 	D_ASSERT(curr_op->get()->type == LogicalOperatorType::LOGICAL_UNNEST);
257: 	auto &unnest = curr_op->get()->Cast<LogicalUnnest>();
258: 
259: 	auto unnest_child_cols = unnest.children[0]->GetColumnBindings();
260: 	for (idx_t delim_col_idx = 0; delim_col_idx < delim_columns.size(); delim_col_idx++) {
261: 		for (idx_t child_col_idx = 0; child_col_idx < unnest_child_cols.size(); child_col_idx++) {
262: 			if (delim_columns[delim_col_idx].table_index == unnest_child_cols[child_col_idx].table_index) {
263: 				ColumnBinding old_binding(overwritten_tbl_idx, DConstants::INVALID_INDEX);
264: 				updater.replace_bindings.emplace_back(old_binding, delim_columns[delim_col_idx]);
265: 				break;
266: 			}
267: 		}
268: 	}
269: 
270: 	// update bindings
271: 	D_ASSERT(unnest.expressions.size() == 1);
272: 	updater.VisitExpression(&unnest.expressions[0]);
273: 	updater.replace_bindings.clear();
274: }
275: 
276: void UnnestRewriter::GetDelimColumns(LogicalOperator &op) {
277: 
278: 	D_ASSERT(op.type == LogicalOperatorType::LOGICAL_DELIM_JOIN);
279: 	auto &delim_join = op.Cast<LogicalDelimJoin>();
280: 	for (idx_t i = 0; i < delim_join.duplicate_eliminated_columns.size(); i++) {
281: 		auto &expr = *delim_join.duplicate_eliminated_columns[i];
282: 		D_ASSERT(expr.type == ExpressionType::BOUND_COLUMN_REF);
283: 		auto &bound_colref_expr = expr.Cast<BoundColumnRefExpression>();
284: 		delim_columns.push_back(bound_colref_expr.binding);
285: 	}
286: }
287: 
288: void UnnestRewriter::GetLHSExpressions(LogicalOperator &op) {
289: 
290: 	op.ResolveOperatorTypes();
291: 	auto col_bindings = op.GetColumnBindings();
292: 	D_ASSERT(op.types.size() == col_bindings.size());
293: 
294: 	bool set_alias = false;
295: 	// we can easily extract the alias for LOGICAL_PROJECTION(s)
296: 	if (op.type == LogicalOperatorType::LOGICAL_PROJECTION) {
297: 		auto &proj = op.Cast<LogicalProjection>();
298: 		if (proj.expressions.size() == op.types.size()) {
299: 			set_alias = true;
300: 		}
301: 	}
302: 
303: 	for (idx_t i = 0; i < op.types.size(); i++) {
304: 		lhs_bindings.emplace_back(col_bindings[i], op.types[i]);
305: 		if (set_alias) {
306: 			auto &proj = op.Cast<LogicalProjection>();
307: 			lhs_bindings.back().alias = proj.expressions[i]->alias;
308: 		}
309: 	}
310: }
311: 
312: } // namespace duckdb
[end of src/optimizer/unnest_rewriter.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: