You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Duplicate primary key error with sequences and large tables
### What happens?

When reading in a large CSV file into a table with a primary key generated by a sequence a duplicate key error is encountered.

>Error: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key

May be related to https://github.com/duckdb/duckdb/issues/6421.

My memory settings during reproduction
```
│ memory_limit                 │ 54.9GB
```

### To Reproduce

Create a large CSV file. I used the following Python script
```python
#!/usr/bin/env python3

print("A0")
for x in range(1618111681):
    print("");
```

Start Duck and run the following
```sql
create sequence T1_sequence start 0 minvalue 0;
create table T1 (ID integer not null default (nextval('T1_sequence')), A0 varchar, primary key (ID));
copy T1(A0) from 'data.csv' (delimiter ',', header);
```

This will eventually cause the error
>Error: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key

Trying to run a `SELECT *` on the table after the failure results in an out of memory error.

```
libc++abi: terminating with uncaught exception of type duckdb::OutOfMemoryException: Out of Memory Error: failed to allocate data of size 32768
Database is launched in in-memory mode and no temporary directory is specified.
Unused blocks cannot be offloaded to disk.

Launch the database with a persistent storage back-end
Or set PRAGMA temp_directory='/path/to/tmp.tmp'
[1]    38402 abort      ./build/release/duckdb
```

### OS:

MacOS M1, Linux x86_64

### DuckDB Version:

0.7.1

### DuckDB Client:

CLI, JDBC

### Full Name:

Michael Albers

### Affiliation:

Mode Analytics

### Have you tried this on the latest `master` branch?

- [X] I agree

### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?

- [X] I agree
Duplicate primary key error with sequences and large tables
### What happens?

When reading in a large CSV file into a table with a primary key generated by a sequence a duplicate key error is encountered.

>Error: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key

May be related to https://github.com/duckdb/duckdb/issues/6421.

My memory settings during reproduction
```
│ memory_limit                 │ 54.9GB
```

### To Reproduce

Create a large CSV file. I used the following Python script
```python
#!/usr/bin/env python3

print("A0")
for x in range(1618111681):
    print("");
```

Start Duck and run the following
```sql
create sequence T1_sequence start 0 minvalue 0;
create table T1 (ID integer not null default (nextval('T1_sequence')), A0 varchar, primary key (ID));
copy T1(A0) from 'data.csv' (delimiter ',', header);
```

This will eventually cause the error
>Error: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key

Trying to run a `SELECT *` on the table after the failure results in an out of memory error.

```
libc++abi: terminating with uncaught exception of type duckdb::OutOfMemoryException: Out of Memory Error: failed to allocate data of size 32768
Database is launched in in-memory mode and no temporary directory is specified.
Unused blocks cannot be offloaded to disk.

Launch the database with a persistent storage back-end
Or set PRAGMA temp_directory='/path/to/tmp.tmp'
[1]    38402 abort      ./build/release/duckdb
```

### OS:

MacOS M1, Linux x86_64

### DuckDB Version:

0.7.1

### DuckDB Client:

CLI, JDBC

### Full Name:

Michael Albers

### Affiliation:

Mode Analytics

### Have you tried this on the latest `master` branch?

- [X] I agree

### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?

- [X] I agree
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
