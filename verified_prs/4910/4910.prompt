You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
list_apply seems to be picking up the wrong value when using columnar values
### What happens?

expect list_apply to work with columnar values, but it does not seem to be the case.

in some cases, it seems to run into a segfault, but i cant seem to find a minimal example to reproduce the segfault.

suspect that fixing this might fix the seg fault error too.

### To Reproduce

```
create table test(a int, b int);
insert into test values (1, 2), (1, 3), (1, 4);
insert into test values (2, 2), (2, 3), (2, 4);
insert into test values (3, 2), (3, 3), (3, 4);

select 
list_apply(bb, x->[x,b]),
bb, b
from (select list(b) over wind as bb, first(b) over wind as b 
    from test window wind as 
        (order by a asc rows between 4 preceding and current row)
    qualify row_number() over wind >4);
```

```
zsh/3 699  (git)-[master]-% duckdb < testtest.sql
┌────────────────────────────────────────────┬─────────────────┬───┐
│ list_apply(bb, x -> main.list_value(x, b)) │       bb        │ b │
├────────────────────────────────────────────┼─────────────────┼───┤
│ [[2, 3], [3, 3], [4, 3], [2, 3], [3, 3]]   │ [2, 3, 4, 2, 3] │ 2 │
│ [[3, 2], [4, 2], [2, 2], [3, 2], [4, 2]]   │ [3, 4, 2, 3, 4] │ 3 │
│ [[4, 2], [2, 2], [3, 2], [4, 2], [2, 2]]   │ [4, 2, 3, 4, 2] │ 4 │
│ [[2, 2], [3, 2], [4, 2], [2, 2], [3, 2]]   │ [2, 3, 4, 2, 3] │ 2 │
│ [[3, 2], [4, 2], [2, 2], [3, 2], [4, 2]]   │ [3, 4, 2, 3, 4] │ 3 │
└────────────────────────────────────────────┴─────────────────┴───┘
```

expects the b to be from that row, but seems like not that case.

### OS:

linux

### DuckDB Version:

v0.5.1 7c111322d

### DuckDB Client:

CLI

### Full Name:

metta ong

### Affiliation:

-

### Have you tried this on the latest `master` branch?

- [X] I agree

### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?

- [X] I agree

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=master" alt="Github Actions Badge">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The detail of benchmarks is in our [Benchmark Guide](benchmark/README.md).
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
[end of README.md]
[start of src/function/scalar/list/list_lambdas.cpp]
1: #include "duckdb/planner/expression/bound_function_expression.hpp"
2: #include "duckdb/function/scalar/nested_functions.hpp"
3: #include "duckdb/planner/expression_iterator.hpp"
4: #include "duckdb/planner/expression/bound_reference_expression.hpp"
5: #include "duckdb/execution/expression_executor.hpp"
6: #include "duckdb/planner/expression/bound_constant_expression.hpp"
7: #include "duckdb/planner/expression/bound_lambda_expression.hpp"
8: 
9: namespace duckdb {
10: 
11: struct ListLambdaBindData : public FunctionData {
12: 	ListLambdaBindData(const LogicalType &stype_p, unique_ptr<Expression> lambda_expr);
13: 	~ListLambdaBindData() override;
14: 
15: 	LogicalType stype;
16: 	unique_ptr<Expression> lambda_expr;
17: 
18: public:
19: 	bool Equals(const FunctionData &other_p) const override;
20: 	unique_ptr<FunctionData> Copy() const override;
21: 	static void Serialize(FieldWriter &writer, const FunctionData *bind_data_p, const ScalarFunction &function) {
22: 		throw NotImplementedException("FIXME: list lambda serialize");
23: 	}
24: 	static unique_ptr<FunctionData> Deserialize(ClientContext &context, FieldReader &reader,
25: 	                                            ScalarFunction &bound_function) {
26: 		throw NotImplementedException("FIXME: list lambda deserialize");
27: 	}
28: };
29: 
30: ListLambdaBindData::ListLambdaBindData(const LogicalType &stype_p, unique_ptr<Expression> lambda_expr_p)
31:     : stype(stype_p), lambda_expr(move(lambda_expr_p)) {
32: }
33: 
34: unique_ptr<FunctionData> ListLambdaBindData::Copy() const {
35: 	return make_unique<ListLambdaBindData>(stype, lambda_expr->Copy());
36: }
37: 
38: bool ListLambdaBindData::Equals(const FunctionData &other_p) const {
39: 	auto &other = (ListLambdaBindData &)other_p;
40: 	return lambda_expr->Equals(other.lambda_expr.get()) && stype == other.stype;
41: }
42: 
43: ListLambdaBindData::~ListLambdaBindData() {
44: }
45: 
46: static void AppendTransformedToResult(Vector &lambda_vector, idx_t &elem_cnt, Vector &result) {
47: 
48: 	// append the lambda_vector to the result list
49: 	UnifiedVectorFormat lambda_child_data;
50: 	lambda_vector.ToUnifiedFormat(elem_cnt, lambda_child_data);
51: 	ListVector::Append(result, lambda_vector, *lambda_child_data.sel, elem_cnt, 0);
52: }
53: 
54: static void AppendFilteredToResult(Vector &lambda_vector, list_entry_t *result_entries, idx_t &elem_cnt, Vector &result,
55:                                    idx_t &curr_list_len, idx_t &curr_list_offset, idx_t &appended_lists_cnt,
56:                                    vector<idx_t> &lists_len, idx_t &curr_original_list_len, DataChunk &input_chunk) {
57: 
58: 	idx_t true_count = 0;
59: 	SelectionVector true_sel(elem_cnt);
60: 	auto lambda_values = FlatVector::GetData<bool>(lambda_vector);
61: 	auto &lambda_validity = FlatVector::Validity(lambda_vector);
62: 
63: 	// compute the new lengths and offsets, and create a selection vector
64: 	for (idx_t i = 0; i < elem_cnt; i++) {
65: 
66: 		while (appended_lists_cnt < lists_len.size() && lists_len[appended_lists_cnt] == 0) {
67: 			result_entries[appended_lists_cnt].offset = curr_list_offset;
68: 			result_entries[appended_lists_cnt].length = 0;
69: 			appended_lists_cnt++;
70: 		}
71: 
72: 		// found a true value
73: 		if (lambda_validity.RowIsValid(i)) {
74: 			if (lambda_values[i] > 0) {
75: 				true_sel.set_index(true_count++, i);
76: 				curr_list_len++;
77: 			}
78: 		}
79: 		curr_original_list_len++;
80: 
81: 		if (lists_len[appended_lists_cnt] == curr_original_list_len) {
82: 			result_entries[appended_lists_cnt].offset = curr_list_offset;
83: 			result_entries[appended_lists_cnt].length = curr_list_len;
84: 			curr_list_offset += curr_list_len;
85: 			appended_lists_cnt++;
86: 			curr_list_len = 0;
87: 			curr_original_list_len = 0;
88: 		}
89: 	}
90: 
91: 	while (appended_lists_cnt < lists_len.size() && lists_len[appended_lists_cnt] == 0) {
92: 		result_entries[appended_lists_cnt].offset = curr_list_offset;
93: 		result_entries[appended_lists_cnt].length = 0;
94: 		appended_lists_cnt++;
95: 	}
96: 
97: 	// slice to get the new lists and append them to the result
98: 	Vector new_lists(input_chunk.data[0], true_sel, true_count);
99: 	new_lists.Flatten(true_count);
100: 	UnifiedVectorFormat new_lists_child_data;
101: 	new_lists.ToUnifiedFormat(true_count, new_lists_child_data);
102: 	ListVector::Append(result, new_lists, *new_lists_child_data.sel, true_count, 0);
103: }
104: 
105: static void ExecuteExpression(vector<LogicalType> &types, vector<LogicalType> &result_types, idx_t &elem_cnt,
106:                               SelectionVector &sel, vector<SelectionVector> &sel_vectors, DataChunk &input_chunk,
107:                               DataChunk &lambda_chunk, Vector &child_vector, DataChunk &args,
108:                               ExpressionExecutor &expr_executor) {
109: 
110: 	input_chunk.SetCardinality(elem_cnt);
111: 	lambda_chunk.SetCardinality(elem_cnt);
112: 
113: 	// set the list child vector
114: 	Vector slice(child_vector, sel, elem_cnt);
115: 	slice.Flatten(elem_cnt);
116: 	input_chunk.data[0].Reference(slice);
117: 
118: 	// set the other vectors
119: 	vector<Vector> slices;
120: 	for (idx_t col_idx = 0; col_idx < args.ColumnCount() - 1; col_idx++) {
121: 		slices.emplace_back(Vector(args.data[col_idx + 1], sel_vectors[col_idx], elem_cnt));
122: 		slices[col_idx].Flatten(elem_cnt);
123: 		input_chunk.data[col_idx + 1].Reference(slices[col_idx]);
124: 	}
125: 
126: 	// execute the lambda expression
127: 	expr_executor.Execute(input_chunk, lambda_chunk);
128: }
129: 
130: template <bool IS_TRANSFORM = true>
131: static void ListLambdaFunction(DataChunk &args, ExpressionState &state, Vector &result) {
132: 
133: 	// always at least the list argument
134: 	D_ASSERT(args.ColumnCount() >= 1);
135: 
136: 	auto count = args.size();
137: 	Vector &lists = args.data[0];
138: 
139: 	result.SetVectorType(VectorType::FLAT_VECTOR);
140: 	auto result_entries = FlatVector::GetData<list_entry_t>(result);
141: 	auto &result_validity = FlatVector::Validity(result);
142: 
143: 	if (lists.GetType().id() == LogicalTypeId::SQLNULL) {
144: 		result_validity.SetInvalid(0);
145: 		return;
146: 	}
147: 
148: 	// get the lists data
149: 	UnifiedVectorFormat lists_data;
150: 	lists.ToUnifiedFormat(count, lists_data);
151: 	auto list_entries = (list_entry_t *)lists_data.data;
152: 
153: 	// get the lambda expression
154: 	auto &func_expr = (BoundFunctionExpression &)state.expr;
155: 	auto &info = (ListLambdaBindData &)*func_expr.bind_info;
156: 	auto &lambda_expr = info.lambda_expr;
157: 
158: 	// get the child vector and child data
159: 	auto lists_size = ListVector::GetListSize(lists);
160: 	auto &child_vector = ListVector::GetEntry(lists);
161: 	UnifiedVectorFormat child_data;
162: 	child_vector.ToUnifiedFormat(lists_size, child_data);
163: 
164: 	// to slice the child vector
165: 	SelectionVector sel(STANDARD_VECTOR_SIZE);
166: 
167: 	// this vector never contains more than one element
168: 	vector<LogicalType> result_types;
169: 	result_types.push_back(lambda_expr->return_type);
170: 
171: 	// non-lambda parameter columns
172: 	vector<UnifiedVectorFormat> columns;
173: 	vector<idx_t> indexes;
174: 	vector<SelectionVector> sel_vectors;
175: 
176: 	vector<LogicalType> types;
177: 	types.push_back(child_vector.GetType());
178: 
179: 	// skip the list column
180: 	for (idx_t i = 1; i < args.ColumnCount(); i++) {
181: 		columns.emplace_back(UnifiedVectorFormat());
182: 		args.data[i].ToUnifiedFormat(count, columns[i - 1]);
183: 		indexes.push_back(0);
184: 		sel_vectors.emplace_back(SelectionVector(STANDARD_VECTOR_SIZE));
185: 		types.push_back(args.data[i].GetType());
186: 	}
187: 
188: 	// get the expression executor
189: 	ExpressionExecutor expr_executor(Allocator::DefaultAllocator(), *lambda_expr);
190: 
191: 	// these are only for the list_filter
192: 	vector<idx_t> lists_len;
193: 	idx_t curr_list_len = 0;
194: 	idx_t curr_list_offset = 0;
195: 	idx_t appended_lists_cnt = 0;
196: 	idx_t curr_original_list_len = 0;
197: 
198: 	if (!IS_TRANSFORM) {
199: 		lists_len.reserve(count);
200: 	}
201: 
202: 	DataChunk input_chunk;
203: 	DataChunk lambda_chunk;
204: 	input_chunk.InitializeEmpty(types);
205: 	lambda_chunk.Initialize(Allocator::DefaultAllocator(), result_types);
206: 
207: 	// loop over the child entries and create chunks to be executed by the expression executor
208: 	idx_t elem_cnt = 0;
209: 	idx_t offset = 0;
210: 	for (idx_t row_idx = 0; row_idx < count; row_idx++) {
211: 
212: 		auto lists_index = lists_data.sel->get_index(row_idx);
213: 		const auto &list_entry = list_entries[lists_index];
214: 
215: 		// set the result to NULL for this row
216: 		if (!lists_data.validity.RowIsValid(lists_index)) {
217: 			result_validity.SetInvalid(row_idx);
218: 			if (!IS_TRANSFORM) {
219: 				lists_len.push_back(0);
220: 			}
221: 			continue;
222: 		}
223: 
224: 		// set the length and offset of the resulting lists of list_transform
225: 		if (IS_TRANSFORM) {
226: 			result_entries[row_idx].offset = offset;
227: 			result_entries[row_idx].length = list_entry.length;
228: 			offset += list_entry.length;
229: 		} else {
230: 			lists_len.push_back(list_entry.length);
231: 		}
232: 
233: 		// empty list, nothing to execute
234: 		if (list_entry.length == 0) {
235: 			continue;
236: 		}
237: 
238: 		// get the data indexes
239: 		for (idx_t col_idx = 0; col_idx < args.ColumnCount() - 1; col_idx++) {
240: 			indexes[col_idx] = columns[col_idx].sel->get_index(row_idx);
241: 		}
242: 
243: 		// iterate list elements and create transformed expression columns
244: 		for (idx_t child_idx = 0; child_idx < list_entry.length; child_idx++) {
245: 
246: 			// reached STANDARD_VECTOR_SIZE elements
247: 			if (elem_cnt == STANDARD_VECTOR_SIZE) {
248: 
249: 				lambda_chunk.Reset();
250: 				ExecuteExpression(types, result_types, elem_cnt, sel, sel_vectors, input_chunk, lambda_chunk,
251: 				                  child_vector, args, expr_executor);
252: 
253: 				auto &lambda_vector = lambda_chunk.data[0];
254: 
255: 				if (IS_TRANSFORM) {
256: 					AppendTransformedToResult(lambda_vector, elem_cnt, result);
257: 				} else {
258: 					AppendFilteredToResult(lambda_vector, result_entries, elem_cnt, result, curr_list_len,
259: 					                       curr_list_offset, appended_lists_cnt, lists_len, curr_original_list_len,
260: 					                       input_chunk);
261: 				}
262: 				elem_cnt = 0;
263: 			}
264: 
265: 			// to slice the child vector
266: 			auto source_idx = child_data.sel->get_index(list_entry.offset + child_idx);
267: 			sel.set_index(elem_cnt, source_idx);
268: 
269: 			// for each column, set the index of the selection vector to slice properly
270: 			for (idx_t col_idx = 0; col_idx < args.ColumnCount() - 1; col_idx++) {
271: 				sel_vectors[col_idx].set_index(elem_cnt, indexes[col_idx]);
272: 			}
273: 			elem_cnt++;
274: 		}
275: 	}
276: 
277: 	lambda_chunk.Reset();
278: 	ExecuteExpression(types, result_types, elem_cnt, sel, sel_vectors, input_chunk, lambda_chunk, child_vector, args,
279: 	                  expr_executor);
280: 	auto &lambda_vector = lambda_chunk.data[0];
281: 
282: 	if (IS_TRANSFORM) {
283: 		AppendTransformedToResult(lambda_vector, elem_cnt, result);
284: 	} else {
285: 		AppendFilteredToResult(lambda_vector, result_entries, elem_cnt, result, curr_list_len, curr_list_offset,
286: 		                       appended_lists_cnt, lists_len, curr_original_list_len, input_chunk);
287: 	}
288: 
289: 	if (args.AllConstant()) {
290: 		result.SetVectorType(VectorType::CONSTANT_VECTOR);
291: 	}
292: }
293: 
294: static void ListTransformFunction(DataChunk &args, ExpressionState &state, Vector &result) {
295: 	ListLambdaFunction<>(args, state, result);
296: }
297: 
298: static void ListFilterFunction(DataChunk &args, ExpressionState &state, Vector &result) {
299: 	ListLambdaFunction<false>(args, state, result);
300: }
301: 
302: template <int64_t LAMBDA_PARAM_CNT>
303: static unique_ptr<FunctionData> ListLambdaBind(ClientContext &context, ScalarFunction &bound_function,
304:                                                vector<unique_ptr<Expression>> &arguments) {
305: 
306: 	auto &bound_lambda_expr = (BoundLambdaExpression &)*arguments[1];
307: 	if (bound_lambda_expr.parameter_count != LAMBDA_PARAM_CNT) {
308: 		throw BinderException("Incorrect number of parameters in lambda function! " + bound_function.name +
309: 		                      " expects " + to_string(LAMBDA_PARAM_CNT) + " parameter(s).");
310: 	}
311: 
312: 	if (arguments[0]->return_type.id() == LogicalTypeId::SQLNULL) {
313: 		bound_function.arguments.pop_back();
314: 		bound_function.arguments[0] = LogicalType::SQLNULL;
315: 		bound_function.return_type = LogicalType::SQLNULL;
316: 		return make_unique<VariableReturnBindData>(bound_function.return_type);
317: 	}
318: 
319: 	if (arguments[0]->return_type.id() == LogicalTypeId::UNKNOWN) {
320: 		throw ParameterNotResolvedException();
321: 	}
322: 
323: 	D_ASSERT(arguments[0]->return_type.id() == LogicalTypeId::LIST);
324: 
325: 	// get the lambda expression and put it in the bind info
326: 	auto lambda_expr = move(bound_lambda_expr.lambda_expr);
327: 	return make_unique<ListLambdaBindData>(bound_function.return_type, move(lambda_expr));
328: }
329: 
330: static unique_ptr<FunctionData> ListTransformBind(ClientContext &context, ScalarFunction &bound_function,
331:                                                   vector<unique_ptr<Expression>> &arguments) {
332: 
333: 	// at least the list column and the lambda function
334: 	D_ASSERT(arguments.size() == 2);
335: 	if (arguments[1]->expression_class != ExpressionClass::BOUND_LAMBDA) {
336: 		throw BinderException("Invalid lambda expression!");
337: 	}
338: 
339: 	auto &bound_lambda_expr = (BoundLambdaExpression &)*arguments[1];
340: 	bound_function.return_type = LogicalType::LIST(bound_lambda_expr.lambda_expr->return_type);
341: 	return ListLambdaBind<1>(context, bound_function, arguments);
342: }
343: 
344: static unique_ptr<FunctionData> ListFilterBind(ClientContext &context, ScalarFunction &bound_function,
345:                                                vector<unique_ptr<Expression>> &arguments) {
346: 
347: 	// at least the list column and the lambda function
348: 	D_ASSERT(arguments.size() == 2);
349: 	if (arguments[1]->expression_class != ExpressionClass::BOUND_LAMBDA) {
350: 		throw BinderException("Invalid lambda expression!");
351: 	}
352: 	bound_function.return_type = arguments[0]->return_type;
353: 	return ListLambdaBind<1>(context, bound_function, arguments);
354: }
355: 
356: void ListTransformFun::RegisterFunction(BuiltinFunctions &set) {
357: 
358: 	ScalarFunction fun("list_transform", {LogicalType::LIST(LogicalType::ANY), LogicalType::LAMBDA},
359: 	                   LogicalType::LIST(LogicalType::ANY), ListTransformFunction, ListTransformBind, nullptr, nullptr);
360: 	fun.null_handling = FunctionNullHandling::SPECIAL_HANDLING;
361: 	fun.serialize = ListLambdaBindData::Serialize;
362: 	fun.deserialize = ListLambdaBindData::Deserialize;
363: 	set.AddFunction(fun);
364: 
365: 	fun.name = "array_transform";
366: 	set.AddFunction(fun);
367: 	fun.name = "list_apply";
368: 	set.AddFunction(fun);
369: 	fun.name = "array_apply";
370: 	set.AddFunction(fun);
371: }
372: 
373: void ListFilterFun::RegisterFunction(BuiltinFunctions &set) {
374: 
375: 	ScalarFunction fun("list_filter", {LogicalType::LIST(LogicalType::ANY), LogicalType::LAMBDA},
376: 	                   LogicalType::LIST(LogicalType::ANY), ListFilterFunction, ListFilterBind, nullptr, nullptr);
377: 	fun.null_handling = FunctionNullHandling::SPECIAL_HANDLING;
378: 	fun.serialize = ListLambdaBindData::Serialize;
379: 	fun.deserialize = ListLambdaBindData::Deserialize;
380: 	set.AddFunction(fun);
381: 
382: 	fun.name = "array_filter";
383: 	set.AddFunction(fun);
384: }
385: 
386: } // namespace duckdb
[end of src/function/scalar/list/list_lambdas.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: