You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
how to find the reserved words list
I tried to name a column alias to including and failed. 
I want to know what words is not reserved. 
```
D select 'am',12345 including; 
Error: Parser Error: syntax error at or near "including"
LINE 1: select 'am',12345 including;
                          ^
D select 'am',12345 includin;
┌────┬──────────┐
│ am │ includin │
├────┼──────────┤
│ am │ 12345    │
└────┴──────────┘
```

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/docs/why_duckdb.html).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
44: 
45: 
[end of README.md]
[start of src/function/table/system/CMakeLists.txt]
1: add_library_unity(
2:   duckdb_table_func_system
3:   OBJECT
4:   duckdb_columns.cpp
5:   duckdb_constraints.cpp
6:   duckdb_dependencies.cpp
7:   duckdb_functions.cpp
8:   duckdb_indexes.cpp
9:   duckdb_schemas.cpp
10:   duckdb_sequences.cpp
11:   duckdb_settings.cpp
12:   duckdb_tables.cpp
13:   duckdb_types.cpp
14:   duckdb_views.cpp
15:   pragma_collations.cpp
16:   pragma_database_list.cpp
17:   pragma_database_size.cpp
18:   pragma_functions.cpp
19:   pragma_storage_info.cpp
20:   pragma_table_info.cpp
21:   test_all_types.cpp)
22: set(ALL_OBJECT_FILES
23:     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_table_func_system>
24:     PARENT_SCOPE)
[end of src/function/table/system/CMakeLists.txt]
[start of src/function/table/system_functions.cpp]
1: #include "duckdb/function/table/system_functions.hpp"
2: #include "duckdb/parser/parsed_data/create_view_info.hpp"
3: #include "duckdb/parser/query_node/select_node.hpp"
4: #include "duckdb/parser/expression/star_expression.hpp"
5: #include "duckdb/parser/tableref/table_function_ref.hpp"
6: #include "duckdb/parser/expression/function_expression.hpp"
7: #include "duckdb/catalog/catalog.hpp"
8: 
9: namespace duckdb {
10: 
11: void BuiltinFunctions::RegisterSQLiteFunctions() {
12: 	PragmaVersion::RegisterFunction(*this);
13: 	PragmaFunctionPragma::RegisterFunction(*this);
14: 	PragmaCollations::RegisterFunction(*this);
15: 	PragmaTableInfo::RegisterFunction(*this);
16: 	PragmaStorageInfo::RegisterFunction(*this);
17: 	PragmaDatabaseSize::RegisterFunction(*this);
18: 	PragmaDatabaseList::RegisterFunction(*this);
19: 	PragmaLastProfilingOutput::RegisterFunction(*this);
20: 	PragmaDetailedProfilingOutput::RegisterFunction(*this);
21: 
22: 	DuckDBColumnsFun::RegisterFunction(*this);
23: 	DuckDBConstraintsFun::RegisterFunction(*this);
24: 	DuckDBFunctionsFun::RegisterFunction(*this);
25: 	DuckDBIndexesFun::RegisterFunction(*this);
26: 	DuckDBSchemasFun::RegisterFunction(*this);
27: 	DuckDBDependenciesFun::RegisterFunction(*this);
28: 	DuckDBSequencesFun::RegisterFunction(*this);
29: 	DuckDBSettingsFun::RegisterFunction(*this);
30: 	DuckDBTablesFun::RegisterFunction(*this);
31: 	DuckDBTypesFun::RegisterFunction(*this);
32: 	DuckDBViewsFun::RegisterFunction(*this);
33: 	TestAllTypesFun::RegisterFunction(*this);
34: }
35: 
36: } // namespace duckdb
[end of src/function/table/system_functions.cpp]
[start of src/include/duckdb/function/table/system_functions.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/function/table/system_functions.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/function/table_function.hpp"
12: 
13: namespace duckdb {
14: 
15: struct PragmaCollations {
16: 	static void RegisterFunction(BuiltinFunctions &set);
17: };
18: 
19: struct PragmaFunctionPragma {
20: 	static void RegisterFunction(BuiltinFunctions &set);
21: };
22: 
23: struct PragmaTableInfo {
24: 	static void RegisterFunction(BuiltinFunctions &set);
25: };
26: 
27: struct PragmaStorageInfo {
28: 	static void RegisterFunction(BuiltinFunctions &set);
29: };
30: 
31: struct PragmaLastProfilingOutput {
32: 	static void RegisterFunction(BuiltinFunctions &set);
33: };
34: 
35: struct PragmaDetailedProfilingOutput {
36: 	static void RegisterFunction(BuiltinFunctions &set);
37: };
38: 
39: struct PragmaVersion {
40: 	static void RegisterFunction(BuiltinFunctions &set);
41: };
42: 
43: struct PragmaDatabaseList {
44: 	static void RegisterFunction(BuiltinFunctions &set);
45: };
46: 
47: struct PragmaDatabaseSize {
48: 	static void RegisterFunction(BuiltinFunctions &set);
49: };
50: 
51: struct DuckDBSchemasFun {
52: 	static void RegisterFunction(BuiltinFunctions &set);
53: };
54: 
55: struct DuckDBColumnsFun {
56: 	static void RegisterFunction(BuiltinFunctions &set);
57: };
58: 
59: struct DuckDBConstraintsFun {
60: 	static void RegisterFunction(BuiltinFunctions &set);
61: };
62: 
63: struct DuckDBDependenciesFun {
64: 	static void RegisterFunction(BuiltinFunctions &set);
65: };
66: 
67: struct DuckDBFunctionsFun {
68: 	static void RegisterFunction(BuiltinFunctions &set);
69: };
70: 
71: struct DuckDBIndexesFun {
72: 	static void RegisterFunction(BuiltinFunctions &set);
73: };
74: 
75: struct DuckDBSequencesFun {
76: 	static void RegisterFunction(BuiltinFunctions &set);
77: };
78: 
79: struct DuckDBSettingsFun {
80: 	static void RegisterFunction(BuiltinFunctions &set);
81: };
82: 
83: struct DuckDBTablesFun {
84: 	static void RegisterFunction(BuiltinFunctions &set);
85: };
86: 
87: struct DuckDBTypesFun {
88: 	static void RegisterFunction(BuiltinFunctions &set);
89: };
90: 
91: struct DuckDBViewsFun {
92: 	static void RegisterFunction(BuiltinFunctions &set);
93: };
94: 
95: struct TestAllTypesFun {
96: 	static void RegisterFunction(BuiltinFunctions &set);
97: };
98: 
99: } // namespace duckdb
[end of src/include/duckdb/function/table/system_functions.hpp]
[start of src/include/duckdb/parser/parser.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/parser/parser.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/parser/sql_statement.hpp"
12: #include "duckdb/parser/parsed_expression.hpp"
13: #include "duckdb/parser/query_node.hpp"
14: #include "duckdb/parser/column_definition.hpp"
15: #include "duckdb/parser/simplified_token.hpp"
16: 
17: namespace duckdb_libpgquery {
18: struct PGNode;
19: struct PGList;
20: } // namespace duckdb_libpgquery
21: 
22: namespace duckdb {
23: 
24: //! The parser is responsible for parsing the query and converting it into a set
25: //! of parsed statements. The parsed statements can then be converted into a
26: //! plan and executed.
27: class Parser {
28: public:
29: 	Parser();
30: 
31: 	//! Attempts to parse a query into a series of SQL statements. Returns
32: 	//! whether or not the parsing was successful. If the parsing was
33: 	//! successful, the parsed statements will be stored in the statements
34: 	//! variable.
35: 	void ParseQuery(const string &query);
36: 
37: 	//! Tokenize a query, returning the raw tokens together with their locations
38: 	static vector<SimplifiedToken> Tokenize(const string &query);
39: 
40: 	//! Returns true if the given text matches a keyword of the parser
41: 	static bool IsKeyword(const string &text);
42: 
43: 	//! Parses a list of expressions (i.e. the list found in a SELECT clause)
44: 	static vector<unique_ptr<ParsedExpression>> ParseExpressionList(const string &select_list);
45: 	//! Parses a list as found in an ORDER BY expression (i.e. including optional ASCENDING/DESCENDING modifiers)
46: 	static vector<OrderByNode> ParseOrderList(const string &select_list);
47: 	//! Parses an update list (i.e. the list found in the SET clause of an UPDATE statement)
48: 	static void ParseUpdateList(const string &update_list, vector<string> &update_columns,
49: 	                            vector<unique_ptr<ParsedExpression>> &expressions);
50: 	//! Parses a VALUES list (i.e. the list of expressions after a VALUES clause)
51: 	static vector<vector<unique_ptr<ParsedExpression>>> ParseValuesList(const string &value_list);
52: 	//! Parses a column list (i.e. as found in a CREATE TABLE statement)
53: 	static vector<ColumnDefinition> ParseColumnList(const string &column_list);
54: 
55: 	//! The parsed SQL statements from an invocation to ParseQuery.
56: 	vector<unique_ptr<SQLStatement>> statements;
57: 
58: private:
59: 	//! Transform a Postgres parse tree into a set of SQL Statements
60: 	bool TransformList(duckdb_libpgquery::PGList *tree);
61: 	//! Transform a single Postgres parse node into a SQL Statement.
62: 	unique_ptr<SQLStatement> TransformNode(duckdb_libpgquery::PGNode *stmt);
63: };
64: } // namespace duckdb
[end of src/include/duckdb/parser/parser.hpp]
[start of src/include/duckdb/parser/simplified_token.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/parser/simplified_token.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/common.hpp"
12: 
13: namespace duckdb {
14: 
15: //! Simplified tokens are a simplified (dense) representation of the lexer
16: //! Used for simple syntax highlighting in the tests
17: enum class SimplifiedTokenType : uint8_t {
18: 	SIMPLIFIED_TOKEN_IDENTIFIER,
19: 	SIMPLIFIED_TOKEN_NUMERIC_CONSTANT,
20: 	SIMPLIFIED_TOKEN_STRING_CONSTANT,
21: 	SIMPLIFIED_TOKEN_OPERATOR,
22: 	SIMPLIFIED_TOKEN_KEYWORD,
23: 	SIMPLIFIED_TOKEN_COMMENT
24: };
25: 
26: struct SimplifiedToken {
27: 	SimplifiedTokenType type;
28: 	idx_t start;
29: };
30: 
31: } // namespace duckdb
[end of src/include/duckdb/parser/simplified_token.hpp]
[start of src/parser/parser.cpp]
1: #include "duckdb/parser/parser.hpp"
2: 
3: #include "duckdb/parser/transformer.hpp"
4: #include "duckdb/parser/parsed_data/create_table_info.hpp"
5: #include "duckdb/parser/statement/create_statement.hpp"
6: #include "duckdb/parser/statement/select_statement.hpp"
7: #include "duckdb/parser/statement/update_statement.hpp"
8: #include "duckdb/parser/query_node/select_node.hpp"
9: #include "duckdb/parser/tableref/expressionlistref.hpp"
10: #include "postgres_parser.hpp"
11: #include "duckdb/parser/query_error_context.hpp"
12: 
13: #include "parser/parser.hpp"
14: 
15: namespace duckdb {
16: 
17: Parser::Parser() {
18: }
19: 
20: void Parser::ParseQuery(const string &query) {
21: 	Transformer transformer;
22: 	{
23: 		PostgresParser parser;
24: 		parser.Parse(query);
25: 
26: 		if (!parser.success) {
27: 			throw ParserException(QueryErrorContext::Format(query, parser.error_message, parser.error_location - 1));
28: 		}
29: 
30: 		if (!parser.parse_tree) {
31: 			// empty statement
32: 			return;
33: 		}
34: 
35: 		// if it succeeded, we transform the Postgres parse tree into a list of
36: 		// SQLStatements
37: 		transformer.TransformParseTree(parser.parse_tree, statements);
38: 	}
39: 	if (!statements.empty()) {
40: 		auto &last_statement = statements.back();
41: 		last_statement->stmt_length = query.size() - last_statement->stmt_location;
42: 		for (auto &statement : statements) {
43: 			statement->query = query;
44: 			if (statement->type == StatementType::CREATE_STATEMENT) {
45: 				auto &create = (CreateStatement &)*statement;
46: 				create.info->sql = query.substr(statement->stmt_location, statement->stmt_length);
47: 			}
48: 		}
49: 	}
50: }
51: 
52: vector<SimplifiedToken> Parser::Tokenize(const string &query) {
53: 	auto pg_tokens = PostgresParser::Tokenize(query);
54: 	vector<SimplifiedToken> result;
55: 	result.reserve(pg_tokens.size());
56: 	for (auto &pg_token : pg_tokens) {
57: 		SimplifiedToken token;
58: 		switch (pg_token.type) {
59: 		case duckdb_libpgquery::PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_IDENTIFIER:
60: 			token.type = SimplifiedTokenType::SIMPLIFIED_TOKEN_IDENTIFIER;
61: 			break;
62: 		case duckdb_libpgquery::PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_NUMERIC_CONSTANT:
63: 			token.type = SimplifiedTokenType::SIMPLIFIED_TOKEN_NUMERIC_CONSTANT;
64: 			break;
65: 		case duckdb_libpgquery::PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_STRING_CONSTANT:
66: 			token.type = SimplifiedTokenType::SIMPLIFIED_TOKEN_STRING_CONSTANT;
67: 			break;
68: 		case duckdb_libpgquery::PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_OPERATOR:
69: 			token.type = SimplifiedTokenType::SIMPLIFIED_TOKEN_OPERATOR;
70: 			break;
71: 		case duckdb_libpgquery::PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_KEYWORD:
72: 			token.type = SimplifiedTokenType::SIMPLIFIED_TOKEN_KEYWORD;
73: 			break;
74: 		// comments are not supported by our tokenizer right now
75: 		case duckdb_libpgquery::PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_COMMENT: // LCOV_EXCL_START
76: 			token.type = SimplifiedTokenType::SIMPLIFIED_TOKEN_COMMENT;
77: 			break;
78: 		} // LCOV_EXCL_STOP
79: 		token.start = pg_token.start;
80: 		result.push_back(token);
81: 	}
82: 	return result;
83: }
84: 
85: bool Parser::IsKeyword(const string &text) {
86: 	return PostgresParser::IsKeyword(text);
87: }
88: 
89: vector<unique_ptr<ParsedExpression>> Parser::ParseExpressionList(const string &select_list) {
90: 	// construct a mock query prefixed with SELECT
91: 	string mock_query = "SELECT " + select_list;
92: 	// parse the query
93: 	Parser parser;
94: 	parser.ParseQuery(mock_query);
95: 	// check the statements
96: 	if (parser.statements.size() != 1 || parser.statements[0]->type != StatementType::SELECT_STATEMENT) {
97: 		throw ParserException("Expected a single SELECT statement");
98: 	}
99: 	auto &select = (SelectStatement &)*parser.statements[0];
100: 	if (select.node->type != QueryNodeType::SELECT_NODE) {
101: 		throw ParserException("Expected a single SELECT node");
102: 	}
103: 	auto &select_node = (SelectNode &)*select.node;
104: 	return move(select_node.select_list);
105: }
106: 
107: vector<OrderByNode> Parser::ParseOrderList(const string &select_list) {
108: 	// construct a mock query
109: 	string mock_query = "SELECT * FROM tbl ORDER BY " + select_list;
110: 	// parse the query
111: 	Parser parser;
112: 	parser.ParseQuery(mock_query);
113: 	// check the statements
114: 	if (parser.statements.size() != 1 || parser.statements[0]->type != StatementType::SELECT_STATEMENT) {
115: 		throw ParserException("Expected a single SELECT statement");
116: 	}
117: 	auto &select = (SelectStatement &)*parser.statements[0];
118: 	if (select.node->type != QueryNodeType::SELECT_NODE) {
119: 		throw InternalException("Expected a single SELECT node");
120: 	}
121: 	auto &select_node = (SelectNode &)*select.node;
122: 	if (select_node.modifiers.empty() || select_node.modifiers[0]->type != ResultModifierType::ORDER_MODIFIER ||
123: 	    select_node.modifiers.size() != 1) {
124: 		throw InternalException("Expected a single ORDER clause");
125: 	}
126: 	auto &order = (OrderModifier &)*select_node.modifiers[0];
127: 	return move(order.orders);
128: }
129: 
130: void Parser::ParseUpdateList(const string &update_list, vector<string> &update_columns,
131:                              vector<unique_ptr<ParsedExpression>> &expressions) {
132: 	// construct a mock query
133: 	string mock_query = "UPDATE tbl SET " + update_list;
134: 	// parse the query
135: 	Parser parser;
136: 	parser.ParseQuery(mock_query);
137: 	// check the statements
138: 	if (parser.statements.size() != 1 || parser.statements[0]->type != StatementType::UPDATE_STATEMENT) {
139: 		throw ParserException("Expected a single UPDATE statement");
140: 	}
141: 	auto &update = (UpdateStatement &)*parser.statements[0];
142: 	update_columns = move(update.columns);
143: 	expressions = move(update.expressions);
144: }
145: 
146: vector<vector<unique_ptr<ParsedExpression>>> Parser::ParseValuesList(const string &value_list) {
147: 	// construct a mock query
148: 	string mock_query = "VALUES " + value_list;
149: 	// parse the query
150: 	Parser parser;
151: 	parser.ParseQuery(mock_query);
152: 	// check the statements
153: 	if (parser.statements.size() != 1 || parser.statements[0]->type != StatementType::SELECT_STATEMENT) {
154: 		throw ParserException("Expected a single SELECT statement");
155: 	}
156: 	auto &select = (SelectStatement &)*parser.statements[0];
157: 	if (select.node->type != QueryNodeType::SELECT_NODE) {
158: 		throw ParserException("Expected a single SELECT node");
159: 	}
160: 	auto &select_node = (SelectNode &)*select.node;
161: 	if (!select_node.from_table || select_node.from_table->type != TableReferenceType::EXPRESSION_LIST) {
162: 		throw InternalException("Expected a single VALUES statement");
163: 	}
164: 	auto &values_list = (ExpressionListRef &)*select_node.from_table;
165: 	return move(values_list.values);
166: }
167: 
168: vector<ColumnDefinition> Parser::ParseColumnList(const string &column_list) {
169: 	string mock_query = "CREATE TABLE blabla (" + column_list + ")";
170: 	Parser parser;
171: 	parser.ParseQuery(mock_query);
172: 	if (parser.statements.size() != 1 || parser.statements[0]->type != StatementType::CREATE_STATEMENT) {
173: 		throw ParserException("Expected a single CREATE statement");
174: 	}
175: 	auto &create = (CreateStatement &)*parser.statements[0];
176: 	if (create.info->type != CatalogType::TABLE_ENTRY) {
177: 		throw InternalException("Expected a single CREATE TABLE statement");
178: 	}
179: 	auto &info = ((CreateTableInfo &)*create.info);
180: 	return move(info.columns);
181: }
182: 
183: } // namespace duckdb
[end of src/parser/parser.cpp]
[start of third_party/libpg_query/include/parser/parser.hpp]
1: /*-------------------------------------------------------------------------
2:  *
3:  * parser.h
4:  *		Definitions for the "raw" parser (flex and bison phases only)
5:  *
6:  * This is the external API for the raw lexing/parsing functions.
7:  *
8:  * Portions Copyright (c) 1996-2017, PostgreSQL Global Development PGGroup
9:  * Portions Copyright (c) 1994, Regents of the University of California
10:  *
11:  * src/include/parser/parser.h
12:  *
13:  *-------------------------------------------------------------------------
14:  */
15: #pragma once
16: 
17: #include "nodes/parsenodes.hpp"
18: #include "pg_simplified_token.hpp"
19: #include <vector>
20: 
21: namespace duckdb_libpgquery {
22: 
23: typedef enum PGBackslashQuoteType {
24: 	PG_BACKSLASH_QUOTE_OFF,
25: 	PG_BACKSLASH_QUOTE_ON,
26: 	PG_BACKSLASH_QUOTE_SAFE_ENCODING
27: } PGBackslashQuoteType;
28: 
29: /* Primary entry point for the raw parsing functions */
30: PGList *raw_parser(const char *str);
31: 
32: bool is_keyword(const char *str);
33: 
34: std::vector<PGSimplifiedToken> tokenize(const char *str);
35: 
36: /* Utility functions exported by gram.y (perhaps these should be elsewhere) */
37: PGList *SystemFuncName(const char *name);
38: PGTypeName *SystemTypeName(const char *name);
39: 
40: }
[end of third_party/libpg_query/include/parser/parser.hpp]
[start of third_party/libpg_query/include/pg_simplified_token.hpp]
1: #pragma once
2: 
3: #include <cstdint>
4: 
5: namespace duckdb_libpgquery {
6: 
7: enum class PGSimplifiedTokenType : uint8_t {
8: 	PG_SIMPLIFIED_TOKEN_IDENTIFIER,
9: 	PG_SIMPLIFIED_TOKEN_NUMERIC_CONSTANT,
10: 	PG_SIMPLIFIED_TOKEN_STRING_CONSTANT,
11: 	PG_SIMPLIFIED_TOKEN_OPERATOR,
12: 	PG_SIMPLIFIED_TOKEN_KEYWORD,
13: 	PG_SIMPLIFIED_TOKEN_COMMENT
14: };
15: 
16: struct PGSimplifiedToken {
17: 	PGSimplifiedTokenType type;
18: 	int32_t start;
19: };
20: 
21: }
[end of third_party/libpg_query/include/pg_simplified_token.hpp]
[start of third_party/libpg_query/include/postgres_parser.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // postgres_parser.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include <string>
12: #include <vector>
13: #include "nodes/pg_list.hpp"
14: #include "pg_simplified_token.hpp"
15: 
16: namespace duckdb {
17: class PostgresParser {
18: public:
19: 	PostgresParser();
20: 	~PostgresParser();
21: 
22: 	bool success;
23: 	duckdb_libpgquery::PGList *parse_tree;
24: 	std::string error_message;
25: 	int error_location;
26: public:
27: 	void Parse(const std::string &query);
28: 	static std::vector<duckdb_libpgquery::PGSimplifiedToken> Tokenize(const std::string &query);
29: 
30: 	static bool IsKeyword(const std::string &text);
31: };
32: }
[end of third_party/libpg_query/include/postgres_parser.hpp]
[start of third_party/libpg_query/postgres_parser.cpp]
1: #include "postgres_parser.hpp"
2: 
3: #include "pg_functions.hpp"
4: #include "parser/parser.hpp"
5: #include "common/keywords.hpp"
6: 
7: using namespace std;
8: 
9: namespace duckdb {
10: 
11: PostgresParser::PostgresParser() : success(false), parse_tree(nullptr), error_message(""), error_location(0) {}
12: 
13: void PostgresParser::Parse(const string &query) {
14: 	duckdb_libpgquery::pg_parser_init();
15:     duckdb_libpgquery::parse_result res;
16: 	pg_parser_parse(query.c_str(), &res);
17: 	success = res.success;
18: 
19: 	if (success) {
20: 		parse_tree = res.parse_tree;
21: 	} else {
22: 		error_message = string(res.error_message);
23: 		error_location = res.error_location;
24: 	}
25: }
26: 
27: vector<duckdb_libpgquery::PGSimplifiedToken> PostgresParser::Tokenize(const std::string &query) {
28: 	duckdb_libpgquery::pg_parser_init();
29: 	auto tokens = duckdb_libpgquery::tokenize(query.c_str());
30: 	duckdb_libpgquery::pg_parser_cleanup();
31: 	return tokens;
32: }
33: 
34: PostgresParser::~PostgresParser()  {
35:     duckdb_libpgquery::pg_parser_cleanup();
36: }
37: 
38: bool PostgresParser::IsKeyword(const std::string &text) {
39: 	return duckdb_libpgquery::is_keyword(text.c_str());
40: }
41: 
42: }
[end of third_party/libpg_query/postgres_parser.cpp]
[start of third_party/libpg_query/src_backend_parser_parser.cpp]
1: /*--------------------------------------------------------------------
2:  * Symbols referenced in this file:
3:  * - raw_parser
4:  * - base_yylex
5:  * - raw_parser
6:  *--------------------------------------------------------------------
7:  */
8: 
9: /*-------------------------------------------------------------------------
10:  *
11:  * parser.c
12:  *		Main entry point/driver for PostgreSQL grammar
13:  *
14:  * Note that the grammar is not allowed to perform any table access
15:  * (since we need to be able to do basic parsing even while inside an
16:  * aborted transaction).  Therefore, the data structures returned by
17:  * the grammar are "raw" parsetrees that still need to be analyzed by
18:  * analyze.c and related files.
19:  *
20:  *
21:  * Portions Copyright (c) 1996-2017, PostgreSQL Global Development PGGroup
22:  * Portions Copyright (c) 1994, Regents of the University of California
23:  *
24:  * IDENTIFICATION
25:  *	  src/backend/parser/parser.c
26:  *
27:  *-------------------------------------------------------------------------
28:  */
29: 
30: #include "pg_functions.hpp"
31: 
32: #include "parser/gramparse.hpp"
33: #include "parser/parser.hpp"
34: #include "parser/kwlist.hpp"
35: 
36: namespace duckdb_libpgquery {
37: 
38: /*
39:  * raw_parser
40:  *		Given a query in string form, do lexical and grammatical analysis.
41:  *
42:  * Returns a list of raw (un-analyzed) parse trees.  The immediate elements
43:  * of the list are always PGRawStmt nodes.
44:  */
45: PGList *raw_parser(const char *str) {
46: 	core_yyscan_t yyscanner;
47: 	base_yy_extra_type yyextra;
48: 	int yyresult;
49: 
50: 	/* initialize the flex scanner */
51: 	yyscanner = scanner_init(str, &yyextra.core_yy_extra, ScanKeywords, NumScanKeywords);
52: 
53: 	/* base_yylex() only needs this much initialization */
54: 	yyextra.have_lookahead = false;
55: 
56: 	/* initialize the bison parser */
57: 	parser_init(&yyextra);
58: 
59: 	/* Parse! */
60: 	yyresult = base_yyparse(yyscanner);
61: 
62: 	/* Clean up (release memory) */
63: 	scanner_finish(yyscanner);
64: 
65: 	if (yyresult) /* error */
66: 		return NIL;
67: 
68: 	return yyextra.parsetree;
69: }
70: 
71: bool is_keyword(const char *text) {
72: 	return ScanKeywordLookup(text, ScanKeywords, NumScanKeywords) != NULL;
73: }
74: 
75: std::vector<PGSimplifiedToken> tokenize(const char *str) {
76: 	core_yyscan_t yyscanner;
77: 	base_yy_extra_type yyextra;
78: 
79: 	std::vector<PGSimplifiedToken> result;
80: 	yyscanner = scanner_init(str, &yyextra.core_yy_extra, ScanKeywords, NumScanKeywords);
81: 	yyextra.have_lookahead = false;
82: 
83: 	while(true) {
84: 		YYSTYPE type;
85: 		YYLTYPE loc;
86: 		int token;
87: 		try {
88: 			token = base_yylex(&type, &loc, yyscanner);
89: 		} catch(...) {
90: 			token = 0;
91: 		}
92: 		if (token == 0) {
93: 			break;
94: 		}
95: 		PGSimplifiedToken current_token;
96: 		switch(token) {
97: 		case IDENT:
98: 			current_token.type = PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_IDENTIFIER;
99: 			break;
100: 		case ICONST:
101: 		case FCONST:
102: 			current_token.type = PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_NUMERIC_CONSTANT;
103: 			break;
104: 		case SCONST:
105: 		case BCONST:
106: 		case XCONST:
107: 			current_token.type = PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_STRING_CONSTANT;
108: 			break;
109: 		case Op:
110: 		case PARAM:
111: 		case COLON_EQUALS:
112: 		case EQUALS_GREATER:
113: 		case LESS_EQUALS:
114: 		case GREATER_EQUALS:
115: 		case NOT_EQUALS:
116: 			current_token.type = PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_OPERATOR;
117: 			break;
118: 		default:
119: 			if (token >= 255) {
120: 				// non-ascii value, probably a keyword
121: 				current_token.type = PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_KEYWORD;
122: 			} else {
123: 				// ascii value, probably an operator
124: 				current_token.type = PGSimplifiedTokenType::PG_SIMPLIFIED_TOKEN_OPERATOR;
125: 			}
126: 			break;
127: 		}
128: 		current_token.start = loc;
129: 		result.push_back(current_token);
130: 	}
131: 
132: 	scanner_finish(yyscanner);
133: 	return result;
134: }
135: 
136: 
137: 
138: /*
139:  * Intermediate filter between parser and core lexer (core_yylex in scan.l).
140:  *
141:  * This filter is needed because in some cases the standard SQL grammar
142:  * requires more than one token lookahead.  We reduce these cases to one-token
143:  * lookahead by replacing tokens here, in order to keep the grammar LALR(1).
144:  *
145:  * Using a filter is simpler than trying to recognize multiword tokens
146:  * directly in scan.l, because we'd have to allow for comments between the
147:  * words.  Furthermore it's not clear how to do that without re-introducing
148:  * scanner backtrack, which would cost more performance than this filter
149:  * layer does.
150:  *
151:  * The filter also provides a convenient place to translate between
152:  * the core_YYSTYPE and YYSTYPE representations (which are really the
153:  * same thing anyway, but notationally they're different).
154:  */
155: int base_yylex(YYSTYPE *lvalp, YYLTYPE *llocp, core_yyscan_t yyscanner) {
156: 	base_yy_extra_type *yyextra = pg_yyget_extra(yyscanner);
157: 	int cur_token;
158: 	int next_token;
159: 	int cur_token_length;
160: 	YYLTYPE cur_yylloc;
161: 
162: 	/* Get next token --- we might already have it */
163: 	if (yyextra->have_lookahead) {
164: 		cur_token = yyextra->lookahead_token;
165: 		lvalp->core_yystype = yyextra->lookahead_yylval;
166: 		*llocp = yyextra->lookahead_yylloc;
167: 		*(yyextra->lookahead_end) = yyextra->lookahead_hold_char;
168: 		yyextra->have_lookahead = false;
169: 	} else
170: 		cur_token = core_yylex(&(lvalp->core_yystype), llocp, yyscanner);
171: 
172: 	/*
173: 	 * If this token isn't one that requires lookahead, just return it.  If it
174: 	 * does, determine the token length.  (We could get that via strlen(), but
175: 	 * since we have such a small set of possibilities, hardwiring seems
176: 	 * feasible and more efficient.)
177: 	 */
178: 	switch (cur_token) {
179: 	case NOT:
180: 		cur_token_length = 3;
181: 		break;
182: 	case NULLS_P:
183: 		cur_token_length = 5;
184: 		break;
185: 	case WITH:
186: 		cur_token_length = 4;
187: 		break;
188: 	default:
189: 		return cur_token;
190: 	}
191: 
192: 	/*
193: 	 * Identify end+1 of current token.  core_yylex() has temporarily stored a
194: 	 * '\0' here, and will undo that when we call it again.  We need to redo
195: 	 * it to fully revert the lookahead call for error reporting purposes.
196: 	 */
197: 	yyextra->lookahead_end = yyextra->core_yy_extra.scanbuf + *llocp + cur_token_length;
198: 	Assert(*(yyextra->lookahead_end) == '\0');
199: 
200: 	/*
201: 	 * Save and restore *llocp around the call.  It might look like we could
202: 	 * avoid this by just passing &lookahead_yylloc to core_yylex(), but that
203: 	 * does not work because flex actually holds onto the last-passed pointer
204: 	 * internally, and will use that for error reporting.  We need any error
205: 	 * reports to point to the current token, not the next one.
206: 	 */
207: 	cur_yylloc = *llocp;
208: 
209: 	/* Get next token, saving outputs into lookahead variables */
210: 	next_token = core_yylex(&(yyextra->lookahead_yylval), llocp, yyscanner);
211: 	yyextra->lookahead_token = next_token;
212: 	yyextra->lookahead_yylloc = *llocp;
213: 
214: 	*llocp = cur_yylloc;
215: 
216: 	/* Now revert the un-truncation of the current token */
217: 	yyextra->lookahead_hold_char = *(yyextra->lookahead_end);
218: 	*(yyextra->lookahead_end) = '\0';
219: 
220: 	yyextra->have_lookahead = true;
221: 
222: 	/* Replace cur_token if needed, based on lookahead */
223: 	switch (cur_token) {
224: 	case NOT:
225: 		/* Replace NOT by NOT_LA if it's followed by BETWEEN, IN, etc */
226: 		switch (next_token) {
227: 		case BETWEEN:
228: 		case IN_P:
229: 		case LIKE:
230: 		case ILIKE:
231: 		case SIMILAR:
232: 			cur_token = NOT_LA;
233: 			break;
234: 		}
235: 		break;
236: 
237: 	case NULLS_P:
238: 		/* Replace NULLS_P by NULLS_LA if it's followed by FIRST or LAST */
239: 		switch (next_token) {
240: 		case FIRST_P:
241: 		case LAST_P:
242: 			cur_token = NULLS_LA;
243: 			break;
244: 		}
245: 		break;
246: 
247: 	case WITH:
248: 		/* Replace WITH by WITH_LA if it's followed by TIME or ORDINALITY */
249: 		switch (next_token) {
250: 		case TIME:
251: 		case ORDINALITY:
252: 			cur_token = WITH_LA;
253: 			break;
254: 		}
255: 		break;
256: 	}
257: 
258: 	return cur_token;
259: }
260: 
261: }
[end of third_party/libpg_query/src_backend_parser_parser.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: