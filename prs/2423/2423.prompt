You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
Segmentation fault on macro creation
**What does happen?**
Creating the following macro causes a segmentation fault:
```sql
create macro extract_field(my_struct, my_field) as my_struct[my_field];
```

This is equivalent, and also results in a segmentation fault:
```sql
create macro extract_field(my_struct, my_field) as array_extract(my_struct, my_field);
```

**What should happen?**
The macro should be created succesfully.

**To Reproduce**
Steps to reproduce the behavior. Bonus points if those are only SQL queries.
1. Run one of the queries as shown above

**Environment (please complete the following information):**
 - OS: macOS Big Sur
 - DuckDB Version 3.0 (latest master branch)

**Before submitting**
- [x] Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?
- [x] Have you tried this on the latest `master` branch? In case you cannot compile, you may find some binaries here: https://github.com/duckdb/duckdb/releases/tag/master-builds

Segmentation fault on macro creation
**What does happen?**
Creating the following macro causes a segmentation fault:
```sql
create macro extract_field(my_struct, my_field) as my_struct[my_field];
```

This is equivalent, and also results in a segmentation fault:
```sql
create macro extract_field(my_struct, my_field) as array_extract(my_struct, my_field);
```

**What should happen?**
The macro should be created succesfully.

**To Reproduce**
Steps to reproduce the behavior. Bonus points if those are only SQL queries.
1. Run one of the queries as shown above

**Environment (please complete the following information):**
 - OS: macOS Big Sur
 - DuckDB Version 3.0 (latest master branch)

**Before submitting**
- [x] Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?
- [x] Have you tried this on the latest `master` branch? In case you cannot compile, you may find some binaries here: https://github.com/duckdb/duckdb/releases/tag/master-builds


</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16: </p>
17: 
18: ## DuckDB
19: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/docs/why_duckdb.html).
20: 
21: ## Installation
22: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
23: 
24: ## Data Import
25: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
26: 
27: ```sql
28: SELECT * FROM 'myfile.csv';
29: SELECT * FROM 'myfile.parquet';
30: ```
31: 
32: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
33: 
34: ## SQL Reference
35: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
36: 
37: ## Development
38: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
39: 
40: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
41: 
42: 
[end of README.md]
[start of src/function/function.cpp]
1: #include "duckdb/function/function.hpp"
2: 
3: #include "duckdb/catalog/catalog.hpp"
4: #include "duckdb/catalog/catalog_entry/scalar_function_catalog_entry.hpp"
5: #include "duckdb/common/types/hash.hpp"
6: #include "duckdb/common/limits.hpp"
7: #include "duckdb/common/string_util.hpp"
8: #include "duckdb/function/aggregate_function.hpp"
9: #include "duckdb/function/cast_rules.hpp"
10: #include "duckdb/function/scalar/string_functions.hpp"
11: #include "duckdb/function/scalar_function.hpp"
12: #include "duckdb/parser/parsed_data/create_aggregate_function_info.hpp"
13: #include "duckdb/parser/parsed_data/create_collation_info.hpp"
14: #include "duckdb/parser/parsed_data/create_copy_function_info.hpp"
15: #include "duckdb/parser/parsed_data/create_pragma_function_info.hpp"
16: #include "duckdb/parser/parsed_data/create_scalar_function_info.hpp"
17: #include "duckdb/parser/parsed_data/create_table_function_info.hpp"
18: #include "duckdb/parser/parsed_data/pragma_info.hpp"
19: #include "duckdb/planner/expression/bound_aggregate_expression.hpp"
20: #include "duckdb/planner/expression/bound_cast_expression.hpp"
21: #include "duckdb/planner/expression/bound_function_expression.hpp"
22: 
23: namespace duckdb {
24: 
25: // add your initializer for new functions here
26: void BuiltinFunctions::Initialize() {
27: 	RegisterSQLiteFunctions();
28: 	RegisterReadFunctions();
29: 	RegisterTableFunctions();
30: 	RegisterArrowFunctions();
31: 
32: 	RegisterAlgebraicAggregates();
33: 	RegisterDistributiveAggregates();
34: 	RegisterNestedAggregates();
35: 	RegisterHolisticAggregates();
36: 	RegisterRegressiveAggregates();
37: 
38: 	RegisterDateFunctions();
39: 	RegisterGenericFunctions();
40: 	RegisterMathFunctions();
41: 	RegisterOperators();
42: 	RegisterSequenceFunctions();
43: 	RegisterStringFunctions();
44: 	RegisterNestedFunctions();
45: 	RegisterTrigonometricsFunctions();
46: 
47: 	RegisterPragmaFunctions();
48: 
49: 	// initialize collations
50: 	AddCollation("nocase", LowerFun::GetFunction(), true);
51: 	AddCollation("noaccent", StripAccentsFun::GetFunction());
52: 	AddCollation("nfc", NFCNormalizeFun::GetFunction());
53: }
54: 
55: BuiltinFunctions::BuiltinFunctions(ClientContext &context, Catalog &catalog) : context(context), catalog(catalog) {
56: }
57: 
58: void BuiltinFunctions::AddCollation(string name, ScalarFunction function, bool combinable,
59:                                     bool not_required_for_equality) {
60: 	CreateCollationInfo info(move(name), move(function), combinable, not_required_for_equality);
61: 	catalog.CreateCollation(context, &info);
62: }
63: 
64: void BuiltinFunctions::AddFunction(AggregateFunctionSet set) {
65: 	CreateAggregateFunctionInfo info(move(set));
66: 	catalog.CreateFunction(context, &info);
67: }
68: 
69: void BuiltinFunctions::AddFunction(AggregateFunction function) {
70: 	CreateAggregateFunctionInfo info(move(function));
71: 	catalog.CreateFunction(context, &info);
72: }
73: 
74: void BuiltinFunctions::AddFunction(PragmaFunction function) {
75: 	CreatePragmaFunctionInfo info(move(function));
76: 	catalog.CreatePragmaFunction(context, &info);
77: }
78: 
79: void BuiltinFunctions::AddFunction(const string &name, vector<PragmaFunction> functions) {
80: 	CreatePragmaFunctionInfo info(name, move(functions));
81: 	catalog.CreatePragmaFunction(context, &info);
82: }
83: 
84: void BuiltinFunctions::AddFunction(ScalarFunction function) {
85: 	CreateScalarFunctionInfo info(move(function));
86: 	catalog.CreateFunction(context, &info);
87: }
88: 
89: void BuiltinFunctions::AddFunction(const vector<string> &names, ScalarFunction function) { // NOLINT: false positive
90: 	for (auto &name : names) {
91: 		function.name = name;
92: 		AddFunction(function);
93: 	}
94: }
95: 
96: void BuiltinFunctions::AddFunction(ScalarFunctionSet set) {
97: 	CreateScalarFunctionInfo info(move(set));
98: 	catalog.CreateFunction(context, &info);
99: }
100: 
101: void BuiltinFunctions::AddFunction(TableFunction function) {
102: 	CreateTableFunctionInfo info(move(function));
103: 	catalog.CreateTableFunction(context, &info);
104: }
105: 
106: void BuiltinFunctions::AddFunction(TableFunctionSet set) {
107: 	CreateTableFunctionInfo info(move(set));
108: 	catalog.CreateTableFunction(context, &info);
109: }
110: 
111: void BuiltinFunctions::AddFunction(CopyFunction function) {
112: 	CreateCopyFunctionInfo info(move(function));
113: 	catalog.CreateCopyFunction(context, &info);
114: }
115: 
116: hash_t BaseScalarFunction::Hash() const {
117: 	hash_t hash = return_type.Hash();
118: 	for (auto &arg : arguments) {
119: 		duckdb::CombineHash(hash, arg.Hash());
120: 	}
121: 	return hash;
122: }
123: 
124: string Function::CallToString(const string &name, const vector<LogicalType> &arguments) {
125: 	string result = name + "(";
126: 	result += StringUtil::Join(arguments, arguments.size(), ", ",
127: 	                           [](const LogicalType &argument) { return argument.ToString(); });
128: 	return result + ")";
129: }
130: 
131: string Function::CallToString(const string &name, const vector<LogicalType> &arguments,
132:                               const LogicalType &return_type) {
133: 	string result = CallToString(name, arguments);
134: 	result += " -> " + return_type.ToString();
135: 	return result;
136: }
137: 
138: string Function::CallToString(const string &name, const vector<LogicalType> &arguments,
139:                               const unordered_map<string, LogicalType> &named_parameters) {
140: 	vector<string> input_arguments;
141: 	input_arguments.reserve(arguments.size() + named_parameters.size());
142: 	for (auto &arg : arguments) {
143: 		input_arguments.push_back(arg.ToString());
144: 	}
145: 	for (auto &kv : named_parameters) {
146: 		input_arguments.push_back(StringUtil::Format("%s : %s", kv.first, kv.second.ToString()));
147: 	}
148: 	return StringUtil::Format("%s(%s)", name, StringUtil::Join(input_arguments, ", "));
149: }
150: 
151: static int64_t BindVarArgsFunctionCost(SimpleFunction &func, vector<LogicalType> &arguments) {
152: 	if (arguments.size() < func.arguments.size()) {
153: 		// not enough arguments to fulfill the non-vararg part of the function
154: 		return -1;
155: 	}
156: 	int64_t cost = 0;
157: 	for (idx_t i = 0; i < arguments.size(); i++) {
158: 		LogicalType arg_type = i < func.arguments.size() ? func.arguments[i] : func.varargs;
159: 		if (arguments[i] == arg_type) {
160: 			// arguments match: do nothing
161: 			continue;
162: 		}
163: 		int64_t cast_cost = CastRules::ImplicitCast(arguments[i], arg_type);
164: 		if (cast_cost >= 0) {
165: 			// we can implicitly cast, add the cost to the total cost
166: 			cost += cast_cost;
167: 		} else {
168: 			// we can't implicitly cast: throw an error
169: 			return -1;
170: 		}
171: 	}
172: 	return cost;
173: }
174: 
175: static int64_t BindFunctionCost(SimpleFunction &func, vector<LogicalType> &arguments) {
176: 	if (func.HasVarArgs()) {
177: 		// special case varargs function
178: 		return BindVarArgsFunctionCost(func, arguments);
179: 	}
180: 	if (func.arguments.size() != arguments.size()) {
181: 		// invalid argument count: check the next function
182: 		return -1;
183: 	}
184: 	int64_t cost = 0;
185: 	for (idx_t i = 0; i < arguments.size(); i++) {
186: 		if (arguments[i].id() == func.arguments[i].id()) {
187: 			// arguments match: do nothing
188: 			continue;
189: 		}
190: 		int64_t cast_cost = CastRules::ImplicitCast(arguments[i], func.arguments[i]);
191: 		if (cast_cost >= 0) {
192: 			// we can implicitly cast, add the cost to the total cost
193: 			cost += cast_cost;
194: 		} else {
195: 			// we can't implicitly cast: throw an error
196: 			return -1;
197: 		}
198: 	}
199: 	return cost;
200: }
201: 
202: template <class T>
203: static idx_t BindFunctionFromArguments(const string &name, vector<T> &functions, vector<LogicalType> &arguments,
204:                                        string &error) {
205: 	idx_t best_function = INVALID_INDEX;
206: 	int64_t lowest_cost = NumericLimits<int64_t>::Maximum();
207: 	vector<idx_t> conflicting_functions;
208: 	for (idx_t f_idx = 0; f_idx < functions.size(); f_idx++) {
209: 		auto &func = functions[f_idx];
210: 		// check the arguments of the function
211: 		int64_t cost = BindFunctionCost(func, arguments);
212: 		if (cost < 0) {
213: 			// auto casting was not possible
214: 			continue;
215: 		}
216: 		if (cost == lowest_cost) {
217: 			conflicting_functions.push_back(f_idx);
218: 			continue;
219: 		}
220: 		if (cost > lowest_cost) {
221: 			continue;
222: 		}
223: 		conflicting_functions.clear();
224: 		lowest_cost = cost;
225: 		best_function = f_idx;
226: 	}
227: 	if (!conflicting_functions.empty()) {
228: 		// there are multiple possible function definitions
229: 		// throw an exception explaining which overloads are there
230: 		conflicting_functions.push_back(best_function);
231: 		string call_str = Function::CallToString(name, arguments);
232: 		string candidate_str = "";
233: 		for (auto &conf : conflicting_functions) {
234: 			auto &f = functions[conf];
235: 			candidate_str += "\t" + f.ToString() + "\n";
236: 		}
237: 		error =
238: 		    StringUtil::Format("Could not choose a best candidate function for the function call \"%s\". In order to "
239: 		                       "select one, please add explicit type casts.\n\tCandidate functions:\n%s",
240: 		                       call_str, candidate_str);
241: 		return INVALID_INDEX;
242: 	}
243: 	if (best_function == INVALID_INDEX) {
244: 		// no matching function was found, throw an error
245: 		string call_str = Function::CallToString(name, arguments);
246: 		string candidate_str = "";
247: 		for (auto &f : functions) {
248: 			candidate_str += "\t" + f.ToString() + "\n";
249: 		}
250: 		error = StringUtil::Format("No function matches the given name and argument types '%s'. You might need to add "
251: 		                           "explicit type casts.\n\tCandidate functions:\n%s",
252: 		                           call_str, candidate_str);
253: 		return INVALID_INDEX;
254: 	}
255: 	return best_function;
256: }
257: 
258: idx_t Function::BindFunction(const string &name, vector<ScalarFunction> &functions, vector<LogicalType> &arguments,
259:                              string &error) {
260: 	return BindFunctionFromArguments(name, functions, arguments, error);
261: }
262: 
263: idx_t Function::BindFunction(const string &name, vector<AggregateFunction> &functions, vector<LogicalType> &arguments,
264:                              string &error) {
265: 	return BindFunctionFromArguments(name, functions, arguments, error);
266: }
267: 
268: idx_t Function::BindFunction(const string &name, vector<TableFunction> &functions, vector<LogicalType> &arguments,
269:                              string &error) {
270: 	return BindFunctionFromArguments(name, functions, arguments, error);
271: }
272: 
273: idx_t Function::BindFunction(const string &name, vector<PragmaFunction> &functions, PragmaInfo &info, string &error) {
274: 	vector<LogicalType> types;
275: 	for (auto &value : info.parameters) {
276: 		types.push_back(value.type());
277: 	}
278: 	idx_t entry = BindFunctionFromArguments(name, functions, types, error);
279: 	if (entry == INVALID_INDEX) {
280: 		throw BinderException(error);
281: 	}
282: 	auto &candidate_function = functions[entry];
283: 	// cast the input parameters
284: 	for (idx_t i = 0; i < info.parameters.size(); i++) {
285: 		auto target_type =
286: 		    i < candidate_function.arguments.size() ? candidate_function.arguments[i] : candidate_function.varargs;
287: 		info.parameters[i] = info.parameters[i].CastAs(target_type);
288: 	}
289: 	return entry;
290: }
291: 
292: vector<LogicalType> GetLogicalTypesFromExpressions(vector<unique_ptr<Expression>> &arguments) {
293: 	vector<LogicalType> types;
294: 	types.reserve(arguments.size());
295: 	for (auto &argument : arguments) {
296: 		types.push_back(argument->return_type);
297: 	}
298: 	return types;
299: }
300: 
301: idx_t Function::BindFunction(const string &name, vector<ScalarFunction> &functions,
302:                              vector<unique_ptr<Expression>> &arguments, string &error) {
303: 	auto types = GetLogicalTypesFromExpressions(arguments);
304: 	return Function::BindFunction(name, functions, types, error);
305: }
306: 
307: idx_t Function::BindFunction(const string &name, vector<AggregateFunction> &functions,
308:                              vector<unique_ptr<Expression>> &arguments, string &error) {
309: 	auto types = GetLogicalTypesFromExpressions(arguments);
310: 	return Function::BindFunction(name, functions, types, error);
311: }
312: 
313: idx_t Function::BindFunction(const string &name, vector<TableFunction> &functions,
314:                              vector<unique_ptr<Expression>> &arguments, string &error) {
315: 	auto types = GetLogicalTypesFromExpressions(arguments);
316: 	return Function::BindFunction(name, functions, types, error);
317: }
318: 
319: void BaseScalarFunction::CastToFunctionArguments(vector<unique_ptr<Expression>> &children) {
320: 	for (idx_t i = 0; i < children.size(); i++) {
321: 		auto target_type = i < this->arguments.size() ? this->arguments[i] : this->varargs;
322: 		target_type.Verify();
323: 		// check if the type of child matches the type of function argument
324: 		// if not we need to add a cast
325: 		bool require_cast = children[i]->return_type != target_type;
326: 		// except for one special case: if the function accepts ANY argument
327: 		// in that case we don't add a cast
328: 		if (target_type.id() == LogicalTypeId::ANY) {
329: 			if (children[i]->return_type.id() == LogicalTypeId::UNKNOWN) {
330: 				// UNLESS the child is a prepared statement parameter
331: 				// in that case we default the prepared statement parameter to VARCHAR
332: 				target_type = LogicalType::VARCHAR;
333: 			} else {
334: 				require_cast = false;
335: 			}
336: 		}
337: 		if (require_cast) {
338: 			children[i] = BoundCastExpression::AddCastToType(move(children[i]), target_type);
339: 		}
340: 	}
341: }
342: 
343: unique_ptr<BoundFunctionExpression> ScalarFunction::BindScalarFunction(ClientContext &context, const string &schema,
344:                                                                        const string &name,
345:                                                                        vector<unique_ptr<Expression>> children,
346:                                                                        string &error, bool is_operator) {
347: 	// bind the function
348: 	auto function = Catalog::GetCatalog(context).GetEntry(context, CatalogType::SCALAR_FUNCTION_ENTRY, schema, name);
349: 	D_ASSERT(function && function->type == CatalogType::SCALAR_FUNCTION_ENTRY);
350: 	return ScalarFunction::BindScalarFunction(context, (ScalarFunctionCatalogEntry &)*function, move(children), error,
351: 	                                          is_operator);
352: }
353: 
354: unique_ptr<BoundFunctionExpression> ScalarFunction::BindScalarFunction(ClientContext &context,
355:                                                                        ScalarFunctionCatalogEntry &func,
356:                                                                        vector<unique_ptr<Expression>> children,
357:                                                                        string &error, bool is_operator) {
358: 	// bind the function
359: 	idx_t best_function = Function::BindFunction(func.name, func.functions, children, error);
360: 	if (best_function == INVALID_INDEX) {
361: 		return nullptr;
362: 	}
363: 	// found a matching function!
364: 	auto &bound_function = func.functions[best_function];
365: 	return ScalarFunction::BindScalarFunction(context, bound_function, move(children), is_operator);
366: }
367: 
368: unique_ptr<BoundFunctionExpression> ScalarFunction::BindScalarFunction(ClientContext &context,
369:                                                                        ScalarFunction bound_function,
370:                                                                        vector<unique_ptr<Expression>> children,
371:                                                                        bool is_operator) {
372: 	unique_ptr<FunctionData> bind_info;
373: 	if (bound_function.bind) {
374: 		bind_info = bound_function.bind(context, bound_function, children);
375: 	}
376: 	// check if we need to add casts to the children
377: 	bound_function.CastToFunctionArguments(children);
378: 
379: 	// now create the function
380: 	auto return_type = bound_function.return_type;
381: 	return make_unique<BoundFunctionExpression>(move(return_type), move(bound_function), move(children),
382: 	                                            move(bind_info), is_operator);
383: }
384: 
385: unique_ptr<BoundAggregateExpression>
386: AggregateFunction::BindAggregateFunction(ClientContext &context, AggregateFunction bound_function,
387:                                          vector<unique_ptr<Expression>> children, unique_ptr<Expression> filter,
388:                                          bool is_distinct, unique_ptr<BoundOrderModifier> order_bys) {
389: 	unique_ptr<FunctionData> bind_info;
390: 	if (bound_function.bind) {
391: 		bind_info = bound_function.bind(context, bound_function, children);
392: 		// we may have lost some arguments in the bind
393: 		children.resize(MinValue(bound_function.arguments.size(), children.size()));
394: 	}
395: 
396: 	// check if we need to add casts to the children
397: 	bound_function.CastToFunctionArguments(children);
398: 
399: 	// Special case: for ORDER BY aggregates, we wrap the aggregate function in a SortedAggregateFunction
400: 	// The children are the sort clauses and the binding contains the ordering data.
401: 	if (order_bys && !order_bys->orders.empty()) {
402: 		bind_info = BindSortedAggregate(bound_function, children, move(bind_info), move(order_bys));
403: 	}
404: 
405: 	return make_unique<BoundAggregateExpression>(move(bound_function), move(children), move(filter), move(bind_info),
406: 	                                             is_distinct);
407: }
408: 
409: } // namespace duckdb
[end of src/function/function.cpp]
[start of src/function/scalar/list/list_extract.cpp]
1: #include "duckdb/planner/expression/bound_function_expression.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/common/vector_operations/binary_executor.hpp"
4: #include "duckdb/parser/expression/bound_expression.hpp"
5: #include "duckdb/function/scalar/nested_functions.hpp"
6: #include "duckdb/function/scalar/string_functions.hpp"
7: #include "duckdb/common/types/chunk_collection.hpp"
8: #include "duckdb/common/types/data_chunk.hpp"
9: #include "duckdb/common/pair.hpp"
10: #include "duckdb/storage/statistics/list_statistics.hpp"
11: #include "duckdb/storage/statistics/validity_statistics.hpp"
12: 
13: namespace duckdb {
14: 
15: template <class T, bool HEAP_REF = false, bool VALIDITY_ONLY = false>
16: void ListExtractTemplate(idx_t count, VectorData &list_data, VectorData &offsets_data, Vector &child_vector,
17:                          idx_t list_size, Vector &result) {
18: 	VectorData child_data;
19: 	child_vector.Orrify(list_size, child_data);
20: 
21: 	T *result_data;
22: 
23: 	result.SetVectorType(VectorType::FLAT_VECTOR);
24: 	if (!VALIDITY_ONLY) {
25: 		result_data = FlatVector::GetData<T>(result);
26: 	}
27: 	auto &result_mask = FlatVector::Validity(result);
28: 
29: 	// heap-ref once
30: 	if (HEAP_REF) {
31: 		StringVector::AddHeapReference(result, child_vector);
32: 	}
33: 
34: 	// this is lifted from ExecuteGenericLoop because we can't push the list child data into this otherwise
35: 	// should have gone with GetValue perhaps
36: 	for (idx_t i = 0; i < count; i++) {
37: 		auto list_index = list_data.sel->get_index(i);
38: 		auto offsets_index = offsets_data.sel->get_index(i);
39: 		if (list_data.validity.RowIsValid(list_index) && offsets_data.validity.RowIsValid(offsets_index)) {
40: 			auto list_entry = ((list_entry_t *)list_data.data)[list_index];
41: 			auto offsets_entry = ((int64_t *)offsets_data.data)[offsets_index];
42: 			idx_t child_offset;
43: 			if (offsets_entry < 0) {
44: 				if ((idx_t)-offsets_entry > list_entry.length) {
45: 					result_mask.SetInvalid(i);
46: 					continue;
47: 				}
48: 				child_offset = list_entry.offset + list_entry.length + offsets_entry;
49: 			} else {
50: 				if ((idx_t)offsets_entry >= list_entry.length) {
51: 					result_mask.SetInvalid(i);
52: 					continue;
53: 				}
54: 				child_offset = list_entry.offset + offsets_entry;
55: 			}
56: 			if (child_data.validity.RowIsValid(child_offset)) {
57: 				if (!VALIDITY_ONLY) {
58: 					result_data[i] = ((T *)child_data.data)[child_offset];
59: 				}
60: 			} else {
61: 				result_mask.SetInvalid(i);
62: 			}
63: 		} else {
64: 			result_mask.SetInvalid(i);
65: 		}
66: 	}
67: 	if (count == 1) {
68: 		result.SetVectorType(VectorType::CONSTANT_VECTOR);
69: 	}
70: }
71: static void ExecuteListExtractInternal(const idx_t count, VectorData &list, VectorData &offsets, Vector &child_vector,
72:                                        idx_t list_size, Vector &result) {
73: 	D_ASSERT(child_vector.GetType() == result.GetType());
74: 	switch (result.GetType().id()) {
75: 	case LogicalTypeId::UTINYINT:
76: 		ListExtractTemplate<uint8_t>(count, list, offsets, child_vector, list_size, result);
77: 		break;
78: 	case LogicalTypeId::TINYINT:
79: 		ListExtractTemplate<int8_t>(count, list, offsets, child_vector, list_size, result);
80: 		break;
81: 	case LogicalTypeId::USMALLINT:
82: 		ListExtractTemplate<uint16_t>(count, list, offsets, child_vector, list_size, result);
83: 		break;
84: 	case LogicalTypeId::SMALLINT:
85: 		ListExtractTemplate<int16_t>(count, list, offsets, child_vector, list_size, result);
86: 		break;
87: 	case LogicalTypeId::UINTEGER:
88: 		ListExtractTemplate<uint32_t>(count, list, offsets, child_vector, list_size, result);
89: 		break;
90: 	case LogicalTypeId::INTEGER:
91: 		ListExtractTemplate<int32_t>(count, list, offsets, child_vector, list_size, result);
92: 		break;
93: 	case LogicalTypeId::UBIGINT:
94: 		ListExtractTemplate<uint64_t>(count, list, offsets, child_vector, list_size, result);
95: 		break;
96: 	case LogicalTypeId::BIGINT:
97: 		ListExtractTemplate<int64_t>(count, list, offsets, child_vector, list_size, result);
98: 		break;
99: 	case LogicalTypeId::HUGEINT:
100: 		ListExtractTemplate<hugeint_t>(count, list, offsets, child_vector, list_size, result);
101: 		break;
102: 	case LogicalTypeId::FLOAT:
103: 		ListExtractTemplate<float>(count, list, offsets, child_vector, list_size, result);
104: 		break;
105: 	case LogicalTypeId::DOUBLE:
106: 		ListExtractTemplate<double>(count, list, offsets, child_vector, list_size, result);
107: 		break;
108: 	case LogicalTypeId::DATE:
109: 		ListExtractTemplate<date_t>(count, list, offsets, child_vector, list_size, result);
110: 		break;
111: 	case LogicalTypeId::TIME:
112: 		ListExtractTemplate<dtime_t>(count, list, offsets, child_vector, list_size, result);
113: 		break;
114: 	case LogicalTypeId::TIMESTAMP:
115: 		ListExtractTemplate<timestamp_t>(count, list, offsets, child_vector, list_size, result);
116: 		break;
117: 	case LogicalTypeId::BLOB:
118: 	case LogicalTypeId::VARCHAR:
119: 		ListExtractTemplate<string_t, true>(count, list, offsets, child_vector, list_size, result);
120: 		break;
121: 	case LogicalTypeId::SQLNULL:
122: 		result.Reference(Value());
123: 		break;
124: 	case LogicalTypeId::STRUCT: {
125: 		auto &entries = StructVector::GetEntries(child_vector);
126: 		auto &result_entries = StructVector::GetEntries(result);
127: 		D_ASSERT(entries.size() == result_entries.size());
128: 		// extract the child entries of the struct
129: 		for (idx_t i = 0; i < entries.size(); i++) {
130: 			ExecuteListExtractInternal(count, list, offsets, *entries[i], list_size, *result_entries[i]);
131: 		}
132: 		// extract the validity mask
133: 		ListExtractTemplate<bool, false, true>(count, list, offsets, child_vector, list_size, result);
134: 		break;
135: 	}
136: 	case LogicalTypeId::LIST: {
137: 		// nested list: we have to reference the child
138: 		auto &child_child_list = ListVector::GetEntry(child_vector);
139: 
140: 		ListVector::GetEntry(result).Reference(child_child_list);
141: 		ListVector::SetListSize(result, ListVector::GetListSize(child_vector));
142: 		ListExtractTemplate<list_entry_t>(count, list, offsets, child_vector, list_size, result);
143: 		break;
144: 	}
145: 	default:
146: 		throw NotImplementedException("Unimplemented type for LIST_EXTRACT");
147: 	}
148: }
149: 
150: static void ExecuteListExtract(Vector &result, Vector &list, Vector &offsets, const idx_t count) {
151: 	D_ASSERT(list.GetType().id() == LogicalTypeId::LIST);
152: 	VectorData list_data;
153: 	VectorData offsets_data;
154: 
155: 	list.Orrify(count, list_data);
156: 	offsets.Orrify(count, offsets_data);
157: 	ExecuteListExtractInternal(count, list_data, offsets_data, ListVector::GetEntry(list),
158: 	                           ListVector::GetListSize(list), result);
159: 	result.Verify(count);
160: }
161: 
162: static void ExecuteStringExtract(Vector &result, Vector &input_vector, Vector &subscript_vector, const idx_t count) {
163: 	BinaryExecutor::Execute<string_t, int32_t, string_t>(
164: 	    input_vector, subscript_vector, result, count, [&](string_t input_string, int32_t subscript) {
165: 		    return SubstringFun::SubstringScalarFunction(result, input_string, subscript + int32_t(subscript >= 0), 1);
166: 	    });
167: }
168: 
169: static void ListExtractFunction(DataChunk &args, ExpressionState &state, Vector &result) {
170: 	D_ASSERT(args.ColumnCount() == 2);
171: 	auto count = args.size();
172: 
173: 	result.SetVectorType(VectorType::CONSTANT_VECTOR);
174: 	for (idx_t i = 0; i < args.ColumnCount(); i++) {
175: 		if (args.data[i].GetVectorType() != VectorType::CONSTANT_VECTOR) {
176: 			result.SetVectorType(VectorType::FLAT_VECTOR);
177: 		}
178: 	}
179: 
180: 	Vector &base = args.data[0];
181: 	Vector &subscript = args.data[1];
182: 
183: 	switch (base.GetType().id()) {
184: 	case LogicalTypeId::LIST:
185: 		ExecuteListExtract(result, base, subscript, count);
186: 		break;
187: 	case LogicalTypeId::VARCHAR:
188: 		ExecuteStringExtract(result, base, subscript, count);
189: 		break;
190: 	default:
191: 		throw NotImplementedException("Specifier type not implemented");
192: 	}
193: }
194: 
195: static unique_ptr<FunctionData> ListExtractBind(ClientContext &context, ScalarFunction &bound_function,
196:                                                 vector<unique_ptr<Expression>> &arguments) {
197: 	D_ASSERT(bound_function.arguments.size() == 2);
198: 	D_ASSERT(LogicalTypeId::LIST == arguments[0]->return_type.id());
199: 	// list extract returns the child type of the list as return type
200: 	bound_function.return_type = ListType::GetChildType(arguments[0]->return_type);
201: 
202: 	return make_unique<VariableReturnBindData>(bound_function.return_type);
203: }
204: 
205: static unique_ptr<BaseStatistics> ListExtractStats(ClientContext &context, BoundFunctionExpression &expr,
206:                                                    FunctionData *bind_data,
207:                                                    vector<unique_ptr<BaseStatistics>> &child_stats) {
208: 	if (!child_stats[0]) {
209: 		return nullptr;
210: 	}
211: 	auto &list_stats = (ListStatistics &)*child_stats[0];
212: 	if (!list_stats.child_stats) {
213: 		return nullptr;
214: 	}
215: 	auto child_copy = list_stats.child_stats->Copy();
216: 	// list_extract always pushes a NULL, since if the offset is out of range for a list it inserts a null
217: 	child_copy->validity_stats = make_unique<ValidityStatistics>(true);
218: 	return child_copy;
219: }
220: 
221: void ListExtractFun::RegisterFunction(BuiltinFunctions &set) {
222: 	// the arguments and return types are actually set in the binder function
223: 	ScalarFunction lfun({LogicalType::LIST(LogicalType::ANY), LogicalType::BIGINT}, LogicalType::ANY,
224: 	                    ListExtractFunction, false, ListExtractBind, nullptr, ListExtractStats);
225: 
226: 	ScalarFunction sfun({LogicalType::VARCHAR, LogicalType::INTEGER}, LogicalType::VARCHAR, ListExtractFunction, false,
227: 	                    nullptr);
228: 
229: 	ScalarFunctionSet list_extract("list_extract");
230: 	list_extract.AddFunction(lfun);
231: 	list_extract.AddFunction(sfun);
232: 	set.AddFunction(list_extract);
233: 
234: 	ScalarFunctionSet list_element("list_element");
235: 	list_element.AddFunction(lfun);
236: 	list_element.AddFunction(sfun);
237: 	set.AddFunction(list_element);
238: 
239: 	ScalarFunctionSet array_extract("array_extract");
240: 	array_extract.AddFunction(lfun);
241: 	array_extract.AddFunction(sfun);
242: 	array_extract.AddFunction(StructExtractFun::GetFunction());
243: 	set.AddFunction(array_extract);
244: }
245: 
246: } // namespace duckdb
[end of src/function/scalar/list/list_extract.cpp]
[start of src/function/scalar/string/length.cpp]
1: #include "duckdb/function/scalar/string_functions.hpp"
2: 
3: #include "duckdb/common/exception.hpp"
4: #include "duckdb/common/vector_operations/vector_operations.hpp"
5: #include "duckdb/planner/expression/bound_function_expression.hpp"
6: #include "duckdb/storage/statistics/string_statistics.hpp"
7: #include "utf8proc.hpp"
8: 
9: namespace duckdb {
10: 
11: // length returns the size in characters
12: struct StringLengthOperator {
13: 	template <class TA, class TR>
14: 	static inline TR Operation(TA input) {
15: 		return LengthFun::Length<TA, TR>(input);
16: 	}
17: };
18: 
19: struct ArrayLengthOperator {
20: 	template <class TA, class TR>
21: 	static inline TR Operation(TA input) {
22: 		return input.length;
23: 	}
24: };
25: 
26: struct ArrayLengthBinaryOperator {
27: 	template <class TA, class TB, class TR>
28: 	static inline TR Operation(TA input, TB dimension) {
29: 		if (dimension != 1) {
30: 			throw NotImplementedException("array_length for dimensions other than 1 not implemented");
31: 		}
32: 		return input.length;
33: 	}
34: };
35: 
36: // strlen returns the size in bytes
37: struct StrLenOperator {
38: 	template <class TA, class TR>
39: 	static inline TR Operation(TA input) {
40: 		return input.GetSize();
41: 	}
42: };
43: 
44: // bitlen returns the size in bits
45: struct BitLenOperator {
46: 	template <class TA, class TR>
47: 	static inline TR Operation(TA input) {
48: 		return 8 * input.GetSize();
49: 	}
50: };
51: 
52: static unique_ptr<BaseStatistics> LengthPropagateStats(ClientContext &context, BoundFunctionExpression &expr,
53:                                                        FunctionData *bind_data,
54:                                                        vector<unique_ptr<BaseStatistics>> &child_stats) {
55: 	D_ASSERT(child_stats.size() == 1);
56: 	// can only propagate stats if the children have stats
57: 	if (!child_stats[0]) {
58: 		return nullptr;
59: 	}
60: 	auto &sstats = (StringStatistics &)*child_stats[0];
61: 	if (!sstats.has_unicode) {
62: 		expr.function.function = ScalarFunction::UnaryFunction<string_t, int64_t, StrLenOperator>;
63: 	}
64: 	return nullptr;
65: }
66: 
67: static unique_ptr<FunctionData> ListLengthBind(ClientContext &context, ScalarFunction &bound_function,
68:                                                vector<unique_ptr<Expression>> &arguments) {
69: 	bound_function.arguments[0] = arguments[0]->return_type;
70: 	return nullptr;
71: }
72: 
73: void LengthFun::RegisterFunction(BuiltinFunctions &set) {
74: 	ScalarFunction array_length_unary = ScalarFunction(
75: 	    {LogicalTypeId::LIST}, LogicalType::BIGINT,
76: 	    ScalarFunction::UnaryFunction<list_entry_t, int64_t, ArrayLengthOperator>, false, ListLengthBind);
77: 	ScalarFunctionSet length("length");
78: 	length.AddFunction(ScalarFunction({LogicalType::VARCHAR}, LogicalType::BIGINT,
79: 	                                  ScalarFunction::UnaryFunction<string_t, int64_t, StringLengthOperator>, false,
80: 	                                  nullptr, nullptr, LengthPropagateStats));
81: 	length.AddFunction(array_length_unary);
82: 	set.AddFunction(length);
83: 	length.name = "len";
84: 	set.AddFunction(length);
85: 
86: 	ScalarFunctionSet array_length("array_length");
87: 	array_length.AddFunction(array_length_unary);
88: 	array_length.AddFunction(
89: 	    ScalarFunction({LogicalTypeId::LIST, LogicalType::BIGINT}, LogicalType::BIGINT,
90: 	                   ScalarFunction::BinaryFunction<list_entry_t, int64_t, int64_t, ArrayLengthBinaryOperator>, false,
91: 	                   ListLengthBind));
92: 	set.AddFunction(array_length);
93: 
94: 	set.AddFunction(ScalarFunction("strlen", {LogicalType::VARCHAR}, LogicalType::BIGINT,
95: 	                               ScalarFunction::UnaryFunction<string_t, int64_t, StrLenOperator>));
96: 	set.AddFunction(ScalarFunction("bit_length", {LogicalType::VARCHAR}, LogicalType::BIGINT,
97: 	                               ScalarFunction::UnaryFunction<string_t, int64_t, BitLenOperator>));
98: 	// length for BLOB type
99: 	set.AddFunction(ScalarFunction("octet_length", {LogicalType::BLOB}, LogicalType::BIGINT,
100: 	                               ScalarFunction::UnaryFunction<string_t, int64_t, StrLenOperator>));
101: }
102: 
103: struct UnicodeOperator {
104: 	template <class TA, class TR>
105: 	static inline TR Operation(const TA &input) {
106: 		auto str = reinterpret_cast<const utf8proc_uint8_t *>(input.GetDataUnsafe());
107: 		auto len = input.GetSize();
108: 		utf8proc_int32_t codepoint;
109: 		(void)utf8proc_iterate(str, len, &codepoint);
110: 		return codepoint;
111: 	}
112: };
113: 
114: void UnicodeFun::RegisterFunction(BuiltinFunctions &set) {
115: 	ScalarFunction unicode("unicode", {LogicalType::VARCHAR}, LogicalType::INTEGER,
116: 	                       ScalarFunction::UnaryFunction<string_t, int32_t, UnicodeOperator>);
117: 	set.AddFunction(unicode);
118: 	unicode.name = "ord";
119: 	set.AddFunction(unicode);
120: }
121: 
122: } // namespace duckdb
[end of src/function/scalar/string/length.cpp]
[start of src/planner/planner.cpp]
1: #include "duckdb/planner/planner.hpp"
2: #include "duckdb/main/query_profiler.hpp"
3: #include "duckdb/common/serializer.hpp"
4: #include "duckdb/main/client_context.hpp"
5: #include "duckdb/main/database.hpp"
6: #include "duckdb/parser/statement/pragma_statement.hpp"
7: #include "duckdb/parser/statement/prepare_statement.hpp"
8: #include "duckdb/main/prepared_statement_data.hpp"
9: #include "duckdb/planner/binder.hpp"
10: #include "duckdb/planner/expression/bound_parameter_expression.hpp"
11: #include "duckdb/planner/operator/logical_execute.hpp"
12: #include "duckdb/planner/operator/logical_prepare.hpp"
13: #include "duckdb/planner/expression_binder/constant_binder.hpp"
14: #include "duckdb/parser/statement/execute_statement.hpp"
15: #include "duckdb/execution/expression_executor.hpp"
16: #include "duckdb/transaction/transaction.hpp"
17: 
18: namespace duckdb {
19: 
20: Planner::Planner(ClientContext &context) : binder(Binder::CreateBinder(context)), context(context) {
21: }
22: 
23: void Planner::CreatePlan(SQLStatement &statement) {
24: 	vector<BoundParameterExpression *> bound_parameters;
25: 
26: 	// first bind the tables and columns to the catalog
27: 	context.profiler->StartPhase("binder");
28: 	binder->parameters = &bound_parameters;
29: 	auto bound_statement = binder->Bind(statement);
30: 	context.profiler->EndPhase();
31: 
32: 	this->read_only = binder->read_only;
33: 	this->requires_valid_transaction = binder->requires_valid_transaction;
34: 	this->allow_stream_result = binder->allow_stream_result;
35: 	this->names = bound_statement.names;
36: 	this->types = bound_statement.types;
37: 	this->plan = move(bound_statement.plan);
38: 
39: 	// set up a map of parameter number -> value entries
40: 	for (auto &expr : bound_parameters) {
41: 		// check if the type of the parameter could be resolved
42: 		if (expr->return_type.id() == LogicalTypeId::INVALID || expr->return_type.id() == LogicalTypeId::UNKNOWN) {
43: 			throw InternalException("Could not determine type of parameters");
44: 		}
45: 		auto value = make_unique<Value>(expr->return_type);
46: 		expr->value = value.get();
47: 		// check if the parameter number has been used before
48: 		if (value_map.find(expr->parameter_nr) == value_map.end()) {
49: 			// not used before, create vector
50: 			value_map[expr->parameter_nr] = vector<unique_ptr<Value>>();
51: 		} else if (value_map[expr->parameter_nr].back()->type() != value->type()) {
52: 			// used before, but types are inconsistent
53: 			throw BinderException("Inconsistent types found for parameter with index %llu", expr->parameter_nr);
54: 		}
55: 		value_map[expr->parameter_nr].push_back(move(value));
56: 	}
57: }
58: 
59: shared_ptr<PreparedStatementData> Planner::PrepareSQLStatement(unique_ptr<SQLStatement> statement) {
60: 	auto copied_statement = statement->Copy();
61: 	// create a plan of the underlying statement
62: 	CreatePlan(move(statement));
63: 	// now create the logical prepare
64: 	auto prepared_data = make_shared<PreparedStatementData>(copied_statement->type);
65: 	prepared_data->unbound_statement = move(copied_statement);
66: 	prepared_data->names = names;
67: 	prepared_data->types = types;
68: 	prepared_data->value_map = move(value_map);
69: 	prepared_data->read_only = this->read_only;
70: 	prepared_data->requires_valid_transaction = this->requires_valid_transaction;
71: 	prepared_data->allow_stream_result = this->allow_stream_result;
72: 	prepared_data->catalog_version = Transaction::GetTransaction(context).catalog_version;
73: 	return prepared_data;
74: }
75: 
76: void Planner::PlanExecute(unique_ptr<SQLStatement> statement) {
77: 	auto &stmt = (ExecuteStatement &)*statement;
78: 
79: 	// bind the prepared statement
80: 	auto entry = context.prepared_statements.find(stmt.name);
81: 	if (entry == context.prepared_statements.end()) {
82: 		throw BinderException("Prepared statement \"%s\" does not exist", stmt.name);
83: 	}
84: 
85: 	// check if we need to rebind the prepared statement
86: 	// this happens if the catalog changes, since in this case e.g. tables we relied on may have been deleted
87: 	auto prepared = entry->second;
88: 	auto &catalog = Catalog::GetCatalog(context);
89: 	bool rebound = false;
90: 	if (catalog.GetCatalogVersion() != entry->second->catalog_version) {
91: 		// catalog was modified: rebind the statement before running the execute
92: 		prepared = PrepareSQLStatement(entry->second->unbound_statement->Copy());
93: 		if (prepared->types != entry->second->types) {
94: 			throw BinderException("Rebinding statement \"%s\" after catalog change resulted in change of types",
95: 			                      stmt.name);
96: 		}
97: 		rebound = true;
98: 	}
99: 
100: 	// the bound prepared statement is ready: bind any supplied parameters
101: 	vector<Value> bind_values;
102: 	for (idx_t i = 0; i < stmt.values.size(); i++) {
103: 		ConstantBinder cbinder(*binder, context, "EXECUTE statement");
104: 		cbinder.target_type = prepared->GetType(i + 1);
105: 		auto bound_expr = cbinder.Bind(stmt.values[i]);
106: 
107: 		Value value = ExpressionExecutor::EvaluateScalar(*bound_expr);
108: 		bind_values.push_back(move(value));
109: 	}
110: 	prepared->Bind(move(bind_values));
111: 	if (rebound) {
112: 		return;
113: 	}
114: 
115: 	// copy the properties of the prepared statement into the planner
116: 	this->read_only = prepared->read_only;
117: 	this->requires_valid_transaction = prepared->requires_valid_transaction;
118: 	this->allow_stream_result = prepared->allow_stream_result;
119: 	this->names = prepared->names;
120: 	this->types = prepared->types;
121: 	this->plan = make_unique<LogicalExecute>(move(prepared));
122: }
123: 
124: void Planner::PlanPrepare(unique_ptr<SQLStatement> statement) {
125: 	auto &stmt = (PrepareStatement &)*statement;
126: 	auto prepared_data = PrepareSQLStatement(move(stmt.statement));
127: 
128: 	auto prepare = make_unique<LogicalPrepare>(stmt.name, move(prepared_data), move(plan));
129: 	// we can prepare in read-only mode: prepared statements are not written to the catalog
130: 	this->read_only = true;
131: 	// we can always prepare, even if the transaction has been invalidated
132: 	// this is required because most clients ALWAYS invoke prepared statements
133: 	this->requires_valid_transaction = false;
134: 	this->allow_stream_result = false;
135: 	this->names = {"Success"};
136: 	this->types = {LogicalType::BOOLEAN};
137: 	this->plan = move(prepare);
138: }
139: 
140: void Planner::CreatePlan(unique_ptr<SQLStatement> statement) {
141: 	D_ASSERT(statement);
142: 	switch (statement->type) {
143: 	case StatementType::SELECT_STATEMENT:
144: 	case StatementType::INSERT_STATEMENT:
145: 	case StatementType::COPY_STATEMENT:
146: 	case StatementType::DELETE_STATEMENT:
147: 	case StatementType::UPDATE_STATEMENT:
148: 	case StatementType::CREATE_STATEMENT:
149: 	case StatementType::DROP_STATEMENT:
150: 	case StatementType::ALTER_STATEMENT:
151: 	case StatementType::TRANSACTION_STATEMENT:
152: 	case StatementType::EXPLAIN_STATEMENT:
153: 	case StatementType::VACUUM_STATEMENT:
154: 	case StatementType::RELATION_STATEMENT:
155: 	case StatementType::CALL_STATEMENT:
156: 	case StatementType::EXPORT_STATEMENT:
157: 	case StatementType::PRAGMA_STATEMENT:
158: 	case StatementType::SHOW_STATEMENT:
159: 	case StatementType::SET_STATEMENT:
160: 	case StatementType::LOAD_STATEMENT:
161: 		CreatePlan(*statement);
162: 		break;
163: 	case StatementType::EXECUTE_STATEMENT:
164: 		PlanExecute(move(statement));
165: 		break;
166: 	case StatementType::PREPARE_STATEMENT:
167: 		PlanPrepare(move(statement));
168: 		break;
169: 	default:
170: 		throw NotImplementedException("Cannot plan statement of type %s!", StatementTypeToString(statement->type));
171: 	}
172: }
173: 
174: } // namespace duckdb
[end of src/planner/planner.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: