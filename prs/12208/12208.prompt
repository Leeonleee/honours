You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
Shadowing of variable names in Python
### What happens?

In builds subsequent to 10.2, names from the duckdb module appear to be shadowing Python variables when used in queries. 

### To Reproduce

When I use a variable name for a dataframe in an SQL query that happens to be the name of some function in the duckdb module, I run in to the following problem. I'm using the variable name "df" in this case but I could have use "pl" or "arrow" or many other to reproduce the same error.

```python
import pandas as pd
import duckdb

df = pd.DataFrame({"a":[1,2,3]})
duckdb.sql("from df")
```
```text
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/Users/username/venv/lib/python3.12/site-packages/duckdb/__init__.py", line 455, in sql
    return conn.sql(query, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
duckdb.duckdb.InvalidInputException: Invalid Input Error: Python Object "df" of type "builtin_function_or_method" found on line "/Users/username/venv/lib/python3.12/site-packages/duckdb/__init__.py:455" not suitable for replacement scans.
Make sure that "df" is either a pandas.DataFrame, duckdb.DuckDBPyRelation, pyarrow Table, Dataset, RecordBatchReader, Scanner, or NumPy ndarrays with supported format
```
When I use a variable name for the dataframe that is not visible in the duckdb module then there are no problems.

```python
pdf = df
duckdb.sql("from pdf")
```
```
┌───────┐
│   a   │
│ int64 │
├───────┤
│     1 │
│     2 │
│     3 │
└───────┘
```


### OS:

MacOS Sonama 14.4.1 (silicon)

### DuckDB Version:

0.10.3-dev777

### DuckDB Client:

Python

### Full Name:

David Brennan

### Affiliation:

None

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a nightly build

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
18: 
19: ## Installation
20: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
21: 
22: ## Data Import
23: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
24: 
25: ```sql
26: SELECT * FROM 'myfile.csv';
27: SELECT * FROM 'myfile.parquet';
28: ```
29: 
30: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
31: 
32: ## SQL Reference
33: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
34: 
35: ## Development
36: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
37: 
38: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
39: 
40: ## Support
41: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of tools/pythonpkg/scripts/cache_data.json]
1: {
2:     "pyarrow": {
3:         "type": "module",
4:         "full_path": "pyarrow",
5:         "name": "pyarrow",
6:         "children": [
7:             "pyarrow.dataset",
8:             "pyarrow.Table",
9:             "pyarrow.RecordBatchReader"
10:         ]
11:     },
12:     "pyarrow.dataset": {
13:         "type": "module",
14:         "full_path": "pyarrow.dataset",
15:         "name": "dataset",
16:         "children": [
17:             "pyarrow.dataset.Scanner",
18:             "pyarrow.dataset.Dataset"
19:         ]
20:     },
21:     "pyarrow.dataset.Scanner": {
22:         "type": "attribute",
23:         "full_path": "pyarrow.dataset.Scanner",
24:         "name": "Scanner",
25:         "children": []
26:     },
27:     "pyarrow.dataset.Dataset": {
28:         "type": "attribute",
29:         "full_path": "pyarrow.dataset.Dataset",
30:         "name": "Dataset",
31:         "children": []
32:     },
33:     "pyarrow.Table": {
34:         "type": "attribute",
35:         "full_path": "pyarrow.Table",
36:         "name": "Table",
37:         "children": []
38:     },
39:     "pyarrow.RecordBatchReader": {
40:         "type": "attribute",
41:         "full_path": "pyarrow.RecordBatchReader",
42:         "name": "RecordBatchReader",
43:         "children": []
44:     },
45:     "pandas": {
46:         "type": "module",
47:         "full_path": "pandas",
48:         "name": "pandas",
49:         "children": [
50:             "pandas.DataFrame",
51:             "pandas.isnull",
52:             "pandas.ArrowDtype",
53:             "pandas.NaT",
54:             "pandas.NA"
55:         ],
56:         "required": false
57:     },
58:     "pandas.DataFrame": {
59:         "type": "attribute",
60:         "full_path": "pandas.DataFrame",
61:         "name": "DataFrame",
62:         "children": []
63:     },
64:     "pandas.NaT": {
65:         "type": "attribute",
66:         "full_path": "pandas.NaT",
67:         "name": "NaT",
68:         "children": []
69:     },
70:     "pandas.NA": {
71:         "type": "attribute",
72:         "full_path": "pandas.NA",
73:         "name": "NA",
74:         "children": []
75:     },
76:     "pandas.isnull": {
77:         "type": "attribute",
78:         "full_path": "pandas.isnull",
79:         "name": "isnull",
80:         "children": []
81:     },
82:     "pandas.ArrowDtype": {
83:         "type": "attribute",
84:         "full_path": "pandas.ArrowDtype",
85:         "name": "ArrowDtype",
86:         "children": []
87:     },
88:     "datetime": {
89:         "type": "module",
90:         "full_path": "datetime",
91:         "name": "datetime",
92:         "children": [
93:             "datetime.date",
94:             "datetime.time",
95:             "datetime.timedelta",
96:             "datetime.timezone",
97:             "datetime.datetime"
98:         ]
99:     },
100:     "datetime.date": {
101:         "type": "attribute",
102:         "full_path": "datetime.date",
103:         "name": "date",
104:         "children": [
105:             "datetime.date.max",
106:             "datetime.date.min"
107:         ]
108:     },
109:     "datetime.date.max": {
110:         "type": "attribute",
111:         "full_path": "datetime.date.max",
112:         "name": "max",
113:         "children": []
114:     },
115:     "datetime.date.min": {
116:         "type": "attribute",
117:         "full_path": "datetime.date.min",
118:         "name": "min",
119:         "children": []
120:     },
121:     "datetime.time": {
122:         "type": "attribute",
123:         "full_path": "datetime.time",
124:         "name": "time",
125:         "children": []
126:     },
127:     "datetime.timedelta": {
128:         "type": "attribute",
129:         "full_path": "datetime.timedelta",
130:         "name": "timedelta",
131:         "children": []
132:     },
133:     "datetime.datetime": {
134:         "type": "attribute",
135:         "full_path": "datetime.datetime",
136:         "name": "datetime",
137:         "children": [
138:             "datetime.datetime.min",
139:             "datetime.datetime.max",
140:             "datetime.datetime.combine"
141:         ]
142:     },
143:     "datetime.datetime.min": {
144:         "type": "attribute",
145:         "full_path": "datetime.datetime.min",
146:         "name": "min",
147:         "children": []
148:     },
149:     "datetime.datetime.max": {
150:         "type": "attribute",
151:         "full_path": "datetime.datetime.max",
152:         "name": "max",
153:         "children": []
154:     },
155:     "datetime.datetime.combine": {
156:         "type": "attribute",
157:         "full_path": "datetime.datetime.combine",
158:         "name": "combine",
159:         "children": []
160:     },
161:     "datetime.timezone": {
162:         "type": "attribute",
163:         "full_path": "datetime.timezone",
164:         "name": "timezone",
165:         "children": []
166:     },
167:     "decimal": {
168:         "type": "module",
169:         "full_path": "decimal",
170:         "name": "decimal",
171:         "children": [
172:             "decimal.Decimal"
173:         ]
174:     },
175:     "decimal.Decimal": {
176:         "type": "attribute",
177:         "full_path": "decimal.Decimal",
178:         "name": "Decimal",
179:         "children": []
180:     },
181:     "IPython": {
182:         "type": "module",
183:         "full_path": "IPython",
184:         "name": "IPython",
185:         "children": [
186:             "IPython.get_ipython",
187:             "IPython.display"
188:         ],
189:         "required": false
190:     },
191:     "IPython.get_ipython": {
192:         "type": "attribute",
193:         "full_path": "IPython.get_ipython",
194:         "name": "get_ipython",
195:         "children": []
196:     },
197:     "IPython.display": {
198:         "type": "attribute",
199:         "full_path": "IPython.display",
200:         "name": "display",
201:         "children": [
202:             "IPython.display.display"
203:         ]
204:     },
205:     "IPython.display.display": {
206:         "type": "attribute",
207:         "full_path": "IPython.display.display",
208:         "name": "display",
209:         "children": []
210:     },
211:     "ipywidgets": {
212:         "type": "module",
213:         "full_path": "ipywidgets",
214:         "name": "ipywidgets",
215:         "children": [
216:             "ipywidgets.FloatProgress"
217:         ],
218:         "required": false
219:     },
220:     "ipywidgets.FloatProgress": {
221:         "type": "attribute",
222:         "full_path": "ipywidgets.FloatProgress",
223:         "name": "FloatProgress",
224:         "children": []
225:     },
226:     "numpy": {
227:         "type": "module",
228:         "full_path": "numpy",
229:         "name": "numpy",
230:         "children": [
231:             "numpy.core",
232:             "numpy.ma",
233:             "numpy.ndarray",
234:             "numpy.datetime64",
235:             "numpy.generic",
236:             "numpy.int64",
237:             "numpy.bool_",
238:             "numpy.byte",
239:             "numpy.ubyte",
240:             "numpy.short",
241:             "numpy.ushort",
242:             "numpy.intc",
243:             "numpy.uintc",
244:             "numpy.int_",
245:             "numpy.uint",
246:             "numpy.longlong",
247:             "numpy.ulonglong",
248:             "numpy.half",
249:             "numpy.float16",
250:             "numpy.single",
251:             "numpy.longdouble",
252:             "numpy.csingle",
253:             "numpy.cdouble",
254:             "numpy.clongdouble"
255:         ],
256:         "required": false
257:     },
258:     "numpy.core": {
259:         "type": "attribute",
260:         "full_path": "numpy.core",
261:         "name": "core",
262:         "children": [
263:             "numpy.core.multiarray"
264:         ]
265:     },
266:     "numpy.core.multiarray": {
267:         "type": "attribute",
268:         "full_path": "numpy.core.multiarray",
269:         "name": "multiarray",
270:         "children": []
271:     },
272:     "numpy.ma": {
273:         "type": "attribute",
274:         "full_path": "numpy.ma",
275:         "name": "ma",
276:         "children": [
277:             "numpy.ma.masked"
278:         ]
279:     },
280:     "numpy.ma.masked": {
281:         "type": "attribute",
282:         "full_path": "numpy.ma.masked",
283:         "name": "masked",
284:         "children": []
285:     },
286:     "numpy.ndarray": {
287:         "type": "attribute",
288:         "full_path": "numpy.ndarray",
289:         "name": "ndarray",
290:         "children": []
291:     },
292:     "numpy.datetime64": {
293:         "type": "attribute",
294:         "full_path": "numpy.datetime64",
295:         "name": "datetime64",
296:         "children": []
297:     },
298:     "numpy.generic": {
299:         "type": "attribute",
300:         "full_path": "numpy.generic",
301:         "name": "generic",
302:         "children": []
303:     },
304:     "numpy.int64": {
305:         "type": "attribute",
306:         "full_path": "numpy.int64",
307:         "name": "int64",
308:         "children": []
309:     },
310:     "numpy.bool_": {
311:         "type": "attribute",
312:         "full_path": "numpy.bool_",
313:         "name": "bool_",
314:         "children": []
315:     },
316:     "numpy.byte": {
317:         "type": "attribute",
318:         "full_path": "numpy.byte",
319:         "name": "byte",
320:         "children": []
321:     },
322:     "numpy.ubyte": {
323:         "type": "attribute",
324:         "full_path": "numpy.ubyte",
325:         "name": "ubyte",
326:         "children": []
327:     },
328:     "numpy.short": {
329:         "type": "attribute",
330:         "full_path": "numpy.short",
331:         "name": "short",
332:         "children": []
333:     },
334:     "numpy.ushort": {
335:         "type": "attribute",
336:         "full_path": "numpy.ushort",
337:         "name": "ushort",
338:         "children": []
339:     },
340:     "numpy.intc": {
341:         "type": "attribute",
342:         "full_path": "numpy.intc",
343:         "name": "intc",
344:         "children": []
345:     },
346:     "numpy.uintc": {
347:         "type": "attribute",
348:         "full_path": "numpy.uintc",
349:         "name": "uintc",
350:         "children": []
351:     },
352:     "numpy.int_": {
353:         "type": "attribute",
354:         "full_path": "numpy.int_",
355:         "name": "int_",
356:         "children": []
357:     },
358:     "numpy.uint": {
359:         "type": "attribute",
360:         "full_path": "numpy.uint",
361:         "name": "uint",
362:         "children": []
363:     },
364:     "numpy.longlong": {
365:         "type": "attribute",
366:         "full_path": "numpy.longlong",
367:         "name": "longlong",
368:         "children": []
369:     },
370:     "numpy.ulonglong": {
371:         "type": "attribute",
372:         "full_path": "numpy.ulonglong",
373:         "name": "ulonglong",
374:         "children": []
375:     },
376:     "numpy.half": {
377:         "type": "attribute",
378:         "full_path": "numpy.half",
379:         "name": "half",
380:         "children": []
381:     },
382:     "numpy.float16": {
383:         "type": "attribute",
384:         "full_path": "numpy.float16",
385:         "name": "float16",
386:         "children": []
387:     },
388:     "numpy.single": {
389:         "type": "attribute",
390:         "full_path": "numpy.single",
391:         "name": "single",
392:         "children": []
393:     },
394:     "numpy.longdouble": {
395:         "type": "attribute",
396:         "full_path": "numpy.longdouble",
397:         "name": "longdouble",
398:         "children": []
399:     },
400:     "numpy.csingle": {
401:         "type": "attribute",
402:         "full_path": "numpy.csingle",
403:         "name": "csingle",
404:         "children": []
405:     },
406:     "numpy.cdouble": {
407:         "type": "attribute",
408:         "full_path": "numpy.cdouble",
409:         "name": "cdouble",
410:         "children": []
411:     },
412:     "numpy.clongdouble": {
413:         "type": "attribute",
414:         "full_path": "numpy.clongdouble",
415:         "name": "clongdouble",
416:         "children": []
417:     },
418:     "pathlib": {
419:         "type": "module",
420:         "full_path": "pathlib",
421:         "name": "pathlib",
422:         "children": [
423:             "pathlib.Path"
424:         ],
425:         "required": false
426:     },
427:     "pathlib.Path": {
428:         "type": "attribute",
429:         "full_path": "pathlib.Path",
430:         "name": "Path",
431:         "children": []
432:     },
433:     "polars": {
434:         "type": "module",
435:         "full_path": "polars",
436:         "name": "polars",
437:         "children": [
438:             "polars.DataFrame",
439:             "polars.LazyFrame"
440:         ],
441:         "required": false
442:     },
443:     "polars.DataFrame": {
444:         "type": "attribute",
445:         "full_path": "polars.DataFrame",
446:         "name": "DataFrame",
447:         "children": []
448:     },
449:     "polars.LazyFrame": {
450:         "type": "attribute",
451:         "full_path": "polars.LazyFrame",
452:         "name": "LazyFrame",
453:         "children": []
454:     },
455:     "duckdb": {
456:         "type": "module",
457:         "full_path": "duckdb",
458:         "name": "duckdb",
459:         "children": [
460:             "duckdb.filesystem",
461:             "duckdb.Value"
462:         ]
463:     },
464:     "duckdb.filesystem": {
465:         "type": "module",
466:         "full_path": "duckdb.filesystem",
467:         "name": "filesystem",
468:         "children": [
469:             "duckdb.filesystem.ModifiedMemoryFileSystem"
470:         ],
471:         "required": false
472:     },
473:     "duckdb.filesystem.ModifiedMemoryFileSystem": {
474:         "type": "attribute",
475:         "full_path": "duckdb.filesystem.ModifiedMemoryFileSystem",
476:         "name": "ModifiedMemoryFileSystem",
477:         "children": []
478:     },
479:     "duckdb.Value": {
480:         "type": "attribute",
481:         "full_path": "duckdb.Value",
482:         "name": "Value",
483:         "children": []
484:     },
485:     "pytz": {
486:         "type": "module",
487:         "full_path": "pytz",
488:         "name": "pytz",
489:         "children": [
490:             "pytz.timezone"
491:         ]
492:     },
493:     "pytz.timezone": {
494:         "type": "attribute",
495:         "full_path": "pytz.timezone",
496:         "name": "timezone",
497:         "children": []
498:     },
499:     "types": {
500:         "type": "module",
501:         "full_path": "types",
502:         "name": "types",
503:         "children": [
504:             "types.UnionType",
505:             "types.GenericAlias"
506:         ]
507:     },
508:     "types.UnionType": {
509:         "type": "attribute",
510:         "full_path": "types.UnionType",
511:         "name": "UnionType",
512:         "children": []
513:     },
514:     "types.GenericAlias": {
515:         "type": "attribute",
516:         "full_path": "types.GenericAlias",
517:         "name": "GenericAlias",
518:         "children": []
519:     },
520:     "typing": {
521:         "type": "module",
522:         "full_path": "typing",
523:         "name": "typing",
524:         "children": [
525:             "typing._UnionGenericAlias"
526:         ]
527:     },
528:     "typing._UnionGenericAlias": {
529:         "type": "attribute",
530:         "full_path": "typing._UnionGenericAlias",
531:         "name": "_UnionGenericAlias",
532:         "children": []
533:     },
534:     "uuid": {
535:         "type": "module",
536:         "full_path": "uuid",
537:         "name": "uuid",
538:         "children": [
539:             "uuid.UUID"
540:         ]
541:     },
542:     "uuid.UUID": {
543:         "type": "attribute",
544:         "full_path": "uuid.UUID",
545:         "name": "UUID",
546:         "children": []
547:     }
548: }
[end of tools/pythonpkg/scripts/cache_data.json]
[start of tools/pythonpkg/scripts/imports.py]
1: import pyarrow
2: import pyarrow.dataset
3: 
4: pyarrow.dataset.Scanner
5: pyarrow.dataset.Dataset
6: pyarrow.Table
7: pyarrow.RecordBatchReader
8: 
9: import pandas
10: 
11: pandas.DataFrame
12: pandas.NaT
13: pandas.NA
14: pandas.isnull
15: pandas.ArrowDtype
16: 
17: import datetime
18: 
19: datetime.date
20: datetime.date.max
21: datetime.date.min
22: datetime.time
23: datetime.timedelta
24: datetime.datetime
25: datetime.datetime.min
26: datetime.datetime.max
27: datetime.datetime.combine
28: datetime.timezone
29: 
30: import decimal
31: 
32: decimal.Decimal
33: 
34: import IPython
35: 
36: IPython.get_ipython
37: IPython.display
38: IPython.display.display
39: 
40: 
41: import ipywidgets
42: 
43: ipywidgets.FloatProgress
44: 
45: import numpy
46: 
47: numpy.core.multiarray
48: numpy.ma.masked
49: numpy.ndarray
50: numpy.datetime64
51: numpy.generic
52: numpy.int64
53: numpy.bool_
54: numpy.byte
55: numpy.ubyte
56: numpy.short
57: numpy.ushort
58: numpy.intc
59: numpy.uintc
60: numpy.int_
61: numpy.uint
62: numpy.longlong
63: numpy.ulonglong
64: numpy.half
65: numpy.float16
66: numpy.single
67: numpy.longdouble
68: numpy.csingle
69: numpy.cdouble
70: numpy.clongdouble
71: 
72: import pathlib
73: 
74: pathlib.Path
75: 
76: import polars
77: 
78: polars.DataFrame
79: polars.LazyFrame
80: 
81: import duckdb
82: import duckdb.filesystem
83: 
84: duckdb.filesystem.ModifiedMemoryFileSystem
85: duckdb.Value
86: 
87: import pytz
88: 
89: pytz.timezone
90: 
91: import types
92: 
93: types.UnionType
94: types.GenericAlias
95: 
96: import typing
97: 
98: typing._UnionGenericAlias
99: 
100: import uuid
101: 
102: uuid.UUID
[end of tools/pythonpkg/scripts/imports.py]
[start of tools/pythonpkg/src/include/duckdb_python/import_cache/modules/types_module.hpp]
1: 
2: //===----------------------------------------------------------------------===//
3: //                         DuckDB
4: //
5: // duckdb_python/import_cache/modules/types_module.hpp
6: //
7: //
8: //===----------------------------------------------------------------------===//
9: 
10: #pragma once
11: 
12: #include "duckdb_python/import_cache/python_import_cache_item.hpp"
13: 
14: namespace duckdb {
15: 
16: struct TypesCacheItem : public PythonImportCacheItem {
17: 
18: public:
19: 	static constexpr const char *Name = "types";
20: 
21: public:
22: 	TypesCacheItem()
23: 	    : PythonImportCacheItem("types"), UnionType("UnionType", this), GenericAlias("GenericAlias", this) {
24: 	}
25: 	~TypesCacheItem() override {
26: 	}
27: 
28: 	PythonImportCacheItem UnionType;
29: 	PythonImportCacheItem GenericAlias;
30: };
31: 
32: } // namespace duckdb
[end of tools/pythonpkg/src/include/duckdb_python/import_cache/modules/types_module.hpp]
[start of tools/pythonpkg/src/python_replacement_scan.cpp]
1: #include "duckdb_python/python_replacement_scan.hpp"
2: #include "duckdb_python/pybind11/pybind_wrapper.hpp"
3: #include "duckdb/main/client_properties.hpp"
4: #include "duckdb_python/numpy/numpy_type.hpp"
5: #include "duckdb/parser/tableref/table_function_ref.hpp"
6: #include "duckdb_python/pyconnection/pyconnection.hpp"
7: #include "duckdb_python/pybind11/dataframe.hpp"
8: #include "duckdb/parser/expression/constant_expression.hpp"
9: #include "duckdb/parser/expression/function_expression.hpp"
10: #include "duckdb/common/typedefs.hpp"
11: #include "duckdb_python/pandas/pandas_scan.hpp"
12: #include "duckdb/parser/tableref/subqueryref.hpp"
13: #include "duckdb_python/pyrelation.hpp"
14: 
15: namespace duckdb {
16: 
17: static void CreateArrowScan(const string &name, py::object entry, TableFunctionRef &table_function,
18:                             vector<unique_ptr<ParsedExpression>> &children, ClientProperties &client_properties) {
19: 	auto stream_factory = make_uniq<PythonTableArrowArrayStreamFactory>(entry.ptr(), client_properties);
20: 	auto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;
21: 	auto stream_factory_get_schema = PythonTableArrowArrayStreamFactory::GetSchema;
22: 
23: 	children.push_back(make_uniq<ConstantExpression>(Value::POINTER(CastPointerToValue(stream_factory.get()))));
24: 	children.push_back(make_uniq<ConstantExpression>(Value::POINTER(CastPointerToValue(stream_factory_produce))));
25: 	children.push_back(make_uniq<ConstantExpression>(Value::POINTER(CastPointerToValue(stream_factory_get_schema))));
26: 
27: 	table_function.function = make_uniq<FunctionExpression>("arrow_scan", std::move(children));
28: 	auto dependency = make_uniq<ExternalDependency>();
29: 	auto dependency_item = PythonDependencyItem::Create(make_uniq<RegisteredArrow>(std::move(stream_factory), entry));
30: 	dependency->AddDependency("replacement_cache", std::move(dependency_item));
31: 	table_function.external_dependency = std::move(dependency);
32: }
33: 
34: static unique_ptr<TableRef> TryReplacementObject(const py::object &entry, const string &name, ClientContext &context) {
35: 	auto client_properties = context.GetClientProperties();
36: 	auto table_function = make_uniq<TableFunctionRef>();
37: 	vector<unique_ptr<ParsedExpression>> children;
38: 	NumpyObjectType numpytype; // Identify the type of accepted numpy objects.
39: 	if (DuckDBPyConnection::IsPandasDataframe(entry)) {
40: 		if (PandasDataFrame::IsPyArrowBacked(entry)) {
41: 			auto table = PandasDataFrame::ToArrowTable(entry);
42: 			CreateArrowScan(name, table, *table_function, children, client_properties);
43: 		} else {
44: 			string name = "df_" + StringUtil::GenerateRandomName();
45: 			auto new_df = PandasScanFunction::PandasReplaceCopiedNames(entry);
46: 			children.push_back(make_uniq<ConstantExpression>(Value::POINTER(CastPointerToValue(new_df.ptr()))));
47: 			table_function->function = make_uniq<FunctionExpression>("pandas_scan", std::move(children));
48: 			auto dependency = make_uniq<ExternalDependency>();
49: 			dependency->AddDependency("replacement_cache", PythonDependencyItem::Create(entry));
50: 			dependency->AddDependency("copy", PythonDependencyItem::Create(new_df));
51: 			table_function->external_dependency = std::move(dependency);
52: 		}
53: 	} else if (DuckDBPyConnection::IsAcceptedArrowObject(entry)) {
54: 		CreateArrowScan(name, entry, *table_function, children, client_properties);
55: 	} else if (DuckDBPyRelation::IsRelation(entry)) {
56: 		auto pyrel = py::cast<DuckDBPyRelation *>(entry);
57: 		if (!pyrel->CanBeRegisteredBy(context)) {
58: 			throw InvalidInputException(
59: 			    "Python Object \"%s\" of type \"DuckDBPyRelation\" not suitable for replacement scan.\nThe object was "
60: 			    "created by another Connection and can therefore not be used by this Connection.",
61: 			    name);
62: 		}
63: 		// create a subquery from the underlying relation object
64: 		auto select = make_uniq<SelectStatement>();
65: 		select->node = pyrel->GetRel().GetQueryNode();
66: 		auto subquery = make_uniq<SubqueryRef>(std::move(select));
67: 		auto dependency = make_uniq<ExternalDependency>();
68: 		dependency->AddDependency("replacement_cache", PythonDependencyItem::Create(entry));
69: 		subquery->external_dependency = std::move(dependency);
70: 		return std::move(subquery);
71: 	} else if (PolarsDataFrame::IsDataFrame(entry)) {
72: 		auto arrow_dataset = entry.attr("to_arrow")();
73: 		CreateArrowScan(name, arrow_dataset, *table_function, children, client_properties);
74: 	} else if (PolarsDataFrame::IsLazyFrame(entry)) {
75: 		auto materialized = entry.attr("collect")();
76: 		auto arrow_dataset = materialized.attr("to_arrow")();
77: 		CreateArrowScan(name, arrow_dataset, *table_function, children, client_properties);
78: 	} else if ((numpytype = DuckDBPyConnection::IsAcceptedNumpyObject(entry)) != NumpyObjectType::INVALID) {
79: 		string name = "np_" + StringUtil::GenerateRandomName();
80: 		py::dict data; // we will convert all the supported format to dict{"key": np.array(value)}.
81: 		size_t idx = 0;
82: 		switch (numpytype) {
83: 		case NumpyObjectType::NDARRAY1D:
84: 			data["column0"] = entry;
85: 			break;
86: 		case NumpyObjectType::NDARRAY2D:
87: 			idx = 0;
88: 			for (auto item : py::cast<py::array>(entry)) {
89: 				data[("column" + std::to_string(idx)).c_str()] = item;
90: 				idx++;
91: 			}
92: 			break;
93: 		case NumpyObjectType::LIST:
94: 			idx = 0;
95: 			for (auto item : py::cast<py::list>(entry)) {
96: 				data[("column" + std::to_string(idx)).c_str()] = item;
97: 				idx++;
98: 			}
99: 			break;
100: 		case NumpyObjectType::DICT:
101: 			data = py::cast<py::dict>(entry);
102: 			break;
103: 		default:
104: 			throw NotImplementedException("Unsupported Numpy object");
105: 			break;
106: 		}
107: 		children.push_back(make_uniq<ConstantExpression>(Value::POINTER(CastPointerToValue(data.ptr()))));
108: 		table_function->function = make_uniq<FunctionExpression>("pandas_scan", std::move(children));
109: 		auto dependency = make_uniq<ExternalDependency>();
110: 		dependency->AddDependency("replacement_cache", PythonDependencyItem::Create(entry));
111: 		dependency->AddDependency("data", PythonDependencyItem::Create(data));
112: 		table_function->external_dependency = std::move(dependency);
113: 	} else {
114: 		// This throws an error later on!
115: 		return nullptr;
116: 	}
117: 	return std::move(table_function);
118: }
119: 
120: static unique_ptr<TableRef> TryReplacement(py::dict &dict, const string &name, ClientContext &context,
121:                                            py::object &current_frame) {
122: 	auto table_name = py::str(name);
123: 	if (!dict.contains(table_name)) {
124: 		// not present in the globals
125: 		return nullptr;
126: 	}
127: 	const py::object &entry = dict[table_name];
128: 	auto result = TryReplacementObject(entry, name, context);
129: 	if (!result) {
130: 		std::string location = py::cast<py::str>(current_frame.attr("f_code").attr("co_filename"));
131: 		location += ":";
132: 		location += py::cast<py::str>(current_frame.attr("f_lineno"));
133: 		std::string cpp_table_name = table_name;
134: 		auto py_object_type = string(py::str(entry.get_type().attr("__name__")));
135: 
136: 		throw InvalidInputException(
137: 		    "Python Object \"%s\" of type \"%s\" found on line \"%s\" not suitable for replacement scans.\nMake sure "
138: 		    "that \"%s\" is either a pandas.DataFrame, duckdb.DuckDBPyRelation, pyarrow Table, Dataset, "
139: 		    "RecordBatchReader, Scanner, or NumPy ndarrays with supported format",
140: 		    cpp_table_name, py_object_type, location, cpp_table_name);
141: 	}
142: 	return result;
143: }
144: 
145: static unique_ptr<TableRef> ReplaceInternal(ClientContext &context, const string &table_name) {
146: 	py::gil_scoped_acquire acquire;
147: 	// Here we do an exhaustive search on the frame lineage
148: 	auto current_frame = py::module::import("inspect").attr("currentframe")();
149: 	while (hasattr(current_frame, "f_locals")) {
150: 		auto local_dict = py::reinterpret_borrow<py::dict>(current_frame.attr("f_locals"));
151: 		// search local dictionary
152: 		if (local_dict) {
153: 			auto result = TryReplacement(local_dict, table_name, context, current_frame);
154: 			if (result) {
155: 				return result;
156: 			}
157: 		}
158: 		// search global dictionary
159: 		auto global_dict = py::reinterpret_borrow<py::dict>(current_frame.attr("f_globals"));
160: 		if (global_dict) {
161: 			auto result = TryReplacement(global_dict, table_name, context, current_frame);
162: 			if (result) {
163: 				return result;
164: 			}
165: 		}
166: 		current_frame = current_frame.attr("f_back");
167: 	}
168: 	// Not found :(
169: 	return nullptr;
170: }
171: unique_ptr<TableRef> PythonReplacementScan::Replace(ClientContext &context, ReplacementScanInput &input,
172:                                                     optional_ptr<ReplacementScanData> data) {
173: 	auto &table_name = input.table_name;
174: 
175: 	auto &table_ref = input.ref;
176: 	if (table_ref.external_dependency) {
177: 		auto dependency_item = table_ref.external_dependency->GetDependency("replacement_cache");
178: 		if (dependency_item) {
179: 			py::gil_scoped_acquire acquire;
180: 			auto &python_dependency = dependency_item->Cast<PythonDependencyItem>();
181: 			auto &registered_object = *python_dependency.object;
182: 			auto &py_object = registered_object.obj;
183: 			auto result = TryReplacementObject(py_object, table_name, context);
184: 			// This was cached, so it was successful before, it should be successfull now
185: 			D_ASSERT(result);
186: 			return std::move(result);
187: 		}
188: 	}
189: 
190: 	unique_ptr<TableRef> result;
191: 	result = ReplaceInternal(context, table_name);
192: 	if (!result) {
193: 		return nullptr;
194: 	}
195: 	if (table_ref.external_dependency) {
196: 		D_ASSERT(result->external_dependency);
197: 
198: 		D_ASSERT(result->external_dependency->GetDependency("replacement_cache") != nullptr);
199: 		result->external_dependency->ScanDependencies(
200: 		    [&table_ref](const string &name, shared_ptr<DependencyItem> item) {
201: 			    table_ref.external_dependency->AddDependency(name, std::move(item));
202: 		    });
203: 	}
204: 	return result;
205: }
206: 
207: } // namespace duckdb
[end of tools/pythonpkg/src/python_replacement_scan.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: