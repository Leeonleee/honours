{
  "repo": "duckdb/duckdb",
  "pull_number": 13989,
  "instance_id": "duckdb__duckdb-13989",
  "issue_numbers": [
    "13967"
  ],
  "base_commit": "86723c9912fde7b76d3863b2ccd2d4333251c4af",
  "patch": "diff --git a/src/common/arrow/arrow_converter.cpp b/src/common/arrow/arrow_converter.cpp\nindex 3524dc89888f..851d45b5beba 100644\n--- a/src/common/arrow/arrow_converter.cpp\n+++ b/src/common/arrow/arrow_converter.cpp\n@@ -166,7 +166,7 @@ void SetArrowFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, co\n \t\tbreak;\n \t}\n \tcase LogicalTypeId::VARCHAR:\n-\t\tif (type.IsJSONType()) {\n+\t\tif (type.IsJSONType() && options.arrow_lossless_conversion) {\n \t\t\tauto schema_metadata = ArrowSchemaMetadata::MetadataFromName(\"arrow.json\");\n \t\t\troot_holder.metadata_info.emplace_back(schema_metadata.SerializeMetadata());\n \t\t\tchild.metadata = root_holder.metadata_info.back().get();\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/arrow/test_canonical_extensions.py b/tools/pythonpkg/tests/fast/arrow/test_canonical_extensions.py\nindex 6fa4806029c4..a357df023214 100644\n--- a/tools/pythonpkg/tests/fast/arrow/test_canonical_extensions.py\n+++ b/tools/pythonpkg/tests/fast/arrow/test_canonical_extensions.py\n@@ -10,14 +10,94 @@\n from arrow_canonical_extensions import UuidType, JSONType, UHugeIntType, HugeIntType\n \n \n+class UuidTypeWrong(pa.ExtensionType):\n+    def __init__(self):\n+        pa.ExtensionType.__init__(self, pa.binary(4), \"arrow.uuid\")\n+\n+    def __arrow_ext_serialize__(self):\n+        # since we don't have a parameterized type, we don't need extra\n+        # metadata to be deserialized\n+        return b''\n+\n+    @classmethod\n+    def __arrow_ext_deserialize__(cls, storage_type, serialized):\n+        # return an instance of this subclass given the serialized\n+        # metadata.\n+        return UuidTypeWrong()\n+\n+\n+class JSONTypeWrong(pa.ExtensionType):\n+    def __init__(self):\n+        pa.ExtensionType.__init__(self, pa.int32(), \"arrow.json\")\n+\n+    def __arrow_ext_serialize__(self):\n+        # since we don't have a parameterized type, we don't need extra\n+        # metadata to be deserialized\n+        return b''\n+\n+    @classmethod\n+    def __arrow_ext_deserialize__(cls, storage_type, serialized):\n+        # return an instance of this subclass given the serialized\n+        # metadata.\n+        return JSONTypeWrong()\n+\n+\n+\"\"\"\n+    These fixtures make sure that the extension_type is registered at the start of the function,\n+    and unregistered at the end.\n+    \n+    No matter if an error occurred or the function ended early for whatever reason\n+\"\"\"\n+\n+\n+@pytest.fixture(scope='function')\n+def arrow_duckdb_hugeint():\n+    pa.register_extension_type(HugeIntType())\n+    yield\n+    pa.unregister_extension_type(\"duckdb.hugeint\")\n+\n+\n+@pytest.fixture(scope='function')\n+def arrow_duckdb_uhugeint():\n+    pa.register_extension_type(UHugeIntType())\n+    yield\n+    pa.unregister_extension_type(\"duckdb.uhugeint\")\n+\n+\n+@pytest.fixture(scope='function')\n+def arrow_json():\n+    pa.register_extension_type(JSONType())\n+    yield\n+    pa.unregister_extension_type(\"arrow.json\")\n+\n+\n+@pytest.fixture(scope='function')\n+def arrow_json_wrong():\n+    pa.register_extension_type(JSONTypeWrong())\n+    yield\n+    pa.unregister_extension_type(\"arrow.json\")\n+\n+\n+@pytest.fixture(scope='function')\n+def arrow_uuid():\n+    pa.register_extension_type(UuidType())\n+    yield\n+    pa.unregister_extension_type(\"arrow.uuid\")\n+\n+\n+@pytest.fixture(scope='function')\n+def arrow_uuid_wrong():\n+    pa.register_extension_type(UuidTypeWrong())\n+    yield\n+    pa.unregister_extension_type(\"arrow.uuid\")\n+\n+\n class TestCanonicalExtensionTypes(object):\n \n-    def test_uuid(self):\n+    def test_uuid(self, arrow_uuid):\n         duckdb_cursor = duckdb.connect()\n         duckdb_cursor.execute(\"SET arrow_lossless_conversion = true\")\n \n-        pa.register_extension_type(UuidType())\n-\n         storage_array = pa.array([uuid.uuid4().bytes for _ in range(4)], pa.binary(16))\n         uuid_type = UuidType()\n         storage_array = uuid_type.wrap_array(storage_array)\n@@ -28,14 +108,10 @@ def test_uuid(self):\n \n         assert duck_arrow.equals(arrow_table)\n \n-        pa.unregister_extension_type(\"arrow.uuid\")\n-\n-    def test_uuid_from_duck(self):\n+    def test_uuid_from_duck(self, arrow_uuid):\n         duckdb_cursor = duckdb.connect()\n         duckdb_cursor.execute(\"SET arrow_lossless_conversion = true\")\n \n-        pa.register_extension_type(UuidType())\n-\n         arrow_table = duckdb_cursor.execute(\"select uuid from test_all_types()\").fetch_arrow_table()\n \n         assert arrow_table.to_pylist() == [\n@@ -59,29 +135,10 @@ def test_uuid_from_duck(self):\n         ]\n         assert duckdb_cursor.execute(\"FROM arrow_table\").fetchall() == [(UUID('00000000-0000-0000-0000-000000000100'),)]\n \n-        pa.unregister_extension_type(\"arrow.uuid\")\n-\n-    def test_uuid_exception(self):\n-        class UuidTypeWrong(pa.ExtensionType):\n-            def __init__(self):\n-                pa.ExtensionType.__init__(self, pa.binary(4), \"arrow.uuid\")\n-\n-            def __arrow_ext_serialize__(self):\n-                # since we don't have a parameterized type, we don't need extra\n-                # metadata to be deserialized\n-                return b''\n-\n-            @classmethod\n-            def __arrow_ext_deserialize__(self, storage_type, serialized):\n-                # return an instance of this subclass given the serialized\n-                # metadata.\n-                return UuidTypeWrong()\n-\n+    def test_uuid_exception(self, arrow_uuid_wrong):\n         duckdb_cursor = duckdb.connect()\n         duckdb_cursor.execute(\"SET arrow_lossless_conversion = true\")\n \n-        pa.register_extension_type(UuidTypeWrong())\n-\n         storage_array = pa.array(['aaaa'], pa.binary(4))\n         uuid_type = UuidTypeWrong()\n         storage_array = uuid_type.wrap_array(storage_array)\n@@ -91,11 +148,7 @@ def __arrow_ext_deserialize__(self, storage_type, serialized):\n         with pytest.raises(duckdb.InvalidInputException, match=\"arrow.uuid must be a fixed-size binary of 16 bytes\"):\n             duck_arrow = duckdb_cursor.execute('FROM arrow_table').arrow()\n \n-        pa.unregister_extension_type(\"arrow.uuid\")\n-\n-    def test_json(self, duckdb_cursor):\n-        pa.register_extension_type(JSONType())\n-\n+    def test_json(self, duckdb_cursor, arrow_json):\n         data = {\"name\": \"Pedro\", \"age\": 28, \"car\": \"VW Fox\"}\n \n         # Convert dictionary to JSON string\n@@ -107,30 +160,12 @@ def test_json(self, duckdb_cursor):\n \n         arrow_table = pa.Table.from_arrays([storage_array], names=['json_col'])\n \n+        duckdb_cursor.execute(\"SET arrow_lossless_conversion = true\")\n         duck_arrow = duckdb_cursor.execute('FROM arrow_table').arrow()\n \n         assert duck_arrow.equals(arrow_table)\n \n-        pa.unregister_extension_type(\"arrow.json\")\n-\n-    def test_json_throw(self, duckdb_cursor):\n-        class JSONTypeWrong(pa.ExtensionType):\n-            def __init__(self):\n-                pa.ExtensionType.__init__(self, pa.int32(), \"arrow.json\")\n-\n-            def __arrow_ext_serialize__(self):\n-                # since we don't have a parameterized type, we don't need extra\n-                # metadata to be deserialized\n-                return b''\n-\n-            @classmethod\n-            def __arrow_ext_deserialize__(self, storage_type, serialized):\n-                # return an instance of this subclass given the serialized\n-                # metadata.\n-                return JSONTypeWrong()\n-\n-        pa.register_extension_type(JSONTypeWrong())\n-\n+    def test_json_throw(self, duckdb_cursor, arrow_json_wrong):\n         storage_array = pa.array([32], pa.int32())\n         json_type = JSONTypeWrong()\n         storage_array = json_type.wrap_array(storage_array)\n@@ -139,7 +174,6 @@ def __arrow_ext_deserialize__(self, storage_type, serialized):\n \n         with pytest.raises(duckdb.InvalidInputException, match=\"arrow.json must be of a varchar format \"):\n             duck_arrow = duckdb_cursor.execute('FROM arrow_table').arrow()\n-        pa.unregister_extension_type(\"arrow.json\")\n \n     def test_uuid_no_def(self):\n         duckdb_cursor = duckdb.connect()\n@@ -181,9 +215,7 @@ def test_uuid_no_def_stream(self):\n             (None,),\n         ]\n \n-    def test_uuid_udf_registered(self, duckdb_cursor):\n-        pa.register_extension_type(UuidType())\n-\n+    def test_uuid_udf_registered(self, arrow_uuid):\n         def test_function(x):\n             print(x.type.__class__)\n             return x\n@@ -194,19 +226,17 @@ def test_function(x):\n         rel = con.sql(\"select ? as x\", params=[uuid.UUID('ffffffff-ffff-ffff-ffff-ffffffffffff')])\n         rel.project(\"test(x) from t\").fetchall()\n \n-        pa.unregister_extension_type(\"arrow.uuid\")\n-\n     def test_uuid_udf_unregistered(self):\n-        duckdb_cursor = duckdb.connect()\n-        duckdb_cursor.execute(\"SET arrow_lossless_conversion = true\")\n+        con = duckdb.connect()\n+        con.execute(\"SET arrow_lossless_conversion = true\")\n \n         def test_function(x):\n             print(x.type.__class__)\n             return x\n \n-        duckdb_cursor.create_function('test', test_function, ['UUID'], 'UUID', type='arrow')\n+        con.create_function('test', test_function, ['UUID'], 'UUID', type='arrow')\n \n-        rel = duckdb_cursor.sql(\"select ? as x\", params=[uuid.UUID('ffffffff-ffff-ffff-ffff-ffffffffffff')])\n+        rel = con.sql(\"select ? as x\", params=[uuid.UUID('ffffffff-ffff-ffff-ffff-ffffffffffff')])\n         with pytest.raises(duckdb.Error, match=\"It seems that you are using the UUID arrow canonical extension\"):\n             rel.project(\"test(x) from t\").fetchall()\n \n@@ -219,11 +249,9 @@ def __arrow_ext_serialize__(self):\n                 return b''\n \n             @classmethod\n-            def __arrow_ext_deserialize__(self, storage_type, serialized):\n+            def __arrow_ext_deserialize__(cls, storage_type, serialized):\n                 return UuidTypeWrong()\n \n-                pa.register_extension_type(UuidType())\n-\n         storage_array = pa.array(['pedro'], pa.binary(5))\n         my_type = MyType()\n         storage_array = my_type.wrap_array(storage_array)\n@@ -233,12 +261,10 @@ def __arrow_ext_deserialize__(self, storage_type, serialized):\n         with pytest.raises(duckdb.NotImplementedException, match=\" Arrow Type with extension name: pedro.binary\"):\n             duck_arrow = duckdb_cursor.execute('FROM arrow_table').arrow()\n \n-    def test_hugeint(self):\n-        duckdb_cursor = duckdb.connect()\n-\n-        duckdb_cursor.execute(\"SET arrow_lossless_conversion = true\")\n+    def test_hugeint(self, arrow_duckdb_hugeint):\n+        con = duckdb.connect()\n \n-        pa.register_extension_type(HugeIntType())\n+        con.execute(\"SET arrow_lossless_conversion = true\")\n \n         storage_array = pa.array([b'\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff'], pa.binary(16))\n         hugeint_type = HugeIntType()\n@@ -246,19 +272,15 @@ def test_hugeint(self):\n \n         arrow_table = pa.Table.from_arrays([storage_array], names=['numbers'])\n \n-        assert duckdb_cursor.execute('FROM arrow_table').fetchall() == [(-1,)]\n-\n-        assert duckdb_cursor.execute('FROM arrow_table').arrow().equals(arrow_table)\n+        assert con.execute('FROM arrow_table').fetchall() == [(-1,)]\n \n-        duckdb_cursor.execute(\"SET arrow_lossless_conversion = false\")\n+        assert con.execute('FROM arrow_table').arrow().equals(arrow_table)\n \n-        assert not duckdb_cursor.execute('FROM arrow_table').arrow().equals(arrow_table)\n+        con.execute(\"SET arrow_lossless_conversion = false\")\n \n-        pa.unregister_extension_type(\"duckdb.hugeint\")\n-\n-    def test_uhugeint(self, duckdb_cursor):\n-        pa.register_extension_type(UHugeIntType())\n+        assert not con.execute('FROM arrow_table').arrow().equals(arrow_table)\n \n+    def test_uhugeint(self, duckdb_cursor, arrow_duckdb_uhugeint):\n         storage_array = pa.array([b'\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff'], pa.binary(16))\n         uhugeint_type = UHugeIntType()\n         storage_array = uhugeint_type.wrap_array(storage_array)\n@@ -267,25 +289,23 @@ def test_uhugeint(self, duckdb_cursor):\n \n         assert duckdb_cursor.execute('FROM arrow_table').fetchall() == [(340282366920938463463374607431768211455,)]\n \n-        pa.unregister_extension_type(\"duckdb.uhugeint\")\n-\n     def test_bit(self):\n-        duckdb_cursor = duckdb.connect()\n+        con = duckdb.connect()\n \n-        res_blob = duckdb_cursor.execute(\"SELECT '0101011'::BIT str FROM range(5) tbl(i)\").arrow()\n+        res_blob = con.execute(\"SELECT '0101011'::BIT str FROM range(5) tbl(i)\").arrow()\n \n-        duckdb_cursor.execute(\"SET arrow_lossless_conversion = true\")\n+        con.execute(\"SET arrow_lossless_conversion = true\")\n \n-        res_bit = duckdb_cursor.execute(\"SELECT '0101011'::BIT str FROM range(5) tbl(i)\").arrow()\n+        res_bit = con.execute(\"SELECT '0101011'::BIT str FROM range(5) tbl(i)\").arrow()\n \n-        assert duckdb_cursor.execute(\"FROM res_blob\").fetchall() == [\n+        assert con.execute(\"FROM res_blob\").fetchall() == [\n             (b'\\x01\\xab',),\n             (b'\\x01\\xab',),\n             (b'\\x01\\xab',),\n             (b'\\x01\\xab',),\n             (b'\\x01\\xab',),\n         ]\n-        assert duckdb_cursor.execute(\"FROM res_bit\").fetchall() == [\n+        assert con.execute(\"FROM res_bit\").fetchall() == [\n             ('0101011',),\n             ('0101011',),\n             ('0101011',),\n@@ -294,15 +314,15 @@ def test_bit(self):\n         ]\n \n     def test_timetz(self):\n-        duckdb_cursor = duckdb.connect()\n+        con = duckdb.connect()\n \n-        res_time = duckdb_cursor.execute(\"SELECT '02:30:00+04'::TIMETZ str FROM range(1) tbl(i)\").arrow()\n+        res_time = con.execute(\"SELECT '02:30:00+04'::TIMETZ str FROM range(1) tbl(i)\").arrow()\n \n-        duckdb_cursor.execute(\"SET arrow_lossless_conversion = true\")\n+        con.execute(\"SET arrow_lossless_conversion = true\")\n \n-        res_tz = duckdb_cursor.execute(\"SELECT '02:30:00+04'::TIMETZ str FROM range(1) tbl(i)\").arrow()\n+        res_tz = con.execute(\"SELECT '02:30:00+04'::TIMETZ str FROM range(1) tbl(i)\").arrow()\n \n-        assert duckdb_cursor.execute(\"FROM res_time\").fetchall() == [(datetime.time(2, 30),)]\n-        assert duckdb_cursor.execute(\"FROM res_tz\").fetchall() == [\n+        assert con.execute(\"FROM res_time\").fetchall() == [(datetime.time(2, 30),)]\n+        assert con.execute(\"FROM res_tz\").fetchall() == [\n             (datetime.time(2, 30, tzinfo=datetime.timezone(datetime.timedelta(seconds=14400))),)\n         ]\ndiff --git a/tools/pythonpkg/tests/fast/arrow/test_polars.py b/tools/pythonpkg/tests/fast/arrow/test_polars.py\nindex 78c74564e091..7a2ae5008f0a 100644\n--- a/tools/pythonpkg/tests/fast/arrow/test_polars.py\n+++ b/tools/pythonpkg/tests/fast/arrow/test_polars.py\n@@ -57,3 +57,19 @@ def test_empty_polars_dataframe(self, duckdb_cursor):\n             duckdb.InvalidInputException, match='Provided table/dataframe must have at least one column'\n         ):\n             duckdb_cursor.sql(\"from polars_empty_df\")\n+\n+    def test_polars_from_json(self, duckdb_cursor):\n+        from io import StringIO\n+\n+        duckdb_cursor.sql(\"set arrow_lossless_conversion=false\")\n+        string = StringIO(\"\"\"{\"entry\":[{\"content\":{\"ManagedSystem\":{\"test\":null}}}]}\"\"\")\n+        res = duckdb_cursor.read_json(string).pl()\n+        assert str(res['entry'][0][0]) == \"{'content': {'ManagedSystem': {'test': None}}}\"\n+\n+    def test_polars_from_json_error(self, duckdb_cursor):\n+        from io import StringIO\n+\n+        duckdb_cursor.sql(\"set arrow_lossless_conversion=true\")\n+        string = StringIO(\"\"\"{\"entry\":[{\"content\":{\"ManagedSystem\":{\"test\":null}}}]}\"\"\")\n+        with pytest.raises(pl.exceptions.PanicException):\n+            res = duckdb_cursor.read_json(string).pl()\n",
  "problem_statement": "Arrow datatype Extension(\"arrow.json\", Utf8, Some(\"\")) not supported by Polars exception\n### What happens?\r\n\r\nwith duckdb 1.1.0 I get the following error when selecting over a json file. multiple different json files. also some json files work.\r\n\r\n`pyo3_runtime.PanicException: Arrow datatype Extension(\"arrow.json\", Utf8, Some(\"\")) not supported by Polars. You probably need to activate that data-type feature.`\r\n\r\nwith duckdb 1.0.0 everything works fine\r\n\r\n### To Reproduce\r\n\r\n```\r\nimport duckdb\r\nduckdb.sql(\"SELECT unnest(entry, recursive := true) FROM read_json_auto('test.json', filename=true)\").pl()\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu 22.04\r\n\r\n### DuckDB Version:\r\n\r\n1.1.0\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nDaniel Gut\r\n\r\n### Affiliation:\r\n\r\nAveniq\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nNo - I cannot share the data sets because they are confidential\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [ ] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "Hi @OneCyrus, thanks for reporting this issue. Is there a chance you can reduce the confidential data set to a non-confidential reproducer? That would go help a lot in getting this resolved.\n@szarnyasg looks like the issue is with the null property.\r\n\r\ni reduced the dataset to the following:\r\n\r\n```\r\n{\r\n    \"entry\": [\r\n        {\r\n            \"content\": {\r\n                \"ManagedSystem\": {\r\n                    \"test\": null\r\n                }\r\n            }\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\n```\r\nfrom duckdb import connect\r\n\r\ndb = connect(\":memory:\")\r\ntest = db.sql(\r\n    \"SELECT entry FROM read_json_auto('test.json', filename=true)\"\r\n).pl()\r\n```\nThanks, what's the Polars version?\nI can reproduce it \ud83d\udc4d \r\n\r\n```\r\n\u279c  duckdb git:(main) \u2717 python3 tmp/polars_json2.py\r\nthread '<unnamed>' panicked at crates/polars-core/src/datatypes/field.rs:189:19:\r\nArrow datatype Extension(\"arrow.json\", Utf8, Some(\"\")) not supported by Polars. You probably need to activate that data-type feature.\r\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\r\nTraceback (most recent call last):\r\n  File \"/Users/thijs/DuckDBLabs/duckdb/tmp/polars_json2.py\", line 6, in <module>\r\n    ).pl()\r\n      ^^^^\r\n  File \"/Users/thijs/.pyenv/versions/3.12.1/lib/python3.12/site-packages/polars/dataframe/frame.py\", line 394, in __init__\r\n    self._df = arrow_to_pydf(\r\n               ^^^^^^^^^^^^^^\r\n  File \"/Users/thijs/.pyenv/versions/3.12.1/lib/python3.12/site-packages/polars/_utils/construction/dataframe.py\", line 1209, in arrow_to_pydf\r\n    pydf = PyDataFrame.from_arrow_record_batches(tbl.to_batches())\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\npyo3_runtime.PanicException: Arrow datatype Extension(\"arrow.json\", Utf8, Some(\"\")) not supported by Polars. You probably need to activate that data-type feature.\r\n```\r\n\r\n```\r\n>>> import polars\r\n>>> polars.__version__\r\n'1.5.0'\r\n```\nfirst had the same issue as above with arrow.uuid instead of arrow.json. but can't reproduce it now. but now i have a consistent issue which shows the following polars type exception.\r\n\r\n```\r\nArrow datatype Map(Field { name: \"entries\", dtype: Struct([Field { name: \"key\", dtype: Utf8, is_nullable: false, metadata: {} }, Field { name: \"value\", dtype: Utf8, is_nullable: true, metadata: {} }]), is_nullable: false, metadata: {} }, false) not supported by Polars. You probably need to activate that data-type feature.\r\n```\n@Tishj ok, got a reproduction with an empty object\r\n\r\n```\r\n[\r\n    {\r\n        \"ipspace\": {\r\n            \"_links\": {}\r\n        }\r\n    }\r\n]\r\n```\r\n\r\n```\r\nthread 'polars-0' panicked at crates/polars-core/src/datatypes/field.rs:188:19:\r\nArrow datatype Map(Field { name: \"entries\", dtype: Struct([Field { name: \"key\", dtype: Utf8, is_nullable: false, metadata: {} }, Field { name: \"value\", dtype: Utf8, is_nullable: true, metadata: {} }]), is_nullable: false, metadata: {} }, false) not supported by Polars. You probably need to activate that data-type feature.\r\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 6, in <module>\r\n    ).pl()\r\n      ^^^^\r\n  File \"/workspaces/automation-data/.venv/lib/python3.11/site-packages/polars/dataframe/frame.py\", line 395, in __init__\r\n    self._df = arrow_to_pydf(\r\n               ^^^^^^^^^^^^^^\r\n  File \"/workspaces/automation-data/.venv/lib/python3.11/site-packages/polars/_utils/construction/dataframe.py\", line 1209, in arrow_to_pydf\r\n    pydf = PyDataFrame.from_arrow_record_batches(tbl.to_batches())\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\npyo3_runtime.PanicException: Arrow datatype Map(Field { name: \"entries\", dtype: Struct([Field { name: \"key\", dtype: Utf8, is_nullable: false, metadata: {} }, Field { name: \"value\", dtype: Utf8, is_nullable: true, metadata: {} }]), is_nullable: false, metadata: {} }, false) not supported by Polars. You probably need to activate that data-type feature.\r\n```",
  "created_at": "2024-09-17T11:51:26Z"
}