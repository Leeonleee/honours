You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
Arrow datatype Extension("arrow.json", Utf8, Some("")) not supported by Polars exception
### What happens?

with duckdb 1.1.0 I get the following error when selecting over a json file. multiple different json files. also some json files work.

`pyo3_runtime.PanicException: Arrow datatype Extension("arrow.json", Utf8, Some("")) not supported by Polars. You probably need to activate that data-type feature.`

with duckdb 1.0.0 everything works fine

### To Reproduce

```
import duckdb
duckdb.sql("SELECT unnest(entry, recursive := true) FROM read_json_auto('test.json', filename=true)").pl()
```

### OS:

Ubuntu 22.04

### DuckDB Version:

1.1.0

### DuckDB Client:

Python

### Hardware:

_No response_

### Full Name:

Daniel Gut

### Affiliation:

Aveniq

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

No - I cannot share the data sets because they are confidential

### Did you include all code required to reproduce the issue?

- [ ] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of src/common/arrow/arrow_converter.cpp]
1: #include "duckdb/common/types/data_chunk.hpp"
2: #include "duckdb/common/types/bit.hpp"
3: #include "duckdb/common/arrow/arrow.hpp"
4: #include "duckdb/common/arrow/arrow_converter.hpp"
5: #include "duckdb/common/exception.hpp"
6: #include "duckdb/common/helper.hpp"
7: #include "duckdb/common/types/interval.hpp"
8: #include "duckdb/common/types/sel_cache.hpp"
9: #include "duckdb/common/types/vector_cache.hpp"
10: #include "duckdb/common/unordered_map.hpp"
11: #include "duckdb/common/vector.hpp"
12: #include <list>
13: #include "duckdb/common/arrow/arrow_appender.hpp"
14: #include "duckdb/common/arrow/schema_metadata.hpp"
15: 
16: namespace duckdb {
17: 
18: void ArrowConverter::ToArrowArray(DataChunk &input, ArrowArray *out_array, ClientProperties options) {
19: 	ArrowAppender appender(input.GetTypes(), input.size(), std::move(options));
20: 	appender.Append(input, 0, input.size(), input.size());
21: 	*out_array = appender.Finalize();
22: }
23: 
24: unsafe_unique_array<char> AddName(const string &name) {
25: 	auto name_ptr = make_unsafe_uniq_array<char>(name.size() + 1);
26: 	for (size_t i = 0; i < name.size(); i++) {
27: 		name_ptr[i] = name[i];
28: 	}
29: 	name_ptr[name.size()] = '\0';
30: 	return name_ptr;
31: }
32: 
33: //===--------------------------------------------------------------------===//
34: // Arrow Schema
35: //===--------------------------------------------------------------------===//
36: struct DuckDBArrowSchemaHolder {
37: 	// unused in children
38: 	vector<ArrowSchema> children;
39: 	// unused in children
40: 	vector<ArrowSchema *> children_ptrs;
41: 	//! used for nested structures
42: 	std::list<vector<ArrowSchema>> nested_children;
43: 	std::list<vector<ArrowSchema *>> nested_children_ptr;
44: 	//! This holds strings created to represent decimal types
45: 	vector<unsafe_unique_array<char>> owned_type_names;
46: 	vector<unsafe_unique_array<char>> owned_column_names;
47: 	//! This holds any values created for metadata info
48: 	vector<unsafe_unique_array<char>> metadata_info;
49: };
50: 
51: static void ReleaseDuckDBArrowSchema(ArrowSchema *schema) {
52: 	if (!schema || !schema->release) {
53: 		return;
54: 	}
55: 	schema->release = nullptr;
56: 	auto holder = static_cast<DuckDBArrowSchemaHolder *>(schema->private_data);
57: 	delete holder;
58: }
59: 
60: void InitializeChild(ArrowSchema &child, DuckDBArrowSchemaHolder &root_holder, const string &name = "") {
61: 	//! Child is cleaned up by parent
62: 	child.private_data = nullptr;
63: 	child.release = ReleaseDuckDBArrowSchema;
64: 
65: 	// Store the child schema
66: 	child.flags = ARROW_FLAG_NULLABLE;
67: 	root_holder.owned_type_names.push_back(AddName(name));
68: 
69: 	child.name = root_holder.owned_type_names.back().get();
70: 	child.n_children = 0;
71: 	child.children = nullptr;
72: 	child.metadata = nullptr;
73: 	child.dictionary = nullptr;
74: }
75: 
76: void SetArrowFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, const LogicalType &type,
77:                     const ClientProperties &options);
78: 
79: void SetArrowMapFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, const LogicalType &type,
80:                        const ClientProperties &options) {
81: 	child.format = "+m";
82: 	//! Map has one child which is a struct
83: 	child.n_children = 1;
84: 	root_holder.nested_children.emplace_back();
85: 	root_holder.nested_children.back().resize(1);
86: 	root_holder.nested_children_ptr.emplace_back();
87: 	root_holder.nested_children_ptr.back().push_back(&root_holder.nested_children.back()[0]);
88: 	InitializeChild(root_holder.nested_children.back()[0], root_holder);
89: 	child.children = &root_holder.nested_children_ptr.back()[0];
90: 	child.children[0]->name = "entries";
91: 	SetArrowFormat(root_holder, **child.children, ListType::GetChildType(type), options);
92: }
93: 
94: void SetArrowFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, const LogicalType &type,
95:                     const ClientProperties &options) {
96: 	switch (type.id()) {
97: 	case LogicalTypeId::BOOLEAN:
98: 		child.format = "b";
99: 		break;
100: 	case LogicalTypeId::TINYINT:
101: 		child.format = "c";
102: 		break;
103: 	case LogicalTypeId::SMALLINT:
104: 		child.format = "s";
105: 		break;
106: 	case LogicalTypeId::INTEGER:
107: 		child.format = "i";
108: 		break;
109: 	case LogicalTypeId::BIGINT:
110: 		child.format = "l";
111: 		break;
112: 	case LogicalTypeId::UTINYINT:
113: 		child.format = "C";
114: 		break;
115: 	case LogicalTypeId::USMALLINT:
116: 		child.format = "S";
117: 		break;
118: 	case LogicalTypeId::UINTEGER:
119: 		child.format = "I";
120: 		break;
121: 	case LogicalTypeId::UBIGINT:
122: 		child.format = "L";
123: 		break;
124: 	case LogicalTypeId::FLOAT:
125: 		child.format = "f";
126: 		break;
127: 	case LogicalTypeId::HUGEINT: {
128: 		if (options.arrow_lossless_conversion) {
129: 			child.format = "w:16";
130: 			auto schema_metadata = ArrowSchemaMetadata::MetadataFromName("duckdb.hugeint");
131: 			root_holder.metadata_info.emplace_back(schema_metadata.SerializeMetadata());
132: 			child.metadata = root_holder.metadata_info.back().get();
133: 		} else {
134: 			child.format = "d:38,0";
135: 		}
136: 		break;
137: 	}
138: 	case LogicalTypeId::UHUGEINT: {
139: 		child.format = "w:16";
140: 		auto schema_metadata = ArrowSchemaMetadata::MetadataFromName("duckdb.uhugeint");
141: 		root_holder.metadata_info.emplace_back(schema_metadata.SerializeMetadata());
142: 		child.metadata = root_holder.metadata_info.back().get();
143: 		break;
144: 	}
145: 	case LogicalTypeId::DOUBLE:
146: 		child.format = "g";
147: 		break;
148: 	case LogicalTypeId::UUID: {
149: 		if (options.arrow_lossless_conversion) {
150: 			// This is a canonical extension, hence needs the "arrow." prefix
151: 			child.format = "w:16";
152: 			auto schema_metadata = ArrowSchemaMetadata::MetadataFromName("arrow.uuid");
153: 			root_holder.metadata_info.emplace_back(schema_metadata.SerializeMetadata());
154: 			child.metadata = root_holder.metadata_info.back().get();
155: 		} else {
156: 			if (options.produce_arrow_string_view) {
157: 				child.format = "vu";
158: 			} else {
159: 				if (options.arrow_offset_size == ArrowOffsetSize::LARGE) {
160: 					child.format = "U";
161: 				} else {
162: 					child.format = "u";
163: 				}
164: 			}
165: 		}
166: 		break;
167: 	}
168: 	case LogicalTypeId::VARCHAR:
169: 		if (type.IsJSONType()) {
170: 			auto schema_metadata = ArrowSchemaMetadata::MetadataFromName("arrow.json");
171: 			root_holder.metadata_info.emplace_back(schema_metadata.SerializeMetadata());
172: 			child.metadata = root_holder.metadata_info.back().get();
173: 		}
174: 		if (options.produce_arrow_string_view) {
175: 			child.format = "vu";
176: 		} else {
177: 			if (options.arrow_offset_size == ArrowOffsetSize::LARGE) {
178: 				child.format = "U";
179: 			} else {
180: 				child.format = "u";
181: 			}
182: 		}
183: 		break;
184: 	case LogicalTypeId::DATE:
185: 		child.format = "tdD";
186: 		break;
187: 	case LogicalTypeId::TIME_TZ: {
188: 		if (options.arrow_lossless_conversion) {
189: 			child.format = "w:8";
190: 			auto schema_metadata = ArrowSchemaMetadata::MetadataFromName("duckdb.time_tz");
191: 			root_holder.metadata_info.emplace_back(schema_metadata.SerializeMetadata());
192: 			child.metadata = root_holder.metadata_info.back().get();
193: 		} else {
194: 			child.format = "ttu";
195: 		}
196: 		break;
197: 	}
198: 	case LogicalTypeId::TIME:
199: 		child.format = "ttu";
200: 		break;
201: 	case LogicalTypeId::TIMESTAMP:
202: 		child.format = "tsu:";
203: 		break;
204: 	case LogicalTypeId::TIMESTAMP_TZ: {
205: 		string format = "tsu:" + options.time_zone;
206: 		root_holder.owned_type_names.push_back(AddName(format));
207: 		child.format = root_holder.owned_type_names.back().get();
208: 		break;
209: 	}
210: 	case LogicalTypeId::TIMESTAMP_SEC:
211: 		child.format = "tss:";
212: 		break;
213: 	case LogicalTypeId::TIMESTAMP_NS:
214: 		child.format = "tsn:";
215: 		break;
216: 	case LogicalTypeId::TIMESTAMP_MS:
217: 		child.format = "tsm:";
218: 		break;
219: 	case LogicalTypeId::INTERVAL:
220: 		child.format = "tin";
221: 		break;
222: 	case LogicalTypeId::DECIMAL: {
223: 		uint8_t width, scale;
224: 		type.GetDecimalProperties(width, scale);
225: 		string format = "d:" + to_string(width) + "," + to_string(scale);
226: 		root_holder.owned_type_names.push_back(AddName(format));
227: 		child.format = root_holder.owned_type_names.back().get();
228: 		break;
229: 	}
230: 	case LogicalTypeId::SQLNULL: {
231: 		child.format = "n";
232: 		break;
233: 	}
234: 	case LogicalTypeId::BLOB:
235: 		if (options.arrow_offset_size == ArrowOffsetSize::LARGE) {
236: 			child.format = "Z";
237: 		} else {
238: 			child.format = "z";
239: 		}
240: 		break;
241: 	case LogicalTypeId::BIT: {
242: 		if (options.arrow_offset_size == ArrowOffsetSize::LARGE) {
243: 			child.format = "Z";
244: 		} else {
245: 			child.format = "z";
246: 		}
247: 		if (options.arrow_lossless_conversion) {
248: 			auto schema_metadata = ArrowSchemaMetadata::MetadataFromName("duckdb.bit");
249: 			root_holder.metadata_info.emplace_back(schema_metadata.SerializeMetadata());
250: 			child.metadata = root_holder.metadata_info.back().get();
251: 		}
252: 		break;
253: 	}
254: 	case LogicalTypeId::LIST: {
255: 		if (options.arrow_use_list_view) {
256: 			if (options.arrow_offset_size == ArrowOffsetSize::LARGE) {
257: 				child.format = "+vL";
258: 			} else {
259: 				child.format = "+vl";
260: 			}
261: 		} else {
262: 			if (options.arrow_offset_size == ArrowOffsetSize::LARGE) {
263: 				child.format = "+L";
264: 			} else {
265: 				child.format = "+l";
266: 			}
267: 		}
268: 		child.n_children = 1;
269: 		root_holder.nested_children.emplace_back();
270: 		root_holder.nested_children.back().resize(1);
271: 		root_holder.nested_children_ptr.emplace_back();
272: 		root_holder.nested_children_ptr.back().push_back(&root_holder.nested_children.back()[0]);
273: 		InitializeChild(root_holder.nested_children.back()[0], root_holder);
274: 		child.children = &root_holder.nested_children_ptr.back()[0];
275: 		child.children[0]->name = "l";
276: 		SetArrowFormat(root_holder, **child.children, ListType::GetChildType(type), options);
277: 		break;
278: 	}
279: 	case LogicalTypeId::STRUCT: {
280: 		child.format = "+s";
281: 		auto &child_types = StructType::GetChildTypes(type);
282: 		child.n_children = NumericCast<int64_t>(child_types.size());
283: 		root_holder.nested_children.emplace_back();
284: 		root_holder.nested_children.back().resize(child_types.size());
285: 		root_holder.nested_children_ptr.emplace_back();
286: 		root_holder.nested_children_ptr.back().resize(child_types.size());
287: 		for (idx_t type_idx = 0; type_idx < child_types.size(); type_idx++) {
288: 			root_holder.nested_children_ptr.back()[type_idx] = &root_holder.nested_children.back()[type_idx];
289: 		}
290: 		child.children = &root_holder.nested_children_ptr.back()[0];
291: 		for (size_t type_idx = 0; type_idx < child_types.size(); type_idx++) {
292: 
293: 			InitializeChild(*child.children[type_idx], root_holder);
294: 
295: 			root_holder.owned_type_names.push_back(AddName(child_types[type_idx].first));
296: 
297: 			child.children[type_idx]->name = root_holder.owned_type_names.back().get();
298: 			SetArrowFormat(root_holder, *child.children[type_idx], child_types[type_idx].second, options);
299: 		}
300: 		break;
301: 	}
302: 	case LogicalTypeId::ARRAY: {
303: 		auto array_size = ArrayType::GetSize(type);
304: 		auto &child_type = ArrayType::GetChildType(type);
305: 		auto format = "+w:" + to_string(array_size);
306: 		root_holder.owned_type_names.push_back(AddName(format));
307: 		child.format = root_holder.owned_type_names.back().get();
308: 
309: 		child.n_children = 1;
310: 		root_holder.nested_children.emplace_back();
311: 		root_holder.nested_children.back().resize(1);
312: 		root_holder.nested_children_ptr.emplace_back();
313: 		root_holder.nested_children_ptr.back().push_back(&root_holder.nested_children.back()[0]);
314: 		InitializeChild(root_holder.nested_children.back()[0], root_holder);
315: 		child.children = &root_holder.nested_children_ptr.back()[0];
316: 		SetArrowFormat(root_holder, **child.children, child_type, options);
317: 		break;
318: 	}
319: 	case LogicalTypeId::MAP: {
320: 		SetArrowMapFormat(root_holder, child, type, options);
321: 		break;
322: 	}
323: 	case LogicalTypeId::UNION: {
324: 		std::string format = "+us:";
325: 
326: 		auto &child_types = UnionType::CopyMemberTypes(type);
327: 		child.n_children = NumericCast<int64_t>(child_types.size());
328: 		root_holder.nested_children.emplace_back();
329: 		root_holder.nested_children.back().resize(child_types.size());
330: 		root_holder.nested_children_ptr.emplace_back();
331: 		root_holder.nested_children_ptr.back().resize(child_types.size());
332: 		for (idx_t type_idx = 0; type_idx < child_types.size(); type_idx++) {
333: 			root_holder.nested_children_ptr.back()[type_idx] = &root_holder.nested_children.back()[type_idx];
334: 		}
335: 		child.children = &root_holder.nested_children_ptr.back()[0];
336: 		for (size_t type_idx = 0; type_idx < child_types.size(); type_idx++) {
337: 
338: 			InitializeChild(*child.children[type_idx], root_holder);
339: 
340: 			root_holder.owned_type_names.push_back(AddName(child_types[type_idx].first));
341: 
342: 			child.children[type_idx]->name = root_holder.owned_type_names.back().get();
343: 			SetArrowFormat(root_holder, *child.children[type_idx], child_types[type_idx].second, options);
344: 
345: 			format += to_string(type_idx) + ",";
346: 		}
347: 
348: 		format.pop_back();
349: 
350: 		root_holder.owned_type_names.push_back(AddName(format));
351: 		child.format = root_holder.owned_type_names.back().get();
352: 
353: 		break;
354: 	}
355: 	case LogicalTypeId::ENUM: {
356: 		// TODO what do we do with pointer enums here?
357: 		switch (EnumType::GetPhysicalType(type)) {
358: 		case PhysicalType::UINT8:
359: 			child.format = "C";
360: 			break;
361: 		case PhysicalType::UINT16:
362: 			child.format = "S";
363: 			break;
364: 		case PhysicalType::UINT32:
365: 			child.format = "I";
366: 			break;
367: 		default:
368: 			throw InternalException("Unsupported Enum Internal Type");
369: 		}
370: 		root_holder.nested_children.emplace_back();
371: 		root_holder.nested_children.back().resize(1);
372: 		root_holder.nested_children_ptr.emplace_back();
373: 		root_holder.nested_children_ptr.back().push_back(&root_holder.nested_children.back()[0]);
374: 		InitializeChild(root_holder.nested_children.back()[0], root_holder);
375: 		child.dictionary = root_holder.nested_children_ptr.back()[0];
376: 		child.dictionary->format = "u";
377: 		break;
378: 	}
379: 	default:
380: 		throw NotImplementedException("Unsupported Arrow type " + type.ToString());
381: 	}
382: }
383: 
384: void ArrowConverter::ToArrowSchema(ArrowSchema *out_schema, const vector<LogicalType> &types,
385:                                    const vector<string> &names, const ClientProperties &options) {
386: 	D_ASSERT(out_schema);
387: 	D_ASSERT(types.size() == names.size());
388: 	idx_t column_count = types.size();
389: 	// Allocate as unique_ptr first to cleanup properly on error
390: 	auto root_holder = make_uniq<DuckDBArrowSchemaHolder>();
391: 
392: 	// Allocate the children
393: 	root_holder->children.resize(column_count);
394: 	root_holder->children_ptrs.resize(column_count, nullptr);
395: 	for (size_t i = 0; i < column_count; ++i) {
396: 		root_holder->children_ptrs[i] = &root_holder->children[i];
397: 	}
398: 	out_schema->children = root_holder->children_ptrs.data();
399: 	out_schema->n_children = NumericCast<int64_t>(column_count);
400: 
401: 	// Store the schema
402: 	out_schema->format = "+s"; // struct apparently
403: 	out_schema->flags = 0;
404: 	out_schema->metadata = nullptr;
405: 	out_schema->name = "duckdb_query_result";
406: 	out_schema->dictionary = nullptr;
407: 
408: 	// Configure all child schemas
409: 	for (idx_t col_idx = 0; col_idx < column_count; col_idx++) {
410: 		root_holder->owned_column_names.push_back(AddName(names[col_idx]));
411: 		auto &child = root_holder->children[col_idx];
412: 		InitializeChild(child, *root_holder, names[col_idx]);
413: 		SetArrowFormat(*root_holder, child, types[col_idx], options);
414: 	}
415: 
416: 	// Release ownership to caller
417: 	out_schema->private_data = root_holder.release();
418: 	out_schema->release = ReleaseDuckDBArrowSchema;
419: }
420: 
421: } // namespace duckdb
[end of src/common/arrow/arrow_converter.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: