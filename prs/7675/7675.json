{
  "repo": "duckdb/duckdb",
  "pull_number": 7675,
  "instance_id": "duckdb__duckdb-7675",
  "issue_numbers": [
    "7659",
    "7659"
  ],
  "base_commit": "aac029220ae28679b98bfbb68cdee5572ecfcccf",
  "patch": "diff --git a/src/catalog/catalog.cpp b/src/catalog/catalog.cpp\nindex 34ce7a8eb946..3ae3fd7002bc 100644\n--- a/src/catalog/catalog.cpp\n+++ b/src/catalog/catalog.cpp\n@@ -674,19 +674,6 @@ vector<reference<SchemaCatalogEntry>> Catalog::GetSchemas(ClientContext &context\n \treturn schemas;\n }\n \n-bool Catalog::TypeExists(ClientContext &context, const string &catalog_name, const string &schema, const string &name) {\n-\toptional_ptr<CatalogEntry> entry;\n-\tentry = GetEntry(context, CatalogType::TYPE_ENTRY, catalog_name, schema, name, OnEntryNotFound::RETURN_NULL);\n-\tif (!entry) {\n-\t\t// look in the system catalog\n-\t\tentry = GetEntry(context, CatalogType::TYPE_ENTRY, SYSTEM_CATALOG, schema, name, OnEntryNotFound::RETURN_NULL);\n-\t\tif (!entry) {\n-\t\t\treturn false;\n-\t\t}\n-\t}\n-\treturn true;\n-}\n-\n vector<reference<SchemaCatalogEntry>> Catalog::GetSchemas(ClientContext &context, const string &catalog_name) {\n \tvector<reference<Catalog>> catalogs;\n \tif (IsInvalidCatalog(catalog_name)) {\ndiff --git a/src/include/duckdb/catalog/catalog.hpp b/src/include/duckdb/catalog/catalog.hpp\nindex 5881f9cffa48..51f9ab782275 100644\n--- a/src/include/duckdb/catalog/catalog.hpp\n+++ b/src/include/duckdb/catalog/catalog.hpp\n@@ -229,9 +229,6 @@ class Catalog {\n \tDUCKDB_API static LogicalType GetType(ClientContext &context, const string &catalog_name, const string &schema,\n \t                                      const string &name);\n \n-\tstatic bool TypeExists(ClientContext &context, const string &catalog_name, const string &schema,\n-\t                       const string &name);\n-\n \ttemplate <class T>\n \toptional_ptr<T> GetEntry(ClientContext &context, const string &schema_name, const string &name,\n \t                         OnEntryNotFound if_not_found, QueryErrorContext error_context = QueryErrorContext()) {\ndiff --git a/src/parser/column_definition.cpp b/src/parser/column_definition.cpp\nindex b4bc1c548c0d..a163832b3c35 100644\n--- a/src/parser/column_definition.cpp\n+++ b/src/parser/column_definition.cpp\n@@ -50,6 +50,7 @@ void ColumnDefinition::Serialize(Serializer &serializer) const {\n \t\twriter.WriteOptional(default_value);\n \t}\n \twriter.WriteField<TableColumnType>(category);\n+\twriter.WriteField<duckdb::CompressionType>(compression_type);\n \twriter.Finalize();\n }\n \n@@ -59,16 +60,12 @@ ColumnDefinition ColumnDefinition::Deserialize(Deserializer &source) {\n \tauto column_type = reader.ReadRequiredSerializable<LogicalType, LogicalType>();\n \tauto expression = reader.ReadOptional<ParsedExpression>(nullptr);\n \tauto category = reader.ReadField<TableColumnType>(TableColumnType::STANDARD);\n+\tauto compression_type = reader.ReadField<duckdb::CompressionType>(duckdb::CompressionType::COMPRESSION_AUTO);\n \treader.Finalize();\n \n-\tswitch (category) {\n-\tcase TableColumnType::STANDARD:\n-\t\treturn ColumnDefinition(column_name, column_type, std::move(expression), TableColumnType::STANDARD);\n-\tcase TableColumnType::GENERATED:\n-\t\treturn ColumnDefinition(column_name, column_type, std::move(expression), TableColumnType::GENERATED);\n-\tdefault:\n-\t\tthrow NotImplementedException(\"Type not implemented for TableColumnType\");\n-\t}\n+\tColumnDefinition result(column_name, column_type, std::move(expression), category);\n+\tresult.compression_type = compression_type;\n+\treturn result;\n }\n \n const unique_ptr<ParsedExpression> &ColumnDefinition::DefaultValue() const {\ndiff --git a/src/storage/data_table.cpp b/src/storage/data_table.cpp\nindex 98906885a539..121c0b1aa081 100644\n--- a/src/storage/data_table.cpp\n+++ b/src/storage/data_table.cpp\n@@ -1201,13 +1201,14 @@ void DataTable::WALAddIndex(ClientContext &context, unique_ptr<Index> index,\n \t// intermediate holds scanned chunks of the underlying data to create the index\n \tDataChunk intermediate;\n \tvector<LogicalType> intermediate_types;\n-\tauto column_ids = index->column_ids;\n-\tcolumn_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);\n-\tfor (auto &id : index->column_ids) {\n-\t\tauto &col = column_definitions[id];\n-\t\tintermediate_types.push_back(col.Type());\n+\tvector<column_t> column_ids;\n+\tfor (auto &it : column_definitions) {\n+\t\tintermediate_types.push_back(it.Type());\n+\t\tcolumn_ids.push_back(it.Oid());\n \t}\n+\tcolumn_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);\n \tintermediate_types.emplace_back(LogicalType::ROW_TYPE);\n+\n \tintermediate.Initialize(allocator, intermediate_types);\n \n \t// holds the result of executing the index expression on the intermediate chunks\ndiff --git a/src/storage/wal_replay.cpp b/src/storage/wal_replay.cpp\nindex 0809cc93ac5e..4b1f54c7d7b0 100644\n--- a/src/storage/wal_replay.cpp\n+++ b/src/storage/wal_replay.cpp\n@@ -195,15 +195,16 @@ void ReplayState::ReplayEntry(WALType entry_type) {\n // Replay Table\n //===--------------------------------------------------------------------===//\n void ReplayState::ReplayCreateTable() {\n-\n \tauto info = TableCatalogEntry::Deserialize(source, context);\n \tif (deserialize_only) {\n \t\treturn;\n \t}\n \n \t// bind the constraints to the table again\n+\n \tauto binder = Binder::CreateBinder(context);\n-\tauto bound_info = binder->BindCreateTableInfo(std::move(info));\n+\tauto &schema = catalog.GetSchema(context, info->schema);\n+\tauto bound_info = binder->BindCreateTableInfo(std::move(info), schema);\n \n \tcatalog.CreateTable(context, *bound_info);\n }\n@@ -282,9 +283,7 @@ void ReplayState::ReplayDropSchema() {\n //===--------------------------------------------------------------------===//\n void ReplayState::ReplayCreateType() {\n \tauto info = TypeCatalogEntry::Deserialize(source);\n-\tif (Catalog::TypeExists(context, info->catalog, info->schema, info->name)) {\n-\t\treturn;\n-\t}\n+\tinfo->on_conflict = OnCreateConflict::IGNORE_ON_CONFLICT;\n \tcatalog.CreateType(context, *info);\n }\n \n",
  "test_patch": "diff --git a/test/helpers/test_helpers.cpp b/test/helpers/test_helpers.cpp\nindex 265e7a4153cf..8355ad54cd4c 100644\n--- a/test/helpers/test_helpers.cpp\n+++ b/test/helpers/test_helpers.cpp\n@@ -131,7 +131,11 @@ bool TestIsInternalError(unordered_set<string> &internal_error_messages, const s\n \n unique_ptr<DBConfig> GetTestConfig() {\n \tauto result = make_uniq<DBConfig>();\n+#ifndef DUCKDB_ALTERNATIVE_VERIFY\n \tresult->options.checkpoint_wal_size = 0;\n+#else\n+\tresult->options.checkpoint_on_shutdown = false;\n+#endif\n \tresult->options.allow_unsigned_extensions = true;\n \tif (single_threaded) {\n \t\tresult->options.maximum_threads = 1;\ndiff --git a/test/sql/attach/attach_different_alias.test b/test/sql/attach/attach_different_alias.test\nnew file mode 100644\nindex 000000000000..40a2bc9acecb\n--- /dev/null\n+++ b/test/sql/attach/attach_different_alias.test\n@@ -0,0 +1,30 @@\n+# name: test/sql/attach/attach_different_alias.test\n+# description: Test ATTACH of a database with a different alias\n+# group: [attach]\n+\n+require noforcestorage\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+ATTACH '__TEST_DIR__/attach_alias.db' AS alias1\n+\n+statement ok\n+create table alias1.tbl1 as select 1 as a;\n+\n+query I\n+FROM alias1.tbl1\n+----\n+1\n+\n+statement ok\n+DETACH alias1\n+\n+statement ok\n+ATTACH '__TEST_DIR__/attach_alias.db' AS alias2\n+\n+query I\n+FROM alias2.tbl1\n+----\n+1\ndiff --git a/test/sql/create/create_table_compression.test b/test/sql/create/create_table_compression.test\nindex 732bd0c85015..a0bd8fbb933a 100644\n--- a/test/sql/create/create_table_compression.test\n+++ b/test/sql/create/create_table_compression.test\n@@ -76,6 +76,9 @@ SELECT * FROM T\n 2\t2\t2\n 3\t3\t3\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT compression FROM pragma_storage_info('T') WHERE segment_type ILIKE 'INTEGER' LIMIT 3\n ----\n@@ -174,6 +177,9 @@ SELECT * FROM T_1\n 2\t2\n 3\t2\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT compression FROM pragma_storage_info('T_1') WHERE segment_type ILIKE 'INTEGER' LIMIT 3\n ----\ndiff --git a/test/sql/pragma/test_pragma_database_size.test b/test/sql/pragma/test_pragma_database_size.test\nindex f0eaca17670d..58af329cdb96 100644\n--- a/test/sql/pragma/test_pragma_database_size.test\n+++ b/test/sql/pragma/test_pragma_database_size.test\n@@ -16,6 +16,9 @@ CREATE TABLE db1.integers AS FROM range(1000000);\n statement ok\n DROP TABLE db1.integers\n \n+statement ok\n+CHECKPOINT db1\n+\n query I\n SELECT free_blocks>0 FROM pragma_database_size() WHERE database_name='db1';\n ----\ndiff --git a/test/sql/storage/compression/bitpacking/bitpacking_index_fetch.test b/test/sql/storage/compression/bitpacking/bitpacking_index_fetch.test\nindex 236e54fe7882..b8b59ec51612 100644\n--- a/test/sql/storage/compression/bitpacking/bitpacking_index_fetch.test\n+++ b/test/sql/storage/compression/bitpacking/bitpacking_index_fetch.test\n@@ -27,13 +27,13 @@ INSERT INTO test SELECT i::VARCHAR id, 1337 FROM range(10000, 20000) tbl(i)\n statement ok\n INSERT INTO test SELECT i::VARCHAR id, i b FROM range(20000, 30000) tbl(i)\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT compression FROM pragma_storage_info('test') WHERE segment_type ILIKE 'INTEGER' and compression != 'BitPacking'\n ----\n \n-statement ok\n-CHECKPOINT\n-\n query IIIIII\n SELECT MIN(id), MAX(id), SUM(col), MIN(col), MAX(col), COUNT(*) FROM test WHERE id='5000'\n ----\ndiff --git a/test/sql/storage/compression/bitpacking/bitpacking_storage_info.test b/test/sql/storage/compression/bitpacking/bitpacking_storage_info.test\nindex 5ca2e5d6b9be..18fee0b50160 100644\n--- a/test/sql/storage/compression/bitpacking/bitpacking_storage_info.test\n+++ b/test/sql/storage/compression/bitpacking/bitpacking_storage_info.test\n@@ -14,6 +14,9 @@ CREATE TABLE test (a INTEGER, b INTEGER);\n statement ok\n INSERT INTO test VALUES (11, 22), (11, 22), (12, 21), (NULL, NULL)\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT compression FROM pragma_storage_info('test') WHERE segment_type ILIKE 'INTEGER' LIMIT 1\n ----\ndiff --git a/test/sql/storage/compression/dictionary/dictionary_storage_info.test b/test/sql/storage/compression/dictionary/dictionary_storage_info.test\nindex a592cd045861..eb6c61a86d84 100644\n--- a/test/sql/storage/compression/dictionary/dictionary_storage_info.test\n+++ b/test/sql/storage/compression/dictionary/dictionary_storage_info.test\n@@ -14,6 +14,9 @@ CREATE TABLE test (a VARCHAR, b VARCHAR);\n statement ok\n INSERT INTO test VALUES ('11', '22'), ('11', '22'), ('12', '21'), (NULL, NULL)\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT compression FROM pragma_storage_info('test') WHERE segment_type ILIKE 'VARCHAR' LIMIT 1\n ----\ndiff --git a/test/sql/storage/compression/fsst/fsst_storage_info.test b/test/sql/storage/compression/fsst/fsst_storage_info.test\nindex eec1f891ac46..ff426357b18e 100644\n--- a/test/sql/storage/compression/fsst/fsst_storage_info.test\n+++ b/test/sql/storage/compression/fsst/fsst_storage_info.test\n@@ -14,6 +14,9 @@ CREATE TABLE test (a VARCHAR, b VARCHAR);\n statement ok\n INSERT INTO test VALUES ('11', '22'), ('11', '22'), ('12', '21'), (NULL, NULL)\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT compression FROM pragma_storage_info('test') WHERE segment_type ILIKE 'VARCHAR' LIMIT 1\n ----\ndiff --git a/test/sql/storage/compression/rle/rle_index_fetch.test b/test/sql/storage/compression/rle/rle_index_fetch.test\nindex b56733833c51..923d2e851da6 100644\n--- a/test/sql/storage/compression/rle/rle_index_fetch.test\n+++ b/test/sql/storage/compression/rle/rle_index_fetch.test\n@@ -17,14 +17,14 @@ INSERT INTO test SELECT i::VARCHAR id, 1 b FROM range(5000) tbl(i)\n statement ok\n INSERT INTO test SELECT (5000 + i)::VARCHAR id, 2 b FROM range(5000) tbl(i)\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT compression FROM pragma_storage_info('test') WHERE segment_type ILIKE 'INTEGER' LIMIT 1\n ----\n RLE\n \n-statement ok\n-CHECKPOINT\n-\n query IIIIII\n SELECT MIN(id), MAX(id), SUM(col), MIN(col), MAX(col), COUNT(*) FROM test WHERE id='5000'\n ----\ndiff --git a/test/sql/storage/compression/rle/rle_storage_info.test b/test/sql/storage/compression/rle/rle_storage_info.test\nindex 0d9eff1557d3..9f61145eee0a 100644\n--- a/test/sql/storage/compression/rle/rle_storage_info.test\n+++ b/test/sql/storage/compression/rle/rle_storage_info.test\n@@ -14,6 +14,9 @@ CREATE TABLE test (a INTEGER, b INTEGER);\n statement ok\n INSERT INTO test VALUES (11, 22), (11, 22), (12, 21), (NULL, NULL)\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT compression FROM pragma_storage_info('test') WHERE segment_type ILIKE 'INTEGER' LIMIT 1\n ----\ndiff --git a/test/sql/storage/compression/string/medium.test b/test/sql/storage/compression/string/medium.test\nindex 28ba32df47b9..ca405a02f3a5 100644\n--- a/test/sql/storage/compression/string/medium.test\n+++ b/test/sql/storage/compression/string/medium.test\n@@ -34,6 +34,9 @@ SELECT SUM(a::INT), MIN(a::INT), MAX(a::INT), COUNT(*) FROM test\n ----\n 2495000\t0\t499\t10000\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT lower(compression)='${compression}' FROM pragma_storage_info('test') WHERE segment_type ILIKE 'VARCHAR' LIMIT 1\n ----\ndiff --git a/test/sql/storage/compression/string/null.test b/test/sql/storage/compression/string/null.test\nindex 87b5b8707c5c..92378e4fc7d8 100644\n--- a/test/sql/storage/compression/string/null.test\n+++ b/test/sql/storage/compression/string/null.test\n@@ -77,6 +77,9 @@ SELECT COUNT(*), COUNT(i::INT), SUM(i::INT) FROM nulls\n ----\n 70006\t6\t9\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT lower(compression)='${compression}' FROM pragma_storage_info('nulls') WHERE segment_type ILIKE 'VARCHAR' LIMIT 1\n ----\ndiff --git a/test/sql/storage/compression/string/struct.test b/test/sql/storage/compression/string/struct.test\nindex a6eedb2fc72e..0d46dfb94259 100644\n--- a/test/sql/storage/compression/string/struct.test\n+++ b/test/sql/storage/compression/string/struct.test\n@@ -36,6 +36,9 @@ SELECT SUM(s['a']::INT), MIN(s['a']::INT), MAX(s['a']::INT), COUNT(*) FROM test\n ----\n 4980000\t0\t249\t40000\n \n+statement ok\n+CHECKPOINT\n+\n query I\n SELECT lower(compression)='${compression}' FROM pragma_storage_info('test') WHERE segment_type ILIKE 'VARCHAR' LIMIT 1\n ----\ndiff --git a/test/sql/storage/partial_blocks/many_columns_storage.test b/test/sql/storage/partial_blocks/many_columns_storage.test\nindex c835f9c51085..f112f9fc46a3 100644\n--- a/test/sql/storage/partial_blocks/many_columns_storage.test\n+++ b/test/sql/storage/partial_blocks/many_columns_storage.test\n@@ -18,6 +18,9 @@ true\n statement ok\n INSERT INTO integers VALUES (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100);\n \n+statement ok\n+CHECKPOINT\n+\n query I\n select count(*) from pragma_storage_info('integers') where block_id IS NULL;\n ----\n",
  "problem_statement": "WAL Replay fails when attach alias changes\n### What happens?\n\nIt seems that the current WAL reply logic is dependent on the catalog name that used when the WAL record were entered. That is a problem,  as the name can change when the file is open. If that happens, you will get the following output:\r\n```\r\nException in WAL playback: Binder Error: Catalog \"test\" does not exist!\r\n```\r\n\r\nAlso, the opening command won't fail, but the data would be lost. I think this type of issues should result in an error. \n\n### To Reproduce\n\nRun the following in the CLI:\r\n```\r\n./duckdb_0.8.0 test.db\r\nD create table tbl1 as select 1 as a;\r\n```\r\nkill the process, so the wal will stick around.\r\n\r\nStart again and run:\r\n```\r\n\u00bb ./duckdb_0.8.0\r\nv0.8.0 e8e4cea5ec\r\nEnter \".help\" for usage hints.\r\nConnected to a transient in-memory database.\r\nUse \".open FILENAME\" to reopen on a persistent database.\r\nD attach 'test.db' as another_name;\r\nException in WAL playback: Binder Error: Catalog \"test\" does not exist!\r\nD select * from another_name.tbl1;\r\nError: Catalog Error: Table with name tbl1 does not exist!\r\nDid you mean \"system.information_schema.tables\"?\r\nLINE 1: select * from another_name.tbl1;\r\n                      ^\r\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\n0.8.0\n\n### DuckDB Client:\n\ncli\n\n### Full Name:\n\nBoaz Leskes\n\n### Affiliation:\n\nMotherDuck\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\nWAL Replay fails when attach alias changes\n### What happens?\n\nIt seems that the current WAL reply logic is dependent on the catalog name that used when the WAL record were entered. That is a problem,  as the name can change when the file is open. If that happens, you will get the following output:\r\n```\r\nException in WAL playback: Binder Error: Catalog \"test\" does not exist!\r\n```\r\n\r\nAlso, the opening command won't fail, but the data would be lost. I think this type of issues should result in an error. \n\n### To Reproduce\n\nRun the following in the CLI:\r\n```\r\n./duckdb_0.8.0 test.db\r\nD create table tbl1 as select 1 as a;\r\n```\r\nkill the process, so the wal will stick around.\r\n\r\nStart again and run:\r\n```\r\n\u00bb ./duckdb_0.8.0\r\nv0.8.0 e8e4cea5ec\r\nEnter \".help\" for usage hints.\r\nConnected to a transient in-memory database.\r\nUse \".open FILENAME\" to reopen on a persistent database.\r\nD attach 'test.db' as another_name;\r\nException in WAL playback: Binder Error: Catalog \"test\" does not exist!\r\nD select * from another_name.tbl1;\r\nError: Catalog Error: Table with name tbl1 does not exist!\r\nDid you mean \"system.information_schema.tables\"?\r\nLINE 1: select * from another_name.tbl1;\r\n                      ^\r\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\n0.8.0\n\n### DuckDB Client:\n\ncli\n\n### Full Name:\n\nBoaz Leskes\n\n### Affiliation:\n\nMotherDuck\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Just a heads up it seems that this issue generally happens with any WAL replay with attach. \r\n\r\nI've attached a screenshot of another recent repro. \r\n\r\n<img width=\"1642\" alt=\"Screen Shot 2023-05-24 at 11 25 44 AM\" src=\"https://github.com/duckdb/duckdb/assets/8812233/bb4f9b3e-ff7d-4437-8bf8-0df9d4cb8abb\">\r\n\nJust a heads up it seems that this issue generally happens with any WAL replay with attach. \r\n\r\nI've attached a screenshot of another recent repro. \r\n\r\n<img width=\"1642\" alt=\"Screen Shot 2023-05-24 at 11 25 44 AM\" src=\"https://github.com/duckdb/duckdb/assets/8812233/bb4f9b3e-ff7d-4437-8bf8-0df9d4cb8abb\">\r\n",
  "created_at": "2023-05-25T10:43:04Z"
}