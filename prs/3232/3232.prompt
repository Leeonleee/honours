You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
Optimize queries with `LIMIT 0`
An optimizer for short-circuiting the execution of queries with `LIMIT 0` would be a nice feature. It would allow you to do some nice stuff as a DuckDB library user:

* Easily determine the query's schema, not only in SQL but also the equivalent schema in `arrow` and/or `pandas`. Then you could do stuff like `relation.limit(0).to_df()` and `relation.limit(0).to_arrow_table()`.
* Create an empty relation which is still `UNION`-compatible with other non-empty relations, without incurring a runtime cost. Allowing you to use such empty relations like a [null object](https://en.wikipedia.org/wiki/Null_object_pattern) of sorts.

If the use cases are unclear, I can write up some better examples ☺️ 
Optimize queries with `LIMIT 0`
An optimizer for short-circuiting the execution of queries with `LIMIT 0` would be a nice feature. It would allow you to do some nice stuff as a DuckDB library user:

* Easily determine the query's schema, not only in SQL but also the equivalent schema in `arrow` and/or `pandas`. Then you could do stuff like `relation.limit(0).to_df()` and `relation.limit(0).to_arrow_table()`.
* Create an empty relation which is still `UNION`-compatible with other non-empty relations, without incurring a runtime cost. Allowing you to use such empty relations like a [null object](https://en.wikipedia.org/wiki/Null_object_pattern) of sorts.

If the use cases are unclear, I can write up some better examples ☺️ 

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
44: 
45: 
[end of README.md]
[start of src/include/duckdb/optimizer/filter_pushdown.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/optimizer/filter_pushdown.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/unordered_set.hpp"
12: #include "duckdb/optimizer/filter_combiner.hpp"
13: #include "duckdb/optimizer/rule.hpp"
14: 
15: namespace duckdb {
16: 
17: class Optimizer;
18: 
19: class FilterPushdown {
20: public:
21: 	explicit FilterPushdown(Optimizer &optimizer) : optimizer(optimizer) {
22: 	}
23: 	//! Perform filter pushdown
24: 	unique_ptr<LogicalOperator> Rewrite(unique_ptr<LogicalOperator> op);
25: 
26: 	struct Filter {
27: 		unordered_set<idx_t> bindings;
28: 		unique_ptr<Expression> filter;
29: 
30: 		Filter() {
31: 		}
32: 		explicit Filter(unique_ptr<Expression> filter) : filter(move(filter)) {
33: 		}
34: 
35: 		void ExtractBindings();
36: 	};
37: 
38: private:
39: 	vector<unique_ptr<Filter>> filters;
40: 	Optimizer &optimizer;
41: 
42: 	//! Push down a LogicalAggregate op
43: 	unique_ptr<LogicalOperator> PushdownAggregate(unique_ptr<LogicalOperator> op);
44: 	//! Push down a LogicalFilter op
45: 	unique_ptr<LogicalOperator> PushdownFilter(unique_ptr<LogicalOperator> op);
46: 	//! Push down a LogicalCrossProduct op
47: 	unique_ptr<LogicalOperator> PushdownCrossProduct(unique_ptr<LogicalOperator> op);
48: 	//! Push down a join operator
49: 	unique_ptr<LogicalOperator> PushdownJoin(unique_ptr<LogicalOperator> op);
50: 	//! Push down a LogicalProjection op
51: 	unique_ptr<LogicalOperator> PushdownProjection(unique_ptr<LogicalOperator> op);
52: 	//! Push down a LogicalSetOperation op
53: 	unique_ptr<LogicalOperator> PushdownSetOperation(unique_ptr<LogicalOperator> op);
54: 	//! Push down a LogicalGet op
55: 	unique_ptr<LogicalOperator> PushdownGet(unique_ptr<LogicalOperator> op);
56: 	// Pushdown an inner join
57: 	unique_ptr<LogicalOperator> PushdownInnerJoin(unique_ptr<LogicalOperator> op, unordered_set<idx_t> &left_bindings,
58: 	                                              unordered_set<idx_t> &right_bindings);
59: 	// Pushdown a left join
60: 	unique_ptr<LogicalOperator> PushdownLeftJoin(unique_ptr<LogicalOperator> op, unordered_set<idx_t> &left_bindings,
61: 	                                             unordered_set<idx_t> &right_bindings);
62: 	// Pushdown a mark join
63: 	unique_ptr<LogicalOperator> PushdownMarkJoin(unique_ptr<LogicalOperator> op, unordered_set<idx_t> &left_bindings,
64: 	                                             unordered_set<idx_t> &right_bindings);
65: 	// Pushdown a single join
66: 	unique_ptr<LogicalOperator> PushdownSingleJoin(unique_ptr<LogicalOperator> op, unordered_set<idx_t> &left_bindings,
67: 	                                               unordered_set<idx_t> &right_bindings);
68: 
69: 	// Finish pushing down at this operator, creating a LogicalFilter to store any of the stored filters and recursively
70: 	// pushing down into its children (if any)
71: 	unique_ptr<LogicalOperator> FinishPushdown(unique_ptr<LogicalOperator> op);
72: 	//! Adds a filter to the set of filters. Returns FilterResult::UNSATISFIABLE if the subtree should be stripped, or
73: 	//! FilterResult::SUCCESS otherwise
74: 	FilterResult AddFilter(unique_ptr<Expression> expr);
75: 	//! Generate filters from the current set of filters stored in the FilterCombiner
76: 	void GenerateFilters();
77: 	//! if there are filters in this FilterPushdown node, push them into the combiner
78: 	void PushFilters();
79: 
80: 	FilterCombiner combiner;
81: };
82: 
83: } // namespace duckdb
[end of src/include/duckdb/optimizer/filter_pushdown.hpp]
[start of src/optimizer/filter_pushdown.cpp]
1: #include "duckdb/optimizer/filter_pushdown.hpp"
2: 
3: #include "duckdb/optimizer/filter_combiner.hpp"
4: #include "duckdb/planner/operator/logical_filter.hpp"
5: #include "duckdb/planner/operator/logical_join.hpp"
6: 
7: namespace duckdb {
8: 
9: using Filter = FilterPushdown::Filter;
10: 
11: unique_ptr<LogicalOperator> FilterPushdown::Rewrite(unique_ptr<LogicalOperator> op) {
12: 	D_ASSERT(!combiner.HasFilters());
13: 	switch (op->type) {
14: 	case LogicalOperatorType::LOGICAL_AGGREGATE_AND_GROUP_BY:
15: 		return PushdownAggregate(move(op));
16: 	case LogicalOperatorType::LOGICAL_FILTER:
17: 		return PushdownFilter(move(op));
18: 	case LogicalOperatorType::LOGICAL_CROSS_PRODUCT:
19: 		return PushdownCrossProduct(move(op));
20: 	case LogicalOperatorType::LOGICAL_COMPARISON_JOIN:
21: 	case LogicalOperatorType::LOGICAL_ANY_JOIN:
22: 	case LogicalOperatorType::LOGICAL_DELIM_JOIN:
23: 		return PushdownJoin(move(op));
24: 	case LogicalOperatorType::LOGICAL_PROJECTION:
25: 		return PushdownProjection(move(op));
26: 	case LogicalOperatorType::LOGICAL_INTERSECT:
27: 	case LogicalOperatorType::LOGICAL_EXCEPT:
28: 	case LogicalOperatorType::LOGICAL_UNION:
29: 		return PushdownSetOperation(move(op));
30: 	case LogicalOperatorType::LOGICAL_DISTINCT:
31: 	case LogicalOperatorType::LOGICAL_ORDER_BY: {
32: 		// we can just push directly through these operations without any rewriting
33: 		op->children[0] = Rewrite(move(op->children[0]));
34: 		return op;
35: 	}
36: 	case LogicalOperatorType::LOGICAL_GET:
37: 		return PushdownGet(move(op));
38: 	default:
39: 		return FinishPushdown(move(op));
40: 	}
41: }
42: 
43: unique_ptr<LogicalOperator> FilterPushdown::PushdownJoin(unique_ptr<LogicalOperator> op) {
44: 	D_ASSERT(op->type == LogicalOperatorType::LOGICAL_COMPARISON_JOIN ||
45: 	         op->type == LogicalOperatorType::LOGICAL_ANY_JOIN || op->type == LogicalOperatorType::LOGICAL_DELIM_JOIN);
46: 	auto &join = (LogicalJoin &)*op;
47: 	unordered_set<idx_t> left_bindings, right_bindings;
48: 	LogicalJoin::GetTableReferences(*op->children[0], left_bindings);
49: 	LogicalJoin::GetTableReferences(*op->children[1], right_bindings);
50: 
51: 	switch (join.join_type) {
52: 	case JoinType::INNER:
53: 		return PushdownInnerJoin(move(op), left_bindings, right_bindings);
54: 	case JoinType::LEFT:
55: 		return PushdownLeftJoin(move(op), left_bindings, right_bindings);
56: 	case JoinType::MARK:
57: 		return PushdownMarkJoin(move(op), left_bindings, right_bindings);
58: 	case JoinType::SINGLE:
59: 		return PushdownSingleJoin(move(op), left_bindings, right_bindings);
60: 	default:
61: 		// unsupported join type: stop pushing down
62: 		return FinishPushdown(move(op));
63: 	}
64: }
65: void FilterPushdown::PushFilters() {
66: 	for (auto &f : filters) {
67: 		auto result = combiner.AddFilter(move(f->filter));
68: 		D_ASSERT(result == FilterResult::SUCCESS);
69: 		(void)result;
70: 	}
71: 	filters.clear();
72: }
73: 
74: FilterResult FilterPushdown::AddFilter(unique_ptr<Expression> expr) {
75: 	PushFilters();
76: 	// split up the filters by AND predicate
77: 	vector<unique_ptr<Expression>> expressions;
78: 	expressions.push_back(move(expr));
79: 	LogicalFilter::SplitPredicates(expressions);
80: 	// push the filters into the combiner
81: 	for (auto &child_expr : expressions) {
82: 		if (combiner.AddFilter(move(child_expr)) == FilterResult::UNSATISFIABLE) {
83: 			return FilterResult::UNSATISFIABLE;
84: 		}
85: 	}
86: 	return FilterResult::SUCCESS;
87: }
88: 
89: void FilterPushdown::GenerateFilters() {
90: 	if (!filters.empty()) {
91: 		D_ASSERT(!combiner.HasFilters());
92: 		return;
93: 	}
94: 	combiner.GenerateFilters([&](unique_ptr<Expression> filter) {
95: 		auto f = make_unique<Filter>();
96: 		f->filter = move(filter);
97: 		f->ExtractBindings();
98: 		filters.push_back(move(f));
99: 	});
100: }
101: 
102: unique_ptr<LogicalOperator> FilterPushdown::FinishPushdown(unique_ptr<LogicalOperator> op) {
103: 	// unhandled type, first perform filter pushdown in its children
104: 	for (auto &child : op->children) {
105: 		FilterPushdown pushdown(optimizer);
106: 		child = pushdown.Rewrite(move(child));
107: 	}
108: 	// now push any existing filters
109: 	if (filters.empty()) {
110: 		// no filters to push
111: 		return op;
112: 	}
113: 	auto filter = make_unique<LogicalFilter>();
114: 	for (auto &f : filters) {
115: 		filter->expressions.push_back(move(f->filter));
116: 	}
117: 	filter->children.push_back(move(op));
118: 	return move(filter);
119: }
120: 
121: void FilterPushdown::Filter::ExtractBindings() {
122: 	bindings.clear();
123: 	LogicalJoin::GetExpressionBindings(*filter, bindings);
124: }
125: 
126: } // namespace duckdb
[end of src/optimizer/filter_pushdown.cpp]
[start of src/optimizer/pushdown/CMakeLists.txt]
1: add_library_unity(
2:   duckdb_optimizer_pushdown
3:   OBJECT
4:   pushdown_aggregate.cpp
5:   pushdown_cross_product.cpp
6:   pushdown_filter.cpp
7:   pushdown_get.cpp
8:   pushdown_inner_join.cpp
9:   pushdown_left_join.cpp
10:   pushdown_mark_join.cpp
11:   pushdown_projection.cpp
12:   pushdown_set_operation.cpp
13:   pushdown_single_join.cpp)
14: set(ALL_OBJECT_FILES
15:     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_optimizer_pushdown>
16:     PARENT_SCOPE)
[end of src/optimizer/pushdown/CMakeLists.txt]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: