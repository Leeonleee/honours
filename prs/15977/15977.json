{
  "repo": "duckdb/duckdb",
  "pull_number": 15977,
  "instance_id": "duckdb__duckdb-15977",
  "issue_numbers": [
    "15791"
  ],
  "base_commit": "45ee9acbc1836a27a6ce4e4d94bf7a44a485bf4f",
  "patch": "diff --git a/src/common/types/column/column_data_collection.cpp b/src/common/types/column/column_data_collection.cpp\nindex d6e01e5a663d..17be6722389b 100644\n--- a/src/common/types/column/column_data_collection.cpp\n+++ b/src/common/types/column/column_data_collection.cpp\n@@ -799,7 +799,10 @@ static bool IsComplexType(const LogicalType &type) {\n \n void ColumnDataCollection::Append(ColumnDataAppendState &state, DataChunk &input) {\n \tD_ASSERT(!finished_append);\n-\tD_ASSERT(types == input.GetTypes());\n+\t{\n+\t\tauto input_types = input.GetTypes();\n+\t\tD_ASSERT(types == input_types);\n+\t}\n \n \tauto &segment = *segments.back();\n \tfor (idx_t vector_idx = 0; vector_idx < types.size(); vector_idx++) {\ndiff --git a/src/execution/operator/persistent/physical_insert.cpp b/src/execution/operator/persistent/physical_insert.cpp\nindex 3d14f365d0a3..161fa8f58a20 100644\n--- a/src/execution/operator/persistent/physical_insert.cpp\n+++ b/src/execution/operator/persistent/physical_insert.cpp\n@@ -253,6 +253,7 @@ static void CreateUpdateChunk(ExecutionContext &context, DataChunk &chunk, Table\n \t\t\tchunk.SetCardinality(selection.Count());\n \t\t\t// Also apply this Slice to the to-update row_ids\n \t\t\trow_ids.Slice(selection.Selection(), selection.Count());\n+\t\t\trow_ids.Flatten(selection.Count());\n \t\t}\n \t}\n \n@@ -284,8 +285,27 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, InsertGlobalState\n \tCreateUpdateChunk(context, chunk, table, row_ids, update_chunk, op);\n \tauto &data_table = table.GetStorage();\n \n+\tif (update_chunk.size() == 0) {\n+\t\t// Nothing to do\n+\t\treturn update_chunk.size();\n+\t}\n+\n+\t// Arrange the columns in the standard table order.\n+\tDataChunk &append_chunk = lstate.append_chunk;\n+\tappend_chunk.SetCardinality(update_chunk);\n+\tfor (idx_t i = 0; i < append_chunk.ColumnCount(); i++) {\n+\t\tappend_chunk.data[i].Reference(chunk.data[i]);\n+\t}\n+\tfor (idx_t i = 0; i < set_columns.size(); i++) {\n+\t\tappend_chunk.data[set_columns[i].index].Reference(update_chunk.data[i]);\n+\t}\n+\n \t// Perform the UPDATE on the (global) storage.\n \tif (!op.update_is_del_and_insert) {\n+\t\tif (!op.parallel && op.return_chunk) {\n+\t\t\tgstate.return_collection.Append(append_chunk);\n+\t\t}\n+\n \t\tif (GLOBAL) {\n \t\t\tauto update_state = data_table.InitializeUpdate(table, context.client, op.bound_constraints);\n \t\t\tdata_table.Update(*update_state, context.client, row_ids, set_columns, update_chunk);\n@@ -301,16 +321,6 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, InsertGlobalState\n \t\treturn update_chunk.size();\n \t}\n \n-\t// Arrange the columns in the standard table order.\n-\tDataChunk &append_chunk = lstate.append_chunk;\n-\tappend_chunk.SetCardinality(update_chunk);\n-\tfor (idx_t i = 0; i < append_chunk.ColumnCount(); i++) {\n-\t\tappend_chunk.data[i].Reference(chunk.data[i]);\n-\t}\n-\tfor (idx_t i = 0; i < set_columns.size(); i++) {\n-\t\tappend_chunk.data[set_columns[i].index].Reference(update_chunk.data[i]);\n-\t}\n-\n \tif (GLOBAL) {\n \t\tauto &delete_state = lstate.GetDeleteState(data_table, table, context.client);\n \t\tdata_table.Delete(delete_state, context.client, row_ids, update_chunk.size());\n@@ -319,6 +329,9 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, InsertGlobalState\n \t\tlocal_storage.Delete(data_table, row_ids, update_chunk.size());\n \t}\n \n+\tif (!op.parallel && op.return_chunk) {\n+\t\tgstate.return_collection.Append(append_chunk);\n+\t}\n \tdata_table.LocalAppend(table, context.client, append_chunk, op.bound_constraints, row_ids, append_chunk);\n \treturn update_chunk.size();\n }\n@@ -647,23 +660,13 @@ SinkResultType PhysicalInsert::Sink(ExecutionContext &context, DataChunk &chunk,\n \t\t\tgstate.initialized = true;\n \t\t}\n \n-\t\t// FIXME: this is way too optimistic\n-\t\t// some tuples could be filtered out entirely and thus shouldn't be added to the return chunk.\n-\t\tif (action_type != OnConflictAction::NOTHING && return_chunk) {\n-\t\t\t// If the action is UPDATE or REPLACE, we will always create either an APPEND or an INSERT\n-\t\t\t// for NOTHING we don't create either an APPEND or an INSERT for the tuple\n-\t\t\t// so it should not be added to the RETURNING chunk\n-\t\t\tgstate.return_collection.Append(lstate.insert_chunk);\n-\t\t}\n \t\tidx_t updated_tuples = OnConflictHandling(table, context, gstate, lstate);\n-\t\tif (action_type == OnConflictAction::NOTHING && return_chunk) {\n-\t\t\t// Because we didn't add to the RETURNING chunk yet\n-\t\t\t// we add the tuples that did not get filtered out now\n-\t\t\tgstate.return_collection.Append(lstate.insert_chunk);\n-\t\t}\n \n \t\tgstate.insert_count += lstate.insert_chunk.size();\n \t\tgstate.insert_count += updated_tuples;\n+\t\tif (!parallel && return_chunk) {\n+\t\t\tgstate.return_collection.Append(lstate.insert_chunk);\n+\t\t}\n \t\tstorage.LocalAppend(gstate.append_state, context.client, lstate.insert_chunk, true);\n \t\tif (action_type == OnConflictAction::UPDATE && lstate.update_chunk.size() != 0) {\n \t\t\t(void)HandleInsertConflicts<true>(table, context, lstate, gstate, lstate.update_chunk, *this);\ndiff --git a/src/storage/local_storage.cpp b/src/storage/local_storage.cpp\nindex cbbf64df28f8..93dccfcba763 100644\n--- a/src/storage/local_storage.cpp\n+++ b/src/storage/local_storage.cpp\n@@ -474,6 +474,7 @@ idx_t LocalStorage::Delete(DataTable &table, Vector &row_ids, idx_t count) {\n \n void LocalStorage::Update(DataTable &table, Vector &row_ids, const vector<PhysicalIndex> &column_ids,\n                           DataChunk &updates) {\n+\tD_ASSERT(updates.size() >= 1);\n \tauto storage = table_manager.GetStorage(table);\n \tD_ASSERT(storage);\n \ndiff --git a/src/storage/table/row_group_collection.cpp b/src/storage/table/row_group_collection.cpp\nindex 2629800a4be8..dc0a7eb47eb7 100644\n--- a/src/storage/table/row_group_collection.cpp\n+++ b/src/storage/table/row_group_collection.cpp\n@@ -593,6 +593,7 @@ idx_t RowGroupCollection::Delete(TransactionData transaction, DataTable &table,\n //===--------------------------------------------------------------------===//\n void RowGroupCollection::Update(TransactionData transaction, row_t *ids, const vector<PhysicalIndex> &column_ids,\n                                 DataChunk &updates) {\n+\tD_ASSERT(updates.size() >= 1);\n \tidx_t pos = 0;\n \tdo {\n \t\tidx_t start = pos;\n",
  "test_patch": "diff --git a/test/sql/upsert/test_problematic_conditional_do_update.test b/test/sql/upsert/test_problematic_conditional_do_update.test\nindex 078c35321ac9..ade3cd1bde07 100644\n--- a/test/sql/upsert/test_problematic_conditional_do_update.test\n+++ b/test/sql/upsert/test_problematic_conditional_do_update.test\n@@ -8,6 +8,9 @@ CREATE TABLE users (\n \temail TEXT\n );\n \n+# FIXME: not consistent\n+mode skip\n+\n # The condition skips the last tuple\n statement error\n INSERT INTO users (id, username, email)\ndiff --git a/test/sql/upsert/upsert_returning.test b/test/sql/upsert/upsert_returning.test\nnew file mode 100644\nindex 000000000000..cbb3c90126d9\n--- /dev/null\n+++ b/test/sql/upsert/upsert_returning.test\n@@ -0,0 +1,83 @@\n+# name: test/sql/upsert/upsert_returning.test\n+# group: [upsert]\n+\n+require vector_size 2048\n+\n+statement ok\n+CREATE TABLE users (\n+    id BIGINT PRIMARY KEY,\n+    username TEXT UNIQUE,\n+    email TEXT\n+);\n+\n+query III\n+INSERT INTO users (id, username, email) VALUES\n+\t(1, 'john_doe', 'john@example.com')\n+ON CONFLICT (username) DO NOTHING\n+RETURNING *;\n+----\n+1\tjohn_doe\tjohn@example.com\n+\n+query III\n+INSERT INTO users (id, username, email) VALUES\n+\t(1, 'john_doe', 'john@example.com')\n+ON CONFLICT (username) DO NOTHING\n+RETURNING *;\n+----\n+\n+# We create a conflict, with a where clause that filters out this conflict\n+# Because the where clause filters it out, the DO UPDATE becomes a DO NOTHING for this row instead\n+# So it does not get added to the returning clause.\n+query III\n+INSERT INTO users (id, username, email)\n+VALUES (1, 'john_doe', 'john_new@example.com')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE EXCLUDED.email != 'john_new@example.com'\n+RETURNING *;\n+----\n+\n+# Verify that the *other* tuple does get added to the returning clause\n+query III\n+INSERT INTO users (id, username, email)\n+VALUES\n+\t(1, 'john_doe', 'john_new@example.com'),\n+\t(2, 'not_john_doe', 'not_john_new@example.com')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE EXCLUDED.email != 'john_new@example.com'\n+RETURNING *;\n+----\n+2\tnot_john_doe\tnot_john_new@example.com\n+\n+\n+# FIXME: not consistent\n+mode skip\n+\n+# Here we have conflicts within the inserted data\n+# Only the last occurrence of this conflict should be present in the returning clause.\n+query III\n+INSERT INTO users (id, username, email)\n+VALUES\n+\t(3, 'inner_conflict', 'test'),\n+\t(4, 'a', ''),\n+\t(5, 'b', ''),\n+\t(6, 'c', ''),\n+\t(3, 'inner_conflict2', 'other_test'),\n+\t(7, 'd', ''),\n+\t(8, 'e', ''),\n+\t(9, 'f', ''),\n+\t(3, 'inner_conflict3', 'yet_another_test')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE EXCLUDED.email != 'test'\n+RETURNING *;\n+----\n+3\tinner_conflict\ttest\n+4\ta\t(empty)\n+5\tb\t(empty)\n+6\tc\t(empty)\n+7\td\t(empty)\n+8\te\t(empty)\n+9\tf\t(empty)\n+3\tinner_conflict3\tyet_another_test\n",
  "problem_statement": "Surprising upsert with returning and where condition result\n### What happens?\n\nGiven I have a table with a primary key and I perform an upsert with a where condition in the update I would expect rows that don't match the condition not be present in the returned rows, this is not the case.\n\n### To Reproduce\n\n```sql\ncreate table foo(id int primary key, bar text);\ninsert into foo select 1, 'zoo';\ninsert into foo select 1, 'zoo' returning *;\n```\n```\nConstraint Error: Duplicate key \"id: 1\" violates primary key constraint. If this is an unexpected constraint violation please double check with the known index limitations section in our documentation (https://duckdb.org/docs/sql/indexes).\n```\n```sql\ninsert into foo select 1, 'zoo'\non conflict (id) do\n    update set bar = excluded.bar\n    where excluded.bar != 'zoo'\nreturning *;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoo     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```sql\ninsert into foo select 1, 'zoom'\non conflict (id) do\n    update set bar = excluded.bar\n    where excluded.bar != 'zoom'\nreturning *;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoom    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```sql\ninsert into foo select 1, 'zoom'\non conflict (id) do\n    update set bar = excluded.bar\n    where id != 1\nreturning *;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoom    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```sql\nselect * from foo;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoo     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nSee in the upserts the where condition prevents the update and I would expect it to prevent anything from being returned, the stored data was never changed.\n\nThe documentation only states\n> The RETURNING clause may be used to return the contents of the rows that were inserted\n\nI think it would be fair in an upsert scenario to assume it would \"return the contents of the rows that were upserted\"\n\n### OS:\n\nMacOs 13.6.7 (aarch64)\n\n### DuckDB Version:\n\nv1.1.3\n\n### DuckDB Client:\n\nCLI (mac via homebrew)\n\n### Hardware:\n\nM1, 16Gb ram\n\n### Full Name:\n\nStephen Flavin\n\n### Affiliation:\n\nN/A\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n",
  "hints_text": "",
  "created_at": "2025-01-29T09:05:53Z"
}