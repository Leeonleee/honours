{
  "repo": "duckdb/duckdb",
  "pull_number": 8982,
  "instance_id": "duckdb__duckdb-8982",
  "issue_numbers": [
    "8592",
    "8592"
  ],
  "base_commit": "0f1ef0a8b56fde3de2b029eb8e49fe2f8f4a6ca2",
  "patch": "diff --git a/src/storage/table/table_statistics.cpp b/src/storage/table/table_statistics.cpp\nindex 829d9d8d5233..4df780f5079a 100644\n--- a/src/storage/table/table_statistics.cpp\n+++ b/src/storage/table/table_statistics.cpp\n@@ -102,9 +102,7 @@ void TableStatistics::CopyStats(TableStatistics &other) {\n }\n \n void TableStatistics::Serialize(Serializer &serializer) const {\n-\tauto column_count = column_stats.size();\n-\tserializer.WriteList(100, \"column_stats\", column_count,\n-\t                     [&](Serializer::List &list, idx_t i) { list.WriteElement(column_stats[i]); });\n+\tserializer.WriteProperty(100, \"column_stats\", column_stats);\n }\n \n void TableStatistics::Deserialize(Deserializer &deserializer, ColumnList &columns) {\ndiff --git a/src/storage/wal_replay.cpp b/src/storage/wal_replay.cpp\nindex 4904b8adf216..7e700e390720 100644\n--- a/src/storage/wal_replay.cpp\n+++ b/src/storage/wal_replay.cpp\n@@ -57,7 +57,10 @@ bool WriteAheadLog::Replay(AttachedDatabase &database, string &path) {\n \t\t\t\tdeserializer.End();\n \t\t\t}\n \t\t}\n-\t} catch (std::exception &ex) { // LCOV_EXCL_START\n+\t} catch (SerializationException &ex) { // LCOV_EXCL_START\n+\t\t                                   // serialization exception - torn WAL\n+\t\t                                   // continue reading\n+\t} catch (std::exception &ex) {\n \t\tPrinter::PrintF(\"Exception in WAL playback during initial read: %s\\n\", ex.what());\n \t\treturn false;\n \t} catch (...) {\n@@ -104,7 +107,10 @@ bool WriteAheadLog::Replay(AttachedDatabase &database, string &path) {\n \t\t\t\tdeserializer.End();\n \t\t\t}\n \t\t}\n-\t} catch (std::exception &ex) { // LCOV_EXCL_START\n+\t} catch (SerializationException &ex) { // LCOV_EXCL_START\n+\t\t// serialization error during WAL replay: rollback\n+\t\tcon.Rollback();\n+\t} catch (std::exception &ex) {\n \t\t// FIXME: this should report a proper warning in the connection\n \t\tPrinter::PrintF(\"Exception in WAL playback: %s\\n\", ex.what());\n \t\t// exception thrown in WAL replay: rollback\n",
  "test_patch": "diff --git a/test/sql/storage/CMakeLists.txt b/test/sql/storage/CMakeLists.txt\nindex bb1195099aab..1c8ad95d3134 100644\n--- a/test/sql/storage/CMakeLists.txt\n+++ b/test/sql/storage/CMakeLists.txt\n@@ -7,7 +7,8 @@ add_library_unity(\n   test_big_storage.cpp\n   test_repeated_checkpoint.cpp\n   test_storage.cpp\n-  test_database_size.cpp)\n+  test_database_size.cpp\n+  wal_torn_write.cpp)\n set(ALL_OBJECT_FILES\n     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:test_sql_storage>\n     PARENT_SCOPE)\ndiff --git a/test/sql/storage/wal_torn_write.cpp b/test/sql/storage/wal_torn_write.cpp\nnew file mode 100644\nindex 000000000000..f84b1efd896f\n--- /dev/null\n+++ b/test/sql/storage/wal_torn_write.cpp\n@@ -0,0 +1,62 @@\n+#include \"catch.hpp\"\n+#include \"duckdb/common/file_system.hpp\"\n+#include \"test_helpers.hpp\"\n+#include \"duckdb/common/local_file_system.hpp\"\n+\n+using namespace duckdb;\n+using namespace std;\n+\n+static idx_t GetWALFileSize(FileSystem &fs, const string &path) {\n+\tauto handle = fs.OpenFile(path, FileFlags::FILE_FLAGS_READ, FileLockType::NO_LOCK);\n+\treturn fs.GetFileSize(*handle);\n+}\n+\n+static void TruncateWAL(FileSystem &fs, const string &path, idx_t new_size) {\n+\tauto handle = fs.OpenFile(path, FileFlags::FILE_FLAGS_WRITE);\n+\tfs.Truncate(*handle, new_size);\n+}\n+\n+TEST_CASE(\"Test torn WAL writes\", \"[storage][.]\") {\n+\tauto config = GetTestConfig();\n+\tduckdb::unique_ptr<QueryResult> result;\n+\tauto storage_database = TestCreatePath(\"storage_test\");\n+\tauto storage_wal = storage_database + \".wal\";\n+\n+\tLocalFileSystem lfs;\n+\tconfig->options.checkpoint_wal_size = idx_t(-1);\n+\tconfig->options.checkpoint_on_shutdown = false;\n+\tidx_t wal_size_one_table;\n+\tidx_t wal_size_two_table;\n+\t// obtain the size of the WAL when writing one table, and then when writing two tables\n+\tDeleteDatabase(storage_database);\n+\t{\n+\t\tDuckDB db(storage_database, config.get());\n+\t\tConnection con(db);\n+\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE A (a INTEGER);\"));\n+\t\twal_size_one_table = GetWALFileSize(lfs, storage_wal);\n+\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE B (a INTEGER);\"));\n+\t\twal_size_two_table = GetWALFileSize(lfs, storage_wal);\n+\t}\n+\tDeleteDatabase(storage_database);\n+\n+\t// now for all sizes in between these two sizes we have a torn write\n+\t// try all of the possible sizes and truncate the WAL\n+\tfor (idx_t i = wal_size_one_table + 1; i < wal_size_two_table; i++) {\n+\t\tDeleteDatabase(storage_database);\n+\t\t{\n+\t\t\tDuckDB db(storage_database, config.get());\n+\t\t\tConnection con(db);\n+\t\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE A (a INTEGER);\"));\n+\t\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE B (a INTEGER);\"));\n+\t\t}\n+\t\tTruncateWAL(lfs, storage_wal, i);\n+\t\t{\n+\t\t\t// reload and make sure table A is there, and table B is not there\n+\t\t\tDuckDB db(storage_database, config.get());\n+\t\t\tConnection con(db);\n+\t\t\tREQUIRE_NO_FAIL(con.Query(\"FROM A\"));\n+\t\t\tREQUIRE_FAIL(con.Query(\"FROM B\"));\n+\t\t}\n+\t}\n+\tDeleteDatabase(storage_database);\n+}\n",
  "problem_statement": "[WAL Replay] Handle partial writes to WAL\n### What happens?\r\n\r\nWe are running DuckDB on NAS. One failure mode we were playing with was with partial writes to the WAL. ex: where the filesystem only writes 90 bytes out of the 100 bytes and then something disastrous happens to the host. \r\n\r\nHere DuckDB acts correctly in that it never ack's the commit. But when I try to restart DuckDB on that db and wal file - I see an error: \"Exception in WAL playback during initial read: Serialization Error: not enough data in file to deserialize result\"\r\n\r\nI guess my assumption would be that we can omit any partially written entries in the WAL as they were not ack'd to the user? \r\n\r\n### To Reproduce\r\n\r\nHacky repro:\r\n1. Start up DuckDB\r\n2. Write a table A. Track the WAL size : size_a\r\n3. Write a table B. Track the WAL size: size_b \r\n4. kill -9 DuckDB\r\n5. Manually truncate the WAL to  size_a < len < size_b (simulate a partial write failure to the WAL)\r\n6. Start a new DuckDB on that file. \r\n\r\nAt step 6 - I see the above error and table A has disappeared. \r\n\r\n### OS:\r\n\r\nany\r\n\r\n### DuckDB Version:\r\n\r\n0.8.1\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Full Name:\r\n\r\nJoseph Hwang\r\n\r\n### Affiliation:\r\n\r\nMotherDuck\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\nI have tested with a master build\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] Yes, I have\n[WAL Replay] Handle partial writes to WAL\n### What happens?\r\n\r\nWe are running DuckDB on NAS. One failure mode we were playing with was with partial writes to the WAL. ex: where the filesystem only writes 90 bytes out of the 100 bytes and then something disastrous happens to the host. \r\n\r\nHere DuckDB acts correctly in that it never ack's the commit. But when I try to restart DuckDB on that db and wal file - I see an error: \"Exception in WAL playback during initial read: Serialization Error: not enough data in file to deserialize result\"\r\n\r\nI guess my assumption would be that we can omit any partially written entries in the WAL as they were not ack'd to the user? \r\n\r\n### To Reproduce\r\n\r\nHacky repro:\r\n1. Start up DuckDB\r\n2. Write a table A. Track the WAL size : size_a\r\n3. Write a table B. Track the WAL size: size_b \r\n4. kill -9 DuckDB\r\n5. Manually truncate the WAL to  size_a < len < size_b (simulate a partial write failure to the WAL)\r\n6. Start a new DuckDB on that file. \r\n\r\nAt step 6 - I see the above error and table A has disappeared. \r\n\r\n### OS:\r\n\r\nany\r\n\r\n### DuckDB Version:\r\n\r\n0.8.1\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Full Name:\r\n\r\nJoseph Hwang\r\n\r\n### Affiliation:\r\n\r\nMotherDuck\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\nI have tested with a master build\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "\n",
  "created_at": "2023-09-18T16:23:51Z"
}