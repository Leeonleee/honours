{
  "repo": "duckdb/duckdb",
  "pull_number": 5079,
  "instance_id": "duckdb__duckdb-5079",
  "issue_numbers": [
    "5045"
  ],
  "base_commit": "0977dcb2a302bf9ffaa3ef685106bc49a0cfae89",
  "patch": "diff --git a/.editorconfig b/.editorconfig\nindex 385fcae45934..de0e9020d3e4 100644\n--- a/.editorconfig\n+++ b/.editorconfig\n@@ -20,7 +20,7 @@ insert_final_newline = true\n indent_style = tab\n tab_width = 4\n indent_size = tab\n-trim_trailing_whitespace = true\n+trim_trailing_whitespace = false\n charset = utf-8\n x-soft-wrap-text = false\n \ndiff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp\nindex b36aabe3f0f1..6a3df18657f0 100644\n--- a/extension/parquet/column_reader.cpp\n+++ b/extension/parquet/column_reader.cpp\n@@ -665,7 +665,7 @@ idx_t ListColumnReader::Read(uint64_t num_values, parquet_filter_t &filter, uint\n \t\t// we have read more values from the child reader than we can fit into the result for this read\n \t\t// we have to pass everything from child_idx to child_actual_num_values into the next call\n \t\tif (child_idx < child_actual_num_values && result_offset == num_values) {\n-\t\t\tread_vector.Slice(read_vector, child_idx);\n+\t\t\tread_vector.Slice(read_vector, child_idx, child_actual_num_values);\n \t\t\toverflow_child_count = child_actual_num_values - child_idx;\n \t\t\tread_vector.Verify(overflow_child_count);\n \ndiff --git a/src/common/types/validity_mask.cpp b/src/common/types/validity_mask.cpp\nindex 55f5756e1118..744af8b56405 100644\n--- a/src/common/types/validity_mask.cpp\n+++ b/src/common/types/validity_mask.cpp\n@@ -68,7 +68,7 @@ void ValidityMask::Resize(idx_t old_size, idx_t new_size) {\n \t}\n }\n \n-void ValidityMask::Slice(const ValidityMask &other, idx_t offset) {\n+void ValidityMask::Slice(const ValidityMask &other, idx_t offset, idx_t end) {\n \tif (other.AllValid()) {\n \t\tvalidity_mask = nullptr;\n \t\tvalidity_data.reset();\n@@ -78,11 +78,11 @@ void ValidityMask::Slice(const ValidityMask &other, idx_t offset) {\n \t\tInitialize(other);\n \t\treturn;\n \t}\n-\tValidityMask new_mask(STANDARD_VECTOR_SIZE);\n+\tValidityMask new_mask(end - offset);\n \n // FIXME THIS NEEDS FIXING!\n #if 1\n-\tfor (idx_t i = offset; i < STANDARD_VECTOR_SIZE; i++) {\n+\tfor (idx_t i = offset; i < end; i++) {\n \t\tnew_mask.Set(i - offset, other.RowIsValid(i));\n \t}\n \tInitialize(new_mask);\ndiff --git a/src/common/types/vector.cpp b/src/common/types/vector.cpp\nindex a7b222ca8106..cc0b534c9487 100644\n--- a/src/common/types/vector.cpp\n+++ b/src/common/types/vector.cpp\n@@ -51,8 +51,8 @@ Vector::Vector(Vector &other, const SelectionVector &sel, idx_t count) : type(ot\n \tSlice(other, sel, count);\n }\n \n-Vector::Vector(Vector &other, idx_t offset) : type(other.type) {\n-\tSlice(other, offset);\n+Vector::Vector(Vector &other, idx_t offset, idx_t end) : type(other.type) {\n+\tSlice(other, offset, end);\n }\n \n Vector::Vector(const Value &value) : type(value.type()) {\n@@ -116,7 +116,7 @@ void Vector::ResetFromCache(const VectorCache &cache) {\n \tcache.ResetFromCache(*this);\n }\n \n-void Vector::Slice(Vector &other, idx_t offset) {\n+void Vector::Slice(Vector &other, idx_t offset, idx_t end) {\n \tif (other.GetVectorType() == VectorType::CONSTANT_VECTOR) {\n \t\tReference(other);\n \t\treturn;\n@@ -130,10 +130,10 @@ void Vector::Slice(Vector &other, idx_t offset) {\n \t\tauto &other_entries = StructVector::GetEntries(other);\n \t\tD_ASSERT(entries.size() == other_entries.size());\n \t\tfor (idx_t i = 0; i < entries.size(); i++) {\n-\t\t\tentries[i]->Slice(*other_entries[i], offset);\n+\t\t\tentries[i]->Slice(*other_entries[i], offset, end);\n \t\t}\n \t\tif (offset > 0) {\n-\t\t\tnew_vector.validity.Slice(other.validity, offset);\n+\t\t\tnew_vector.validity.Slice(other.validity, offset, end);\n \t\t} else {\n \t\t\tnew_vector.validity = other.validity;\n \t\t}\n@@ -142,7 +142,7 @@ void Vector::Slice(Vector &other, idx_t offset) {\n \t\tReference(other);\n \t\tif (offset > 0) {\n \t\t\tdata = data + GetTypeIdSize(internal_type) * offset;\n-\t\t\tvalidity.Slice(other.validity, offset);\n+\t\t\tvalidity.Slice(other.validity, offset, end);\n \t\t}\n \t}\n }\ndiff --git a/src/execution/operator/aggregate/physical_window.cpp b/src/execution/operator/aggregate/physical_window.cpp\nindex 280b3aa55989..b3130894b58e 100644\n--- a/src/execution/operator/aggregate/physical_window.cpp\n+++ b/src/execution/operator/aggregate/physical_window.cpp\n@@ -837,21 +837,23 @@ static bool WindowNeedsRank(BoundWindowExpression *wexpr) {\n }\n \n template <typename T>\n-static T GetCell(ChunkCollection &collection, idx_t column, idx_t index) {\n-\tD_ASSERT(collection.ColumnCount() > column);\n-\tauto &chunk = collection.GetChunkForRow(index);\n+static T GetCell(DataChunk &chunk, idx_t column, idx_t index) {\n+\tD_ASSERT(chunk.ColumnCount() > column);\n \tauto &source = chunk.data[column];\n-\tconst auto source_offset = index % STANDARD_VECTOR_SIZE;\n \tconst auto data = FlatVector::GetData<T>(source);\n-\treturn data[source_offset];\n+\treturn data[index];\n }\n \n-static bool CellIsNull(ChunkCollection &collection, idx_t column, idx_t index) {\n-\tD_ASSERT(collection.ColumnCount() > column);\n-\tauto &chunk = collection.GetChunkForRow(index);\n+static bool CellIsNull(DataChunk &chunk, idx_t column, idx_t index) {\n+\tD_ASSERT(chunk.ColumnCount() > column);\n \tauto &source = chunk.data[column];\n-\tconst auto source_offset = index % STANDARD_VECTOR_SIZE;\n-\treturn FlatVector::IsNull(source, source_offset);\n+\treturn FlatVector::IsNull(source, index);\n+}\n+\n+static void CopyCell(DataChunk &chunk, idx_t column, idx_t index, Vector &target, idx_t target_offset) {\n+\tD_ASSERT(chunk.ColumnCount() > column);\n+\tauto &source = chunk.data[column];\n+\tVectorOperations::Copy(source, target, index + 1, index, target_offset);\n }\n \n template <typename T>\n@@ -1150,7 +1152,7 @@ struct WindowExecutor {\n \tuint64_t rank = 1;\n \n \t// Expression collections\n-\tChunkCollection payload_collection;\n+\tDataChunk payload_collection;\n \tExpressionExecutor payload_executor;\n \tDataChunk payload_chunk;\n \n@@ -1179,10 +1181,9 @@ struct WindowExecutor {\n };\n \n WindowExecutor::WindowExecutor(BoundWindowExpression *wexpr, Allocator &allocator, const idx_t count)\n-    : wexpr(wexpr), bounds(wexpr, count), payload_collection(allocator), payload_executor(allocator),\n-      filter_executor(allocator), leadlag_offset(wexpr->offset_expr.get(), allocator),\n-      leadlag_default(wexpr->default_expr.get(), allocator), boundary_start(wexpr->start_expr.get(), allocator),\n-      boundary_end(wexpr->end_expr.get(), allocator),\n+    : wexpr(wexpr), bounds(wexpr, count), payload_collection(), payload_executor(allocator), filter_executor(allocator),\n+      leadlag_offset(wexpr->offset_expr.get(), allocator), leadlag_default(wexpr->default_expr.get(), allocator),\n+      boundary_start(wexpr->start_expr.get(), allocator), boundary_end(wexpr->end_expr.get(), allocator),\n       range((bounds.has_preceding_range || bounds.has_following_range) ? wexpr->orders[0].expression.get() : nullptr,\n             allocator, count)\n \n@@ -1206,6 +1207,11 @@ WindowExecutor::WindowExecutor(BoundWindowExpression *wexpr, Allocator &allocato\n \t\texprs.push_back(child.get());\n \t}\n \tPrepareInputExpressions(exprs.data(), exprs.size(), payload_executor, payload_chunk);\n+\n+\tauto types = payload_chunk.GetTypes();\n+\tif (!types.empty()) {\n+\t\tpayload_collection.Initialize(allocator, types);\n+\t}\n }\n \n void WindowExecutor::Sink(DataChunk &input_chunk, const idx_t input_idx, const idx_t total_count) {\n@@ -1234,7 +1240,7 @@ void WindowExecutor::Sink(DataChunk &input_chunk, const idx_t input_idx, const i\n \t\tpayload_chunk.Reset();\n \t\tpayload_executor.Execute(input_chunk, payload_chunk);\n \t\tpayload_chunk.Verify();\n-\t\tpayload_collection.Append(payload_chunk);\n+\t\tpayload_collection.Append(payload_chunk, true);\n \n \t\t// process payload chunks while they are still piping hot\n \t\tif (check_nulls) {\n@@ -1246,11 +1252,18 @@ void WindowExecutor::Sink(DataChunk &input_chunk, const idx_t input_idx, const i\n \t\t\t\t\tignore_nulls.Initialize(total_count);\n \t\t\t\t}\n \t\t\t\t// Write to the current position\n-\t\t\t\t// Chunks in a collection are full, so we don't have to worry about raggedness\n-\t\t\t\tauto dst = ignore_nulls.GetData() + ignore_nulls.EntryCount(input_idx);\n-\t\t\t\tauto src = vdata.validity.GetData();\n-\t\t\t\tfor (auto entry_count = vdata.validity.EntryCount(count); entry_count-- > 0;) {\n-\t\t\t\t\t*dst++ = *src++;\n+\t\t\t\tif (input_idx % ValidityMask::BITS_PER_VALUE == 0) {\n+\t\t\t\t\t// If we are at the edge of an output entry, just copy the entries\n+\t\t\t\t\tauto dst = ignore_nulls.GetData() + ignore_nulls.EntryCount(input_idx);\n+\t\t\t\t\tauto src = vdata.validity.GetData();\n+\t\t\t\t\tfor (auto entry_count = vdata.validity.EntryCount(count); entry_count-- > 0;) {\n+\t\t\t\t\t\t*dst++ = *src++;\n+\t\t\t\t\t}\n+\t\t\t\t} else {\n+\t\t\t\t\t// If not, we have ragged data and need to copy one bit at a time.\n+\t\t\t\t\tfor (idx_t i = 0; i < count; ++i) {\n+\t\t\t\t\t\tignore_nulls.Set(input_idx + i, vdata.validity.RowIsValid(i));\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n \t\t}\n@@ -1406,7 +1419,7 @@ void WindowExecutor::Evaluate(idx_t row_idx, DataChunk &input_chunk, Vector &res\n \t\t\t// else offset is zero, so don't move.\n \n \t\t\tif (!delta) {\n-\t\t\t\tpayload_collection.CopyCell(0, val_idx, result, output_offset);\n+\t\t\t\tCopyCell(payload_collection, 0, val_idx, result, output_offset);\n \t\t\t} else if (wexpr->default_expr) {\n \t\t\t\tleadlag_default.CopyCell(result, output_offset);\n \t\t\t} else {\n@@ -1417,13 +1430,13 @@ void WindowExecutor::Evaluate(idx_t row_idx, DataChunk &input_chunk, Vector &res\n \t\tcase ExpressionType::WINDOW_FIRST_VALUE: {\n \t\t\tidx_t n = 1;\n \t\t\tconst auto first_idx = FindNextStart(ignore_nulls, bounds.window_start, bounds.window_end, n);\n-\t\t\tpayload_collection.CopyCell(0, first_idx, result, output_offset);\n+\t\t\tCopyCell(payload_collection, 0, first_idx, result, output_offset);\n \t\t\tbreak;\n \t\t}\n \t\tcase ExpressionType::WINDOW_LAST_VALUE: {\n \t\t\tidx_t n = 1;\n-\t\t\tpayload_collection.CopyCell(0, FindPrevStart(ignore_nulls, bounds.window_start, bounds.window_end, n),\n-\t\t\t                            result, output_offset);\n+\t\t\tCopyCell(payload_collection, 0, FindPrevStart(ignore_nulls, bounds.window_start, bounds.window_end, n),\n+\t\t\t         result, output_offset);\n \t\t\tbreak;\n \t\t}\n \t\tcase ExpressionType::WINDOW_NTH_VALUE: {\n@@ -1440,7 +1453,7 @@ void WindowExecutor::Evaluate(idx_t row_idx, DataChunk &input_chunk, Vector &res\n \t\t\t\t\tauto n = idx_t(n_param);\n \t\t\t\t\tconst auto nth_index = FindNextStart(ignore_nulls, bounds.window_start, bounds.window_end, n);\n \t\t\t\t\tif (!n) {\n-\t\t\t\t\t\tpayload_collection.CopyCell(0, nth_index, result, output_offset);\n+\t\t\t\t\t\tCopyCell(payload_collection, 0, nth_index, result, output_offset);\n \t\t\t\t\t} else {\n \t\t\t\t\t\tFlatVector::SetNull(result, output_offset, true);\n \t\t\t\t\t}\ndiff --git a/src/execution/window_segment_tree.cpp b/src/execution/window_segment_tree.cpp\nindex 958deef65b47..ba39b704290a 100644\n--- a/src/execution/window_segment_tree.cpp\n+++ b/src/execution/window_segment_tree.cpp\n@@ -7,27 +7,26 @@\n namespace duckdb {\n \n WindowSegmentTree::WindowSegmentTree(AggregateFunction &aggregate, FunctionData *bind_info,\n-                                     const LogicalType &result_type_p, ChunkCollection *input,\n+                                     const LogicalType &result_type_p, DataChunk *input,\n                                      const ValidityMask &filter_mask_p, WindowAggregationMode mode_p)\n     : aggregate(aggregate), bind_info(bind_info), result_type(result_type_p), state(aggregate.state_size()),\n-      statep(Value::POINTER((idx_t)state.data())), frame(0, 0), active(0, 1),\n-      statev(Value::POINTER((idx_t)state.data())), internal_nodes(0), input_ref(input), filter_mask(filter_mask_p),\n-      mode(mode_p) {\n-#if STANDARD_VECTOR_SIZE < 512\n-\tthrow NotImplementedException(\"Window functions are not supported for vector sizes < 512\");\n-#endif\n-\tstatep.Flatten(STANDARD_VECTOR_SIZE);\n+      statep(Value::POINTER((idx_t)state.data())), frame(0, 0), statev(Value::POINTER((idx_t)state.data())),\n+      internal_nodes(0), input_ref(input), filter_mask(filter_mask_p), mode(mode_p) {\n+\tstatep.Flatten(input->size());\n \tstatev.SetVectorType(VectorType::FLAT_VECTOR); // Prevent conversion of results to constants\n \n \tif (input_ref && input_ref->ColumnCount() > 0) {\n-\t\tfilter_sel.Initialize(STANDARD_VECTOR_SIZE);\n-\t\tinputs.Initialize(Allocator::DefaultAllocator(), input_ref->Types());\n+\t\tfilter_sel.Initialize(input->size());\n+\t\tinputs.Initialize(Allocator::DefaultAllocator(), input_ref->GetTypes());\n \t\t// if we have a frame-by-frame method, share the single state\n \t\tif (aggregate.window && UseWindowAPI()) {\n \t\t\tAggregateInit();\n-\t\t\tinputs.Reference(input_ref->GetChunk(0));\n-\t\t} else if (aggregate.combine && UseCombineAPI()) {\n-\t\t\tConstructTree();\n+\t\t\tinputs.Reference(*input_ref);\n+\t\t} else {\n+\t\t\tinputs.SetCapacity(*input_ref);\n+\t\t\tif (aggregate.combine && UseCombineAPI()) {\n+\t\t\t\tConstructTree();\n+\t\t\t}\n \t\t}\n \t}\n }\n@@ -72,35 +71,15 @@ void WindowSegmentTree::AggegateFinal(Vector &result, idx_t rid) {\n \n void WindowSegmentTree::ExtractFrame(idx_t begin, idx_t end) {\n \tconst auto size = end - begin;\n-\tif (size >= STANDARD_VECTOR_SIZE) {\n-\t\tthrow InternalException(\"Cannot compute window aggregation: bounds are too large\");\n-\t}\n \n-\tconst idx_t start_in_vector = begin % STANDARD_VECTOR_SIZE;\n+\tauto &chunk = *input_ref;\n \tconst auto input_count = input_ref->ColumnCount();\n-\tif (start_in_vector + size <= STANDARD_VECTOR_SIZE) {\n-\t\tinputs.SetCardinality(size);\n-\t\tauto &chunk = input_ref->GetChunkForRow(begin);\n-\t\tfor (idx_t i = 0; i < input_count; ++i) {\n-\t\t\tauto &v = inputs.data[i];\n-\t\t\tauto &vec = chunk.data[i];\n-\t\t\tv.Slice(vec, start_in_vector);\n-\t\t\tv.Verify(size);\n-\t\t}\n-\t} else {\n-\t\tinputs.Reset();\n-\t\tinputs.SetCardinality(size);\n-\n-\t\t// we cannot just slice the individual vector!\n-\t\tauto &chunk_a = input_ref->GetChunkForRow(begin);\n-\t\tauto &chunk_b = input_ref->GetChunkForRow(end);\n-\t\tidx_t chunk_a_count = chunk_a.size() - start_in_vector;\n-\t\tidx_t chunk_b_count = inputs.size() - chunk_a_count;\n-\t\tfor (idx_t i = 0; i < input_count; ++i) {\n-\t\t\tauto &v = inputs.data[i];\n-\t\t\tVectorOperations::Copy(chunk_a.data[i], v, chunk_a.size(), start_in_vector, 0);\n-\t\t\tVectorOperations::Copy(chunk_b.data[i], v, chunk_b_count, 0, chunk_a_count);\n-\t\t}\n+\tinputs.SetCardinality(size);\n+\tfor (idx_t i = 0; i < input_count; ++i) {\n+\t\tauto &v = inputs.data[i];\n+\t\tauto &vec = chunk.data[i];\n+\t\tv.Slice(vec, begin, end);\n+\t\tv.Verify(size);\n \t}\n \n \t// Slice to any filtered rows\n@@ -123,29 +102,24 @@ void WindowSegmentTree::WindowSegmentValue(idx_t l_idx, idx_t begin, idx_t end)\n \t\treturn;\n \t}\n \n-\tif (end - begin >= STANDARD_VECTOR_SIZE) {\n-\t\tthrow InternalException(\"Cannot compute window aggregation: bounds are too large\");\n-\t}\n-\n-\tVector s(statep, 0);\n+\tconst auto count = end - begin;\n+\tVector s(statep, 0, count);\n \tif (l_idx == 0) {\n \t\tExtractFrame(begin, end);\n \t\tAggregateInputData aggr_input_data(bind_info, Allocator::DefaultAllocator());\n \t\taggregate.update(&inputs.data[0], aggr_input_data, input_ref->ColumnCount(), s, inputs.size());\n \t} else {\n-\t\tinputs.Reset();\n-\t\tinputs.SetCardinality(end - begin);\n \t\t// find out where the states begin\n \t\tdata_ptr_t begin_ptr = levels_flat_native.get() + state.size() * (begin + levels_flat_start[l_idx - 1]);\n \t\t// set up a vector of pointers that point towards the set of states\n-\t\tVector v(LogicalType::POINTER);\n+\t\tVector v(LogicalType::POINTER, count);\n \t\tauto pdata = FlatVector::GetData<data_ptr_t>(v);\n-\t\tfor (idx_t i = 0; i < inputs.size(); i++) {\n+\t\tfor (idx_t i = 0; i < count; i++) {\n \t\t\tpdata[i] = begin_ptr + i * state.size();\n \t\t}\n-\t\tv.Verify(inputs.size());\n+\t\tv.Verify(count);\n \t\tAggregateInputData aggr_input_data(bind_info, Allocator::DefaultAllocator());\n-\t\taggregate.combine(v, s, aggr_input_data, inputs.size());\n+\t\taggregate.combine(v, s, aggr_input_data, count);\n \t}\n }\n \n@@ -155,7 +129,7 @@ void WindowSegmentTree::ConstructTree() {\n \n \t// compute space required to store internal nodes of segment tree\n \tinternal_nodes = 0;\n-\tidx_t level_nodes = input_ref->Count();\n+\tidx_t level_nodes = input_ref->size();\n \tdo {\n \t\tlevel_nodes = (level_nodes + (TREE_FANOUT - 1)) / TREE_FANOUT;\n \t\tinternal_nodes += level_nodes;\n@@ -168,7 +142,7 @@ void WindowSegmentTree::ConstructTree() {\n \t// level 0 is data itself\n \tidx_t level_size;\n \t// iterate over the levels of the segment tree\n-\twhile ((level_size = (level_current == 0 ? input_ref->Count()\n+\twhile ((level_size = (level_current == 0 ? input_ref->size()\n \t                                         : levels_flat_offset - levels_flat_start[level_current - 1])) > 1) {\n \t\tfor (idx_t pos = 0; pos < level_size; pos += TREE_FANOUT) {\n \t\t\t// compute the aggregate for this entry in the segment tree\n@@ -217,39 +191,9 @@ void WindowSegmentTree::Compute(Vector &result, idx_t rid, idx_t begin, idx_t en\n \t\tframe = FrameBounds(begin, end);\n \n \t\t// Extract the range\n-\t\tauto &coll = *input_ref;\n-\t\tconst auto prev_active = active;\n-\t\tconst FrameBounds combined(MinValue(frame.first, prev.first), MaxValue(frame.second, prev.second));\n-\n-\t\t// The chunk bounds are the range that includes the begin and end - 1\n-\t\tconst FrameBounds prev_chunks(coll.LocateChunk(prev_active.first), coll.LocateChunk(prev_active.second - 1));\n-\t\tconst FrameBounds active_chunks(coll.LocateChunk(combined.first), coll.LocateChunk(combined.second - 1));\n-\n-\t\t// Extract the range\n-\t\tif (active_chunks.first == active_chunks.second) {\n-\t\t\t// If all the data is in a single chunk, then just reference it\n-\t\t\tif (prev_chunks != active_chunks || (!prev.first && !prev.second)) {\n-\t\t\t\tinputs.Reference(coll.GetChunk(active_chunks.first));\n-\t\t\t}\n-\t\t} else if (active_chunks.first == prev_chunks.first && prev_chunks.first != prev_chunks.second) {\n-\t\t\t// If the start chunk did not change, and we are not just a reference, then extend if necessary\n-\t\t\tfor (auto chunk_idx = prev_chunks.second + 1; chunk_idx <= active_chunks.second; ++chunk_idx) {\n-\t\t\t\tinputs.Append(coll.GetChunk(chunk_idx), true);\n-\t\t\t}\n-\t\t} else {\n-\t\t\t// If the first chunk changed, start over\n-\t\t\tinputs.Reset();\n-\t\t\tfor (auto chunk_idx = active_chunks.first; chunk_idx <= active_chunks.second; ++chunk_idx) {\n-\t\t\t\tinputs.Append(coll.GetChunk(chunk_idx), true);\n-\t\t\t}\n-\t\t}\n-\n-\t\tactive = FrameBounds(active_chunks.first * STANDARD_VECTOR_SIZE,\n-\t\t                     MinValue((active_chunks.second + 1) * STANDARD_VECTOR_SIZE, coll.Count()));\n-\n \t\tAggregateInputData aggr_input_data(bind_info, Allocator::DefaultAllocator());\n-\t\taggregate.window(inputs.data.data(), filter_mask, aggr_input_data, inputs.ColumnCount(), state.data(), frame,\n-\t\t                 prev, result, rid, active.first);\n+\t\taggregate.window(input_ref->data.data(), filter_mask, aggr_input_data, inputs.ColumnCount(), state.data(),\n+\t\t                 frame, prev, result, rid, 0);\n \t\treturn;\n \t}\n \ndiff --git a/src/function/aggregate/distributive/approx_count.cpp b/src/function/aggregate/distributive/approx_count.cpp\nindex e5c76f324480..289a01e84930 100644\n--- a/src/function/aggregate/distributive/approx_count.cpp\n+++ b/src/function/aggregate/distributive/approx_count.cpp\n@@ -9,13 +9,27 @@\n namespace duckdb {\n \n struct ApproxDistinctCountState {\n+\tApproxDistinctCountState() : log(nullptr) {\n+\t}\n+\t~ApproxDistinctCountState() {\n+\t\tif (log) {\n+\t\t\tdelete log;\n+\t\t}\n+\t}\n+\tvoid Resize(idx_t count) {\n+\t\tindices.resize(count);\n+\t\tcounts.resize(count);\n+\t}\n+\n \tHyperLogLog *log;\n+\tvector<uint64_t> indices;\n+\tvector<uint8_t> counts;\n };\n \n struct ApproxCountDistinctFunction {\n \ttemplate <class STATE>\n \tstatic void Initialize(STATE *state) {\n-\t\tstate->log = nullptr;\n+\t\tnew (state) STATE;\n \t}\n \n \ttemplate <class STATE, class OP>\n@@ -47,9 +61,7 @@ struct ApproxCountDistinctFunction {\n \t}\n \ttemplate <class STATE>\n \tstatic void Destroy(STATE *state) {\n-\t\tif (state->log) {\n-\t\t\tdelete state->log;\n-\t\t}\n+\t\tstate->~STATE();\n \t}\n };\n \n@@ -65,8 +77,9 @@ static void ApproxCountDistinctSimpleUpdateFunction(Vector inputs[], AggregateIn\n \tUnifiedVectorFormat vdata;\n \tinputs[0].ToUnifiedFormat(count, vdata);\n \n-\tuint64_t indices[STANDARD_VECTOR_SIZE];\n-\tuint8_t counts[STANDARD_VECTOR_SIZE];\n+\tagg_state->Resize(count);\n+\tauto indices = agg_state->indices.data();\n+\tauto counts = agg_state->counts.data();\n \n \tHyperLogLog::ProcessEntries(vdata, inputs[0].GetType(), indices, counts, count);\n \tagg_state->log->AddToLog(vdata, count, indices, counts);\n@@ -80,19 +93,23 @@ static void ApproxCountDistinctUpdateFunction(Vector inputs[], AggregateInputDat\n \tstate_vector.ToUnifiedFormat(count, sdata);\n \tauto states = (ApproxDistinctCountState **)sdata.data;\n \n+\tuint64_t *indices;\n+\tuint8_t *counts;\n \tfor (idx_t i = 0; i < count; i++) {\n \t\tauto agg_state = states[sdata.sel->get_index(i)];\n \t\tif (!agg_state->log) {\n \t\t\tagg_state->log = new HyperLogLog();\n \t\t}\n+\t\tif (i == 0) {\n+\t\t\tagg_state->Resize(count);\n+\t\t\tindices = agg_state->indices.data();\n+\t\t\tcounts = agg_state->counts.data();\n+\t\t}\n \t}\n \n \tUnifiedVectorFormat vdata;\n \tinputs[0].ToUnifiedFormat(count, vdata);\n \n-\tuint64_t indices[STANDARD_VECTOR_SIZE];\n-\tuint8_t counts[STANDARD_VECTOR_SIZE];\n-\n \tHyperLogLog::ProcessEntries(vdata, inputs[0].GetType(), indices, counts, count);\n \tHyperLogLog::AddToLogs(vdata, count, indices, counts, (HyperLogLog ***)states, sdata.sel);\n }\ndiff --git a/src/include/duckdb/common/types/validity_mask.hpp b/src/include/duckdb/common/types/validity_mask.hpp\nindex e5a86f59587a..c09c3ac0b41b 100644\n--- a/src/include/duckdb/common/types/validity_mask.hpp\n+++ b/src/include/duckdb/common/types/validity_mask.hpp\n@@ -331,7 +331,7 @@ struct ValidityMask : public TemplatedValidityMask<validity_t> {\n public:\n \tDUCKDB_API void Resize(idx_t old_size, idx_t new_size);\n \n-\tDUCKDB_API void Slice(const ValidityMask &other, idx_t offset);\n+\tDUCKDB_API void Slice(const ValidityMask &other, idx_t offset, idx_t end);\n \tDUCKDB_API void Combine(const ValidityMask &other, idx_t count);\n \tDUCKDB_API string ToString(idx_t count) const;\n };\ndiff --git a/src/include/duckdb/common/types/vector.hpp b/src/include/duckdb/common/types/vector.hpp\nindex 9847d94781c4..34f3f04dec67 100644\n--- a/src/include/duckdb/common/types/vector.hpp\n+++ b/src/include/duckdb/common/types/vector.hpp\n@@ -48,11 +48,11 @@ class Vector {\n \n public:\n \t//! Create a vector that references the other vector\n-\tDUCKDB_API explicit Vector(Vector &other);\n+\tDUCKDB_API Vector(Vector &other);\n \t//! Create a vector that slices another vector\n \tDUCKDB_API explicit Vector(Vector &other, const SelectionVector &sel, idx_t count);\n-\t//! Create a vector that slices another vector starting from a specific offset\n-\tDUCKDB_API explicit Vector(Vector &other, idx_t offset);\n+\t//! Create a vector that slices another vector between a pair of offsets\n+\tDUCKDB_API explicit Vector(Vector &other, idx_t offset, idx_t end);\n \t//! Create a vector of size one holding the passed on value\n \tDUCKDB_API explicit Vector(const Value &value);\n \t//! Create a vector of size tuple_count (non-standard)\n@@ -93,7 +93,7 @@ class Vector {\n \tDUCKDB_API void ResetFromCache(const VectorCache &cache);\n \n \t//! Creates a reference to a slice of the other vector\n-\tDUCKDB_API void Slice(Vector &other, idx_t offset);\n+\tDUCKDB_API void Slice(Vector &other, idx_t offset, idx_t end);\n \t//! Creates a reference to a slice of the other vector\n \tDUCKDB_API void Slice(Vector &other, const SelectionVector &sel, idx_t count);\n \t//! Turns the vector into a dictionary vector with the specified dictionary\n@@ -200,7 +200,8 @@ class Vector {\n //! The DictionaryBuffer holds a selection vector\n class VectorChildBuffer : public VectorBuffer {\n public:\n-\tVectorChildBuffer(Vector vector) : VectorBuffer(VectorBufferType::VECTOR_CHILD_BUFFER), data(move(vector)) {\n+\texplicit VectorChildBuffer(Vector vector)\n+\t    : VectorBuffer(VectorBufferType::VECTOR_CHILD_BUFFER), data(move(vector)) {\n \t}\n \n public:\ndiff --git a/src/include/duckdb/execution/window_segment_tree.hpp b/src/include/duckdb/execution/window_segment_tree.hpp\nindex 904507f6c6f0..e871848cab3b 100644\n--- a/src/include/duckdb/execution/window_segment_tree.hpp\n+++ b/src/include/duckdb/execution/window_segment_tree.hpp\n@@ -8,7 +8,7 @@\n \n #pragma once\n \n-#include \"duckdb/common/types/chunk_collection.hpp\"\n+#include \"duckdb/common/types/data_chunk.hpp\"\n #include \"duckdb/execution/physical_operator.hpp\"\n #include \"duckdb/function/aggregate_function.hpp\"\n #include \"duckdb/common/enums/window_aggregation_mode.hpp\"\n@@ -20,7 +20,7 @@ class WindowSegmentTree {\n \tusing FrameBounds = std::pair<idx_t, idx_t>;\n \n \tWindowSegmentTree(AggregateFunction &aggregate, FunctionData *bind_info, const LogicalType &result_type,\n-\t                  ChunkCollection *input, const ValidityMask &filter_mask, WindowAggregationMode mode);\n+\t                  DataChunk *input, const ValidityMask &filter_mask, WindowAggregationMode mode);\n \t~WindowSegmentTree();\n \n \t//! First row contains the result.\n@@ -59,8 +59,6 @@ class WindowSegmentTree {\n \tVector statep;\n \t//! The frame boundaries, used for the window functions\n \tFrameBounds frame;\n-\t//! The active data in the inputs. Used for the window functions\n-\tFrameBounds active;\n \t//! Reused result state container for the window functions\n \tVector statev;\n \n@@ -73,7 +71,7 @@ class WindowSegmentTree {\n \tidx_t internal_nodes;\n \n \t//! The (sorted) input chunk collection on which the tree is built\n-\tChunkCollection *input_ref;\n+\tDataChunk *input_ref;\n \n \t//! The filtered rows in input_ref.\n \tconst ValidityMask &filter_mask;\ndiff --git a/src/storage/table/row_group.cpp b/src/storage/table/row_group.cpp\nindex 779ad421ce11..fa0ba0d147af 100644\n--- a/src/storage/table/row_group.cpp\n+++ b/src/storage/table/row_group.cpp\n@@ -637,7 +637,7 @@ void RowGroup::Update(TransactionData transaction, DataChunk &update_chunk, row_\n \t\tD_ASSERT(column != COLUMN_IDENTIFIER_ROW_ID);\n \t\tD_ASSERT(columns[column]->type.id() == update_chunk.data[i].GetType().id());\n \t\tif (offset > 0) {\n-\t\t\tVector sliced_vector(update_chunk.data[i], offset);\n+\t\t\tVector sliced_vector(update_chunk.data[i], offset, offset + count);\n \t\t\tsliced_vector.Flatten(count);\n \t\t\tcolumns[column]->Update(transaction, column, sliced_vector, ids + offset, count);\n \t\t} else {\ndiff --git a/tools/rpkg/src/statement.cpp b/tools/rpkg/src/statement.cpp\nindex 11ba7efe2458..54f06e02447c 100644\n--- a/tools/rpkg/src/statement.cpp\n+++ b/tools/rpkg/src/statement.cpp\n@@ -493,7 +493,8 @@ static void transform(Vector &src_vec, SEXP &dest, idx_t dest_offset, idx_t n, b\n \t\t\tif (!FlatVector::Validity(src_vec).RowIsValid(row_idx)) {\n \t\t\t\tSET_ELEMENT(dest, dest_offset + row_idx, R_NilValue);\n \t\t\t} else {\n-\t\t\t\tchild_vector.Slice(ListVector::GetEntry(src_vec), src_data[row_idx].offset);\n+\t\t\t\tconst auto end = src_data[row_idx].offset + src_data[row_idx].length;\n+\t\t\t\tchild_vector.Slice(ListVector::GetEntry(src_vec), src_data[row_idx].offset, end);\n \n \t\t\t\tRProtector ele_prot;\n \t\t\t\t// transform the list child vector to a single R SEXP\n",
  "test_patch": "diff --git a/test/fuzzer/afl/window_function_binder_error.test b/test/fuzzer/afl/window_function_binder_error.test\nindex 3a2cd771e6aa..c722ea549693 100644\n--- a/test/fuzzer/afl/window_function_binder_error.test\n+++ b/test/fuzzer/afl/window_function_binder_error.test\n@@ -2,8 +2,6 @@\n # description: Invalid window function call\n # group: [afl]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/fuzzer/sqlsmith/fuzzer_window_varchar.test b/test/fuzzer/sqlsmith/fuzzer_window_varchar.test\nindex 3ce8462eda90..15a6aed03032 100644\n--- a/test/fuzzer/sqlsmith/fuzzer_window_varchar.test\n+++ b/test/fuzzer/sqlsmith/fuzzer_window_varchar.test\n@@ -2,8 +2,6 @@\n # description: Fuzzer #76: invalid string assertion in window function\n # group: [sqlsmith]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/issues/fuzz/encode_string_data_crash.test b/test/issues/fuzz/encode_string_data_crash.test\nindex 5320f7cf8a98..a52920a52720 100644\n--- a/test/issues/fuzz/encode_string_data_crash.test\n+++ b/test/issues/fuzz/encode_string_data_crash.test\n@@ -2,8 +2,6 @@\n # description: Issue #3350: SEGV in duckdb::EncodeStringDataPrefix\n # group: [fuzz]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/issues/general/test_4625.test b/test/issues/general/test_4625.test\nindex 187d32342bb0..38f98a4deedd 100644\n--- a/test/issues/general/test_4625.test\n+++ b/test/issues/general/test_4625.test\n@@ -2,8 +2,6 @@\n # description: Issue 4625: Address boundary error when using PARTITION BY\n # group: [general]\n \n-require vector_size 512\n-\n statement ok\n CREATE TABLE \"crash\"\n (\"amount\" \"FLOAT\",\ndiff --git a/test/issues/monetdb/analytics11.test b/test/issues/monetdb/analytics11.test\nindex a7c2a69f2cd8..2270c4351fba 100644\n--- a/test/issues/monetdb/analytics11.test\n+++ b/test/issues/monetdb/analytics11.test\n@@ -2,8 +2,6 @@\n # description: MonetDB Test for grouping sets\n # group: [monetdb]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sakila/test_sakila.test_slow b/test/sakila/test_sakila.test_slow\nindex 0e65c7d013d4..531b4eba856d 100644\n--- a/test/sakila/test_sakila.test_slow\n+++ b/test/sakila/test_sakila.test_slow\n@@ -2,10 +2,6 @@\n # description: Run Sakila test queries\n # group: [sakila]\n \n-require vector_size 512\n-\n-\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/aggregate/aggregates/test_any_value.test b/test/sql/aggregate/aggregates/test_any_value.test\nindex f1e902dcd389..3cd94471ff1d 100644\n--- a/test/sql/aggregate/aggregates/test_any_value.test\n+++ b/test/sql/aggregate/aggregates/test_any_value.test\n@@ -216,8 +216,6 @@ statement ok\n DROP TABLE five_complex\n \n # Window Function\n-require vector_size 512\n-\n query I\n SELECT ANY_VALUE(i) OVER () AS a FROM generate_series(1, 5) t(i);\n ----\ndiff --git a/test/sql/aggregate/aggregates/test_approx_quantile.test b/test/sql/aggregate/aggregates/test_approx_quantile.test\nindex 2aead64d8022..97da71b03d29 100644\n--- a/test/sql/aggregate/aggregates/test_approx_quantile.test\n+++ b/test/sql/aggregate/aggregates/test_approx_quantile.test\n@@ -4,8 +4,6 @@\n \n require skip_reload\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/aggregate/aggregates/test_approximate_distinct_count.test b/test/sql/aggregate/aggregates/test_approximate_distinct_count.test\nindex d1fb8aec6174..0a28eec41076 100644\n--- a/test/sql/aggregate/aggregates/test_approximate_distinct_count.test\n+++ b/test/sql/aggregate/aggregates/test_approximate_distinct_count.test\n@@ -63,8 +63,6 @@ SELECT approx_count_distinct(a) from t group by a %2;\n 993\n 986\n \n-require vector_size 512\n-\n query I\n SELECT count(*) from t where a < 10;\n ----\ndiff --git a/test/sql/aggregate/aggregates/test_arg_min_max.test b/test/sql/aggregate/aggregates/test_arg_min_max.test\nindex 9b08530e5503..224d3fe9376c 100644\n--- a/test/sql/aggregate/aggregates/test_arg_min_max.test\n+++ b/test/sql/aggregate/aggregates/test_arg_min_max.test\n@@ -89,8 +89,6 @@ select argmin(a,b), argmax(a,b)  from blobs ;\n 5\t20\n \n # Window Function\n-require vector_size 512\n-\n query I rowsort\n select argmin(a,b) over ( partition by a%2) from args;\n ----\ndiff --git a/test/sql/aggregate/aggregates/test_bool.test b/test/sql/aggregate/aggregates/test_bool.test\nindex 6f50fd1d12af..5f76f7d6a0b6 100644\n--- a/test/sql/aggregate/aggregates/test_bool.test\n+++ b/test/sql/aggregate/aggregates/test_bool.test\n@@ -75,8 +75,6 @@ NULL\tNULL\tNULL\n 2021-02-10\t1\t1\n \n # Window Function\n-require vector_size 512\n-\n query I\n select bool_or(d > '2021-02-09') over (partition by d)\n     from t order by d;\ndiff --git a/test/sql/aggregate/aggregates/test_corr.test b/test/sql/aggregate/aggregates/test_corr.test\nindex 4e96b0a89718..5dedec3b4723 100644\n--- a/test/sql/aggregate/aggregates/test_corr.test\n+++ b/test/sql/aggregate/aggregates/test_corr.test\n@@ -37,8 +37,6 @@ select  corr(v, v2) from aggr\n 0.9988445981\n \n # Window Function\n-require vector_size 512\n-\n query I rowsort\n select  corr(v, v2) over (partition by k)\n     from aggr;\ndiff --git a/test/sql/aggregate/aggregates/test_entropy.test b/test/sql/aggregate/aggregates/test_entropy.test\nindex 04bb79a6b6fa..90cae4638953 100644\n--- a/test/sql/aggregate/aggregates/test_entropy.test\n+++ b/test/sql/aggregate/aggregates/test_entropy.test\n@@ -52,8 +52,6 @@ select entropy(name) from names;\n ----\n 1.459148\n \n-require vector_size 512\n-\n query I rowsort\n select entropy(k) over (partition by k%2)\n     from aggr;\ndiff --git a/test/sql/aggregate/aggregates/test_histogram.test b/test/sql/aggregate/aggregates/test_histogram.test\nindex f4d8c99c63c5..876aca069b1f 100644\n--- a/test/sql/aggregate/aggregates/test_histogram.test\n+++ b/test/sql/aggregate/aggregates/test_histogram.test\n@@ -106,8 +106,6 @@ SELECT histogram(CAST('2022-01-02' AS DATE));\n ----\n {2022-01-02=1}\n \n-require vector_size 512\n-\n query II rowsort\n select g,histogram(g) over (partition by g%2)\n     from hist_data;\ndiff --git a/test/sql/aggregate/aggregates/test_kurtosis.test b/test/sql/aggregate/aggregates/test_kurtosis.test\nindex bf31ad256a5a..2742ef409e4a 100644\n--- a/test/sql/aggregate/aggregates/test_kurtosis.test\n+++ b/test/sql/aggregate/aggregates/test_kurtosis.test\n@@ -71,8 +71,6 @@ NULL\n -3.977599\n \n # Window Function\n-require vector_size 512\n-\n query I rowsort\n select kurtosis(v2) over (partition by v)\n     from aggr;\ndiff --git a/test/sql/aggregate/aggregates/test_mode.test b/test/sql/aggregate/aggregates/test_mode.test\nindex 4ef756e1aea5..e56fbafe1990 100644\n--- a/test/sql/aggregate/aggregates/test_mode.test\n+++ b/test/sql/aggregate/aggregates/test_mode.test\n@@ -72,8 +72,6 @@ select mode(name) from names;\n ----\n pedro\n \n-require vector_size 512\n-\n query III\n select k, v, mode(v) over (partition by k)\n     from aggr\ndiff --git a/test/sql/aggregate/aggregates/test_product.test b/test/sql/aggregate/aggregates/test_product.test\nindex 55896a2815af..a19546860e10 100644\n--- a/test/sql/aggregate/aggregates/test_product.test\n+++ b/test/sql/aggregate/aggregates/test_product.test\n@@ -55,8 +55,6 @@ SELECT PRODUCT(i) FROM range(100) tbl(i) WHERE 1=0;\n NULL\n \n # Window Function\n-require vector_size 512\n-\n query I rowsort\n select product(i) over (partition by i%2)\n     from integers;\ndiff --git a/test/sql/aggregate/aggregates/test_regression.test b/test/sql/aggregate/aggregates/test_regression.test\nindex 510357cc9ae1..e560e46514eb 100644\n--- a/test/sql/aggregate/aggregates/test_regression.test\n+++ b/test/sql/aggregate/aggregates/test_regression.test\n@@ -278,8 +278,6 @@ select regr_intercept(v, v2) from aggr;\n \n \n # Window Function\n-require vector_size 512\n-\n query I rowsort\n select  regr_avgx(v, v2) over (partition by k)\n     from aggr;\ndiff --git a/test/sql/aggregate/aggregates/test_sem.test b/test/sql/aggregate/aggregates/test_sem.test\nindex 819aa0748ba3..a38c42fe9cba 100644\n--- a/test/sql/aggregate/aggregates/test_sem.test\n+++ b/test/sql/aggregate/aggregates/test_sem.test\n@@ -37,8 +37,6 @@ select  sem(v),sem(v2) from aggr\n 3.577709\t5.663398\n \n # Window Function\n-require vector_size 512\n-\n query I rowsort\n select  sem(v) over (partition by k)\n     from aggr;\ndiff --git a/test/sql/aggregate/aggregates/test_skewness.test b/test/sql/aggregate/aggregates/test_skewness.test\nindex 0df8834795ce..fc5872a1b433 100644\n--- a/test/sql/aggregate/aggregates/test_skewness.test\n+++ b/test/sql/aggregate/aggregates/test_skewness.test\n@@ -66,8 +66,6 @@ NULL\n -0.330141\n \n # Window Function\n-require vector_size 512\n-\n query I\n select skewness(v2) over (partition by v)\n     from aggr order by v;\ndiff --git a/test/sql/aggregate/qualify/test_qualify.test b/test/sql/aggregate/qualify/test_qualify.test\nindex d2cd5feb7ad2..fcd745194011 100644\n--- a/test/sql/aggregate/qualify/test_qualify.test\n+++ b/test/sql/aggregate/qualify/test_qualify.test\n@@ -2,8 +2,6 @@\n # description: Test QUALIFY clause\n # group: [qualify]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/catalog/function/test_complex_macro.test b/test/sql/catalog/function/test_complex_macro.test\nindex cc0a479d9faa..0c244ce1af3c 100644\n--- a/test/sql/catalog/function/test_complex_macro.test\n+++ b/test/sql/catalog/function/test_complex_macro.test\n@@ -277,8 +277,6 @@ doc1\t QU\u00c1CK+QU\u00c1CK+QU\u00c1CK\n doc2\t B\u00c1RK+B\u00c1RK+B\u00c1RK+B\u00c1RK\n \n # macro with window function\n-require vector_size 512\n-\n statement ok\n CREATE MACRO mywindow(k,v) AS SUM(v) OVER (PARTITION BY k)\n \ndiff --git a/test/sql/copy/csv/auto/test_auto_cranlogs.test b/test/sql/copy/csv/auto/test_auto_cranlogs.test\nindex f34660569f5e..bc63fb611626 100644\n--- a/test/sql/copy/csv/auto/test_auto_cranlogs.test\n+++ b/test/sql/copy/csv/auto/test_auto_cranlogs.test\n@@ -2,8 +2,6 @@\n # description: Test read_csv_auto from cranlogs gzip\n # group: [auto]\n \n-require vector_size 512\n-\n statement ok\n CREATE TABLE cranlogs AS SELECT * FROM read_csv_auto ('test/sql/copy/csv/data/real/tmp2013-06-15.csv.gz');\n \ndiff --git a/test/sql/copy/csv/auto/test_auto_greek_ncvoter.test b/test/sql/copy/csv/auto/test_auto_greek_ncvoter.test\nindex edd9b1a1231b..9d6c5620ab97 100644\n--- a/test/sql/copy/csv/auto/test_auto_greek_ncvoter.test\n+++ b/test/sql/copy/csv/auto/test_auto_greek_ncvoter.test\n@@ -2,8 +2,6 @@\n # description: Test read_csv_auto from ncvoter csv\n # group: [auto]\n \n-require vector_size 512\n-\n statement ok\n CREATE TABLE IF NOT EXISTS ncvoters(county_id INTEGER, county_desc STRING, voter_reg_num STRING,status_cd STRING, voter_status_desc STRING, reason_cd STRING, voter_status_reason_desc STRING, absent_ind STRING, name_prefx_cd STRING,last_name STRING, first_name STRING, midl_name STRING, name_sufx_cd STRING, full_name_rep STRING,full_name_mail STRING, house_num STRING, half_code STRING, street_dir STRING, street_name STRING, street_type_cd STRING, street_sufx_cd STRING, unit_designator STRING, unit_num STRING, res_city_desc STRING,state_cd STRING, zip_code STRING, res_street_address STRING, res_city_state_zip STRING, mail_addr1 STRING, mail_addr2 STRING, mail_addr3 STRING, mail_addr4 STRING, mail_city STRING, mail_state STRING, mail_zipcode STRING, mail_city_state_zip STRING, area_cd STRING, phone_num STRING, full_phone_number STRING, drivers_lic STRING, race_code STRING, race_desc STRING, ethnic_code STRING, ethnic_desc STRING, party_cd STRING, party_desc STRING, sex_code STRING, sex STRING, birth_age STRING, birth_place STRING, registr_dt STRING, precinct_abbrv STRING, precinct_desc STRING,municipality_abbrv STRING, municipality_desc STRING, ward_abbrv STRING, ward_desc STRING, cong_dist_abbrv STRING, cong_dist_desc STRING, super_court_abbrv STRING, super_court_desc STRING, judic_dist_abbrv STRING, judic_dist_desc STRING, nc_senate_abbrv STRING, nc_senate_desc STRING, nc_house_abbrv STRING, nc_house_desc STRING,county_commiss_abbrv STRING, county_commiss_desc STRING, township_abbrv STRING, township_desc STRING,school_dist_abbrv STRING, school_dist_desc STRING, fire_dist_abbrv STRING, fire_dist_desc STRING, water_dist_abbrv STRING, water_dist_desc STRING, sewer_dist_abbrv STRING, sewer_dist_desc STRING, sanit_dist_abbrv STRING, sanit_dist_desc STRING, rescue_dist_abbrv STRING, rescue_dist_desc STRING, munic_dist_abbrv STRING, munic_dist_desc STRING, dist_1_abbrv STRING, dist_1_desc STRING, dist_2_abbrv STRING, dist_2_desc STRING, confidential_ind STRING, age STRING, ncid STRING, vtd_abbrv STRING, vtd_desc STRING);\n \ndiff --git a/test/sql/copy/csv/auto/test_auto_greek_utf8.test b/test/sql/copy/csv/auto/test_auto_greek_utf8.test\nindex 340fd0fb4120..c0f77b2c3770 100644\n--- a/test/sql/copy/csv/auto/test_auto_greek_utf8.test\n+++ b/test/sql/copy/csv/auto/test_auto_greek_utf8.test\n@@ -2,8 +2,6 @@\n # description: Test read_csv_auto from greek-utf8 csv\n # group: [auto]\n \n-require vector_size 512\n-\n statement ok\n CREATE TABLE greek_utf8 AS SELECT i, nfc_normalize(j) j, k FROM read_csv_auto ('test/sql/copy/csv/data/real/greek_utf8.csv') t(i, j, k)\n \ndiff --git a/test/sql/copy/csv/auto/test_auto_lineitem.test b/test/sql/copy/csv/auto/test_auto_lineitem.test\nindex 933f39222702..d85f076d40d5 100644\n--- a/test/sql/copy/csv/auto/test_auto_lineitem.test\n+++ b/test/sql/copy/csv/auto/test_auto_lineitem.test\n@@ -2,8 +2,6 @@\n # description: Test copy into auto from lineitem csv\n # group: [auto]\n \n-require vector_size 512\n-\n statement ok\n CREATE TABLE lineitem(l_orderkey INT NOT NULL, l_partkey INT NOT NULL, l_suppkey INT NOT NULL, l_linenumber INT NOT NULL, l_quantity INTEGER NOT NULL, l_extendedprice DECIMAL(15,2) NOT NULL, l_discount DECIMAL(15,2) NOT NULL, l_tax DECIMAL(15,2) NOT NULL, l_returnflag VARCHAR(1) NOT NULL, l_linestatus VARCHAR(1) NOT NULL, l_shipdate DATE NOT NULL, l_commitdate DATE NOT NULL, l_receiptdate DATE NOT NULL, l_shipinstruct VARCHAR(25) NOT NULL, l_shipmode VARCHAR(10) NOT NULL, l_comment VARCHAR(44) NOT NULL);\n \ndiff --git a/test/sql/copy/csv/auto/test_auto_ontime.test b/test/sql/copy/csv/auto/test_auto_ontime.test\nindex 2c96ad3c3d7a..2e9c97ddc0d2 100644\n--- a/test/sql/copy/csv/auto/test_auto_ontime.test\n+++ b/test/sql/copy/csv/auto/test_auto_ontime.test\n@@ -2,8 +2,6 @@\n # description: Test read_csv_auto from on-time dataset\n # group: [auto]\n \n-require vector_size 512\n-\n statement ok\n CREATE TABLE ontime(year SMALLINT, quarter SMALLINT, month SMALLINT, dayofmonth SMALLINT, dayofweek SMALLINT, flightdate DATE, uniquecarrier CHAR(7), airlineid DECIMAL(8,2), carrier CHAR(2), tailnum VARCHAR(50), flightnum VARCHAR(10), originairportid INTEGER, originairportseqid INTEGER, origincitymarketid INTEGER, origin CHAR(5), origincityname VARCHAR(100), originstate CHAR(2), originstatefips VARCHAR(10), originstatename VARCHAR(100), originwac DECIMAL(8,2), destairportid INTEGER, destairportseqid INTEGER, destcitymarketid INTEGER, dest CHAR(5), destcityname VARCHAR(100), deststate CHAR(2), deststatefips VARCHAR(10), deststatename VARCHAR(100), destwac DECIMAL(8,2), crsdeptime DECIMAL(8,2), deptime DECIMAL(8,2), depdelay DECIMAL(8,2), depdelayminutes DECIMAL(8,2), depdel15 DECIMAL(8,2), departuredelaygroups DECIMAL(8,2), deptimeblk VARCHAR(20), taxiout DECIMAL(8,2), wheelsoff DECIMAL(8,2), wheelson DECIMAL(8,2), taxiin DECIMAL(8,2), crsarrtime DECIMAL(8,2), arrtime DECIMAL(8,2), arrdelay DECIMAL(8,2), arrdelayminutes DECIMAL(8,2), arrdel15 DECIMAL(8,2), arrivaldelaygroups DECIMAL(8,2), arrtimeblk VARCHAR(20), cancelled DECIMAL(8,2), cancellationcode CHAR(1), diverted DECIMAL(8,2), crselapsedtime DECIMAL(8,2), actualelapsedtime DECIMAL(8,2), airtime DECIMAL(8,2), flights DECIMAL(8,2), distance DECIMAL(8,2), distancegroup DECIMAL(8,2), carrierdelay DECIMAL(8,2), weatherdelay DECIMAL(8,2), nasdelay DECIMAL(8,2), securitydelay DECIMAL(8,2), lateaircraftdelay DECIMAL(8,2), firstdeptime VARCHAR(10), totaladdgtime VARCHAR(10), longestaddgtime VARCHAR(10), divairportlandings VARCHAR(10), divreacheddest VARCHAR(10), divactualelapsedtime VARCHAR(10), divarrdelay VARCHAR(10), divdistance VARCHAR(10), div1airport VARCHAR(10), div1aiportid INTEGER, div1airportseqid INTEGER, div1wheelson VARCHAR(10), div1totalgtime VARCHAR(10), div1longestgtime VARCHAR(10), div1wheelsoff VARCHAR(10), div1tailnum VARCHAR(10), div2airport VARCHAR(10), div2airportid INTEGER, div2airportseqid INTEGER, div2wheelson VARCHAR(10), div2totalgtime VARCHAR(10), div2longestgtime VARCHAR(10), div2wheelsoff VARCHAR(10), div2tailnum VARCHAR(10), div3airport VARCHAR(10), div3airportid INTEGER, div3airportseqid INTEGER, div3wheelson VARCHAR(10), div3totalgtime VARCHAR(10), div3longestgtime VARCHAR(10), div3wheelsoff VARCHAR(10), div3tailnum VARCHAR(10), div4airport VARCHAR(10), div4airportid INTEGER, div4airportseqid INTEGER, div4wheelson VARCHAR(10), div4totalgtime VARCHAR(10), div4longestgtime VARCHAR(10), div4wheelsoff VARCHAR(10), div4tailnum VARCHAR(10), div5airport VARCHAR(10), div5airportid INTEGER, div5airportseqid INTEGER, div5wheelson VARCHAR(10), div5totalgtime VARCHAR(10), div5longestgtime VARCHAR(10), div5wheelsoff VARCHAR(10), div5tailnum VARCHAR(10));\n \ndiff --git a/test/sql/copy/csv/auto/test_auto_voter.test b/test/sql/copy/csv/auto/test_auto_voter.test\nindex b84f76c2681e..6fd34b75fda6 100644\n--- a/test/sql/copy/csv/auto/test_auto_voter.test\n+++ b/test/sql/copy/csv/auto/test_auto_voter.test\n@@ -2,8 +2,6 @@\n # description: Test read_csv_auto from voter tsv\n # group: [auto]\n \n-require vector_size 512\n-\n statement ok\n CREATE TABLE voters AS SELECT * FROM read_csv_auto ('test/sql/copy/csv/data/real/voter.tsv');\n \ndiff --git a/test/sql/copy/csv/auto/test_csv_auto.test b/test/sql/copy/csv/auto/test_csv_auto.test\nindex 19a591e80cda..ad1c9397487d 100644\n--- a/test/sql/copy/csv/auto/test_csv_auto.test\n+++ b/test/sql/copy/csv/auto/test_csv_auto.test\n@@ -225,4 +225,4 @@ SELECT a, b FROM test;\n 1\t2\n \n statement ok\n-DROP TABLE test;\n\\ No newline at end of file\n+DROP TABLE test;\ndiff --git a/test/sql/copy/csv/auto/test_fallback_all_varchar.test b/test/sql/copy/csv/auto/test_fallback_all_varchar.test\nindex 4671046c179d..2d459a027d98 100644\n--- a/test/sql/copy/csv/auto/test_fallback_all_varchar.test\n+++ b/test/sql/copy/csv/auto/test_fallback_all_varchar.test\n@@ -2,8 +2,6 @@\n # description: Test optional parameters for read csv\n # group: [auto]\n \n-require vector_size 512\n-\n # CSV file with irregularity in first column and default sample size\n statement ok\n CREATE TABLE test AS SELECT * FROM read_csv_auto ('test/sql/copy/csv/data/auto/test_fallback.csv');\ndiff --git a/test/sql/copy/csv/auto/test_header_completion.test b/test/sql/copy/csv/auto/test_header_completion.test\nindex 3354da39b17b..46a50a500be5 100644\n--- a/test/sql/copy/csv/auto/test_header_completion.test\n+++ b/test/sql/copy/csv/auto/test_header_completion.test\n@@ -2,8 +2,6 @@\n # description: Test csv header completion\n # group: [auto]\n \n-require vector_size 512\n-\n # CSV file with one missing header\n statement ok\n CREATE TABLE test AS SELECT * FROM read_csv_auto ('test/sql/copy/csv/data/auto/missing_header_col.csv');\ndiff --git a/test/sql/copy/csv/auto/test_normalize_names b/test/sql/copy/csv/auto/test_normalize_names\nindex 221af48d51f5..e70293239e6d 100644\n--- a/test/sql/copy/csv/auto/test_normalize_names\n+++ b/test/sql/copy/csv/auto/test_normalize_names\n@@ -2,8 +2,6 @@\n # description: Test csv header normalization\n # group: [auto]\n \n-require vector_size 512\n-\n # CSV file with uppercase header\n statement ok\n CREATE TABLE test AS SELECT * FROM read_csv_auto ('test/sql/copy/csv/data/auto/normalize_names_1.csv', normalize_names=TRUE);\ndiff --git a/test/sql/copy/csv/auto/test_sample_size.test b/test/sql/copy/csv/auto/test_sample_size.test\nindex 4c5a6f613aaf..1b25640dad9d 100644\n--- a/test/sql/copy/csv/auto/test_sample_size.test\n+++ b/test/sql/copy/csv/auto/test_sample_size.test\n@@ -99,4 +99,4 @@ statement ok\n COPY test FROM 'test/sql/copy/csv/data/auto/issue_811.csv' (SAMPLE_SIZE -1, AUTO_DETECT TRUE);\n \n statement ok\n-drop table test;\n\\ No newline at end of file\n+drop table test;\ndiff --git a/test/sql/copy/csv/auto/test_type_detection.test b/test/sql/copy/csv/auto/test_type_detection.test\nindex d2aac0c1c127..f8e2d74aa0a5 100644\n--- a/test/sql/copy/csv/auto/test_type_detection.test\n+++ b/test/sql/copy/csv/auto/test_type_detection.test\n@@ -2,8 +2,6 @@\n # description: Test csv type detection\n # group: [auto]\n \n-require vector_size 512\n-\n # a CSV file with many strings\n statement ok\n CREATE TABLE test AS SELECT * FROM read_csv_auto ('test/sql/copy/csv/data/auto/large_mixed_data.csv', SAMPLE_SIZE=-1);\ndiff --git a/test/sql/copy/parquet/infer_copy_format.test b/test/sql/copy/parquet/infer_copy_format.test\nindex 1e409c65fd05..2516caa34584 100644\n--- a/test/sql/copy/parquet/infer_copy_format.test\n+++ b/test/sql/copy/parquet/infer_copy_format.test\n@@ -2,8 +2,6 @@\n # description: Infer COPY TO format test\n # group: [parquet]\n \n-require vector_size 512\n-\n require parquet\n \n statement ok\ndiff --git a/test/sql/copy/parquet/test_parquet_scan.test b/test/sql/copy/parquet/test_parquet_scan.test\nindex fb703caeb238..608d33fb803a 100644\n--- a/test/sql/copy/parquet/test_parquet_scan.test\n+++ b/test/sql/copy/parquet/test_parquet_scan.test\n@@ -4,8 +4,6 @@\n \n require parquet\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/copy/parquet/writer/parquet_write_booleans.test b/test/sql/copy/parquet/writer/parquet_write_booleans.test\nindex 0362a442d163..bc1766f5f799 100644\n--- a/test/sql/copy/parquet/writer/parquet_write_booleans.test\n+++ b/test/sql/copy/parquet/writer/parquet_write_booleans.test\n@@ -4,8 +4,6 @@\n \n require parquet\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/copy/parquet/writer/test_parquet_write_complex.test b/test/sql/copy/parquet/writer/test_parquet_write_complex.test\nindex 90ac7229fac5..a2b6a93f19eb 100644\n--- a/test/sql/copy/parquet/writer/test_parquet_write_complex.test\n+++ b/test/sql/copy/parquet/writer/test_parquet_write_complex.test\n@@ -4,8 +4,6 @@\n \n require parquet\n \n-require vector_size 512\n-\n # alltypes_dictionary: scan as parquet\n query I nosort alltypes_dictionary\n SELECT * FROM parquet_scan('data/parquet-testing/arrow/alltypes_dictionary.parquet');\ndiff --git a/test/sql/function/list/aggregates/mode.test b/test/sql/function/list/aggregates/mode.test\nindex 9c175dbb8542..97328298f344 100644\n--- a/test/sql/function/list/aggregates/mode.test\n+++ b/test/sql/function/list/aggregates/mode.test\n@@ -29,8 +29,6 @@ select list_mode(name) from names;\n ----\n pedro\n \n-require vector_size 512\n-\n # temporal types\n \n # date\ndiff --git a/test/sql/function/list/lambdas/expression_iterator_cases.test b/test/sql/function/list/lambdas/expression_iterator_cases.test\nindex 1b0e9e96934b..97a32fd02562 100644\n--- a/test/sql/function/list/lambdas/expression_iterator_cases.test\n+++ b/test/sql/function/list/lambdas/expression_iterator_cases.test\n@@ -125,8 +125,6 @@ SELECT list_filter([1], x -> x = UNNEST([1]));\n ----\n [1]\n \n-require vector_size 512\n-\n # BOUND_WINDOW\n \n statement ok\ndiff --git a/test/sql/function/list/lambdas/transform.test b/test/sql/function/list/lambdas/transform.test\nindex 5c2ac4bb4ed4..5a70478404be 100644\n--- a/test/sql/function/list/lambdas/transform.test\n+++ b/test/sql/function/list/lambdas/transform.test\n@@ -269,8 +269,6 @@ SELECT list_transform([1, 2, 3], x -> x + #1) FROM range(10)\n \n # test for issue 4855\n \n-require vector_size 512\n-\n statement ok\n create table test(a int, b int);\n \ndiff --git a/test/sql/generated_columns/virtual/partition.test b/test/sql/generated_columns/virtual/partition.test\nindex 4a3974db555f..1d5d2bd2322f 100644\n--- a/test/sql/generated_columns/virtual/partition.test\n+++ b/test/sql/generated_columns/virtual/partition.test\n@@ -5,8 +5,6 @@\n statement ok\n PRAGMA enable_verification\n \n-require vector_size 512\n-\n statement ok\n CREATE TABLE unit (\n \tprice INTEGER,\ndiff --git a/test/sql/prepared/prepare_window_functions.test b/test/sql/prepared/prepare_window_functions.test\nindex fe893007beaf..ad34e0e13cb3 100644\n--- a/test/sql/prepared/prepare_window_functions.test\n+++ b/test/sql/prepared/prepare_window_functions.test\n@@ -2,8 +2,6 @@\n # description: PREPARE of window functions\n # group: [prepared]\n \n-require vector_size 512\n-\n # ambiguous window function usage\n statement ok\n PREPARE v1 AS SELECT SUM(?) OVER ()\ndiff --git a/test/sql/progress_bar/test_parquet.test_slow b/test/sql/progress_bar/test_parquet.test_slow\nindex 4821781867f9..1c4d83063132 100644\n--- a/test/sql/progress_bar/test_parquet.test_slow\n+++ b/test/sql/progress_bar/test_parquet.test_slow\n@@ -4,8 +4,6 @@\n \n require parquet\n \n-require vector_size 512\n-\n require tpch\n \n statement ok\ndiff --git a/test/sql/storage/compression/dictionary/dictionary_compression_ratio.test_coverage b/test/sql/storage/compression/dictionary/dictionary_compression_ratio.test_coverage\nindex 3faf8fdac660..ee4d85a65265 100644\n--- a/test/sql/storage/compression/dictionary/dictionary_compression_ratio.test_coverage\n+++ b/test/sql/storage/compression/dictionary/dictionary_compression_ratio.test_coverage\n@@ -5,8 +5,6 @@\n # load the DB from disk\n load __TEST_DIR__/test_dictionary.db\n \n-require vector_size 512\n-\n # First test: detailed compression ratio\n statement ok\n PRAGMA force_compression='dictionary'\ndiff --git a/test/sql/storage/compression/fsst/fsst_compression_ratio.test_slow b/test/sql/storage/compression/fsst/fsst_compression_ratio.test_slow\nindex 63a9af7c32a2..1e7d3d815940 100644\n--- a/test/sql/storage/compression/fsst/fsst_compression_ratio.test_slow\n+++ b/test/sql/storage/compression/fsst/fsst_compression_ratio.test_slow\n@@ -5,8 +5,6 @@\n # load the DB from disk\n load __TEST_DIR__/test_dictionary.db\n \n-require vector_size 512\n-\n require tpch\n \n # First test: detailed compression ratio\ndiff --git a/test/sql/storage/compression/string/null.test b/test/sql/storage/compression/string/null.test\nindex a8ce0acc3930..87b5b8707c5c 100644\n--- a/test/sql/storage/compression/string/null.test\n+++ b/test/sql/storage/compression/string/null.test\n@@ -2,8 +2,6 @@\n # description: Test storage of string columns with compression and many null values\n # group: [string]\n \n-require vector_size 512\n-\n # load the DB from disk\n load __TEST_DIR__/test_rle.db\n \ndiff --git a/test/sql/subquery/scalar/test_window_function_subquery.test b/test/sql/subquery/scalar/test_window_function_subquery.test\nindex 38a6185c6f02..0f1c670c3b18 100644\n--- a/test/sql/subquery/scalar/test_window_function_subquery.test\n+++ b/test/sql/subquery/scalar/test_window_function_subquery.test\n@@ -2,8 +2,6 @@\n # description: Test window functions in correlated subqueries\n # group: [scalar]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/types/float/nan_window.test b/test/sql/types/float/nan_window.test\nindex 5ad8cbed0666..b583e69b696e 100644\n--- a/test/sql/types/float/nan_window.test\n+++ b/test/sql/types/float/nan_window.test\n@@ -2,8 +2,6 @@\n # description: Test NaN and inf in windowing functions\n # group: [float]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/types/nested/list/list_aggregates.test b/test/sql/types/nested/list/list_aggregates.test\nindex 3a2f1e7b2306..bc5e4c3f25c7 100644\n--- a/test/sql/types/nested/list/list_aggregates.test\n+++ b/test/sql/types/nested/list/list_aggregates.test\n@@ -2,8 +2,6 @@\n # description: Test lists with aggregations\n # group: [list]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_basic_window.test b/test/sql/window/test_basic_window.test\nindex 43a1eae2b530..59def7467ac7 100644\n--- a/test/sql/window/test_basic_window.test\n+++ b/test/sql/window/test_basic_window.test\n@@ -2,8 +2,6 @@\n # description: Most basic window function\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_boundary_expr.test b/test/sql/window/test_boundary_expr.test\nindex 7200d135cad6..4123b84ee85a 100644\n--- a/test/sql/window/test_boundary_expr.test\n+++ b/test/sql/window/test_boundary_expr.test\n@@ -2,8 +2,6 @@\n # description: Expressions in boundaries\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_evil_window.test b/test/sql/window/test_evil_window.test\nindex 8287ac829624..1baca0eef8de 100644\n--- a/test/sql/window/test_evil_window.test\n+++ b/test/sql/window/test_evil_window.test\n@@ -2,8 +2,6 @@\n # description: More evil cases\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_ignore_nulls.test b/test/sql/window/test_ignore_nulls.test\nindex dcc3179d2e0b..5db205676d95 100644\n--- a/test/sql/window/test_ignore_nulls.test\n+++ b/test/sql/window/test_ignore_nulls.test\n@@ -2,8 +2,6 @@\n # description: Test IGNORE NULLS window syntax\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_invalid_window.test b/test/sql/window/test_invalid_window.test\nindex 009c1c04d869..7c39ffb1eccb 100644\n--- a/test/sql/window/test_invalid_window.test\n+++ b/test/sql/window/test_invalid_window.test\n@@ -2,8 +2,6 @@\n # description: Illegal window function\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_list_window.test b/test/sql/window/test_list_window.test\nindex 1428cf2e610f..b57a1a2d8b0e 100644\n--- a/test/sql/window/test_list_window.test\n+++ b/test/sql/window/test_list_window.test\n@@ -2,8 +2,6 @@\n # description: Test aggregate list\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_mad_window.test b/test/sql/window/test_mad_window.test\nindex bcf6996d0e97..59139382bf33 100644\n--- a/test/sql/window/test_mad_window.test\n+++ b/test/sql/window/test_mad_window.test\n@@ -2,8 +2,6 @@\n # description: Test MAD aggregate as a window function\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_mode_window.test b/test/sql/window/test_mode_window.test\nindex 2393f44afb4c..e1b21b95a6bb 100644\n--- a/test/sql/window/test_mode_window.test\n+++ b/test/sql/window/test_mode_window.test\n@@ -2,8 +2,6 @@\n # description: Test MODE aggregate as a window function\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_no_default_window_spec.test b/test/sql/window/test_no_default_window_spec.test\nindex 9b367b849e47..dde87f93269a 100644\n--- a/test/sql/window/test_no_default_window_spec.test\n+++ b/test/sql/window/test_no_default_window_spec.test\n@@ -2,8 +2,6 @@\n # description: Non-default window specs\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_nthvalue.test b/test/sql/window/test_nthvalue.test\nindex c5f224369e06..7da7349324d5 100644\n--- a/test/sql/window/test_nthvalue.test\n+++ b/test/sql/window/test_nthvalue.test\n@@ -2,8 +2,6 @@\n # description: Most basic window function\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_ntile.test b/test/sql/window/test_ntile.test\nindex 12a7a57659d4..7294dd103fb3 100644\n--- a/test/sql/window/test_ntile.test\n+++ b/test/sql/window/test_ntile.test\n@@ -2,8 +2,6 @@\n # description: Test NTile function\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n CREATE TABLE Scoreboard(TeamName VARCHAR, Player VARCHAR, Score INTEGER);\n \ndiff --git a/test/sql/window/test_over_grouping.test_slow b/test/sql/window/test_over_grouping.test_slow\nindex ad65bfbfba92..be4e581dea2c 100644\n--- a/test/sql/window/test_over_grouping.test_slow\n+++ b/test/sql/window/test_over_grouping.test_slow\n@@ -4,8 +4,6 @@\n \n require skip_reload\n \n-require vector_size 512\n-\n #statement ok\n #PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_parallel_window.test_slow b/test/sql/window/test_parallel_window.test_slow\nindex 6e5f9bc5ed02..4eeb65228803 100644\n--- a/test/sql/window/test_parallel_window.test_slow\n+++ b/test/sql/window/test_parallel_window.test_slow\n@@ -2,8 +2,6 @@\n # description: Hashing and parallel execution\n # group: [window]\n \n-require vector_size 512\n-\n #statement ok\n #PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_partition_flushing.test_slow b/test/sql/window/test_partition_flushing.test_slow\nindex 3ce70ca6d105..6e72ddddc597 100644\n--- a/test/sql/window/test_partition_flushing.test_slow\n+++ b/test/sql/window/test_partition_flushing.test_slow\n@@ -2,8 +2,6 @@\n # description: Test chunk flushing under multithreaded partitioning\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n CREATE  TABLE \"data\" (\"Store\" INTEGER, \"Dept\" INTEGER, \"Date\" DATE, \"Weekly_Sales\" DOUBLE, \"IsHoliday\" BOOLEAN);\n \ndiff --git a/test/sql/window/test_quantile_window.test b/test/sql/window/test_quantile_window.test\nindex 24291575b6b6..7554ecd385c1 100644\n--- a/test/sql/window/test_quantile_window.test\n+++ b/test/sql/window/test_quantile_window.test\n@@ -2,8 +2,6 @@\n # description: Test MEDIAN and QUANTILE aggregates as window functions\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_scalar_window.test b/test/sql/window/test_scalar_window.test\nindex 783d10786b97..ff72b0ab44b6 100644\n--- a/test/sql/window/test_scalar_window.test\n+++ b/test/sql/window/test_scalar_window.test\n@@ -2,8 +2,6 @@\n # description: Most scalar window functions\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_tpcds_q49.test b/test/sql/window/test_tpcds_q49.test\nindex 90c56b40da6f..5ce2e7ae30f7 100644\n--- a/test/sql/window/test_tpcds_q49.test\n+++ b/test/sql/window/test_tpcds_q49.test\n@@ -2,8 +2,6 @@\n # description: TPC-DS Q49 bug fix for multi-sort window functions\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_1367.test_slow b/test/sql/window/test_window_1367.test_slow\nindex 70a5391d8157..1f28495925ee 100644\n--- a/test/sql/window/test_window_1367.test_slow\n+++ b/test/sql/window/test_window_1367.test_slow\n@@ -2,8 +2,6 @@\n # description: Performance test from Issue #1367\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_binding.test b/test/sql/window/test_window_binding.test\nindex 6d4979e9b6a0..e2e405b767e8 100644\n--- a/test/sql/window/test_window_binding.test\n+++ b/test/sql/window/test_window_binding.test\n@@ -2,8 +2,6 @@\n # description: Test errors in binding window functions\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_binding_ctes.test b/test/sql/window/test_window_binding_ctes.test\nindex c698cfc56cb7..b7fefc55d3c1 100644\n--- a/test/sql/window/test_window_binding_ctes.test\n+++ b/test/sql/window/test_window_binding_ctes.test\n@@ -2,8 +2,6 @@\n # description: Test binding of named window functions in CTEs\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_bool.test b/test/sql/window/test_window_bool.test\nindex acffb57559f2..e1a4a86276db 100644\n--- a/test/sql/window/test_window_bool.test\n+++ b/test/sql/window/test_window_bool.test\n@@ -2,8 +2,6 @@\n # description: Test window functions with booleans\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_clause.test b/test/sql/window/test_window_clause.test\nindex 76b29e181757..da5b3b32290f 100644\n--- a/test/sql/window/test_window_clause.test\n+++ b/test/sql/window/test_window_clause.test\n@@ -2,8 +2,6 @@\n # description: Most basic window function\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_dbplyr.test b/test/sql/window/test_window_dbplyr.test\nindex 84cc2eacf2b0..4e3ef25805c9 100644\n--- a/test/sql/window/test_window_dbplyr.test\n+++ b/test/sql/window/test_window_dbplyr.test\n@@ -2,8 +2,6 @@\n # description: Ensure dbplyr crash with ORDER BY under window stays fixed\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_filter.test b/test/sql/window/test_window_filter.test\nindex 214995c97795..cfc93a910327 100644\n--- a/test/sql/window/test_window_filter.test\n+++ b/test/sql/window/test_window_filter.test\n@@ -2,8 +2,6 @@\n # description: FILTER clause for WINDOW functions\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_interval.test b/test/sql/window/test_window_interval.test\nindex 68029c7ff7f6..318e8d705a7f 100644\n--- a/test/sql/window/test_window_interval.test\n+++ b/test/sql/window/test_window_interval.test\n@@ -2,8 +2,6 @@\n # description: Test window functions with intervals\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_range.test b/test/sql/window/test_window_range.test\nindex 13a014a90086..de183643137a 100644\n--- a/test/sql/window/test_window_range.test\n+++ b/test/sql/window/test_window_range.test\n@@ -2,8 +2,6 @@\n # description: Range functionality tests. Taken from sqlite test/window8.test\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_string_agg.test b/test/sql/window/test_window_string_agg.test\nindex 40435529afd3..f7e7d3d53333 100644\n--- a/test/sql/window/test_window_string_agg.test\n+++ b/test/sql/window/test_window_string_agg.test\n@@ -2,8 +2,6 @@\n # description: Test string_agg with window functions\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_tpcds.test b/test/sql/window/test_window_tpcds.test\nindex 1e5edd1ba896..aec09c6dc926 100644\n--- a/test/sql/window/test_window_tpcds.test\n+++ b/test/sql/window/test_window_tpcds.test\n@@ -2,8 +2,6 @@\n # description: TPC-DS inspired micro benchmarks\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_types.test b/test/sql/window/test_window_types.test\nindex 7c60f544cab7..90cc48c02061 100644\n--- a/test/sql/window/test_window_types.test\n+++ b/test/sql/window/test_window_types.test\n@@ -2,8 +2,6 @@\n # description: Test window functions with different types\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/test_window_walmart.test_slow b/test/sql/window/test_window_walmart.test_slow\nindex b576cbe2e83e..d6450d93cccf 100644\n--- a/test/sql/window/test_window_walmart.test_slow\n+++ b/test/sql/window/test_window_walmart.test_slow\n@@ -2,8 +2,6 @@\n # description: Parallel window lag\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n CREATE  TABLE \"data\" (\"Store\" INTEGER, \"Dept\" INTEGER, \"Date\" DATE, \"Weekly_Sales\" DOUBLE, \"IsHoliday\" BOOLEAN);\n \ndiff --git a/test/sql/window/test_window_wisconsin.test b/test/sql/window/test_window_wisconsin.test\nindex a97e5f5eda82..25eb300559ef 100644\n--- a/test/sql/window/test_window_wisconsin.test\n+++ b/test/sql/window/test_window_wisconsin.test\n@@ -2,8 +2,6 @@\n # description: Wisconsin-derived window test cases\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/window_mtcars.test b/test/sql/window/window_mtcars.test\nindex 398814bbc090..378512d6f5a8 100644\n--- a/test/sql/window/window_mtcars.test\n+++ b/test/sql/window/window_mtcars.test\n@@ -2,8 +2,6 @@\n # description: Test window function without\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/window/window_rolling_summation.test_slow b/test/sql/window/window_rolling_summation.test_slow\nindex f92b05c224fc..cb599c8db0ca 100644\n--- a/test/sql/window/window_rolling_summation.test_slow\n+++ b/test/sql/window/window_rolling_summation.test_slow\n@@ -2,8 +2,6 @@\n # description: Rolling summation (issue #965)\n # group: [window]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sqlserver/test_sqlserver.test_slow b/test/sqlserver/test_sqlserver.test_slow\nindex c95be131b227..88c3f15e23bd 100644\n--- a/test/sqlserver/test_sqlserver.test_slow\n+++ b/test/sqlserver/test_sqlserver.test_slow\n@@ -2,8 +2,6 @@\n # description: SQL Server functions tests\n # group: [sqlserver]\n \n-require vector_size 512\n-\n statement ok\n PRAGMA default_null_order='NULLS LAST'\n \n",
  "problem_statement": "Convert window payloads to DataChunks\nThe input argument payloads for computing window functions are `ChunkCollection`s, which we want to eliminate. With the removal of standard vector size limits from `DataChunk` it makes more sense to just build a partition-sized `DataChunk`.  In future, we hope to reduce partition sizes to a minimum, which should make this even more valuable.\n",
  "hints_text": "",
  "created_at": "2022-10-25T01:19:27Z"
}