{
  "repo": "duckdb/duckdb",
  "pull_number": 16851,
  "instance_id": "duckdb__duckdb-16851",
  "issue_numbers": [
    "16836",
    "16836"
  ],
  "base_commit": "a4380e7c0895ebdb879bf1c32616004643834ff8",
  "patch": "diff --git a/src/storage/compression/roaring/common.cpp b/src/storage/compression/roaring/common.cpp\nindex 190e6dbf682e..c8450c32d7b8 100644\n--- a/src/storage/compression/roaring/common.cpp\n+++ b/src/storage/compression/roaring/common.cpp\n@@ -225,10 +225,6 @@ void RoaringScanPartial(ColumnSegment &segment, ColumnScanState &state, idx_t sc\n }\n \n void RoaringScan(ColumnSegment &segment, ColumnScanState &state, idx_t scan_count, Vector &result) {\n-\tif (result.GetVectorType() == VectorType::DICTIONARY_VECTOR) {\n-\t\t// dictionary encoding handles the validity itself\n-\t\treturn;\n-\t}\n \tRoaringScanPartial(segment, state, scan_count, result, 0);\n }\n \ndiff --git a/src/storage/compression/validity_uncompressed.cpp b/src/storage/compression/validity_uncompressed.cpp\nindex 48f2ec749ed3..8fa4acca9923 100644\n--- a/src/storage/compression/validity_uncompressed.cpp\n+++ b/src/storage/compression/validity_uncompressed.cpp\n@@ -401,10 +401,6 @@ void ValidityScanPartial(ColumnSegment &segment, ColumnScanState &state, idx_t s\n }\n \n void ValidityScan(ColumnSegment &segment, ColumnScanState &state, idx_t scan_count, Vector &result) {\n-\tif (result.GetVectorType() == VectorType::DICTIONARY_VECTOR) {\n-\t\t// dictionary encoding handles the validity itself\n-\t\treturn;\n-\t}\n \tresult.Flatten(scan_count);\n \n \tauto start = segment.GetRelativeIndex(state.row_index);\n",
  "test_patch": "diff --git a/test/sql/storage/update/dictionary_update_null.test b/test/sql/storage/update/dictionary_update_null.test\nnew file mode 100644\nindex 000000000000..038d4b21dcbe\n--- /dev/null\n+++ b/test/sql/storage/update/dictionary_update_null.test\n@@ -0,0 +1,21 @@\n+# name: test/sql/storage/update/dictionary_update_null.test\n+# description: Test updating only the validity mask of a dictionary compressed column\n+# group: [update]\n+\n+# load the DB from disk\n+load __TEST_DIR__/dictionary_update_null.db\n+\n+statement ok\n+SET force_compression='dictionary'\n+\n+statement ok\n+CREATE OR REPLACE TABLE 'everflow_daily' AS SELECT case when i%10=0 THEN uuid()::VARCHAR ELSE 'N/A' END sub4 FROM range(10000) t(i)\n+\n+statement ok\n+UPDATE everflow_daily SET sub4 = NULL WHERE sub4 = 'N/A';\n+\n+query I\n+select count(*) from everflow_daily\n+where sub4 = 'N/A'\n+----\n+0\n",
  "problem_statement": "Regression: incorrect results after UPDATE operation when migrating from DuckDB 1.1.2 to 1.2.1\n### What happens?\n\nhttps://github.com/duckdb/duckdb/issues/16780\nI was able to reproduce it, I've hashed certain columns but still don't feel comfortable sharing them in public, but I have the archive.\n\n### To Reproduce\n\nunarchive the 7z file\nrun this in python 3.12.7 duckdb 1.1.2 in the same folder.\n```\nimport duckdb\nwith duckdb.connect('ddb.db') as conn:\n    conn.execute(fr\"\"\"\n            CREATE OR REPLACE TABLE 'everflow_daily' AS SELECT * FROM read_csv_auto('myexport/*.csv', union_by_name = true, filename = true);\n        UPDATE everflow_daily SET sub5 = replace(sub5, '''', '');\n        UPDATE everflow_daily SET sub5 = lower(trim(sub5));\n        UPDATE everflow_daily SET sub5 = NULL WHERE sub5 = 'n/a';\n        UPDATE everflow_daily SET sub4 = NULL WHERE sub4 = 'N/A';\n        UPDATE everflow_daily SET sub3 = NULL WHERE sub3 = 'N/A';\n        ALTER TABLE everflow_daily\n        ADD offer_type VARCHAR(32);\n\n        UPDATE everflow_daily\n        SET offer_type = CASE \n            WHEN UPPER(offer_name) LIKE '%CPA%' THEN 'CPA'\n            WHEN UPPER(offer_name) LIKE '%CPC%' THEN 'CPC'\n            WHEN UPPER(offer_name) LIKE '%CPL%' THEN 'CPL'\n            ELSE 'Other'\n        END;\n            \"\"\")\n\n```\n\nrun this to see results\n\n```\nselect sub4, sum(revenue), len(sub4), count(*) from everflow_daily\nwhere network_affiliate_id <> 16201\nand sub4 = 'N/A'\nor sub4 = ''\nor sub4 is null\ngroup by 1\norder by 2 desc\n```\n\n![Image](https://github.com/user-attachments/assets/1f11c7a8-f21a-41ec-8dd1-5d20e5b8c8bf)\n\n\nthen run it again in 1.2.1 CLI\n\n![Image](https://github.com/user-attachments/assets/e10ed15e-8690-4d99-b40f-52bca3601937)\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nJohn Doe\n\n### Affiliation:\n\nJohn Doe\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nRegression: incorrect results after UPDATE operation when migrating from DuckDB 1.1.2 to 1.2.1\n### What happens?\n\nhttps://github.com/duckdb/duckdb/issues/16780\nI was able to reproduce it, I've hashed certain columns but still don't feel comfortable sharing them in public, but I have the archive.\n\n### To Reproduce\n\nunarchive the 7z file\nrun this in python 3.12.7 duckdb 1.1.2 in the same folder.\n```\nimport duckdb\nwith duckdb.connect('ddb.db') as conn:\n    conn.execute(fr\"\"\"\n            CREATE OR REPLACE TABLE 'everflow_daily' AS SELECT * FROM read_csv_auto('myexport/*.csv', union_by_name = true, filename = true);\n        UPDATE everflow_daily SET sub5 = replace(sub5, '''', '');\n        UPDATE everflow_daily SET sub5 = lower(trim(sub5));\n        UPDATE everflow_daily SET sub5 = NULL WHERE sub5 = 'n/a';\n        UPDATE everflow_daily SET sub4 = NULL WHERE sub4 = 'N/A';\n        UPDATE everflow_daily SET sub3 = NULL WHERE sub3 = 'N/A';\n        ALTER TABLE everflow_daily\n        ADD offer_type VARCHAR(32);\n\n        UPDATE everflow_daily\n        SET offer_type = CASE \n            WHEN UPPER(offer_name) LIKE '%CPA%' THEN 'CPA'\n            WHEN UPPER(offer_name) LIKE '%CPC%' THEN 'CPC'\n            WHEN UPPER(offer_name) LIKE '%CPL%' THEN 'CPL'\n            ELSE 'Other'\n        END;\n            \"\"\")\n\n```\n\nrun this to see results\n\n```\nselect sub4, sum(revenue), len(sub4), count(*) from everflow_daily\nwhere network_affiliate_id <> 16201\nand sub4 = 'N/A'\nor sub4 = ''\nor sub4 is null\ngroup by 1\norder by 2 desc\n```\n\n![Image](https://github.com/user-attachments/assets/1f11c7a8-f21a-41ec-8dd1-5d20e5b8c8bf)\n\n\nthen run it again in 1.2.1 CLI\n\n![Image](https://github.com/user-attachments/assets/e10ed15e-8690-4d99-b40f-52bca3601937)\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nJohn Doe\n\n### Affiliation:\n\nJohn Doe\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n",
  "hints_text": "Hi, thanks for your work on a reproducer. Is it possible to share the archive in private? If so, please email them to gabor@duckdblabs.com or reach out and we'll discuss a way to transfer it.\nHi, thanks for your work on a reproducer. Is it possible to share the archive in private? If so, please email them to gabor@duckdblabs.com or reach out and we'll discuss a way to transfer it.",
  "created_at": "2025-03-26T18:09:49Z"
}