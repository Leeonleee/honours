{
  "repo": "duckdb/duckdb",
  "pull_number": 8540,
  "instance_id": "duckdb__duckdb-8540",
  "issue_numbers": [
    "8461"
  ],
  "base_commit": "a8ce02cc2e740d8973d26ccdb77d0068c69c9124",
  "patch": "diff --git a/src/common/multi_file_reader.cpp b/src/common/multi_file_reader.cpp\nindex 6a2cbf701725..7dcc44729e38 100644\n--- a/src/common/multi_file_reader.cpp\n+++ b/src/common/multi_file_reader.cpp\n@@ -550,6 +550,12 @@ Value MultiFileReaderOptions::GetHivePartitionValue(const string &base, const st\n \tif (it == hive_types_schema.end()) {\n \t\treturn value;\n \t}\n+\n+\t// Handle nulls\n+\tif (base.empty() || StringUtil::CIEquals(base, \"NULL\")) {\n+\t\treturn Value(it->second);\n+\t}\n+\n \tif (!value.TryCastAs(context, it->second)) {\n \t\tthrow InvalidInputException(\"Unable to cast '%s' (from hive partition column '%s') to: '%s'\", value.ToString(),\n \t\t                            StringUtil::Upper(it->first), it->second.ToString());\n",
  "test_patch": "diff --git a/test/sql/copy/parquet/parquet_hive_null.test b/test/sql/copy/parquet/parquet_hive_null.test\nnew file mode 100644\nindex 000000000000..40ef639007fb\n--- /dev/null\n+++ b/test/sql/copy/parquet/parquet_hive_null.test\n@@ -0,0 +1,31 @@\n+# name: test/sql/copy/parquet/parquet_hive_null.test\n+# description: Test NULL partitioning values\n+# group: [parquet]\n+\n+require parquet\n+\n+statement ok\n+create table test as select i%5 as a, i%2 as b from range(0,10) tbl(i);\n+\n+statement ok\n+copy test to '__TEST_DIR__/null-parquet' (FORMAT 'parquet', PARTITION_BY (a,b));\n+\n+statement ok\n+copy (select 'NULL' as a, 'NULL' as b) to '__TEST_DIR__/null-parquet' (PARTITION_BY (a,b), OVERWRITE_OR_IGNORE, FORMAT 'parquet');\n+\n+query II\n+select * \n+from parquet_scan('__TEST_DIR__/null-parquet/**/*.parquet', hive_partitioning=1, hive_types={'a': INT})\n+ORDER BY ALL\n+----\n+0\t0\n+0\t1\n+1\t0\n+1\t1\n+2\t0\n+2\t1\n+3\t0\n+3\t1\n+4\t0\n+4\t1\n+NULL\tNULL\n",
  "problem_statement": "Hive Typing Does not understand NULL\n### What happens?\n\nIf you have a large, deep tree of hive-partitioned data, it may be that the type sampler \n\n### To Reproduce\n\nThis is easy to fix but hard to reproduce. Unfortunately the data I found it with is highly proprietary, but the tree has about 20K parquet files with the same name in the form `root/key1=BIGINT/key2=BIGINT/problem=BIGINT|NULL/schema.parquet` There are 590 values for `key1` typically 5 values for `key2` and often only 1 `NULL` value for `problem`.\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\nv0.8.2-dev2399 20ad35b3fa\n\n### DuckDB Client:\n\nJDBC\n\n### Full Name:\n\nRichard Wesley\n\n### Affiliation:\n\nDuckDB Labs\n\n### Have you tried this on the latest `master` branch?\n\nI have tested with a master build\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] Yes, I have\n",
  "hints_text": "",
  "created_at": "2023-08-10T18:19:19Z"
}