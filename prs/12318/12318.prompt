You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
Why is the db.file size still large after deleting data or dropping tables? 
### What happens?

I created a table (persistent, dbfile), inserted 1 billion tuples into it, and then deleted these tuples. However, the dbfile remains 89MB in size.

### To Reproduce

```bash
./duckdb vacuum.db
```

```sql
CREATE TABLE test (x INT, y AS (x + 100));
insert into test select range FROM range(1000000000);

delete from test where x % 10 = 7;    --dbfile size : 187MB

delete from test where x % 10 = 6;   --dbfile size : 363MB

delete from test where x % 10 = 5;   --dbfile size : 404M

delete from test where x % 10 = 4;   --dbfile size : 404M

delete from test where x % 10 = 3;   --dbfile size : 566M

delete from test where x % 10 = 2;   --dbfile size : 566M

delete from test where x % 10 = 1;   --dbfile size : 404M

delete from test where x % 10 = 0;   --dbfile size : 404M

delete from test where x % 10 = 8;   --dbfile size : 90M

delete from test where x % 10 = 9;   --dbfile size : 89M

drop table test;                                    --dbfile size : 89M
```


### OS:

MacOs

### DuckDB Version:

0.10.3

### DuckDB Client:

cli

### Full Name:

EricDuck

### Affiliation:

personal

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [ ] Yes, I have
Why is the db.file size still large after deleting data or dropping tables? 
### What happens?

I created a table (persistent, dbfile), inserted 1 billion tuples into it, and then deleted these tuples. However, the dbfile remains 89MB in size.

### To Reproduce

```bash
./duckdb vacuum.db
```

```sql
CREATE TABLE test (x INT, y AS (x + 100));
insert into test select range FROM range(1000000000);

delete from test where x % 10 = 7;    --dbfile size : 187MB

delete from test where x % 10 = 6;   --dbfile size : 363MB

delete from test where x % 10 = 5;   --dbfile size : 404M

delete from test where x % 10 = 4;   --dbfile size : 404M

delete from test where x % 10 = 3;   --dbfile size : 566M

delete from test where x % 10 = 2;   --dbfile size : 566M

delete from test where x % 10 = 1;   --dbfile size : 404M

delete from test where x % 10 = 0;   --dbfile size : 404M

delete from test where x % 10 = 8;   --dbfile size : 90M

delete from test where x % 10 = 9;   --dbfile size : 89M

drop table test;                                    --dbfile size : 89M
```


### OS:

MacOs

### DuckDB Version:

0.10.3

### DuckDB Client:

cli

### Full Name:

EricDuck

### Affiliation:

personal

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [ ] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
18: 
19: ## Installation
20: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
21: 
22: ## Data Import
23: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
24: 
25: ```sql
26: SELECT * FROM 'myfile.csv';
27: SELECT * FROM 'myfile.parquet';
28: ```
29: 
30: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
31: 
32: ## SQL Reference
33: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
34: 
35: ## Development
36: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
37: 
38: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
39: 
40: ## Support
41: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of src/include/duckdb/storage/block_manager.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/storage/block_manager.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/common.hpp"
12: #include "duckdb/common/mutex.hpp"
13: #include "duckdb/common/optional_idx.hpp"
14: #include "duckdb/storage/block.hpp"
15: #include "duckdb/storage/storage_info.hpp"
16: #include "duckdb/common/unordered_map.hpp"
17: 
18: namespace duckdb {
19: class BlockHandle;
20: class BufferManager;
21: class ClientContext;
22: class DatabaseInstance;
23: class MetadataManager;
24: 
25: //! BlockManager is an abstract representation to manage blocks on DuckDB. When writing or reading blocks, the
26: //! BlockManager creates and accesses blocks. The concrete types implement specific block storage strategies.
27: class BlockManager {
28: public:
29: 	BlockManager() = delete;
30: 	BlockManager(BufferManager &buffer_manager, const optional_idx block_alloc_size_p);
31: 	virtual ~BlockManager() = default;
32: 
33: 	//! The buffer manager
34: 	BufferManager &buffer_manager;
35: 
36: public:
37: 	//! Creates a new block inside the block manager
38: 	virtual unique_ptr<Block> ConvertBlock(block_id_t block_id, FileBuffer &source_buffer) = 0;
39: 	virtual unique_ptr<Block> CreateBlock(block_id_t block_id, FileBuffer *source_buffer) = 0;
40: 	//! Return the next free block id
41: 	virtual block_id_t GetFreeBlockId() = 0;
42: 	//! Returns whether or not a specified block is the root block
43: 	virtual bool IsRootBlock(MetaBlockPointer root) = 0;
44: 	//! Mark a block as "free"; free blocks are immediately added to the free list and can be immediately overwritten
45: 	virtual void MarkBlockAsFree(block_id_t block_id) = 0;
46: 	//! Mark a block as "modified"; modified blocks are added to the free list after a checkpoint (i.e. their data is
47: 	//! assumed to be rewritten)
48: 	virtual void MarkBlockAsModified(block_id_t block_id) = 0;
49: 	//! Increase the reference count of a block. The block should hold at least one reference before this method is
50: 	//! called.
51: 	virtual void IncreaseBlockReferenceCount(block_id_t block_id) = 0;
52: 	//! Get the first meta block id
53: 	virtual idx_t GetMetaBlock() = 0;
54: 	//! Read the content of the block from disk
55: 	virtual void Read(Block &block) = 0;
56: 	//! Writes the block to disk
57: 	virtual void Write(FileBuffer &block, block_id_t block_id) = 0;
58: 	//! Writes the block to disk
59: 	void Write(Block &block) {
60: 		Write(block, block.id);
61: 	}
62: 	//! Write the header; should be the final step of a checkpoint
63: 	virtual void WriteHeader(DatabaseHeader header) = 0;
64: 
65: 	//! Returns the number of total blocks
66: 	virtual idx_t TotalBlocks() = 0;
67: 	//! Returns the number of free blocks
68: 	virtual idx_t FreeBlocks() = 0;
69: 
70: 	//! Truncate the underlying database file after a checkpoint
71: 	virtual void Truncate();
72: 
73: 	//! Register a block with the given block id in the base file
74: 	shared_ptr<BlockHandle> RegisterBlock(block_id_t block_id);
75: 	//! Convert an existing in-memory buffer into a persistent disk-backed block
76: 	shared_ptr<BlockHandle> ConvertToPersistent(block_id_t block_id, shared_ptr<BlockHandle> old_block);
77: 
78: 	void UnregisterBlock(block_id_t block_id, bool can_destroy);
79: 
80: 	//! Returns a reference to the metadata manager of this block manager.
81: 	MetadataManager &GetMetadataManager();
82: 	//! Returns the block allocation size of this block manager.
83: 	inline idx_t GetBlockAllocSize() const {
84: 		return block_alloc_size.GetIndex();
85: 	}
86: 	//! Returns the possibly invalid block allocation size of this block manager.
87: 	inline optional_idx GetOptionalBlockAllocSize() const {
88: 		return block_alloc_size;
89: 	}
90: 	//! Returns the block size of this block manager.
91: 	inline idx_t GetBlockSize() const {
92: 		return block_alloc_size.GetIndex() - Storage::BLOCK_HEADER_SIZE;
93: 	}
94: 	//! Sets the block allocation size. This should only happen when initializing an existing database.
95: 	//! When initializing an existing database, we construct the block manager before reading the file header,
96: 	//! which contains the file's actual block allocation size.
97: 	void SetBlockAllocSize(const optional_idx block_alloc_size_p) {
98: 		if (block_alloc_size.IsValid()) {
99: 			throw InternalException("the block allocation size must be set once");
100: 		}
101: 		block_alloc_size = block_alloc_size_p.GetIndex();
102: 	}
103: 
104: private:
105: 	//! The lock for the set of blocks
106: 	mutex blocks_lock;
107: 	//! A mapping of block id -> BlockHandle
108: 	unordered_map<block_id_t, weak_ptr<BlockHandle>> blocks;
109: 	//! The metadata manager
110: 	unique_ptr<MetadataManager> metadata_manager;
111: 	//! The allocation size of blocks managed by this block manager. Defaults to DEFAULT_BLOCK_ALLOC_SIZE
112: 	//! for in-memory block managers. Default to default_block_alloc_size for file-backed block managers.
113: 	//! This is NOT the actual memory available on a block (block_size).
114: 	optional_idx block_alloc_size;
115: };
116: } // namespace duckdb
[end of src/include/duckdb/storage/block_manager.hpp]
[start of src/include/duckdb/storage/in_memory_block_manager.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/storage/in_memory_block_manager.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/common.hpp"
12: #include "duckdb/common/exception.hpp"
13: #include "duckdb/storage/block_manager.hpp"
14: 
15: namespace duckdb {
16: 
17: //! InMemoryBlockManager is an implementation for a BlockManager
18: class InMemoryBlockManager : public BlockManager {
19: public:
20: 	using BlockManager::BlockManager;
21: 
22: 	// LCOV_EXCL_START
23: 	unique_ptr<Block> ConvertBlock(block_id_t block_id, FileBuffer &source_buffer) override {
24: 		throw InternalException("Cannot perform IO in in-memory database - ConvertBlock!");
25: 	}
26: 	unique_ptr<Block> CreateBlock(block_id_t block_id, FileBuffer *source_buffer) override {
27: 		throw InternalException("Cannot perform IO in in-memory database - CreateBlock!");
28: 	}
29: 	block_id_t GetFreeBlockId() override {
30: 		throw InternalException("Cannot perform IO in in-memory database - GetFreeBlockId!");
31: 	}
32: 	bool IsRootBlock(MetaBlockPointer root) override {
33: 		throw InternalException("Cannot perform IO in in-memory database - IsRootBlock!");
34: 	}
35: 	void MarkBlockAsFree(block_id_t block_id) override {
36: 		throw InternalException("Cannot perform IO in in-memory database - MarkBlockAsFree!");
37: 	}
38: 	void MarkBlockAsModified(block_id_t block_id) override {
39: 		throw InternalException("Cannot perform IO in in-memory database - MarkBlockAsModified!");
40: 	}
41: 	void IncreaseBlockReferenceCount(block_id_t block_id) override {
42: 		throw InternalException("Cannot perform IO in in-memory database - IncreaseBlockReferenceCount!");
43: 	}
44: 	idx_t GetMetaBlock() override {
45: 		throw InternalException("Cannot perform IO in in-memory database - GetMetaBlock!");
46: 	}
47: 	void Read(Block &block) override {
48: 		throw InternalException("Cannot perform IO in in-memory database - Read!");
49: 	}
50: 	void Write(FileBuffer &block, block_id_t block_id) override {
51: 		throw InternalException("Cannot perform IO in in-memory database - Write!");
52: 	}
53: 	void WriteHeader(DatabaseHeader header) override {
54: 		throw InternalException("Cannot perform IO in in-memory database - WriteHeader!");
55: 	}
56: 	idx_t TotalBlocks() override {
57: 		throw InternalException("Cannot perform IO in in-memory database - TotalBlocks!");
58: 	}
59: 	idx_t FreeBlocks() override {
60: 		throw InternalException("Cannot perform IO in in-memory database - FreeBlocks!");
61: 	}
62: 	// LCOV_EXCL_STOP
63: };
64: } // namespace duckdb
[end of src/include/duckdb/storage/in_memory_block_manager.hpp]
[start of src/include/duckdb/storage/metadata/metadata_manager.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/storage/metadata/metadata_manager.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/common.hpp"
12: #include "duckdb/storage/block.hpp"
13: #include "duckdb/storage/block_manager.hpp"
14: #include "duckdb/common/set.hpp"
15: #include "duckdb/storage/buffer/buffer_handle.hpp"
16: 
17: namespace duckdb {
18: class DatabaseInstance;
19: struct MetadataBlockInfo;
20: 
21: struct MetadataBlock {
22: 	shared_ptr<BlockHandle> block;
23: 	block_id_t block_id;
24: 	vector<uint8_t> free_blocks;
25: 
26: 	void Write(WriteStream &sink);
27: 	static MetadataBlock Read(ReadStream &source);
28: 
29: 	idx_t FreeBlocksToInteger();
30: 	void FreeBlocksFromInteger(idx_t blocks);
31: };
32: 
33: struct MetadataPointer {
34: 	idx_t block_index : 56;
35: 	uint8_t index : 8;
36: };
37: 
38: struct MetadataHandle {
39: 	MetadataPointer pointer;
40: 	BufferHandle handle;
41: };
42: 
43: class MetadataManager {
44: public:
45: 	//! The amount of metadata blocks per storage block
46: 	static constexpr const idx_t METADATA_BLOCK_COUNT = 64;
47: 	//! The size of metadata blocks
48: 	static constexpr const idx_t METADATA_BLOCK_SIZE = AlignValueFloor(Storage::BLOCK_SIZE / METADATA_BLOCK_COUNT);
49: 
50: public:
51: 	MetadataManager(BlockManager &block_manager, BufferManager &buffer_manager);
52: 	~MetadataManager();
53: 
54: 	MetadataHandle AllocateHandle();
55: 	MetadataHandle Pin(MetadataPointer pointer);
56: 
57: 	MetaBlockPointer GetDiskPointer(MetadataPointer pointer, uint32_t offset = 0);
58: 	MetadataPointer FromDiskPointer(MetaBlockPointer pointer);
59: 	MetadataPointer RegisterDiskPointer(MetaBlockPointer pointer);
60: 
61: 	static BlockPointer ToBlockPointer(MetaBlockPointer meta_pointer);
62: 	static MetaBlockPointer FromBlockPointer(BlockPointer block_pointer);
63: 
64: 	//! Flush all blocks to disk
65: 	void Flush();
66: 
67: 	void MarkBlocksAsModified();
68: 	void ClearModifiedBlocks(const vector<MetaBlockPointer> &pointers);
69: 
70: 	vector<MetadataBlockInfo> GetMetadataInfo() const;
71: 	idx_t BlockCount();
72: 
73: 	void Write(WriteStream &sink);
74: 	void Read(ReadStream &source);
75: 
76: protected:
77: 	BlockManager &block_manager;
78: 	BufferManager &buffer_manager;
79: 	unordered_map<block_id_t, MetadataBlock> blocks;
80: 	unordered_map<block_id_t, idx_t> modified_blocks;
81: 
82: protected:
83: 	block_id_t AllocateNewBlock();
84: 	block_id_t GetNextBlockId();
85: 
86: 	void AddBlock(MetadataBlock new_block, bool if_exists = false);
87: 	void AddAndRegisterBlock(MetadataBlock block);
88: 	void ConvertToTransient(MetadataBlock &block);
89: };
90: 
91: //! Detect mismatching constant values
92: static_assert(MetadataManager::METADATA_BLOCK_SIZE * MetadataManager::METADATA_BLOCK_COUNT <= Storage::BLOCK_SIZE,
93:               "metadata block count exceeds total block alloc size");
94: 
95: } // namespace duckdb
[end of src/include/duckdb/storage/metadata/metadata_manager.hpp]
[start of src/include/duckdb/storage/single_file_block_manager.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/storage/single_file_block_manager.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/common.hpp"
12: #include "duckdb/storage/block_manager.hpp"
13: #include "duckdb/storage/block.hpp"
14: #include "duckdb/common/file_system.hpp"
15: #include "duckdb/common/unordered_set.hpp"
16: #include "duckdb/common/set.hpp"
17: #include "duckdb/common/vector.hpp"
18: #include "duckdb/main/config.hpp"
19: 
20: namespace duckdb {
21: 
22: class DatabaseInstance;
23: struct MetadataHandle;
24: 
25: struct StorageManagerOptions {
26: 	bool read_only = false;
27: 	bool use_direct_io = false;
28: 	DebugInitialize debug_initialize = DebugInitialize::NO_INITIALIZE;
29: 	optional_idx block_alloc_size = optional_idx();
30: };
31: 
32: //! SingleFileBlockManager is an implementation for a BlockManager which manages blocks in a single file
33: class SingleFileBlockManager : public BlockManager {
34: 	//! The location in the file where the block writing starts
35: 	static constexpr uint64_t BLOCK_START = Storage::FILE_HEADER_SIZE * 3;
36: 
37: public:
38: 	SingleFileBlockManager(AttachedDatabase &db, const string &path, const StorageManagerOptions &options);
39: 
40: 	FileOpenFlags GetFileFlags(bool create_new) const;
41: 	//! Creates a new database.
42: 	void CreateNewDatabase();
43: 	//! Loads an existing database. We pass the provided block allocation size as a parameter
44: 	//! to detect inconsistencies with the file header.
45: 	void LoadExistingDatabase();
46: 
47: 	//! Creates a new Block using the specified block_id and returns a pointer
48: 	unique_ptr<Block> ConvertBlock(block_id_t block_id, FileBuffer &source_buffer) override;
49: 	unique_ptr<Block> CreateBlock(block_id_t block_id, FileBuffer *source_buffer) override;
50: 	//! Return the next free block id
51: 	block_id_t GetFreeBlockId() override;
52: 	//! Returns whether or not a specified block is the root block
53: 	bool IsRootBlock(MetaBlockPointer root) override;
54: 	//! Mark a block as free (immediately re-writeable)
55: 	void MarkBlockAsFree(block_id_t block_id) override;
56: 	//! Mark a block as modified (re-writeable after a checkpoint)
57: 	void MarkBlockAsModified(block_id_t block_id) override;
58: 	//! Increase the reference count of a block. The block should hold at least one reference
59: 	void IncreaseBlockReferenceCount(block_id_t block_id) override;
60: 	//! Return the meta block id
61: 	idx_t GetMetaBlock() override;
62: 	//! Read the content of the block from disk
63: 	void Read(Block &block) override;
64: 	//! Write the given block to disk
65: 	void Write(FileBuffer &block, block_id_t block_id) override;
66: 	//! Write the header to disk, this is the final step of the checkpointing process
67: 	void WriteHeader(DatabaseHeader header) override;
68: 	//! Truncate the underlying database file after a checkpoint
69: 	void Truncate() override;
70: 
71: 	//! Returns the number of total blocks
72: 	idx_t TotalBlocks() override;
73: 	//! Returns the number of free blocks
74: 	idx_t FreeBlocks() override;
75: 
76: private:
77: 	//! Loads the free list of the file.
78: 	void LoadFreeList();
79: 	//! Initializes the database header. We pass the provided block allocation size as a parameter
80: 	//!	to detect inconsistencies with the file header.
81: 	void Initialize(const DatabaseHeader &header, const optional_idx block_alloc_size);
82: 
83: 	void ReadAndChecksum(FileBuffer &handle, uint64_t location) const;
84: 	void ChecksumAndWrite(FileBuffer &handle, uint64_t location) const;
85: 
86: 	//! Return the blocks to which we will write the free list and modified blocks
87: 	vector<MetadataHandle> GetFreeListBlocks();
88: 	void TrimFreeBlocks();
89: 
90: private:
91: 	AttachedDatabase &db;
92: 	//! The active DatabaseHeader, either 0 (h1) or 1 (h2)
93: 	uint8_t active_header;
94: 	//! The path where the file is stored
95: 	string path;
96: 	//! The file handle
97: 	unique_ptr<FileHandle> handle;
98: 	//! The buffer used to read/write to the headers
99: 	FileBuffer header_buffer;
100: 	//! The list of free blocks that can be written to currently
101: 	set<block_id_t> free_list;
102: 	//! The list of blocks that were freed since the last checkpoint.
103: 	set<block_id_t> newly_freed_list;
104: 	//! The list of multi-use blocks (i.e. blocks that have >1 reference in the file)
105: 	//! When a multi-use block is marked as modified, the reference count is decreased by 1 instead of directly
106: 	//! Appending the block to the modified_blocks list
107: 	unordered_map<block_id_t, uint32_t> multi_use_blocks;
108: 	//! The list of blocks that will be added to the free list
109: 	unordered_set<block_id_t> modified_blocks;
110: 	//! The current meta block id
111: 	idx_t meta_block;
112: 	//! The current maximum block id, this id will be given away first after the free_list runs out
113: 	block_id_t max_block;
114: 	//! The block id where the free list can be found
115: 	idx_t free_list_id;
116: 	//! The current header iteration count
117: 	uint64_t iteration_count;
118: 	//! The storage manager options
119: 	StorageManagerOptions options;
120: 	//! Lock for performing various operations in the single file block manager
121: 	mutex block_lock;
122: };
123: } // namespace duckdb
[end of src/include/duckdb/storage/single_file_block_manager.hpp]
[start of src/storage/metadata/metadata_manager.cpp]
1: #include "duckdb/storage/metadata/metadata_manager.hpp"
2: #include "duckdb/storage/buffer_manager.hpp"
3: #include "duckdb/storage/buffer/block_handle.hpp"
4: #include "duckdb/common/serializer/write_stream.hpp"
5: #include "duckdb/common/serializer/read_stream.hpp"
6: #include "duckdb/storage/database_size.hpp"
7: 
8: namespace duckdb {
9: 
10: MetadataManager::MetadataManager(BlockManager &block_manager, BufferManager &buffer_manager)
11:     : block_manager(block_manager), buffer_manager(buffer_manager) {
12: }
13: 
14: MetadataManager::~MetadataManager() {
15: }
16: 
17: MetadataHandle MetadataManager::AllocateHandle() {
18: 	// check if there is any free space left in an existing block
19: 	// if not allocate a new block
20: 	block_id_t free_block = INVALID_BLOCK;
21: 	for (auto &kv : blocks) {
22: 		auto &block = kv.second;
23: 		D_ASSERT(kv.first == block.block_id);
24: 		if (!block.free_blocks.empty()) {
25: 			free_block = kv.first;
26: 			break;
27: 		}
28: 	}
29: 	if (free_block == INVALID_BLOCK) {
30: 		free_block = AllocateNewBlock();
31: 	}
32: 	D_ASSERT(free_block != INVALID_BLOCK);
33: 
34: 	// select the first free metadata block we can find
35: 	MetadataPointer pointer;
36: 	pointer.block_index = UnsafeNumericCast<idx_t>(free_block);
37: 	auto &block = blocks[free_block];
38: 	if (block.block->BlockId() < MAXIMUM_BLOCK) {
39: 		// this block is a disk-backed block, yet we are planning to write to it
40: 		// we need to convert it into a transient block before we can write to it
41: 		ConvertToTransient(block);
42: 		D_ASSERT(block.block->BlockId() >= MAXIMUM_BLOCK);
43: 	}
44: 	D_ASSERT(!block.free_blocks.empty());
45: 	pointer.index = block.free_blocks.back();
46: 	// mark the block as used
47: 	block.free_blocks.pop_back();
48: 	D_ASSERT(pointer.index < METADATA_BLOCK_COUNT);
49: 	// pin the block
50: 	return Pin(pointer);
51: }
52: 
53: MetadataHandle MetadataManager::Pin(MetadataPointer pointer) {
54: 	D_ASSERT(pointer.index < METADATA_BLOCK_COUNT);
55: 	auto &block = blocks[pointer.block_index];
56: 
57: 	MetadataHandle handle;
58: 	handle.pointer.block_index = pointer.block_index;
59: 	handle.pointer.index = pointer.index;
60: 	handle.handle = buffer_manager.Pin(block.block);
61: 	return handle;
62: }
63: 
64: void MetadataManager::ConvertToTransient(MetadataBlock &block) {
65: 	// pin the old block
66: 	auto old_buffer = buffer_manager.Pin(block.block);
67: 
68: 	// allocate a new transient block to replace it
69: 	shared_ptr<BlockHandle> new_block;
70: 	auto new_buffer = buffer_manager.Allocate(MemoryTag::METADATA, Storage::BLOCK_SIZE, false, &new_block);
71: 
72: 	// copy the data to the transient block
73: 	memcpy(new_buffer.Ptr(), old_buffer.Ptr(), Storage::BLOCK_SIZE);
74: 
75: 	block.block = std::move(new_block);
76: 
77: 	// unregister the old block
78: 	block_manager.UnregisterBlock(block.block_id, false);
79: }
80: 
81: block_id_t MetadataManager::AllocateNewBlock() {
82: 	auto new_block_id = GetNextBlockId();
83: 
84: 	MetadataBlock new_block;
85: 	auto handle = buffer_manager.Allocate(MemoryTag::METADATA, Storage::BLOCK_SIZE, false, &new_block.block);
86: 	new_block.block_id = new_block_id;
87: 	for (idx_t i = 0; i < METADATA_BLOCK_COUNT; i++) {
88: 		new_block.free_blocks.push_back(NumericCast<uint8_t>(METADATA_BLOCK_COUNT - i - 1));
89: 	}
90: 	// zero-initialize the handle
91: 	memset(handle.Ptr(), 0, Storage::BLOCK_SIZE);
92: 	AddBlock(std::move(new_block));
93: 	return new_block_id;
94: }
95: 
96: void MetadataManager::AddBlock(MetadataBlock new_block, bool if_exists) {
97: 	if (blocks.find(new_block.block_id) != blocks.end()) {
98: 		if (if_exists) {
99: 			return;
100: 		}
101: 		throw InternalException("Block id with id %llu already exists", new_block.block_id);
102: 	}
103: 	blocks[new_block.block_id] = std::move(new_block);
104: }
105: 
106: void MetadataManager::AddAndRegisterBlock(MetadataBlock block) {
107: 	if (block.block) {
108: 		throw InternalException("Calling AddAndRegisterBlock on block that already exists");
109: 	}
110: 	block.block = block_manager.RegisterBlock(block.block_id);
111: 	AddBlock(std::move(block), true);
112: }
113: 
114: MetaBlockPointer MetadataManager::GetDiskPointer(MetadataPointer pointer, uint32_t offset) {
115: 	idx_t block_pointer = idx_t(pointer.block_index);
116: 	block_pointer |= idx_t(pointer.index) << 56ULL;
117: 	return MetaBlockPointer(block_pointer, offset);
118: }
119: 
120: block_id_t MetaBlockPointer::GetBlockId() const {
121: 	return block_id_t(block_pointer & ~(idx_t(0xFF) << 56ULL));
122: }
123: 
124: uint32_t MetaBlockPointer::GetBlockIndex() const {
125: 	return block_pointer >> 56ULL;
126: }
127: 
128: MetadataPointer MetadataManager::FromDiskPointer(MetaBlockPointer pointer) {
129: 	auto block_id = pointer.GetBlockId();
130: 	auto index = pointer.GetBlockIndex();
131: 	auto entry = blocks.find(block_id);
132: 	if (entry == blocks.end()) { // LCOV_EXCL_START
133: 		throw InternalException("Failed to load metadata pointer (id %llu, idx %llu, ptr %llu)\n", block_id, index,
134: 		                        pointer.block_pointer);
135: 	} // LCOV_EXCL_STOP
136: 	MetadataPointer result;
137: 	result.block_index = UnsafeNumericCast<idx_t>(block_id);
138: 	result.index = UnsafeNumericCast<uint8_t>(index);
139: 	return result;
140: }
141: 
142: MetadataPointer MetadataManager::RegisterDiskPointer(MetaBlockPointer pointer) {
143: 	auto block_id = pointer.GetBlockId();
144: 	MetadataBlock block;
145: 	block.block_id = block_id;
146: 	AddAndRegisterBlock(block);
147: 	return FromDiskPointer(pointer);
148: }
149: 
150: BlockPointer MetadataManager::ToBlockPointer(MetaBlockPointer meta_pointer) {
151: 	BlockPointer result;
152: 	result.block_id = meta_pointer.GetBlockId();
153: 	result.offset = meta_pointer.GetBlockIndex() * MetadataManager::METADATA_BLOCK_SIZE + meta_pointer.offset;
154: 	D_ASSERT(result.offset < MetadataManager::METADATA_BLOCK_SIZE * MetadataManager::METADATA_BLOCK_COUNT);
155: 	return result;
156: }
157: 
158: MetaBlockPointer MetadataManager::FromBlockPointer(BlockPointer block_pointer) {
159: 	if (!block_pointer.IsValid()) {
160: 		return MetaBlockPointer();
161: 	}
162: 	idx_t index = block_pointer.offset / MetadataManager::METADATA_BLOCK_SIZE;
163: 	auto offset = block_pointer.offset % MetadataManager::METADATA_BLOCK_SIZE;
164: 	D_ASSERT(index < MetadataManager::METADATA_BLOCK_COUNT);
165: 	D_ASSERT(offset < MetadataManager::METADATA_BLOCK_SIZE);
166: 	MetaBlockPointer result;
167: 	result.block_pointer = idx_t(block_pointer.block_id) | index << 56ULL;
168: 	result.offset = UnsafeNumericCast<uint32_t>(offset);
169: 	return result;
170: }
171: 
172: idx_t MetadataManager::BlockCount() {
173: 	return blocks.size();
174: }
175: 
176: void MetadataManager::Flush() {
177: 	const idx_t total_metadata_size = MetadataManager::METADATA_BLOCK_SIZE * MetadataManager::METADATA_BLOCK_COUNT;
178: 	// write the blocks of the metadata manager to disk
179: 	for (auto &kv : blocks) {
180: 		auto &block = kv.second;
181: 		auto handle = buffer_manager.Pin(block.block);
182: 		// there are a few bytes left-over at the end of the block, zero-initialize them
183: 		memset(handle.Ptr() + total_metadata_size, 0, Storage::BLOCK_SIZE - total_metadata_size);
184: 		D_ASSERT(kv.first == block.block_id);
185: 		if (block.block->BlockId() >= MAXIMUM_BLOCK) {
186: 			// temporary block - convert to persistent
187: 			block.block = block_manager.ConvertToPersistent(kv.first, std::move(block.block));
188: 		} else {
189: 			// already a persistent block - only need to write it
190: 			D_ASSERT(block.block->BlockId() == block.block_id);
191: 			block_manager.Write(handle.GetFileBuffer(), block.block_id);
192: 		}
193: 	}
194: }
195: 
196: void MetadataManager::Write(WriteStream &sink) {
197: 	sink.Write<uint64_t>(blocks.size());
198: 	for (auto &kv : blocks) {
199: 		kv.second.Write(sink);
200: 	}
201: }
202: 
203: void MetadataManager::Read(ReadStream &source) {
204: 	auto block_count = source.Read<uint64_t>();
205: 	for (idx_t i = 0; i < block_count; i++) {
206: 		auto block = MetadataBlock::Read(source);
207: 		auto entry = blocks.find(block.block_id);
208: 		if (entry == blocks.end()) {
209: 			// block does not exist yet
210: 			AddAndRegisterBlock(std::move(block));
211: 		} else {
212: 			// block was already created - only copy over the free list
213: 			entry->second.free_blocks = std::move(block.free_blocks);
214: 		}
215: 	}
216: }
217: 
218: void MetadataBlock::Write(WriteStream &sink) {
219: 	sink.Write<block_id_t>(block_id);
220: 	sink.Write<idx_t>(FreeBlocksToInteger());
221: }
222: 
223: MetadataBlock MetadataBlock::Read(ReadStream &source) {
224: 	MetadataBlock result;
225: 	result.block_id = source.Read<block_id_t>();
226: 	auto free_list = source.Read<idx_t>();
227: 	result.FreeBlocksFromInteger(free_list);
228: 	return result;
229: }
230: 
231: idx_t MetadataBlock::FreeBlocksToInteger() {
232: 	idx_t result = 0;
233: 	for (idx_t i = 0; i < free_blocks.size(); i++) {
234: 		D_ASSERT(free_blocks[i] < idx_t(64));
235: 		idx_t mask = idx_t(1) << idx_t(free_blocks[i]);
236: 		result |= mask;
237: 	}
238: 	return result;
239: }
240: 
241: void MetadataBlock::FreeBlocksFromInteger(idx_t free_list) {
242: 	free_blocks.clear();
243: 	if (free_list == 0) {
244: 		return;
245: 	}
246: 	for (idx_t i = 64; i > 0; i--) {
247: 		auto index = i - 1;
248: 		idx_t mask = idx_t(1) << index;
249: 		if (free_list & mask) {
250: 			free_blocks.push_back(UnsafeNumericCast<uint8_t>(index));
251: 		}
252: 	}
253: }
254: 
255: void MetadataManager::MarkBlocksAsModified() {
256: 	// for any blocks that were modified in the last checkpoint - set them to free blocks currently
257: 	for (auto &kv : modified_blocks) {
258: 		auto block_id = kv.first;
259: 		idx_t modified_list = kv.second;
260: 		auto entry = blocks.find(block_id);
261: 		D_ASSERT(entry != blocks.end());
262: 		auto &block = entry->second;
263: 		idx_t current_free_blocks = block.FreeBlocksToInteger();
264: 		// merge the current set of free blocks with the modified blocks
265: 		idx_t new_free_blocks = current_free_blocks | modified_list;
266: 		if (new_free_blocks == NumericLimits<idx_t>::Maximum()) {
267: 			// if new free_blocks is all blocks - mark entire block as modified
268: 			blocks.erase(entry);
269: 			block_manager.MarkBlockAsModified(block_id);
270: 		} else {
271: 			// set the new set of free blocks
272: 			block.FreeBlocksFromInteger(new_free_blocks);
273: 		}
274: 	}
275: 
276: 	modified_blocks.clear();
277: 	for (auto &kv : blocks) {
278: 		auto &block = kv.second;
279: 		idx_t free_list = block.FreeBlocksToInteger();
280: 		idx_t occupied_list = ~free_list;
281: 		modified_blocks[block.block_id] = occupied_list;
282: 	}
283: }
284: 
285: void MetadataManager::ClearModifiedBlocks(const vector<MetaBlockPointer> &pointers) {
286: 	for (auto &pointer : pointers) {
287: 		auto block_id = pointer.GetBlockId();
288: 		auto block_index = pointer.GetBlockIndex();
289: 		auto entry = modified_blocks.find(block_id);
290: 		if (entry == modified_blocks.end()) {
291: 			throw InternalException("ClearModifiedBlocks - Block id %llu not found in modified_blocks", block_id);
292: 		}
293: 		auto &modified_list = entry->second;
294: 		// verify the block has been modified
295: 		D_ASSERT(modified_list && (1ULL << block_index));
296: 		// unset the bit
297: 		modified_list &= ~(1ULL << block_index);
298: 	}
299: }
300: 
301: vector<MetadataBlockInfo> MetadataManager::GetMetadataInfo() const {
302: 	vector<MetadataBlockInfo> result;
303: 	for (auto &block : blocks) {
304: 		MetadataBlockInfo block_info;
305: 		block_info.block_id = block.second.block_id;
306: 		block_info.total_blocks = MetadataManager::METADATA_BLOCK_COUNT;
307: 		for (auto free_block : block.second.free_blocks) {
308: 			block_info.free_list.push_back(free_block);
309: 		}
310: 		std::sort(block_info.free_list.begin(), block_info.free_list.end());
311: 		result.push_back(std::move(block_info));
312: 	}
313: 	std::sort(result.begin(), result.end(),
314: 	          [](const MetadataBlockInfo &a, const MetadataBlockInfo &b) { return a.block_id < b.block_id; });
315: 	return result;
316: }
317: 
318: block_id_t MetadataManager::GetNextBlockId() {
319: 	return block_manager.GetFreeBlockId();
320: }
321: 
322: } // namespace duckdb
[end of src/storage/metadata/metadata_manager.cpp]
[start of src/storage/single_file_block_manager.cpp]
1: #include "duckdb/storage/single_file_block_manager.hpp"
2: 
3: #include "duckdb/common/allocator.hpp"
4: #include "duckdb/common/checksum.hpp"
5: #include "duckdb/common/exception.hpp"
6: #include "duckdb/common/serializer/memory_stream.hpp"
7: #include "duckdb/storage/metadata/metadata_reader.hpp"
8: #include "duckdb/storage/metadata/metadata_writer.hpp"
9: #include "duckdb/storage/buffer_manager.hpp"
10: #include "duckdb/main/config.hpp"
11: #include "duckdb/main/database.hpp"
12: 
13: #include <algorithm>
14: #include <cstring>
15: 
16: namespace duckdb {
17: 
18: const char MainHeader::MAGIC_BYTES[] = "DUCK";
19: 
20: void SerializeVersionNumber(WriteStream &ser, const string &version_str) {
21: 	data_t version[MainHeader::MAX_VERSION_SIZE];
22: 	memset(version, 0, MainHeader::MAX_VERSION_SIZE);
23: 	memcpy(version, version_str.c_str(), MinValue<idx_t>(version_str.size(), MainHeader::MAX_VERSION_SIZE));
24: 	ser.WriteData(version, MainHeader::MAX_VERSION_SIZE);
25: }
26: 
27: void DeserializeVersionNumber(ReadStream &stream, data_t *dest) {
28: 	memset(dest, 0, MainHeader::MAX_VERSION_SIZE);
29: 	stream.ReadData(dest, MainHeader::MAX_VERSION_SIZE);
30: }
31: 
32: void MainHeader::Write(WriteStream &ser) {
33: 	ser.WriteData(const_data_ptr_cast(MAGIC_BYTES), MAGIC_BYTE_SIZE);
34: 	ser.Write<uint64_t>(version_number);
35: 	for (idx_t i = 0; i < FLAG_COUNT; i++) {
36: 		ser.Write<uint64_t>(flags[i]);
37: 	}
38: 	SerializeVersionNumber(ser, DuckDB::LibraryVersion());
39: 	SerializeVersionNumber(ser, DuckDB::SourceID());
40: }
41: 
42: void MainHeader::CheckMagicBytes(FileHandle &handle) {
43: 	data_t magic_bytes[MAGIC_BYTE_SIZE];
44: 	if (handle.GetFileSize() < MainHeader::MAGIC_BYTE_SIZE + MainHeader::MAGIC_BYTE_OFFSET) {
45: 		throw IOException("The file \"%s\" exists, but it is not a valid DuckDB database file!", handle.path);
46: 	}
47: 	handle.Read(magic_bytes, MainHeader::MAGIC_BYTE_SIZE, MainHeader::MAGIC_BYTE_OFFSET);
48: 	if (memcmp(magic_bytes, MainHeader::MAGIC_BYTES, MainHeader::MAGIC_BYTE_SIZE) != 0) {
49: 		throw IOException("The file \"%s\" exists, but it is not a valid DuckDB database file!", handle.path);
50: 	}
51: }
52: 
53: MainHeader MainHeader::Read(ReadStream &source) {
54: 	data_t magic_bytes[MAGIC_BYTE_SIZE];
55: 	MainHeader header;
56: 	source.ReadData(magic_bytes, MainHeader::MAGIC_BYTE_SIZE);
57: 	if (memcmp(magic_bytes, MainHeader::MAGIC_BYTES, MainHeader::MAGIC_BYTE_SIZE) != 0) {
58: 		throw IOException("The file is not a valid DuckDB database file!");
59: 	}
60: 	header.version_number = source.Read<uint64_t>();
61: 	// check the version number
62: 	if (header.version_number != VERSION_NUMBER) {
63: 		auto version = GetDuckDBVersion(header.version_number);
64: 		string version_text;
65: 		if (!version.empty()) {
66: 			// known version
67: 			version_text = "DuckDB version " + string(version);
68: 		} else {
69: 			version_text = string("an ") + (VERSION_NUMBER > header.version_number ? "older development" : "newer") +
70: 			               string(" version of DuckDB");
71: 		}
72: 		throw IOException(
73: 		    "Trying to read a database file with version number %lld, but we can only read version %lld.\n"
74: 		    "The database file was created with %s.\n\n"
75: 		    "The storage of DuckDB is not yet stable; newer versions of DuckDB cannot read old database files and "
76: 		    "vice versa.\n"
77: 		    "The storage will be stabilized when version 1.0 releases.\n\n"
78: 		    "For now, we recommend that you load the database file in a supported version of DuckDB, and use the "
79: 		    "EXPORT DATABASE command "
80: 		    "followed by IMPORT DATABASE on the current version of DuckDB.\n\n"
81: 		    "See the storage page for more information: https://duckdb.org/internals/storage",
82: 		    header.version_number, VERSION_NUMBER, version_text);
83: 	}
84: 	// read the flags
85: 	for (idx_t i = 0; i < FLAG_COUNT; i++) {
86: 		header.flags[i] = source.Read<uint64_t>();
87: 	}
88: 	DeserializeVersionNumber(source, header.library_git_desc);
89: 	DeserializeVersionNumber(source, header.library_git_hash);
90: 	return header;
91: }
92: 
93: void DatabaseHeader::Write(WriteStream &ser) {
94: 	ser.Write<uint64_t>(iteration);
95: 	ser.Write<idx_t>(meta_block);
96: 	ser.Write<idx_t>(free_list);
97: 	ser.Write<uint64_t>(block_count);
98: 	ser.Write<idx_t>(block_alloc_size);
99: 	ser.Write<idx_t>(vector_size);
100: }
101: 
102: DatabaseHeader DatabaseHeader::Read(ReadStream &source) {
103: 	DatabaseHeader header;
104: 	header.iteration = source.Read<uint64_t>();
105: 	header.meta_block = source.Read<idx_t>();
106: 	header.free_list = source.Read<idx_t>();
107: 	header.block_count = source.Read<uint64_t>();
108: 
109: 	header.block_alloc_size = source.Read<idx_t>();
110: 	if (!header.block_alloc_size) {
111: 		// backwards compatibility
112: 		header.block_alloc_size = DEFAULT_BLOCK_ALLOC_SIZE;
113: 	}
114: 
115: 	header.vector_size = source.Read<idx_t>();
116: 	if (!header.vector_size) {
117: 		// backwards compatibility
118: 		header.vector_size = DEFAULT_STANDARD_VECTOR_SIZE;
119: 	}
120: 	if (header.vector_size != STANDARD_VECTOR_SIZE) {
121: 		throw IOException("Cannot read database file: DuckDB's compiled vector size is %llu bytes, but the file has a "
122: 		                  "vector size of %llu bytes.",
123: 		                  STANDARD_VECTOR_SIZE, header.vector_size);
124: 	}
125: 
126: 	return header;
127: }
128: 
129: template <class T>
130: void SerializeHeaderStructure(T header, data_ptr_t ptr) {
131: 	MemoryStream ser(ptr, Storage::FILE_HEADER_SIZE);
132: 	header.Write(ser);
133: }
134: 
135: template <class T>
136: T DeserializeHeaderStructure(data_ptr_t ptr) {
137: 	MemoryStream source(ptr, Storage::FILE_HEADER_SIZE);
138: 	return T::Read(source);
139: }
140: 
141: SingleFileBlockManager::SingleFileBlockManager(AttachedDatabase &db, const string &path_p,
142:                                                const StorageManagerOptions &options)
143:     : BlockManager(BufferManager::GetBufferManager(db), options.block_alloc_size), db(db), path(path_p),
144:       header_buffer(Allocator::Get(db), FileBufferType::MANAGED_BUFFER,
145:                     Storage::FILE_HEADER_SIZE - Storage::BLOCK_HEADER_SIZE),
146:       iteration_count(0), options(options) {
147: }
148: 
149: FileOpenFlags SingleFileBlockManager::GetFileFlags(bool create_new) const {
150: 	FileOpenFlags result;
151: 	if (options.read_only) {
152: 		D_ASSERT(!create_new);
153: 		result = FileFlags::FILE_FLAGS_READ | FileFlags::FILE_FLAGS_NULL_IF_NOT_EXISTS | FileLockType::READ_LOCK;
154: 	} else {
155: 		result = FileFlags::FILE_FLAGS_WRITE | FileFlags::FILE_FLAGS_READ | FileLockType::WRITE_LOCK;
156: 		if (create_new) {
157: 			result |= FileFlags::FILE_FLAGS_FILE_CREATE;
158: 		}
159: 	}
160: 	if (options.use_direct_io) {
161: 		result |= FileFlags::FILE_FLAGS_DIRECT_IO;
162: 	}
163: 	// database files can be read from in parallel
164: 	result |= FileFlags::FILE_FLAGS_PARALLEL_ACCESS;
165: 	return result;
166: }
167: 
168: void SingleFileBlockManager::CreateNewDatabase() {
169: 	auto flags = GetFileFlags(true);
170: 
171: 	// open the RDBMS handle
172: 	auto &fs = FileSystem::Get(db);
173: 	handle = fs.OpenFile(path, flags);
174: 
175: 	// if we create a new file, we fill the metadata of the file
176: 	// first fill in the new header
177: 	header_buffer.Clear();
178: 
179: 	MainHeader main_header;
180: 	main_header.version_number = VERSION_NUMBER;
181: 	memset(main_header.flags, 0, sizeof(uint64_t) * 4);
182: 
183: 	SerializeHeaderStructure<MainHeader>(main_header, header_buffer.buffer);
184: 	// now write the header to the file
185: 	ChecksumAndWrite(header_buffer, 0);
186: 	header_buffer.Clear();
187: 
188: 	// write the database headers
189: 	// initialize meta_block and free_list to INVALID_BLOCK because the database file does not contain any actual
190: 	// content yet
191: 	DatabaseHeader h1;
192: 	// header 1
193: 	h1.iteration = 0;
194: 	h1.meta_block = idx_t(INVALID_BLOCK);
195: 	h1.free_list = idx_t(INVALID_BLOCK);
196: 	h1.block_count = 0;
197: 	// We create the SingleFileBlockManager with the desired block allocation size before calling CreateNewDatabase.
198: 	h1.block_alloc_size = GetBlockAllocSize();
199: 	h1.vector_size = STANDARD_VECTOR_SIZE;
200: 	SerializeHeaderStructure<DatabaseHeader>(h1, header_buffer.buffer);
201: 	ChecksumAndWrite(header_buffer, Storage::FILE_HEADER_SIZE);
202: 
203: 	// header 2
204: 	DatabaseHeader h2;
205: 	h2.iteration = 0;
206: 	h2.meta_block = idx_t(INVALID_BLOCK);
207: 	h2.free_list = idx_t(INVALID_BLOCK);
208: 	h2.block_count = 0;
209: 	// We create the SingleFileBlockManager with the desired block allocation size before calling CreateNewDatabase.
210: 	h2.block_alloc_size = GetBlockAllocSize();
211: 	h2.vector_size = STANDARD_VECTOR_SIZE;
212: 	SerializeHeaderStructure<DatabaseHeader>(h2, header_buffer.buffer);
213: 	ChecksumAndWrite(header_buffer, Storage::FILE_HEADER_SIZE * 2ULL);
214: 
215: 	// ensure that writing to disk is completed before returning
216: 	handle->Sync();
217: 	// we start with h2 as active_header, this way our initial write will be in h1
218: 	iteration_count = 0;
219: 	active_header = 1;
220: 	max_block = 0;
221: }
222: 
223: void SingleFileBlockManager::LoadExistingDatabase() {
224: 	auto flags = GetFileFlags(false);
225: 
226: 	// open the RDBMS handle
227: 	auto &fs = FileSystem::Get(db);
228: 	handle = fs.OpenFile(path, flags);
229: 	if (!handle) {
230: 		// this can only happen in read-only mode - as that is when we set FILE_FLAGS_NULL_IF_NOT_EXISTS
231: 		throw IOException("Cannot open database \"%s\" in read-only mode: database does not exist", path);
232: 	}
233: 
234: 	MainHeader::CheckMagicBytes(*handle);
235: 	// otherwise, we check the metadata of the file
236: 	ReadAndChecksum(header_buffer, 0);
237: 	DeserializeHeaderStructure<MainHeader>(header_buffer.buffer);
238: 
239: 	// read the database headers from disk
240: 	DatabaseHeader h1;
241: 	ReadAndChecksum(header_buffer, Storage::FILE_HEADER_SIZE);
242: 	h1 = DeserializeHeaderStructure<DatabaseHeader>(header_buffer.buffer);
243: 
244: 	DatabaseHeader h2;
245: 	ReadAndChecksum(header_buffer, Storage::FILE_HEADER_SIZE * 2ULL);
246: 	h2 = DeserializeHeaderStructure<DatabaseHeader>(header_buffer.buffer);
247: 
248: 	// check the header with the highest iteration count
249: 	if (h1.iteration > h2.iteration) {
250: 		// h1 is active header
251: 		active_header = 0;
252: 		Initialize(h1, GetOptionalBlockAllocSize());
253: 	} else {
254: 		// h2 is active header
255: 		active_header = 1;
256: 		Initialize(h2, GetOptionalBlockAllocSize());
257: 	}
258: 	LoadFreeList();
259: }
260: 
261: void SingleFileBlockManager::ReadAndChecksum(FileBuffer &block, uint64_t location) const {
262: 	// read the buffer from disk
263: 	block.Read(*handle, location);
264: 
265: 	// compute the checksum
266: 	auto stored_checksum = Load<uint64_t>(block.InternalBuffer());
267: 	uint64_t computed_checksum = Checksum(block.buffer, block.size);
268: 
269: 	// verify the checksum
270: 	if (stored_checksum != computed_checksum) {
271: 		throw IOException("Corrupt database file: computed checksum %llu does not match stored checksum %llu in block "
272: 		                  "at location %llu",
273: 		                  computed_checksum, stored_checksum, location);
274: 	}
275: }
276: 
277: void SingleFileBlockManager::ChecksumAndWrite(FileBuffer &block, uint64_t location) const {
278: 	// compute the checksum and write it to the start of the buffer (if not temp buffer)
279: 	uint64_t checksum = Checksum(block.buffer, block.size);
280: 	Store<uint64_t>(checksum, block.InternalBuffer());
281: 	// now write the buffer
282: 	block.Write(*handle, location);
283: }
284: 
285: void SingleFileBlockManager::Initialize(const DatabaseHeader &header, const optional_idx block_alloc_size) {
286: 	free_list_id = header.free_list;
287: 	meta_block = header.meta_block;
288: 	iteration_count = header.iteration;
289: 	max_block = NumericCast<block_id_t>(header.block_count);
290: 
291: 	if (block_alloc_size.IsValid() && block_alloc_size.GetIndex() != header.block_alloc_size) {
292: 		throw InvalidInputException("cannot initialize the same database with a different block size: provided block "
293: 		                            "size: %llu, file block size: %llu",
294: 		                            GetBlockAllocSize(), header.block_alloc_size);
295: 	}
296: 
297: 	// NOTE: remove this once we start supporting different block sizes.
298: 	if (Storage::BLOCK_ALLOC_SIZE != header.block_alloc_size) {
299: 		throw NotImplementedException("cannot initialize a database with a different block size than the default block "
300: 		                              "size: default block size: %llu, file block size: %llu",
301: 		                              Storage::BLOCK_ALLOC_SIZE, header.block_alloc_size);
302: 	}
303: 
304: 	SetBlockAllocSize(header.block_alloc_size);
305: }
306: 
307: void SingleFileBlockManager::LoadFreeList() {
308: 	MetaBlockPointer free_pointer(free_list_id, 0);
309: 	if (!free_pointer.IsValid()) {
310: 		// no free list
311: 		return;
312: 	}
313: 	MetadataReader reader(GetMetadataManager(), free_pointer, nullptr, BlockReaderType::REGISTER_BLOCKS);
314: 	auto free_list_count = reader.Read<uint64_t>();
315: 	free_list.clear();
316: 	for (idx_t i = 0; i < free_list_count; i++) {
317: 		auto block = reader.Read<block_id_t>();
318: 		free_list.insert(block);
319: 		newly_freed_list.insert(block);
320: 	}
321: 	auto multi_use_blocks_count = reader.Read<uint64_t>();
322: 	multi_use_blocks.clear();
323: 	for (idx_t i = 0; i < multi_use_blocks_count; i++) {
324: 		auto block_id = reader.Read<block_id_t>();
325: 		auto usage_count = reader.Read<uint32_t>();
326: 		multi_use_blocks[block_id] = usage_count;
327: 	}
328: 	GetMetadataManager().Read(reader);
329: 	GetMetadataManager().MarkBlocksAsModified();
330: }
331: 
332: bool SingleFileBlockManager::IsRootBlock(MetaBlockPointer root) {
333: 	return root.block_pointer == meta_block;
334: }
335: 
336: block_id_t SingleFileBlockManager::GetFreeBlockId() {
337: 	lock_guard<mutex> lock(block_lock);
338: 	block_id_t block;
339: 	if (!free_list.empty()) {
340: 		// The free list is not empty, so we take its first element.
341: 		block = *free_list.begin();
342: 		// erase the entry from the free list again
343: 		free_list.erase(free_list.begin());
344: 		newly_freed_list.erase(block);
345: 	} else {
346: 		block = max_block++;
347: 	}
348: 	return block;
349: }
350: 
351: void SingleFileBlockManager::MarkBlockAsFree(block_id_t block_id) {
352: 	lock_guard<mutex> lock(block_lock);
353: 	D_ASSERT(block_id >= 0);
354: 	D_ASSERT(block_id < max_block);
355: 	if (free_list.find(block_id) != free_list.end()) {
356: 		throw InternalException("MarkBlockAsFree called but block %llu was already freed!", block_id);
357: 	}
358: 	multi_use_blocks.erase(block_id);
359: 	free_list.insert(block_id);
360: 	newly_freed_list.insert(block_id);
361: }
362: 
363: void SingleFileBlockManager::MarkBlockAsModified(block_id_t block_id) {
364: 	lock_guard<mutex> lock(block_lock);
365: 	D_ASSERT(block_id >= 0);
366: 	D_ASSERT(block_id < max_block);
367: 
368: 	// check if the block is a multi-use block
369: 	auto entry = multi_use_blocks.find(block_id);
370: 	if (entry != multi_use_blocks.end()) {
371: 		// it is! reduce the reference count of the block
372: 		entry->second--;
373: 		// check the reference count: is the block still a multi-use block?
374: 		if (entry->second <= 1) {
375: 			// no longer a multi-use block!
376: 			multi_use_blocks.erase(entry);
377: 		}
378: 		return;
379: 	}
380: 	// Check for multi-free
381: 	// TODO: Fix the bug that causes this assert to fire, then uncomment it.
382: 	// D_ASSERT(modified_blocks.find(block_id) == modified_blocks.end());
383: 	D_ASSERT(free_list.find(block_id) == free_list.end());
384: 	modified_blocks.insert(block_id);
385: }
386: 
387: void SingleFileBlockManager::IncreaseBlockReferenceCount(block_id_t block_id) {
388: 	lock_guard<mutex> lock(block_lock);
389: 	D_ASSERT(block_id >= 0);
390: 	D_ASSERT(block_id < max_block);
391: 	D_ASSERT(free_list.find(block_id) == free_list.end());
392: 	auto entry = multi_use_blocks.find(block_id);
393: 	if (entry != multi_use_blocks.end()) {
394: 		entry->second++;
395: 	} else {
396: 		multi_use_blocks[block_id] = 2;
397: 	}
398: }
399: 
400: idx_t SingleFileBlockManager::GetMetaBlock() {
401: 	return meta_block;
402: }
403: 
404: idx_t SingleFileBlockManager::TotalBlocks() {
405: 	lock_guard<mutex> lock(block_lock);
406: 	return NumericCast<idx_t>(max_block);
407: }
408: 
409: idx_t SingleFileBlockManager::FreeBlocks() {
410: 	lock_guard<mutex> lock(block_lock);
411: 	return free_list.size();
412: }
413: 
414: unique_ptr<Block> SingleFileBlockManager::ConvertBlock(block_id_t block_id, FileBuffer &source_buffer) {
415: 	D_ASSERT(source_buffer.AllocSize() == Storage::BLOCK_ALLOC_SIZE);
416: 	return make_uniq<Block>(source_buffer, block_id);
417: }
418: 
419: unique_ptr<Block> SingleFileBlockManager::CreateBlock(block_id_t block_id, FileBuffer *source_buffer) {
420: 	unique_ptr<Block> result;
421: 	if (source_buffer) {
422: 		result = ConvertBlock(block_id, *source_buffer);
423: 	} else {
424: 		result = make_uniq<Block>(Allocator::Get(db), block_id);
425: 	}
426: 	result->Initialize(options.debug_initialize);
427: 	return result;
428: }
429: 
430: void SingleFileBlockManager::Read(Block &block) {
431: 	D_ASSERT(block.id >= 0);
432: 	D_ASSERT(std::find(free_list.begin(), free_list.end(), block.id) == free_list.end());
433: 	ReadAndChecksum(block, BLOCK_START + NumericCast<idx_t>(block.id) * Storage::BLOCK_ALLOC_SIZE);
434: }
435: 
436: void SingleFileBlockManager::Write(FileBuffer &buffer, block_id_t block_id) {
437: 	D_ASSERT(block_id >= 0);
438: 	ChecksumAndWrite(buffer, BLOCK_START + NumericCast<idx_t>(block_id) * Storage::BLOCK_ALLOC_SIZE);
439: }
440: 
441: void SingleFileBlockManager::Truncate() {
442: 	BlockManager::Truncate();
443: 	idx_t blocks_to_truncate = 0;
444: 	// reverse iterate over the free-list
445: 	for (auto entry = free_list.rbegin(); entry != free_list.rend(); entry++) {
446: 		auto block_id = *entry;
447: 		if (block_id + 1 != max_block) {
448: 			break;
449: 		}
450: 		blocks_to_truncate++;
451: 		max_block--;
452: 	}
453: 	if (blocks_to_truncate == 0) {
454: 		// nothing to truncate
455: 		return;
456: 	}
457: 	// truncate the file
458: 	free_list.erase(free_list.lower_bound(max_block), free_list.end());
459: 	newly_freed_list.erase(newly_freed_list.lower_bound(max_block), newly_freed_list.end());
460: 	handle->Truncate(NumericCast<int64_t>(BLOCK_START + NumericCast<idx_t>(max_block) * Storage::BLOCK_ALLOC_SIZE));
461: }
462: 
463: vector<MetadataHandle> SingleFileBlockManager::GetFreeListBlocks() {
464: 	vector<MetadataHandle> free_list_blocks;
465: 
466: 	// reserve all blocks that we are going to write the free list to
467: 	// since these blocks are no longer free we cannot just include them in the free list!
468: 	auto block_size = MetadataManager::METADATA_BLOCK_SIZE - sizeof(idx_t);
469: 	idx_t allocated_size = 0;
470: 	while (true) {
471: 		auto free_list_size = sizeof(uint64_t) + sizeof(block_id_t) * (free_list.size() + modified_blocks.size());
472: 		auto multi_use_blocks_size =
473: 		    sizeof(uint64_t) + (sizeof(block_id_t) + sizeof(uint32_t)) * multi_use_blocks.size();
474: 		auto metadata_blocks =
475: 		    sizeof(uint64_t) + (sizeof(block_id_t) + sizeof(idx_t)) * GetMetadataManager().BlockCount();
476: 		auto total_size = free_list_size + multi_use_blocks_size + metadata_blocks;
477: 		if (total_size < allocated_size) {
478: 			break;
479: 		}
480: 		auto free_list_handle = GetMetadataManager().AllocateHandle();
481: 		free_list_blocks.push_back(std::move(free_list_handle));
482: 		allocated_size += block_size;
483: 	}
484: 
485: 	return free_list_blocks;
486: }
487: 
488: class FreeListBlockWriter : public MetadataWriter {
489: public:
490: 	FreeListBlockWriter(MetadataManager &manager, vector<MetadataHandle> free_list_blocks_p)
491: 	    : MetadataWriter(manager), free_list_blocks(std::move(free_list_blocks_p)), index(0) {
492: 	}
493: 
494: 	vector<MetadataHandle> free_list_blocks;
495: 	idx_t index;
496: 
497: protected:
498: 	MetadataHandle NextHandle() override {
499: 		if (index >= free_list_blocks.size()) {
500: 			throw InternalException(
501: 			    "Free List Block Writer ran out of blocks, this means not enough blocks were allocated up front");
502: 		}
503: 		return std::move(free_list_blocks[index++]);
504: 	}
505: };
506: 
507: void SingleFileBlockManager::WriteHeader(DatabaseHeader header) {
508: 	auto free_list_blocks = GetFreeListBlocks();
509: 
510: 	// now handle the free list
511: 	auto &metadata_manager = GetMetadataManager();
512: 	// add all modified blocks to the free list: they can now be written to again
513: 	metadata_manager.MarkBlocksAsModified();
514: 
515: 	lock_guard<mutex> lock(block_lock);
516: 	// set the iteration count
517: 	header.iteration = ++iteration_count;
518: 
519: 	for (auto &block : modified_blocks) {
520: 		free_list.insert(block);
521: 		newly_freed_list.insert(block);
522: 	}
523: 	modified_blocks.clear();
524: 
525: 	if (!free_list_blocks.empty()) {
526: 		// there are blocks to write, either in the free_list or in the modified_blocks
527: 		// we write these blocks specifically to the free_list_blocks
528: 		// a normal MetadataWriter will fetch blocks to use from the free_list
529: 		// but since we are WRITING the free_list, this behavior is sub-optimal
530: 		FreeListBlockWriter writer(metadata_manager, std::move(free_list_blocks));
531: 
532: 		auto ptr = writer.GetMetaBlockPointer();
533: 		header.free_list = ptr.block_pointer;
534: 
535: 		writer.Write<uint64_t>(free_list.size());
536: 		for (auto &block_id : free_list) {
537: 			writer.Write<block_id_t>(block_id);
538: 		}
539: 		writer.Write<uint64_t>(multi_use_blocks.size());
540: 		for (auto &entry : multi_use_blocks) {
541: 			writer.Write<block_id_t>(entry.first);
542: 			writer.Write<uint32_t>(entry.second);
543: 		}
544: 		GetMetadataManager().Write(writer);
545: 		writer.Flush();
546: 	} else {
547: 		// no blocks in the free list
548: 		header.free_list = DConstants::INVALID_INDEX;
549: 	}
550: 	metadata_manager.Flush();
551: 	header.block_count = NumericCast<idx_t>(max_block);
552: 
553: 	auto &config = DBConfig::Get(db);
554: 	if (config.options.checkpoint_abort == CheckpointAbort::DEBUG_ABORT_AFTER_FREE_LIST_WRITE) {
555: 		throw FatalException("Checkpoint aborted after free list write because of PRAGMA checkpoint_abort flag");
556: 	}
557: 
558: 	if (!options.use_direct_io) {
559: 		// if we are not using Direct IO we need to fsync BEFORE we write the header to ensure that all the previous
560: 		// blocks are written as well
561: 		handle->Sync();
562: 	}
563: 	// set the header inside the buffer
564: 	header_buffer.Clear();
565: 	MemoryStream serializer;
566: 	header.Write(serializer);
567: 	memcpy(header_buffer.buffer, serializer.GetData(), serializer.GetPosition());
568: 	// now write the header to the file, active_header determines whether we write to h1 or h2
569: 	// note that if active_header is h1 we write to h2, and vice versa
570: 	ChecksumAndWrite(header_buffer, active_header == 1 ? Storage::FILE_HEADER_SIZE : Storage::FILE_HEADER_SIZE * 2);
571: 	// switch active header to the other header
572: 	active_header = 1 - active_header;
573: 	//! Ensure the header write ends up on disk
574: 	handle->Sync();
575: 	// Release the free blocks to the filesystem.
576: 	TrimFreeBlocks();
577: }
578: 
579: void SingleFileBlockManager::TrimFreeBlocks() {
580: 	if (DBConfig::Get(db).options.trim_free_blocks) {
581: 		for (auto itr = newly_freed_list.begin(); itr != newly_freed_list.end(); ++itr) {
582: 			block_id_t first = *itr;
583: 			block_id_t last = first;
584: 			// Find end of contiguous range.
585: 			for (++itr; itr != newly_freed_list.end() && (*itr == last + 1); ++itr) {
586: 				last = *itr;
587: 			}
588: 			// We are now one too far.
589: 			--itr;
590: 			// Trim the range.
591: 			handle->Trim(BLOCK_START + (NumericCast<idx_t>(first) * Storage::BLOCK_ALLOC_SIZE),
592: 			             NumericCast<idx_t>(last + 1 - first) * Storage::BLOCK_ALLOC_SIZE);
593: 		}
594: 	}
595: 	newly_freed_list.clear();
596: }
597: 
598: } // namespace duckdb
[end of src/storage/single_file_block_manager.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: