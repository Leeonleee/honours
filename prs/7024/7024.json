{
  "repo": "duckdb/duckdb",
  "pull_number": 7024,
  "instance_id": "duckdb__duckdb-7024",
  "issue_numbers": [
    "6466",
    "6466"
  ],
  "base_commit": "7312132f84cbc0960751a06d4f610af0043c8ae3",
  "patch": "diff --git a/tools/pythonpkg/src/python_objects.cpp b/tools/pythonpkg/src/python_objects.cpp\nindex 3b3847a7a692..76e67f7fc3fa 100644\n--- a/tools/pythonpkg/src/python_objects.cpp\n+++ b/tools/pythonpkg/src/python_objects.cpp\n@@ -251,6 +251,7 @@ Value PyDateTime::ToDuckValue() {\n \t\t// Need to subtract the UTC offset, so we invert the interval\n \t\tutc_offset = Interval::Invert(utc_offset);\n \t\ttimestamp = Interval::Add(timestamp, utc_offset);\n+\t\treturn Value::TIMESTAMPTZ(timestamp);\n \t}\n \treturn Value::TIMESTAMP(timestamp);\n }\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/pandas/test_datetime_time.py b/tools/pythonpkg/tests/fast/pandas/test_datetime_time.py\nindex e40733e71972..66b4dbcebcc4 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_datetime_time.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_datetime_time.py\n@@ -1,15 +1,14 @@\n import pandas as pd\n import duckdb\n-import datetime\n import numpy as np\n import pytest\n-\n+from datetime import datetime, timezone, time, timedelta\n \n class TestDateTimeTime(object):\n \n     def test_time_high(self, duckdb_cursor):\n         duckdb_time = duckdb.query(\"SELECT make_time(23, 1, 34.234345) AS '0'\").df()\n-        data = [datetime.time(hour=23, minute=1, second=34, microsecond=234345)]\n+        data = [time(hour=23, minute=1, second=34, microsecond=234345)]\n         df_in = pd.DataFrame(\n             {'0': pd.Series(data=data, dtype='object')}\n         )\n@@ -18,7 +17,7 @@ def test_time_high(self, duckdb_cursor):\n \n     def test_time_low(self, duckdb_cursor):\n         duckdb_time = duckdb.query(\"SELECT make_time(00, 01, 1.000) AS '0'\").df()\n-        data = [datetime.time(hour=0, minute=1, second=1)]\n+        data = [time(hour=0, minute=1, second=1)]\n         df_in = pd.DataFrame(\n             {'0': pd.Series(data=data, dtype='object')}\n         )\n@@ -28,9 +27,9 @@ def test_time_low(self, duckdb_cursor):\n     def test_time_timezone_regular(self, duckdb_cursor):\n         duckdb_time = duckdb.query(\"SELECT make_time(00, 01, 1.000) AS '0'\").df()\n         # time is 3 hours ahead of UTC\n-        offset = datetime.timedelta(hours=3)\n-        timezone = datetime.timezone(offset)\n-        data = [datetime.time(hour=3, minute=1, second=1, tzinfo=timezone)]\n+        offset = timedelta(hours=3)\n+        tz = timezone(offset)\n+        data = [time(hour=3, minute=1, second=1, tzinfo=tz)]\n         df_in = pd.DataFrame(\n             {'0': pd.Series(data=data, dtype='object')}\n         )\n@@ -40,9 +39,9 @@ def test_time_timezone_regular(self, duckdb_cursor):\n     def test_time_timezone_negative_extreme(self, duckdb_cursor):\n         duckdb_time = duckdb.query(\"SELECT make_time(12, 01, 1.000) AS '0'\").df()\n         # time is 14 hours behind UTC\n-        offset = datetime.timedelta(hours=-14)\n-        timezone = datetime.timezone(offset)\n-        data = [datetime.time(hour=22, minute=1, second=1, tzinfo=timezone)]\n+        offset = timedelta(hours=-14)\n+        tz = timezone(offset)\n+        data = [time(hour=22, minute=1, second=1, tzinfo=tz)]\n         df_in = pd.DataFrame(\n             {'0': pd.Series(data=data, dtype='object')}\n         )\n@@ -52,9 +51,9 @@ def test_time_timezone_negative_extreme(self, duckdb_cursor):\n     def test_time_timezone_positive_extreme(self, duckdb_cursor):\n         duckdb_time = duckdb.query(\"SELECT make_time(12, 01, 1.000) AS '0'\").df()\n         # time is 20 hours ahead of UTC\n-        offset = datetime.timedelta(hours=20)\n-        timezone = datetime.timezone(offset)\n-        data = [datetime.time(hour=8, minute=1, second=1, tzinfo=timezone)]\n+        offset = timedelta(hours=20)\n+        tz = timezone(offset)\n+        data = [time(hour=8, minute=1, second=1, tzinfo=tz)]\n         df_in = pd.DataFrame(\n             {'0': pd.Series(data=data, dtype='object')}\n         )\n@@ -69,3 +68,15 @@ def test_pandas_datetime_overflow(self):\n \n         with pytest.raises(duckdb.ConversionException):\n             res = duckdb_con.execute(\"select * from test\").df()\n+\n+    def test_timezone_datetime(self):\n+        con = duckdb.connect()\n+\n+        dt = datetime.now(timezone.utc).replace(microsecond=0)\n+\n+        original = dt\n+        stringified = str(dt)\n+\n+        original_res = con.execute('select ?::TIMESTAMPTZ', [original]).fetchone()\n+        stringified_res = con.execute('select ?::TIMESTAMPTZ', [stringified]).fetchone()\n+        assert original_res == stringified_res\n",
  "problem_statement": "[Python] datetime -> [duckdb] timestamptz conversion error\n### What happens?\n\nIncorrect timezone conversion.\r\n\n\n### To Reproduce\n\n```\r\nfrom datetime import datetime, timezone\r\nimport duckdb\r\n\r\ndt = datetime.now(timezone.utc).replace(microsecond=0)\r\nprint(dt)\r\n\r\nq = \"CREATE TABLE IF NOT EXISTS test (uid INT, dt TIMESTAMPTZ)\"\r\nduckdb.execute(q).commit()\r\n\r\nq1 = \"INSERT INTO test VALUES (?, ?)\"\r\nduckdb.execute(q1, (1, dt))     # BUG time zone\r\nduckdb.execute(q1, (2, str(dt)))\r\nduckdb.commit()\r\n\r\nduckdb.sql(\"SELECT * FROM test\").show()\r\n```\r\n```\r\n2023-02-25 21:02:54+00:00\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502  uid  \u2502            dt            \u2502\r\n\u2502 int32 \u2502 timestamp with time zone \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502 2023-02-25 21:02:54+05   \u2502\r\n\u2502     2 \u2502 2023-02-26 02:02:54+05   \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\n\n### OS:\n\nLinux x64, Windows x64\n\n### DuckDB Version:\n\n0.7.0\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nLeo\n\n### Affiliation:\n\nprivate\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n[Python] datetime -> [duckdb] timestamptz conversion error\n### What happens?\n\nIncorrect timezone conversion.\r\n\n\n### To Reproduce\n\n```\r\nfrom datetime import datetime, timezone\r\nimport duckdb\r\n\r\ndt = datetime.now(timezone.utc).replace(microsecond=0)\r\nprint(dt)\r\n\r\nq = \"CREATE TABLE IF NOT EXISTS test (uid INT, dt TIMESTAMPTZ)\"\r\nduckdb.execute(q).commit()\r\n\r\nq1 = \"INSERT INTO test VALUES (?, ?)\"\r\nduckdb.execute(q1, (1, dt))     # BUG time zone\r\nduckdb.execute(q1, (2, str(dt)))\r\nduckdb.commit()\r\n\r\nduckdb.sql(\"SELECT * FROM test\").show()\r\n```\r\n```\r\n2023-02-25 21:02:54+00:00\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502  uid  \u2502            dt            \u2502\r\n\u2502 int32 \u2502 timestamp with time zone \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502 2023-02-25 21:02:54+05   \u2502\r\n\u2502     2 \u2502 2023-02-26 02:02:54+05   \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\n\n### OS:\n\nLinux x64, Windows x64\n\n### DuckDB Version:\n\n0.7.0\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nLeo\n\n### Affiliation:\n\nprivate\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "@hawkfish\r\nI wonder if this is related to our ingestion of timestamptz values from a DataFrame or our internal timestamptz handling\r\n\r\nIf you can't reproduce this in the CLI/unittest let me know and I'll look into the dataframe ingestion code\nthis is output of same above snippet, if it helps cool.\r\n\r\nPython 3.10.9\r\nduckdb = 0.7.1\r\nmy timezone: IST\r\n```\r\n2023-03-01 09:30:05+00:00\r\n\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502  uid  \u2502            dt             \u2502\r\n\u2502 int32 \u2502 timestamp with time zone  \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502 2023-03-01 09:30:05+05:30 \u2502\r\n\u2502     2 \u2502 2023-03-01 15:00:05+05:30 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\nI think this is related, but when loading data from .parquet files, columns that are UTC-denominated are losing their timezone information. In otherwords, I put UTC-marked timestamps into a .parquet file, and DuckDB returns a timezone-naive dataframe to me when converting to Pandas.\r\n\r\nI can make a test case if this isn't clear.\n@rachtsingh \r\n\r\n> I think this is related, but when loading data from .parquet files, columns that are UTC-denominated are losing their timezone information. In otherwords, I put UTC-marked timestamps into a .parquet file, and DuckDB returns a timezone-naive dataframe to me when converting to Pandas.\r\n> \r\n> I can make a test case if this isn't clear.\r\n\r\nSQL does not store time zones, so this is expected. And UTC timestamps cannot (by definition) be na\u00efve. It sounds like what is happening is you have a Parquet file with timestamps that have an attached time zone that are being inserted into at DuckDB `TIMESTAMP` column. When this is read back out into a Pandas data frame, you get timestamps with no attached time zone. Does that sound right?\r\n\r\nTo preserve the time zone name at the row level, you would need to somehow extract it as a separate string before inserting it into DuckDB. You could then use the `timezone` function to create na\u00efve (local) timestamps for row level binning (we don't currently have row level binning functions that accept time zone names, but it would not be hard to add).\n@Tishj \r\n\r\n> I wonder if this is related to our ingestion of timestamptz values from a DataFrame or our internal timestamptz handling\r\n> \r\n> If you can't reproduce this in the CLI/unittest let me know and I'll look into the dataframe ingestion code\r\n\r\nIn both of the examples from @nikeshnaik, the second row is created by parsing the string representation that Python provides for a UTC tagged timestamp (which was printed out) and they are both correct when presented in the DuckDB time zone (UTC+05 for the first one and IST == +05:30 for the second one). Also in both of them, the first row appears to be generated as a na\u00efve (local) timestamp value in the current time zone. (It would be helpful to know whether Python and DuckDB have the same TZ setting here, but I suspect they are both using ICU and the initialization code in both would likely agree.) But it looks like Python (or its bindings) are generating a na\u00efve timestamp for insertion, so maybe you should have a look?\n> It sounds like what is happening is you have a Parquet file with timestamps that have an attached time zone that are being inserted into at DuckDB TIMESTAMP column. When this is read back out into a Pandas data frame, you get timestamps with no attached time zone. Does that sound right?\r\n\r\nI think that's right, if how `read_parquet` works is that DuckDB creates a temporary table and imports it on the fly. I'm afraid I don't really understand the solution with creating a separate string column - if it doesn't fit into the `read_parquet` API, we're unlikely to use it, at least right now. We're working around this right now by just marking naive timestamps as UTC with a wrapper around `execute`.\r\n\r\nRe: UTC timestamps being naive, I'm just saying that Pandas treats `datetime64[ns]` and `datetime64[ns, UTC]` as two different types - for example you can't subtract them. Here's a complete description:\r\n\r\n```python\r\nIn [1]: now = pd.Timestamp.utcnow() # tz-aware timestamp\r\n[PYFLYBY] import pandas as pd\r\n\r\nIn [2]: df = pd.DataFrame({'ts': [now, now], 'val': [1, 2]})\r\n\r\nIn [3]: df.info()\r\n<class 'pandas.core.frame.DataFrame'>\r\nRangeIndex: 2 entries, 0 to 1\r\nData columns (total 2 columns):\r\n #   Column  Non-Null Count  Dtype\r\n---  ------  --------------  -----\r\n 0   ts      2 non-null      datetime64[ns, UTC]\r\n 1   val     2 non-null      int64\r\ndtypes: datetime64[ns, UTC](1), int64(1)\r\nmemory usage: 160.0 bytes\r\n\r\nIn [4]: df.to_parquet('test.parquet')\r\n\r\nIn [5]: import duckdb\r\n\r\nIn [6]: df2 = duckdb.default_connection.execute(\"\"\"SELECT * FROM read_parquet('test.parquet')\"\"\").df()\r\n\r\nIn [7]: df2.info()\r\n<class 'pandas.core.frame.DataFrame'>\r\nRangeIndex: 2 entries, 0 to 1\r\nData columns (total 2 columns):\r\n #   Column  Non-Null Count  Dtype\r\n---  ------  --------------  -----\r\n 0   ts      2 non-null      datetime64[ns]\r\n 1   val     2 non-null      int64\r\ndtypes: datetime64[ns](1), int64(1)\r\nmemory usage: 160.0 bytes\r\n\r\nIn [8]: df\r\nOut[8]:\r\n                                ts  val\r\n0 2023-03-07 22:37:59.679577+00:00    1\r\n1 2023-03-07 22:37:59.679577+00:00    2\r\n\r\nIn [9]: df2\r\nOut[9]:\r\n                          ts  val\r\n0 2023-03-07 22:37:59.679577    1\r\n1 2023-03-07 22:37:59.679577    2\r\n\r\n...\r\n\r\nIn [19]: df2.ts - df.ts\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nFile ~/.pyenv/versions/3.10.4/envs/prod/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py:1112, in DatetimeLikeArrayMixin._sub_datetimelike(self, other)\r\n   1111 try:\r\n-> 1112     self._assert_tzawareness_compat(other)\r\n   1113 except TypeError as err:\r\n\r\nFile ~/.pyenv/versions/3.10.4/envs/prod/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:744, in DatetimeArray._assert_tzawareness_compat(self, other)\r\n    743     if other_tz is not None:\r\n--> 744         raise TypeError(\r\n    745             \"Cannot compare tz-naive and tz-aware datetime-like objects.\"\r\n    746         )\r\n    747 elif other_tz is None:\r\n\r\nTypeError: Cannot compare tz-naive and tz-aware datetime-like objects.\r\n```\r\n\r\nThanks for taking a look!\nAh, so Pandas assumes that non-TZ columns are na\u00efve (local, non-dense, non-unique). In DuckDB we assume both types contain well-defined data (e.g., \u00b5s since the Unix epoch) unless told otherwise (e.g., `timezone(...)`. This is in part because we rely on extensions (e.g., ICU) to provide time zone support, and partly because storing na\u00efve values is bad practice.\nIt looks like the parquet file is being read with type TSTZ but the data frame output is not setting the Pandas type correctly (e.g., `datetime64[ns, UTC]` or `datetime64[ns, <current tz>`).\r\n\r\n```sql\r\nD select * from read_parquet('test.parquet');\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502              ts               \u2502  val  \u2502\r\n\u2502   timestamp with time zone    \u2502 int64 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2023-03-07 15:05:34.544974-08 \u2502     1 \u2502\r\n\u2502 2023-03-07 15:05:34.544974-08 \u2502     2 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\nSome more weird behavior (back to just CLI and vanilla Python).\r\n\r\nUsing CLI I can see I have a `TIMESTAMPTZ` which is 10 am in Phoenix time (UTC -7), all good:\r\n\r\n```sql\r\nSELECT * FROM duckdb_settings() WHERE name = 'TimeZone';\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   name   \u2502      value      \u2502      description      \u2502 input_type \u2502\r\n\u2502 varchar  \u2502     varchar     \u2502        varchar        \u2502  varchar   \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 TimeZone \u2502 America/Phoenix \u2502 The current time zone \u2502 VARCHAR    \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nD select ts from ota; \r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502              ts               \u2502\r\n\u2502   timestamp with time zone    \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2019-04-25 10:03:56.072698-07 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nPer [this blog](https://duckdb.org/2022/01/06/time-zones.html#icu-time-zones) I can change zone and conversion is done: 5pm in UTC, great:\r\n```sql\r\nD SET TimeZone='UTC';\r\nD select ts from ota; \r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502              ts               \u2502\r\n\u2502   timestamp with time zone    \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2019-04-25 17:03:56.072698+00 \u2502\r\n```\r\n\r\n---\r\n\r\nOpening the same file in Python:\r\n\r\nPython knows we're in Phoenix time (aka MST):\r\n\r\n```py\r\ndatetime.now().astimezone().tzinfo\r\n# datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'MST')\r\n```\r\n\r\nduckdb appears to agree:\r\n\r\n```py\r\ncon.sql(\"SELECT * FROM duckdb_settings() WHERE name = 'TimeZone';\").fetchone()\r\n# ('TimeZone', 'America/Phoenix', 'The current time zone', 'VARCHAR')\r\n```\r\n\r\nBut when I `fetchone` the time is implicitly 'adjusted' to UTC (note the `17`:\r\n```py\r\ncon.sql(\"SELECT ts FROM ota\").fetchone()[0]\r\ndatetime.datetime(2019, 4, 25, 17, 3, 56, 72698)\r\n```\r\n\r\nIs this by design?\r\nIt's not _terrible_, but I'd prefer if the returned time was timezone aware (i.e. had a UTC `tzinfo`).\r\n\r\n---\r\n\r\nBut wait there's more!\r\n\r\nIf I get as a Pandas dataframe, it's UTC *and* aware:\r\n\r\n```py\r\nota = con.sql('SELECT * FROM ota').df()\r\nota['ts']\r\n# 0   2019-04-25 17:03:56.072698+00:00\r\n# Name: ts, dtype: datetime64[ns, UTC]\r\n```\r\n\r\nJust for the fun of it, If I cast to text, then fetch, it comes back as Phoenix time:\r\n\r\n```py\r\ncon.sql(\"SELECT cast(ts as text) FROM ota\").fetchone()[0]\r\n'2019-04-25 10:03:56.072698-07'\r\n```\r\n\r\n---\r\n\r\nMaybe this?\r\nhttps://github.com/duckdb/duckdb/blob/ab5c07cb689d2b899b6abf738284baeae6ba0046/tools/pythonpkg/src/pyresult.cpp#L226-L235\r\n\r\nThat comes from:\r\nhttps://github.com/duckdb/duckdb/blob/ab5c07cb689d2b899b6abf738284baeae6ba0046/src/main/query_result.cpp#L154-L156\r\n\r\nBut I don't know where `client_properties` comes from? \ud83e\udd37\ud83c\udffb \nAh yea we should add support for that, the relevant code is in `pyresult.cpp` `DuckDBPyResult::FetchOne()`\r\nThe `PythonObject::FromValue` method should likely take a `timezone` string, defaulting to UTC so it can still be used in places where we don't have a ClientContext/ClientProperties object to get it from\nI just got caught out by missing the `str` on an `execute` again, i.e. the original problem:\r\n\r\n```python\r\nduckdb.execute(q1, (1, dt))     # BUG time zone\r\nduckdb.execute(q1, (2, str(dt)))\r\n```\r\n\r\nCan I suggest a PR to do that (call `str` aka `dt.isoformat()`) by default?\r\n\r\nI _assume_ if `dt` has `tzinfo` then it would always be preferable to pass that\r\n(and it not being passed is cause of reported behavior).\n@hawkfish\r\nI wonder if this is related to our ingestion of timestamptz values from a DataFrame or our internal timestamptz handling\r\n\r\nIf you can't reproduce this in the CLI/unittest let me know and I'll look into the dataframe ingestion code\nthis is output of same above snippet, if it helps cool.\r\n\r\nPython 3.10.9\r\nduckdb = 0.7.1\r\nmy timezone: IST\r\n```\r\n2023-03-01 09:30:05+00:00\r\n\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502  uid  \u2502            dt             \u2502\r\n\u2502 int32 \u2502 timestamp with time zone  \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502 2023-03-01 09:30:05+05:30 \u2502\r\n\u2502     2 \u2502 2023-03-01 15:00:05+05:30 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\nI think this is related, but when loading data from .parquet files, columns that are UTC-denominated are losing their timezone information. In otherwords, I put UTC-marked timestamps into a .parquet file, and DuckDB returns a timezone-naive dataframe to me when converting to Pandas.\r\n\r\nI can make a test case if this isn't clear.\n@rachtsingh \r\n\r\n> I think this is related, but when loading data from .parquet files, columns that are UTC-denominated are losing their timezone information. In otherwords, I put UTC-marked timestamps into a .parquet file, and DuckDB returns a timezone-naive dataframe to me when converting to Pandas.\r\n> \r\n> I can make a test case if this isn't clear.\r\n\r\nSQL does not store time zones, so this is expected. And UTC timestamps cannot (by definition) be na\u00efve. It sounds like what is happening is you have a Parquet file with timestamps that have an attached time zone that are being inserted into at DuckDB `TIMESTAMP` column. When this is read back out into a Pandas data frame, you get timestamps with no attached time zone. Does that sound right?\r\n\r\nTo preserve the time zone name at the row level, you would need to somehow extract it as a separate string before inserting it into DuckDB. You could then use the `timezone` function to create na\u00efve (local) timestamps for row level binning (we don't currently have row level binning functions that accept time zone names, but it would not be hard to add).\n@Tishj \r\n\r\n> I wonder if this is related to our ingestion of timestamptz values from a DataFrame or our internal timestamptz handling\r\n> \r\n> If you can't reproduce this in the CLI/unittest let me know and I'll look into the dataframe ingestion code\r\n\r\nIn both of the examples from @nikeshnaik, the second row is created by parsing the string representation that Python provides for a UTC tagged timestamp (which was printed out) and they are both correct when presented in the DuckDB time zone (UTC+05 for the first one and IST == +05:30 for the second one). Also in both of them, the first row appears to be generated as a na\u00efve (local) timestamp value in the current time zone. (It would be helpful to know whether Python and DuckDB have the same TZ setting here, but I suspect they are both using ICU and the initialization code in both would likely agree.) But it looks like Python (or its bindings) are generating a na\u00efve timestamp for insertion, so maybe you should have a look?\n> It sounds like what is happening is you have a Parquet file with timestamps that have an attached time zone that are being inserted into at DuckDB TIMESTAMP column. When this is read back out into a Pandas data frame, you get timestamps with no attached time zone. Does that sound right?\r\n\r\nI think that's right, if how `read_parquet` works is that DuckDB creates a temporary table and imports it on the fly. I'm afraid I don't really understand the solution with creating a separate string column - if it doesn't fit into the `read_parquet` API, we're unlikely to use it, at least right now. We're working around this right now by just marking naive timestamps as UTC with a wrapper around `execute`.\r\n\r\nRe: UTC timestamps being naive, I'm just saying that Pandas treats `datetime64[ns]` and `datetime64[ns, UTC]` as two different types - for example you can't subtract them. Here's a complete description:\r\n\r\n```python\r\nIn [1]: now = pd.Timestamp.utcnow() # tz-aware timestamp\r\n[PYFLYBY] import pandas as pd\r\n\r\nIn [2]: df = pd.DataFrame({'ts': [now, now], 'val': [1, 2]})\r\n\r\nIn [3]: df.info()\r\n<class 'pandas.core.frame.DataFrame'>\r\nRangeIndex: 2 entries, 0 to 1\r\nData columns (total 2 columns):\r\n #   Column  Non-Null Count  Dtype\r\n---  ------  --------------  -----\r\n 0   ts      2 non-null      datetime64[ns, UTC]\r\n 1   val     2 non-null      int64\r\ndtypes: datetime64[ns, UTC](1), int64(1)\r\nmemory usage: 160.0 bytes\r\n\r\nIn [4]: df.to_parquet('test.parquet')\r\n\r\nIn [5]: import duckdb\r\n\r\nIn [6]: df2 = duckdb.default_connection.execute(\"\"\"SELECT * FROM read_parquet('test.parquet')\"\"\").df()\r\n\r\nIn [7]: df2.info()\r\n<class 'pandas.core.frame.DataFrame'>\r\nRangeIndex: 2 entries, 0 to 1\r\nData columns (total 2 columns):\r\n #   Column  Non-Null Count  Dtype\r\n---  ------  --------------  -----\r\n 0   ts      2 non-null      datetime64[ns]\r\n 1   val     2 non-null      int64\r\ndtypes: datetime64[ns](1), int64(1)\r\nmemory usage: 160.0 bytes\r\n\r\nIn [8]: df\r\nOut[8]:\r\n                                ts  val\r\n0 2023-03-07 22:37:59.679577+00:00    1\r\n1 2023-03-07 22:37:59.679577+00:00    2\r\n\r\nIn [9]: df2\r\nOut[9]:\r\n                          ts  val\r\n0 2023-03-07 22:37:59.679577    1\r\n1 2023-03-07 22:37:59.679577    2\r\n\r\n...\r\n\r\nIn [19]: df2.ts - df.ts\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nFile ~/.pyenv/versions/3.10.4/envs/prod/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py:1112, in DatetimeLikeArrayMixin._sub_datetimelike(self, other)\r\n   1111 try:\r\n-> 1112     self._assert_tzawareness_compat(other)\r\n   1113 except TypeError as err:\r\n\r\nFile ~/.pyenv/versions/3.10.4/envs/prod/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:744, in DatetimeArray._assert_tzawareness_compat(self, other)\r\n    743     if other_tz is not None:\r\n--> 744         raise TypeError(\r\n    745             \"Cannot compare tz-naive and tz-aware datetime-like objects.\"\r\n    746         )\r\n    747 elif other_tz is None:\r\n\r\nTypeError: Cannot compare tz-naive and tz-aware datetime-like objects.\r\n```\r\n\r\nThanks for taking a look!\nAh, so Pandas assumes that non-TZ columns are na\u00efve (local, non-dense, non-unique). In DuckDB we assume both types contain well-defined data (e.g., \u00b5s since the Unix epoch) unless told otherwise (e.g., `timezone(...)`. This is in part because we rely on extensions (e.g., ICU) to provide time zone support, and partly because storing na\u00efve values is bad practice.\nIt looks like the parquet file is being read with type TSTZ but the data frame output is not setting the Pandas type correctly (e.g., `datetime64[ns, UTC]` or `datetime64[ns, <current tz>`).\r\n\r\n```sql\r\nD select * from read_parquet('test.parquet');\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502              ts               \u2502  val  \u2502\r\n\u2502   timestamp with time zone    \u2502 int64 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2023-03-07 15:05:34.544974-08 \u2502     1 \u2502\r\n\u2502 2023-03-07 15:05:34.544974-08 \u2502     2 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\nSome more weird behavior (back to just CLI and vanilla Python).\r\n\r\nUsing CLI I can see I have a `TIMESTAMPTZ` which is 10 am in Phoenix time (UTC -7), all good:\r\n\r\n```sql\r\nSELECT * FROM duckdb_settings() WHERE name = 'TimeZone';\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   name   \u2502      value      \u2502      description      \u2502 input_type \u2502\r\n\u2502 varchar  \u2502     varchar     \u2502        varchar        \u2502  varchar   \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 TimeZone \u2502 America/Phoenix \u2502 The current time zone \u2502 VARCHAR    \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nD select ts from ota; \r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502              ts               \u2502\r\n\u2502   timestamp with time zone    \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2019-04-25 10:03:56.072698-07 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nPer [this blog](https://duckdb.org/2022/01/06/time-zones.html#icu-time-zones) I can change zone and conversion is done: 5pm in UTC, great:\r\n```sql\r\nD SET TimeZone='UTC';\r\nD select ts from ota; \r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502              ts               \u2502\r\n\u2502   timestamp with time zone    \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2019-04-25 17:03:56.072698+00 \u2502\r\n```\r\n\r\n---\r\n\r\nOpening the same file in Python:\r\n\r\nPython knows we're in Phoenix time (aka MST):\r\n\r\n```py\r\ndatetime.now().astimezone().tzinfo\r\n# datetime.timezone(datetime.timedelta(days=-1, seconds=61200), 'MST')\r\n```\r\n\r\nduckdb appears to agree:\r\n\r\n```py\r\ncon.sql(\"SELECT * FROM duckdb_settings() WHERE name = 'TimeZone';\").fetchone()\r\n# ('TimeZone', 'America/Phoenix', 'The current time zone', 'VARCHAR')\r\n```\r\n\r\nBut when I `fetchone` the time is implicitly 'adjusted' to UTC (note the `17`:\r\n```py\r\ncon.sql(\"SELECT ts FROM ota\").fetchone()[0]\r\ndatetime.datetime(2019, 4, 25, 17, 3, 56, 72698)\r\n```\r\n\r\nIs this by design?\r\nIt's not _terrible_, but I'd prefer if the returned time was timezone aware (i.e. had a UTC `tzinfo`).\r\n\r\n---\r\n\r\nBut wait there's more!\r\n\r\nIf I get as a Pandas dataframe, it's UTC *and* aware:\r\n\r\n```py\r\nota = con.sql('SELECT * FROM ota').df()\r\nota['ts']\r\n# 0   2019-04-25 17:03:56.072698+00:00\r\n# Name: ts, dtype: datetime64[ns, UTC]\r\n```\r\n\r\nJust for the fun of it, If I cast to text, then fetch, it comes back as Phoenix time:\r\n\r\n```py\r\ncon.sql(\"SELECT cast(ts as text) FROM ota\").fetchone()[0]\r\n'2019-04-25 10:03:56.072698-07'\r\n```\r\n\r\n---\r\n\r\nMaybe this?\r\nhttps://github.com/duckdb/duckdb/blob/ab5c07cb689d2b899b6abf738284baeae6ba0046/tools/pythonpkg/src/pyresult.cpp#L226-L235\r\n\r\nThat comes from:\r\nhttps://github.com/duckdb/duckdb/blob/ab5c07cb689d2b899b6abf738284baeae6ba0046/src/main/query_result.cpp#L154-L156\r\n\r\nBut I don't know where `client_properties` comes from? \ud83e\udd37\ud83c\udffb \nAh yea we should add support for that, the relevant code is in `pyresult.cpp` `DuckDBPyResult::FetchOne()`\r\nThe `PythonObject::FromValue` method should likely take a `timezone` string, defaulting to UTC so it can still be used in places where we don't have a ClientContext/ClientProperties object to get it from\nI just got caught out by missing the `str` on an `execute` again, i.e. the original problem:\r\n\r\n```python\r\nduckdb.execute(q1, (1, dt))     # BUG time zone\r\nduckdb.execute(q1, (2, str(dt)))\r\n```\r\n\r\nCan I suggest a PR to do that (call `str` aka `dt.isoformat()`) by default?\r\n\r\nI _assume_ if `dt` has `tzinfo` then it would always be preferable to pass that\r\n(and it not being passed is cause of reported behavior).",
  "created_at": "2023-04-11T07:22:25Z"
}