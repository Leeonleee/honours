You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
sniff_csv fails to detect compression when reading from a url that has a query string
### What happens?

`sniff_csv` fails to  detect compression when reading from a url that has a query string.

For example this statement
```sql
from sniff_csv('https://github.com/duckdb/duckdb/raw/main/data/csv/who.csv.gz?v=1');
```
Fails withs this error
```text
Error: Invalid Input Error: Invalid unicode (byte sequence mismatch) detected in value construction
```

but this statement succeeds
```sql
from sniff_csv('https://github.com/duckdb/duckdb/raw/main/data/csv/who.csv.gz');
```

The root cause of this is in the file at line src/common/virtual_file_system.cpp at line 15 https://github.com/duckdb/duckdb/blob/4d24f5c660a205bf22a7fd99e36efece798452c4/src/common/virtual_file_system.cpp#L15 and could be fixed with a check for url and remove the query string path.


I will open a PR for this.


### To Reproduce

Run this statement
```sql
from sniff_csv('https://github.com/duckdb/duckdb/raw/main/data/csv/who.csv.gz?v=1');
```

### OS:

all

### DuckDB Version:

0.9.3

### DuckDB Client:

all

### Full Name:

Gabriel Hodoroaga

### Affiliation:

Bobsled

### Have you tried this on the latest [nightly build](https://duckdb.org/docs/installation/?version=main)?

I have tested with a nightly build

### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of src/common/enums/file_compression_type.cpp]
1: #include "duckdb/common/enums/file_compression_type.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/common/exception/parser_exception.hpp"
4: 
5: namespace duckdb {
6: 
7: FileCompressionType FileCompressionTypeFromString(const string &input) {
8: 	auto parameter = StringUtil::Lower(input);
9: 	if (parameter == "infer" || parameter == "auto") {
10: 		return FileCompressionType::AUTO_DETECT;
11: 	} else if (parameter == "gzip") {
12: 		return FileCompressionType::GZIP;
13: 	} else if (parameter == "zstd") {
14: 		return FileCompressionType::ZSTD;
15: 	} else if (parameter == "uncompressed" || parameter == "none" || parameter.empty()) {
16: 		return FileCompressionType::UNCOMPRESSED;
17: 	} else {
18: 		throw ParserException("Unrecognized file compression type \"%s\"", input);
19: 	}
20: }
21: 
22: } // namespace duckdb
[end of src/common/enums/file_compression_type.cpp]
[start of src/common/virtual_file_system.cpp]
1: #include "duckdb/common/virtual_file_system.hpp"
2: #include "duckdb/common/gzip_file_system.hpp"
3: #include "duckdb/common/pipe_file_system.hpp"
4: #include "duckdb/common/string_util.hpp"
5: 
6: namespace duckdb {
7: 
8: VirtualFileSystem::VirtualFileSystem() : default_fs(FileSystem::CreateLocal()) {
9: 	VirtualFileSystem::RegisterSubSystem(FileCompressionType::GZIP, make_uniq<GZipFileSystem>());
10: }
11: 
12: unique_ptr<FileHandle> VirtualFileSystem::OpenFile(const string &path, FileOpenFlags flags,
13:                                                    optional_ptr<FileOpener> opener) {
14: 	auto compression = flags.Compression();
15: 	if (compression == FileCompressionType::AUTO_DETECT) {
16: 		// auto detect compression settings based on file name
17: 		auto lower_path = StringUtil::Lower(path);
18: 		if (StringUtil::EndsWith(lower_path, ".tmp")) {
19: 			// strip .tmp
20: 			lower_path = lower_path.substr(0, lower_path.length() - 4);
21: 		}
22: 		if (StringUtil::EndsWith(lower_path, ".gz")) {
23: 			compression = FileCompressionType::GZIP;
24: 		} else if (StringUtil::EndsWith(lower_path, ".zst")) {
25: 			compression = FileCompressionType::ZSTD;
26: 		} else {
27: 			compression = FileCompressionType::UNCOMPRESSED;
28: 		}
29: 	}
30: 	// open the base file handle in UNCOMPRESSED mode
31: 	flags.SetCompression(FileCompressionType::UNCOMPRESSED);
32: 	auto file_handle = FindFileSystem(path).OpenFile(path, flags, opener);
33: 	if (!file_handle) {
34: 		return nullptr;
35: 	}
36: 	if (file_handle->GetType() == FileType::FILE_TYPE_FIFO) {
37: 		file_handle = PipeFileSystem::OpenPipe(std::move(file_handle));
38: 	} else if (compression != FileCompressionType::UNCOMPRESSED) {
39: 		auto entry = compressed_fs.find(compression);
40: 		if (entry == compressed_fs.end()) {
41: 			throw NotImplementedException(
42: 			    "Attempting to open a compressed file, but the compression type is not supported");
43: 		}
44: 		file_handle = entry->second->OpenCompressedFile(std::move(file_handle), flags.OpenForWriting());
45: 	}
46: 	return file_handle;
47: }
48: 
49: void VirtualFileSystem::Read(FileHandle &handle, void *buffer, int64_t nr_bytes, idx_t location) {
50: 	handle.file_system.Read(handle, buffer, nr_bytes, location);
51: }
52: 
53: void VirtualFileSystem::Write(FileHandle &handle, void *buffer, int64_t nr_bytes, idx_t location) {
54: 	handle.file_system.Write(handle, buffer, nr_bytes, location);
55: }
56: 
57: int64_t VirtualFileSystem::Read(FileHandle &handle, void *buffer, int64_t nr_bytes) {
58: 	return handle.file_system.Read(handle, buffer, nr_bytes);
59: }
60: 
61: int64_t VirtualFileSystem::Write(FileHandle &handle, void *buffer, int64_t nr_bytes) {
62: 	return handle.file_system.Write(handle, buffer, nr_bytes);
63: }
64: 
65: int64_t VirtualFileSystem::GetFileSize(FileHandle &handle) {
66: 	return handle.file_system.GetFileSize(handle);
67: }
68: time_t VirtualFileSystem::GetLastModifiedTime(FileHandle &handle) {
69: 	return handle.file_system.GetLastModifiedTime(handle);
70: }
71: FileType VirtualFileSystem::GetFileType(FileHandle &handle) {
72: 	return handle.file_system.GetFileType(handle);
73: }
74: 
75: void VirtualFileSystem::Truncate(FileHandle &handle, int64_t new_size) {
76: 	handle.file_system.Truncate(handle, new_size);
77: }
78: 
79: void VirtualFileSystem::FileSync(FileHandle &handle) {
80: 	handle.file_system.FileSync(handle);
81: }
82: 
83: // need to look up correct fs for this
84: bool VirtualFileSystem::DirectoryExists(const string &directory, optional_ptr<FileOpener> opener) {
85: 	return FindFileSystem(directory).DirectoryExists(directory, opener);
86: }
87: void VirtualFileSystem::CreateDirectory(const string &directory, optional_ptr<FileOpener> opener) {
88: 	FindFileSystem(directory).CreateDirectory(directory, opener);
89: }
90: 
91: void VirtualFileSystem::RemoveDirectory(const string &directory, optional_ptr<FileOpener> opener) {
92: 	FindFileSystem(directory).RemoveDirectory(directory, opener);
93: }
94: 
95: bool VirtualFileSystem::ListFiles(const string &directory, const std::function<void(const string &, bool)> &callback,
96:                                   FileOpener *opener) {
97: 	return FindFileSystem(directory).ListFiles(directory, callback, opener);
98: }
99: 
100: void VirtualFileSystem::MoveFile(const string &source, const string &target, optional_ptr<FileOpener> opener) {
101: 	FindFileSystem(source).MoveFile(source, target, opener);
102: }
103: 
104: bool VirtualFileSystem::FileExists(const string &filename, optional_ptr<FileOpener> opener) {
105: 	return FindFileSystem(filename).FileExists(filename, opener);
106: }
107: 
108: bool VirtualFileSystem::IsPipe(const string &filename, optional_ptr<FileOpener> opener) {
109: 	return FindFileSystem(filename).IsPipe(filename, opener);
110: }
111: 
112: void VirtualFileSystem::RemoveFile(const string &filename, optional_ptr<FileOpener> opener) {
113: 	FindFileSystem(filename).RemoveFile(filename, opener);
114: }
115: 
116: string VirtualFileSystem::PathSeparator(const string &path) {
117: 	return FindFileSystem(path).PathSeparator(path);
118: }
119: 
120: vector<string> VirtualFileSystem::Glob(const string &path, FileOpener *opener) {
121: 	return FindFileSystem(path).Glob(path, opener);
122: }
123: 
124: void VirtualFileSystem::RegisterSubSystem(unique_ptr<FileSystem> fs) {
125: 	sub_systems.push_back(std::move(fs));
126: }
127: 
128: void VirtualFileSystem::UnregisterSubSystem(const string &name) {
129: 	for (auto sub_system = sub_systems.begin(); sub_system != sub_systems.end(); sub_system++) {
130: 		if (sub_system->get()->GetName() == name) {
131: 			sub_systems.erase(sub_system);
132: 			return;
133: 		}
134: 	}
135: 	throw InvalidInputException("Could not find filesystem with name %s", name);
136: }
137: 
138: void VirtualFileSystem::RegisterSubSystem(FileCompressionType compression_type, unique_ptr<FileSystem> fs) {
139: 	compressed_fs[compression_type] = std::move(fs);
140: }
141: 
142: vector<string> VirtualFileSystem::ListSubSystems() {
143: 	vector<string> names(sub_systems.size());
144: 	for (idx_t i = 0; i < sub_systems.size(); i++) {
145: 		names[i] = sub_systems[i]->GetName();
146: 	}
147: 	return names;
148: }
149: 
150: std::string VirtualFileSystem::GetName() const {
151: 	return "VirtualFileSystem";
152: }
153: 
154: void VirtualFileSystem::SetDisabledFileSystems(const vector<string> &names) {
155: 	unordered_set<string> new_disabled_file_systems;
156: 	for (auto &name : names) {
157: 		if (name.empty()) {
158: 			continue;
159: 		}
160: 		if (new_disabled_file_systems.find(name) != new_disabled_file_systems.end()) {
161: 			throw InvalidInputException("Duplicate disabled file system \"%s\"", name);
162: 		}
163: 		new_disabled_file_systems.insert(name);
164: 	}
165: 	for (auto &disabled_fs : disabled_file_systems) {
166: 		if (new_disabled_file_systems.find(disabled_fs) == new_disabled_file_systems.end()) {
167: 			throw InvalidInputException("File system \"%s\" has been disabled previously, it cannot be re-enabled",
168: 			                            disabled_fs);
169: 		}
170: 	}
171: 	disabled_file_systems = std::move(new_disabled_file_systems);
172: }
173: 
174: FileSystem &VirtualFileSystem::FindFileSystem(const string &path) {
175: 	auto &fs = FindFileSystemInternal(path);
176: 	if (!disabled_file_systems.empty() && disabled_file_systems.find(fs.GetName()) != disabled_file_systems.end()) {
177: 		throw PermissionException("File system %s has been disabled by configuration", fs.GetName());
178: 	}
179: 	return fs;
180: }
181: 
182: FileSystem &VirtualFileSystem::FindFileSystemInternal(const string &path) {
183: 	FileSystem *fs = nullptr;
184: 	for (auto &sub_system : sub_systems) {
185: 		if (sub_system->CanHandleFile(path)) {
186: 			if (sub_system->IsManuallySet()) {
187: 				return *sub_system;
188: 			}
189: 			fs = sub_system.get();
190: 		}
191: 	}
192: 	if (fs) {
193: 		return *fs;
194: 	}
195: 	return *default_fs;
196: }
197: 
198: } // namespace duckdb
[end of src/common/virtual_file_system.cpp]
[start of src/function/table/copy_csv.cpp]
1: #include "duckdb/common/bind_helpers.hpp"
2: #include "duckdb/common/file_system.hpp"
3: #include "duckdb/common/multi_file_reader.hpp"
4: #include "duckdb/common/serializer/memory_stream.hpp"
5: #include "duckdb/common/serializer/write_stream.hpp"
6: #include "duckdb/common/string_util.hpp"
7: #include "duckdb/common/types/column/column_data_collection.hpp"
8: #include "duckdb/common/types/string_type.hpp"
9: #include "duckdb/common/vector_operations/vector_operations.hpp"
10: #include "duckdb/execution/operator/csv_scanner/csv_sniffer.hpp"
11: #include "duckdb/function/copy_function.hpp"
12: #include "duckdb/function/scalar/string_functions.hpp"
13: #include "duckdb/function/table/read_csv.hpp"
14: #include "duckdb/parser/expression/bound_expression.hpp"
15: #include "duckdb/parser/expression/cast_expression.hpp"
16: #include "duckdb/parser/expression/constant_expression.hpp"
17: #include "duckdb/parser/expression/function_expression.hpp"
18: #include "duckdb/parser/parsed_data/copy_info.hpp"
19: #include "duckdb/planner/expression/bound_reference_expression.hpp"
20: 
21: #include <limits>
22: 
23: namespace duckdb {
24: 
25: void AreOptionsEqual(char str_1, char str_2, const string &name_str_1, const string &name_str_2) {
26: 	if (str_1 == '\0' || str_2 == '\0') {
27: 		return;
28: 	}
29: 	if (str_1 == str_2) {
30: 		throw BinderException("%s must not appear in the %s specification and vice versa", name_str_1, name_str_2);
31: 	}
32: }
33: 
34: void SubstringDetection(char str_1, string &str_2, const string &name_str_1, const string &name_str_2) {
35: 	if (str_1 == '\0' || str_2.empty()) {
36: 		return;
37: 	}
38: 	if (str_2.find(str_1) != string::npos) {
39: 		throw BinderException("%s must not appear in the %s specification and vice versa", name_str_1, name_str_2);
40: 	}
41: }
42: 
43: //===--------------------------------------------------------------------===//
44: // Bind
45: //===--------------------------------------------------------------------===//
46: void WriteQuoteOrEscape(WriteStream &writer, char quote_or_escape) {
47: 	if (quote_or_escape != '\0') {
48: 		writer.Write(quote_or_escape);
49: 	}
50: }
51: 
52: void BaseCSVData::Finalize() {
53: 	// verify that the options are correct in the final pass
54: 	if (options.dialect_options.state_machine_options.escape == '\0') {
55: 		options.dialect_options.state_machine_options.escape = options.dialect_options.state_machine_options.quote;
56: 	}
57: 	// escape and delimiter must not be substrings of each other
58: 	AreOptionsEqual(options.dialect_options.state_machine_options.delimiter.GetValue(),
59: 	                options.dialect_options.state_machine_options.escape.GetValue(), "DELIMITER", "ESCAPE");
60: 
61: 	// delimiter and quote must not be substrings of each other
62: 	AreOptionsEqual(options.dialect_options.state_machine_options.quote.GetValue(),
63: 	                options.dialect_options.state_machine_options.delimiter.GetValue(), "DELIMITER", "QUOTE");
64: 
65: 	// escape and quote must not be substrings of each other (but can be the same)
66: 	if (options.dialect_options.state_machine_options.quote != options.dialect_options.state_machine_options.escape) {
67: 		AreOptionsEqual(options.dialect_options.state_machine_options.quote.GetValue(),
68: 		                options.dialect_options.state_machine_options.escape.GetValue(), "QUOTE", "ESCAPE");
69: 	}
70: 
71: 	// delimiter and quote must not be substrings of each other
72: 	AreOptionsEqual(options.dialect_options.state_machine_options.comment.GetValue(),
73: 	                options.dialect_options.state_machine_options.quote.GetValue(), "COMMENT", "QUOTE");
74: 
75: 	// delimiter and quote must not be substrings of each other
76: 	AreOptionsEqual(options.dialect_options.state_machine_options.comment.GetValue(),
77: 	                options.dialect_options.state_machine_options.delimiter.GetValue(), "COMMENT", "DELIMITER");
78: 
79: 	// null string and delimiter must not be substrings of each other
80: 	for (auto &null_str : options.null_str) {
81: 		if (!null_str.empty()) {
82: 			SubstringDetection(options.dialect_options.state_machine_options.delimiter.GetValue(), null_str,
83: 			                   "DELIMITER", "NULL");
84: 
85: 			// quote/escape and nullstr must not be substrings of each other
86: 			SubstringDetection(options.dialect_options.state_machine_options.quote.GetValue(), null_str, "QUOTE",
87: 			                   "NULL");
88: 
89: 			SubstringDetection(options.dialect_options.state_machine_options.escape.GetValue(), null_str, "ESCAPE",
90: 			                   "NULL");
91: 		}
92: 	}
93: 
94: 	if (!options.prefix.empty() || !options.suffix.empty()) {
95: 		if (options.prefix.empty() || options.suffix.empty()) {
96: 			throw BinderException("COPY ... (FORMAT CSV) must have both PREFIX and SUFFIX, or none at all");
97: 		}
98: 		if (options.dialect_options.header.GetValue()) {
99: 			throw BinderException("COPY ... (FORMAT CSV)'s HEADER cannot be combined with PREFIX/SUFFIX");
100: 		}
101: 	}
102: }
103: 
104: string TransformNewLine(string new_line) {
105: 	new_line = StringUtil::Replace(new_line, "\\r", "\r");
106: 	return StringUtil::Replace(new_line, "\\n", "\n");
107: 	;
108: }
109: 
110: static vector<unique_ptr<Expression>> CreateCastExpressions(WriteCSVData &bind_data, ClientContext &context,
111:                                                             const vector<string> &names,
112:                                                             const vector<LogicalType> &sql_types) {
113: 	auto &options = bind_data.options;
114: 	auto &formats = options.write_date_format;
115: 
116: 	bool has_dateformat = !formats[LogicalTypeId::DATE].IsNull();
117: 	bool has_timestampformat = !formats[LogicalTypeId::TIMESTAMP].IsNull();
118: 
119: 	// Create a binder
120: 	auto binder = Binder::CreateBinder(context);
121: 
122: 	auto &bind_context = binder->bind_context;
123: 	auto table_index = binder->GenerateTableIndex();
124: 	bind_context.AddGenericBinding(table_index, "copy_csv", names, sql_types);
125: 
126: 	// Create the ParsedExpressions (cast, strftime, etc..)
127: 	vector<unique_ptr<ParsedExpression>> unbound_expressions;
128: 	for (idx_t i = 0; i < sql_types.size(); i++) {
129: 		auto &type = sql_types[i];
130: 		auto &name = names[i];
131: 
132: 		bool is_timestamp = type.id() == LogicalTypeId::TIMESTAMP || type.id() == LogicalTypeId::TIMESTAMP_TZ;
133: 		if (has_dateformat && type.id() == LogicalTypeId::DATE) {
134: 			// strftime(<name>, 'format')
135: 			vector<unique_ptr<ParsedExpression>> children;
136: 			children.push_back(make_uniq<BoundExpression>(make_uniq<BoundReferenceExpression>(name, type, i)));
137: 			children.push_back(make_uniq<ConstantExpression>(formats[LogicalTypeId::DATE]));
138: 			auto func = make_uniq_base<ParsedExpression, FunctionExpression>("strftime", std::move(children));
139: 			unbound_expressions.push_back(std::move(func));
140: 		} else if (has_timestampformat && is_timestamp) {
141: 			// strftime(<name>, 'format')
142: 			vector<unique_ptr<ParsedExpression>> children;
143: 			children.push_back(make_uniq<BoundExpression>(make_uniq<BoundReferenceExpression>(name, type, i)));
144: 			children.push_back(make_uniq<ConstantExpression>(formats[LogicalTypeId::TIMESTAMP]));
145: 			auto func = make_uniq_base<ParsedExpression, FunctionExpression>("strftime", std::move(children));
146: 			unbound_expressions.push_back(std::move(func));
147: 		} else {
148: 			// CAST <name> AS VARCHAR
149: 			auto column = make_uniq<BoundExpression>(make_uniq<BoundReferenceExpression>(name, type, i));
150: 			auto expr = make_uniq_base<ParsedExpression, CastExpression>(LogicalType::VARCHAR, std::move(column));
151: 			unbound_expressions.push_back(std::move(expr));
152: 		}
153: 	}
154: 
155: 	// Create an ExpressionBinder, bind the Expressions
156: 	vector<unique_ptr<Expression>> expressions;
157: 	ExpressionBinder expression_binder(*binder, context);
158: 	expression_binder.target_type = LogicalType::VARCHAR;
159: 	for (auto &expr : unbound_expressions) {
160: 		expressions.push_back(expression_binder.Bind(expr));
161: 	}
162: 
163: 	return expressions;
164: }
165: 
166: static unique_ptr<FunctionData> WriteCSVBind(ClientContext &context, CopyFunctionBindInput &input,
167:                                              const vector<string> &names, const vector<LogicalType> &sql_types) {
168: 	auto bind_data = make_uniq<WriteCSVData>(input.info.file_path, sql_types, names);
169: 
170: 	// check all the options in the copy info
171: 	for (auto &option : input.info.options) {
172: 		auto loption = StringUtil::Lower(option.first);
173: 		auto &set = option.second;
174: 		bind_data->options.SetWriteOption(loption, ConvertVectorToValue(set));
175: 	}
176: 	// verify the parsed options
177: 	if (bind_data->options.force_quote.empty()) {
178: 		// no FORCE_QUOTE specified: initialize to false
179: 		bind_data->options.force_quote.resize(names.size(), false);
180: 	}
181: 	bind_data->Finalize();
182: 
183: 	switch (bind_data->options.compression) {
184: 	case FileCompressionType::GZIP:
185: 		if (!StringUtil::EndsWith(input.file_extension, ".gz")) {
186: 			input.file_extension += ".gz";
187: 		}
188: 		break;
189: 	case FileCompressionType::ZSTD:
190: 		if (!StringUtil::EndsWith(input.file_extension, ".zst")) {
191: 			input.file_extension += ".zst";
192: 		}
193: 		break;
194: 	default:
195: 		break;
196: 	}
197: 
198: 	auto expressions = CreateCastExpressions(*bind_data, context, names, sql_types);
199: 	bind_data->cast_expressions = std::move(expressions);
200: 
201: 	bind_data->requires_quotes = make_unsafe_uniq_array<bool>(256);
202: 	memset(bind_data->requires_quotes.get(), 0, sizeof(bool) * 256);
203: 	bind_data->requires_quotes['\n'] = true;
204: 	bind_data->requires_quotes['\r'] = true;
205: 	bind_data->requires_quotes[NumericCast<idx_t>(
206: 	    bind_data->options.dialect_options.state_machine_options.delimiter.GetValue())] = true;
207: 	bind_data->requires_quotes[NumericCast<idx_t>(
208: 	    bind_data->options.dialect_options.state_machine_options.quote.GetValue())] = true;
209: 
210: 	if (!bind_data->options.write_newline.empty()) {
211: 		bind_data->newline = TransformNewLine(bind_data->options.write_newline);
212: 	}
213: 	return std::move(bind_data);
214: }
215: 
216: static unique_ptr<FunctionData> ReadCSVBind(ClientContext &context, CopyInfo &info, vector<string> &expected_names,
217:                                             vector<LogicalType> &expected_types) {
218: 	auto bind_data = make_uniq<ReadCSVData>();
219: 	bind_data->csv_types = expected_types;
220: 	bind_data->csv_names = expected_names;
221: 	bind_data->return_types = expected_types;
222: 	bind_data->return_names = expected_names;
223: 
224: 	auto multi_file_reader = MultiFileReader::CreateDefault("CSVCopy");
225: 	bind_data->files = multi_file_reader->CreateFileList(context, Value(info.file_path))->GetAllFiles();
226: 
227: 	auto &options = bind_data->options;
228: 
229: 	// check all the options in the copy info
230: 	for (auto &option : info.options) {
231: 		auto loption = StringUtil::Lower(option.first);
232: 		auto &set = option.second;
233: 		options.SetReadOption(loption, ConvertVectorToValue(set), expected_names);
234: 	}
235: 	// verify the parsed options
236: 	if (options.force_not_null.empty()) {
237: 		// no FORCE_QUOTE specified: initialize to false
238: 		options.force_not_null.resize(expected_types.size(), false);
239: 	}
240: 
241: 	// Look for rejects table options last
242: 	named_parameter_map_t options_map;
243: 	for (auto &option : info.options) {
244: 		options_map[option.first] = ConvertVectorToValue(std::move(option.second));
245: 	}
246: 	options.file_path = bind_data->files[0];
247: 	options.name_list = expected_names;
248: 	options.sql_type_list = expected_types;
249: 	options.columns_set = true;
250: 	for (idx_t i = 0; i < expected_types.size(); i++) {
251: 		options.sql_types_per_column[expected_names[i]] = i;
252: 	}
253: 
254: 	if (options.auto_detect) {
255: 		auto buffer_manager = make_shared_ptr<CSVBufferManager>(context, options, bind_data->files[0], 0);
256: 		CSVSniffer sniffer(options, buffer_manager, CSVStateMachineCache::Get(context));
257: 		sniffer.SniffCSV();
258: 	}
259: 	bind_data->FinalizeRead(context);
260: 
261: 	return std::move(bind_data);
262: }
263: 
264: //===--------------------------------------------------------------------===//
265: // Helper writing functions
266: //===--------------------------------------------------------------------===//
267: static string AddEscapes(char to_be_escaped, const char escape, const string &val) {
268: 	idx_t i = 0;
269: 	string new_val = "";
270: 	idx_t found = val.find(to_be_escaped);
271: 
272: 	while (found != string::npos) {
273: 		while (i < found) {
274: 			new_val += val[i];
275: 			i++;
276: 		}
277: 		if (escape != '\0') {
278: 			new_val += escape;
279: 			found = val.find(to_be_escaped, found + 1);
280: 		}
281: 	}
282: 	while (i < val.length()) {
283: 		new_val += val[i];
284: 		i++;
285: 	}
286: 	return new_val;
287: }
288: 
289: static bool RequiresQuotes(WriteCSVData &csv_data, const char *str, idx_t len) {
290: 	auto &options = csv_data.options;
291: 	// check if the string is equal to the null string
292: 	if (len == options.null_str[0].size() && memcmp(str, options.null_str[0].c_str(), len) == 0) {
293: 		return true;
294: 	}
295: 	auto str_data = reinterpret_cast<const_data_ptr_t>(str);
296: 	for (idx_t i = 0; i < len; i++) {
297: 		if (csv_data.requires_quotes[str_data[i]]) {
298: 			// this byte requires quotes - write a quoted string
299: 			return true;
300: 		}
301: 	}
302: 	// no newline, quote or delimiter in the string
303: 	// no quoting or escaping necessary
304: 	return false;
305: }
306: 
307: static void WriteQuotedString(WriteStream &writer, WriteCSVData &csv_data, const char *str, idx_t len,
308:                               bool force_quote) {
309: 	auto &options = csv_data.options;
310: 	if (!force_quote) {
311: 		// force quote is disabled: check if we need to add quotes anyway
312: 		force_quote = RequiresQuotes(csv_data, str, len);
313: 	}
314: 	if (force_quote) {
315: 		// quoting is enabled: we might need to escape things in the string
316: 		bool requires_escape = false;
317: 		// simple CSV
318: 		// do a single loop to check for a quote or escape value
319: 		for (idx_t i = 0; i < len; i++) {
320: 			if (str[i] == options.dialect_options.state_machine_options.quote.GetValue() ||
321: 			    str[i] == options.dialect_options.state_machine_options.escape.GetValue()) {
322: 				requires_escape = true;
323: 				break;
324: 			}
325: 		}
326: 
327: 		if (!requires_escape) {
328: 			// fast path: no need to escape anything
329: 			WriteQuoteOrEscape(writer, options.dialect_options.state_machine_options.quote.GetValue());
330: 			writer.WriteData(const_data_ptr_cast(str), len);
331: 			WriteQuoteOrEscape(writer, options.dialect_options.state_machine_options.quote.GetValue());
332: 			return;
333: 		}
334: 
335: 		// slow path: need to add escapes
336: 		string new_val(str, len);
337: 		new_val = AddEscapes(options.dialect_options.state_machine_options.escape.GetValue(),
338: 		                     options.dialect_options.state_machine_options.escape.GetValue(), new_val);
339: 		if (options.dialect_options.state_machine_options.escape !=
340: 		    options.dialect_options.state_machine_options.quote) {
341: 			// need to escape quotes separately
342: 			new_val = AddEscapes(options.dialect_options.state_machine_options.quote.GetValue(),
343: 			                     options.dialect_options.state_machine_options.escape.GetValue(), new_val);
344: 		}
345: 		WriteQuoteOrEscape(writer, options.dialect_options.state_machine_options.quote.GetValue());
346: 		writer.WriteData(const_data_ptr_cast(new_val.c_str()), new_val.size());
347: 		WriteQuoteOrEscape(writer, options.dialect_options.state_machine_options.quote.GetValue());
348: 	} else {
349: 		writer.WriteData(const_data_ptr_cast(str), len);
350: 	}
351: }
352: 
353: //===--------------------------------------------------------------------===//
354: // Sink
355: //===--------------------------------------------------------------------===//
356: struct LocalWriteCSVData : public LocalFunctionData {
357: public:
358: 	LocalWriteCSVData(ClientContext &context, vector<unique_ptr<Expression>> &expressions)
359: 	    : executor(context, expressions) {
360: 	}
361: 
362: public:
363: 	//! Used to execute the expressions that transform input -> string
364: 	ExpressionExecutor executor;
365: 	//! The thread-local buffer to write data into
366: 	MemoryStream stream;
367: 	//! A chunk with VARCHAR columns to cast intermediates into
368: 	DataChunk cast_chunk;
369: 	//! If we've written any rows yet, allows us to prevent a trailing comma when writing JSON ARRAY
370: 	bool written_anything = false;
371: };
372: 
373: struct GlobalWriteCSVData : public GlobalFunctionData {
374: 	GlobalWriteCSVData(FileSystem &fs, const string &file_path, FileCompressionType compression)
375: 	    : fs(fs), written_anything(false) {
376: 		handle = fs.OpenFile(file_path, FileFlags::FILE_FLAGS_WRITE | FileFlags::FILE_FLAGS_FILE_CREATE_NEW |
377: 		                                    FileLockType::WRITE_LOCK | compression);
378: 	}
379: 
380: 	//! Write generic data, e.g., CSV header
381: 	void WriteData(const_data_ptr_t data, idx_t size) {
382: 		lock_guard<mutex> flock(lock);
383: 		handle->Write((void *)data, size);
384: 	}
385: 
386: 	void WriteData(const char *data, idx_t size) {
387: 		WriteData(const_data_ptr_cast(data), size);
388: 	}
389: 
390: 	//! Write rows
391: 	void WriteRows(const_data_ptr_t data, idx_t size, const string &newline) {
392: 		lock_guard<mutex> flock(lock);
393: 		if (written_anything) {
394: 			handle->Write((void *)newline.c_str(), newline.length());
395: 		} else {
396: 			written_anything = true;
397: 		}
398: 		handle->Write((void *)data, size);
399: 	}
400: 
401: 	idx_t FileSize() {
402: 		lock_guard<mutex> flock(lock);
403: 		return handle->GetFileSize();
404: 	}
405: 
406: 	FileSystem &fs;
407: 	//! The mutex for writing to the physical file
408: 	mutex lock;
409: 	//! The file handle to write to
410: 	unique_ptr<FileHandle> handle;
411: 	//! If we've written any rows yet, allows us to prevent a trailing comma when writing JSON ARRAY
412: 	bool written_anything;
413: };
414: 
415: static unique_ptr<LocalFunctionData> WriteCSVInitializeLocal(ExecutionContext &context, FunctionData &bind_data) {
416: 	auto &csv_data = bind_data.Cast<WriteCSVData>();
417: 	auto local_data = make_uniq<LocalWriteCSVData>(context.client, csv_data.cast_expressions);
418: 
419: 	// create the chunk with VARCHAR types
420: 	vector<LogicalType> types;
421: 	types.resize(csv_data.options.name_list.size(), LogicalType::VARCHAR);
422: 
423: 	local_data->cast_chunk.Initialize(Allocator::Get(context.client), types);
424: 	return std::move(local_data);
425: }
426: 
427: static unique_ptr<GlobalFunctionData> WriteCSVInitializeGlobal(ClientContext &context, FunctionData &bind_data,
428:                                                                const string &file_path) {
429: 	auto &csv_data = bind_data.Cast<WriteCSVData>();
430: 	auto &options = csv_data.options;
431: 	auto global_data =
432: 	    make_uniq<GlobalWriteCSVData>(FileSystem::GetFileSystem(context), file_path, options.compression);
433: 
434: 	if (!options.prefix.empty()) {
435: 		global_data->WriteData(options.prefix.c_str(), options.prefix.size());
436: 	}
437: 
438: 	if (!(options.dialect_options.header.IsSetByUser() && !options.dialect_options.header.GetValue())) {
439: 		MemoryStream stream;
440: 		// write the header line to the file
441: 		for (idx_t i = 0; i < csv_data.options.name_list.size(); i++) {
442: 			if (i != 0) {
443: 				WriteQuoteOrEscape(stream, options.dialect_options.state_machine_options.delimiter.GetValue());
444: 			}
445: 			WriteQuotedString(stream, csv_data, csv_data.options.name_list[i].c_str(),
446: 			                  csv_data.options.name_list[i].size(), false);
447: 		}
448: 		stream.WriteData(const_data_ptr_cast(csv_data.newline.c_str()), csv_data.newline.size());
449: 
450: 		global_data->WriteData(stream.GetData(), stream.GetPosition());
451: 	}
452: 
453: 	return std::move(global_data);
454: }
455: 
456: static void WriteCSVChunkInternal(ClientContext &context, FunctionData &bind_data, DataChunk &cast_chunk,
457:                                   MemoryStream &writer, DataChunk &input, bool &written_anything,
458:                                   ExpressionExecutor &executor) {
459: 	auto &csv_data = bind_data.Cast<WriteCSVData>();
460: 	auto &options = csv_data.options;
461: 
462: 	// first cast the columns of the chunk to varchar
463: 	cast_chunk.Reset();
464: 	cast_chunk.SetCardinality(input);
465: 
466: 	executor.Execute(input, cast_chunk);
467: 
468: 	cast_chunk.Flatten();
469: 	// now loop over the vectors and output the values
470: 	for (idx_t row_idx = 0; row_idx < cast_chunk.size(); row_idx++) {
471: 		if (row_idx == 0 && !written_anything) {
472: 			written_anything = true;
473: 		} else {
474: 			writer.WriteData(const_data_ptr_cast(csv_data.newline.c_str()), csv_data.newline.size());
475: 		}
476: 		// write values
477: 		D_ASSERT(options.null_str.size() == 1);
478: 		for (idx_t col_idx = 0; col_idx < cast_chunk.ColumnCount(); col_idx++) {
479: 			if (col_idx != 0) {
480: 				WriteQuoteOrEscape(writer, options.dialect_options.state_machine_options.delimiter.GetValue());
481: 			}
482: 			if (FlatVector::IsNull(cast_chunk.data[col_idx], row_idx)) {
483: 				// write null value
484: 				writer.WriteData(const_data_ptr_cast(options.null_str[0].c_str()), options.null_str[0].size());
485: 				continue;
486: 			}
487: 
488: 			// non-null value, fetch the string value from the cast chunk
489: 			auto str_data = FlatVector::GetData<string_t>(cast_chunk.data[col_idx]);
490: 			// FIXME: we could gain some performance here by checking for certain types if they ever require quotes
491: 			// (e.g. integers only require quotes if the delimiter is a number, decimals only require quotes if the
492: 			// delimiter is a number or "." character)
493: 			WriteQuotedString(writer, csv_data, str_data[row_idx].GetData(), str_data[row_idx].GetSize(),
494: 			                  csv_data.options.force_quote[col_idx]);
495: 		}
496: 	}
497: }
498: 
499: static void WriteCSVSink(ExecutionContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,
500:                          LocalFunctionData &lstate, DataChunk &input) {
501: 	auto &csv_data = bind_data.Cast<WriteCSVData>();
502: 	auto &local_data = lstate.Cast<LocalWriteCSVData>();
503: 	auto &global_state = gstate.Cast<GlobalWriteCSVData>();
504: 
505: 	// write data into the local buffer
506: 	WriteCSVChunkInternal(context.client, bind_data, local_data.cast_chunk, local_data.stream, input,
507: 	                      local_data.written_anything, local_data.executor);
508: 
509: 	// check if we should flush what we have currently written
510: 	auto &writer = local_data.stream;
511: 	if (writer.GetPosition() >= csv_data.flush_size) {
512: 		global_state.WriteRows(writer.GetData(), writer.GetPosition(), csv_data.newline);
513: 		writer.Rewind();
514: 		local_data.written_anything = false;
515: 	}
516: }
517: 
518: //===--------------------------------------------------------------------===//
519: // Combine
520: //===--------------------------------------------------------------------===//
521: static void WriteCSVCombine(ExecutionContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,
522:                             LocalFunctionData &lstate) {
523: 	auto &local_data = lstate.Cast<LocalWriteCSVData>();
524: 	auto &global_state = gstate.Cast<GlobalWriteCSVData>();
525: 	auto &csv_data = bind_data.Cast<WriteCSVData>();
526: 	auto &writer = local_data.stream;
527: 	// flush the local writer
528: 	if (local_data.written_anything) {
529: 		global_state.WriteRows(writer.GetData(), writer.GetPosition(), csv_data.newline);
530: 		writer.Rewind();
531: 	}
532: }
533: 
534: //===--------------------------------------------------------------------===//
535: // Finalize
536: //===--------------------------------------------------------------------===//
537: void WriteCSVFinalize(ClientContext &context, FunctionData &bind_data, GlobalFunctionData &gstate) {
538: 	auto &global_state = gstate.Cast<GlobalWriteCSVData>();
539: 	auto &csv_data = bind_data.Cast<WriteCSVData>();
540: 	auto &options = csv_data.options;
541: 
542: 	MemoryStream stream;
543: 	if (!options.suffix.empty()) {
544: 		stream.WriteData(const_data_ptr_cast(options.suffix.c_str()), options.suffix.size());
545: 	} else if (global_state.written_anything) {
546: 		stream.WriteData(const_data_ptr_cast(csv_data.newline.c_str()), csv_data.newline.size());
547: 	}
548: 	global_state.WriteData(stream.GetData(), stream.GetPosition());
549: 
550: 	global_state.handle->Close();
551: 	global_state.handle.reset();
552: }
553: 
554: //===--------------------------------------------------------------------===//
555: // Execution Mode
556: //===--------------------------------------------------------------------===//
557: CopyFunctionExecutionMode WriteCSVExecutionMode(bool preserve_insertion_order, bool supports_batch_index) {
558: 	if (!preserve_insertion_order) {
559: 		return CopyFunctionExecutionMode::PARALLEL_COPY_TO_FILE;
560: 	}
561: 	if (supports_batch_index) {
562: 		return CopyFunctionExecutionMode::BATCH_COPY_TO_FILE;
563: 	}
564: 	return CopyFunctionExecutionMode::REGULAR_COPY_TO_FILE;
565: }
566: //===--------------------------------------------------------------------===//
567: // Prepare Batch
568: //===--------------------------------------------------------------------===//
569: struct WriteCSVBatchData : public PreparedBatchData {
570: 	//! The thread-local buffer to write data into
571: 	MemoryStream stream;
572: };
573: 
574: unique_ptr<PreparedBatchData> WriteCSVPrepareBatch(ClientContext &context, FunctionData &bind_data,
575:                                                    GlobalFunctionData &gstate,
576:                                                    unique_ptr<ColumnDataCollection> collection) {
577: 	auto &csv_data = bind_data.Cast<WriteCSVData>();
578: 
579: 	// create the cast chunk with VARCHAR types
580: 	vector<LogicalType> types;
581: 	types.resize(csv_data.options.name_list.size(), LogicalType::VARCHAR);
582: 	DataChunk cast_chunk;
583: 	cast_chunk.Initialize(Allocator::Get(context), types);
584: 
585: 	auto &original_types = collection->Types();
586: 	auto expressions = CreateCastExpressions(csv_data, context, csv_data.options.name_list, original_types);
587: 	ExpressionExecutor executor(context, expressions);
588: 
589: 	// write CSV chunks to the batch data
590: 	bool written_anything = false;
591: 	auto batch = make_uniq<WriteCSVBatchData>();
592: 	for (auto &chunk : collection->Chunks()) {
593: 		WriteCSVChunkInternal(context, bind_data, cast_chunk, batch->stream, chunk, written_anything, executor);
594: 	}
595: 	return std::move(batch);
596: }
597: 
598: //===--------------------------------------------------------------------===//
599: // Flush Batch
600: //===--------------------------------------------------------------------===//
601: void WriteCSVFlushBatch(ClientContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,
602:                         PreparedBatchData &batch) {
603: 	auto &csv_batch = batch.Cast<WriteCSVBatchData>();
604: 	auto &global_state = gstate.Cast<GlobalWriteCSVData>();
605: 	auto &csv_data = bind_data.Cast<WriteCSVData>();
606: 	auto &writer = csv_batch.stream;
607: 	global_state.WriteRows(writer.GetData(), writer.GetPosition(), csv_data.newline);
608: 	writer.Rewind();
609: }
610: 
611: //===--------------------------------------------------------------------===//
612: // File rotation
613: //===--------------------------------------------------------------------===//
614: bool WriteCSVRotateFiles(FunctionData &, const optional_idx &file_size_bytes) {
615: 	return file_size_bytes.IsValid();
616: }
617: 
618: bool WriteCSVRotateNextFile(GlobalFunctionData &gstate, FunctionData &, const optional_idx &file_size_bytes) {
619: 	auto &global_state = gstate.Cast<GlobalWriteCSVData>();
620: 	return global_state.FileSize() > file_size_bytes.GetIndex();
621: }
622: 
623: void CSVCopyFunction::RegisterFunction(BuiltinFunctions &set) {
624: 	CopyFunction info("csv");
625: 	info.copy_to_bind = WriteCSVBind;
626: 	info.copy_to_initialize_local = WriteCSVInitializeLocal;
627: 	info.copy_to_initialize_global = WriteCSVInitializeGlobal;
628: 	info.copy_to_sink = WriteCSVSink;
629: 	info.copy_to_combine = WriteCSVCombine;
630: 	info.copy_to_finalize = WriteCSVFinalize;
631: 	info.execution_mode = WriteCSVExecutionMode;
632: 	info.prepare_batch = WriteCSVPrepareBatch;
633: 	info.flush_batch = WriteCSVFlushBatch;
634: 	info.rotate_files = WriteCSVRotateFiles;
635: 	info.rotate_next_file = WriteCSVRotateNextFile;
636: 
637: 	info.copy_from_bind = ReadCSVBind;
638: 	info.copy_from_function = ReadCSVTableFunction::GetFunction();
639: 
640: 	info.extension = "csv";
641: 
642: 	set.AddFunction(info);
643: }
644: 
645: } // namespace duckdb
[end of src/function/table/copy_csv.cpp]
[start of src/function/table/read_csv.cpp]
1: #include "duckdb/function/table/read_csv.hpp"
2: 
3: #include "duckdb/common/enum_util.hpp"
4: #include "duckdb/common/multi_file_reader.hpp"
5: #include "duckdb/common/serializer/deserializer.hpp"
6: #include "duckdb/common/serializer/serializer.hpp"
7: #include "duckdb/common/string_util.hpp"
8: #include "duckdb/common/union_by_name.hpp"
9: #include "duckdb/execution/operator/csv_scanner/global_csv_state.hpp"
10: #include "duckdb/execution/operator/csv_scanner/csv_error.hpp"
11: #include "duckdb/execution/operator/csv_scanner/csv_sniffer.hpp"
12: #include "duckdb/execution/operator/persistent/csv_rejects_table.hpp"
13: #include "duckdb/function/function_set.hpp"
14: #include "duckdb/main/client_context.hpp"
15: #include "duckdb/main/client_data.hpp"
16: #include "duckdb/main/config.hpp"
17: #include "duckdb/main/database.hpp"
18: #include "duckdb/main/extension_helper.hpp"
19: #include "duckdb/parser/expression/constant_expression.hpp"
20: #include "duckdb/parser/expression/function_expression.hpp"
21: #include "duckdb/parser/tableref/table_function_ref.hpp"
22: #include "duckdb/planner/operator/logical_get.hpp"
23: #include "duckdb/execution/operator/csv_scanner/csv_file_scanner.hpp"
24: #include "duckdb/execution/operator/csv_scanner/base_scanner.hpp"
25: 
26: #include "duckdb/execution/operator/csv_scanner/string_value_scanner.hpp"
27: 
28: #include <limits>
29: 
30: namespace duckdb {
31: 
32: unique_ptr<CSVFileHandle> ReadCSV::OpenCSV(const string &file_path, FileCompressionType compression,
33:                                            ClientContext &context) {
34: 	auto &fs = FileSystem::GetFileSystem(context);
35: 	auto &allocator = BufferAllocator::Get(context);
36: 	return CSVFileHandle::OpenFile(fs, allocator, file_path, compression);
37: }
38: 
39: ReadCSVData::ReadCSVData() {
40: }
41: 
42: void ReadCSVData::FinalizeRead(ClientContext &context) {
43: 	BaseCSVData::Finalize();
44: }
45: 
46: static unique_ptr<FunctionData> ReadCSVBind(ClientContext &context, TableFunctionBindInput &input,
47:                                             vector<LogicalType> &return_types, vector<string> &names) {
48: 
49: 	auto result = make_uniq<ReadCSVData>();
50: 	auto &options = result->options;
51: 	auto multi_file_reader = MultiFileReader::Create(input.table_function);
52: 	auto multi_file_list = multi_file_reader->CreateFileList(context, input.inputs[0]);
53: 
54: 	options.FromNamedParameters(input.named_parameters, context);
55: 	if (options.rejects_table_name.IsSetByUser() && !options.store_rejects.GetValue() &&
56: 	    options.store_rejects.IsSetByUser()) {
57: 		throw BinderException("REJECTS_TABLE option is only supported when store_rejects is not manually set to false");
58: 	}
59: 	if (options.rejects_scan_name.IsSetByUser() && !options.store_rejects.GetValue() &&
60: 	    options.store_rejects.IsSetByUser()) {
61: 		throw BinderException("REJECTS_SCAN option is only supported when store_rejects is not manually set to false");
62: 	}
63: 	if (options.rejects_scan_name.IsSetByUser() || options.rejects_table_name.IsSetByUser()) {
64: 		// Ensure we set store_rejects to true automagically
65: 		options.store_rejects.Set(true, false);
66: 	}
67: 	// Validate rejects_table options
68: 	if (options.store_rejects.GetValue()) {
69: 		if (!options.ignore_errors.GetValue() && options.ignore_errors.IsSetByUser()) {
70: 			throw BinderException(
71: 			    "STORE_REJECTS option is only supported when IGNORE_ERRORS is not manually set to false");
72: 		}
73: 		// Ensure we set ignore errors to true automagically
74: 		options.ignore_errors.Set(true, false);
75: 		if (options.file_options.union_by_name) {
76: 			throw BinderException("REJECTS_TABLE option is not supported when UNION_BY_NAME is set to true");
77: 		}
78: 	}
79: 	if (options.rejects_limit != 0 && !options.store_rejects.GetValue()) {
80: 		throw BinderException("REJECTS_LIMIT option is only supported when REJECTS_TABLE is set to a table name");
81: 	}
82: 
83: 	options.file_options.AutoDetectHivePartitioning(*multi_file_list, context);
84: 
85: 	if (!options.auto_detect) {
86: 		if (!options.columns_set) {
87: 			throw BinderException("read_csv requires columns to be specified through the 'columns' option. Use "
88: 			                      "read_csv_auto or set read_csv(..., "
89: 			                      "AUTO_DETECT=TRUE) to automatically guess columns.");
90: 		} else {
91: 			names = options.name_list;
92: 			return_types = options.sql_type_list;
93: 		}
94: 	}
95: 	if (options.auto_detect && !options.file_options.union_by_name) {
96: 		options.file_path = multi_file_list->GetFirstFile();
97: 		result->buffer_manager = make_shared_ptr<CSVBufferManager>(context, options, options.file_path, 0);
98: 		CSVSniffer sniffer(options, result->buffer_manager, CSVStateMachineCache::Get(context));
99: 		auto sniffer_result = sniffer.SniffCSV();
100: 		if (names.empty()) {
101: 			names = sniffer_result.names;
102: 			return_types = sniffer_result.return_types;
103: 		}
104: 		result->csv_types = return_types;
105: 		result->csv_names = names;
106: 	}
107: 
108: 	D_ASSERT(return_types.size() == names.size());
109: 	result->options.dialect_options.num_cols = names.size();
110: 	if (options.file_options.union_by_name) {
111: 		result->reader_bind = multi_file_reader->BindUnionReader<CSVFileScan>(context, return_types, names,
112: 		                                                                      *multi_file_list, *result, options);
113: 		if (result->union_readers.size() > 1) {
114: 			for (idx_t i = 0; i < result->union_readers.size(); i++) {
115: 				result->column_info.emplace_back(result->union_readers[i]->names, result->union_readers[i]->types);
116: 			}
117: 		}
118: 		if (!options.sql_types_per_column.empty()) {
119: 			auto exception = CSVError::ColumnTypesError(options.sql_types_per_column, names);
120: 			if (!exception.error_message.empty()) {
121: 				throw BinderException(exception.error_message);
122: 			}
123: 			for (idx_t i = 0; i < names.size(); i++) {
124: 				auto it = options.sql_types_per_column.find(names[i]);
125: 				if (it != options.sql_types_per_column.end()) {
126: 					return_types[i] = options.sql_type_list[it->second];
127: 				}
128: 			}
129: 		}
130: 		result->csv_types = return_types;
131: 		result->csv_names = names;
132: 	} else {
133: 		result->csv_types = return_types;
134: 		result->csv_names = names;
135: 		multi_file_reader->BindOptions(options.file_options, *multi_file_list, return_types, names,
136: 		                               result->reader_bind);
137: 	}
138: 	result->return_types = return_types;
139: 	result->return_names = names;
140: 	if (!options.force_not_null_names.empty()) {
141: 		// Lets first check all column names match
142: 		duckdb::unordered_set<string> column_names;
143: 		for (auto &name : names) {
144: 			column_names.insert(name);
145: 		}
146: 		for (auto &force_name : options.force_not_null_names) {
147: 			if (column_names.find(force_name) == column_names.end()) {
148: 				throw BinderException("\"force_not_null\" expected to find %s, but it was not found in the table",
149: 				                      force_name);
150: 			}
151: 		}
152: 		D_ASSERT(options.force_not_null.empty());
153: 		for (idx_t i = 0; i < names.size(); i++) {
154: 			if (options.force_not_null_names.find(names[i]) != options.force_not_null_names.end()) {
155: 				options.force_not_null.push_back(true);
156: 			} else {
157: 				options.force_not_null.push_back(false);
158: 			}
159: 		}
160: 	}
161: 
162: 	// TODO: make the CSV reader use MultiFileList throughout, instead of converting to vector<string>
163: 	result->files = multi_file_list->GetAllFiles();
164: 
165: 	result->Finalize();
166: 	return std::move(result);
167: }
168: 
169: //===--------------------------------------------------------------------===//
170: // Read CSV Local State
171: //===--------------------------------------------------------------------===//
172: struct CSVLocalState : public LocalTableFunctionState {
173: public:
174: 	explicit CSVLocalState(unique_ptr<StringValueScanner> csv_reader_p) : csv_reader(std::move(csv_reader_p)) {
175: 	}
176: 
177: 	//! The CSV reader
178: 	unique_ptr<StringValueScanner> csv_reader;
179: 	bool done = false;
180: };
181: 
182: //===--------------------------------------------------------------------===//
183: // Read CSV Functions
184: //===--------------------------------------------------------------------===//
185: static unique_ptr<GlobalTableFunctionState> ReadCSVInitGlobal(ClientContext &context, TableFunctionInitInput &input) {
186: 	auto &bind_data = input.bind_data->Cast<ReadCSVData>();
187: 
188: 	// Create the temporary rejects table
189: 	if (bind_data.options.store_rejects.GetValue()) {
190: 		CSVRejectsTable::GetOrCreate(context, bind_data.options.rejects_scan_name.GetValue(),
191: 		                             bind_data.options.rejects_table_name.GetValue())
192: 		    ->InitializeTable(context, bind_data);
193: 	}
194: 	if (bind_data.files.empty()) {
195: 		// This can happen when a filename based filter pushdown has eliminated all possible files for this scan.
196: 		return nullptr;
197: 	}
198: 	return make_uniq<CSVGlobalState>(context, bind_data.buffer_manager, bind_data.options,
199: 	                                 context.db->NumberOfThreads(), bind_data.files, input.column_ids, bind_data);
200: }
201: 
202: unique_ptr<LocalTableFunctionState> ReadCSVInitLocal(ExecutionContext &context, TableFunctionInitInput &input,
203:                                                      GlobalTableFunctionState *global_state_p) {
204: 	if (!global_state_p) {
205: 		return nullptr;
206: 	}
207: 	auto &global_state = global_state_p->Cast<CSVGlobalState>();
208: 	if (global_state.current_boundary.done) {
209: 		// nothing to do
210: 		return nullptr;
211: 	}
212: 	auto csv_scanner = global_state.Next(nullptr);
213: 	if (!csv_scanner) {
214: 		global_state.DecrementThread();
215: 	}
216: 	return make_uniq<CSVLocalState>(std::move(csv_scanner));
217: }
218: 
219: static void ReadCSVFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &output) {
220: 	auto &bind_data = data_p.bind_data->Cast<ReadCSVData>();
221: 	if (!data_p.global_state) {
222: 		return;
223: 	}
224: 	auto &csv_global_state = data_p.global_state->Cast<CSVGlobalState>();
225: 	if (!data_p.local_state) {
226: 		return;
227: 	}
228: 	auto &csv_local_state = data_p.local_state->Cast<CSVLocalState>();
229: 
230: 	if (!csv_local_state.csv_reader) {
231: 		// no csv_reader was set, this can happen when a filename-based filter has filtered out all possible files
232: 		return;
233: 	}
234: 	do {
235: 		if (output.size() != 0) {
236: 			MultiFileReader().FinalizeChunk(context, bind_data.reader_bind,
237: 			                                csv_local_state.csv_reader->csv_file_scan->reader_data, output, nullptr);
238: 			break;
239: 		}
240: 		if (csv_local_state.csv_reader->FinishedIterator()) {
241: 			csv_local_state.csv_reader = csv_global_state.Next(csv_local_state.csv_reader.get());
242: 			if (!csv_local_state.csv_reader) {
243: 				csv_global_state.DecrementThread();
244: 				break;
245: 			}
246: 		}
247: 		csv_local_state.csv_reader->Flush(output);
248: 
249: 	} while (true);
250: }
251: 
252: static idx_t CSVReaderGetBatchIndex(ClientContext &context, const FunctionData *bind_data_p,
253:                                     LocalTableFunctionState *local_state, GlobalTableFunctionState *global_state) {
254: 	auto &data = local_state->Cast<CSVLocalState>();
255: 	return data.csv_reader->scanner_idx;
256: }
257: 
258: void ReadCSVTableFunction::ReadCSVAddNamedParameters(TableFunction &table_function) {
259: 	table_function.named_parameters["sep"] = LogicalType::VARCHAR;
260: 	table_function.named_parameters["delim"] = LogicalType::VARCHAR;
261: 	table_function.named_parameters["quote"] = LogicalType::VARCHAR;
262: 	table_function.named_parameters["new_line"] = LogicalType::VARCHAR;
263: 	table_function.named_parameters["escape"] = LogicalType::VARCHAR;
264: 	table_function.named_parameters["nullstr"] = LogicalType::ANY;
265: 	table_function.named_parameters["columns"] = LogicalType::ANY;
266: 	table_function.named_parameters["auto_type_candidates"] = LogicalType::ANY;
267: 	table_function.named_parameters["header"] = LogicalType::BOOLEAN;
268: 	table_function.named_parameters["auto_detect"] = LogicalType::BOOLEAN;
269: 	table_function.named_parameters["sample_size"] = LogicalType::BIGINT;
270: 	table_function.named_parameters["all_varchar"] = LogicalType::BOOLEAN;
271: 	table_function.named_parameters["dateformat"] = LogicalType::VARCHAR;
272: 	table_function.named_parameters["timestampformat"] = LogicalType::VARCHAR;
273: 	table_function.named_parameters["normalize_names"] = LogicalType::BOOLEAN;
274: 	table_function.named_parameters["compression"] = LogicalType::VARCHAR;
275: 	table_function.named_parameters["skip"] = LogicalType::BIGINT;
276: 	table_function.named_parameters["max_line_size"] = LogicalType::VARCHAR;
277: 	table_function.named_parameters["maximum_line_size"] = LogicalType::VARCHAR;
278: 	table_function.named_parameters["ignore_errors"] = LogicalType::BOOLEAN;
279: 	table_function.named_parameters["store_rejects"] = LogicalType::BOOLEAN;
280: 	table_function.named_parameters["rejects_table"] = LogicalType::VARCHAR;
281: 	table_function.named_parameters["rejects_scan"] = LogicalType::VARCHAR;
282: 	table_function.named_parameters["rejects_limit"] = LogicalType::BIGINT;
283: 	table_function.named_parameters["force_not_null"] = LogicalType::LIST(LogicalType::VARCHAR);
284: 	table_function.named_parameters["buffer_size"] = LogicalType::UBIGINT;
285: 	table_function.named_parameters["decimal_separator"] = LogicalType::VARCHAR;
286: 	table_function.named_parameters["parallel"] = LogicalType::BOOLEAN;
287: 	table_function.named_parameters["null_padding"] = LogicalType::BOOLEAN;
288: 	table_function.named_parameters["allow_quoted_nulls"] = LogicalType::BOOLEAN;
289: 	table_function.named_parameters["column_types"] = LogicalType::ANY;
290: 	table_function.named_parameters["dtypes"] = LogicalType::ANY;
291: 	table_function.named_parameters["types"] = LogicalType::ANY;
292: 	table_function.named_parameters["names"] = LogicalType::LIST(LogicalType::VARCHAR);
293: 	table_function.named_parameters["column_names"] = LogicalType::LIST(LogicalType::VARCHAR);
294: 	table_function.named_parameters["parallel"] = LogicalType::BOOLEAN;
295: 	table_function.named_parameters["comment"] = LogicalType::VARCHAR;
296: 
297: 	MultiFileReader::AddParameters(table_function);
298: }
299: 
300: double CSVReaderProgress(ClientContext &context, const FunctionData *bind_data_p,
301:                          const GlobalTableFunctionState *global_state) {
302: 	if (!global_state) {
303: 		return 0;
304: 	}
305: 	auto &bind_data = bind_data_p->Cast<ReadCSVData>();
306: 	auto &data = global_state->Cast<CSVGlobalState>();
307: 	return data.GetProgress(bind_data);
308: }
309: 
310: void CSVComplexFilterPushdown(ClientContext &context, LogicalGet &get, FunctionData *bind_data_p,
311:                               vector<unique_ptr<Expression>> &filters) {
312: 	auto &data = bind_data_p->Cast<ReadCSVData>();
313: 	SimpleMultiFileList file_list(data.files);
314: 	MultiFilePushdownInfo info(get);
315: 	auto filtered_list =
316: 	    MultiFileReader().ComplexFilterPushdown(context, file_list, data.options.file_options, info, filters);
317: 	if (filtered_list) {
318: 		data.files = filtered_list->GetAllFiles();
319: 		MultiFileReader::PruneReaders(data, file_list);
320: 	} else {
321: 		data.files = file_list.GetAllFiles();
322: 	}
323: }
324: 
325: unique_ptr<NodeStatistics> CSVReaderCardinality(ClientContext &context, const FunctionData *bind_data_p) {
326: 	auto &bind_data = bind_data_p->Cast<ReadCSVData>();
327: 	idx_t per_file_cardinality = 0;
328: 	if (bind_data.buffer_manager && bind_data.buffer_manager->file_handle) {
329: 		auto estimated_row_width = (bind_data.csv_types.size() * 5);
330: 		per_file_cardinality = bind_data.buffer_manager->file_handle->FileSize() / estimated_row_width;
331: 	} else {
332: 		// determined through the scientific method as the average amount of rows in a CSV file
333: 		per_file_cardinality = 42;
334: 	}
335: 	return make_uniq<NodeStatistics>(bind_data.files.size() * per_file_cardinality);
336: }
337: 
338: static void CSVReaderSerialize(Serializer &serializer, const optional_ptr<FunctionData> bind_data_p,
339:                                const TableFunction &function) {
340: 	auto &bind_data = bind_data_p->Cast<ReadCSVData>();
341: 	serializer.WriteProperty(100, "extra_info", function.extra_info);
342: 	serializer.WriteProperty(101, "csv_data", &bind_data);
343: }
344: 
345: static unique_ptr<FunctionData> CSVReaderDeserialize(Deserializer &deserializer, TableFunction &function) {
346: 	unique_ptr<ReadCSVData> result;
347: 	deserializer.ReadProperty(100, "extra_info", function.extra_info);
348: 	deserializer.ReadProperty(101, "csv_data", result);
349: 	return std::move(result);
350: }
351: 
352: void PushdownTypeToCSVScanner(ClientContext &context, optional_ptr<FunctionData> bind_data,
353:                               const unordered_map<idx_t, LogicalType> &new_column_types) {
354: 	auto &csv_bind = bind_data->Cast<ReadCSVData>();
355: 	for (auto &type : new_column_types) {
356: 		csv_bind.csv_types[type.first] = type.second;
357: 		csv_bind.return_types[type.first] = type.second;
358: 	}
359: }
360: 
361: TableFunction ReadCSVTableFunction::GetFunction() {
362: 	TableFunction read_csv("read_csv", {LogicalType::VARCHAR}, ReadCSVFunction, ReadCSVBind, ReadCSVInitGlobal,
363: 	                       ReadCSVInitLocal);
364: 	read_csv.table_scan_progress = CSVReaderProgress;
365: 	read_csv.pushdown_complex_filter = CSVComplexFilterPushdown;
366: 	read_csv.serialize = CSVReaderSerialize;
367: 	read_csv.deserialize = CSVReaderDeserialize;
368: 	read_csv.get_batch_index = CSVReaderGetBatchIndex;
369: 	read_csv.cardinality = CSVReaderCardinality;
370: 	read_csv.projection_pushdown = true;
371: 	read_csv.type_pushdown = PushdownTypeToCSVScanner;
372: 	ReadCSVAddNamedParameters(read_csv);
373: 	return read_csv;
374: }
375: 
376: TableFunction ReadCSVTableFunction::GetAutoFunction() {
377: 	auto read_csv_auto = ReadCSVTableFunction::GetFunction();
378: 	read_csv_auto.name = "read_csv_auto";
379: 	read_csv_auto.bind = ReadCSVBind;
380: 	return read_csv_auto;
381: }
382: 
383: void ReadCSVTableFunction::RegisterFunction(BuiltinFunctions &set) {
384: 	set.AddFunction(MultiFileReader::CreateFunctionSet(ReadCSVTableFunction::GetFunction()));
385: 	set.AddFunction(MultiFileReader::CreateFunctionSet(ReadCSVTableFunction::GetAutoFunction()));
386: }
387: 
388: unique_ptr<TableRef> ReadCSVReplacement(ClientContext &context, ReplacementScanInput &input,
389:                                         optional_ptr<ReplacementScanData> data) {
390: 	auto table_name = ReplacementScan::GetFullPath(input);
391: 	auto lower_name = StringUtil::Lower(table_name);
392: 	// remove any compression
393: 	if (StringUtil::EndsWith(lower_name, ".gz")) {
394: 		lower_name = lower_name.substr(0, lower_name.size() - 3);
395: 	} else if (StringUtil::EndsWith(lower_name, ".zst")) {
396: 		if (!Catalog::TryAutoLoad(context, "parquet")) {
397: 			throw MissingExtensionException("parquet extension is required for reading zst compressed file");
398: 		}
399: 		lower_name = lower_name.substr(0, lower_name.size() - 4);
400: 	}
401: 	if (!StringUtil::EndsWith(lower_name, ".csv") && !StringUtil::Contains(lower_name, ".csv?") &&
402: 	    !StringUtil::EndsWith(lower_name, ".tsv") && !StringUtil::Contains(lower_name, ".tsv?")) {
403: 		return nullptr;
404: 	}
405: 	auto table_function = make_uniq<TableFunctionRef>();
406: 	vector<unique_ptr<ParsedExpression>> children;
407: 	children.push_back(make_uniq<ConstantExpression>(Value(table_name)));
408: 	table_function->function = make_uniq<FunctionExpression>("read_csv_auto", std::move(children));
409: 
410: 	if (!FileSystem::HasGlob(table_name)) {
411: 		auto &fs = FileSystem::GetFileSystem(context);
412: 		table_function->alias = fs.ExtractBaseName(table_name);
413: 	}
414: 
415: 	return std::move(table_function);
416: }
417: 
418: void BuiltinFunctions::RegisterReadFunctions() {
419: 	CSVCopyFunction::RegisterFunction(*this);
420: 	ReadCSVTableFunction::RegisterFunction(*this);
421: 	auto &config = DBConfig::GetConfig(*transaction.db);
422: 	config.replacement_scans.emplace_back(ReadCSVReplacement);
423: }
424: 
425: } // namespace duckdb
[end of src/function/table/read_csv.cpp]
[start of src/function/table/sniff_csv.cpp]
1: #include "duckdb/function/built_in_functions.hpp"
2: #include "duckdb/execution/operator/csv_scanner/csv_reader_options.hpp"
3: #include "duckdb/common/types/data_chunk.hpp"
4: #include "duckdb/execution/operator/csv_scanner/csv_sniffer.hpp"
5: #include "duckdb/execution/operator/csv_scanner/csv_buffer_manager.hpp"
6: #include "duckdb/function/table_function.hpp"
7: #include "duckdb/main/client_context.hpp"
8: #include "duckdb/function/table/range.hpp"
9: #include "duckdb/execution/operator/csv_scanner/csv_file_handle.hpp"
10: #include "duckdb/function/table/read_csv.hpp"
11: 
12: namespace duckdb {
13: 
14: struct CSVSniffFunctionData : public TableFunctionData {
15: 	CSVSniffFunctionData() {
16: 	}
17: 	string path;
18: 	// The CSV reader options
19: 	CSVReaderOptions options;
20: 	// Return Types of CSV (If given by the user)
21: 	vector<LogicalType> return_types_csv;
22: 	// Column Names of CSV (If given by the user)
23: 	vector<string> names_csv;
24: };
25: 
26: struct CSVSniffGlobalState : public GlobalTableFunctionState {
27: 	CSVSniffGlobalState() {
28: 	}
29: 	bool done = false;
30: };
31: 
32: static unique_ptr<GlobalTableFunctionState> CSVSniffInitGlobal(ClientContext &context, TableFunctionInitInput &input) {
33: 	return make_uniq<CSVSniffGlobalState>();
34: }
35: 
36: static unique_ptr<FunctionData> CSVSniffBind(ClientContext &context, TableFunctionBindInput &input,
37:                                              vector<LogicalType> &return_types, vector<string> &names) {
38: 	auto result = make_uniq<CSVSniffFunctionData>();
39: 	auto &config = DBConfig::GetConfig(context);
40: 	if (!config.options.enable_external_access) {
41: 		throw PermissionException("sniff_csv is disabled through configuration");
42: 	}
43: 	result->path = input.inputs[0].ToString();
44: 	auto it = input.named_parameters.find("auto_detect");
45: 	if (it != input.named_parameters.end()) {
46: 		if (!it->second.GetValue<bool>()) {
47: 			throw InvalidInputException("sniff_csv function does not accept auto_detect variable set to false");
48: 		}
49: 		// otherwise remove it
50: 		input.named_parameters.erase("auto_detect");
51: 	}
52: 	result->options.FromNamedParameters(input.named_parameters, context);
53: 	// We want to return the whole CSV Configuration
54: 	// 1. Delimiter
55: 	return_types.emplace_back(LogicalType::VARCHAR);
56: 	names.emplace_back("Delimiter");
57: 	// 2. Quote
58: 	return_types.emplace_back(LogicalType::VARCHAR);
59: 	names.emplace_back("Quote");
60: 	// 3. Escape
61: 	return_types.emplace_back(LogicalType::VARCHAR);
62: 	names.emplace_back("Escape");
63: 	// 4. NewLine Delimiter
64: 	return_types.emplace_back(LogicalType::VARCHAR);
65: 	names.emplace_back("NewLineDelimiter");
66: 	// 5. Comment
67: 	return_types.emplace_back(LogicalType::VARCHAR);
68: 	names.emplace_back("Comment");
69: 	// 6. Skip Rows
70: 	return_types.emplace_back(LogicalType::UINTEGER);
71: 	names.emplace_back("SkipRows");
72: 	// 7. Has Header
73: 	return_types.emplace_back(LogicalType::BOOLEAN);
74: 	names.emplace_back("HasHeader");
75: 	// 8. List<Struct<Column-Name:Types>>
76: 	child_list_t<LogicalType> struct_children {{"name", LogicalType::VARCHAR}, {"type", LogicalType::VARCHAR}};
77: 	auto list_child = LogicalType::STRUCT(struct_children);
78: 	return_types.emplace_back(LogicalType::LIST(list_child));
79: 	names.emplace_back("Columns");
80: 	// 9. Date Format
81: 	return_types.emplace_back(LogicalType::VARCHAR);
82: 	names.emplace_back("DateFormat");
83: 	// 10. Timestamp Format
84: 	return_types.emplace_back(LogicalType::VARCHAR);
85: 	names.emplace_back("TimestampFormat");
86: 	// 11. CSV read function with all the options used
87: 	return_types.emplace_back(LogicalType::VARCHAR);
88: 	names.emplace_back("UserArguments");
89: 	// 12. CSV read function with all the options used
90: 	return_types.emplace_back(LogicalType::VARCHAR);
91: 	names.emplace_back("Prompt");
92: 	return std::move(result);
93: }
94: 
95: string FormatOptions(char opt) {
96: 	if (opt == '\'') {
97: 		return "''";
98: 	}
99: 	string result;
100: 	result += opt;
101: 	return result;
102: }
103: 
104: static void CSVSniffFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &output) {
105: 	auto &global_state = data_p.global_state->Cast<CSVSniffGlobalState>();
106: 	// Are we done?
107: 	if (global_state.done) {
108: 		return;
109: 	}
110: 	const CSVSniffFunctionData &data = data_p.bind_data->Cast<CSVSniffFunctionData>();
111: 	auto &fs = duckdb::FileSystem::GetFileSystem(context);
112: 
113: 	if (data.path.rfind("http://", 0) != 0 && data.path.rfind("https://", 0) != 0 && fs.HasGlob(data.path)) {
114: 		throw NotImplementedException("sniff_csv does not operate on globs yet");
115: 	}
116: 
117: 	// We must run the sniffer.
118: 	auto sniffer_options = data.options;
119: 	sniffer_options.file_path = data.path;
120: 
121: 	auto buffer_manager = make_shared_ptr<CSVBufferManager>(context, sniffer_options, sniffer_options.file_path, 0);
122: 	if (sniffer_options.name_list.empty()) {
123: 		sniffer_options.name_list = data.names_csv;
124: 	}
125: 	if (sniffer_options.sql_type_list.empty()) {
126: 		sniffer_options.sql_type_list = data.return_types_csv;
127: 	}
128: 	CSVSniffer sniffer(sniffer_options, buffer_manager, CSVStateMachineCache::Get(context));
129: 	auto sniffer_result = sniffer.SniffCSV(true);
130: 	string str_opt;
131: 	string separator = ", ";
132: 	// Set output
133: 	output.SetCardinality(1);
134: 
135: 	// 1. Delimiter
136: 	str_opt = sniffer_options.dialect_options.state_machine_options.delimiter.GetValue();
137: 	output.SetValue(0, 0, str_opt);
138: 	// 2. Quote
139: 	str_opt = sniffer_options.dialect_options.state_machine_options.quote.GetValue();
140: 	output.SetValue(1, 0, str_opt);
141: 	// 3. Escape
142: 	str_opt = sniffer_options.dialect_options.state_machine_options.escape.GetValue();
143: 	output.SetValue(2, 0, str_opt);
144: 	// 4. NewLine Delimiter
145: 	auto new_line_identifier = sniffer_options.NewLineIdentifierToString();
146: 	output.SetValue(3, 0, new_line_identifier);
147: 	// 5. Comment
148: 	str_opt = sniffer_options.dialect_options.state_machine_options.comment.GetValue();
149: 	output.SetValue(4, 0, str_opt);
150: 	// 6. Skip Rows
151: 	output.SetValue(5, 0, Value::UINTEGER(NumericCast<uint32_t>(sniffer_options.dialect_options.skip_rows.GetValue())));
152: 	// 7. Has Header
153: 	auto has_header = Value::BOOLEAN(sniffer_options.dialect_options.header.GetValue()).ToString();
154: 	output.SetValue(6, 0, has_header);
155: 	// 8. List<Struct<Column-Name:Types>> {'col1': 'INTEGER', 'col2': 'VARCHAR'}
156: 	vector<Value> values;
157: 	std::ostringstream columns;
158: 	columns << "{";
159: 	for (idx_t i = 0; i < sniffer_result.return_types.size(); i++) {
160: 		child_list_t<Value> struct_children {{"name", sniffer_result.names[i]},
161: 		                                     {"type", {sniffer_result.return_types[i].ToString()}}};
162: 		values.emplace_back(Value::STRUCT(struct_children));
163: 		columns << "'" << sniffer_result.names[i] << "': '" << sniffer_result.return_types[i].ToString() << "'";
164: 		if (i != sniffer_result.return_types.size() - 1) {
165: 			columns << separator;
166: 		}
167: 	}
168: 	columns << "}";
169: 	output.SetValue(7, 0, Value::LIST(values));
170: 	// 9. Date Format
171: 	auto date_format = sniffer_options.dialect_options.date_format[LogicalType::DATE].GetValue();
172: 	if (!date_format.Empty()) {
173: 		output.SetValue(8, 0, date_format.format_specifier);
174: 	} else {
175: 		bool has_date = false;
176: 		for (auto &c_type : sniffer_result.return_types) {
177: 			// Must be ISO 8601
178: 			if (c_type.id() == LogicalTypeId::DATE) {
179: 				output.SetValue(8, 0, Value("%Y-%m-%d"));
180: 				has_date = true;
181: 			}
182: 		}
183: 		if (!has_date) {
184: 			output.SetValue(8, 0, Value(nullptr));
185: 		}
186: 	}
187: 
188: 	// 10. Timestamp Format
189: 	auto timestamp_format = sniffer_options.dialect_options.date_format[LogicalType::TIMESTAMP].GetValue();
190: 	if (!timestamp_format.Empty()) {
191: 		output.SetValue(9, 0, timestamp_format.format_specifier);
192: 	} else {
193: 		output.SetValue(9, 0, Value(nullptr));
194: 	}
195: 
196: 	// 11. The Extra User Arguments
197: 	if (data.options.user_defined_parameters.empty()) {
198: 		output.SetValue(10, 0, Value());
199: 	} else {
200: 		output.SetValue(10, 0, Value(data.options.user_defined_parameters));
201: 	}
202: 
203: 	// 12. csv_read string
204: 	std::ostringstream csv_read;
205: 
206: 	// Base, Path and auto_detect=false
207: 	csv_read << "FROM read_csv('" << data.path << "'" << separator << "auto_detect=false" << separator;
208: 	// 10.1. Delimiter
209: 	if (!sniffer_options.dialect_options.state_machine_options.delimiter.IsSetByUser()) {
210: 		csv_read << "delim="
211: 		         << "'" << FormatOptions(sniffer_options.dialect_options.state_machine_options.delimiter.GetValue())
212: 		         << "'" << separator;
213: 	}
214: 	// 11.2. Quote
215: 	if (!sniffer_options.dialect_options.header.IsSetByUser()) {
216: 		csv_read << "quote="
217: 		         << "'" << FormatOptions(sniffer_options.dialect_options.state_machine_options.quote.GetValue()) << "'"
218: 		         << separator;
219: 	}
220: 	// 11.3. Escape
221: 	if (!sniffer_options.dialect_options.state_machine_options.escape.IsSetByUser()) {
222: 		csv_read << "escape="
223: 		         << "'" << FormatOptions(sniffer_options.dialect_options.state_machine_options.escape.GetValue()) << "'"
224: 		         << separator;
225: 	}
226: 	// 11.4. NewLine Delimiter
227: 	if (!sniffer_options.dialect_options.state_machine_options.new_line.IsSetByUser()) {
228: 		if (new_line_identifier != "mix") {
229: 			csv_read << "new_line="
230: 			         << "'" << new_line_identifier << "'" << separator;
231: 		}
232: 	}
233: 	// 11.5. Skip Rows
234: 	if (!sniffer_options.dialect_options.skip_rows.IsSetByUser()) {
235: 		csv_read << "skip=" << sniffer_options.dialect_options.skip_rows.GetValue() << separator;
236: 	}
237: 
238: 	// 11.6. Comment
239: 	if (!sniffer_options.dialect_options.state_machine_options.comment.IsSetByUser()) {
240: 		csv_read << "comment="
241: 		         << "'" << FormatOptions(sniffer_options.dialect_options.state_machine_options.comment.GetValue())
242: 		         << "'" << separator;
243: 	}
244: 
245: 	// 11.7. Has Header
246: 	if (!sniffer_options.dialect_options.header.IsSetByUser()) {
247: 		csv_read << "header=" << has_header << separator;
248: 	}
249: 	// 11.8. column={'col1': 'INTEGER', 'col2': 'VARCHAR'}
250: 	csv_read << "columns=" << columns.str();
251: 	// 11.9. Date Format
252: 	if (!sniffer_options.dialect_options.date_format[LogicalType::DATE].IsSetByUser()) {
253: 		if (!sniffer_options.dialect_options.date_format[LogicalType::DATE].GetValue().format_specifier.empty()) {
254: 			csv_read << separator << "dateformat="
255: 			         << "'"
256: 			         << sniffer_options.dialect_options.date_format[LogicalType::DATE].GetValue().format_specifier
257: 			         << "'";
258: 		} else {
259: 			for (auto &c_type : sniffer_result.return_types) {
260: 				// Must be ISO 8601
261: 				if (c_type.id() == LogicalTypeId::DATE) {
262: 					csv_read << separator << "dateformat="
263: 					         << "'%Y-%m-%d'";
264: 					break;
265: 				}
266: 			}
267: 		}
268: 	}
269: 	// 11.10. Timestamp Format
270: 	if (!sniffer_options.dialect_options.date_format[LogicalType::TIMESTAMP].IsSetByUser()) {
271: 		if (!sniffer_options.dialect_options.date_format[LogicalType::TIMESTAMP].GetValue().format_specifier.empty()) {
272: 			csv_read << separator << "timestampformat="
273: 			         << "'"
274: 			         << sniffer_options.dialect_options.date_format[LogicalType::TIMESTAMP].GetValue().format_specifier
275: 			         << "'";
276: 		}
277: 	}
278: 	// 11.11 User Arguments
279: 	if (!data.options.user_defined_parameters.empty()) {
280: 		csv_read << separator << data.options.user_defined_parameters;
281: 	}
282: 	csv_read << ");";
283: 	output.SetValue(11, 0, csv_read.str());
284: 	global_state.done = true;
285: }
286: 
287: void CSVSnifferFunction::RegisterFunction(BuiltinFunctions &set) {
288: 	TableFunction csv_sniffer("sniff_csv", {LogicalType::VARCHAR}, CSVSniffFunction, CSVSniffBind, CSVSniffInitGlobal);
289: 	// Accept same options as the actual csv reader
290: 	ReadCSVTableFunction::ReadCSVAddNamedParameters(csv_sniffer);
291: 	set.AddFunction(csv_sniffer);
292: }
293: } // namespace duckdb
[end of src/function/table/sniff_csv.cpp]
[start of src/include/duckdb/common/enums/file_compression_type.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/common/enums/file_compression_type.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/constants.hpp"
12: 
13: namespace duckdb {
14: 
15: enum class FileCompressionType : uint8_t { AUTO_DETECT = 0, UNCOMPRESSED = 1, GZIP = 2, ZSTD = 3 };
16: 
17: FileCompressionType FileCompressionTypeFromString(const string &input);
18: 
19: } // namespace duckdb
[end of src/include/duckdb/common/enums/file_compression_type.hpp]
[start of src/include/duckdb/function/replacement_scan.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/function/replacement_scan.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/common.hpp"
12: #include "duckdb/common/string_util.hpp"
13: 
14: namespace duckdb {
15: 
16: class ClientContext;
17: class TableRef;
18: 
19: struct ReplacementScanData {
20: public:
21: 	virtual ~ReplacementScanData() {
22: 	}
23: 
24: public:
25: 	template <class TARGET>
26: 	TARGET &Cast() {
27: 		DynamicCastCheck<TARGET>(this);
28: 		return reinterpret_cast<TARGET &>(*this);
29: 	}
30: 	template <class TARGET>
31: 	const TARGET &Cast() const {
32: 		DynamicCastCheck<TARGET>(this);
33: 		return reinterpret_cast<const TARGET &>(*this);
34: 	}
35: };
36: 
37: struct ReplacementScanInput {
38: public:
39: 	explicit ReplacementScanInput(const string &catalog_name, const string &schema_name, const string &table_name)
40: 	    : catalog_name(catalog_name), schema_name(schema_name), table_name(table_name) {
41: 	}
42: 
43: public:
44: 	const string &catalog_name;
45: 	const string &schema_name;
46: 	const string &table_name;
47: };
48: 
49: typedef unique_ptr<TableRef> (*replacement_scan_t)(ClientContext &context, ReplacementScanInput &input,
50:                                                    optional_ptr<ReplacementScanData> data);
51: 
52: //! Replacement table scans are automatically attempted when a table name cannot be found in the schema
53: //! This allows you to do e.g. SELECT * FROM 'filename.csv', and automatically convert this into a CSV scan
54: struct ReplacementScan {
55: 	explicit ReplacementScan(replacement_scan_t function, unique_ptr<ReplacementScanData> data_p = nullptr)
56: 	    : function(function), data(std::move(data_p)) {
57: 	}
58: 
59: 	static bool CanReplace(const string &table_name, const vector<string> &extensions) {
60: 		auto lower_name = StringUtil::Lower(table_name);
61: 
62: 		if (StringUtil::EndsWith(lower_name, ".gz")) {
63: 			lower_name = lower_name.substr(0, lower_name.size() - 3);
64: 		} else if (StringUtil::EndsWith(lower_name, ".zst")) {
65: 			lower_name = lower_name.substr(0, lower_name.size() - 4);
66: 		}
67: 
68: 		for (auto &extension : extensions) {
69: 			if (StringUtil::EndsWith(lower_name, "." + extension) ||
70: 			    StringUtil::Contains(lower_name, "." + extension + "?")) {
71: 				return true;
72: 			}
73: 		}
74: 
75: 		return false;
76: 	}
77: 
78: 	static string GetFullPath(const string &catalog, const string &schema, const string &table) {
79: 		string table_name = catalog;
80: 		if (!schema.empty()) {
81: 			table_name += (!table_name.empty() ? "." : "") + schema;
82: 		}
83: 		table_name += (!table_name.empty() ? "." : "") + table;
84: 		return table_name;
85: 	}
86: 
87: 	static string GetFullPath(ReplacementScanInput &input) {
88: 		return GetFullPath(input.catalog_name, input.schema_name, input.table_name);
89: 	}
90: 
91: 	replacement_scan_t function;
92: 	unique_ptr<ReplacementScanData> data;
93: };
94: 
95: } // namespace duckdb
[end of src/include/duckdb/function/replacement_scan.hpp]
[start of src/main/extension/extension_install.cpp]
1: #include "duckdb/common/exception/http_exception.hpp"
2: #include "duckdb/common/gzip_file_system.hpp"
3: #include "duckdb/common/http_util.hpp"
4: #include "duckdb/common/local_file_system.hpp"
5: #include "duckdb/common/serializer/binary_serializer.hpp"
6: #include "duckdb/common/string_util.hpp"
7: #include "duckdb/common/types/uuid.hpp"
8: #include "duckdb/logging/http_logger.hpp"
9: #include "duckdb/main/client_data.hpp"
10: #include "duckdb/main/extension_helper.hpp"
11: #include "duckdb/main/extension_install_info.hpp"
12: #include "duckdb/main/secret/secret.hpp"
13: #include "duckdb/main/secret/secret_manager.hpp"
14: 
15: #ifndef DISABLE_DUCKDB_REMOTE_INSTALL
16: #ifndef DUCKDB_DISABLE_EXTENSION_LOAD
17: #include "httplib.hpp"
18: #ifndef DUCKDB_NO_THREADS
19: #include <chrono>
20: #include <thread>
21: #endif
22: #endif
23: #endif
24: #include "duckdb/common/windows_undefs.hpp"
25: 
26: #include <fstream>
27: 
28: namespace duckdb {
29: 
30: //===--------------------------------------------------------------------===//
31: // Install Extension
32: //===--------------------------------------------------------------------===//
33: const string ExtensionHelper::NormalizeVersionTag(const string &version_tag) {
34: 	if (!version_tag.empty() && version_tag[0] != 'v') {
35: 		return "v" + version_tag;
36: 	}
37: 	return version_tag;
38: }
39: 
40: bool ExtensionHelper::IsRelease(const string &version_tag) {
41: 	return !StringUtil::Contains(version_tag, "-dev");
42: }
43: 
44: const string ExtensionHelper::GetVersionDirectoryName() {
45: #ifdef DUCKDB_WASM_VERSION
46: 	return DUCKDB_QUOTE_DEFINE(DUCKDB_WASM_VERSION);
47: #endif
48: 	if (IsRelease(DuckDB::LibraryVersion())) {
49: 		return NormalizeVersionTag(DuckDB::LibraryVersion());
50: 	} else {
51: 		return DuckDB::SourceID();
52: 	}
53: }
54: 
55: const vector<string> ExtensionHelper::PathComponents() {
56: 	return vector<string> {GetVersionDirectoryName(), DuckDB::Platform()};
57: }
58: 
59: duckdb::string ExtensionHelper::DefaultExtensionFolder(FileSystem &fs) {
60: 	string home_directory = fs.GetHomeDirectory();
61: 	// exception if the home directory does not exist, don't create whatever we think is home
62: 	if (!fs.DirectoryExists(home_directory)) {
63: 		throw IOException("Can't find the home directory at '%s'\nSpecify a home directory using the SET "
64: 		                  "home_directory='/path/to/dir' option.",
65: 		                  home_directory);
66: 	}
67: 	string res = home_directory;
68: 	res = fs.JoinPath(res, ".duckdb");
69: 	res = fs.JoinPath(res, "extensions");
70: 	return res;
71: }
72: 
73: string ExtensionHelper::ExtensionDirectory(DatabaseInstance &db, FileSystem &fs) {
74: #ifdef WASM_LOADABLE_EXTENSIONS
75: 	throw PermissionException("ExtensionDirectory functionality is not supported in duckdb-wasm");
76: #endif
77: 	string extension_directory;
78: 	auto &config = db.config;
79: 	if (!config.options.extension_directory.empty()) { // create the extension directory if not present
80: 		extension_directory = config.options.extension_directory;
81: 		// TODO this should probably live in the FileSystem
82: 		// convert random separators to platform-canonic
83: 	} else { // otherwise default to home
84: 		extension_directory = DefaultExtensionFolder(fs);
85: 	}
86: 	{
87: 		extension_directory = fs.ConvertSeparators(extension_directory);
88: 		// expand ~ in extension directory
89: 		extension_directory = fs.ExpandPath(extension_directory);
90: 		if (!fs.DirectoryExists(extension_directory)) {
91: 			auto sep = fs.PathSeparator(extension_directory);
92: 			auto splits = StringUtil::Split(extension_directory, sep);
93: 			D_ASSERT(!splits.empty());
94: 			string extension_directory_prefix;
95: 			if (StringUtil::StartsWith(extension_directory, sep)) {
96: 				extension_directory_prefix = sep; // this is swallowed by Split otherwise
97: 			}
98: 			for (auto &split : splits) {
99: 				extension_directory_prefix = extension_directory_prefix + split + sep;
100: 				if (!fs.DirectoryExists(extension_directory_prefix)) {
101: 					fs.CreateDirectory(extension_directory_prefix);
102: 				}
103: 			}
104: 		}
105: 	}
106: 	D_ASSERT(fs.DirectoryExists(extension_directory));
107: 
108: 	auto path_components = PathComponents();
109: 	for (auto &path_ele : path_components) {
110: 		extension_directory = fs.JoinPath(extension_directory, path_ele);
111: 		if (!fs.DirectoryExists(extension_directory)) {
112: 			fs.CreateDirectory(extension_directory);
113: 		}
114: 	}
115: 	return extension_directory;
116: }
117: 
118: string ExtensionHelper::ExtensionDirectory(ClientContext &context) {
119: 	auto &db = DatabaseInstance::GetDatabase(context);
120: 	auto &fs = FileSystem::GetFileSystem(context);
121: 	return ExtensionDirectory(db, fs);
122: }
123: 
124: bool ExtensionHelper::CreateSuggestions(const string &extension_name, string &message) {
125: 	auto lowercase_extension_name = StringUtil::Lower(extension_name);
126: 	vector<string> candidates;
127: 	for (idx_t ext_count = ExtensionHelper::DefaultExtensionCount(), i = 0; i < ext_count; i++) {
128: 		candidates.emplace_back(ExtensionHelper::GetDefaultExtension(i).name);
129: 	}
130: 	for (idx_t ext_count = ExtensionHelper::ExtensionAliasCount(), i = 0; i < ext_count; i++) {
131: 		candidates.emplace_back(ExtensionHelper::GetExtensionAlias(i).alias);
132: 	}
133: 	auto closest_extensions = StringUtil::TopNJaroWinkler(candidates, lowercase_extension_name);
134: 	message = StringUtil::CandidatesMessage(closest_extensions, "Candidate extensions");
135: 	for (auto &closest : closest_extensions) {
136: 		if (closest == lowercase_extension_name) {
137: 			message = "Extension \"" + extension_name + "\" is an existing extension.\n";
138: 			return true;
139: 		}
140: 	}
141: 	return false;
142: }
143: 
144: unique_ptr<ExtensionInstallInfo> ExtensionHelper::InstallExtension(DatabaseInstance &db, FileSystem &fs,
145:                                                                    const string &extension, bool force_install,
146:                                                                    optional_ptr<ExtensionRepository> repository,
147:                                                                    bool throw_on_origin_mismatch,
148:                                                                    const string &version) {
149: #ifdef WASM_LOADABLE_EXTENSIONS
150: 	// Install is currently a no-op
151: 	return nullptr;
152: #endif
153: 	string local_path = ExtensionDirectory(db, fs);
154: 	return InstallExtensionInternal(db, fs, local_path, extension, force_install, throw_on_origin_mismatch, version,
155: 	                                repository);
156: }
157: 
158: unique_ptr<ExtensionInstallInfo> ExtensionHelper::InstallExtension(ClientContext &context, const string &extension,
159:                                                                    bool force_install,
160:                                                                    optional_ptr<ExtensionRepository> repository,
161:                                                                    bool throw_on_origin_mismatch,
162:                                                                    const string &version) {
163: #ifdef WASM_LOADABLE_EXTENSIONS
164: 	// Install is currently a no-op
165: 	return nullptr;
166: #endif
167: 	auto &db = DatabaseInstance::GetDatabase(context);
168: 	auto &fs = FileSystem::GetFileSystem(context);
169: 	string local_path = ExtensionDirectory(context);
170: 	optional_ptr<HTTPLogger> http_logger =
171: 	    ClientConfig::GetConfig(context).enable_http_logging ? context.client_data->http_logger.get() : nullptr;
172: 	return InstallExtensionInternal(db, fs, local_path, extension, force_install, throw_on_origin_mismatch, version,
173: 	                                repository, http_logger, context);
174: }
175: 
176: unsafe_unique_array<data_t> ReadExtensionFileFromDisk(FileSystem &fs, const string &path, idx_t &file_size) {
177: 	auto source_file = fs.OpenFile(path, FileFlags::FILE_FLAGS_READ);
178: 	file_size = source_file->GetFileSize();
179: 	auto in_buffer = make_unsafe_uniq_array<data_t>(file_size);
180: 	source_file->Read(in_buffer.get(), file_size);
181: 	source_file->Close();
182: 	return in_buffer;
183: }
184: 
185: static void WriteExtensionFileToDisk(FileSystem &fs, const string &path, void *data, idx_t data_size) {
186: 	auto target_file = fs.OpenFile(path, FileFlags::FILE_FLAGS_WRITE | FileFlags::FILE_FLAGS_APPEND |
187: 	                                         FileFlags::FILE_FLAGS_FILE_CREATE_NEW);
188: 	target_file->Write(data, data_size);
189: 	target_file->Close();
190: 	target_file.reset();
191: }
192: 
193: static void WriteExtensionMetadataFileToDisk(FileSystem &fs, const string &path, ExtensionInstallInfo &metadata) {
194: 	auto file_writer = BufferedFileWriter(fs, path);
195: 	BinarySerializer::Serialize(metadata, file_writer);
196: 	file_writer.Sync();
197: }
198: 
199: string ExtensionHelper::ExtensionUrlTemplate(optional_ptr<const DatabaseInstance> db,
200:                                              const ExtensionRepository &repository, const string &version) {
201: 	string versioned_path;
202: 	if (!version.empty()) {
203: 		versioned_path = "/${NAME}/" + version + "/${REVISION}/${PLATFORM}/${NAME}.duckdb_extension";
204: 	} else {
205: 		versioned_path = "/${REVISION}/${PLATFORM}/${NAME}.duckdb_extension";
206: 	}
207: #ifdef WASM_LOADABLE_EXTENSIONS
208: 	string default_endpoint = DEFAULT_REPOSITORY;
209: 	versioned_path = versioned_path + ".wasm";
210: #else
211: 	string default_endpoint = ExtensionRepository::DEFAULT_REPOSITORY_URL;
212: 	versioned_path = versioned_path + ".gz";
213: #endif
214: 	string url_template = repository.path + versioned_path;
215: 	return url_template;
216: }
217: 
218: string ExtensionHelper::ExtensionFinalizeUrlTemplate(const string &url_template, const string &extension_name) {
219: 	auto url = StringUtil::Replace(url_template, "${REVISION}", GetVersionDirectoryName());
220: 	url = StringUtil::Replace(url, "${PLATFORM}", DuckDB::Platform());
221: 	url = StringUtil::Replace(url, "${NAME}", extension_name);
222: 	return url;
223: }
224: 
225: static void CheckExtensionMetadataOnInstall(DatabaseInstance &db, void *in_buffer, idx_t file_size,
226:                                             ExtensionInstallInfo &info, const string &extension_name) {
227: 	if (file_size < ParsedExtensionMetaData::FOOTER_SIZE) {
228: 		throw IOException("Failed to install '%s', file too small to be a valid DuckDB extension!", extension_name);
229: 	}
230: 
231: 	auto parsed_metadata = ExtensionHelper::ParseExtensionMetaData(static_cast<char *>(in_buffer) +
232: 	                                                               (file_size - ParsedExtensionMetaData::FOOTER_SIZE));
233: 
234: 	auto metadata_mismatch_error = parsed_metadata.GetInvalidMetadataError();
235: 
236: 	if (!metadata_mismatch_error.empty() && !db.config.options.allow_extensions_metadata_mismatch) {
237: 		throw IOException("Failed to install '%s'\n%s", extension_name, metadata_mismatch_error);
238: 	}
239: 
240: 	info.version = parsed_metadata.extension_version;
241: }
242: 
243: // Note: since this method is not atomic, this can fail in different ways, that should all be handled properly by
244: // DuckDB:
245: //   1. Crash after extension removal: extension is now uninstalled, metadata file still present
246: //   2. Crash after metadata removal: extension is now uninstalled, extension dir is clean
247: //   3. Crash after extension move: extension is now uninstalled, new metadata file present
248: static void WriteExtensionFiles(FileSystem &fs, const string &temp_path, const string &local_extension_path,
249:                                 void *in_buffer, idx_t file_size, ExtensionInstallInfo &info) {
250: 	// Write extension to tmp file
251: 	WriteExtensionFileToDisk(fs, temp_path, in_buffer, file_size);
252: 
253: 	// Write metadata to tmp file
254: 	auto metadata_tmp_path = temp_path + ".info";
255: 	auto metadata_file_path = local_extension_path + ".info";
256: 	WriteExtensionMetadataFileToDisk(fs, metadata_tmp_path, info);
257: 
258: 	// First remove the local extension we are about to replace
259: 	if (fs.FileExists(local_extension_path)) {
260: 		fs.RemoveFile(local_extension_path);
261: 	}
262: 
263: 	// Then remove the old metadata file
264: 	if (fs.FileExists(metadata_file_path)) {
265: 		fs.RemoveFile(metadata_file_path);
266: 	}
267: 
268: 	fs.MoveFile(metadata_tmp_path, metadata_file_path);
269: 	fs.MoveFile(temp_path, local_extension_path);
270: }
271: 
272: // Install an extension using a filesystem
273: static unique_ptr<ExtensionInstallInfo> DirectInstallExtension(DatabaseInstance &db, FileSystem &fs, const string &path,
274:                                                                const string &temp_path, const string &extension_name,
275:                                                                const string &local_extension_path, bool force_install,
276:                                                                optional_ptr<ExtensionRepository> repository,
277:                                                                optional_ptr<ClientContext> context) {
278: 	string file = fs.ConvertSeparators(path);
279: 
280: 	// Try autoloading httpfs for loading extensions over https
281: 	if (context) {
282: 		auto &db = DatabaseInstance::GetDatabase(*context);
283: 		if (StringUtil::StartsWith(path, "https://") && !db.ExtensionIsLoaded("httpfs") &&
284: 		    db.config.options.autoload_known_extensions) {
285: 			ExtensionHelper::AutoLoadExtension(*context, "httpfs");
286: 		}
287: 	}
288: 
289: 	// Check if file exists
290: 	bool exists = fs.FileExists(file);
291: 
292: 	// Recheck without .gz
293: 	if (!exists && StringUtil::EndsWith(file, ".gz")) {
294: 		file = file.substr(0, file.size() - 3);
295: 		exists = fs.FileExists(file);
296: 	}
297: 
298: 	// Throw error on failure
299: 	if (!exists) {
300: 		if (!fs.IsRemoteFile(file)) {
301: 			throw IOException("Failed to copy local extension \"%s\" at PATH \"%s\"\n", extension_name, file);
302: 		}
303: 		if (StringUtil::StartsWith(file, "https://")) {
304: 			throw IOException("Failed to install remote extension \"%s\" from url \"%s\"", extension_name, file);
305: 		}
306: 	}
307: 
308: 	idx_t file_size;
309: 	auto in_buffer = ReadExtensionFileFromDisk(fs, file, file_size);
310: 
311: 	ExtensionInstallInfo info;
312: 
313: 	string decompressed_data;
314: 	void *extension_decompressed;
315: 	idx_t extension_decompressed_size;
316: 
317: 	if (GZipFileSystem::CheckIsZip(const_char_ptr_cast(in_buffer.get()), file_size)) {
318: 		decompressed_data = GZipFileSystem::UncompressGZIPString(const_char_ptr_cast(in_buffer.get()), file_size);
319: 		extension_decompressed = (void *)decompressed_data.data();
320: 		extension_decompressed_size = decompressed_data.size();
321: 	} else {
322: 		extension_decompressed = (void *)in_buffer.get();
323: 		extension_decompressed_size = file_size;
324: 	}
325: 
326: 	CheckExtensionMetadataOnInstall(db, extension_decompressed, extension_decompressed_size, info, extension_name);
327: 
328: 	if (!repository) {
329: 		info.mode = ExtensionInstallMode::CUSTOM_PATH;
330: 		info.full_path = file;
331: 	} else {
332: 		info.mode = ExtensionInstallMode::REPOSITORY;
333: 		info.full_path = file;
334: 		info.repository_url = repository->path;
335: 	}
336: 
337: 	WriteExtensionFiles(fs, temp_path, local_extension_path, extension_decompressed, extension_decompressed_size, info);
338: 
339: 	return make_uniq<ExtensionInstallInfo>(info);
340: }
341: 
342: #ifndef DUCKDB_DISABLE_EXTENSION_LOAD
343: static unique_ptr<ExtensionInstallInfo> InstallFromHttpUrl(DatabaseInstance &db, const string &url,
344:                                                            const string &extension_name, const string &temp_path,
345:                                                            const string &local_extension_path, bool force_install,
346:                                                            optional_ptr<ExtensionRepository> repository,
347:                                                            optional_ptr<HTTPLogger> http_logger) {
348: 	string no_http = StringUtil::Replace(url, "http://", "");
349: 
350: 	idx_t next = no_http.find('/', 0);
351: 	if (next == string::npos) {
352: 		throw IOException("No slash in URL template");
353: 	}
354: 
355: 	// Push the substring [last, next) on to splits
356: 	auto hostname_without_http = no_http.substr(0, next);
357: 	auto url_local_part = no_http.substr(next);
358: 
359: 	unique_ptr<ExtensionInstallInfo> install_info;
360: 	{
361: 		auto fs = FileSystem::CreateLocal();
362: 		if (fs->FileExists(local_extension_path + ".info")) {
363: 			install_info = ExtensionInstallInfo::TryReadInfoFile(*fs, local_extension_path + ".info", extension_name);
364: 		}
365: 	}
366: 
367: 	auto url_base = "http://" + hostname_without_http;
368: 	// FIXME: the retry logic should be unified with the retry logic in the httpfs client
369: 	static constexpr idx_t MAX_RETRY_COUNT = 3;
370: 	static constexpr uint64_t RETRY_WAIT_MS = 100;
371: 	static constexpr double RETRY_BACKOFF = 4;
372: 	idx_t retry_count = 0;
373: 	duckdb_httplib::Result res;
374: 	while (true) {
375: 		duckdb_httplib::Client cli(url_base.c_str());
376: 		if (!db.config.options.http_proxy.empty()) {
377: 			idx_t port;
378: 			string host;
379: 			HTTPUtil::ParseHTTPProxyHost(db.config.options.http_proxy, host, port);
380: 			cli.set_proxy(host, NumericCast<int>(port));
381: 		}
382: 
383: 		if (!db.config.options.http_proxy_username.empty() || !db.config.options.http_proxy_password.empty()) {
384: 			cli.set_proxy_basic_auth(db.config.options.http_proxy_username, db.config.options.http_proxy_password);
385: 		}
386: 
387: 		if (http_logger) {
388: 			cli.set_logger(http_logger->GetLogger<duckdb_httplib::Request, duckdb_httplib::Response>());
389: 		}
390: 
391: 		duckdb_httplib::Headers headers = {
392: 		    {"User-Agent", StringUtil::Format("%s %s", db.config.UserAgent(), DuckDB::SourceID())}};
393: 
394: 		if (install_info && !install_info->etag.empty()) {
395: 			headers.insert({"If-None-Match", StringUtil::Format("%s", install_info->etag)});
396: 		}
397: 
398: 		res = cli.Get(url_local_part.c_str(), headers);
399: 		if (install_info && res && res->status == 304) {
400: 			return install_info;
401: 		}
402: 
403: 		if (res && res->status == 200) {
404: 			// success!
405: 			break;
406: 		}
407: 		// failure - check if we should retry
408: 		bool should_retry = false;
409: 		if (res.error() == duckdb_httplib::Error::Success) {
410: 			switch (res->status) {
411: 			case 408: // Request Timeout
412: 			case 418: // Server is pretending to be a teapot
413: 			case 429: // Rate limiter hit
414: 			case 500: // Server has error
415: 			case 503: // Server has error
416: 			case 504: // Server has error
417: 				should_retry = true;
418: 				break;
419: 			default:
420: 				break;
421: 			}
422: 		} else {
423: 			// always retry on duckdb_httplib::Error::Error
424: 			should_retry = true;
425: 		}
426: 		retry_count++;
427: 		if (!should_retry || retry_count >= MAX_RETRY_COUNT) {
428: 			// if we should not retry or exceeded the number of retries - bubble up the error
429: 			string message;
430: 			auto exact_match = ExtensionHelper::CreateSuggestions(extension_name, message);
431: 			if (exact_match && !ExtensionHelper::IsRelease(DuckDB::LibraryVersion())) {
432: 				message += "\nAre you using a development build? In this case, extensions might not (yet) be uploaded.";
433: 			}
434: 			if (res.error() == duckdb_httplib::Error::Success) {
435: 				throw HTTPException(res.value(), "Failed to download extension \"%s\" at URL \"%s%s\" (HTTP %n)\n%s",
436: 				                    extension_name, url_base, url_local_part, res->status, message);
437: 			} else {
438: 				throw IOException("Failed to download extension \"%s\" at URL \"%s%s\"\n%s (ERROR %s)", extension_name,
439: 				                  url_base, url_local_part, message, to_string(res.error()));
440: 			}
441: 		}
442: #ifndef DUCKDB_NO_THREADS
443: 		// retry
444: 		// sleep first
445: 		uint64_t sleep_amount = static_cast<uint64_t>(static_cast<double>(RETRY_WAIT_MS) *
446: 		                                              pow(RETRY_BACKOFF, static_cast<double>(retry_count) - 1));
447: 		std::this_thread::sleep_for(std::chrono::milliseconds(sleep_amount));
448: #endif
449: 	}
450: 	auto decompressed_body = GZipFileSystem::UncompressGZIPString(res->body);
451: 
452: 	ExtensionInstallInfo info;
453: 	CheckExtensionMetadataOnInstall(db, (void *)decompressed_body.data(), decompressed_body.size(), info,
454: 	                                extension_name);
455: 	if (res->has_header("ETag")) {
456: 		info.etag = res->get_header_value("ETag");
457: 	}
458: 
459: 	if (repository) {
460: 		info.mode = ExtensionInstallMode::REPOSITORY;
461: 		info.full_path = url;
462: 		info.repository_url = repository->path;
463: 	} else {
464: 		info.mode = ExtensionInstallMode::CUSTOM_PATH;
465: 		info.full_path = url;
466: 	}
467: 
468: 	auto fs = FileSystem::CreateLocal();
469: 	WriteExtensionFiles(*fs, temp_path, local_extension_path, (void *)decompressed_body.data(),
470: 	                    decompressed_body.size(), info);
471: 
472: 	return make_uniq<ExtensionInstallInfo>(info);
473: }
474: 
475: // Install an extension using a hand-rolled http request
476: static unique_ptr<ExtensionInstallInfo> InstallFromRepository(DatabaseInstance &db, FileSystem &fs, const string &url,
477:                                                               const string &extension_name,
478:                                                               ExtensionRepository &repository, const string &temp_path,
479:                                                               const string &local_extension_path, const string &version,
480:                                                               bool force_install, optional_ptr<HTTPLogger> http_logger,
481:                                                               optional_ptr<ClientContext> context) {
482: 	string url_template = ExtensionHelper::ExtensionUrlTemplate(db, repository, version);
483: 	string generated_url = ExtensionHelper::ExtensionFinalizeUrlTemplate(url_template, extension_name);
484: 
485: 	// Special handling for http repository: avoid using regular filesystem (note: the filesystem is not used here)
486: 	if (StringUtil::StartsWith(repository.path, "http://")) {
487: 		return InstallFromHttpUrl(db, generated_url, extension_name, temp_path, local_extension_path, force_install,
488: 		                          repository, http_logger);
489: 	}
490: 
491: 	// Default case, let the FileSystem figure it out
492: 	return DirectInstallExtension(db, fs, generated_url, temp_path, extension_name, local_extension_path, force_install,
493: 	                              repository, context);
494: }
495: 
496: static bool IsHTTP(const string &path) {
497: 	return StringUtil::StartsWith(path, "http://") || !StringUtil::StartsWith(path, "https://");
498: }
499: 
500: static void ThrowErrorOnMismatchingExtensionOrigin(FileSystem &fs, const string &local_extension_path,
501:                                                    const string &extension_name, const string &extension,
502:                                                    optional_ptr<ExtensionRepository> repository) {
503: 	auto install_info = ExtensionInstallInfo::TryReadInfoFile(fs, local_extension_path + ".info", extension_name);
504: 
505: 	string format_string = "Installing extension '%s' failed. The extension is already installed "
506: 	                       "but the origin is different.\n"
507: 	                       "Currently installed extension is from %s '%s', while the extension to be "
508: 	                       "installed is from %s '%s'.\n"
509: 	                       "To solve this rerun this command with `FORCE INSTALL`";
510: 	string repo = "repository";
511: 	string custom_path = "custom_path";
512: 
513: 	if (install_info) {
514: 		if (install_info->mode == ExtensionInstallMode::REPOSITORY && repository &&
515: 		    install_info->repository_url != repository->path) {
516: 			throw InvalidInputException(format_string, extension_name, repo, install_info->repository_url, repo,
517: 			                            repository->path);
518: 		}
519: 		if (install_info->mode == ExtensionInstallMode::REPOSITORY && ExtensionHelper::IsFullPath(extension)) {
520: 			throw InvalidInputException(format_string, extension_name, repo, install_info->repository_url, custom_path,
521: 			                            extension);
522: 		}
523: 	}
524: }
525: #endif // DUCKDB_DISABLE_EXTENSION_LOAD
526: 
527: unique_ptr<ExtensionInstallInfo>
528: ExtensionHelper::InstallExtensionInternal(DatabaseInstance &db, FileSystem &fs, const string &local_path,
529:                                           const string &extension, bool force_install, bool throw_on_origin_mismatch,
530:                                           const string &version, optional_ptr<ExtensionRepository> repository,
531:                                           optional_ptr<HTTPLogger> http_logger, optional_ptr<ClientContext> context) {
532: #ifdef DUCKDB_DISABLE_EXTENSION_LOAD
533: 	throw PermissionException("Installing external extensions is disabled through a compile time flag");
534: #else
535: 	if (!db.config.options.enable_external_access) {
536: 		throw PermissionException("Installing extensions is disabled through configuration");
537: 	}
538: 
539: 	auto extension_name = ApplyExtensionAlias(fs.ExtractBaseName(extension));
540: 	string local_extension_path = fs.JoinPath(local_path, extension_name + ".duckdb_extension");
541: 	string temp_path = local_extension_path + ".tmp-" + UUID::ToString(UUID::GenerateRandomUUID());
542: 
543: 	if (fs.FileExists(local_extension_path) && !force_install) {
544: 		// File exists: throw error if origin mismatches
545: 		if (throw_on_origin_mismatch && !db.config.options.allow_extensions_metadata_mismatch &&
546: 		    fs.FileExists(local_extension_path + ".info")) {
547: 			ThrowErrorOnMismatchingExtensionOrigin(fs, local_extension_path, extension_name, extension, repository);
548: 		}
549: 
550: 		// File exists, but that's okay, install is now a NOP
551: 		return nullptr;
552: 	}
553: 
554: 	if (fs.FileExists(temp_path)) {
555: 		fs.RemoveFile(temp_path);
556: 	}
557: 
558: 	if (ExtensionHelper::IsFullPath(extension) && repository) {
559: 		throw InvalidInputException("Cannot pass both a repository and a full path url");
560: 	}
561: 
562: 	// Resolve default repository if there is none set
563: 	ExtensionRepository resolved_repository;
564: 	if (!ExtensionHelper::IsFullPath(extension) && !repository) {
565: 		resolved_repository = ExtensionRepository::GetDefaultRepository(db.config);
566: 		repository = resolved_repository;
567: 	}
568: 
569: 	// Install extension from local, direct url
570: 	if (ExtensionHelper::IsFullPath(extension) && !IsHTTP(extension)) {
571: 		LocalFileSystem local_fs;
572: 		return DirectInstallExtension(db, local_fs, extension, temp_path, extension, local_extension_path,
573: 		                              force_install, nullptr, context);
574: 	}
575: 
576: 	// Install extension from local url based on a repository (Note that this will install it as a local file)
577: 	if (repository && !IsHTTP(repository->path)) {
578: 		LocalFileSystem local_fs;
579: 		return InstallFromRepository(db, fs, extension, extension_name, *repository, temp_path, local_extension_path,
580: 		                             version, force_install, http_logger, context);
581: 	}
582: 
583: #ifdef DISABLE_DUCKDB_REMOTE_INSTALL
584: 	throw BinderException("Remote extension installation is disabled through configuration");
585: #else
586: 
587: 	// Full path direct installation
588: 	if (IsFullPath(extension)) {
589: 		if (StringUtil::StartsWith(extension, "http://")) {
590: 			// HTTP takes separate path to avoid dependency on httpfs extension
591: 			return InstallFromHttpUrl(db, extension, extension_name, temp_path, local_extension_path, force_install,
592: 			                          nullptr, http_logger);
593: 		}
594: 
595: 		// Direct installation from local or remote path
596: 		return DirectInstallExtension(db, fs, extension, temp_path, extension, local_extension_path, force_install,
597: 		                              nullptr, context);
598: 	}
599: 
600: 	// Repository installation
601: 	return InstallFromRepository(db, fs, extension, extension_name, *repository, temp_path, local_extension_path,
602: 	                             version, force_install, http_logger, context);
603: #endif
604: #endif
605: }
606: 
607: } // namespace duckdb
[end of src/main/extension/extension_install.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: