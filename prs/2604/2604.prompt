You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
union all disorders
#### What happens?
use 2 union all to link 3 select, the 3rd sometimes come to in front of the 2nd.

#### To Reproduce
v0.3.0 46a0fc50a is right

```
D SELECT 'select count(case 'a union all select 'when a='||range||' then 1 ' from range(2) union all select 'end) from t';
┌────────────────────┐
│         a          │
├────────────────────┤
│ select count(case  │
│ when a=0 then 1    │
│ when a=1 then 1    │
│ end) from t        │
└────────────────────┘
D select * from(SELECT 'select count(case 'a union all select 'when a='||range||' then 1 ' from range(2000) union all select 'end) from t')limit 5;
┌────────────────────┐
│         a          │
├────────────────────┤
│ select count(case  │
│ when a=0 then 1    │
│ when a=1 then 1    │
│ when a=2 then 1    │
│ when a=3 then 1    │
└────────────────────┘
```

v0.3.1-dev705 b77704c86 is right when second select is from range(2)
wrong when range(2000)
```
D SELECT 'select count(case 'a union all select 'when a='||range||' then 1 ' from range(2) union all select 'end) from t';
┌────────────────────┐
│         a          │
├────────────────────┤
│ select count(case  │
│ when a=0 then 1    │
│ when a=1 then 1    │
│ end) from t        │
└────────────────────┘

D select * from(SELECT 'select count(case 'a union all select 'when a='||range||' then 1 ' from range(2000) union all select 'end) from t')limit 5;
┌────────────────────┐
│         a          │
├────────────────────┤
│ select count(case  │
│ end) from t        │
│ when a=0 then 1    │
│ when a=1 then 1    │
│ when a=2 then 1    │
└────────────────────┘
```
		

#### Environment (please complete the following information):
 - OS: [e.g. iOS]
 - DuckDB Version: [e.g. 22]0.3.1-dev 705
 - DuckDB Client: [e.g. Python]

#### Before Submitting

- [x ] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x ] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**
 
union all disorders
#### What happens?
use 2 union all to link 3 select, the 3rd sometimes come to in front of the 2nd.

#### To Reproduce
v0.3.0 46a0fc50a is right

```
D SELECT 'select count(case 'a union all select 'when a='||range||' then 1 ' from range(2) union all select 'end) from t';
┌────────────────────┐
│         a          │
├────────────────────┤
│ select count(case  │
│ when a=0 then 1    │
│ when a=1 then 1    │
│ end) from t        │
└────────────────────┘
D select * from(SELECT 'select count(case 'a union all select 'when a='||range||' then 1 ' from range(2000) union all select 'end) from t')limit 5;
┌────────────────────┐
│         a          │
├────────────────────┤
│ select count(case  │
│ when a=0 then 1    │
│ when a=1 then 1    │
│ when a=2 then 1    │
│ when a=3 then 1    │
└────────────────────┘
```

v0.3.1-dev705 b77704c86 is right when second select is from range(2)
wrong when range(2000)
```
D SELECT 'select count(case 'a union all select 'when a='||range||' then 1 ' from range(2) union all select 'end) from t';
┌────────────────────┐
│         a          │
├────────────────────┤
│ select count(case  │
│ when a=0 then 1    │
│ when a=1 then 1    │
│ end) from t        │
└────────────────────┘

D select * from(SELECT 'select count(case 'a union all select 'when a='||range||' then 1 ' from range(2000) union all select 'end) from t')limit 5;
┌────────────────────┐
│         a          │
├────────────────────┤
│ select count(case  │
│ end) from t        │
│ when a=0 then 1    │
│ when a=1 then 1    │
│ when a=2 then 1    │
└────────────────────┘
```
		

#### Environment (please complete the following information):
 - OS: [e.g. iOS]
 - DuckDB Version: [e.g. 22]0.3.1-dev 705
 - DuckDB Client: [e.g. Python]

#### Before Submitting

- [x ] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x ] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**
 

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16: </p>
17: 
18: ## DuckDB
19: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/docs/why_duckdb.html).
20: 
21: ## Installation
22: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
23: 
24: ## Data Import
25: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
26: 
27: ```sql
28: SELECT * FROM 'myfile.csv';
29: SELECT * FROM 'myfile.parquet';
30: ```
31: 
32: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
33: 
34: ## SQL Reference
35: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
36: 
37: ## Development
38: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
39: 
40: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
41: 
42: 
[end of README.md]
[start of src/include/duckdb/execution/executor.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/execution/executor.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/common.hpp"
12: #include "duckdb/common/mutex.hpp"
13: #include "duckdb/parallel/pipeline.hpp"
14: #include "duckdb/common/unordered_map.hpp"
15: #include "duckdb/common/pair.hpp"
16: 
17: namespace duckdb {
18: class ClientContext;
19: class DataChunk;
20: class PhysicalOperator;
21: class PipelineExecutor;
22: class OperatorState;
23: class ThreadContext;
24: class Task;
25: 
26: struct PipelineEventStack;
27: struct ProducerToken;
28: 
29: class Executor {
30: 	friend class Pipeline;
31: 	friend class PipelineTask;
32: 
33: public:
34: 	explicit Executor(ClientContext &context);
35: 	~Executor();
36: 
37: 	ClientContext &context;
38: 
39: public:
40: 	static Executor &Get(ClientContext &context);
41: 
42: 	void Initialize(PhysicalOperator *physical_plan);
43: 	void BuildPipelines(PhysicalOperator *op, Pipeline *current);
44: 
45: 	void Reset();
46: 
47: 	vector<LogicalType> GetTypes();
48: 
49: 	unique_ptr<DataChunk> FetchChunk();
50: 
51: 	//! Push a new error
52: 	void PushError(ExceptionType type, const string &exception);
53: 	//! True if an error has been thrown
54: 	bool HasError();
55: 	//! Throw the exception that was pushed using PushError.
56: 	//! Should only be called if HasError returns true
57: 	void ThrowException();
58: 
59: 	//! Work on tasks for this specific executor, until there are no tasks remaining
60: 	void WorkOnTasks();
61: 
62: 	//! Flush a thread context into the client context
63: 	void Flush(ThreadContext &context);
64: 
65: 	//! Returns the progress of the pipelines
66: 	bool GetPipelinesProgress(int &current_progress);
67: 
68: 	void CompletePipeline() {
69: 		completed_pipelines++;
70: 	}
71: 	ProducerToken &GetToken() {
72: 		return *producer;
73: 	}
74: 	void AddEvent(shared_ptr<Event> event);
75: 
76: 	void ReschedulePipelines(const vector<shared_ptr<Pipeline>> &pipelines, vector<shared_ptr<Event>> &events);
77: 
78: private:
79: 	void ScheduleEvents();
80: 	void ScheduleEventsInternal(const vector<shared_ptr<Pipeline>> &pipelines,
81: 	                            unordered_map<Pipeline *, vector<shared_ptr<Pipeline>>> &child_pipelines,
82: 	                            vector<shared_ptr<Event>> &events, bool main_schedule = true);
83: 
84: 	void SchedulePipeline(const shared_ptr<Pipeline> &pipeline,
85: 	                      unordered_map<Pipeline *, PipelineEventStack> &event_map, vector<shared_ptr<Event>> &events,
86: 	                      bool complete_pipeline);
87: 	void ScheduleUnionPipeline(const shared_ptr<Pipeline> &pipeline, PipelineEventStack &stack,
88: 	                           unordered_map<Pipeline *, PipelineEventStack> &event_map,
89: 	                           vector<shared_ptr<Event>> &events);
90: 	void ScheduleChildPipeline(Pipeline *parent, const shared_ptr<Pipeline> &pipeline,
91: 	                           unordered_map<Pipeline *, PipelineEventStack> &event_map,
92: 	                           vector<shared_ptr<Event>> &events);
93: 	void ExtractPipelines(shared_ptr<Pipeline> &pipeline, vector<shared_ptr<Pipeline>> &result);
94: 	bool NextExecutor();
95: 
96: 	void AddChildPipeline(Pipeline *current);
97: 
98: 	void VerifyPipeline(Pipeline &pipeline);
99: 	void VerifyPipelines();
100: 	void ThrowExceptionInternal();
101: 
102: private:
103: 	PhysicalOperator *physical_plan;
104: 
105: 	mutex executor_lock;
106: 	//! The pipelines of the current query
107: 	vector<shared_ptr<Pipeline>> pipelines;
108: 	//! The root pipeline of the query
109: 	vector<shared_ptr<Pipeline>> root_pipelines;
110: 	//! The pipeline executor for the root pipeline
111: 	unique_ptr<PipelineExecutor> root_executor;
112: 	//! The current root pipeline index
113: 	idx_t root_pipeline_idx;
114: 	//! The producer of this query
115: 	unique_ptr<ProducerToken> producer;
116: 	//! Exceptions that occurred during the execution of the current query
117: 	vector<pair<ExceptionType, string>> exceptions;
118: 	//! List of events
119: 	vector<shared_ptr<Event>> events;
120: 
121: 	//! The amount of completed pipelines of the query
122: 	atomic<idx_t> completed_pipelines;
123: 	//! The total amount of pipelines in the query
124: 	idx_t total_pipelines;
125: 
126: 	//! The adjacent union pipelines of each pipeline
127: 	//! Union pipelines have the same sink, but can be run concurrently along with this pipeline
128: 	unordered_map<Pipeline *, vector<shared_ptr<Pipeline>>> union_pipelines;
129: 	//! Child pipelines of this pipeline
130: 	//! Like union pipelines, child pipelines share the same sink
131: 	//! Unlike union pipelines, child pipelines should be run AFTER their dependencies are completed
132: 	//! i.e. they should be run after the dependencies are completed, but before finalize is called on the sink
133: 	unordered_map<Pipeline *, vector<shared_ptr<Pipeline>>> child_pipelines;
134: 	//! Dependencies of child pipelines
135: 	unordered_map<Pipeline *, vector<Pipeline *>> child_dependencies;
136: 
137: 	//! Duplicate eliminated join scan dependencies
138: 	unordered_map<PhysicalOperator *, Pipeline *> delim_join_dependencies;
139: 
140: 	//! Active recursive CTE node (if any)
141: 	PhysicalOperator *recursive_cte;
142: };
143: } // namespace duckdb
[end of src/include/duckdb/execution/executor.hpp]
[start of src/parallel/executor.cpp]
1: #include "duckdb/execution/executor.hpp"
2: 
3: #include "duckdb/execution/operator/helper/physical_execute.hpp"
4: #include "duckdb/execution/operator/join/physical_delim_join.hpp"
5: #include "duckdb/execution/operator/scan/physical_chunk_scan.hpp"
6: #include "duckdb/execution/operator/set/physical_recursive_cte.hpp"
7: #include "duckdb/execution/physical_operator.hpp"
8: #include "duckdb/main/client_context.hpp"
9: #include "duckdb/execution/execution_context.hpp"
10: #include "duckdb/parallel/thread_context.hpp"
11: #include "duckdb/parallel/task_scheduler.hpp"
12: #include "duckdb/parallel/pipeline_executor.hpp"
13: 
14: #include "duckdb/parallel/pipeline_event.hpp"
15: #include "duckdb/parallel/pipeline_finish_event.hpp"
16: #include "duckdb/parallel/pipeline_complete_event.hpp"
17: 
18: #include <algorithm>
19: 
20: namespace duckdb {
21: 
22: Executor::Executor(ClientContext &context) : context(context) {
23: }
24: 
25: Executor::~Executor() {
26: }
27: 
28: Executor &Executor::Get(ClientContext &context) {
29: 	return context.executor;
30: }
31: 
32: void Executor::AddEvent(shared_ptr<Event> event) {
33: 	lock_guard<mutex> elock(executor_lock);
34: 	events.push_back(move(event));
35: }
36: 
37: struct PipelineEventStack {
38: 	Event *pipeline_event;
39: 	Event *pipeline_finish_event;
40: 	Event *pipeline_complete_event;
41: };
42: 
43: void Executor::ScheduleUnionPipeline(const shared_ptr<Pipeline> &pipeline, PipelineEventStack &parent_stack,
44:                                      unordered_map<Pipeline *, PipelineEventStack> &event_map,
45:                                      vector<shared_ptr<Event>> &events) {
46: 	pipeline->Ready();
47: 
48: 	D_ASSERT(pipeline);
49: 	auto pipeline_event = make_shared<PipelineEvent>(pipeline);
50: 
51: 	PipelineEventStack stack;
52: 	stack.pipeline_event = pipeline_event.get();
53: 	stack.pipeline_finish_event = parent_stack.pipeline_finish_event;
54: 	stack.pipeline_complete_event = parent_stack.pipeline_complete_event;
55: 
56: 	stack.pipeline_event->AddDependency(*parent_stack.pipeline_event);
57: 	parent_stack.pipeline_finish_event->AddDependency(*pipeline_event);
58: 
59: 	events.push_back(move(pipeline_event));
60: 
61: 	auto union_entry = union_pipelines.find(pipeline.get());
62: 	if (union_entry != union_pipelines.end()) {
63: 		for (auto &entry : union_entry->second) {
64: 			ScheduleUnionPipeline(entry, parent_stack, event_map, events);
65: 		}
66: 	}
67: 	event_map.insert(make_pair(pipeline.get(), stack));
68: }
69: 
70: void Executor::ScheduleChildPipeline(Pipeline *parent, const shared_ptr<Pipeline> &pipeline,
71:                                      unordered_map<Pipeline *, PipelineEventStack> &event_map,
72:                                      vector<shared_ptr<Event>> &events) {
73: 	pipeline->Ready();
74: 
75: 	auto child_ptr = pipeline.get();
76: 	auto dependencies = child_dependencies.find(child_ptr);
77: 	D_ASSERT(union_pipelines.find(child_ptr) == union_pipelines.end());
78: 	D_ASSERT(dependencies != child_dependencies.end());
79: 	// create the pipeline event and the event stack
80: 	auto pipeline_event = make_shared<PipelineEvent>(pipeline);
81: 
82: 	auto parent_entry = event_map.find(parent);
83: 	PipelineEventStack stack;
84: 	stack.pipeline_event = pipeline_event.get();
85: 	stack.pipeline_finish_event = parent_entry->second.pipeline_finish_event;
86: 	stack.pipeline_complete_event = parent_entry->second.pipeline_complete_event;
87: 
88: 	// set up the dependencies for this child pipeline
89: 	unordered_set<Event *> finish_events;
90: 	for (auto &dep : dependencies->second) {
91: 		auto dep_entry = event_map.find(dep);
92: 		D_ASSERT(dep_entry != event_map.end());
93: 		D_ASSERT(dep_entry->second.pipeline_event);
94: 		D_ASSERT(dep_entry->second.pipeline_finish_event);
95: 
96: 		auto finish_event = dep_entry->second.pipeline_finish_event;
97: 		stack.pipeline_event->AddDependency(*dep_entry->second.pipeline_event);
98: 		if (finish_events.find(finish_event) == finish_events.end()) {
99: 			finish_event->AddDependency(*stack.pipeline_event);
100: 			finish_events.insert(finish_event);
101: 		}
102: 	}
103: 
104: 	events.push_back(move(pipeline_event));
105: 
106: 	event_map.insert(make_pair(child_ptr, stack));
107: }
108: 
109: void Executor::SchedulePipeline(const shared_ptr<Pipeline> &pipeline,
110:                                 unordered_map<Pipeline *, PipelineEventStack> &event_map,
111:                                 vector<shared_ptr<Event>> &events, bool complete_pipeline) {
112: 	D_ASSERT(pipeline);
113: 
114: 	pipeline->Ready();
115: 
116: 	auto pipeline_event = make_shared<PipelineEvent>(pipeline);
117: 	auto pipeline_finish_event = make_shared<PipelineFinishEvent>(pipeline);
118: 	auto pipeline_complete_event = make_shared<PipelineCompleteEvent>(pipeline->executor, complete_pipeline);
119: 
120: 	PipelineEventStack stack;
121: 	stack.pipeline_event = pipeline_event.get();
122: 	stack.pipeline_finish_event = pipeline_finish_event.get();
123: 	stack.pipeline_complete_event = pipeline_complete_event.get();
124: 
125: 	pipeline_finish_event->AddDependency(*pipeline_event);
126: 	pipeline_complete_event->AddDependency(*pipeline_finish_event);
127: 
128: 	events.push_back(move(pipeline_event));
129: 	events.push_back(move(pipeline_finish_event));
130: 	events.push_back(move(pipeline_complete_event));
131: 
132: 	auto union_entry = union_pipelines.find(pipeline.get());
133: 	if (union_entry != union_pipelines.end()) {
134: 		for (auto &entry : union_entry->second) {
135: 			ScheduleUnionPipeline(entry, stack, event_map, events);
136: 		}
137: 	}
138: 	event_map.insert(make_pair(pipeline.get(), stack));
139: }
140: 
141: void Executor::ScheduleEventsInternal(const vector<shared_ptr<Pipeline>> &pipelines,
142:                                       unordered_map<Pipeline *, vector<shared_ptr<Pipeline>>> &child_pipelines,
143:                                       vector<shared_ptr<Event>> &events, bool main_schedule) {
144: 	D_ASSERT(events.empty());
145: 	// create all the required pipeline events
146: 	unordered_map<Pipeline *, PipelineEventStack> event_map;
147: 	for (auto &pipeline : pipelines) {
148: 		SchedulePipeline(pipeline, event_map, events, main_schedule);
149: 	}
150: 	// schedule child pipelines
151: 	for (auto &entry : child_pipelines) {
152: 		// iterate in reverse order
153: 		// since child entries are added from top to bottom
154: 		// dependencies are in reverse order (bottom to top)
155: 		for (idx_t i = entry.second.size(); i > 0; i--) {
156: 			auto &child_entry = entry.second[i - 1];
157: 			ScheduleChildPipeline(entry.first, child_entry, event_map, events);
158: 		}
159: 	}
160: 	// set up the dependencies between pipeline events
161: 	for (auto &entry : event_map) {
162: 		auto pipeline = entry.first;
163: 		for (auto &dependency : pipeline->dependencies) {
164: 			auto dep = dependency.lock();
165: 			D_ASSERT(dep);
166: 			auto event_map_entry = event_map.find(dep.get());
167: 			D_ASSERT(event_map_entry != event_map.end());
168: 			auto &dep_entry = event_map_entry->second;
169: 			D_ASSERT(dep_entry.pipeline_complete_event);
170: 			entry.second.pipeline_event->AddDependency(*dep_entry.pipeline_complete_event);
171: 		}
172: 	}
173: 	// schedule the pipelines that do not have dependencies
174: 	for (auto &event : events) {
175: 		if (!event->HasDependencies()) {
176: 			event->Schedule();
177: 		}
178: 	}
179: }
180: 
181: void Executor::ScheduleEvents() {
182: 	ScheduleEventsInternal(pipelines, child_pipelines, events);
183: }
184: 
185: void Executor::ReschedulePipelines(const vector<shared_ptr<Pipeline>> &pipelines, vector<shared_ptr<Event>> &events) {
186: 	unordered_map<Pipeline *, vector<shared_ptr<Pipeline>>> child_pipelines;
187: 	ScheduleEventsInternal(pipelines, child_pipelines, events, false);
188: }
189: 
190: void Executor::ExtractPipelines(shared_ptr<Pipeline> &pipeline, vector<shared_ptr<Pipeline>> &result) {
191: 	pipeline->Ready();
192: 
193: 	auto pipeline_ptr = pipeline.get();
194: 	result.push_back(move(pipeline));
195: 	auto union_entry = union_pipelines.find(pipeline_ptr);
196: 	if (union_entry != union_pipelines.end()) {
197: 		auto &union_pipeline_list = union_entry->second;
198: 		for (auto &pipeline : union_pipeline_list) {
199: 			ExtractPipelines(pipeline, result);
200: 		}
201: 		union_pipelines.erase(pipeline_ptr);
202: 	}
203: 	auto child_entry = child_pipelines.find(pipeline_ptr);
204: 	if (child_entry != child_pipelines.end()) {
205: 		for (auto &entry : child_entry->second) {
206: 			ExtractPipelines(entry, result);
207: 		}
208: 		child_pipelines.erase(pipeline_ptr);
209: 	}
210: }
211: 
212: bool Executor::NextExecutor() {
213: 	if (root_pipeline_idx >= root_pipelines.size()) {
214: 		return false;
215: 	}
216: 	root_executor = make_unique<PipelineExecutor>(context, *root_pipelines[root_pipeline_idx]);
217: 	root_pipeline_idx++;
218: 	return true;
219: }
220: 
221: void Executor::VerifyPipeline(Pipeline &pipeline) {
222: 	D_ASSERT(!pipeline.ToString().empty());
223: 	auto operators = pipeline.GetOperators();
224: 	for (auto &other_pipeline : pipelines) {
225: 		auto other_operators = other_pipeline->GetOperators();
226: 		for (idx_t op_idx = 0; op_idx < operators.size(); op_idx++) {
227: 			for (idx_t other_idx = 0; other_idx < other_operators.size(); other_idx++) {
228: 				auto &left = *operators[op_idx];
229: 				auto &right = *other_operators[other_idx];
230: 				if (left.Equals(right)) {
231: 					D_ASSERT(right.Equals(left));
232: 				} else {
233: 					D_ASSERT(!right.Equals(left));
234: 				}
235: 			}
236: 		}
237: 	}
238: }
239: 
240: void Executor::VerifyPipelines() {
241: #ifdef DEBUG
242: 	for (auto &pipeline : pipelines) {
243: 		VerifyPipeline(*pipeline);
244: 	}
245: 	for (auto &pipeline : root_pipelines) {
246: 		VerifyPipeline(*pipeline);
247: 	}
248: #endif
249: }
250: 
251: void Executor::WorkOnTasks() {
252: 	auto &scheduler = TaskScheduler::GetScheduler(context);
253: 
254: 	unique_ptr<Task> task;
255: 	while (scheduler.GetTaskFromProducer(*producer, task)) {
256: 		task->Execute();
257: 		task.reset();
258: 	}
259: }
260: 
261: void Executor::Initialize(PhysicalOperator *plan) {
262: 	Reset();
263: 
264: 	auto &scheduler = TaskScheduler::GetScheduler(context);
265: 	{
266: 		lock_guard<mutex> elock(executor_lock);
267: 		physical_plan = plan;
268: 
269: 		context.profiler->Initialize(physical_plan);
270: 		this->producer = scheduler.CreateProducer();
271: 
272: 		auto root_pipeline = make_shared<Pipeline>(*this);
273: 		root_pipeline->sink = nullptr;
274: 		BuildPipelines(physical_plan, root_pipeline.get());
275: 
276: 		this->total_pipelines = pipelines.size();
277: 
278: 		root_pipeline_idx = 0;
279: 		ExtractPipelines(root_pipeline, root_pipelines);
280: 
281: 		VerifyPipelines();
282: 
283: 		ScheduleEvents();
284: 	}
285: 
286: 	// now execute tasks from this producer until all pipelines are completed
287: 	while (completed_pipelines < total_pipelines) {
288: 		WorkOnTasks();
289: 		if (!HasError()) {
290: 			// no exceptions: continue
291: 			continue;
292: 		}
293: 
294: 		// an exception has occurred executing one of the pipelines
295: 		// we need to wait until all threads are finished
296: 		// we do this by creating weak pointers to all pipelines
297: 		// then clearing our references to the pipelines
298: 		// and waiting until all pipelines have been destroyed
299: 		vector<weak_ptr<Pipeline>> weak_references;
300: 		{
301: 			lock_guard<mutex> elock(executor_lock);
302: 			weak_references.reserve(pipelines.size());
303: 			for (auto &pipeline : pipelines) {
304: 				weak_references.push_back(weak_ptr<Pipeline>(pipeline));
305: 			}
306: 			for (auto &kv : union_pipelines) {
307: 				for (auto &pipeline : kv.second) {
308: 					weak_references.push_back(weak_ptr<Pipeline>(pipeline));
309: 				}
310: 			}
311: 			for (auto &kv : child_pipelines) {
312: 				for (auto &pipeline : kv.second) {
313: 					weak_references.push_back(weak_ptr<Pipeline>(pipeline));
314: 				}
315: 			}
316: 			pipelines.clear();
317: 			union_pipelines.clear();
318: 			child_pipelines.clear();
319: 			events.clear();
320: 		}
321: 		for (auto &weak_ref : weak_references) {
322: 			while (true) {
323: 				auto weak = weak_ref.lock();
324: 				if (!weak) {
325: 					break;
326: 				}
327: 			}
328: 		}
329: 		ThrowException();
330: 	}
331: 
332: 	lock_guard<mutex> elock(executor_lock);
333: 	pipelines.clear();
334: 	NextExecutor();
335: 	if (!exceptions.empty()) { // LCOV_EXCL_START
336: 		// an exception has occurred executing one of the pipelines
337: 		ThrowExceptionInternal();
338: 	} // LCOV_EXCL_STOP
339: }
340: 
341: void Executor::Reset() {
342: 	lock_guard<mutex> elock(executor_lock);
343: 	delim_join_dependencies.clear();
344: 	recursive_cte = nullptr;
345: 	physical_plan = nullptr;
346: 	root_executor.reset();
347: 	root_pipelines.clear();
348: 	root_pipeline_idx = 0;
349: 	completed_pipelines = 0;
350: 	total_pipelines = 0;
351: 	exceptions.clear();
352: 	pipelines.clear();
353: 	events.clear();
354: 	union_pipelines.clear();
355: 	child_pipelines.clear();
356: 	child_dependencies.clear();
357: }
358: 
359: void Executor::AddChildPipeline(Pipeline *current) {
360: 	D_ASSERT(!current->operators.empty());
361: 	// found another operator that is a source
362: 	// schedule a child pipeline
363: 	auto child_pipeline = make_shared<Pipeline>(*this);
364: 	auto child_pipeline_ptr = child_pipeline.get();
365: 	child_pipeline->sink = current->sink;
366: 	child_pipeline->operators = current->operators;
367: 	child_pipeline->source = current->operators.back();
368: 	D_ASSERT(child_pipeline->source->IsSource());
369: 	child_pipeline->operators.pop_back();
370: 
371: 	vector<Pipeline *> dependencies;
372: 	dependencies.push_back(current);
373: 	auto child_entry = child_pipelines.find(current);
374: 	if (child_entry != child_pipelines.end()) {
375: 		for (auto &current_child : child_entry->second) {
376: 			D_ASSERT(child_dependencies.find(current_child.get()) != child_dependencies.end());
377: 			child_dependencies[current_child.get()].push_back(child_pipeline_ptr);
378: 		}
379: 	}
380: 	D_ASSERT(child_dependencies.find(child_pipeline_ptr) == child_dependencies.end());
381: 	child_dependencies.insert(make_pair(child_pipeline_ptr, move(dependencies)));
382: 	child_pipelines[current].push_back(move(child_pipeline));
383: }
384: 
385: void Executor::BuildPipelines(PhysicalOperator *op, Pipeline *current) {
386: 	D_ASSERT(current);
387: 	if (op->IsSink()) {
388: 		// operator is a sink, build a pipeline
389: 		op->sink_state.reset();
390: 
391: 		PhysicalOperator *pipeline_child = nullptr;
392: 		switch (op->type) {
393: 		case PhysicalOperatorType::CREATE_TABLE_AS:
394: 		case PhysicalOperatorType::INSERT:
395: 		case PhysicalOperatorType::DELETE_OPERATOR:
396: 		case PhysicalOperatorType::UPDATE:
397: 		case PhysicalOperatorType::HASH_GROUP_BY:
398: 		case PhysicalOperatorType::SIMPLE_AGGREGATE:
399: 		case PhysicalOperatorType::PERFECT_HASH_GROUP_BY:
400: 		case PhysicalOperatorType::WINDOW:
401: 		case PhysicalOperatorType::ORDER_BY:
402: 		case PhysicalOperatorType::RESERVOIR_SAMPLE:
403: 		case PhysicalOperatorType::TOP_N:
404: 		case PhysicalOperatorType::COPY_TO_FILE:
405: 		case PhysicalOperatorType::LIMIT:
406: 		case PhysicalOperatorType::EXPRESSION_SCAN:
407: 			D_ASSERT(op->children.size() == 1);
408: 			// single operator:
409: 			// the operator becomes the data source of the current pipeline
410: 			current->source = op;
411: 			// we create a new pipeline starting from the child
412: 			pipeline_child = op->children[0].get();
413: 			break;
414: 		case PhysicalOperatorType::EXPORT:
415: 			// EXPORT has an optional child
416: 			// we only need to schedule child pipelines if there is a child
417: 			current->source = op;
418: 			if (op->children.empty()) {
419: 				return;
420: 			}
421: 			D_ASSERT(op->children.size() == 1);
422: 			pipeline_child = op->children[0].get();
423: 			break;
424: 		case PhysicalOperatorType::NESTED_LOOP_JOIN:
425: 		case PhysicalOperatorType::BLOCKWISE_NL_JOIN:
426: 		case PhysicalOperatorType::HASH_JOIN:
427: 		case PhysicalOperatorType::PIECEWISE_MERGE_JOIN:
428: 		case PhysicalOperatorType::CROSS_PRODUCT:
429: 			// regular join, create a pipeline with RHS source that sinks into this pipeline
430: 			pipeline_child = op->children[1].get();
431: 			// on the LHS (probe child), the operator becomes a regular operator
432: 			current->operators.push_back(op);
433: 			if (op->IsSource()) {
434: 				// FULL or RIGHT outer join
435: 				// schedule a scan of the node as a child pipeline
436: 				// this scan has to be performed AFTER all the probing has happened
437: 				if (recursive_cte) {
438: 					throw NotImplementedException("FULL and RIGHT outer joins are not supported in recursive CTEs yet");
439: 				}
440: 				AddChildPipeline(current);
441: 			}
442: 			BuildPipelines(op->children[0].get(), current);
443: 			break;
444: 		case PhysicalOperatorType::DELIM_JOIN: {
445: 			// duplicate eliminated join
446: 			// for delim joins, recurse into the actual join
447: 			pipeline_child = op->children[0].get();
448: 			break;
449: 		}
450: 		case PhysicalOperatorType::RECURSIVE_CTE: {
451: 			auto &cte_node = (PhysicalRecursiveCTE &)*op;
452: 
453: 			// recursive CTE
454: 			current->source = op;
455: 			// the LHS of the recursive CTE is our initial state
456: 			// we build this pipeline as normal
457: 			pipeline_child = op->children[0].get();
458: 			// for the RHS, we gather all pipelines that depend on the recursive cte
459: 			// these pipelines need to be rerun
460: 			if (recursive_cte) {
461: 				throw InternalException("Recursive CTE detected WITHIN a recursive CTE node");
462: 			}
463: 			recursive_cte = op;
464: 
465: 			auto recursive_pipeline = make_shared<Pipeline>(*this);
466: 			recursive_pipeline->sink = op;
467: 			op->sink_state.reset();
468: 			BuildPipelines(op->children[1].get(), recursive_pipeline.get());
469: 
470: 			cte_node.pipelines.push_back(move(recursive_pipeline));
471: 
472: 			recursive_cte = nullptr;
473: 			break;
474: 		}
475: 		default:
476: 			throw InternalException("Unimplemented sink type!");
477: 		}
478: 		// the current is dependent on this pipeline to complete
479: 		auto pipeline = make_shared<Pipeline>(*this);
480: 		pipeline->sink = op;
481: 		current->AddDependency(pipeline);
482: 		D_ASSERT(pipeline_child);
483: 		// recurse into the pipeline child
484: 		BuildPipelines(pipeline_child, pipeline.get());
485: 		if (op->type == PhysicalOperatorType::DELIM_JOIN) {
486: 			// for delim joins, recurse into the actual join
487: 			// any pipelines in there depend on the main pipeline
488: 			auto &delim_join = (PhysicalDelimJoin &)*op;
489: 			// any scan of the duplicate eliminated data on the RHS depends on this pipeline
490: 			// we add an entry to the mapping of (PhysicalOperator*) -> (Pipeline*)
491: 			for (auto &delim_scan : delim_join.delim_scans) {
492: 				delim_join_dependencies[delim_scan] = pipeline.get();
493: 			}
494: 			BuildPipelines(delim_join.join.get(), current);
495: 		}
496: 		if (!recursive_cte) {
497: 			// regular pipeline: schedule it
498: 			pipelines.push_back(move(pipeline));
499: 		} else {
500: 			// CTE pipeline! add it to the CTE pipelines
501: 			D_ASSERT(recursive_cte);
502: 			auto &cte = (PhysicalRecursiveCTE &)*recursive_cte;
503: 			cte.pipelines.push_back(move(pipeline));
504: 		}
505: 	} else {
506: 		// operator is not a sink! recurse in children
507: 		// first check if there is any additional action we need to do depending on the type
508: 		switch (op->type) {
509: 		case PhysicalOperatorType::DELIM_SCAN: {
510: 			D_ASSERT(op->children.empty());
511: 			auto entry = delim_join_dependencies.find(op);
512: 			D_ASSERT(entry != delim_join_dependencies.end());
513: 			// this chunk scan introduces a dependency to the current pipeline
514: 			// namely a dependency on the duplicate elimination pipeline to finish
515: 			auto delim_dependency = entry->second->shared_from_this();
516: 			D_ASSERT(delim_dependency->sink->type == PhysicalOperatorType::DELIM_JOIN);
517: 			auto &delim_join = (PhysicalDelimJoin &)*delim_dependency->sink;
518: 			current->AddDependency(delim_dependency);
519: 			current->source = (PhysicalOperator *)delim_join.distinct.get();
520: 			return;
521: 		}
522: 		case PhysicalOperatorType::EXECUTE: {
523: 			// EXECUTE statement: build pipeline on child
524: 			auto &execute = (PhysicalExecute &)*op;
525: 			BuildPipelines(execute.plan, current);
526: 			return;
527: 		}
528: 		case PhysicalOperatorType::RECURSIVE_CTE_SCAN: {
529: 			if (!recursive_cte) {
530: 				throw InternalException("Recursive CTE scan found without recursive CTE node");
531: 			}
532: 			break;
533: 		}
534: 		case PhysicalOperatorType::INDEX_JOIN: {
535: 			// index join: we only continue into the LHS
536: 			// the right side is probed by the index join
537: 			// so we don't need to do anything in the pipeline with this child
538: 			current->operators.push_back(op);
539: 			BuildPipelines(op->children[0].get(), current);
540: 			return;
541: 		}
542: 		case PhysicalOperatorType::UNION: {
543: 			if (recursive_cte) {
544: 				throw NotImplementedException("UNIONS are not supported in recursive CTEs yet");
545: 			}
546: 			auto union_pipeline = make_shared<Pipeline>(*this);
547: 			auto pipeline_ptr = union_pipeline.get();
548: 			// set up dependencies for any child pipelines to this union pipeline
549: 			auto child_entry = child_pipelines.find(current);
550: 			if (child_entry != child_pipelines.end()) {
551: 				for (auto &current_child : child_entry->second) {
552: 					D_ASSERT(child_dependencies.find(current_child.get()) != child_dependencies.end());
553: 					child_dependencies[current_child.get()].push_back(pipeline_ptr);
554: 				}
555: 			}
556: 			// for the current pipeline, continue building on the LHS
557: 			union_pipeline->operators = current->operators;
558: 			BuildPipelines(op->children[0].get(), current);
559: 			// insert the union pipeline as a union pipeline of the current node
560: 			union_pipelines[current].push_back(move(union_pipeline));
561: 
562: 			// for the union pipeline, build on the RHS
563: 			pipeline_ptr->sink = current->sink;
564: 			BuildPipelines(op->children[1].get(), pipeline_ptr);
565: 			return;
566: 		}
567: 		default:
568: 			break;
569: 		}
570: 		if (op->children.empty()) {
571: 			// source
572: 			current->source = op;
573: 		} else {
574: 			if (op->children.size() != 1) {
575: 				throw InternalException("Operator not supported yet");
576: 			}
577: 			current->operators.push_back(op);
578: 			BuildPipelines(op->children[0].get(), current);
579: 		}
580: 	}
581: }
582: 
583: vector<LogicalType> Executor::GetTypes() {
584: 	D_ASSERT(physical_plan);
585: 	return physical_plan->GetTypes();
586: }
587: 
588: void Executor::PushError(ExceptionType type, const string &exception) {
589: 	lock_guard<mutex> elock(executor_lock);
590: 	// interrupt execution of any other pipelines that belong to this executor
591: 	context.interrupted = true;
592: 	// push the exception onto the stack
593: 	exceptions.emplace_back(type, exception);
594: }
595: 
596: bool Executor::HasError() {
597: 	lock_guard<mutex> elock(executor_lock);
598: 	return !exceptions.empty();
599: }
600: 
601: void Executor::ThrowException() {
602: 	lock_guard<mutex> elock(executor_lock);
603: 	ThrowExceptionInternal();
604: }
605: 
606: void Executor::ThrowExceptionInternal() { // LCOV_EXCL_START
607: 	D_ASSERT(!exceptions.empty());
608: 	auto &entry = exceptions[0];
609: 	switch (entry.first) {
610: 	case ExceptionType::TRANSACTION:
611: 		throw TransactionException(entry.second);
612: 	case ExceptionType::CATALOG:
613: 		throw CatalogException(entry.second);
614: 	case ExceptionType::PARSER:
615: 		throw ParserException(entry.second);
616: 	case ExceptionType::BINDER:
617: 		throw BinderException(entry.second);
618: 	case ExceptionType::INTERRUPT:
619: 		throw InterruptException();
620: 	case ExceptionType::FATAL:
621: 		throw FatalException(entry.second);
622: 	case ExceptionType::INTERNAL:
623: 		throw InternalException(entry.second);
624: 	case ExceptionType::IO:
625: 		throw IOException(entry.second);
626: 	case ExceptionType::CONSTRAINT:
627: 		throw ConstraintException(entry.second);
628: 	case ExceptionType::CONVERSION:
629: 		throw ConversionException(entry.second);
630: 	default:
631: 		throw Exception(entry.second);
632: 	}
633: } // LCOV_EXCL_STOP
634: 
635: void Executor::Flush(ThreadContext &tcontext) {
636: 	lock_guard<mutex> elock(executor_lock);
637: 	context.profiler->Flush(tcontext.profiler);
638: }
639: 
640: bool Executor::GetPipelinesProgress(int &current_progress) { // LCOV_EXCL_START
641: 	lock_guard<mutex> elock(executor_lock);
642: 
643: 	if (!pipelines.empty()) {
644: 		return pipelines.back()->GetProgress(current_progress);
645: 	} else {
646: 		current_progress = -1;
647: 		return true;
648: 	}
649: } // LCOV_EXCL_STOP
650: 
651: unique_ptr<DataChunk> Executor::FetchChunk() {
652: 	D_ASSERT(physical_plan);
653: 
654: 	auto chunk = make_unique<DataChunk>();
655: 	root_executor->InitializeChunk(*chunk);
656: 	while (true) {
657: 		root_executor->ExecutePull(*chunk);
658: 		if (chunk->size() == 0) {
659: 			root_executor->PullFinalize();
660: 			if (NextExecutor()) {
661: 				continue;
662: 			}
663: 			break;
664: 		} else {
665: 			break;
666: 		}
667: 	}
668: 	return chunk;
669: }
670: 
671: } // namespace duckdb
[end of src/parallel/executor.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: