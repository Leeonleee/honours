{
  "repo": "duckdb/duckdb",
  "pull_number": 13761,
  "instance_id": "duckdb__duckdb-13761",
  "issue_numbers": [
    "13725",
    "13725"
  ],
  "base_commit": "a6e32b115826ba543e32a733cb92f68fd0549186",
  "patch": "diff --git a/extension/json/json_functions/read_json_objects.cpp b/extension/json/json_functions/read_json_objects.cpp\nindex 46d4e7982f88..7e97b64717b2 100644\n--- a/extension/json/json_functions/read_json_objects.cpp\n+++ b/extension/json/json_functions/read_json_objects.cpp\n@@ -33,8 +33,9 @@ static void ReadJSONObjectsFunction(ClientContext &context, TableFunctionInput &\n \n \tif (!gstate.names.empty()) {\n \t\t// Create the strings without copying them\n-\t\tauto strings = FlatVector::GetData<string_t>(output.data[0]);\n-\t\tauto &validity = FlatVector::Validity(output.data[0]);\n+\t\tconst auto col_idx = gstate.column_indices[0];\n+\t\tauto strings = FlatVector::GetData<string_t>(output.data[col_idx]);\n+\t\tauto &validity = FlatVector::Validity(output.data[col_idx]);\n \t\tfor (idx_t i = 0; i < count; i++) {\n \t\t\tif (objects[i]) {\n \t\t\t\tstrings[i] = string_t(units[i].pointer, units[i].size);\n",
  "test_patch": "diff --git a/data/json/13725/month=07/mytest.json b/data/json/13725/month=07/mytest.json\nnew file mode 100644\nindex 000000000000..e9d008e5d983\n--- /dev/null\n+++ b/data/json/13725/month=07/mytest.json\n@@ -0,0 +1,1 @@\n+{\"hello\": \"there\"}\ndiff --git a/test/sql/json/issues/issue13725.test b/test/sql/json/issues/issue13725.test\nnew file mode 100644\nindex 000000000000..62664f600995\n--- /dev/null\n+++ b/test/sql/json/issues/issue13725.test\n@@ -0,0 +1,36 @@\n+# name: test/sql/json/issues/issue13725.test\n+# description: Test issue 13725 - Using both hive_partitioning and hive_types in read_json_objects intermittently segfaults\n+# group: [issues]\n+\n+require json\n+\n+# path slashes\n+require notwindows\n+\n+query III\n+select *\n+from read_json_objects('data/json/13725/month=*/*.json', hive_partitioning = true, format = auto, hive_types = {'month': int}, filename = true)\n+where month = 7;\n+----\n+{\"hello\": \"there\"}\tdata/json/13725/month=07/mytest.json\t7\n+\n+query I\n+select count(*)\n+from read_json_objects('data/json/13725/month=*/*.json', hive_partitioning = true, format = auto, hive_types = {'month': int}, filename = true)\n+where month = 7;\n+----\n+1\n+\n+query III\n+select *\n+from read_json('data/json/13725/month=*/*.json', hive_partitioning = true, format = auto, hive_types = {'month': int}, filename = true)\n+where month = 7;\n+----\n+there\tdata/json/13725/month=07/mytest.json\t7\n+\n+query I\n+select count(*)\n+from read_json('data/json/13725/month=*/*.json', hive_partitioning = true, format = auto, hive_types = {'month': int}, filename = true)\n+where month = 7;\n+----\n+1\n",
  "problem_statement": "Using both `hive_partitioning` and `hive_types` in `read_json_objects` intermittently segfaults\n### What happens?\n\nduckdb cli will intermittently segfault when using `read_json_objects` with `hive_partitioning = true` and defined `hive_types`.\r\n\r\nSpecifically the segfault is of type `EXC_BAD_ACCESS`, subtype `KERN_INVALID_ADDRESS at 0x0000000000000004`\r\n\r\nThe intermittency varies, however in my local testing running the supplied script will cause the issue on anything between 1-120 attempts at a query.\n\n### To Reproduce\n\nTo reproduce:\r\n\r\n- Install duckdb (in my case by using `brew install duckdb` on macOS)\r\n- Create the following script in your editor, and run it.  It should run the problematic command repeatedly until it segfaults at which point it should say upon which attempt this occurred.\r\n```sh\r\n#!/bin/sh\r\n\r\nmkdir \"month=07\"\r\necho '{ \"hello\": \"there\" }' > month=07/mytest.json\r\n\r\ncounter=1\r\nuntil duckdb -s \"select * from read_json_objects('./month=*/*.json', hive_partitioning = true, format = auto, hive_types = {'month': int}, filename = true ) where month = 7;\" \r\n  [ $? -eq 139 ]\r\ndo counter=$((counter+1)) \r\ndone\r\n\r\nprintf \"segfaulted on try: $counter\\n\"\r\n```\r\n\r\nIn the hopes of saving you some debug time, some additional info:\r\n\r\n- The state occurs when both when running duckdb interactively or via `-s`.... I only use `-s` here to make repeat testing until a failure state easier\r\n- The same issue seems to manifest with single JSON objects, and line delimited JSON files with multiple objects\r\n- The issue manifests with all sorts of JSON content, the content in the above script is just to illustrate, it does not appear to be the problem.\r\n- Using `hive_partitioning = true` but not setting `hive_types` does not seem to trigger the condition\r\n\r\n\n\n### OS:\n\nmacOS 14.5 (23F79), arm64\n\n### DuckDB Version:\n\nv1.0.0 1f98600c2c\n\n### DuckDB Client:\n\nNative CLI Client\n\n### Full Name:\n\nLee Brotherston\n\n### Affiliation:\n\nOpsHelmInc\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\nUsing both `hive_partitioning` and `hive_types` in `read_json_objects` intermittently segfaults\n### What happens?\n\nduckdb cli will intermittently segfault when using `read_json_objects` with `hive_partitioning = true` and defined `hive_types`.\r\n\r\nSpecifically the segfault is of type `EXC_BAD_ACCESS`, subtype `KERN_INVALID_ADDRESS at 0x0000000000000004`\r\n\r\nThe intermittency varies, however in my local testing running the supplied script will cause the issue on anything between 1-120 attempts at a query.\n\n### To Reproduce\n\nTo reproduce:\r\n\r\n- Install duckdb (in my case by using `brew install duckdb` on macOS)\r\n- Create the following script in your editor, and run it.  It should run the problematic command repeatedly until it segfaults at which point it should say upon which attempt this occurred.\r\n```sh\r\n#!/bin/sh\r\n\r\nmkdir \"month=07\"\r\necho '{ \"hello\": \"there\" }' > month=07/mytest.json\r\n\r\ncounter=1\r\nuntil duckdb -s \"select * from read_json_objects('./month=*/*.json', hive_partitioning = true, format = auto, hive_types = {'month': int}, filename = true ) where month = 7;\" \r\n  [ $? -eq 139 ]\r\ndo counter=$((counter+1)) \r\ndone\r\n\r\nprintf \"segfaulted on try: $counter\\n\"\r\n```\r\n\r\nIn the hopes of saving you some debug time, some additional info:\r\n\r\n- The state occurs when both when running duckdb interactively or via `-s`.... I only use `-s` here to make repeat testing until a failure state easier\r\n- The same issue seems to manifest with single JSON objects, and line delimited JSON files with multiple objects\r\n- The issue manifests with all sorts of JSON content, the content in the above script is just to illustrate, it does not appear to be the problem.\r\n- Using `hive_partitioning = true` but not setting `hive_types` does not seem to trigger the condition\r\n\r\n\n\n### OS:\n\nmacOS 14.5 (23F79), arm64\n\n### DuckDB Version:\n\nv1.0.0 1f98600c2c\n\n### DuckDB Client:\n\nNative CLI Client\n\n### Full Name:\n\nLee Brotherston\n\n### Affiliation:\n\nOpsHelmInc\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n",
  "hints_text": "Thanks for the reproducer - it works great - and for the additional info. We'll take a look.\nThanks for the reproducer - it works great - and for the additional info. We'll take a look.",
  "created_at": "2024-09-05T08:20:32Z"
}