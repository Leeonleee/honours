You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
Assertion Failed: chunk.ColumnCount() == op.aggregates.size()
#### What happens?
Assertion triggered in file "/root/duckdb/src/execution/radix_partitioned_hashtable.cpp" on line 344: chunk.ColumnCount() == op.aggregates.size()

#### To Reproduce
```sql
create table strings (a VARCHAR, b VARCHAR);
select b, b, count(*) from strings group by rollup (b, b) order by 1, 2, 3;
```

#### Environment (please complete the following information):
 - OS: linux
 - DuckDB Version: v0.3.3-dev1395 80ae1e12d
 - DuckDB Client: /usr/local/bin/duckdb 

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**

Assertion Failed: chunk.ColumnCount() == op.aggregates.size()
#### What happens?
Assertion triggered in file "/root/duckdb/src/execution/radix_partitioned_hashtable.cpp" on line 344: chunk.ColumnCount() == op.aggregates.size()

#### To Reproduce
```sql
create table strings (a VARCHAR, b VARCHAR);
select b, b, count(*) from strings group by rollup (b, b) order by 1, 2, 3;
```

#### Environment (please complete the following information):
 - OS: linux
 - DuckDB Version: v0.3.3-dev1395 80ae1e12d
 - DuckDB Client: /usr/local/bin/duckdb 

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**


</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
44: 
45: 
[end of README.md]
[start of src/execution/radix_partitioned_hashtable.cpp]
1: #include "duckdb/execution/radix_partitioned_hashtable.hpp"
2: #include "duckdb/parallel/task_scheduler.hpp"
3: #include "duckdb/execution/operator/aggregate/physical_hash_aggregate.hpp"
4: #include "duckdb/parallel/event.hpp"
5: 
6: namespace duckdb {
7: 
8: RadixPartitionedHashTable::RadixPartitionedHashTable(GroupingSet &grouping_set_p, const PhysicalHashAggregate &op_p)
9:     : grouping_set(grouping_set_p), op(op_p) {
10: 
11: 	for (idx_t i = 0; i < op.groups.size(); i++) {
12: 		if (grouping_set.find(i) == grouping_set.end()) {
13: 			null_groups.push_back(i);
14: 		}
15: 	}
16: 
17: 	// 10000 seems like a good compromise here
18: 	radix_limit = 10000;
19: 
20: 	if (grouping_set.empty()) {
21: 		// fake a single group with a constant value for aggregation without groups
22: 		group_types.emplace_back(LogicalType::TINYINT);
23: 	}
24: 	for (auto &entry : grouping_set) {
25: 		D_ASSERT(entry < op.group_types.size());
26: 		group_types.push_back(op.group_types[entry]);
27: 	}
28: 	// compute the GROUPING values
29: 	// for each parameter to the GROUPING clause, we check if the hash table groups on this particular group
30: 	// if it does, we return 0, otherwise we return 1
31: 	// we then use bitshifts to combine these values
32: 	for (auto &grouping : op.grouping_functions) {
33: 		int64_t grouping_value = 0;
34: 		for (idx_t i = 0; i < grouping.size(); i++) {
35: 			if (grouping_set.find(grouping[i]) == grouping_set.end()) {
36: 				// we don't group on this value!
37: 				grouping_value += 1 << (grouping.size() - (i + 1));
38: 			}
39: 		}
40: 		grouping_values.push_back(Value::BIGINT(grouping_value));
41: 	}
42: }
43: 
44: //===--------------------------------------------------------------------===//
45: // Sink
46: //===--------------------------------------------------------------------===//
47: class RadixHTGlobalState : public GlobalSinkState {
48: public:
49: 	explicit RadixHTGlobalState(ClientContext &context)
50: 	    : is_empty(true), multi_scan(true), total_groups(0),
51: 	      partition_info((idx_t)TaskScheduler::GetScheduler(context).NumberOfThreads()) {
52: 	}
53: 
54: 	vector<unique_ptr<PartitionableHashTable>> intermediate_hts;
55: 	vector<unique_ptr<GroupedAggregateHashTable>> finalized_hts;
56: 
57: 	//! Whether or not any tuples were added to the HT
58: 	bool is_empty;
59: 	//! Whether or not the hash table should be scannable multiple times
60: 	bool multi_scan;
61: 	//! The lock for updating the global aggregate state
62: 	mutex lock;
63: 	//! a counter to determine if we should switch over to p
64: 	atomic<idx_t> total_groups;
65: 
66: 	bool is_finalized = false;
67: 	bool is_partitioned = false;
68: 
69: 	RadixPartitionInfo partition_info;
70: };
71: 
72: class RadixHTLocalState : public LocalSinkState {
73: public:
74: 	explicit RadixHTLocalState(const RadixPartitionedHashTable &ht) : is_empty(true) {
75: 		// if there are no groups we create a fake group so everything has the same group
76: 		group_chunk.InitializeEmpty(ht.group_types);
77: 		if (ht.grouping_set.empty()) {
78: 			group_chunk.data[0].Reference(Value::TINYINT(42));
79: 		}
80: 	}
81: 
82: 	DataChunk group_chunk;
83: 	//! The aggregate HT
84: 	unique_ptr<PartitionableHashTable> ht;
85: 
86: 	//! Whether or not any tuples were added to the HT
87: 	bool is_empty;
88: };
89: 
90: void RadixPartitionedHashTable::SetMultiScan(GlobalSinkState &state) {
91: 	auto &gstate = (RadixHTGlobalState &)state;
92: 	gstate.multi_scan = true;
93: }
94: 
95: unique_ptr<GlobalSinkState> RadixPartitionedHashTable::GetGlobalSinkState(ClientContext &context) const {
96: 	return make_unique<RadixHTGlobalState>(context);
97: }
98: 
99: unique_ptr<LocalSinkState> RadixPartitionedHashTable::GetLocalSinkState(ExecutionContext &context) const {
100: 	return make_unique<RadixHTLocalState>(*this);
101: }
102: 
103: void RadixPartitionedHashTable::Sink(ExecutionContext &context, GlobalSinkState &state, LocalSinkState &lstate,
104:                                      DataChunk &input, DataChunk &aggregate_input_chunk) const {
105: 	auto &llstate = (RadixHTLocalState &)lstate;
106: 	auto &gstate = (RadixHTGlobalState &)state;
107: 	D_ASSERT(!gstate.is_finalized);
108: 
109: 	DataChunk &group_chunk = llstate.group_chunk;
110: 	idx_t chunk_index = 0;
111: 	for (auto &group_idx : grouping_set) {
112: 		auto &group = op.groups[group_idx];
113: 		D_ASSERT(group->type == ExpressionType::BOUND_REF);
114: 		auto &bound_ref_expr = (BoundReferenceExpression &)*group;
115: 		group_chunk.data[chunk_index++].Reference(input.data[bound_ref_expr.index]);
116: 	}
117: 	group_chunk.SetCardinality(input.size());
118: 	group_chunk.Verify();
119: 
120: 	// if we have non-combinable aggregates (e.g. string_agg) or any distinct aggregates we cannot keep parallel hash
121: 	// tables
122: 	if (ForceSingleHT(state)) {
123: 		lock_guard<mutex> glock(gstate.lock);
124: 		gstate.is_empty = gstate.is_empty && group_chunk.size() == 0;
125: 		if (gstate.finalized_hts.empty()) {
126: 			gstate.finalized_hts.push_back(
127: 			    make_unique<GroupedAggregateHashTable>(BufferManager::GetBufferManager(context.client), group_types,
128: 			                                           op.payload_types, op.bindings, HtEntryType::HT_WIDTH_64));
129: 		}
130: 		D_ASSERT(gstate.finalized_hts.size() == 1);
131: 		D_ASSERT(gstate.finalized_hts[0]);
132: 		gstate.total_groups += gstate.finalized_hts[0]->AddChunk(group_chunk, aggregate_input_chunk);
133: 		return;
134: 	}
135: 
136: 	D_ASSERT(op.all_combinable);
137: 	D_ASSERT(!op.any_distinct);
138: 
139: 	if (group_chunk.size() > 0) {
140: 		llstate.is_empty = false;
141: 	}
142: 
143: 	if (!llstate.ht) {
144: 		llstate.ht =
145: 		    make_unique<PartitionableHashTable>(BufferManager::GetBufferManager(context.client), gstate.partition_info,
146: 		                                        group_types, op.payload_types, op.bindings);
147: 	}
148: 
149: 	gstate.total_groups +=
150: 	    llstate.ht->AddChunk(group_chunk, aggregate_input_chunk,
151: 	                         gstate.total_groups > radix_limit && gstate.partition_info.n_partitions > 1);
152: }
153: 
154: void RadixPartitionedHashTable::Combine(ExecutionContext &context, GlobalSinkState &state,
155:                                         LocalSinkState &lstate) const {
156: 	auto &llstate = (RadixHTLocalState &)lstate;
157: 	auto &gstate = (RadixHTGlobalState &)state;
158: 	D_ASSERT(!gstate.is_finalized);
159: 
160: 	// this actually does not do a lot but just pushes the local HTs into the global state so we can later combine them
161: 	// in parallel
162: 
163: 	if (ForceSingleHT(state)) {
164: 		D_ASSERT(gstate.finalized_hts.size() <= 1);
165: 		return;
166: 	}
167: 
168: 	if (!llstate.ht) {
169: 		return; // no data
170: 	}
171: 
172: 	if (!llstate.ht->IsPartitioned() && gstate.partition_info.n_partitions > 1 && gstate.total_groups > radix_limit) {
173: 		llstate.ht->Partition();
174: 	}
175: 
176: 	lock_guard<mutex> glock(gstate.lock);
177: 	D_ASSERT(op.all_combinable);
178: 	D_ASSERT(!op.any_distinct);
179: 
180: 	if (!llstate.is_empty) {
181: 		gstate.is_empty = false;
182: 	}
183: 
184: 	// we will never add new values to these HTs so we can drop the first part of the HT
185: 	llstate.ht->Finalize();
186: 
187: 	// at this point we just collect them the PhysicalHashAggregateFinalizeTask (below) will merge them in parallel
188: 	gstate.intermediate_hts.push_back(move(llstate.ht));
189: }
190: 
191: bool RadixPartitionedHashTable::Finalize(ClientContext &context, GlobalSinkState &gstate_p) const {
192: 	auto &gstate = (RadixHTGlobalState &)gstate_p;
193: 	D_ASSERT(!gstate.is_finalized);
194: 	gstate.is_finalized = true;
195: 
196: 	// special case if we have non-combinable aggregates
197: 	// we have already aggreagted into a global shared HT that does not require any additional finalization steps
198: 	if (ForceSingleHT(gstate)) {
199: 		D_ASSERT(gstate.finalized_hts.size() <= 1);
200: 		D_ASSERT(gstate.finalized_hts.empty() || gstate.finalized_hts[0]);
201: 		return false;
202: 	}
203: 
204: 	// we can have two cases now, non-partitioned for few groups and radix-partitioned for very many groups.
205: 	// go through all of the child hts and see if we ever called partition() on any of them
206: 	// if we did, its the latter case.
207: 	bool any_partitioned = false;
208: 	for (auto &pht : gstate.intermediate_hts) {
209: 		if (pht->IsPartitioned()) {
210: 			any_partitioned = true;
211: 			break;
212: 		}
213: 	}
214: 
215: 	if (any_partitioned) {
216: 		// if one is partitioned, all have to be
217: 		// this should mostly have already happened in Combine, but if not we do it here
218: 		for (auto &pht : gstate.intermediate_hts) {
219: 			if (!pht->IsPartitioned()) {
220: 				pht->Partition();
221: 			}
222: 		}
223: 		// schedule additional tasks to combine the partial HTs
224: 		gstate.finalized_hts.resize(gstate.partition_info.n_partitions);
225: 		for (idx_t r = 0; r < gstate.partition_info.n_partitions; r++) {
226: 			gstate.finalized_hts[r] =
227: 			    make_unique<GroupedAggregateHashTable>(BufferManager::GetBufferManager(context), group_types,
228: 			                                           op.payload_types, op.bindings, HtEntryType::HT_WIDTH_64);
229: 		}
230: 		gstate.is_partitioned = true;
231: 		return true;
232: 	} else { // in the non-partitioned case we immediately combine all the unpartitioned hts created by the threads.
233: 		     // TODO possible optimization, if total count < limit for 32 bit ht, use that one
234: 		     // create this ht here so finalize needs no lock on gstate
235: 
236: 		gstate.finalized_hts.push_back(make_unique<GroupedAggregateHashTable>(BufferManager::GetBufferManager(context),
237: 		                                                                      group_types, op.payload_types,
238: 		                                                                      op.bindings, HtEntryType::HT_WIDTH_64));
239: 		for (auto &pht : gstate.intermediate_hts) {
240: 			auto unpartitioned = pht->GetUnpartitioned();
241: 			for (auto &unpartitioned_ht : unpartitioned) {
242: 				D_ASSERT(unpartitioned_ht);
243: 				gstate.finalized_hts[0]->Combine(*unpartitioned_ht);
244: 				unpartitioned_ht.reset();
245: 			}
246: 			unpartitioned.clear();
247: 		}
248: 		D_ASSERT(gstate.finalized_hts[0]);
249: 		gstate.finalized_hts[0]->Finalize();
250: 		return false;
251: 	}
252: }
253: 
254: // this task is run in multiple threads and combines the radix-partitioned hash tables into a single onen and then
255: // folds them into the global ht finally.
256: class RadixAggregateFinalizeTask : public ExecutorTask {
257: public:
258: 	RadixAggregateFinalizeTask(Executor &executor, shared_ptr<Event> event_p, RadixHTGlobalState &state_p,
259: 	                           idx_t radix_p)
260: 	    : ExecutorTask(executor), event(move(event_p)), state(state_p), radix(radix_p) {
261: 	}
262: 
263: 	static void FinalizeHT(RadixHTGlobalState &gstate, idx_t radix) {
264: 		D_ASSERT(gstate.partition_info.n_partitions <= gstate.finalized_hts.size());
265: 		D_ASSERT(gstate.finalized_hts[radix]);
266: 		for (auto &pht : gstate.intermediate_hts) {
267: 			for (auto &ht : pht->GetPartition(radix)) {
268: 				gstate.finalized_hts[radix]->Combine(*ht);
269: 				ht.reset();
270: 			}
271: 		}
272: 		gstate.finalized_hts[radix]->Finalize();
273: 	}
274: 
275: 	TaskExecutionResult ExecuteTask(TaskExecutionMode mode) override {
276: 		FinalizeHT(state, radix);
277: 		event->FinishTask();
278: 		return TaskExecutionResult::TASK_FINISHED;
279: 	}
280: 
281: private:
282: 	shared_ptr<Event> event;
283: 	RadixHTGlobalState &state;
284: 	idx_t radix;
285: };
286: 
287: void RadixPartitionedHashTable::ScheduleTasks(Executor &executor, const shared_ptr<Event> &event,
288:                                               GlobalSinkState &state, vector<unique_ptr<Task>> &tasks) const {
289: 	auto &gstate = (RadixHTGlobalState &)state;
290: 	if (!gstate.is_partitioned) {
291: 		return;
292: 	}
293: 	for (idx_t r = 0; r < gstate.partition_info.n_partitions; r++) {
294: 		D_ASSERT(gstate.partition_info.n_partitions <= gstate.finalized_hts.size());
295: 		D_ASSERT(gstate.finalized_hts[r]);
296: 		tasks.push_back(make_unique<RadixAggregateFinalizeTask>(executor, event, gstate, r));
297: 	}
298: }
299: 
300: bool RadixPartitionedHashTable::ForceSingleHT(GlobalSinkState &state) const {
301: 	auto &gstate = (RadixHTGlobalState &)state;
302: 	return !op.all_combinable || op.any_distinct || gstate.partition_info.n_partitions < 2;
303: }
304: 
305: //===--------------------------------------------------------------------===//
306: // Source
307: //===--------------------------------------------------------------------===//
308: class RadixHTGlobalSourceState : public GlobalSourceState {
309: public:
310: 	explicit RadixHTGlobalSourceState(const RadixPartitionedHashTable &ht)
311: 	    : ht_index(0), ht_scan_position(0), finished(false) {
312: 		auto scan_chunk_types = ht.group_types;
313: 		for (auto &aggr_type : ht.op.aggregate_return_types) {
314: 			scan_chunk_types.push_back(aggr_type);
315: 		}
316: 		scan_chunk.Initialize(scan_chunk_types);
317: 	}
318: 
319: 	//! Materialized GROUP BY expressions & aggregates
320: 	DataChunk scan_chunk;
321: 	//! The current position to scan the HT for output tuples
322: 	idx_t ht_index;
323: 	idx_t ht_scan_position;
324: 	bool finished;
325: };
326: 
327: unique_ptr<GlobalSourceState> RadixPartitionedHashTable::GetGlobalSourceState() const {
328: 	return make_unique<RadixHTGlobalSourceState>(*this);
329: }
330: 
331: void RadixPartitionedHashTable::GetData(ExecutionContext &context, DataChunk &chunk, GlobalSinkState &sink_state,
332:                                         GlobalSourceState &source_state) const {
333: 	auto &gstate = (RadixHTGlobalState &)sink_state;
334: 	auto &state = (RadixHTGlobalSourceState &)source_state;
335: 	D_ASSERT(gstate.is_finalized);
336: 	if (state.finished) {
337: 		return;
338: 	}
339: 
340: 	state.scan_chunk.Reset();
341: 	// special case hack to sort out aggregating from empty intermediates
342: 	// for aggregations without groups
343: 	if (gstate.is_empty && grouping_set.empty()) {
344: 		D_ASSERT(chunk.ColumnCount() == op.aggregates.size());
345: 		// for each column in the aggregates, set to initial state
346: 		chunk.SetCardinality(1);
347: 		for (idx_t i = 0; i < chunk.ColumnCount(); i++) {
348: 			D_ASSERT(op.aggregates[i]->GetExpressionClass() == ExpressionClass::BOUND_AGGREGATE);
349: 			auto &aggr = (BoundAggregateExpression &)*op.aggregates[i];
350: 			auto aggr_state = unique_ptr<data_t[]>(new data_t[aggr.function.state_size()]);
351: 			aggr.function.initialize(aggr_state.get());
352: 
353: 			Vector state_vector(Value::POINTER((uintptr_t)aggr_state.get()));
354: 			aggr.function.finalize(state_vector, aggr.bind_info.get(), chunk.data[i], 1, 0);
355: 			if (aggr.function.destructor) {
356: 				aggr.function.destructor(state_vector, 1);
357: 			}
358: 		}
359: 		state.finished = true;
360: 		return;
361: 	}
362: 	if (gstate.is_empty && !state.finished) {
363: 		state.finished = true;
364: 		return;
365: 	}
366: 	idx_t elements_found = 0;
367: 
368: 	while (true) {
369: 		if (state.ht_index == gstate.finalized_hts.size()) {
370: 			state.finished = true;
371: 			return;
372: 		}
373: 		D_ASSERT(gstate.finalized_hts[state.ht_index]);
374: 		elements_found = gstate.finalized_hts[state.ht_index]->Scan(state.ht_scan_position, state.scan_chunk);
375: 
376: 		if (elements_found > 0) {
377: 			break;
378: 		}
379: 		if (!gstate.multi_scan) {
380: 			gstate.finalized_hts[state.ht_index].reset();
381: 		}
382: 		state.ht_index++;
383: 		state.ht_scan_position = 0;
384: 	}
385: 
386: 	// compute the final projection list
387: 	chunk.SetCardinality(elements_found);
388: 
389: 	idx_t chunk_index = 0;
390: 	for (auto &entry : grouping_set) {
391: 		chunk.data[entry].Reference(state.scan_chunk.data[chunk_index++]);
392: 	}
393: 	for (auto null_group : null_groups) {
394: 		chunk.data[null_group].SetVectorType(VectorType::CONSTANT_VECTOR);
395: 		ConstantVector::SetNull(chunk.data[null_group], true);
396: 	}
397: 	for (idx_t col_idx = 0; col_idx < op.aggregates.size(); col_idx++) {
398: 		chunk.data[op.groups.size() + col_idx].Reference(state.scan_chunk.data[group_types.size() + col_idx]);
399: 	}
400: 	D_ASSERT(op.grouping_functions.size() == grouping_values.size());
401: 	for (idx_t i = 0; i < op.grouping_functions.size(); i++) {
402: 		chunk.data[op.groups.size() + op.aggregates.size() + i].Reference(grouping_values[i]);
403: 	}
404: }
405: 
406: } // namespace duckdb
[end of src/execution/radix_partitioned_hashtable.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: