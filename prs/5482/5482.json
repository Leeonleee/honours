{
  "repo": "duckdb/duckdb",
  "pull_number": 5482,
  "instance_id": "duckdb__duckdb-5482",
  "issue_numbers": [
    "4269",
    "5437"
  ],
  "base_commit": "0c8bafb8213ce59dc21b5a015632d603a988c104",
  "patch": "diff --git a/src/catalog/catalog_entry.cpp b/src/catalog/catalog_entry.cpp\nindex 676ca39e1556..dcfa0efc5ecf 100644\n--- a/src/catalog/catalog_entry.cpp\n+++ b/src/catalog/catalog_entry.cpp\n@@ -20,6 +20,9 @@ unique_ptr<CatalogEntry> CatalogEntry::AlterEntry(ClientContext &context, AlterI\n \tthrow InternalException(\"Unsupported alter type for catalog entry!\");\n }\n \n+void CatalogEntry::UndoAlter(ClientContext &context, AlterInfo *info) {\n+}\n+\n unique_ptr<CatalogEntry> CatalogEntry::Copy(ClientContext &context) {\n \tthrow InternalException(\"Unsupported copy type for catalog entry!\");\n }\ndiff --git a/src/catalog/catalog_entry/table_catalog_entry.cpp b/src/catalog/catalog_entry/table_catalog_entry.cpp\nindex fdd2db5bc720..20dac97bed4f 100644\n--- a/src/catalog/catalog_entry/table_catalog_entry.cpp\n+++ b/src/catalog/catalog_entry/table_catalog_entry.cpp\n@@ -207,6 +207,20 @@ unique_ptr<CatalogEntry> TableCatalogEntry::AlterEntry(ClientContext &context, A\n \t}\n }\n \n+void TableCatalogEntry::UndoAlter(ClientContext &context, AlterInfo *info) {\n+\tD_ASSERT(!internal);\n+\tD_ASSERT(info->type == AlterType::ALTER_TABLE);\n+\tauto table_info = (AlterTableInfo *)info;\n+\tswitch (table_info->alter_table_type) {\n+\tcase AlterTableType::RENAME_TABLE: {\n+\t\tstorage->info->table = this->name;\n+\t\tbreak;\n+\tdefault:\n+\t\tbreak;\n+\t}\n+\t}\n+}\n+\n static void RenameExpression(ParsedExpression &expr, RenameColumnInfo &info) {\n \tif (expr.type == ExpressionType::COLUMN_REF) {\n \t\tauto &colref = (ColumnRefExpression &)expr;\n@@ -305,6 +319,8 @@ unique_ptr<CatalogEntry> TableCatalogEntry::AddColumn(ClientContext &context, Ad\n \t\tcreate_info->constraints.push_back(constraint->Copy());\n \t}\n \tBinder::BindLogicalType(context, info.new_column.TypeMutable(), schema->name);\n+\tinfo.new_column.SetOid(columns.LogicalColumnCount());\n+\tinfo.new_column.SetStorageOid(columns.PhysicalColumnCount());\n \tauto col = info.new_column.Copy();\n \n \tcreate_info->columns.AddColumn(move(col));\ndiff --git a/src/catalog/catalog_set.cpp b/src/catalog/catalog_set.cpp\nindex 630a5c0980d8..ec07f6eca4e3 100644\n--- a/src/catalog/catalog_set.cpp\n+++ b/src/catalog/catalog_set.cpp\n@@ -184,8 +184,9 @@ bool CatalogSet::AlterEntry(ClientContext &context, const string &name, AlterInf\n \tif (value->name != original_name) {\n \t\tauto mapping_value = GetMapping(context, value->name);\n \t\tif (mapping_value && !mapping_value->deleted) {\n-\t\t\tauto entry = GetEntryForTransaction(context, entries[mapping_value->index].get());\n-\t\t\tif (!entry->deleted) {\n+\t\t\tauto original_entry = GetEntryForTransaction(context, entries[mapping_value->index].get());\n+\t\t\tif (!original_entry->deleted) {\n+\t\t\t\tentry->UndoAlter(context, alter_info);\n \t\t\t\tstring rename_err_msg =\n \t\t\t\t    \"Could not rename \\\"%s\\\" to \\\"%s\\\": another entry with this name already exists!\";\n \t\t\t\tthrow CatalogException(rename_err_msg, original_name, value->name);\n@@ -274,6 +275,7 @@ bool CatalogSet::DropEntry(ClientContext &context, const string &name, bool casc\n \t\tthrow CatalogException(\"Cannot drop entry \\\"%s\\\" because it is an internal system entry\", entry->name);\n \t}\n \n+\tlock_guard<mutex> read_lock(catalog_lock);\n \tDropEntryInternal(context, entry_index, *entry, cascade);\n \treturn true;\n }\ndiff --git a/src/common/vector_operations/vector_hash.cpp b/src/common/vector_operations/vector_hash.cpp\nindex 794a58e5e220..1a8700a3d943 100644\n--- a/src/common/vector_operations/vector_hash.cpp\n+++ b/src/common/vector_operations/vector_hash.cpp\n@@ -101,7 +101,9 @@ static inline void ListLoopHash(Vector &input, Vector &hashes, const SelectionVe\n \tconst auto child_count = ListVector::GetListSize(input);\n \n \tVector child_hashes(LogicalType::HASH, child_count);\n-\tVectorOperations::Hash(child, child_hashes, child_count);\n+\tif (child_count > 0) {\n+\t\tVectorOperations::Hash(child, child_hashes, child_count);\n+\t}\n \tauto chdata = FlatVector::GetData<hash_t>(child_hashes);\n \n \t// Reduce the number of entries to check to the non-empty ones\ndiff --git a/src/execution/column_binding_resolver.cpp b/src/execution/column_binding_resolver.cpp\nindex abaa6abddae0..c9b92b931a53 100644\n--- a/src/execution/column_binding_resolver.cpp\n+++ b/src/execution/column_binding_resolver.cpp\n@@ -95,4 +95,33 @@ unique_ptr<Expression> ColumnBindingResolver::VisitReplace(BoundColumnRefExpress\n \t// LCOV_EXCL_STOP\n }\n \n+unordered_set<idx_t> ColumnBindingResolver::VerifyInternal(LogicalOperator &op) {\n+\tunordered_set<idx_t> result;\n+\tfor (auto &child : op.children) {\n+\t\tauto child_indexes = VerifyInternal(*child);\n+\t\tfor (auto index : child_indexes) {\n+\t\t\tD_ASSERT(index != DConstants::INVALID_INDEX);\n+\t\t\tif (result.find(index) != result.end()) {\n+\t\t\t\tthrow InternalException(\"Duplicate table index \\\"%lld\\\" found\", index);\n+\t\t\t}\n+\t\t\tresult.insert(index);\n+\t\t}\n+\t}\n+\tauto indexes = op.GetTableIndex();\n+\tfor (auto index : indexes) {\n+\t\tD_ASSERT(index != DConstants::INVALID_INDEX);\n+\t\tif (result.find(index) != result.end()) {\n+\t\t\tthrow InternalException(\"Duplicate table index \\\"%lld\\\" found\", index);\n+\t\t}\n+\t\tresult.insert(index);\n+\t}\n+\treturn result;\n+}\n+\n+void ColumnBindingResolver::Verify(LogicalOperator &op) {\n+#ifdef DEBUG\n+\tVerifyInternal(op);\n+#endif\n+}\n+\n } // namespace duckdb\ndiff --git a/src/execution/nested_loop_join/nested_loop_join_mark.cpp b/src/execution/nested_loop_join/nested_loop_join_mark.cpp\nindex 2fd61fd6393b..5eb4f182aac2 100644\n--- a/src/execution/nested_loop_join/nested_loop_join_mark.cpp\n+++ b/src/execution/nested_loop_join/nested_loop_join_mark.cpp\n@@ -33,6 +33,44 @@ static void TemplatedMarkJoin(Vector &left, Vector &right, idx_t lcount, idx_t r\n \t}\n }\n \n+static void MarkJoinNested(Vector &left, Vector &right, idx_t lcount, idx_t rcount, bool found_match[],\n+                           ExpressionType comparison_type) {\n+\tVector left_reference(left.GetType());\n+\tSelectionVector true_sel(rcount);\n+\tfor (idx_t i = 0; i < lcount; i++) {\n+\t\tif (found_match[i]) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tConstantVector::Reference(left_reference, left, i, rcount);\n+\t\tidx_t count;\n+\t\tswitch (comparison_type) {\n+\t\tcase ExpressionType::COMPARE_EQUAL:\n+\t\t\tcount = VectorOperations::Equals(left_reference, right, nullptr, rcount, nullptr, nullptr);\n+\t\t\tbreak;\n+\t\tcase ExpressionType::COMPARE_NOTEQUAL:\n+\t\t\tcount = VectorOperations::NotEquals(left_reference, right, nullptr, rcount, nullptr, nullptr);\n+\t\t\tbreak;\n+\t\tcase ExpressionType::COMPARE_LESSTHAN:\n+\t\t\tcount = VectorOperations::LessThan(left_reference, right, nullptr, rcount, nullptr, nullptr);\n+\t\t\tbreak;\n+\t\tcase ExpressionType::COMPARE_GREATERTHAN:\n+\t\t\tcount = VectorOperations::GreaterThan(left_reference, right, nullptr, rcount, nullptr, nullptr);\n+\t\t\tbreak;\n+\t\tcase ExpressionType::COMPARE_LESSTHANOREQUALTO:\n+\t\t\tcount = VectorOperations::LessThanEquals(left_reference, right, nullptr, rcount, nullptr, nullptr);\n+\t\t\tbreak;\n+\t\tcase ExpressionType::COMPARE_GREATERTHANOREQUALTO:\n+\t\t\tcount = VectorOperations::GreaterThanEquals(left_reference, right, nullptr, rcount, nullptr, nullptr);\n+\t\t\tbreak;\n+\t\tdefault:\n+\t\t\tthrow InternalException(\"Unsupported comparison type for MarkJoinNested\");\n+\t\t}\n+\t\tif (count > 0) {\n+\t\t\tfound_match[i] = true;\n+\t\t}\n+\t}\n+}\n+\n template <class OP>\n static void MarkJoinSwitch(Vector &left, Vector &right, idx_t lcount, idx_t rcount, bool found_match[]) {\n \tswitch (left.GetType().InternalType()) {\n@@ -68,6 +106,13 @@ static void MarkJoinSwitch(Vector &left, Vector &right, idx_t lcount, idx_t rcou\n \n static void MarkJoinComparisonSwitch(Vector &left, Vector &right, idx_t lcount, idx_t rcount, bool found_match[],\n                                      ExpressionType comparison_type) {\n+\tswitch (left.GetType().InternalType()) {\n+\tcase PhysicalType::STRUCT:\n+\tcase PhysicalType::LIST:\n+\t\treturn MarkJoinNested(left, right, lcount, rcount, found_match, comparison_type);\n+\tdefault:\n+\t\tbreak;\n+\t}\n \tD_ASSERT(left.GetType() == right.GetType());\n \tswitch (comparison_type) {\n \tcase ExpressionType::COMPARE_EQUAL:\ndiff --git a/src/execution/operator/helper/physical_limit_percent.cpp b/src/execution/operator/helper/physical_limit_percent.cpp\nindex fa72eac6e93e..17b6257f19cb 100644\n--- a/src/execution/operator/helper/physical_limit_percent.cpp\n+++ b/src/execution/operator/helper/physical_limit_percent.cpp\n@@ -87,6 +87,7 @@ class LimitPercentOperatorState : public GlobalSourceState {\n public:\n \texplicit LimitPercentOperatorState(const PhysicalLimitPercent &op)\n \t    : limit(DConstants::INVALID_INDEX), current_offset(0) {\n+\t\tD_ASSERT(op.sink_state);\n \t\tauto &gstate = (LimitPercentGlobalState &)*op.sink_state;\n \t\tgstate.data.InitializeScan(scan_state);\n \t}\ndiff --git a/src/execution/operator/helper/physical_transaction.cpp b/src/execution/operator/helper/physical_transaction.cpp\nindex f746b29cfb25..17a6dd3f9b10 100644\n--- a/src/execution/operator/helper/physical_transaction.cpp\n+++ b/src/execution/operator/helper/physical_transaction.cpp\n@@ -7,7 +7,12 @@ void PhysicalTransaction::GetData(ExecutionContext &context, DataChunk &chunk, G\n                                   LocalSourceState &lstate) const {\n \tauto &client = context.client;\n \n-\tswitch (info->type) {\n+\tauto type = info->type;\n+\tif (type == TransactionType::COMMIT && ValidChecker::IsInvalidated(client.ActiveTransaction())) {\n+\t\t// transaction is invalidated - turn COMMIT into ROLLBACK\n+\t\ttype = TransactionType::ROLLBACK;\n+\t}\n+\tswitch (type) {\n \tcase TransactionType::BEGIN_TRANSACTION: {\n \t\tif (client.transaction.IsAutoCommit()) {\n \t\t\t// start the active transaction\ndiff --git a/src/execution/operator/join/physical_nested_loop_join.cpp b/src/execution/operator/join/physical_nested_loop_join.cpp\nindex df6a3185dc3b..a8fa42d3c13c 100644\n--- a/src/execution/operator/join/physical_nested_loop_join.cpp\n+++ b/src/execution/operator/join/physical_nested_loop_join.cpp\n@@ -17,7 +17,7 @@ PhysicalNestedLoopJoin::PhysicalNestedLoopJoin(LogicalOperator &op, unique_ptr<P\n \tchildren.push_back(move(right));\n }\n \n-static bool HasNullValues(DataChunk &chunk) {\n+bool PhysicalJoin::HasNullValues(DataChunk &chunk) {\n \tfor (idx_t col_idx = 0; col_idx < chunk.ColumnCount(); col_idx++) {\n \t\tUnifiedVectorFormat vdata;\n \t\tchunk.data[col_idx].ToUnifiedFormat(chunk.size(), vdata);\n@@ -106,7 +106,10 @@ void PhysicalJoin::ConstructMarkJoinResult(DataChunk &join_keys, DataChunk &left\n \t}\n }\n \n-bool PhysicalNestedLoopJoin::IsSupported(const vector<JoinCondition> &conditions) {\n+bool PhysicalNestedLoopJoin::IsSupported(const vector<JoinCondition> &conditions, JoinType join_type) {\n+\tif (join_type == JoinType::MARK) {\n+\t\treturn true;\n+\t}\n \tfor (auto &cond : conditions) {\n \t\tif (cond.left->return_type.InternalType() == PhysicalType::STRUCT ||\n \t\t    cond.left->return_type.InternalType() == PhysicalType::LIST) {\n@@ -150,7 +153,7 @@ class NestedLoopJoinGlobalState : public GlobalSinkState {\n \t//! Materialized join condition of the RHS\n \tColumnDataCollection right_condition_data;\n \t//! Whether or not the RHS of the nested loop join has NULL values\n-\tbool has_null;\n+\tatomic<bool> has_null;\n \t//! A bool indicating for each tuple in the RHS if they found a match (only used in FULL OUTER JOIN)\n \tOuterJoinMarker right_outer;\n };\ndiff --git a/src/execution/operator/set/physical_recursive_cte.cpp b/src/execution/operator/set/physical_recursive_cte.cpp\nindex 6825c2fb703b..d864c6a77a26 100644\n--- a/src/execution/operator/set/physical_recursive_cte.cpp\n+++ b/src/execution/operator/set/physical_recursive_cte.cpp\n@@ -129,15 +129,14 @@ void PhysicalRecursiveCTE::ExecuteRecursivePipelines(ExecutionContext &context)\n \tfor (auto &pipeline : pipelines) {\n \t\tauto sink = pipeline->GetSink();\n \t\tif (sink != this) {\n-\t\t\t// reset the sink state for any intermediate sinks\n-\t\t\tsink->sink_state = sink->GetGlobalSinkState(context.client);\n+\t\t\tsink->sink_state.reset();\n \t\t}\n \t\tfor (auto &op : pipeline->GetOperators()) {\n \t\t\tif (op) {\n-\t\t\t\top->op_state = op->GetGlobalOperatorState(context.client);\n+\t\t\t\top->op_state.reset();\n \t\t\t}\n \t\t}\n-\t\tpipeline->ResetSource(true);\n+\t\tpipeline->ClearSource();\n \t}\n \n \t// get the MetaPipelines in the recursive_meta_pipeline and reschedule them\ndiff --git a/src/execution/physical_plan/plan_comparison_join.cpp b/src/execution/physical_plan/plan_comparison_join.cpp\nindex fd1c9893b8ef..289b474a200b 100644\n--- a/src/execution/physical_plan/plan_comparison_join.cpp\n+++ b/src/execution/physical_plan/plan_comparison_join.cpp\n@@ -261,7 +261,7 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalComparison\n \t\t\t// range join: use piecewise merge join\n \t\t\tplan = make_unique<PhysicalPiecewiseMergeJoin>(op, move(left), move(right), move(op.conditions),\n \t\t\t                                               op.join_type, op.estimated_cardinality);\n-\t\t} else if (PhysicalNestedLoopJoin::IsSupported(op.conditions)) {\n+\t\t} else if (PhysicalNestedLoopJoin::IsSupported(op.conditions, op.join_type)) {\n \t\t\t// inequality join: use nested loop\n \t\t\tplan = make_unique<PhysicalNestedLoopJoin>(op, move(left), move(right), move(op.conditions), op.join_type,\n \t\t\t                                           op.estimated_cardinality);\ndiff --git a/src/execution/physical_plan/plan_create_table.cpp b/src/execution/physical_plan/plan_create_table.cpp\nindex c02833dae96b..c4d0d1f5dc5b 100644\n--- a/src/execution/physical_plan/plan_create_table.cpp\n+++ b/src/execution/physical_plan/plan_create_table.cpp\n@@ -4,30 +4,14 @@\n #include \"duckdb/parser/parsed_data/create_table_info.hpp\"\n #include \"duckdb/execution/operator/persistent/physical_insert.hpp\"\n #include \"duckdb/planner/expression/bound_function_expression.hpp\"\n-#include \"duckdb/planner/expression_iterator.hpp\"\n #include \"duckdb/planner/operator/logical_create_table.hpp\"\n #include \"duckdb/main/config.hpp\"\n #include \"duckdb/execution/operator/persistent/physical_batch_insert.hpp\"\n+#include \"duckdb/planner/constraints/bound_check_constraint.hpp\"\n \n namespace duckdb {\n \n-static void ExtractDependencies(Expression &expr, unordered_set<CatalogEntry *> &dependencies) {\n-\tif (expr.type == ExpressionType::BOUND_FUNCTION) {\n-\t\tauto &function = (BoundFunctionExpression &)expr;\n-\t\tif (function.function.dependency) {\n-\t\t\tfunction.function.dependency(function, dependencies);\n-\t\t}\n-\t}\n-\tExpressionIterator::EnumerateChildren(expr, [&](Expression &child) { ExtractDependencies(child, dependencies); });\n-}\n-\n unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalCreateTable &op) {\n-\t// extract dependencies from any default values\n-\tfor (auto &default_value : op.info->bound_defaults) {\n-\t\tif (default_value) {\n-\t\t\tExtractDependencies(*default_value, op.info->dependencies);\n-\t\t}\n-\t}\n \tauto &create_info = (CreateTableInfo &)*op.info->base;\n \tauto &catalog = Catalog::GetCatalog(context);\n \tauto existing_entry =\ndiff --git a/src/function/aggregate/regression/regr_count.cpp b/src/function/aggregate/regression/regr_count.cpp\nindex 768dbc289a11..90dc11d4f0a5 100644\n--- a/src/function/aggregate/regression/regr_count.cpp\n+++ b/src/function/aggregate/regression/regr_count.cpp\n@@ -8,10 +8,11 @@\n namespace duckdb {\n \n void RegrCountFun::RegisterFunction(BuiltinFunctions &set) {\n-\tAggregateFunctionSet corr(\"regr_count\");\n-\tcorr.AddFunction(AggregateFunction::BinaryAggregate<size_t, double, double, uint32_t, RegrCountFunction>(\n-\t    LogicalType::DOUBLE, LogicalType::DOUBLE, LogicalType::UINTEGER));\n-\tset.AddFunction(corr);\n+\tauto regr_count = AggregateFunction::BinaryAggregate<size_t, double, double, uint32_t, RegrCountFunction>(\n+\t    LogicalType::DOUBLE, LogicalType::DOUBLE, LogicalType::UINTEGER);\n+\tregr_count.name = \"regr_count\";\n+\tregr_count.null_handling = FunctionNullHandling::SPECIAL_HANDLING;\n+\tset.AddFunction(regr_count);\n }\n \n } // namespace duckdb\ndiff --git a/src/function/scalar/date/strftime.cpp b/src/function/scalar/date/strftime.cpp\nindex e4530c65890d..a2a4aff7333e 100644\n--- a/src/function/scalar/date/strftime.cpp\n+++ b/src/function/scalar/date/strftime.cpp\n@@ -593,15 +593,16 @@ string StrTimeFormat::ParseFormatSpecifier(const string &format_string, StrTimeF\n }\n \n struct StrfTimeBindData : public FunctionData {\n-\texplicit StrfTimeBindData(StrfTimeFormat format_p, string format_string_p)\n-\t    : format(move(format_p)), format_string(move(format_string_p)) {\n+\texplicit StrfTimeBindData(StrfTimeFormat format_p, string format_string_p, bool is_null)\n+\t    : format(move(format_p)), format_string(move(format_string_p)), is_null(is_null) {\n \t}\n \n \tStrfTimeFormat format;\n \tstring format_string;\n+\tbool is_null;\n \n \tunique_ptr<FunctionData> Copy() const override {\n-\t\treturn make_unique<StrfTimeBindData>(format, format_string);\n+\t\treturn make_unique<StrfTimeBindData>(format, format_string, is_null);\n \t}\n \n \tbool Equals(const FunctionData &other_p) const override {\n@@ -624,13 +625,14 @@ static unique_ptr<FunctionData> StrfTimeBindFunction(ClientContext &context, Sca\n \tValue options_str = ExpressionExecutor::EvaluateScalar(context, *format_arg);\n \tauto format_string = options_str.GetValue<string>();\n \tStrfTimeFormat format;\n-\tif (!options_str.IsNull()) {\n+\tbool is_null = options_str.IsNull();\n+\tif (!is_null) {\n \t\tstring error = StrTimeFormat::ParseFormatSpecifier(format_string, format);\n \t\tif (!error.empty()) {\n \t\t\tthrow InvalidInputException(\"Failed to parse format specifier %s: %s\", format_string, error);\n \t\t}\n \t}\n-\treturn make_unique<StrfTimeBindData>(format, format_string);\n+\treturn make_unique<StrfTimeBindData>(format, format_string, is_null);\n }\n \n void StrfTimeFormat::ConvertDateVector(Vector &input, Vector &result, idx_t count) {\n@@ -657,7 +659,7 @@ static void StrfTimeFunctionDate(DataChunk &args, ExpressionState &state, Vector\n \tauto &func_expr = (BoundFunctionExpression &)state.expr;\n \tauto &info = (StrfTimeBindData &)*func_expr.bind_info;\n \n-\tif (ConstantVector::IsNull(args.data[REVERSED ? 0 : 1])) {\n+\tif (info.is_null) {\n \t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n \t\tConstantVector::SetNull(result, true);\n \t\treturn;\n@@ -691,7 +693,7 @@ static void StrfTimeFunctionTimestamp(DataChunk &args, ExpressionState &state, V\n \tauto &func_expr = (BoundFunctionExpression &)state.expr;\n \tauto &info = (StrfTimeBindData &)*func_expr.bind_info;\n \n-\tif (ConstantVector::IsNull(args.data[REVERSED ? 0 : 1])) {\n+\tif (info.is_null) {\n \t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n \t\tConstantVector::SetNull(result, true);\n \t\treturn;\ndiff --git a/src/function/scalar/struct/struct_insert.cpp b/src/function/scalar/struct/struct_insert.cpp\nindex a82d5ec52dfa..d84e8f70e537 100644\n--- a/src/function/scalar/struct/struct_insert.cpp\n+++ b/src/function/scalar/struct/struct_insert.cpp\n@@ -81,7 +81,9 @@ static unique_ptr<FunctionData> StructInsertBind(ClientContext &context, ScalarF\n unique_ptr<BaseStatistics> StructInsertStats(ClientContext &context, FunctionStatisticsInput &input) {\n \tauto &child_stats = input.child_stats;\n \tauto &expr = input.expr;\n-\n+\tif (child_stats.empty() || !child_stats[0]) {\n+\t\treturn nullptr;\n+\t}\n \tauto &existing_struct_stats = (StructStatistics &)*child_stats[0];\n \tauto new_struct_stats = make_unique<StructStatistics>(expr.return_type);\n \ndiff --git a/src/include/duckdb/catalog/catalog_entry.hpp b/src/include/duckdb/catalog/catalog_entry.hpp\nindex f97cf4798fd7..0642edf5e813 100644\n--- a/src/include/duckdb/catalog/catalog_entry.hpp\n+++ b/src/include/duckdb/catalog/catalog_entry.hpp\n@@ -52,6 +52,7 @@ class CatalogEntry {\n \n public:\n \tvirtual unique_ptr<CatalogEntry> AlterEntry(ClientContext &context, AlterInfo *info);\n+\tvirtual void UndoAlter(ClientContext &context, AlterInfo *info);\n \n \tvirtual unique_ptr<CatalogEntry> Copy(ClientContext &context);\n \ndiff --git a/src/include/duckdb/catalog/catalog_entry/table_catalog_entry.hpp b/src/include/duckdb/catalog/catalog_entry/table_catalog_entry.hpp\nindex f2919537596f..65f990d8035e 100644\n--- a/src/include/duckdb/catalog/catalog_entry/table_catalog_entry.hpp\n+++ b/src/include/duckdb/catalog/catalog_entry/table_catalog_entry.hpp\n@@ -53,6 +53,8 @@ class TableCatalogEntry : public StandardEntry {\n public:\n \tbool HasGeneratedColumns() const;\n \tunique_ptr<CatalogEntry> AlterEntry(ClientContext &context, AlterInfo *info) override;\n+\tvoid UndoAlter(ClientContext &context, AlterInfo *info) override;\n+\n \t//! Returns whether or not a column with the given name exists\n \tDUCKDB_API bool ColumnExists(const string &name);\n \t//! Returns a reference to the column of the specified name. Throws an\ndiff --git a/src/include/duckdb/execution/column_binding_resolver.hpp b/src/include/duckdb/execution/column_binding_resolver.hpp\nindex 1cc6e58b66d2..fa9fd3f9c68e 100644\n--- a/src/include/duckdb/execution/column_binding_resolver.hpp\n+++ b/src/include/duckdb/execution/column_binding_resolver.hpp\n@@ -22,10 +22,12 @@ class ColumnBindingResolver : public LogicalOperatorVisitor {\n \tColumnBindingResolver();\n \n \tvoid VisitOperator(LogicalOperator &op) override;\n+\tstatic void Verify(LogicalOperator &op);\n \n protected:\n \tvector<ColumnBinding> bindings;\n \n \tunique_ptr<Expression> VisitReplace(BoundColumnRefExpression &expr, unique_ptr<Expression> *expr_ptr) override;\n+\tstatic unordered_set<idx_t> VerifyInternal(LogicalOperator &op);\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/operator/join/physical_join.hpp b/src/include/duckdb/execution/operator/join/physical_join.hpp\nindex 734b9cd60d65..c90a7dc9e8bd 100644\n--- a/src/include/duckdb/execution/operator/join/physical_join.hpp\n+++ b/src/include/duckdb/execution/operator/join/physical_join.hpp\n@@ -23,6 +23,7 @@ class PhysicalJoin : public CachingPhysicalOperator {\n public:\n \tbool EmptyResultIfRHSIsEmpty() const;\n \n+\tstatic bool HasNullValues(DataChunk &chunk);\n \tstatic void ConstructSemiJoinResult(DataChunk &left, DataChunk &result, bool found_match[]);\n \tstatic void ConstructAntiJoinResult(DataChunk &left, DataChunk &result, bool found_match[]);\n \tstatic void ConstructMarkJoinResult(DataChunk &join_keys, DataChunk &left, DataChunk &result, bool found_match[],\ndiff --git a/src/include/duckdb/execution/operator/join/physical_nested_loop_join.hpp b/src/include/duckdb/execution/operator/join/physical_nested_loop_join.hpp\nindex b17c7d5fd374..32796a3480db 100644\n--- a/src/include/duckdb/execution/operator/join/physical_nested_loop_join.hpp\n+++ b/src/include/duckdb/execution/operator/join/physical_nested_loop_join.hpp\n@@ -68,7 +68,7 @@ class PhysicalNestedLoopJoin : public PhysicalComparisonJoin {\n \t\treturn true;\n \t}\n \n-\tstatic bool IsSupported(const vector<JoinCondition> &conditions);\n+\tstatic bool IsSupported(const vector<JoinCondition> &conditions, JoinType join_type);\n \n public:\n \t//! Returns a list of the types of the join conditions\ndiff --git a/src/include/duckdb/optimizer/optimizer.hpp b/src/include/duckdb/optimizer/optimizer.hpp\nindex a1abfa53ac52..96bde0ad7012 100644\n--- a/src/include/duckdb/optimizer/optimizer.hpp\n+++ b/src/include/duckdb/optimizer/optimizer.hpp\n@@ -30,6 +30,10 @@ class Optimizer {\n \n private:\n \tvoid RunOptimizer(OptimizerType type, const std::function<void()> &callback);\n+\tvoid Verify(LogicalOperator &op);\n+\n+private:\n+\tunique_ptr<LogicalOperator> plan;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/parallel/pipeline.hpp b/src/include/duckdb/parallel/pipeline.hpp\nindex 6642b63cc738..2608b7d49ddf 100644\n--- a/src/include/duckdb/parallel/pipeline.hpp\n+++ b/src/include/duckdb/parallel/pipeline.hpp\n@@ -64,6 +64,9 @@ class Pipeline : public std::enable_shared_from_this<Pipeline> {\n \tvoid Reset();\n \tvoid ResetSink();\n \tvoid ResetSource(bool force);\n+\tvoid ClearSource() {\n+\t\tsource_state.reset();\n+\t}\n \tvoid Schedule(shared_ptr<Event> &event);\n \n \t//! Finalize this pipeline\ndiff --git a/src/include/duckdb/planner/expression_binder/having_binder.hpp b/src/include/duckdb/planner/expression_binder/having_binder.hpp\nindex 4ac14b889d9c..11b130c53c42 100644\n--- a/src/include/duckdb/planner/expression_binder/having_binder.hpp\n+++ b/src/include/duckdb/planner/expression_binder/having_binder.hpp\n@@ -10,6 +10,7 @@\n \n #include \"duckdb/planner/expression_binder/select_binder.hpp\"\n #include \"duckdb/planner/expression_binder/column_alias_binder.hpp\"\n+#include \"duckdb/common/enums/aggregate_handling.hpp\"\n \n namespace duckdb {\n \n@@ -17,7 +18,7 @@ namespace duckdb {\n class HavingBinder : public SelectBinder {\n public:\n \tHavingBinder(Binder &binder, ClientContext &context, BoundSelectNode &node, BoundGroupInformation &info,\n-\t             case_insensitive_map_t<idx_t> &alias_map);\n+\t             case_insensitive_map_t<idx_t> &alias_map, AggregateHandling aggregate_handling);\n \n protected:\n \tBindResult BindExpression(unique_ptr<ParsedExpression> *expr_ptr, idx_t depth,\n@@ -27,6 +28,7 @@ class HavingBinder : public SelectBinder {\n \tBindResult BindColumnRef(unique_ptr<ParsedExpression> *expr_ptr, idx_t depth, bool root_expression);\n \n \tColumnAliasBinder column_alias_binder;\n+\tAggregateHandling aggregate_handling;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/planner/logical_operator.hpp b/src/include/duckdb/planner/logical_operator.hpp\nindex 57ef32c22821..a02f232eacd7 100644\n--- a/src/include/duckdb/planner/logical_operator.hpp\n+++ b/src/include/duckdb/planner/logical_operator.hpp\n@@ -83,6 +83,9 @@ class LogicalOperator {\n \t\treturn true;\n \t}\n \n+\t//! Returns the set of table indexes of this operator\n+\tvirtual vector<idx_t> GetTableIndex() const;\n+\n protected:\n \t//! Resolve types for this specific operator\n \tvirtual void ResolveTypes() = 0;\ndiff --git a/src/include/duckdb/planner/operator/logical_aggregate.hpp b/src/include/duckdb/planner/operator/logical_aggregate.hpp\nindex f992b9ba3dd3..bcfce28f152c 100644\n--- a/src/include/duckdb/planner/operator/logical_aggregate.hpp\n+++ b/src/include/duckdb/planner/operator/logical_aggregate.hpp\n@@ -43,6 +43,7 @@ class LogicalAggregate : public LogicalOperator {\n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n \tidx_t EstimateCardinality(ClientContext &context) override;\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override;\ndiff --git a/src/include/duckdb/planner/operator/logical_column_data_get.hpp b/src/include/duckdb/planner/operator/logical_column_data_get.hpp\nindex 402b6907ace1..4827d9d215cb 100644\n--- a/src/include/duckdb/planner/operator/logical_column_data_get.hpp\n+++ b/src/include/duckdb/planner/operator/logical_column_data_get.hpp\n@@ -30,6 +30,7 @@ class LogicalColumnDataGet : public LogicalOperator {\n \n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override {\ndiff --git a/src/include/duckdb/planner/operator/logical_cteref.hpp b/src/include/duckdb/planner/operator/logical_cteref.hpp\nindex 0203f698df88..9f447687ecac 100644\n--- a/src/include/duckdb/planner/operator/logical_cteref.hpp\n+++ b/src/include/duckdb/planner/operator/logical_cteref.hpp\n@@ -37,6 +37,7 @@ class LogicalCTERef : public LogicalOperator {\n \t}\n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override {\ndiff --git a/src/include/duckdb/planner/operator/logical_delete.hpp b/src/include/duckdb/planner/operator/logical_delete.hpp\nindex 616bb0e3f5bc..d6b770eec5c6 100644\n--- a/src/include/duckdb/planner/operator/logical_delete.hpp\n+++ b/src/include/duckdb/planner/operator/logical_delete.hpp\n@@ -16,8 +16,9 @@ namespace duckdb {\n \n class LogicalDelete : public LogicalOperator {\n public:\n-\texplicit LogicalDelete(TableCatalogEntry *table)\n-\t    : LogicalOperator(LogicalOperatorType::LOGICAL_DELETE), table(table), table_index(0), return_chunk(false) {\n+\texplicit LogicalDelete(TableCatalogEntry *table, idx_t table_index)\n+\t    : LogicalOperator(LogicalOperatorType::LOGICAL_DELETE), table(table), table_index(table_index),\n+\t      return_chunk(false) {\n \t}\n \n \tTableCatalogEntry *table;\n@@ -28,6 +29,7 @@ class LogicalDelete : public LogicalOperator {\n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n \tidx_t EstimateCardinality(ClientContext &context) override;\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvector<ColumnBinding> GetColumnBindings() override {\ndiff --git a/src/include/duckdb/planner/operator/logical_delim_get.hpp b/src/include/duckdb/planner/operator/logical_delim_get.hpp\nindex 28cb098289ef..c7d014f1a2dc 100644\n--- a/src/include/duckdb/planner/operator/logical_delim_get.hpp\n+++ b/src/include/duckdb/planner/operator/logical_delim_get.hpp\n@@ -32,6 +32,7 @@ class LogicalDelimGet : public LogicalOperator {\n \t}\n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override {\ndiff --git a/src/include/duckdb/planner/operator/logical_dummy_scan.hpp b/src/include/duckdb/planner/operator/logical_dummy_scan.hpp\nindex 354d29e27efb..2079ba2287ac 100644\n--- a/src/include/duckdb/planner/operator/logical_dummy_scan.hpp\n+++ b/src/include/duckdb/planner/operator/logical_dummy_scan.hpp\n@@ -31,6 +31,7 @@ class LogicalDummyScan : public LogicalOperator {\n \t}\n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override {\ndiff --git a/src/include/duckdb/planner/operator/logical_expression_get.hpp b/src/include/duckdb/planner/operator/logical_expression_get.hpp\nindex 909a4f5002a6..70f3d50e46e6 100644\n--- a/src/include/duckdb/planner/operator/logical_expression_get.hpp\n+++ b/src/include/duckdb/planner/operator/logical_expression_get.hpp\n@@ -37,6 +37,7 @@ class LogicalExpressionGet : public LogicalOperator {\n \tidx_t EstimateCardinality(ClientContext &context) override {\n \t\treturn expressions.size();\n \t}\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override {\ndiff --git a/src/include/duckdb/planner/operator/logical_get.hpp b/src/include/duckdb/planner/operator/logical_get.hpp\nindex 15db5e33c968..12882947f2bb 100644\n--- a/src/include/duckdb/planner/operator/logical_get.hpp\n+++ b/src/include/duckdb/planner/operator/logical_get.hpp\n@@ -56,6 +56,7 @@ class LogicalGet : public LogicalOperator {\n \n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override;\ndiff --git a/src/include/duckdb/planner/operator/logical_insert.hpp b/src/include/duckdb/planner/operator/logical_insert.hpp\nindex 2e08a891e8f8..319b5cee665b 100644\n--- a/src/include/duckdb/planner/operator/logical_insert.hpp\n+++ b/src/include/duckdb/planner/operator/logical_insert.hpp\n@@ -16,8 +16,9 @@ namespace duckdb {\n //! LogicalInsert represents an insertion of data into a base table\n class LogicalInsert : public LogicalOperator {\n public:\n-\texplicit LogicalInsert(TableCatalogEntry *table)\n-\t    : LogicalOperator(LogicalOperatorType::LOGICAL_INSERT), table(table), table_index(0), return_chunk(false) {\n+\tLogicalInsert(TableCatalogEntry *table, idx_t table_index)\n+\t    : LogicalOperator(LogicalOperatorType::LOGICAL_INSERT), table(table), table_index(table_index),\n+\t      return_chunk(false) {\n \t}\n \n \tvector<vector<unique_ptr<Expression>>> insert_values;\n@@ -54,5 +55,6 @@ class LogicalInsert : public LogicalOperator {\n \t}\n \n \tidx_t EstimateCardinality(ClientContext &context) override;\n+\tvector<idx_t> GetTableIndex() const override;\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/planner/operator/logical_projection.hpp b/src/include/duckdb/planner/operator/logical_projection.hpp\nindex c751ce8d754c..c20567e73f48 100644\n--- a/src/include/duckdb/planner/operator/logical_projection.hpp\n+++ b/src/include/duckdb/planner/operator/logical_projection.hpp\n@@ -23,6 +23,7 @@ class LogicalProjection : public LogicalOperator {\n \tvector<ColumnBinding> GetColumnBindings() override;\n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override;\ndiff --git a/src/include/duckdb/planner/operator/logical_recursive_cte.hpp b/src/include/duckdb/planner/operator/logical_recursive_cte.hpp\nindex f8370fe4353f..94dde0c87499 100644\n--- a/src/include/duckdb/planner/operator/logical_recursive_cte.hpp\n+++ b/src/include/duckdb/planner/operator/logical_recursive_cte.hpp\n@@ -36,6 +36,7 @@ class LogicalRecursiveCTE : public LogicalOperator {\n \t}\n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override {\ndiff --git a/src/include/duckdb/planner/operator/logical_set_operation.hpp b/src/include/duckdb/planner/operator/logical_set_operation.hpp\nindex 11fcd72a3a67..8abe468c45ad 100644\n--- a/src/include/duckdb/planner/operator/logical_set_operation.hpp\n+++ b/src/include/duckdb/planner/operator/logical_set_operation.hpp\n@@ -37,6 +37,7 @@ class LogicalSetOperation : public LogicalOperator {\n \n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override {\ndiff --git a/src/include/duckdb/planner/operator/logical_unnest.hpp b/src/include/duckdb/planner/operator/logical_unnest.hpp\nindex 2172071313f3..7b71acc44a91 100644\n--- a/src/include/duckdb/planner/operator/logical_unnest.hpp\n+++ b/src/include/duckdb/planner/operator/logical_unnest.hpp\n@@ -26,6 +26,7 @@ class LogicalUnnest : public LogicalOperator {\n \tvector<ColumnBinding> GetColumnBindings() override;\n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override;\ndiff --git a/src/include/duckdb/planner/operator/logical_window.hpp b/src/include/duckdb/planner/operator/logical_window.hpp\nindex ee48bc3acae7..0b9685506ee1 100644\n--- a/src/include/duckdb/planner/operator/logical_window.hpp\n+++ b/src/include/duckdb/planner/operator/logical_window.hpp\n@@ -26,6 +26,7 @@ class LogicalWindow : public LogicalOperator {\n \tvector<ColumnBinding> GetColumnBindings() override;\n \tvoid Serialize(FieldWriter &writer) const override;\n \tstatic unique_ptr<LogicalOperator> Deserialize(LogicalDeserializationState &state, FieldReader &reader);\n+\tvector<idx_t> GetTableIndex() const override;\n \n protected:\n \tvoid ResolveTypes() override;\ndiff --git a/src/main/client_context.cpp b/src/main/client_context.cpp\nindex 394bc1c42026..97901b36ed0d 100644\n--- a/src/main/client_context.cpp\n+++ b/src/main/client_context.cpp\n@@ -482,6 +482,7 @@ unique_ptr<LogicalOperator> ClientContext::ExtractPlan(const string &query) {\n \t\t}\n \n \t\tColumnBindingResolver resolver;\n+\t\tresolver.Verify(*plan);\n \t\tresolver.VisitOperator(*plan);\n \n \t\tplan->ResolveOperatorTypes();\ndiff --git a/src/optimizer/deliminator.cpp b/src/optimizer/deliminator.cpp\nindex 00867bbe0af2..8dd9f8f17511 100644\n--- a/src/optimizer/deliminator.cpp\n+++ b/src/optimizer/deliminator.cpp\n@@ -415,7 +415,8 @@ bool Deliminator::RemoveInequalityCandidate(unique_ptr<LogicalOperator> *plan, u\n \t\t\t}\n \t\t\tparent_expr =\n \t\t\t    make_unique<BoundColumnRefExpression>(parent_expr->alias, parent_expr->return_type, it->first);\n-\t\t\tparent_cond.comparison = child_cond.comparison;\n+\t\t\tparent_cond.comparison =\n+\t\t\t    parent_delim_get_side == 0 ? child_cond.comparison : FlipComparisionExpression(child_cond.comparison);\n \t\t\tbreak;\n \t\t}\n \t}\ndiff --git a/src/optimizer/filter_combiner.cpp b/src/optimizer/filter_combiner.cpp\nindex 44bb22aa9ec9..b8afe56fd7e5 100644\n--- a/src/optimizer/filter_combiner.cpp\n+++ b/src/optimizer/filter_combiner.cpp\n@@ -61,6 +61,9 @@ idx_t FilterCombiner::GetEquivalenceSet(Expression *expr) {\n \n FilterResult FilterCombiner::AddConstantComparison(vector<ExpressionValueInformation> &info_list,\n                                                    ExpressionValueInformation info) {\n+\tif (info.constant.IsNull()) {\n+\t\treturn FilterResult::UNSATISFIABLE;\n+\t}\n \tfor (idx_t i = 0; i < info_list.size(); i++) {\n \t\tauto comparison = CompareValueInformation(info_list[i], info);\n \t\tswitch (comparison) {\ndiff --git a/src/optimizer/filter_pushdown.cpp b/src/optimizer/filter_pushdown.cpp\nindex b2b2d547a480..b8b51830ab79 100644\n--- a/src/optimizer/filter_pushdown.cpp\n+++ b/src/optimizer/filter_pushdown.cpp\n@@ -71,7 +71,7 @@ unique_ptr<LogicalOperator> FilterPushdown::PushdownJoin(unique_ptr<LogicalOpera\n void FilterPushdown::PushFilters() {\n \tfor (auto &f : filters) {\n \t\tauto result = combiner.AddFilter(move(f->filter));\n-\t\tD_ASSERT(result == FilterResult::SUCCESS);\n+\t\tD_ASSERT(result != FilterResult::UNSUPPORTED);\n \t\t(void)result;\n \t}\n \tfilters.clear();\ndiff --git a/src/optimizer/optimizer.cpp b/src/optimizer/optimizer.cpp\nindex 672ec4b43869..bd676fd8a09b 100644\n--- a/src/optimizer/optimizer.cpp\n+++ b/src/optimizer/optimizer.cpp\n@@ -22,6 +22,7 @@\n #include \"duckdb/optimizer/topn_optimizer.hpp\"\n #include \"duckdb/planner/binder.hpp\"\n #include \"duckdb/planner/planner.hpp\"\n+#include \"duckdb/execution/column_binding_resolver.hpp\"\n \n namespace duckdb {\n \n@@ -59,9 +60,18 @@ void Optimizer::RunOptimizer(OptimizerType type, const std::function<void()> &ca\n \tprofiler.StartPhase(OptimizerTypeToString(type));\n \tcallback();\n \tprofiler.EndPhase();\n+\tif (plan) {\n+\t\tVerify(*plan);\n+\t}\n+}\n+\n+void Optimizer::Verify(LogicalOperator &op) {\n+\tColumnBindingResolver::Verify(op);\n }\n \n-unique_ptr<LogicalOperator> Optimizer::Optimize(unique_ptr<LogicalOperator> plan) {\n+unique_ptr<LogicalOperator> Optimizer::Optimize(unique_ptr<LogicalOperator> plan_p) {\n+\tVerify(*plan_p);\n+\tthis->plan = move(plan_p);\n \t// first we perform expression rewrites using the ExpressionRewriter\n \t// this does not change the logical plan structure, but only simplifies the expression trees\n \tRunOptimizer(OptimizerType::EXPRESSION_REWRITER, [&]() { rewriter.VisitOperator(*plan); });\n@@ -148,7 +158,7 @@ unique_ptr<LogicalOperator> Optimizer::Optimize(unique_ptr<LogicalOperator> plan\n \n \tPlanner::VerifyPlan(context, plan);\n \n-\treturn plan;\n+\treturn move(plan);\n }\n \n } // namespace duckdb\ndiff --git a/src/optimizer/pullup/pullup_filter.cpp b/src/optimizer/pullup/pullup_filter.cpp\nindex 51ea3699110b..895b5515ab42 100644\n--- a/src/optimizer/pullup/pullup_filter.cpp\n+++ b/src/optimizer/pullup/pullup_filter.cpp\n@@ -9,7 +9,8 @@ namespace duckdb {\n unique_ptr<LogicalOperator> FilterPullup::PullupFilter(unique_ptr<LogicalOperator> op) {\n \tD_ASSERT(op->type == LogicalOperatorType::LOGICAL_FILTER);\n \n-\tif (can_pullup) {\n+\tauto &filter = (LogicalFilter &)*op;\n+\tif (can_pullup && filter.projection_map.empty()) {\n \t\tunique_ptr<LogicalOperator> child = move(op->children[0]);\n \t\tchild = Rewrite(move(child));\n \t\t// moving filter's expressions\ndiff --git a/src/optimizer/pushdown/pushdown_filter.cpp b/src/optimizer/pushdown/pushdown_filter.cpp\nindex 4ab47345e9aa..624809056804 100644\n--- a/src/optimizer/pushdown/pushdown_filter.cpp\n+++ b/src/optimizer/pushdown/pushdown_filter.cpp\n@@ -9,6 +9,9 @@ using Filter = FilterPushdown::Filter;\n unique_ptr<LogicalOperator> FilterPushdown::PushdownFilter(unique_ptr<LogicalOperator> op) {\n \tD_ASSERT(op->type == LogicalOperatorType::LOGICAL_FILTER);\n \tauto &filter = (LogicalFilter &)*op;\n+\tif (!filter.projection_map.empty()) {\n+\t\treturn FinishPushdown(move(op));\n+\t}\n \t// filter: gather the filters and remove the filter from the set of operations\n \tfor (auto &expression : filter.expressions) {\n \t\tif (AddFilter(move(expression)) == FilterResult::UNSATISFIABLE) {\ndiff --git a/src/optimizer/pushdown/pushdown_mark_join.cpp b/src/optimizer/pushdown/pushdown_mark_join.cpp\nindex de604f029c2b..58530d4039bd 100644\n--- a/src/optimizer/pushdown/pushdown_mark_join.cpp\n+++ b/src/optimizer/pushdown/pushdown_mark_join.cpp\n@@ -17,8 +17,8 @@ unique_ptr<LogicalOperator> FilterPushdown::PushdownMarkJoin(unique_ptr<LogicalO\n \n \tright_bindings.insert(comp_join.mark_index);\n \tFilterPushdown left_pushdown(optimizer), right_pushdown(optimizer);\n-#ifndef NDEBUG\n-\tbool found_mark_reference = false;\n+#ifdef DEBUG\n+\tbool simplified_mark_join = false;\n #endif\n \t// now check the set of filters\n \tfor (idx_t i = 0; i < filters.size(); i++) {\n@@ -30,15 +30,16 @@ unique_ptr<LogicalOperator> FilterPushdown::PushdownMarkJoin(unique_ptr<LogicalO\n \t\t\tfilters.erase(filters.begin() + i);\n \t\t\ti--;\n \t\t} else if (side == JoinSide::RIGHT) {\n-\t\t\t// there can only be at most one filter referencing the marker\n-#ifndef NDEBUG\n-\t\t\tD_ASSERT(!found_mark_reference);\n-\t\t\tfound_mark_reference = true;\n+#ifdef DEBUG\n+\t\t\tD_ASSERT(!simplified_mark_join);\n #endif\n \t\t\t// this filter references the marker\n \t\t\t// we can turn this into a SEMI join if the filter is on only the marker\n \t\t\tif (filters[i]->filter->type == ExpressionType::BOUND_COLUMN_REF) {\n \t\t\t\t// filter just references the marker: turn into semi join\n+#ifdef DEBUG\n+\t\t\t\tsimplified_mark_join = true;\n+#endif\n \t\t\t\tjoin.join_type = JoinType::SEMI;\n \t\t\t\tfilters.erase(filters.begin() + i);\n \t\t\t\ti--;\n@@ -61,6 +62,9 @@ unique_ptr<LogicalOperator> FilterPushdown::PushdownMarkJoin(unique_ptr<LogicalO\n \t\t\t\t\t\t}\n \t\t\t\t\t}\n \t\t\t\t\tif (all_null_values_are_equal) {\n+#ifdef DEBUG\n+\t\t\t\t\t\tsimplified_mark_join = true;\n+#endif\n \t\t\t\t\t\t// all null values are equal, convert to ANTI join\n \t\t\t\t\t\tjoin.join_type = JoinType::ANTI;\n \t\t\t\t\t\tfilters.erase(filters.begin() + i);\ndiff --git a/src/optimizer/rule/comparison_simplification.cpp b/src/optimizer/rule/comparison_simplification.cpp\nindex f1cf1f8c32cc..aee4542793a5 100644\n--- a/src/optimizer/rule/comparison_simplification.cpp\n+++ b/src/optimizer/rule/comparison_simplification.cpp\n@@ -52,7 +52,8 @@ unique_ptr<Expression> ComparisonSimplificationRule::Apply(LogicalOperator &op,\n \t\t}\n \n \t\t// Is the constant cast invertible?\n-\t\tif (!BoundCastExpression::CastIsInvertible(cast_expression->return_type, target_type)) {\n+\t\tif (!cast_constant.IsNull() &&\n+\t\t    !BoundCastExpression::CastIsInvertible(cast_expression->return_type, target_type)) {\n \t\t\t// Is it actually invertible?\n \t\t\tValue uncast_constant;\n \t\t\tif (!cast_constant.DefaultTryCastAs(constant_value.type(), uncast_constant, &error_message, true) ||\ndiff --git a/src/planner/binder/query_node/bind_select_node.cpp b/src/planner/binder/query_node/bind_select_node.cpp\nindex 7794514796f3..a03c8ee98f57 100644\n--- a/src/planner/binder/query_node/bind_select_node.cpp\n+++ b/src/planner/binder/query_node/bind_select_node.cpp\n@@ -54,6 +54,9 @@ unique_ptr<Expression> Binder::BindDelimiter(ClientContext &context, OrderBinder\n \t\tdelimiter_value = ExpressionExecutor::EvaluateScalar(context, *expr).CastAs(context, type);\n \t\treturn nullptr;\n \t}\n+\tif (!new_binder->correlated_columns.empty()) {\n+\t\tthrow BinderException(\"Correlated columns not supported in LIMIT/OFFSET\");\n+\t}\n \t// move any correlated columns to this binder\n \tMoveCorrelatedExpressions(*new_binder);\n \treturn expr;\n@@ -419,16 +422,22 @@ unique_ptr<BoundQueryNode> Binder::BindNode(SelectNode &statement) {\n \n \t// bind the HAVING clause, if any\n \tif (statement.having) {\n-\t\tHavingBinder having_binder(*this, context, *result, info, alias_map);\n+\t\tHavingBinder having_binder(*this, context, *result, info, alias_map, statement.aggregate_handling);\n \t\tExpressionBinder::QualifyColumnNames(*this, statement.having);\n \t\tresult->having = having_binder.Bind(statement.having);\n \t}\n \n \t// bind the QUALIFY clause, if any\n \tif (statement.qualify) {\n+\t\tif (statement.aggregate_handling == AggregateHandling::FORCE_AGGREGATES) {\n+\t\t\tthrow BinderException(\"Combining QUALIFY with GROUP BY ALL is not supported yet\");\n+\t\t}\n \t\tQualifyBinder qualify_binder(*this, context, *result, info, alias_map);\n \t\tExpressionBinder::QualifyColumnNames(*this, statement.qualify);\n \t\tresult->qualify = qualify_binder.Bind(statement.qualify);\n+\t\tif (qualify_binder.HasBoundColumns() && qualify_binder.BoundAggregates()) {\n+\t\t\tthrow BinderException(\"Cannot mix aggregates with non-aggregated columns!\");\n+\t\t}\n \t}\n \n \t// after that, we bind to the SELECT list\ndiff --git a/src/planner/binder/query_node/plan_subquery.cpp b/src/planner/binder/query_node/plan_subquery.cpp\nindex 570bd3e678cc..325fd22b0894 100644\n--- a/src/planner/binder/query_node/plan_subquery.cpp\n+++ b/src/planner/binder/query_node/plan_subquery.cpp\n@@ -353,7 +353,7 @@ unique_ptr<Expression> Binder::PlanSubquery(BoundSubqueryExpression &expr, uniqu\n \tD_ASSERT(root);\n \t// first we translate the QueryNode of the subquery into a logical plan\n \t// note that we do not plan nested subqueries yet\n-\tauto sub_binder = Binder::CreateBinder(context);\n+\tauto sub_binder = Binder::CreateBinder(context, this);\n \tsub_binder->plan_subquery = false;\n \tauto subquery_root = sub_binder->CreatePlan(*expr.subquery);\n \tD_ASSERT(subquery_root);\ndiff --git a/src/planner/binder/statement/bind_copy.cpp b/src/planner/binder/statement/bind_copy.cpp\nindex 108e0c8d722d..1138f3a62b81 100644\n--- a/src/planner/binder/statement/bind_copy.cpp\n+++ b/src/planner/binder/statement/bind_copy.cpp\n@@ -112,8 +112,8 @@ BoundStatement Binder::BindCopyFrom(CopyStatement &stmt) {\n \n \tauto function_data =\n \t    copy_function->function.copy_from_bind(context, *stmt.info, expected_names, bound_insert.expected_types);\n-\tauto get = make_unique<LogicalGet>(0, copy_function->function.copy_from_function, move(function_data),\n-\t                                   bound_insert.expected_types, expected_names);\n+\tauto get = make_unique<LogicalGet>(GenerateTableIndex(), copy_function->function.copy_from_function,\n+\t                                   move(function_data), bound_insert.expected_types, expected_names);\n \tfor (idx_t i = 0; i < bound_insert.expected_types.size(); i++) {\n \t\tget->column_ids.push_back(i);\n \t}\ndiff --git a/src/planner/binder/statement/bind_create_table.cpp b/src/planner/binder/statement/bind_create_table.cpp\nindex 8d42e0eaff78..a8f2eaf296f1 100644\n--- a/src/planner/binder/statement/bind_create_table.cpp\n+++ b/src/planner/binder/statement/bind_create_table.cpp\n@@ -15,6 +15,7 @@\n #include \"duckdb/common/queue.hpp\"\n #include \"duckdb/parser/expression/list.hpp\"\n #include \"duckdb/common/index_map.hpp\"\n+#include \"duckdb/planner/expression_iterator.hpp\"\n \n #include <algorithm>\n \n@@ -216,6 +217,31 @@ void Binder::BindDefaultValues(ColumnList &columns, vector<unique_ptr<Expression\n \t}\n }\n \n+static void ExtractExpressionDependencies(Expression &expr, unordered_set<CatalogEntry *> &dependencies) {\n+\tif (expr.type == ExpressionType::BOUND_FUNCTION) {\n+\t\tauto &function = (BoundFunctionExpression &)expr;\n+\t\tif (function.function.dependency) {\n+\t\t\tfunction.function.dependency(function, dependencies);\n+\t\t}\n+\t}\n+\tExpressionIterator::EnumerateChildren(\n+\t    expr, [&](Expression &child) { ExtractExpressionDependencies(child, dependencies); });\n+}\n+\n+static void ExtractDependencies(BoundCreateTableInfo &info) {\n+\tfor (auto &default_value : info.bound_defaults) {\n+\t\tif (default_value) {\n+\t\t\tExtractExpressionDependencies(*default_value, info.dependencies);\n+\t\t}\n+\t}\n+\tfor (auto &constraint : info.bound_constraints) {\n+\t\tif (constraint->type == ConstraintType::CHECK) {\n+\t\t\tauto &bound_check = (BoundCheckConstraint &)*constraint;\n+\t\t\tExtractExpressionDependencies(*bound_check.expression, info.dependencies);\n+\t\t}\n+\t}\n+}\n+\n unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateInfo> info) {\n \tauto &base = (CreateTableInfo &)*info;\n \n@@ -246,6 +272,8 @@ unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateIn\n \t\t// bind the default values\n \t\tBindDefaultValues(base.columns, result->bound_defaults);\n \t}\n+\t// extract dependencies from any default values or CHECK constraints\n+\tExtractDependencies(*result);\n \n \tif (base.columns.PhysicalColumnCount() == 0) {\n \t\tthrow BinderException(\"Creating a table without physical (non-generated) columns is not supported\");\ndiff --git a/src/planner/binder/statement/bind_delete.cpp b/src/planner/binder/statement/bind_delete.cpp\nindex e4c4b929064b..cd03c6c57229 100644\n--- a/src/planner/binder/statement/bind_delete.cpp\n+++ b/src/planner/binder/statement/bind_delete.cpp\n@@ -39,7 +39,8 @@ BoundStatement Binder::Bind(DeleteStatement &stmt) {\n \t\tunique_ptr<LogicalOperator> child_operator;\n \t\tfor (auto &using_clause : stmt.using_clauses) {\n \t\t\t// bind the using clause\n-\t\t\tauto bound_node = Bind(*using_clause);\n+\t\t\tauto using_binder = Binder::CreateBinder(context, this);\n+\t\t\tauto bound_node = using_binder->Bind(*using_clause);\n \t\t\tauto op = CreatePlan(*bound_node);\n \t\t\tif (child_operator) {\n \t\t\t\t// already bound a child: create a cross product to unify the two\n@@ -47,6 +48,7 @@ BoundStatement Binder::Bind(DeleteStatement &stmt) {\n \t\t\t} else {\n \t\t\t\tchild_operator = move(op);\n \t\t\t}\n+\t\t\tbind_context.AddContext(move(using_binder->bind_context));\n \t\t}\n \t\tif (child_operator) {\n \t\t\troot = LogicalCrossProduct::Create(move(root), move(child_operator));\n@@ -65,7 +67,7 @@ BoundStatement Binder::Bind(DeleteStatement &stmt) {\n \t\troot = move(filter);\n \t}\n \t// create the delete node\n-\tauto del = make_unique<LogicalDelete>(table);\n+\tauto del = make_unique<LogicalDelete>(table, GenerateTableIndex());\n \tdel->AddChild(move(root));\n \n \t// set up the delete expression\ndiff --git a/src/planner/binder/statement/bind_execute.cpp b/src/planner/binder/statement/bind_execute.cpp\nindex f960a5037642..1f3aec572131 100644\n--- a/src/planner/binder/statement/bind_execute.cpp\n+++ b/src/planner/binder/statement/bind_execute.cpp\n@@ -45,6 +45,7 @@ BoundStatement Binder::Bind(ExecuteStatement &stmt) {\n \t\tprepared = prepared_planner.PrepareSQLStatement(entry->second->unbound_statement->Copy());\n \t\trebound_plan = move(prepared_planner.plan);\n \t\tD_ASSERT(prepared->properties.bound_all_parameters);\n+\t\tthis->bound_tables = prepared_planner.binder->bound_tables;\n \t}\n \t// copy the properties of the prepared statement into the planner\n \tthis->properties = prepared->properties;\ndiff --git a/src/planner/binder/statement/bind_export.cpp b/src/planner/binder/statement/bind_export.cpp\nindex 0a1c9062e5e5..320e89fae702 100644\n--- a/src/planner/binder/statement/bind_export.cpp\n+++ b/src/planner/binder/statement/bind_export.cpp\n@@ -175,7 +175,7 @@ BoundStatement Binder::Bind(ExportStatement &stmt) {\n \t\tCopyStatement copy_stmt;\n \t\tcopy_stmt.info = move(info);\n \n-\t\tauto copy_binder = Binder::CreateBinder(context);\n+\t\tauto copy_binder = Binder::CreateBinder(context, this);\n \t\tauto bound_statement = copy_binder->Bind(copy_stmt);\n \t\tif (child_operator) {\n \t\t\t// use UNION ALL to combine the individual copy statements into a single node\ndiff --git a/src/planner/binder/statement/bind_insert.cpp b/src/planner/binder/statement/bind_insert.cpp\nindex 6fa41e6d1d50..4e9ea1c9a75b 100644\n--- a/src/planner/binder/statement/bind_insert.cpp\n+++ b/src/planner/binder/statement/bind_insert.cpp\n@@ -37,7 +37,7 @@ BoundStatement Binder::Bind(InsertStatement &stmt) {\n \t\tproperties.read_only = false;\n \t}\n \n-\tauto insert = make_unique<LogicalInsert>(table);\n+\tauto insert = make_unique<LogicalInsert>(table, GenerateTableIndex());\n \n \t// Add CTEs as bindable\n \tAddCTEMap(stmt.cte_map);\ndiff --git a/src/planner/binder/statement/bind_prepare.cpp b/src/planner/binder/statement/bind_prepare.cpp\nindex 7e94252799ca..430c558819e6 100644\n--- a/src/planner/binder/statement/bind_prepare.cpp\n+++ b/src/planner/binder/statement/bind_prepare.cpp\n@@ -8,6 +8,7 @@ namespace duckdb {\n BoundStatement Binder::Bind(PrepareStatement &stmt) {\n \tPlanner prepared_planner(context);\n \tauto prepared_data = prepared_planner.PrepareSQLStatement(move(stmt.statement));\n+\tthis->bound_tables = prepared_planner.binder->bound_tables;\n \n \tauto prepare = make_unique<LogicalPrepare>(stmt.name, move(prepared_data), move(prepared_planner.plan));\n \t// we can prepare in read-only mode: prepared statements are not written to the catalog\ndiff --git a/src/planner/binder/statement/bind_simple.cpp b/src/planner/binder/statement/bind_simple.cpp\nindex b778490c2c7d..7ba60561a03b 100644\n--- a/src/planner/binder/statement/bind_simple.cpp\n+++ b/src/planner/binder/statement/bind_simple.cpp\n@@ -29,7 +29,7 @@ BoundStatement Binder::Bind(AlterStatement &stmt) {\n \n BoundStatement Binder::Bind(TransactionStatement &stmt) {\n \t// transaction statements do not require a valid transaction\n-\tproperties.requires_valid_transaction = false;\n+\tproperties.requires_valid_transaction = stmt.info->type == TransactionType::BEGIN_TRANSACTION;\n \n \tBoundStatement result;\n \tresult.names = {\"Success\"};\ndiff --git a/src/planner/binder/statement/bind_update.cpp b/src/planner/binder/statement/bind_update.cpp\nindex a9593fe1634c..b5bd57a3e33c 100644\n--- a/src/planner/binder/statement/bind_update.cpp\n+++ b/src/planner/binder/statement/bind_update.cpp\n@@ -88,6 +88,13 @@ static void BindUpdateConstraints(TableCatalogEntry &table, LogicalGet &get, Log\n \t\t\tBindExtraColumns(table, get, proj, update, check.bound_columns);\n \t\t}\n \t}\n+\tif (update.return_chunk) {\n+\t\tphysical_index_set_t all_columns;\n+\t\tfor (idx_t i = 0; i < table.storage->column_definitions.size(); i++) {\n+\t\t\tall_columns.insert(PhysicalIndex(i));\n+\t\t}\n+\t\tBindExtraColumns(table, get, proj, update, all_columns);\n+\t}\n \t// for index updates we always turn any update into an insert and a delete\n \t// we thus need all the columns to be available, hence we check if the update touches any index columns\n \t// If the returning keyword is used, we need access to the whole row in case the user requests it.\n@@ -110,7 +117,7 @@ static void BindUpdateConstraints(TableCatalogEntry &table, LogicalGet &get, Log\n \t\t}\n \t}\n \n-\tif (update.update_is_del_and_insert || update.return_chunk) {\n+\tif (update.update_is_del_and_insert) {\n \t\t// the update updates a column required by an index or requires returning the updated rows,\n \t\t// push projections for all columns\n \t\tphysical_index_set_t all_columns;\n@@ -221,16 +228,15 @@ BoundStatement Binder::Bind(UpdateStatement &stmt) {\n \t// set the projection as child of the update node and finalize the result\n \tupdate->AddChild(move(proj));\n \n+\tauto update_table_index = GenerateTableIndex();\n+\tupdate->table_index = update_table_index;\n \tif (!stmt.returning_list.empty()) {\n-\t\tauto update_table_index = GenerateTableIndex();\n-\t\tupdate->table_index = update_table_index;\n \t\tunique_ptr<LogicalOperator> update_as_logicaloperator = move(update);\n \n \t\treturn BindReturning(move(stmt.returning_list), table, update_table_index, move(update_as_logicaloperator),\n \t\t                     move(result));\n \t}\n \n-\tupdate->table_index = 0;\n \tresult.names = {\"Count\"};\n \tresult.types = {LogicalType::BIGINT};\n \tresult.plan = move(update);\ndiff --git a/src/planner/binder/tableref/bind_basetableref.cpp b/src/planner/binder/tableref/bind_basetableref.cpp\nindex 02c48328a089..50350c1d16cd 100644\n--- a/src/planner/binder/tableref/bind_basetableref.cpp\n+++ b/src/planner/binder/tableref/bind_basetableref.cpp\n@@ -140,6 +140,9 @@ unique_ptr<BoundTableRef> Binder::Bind(BaseTableRef &ref) {\n \t\t// bind the child subquery\n \t\tview_binder->AddBoundView(view_catalog_entry);\n \t\tauto bound_child = view_binder->Bind(subquery);\n+\t\tif (!view_binder->correlated_columns.empty()) {\n+\t\t\tthrow BinderException(\"Contents of view were altered - view bound correlated columns\");\n+\t\t}\n \n \t\tD_ASSERT(bound_child->type == TableReferenceType::SUBQUERY);\n \t\t// verify that the types and names match up with the expected types and names\ndiff --git a/src/planner/expression_binder/having_binder.cpp b/src/planner/expression_binder/having_binder.cpp\nindex cdea0b0c2b2e..12f60cb2c745 100644\n--- a/src/planner/expression_binder/having_binder.cpp\n+++ b/src/planner/expression_binder/having_binder.cpp\n@@ -9,8 +9,9 @@\n namespace duckdb {\n \n HavingBinder::HavingBinder(Binder &binder, ClientContext &context, BoundSelectNode &node, BoundGroupInformation &info,\n-                           case_insensitive_map_t<idx_t> &alias_map)\n-    : SelectBinder(binder, context, node, info), column_alias_binder(node, alias_map) {\n+                           case_insensitive_map_t<idx_t> &alias_map, AggregateHandling aggregate_handling)\n+    : SelectBinder(binder, context, node, info), column_alias_binder(node, alias_map),\n+      aggregate_handling(aggregate_handling) {\n \ttarget_type = LogicalType(LogicalTypeId::BOOLEAN);\n }\n \n@@ -20,7 +21,16 @@ BindResult HavingBinder::BindColumnRef(unique_ptr<ParsedExpression> *expr_ptr, i\n \tif (!alias_result.HasError()) {\n \t\treturn alias_result;\n \t}\n-\n+\tif (aggregate_handling == AggregateHandling::FORCE_AGGREGATES) {\n+\t\tauto expr = duckdb::SelectBinder::BindExpression(expr_ptr, depth);\n+\t\tif (expr.HasError()) {\n+\t\t\treturn expr;\n+\t\t}\n+\t\tauto group_ref = make_unique<BoundColumnRefExpression>(\n+\t\t    expr.expression->return_type, ColumnBinding(node.group_index, node.groups.group_expressions.size()));\n+\t\tnode.groups.group_expressions.push_back(move(expr.expression));\n+\t\treturn BindResult(move(group_ref));\n+\t}\n \treturn BindResult(StringUtil::Format(\n \t    \"column %s must appear in the GROUP BY clause or be used in an aggregate function\", expr.ToString()));\n }\ndiff --git a/src/planner/logical_operator.cpp b/src/planner/logical_operator.cpp\nindex 5619c2c40cde..7c91c6ccbad0 100644\n--- a/src/planner/logical_operator.cpp\n+++ b/src/planner/logical_operator.cpp\n@@ -351,6 +351,10 @@ unique_ptr<LogicalOperator> LogicalOperator::Deserialize(Deserializer &deseriali\n \treturn result;\n }\n \n+vector<idx_t> LogicalOperator::GetTableIndex() const {\n+\treturn vector<idx_t> {};\n+}\n+\n unique_ptr<LogicalOperator> LogicalOperator::Copy(ClientContext &context) const {\n \tBufferedSerializer logical_op_serializer;\n \ttry {\ndiff --git a/src/planner/operator/logical_aggregate.cpp b/src/planner/operator/logical_aggregate.cpp\nindex c82a17d7ab4a..51ac77456062 100644\n--- a/src/planner/operator/logical_aggregate.cpp\n+++ b/src/planner/operator/logical_aggregate.cpp\n@@ -108,4 +108,12 @@ idx_t LogicalAggregate::EstimateCardinality(ClientContext &context) {\n \treturn LogicalOperator::EstimateCardinality(context);\n }\n \n+vector<idx_t> LogicalAggregate::GetTableIndex() const {\n+\tvector<idx_t> result {group_index, aggregate_index};\n+\tif (groupings_index != DConstants::INVALID_INDEX) {\n+\t\tresult.push_back(groupings_index);\n+\t}\n+\treturn result;\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_column_data_get.cpp b/src/planner/operator/logical_column_data_get.cpp\nindex 3c09eac63ea3..c726dbe3c604 100644\n--- a/src/planner/operator/logical_column_data_get.cpp\n+++ b/src/planner/operator/logical_column_data_get.cpp\n@@ -37,4 +37,8 @@ unique_ptr<LogicalOperator> LogicalColumnDataGet::Deserialize(LogicalDeserializa\n \treturn make_unique<LogicalColumnDataGet>(table_index, move(chunk_types), move(collection));\n }\n \n+vector<idx_t> LogicalColumnDataGet::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_cteref.cpp b/src/planner/operator/logical_cteref.cpp\nindex 8931a12d541b..5860ec8e93e8 100644\n--- a/src/planner/operator/logical_cteref.cpp\n+++ b/src/planner/operator/logical_cteref.cpp\n@@ -18,4 +18,8 @@ unique_ptr<LogicalOperator> LogicalCTERef::Deserialize(LogicalDeserializationSta\n \treturn make_unique<LogicalCTERef>(table_index, cte_index, chunk_types, bound_columns);\n }\n \n+vector<idx_t> LogicalCTERef::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_delete.cpp b/src/planner/operator/logical_delete.cpp\nindex 422e90762d6d..3c29a6a537c0 100644\n--- a/src/planner/operator/logical_delete.cpp\n+++ b/src/planner/operator/logical_delete.cpp\n@@ -17,8 +17,8 @@ unique_ptr<LogicalOperator> LogicalDelete::Deserialize(LogicalDeserializationSta\n \n \tTableCatalogEntry *table_catalog_entry = catalog.GetEntry<TableCatalogEntry>(context, info->schema, info->table);\n \n-\tauto result = make_unique<LogicalDelete>(table_catalog_entry);\n-\tresult->table_index = reader.ReadRequired<idx_t>();\n+\tauto table_index = reader.ReadRequired<idx_t>();\n+\tauto result = make_unique<LogicalDelete>(table_catalog_entry, table_index);\n \tresult->return_chunk = reader.ReadRequired<bool>();\n \treturn move(result);\n }\n@@ -27,4 +27,8 @@ idx_t LogicalDelete::EstimateCardinality(ClientContext &context) {\n \treturn return_chunk ? LogicalOperator::EstimateCardinality(context) : 1;\n }\n \n+vector<idx_t> LogicalDelete::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_delim_get.cpp b/src/planner/operator/logical_delim_get.cpp\nindex c8412150fa69..b2be228fb501 100644\n--- a/src/planner/operator/logical_delim_get.cpp\n+++ b/src/planner/operator/logical_delim_get.cpp\n@@ -14,4 +14,8 @@ unique_ptr<LogicalOperator> LogicalDelimGet::Deserialize(LogicalDeserializationS\n \treturn make_unique<LogicalDelimGet>(table_index, chunk_types);\n }\n \n+vector<idx_t> LogicalDelimGet::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_dummy_scan.cpp b/src/planner/operator/logical_dummy_scan.cpp\nindex e3f81cac1583..03813658c43c 100644\n--- a/src/planner/operator/logical_dummy_scan.cpp\n+++ b/src/planner/operator/logical_dummy_scan.cpp\n@@ -12,4 +12,8 @@ unique_ptr<LogicalOperator> LogicalDummyScan::Deserialize(LogicalDeserialization\n \treturn make_unique<LogicalDummyScan>(table_index);\n }\n \n+vector<idx_t> LogicalDummyScan::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_expression_get.cpp b/src/planner/operator/logical_expression_get.cpp\nindex d3a2c63abd94..de3f5c309134 100644\n--- a/src/planner/operator/logical_expression_get.cpp\n+++ b/src/planner/operator/logical_expression_get.cpp\n@@ -26,4 +26,8 @@ unique_ptr<LogicalOperator> LogicalExpressionGet::Deserialize(LogicalDeserializa\n \treturn make_unique<LogicalExpressionGet>(table_index, expr_types, move(expressions));\n }\n \n+vector<idx_t> LogicalExpressionGet::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_get.cpp b/src/planner/operator/logical_get.cpp\nindex 3f6cbbccd6b0..89b2e72489e7 100644\n--- a/src/planner/operator/logical_get.cpp\n+++ b/src/planner/operator/logical_get.cpp\n@@ -174,4 +174,8 @@ unique_ptr<LogicalOperator> LogicalGet::Deserialize(LogicalDeserializationState\n \treturn move(result);\n }\n \n+vector<idx_t> LogicalGet::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_insert.cpp b/src/planner/operator/logical_insert.cpp\nindex 5b7f5217efb8..eb4c29cff629 100644\n--- a/src/planner/operator/logical_insert.cpp\n+++ b/src/planner/operator/logical_insert.cpp\n@@ -42,10 +42,9 @@ unique_ptr<LogicalOperator> LogicalInsert::Deserialize(LogicalDeserializationSta\n \t\tthrow InternalException(\"Cant find catalog entry for table %s\", info->table);\n \t}\n \n-\tauto result = make_unique<LogicalInsert>(table_catalog_entry);\n+\tauto result = make_unique<LogicalInsert>(table_catalog_entry, table_index);\n \tresult->type = state.type;\n \tresult->table = table_catalog_entry;\n-\tresult->table_index = table_index;\n \tresult->return_chunk = return_chunk;\n \tresult->insert_values = move(insert_values);\n \tresult->column_index_map = column_index_map;\n@@ -58,4 +57,8 @@ idx_t LogicalInsert::EstimateCardinality(ClientContext &context) {\n \treturn return_chunk ? LogicalOperator::EstimateCardinality(context) : 1;\n }\n \n+vector<idx_t> LogicalInsert::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_projection.cpp b/src/planner/operator/logical_projection.cpp\nindex 44a59cbb0e03..8d165f98cff8 100644\n--- a/src/planner/operator/logical_projection.cpp\n+++ b/src/planner/operator/logical_projection.cpp\n@@ -28,4 +28,8 @@ unique_ptr<LogicalOperator> LogicalProjection::Deserialize(LogicalDeserializatio\n \treturn make_unique<LogicalProjection>(table_index, move(expressions));\n }\n \n+vector<idx_t> LogicalProjection::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_recursive_cte.cpp b/src/planner/operator/logical_recursive_cte.cpp\nindex dde425864ed0..f0b297034c51 100644\n--- a/src/planner/operator/logical_recursive_cte.cpp\n+++ b/src/planner/operator/logical_recursive_cte.cpp\n@@ -17,4 +17,8 @@ unique_ptr<LogicalOperator> LogicalRecursiveCTE::Deserialize(LogicalDeserializat\n \treturn unique_ptr<LogicalRecursiveCTE>(new LogicalRecursiveCTE(table_index, column_count, union_all, state.type));\n }\n \n+vector<idx_t> LogicalRecursiveCTE::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_sample.cpp b/src/planner/operator/logical_sample.cpp\nindex a769694688ab..b4a3ceef8f6a 100644\n--- a/src/planner/operator/logical_sample.cpp\n+++ b/src/planner/operator/logical_sample.cpp\n@@ -15,7 +15,12 @@ vector<ColumnBinding> LogicalSample::GetColumnBindings() {\n idx_t LogicalSample::EstimateCardinality(ClientContext &context) {\n \tauto child_cardinality = children[0]->EstimateCardinality(context);\n \tif (sample_options->is_percentage) {\n-\t\treturn idx_t(child_cardinality * sample_options->sample_size.GetValue<double>());\n+\t\tdouble sample_cardinality =\n+\t\t    double(child_cardinality) * (sample_options->sample_size.GetValue<double>() / 100.0);\n+\t\tif (sample_cardinality > double(child_cardinality)) {\n+\t\t\treturn child_cardinality;\n+\t\t}\n+\t\treturn idx_t(sample_cardinality);\n \t} else {\n \t\tauto sample_size = sample_options->sample_size.GetValue<uint64_t>();\n \t\tif (sample_size < child_cardinality) {\ndiff --git a/src/planner/operator/logical_set_operation.cpp b/src/planner/operator/logical_set_operation.cpp\nindex 5d2eda982a1d..ed3832337c1c 100644\n--- a/src/planner/operator/logical_set_operation.cpp\n+++ b/src/planner/operator/logical_set_operation.cpp\n@@ -14,4 +14,9 @@ unique_ptr<LogicalOperator> LogicalSetOperation::Deserialize(LogicalDeserializat\n \t// TODO(stephwang): review if unique_ptr<LogicalOperator> plan is needed\n \treturn unique_ptr<LogicalSetOperation>(new LogicalSetOperation(table_index, column_count, state.type));\n }\n+\n+vector<idx_t> LogicalSetOperation::GetTableIndex() const {\n+\treturn vector<idx_t> {table_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_unnest.cpp b/src/planner/operator/logical_unnest.cpp\nindex 17d846eb61fb..d251098b60fa 100644\n--- a/src/planner/operator/logical_unnest.cpp\n+++ b/src/planner/operator/logical_unnest.cpp\n@@ -30,4 +30,9 @@ unique_ptr<LogicalOperator> LogicalUnnest::Deserialize(LogicalDeserializationSta\n \tresult->expressions = move(expressions);\n \treturn move(result);\n }\n+\n+vector<idx_t> LogicalUnnest::GetTableIndex() const {\n+\treturn vector<idx_t> {unnest_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/operator/logical_window.cpp b/src/planner/operator/logical_window.cpp\nindex 72f547e803e4..7b8627e36ede 100644\n--- a/src/planner/operator/logical_window.cpp\n+++ b/src/planner/operator/logical_window.cpp\n@@ -30,4 +30,8 @@ unique_ptr<LogicalOperator> LogicalWindow::Deserialize(LogicalDeserializationSta\n \treturn move(result);\n }\n \n+vector<idx_t> LogicalWindow::GetTableIndex() const {\n+\treturn vector<idx_t> {window_index};\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/subquery/flatten_dependent_join.cpp b/src/planner/subquery/flatten_dependent_join.cpp\nindex 246d2a643cc9..84487098553f 100644\n--- a/src/planner/subquery/flatten_dependent_join.cpp\n+++ b/src/planner/subquery/flatten_dependent_join.cpp\n@@ -80,8 +80,10 @@ unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal\n \t\t// now create the duplicate eliminated scan for this node\n \t\tauto delim_index = binder.GenerateTableIndex();\n \t\tthis->base_binding = ColumnBinding(delim_index, 0);\n+\t\tthis->delim_offset = 0;\n+\t\tthis->data_offset = 0;\n \t\tauto delim_scan = make_unique<LogicalDelimGet>(delim_index, delim_types);\n-\t\treturn LogicalCrossProduct::Create(move(delim_scan), move(plan));\n+\t\treturn LogicalCrossProduct::Create(move(plan), move(delim_scan));\n \t}\n \tswitch (plan->type) {\n \tcase LogicalOperatorType::LOGICAL_UNNEST:\n@@ -445,8 +447,19 @@ unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal\n \tcase LogicalOperatorType::LOGICAL_UNION: {\n \t\tauto &setop = (LogicalSetOperation &)*plan;\n \t\t// set operator, push into both children\n+#ifdef DEBUG\n+\t\tplan->children[0]->ResolveOperatorTypes();\n+\t\tplan->children[1]->ResolveOperatorTypes();\n+\t\tD_ASSERT(plan->children[0]->types == plan->children[1]->types);\n+#endif\n \t\tplan->children[0] = PushDownDependentJoin(move(plan->children[0]));\n \t\tplan->children[1] = PushDownDependentJoin(move(plan->children[1]));\n+#ifdef DEBUG\n+\t\tD_ASSERT(plan->children[0]->GetColumnBindings().size() == plan->children[1]->GetColumnBindings().size());\n+\t\tplan->children[0]->ResolveOperatorTypes();\n+\t\tplan->children[1]->ResolveOperatorTypes();\n+\t\tD_ASSERT(plan->children[0]->types == plan->children[1]->types);\n+#endif\n \t\t// we have to refer to the setop index now\n \t\tbase_binding.table_index = setop.table_index;\n \t\tbase_binding.column_index = setop.column_count;\ndiff --git a/src/storage/data_table.cpp b/src/storage/data_table.cpp\nindex beaac1619089..ca280530d634 100644\n--- a/src/storage/data_table.cpp\n+++ b/src/storage/data_table.cpp\n@@ -666,7 +666,12 @@ bool DataTable::AppendToIndexes(TableIndexList &indexes, DataChunk &chunk, row_t\n \tbool append_failed = false;\n \t// now append the entries to the indices\n \tindexes.Scan([&](Index &index) {\n-\t\tif (!index.Append(chunk, row_identifiers)) {\n+\t\ttry {\n+\t\t\tif (!index.Append(chunk, row_identifiers)) {\n+\t\t\t\tappend_failed = true;\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t} catch (...) {\n \t\t\tappend_failed = true;\n \t\t\treturn true;\n \t\t}\n@@ -680,7 +685,6 @@ bool DataTable::AppendToIndexes(TableIndexList &indexes, DataChunk &chunk, row_t\n \t\tfor (auto *index : already_appended) {\n \t\t\tindex->Delete(chunk, row_identifiers);\n \t\t}\n-\n \t\treturn false;\n \t}\n \treturn true;\ndiff --git a/src/storage/local_storage.cpp b/src/storage/local_storage.cpp\nindex 422a75852163..a6276480c1b3 100644\n--- a/src/storage/local_storage.cpp\n+++ b/src/storage/local_storage.cpp\n@@ -246,12 +246,21 @@ void LocalTableStorage::AppendToIndexes(Transaction &transaction, TableAppendSta\n \t\t                                       append_state.current_row);\n \t}\n \tif (constraint_violated) {\n+\t\tPreservedError error;\n \t\t// need to revert the append\n \t\trow_t current_row = append_state.row_start;\n \t\t// remove the data from the indexes, if there are any indexes\n \t\trow_groups->Scan(transaction, [&](DataChunk &chunk) -> bool {\n \t\t\t// append this chunk to the indexes of the table\n-\t\t\ttable->RemoveFromIndexes(append_state, chunk, current_row);\n+\t\t\ttry {\n+\t\t\t\ttable->RemoveFromIndexes(append_state, chunk, current_row);\n+\t\t\t} catch (Exception &ex) {\n+\t\t\t\terror = PreservedError(ex);\n+\t\t\t\treturn false;\n+\t\t\t} catch (std::exception &ex) {\n+\t\t\t\terror = PreservedError(ex);\n+\t\t\t\treturn false;\n+\t\t\t}\n \n \t\t\tcurrent_row += chunk.size();\n \t\t\tif (current_row >= append_state.current_row) {\n@@ -263,6 +272,9 @@ void LocalTableStorage::AppendToIndexes(Transaction &transaction, TableAppendSta\n \t\tif (append_to_table) {\n \t\t\ttable->RevertAppendInternal(append_state.row_start, append_count);\n \t\t}\n+\t\tif (error) {\n+\t\t\terror.Throw();\n+\t\t}\n \t\tthrow ConstraintException(\"PRIMARY KEY or UNIQUE constraint violated: duplicated key\");\n \t}\n }\n@@ -394,7 +406,7 @@ void LocalStorage::InitializeAppend(LocalAppendState &state, DataTable *table) {\n void LocalStorage::Append(LocalAppendState &state, DataChunk &chunk) {\n \t// append to unique indices (if any)\n \tauto storage = state.storage;\n-\tidx_t base_id = MAX_ROW_ID + storage->row_groups->GetTotalRows();\n+\tidx_t base_id = MAX_ROW_ID + storage->row_groups->GetTotalRows() + state.append_state.total_append_count;\n \tif (!DataTable::AppendToIndexes(storage->indexes, chunk, base_id)) {\n \t\tthrow ConstraintException(\"PRIMARY KEY or UNIQUE constraint violated: duplicated key\");\n \t}\ndiff --git a/src/transaction/cleanup_state.cpp b/src/transaction/cleanup_state.cpp\nindex d96342177ccb..59f457cd0d10 100644\n--- a/src/transaction/cleanup_state.cpp\n+++ b/src/transaction/cleanup_state.cpp\n@@ -77,7 +77,10 @@ void CleanupState::Flush() {\n \tVector row_identifiers(LogicalType::ROW_TYPE, (data_ptr_t)row_numbers);\n \n \t// delete the tuples from all the indexes\n-\tcurrent_table->RemoveFromIndexes(row_identifiers, count);\n+\ttry {\n+\t\tcurrent_table->RemoveFromIndexes(row_identifiers, count);\n+\t} catch (...) {\n+\t}\n \n \tcount = 0;\n }\n",
  "test_patch": "diff --git a/test/fuzzer/pedro/alter_dependencies.test b/test/fuzzer/pedro/alter_dependencies.test\nnew file mode 100644\nindex 000000000000..437aa165fdc7\n--- /dev/null\n+++ b/test/fuzzer/pedro/alter_dependencies.test\n@@ -0,0 +1,26 @@\n+# name: test/fuzzer/pedro/alter_dependencies.test\n+# description: Issue #4696: Alter table dependency conflict\n+# group: [pedro]\n+\n+statement ok\n+CREATE TABLE t1 (c2 INT, c1 INT);\n+\n+statement ok\n+CREATE INDEX i1 ON t1 (c1);\n+\n+statement ok\n+START TRANSACTION;\n+\n+statement error\n+ALTER TABLE t1 ALTER c2 TYPE BOOLEAN;\n+----\n+Cannot alter\n+\n+# committing triggers a rollback\n+statement ok\n+COMMIT;\n+\n+statement error\n+ALTER TABLE t1 ALTER c2 SET NOT NULL;\n+---\n+Cannot alter\ndiff --git a/test/fuzzer/pedro/between_mark_reference.test b/test/fuzzer/pedro/between_mark_reference.test\nnew file mode 100644\nindex 000000000000..97eaaa932c16\n--- /dev/null\n+++ b/test/fuzzer/pedro/between_mark_reference.test\n@@ -0,0 +1,16 @@\n+# name: test/fuzzer/pedro/between_mark_reference.test\n+# description: Test deletions with USING clause\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification;\n+\n+query I\n+SELECT 1 WHERE '23:' > ALL(SELECT '0') BETWEEN false AND true;\n+----\n+1\n+\n+statement error\n+SELECT 1 WHERE '23:' > ALL(SELECT '0') BETWEEN '0' AND '0:';\n+----\n+'0:'\ndiff --git a/test/fuzzer/pedro/complex_type_all_subquery.test b/test/fuzzer/pedro/complex_type_all_subquery.test\nnew file mode 100644\nindex 000000000000..45c570b8b3f8\n--- /dev/null\n+++ b/test/fuzzer/pedro/complex_type_all_subquery.test\n@@ -0,0 +1,47 @@\n+# name: test/fuzzer/pedro/complex_type_all_subquery.test\n+# description: Use complex types in ALL clause\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+# cast from struct to int not supported\n+statement error\n+VALUES((0, 0) = ALL(SELECT 2));\n+----\n+Unimplemented\n+\n+# use ALL with complex types\n+query I\n+SELECT {'a': 42} = ALL(SELECT {'a': '42'})\n+----\n+1\n+\n+foreach val 42 [1,2,3] {'a':42} {'a':[1,2,3],'b':'thisisalongstring'}\n+\n+query I\n+SELECT ${val} = ALL(SELECT ${val})\n+----\n+1\n+\n+query I\n+SELECT ${val} = ALL(SELECT ${val} UNION ALL SELECT NULL)\n+----\n+NULL\n+\n+query I\n+SELECT ${val} = ALL(SELECT ${val} FROM range(3000))\n+----\n+1\n+\n+query I\n+SELECT ${val} > ANY(SELECT ${val} FROM range(3000))\n+----\n+0\n+\n+query I\n+SELECT ${val} >= ANY(SELECT ${val} FROM range(3000))\n+----\n+1\n+\n+endloop\ndiff --git a/test/fuzzer/pedro/concurrent_catalog_usage.test b/test/fuzzer/pedro/concurrent_catalog_usage.test\nnew file mode 100644\nindex 000000000000..5bded8ba2728\n--- /dev/null\n+++ b/test/fuzzer/pedro/concurrent_catalog_usage.test\n@@ -0,0 +1,15 @@\n+# name: test/fuzzer/pedro/concurrent_catalog_usage.test\n+# description: Concurrent catalog usage\n+# group: [pedro]\n+\n+statement ok\n+CREATE TABLE t2 AS (SELECT 42);\n+\n+concurrentloop i 1 10\n+\n+statement maybe\n+CREATE OR REPLACE TABLE t2 AS (SELECT -54124033386577348004002656426531535114 FROM t2 LIMIT 70%);\n+----\n+write-write conflict\n+\n+endloop\ndiff --git a/test/fuzzer/pedro/correlated_in_segv.test b/test/fuzzer/pedro/correlated_in_segv.test\nnew file mode 100644\nindex 000000000000..a5a81e07c275\n--- /dev/null\n+++ b/test/fuzzer/pedro/correlated_in_segv.test\n@@ -0,0 +1,21 @@\n+# name: test/fuzzer/pedro/correlated_in_segv.test\n+# description: Correlated IN segfault\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query I\n+SELECT (SELECT 1 WHERE 1 IN (c0) GROUP BY ()) FROM (SELECT 1) t0(c0);\n+----\n+1\n+\n+query I\n+SELECT ((SELECT 1) EXCEPT (SELECT c0 LIMIT 0)) FROM VALUES (0), t0(c0);\n+----\n+1\n+\n+query I\n+SELECT 1 + count() FILTER (WHERE EXISTS (SELECT EXISTS (SELECT 1)));\n+----\n+2\ndiff --git a/test/fuzzer/pedro/correlated_limit_rowid.test b/test/fuzzer/pedro/correlated_limit_rowid.test\nnew file mode 100644\nindex 000000000000..34c1aebfb002\n--- /dev/null\n+++ b/test/fuzzer/pedro/correlated_limit_rowid.test\n@@ -0,0 +1,14 @@\n+# name: test/fuzzer/pedro/correlated_limit_rowid.test\n+# description: Issue #4580: heap-buffer-overflow when creating index on table with generated columns\n+# group: [pedro]\n+\n+statement ok\n+CREATE TABLE t0 (c0 INT);\n+\n+statement ok\n+CREATE TABLE t1 (c0 INT);\n+\n+statement error\n+SELECT (SELECT 1 LIMIT t1.rowid) FROM t1 NATURAL JOIN t0;\n+----\n+Correlated\ndiff --git a/test/fuzzer/pedro/create_index_error.test b/test/fuzzer/pedro/create_index_error.test\nnew file mode 100644\nindex 000000000000..cb83144e66dc\n--- /dev/null\n+++ b/test/fuzzer/pedro/create_index_error.test\n@@ -0,0 +1,60 @@\n+# name: test/fuzzer/pedro/create_index_error.test\n+# description: Errors while inserting into indexes\n+# group: [pedro]\n+\n+# create an index with an expression that leads to an error on insert\n+statement ok\n+CREATE TABLE t0 (c0 VARCHAR, c1 INT);\n+\n+statement ok\n+INSERT INTO t0(c0) VALUES ('a');\n+\n+statement ok\n+CREATE INDEX i1 ON t0 (c1, CAST('c' AS INT));\n+\n+statement error\n+INSERT INTO t0(c0) VALUES ('b');\n+----\n+Could not convert\n+\n+statement ok\n+CREATE INDEX i0 ON t0 (c0);\n+\n+statement ok\n+DROP TABLE t0\n+\n+# create an index with an expression that leads to an error on insert, then delete from that table\n+statement ok\n+CREATE TABLE t0 (c1 INT, c0 INT);\n+\n+statement ok\n+INSERT INTO t0(c0) VALUES (1);\n+\n+statement ok\n+CREATE INDEX i1 ON t0 ((decode('\\x0C\\xE4\\x85\\xF5'::BLOB)::VARCHAR), c1);\n+\n+statement ok\n+DELETE FROM t0;\n+\n+statement ok\n+DROP TABLE t0;\n+\n+statement ok\n+CREATE TABLE t1 (c1 BOOLEAN);\n+\n+statement ok\n+INSERT INTO t1 VALUES (0);\n+\n+statement ok\n+DELETE FROM t1;\n+\n+statement ok\n+CREATE INDEX i0 ON t1 (c1, (decode('\\x81\\x5C\\xE5'::BLOB)::VARCHAR));\n+\n+statement error\n+INSERT INTO t1 VALUES (1);\n+----\n+Failure in decode\n+\n+statement ok\n+CREATE INDEX i1 ON t1 USING ART (c1);\ndiff --git a/test/fuzzer/pedro/currval_sequence_dependency.test b/test/fuzzer/pedro/currval_sequence_dependency.test\nnew file mode 100644\nindex 000000000000..17f31e48b6ae\n--- /dev/null\n+++ b/test/fuzzer/pedro/currval_sequence_dependency.test\n@@ -0,0 +1,28 @@\n+# name: test/fuzzer/pedro/currval_sequence_dependency.test\n+# description: Test sequence dependency in currval\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+foreach fun nextval currval\n+\n+statement ok\n+CREATE SEQUENCE seq;\n+\n+statement ok\n+CREATE TABLE t1(c1 INT, CHECK(${fun}('seq')));\n+\n+statement error\n+DROP SEQUENCE seq;\n+----\n+there are entries that depend\n+\n+statement ok\n+DROP SEQUENCE seq CASCADE;\n+\n+# this also drops the table\n+statement error\n+INSERT INTO t1 VALUES (1)\n+\n+endloop\ndiff --git a/test/fuzzer/pedro/delete_add_column.test b/test/fuzzer/pedro/delete_add_column.test\nnew file mode 100644\nindex 000000000000..610705acda33\n--- /dev/null\n+++ b/test/fuzzer/pedro/delete_add_column.test\n@@ -0,0 +1,48 @@\n+# name: test/fuzzer/pedro/delete_add_column.test\n+# description: Delete from altered table triggers assertion\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE t1 AS SELECT 1 c1;\n+\n+statement ok\n+ALTER TABLE t1 ADD c0 INT;\n+\n+query II\n+SELECT * FROM t1\n+----\n+1\tNULL\n+\n+statement ok\n+TRUNCATE t1;\n+\n+query II\n+SELECT * FROM t1\n+----\n+\n+statement ok\n+DROP TABLE t1\n+\n+statement ok\n+CREATE TABLE t1(c0 VARCHAR);\n+\n+statement ok\n+ALTER TABLE t1 ADD c1 INT;\n+\n+statement ok\n+INSERT INTO t1 AS t0(c0) VALUES(4);\n+\n+query II\n+SELECT * FROM t1\n+----\n+4\tNULL\n+\n+statement ok\n+DELETE FROM t1;\n+\n+query II\n+SELECT * FROM t1\n+----\ndiff --git a/test/fuzzer/pedro/delete_using_bindings.test b/test/fuzzer/pedro/delete_using_bindings.test\nnew file mode 100644\nindex 000000000000..1efe09e2782e\n--- /dev/null\n+++ b/test/fuzzer/pedro/delete_using_bindings.test\n@@ -0,0 +1,16 @@\n+# name: test/fuzzer/pedro/delete_using_bindings.test\n+# description: Test correlated limit\n+# group: [pedro]\n+\n+statement ok\n+CREATE TABLE t0(c0 INT);\n+\n+statement error\n+DELETE FROM t0 USING ((SELECT 1) t1 INNER JOIN (SELECT 2) t2 ON t0.c0);\n+----\n+\"t0\" not found\n+\n+statement error\n+DELETE FROM t0 USING ((SELECT 1) t1 INNER JOIN (SELECT 2) t2 ON c0);\n+----\n+\"c0\" not found\ndiff --git a/test/fuzzer/pedro/index_insert_from_union.test b/test/fuzzer/pedro/index_insert_from_union.test\nnew file mode 100644\nindex 000000000000..e47eebec137d\n--- /dev/null\n+++ b/test/fuzzer/pedro/index_insert_from_union.test\n@@ -0,0 +1,47 @@\n+# name: test/fuzzer/pedro/index_insert_from_union.test\n+# description: Issue #4978 (33): Insert into ART index leaf assertion error\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE t2 (c1 INT, PRIMARY KEY (c1));\n+\n+statement error\n+INSERT INTO t2 SELECT * FROM (VALUES (2), (2))\n+\n+statement error\n+INSERT INTO t2 SELECT 2 FROM range(10);\n+\n+statement error\n+INSERT INTO t2 SELECT 2 UNION ALL SELECT 2;\n+\n+statement ok\n+BEGIN TRANSACTION\n+\n+statement ok\n+INSERT INTO t2 SELECT 1 UNION ALL SELECT 2;\n+\n+query I\n+SELECT * FROM t2 WHERE c1>1\n+----\n+2\n+\n+query I\n+SELECT * FROM t2 WHERE c1<2\n+----\n+1\n+\n+statement ok\n+COMMIT\n+\n+query I\n+SELECT * FROM t2 WHERE c1>1\n+----\n+2\n+\n+query I\n+SELECT * FROM t2 WHERE c1<2\n+----\n+1\ndiff --git a/test/fuzzer/pedro/index_not_updated_returning.test b/test/fuzzer/pedro/index_not_updated_returning.test\nnew file mode 100644\nindex 000000000000..7d2c7a76fa05\n--- /dev/null\n+++ b/test/fuzzer/pedro/index_not_updated_returning.test\n@@ -0,0 +1,17 @@\n+# name: test/fuzzer/pedro/index_not_updated_returning.test\n+# description: Issue #4978 (23): Index not updated assertion\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE t2 AS SELECT 1 c1, 1 c2;\n+\n+statement ok\n+CREATE INDEX i0 ON t2 (c1);\n+\n+query II\n+UPDATE t2 SET c2 = 2 RETURNING *;\n+----\n+1\t2\ndiff --git a/test/fuzzer/pedro/intersect_correlated_subquery.test b/test/fuzzer/pedro/intersect_correlated_subquery.test\nnew file mode 100644\nindex 000000000000..f95a374afeb6\n--- /dev/null\n+++ b/test/fuzzer/pedro/intersect_correlated_subquery.test\n@@ -0,0 +1,17 @@\n+# name: test/fuzzer/pedro/intersect_correlated_subquery.test\n+# description: Intersect correlated subquery\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE t0 (c1 TINYINT);\n+\n+query I\n+SELECT (SELECT 1 INTERSECT SELECT 1 HAVING true) FROM t0;\n+----\n+\n+query I\n+SELECT (SELECT 1 INTERSECT SELECT 1 HAVING t0.rowid) FROM t0;\n+----\ndiff --git a/test/fuzzer/pedro/intersect_empty_array.test b/test/fuzzer/pedro/intersect_empty_array.test\nnew file mode 100644\nindex 000000000000..b6374bc4c7d2\n--- /dev/null\n+++ b/test/fuzzer/pedro/intersect_empty_array.test\n@@ -0,0 +1,11 @@\n+# name: test/fuzzer/pedro/intersect_empty_array.test\n+# description: Intersect empty array\n+# group: [pedro]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement error\n+SELECT 2 INTERSECT VALUES([]);\n+----\n+Unimplemented\ndiff --git a/test/fuzzer/pedro/nested_limit_subquery.test b/test/fuzzer/pedro/nested_limit_subquery.test\nnew file mode 100644\nindex 000000000000..2f0fbf4d3a4c\n--- /dev/null\n+++ b/test/fuzzer/pedro/nested_limit_subquery.test\n@@ -0,0 +1,32 @@\n+# name: test/fuzzer/pedro/nested_limit_subquery.test\n+# description: Test correlated limit\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query I\n+SELECT 1 FROM (SELECT 1) t0(c0) WHERE (SELECT c0);\n+----\n+1\n+\n+query I\n+SELECT 1 FROM (SELECT 1) t0(c0) WHERE (SELECT (SELECT c0));\n+----\n+1\n+\n+query I\n+SELECT 1 FROM (SELECT 1) t0(c0) WHERE (SELECT (SELECT 1 ORDER BY c0));\n+----\n+1\n+\n+statement error\n+SELECT 1 FROM (SELECT 1) t0(c0) WHERE (SELECT 1 LIMIT c0);\n+----\n+Correlated columns not supported in LIMIT/OFFSET\n+\n+statement error\n+SELECT 1 FROM (SELECT 1) t0(c0) WHERE (SELECT (SELECT 1 LIMIT c0));\n+----\n+Correlated columns not supported in LIMIT/OFFSET\n+\ndiff --git a/test/fuzzer/pedro/pushdown_assertion_error.test b/test/fuzzer/pedro/pushdown_assertion_error.test\nnew file mode 100644\nindex 000000000000..fbe3a27d156a\n--- /dev/null\n+++ b/test/fuzzer/pedro/pushdown_assertion_error.test\n@@ -0,0 +1,20 @@\n+# name: test/fuzzer/pedro/pushdown_assertion_error.test\n+# description: Use complex types in ALL clause\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE t2 (c2 INT);\n+\n+statement ok\n+CREATE SEQUENCE t0;\n+\n+query I\n+SELECT 1 FROM t2 WHERE currval('t0') BETWEEN TRY_CAST(0 AS TIMESTAMP WITH TIME ZONE) AND 1;\n+----\n+\n+query I\n+SELECT 1 FROM t2 WHERE currval('t0') BETWEEN TRY_CAST(0 AS TIMESTAMP WITH TIME ZONE) AND -156587962151166338620429995158284936977;\n+----\ndiff --git a/test/fuzzer/pedro/qualify_binder_error.test b/test/fuzzer/pedro/qualify_binder_error.test\nnew file mode 100644\nindex 000000000000..3044fe0013f4\n--- /dev/null\n+++ b/test/fuzzer/pedro/qualify_binder_error.test\n@@ -0,0 +1,36 @@\n+# name: test/fuzzer/pedro/qualify_binder_error.test\n+# description: Qualify clause binder error\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query II\n+SELECT c0, count(c0) over () AS count_window FROM (SELECT 1) t0(c0) GROUP BY c0 QUALIFY count_window;\n+----\n+1\t1\n+\n+query I\n+SELECT * FROM (SELECT 1) t0(c0) GROUP BY c0 QUALIFY count(c0) OVER ();\n+----\n+1\n+\n+statement error\n+SELECT * FROM (SELECT 1) t0(c0) GROUP BY ALL QUALIFY count(c0) OVER ();\n+----\n+Combining QUALIFY with GROUP BY ALL is not supported yet\n+\n+statement error\n+SELECT 1 FROM (SELECT 2) t0(c0) QUALIFY (c0, dense_rank() OVER(), mode(0));\n+----\n+Cannot mix aggregates with non-aggregated columns\n+\n+query I\n+SELECT 1 FROM (SELECT 2) t0(c0) QUALIFY (count(sum(42)) OVER());\n+----\n+1\n+\n+query I\n+SELECT 1 FROM (SELECT 2) t0(c0) QUALIFY (count(sum(c0)) OVER());\n+----\n+1\ndiff --git a/test/fuzzer/pedro/recursive_cte_limit_percent.test b/test/fuzzer/pedro/recursive_cte_limit_percent.test\nnew file mode 100644\nindex 000000000000..48db85f48efe\n--- /dev/null\n+++ b/test/fuzzer/pedro/recursive_cte_limit_percent.test\n@@ -0,0 +1,16 @@\n+# name: test/fuzzer/pedro/recursive_cte_limit_percent.test\n+# description: Recursive CTE error\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query I\n+WITH RECURSIVE t1(c0) AS ((SELECT 1, 1 c1) UNION (SELECT 1, 1 FROM (SELECT 1) x(x) JOIN t1 ON FALSE LIMIT 1%)) SELECT 1 FROM t1 JOIN t1 t0 USING (c1);\n+----\n+1\n+\n+query I\n+WITH RECURSIVE t1(c0) AS ((SELECT 1, 1 c1) UNION (SELECT 1, 1 FROM (SELECT 1) x(x) JOIN t1 ON FALSE LIMIT 1)) SELECT 1 FROM t1 JOIN t1 t0 USING (c1);\n+----\n+1\ndiff --git a/test/fuzzer/pedro/regr_count_validity.test b/test/fuzzer/pedro/regr_count_validity.test\nnew file mode 100644\nindex 000000000000..818db4e4f4d7\n--- /dev/null\n+++ b/test/fuzzer/pedro/regr_count_validity.test\n@@ -0,0 +1,12 @@\n+# name: test/fuzzer/pedro/regr_count_validity.test\n+# description: Recursive CTE error\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE t0 (c0 INT);\n+\n+statement ok\n+SELECT regr_count(1,1) FROM t0;\ndiff --git a/test/fuzzer/pedro/rename_restart.test b/test/fuzzer/pedro/rename_restart.test\nnew file mode 100644\nindex 000000000000..8179826f2bca\n--- /dev/null\n+++ b/test/fuzzer/pedro/rename_restart.test\n@@ -0,0 +1,30 @@\n+# name: test/fuzzer/pedro/rename_restart.test\n+# description: Rename table restart\n+# group: [pedro]\n+\n+load __TEST_DIR__/rename_restart.db\n+\n+statement ok\n+SET wal_autocheckpoint='10MB';\n+\n+statement ok\n+CREATE TABLE t0(c0 INT);\n+\n+statement ok\n+CREATE VIEW t1 AS SELECT 1 c0;\n+\n+statement ok\n+CREATE INDEX i1 ON t0(c0);\n+\n+statement error\n+ALTER TABLE t0 RENAME TO t1;\n+----\n+t1\n+\n+statement ok\n+CHECKPOINT;\n+\n+restart\n+\n+statement ok\n+select 42\n\\ No newline at end of file\ndiff --git a/test/fuzzer/pedro/sample_limit_overflow.test b/test/fuzzer/pedro/sample_limit_overflow.test\nnew file mode 100644\nindex 000000000000..b9e024812304\n--- /dev/null\n+++ b/test/fuzzer/pedro/sample_limit_overflow.test\n@@ -0,0 +1,7 @@\n+# name: test/fuzzer/pedro/sample_limit_overflow.test\n+# description: Sample limit overflow\n+# group: [pedro]\n+\n+statement ok\n+SELECT 1 FROM (SELECT 1 ORDER BY ALL LIMIT 514322393620248226) USING SAMPLE SYSTEM (36%);\n+\ndiff --git a/test/fuzzer/pedro/setop_type_mismatch.test b/test/fuzzer/pedro/setop_type_mismatch.test\nnew file mode 100644\nindex 000000000000..b087cebdd341\n--- /dev/null\n+++ b/test/fuzzer/pedro/setop_type_mismatch.test\n@@ -0,0 +1,36 @@\n+# name: test/fuzzer/pedro/setop_type_mismatch.test\n+# description: Correlated SetOp type mismatches\n+# group: [pedro]\n+\n+query I\n+SELECT '\\x1E' FROM (SELECT 1) t1(c0) ORDER BY ALL OFFSET (SELECT DISTINCT 6.5 FROM (SELECT 1) t1(c0) UNION ALL SELECT 3);\n+----\n+\\x1E\n+\n+statement ok\n+CREATE TABLE t1 (c0 BOOLEAN, c1 BIGINT);\n+\n+statement ok\n+INSERT INTO t1 (c1) VALUES (1);\n+\n+query I\n+SELECT ((SELECT 0) UNION (SELECT t1.c0) OFFSET 1) FROM t1;\n+----\n+NULL\n+\n+statement ok\n+CREATE TABLE t2 (c0 DECIMAL);\n+\n+query I\n+SELECT (SELECT 0 WHERE CAST(c0 AS VARCHAR) LIKE '1' INTERSECT (SELECT 1)) FROM t2;\n+----\n+\n+statement ok\n+CREATE TABLE t3 (c1 INT);\n+\n+statement ok\n+CREATE TABLE t4 (c0 BOOLEAN, c1 INT);\n+\n+query I\n+SELECT 1 FROM t4 JOIN t3 ON 0 WHERE EXISTS (SELECT 1 INTERSECT SELECT 1 FROM t4 JOIN t3 t0(c1) ON 0 WHERE NOT c0);\n+----\ndiff --git a/test/fuzzer/pedro/statistics_propagation_set_op.test b/test/fuzzer/pedro/statistics_propagation_set_op.test\nnew file mode 100644\nindex 000000000000..939e69a360ba\n--- /dev/null\n+++ b/test/fuzzer/pedro/statistics_propagation_set_op.test\n@@ -0,0 +1,12 @@\n+# name: test/fuzzer/pedro/statistics_propagation_set_op.test\n+# description: Issue #4978 (32): Statistics propagation error\n+# group: [pedro]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query I\n+SELECT 1 FROM (SELECT 1) t0(c0) WHERE ((VALUES(1), (c0) LIMIT 1) INTERSECT (SELECT 1));\n+----\n+1\n+\ndiff --git a/test/fuzzer/pedro/strftime_constant_null.test b/test/fuzzer/pedro/strftime_constant_null.test\nnew file mode 100644\nindex 000000000000..769f06f8ed0a\n--- /dev/null\n+++ b/test/fuzzer/pedro/strftime_constant_null.test\n@@ -0,0 +1,15 @@\n+# name: test/fuzzer/pedro/strftime_constant_null.test\n+# description: Strftime assertion trigger\n+# group: [pedro]\n+\n+statement ok\n+CREATE TABLE t0 (c1 TIMESTAMP);\n+\n+statement ok\n+INSERT INTO t0 VALUES (TIMESTAMP '91288-5-25 0:5:30'),(TIMESTAMP '253915-8-21 3:7:0');\n+\n+statement ok\n+PRAGMA DISABLE_OPTIMIZER;\n+\n+statement ok\n+SELECT strftime(TIMESTAMP '2608-11-25 3:4:35',coalesce('a', 'b')) FROM t0;\ndiff --git a/test/fuzzer/pedro/strptime_null_argument.test b/test/fuzzer/pedro/strptime_null_argument.test\nnew file mode 100644\nindex 000000000000..d32501b7929e\n--- /dev/null\n+++ b/test/fuzzer/pedro/strptime_null_argument.test\n@@ -0,0 +1,6 @@\n+# name: test/fuzzer/pedro/strptime_null_argument.test\n+# description: Strptime null argument\n+# group: [pedro]\n+\n+statement ok\n+SELECT strptime(NULL,'p') IS DISTINCT FROM DATE '-543572-1-1';\ndiff --git a/test/fuzzer/pedro/update_join_statistics.test b/test/fuzzer/pedro/update_join_statistics.test\nnew file mode 100644\nindex 000000000000..3335dbc358a0\n--- /dev/null\n+++ b/test/fuzzer/pedro/update_join_statistics.test\n@@ -0,0 +1,15 @@\n+# name: test/fuzzer/pedro/update_join_statistics.test\n+# description: Base statistics assertion error\n+# group: [pedro]\n+\n+#statement ok\n+#PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE t1 (c0 INT, c2 BIGINT, PRIMARY KEY (c0));\n+\n+#statement ok\n+#PRAGMA disabled_optimizers='statistics_propagation'\n+\n+statement ok\n+PREPARE p2 AS UPDATE t1 SET c0 = (SELECT 2) FROM ((SELECT 1) UNION ALL (SELECT 2)) t2(c1);\ndiff --git a/test/fuzzer/pedro/view_not_rebound_error.test b/test/fuzzer/pedro/view_not_rebound_error.test\nnew file mode 100644\nindex 000000000000..5906b17648e8\n--- /dev/null\n+++ b/test/fuzzer/pedro/view_not_rebound_error.test\n@@ -0,0 +1,22 @@\n+# name: test/fuzzer/pedro/view_not_rebound_error.test\n+# group: [pedro]\n+\n+statement ok\n+CREATE TABLE t1 (c1 INT);\n+\n+statement ok\n+CREATE VIEW t0 AS SELECT 1 FROM t1 GROUP BY c1;\n+\n+statement ok\n+DROP TABLE t1;\n+\n+statement ok\n+CREATE TABLE t2 (c1 INT);\n+\n+statement ok\n+CREATE TABLE t1 (c2 INT);\n+\n+statement error\n+SELECT 1 FROM t2 JOIN t1 ON (SELECT TRUE FROM t0);\n+----\n+Contents of view were altered\ndiff --git a/test/sql/aggregate/group/group_by_all_having.test b/test/sql/aggregate/group/group_by_all_having.test\nnew file mode 100644\nindex 000000000000..6dba87c877f4\n--- /dev/null\n+++ b/test/sql/aggregate/group/group_by_all_having.test\n@@ -0,0 +1,28 @@\n+# name: test/sql/aggregate/group/group_by_all_having.test\n+# description: Test group by all with having\n+# group: [group]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query I\n+SELECT * FROM (SELECT 1) t0(c0) GROUP BY c0 HAVING c0>0\n+----\n+1\n+\n+query I\n+SELECT c0 FROM (SELECT 1) t0(c0) GROUP BY ALL HAVING c0>0\n+----\n+1\n+\n+query I\n+SELECT c0 FROM (SELECT 1, 1 UNION ALL SELECT 1, 2) t0(c0, c1) GROUP BY ALL ORDER BY c0\n+----\n+1\n+\n+# new column \"c1\" referenced in HAVING - it is added to the set of grouping columns\n+query I\n+SELECT c0 FROM (SELECT 1, 1 UNION ALL SELECT 1, 2) t0(c0, c1) GROUP BY ALL HAVING c1>0 ORDER BY c0\n+----\n+1\n+1\ndiff --git a/test/sql/alter/alter_col/test_not_null_in_tran.test b/test/sql/alter/alter_col/test_not_null_in_tran.test\nindex b38b03e25bcd..de101a41e9ba 100644\n--- a/test/sql/alter/alter_col/test_not_null_in_tran.test\n+++ b/test/sql/alter/alter_col/test_not_null_in_tran.test\n@@ -23,10 +23,13 @@ statement error\n ALTER TABLE t ALTER COLUMN j SET NOT NULL\n \n statement ok\n-COMMIT\n+ROLLBACK\n+\n+statement ok\n+INSERT INTO t VALUES(9999, NULL)\n \n # Has null, cannot alter after tran\n-statement error \n+statement error\n ALTER TABLE t ALTER COLUMN j SET NOT NULL\n \n query I\ndiff --git a/test/sql/alter/alter_col/test_not_null_multi_tran.test b/test/sql/alter/alter_col/test_not_null_multi_tran.test\nindex d85d8e505d1c..9956183f01e3 100644\n--- a/test/sql/alter/alter_col/test_not_null_multi_tran.test\n+++ b/test/sql/alter/alter_col/test_not_null_multi_tran.test\n@@ -91,7 +91,7 @@ statement ok con1\n COMMIT\n \n statement ok con2\n-COMMIT\n+ROLLBACK\n \n query I con1\n SELECT count(*) from t\n@@ -130,7 +130,7 @@ statement error con2\n INSERT INTO t VALUES(1, NULL)\n \n statement ok con2\n-COMMIT\n+ROLLBACK\n \n query I con1\n SELECT count(*) from t\n@@ -234,7 +234,7 @@ statement error con1\n ALTER TABLE t ALTER COLUMN j SET NOT NULL\n \n statement ok con1\n-COMMIT\n+ROLLBACK\n \n query I con1\n SELECT count(*) from t\ndiff --git a/test/sql/function/nested/test_issue_5437.test b/test/sql/function/nested/test_issue_5437.test\nnew file mode 100644\nindex 000000000000..aa61918954f8\n--- /dev/null\n+++ b/test/sql/function/nested/test_issue_5437.test\n@@ -0,0 +1,13 @@\n+# name: test/sql/function/nested/test_issue_5437.test\n+# description: Issue #5437: Python crashes with struct_insert\n+# group: [nested]\n+\n+statement ok\n+pragma enable_verification;\n+\n+statement ok\n+with data as (\n+select * from (VALUES ('Amsterdam', {'x': 1, 'y': 2, 'z': 3}), ('London', {'x': 4, 'y': 5, 'z': 6})) Cities(Name, Id)\n+)\n+select *, struct_insert(Id, d := 4)\n+from data\ndiff --git a/test/sql/transactions/aborted_transaction_commit.test b/test/sql/transactions/aborted_transaction_commit.test\nnew file mode 100644\nindex 000000000000..feefe3df63e1\n--- /dev/null\n+++ b/test/sql/transactions/aborted_transaction_commit.test\n@@ -0,0 +1,45 @@\n+# name: test/sql/transactions/aborted_transaction_commit.test\n+# description: Commit aborted transaction becomes a rollback\n+# group: [transactions]\n+\n+statement ok\n+CREATE TABLE keys(i INTEGER PRIMARY KEY);\n+\n+# start transactions\n+statement ok\n+BEGIN TRANSACTION;\n+\n+statement ok\n+INSERT INTO keys VALUES (1);\n+\n+statement error\n+INSERT INTO keys VALUES (1);\n+----\n+constraint violated\n+\n+# commit becomes a rollback\n+statement ok\n+COMMIT\n+\n+query I\n+SELECT COUNT(*) FROM keys\n+----\n+0\n+\n+# BEGIN TRANSACTION does require a valid transaction\n+statement ok\n+BEGIN TRANSACTION;\n+\n+statement ok\n+INSERT INTO keys VALUES (1);\n+\n+statement error\n+INSERT INTO keys VALUES (1);\n+----\n+constraint violated\n+\n+# commit becomes a rollback\n+statement error\n+BEGIN TRANSACTION\n+----\n+ROLLBACK\ndiff --git a/test/sqlite/result_helper.cpp b/test/sqlite/result_helper.cpp\nindex df25e9f38fd2..6858341672f6 100644\n--- a/test/sqlite/result_helper.cpp\n+++ b/test/sqlite/result_helper.cpp\n@@ -250,8 +250,8 @@ bool TestResultHelper::CheckStatementResult(const Statement &statement, ExecuteC\n \t}\n \n \t/* Check to see if we are expecting success or failure */\n-\tauto expect_ok = statement.expect_ok;\n-\tif (!expect_ok) {\n+\tauto expected_result = statement.expected_result;\n+\tif (expected_result != ExpectedResult::RESULT_SUCCESS) {\n \t\t// even in the case of \"statement error\", we do not accept ALL errors\n \t\t// internal errors are never expected\n \t\t// neither are \"unoptimized result differs from original result\" errors\n@@ -259,9 +259,13 @@ bool TestResultHelper::CheckStatementResult(const Statement &statement, ExecuteC\n \t\tbool internal_error =\n \t\t    result.HasError() ? TestIsInternalError(runner.always_fail_error_messages, result.GetError()) : false;\n \t\tif (!internal_error) {\n-\t\t\terror = !error;\n+\t\t\tif (expected_result == ExpectedResult::RESULT_UNKNOWN) {\n+\t\t\t\terror = false;\n+\t\t\t} else {\n+\t\t\t\terror = !error;\n+\t\t\t}\n \t\t} else {\n-\t\t\texpect_ok = true;\n+\t\t\texpected_result = ExpectedResult::RESULT_SUCCESS;\n \t\t}\n \t\tif (result.HasError() && !statement.expected_error.empty()) {\n \t\t\tif (!StringUtil::Contains(result.GetError(), statement.expected_error)) {\n@@ -273,8 +277,8 @@ bool TestResultHelper::CheckStatementResult(const Statement &statement, ExecuteC\n \n \t/* Report an error if the results do not match expectation */\n \tif (error) {\n-\t\tlogger.UnexpectedStatement(expect_ok, result);\n-\t\tif (expect_ok && SkipErrorMessage(result.GetError())) {\n+\t\tlogger.UnexpectedStatement(expected_result == ExpectedResult::RESULT_SUCCESS, result);\n+\t\tif (expected_result == ExpectedResult::RESULT_SUCCESS && SkipErrorMessage(result.GetError())) {\n \t\t\trunner.finished_processing_file = true;\n \t\t\treturn true;\n \t\t}\ndiff --git a/test/sqlite/sqllogic_command.hpp b/test/sqlite/sqllogic_command.hpp\nindex 6b4d180d26e1..069c6834763a 100644\n--- a/test/sqlite/sqllogic_command.hpp\n+++ b/test/sqlite/sqllogic_command.hpp\n@@ -14,6 +14,7 @@ namespace duckdb {\n class SQLLogicTestRunner;\n \n enum class SortStyle : uint8_t { NO_SORT, ROW_SORT, VALUE_SORT };\n+enum class ExpectedResult : uint8_t { RESULT_SUCCESS, RESULT_ERROR, RESULT_UNKNOWN };\n \n struct LoopDefinition {\n \tstring loop_iterator_name;\n@@ -67,7 +68,7 @@ class Statement : public Command {\n public:\n \tStatement(SQLLogicTestRunner &runner);\n \n-\tbool expect_ok;\n+\tExpectedResult expected_result;\n \tstring expected_error;\n \n public:\ndiff --git a/test/sqlite/sqllogic_test_runner.cpp b/test/sqlite/sqllogic_test_runner.cpp\nindex 21bd58ed6e87..d2d33344706b 100644\n--- a/test/sqlite/sqllogic_test_runner.cpp\n+++ b/test/sqlite/sqllogic_test_runner.cpp\n@@ -256,9 +256,11 @@ void SQLLogicTestRunner::ExecuteFile(string script) {\n \n \t\t\t// parse the first parameter\n \t\t\tif (token.parameters[0] == \"ok\") {\n-\t\t\t\tcommand->expect_ok = true;\n+\t\t\t\tcommand->expected_result = ExpectedResult::RESULT_SUCCESS;\n \t\t\t} else if (token.parameters[0] == \"error\") {\n-\t\t\t\tcommand->expect_ok = false;\n+\t\t\t\tcommand->expected_result = ExpectedResult::RESULT_ERROR;\n+\t\t\t} else if (token.parameters[0] == \"maybe\") {\n+\t\t\t\tcommand->expected_result = ExpectedResult::RESULT_UNKNOWN;\n \t\t\t} else {\n \t\t\t\tparser.Fail(\"statement argument should be 'ok' or 'error\");\n \t\t\t}\n@@ -272,7 +274,8 @@ void SQLLogicTestRunner::ExecuteFile(string script) {\n \t\t\tif (statement_text.empty()) {\n \t\t\t\tparser.Fail(\"Unexpected empty statement text\");\n \t\t\t}\n-\t\t\tcommand->expected_error = parser.ExtractExpectedError(command->expect_ok);\n+\t\t\tcommand->expected_error =\n+\t\t\t    parser.ExtractExpectedError(command->expected_result == ExpectedResult::RESULT_SUCCESS);\n \n \t\t\t// perform any renames in the text\n \t\t\tcommand->base_sql_query = ReplaceKeywords(move(statement_text));\n",
  "problem_statement": "\"having\" is not working: python binding\n### What happens?\r\n\r\nI have been using duckdb for the last few months and love it.\r\nThank you for your work on this.\r\n\r\nUsing 'having' after 'group by' raises the following error:\r\n\"Binder Error: column df.grp must appear in the GROUP BY clause or be used in an aggregate function\"\r\n\r\n**#session_info.show():**\r\nduckdb              0.4.1-dev1115\r\nnumpy               1.22.4\r\npandas              1.4.2\r\nsession_info        1.0.0\r\n\r\nClick to view modules imported as dependencies\r\n\r\nIPython             8.4.0\r\njupyter_client      7.3.4\r\njupyter_core        4.10.0\r\n\r\nPython 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]\r\nLinux-5.15.0-1015-aws-x86_64-with-glibc2.35\r\n\r\nSession information updated at 2022-08-01 16:28\r\n\r\n### To Reproduce\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\nimport duckdb \r\n\r\ncon = duckdb.connect()\r\n\r\n**#generate sample data**\r\nn_rows=1000\r\ndata = {\r\n'val':range(n_rows),\r\n'grp':np.random.choice(['a','b','c'],n_rows)\r\n}\r\ndf=pd.DataFrame(data)\r\n\r\n**#query to reproduce the error**\r\n_qry=f\"\"\"\r\n```sql \r\nSELECT \r\n    grp,SUM(val) AS val\r\nFROM df\r\nGROUP BY ALL\r\nHAVING grp=='a'\r\n```\r\n\"\"\"\r\n\r\ncon.execute(_qry).df()\r\n\r\n### OS:\r\n\r\nmac Monterey 12.4\r\n\r\n### DuckDB Version:\r\n\r\n0.4.0\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Full Name:\r\n\r\nAdarsh\r\n\r\n### Affiliation:\r\n\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [x] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\nPython crashes with struct_insert\n### What happens?\r\n\r\nAdding values to a struct crashes my python.\r\n\r\n### To Reproduce\r\n\r\n```py\r\nimport duckdb\r\n\r\nsql= \"\"\"\r\nwith data as (\r\n    Select * from (VALUES ('Amsterdam', {'x': 1, 'y': 2, 'z': 3}), ('London', {'x': 4, 'y': 5, 'z': 6})) Cities(Name, Id)\r\n)\r\n\r\nSelect\r\n    *,\r\n    struct_insert(Id, d := 4)\r\nfrom data\r\n\"\"\"\r\n\r\nduckdb.query(sql).df()\r\n```\r\n\r\n### OS:\r\n\r\nWindows 10 Enterprise 21H2\r\n\r\n### DuckDB Version:\r\n\r\n0.6.0, 0.5.1, 0.6.1-dev32\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Full Name:\r\n\r\nDino Burger\r\n\r\n### Affiliation:\r\n\r\nCrif AG\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\n",
  "hints_text": "Are you sure you don't mean\r\n\r\n```sql\r\nSELECT grp, SUM(val) AS val\r\nFROM df\r\nGROUP BY a\r\nHAVING grp == 'a'\r\n```\r\n?\nDoes it work with only 1 equals, and/or if you explicitly say `group by grp`?\n\r\n> Does it work with only 1 equals, and/or if you explicitly say `group by grp`?\r\n\r\nIt does work with 'group by grp'. Thanks. \r\nIt does not work when I use 'ALL' in the group by. \r\nusing '='  instead of '==' does not change the outcome. \n",
  "created_at": "2022-11-24T13:30:14Z"
}