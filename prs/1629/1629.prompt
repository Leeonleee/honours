You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
NULLS FIRST/NULLS LAST behavior is incorrect in Top-N implementation
```sql
create table integers(i integer);
insert into integers values (1), (null);
select * from integers order by i asc nulls last limit 1;
--1, correct
select * from integers order by i desc nulls last limit 1;
--NULL, incorrect, should be 1
```


</issue>
<code>
[start of README.md]
1: <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
2: 
3: ![.github/workflows/main.yml](https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master)
4: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
5: [![Coverage Status](https://coveralls.io/repos/github/cwida/duckdb/badge.svg?branch=master)](https://coveralls.io/github/cwida/duckdb?branch=master)
6: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3901452.svg)](https://zenodo.org/record/3901452)
7: 
8: 
9: ## Installation
10: If you just want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
11: 
12: ## Development
13: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
14: 
15: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
16: 
17: 
[end of README.md]
[start of src/execution/operator/order/physical_top_n.cpp]
1: #include "duckdb/execution/operator/order/physical_top_n.hpp"
2: 
3: #include "duckdb/common/assert.hpp"
4: #include "duckdb/common/value_operations/value_operations.hpp"
5: #include "duckdb/common/vector_operations/vector_operations.hpp"
6: #include "duckdb/execution/expression_executor.hpp"
7: #include "duckdb/storage/data_table.hpp"
8: #include "duckdb/common/to_string.hpp"
9: 
10: namespace duckdb {
11: 
12: //===--------------------------------------------------------------------===//
13: // Heaps
14: //===--------------------------------------------------------------------===//
15: class TopNHeap {
16: public:
17: 	TopNHeap(const vector<BoundOrderByNode> &orders, idx_t limit, idx_t offset)
18: 	    : limit(limit), offset(offset), heap_size(0) {
19: 		for (auto &order : orders) {
20: 			auto &expr = order.expression;
21: 			sort_types.push_back(expr->return_type);
22: 			order_types.push_back(order.type);
23: 			null_order_types.push_back(order.null_order);
24: 			executor.AddExpression(*expr);
25: 		}
26: 		// preallocate the heap
27: 		heap = unique_ptr<idx_t[]>(new idx_t[limit + offset]);
28: 	}
29: 
30: 	void Append(DataChunk &top_chunk, DataChunk &heap_chunk) {
31: 		top_data.Append(top_chunk);
32: 		heap_data.Append(heap_chunk);
33: 		D_ASSERT(heap_data.Count() == top_data.Count());
34: 	}
35: 
36: 	void Sink(DataChunk &input);
37: 	void Combine(TopNHeap &other);
38: 	void Reduce();
39: 
40: 	idx_t MaterializeTopChunk(DataChunk &top_chunk, idx_t position) {
41: 		return top_data.MaterializeHeapChunk(top_chunk, heap.get(), position, heap_size);
42: 	}
43: 
44: 	idx_t limit;
45: 	idx_t offset;
46: 	idx_t heap_size;
47: 	ExpressionExecutor executor;
48: 	vector<LogicalType> sort_types;
49: 	vector<OrderType> order_types;
50: 	vector<OrderByNullType> null_order_types;
51: 	ChunkCollection top_data;
52: 	ChunkCollection heap_data;
53: 	unique_ptr<idx_t[]> heap;
54: };
55: 
56: void TopNHeap::Sink(DataChunk &input) {
57: 	// compute the ordering values for the new chunk
58: 	DataChunk heap_chunk;
59: 	heap_chunk.Initialize(sort_types);
60: 
61: 	executor.Execute(input, heap_chunk);
62: 
63: 	// append the new chunk to what we have already
64: 	Append(input, heap_chunk);
65: }
66: 
67: void TopNHeap::Combine(TopNHeap &other) {
68: 	for (idx_t i = 0; i < other.top_data.ChunkCount(); ++i) {
69: 		auto &top_chunk = other.top_data.GetChunk(i);
70: 		auto &heap_chunk = other.heap_data.GetChunk(i);
71: 		Append(top_chunk, heap_chunk);
72: 	}
73: }
74: 
75: void TopNHeap::Reduce() {
76: 	heap_size = (heap_data.Count() > offset) ? MinValue(limit + offset, heap_data.Count()) : 0;
77: 	if (heap_size == 0) {
78: 		return;
79: 	}
80: 
81: 	// create the heap
82: 	heap_data.Heap(order_types, null_order_types, heap.get(), heap_size);
83: 
84: 	// extract the top rows into new collections
85: 	ChunkCollection new_top;
86: 	ChunkCollection new_heap;
87: 	DataChunk top_chunk;
88: 	top_chunk.Initialize(top_data.Types());
89: 	DataChunk heap_chunk;
90: 	heap_chunk.Initialize(heap_data.Types());
91: 	for (idx_t position = 0; position < heap_size;) {
92: 		(void)top_data.MaterializeHeapChunk(top_chunk, heap.get(), position, heap_size);
93: 		position = heap_data.MaterializeHeapChunk(heap_chunk, heap.get(), position, heap_size);
94: 		new_top.Append(top_chunk);
95: 		new_heap.Append(heap_chunk);
96: 	}
97: 
98: 	// replace the old data
99: 	std::swap(top_data, new_top);
100: 	std::swap(heap_data, new_heap);
101: }
102: 
103: class TopNGlobalState : public GlobalOperatorState {
104: public:
105: 	TopNGlobalState(const vector<BoundOrderByNode> &orders, idx_t limit, idx_t offset) : heap(orders, limit, offset) {
106: 	}
107: 	mutex lock;
108: 	TopNHeap heap;
109: };
110: 
111: class TopNLocalState : public LocalSinkState {
112: public:
113: 	TopNLocalState(const vector<BoundOrderByNode> &orders, idx_t limit, idx_t offset) : heap(orders, limit, offset) {
114: 	}
115: 	TopNHeap heap;
116: };
117: 
118: unique_ptr<LocalSinkState> PhysicalTopN::GetLocalSinkState(ExecutionContext &context) {
119: 	return make_unique<TopNLocalState>(orders, limit, offset);
120: }
121: 
122: unique_ptr<GlobalOperatorState> PhysicalTopN::GetGlobalState(ClientContext &context) {
123: 	return make_unique<TopNGlobalState>(orders, limit, offset);
124: }
125: 
126: //===--------------------------------------------------------------------===//
127: // Sink
128: //===--------------------------------------------------------------------===//
129: void PhysicalTopN::Sink(ExecutionContext &context, GlobalOperatorState &state, LocalSinkState &lstate,
130:                         DataChunk &input) {
131: 	// append to the local sink state
132: 	auto &sink = (TopNLocalState &)lstate;
133: 	sink.heap.Sink(input);
134: 	sink.heap.Reduce();
135: }
136: 
137: //===--------------------------------------------------------------------===//
138: // Combine
139: //===--------------------------------------------------------------------===//
140: void PhysicalTopN::Combine(ExecutionContext &context, GlobalOperatorState &state, LocalSinkState &lstate_p) {
141: 	auto &gstate = (TopNGlobalState &)state;
142: 	auto &lstate = (TopNLocalState &)lstate_p;
143: 
144: 	// scan the local top N and append it to the global heap
145: 	lock_guard<mutex> glock(gstate.lock);
146: 	gstate.heap.Combine(lstate.heap);
147: }
148: 
149: //===--------------------------------------------------------------------===//
150: // Finalize
151: //===--------------------------------------------------------------------===//
152: void PhysicalTopN::Finalize(Pipeline &pipeline, ClientContext &context, unique_ptr<GlobalOperatorState> state) {
153: 	auto &gstate = (TopNGlobalState &)*state;
154: 	// global finalize: compute the final top N
155: 	gstate.heap.Reduce();
156: 
157: 	PhysicalSink::Finalize(pipeline, context, move(state));
158: }
159: 
160: //===--------------------------------------------------------------------===//
161: // GetChunkInternal
162: //===--------------------------------------------------------------------===//
163: class PhysicalTopNOperatorState : public PhysicalOperatorState {
164: public:
165: 	PhysicalTopNOperatorState(PhysicalOperator &op, PhysicalOperator *child)
166: 	    : PhysicalOperatorState(op, child), position(0) {
167: 	}
168: 
169: 	idx_t position;
170: };
171: 
172: void PhysicalTopN::GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state_p) {
173: 	auto &state = (PhysicalTopNOperatorState &)*state_p;
174: 	auto &gstate = (TopNGlobalState &)*sink_state;
175: 
176: 	if (state.position >= gstate.heap.heap_size) {
177: 		return;
178: 	} else if (state.position < offset) {
179: 		state.position = offset;
180: 	}
181: 
182: 	state.position = gstate.heap.MaterializeTopChunk(chunk, state.position);
183: }
184: 
185: unique_ptr<PhysicalOperatorState> PhysicalTopN::GetOperatorState() {
186: 	return make_unique<PhysicalTopNOperatorState>(*this, children[0].get());
187: }
188: 
189: string PhysicalTopN::ParamsToString() const {
190: 	string result;
191: 	result += "Top " + to_string(limit);
192: 	if (offset > 0) {
193: 		result += "\n";
194: 		result += "Offset " + to_string(offset);
195: 	}
196: 	result += "\n[INFOSEPARATOR]";
197: 	for (idx_t i = 0; i < orders.size(); i++) {
198: 		result += "\n";
199: 		result += orders[i].expression->ToString() + " ";
200: 		result += orders[i].type == OrderType::DESCENDING ? "DESC" : "ASC";
201: 	}
202: 	return result;
203: }
204: 
205: } // namespace duckdb
[end of src/execution/operator/order/physical_top_n.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: