{
  "repo": "duckdb/duckdb",
  "pull_number": 5721,
  "instance_id": "duckdb__duckdb-5721",
  "issue_numbers": [
    "5662"
  ],
  "base_commit": "727d15404eb911d448bcecba6cea2c677225074a",
  "patch": "diff --git a/src/function/table/read_csv.cpp b/src/function/table/read_csv.cpp\nindex ded16bcb86b1..00dc837dc406 100644\n--- a/src/function/table/read_csv.cpp\n+++ b/src/function/table/read_csv.cpp\n@@ -65,9 +65,11 @@ static unique_ptr<FunctionData> ReadCSVBind(ClientContext &context, TableFunctio\n \n \tresult->InitializeFiles(context, patterns);\n \n+\tbool explicitly_set_columns = false;\n \tfor (auto &kv : input.named_parameters) {\n \t\tauto loption = StringUtil::Lower(kv.first);\n \t\tif (loption == \"columns\") {\n+\t\t\texplicitly_set_columns = true;\n \t\t\tauto &child_type = kv.second.type();\n \t\t\tif (child_type.id() != LogicalTypeId::STRUCT) {\n \t\t\t\tthrow BinderException(\"read_csv columns requires a struct as input\");\n@@ -105,7 +107,6 @@ static unique_ptr<FunctionData> ReadCSVBind(ClientContext &context, TableFunctio\n \t\t\t\t}\n \t\t\t\toptions.sql_types_per_column[name] = def_type;\n \t\t\t}\n-\n \t\t} else if (loption == \"all_varchar\") {\n \t\t\toptions.all_varchar = BooleanValue::Get(kv.second);\n \t\t} else if (loption == \"normalize_names\") {\n@@ -130,7 +131,16 @@ static unique_ptr<FunctionData> ReadCSVBind(ClientContext &context, TableFunctio\n \t\tif (names.empty()) {\n \t\t\tnames.assign(initial_reader->col_names.begin(), initial_reader->col_names.end());\n \t\t} else {\n-\t\t\tD_ASSERT(return_types.size() == names.size());\n+\t\t\tif (explicitly_set_columns) {\n+\t\t\t\t// The user has influenced the names, can't assume they are valid anymore\n+\t\t\t\tif (return_types.size() != names.size()) {\n+\t\t\t\t\tthrow BinderException(\"The amount of names specified (%d) and the observed amount of types (%d) in \"\n+\t\t\t\t\t                      \"the file don't match\",\n+\t\t\t\t\t                      names.size(), return_types.size());\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tD_ASSERT(return_types.size() == names.size());\n+\t\t\t}\n \t\t}\n \t\toptions = initial_reader->options;\n \t\tresult->sql_types = initial_reader->sql_types;\n",
  "test_patch": "diff --git a/test/sql/copy/csv/test_csv_column_count_mismatch b/test/sql/copy/csv/test_csv_column_count_mismatch\nnew file mode 100644\nindex 000000000000..fc2f8d587e93\n--- /dev/null\n+++ b/test/sql/copy/csv/test_csv_column_count_mismatch\n@@ -0,0 +1,14 @@\n+statement ok\n+pragma enable_verification;\n+\n+# We can read with auto just fine\n+statement ok\n+select * from read_csv_auto('test/sql/copy/csv/data/people.csv');\n+\n+# Specifying columns, but not specifying the right amount throws an error\n+statement error\n+select * from read_csv_auto('test/sql/copy/csv/data/people.csv', columns={'a': 'VARCHAR'})\n+\n+# When we do specify the right amount of columns, everything works\n+statement ok\n+select * from read_csv_auto('test/sql/copy/csv/data/people.csv', columns={'a': 'VARCHAR', 'b': 'VARCHAR'})\n",
  "problem_statement": "CSV Reader INTERNAL Error on size mismatch between `columns` and header\n### What happens?\r\n\r\nWhen reading a csv `header=true`, and also explicitly supplying `columns`, when they don't match an InternalException is thrown. Similar to:\r\n```\r\n  File \"/Users/thijs/DuckDBLabs/duckdb/tmp/mismatch_csv.py\", line 13, in <module>\r\n    data = con.execute(q2).fetchall()\r\nduckdb.InternalException: INTERNAL Error: Assertion triggered in file \"/Users/thijs/DuckDBLabs/duckdb/src/function/table/read_csv.cpp\" on line 113: return_types.size() == names.size()\r\n```\r\n\r\nNote: I'm sure this can also be reproduced as a `.test` file, for convenience I've supplied the example using the python client.\r\n\r\n### To Reproduce\r\n\r\ntest.csv\r\n```csv\r\na, b, c, d\r\n1, 2, 3, 4\r\n```\r\n\r\n```py\r\nimport duckdb\r\n\r\ncon=duckdb.connect()\r\ncolumns=\"{'a':'varchar','b':'varchar','c':'varchar','d':'varchar','e':'varchar'}\"\r\nq2=f\"\"\"\r\n\tSELECT * FROM read_csv_auto(\r\n\t\t'test.csv',\r\n\t\tdelim='/t',\r\n\t\theader=True,\r\n\t\tcolumns={columns}\r\n\t)\r\n\t\"\"\"\r\ndata = con.execute(q2).fetchall()\r\nprint(data)\r\n```\r\n\r\n### OS:\r\n\r\nMacOS\r\n\r\n### DuckDB Version:\r\n\r\nmaster\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Full Name:\r\n\r\nThijs Bruineman\r\n\r\n### Affiliation:\r\n\r\nDuckDB Labs\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\n",
  "hints_text": "",
  "created_at": "2022-12-16T16:16:19Z"
}