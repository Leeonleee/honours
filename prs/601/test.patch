diff --git a/test/rigger/test_rigger.cpp b/test/rigger/test_rigger.cpp
index 41b3f0c567b5..4dd1be33e206 100644
--- a/test/rigger/test_rigger.cpp
+++ b/test/rigger/test_rigger.cpp
@@ -637,4 +637,33 @@ TEST_CASE("Tests found by Rigger", "[rigger]") {
 		result = con.Query("SELECT * FROM t0 WHERE c0 LIKE '' AND c0 < true;");
 		REQUIRE(CHECK_COLUMN(result, 0, {}));
 	}
+	SECTION("596") {
+		// STDDEV_POP unexpectedly does not fetch any rows
+		REQUIRE_NO_FAIL(con.Query("CREATE TABLE t0(c0 DOUBLE);"));
+		REQUIRE_NO_FAIL(con.Query("INSERT INTO t0(c0) VALUES(1E200), (0);"));
+		REQUIRE_FAIL(con.Query("SELECT STDDEV_POP(c0) FROM t0;"));
+	}
+	SECTION("599") {
+		// UPDATE results in crash or ASan error
+		REQUIRE_NO_FAIL(con.Query("CREATE TABLE t0(c0 INT, c1 VARCHAR);"));
+		REQUIRE_NO_FAIL(con.Query("INSERT INTO t0 VALUES (0, 0), (NULL, 0);"));
+		REQUIRE_NO_FAIL(con.Query("UPDATE t0 SET c1 = c0;"));
+		result = con.Query("SELECT * FROM t0 ORDER BY 1");
+		REQUIRE(CHECK_COLUMN(result, 0, {Value(), 0}));
+		REQUIRE(CHECK_COLUMN(result, 1, {Value(), "0"}));
+	}
+	SECTION("602") {
+		// GROUP BY does not take COLLATE into account
+		REQUIRE_NO_FAIL(con.Query("CREATE TABLE t0(c0 VARCHAR COLLATE NOCASE);"));
+		REQUIRE_NO_FAIL(con.Query("INSERT INTO t0(c0) VALUES ('a'), ('A');"));
+		result = con.Query("SELECT t0.c0 FROM t0 GROUP BY t0.c0;");
+		REQUIRE(CHECK_COLUMN(result, 0, {"a"}));
+	}
+	SECTION("603") {
+		// BETWEEN with COLLATE NOACCENT.NOCASE expression results in a segfault/ASan failure
+		REQUIRE_NO_FAIL(con.Query("CREATE TABLE t0(c0 DATE, c1 VARCHAR);"));
+		REQUIRE_NO_FAIL(con.Query("INSERT INTO t0(c0) VALUES (NULL), ('2000-01-01');"));
+		result = con.Query("SELECT * FROM t0 WHERE 'a' BETWEEN c0 AND c1 COLLATE NOACCENT.NOCASE;");
+		REQUIRE(CHECK_COLUMN(result, 0, {}));
+	}
 }
diff --git a/test/sql/simple/test_inserts.cpp b/test/sql/simple/test_inserts.cpp
index 1ef4d559e8c7..6eade2e428af 100644
--- a/test/sql/simple/test_inserts.cpp
+++ b/test/sql/simple/test_inserts.cpp
@@ -199,3 +199,13 @@ TEST_CASE("Test insert with too few or too many cols", "[simpleinserts]") {
 	// also with queries
 	REQUIRE_FAIL(con.Query("INSERT INTO a SELECT 42"));
 }
+
+TEST_CASE("Test insert with long string constant", "[simpleinserts]") {
+	unique_ptr<QueryResult> result;
+	DuckDB db(nullptr);
+	Connection con(db);
+
+	// found by Pedro Holanda
+	REQUIRE_NO_FAIL(con.Query("CREATE TABLE IF NOT EXISTS presentations(presentation_date Date NOT NULL UNIQUE, author VARCHAR NOT NULL, title VARCHAR NOT NULL, bio VARCHAR, abstract VARCHAR, zoom_link VARCHAR);"));
+	REQUIRE_NO_FAIL(con.Query("insert into presentations values ('2020-05-29', 'Eduardo Pena', 'Analytical Query Processing Based on Continuous Compression of Intermediates', NULL, 'Modern in-memory column-stores are widely accepted as the adequate database architecture for the efficient processing of complex analytical queries over large relational data volumes. These systems keep their entire data in main memory and typically employ lightweight compression to address the bottleneck between main memory and CPU. Numerous lightweight compression algorithms have been proposed in the past years, but none of them is suitable in all cases. While lightweight compression is already well established for base data, the efficient representation of intermediate results generated during query processing has attracted insufficient attention so far, although in in-memory systems, accessing intermeFdiates is as expensive as accessing base data. Thus, our vision is a continuous use of lightweight compression for all intermediates in a query execution plan, whereby a suitable compression algorithm should be selected for each intermediate. In this talk, I will provide an overview of our research in the context of this vision, including an experimental survey of lightweight compression algorithms, our compression-enabled processing model, and our compression-aware query optimization strategies.', 'https://zoom.us/j/7845983526');"));
+}
