{
  "repo": "duckdb/duckdb",
  "pull_number": 8977,
  "instance_id": "duckdb__duckdb-8977",
  "issue_numbers": [
    "8822"
  ],
  "base_commit": "c3aa7594ab191e89d2aa4500916f67be5bdb1895",
  "patch": "diff --git a/src/common/string_util.cpp b/src/common/string_util.cpp\nindex 4f994b6a45fc..1c24580801bf 100644\n--- a/src/common/string_util.cpp\n+++ b/src/common/string_util.cpp\n@@ -154,6 +154,22 @@ string StringUtil::Join(const vector<string> &input, const string &separator) {\n \treturn StringUtil::Join(input, input.size(), separator, [](const string &s) { return s; });\n }\n \n+string StringUtil::Join(const set<string> &input, const string &separator) {\n+\t// The result\n+\tstd::string result;\n+\n+\tauto it = input.begin();\n+\twhile (it != input.end()) {\n+\t\tresult += *it;\n+\t\tit++;\n+\t\tif (it == input.end()) {\n+\t\t\tbreak;\n+\t\t}\n+\t\tresult += separator;\n+\t}\n+\treturn result;\n+}\n+\n string StringUtil::BytesToHumanReadableString(idx_t bytes) {\n \tstring db_size;\n \tauto kilobytes = bytes / 1000;\ndiff --git a/src/execution/operator/csv_scanner/buffered_csv_reader.cpp b/src/execution/operator/csv_scanner/buffered_csv_reader.cpp\nindex 55c9494cd9c7..eb6f469a5340 100644\n--- a/src/execution/operator/csv_scanner/buffered_csv_reader.cpp\n+++ b/src/execution/operator/csv_scanner/buffered_csv_reader.cpp\n@@ -18,6 +18,7 @@\n #include \"duckdb/storage/data_table.hpp\"\n #include \"utf8proc.hpp\"\n #include \"utf8proc_wrapper.hpp\"\n+#include \"duckdb/common/set.hpp\"\n \n #include <algorithm>\n #include <cctype>\n@@ -97,10 +98,11 @@ string BufferedCSVReader::ColumnTypesError(case_insensitive_map_t<idx_t> sql_typ\n \t\treturn string();\n \t}\n \tstring exception = \"COLUMN_TYPES error: Columns with names: \";\n+\tset<string> problematic_columns;\n \tfor (auto &col : sql_types_per_column) {\n-\t\texception += \"\\\"\" + col.first + \"\\\",\";\n+\t\tproblematic_columns.insert(\"\\\"\" + col.first + \"\\\"\");\n \t}\n-\texception.pop_back();\n+\texception += StringUtil::Join(problematic_columns, \",\");\n \texception += \" do not exist in the CSV File\";\n \treturn exception;\n }\ndiff --git a/src/include/duckdb/common/string_util.hpp b/src/include/duckdb/common/string_util.hpp\nindex 7074387a6071..e237ce4b8ccf 100644\n--- a/src/include/duckdb/common/string_util.hpp\n+++ b/src/include/duckdb/common/string_util.hpp\n@@ -11,6 +11,7 @@\n #include \"duckdb/common/constants.hpp\"\n #include \"duckdb/common/exception.hpp\"\n #include \"duckdb/common/vector.hpp\"\n+#include \"duckdb/common/set.hpp\"\n \n #include <cstring>\n \n@@ -134,6 +135,7 @@ class StringUtil {\n \n \t//! Join multiple strings into one string. Components are concatenated by the given separator\n \tDUCKDB_API static string Join(const vector<string> &input, const string &separator);\n+\tDUCKDB_API static string Join(const set<string> &input, const string &separator);\n \n \ttemplate <class T>\n \tstatic string ToString(const vector<T> &input, const string &separator) {\ndiff --git a/src/include/duckdb/main/connection.hpp b/src/include/duckdb/main/connection.hpp\nindex 29048a9e438e..75cae1500909 100644\n--- a/src/include/duckdb/main/connection.hpp\n+++ b/src/include/duckdb/main/connection.hpp\n@@ -131,7 +131,8 @@ class Connection {\n \n \t//! Reads CSV file\n \tDUCKDB_API shared_ptr<Relation> ReadCSV(const string &csv_file);\n-\tDUCKDB_API shared_ptr<Relation> ReadCSV(const string &csv_file, named_parameter_map_t &&options);\n+\tDUCKDB_API shared_ptr<Relation> ReadCSV(const vector<string> &csv_input, named_parameter_map_t &&options);\n+\tDUCKDB_API shared_ptr<Relation> ReadCSV(const string &csv_input, named_parameter_map_t &&options);\n \tDUCKDB_API shared_ptr<Relation> ReadCSV(const string &csv_file, const vector<string> &columns);\n \n \t//! Reads Parquet file\ndiff --git a/src/include/duckdb/main/relation/read_csv_relation.hpp b/src/include/duckdb/main/relation/read_csv_relation.hpp\nindex fc2f98181f7d..9da5cd1727a2 100644\n--- a/src/include/duckdb/main/relation/read_csv_relation.hpp\n+++ b/src/include/duckdb/main/relation/read_csv_relation.hpp\n@@ -19,12 +19,16 @@ class ReadCSVRelation : public TableFunctionRelation {\n public:\n \tReadCSVRelation(const shared_ptr<ClientContext> &context, const string &csv_file, vector<ColumnDefinition> columns,\n \t                string alias = string());\n-\tReadCSVRelation(const shared_ptr<ClientContext> &context, const string &csv_file, named_parameter_map_t &&options,\n-\t                string alias = string());\n+\tReadCSVRelation(const shared_ptr<ClientContext> &context, const vector<string> &csv_files,\n+\t                named_parameter_map_t &&options, string alias = string());\n \n \tstring alias;\n \tbool auto_detect;\n \n+protected:\n+\tvoid ReadCSVAutoInit(named_parameter_map_t &&options);\n+\tvoid InitializeAlias(const vector<string> &input);\n+\n public:\n \tstring GetAlias() override;\n };\ndiff --git a/src/main/connection.cpp b/src/main/connection.cpp\nindex e225c643cd62..5d13594a353a 100644\n--- a/src/main/connection.cpp\n+++ b/src/main/connection.cpp\n@@ -223,8 +223,13 @@ shared_ptr<Relation> Connection::ReadCSV(const string &csv_file) {\n \treturn ReadCSV(csv_file, std::move(options));\n }\n \n-shared_ptr<Relation> Connection::ReadCSV(const string &csv_file, named_parameter_map_t &&options) {\n-\treturn make_shared<ReadCSVRelation>(context, csv_file, std::move(options));\n+shared_ptr<Relation> Connection::ReadCSV(const vector<string> &csv_input, named_parameter_map_t &&options) {\n+\treturn make_shared<ReadCSVRelation>(context, csv_input, std::move(options));\n+}\n+\n+shared_ptr<Relation> Connection::ReadCSV(const string &csv_input, named_parameter_map_t &&options) {\n+\tvector<string> csv_files = {csv_input};\n+\treturn ReadCSV(csv_files, std::move(options));\n }\n \n shared_ptr<Relation> Connection::ReadCSV(const string &csv_file, const vector<string> &columns) {\ndiff --git a/src/main/relation/read_csv_relation.cpp b/src/main/relation/read_csv_relation.cpp\nindex fd9ecf5523e1..3b8c9fb75b99 100644\n--- a/src/main/relation/read_csv_relation.cpp\n+++ b/src/main/relation/read_csv_relation.cpp\n@@ -17,15 +17,18 @@\n \n namespace duckdb {\n \n+void ReadCSVRelation::InitializeAlias(const vector<string> &input) {\n+\tD_ASSERT(input.size() >= 1);\n+\tauto csv_file = input[0];\n+\talias = StringUtil::Split(csv_file, \".\")[0];\n+}\n+\n ReadCSVRelation::ReadCSVRelation(const shared_ptr<ClientContext> &context, const string &csv_file,\n                                  vector<ColumnDefinition> columns_p, string alias_p)\n     : TableFunctionRelation(context, \"read_csv\", {Value(csv_file)}, nullptr, false), alias(std::move(alias_p)),\n       auto_detect(false) {\n \n-\tif (alias.empty()) {\n-\t\talias = StringUtil::Split(csv_file, \".\")[0];\n-\t}\n-\n+\tInitializeAlias({csv_file});\n \tcolumns = std::move(columns_p);\n \n \tchild_list_t<Value> column_names;\n@@ -36,16 +39,23 @@ ReadCSVRelation::ReadCSVRelation(const shared_ptr<ClientContext> &context, const\n \tAddNamedParameter(\"columns\", Value::STRUCT(std::move(column_names)));\n }\n \n-ReadCSVRelation::ReadCSVRelation(const std::shared_ptr<ClientContext> &context, const string &csv_file,\n+static Value CreateValueFromFileList(const vector<string> &file_list) {\n+\tvector<Value> files;\n+\tfor (auto &file : file_list) {\n+\t\tfiles.push_back(file);\n+\t}\n+\treturn Value::LIST(std::move(files));\n+}\n+\n+ReadCSVRelation::ReadCSVRelation(const std::shared_ptr<ClientContext> &context, const vector<string> &input,\n                                  named_parameter_map_t &&options, string alias_p)\n-    : TableFunctionRelation(context, \"read_csv_auto\", {Value(csv_file)}, nullptr, false), alias(std::move(alias_p)),\n-      auto_detect(true) {\n+    : TableFunctionRelation(context, \"read_csv_auto\", {CreateValueFromFileList(input)}, nullptr, false),\n+      alias(std::move(alias_p)), auto_detect(true) {\n \n-\tif (alias.empty()) {\n-\t\talias = StringUtil::Split(csv_file, \".\")[0];\n-\t}\n+\tInitializeAlias(input);\n \n-\tauto files = MultiFileReader::GetFileList(*context, csv_file, \"CSV\");\n+\tauto file_list = CreateValueFromFileList(input);\n+\tauto files = MultiFileReader::GetFileList(*context, file_list, \"CSV\");\n \tD_ASSERT(!files.empty());\n \n \tauto &file_name = files[0];\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/filesystem_object.hpp b/tools/pythonpkg/src/include/duckdb_python/filesystem_object.hpp\nindex 807e36e09ce9..d78b5dac12e6 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/filesystem_object.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/filesystem_object.hpp\n@@ -14,18 +14,20 @@ namespace duckdb {\n \n class FileSystemObject : public RegisteredObject {\n public:\n-\texplicit FileSystemObject(py::object fs, const string &filename)\n-\t    : RegisteredObject(std::move(fs)), filename(filename) {\n+\texplicit FileSystemObject(py::object fs, vector<string> filenames_p)\n+\t    : RegisteredObject(std::move(fs)), filenames(std::move(filenames_p)) {\n \t}\n \tvirtual ~FileSystemObject() {\n \t\tpy::gil_scoped_acquire acquire;\n \t\t// Assert that the 'obj' is a filesystem\n \t\tD_ASSERT(\n \t\t    py::isinstance(obj, DuckDBPyConnection::ImportCache()->pyduckdb().filesystem.modified_memory_filesystem()));\n-\t\tobj.attr(\"delete\")(filename);\n+\t\tfor (auto &file : filenames) {\n+\t\t\tobj.attr(\"delete\")(file);\n+\t\t}\n \t}\n \n-\tstring filename;\n+\tvector<string> filenames;\n };\n \n } // namespace duckdb\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/path_like.hpp b/tools/pythonpkg/src/include/duckdb_python/path_like.hpp\nindex b78eef480725..7d577b1a6aa5 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/path_like.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/path_like.hpp\n@@ -3,6 +3,7 @@\n #include \"duckdb/common/common.hpp\"\n #include \"duckdb_python/pybind11/pybind_wrapper.hpp\"\n #include \"duckdb/main/external_dependencies.hpp\"\n+#include \"duckdb/common/types/value.hpp\"\n \n namespace duckdb {\n \n@@ -10,7 +11,8 @@ struct DuckDBPyConnection;\n \n struct PathLike {\n \tstatic PathLike Create(const py::object &object, DuckDBPyConnection &connection);\n-\tstring str;\n+\t// The file(s) extracted from object\n+\tvector<string> files;\n \tshared_ptr<ExternalDependency> dependency;\n };\n \ndiff --git a/tools/pythonpkg/src/path_like.cpp b/tools/pythonpkg/src/path_like.cpp\nindex 5e600b845e2a..0e11183ba1eb 100644\n--- a/tools/pythonpkg/src/path_like.cpp\n+++ b/tools/pythonpkg/src/path_like.cpp\n@@ -4,26 +4,92 @@\n #include \"duckdb/common/string_util.hpp\"\n #include \"duckdb_python/pyfilesystem.hpp\"\n #include \"duckdb_python/filesystem_object.hpp\"\n+#include \"duckdb/common/optional_ptr.hpp\"\n \n namespace duckdb {\n \n-PathLike PathLike::Create(const py::object &object, DuckDBPyConnection &connection) {\n-\tPathLike result;\n-\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+struct PathLikeProcessor {\n+public:\n+\tPathLikeProcessor(DuckDBPyConnection &connection, PythonImportCache &import_cache)\n+\t    : connection(connection), import_cache(import_cache) {\n+\t}\n+\n+public:\n+\tvoid AddFile(const py::object &object);\n+\tPathLike Finalize();\n+\n+protected:\n+\tModifiedMemoryFileSystem &GetFS() {\n+\t\tif (!object_store) {\n+\t\t\tobject_store = &connection.GetObjectFileSystem();\n+\t\t}\n+\t\treturn *object_store;\n+\t}\n+\n+public:\n+\tDuckDBPyConnection &connection;\n+\toptional_ptr<ModifiedMemoryFileSystem> object_store;\n+\tPythonImportCache &import_cache;\n+\t// The list containing every file\n+\tvector<string> all_files;\n+\t// The list of files that are registered in the object_store;\n+\tvector<string> fs_files;\n+};\n+\n+void PathLikeProcessor::AddFile(const py::object &object) {\n \tif (py::isinstance<py::str>(object)) {\n-\t\tresult.str = py::str(object);\n-\t\treturn result;\n+\t\tall_files.push_back(std::string(py::str(object)));\n+\t\treturn;\n \t}\n \tif (py::isinstance(object, import_cache.pathlib().Path())) {\n-\t\tresult.str = py::str(object);\n+\t\tall_files.push_back(std::string(py::str(object)));\n+\t\treturn;\n+\t}\n+\t// This is (assumed to be) a file-like object\n+\tauto generated_name =\n+\t    StringUtil::Format(\"%s://%s\", \"DUCKDB_INTERNAL_OBJECTSTORE\", StringUtil::GenerateRandomName());\n+\tall_files.push_back(generated_name);\n+\tfs_files.push_back(generated_name);\n+\n+\tauto &fs = GetFS();\n+\tfs.attr(\"add_file\")(object, generated_name);\n+}\n+\n+PathLike PathLikeProcessor::Finalize() {\n+\tPathLike result;\n+\n+\tif (all_files.empty()) {\n+\t\tthrow InvalidInputException(\"Please provide a non-empty list of paths or file-like objects\");\n+\t}\n+\tresult.files = std::move(all_files);\n+\n+\tif (fs_files.empty()) {\n+\t\t// No file-like objects were registered in the filesystem\n+\t\t// no need to make a dependency\n \t\treturn result;\n \t}\n-\t// Make sure that the object filesystem is initialized and registered\n-\tauto &fs = connection.GetObjectFileSystem();\n-\tresult.str = StringUtil::Format(\"%s://%s\", \"DUCKDB_INTERNAL_OBJECTSTORE\", StringUtil::GenerateRandomName());\n-\tfs.attr(\"add_file\")(object, result.str);\n-\tresult.dependency = make_uniq<PythonDependencies>(make_uniq<FileSystemObject>(fs, result.str));\n+\n+\t// Create the dependency, which contains the logic to clean up the files in its destructor\n+\tauto &fs = GetFS();\n+\tresult.dependency = make_uniq<PythonDependencies>(make_uniq<FileSystemObject>(fs, std::move(fs_files)));\n \treturn result;\n }\n \n+PathLike PathLike::Create(const py::object &object, DuckDBPyConnection &connection) {\n+\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+\n+\tPathLikeProcessor processor(connection, import_cache);\n+\tif (py::isinstance<py::list>(object)) {\n+\t\tauto list = py::list(object);\n+\t\tfor (auto &item : list) {\n+\t\t\tprocessor.AddFile(py::reinterpret_borrow<py::object>(item));\n+\t\t}\n+\t} else {\n+\t\t// Single object\n+\t\tprocessor.AddFile(object);\n+\t}\n+\n+\treturn processor.Finalize();\n+}\n+\n } // namespace duckdb\ndiff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex 8161276ccf5a..90332dfc8555 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -713,7 +713,7 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::ReadCSV(\n \t}\n \tCSVReaderOptions options;\n \tauto path_like = GetPathLike(name_p);\n-\tauto &name = path_like.str;\n+\tauto &name = path_like.files;\n \tauto file_like_object_wrapper = std::move(path_like.dependency);\n \tnamed_parameter_map_t bind_parameters;\n \n@@ -903,7 +903,7 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::ReadCSV(\n \t\tread_csv.extra_dependencies = std::move(file_like_object_wrapper);\n \t}\n \n-\treturn make_uniq<DuckDBPyRelation>(read_csv_p->Alias(name));\n+\treturn make_uniq<DuckDBPyRelation>(read_csv_p->Alias(read_csv.alias));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::RunQuery(const string &query, string alias, const py::object &params) {\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/api/test_read_csv.py b/tools/pythonpkg/tests/fast/api/test_read_csv.py\nindex 949ec73219bd..1a609238714f 100644\n--- a/tools/pythonpkg/tests/fast/api/test_read_csv.py\n+++ b/tools/pythonpkg/tests/fast/api/test_read_csv.py\n@@ -142,7 +142,7 @@ def test_parallel_true(self, duckdb_cursor):\n         print(res)\n         assert res == (1, 'Action', datetime.datetime(2006, 2, 15, 4, 46, 27))\n \n-    def test_parallel_true(self, duckdb_cursor):\n+    def test_parallel_false(self, duckdb_cursor):\n         rel = duckdb_cursor.read_csv(TestFile('category.csv'), parallel=False)\n         res = rel.fetchone()\n         print(res)\n@@ -525,7 +525,7 @@ def test_read_csv_names_mixed_with_dtypes(self):\n         # dtypes and names dont match\n         # FIXME: seems the order columns are named in this error is non-deterministic\n         # so for now I'm excluding the list of columns from the expected error\n-        expected_error = \"\"\"do not exist in the CSV File\"\"\"\n+        expected_error = \"\"\"Columns with names: \"d\",\"e\",\"f\" do not exist in the CSV File\"\"\"\n         with pytest.raises(duckdb.BinderException, match=expected_error):\n             rel = con.read_csv(\n                 file,\n@@ -536,3 +536,43 @@ def test_read_csv_names_mixed_with_dtypes(self):\n                     'f': str,\n                 },\n             )\n+\n+    def test_read_csv_multi_file(self):\n+        con = duckdb.connect()\n+        file1 = StringIO('one,two,three,four\\n1,2,3,4\\n1,2,3,4\\n1,2,3,4')\n+        file2 = StringIO('one,two,three,four\\n5,6,7,8\\n5,6,7,8\\n5,6,7,8')\n+        file3 = StringIO('one,two,three,four\\n9,10,11,12\\n9,10,11,12\\n9,10,11,12')\n+        files = [file1, file2, file3]\n+        rel = con.read_csv(files)\n+        res = rel.fetchall()\n+        assert res == [\n+            (1, 2, 3, 4),\n+            (1, 2, 3, 4),\n+            (1, 2, 3, 4),\n+            (5, 6, 7, 8),\n+            (5, 6, 7, 8),\n+            (5, 6, 7, 8),\n+            (9, 10, 11, 12),\n+            (9, 10, 11, 12),\n+            (9, 10, 11, 12),\n+        ]\n+\n+    def test_read_csv_empty_list(self):\n+        con = duckdb.connect()\n+        files = []\n+        with pytest.raises(\n+            duckdb.InvalidInputException, match='Please provide a non-empty list of paths or file-like objects'\n+        ):\n+            rel = con.read_csv(files)\n+            res = rel.fetchall()\n+\n+    def test_read_csv_list_invalid_path(self):\n+        con = duckdb.connect()\n+        files = [\n+            StringIO('one,two,three,four\\n1,2,3,4\\n1,2,3,4\\n1,2,3,4'),\n+            'not_valid_path',\n+            StringIO('one,two,three,four\\n9,10,11,12\\n9,10,11,12\\n9,10,11,12'),\n+        ]\n+        with pytest.raises(duckdb.IOException, match='No files found that match the pattern \"not_valid_path\"'):\n+            rel = con.read_csv(files)\n+            res = rel.fetchall()\n",
  "problem_statement": "[python] read_csv should accept iterable of filenames\n### What happens?\r\n\r\nIn the Python api, passing a list of strings of filename to `read_csv` errors.\r\n\r\nIn the CLI, this works fine.  Probably just a matter of wiring up the python bindings a little bit differently.\r\n\r\n### To Reproduce\r\n\r\n```\r\nD select count(*) from read_csv_auto('ci/ibis-testing-data/csv/batting.csv');\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 count_star() \u2502\r\n\u2502    int64     \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502       101332 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nD select count(*) from read_csv_auto(['ci/ibis-testing-data/csv/batting.csv', 'ci/ibis-testing-data/csv/batting.csv']);\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 count_star() \u2502\r\n\u2502    int64     \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502       202664 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nvs\r\n\r\n```python\r\n\r\n[ins] In [1]: import duckdb\r\n\r\n[ins] In [2]: con = duckdb.connect()\r\n\r\n[ins] In [3]: con.read_csv(\r\n         ...:     [\"ci/ibis-testing-data/csv/batting.csv\", \"ci/ibis-testing-data/csv/batting.csv\"]\r\n         ...: )\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[3], line 1\r\n----> 1 con.read_csv(\r\n      2     [\"ci/ibis-testing-data/csv/batting.csv\", \"ci/ibis-testing-data/csv/batting.csv\"]\r\n      3 )\r\n\r\nFile /nix/store/pl3rxj6p2s8mx25z469vs6ccr4xvm36f-python3-3.10.12-env/lib/python3.10/site-packages/pyduckdb/filesystem.py:56, in ModifiedMemoryFileSystem.add_file(self, object, path)\r\n     54 def add_file(self, object, path):\r\n     55 \tif not is_file_like(object):\r\n---> 56 \t\traise ValueError(\"Can not read from a non file-like object\")\r\n     57 \tpath = self._strip_protocol(path)\r\n     58 \tif isinstance(object, TextIOBase):\r\n     59 \t\t# Wrap this so that we can return a bytes object from 'read'\r\n\r\nValueError: Can not read from a non file-like object\r\n```\r\n\r\n### OS:\r\n\r\nubuntu 22.04.2 x86\r\n\r\n### DuckDB Version:\r\n\r\nv0.8.1 and 0.8.2-dev3250\r\n\r\n### DuckDB Client:\r\n\r\nPython and CLI\r\n\r\n### Full Name:\r\n\r\nGil Forsyth\r\n\r\n### Affiliation:\r\n\r\nVoltron Data\r\n\r\n### Have you tried this on the latest `main` branch?\r\n\r\nI have tested with a main build\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "",
  "created_at": "2023-09-18T11:16:21Z"
}