You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
PyRelation insert_into fails if Table has designated Schema
**What does happen?**
If a table belongs to a designated schema, the `insert_into` method will fail, whether the schema is specified or not.

**What should happen?**
Insert into the specified schema/table.  If only table is specified and is ambiguous (i.e. multiple schemas contain the same table name), then DuckDB should throw an error.  Also, may perhaps be helpful if `show_tables' likewise specifies schema as well, assuming one has been created.

**To Reproduce**
Steps to reproduce the behavior. Bonus points if those are only SQL queries.
```
import duckdb
from pandas import DataFrame

# open connection
con = duckdb.connect()
con.execute('CREATE SCHEMA s')
con.execute('CREATE TABLE s.t (id INTEGER PRIMARY KEY)')

# make relation
df = DataFrame([1],columns=['id'])
rel = con.from_df(df)

# this fails
rel.insert_into('s.t')

# so does this
rel.insert_into('t')
```

**Environment (please complete the following information):**
 - OS: Windows 10
 - DuckDB Version [0.2.8-dev919]

**Before submitting**
- [X] Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?
- [X] Have you tried this on the latest `master` branch? In case you cannot compile, you may find some binaries here: https://github.com/duckdb/duckdb/releases/tag/master-builds


</issue>
<code>
[start of README.md]
1: <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
2: 
3: ![.github/workflows/main.yml](https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master)
4: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
5: [![codecov](https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN)](https://codecov.io/gh/duckdb/duckdb)
6: 
7: 
8: ## Installation
9: If you just want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
10: 
11: ## Development
12: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
13: 
14: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
15: 
16: 
[end of README.md]
[start of .github/workflows/main.yml]
1: on: [push, pull_request]
2: 
3: defaults:
4:   run:
5:     shell: bash
6: 
7: env:
8:   GH_TOKEN: ${{ secrets.GH_TOKEN }}
9:   TWINE_PASSWORD: ${{ secrets.TWINE_PASSWORD }}
10:   AWS_ACCESS_KEY_ID: AKIAVBLKPL2ZW2T7TYFQ
11:   AWS_SECRET_ACCESS_KEY: ${{ secrets.NODE_PRE_GYP_SECRETACCESSKEY }}
12:   NODE_AUTH_TOKEN: ${{secrets.NODE_AUTH_TOKEN}}
13: 
14: jobs:
15:   linux-debug:
16:     name: Linux Debug
17:     runs-on: ubuntu-20.04
18: 
19:     env:
20:       CC: gcc-10
21:       CXX: g++-10
22:       TREAT_WARNINGS_AS_ERRORS: 1
23:       GEN: ninja
24: 
25:     steps:
26:     - uses: actions/checkout@v2
27:       with:
28:         fetch-depth: 0
29: 
30:     - name: Install
31:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
32: 
33:     - name: Build
34:       run: BUILD_ARROW_ABI_TEST=1 make debug
35: 
36:     - name: Test
37:       run: make unittestci
38: 
39:   format-check:
40:     name: Format Check
41:     runs-on: ubuntu-20.04
42: 
43:     env:
44:       CC: gcc-10
45:       CXX: g++-10
46:       GEN: ninja
47: 
48:     steps:
49:     - uses: actions/checkout@v2
50:       with:
51:         fetch-depth: 0
52: 
53:     - name: Install
54:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build clang-format && sudo pip3 install cmake-format
55: 
56:     - name: Format Check
57:       run: |
58:         clang-format --version
59:         clang-format --dump-config
60:         make format-check-silent
61: 
62:   tidy-check:
63:     name: Tidy Check
64:     runs-on: ubuntu-20.04
65: 
66:     env:
67:       CC: gcc-10
68:       CXX: g++-10
69:       GEN: ninja
70:       TIDY_THREADS: 4
71: 
72:     steps:
73:     - uses: actions/checkout@v2
74:       with:
75:         fetch-depth: 0
76: 
77:     - name: Install
78:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build clang-tidy && sudo pip3 install pybind11[global]
79: 
80:     - name: Tidy Check
81:       run: make tidy-check
82: 
83:   win-release-64:
84:     name: Windows (64 Bit)
85:     runs-on: windows-latest
86:     needs: linux-debug
87: 
88:     steps:
89:     - uses: actions/checkout@v2
90:       with:
91:         fetch-depth: 0
92: 
93:     - uses: actions/setup-python@v2
94:       with:
95:         python-version: '3.7'
96: 
97:     - name: Build
98:       run: |
99:         python scripts/windows_ci.py
100:         cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_GENERATOR_PLATFORM=x64 -DBUILD_ICU_EXTENSION=1 -DBUILD_PARQUET_EXTENSION=1 -DBUILD_TPCH_EXTENSION=1 -DBUILD_TPCDS_EXTENSION=1 -DBUILD_FTS_EXTENSION=1 -DBUILD_REST=1 -DJDBC_DRIVER=1 -DBUILD_VISUALIZER_EXTENSION=1
101:         cmake --build . --config Release
102: 
103:     - name: Test
104:       run: test/Release/unittest.exe
105: 
106:     - name: Tools Test
107:       run: |
108:         python tools/shell/shell-test.py Release/duckdb.exe
109:         java -cp tools/jdbc/duckdb_jdbc.jar org.duckdb.test.TestDuckDBJDBC
110: 
111:     - name: Deploy
112:       run: |
113:         python scripts/amalgamation.py
114:         choco install zip -y --force
115:         zip -j duckdb_cli-windows-amd64.zip Release/duckdb.exe
116:         zip -j libduckdb-windows-amd64.zip src/Release/duckdb.dll src/amalgamation/duckdb.hpp src/include/duckdb.h
117:         python scripts/asset-upload-gha.py libduckdb-windows-amd64.zip duckdb_cli-windows-amd64.zip duckdb_jdbc-windows-amd64.jar=tools/jdbc/duckdb_jdbc.jar
118: 
119:     - uses: actions/upload-artifact@v2
120:       with:
121:         name: duckdb-binaries-windows
122:         path: |
123:           libduckdb-windows-amd64.zip
124:           duckdb_cli-windows-amd64.zip
125:           tools/jdbc/duckdb_jdbc.jar
126: 
127:     - uses: ilammy/msvc-dev-cmd@v1
128:     - name: Duckdb.dll export symbols with C++ on Windows
129:       run: cl -I src/include examples/embedded-c++-windows/cppintegration.cpp -link src/Release/duckdb.lib
130: 
131:   win-release-32:
132:     name: Windows (32 Bit)
133:     runs-on: windows-latest
134:     needs: linux-debug
135: 
136:     steps:
137:     - uses: actions/checkout@v2
138:       with:
139:         fetch-depth: 0
140: 
141:     - uses: actions/setup-python@v2
142:       with:
143:         python-version: '3.7'
144: 
145:     - name: Build
146:       run: |
147:         cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_GENERATOR_PLATFORM=Win32 -DBUILD_ICU_EXTENSION=1 -DBUILD_PARQUET_EXTENSION=1 -DBUILD_TPCH_EXTENSION=1 -DBUILD_TPCDS_EXTENSION=1 -DBUILD_FTS_EXTENSION=1 -DJDBC_DRIVER=1 -DBUILD_VISUALIZER_EXTENSION=1
148:         cmake --build . --config Release
149: 
150:     - name: Test
151:       run: test/Release/unittest.exe
152: 
153:     - name: Tools Test
154:       run: |
155:         python tools/shell/shell-test.py Release/duckdb.exe
156: 
157:     - name: Deploy
158:       run: |
159:         python scripts/amalgamation.py
160:         choco install zip -y --force
161:         zip -j duckdb_cli-windows-i386.zip Release/duckdb.exe
162:         zip -j libduckdb-windows-i386.zip src/Release/duckdb.dll src/amalgamation/duckdb.hpp src/include/duckdb.h
163:         python scripts/asset-upload-gha.py libduckdb-windows-i386.zip duckdb_cli-windows-i386.zip duckdb_jdbc-windows-i386.jar=tools/jdbc/duckdb_jdbc.jar
164: 
165:     - uses: actions/upload-artifact@v2
166:       with:
167:         name: duckdb-binaries-windows
168:         path: |
169:           libduckdb-windows-i386.zip
170:           duckdb_cli-windows-i386.zip
171:           tools/jdbc/duckdb_jdbc.jar
172: 
173:   mingw:
174:      name: MingW (64 Bit)
175:      runs-on: windows-latest
176:      needs: linux-debug
177:      defaults:
178:        run:
179:          shell: msys2 {0}
180:      steps:
181:        - uses: actions/checkout@v2
182:        - uses: msys2/setup-msys2@v2
183:          with:
184:            msystem: MINGW64
185:            update: true
186:            install: git mingw-w64-x86_64-toolchain mingw-w64-x86_64-cmake mingw-w64-x86_64-ninja git
187:        # see here: https://gist.github.com/scivision/1de4fd6abea9ba6b2d87dc1e86b5d2ce
188:        - name: Put MSYS2_MinGW64 on PATH
189:          # there is not yet an environment variable for this path from msys2/setup-msys2
190:          run: export PATH=D:/a/_temp/msys/msys64/mingw64/bin:$PATH
191: 
192:        - name: Build
193:          run: |
194:            cmake -G "Ninja" -DCMAKE_BUILD_TYPE=Release -DBUILD_PARQUET_EXTENSION=1
195:            cmake --build . --config Release
196: 
197:        - name: Test
198:          run: |
199:            cp src/libduckdb.dll .
200:            test/unittest.exe
201: 
202:   xcode-release:
203:     name: OSX Release
204:     runs-on: macos-latest
205:     needs: linux-debug
206: 
207:     env:
208:       BUILD_VISUALIZER: 1
209:       BUILD_ICU: 1
210:       BUILD_TPCH: 1
211:       BUILD_TPCDS: 1
212:       BUILD_FTS: 1
213:       BUILD_REST: 1
214:       BUILD_JDBC: 1
215:       BUILD_HTTPFS: 1
216:       OPENSSL_ROOT_DIR: /usr/local/opt/openssl/
217: 
218: 
219:     steps:
220:     - uses: actions/checkout@v2
221:       with:
222:         fetch-depth: 0
223: 
224:     - uses: actions/setup-python@v2
225:       with:
226:         python-version: '3.7'
227: 
228:     - name: Build
229:       run: make
230: 
231:     - name: Unit Test
232:       run: make allunit
233: 
234:     - name: Tools Tests
235:       run: |
236:         python tools/shell/shell-test.py build/release/duckdb
237:         java -cp build/release/tools/jdbc/duckdb_jdbc.jar org.duckdb.test.TestDuckDBJDBC
238: 
239:     - name: Examples
240:       run: |
241:         (cd examples/embedded-c; make)
242:         (cd examples/embedded-c++; make)
243:         (cd examples/jdbc; make; make maven)
244: 
245:     - name: Deploy
246:       run: |
247:         python scripts/amalgamation.py
248:         zip -j duckdb_cli-osx-amd64.zip build/release/duckdb
249:         zip -j libduckdb-osx-amd64.zip build/release/src/libduckdb*.dylib src/amalgamation/duckdb.hpp src/include/duckdb.h
250:         python scripts/asset-upload-gha.py libduckdb-osx-amd64.zip duckdb_cli-osx-amd64.zip duckdb_jdbc-osx-amd64.jar=build/release/tools/jdbc/duckdb_jdbc.jar
251: 
252:     - uses: actions/upload-artifact@v2
253:       with:
254:         name: duckdb-binaries-osx
255:         path: |
256:           libduckdb-osx-amd64.zip
257:           duckdb_cli-osx-amd64.zip
258:           build/release/tools/jdbc/duckdb_jdbc.jar
259: 
260: 
261:   xcode-debug:
262:     name: OSX Debug
263:     runs-on: macos-latest
264:     needs: linux-debug
265: 
266:     env:
267:       TREAT_WARNINGS_AS_ERRORS: 1
268: 
269:     steps:
270:     - uses: actions/checkout@v2
271:       with:
272:         fetch-depth: 0
273: 
274:     - name: Build
275:       run: make debug
276: 
277:     - name: Test
278:       run: make unittestci
279: 
280:     - name: Amalgamation
281:       run: |
282:         python scripts/amalgamation.py --extended
283:         python scripts/parquet_amalgamation.py
284:         cd src/amalgamation
285:         clang++ -std=c++11 -O0 -Wall -Werror -emit-llvm -S duckdb.cpp parquet-amalgamation.cpp
286:         clang++ -DNDEBUG -O0 -std=c++11 -Wall -Werror -emit-llvm -S duckdb.cpp parquet-amalgamation.cpp
287:         clang++ -DDEBUG -O0 -std=c++11 -Wall -Werror -emit-llvm -S duckdb.cpp parquet-amalgamation.cpp
288: 
289:   linux-release-64:
290:     name: Linux (64 Bit)
291:     runs-on: ubuntu-16.04
292:     needs: linux-debug
293: 
294:     env:
295:       GEN: ninja
296:       BUILD_VISUALIZER: 1
297:       BUILD_BENCHMARK: 1
298:       BUILD_ICU: 1
299:       BUILD_TPCH: 1
300:       BUILD_TPCDS: 1
301:       BUILD_FTS: 1
302:       BUILD_REST: 1
303:       BUILD_JDBC: 1
304:       BUILD_HTTPFS: 1
305:       TREAT_WARNINGS_AS_ERRORS: 1
306:       FORCE_WARN_UNUSED: 1
307: 
308:     steps:
309:     - uses: actions/checkout@v2
310:       with:
311:         fetch-depth: 0
312: 
313:     - uses: actions/setup-python@v2
314:       with:
315:         python-version: '3.7'
316: 
317:     - name: Install
318:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
319: 
320:     - name: Build
321:       run: STATIC_LIBCPP=1 make
322: 
323:     - name: Test
324:       run: make allunit
325: 
326:     - name: Symbol Leakage Test
327:       run: python scripts/exported_symbols_check.py build/release/src/libduckdb*.so
328: 
329:     - name: Tools Tests
330:       run: |
331:         python tools/shell/shell-test.py build/release/duckdb
332:         pip install requests
333:         python tools/rest/test_the_rest.py build/release/tools/rest
334:         java -cp build/release/tools/jdbc/duckdb_jdbc.jar org.duckdb.test.TestDuckDBJDBC
335: 
336:     - name: Examples
337:       run: |
338:         (cd examples/embedded-c; make)
339:         (cd examples/embedded-c++; make)
340:         (cd examples/jdbc; make; make maven)
341:         build/release/benchmark/benchmark_runner benchmark/tpch/sf1/q01.benchmark
342: 
343:     - name: Deploy
344:       run: |
345:         python scripts/amalgamation.py
346:         zip -j duckdb_cli-linux-amd64.zip build/release/duckdb
347:         zip -j libduckdb-linux-amd64.zip build/release/src/libduckdb*.so src/amalgamation/duckdb.hpp src/include/duckdb.h
348:         zip -j libduckdb-src.zip src/amalgamation/duckdb.hpp src/amalgamation/duckdb.cpp src/include/duckdb.h
349:         zip -j duckdb_rest-linux-amd64.zip build/release/tools/rest/duckdb_rest_server
350:         python scripts/asset-upload-gha.py libduckdb-src.zip libduckdb-linux-amd64.zip duckdb_cli-linux-amd64.zip duckdb_rest-linux-amd64.zip duckdb_jdbc-linux-amd64.jar=build/release/tools/jdbc/duckdb_jdbc.jar
351: 
352:     - uses: actions/upload-artifact@v2
353:       with:
354:         name: duckdb-binaries-linux
355:         path: |
356:           libduckdb-linux-amd64.zip
357:           duckdb_cli-linux-amd64.zip
358:           build/release/tools/jdbc/duckdb_jdbc.jar
359: 
360: 
361: 
362:   linux-release-32:
363:     name: Linux (32 Bit)
364:     runs-on: ubuntu-16.04
365:     needs: linux-debug
366: 
367:     env:
368:       GEN: ninja
369: 
370:     steps:
371:     - uses: actions/checkout@v2
372:       with:
373:         fetch-depth: 0
374: 
375:     - uses: actions/setup-python@v2
376:       with:
377:         python-version: '3.7'
378: 
379:     - name: Install
380:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build libc6-dev-i386 gcc-multilib g++-multilib lib32readline6-dev
381: 
382:     - name: Build
383:       run: |
384:         mkdir -p build/release
385:         (cd build/release && cmake -DSTATIC_LIBCPP=1 -DJDBC_DRIVER=1 -DBUILD_ICU_EXTENSION=1 -DBUILD_PARQUET_EXTENSION=1 -DBUILD_FTS_EXTENSION=1 -DFORCE_32_BIT=1 -DCMAKE_BUILD_TYPE=Release ../.. && cmake --build .)
386: 
387:     - name: Test
388:       run: build/release/test/unittest "*"
389: 
390:     - name: Deploy
391:       run: |
392:         python scripts/amalgamation.py
393:         zip -j duckdb_cli-linux-i386.zip build/release/duckdb
394:         zip -j libduckdb-linux-i386.zip build/release/src/libduckdb*.so src/amalgamation/duckdb.hpp src/include/duckdb.h
395:         python scripts/asset-upload-gha.py libduckdb-linux-i386.zip duckdb_cli-linux-i386.zip duckdb_jdbc-linux-i386.jar=build/release/tools/jdbc/duckdb_jdbc.jar
396: 
397:     - uses: actions/upload-artifact@v2
398:       with:
399:         name: duckdb-binaries-linux
400:         path: |
401:           libduckdb-linux-i386.zip
402:           duckdb_cli-linux-i386.zip
403:           build/release/tools/jdbc/duckdb_jdbc.jar
404: 
405: 
406:   linux-rpi:
407:     name: Linux (Raspberry Pi)
408:     runs-on: ubuntu-20.04
409:     needs: linux-debug
410: 
411:     steps:
412:     - uses: actions/checkout@v2
413:       with:
414:         fetch-depth: 0
415: 
416:     - uses: actions/setup-python@v2
417:       with:
418:         python-version: '3.7'
419: 
420:     - name: Install
421:       run: |
422:         sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
423:         git clone https://github.com/raspberrypi/tools --depth=1 rpi-tools
424: 
425:     - name: Build
426:       run: |
427:         export TOOLCHAIN=`pwd`/rpi-tools
428:         mkdir -p build/release
429:         cd build/release
430:         cmake -G Ninja -DBUILD_TPCH_EXTENSION=1 -DBUILD_TPCDS_EXTENSION=1 -DDUCKDB_RPI_TOOLCHAIN_PREFIX=$TOOLCHAIN -DBUILD_UNITTESTS=0 -DCMAKE_TOOLCHAIN_FILE=../../scripts/raspberry-pi-cmake-toolchain.cmake ../../
431:         cmake --build .
432:         file duckdb
433: 
434:     - name: Deploy
435:       run: |
436:         python scripts/amalgamation.py
437:         zip -j duckdb_cli-linux-rpi.zip build/release/duckdb
438:         zip -j libduckdb-linux-rpi.zip build/release/src/libduckdb*.so src/amalgamation/duckdb.hpp src/include/duckdb.h
439:         python scripts/asset-upload-gha.py libduckdb-linux-rpi.zip duckdb_cli-linux-rpi.zip
440: 
441:     - uses: actions/upload-artifact@v2
442:       with:
443:         name: duckdb-binaries-rpi
444:         path: |
445:           libduckdb-linux-rpi.zip
446:           duckdb_cli-linux-rpi.zip
447: 
448: 
449:   old-gcc:
450:     name: GCC 4.8
451:     runs-on: ubuntu-18.04
452:     needs: linux-debug
453: 
454:     env:
455:       CC: gcc-4.8
456:       CXX: g++-4.8
457: 
458:     steps:
459:     - uses: actions/checkout@v2
460:       with:
461:         fetch-depth: 0
462: 
463:     - uses: actions/setup-python@v2
464:       with:
465:         python-version: '3.7'
466: 
467:     - name: Install
468:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq g++-4.8 binutils
469: 
470:     - name: Build
471:       run: make release
472: 
473:     - name: Test
474:       run: make allunit
475: 
476: 
477:   centos:
478:     name: CentOS 7
479:     runs-on: ubuntu-latest
480:     container: centos:7
481:     needs: linux-debug
482: 
483:     steps:
484:     - uses: actions/checkout@v2
485:       with:
486:         fetch-depth: 0
487: 
488:     - name: Install
489:       run: yum install -y gcc gcc-c++ git cmake make
490: 
491:     - name: Build
492:       run: make release
493: 
494:     - name: Test
495:       run: ./build/release/test/unittest
496: 
497: 
498:   release-assert:
499:     name: Release Assertions
500:     runs-on: ubuntu-20.04
501:     needs: linux-debug
502: 
503:     env:
504:       CC: gcc-10
505:       CXX: g++-10
506:       GEN: ninja
507:       BUILD_ICU: 1
508:       BUILD_TPCH: 1
509:       BUILD_TPCDS: 1
510:       BUILD_FTS: 1
511:       BUILD_VISUALIZER: 1
512:       DISABLE_SANITIZER: 1
513: 
514:     steps:
515:     - uses: actions/checkout@v2
516:       with:
517:         fetch-depth: 0
518: 
519:     - name: Install
520:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
521: 
522:     - name: Build
523:       run: make relassert
524: 
525:     - name: Test
526:       run: |
527:           python3 scripts/run_tests_one_by_one.py build/relassert/test/unittest "*"
528: 
529:   force-storage:
530:     name: Force Storage
531:     runs-on: ubuntu-20.04
532:     needs: linux-debug
533: 
534:     env:
535:       CC: gcc-10
536:       CXX: g++-10
537:       GEN: ninja
538:       BUILD_ICU: 1
539:       BUILD_PARQUET: 1
540:       BUILD_TPCH: 1
541:       BUILD_TPCDS: 1
542:       BUILD_FTS: 1
543:       BUILD_VISUALIZER: 1
544: 
545:     steps:
546:     - uses: actions/checkout@v2
547:       with:
548:         fetch-depth: 0
549: 
550:     - name: Install
551:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
552: 
553:     - name: Build
554:       run: make reldebug
555: 
556:     - name: Test
557:       run: build/reldebug/test/unittest "*" --force-storage
558: 
559: 
560:   threadsan:
561:     name: Thread Sanitizer
562:     runs-on: ubuntu-20.04
563:     needs: linux-debug
564: 
565:     env:
566:       CC: gcc-10
567:       CXX: g++-10
568:       GEN: ninja
569:       BUILD_ICU: 1
570:       BUILD_TPCH: 1
571:       BUILD_TPCDS: 1
572:       BUILD_FTS: 1
573:       BUILD_VISUALIZER: 1
574:       TSAN_OPTIONS: suppressions=.sanitizer-thread-suppressions.txt
575: 
576:     steps:
577:     - uses: actions/checkout@v2
578:       with:
579:         fetch-depth: 0
580: 
581:     - name: Install
582:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
583: 
584:     - name: Build
585:       run: THREADSAN=1 make reldebug
586: 
587:     - name: Test
588:       run: |
589:           python3 scripts/run_tests_one_by_one.py build/reldebug/test/unittest
590:           python3 scripts/run_tests_one_by_one.py build/reldebug/test/unittest "[intraquery]"
591:           python3 scripts/run_tests_one_by_one.py build/reldebug/test/unittest "[interquery]"
592:           python3 scripts/run_tests_one_by_one.py build/reldebug/test/unittest "[detailed_profiler]"
593:           python3 scripts/run_tests_one_by_one.py build/reldebug/test/unittest test/sql/tpch/tpch_sf01.test_slow
594: 
595:   valgrind:
596:     name: Valgrind
597:     runs-on: ubuntu-20.04
598:     needs: linux-debug
599: 
600:     env:
601:       CC: gcc-10
602:       CXX: g++-10
603:       DISABLE_SANITIZER: 1
604:       GEN: ninja
605: 
606:     steps:
607:     - uses: actions/checkout@v2
608:       with:
609:         fetch-depth: 0
610: 
611:     - name: Install
612:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build valgrind
613: 
614:     - name: Build
615:       run: make debug
616: 
617:     - name: Test
618:       run: valgrind ./build/debug/test/unittest test/sql/tpch/tpch_sf001.test_slow
619: 
620:   codecov:
621:     name: CodeCov
622:     runs-on: ubuntu-20.04
623:     needs: linux-debug
624:     env:
625:       GEN: ninja
626:     steps:
627:       - uses: actions/checkout@v2
628:         with:
629:           fetch-depth: 0
630: 
631:       - name: Install
632:         run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build lcov
633: 
634:       - name: Set up Python 3.9
635:         uses: actions/setup-python@v2
636:         with:
637:           python-version: '3.9'
638: 
639:       - name: Before Install
640:         run: |
641:           pip install requests
642:           sudo apt-get install g++
643: 
644:       - name: Coverage Reset
645:         run: |
646:           lcov --config-file .github/workflows/lcovrc --zerocounters --directory .
647:           lcov --config-file .github/workflows/lcovrc --capture --initial --directory . --base-directory . --no-external --output-file coverage.info
648: 
649:       - name: Run Tests
650:         run: |
651:           mkdir -p build/coverage
652:           (cd build/coverage && cmake -E env CXXFLAGS="--coverage" cmake -DBUILD_ARROW_ABI_TEST=1 -DBUILD_PARQUET_EXTENSION=1 -DENABLE_SANITIZER=0 -DCMAKE_BUILD_TYPE=Debug ../.. && make)
653:           build/coverage/test/unittest
654:           build/coverage/test/unittest "[intraquery]"
655:           build/coverage/test/unittest "[interquery]"
656:           build/coverage/test/unittest "[coverage]"
657:           build/coverage/test/unittest "[detailed_profiler]"
658:           build/coverage/test/unittest "[tpch]"
659:           build/coverage/tools/sqlite3_api_wrapper/test_sqlite3_api_wrapper
660:           python tools/shell/shell-test.py build/coverage/duckdb
661: 
662:       - name: Generate Coverage
663:         run: |
664:           lcov --config-file .github/workflows/lcovrc --directory . --base-directory . --no-external --capture --output-file coverage.info
665:           lcov --config-file .github/workflows/lcovrc --remove coverage.info '/usr*' '*/cl.hpp' '*/tools/*' '*/benchmark/*' '*/examples/*' '*/third_party/*' '*/test/*' -o lcov.info
666: 
667:       - name: CodeCov Upload
668:         uses: codecov/codecov-action@v1
669:         with:
670:           files: lcov.info
671:           fail_ci_if_error: true
672: 
673:   vector-sizes:
674:     name: Vector Sizes
675:     runs-on: ubuntu-20.04
676:     needs: linux-debug
677: 
678:     env:
679:       CC: gcc-10
680:       CXX: g++-10
681: 
682:     steps:
683:     - uses: actions/checkout@v2
684:       with:
685:         fetch-depth: 0
686: 
687:     - uses: actions/setup-python@v2
688:       with:
689:         python-version: '3.7'
690: 
691:     - name: Test
692:       run: python scripts/test_vector_sizes.py
693: 
694: 
695:   sqllogic:
696:     name: Sqllogic tests
697:     runs-on: ubuntu-20.04
698:     needs: linux-debug
699: 
700:     env:
701:       CC: gcc-10
702:       CXX: g++-10
703: 
704:     steps:
705:     - uses: actions/checkout@v2
706:       with:
707:         fetch-depth: 0
708: 
709:     - name: Test
710:       run: make sqlite
711: 
712: 
713:   expanded:
714:     name: Expanded
715:     runs-on: ubuntu-20.04
716:     needs: linux-debug
717: 
718:     env:
719:       CC: gcc-10
720:       CXX: g++-10
721:       TREAT_WARNINGS_AS_ERRORS: 1
722:       DISABLE_UNITY: 1
723:       GEN: ninja
724: 
725:     steps:
726:     - uses: actions/checkout@v2
727:       with:
728:         fetch-depth: 0
729: 
730:     - name: Install
731:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
732: 
733:     - name: Build
734:       run: make debug
735: 
736: 
737:   sqlancer:
738:     name: SQLancer
739:     runs-on: ubuntu-20.04
740:     needs: linux-debug
741: 
742:     env:
743:       BUILD_JDBC: 1
744:       FORCE_QUERY_LOG: sqlancer_log.tmp
745:       GEN: ninja
746: 
747:     steps:
748:     - uses: actions/checkout@v2
749:       with:
750:         fetch-depth: 0
751: 
752:     - name: Install
753:       run: |
754:         sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
755:         git clone https://github.com/hannesmuehleisen/sqlancer
756:         cd sqlancer
757:         git checkout persistent
758:         mvn package -q -DskipTests
759: 
760:     - name: Build
761:       run: make reldebug
762: 
763:     - name: Test
764:       run: |
765:         cp build/reldebug/tools/jdbc/duckdb_jdbc.jar sqlancer/target/lib/duckdb_jdbc-*.jar
766:         python3 scripts/run_sqlancer.py
767: 
768: 
769:   sqlancer_persistent:
770:     name: SQLancer (Persistent)
771:     runs-on: ubuntu-20.04
772:     needs: linux-debug
773: 
774:     env:
775:       BUILD_JDBC: 1
776:       FORCE_QUERY_LOG: sqlancer_log.tmp
777:       GEN: ninja
778: 
779:     steps:
780:     - uses: actions/checkout@v2
781:       with:
782:         fetch-depth: 0
783: 
784:     - name: Install
785:       run: |
786:         sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
787:         git clone https://github.com/hannesmuehleisen/sqlancer
788:         cd sqlancer
789:         git checkout persistent
790:         mvn package -q -DskipTests
791: 
792:     - name: Build
793:       run: make reldebug
794: 
795:     - name: Test
796:       run: |
797:         cp build/reldebug/tools/jdbc/duckdb_jdbc.jar sqlancer/target/lib/duckdb_jdbc-*.jar
798:         python3 scripts/run_sqlancer.py --persistent
799: 
800: 
801:   jdbc:
802:     name: JDBC Compliance
803:     runs-on: ubuntu-18.04
804:     needs: linux-debug
805: 
806:     env:
807:       CC: gcc-10
808:       CXX: g++-10
809:       BUILD_JDBC: 1
810:       GEN: ninja
811: 
812:     steps:
813:     - uses: actions/checkout@v2
814:       with:
815:         fetch-depth: 0
816: 
817:     - name: Install
818:       run: |
819:         sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
820:         git clone https://github.com/cwida/jdbccts.git
821: 
822:     - name: Build
823:       run: make release
824: 
825:     - name: Test
826:       run: (cd jdbccts && make DUCKDB_JAR=../build/release/tools/jdbc/duckdb_jdbc.jar test)
827: 
828: 
829:   odbc:
830:     name: ODBC
831:     runs-on: ubuntu-20.04
832:     needs: linux-debug
833: 
834:     env:
835:       BUILD_ODBC: 1
836:       GEN: ninja
837: 
838:     steps:
839:     - uses: actions/checkout@v2
840:       with:
841:         fetch-depth: 0
842: 
843:     - uses: actions/setup-python@v2
844:       with:
845:         python-version: '3.7'
846: 
847:     - name: Dependencies
848:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build unixodbc-dev
849: 
850: 
851:     - name: Install nanodbc
852:       run: |
853:         wget https://github.com/nanodbc/nanodbc/archive/refs/tags/v2.13.0.tar.gz -O nanodbc.tgz
854:         (mkdir nanodbc && tar xvf nanodbc.tgz -C nanodbc --strip-components=1 && cd nanodbc && sed -i -e "s/set(test_list/set(test_list odbc/" test/CMakeLists.txt && mkdir build && cd build && cmake -DNANODBC_DISABLE_TESTS=OFF .. && cmake --build .)
855: 
856:     - name: Install psqlodbc
857:       run: |
858:         git clone https://github.com/Mytherin/psqlodbc.git
859:         (cd psqlodbc && make debug)
860: 
861:     - name: Build
862:       run: DISABLE_SANITIZER=1 make debug
863: 
864:     # - name: Test nanodbc
865:     #   run: NANODBC_TEST_CONNSTR_ODBC="DRIVER=./build/debug/tools/odbc/libduckdb_odbc.so" ./nanodbc/build/test/odbc_tests test_simple
866: 
867:     - name: Test psqlodbc
868:       run: |
869:         echo -e "[ODBC]\nTrace = yes\nTraceFile = /tmp/odbctrace\n\n[DuckDB Driver]\nDriver = "`pwd`"/build/debug/tools/odbc/libduckdb_odbc.so" > ~/.odbcinst.ini
870:         echo -e "[DuckDB]\nDriver = DuckDB Driver\nDatabase=:memory:\n" > ~/.odbc.ini
871:         cd psqlodbc
872:         export PSQLODBC_TEST_DSN="DuckDB"
873:         # creating contrib_regression database used by some tests
874:         (./build/debug/reset-db < sampletables.sql) || (cat /tmp/odbctrace; exit 1)
875:         # running supported tests
876:         (./build/debug/psql_odbc_test -f ../tools/odbc/supported_tests) || (cat /tmp/odbctrace; exit 1)
877: 
878:     - name: Test isql
879:       run: |
880:         echo -e "[ODBC]\nTrace = yes\nTraceFile = /tmp/odbctrace\n\n[DuckDB Driver]\nDriver = "`pwd`"/build/debug/tools/odbc/libduckdb_odbc.so" > ~/.odbcinst.ini
881:         echo -e "[DuckDB]\nDriver = DuckDB Driver\nDatabase=test.db\n" > ~/.odbc.ini
882:         export ASAN_OPTIONS=verify_asan_link_order=0
883:         python tools/odbc/test/isql-test.py isql
884:         if [[ $? != 0 ]]; then exit 1; fi
885:         # running isql with the option -e
886:         rm test.db && python tools/odbc/test/isql-test.py isql -e
887:         if [[ $? != 0 ]]; then exit 1; fi
888: 
889:   linux-python3:
890:     name: Python 3 Linux
891:     runs-on: ubuntu-20.04
892:     needs: linux-debug
893: 
894:     env:
895:       CIBW_BUILD: 'cp36-* cp37-* cp38-* cp39-*'
896:       CIBW_BEFORE_BUILD: 'pip install --prefer-binary "pandas>=0.24" "pytest>=4.3"'
897:       CIBW_TEST_REQUIRES: 'pytest'
898:       CIBW_BEFORE_TEST: 'pip install --prefer-binary "pandas>=0.24" && pip install --prefer-binary "requests>=2.26" && (pip install --extra-index-url https://pypi.fury.io/arrow-nightlies/ --prefer-binary --pre pyarrow || true)'
899:       CIBW_TEST_COMMAND: 'python -m pytest {project}/tests'
900:       SETUPTOOLS_SCM_NO_LOCAL: 'yes'
901:       TWINE_USERNAME: 'hfmuehleisen'
902: 
903:     steps:
904:     - uses: actions/checkout@v2
905:       with:
906:         fetch-depth: 0
907: 
908:     - uses: actions/setup-python@v2
909:       with:
910:         python-version: '3.7'
911: 
912:     - name: Install
913:       run: pip install cibuildwheel twine
914: 
915:     - name: Build
916:       run: |
917:         cd tools/pythonpkg
918:         python setup.py sdist
919:         mkdir duckdb_tarball && tar xvf dist/duckdb-*.tar.gz --strip-components=1 -C duckdb_tarball
920:         cibuildwheel --output-dir wheelhouse duckdb_tarball
921: 
922:     - name: Deploy
923:       run: |
924:         python scripts/asset-upload-gha.py duckdb_python_src.tar.gz=tools/pythonpkg/dist/duckdb-*.tar.gz
925:         if [[ "$GITHUB_REF" =~ ^(refs/heads/master|refs/tags/v.+)$ ]] ; then
926:           twine upload --non-interactive --disable-progress-bar --skip-existing tools/pythonpkg/wheelhouse/*.whl tools/pythonpkg/dist/duckdb-*.tar.gz
927:         fi
928: 
929:   linux-python3-httpfs:
930:     name: Python 3 Linux with HTTPFS support
931:     runs-on: ubuntu-20.04
932:     needs: linux-debug
933: 
934:     env:
935:       CIBW_BUILD: 'cp36-* cp37-* cp38-* cp39-*'
936:       CIBW_BEFORE_BUILD: 'yum install -y openssl-devel && pip install --prefer-binary "pandas>=0.24" "pytest>=4.3"'
937:       CIBW_TEST_REQUIRES: 'pytest'
938:       CIBW_BEFORE_TEST: 'yum install -y openssl && pip install --prefer-binary "pandas>=0.24"  && pip install --prefer-binary "requests>=2.26" && (pip install --extra-index-url https://pypi.fury.io/arrow-nightlies/ --prefer-binary --pre pyarrow || true)'
939:       CIBW_TEST_COMMAND: 'python -m pytest {project}/tests'
940:       CIBW_ENVIRONMENT: 'BUILD_HTTPFS=1'
941:       SETUPTOOLS_SCM_NO_LOCAL: 'yes'
942:       TWINE_USERNAME: 'hfmuehleisen'
943: 
944:     steps:
945:       - uses: actions/checkout@v2
946:         with:
947:           fetch-depth: 0
948: 
949:       - uses: actions/setup-python@v2
950:         with:
951:           python-version: '3.7'
952: 
953:       - name: Install
954:         run: pip install cibuildwheel twine
955: 
956:       - name: Build
957:         run: |
958:           cd tools/pythonpkg
959:           BUILD_HTTPFS=1 python setup.py sdist
960:           mkdir duckdb_tarball && tar xvf dist/duckdb-*.tar.gz --strip-components=1 -C duckdb_tarball
961:           cibuildwheel --output-dir wheelhouse duckdb_tarball
962: 
963:   osx-python3:
964:     name: Python 3 OSX
965:     runs-on: macos-latest
966:     needs: linux-debug
967: 
968:     env:
969:       CIBW_BUILD: 'cp36-* cp37-* cp38-* cp39-*'
970:       CIBW_BEFORE_BUILD: 'pip install --prefer-binary "pandas>=0.24" "pytest>=4.3"'
971:       CIBW_TEST_REQUIRES: 'pytest'
972:       CIBW_BEFORE_TEST: 'pip install --prefer-binary "pandas>=0.24" "requests>=2.26" && (pip install --extra-index-url https://pypi.fury.io/arrow-nightlies/ --prefer-binary --pre pyarrow || true)'
973:       CIBW_TEST_COMMAND: 'python -m pytest {project}/tests'
974:       CIBW_ARCHS_MACOS: 'x86_64 universal2 arm64'
975:       SETUPTOOLS_SCM_NO_LOCAL: 'yes'
976:       TWINE_USERNAME: 'hfmuehleisen'
977: 
978:     steps:
979:     - uses: actions/checkout@v2
980:       with:
981:         fetch-depth: 0
982: 
983:     - uses: actions/setup-python@v2
984:       with:
985:         python-version: '3.7'
986: 
987:     - name: Install
988:       run: pip install cibuildwheel twine
989: 
990:     - name: Build
991:       run: |
992:         cd tools/pythonpkg
993:         python setup.py sdist
994:         mkdir duckdb_tarball && tar xvf dist/duckdb-*.tar.gz --strip-components=1 -C duckdb_tarball
995:         cibuildwheel --output-dir wheelhouse duckdb_tarball
996: 
997:     - name: Deploy
998:       run: |
999:         if [[ "$GITHUB_REF" =~ ^(refs/heads/master|refs/tags/v.+)$ ]] ; then
1000:           twine upload --non-interactive --disable-progress-bar --skip-existing tools/pythonpkg/wheelhouse/*.whl
1001:         fi
1002: 
1003:   win-python3:
1004:     name: Python 3 Windows
1005:     runs-on: windows-latest
1006:     needs: linux-debug
1007: 
1008:     env:
1009:       CIBW_BUILD: 'cp36-* cp37-* cp38-* cp39-*'
1010:       CIBW_BEFORE_BUILD: 'pip install --prefer-binary "pandas>=0.24" "pytest>=4.3"'
1011:       CIBW_TEST_REQUIRES: 'pytest'
1012:       CIBW_BEFORE_TEST: 'pip install --prefer-binary "pandas>=0.24" '
1013:       CIBW_TEST_COMMAND: 'python -m pytest {project}/tests'
1014:       SETUPTOOLS_SCM_NO_LOCAL: 'yes'
1015:       TWINE_USERNAME: 'hfmuehleisen'
1016: 
1017:     steps:
1018:     - uses: actions/checkout@v2
1019:       with:
1020:         fetch-depth: 0
1021: 
1022:     - uses: actions/setup-python@v2
1023:       with:
1024:         python-version: '3.7'
1025: 
1026:     - name: Install
1027:       run: pip install cibuildwheel twine
1028: 
1029:     - name: Build
1030:       run: |
1031:         cd tools/pythonpkg
1032:         python setup.py sdist
1033:         mkdir duckdb_tarball && tar xvf dist/duckdb-*.tar.gz --strip-components=1 -C duckdb_tarball
1034:         cibuildwheel --output-dir wheelhouse duckdb_tarball
1035: 
1036:     - name: Deploy
1037:       run: |
1038:         if [[ "$GITHUB_REF" =~ ^(refs/heads/master|refs/tags/v.+)$ ]] ; then
1039:           twine upload --non-interactive --disable-progress-bar --skip-existing tools/pythonpkg/wheelhouse/*.whl
1040:         fi
1041: 
1042: 
1043:   rstats-linux:
1044:     name: R Package Linux
1045:     runs-on: ubuntu-20.04
1046:     needs: linux-debug
1047: 
1048:     steps:
1049:     - uses: actions/checkout@v2
1050:       with:
1051:         fetch-depth: 0
1052: 
1053:     - uses: actions/setup-python@v2
1054:       with:
1055:         python-version: '3.7'
1056: 
1057:     - uses: r-lib/actions/setup-r@v1
1058:       with:
1059:         r-version: 'devel'
1060: 
1061:     - name: Install
1062:       run: |
1063:         sudo apt-get update -y -qq && sudo apt-get install -y -qq texlive-latex-base texlive-fonts-extra libcurl4-openssl-dev
1064:         mkdir -p $HOME/.R
1065:         R -f tools/rpkg/dependencies.R
1066: 
1067:     - name: Build
1068:       run: |
1069:         cd tools/rpkg
1070:         ./configure
1071:         R CMD build .
1072:         R CMD INSTALL duckdb_*.tar.gz
1073:         (cd tests && R -f testthat.R)
1074:         R CMD check --as-cran -o /tmp duckdb_*.tar.gz
1075:         if grep WARNING /tmp/duckdb.Rcheck/00check.log ; then exit 1; fi
1076: 
1077:     - name: Deploy
1078:       run: python scripts/asset-upload-gha.py duckdb_r_src.tar.gz=tools/rpkg/duckdb_*.tar.gz
1079: 
1080: 
1081:   rstats-windows:
1082:     name: R Package Windows
1083:     runs-on: windows-latest
1084:     needs: linux-debug
1085: 
1086:     steps:
1087:     - uses: actions/checkout@v2
1088:       with:
1089:         fetch-depth: 0
1090: 
1091:     - uses: actions/setup-python@v2
1092:       with:
1093:         python-version: '3.7'
1094: 
1095:     - uses: r-lib/actions/setup-r@v1
1096:       with:
1097:         r-version: 'devel'
1098: 
1099:     - name: Install
1100:       run: |
1101:         R -f tools/rpkg/dependencies.R
1102: 
1103:     - name: Build
1104:       run: |
1105:         cd tools/rpkg
1106:         ./configure
1107:         R CMD build .
1108:         R CMD INSTALL duckdb_*.tar.gz
1109:         (cd tests && R -f testthat.R)
1110:         R CMD check --as-cran --no-manual -o /tmp duckdb_*.tar.gz
1111:         if grep WARNING /tmp/duckdb.Rcheck/00check.log ; then exit 1; fi
1112: 
1113: 
1114:   linux-tarball-v2:
1115:     name: Python 2 Tarball
1116:     runs-on: ubuntu-20.04
1117:     needs: linux-debug
1118: 
1119:     steps:
1120:     - uses: actions/checkout@v2
1121:       with:
1122:         fetch-depth: 0
1123: 
1124:     - uses: actions/setup-python@v2
1125:       with:
1126:         python-version: '2.7'
1127: 
1128:     - name: Install
1129:       run: |
1130:         pip install setuptools-scm==5.0.2
1131:         pip install numpy pytest pandas
1132: 
1133:     - name: Build
1134:       run: |
1135:         python --version
1136:         git archive --format zip --output test-tarball.zip HEAD
1137:         mkdir duckdb-test-tarball
1138:         mv test-tarball.zip duckdb-test-tarball
1139:         cd duckdb-test-tarball
1140:         unzip test-tarball.zip
1141:         cd tools/pythonpkg
1142:         export SETUPTOOLS_SCM_PRETEND_VERSION=0.2.2
1143:         python setup.py install --user
1144:         (cd tests/ && python -m pytest)
1145: 
1146:   linux-tarball:
1147:     name: Python 3 Tarball
1148:     runs-on: ubuntu-20.04
1149:     needs: linux-debug
1150: 
1151:     steps:
1152:     - uses: actions/checkout@v2
1153:       with:
1154:         fetch-depth: 0
1155: 
1156:     - uses: actions/setup-python@v2
1157:       with:
1158:         python-version: '3.7'
1159: 
1160:     - name: Install
1161:       run: pip install numpy pytest pandas
1162: 
1163:     - name: Build
1164:       run: |
1165:         python --version
1166:         git archive --format zip --output test-tarball.zip HEAD
1167:         mkdir duckdb-test-tarball
1168:         mv test-tarball.zip duckdb-test-tarball
1169:         cd duckdb-test-tarball
1170:         unzip test-tarball.zip
1171:         cd tools/pythonpkg
1172:         export SETUPTOOLS_SCM_PRETEND_VERSION=0.2.2
1173:         python setup.py install --user
1174:         (cd tests/ && python -m pytest)
1175: 
1176:   linux-nodejs:
1177:     name: node.js Linux
1178:     runs-on: ubuntu-20.04
1179:     needs: linux-debug
1180: 
1181: 
1182:     steps:
1183:     - uses: actions/checkout@v2
1184:       with:
1185:         fetch-depth: 0
1186: 
1187:     - name: Setup
1188:       run: ./scripts/node_version.sh upload
1189: 
1190:     - name: Node 10
1191:       run: ./scripts/node_build.sh 10
1192: 
1193:     - name: Node 12
1194:       run: ./scripts/node_build.sh 12
1195: 
1196:     - name: Node 14
1197:       run: ./scripts/node_build.sh 14
1198: 
1199:     - name: Node 15
1200:       run: ./scripts/node_build.sh 15
1201: 
1202: 
1203:   osx-nodejs:
1204:     name: node.js OSX
1205:     runs-on: macos-latest
1206:     needs: linux-debug
1207: 
1208:     steps:
1209:     - uses: actions/checkout@v2
1210:       with:
1211:         fetch-depth: 0
1212: 
1213:     - name: Setup
1214:       run: ./scripts/node_version.sh
1215: 
1216:     - name: Node 10
1217:       run: ./scripts/node_build.sh 10
1218: 
1219:     - name: Node 12
1220:       run: ./scripts/node_build.sh 12
1221: 
1222:     - name: Node 14
1223:       run: ./scripts/node_build.sh 14
1224: 
1225:     - name: Node 15
1226:       run: ./scripts/node_build.sh 15
1227: 
1228:   linux-wasm-release:
1229:     name: WebAssembly Release
1230:     runs-on: ubuntu-20.04
1231:     needs: linux-debug
1232: 
1233:     steps:
1234:     - uses: actions/checkout@v2
1235:       with:
1236:         fetch-depth: 0
1237: 
1238:     - name: Build Amalgamation
1239:       run: python scripts/amalgamation.py
1240: 
1241:     - name: Setup
1242:       run: ./scripts/wasm_configure.sh
1243: 
1244:     - name: Build Library Module
1245:       run: ./scripts/wasm_build_lib.sh Release
1246: 
1247:     - name: Build Test Module
1248:       run: ./scripts/wasm_build_test.sh Release
1249: 
1250:     - name: Test WASM Module
1251:       run: node ./test/wasm/hello_wasm_test.js
1252: 
1253:     - name: Package
1254:       run: |
1255:         zip -j duckdb-wasm32-nothreads.zip ./.wasm/build/duckdb.wasm
1256:         python scripts/asset-upload-gha.py duckdb-wasm32-nothreads.zip
1257: 
1258:     - uses: actions/upload-artifact@v2
1259:       with:
1260:         name: duckdb-wasm32-nothreads
1261:         path: |
1262:           duckdb-wasm32-nothreads.zip
[end of .github/workflows/main.yml]
[start of src/include/duckdb/parser/qualified_name.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/parser/qualified_name.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/string.hpp"
12: #include "duckdb/common/exception.hpp"
13: 
14: namespace duckdb {
15: 
16: struct QualifiedName {
17: 	string schema;
18: 	string name;
19: 
20: 	//! Parse the (optional) schema and a name from a string in the format of e.g. "schema"."table"; if there is no dot
21: 	//! the schema will be set to INVALID_SCHEMA
22: 	static QualifiedName Parse(string input) {
23: 		string schema;
24: 		string name;
25: 		idx_t idx = 0;
26: 		vector<string> entries;
27: 		string entry;
28: 	normal:
29: 		// quote
30: 		for (; idx < input.size(); idx++) {
31: 			if (input[idx] == '"') {
32: 				idx++;
33: 				goto quoted;
34: 			} else if (input[idx] == '.') {
35: 				goto separator;
36: 			}
37: 			entry += input[idx];
38: 		}
39: 		goto end;
40: 	separator:
41: 		entries.push_back(entry);
42: 		entry = "";
43: 		idx++;
44: 		goto normal;
45: 	quoted:
46: 		// look for another quote
47: 		for (; idx < input.size(); idx++) {
48: 			if (input[idx] == '"') {
49: 				// unquote
50: 				idx++;
51: 				goto normal;
52: 			}
53: 			entry += input[idx];
54: 		}
55: 		throw ParserException("Unterminated quote in qualified name!");
56: 	end:
57: 		if (entries.size() == 0) {
58: 			schema = INVALID_SCHEMA;
59: 			name = entry;
60: 		} else if (entries.size() == 1) {
61: 			schema = entries[0];
62: 			name = entry;
63: 		} else {
64: 			throw ParserException("Expected schema.entry or entry: too many entries found");
65: 		}
66: 		return QualifiedName {schema, name};
67: 	}
68: };
69: 
70: struct QualifiedColumnName {
71: 	QualifiedColumnName() {
72: 	}
73: 	QualifiedColumnName(string table_p, string column_p) : table(move(table_p)), column(move(column_p)) {
74: 	}
75: 
76: 	string schema;
77: 	string table;
78: 	string column;
79: };
80: 
81: } // namespace duckdb
[end of src/include/duckdb/parser/qualified_name.hpp]
[start of tools/pythonpkg/src/pyrelation.cpp]
1: #include "duckdb_python/pyrelation.hpp"
2: #include "duckdb_python/pyconnection.hpp"
3: #include "duckdb_python/pyresult.hpp"
4: 
5: namespace duckdb {
6: 
7: void DuckDBPyRelation::Initialize(py::handle &m) {
8: 	py::class_<DuckDBPyRelation>(m, "DuckDBPyRelation")
9: 	    .def("filter", &DuckDBPyRelation::Filter, "Filter the relation object by the filter in filter_expr",
10: 	         py::arg("filter_expr"))
11: 	    .def("project", &DuckDBPyRelation::Project, "Project the relation object by the projection in project_expr",
12: 	         py::arg("project_expr"))
13: 	    .def("set_alias", &DuckDBPyRelation::Alias, "Rename the relation object to new alias", py::arg("alias"))
14: 	    .def("order", &DuckDBPyRelation::Order, "Reorder the relation object by order_expr", py::arg("order_expr"))
15: 	    .def("aggregate", &DuckDBPyRelation::Aggregate,
16: 	         "Compute the aggregate aggr_expr by the optional groups group_expr on the relation", py::arg("aggr_expr"),
17: 	         py::arg("group_expr") = "")
18: 	    .def("union", &DuckDBPyRelation::Union,
19: 	         "Create the set union of this relation object with another relation object in other_rel")
20: 	    .def("except_", &DuckDBPyRelation::Except,
21: 	         "Create the set except of this relation object with another relation object in other_rel",
22: 	         py::arg("other_rel"))
23: 	    .def("intersect", &DuckDBPyRelation::Intersect,
24: 	         "Create the set intersection of this relation object with another relation object in other_rel",
25: 	         py::arg("other_rel"))
26: 	    .def("join", &DuckDBPyRelation::Join,
27: 	         "Join the relation object with another relation object in other_rel using the join condition expression "
28: 	         "in join_condition",
29: 	         py::arg("other_rel"), py::arg("join_condition"))
30: 	    .def("distinct", &DuckDBPyRelation::Distinct, "Retrieve distinct rows from this relation object")
31: 	    .def("limit", &DuckDBPyRelation::Limit, "Only retrieve the first n rows from this relation object",
32: 	         py::arg("n"))
33: 	    .def("query", &DuckDBPyRelation::Query,
34: 	         "Run the given SQL query in sql_query on the view named virtual_table_name that refers to the relation "
35: 	         "object",
36: 	         py::arg("virtual_table_name"), py::arg("sql_query"))
37: 	    .def("execute", &DuckDBPyRelation::Execute, "Transform the relation into a result set")
38: 	    .def("write_csv", &DuckDBPyRelation::WriteCsv, "Write the relation object to a CSV file in file_name",
39: 	         py::arg("file_name"))
40: 	    .def("insert_into", &DuckDBPyRelation::InsertInto,
41: 	         "Inserts the relation object into an existing table named table_name", py::arg("table_name"))
42: 	    .def("insert", &DuckDBPyRelation::Insert, "Inserts the given values into the relation", py::arg("values"))
43: 	    .def("create", &DuckDBPyRelation::Create,
44: 	         "Creates a new table named table_name with the contents of the relation object", py::arg("table_name"))
45: 	    .def("create_view", &DuckDBPyRelation::CreateView,
46: 	         "Creates a view named view_name that refers to the relation object", py::arg("view_name"),
47: 	         py::arg("replace") = true)
48: 	    .def("to_arrow_table", &DuckDBPyRelation::ToArrowTable, "Transforms the relation object into a Arrow table")
49: 	    .def("arrow", &DuckDBPyRelation::ToArrowTable, "Transforms the relation object into a Arrow table")
50: 	    .def("to_df", &DuckDBPyRelation::ToDF, "Transforms the relation object into a Data.Frame")
51: 	    .def("df", &DuckDBPyRelation::ToDF, "Transforms the relation object into a Data.Frame")
52: 	    .def("fetchone", &DuckDBPyRelation::Fetchone, "Execute and fetch a single row")
53: 	    .def("fetchall", &DuckDBPyRelation::Fetchall, "Execute and fetch all rows")
54: 	    .def("map", &DuckDBPyRelation::Map, py::arg("map_function"), "Calls the passed function on the relation")
55: 	    .def("__str__", &DuckDBPyRelation::Print)
56: 	    .def("__repr__", &DuckDBPyRelation::Print)
57: 	    .def("__getattr__", &DuckDBPyRelation::Getattr);
58: }
59: 
60: DuckDBPyRelation::DuckDBPyRelation(shared_ptr<Relation> rel) : rel(move(rel)) {
61: }
62: 
63: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::FromDf(py::object df) {
64: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df));
65: }
66: 
67: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Values(py::object values) {
68: 	return DuckDBPyConnection::DefaultConnection()->Values(std::move(values));
69: }
70: 
71: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::FromQuery(const string &query, const string &alias) {
72: 	return DuckDBPyConnection::DefaultConnection()->FromQuery(query, alias);
73: }
74: 
75: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::FromCsvAuto(const string &filename) {
76: 	return DuckDBPyConnection::DefaultConnection()->FromCsvAuto(filename);
77: }
78: 
79: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::FromParquet(const string &filename) {
80: 	return DuckDBPyConnection::DefaultConnection()->FromParquet(filename);
81: }
82: 
83: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::FromArrowTable(py::object &table) {
84: 	return DuckDBPyConnection::DefaultConnection()->FromArrowTable(table);
85: }
86: 
87: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Project(const string &expr) {
88: 	return make_unique<DuckDBPyRelation>(rel->Project(expr));
89: }
90: 
91: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::ProjectDf(py::object df, const string &expr) {
92: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df))->Project(expr);
93: }
94: 
95: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Alias(const string &expr) {
96: 	return make_unique<DuckDBPyRelation>(rel->Alias(expr));
97: }
98: 
99: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::AliasDF(py::object df, const string &expr) {
100: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df))->Alias(expr);
101: }
102: 
103: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Filter(const string &expr) {
104: 	return make_unique<DuckDBPyRelation>(rel->Filter(expr));
105: }
106: 
107: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::FilterDf(py::object df, const string &expr) {
108: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df))->Filter(expr);
109: }
110: 
111: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Limit(int64_t n) {
112: 	return make_unique<DuckDBPyRelation>(rel->Limit(n));
113: }
114: 
115: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::LimitDF(py::object df, int64_t n) {
116: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df))->Limit(n);
117: }
118: 
119: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Order(const string &expr) {
120: 	return make_unique<DuckDBPyRelation>(rel->Order(expr));
121: }
122: 
123: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::OrderDf(py::object df, const string &expr) {
124: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df))->Order(expr);
125: }
126: 
127: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Aggregate(const string &expr, const string &groups) {
128: 	if (!groups.empty()) {
129: 		return make_unique<DuckDBPyRelation>(rel->Aggregate(expr, groups));
130: 	}
131: 	return make_unique<DuckDBPyRelation>(rel->Aggregate(expr));
132: }
133: 
134: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::AggregateDF(py::object df, const string &expr, const string &groups) {
135: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df))->Aggregate(expr, groups);
136: }
137: 
138: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Distinct() {
139: 	return make_unique<DuckDBPyRelation>(rel->Distinct());
140: }
141: 
142: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::DistinctDF(py::object df) {
143: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df))->Distinct();
144: }
145: 
146: py::object DuckDBPyRelation::ToDF() {
147: 	auto res = make_unique<DuckDBPyResult>();
148: 	{
149: 		py::gil_scoped_release release;
150: 		res->result = rel->Execute();
151: 	}
152: 	if (!res->result->success) {
153: 		throw std::runtime_error(res->result->error);
154: 	}
155: 	return res->FetchDF();
156: }
157: 
158: py::object DuckDBPyRelation::Fetchone() {
159: 	auto res = make_unique<DuckDBPyResult>();
160: 	{
161: 		py::gil_scoped_release release;
162: 		res->result = rel->Execute();
163: 	}
164: 	if (!res->result->success) {
165: 		throw std::runtime_error(res->result->error);
166: 	}
167: 	return res->Fetchone();
168: }
169: 
170: py::object DuckDBPyRelation::Fetchall() {
171: 	auto res = make_unique<DuckDBPyResult>();
172: 	{
173: 		py::gil_scoped_release release;
174: 		res->result = rel->Execute();
175: 	}
176: 	if (!res->result->success) {
177: 		throw std::runtime_error(res->result->error);
178: 	}
179: 	return res->Fetchall();
180: }
181: 
182: py::object DuckDBPyRelation::ToArrowTable() {
183: 	auto res = make_unique<DuckDBPyResult>();
184: 	{
185: 		py::gil_scoped_release release;
186: 		res->result = rel->Execute();
187: 	}
188: 	if (!res->result->success) {
189: 		throw std::runtime_error(res->result->error);
190: 	}
191: 	return res->FetchArrowTable();
192: }
193: 
194: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Union(DuckDBPyRelation *other) {
195: 	return make_unique<DuckDBPyRelation>(rel->Union(other->rel));
196: }
197: 
198: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Except(DuckDBPyRelation *other) {
199: 	return make_unique<DuckDBPyRelation>(rel->Except(other->rel));
200: }
201: 
202: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Intersect(DuckDBPyRelation *other) {
203: 	return make_unique<DuckDBPyRelation>(rel->Intersect(other->rel));
204: }
205: 
206: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Join(DuckDBPyRelation *other, const string &condition) {
207: 	return make_unique<DuckDBPyRelation>(rel->Join(other->rel, condition));
208: }
209: 
210: void DuckDBPyRelation::WriteCsv(const string &file) {
211: 	rel->WriteCSV(file);
212: }
213: 
214: void DuckDBPyRelation::WriteCsvDF(py::object df, const string &file) {
215: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df))->WriteCsv(file);
216: }
217: 
218: // should this return a rel with the new view?
219: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::CreateView(const string &view_name, bool replace) {
220: 	rel->CreateView(view_name, replace);
221: 	return make_unique<DuckDBPyRelation>(rel);
222: }
223: 
224: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::CreateViewDf(py::object df, const string &view_name, bool replace) {
225: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df))->CreateView(view_name, replace);
226: }
227: 
228: unique_ptr<DuckDBPyResult> DuckDBPyRelation::Query(const string &view_name, const string &sql_query) {
229: 	auto res = make_unique<DuckDBPyResult>();
230: 	res->result = rel->Query(view_name, sql_query);
231: 	if (!res->result->success) {
232: 		throw std::runtime_error(res->result->error);
233: 	}
234: 	return res;
235: }
236: 
237: unique_ptr<DuckDBPyResult> DuckDBPyRelation::Execute() {
238: 	auto res = make_unique<DuckDBPyResult>();
239: 	{
240: 		py::gil_scoped_release release;
241: 		res->result = rel->Execute();
242: 	}
243: 	if (!res->result->success) {
244: 		throw std::runtime_error(res->result->error);
245: 	}
246: 	return res;
247: }
248: 
249: unique_ptr<DuckDBPyResult> DuckDBPyRelation::QueryDF(py::object df, const string &view_name, const string &sql_query) {
250: 	return DuckDBPyConnection::DefaultConnection()->FromDF(std::move(df))->Query(view_name, sql_query);
251: }
252: 
253: void DuckDBPyRelation::InsertInto(const string &table) {
254: 	rel->Insert(table);
255: }
256: 
257: void DuckDBPyRelation::Insert(py::object params) {
258: 	vector<vector<Value>> values {DuckDBPyConnection::TransformPythonParamList(move(params))};
259: 	rel->Insert(values);
260: }
261: 
262: void DuckDBPyRelation::Create(const string &table) {
263: 	rel->Create(table);
264: }
265: 
266: unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Map(py::function fun) {
267: 	vector<Value> params;
268: 	params.emplace_back(Value::POINTER((uintptr_t)fun.ptr()));
269: 	auto res = make_unique<DuckDBPyRelation>(rel->TableFunction("python_map_function", params));
270: 	res->map_function = fun;
271: 	return res;
272: }
273: 
274: string DuckDBPyRelation::Print() {
275: 	std::string rel_res_string;
276: 	{
277: 		py::gil_scoped_release release;
278: 		rel_res_string = rel->Limit(10)->Execute()->ToString();
279: 	}
280: 
281: 	return rel->ToString() + "\n---------------------\n-- Result Preview  --\n---------------------\n" +
282: 	       rel_res_string + "\n";
283: }
284: 
285: py::object DuckDBPyRelation::Getattr(const py::str &key) {
286: 	auto key_s = key.cast<string>();
287: 	if (key_s == "alias") {
288: 		return py::str(string(rel->GetAlias()));
289: 	} else if (key_s == "type") {
290: 		return py::str(RelationTypeToString(rel->type));
291: 	} else if (key_s == "columns") {
292: 		py::list res;
293: 		for (auto &col : rel->Columns()) {
294: 			res.append(col.name);
295: 		}
296: 		return move(res);
297: 	} else if (key_s == "types" || key_s == "dtypes") {
298: 		py::list res;
299: 		for (auto &col : rel->Columns()) {
300: 			res.append(col.type.ToString());
301: 		}
302: 		return move(res);
303: 	}
304: 	return py::none();
305: }
306: 
307: } // namespace duckdb
[end of tools/pythonpkg/src/pyrelation.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: