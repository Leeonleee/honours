{
  "repo": "duckdb/duckdb",
  "pull_number": 7739,
  "instance_id": "duckdb__duckdb-7739",
  "issue_numbers": [
    "7734"
  ],
  "base_commit": "54a1955565ad8c6c0d9e3633b18a877ad9ed88be",
  "patch": "diff --git a/tools/pythonpkg/src/native/python_conversion.cpp b/tools/pythonpkg/src/native/python_conversion.cpp\nindex d2169e46c6bc..4983faa802e9 100644\n--- a/tools/pythonpkg/src/native/python_conversion.cpp\n+++ b/tools/pythonpkg/src/native/python_conversion.cpp\n@@ -67,9 +67,15 @@ bool DictionaryHasMapFormat(const PyDictionary &dict) {\n Value TransformDictionaryToStruct(const PyDictionary &dict, const LogicalType &target_type = LogicalType::UNKNOWN) {\n \tauto struct_keys = TransformStructKeys(dict.keys, dict.len, target_type);\n \n+\tbool struct_target = target_type.id() == LogicalTypeId::STRUCT;\n+\tif (struct_target) {\n+\t\tD_ASSERT(dict.len == StructType::GetChildCount(target_type));\n+\t}\n+\n \tchild_list_t<Value> struct_values;\n \tfor (idx_t i = 0; i < dict.len; i++) {\n-\t\tauto val = TransformPythonValue(dict.values.attr(\"__getitem__\")(i));\n+\t\tauto &child_type = struct_target ? StructType::GetChildType(target_type, i) : LogicalType::UNKNOWN;\n+\t\tauto val = TransformPythonValue(dict.values.attr(\"__getitem__\")(i), child_type);\n \t\tstruct_values.emplace_back(make_pair(std::move(struct_keys[i]), std::move(val)));\n \t}\n \treturn Value::STRUCT(std::move(struct_values));\n@@ -150,7 +156,7 @@ Value TransformDictionaryToMap(const PyDictionary &dict, const LogicalType &targ\n \treturn Value::MAP(ListType::GetChildType(map_type), std::move(elements));\n }\n \n-Value TransformListValue(py::handle ele) {\n+Value TransformListValue(py::handle ele, const LogicalType &target_type = LogicalType::UNKNOWN) {\n \tauto size = py::len(ele);\n \n \tif (size == 0) {\n@@ -160,9 +166,12 @@ Value TransformListValue(py::handle ele) {\n \tvector<Value> values;\n \tvalues.reserve(size);\n \n+\tbool list_target = target_type.id() == LogicalTypeId::LIST;\n+\n \tLogicalType element_type = LogicalType::SQLNULL;\n \tfor (idx_t i = 0; i < size; i++) {\n-\t\tValue new_value = TransformPythonValue(ele.attr(\"__getitem__\")(i));\n+\t\tauto &child_type = list_target ? ListType::GetChildType(target_type) : LogicalType::UNKNOWN;\n+\t\tValue new_value = TransformPythonValue(ele.attr(\"__getitem__\")(i), child_type);\n \t\telement_type = LogicalType::MaxLogicalType(element_type, new_value.type());\n \t\tvalues.push_back(std::move(new_value));\n \t}\n@@ -374,7 +383,7 @@ Value TransformPythonValue(py::handle ele, const LogicalType &target_type, bool\n \t\treturn Value::BLOB(const_data_ptr_t(ele_string.data()), ele_string.size());\n \t}\n \tcase PythonObjectType::List:\n-\t\treturn TransformListValue(ele);\n+\t\treturn TransformListValue(ele, target_type);\n \tcase PythonObjectType::Dict: {\n \t\tPyDictionary dict = PyDictionary(py::reinterpret_borrow<py::object>(ele));\n \t\tswitch (target_type.id()) {\ndiff --git a/tools/pythonpkg/src/pandas/analyzer.cpp b/tools/pythonpkg/src/pandas/analyzer.cpp\nindex 82ef3b2f25f4..26ffe5998544 100644\n--- a/tools/pythonpkg/src/pandas/analyzer.cpp\n+++ b/tools/pythonpkg/src/pandas/analyzer.cpp\n@@ -115,7 +115,21 @@ static bool UpgradeType(LogicalType &left, const LogicalType &right) {\n \t}\n \t// If struct constraints are not respected, left will be set to MAP\n \tif (left.id() == LogicalTypeId::STRUCT && right.id() == left.id()) {\n-\t\tif (!IsStructColumnValid(left, right)) {\n+\t\tbool valid_struct = IsStructColumnValid(left, right);\n+\t\tif (valid_struct) {\n+\t\t\tchild_list_t<LogicalType> children;\n+\t\t\tfor (idx_t i = 0; i < StructType::GetChildCount(right); i++) {\n+\t\t\t\tauto &right_child = StructType::GetChildType(right, i);\n+\t\t\t\tauto new_child = StructType::GetChildType(left, i);\n+\t\t\t\tauto child_name = StructType::GetChildName(left, i);\n+\t\t\t\tif (!UpgradeType(new_child, right_child)) {\n+\t\t\t\t\treturn false;\n+\t\t\t\t}\n+\t\t\t\tchildren.push_back(std::make_pair(child_name, new_child));\n+\t\t\t}\n+\t\t\tleft = LogicalType::STRUCT(std::move(children));\n+\t\t}\n+\t\tif (!valid_struct) {\n \t\t\tLogicalType map_value_type = LogicalType::SQLNULL;\n \t\t\tif (SatisfiesMapConstraints(left, right, map_value_type)) {\n \t\t\t\tleft = ConvertStructToMap(map_value_type);\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py b/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\nindex ac19221aa163..5193b967b542 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\n@@ -555,6 +555,84 @@ def test_mixed_object_types(self, pandas):\n         assert(res['nested'].dtype == np.dtype('object'))\n \n \n+    @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n+    def test_struct_deeply_nested_in_struct(self, pandas):\n+        x = pandas.DataFrame([\n+            {\n+                # STRUCT(b STRUCT(x VARCHAR, y VARCHAR))\n+                'a': {\n+                    'b': {\n+                        'x': 'A', \n+                        'y': 'B'\n+                    }\n+                }\n+            },\n+            {\n+                # STRUCT(b STRUCT(x VARCHAR))\n+                'a': {\n+                    'b': {\n+                        'x': 'A'\n+                    }\n+                }\n+            }\n+        ])\n+        # The dataframe has incompatible struct schemas in the nested child\n+        # This gets upgraded to STRUCT(b MAP(VARCHAR, VARCHAR))\n+        con = duckdb.connect()\n+        res = con.sql(\"select * from x\").fetchall()\n+        assert res == [\n+            (\n+                {\n+                    'b': {\n+                        'key': ['x', 'y'],\n+                        'value': ['A', 'B']\n+                    }\n+                },\n+            ),\n+            (\n+                {\n+                    'b': {\n+                        'key': ['x'],\n+                        'value': ['A']\n+                    }\n+                },\n+            )\n+        ]\n+\n+    @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n+    def test_struct_deeply_nested_in_list(self, pandas):\n+        x = pandas.DataFrame({'a': [\n+            [\n+                # STRUCT(x VARCHAR, y VARCHAR)[]\n+                {\n+                    'x': 'A', \n+                    'y': 'B'\n+                },\n+                # STRUCT(x VARCHAR)[]\n+                {\n+                    'x': 'A'\n+                }\n+            ]\n+        ]})\n+        # The dataframe has incompatible struct schemas in the nested child\n+        # This gets upgraded to STRUCT(b MAP(VARCHAR, VARCHAR))\n+        con = duckdb.connect()\n+        res = con.sql(\"select * from x\").fetchall()\n+        assert res == [\n+            (\n+                [\n+                    {\n+                        'key': ['x', 'y'],\n+                        'value': ['A', 'B']\n+                    },\n+                    {\n+                        'key': ['x'],\n+                        'value': ['A']\n+                    }\n+                ],\n+            )\n+        ]\n+\n     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n     def test_analyze_sample_too_small(self, pandas):\n         data = [1 for _ in range(9)] + [[1,2,3]] + [1 for _ in range(9991)]\n",
  "problem_statement": "\"duckdb.TypeMismatchException: Mismatch Type Error\" using dicts with different set of keys in python\n### What happens?\n\nIn python duckdb module raises exception if  different sets of keys are using on 3rd level of dict.\r\n\r\nThe error exists on pip duckdb versions: 0.6.0, 0.7.0, 0.8.0\r\nVersion 0.5.0 raises Segmentation fault\r\nVersion 0.4.0 works fine \r\n\n\n### To Reproduce\n\nThis code \r\n```python\r\nimport duckdb\r\nimport pandas as pd\r\ncon = duckdb.connect(database=':memory:')\r\n\r\nd = [\r\n    {'a': \r\n       {'b': {\r\n          'x': 'A', \r\n          'y': 'B'}}},\r\n    {'a': \r\n       {'b': {\r\n          'x': 'A'}}}\r\n]\r\n\r\ncon.register('tbl', pd.DataFrame(d))\r\ncon.execute(\"SELECT * FROM tbl\").fetchdf()\r\n```\r\nraises exception: \r\n`duckdb.TypeMismatchException: Mismatch Type Error: Type STRUCT(x VARCHAR) does not match with STRUCT(x VARCHAR, y VARCHAR). Cannot cast STRUCTs of different size`\n\n### OS:\n\nUbuntu 22.04\n\n### DuckDB Version:\n\n0.8.0\n\n### DuckDB Client:\n\npython\n\n### Full Name:\n\nAndrey Elkin\n\n### Affiliation:\n\nMindsdb\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "I assume 0.4.0 works fine because we didn't yet have `struct` support in DuckDB, so your data was probably stored as a varchar. I'd have to find a copy of 0.4.0 to confirm that. Once we had we started validating the input types, you started getting that error.\r\n\r\nI guess we need to infer the column as a union now @Tishj?\nYep, in 0.4.0:\r\n```python\r\n>>> con.execute(\"DESCRIBE SELECT * FROM tbl\").fetchall()\r\n[('a', 'VARCHAR', 'YES', None, None, None)]\r\n```\nStrange, for me result is different...\r\n```\r\n>>> con.execute(\"SELECT * FROM tbl\").fetchdf()\r\na\r\n0  {'b': {'x': 'A', 'y': 'B'}}\r\n1            {'b': {'x': 'A'}}\r\n>>> con.execute(\"SELECT * FROM tbl\").fetchall()\r\n[(\"{'b': {'x': 'A', 'y': 'B'}}\",), (\"{'b': {'x': 'A'}}\",)]\r\n>>> duckdb.__version__\r\n'0.4.0'\r\n```\nI was thinking we might need to accept casting struct A to struct B if the children of A are a subset of B, and populate the other children with NULL.\n> I assume 0.4.0 works fine because we didn't yet have `struct` support in DuckDB, so your data was probably stored as a varchar. I'd have to find a copy of 0.4.0 to confirm that. Once we had we started validating the input types, you started getting that error.\r\n> \r\n> I guess we need to infer the column as a union now @Tishj?\r\n\r\nI'm not sure I follow entirely, what would the inferred type be in this case?\n> Strange, for me result is different...\r\n> \r\n> ```\r\n> >>> con.execute(\"SELECT * FROM tbl\").fetchdf()\r\n> a\r\n> 0  {'b': {'x': 'A', 'y': 'B'}}\r\n> 1            {'b': {'x': 'A'}}\r\n> >>> con.execute(\"SELECT * FROM tbl\").fetchall()\r\n> [(\"{'b': {'x': 'A', 'y': 'B'}}\",), (\"{'b': {'x': 'A'}}\",)]\r\n> >>> duckdb.__version__\r\n> '0.4.0'\r\n> ```\r\n\r\nIt isn't different, you ran a different SQL query, and missing the `DESCRIBE`\n> > I assume 0.4.0 works fine because we didn't yet have `struct` support in DuckDB, so your data was probably stored as a varchar. I'd have to find a copy of 0.4.0 to confirm that. Once we had we started validating the input types, you started getting that error.\r\n> > I guess we need to infer the column as a union now @Tishj?\r\n> \r\n> I'm not sure I follow entirely, what would the inferred type be in this case?\r\n\r\nA union of the two struct types perhaps? Depends on whether that's preferable to simply combining the keys of both and leaving the missing ones null?\nMaybe this example is also related to this problem and can help somehow:\r\n```\r\nd=[\r\n    {'a': {'b': {'xxxx': 'A'}}},\r\n    {'a': {'b': {'yyyy': 'B'}}},\r\n]\r\ncon.register('tbl', pd.DataFrame(d))\r\ncon.execute(\"SELECT * FROM tbl\").fetchdf()\r\n```\r\ndifferent keys (xxxx, yyyy) on input become the same key on output\r\n```\r\na\r\n0  {'b': {'xxxx': 'A'}}\r\n1  {'b': {'xxxx': 'B'}}\r\n```\n> Maybe this example is also related to this problem and can help somehow:\r\n> \r\n> ```\r\n> d=[\r\n>     {'a': {'b': {'xxxx': 'A'}}},\r\n>     {'a': {'b': {'yyyy': 'B'}}},\r\n> ]\r\n> con.register('tbl', pd.DataFrame(d))\r\n> con.execute(\"SELECT * FROM tbl\").fetchdf()\r\n> ```\r\n> \r\n> different keys (xxxx, yyyy) on input become the same key on output\r\n> \r\n> ```\r\n> a\r\n> 0  {'b': {'xxxx': 'A'}}\r\n> 1  {'b': {'xxxx': 'B'}}\r\n> ```\r\n\r\nThis sounds more like https://github.com/duckdb/duckdb/issues/7303\n@Mause The union idea would cover more cases than my idea, but I'm not sure if implicitly creating a union is the most user friendly.\r\nI might be wrong but I think working with a union is still not as easy as a regular struct\n> @Mause The union idea would cover more cases than my idea, but I'm not sure if implicitly creating a union is the most user friendly.\n> I might be wrong but working with a union is still not as easy as a regular struct\n\nFair point - I'm not sure what the alternative solution would be though? Aside from not fixing this\nMytherin had a good idea, maybe we can turn this into a `MAP(VARCHAR, <combination_of_struct_child_types>)` if not all the structs children types can be combined into one, we might fall back to a `MAP(VARCHAR, UNION(..))` but I think I'll start of with just throwing in this case.\r\n\r\nAh actually, this is definitely a bug.\r\nWe have a check like this, but it's not recursive so because this happens in a nested structure we don't detect it on time\n```py\r\nimport duckdb\r\nimport pandas as pd\r\n\r\nd = [\r\n    {'a': \r\n       {'b': {\r\n          'x': 'A', \r\n          'y': 'B'}}},\r\n    {'a': \r\n       {'b': {\r\n          'x': 'A'}}}\r\n]\r\n\r\ndf = pd.DataFrame(d)\r\nduckdb.sql('select * from df').show()\r\n```\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                a                \u2502\r\n\u2502 struct(b map(varchar, varchar)) \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 {'b': {x=A, y=B}}               \u2502\r\n\u2502 {'b': {x=A}}                    \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```",
  "created_at": "2023-05-30T14:10:35Z"
}