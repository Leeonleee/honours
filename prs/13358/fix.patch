diff --git a/src/common/vector_operations/vector_copy.cpp b/src/common/vector_operations/vector_copy.cpp
index 7315a4e591dc..0880f23be632 100644
--- a/src/common/vector_operations/vector_copy.cpp
+++ b/src/common/vector_operations/vector_copy.cpp
@@ -35,10 +35,7 @@ static const ValidityMask &ExtractValidityMask(const Vector &v) {
 }
 
 void VectorOperations::Copy(const Vector &source_p, Vector &target, const SelectionVector &sel_p, idx_t source_count,
-                            idx_t source_offset, idx_t target_offset) {
-	D_ASSERT(source_offset <= source_count);
-	D_ASSERT(source_p.GetType() == target.GetType());
-	idx_t copy_count = source_count - source_offset;
+                            idx_t source_offset, idx_t target_offset, idx_t copy_count) {
 
 	SelectionVector owned_sel;
 	const SelectionVector *sel = &sel_p;
@@ -173,7 +170,7 @@ void VectorOperations::Copy(const Vector &source_p, Vector &target, const Select
 		D_ASSERT(source_children.size() == target_children.size());
 		for (idx_t i = 0; i < source_children.size(); i++) {
 			VectorOperations::Copy(*source_children[i], *target_children[i], sel_p, source_count, source_offset,
-			                       target_offset);
+			                       target_offset, copy_count);
 		}
 		break;
 	}
@@ -267,6 +264,14 @@ void VectorOperations::Copy(const Vector &source_p, Vector &target, const Select
 	}
 }
 
+void VectorOperations::Copy(const Vector &source_p, Vector &target, const SelectionVector &sel_p, idx_t source_count,
+                            idx_t source_offset, idx_t target_offset) {
+	D_ASSERT(source_offset <= source_count);
+	D_ASSERT(source_p.GetType() == target.GetType());
+	idx_t copy_count = source_count - source_offset;
+	VectorOperations::Copy(source_p, target, sel_p, source_count, source_offset, target_offset, copy_count);
+}
+
 void VectorOperations::Copy(const Vector &source, Vector &target, idx_t source_count, idx_t source_offset,
                             idx_t target_offset) {
 	VectorOperations::Copy(source, target, *FlatVector::IncrementalSelectionVector(), source_count, source_offset,
diff --git a/src/include/duckdb/common/vector_operations/vector_operations.hpp b/src/include/duckdb/common/vector_operations/vector_operations.hpp
index 514c703c9004..bd772fcad3ba 100644
--- a/src/include/duckdb/common/vector_operations/vector_operations.hpp
+++ b/src/include/duckdb/common/vector_operations/vector_operations.hpp
@@ -192,6 +192,8 @@ struct VectorOperations {
 	                 idx_t target_offset);
 	static void Copy(const Vector &source, Vector &target, const SelectionVector &sel, idx_t source_count,
 	                 idx_t source_offset, idx_t target_offset);
+	static void Copy(const Vector &source, Vector &target, const SelectionVector &sel, idx_t source_count,
+	                 idx_t source_offset, idx_t target_offset, idx_t copy_count);
 
 	// Copy the data of <source> to the target location, setting null values to
 	// NullValue<T>. Used to store data without separate NULL mask.
diff --git a/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp b/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp
index 4ab31a90ef23..6717648d0b03 100644
--- a/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp
+++ b/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp
@@ -79,7 +79,7 @@ template <class T>
 bool try_cast(const handle &object, T &result) {
 	try {
 		result = cast<T>(object);
-	} catch (cast_error &) {
+	} catch (pybind11::cast_error &) {
 		return false;
 	}
 	return true;
diff --git a/tools/pythonpkg/src/python_udf.cpp b/tools/pythonpkg/src/python_udf.cpp
index 53e3eb72c6c9..bca316f09e36 100644
--- a/tools/pythonpkg/src/python_udf.cpp
+++ b/tools/pythonpkg/src/python_udf.cpp
@@ -43,8 +43,7 @@ static py::object ConvertDataChunkToPyArrowTable(DataChunk &input, const ClientP
 	return pyarrow::ToArrowTable(types, names, ConvertToSingleBatch(types, names, input, options), options);
 }
 
-static void ConvertPyArrowToDataChunk(const py::object &table, Vector &out, ClientContext &context, idx_t count) {
-
+static void ConvertArrowTableToVector(const py::object &table, Vector &out, ClientContext &context, idx_t count) {
 	// Create the stream factory from the Table object
 	auto stream_factory = make_uniq<PythonTableArrowArrayStreamFactory>(table.ptr(), context.GetClientProperties());
 	auto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;
@@ -68,7 +67,7 @@ static void ConvertPyArrowToDataChunk(const py::object &table, Vector &out, Clie
 
 	TableFunctionRef empty;
 	TableFunction dummy_table_function;
-	dummy_table_function.name = "ConvertPyArrowToDataChunk";
+	dummy_table_function.name = "ConvertArrowTableToVector";
 	TableFunctionBindInput bind_input(children, named_params, input_types, input_names, nullptr, nullptr,
 	                                  dummy_table_function, empty);
 	vector<LogicalType> return_types;
@@ -81,9 +80,6 @@ static void ConvertPyArrowToDataChunk(const py::object &table, Vector &out, Clie
 		    "The returned table from a pyarrow scalar udf should only contain one column, found %d",
 		    return_types.size());
 	}
-	// if (return_types[0] != out.GetType()) {
-	//	throw InvalidInputException("The type of the returned array (%s) does not match the expected type: '%s'", )
-	//}
 
 	DataChunk result;
 	// Reserve for STANDARD_VECTOR_SIZE instead of count, in case the returned table contains too many tuples
@@ -101,14 +97,51 @@ static void ConvertPyArrowToDataChunk(const py::object &table, Vector &out, Clie
 	}
 
 	VectorOperations::Cast(context, result.data[0], out, count);
+	out.Flatten(count);
 }
 
-static scalar_function_t CreateVectorizedFunction(PyObject *function, PythonExceptionHandling exception_handling) {
+static string NullHandlingError() {
+	return R"(
+The returned result contained NULL values, but the 'null_handling' was set to DEFAULT.
+If you want more control over NULL values then 'null_handling' should be set to SPECIAL.
+
+With DEFAULT all rows containing NULL have been filtered from the UDFs input.
+Those rows are automatically set to NULL in the final result.
+The UDF is not expected to return NULL values.
+	)";
+}
+
+static ValidityMask &GetResultValidity(Vector &result) {
+	auto vector_type = result.GetVectorType();
+	if (vector_type == VectorType::CONSTANT_VECTOR) {
+		return ConstantVector::Validity(result);
+	} else if (vector_type == VectorType::FLAT_VECTOR) {
+		return FlatVector::Validity(result);
+	} else {
+		throw InternalException("VectorType %s was not expected here (GetResultValidity)",
+		                        EnumUtil::ToString(vector_type));
+	}
+}
+
+static void VerifyVectorizedNullHandling(Vector &result, idx_t count) {
+	auto &validity = GetResultValidity(result);
+
+	if (validity.AllValid()) {
+		return;
+	}
+
+	throw InvalidInputException(NullHandlingError());
+}
+
+static scalar_function_t CreateVectorizedFunction(PyObject *function, PythonExceptionHandling exception_handling,
+                                                  FunctionNullHandling null_handling) {
 	// Through the capture of the lambda, we have access to the function pointer
 	// We just need to make sure that it doesn't get garbage collected
 	scalar_function_t func = [=](DataChunk &input, ExpressionState &state, Vector &result) -> void {
 		py::gil_scoped_acquire gil;
 
+		const bool default_null_handling = null_handling == FunctionNullHandling::DEFAULT_NULL_HANDLING;
+
 		// owning references
 		py::object python_object;
 		// Convert the input datachunk to pyarrow
@@ -119,6 +152,36 @@ static scalar_function_t CreateVectorizedFunction(PyObject *function, PythonExce
 			options = context.GetClientProperties();
 		}
 
+		auto result_validity = FlatVector::Validity(result);
+		SelectionVector selvec(input.size());
+		idx_t input_size = input.size();
+		if (default_null_handling) {
+			vector<UnifiedVectorFormat> vec_data(input.ColumnCount());
+			for (idx_t i = 0; i < input.ColumnCount(); i++) {
+				input.data[i].ToUnifiedFormat(input.size(), vec_data[i]);
+			}
+
+			idx_t index = 0;
+			for (idx_t i = 0; i < input.size(); i++) {
+				bool any_null = false;
+				for (idx_t col_idx = 0; col_idx < input.ColumnCount(); col_idx++) {
+					auto &vec = vec_data[col_idx];
+					if (!vec.validity.RowIsValid(vec.sel->get_index(i))) {
+						any_null = true;
+						break;
+					}
+				}
+				if (any_null) {
+					result_validity.SetInvalid(i);
+					continue;
+				}
+				selvec.set_index(index++, i);
+			}
+			if (index != input.size()) {
+				input.Slice(selvec, index);
+			}
+		}
+
 		auto pyarrow_table = ConvertDataChunkToPyArrowTable(input, options);
 		py::tuple column_list = pyarrow_table.attr("columns");
 
@@ -126,7 +189,9 @@ static scalar_function_t CreateVectorizedFunction(PyObject *function, PythonExce
 
 		// Call the function
 		auto ret = PyObject_CallObject(function, column_list.ptr());
+		bool exception_occurred = false;
 		if (ret == nullptr && PyErr_Occurred()) {
+			exception_occurred = true;
 			if (exception_handling == PythonExceptionHandling::FORWARD_ERROR) {
 				auto exception = py::error_already_set();
 				throw InvalidInputException("Python exception occurred while executing the UDF: %s", exception.what());
@@ -154,9 +219,43 @@ static scalar_function_t CreateVectorizedFunction(PyObject *function, PythonExce
 			}
 		}
 		// Convert the pyarrow result back to a DuckDB datachunk
-		ConvertPyArrowToDataChunk(python_object, result, state.GetContext(), count);
+		if (count != input_size) {
+			D_ASSERT(default_null_handling);
+			// We filtered out some NULLs, now we need to reconstruct the final result by adding the nulls back
+			Vector temp(result.GetType(), count);
+			// Convert the table into a temporary Vector
+			ConvertArrowTableToVector(python_object, temp, state.GetContext(), count);
+			if (!exception_occurred) {
+				VerifyVectorizedNullHandling(temp, count);
+			}
+			if (count) {
+				SelectionVector inverted(input_size);
+				// Create a SelVec that inverts the filtering
+				// example: count: 6, null_indices: 1,3
+				// input selvec: [0, 2, 4, 5]
+				// inverted selvec: [0, 0, 1, 1, 2, 3]
+				idx_t src_index = 0;
+				for (idx_t i = 0; i < input_size; i++) {
+					// Fill the gaps with the previous index
+					inverted.set_index(i, src_index);
+					if (src_index + 1 < count && selvec.get_index(src_index) == i) {
+						src_index++;
+					}
+				}
+				VectorOperations::Copy(temp, result, inverted, count, 0, 0, input_size);
+			}
+			for (idx_t i = 0; i < input_size; i++) {
+				FlatVector::SetNull(result, i, !result_validity.RowIsValid(i));
+			}
+			result.Verify(input_size);
+		} else {
+			ConvertArrowTableToVector(python_object, result, state.GetContext(), count);
+			if (default_null_handling && !exception_occurred) {
+				VerifyVectorizedNullHandling(result, count);
+			}
+		}
 
-		if (input.size() == 1) {
+		if (input_size == 1) {
 			result.SetVectorType(VectorType::CONSTANT_VECTOR);
 		}
 	};
@@ -164,12 +263,15 @@ static scalar_function_t CreateVectorizedFunction(PyObject *function, PythonExce
 }
 
 static scalar_function_t CreateNativeFunction(PyObject *function, PythonExceptionHandling exception_handling,
-                                              const ClientProperties &client_properties) {
+                                              const ClientProperties &client_properties,
+                                              FunctionNullHandling null_handling) {
 	// Through the capture of the lambda, we have access to the function pointer
 	// We just need to make sure that it doesn't get garbage collected
 	scalar_function_t func = [=](DataChunk &input, ExpressionState &state, Vector &result) -> void { // NOLINT
 		py::gil_scoped_acquire gil;
 
+		const bool default_null_handling = null_handling == FunctionNullHandling::DEFAULT_NULL_HANDLING;
+
 		// owning references
 		vector<py::object> python_objects;
 		vector<PyObject *> python_results;
@@ -177,12 +279,23 @@ static scalar_function_t CreateNativeFunction(PyObject *function, PythonExceptio
 		for (idx_t row = 0; row < input.size(); row++) {
 
 			auto bundled_parameters = py::tuple((int)input.ColumnCount());
+			bool contains_null = false;
 			for (idx_t i = 0; i < input.ColumnCount(); i++) {
 				// Fill the tuple with the arguments for this row
 				auto &column = input.data[i];
 				auto value = column.GetValue(row);
+				if (value.IsNull() && default_null_handling) {
+					contains_null = true;
+					break;
+				}
 				bundled_parameters[i] = PythonObject::FromValue(value, column.GetType(), client_properties);
 			}
+			if (contains_null) {
+				// Immediately insert None, no need to call the function
+				python_objects.push_back(py::none());
+				python_results[row] = py::none().ptr();
+				continue;
+			}
 
 			// Call the function
 			auto ret = PyObject_CallObject(function, bundled_parameters.ptr());
@@ -197,6 +310,8 @@ static scalar_function_t CreateNativeFunction(PyObject *function, PythonExceptio
 				} else {
 					throw NotImplementedException("Exception handling type not implemented");
 				}
+			} else if ((!ret || ret == Py_None) && default_null_handling) {
+				throw InvalidInputException(NullHandlingError());
 			}
 			python_objects.push_back(py::reinterpret_steal<py::object>(ret));
 			python_results[row] = ret;
@@ -304,7 +419,8 @@ struct PythonUDFData {
 		auto signature = GetSignature(udf);
 		auto sig_params = signature.attr("parameters");
 		auto return_annotation = signature.attr("return_annotation");
-		if (!py::none().is(return_annotation)) {
+		auto empty = py::module_::import("inspect").attr("Signature").attr("empty");
+		if (!py::none().is(return_annotation) && !empty.is(return_annotation)) {
 			shared_ptr<DuckDBPyType> pytype;
 			if (py::try_cast<shared_ptr<DuckDBPyType>>(return_annotation, pytype)) {
 				return_type = pytype->Type();
@@ -338,9 +454,9 @@ struct PythonUDFData {
 
 		scalar_function_t func;
 		if (vectorized) {
-			func = CreateVectorizedFunction(udf.ptr(), exception_handling);
+			func = CreateVectorizedFunction(udf.ptr(), exception_handling, null_handling);
 		} else {
-			func = CreateNativeFunction(udf.ptr(), exception_handling, client_properties);
+			func = CreateNativeFunction(udf.ptr(), exception_handling, client_properties, null_handling);
 		}
 		FunctionStability function_side_effects =
 		    side_effects ? FunctionStability::VOLATILE : FunctionStability::CONSISTENT;
diff --git a/tools/pythonpkg/src/typing/pytype.cpp b/tools/pythonpkg/src/typing/pytype.cpp
index 39172a12eb4a..7b03f167121c 100644
--- a/tools/pythonpkg/src/typing/pytype.cpp
+++ b/tools/pythonpkg/src/typing/pytype.cpp
@@ -127,6 +127,9 @@ static bool FromNumpyType(const py::object &type, LogicalType &result) {
 	auto obj = type();
 	// We convert these to string because the underlying physical
 	// types of a numpy type aren't consistent on every platform
+	if (!py::hasattr(obj, "dtype")) {
+		return false;
+	}
 	string type_str = py::str(obj.attr("dtype"));
 	if (type_str == "bool") {
 		result = LogicalType::BOOLEAN;
@@ -185,7 +188,7 @@ static LogicalType FromType(const py::type &obj) {
 		return result;
 	}
 
-	throw py::type_error("Could not convert from unknown 'type' to DuckDBPyType");
+	throw py::cast_error("Could not convert from unknown 'type' to DuckDBPyType");
 }
 
 static bool IsMapType(const py::tuple &args) {
