You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
[fts] not statically linked when `DUCKDB_EXTENSION_FTS_LINKED=1` (commented out)
### What happens?

Not linked, its commented out :)

https://github.com/duckdb/duckdb/blob/1bb332c9c59a9d15b196b4486a6d1ffcaa833ba5/src/main/extension/extension_helper.cpp#L497

### To Reproduce

Build with `DUCKDB_EXTENSION_FTS_LINKED=1`, try:

```
SELECT extension_name, installed, description FROM duckdb_extensions() WHERE extension_name = 'fts';
```

> ```
> │ fts            │ true      │ Adds support for Full-Text Search Indexes │
> ```

But, running `PRAGMA create_fts_index(...` gets upset and says to install the extension

### OS:

iOS / macOS aarch64

### DuckDB Version:

1.1.1

### DuckDB Client:

Swift

### Hardware:

_No response_

### Full Name:

Quinn Blenkinsop

### Affiliation:

None

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Not applicable - the reproduction does not require a data set

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation/) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of .github/config/bundled_extensions.cmake]
1: #
2: # Default extension config for DuckDB releases.
3: #
4: # This is the extension config that is used to build / test DuckDB releases, e.g.:
5: #  - Which extensions are statically linked into DuckDB
6: #  - Which extensions are tested
7: #  - Which extensions can be autoloaded
8: #
9: # Distributions that run this config:
10: # - Windows (64bit and 32bit) # TODO: 32bit needs autoloading disabled
11: # - Linux (arm64 and 32bit)
12: # - OSX (universal binary)
13: 
14: #
15: ## Extensions that are linked
16: #
17: duckdb_extension_load(icu)
18: duckdb_extension_load(tpch)
19: duckdb_extension_load(json)
20: duckdb_extension_load(fts)
21: duckdb_extension_load(parquet)
22: duckdb_extension_load(autocomplete)
23: 
24: #
25: ## Extensions that are not linked, but we do want to test them as part of the release build
26: #
27: duckdb_extension_load(tpcds DONT_LINK)
[end of .github/config/bundled_extensions.cmake]
[start of .github/config/extensions.csv]
1: name,url,commit,options
2: excel,,,
3: fts,,,
4: httpfs,,,
5: icu,,,
6: json,,,
7: parquet,,,
8: tpcds,,,
9: tpch,,,
10: sqlite_scanner,https://github.com/duckdb/sqlite_scanner,091197efb34579c7195afa43dfb5925023c915c0,
11: postgres_scanner,https://github.com/duckdb/postgres_scanner,96206f41d5ca7015920a66b54e936c986fe0b0f8,
12: substrait,https://github.com/duckdb/substrait,1116fb580edd3e26e675436dbdbdf4a0aa5e456e,no-windows
13: arrow,https://github.com/duckdb/arrow,9e10240da11f61ea7fbfe3fc9988ffe672ccd40f,no-windows
14: aws,https://github.com/duckdb/duckdb_aws,f7b8729f1cce5ada5d4add70e1486de50763fb97,
15: azure,https://github.com/duckdb/duckdb_azure,09623777a366572bfb8fa53e47acdf72133a360e,
16: spatial,https://github.com/duckdb/duckdb_spatial,7ea79b614755d2bdee4be468691e4e17b39b8dbc,
17: iceberg,https://github.com/duckdb/duckdb_iceberg,d89423c2ff90a0b98a093a133c8dfe2a55b9e092,
18: vss,https://github.com/duckdb/duckdb_vss,96374099476b3427c9ab43c1821e610b0465c864,
[end of .github/config/extensions.csv]
[start of .github/config/in_tree_extensions.cmake]
1: #
2: # This is the DuckDB in-tree extension config as it will run on the CI
3: #
4: # to build duckdb with this configuration run:
5: #   EXTENSION_CONFIGS=.github/config/in_tree_extensions.cmake make
6: #
7: 
8: duckdb_extension_load(autocomplete)
9: duckdb_extension_load(core_functions)
10: duckdb_extension_load(fts)
11: duckdb_extension_load(httpfs)
12: duckdb_extension_load(icu)
13: duckdb_extension_load(json)
14: duckdb_extension_load(parquet)
15: duckdb_extension_load(tpcds)
16: duckdb_extension_load(tpch)
17: 
18: # Test extension for the upcoming C CAPI extensions
19: duckdb_extension_load(demo_capi DONT_LINK)
[end of .github/config/in_tree_extensions.cmake]
[start of .github/config/out_of_tree_extensions.cmake]
1: #
2: # This config file holds all out-of-tree extension that are built with DuckDB's CI
3: #
4: # to build duckdb with this configuration run:
5: #   EXTENSION_CONFIGS=.github/config/out_of_tree_extensions.cmake make
6: #
7: #  Note that many of these packages require vcpkg, and a merged manifest must be created to
8: #  compile multiple of them.
9: #
10: #  After setting up vcpkg, build using e.g. the following commands:
11: #  USE_MERGED_VCPKG_MANIFEST=1 BUILD_ALL_EXT=1 make extension_configuration
12: #  USE_MERGED_VCPKG_MANIFEST=1 BUILD_ALL_EXT=1 make debug
13: #
14: #  Make sure the VCPKG_TOOLCHAIN_PATH and VCPKG_TARGET_TRIPLET are set. For example:
15: #  VCPKG_TOOLCHAIN_PATH=~/vcpkg/scripts/buildsystems/vcpkg.cmake
16: #  VCPKG_TARGET_TRIPLET=arm64-osx
17: 
18: ################# ARROW
19: if (NOT MINGW)
20:     duckdb_extension_load(arrow
21:             LOAD_TESTS DONT_LINK
22:             GIT_URL https://github.com/duckdb/arrow
23:             GIT_TAG c50862c82c065096722745631f4230832a3a04e8
24:             APPLY_PATCHES
25:             )
26: endif()
27: 
28: ################## AWS
29: if (NOT MINGW)
30:     duckdb_extension_load(aws
31:             LOAD_TESTS
32:             GIT_URL https://github.com/duckdb/duckdb_aws
33:             GIT_TAG f743d4b3c2faecda15498d0219a1727ad6d62b5b
34:             )
35: endif()
36: 
37: ################# AZURE
38: if (NOT MINGW)
39:     duckdb_extension_load(azure
40:             LOAD_TESTS
41:             GIT_URL https://github.com/duckdb/duckdb_azure
42:             GIT_TAG a40ecb7bc9036eb8ecc5bf30db935a31b78011f5
43:             APPLY_PATCHES
44:             )
45: endif()
46: 
47: ################# DELTA
48: # MinGW build is not available, and our current manylinux ci does not have enough storage space to run the rust build
49: # for Delta
50: if (NOT MINGW AND NOT "${OS_NAME}" STREQUAL "linux")
51:     duckdb_extension_load(delta
52:             LOAD_TESTS
53:             GIT_URL https://github.com/duckdb/duckdb_delta
54:             GIT_TAG b7333c0143e101c720117d564651e693b317bb31
55:             APPLY_PATCHES
56:     )
57: endif()
58: 
59: ################# EXCEL
60: duckdb_extension_load(excel
61:     LOAD_TESTS
62:     GIT_URL https://github.com/duckdb/duckdb_excel
63:     GIT_TAG 0e99dc789038c7af658e30d579b818473a6d6ea8
64:     INCLUDE_DIR extension/excel/include
65:     )
66: 
67: ################# ICEBERG
68: # Windows tests for iceberg currently not working
69: if (NOT WIN32)
70:     set(LOAD_ICEBERG_TESTS "LOAD_TESTS")
71: else ()
72:     set(LOAD_ICEBERG_TESTS "")
73: endif()
74: 
75: if (NOT MINGW)
76:     duckdb_extension_load(iceberg
77:             ${LOAD_ICEBERG_TESTS}
78:             GIT_URL https://github.com/duckdb/duckdb_iceberg
79:             GIT_TAG d62d91d8a089371c4d1862a88f2e62a97bc2af3a
80:             APPLY_PATCHES
81:             )
82: endif()
83: 
84: ################# INET
85: duckdb_extension_load(inet
86:     LOAD_TESTS
87:     GIT_URL https://github.com/duckdb/duckdb_inet
88:     GIT_TAG 51d7ad789f34eecb36a2071bac5aef0e12747d70
89:     INCLUDE_DIR src/include
90:     TEST_DIR test/sql
91:     )
92: 
93: ################# POSTGRES_SCANNER
94: # Note: tests for postgres_scanner are currently not run. All of them need a postgres server running. One test
95: #       uses a remote rds server but that's not something we want to run here.
96: if (NOT MINGW)
97:     duckdb_extension_load(postgres_scanner
98:             DONT_LINK
99:             GIT_URL https://github.com/duckdb/postgres_scanner
100:             GIT_TAG 03eaed75f0ec5500609b7a97aa05468493b229d1
101:             APPLY_PATCHES
102:             )
103: endif()
104: 
105: ################# SPATIAL
106: duckdb_extension_load(spatial
107:     DONT_LINK LOAD_TESTS
108:     GIT_URL https://github.com/duckdb/duckdb_spatial.git
109:     GIT_TAG 7ea79b614755d2bdee4be468691e4e17b39b8dbc
110:     INCLUDE_DIR spatial/include
111:     TEST_DIR test/sql
112:     APPLY_PATCHES
113:     )
114: 
115: ################# SQLITE_SCANNER
116: # Static linking on windows does not properly work due to symbol collision
117: if (WIN32)
118:     set(STATIC_LINK_SQLITE "DONT_LINK")
119: else ()
120:     set(STATIC_LINK_SQLITE "")
121: endif()
122: 
123: duckdb_extension_load(sqlite_scanner
124:         ${STATIC_LINK_SQLITE} LOAD_TESTS
125:         GIT_URL https://github.com/duckdb/sqlite_scanner
126:         GIT_TAG d5d62657702d33cb44a46cddc7ffc4b67bf7e961
127:         APPLY_PATCHES
128:         )
129: 
130: duckdb_extension_load(sqlsmith
131:         DONT_LINK LOAD_TESTS
132:         GIT_URL https://github.com/duckdb/duckdb_sqlsmith
133:         GIT_TAG d6d62c1cba6b1369ba79db4bff3c67f24aaa95c2
134:         )
135: 
136: ################# SUBSTRAIT
137: if (NOT WIN32)
138:     duckdb_extension_load(substrait
139:             LOAD_TESTS DONT_LINK
140:             GIT_URL https://github.com/duckdb/substrait
141:             GIT_TAG be71387cf0a484dc7b261a0cb21abec0d0e0ce5c
142:             APPLY_PATCHES
143:             )
144: endif()
145: 
146: 
147: ################# VSS
148: duckdb_extension_load(vss
149:         LOAD_TESTS
150:         DONT_LINK
151:         GIT_URL https://github.com/duckdb/duckdb_vss
152:         GIT_TAG 96374099476b3427c9ab43c1821e610b0465c864
153:         TEST_DIR test/sql
154:         APPLY_PATCHES
155:     )
156: 
157: ################# MYSQL
158: if (NOT MINGW)
159:     duckdb_extension_load(mysql_scanner
160:             DONT_LINK
161:             LOAD_TESTS
162:             GIT_URL https://github.com/duckdb/duckdb_mysql
163:             GIT_TAG f2a15013fb4559e1591e977c1c023aa0a369c6f3
164:             )
165: endif()
[end of .github/config/out_of_tree_extensions.cmake]
[start of .github/workflows/Main.yml]
1: name: Main
2: on:
3:   workflow_dispatch:
4:   repository_dispatch:
5:   push:
6:     branches:
7:       - '**'
8:       - '!main'
9:       - '!feature'
10:     paths-ignore:
11:       - '**.md'
12:       - 'tools/**'
13:       - '!tools/shell/**'
14:       - '.github/patches/duckdb-wasm/**'
15:       - '.github/workflows/**'
16:       - '!.github/workflows/Main.yml'
17: 
18:   pull_request:
19:     types: [opened, reopened, ready_for_review]
20:     paths-ignore:
21:       - '**.md'
22:       - 'tools/**'
23:       - '!tools/shell/**'
24:       - '.github/patches/duckdb-wasm/**'
25:       - '.github/workflows/**'
26:       - '!.github/workflows/Main.yml'
27: 
28: 
29: concurrency:
30:   group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref || '' }}-${{ github.base_ref || '' }}-${{ github.ref != 'refs/heads/main' || github.sha }}
31:   cancel-in-progress: true
32: 
33: env:
34:   GH_TOKEN: ${{ secrets.GH_TOKEN }}
35: 
36: jobs:
37:  linux-debug:
38:     name: Linux Debug
39:     if: ${{ !startsWith(github.ref, 'refs/tags/v') }}
40:     outputs:
41:       git_describe: ${{ steps.describe_step.outputs.git_describe }}
42:     runs-on: ubuntu-20.04
43:     env:
44:       CC: gcc-10
45:       CXX: g++-10
46:       TREAT_WARNINGS_AS_ERRORS: 1
47:       GEN: ninja
48: 
49:     steps:
50:     - uses: actions/checkout@v4
51:       with:
52:         fetch-depth: 0
53: 
54:     - id: describe_step
55:       run: echo "git_describe=$(git describe --tags --long)" >> "$GITHUB_OUTPUT"
56: 
57:     - name: Install
58:       shell: bash
59:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
60: 
61:     - name: Setup Ccache
62:       uses: hendrikmuhs/ccache-action@main
63:       with:
64:         key: ${{ github.job }}
65:         save: ${{ github.ref == 'refs/heads/main' || github.repository != 'duckdb/duckdb' }}
66: 
67:     - name: Build
68:       shell: bash
69:       run:  make debug
70: 
71:     - name: Output version info
72:       shell: bash
73:       run: ./build/debug/duckdb -c "PRAGMA version;"
74: 
75:     - name: Set DUCKDB_INSTALL_LIB for ADBC tests
76:       shell: bash
77:       run: echo "DUCKDB_INSTALL_LIB=$(find `pwd` -name "libduck*.so" | head -n 1)" >> $GITHUB_ENV
78: 
79:     - name: Test DUCKDB_INSTALL_LIB variable
80:       run: echo $DUCKDB_INSTALL_LIB
81: 
82:     - name: Test
83:       shell: bash
84:       run: make unittestci
85: 
86: 
87:  force-storage:
88:     name: Force Storage
89:     if: ${{ !startsWith(github.ref, 'refs/tags/v') }}
90:     runs-on: ubuntu-20.04
91:     needs: linux-debug
92:     env:
93:       OVERRIDE_GIT_DESCRIBE: ${{needs.linux-debug.outputs.git_describe}}
94:       CC: gcc-10
95:       CXX: g++-10
96:       GEN: ninja
97:       BUILD_JEMALLOC: 1
98:       CORE_EXTENSIONS: "icu;parquet;tpch;tpcds;fts;json"
99:       RUN_SLOW_VERIFIERS: 1
100: 
101:     steps:
102:     - uses: actions/checkout@v4
103: 
104:     - name: Install
105:       shell: bash
106:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
107: 
108:     - name: Setup Ccache
109:       uses: hendrikmuhs/ccache-action@main
110:       with:
111:         key: ${{ github.job }}
112:         save: ${{ github.ref == 'refs/heads/main' || github.repository != 'duckdb/duckdb' }}
113: 
114:     - name: Build
115:       shell: bash
116:       run: make reldebug
117: 
118:     - name: Output version info
119:       shell: bash
120:       run: ./build/reldebug/duckdb -c "PRAGMA version;"
121: 
122:     - name: Test
123:       shell: bash
124:       run: build/reldebug/test/unittest --force-storage
125: 
126:  force-restart:
127:     name: Force Restart
128:     if: ${{ !startsWith(github.ref, 'refs/tags/v') }}
129:     runs-on: ubuntu-20.04
130:     needs: linux-debug
131:     env:
132:       OVERRIDE_GIT_DESCRIBE: ${{needs.linux-debug.outputs.git_describe}}
133:       CC: gcc-10
134:       CXX: g++-10
135:       GEN: ninja
136:       BUILD_JEMALLOC: 1
137:       CORE_EXTENSIONS: "icu;parquet;tpch;tpcds;fts;json"
138: 
139:     steps:
140:     - uses: actions/checkout@v4
141: 
142:     - name: Install
143:       shell: bash
144:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
145: 
146:     - name: Setup Ccache
147:       uses: hendrikmuhs/ccache-action@main
148:       with:
149:         key: ${{ github.job }}
150:         save: ${{ github.ref == 'refs/heads/main' || github.repository != 'duckdb/duckdb' }}
151: 
152:     - name: Build
153:       shell: bash
154:       run: make reldebug
155: 
156:     - name: Output version info
157:       shell: bash
158:       run: ./build/reldebug/duckdb -c "PRAGMA version;"
159: 
160:     - name: Test
161:       shell: bash
162:       run: build/reldebug/test/unittest --force-reload --force-storage
163: 
164:  valgrind:
165:     name: Valgrind
166:     if: ${{ !startsWith(github.ref, 'refs/tags/v') }}
167:     runs-on: ubuntu-20.04
168:     needs: linux-debug
169:     env:
170:       OVERRIDE_GIT_DESCRIBE: ${{needs.linux-debug.outputs.git_describe}}
171:       CC: gcc-10
172:       CXX: g++-10
173:       DISABLE_SANITIZER: 1
174:       BUILD_JEMALLOC: 1
175:       GEN: ninja
176: 
177:     steps:
178:     - uses: actions/checkout@v4
179: 
180:     - name: Install
181:       shell: bash
182:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build valgrind
183: 
184:     - name: Setup Ccache
185:       uses: hendrikmuhs/ccache-action@main
186:       with:
187:         key: ${{ github.job }}
188:         save: ${{ github.ref == 'refs/heads/main' || github.repository != 'duckdb/duckdb' }}
189: 
190:     - name: Build
191:       shell: bash
192:       run: make debug
193: 
194:     - name: Output version info
195:       shell: bash
196:       run: ./build/debug/duckdb -c "PRAGMA version;"
197: 
198:     - name: Test
199:       shell: bash
200:       run: valgrind ./build/debug/test/unittest test/sql/tpch/tpch_sf001.test_slow
[end of .github/workflows/Main.yml]
[start of extension/fts/CMakeLists.txt]
1: cmake_minimum_required(VERSION 2.8.12...3.29)
2: 
3: project(FTSExtension)
4: 
5: include_directories(include ../../third_party/snowball/libstemmer)
6: set(FTS_SOURCES
7:     fts_extension.cpp
8:     fts_indexing.cpp
9:     ../../third_party/snowball/libstemmer/libstemmer.cpp
10:     ../../third_party/snowball/runtime/utilities.cpp
11:     ../../third_party/snowball/runtime/api.cpp
12:     ../../third_party/snowball/src_c/stem_UTF_8_arabic.cpp
13:     ../../third_party/snowball/src_c/stem_UTF_8_basque.cpp
14:     ../../third_party/snowball/src_c/stem_UTF_8_catalan.cpp
15:     ../../third_party/snowball/src_c/stem_UTF_8_danish.cpp
16:     ../../third_party/snowball/src_c/stem_UTF_8_dutch.cpp
17:     ../../third_party/snowball/src_c/stem_UTF_8_english.cpp
18:     ../../third_party/snowball/src_c/stem_UTF_8_finnish.cpp
19:     ../../third_party/snowball/src_c/stem_UTF_8_french.cpp
20:     ../../third_party/snowball/src_c/stem_UTF_8_german.cpp
21:     ../../third_party/snowball/src_c/stem_UTF_8_german2.cpp
22:     ../../third_party/snowball/src_c/stem_UTF_8_greek.cpp
23:     ../../third_party/snowball/src_c/stem_UTF_8_hindi.cpp
24:     ../../third_party/snowball/src_c/stem_UTF_8_hungarian.cpp
25:     ../../third_party/snowball/src_c/stem_UTF_8_indonesian.cpp
26:     ../../third_party/snowball/src_c/stem_UTF_8_irish.cpp
27:     ../../third_party/snowball/src_c/stem_UTF_8_italian.cpp
28:     ../../third_party/snowball/src_c/stem_UTF_8_kraaij_pohlmann.cpp
29:     ../../third_party/snowball/src_c/stem_UTF_8_lithuanian.cpp
30:     ../../third_party/snowball/src_c/stem_UTF_8_lovins.cpp
31:     ../../third_party/snowball/src_c/stem_UTF_8_nepali.cpp
32:     ../../third_party/snowball/src_c/stem_UTF_8_norwegian.cpp
33:     ../../third_party/snowball/src_c/stem_UTF_8_porter.cpp
34:     ../../third_party/snowball/src_c/stem_UTF_8_portuguese.cpp
35:     ../../third_party/snowball/src_c/stem_UTF_8_romanian.cpp
36:     ../../third_party/snowball/src_c/stem_UTF_8_russian.cpp
37:     ../../third_party/snowball/src_c/stem_UTF_8_serbian.cpp
38:     ../../third_party/snowball/src_c/stem_UTF_8_spanish.cpp
39:     ../../third_party/snowball/src_c/stem_UTF_8_swedish.cpp
40:     ../../third_party/snowball/src_c/stem_UTF_8_tamil.cpp
41:     ../../third_party/snowball/src_c/stem_UTF_8_turkish.cpp)
42: 
43: build_static_extension(fts ${FTS_SOURCES})
44: set(PARAMETERS "-warnings")
45: build_loadable_extension(fts ${PARAMETERS} ${FTS_SOURCES})
46: 
47: install(
48:   TARGETS fts_extension
49:   EXPORT "${DUCKDB_EXPORT_SET}"
50:   LIBRARY DESTINATION "${INSTALL_LIB_DIR}"
51:   ARCHIVE DESTINATION "${INSTALL_LIB_DIR}")
[end of extension/fts/CMakeLists.txt]
[start of extension/fts/fts_config.py]
1: import os
2: 
3: # list all include directories
4: include_directories = [
5:     os.path.sep.join(x.split('/'))
6:     for x in [
7:         'extension/fts/include',
8:         'third_party/snowball/libstemmer',
9:         'third_party/snowball/runtime',
10:         'third_party/snowball/src_c',
11:     ]
12: ]
13: # source files
14: source_files = [
15:     os.path.sep.join(x.split('/')) for x in ['extension/fts/fts_extension.cpp', 'extension/fts/fts_indexing.cpp']
16: ]
17: # snowball
18: source_files += [
19:     os.path.sep.join(x.split('/'))
20:     for x in [
21:         'third_party/snowball/libstemmer/libstemmer.cpp',
22:         'third_party/snowball/runtime/utilities.cpp',
23:         'third_party/snowball/runtime/api.cpp',
24:         'third_party/snowball/src_c/stem_UTF_8_arabic.cpp',
25:         'third_party/snowball/src_c/stem_UTF_8_basque.cpp',
26:         'third_party/snowball/src_c/stem_UTF_8_catalan.cpp',
27:         'third_party/snowball/src_c/stem_UTF_8_danish.cpp',
28:         'third_party/snowball/src_c/stem_UTF_8_dutch.cpp',
29:         'third_party/snowball/src_c/stem_UTF_8_english.cpp',
30:         'third_party/snowball/src_c/stem_UTF_8_finnish.cpp',
31:         'third_party/snowball/src_c/stem_UTF_8_french.cpp',
32:         'third_party/snowball/src_c/stem_UTF_8_german.cpp',
33:         'third_party/snowball/src_c/stem_UTF_8_german2.cpp',
34:         'third_party/snowball/src_c/stem_UTF_8_greek.cpp',
35:         'third_party/snowball/src_c/stem_UTF_8_hindi.cpp',
36:         'third_party/snowball/src_c/stem_UTF_8_hungarian.cpp',
37:         'third_party/snowball/src_c/stem_UTF_8_indonesian.cpp',
38:         'third_party/snowball/src_c/stem_UTF_8_irish.cpp',
39:         'third_party/snowball/src_c/stem_UTF_8_italian.cpp',
40:         'third_party/snowball/src_c/stem_UTF_8_kraaij_pohlmann.cpp',
41:         'third_party/snowball/src_c/stem_UTF_8_lithuanian.cpp',
42:         'third_party/snowball/src_c/stem_UTF_8_lovins.cpp',
43:         'third_party/snowball/src_c/stem_UTF_8_nepali.cpp',
44:         'third_party/snowball/src_c/stem_UTF_8_norwegian.cpp',
45:         'third_party/snowball/src_c/stem_UTF_8_porter.cpp',
46:         'third_party/snowball/src_c/stem_UTF_8_portuguese.cpp',
47:         'third_party/snowball/src_c/stem_UTF_8_romanian.cpp',
48:         'third_party/snowball/src_c/stem_UTF_8_russian.cpp',
49:         'third_party/snowball/src_c/stem_UTF_8_serbian.cpp',
50:         'third_party/snowball/src_c/stem_UTF_8_spanish.cpp',
51:         'third_party/snowball/src_c/stem_UTF_8_swedish.cpp',
52:         'third_party/snowball/src_c/stem_UTF_8_tamil.cpp',
53:         'third_party/snowball/src_c/stem_UTF_8_turkish.cpp',
54:     ]
55: ]
[end of extension/fts/fts_config.py]
[start of extension/fts/fts_extension.cpp]
1: #define DUCKDB_EXTENSION_MAIN
2: #include "fts_extension.hpp"
3: 
4: #include "duckdb.hpp"
5: #include "duckdb/common/exception.hpp"
6: #include "duckdb/common/string_util.hpp"
7: #include "duckdb/function/pragma_function.hpp"
8: #include "duckdb/function/scalar_function.hpp"
9: #include "duckdb/main/extension_util.hpp"
10: #include "fts_indexing.hpp"
11: #include "libstemmer.h"
12: 
13: namespace duckdb {
14: 
15: static void StemFunction(DataChunk &args, ExpressionState &state, Vector &result) {
16: 	auto &input_vector = args.data[0];
17: 	auto &stemmer_vector = args.data[1];
18: 
19: 	BinaryExecutor::Execute<string_t, string_t, string_t>(
20: 	    input_vector, stemmer_vector, result, args.size(), [&](string_t input, string_t stemmer) {
21: 		    auto input_data = input.GetData();
22: 		    auto input_size = input.GetSize();
23: 
24: 		    if (stemmer.GetString() == "none") {
25: 			    auto output = StringVector::AddString(result, input_data, input_size);
26: 			    return output;
27: 		    }
28: 
29: 		    struct sb_stemmer *s = sb_stemmer_new(stemmer.GetString().c_str(), "UTF_8");
30: 		    if (s == 0) {
31: 			    const char **stemmers = sb_stemmer_list();
32: 			    size_t n_stemmers = 27;
33: 			    throw InvalidInputException(
34: 			        "Unrecognized stemmer '%s'. Supported stemmers are: ['%s'], or use 'none' for no stemming",
35: 			        stemmer.GetString(),
36: 			        StringUtil::Join(stemmers, n_stemmers, "', '", [](const char *st) { return st; }));
37: 		    }
38: 
39: 		    auto output_data =
40: 		        const_char_ptr_cast(sb_stemmer_stem(s, reinterpret_cast<const sb_symbol *>(input_data), input_size));
41: 		    auto output_size = sb_stemmer_length(s);
42: 		    auto output = StringVector::AddString(result, output_data, output_size);
43: 
44: 		    sb_stemmer_delete(s);
45: 		    return output;
46: 	    });
47: }
48: 
49: static void LoadInternal(DuckDB &db) {
50: 	auto &db_instance = *db.instance;
51: 	ScalarFunction stem_func("stem", {LogicalType::VARCHAR, LogicalType::VARCHAR}, LogicalType::VARCHAR, StemFunction);
52: 
53: 	auto create_fts_index_func =
54: 	    PragmaFunction::PragmaCall("create_fts_index", FTSIndexing::CreateFTSIndexQuery,
55: 	                               {LogicalType::VARCHAR, LogicalType::VARCHAR}, LogicalType::VARCHAR);
56: 	create_fts_index_func.named_parameters["stemmer"] = LogicalType::VARCHAR;
57: 	create_fts_index_func.named_parameters["stopwords"] = LogicalType::VARCHAR;
58: 	create_fts_index_func.named_parameters["ignore"] = LogicalType::VARCHAR;
59: 	create_fts_index_func.named_parameters["strip_accents"] = LogicalType::BOOLEAN;
60: 	create_fts_index_func.named_parameters["lower"] = LogicalType::BOOLEAN;
61: 	create_fts_index_func.named_parameters["overwrite"] = LogicalType::BOOLEAN;
62: 
63: 	auto drop_fts_index_func =
64: 	    PragmaFunction::PragmaCall("drop_fts_index", FTSIndexing::DropFTSIndexQuery, {LogicalType::VARCHAR});
65: 
66: 	ExtensionUtil::RegisterFunction(db_instance, stem_func);
67: 	ExtensionUtil::RegisterFunction(db_instance, create_fts_index_func);
68: 	ExtensionUtil::RegisterFunction(db_instance, drop_fts_index_func);
69: }
70: 
71: void FtsExtension::Load(DuckDB &db) {
72: 	LoadInternal(db);
73: }
74: 
75: std::string FtsExtension::Name() {
76: 	return "fts";
77: }
78: 
79: std::string FtsExtension::Version() const {
80: #ifdef EXT_VERSION_FTS
81: 	return EXT_VERSION_FTS;
82: #else
83: 	return "";
84: #endif
85: }
86: 
87: } // namespace duckdb
88: 
89: extern "C" {
90: 
91: DUCKDB_EXTENSION_API void fts_init(duckdb::DatabaseInstance &db) {
92: 	duckdb::DuckDB db_wrapper(db);
93: 	duckdb::LoadInternal(db_wrapper);
94: }
95: 
96: DUCKDB_EXTENSION_API const char *fts_version() {
97: 	return duckdb::DuckDB::LibraryVersion();
98: }
99: }
100: 
101: #ifndef DUCKDB_EXTENSION_MAIN
102: #error DUCKDB_EXTENSION_MAIN not defined
103: #endif
[end of extension/fts/fts_extension.cpp]
[start of extension/fts/fts_indexing.cpp]
1: #include "fts_indexing.hpp"
2: 
3: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
4: #include "duckdb/catalog/catalog_search_path.hpp"
5: #include "duckdb/common/exception.hpp"
6: #include "duckdb/common/string_util.hpp"
7: #include "duckdb/main/client_data.hpp"
8: #include "duckdb/main/connection.hpp"
9: #include "duckdb/parser/qualified_name.hpp"
10: 
11: namespace duckdb {
12: 
13: static QualifiedName GetQualifiedName(ClientContext &context, const string &qname_str) {
14: 	auto qname = QualifiedName::Parse(qname_str);
15: 	if (qname.schema == INVALID_SCHEMA) {
16: 		qname.schema = ClientData::Get(context).catalog_search_path->GetDefaultSchema(qname.catalog);
17: 	}
18: 	return qname;
19: }
20: 
21: static string GetFTSSchema(QualifiedName &qname) {
22: 	auto result = qname.catalog == INVALID_CATALOG ? "" : StringUtil::Format("%s.", qname.catalog);
23: 	result += StringUtil::Format("fts_%s_%s", qname.schema, qname.name);
24: 	return result;
25: }
26: 
27: string FTSIndexing::DropFTSIndexQuery(ClientContext &context, const FunctionParameters &parameters) {
28: 	auto qname = GetQualifiedName(context, StringValue::Get(parameters.values[0]));
29: 	string fts_schema = GetFTSSchema(qname);
30: 
31: 	if (!Catalog::GetSchema(context, qname.catalog, fts_schema, OnEntryNotFound::RETURN_NULL)) {
32: 		throw CatalogException(
33: 		    "a FTS index does not exist on table '%s.%s'. Create one with 'PRAGMA create_fts_index()'.", qname.schema,
34: 		    qname.name);
35: 	}
36: 
37: 	return StringUtil::Format("DROP SCHEMA %s CASCADE;", fts_schema);
38: }
39: 
40: static string IndexingScript(ClientContext &context, QualifiedName &qname, const string &input_id,
41:                              const vector<string> &input_values, const string &stemmer, const string &stopwords,
42:                              const string &ignore, bool strip_accents, bool lower) {
43: 	// clang-format off
44:     string result = R"(
45:         DROP SCHEMA IF EXISTS %fts_schema% CASCADE;
46:         CREATE SCHEMA %fts_schema%;
47:         CREATE TABLE %fts_schema%.stopwords (sw VARCHAR);
48:     )";
49: 	// clang-format on
50: 
51: 	if (stopwords == "none") {
52: 		// do nothing
53: 	} else if (stopwords == "english") {
54: 		// default list of english stopwords from "The SMART system"
55: 		// clang-format off
56:         result += R"(
57:             INSERT INTO %fts_schema%.stopwords VALUES ('a'), ('a''s'), ('able'), ('about'), ('above'), ('according'), ('accordingly'), ('across'), ('actually'), ('after'), ('afterwards'), ('again'), ('against'), ('ain''t'), ('all'), ('allow'), ('allows'), ('almost'), ('alone'), ('along'), ('already'), ('also'), ('although'), ('always'), ('am'), ('among'), ('amongst'), ('an'), ('and'), ('another'), ('any'), ('anybody'), ('anyhow'), ('anyone'), ('anything'), ('anyway'), ('anyways'), ('anywhere'), ('apart'), ('appear'), ('appreciate'), ('appropriate'), ('are'), ('aren''t'), ('around'), ('as'), ('aside'), ('ask'), ('asking'), ('associated'), ('at'), ('available'), ('away'), ('awfully'), ('b'), ('be'), ('became'), ('because'), ('become'), ('becomes'), ('becoming'), ('been'), ('before'), ('beforehand'), ('behind'), ('being'), ('believe'), ('below'), ('beside'), ('besides'), ('best'), ('better'), ('between'), ('beyond'), ('both'), ('brief'), ('but'), ('by'), ('c'), ('c''mon'), ('c''s'), ('came'), ('can'), ('can''t'), ('cannot'), ('cant'), ('cause'), ('causes'), ('certain'), ('certainly'), ('changes'), ('clearly'), ('co'), ('com'), ('come'), ('comes'), ('concerning'), ('consequently'), ('consider'), ('considering'), ('contain'), ('containing'), ('contains'), ('corresponding'), ('could'), ('couldn''t'), ('course'), ('currently'), ('d'), ('definitely'), ('described'), ('despite'), ('did'), ('didn''t'), ('different'), ('do'), ('does'), ('doesn''t'), ('doing'), ('don''t'), ('done'), ('down'), ('downwards'), ('during'), ('e'), ('each'), ('edu'), ('eg'), ('eight'), ('either'), ('else'), ('elsewhere'), ('enough'), ('entirely'), ('especially'), ('et'), ('etc'), ('even'), ('ever'), ('every'), ('everybody'), ('everyone'), ('everything'), ('everywhere'), ('ex'), ('exactly'), ('example'), ('except'), ('f'), ('far'), ('few'), ('fifth'), ('first'), ('five'), ('followed'), ('following'), ('follows'), ('for'), ('former'), ('formerly'), ('forth'), ('four'), ('from'), ('further'), ('furthermore'), ('g'), ('get'), ('gets'), ('getting'), ('given'), ('gives'), ('go'), ('goes'), ('going'), ('gone'), ('got'), ('gotten'), ('greetings'), ('h'), ('had'), ('hadn''t'), ('happens'), ('hardly'), ('has'), ('hasn''t'), ('have'), ('haven''t'), ('having'), ('he'), ('he''s'), ('hello'), ('help'), ('hence'), ('her'), ('here'), ('here''s'), ('hereafter'), ('hereby'), ('herein'), ('hereupon'), ('hers'), ('herself'), ('hi'), ('him'), ('himself'), ('his'), ('hither'), ('hopefully'), ('how'), ('howbeit'), ('however'), ('i'), ('i''d'), ('i''ll'), ('i''m'), ('i''ve'), ('ie'), ('if'), ('ignored'), ('immediate'), ('in'), ('inasmuch'), ('inc'), ('indeed'), ('indicate'), ('indicated'), ('indicates'), ('inner'), ('insofar'), ('instead'), ('into'), ('inward'), ('is'), ('isn''t'), ('it'), ('it''d'), ('it''ll'), ('it''s'), ('its'), ('itself'), ('j'), ('just'), ('k'), ('keep'), ('keeps'), ('kept'), ('know'), ('knows'), ('known'), ('l'), ('last'), ('lately'), ('later'), ('latter'), ('latterly'), ('least'), ('less'), ('lest'), ('let'), ('let''s'), ('like'), ('liked'), ('likely'), ('little'), ('look'), ('looking'), ('looks'), ('ltd'), ('m'), ('mainly'), ('many'), ('may'), ('maybe'), ('me'), ('mean'), ('meanwhile'), ('merely'), ('might'), ('more'), ('moreover'), ('most'), ('mostly'), ('much'), ('must'), ('my'), ('myself'), ('n'), ('name'), ('namely'), ('nd'), ('near'), ('nearly'), ('necessary'), ('need'), ('needs'), ('neither'), ('never'), ('nevertheless'), ('new'), ('next'), ('nine'), ('no'), ('nobody'), ('non'), ('none'), ('noone'), ('nor'), ('normally'), ('not'), ('nothing'), ('novel'), ('now'), ('nowhere'), ('o'), ('obviously'), ('of'), ('off'), ('often'), ('oh'), ('ok'), ('okay'), ('old'), ('on'), ('once'), ('one'), ('ones'), ('only'), ('onto'), ('or'), ('other'), ('others'), ('otherwise'), ('ought'), ('our'), ('ours'), ('ourselves'), ('out'), ('outside'), ('over'), ('overall'), ('own');
58:             INSERT INTO %fts_schema%.stopwords VALUES ('p'), ('particular'), ('particularly'), ('per'), ('perhaps'), ('placed'), ('please'), ('plus'), ('possible'), ('presumably'), ('probably'), ('provides'), ('q'), ('que'), ('quite'), ('qv'), ('r'), ('rather'), ('rd'), ('re'), ('really'), ('reasonably'), ('regarding'), ('regardless'), ('regards'), ('relatively'), ('respectively'), ('right'), ('s'), ('said'), ('same'), ('saw'), ('say'), ('saying'), ('says'), ('second'), ('secondly'), ('see'), ('seeing'), ('seem'), ('seemed'), ('seeming'), ('seems'), ('seen'), ('self'), ('selves'), ('sensible'), ('sent'), ('serious'), ('seriously'), ('seven'), ('several'), ('shall'), ('she'), ('should'), ('shouldn''t'), ('since'), ('six'), ('so'), ('some'), ('somebody'), ('somehow'), ('someone'), ('something'), ('sometime'), ('sometimes'), ('somewhat'), ('somewhere'), ('soon'), ('sorry'), ('specified'), ('specify'), ('specifying'), ('still'), ('sub'), ('such'), ('sup'), ('sure'), ('t'), ('t''s'), ('take'), ('taken'), ('tell'), ('tends'), ('th'), ('than'), ('thank'), ('thanks'), ('thanx'), ('that'), ('that''s'), ('thats'), ('the'), ('their'), ('theirs'), ('them'), ('themselves'), ('then'), ('thence'), ('there'), ('there''s'), ('thereafter'), ('thereby'), ('therefore'), ('therein'), ('theres'), ('thereupon'), ('these'), ('they'), ('they''d'), ('they''ll'), ('they''re'), ('they''ve'), ('think'), ('third'), ('this'), ('thorough'), ('thoroughly'), ('those'), ('though'), ('three'), ('through'), ('throughout'), ('thru'), ('thus'), ('to'), ('together'), ('too'), ('took'), ('toward'), ('towards'), ('tried'), ('tries'), ('truly'), ('try'), ('trying'), ('twice'), ('two'), ('u'), ('un'), ('under'), ('unfortunately'), ('unless'), ('unlikely'), ('until'), ('unto'), ('up'), ('upon'), ('us'), ('use'), ('used'), ('useful'), ('uses'), ('using'), ('usually'), ('uucp'), ('v'), ('value'), ('various'), ('very'), ('via'), ('viz'), ('vs'), ('w'), ('want'), ('wants'), ('was'), ('wasn''t'), ('way'), ('we'), ('we''d'), ('we''ll'), ('we''re'), ('we''ve'), ('welcome'), ('well'), ('went'), ('were'), ('weren''t'), ('what'), ('what''s'), ('whatever'), ('when'), ('whence'), ('whenever'), ('where'), ('where''s'), ('whereafter'), ('whereas'), ('whereby'), ('wherein'), ('whereupon'), ('wherever'), ('whether'), ('which'), ('while'), ('whither'), ('who'), ('who''s'), ('whoever'), ('whole'), ('whom'), ('whose'), ('why'), ('will'), ('willing'), ('wish'), ('with'), ('within'), ('without'), ('won''t'), ('wonder'), ('would'), ('would'), ('wouldn''t'), ('x'), ('y'), ('yes'), ('yet'), ('you'), ('you''d'), ('you''ll'), ('you''re'), ('you''ve'), ('your'), ('yours'), ('yourself'), ('yourselves'), ('z'), ('zero');
59:         )";
60: 		// clang-format on
61: 	} else {
62: 		// custom stopwords
63: 		result += "INSERT INTO %fts_schema%.stopwords SELECT * FROM " + stopwords + ";";
64: 	}
65: 
66: 	// create tokenize macro based on parameters
67: 	string tokenize = "s::VARCHAR";
68: 	vector<string> before;
69: 	vector<string> after;
70: 	if (strip_accents) {
71: 		tokenize = "strip_accents(" + tokenize + ")";
72: 	}
73: 	if (lower) {
74: 		tokenize = "lower(" + tokenize + ")";
75: 	}
76: 	tokenize = "regexp_replace(" + tokenize + ", $$" + ignore + "$$, " + "' ', 'g')";
77: 	tokenize = "string_split_regex(" + tokenize + ", '\\s+')";
78: 	result += "CREATE MACRO %fts_schema%.tokenize(s) AS " + tokenize + ";";
79: 
80: 	// parameterized definition of indexing and retrieval model
81: 	// clang-format off
82: 	result += R"(
83:         CREATE TABLE %fts_schema%.docs AS (
84:             SELECT rowid AS docid,
85:                    "%input_id%" AS name
86:             FROM %input_table%
87:         );
88: 
89: 	    CREATE TABLE %fts_schema%.fields (fieldid BIGINT, field VARCHAR);
90: 	    INSERT INTO %fts_schema%.fields VALUES %field_values%;
91: 
92:         CREATE TABLE %fts_schema%.terms AS
93:         WITH tokenized AS (
94:             %union_fields_query%
95:         ),
96: 	    stemmed_stopped AS (
97:             SELECT stem(t.w, '%stemmer%') AS term,
98: 	               t.docid AS docid,
99:                    t.fieldid AS fieldid
100: 	        FROM tokenized AS t
101: 	        WHERE t.w NOT NULL
102:               AND len(t.w) > 0
103: 	          AND t.w NOT IN (SELECT sw FROM %fts_schema%.stopwords)
104:         )
105: 	    SELECT ss.term,
106: 	           ss.docid,
107: 	           ss.fieldid
108:         FROM stemmed_stopped AS ss;
109: 
110:         ALTER TABLE %fts_schema%.docs ADD len BIGINT;
111:         UPDATE %fts_schema%.docs d
112:         SET len = (
113:             SELECT count(term)
114:             FROM %fts_schema%.terms AS t
115:             WHERE t.docid = d.docid
116:         );
117: 
118:         CREATE TABLE %fts_schema%.dict AS
119:         WITH distinct_terms AS (
120:             SELECT DISTINCT term
121:             FROM %fts_schema%.terms
122:             ORDER BY docid, term
123:         )
124:         SELECT row_number() OVER () - 1 AS termid,
125:                dt.term
126:         FROM distinct_terms AS dt;
127: 
128:         ALTER TABLE %fts_schema%.terms ADD termid BIGINT;
129:         UPDATE %fts_schema%.terms t
130:         SET termid = (
131:             SELECT termid
132:             FROM %fts_schema%.dict d
133:             WHERE t.term = d.term
134:         );
135:         ALTER TABLE %fts_schema%.terms DROP term;
136: 
137:         ALTER TABLE %fts_schema%.dict ADD df BIGINT;
138:         UPDATE %fts_schema%.dict d
139:         SET df = (
140:             SELECT count(distinct docid)
141:             FROM %fts_schema%.terms t
142:             WHERE d.termid = t.termid
143:             GROUP BY termid
144:         );
145: 
146:         CREATE TABLE %fts_schema%.stats AS (
147:             SELECT COUNT(docs.docid) AS num_docs,
148:                    SUM(docs.len) / COUNT(docs.len) AS avgdl
149:             FROM %fts_schema%.docs AS docs
150:         );
151: 
152:         CREATE MACRO %fts_schema%.match_bm25(docname, query_string, fields := NULL, k := 1.2, b := 0.75, conjunctive := false) AS (
153:             WITH tokens AS (
154:                 SELECT DISTINCT stem(unnest(%fts_schema%.tokenize(query_string)), '%stemmer%') AS t
155:             ),
156:             fieldids AS (
157:                 SELECT fieldid
158:                 FROM %fts_schema%.fields
159:                 WHERE CASE WHEN fields IS NULL THEN 1 ELSE field IN (SELECT * FROM (SELECT UNNEST(string_split(fields, ','))) AS fsq) END
160:             ),
161:             qtermids AS (
162:                 SELECT termid
163:                 FROM %fts_schema%.dict AS dict,
164:                      tokens
165:                 WHERE dict.term = tokens.t
166:             ),
167:             qterms AS (
168:                 SELECT termid,
169:                        docid
170:                 FROM %fts_schema%.terms AS terms
171:                 WHERE CASE WHEN fields IS NULL THEN 1 ELSE fieldid IN (SELECT * FROM fieldids) END
172:                   AND termid IN (SELECT qtermids.termid FROM qtermids)
173:             ),
174: 			term_tf AS (
175: 				SELECT termid,
176: 				   	   docid,
177:                        COUNT(*) AS tf
178: 				FROM qterms
179: 				GROUP BY docid,
180: 						 termid
181: 			),
182: 			cdocs AS (
183: 				SELECT docid
184: 				FROM qterms
185: 				GROUP BY docid
186: 				HAVING CASE WHEN conjunctive THEN COUNT(DISTINCT termid) = (SELECT COUNT(*) FROM tokens) ELSE 1 END
187: 			),
188:             subscores AS (
189:                 SELECT docs.docid,
190:                        len,
191:                        term_tf.termid,
192:                        tf,
193:                        df,
194:                        (log(((SELECT num_docs FROM %fts_schema%.stats) - df + 0.5) / (df + 0.5) + 1) * ((tf * (k + 1)/(tf + k * (1 - b + b * (len / (SELECT avgdl FROM %fts_schema%.stats))))))) AS subscore
195:                 FROM term_tf,
196: 					 cdocs,
197: 					 %fts_schema%.docs AS docs,
198: 					 %fts_schema%.dict AS dict
199: 				WHERE term_tf.docid = cdocs.docid
200: 				  AND term_tf.docid = docs.docid
201:                   AND term_tf.termid = dict.termid
202:             ),
203: 			scores AS (
204: 				SELECT docid,
205: 					   sum(subscore) AS score
206: 				FROM subscores
207: 				GROUP BY docid
208: 			)
209:             SELECT score
210:             FROM scores,
211: 				 %fts_schema%.docs AS docs
212:             WHERE scores.docid = docs.docid
213:               AND docs.name = docname
214:         );
215:     )";
216: 
217:     // we may have more than 1 input field, therefore we union over the fields, retaining information which field it came from
218: 	string tokenize_field_query = R"(
219:         SELECT unnest(%fts_schema%.tokenize(fts_ii."%input_value%")) AS w,
220: 	           rowid AS docid,
221: 	           (SELECT fieldid FROM %fts_schema%.fields WHERE field = '%input_value%') AS fieldid
222:         FROM %input_table% AS fts_ii
223:     )";
224: 	// clang-format on
225: 	vector<string> field_values;
226: 	vector<string> tokenize_fields;
227: 	for (idx_t i = 0; i < input_values.size(); i++) {
228: 		field_values.push_back(StringUtil::Format("(%i, '%s')", i, input_values[i]));
229: 		tokenize_fields.push_back(StringUtil::Replace(tokenize_field_query, "%input_value%", input_values[i]));
230: 	}
231: 	result = StringUtil::Replace(result, "%field_values%", StringUtil::Join(field_values, ", "));
232: 	result = StringUtil::Replace(result, "%union_fields_query%", StringUtil::Join(tokenize_fields, " UNION ALL "));
233: 
234: 	string fts_schema = GetFTSSchema(qname);
235: 	string input_table = qname.catalog == INVALID_CATALOG ? "" : StringUtil::Format("%s.", qname.catalog);
236: 	input_table += StringUtil::Format("%s.%s", qname.schema, qname.name);
237: 
238: 	// fill in variables (inefficiently, but keeps SQL script readable)
239: 	result = StringUtil::Replace(result, "%fts_schema%", fts_schema);
240: 	result = StringUtil::Replace(result, "%input_table%", input_table);
241: 	result = StringUtil::Replace(result, "%input_id%", input_id);
242: 	result = StringUtil::Replace(result, "%stemmer%", stemmer);
243: 
244: 	return result;
245: }
246: 
247: static void CheckIfTableExists(ClientContext &context, QualifiedName &qname) {
248: 	Catalog::GetEntry<TableCatalogEntry>(context, qname.catalog, qname.schema, qname.name);
249: }
250: 
251: string FTSIndexing::CreateFTSIndexQuery(ClientContext &context, const FunctionParameters &parameters) {
252: 	auto qname = GetQualifiedName(context, StringValue::Get(parameters.values[0]));
253: 	CheckIfTableExists(context, qname);
254: 
255: 	// get named parameters
256: 	string stemmer = "porter";
257: 	auto stemmer_entry = parameters.named_parameters.find("stemmer");
258: 	if (stemmer_entry != parameters.named_parameters.end()) {
259: 		stemmer = StringValue::Get(stemmer_entry->second);
260: 	}
261: 
262: 	string stopwords = "english";
263: 	auto stopword_entry = parameters.named_parameters.find("stopwords");
264: 	if (stopword_entry != parameters.named_parameters.end()) {
265: 		stopwords = StringValue::Get(stopword_entry->second);
266: 		if (stopwords != "english" && stopwords != "none") {
267: 			auto stopwords_qname = GetQualifiedName(context, stopwords);
268: 			CheckIfTableExists(context, stopwords_qname);
269: 		}
270: 	}
271: 
272: 	string ignore = "[0-9!@#$%^&*()_+={}\\[\\]:;<>,.?~\\\\/\\|''\"`-]+";
273: 	auto ignore_entry = parameters.named_parameters.find("ignore");
274: 	if (ignore_entry != parameters.named_parameters.end()) {
275: 		ignore = StringValue::Get(ignore_entry->second);
276: 	}
277: 
278: 	bool strip_accents = true;
279: 	auto strip_accents_entry = parameters.named_parameters.find("strip_accents");
280: 	if (strip_accents_entry != parameters.named_parameters.end()) {
281: 		strip_accents = BooleanValue::Get(strip_accents_entry->second);
282: 	}
283: 
284: 	bool lower = true;
285: 	auto lower_entry = parameters.named_parameters.find("lower");
286: 	if (lower_entry != parameters.named_parameters.end()) {
287: 		lower = BooleanValue::Get(lower_entry->second);
288: 	}
289: 
290: 	bool overwrite = false;
291: 	auto overwrite_entry = parameters.named_parameters.find("overwrite");
292: 	if (overwrite_entry != parameters.named_parameters.end()) {
293: 		overwrite = BooleanValue::Get(overwrite_entry->second);
294: 	}
295: 
296: 	// throw error if an index already exists on this table
297: 	const string fts_schema = GetFTSSchema(qname);
298: 	if (Catalog::GetSchema(context, qname.catalog, fts_schema, OnEntryNotFound::RETURN_NULL) && !overwrite) {
299: 		throw CatalogException("a FTS index already exists on table '%s.%s'. Supply 'overwrite=1' to overwrite, or "
300: 		                       "drop the existing index with 'PRAGMA drop_fts_index()' before creating a new one.",
301: 		                       qname.schema, qname.name);
302: 	}
303: 
304: 	// positional parameters
305: 	auto doc_id = StringValue::Get(parameters.values[1]);
306: 	// check all specified columns
307: 	auto &table = Catalog::GetEntry<TableCatalogEntry>(context, qname.catalog, qname.schema, qname.name);
308: 	vector<string> doc_values;
309: 	for (idx_t i = 2; i < parameters.values.size(); i++) {
310: 		string col_name = StringValue::Get(parameters.values[i]);
311: 		if (col_name == "*") {
312: 			// star found - get all columns
313: 			doc_values.clear();
314: 			for (auto &cd : table.GetColumns().Logical()) {
315: 				if (cd.Type() == LogicalType::VARCHAR) {
316: 					doc_values.push_back(cd.Name());
317: 				}
318: 			}
319: 			break;
320: 		}
321: 		if (!table.ColumnExists(col_name)) {
322: 			// we check this here because else we we end up with an error halfway the indexing script
323: 			throw CatalogException("Table '%s.%s' does not have a column named '%s'!", qname.schema, qname.name,
324: 			                       col_name);
325: 		}
326: 		doc_values.push_back(col_name);
327: 	}
328: 	if (doc_values.empty()) {
329: 		throw InvalidInputException("at least one column must be supplied for indexing!");
330: 	}
331: 
332: 	return IndexingScript(context, qname, doc_id, doc_values, stemmer, stopwords, ignore, strip_accents, lower);
333: }
334: 
335: } // namespace duckdb
[end of extension/fts/fts_indexing.cpp]
[start of extension/fts/include/fts_extension.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // fts_extension.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb.hpp"
12: 
13: namespace duckdb {
14: 
15: class FtsExtension : public Extension {
16: public:
17: 	void Load(DuckDB &db) override;
18: 	std::string Name() override;
19: 	std::string Version() const override;
20: };
21: 
22: } // namespace duckdb
[end of extension/fts/include/fts_extension.hpp]
[start of extension/fts/include/fts_indexing.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // fts_indexing.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/main/client_context.hpp"
12: 
13: namespace duckdb {
14: 
15: struct FTSIndexing {
16: 	static string DropFTSIndexQuery(ClientContext &context, const FunctionParameters &parameters);
17: 	static string CreateFTSIndexQuery(ClientContext &context, const FunctionParameters &parameters);
18: };
19: 
20: } // namespace duckdb
[end of extension/fts/include/fts_indexing.hpp]
[start of extension/fts/indexing.sql]
1: DROP SCHEMA IF EXISTS %fts_schema% CASCADE;
2: CREATE SCHEMA %fts_schema%;
3: CREATE MACRO %fts_schema%.tokenize(s) AS stem(unnest(string_split_regex(regexp_replace(lower(strip_accents(s)), '[^a-z]', ' ', 'g'), '\s+')), '%stemmer%');
4: 
5: CREATE TABLE %fts_schema%.docs AS (
6:     SELECT
7:         row_number() OVER (PARTITION BY(SELECT NULL)) AS docid,
8:         %input_id% AS name
9:     FROM
10:         %input_schema%.%input_table%
11: );
12: 
13: CREATE TABLE %fts_schema%.terms AS (
14:     SELECT
15:         term,
16:         docid,
17:         row_number() OVER (PARTITION BY docid) AS pos
18:     FROM (
19:         SELECT
20:             %fts_schema%.tokenize(%input_val%) AS term,
21:             row_number() OVER (PARTITION BY (SELECT NULL)) AS docid
22:         FROM %input_schema%.%input_table%
23:     ) AS sq
24:     WHERE
25:         term != ''
26: );
27: 
28: ALTER TABLE %fts_schema%.docs ADD len INT;
29: UPDATE %fts_schema%.docs d
30: SET len = (
31:     SELECT count(term)
32:     FROM %fts_schema%.terms t
33:     WHERE t.docid = d.docid
34: );
35: 
36: CREATE TABLE %fts_schema%.dict AS
37: WITH distinct_terms AS (
38:     SELECT DISTINCT term, docid
39:     FROM %fts_schema%.terms
40:     ORDER BY docid
41: )
42: SELECT
43:     row_number() OVER (PARTITION BY (SELECT NULL)) AS termid,
44:     term
45: FROM
46:     distinct_terms;
47: 
48: ALTER TABLE %fts_schema%.terms ADD termid INT;
49: UPDATE %fts_schema%.terms t
50: SET termid = (
51:     SELECT termid
52:     FROM %fts_schema%.dict d
53:     WHERE t.term = d.term
54: );
55: ALTER TABLE %fts_schema%.terms DROP term;
56: 
57: ALTER TABLE %fts_schema%.dict ADD df INT;
58: UPDATE %fts_schema%.dict d
59: SET df = (
60:     SELECT count(distinct docid)
61:     FROM %fts_schema%.terms t
62:     WHERE d.termid = t.termid
63:     GROUP BY termid
64: );
65: 
66: CREATE TABLE %fts_schema%.stats AS (
67:     SELECT COUNT(docs.docid) AS num_docs, SUM(docs.len) / COUNT(docs.len) AS avgdl
68:     FROM %fts_schema%.docs AS docs
69: );
70: 
71: CREATE MACRO %fts_schema%.match_bm25(docname, query_string, k=1.2, b=0.75, conjunctive=0) AS docname IN (
72:     WITH tokens AS
73:         (SELECT DISTINCT %fts_schema%.tokenize(query_string) AS t),
74:     qtermids AS
75:         (SELECT termid FROM %fts_schema%.dict AS dict, tokens WHERE dict.term = tokens.t),
76:     qterms AS
77:         (SELECT termid, docid FROM %fts_schema%.terms AS terms WHERE termid IN (SELECT qtermids.termid FROM qtermids)),
78:     subscores AS (
79:         SELECT
80:             docs.docid, len, term_tf.termid, tf, df,
81:             (log(((SELECT num_docs FROM %fts_schema%.stats) - df + 0.5) / (df + 0.5))* ((tf * (k + 1)/(tf + k * (1 - b + b * (len / (SELECT avgdl FROM %fts_schema%.stats))))))) AS subscore
82:         FROM
83:             (SELECT termid, docid, COUNT(*) AS tf FROM qterms GROUP BY docid, termid) AS term_tf
84:         JOIN
85:             (SELECT docid FROM qterms GROUP BY docid HAVING CASE WHEN conjunctive THEN COUNT(DISTINCT termid) = (SELECT COUNT(*) FROM tokens) ELSE 1 END) AS cdocs
86:         ON
87:             term_tf.docid = cdocs.docid
88:         JOIN
89:             %fts_schema%.docs AS docs
90:         ON
91:             term_tf.docid = docs.docid
92:         JOIN
93:             %fts_schema%.dict AS dict
94:         ON
95:             term_tf.termid = dict.termid
96:     )
97:     SELECT name
98:     FROM (SELECT docid, sum(subscore) AS score FROM subscores GROUP BY docid) AS scores
99:     JOIN %fts_schema%.docs AS docs
100:     ON scores.docid = docs.docid ORDER BY score DESC LIMIT 1000
101: );
[end of extension/fts/indexing.sql]
[start of src/main/extension/extension_helper.cpp]
1: #include "duckdb/main/extension_helper.hpp"
2: 
3: #include "duckdb/common/file_system.hpp"
4: #include "duckdb/common/serializer/binary_deserializer.hpp"
5: #include "duckdb/common/serializer/buffered_file_reader.hpp"
6: #include "duckdb/common/string_util.hpp"
7: #include "duckdb/common/windows.hpp"
8: #include "duckdb/main/client_context.hpp"
9: #include "duckdb/main/database.hpp"
10: #include "duckdb/main/extension.hpp"
11: #include "duckdb/main/extension_install_info.hpp"
12: 
13: // Note that c++ preprocessor doesn't have a nice way to clean this up so we need to set the defines we use to false
14: // explicitly when they are undefined
15: #ifndef DUCKDB_EXTENSION_CORE_FUNCTIONS_LINKED
16: #define DUCKDB_EXTENSION_CORE_FUNCTIONS_LINKED false
17: #endif
18: 
19: #ifndef DUCKDB_EXTENSION_ICU_LINKED
20: #define DUCKDB_EXTENSION_ICU_LINKED false
21: #endif
22: 
23: #ifndef DUCKDB_EXTENSION_EXCEL_LINKED
24: #define DUCKDB_EXTENSION_EXCEL_LINKED false
25: #endif
26: 
27: #ifndef DUCKDB_EXTENSION_PARQUET_LINKED
28: #define DUCKDB_EXTENSION_PARQUET_LINKED false
29: #endif
30: 
31: #ifndef DUCKDB_EXTENSION_TPCH_LINKED
32: #define DUCKDB_EXTENSION_TPCH_LINKED false
33: #endif
34: 
35: #ifndef DUCKDB_EXTENSION_TPCDS_LINKED
36: #define DUCKDB_EXTENSION_TPCDS_LINKED false
37: #endif
38: 
39: #ifndef DUCKDB_EXTENSION_FTS_LINKED
40: #define DUCKDB_EXTENSION_FTS_LINKED false
41: #endif
42: 
43: #ifndef DUCKDB_EXTENSION_HTTPFS_LINKED
44: #define DUCKDB_EXTENSION_HTTPFS_LINKED false
45: #endif
46: 
47: #ifndef DUCKDB_EXTENSION_JSON_LINKED
48: #define DUCKDB_EXTENSION_JSON_LINKED false
49: #endif
50: 
51: #ifndef DUCKDB_EXTENSION_JEMALLOC_LINKED
52: #define DUCKDB_EXTENSION_JEMALLOC_LINKED false
53: #endif
54: 
55: #ifndef DUCKDB_EXTENSION_AUTOCOMPLETE_LINKED
56: #define DUCKDB_EXTENSION_AUTOCOMPLETE_LINKED false
57: #endif
58: 
59: // Load the generated header file containing our list of extension headers
60: #if defined(GENERATED_EXTENSION_HEADERS) && GENERATED_EXTENSION_HEADERS && !defined(DUCKDB_AMALGAMATION)
61: #include "duckdb/main/extension/generated_extension_loader.hpp"
62: #else
63: // TODO: rewrite package_build.py to allow also loading out-of-tree extensions in non-cmake builds, after that
64: //		 these can be removed
65: #if DUCKDB_EXTENSION_CORE_FUNCTIONS_LINKED
66: #include "core_functions_extension.hpp"
67: #endif
68: 
69: #if DUCKDB_EXTENSION_ICU_LINKED
70: #include "icu_extension.hpp"
71: #endif
72: 
73: #if DUCKDB_EXTENSION_PARQUET_LINKED
74: #include "parquet_extension.hpp"
75: #endif
76: 
77: #if DUCKDB_EXTENSION_TPCH_LINKED
78: #include "tpch_extension.hpp"
79: #endif
80: 
81: #if DUCKDB_EXTENSION_TPCDS_LINKED
82: #include "tpcds_extension.hpp"
83: #endif
84: 
85: #if DUCKDB_EXTENSION_FTS_LINKED
86: #include "fts_extension.hpp"
87: #endif
88: 
89: #if DUCKDB_EXTENSION_HTTPFS_LINKED
90: #include "httpfs_extension.hpp"
91: #endif
92: 
93: #if DUCKDB_EXTENSION_JSON_LINKED
94: #include "json_extension.hpp"
95: #endif
96: 
97: #if DUCKDB_EXTENSION_JEMALLOC_LINKED
98: #include "jemalloc_extension.hpp"
99: #endif
100: 
101: #if DUCKDB_EXTENSION_AUTOCOMPLETE_LINKED
102: #include "autocomplete_extension.hpp"
103: #endif
104: 
105: #endif
106: 
107: namespace duckdb {
108: 
109: //===--------------------------------------------------------------------===//
110: // Default Extensions
111: //===--------------------------------------------------------------------===//
112: static const DefaultExtension internal_extensions[] = {
113:     {"core_functions", "Core function library", DUCKDB_EXTENSION_CORE_FUNCTIONS_LINKED},
114:     {"icu", "Adds support for time zones and collations using the ICU library", DUCKDB_EXTENSION_ICU_LINKED},
115:     {"excel", "Adds support for Excel-like format strings", DUCKDB_EXTENSION_EXCEL_LINKED},
116:     {"parquet", "Adds support for reading and writing parquet files", DUCKDB_EXTENSION_PARQUET_LINKED},
117:     {"tpch", "Adds TPC-H data generation and query support", DUCKDB_EXTENSION_TPCH_LINKED},
118:     {"tpcds", "Adds TPC-DS data generation and query support", DUCKDB_EXTENSION_TPCDS_LINKED},
119:     {"fts", "Adds support for Full-Text Search Indexes", DUCKDB_EXTENSION_FTS_LINKED},
120:     {"httpfs", "Adds support for reading and writing files over a HTTP(S) connection", DUCKDB_EXTENSION_HTTPFS_LINKED},
121:     {"json", "Adds support for JSON operations", DUCKDB_EXTENSION_JSON_LINKED},
122:     {"jemalloc", "Overwrites system allocator with JEMalloc", DUCKDB_EXTENSION_JEMALLOC_LINKED},
123:     {"autocomplete", "Adds support for autocomplete in the shell", DUCKDB_EXTENSION_AUTOCOMPLETE_LINKED},
124:     {"motherduck", "Enables motherduck integration with the system", false},
125:     {"mysql_scanner", "Adds support for connecting to a MySQL database", false},
126:     {"sqlite_scanner", "Adds support for reading and writing SQLite database files", false},
127:     {"postgres_scanner", "Adds support for connecting to a Postgres database", false},
128:     {"inet", "Adds support for IP-related data types and functions", false},
129:     {"spatial", "Geospatial extension that adds support for working with spatial data and functions", false},
130:     {"substrait", "Adds support for the Substrait integration", false},
131:     {"aws", "Provides features that depend on the AWS SDK", false},
132:     {"arrow", "A zero-copy data integration between Apache Arrow and DuckDB", false},
133:     {"azure", "Adds a filesystem abstraction for Azure blob storage to DuckDB", false},
134:     {"iceberg", "Adds support for Apache Iceberg", false},
135:     {"vss", "Adds indexing support to accelerate Vector Similarity Search", false},
136:     {"delta", "Adds support for Delta Lake", false},
137:     {nullptr, nullptr, false}};
138: 
139: idx_t ExtensionHelper::DefaultExtensionCount() {
140: 	idx_t index;
141: 	for (index = 0; internal_extensions[index].name != nullptr; index++) {
142: 	}
143: 	return index;
144: }
145: 
146: DefaultExtension ExtensionHelper::GetDefaultExtension(idx_t index) {
147: 	D_ASSERT(index < DefaultExtensionCount());
148: 	return internal_extensions[index];
149: }
150: 
151: //===--------------------------------------------------------------------===//
152: // Allow Auto-Install Extensions
153: //===--------------------------------------------------------------------===//
154: static const char *const auto_install[] = {"motherduck", "postgres_scanner", "mysql_scanner", "sqlite_scanner",
155:                                            nullptr};
156: 
157: // TODO: unify with new autoload mechanism
158: bool ExtensionHelper::AllowAutoInstall(const string &extension) {
159: 	auto lcase = StringUtil::Lower(extension);
160: 	for (idx_t i = 0; auto_install[i]; i++) {
161: 		if (lcase == auto_install[i]) {
162: 			return true;
163: 		}
164: 	}
165: 	return false;
166: }
167: 
168: bool ExtensionHelper::CanAutoloadExtension(const string &ext_name) {
169: #ifdef DUCKDB_DISABLE_EXTENSION_LOAD
170: 	return false;
171: #endif
172: 
173: 	if (ext_name.empty()) {
174: 		return false;
175: 	}
176: 	for (const auto &ext : AUTOLOADABLE_EXTENSIONS) {
177: 		if (ext_name == ext) {
178: 			return true;
179: 		}
180: 	}
181: 	return false;
182: }
183: 
184: string ExtensionHelper::AddExtensionInstallHintToErrorMsg(ClientContext &context, const string &base_error,
185:                                                           const string &extension_name) {
186: 
187: 	return AddExtensionInstallHintToErrorMsg(DatabaseInstance::GetDatabase(context), base_error, extension_name);
188: }
189: string ExtensionHelper::AddExtensionInstallHintToErrorMsg(DatabaseInstance &db, const string &base_error,
190:                                                           const string &extension_name) {
191: 	string install_hint;
192: 
193: 	auto &config = db.config;
194: 
195: 	if (!ExtensionHelper::CanAutoloadExtension(extension_name)) {
196: 		install_hint = "Please try installing and loading the " + extension_name + " extension:\nINSTALL " +
197: 		               extension_name + ";\nLOAD " + extension_name + ";\n\n";
198: 	} else if (!config.options.autoload_known_extensions) {
199: 		install_hint =
200: 		    "Please try installing and loading the " + extension_name + " extension by running:\nINSTALL " +
201: 		    extension_name + ";\nLOAD " + extension_name +
202: 		    ";\n\nAlternatively, consider enabling auto-install "
203: 		    "and auto-load by running:\nSET autoinstall_known_extensions=1;\nSET autoload_known_extensions=1;";
204: 	} else if (!config.options.autoinstall_known_extensions) {
205: 		install_hint =
206: 		    "Please try installing the " + extension_name + " extension by running:\nINSTALL " + extension_name +
207: 		    ";\n\nAlternatively, consider enabling autoinstall by running:\nSET autoinstall_known_extensions=1;";
208: 	}
209: 
210: 	if (!install_hint.empty()) {
211: 		return base_error + "\n\n" + install_hint;
212: 	}
213: 
214: 	return base_error;
215: }
216: 
217: bool ExtensionHelper::TryAutoLoadExtension(ClientContext &context, const string &extension_name) noexcept {
218: 	if (context.db->ExtensionIsLoaded(extension_name)) {
219: 		return true;
220: 	}
221: 	auto &dbconfig = DBConfig::GetConfig(context);
222: 	try {
223: 		if (dbconfig.options.autoinstall_known_extensions) {
224: 			auto &config = DBConfig::GetConfig(context);
225: 			auto autoinstall_repo = ExtensionRepository::GetRepositoryByUrl(
226: 			    StringValue::Get(config.GetSetting<AutoinstallExtensionRepositorySetting>(context)));
227: 			ExtensionInstallOptions options;
228: 			options.repository = autoinstall_repo;
229: 			ExtensionHelper::InstallExtension(context, extension_name, options);
230: 		}
231: 		ExtensionHelper::LoadExternalExtension(context, extension_name);
232: 		return true;
233: 	} catch (...) {
234: 		return false;
235: 	}
236: }
237: 
238: bool ExtensionHelper::TryAutoLoadExtension(DatabaseInstance &instance, const string &extension_name) noexcept {
239: 	if (instance.ExtensionIsLoaded(extension_name)) {
240: 		return true;
241: 	}
242: 	auto &dbconfig = DBConfig::GetConfig(instance);
243: 	try {
244: 		auto &fs = FileSystem::GetFileSystem(instance);
245: 		if (dbconfig.options.autoinstall_known_extensions) {
246: 			auto autoinstall_repo =
247: 			    ExtensionRepository::GetRepositoryByUrl(dbconfig.options.autoinstall_extension_repo);
248: 			ExtensionInstallOptions options;
249: 			options.repository = autoinstall_repo;
250: 			ExtensionHelper::InstallExtension(instance, fs, extension_name, options);
251: 		}
252: 		ExtensionHelper::LoadExternalExtension(instance, fs, extension_name);
253: 		return true;
254: 	} catch (...) {
255: 		return false;
256: 	}
257: }
258: 
259: static ExtensionUpdateResult UpdateExtensionInternal(ClientContext &context, DatabaseInstance &db, FileSystem &fs,
260:                                                      const string &full_extension_path, const string &extension_name) {
261: 	ExtensionUpdateResult result;
262: 	result.extension_name = extension_name;
263: 
264: 	auto &config = DBConfig::GetConfig(db);
265: 
266: 	if (!fs.FileExists(full_extension_path)) {
267: 		result.tag = ExtensionUpdateResultTag::NOT_INSTALLED;
268: 		return result;
269: 	}
270: 
271: 	// Extension exists, check for .info file
272: 	const string info_file_path = full_extension_path + ".info";
273: 	if (!fs.FileExists(info_file_path)) {
274: 		result.tag = ExtensionUpdateResultTag::MISSING_INSTALL_INFO;
275: 		return result;
276: 	}
277: 
278: 	// Parse the version of the extension before updating
279: 	auto ext_binary_handle = fs.OpenFile(full_extension_path, FileOpenFlags::FILE_FLAGS_READ);
280: 	auto parsed_metadata = ExtensionHelper::ParseExtensionMetaData(*ext_binary_handle);
281: 	if (!parsed_metadata.AppearsValid() && !config.options.allow_extensions_metadata_mismatch) {
282: 		throw IOException(
283: 		    "Failed to update extension: '%s', the metadata of the extension appears invalid! To resolve this, either "
284: 		    "reinstall the extension using 'FORCE INSTALL %s', manually remove the file '%s', or enable '"
285: 		    "SET allow_extensions_metadata_mismatch=true'",
286: 		    extension_name, extension_name, full_extension_path);
287: 	}
288: 
289: 	result.prev_version = parsed_metadata.AppearsValid() ? parsed_metadata.extension_version : "";
290: 
291: 	auto extension_install_info = ExtensionInstallInfo::TryReadInfoFile(fs, info_file_path, extension_name);
292: 
293: 	// Early out: no info file found
294: 	if (extension_install_info->mode == ExtensionInstallMode::UNKNOWN) {
295: 		result.tag = ExtensionUpdateResultTag::MISSING_INSTALL_INFO;
296: 		return result;
297: 	}
298: 
299: 	// Early out: we can only update extensions from repositories
300: 	if (extension_install_info->mode != ExtensionInstallMode::REPOSITORY) {
301: 		result.tag = ExtensionUpdateResultTag::NOT_A_REPOSITORY;
302: 		result.installed_version = result.prev_version;
303: 		return result;
304: 	}
305: 
306: 	auto repository_from_info = ExtensionRepository::GetRepositoryByUrl(extension_install_info->repository_url);
307: 	result.repository = repository_from_info.ToReadableString();
308: 
309: 	// Force install the full url found in this file, enabling etags to ensure efficient updating
310: 	ExtensionInstallOptions options;
311: 	options.repository = repository_from_info;
312: 	options.force_install = true;
313: 	options.use_etags = true;
314: 
315: 	unique_ptr<ExtensionInstallInfo> install_result;
316: 	try {
317: 		install_result = ExtensionHelper::InstallExtension(context, extension_name, options);
318: 	} catch (std::exception &e) {
319: 		ErrorData error(e);
320: 		error.Throw("Extension updating failed when trying to install '" + extension_name + "', original error: ");
321: 	}
322: 
323: 	result.installed_version = install_result->version;
324: 
325: 	if (result.installed_version.empty()) {
326: 		result.tag = ExtensionUpdateResultTag::REDOWNLOADED;
327: 	} else if (result.installed_version != result.prev_version) {
328: 		result.tag = ExtensionUpdateResultTag::UPDATED;
329: 	} else {
330: 		result.tag = ExtensionUpdateResultTag::NO_UPDATE_AVAILABLE;
331: 	}
332: 
333: 	return result;
334: }
335: 
336: vector<ExtensionUpdateResult> ExtensionHelper::UpdateExtensions(ClientContext &context) {
337: 	auto &fs = FileSystem::GetFileSystem(context);
338: 
339: 	vector<ExtensionUpdateResult> result;
340: 	DatabaseInstance &db = DatabaseInstance::GetDatabase(context);
341: 
342: #ifndef WASM_LOADABLE_EXTENSIONS
343: 	case_insensitive_set_t seen_extensions;
344: 
345: 	// scan the install directory for installed extensions
346: 	auto ext_directory = ExtensionHelper::ExtensionDirectory(db, fs);
347: 	fs.ListFiles(ext_directory, [&](const string &path, bool is_directory) {
348: 		if (!StringUtil::EndsWith(path, ".duckdb_extension")) {
349: 			return;
350: 		}
351: 
352: 		auto extension_file_name = StringUtil::GetFileName(path);
353: 		auto extension_name = StringUtil::Split(extension_file_name, ".")[0];
354: 
355: 		seen_extensions.insert(extension_name);
356: 
357: 		result.push_back(UpdateExtensionInternal(context, db, fs, fs.JoinPath(ext_directory, path), extension_name));
358: 	});
359: #endif
360: 
361: 	return result;
362: }
363: 
364: ExtensionUpdateResult ExtensionHelper::UpdateExtension(ClientContext &context, const string &extension_name) {
365: 	auto &fs = FileSystem::GetFileSystem(context);
366: 	DatabaseInstance &db = DatabaseInstance::GetDatabase(context);
367: 	auto ext_directory = ExtensionHelper::ExtensionDirectory(db, fs);
368: 
369: 	auto full_extension_path = fs.JoinPath(ext_directory, extension_name + ".duckdb_extension");
370: 
371: 	auto update_result = UpdateExtensionInternal(context, db, fs, full_extension_path, extension_name);
372: 
373: 	if (update_result.tag == ExtensionUpdateResultTag::NOT_INSTALLED) {
374: 		throw InvalidInputException("Failed to update the extension '%s', the extension is not installed!",
375: 		                            extension_name);
376: 	} else if (update_result.tag == ExtensionUpdateResultTag::UNKNOWN) {
377: 		throw InternalException("Failed to update extension '%s', an unknown error occurred", extension_name);
378: 	}
379: 	return update_result;
380: }
381: 
382: void ExtensionHelper::AutoLoadExtension(ClientContext &context, const string &extension_name) {
383: 	return ExtensionHelper::AutoLoadExtension(*context.db, extension_name);
384: }
385: 
386: void ExtensionHelper::AutoLoadExtension(DatabaseInstance &db, const string &extension_name) {
387: 	if (db.ExtensionIsLoaded(extension_name)) {
388: 		// Avoid downloading again
389: 		return;
390: 	}
391: 	auto &dbconfig = DBConfig::GetConfig(db);
392: 	try {
393: 		auto fs = FileSystem::CreateLocal();
394: #ifndef DUCKDB_WASM
395: 		if (dbconfig.options.autoinstall_known_extensions) {
396: 			//! Get the autoloading repository
397: 			auto repository = ExtensionRepository::GetRepositoryByUrl(dbconfig.options.autoinstall_extension_repo);
398: 			ExtensionInstallOptions options;
399: 			options.repository = repository;
400: 			ExtensionHelper::InstallExtension(db, *fs, extension_name, options);
401: 		}
402: #endif
403: 		ExtensionHelper::LoadExternalExtension(db, *fs, extension_name);
404: 	} catch (std::exception &e) {
405: 		ErrorData error(e);
406: 		throw AutoloadException(extension_name, error.RawMessage());
407: 	}
408: }
409: 
410: //===--------------------------------------------------------------------===//
411: // Load Statically Compiled Extension
412: //===--------------------------------------------------------------------===//
413: void ExtensionHelper::LoadAllExtensions(DuckDB &db) {
414: 	// The in-tree extensions that we check. Non-cmake builds are currently limited to these for static linking
415: 	// TODO: rewrite package_build.py to allow also loading out-of-tree extensions in non-cmake builds, after that
416: 	//		 these can be removed
417: 	vector<string> extensions {"parquet", "icu",   "tpch", "tpcds",    "fts",          "httpfs",
418: 	                           "json",    "excel", "inet", "jemalloc", "autocomplete", "core_functions"};
419: 	for (auto &ext : extensions) {
420: 		LoadExtensionInternal(db, ext, true);
421: 	}
422: 
423: #if defined(GENERATED_EXTENSION_HEADERS) && GENERATED_EXTENSION_HEADERS
424: 	for (const auto &ext : LinkedExtensions()) {
425: 		LoadExtensionInternal(db, ext, true);
426: 	}
427: #endif
428: }
429: 
430: ExtensionLoadResult ExtensionHelper::LoadExtension(DuckDB &db, const std::string &extension) {
431: 	return LoadExtensionInternal(db, extension, false);
432: }
433: 
434: ExtensionLoadResult ExtensionHelper::LoadExtensionInternal(DuckDB &db, const std::string &extension,
435:                                                            bool initial_load) {
436: #ifdef DUCKDB_TEST_REMOTE_INSTALL
437: 	if (!initial_load && StringUtil::Contains(DUCKDB_TEST_REMOTE_INSTALL, extension)) {
438: 		Connection con(db);
439: 		auto result = con.Query("INSTALL " + extension);
440: 		if (result->HasError()) {
441: 			result->Print();
442: 			return ExtensionLoadResult::EXTENSION_UNKNOWN;
443: 		}
444: 		result = con.Query("LOAD " + extension);
445: 		if (result->HasError()) {
446: 			result->Print();
447: 			return ExtensionLoadResult::EXTENSION_UNKNOWN;
448: 		}
449: 		return ExtensionLoadResult::LOADED_EXTENSION;
450: 	}
451: #endif
452: 
453: #ifdef DUCKDB_EXTENSIONS_TEST_WITH_LOADABLE
454: 	// Note: weird comma's are on purpose to do easy string contains on a list of extension names
455: 	if (!initial_load && StringUtil::Contains(DUCKDB_EXTENSIONS_TEST_WITH_LOADABLE, "," + extension + ",")) {
456: 		Connection con(db);
457: 		auto result = con.Query((string) "LOAD '" + DUCKDB_EXTENSIONS_BUILD_PATH + "/" + extension + "/" + extension +
458: 		                        ".duckdb_extension'");
459: 		if (result->HasError()) {
460: 			result->Print();
461: 			return ExtensionLoadResult::EXTENSION_UNKNOWN;
462: 		}
463: 		return ExtensionLoadResult::LOADED_EXTENSION;
464: 	}
465: #endif
466: 
467: 	// This is the main extension loading mechanism that loads the extension that are statically linked.
468: #if defined(GENERATED_EXTENSION_HEADERS) && GENERATED_EXTENSION_HEADERS
469: 	if (TryLoadLinkedExtension(db, extension)) {
470: 		return ExtensionLoadResult::LOADED_EXTENSION;
471: 	} else {
472: 		return ExtensionLoadResult::NOT_LOADED;
473: 	}
474: #endif
475: 
476: 	// This is the fallback to the "old" extension loading mechanism for non-cmake builds
477: 	// TODO: rewrite package_build.py to allow also loading out-of-tree extensions in non-cmake builds
478: 	if (extension == "parquet") {
479: #if DUCKDB_EXTENSION_PARQUET_LINKED
480: 		db.LoadStaticExtension<ParquetExtension>();
481: #else
482: 		// parquet extension required but not build: skip this test
483: 		return ExtensionLoadResult::NOT_LOADED;
484: #endif
485: 	} else if (extension == "icu") {
486: #if DUCKDB_EXTENSION_ICU_LINKED
487: 		db.LoadStaticExtension<IcuExtension>();
488: #else
489: 		// icu extension required but not build: skip this test
490: 		return ExtensionLoadResult::NOT_LOADED;
491: #endif
492: 	} else if (extension == "tpch") {
493: #if DUCKDB_EXTENSION_TPCH_LINKED
494: 		db.LoadStaticExtension<TpchExtension>();
495: #else
496: 		// icu extension required but not build: skip this test
497: 		return ExtensionLoadResult::NOT_LOADED;
498: #endif
499: 	} else if (extension == "tpcds") {
500: #if DUCKDB_EXTENSION_TPCDS_LINKED
501: 		db.LoadStaticExtension<TpcdsExtension>();
502: #else
503: 		// icu extension required but not build: skip this test
504: 		return ExtensionLoadResult::NOT_LOADED;
505: #endif
506: 	} else if (extension == "fts") {
507: #if DUCKDB_EXTENSION_FTS_LINKED
508: //		db.LoadStaticExtension<FtsExtension>();
509: #else
510: 		// fts extension required but not build: skip this test
511: 		return ExtensionLoadResult::NOT_LOADED;
512: #endif
513: 	} else if (extension == "httpfs") {
514: #if DUCKDB_EXTENSION_HTTPFS_LINKED
515: 		db.LoadStaticExtension<HttpfsExtension>();
516: #else
517: 		return ExtensionLoadResult::NOT_LOADED;
518: #endif
519: 	} else if (extension == "json") {
520: #if DUCKDB_EXTENSION_JSON_LINKED
521: 		db.LoadStaticExtension<JsonExtension>();
522: #else
523: 		// json extension required but not build: skip this test
524: 		return ExtensionLoadResult::NOT_LOADED;
525: #endif
526: 	} else if (extension == "excel") {
527: #if DUCKDB_EXTENSION_EXCEL_LINKED
528: 		db.LoadStaticExtension<ExcelExtension>();
529: #else
530: 		// excel extension required but not build: skip this test
531: 		return ExtensionLoadResult::NOT_LOADED;
532: #endif
533: 	} else if (extension == "jemalloc") {
534: #if DUCKDB_EXTENSION_JEMALLOC_LINKED
535: 		db.LoadStaticExtension<JemallocExtension>();
536: #else
537: 		// jemalloc extension required but not build: skip this test
538: 		return ExtensionLoadResult::NOT_LOADED;
539: #endif
540: 	} else if (extension == "autocomplete") {
541: #if DUCKDB_EXTENSION_AUTOCOMPLETE_LINKED
542: 		db.LoadStaticExtension<AutocompleteExtension>();
543: #else
544: 		// autocomplete extension required but not build: skip this test
545: 		return ExtensionLoadResult::NOT_LOADED;
546: #endif
547: 	} else if (extension == "inet") {
548: #if DUCKDB_EXTENSION_INET_LINKED
549: 		db.LoadStaticExtension<InetExtension>();
550: #else
551: 		// inet extension required but not build: skip this test
552: 		return ExtensionLoadResult::NOT_LOADED;
553: #endif
554: 	} else if (extension == "core_functions") {
555: #if DUCKDB_EXTENSION_CORE_FUNCTIONS_LINKED
556: 		db.LoadStaticExtension<CoreFunctionsExtension>();
557: #else
558: 		// core_functions extension required but not build: skip this test
559: 		return ExtensionLoadResult::NOT_LOADED;
560: #endif
561: 	}
562: 
563: 	return ExtensionLoadResult::LOADED_EXTENSION;
564: }
565: 
566: static const char *const public_keys[] = {
567:     R"(
568: -----BEGIN PUBLIC KEY-----
569: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA6aZuHUa1cLR9YDDYaEfi
570: UDbWY8m2t7b71S+k1ZkXfHqu+5drAxm+dIDzdOHOKZSIdwnJbT3sSqwFoG6PlXF3
571: g3dsJjax5qESIhbVvf98nyipwNINxoyHCkcCIPkX17QP2xpnT7V59+CqcfDJXLqB
572: ymjqoFSlaH8dUCHybM4OXlWnAtVHW/nmw0khF8CetcWn4LxaTUHptByaBz8CasSs
573: gWpXgSfaHc3R9eArsYhtsVFGyL/DEWgkEHWolxY3Llenhgm/zOf3s7PsAMe7EJX4
574: qlSgiXE6OVBXnqd85z4k20lCw/LAOe5hoTMmRWXIj74MudWe2U91J6GrrGEZa7zT
575: 7QIDAQAB
576: -----END PUBLIC KEY-----
577: )",
578:     R"(
579: -----BEGIN PUBLIC KEY-----
580: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAq8Gg1S/LI6ApMAYsFc9m
581: PrkFIY+nc0LXSpxm77twU8D5M0Xkz/Av4f88DQmj1OE3164bEtR7sl7xDPZojFHj
582: YYyucJxEI97l5OU1d3Pc1BdKXL4+mnW5FlUGj218u8qD+G1hrkySXQkrUzIjPPNw
583: o6knF3G/xqQF+KI+tc7ajnTni8CAlnUSxfnstycqbVS86m238PLASVPK9/SmIRgO
584: XCEV+ZNMlerq8EwsW4cJPHH0oNVMcaG+QT4z79roW1rbJghn9ubAVdQU6VLUAikI
585: b8keUyY+D0XdY9DpDBeiorb1qPYt8BPLOAQrIUAw1CgpMM9KFp9TNvW47KcG4bcB
586: dQIDAQAB
587: -----END PUBLIC KEY-----
588: )",
589:     R"(
590: -----BEGIN PUBLIC KEY-----
591: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAyYATA9KOQ0Azf97QAPfY
592: Jc/WeZyE4E1qlRgKWKqNtYSXZqk5At0V7w2ntAWtYSpczFrVepCJ0oPMDpZTigEr
593: NgOgfo5LEhPx5XmtCf62xY/xL3kgtfz9Mm5TBkuQy4KwY4z1npGr4NYYDXtF7kkf
594: LQE+FnD8Yr4E0wHBib7ey7aeeKWmwqvUjzDqG+TzaqwzO/RCUsSctqSS0t1oo2hv
595: 4q1ofanUXsV8MXk/ujtgxu7WkVvfiSpK1zRazgeZjcrQFO9qL/pla0vBUxa1U8He
596: GMLnL0oRfcMg7yKrbIMrvlEl2ZmiR9im44dXJWfY42quObwr1PuEkEoCMcMisSWl
597: jwIDAQAB
598: -----END PUBLIC KEY-----
599: )",
600:     R"(
601: -----BEGIN PUBLIC KEY-----
602: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA4RvbWx3zLblDHH/lGUF5
603: Q512MT+v3YPriuibROMllv8WiCLAMeJ0QXbVaIzBOeHDeLx8yvoZZN+TENKxtT6u
604: IfMMneUzxHBqy0AQNfIsSsOnG5nqoeE/AwbS6VqCdH1aLfoCoPffacHYa0XvTcsi
605: aVlZfr+UzJS+ty8pRmFVi1UKSOADDdK8XfIovJl/zMP2TxYX2Y3fnjeLtl8Sqs2e
606: P+eHDoy7Wi4EPTyY7tNTCfxwKNHn1HQ5yrv5dgvMxFWIWXGz24yikFvtwLGHe8uJ
607: Wi+fBX+0PF0diZ6pIthZ149VU8qCqYAXjgpxZ0EZdrsiF6Ewz0cfg20SYApFcmW4
608: pwIDAQAB
609: -----END PUBLIC KEY-----
610: )",
611:     R"(
612: -----BEGIN PUBLIC KEY-----
613: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAyhd5AfwrUohG3O4DE0K9
614: O3FmgB7zE4aDnkL8UUfGCh5kdP8q7ewMjekY+c6LwWOmpdJpSwqhfV1q5ZU1l6rk
615: 3hlt03LO3sgs28kcfOVH15hqfxts6Sg5KcRjxStE50ORmXGwXDcS9vqkJ60J1EHA
616: lcZqbCRSO73ZPLhdepfd0/C6tM0L7Ge6cAE62/MTmYNGv8fDzwQr/kYIJMdoS8Zp
617: thRpctFZJtPs3b0fffZA/TCLVKMvEVgTWs48751qKid7N/Lm/iEGx/tOf4o23Nec
618: Pz1IQaGLP+UOLVQbqQBHJWNOqigm7kWhDgs3N4YagWgxPEQ0WVLtFji/ZjlKZc7h
619: dwIDAQAB
620: -----END PUBLIC KEY-----
621: )",
622:     R"(
623: -----BEGIN PUBLIC KEY-----
624: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAnFDg3LhyV6BVE2Z3zQvN
625: 6urrKvPhygTa5+wIPGwYTzJ8DfGALqlsX3VOXMvcJTca6SbuwwkoXHuSU5wQxfcs
626: bt4jTXD3NIoRwQPl+D9IbgIMuX0ACl27rJmr/f9zkY7qui4k1X82pQkxBe+/qJ4r
627: TBwVNONVx1fekTMnSCEhwg5yU3TNbkObu0qlQeJfuMWLDQbW/8v/qfr/Nz0JqHDN
628: yYKfKvFMlORxyJYiOyeOsbzNGEhkGQGOmKhRUhS35kD+oA0jqwPwMCM9O4kFg/L8
629: iZbpBBX2By1K3msejWMRAewTOyPas6YMQOYq9BMmWQqzVtG5xcaSJwN/YnMpJyqb
630: sQIDAQAB
631: -----END PUBLIC KEY-----
632: )",
633:     R"(
634: -----BEGIN PUBLIC KEY-----
635: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA1z0RU8vGrfEkrscEoZKA
636: GiOcGh2EMcKwjQpl4nKuR9H4o/dg+CZregVSHg7MP2f8mhLZZyoFev49oWOV4Rmi
637: qs99UNxm7DyKW1fF1ovowsUW5lsDoKYLvpuzHo0s4laiV4AnIYP7tHGLdzsnK2Os
638: Cp5dSuMwKHPZ9N25hXxFB/dRrAdIiXHvbSqr4N29XzfQloQpL3bGHLKY6guFHluH
639: X5dJ9eirVakWWou7BR2rnD0k9vER6oRdVnJ6YKb5uhWEOQ3NmV961oyr+uiDTcep
640: qqtGHWuFhENixtiWGjFJJcACwqxEAW3bz9lyrfnPDsHSW/rlQVDIAkik+fOp+R7L
641: kQIDAQAB
642: -----END PUBLIC KEY-----
643: )",
644:     R"(
645: -----BEGIN PUBLIC KEY-----
646: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxwO27e1vnbNcpiDg7Wwx
647: K/w5aEGukXotu3529ieq+O39H0+Bak4vIbzGhDUh3/ElmxaFMAs4PYrWe/hc2WFD
648: H4JCOoFIn4y9gQeE855DGGFgeIVd1BnSs5S+5wUEMxLNyHdHSmINN6FsoZ535iUg
649: KdYjRh1iZevezg7ln8o/O36uthu925ehFBXSy6jLJgQlwmq0KxZJE0OAZhuDBM60
650: MtIunNa/e5y+Gw3GknFwtRLmn/nEckZx1nEtepYvvUa7UGy+8KuGuhOerCZTutbG
651: k8liCVgGenRve8unA2LrBbpL+AUf3CrZU/uAxxTqWmw6Z/S6TeW5ozeeyOCh8ii6
652: TwIDAQAB
653: -----END PUBLIC KEY-----
654: )",
655:     R"(
656: -----BEGIN PUBLIC KEY-----
657: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAsGIFOfIQ4RI5qu4klOxf
658: ge6eXwBMAkuTXyhyIIJDtE8CurnwQvUXVlt+Kf0SfuIFW6MY5ErcWE/vMFbc81IR
659: 9wByOAAV2CTyiLGZT63uE8pN6FSHd6yGYCLjXd3P3cnP3Qj5pBncpLuAUDfHG4wP
660: bs9jIADw3HysD+eCNja8p7ZC7CzWxTcO7HsEu9deAAU19YywdpagXvQ0pJ9zV5qU
661: jrHxBygl31t6TmmX+3d+azjGu9Hu36E+5wcSOOhuwAFXDejb40Ixv53ItJ3fZzzH
662: PF2nj9sQvQ8c5ptjyOvQCBRdqkEWXIVHClxqWb+o59pDIh1G0UGcmiDN7K9Gz5HA
663: ZQIDAQAB
664: -----END PUBLIC KEY-----
665: )",
666:     R"(
667: -----BEGIN PUBLIC KEY-----
668: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAt9uUnlW/CoUXT68yaZh9
669: SeXHzGRCPNEI98Tara+dgYxDX1z7nfOh8o15liT0QsAzx34EewZOxcKCNiV/dZX5
670: z4clCkD8uUbZut6IVx8Eu+7Qcd5jZthRc6hQrN9Ltv7ZQEh7KGXOHa53kT2K01ws
671: 4jbVmd/7Nx7y0Yyqhja01pIu/CUaTkODfQxBXwriLdIzp7y/iJeF/TLqCwZWHKQx
672: QOZnsPEveB1F00Va9MeAtTlXFUJ/TQXquqTjeLj4HuIRtbyuNgWoc0JyF+mcafAl
673: bnrNEBIfxZhAT81aUCIAzRJp6AqfdeZxnZ/WwohtZQZLXAxFQPTWCcP+Z9M7OIQL
674: WwIDAQAB
675: -----END PUBLIC KEY-----
676: )",
677:     R"(
678: -----BEGIN PUBLIC KEY-----
679: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA56NhfACkeCyZM07l2wmd
680: iTp24E2tLLKU3iByKlIRWRAvXsOejRMJTHTNHWa3cQ7uLP++Tf2St7ksNsyPMNZy
681: 9QRTLNCYr9rN9loLwdb2sMWxFBwwzCaAOTahGI7GJQy30UB7FEND0X/5U2rZvQij
682: Q6K+O4aa+K9M5qyOHNMmXywmTnAgWKNaNxQHPRtD2+dSj60T6zXdtIuCrPfcNGg5
683: gj07qWGEXX83V/L7nSqCiIVYg/wqds1x52Yjk1nhXYNBTqlnhmOd8LynGxz/sXC7
684: h2Q9XsHjXIChW4FHyLIOl6b4zPMBSxzCigYm3QZJWfAkZv5PBRtnq7vhYOLHzLQj
685: CwIDAQAB
686: -----END PUBLIC KEY-----
687: )",
688:     R"(
689: -----BEGIN PUBLIC KEY-----
690: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAmfPLe0IWGYC0MZC6YiM3
691: QGfhT6zSKB0I2DW44nlBlWUcF+32jW2bFJtgE76qGGKFeU4kJBWYr99ufHoAodNg
692: M1Ehl/JfQ5KmbC1WIqnFTrgbmqJde79jeCvCpbFLuqnzidwO1PbXDbfRFQcgWaXT
693: mDVLNNVmLxA0GkCv+kydE2gtcOD9BDceg7F/56TDvclyI5QqAnjE2XIRMPZlXQP4
694: oF2kgz4Cn7LxLHYmkU2sS9NYLzHoyUqFplWlxkQjA4eQ0neutV1Ydmc1IX8W7R38
695: A7nFtaT8iI8w6Vkv7ijYN6xf5cVBPKZ3Dv7AdwPet86JD5mf5v+r7iwg5xl3r77Z
696: iwIDAQAB
697: -----END PUBLIC KEY-----
698: )",
699:     R"(
700: -----BEGIN PUBLIC KEY-----
701: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAoB1kWsX8YmCcFOD9ilBY
702: xK076HmUAN026uJ8JpmU9Hz+QT1FNXOsnj1h2G6U6btYVIdHUTHy/BvAumrDKqRz
703: qcEAzCuhxUjPjss54a/Zqu6nQcoIPHuG/Er39oZHIVkPR1WCvWj8wmyYv6T//dPH
704: unO6tW29sXXxS+J1Gah6vpbtJw1pI/liah1DZzb13KWPDI6ZzviTNnW4S05r6js/
705: 30He+Yud6aywrdaP/7G90qcrteEFcjFy4Xf+5vG960oKoGoDplwX5poay1oCP9tb
706: g8AC8VSRAGi3oviTeSWZcrLXS8AtJhGvF48cXQj2q+8YeVKVDpH6fPQxJ9Sh9aeU
707: awIDAQAB
708: -----END PUBLIC KEY-----
709: )",
710:     R"(
711: -----BEGIN PUBLIC KEY-----
712: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA4NTMAIYIlCMID00ufy/I
713: AZXc8pocDx9N1Q5x5/cL3aIpLmx02AKo9BvTJaJuHiTjlwYhPtlhIrHV4HUVTkOX
714: sISp8B8v9i2I1RIvCTAcvy3gcH6rdRWZ0cdTUiMEqnnxBX9zdzl8oMzZcyauv19D
715: BeqJvzflIT96b8g8K3mvgJHs9a1j9f0gN8FuTA0c52DouKnrh8UwH7mlrumYerJw
716: 6goJGQuK1HEOt6bcQuvogkbgJWOoEYwjNrPwQvIcP4wyrgSnOHg1yXOFE84oVynJ
717: czQEOz9ke42I3h8wrnQxilEYBVo2uX8MenqTyfGnE32lPRt3Wv1iEVQls8Cxiuy2
718: CQIDAQAB
719: -----END PUBLIC KEY-----
720: )",
721:     R"(
722: -----BEGIN PUBLIC KEY-----
723: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA3bUtfp66OtRyvIF/oucn
724: id8mo7gvbNEH04QMLO3Ok43dlWgWI3hekJAqOYc0mvoI5anqr98h8FI7aCYZm/bY
725: vpz0I1aXBaEPh3aWh8f/w9HME7ykBvmhMe3J+VFGWWL4eswfRl//GCtnSMBzDFhM
726: SaQOTvADWHkC0njeI5yXjf/lNm6fMACP1cnhuvCtnx7VP/DAtvUk9usDKG56MJnZ
727: UoVM3HHjbJeRwxCdlSWe12ilCdwMRKSDY92Hk38/zBLenH04C3HRQLjBGewACUmx
728: uvNInehZ4kSYFGa+7UxBxFtzJhlKzGR73qUjpWzZivCe1K0WfRVP5IWsKNCCESJ/
729: nQIDAQAB
730: -----END PUBLIC KEY-----
731: )",
732:     R"(
733: -----BEGIN PUBLIC KEY-----
734: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAyV2dE/CRUAUE8ybq/DoS
735: Lc7QlYXh04K+McbhN724TbHahLTuDk5mR5TAunA8Nea4euRzknKdMFAz1eh9gyy3
736: 5x4UfXQW1fIZqNo6WNrGxYJgWAXU+pov+OvxsMQWzqS4jrTHDHbblCCLKp1akwJk
737: aFNyqgjAL373PcqXC+XAn8vHx4xHFoFP5lq4lLcJCOW5ee9v9El3w0USLwS+t1cF
738: RY3kuV6Njlr4zsRH9iM6/zaSuCALYWJ/JrPEurSJXzFZnWsvn6aQdeNeAn08+z0F
739: k2NwaauEo0xmLqzqTRGzjHqKKmeefN3/+M/FN2FrApDlxWQfhD2Y3USdAiN547Nj
740: 1wIDAQAB
741: -----END PUBLIC KEY-----
742: )",
743:     R"(
744: -----BEGIN PUBLIC KEY-----
745: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvm2+kTrEQWZXuxhWzBdl
746: PCbQGqbrukbeS6JKSlQLJDC8ayZIxFxatqg1Q8UPyv89MVRsHOGlG1OqFaOEtPjQ
747: Oo6j/moFwB4GPyJhJHOGpCKa4CLB5clhfDCLJw6ty7PcDU3T6yW4X4Qc5k4LRRWy
748: yzC8lVHfBdarN+1iEe0ALMOGoeiJjVn6i/AFxktRwgd8njqv/oWQyfjJZXkNMsb6
749: 7ZDxNVAUrp/WXpE4Kq694bB9xa/pWsqv7FjQJUgTnEzvbN+qXnVPtA7dHcOYYJ8Z
750: SbrJUfHrf8TS5B54AiopFpWG+hIbjqqdigqabBqFpmjiRDZgDy4zJJj52xJZMnrp
751: rwIDAQAB
752: -----END PUBLIC KEY-----
753: )",
754:     R"(
755: -----BEGIN PUBLIC KEY-----
756: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwEAcVmY3589O02pLA22f
757: MlarLyJUgy0BeJDG5AUsi17ct8sHZzRiv9zKQVCBk1CtZY//jyqnrM7iCBLWsyby
758: TiTOtGYHHApaLnNjjtaHdQ6zplhbc3g2XLy+4ab8GNKG3zc8iXpsQM6r+JO5n9pm
759: V9vollz9dkFxS9l+1P17lZdIgCh9O3EIFJv5QCd5c9l2ezHAan2OhkWhiDtldnH/
760: MfRXbz7X5sqlwWLa/jhPtvY45x7dZaCHGqNzbupQZs0vHnAVdDu3vAWDmT/3sXHG
761: vmGxswKA9tPU0prSvQWLz4LUCnGi/cC5R+fiu+fovFM/BwvaGtqBFIF/1oWVq7bZ
762: 4wIDAQAB
763: -----END PUBLIC KEY-----
764: )",
765:     R"(
766: -----BEGIN PUBLIC KEY-----
767: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA25qGwNO1+qHygC8mjm8L
768: 3I66mV/IzslgBDHC91mE8YcI5Fq0sdrtsbUhK3z89wIN/zOhbHX0NEiXm2GxUnsI
769: vb5tDZXAh7AbTnXTMVbxO/e/8sPLUiObGjDvjVzyzrxOeG87yK/oIiilwk9wTsIb
770: wMn2Grj4ht9gVKx3oGHYV7STNdWBlzSaJj4Ou7+5M1InjPDRFZG1K31D2d3IHByX
771: lmcRPZtPFTa5C1uVJw00fI4F4uEFlPclZQlR5yA0G9v+0uDgLcjIUB4eqwMthUWc
772: dHhlmrPp04LI19eksWHCtG30RzmUaxDiIC7J2Ut0zHDqUe7aXn8tOVI7dE9tTKQD
773: KQIDAQAB
774: -----END PUBLIC KEY-----
775: )",
776:     R"(
777: -----BEGIN PUBLIC KEY-----
778: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA7EC2bx7aRnf3TcRg5gmw
779: QOKNCUheCelK8hoXLMsKSJqmufyJ+IHUejpXGOpvyYRbACiJ5GiNcww20MVpTBU7
780: YESWB2QSU2eEJJXMq84qsZSO8WGmAuKpUckI+hNHKQYJBEDOougV6/vVVEm5c5bc
781: SLWQo0+/ciQ21Zwz5SwimX8ep1YpqYirO04gcyGZzAfGboXRvdUwA+1bZvuUXdKC
782: 4zsCw2QALlcVpzPwjB5mqA/3a+SPgdLAiLOwWXFDRMnQw44UjsnPJFoXgEZiUpZm
783: EMS5gLv50CzQqJXK9mNzPuYXNUIc4Pw4ssVWe0OfN3Od90gl5uFUwk/G9lWSYnBN
784: 3wIDAQAB
785: -----END PUBLIC KEY-----
786: )", nullptr};
787: 
788: static const char *const community_public_keys[] = {
789:     R"(
790: -----BEGIN PUBLIC KEY-----
791: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAtXl28loGwAH3ZGQXXgJQ
792: 3omhIEiUb3z9Petjl+jmdtEQnMNUFEZiXkfJB02UFWBL1OoKKnjiGhcr5oGiIZKR
793: CoaL6SfmWe//7o8STM44stE0exzZcv8W4tWwjrzSWQnwh2JgSnHN64xoDQjdvG3X
794: 9uQ1xXMXghWOKqEpgArpJQkHoPW3CD5sCS2NLFrBG6KgX0W+GTV5HaKhTMr2754F
795: l260drcBJZhLFCeesze2DXtQC+R9D25Zwn2ehHHd2Fd1M10ZL/iKN8NeerB4Jnph
796: w6E3orA0DusDLDLtpJUHhmpLoU/1eYQFQOpGw2ce5I88Tkx7SKnCRy1UiE7BA82W
797: YQIDAQAB
798: -----END PUBLIC KEY-----
799: )",
800:     R"(
801: -----BEGIN PUBLIC KEY-----
802: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvTgQ+mJs8vG/TQTJ6sV+
803: tACTZTbmp8NkgTuwEyHZSNhX6W8FYwAqPzbePo7wudsUdBWV8j+kUYaBiqeiPUp0
804: 7neO/3oTUQkMJLq9FeIXfoYkS3+/5CIuvsfas6PJP9U2ge6MV1Ndgbd7a12cmX8V
805: 4eNwQRDv/H4zgL7YI2ZZSG1loxgMffZrpflNB87t/f0QYdmnwphMC5RqxiCkDZPA
806: a5/5KbmD6kjLh8RRRw3lAZbPQe5r7o2Xqqwg9gc6rQ/WFBB1Oj+Q5Bggqznl6dCB
807: JcLOA7rhYatv/mvt1h6ogQwQ9FGRM3PifV9boZxOQGBAkMD6ngpd5kVoOxdygC7v
808: twIDAQAB
809: -----END PUBLIC KEY-----
810: )",
811:     R"(
812: -----BEGIN PUBLIC KEY-----
813: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA7KvnA+Ixj4ZCLR+aXSFz
814: ICGbQdVrZ/hhjImDQcWgWY+z/bEbybslDvy5KEPrxTNxKZ0VfFFAVEUj2cw8B5KI
815: naK8U2VIpdD6LpEJvkOuWKg3bym4COhyAcRNqKKu/GPzS90wICJ2aaayF1mVoCIL
816: dsp2ZShSIVRJa55gVvfRN1ZEkqBnZryKNt/h3DNqqq2Sn3n3HIZ8H9oEO+L+2Efe
817: kyET7o9OHy6QZXhf4SJ8QlQAwxxe/L4bln8CBlBHKrUNNqxpjhC37EnY2jpuu3a9
818: EZcNFj8R4qIJx7hcltntZyKrEIXqc6I6x4oZ4qhZj3RQ5Lr+pJ++idoc1LmBS3k5
819: yQIDAQAB
820: -----END PUBLIC KEY-----
821: )",
822:     R"(
823: -----BEGIN PUBLIC KEY-----
824: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA7SF+5RZ9jXyruBkhxhk2
825: BSWPbohevxxv++7Uw0HXC/3Xw4jzii0tYaJ6O8QWXyggEAkvmONblAN1rfiz+h5M
826: oJUQwHjTTZ8BmKUmWrNayVokUXLu4IpCAHk4uSXfx4U/AINnNfWW7z8mUJf6nGsM
827: XePuKPBRUsw+JmTWOXEIVrkc/66B+gpgi+DwRFLUPh96D8XRAhp7QbHE9UMD3HpA
828: mPMX7ICVsVS+NGdCHNsdWfH4noaESjgmMdApKekgeeo8Zu1pvQ3y8iew1xOQVBoR
829: V+PCGWAJYB7ulqBBkRz+NhPLWw7wRA4yLNcZVlZuDFxH9EoavWdfIyYYUn4efSz9
830: tQIDAQAB
831: -----END PUBLIC KEY-----
832: )",
833:     R"(
834: -----BEGIN PUBLIC KEY-----
835: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAszmZ6Slv/oJvFpOLtSMx
836: 58AKMia9y+qcVfw77/Alb3b+Qi5L2uy6nHfJElT7RIeeXhJ8mFglZ70MecTfj0jl
837: 5WhW+yMg6jmPCJL2JMt/oeC4iY4Cf/3C9RHU4IO13VN4dnVQ5S+SEEmSbXnno9Pe
838: 06yyVgZeJ0REJMV1JZj9gOPc/wbeLHsx4UC5qsu32Ammy6J7tS+k7JvRc9CPOEpe
839: IhWoZmpONydcI6IRfyH2xl4uLY3hWDrRei0I2zGH45G2hPNeTtRh27t+SzXO7h9j
840: y072CgHytRgQBiH711i8fe4bHMmtVPhPjFrbuzbJSgE7SyikrWIHMDsnPz443bdR
841: cQIDAQAB
842: -----END PUBLIC KEY-----
843: )",
844:     R"(
845: -----BEGIN PUBLIC KEY-----
846: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAleywAb7xZKYTFE08gGA9
847: ffTeYPRcECl/J060fUziIiFu0NHTOZO+a4BH2X+E1WjjNNQkbn00g+op4nqg3/U+
848: UaKuXNjWY2Rvd8s91fUD0YOdRpPmsTm2QqhgmYYzO8Oh3YXBNRpXaqALbjL9Nahw
849: YEAsI3o5yenZGUIEk3JaZFHsAZPL5wGgDVpZgmVUHJ0EO8N5LQh01aHxnP5+ey2z
850: L5h6IdWLubb07wEBk5bnmIvdhd6dIBzUql27BAqvxKJbW0/okjrhIgcIANDCavfV
851: L8UP7MCGnfozK7VIl5DG85gCQVAD8+lGUDzOuhzZjl7XKpkFAIWaS8pl4AJbJuG8
852: nwIDAQAB
853: -----END PUBLIC KEY-----
854: )",
855:     R"(
856: -----BEGIN PUBLIC KEY-----
857: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxiKgcR7Kb1CGTNczbuX+
858: S7OFpnVLDD5XGVKvYWxL+2By2QRFPWtMs8c24omLIgZ/CWBFPraMiNKS4+V9ar2C
859: wJhToJnAOKyayA0Gw2wNZx1mgHAZ/5mT+ImfkmZu2HPwtzJmJDQlESD4p40BWBNa
860: ZpWFGPMKn4GqvOOSGevC/r9inXm6NaPkM+B/piVDEgiJ7g/kpoqImmNb/c2/3XG5
861: 3kbDIHdbd2m3A3jWCjNGSANKsR5C0/rZtvsA8tjDlNWIuKmkU3C2nfj3UduU4dNP
862: Cisod/pDY8ov0U9sdkM9XZsTXjtbAIGLzMshmOv4ajRFUueGnsZW0GRqp9DSnKmj
863: 2QIDAQAB
864: -----END PUBLIC KEY-----
865: )",
866:     R"(
867: -----BEGIN PUBLIC KEY-----
868: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAuh334hUmJcdDJUSmeXqE
869: GUfGnASD2QrnuoS+gsXgW5BQW8YMDFASvADQhoDUdcwZMlAF+p+CxKCX/gBp40nC
870: 5eyPXv1e0K6PFcCdHtJq8MhGYAr1sy+7cOpzv0r9whobYUykGoHjdwZeu3VbA3uz
871: go80oYQlwY+v4zZFafCz3cXw8u7n/9PlddgeqHuIPsNZLocICuBUxwg5rHTzycg2
872: Pa68CRselONGN12V0/wlOg+NZpKCym58CM9SS/0v4YZ6LnmINo8gdRYnGE2zhvey
873: pHR8IJ8WSJXbl8NwyIY1AmtT/Z0dbAclfD8Wt/w5KA/sttnQzrB7fPsLRyLP1Alq
874: iQIDAQAB
875: -----END PUBLIC KEY-----
876: )",
877:     R"(
878: -----BEGIN PUBLIC KEY-----
879: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvWuRMEbez/Ud2o/0KA04
880: K9u3HePWud9rEqMsPv2HlclH3k+cezoUJzVre0lopv3R4aG3LDoFETrgGgUVrfPG
881: z3Zh7vyk0kb4IGkv+kLQu/cWQXyNzigxV+WQnpIWQ28vrP45y5f+GhwwgzFaDAQR
882: u1o1HH1FEnP7SSzHVvisNTecY95+F5AOvtOOUg4VlegXdUeGZHEza/0D9V8gODPL
883: DzbOJDDiqX8ahhRnIZyGEg6y7QqftZFz7j0siCHTXXYJBOcPjD4TqTUNpGvBox44
884: wgLlLcDsZ/n2Ck4doLXxVz9F80VKOriHSk+qIwseykKVzWQDQTOMOsjCmQsDvram
885: RwIDAQAB
886: -----END PUBLIC KEY-----
887: )",
888:     R"(
889: -----BEGIN PUBLIC KEY-----
890: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAyJmGd1GuBv/WD80IcVyr
891: dZcmuYe/7azLuV1wsgtH4gsUx+ifUwLZUhLFGOTAPFitbFYPPdhQKncO+BcbvOIo
892: 9FGKj9jGVpMU6C+0JQfi+koESevtO1tYzG8c2dMOGNUO0Hlj2Hezm3tZY4nAbo1J
893: DYqQSY7qvOYZPFvOS/zL+q2vMx93w9jDHJK4iU02ovAqK9xCWfTp4W7rtbDeTgiX
894: W/75rMG8DWI1ZHA2JXAOFPsiOHa0/yyvCvUIWvRuNHqTTN5NFiJRIcbTCKKbNwNM
895: xcNkBQCx4xwOqD9TkDbHpBOC/pfW7j3ygJdYRjFFqm10+KwPACYo/f0n4n4DI8Zz
896: twIDAQAB
897: -----END PUBLIC KEY-----
898: )",
899:     R"(
900: -----BEGIN PUBLIC KEY-----
901: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAnmxbunsK+2pL8Cva9F8E
902: 9o/dQ35TuIqcgpl9/oIc++x+6G5/8UT5mgGCQTITJRIAPnHsZ9XEnMxTAuSCDkYG
903: CA3JMl1MT7Zxu8TQJBPiXxOaAE1UmA13JuQ2Uu0v7T6TucQxR9KMvcdCxOZ5cBU4
904: uyJObnZVy/WjM2vWcWDUaYGfMss3eYxcDpavspBANdtSZfv11+8/VC+gEGBOe+oW
905: zDR+BlQx//MAzwSP5HVQcmLHsT073IvkoUWJUxSCCwlLe60ylpY16BLT6dB0RU8B
906: sxFcIwmYg0kq19EEPPvZLvRKjG/TJRm1MFzOE5LP2VxLGdMltWYEVsBZHTcWU7HR
907: 8wIDAQAB
908: -----END PUBLIC KEY-----
909: )",
910:     R"(
911: -----BEGIN PUBLIC KEY-----
912: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAlo7eDZOpCptanajUtDK3
913: q8Q/ykxmDDw6lVSiLBm54zwMxaqfM+tV/xqalvIVv3BrucRkCs6H+R0bpd7XhbE5
914: a7ZFSrWCBf1V6y/NZrEn4qcRbk/WsG4UFqu7CG4r+EgQ4nmoIH/A5+e8FUcur3Y8
915: 2ie9Foi1CUpZojWYZJeHKbb2yYn4MFHszEb5w9HVxY+i9jR1B8Rvn6OEK3OYDrtA
916: KnPXp4OiDx6CviYEmipX815PPj7Sv8KKL96JqGWjC4kYw6ALgV/GxiX++tv6rh2O
917: paW9MBv1y+5oZ8ls5S2T/LXbxDpjUEKC9guSSWmsPHRMxOumXsw0H43grC3Ce8Ui
918: CwIDAQAB
919: -----END PUBLIC KEY-----
920: )",
921:     R"(
922: -----BEGIN PUBLIC KEY-----
923: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA0ACgf0kJeQgDh+vHj2aj
924: K/6FQ794MknLxlwTARGlktoVwZgW/qc6vMZsILRUP1gb/gPXdpSTqqad/GLG4f5R
925: 1Ji1It6BniJOPWu1YyTz0C/BXzTGWbwPnIaawbpQE8n4A+tjGGvAoauPtzr0bWfV
926: XOXPfIW9XB51dcaVTZgHN55Y8Yd/Pcu9/lqXqXyE23tDLXR/QgGpwK9VxTSbRmuC
927: WspwqWY6L3MIw+3HIXERTM1uNhc9oHxMOCRbJmUghG0wCWB0ed3Xhbnl9mHlX+l1
928: rfCJAP4lVWKFjkKBNUejaf+WHxASMjrQubgHLZ2fpf3Ra8TfI3rgPABsAqEIFw3T
929: QwIDAQAB
930: -----END PUBLIC KEY-----
931: )",
932:     R"(
933: -----BEGIN PUBLIC KEY-----
934: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAt635/P50bMbEDTapjAQz
935: ARTb3y8jMHxVruX0tJU1tycmkX3J8tBALmc6TkSHNTJcQmR8L8Sj3h76l/vuL373
936: HFSGZ4xghBQqR1lUd2kVomoh+rzEte+0rHWm0JMhjmTQBx+AkDCOw4z3vi5AxWx0
937: 4EbYpQm2akVGKXQrQPyds0UirmdLACCH6WM6exgAXr75DB4PUpG85oI9Q+5ee1Km
938: +4atVJ4FNa6ZnjWccrlMYT0W7a0Y7feJPAPvfizrs2MG9/ijyBX34eCWA5dtUSIm
939: 2uqI6DxITZlLTvXVDSKQGlq5TEGMvRULWTatqWy4g+tOZ8rSbRuj32pcBnXlwuVu
940: 7QIDAQAB
941: -----END PUBLIC KEY-----
942: )",
943:     R"(
944: -----BEGIN PUBLIC KEY-----
945: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwqO3yWSLKqz1uQ54iFd/
946: VcQzgT6chLVuhktt7EFvi3tKaQqz2h2KPkDR+MssRV/BZ/41GNlR6r6p5CaPVDDe
947: Cuj5IcxrIFZIOBMBi1YZ/bknF9edJacINxNfGK/lXBNEAdUvxcOxX8WeP69uvl2l
948: SKyO3yAdx6HOyL9if95bYQD19HYPZzbfccPX1aD4pjnej6uMfd7yZErH7i8y0oj4
949: eSKSe1CisjFlR9NzRGO42jU9rtqnAFH9sK5wU9xKQ7bQwlz7yKBF2RuuQweMpXb6
950: lSObI7ZqYN+7jkf9F5hKRx4kX3+MMBeYmFOy1aYZ08u6sdJ2ua/hFNSDRg7e/UCe
951: AwIDAQAB
952: -----END PUBLIC KEY-----
953: )",
954:     R"(
955: -----BEGIN PUBLIC KEY-----
956: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAkJihnfMECaa6YCg6avam
957: cb8Sy1GshJ7c7+EW6C4vnspSSvEi04AEBB29pnEF9+VO6VSUHLxunVCpbmKFaLH+
958: 5fDLnc/wCkjPQww49da9MEScCmVGjROlmog65cxQbv4lfxyw55sFV3s/5CPcGlVc
959: 1gojHRABrx4YocpeYies04mEVoOYg1DBG4Uf+aFd5+hm3ZtBa4mqTK2iQa4ILkHa
960: a0/Us1drRuDjjI4zSbgRzy9x0JVDvqDdLubHyaEf7d7SdrKzodhydG84qpsPFxIj
961: LK7Bu5v7P4ZTJmxMG3PBM2kB//hlYVR4vO4VEu66mQIM6km+vT9cwxz77qIJhLn3
962: ywIDAQAB
963: -----END PUBLIC KEY-----
964: )",
965:     R"(
966: -----BEGIN PUBLIC KEY-----
967: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA9NbP7ijUxZh4j0NVF6yO
968: IZ0rzROwl4pP4HGeN+Woyi9+qpdE874WlVoquGEpsshF4Ojzbu2BtXuihb783awa
969: GLx66MYPeID1FjTKmuCJ2aluOP+DkVo6K1EoqVJXyeIxZzVSqhSIuAdb/vmPlgLz
970: Fzdk3FgNNOERuGV363DRGz1YxZVnJeSs76g+/9ddhMk8cqIRup5S4YgTOSr0vKem
971: 1E6lyE8IbLoq9J7w5Ur8VjzE2cI+eLKGFqr46Q8pf0pJq72gd+Z3mH5D2LmvEtAR
972: 9jAQXVlLfHauQR2M0K6mqDy9GxL19OU4tGO+GY86VvDTU+wZppAZRz9AKoL1fwfI
973: BQIDAQAB
974: -----END PUBLIC KEY-----
975: )",
976:     R"(
977: -----BEGIN PUBLIC KEY-----
978: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAjrI16GdC2zJriLbyzcre
979: AqvckBSTMd4bdGaodUBNBTBVbITsOw/k7D62y2hSZHt2nHOyEVkJINJHADrpNZuY
980: ybS4ssEXxD8+NnjATqQxDMuSz8lUj/Jnf49uzLh84fep3DTksDcQX6Nvio5q8Xbh
981: HRgvl5I+tPfLtme0oW9cVuVja2i5lHB3SzYCW9Kk/V4/d2WiceYf91a1Nae6m7QV
982: 5bmbYoHmsxT8refTQq+5lAhzVXYU9QRgiKdbE8sSmkV+YiZEtGijefUXgmOxx3I9
983: B3y03796WBS/RHpSzdMNJw/xPWJcSEMqaUdSYr0DuPCnrn7ojFeF/EFC47CBq5DU
984: swIDAQAB
985: -----END PUBLIC KEY-----
986: )",
987:     R"(
988: -----BEGIN PUBLIC KEY-----
989: MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAjS1+My6OhQCCD1DgrzKu
990: db4Fvc3aqqEhQyjqMLnalp0uoGFpSLoPsZiPGloTE8FSs1ZBFKQ8h2SsGwSdhRKF
991: xIqoOnS0B/ORjGJxTj7Q2YWjzkCZUD4Ul2AxIbv3TmZM2LeyHJL3A71tSuck8EQY
992: PE2aj1tLzXsSfRaByy5xwXiU6UpnwCY1xb8tK8QxavRCo5T9Si9tNsolStoNVXV0
993: k9EbTcRNnxCvab/oqjvgyRuSmIES00v8jZOGQZQUpw02RN6yCBeX2i8GPsGjj/T9
994: 6Gu1Z3G4zUjLlJxl8vjo8KIDaQ8NVWT0j7gx9Knvb5tWnAORI1aJA8AHQvaoOT1W
995: 1wIDAQAB
996: -----END PUBLIC KEY-----
997: )", nullptr};
998: 
999: const vector<string> ExtensionHelper::GetPublicKeys(bool allow_community_extensions) {
1000: 	vector<string> keys;
1001: 	for (idx_t i = 0; public_keys[i]; i++) {
1002: 		keys.emplace_back(public_keys[i]);
1003: 	}
1004: 	if (allow_community_extensions) {
1005: 		for (idx_t i = 0; community_public_keys[i]; i++) {
1006: 			keys.emplace_back(community_public_keys[i]);
1007: 		}
1008: 	}
1009: 	return keys;
1010: }
1011: 
1012: } // namespace duckdb
[end of src/main/extension/extension_helper.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: