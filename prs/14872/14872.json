{
  "repo": "duckdb/duckdb",
  "pull_number": 14872,
  "instance_id": "duckdb__duckdb-14872",
  "issue_numbers": [
    "14410"
  ],
  "base_commit": "810cfa4568ffb4b4019480287ab6a6e414b47cd7",
  "patch": "diff --git a/.github/config/bundled_extensions.cmake b/.github/config/bundled_extensions.cmake\nindex a738bdad8c04..900f578a3b82 100644\n--- a/.github/config/bundled_extensions.cmake\n+++ b/.github/config/bundled_extensions.cmake\n@@ -17,7 +17,6 @@\n duckdb_extension_load(icu)\n duckdb_extension_load(tpch)\n duckdb_extension_load(json)\n-duckdb_extension_load(fts)\n duckdb_extension_load(parquet)\n duckdb_extension_load(autocomplete)\n \ndiff --git a/.github/config/extensions.csv b/.github/config/extensions.csv\nindex 16a369cc25ea..5c08e305ae7d 100644\n--- a/.github/config/extensions.csv\n+++ b/.github/config/extensions.csv\n@@ -1,6 +1,5 @@\n name,url,commit,options\n excel,,,\n-fts,,,\n httpfs,,,\n icu,,,\n json,,,\n@@ -16,3 +15,4 @@ azure,https://github.com/duckdb/duckdb_azure,09623777a366572bfb8fa53e47acdf72133\n spatial,https://github.com/duckdb/duckdb_spatial,7ea79b614755d2bdee4be468691e4e17b39b8dbc,\n iceberg,https://github.com/duckdb/duckdb_iceberg,d89423c2ff90a0b98a093a133c8dfe2a55b9e092,\n vss,https://github.com/duckdb/duckdb_vss,96374099476b3427c9ab43c1821e610b0465c864,\n+fts,https://github.com/duckdb/duckdb_fts,0477abaf2484aa7b9aabf8ace9dc0bde80a15554,\n\\ No newline at end of file\ndiff --git a/.github/config/in_tree_extensions.cmake b/.github/config/in_tree_extensions.cmake\nindex 220b82d89a07..155fcdc6afc6 100644\n--- a/.github/config/in_tree_extensions.cmake\n+++ b/.github/config/in_tree_extensions.cmake\n@@ -7,7 +7,6 @@\n \n duckdb_extension_load(autocomplete)\n duckdb_extension_load(core_functions)\n-duckdb_extension_load(fts)\n duckdb_extension_load(httpfs)\n duckdb_extension_load(icu)\n duckdb_extension_load(json)\ndiff --git a/.github/config/out_of_tree_extensions.cmake b/.github/config/out_of_tree_extensions.cmake\nindex 89dbddec3340..18b888201a85 100644\n--- a/.github/config/out_of_tree_extensions.cmake\n+++ b/.github/config/out_of_tree_extensions.cmake\n@@ -163,3 +163,12 @@ if (NOT MINGW)\n             GIT_TAG f2a15013fb4559e1591e977c1c023aa0a369c6f3\n             )\n endif()\n+\n+################# FTS\n+duckdb_extension_load(fts\n+        LOAD_TESTS\n+        DONT_LINK\n+        GIT_URL https://github.com/duckdb/duckdb_fts\n+        GIT_TAG 0477abaf2484aa7b9aabf8ace9dc0bde80a15554\n+        TEST_DIR test/sql\n+)\ndiff --git a/.github/workflows/Main.yml b/.github/workflows/Main.yml\nindex 7e897cfd6f8c..02603d5dce65 100644\n--- a/.github/workflows/Main.yml\n+++ b/.github/workflows/Main.yml\n@@ -95,7 +95,7 @@ jobs:\n       CXX: g++-10\n       GEN: ninja\n       BUILD_JEMALLOC: 1\n-      CORE_EXTENSIONS: \"icu;parquet;tpch;tpcds;fts;json\"\n+      CORE_EXTENSIONS: \"icu;parquet;tpch;tpcds;json\"\n       RUN_SLOW_VERIFIERS: 1\n \n     steps:\n@@ -134,7 +134,7 @@ jobs:\n       CXX: g++-10\n       GEN: ninja\n       BUILD_JEMALLOC: 1\n-      CORE_EXTENSIONS: \"icu;parquet;tpch;tpcds;fts;json\"\n+      CORE_EXTENSIONS: \"icu;parquet;tpch;tpcds;json\"\n \n     steps:\n     - uses: actions/checkout@v4\ndiff --git a/extension/fts/CMakeLists.txt b/extension/fts/CMakeLists.txt\ndeleted file mode 100644\nindex 40b3696919d7..000000000000\n--- a/extension/fts/CMakeLists.txt\n+++ /dev/null\n@@ -1,51 +0,0 @@\n-cmake_minimum_required(VERSION 2.8.12...3.29)\n-\n-project(FTSExtension)\n-\n-include_directories(include ../../third_party/snowball/libstemmer)\n-set(FTS_SOURCES\n-    fts_extension.cpp\n-    fts_indexing.cpp\n-    ../../third_party/snowball/libstemmer/libstemmer.cpp\n-    ../../third_party/snowball/runtime/utilities.cpp\n-    ../../third_party/snowball/runtime/api.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_arabic.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_basque.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_catalan.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_danish.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_dutch.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_english.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_finnish.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_french.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_german.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_german2.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_greek.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_hindi.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_hungarian.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_indonesian.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_irish.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_italian.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_kraaij_pohlmann.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_lithuanian.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_lovins.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_nepali.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_norwegian.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_porter.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_portuguese.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_romanian.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_russian.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_serbian.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_spanish.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_swedish.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_tamil.cpp\n-    ../../third_party/snowball/src_c/stem_UTF_8_turkish.cpp)\n-\n-build_static_extension(fts ${FTS_SOURCES})\n-set(PARAMETERS \"-warnings\")\n-build_loadable_extension(fts ${PARAMETERS} ${FTS_SOURCES})\n-\n-install(\n-  TARGETS fts_extension\n-  EXPORT \"${DUCKDB_EXPORT_SET}\"\n-  LIBRARY DESTINATION \"${INSTALL_LIB_DIR}\"\n-  ARCHIVE DESTINATION \"${INSTALL_LIB_DIR}\")\ndiff --git a/extension/fts/fts_config.py b/extension/fts/fts_config.py\ndeleted file mode 100644\nindex 1f8f0eb0ec7e..000000000000\n--- a/extension/fts/fts_config.py\n+++ /dev/null\n@@ -1,55 +0,0 @@\n-import os\n-\n-# list all include directories\n-include_directories = [\n-    os.path.sep.join(x.split('/'))\n-    for x in [\n-        'extension/fts/include',\n-        'third_party/snowball/libstemmer',\n-        'third_party/snowball/runtime',\n-        'third_party/snowball/src_c',\n-    ]\n-]\n-# source files\n-source_files = [\n-    os.path.sep.join(x.split('/')) for x in ['extension/fts/fts_extension.cpp', 'extension/fts/fts_indexing.cpp']\n-]\n-# snowball\n-source_files += [\n-    os.path.sep.join(x.split('/'))\n-    for x in [\n-        'third_party/snowball/libstemmer/libstemmer.cpp',\n-        'third_party/snowball/runtime/utilities.cpp',\n-        'third_party/snowball/runtime/api.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_arabic.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_basque.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_catalan.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_danish.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_dutch.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_english.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_finnish.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_french.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_german.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_german2.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_greek.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_hindi.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_hungarian.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_indonesian.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_irish.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_italian.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_kraaij_pohlmann.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_lithuanian.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_lovins.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_nepali.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_norwegian.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_porter.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_portuguese.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_romanian.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_russian.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_serbian.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_spanish.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_swedish.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_tamil.cpp',\n-        'third_party/snowball/src_c/stem_UTF_8_turkish.cpp',\n-    ]\n-]\ndiff --git a/extension/fts/fts_extension.cpp b/extension/fts/fts_extension.cpp\ndeleted file mode 100644\nindex 3cd6e75d467d..000000000000\n--- a/extension/fts/fts_extension.cpp\n+++ /dev/null\n@@ -1,103 +0,0 @@\n-#define DUCKDB_EXTENSION_MAIN\n-#include \"fts_extension.hpp\"\n-\n-#include \"duckdb.hpp\"\n-#include \"duckdb/common/exception.hpp\"\n-#include \"duckdb/common/string_util.hpp\"\n-#include \"duckdb/function/pragma_function.hpp\"\n-#include \"duckdb/function/scalar_function.hpp\"\n-#include \"duckdb/main/extension_util.hpp\"\n-#include \"fts_indexing.hpp\"\n-#include \"libstemmer.h\"\n-\n-namespace duckdb {\n-\n-static void StemFunction(DataChunk &args, ExpressionState &state, Vector &result) {\n-\tauto &input_vector = args.data[0];\n-\tauto &stemmer_vector = args.data[1];\n-\n-\tBinaryExecutor::Execute<string_t, string_t, string_t>(\n-\t    input_vector, stemmer_vector, result, args.size(), [&](string_t input, string_t stemmer) {\n-\t\t    auto input_data = input.GetData();\n-\t\t    auto input_size = input.GetSize();\n-\n-\t\t    if (stemmer.GetString() == \"none\") {\n-\t\t\t    auto output = StringVector::AddString(result, input_data, input_size);\n-\t\t\t    return output;\n-\t\t    }\n-\n-\t\t    struct sb_stemmer *s = sb_stemmer_new(stemmer.GetString().c_str(), \"UTF_8\");\n-\t\t    if (s == 0) {\n-\t\t\t    const char **stemmers = sb_stemmer_list();\n-\t\t\t    size_t n_stemmers = 27;\n-\t\t\t    throw InvalidInputException(\n-\t\t\t        \"Unrecognized stemmer '%s'. Supported stemmers are: ['%s'], or use 'none' for no stemming\",\n-\t\t\t        stemmer.GetString(),\n-\t\t\t        StringUtil::Join(stemmers, n_stemmers, \"', '\", [](const char *st) { return st; }));\n-\t\t    }\n-\n-\t\t    auto output_data =\n-\t\t        const_char_ptr_cast(sb_stemmer_stem(s, reinterpret_cast<const sb_symbol *>(input_data), input_size));\n-\t\t    auto output_size = sb_stemmer_length(s);\n-\t\t    auto output = StringVector::AddString(result, output_data, output_size);\n-\n-\t\t    sb_stemmer_delete(s);\n-\t\t    return output;\n-\t    });\n-}\n-\n-static void LoadInternal(DuckDB &db) {\n-\tauto &db_instance = *db.instance;\n-\tScalarFunction stem_func(\"stem\", {LogicalType::VARCHAR, LogicalType::VARCHAR}, LogicalType::VARCHAR, StemFunction);\n-\n-\tauto create_fts_index_func =\n-\t    PragmaFunction::PragmaCall(\"create_fts_index\", FTSIndexing::CreateFTSIndexQuery,\n-\t                               {LogicalType::VARCHAR, LogicalType::VARCHAR}, LogicalType::VARCHAR);\n-\tcreate_fts_index_func.named_parameters[\"stemmer\"] = LogicalType::VARCHAR;\n-\tcreate_fts_index_func.named_parameters[\"stopwords\"] = LogicalType::VARCHAR;\n-\tcreate_fts_index_func.named_parameters[\"ignore\"] = LogicalType::VARCHAR;\n-\tcreate_fts_index_func.named_parameters[\"strip_accents\"] = LogicalType::BOOLEAN;\n-\tcreate_fts_index_func.named_parameters[\"lower\"] = LogicalType::BOOLEAN;\n-\tcreate_fts_index_func.named_parameters[\"overwrite\"] = LogicalType::BOOLEAN;\n-\n-\tauto drop_fts_index_func =\n-\t    PragmaFunction::PragmaCall(\"drop_fts_index\", FTSIndexing::DropFTSIndexQuery, {LogicalType::VARCHAR});\n-\n-\tExtensionUtil::RegisterFunction(db_instance, stem_func);\n-\tExtensionUtil::RegisterFunction(db_instance, create_fts_index_func);\n-\tExtensionUtil::RegisterFunction(db_instance, drop_fts_index_func);\n-}\n-\n-void FtsExtension::Load(DuckDB &db) {\n-\tLoadInternal(db);\n-}\n-\n-std::string FtsExtension::Name() {\n-\treturn \"fts\";\n-}\n-\n-std::string FtsExtension::Version() const {\n-#ifdef EXT_VERSION_FTS\n-\treturn EXT_VERSION_FTS;\n-#else\n-\treturn \"\";\n-#endif\n-}\n-\n-} // namespace duckdb\n-\n-extern \"C\" {\n-\n-DUCKDB_EXTENSION_API void fts_init(duckdb::DatabaseInstance &db) {\n-\tduckdb::DuckDB db_wrapper(db);\n-\tduckdb::LoadInternal(db_wrapper);\n-}\n-\n-DUCKDB_EXTENSION_API const char *fts_version() {\n-\treturn duckdb::DuckDB::LibraryVersion();\n-}\n-}\n-\n-#ifndef DUCKDB_EXTENSION_MAIN\n-#error DUCKDB_EXTENSION_MAIN not defined\n-#endif\ndiff --git a/extension/fts/fts_indexing.cpp b/extension/fts/fts_indexing.cpp\ndeleted file mode 100644\nindex a74b9f5de1c4..000000000000\n--- a/extension/fts/fts_indexing.cpp\n+++ /dev/null\n@@ -1,335 +0,0 @@\n-#include \"fts_indexing.hpp\"\n-\n-#include \"duckdb/catalog/catalog_entry/table_catalog_entry.hpp\"\n-#include \"duckdb/catalog/catalog_search_path.hpp\"\n-#include \"duckdb/common/exception.hpp\"\n-#include \"duckdb/common/string_util.hpp\"\n-#include \"duckdb/main/client_data.hpp\"\n-#include \"duckdb/main/connection.hpp\"\n-#include \"duckdb/parser/qualified_name.hpp\"\n-\n-namespace duckdb {\n-\n-static QualifiedName GetQualifiedName(ClientContext &context, const string &qname_str) {\n-\tauto qname = QualifiedName::Parse(qname_str);\n-\tif (qname.schema == INVALID_SCHEMA) {\n-\t\tqname.schema = ClientData::Get(context).catalog_search_path->GetDefaultSchema(qname.catalog);\n-\t}\n-\treturn qname;\n-}\n-\n-static string GetFTSSchema(QualifiedName &qname) {\n-\tauto result = qname.catalog == INVALID_CATALOG ? \"\" : StringUtil::Format(\"%s.\", qname.catalog);\n-\tresult += StringUtil::Format(\"fts_%s_%s\", qname.schema, qname.name);\n-\treturn result;\n-}\n-\n-string FTSIndexing::DropFTSIndexQuery(ClientContext &context, const FunctionParameters &parameters) {\n-\tauto qname = GetQualifiedName(context, StringValue::Get(parameters.values[0]));\n-\tstring fts_schema = GetFTSSchema(qname);\n-\n-\tif (!Catalog::GetSchema(context, qname.catalog, fts_schema, OnEntryNotFound::RETURN_NULL)) {\n-\t\tthrow CatalogException(\n-\t\t    \"a FTS index does not exist on table '%s.%s'. Create one with 'PRAGMA create_fts_index()'.\", qname.schema,\n-\t\t    qname.name);\n-\t}\n-\n-\treturn StringUtil::Format(\"DROP SCHEMA %s CASCADE;\", fts_schema);\n-}\n-\n-static string IndexingScript(ClientContext &context, QualifiedName &qname, const string &input_id,\n-                             const vector<string> &input_values, const string &stemmer, const string &stopwords,\n-                             const string &ignore, bool strip_accents, bool lower) {\n-\t// clang-format off\n-    string result = R\"(\n-        DROP SCHEMA IF EXISTS %fts_schema% CASCADE;\n-        CREATE SCHEMA %fts_schema%;\n-        CREATE TABLE %fts_schema%.stopwords (sw VARCHAR);\n-    )\";\n-\t// clang-format on\n-\n-\tif (stopwords == \"none\") {\n-\t\t// do nothing\n-\t} else if (stopwords == \"english\") {\n-\t\t// default list of english stopwords from \"The SMART system\"\n-\t\t// clang-format off\n-        result += R\"(\n-            INSERT INTO %fts_schema%.stopwords VALUES ('a'), ('a''s'), ('able'), ('about'), ('above'), ('according'), ('accordingly'), ('across'), ('actually'), ('after'), ('afterwards'), ('again'), ('against'), ('ain''t'), ('all'), ('allow'), ('allows'), ('almost'), ('alone'), ('along'), ('already'), ('also'), ('although'), ('always'), ('am'), ('among'), ('amongst'), ('an'), ('and'), ('another'), ('any'), ('anybody'), ('anyhow'), ('anyone'), ('anything'), ('anyway'), ('anyways'), ('anywhere'), ('apart'), ('appear'), ('appreciate'), ('appropriate'), ('are'), ('aren''t'), ('around'), ('as'), ('aside'), ('ask'), ('asking'), ('associated'), ('at'), ('available'), ('away'), ('awfully'), ('b'), ('be'), ('became'), ('because'), ('become'), ('becomes'), ('becoming'), ('been'), ('before'), ('beforehand'), ('behind'), ('being'), ('believe'), ('below'), ('beside'), ('besides'), ('best'), ('better'), ('between'), ('beyond'), ('both'), ('brief'), ('but'), ('by'), ('c'), ('c''mon'), ('c''s'), ('came'), ('can'), ('can''t'), ('cannot'), ('cant'), ('cause'), ('causes'), ('certain'), ('certainly'), ('changes'), ('clearly'), ('co'), ('com'), ('come'), ('comes'), ('concerning'), ('consequently'), ('consider'), ('considering'), ('contain'), ('containing'), ('contains'), ('corresponding'), ('could'), ('couldn''t'), ('course'), ('currently'), ('d'), ('definitely'), ('described'), ('despite'), ('did'), ('didn''t'), ('different'), ('do'), ('does'), ('doesn''t'), ('doing'), ('don''t'), ('done'), ('down'), ('downwards'), ('during'), ('e'), ('each'), ('edu'), ('eg'), ('eight'), ('either'), ('else'), ('elsewhere'), ('enough'), ('entirely'), ('especially'), ('et'), ('etc'), ('even'), ('ever'), ('every'), ('everybody'), ('everyone'), ('everything'), ('everywhere'), ('ex'), ('exactly'), ('example'), ('except'), ('f'), ('far'), ('few'), ('fifth'), ('first'), ('five'), ('followed'), ('following'), ('follows'), ('for'), ('former'), ('formerly'), ('forth'), ('four'), ('from'), ('further'), ('furthermore'), ('g'), ('get'), ('gets'), ('getting'), ('given'), ('gives'), ('go'), ('goes'), ('going'), ('gone'), ('got'), ('gotten'), ('greetings'), ('h'), ('had'), ('hadn''t'), ('happens'), ('hardly'), ('has'), ('hasn''t'), ('have'), ('haven''t'), ('having'), ('he'), ('he''s'), ('hello'), ('help'), ('hence'), ('her'), ('here'), ('here''s'), ('hereafter'), ('hereby'), ('herein'), ('hereupon'), ('hers'), ('herself'), ('hi'), ('him'), ('himself'), ('his'), ('hither'), ('hopefully'), ('how'), ('howbeit'), ('however'), ('i'), ('i''d'), ('i''ll'), ('i''m'), ('i''ve'), ('ie'), ('if'), ('ignored'), ('immediate'), ('in'), ('inasmuch'), ('inc'), ('indeed'), ('indicate'), ('indicated'), ('indicates'), ('inner'), ('insofar'), ('instead'), ('into'), ('inward'), ('is'), ('isn''t'), ('it'), ('it''d'), ('it''ll'), ('it''s'), ('its'), ('itself'), ('j'), ('just'), ('k'), ('keep'), ('keeps'), ('kept'), ('know'), ('knows'), ('known'), ('l'), ('last'), ('lately'), ('later'), ('latter'), ('latterly'), ('least'), ('less'), ('lest'), ('let'), ('let''s'), ('like'), ('liked'), ('likely'), ('little'), ('look'), ('looking'), ('looks'), ('ltd'), ('m'), ('mainly'), ('many'), ('may'), ('maybe'), ('me'), ('mean'), ('meanwhile'), ('merely'), ('might'), ('more'), ('moreover'), ('most'), ('mostly'), ('much'), ('must'), ('my'), ('myself'), ('n'), ('name'), ('namely'), ('nd'), ('near'), ('nearly'), ('necessary'), ('need'), ('needs'), ('neither'), ('never'), ('nevertheless'), ('new'), ('next'), ('nine'), ('no'), ('nobody'), ('non'), ('none'), ('noone'), ('nor'), ('normally'), ('not'), ('nothing'), ('novel'), ('now'), ('nowhere'), ('o'), ('obviously'), ('of'), ('off'), ('often'), ('oh'), ('ok'), ('okay'), ('old'), ('on'), ('once'), ('one'), ('ones'), ('only'), ('onto'), ('or'), ('other'), ('others'), ('otherwise'), ('ought'), ('our'), ('ours'), ('ourselves'), ('out'), ('outside'), ('over'), ('overall'), ('own');\n-            INSERT INTO %fts_schema%.stopwords VALUES ('p'), ('particular'), ('particularly'), ('per'), ('perhaps'), ('placed'), ('please'), ('plus'), ('possible'), ('presumably'), ('probably'), ('provides'), ('q'), ('que'), ('quite'), ('qv'), ('r'), ('rather'), ('rd'), ('re'), ('really'), ('reasonably'), ('regarding'), ('regardless'), ('regards'), ('relatively'), ('respectively'), ('right'), ('s'), ('said'), ('same'), ('saw'), ('say'), ('saying'), ('says'), ('second'), ('secondly'), ('see'), ('seeing'), ('seem'), ('seemed'), ('seeming'), ('seems'), ('seen'), ('self'), ('selves'), ('sensible'), ('sent'), ('serious'), ('seriously'), ('seven'), ('several'), ('shall'), ('she'), ('should'), ('shouldn''t'), ('since'), ('six'), ('so'), ('some'), ('somebody'), ('somehow'), ('someone'), ('something'), ('sometime'), ('sometimes'), ('somewhat'), ('somewhere'), ('soon'), ('sorry'), ('specified'), ('specify'), ('specifying'), ('still'), ('sub'), ('such'), ('sup'), ('sure'), ('t'), ('t''s'), ('take'), ('taken'), ('tell'), ('tends'), ('th'), ('than'), ('thank'), ('thanks'), ('thanx'), ('that'), ('that''s'), ('thats'), ('the'), ('their'), ('theirs'), ('them'), ('themselves'), ('then'), ('thence'), ('there'), ('there''s'), ('thereafter'), ('thereby'), ('therefore'), ('therein'), ('theres'), ('thereupon'), ('these'), ('they'), ('they''d'), ('they''ll'), ('they''re'), ('they''ve'), ('think'), ('third'), ('this'), ('thorough'), ('thoroughly'), ('those'), ('though'), ('three'), ('through'), ('throughout'), ('thru'), ('thus'), ('to'), ('together'), ('too'), ('took'), ('toward'), ('towards'), ('tried'), ('tries'), ('truly'), ('try'), ('trying'), ('twice'), ('two'), ('u'), ('un'), ('under'), ('unfortunately'), ('unless'), ('unlikely'), ('until'), ('unto'), ('up'), ('upon'), ('us'), ('use'), ('used'), ('useful'), ('uses'), ('using'), ('usually'), ('uucp'), ('v'), ('value'), ('various'), ('very'), ('via'), ('viz'), ('vs'), ('w'), ('want'), ('wants'), ('was'), ('wasn''t'), ('way'), ('we'), ('we''d'), ('we''ll'), ('we''re'), ('we''ve'), ('welcome'), ('well'), ('went'), ('were'), ('weren''t'), ('what'), ('what''s'), ('whatever'), ('when'), ('whence'), ('whenever'), ('where'), ('where''s'), ('whereafter'), ('whereas'), ('whereby'), ('wherein'), ('whereupon'), ('wherever'), ('whether'), ('which'), ('while'), ('whither'), ('who'), ('who''s'), ('whoever'), ('whole'), ('whom'), ('whose'), ('why'), ('will'), ('willing'), ('wish'), ('with'), ('within'), ('without'), ('won''t'), ('wonder'), ('would'), ('would'), ('wouldn''t'), ('x'), ('y'), ('yes'), ('yet'), ('you'), ('you''d'), ('you''ll'), ('you''re'), ('you''ve'), ('your'), ('yours'), ('yourself'), ('yourselves'), ('z'), ('zero');\n-        )\";\n-\t\t// clang-format on\n-\t} else {\n-\t\t// custom stopwords\n-\t\tresult += \"INSERT INTO %fts_schema%.stopwords SELECT * FROM \" + stopwords + \";\";\n-\t}\n-\n-\t// create tokenize macro based on parameters\n-\tstring tokenize = \"s::VARCHAR\";\n-\tvector<string> before;\n-\tvector<string> after;\n-\tif (strip_accents) {\n-\t\ttokenize = \"strip_accents(\" + tokenize + \")\";\n-\t}\n-\tif (lower) {\n-\t\ttokenize = \"lower(\" + tokenize + \")\";\n-\t}\n-\ttokenize = \"regexp_replace(\" + tokenize + \", $$\" + ignore + \"$$, \" + \"' ', 'g')\";\n-\ttokenize = \"string_split_regex(\" + tokenize + \", '\\\\s+')\";\n-\tresult += \"CREATE MACRO %fts_schema%.tokenize(s) AS \" + tokenize + \";\";\n-\n-\t// parameterized definition of indexing and retrieval model\n-\t// clang-format off\n-\tresult += R\"(\n-        CREATE TABLE %fts_schema%.docs AS (\n-            SELECT rowid AS docid,\n-                   \"%input_id%\" AS name\n-            FROM %input_table%\n-        );\n-\n-\t    CREATE TABLE %fts_schema%.fields (fieldid BIGINT, field VARCHAR);\n-\t    INSERT INTO %fts_schema%.fields VALUES %field_values%;\n-\n-        CREATE TABLE %fts_schema%.terms AS\n-        WITH tokenized AS (\n-            %union_fields_query%\n-        ),\n-\t    stemmed_stopped AS (\n-            SELECT stem(t.w, '%stemmer%') AS term,\n-\t               t.docid AS docid,\n-                   t.fieldid AS fieldid\n-\t        FROM tokenized AS t\n-\t        WHERE t.w NOT NULL\n-              AND len(t.w) > 0\n-\t          AND t.w NOT IN (SELECT sw FROM %fts_schema%.stopwords)\n-        )\n-\t    SELECT ss.term,\n-\t           ss.docid,\n-\t           ss.fieldid\n-        FROM stemmed_stopped AS ss;\n-\n-        ALTER TABLE %fts_schema%.docs ADD len BIGINT;\n-        UPDATE %fts_schema%.docs d\n-        SET len = (\n-            SELECT count(term)\n-            FROM %fts_schema%.terms AS t\n-            WHERE t.docid = d.docid\n-        );\n-\n-        CREATE TABLE %fts_schema%.dict AS\n-        WITH distinct_terms AS (\n-            SELECT DISTINCT term\n-            FROM %fts_schema%.terms\n-            ORDER BY docid, term\n-        )\n-        SELECT row_number() OVER () - 1 AS termid,\n-               dt.term\n-        FROM distinct_terms AS dt;\n-\n-        ALTER TABLE %fts_schema%.terms ADD termid BIGINT;\n-        UPDATE %fts_schema%.terms t\n-        SET termid = (\n-            SELECT termid\n-            FROM %fts_schema%.dict d\n-            WHERE t.term = d.term\n-        );\n-        ALTER TABLE %fts_schema%.terms DROP term;\n-\n-        ALTER TABLE %fts_schema%.dict ADD df BIGINT;\n-        UPDATE %fts_schema%.dict d\n-        SET df = (\n-            SELECT count(distinct docid)\n-            FROM %fts_schema%.terms t\n-            WHERE d.termid = t.termid\n-            GROUP BY termid\n-        );\n-\n-        CREATE TABLE %fts_schema%.stats AS (\n-            SELECT COUNT(docs.docid) AS num_docs,\n-                   SUM(docs.len) / COUNT(docs.len) AS avgdl\n-            FROM %fts_schema%.docs AS docs\n-        );\n-\n-        CREATE MACRO %fts_schema%.match_bm25(docname, query_string, fields := NULL, k := 1.2, b := 0.75, conjunctive := false) AS (\n-            WITH tokens AS (\n-                SELECT DISTINCT stem(unnest(%fts_schema%.tokenize(query_string)), '%stemmer%') AS t\n-            ),\n-            fieldids AS (\n-                SELECT fieldid\n-                FROM %fts_schema%.fields\n-                WHERE CASE WHEN fields IS NULL THEN 1 ELSE field IN (SELECT * FROM (SELECT UNNEST(string_split(fields, ','))) AS fsq) END\n-            ),\n-            qtermids AS (\n-                SELECT termid\n-                FROM %fts_schema%.dict AS dict,\n-                     tokens\n-                WHERE dict.term = tokens.t\n-            ),\n-            qterms AS (\n-                SELECT termid,\n-                       docid\n-                FROM %fts_schema%.terms AS terms\n-                WHERE CASE WHEN fields IS NULL THEN 1 ELSE fieldid IN (SELECT * FROM fieldids) END\n-                  AND termid IN (SELECT qtermids.termid FROM qtermids)\n-            ),\n-\t\t\tterm_tf AS (\n-\t\t\t\tSELECT termid,\n-\t\t\t\t   \t   docid,\n-                       COUNT(*) AS tf\n-\t\t\t\tFROM qterms\n-\t\t\t\tGROUP BY docid,\n-\t\t\t\t\t\t termid\n-\t\t\t),\n-\t\t\tcdocs AS (\n-\t\t\t\tSELECT docid\n-\t\t\t\tFROM qterms\n-\t\t\t\tGROUP BY docid\n-\t\t\t\tHAVING CASE WHEN conjunctive THEN COUNT(DISTINCT termid) = (SELECT COUNT(*) FROM tokens) ELSE 1 END\n-\t\t\t),\n-            subscores AS (\n-                SELECT docs.docid,\n-                       len,\n-                       term_tf.termid,\n-                       tf,\n-                       df,\n-                       (log(((SELECT num_docs FROM %fts_schema%.stats) - df + 0.5) / (df + 0.5) + 1) * ((tf * (k + 1)/(tf + k * (1 - b + b * (len / (SELECT avgdl FROM %fts_schema%.stats))))))) AS subscore\n-                FROM term_tf,\n-\t\t\t\t\t cdocs,\n-\t\t\t\t\t %fts_schema%.docs AS docs,\n-\t\t\t\t\t %fts_schema%.dict AS dict\n-\t\t\t\tWHERE term_tf.docid = cdocs.docid\n-\t\t\t\t  AND term_tf.docid = docs.docid\n-                  AND term_tf.termid = dict.termid\n-            ),\n-\t\t\tscores AS (\n-\t\t\t\tSELECT docid,\n-\t\t\t\t\t   sum(subscore) AS score\n-\t\t\t\tFROM subscores\n-\t\t\t\tGROUP BY docid\n-\t\t\t)\n-            SELECT score\n-            FROM scores,\n-\t\t\t\t %fts_schema%.docs AS docs\n-            WHERE scores.docid = docs.docid\n-              AND docs.name = docname\n-        );\n-    )\";\n-\n-    // we may have more than 1 input field, therefore we union over the fields, retaining information which field it came from\n-\tstring tokenize_field_query = R\"(\n-        SELECT unnest(%fts_schema%.tokenize(fts_ii.\"%input_value%\")) AS w,\n-\t           rowid AS docid,\n-\t           (SELECT fieldid FROM %fts_schema%.fields WHERE field = '%input_value%') AS fieldid\n-        FROM %input_table% AS fts_ii\n-    )\";\n-\t// clang-format on\n-\tvector<string> field_values;\n-\tvector<string> tokenize_fields;\n-\tfor (idx_t i = 0; i < input_values.size(); i++) {\n-\t\tfield_values.push_back(StringUtil::Format(\"(%i, '%s')\", i, input_values[i]));\n-\t\ttokenize_fields.push_back(StringUtil::Replace(tokenize_field_query, \"%input_value%\", input_values[i]));\n-\t}\n-\tresult = StringUtil::Replace(result, \"%field_values%\", StringUtil::Join(field_values, \", \"));\n-\tresult = StringUtil::Replace(result, \"%union_fields_query%\", StringUtil::Join(tokenize_fields, \" UNION ALL \"));\n-\n-\tstring fts_schema = GetFTSSchema(qname);\n-\tstring input_table = qname.catalog == INVALID_CATALOG ? \"\" : StringUtil::Format(\"%s.\", qname.catalog);\n-\tinput_table += StringUtil::Format(\"%s.%s\", qname.schema, qname.name);\n-\n-\t// fill in variables (inefficiently, but keeps SQL script readable)\n-\tresult = StringUtil::Replace(result, \"%fts_schema%\", fts_schema);\n-\tresult = StringUtil::Replace(result, \"%input_table%\", input_table);\n-\tresult = StringUtil::Replace(result, \"%input_id%\", input_id);\n-\tresult = StringUtil::Replace(result, \"%stemmer%\", stemmer);\n-\n-\treturn result;\n-}\n-\n-static void CheckIfTableExists(ClientContext &context, QualifiedName &qname) {\n-\tCatalog::GetEntry<TableCatalogEntry>(context, qname.catalog, qname.schema, qname.name);\n-}\n-\n-string FTSIndexing::CreateFTSIndexQuery(ClientContext &context, const FunctionParameters &parameters) {\n-\tauto qname = GetQualifiedName(context, StringValue::Get(parameters.values[0]));\n-\tCheckIfTableExists(context, qname);\n-\n-\t// get named parameters\n-\tstring stemmer = \"porter\";\n-\tauto stemmer_entry = parameters.named_parameters.find(\"stemmer\");\n-\tif (stemmer_entry != parameters.named_parameters.end()) {\n-\t\tstemmer = StringValue::Get(stemmer_entry->second);\n-\t}\n-\n-\tstring stopwords = \"english\";\n-\tauto stopword_entry = parameters.named_parameters.find(\"stopwords\");\n-\tif (stopword_entry != parameters.named_parameters.end()) {\n-\t\tstopwords = StringValue::Get(stopword_entry->second);\n-\t\tif (stopwords != \"english\" && stopwords != \"none\") {\n-\t\t\tauto stopwords_qname = GetQualifiedName(context, stopwords);\n-\t\t\tCheckIfTableExists(context, stopwords_qname);\n-\t\t}\n-\t}\n-\n-\tstring ignore = \"[0-9!@#$%^&*()_+={}\\\\[\\\\]:;<>,.?~\\\\\\\\/\\\\|''\\\"`-]+\";\n-\tauto ignore_entry = parameters.named_parameters.find(\"ignore\");\n-\tif (ignore_entry != parameters.named_parameters.end()) {\n-\t\tignore = StringValue::Get(ignore_entry->second);\n-\t}\n-\n-\tbool strip_accents = true;\n-\tauto strip_accents_entry = parameters.named_parameters.find(\"strip_accents\");\n-\tif (strip_accents_entry != parameters.named_parameters.end()) {\n-\t\tstrip_accents = BooleanValue::Get(strip_accents_entry->second);\n-\t}\n-\n-\tbool lower = true;\n-\tauto lower_entry = parameters.named_parameters.find(\"lower\");\n-\tif (lower_entry != parameters.named_parameters.end()) {\n-\t\tlower = BooleanValue::Get(lower_entry->second);\n-\t}\n-\n-\tbool overwrite = false;\n-\tauto overwrite_entry = parameters.named_parameters.find(\"overwrite\");\n-\tif (overwrite_entry != parameters.named_parameters.end()) {\n-\t\toverwrite = BooleanValue::Get(overwrite_entry->second);\n-\t}\n-\n-\t// throw error if an index already exists on this table\n-\tconst string fts_schema = GetFTSSchema(qname);\n-\tif (Catalog::GetSchema(context, qname.catalog, fts_schema, OnEntryNotFound::RETURN_NULL) && !overwrite) {\n-\t\tthrow CatalogException(\"a FTS index already exists on table '%s.%s'. Supply 'overwrite=1' to overwrite, or \"\n-\t\t                       \"drop the existing index with 'PRAGMA drop_fts_index()' before creating a new one.\",\n-\t\t                       qname.schema, qname.name);\n-\t}\n-\n-\t// positional parameters\n-\tauto doc_id = StringValue::Get(parameters.values[1]);\n-\t// check all specified columns\n-\tauto &table = Catalog::GetEntry<TableCatalogEntry>(context, qname.catalog, qname.schema, qname.name);\n-\tvector<string> doc_values;\n-\tfor (idx_t i = 2; i < parameters.values.size(); i++) {\n-\t\tstring col_name = StringValue::Get(parameters.values[i]);\n-\t\tif (col_name == \"*\") {\n-\t\t\t// star found - get all columns\n-\t\t\tdoc_values.clear();\n-\t\t\tfor (auto &cd : table.GetColumns().Logical()) {\n-\t\t\t\tif (cd.Type() == LogicalType::VARCHAR) {\n-\t\t\t\t\tdoc_values.push_back(cd.Name());\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tbreak;\n-\t\t}\n-\t\tif (!table.ColumnExists(col_name)) {\n-\t\t\t// we check this here because else we we end up with an error halfway the indexing script\n-\t\t\tthrow CatalogException(\"Table '%s.%s' does not have a column named '%s'!\", qname.schema, qname.name,\n-\t\t\t                       col_name);\n-\t\t}\n-\t\tdoc_values.push_back(col_name);\n-\t}\n-\tif (doc_values.empty()) {\n-\t\tthrow InvalidInputException(\"at least one column must be supplied for indexing!\");\n-\t}\n-\n-\treturn IndexingScript(context, qname, doc_id, doc_values, stemmer, stopwords, ignore, strip_accents, lower);\n-}\n-\n-} // namespace duckdb\ndiff --git a/extension/fts/include/fts_extension.hpp b/extension/fts/include/fts_extension.hpp\ndeleted file mode 100644\nindex 389ffd787b07..000000000000\n--- a/extension/fts/include/fts_extension.hpp\n+++ /dev/null\n@@ -1,22 +0,0 @@\n-//===----------------------------------------------------------------------===//\n-//                         DuckDB\n-//\n-// fts_extension.hpp\n-//\n-//\n-//===----------------------------------------------------------------------===//\n-\n-#pragma once\n-\n-#include \"duckdb.hpp\"\n-\n-namespace duckdb {\n-\n-class FtsExtension : public Extension {\n-public:\n-\tvoid Load(DuckDB &db) override;\n-\tstd::string Name() override;\n-\tstd::string Version() const override;\n-};\n-\n-} // namespace duckdb\ndiff --git a/extension/fts/include/fts_indexing.hpp b/extension/fts/include/fts_indexing.hpp\ndeleted file mode 100644\nindex 40f67e262c16..000000000000\n--- a/extension/fts/include/fts_indexing.hpp\n+++ /dev/null\n@@ -1,20 +0,0 @@\n-//===----------------------------------------------------------------------===//\n-//                         DuckDB\n-//\n-// fts_indexing.hpp\n-//\n-//\n-//===----------------------------------------------------------------------===//\n-\n-#pragma once\n-\n-#include \"duckdb/main/client_context.hpp\"\n-\n-namespace duckdb {\n-\n-struct FTSIndexing {\n-\tstatic string DropFTSIndexQuery(ClientContext &context, const FunctionParameters &parameters);\n-\tstatic string CreateFTSIndexQuery(ClientContext &context, const FunctionParameters &parameters);\n-};\n-\n-} // namespace duckdb\ndiff --git a/extension/fts/indexing.sql b/extension/fts/indexing.sql\ndeleted file mode 100644\nindex f98624664e7e..000000000000\n--- a/extension/fts/indexing.sql\n+++ /dev/null\n@@ -1,101 +0,0 @@\n-DROP SCHEMA IF EXISTS %fts_schema% CASCADE;\n-CREATE SCHEMA %fts_schema%;\n-CREATE MACRO %fts_schema%.tokenize(s) AS stem(unnest(string_split_regex(regexp_replace(lower(strip_accents(s)), '[^a-z]', ' ', 'g'), '\\s+')), '%stemmer%');\n-\n-CREATE TABLE %fts_schema%.docs AS (\n-    SELECT\n-        row_number() OVER (PARTITION BY(SELECT NULL)) AS docid,\n-        %input_id% AS name\n-    FROM\n-        %input_schema%.%input_table%\n-);\n-\n-CREATE TABLE %fts_schema%.terms AS (\n-    SELECT\n-        term,\n-        docid,\n-        row_number() OVER (PARTITION BY docid) AS pos\n-    FROM (\n-        SELECT\n-            %fts_schema%.tokenize(%input_val%) AS term,\n-            row_number() OVER (PARTITION BY (SELECT NULL)) AS docid\n-        FROM %input_schema%.%input_table%\n-    ) AS sq\n-    WHERE\n-        term != ''\n-);\n-\n-ALTER TABLE %fts_schema%.docs ADD len INT;\n-UPDATE %fts_schema%.docs d\n-SET len = (\n-    SELECT count(term)\n-    FROM %fts_schema%.terms t\n-    WHERE t.docid = d.docid\n-);\n-\n-CREATE TABLE %fts_schema%.dict AS\n-WITH distinct_terms AS (\n-    SELECT DISTINCT term, docid\n-    FROM %fts_schema%.terms\n-    ORDER BY docid\n-)\n-SELECT\n-    row_number() OVER (PARTITION BY (SELECT NULL)) AS termid,\n-    term\n-FROM\n-    distinct_terms;\n-\n-ALTER TABLE %fts_schema%.terms ADD termid INT;\n-UPDATE %fts_schema%.terms t\n-SET termid = (\n-    SELECT termid\n-    FROM %fts_schema%.dict d\n-    WHERE t.term = d.term\n-);\n-ALTER TABLE %fts_schema%.terms DROP term;\n-\n-ALTER TABLE %fts_schema%.dict ADD df INT;\n-UPDATE %fts_schema%.dict d\n-SET df = (\n-    SELECT count(distinct docid)\n-    FROM %fts_schema%.terms t\n-    WHERE d.termid = t.termid\n-    GROUP BY termid\n-);\n-\n-CREATE TABLE %fts_schema%.stats AS (\n-    SELECT COUNT(docs.docid) AS num_docs, SUM(docs.len) / COUNT(docs.len) AS avgdl\n-    FROM %fts_schema%.docs AS docs\n-);\n-\n-CREATE MACRO %fts_schema%.match_bm25(docname, query_string, k=1.2, b=0.75, conjunctive=0) AS docname IN (\n-    WITH tokens AS\n-        (SELECT DISTINCT %fts_schema%.tokenize(query_string) AS t),\n-    qtermids AS\n-        (SELECT termid FROM %fts_schema%.dict AS dict, tokens WHERE dict.term = tokens.t),\n-    qterms AS\n-        (SELECT termid, docid FROM %fts_schema%.terms AS terms WHERE termid IN (SELECT qtermids.termid FROM qtermids)),\n-    subscores AS (\n-        SELECT\n-            docs.docid, len, term_tf.termid, tf, df,\n-            (log(((SELECT num_docs FROM %fts_schema%.stats) - df + 0.5) / (df + 0.5))* ((tf * (k + 1)/(tf + k * (1 - b + b * (len / (SELECT avgdl FROM %fts_schema%.stats))))))) AS subscore\n-        FROM\n-            (SELECT termid, docid, COUNT(*) AS tf FROM qterms GROUP BY docid, termid) AS term_tf\n-        JOIN\n-            (SELECT docid FROM qterms GROUP BY docid HAVING CASE WHEN conjunctive THEN COUNT(DISTINCT termid) = (SELECT COUNT(*) FROM tokens) ELSE 1 END) AS cdocs\n-        ON\n-            term_tf.docid = cdocs.docid\n-        JOIN\n-            %fts_schema%.docs AS docs\n-        ON\n-            term_tf.docid = docs.docid\n-        JOIN\n-            %fts_schema%.dict AS dict\n-        ON\n-            term_tf.termid = dict.termid\n-    )\n-    SELECT name\n-    FROM (SELECT docid, sum(subscore) AS score FROM subscores GROUP BY docid) AS scores\n-    JOIN %fts_schema%.docs AS docs\n-    ON scores.docid = docs.docid ORDER BY score DESC LIMIT 1000\n-);\ndiff --git a/src/main/extension/extension_helper.cpp b/src/main/extension/extension_helper.cpp\nindex 18b7cbb2e8ae..e6fb885334ee 100644\n--- a/src/main/extension/extension_helper.cpp\n+++ b/src/main/extension/extension_helper.cpp\n@@ -36,10 +36,6 @@\n #define DUCKDB_EXTENSION_TPCDS_LINKED false\n #endif\n \n-#ifndef DUCKDB_EXTENSION_FTS_LINKED\n-#define DUCKDB_EXTENSION_FTS_LINKED false\n-#endif\n-\n #ifndef DUCKDB_EXTENSION_HTTPFS_LINKED\n #define DUCKDB_EXTENSION_HTTPFS_LINKED false\n #endif\n@@ -82,10 +78,6 @@\n #include \"tpcds_extension.hpp\"\n #endif\n \n-#if DUCKDB_EXTENSION_FTS_LINKED\n-#include \"fts_extension.hpp\"\n-#endif\n-\n #if DUCKDB_EXTENSION_HTTPFS_LINKED\n #include \"httpfs_extension.hpp\"\n #endif\n@@ -116,7 +108,6 @@ static const DefaultExtension internal_extensions[] = {\n     {\"parquet\", \"Adds support for reading and writing parquet files\", DUCKDB_EXTENSION_PARQUET_LINKED},\n     {\"tpch\", \"Adds TPC-H data generation and query support\", DUCKDB_EXTENSION_TPCH_LINKED},\n     {\"tpcds\", \"Adds TPC-DS data generation and query support\", DUCKDB_EXTENSION_TPCDS_LINKED},\n-    {\"fts\", \"Adds support for Full-Text Search Indexes\", DUCKDB_EXTENSION_FTS_LINKED},\n     {\"httpfs\", \"Adds support for reading and writing files over a HTTP(S) connection\", DUCKDB_EXTENSION_HTTPFS_LINKED},\n     {\"json\", \"Adds support for JSON operations\", DUCKDB_EXTENSION_JSON_LINKED},\n     {\"jemalloc\", \"Overwrites system allocator with JEMalloc\", DUCKDB_EXTENSION_JEMALLOC_LINKED},\n@@ -134,6 +125,7 @@ static const DefaultExtension internal_extensions[] = {\n     {\"iceberg\", \"Adds support for Apache Iceberg\", false},\n     {\"vss\", \"Adds indexing support to accelerate Vector Similarity Search\", false},\n     {\"delta\", \"Adds support for Delta Lake\", false},\n+    {\"fts\", \"Adds support for Full-Text Search Indexes\", false},\n     {nullptr, nullptr, false}};\n \n idx_t ExtensionHelper::DefaultExtensionCount() {\n@@ -414,8 +406,8 @@ void ExtensionHelper::LoadAllExtensions(DuckDB &db) {\n \t// The in-tree extensions that we check. Non-cmake builds are currently limited to these for static linking\n \t// TODO: rewrite package_build.py to allow also loading out-of-tree extensions in non-cmake builds, after that\n \t//\t\t these can be removed\n-\tvector<string> extensions {\"parquet\", \"icu\",   \"tpch\", \"tpcds\",    \"fts\",          \"httpfs\",\n-\t                           \"json\",    \"excel\", \"inet\", \"jemalloc\", \"autocomplete\", \"core_functions\"};\n+\tvector<string> extensions {\"parquet\", \"icu\",  \"tpch\",     \"tpcds\",        \"httpfs\",        \"json\",\n+\t                           \"excel\",   \"inet\", \"jemalloc\", \"autocomplete\", \"core_functions\"};\n \tfor (auto &ext : extensions) {\n \t\tLoadExtensionInternal(db, ext, true);\n \t}\n@@ -502,13 +494,6 @@ ExtensionLoadResult ExtensionHelper::LoadExtensionInternal(DuckDB &db, const std\n #else\n \t\t// icu extension required but not build: skip this test\n \t\treturn ExtensionLoadResult::NOT_LOADED;\n-#endif\n-\t} else if (extension == \"fts\") {\n-#if DUCKDB_EXTENSION_FTS_LINKED\n-//\t\tdb.LoadStaticExtension<FtsExtension>();\n-#else\n-\t\t// fts extension required but not build: skip this test\n-\t\treturn ExtensionLoadResult::NOT_LOADED;\n #endif\n \t} else if (extension == \"httpfs\") {\n #if DUCKDB_EXTENSION_HTTPFS_LINKED\n",
  "test_patch": "diff --git a/test/optimizer/deliminator.test b/test/optimizer/deliminator.test\nindex 0649337fac6c..a401c35601aa 100644\n--- a/test/optimizer/deliminator.test\n+++ b/test/optimizer/deliminator.test\n@@ -181,22 +181,3 @@ NULL\t0\n 1\t1\n 2\t1\n 3\t0\n-\n-# FTS\n-require fts\n-\n-require no_alternative_verify\n-\n-statement ok\n-CREATE TABLE documents(id VARCHAR, body VARCHAR)\n-\n-statement ok\n-INSERT INTO documents VALUES ('doc1', ' QU\u00c1CKING+QU\u00c1CKING+QU\u00c1CKING'), ('doc2', ' B\u00c1RKING+B\u00c1RKING+B\u00c1RKING+B\u00c1RKING'), ('doc3', ' M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+999')\n-\n-statement ok\n-PRAGMA create_fts_index('documents', 'id', 'body', overwrite=1)\n-\n-query II\n-EXPLAIN SELECT score, id, body FROM (SELECT *, fts_main_documents.match_bm25(id, 'quacked barked') AS score FROM documents) sq WHERE score IS NOT NULL ORDER BY score DESC\n-----\n-logical_opt\t<!REGEX>:.*DELIM_JOIN.*\ndiff --git a/test/sql/fts/issue_12330.test b/test/sql/fts/issue_12330.test\ndeleted file mode 100644\nindex 9a68d66f847f..000000000000\n--- a/test/sql/fts/issue_12330.test\n+++ /dev/null\n@@ -1,36 +0,0 @@\n-# name: test/sql/fts/issue_12330.test\n-# description: Issue 12330: BM25 matching scores seems to be invalid\n-# group: [fts]\n-\n-# issue #7384 and #8141\n-\n-require fts\n-\n-require noalternativeverify\n-\n-statement ok\n-CREATE OR REPLACE TABLE documents (\n-    id VARCHAR,\n-    content VARCHAR\n-);\n-\n-statement ok\n-INSERT INTO documents VALUES\n-    ('doc1', 'DuckDB database lorem'),\n-    ('doc2', 'DuckDB database ipsum'),\n-    ('doc3', 'DuckDB database ipsum dolor');\n-\n-statement ok\n-PRAGMA create_fts_index('documents', 'id', 'content');\n-\n-query I\n-SELECT\n-    id\n-FROM\n-    documents\n-ORDER BY\n-    fts_main_documents.match_bm25(id, 'DuckDB database ipsum') DESC;\n-----\n-doc2\n-doc3\n-doc1\ndiff --git a/test/sql/fts/issue_13866.test b/test/sql/fts/issue_13866.test\ndeleted file mode 100644\nindex 6334ebd5a8dc..000000000000\n--- a/test/sql/fts/issue_13866.test\n+++ /dev/null\n@@ -1,13 +0,0 @@\n-# name: test/sql/fts/issue_13866.test\n-# description: Issue 13866: FTS ignore regex to include single quote\n-# group: [fts]\n-\n-require fts\n-\n-require noalternativeverify\n-\n-statement ok\n-CREATE TABLE my_table AS SELECT 1 AS CustomerId, 'hans' as CustomerName\n-\n-statement ok\n-PRAGMA create_fts_index(my_table, 'CustomerId', 'CustomerName', ignore='(\\\\.|[^a-z0-9''])+')\ndiff --git a/test/sql/fts/test_fts_attach.test b/test/sql/fts/test_fts_attach.test\ndeleted file mode 100644\nindex 9d9003674f03..000000000000\n--- a/test/sql/fts/test_fts_attach.test\n+++ /dev/null\n@@ -1,67 +0,0 @@\n-# name: test/sql/fts/test_fts_attach.test\n-# description: Test FTS and attach\n-# group: [fts]\n-\n-# issue #7384 and #8141\n-\n-require fts\n-\n-require skip_reload\n-\n-require no_alternative_verify\n-\n-statement ok\n-ATTACH '__TEST_DIR__/tester.db' as search_con\n-\n-statement ok\n-CREATE TABLE search_con.main.my_table AS SELECT 1 AS CustomerId, 'hans' as CustomerName\n-\n-statement ok\n-PRAGMA create_fts_index(search_con.main.my_table, 'CustomerId', 'CustomerName')\n-\n-statement ok\n-SELECT search_con.fts_main_my_table.match_bm25(1, 'han')\n-\n-statement ok\n-DETACH search_con\n-\n-# test reopened #8141\n-load __TEST_DIR__/index.db\n-\n-statement ok\n-CREATE TABLE data AS SELECT 0 __index, 0 id, 'lorem ipsum' nl, NULL code;\n-\n-statement ok\n-PRAGMA create_fts_index('data', '__index', '*', overwrite=1);\n-\n-# test that it works before doing the problematic stuff\n-query IIII\n-SELECT * FROM data WHERE fts_main_data.match_bm25(__index, 'lorem') IS NOT NULL;\n-----\n-0\t0\tlorem ipsum\tNULL\n-\n-statement ok\n-ATTACH ':memory:' AS memory;\n-\n-statement ok\n-USE memory;\n-\n-statement ok\n-DETACH \"index\";\n-\n-# now attach again\n-statement ok\n-ATTACH '__TEST_DIR__/index.db' AS db;\n-\n-statement ok\n-USE db;\n-\n-query T\n-SELECT COUNT(*) FROM data;\n-----\n-1\n-\n-query IIII\n-SELECT * FROM data WHERE fts_main_data.match_bm25(__index, 'lorem') IS NOT NULL;\n-----\n-0\t0\tlorem ipsum\tNULL\ndiff --git a/test/sql/fts/test_indexing.test_slow b/test/sql/fts/test_indexing.test_slow\ndeleted file mode 100644\nindex e633dd38b95a..000000000000\n--- a/test/sql/fts/test_indexing.test_slow\n+++ /dev/null\n@@ -1,259 +0,0 @@\n-# name: test/sql/fts/test_indexing.test_slow\n-# description: Full text search indexing\n-# group: [fts]\n-\n-require skip_reload\n-\n-require fts\n-\n-require no_alternative_verify\n-\n-statement ok\n-PRAGMA enable_verification\n-\n-statement error\n-PRAGMA drop_fts_index('test')\n-----\n-\n-statement ok\n-CREATE SCHEMA fts_main_test\n-\n-statement ok\n-PRAGMA drop_fts_index('test')\n-\n-statement ok\n-CREATE TABLE documents(id VARCHAR, body VARCHAR)\n-\n-statement ok\n-INSERT INTO documents VALUES ('doc1', ' QU\u00c1CKING+QU\u00c1CKING+QU\u00c1CKING'), ('doc2', ' B\u00c1RKING+B\u00c1RKING+B\u00c1RKING+B\u00c1RKING'), ('doc3', ' M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+999')\n-\n-# non-existant parameters should yield an error\n-statement error\n-PRAGMA create_fts_index('documents', 'id', 'body', nonexistant_param='dummy')\n-----\n-\n-# test different stemmer\n-statement ok\n-PRAGMA create_fts_index('documents', 'id', 'body', stemmer='turkish')\n-\n-# cannot overwrite without supplying the 'overwrite' param\n-statement error\n-PRAGMA create_fts_index('documents', 'id', 'body')\n-----\n-\n-statement ok\n-PRAGMA create_fts_index('documents', 'id', 'body', overwrite=true)\n-\n-# drop and re-create\n-statement ok\n-PRAGMA drop_fts_index('documents')\n-\n-statement error\n-PRAGMA create_fts_index('documents', 'id', 'body', stopwords='nonexistant_stopwords_table')\n-----\n-\n-statement ok\n-PRAGMA create_fts_index('documents', 'id', 'body', stopwords='english')\n-\n-query III\n-SELECT termid, docid, fieldid FROM fts_main_documents.terms\n-----\n-0\t0\t0\n-0\t0\t0\n-0\t0\t0\n-1\t1\t0\n-1\t1\t0\n-1\t1\t0\n-1\t1\t0\n-2\t2\t0\n-2\t2\t0\n-2\t2\t0\n-2\t2\t0\n-2\t2\t0\n-\n-query III\n-SELECT name, docid, len FROM fts_main_documents.docs\n-----\n-doc1\t0\t3\n-doc2\t1\t4\n-doc3\t2\t5\n-\n-query III\n-SELECT termid, term, df FROM fts_main_documents.dict\n-----\n-0\tquack\t1\n-1\tbark\t1\n-2\tmeow\t1\n-\n-query T\n-WITH ppterms AS (SELECT stem(unnest(string_split_regex(regexp_replace(lower(strip_accents('QU\u00c1CKED B\u00c1RKED')), '[^a-z]', ' ', 'g'), '\\s+')), 'porter') AS term),\n-qtermids AS (SELECT termid FROM fts_main_documents.dict AS dict, ppterms WHERE dict.term = ppterms.term)\n-SELECT * FROM qtermids\n-----\n-0\n-1\n-\n-query II\n-WITH ppterms AS (SELECT stem(unnest(string_split_regex(regexp_replace(lower(strip_accents('QU\u00c1CKED B\u00c1RKED')), '[^a-z]', ' ', 'g'), '\\s+')), 'porter') AS term),\n-qtermids AS (SELECT termid FROM fts_main_documents.dict AS dict, ppterms WHERE dict.term = ppterms.term),\n-qterms AS (SELECT termid, docid FROM fts_main_documents.terms AS terms WHERE termid IN (SELECT qtermids.termid FROM qtermids))\n-SELECT * FROM qterms\n-----\n-0\t0\n-0\t0\n-0\t0\n-1\t1\n-1\t1\n-1\t1\n-1\t1\n-\n-# log((3 - df + 0.5) / (df + 0.5)) -- number of documents = 3\n-# (len / 4) -- average document length is 4\n-# HAVING COUNT(DISTINCT termid) = 3 -- commented this out because there is no document with all terms present\n-query II\n-WITH ppterms AS (SELECT stem(unnest(string_split_regex(regexp_replace(lower(strip_accents('QU\u00c1CKED B\u00c1RKED')), '[^a-z]', ' ', 'g'), '\\s+')), 'porter') AS term),\n-qtermids AS (SELECT termid FROM fts_main_documents.dict AS dict, ppterms WHERE dict.term = ppterms.term),\n-qterms AS (SELECT termid, docid FROM fts_main_documents.terms AS terms WHERE termid IN (SELECT qtermids.termid FROM qtermids)),\n-subscores AS (\n-SELECT docs.docid, len, term_tf.termid,\n-        tf, df, (log((3 - df + 0.5) / (df + 0.5))* ((tf * (1.2 + 1)/(tf + 1.2 * (1 - 0.75 + 0.75 * (len / 4)))))) AS subscore\n-FROM (SELECT termid, docid, COUNT(*) AS tf FROM qterms\n-    GROUP BY docid, termid) AS term_tf\n-    JOIN (SELECT docid FROM qterms\n-        GROUP BY docid) -- HAVING COUNT(DISTINCT termid) = 3)\n-        AS cdocs ON term_tf.docid = cdocs.docid\n-    JOIN fts_main_documents.docs AS docs ON term_tf.docid = docs.docid\n-    JOIN fts_main_documents.dict AS dict ON term_tf.termid = dict.termid)\n-SELECT name, score FROM (SELECT docid, sum(subscore) AS score\n-    FROM subscores GROUP BY docid) AS scores JOIN fts_main_documents.docs AS docs ON\n-    scores.docid = docs.docid ORDER BY score DESC LIMIT 1000\n-----\n-doc2\t0.3754363455046031\n-doc1\t0.36835264087244074\n-\n-# now test the actual match macro\n-query III\n-SELECT score, id, body FROM (SELECT *, fts_main_documents.match_bm25(id, 'quacked barked') AS score FROM documents) sq WHERE score IS NOT NULL ORDER BY score DESC\n-----\n-0.7208701623069375\tdoc2\t B\u00c1RKING+B\u00c1RKING+B\u00c1RKING+B\u00c1RKING\n-0.7072688384898254\tdoc1\t QU\u00c1CKING+QU\u00c1CKING+QU\u00c1CKING\n-\n-# drop and re-create, but index both the 'body' and 'author' column this time\n-statement ok\n-PRAGMA drop_fts_index('documents')\n-\n-statement ok\n-DROP TABLE documents\n-\n-statement ok\n-CREATE TABLE documents(id VARCHAR, body VARCHAR, author VARCHAR)\n-\n-statement ok\n-INSERT INTO documents VALUES ('doc1', ' QU\u00c1CKING+QU\u00c1CKING+QU\u00c1CKING', 'Hannes'), ('doc2', ' B\u00c1RKING+B\u00c1RKING+B\u00c1RKING+B\u00c1RKING', 'Mark'), ('doc3', ' M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+999', 'Laurens')\n-\n-statement ok\n-PRAGMA create_fts_index('main.documents', 'id', 'body', 'author')\n-\n-# prepared statement for easier use\n-statement ok\n-PREPARE fts_query AS (WITH scored_docs AS (SELECT *, fts_main_documents.match_bm25(id, ?) AS score FROM documents) SELECT id, body, author FROM scored_docs WHERE score IS NOT NULL ORDER BY score DESC)\n-\n-query III\n-EXECUTE fts_query('hannes')\n-----\n-doc1\t QU\u00c1CKING+QU\u00c1CKING+QU\u00c1CKING\tHannes\n-\n-query III\n-EXECUTE fts_query('mark laurens')\n-----\n-doc2\t B\u00c1RKING+B\u00c1RKING+B\u00c1RKING+B\u00c1RKING\tMark\n-doc3\t M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+999\tLaurens\n-\n-query III\n-EXECUTE fts_query(NULL)\n-----\n-\n-# different order by changing the parameters\n-query III\n-SELECT id, body, author FROM (SELECT *, fts_main_documents.match_bm25(id, 'quacked barked', k := 0.6, b := 0.1) AS score FROM documents) sq WHERE score IS NOT NULL ORDER BY score DESC\n-----\n-doc2\t B\u00c1RKING+B\u00c1RKING+B\u00c1RKING+B\u00c1RKING\tMark\n-doc1\t QU\u00c1CKING+QU\u00c1CKING+QU\u00c1CKING\tHannes\n-\n-# no results for conjunctive query because no document contains both 'mark' and 'laurens\n-query I\n-SELECT id FROM (SELECT *, fts_main_documents.match_bm25(id, 'mark laurens', conjunctive := 1) AS score FROM documents) sq WHERE score IS NOT NULL ORDER BY score DESC\n-----\n-\n-# strings 'mark' and 'laurens' are not found in the 'body' field of the table 'documents'\n-query I\n-SELECT id FROM (SELECT *, fts_main_documents.match_bm25(id, 'mark laurens', fields := 'body') AS score FROM documents) sq WHERE score IS NOT NULL ORDER BY score DESC\n-----\n-\n-# but they are found in the 'author' field!\n-query I\n-SELECT id FROM (SELECT *, fts_main_documents.match_bm25(id, 'mark laurens', fields := 'author') AS score FROM documents) sq WHERE score IS NOT NULL ORDER BY score DESC\n-----\n-doc2\n-doc3\n-\n-# if we search both the 'author' and 'body' fields then we get the same behaviour as leaving the fields empty\n-query I\n-SELECT id FROM (SELECT *, fts_main_documents.match_bm25(id, 'mark laurens', fields := 'body,author') AS score FROM documents) sq WHERE score IS NOT NULL ORDER BY score DESC\n-----\n-doc2\n-doc3\n-\n-# if we don't search any fields, we won't get any results\n-query I\n-SELECT id FROM (SELECT *, fts_main_documents.match_bm25(id, 'hannes mark laurens', fields := '') AS score FROM documents) sq WHERE score IS NOT NULL ORDER BY score DESC\n-----\n-\n-# re-index with different stopwords table\n-statement ok\n-PRAGMA drop_fts_index('documents')\n-\n-statement ok\n-CREATE TABLE my_stopwords (word VARCHAR)\n-\n-statement ok\n-INSERT INTO my_stopwords VALUES ('quacking')\n-\n-statement ok\n-PRAGMA create_fts_index('documents', 'id', 'body', stopwords='my_stopwords')\n-\n-# the word 'quacking' is no longer indexed, therefore doc1 is no longer retrieved with this query\n-query III\n-SELECT id, body, author FROM (SELECT *, fts_main_documents.match_bm25(id, 'quacked barked') AS score FROM documents) sq WHERE score IS NOT NULL ORDER BY score DESC\n-----\n-doc2\t B\u00c1RKING+B\u00c1RKING+B\u00c1RKING+B\u00c1RKING\tMark\n-\n-# re-index with a custom whitelist, so that we can retrieve documents by searching on numbers\n-statement ok\n-PRAGMA drop_fts_index('documents')\n-\n-statement ok\n-PRAGMA create_fts_index('documents', 'id', 'body', ignore='(\\\\.|[^a-z0-9])+')\n-\n-query I\n-SELECT body FROM (SELECT *, fts_main_documents.match_bm25(id, '999') AS score FROM documents) sq WHERE score IS NOT NULL ORDER BY score DESC\n-----\n- M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+999\n-\n-# re-index with '*' to index all columns\n-statement ok\n-PRAGMA drop_fts_index('documents')\n-\n-statement ok\n-PRAGMA create_fts_index('documents', 'id', '*', stopwords='english')\n-\n-# prepared statement again for easier use\n-statement ok\n-PREPARE fts_query AS (WITH scored_docs AS (SELECT *, fts_main_documents.match_bm25(id, ?) AS score FROM documents) SELECT id, body, author FROM scored_docs WHERE score IS NOT NULL ORDER BY score DESC)\n-\n-query III\n-EXECUTE fts_query('quacked mark laurens')\n-----\n-doc1\t QU\u00c1CKING+QU\u00c1CKING+QU\u00c1CKING\tHannes\n-doc2\t B\u00c1RKING+B\u00c1RKING+B\u00c1RKING+B\u00c1RKING\tMark\n-doc3\t M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+999\tLaurens\ndiff --git a/test/sql/fts/test_indexing_and_schema.test b/test/sql/fts/test_indexing_and_schema.test\ndeleted file mode 100644\nindex 19f9e43c9878..000000000000\n--- a/test/sql/fts/test_indexing_and_schema.test\n+++ /dev/null\n@@ -1,39 +0,0 @@\n-# name: test/sql/fts/test_indexing_and_schema.test\n-# description: Refer default schema when the table name doesn't have a qualifier.\n-# group: [fts]\n-\n-require fts\n-\n-require no_alternative_verify\n-\n-statement ok\n-CREATE SCHEMA test\n-\n-statement ok\n-CREATE TABLE test.documents(id VARCHAR, body VARCHAR)\n-\n-statement ok\n-INSERT INTO test.documents VALUES ('doc1', ' QU\u00c1CKING+QU\u00c1CKING+QU\u00c1CKING'), ('doc2', ' B\u00c1RKING+B\u00c1RKING+B\u00c1RKING+B\u00c1RKING'), ('doc3', ' M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+M\u00c9OWING+999')\n-\n-statement error\n-PRAGMA create_fts_index('documents', 'id', 'body')\n-----\n-\n-statement ok\n-SET SCHEMA='test'\n-\n-statement ok\n-PRAGMA create_fts_index('documents', 'id', 'body')\n-\n-statement ok\n-SET SCHEMA='main'\n-\n-statement error\n-PRAGMA drop_fts_index('documents')\n-----\n-\n-statement ok\n-SET SCHEMA='test'\n-\n-statement ok\n-PRAGMA drop_fts_index('documents')\ndiff --git a/test/sql/fts/test_issue_10254.test b/test/sql/fts/test_issue_10254.test\ndeleted file mode 100644\nindex c1afeaf3f6a9..000000000000\n--- a/test/sql/fts/test_issue_10254.test\n+++ /dev/null\n@@ -1,25 +0,0 @@\n-# name: test/sql/fts/test_issue_10254.test\n-# description: Test issue #10254: FTS not working with stemmer\n-# group: [fts]\n-\n-require fts\n-\n-require no_alternative_verify\n-\n-statement ok\n-CREATE TABLE data (context VARCHAR, question VARCHAR, id BIGINT)\n-\n-statement ok\n-INSERT INTO data VALUES\n-    ('\u041c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u044b\u0439 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c \u2014 \u0432\u043d\u0435\u0441\u0438\u0441\u0442\u0435\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u0436\u0438\u0432\u044b\u0445 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u043e\u0432, \u0442\u0435\u043b\u043e \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0441\u043e\u0441\u0442\u043e\u0438\u0442 \u0438\u0437 \u043c\u043d\u043e\u0433\u0438\u0445 \u043a\u043b\u0435\u0442\u043e\u043a, \u0431\u043e\u043b\u044c\u0448\u0430\u044f \u0447\u0430\u0441\u0442\u044c \u043a\u043e\u0442\u043e\u0440\u044b\u0445 (\u043a\u0440\u043e\u043c\u0435 \u0441\u0442\u0432\u043e\u043b\u043e\u0432\u044b\u0445, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u043a\u043b\u0435\u0442\u043e\u043a \u043a\u0430\u043c\u0431\u0438\u044f \u0443 \u0440\u0430\u0441\u0442\u0435\u043d\u0438\u0439) \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u044b, \u0442\u043e \u0435\u0441\u0442\u044c \u0440\u0430\u0437\u043b\u0438\u0447\u0430\u044e\u0442\u0441\u044f \u043f\u043e \u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044e \u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u043c\u044b\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044f\u043c. \u0421\u043b\u0435\u0434\u0443\u0435\u0442 \u043e\u0442\u043b\u0438\u0447\u0430\u0442\u044c \u043c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0438 \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u043e\u0441\u0442\u044c. \u0423 \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u043e\u0432 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043a\u043b\u0435\u0442\u043a\u0438, \u0430 \u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e, \u0438 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0442\u0435\u043b\u0430 \u043d\u0430 \u0442\u043a\u0430\u043d\u0438. \u0413\u0440\u0430\u043d\u0438\u0446\u0430 \u043c\u0435\u0436\u0434\u0443 \u043c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c\u044e \u0438 \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u043e\u0441\u0442\u044c\u044e \u043d\u0435\u0447\u0451\u0442\u043a\u0430\u044f. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0432\u043e\u043b\u044c\u0432\u043e\u043a\u0441 \u0447\u0430\u0441\u0442\u043e \u043e\u0442\u043d\u043e\u0441\u044f\u0442 \u043a \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u044b\u043c \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u0430\u043c, \u0445\u043e\u0442\u044f \u0432 \u0435\u0433\u043e \u043a\u043e\u043b\u043e\u043d\u0438\u044f\u0445 \u0435\u0441\u0442\u044c \u0447\u0451\u0442\u043a\u043e\u0435 \u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0435\u0442\u043e\u043a \u043d\u0430 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u0438\u0432\u043d\u044b\u0435 \u0438 \u0441\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0435. \u041a\u0440\u043e\u043c\u0435 \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0430\u0446\u0438\u0438 \u043a\u043b\u0435\u0442\u043e\u043a, \u0434\u043b\u044f \u043c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u044b\u0445 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0435\u043d \u0438 \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0441\u043e\u043a\u0438\u0439 \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u0438\u043d\u0442\u0435\u0433\u0440\u0430\u0446\u0438\u0438, \u0447\u0435\u043c \u0434\u043b\u044f \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0444\u043e\u0440\u043c. \u041c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u044b\u0435 \u0436\u0438\u0432\u043e\u0442\u043d\u044b\u0435, \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u043f\u043e\u044f\u0432\u0438\u043b\u0438\u0441\u044c \u043d\u0430 \u0417\u0435\u043c\u043b\u0435 2,1 \u043c\u0438\u043b\u043b\u0438\u0430\u0440\u0434\u0430 \u043b\u0435\u0442 \u043d\u0430\u0437\u0430\u0434, \u0432\u0441\u043a\u043e\u0440\u0435 \u043f\u043e\u0441\u043b\u0435 \u043a\u0438\u0441\u043b\u043e\u0440\u043e\u0434\u043d\u043e\u0439 \u0440\u0435\u0432\u043e\u043b\u044e\u0446\u0438\u0438 .', '\u0423 \u043a\u0430\u043a\u0438\u0445 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u043e\u0432 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043a\u043b\u0435\u0442\u043a\u0438?', 0),\n-    ('\u041c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u044b\u0439 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c \u2014 \u0432\u043d\u0435\u0441\u0438\u0441\u0442\u0435\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u0436\u0438\u0432\u044b\u0445 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u043e\u0432, \u0442\u0435\u043b\u043e \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0441\u043e\u0441\u0442\u043e\u0438\u0442 \u0438\u0437 \u043c\u043d\u043e\u0433\u0438\u0445 \u043a\u043b\u0435\u0442\u043e\u043a, \u0431\u043e\u043b\u044c\u0448\u0430\u044f \u0447\u0430\u0441\u0442\u044c \u043a\u043e\u0442\u043e\u0440\u044b\u0445 (\u043a\u0440\u043e\u043c\u0435 \u0441\u0442\u0432\u043e\u043b\u043e\u0432\u044b\u0445, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u043a\u043b\u0435\u0442\u043e\u043a \u043a\u0430\u043c\u0431\u0438\u044f \u0443 \u0440\u0430\u0441\u0442\u0435\u043d\u0438\u0439) \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u044b, \u0442\u043e \u0435\u0441\u0442\u044c \u0440\u0430\u0437\u043b\u0438\u0447\u0430\u044e\u0442\u0441\u044f \u043f\u043e \u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044e \u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u043c\u044b\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044f\u043c. \u0421\u043b\u0435\u0434\u0443\u0435\u0442 \u043e\u0442\u043b\u0438\u0447\u0430\u0442\u044c \u043c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0438 \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u043e\u0441\u0442\u044c. \u0423 \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u043e\u0432 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043a\u043b\u0435\u0442\u043a\u0438, \u0430 \u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e, \u0438 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0442\u0435\u043b\u0430 \u043d\u0430 \u0442\u043a\u0430\u043d\u0438. \u0413\u0440\u0430\u043d\u0438\u0446\u0430 \u043c\u0435\u0436\u0434\u0443 \u043c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c\u044e \u0438 \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u043e\u0441\u0442\u044c\u044e \u043d\u0435\u0447\u0451\u0442\u043a\u0430\u044f. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0432\u043e\u043b\u044c\u0432\u043e\u043a\u0441 \u0447\u0430\u0441\u0442\u043e \u043e\u0442\u043d\u043e\u0441\u044f\u0442 \u043a \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u044b\u043c \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u0430\u043c, \u0445\u043e\u0442\u044f \u0432 \u0435\u0433\u043e \u043a\u043e\u043b\u043e\u043d\u0438\u044f\u0445 \u0435\u0441\u0442\u044c \u0447\u0451\u0442\u043a\u043e\u0435 \u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0435\u0442\u043e\u043a \u043d\u0430 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u0438\u0432\u043d\u044b\u0435 \u0438 \u0441\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0435. \u041a\u0440\u043e\u043c\u0435 \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0430\u0446\u0438\u0438 \u043a\u043b\u0435\u0442\u043e\u043a, \u0434\u043b\u044f \u043c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u044b\u0445 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0435\u043d \u0438 \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0441\u043e\u043a\u0438\u0439 \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u0438\u043d\u0442\u0435\u0433\u0440\u0430\u0446\u0438\u0438, \u0447\u0435\u043c \u0434\u043b\u044f \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0444\u043e\u0440\u043c. \u041c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u044b\u0435 \u0436\u0438\u0432\u043e\u0442\u043d\u044b\u0435, \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u043f\u043e\u044f\u0432\u0438\u043b\u0438\u0441\u044c \u043d\u0430 \u0417\u0435\u043c\u043b\u0435 2,1 \u043c\u0438\u043b\u043b\u0438\u0430\u0440\u0434\u0430 \u043b\u0435\u0442 \u043d\u0430\u0437\u0430\u0434, \u0432\u0441\u043a\u043e\u0440\u0435 \u043f\u043e\u0441\u043b\u0435 \u043a\u0438\u0441\u043b\u043e\u0440\u043e\u0434\u043d\u043e\u0439 \u0440\u0435\u0432\u043e\u043b\u044e\u0446\u0438\u0438 .', '\u041a\u0430\u043a\u0438\u0435 \u0436\u0438\u0432\u043e\u0442\u043d\u044b\u0435 \u043f\u043e\u044f\u0432\u0438\u043b\u0438\u0441\u044c \u043d\u0430 \u0417\u0435\u043c\u043b\u0435 2,1 \u043c\u0438\u043b\u043b\u0438\u0430\u0440\u0434\u0430 \u043b\u0435\u0442 \u043d\u0430\u0437\u0430\u0434?', 1),\n-    ('\u041c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u044b\u0439 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c \u2014 \u0432\u043d\u0435\u0441\u0438\u0441\u0442\u0435\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u0436\u0438\u0432\u044b\u0445 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u043e\u0432, \u0442\u0435\u043b\u043e \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0441\u043e\u0441\u0442\u043e\u0438\u0442 \u0438\u0437 \u043c\u043d\u043e\u0433\u0438\u0445 \u043a\u043b\u0435\u0442\u043e\u043a, \u0431\u043e\u043b\u044c\u0448\u0430\u044f \u0447\u0430\u0441\u0442\u044c \u043a\u043e\u0442\u043e\u0440\u044b\u0445 (\u043a\u0440\u043e\u043c\u0435 \u0441\u0442\u0432\u043e\u043b\u043e\u0432\u044b\u0445, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u043a\u043b\u0435\u0442\u043e\u043a \u043a\u0430\u043c\u0431\u0438\u044f \u0443 \u0440\u0430\u0441\u0442\u0435\u043d\u0438\u0439) \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u044b, \u0442\u043e \u0435\u0441\u0442\u044c \u0440\u0430\u0437\u043b\u0438\u0447\u0430\u044e\u0442\u0441\u044f \u043f\u043e \u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044e \u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u043c\u044b\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044f\u043c. \u0421\u043b\u0435\u0434\u0443\u0435\u0442 \u043e\u0442\u043b\u0438\u0447\u0430\u0442\u044c \u043c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0438 \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u043e\u0441\u0442\u044c. \u0423 \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u043e\u0432 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043a\u043b\u0435\u0442\u043a\u0438, \u0430 \u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e, \u0438 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0442\u0435\u043b\u0430 \u043d\u0430 \u0442\u043a\u0430\u043d\u0438. \u0413\u0440\u0430\u043d\u0438\u0446\u0430 \u043c\u0435\u0436\u0434\u0443 \u043c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c\u044e \u0438 \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u043e\u0441\u0442\u044c\u044e \u043d\u0435\u0447\u0451\u0442\u043a\u0430\u044f. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0432\u043e\u043b\u044c\u0432\u043e\u043a\u0441 \u0447\u0430\u0441\u0442\u043e \u043e\u0442\u043d\u043e\u0441\u044f\u0442 \u043a \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u044b\u043c \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u0430\u043c, \u0445\u043e\u0442\u044f \u0432 \u0435\u0433\u043e \u043a\u043e\u043b\u043e\u043d\u0438\u044f\u0445 \u0435\u0441\u0442\u044c \u0447\u0451\u0442\u043a\u043e\u0435 \u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0435\u0442\u043e\u043a \u043d\u0430 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u0438\u0432\u043d\u044b\u0435 \u0438 \u0441\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0435. \u041a\u0440\u043e\u043c\u0435 \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0430\u0446\u0438\u0438 \u043a\u043b\u0435\u0442\u043e\u043a, \u0434\u043b\u044f \u043c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u044b\u0445 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0435\u043d \u0438 \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0441\u043e\u043a\u0438\u0439 \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u0438\u043d\u0442\u0435\u0433\u0440\u0430\u0446\u0438\u0438, \u0447\u0435\u043c \u0434\u043b\u044f \u043a\u043e\u043b\u043e\u043d\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0444\u043e\u0440\u043c. \u041c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u044b\u0435 \u0436\u0438\u0432\u043e\u0442\u043d\u044b\u0435, \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u043f\u043e\u044f\u0432\u0438\u043b\u0438\u0441\u044c \u043d\u0430 \u0417\u0435\u043c\u043b\u0435 2,1 \u043c\u0438\u043b\u043b\u0438\u0430\u0440\u0434\u0430 \u043b\u0435\u0442 \u043d\u0430\u0437\u0430\u0434, \u0432\u0441\u043a\u043e\u0440\u0435 \u043f\u043e\u0441\u043b\u0435 \u043a\u0438\u0441\u043b\u043e\u0440\u043e\u0434\u043d\u043e\u0439 \u0440\u0435\u0432\u043e\u043b\u044e\u0446\u0438\u0438 .', '\u041a\u043e\u0433\u0434\u0430 \u043f\u0440\u0435\u0434\u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u043e\u044f\u0432\u0438\u043b\u0438\u0441\u044c \u043c\u043d\u043e\u0433\u043e\u043a\u043b\u0435\u0442\u043e\u0447\u043d\u044b\u0435 \u0436\u0438\u0432\u043e\u0442\u043d\u044b\u0435?', 2)\n-\n-statement ok\n-PRAGMA create_fts_index('data', 'id', 'context', 'question', stemmer='russian', overwrite=1);\n-\n-query I\n-SELECT id FROM (SELECT *, fts_main_data.match_bm25(id, '\u041a\u0430\u043a\u0438\u0435') AS score FROM data) sq WHERE score IS NOT NULL ORDER BY score DESC;\n-----\n-0\n-1\ndiff --git a/test/sql/fts/test_issue_10281.test b/test/sql/fts/test_issue_10281.test\ndeleted file mode 100644\nindex a62e3b5c93c4..000000000000\n--- a/test/sql/fts/test_issue_10281.test\n+++ /dev/null\n@@ -1,19 +0,0 @@\n-# name: test/sql/fts/test_issue_10281.test\n-# description: Test issue #10281: Error when trying to create FTS index for column with struct data\n-# group: [fts]\n-\n-require fts\n-\n-require no_alternative_verify\n-\n-statement ok\n-CREATE OR REPLACE TABLE data AS SELECT {'duck': 42} conversations, 42::bigint _id;\n-\n-statement ok\n-PRAGMA create_fts_index('data', '_id', 'conversations');\n-\n-# we should be able to retrieve the struct col\n-query I\n-SELECT _id FROM (SELECT *, fts_main_data.match_bm25(_id, 'duck') AS score FROM data) sq WHERE score IS NOT NULL ORDER BY score DESC;\n-----\n-42\ndiff --git a/test/sql/fts/test_issue_5936.test b/test/sql/fts/test_issue_5936.test\ndeleted file mode 100644\nindex 1f08477d6a79..000000000000\n--- a/test/sql/fts/test_issue_5936.test\n+++ /dev/null\n@@ -1,18 +0,0 @@\n-# name: test/sql/fts/test_issue_5936.test\n-# description: Issue #5936 - Confusing \"column does not exist\" error when using column named \"document\" with full text search\n-# group: [fts]\n-\n-require skip_reload\n-\n-require fts\n-\n-require no_alternative_verify\n-\n-statement ok\n-CREATE TABLE documents(document VARCHAR, url VARCHAR);\n-\n-statement ok\n-INSERT INTO documents VALUES ('hello world', 'https://example.com'), ('foobar', 'https://google.com');\n-\n-statement ok\n-PRAGMA create_fts_index(documents, url, document);\ndiff --git a/test/sql/fts/test_stemmer.test_slow b/test/sql/fts/test_stemmer.test_slow\ndeleted file mode 100644\nindex cf637c0b0d5a..000000000000\n--- a/test/sql/fts/test_stemmer.test_slow\n+++ /dev/null\n@@ -1,73 +0,0 @@\n-# name: test/sql/fts/test_stemmer.test_slow\n-# description: Full text search stemmer\n-# group: [fts]\n-\n-require fts\n-\n-statement ok\n-PRAGMA enable_verification\n-\n-query T\n-select stem('iiiiiiinformation', 'porter')\n-----\n-iiiiiiinform\n-\n-query T\n-SELECT stem(NULL, 'porter')\n-----\n-NULL\n-\n-query T\n-SELECT stem('', 'porter')\n-----\n-(empty)\n-\n-query T\n-SELECT stem('connection', 'porter')\n-----\n-connect\n-\n-query T\n-SELECT stem('an', 'porter')\n-----\n-an\n-\n-query T\n-SELECT stem('\ud83e\udd86', 'porter')\n-----\n-\ud83e\udd86\n-\n-query T\n-SELECT stem('information information', 'porter')\n-----\n-information inform\n-\n-query T\n-SELECT stem(concat(repeat('i', 64), 'nformation'), 'porter')\n-----\n-iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiinform\n-\n-query T\n-SELECT stem('information', 'none')\n-----\n-information\n-\n-query T\n-SELECT stem('information ', 'porter')\n-----\n-information \n-\n-query T\n-select stem(UNNEST(string_split(repeat('information ', 5), ' ')), 'porter')\n-----\n-inform\n-inform\n-inform\n-inform\n-inform\n-(empty)\n-\n-query I\n-SELECT stem(UNNEST(string_split(string_agg(range, 'information '), ' ')), 'porter') AS s, mod(range, 100) xx FROM range(50000) GROUP BY xx ORDER BY s\n-----\n-100000 values hashing to 030f4662a25fbc772e84af37e1cc8177\n",
  "problem_statement": "[fts] not statically linked when `DUCKDB_EXTENSION_FTS_LINKED=1` (commented out)\n### What happens?\r\n\r\nNot linked, its commented out :)\r\n\r\nhttps://github.com/duckdb/duckdb/blob/1bb332c9c59a9d15b196b4486a6d1ffcaa833ba5/src/main/extension/extension_helper.cpp#L497\r\n\r\n### To Reproduce\r\n\r\nBuild with `DUCKDB_EXTENSION_FTS_LINKED=1`, try:\r\n\r\n```\r\nSELECT extension_name, installed, description FROM duckdb_extensions() WHERE extension_name = 'fts';\r\n```\r\n\r\n> ```\r\n> \u2502 fts            \u2502 true      \u2502 Adds support for Full-Text Search Indexes \u2502\r\n> ```\r\n\r\nBut, running `PRAGMA create_fts_index(...` gets upset and says to install the extension\r\n\r\n### OS:\r\n\r\niOS / macOS aarch64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.1\r\n\r\n### DuckDB Client:\r\n\r\nSwift\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nQuinn Blenkinsop\r\n\r\n### Affiliation:\r\n\r\nNone\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nNot applicable - the reproduction does not require a data set\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "",
  "created_at": "2024-11-18T08:21:18Z"
}