{
  "repo": "duckdb/duckdb",
  "pull_number": 16317,
  "instance_id": "duckdb__duckdb-16317",
  "issue_numbers": [
    "16306"
  ],
  "base_commit": "ef50246314b2f80dcf6a8132db45a80dab7dd162",
  "patch": "diff --git a/extension/parquet/column_writer.cpp b/extension/parquet/column_writer.cpp\nindex 8791bc596c08..b4c33ef41f52 100644\n--- a/extension/parquet/column_writer.cpp\n+++ b/extension/parquet/column_writer.cpp\n@@ -309,6 +309,7 @@ struct PageInformation {\n \tidx_t offset = 0;\n \tidx_t row_count = 0;\n \tidx_t empty_count = 0;\n+\tidx_t null_count = 0;\n \tidx_t estimated_page_size = 0;\n };\n \n@@ -464,6 +465,8 @@ void BasicColumnWriter::Prepare(ColumnWriterState &state_p, ColumnWriterState *p\n \t\t\t\tstate.page_info.push_back(new_info);\n \t\t\t\tpage_info_ref = state.page_info.back();\n \t\t\t}\n+\t\t} else {\n+\t\t\tpage_info.null_count++;\n \t\t}\n \t\tvector_index++;\n \t}\n@@ -1237,7 +1240,8 @@ class StandardColumnWriter : public BasicColumnWriter {\n \t\tauto &state = state_p.Cast<StandardColumnWriterState<SRC>>();\n \t\tconst auto &page_info = state_p.page_info[page_idx];\n \t\tauto result = make_uniq<StandardWriterPageState<SRC, TGT>>(\n-\t\t    page_info.row_count - page_info.empty_count, state.total_string_size, state.encoding, state.dictionary);\n+\t\t    page_info.row_count - (page_info.empty_count + page_info.null_count), state.total_string_size,\n+\t\t    state.encoding, state.dictionary);\n \t\treturn std::move(result);\n \t}\n \n",
  "test_patch": "diff --git a/test/issues/general/test_16257.test_slow b/test/issues/general/test_16257.test_slow\nindex 6b3faf9a7ba4..df2a3ed75f9c 100644\n--- a/test/issues/general/test_16257.test_slow\n+++ b/test/issues/general/test_16257.test_slow\n@@ -21,5 +21,6 @@ CREATE OR REPLACE MACRO lorem_sentence(rand, words) AS lorem_sentence_util(list_\n statement ok\n SET preserve_insertion_order=false;\n \n+# added NULLs for issue #16306\n statement ok\n-COPY (SELECT lorem_sentence(random(), 20) FROM range(1_000_000)) TO '__TEST_DIR__/16257.parquet' (PARQUET_VERSION V2, ROW_GROUP_SIZE 2_000_000);\n+COPY (SELECT CASE WHEN random() < 0.01 THEN NULL ELSE lorem_sentence(random(), 20) END FROM range(1_000_000)) TO '__TEST_DIR__/16257.parquet' (PARQUET_VERSION V2, ROW_GROUP_SIZE 2_000_000);\n",
  "problem_statement": "Parquet Write value count mismatch when writing DELTA_BINARY_PACKED\n### What happens?\n\nWriting out a Parquet file using COPY hits an assertion failure. Works in DuckDB 1.2, but not in main HEAD compiled 2025/02/18.\n\nData source: https://noaa-ghcn-pds.s3.amazonaws.com/index.html#parquet/by_year/\n\n### To Reproduce\n\n```sql\nCOPY (\n    SELECT * FROM read_parquet('**/*.parquet', union_by_name = true)\n    WHERE year\n    BETWEEN 2010 AND 2015 ORDER BY element, obs_time\n)\nTO 'weather_v2_zstd_2025_02_18_HEAD.parquet'\n(PARQUET_VERSION V2, COMPRESSION 'zstd');\n```\n\n```\nINTERNAL Error:\nvalue count mismatch when writing DELTA_BINARY_PACKED\n\nStack Trace:\n\n0        duckdb::Exception::Exception(duckdb::ExceptionType, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 64\n1        duckdb::InternalException::InternalException(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 20\n2        duckdb::DbpEncoder::FinishWrite(duckdb::WriteStream&) + 128\n3        duckdb::StandardColumnWriter<duckdb::string_t, duckdb::string_t, duckdb::ParquetStringOperator>::FlushPageState(duckdb::WriteStream&, duckdb::ColumnWriterPageState*) + 268\n4        duckdb::PrimitiveColumnWriter::FlushPage(duckdb::PrimitiveColumnWriterState&) + 124\n5        duckdb::PrimitiveColumnWriter::NextPage(duckdb::PrimitiveColumnWriterState&) + 52\n6        duckdb::PrimitiveColumnWriter::Write(duckdb::ColumnWriterState&, duckdb::Vector&, unsigned long long) + 204\n7        duckdb::ParquetWriter::PrepareRowGroup(duckdb::ColumnDataCollection&, duckdb::PreparedRowGroup&) + 6036\n8        duckdb::ParquetWritePrepareBatch(duckdb::ClientContext&, duckdb::FunctionData&, duckdb::GlobalFunctionData&, duckdb::unique_ptr<duckdb::ColumnDataCollection, std::__1::default_delete<duckdb::ColumnDataCollection>, true>) + 144\n9        duckdb::PrepareBatchTask::Execute(duckdb::PhysicalBatchCopyToFile const&, duckdb::ClientContext&, duckdb::GlobalSinkState&) + 132\n10       duckdb::PhysicalBatchCopyToFile::ExecuteTask(duckdb::ClientContext&, duckdb::GlobalSinkState&) const + 232\n11       duckdb::ProcessRemainingBatchesTask::ExecuteTask(duckdb::TaskExecutionMode) + 32\n12       duckdb::ExecutorTask::Execute(duckdb::TaskExecutionMode) + 236\n13       duckdb::TaskScheduler::ExecuteForever(std::__1::atomic<bool>*) + 612\n14       void* std::__1::__thread_proxy[abi:ne180100]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>>(void*) + 56\n15       _pthread_start + 136\n16       thread_start + 8\n\nThis error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\nFor more information, see https://duckdb.org/docs/dev/internal_errors\n```\n\n### OS:\n\nmacOS Sequoia 15.3.1\n\n### DuckDB Version:\n\nmain/HEAD e249a40c8be4709c6aae693bc8bf2c012cc3d6b2\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nAlejandro Wainzinger\n\n### Affiliation:\n\nN/A\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - I cannot easily share my data sets due to their large size\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n",
  "hints_text": "Thanks \u2013 this runs into a spinlock on the nightly (release build). We'll take a look into what's causing it and also run it in a debug (relassert) build.",
  "created_at": "2025-02-19T15:05:35Z"
}