You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
CASE expressions


</issue>
<code>
[start of README.md]
1: <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="30">
2: 
3: [![Travis](https://api.travis-ci.org/cwida/duckdb.svg?branch=master)](https://travis-ci.org/cwida/duckdb)
4: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
5: [![Coverage Status](https://coveralls.io/repos/github/cwida/duckdb/badge.svg?branch=master)](https://coveralls.io/github/cwida/duckdb?branch=master)
6: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3901452.svg)](https://zenodo.org/record/3901452)
7: 
8: 
9: ## Installation
10: If you just want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
11: 
12: ## Development
13: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
14: 
15: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
16: 
17: 
[end of README.md]
[start of src/common/operator/cast_operators.cpp]
1: #include "duckdb/common/operator/cast_operators.hpp"
2: 
3: #include "duckdb/common/exception.hpp"
4: #include "duckdb/common/limits.hpp"
5: #include "duckdb/common/types/date.hpp"
6: #include "duckdb/common/types/hugeint.hpp"
7: #include "duckdb/common/types/interval.hpp"
8: #include "duckdb/common/types/numeric_helper.hpp"
9: #include "duckdb/common/types/time.hpp"
10: #include "duckdb/common/types/timestamp.hpp"
11: #include "duckdb/common/types/vector.hpp"
12: #include "fmt/format.h"
13: 
14: #include <cctype>
15: #include <cmath>
16: #include <cstdlib>
17: 
18: using namespace std;
19: 
20: namespace duckdb {
21: 
22: template <class SRC, class DST> static bool try_cast_with_overflow_check(SRC value, DST &result) {
23: 	if (value < NumericLimits<DST>::Minimum() || value > NumericLimits<DST>::Maximum()) {
24: 		return false;
25: 	}
26: 	result = (DST)value;
27: 	return true;
28: }
29: 
30: template <class SRC, class DST> static DST cast_with_overflow_check(SRC value) {
31: 	DST result;
32: 	if (!try_cast_with_overflow_check<SRC, DST>(value, result)) {
33: 		throw ValueOutOfRangeException((int64_t)value, GetTypeId<SRC>(), GetTypeId<DST>());
34: 	}
35: 	return result;
36: }
37: 
38: //===--------------------------------------------------------------------===//
39: // Numeric -> int8_t casts
40: //===--------------------------------------------------------------------===//
41: template <> bool TryCast::Operation(int16_t input, int8_t &result, bool strict) {
42: 	return try_cast_with_overflow_check(input, result);
43: }
44: template <> bool TryCast::Operation(int32_t input, int8_t &result, bool strict) {
45: 	return try_cast_with_overflow_check(input, result);
46: }
47: template <> bool TryCast::Operation(int64_t input, int8_t &result, bool strict) {
48: 	return try_cast_with_overflow_check(input, result);
49: }
50: template <> bool TryCast::Operation(float input, int8_t &result, bool strict) {
51: 	return try_cast_with_overflow_check(input, result);
52: }
53: template <> bool TryCast::Operation(double input, int8_t &result, bool strict) {
54: 	return try_cast_with_overflow_check(input, result);
55: }
56: 
57: template <> int8_t Cast::Operation(int16_t input) {
58: 	return cast_with_overflow_check<int16_t, int8_t>(input);
59: }
60: template <> int8_t Cast::Operation(int32_t input) {
61: 	return cast_with_overflow_check<int32_t, int8_t>(input);
62: }
63: template <> int8_t Cast::Operation(int64_t input) {
64: 	return cast_with_overflow_check<int64_t, int8_t>(input);
65: }
66: template <> int8_t Cast::Operation(float input) {
67: 	return cast_with_overflow_check<float, int8_t>(input);
68: }
69: template <> int8_t Cast::Operation(double input) {
70: 	return cast_with_overflow_check<double, int8_t>(input);
71: }
72: //===--------------------------------------------------------------------===//
73: // Numeric -> int16_t casts
74: //===--------------------------------------------------------------------===//
75: template <> bool TryCast::Operation(int32_t input, int16_t &result, bool strict) {
76: 	return try_cast_with_overflow_check(input, result);
77: }
78: template <> bool TryCast::Operation(int64_t input, int16_t &result, bool strict) {
79: 	return try_cast_with_overflow_check(input, result);
80: }
81: template <> bool TryCast::Operation(float input, int16_t &result, bool strict) {
82: 	return try_cast_with_overflow_check(input, result);
83: }
84: template <> bool TryCast::Operation(double input, int16_t &result, bool strict) {
85: 	return try_cast_with_overflow_check(input, result);
86: }
87: 
88: template <> int16_t Cast::Operation(int32_t input) {
89: 	return cast_with_overflow_check<int32_t, int16_t>(input);
90: }
91: template <> int16_t Cast::Operation(int64_t input) {
92: 	return cast_with_overflow_check<int64_t, int16_t>(input);
93: }
94: template <> int16_t Cast::Operation(float input) {
95: 	return cast_with_overflow_check<float, int16_t>(input);
96: }
97: template <> int16_t Cast::Operation(double input) {
98: 	return cast_with_overflow_check<double, int16_t>(input);
99: }
100: //===--------------------------------------------------------------------===//
101: // Numeric -> int32_t casts
102: //===--------------------------------------------------------------------===//
103: template <> bool TryCast::Operation(int64_t input, int32_t &result, bool strict) {
104: 	return try_cast_with_overflow_check(input, result);
105: }
106: template <> bool TryCast::Operation(float input, int32_t &result, bool strict) {
107: 	return try_cast_with_overflow_check(input, result);
108: }
109: template <> bool TryCast::Operation(double input, int32_t &result, bool strict) {
110: 	return try_cast_with_overflow_check(input, result);
111: }
112: 
113: template <> int32_t Cast::Operation(int64_t input) {
114: 	return cast_with_overflow_check<int64_t, int32_t>(input);
115: }
116: template <> int32_t Cast::Operation(float input) {
117: 	return cast_with_overflow_check<float, int32_t>(input);
118: }
119: template <> int32_t Cast::Operation(double input) {
120: 	return cast_with_overflow_check<double, int32_t>(input);
121: }
122: //===--------------------------------------------------------------------===//
123: // Numeric -> int64_t casts
124: //===--------------------------------------------------------------------===//
125: template <> bool TryCast::Operation(float input, int64_t &result, bool strict) {
126: 	return try_cast_with_overflow_check(input, result);
127: }
128: template <> bool TryCast::Operation(double input, int64_t &result, bool strict) {
129: 	return try_cast_with_overflow_check(input, result);
130: }
131: 
132: template <> int64_t Cast::Operation(float input) {
133: 	return cast_with_overflow_check<float, int64_t>(input);
134: }
135: template <> int64_t Cast::Operation(double input) {
136: 	return cast_with_overflow_check<double, int64_t>(input);
137: }
138: 
139: //===--------------------------------------------------------------------===//
140: // Double -> float casts
141: //===--------------------------------------------------------------------===//
142: template <> bool TryCast::Operation(double input, float &result, bool strict) {
143: 	auto res = (float)input;
144: 	if (std::isnan(res) || std::isinf(res)) {
145: 		return false;
146: 	}
147: 	result = res;
148: 	return true;
149: }
150: 
151: template <> float Cast::Operation(double input) {
152: 	float result;
153: 	bool strict = false;
154: 	if (!TryCast::Operation(input, result, strict)) {
155: 		throw ValueOutOfRangeException(input, GetTypeId<double>(), GetTypeId<float>());
156: 	}
157: 	return result;
158: }
159: 
160: //===--------------------------------------------------------------------===//
161: // Cast String -> Numeric
162: //===--------------------------------------------------------------------===//
163: template <class T> static T try_cast_string(string_t input) {
164: 	T result;
165: 	if (!TryCast::Operation<string_t, T>(input, result)) {
166: 		throw ConversionException("Could not convert string '%s' to %s", input.GetData(), TypeIdToString(GetTypeId<T>()).c_str());
167: 	}
168: 	return result;
169: }
170: 
171: 
172: 
173: template <class T> static T try_strict_cast_string(string_t input) {
174: 	T result;
175: 	if (!TryCast::Operation<string_t, T>(input, result, true)) {
176: 		throw ConversionException("Could not convert string '%s' to %s", input.GetData(), TypeIdToString(GetTypeId<T>()).c_str());
177: 	}
178: 	return result;
179: }
180: 
181: struct IntegerCastOperation {
182: 	template<class T, bool NEGATIVE>
183: 	static bool HandleDigit(T &result, uint8_t digit) {
184: 		if (NEGATIVE) {
185: 			if (result < (NumericLimits<T>::Minimum() + digit) / 10) {
186: 				return false;
187: 			}
188: 			result = result * 10 - digit;
189: 		} else {
190: 			if (result > (NumericLimits<T>::Maximum() - digit) / 10) {
191: 				return false;
192: 			}
193: 			result = result * 10 + digit;
194: 		}
195: 		return true;
196: 	}
197: 
198: 	template<class T>
199: 	static bool HandleExponent(T &result, int64_t exponent) {
200: 		double dbl_res = result * pow(10, exponent);
201: 		if (dbl_res < NumericLimits<T>::Minimum() || dbl_res > NumericLimits<T>::Maximum()) {
202: 			return false;
203: 		}
204: 		result = (T)dbl_res;
205: 		return true;
206: 	}
207: 
208: 	template<class T>
209: 	static bool Finalize(T &result) {
210: 		return true;
211: 	}
212: };
213: 
214: template <class T, bool NEGATIVE, bool ALLOW_EXPONENT, class OP=IntegerCastOperation>
215: static bool IntegerCastLoop(const char *buf, idx_t len, T &result, bool strict) {
216: 	idx_t start_pos = NEGATIVE || *buf == '+' ? 1 : 0;
217: 	idx_t pos = start_pos;
218: 	while(pos < len) {
219: 		if (!std::isdigit((unsigned char)buf[pos])) {
220: 			// not a digit!
221: 			if (buf[pos] == '.') {
222: 				if (strict) {
223: 					return false;
224: 				}
225: 				bool number_before_period = pos > start_pos;
226: 				if (!OP::template Finalize<T>(result)) {
227: 					return false;
228: 				}
229: 				// decimal point: we accept decimal values for integers as well
230: 				// we just truncate them
231: 				// make sure everything after the period is a number
232: 				pos++;
233: 				idx_t start_digit = pos;
234: 				while(pos < len) {
235: 					if (!std::isdigit((unsigned char)buf[pos++])) {
236: 						return false;
237: 					}
238: 				}
239: 				// make sure there is either (1) one number after the period, or (2) one number before the period
240: 				// i.e. we accept "1." and ".1" as valid numbers, but not "."
241: 				return number_before_period || pos > start_digit;
242: 			}
243: 			if (std::isspace((unsigned char)buf[pos])) {
244: 				// skip any trailing spaces
245: 				while(++pos < len) {
246: 					if (!std::isspace((unsigned char)buf[pos])) {
247: 						return false;
248: 					}
249: 				}
250: 				break;
251: 			}
252: 			if (ALLOW_EXPONENT) {
253: 				if (buf[pos] == 'e' || buf[pos] == 'E') {
254: 					pos++;
255: 					int64_t exponent = 0;
256: 					int negative = buf[pos] == '-';
257: 					if (negative) {
258: 						if (!IntegerCastLoop<int64_t, true, false>(buf + pos, len - pos, exponent, strict)) {
259: 							return false;
260: 						}
261: 					} else {
262: 						if (!IntegerCastLoop<int64_t, false, false>(buf + pos, len - pos, exponent, strict)) {
263: 							return false;
264: 						}
265: 					}
266: 					return OP::template HandleExponent<T>(result, exponent);
267: 				}
268: 			}
269: 			return false;
270: 		}
271: 		uint8_t digit = buf[pos++] - '0';
272: 		if (!OP::template HandleDigit<T, NEGATIVE>(result, digit)) {
273: 			return false;
274: 		}
275: 	}
276: 	if (!OP::template Finalize<T>(result)) {
277: 		return false;
278: 	}
279: 	return pos > start_pos;
280: }
281: 
282: template <class T, bool ALLOW_EXPONENT = true, class OP=IntegerCastOperation> static bool TryIntegerCast(const char *buf, idx_t len, T &result, bool strict) {
283: 	// skip any spaces at the start
284: 	while(len > 0 && std::isspace(*buf)) {
285: 		buf++;
286: 		len--;
287: 	}
288: 	if (len == 0) {
289: 		return false;
290: 	}
291: 	int negative = *buf == '-';
292: 
293: 	memset(&result, 0, sizeof(T));
294: 	if (!negative) {
295: 		return IntegerCastLoop<T, false, ALLOW_EXPONENT, OP>(buf, len, result, strict);
296: 	} else {
297: 		return IntegerCastLoop<T, true, ALLOW_EXPONENT, OP>(buf, len, result, strict);
298: 	}
299: }
300: 
301: template <> bool TryCast::Operation(string_t input, bool &result, bool strict) {
302: 	auto input_data = input.GetData();
303: 	auto input_size = input.GetSize();
304: 
305: 	switch(input_size) {
306: 	case 1: {
307: 		char c = std::tolower(*input_data);
308: 		if (c == 't' || (!strict && c == '1')) {
309: 			result = true;
310: 			return true;
311: 		} else if (c == 'f' || (!strict && c == '0')) {
312: 			result = false;
313: 			return true;
314: 		}
315: 		return false;
316: 	}
317: 	case 4: {
318: 		char t = std::tolower(input_data[0]);
319: 		char r = std::tolower(input_data[1]);
320: 		char u = std::tolower(input_data[2]);
321: 		char e = std::tolower(input_data[3]);
322: 		if (t == 't' && r == 'r' && u == 'u' && e == 'e') {
323: 			result = true;
324: 			return true;
325: 		}
326: 		return false;
327: 	}
328: 	case 5: {
329: 		char f = std::tolower(input_data[0]);
330: 		char a = std::tolower(input_data[1]);
331: 		char l = std::tolower(input_data[2]);
332: 		char s = std::tolower(input_data[3]);
333: 		char e = std::tolower(input_data[4]);
334: 		if (f == 'f' && a == 'a' && l == 'l' && s == 's' && e == 'e') {
335: 			result = false;
336: 			return true;
337: 		}
338: 		return false;
339: 	}
340: 	default:
341: 		return false;
342: 	}
343: }
344: template <> bool TryCast::Operation(string_t input, int8_t &result, bool strict) {
345: 	return TryIntegerCast<int8_t>(input.GetData(), input.GetSize(), result, strict);
346: }
347: template <> bool TryCast::Operation(string_t input, int16_t &result, bool strict) {
348: 	return TryIntegerCast<int16_t>(input.GetData(), input.GetSize(), result, strict);
349: }
350: template <> bool TryCast::Operation(string_t input, int32_t &result, bool strict) {
351: 	return TryIntegerCast<int32_t>(input.GetData(), input.GetSize(), result, strict);
352: }
353: template <> bool TryCast::Operation(string_t input, int64_t &result, bool strict) {
354: 	return TryIntegerCast<int64_t>(input.GetData(), input.GetSize(), result, strict);
355: }
356: 
357: template <class T, bool NEGATIVE> static void ComputeDoubleResult(T &result, idx_t decimal, idx_t decimal_factor) {
358: 	if (decimal_factor > 1) {
359: 		if (NEGATIVE) {
360: 			result -= (T)decimal / (T)decimal_factor;
361: 		} else {
362: 			result += (T)decimal / (T)decimal_factor;
363: 		}
364: 	}
365: }
366: 
367: template <class T, bool NEGATIVE> static bool DoubleCastLoop(const char *buf, idx_t len, T &result, bool strict) {
368: 	idx_t start_pos = NEGATIVE || *buf == '+' ? 1 : 0;
369: 	idx_t pos = start_pos;
370: 	idx_t decimal = 0;
371: 	idx_t decimal_factor = 0;
372: 	while (pos < len) {
373: 		if (!std::isdigit((unsigned char)buf[pos])) {
374: 			// not a digit!
375: 			if (buf[pos] == '.') {
376: 				// decimal point
377: 				if (decimal_factor != 0) {
378: 					// nested periods
379: 					return false;
380: 				}
381: 				decimal_factor = 1;
382: 				pos++;
383: 				continue;
384: 			} else if (std::isspace((unsigned char)buf[pos])) {
385: 				// skip any trailing spaces
386: 				while (++pos < len) {
387: 					if (!std::isspace((unsigned char)buf[pos])) {
388: 						return false;
389: 					}
390: 				}
391: 				ComputeDoubleResult<T, NEGATIVE>(result, decimal, decimal_factor);
392: 				return true;
393: 			} else if (buf[pos] == 'e' || buf[pos] == 'E') {
394: 				// E power
395: 				// parse an integer, this time not allowing another exponent
396: 				pos++;
397: 				int64_t exponent;
398: 				if (!TryIntegerCast<int64_t, false>(buf + pos, len - pos, exponent, strict)) {
399: 					return false;
400: 				}
401: 				ComputeDoubleResult<T, NEGATIVE>(result, decimal, decimal_factor);
402: 				result = result * pow(10, exponent);
403: 				return true;
404: 			} else {
405: 				return false;
406: 			}
407: 		}
408: 		T digit = buf[pos++] - '0';
409: 		if (decimal_factor == 0) {
410: 			result = result * 10 + (NEGATIVE ? -digit : digit);
411: 		} else {
412: 			if (decimal_factor >= 1000000000000000000) {
413: 				// decimal value will overflow if we parse more, ignore any subsequent numbers
414: 				continue;
415: 			}
416: 			decimal = decimal * 10 + digit;
417: 			decimal_factor *= 10;
418: 		}
419: 	}
420: 	ComputeDoubleResult<T, NEGATIVE>(result, decimal, decimal_factor);
421: 	return pos > start_pos;
422: }
423: 
424: template <class T> bool CheckDoubleValidity(T value);
425: 
426: template <> bool CheckDoubleValidity(float value) {
427: 	return Value::FloatIsValid(value);
428: }
429: 
430: template <> bool CheckDoubleValidity(double value) {
431: 	return Value::DoubleIsValid(value);
432: }
433: 
434: template <class T> static bool TryDoubleCast(const char *buf, idx_t len, T &result, bool strict) {
435: 	// skip any spaces at the start
436: 	while(len > 0 && std::isspace(*buf)) {
437: 		buf++;
438: 		len--;
439: 	}
440: 	if (len == 0) {
441: 		return false;
442: 	}
443: 	int negative = *buf == '-';
444: 
445: 	result = 0;
446: 	if (!negative) {
447: 		if (!DoubleCastLoop<T, false>(buf, len, result, strict)) {
448: 			return false;
449: 		}
450: 	} else {
451: 		if (!DoubleCastLoop<T, true>(buf, len, result, strict)) {
452: 			return false;
453: 		}
454: 	}
455: 	if (!CheckDoubleValidity<T>(result)) {
456: 		return false;
457: 	}
458: 	return true;
459: }
460: 
461: template <> bool TryCast::Operation(string_t input, float &result, bool strict) {
462: 	return TryDoubleCast<float>(input.GetData(), input.GetSize(), result, strict);
463: }
464: template <> bool TryCast::Operation(string_t input, double &result, bool strict) {
465: 	return TryDoubleCast<double>(input.GetData(), input.GetSize(), result, strict);
466: }
467: 
468: template <> bool Cast::Operation(string_t input) {
469: 	return try_cast_string<bool>(input);
470: }
471: template <> int8_t Cast::Operation(string_t input) {
472: 	return try_cast_string<int8_t>(input);
473: }
474: template <> int16_t Cast::Operation(string_t input) {
475: 	return try_cast_string<int16_t>(input);
476: }
477: template <> int32_t Cast::Operation(string_t input) {
478: 	return try_cast_string<int32_t>(input);
479: }
480: template <> int64_t Cast::Operation(string_t input) {
481: 	return try_cast_string<int64_t>(input);
482: }
483: template <> float Cast::Operation(string_t input) {
484: 	return try_cast_string<float>(input);
485: }
486: template <> double Cast::Operation(string_t input) {
487: 	return try_cast_string<double>(input);
488: }
489: 
490: template <> bool StrictCast::Operation(string_t input) {
491: 	return try_strict_cast_string<bool>(input);
492: }
493: template <> int8_t StrictCast::Operation(string_t input) {
494: 	return try_strict_cast_string<int8_t>(input);
495: }
496: template <> int16_t StrictCast::Operation(string_t input) {
497: 	return try_strict_cast_string<int16_t>(input);
498: }
499: template <> int32_t StrictCast::Operation(string_t input) {
500: 	return try_strict_cast_string<int32_t>(input);
501: }
502: template <> int64_t StrictCast::Operation(string_t input) {
503: 	return try_strict_cast_string<int64_t>(input);
504: }
505: template <> float StrictCast::Operation(string_t input) {
506: 	return try_strict_cast_string<float>(input);
507: }
508: template <> double StrictCast::Operation(string_t input) {
509: 	return try_strict_cast_string<double>(input);
510: }
511: 
512: //===--------------------------------------------------------------------===//
513: // Cast Numeric -> String
514: //===--------------------------------------------------------------------===//
515: template <class T> string CastToStandardString(T input) {
516: 	Vector v(TypeId::VARCHAR);
517: 	return StringCast::Operation(input, v).GetString();
518: }
519: 
520: template <> string Cast::Operation(bool input) {
521: 	return CastToStandardString(input);
522: }
523: template <> string Cast::Operation(int8_t input) {
524: 	return CastToStandardString(input);
525: }
526: template <> string Cast::Operation(int16_t input) {
527: 	return CastToStandardString(input);
528: }
529: template <> string Cast::Operation(int32_t input) {
530: 	return CastToStandardString(input);
531: }
532: template <> string Cast::Operation(int64_t input) {
533: 	return CastToStandardString(input);
534: }
535: template <> string Cast::Operation(hugeint_t input) {
536: 	return Hugeint::ToString(input);
537: }
538: template <> string Cast::Operation(float input) {
539: 	return CastToStandardString(input);
540: }
541: template <> string Cast::Operation(double input) {
542: 	return CastToStandardString(input);
543: }
544: template <> string Cast::Operation(string_t input) {
545: 	return input.GetString();
546: }
547: 
548: template <> string_t StringCast::Operation(bool input, Vector &vector) {
549: 	if (input) {
550: 		return StringVector::AddString(vector, "true", 4);
551: 	} else {
552: 		return StringVector::AddString(vector, "false", 5);
553: 	}
554: }
555: 
556: template <> string_t StringCast::Operation(int8_t input, Vector &vector) {
557: 	return NumericHelper::FormatSigned<int8_t, uint8_t>(input, vector);
558: }
559: 
560: template <> string_t StringCast::Operation(int16_t input, Vector &vector) {
561: 	return NumericHelper::FormatSigned<int16_t, uint16_t>(input, vector);
562: }
563: template <> string_t StringCast::Operation(int32_t input, Vector &vector) {
564: 	return NumericHelper::FormatSigned<int32_t, uint32_t>(input, vector);
565: }
566: 
567: template <> string_t StringCast::Operation(int64_t input, Vector &vector) {
568: 	return NumericHelper::FormatSigned<int64_t, uint64_t>(input, vector);
569: }
570: 
571: template <> string_t StringCast::Operation(float input, Vector &vector) {
572: 	std::string s = duckdb_fmt::format("{}", input);
573: 	return StringVector::AddString(vector, s);
574: }
575: 
576: template <> string_t StringCast::Operation(double input, Vector &vector) {
577: 	std::string s = duckdb_fmt::format("{}", input);
578: 	return StringVector::AddString(vector, s);
579: }
580: 
581: template <> string_t StringCast::Operation(interval_t input, Vector &vector) {
582: 	std::string s = Interval::ToString(input);
583: 	return StringVector::AddString(vector, s);
584: }
585: 
586: struct HugeintToStringCast {
587: 	static int UnsignedLength(hugeint_t value) {
588: 		assert(value.upper >= 0);
589: 		if (value.upper == 0) {
590: 			return NumericHelper::UnsignedLength<uint64_t>(value.lower);
591: 		}
592: 		// search the length using the PowersOfTen array
593: 		// the length has to be between [17] and [38], because the hugeint is bigger than 2^63
594: 		// we use the same approach as above, but split a bit more because comparisons for hugeints are more expensive
595: 		if (value >= Hugeint::PowersOfTen[27]) {
596: 			// [27..38]
597: 			if (value >= Hugeint::PowersOfTen[32]) {
598: 				if (value >= Hugeint::PowersOfTen[36]) {
599: 					int length = 37;
600: 					length += value >= Hugeint::PowersOfTen[37];
601: 					length += value >= Hugeint::PowersOfTen[38];
602: 					return length;
603: 				} else {
604: 					int length = 33;
605: 					length += value >= Hugeint::PowersOfTen[33];
606: 					length += value >= Hugeint::PowersOfTen[34];
607: 					length += value >= Hugeint::PowersOfTen[35];
608: 					return length;
609: 				}
610: 			} else {
611: 				if (value >= Hugeint::PowersOfTen[30]) {
612: 					int length = 31;
613: 					length += value >= Hugeint::PowersOfTen[31];
614: 					length += value >= Hugeint::PowersOfTen[32];
615: 					return length;
616: 				} else {
617: 					int length = 28;
618: 					length += value >= Hugeint::PowersOfTen[28];
619: 					length += value >= Hugeint::PowersOfTen[29];
620: 					return length;
621: 				}
622: 			}
623: 		} else {
624: 			// [17..27]
625: 			if (value >= Hugeint::PowersOfTen[22]) {
626: 				// [22..27]
627: 				if (value >= Hugeint::PowersOfTen[25]) {
628: 					int length = 26;
629: 					length += value >= Hugeint::PowersOfTen[26];
630: 					return length;
631: 				} else {
632: 					int length = 23;
633: 					length += value >= Hugeint::PowersOfTen[23];
634: 					length += value >= Hugeint::PowersOfTen[24];
635: 					return length;
636: 				}
637: 			} else {
638: 				// [17..22]
639: 				if (value >= Hugeint::PowersOfTen[20]) {
640: 					int length = 21;
641: 					length += value >= Hugeint::PowersOfTen[21];
642: 					return length;
643: 				} else {
644: 					int length = 18;
645: 					length += value >= Hugeint::PowersOfTen[18];
646: 					length += value >= Hugeint::PowersOfTen[19];
647: 					return length;
648: 				}
649: 			}
650: 		}
651: 	}
652: 
653: 	// Formats value in reverse and returns a pointer to the beginning.
654: 	static char *FormatUnsigned(hugeint_t value, char *ptr) {
655: 		while (value.upper > 0) {
656: 			// while integer division is slow, hugeint division is MEGA slow
657: 			// we want to avoid doing as many divisions as possible
658: 			// for that reason we start off doing a division by a large power of ten that uint64_t can hold
659: 			// (100000000000000000) - this is the third largest
660: 			// the reason we don't use the largest is because that can result in an overflow inside the division function
661: 			uint64_t remainder;
662: 			value = Hugeint::DivModPositive(value, 100000000000000000ULL, remainder);
663: 
664: 			auto startptr = ptr;
665: 			// now we format the remainder: note that we need to pad with zero's in case
666: 			// the remainder is small (i.e. less than 10000000000000000)
667: 			ptr = NumericHelper::FormatUnsigned<uint64_t>(remainder, ptr);
668: 
669: 			int format_length = startptr - ptr;
670: 			// pad with zero
671: 			for(int i = format_length; i < 17; i++) {
672: 				*--ptr = '0';
673: 			}
674: 		}
675: 		// once the value falls in the range of a uint64_t, fallback to formatting as uint64_t to avoid hugeint division
676: 		return NumericHelper::FormatUnsigned<uint64_t>(value.lower, ptr);
677: 	}
678: 
679: 	static string_t FormatSigned(hugeint_t value, Vector &vector) {
680: 		int negative = value.upper < 0;
681: 		if (negative) {
682: 			Hugeint::NegateInPlace(value);
683: 		}
684: 		int length = UnsignedLength(value) + negative;
685: 		string_t result = StringVector::EmptyString(vector, length);
686: 		auto dataptr = result.GetData();
687: 		auto endptr = dataptr + length;
688: 		if (value.upper == 0) {
689: 			// small value: format as uint64_t
690: 			endptr = NumericHelper::FormatUnsigned<uint64_t>(value.lower, endptr);
691: 		} else {
692: 			endptr = FormatUnsigned(value, endptr);
693: 		}
694: 		if (negative) {
695: 			*--endptr = '-';
696: 		}
697: 		assert(endptr == dataptr);
698: 		result.Finalize();
699: 		return result;
700: 	}
701: };
702: 
703: template <> duckdb::string_t StringCast::Operation(hugeint_t input, Vector &vector) {
704: 	return HugeintToStringCast::FormatSigned(move(input), vector);
705: }
706: 
707: //===--------------------------------------------------------------------===//
708: // Cast From Date
709: //===--------------------------------------------------------------------===//
710: struct DateToStringCast {
711: 	static idx_t Length(int32_t date[], idx_t &year_length, bool &add_bc) {
712: 		// format is YYYY-MM-DD with optional (BC) at the end
713: 		// regular length is 10
714: 		idx_t length = 6;
715: 		year_length = 4;
716: 		add_bc = false;
717: 		if (date[0] <= 0) {
718: 			// add (BC) suffix
719: 			length += 5;
720: 			date[0] = -date[0];
721: 			add_bc = true;
722: 		}
723: 
724: 		// potentially add extra characters depending on length of year
725: 		year_length += date[0] >= 10000;
726: 		year_length += date[0] >= 100000;
727: 		year_length += date[0] >= 1000000;
728: 		year_length += date[0] >= 10000000;
729: 		length += year_length;
730: 		return length;
731: 	}
732: 
733: 	static void Format(char *data, int32_t date[], idx_t year_length, bool add_bc) {
734: 		// now we write the string, first write the year
735: 		auto endptr = data + year_length;
736: 		endptr = NumericHelper::FormatUnsigned(date[0], endptr);
737: 		// add optional leading zeros
738: 		while (endptr > data) {
739: 			*--endptr = '0';
740: 		}
741: 		// now write the month and day
742: 		auto ptr = data + year_length;
743: 		for (int i = 1; i <= 2; i++) {
744: 			ptr[0] = '-';
745: 			if (date[i] < 10) {
746: 				ptr[1] = '0';
747: 				ptr[2] = '0' + date[i];
748: 			} else {
749: 				auto index = static_cast<unsigned>(date[i] * 2);
750: 				ptr[1] = duckdb_fmt::internal::data::digits[index];
751: 				ptr[2] = duckdb_fmt::internal::data::digits[index + 1];
752: 			}
753: 			ptr += 3;
754: 		}
755: 		// optionally add BC to the end of the date
756: 		if (add_bc) {
757: 			memcpy(ptr, " (BC)", 5);
758: 		}
759: 	}
760: };
761: 
762: template <> string_t CastFromDate::Operation(date_t input, Vector &vector) {
763: 	int32_t date[3];
764: 	Date::Convert(input, date[0], date[1], date[2]);
765: 
766: 	idx_t year_length;
767: 	bool add_bc;
768: 	idx_t length = DateToStringCast::Length(date, year_length, add_bc);
769: 
770: 	string_t result = StringVector::EmptyString(vector, length);
771: 	auto data = result.GetData();
772: 
773: 	DateToStringCast::Format(data, date, year_length, add_bc);
774: 
775: 	result.Finalize();
776: 	return result;
777: }
778: 
779: //===--------------------------------------------------------------------===//
780: // Cast To Date
781: //===--------------------------------------------------------------------===//
782: template <> date_t CastToDate::Operation(string_t input) {
783: 	return Date::FromCString(input.GetData());
784: }
785: 
786: template <> date_t StrictCastToDate::Operation(string_t input) {
787: 	return Date::FromCString(input.GetData(), true);
788: }
789: 
790: //===--------------------------------------------------------------------===//
791: // Cast From Time
792: //===--------------------------------------------------------------------===//
793: struct TimeToStringCast {
794: 	static idx_t Length(int32_t time[]) {
795: 		// format is HH:MM:DD
796: 		// regular length is 8
797: 		idx_t length = 8;
798: 		if (time[3] > 0) {
799: 			// if there are msecs, we add the miliseconds after the time with a period separator
800: 			// i.e. the format becomes HH:MM:DD.msec
801: 			length += 4;
802: 		}
803: 		return length;
804: 	}
805: 
806: 	static void Format(char *data, idx_t length, int32_t time[]) {
807: 		// first write hour, month and day
808: 		auto ptr = data;
809: 		for (int i = 0; i <= 2; i++) {
810: 			if (time[i] < 10) {
811: 				ptr[0] = '0';
812: 				ptr[1] = '0' + time[i];
813: 			} else {
814: 				auto index = static_cast<unsigned>(time[i] * 2);
815: 				ptr[0] = duckdb_fmt::internal::data::digits[index];
816: 				ptr[1] = duckdb_fmt::internal::data::digits[index + 1];
817: 			}
818: 			ptr[2] = ':';
819: 			ptr += 3;
820: 		}
821: 		// now optionally write ms at the end
822: 		if (time[3] > 0) {
823: 			auto start = ptr;
824: 			ptr = NumericHelper::FormatUnsigned(time[3], data + length);
825: 			while (ptr > start) {
826: 				*--ptr = '0';
827: 			}
828: 			*--ptr = '.';
829: 		}
830: 	}
831: };
832: 
833: template <> string_t CastFromTime::Operation(dtime_t input, Vector &vector) {
834: 	int32_t time[4];
835: 	Time::Convert(input, time[0], time[1], time[2], time[3]);
836: 
837: 	idx_t length = TimeToStringCast::Length(time);
838: 
839: 	string_t result = StringVector::EmptyString(vector, length);
840: 	auto data = result.GetData();
841: 
842: 	TimeToStringCast::Format(data, length, time);
843: 
844: 	result.Finalize();
845: 	return result;
846: }
847: 
848: //===--------------------------------------------------------------------===//
849: // Cast To Time
850: //===--------------------------------------------------------------------===//
851: template <> dtime_t CastToTime::Operation(string_t input) {
852: 	return Time::FromCString(input.GetData());
853: }
854: 
855: template <> dtime_t StrictCastToTime::Operation(string_t input) {
856: 	return Time::FromCString(input.GetData(), true);
857: }
858: 
859: template <> timestamp_t CastDateToTimestamp::Operation(date_t input) {
860: 	return Timestamp::FromDatetime(input, Time::FromTime(0, 0, 0, 0));
861: }
862: 
863: //===--------------------------------------------------------------------===//
864: // Cast From Timestamps
865: //===--------------------------------------------------------------------===//
866: template <> string_t CastFromTimestamp::Operation(timestamp_t input, Vector &vector) {
867: 	date_t date_entry;
868: 	dtime_t time_entry;
869: 	Timestamp::Convert(input, date_entry, time_entry);
870: 
871: 	int32_t date[3], time[4];
872: 	Date::Convert(date_entry, date[0], date[1], date[2]);
873: 	Time::Convert(time_entry, time[0], time[1], time[2], time[3]);
874: 
875: 	// format for timestamp is DATE TIME (separated by space)
876: 	idx_t year_length;
877: 	bool add_bc;
878: 	idx_t date_length = DateToStringCast::Length(date, year_length, add_bc);
879: 	idx_t time_length = TimeToStringCast::Length(time);
880: 	idx_t length = date_length + time_length + 1;
881: 
882: 	string_t result = StringVector::EmptyString(vector, length);
883: 	auto data = result.GetData();
884: 
885: 	DateToStringCast::Format(data, date, year_length, add_bc);
886: 	data[date_length] = ' ';
887: 	TimeToStringCast::Format(data + date_length + 1, time_length, time);
888: 
889: 	result.Finalize();
890: 	return result;
891: }
892: 
893: template <> date_t CastTimestampToDate::Operation(timestamp_t input) {
894: 	return Timestamp::GetDate(input);
895: }
896: 
897: template <> dtime_t CastTimestampToTime::Operation(timestamp_t input) {
898: 	return Timestamp::GetTime(input);
899: }
900: 
901: //===--------------------------------------------------------------------===//
902: // Cast To Timestamp
903: //===--------------------------------------------------------------------===//
904: template <> timestamp_t CastToTimestamp::Operation(string_t input) {
905: 	return Timestamp::FromCString(input.GetData(), input.GetSize());
906: }
907: 
908: //===--------------------------------------------------------------------===//
909: // Cast From Blob
910: //===--------------------------------------------------------------------===//
911: template <> string_t CastFromBlob::Operation(string_t input, Vector &vector) {
912: 	idx_t input_size = input.GetSize();
913: 	// double chars for hex string plus two because of hex identifier ('\x')
914: 	string_t result = StringVector::EmptyString(vector, input_size * 2 + 2);
915: 	CastFromBlob::ToHexString(input, result);
916: 	return result;
917: }
918: 
919: void CastFromBlob::ToHexString(string_t input, string_t &output) {
920: 	const char hexa_table[] = {'0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F'};
921: 	idx_t input_size = input.GetSize();
922: 	assert(output.GetSize() == (input_size * 2 + 2));
923: 	auto input_data = input.GetData();
924: 	auto hexa_data  = output.GetData();
925: 	// hex identifier
926: 	hexa_data[0] = '\\'; hexa_data[1] = 'x';
927: 	hexa_data += 2;
928: 	for(idx_t idx = 0; idx < input_size; ++idx) {
929: 		hexa_data[idx * 2]     = hexa_table[(input_data[idx] >> 4) & 0x0F];
930: 		hexa_data[idx * 2 + 1] = hexa_table[input_data[idx] & 0x0F];
931: 	}
932: 	output.Finalize();
933: }
934: 
935: void CastFromBlob::FromHexToBytes(string_t input, string_t &output) {
936: 	idx_t in_size = input.GetSize();
937: 	// amount of hex chars must be even
938: 	if((in_size % 2) != 0) {
939: 		throw OutOfRangeException("Hex string must have an even number of bytes.");
940: 	}
941: 
942: 	auto in_data = input.GetData();
943: 	// removing '\x'
944: 	in_data += 2;
945: 	in_size -= 2;
946: 
947: 	auto out_data = output.GetData();
948: 	idx_t out_size = output.GetSize();
949: 	assert(out_size == (in_size / 2));
950: 	idx_t out_idx=0;
951: 
952: 	idx_t num_hex_per_byte = 2;
953: 	uint8_t hex[2];
954: 
955: 	for(idx_t in_idx = 0; in_idx < in_size; in_idx+=2, ++out_idx) {
956: 		for(idx_t hex_idx = 0; hex_idx < num_hex_per_byte; ++hex_idx) {
957: 			uint8_t int_ch = in_data[in_idx + hex_idx];
958: 			if(int_ch >= (uint8_t)'0' && int_ch <= (uint8_t)'9') {
959: 				// numeric ascii chars: '0' to '9'
960: 				hex[hex_idx] = int_ch & 0X0F;
961: 			}
962: 			else if((int_ch >= (uint8_t)'A' && int_ch <= (uint8_t)'F') ||
963: 					(int_ch >= (uint8_t)'a' && int_ch <= (uint8_t)'f')) {
964: 					// hex chars: ['A':'F'] or ['a':'f']
965: 				// transforming char into an integer in the range of 10 to 15
966: 				hex[hex_idx] = ((int_ch & 0X0F) - 1) + 10;
967: 			} else {
968: 				throw OutOfRangeException("\"%c\" is not a valid hexadecimal char.", in_data[in_idx + hex_idx]);
969: 			}
970: 		}
971: 		// adding two hex into the same byte
972: 		out_data[out_idx] = hex[0];
973: 		out_data[out_idx] = (out_data[out_idx] << 4) | hex[1];
974: 	}
975: 	out_data[out_idx] = '\0';
976: }
977: 
978: //===--------------------------------------------------------------------===//
979: // Cast To Blob
980: //===--------------------------------------------------------------------===//
981: template <> string_t CastToBlob::Operation(string_t input, Vector &vector) {
982: 	idx_t input_size = input.GetSize();
983: 	auto input_data = input.GetData();
984: 	string_t result;
985: 	// Check by a hex string
986: 	if(input_size >= 2 && input_data[0] == '\\' && input_data[1] == 'x') {
987: 		auto output = StringVector::EmptyString(vector, (input_size - 2) / 2);
988: 		CastFromBlob::FromHexToBytes(input, output);
989: 		result = output;
990: 	} else {
991: 		// raw string
992: 		result = StringVector::AddBlob(vector, input);
993: 	}
994: 	return result;
995: }
996: 
997: //===--------------------------------------------------------------------===//
998: // Cast From Interval
999: //===--------------------------------------------------------------------===//
1000: template <> bool TryCast::Operation(string_t input, interval_t &result, bool strict) {
1001: 	return Interval::FromCString(input.GetData(), input.GetSize(), result);
1002: }
1003: 
1004: template <> interval_t StrictCast::Operation(string_t input) {
1005: 	return try_strict_cast_string<interval_t>(input);
1006: }
1007: 
1008: template <> interval_t Cast::Operation(string_t input) {
1009: 	return try_cast_string<interval_t>(input);
1010: }
1011: 
1012: //===--------------------------------------------------------------------===//
1013: // Cast From Hugeint
1014: //===--------------------------------------------------------------------===//
1015: // parsing hugeint from string is done a bit differently for performance reasons
1016: // for other integer types we keep track of a single value
1017: // and multiply that value by 10 for every digit we read
1018: // however, for hugeints, multiplication is very expensive (>20X as expensive as for int64)
1019: // for that reason, we parse numbers first into an int64 value
1020: // when that value is full, we perform a HUGEINT multiplication to flush it into the hugeint
1021: // this takes the number of HUGEINT multiplications down from [0-38] to [0-2]
1022: struct HugeIntCastData {
1023: 	hugeint_t hugeint;
1024: 	int64_t intermediate;
1025: 	uint8_t digits;
1026: 
1027: 	bool Flush() {
1028: 		if (digits == 0 && intermediate == 0) {
1029: 			return true;
1030: 		}
1031: 		if (hugeint.lower != 0 || hugeint.upper != 0) {
1032: 			if (digits > 38) {
1033: 				return false;
1034: 			}
1035: 			if (!Hugeint::TryMultiply(hugeint, Hugeint::PowersOfTen[digits], hugeint)) {
1036: 				return false;
1037: 			}
1038: 		}
1039: 		if (!Hugeint::AddInPlace(hugeint, hugeint_t(intermediate))) {
1040: 			return false;
1041: 		}
1042: 		digits = 0;
1043: 		intermediate = 0;
1044: 		return true;
1045: 	}
1046: };
1047: 
1048: struct HugeIntegerCastOperation {
1049: 	template<class T, bool NEGATIVE>
1050: 	static bool HandleDigit(T &result, uint8_t digit) {
1051: 		if (NEGATIVE) {
1052: 			if (result.intermediate < (NumericLimits<int64_t>::Minimum() + digit) / 10) {
1053: 				// intermediate is full: need to flush it
1054: 				if (!result.Flush()) {
1055: 					return false;
1056: 				}
1057: 			}
1058: 			result.intermediate = result.intermediate * 10 - digit;
1059: 		} else {
1060: 			if (result.intermediate > (NumericLimits<int64_t>::Maximum() - digit) / 10) {
1061: 				if (!result.Flush()) {
1062: 					return false;
1063: 				}
1064: 			}
1065: 			result.intermediate = result.intermediate * 10 + digit;
1066: 		}
1067: 		result.digits++;
1068: 		return true;
1069: 	}
1070: 
1071: 	template<class T>
1072: 	static bool HandleExponent(T &result, int64_t exponent) {
1073: 		result.Flush();
1074: 		if (exponent < -38 || exponent > 38) {
1075: 			// out of range for exact exponent: use double and convert
1076: 			double dbl_res = Hugeint::Cast<double>(result.hugeint) * pow(10, exponent);
1077: 			if (dbl_res < Hugeint::Cast<double>(NumericLimits<hugeint_t>::Minimum()) || dbl_res > Hugeint::Cast<double>(NumericLimits<hugeint_t>::Maximum())) {
1078: 				return false;
1079: 			}
1080: 			result.hugeint = Hugeint::Convert(dbl_res);
1081: 			return true;
1082: 		}
1083: 		if (exponent < 0) {
1084: 			// negative exponent: divide by power of 10
1085: 			result.hugeint = Hugeint::Divide(result.hugeint, Hugeint::PowersOfTen[-exponent]);
1086: 			return true;
1087: 		} else {
1088: 			// positive exponent: multiply by power of 10
1089: 			return Hugeint::TryMultiply(result.hugeint, Hugeint::PowersOfTen[exponent], result.hugeint);
1090: 		}
1091: 	}
1092: 
1093: 	template<class T>
1094: 	static bool Finalize(T &result) {
1095: 		return result.Flush();
1096: 	}
1097: };
1098: 
1099: template <> bool TryCast::Operation(string_t input, hugeint_t &result, bool strict) {
1100: 	HugeIntCastData data;
1101: 	if (!TryIntegerCast<HugeIntCastData, true, HugeIntegerCastOperation>(input.GetData(), input.GetSize(), data, strict)) {
1102: 		return false;
1103: 	}
1104: 	result = data.hugeint;
1105: 	return true;
1106: }
1107: 
1108: template <> hugeint_t Cast::Operation(string_t input) {
1109: 	return try_cast_string<hugeint_t>(input);
1110: }
1111: 
1112: template <> hugeint_t StrictCast::Operation(string_t input) {
1113: 	return try_strict_cast_string<hugeint_t>(input);
1114: }
1115: 
1116: //===--------------------------------------------------------------------===//
1117: // Numeric -> Hugeint
1118: //===--------------------------------------------------------------------===//
1119: template <> bool TryCast::Operation(bool input, hugeint_t &result, bool strict) {
1120: 	result = Cast::Operation<bool, hugeint_t>(input);
1121: 	return true;
1122: }
1123: 
1124: template <> bool TryCast::Operation(int8_t input, hugeint_t &result, bool strict) {
1125: 	result = Cast::Operation<int8_t, hugeint_t>(input);
1126: 	return true;
1127: }
1128: 
1129: template <> bool TryCast::Operation(int16_t input, hugeint_t &result, bool strict) {
1130: 	result = Cast::Operation<int16_t, hugeint_t>(input);
1131: 	return true;
1132: }
1133: 
1134: template <> bool TryCast::Operation(int32_t input, hugeint_t &result, bool strict) {
1135: 	result = Cast::Operation<int32_t, hugeint_t>(input);
1136: 	return true;
1137: }
1138: 
1139: template <> bool TryCast::Operation(int64_t input, hugeint_t &result, bool strict) {
1140: 	result = Cast::Operation<int64_t, hugeint_t>(input);
1141: 	return true;
1142: }
1143: 
1144: template <> bool TryCast::Operation(float input, hugeint_t &result, bool strict) {
1145: 	result = Cast::Operation<float, hugeint_t>(input);
1146: 	return true;
1147: }
1148: 
1149: template <> bool TryCast::Operation(double input, hugeint_t &result, bool strict) {
1150: 	result = Cast::Operation<double, hugeint_t>(input);
1151: 	return true;
1152: }
1153: 
1154: template <> hugeint_t Cast::Operation(bool input) {
1155: 	hugeint_t result;
1156: 	result.upper = 0;
1157: 	result.lower = input ? 1 : 0;
1158: 	return result;
1159: }
1160: template <> hugeint_t Cast::Operation(int8_t input) {
1161: 	return Hugeint::Convert<int8_t>(input);
1162: }
1163: template <> hugeint_t Cast::Operation(int16_t input) {
1164: 	return Hugeint::Convert<int16_t>(input);
1165: }
1166: template <> hugeint_t Cast::Operation(int32_t input) {
1167: 	return Hugeint::Convert<int32_t>(input);
1168: }
1169: template <> hugeint_t Cast::Operation(int64_t input) {
1170: 	return Hugeint::Convert<int64_t>(input);
1171: }
1172: template <> hugeint_t Cast::Operation(float input) {
1173: 	return Hugeint::Convert<float>(input);
1174: }
1175: template <> hugeint_t Cast::Operation(double input) {
1176: 	return Hugeint::Convert<double>(input);
1177: }
1178: 
1179: //===--------------------------------------------------------------------===//
1180: // Hugeint -> Numeric
1181: //===--------------------------------------------------------------------===//
1182: template <> bool TryCast::Operation(hugeint_t input, bool &result, bool strict) {
1183: 	// any positive number converts to true
1184: 	result = input.upper > 0 || (input.upper == 0 && input.lower > 0);
1185: 	return true;
1186: }
1187: 
1188: template <> bool TryCast::Operation(hugeint_t input, int8_t &result, bool strict) {
1189: 	return Hugeint::TryCast<int8_t>(input, result);
1190: }
1191: 
1192: template <> bool TryCast::Operation(hugeint_t input, int16_t &result, bool strict) {
1193: 	return Hugeint::TryCast<int16_t>(input, result);
1194: }
1195: 
1196: template <> bool TryCast::Operation(hugeint_t input, int32_t &result, bool strict) {
1197: 	return Hugeint::TryCast<int32_t>(input, result);
1198: }
1199: 
1200: template <> bool TryCast::Operation(hugeint_t input, int64_t &result, bool strict) {
1201: 	return Hugeint::TryCast<int64_t>(input, result);
1202: }
1203: 
1204: template <> bool TryCast::Operation(hugeint_t input, float &result, bool strict) {
1205: 	return Hugeint::TryCast<float>(input, result);
1206: }
1207: 
1208: template <> bool TryCast::Operation(hugeint_t input, double &result, bool strict) {
1209: 	return Hugeint::TryCast<double>(input, result);
1210: }
1211: 
1212: template <> bool Cast::Operation(hugeint_t input) {
1213: 	bool result;
1214: 	TryCast::Operation(input, result);
1215: 	return result;
1216: }
1217: 
1218: template<class T>
1219: static T hugeint_cast_to_numeric(hugeint_t input) {
1220: 	T result;
1221: 	if (!TryCast::Operation<hugeint_t, T>(input, result)) {
1222: 		throw OutOfRangeException("Failed to cast from hugeint: value is out of range");
1223: 	}
1224: 	return result;
1225: }
1226: 
1227: template <> int8_t Cast::Operation(hugeint_t input) {
1228: 	return hugeint_cast_to_numeric<int8_t>(input);
1229: }
1230: 
1231: template <> int16_t Cast::Operation(hugeint_t input) {
1232: 	return hugeint_cast_to_numeric<int16_t>(input);
1233: }
1234: 
1235: template <> int32_t Cast::Operation(hugeint_t input) {
1236: 	return hugeint_cast_to_numeric<int32_t>(input);
1237: }
1238: 
1239: template <> int64_t Cast::Operation(hugeint_t input) {
1240: 	return hugeint_cast_to_numeric<int64_t>(input);
1241: }
1242: 
1243: template <> float Cast::Operation(hugeint_t input) {
1244: 	return hugeint_cast_to_numeric<float>(input);
1245: }
1246: 
1247: template <> double Cast::Operation(hugeint_t input) {
1248: 	return hugeint_cast_to_numeric<double>(input);
1249: }
1250: 
1251: template <> bool TryCast::Operation(hugeint_t input, hugeint_t &result, bool strict) {
1252: 	result = input;
1253: 	return true;
1254: }
1255: 
1256: template <> hugeint_t Cast::Operation(hugeint_t input) {
1257: 	return input;
1258: }
1259: 
1260: } // namespace duckdb
[end of src/common/operator/cast_operators.cpp]
[start of src/common/types.cpp]
1: #include "duckdb/common/types.hpp"
2: 
3: #include "duckdb/common/exception.hpp"
4: #include "duckdb/common/serializer.hpp"
5: #include "duckdb/common/string_util.hpp"
6: #include "duckdb/common/types/string_type.hpp"
7: 
8: #include <cmath>
9: 
10: using namespace std;
11: 
12: namespace duckdb {
13: 
14: const SQLType SQLType::INVALID = SQLType(SQLTypeId::INVALID);
15: const SQLType SQLType::SQLNULL = SQLType(SQLTypeId::SQLNULL);
16: const SQLType SQLType::BOOLEAN = SQLType(SQLTypeId::BOOLEAN);
17: const SQLType SQLType::TINYINT = SQLType(SQLTypeId::TINYINT);
18: const SQLType SQLType::SMALLINT = SQLType(SQLTypeId::SMALLINT);
19: const SQLType SQLType::INTEGER = SQLType(SQLTypeId::INTEGER);
20: const SQLType SQLType::BIGINT = SQLType(SQLTypeId::BIGINT);
21: const SQLType SQLType::HUGEINT = SQLType(SQLTypeId::HUGEINT);
22: const SQLType SQLType::FLOAT = SQLType(SQLTypeId::FLOAT);
23: const SQLType SQLType::DOUBLE = SQLType(SQLTypeId::DOUBLE);
24: const SQLType SQLType::DATE = SQLType(SQLTypeId::DATE);
25: const SQLType SQLType::TIMESTAMP = SQLType(SQLTypeId::TIMESTAMP);
26: const SQLType SQLType::TIME = SQLType(SQLTypeId::TIME);
27: 
28: const SQLType SQLType::VARCHAR = SQLType(SQLTypeId::VARCHAR);
29: const SQLType SQLType::VARBINARY = SQLType(SQLTypeId::VARBINARY);
30: 
31: const SQLType SQLType::BLOB = SQLType(SQLTypeId::BLOB);
32: const SQLType SQLType::INTERVAL = SQLType(SQLTypeId::INTERVAL);
33: 
34: // TODO these are incomplete and should maybe not exist as such
35: const SQLType SQLType::STRUCT = SQLType(SQLTypeId::STRUCT);
36: const SQLType SQLType::LIST = SQLType(SQLTypeId::LIST);
37: 
38: const SQLType SQLType::ANY = SQLType(SQLTypeId::ANY);
39: 
40: const vector<SQLType> SQLType::NUMERIC = {
41:     SQLType::TINYINT, SQLType::SMALLINT, SQLType::INTEGER, SQLType::BIGINT, SQLType::HUGEINT,
42:     SQLType::FLOAT,   SQLType::DOUBLE };
43: 
44: const vector<SQLType> SQLType::INTEGRAL = {SQLType::TINYINT, SQLType::SMALLINT, SQLType::INTEGER, SQLType::BIGINT, SQLType::HUGEINT};
45: 
46: const vector<SQLType> SQLType::ALL_TYPES = {
47:     SQLType::BOOLEAN, SQLType::TINYINT,   SQLType::SMALLINT, SQLType::INTEGER, SQLType::BIGINT,
48:     SQLType::DATE,    SQLType::TIMESTAMP, SQLType::DOUBLE,   SQLType::FLOAT,
49:     SQLType::VARCHAR, SQLType::BLOB, SQLType::INTERVAL, SQLType::HUGEINT};
50: // TODO add LIST/STRUCT here
51: 
52: const TypeId ROW_TYPE = TypeId::INT64;
53: 
54: string TypeIdToString(TypeId type) {
55: 	switch (type) {
56: 	case TypeId::BOOL:
57: 		return "BOOL";
58: 	case TypeId::INT8:
59: 		return "INT8";
60: 	case TypeId::INT16:
61: 		return "INT16";
62: 	case TypeId::INT32:
63: 		return "INT32";
64: 	case TypeId::INT64:
65: 		return "INT64";
66: 	case TypeId::INT128:
67: 		return "INT128";
68: 	case TypeId::HASH:
69: 		return "HASH";
70: 	case TypeId::POINTER:
71: 		return "POINTER";
72: 	case TypeId::FLOAT:
73: 		return "FLOAT";
74: 	case TypeId::DOUBLE:
75: 		return "DOUBLE";
76: 	case TypeId::VARCHAR:
77: 		return "VARCHAR";
78: 	case TypeId::VARBINARY:
79: 		return "VARBINARY";
80: 	case TypeId::INTERVAL:
81: 		return "INTERVAL";
82: 	case TypeId::STRUCT:
83: 		return "STRUCT<?>";
84: 	case TypeId::LIST:
85: 		return "LIST<?>";
86: 	default:
87: 		throw ConversionException("Invalid TypeId %d", type);
88: 	}
89: }
90: 
91: idx_t GetTypeIdSize(TypeId type) {
92: 	switch (type) {
93: 	case TypeId::BOOL:
94: 		return sizeof(bool);
95: 	case TypeId::INT8:
96: 		return sizeof(int8_t);
97: 	case TypeId::INT16:
98: 		return sizeof(int16_t);
99: 	case TypeId::INT32:
100: 		return sizeof(int32_t);
101: 	case TypeId::INT64:
102: 		return sizeof(int64_t);
103: 	case TypeId::INT128:
104: 		return sizeof(hugeint_t);
105: 	case TypeId::FLOAT:
106: 		return sizeof(float);
107: 	case TypeId::DOUBLE:
108: 		return sizeof(double);
109: 	case TypeId::HASH:
110: 		return sizeof(hash_t);
111: 	case TypeId::POINTER:
112: 		return sizeof(uintptr_t);
113: 	case TypeId::VARCHAR:
114: 		return sizeof(string_t);
115: 	case TypeId::INTERVAL:
116: 		return sizeof(interval_t);
117: 	case TypeId::STRUCT:
118: 		return 0; // no own payload
119: 	case TypeId::LIST:
120: 		return 16; // offset + len
121: 	case TypeId::VARBINARY:
122: 		return sizeof(blob_t);
123: 	default:
124: 		throw ConversionException("Invalid TypeId %d", type);
125: 	}
126: }
127: 
128: SQLType SQLTypeFromInternalType(TypeId type) {
129: 	switch (type) {
130: 	case TypeId::BOOL:
131: 		return SQLType(SQLTypeId::BOOLEAN);
132: 	case TypeId::INT8:
133: 		return SQLType::TINYINT;
134: 	case TypeId::INT16:
135: 		return SQLType::SMALLINT;
136: 	case TypeId::INT32:
137: 		return SQLType::INTEGER;
138: 	case TypeId::INT64:
139: 		return SQLType::BIGINT;
140: 	case TypeId::INT128:
141: 		return SQLType::HUGEINT;
142: 	case TypeId::FLOAT:
143: 		return SQLType::FLOAT;
144: 	case TypeId::DOUBLE:
145: 		return SQLType::DOUBLE;
146: 	case TypeId::INTERVAL:
147: 		return SQLType::INTERVAL;
148: 	case TypeId::VARCHAR:
149: 		return SQLType::VARCHAR;
150: 	case TypeId::VARBINARY:
151: 		return SQLType(SQLTypeId::VARBINARY);
152: 	case TypeId::STRUCT:
153: 		return SQLType(SQLTypeId::STRUCT); // TODO we do not know the child types here
154: 	case TypeId::LIST:
155: 		return SQLType(SQLTypeId::LIST);
156: 	default:
157: 		throw ConversionException("Invalid TypeId %d", type);
158: 	}
159: }
160: 
161: bool TypeIsConstantSize(TypeId type) {
162: 	return (type >= TypeId::BOOL && type <= TypeId::DOUBLE) ||
163: 	       (type >= TypeId::FIXED_SIZE_BINARY && type <= TypeId::DECIMAL) || type == TypeId::HASH ||
164: 	       type == TypeId::POINTER || type == TypeId::INTERVAL || type == TypeId::INT128;
165: }
166: bool TypeIsIntegral(TypeId type) {
167: 	return (type >= TypeId::UINT8 && type <= TypeId::INT64) || type == TypeId::HASH || type == TypeId::POINTER || type == TypeId::INT128;
168: }
169: bool TypeIsNumeric(TypeId type) {
170: 	return (type >= TypeId::UINT8 && type <= TypeId::DOUBLE)|| type == TypeId::INT128;
171: }
172: bool TypeIsInteger(TypeId type) {
173: 	return (type >= TypeId::UINT8 && type <= TypeId::INT64) || type == TypeId::INT128;
174: }
175: 
176: void SQLType::Serialize(Serializer &serializer) {
177: 	serializer.Write(id);
178: 	serializer.Write(width);
179: 	serializer.Write(scale);
180: 	serializer.WriteString(collation);
181: }
182: 
183: SQLType SQLType::Deserialize(Deserializer &source) {
184: 	auto id = source.Read<SQLTypeId>();
185: 	auto width = source.Read<uint16_t>();
186: 	auto scale = source.Read<uint8_t>();
187: 	auto collation = source.Read<string>();
188: 	return SQLType(id, width, scale, collation);
189: }
190: 
191: string SQLTypeIdToString(SQLTypeId id) {
192: 	switch (id) {
193: 	case SQLTypeId::BOOLEAN:
194: 		return "BOOLEAN";
195: 	case SQLTypeId::TINYINT:
196: 		return "TINYINT";
197: 	case SQLTypeId::SMALLINT:
198: 		return "SMALLINT";
199: 	case SQLTypeId::INTEGER:
200: 		return "INTEGER";
201: 	case SQLTypeId::BIGINT:
202: 		return "BIGINT";
203: 	case SQLTypeId::HUGEINT:
204: 		return "HUGEINT";
205: 	case SQLTypeId::DATE:
206: 		return "DATE";
207: 	case SQLTypeId::TIME:
208: 		return "TIME";
209: 	case SQLTypeId::TIMESTAMP:
210: 		return "TIMESTAMP";
211: 	case SQLTypeId::FLOAT:
212: 		return "FLOAT";
213: 	case SQLTypeId::DOUBLE:
214: 		return "DOUBLE";
215: 	case SQLTypeId::DECIMAL:
216: 		return "DECIMAL";
217: 	case SQLTypeId::VARCHAR:
218: 		return "VARCHAR";
219: 	case SQLTypeId::BLOB:
220: 		return "BLOB";
221: 	case SQLTypeId::VARBINARY:
222: 		return "VARBINARY";
223: 	case SQLTypeId::CHAR:
224: 		return "CHAR";
225: 	case SQLTypeId::INTERVAL:
226: 		return "INTERVAL";
227: 	case SQLTypeId::SQLNULL:
228: 		return "NULL";
229: 	case SQLTypeId::ANY:
230: 		return "ANY";
231: 	case SQLTypeId::STRUCT:
232: 		return "STRUCT<?>";
233: 	case SQLTypeId::LIST:
234: 		return "LIST<?>";
235: 	case SQLTypeId::INVALID:
236: 		return "INVALID";
237: 	case SQLTypeId::UNKNOWN:
238: 		return "UNKNOWN";
239: 	}
240: 	return "UNDEFINED";
241: }
242: 
243: string SQLTypeToString(SQLType type) {
244: 	// FIXME: display width/scale
245: 	switch (type.id) {
246: 	case SQLTypeId::STRUCT: {
247: 		string ret = "STRUCT<";
248: 		for (size_t i = 0; i < type.child_type.size(); i++) {
249: 			ret += type.child_type[i].first + ": " + SQLTypeToString(type.child_type[i].second);
250: 			if (i < type.child_type.size() - 1) {
251: 				ret += ", ";
252: 			}
253: 		}
254: 		ret += ">";
255: 		return ret;
256: 	}
257: 	case SQLTypeId::LIST: {
258: 		if (type.child_type.size() == 0) {
259: 			return "LIST<?>";
260: 		}
261: 		if (type.child_type.size() != 1) {
262: 			throw Exception("List needs a single child element");
263: 		}
264: 		return "LIST<" + SQLTypeToString(type.child_type[0].second) + ">";
265: 	}
266: 	default:
267: 		return SQLTypeIdToString(type.id);
268: 	}
269: }
270: 
271: SQLType TransformStringToSQLType(string str) {
272: 	auto lower_str = StringUtil::Lower(str);
273: 	// Transform column type
274: 	if (lower_str == "int" || lower_str == "int4" || lower_str == "signed" || lower_str == "integer" ||
275: 	    lower_str == "integral" || lower_str == "int32") {
276: 		return SQLType::INTEGER;
277: 	} else if (lower_str == "varchar" || lower_str == "bpchar" || lower_str == "text" || lower_str == "string" ||
278: 	           lower_str == "char") {
279: 		return SQLType::VARCHAR;
280: 	} else if (lower_str == "bytea" || lower_str == "blob") {
281: 		return SQLType::BLOB;
282: 	} else if (lower_str == "int8" || lower_str == "bigint" || lower_str == "int64" || lower_str == "long") {
283: 		return SQLType::BIGINT;
284: 	} else if (lower_str == "int2" || lower_str == "smallint" || lower_str == "short" || lower_str == "int16") {
285: 		return SQLType::SMALLINT;
286: 	} else if (lower_str == "timestamp" || lower_str == "datetime") {
287: 		return SQLType::TIMESTAMP;
288: 	} else if (lower_str == "bool" || lower_str == "boolean" || lower_str == "logical") {
289: 		return SQLType(SQLTypeId::BOOLEAN);
290: 	} else if (lower_str == "real" || lower_str == "float4" || lower_str == "float") {
291: 		return SQLType::FLOAT;
292: 	} else if (lower_str == "double" || lower_str == "numeric" || lower_str == "float8" || lower_str == "decimal") {
293: 		return SQLType::DOUBLE;
294: 	} else if (lower_str == "tinyint" || lower_str == "int1") {
295: 		return SQLType::TINYINT;
296: 	} else if (lower_str == "varbinary") {
297: 		return SQLType(SQLTypeId::VARBINARY);
298: 	} else if (lower_str == "date") {
299: 		return SQLType::DATE;
300: 	} else if (lower_str == "time") {
301: 		return SQLType::TIME;
302: 	} else if (lower_str == "interval") {
303: 		return SQLType::INTERVAL;
304: 	} else if (lower_str == "hugeint" || lower_str == "int128") {
305: 		return SQLType::HUGEINT;
306: 	}  else {
307: 		throw NotImplementedException("DataType %s not supported yet...\n", str.c_str());
308: 	}
309: }
310: 
311: bool SQLType::IsIntegral() const {
312: 	switch (id) {
313: 	case SQLTypeId::TINYINT:
314: 	case SQLTypeId::SMALLINT:
315: 	case SQLTypeId::INTEGER:
316: 	case SQLTypeId::BIGINT:
317: 	case SQLTypeId::HUGEINT:
318: 		return true;
319: 	default:
320: 		return false;
321: 	}
322: }
323: 
324: bool SQLType::IsNumeric() const {
325: 	switch (id) {
326: 	case SQLTypeId::TINYINT:
327: 	case SQLTypeId::SMALLINT:
328: 	case SQLTypeId::INTEGER:
329: 	case SQLTypeId::BIGINT:
330: 	case SQLTypeId::HUGEINT:
331: 	case SQLTypeId::FLOAT:
332: 	case SQLTypeId::DOUBLE:
333: 	case SQLTypeId::DECIMAL:
334: 		return true;
335: 	default:
336: 		return false;
337: 	}
338: }
339: 
340: int NumericTypeOrder(TypeId type) {
341: 	switch (type) {
342: 	case TypeId::INT8:
343: 		return 1;
344: 	case TypeId::INT16:
345: 		return 2;
346: 	case TypeId::INT32:
347: 		return 3;
348: 	case TypeId::INT64:
349: 		return 4;
350: 	case TypeId::INT128:
351: 		return 5;
352: 	case TypeId::FLOAT:
353: 		return 6;
354: 	case TypeId::DOUBLE:
355: 		return 7;
356: 	default:
357: 		throw NotImplementedException("Not a numeric type");
358: 	}
359: }
360: 
361: bool SQLType::IsMoreGenericThan(SQLType &other) const {
362: 	if (other.id == id) {
363: 		return false;
364: 	}
365: 
366: 	if (other.id == SQLTypeId::SQLNULL) {
367: 		return true;
368: 	}
369: 
370: 	// all integer types can cast from INTEGER
371: 	// this is because INTEGER is the smallest type considered by the automatic csv sniffer
372: 	switch (id) {
373: 	case SQLTypeId::SMALLINT:
374: 		switch (other.id) {
375: 		case SQLTypeId::TINYINT:
376: 		case SQLTypeId::SMALLINT:
377: 		case SQLTypeId::INTEGER:
378: 			return true;
379: 		default:
380: 			return false;
381: 		}
382: 	case SQLTypeId::INTEGER:
383: 		switch (other.id) {
384: 		case SQLTypeId::TINYINT:
385: 		case SQLTypeId::SMALLINT:
386: 		case SQLTypeId::INTEGER:
387: 			return true;
388: 		default:
389: 			return false;
390: 		}
391: 	case SQLTypeId::BIGINT:
392: 		switch (other.id) {
393: 		case SQLTypeId::TINYINT:
394: 		case SQLTypeId::SMALLINT:
395: 		case SQLTypeId::INTEGER:
396: 			return true;
397: 		default:
398: 			return false;
399: 		}
400: 	case SQLTypeId::HUGEINT:
401: 		switch (other.id) {
402: 		case SQLTypeId::TINYINT:
403: 		case SQLTypeId::SMALLINT:
404: 		case SQLTypeId::INTEGER:
405: 		case SQLTypeId::BIGINT:
406: 			return true;
407: 		default:
408: 			return false;
409: 		}
410: 	case SQLTypeId::DOUBLE:
411: 		switch (other.id) {
412: 		case SQLTypeId::TINYINT:
413: 		case SQLTypeId::SMALLINT:
414: 		case SQLTypeId::INTEGER:
415: 		case SQLTypeId::BIGINT:
416: 			return true;
417: 		default:
418: 			return false;
419: 		}
420: 		return false;
421: 	case SQLTypeId::DATE:
422: 		return false;
423: 	case SQLTypeId::TIMESTAMP:
424: 		switch (other.id) {
425: 		case SQLTypeId::TIME:
426: 		case SQLTypeId::DATE:
427: 			return true;
428: 		default:
429: 			return false;
430: 		}
431: 	case SQLTypeId::VARCHAR:
432: 		return true;
433: 	default:
434: 		return false;
435: 	}
436: 
437: 	return true;
438: }
439: 
440: TypeId GetInternalType(SQLType type) {
441: 	switch (type.id) {
442: 	case SQLTypeId::BOOLEAN:
443: 		return TypeId::BOOL;
444: 	case SQLTypeId::TINYINT:
445: 		return TypeId::INT8;
446: 	case SQLTypeId::SMALLINT:
447: 		return TypeId::INT16;
448: 	case SQLTypeId::SQLNULL:
449: 	case SQLTypeId::DATE:
450: 	case SQLTypeId::TIME:
451: 	case SQLTypeId::INTEGER:
452: 		return TypeId::INT32;
453: 	case SQLTypeId::BIGINT:
454: 	case SQLTypeId::TIMESTAMP:
455: 		return TypeId::INT64;
456: 	case SQLTypeId::HUGEINT:
457: 		return TypeId::INT128;
458: 	case SQLTypeId::FLOAT:
459: 		return TypeId::FLOAT;
460: 	case SQLTypeId::DOUBLE:
461: 		return TypeId::DOUBLE;
462: 	case SQLTypeId::DECIMAL:
463: 		// FIXME: for now
464: 		return TypeId::DOUBLE;
465: 	case SQLTypeId::VARCHAR:
466: 	case SQLTypeId::CHAR:
467: 	case SQLTypeId::BLOB:
468: 		return TypeId::VARCHAR;
469: 	case SQLTypeId::VARBINARY:
470: 		return TypeId::VARBINARY;
471: 	case SQLTypeId::INTERVAL:
472: 		return TypeId::INTERVAL;
473: 	case SQLTypeId::STRUCT:
474: 		return TypeId::STRUCT;
475: 	case SQLTypeId::LIST:
476: 		return TypeId::LIST;
477: 	case SQLTypeId::ANY:
478: 		return TypeId::INVALID;
479: 	default:
480: 		throw ConversionException("Invalid SQLType %s", SQLTypeToString(type).c_str());
481: 	}
482: }
483: 
484: SQLType MaxSQLType(SQLType left, SQLType right) {
485: 	if (left.id < right.id) {
486: 		return right;
487: 	} else if (right.id < left.id) {
488: 		return left;
489: 	} else if (left.width > right.width || left.collation > right.collation) {
490: 		return left;
491: 	} else {
492: 		return right;
493: 	}
494: }
495: 
496: bool ApproxEqual(float ldecimal, float rdecimal) {
497: 	float epsilon = fabs(rdecimal) * 0.01;
498: 	return fabs(ldecimal - rdecimal) <= epsilon;
499: }
500: 
501: bool ApproxEqual(double ldecimal, double rdecimal) {
502: 	double epsilon = fabs(rdecimal) * 0.01;
503: 	return fabs(ldecimal - rdecimal) <= epsilon;
504: }
505: 
506: } // namespace duckdb
[end of src/common/types.cpp]
[start of src/execution/operator/persistent/buffered_csv_reader.cpp]
1: #include "duckdb/execution/operator/persistent/buffered_csv_reader.hpp"
2: 
3: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
4: #include "duckdb/common/file_system.hpp"
5: #include "duckdb/common/gzip_stream.hpp"
6: #include "duckdb/common/string_util.hpp"
7: #include "duckdb/common/vector_operations/vector_operations.hpp"
8: #include "duckdb/common/vector_operations/unary_executor.hpp"
9: #include "duckdb/execution/operator/persistent/physical_copy_from_file.hpp"
10: #include "duckdb/function/scalar/strftime.hpp"
11: #include "duckdb/main/database.hpp"
12: #include "duckdb/parser/column_definition.hpp"
13: #include "duckdb/storage/data_table.hpp"
14: #include "utf8proc_wrapper.hpp"
15: 
16: #include <algorithm>
17: #include <cstring>
18: #include <fstream>
19: 
20: using namespace std;
21: 
22: namespace duckdb {
23: 
24: static char is_newline(char c) {
25: 	return c == '\n' || c == '\r';
26: }
27: 
28: // Helper function to generate column names
29: static string GenerateColumnName(const idx_t total_cols, const idx_t col_number, const string prefix = "column") {
30: 	uint8_t max_digits = total_cols > 10 ? (int)log10((double)total_cols - 1) + 1 : 1;
31: 	uint8_t digits = col_number >= 10 ? (int)log10((double)col_number) + 1 : 1;
32: 	string leading_zeros = string("0", max_digits - digits);
33: 	string value = std::to_string(col_number);
34: 	return string(prefix + leading_zeros + value);
35: }
36: 
37: static string GetLineNumberStr(idx_t linenr, bool linenr_estimated) {
38: 	string estimated = (linenr_estimated ? string(" (estimated)") : string(""));
39: 	return std::to_string(linenr) + estimated;
40: }
41: 
42: TextSearchShiftArray::TextSearchShiftArray() {
43: }
44: 
45: TextSearchShiftArray::TextSearchShiftArray(string search_term) : length(search_term.size()) {
46: 	if (length > 255) {
47: 		throw Exception("Size of delimiter/quote/escape in CSV reader is limited to 255 bytes");
48: 	}
49: 	// initialize the shifts array
50: 	shifts = unique_ptr<uint8_t[]>(new uint8_t[length * 255]);
51: 	memset(shifts.get(), 0, length * 255 * sizeof(uint8_t));
52: 	// iterate over each of the characters in the array
53: 	for (idx_t main_idx = 0; main_idx < length; main_idx++) {
54: 		uint8_t current_char = (uint8_t)search_term[main_idx];
55: 		// now move over all the remaining positions
56: 		for (idx_t i = main_idx; i < length; i++) {
57: 			bool is_match = true;
58: 			// check if the prefix matches at this position
59: 			// if it does, we move to this position after encountering the current character
60: 			for (idx_t j = 0; j < main_idx; j++) {
61: 				if (search_term[i - main_idx + j] != search_term[j]) {
62: 					is_match = false;
63: 				}
64: 			}
65: 			if (!is_match) {
66: 				continue;
67: 			}
68: 			shifts[i * 255 + current_char] = main_idx + 1;
69: 		}
70: 	}
71: }
72: 
73: BufferedCSVReader::BufferedCSVReader(ClientContext &context, BufferedCSVReaderOptions options, vector<SQLType> requested_types)
74: 	: options(options), buffer_size(0), position(0), start(0) {
75: 	source = OpenCSV(context, options);
76: 	Initialize(requested_types);
77: }
78: 
79: BufferedCSVReader::BufferedCSVReader(BufferedCSVReaderOptions options, vector<SQLType> requested_types, unique_ptr<istream> ssource)
80: 	: options(options), source(move(ssource)), buffer_size(0), position(0), start(0) {
81: 	Initialize(requested_types);
82: }
83: 
84: void BufferedCSVReader::Initialize(vector<SQLType> requested_types) {
85: 	if (options.auto_detect) {
86: 		sql_types = SniffCSV(requested_types);
87: 	} else {
88: 		sql_types = requested_types;
89: 	}
90: 
91: 	PrepareComplexParser();
92: 	InitParseChunk(sql_types.size());
93: 	SkipHeader();
94: }
95: 
96: void BufferedCSVReader::PrepareComplexParser() {
97: 	delimiter_search = TextSearchShiftArray(options.delimiter);
98: 	escape_search = TextSearchShiftArray(options.escape);
99: 	quote_search = TextSearchShiftArray(options.quote);
100: }
101: 
102: unique_ptr<istream> BufferedCSVReader::OpenCSV(ClientContext &context, BufferedCSVReaderOptions options) {
103: 	if (!FileSystem::GetFileSystem(context).FileExists(options.file_path)) {
104: 		throw IOException("File \"%s\" not found", options.file_path.c_str());
105: 	}
106: 	unique_ptr<istream> result;
107: 	// decide based on the extension which stream to use
108: 	if (StringUtil::EndsWith(StringUtil::Lower(options.file_path), ".gz")) {
109: 		result = make_unique<GzipStream>(options.file_path);
110: 		plain_file_source = false;
111: 	} else {
112: 		auto csv_local = make_unique<ifstream>();
113: 		csv_local->open(options.file_path);
114: 		result = move(csv_local);
115: 
116: 		// determine filesize
117: 		plain_file_source = true;
118: 		result->seekg(0, result->end);
119: 		file_size = (idx_t)result->tellg();
120: 		result->clear();
121: 		result->seekg(0, result->beg);
122: 	}
123: 	return result;
124: }
125: 
126: void BufferedCSVReader::SkipHeader() {
127: 	for (idx_t i = 0; i < options.skip_rows; i++) {
128: 		// ignore skip rows
129: 		string read_line;
130: 		getline(*source, read_line);
131: 		linenr++;
132: 	}
133: 
134: 	if (options.header) {
135: 		// ignore the first line as a header line
136: 		string read_line;
137: 		getline(*source, read_line);
138: 		linenr++;
139: 	}
140: }
141: 
142: void BufferedCSVReader::ResetBuffer() {
143: 	buffer.reset();
144: 	buffer_size = 0;
145: 	position = 0;
146: 	start = 0;
147: 	cached_buffers.clear();
148: }
149: 
150: void BufferedCSVReader::ResetStream() {
151: 	if (!plain_file_source && StringUtil::EndsWith(StringUtil::Lower(options.file_path), ".gz")) {
152: 		// seeking to the beginning appears to not be supported in all compiler/os-scenarios,
153: 		// so we have to create a new stream source here for now
154: 		source = make_unique<GzipStream>(options.file_path);
155: 	} else {
156: 		source->clear();
157: 		source->seekg(0, source->beg);
158: 	}
159: 	linenr = 0;
160: 	linenr_estimated = false;
161: 	bytes_per_line_avg = 0;
162: 	sample_chunk_idx = 0;
163: 	jumping_samples = false;
164: }
165: 
166: void BufferedCSVReader::ResetParseChunk() {
167: 	bytes_in_chunk = 0;
168: 	parse_chunk.Reset();
169: }
170: 
171: void BufferedCSVReader::InitParseChunk(idx_t num_cols) {
172: 	// adapt not null info
173: 	if (options.force_not_null.size() != num_cols) {
174: 		options.force_not_null.resize(num_cols, false);
175: 	}
176: 
177: 	// destroy previous chunk
178: 	parse_chunk.Destroy();
179: 
180: 	// initialize the parse_chunk with a set of VARCHAR types
181: 	vector<TypeId> varchar_types(num_cols, TypeId::VARCHAR);
182: 	parse_chunk.Initialize(varchar_types);
183: }
184: 
185: void BufferedCSVReader::JumpToBeginning() {
186: 	ResetBuffer();
187: 	ResetStream();
188: 	ResetParseChunk();
189: 	SkipHeader();
190: }
191: 
192: bool BufferedCSVReader::JumpToNextSample() {
193: 	if (source->eof() || sample_chunk_idx >= MAX_SAMPLE_CHUNKS) {
194: 		return false;
195: 	}
196: 
197: 	// update average bytes per line
198: 	double bytes_per_line = bytes_in_chunk / (double)SAMPLE_CHUNK_SIZE;
199: 	bytes_per_line_avg = ((bytes_per_line_avg * sample_chunk_idx) + bytes_per_line) / (sample_chunk_idx + 1);
200: 
201: 	// assess if it makes sense to jump, based on size of the first chunk relative to size of the entire file
202: 	if (sample_chunk_idx == 0) {
203: 		idx_t bytes_first_chunk = bytes_in_chunk;
204: 		double chunks_fit = (file_size / (double)bytes_first_chunk);
205: 		jumping_samples = chunks_fit >= (MAX_SAMPLE_CHUNKS - 1);
206: 	}
207: 
208: 	// if we deal with any other sources than plaintext files, jumping_samples can be tricky. In that case
209: 	// we just read x continuous chunks from the stream TODO: make jumps possible for zipfiles.
210: 	if (!plain_file_source || !jumping_samples) {
211: 		sample_chunk_idx++;
212: 		ResetParseChunk();
213: 		return true;
214: 	}
215: 
216: 	// adjust the value of bytes_in_chunk, based on current state of the buffer
217: 	idx_t remaining_bytes_in_buffer = buffer_size - start;
218: 	bytes_in_chunk -= remaining_bytes_in_buffer;
219: 
220: 	// if none of the previous conditions were met, we can jump
221: 	idx_t partition_size = (idx_t)round(file_size / (double)MAX_SAMPLE_CHUNKS);
222: 
223: 	// calculate offset to end of the current partition
224: 	int64_t offset = partition_size - bytes_in_chunk - remaining_bytes_in_buffer;
225: 	idx_t current_pos = (idx_t)source->tellg();
226: 
227: 	if (current_pos + offset < file_size) {
228: 		// set position in stream and clear failure bits
229: 		source->clear();
230: 		source->seekg(offset, source->cur);
231: 
232: 		// estimate linenr
233: 		linenr += (idx_t)round((offset + remaining_bytes_in_buffer) / bytes_per_line_avg);
234: 		linenr_estimated = true;
235: 	} else {
236: 		// seek backwards from the end in last chunk and hope to catch the end of the file
237: 		// TODO: actually it would be good to make sure that the end of file is being reached, because
238: 		// messy end-lines are quite common. For this case, however, we first need a skip_end detection anyways.
239: 		source->seekg(-bytes_in_chunk, source->end);
240: 
241: 		// estimate linenr
242: 		linenr = (idx_t)round((file_size - bytes_in_chunk) / bytes_per_line_avg);
243: 		linenr_estimated = true;
244: 	}
245: 
246: 	// reset buffers and internal positions
247: 	ResetBuffer();
248: 	ResetParseChunk();
249: 
250: 	// seek beginning of next line
251: 	// FIXME: if this jump ends up in a quoted linebreak, we will have a problem
252: 	string read_line;
253: 	getline(*source, read_line);
254: 	linenr++;
255: 
256: 	sample_chunk_idx++;
257: 
258: 	return true;
259: }
260: 
261: bool BufferedCSVReader::TryCastValue(Value value, SQLType sql_type) {
262: 	try {
263: 		if (options.has_date_format && sql_type.id == SQLTypeId::DATE) {
264: 			options.date_format.ParseDate(value.str_value);
265: 		} else if (options.has_timestamp_format && sql_type.id == SQLTypeId::TIMESTAMP) {
266: 			options.timestamp_format.ParseTimestamp(value.str_value);
267: 		} else {
268: 			value.CastAs(SQLType::VARCHAR, sql_type, true);
269: 		}
270: 		return true;
271: 	} catch (const Exception &e) {
272: 		return false;
273: 	}
274: 	return false;
275: }
276: 
277: vector<SQLType> BufferedCSVReader::SniffCSV(vector<SQLType> requested_types) {
278: 	// TODO: sniff for uncommon (UTF-8) delimiter variants in first lines and add them to the list
279: 	const vector<string> delim_candidates = {",", "|", ";", "\t"};
280: 	const vector<QuoteRule> quoterule_candidates = {QuoteRule::QUOTES_RFC, QuoteRule::QUOTES_OTHER,
281: 													QuoteRule::NO_QUOTES};
282: 	// quote candiates depend on quote rule
283: 	const vector<vector<string>> quote_candidates_map = {{"\""}, {"\"", "'"}, {""}};
284: 	// escape candiates also depend on quote rule.
285: 	// Note: RFC-conform escapes are handled automatically, and without quotes no escape char is required
286: 	const vector<vector<string>> escape_candidates_map = {{""}, {"\\"}, {""}};
287: 
288: 	vector<BufferedCSVReaderOptions> info_candidates;
289: 	idx_t best_consistent_rows = 0;
290: 	idx_t best_num_cols = 0;
291: 
292: 	// if requested_types were provided, use them already in dialect detection
293: 	// TODO: currently they only serve to solve the edge case of trailing empty delimiters,
294: 	// however, they could be used to solve additional ambigious scenarios.
295: 	sql_types = requested_types;
296: 	// TODO: add a flag to indicate that no option actually worked and default will be used (RFC-4180)
297: 	for (QuoteRule quoterule : quoterule_candidates) {
298: 		vector<string> quote_candidates = quote_candidates_map[static_cast<uint8_t>(quoterule)];
299: 		for (const auto &quote : quote_candidates) {
300: 			for (const auto &delim : delim_candidates) {
301: 				vector<string> escape_candidates = escape_candidates_map[static_cast<uint8_t>(quoterule)];
302: 				for (const auto &escape : escape_candidates) {
303: 					BufferedCSVReaderOptions sniff_info = options;
304: 					sniff_info.delimiter = delim;
305: 					sniff_info.quote = quote;
306: 					sniff_info.escape = escape;
307: 
308: 					options = sniff_info;
309: 					PrepareComplexParser();
310: 
311: 					ResetBuffer();
312: 					ResetStream();
313: 					sniffed_column_counts.clear();
314: 					try {
315: 						ParseCSV(ParserMode::SNIFFING_DIALECT);
316: 					} catch (const ParserException &e) {
317: 						continue;
318: 					}
319: 
320: 					idx_t start_row = 0;
321: 					idx_t consistent_rows = 0;
322: 					idx_t num_cols = 0;
323: 
324: 					for (idx_t row = 0; row < sniffed_column_counts.size(); row++) {
325: 						if (sniffed_column_counts[row] == num_cols) {
326: 							consistent_rows++;
327: 						} else {
328: 							num_cols = sniffed_column_counts[row];
329: 							start_row = row;
330: 							consistent_rows = 1;
331: 						}
332: 					}
333: 
334: 					// some logic
335: 					bool more_values = (consistent_rows > best_consistent_rows && num_cols >= best_num_cols);
336: 					bool single_column_before = best_num_cols < 2 && num_cols > best_num_cols;
337: 					bool rows_consistent = start_row + consistent_rows == sniffed_column_counts.size();
338: 					bool more_than_one_row = (consistent_rows > 1);
339: 					bool more_than_one_column = (num_cols > 1);
340: 					bool start_good = info_candidates.size() > 0 && (start_row <= info_candidates.front().skip_rows);
341: 
342: 					if ((more_values || single_column_before) && rows_consistent) {
343: 						sniff_info.skip_rows = start_row;
344: 						sniff_info.num_cols = num_cols;
345: 						best_consistent_rows = consistent_rows;
346: 						best_num_cols = num_cols;
347: 
348: 						info_candidates.clear();
349: 						info_candidates.push_back(sniff_info);
350: 					} else if (more_than_one_row && more_than_one_column && start_good && rows_consistent) {
351: 						bool same_quote_is_candidate = false;
352: 						for (auto &info_candidate : info_candidates) {
353: 							if (quote.compare(info_candidate.quote) == 0) {
354: 								same_quote_is_candidate = true;
355: 							}
356: 						}
357: 						if (!same_quote_is_candidate) {
358: 							sniff_info.skip_rows = start_row;
359: 							sniff_info.num_cols = num_cols;
360: 							info_candidates.push_back(sniff_info);
361: 						}
362: 					}
363: 				}
364: 			}
365: 		}
366: 	}
367: 
368: 	// then, file was most likely empty and we can do no more
369: 	if (info_candidates.size() < 1) {
370: 		if (requested_types.size() == 0) {
371: 			// no types requested and no types/names could be deduced: default to a single varchar column
372: 			col_names.push_back("col0");
373: 			requested_types.push_back(SQLType::VARCHAR);
374: 		}
375: 		return requested_types;
376: 	}
377: 
378: 	// type candidates, ordered by descending specificity (~ from high to low)
379: 	vector<SQLType> type_candidates = {SQLType::VARCHAR, SQLType::TIMESTAMP, SQLType::DATE,
380: 									   SQLType::TIME,    SQLType::DOUBLE,    /*SQLType::FLOAT,*/ SQLType::BIGINT,
381: 									   SQLType::INTEGER, /* SQLType::SMALLINT, */  /*SQLType::TINYINT,*/ SQLType::BOOLEAN,
382: 									   SQLType::SQLNULL};
383: 
384: 	// check which info candiate leads to minimum amount of non-varchar columns...
385: 	BufferedCSVReaderOptions best_options;
386: 	idx_t min_varchar_cols = best_num_cols + 1;
387: 	vector<vector<SQLType>> best_sql_types_candidates;
388: 	for (auto &info_candidate : info_candidates) {
389: 		options = info_candidate;
390: 		vector<vector<SQLType>> info_sql_types_candidates(options.num_cols, type_candidates);
391: 
392: 		// set all sql_types to VARCHAR so we can do datatype detection based on VARCHAR values
393: 		sql_types.clear();
394: 		sql_types.assign(options.num_cols, SQLType::VARCHAR);
395: 		InitParseChunk(sql_types.size());
396: 
397: 		// detect types in first chunk
398: 		JumpToBeginning();
399: 		ParseCSV(ParserMode::SNIFFING_DATATYPES);
400: 		for (idx_t row = 0; row < parse_chunk.size(); row++) {
401: 			for (idx_t col = 0; col < parse_chunk.column_count(); col++) {
402: 				vector<SQLType> &col_type_candidates = info_sql_types_candidates[col];
403: 				while (col_type_candidates.size() > 1) {
404: 					const auto &sql_type = col_type_candidates.back();
405: 					// try cast from string to sql_type
406: 					auto dummy_val = parse_chunk.GetValue(col, row);
407: 					if (TryCastValue(dummy_val, sql_type)) {
408: 						break;
409: 					} else {
410: 						col_type_candidates.pop_back();
411: 					}
412: 				}
413: 			}
414: 			// reset type detection for second row, because first row could be header,
415: 			// but only do it if csv has more than one line
416: 			if (parse_chunk.size() > 1 && row == 0) {
417: 				info_sql_types_candidates = vector<vector<SQLType>>(options.num_cols, type_candidates);
418: 			}
419: 		}
420: 
421: 		// check number of varchar columns
422: 		idx_t varchar_cols = 0;
423: 		for (idx_t col = 0; col < parse_chunk.column_count(); col++) {
424: 			const auto &col_type = info_sql_types_candidates[col].back();
425: 			if (col_type == SQLType::VARCHAR) {
426: 				varchar_cols++;
427: 			}
428: 		}
429: 
430: 		// it's good if the dialect creates more non-varchar columns, but only if we sacrifice < 40% of best_num_cols.
431: 		if (varchar_cols < min_varchar_cols && parse_chunk.column_count() > (best_num_cols * 0.7)) {
432: 			// we have a new best_info candidate
433: 			best_options = info_candidate;
434: 			min_varchar_cols = varchar_cols;
435: 			best_sql_types_candidates = info_sql_types_candidates;
436: 		}
437: 	}
438: 
439: 	options = best_options;
440: 
441: 	// if data types were provided, exit here if number of columns does not match
442: 	// TODO: we could think about postponing this to see if the csv happens to contain a superset of requested columns
443: 	if (requested_types.size() > 0 && requested_types.size() != options.num_cols) {
444: 		throw ParserException("Error while determining column types: found %lld columns but expected %d", options.num_cols,
445: 							  requested_types.size());
446: 	}
447: 
448: 	// sql_types and parse_chunk have to be in line with new info
449: 	sql_types.clear();
450: 	sql_types.assign(options.num_cols, SQLType::VARCHAR);
451: 	InitParseChunk(sql_types.size());
452: 
453: 	// jump through the rest of the file and continue to refine the sql type guess
454: 	while (JumpToNextSample()) {
455: 		// if jump ends up a bad line, we just skip this chunk
456: 		try {
457: 			ParseCSV(ParserMode::SNIFFING_DATATYPES);
458: 		} catch (const ParserException &e) {
459: 			continue;
460: 		}
461: 		for (idx_t col = 0; col < parse_chunk.column_count(); col++) {
462: 			vector<SQLType> &col_type_candidates = best_sql_types_candidates[col];
463: 			while (col_type_candidates.size() > 1) {
464: 				try {
465: 					const auto &sql_type = col_type_candidates.back();
466: 					// try vector-cast from string to sql_type
467: 					parse_chunk.data[col];
468: 					Vector dummy_result(GetInternalType(sql_type));
469: 					VectorOperations::Cast(parse_chunk.data[col], dummy_result, SQLType::VARCHAR, sql_type,
470: 										   parse_chunk.size(), true);
471: 					break;
472: 				} catch (const Exception &e) {
473: 					col_type_candidates.pop_back();
474: 				}
475: 			}
476: 		}
477: 	}
478: 
479: 	// information for header detection
480: 	bool first_row_consistent = true;
481: 	bool first_row_nulls = true;
482: 
483: 	// parse first row again with knowledge from the rest of the file to check
484: 	// whether first row is consistent with the others or not.
485: 	JumpToBeginning();
486: 	ParseCSV(ParserMode::SNIFFING_DATATYPES);
487: 	if (parse_chunk.size() > 0) {
488: 		for (idx_t col = 0; col < parse_chunk.column_count(); col++) {
489: 			auto dummy_val = parse_chunk.GetValue(col, 0);
490: 			// try cast as SQLNULL
491: 			try {
492: 				dummy_val.CastAs(SQLType::VARCHAR, SQLType::SQLNULL, true);
493: 			} catch (const Exception &e) {
494: 				first_row_nulls = false;
495: 			}
496: 			// try cast to sql_type of column
497: 			vector<SQLType> &col_type_candidates = best_sql_types_candidates[col];
498: 			const auto &sql_type = col_type_candidates.back();
499: 			if (!TryCastValue(dummy_val, sql_type)) {
500: 				first_row_consistent = false;
501: 			}
502: 		}
503: 	}
504: 
505: 	// if all rows are of type string, we will currently make the assumption there is no header.
506: 	// TODO: Do some kind of string-distance based constistency metic between first row and others
507: 	/*bool all_types_string = true;
508: 	for (idx_t col = 0; col < parse_chunk.column_count(); col++) {
509: 		const auto &col_type = best_sql_types_candidates[col].back();
510: 		all_types_string &= (col_type == SQLType::VARCHAR);
511: 	}*/
512: 
513: 	// update parser info, and read, generate & set col_names based on previous findings
514: 	if (!first_row_consistent || first_row_nulls) {
515: 		options.header = true;
516: 		vector<string> t_col_names;
517: 		for (idx_t col = 0; col < parse_chunk.column_count(); col++) {
518: 			const auto &val = parse_chunk.GetValue(col, 0);
519: 			string col_name = val.ToString();
520: 			if (col_name.empty() || val.is_null) {
521: 				col_name = GenerateColumnName(parse_chunk.column_count(), col);
522: 			}
523: 			// We'll keep column names as they appear in the file, no canonicalization
524: 			// col_name = StringUtil::Lower(col_name);
525: 			t_col_names.push_back(col_name);
526: 		}
527: 		for (idx_t col = 0; col < t_col_names.size(); col++) {
528: 			string col_name = t_col_names[col];
529: 			idx_t exists_n_times = std::count(t_col_names.begin(), t_col_names.end(), col_name);
530: 			idx_t exists_n_times_before = std::count(t_col_names.begin(), t_col_names.begin() + col, col_name);
531: 			if (exists_n_times > 1) {
532: 				col_name = GenerateColumnName(exists_n_times, exists_n_times_before, col_name + "_");
533: 			}
534: 			col_names.push_back(col_name);
535: 		}
536: 	} else {
537: 		options.header = false;
538: 		idx_t total_columns = parse_chunk.column_count();
539: 		for (idx_t col = 0; col < total_columns; col++) {
540: 			string column_name = GenerateColumnName(total_columns, col);
541: 			col_names.push_back(column_name);
542: 		}
543: 	}
544: 
545: 	// set sql types
546: 	vector<SQLType> detected_types;
547: 	for (idx_t col = 0; col < best_sql_types_candidates.size(); col++) {
548: 		SQLType d_type = best_sql_types_candidates[col].back();
549: 
550: 		if (requested_types.size() > 0) {
551: 			SQLType r_type = requested_types[col];
552: 
553: 			// check if the detected types are in line with the provided types
554: 			if (r_type != d_type) {
555: 				if (r_type.IsMoreGenericThan(d_type)) {
556: 					d_type = r_type;
557: 				} else {
558: 					throw ParserException(
559: 						"Error while sniffing data type for column '%s': Requested column type %s, detected type %s",
560: 						col_names[col].c_str(), SQLTypeToString(r_type).c_str(), SQLTypeToString(d_type).c_str());
561: 				}
562: 			}
563: 		}
564: 
565: 		detected_types.push_back(d_type);
566: 	}
567: 
568: 	// back to normal
569: 	ResetBuffer();
570: 	ResetStream();
571: 	ResetParseChunk();
572: 	sniffed_column_counts.clear();
573: 
574: 	return detected_types;
575: }
576: 
577: void BufferedCSVReader::ParseComplexCSV(DataChunk &insert_chunk) {
578: 	// used for parsing algorithm
579: 	bool finished_chunk = false;
580: 	idx_t column = 0;
581: 	vector<idx_t> escape_positions;
582: 	uint8_t delimiter_pos = 0, escape_pos = 0, quote_pos = 0;
583: 	idx_t offset = 0;
584: 
585: 	// read values into the buffer (if any)
586: 	if (position >= buffer_size) {
587: 		if (!ReadBuffer(start)) {
588: 			return;
589: 		}
590: 	}
591: 	// start parsing the first value
592: 	start = position;
593: 	goto value_start;
594: value_start:
595: 	/* state: value_start */
596: 	// this state parses the first characters of a value
597: 	offset = 0;
598: 	delimiter_pos = 0;
599: 	quote_pos = 0;
600: 	do {
601: 		idx_t count = 0;
602: 		for (; position < buffer_size; position++) {
603: 			quote_search.Match(quote_pos, buffer[position]);
604: 			delimiter_search.Match(delimiter_pos, buffer[position]);
605: 			count++;
606: 			if (delimiter_pos == options.delimiter.size()) {
607: 				// found a delimiter, add the value
608: 				offset = options.delimiter.size() - 1;
609: 				goto add_value;
610: 			} else if (is_newline(buffer[position])) {
611: 				// found a newline, add the row
612: 				goto add_row;
613: 			}
614: 			if (count > quote_pos) {
615: 				// did not find a quote directly at the start of the value, stop looking for the quote now
616: 				goto normal;
617: 			}
618: 			if (quote_pos == options.quote.size()) {
619: 				// found a quote, go to quoted loop and skip the initial quote
620: 				start += options.quote.size();
621: 				goto in_quotes;
622: 			}
623: 		}
624: 	} while (ReadBuffer(start));
625: 	// file ends while scanning for quote/delimiter, go to final state
626: 	goto final_state;
627: normal:
628: 	/* state: normal parsing state */
629: 	// this state parses the remainder of a non-quoted value until we reach a delimiter or newline
630: 	position++;
631: 	do {
632: 		for (; position < buffer_size; position++) {
633: 			delimiter_search.Match(delimiter_pos, buffer[position]);
634: 			if (delimiter_pos == options.delimiter.size()) {
635: 				offset = options.delimiter.size() - 1;
636: 				goto add_value;
637: 			} else if (is_newline(buffer[position])) {
638: 				goto add_row;
639: 			}
640: 		}
641: 	} while (ReadBuffer(start));
642: 	goto final_state;
643: add_value:
644: 	AddValue(buffer.get() + start, position - start - offset, column, escape_positions);
645: 	// increase position by 1 and move start to the new position
646: 	offset = 0;
647: 	start = ++position;
648: 	if (position >= buffer_size && !ReadBuffer(start)) {
649: 		// file ends right after delimiter, go to final state
650: 		goto final_state;
651: 	}
652: 	goto value_start;
653: add_row : {
654: 	// check type of newline (\r or \n)
655: 	bool carriage_return = buffer[position] == '\r';
656: 	AddValue(buffer.get() + start, position - start - offset, column, escape_positions);
657: 	finished_chunk = AddRow(insert_chunk, column);
658: 	// increase position by 1 and move start to the new position
659: 	offset = 0;
660: 	start = ++position;
661: 	if (position >= buffer_size && !ReadBuffer(start)) {
662: 		// file ends right after newline, go to final state
663: 		goto final_state;
664: 	}
665: 	if (carriage_return) {
666: 		// \r newline, go to special state that parses an optional \n afterwards
667: 		goto carriage_return;
668: 	} else {
669: 		// \n newline, move to value start
670: 		if (finished_chunk) {
671: 			return;
672: 		}
673: 		goto value_start;
674: 	}
675: }
676: in_quotes:
677: 	/* state: in_quotes */
678: 	// this state parses the remainder of a quoted value
679: 	quote_pos = 0;
680: 	escape_pos = 0;
681: 	position++;
682: 	do {
683: 		for (; position < buffer_size; position++) {
684: 			quote_search.Match(quote_pos, buffer[position]);
685: 			escape_search.Match(escape_pos, buffer[position]);
686: 			if (quote_pos == options.quote.size()) {
687: 				goto unquote;
688: 			} else if (escape_pos == options.escape.size()) {
689: 				escape_positions.push_back(position - start - (options.escape.size() - 1));
690: 				goto handle_escape;
691: 			}
692: 		}
693: 	} while (ReadBuffer(start));
694: 	// still in quoted state at the end of the file, error:
695: 	throw ParserException("Error on line %s: unterminated quotes", GetLineNumberStr(linenr, linenr_estimated).c_str());
696: unquote:
697: 	/* state: unquote */
698: 	// this state handles the state directly after we unquote
699: 	// in this state we expect either another quote (entering the quoted state again, and escaping the quote)
700: 	// or a delimiter/newline, ending the current value and moving on to the next value
701: 	delimiter_pos = 0;
702: 	quote_pos = 0;
703: 	position++;
704: 	if (position >= buffer_size && !ReadBuffer(start)) {
705: 		// file ends right after unquote, go to final state
706: 		offset = options.quote.size();
707: 		goto final_state;
708: 	}
709: 	if (is_newline(buffer[position])) {
710: 		// quote followed by newline, add row
711: 		offset = options.quote.size();
712: 		goto add_row;
713: 	}
714: 	do {
715: 		idx_t count = 0;
716: 		for (; position < buffer_size; position++) {
717: 			quote_search.Match(quote_pos, buffer[position]);
718: 			delimiter_search.Match(delimiter_pos, buffer[position]);
719: 			count++;
720: 			if (count > delimiter_pos && count > quote_pos) {
721: 				throw ParserException(
722: 					"Error on line %s: quote should be followed by end of value, end of row or another quote",
723: 					GetLineNumberStr(linenr, linenr_estimated).c_str());
724: 			}
725: 			if (delimiter_pos == options.delimiter.size()) {
726: 				// quote followed by delimiter, add value
727: 				offset = options.quote.size() + options.delimiter.size() - 1;
728: 				goto add_value;
729: 			} else if (quote_pos == options.quote.size() && (options.escape.size() == 0 || options.escape == options.quote)) {
730: 				// quote followed by quote, go back to quoted state and add to escape
731: 				escape_positions.push_back(position - start - (options.quote.size() - 1));
732: 				goto in_quotes;
733: 			}
734: 		}
735: 	} while (ReadBuffer(start));
736: 	throw ParserException("Error on line %s: quote should be followed by end of value, end of row or another quote",
737: 						  GetLineNumberStr(linenr, linenr_estimated).c_str());
738: handle_escape:
739: 	escape_pos = 0;
740: 	quote_pos = 0;
741: 	position++;
742: 	do {
743: 		idx_t count = 0;
744: 		for (; position < buffer_size; position++) {
745: 			quote_search.Match(quote_pos, buffer[position]);
746: 			escape_search.Match(escape_pos, buffer[position]);
747: 			count++;
748: 			if (count > escape_pos && count > quote_pos) {
749: 				throw ParserException("Error on line %s: neither QUOTE nor ESCAPE is proceeded by ESCAPE",
750: 									  GetLineNumberStr(linenr, linenr_estimated).c_str());
751: 			}
752: 			if (quote_pos == options.quote.size() || escape_pos == options.escape.size()) {
753: 				// found quote or escape: move back to quoted state
754: 				goto in_quotes;
755: 			}
756: 		}
757: 	} while (ReadBuffer(start));
758: 	throw ParserException("Error on line %s: neither QUOTE nor ESCAPE is proceeded by ESCAPE",
759: 						  GetLineNumberStr(linenr, linenr_estimated).c_str());
760: carriage_return:
761: 	/* state: carriage_return */
762: 	// this stage optionally skips a newline (\n) character, which allows \r\n to be interpreted as a single line
763: 	if (buffer[position] == '\n') {
764: 		// newline after carriage return: skip
765: 		start = ++position;
766: 		if (position >= buffer_size && !ReadBuffer(start)) {
767: 			// file ends right after newline, go to final state
768: 			goto final_state;
769: 		}
770: 	}
771: 	if (finished_chunk) {
772: 		return;
773: 	}
774: 	goto value_start;
775: final_state:
776: 	if (finished_chunk) {
777: 		return;
778: 	}
779: 	if (column > 0 || position > start) {
780: 		// remaining values to be added to the chunk
781: 		AddValue(buffer.get() + start, position - start - offset, column, escape_positions);
782: 		finished_chunk = AddRow(insert_chunk, column);
783: 	}
784: 	// final stage, only reached after parsing the file is finished
785: 	// flush the parsed chunk and finalize parsing
786: 	if (mode == ParserMode::PARSING) {
787: 		Flush(insert_chunk);
788: 	}
789: }
790: 
791: void BufferedCSVReader::ParseSimpleCSV(DataChunk &insert_chunk) {
792: 	// used for parsing algorithm
793: 	bool finished_chunk = false;
794: 	idx_t column = 0;
795: 	idx_t offset = 0;
796: 	vector<idx_t> escape_positions;
797: 
798: 	// read values into the buffer (if any)
799: 	if (position >= buffer_size) {
800: 		if (!ReadBuffer(start)) {
801: 			return;
802: 		}
803: 	}
804: 	// start parsing the first value
805: 	goto value_start;
806: value_start:
807: 	offset = 0;
808: 	/* state: value_start */
809: 	// this state parses the first character of a value
810: 	if (buffer[position] == options.quote[0]) {
811: 		// quote: actual value starts in the next position
812: 		// move to in_quotes state
813: 		start = position + 1;
814: 		goto in_quotes;
815: 	} else {
816: 		// no quote, move to normal parsing state
817: 		start = position;
818: 		goto normal;
819: 	}
820: normal:
821: 	/* state: normal parsing state */
822: 	// this state parses the remainder of a non-quoted value until we reach a delimiter or newline
823: 	do {
824: 		for (; position < buffer_size; position++) {
825: 			if (buffer[position] == options.delimiter[0]) {
826: 				// delimiter: end the value and add it to the chunk
827: 				goto add_value;
828: 			} else if (is_newline(buffer[position])) {
829: 				// newline: add row
830: 				goto add_row;
831: 			}
832: 		}
833: 	} while (ReadBuffer(start));
834: 	// file ends during normal scan: go to end state
835: 	goto final_state;
836: add_value:
837: 	AddValue(buffer.get() + start, position - start - offset, column, escape_positions);
838: 	// increase position by 1 and move start to the new position
839: 	offset = 0;
840: 	start = ++position;
841: 	if (position >= buffer_size && !ReadBuffer(start)) {
842: 		// file ends right after delimiter, go to final state
843: 		goto final_state;
844: 	}
845: 	goto value_start;
846: add_row : {
847: 	// check type of newline (\r or \n)
848: 	bool carriage_return = buffer[position] == '\r';
849: 	AddValue(buffer.get() + start, position - start - offset, column, escape_positions);
850: 	finished_chunk = AddRow(insert_chunk, column);
851: 	// increase position by 1 and move start to the new position
852: 	offset = 0;
853: 	start = ++position;
854: 	if (position >= buffer_size && !ReadBuffer(start)) {
855: 		// file ends right after delimiter, go to final state
856: 		goto final_state;
857: 	}
858: 	if (carriage_return) {
859: 		// \r newline, go to special state that parses an optional \n afterwards
860: 		goto carriage_return;
861: 	} else {
862: 		// \n newline, move to value start
863: 		if (finished_chunk) {
864: 			return;
865: 		}
866: 		goto value_start;
867: 	}
868: }
869: in_quotes:
870: 	/* state: in_quotes */
871: 	// this state parses the remainder of a quoted value
872: 	position++;
873: 	do {
874: 		for (; position < buffer_size; position++) {
875: 			if (buffer[position] == options.quote[0]) {
876: 				// quote: move to unquoted state
877: 				goto unquote;
878: 			} else if (buffer[position] == options.escape[0]) {
879: 				// escape: store the escaped position and move to handle_escape state
880: 				escape_positions.push_back(position - start);
881: 				goto handle_escape;
882: 			}
883: 		}
884: 	} while (ReadBuffer(start));
885: 	// still in quoted state at the end of the file, error:
886: 	throw ParserException("Error on line %s: unterminated quotes", GetLineNumberStr(linenr, linenr_estimated).c_str());
887: unquote:
888: 	/* state: unquote */
889: 	// this state handles the state directly after we unquote
890: 	// in this state we expect either another quote (entering the quoted state again, and escaping the quote)
891: 	// or a delimiter/newline, ending the current value and moving on to the next value
892: 	position++;
893: 	if (position >= buffer_size && !ReadBuffer(start)) {
894: 		// file ends right after unquote, go to final state
895: 		offset = 1;
896: 		goto final_state;
897: 	}
898: 	if (buffer[position] == options.quote[0] && (options.escape.size() == 0 || options.escape[0] == options.quote[0])) {
899: 		// escaped quote, return to quoted state and store escape position
900: 		escape_positions.push_back(position - start);
901: 		goto in_quotes;
902: 	} else if (buffer[position] == options.delimiter[0]) {
903: 		// delimiter, add value
904: 		offset = 1;
905: 		goto add_value;
906: 	} else if (is_newline(buffer[position])) {
907: 		offset = 1;
908: 		goto add_row;
909: 	} else {
910: 		throw ParserException("Error on line %s: quote should be followed by end of value, end of row or another quote",
911: 							  GetLineNumberStr(linenr, linenr_estimated).c_str());
912: 	}
913: handle_escape:
914: 	/* state: handle_escape */
915: 	// escape should be followed by a quote or another escape character
916: 	position++;
917: 	if (position >= buffer_size && !ReadBuffer(start)) {
918: 		throw ParserException("Error on line %s: neither QUOTE nor ESCAPE is proceeded by ESCAPE",
919: 							  GetLineNumberStr(linenr, linenr_estimated).c_str());
920: 	}
921: 	if (buffer[position] != options.quote[0] && buffer[position] != options.escape[0]) {
922: 		throw ParserException("Error on line %s: neither QUOTE nor ESCAPE is proceeded by ESCAPE",
923: 							  GetLineNumberStr(linenr, linenr_estimated).c_str());
924: 	}
925: 	// escape was followed by quote or escape, go back to quoted state
926: 	goto in_quotes;
927: carriage_return:
928: 	/* state: carriage_return */
929: 	// this stage optionally skips a newline (\n) character, which allows \r\n to be interpreted as a single line
930: 	if (buffer[position] == '\n') {
931: 		// newline after carriage return: skip
932: 		// increase position by 1 and move start to the new position
933: 		start = ++position;
934: 		if (position >= buffer_size && !ReadBuffer(start)) {
935: 			// file ends right after delimiter, go to final state
936: 			goto final_state;
937: 		}
938: 	}
939: 	if (finished_chunk) {
940: 		return;
941: 	}
942: 	goto value_start;
943: final_state:
944: 	if (finished_chunk) {
945: 		return;
946: 	}
947: 
948: 	if (column > 0 || position > start) {
949: 		// remaining values to be added to the chunk
950: 		AddValue(buffer.get() + start, position - start - offset, column, escape_positions);
951: 		finished_chunk = AddRow(insert_chunk, column);
952: 	}
953: 
954: 	// final stage, only reached after parsing the file is finished
955: 	// flush the parsed chunk and finalize parsing
956: 	if (mode == ParserMode::PARSING) {
957: 		Flush(insert_chunk);
958: 	}
959: }
960: 
961: bool BufferedCSVReader::ReadBuffer(idx_t &start) {
962: 	auto old_buffer = move(buffer);
963: 
964: 	// the remaining part of the last buffer
965: 	idx_t remaining = buffer_size - start;
966: 	idx_t buffer_read_size = INITIAL_BUFFER_SIZE;
967: 	while (remaining > buffer_read_size) {
968: 		buffer_read_size *= 2;
969: 	}
970: 	if (remaining + buffer_read_size > MAXIMUM_CSV_LINE_SIZE) {
971: 		throw ParserException("Maximum line size of %llu bytes exceeded!", MAXIMUM_CSV_LINE_SIZE);
972: 	}
973: 	buffer = unique_ptr<char[]>(new char[buffer_read_size + remaining + 1]);
974: 	buffer_size = remaining + buffer_read_size;
975: 	if (remaining > 0) {
976: 		// remaining from last buffer: copy it here
977: 		memcpy(buffer.get(), old_buffer.get() + start, remaining);
978: 	}
979: 	source->read(buffer.get() + remaining, buffer_read_size);
980: 
981: 	idx_t read_count = source->eof() ? source->gcount() : buffer_read_size;
982: 	bytes_in_chunk += read_count;
983: 	buffer_size = remaining + read_count;
984: 	buffer[buffer_size] = '\0';
985: 	if (old_buffer) {
986: 		cached_buffers.push_back(move(old_buffer));
987: 	}
988: 	start = 0;
989: 	position = remaining;
990: 
991: 	return read_count > 0;
992: }
993: 
994: void BufferedCSVReader::ParseCSV(DataChunk &insert_chunk) {
995: 	cached_buffers.clear();
996: 
997: 	ParseCSV(ParserMode::PARSING, insert_chunk);
998: }
999: 
1000: void BufferedCSVReader::ParseCSV(ParserMode parser_mode, DataChunk &insert_chunk) {
1001: 	mode = parser_mode;
1002: 
1003: 	if (options.quote.size() <= 1 && options.escape.size() <= 1 && options.delimiter.size() == 1) {
1004: 		ParseSimpleCSV(insert_chunk);
1005: 	} else {
1006: 		ParseComplexCSV(insert_chunk);
1007: 	}
1008: }
1009: 
1010: void BufferedCSVReader::AddValue(char *str_val, idx_t length, idx_t &column, vector<idx_t> &escape_positions) {
1011: 	if (sql_types.size() > 0 && column == sql_types.size() && length == 0) {
1012: 		// skip a single trailing delimiter in last column
1013: 		return;
1014: 	}
1015: 	if (mode == ParserMode::SNIFFING_DIALECT) {
1016: 		column++;
1017: 		return;
1018: 	}
1019: 	if (column >= sql_types.size()) {
1020: 		throw ParserException("Error on line %s: expected %lld values but got %d",
1021: 							  GetLineNumberStr(linenr, linenr_estimated).c_str(), sql_types.size(), column + 1);
1022: 	}
1023: 
1024: 	// insert the line number into the chunk
1025: 	idx_t row_entry = parse_chunk.size();
1026: 
1027: 	str_val[length] = '\0';
1028: 
1029: 	// test against null string
1030: 	if (!options.force_not_null[column] && strcmp(options.null_str.c_str(), str_val) == 0) {
1031: 		FlatVector::SetNull(parse_chunk.data[column], row_entry, true);
1032: 	} else {
1033: 		auto &v = parse_chunk.data[column];
1034: 		auto parse_data = FlatVector::GetData<string_t>(v);
1035: 		if (escape_positions.size() > 0) {
1036: 			// remove escape characters (if any)
1037: 			string old_val = str_val;
1038: 			string new_val = "";
1039: 			idx_t prev_pos = 0;
1040: 			for (idx_t i = 0; i < escape_positions.size(); i++) {
1041: 				idx_t next_pos = escape_positions[i];
1042: 				new_val += old_val.substr(prev_pos, next_pos - prev_pos);
1043: 
1044: 				if (options.escape.size() == 0 || options.escape == options.quote) {
1045: 					prev_pos = next_pos + options.quote.size();
1046: 				} else {
1047: 					prev_pos = next_pos + options.escape.size();
1048: 				}
1049: 			}
1050: 			new_val += old_val.substr(prev_pos, old_val.size() - prev_pos);
1051: 			escape_positions.clear();
1052: 			parse_data[row_entry] = StringVector::AddBlob(v, string_t(new_val));
1053: 		} else {
1054: 			parse_data[row_entry] = string_t(str_val, length);
1055: 		}
1056: 	}
1057: 
1058: 	// move to the next column
1059: 	column++;
1060: }
1061: 
1062: bool BufferedCSVReader::AddRow(DataChunk &insert_chunk, idx_t &column) {
1063: 	if (column < sql_types.size() && mode != ParserMode::SNIFFING_DIALECT) {
1064: 		throw ParserException("Error on line %s: expected %lld values but got %d",
1065: 							  GetLineNumberStr(linenr, linenr_estimated).c_str(), sql_types.size(), column);
1066: 	}
1067: 
1068: 	if (mode == ParserMode::SNIFFING_DIALECT) {
1069: 		sniffed_column_counts.push_back(column);
1070: 
1071: 		if (sniffed_column_counts.size() == SAMPLE_CHUNK_SIZE) {
1072: 			return true;
1073: 		}
1074: 	} else {
1075: 		parse_chunk.SetCardinality(parse_chunk.size() + 1);
1076: 	}
1077: 
1078: 	if (mode == ParserMode::SNIFFING_DATATYPES && parse_chunk.size() == SAMPLE_CHUNK_SIZE) {
1079: 		return true;
1080: 	}
1081: 
1082: 	if (mode == ParserMode::PARSING && parse_chunk.size() == STANDARD_VECTOR_SIZE) {
1083: 		Flush(insert_chunk);
1084: 		return true;
1085: 	}
1086: 
1087: 	column = 0;
1088: 	linenr++;
1089: 	return false;
1090: }
1091: 
1092: void BufferedCSVReader::Flush(DataChunk &insert_chunk) {
1093: 	if (parse_chunk.size() == 0) {
1094: 		return;
1095: 	}
1096: 	// convert the columns in the parsed chunk to the types of the table
1097: 	insert_chunk.SetCardinality(parse_chunk);
1098: 	for (idx_t col_idx = 0; col_idx < sql_types.size(); col_idx++) {
1099: 		if (sql_types[col_idx].id == SQLTypeId::VARCHAR) {
1100: 			// target type is varchar: no need to convert
1101: 			// just test that all strings are valid utf-8 strings
1102: 			auto parse_data = FlatVector::GetData<string_t>(parse_chunk.data[col_idx]);
1103: 			for (idx_t i = 0; i < parse_chunk.size(); i++) {
1104: 				if (!FlatVector::IsNull(parse_chunk.data[col_idx], i)) {
1105: 					auto s = parse_data[i];
1106: 					auto utf_type = Utf8Proc::Analyze(s.GetData(), s.GetSize());
1107: 					switch (utf_type) {
1108: 					case UnicodeType::INVALID:
1109: 						throw ParserException("Error on line %s: file is not valid UTF8",
1110: 											  GetLineNumberStr(linenr, linenr_estimated).c_str());
1111: 					case UnicodeType::ASCII:
1112: 						break;
1113: 					case UnicodeType::UNICODE: {
1114: 						auto normie = Utf8Proc::Normalize(s.GetData());
1115: 						parse_data[i] = StringVector::AddString(parse_chunk.data[col_idx], normie);
1116: 						free(normie);
1117: 						break;
1118: 					}
1119: 					}
1120: 				}
1121: 			}
1122: 			insert_chunk.data[col_idx].Reference(parse_chunk.data[col_idx]);
1123: 		} else if (options.has_date_format && sql_types[col_idx].id == SQLTypeId::DATE) {
1124: 			// use the date format to cast the chunk
1125: 			UnaryExecutor::Execute<string_t, date_t, true>(parse_chunk.data[col_idx], insert_chunk.data[col_idx], parse_chunk.size(), [&](string_t input) {
1126: 				return options.date_format.ParseDate(input);
1127: 			});
1128: 		} else if (options.has_timestamp_format && sql_types[col_idx].id == SQLTypeId::TIMESTAMP) {
1129: 			// use the date format to cast the chunk
1130: 			UnaryExecutor::Execute<string_t, timestamp_t, true>(parse_chunk.data[col_idx], insert_chunk.data[col_idx], parse_chunk.size(), [&](string_t input) {
1131: 				return options.timestamp_format.ParseTimestamp(input);
1132: 			});
1133: 		} else {
1134: 			// target type is not varchar: perform a cast
1135: 			VectorOperations::Cast(parse_chunk.data[col_idx], insert_chunk.data[col_idx], SQLType::VARCHAR,
1136: 								   sql_types[col_idx], parse_chunk.size());
1137: 		}
1138: 	}
1139: 	parse_chunk.Reset();
1140: }
1141: 
1142: }
[end of src/execution/operator/persistent/buffered_csv_reader.cpp]
[start of src/function/scalar/date/strftime.cpp]
1: #include "duckdb/function/scalar/date_functions.hpp"
2: 
3: #include "duckdb/planner/expression/bound_function_expression.hpp"
4: 
5: #include "duckdb/common/types/date.hpp"
6: #include "duckdb/common/types/time.hpp"
7: #include "duckdb/common/types/timestamp.hpp"
8: #include "duckdb/common/types/numeric_helper.hpp"
9: 
10: #include "duckdb/function/scalar/strftime.hpp"
11: 
12: #include "duckdb/common/vector_operations/unary_executor.hpp"
13: 
14: #include "duckdb/execution/expression_executor.hpp"
15: 
16: #include "re2/re2.h"
17: 
18: namespace duckdb {
19: 
20: idx_t StrfTimepecifierSize(StrTimeSpecifier specifier) {
21: 	switch(specifier) {
22: 	case StrTimeSpecifier::ABBREVIATED_WEEKDAY_NAME:
23: 	case StrTimeSpecifier::ABBREVIATED_MONTH_NAME:
24: 		return 3;
25: 	case StrTimeSpecifier::WEEKDAY_DECIMAL:
26: 		return 1;
27: 	case StrTimeSpecifier::DAY_OF_MONTH_PADDED:
28: 	case StrTimeSpecifier::MONTH_DECIMAL_PADDED:
29: 	case StrTimeSpecifier::YEAR_WITHOUT_CENTURY_PADDED:
30: 	case StrTimeSpecifier::HOUR_24_PADDED:
31: 	case StrTimeSpecifier::HOUR_12_PADDED:
32: 	case StrTimeSpecifier::MINUTE_PADDED:
33: 	case StrTimeSpecifier::SECOND_PADDED:
34: 	case StrTimeSpecifier::AM_PM:
35: 	case StrTimeSpecifier::WEEK_NUMBER_PADDED_SUN_FIRST:
36: 	case StrTimeSpecifier::WEEK_NUMBER_PADDED_MON_FIRST:
37: 		return 2;
38: 	case StrTimeSpecifier::MICROSECOND_PADDED:
39: 		return 6;
40: 	case StrTimeSpecifier::DAY_OF_YEAR_PADDED:
41: 		return 3;
42: 	default:
43: 		return 0;
44: 	}
45: }
46: 
47: void StrTimeFormat::AddLiteral(string literal) {
48: 	constant_size += literal.size();
49: 	literals.push_back(move(literal));
50: }
51: 
52: void StrTimeFormat::AddFormatSpecifier(string preceding_literal, StrTimeSpecifier specifier) {
53: 	AddLiteral(move(preceding_literal));
54: 	specifiers.push_back(specifier);
55: }
56: 
57: 
58: void StrfTimeFormat::AddFormatSpecifier(string preceding_literal, StrTimeSpecifier specifier) {
59: 	is_date_specifier.push_back(IsDateSpecifier(specifier));
60: 	idx_t specifier_size = StrfTimepecifierSize(specifier);
61: 	if (specifier_size == 0) {
62: 		// variable length specifier
63: 		var_length_specifiers.push_back(specifier);
64: 	} else {
65: 		// constant size specifier
66: 		constant_size += specifier_size;
67: 	}
68: 	StrTimeFormat::AddFormatSpecifier(move(preceding_literal), specifier);
69: }
70: 
71: idx_t StrfTimeFormat::GetSpecifierLength(StrTimeSpecifier specifier, date_t date, time_t time) {
72: 	switch(specifier) {
73: 	case StrTimeSpecifier::FULL_WEEKDAY_NAME:
74: 		return Date::DayNames[Date::ExtractISODayOfTheWeek(date) % 7].GetSize();
75: 	case StrTimeSpecifier::FULL_MONTH_NAME:
76: 		return Date::MonthNames[Date::ExtractMonth(date) - 1].GetSize();
77: 	case StrTimeSpecifier::YEAR_DECIMAL: {
78: 		auto year = Date::ExtractYear(date);
79: 		return NumericHelper::SignedLength<int32_t, uint32_t>(year);
80: 	}
81: 	case StrTimeSpecifier::MONTH_DECIMAL: {
82: 		idx_t len = 1;
83: 		auto month = Date::ExtractMonth(date);
84: 		len += month >= 10;
85: 		return len;
86: 	}
87: 	case StrTimeSpecifier::UTC_OFFSET:
88: 	case StrTimeSpecifier::TZ_NAME:
89: 		// empty for now
90: 		return 0;
91: 	case StrTimeSpecifier::HOUR_24_DECIMAL:
92: 	case StrTimeSpecifier::HOUR_12_DECIMAL:
93: 	case StrTimeSpecifier::MINUTE_DECIMAL:
94: 	case StrTimeSpecifier::SECOND_DECIMAL: {
95: 		// time specifiers
96: 		idx_t len = 1;
97: 		int32_t hour, min, sec, msec;
98: 		Time::Convert(time, hour, min, sec, msec);
99: 		switch(specifier) {
100: 		case StrTimeSpecifier::HOUR_24_DECIMAL:
101: 			len += hour >= 10;
102: 			break;
103: 		case StrTimeSpecifier::HOUR_12_DECIMAL:
104: 			hour = hour % 12;
105: 			if (hour == 0) {
106: 				hour = 12;
107: 			}
108: 			len += hour >= 10;
109: 			break;
110: 		case StrTimeSpecifier::MINUTE_DECIMAL:
111: 			len += min >= 10;
112: 			break;
113: 		case StrTimeSpecifier::SECOND_DECIMAL:
114: 			len += sec >= 10;
115: 			break;
116: 		default:
117: 			break;
118: 		}
119: 		return len;
120: 	}
121: 	case StrTimeSpecifier::DAY_OF_MONTH:
122: 		return NumericHelper::UnsignedLength<uint32_t>(Date::ExtractDay(date));
123: 	case StrTimeSpecifier::DAY_OF_YEAR_DECIMAL:
124: 		return NumericHelper::UnsignedLength<uint32_t>(Date::ExtractDayOfTheYear(date));
125: 	case StrTimeSpecifier::YEAR_WITHOUT_CENTURY:
126: 		return NumericHelper::UnsignedLength<uint32_t>(Date::ExtractYear(date) % 100);
127: 	default:
128: 		throw NotImplementedException("Unimplemented specifier for GetSpecifierLength");
129: 	}
130: }
131: 
132: //! Returns the total length of the date formatted by this format specifier
133: idx_t StrfTimeFormat::GetLength(date_t date, time_t time) {
134: 	idx_t size = constant_size;
135: 	if (var_length_specifiers.size() > 0) {
136: 		for(auto &specifier : var_length_specifiers) {
137: 			size += GetSpecifierLength(specifier, date, time);
138: 		}
139: 	}
140: 	return size;
141: }
142: 
143: char* StrfTimeFormat::WriteString(char *target, string_t &str) {
144: 	idx_t size = str.GetSize();
145: 	memcpy(target, str.GetData(), str.GetSize());
146: 	return target + size;
147: }
148: 
149: // write a value in the range of 0..99 unpadded (e.g. "1", "2", ... "98", "99")
150: char *StrfTimeFormat::Write2(char *target, uint8_t value) {
151: 	if (value >= 10) {
152: 		return WritePadded2(target, value);
153: 	} else {
154: 		*target = '0' + value;
155: 		return target + 1;
156: 	}
157: }
158: 
159: // write a value in the range of 0..99 padded to 2 digits
160: char* StrfTimeFormat::WritePadded2(char *target, int32_t value) {
161: 	auto index = static_cast<unsigned>(value * 2);
162: 	*target++ = duckdb_fmt::internal::data::digits[index];
163: 	*target++ = duckdb_fmt::internal::data::digits[index + 1];
164: 	return target;
165: }
166: 
167: // write a value in the range of 0..999 padded
168: char *StrfTimeFormat::WritePadded3(char *target, uint32_t value) {
169: 	if (value >= 100) {
170: 		WritePadded2(target + 1, value % 100);
171: 		*target = '0' + value / 100;
172: 		return target + 3;
173: 	} else {
174: 		*target = '0';
175: 		target++;
176: 		return WritePadded2(target, value);
177: 	}
178: }
179: 
180: // write a value in the range of 0..999999 padded to 6 digits
181: char* StrfTimeFormat::WritePadded(char *target, int32_t value, int32_t padding) {
182: 	assert(padding % 2 == 0);
183: 	for(int i = 0; i < padding / 2; i++) {
184: 		int decimals = value % 100;
185: 		WritePadded2(target + padding - 2 * (i + 1), decimals);
186: 		value /= 100;
187: 	}
188: 	return target + padding;
189: }
190: 
191: bool StrfTimeFormat::IsDateSpecifier(StrTimeSpecifier specifier) {
192: 	switch(specifier) {
193: 	case StrTimeSpecifier::ABBREVIATED_WEEKDAY_NAME:
194: 	case StrTimeSpecifier::FULL_WEEKDAY_NAME:
195: 	case StrTimeSpecifier::WEEKDAY_DECIMAL:
196: 	case StrTimeSpecifier::DAY_OF_YEAR_PADDED:
197: 	case StrTimeSpecifier::WEEK_NUMBER_PADDED_MON_FIRST:
198: 	case StrTimeSpecifier::WEEK_NUMBER_PADDED_SUN_FIRST:
199: 	case StrTimeSpecifier::DAY_OF_YEAR_DECIMAL:
200: 		return true;
201: 	default:
202: 		return false;
203: 	}
204: }
205: 
206: char* StrfTimeFormat::WriteDateSpecifier(StrTimeSpecifier specifier, date_t date, char *target) {
207: 	switch(specifier) {
208: 	case StrTimeSpecifier::ABBREVIATED_WEEKDAY_NAME: {
209: 		date_t dow = Date::ExtractISODayOfTheWeek(date);
210: 		target = WriteString(target, Date::DayNamesAbbreviated[dow % 7]);
211: 		break;
212: 	}
213: 	case StrTimeSpecifier::FULL_WEEKDAY_NAME: {
214: 		date_t dow = Date::ExtractISODayOfTheWeek(date);
215: 		target = WriteString(target, Date::DayNames[dow % 7]);
216: 		break;
217: 	}
218: 	case StrTimeSpecifier::WEEKDAY_DECIMAL: {
219: 		date_t dow = Date::ExtractISODayOfTheWeek(date);
220: 		*target = '0' + (dow % 7);
221: 		target++;
222: 		break;
223: 	}
224: 	case StrTimeSpecifier::DAY_OF_YEAR_PADDED: {
225: 		int32_t doy = Date::ExtractDayOfTheYear(date);
226: 		target = WritePadded3(target, doy);
227: 		break;
228: 	}
229: 	case StrTimeSpecifier::WEEK_NUMBER_PADDED_MON_FIRST:
230: 		target = WritePadded2(target, Date::ExtractWeekNumberRegular(date, true));
231: 		break;
232: 	case StrTimeSpecifier::WEEK_NUMBER_PADDED_SUN_FIRST:
233: 		target = WritePadded2(target, Date::ExtractWeekNumberRegular(date, false));
234: 		break;
235: 	case StrTimeSpecifier::DAY_OF_YEAR_DECIMAL: {
236: 		uint32_t doy = Date::ExtractDayOfTheYear(date);
237: 		target += NumericHelper::UnsignedLength<uint32_t>(doy);
238: 		NumericHelper::FormatUnsigned(doy, target);
239: 		break;
240: 	}
241: 	default:
242: 		throw NotImplementedException("Unimplemented date specifier for strftime");
243: 	}
244: 	return target;
245: }
246: 
247: char* StrfTimeFormat::WriteStandardSpecifier(StrTimeSpecifier specifier, int32_t data[], char *target) {
248: 	// data contains [0] year, [1] month, [2] day, [3] hour, [4] minute, [5] second, [6] msec
249: 	switch(specifier) {
250: 	case StrTimeSpecifier::DAY_OF_MONTH_PADDED:
251: 		target = WritePadded2(target, data[2]);
252: 		break;
253: 	case StrTimeSpecifier::ABBREVIATED_MONTH_NAME: {
254: 		auto &month_name = Date::MonthNamesAbbreviated[data[1] - 1];
255: 		return WriteString(target, month_name);
256: 	}
257: 	case StrTimeSpecifier::FULL_MONTH_NAME: {
258: 		auto &month_name = Date::MonthNames[data[1] - 1];
259: 		return WriteString(target, month_name);
260: 	}
261: 	case StrTimeSpecifier::MONTH_DECIMAL_PADDED:
262: 		target = WritePadded2(target, data[1]);
263: 		break;
264: 	case StrTimeSpecifier::YEAR_WITHOUT_CENTURY_PADDED:
265: 		target = WritePadded2(target, data[0] % 100);
266: 		break;
267: 	case StrTimeSpecifier::YEAR_DECIMAL:
268: 		if (data[0] >= 0 && data[0] <= 9999) {
269: 			target = WritePadded(target, data[0], 4);
270: 		} else {
271: 			int32_t year = data[0];
272: 			if (data[0] < 0) {
273: 				*target = '-';
274: 				year = -year;
275: 				target++;
276: 			}
277: 			auto len = NumericHelper::UnsignedLength<uint32_t>(year);
278: 			NumericHelper::FormatUnsigned(year, target + len);
279: 			target += len;
280: 		}
281: 		break;
282: 	case StrTimeSpecifier::HOUR_24_PADDED: {
283: 		target = WritePadded2(target, data[3]);
284: 		break;
285: 	}
286: 	case StrTimeSpecifier::HOUR_12_PADDED: {
287: 		int hour = data[3] % 12;
288: 		if (hour == 0) {
289: 			hour = 12;
290: 		}
291: 		target = WritePadded2(target, hour);
292: 		break;
293: 	}
294: 	case StrTimeSpecifier::AM_PM:
295: 		*target++ = data[3] >= 12 ? 'P' : 'A';
296: 		*target++ = 'M';
297: 		break;
298: 	case StrTimeSpecifier::MINUTE_PADDED: {
299: 		target = WritePadded2(target, data[4]);
300: 		break;
301: 	}
302: 	case StrTimeSpecifier::SECOND_PADDED:
303: 		target = WritePadded2(target, data[5]);
304: 		break;
305: 	case StrTimeSpecifier::MICROSECOND_PADDED:
306: 		target = WritePadded(target, data[6] * 1000, 6);
307: 		break;
308: 	case StrTimeSpecifier::UTC_OFFSET:
309: 	case StrTimeSpecifier::TZ_NAME:
310: 		// always empty for now, FIXME when we have timestamp with tz
311: 		break;
312: 	case StrTimeSpecifier::DAY_OF_MONTH: {
313: 		target = Write2(target, data[2] % 100);
314: 		break;
315: 	}
316: 	case StrTimeSpecifier::MONTH_DECIMAL: {
317: 		target = Write2(target, data[1]);
318: 		break;
319: 	}
320: 	case StrTimeSpecifier::YEAR_WITHOUT_CENTURY: {
321: 		target = Write2(target, data[0] % 100);
322: 		break;
323: 	}
324: 	case StrTimeSpecifier::HOUR_24_DECIMAL: {
325: 		target = Write2(target, data[3]);
326: 		break;
327: 	}
328: 	case StrTimeSpecifier::HOUR_12_DECIMAL: {
329: 		int hour = data[3] % 12;
330: 		if (hour == 0) {
331: 			hour = 12;
332: 		}
333: 		target = Write2(target, hour);
334: 		break;
335: 	}
336: 	case StrTimeSpecifier::MINUTE_DECIMAL: {
337: 		target = Write2(target, data[4]);
338: 		break;
339: 	}
340: 	case StrTimeSpecifier::SECOND_DECIMAL: {
341: 		target = Write2(target, data[5]);
342: 		break;
343: 	}
344: 	default:
345: 		throw NotImplementedException("Unimplemented specifier for WriteStandardSpecifier in strftime");
346: 	}
347: 	return target;
348: }
349: 
350: void StrfTimeFormat::FormatString(date_t date, int32_t data[7], char *target) {
351: 	idx_t i;
352: 	for(i = 0; i < specifiers.size(); i++) {
353: 		// first copy the current literal
354: 		memcpy(target, literals[i].c_str(), literals[i].size());
355: 		target += literals[i].size();
356: 		// now copy the specifier
357: 		if (is_date_specifier[i]) {
358: 			target = WriteDateSpecifier(specifiers[i], date, target);
359: 		} else {
360: 			target = WriteStandardSpecifier(specifiers[i], data, target);
361: 		}
362: 	}
363: 	// copy the final literal into the target
364: 	memcpy(target, literals[i].c_str(), literals[i].size());
365: 
366: }
367: 
368: void StrfTimeFormat::FormatString(date_t date, time_t time, char *target) {
369: 	int32_t data[7]; // year, month, day, hour, min, sec, msec
370: 	Date::Convert(date, data[0], data[1], data[2]);
371: 	Time::Convert(time, data[3], data[4], data[5], data[6]);
372: 
373: 	FormatString(date, data, target);
374: }
375: 
376: string StrTimeFormat::ParseFormatSpecifier(string format_string, StrTimeFormat &format) {
377: 	format.constant_size = 0;
378: 	idx_t pos = 0;
379: 	string current_literal;
380: 	for(idx_t i = 0; i < format_string.size(); i++) {
381: 		if (format_string[i] == '%') {
382: 			if (i + 1 == format_string.size()) {
383: 				return "Trailing format character %";
384: 			}
385: 			if (i > pos) {
386: 				// push the previous string to the current literal
387: 				current_literal += format_string.substr(pos, i - pos);
388: 			}
389: 			char format_char = format_string[++i];
390: 			if (format_char == '%') {
391: 				// special case: %%
392: 				// set the pos for the next literal and continue
393: 				pos = i;
394: 				continue;
395: 			}
396: 			StrTimeSpecifier specifier;
397: 			if (format_char == '-' && i + 1 < format_string.size()) {
398: 				format_char = format_string[++i];
399: 				switch(format_char) {
400: 				case 'd':
401: 					specifier = StrTimeSpecifier::DAY_OF_MONTH;
402: 					break;
403: 				case 'm':
404: 					specifier = StrTimeSpecifier::MONTH_DECIMAL;
405: 					break;
406: 				case 'y':
407: 					specifier = StrTimeSpecifier::YEAR_WITHOUT_CENTURY;
408: 					break;
409: 				case 'H':
410: 					specifier = StrTimeSpecifier::HOUR_24_DECIMAL;
411: 					break;
412: 				case 'I':
413: 					specifier = StrTimeSpecifier::HOUR_12_DECIMAL;
414: 					break;
415: 				case 'M':
416: 					specifier = StrTimeSpecifier::MINUTE_DECIMAL;
417: 					break;
418: 				case 'S':
419: 					specifier = StrTimeSpecifier::SECOND_DECIMAL;
420: 					break;
421: 				case 'j':
422: 					specifier = StrTimeSpecifier::DAY_OF_YEAR_DECIMAL;
423: 					break;
424: 				default:
425: 					return "Unrecognized format for strftime/strptime: %-" + string(format_char, 1);
426: 				}
427: 			} else {
428: 				switch(format_char) {
429: 				case 'a':
430: 					specifier = StrTimeSpecifier::ABBREVIATED_WEEKDAY_NAME;
431: 					break;
432: 				case 'A':
433: 					specifier = StrTimeSpecifier::FULL_WEEKDAY_NAME;
434: 					break;
435: 				case 'w':
436: 					specifier = StrTimeSpecifier::WEEKDAY_DECIMAL;
437: 					break;
438: 				case 'd':
439: 					specifier = StrTimeSpecifier::DAY_OF_MONTH_PADDED;
440: 					break;
441: 				case 'h':
442: 				case 'b':
443: 					specifier = StrTimeSpecifier::ABBREVIATED_MONTH_NAME;
444: 					break;
445: 				case 'B':
446: 					specifier = StrTimeSpecifier::FULL_MONTH_NAME;
447: 					break;
448: 				case 'm':
449: 					specifier = StrTimeSpecifier::MONTH_DECIMAL_PADDED;
450: 					break;
451: 				case 'y':
452: 					specifier = StrTimeSpecifier::YEAR_WITHOUT_CENTURY_PADDED;
453: 					break;
454: 				case 'Y':
455: 					specifier = StrTimeSpecifier::YEAR_DECIMAL;
456: 					break;
457: 				case 'H':
458: 					specifier = StrTimeSpecifier::HOUR_24_PADDED;
459: 					break;
460: 				case 'I':
461: 					specifier = StrTimeSpecifier::HOUR_12_PADDED;
462: 					break;
463: 				case 'p':
464: 					specifier = StrTimeSpecifier::AM_PM;
465: 					break;
466: 				case 'M':
467: 					specifier = StrTimeSpecifier::MINUTE_PADDED;
468: 					break;
469: 				case 'S':
470: 					specifier = StrTimeSpecifier::SECOND_PADDED;
471: 					break;
472: 				case 'f':
473: 					specifier = StrTimeSpecifier::MICROSECOND_PADDED;
474: 					break;
475: 				case 'z':
476: 					specifier = StrTimeSpecifier::UTC_OFFSET;
477: 					break;
478: 				case 'Z':
479: 					specifier = StrTimeSpecifier::TZ_NAME;
480: 					break;
481: 				case 'j':
482: 					specifier = StrTimeSpecifier::DAY_OF_YEAR_PADDED;
483: 					break;
484: 				case 'U':
485: 					specifier = StrTimeSpecifier::WEEK_NUMBER_PADDED_SUN_FIRST;
486: 					break;
487: 				case 'W':
488: 					specifier = StrTimeSpecifier::WEEK_NUMBER_PADDED_MON_FIRST;
489: 					break;
490: 				case 'c':
491: 				case 'x':
492: 				case 'X': {
493: 					string subformat;
494: 					if (format_char == 'c') {
495: 						// %c: Locales appropriate date and time representation.
496: 						// we push the ISO timestamp representation here
497: 						subformat = "%Y-%m-%d %H:%M:%S";
498: 					} else if (format_char == 'x') {
499: 						// %x - Locales appropriate date representation.
500: 						// we push the ISO date format here
501: 						subformat = "%Y-%m-%d";
502: 					} else if (format_char == 'X') {
503: 						// %X - Locales appropriate time representation.
504: 						// we push the ISO time format here
505: 						subformat = "%H:%M:%S";
506: 					}
507: 					// parse the subformat in a separate format specifier
508: 					StrfTimeFormat locale_format;
509: 					string error = StrTimeFormat::ParseFormatSpecifier(subformat, locale_format);
510: 					assert(error.empty());
511: 					// add the previous literal to the first literal of the subformat
512: 					locale_format.literals[0] = move(current_literal) + locale_format.literals[0];
513: 					// now push the subformat into the current format specifier
514: 					for(idx_t i = 0; i < locale_format.specifiers.size(); i++) {
515: 						format.AddFormatSpecifier(move(locale_format.literals[i]), locale_format.specifiers[i]);
516: 					}
517: 					pos = i + 1;
518: 					continue;
519: 				}
520: 				default:
521: 					return "Unrecognized format for strftime/strptime: %" + string(format_char, 1);
522: 				}
523: 			}
524: 			format.AddFormatSpecifier(move(current_literal), specifier);
525: 			pos = i + 1;
526: 		}
527: 	}
528: 	// add the final literal
529: 	if (pos < format_string.size()) {
530: 		current_literal += format_string.substr(pos, format_string.size() - pos);
531: 	}
532: 	format.AddLiteral(move(current_literal));
533: 	return string();
534: }
535: 
536: struct StrfTimeBindData : public FunctionData {
537: 	StrfTimeBindData(StrfTimeFormat format) : format(move(format)) {}
538: 
539: 	StrfTimeFormat format;
540: 
541: 	unique_ptr<FunctionData> Copy() override {
542: 		return make_unique<StrfTimeBindData>(format);
543: 	}
544: };
545: 
546: static unique_ptr<FunctionData> strftime_bind_function(BoundFunctionExpression &expr, ClientContext &context) {
547: 	if (!expr.children[1]->IsScalar()) {
548: 		throw InvalidInputException("strftime format must be a constant");
549: 	}
550: 	Value options_str = ExpressionExecutor::EvaluateScalar(*expr.children[1]);
551: 	StrfTimeFormat format;
552: 	if (!options_str.is_null && options_str.type == TypeId::VARCHAR) {
553: 		string error = StrTimeFormat::ParseFormatSpecifier(options_str.str_value, format);
554: 		if (!error.empty()) {
555: 			throw InvalidInputException("Failed to parse format specifier %s: %s", options_str.str_value.c_str(), error.c_str());
556: 		}
557: 	}
558: 	return make_unique<StrfTimeBindData>(format);
559: }
560: 
561: static void strftime_function_date(DataChunk &args, ExpressionState &state, Vector &result) {
562: 	auto &func_expr = (BoundFunctionExpression &)state.expr;
563: 	auto &info = (StrfTimeBindData &)*func_expr.bind_info;
564: 
565: 	if (ConstantVector::IsNull(args.data[1])) {
566: 		result.vector_type = VectorType::CONSTANT_VECTOR;
567: 		ConstantVector::SetNull(result, true);
568: 		return;
569: 	}
570: 
571: 	time_t time = 0;
572: 	UnaryExecutor::Execute<date_t, string_t, true>(args.data[0], result, args.size(), [&](date_t date) {
573: 		idx_t len = info.format.GetLength(date, time);
574: 		string_t target = StringVector::EmptyString(result, len);
575: 		info.format.FormatString(date, time, target.GetData());
576: 		target.Finalize();
577: 		return target;
578: 	});
579: }
580: 
581: static void strftime_function_timestamp(DataChunk &args, ExpressionState &state, Vector &result) {
582: 	auto &func_expr = (BoundFunctionExpression &)state.expr;
583: 	auto &info = (StrfTimeBindData &)*func_expr.bind_info;
584: 
585: 	if (ConstantVector::IsNull(args.data[1])) {
586: 		result.vector_type = VectorType::CONSTANT_VECTOR;
587: 		ConstantVector::SetNull(result, true);
588: 		return;
589: 	}
590: 
591: 	UnaryExecutor::Execute<timestamp_t, string_t, true>(args.data[0], result, args.size(), [&](timestamp_t timestamp) {
592: 		date_t date;
593: 		dtime_t time;
594: 		Timestamp::Convert(timestamp, date, time);
595: 		idx_t len = info.format.GetLength(date, time);
596: 		string_t target = StringVector::EmptyString(result, len);
597: 		info.format.FormatString(date, time, target.GetData());
598: 		target.Finalize();
599: 		return target;
600: 	});
601: }
602: 
603: void StrfTimeFun::RegisterFunction(BuiltinFunctions &set) {
604: 	ScalarFunctionSet strftime("strftime");
605: 
606: 	strftime.AddFunction(ScalarFunction({SQLType::DATE, SQLType::VARCHAR}, SQLType::VARCHAR,
607: 	                               strftime_function_date, false, strftime_bind_function));
608: 
609: 	strftime.AddFunction(ScalarFunction({SQLType::TIMESTAMP, SQLType::VARCHAR}, SQLType::VARCHAR,
610: 	                               strftime_function_timestamp, false, strftime_bind_function));
611: 
612: 	set.AddFunction(strftime);
613: }
614: 
615: void StrpTimeFormat::AddFormatSpecifier(string preceding_literal, StrTimeSpecifier specifier) {
616: 	switch(specifier) {
617: 	case StrTimeSpecifier::DAY_OF_YEAR_PADDED:
618: 	case StrTimeSpecifier::DAY_OF_YEAR_DECIMAL:
619: 	case StrTimeSpecifier::WEEKDAY_DECIMAL:
620: 	case StrTimeSpecifier::WEEK_NUMBER_PADDED_SUN_FIRST:
621: 	case StrTimeSpecifier::WEEK_NUMBER_PADDED_MON_FIRST:
622: 		throw NotImplementedException("Unimplemented specifier for strptime");
623: 	default:
624: 		break;
625: 	}
626: 	is_numeric.push_back(IsNumericSpecifier(specifier));
627: 	StrTimeFormat::AddFormatSpecifier(move(preceding_literal), specifier);
628: }
629: 
630: bool StrpTimeFormat::IsNumericSpecifier(StrTimeSpecifier specifier) {
631: 	switch(specifier) {
632: 	case StrTimeSpecifier::WEEKDAY_DECIMAL:
633: 	case StrTimeSpecifier::DAY_OF_MONTH_PADDED:
634: 	case StrTimeSpecifier::DAY_OF_MONTH:
635: 	case StrTimeSpecifier::MONTH_DECIMAL_PADDED:
636: 	case StrTimeSpecifier::MONTH_DECIMAL:
637: 	case StrTimeSpecifier::YEAR_WITHOUT_CENTURY_PADDED:
638: 	case StrTimeSpecifier::YEAR_WITHOUT_CENTURY:
639: 	case StrTimeSpecifier::YEAR_DECIMAL:
640: 	case StrTimeSpecifier::HOUR_24_PADDED:
641: 	case StrTimeSpecifier::HOUR_24_DECIMAL:
642: 	case StrTimeSpecifier::HOUR_12_PADDED:
643: 	case StrTimeSpecifier::HOUR_12_DECIMAL:
644: 	case StrTimeSpecifier::MINUTE_PADDED:
645: 	case StrTimeSpecifier::MINUTE_DECIMAL:
646: 	case StrTimeSpecifier::SECOND_PADDED:
647: 	case StrTimeSpecifier::SECOND_DECIMAL:
648: 	case StrTimeSpecifier::MICROSECOND_PADDED:
649: 	case StrTimeSpecifier::DAY_OF_YEAR_PADDED:
650: 	case StrTimeSpecifier::DAY_OF_YEAR_DECIMAL:
651: 	case StrTimeSpecifier::WEEK_NUMBER_PADDED_SUN_FIRST:
652: 	case StrTimeSpecifier::WEEK_NUMBER_PADDED_MON_FIRST:
653: 		return true;
654: 	default:
655: 		return false;
656: 	}
657: }
658: 
659: enum class TimeSpecifierAMOrPM : uint8_t {
660: 	TIME_SPECIFIER_NONE = 0,
661: 	TIME_SPECIFIER_AM = 1,
662: 	TIME_SPECIFIER_PM = 2
663: };
664: 
665: int32_t StrpTimeFormat::TryParseCollection(const char *data, idx_t &pos, idx_t size, string_t collection[], idx_t collection_count) {
666: 	for(idx_t c = 0; c < collection_count; c++) {
667: 		auto &entry = collection[c];
668: 		auto entry_data = entry.GetData();
669: 		auto entry_size = entry.GetSize();
670: 		// check if this entry matches
671: 		if (pos + entry_size > size) {
672: 			// too big: can't match
673: 			continue;
674: 		}
675: 		// compare the characters
676: 		idx_t i;
677: 		for(i = 0; i < entry_size; i++) {
678: 			if (std::tolower(entry_data[i]) != std::tolower(data[pos + i])) {
679: 				break;
680: 			}
681: 		}
682: 		if (i == entry_size) {
683: 			// full match
684: 			pos += entry_size;
685: 			return c;
686: 		}
687: 	}
688: 	return -1;
689: }
690: 
691: //! Parses a timestamp using the given specifier
692: bool StrpTimeFormat::Parse(string_t str, int32_t result_data[], string &error_message, idx_t &error_position) {
693: 	// initialize the result
694: 	result_data[0] = 1900;
695: 	result_data[1] = 1;
696: 	result_data[2] = 1;
697: 	result_data[3] = 0;
698: 	result_data[4] = 0;
699: 	result_data[5] = 0;
700: 	result_data[6] = 0;
701: 
702: 	auto data = str.GetData();
703: 	idx_t size = str.GetSize();
704: 	// skip leading spaces
705: 	while(std::isspace(*data)) {
706: 		data++;
707: 		size--;
708: 	}
709: 	idx_t pos = 0;
710: 	TimeSpecifierAMOrPM ampm = TimeSpecifierAMOrPM::TIME_SPECIFIER_NONE;
711: 
712: 	for(idx_t i = 0; ; i++) {
713: 		// first compare the literal
714: 		if (literals[i].size() > (size - pos) || memcmp(data + pos, literals[i].c_str(), literals[i].size()) != 0) {
715: 			// literal does not match
716: 			error_message = "Literal does not match, expected " + literals[i];
717: 			error_position = pos;
718: 			return false;
719: 		}
720: 		pos += literals[i].size();
721: 		if (i == specifiers.size()) {
722: 			break;
723: 		}
724: 		// now parse the specifier
725: 		if (is_numeric[i]) {
726: 			// numeric specifier: parse a number
727: 			uint64_t number = 0;
728: 			size_t start_pos = pos;
729: 			while(pos < size && std::isdigit(data[pos])) {
730: 				if (number > 1000000ULL) {
731: 					// no number bigger than this is required anywhere
732: 					error_message = "Number is out of range of format specifier";
733: 					error_position = start_pos;
734: 					return false;
735: 				}
736: 				number = number * 10 + data[pos] - '0';
737: 				pos++;
738: 			}
739: 			if (pos == start_pos) {
740: 				// expected a number here
741: 				error_message = "Expected a number";
742: 				error_position = start_pos;
743: 				return false;
744: 			}
745: 			switch(specifiers[i]) {
746: 			case StrTimeSpecifier::DAY_OF_MONTH_PADDED:
747: 			case StrTimeSpecifier::DAY_OF_MONTH:
748: 				if (number < 1 || number > 31) {
749: 					error_message = "Day out of range, expected a value between 1 and 31";
750: 					error_position = start_pos;
751: 					return false;
752: 				}
753: 				// day of the month
754: 				result_data[2] = number;
755: 				break;
756: 			case StrTimeSpecifier::MONTH_DECIMAL_PADDED:
757: 			case StrTimeSpecifier::MONTH_DECIMAL:
758: 				if (number < 1 || number > 12) {
759: 					error_message = "Month out of range, expected a value between 1 and 12";
760: 					error_position = start_pos;
761: 					return false;
762: 				}
763: 				// month number
764: 				result_data[1] = number;
765: 				break;
766: 			case StrTimeSpecifier::YEAR_WITHOUT_CENTURY_PADDED:
767: 			case StrTimeSpecifier::YEAR_WITHOUT_CENTURY:
768: 				// year without century..
769: 				// Python uses 69 as a crossover point (i.e. >= 69 is 19.., < 69 is 20..)
770: 				if (number >= 100) {
771: 					// %y only supports numbers between [0..99]
772: 					error_message = "Year without century out of range, expected a value between 0 and 99";
773: 					error_position = start_pos;
774: 					return false;
775: 				}
776: 				if (number >= 69) {
777: 					result_data[0] = 1900 + number;
778: 				} else {
779: 					result_data[0] = 2000 + number;
780: 				}
781: 				break;
782: 			case StrTimeSpecifier::YEAR_DECIMAL:
783: 				// year as full number
784: 				result_data[0] = number;
785: 				break;
786: 			case StrTimeSpecifier::HOUR_24_PADDED:
787: 			case StrTimeSpecifier::HOUR_24_DECIMAL:
788: 				if (number >= 24) {
789: 					error_message = "Hour out of range, expected a value between 0 and 23";
790: 					error_position = start_pos;
791: 					return false;
792: 				}
793: 				// hour as full number
794: 				result_data[3] = number;
795: 				break;
796: 			case StrTimeSpecifier::HOUR_12_PADDED:
797: 			case StrTimeSpecifier::HOUR_12_DECIMAL:
798: 				if (number < 1 || number > 12) {
799: 					error_message = "Hour12 out of range, expected a value between 1 and 12";
800: 					error_position = start_pos;
801: 					return false;
802: 				}
803: 				// 12-hour number: start off by just storing the number
804: 				result_data[3] = number;
805: 				break;
806: 			case StrTimeSpecifier::MINUTE_PADDED:
807: 			case StrTimeSpecifier::MINUTE_DECIMAL:
808: 				if (number >= 60) {
809: 					error_message = "Minutes out of range, expected a value between 0 and 59";
810: 					error_position = start_pos;
811: 					return false;
812: 				}
813: 				// minutes
814: 				result_data[4] = number;
815: 				break;
816: 			case StrTimeSpecifier::SECOND_PADDED:
817: 			case StrTimeSpecifier::SECOND_DECIMAL:
818: 				if (number >= 60) {
819: 					error_message = "Seconds out of range, expected a value between 0 and 59";
820: 					error_position = start_pos;
821: 					return false;
822: 				}
823: 				// seconds
824: 				result_data[5] = number;
825: 				break;
826: 			case StrTimeSpecifier::MICROSECOND_PADDED:
827: 				if (number >= 1000000ULL) {
828: 					error_message = "Microseconds out of range, expected a value between 0 and 999999";
829: 					error_position = start_pos;
830: 					return false;
831: 				}
832: 				// microseconds
833: 				result_data[6] = number * 1000;
834: 				break;
835: 			default:
836: 				throw NotImplementedException("Unsupported specifier for strptime");
837: 			}
838: 		} else {
839: 			switch(specifiers[i]) {
840: 			case StrTimeSpecifier::AM_PM: {
841: 				// parse the next 2 characters
842: 				if (pos + 2 > size) {
843: 					// no characters left to parse
844: 					error_message = "Expected AM/PM";
845: 					error_position = pos;
846: 					return false;
847: 				}
848: 				char pa_char = std::tolower(data[pos]);
849: 				char m_char = std::tolower(data[pos + 1]);
850: 				if (m_char != 'm') {
851: 					error_message = "Expected AM/PM";
852: 					error_position = pos;
853: 					return false;
854: 				}
855: 				if (pa_char == 'p') {
856: 					ampm = TimeSpecifierAMOrPM::TIME_SPECIFIER_PM;
857: 				} else if (pa_char == 'a') {
858: 					ampm = TimeSpecifierAMOrPM::TIME_SPECIFIER_AM;
859: 				} else {
860: 					error_message = "Expected AM/PM";
861: 					error_position = pos;
862: 					return false;
863: 				}
864: 				pos += 2;
865: 				break;
866: 			}
867: 			// we parse weekday names, but we don't use them as information
868: 			case StrTimeSpecifier::ABBREVIATED_WEEKDAY_NAME:
869: 				if (TryParseCollection(data, pos, size, Date::DayNamesAbbreviated, 7) < 0) {
870: 					error_message = "Expected an abbreviated day name (Mon, Tue, Wed, Thu, Fri, Sat, Sun)";
871: 					error_position = pos;
872: 					return false;
873: 				}
874: 				break;
875: 			case StrTimeSpecifier::FULL_WEEKDAY_NAME:
876: 				if (TryParseCollection(data, pos, size, Date::DayNames, 7) < 0) {
877: 					error_message = "Expected a full day name (Monday, Tuesday, etc...)";
878: 					error_position = pos;
879: 					return false;
880: 				}
881: 				break;
882: 			case StrTimeSpecifier::ABBREVIATED_MONTH_NAME: {
883: 				int32_t month = TryParseCollection(data, pos, size, Date::MonthNamesAbbreviated, 12);
884: 				if (month < 0) {
885: 					error_message = "Expected an abbreviated month name (Jan, Feb, Mar, etc..)";
886: 					error_position = pos;
887: 					return false;
888: 				}
889: 				result_data[1] = month + 1;
890: 				break;
891: 			}
892: 			case StrTimeSpecifier::FULL_MONTH_NAME: {
893: 				int32_t month = TryParseCollection(data, pos, size, Date::MonthNames, 12);
894: 				if (month < 0) {
895: 					error_message = "Expected a full month name (January, February, etc...)";
896: 					error_position = pos;
897: 					return false;
898: 				}
899: 				result_data[1] = month + 1;
900: 				break;
901: 			}
902: 			default:
903: 				throw NotImplementedException("Unsupported specifier for strptime");
904: 			}
905: 		}
906: 	}
907: 	// skip trailing spaces
908: 	while(std::isspace(data[pos])) {
909: 		pos++;
910: 	}
911: 	if (pos != size) {
912: 		error_message = "Full specifier did not match: trailing characters";
913: 		error_position = pos;
914: 		return false;
915: 	}
916: 	if (ampm != TimeSpecifierAMOrPM::TIME_SPECIFIER_NONE) {
917: 		// fixme: adjust the hours based on the AM or PM specifier
918: 		if (ampm == TimeSpecifierAMOrPM::TIME_SPECIFIER_AM) {
919: 			// AM: 12AM=0, 1AM=1, 2AM=2, ..., 11AM=11
920: 			if (result_data[3] == 12) {
921: 				result_data[3] = 0;
922: 			}
923: 		} else {
924: 			// PM: 12PM=12, 1PM=13, 2PM=14, ..., 11PM=23
925: 			if (result_data[3] != 12) {
926: 				result_data[3] += 12;
927: 			}
928: 		}
929: 	}
930: 	return true;
931: }
932: 
933: struct StrpTimeBindData : public FunctionData {
934: 	StrpTimeBindData(StrpTimeFormat format) : format(move(format)) {}
935: 
936: 	StrpTimeFormat format;
937: 
938: 	unique_ptr<FunctionData> Copy() override {
939: 		return make_unique<StrpTimeBindData>(format);
940: 	}
941: };
942: 
943: static unique_ptr<FunctionData> strptime_bind_function(BoundFunctionExpression &expr, ClientContext &context) {
944: 	if (!expr.children[1]->IsScalar()) {
945: 		throw InvalidInputException("strftime format must be a constant");
946: 	}
947: 	Value options_str = ExpressionExecutor::EvaluateScalar(*expr.children[1]);
948: 	StrpTimeFormat format;
949: 	if (!options_str.is_null && options_str.type == TypeId::VARCHAR) {
950: 		format.format_specifier = options_str.str_value;
951: 		string error = StrTimeFormat::ParseFormatSpecifier(options_str.str_value, format);
952: 		if (!error.empty()) {
953: 			throw InvalidInputException("Failed to parse format specifier %s: %s", options_str.str_value.c_str(), error.c_str());
954: 		}
955: 	}
956: 	return make_unique<StrpTimeBindData>(format);
957: }
958: 
959: string StrpTimeFormat::FormatStrpTimeError(string input, idx_t position) {
960: 	if (position == INVALID_INDEX) {
961: 		return string();
962: 	}
963: 	return input + "\n" + string(position, ' ') + "^";
964: }
965: 
966: date_t StrpTimeFormat::ParseDate(string_t input) {
967: 	string error_message;
968: 	idx_t error_position = INVALID_INDEX;
969: 	int32_t result_data[7];
970: 	if (!Parse(input, result_data, error_message, error_position)) {
971: 		throw InvalidInputException("Could not parse string \"%s\" according to format specifier \"%s\"\n%s\nError: %s",
972: 			input.GetData(),
973: 			format_specifier.c_str(),
974: 			FormatStrpTimeError(string(input.GetData(), input.GetSize()), error_position).c_str(),
975: 			error_message.c_str());
976: 	}
977: 	return Date::FromDate(result_data[0], result_data[1], result_data[2]);
978: }
979: 
980: timestamp_t StrpTimeFormat::ParseTimestamp(string_t input) {
981: 	string error_message;
982: 	idx_t error_position = INVALID_INDEX;
983: 	int32_t result_data[7];
984: 	if (!Parse(input, result_data, error_message, error_position)) {
985: 		throw InvalidInputException("Could not parse string \"%s\" according to format specifier \"%s\"\n%s\nError: %s",
986: 			input.GetData(),
987: 			format_specifier.c_str(),
988: 			FormatStrpTimeError(string(input.GetData(), input.GetSize()), error_position).c_str(),
989: 			error_message.c_str());
990: 	}
991: 	date_t date = Date::FromDate(result_data[0], result_data[1], result_data[2]);
992: 	dtime_t time = Time::FromTime(result_data[3], result_data[4], result_data[5], result_data[6]);
993: 	return Timestamp::FromDatetime(date, time);
994: }
995: 
996: static void strptime_function(DataChunk &args, ExpressionState &state, Vector &result) {
997: 	auto &func_expr = (BoundFunctionExpression &)state.expr;
998: 	auto &info = (StrpTimeBindData &)*func_expr.bind_info;
999: 
1000: 	if (ConstantVector::IsNull(args.data[1])) {
1001: 		result.vector_type = VectorType::CONSTANT_VECTOR;
1002: 		ConstantVector::SetNull(result, true);
1003: 		return;
1004: 	}
1005: 	UnaryExecutor::Execute<string_t, timestamp_t, true>(args.data[0], result, args.size(), [&](string_t input) {
1006: 		return info.format.ParseTimestamp(input);
1007: 	});
1008: }
1009: 
1010: void StrpTimeFun::RegisterFunction(BuiltinFunctions &set) {
1011: 	ScalarFunctionSet strptime("strptime");
1012: 
1013: 	strptime.AddFunction(ScalarFunction({SQLType::VARCHAR, SQLType::VARCHAR}, SQLType::TIMESTAMP,
1014: 	                               strptime_function, false, strptime_bind_function));
1015: 
1016: 	set.AddFunction(strptime);
1017: }
1018: 
1019: 
1020: }
[end of src/function/scalar/date/strftime.cpp]
[start of src/function/table/copy_csv.cpp]
1: #include "duckdb/function/table/read_csv.hpp"
2: #include "duckdb/execution/operator/persistent/buffered_csv_reader.hpp"
3: #include "duckdb/common/serializer/buffered_serializer.hpp"
4: #include "duckdb/function/copy_function.hpp"
5: #include "duckdb/parser/parsed_data/copy_info.hpp"
6: #include "duckdb/common/string_util.hpp"
7: #include "duckdb/common/file_system.hpp"
8: #include "duckdb/common/types/string_type.hpp"
9: #include "duckdb/common/vector_operations/vector_operations.hpp"
10: 
11: using namespace std;
12: 
13: namespace duckdb {
14: 
15: struct BaseCSVData : public FunctionData {
16: 	BaseCSVData(string file_path) :
17: 		file_path(move(file_path)) {}
18: 
19: 	//! The file path of the CSV file to read or write
20: 	string file_path;
21: 	//! Whether or not to write a header in the file
22: 	bool header = false;
23: 	//! Delimiter to separate columns within each line
24: 	string delimiter = ",";
25: 	//! Quote used for columns that contain reserved characters, e.g., delimiter
26: 	string quote = "\"";
27: 	//! Escape character to escape quote character
28: 	string escape;
29: 	//! Specifies the string that represents a null value
30: 	string null_str;
31: 	//! Whether or not the options are specified; if not we default to auto detect
32: 	bool is_auto_detect = true;
33: 
34: 	void Finalize();
35: };
36: 
37: struct WriteCSVData : public BaseCSVData {
38: 	WriteCSVData(string file_path, vector<SQLType> sql_types, vector<string> names) :
39: 		BaseCSVData(move(file_path)), sql_types(move(sql_types)), names(move(names)) {}
40: 
41: 	//! The SQL types to write
42: 	vector<SQLType> sql_types;
43: 	//! The column names of the columns to write
44: 	vector<string> names;
45: 	//! True, if column with that index must be quoted
46: 	vector<bool> force_quote;
47: 	//! The newline string to write
48: 	string newline = "\n";
49: 	//! Whether or not we are writing a simple CSV (delimiter, quote and escape are all 1 byte in length)
50: 	bool is_simple;
51: 	//! The size of the CSV file (in bytes) that we buffer before we flush it to disk
52: 	idx_t flush_size = 4096 * 8;
53: };
54: 
55: struct ReadCSVData : public BaseCSVData {
56: 	ReadCSVData(string file_path, vector<SQLType> sql_types) :
57: 		BaseCSVData(move(file_path)), sql_types(move(sql_types)) {}
58: 
59: 	//! The expected SQL types to read
60: 	vector<SQLType> sql_types;
61: 	//! True, if column with that index must be quoted
62: 	vector<bool> force_not_null;
63: 	//! The DATE_FORMAT to use to read or write dates
64: 	StrpTimeFormat date_format;
65: 	//! Whether or not there is a date format specified
66: 	bool has_date_format = false;
67: 	//! The DATE_FORMAT to use to read or write dates
68: 	StrpTimeFormat timestamp_format;
69: 	//! Whether or not there is a date format specified
70: 	bool has_timestamp_format = false;
71: };
72: 
73: void SubstringDetection(string &str_1, string &str_2, string name_str_1, string name_str_2) {
74: 	if (str_1.find(str_2) != string::npos || str_2.find(str_1) != std::string::npos) {
75: 		throw BinderException("COPY " + name_str_1 + " must not appear in the " + name_str_2 +
76: 		                " specification and vice versa");
77: 	}
78: }
79: 
80: static bool ParseBoolean(vector<Value> &set) {
81: 	if (set.size() == 0) {
82: 		// no option specified: default to true
83: 		return true;
84: 	}
85: 	if (set.size() > 1) {
86: 		throw BinderException("Expected a single argument as a boolean value (e.g. TRUE or 1)");
87: 	}
88: 	if (set[0].type == TypeId::FLOAT || set[0].type == TypeId::DOUBLE) {
89: 		throw BinderException("Expected a boolean value (e.g. TRUE or 1)");
90: 	}
91: 	return set[0].CastAs(TypeId::BOOL).value_.boolean;
92: }
93: 
94: static string ParseString(vector<Value> &set) {
95: 	if (set.size() != 1) {
96: 		// no option specified or multiple options specified
97: 		throw BinderException("Expected a single argument as a string value");
98: 	}
99: 	if (set[0].type != TypeId::VARCHAR) {
100: 		throw BinderException("Expected a string argument!");
101: 	}
102: 	return set[0].str_value;
103: }
104: 
105: //===--------------------------------------------------------------------===//
106: // Bind
107: //===--------------------------------------------------------------------===//
108: static bool ParseBaseOption(BaseCSVData &bind_data, string &loption, vector<Value> &set) {
109: 	if (StringUtil::StartsWith(loption, "delim") || StringUtil::StartsWith(loption, "sep")) {
110: 		bind_data.delimiter = ParseString(set);
111: 		bind_data.is_auto_detect = false;
112: 		if (bind_data.delimiter.length() == 0) {
113: 			throw BinderException("QUOTE must not be empty");
114: 		}
115: 	} else if (loption == "quote") {
116: 		bind_data.quote = ParseString(set);
117: 		bind_data.is_auto_detect = false;
118: 		if (bind_data.quote.length() == 0) {
119: 			throw BinderException("QUOTE must not be empty");
120: 		}
121: 	} else if (loption == "escape") {
122: 		bind_data.escape = ParseString(set);
123: 		bind_data.is_auto_detect = false;
124: 		if (bind_data.escape.length() == 0) {
125: 			throw BinderException("ESCAPE must not be empty");
126: 		}
127: 	} else if (loption == "header") {
128: 		bind_data.header = ParseBoolean(set);
129: 		bind_data.is_auto_detect = false;
130: 	} else if (loption == "null") {
131: 		bind_data.null_str = ParseString(set);
132: 		bind_data.is_auto_detect = false;
133: 	} else if (loption == "encoding") {
134: 		auto encoding = StringUtil::Lower(ParseString(set));
135: 		if (encoding != "utf8" && encoding != "utf-8") {
136: 			throw BinderException("Copy is only supported for UTF-8 encoded files, ENCODING 'UTF-8'");
137: 		}
138: 	} else {
139: 		// unrecognized option in base CSV
140: 		return false;
141: 	}
142: 	return true;
143: }
144: 
145: void BaseCSVData::Finalize() {
146: 	// verify that the options are correct in the final pass
147: 	if (escape.empty()) {
148: 		escape = quote;
149: 	}
150: 	// escape and delimiter must not be substrings of each other
151: 	SubstringDetection(delimiter, escape, "DELIMITER", "ESCAPE");
152: 	// delimiter and quote must not be substrings of each other
153: 	SubstringDetection(quote, delimiter, "DELIMITER", "QUOTE");
154: 	// escape and quote must not be substrings of each other (but can be the same)
155: 	if (quote != escape) {
156: 		SubstringDetection(quote, escape, "QUOTE", "ESCAPE");
157: 	}
158: 	if (null_str != "") {
159: 		// null string and delimiter must not be substrings of each other
160: 		SubstringDetection(delimiter, null_str, "DELIMITER", "NULL");
161: 		// quote/escape and nullstr must not be substrings of each other
162: 		SubstringDetection(quote, null_str, "QUOTE", "NULL");
163: 		SubstringDetection(escape, null_str, "ESCAPE", "NULL");
164: 	}
165: }
166: 
167: static vector<bool> ParseColumnList(vector<Value> &set, vector<string> &names) {
168: 	vector<bool> result;
169: 	if (set.size() == 0) {
170: 		throw BinderException("Expected a column list or * as parameter");
171: 	}
172: 	if (set.size() == 1 && set[0].type == TypeId::VARCHAR && set[0].str_value == "*") {
173: 		// *, force_not_null on all columns
174: 		result.resize(names.size(), true);
175: 	} else {
176: 		// list of options: parse the list
177: 		unordered_map<string, bool> option_map;
178: 		for(idx_t i = 0; i < set.size(); i++) {
179: 			option_map[set[i].ToString()] = false;
180: 		}
181: 		result.resize(names.size(), false);
182: 		for(idx_t i = 0; i < names.size(); i++) {
183: 			auto entry = option_map.find(names[i]);
184: 			if (entry != option_map.end()) {
185: 				result[i] = true;
186: 				entry->second = true;
187: 			}
188: 		}
189: 		for(auto entry : option_map) {
190: 			if (!entry.second) {
191: 				throw BinderException("Column %s not found in table", entry.first.c_str());
192: 			}
193: 		}
194: 	}
195: 	return result;
196: }
197: 
198: static unique_ptr<FunctionData> write_csv_bind(ClientContext &context, CopyInfo &info, vector<string> &names,
199:                                            vector<SQLType> &sql_types) {
200: 	auto bind_data = make_unique<WriteCSVData>(info.file_path, sql_types, names);
201: 
202: 	// check all the options in the copy info
203: 	for(auto &option : info.options) {
204: 		auto loption = StringUtil::Lower(option.first);
205: 		auto &set = option.second;
206: 		if (ParseBaseOption(*bind_data, loption, set)) {
207: 			// parsed option in base CSV options: continue
208: 			continue;
209: 		} else if (loption == "force_quote") {
210: 			bind_data->force_quote = ParseColumnList(set, names);
211: 		} else {
212: 			throw NotImplementedException("Unrecognized option for CSV: %s", option.first.c_str());
213: 		}
214: 	}
215: 	// verify the parsed options
216: 	if (bind_data->force_quote.size() == 0) {
217: 		// no FORCE_QUOTE specified: initialize to false
218: 		bind_data->force_quote.resize(names.size(), false);
219: 	}
220: 	bind_data->Finalize();
221: 	bind_data->is_simple = bind_data->delimiter.size() == 1 && bind_data->escape.size() == 1 && bind_data->quote.size() == 1;
222: 	return move(bind_data);
223: }
224: 
225: static unique_ptr<FunctionData> read_csv_bind(ClientContext &context, CopyInfo &info, vector<string> &expected_names, vector<SQLType> &expected_types) {
226: 	auto bind_data = make_unique<ReadCSVData>(info.file_path, expected_types);
227: 
228: 	// check all the options in the copy info
229: 	for(auto &option : info.options) {
230: 		auto loption = StringUtil::Lower(option.first);
231: 		auto &set = option.second;
232: 		if (ParseBaseOption(*bind_data, loption, set)) {
233: 			// parsed option in base CSV options: continue
234: 			continue;
235: 		} else if (loption == "force_not_null") {
236: 			bind_data->force_not_null = ParseColumnList(set, expected_names);
237: 		}  else if (loption == "date_format" || loption == "dateformat") {
238: 			string format = ParseString(set);
239: 			string error = StrTimeFormat::ParseFormatSpecifier(format, bind_data->date_format);
240: 			bind_data->date_format.format_specifier = format;
241: 			if (!error.empty()) {
242: 				throw InvalidInputException("Could not parse DATEFORMAT: %s", error.c_str());
243: 			}
244: 			bind_data->has_date_format = true;
245: 		} else if (loption == "timestamp_format" || loption == "timestampformat") {
246: 			string format = ParseString(set);
247: 			string error = StrTimeFormat::ParseFormatSpecifier(format, bind_data->timestamp_format);
248: 			bind_data->timestamp_format.format_specifier = format;
249: 			if (!error.empty()) {
250: 				throw InvalidInputException("Could not parse TIMESTAMPFORMAT: %s", error.c_str());
251: 			}
252: 			bind_data->has_timestamp_format = true;
253: 		} else {
254: 			throw NotImplementedException("Unrecognized option for CSV: %s", option.first.c_str());
255: 		}
256: 	}
257: 	// verify the parsed options
258: 	if (bind_data->force_not_null.size() == 0) {
259: 		// no FORCE_QUOTE specified: initialize to false
260: 		bind_data->force_not_null.resize(expected_types.size(), false);
261: 	}
262: 	bind_data->Finalize();
263: 	return move(bind_data);
264: }
265: 
266: static unique_ptr<FunctionData> read_csv_auto_bind(ClientContext &context, CopyInfo &info, vector<string> &expected_names, vector<SQLType> &expected_types) {
267: 	auto bind_data = make_unique<ReadCSVData>(info.file_path, expected_types);
268: 
269: 	for(auto &option : info.options) {
270: 		auto loption = StringUtil::Lower(option.first);
271: 		// auto &set = option.second;
272: 		// CSV auto accepts no options!
273: 		throw NotImplementedException("Unrecognized option for CSV_AUTO: %s", option.first.c_str());
274: 	}
275: 
276: 	bind_data->Finalize();
277: 	return move(bind_data);
278: }
279: 
280: //===--------------------------------------------------------------------===//
281: // Helper writing functions
282: //===--------------------------------------------------------------------===//
283: static string AddEscapes(string &to_be_escaped, string escape, string val) {
284: 	idx_t i = 0;
285: 	string new_val = "";
286: 	idx_t found = val.find(to_be_escaped);
287: 
288: 	while (found != string::npos) {
289: 		while (i < found) {
290: 			new_val += val[i];
291: 			i++;
292: 		}
293: 		new_val += escape;
294: 		found = val.find(to_be_escaped, found + escape.length());
295: 	}
296: 	while (i < val.length()) {
297: 		new_val += val[i];
298: 		i++;
299: 	}
300: 	return new_val;
301: }
302: 
303: static bool RequiresQuotes(WriteCSVData &options, const char *str, idx_t len) {
304: 	// check if the string is equal to the null string
305: 	if (len == options.null_str.size() && memcmp(str, options.null_str.c_str(), len) == 0) {
306: 		return true;
307: 	}
308: 	if (options.is_simple) {
309: 		// simple CSV: check for newlines, quotes and delimiter all at once
310: 		for (idx_t i = 0; i < len; i++) {
311: 			if (str[i] == '\n' || str[i] == '\r' || str[i] == options.quote[0] || str[i] == options.delimiter[0]) {
312: 				// newline, write a quoted string
313: 				return true;
314: 			}
315: 		}
316: 		// no newline, quote or delimiter in the string
317: 		// no quoting or escaping necessary
318: 		return false;
319: 	} else {
320: 		// CSV with complex quotes/delimiter (multiple bytes)
321: 
322: 		// first check for \n, \r, \n\r in string
323: 		for (idx_t i = 0; i < len; i++) {
324: 			if (str[i] == '\n' || str[i] == '\r') {
325: 				// newline, write a quoted string
326: 				return true;
327: 			}
328: 		}
329: 
330: 		// check for delimiter
331: 		if (strstr(str, options.delimiter.c_str())) {
332: 			return true;
333: 		}
334: 		// check for quote
335: 		if (strstr(str, options.quote.c_str())) {
336: 			return true;
337: 		}
338: 		return false;
339: 	}
340: }
341: 
342: static void WriteQuotedString(Serializer &serializer, WriteCSVData &options, const char *str, idx_t len, bool force_quote) {
343: 	if (!force_quote) {
344: 		// force quote is disabled: check if we need to add quotes anyway
345: 		force_quote = RequiresQuotes(options, str, len);
346: 	}
347: 	if (force_quote) {
348: 		// quoting is enabled: we might need to escape things in the string
349: 		bool requires_escape = false;
350: 		if (options.is_simple) {
351: 			// simple CSV
352: 			// do a single loop to check for a quote or escape value
353: 			for (idx_t i = 0; i < len; i++) {
354: 				if (str[i] == options.quote[0] || str[i] == options.escape[0]) {
355: 					requires_escape = true;
356: 					break;
357: 				}
358: 			}
359: 		} else {
360: 			// complex CSV
361: 			// check for quote or escape separately
362: 			if (strstr(str, options.quote.c_str())) {
363: 				requires_escape = true;
364: 			} else if (strstr(str, options.escape.c_str())) {
365: 				requires_escape = true;
366: 			}
367: 		}
368: 		if (!requires_escape) {
369: 			// fast path: no need to escape anything
370: 			serializer.WriteBufferData(options.quote);
371: 			serializer.WriteData((const_data_ptr_t) str, len);
372: 			serializer.WriteBufferData(options.quote);
373: 			return;
374: 		}
375: 
376: 		// slow path: need to add escapes
377: 		string new_val(str, len);
378: 		new_val = AddEscapes(options.escape, options.escape, new_val);
379: 		if (options.escape != options.quote) {
380: 			// need to escape quotes separately
381: 			new_val = AddEscapes(options.quote, options.escape, new_val);
382: 		}
383: 		serializer.WriteBufferData(options.quote);
384: 		serializer.WriteBufferData(new_val);
385: 		serializer.WriteBufferData(options.quote);
386: 	} else {
387: 		serializer.WriteData((const_data_ptr_t) str, len);
388: 	}
389: }
390: 
391: //===--------------------------------------------------------------------===//
392: // Sink
393: //===--------------------------------------------------------------------===//
394: struct LocalReadCSVData : public LocalFunctionData {
395: 	//! The thread-local buffer to write data into
396: 	BufferedSerializer serializer;
397: 	//! A chunk with VARCHAR columns to cast intermediates into
398: 	DataChunk cast_chunk;
399: };
400: 
401: struct GlobalWriteCSVData : public GlobalFunctionData {
402: 	GlobalWriteCSVData(FileSystem &fs, string file_path) : fs(fs) {
403: 		handle = fs.OpenFile(file_path, FileFlags::FILE_FLAGS_WRITE | FileFlags::FILE_FLAGS_FILE_CREATE_NEW, FileLockType::WRITE_LOCK);
404: 	}
405: 
406: 	void WriteData(const_data_ptr_t data, idx_t size) {
407: 		lock_guard<mutex> flock(lock);
408: 		fs.Write(*handle, (void*) data, size);
409: 	}
410: 
411: 	FileSystem &fs;
412: 	//! The mutex for writing to the physical file
413: 	mutex lock;
414: 	//! The file handle to write to
415: 	unique_ptr<FileHandle> handle;
416: };
417: 
418: static unique_ptr<LocalFunctionData> write_csv_initialize_local(ClientContext &context, FunctionData &bind_data) {
419: 	auto &csv_data = (WriteCSVData &) bind_data;
420: 	auto local_data = make_unique<LocalReadCSVData>();
421: 
422: 	// create the chunk with VARCHAR types
423: 	vector<TypeId> types;
424: 	types.resize(csv_data.names.size(), TypeId::VARCHAR);
425: 
426: 	local_data->cast_chunk.Initialize(types);
427: 	return move(local_data);
428: }
429: 
430: static unique_ptr<GlobalFunctionData> write_csv_initialize_global(ClientContext &context, FunctionData &bind_data) {
431: 	auto &csv_data = (WriteCSVData &) bind_data;
432: 	auto global_data =  make_unique<GlobalWriteCSVData>(FileSystem::GetFileSystem(context), csv_data.file_path);
433: 
434: 	if (csv_data.header) {
435: 		BufferedSerializer serializer;
436: 		// write the header line to the file
437: 		for (idx_t i = 0; i < csv_data.names.size(); i++) {
438: 			if (i != 0) {
439: 				serializer.WriteBufferData(csv_data.delimiter);
440: 			}
441: 			WriteQuotedString(serializer, csv_data, csv_data.names[i].c_str(), csv_data.names[i].size(), false);
442: 		}
443: 		serializer.WriteBufferData(csv_data.newline);
444: 
445: 		global_data->WriteData(serializer.blob.data.get(), serializer.blob.size);
446: 	}
447: 	return move(global_data);
448: }
449: 
450: 
451: static void write_csv_sink(ClientContext &context, FunctionData &bind_data, GlobalFunctionData &gstate, LocalFunctionData &lstate, DataChunk &input) {
452: 	auto &csv_data = (WriteCSVData &) bind_data;
453: 	auto &local_data = (LocalReadCSVData &) lstate;
454: 	auto &global_state = (GlobalWriteCSVData &) gstate;
455: 
456: 	// write data into the local buffer
457: 
458: 	// first cast the columns of the chunk to varchar
459: 	auto &cast_chunk = local_data.cast_chunk;
460: 	cast_chunk.SetCardinality(input);
461: 	for (idx_t col_idx = 0; col_idx < input.column_count(); col_idx++) {
462: 		if (csv_data.sql_types[col_idx].id == SQLTypeId::VARCHAR || csv_data.sql_types[col_idx].id == SQLTypeId::BLOB) {
463: 			// VARCHAR, just create a reference
464: 			cast_chunk.data[col_idx].Reference(input.data[col_idx]);
465: 		} else {
466: 			// non varchar column, perform the cast
467: 			VectorOperations::Cast(input.data[col_idx], cast_chunk.data[col_idx], csv_data.sql_types[col_idx],
468: 									SQLType::VARCHAR, input.size());
469: 		}
470: 	}
471: 
472: 	cast_chunk.Normalify();
473: 	auto &writer = local_data.serializer;
474: 	// now loop over the vectors and output the values
475: 	for (idx_t row_idx = 0; row_idx < cast_chunk.size(); row_idx++) {
476: 		// write values
477: 		for (idx_t col_idx = 0; col_idx < cast_chunk.column_count(); col_idx++) {
478: 			if (col_idx != 0) {
479: 				writer.WriteBufferData(csv_data.delimiter);
480: 			}
481: 			if (FlatVector::IsNull(cast_chunk.data[col_idx], row_idx)) {
482: 				// write null value
483: 				writer.WriteBufferData(csv_data.null_str);
484: 				continue;
485: 			}
486: 
487: 			// non-null value, fetch the string value from the cast chunk
488: 			auto str_data = FlatVector::GetData<string_t>(cast_chunk.data[col_idx]);
489: 			auto str_value = str_data[row_idx];
490: 			// FIXME: we could gain some performance here by checking for certain types if they ever require quotes (e.g. integers only require quotes if the delimiter is a number, decimals only require quotes if the delimiter is a number or "." character)
491: 			WriteQuotedString(writer, csv_data, str_value.GetData(), str_value.GetSize(), csv_data.force_quote[col_idx]);
492: 		}
493: 		writer.WriteBufferData(csv_data.newline);
494: 	}
495: 	// check if we should flush what we have currently written
496: 	if (writer.blob.size >= csv_data.flush_size) {
497: 		global_state.WriteData(writer.blob.data.get(), writer.blob.size);
498: 		writer.Reset();
499: 	}
500: }
501: 
502: //===--------------------------------------------------------------------===//
503: // Combine
504: //===--------------------------------------------------------------------===//
505: static void write_csv_combine(ClientContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,
506:                           LocalFunctionData &lstate) {
507: 	auto &local_data = (LocalReadCSVData &) lstate;
508: 	auto &global_state = (GlobalWriteCSVData &) gstate;
509: 	auto &writer = local_data.serializer;
510: 	// flush the local writer
511: 	if (writer.blob.size > 0) {
512: 		global_state.WriteData(writer.blob.data.get(), writer.blob.size);
513: 		writer.Reset();
514: 	}
515: }
516: 
517: //===--------------------------------------------------------------------===//
518: // Read CSV
519: //===--------------------------------------------------------------------===//
520: struct GlobalReadCSVData : public GlobalFunctionData {
521: 	unique_ptr<BufferedCSVReader> csv_reader;
522: };
523: 
524: unique_ptr<GlobalFunctionData> read_csv_initialize(ClientContext &context, FunctionData &fdata) {
525: 	auto global_data = make_unique<GlobalReadCSVData>();
526: 	auto &bind_data = (ReadCSVData&) fdata;
527: 
528: 	// set up the CSV reader with the parsed options
529:     BufferedCSVReaderOptions options;
530: 	options.file_path = bind_data.file_path;
531: 	options.auto_detect = bind_data.is_auto_detect;
532: 	options.delimiter = bind_data.delimiter;
533: 	options.quote = bind_data.quote;
534: 	options.escape = bind_data.escape;
535: 	options.header = bind_data.header;
536: 	options.null_str = bind_data.null_str;
537: 	options.skip_rows = 0;
538: 	options.num_cols = bind_data.sql_types.size();
539: 	options.force_not_null = bind_data.force_not_null;
540: 	options.has_date_format = bind_data.has_date_format;
541: 	options.date_format = move(bind_data.date_format);
542: 	options.has_timestamp_format = bind_data.has_timestamp_format;
543: 	options.timestamp_format = move(bind_data.timestamp_format);
544: 
545: 	global_data->csv_reader = make_unique<BufferedCSVReader>(context, move(options), bind_data.sql_types);
546: 	return move(global_data);
547: }
548: 
549: void read_csv_get_chunk(ExecutionContext &context, GlobalFunctionData &gstate, FunctionData &bind_data, DataChunk &chunk) {
550: 	// read a chunk from the CSV reader
551: 	auto &gdata = (GlobalReadCSVData &) gstate;
552: 	gdata.csv_reader->ParseCSV(chunk);
553: }
554: 
555: void CSVCopyFunction::RegisterFunction(BuiltinFunctions &set) {
556: 	CopyFunction info("csv");
557: 	info.copy_to_bind = write_csv_bind;
558: 	info.copy_to_initialize_local = write_csv_initialize_local;
559: 	info.copy_to_initialize_global = write_csv_initialize_global;
560: 	info.copy_to_sink = write_csv_sink;
561: 	info.copy_to_combine = write_csv_combine;
562: 
563: 	info.copy_from_bind = read_csv_bind;
564: 	info.copy_from_initialize = read_csv_initialize;
565: 	info.copy_from_get_chunk = read_csv_get_chunk;
566: 
567: 	// CSV_AUTO can only be used in COPY FROM
568: 	CopyFunction auto_info("csv_auto");
569: 	auto_info.copy_from_bind = read_csv_auto_bind;
570: 	auto_info.copy_from_initialize = read_csv_initialize;
571: 	auto_info.copy_from_get_chunk = read_csv_get_chunk;
572: 
573: 	set.AddFunction(info);
574: 	set.AddFunction(auto_info);
575: }
576: 
577: } // namespace duckdb
[end of src/function/table/copy_csv.cpp]
[start of src/function/table/read_csv.cpp]
1: #include "duckdb/function/table/read_csv.hpp"
2: #include "duckdb/execution/operator/persistent/buffered_csv_reader.hpp"
3: #include "duckdb/function/function_set.hpp"
4: #include "duckdb/main/client_context.hpp"
5: #include "duckdb/main/database.hpp"
6: 
7: using namespace std;
8: 
9: namespace duckdb {
10: 
11: struct ReadCSVFunctionData : public TableFunctionData {
12: 	ReadCSVFunctionData() {
13: 	}
14: 
15: 	//! The CSV reader
16: 	unique_ptr<BufferedCSVReader> csv_reader;
17: };
18: 
19: static unique_ptr<FunctionData> read_csv_bind(ClientContext &context, vector<Value> &inputs, unordered_map<string, Value> &named_parameters,
20:                                               vector<SQLType> &return_types, vector<string> &names) {
21: 
22: 	if (!context.db.config.enable_copy) {
23: 		throw Exception("read_csv is disabled by configuration");
24: 	}
25: 	auto result = make_unique<ReadCSVFunctionData>();
26: 
27: 	BufferedCSVReaderOptions options;
28: 	options.file_path = inputs[0].str_value;
29: 	options.auto_detect = true;
30: 	options.header = false;
31: 	options.delimiter = ",";
32: 	options.quote = "\"";
33: 
34: 	for(auto &kv : named_parameters) {
35: 		if (kv.first == "sep") {
36: 			options.auto_detect = false;
37: 			options.delimiter = kv.second.str_value;
38: 		} else if (kv.first == "header") {
39: 			options.auto_detect = false;
40: 			options.header = kv.second.value_.boolean;
41: 		} else if (kv.first == "quote") {
42: 			options.auto_detect = false;
43: 			options.quote = kv.second.str_value;
44: 		} else if (kv.first == "escape") {
45: 			options.auto_detect = false;
46: 			options.escape = kv.second.str_value;
47: 		} else if (kv.first == "nullstr") {
48: 			options.auto_detect = false;
49: 			options.null_str = kv.second.str_value;
50: 		} else if (kv.first == "dateformat") {
51: 			options.has_date_format = true;
52: 			options.date_format.format_specifier = kv.second.str_value;
53: 			string error = StrTimeFormat::ParseFormatSpecifier(kv.second.str_value, options.date_format);
54: 			if (!error.empty()) {
55: 				throw InvalidInputException("Could not parse DATEFORMAT: %s", error.c_str());
56: 			}
57: 		} else if (kv.first == "timestampformat") {
58: 			options.has_timestamp_format = true;
59: 			options.timestamp_format.format_specifier = kv.second.str_value;
60: 			string error = StrTimeFormat::ParseFormatSpecifier(kv.second.str_value, options.timestamp_format);
61: 			if (!error.empty()) {
62: 				throw InvalidInputException("Could not parse TIMESTAMPFORMAT: %s", error.c_str());
63: 			}
64: 		} else if (kv.first == "columns") {
65: 			options.auto_detect = false;
66: 			for (auto &val : kv.second.struct_value) {
67: 				names.push_back(val.first);
68: 				if (val.second.type != TypeId::VARCHAR) {
69: 					throw BinderException("read_csv requires a type specification as string");
70: 				}
71: 				return_types.push_back(TransformStringToSQLType(val.second.str_value.c_str()));
72: 			}
73: 			if (names.size() == 0) {
74: 				throw BinderException("read_csv requires at least a single column as input!");
75: 			}
76: 		}
77: 	}
78: 	if (!options.auto_detect && return_types.size() == 0) {
79: 		throw BinderException("Specifying CSV options requires columns to be specified as well (for now)");
80: 	}
81: 	if (return_types.size() > 0) {
82: 		// return types specified: no auto detect
83: 		result->csv_reader = make_unique<BufferedCSVReader>(context, move(options), return_types);
84: 	} else {
85: 		// auto detect options
86: 		result->csv_reader = make_unique<BufferedCSVReader>(context, move(options));
87: 
88: 		return_types.assign(result->csv_reader->sql_types.begin(), result->csv_reader->sql_types.end());
89: 		names.assign(result->csv_reader->col_names.begin(), result->csv_reader->col_names.end());
90: 	}
91: 	return move(result);
92: }
93: 
94: static unique_ptr<FunctionData> read_csv_auto_bind(ClientContext &context, vector<Value> &inputs, unordered_map<string, Value> &named_parameters,
95:                                                    vector<SQLType> &return_types, vector<string> &names) {
96: 
97: 	if (!context.db.config.enable_copy) {
98: 		throw Exception("read_csv_auto is disabled by configuration");
99: 	}
100: 	auto result = make_unique<ReadCSVFunctionData>();
101: 	BufferedCSVReaderOptions options;
102: 	options.auto_detect = true;
103: 	options.file_path = inputs[0].str_value;
104: 
105: 	result->csv_reader = make_unique<BufferedCSVReader>(context, move(options));
106: 
107: 	// TODO: print detected dialect from result->csv_reader->info
108: 	return_types.assign(result->csv_reader->sql_types.begin(), result->csv_reader->sql_types.end());
109: 	names.assign(result->csv_reader->col_names.begin(), result->csv_reader->col_names.end());
110: 
111: 	return move(result);
112: }
113: 
114: static void read_csv_info(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {
115: 	auto &data = ((ReadCSVFunctionData &)*dataptr);
116: 	data.csv_reader->ParseCSV(output);
117: }
118: 
119: void ReadCSVTableFunction::RegisterFunction(BuiltinFunctions &set) {
120: 	TableFunctionSet read_csv("read_csv");
121: 
122: 	TableFunction read_csv_function = TableFunction({SQLType::VARCHAR}, read_csv_bind, read_csv_info, nullptr);
123: 	read_csv_function.named_parameters["sep"] = SQLType::VARCHAR;
124: 	read_csv_function.named_parameters["quote"] = SQLType::VARCHAR;
125: 	read_csv_function.named_parameters["escape"] = SQLType::VARCHAR;
126: 	read_csv_function.named_parameters["nullstr"] = SQLType::VARCHAR;
127: 	read_csv_function.named_parameters["columns"] = SQLType::STRUCT;
128: 	read_csv_function.named_parameters["header"] = SQLType::BOOLEAN;
129: 	read_csv_function.named_parameters["dateformat"] = SQLType::VARCHAR;
130: 	read_csv_function.named_parameters["timestampformat"] = SQLType::VARCHAR;
131: 
132: 	read_csv.AddFunction(move(read_csv_function));
133: 
134: 	set.AddFunction(read_csv);
135: 	set.AddFunction(TableFunction("read_csv_auto", {SQLType::VARCHAR}, read_csv_auto_bind, read_csv_info, nullptr));
136: }
137: 
138: void BuiltinFunctions::RegisterReadFunctions() {
139: 	CSVCopyFunction::RegisterFunction(*this);
140: 	ReadCSVTableFunction::RegisterFunction(*this);
141: }
142: 
143: } // namespace duckdb
[end of src/function/table/read_csv.cpp]
[start of src/include/duckdb/execution/operator/persistent/buffered_csv_reader.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/execution/operator/persistent/buffered_csv_reader.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/execution/physical_operator.hpp"
12: #include "duckdb/parser/parsed_data/copy_info.hpp"
13: #include "duckdb/function/scalar/strftime.hpp"
14: 
15: #include <sstream>
16: 
17: #define SAMPLE_CHUNK_SIZE 100
18: #if STANDARD_VECTOR_SIZE < SAMPLE_CHUNK_SIZE
19: #undef SAMPLE_CHUNK_SIZE
20: #define SAMPLE_CHUNK_SIZE STANDARD_VECTOR_SIZE
21: #endif
22: 
23: namespace duckdb {
24: struct CopyInfo;
25: struct StrpTimeFormat;
26: 
27: //! The shifts array allows for linear searching of multi-byte values. For each position, it determines the next
28: //! position given that we encounter a byte with the given value.
29: /*! For example, if we have a string "ABAC", the shifts array will have the following values:
30:  *  [0] --> ['A'] = 1, all others = 0
31:  *  [1] --> ['B'] = 2, ['A'] = 1, all others = 0
32:  *  [2] --> ['A'] = 3, all others = 0
33:  *  [3] --> ['C'] = 4 (match), 'B' = 2, 'A' = 1, all others = 0
34:  * Suppose we then search in the following string "ABABAC", our progression will be as follows:
35:  * 'A' -> [1], 'B' -> [2], 'A' -> [3], 'B' -> [2], 'A' -> [3], 'C' -> [4] (match!)
36:  */
37: struct TextSearchShiftArray {
38: 	TextSearchShiftArray();
39: 	TextSearchShiftArray(string search_term);
40: 
41: 	inline bool Match(uint8_t &position, uint8_t byte_value) {
42: 		position = shifts[position * 255 + byte_value];
43: 		return position == length;
44: 	}
45: 
46: 	idx_t length;
47: 	unique_ptr<uint8_t[]> shifts;
48: };
49: 
50: struct BufferedCSVReaderOptions  {
51: 	//! The file path of the CSV file to read
52: 	string file_path;
53:     //! Whether or not to automatically detect dialect and datatypes
54:     bool auto_detect;
55:     //! Delimiter to separate columns within each line
56:     string delimiter;
57:     //! Quote used for columns that contain reserved characters, e.g., delimiter
58:     string quote;
59:     //! Escape character to escape quote character
60:     string escape;
61:     //! Whether or not the file has a header line
62:     bool header = false;
63:     //! How many leading rows to skip
64:     idx_t skip_rows = 0;
65:     //! Expected number of columns
66:     idx_t num_cols = 0;
67:     //! Specifies the string that represents a null value
68:     string null_str;
69:     //! True, if column with that index must skip null check
70:     vector<bool> force_not_null;
71: 	//! The date format to use (if any is specified)
72: 	StrpTimeFormat date_format;
73: 	//! Whether or not a date format is specified
74: 	bool has_date_format = false;
75: 	//! The timestamp format to use (if any is specified)
76: 	StrpTimeFormat timestamp_format;
77: 	//! Whether or not a timestamp format is specified
78: 	bool has_timestamp_format = false;
79: };
80: 
81: enum class QuoteRule : uint8_t { QUOTES_RFC = 0, QUOTES_OTHER = 1, NO_QUOTES = 2 };
82: 
83: enum class ParserMode : uint8_t { PARSING = 0, SNIFFING_DIALECT = 1, SNIFFING_DATATYPES = 2 };
84: 
85: static DataChunk DUMMY_CHUNK;
86: 
87: //! Buffered CSV reader is a class that reads values from a stream and parses them as a CSV file
88: class BufferedCSVReader {
89: 	//! Initial buffer read size; can be extended for long lines
90: 	static constexpr idx_t INITIAL_BUFFER_SIZE = 16384;
91: 	//! Maximum CSV line size: specified because if we reach this amount, we likely have the wrong delimiters
92: 	static constexpr idx_t MAXIMUM_CSV_LINE_SIZE = 1048576;
93: 	static constexpr uint8_t MAX_SAMPLE_CHUNKS = 10;
94: 	ParserMode mode;
95: 
96: public:
97: 	BufferedCSVReader(ClientContext &context, BufferedCSVReaderOptions options, vector<SQLType> requested_types = vector<SQLType>());
98: 	BufferedCSVReader(BufferedCSVReaderOptions options, vector<SQLType> requested_types, unique_ptr<std::istream> source);
99: 
100: 	BufferedCSVReaderOptions options;
101: 	vector<SQLType> sql_types;
102: 	vector<string> col_names;
103: 	unique_ptr<std::istream> source;
104: 	bool plain_file_source = false;
105: 	idx_t file_size = 0;
106: 
107: 	unique_ptr<char[]> buffer;
108: 	idx_t buffer_size;
109: 	idx_t position;
110: 	idx_t start = 0;
111: 
112: 	idx_t linenr = 0;
113: 	bool linenr_estimated = false;
114: 
115: 	vector<idx_t> sniffed_column_counts;
116: 	uint8_t sample_chunk_idx = 0;
117: 	bool jumping_samples = false;
118: 
119: 	idx_t bytes_in_chunk = 0;
120: 	double bytes_per_line_avg = 0;
121: 
122: 	vector<unique_ptr<char[]>> cached_buffers;
123: 
124: 	TextSearchShiftArray delimiter_search, escape_search, quote_search;
125: 
126: 	DataChunk parse_chunk;
127: 
128: public:
129: 	//! Extract a single DataChunk from the CSV file and stores it in insert_chunk
130: 	void ParseCSV(DataChunk &insert_chunk);
131: 
132: private:
133: 	//! Initialize Parser
134: 	void Initialize(vector<SQLType> requested_types);
135: 	//! Initializes the parse_chunk with varchar columns and aligns info with new number of cols
136: 	void InitParseChunk(idx_t num_cols);
137: 	//! Initializes the TextSearchShiftArrays for complex parser
138: 	void PrepareComplexParser();
139: 	//! Extract a single DataChunk from the CSV file and stores it in insert_chunk
140: 	void ParseCSV(ParserMode mode, DataChunk &insert_chunk = DUMMY_CHUNK);
141: 	//! Sniffs CSV dialect and determines skip rows, header row, column types and column names
142: 	vector<SQLType> SniffCSV(vector<SQLType> requested_types);
143: 	//! Try to cast a string value to the specified sql type
144: 	bool TryCastValue(Value value, SQLType sql_type);
145: 	//! Skips header rows and skip_rows in the input stream
146: 	void SkipHeader();
147: 	//! Jumps back to the beginning of input stream and resets necessary internal states
148: 	void JumpToBeginning();
149: 	//! Jumps back to the beginning of input stream and resets necessary internal states
150: 	bool JumpToNextSample();
151: 	//! Resets the buffer
152: 	void ResetBuffer();
153: 	//! Resets the steam
154: 	void ResetStream();
155: 	//! Resets the parse_chunk and related internal states, keep_types keeps the parse_chunk initialized
156: 	void ResetParseChunk();
157: 
158: 	//! Parses a CSV file with a one-byte delimiter, escape and quote character
159: 	void ParseSimpleCSV(DataChunk &insert_chunk);
160: 	//! Parses more complex CSV files with multi-byte delimiters, escapes or quotes
161: 	void ParseComplexCSV(DataChunk &insert_chunk);
162: 
163: 	//! Adds a value to the current row
164: 	void AddValue(char *str_val, idx_t length, idx_t &column, vector<idx_t> &escape_positions);
165: 	//! Adds a row to the insert_chunk, returns true if the chunk is filled as a result of this row being added
166: 	bool AddRow(DataChunk &insert_chunk, idx_t &column);
167: 	//! Finalizes a chunk, parsing all values that have been added so far and adding them to the insert_chunk
168: 	void Flush(DataChunk &insert_chunk);
169: 	//! Reads a new buffer from the CSV file if the current one has been exhausted
170: 	bool ReadBuffer(idx_t &start);
171: 
172: 	unique_ptr<std::istream> OpenCSV(ClientContext &context, BufferedCSVReaderOptions options);
173: };
174: 
175: } // namespace duckdb
[end of src/include/duckdb/execution/operator/persistent/buffered_csv_reader.hpp]
[start of src/parser/transform/statement/transform_copy.cpp]
1: #include "duckdb/parser/expression/columnref_expression.hpp"
2: #include "duckdb/parser/expression/constant_expression.hpp"
3: #include "duckdb/parser/expression/star_expression.hpp"
4: #include "duckdb/parser/statement/copy_statement.hpp"
5: #include "duckdb/parser/statement/select_statement.hpp"
6: #include "duckdb/parser/tableref/basetableref.hpp"
7: #include "duckdb/parser/transformer.hpp"
8: #include "duckdb/common/string_util.hpp"
9: #include "duckdb/common/types/value.hpp"
10: 
11: #include <cstring>
12: 
13: namespace duckdb {
14: using namespace std;
15: 
16: unique_ptr<CopyStatement> Transformer::TransformCopy(PGNode *node) {
17: 	auto stmt = reinterpret_cast<PGCopyStmt *>(node);
18: 	assert(stmt);
19: 	auto result = make_unique<CopyStatement>();
20: 	auto &info = *result->info;
21: 
22: 	// get file_path and is_from
23: 	info.file_path = stmt->filename;
24: 	info.is_from = stmt->is_from;
25: 	info.format = "csv";
26: 
27: 	// get select_list
28: 	if (stmt->attlist) {
29: 		for (auto n = stmt->attlist->head; n != nullptr; n = n->next) {
30: 			auto target = reinterpret_cast<PGResTarget *>(n->data.ptr_value);
31: 			if (target->name) {
32: 				info.select_list.push_back(string(target->name));
33: 			}
34: 		}
35: 	}
36: 
37: 	if (stmt->relation) {
38: 		auto ref = TransformRangeVar(stmt->relation);
39: 		if (info.is_from) {
40: 			// copy file into table
41: 			auto &table = *reinterpret_cast<BaseTableRef *>(ref.get());
42: 			info.table = table.table_name;
43: 			info.schema = table.schema_name;
44: 		} else {
45: 			// copy table into file, generate SELECT * FROM table;
46: 			auto statement = make_unique<SelectNode>();
47: 			statement->from_table = move(ref);
48: 			if (stmt->attlist) {
49: 				for (idx_t i = 0; i < info.select_list.size(); i++)
50: 					statement->select_list.push_back(make_unique<ColumnRefExpression>(info.select_list[i]));
51: 			} else {
52: 				statement->select_list.push_back(make_unique<StarExpression>());
53: 			}
54: 			result->select_statement = move(statement);
55: 		}
56: 	} else {
57: 		result->select_statement = TransformSelectNode((PGSelectStmt *)stmt->query);
58: 	}
59: 
60: 	// handle the different options of the COPY statement
61: 	if (stmt->options) {
62: 		PGListCell *cell = nullptr;
63: 
64: 		// iterate over each option
65: 		for_each_cell(cell, stmt->options->head) {
66: 			auto *def_elem = reinterpret_cast<PGDefElem *>(cell->data.ptr_value);
67: 			if (StringUtil::Lower(def_elem->defname) == "format") {
68: 				// format specifier: interpret this option
69: 				auto *format_val = (PGValue *)(def_elem->arg);
70: 				if (!format_val || format_val->type != T_PGString) {
71: 					throw ParserException(
72: 					    "Unsupported parameter type for FORMAT: expected e.g. FORMAT 'csv', 'csv_auto'");
73: 				}
74: 				info.format = StringUtil::Lower(format_val->val.str);
75: 				continue;
76: 			}
77: 			// otherwise
78: 			if (info.options.find(def_elem->defname) != info.options.end()) {
79: 				throw ParserException("Unexpected duplicate option \"%s\"", def_elem->defname);
80: 			}
81: 			if (!def_elem->arg) {
82: 				info.options[def_elem->defname] = vector<Value>();
83: 				continue;
84: 			}
85: 			switch (def_elem->arg->type) {
86: 			case T_PGList: {
87: 				auto column_list = (PGList *)(def_elem->arg);
88: 				for (auto c = column_list->head; c != NULL; c = lnext(c)) {
89: 					auto target = (PGResTarget *)(c->data.ptr_value);
90: 					info.options[def_elem->defname].push_back(Value(target->name));
91: 				}
92: 				break;
93: 			}
94: 			case T_PGAStar:
95: 				info.options[def_elem->defname].push_back(Value("*"));
96: 				break;
97: 			default:
98: 				info.options[def_elem->defname].push_back(TransformValue(*((PGValue *)def_elem->arg))->value);
99: 				break;
100: 			}
101: 		}
102: 	}
103: 
104: 	return result;
105: }
106: 
107: } // namespace duckdb
[end of src/parser/transform/statement/transform_copy.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: