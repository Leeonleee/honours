diff --git a/benchmark/benchmark_runner.cpp b/benchmark/benchmark_runner.cpp
index 57c2b5498018..8714e5e20afb 100644
--- a/benchmark/benchmark_runner.cpp
+++ b/benchmark/benchmark_runner.cpp
@@ -281,6 +281,9 @@ ConfigurationError run_benchmarks(const BenchmarkConfiguration &configuration) {
 		if (benchmark_indices.empty()) {
 			return ConfigurationError::BenchmarkNotFound;
 		}
+		std::sort(benchmark_indices.begin(), benchmark_indices.end(), [&](const int a, const int b) -> bool {
+			return benchmarks[a]->name < benchmarks[b]->name;
+		});
 		if (configuration.meta == BenchmarkMetaType::INFO) {
 			// print info of benchmarks
 			for (const auto &benchmark_index : benchmark_indices) {
diff --git a/benchmark/interpreted_benchmark.cpp b/benchmark/interpreted_benchmark.cpp
index b75fcf51578e..566851d0f0a4 100644
--- a/benchmark/interpreted_benchmark.cpp
+++ b/benchmark/interpreted_benchmark.cpp
@@ -168,9 +168,9 @@ void InterpretedBenchmark::LoadBenchmark() {
 					}
 					auto result_splits = StringUtil::Split(line, "\t");
 					if ((int64_t)result_splits.size() != result_column_count) {
-						throw std::runtime_error(reader.FormatException("expected " + to_string(result_column_count) +
+						throw std::runtime_error(reader.FormatException("expected " + to_string(result_splits.size()) +
 						                                                " values but got " +
-						                                                to_string(result_splits.size())));
+						                                                to_string(result_column_count)));
 					}
 					result_values.push_back(move(result_splits));
 				}
diff --git a/benchmark/micro/CMakeLists.txt b/benchmark/micro/CMakeLists.txt
index 1e9eedb1334b..53fff40b31a6 100644
--- a/benchmark/micro/CMakeLists.txt
+++ b/benchmark/micro/CMakeLists.txt
@@ -9,7 +9,6 @@ add_library(
   in.cpp
   multiplications.cpp
   orderby.cpp
-  pointquery.cpp
   indexcreation.cpp
   rangejoin.cpp
   rangequery.cpp
diff --git a/benchmark/micro/index/point_query_with_index.benchmark b/benchmark/micro/index/point_query_with_index.benchmark
new file mode 100644
index 000000000000..cee387c99a3f
--- /dev/null
+++ b/benchmark/micro/index/point_query_with_index.benchmark
@@ -0,0 +1,13 @@
+# name: benchmark/micro/index/point_query_with_index.benchmark
+# description: Point query with an index on randomly ordered data
+# group: [index]
+
+load
+CREATE TABLE integers AS SELECT (i * 9876983769044 % 100000000) AS i, i + 2 AS j FROM range(0, 100000000) t(i);
+CREATE INDEX i_index ON integers using art(i);
+
+run
+SELECT i FROM integers WHERE i=50000 LIMIT 1
+
+result I
+50000
diff --git a/benchmark/micro/index/point_query_without_index.benchmark b/benchmark/micro/index/point_query_without_index.benchmark
new file mode 100644
index 000000000000..6b334e0f8ce0
--- /dev/null
+++ b/benchmark/micro/index/point_query_without_index.benchmark
@@ -0,0 +1,12 @@
+# name: benchmark/micro/index/point_query_without_index.benchmark
+# description: Point query without index on randomly ordered data
+# group: [index]
+
+load
+CREATE TABLE integers AS SELECT (i * 9876983769044 % 100000000) AS i, i + 2 AS j FROM range(0, 100000000) t(i);
+
+run
+SELECT i FROM integers WHERE i=50000 LIMIT 1
+
+result I
+50000
diff --git a/benchmark/micro/index/point_query_without_index_sequential.benchmark b/benchmark/micro/index/point_query_without_index_sequential.benchmark
new file mode 100644
index 000000000000..c5e59c68e8f5
--- /dev/null
+++ b/benchmark/micro/index/point_query_without_index_sequential.benchmark
@@ -0,0 +1,12 @@
+# name: benchmark/micro/index/point_query_without_index_sequential.benchmark
+# description: Point query without on sequentially ordered data
+# group: [index]
+
+load
+CREATE TABLE integers AS SELECT i, i + 2 AS j FROM range(0, 100000000) t(i)
+
+run
+SELECT j FROM integers WHERE i=50000
+
+result I
+50002
diff --git a/benchmark/micro/index/range_query_with_index.benchmark b/benchmark/micro/index/range_query_with_index.benchmark
new file mode 100644
index 000000000000..aed437a5d185
--- /dev/null
+++ b/benchmark/micro/index/range_query_with_index.benchmark
@@ -0,0 +1,13 @@
+# name: benchmark/micro/index/range_query_with_index.benchmark
+# description: Range query with index
+# group: [index]
+
+load
+CREATE TABLE integers AS SELECT i, i + 2 AS j FROM range(0, 100000000) t(i);
+CREATE INDEX i_index ON integers using art(i);
+
+run
+SELECT COUNT(j) FROM integers WHERE i >= 15000100 AND i < 15000200;
+
+result I
+100
diff --git a/benchmark/micro/index/range_query_without_index.benchmark b/benchmark/micro/index/range_query_without_index.benchmark
new file mode 100644
index 000000000000..cd05647fa7f0
--- /dev/null
+++ b/benchmark/micro/index/range_query_without_index.benchmark
@@ -0,0 +1,12 @@
+# name: benchmark/micro/index/point_query_without_index.benchmark
+# description: Range query without index
+# group: [index]
+
+load
+CREATE TABLE integers AS SELECT i, i + 2 AS j FROM range(0, 100000000) t(i);
+
+run
+SELECT COUNT(j) FROM integers WHERE i >= 15000100 AND i < 15000200;
+
+result I
+100
diff --git a/benchmark/micro/index/wide_range_query_with_index.benchmark b/benchmark/micro/index/wide_range_query_with_index.benchmark
new file mode 100644
index 000000000000..9a540320ab8a
--- /dev/null
+++ b/benchmark/micro/index/wide_range_query_with_index.benchmark
@@ -0,0 +1,13 @@
+# name: benchmark/micro/index/wide_range_query_with_index.benchmark
+# description: Wide (non-selective) range query with index
+# group: [index]
+
+load
+CREATE TABLE integers AS SELECT i, i + 2 AS j FROM range(0, 100000000) t(i);
+CREATE INDEX i_index ON integers using art(i);
+
+run
+SELECT COUNT(j) FROM integers WHERE i >= 0 AND i < 15000200;
+
+result I
+15000200
diff --git a/benchmark/micro/index/wide_range_query_without_index.benchmark b/benchmark/micro/index/wide_range_query_without_index.benchmark
new file mode 100644
index 000000000000..af9ba2bb9f6e
--- /dev/null
+++ b/benchmark/micro/index/wide_range_query_without_index.benchmark
@@ -0,0 +1,12 @@
+# name: benchmark/micro/index/wide_range_query_without_index.benchmark
+# description: Wide (non-selective) range query without index
+# group: [index]
+
+load
+CREATE TABLE integers AS SELECT i, i + 2 AS j FROM range(0, 100000000) t(i);
+
+run
+SELECT COUNT(j) FROM integers WHERE i >= 0 AND i < 15000200;
+
+result I
+15000200
diff --git a/benchmark/micro/pointquery.cpp b/benchmark/micro/pointquery.cpp
deleted file mode 100644
index dc720d271d2e..000000000000
--- a/benchmark/micro/pointquery.cpp
+++ /dev/null
@@ -1,89 +0,0 @@
-#include "benchmark_runner.hpp"
-#include "duckdb_benchmark_macro.hpp"
-#include "duckdb/main/appender.hpp"
-
-#include <random>
-
-using namespace duckdb;
-using namespace std;
-
-#define POINT_QUERY_ROW_COUNT 100000000
-#define POINT_QUERY_ENTRY 50000
-
-DUCKDB_BENCHMARK(PointQueryWithoutIndex, "[micro]")
-virtual void Load(DuckDBBenchmarkState *state) {
-	state->conn.Query("CREATE TABLE integers(i INTEGER, j INTEGER);");
-	Appender appender(state->conn, "integers"); // insert the elements into the database
-	for (size_t i = 0; i < POINT_QUERY_ROW_COUNT; i++) {
-		appender.BeginRow();
-		appender.Append<int32_t>(i);
-		appender.Append<int32_t>(i + 2);
-		appender.EndRow();
-	}
-}
-
-virtual string GetQuery() {
-	return "SELECT j FROM integers WHERE i=" + to_string(POINT_QUERY_ENTRY);
-}
-
-virtual string VerifyResult(QueryResult *result) {
-	if (!result->success) {
-		return result->error;
-	}
-	auto &materialized = (MaterializedQueryResult &)*result;
-	if (materialized.collection.count != 1) {
-		return "Incorrect amount of rows in result";
-	}
-	if (materialized.names.size() != 1) {
-		return "Incorrect amount of columns";
-	}
-	if (materialized.GetValue<int32_t>(0, 0) != POINT_QUERY_ENTRY + 2) {
-		return "Incorrect result returned, expected " + to_string(POINT_QUERY_ENTRY + 2);
-	}
-	return string();
-}
-
-virtual string BenchmarkInfo() {
-	return StringUtil::Format("Runs the following query: \"" + GetQuery() + "\" without an index");
-}
-FINISH_BENCHMARK(PointQueryWithoutIndex)
-
-DUCKDB_BENCHMARK(PointQueryWithIndexART, "[micro]")
-virtual void Load(DuckDBBenchmarkState *state) {
-	state->conn.Query("CREATE TABLE integers(i INTEGER, j INTEGER);");
-	Appender appender(state->conn, "integers"); // insert the elements into the database
-	for (size_t i = 0; i < POINT_QUERY_ROW_COUNT; i++) {
-		appender.BeginRow();
-		appender.Append<int32_t>(i);
-		appender.Append<int32_t>(i + 2);
-		appender.EndRow();
-	}
-	appender.Close();
-	state->conn.Query("CREATE INDEX i_index ON integers using art(i)");
-}
-
-virtual string GetQuery() {
-	return "SELECT j FROM integers WHERE i=" + to_string(POINT_QUERY_ENTRY);
-}
-
-virtual string VerifyResult(QueryResult *result) {
-	if (!result->success) {
-		return result->error;
-	}
-	auto &materialized = (MaterializedQueryResult &)*result;
-	if (materialized.collection.count != 1) {
-		return "Incorrect amount of rows in result";
-	}
-	if (materialized.names.size() != 1) {
-		return "Incorrect amount of columns";
-	}
-	if (materialized.GetValue<int32_t>(0, 0) != POINT_QUERY_ENTRY + 2) {
-		return "Incorrect result returned, expected " + to_string(POINT_QUERY_ENTRY + 2);
-	}
-	return string();
-}
-
-virtual string BenchmarkInfo() {
-	return StringUtil::Format("Runs the following query: \"" + GetQuery() + "\" with an ART index");
-}
-FINISH_BENCHMARK(PointQueryWithIndexART)
diff --git a/extension/parquet/parquet-extension.cpp b/extension/parquet/parquet-extension.cpp
index f3024df2c7f4..9065df20e782 100644
--- a/extension/parquet/parquet-extension.cpp
+++ b/extension/parquet/parquet-extension.cpp
@@ -845,8 +845,9 @@ void ParquetScanFunctionData::ReadChunk(DataChunk &output) {
 class ParquetScanFunction : public TableFunction {
 public:
 	ParquetScanFunction()
-	    : TableFunction("parquet_scan", {LogicalType::VARCHAR}, parquet_scan_bind, parquet_scan_function, nullptr) {
-		supports_projection = true;
+	    : TableFunction("parquet_scan", {LogicalType::VARCHAR}, parquet_scan_function, parquet_scan_bind,
+	                    parquet_scan_init) {
+		projection_pushdown = true;
 	}
 
 	static unique_ptr<FunctionData> ReadParquetHeader(string file_name, vector<LogicalType> &return_types,
@@ -988,6 +989,14 @@ class ParquetScanFunction : public TableFunction {
 		return ReadParquetHeader(file_name, return_types, names);
 	}
 
+	static unique_ptr<FunctionOperatorData>
+	parquet_scan_init(ClientContext &context, const FunctionData *bind_data, OperatorTaskInfo *task_info,
+	                  vector<column_t> &column_ids, unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+		auto &data = (ParquetScanFunctionData &)*bind_data;
+		data.column_ids = column_ids;
+		return nullptr;
+	}
+
 	static unique_ptr<GlobalFunctionData> parquet_read_initialize(ClientContext &context, FunctionData &fdata) {
 		return make_unique<GlobalFunctionData>();
 	}
@@ -998,9 +1007,9 @@ class ParquetScanFunction : public TableFunction {
 		data.ReadChunk(output);
 	}
 
-	static void parquet_scan_function(ClientContext &context, vector<Value> &input, DataChunk &output,
-	                                  FunctionData *dataptr) {
-		auto &data = *((ParquetScanFunctionData *)dataptr);
+	static void parquet_scan_function(ClientContext &context, const FunctionData *bind_data,
+	                                  FunctionOperatorData *operator_state, DataChunk &output) {
+		auto &data = (ParquetScanFunctionData &)*bind_data;
 		data.ReadChunk(output);
 	}
 };
diff --git a/extension/tpch/tpch-extension.cpp b/extension/tpch/tpch-extension.cpp
index 6fee2e881d77..5dc3e0b6e5e6 100644
--- a/extension/tpch/tpch-extension.cpp
+++ b/extension/tpch/tpch-extension.cpp
@@ -41,8 +41,9 @@ static unique_ptr<FunctionData> dbgen_bind(ClientContext &context, vector<Value>
 	return move(result);
 }
 
-static void dbgen_function(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {
-	auto &data = ((DBGenFunctionData &)*dataptr);
+static void dbgen_function(ClientContext &context, const FunctionData *bind_data, FunctionOperatorData *operator_state,
+                           DataChunk &output) {
+	auto &data = (DBGenFunctionData &)*bind_data;
 	if (data.finished) {
 		return;
 	}
@@ -60,7 +61,7 @@ void TPCHExtension::Load(DuckDB &db) {
 	Connection con(db);
 	con.BeginTransaction();
 
-	TableFunction dbgen_func("dbgen", {}, dbgen_bind, dbgen_function);
+	TableFunction dbgen_func("dbgen", {}, dbgen_function, dbgen_bind);
 	dbgen_func.named_parameters["sf"] = LogicalType::DOUBLE;
 	dbgen_func.named_parameters["overwrite"] = LogicalType::BOOLEAN;
 	dbgen_func.named_parameters["schema"] = LogicalType::VARCHAR;
diff --git a/src/common/enums/logical_operator_type.cpp b/src/common/enums/logical_operator_type.cpp
index df49a93ce3ea..0db2fe735c96 100644
--- a/src/common/enums/logical_operator_type.cpp
+++ b/src/common/enums/logical_operator_type.cpp
@@ -65,8 +65,8 @@ string LogicalOperatorToString(LogicalOperatorType type) {
 		return "UPDATE";
 	case LogicalOperatorType::PREPARE:
 		return "PREPARE";
-	case LogicalOperatorType::TABLE_FUNCTION:
-		return "TABLE_FUNCTION";
+	case LogicalOperatorType::DUMMY_SCAN:
+		return "DUMMY_SCAN";
 	case LogicalOperatorType::CREATE_INDEX:
 		return "CREATE_INDEX";
 	case LogicalOperatorType::CREATE_TABLE:
@@ -77,8 +77,6 @@ string LogicalOperatorToString(LogicalOperatorType type) {
 		return "EXECUTE";
 	case LogicalOperatorType::VACUUM:
 		return "VACUUM";
-	case LogicalOperatorType::INDEX_SCAN:
-		return "INDEX_SCAN";
 	case LogicalOperatorType::RECURSIVE_CTE:
 		return "REC_CTE";
 	case LogicalOperatorType::CTE_REF:
diff --git a/src/common/enums/physical_operator_type.cpp b/src/common/enums/physical_operator_type.cpp
index 835b47999ce5..2caf45511585 100644
--- a/src/common/enums/physical_operator_type.cpp
+++ b/src/common/enums/physical_operator_type.cpp
@@ -8,12 +8,10 @@ string PhysicalOperatorToString(PhysicalOperatorType type) {
 	switch (type) {
 	case PhysicalOperatorType::LEAF:
 		return "LEAF";
+	case PhysicalOperatorType::TABLE_SCAN:
+		return "TABLE_SCAN";
 	case PhysicalOperatorType::DUMMY_SCAN:
 		return "DUMMY_SCAN";
-	case PhysicalOperatorType::SEQ_SCAN:
-		return "SEQ_SCAN";
-	case PhysicalOperatorType::INDEX_SCAN:
-		return "INDEX_SCAN";
 	case PhysicalOperatorType::CHUNK_SCAN:
 		return "CHUNK_SCAN";
 	case PhysicalOperatorType::DELIM_SCAN:
@@ -76,8 +74,6 @@ string PhysicalOperatorToString(PhysicalOperatorType type) {
 		return "EXPORT_EXTERNAL_FILE";
 	case PhysicalOperatorType::EMPTY_RESULT:
 		return "EMPTY_RESULT";
-	case PhysicalOperatorType::TABLE_FUNCTION:
-		return "TABLE_FUNCTION";
 	case PhysicalOperatorType::CREATE:
 		return "CREATE";
 	case PhysicalOperatorType::CREATE_INDEX:
diff --git a/src/execution/index/art/art.cpp b/src/execution/index/art/art.cpp
index f9b6687620eb..7fb36ea39443 100644
--- a/src/execution/index/art/art.cpp
+++ b/src/execution/index/art/art.cpp
@@ -49,18 +49,18 @@ bool ART::LeafMatches(Node *node, Key &key, unsigned depth) {
 	return true;
 }
 
-unique_ptr<IndexScanState> ART::InitializeScanSinglePredicate(Transaction &transaction, vector<column_t> column_ids,
-                                                              Value value, ExpressionType expression_type) {
-	auto result = make_unique<ARTIndexScanState>(column_ids);
+unique_ptr<IndexScanState> ART::InitializeScanSinglePredicate(Transaction &transaction, Value value,
+                                                              ExpressionType expression_type) {
+	auto result = make_unique<ARTIndexScanState>();
 	result->values[0] = value;
 	result->expressions[0] = expression_type;
 	return move(result);
 }
 
-unique_ptr<IndexScanState> ART::InitializeScanTwoPredicates(Transaction &transaction, vector<column_t> column_ids,
-                                                            Value low_value, ExpressionType low_expression_type,
-                                                            Value high_value, ExpressionType high_expression_type) {
-	auto result = make_unique<ARTIndexScanState>(column_ids);
+unique_ptr<IndexScanState> ART::InitializeScanTwoPredicates(Transaction &transaction, Value low_value,
+                                                            ExpressionType low_expression_type, Value high_value,
+                                                            ExpressionType high_expression_type) {
+	auto result = make_unique<ARTIndexScanState>();
 	result->values[0] = low_value;
 	result->expressions[0] = low_expression_type;
 	result->values[1] = high_value;
@@ -423,16 +423,20 @@ static unique_ptr<Key> CreateKey(ART &art, PhysicalType type, Value &value) {
 	}
 }
 
-void ART::SearchEqual(vector<row_t> &result_ids, ARTIndexScanState *state) {
-	unique_ptr<Key> key = CreateKey(*this, types[0], state->values[0]);
+bool ART::SearchEqual(ARTIndexScanState *state, idx_t max_count, vector<row_t> &result_ids) {
+	auto key = CreateKey(*this, types[0], state->values[0]);
 	auto leaf = static_cast<Leaf *>(Lookup(tree, *key, 0));
 	if (!leaf) {
-		return;
+		return true;
+	}
+	if (leaf->num_elements > max_count) {
+		return false;
 	}
 	for (idx_t i = 0; i < leaf->num_elements; i++) {
 		row_t row_id = leaf->GetRowId(i);
 		result_ids.push_back(row_id);
 	}
+	return true;
 }
 
 Node *ART::Lookup(unique_ptr<Node> &node, Key &key, unsigned depth) {
@@ -475,7 +479,7 @@ Node *ART::Lookup(unique_ptr<Node> &node, Key &key, unsigned depth) {
 // Iterator scans
 //===--------------------------------------------------------------------===//
 template <bool HAS_BOUND, bool INCLUSIVE>
-void ART::IteratorScan(ARTIndexScanState *state, Iterator *it, vector<row_t> &result_ids, Key *bound) {
+bool ART::IteratorScan(ARTIndexScanState *state, Iterator *it, Key *bound, idx_t max_count, vector<row_t> &result_ids) {
 	bool has_next;
 	do {
 		if (HAS_BOUND) {
@@ -490,12 +494,17 @@ void ART::IteratorScan(ARTIndexScanState *state, Iterator *it, vector<row_t> &re
 				}
 			}
 		}
+		if (result_ids.size() + it->node->num_elements > max_count) {
+			// adding these elements would exceed the max count
+			return false;
+		}
 		for (idx_t i = 0; i < it->node->num_elements; i++) {
 			row_t row_id = it->node->GetRowId(i);
 			result_ids.push_back(row_id);
 		}
 		has_next = ART::IteratorNext(*it);
 	} while (has_next);
+	return true;
 }
 
 bool ART::IteratorNext(Iterator &it) {
@@ -618,7 +627,7 @@ bool ART::Bound(unique_ptr<Node> &n, Key &key, Iterator &it, bool inclusive) {
 	}
 }
 
-void ART::SearchGreater(vector<row_t> &result_ids, ARTIndexScanState *state, bool inclusive) {
+bool ART::SearchGreater(ARTIndexScanState *state, bool inclusive, idx_t max_count, vector<row_t> &result_ids) {
 	Iterator *it = &state->iterator;
 	auto key = CreateKey(*this, types[0], state->values[0]);
 
@@ -627,13 +636,13 @@ void ART::SearchGreater(vector<row_t> &result_ids, ARTIndexScanState *state, boo
 	if (!it->start) {
 		bool found = ART::Bound(tree, *key, *it, inclusive);
 		if (!found) {
-			return;
+			return true;
 		}
 		it->start = true;
 	}
 	// after that we continue the scan; we don't need to check the bounds as any value following this value is
 	// automatically bigger and hence satisfies our predicate
-	IteratorScan<false, false>(state, it, result_ids, nullptr);
+	return IteratorScan<false, false>(state, it, nullptr, max_count, result_ids);
 }
 
 //===--------------------------------------------------------------------===//
@@ -675,9 +684,9 @@ static Leaf &FindMinimum(Iterator &it, Node &node) {
 	return FindMinimum(it, *next);
 }
 
-void ART::SearchLess(vector<row_t> &result_ids, ARTIndexScanState *state, bool inclusive) {
+bool ART::SearchLess(ARTIndexScanState *state, bool inclusive, idx_t max_count, vector<row_t> &result_ids) {
 	if (!tree) {
-		return;
+		return true;
 	}
 
 	Iterator *it = &state->iterator;
@@ -688,23 +697,23 @@ void ART::SearchLess(vector<row_t> &result_ids, ARTIndexScanState *state, bool i
 		auto &minimum = FindMinimum(state->iterator, *tree);
 		// early out min value higher than upper bound query
 		if (*minimum.value > *upper_bound) {
-			return;
+			return true;
 		}
 		it->start = true;
 	}
 	// now continue the scan until we reach the upper bound
 	if (inclusive) {
-		IteratorScan<true, true>(state, it, result_ids, upper_bound.get());
+		return IteratorScan<true, true>(state, it, upper_bound.get(), max_count, result_ids);
 	} else {
-		IteratorScan<true, false>(state, it, result_ids, upper_bound.get());
+		return IteratorScan<true, false>(state, it, upper_bound.get(), max_count, result_ids);
 	}
 }
 
 //===--------------------------------------------------------------------===//
 // Closed Range Query
 //===--------------------------------------------------------------------===//
-void ART::SearchCloseRange(vector<row_t> &result_ids, ARTIndexScanState *state, bool left_inclusive,
-                           bool right_inclusive) {
+bool ART::SearchCloseRange(ARTIndexScanState *state, bool left_inclusive, bool right_inclusive, idx_t max_count,
+                           vector<row_t> &result_ids) {
 	auto lower_bound = CreateKey(*this, types[0], state->values[0]);
 	auto upper_bound = CreateKey(*this, types[0], state->values[1]);
 	Iterator *it = &state->iterator;
@@ -712,88 +721,74 @@ void ART::SearchCloseRange(vector<row_t> &result_ids, ARTIndexScanState *state,
 	if (!it->start) {
 		bool found = ART::Bound(tree, *lower_bound, *it, left_inclusive);
 		if (!found) {
-			return;
+			return true;
 		}
 		it->start = true;
 	}
 	// now continue the scan until we reach the upper bound
 	if (right_inclusive) {
-		IteratorScan<true, true>(state, it, result_ids, upper_bound.get());
+		return IteratorScan<true, true>(state, it, upper_bound.get(), max_count, result_ids);
 	} else {
-		IteratorScan<true, false>(state, it, result_ids, upper_bound.get());
+		return IteratorScan<true, false>(state, it, upper_bound.get(), max_count, result_ids);
 	}
 }
 
-void ART::Scan(Transaction &transaction, DataTable &table, TableIndexScanState &table_state, DataChunk &result) {
-	auto state = (ARTIndexScanState *)table_state.index_state.get();
-
-	// scan the index
-	if (!state->checked) {
-		vector<row_t> result_ids;
-		assert(state->values[0].type().InternalType() == types[0]);
-
-		if (state->values[1].is_null) {
-			lock_guard<mutex> l(lock);
-			// single predicate
-			switch (state->expressions[0]) {
-			case ExpressionType::COMPARE_EQUAL:
-				SearchEqual(result_ids, state);
-				break;
-			case ExpressionType::COMPARE_GREATERTHANOREQUALTO:
-				SearchGreater(result_ids, state, true);
-				break;
-			case ExpressionType::COMPARE_GREATERTHAN:
-				SearchGreater(result_ids, state, false);
-				break;
-			case ExpressionType::COMPARE_LESSTHANOREQUALTO:
-				SearchLess(result_ids, state, true);
-				break;
-			case ExpressionType::COMPARE_LESSTHAN:
-				SearchLess(result_ids, state, false);
-				break;
-			default:
-				throw NotImplementedException("Operation not implemented");
-			}
-		} else {
-			lock_guard<mutex> l(lock);
-			// two predicates
-			assert(state->values[1].type().InternalType() == types[0]);
-			bool left_inclusive = state->expressions[0] == ExpressionType ::COMPARE_GREATERTHANOREQUALTO;
-			bool right_inclusive = state->expressions[1] == ExpressionType ::COMPARE_LESSTHANOREQUALTO;
-			SearchCloseRange(result_ids, state, left_inclusive, right_inclusive);
-		}
-		state->checked = true;
+bool ART::Scan(Transaction &transaction, DataTable &table, IndexScanState &table_state, idx_t max_count,
+               vector<row_t> &result_ids) {
+	auto state = (ARTIndexScanState *)&table_state;
 
-		if (result_ids.size() == 0) {
-			return;
-		}
-
-		// sort the row ids
-		sort(result_ids.begin(), result_ids.end());
-		// duplicate eliminate the row ids and append them to the row ids of the state
-		state->result_ids.reserve(result_ids.size());
+	assert(state->values[0].type().InternalType() == types[0]);
 
-		state->result_ids.push_back(result_ids[0]);
-		for (idx_t i = 1; i < result_ids.size(); i++) {
-			if (result_ids[i] != result_ids[i - 1]) {
-				state->result_ids.push_back(result_ids[i]);
-			}
+	vector<row_t> row_ids;
+	bool success = true;
+	if (state->values[1].is_null) {
+		lock_guard<mutex> l(lock);
+		// single predicate
+		switch (state->expressions[0]) {
+		case ExpressionType::COMPARE_EQUAL:
+			success = SearchEqual(state, max_count, row_ids);
+			break;
+		case ExpressionType::COMPARE_GREATERTHANOREQUALTO:
+			success = SearchGreater(state, true, max_count, row_ids);
+			break;
+		case ExpressionType::COMPARE_GREATERTHAN:
+			success = SearchGreater(state, false, max_count, row_ids);
+			break;
+		case ExpressionType::COMPARE_LESSTHANOREQUALTO:
+			success = SearchLess(state, true, max_count, row_ids);
+			break;
+		case ExpressionType::COMPARE_LESSTHAN:
+			success = SearchLess(state, false, max_count, row_ids);
+			break;
+		default:
+			throw NotImplementedException("Operation not implemented");
 		}
+	} else {
+		lock_guard<mutex> l(lock);
+		// two predicates
+		assert(state->values[1].type().InternalType() == types[0]);
+		bool left_inclusive = state->expressions[0] == ExpressionType ::COMPARE_GREATERTHANOREQUALTO;
+		bool right_inclusive = state->expressions[1] == ExpressionType ::COMPARE_LESSTHANOREQUALTO;
+		success = SearchCloseRange(state, left_inclusive, right_inclusive, max_count, row_ids);
+	}
+	if (!success) {
+		return false;
 	}
-
-	if (state->result_index >= state->result_ids.size()) {
-		// exhausted all row ids
-		return;
+	if (row_ids.size() == 0) {
+		return true;
 	}
+	// sort the row ids
+	sort(row_ids.begin(), row_ids.end());
+	// duplicate eliminate the row ids and append them to the row ids of the state
+	result_ids.reserve(row_ids.size());
 
-	// create a vector pointing to the current set of row ids
-	Vector row_identifiers(LOGICAL_ROW_TYPE, (data_ptr_t)&state->result_ids[state->result_index]);
-	idx_t scan_count = MinValue<idx_t>(STANDARD_VECTOR_SIZE, state->result_ids.size() - state->result_index);
-
-	// fetch the actual values from the base table
-	table.Fetch(transaction, result, state->column_ids, row_identifiers, scan_count, table_state);
-
-	// move to the next set of row ids
-	state->result_index += scan_count;
+	result_ids.push_back(row_ids[0]);
+	for (idx_t i = 1; i < row_ids.size(); i++) {
+		if (row_ids[i] != row_ids[i - 1]) {
+			result_ids.push_back(row_ids[i]);
+		}
+	}
+	return true;
 }
+
 } // namespace duckdb
diff --git a/src/execution/operator/scan/CMakeLists.txt b/src/execution/operator/scan/CMakeLists.txt
index c278bd6ab9c4..bac1efb41958 100644
--- a/src/execution/operator/scan/CMakeLists.txt
+++ b/src/execution/operator/scan/CMakeLists.txt
@@ -1,12 +1,11 @@
-add_library_unity(duckdb_operator_scan
-                  OBJECT
-                  physical_chunk_scan.cpp
-                  physical_dummy_scan.cpp
-                  physical_empty_result.cpp
-                  physical_expression_scan.cpp
-                  physical_index_scan.cpp
-                  physical_table_function.cpp
-                  physical_table_scan.cpp)
+add_library_unity(
+  duckdb_operator_scan
+  OBJECT
+  physical_chunk_scan.cpp
+  physical_dummy_scan.cpp
+  physical_empty_result.cpp
+  physical_expression_scan.cpp
+  physical_table_scan.cpp)
 set(ALL_OBJECT_FILES
     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_operator_scan>
     PARENT_SCOPE)
diff --git a/src/execution/operator/scan/physical_index_scan.cpp b/src/execution/operator/scan/physical_index_scan.cpp
deleted file mode 100644
index 76dd8d6e6a11..000000000000
--- a/src/execution/operator/scan/physical_index_scan.cpp
+++ /dev/null
@@ -1,66 +0,0 @@
-#include "duckdb/execution/operator/scan/physical_index_scan.hpp"
-
-#include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
-#include "duckdb/transaction/transaction.hpp"
-
-using namespace std;
-
-namespace duckdb {
-
-class PhysicalIndexScanOperatorState : public PhysicalOperatorState {
-public:
-	PhysicalIndexScanOperatorState() : PhysicalOperatorState(nullptr), initialized(false) {
-	}
-
-	bool initialized;
-	TableIndexScanState scan_state;
-};
-
-void PhysicalIndexScan::GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state_) {
-	auto state = reinterpret_cast<PhysicalIndexScanOperatorState *>(state_);
-	if (column_ids.size() == 0) {
-		return;
-	}
-
-	auto &transaction = Transaction::GetTransaction(context.client);
-	if (!state->initialized) {
-		// initialize the scan state of the index
-		if (low_index && high_index) {
-			// two predicates
-			table.InitializeIndexScan(transaction, state->scan_state, index, low_value, low_expression_type, high_value,
-			                          high_expression_type, column_ids);
-		} else {
-			// single predicate
-			Value value;
-			ExpressionType type;
-			if (low_index) {
-				// > or >=
-				value = low_value;
-				type = low_expression_type;
-			} else if (high_index) {
-				// < or <=
-				value = high_value;
-				type = high_expression_type;
-			} else {
-				// equality
-				assert(equal_index);
-				value = equal_value;
-				type = ExpressionType::COMPARE_EQUAL;
-			}
-			table.InitializeIndexScan(transaction, state->scan_state, index, value, type, column_ids);
-		}
-		state->initialized = true;
-	}
-	// scan the index
-	table.IndexScan(transaction, chunk, state->scan_state);
-}
-
-string PhysicalIndexScan::ExtraRenderInformation() const {
-	return tableref.name + "[" + low_value.ToString() + "]";
-}
-
-unique_ptr<PhysicalOperatorState> PhysicalIndexScan::GetOperatorState() {
-	return make_unique<PhysicalIndexScanOperatorState>();
-}
-
-} // namespace duckdb
diff --git a/src/execution/operator/scan/physical_table_function.cpp b/src/execution/operator/scan/physical_table_function.cpp
deleted file mode 100644
index 5525dc9e2585..000000000000
--- a/src/execution/operator/scan/physical_table_function.cpp
+++ /dev/null
@@ -1,28 +0,0 @@
-#include "duckdb/execution/operator/scan/physical_table_function.hpp"
-
-#include "duckdb/catalog/catalog_entry/schema_catalog_entry.hpp"
-#include "duckdb/catalog/catalog_entry/table_function_catalog_entry.hpp"
-#include "duckdb/execution/expression_executor.hpp"
-#include "duckdb/planner/expression/bound_function_expression.hpp"
-
-using namespace std;
-
-namespace duckdb {
-
-void PhysicalTableFunction::GetChunkInternal(ExecutionContext &context, DataChunk &chunk,
-                                             PhysicalOperatorState *state) {
-	// run main code
-	function.function(context.client, parameters, chunk, bind_data.get());
-	if (chunk.size() == 0) {
-		// finished, call clean up
-		if (function.final) {
-			function.final(context.client, bind_data.get());
-		}
-	}
-}
-
-string PhysicalTableFunction::ExtraRenderInformation() const {
-	return function.name;
-}
-
-} // namespace duckdb
diff --git a/src/execution/operator/scan/physical_table_scan.cpp b/src/execution/operator/scan/physical_table_scan.cpp
index c972f629a0ed..e659f072aba8 100644
--- a/src/execution/operator/scan/physical_table_scan.cpp
+++ b/src/execution/operator/scan/physical_table_scan.cpp
@@ -14,87 +14,65 @@ namespace duckdb {
 
 class PhysicalTableScanOperatorState : public PhysicalOperatorState {
 public:
-	PhysicalTableScanOperatorState(Expression &expr)
-	    : PhysicalOperatorState(nullptr), initialized(false), executor(expr) {
-	}
 	PhysicalTableScanOperatorState() : PhysicalOperatorState(nullptr), initialized(false) {
 	}
+
+	unique_ptr<FunctionOperatorData> operator_data;
 	//! Whether or not the scan has been initialized
 	bool initialized;
-	//! The current position in the scan
-	TableScanState scan_state;
-	//! Execute filters inside the table
-	ExpressionExecutor executor;
 };
 
-PhysicalTableScan::PhysicalTableScan(vector<LogicalType> types, TableCatalogEntry &tableref, DataTable &table,
-                                     vector<column_t> column_ids, vector<unique_ptr<Expression>> filter,
+PhysicalTableScan::PhysicalTableScan(vector<LogicalType> types, TableFunction function_,
+                                     unique_ptr<FunctionData> bind_data_, vector<column_t> column_ids,
                                      unordered_map<idx_t, vector<TableFilter>> table_filters)
-    : PhysicalOperator(PhysicalOperatorType::SEQ_SCAN, move(types)), tableref(tableref), table(table),
-      column_ids(move(column_ids)), table_filters(move(table_filters)) {
-	if (filter.size() > 1) {
-		//! create a big AND out of the expressions
-		auto conjunction = make_unique<BoundConjunctionExpression>(ExpressionType::CONJUNCTION_AND);
-		for (auto &expr : filter) {
-			conjunction->children.push_back(move(expr));
-		}
-		expression = move(conjunction);
-	} else if (filter.size() == 1) {
-		expression = move(filter[0]);
-	}
+    : PhysicalOperator(PhysicalOperatorType::TABLE_SCAN, move(types)), function(move(function_)),
+      bind_data(move(bind_data_)), column_ids(move(column_ids)), table_filters(move(table_filters)) {
 }
 
-class TableScanTaskInfo : public OperatorTaskInfo {
-public:
-	TableScanState state;
-};
-
 void PhysicalTableScan::ParallelScanInfo(ClientContext &context,
                                          std::function<void(unique_ptr<OperatorTaskInfo>)> callback) {
 	// generate parallel scans
-	table.InitializeParallelScan(context, column_ids, &table_filters, [&](TableScanState state) {
-		auto task = make_unique<TableScanTaskInfo>();
-		task->state = move(state);
-		callback(move(task));
-	});
+	if (function.parallel_tasks) {
+		function.parallel_tasks(context, bind_data.get(), column_ids, table_filters, callback);
+	}
 }
 
 void PhysicalTableScan::GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state_) {
-	auto state = reinterpret_cast<PhysicalTableScanOperatorState *>(state_);
+	auto &state = (PhysicalTableScanOperatorState &)*state_;
 	if (column_ids.empty()) {
 		return;
 	}
-	auto &transaction = Transaction::GetTransaction(context.client);
-	if (!state->initialized) {
-		auto &task = context.task;
-		auto task_info = task.task_info.find(this);
-		if (task_info != task.task_info.end()) {
-			// task specific limitations: scan the part indicated by the task
-			auto &info = (TableScanTaskInfo &)*task_info->second;
-			state->scan_state = move(info.state);
-		} else {
-			// no task specific limitations for the scan: scan the entire table
-			table.InitializeScan(transaction, state->scan_state, column_ids, &table_filters);
+	if (!state.initialized) {
+		if (function.init) {
+			auto &task = context.task;
+			auto task_info = task.task_info.find(this);
+			if (task_info != task.task_info.end()) {
+				// task specific limitations: pass the task information to the init function
+				state.operator_data =
+				    function.init(context.client, bind_data.get(), task_info->second.get(), column_ids, table_filters);
+			} else {
+				// no task specific limitations
+				state.operator_data =
+				    function.init(context.client, bind_data.get(), nullptr, column_ids, table_filters);
+			}
 		}
-		state->initialized = true;
+		state.initialized = true;
+	}
+	function.function(context.client, bind_data.get(), state.operator_data.get(), chunk);
+	if (chunk.size() == 0 && function.cleanup) {
+		function.cleanup(context.client, bind_data.get(), state.operator_data.get());
 	}
-	table.Scan(transaction, chunk, state->scan_state, column_ids, table_filters);
 }
 
-string PhysicalTableScan::ExtraRenderInformation() const {
-	if (expression) {
-		return tableref.name + " " + expression->ToString();
-	} else {
-		return tableref.name;
+string PhysicalTableScan::ToString(idx_t depth) const {
+	if (function.to_string) {
+		return string(depth * 4, ' ') + function.to_string(bind_data.get());
 	}
+	return PhysicalOperator::ToString(depth);
 }
 
 unique_ptr<PhysicalOperatorState> PhysicalTableScan::GetOperatorState() {
-	if (expression) {
-		return make_unique<PhysicalTableScanOperatorState>(*expression);
-	} else {
-		return make_unique<PhysicalTableScanOperatorState>();
-	}
+	return make_unique<PhysicalTableScanOperatorState>();
 }
 
 } // namespace duckdb
diff --git a/src/execution/physical_plan/CMakeLists.txt b/src/execution/physical_plan/CMakeLists.txt
index 8b78a540aeba..41262888d9ec 100644
--- a/src/execution/physical_plan/CMakeLists.txt
+++ b/src/execution/physical_plan/CMakeLists.txt
@@ -15,13 +15,13 @@ add_library_unity(
   plan_delim_get.cpp
   plan_delim_join.cpp
   plan_distinct.cpp
+  plan_dummy_scan.cpp
   plan_empty_result.cpp
   plan_execute.cpp
   plan_explain.cpp
   plan_export.cpp
   plan_filter.cpp
   plan_get.cpp
-  plan_index_scan.cpp
   plan_insert.cpp
   plan_limit.cpp
   plan_order.cpp
@@ -30,7 +30,6 @@ add_library_unity(
   plan_projection.cpp
   plan_set_operation.cpp
   plan_simple.cpp
-  plan_table_function.cpp
   plan_top_n.cpp
   plan_update.cpp
   plan_window.cpp
diff --git a/src/execution/physical_plan/plan_dummy_scan.cpp b/src/execution/physical_plan/plan_dummy_scan.cpp
new file mode 100644
index 000000000000..56fc4f209843
--- /dev/null
+++ b/src/execution/physical_plan/plan_dummy_scan.cpp
@@ -0,0 +1,13 @@
+#include "duckdb/execution/operator/scan/physical_dummy_scan.hpp"
+#include "duckdb/execution/physical_plan_generator.hpp"
+#include "duckdb/planner/operator/logical_dummy_scan.hpp"
+
+namespace duckdb {
+using namespace std;
+
+unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalDummyScan &op) {
+	assert(op.children.size() == 0);
+	return make_unique<PhysicalDummyScan>(op.types);
+}
+
+} // namespace duckdb
diff --git a/src/execution/physical_plan/plan_get.cpp b/src/execution/physical_plan/plan_get.cpp
index c3eb801d831c..53b8bea9ecf3 100644
--- a/src/execution/physical_plan/plan_get.cpp
+++ b/src/execution/physical_plan/plan_get.cpp
@@ -1,34 +1,82 @@
-#include "duckdb/execution/operator/scan/physical_dummy_scan.hpp"
+#include "duckdb/execution/operator/projection/physical_projection.hpp"
 #include "duckdb/execution/operator/scan/physical_table_scan.hpp"
+#include "duckdb/planner/expression/bound_constant_expression.hpp"
+#include "duckdb/planner/expression/bound_reference_expression.hpp"
 #include "duckdb/execution/physical_plan_generator.hpp"
 #include "duckdb/planner/operator/logical_get.hpp"
+#include "duckdb/function/table/table_scan.hpp"
 
 namespace duckdb {
 using namespace std;
 
 unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalGet &op) {
 	assert(op.children.empty());
+
+	// create the table filter map
 	unordered_map<idx_t, vector<TableFilter>> table_filter_umap;
-	if (!op.table) {
-		return make_unique<PhysicalDummyScan>(op.types);
-	} else {
-		for (auto &tableFilter : op.tableFilters) {
+	for (auto &tableFilter : op.tableFilters) {
+		// find the relative column index from the absolute column index into the table
+		idx_t column_index = INVALID_INDEX;
+		for (idx_t i = 0; i < op.column_ids.size(); i++) {
+			if (tableFilter.column_index == op.column_ids[i]) {
+				column_index = i;
+				break;
+			}
+		}
+		if (column_index == INVALID_INDEX) {
+			throw InternalException("Could not find column index for table filter");
+		}
+		tableFilter.column_index = column_index;
+		auto filter = table_filter_umap.find(column_index);
+		if (filter != table_filter_umap.end()) {
+			filter->second.push_back(tableFilter);
+		} else {
+			table_filter_umap.insert(make_pair(column_index, vector<TableFilter>{tableFilter}));
+		}
+	}
+
+	if (op.function.dependency) {
+		op.function.dependency(dependencies, op.bind_data.get());
+	}
+	// create the table scan node
+	if (!op.function.projection_pushdown) {
+		// function does not support projection pushdown
+		auto node = make_unique<PhysicalTableScan>(op.returned_types, op.function, move(op.bind_data), op.column_ids,
+		                                           move(table_filter_umap));
+		// first check if an additional projection is necessary
+		if (op.column_ids.size() == op.returned_types.size()) {
+			bool projection_necessary = false;
 			for (idx_t i = 0; i < op.column_ids.size(); i++) {
-				if (tableFilter.column_index == op.column_ids[i]) {
-					tableFilter.column_index = i;
-					auto filter = table_filter_umap.find(i);
-					if (filter != table_filter_umap.end()) {
-						filter->second.push_back(tableFilter);
-					} else {
-						table_filter_umap.insert(make_pair(i, vector<TableFilter>{tableFilter}));
-					}
+				if (op.column_ids[i] != i) {
+					projection_necessary = true;
 					break;
 				}
 			}
+			if (!projection_necessary) {
+				// a projection is not necessary if all columns have been requested in-order
+				// in that case we just return the node
+				return move(node);
+			}
 		}
-		dependencies.insert(op.table);
-		return make_unique<PhysicalTableScan>(op.types, *op.table, *op.table->storage, op.column_ids,
-		                                      move(op.expressions), move(table_filter_umap));
+		// push a projection on top that does the projection
+		vector<LogicalType> types;
+		vector<unique_ptr<Expression>> expressions;
+		for (auto &column_id : op.column_ids) {
+			if (column_id == COLUMN_IDENTIFIER_ROW_ID) {
+				types.push_back(LogicalType::BIGINT);
+				expressions.push_back(make_unique<BoundConstantExpression>(Value::BIGINT(0)));
+			} else {
+				auto type = op.returned_types[column_id];
+				types.push_back(type);
+				expressions.push_back(make_unique<BoundReferenceExpression>(type, column_id));
+			}
+		}
+		auto projection = make_unique<PhysicalProjection>(move(types), move(expressions));
+		projection->children.push_back(move(node));
+		return move(projection);
+	} else {
+		return make_unique<PhysicalTableScan>(op.types, op.function, move(op.bind_data), op.column_ids,
+		                                      move(table_filter_umap));
 	}
 }
 
diff --git a/src/execution/physical_plan/plan_index_scan.cpp b/src/execution/physical_plan/plan_index_scan.cpp
deleted file mode 100644
index 4cdc95b80964..000000000000
--- a/src/execution/physical_plan/plan_index_scan.cpp
+++ /dev/null
@@ -1,30 +0,0 @@
-#include "duckdb/execution/operator/scan/physical_index_scan.hpp"
-#include "duckdb/execution/physical_plan_generator.hpp"
-
-#include "duckdb/planner/operator/logical_index_scan.hpp"
-
-namespace duckdb {
-using namespace std;
-
-unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalIndexScan &op) {
-	unique_ptr<PhysicalOperator> plan;
-	auto node = make_unique<PhysicalIndexScan>(op, op.tableref, op.table, op.index, op.column_ids);
-	if (op.equal_index) {
-		node->equal_value = op.equal_value;
-		node->equal_index = true;
-	}
-	if (op.low_index) {
-		node->low_value = op.low_value;
-		node->low_index = true;
-		node->low_expression_type = op.low_expression_type;
-	}
-	if (op.high_index) {
-		node->high_value = op.high_value;
-		node->high_index = true;
-		node->high_expression_type = op.high_expression_type;
-	}
-	plan = move(node);
-	return plan;
-}
-
-} // namespace duckdb
diff --git a/src/execution/physical_plan/plan_table_function.cpp b/src/execution/physical_plan/plan_table_function.cpp
deleted file mode 100644
index 11b01adc9fbb..000000000000
--- a/src/execution/physical_plan/plan_table_function.cpp
+++ /dev/null
@@ -1,18 +0,0 @@
-#include "duckdb/execution/operator/scan/physical_table_function.hpp"
-#include "duckdb/execution/physical_plan_generator.hpp"
-#include "duckdb/planner/operator/logical_table_function.hpp"
-
-namespace duckdb {
-using namespace std;
-
-unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalTableFunction &op) {
-	assert(op.children.size() == 0);
-
-	auto tfd = (TableFunctionData *)op.bind_data.get();
-	assert(tfd);
-	// pass on bound column ids into the bind data so the function scan can see them
-	tfd->column_ids = op.column_ids;
-	return make_unique<PhysicalTableFunction>(op.types, op.function, move(op.bind_data), move(op.parameters));
-}
-
-} // namespace duckdb
diff --git a/src/execution/physical_plan_generator.cpp b/src/execution/physical_plan_generator.cpp
index 5523366dfcc1..f396bc5ef161 100644
--- a/src/execution/physical_plan_generator.cpp
+++ b/src/execution/physical_plan_generator.cpp
@@ -75,8 +75,8 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalOperator &
 		return CreatePlan((LogicalCopyFromFile &)op);
 	case LogicalOperatorType::COPY_TO_FILE:
 		return CreatePlan((LogicalCopyToFile &)op);
-	case LogicalOperatorType::TABLE_FUNCTION:
-		return CreatePlan((LogicalTableFunction &)op);
+	case LogicalOperatorType::DUMMY_SCAN:
+		return CreatePlan((LogicalDummyScan &)op);
 	case LogicalOperatorType::ANY_JOIN:
 		return CreatePlan((LogicalAnyJoin &)op);
 	case LogicalOperatorType::DELIM_JOIN:
@@ -113,8 +113,6 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalOperator &
 		return CreatePlan((LogicalPrepare &)op);
 	case LogicalOperatorType::EXECUTE:
 		return CreatePlan((LogicalExecute &)op);
-	case LogicalOperatorType::INDEX_SCAN:
-		return CreatePlan((LogicalIndexScan &)op);
 	case LogicalOperatorType::CREATE_VIEW:
 	case LogicalOperatorType::CREATE_SEQUENCE:
 	case LogicalOperatorType::CREATE_SCHEMA:
diff --git a/src/function/table/CMakeLists.txt b/src/function/table/CMakeLists.txt
index d1ee5a1fca0f..f495772d86a6 100644
--- a/src/function/table/CMakeLists.txt
+++ b/src/function/table/CMakeLists.txt
@@ -8,7 +8,8 @@ add_library_unity(
   repeat.cpp
   copy_csv.cpp
   read_csv.cpp
-  sqlite_functions.cpp)
+  sqlite_functions.cpp
+  table_scan.cpp)
 
 set(ALL_OBJECT_FILES
     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_func_table>
diff --git a/src/function/table/arrow.cpp b/src/function/table/arrow.cpp
index 2dc3bdcc25cb..8c60ccd0af6e 100644
--- a/src/function/table/arrow.cpp
+++ b/src/function/table/arrow.cpp
@@ -20,6 +20,7 @@ struct ArrowScanFunctionData : public TableFunctionData {
 	ArrowArray current_chunk_root;
 	idx_t chunk_idx = 0;
 	idx_t chunk_offset = 0;
+	bool is_consumed = false;
 
 	void ReleaseArray() {
 		if (current_chunk_root.release) {
@@ -118,11 +119,22 @@ static unique_ptr<FunctionData> arrow_scan_bind(ClientContext &context, vector<V
 	return move(res);
 }
 
-static void arrow_scan_function(ClientContext &context, vector<Value> &input, DataChunk &output,
-                                FunctionData *dataptr) {
-	auto &data = *((ArrowScanFunctionData *)dataptr);
+static unique_ptr<FunctionOperatorData> arrow_scan_init(ClientContext &context, const FunctionData *bind_data,
+                                                        OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                        unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+	auto &data = (ArrowScanFunctionData &)*bind_data;
+	if (data.is_consumed) {
+		throw NotImplementedException("FIXME: Arrow streams can only be read once");
+	}
+	data.is_consumed = true;
+	return nullptr;
+}
 
-	if (!data.stream->release) { // no more chunks
+static void arrow_scan_function(ClientContext &context, const FunctionData *bind_data,
+                                FunctionOperatorData *operator_state, DataChunk &output) {
+	auto &data = (ArrowScanFunctionData &)*bind_data;
+	if (!data.stream->release) {
+		// no more chunks
 		return;
 	}
 
@@ -250,7 +262,7 @@ static void arrow_scan_function(ClientContext &context, vector<Value> &input, Da
 void ArrowTableFunction::RegisterFunction(BuiltinFunctions &set) {
 	TableFunctionSet arrow("arrow_scan");
 
-	arrow.AddFunction(TableFunction({LogicalType::POINTER}, arrow_scan_bind, arrow_scan_function));
+	arrow.AddFunction(TableFunction({LogicalType::POINTER}, arrow_scan_function, arrow_scan_bind, arrow_scan_init));
 	set.AddFunction(arrow);
 }
 
diff --git a/src/function/table/range.cpp b/src/function/table/range.cpp
index 428bafe01cfe..89daf26d5532 100644
--- a/src/function/table/range.cpp
+++ b/src/function/table/range.cpp
@@ -7,30 +7,30 @@ using namespace std;
 
 namespace duckdb {
 
-struct RangeFunctionData : public TableFunctionData {
-	Value start;
-	Value end;
-	Value increment;
-	idx_t current_idx;
+struct RangeFunctionBindData : public TableFunctionData {
+	int64_t start;
+	int64_t end;
+	int64_t increment;
 };
 
+template <bool GENERATE_SERIES>
 static unique_ptr<FunctionData> range_function_bind(ClientContext &context, vector<Value> &inputs,
                                                     unordered_map<string, Value> &named_parameters,
                                                     vector<LogicalType> &return_types, vector<string> &names) {
-	auto result = make_unique<RangeFunctionData>();
+	auto result = make_unique<RangeFunctionBindData>();
 	if (inputs.size() < 2) {
 		// single argument: only the end is specified
-		result->start = Value::BIGINT(0);
-		result->end = inputs[0].CastAs(LogicalType::BIGINT);
+		result->start = 0;
+		result->end = inputs[0].GetValue<int64_t>();
 	} else {
 		// two arguments: first two arguments are start and end
-		result->start = inputs[0].CastAs(LogicalType::BIGINT);
-		result->end = inputs[1].CastAs(LogicalType::BIGINT);
+		result->start = inputs[0].GetValue<int64_t>();
+		result->end = inputs[1].GetValue<int64_t>();
 	}
 	if (inputs.size() < 3) {
-		result->increment = Value::BIGINT(1);
+		result->increment = 1;
 	} else {
-		result->increment = inputs[2].CastAs(LogicalType::BIGINT);
+		result->increment = inputs[2].GetValue<int64_t>();
 	}
 	if (result->increment == 0) {
 		throw BinderException("interval cannot be 0!");
@@ -40,38 +40,81 @@ static unique_ptr<FunctionData> range_function_bind(ClientContext &context, vect
 	} else if (result->start < result->end && result->increment < 0) {
 		throw BinderException("start is smaller than end, but increment is negative: cannot generate infinite series");
 	}
-	result->current_idx = 0;
 	return_types.push_back(LogicalType::BIGINT);
-	names.push_back("range");
+	if (GENERATE_SERIES) {
+		// generate_series has inclusive bounds on the RHS
+		if (result->increment < 0) {
+			result->end = result->end - 1;
+		} else {
+			result->end = result->end + 1;
+		}
+		names.push_back("generate_series");
+	} else {
+		names.push_back("range");
+	}
 	return move(result);
 }
 
-static void range_function(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {
-	auto &data = ((RangeFunctionData &)*dataptr);
-	auto increment = data.increment.value_.bigint;
-	auto end = data.end.value_.bigint;
-	int64_t current_value = data.start.value_.bigint + (int64_t)increment * data.current_idx;
+struct RangeFunctionState : public FunctionOperatorData {
+	RangeFunctionState() : current_idx(0) {
+	}
+
+	int64_t current_idx;
+};
+
+static unique_ptr<FunctionOperatorData> range_function_init(ClientContext &context, const FunctionData *bind_data,
+                                                            OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                            unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+	return make_unique<RangeFunctionState>();
+}
+
+static void range_function(ClientContext &context, const FunctionData *bind_data_, FunctionOperatorData *state_,
+                           DataChunk &output) {
+	auto &bind_data = (RangeFunctionBindData &)*bind_data_;
+	auto &state = (RangeFunctionState &)*state_;
+
+	auto increment = bind_data.increment;
+	auto end = bind_data.end;
+	int64_t current_value = bind_data.start + (int64_t)increment * state.current_idx;
 	// set the result vector as a sequence vector
 	output.data[0].Sequence(current_value, increment);
-	idx_t remaining = min<int64_t>((end - current_value) / increment, STANDARD_VECTOR_SIZE);
+	idx_t remaining = min<idx_t>((end - current_value) / increment, STANDARD_VECTOR_SIZE);
 	// increment the index pointer by the remaining count
-	data.current_idx += remaining;
+	state.current_idx += remaining;
 	output.SetCardinality(remaining);
 }
 
+idx_t range_cardinality(const FunctionData *bind_data_) {
+	auto &bind_data = (RangeFunctionBindData &)*bind_data_;
+	return (bind_data.end - bind_data.start) / bind_data.increment;
+}
+
 void RangeTableFunction::RegisterFunction(BuiltinFunctions &set) {
 	TableFunctionSet range("range");
 
 	// single argument range: (end) - implicit start = 0 and increment = 1
-	range.AddFunction(TableFunction({LogicalType::BIGINT}, range_function_bind, range_function));
+	range.AddFunction(TableFunction({LogicalType::BIGINT}, range_function, range_function_bind<false>,
+	                                range_function_init, nullptr, nullptr, nullptr, range_cardinality));
 	// two arguments range: (start, end) - implicit increment = 1
-	range.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT}, range_function_bind, range_function));
+	range.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT}, range_function,
+	                                range_function_bind<false>, range_function_init, nullptr, nullptr, nullptr,
+	                                range_cardinality));
 	// three arguments range: (start, end, increment)
-	range.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT, LogicalType::BIGINT},
-	                                range_function_bind, range_function));
-	set.AddFunction(range);
-	range.name = "generate_series";
+	range.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT, LogicalType::BIGINT}, range_function,
+	                                range_function_bind<false>, range_function_init, nullptr, nullptr, nullptr,
+	                                range_cardinality));
 	set.AddFunction(range);
+	// generate_series: similar to range, but inclusive instead of exclusive bounds on the RHS
+	TableFunctionSet generate_series("generate_series");
+	generate_series.AddFunction(TableFunction({LogicalType::BIGINT}, range_function, range_function_bind<true>,
+	                                          range_function_init, nullptr, nullptr, nullptr, range_cardinality));
+	generate_series.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT}, range_function,
+	                                          range_function_bind<true>, range_function_init, nullptr, nullptr, nullptr,
+	                                          range_cardinality));
+	generate_series.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT, LogicalType::BIGINT},
+	                                          range_function, range_function_bind<true>, range_function_init, nullptr,
+	                                          nullptr, nullptr, range_cardinality));
+	set.AddFunction(generate_series);
 }
 
 void BuiltinFunctions::RegisterTableFunctions() {
diff --git a/src/function/table/read_csv.cpp b/src/function/table/read_csv.cpp
index ff0e3b38f978..bf6dfc701e2a 100644
--- a/src/function/table/read_csv.cpp
+++ b/src/function/table/read_csv.cpp
@@ -9,11 +9,13 @@ using namespace std;
 namespace duckdb {
 
 struct ReadCSVFunctionData : public TableFunctionData {
-	ReadCSVFunctionData() {
+	ReadCSVFunctionData() : is_consumed(false) {
 	}
 
 	//! The CSV reader
 	unique_ptr<BufferedCSVReader> csv_reader;
+	//! Whether or not the CSV has already been read completely
+	bool is_consumed;
 };
 
 static unique_ptr<FunctionData> read_csv_bind(ClientContext &context, vector<Value> &inputs,
@@ -102,6 +104,18 @@ static unique_ptr<FunctionData> read_csv_bind(ClientContext &context, vector<Val
 	return move(result);
 }
 
+static unique_ptr<FunctionOperatorData> read_csv_init(ClientContext &context, const FunctionData *bind_data_,
+                                                      OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                      unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+	auto &bind_data = (ReadCSVFunctionData &)*bind_data_;
+	if (bind_data.is_consumed) {
+		bind_data.csv_reader =
+		    make_unique<BufferedCSVReader>(context, bind_data.csv_reader->options, bind_data.csv_reader->sql_types);
+	}
+	bind_data.is_consumed = true;
+	return nullptr;
+}
+
 static unique_ptr<FunctionData> read_csv_auto_bind(ClientContext &context, vector<Value> &inputs,
                                                    unordered_map<string, Value> &named_parameters,
                                                    vector<LogicalType> &return_types, vector<string> &names) {
@@ -109,8 +123,9 @@ static unique_ptr<FunctionData> read_csv_auto_bind(ClientContext &context, vecto
 	return read_csv_bind(context, inputs, named_parameters, return_types, names);
 }
 
-static void read_csv_info(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {
-	auto &data = ((ReadCSVFunctionData &)*dataptr);
+static void read_csv_function(ClientContext &context, const FunctionData *bind_data,
+                              FunctionOperatorData *operator_state, DataChunk &output) {
+	auto &data = (ReadCSVFunctionData &)*bind_data;
 	data.csv_reader->ParseCSV(output);
 }
 
@@ -130,15 +145,15 @@ static void add_named_parameters(TableFunction &table_function) {
 }
 
 void ReadCSVTableFunction::RegisterFunction(BuiltinFunctions &set) {
-	TableFunction read_csv_function =
-	    TableFunction("read_csv", {LogicalType::VARCHAR}, read_csv_bind, read_csv_info, nullptr);
-	add_named_parameters(read_csv_function);
-	set.AddFunction(read_csv_function);
-
-	TableFunction read_csv_auto_function =
-	    TableFunction("read_csv_auto", {LogicalType::VARCHAR}, read_csv_auto_bind, read_csv_info, nullptr);
-	add_named_parameters(read_csv_auto_function);
-	set.AddFunction(read_csv_auto_function);
+
+	TableFunction read_csv("read_csv", {LogicalType::VARCHAR}, read_csv_function, read_csv_bind, read_csv_init);
+	add_named_parameters(read_csv);
+	set.AddFunction(read_csv);
+
+	TableFunction read_csv_auto("read_csv_auto", {LogicalType::VARCHAR}, read_csv_function, read_csv_auto_bind,
+	                            read_csv_init);
+	add_named_parameters(read_csv_auto);
+	set.AddFunction(read_csv_auto);
 }
 
 void BuiltinFunctions::RegisterReadFunctions() {
diff --git a/src/function/table/repeat.cpp b/src/function/table/repeat.cpp
index 75bfbb794436..63042d4cbce2 100644
--- a/src/function/table/repeat.cpp
+++ b/src/function/table/repeat.cpp
@@ -6,32 +6,53 @@ using namespace std;
 namespace duckdb {
 
 struct RepeatFunctionData : public TableFunctionData {
-	RepeatFunctionData(idx_t target_count) : current_count(0), target_count(target_count) {
+	RepeatFunctionData(Value value, idx_t target_count) : value(move(value)), target_count(target_count) {
 	}
 
-	idx_t current_count;
+	Value value;
 	idx_t target_count;
 };
 
+struct RepeatOperatorData : public FunctionOperatorData {
+	RepeatOperatorData() : current_count(0) {
+	}
+	idx_t current_count;
+};
+
 static unique_ptr<FunctionData> repeat_bind(ClientContext &context, vector<Value> &inputs,
                                             unordered_map<string, Value> &named_parameters,
                                             vector<LogicalType> &return_types, vector<string> &names) {
 	// the repeat function returns the type of the first argument
 	return_types.push_back(inputs[0].type());
 	names.push_back(inputs[0].ToString());
-	return make_unique<RepeatFunctionData>(inputs[1].GetValue<int64_t>());
+	return make_unique<RepeatFunctionData>(inputs[0], inputs[1].GetValue<int64_t>());
 }
 
-static void repeat_function(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {
-	auto &repeat = (RepeatFunctionData &)*dataptr;
-	idx_t remaining = min<idx_t>(repeat.target_count - repeat.current_count, STANDARD_VECTOR_SIZE);
-	output.data[0].Reference(input[0]);
+static unique_ptr<FunctionOperatorData> repeat_init(ClientContext &context, const FunctionData *bind_data,
+                                                    OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                    unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+	return make_unique<RepeatOperatorData>();
+}
+
+static void repeat_function(ClientContext &context, const FunctionData *bind_data_,
+                            FunctionOperatorData *operator_state, DataChunk &output) {
+	auto &bind_data = (RepeatFunctionData &)*bind_data_;
+	auto &state = (RepeatOperatorData &)*operator_state;
+
+	idx_t remaining = min<idx_t>(bind_data.target_count - state.current_count, STANDARD_VECTOR_SIZE);
+	output.data[0].Reference(bind_data.value);
 	output.SetCardinality(remaining);
-	repeat.current_count += remaining;
+	state.current_count += remaining;
+}
+
+static idx_t repeat_cardinality(const FunctionData *bind_data_) {
+	auto &bind_data = (RepeatFunctionData &)*bind_data_;
+	return bind_data.target_count;
 }
 
 void RepeatTableFunction::RegisterFunction(BuiltinFunctions &set) {
-	TableFunction repeat("repeat", {LogicalType::ANY, LogicalType::BIGINT}, repeat_bind, repeat_function, nullptr);
+	TableFunction repeat("repeat", {LogicalType::ANY, LogicalType::BIGINT}, repeat_function, repeat_bind, repeat_init,
+	                     nullptr, nullptr, nullptr, repeat_cardinality);
 	set.AddFunction(repeat);
 }
 
diff --git a/src/function/table/sqlite/pragma_collations.cpp b/src/function/table/sqlite/pragma_collations.cpp
index 231165379f7d..5094cdb9b0a8 100644
--- a/src/function/table/sqlite/pragma_collations.cpp
+++ b/src/function/table/sqlite/pragma_collations.cpp
@@ -10,12 +10,11 @@ using namespace std;
 
 namespace duckdb {
 
-struct PragmaCollateData : public TableFunctionData {
-	PragmaCollateData() : initialized(false), offset(0) {
+struct PragmaCollateData : public FunctionOperatorData {
+	PragmaCollateData() : offset(0) {
 	}
 
-	bool initialized;
-	vector<CatalogEntry *> entries;
+	vector<string> entries;
 	idx_t offset;
 };
 
@@ -25,23 +24,26 @@ static unique_ptr<FunctionData> pragma_collate_bind(ClientContext &context, vect
 	names.push_back("collname");
 	return_types.push_back(LogicalType::VARCHAR);
 
-	return make_unique<PragmaCollateData>();
+	return nullptr;
 }
 
-static void pragma_collate_info(ClientContext &context, vector<Value> &input, DataChunk &output,
-                                FunctionData *dataptr) {
-	auto &data = *((PragmaCollateData *)dataptr);
-	assert(input.size() == 0);
-	if (!data.initialized) {
-		// scan all the schemas
-		auto &transaction = Transaction::GetTransaction(context);
-		Catalog::GetCatalog(context).schemas->Scan(transaction, [&](CatalogEntry *entry) {
-			auto schema = (SchemaCatalogEntry *)entry;
-			schema->collations.Scan(transaction, [&](CatalogEntry *entry) { data.entries.push_back(entry); });
-		});
-		data.initialized = true;
-	}
+unique_ptr<FunctionOperatorData> pragma_collate_init(ClientContext &context, const FunctionData *bind_data,
+                                                     OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                     unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+	auto result = make_unique<PragmaCollateData>();
+
+	auto &transaction = Transaction::GetTransaction(context);
+	Catalog::GetCatalog(context).schemas->Scan(transaction, [&](CatalogEntry *entry) {
+		auto schema = (SchemaCatalogEntry *)entry;
+		schema->collations.Scan(transaction, [&](CatalogEntry *entry) { result->entries.push_back(entry->name); });
+	});
 
+	return move(result);
+}
+
+static void pragma_collate(ClientContext &context, const FunctionData *bind_data, FunctionOperatorData *operator_state,
+                           DataChunk &output) {
+	auto &data = (PragmaCollateData &)*operator_state;
 	if (data.offset >= data.entries.size()) {
 		// finished returning values
 		return;
@@ -50,16 +52,14 @@ static void pragma_collate_info(ClientContext &context, vector<Value> &input, Da
 	output.SetCardinality(next - data.offset);
 	for (idx_t i = data.offset; i < next; i++) {
 		auto index = i - data.offset;
-		auto entry = (CollateCatalogEntry *)data.entries[i];
-
-		output.SetValue(0, index, Value(entry->name));
+		output.SetValue(0, index, Value(data.entries[i]));
 	}
 
 	data.offset = next;
 }
 
 void PragmaCollations::RegisterFunction(BuiltinFunctions &set) {
-	set.AddFunction(TableFunction("pragma_collations", {}, pragma_collate_bind, pragma_collate_info, nullptr));
+	set.AddFunction(TableFunction("pragma_collations", {}, pragma_collate, pragma_collate_bind, pragma_collate_init));
 }
 
 } // namespace duckdb
diff --git a/src/function/table/sqlite/pragma_database_list.cpp b/src/function/table/sqlite/pragma_database_list.cpp
index 8b960a0ec052..2b91da629bea 100644
--- a/src/function/table/sqlite/pragma_database_list.cpp
+++ b/src/function/table/sqlite/pragma_database_list.cpp
@@ -6,7 +6,7 @@ using namespace std;
 
 namespace duckdb {
 
-struct PragmaDatabaseListData : public TableFunctionData {
+struct PragmaDatabaseListData : public FunctionOperatorData {
 	PragmaDatabaseListData() : finished(false) {
 	}
 
@@ -25,12 +25,18 @@ static unique_ptr<FunctionData> pragma_database_list_bind(ClientContext &context
 	names.push_back("file");
 	return_types.push_back(LogicalType::VARCHAR);
 
-	// initialize the function data structure
+	return nullptr;
+}
+
+unique_ptr<FunctionOperatorData> pragma_database_list_init(ClientContext &context, const FunctionData *bind_data,
+                                                           OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                           unordered_map<idx_t, vector<TableFilter>> &table_filters) {
 	return make_unique<PragmaDatabaseListData>();
 }
 
-void pragma_database_list(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {
-	auto &data = *((PragmaDatabaseListData *)dataptr);
+void pragma_database_list(ClientContext &context, const FunctionData *bind_data, FunctionOperatorData *operator_state,
+                          DataChunk &output) {
+	auto &data = (PragmaDatabaseListData &)*operator_state;
 	if (data.finished) {
 		return;
 	}
@@ -44,8 +50,8 @@ void pragma_database_list(ClientContext &context, vector<Value> &input, DataChun
 }
 
 void PragmaDatabaseList::RegisterFunction(BuiltinFunctions &set) {
-	set.AddFunction(
-	    TableFunction("pragma_database_list", {}, pragma_database_list_bind, pragma_database_list, nullptr));
+	set.AddFunction(TableFunction("pragma_database_list", {}, pragma_database_list, pragma_database_list_bind,
+	                              pragma_database_list_init));
 }
 
 } // namespace duckdb
diff --git a/src/function/table/sqlite/pragma_table_info.cpp b/src/function/table/sqlite/pragma_table_info.cpp
index 349a3f7d3e3a..8534ab204137 100644
--- a/src/function/table/sqlite/pragma_table_info.cpp
+++ b/src/function/table/sqlite/pragma_table_info.cpp
@@ -13,10 +13,15 @@ using namespace std;
 namespace duckdb {
 
 struct PragmaTableFunctionData : public TableFunctionData {
-	PragmaTableFunctionData() : entry(nullptr), offset(0) {
+	PragmaTableFunctionData(CatalogEntry *entry_) : entry(entry_) {
 	}
 
 	CatalogEntry *entry;
+};
+
+struct PragmaTableOperatorData : public FunctionOperatorData {
+	PragmaTableOperatorData() : offset(0) {
+	}
 	idx_t offset;
 };
 
@@ -41,10 +46,23 @@ static unique_ptr<FunctionData> pragma_table_info_bind(ClientContext &context, v
 	names.push_back("pk");
 	return_types.push_back(LogicalType::BOOLEAN);
 
-	return make_unique<PragmaTableFunctionData>();
+	string schema, table_name;
+	auto range_var = inputs[0].GetValue<string>();
+	Catalog::ParseRangeVar(range_var, schema, table_name);
+
+	// look up the table name in the catalog
+	auto &catalog = Catalog::GetCatalog(context);
+	auto entry = catalog.GetEntry(context, CatalogType::TABLE_ENTRY, schema, table_name);
+	return make_unique<PragmaTableFunctionData>(entry);
 }
 
-static void pragma_table_info_table(PragmaTableFunctionData &data, TableCatalogEntry *table, DataChunk &output) {
+unique_ptr<FunctionOperatorData> pragma_table_info_init(ClientContext &context, const FunctionData *bind_data,
+                                                        OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                        unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+	return make_unique<PragmaTableOperatorData>();
+}
+
+static void pragma_table_info_table(PragmaTableOperatorData &data, TableCatalogEntry *table, DataChunk &output) {
 	if (data.offset >= table->columns.size()) {
 		// finished returning values
 		return;
@@ -79,7 +97,7 @@ static void pragma_table_info_table(PragmaTableFunctionData &data, TableCatalogE
 	data.offset = next;
 }
 
-static void pragma_table_info_view(PragmaTableFunctionData &data, ViewCatalogEntry *view, DataChunk &output) {
+static void pragma_table_info_view(PragmaTableOperatorData &data, ViewCatalogEntry *view, DataChunk &output) {
 	if (data.offset >= view->types.size()) {
 		// finished returning values
 		return;
@@ -111,26 +129,16 @@ static void pragma_table_info_view(PragmaTableFunctionData &data, ViewCatalogEnt
 	data.offset = next;
 }
 
-static void pragma_table_info(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {
-	auto &data = *((PragmaTableFunctionData *)dataptr);
-	if (!data.entry) {
-		// first call: load the entry from the catalog
-		assert(input.size() == 1);
-
-		string schema, table_name;
-		auto range_var = input[0].GetValue<string>();
-		Catalog::ParseRangeVar(range_var, schema, table_name);
-
-		// look up the table name in the catalog
-		auto &catalog = Catalog::GetCatalog(context);
-		data.entry = catalog.GetEntry(context, CatalogType::TABLE_ENTRY, schema, table_name);
-	}
-	switch (data.entry->type) {
+static void pragma_table_info(ClientContext &context, const FunctionData *bind_data_,
+                              FunctionOperatorData *operator_state, DataChunk &output) {
+	auto &bind_data = (PragmaTableFunctionData &)*bind_data_;
+	auto &state = (PragmaTableOperatorData &)*operator_state;
+	switch (bind_data.entry->type) {
 	case CatalogType::TABLE_ENTRY:
-		pragma_table_info_table(data, (TableCatalogEntry *)data.entry, output);
+		pragma_table_info_table(state, (TableCatalogEntry *)bind_data.entry, output);
 		break;
 	case CatalogType::VIEW_ENTRY:
-		pragma_table_info_view(data, (ViewCatalogEntry *)data.entry, output);
+		pragma_table_info_view(state, (ViewCatalogEntry *)bind_data.entry, output);
 		break;
 	default:
 		throw NotImplementedException("Unimplemented catalog type for pragma_table_info");
@@ -138,8 +146,8 @@ static void pragma_table_info(ClientContext &context, vector<Value> &input, Data
 }
 
 void PragmaTableInfo::RegisterFunction(BuiltinFunctions &set) {
-	set.AddFunction(
-	    TableFunction("pragma_table_info", {LogicalType::VARCHAR}, pragma_table_info_bind, pragma_table_info, nullptr));
+	set.AddFunction(TableFunction("pragma_table_info", {LogicalType::VARCHAR}, pragma_table_info,
+	                              pragma_table_info_bind, pragma_table_info_init));
 }
 
 } // namespace duckdb
diff --git a/src/function/table/sqlite/sqlite_master.cpp b/src/function/table/sqlite/sqlite_master.cpp
index 84d932cee188..de8075ec2ecc 100644
--- a/src/function/table/sqlite/sqlite_master.cpp
+++ b/src/function/table/sqlite/sqlite_master.cpp
@@ -12,11 +12,10 @@ using namespace std;
 
 namespace duckdb {
 
-struct SQLiteMasterData : public TableFunctionData {
-	SQLiteMasterData() : initialized(false), offset(0) {
+struct SQLiteMasterData : public FunctionOperatorData {
+	SQLiteMasterData() : offset(0) {
 	}
 
-	bool initialized;
 	vector<CatalogEntry *> entries;
 	idx_t offset;
 };
@@ -39,23 +38,27 @@ static unique_ptr<FunctionData> sqlite_master_bind(ClientContext &context, vecto
 	names.push_back("sql");
 	return_types.push_back(LogicalType::VARCHAR);
 
-	// initialize the function data structure
-	return make_unique<SQLiteMasterData>();
+	return nullptr;
 }
 
-void sqlite_master(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {
-	auto &data = *((SQLiteMasterData *)dataptr);
-	assert(input.size() == 0);
-	if (!data.initialized) {
-		// scan all the schemas
-		auto &transaction = Transaction::GetTransaction(context);
-		Catalog::GetCatalog(context).schemas->Scan(transaction, [&](CatalogEntry *entry) {
-			auto schema = (SchemaCatalogEntry *)entry;
-			schema->tables.Scan(transaction, [&](CatalogEntry *entry) { data.entries.push_back(entry); });
-		});
-		data.initialized = true;
-	}
+unique_ptr<FunctionOperatorData> sqlite_master_init(ClientContext &context, const FunctionData *bind_data,
+                                                    OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                    unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+	auto result = make_unique<SQLiteMasterData>();
+
+	// scan all the schemas for tables and views and collect them
+	auto &transaction = Transaction::GetTransaction(context);
+	Catalog::GetCatalog(context).schemas->Scan(transaction, [&](CatalogEntry *entry) {
+		auto schema = (SchemaCatalogEntry *)entry;
+		schema->tables.Scan(transaction, [&](CatalogEntry *entry) { result->entries.push_back(entry); });
+	});
+
+	return move(result);
+}
 
+void sqlite_master(ClientContext &context, const FunctionData *bind_data, FunctionOperatorData *operator_state,
+                   DataChunk &output) {
+	auto &data = (SQLiteMasterData &)*operator_state;
 	if (data.offset >= data.entries.size()) {
 		// finished returning values
 		return;
@@ -102,7 +105,7 @@ void sqlite_master(ClientContext &context, vector<Value> &input, DataChunk &outp
 }
 
 void SQLiteMaster::RegisterFunction(BuiltinFunctions &set) {
-	set.AddFunction(TableFunction("sqlite_master", {}, sqlite_master_bind, sqlite_master, nullptr));
+	set.AddFunction(TableFunction("sqlite_master", {}, sqlite_master, sqlite_master_bind, sqlite_master_init));
 }
 
 } // namespace duckdb
diff --git a/src/function/table/sqlite_functions.cpp b/src/function/table/sqlite_functions.cpp
index 5a95c41663fa..9de75483aa25 100644
--- a/src/function/table/sqlite_functions.cpp
+++ b/src/function/table/sqlite_functions.cpp
@@ -17,20 +17,20 @@ void BuiltinFunctions::RegisterSQLiteFunctions() {
 	SQLiteMaster::RegisterFunction(*this);
 	PragmaDatabaseList::RegisterFunction(*this);
 
-	CreateViewInfo info;
-	info.schema = DEFAULT_SCHEMA;
-	info.view_name = "sqlite_master";
-	info.on_conflict = OnCreateConflict::REPLACE;
+	// CreateViewInfo info;
+	// info.schema = DEFAULT_SCHEMA;
+	// info.view_name = "sqlite_master";
+	// info.on_conflict = OnCreateConflict::REPLACE;
 
-	auto select = make_unique<SelectNode>();
-	select->select_list.push_back(make_unique<StarExpression>());
-	vector<unique_ptr<ParsedExpression>> children;
+	// auto select = make_unique<SelectNode>();
+	// select->select_list.push_back(make_unique<StarExpression>());
+	// vector<unique_ptr<ParsedExpression>> children;
 
-	auto function = make_unique<FunctionExpression>(DEFAULT_SCHEMA, "sqlite_master", children);
-	auto function_expr = make_unique<TableFunctionRef>();
-	function_expr->function = move(function);
-	select->from_table = move(function_expr);
-	info.query = move(select);
+	// auto function = make_unique<FunctionExpression>(DEFAULT_SCHEMA, "sqlite_master", children);
+	// auto function_expr = make_unique<TableFunctionRef>();
+	// function_expr->function = move(function);
+	// select->from_table = move(function_expr);
+	// info.query = move(select);
 	//	catalog.CreateView(transaction, &info);
 }
 
diff --git a/src/function/table/table_scan.cpp b/src/function/table/table_scan.cpp
new file mode 100644
index 000000000000..6c03ad98147d
--- /dev/null
+++ b/src/function/table/table_scan.cpp
@@ -0,0 +1,288 @@
+#include "duckdb/function/table/table_scan.hpp"
+#include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
+
+#include "duckdb/parallel/task_context.hpp"
+#include "duckdb/storage/data_table.hpp"
+#include "duckdb/transaction/transaction.hpp"
+#include "duckdb/transaction/local_storage.hpp"
+
+#include "duckdb/optimizer/matcher/expression_matcher.hpp"
+
+#include "duckdb/planner/expression/bound_between_expression.hpp"
+#include "duckdb/planner/expression_iterator.hpp"
+#include "duckdb/planner/operator/logical_get.hpp"
+
+namespace duckdb {
+
+class TableScanTaskInfo : public OperatorTaskInfo {
+public:
+	TableScanState state;
+};
+
+struct TableScanOperatorData : public FunctionOperatorData {
+	//! The current position in the scan
+	TableScanState scan_state;
+	vector<column_t> column_ids;
+	unordered_map<idx_t, vector<TableFilter>> table_filters;
+};
+
+struct IndexScanOperatorData : public FunctionOperatorData {
+	Vector row_ids;
+	ColumnFetchState fetch_state;
+	LocalScanState local_storage_state;
+	vector<column_t> column_ids;
+	bool finished;
+};
+
+static unique_ptr<FunctionOperatorData> table_scan_init(ClientContext &context, const FunctionData *bind_data_,
+                                                        OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                        unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+	auto result = make_unique<TableScanOperatorData>();
+	auto &transaction = Transaction::GetTransaction(context);
+	auto &bind_data = (const TableScanBindData &)*bind_data_;
+	result->column_ids = column_ids;
+	result->table_filters = table_filters;
+	if (task_info) {
+		auto &info = (TableScanTaskInfo &)*task_info;
+		result->scan_state = move(info.state);
+	} else {
+		bind_data.table->storage->InitializeScan(transaction, result->scan_state, result->column_ids,
+		                                         &result->table_filters);
+	}
+	return move(result);
+}
+
+static void table_scan_function(ClientContext &context, const FunctionData *bind_data_,
+                                FunctionOperatorData *operator_state, DataChunk &output) {
+	auto &bind_data = (const TableScanBindData &)*bind_data_;
+	auto &state = (TableScanOperatorData &)*operator_state;
+	auto &transaction = Transaction::GetTransaction(context);
+	bind_data.table->storage->Scan(transaction, output, state.scan_state, state.column_ids, state.table_filters);
+}
+
+static unique_ptr<FunctionOperatorData> index_scan_init(ClientContext &context, const FunctionData *bind_data_,
+                                                        OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                        unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+	auto result = make_unique<IndexScanOperatorData>();
+	auto &transaction = Transaction::GetTransaction(context);
+	auto &bind_data = (const TableScanBindData &)*bind_data_;
+	result->column_ids = column_ids;
+	result->row_ids.type = LOGICAL_ROW_TYPE;
+	FlatVector::SetData(result->row_ids, (data_ptr_t)&bind_data.result_ids[0]);
+	transaction.storage.InitializeScan(bind_data.table->storage.get(), result->local_storage_state);
+
+	result->finished = false;
+	return move(result);
+}
+
+static void index_scan_function(ClientContext &context, const FunctionData *bind_data_,
+                                FunctionOperatorData *operator_state, DataChunk &output) {
+	auto &bind_data = (const TableScanBindData &)*bind_data_;
+	auto &state = (IndexScanOperatorData &)*operator_state;
+	auto &transaction = Transaction::GetTransaction(context);
+	if (!state.finished) {
+		bind_data.table->storage->Fetch(transaction, output, state.column_ids, state.row_ids,
+		                                bind_data.result_ids.size(), state.fetch_state);
+		state.finished = true;
+	}
+	if (output.size() == 0) {
+		transaction.storage.Scan(state.local_storage_state, state.column_ids, output);
+	}
+}
+
+void table_scan_parallel(ClientContext &context, const FunctionData *bind_data_, vector<column_t> &column_ids,
+                         unordered_map<idx_t, vector<TableFilter>> &table_filters,
+                         std::function<void(unique_ptr<OperatorTaskInfo>)> callback) {
+	auto &bind_data = (const TableScanBindData &)*bind_data_;
+	if (bind_data.is_index_scan) {
+		// don't need to parallelize index scans: we only fetch up to 1024 entries anyway...
+		return;
+	}
+	bind_data.table->storage->InitializeParallelScan(context, column_ids, &table_filters, [&](TableScanState state) {
+		auto task = make_unique<TableScanTaskInfo>();
+		task->state = move(state);
+		callback(move(task));
+	});
+}
+
+void table_scan_dependency(unordered_set<CatalogEntry *> &entries, const FunctionData *bind_data_) {
+	auto &bind_data = (const TableScanBindData &)*bind_data_;
+	entries.insert(bind_data.table);
+}
+
+idx_t table_scan_cardinality(const FunctionData *bind_data_) {
+	auto &bind_data = (const TableScanBindData &)*bind_data_;
+	return bind_data.table->storage->info->cardinality;
+}
+
+static void RewriteIndexExpression(Index &index, LogicalGet &get, Expression &expr, bool &rewrite_possible) {
+	if (expr.type == ExpressionType::BOUND_COLUMN_REF) {
+		auto &bound_colref = (BoundColumnRefExpression &)expr;
+		// bound column ref: rewrite to fit in the current set of bound column ids
+		bound_colref.binding.table_index = get.table_index;
+		column_t referenced_column = index.column_ids[bound_colref.binding.column_index];
+		// search for the referenced column in the set of column_ids
+		for (idx_t i = 0; i < get.column_ids.size(); i++) {
+			if (get.column_ids[i] == referenced_column) {
+				bound_colref.binding.column_index = i;
+				return;
+			}
+		}
+		// column id not found in bound columns in the LogicalGet: rewrite not possible
+		rewrite_possible = false;
+	}
+	ExpressionIterator::EnumerateChildren(
+	    expr, [&](Expression &child) { RewriteIndexExpression(index, get, child, rewrite_possible); });
+}
+
+void table_scan_pushdown_complex_filter(ClientContext &context, LogicalGet &get, FunctionData *bind_data_,
+                                        vector<unique_ptr<Expression>> &filters) {
+	auto &bind_data = (TableScanBindData &)*bind_data_;
+	auto table = bind_data.table;
+	auto &storage = *table->storage;
+
+	if (bind_data.is_index_scan) {
+		return;
+	}
+	if (filters.size() == 0 || storage.info->indexes.size() == 0) {
+		// no indexes or no filters: skip the pushdown
+		return;
+	}
+	// check all the indexes
+	for (size_t j = 0; j < storage.info->indexes.size(); j++) {
+		auto &index = storage.info->indexes[j];
+
+		// first rewrite the index expression so the ColumnBindings align with the column bindings of the current table
+		if (index->unbound_expressions.size() > 1) {
+			continue;
+		}
+		auto index_expression = index->unbound_expressions[0]->Copy();
+		bool rewrite_possible = true;
+		RewriteIndexExpression(*index, get, *index_expression, rewrite_possible);
+		if (!rewrite_possible) {
+			// could not rewrite!
+			continue;
+		}
+
+		Value low_value, high_value, equal_value;
+		ExpressionType low_comparison_type, high_comparison_type;
+		// try to find a matching index for any of the filter expressions
+		for (idx_t i = 0; i < filters.size(); i++) {
+			auto expr = filters[i].get();
+
+			// create a matcher for a comparison with a constant
+			ComparisonExpressionMatcher matcher;
+			// match on a comparison type
+			matcher.expr_type = make_unique<ComparisonExpressionTypeMatcher>();
+			// match on a constant comparison with the indexed expression
+			matcher.matchers.push_back(make_unique<ExpressionEqualityMatcher>(index_expression.get()));
+			matcher.matchers.push_back(make_unique<ConstantExpressionMatcher>());
+
+			matcher.policy = SetMatcher::Policy::UNORDERED;
+
+			vector<Expression *> bindings;
+			if (matcher.Match(expr, bindings)) {
+				// range or equality comparison with constant value
+				// we can use our index here
+				// bindings[0] = the expression
+				// bindings[1] = the index expression
+				// bindings[2] = the constant
+				auto comparison = (BoundComparisonExpression *)bindings[0];
+				assert(bindings[0]->GetExpressionClass() == ExpressionClass::BOUND_COMPARISON);
+				assert(bindings[2]->type == ExpressionType::VALUE_CONSTANT);
+
+				auto constant_value = ((BoundConstantExpression *)bindings[2])->value;
+				auto comparison_type = comparison->type;
+				if (comparison->left->type == ExpressionType::VALUE_CONSTANT) {
+					// the expression is on the right side, we flip them around
+					comparison_type = FlipComparisionExpression(comparison_type);
+				}
+				if (comparison_type == ExpressionType::COMPARE_EQUAL) {
+					// equality value
+					// equality overrides any other bounds so we just break here
+					equal_value = constant_value;
+					break;
+				} else if (comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO ||
+				           comparison_type == ExpressionType::COMPARE_GREATERTHAN) {
+					// greater than means this is a lower bound
+					low_value = constant_value;
+					low_comparison_type = comparison_type;
+				} else {
+					// smaller than means this is an upper bound
+					high_value = constant_value;
+					high_comparison_type = comparison_type;
+				}
+			} else if (expr->type == ExpressionType::COMPARE_BETWEEN) {
+				// BETWEEN expression
+				auto &between = (BoundBetweenExpression &)*expr;
+				if (!between.input->Equals(index_expression.get())) {
+					// expression doesn't match the current index expression
+					continue;
+				}
+				if (between.lower->type != ExpressionType::VALUE_CONSTANT ||
+				    between.upper->type != ExpressionType::VALUE_CONSTANT) {
+					// not a constant comparison
+					continue;
+				}
+				low_value = ((BoundConstantExpression &)*between.lower).value;
+				low_comparison_type = between.lower_inclusive ? ExpressionType::COMPARE_GREATERTHANOREQUALTO
+				                                              : ExpressionType::COMPARE_GREATERTHAN;
+				high_value = ((BoundConstantExpression &)*between.upper).value;
+				high_comparison_type = between.upper_inclusive ? ExpressionType::COMPARE_LESSTHANOREQUALTO
+				                                               : ExpressionType::COMPARE_LESSTHAN;
+				break;
+			}
+		}
+		if (!equal_value.is_null || !low_value.is_null || !high_value.is_null) {
+			// we can scan this index using this predicate: try a scan
+			auto &transaction = Transaction::GetTransaction(context);
+			unique_ptr<IndexScanState> index_state;
+			if (!equal_value.is_null) {
+				// equality predicate
+				index_state =
+				    index->InitializeScanSinglePredicate(transaction, equal_value, ExpressionType::COMPARE_EQUAL);
+			} else if (!low_value.is_null && !high_value.is_null) {
+				// two-sided predicate
+				index_state = index->InitializeScanTwoPredicates(transaction, low_value, low_comparison_type,
+				                                                 high_value, high_comparison_type);
+			} else if (!low_value.is_null) {
+				// less than predicate
+				index_state = index->InitializeScanSinglePredicate(transaction, low_value, low_comparison_type);
+			} else {
+				assert(!high_value.is_null);
+				index_state = index->InitializeScanSinglePredicate(transaction, high_value, high_comparison_type);
+			}
+			if (index->Scan(transaction, storage, *index_state, STANDARD_VECTOR_SIZE, bind_data.result_ids)) {
+				// use an index scan!
+				bind_data.is_index_scan = true;
+				get.function.init = index_scan_init;
+				get.function.function = index_scan_function;
+				get.function.filter_pushdown = false;
+			} else {
+				bind_data.result_ids.clear();
+			}
+			return;
+		}
+	}
+}
+
+string table_scan_to_string(const FunctionData *bind_data_) {
+	auto &bind_data = (const TableScanBindData &)*bind_data_;
+	string result = "SEQ_SCAN(" + bind_data.table->name + ")";
+	return result;
+}
+
+TableFunction TableScanFunction::GetFunction() {
+	TableFunction scan_function("seq_scan", {}, table_scan_function);
+	scan_function.init = table_scan_init;
+	scan_function.parallel_tasks = table_scan_parallel;
+	scan_function.dependency = table_scan_dependency;
+	scan_function.cardinality = table_scan_cardinality;
+	scan_function.pushdown_complex_filter = table_scan_pushdown_complex_filter;
+	scan_function.to_string = table_scan_to_string;
+	scan_function.projection_pushdown = true;
+	scan_function.filter_pushdown = true;
+	return scan_function;
+}
+
+} // namespace duckdb
diff --git a/src/function/table/version/pragma_version.cpp b/src/function/table/version/pragma_version.cpp
index 225b7f020bc4..bf809cfb00a7 100644
--- a/src/function/table/version/pragma_version.cpp
+++ b/src/function/table/version/pragma_version.cpp
@@ -3,10 +3,10 @@
 
 namespace duckdb {
 
-struct PragmaVersionData : public TableFunctionData {
-	PragmaVersionData() : done(false) {
+struct PragmaVersionData : public FunctionOperatorData {
+	PragmaVersionData() : finished(false) {
 	}
-	bool done;
+	bool finished;
 };
 
 static unique_ptr<FunctionData> pragma_version_bind(ClientContext &context, vector<Value> &inputs,
@@ -16,26 +16,30 @@ static unique_ptr<FunctionData> pragma_version_bind(ClientContext &context, vect
 	return_types.push_back(LogicalType::VARCHAR);
 	names.push_back("source_id");
 	return_types.push_back(LogicalType::VARCHAR);
+	return nullptr;
+}
 
+static unique_ptr<FunctionOperatorData> pragma_version_init(ClientContext &context, const FunctionData *bind_data,
+                                                            OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+                                                            unordered_map<idx_t, vector<TableFilter>> &table_filters) {
 	return make_unique<PragmaVersionData>();
 }
 
-static void pragma_version_info(ClientContext &context, vector<Value> &input, DataChunk &output,
-                                FunctionData *dataptr) {
-	auto &data = *((PragmaVersionData *)dataptr);
-	assert(input.size() == 0);
-	if (data.done) {
+static void pragma_version(ClientContext &context, const FunctionData *bind_data, FunctionOperatorData *operator_state,
+                           DataChunk &output) {
+	auto &data = (PragmaVersionData &)*operator_state;
+	if (data.finished) {
 		// finished returning values
 		return;
 	}
 	output.SetCardinality(1);
 	output.SetValue(0, 0, DuckDB::LibraryVersion());
 	output.SetValue(1, 0, DuckDB::SourceID());
-	data.done = true;
+	data.finished = true;
 }
 
 void PragmaVersion::RegisterFunction(BuiltinFunctions &set) {
-	set.AddFunction(TableFunction("pragma_version", {}, pragma_version_bind, pragma_version_info, nullptr));
+	set.AddFunction(TableFunction("pragma_version", {}, pragma_version, pragma_version_bind, pragma_version_init));
 }
 
 const char *DuckDB::SourceID() {
diff --git a/src/include/duckdb/common/enums/logical_operator_type.hpp b/src/include/duckdb/common/enums/logical_operator_type.hpp
index 572d96c94487..b23559fa2ad0 100644
--- a/src/include/duckdb/common/enums/logical_operator_type.hpp
+++ b/src/include/duckdb/common/enums/logical_operator_type.hpp
@@ -28,7 +28,7 @@ enum class LogicalOperatorType : uint8_t {
 	COPY_FROM_FILE = 9,
 	COPY_TO_FILE = 10,
 	DISTINCT = 11,
-	INDEX_SCAN = 12,
+
 	// -----------------------------
 	// Data sources
 	// -----------------------------
@@ -36,7 +36,7 @@ enum class LogicalOperatorType : uint8_t {
 	CHUNK_GET = 26,
 	DELIM_GET = 27,
 	EXPRESSION_GET = 28,
-	TABLE_FUNCTION = 29,
+	DUMMY_SCAN = 29,
 	EMPTY_RESULT = 30,
 	CTE_REF = 31,
 	// -----------------------------
diff --git a/src/include/duckdb/common/enums/physical_operator_type.hpp b/src/include/duckdb/common/enums/physical_operator_type.hpp
index 952bae1ffa1d..6c9a21ae7f82 100644
--- a/src/include/duckdb/common/enums/physical_operator_type.hpp
+++ b/src/include/duckdb/common/enums/physical_operator_type.hpp
@@ -32,13 +32,11 @@ enum class PhysicalOperatorType : uint8_t {
 	PROJECTION,
 	COPY_FROM_FILE,
 	COPY_TO_FILE,
-	TABLE_FUNCTION,
 	// -----------------------------
 	// Scans
 	// -----------------------------
+	TABLE_SCAN,
 	DUMMY_SCAN,
-	SEQ_SCAN,
-	INDEX_SCAN,
 	CHUNK_SCAN,
 	RECURSIVE_CTE_SCAN,
 	DELIM_SCAN,
diff --git a/src/include/duckdb/execution/index/art/art.hpp b/src/include/duckdb/execution/index/art/art.hpp
index a867d0c75dd9..d37fbd53b1a3 100644
--- a/src/include/duckdb/execution/index/art/art.hpp
+++ b/src/include/duckdb/execution/index/art/art.hpp
@@ -41,7 +41,7 @@ struct Iterator {
 };
 
 struct ARTIndexScanState : public IndexScanState {
-	ARTIndexScanState(vector<column_t> column_ids) : IndexScanState(column_ids), checked(false), result_index(0) {
+	ARTIndexScanState() : checked(false), result_index(0) {
 	}
 
 	Value values[2];
@@ -67,18 +67,18 @@ class ART : public Index {
 public:
 	//! Initialize a scan on the index with the given expression and column ids
 	//! to fetch from the base table for a single predicate
-	unique_ptr<IndexScanState> InitializeScanSinglePredicate(Transaction &transaction, vector<column_t> column_ids,
-	                                                         Value value, ExpressionType expressionType) override;
+	unique_ptr<IndexScanState> InitializeScanSinglePredicate(Transaction &transaction, Value value,
+	                                                         ExpressionType expressionType) override;
 
 	//! Initialize a scan on the index with the given expression and column ids
 	//! to fetch from the base table for two predicates
-	unique_ptr<IndexScanState> InitializeScanTwoPredicates(Transaction &transaction, vector<column_t> column_ids,
-	                                                       Value low_value, ExpressionType low_expression_type,
-	                                                       Value high_value,
+	unique_ptr<IndexScanState> InitializeScanTwoPredicates(Transaction &transaction, Value low_value,
+	                                                       ExpressionType low_expression_type, Value high_value,
 	                                                       ExpressionType high_expression_type) override;
 
 	//! Perform a lookup on the index
-	void Scan(Transaction &transaction, DataTable &table, TableIndexScanState &state, DataChunk &result) override;
+	bool Scan(Transaction &transaction, DataTable &table, IndexScanState &state, idx_t max_count,
+	          vector<row_t> &result_ids) override;
 	//! Append entries to the index
 	bool Append(IndexLock &lock, DataChunk &entries, Vector &row_identifiers) override;
 	//! Verify that data can be appended to the index
@@ -113,15 +113,16 @@ class ART : public Index {
 	//! Gets next node for range queries
 	bool IteratorNext(Iterator &iter);
 
-	void SearchEqual(vector<row_t> &result_ids, ARTIndexScanState *state);
-	void SearchGreater(vector<row_t> &result_ids, ARTIndexScanState *state, bool inclusive);
-	void SearchLess(vector<row_t> &result_ids, ARTIndexScanState *state, bool inclusive);
-	void SearchCloseRange(vector<row_t> &result_ids, ARTIndexScanState *state, bool left_inclusive,
-	                      bool right_inclusive);
+	bool SearchEqual(ARTIndexScanState *state, idx_t max_count, vector<row_t> &result_ids);
+	bool SearchGreater(ARTIndexScanState *state, bool inclusive, idx_t max_count, vector<row_t> &result_ids);
+	bool SearchLess(ARTIndexScanState *state, bool inclusive, idx_t max_count, vector<row_t> &result_ids);
+	bool SearchCloseRange(ARTIndexScanState *state, bool left_inclusive, bool right_inclusive, idx_t max_count,
+	                      vector<row_t> &result_ids);
 
 private:
 	template <bool HAS_BOUND, bool INCLUSIVE>
-	void IteratorScan(ARTIndexScanState *state, Iterator *it, vector<row_t> &result_ids, Key *upper_bound);
+	bool IteratorScan(ARTIndexScanState *state, Iterator *it, Key *upper_bound, idx_t max_count,
+	                  vector<row_t> &result_ids);
 
 	void GenerateKeys(DataChunk &input, vector<unique_ptr<Key>> &keys);
 };
diff --git a/src/include/duckdb/execution/operator/list.hpp b/src/include/duckdb/execution/operator/list.hpp
index 795ae844ecc6..2f9627616b15 100644
--- a/src/include/duckdb/execution/operator/list.hpp
+++ b/src/include/duckdb/execution/operator/list.hpp
@@ -22,6 +22,7 @@
 #include "duckdb/execution/operator/persistent/physical_copy_from_file.hpp"
 #include "duckdb/execution/operator/persistent/physical_copy_to_file.hpp"
 #include "duckdb/execution/operator/persistent/physical_delete.hpp"
+#include "duckdb/execution/operator/persistent/physical_export.hpp"
 #include "duckdb/execution/operator/persistent/physical_insert.hpp"
 #include "duckdb/execution/operator/persistent/physical_update.hpp"
 #include "duckdb/execution/operator/projection/physical_projection.hpp"
@@ -30,8 +31,6 @@
 #include "duckdb/execution/operator/scan/physical_dummy_scan.hpp"
 #include "duckdb/execution/operator/scan/physical_empty_result.hpp"
 #include "duckdb/execution/operator/scan/physical_expression_scan.hpp"
-#include "duckdb/execution/operator/scan/physical_index_scan.hpp"
-#include "duckdb/execution/operator/scan/physical_table_function.hpp"
 #include "duckdb/execution/operator/scan/physical_table_scan.hpp"
 #include "duckdb/execution/operator/schema/physical_alter.hpp"
 #include "duckdb/execution/operator/schema/physical_create_index.hpp"
diff --git a/src/include/duckdb/execution/operator/scan/physical_index_scan.hpp b/src/include/duckdb/execution/operator/scan/physical_index_scan.hpp
deleted file mode 100644
index 7ebf6d8ebf9c..000000000000
--- a/src/include/duckdb/execution/operator/scan/physical_index_scan.hpp
+++ /dev/null
@@ -1,55 +0,0 @@
-//===----------------------------------------------------------------------===//
-//                         DuckDB
-//
-// duckdb/execution/operator/scan/physical_index_scan.hpp
-//
-//
-//===----------------------------------------------------------------------===//
-
-#pragma once
-
-#include "duckdb/execution/physical_operator.hpp"
-#include "duckdb/storage/data_table.hpp"
-#include "duckdb/storage/index.hpp"
-
-namespace duckdb {
-
-//! Represents a scan of an index
-class PhysicalIndexScan : public PhysicalOperator {
-public:
-	PhysicalIndexScan(LogicalOperator &op, TableCatalogEntry &tableref, DataTable &table, Index &index,
-	                  vector<column_t> column_ids)
-	    : PhysicalOperator(PhysicalOperatorType::INDEX_SCAN, op.types), tableref(tableref), table(table), index(index),
-	      column_ids(column_ids) {
-	}
-
-	//! The table to scan
-	TableCatalogEntry &tableref;
-	//! The physical data table to scan
-	DataTable &table;
-	//! The index to use for the scan
-	Index &index;
-	//! The column ids to project
-	vector<column_t> column_ids;
-
-	//! The value for the query predicate
-	Value low_value;
-	Value high_value;
-	Value equal_value;
-
-	//! If the predicate is low, high or equal
-	bool low_index = false;
-	bool high_index = false;
-	bool equal_index = false;
-
-	//! The expression type (e.g., >, <, >=, <=)
-	ExpressionType low_expression_type;
-	ExpressionType high_expression_type;
-
-public:
-	void GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state) override;
-	string ExtraRenderInformation() const override;
-	unique_ptr<PhysicalOperatorState> GetOperatorState() override;
-};
-
-} // namespace duckdb
diff --git a/src/include/duckdb/execution/operator/scan/physical_table_function.hpp b/src/include/duckdb/execution/operator/scan/physical_table_function.hpp
deleted file mode 100644
index 2bb3316b515e..000000000000
--- a/src/include/duckdb/execution/operator/scan/physical_table_function.hpp
+++ /dev/null
@@ -1,38 +0,0 @@
-//===----------------------------------------------------------------------===//
-//                         DuckDB
-//
-// duckdb/execution/operator/scan/physical_table_function.hpp
-//
-//
-//===----------------------------------------------------------------------===//
-
-#pragma once
-
-#include "duckdb/execution/physical_operator.hpp"
-#include "duckdb/function/table_function.hpp"
-#include "duckdb/storage/data_table.hpp"
-
-namespace duckdb {
-
-//! Represents a scan of a base table
-class PhysicalTableFunction : public PhysicalOperator {
-public:
-	PhysicalTableFunction(vector<LogicalType> types, TableFunction function, unique_ptr<FunctionData> bind_data,
-	                      vector<Value> parameters)
-	    : PhysicalOperator(PhysicalOperatorType::TABLE_FUNCTION, move(types)), function(move(function)),
-	      bind_data(move(bind_data)), parameters(move(parameters)) {
-	}
-
-	//! Function to call
-	TableFunction function;
-	//! The bind data
-	unique_ptr<FunctionData> bind_data;
-	//! Parameters
-	vector<Value> parameters;
-
-public:
-	void GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state) override;
-	string ExtraRenderInformation() const override;
-};
-
-} // namespace duckdb
diff --git a/src/include/duckdb/execution/operator/scan/physical_table_scan.hpp b/src/include/duckdb/execution/operator/scan/physical_table_scan.hpp
index 8cd857bbc2cd..a439daa72932 100644
--- a/src/include/duckdb/execution/operator/scan/physical_table_scan.hpp
+++ b/src/include/duckdb/execution/operator/scan/physical_table_scan.hpp
@@ -10,31 +10,28 @@
 
 #include "duckdb/execution/physical_operator.hpp"
 #include "duckdb/storage/data_table.hpp"
+#include "duckdb/function/table_function.hpp"
 
 namespace duckdb {
 
 //! Represents a scan of a base table
 class PhysicalTableScan : public PhysicalOperator {
 public:
-	PhysicalTableScan(vector<LogicalType> types, TableCatalogEntry &tableref, DataTable &table,
-	                  vector<column_t> column_ids, vector<unique_ptr<Expression>> filter,
-	                  unordered_map<idx_t, vector<TableFilter>> table_filters);
-
-	//! The table to scan
-	TableCatalogEntry &tableref;
-	//! The physical data table to scan
-	DataTable &table;
-	//! The column ids to project
+	PhysicalTableScan(vector<LogicalType> types, TableFunction function, unique_ptr<FunctionData> bind_data,
+	                  vector<column_t> column_ids, unordered_map<idx_t, vector<TableFilter>> table_filters);
+
+	//! The table function
+	TableFunction function;
+	//! Bind data of the function
+	unique_ptr<FunctionData> bind_data;
+	//! The projected-out column ids
 	vector<column_t> column_ids;
-
-	//! The filter expression
-	unique_ptr<Expression> expression;
-	//! Filters pushed down to table scan
+	//! The table filters
 	unordered_map<idx_t, vector<TableFilter>> table_filters;
 
 public:
 	void GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state) override;
-	string ExtraRenderInformation() const override;
+	string ToString(idx_t depth = 0) const override;
 	unique_ptr<PhysicalOperatorState> GetOperatorState() override;
 
 	void ParallelScanInfo(ClientContext &context, std::function<void(unique_ptr<OperatorTaskInfo>)> callback) override;
diff --git a/src/include/duckdb/execution/physical_operator.hpp b/src/include/duckdb/execution/physical_operator.hpp
index 3fe8755eb121..bfaca7be7298 100644
--- a/src/include/duckdb/execution/physical_operator.hpp
+++ b/src/include/duckdb/execution/physical_operator.hpp
@@ -64,7 +64,7 @@ class PhysicalOperator {
 	vector<LogicalType> types;
 
 public:
-	string ToString(idx_t depth = 0) const;
+	virtual string ToString(idx_t depth = 0) const;
 	void Print();
 
 	//! Return a vector of the types that will be returned by this operator
diff --git a/src/include/duckdb/execution/physical_plan_generator.hpp b/src/include/duckdb/execution/physical_plan_generator.hpp
index 9bbe8aae4495..2ed46e4ded4b 100644
--- a/src/include/duckdb/execution/physical_plan_generator.hpp
+++ b/src/include/duckdb/execution/physical_plan_generator.hpp
@@ -51,13 +51,13 @@ class PhysicalPlanGenerator {
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalDelimGet &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalDelimJoin &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalDistinct &op);
+	unique_ptr<PhysicalOperator> CreatePlan(LogicalDummyScan &expr);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalEmptyResult &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalExpressionGet &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalExport &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalFilter &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalGet &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalLimit &op);
-	unique_ptr<PhysicalOperator> CreatePlan(LogicalIndexScan &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalOrder &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalTopN &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalProjection &op);
@@ -67,7 +67,6 @@ class PhysicalPlanGenerator {
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalExplain &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalSetOperation &op);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalUpdate &op);
-	unique_ptr<PhysicalOperator> CreatePlan(LogicalTableFunction &expr);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalPrepare &expr);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalWindow &expr);
 	unique_ptr<PhysicalOperator> CreatePlan(LogicalExecute &op);
diff --git a/src/include/duckdb/function/table/table_scan.hpp b/src/include/duckdb/function/table/table_scan.hpp
new file mode 100644
index 000000000000..ea2e265a3d15
--- /dev/null
+++ b/src/include/duckdb/function/table/table_scan.hpp
@@ -0,0 +1,41 @@
+//===----------------------------------------------------------------------===//
+//                         DuckDB
+//
+// duckdb/function/table/table_scan.hpp
+//
+//
+//===----------------------------------------------------------------------===//
+
+#pragma once
+
+#include "duckdb/function/table_function.hpp"
+
+namespace duckdb {
+class TableCatalogEntry;
+
+struct TableScanBindData : public FunctionData {
+	TableScanBindData(TableCatalogEntry *table) : table(table), is_index_scan(false) {
+	}
+
+	//! The table to scan
+	TableCatalogEntry *table;
+
+	//! Whether or not the table scan is an index scan
+	bool is_index_scan;
+	//! The row ids to fetch (in case of an index scan)
+	vector<row_t> result_ids;
+
+	unique_ptr<FunctionData> Copy() override {
+		auto result = make_unique<TableScanBindData>(table);
+		result->is_index_scan = is_index_scan;
+		result->result_ids = result_ids;
+		return move(result);
+	}
+};
+
+//! The table scan function represents a sequential scan over one of DuckDB's base tables.
+struct TableScanFunction {
+	static TableFunction GetFunction();
+};
+
+} // namespace duckdb
diff --git a/src/include/duckdb/function/table_function.hpp b/src/include/duckdb/function/table_function.hpp
index 3ed0b93a1b21..adebc9c546e3 100644
--- a/src/include/duckdb/function/table_function.hpp
+++ b/src/include/duckdb/function/table_function.hpp
@@ -11,40 +11,110 @@
 #include "duckdb/function/function.hpp"
 #include "duckdb/common/unordered_map.hpp"
 
+#include <functional>
+
 namespace duckdb {
+class LogicalGet;
+class OperatorTaskInfo;
+class TableFilter;
+
+struct FunctionOperatorData {
+	virtual ~FunctionOperatorData() {
+	}
+};
+
+//! TableFilter represents a filter pushed down into the table scan.
+class TableFilter {
+public:
+	TableFilter(Value constant, ExpressionType comparison_type, idx_t column_index)
+	    : constant(constant), comparison_type(comparison_type), column_index(column_index){};
+	Value constant;
+	ExpressionType comparison_type;
+	idx_t column_index;
+};
 
-//! Function used for determining the return type of a table producing function
 typedef unique_ptr<FunctionData> (*table_function_bind_t)(ClientContext &context, vector<Value> &inputs,
                                                           unordered_map<string, Value> &named_parameters,
                                                           vector<LogicalType> &return_types, vector<string> &names);
-//! Type used for table-returning function
-typedef void (*table_function_t)(ClientContext &context, vector<Value> &input, DataChunk &output,
-                                 FunctionData *dataptr);
-//! Type used for final (cleanup) function
-typedef void (*table_function_final_t)(ClientContext &context, FunctionData *dataptr);
+typedef unique_ptr<FunctionOperatorData> (*table_function_init_t)(
+    ClientContext &context, const FunctionData *bind_data, OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+    unordered_map<idx_t, vector<TableFilter>> &table_filters);
+typedef void (*table_function_t)(ClientContext &context, const FunctionData *bind_data,
+                                 FunctionOperatorData *operator_state, DataChunk &output);
+typedef void (*table_function_cleanup_t)(ClientContext &context, const FunctionData *bind_data,
+                                         FunctionOperatorData *operator_state);
+typedef void (*table_function_parallel_t)(ClientContext &context, const FunctionData *bind_data,
+                                          vector<column_t> &column_ids,
+                                          unordered_map<idx_t, vector<TableFilter>> &table_filters,
+                                          std::function<void(unique_ptr<OperatorTaskInfo>)> callback);
+typedef void (*table_function_dependency_t)(unordered_set<CatalogEntry *> &dependencies, const FunctionData *bind_data);
+typedef idx_t (*table_function_cardinality_t)(const FunctionData *bind_data);
+typedef void (*table_function_pushdown_complex_filter_t)(ClientContext &context, LogicalGet &get,
+                                                         FunctionData *bind_data,
+                                                         vector<unique_ptr<Expression>> &filters);
+typedef string (*table_function_to_string_t)(const FunctionData *bind_data);
 
 class TableFunction : public SimpleFunction {
 public:
-	TableFunction(string name, vector<LogicalType> arguments, table_function_bind_t bind, table_function_t function,
-	              table_function_final_t final = nullptr, bool supports_projection = false)
-	    : SimpleFunction(name, move(arguments)), bind(bind), function(function), final(final),
-	      supports_projection(supports_projection) {
+	TableFunction(string name, vector<LogicalType> arguments, table_function_t function,
+	              table_function_bind_t bind = nullptr, table_function_init_t init = nullptr,
+	              table_function_cleanup_t cleanup = nullptr, table_function_parallel_t parallel_tasks = nullptr,
+	              table_function_dependency_t dependency = nullptr, table_function_cardinality_t cardinality = nullptr,
+	              table_function_pushdown_complex_filter_t pushdown_complex_filter = nullptr,
+	              table_function_to_string_t to_string = nullptr, bool projection_pushdown = false,
+	              bool filter_pushdown = false)
+	    : SimpleFunction(name, move(arguments)), bind(bind), init(init), function(function), cleanup(cleanup),
+	      parallel_tasks(parallel_tasks), dependency(dependency), cardinality(cardinality),
+	      pushdown_complex_filter(pushdown_complex_filter), to_string(to_string),
+	      projection_pushdown(projection_pushdown), filter_pushdown(filter_pushdown) {
 	}
-	TableFunction(vector<LogicalType> arguments, table_function_bind_t bind, table_function_t function,
-	              table_function_final_t final = nullptr, bool supports_projection = false)
-	    : TableFunction(string(), move(arguments), bind, function, final, supports_projection) {
+	TableFunction(vector<LogicalType> arguments, table_function_t function, table_function_bind_t bind = nullptr,
+	              table_function_init_t init = nullptr, table_function_cleanup_t cleanup = nullptr,
+	              table_function_parallel_t parallel_tasks = nullptr, table_function_dependency_t dependency = nullptr,
+	              table_function_cardinality_t cardinality = nullptr,
+	              table_function_pushdown_complex_filter_t pushdown_complex_filter = nullptr,
+	              table_function_to_string_t to_string = nullptr, bool projection_pushdown = false,
+	              bool filter_pushdown = false)
+	    : TableFunction(string(), move(arguments), function, bind, init, cleanup, parallel_tasks, dependency,
+	                    cardinality, pushdown_complex_filter, to_string, projection_pushdown, filter_pushdown) {
 	}
 
-	//! The bind function
+	//! (Optional) Bind function
+	//! This function is used for determining the return type of a table producing function and returning bind data
+	//! The returned FunctionData object should be constant and should not be changed during execution.
 	table_function_bind_t bind;
-	//! The function pointer
+	//! (Optional) init function
+	//! Initialize the operator state of the function. The operator state is used to keep track of the progress in the
+	//! table function.
+	table_function_init_t init;
+	//! The main function
 	table_function_t function;
-	//! Final function pointer
-	table_function_final_t final;
+	//! (Optional) cleanup function
+	//! The final cleanup function, called after all data is exhausted from the main function
+	table_function_cleanup_t cleanup;
+	//! (Optional) parallel task split
+	//! The function used to split the table-producing function into parallel tasks
+	table_function_parallel_t parallel_tasks;
+	//! (Optional) dependency function
+	//! Sets up which catalog entries this table function depend on
+	table_function_dependency_t dependency;
+	//! (Optional) cardinality function
+	//! Returns the expected cardinality of this scan
+	table_function_cardinality_t cardinality;
+	//! (Optional) pushdown a set of arbitrary filter expressions, rather than only simple comparisons with a constant
+	//! Any functions remaining in the expression list will be pushed as a regular filter after the scan
+	table_function_pushdown_complex_filter_t pushdown_complex_filter;
+	//! (Optional) function for rendering the operator to a string in profiling output
+	table_function_to_string_t to_string;
+
 	//! Supported named parameters by the function
 	unordered_map<string, LogicalType> named_parameters;
-	//! Whether or not the table function supports projection
-	bool supports_projection;
+	//! Whether or not the table function supports projection pushdown. If not supported a projection will be added
+	//! that filters out unused columns.
+	bool projection_pushdown;
+	//! Whether or not the table function supports filter pushdown. If not supported a filter will be added
+	//! that applies the table filter directly.
+	bool filter_pushdown;
 
 	string ToString();
 };
diff --git a/src/include/duckdb/optimizer/filter_combiner.hpp b/src/include/duckdb/optimizer/filter_combiner.hpp
index 187ace5a2358..2c6e3c8272e8 100644
--- a/src/include/duckdb/optimizer/filter_combiner.hpp
+++ b/src/include/duckdb/optimizer/filter_combiner.hpp
@@ -37,8 +37,7 @@ class FilterCombiner {
 
 	void GenerateFilters(std::function<void(unique_ptr<Expression> filter)> callback);
 	bool HasFilters();
-	vector<TableFilter> GenerateTableScanFilters(std::function<void(unique_ptr<Expression> filter)> callback,
-	                                             vector<idx_t> &column_ids);
+	vector<TableFilter> GenerateTableScanFilters(vector<idx_t> &column_ids);
 
 private:
 	FilterResult AddFilter(Expression *expr);
diff --git a/src/include/duckdb/optimizer/index_scan.hpp b/src/include/duckdb/optimizer/index_scan.hpp
deleted file mode 100644
index 59d8cff96f2e..000000000000
--- a/src/include/duckdb/optimizer/index_scan.hpp
+++ /dev/null
@@ -1,27 +0,0 @@
-//===----------------------------------------------------------------------===//
-//                         DuckDB
-//
-// duckdb/optimizer/index_scan.hpp
-//
-//
-//===----------------------------------------------------------------------===//
-
-#pragma once
-
-#include "duckdb/optimizer/filter_combiner.hpp"
-#include "duckdb/optimizer/rule.hpp"
-
-namespace duckdb {
-class Optimizer;
-
-class IndexScan {
-public:
-	//! Optimize Filters in Index Scans
-	unique_ptr<LogicalOperator> Optimize(unique_ptr<LogicalOperator> node);
-
-private:
-	//! Transform a Filter in an index scan
-	unique_ptr<LogicalOperator> TransformFilterToIndexScan(unique_ptr<LogicalOperator> op);
-};
-
-} // namespace duckdb
diff --git a/src/include/duckdb/planner/bind_context.hpp b/src/include/duckdb/planner/bind_context.hpp
index ba3e6fb6d848..90df4b1527b0 100644
--- a/src/include/duckdb/planner/bind_context.hpp
+++ b/src/include/duckdb/planner/bind_context.hpp
@@ -45,7 +45,11 @@ class BindContext {
 	void GenerateAllColumnExpressions(vector<unique_ptr<ParsedExpression>> &new_select_list, string relation_name = "");
 
 	//! Adds a base table with the given alias to the BindContext.
-	void AddBaseTable(idx_t index, const string &alias, TableCatalogEntry &table, LogicalGet &get);
+	void AddBaseTable(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types,
+	                  unordered_map<string, column_t> name_map, LogicalGet &get);
+	//! Adds a call to a table function with the given alias to the BindContext.
+	void AddTableFunction(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types,
+	                      LogicalGet &get);
 	//! Adds a subquery with a given alias to the BindContext.
 	void AddSubquery(idx_t index, const string &alias, SubqueryRef &ref, BoundQueryNode &subquery);
 	//! Adds a base table with the given alias to the BindContext.
diff --git a/src/include/duckdb/planner/logical_tokens.hpp b/src/include/duckdb/planner/logical_tokens.hpp
index 5fd7488cffd5..01852dc9b385 100644
--- a/src/include/duckdb/planner/logical_tokens.hpp
+++ b/src/include/duckdb/planner/logical_tokens.hpp
@@ -28,6 +28,7 @@ class LogicalDelete;
 class LogicalDelimGet;
 class LogicalDelimJoin;
 class LogicalDistinct;
+class LogicalDummyScan;
 class LogicalEmptyResult;
 class LogicalExecute;
 class LogicalExplain;
@@ -35,7 +36,6 @@ class LogicalExport;
 class LogicalExpressionGet;
 class LogicalFilter;
 class LogicalGet;
-class LogicalIndexScan;
 class LogicalInsert;
 class LogicalJoin;
 class LogicalLimit;
@@ -46,7 +46,6 @@ class LogicalProjection;
 class LogicalRecursiveCTE;
 class LogicalSetOperation;
 class LogicalSimple;
-class LogicalTableFunction;
 class LogicalTopN;
 class LogicalUnnest;
 class LogicalUpdate;
diff --git a/src/include/duckdb/planner/operator/list.hpp b/src/include/duckdb/planner/operator/list.hpp
index 34ff14b10cec..bbd3c9b189e0 100644
--- a/src/include/duckdb/planner/operator/list.hpp
+++ b/src/include/duckdb/planner/operator/list.hpp
@@ -13,6 +13,7 @@
 #include "duckdb/planner/operator/logical_delim_get.hpp"
 #include "duckdb/planner/operator/logical_delim_join.hpp"
 #include "duckdb/planner/operator/logical_distinct.hpp"
+#include "duckdb/planner/operator/logical_dummy_scan.hpp"
 #include "duckdb/planner/operator/logical_empty_result.hpp"
 #include "duckdb/planner/operator/logical_execute.hpp"
 #include "duckdb/planner/operator/logical_explain.hpp"
@@ -20,7 +21,6 @@
 #include "duckdb/planner/operator/logical_expression_get.hpp"
 #include "duckdb/planner/operator/logical_filter.hpp"
 #include "duckdb/planner/operator/logical_get.hpp"
-#include "duckdb/planner/operator/logical_index_scan.hpp"
 #include "duckdb/planner/operator/logical_insert.hpp"
 #include "duckdb/planner/operator/logical_join.hpp"
 #include "duckdb/planner/operator/logical_limit.hpp"
@@ -31,7 +31,6 @@
 #include "duckdb/planner/operator/logical_recursive_cte.hpp"
 #include "duckdb/planner/operator/logical_set_operation.hpp"
 #include "duckdb/planner/operator/logical_simple.hpp"
-#include "duckdb/planner/operator/logical_table_function.hpp"
 #include "duckdb/planner/operator/logical_top_n.hpp"
 #include "duckdb/planner/operator/logical_unnest.hpp"
 #include "duckdb/planner/operator/logical_update.hpp"
diff --git a/src/include/duckdb/planner/operator/logical_dummy_scan.hpp b/src/include/duckdb/planner/operator/logical_dummy_scan.hpp
new file mode 100644
index 000000000000..612f8e081b56
--- /dev/null
+++ b/src/include/duckdb/planner/operator/logical_dummy_scan.hpp
@@ -0,0 +1,39 @@
+//===----------------------------------------------------------------------===//
+//                         DuckDB
+//
+// duckdb/planner/operator/logical_dummy_scan.hpp
+//
+//
+//===----------------------------------------------------------------------===//
+
+#pragma once
+
+#include "duckdb/planner/logical_operator.hpp"
+
+namespace duckdb {
+
+//! LogicalDummyScan represents a dummy scan returning a single row
+class LogicalDummyScan : public LogicalOperator {
+public:
+	LogicalDummyScan(idx_t table_index) : LogicalOperator(LogicalOperatorType::DUMMY_SCAN), table_index(table_index) {
+	}
+
+	idx_t table_index;
+
+public:
+	vector<ColumnBinding> GetColumnBindings() override {
+		return {ColumnBinding(table_index, 0)};
+	}
+
+	idx_t EstimateCardinality() override {
+		return 1;
+	}
+
+protected:
+	void ResolveTypes() override {
+		if (types.size() == 0) {
+			types.push_back(LogicalType::INTEGER);
+		}
+	}
+};
+} // namespace duckdb
diff --git a/src/include/duckdb/planner/operator/logical_get.hpp b/src/include/duckdb/planner/operator/logical_get.hpp
index 38b4c3b7581c..a5c65987fdd0 100644
--- a/src/include/duckdb/planner/operator/logical_get.hpp
+++ b/src/include/duckdb/planner/operator/logical_get.hpp
@@ -8,35 +8,39 @@
 
 #pragma once
 
-#include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
 #include "duckdb/planner/logical_operator.hpp"
-
-#include "duckdb/storage/data_table.hpp"
+#include "duckdb/function/table_function.hpp"
 
 namespace duckdb {
 
 //! LogicalGet represents a scan operation from a data source
 class LogicalGet : public LogicalOperator {
 public:
-	LogicalGet(idx_t table_index);
-	LogicalGet(TableCatalogEntry *table, idx_t table_index);
-	LogicalGet(TableCatalogEntry *table, idx_t table_index, vector<column_t> column_ids);
-
-	idx_t EstimateCardinality() override;
+	LogicalGet(idx_t table_index, TableFunction function, unique_ptr<FunctionData> bind_data,
+	           vector<LogicalType> returned_types, vector<string> returned_names);
 
-	//! The base table to retrieve data from
-	TableCatalogEntry *table;
 	//! The table index in the current bind context
 	idx_t table_index;
+	//! The function that is called
+	TableFunction function;
+	//! The bind data of the function
+	unique_ptr<FunctionData> bind_data;
+	//! The types of ALL columns that can be returned by the table function
+	vector<LogicalType> returned_types;
+	//! The names of ALL columns that can be returned by the table function
+	vector<string> names;
 	//! Bound column IDs
 	vector<column_t> column_ids;
 	//! Filters pushed down for table scan
 	vector<TableFilter> tableFilters;
+
 	string ParamsToString() const override;
 
 public:
 	vector<ColumnBinding> GetColumnBindings() override;
 
+	idx_t EstimateCardinality() override;
+
 protected:
 	void ResolveTypes() override;
 };
diff --git a/src/include/duckdb/planner/operator/logical_index_scan.hpp b/src/include/duckdb/planner/operator/logical_index_scan.hpp
deleted file mode 100644
index 3116bb1db796..000000000000
--- a/src/include/duckdb/planner/operator/logical_index_scan.hpp
+++ /dev/null
@@ -1,67 +0,0 @@
-//===----------------------------------------------------------------------===//
-//                         DuckDB
-//
-// duckdb/planner/operator/logical_index_scan.hpp
-//
-//
-//===----------------------------------------------------------------------===//
-
-#pragma once
-
-#include "duckdb/planner/logical_operator.hpp"
-#include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
-#include "duckdb/storage/index.hpp"
-
-namespace duckdb {
-
-//! LogicalIndex represents an Index Scan operation
-class LogicalIndexScan : public LogicalOperator {
-public:
-	LogicalIndexScan(TableCatalogEntry &tableref, DataTable &table, Index &index, vector<column_t> column_ids,
-	                 idx_t table_index)
-	    : LogicalOperator(LogicalOperatorType::INDEX_SCAN), tableref(tableref), table(table), index(index),
-	      column_ids(column_ids), table_index(table_index) {
-	}
-
-	//! The table to scan
-	TableCatalogEntry &tableref;
-	//! The physical data table to scan
-	DataTable &table;
-	//! The index to use for the scan
-	Index &index;
-	//! The column ids to project
-	vector<column_t> column_ids;
-
-	//! The value for the query predicate
-	Value low_value;
-	Value high_value;
-	Value equal_value;
-
-	//! If the predicate is low, high or equal
-	bool low_index = false;
-	bool high_index = false;
-	bool equal_index = false;
-
-	//! The expression type (e.g., >, <, >=, <=)
-	ExpressionType low_expression_type;
-	ExpressionType high_expression_type;
-
-	//! The table index in the current bind context
-	idx_t table_index;
-
-public:
-	vector<ColumnBinding> GetColumnBindings() override {
-		return GenerateColumnBindings(table_index, column_ids.size());
-	}
-
-protected:
-	void ResolveTypes() override {
-		if (column_ids.size() == 0) {
-			types = {LogicalType::INTEGER};
-		} else {
-			types = tableref.GetTypes(column_ids);
-		}
-	}
-};
-
-} // namespace duckdb
diff --git a/src/include/duckdb/planner/operator/logical_table_function.hpp b/src/include/duckdb/planner/operator/logical_table_function.hpp
deleted file mode 100644
index 73bcd4d56306..000000000000
--- a/src/include/duckdb/planner/operator/logical_table_function.hpp
+++ /dev/null
@@ -1,49 +0,0 @@
-//===----------------------------------------------------------------------===//
-//                         DuckDB
-//
-// duckdb/planner/operator/logical_table_function.hpp
-//
-//
-//===----------------------------------------------------------------------===//
-
-#pragma once
-
-#include "duckdb/planner/logical_operator.hpp"
-#include "duckdb/function/table_function.hpp"
-#include "duckdb/common/types/value.hpp"
-
-namespace duckdb {
-
-//! LogicalTableFunction represents a call to a table-producing function
-class LogicalTableFunction : public LogicalOperator {
-public:
-	LogicalTableFunction(TableFunction function, idx_t table_index, unique_ptr<FunctionData> bind_data,
-	                     vector<Value> parameters, vector<LogicalType> return_types, vector<string> names)
-	    : LogicalOperator(LogicalOperatorType::TABLE_FUNCTION), function(move(function)), table_index(table_index),
-	      bind_data(move(bind_data)), parameters(move(parameters)), return_types(move(return_types)),
-	      names(move(names)) {
-	}
-
-	//! The function
-	TableFunction function;
-	//! The table index of the table-producing function
-	idx_t table_index;
-	//! The bind data of the function
-	unique_ptr<FunctionData> bind_data;
-	//! The input parameters
-	vector<Value> parameters;
-	//! The set of returned sql types
-	vector<LogicalType> return_types;
-	//! The set of returned column names
-	vector<string> names;
-	//! Bound column IDs
-	vector<column_t> column_ids;
-
-public:
-	vector<ColumnBinding> GetColumnBindings() override;
-	string ParamsToString() const override;
-
-protected:
-	void ResolveTypes() override;
-};
-} // namespace duckdb
diff --git a/src/include/duckdb/planner/table_binding.hpp b/src/include/duckdb/planner/table_binding.hpp
index 285eadd51f08..c270c6bc4930 100644
--- a/src/include/duckdb/planner/table_binding.hpp
+++ b/src/include/duckdb/planner/table_binding.hpp
@@ -24,53 +24,40 @@ class TableCatalogEntry;
 class TableFunctionCatalogEntry;
 class BoundTableFunction;
 
-enum class BindingType : uint8_t { TABLE = 0, SUBQUERY = 1, TABLE_FUNCTION = 2, GENERIC = 3 };
-
-//! A Binding represents a binding to a table, table-producing function or subquery with a specified table index. Used
-//! in the binder.
+//! A Binding represents a binding to a table, table-producing function or subquery with a specified table index.
 struct Binding {
-	Binding(BindingType type, const string &alias, idx_t index) : type(type), alias(alias), index(index) {
-	}
+	Binding(const string &alias, vector<LogicalType> types, vector<string> names, idx_t index);
+	Binding(const string &alias, idx_t index);
 	virtual ~Binding() = default;
 
-	BindingType type;
+	//! The alias of the binding
 	string alias;
+	//! The table index of the binding
 	idx_t index;
+	vector<LogicalType> types;
+	//! Column names of the subquery
+	vector<string> names;
+	//! Name -> index for the names
+	unordered_map<string, column_t> name_map;
 
 public:
-	virtual bool HasMatchingBinding(const string &column_name) = 0;
-	virtual BindResult Bind(ColumnRefExpression &colref, idx_t depth) = 0;
-	virtual void GenerateAllColumnExpressions(BindContext &context,
-	                                          vector<unique_ptr<ParsedExpression>> &select_list) = 0;
+	bool HasMatchingBinding(const string &column_name);
+	virtual BindResult Bind(ColumnRefExpression &colref, idx_t depth);
+	void GenerateAllColumnExpressions(BindContext &context, vector<unique_ptr<ParsedExpression>> &select_list);
 };
 
-//! Represents a binding to a base table
+//! TableBinding is exactly like the Binding, except it keeps track of which columns were bound in the linked LogicalGet
+//! node for projection pushdown purposes.
 struct TableBinding : public Binding {
-	TableBinding(const string &alias, TableCatalogEntry &table, LogicalGet &get, idx_t index);
+	TableBinding(const string &alias, vector<LogicalType> types, vector<string> names, LogicalGet &get, idx_t index);
+	TableBinding(const string &alias, vector<LogicalType> types, vector<string> names,
+	             unordered_map<string, column_t> name_map, LogicalGet &get, idx_t index);
 
-	TableCatalogEntry &table;
+	//! the underlying LogicalGet
 	LogicalGet &get;
 
 public:
-	bool HasMatchingBinding(const string &column_name) override;
-	BindResult Bind(ColumnRefExpression &colref, idx_t depth) override;
-	void GenerateAllColumnExpressions(BindContext &context, vector<unique_ptr<ParsedExpression>> &select_list) override;
-};
-
-//! Represents a generic binding with types and names
-struct GenericBinding : public Binding {
-	GenericBinding(const string &alias, vector<LogicalType> types, vector<string> names, idx_t index);
-
-	vector<LogicalType> types;
-	//! Column names of the subquery
-	vector<string> names;
-	//! Name -> index for the names
-	unordered_map<string, column_t> name_map;
-
-public:
-	bool HasMatchingBinding(const string &column_name) override;
 	BindResult Bind(ColumnRefExpression &colref, idx_t depth) override;
-	void GenerateAllColumnExpressions(BindContext &context, vector<unique_ptr<ParsedExpression>> &select_list) override;
 };
 
 } // namespace duckdb
diff --git a/src/include/duckdb/planner/tableref/bound_basetableref.hpp b/src/include/duckdb/planner/tableref/bound_basetableref.hpp
index 679d33651298..b3182c7f47b7 100644
--- a/src/include/duckdb/planner/tableref/bound_basetableref.hpp
+++ b/src/include/duckdb/planner/tableref/bound_basetableref.hpp
@@ -17,9 +17,11 @@ class TableCatalogEntry;
 //! Represents a TableReference to a base table in the schema
 class BoundBaseTableRef : public BoundTableRef {
 public:
-	BoundBaseTableRef(unique_ptr<LogicalOperator> get) : BoundTableRef(TableReferenceType::BASE_TABLE), get(move(get)) {
+	BoundBaseTableRef(TableCatalogEntry *table, unique_ptr<LogicalOperator> get)
+	    : BoundTableRef(TableReferenceType::BASE_TABLE), table(table), get(move(get)) {
 	}
 
+	TableCatalogEntry *table;
 	unique_ptr<LogicalOperator> get;
 };
 } // namespace duckdb
diff --git a/src/include/duckdb/planner/tableref/bound_table_function.hpp b/src/include/duckdb/planner/tableref/bound_table_function.hpp
index b6b6361273fa..20e5575a8a61 100644
--- a/src/include/duckdb/planner/tableref/bound_table_function.hpp
+++ b/src/include/duckdb/planner/tableref/bound_table_function.hpp
@@ -8,31 +8,19 @@
 
 #pragma once
 
-#include "duckdb/common/types/value.hpp"
-#include "duckdb/planner/expression.hpp"
 #include "duckdb/planner/bound_tableref.hpp"
-#include "duckdb/function/table_function.hpp"
+#include "duckdb/planner/logical_operator.hpp"
 
 namespace duckdb {
 
 //! Represents a reference to a table-producing function call
 class BoundTableFunction : public BoundTableRef {
 public:
-	BoundTableFunction(TableFunction function, idx_t bind_index)
-	    : BoundTableRef(TableReferenceType::TABLE_FUNCTION), function(function), bind_index(bind_index) {
+	BoundTableFunction(unique_ptr<LogicalOperator> get)
+	    : BoundTableRef(TableReferenceType::TABLE_FUNCTION), get(move(get)) {
 	}
 
-	//! The function that is called
-	TableFunction function;
-	//! The bind data of the function
-	unique_ptr<FunctionData> bind_data;
-	//! The set of parameters to use as input to the table-producing function
-	vector<Value> parameters;
-	//! The set of returned sql types
-	vector<LogicalType> return_types;
-	//! The set of returned column names
-	vector<string> names;
-	//! The index in the bind context
-	idx_t bind_index;
+	unique_ptr<LogicalOperator> get;
 };
+
 } // namespace duckdb
diff --git a/src/include/duckdb/storage/data_table.hpp b/src/include/duckdb/storage/data_table.hpp
index d54be8443e5c..39b5d6e9fda6 100644
--- a/src/include/duckdb/storage/data_table.hpp
+++ b/src/include/duckdb/storage/data_table.hpp
@@ -32,16 +32,6 @@ class Transaction;
 
 typedef unique_ptr<vector<unique_ptr<PersistentSegment>>[]> persistent_data_t;
 
-//! TableFilter represents a filter pushed down into the table scan.
-class TableFilter {
-public:
-	TableFilter(Value constant, ExpressionType comparison_type, idx_t column_index)
-	    : constant(constant), comparison_type(comparison_type), column_index(column_index){};
-	Value constant;
-	ExpressionType comparison_type;
-	idx_t column_index;
-};
-
 struct DataTableInfo {
 	DataTableInfo(string schema, string table) : cardinality(0), schema(move(schema)), table(move(table)) {
 	}
@@ -97,19 +87,9 @@ class DataTable {
 	void Scan(Transaction &transaction, DataChunk &result, TableScanState &state, vector<column_t> &column_ids,
 	          unordered_map<idx_t, vector<TableFilter>> &table_filters);
 
-	//! Initialize an index scan with a single predicate and a comparison type (= <= < > >=)
-	void InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index, Value value,
-	                         ExpressionType expr_type, vector<column_t> column_ids);
-	//! Initialize an index scan with two predicates and two comparison types (> >= < <=)
-	void InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index, Value low_value,
-	                         ExpressionType low_type, Value high_value, ExpressionType high_type,
-	                         vector<column_t> column_ids);
-	//! Scans up to STANDARD_VECTOR_SIZE elements from the table from the given index structure
-	void IndexScan(Transaction &transaction, DataChunk &result, TableIndexScanState &state);
-
 	//! Fetch data from the specific row identifiers from the base table
 	void Fetch(Transaction &transaction, DataChunk &result, vector<column_t> &column_ids, Vector &row_ids,
-	           idx_t fetch_count, TableIndexScanState &state);
+	           idx_t fetch_count, ColumnFetchState &state);
 
 	//! Append a DataChunk to the table. Throws an exception if the columns don't match the tables' columns.
 	void Append(TableCatalogEntry &table, ClientContext &context, DataChunk &chunk);
@@ -150,9 +130,6 @@ class DataTable {
 	//! Verify constraints with a chunk from the Update containing only the specified column_ids
 	void VerifyUpdateConstraints(TableCatalogEntry &table, DataChunk &chunk, vector<column_t> &column_ids);
 
-	void InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index,
-	                         vector<column_t> column_ids);
-
 	void InitializeScanWithOffset(TableScanState &state, const vector<column_t> &column_ids,
 	                              unordered_map<idx_t, vector<TableFilter>> *table_filters, idx_t offset);
 	bool CheckZonemap(TableScanState &state, unordered_map<idx_t, vector<TableFilter>> &table_filters,
diff --git a/src/include/duckdb/storage/index.hpp b/src/include/duckdb/storage/index.hpp
index 23bc6f168f14..a74aba637f82 100644
--- a/src/include/duckdb/storage/index.hpp
+++ b/src/include/duckdb/storage/index.hpp
@@ -47,17 +47,17 @@ class Index {
 public:
 	//! Initialize a scan on the index with the given expression and column ids
 	//! to fetch from the base table when we only have one query predicate
-	virtual unique_ptr<IndexScanState> InitializeScanSinglePredicate(Transaction &transaction,
-	                                                                 vector<column_t> column_ids, Value value,
+	virtual unique_ptr<IndexScanState> InitializeScanSinglePredicate(Transaction &transaction, Value value,
 	                                                                 ExpressionType expressionType) = 0;
 	//! Initialize a scan on the index with the given expression and column ids
 	//! to fetch from the base table for two query predicates
-	virtual unique_ptr<IndexScanState> InitializeScanTwoPredicates(Transaction &transaction,
-	                                                               vector<column_t> column_ids, Value low_value,
+	virtual unique_ptr<IndexScanState> InitializeScanTwoPredicates(Transaction &transaction, Value low_value,
 	                                                               ExpressionType low_expression_type, Value high_value,
 	                                                               ExpressionType high_expression_type) = 0;
-	//! Perform a lookup on the index
-	virtual void Scan(Transaction &transaction, DataTable &table, TableIndexScanState &state, DataChunk &result) = 0;
+	//! Perform a lookup on the index, fetching up to max_count result ids. Returns true if all row ids were fetched,
+	//! and false otherwise.
+	virtual bool Scan(Transaction &transaction, DataTable &table, IndexScanState &state, idx_t max_count,
+	                  vector<row_t> &result_ids) = 0;
 
 	//! Obtain a lock on the index
 	virtual void InitializeLock(IndexLock &state);
diff --git a/src/include/duckdb/storage/table/scan_state.hpp b/src/include/duckdb/storage/table/scan_state.hpp
index f9416f3982b6..2039af87eba1 100644
--- a/src/include/duckdb/storage/table/scan_state.hpp
+++ b/src/include/duckdb/storage/table/scan_state.hpp
@@ -22,10 +22,6 @@ class PersistentSegment;
 class TransientSegment;
 
 struct IndexScanState {
-	vector<column_t> column_ids;
-
-	IndexScanState(vector<column_t> column_ids) : column_ids(column_ids) {
-	}
 	virtual ~IndexScanState() {
 	}
 };
@@ -86,12 +82,4 @@ class CreateIndexScanState : public TableScanState {
 	std::unique_lock<std::mutex> append_lock;
 };
 
-struct TableIndexScanState {
-	Index *index;
-	unique_ptr<IndexScanState> index_state;
-	ColumnFetchState fetch_state;
-	LocalScanState local_state;
-	vector<column_t> column_ids;
-};
-
 } // namespace duckdb
diff --git a/src/main/query_profiler.cpp b/src/main/query_profiler.cpp
index 1b59a6df7cfc..3f6ee5259070 100644
--- a/src/main/query_profiler.cpp
+++ b/src/main/query_profiler.cpp
@@ -52,9 +52,7 @@ bool QueryProfiler::OperatorRequiresProfiling(PhysicalOperatorType op_type) {
 	case PhysicalOperatorType::PROJECTION:
 	case PhysicalOperatorType::COPY_FROM_FILE:
 	case PhysicalOperatorType::COPY_TO_FILE:
-	case PhysicalOperatorType::TABLE_FUNCTION:
-	case PhysicalOperatorType::SEQ_SCAN:
-	case PhysicalOperatorType::INDEX_SCAN:
+	case PhysicalOperatorType::TABLE_SCAN:
 	case PhysicalOperatorType::CHUNK_SCAN:
 	case PhysicalOperatorType::DELIM_SCAN:
 	case PhysicalOperatorType::EXTERNAL_FILE_SCAN:
diff --git a/src/optimizer/CMakeLists.txt b/src/optimizer/CMakeLists.txt
index 21aaa19ab4ed..e3458148303e 100644
--- a/src/optimizer/CMakeLists.txt
+++ b/src/optimizer/CMakeLists.txt
@@ -3,21 +3,21 @@ add_subdirectory(join_order)
 add_subdirectory(pushdown)
 add_subdirectory(rule)
 
-add_library_unity(duckdb_optimizer
-                  OBJECT
-                  cse_optimizer.cpp
-                  column_lifetime_analyzer.cpp
-                  expression_heuristics.cpp
-                  filter_combiner.cpp
-                  filter_pushdown.cpp
-                  in_clause_rewriter.cpp
-                  join_order_optimizer.cpp
-                  optimizer.cpp
-                  expression_rewriter.cpp
-                  regex_range_filter.cpp
-                  remove_unused_columns.cpp
-                  index_scan.cpp
-                  topn_optimizer.cpp)
+add_library_unity(
+  duckdb_optimizer
+  OBJECT
+  cse_optimizer.cpp
+  column_lifetime_analyzer.cpp
+  expression_heuristics.cpp
+  filter_combiner.cpp
+  filter_pushdown.cpp
+  in_clause_rewriter.cpp
+  join_order_optimizer.cpp
+  optimizer.cpp
+  expression_rewriter.cpp
+  regex_range_filter.cpp
+  remove_unused_columns.cpp
+  topn_optimizer.cpp)
 set(ALL_OBJECT_FILES
     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_optimizer>
     PARENT_SCOPE)
diff --git a/src/optimizer/filter_combiner.cpp b/src/optimizer/filter_combiner.cpp
index 70ab3a49855e..f51cc9f5d57c 100644
--- a/src/optimizer/filter_combiner.cpp
+++ b/src/optimizer/filter_combiner.cpp
@@ -155,14 +155,11 @@ bool FilterCombiner::HasFilters() {
 	return has_filters;
 }
 
-vector<TableFilter>
-FilterCombiner::GenerateTableScanFilters(std::function<void(unique_ptr<Expression> filter)> callback,
-                                         vector<idx_t> &column_ids) {
+vector<TableFilter> FilterCombiner::GenerateTableScanFilters(vector<idx_t> &column_ids) {
 	vector<TableFilter> tableFilters;
 	//! First, we figure the filters that have constant expressions that we can push down to the table scan
 	for (auto &constant_value : constant_values) {
 		if (constant_value.second.size() > 0) {
-			//			for (idx_t i = 0; i < constant_value.second.size(); ++i) {
 			auto filter_exp = equivalence_map.end();
 			if ((constant_value.second[0].comparison_type == ExpressionType::COMPARE_EQUAL ||
 			     constant_value.second[0].comparison_type == ExpressionType::COMPARE_GREATERTHAN ||
@@ -183,45 +180,11 @@ FilterCombiner::GenerateTableScanFilters(std::function<void(unique_ptr<Expressio
 					auto &constant_list = constant_values.find(equivalence_set)->second;
 					// for each entry generate an equality expression comparing to each other
 					for (idx_t i = 0; i < entries.size(); i++) {
-						for (idx_t k = i + 1; k < entries.size(); k++) {
-							auto comparison = make_unique<BoundComparisonExpression>(
-							    ExpressionType::COMPARE_EQUAL, entries[i]->Copy(), entries[k]->Copy());
-							callback(move(comparison));
-						}
 						// for each entry also create a comparison with each constant
-						int lower_index = -1, upper_index = -1;
 						for (idx_t k = 0; k < constant_list.size(); k++) {
 							tableFilters.push_back(TableFilter(constant_value.second[k].constant,
 							                                   constant_value.second[k].comparison_type,
 							                                   filter_col_exp->binding.column_index));
-							auto &info = constant_list[k];
-							if (info.comparison_type == ExpressionType::COMPARE_GREATERTHAN ||
-							    info.comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO) {
-								lower_index = k;
-
-							} else if (info.comparison_type == ExpressionType::COMPARE_LESSTHAN ||
-							           info.comparison_type == ExpressionType::COMPARE_LESSTHANOREQUALTO) {
-								upper_index = k;
-							} else {
-								auto constant = make_unique<BoundConstantExpression>(info.constant);
-								auto comparison = make_unique<BoundComparisonExpression>(
-								    info.comparison_type, entries[i]->Copy(), move(constant));
-								callback(move(comparison));
-							}
-						}
-						if (lower_index >= 0) {
-							// only lower index found, create simple comparison expression
-							auto constant = make_unique<BoundConstantExpression>(constant_list[lower_index].constant);
-							auto comparison = make_unique<BoundComparisonExpression>(
-							    constant_list[lower_index].comparison_type, entries[i]->Copy(), move(constant));
-							callback(move(comparison));
-						}
-						if (upper_index >= 0) {
-							// only upper index found, create simple comparison expression
-							auto constant = make_unique<BoundConstantExpression>(constant_list[upper_index].constant);
-							auto comparison = make_unique<BoundComparisonExpression>(
-							    constant_list[upper_index].comparison_type, entries[i]->Copy(), move(constant));
-							callback(move(comparison));
 						}
 					}
 					equivalence_map.erase(filter_exp);
diff --git a/src/optimizer/index_scan.cpp b/src/optimizer/index_scan.cpp
deleted file mode 100644
index 5264fcd000cf..000000000000
--- a/src/optimizer/index_scan.cpp
+++ /dev/null
@@ -1,155 +0,0 @@
-#include "duckdb/optimizer/index_scan.hpp"
-#include "duckdb/optimizer/matcher/expression_matcher.hpp"
-
-#include "duckdb/parser/expression/comparison_expression.hpp"
-
-#include "duckdb/planner/expression/bound_columnref_expression.hpp"
-#include "duckdb/planner/expression/bound_comparison_expression.hpp"
-#include "duckdb/planner/expression/bound_constant_expression.hpp"
-#include "duckdb/planner/expression_iterator.hpp"
-#include "duckdb/planner/operator/logical_filter.hpp"
-#include "duckdb/planner/operator/logical_get.hpp"
-#include "duckdb/planner/operator/logical_index_scan.hpp"
-
-#include "duckdb/storage/data_table.hpp"
-namespace duckdb {
-using namespace std;
-
-unique_ptr<LogicalOperator> IndexScan::Optimize(unique_ptr<LogicalOperator> op) {
-	if (op->type == LogicalOperatorType::FILTER && op->children[0]->type == LogicalOperatorType::GET) {
-		return TransformFilterToIndexScan(move(op));
-	}
-	for (auto &child : op->children) {
-		child = Optimize(move(child));
-	}
-	return op;
-}
-
-static void RewriteIndexExpression(Index &index, LogicalGet &get, Expression &expr, bool &rewrite_possible) {
-	if (expr.type == ExpressionType::BOUND_COLUMN_REF) {
-		auto &bound_colref = (BoundColumnRefExpression &)expr;
-		// bound column ref: rewrite to fit in the current set of bound column ids
-		bound_colref.binding.table_index = get.table_index;
-		column_t referenced_column = index.column_ids[bound_colref.binding.column_index];
-		// search for the referenced column in the set of column_ids
-		for (idx_t i = 0; i < get.column_ids.size(); i++) {
-			if (get.column_ids[i] == referenced_column) {
-				bound_colref.binding.column_index = i;
-				return;
-			}
-		}
-		// column id not found in bound columns in the LogicalGet: rewrite not possible
-		rewrite_possible = false;
-	}
-	ExpressionIterator::EnumerateChildren(
-	    expr, [&](Expression &child) { RewriteIndexExpression(index, get, child, rewrite_possible); });
-}
-
-unique_ptr<LogicalOperator> IndexScan::TransformFilterToIndexScan(unique_ptr<LogicalOperator> op) {
-	assert(op->type == LogicalOperatorType::FILTER);
-	auto &filter = (LogicalFilter &)*op;
-	auto get = (LogicalGet *)op->children[0].get();
-
-	if (!get->table) {
-		return op;
-	}
-
-	auto &storage = *get->table->storage;
-
-	if (storage.info->indexes.size() == 0) {
-		// no indexes on the table, can't rewrite
-		return op;
-	}
-
-	// check all the indexes
-	for (size_t j = 0; j < storage.info->indexes.size(); j++) {
-		auto &index = storage.info->indexes[j];
-
-		//		assert(index->unbound_expressions.size() == 1);
-		// first rewrite the index expression so the ColumnBindings align with the column bindings of the current table
-		if (index->unbound_expressions.size() > 1)
-			continue;
-		auto index_expression = index->unbound_expressions[0]->Copy();
-		bool rewrite_possible = true;
-		RewriteIndexExpression(*index, *get, *index_expression, rewrite_possible);
-		if (!rewrite_possible) {
-			// could not rewrite!
-			continue;
-		}
-
-		Value low_value, high_value, equal_value;
-		// try to find a matching index for any of the filter expressions
-		auto expr = filter.expressions[0].get();
-		auto low_comparison_type = expr->type;
-		auto high_comparison_type = expr->type;
-		for (idx_t i = 0; i < filter.expressions.size(); i++) {
-			expr = filter.expressions[i].get();
-			// create a matcher for a comparison with a constant
-			ComparisonExpressionMatcher matcher;
-			// match on a comparison type
-			matcher.expr_type = make_unique<ComparisonExpressionTypeMatcher>();
-			// match on a constant comparison with the indexed expression
-			matcher.matchers.push_back(make_unique<ExpressionEqualityMatcher>(index_expression.get()));
-			matcher.matchers.push_back(make_unique<ConstantExpressionMatcher>());
-
-			matcher.policy = SetMatcher::Policy::UNORDERED;
-
-			vector<Expression *> bindings;
-			if (matcher.Match(expr, bindings)) {
-				// range or equality comparison with constant value
-				// we can use our index here
-				// bindings[0] = the expression
-				// bindings[1] = the index expression
-				// bindings[2] = the constant
-				auto comparison = (BoundComparisonExpression *)bindings[0];
-				assert(bindings[0]->GetExpressionClass() == ExpressionClass::BOUND_COMPARISON);
-				assert(bindings[2]->type == ExpressionType::VALUE_CONSTANT);
-
-				auto constant_value = ((BoundConstantExpression *)bindings[2])->value;
-				auto comparison_type = comparison->type;
-				if (comparison->left->type == ExpressionType::VALUE_CONSTANT) {
-					// the expression is on the right side, we flip them around
-					comparison_type = FlipComparisionExpression(comparison_type);
-				}
-				if (comparison_type == ExpressionType::COMPARE_EQUAL) {
-					// equality value
-					// equality overrides any other bounds so we just break here
-					equal_value = constant_value;
-					break;
-				} else if (comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO ||
-				           comparison_type == ExpressionType::COMPARE_GREATERTHAN) {
-					// greater than means this is a lower bound
-					low_value = constant_value;
-					low_comparison_type = comparison_type;
-				} else {
-					// smaller than means this is an upper bound
-					high_value = constant_value;
-					high_comparison_type = comparison_type;
-				}
-			}
-		}
-		if (!equal_value.is_null || !low_value.is_null || !high_value.is_null) {
-			auto logical_index_scan = make_unique<LogicalIndexScan>(*get->table, *get->table->storage, *index,
-			                                                        get->column_ids, get->table_index);
-			if (!equal_value.is_null) {
-				logical_index_scan->equal_value = equal_value;
-				logical_index_scan->equal_index = true;
-			}
-			if (!low_value.is_null) {
-				logical_index_scan->low_value = low_value;
-				logical_index_scan->low_index = true;
-				logical_index_scan->low_expression_type = low_comparison_type;
-			}
-			if (!high_value.is_null) {
-				logical_index_scan->high_value = high_value;
-				logical_index_scan->high_index = true;
-				logical_index_scan->high_expression_type = high_comparison_type;
-			}
-			op->children[0] = move(logical_index_scan);
-			break;
-		}
-	}
-	return op;
-}
-
-} // namespace duckdb
diff --git a/src/optimizer/join_order_optimizer.cpp b/src/optimizer/join_order_optimizer.cpp
index 2c59877580ac..d83b04aee817 100644
--- a/src/optimizer/join_order_optimizer.cpp
+++ b/src/optimizer/join_order_optimizer.cpp
@@ -143,11 +143,11 @@ bool JoinOrderOptimizer::ExtractJoinRelations(LogicalOperator &input_op, vector<
 		relation_mapping[get->table_index] = relations.size();
 		relations.push_back(move(relation));
 		return true;
-	} else if (op->type == LogicalOperatorType::TABLE_FUNCTION) {
+	} else if (op->type == LogicalOperatorType::DUMMY_SCAN) {
 		// table function call, add to set of relations
-		auto table_function = (LogicalTableFunction *)op;
+		auto dummy_scan = (LogicalDummyScan *)op;
 		auto relation = make_unique<SingleJoinRelation>(&input_op, parent);
-		relation_mapping[table_function->table_index] = relations.size();
+		relation_mapping[dummy_scan->table_index] = relations.size();
 		relations.push_back(move(relation));
 		return true;
 	} else if (op->type == LogicalOperatorType::PROJECTION) {
diff --git a/src/optimizer/optimizer.cpp b/src/optimizer/optimizer.cpp
index cc46691698da..1ef7ee8f6fa5 100644
--- a/src/optimizer/optimizer.cpp
+++ b/src/optimizer/optimizer.cpp
@@ -7,7 +7,6 @@
 #include "duckdb/optimizer/expression_heuristics.hpp"
 #include "duckdb/optimizer/filter_pushdown.hpp"
 #include "duckdb/optimizer/in_clause_rewriter.hpp"
-#include "duckdb/optimizer/index_scan.hpp"
 #include "duckdb/optimizer/join_order_optimizer.hpp"
 #include "duckdb/optimizer/regex_range_filter.hpp"
 #include "duckdb/optimizer/remove_unused_columns.hpp"
@@ -51,12 +50,6 @@ unique_ptr<LogicalOperator> Optimizer::Optimize(unique_ptr<LogicalOperator> plan
 	plan = filter_pushdown.Rewrite(move(plan));
 	context.profiler.EndPhase();
 
-	// check if filters match with existing indexes, if true transforms filters to index scans
-	context.profiler.StartPhase("index_scan");
-	IndexScan index_scan;
-	plan = index_scan.Optimize(move(plan));
-	context.profiler.EndPhase();
-
 	context.profiler.StartPhase("regex_range");
 	RegexRangeFilter regex_opt;
 	plan = regex_opt.Rewrite(move(plan));
diff --git a/src/optimizer/pushdown/pushdown_get.cpp b/src/optimizer/pushdown/pushdown_get.cpp
index aa1c4237ef52..9a4e054722a0 100644
--- a/src/optimizer/pushdown/pushdown_get.cpp
+++ b/src/optimizer/pushdown/pushdown_get.cpp
@@ -1,70 +1,51 @@
 #include "duckdb/optimizer/filter_pushdown.hpp"
 #include "duckdb/planner/operator/logical_filter.hpp"
 #include "duckdb/planner/operator/logical_get.hpp"
+#include "duckdb/planner/expression/bound_columnref_expression.hpp"
 #include "duckdb/storage/data_table.hpp"
+#include "duckdb/optimizer/optimizer.hpp"
+
 namespace duckdb {
 using namespace std;
 
 unique_ptr<LogicalOperator> FilterPushdown::PushdownGet(unique_ptr<LogicalOperator> op) {
 	assert(op->type == LogicalOperatorType::GET);
 	auto &get = (LogicalGet &)*op;
-	if (!get.tableFilters.empty()) {
-		if (!filters.empty()) {
-			//! We didn't managed to push down all filters to table scan
-			auto logicalFilter = make_unique<LogicalFilter>();
-			for (auto &f : filters) {
-				logicalFilter->expressions.push_back(move(f->filter));
-			}
-			logicalFilter->children.push_back(move(op));
-			return move(logicalFilter);
-		} else {
-			return op;
+	// first push down arbitrary filters
+	if (get.function.pushdown_complex_filter) {
+		// for the remaining filters, check if we can push any of them into the scan as well
+		vector<unique_ptr<Expression>> expressions;
+		for (idx_t i = 0; i < filters.size(); i++) {
+			expressions.push_back(move(filters[i]->filter));
 		}
-	}
-	//! FIXME: We only need to skip if the index is in the column being filtered
-	if (!get.table || !get.table->storage->info->indexes.empty()) {
-		//! now push any existing filters
-		if (filters.empty()) {
-			//! no filters to push
-			return op;
+		filters.clear();
+
+		get.function.pushdown_complex_filter(optimizer.context, get, get.bind_data.get(), expressions);
+
+		if (expressions.size() == 0) {
+			return move(op);
 		}
-		auto filter = make_unique<LogicalFilter>();
-		for (auto &f : filters) {
-			filter->expressions.push_back(move(f->filter));
+		// re-generate the filters
+		for (auto &expr : expressions) {
+			auto f = make_unique<Filter>();
+			f->filter = move(expr);
+			f->ExtractBindings();
+			filters.push_back(move(f));
 		}
-		filter->children.push_back(move(op));
-		return move(filter);
+	}
+	if (!get.tableFilters.empty() || !get.function.filter_pushdown) {
+		// the table function does not support filter pushdown: push a LogicalFilter on top
+		return FinishPushdown(move(op));
 	}
 	PushFilters();
 
-	vector<unique_ptr<Filter>> filtersToPushDown;
-	get.tableFilters = combiner.GenerateTableScanFilters(
-	    [&](unique_ptr<Expression> filter) {
-		    auto f = make_unique<Filter>();
-		    f->filter = move(filter);
-		    f->ExtractBindings();
-		    filtersToPushDown.push_back(move(f));
-	    },
-	    get.column_ids);
+	get.tableFilters = combiner.GenerateTableScanFilters(get.column_ids);
 	for (auto &f : get.tableFilters) {
 		f.column_index = get.column_ids[f.column_index];
 	}
 
 	GenerateFilters();
-	for (auto &f : filtersToPushDown) {
-		get.expressions.push_back(move(f->filter));
-	}
-
-	if (!filters.empty()) {
-		//! We didn't managed to push down all filters to table scan
-		auto logicalFilter = make_unique<LogicalFilter>();
-		for (auto &f : filters) {
-			logicalFilter->expressions.push_back(move(f->filter));
-		}
-		logicalFilter->children.push_back(move(op));
-		return move(logicalFilter);
-	}
-	return op;
+	return FinishPushdown(move(op));
 }
 
 } // namespace duckdb
diff --git a/src/optimizer/remove_unused_columns.cpp b/src/optimizer/remove_unused_columns.cpp
index 4b9c44fd7641..0de8ce22b8a9 100644
--- a/src/optimizer/remove_unused_columns.cpp
+++ b/src/optimizer/remove_unused_columns.cpp
@@ -10,7 +10,6 @@
 #include "duckdb/planner/operator/logical_comparison_join.hpp"
 #include "duckdb/planner/operator/logical_filter.hpp"
 #include "duckdb/planner/operator/logical_get.hpp"
-#include "duckdb/planner/operator/logical_table_function.hpp"
 #include "duckdb/planner/operator/logical_projection.hpp"
 #include "duckdb/planner/column_binding_map.hpp"
 
@@ -140,6 +139,24 @@ void RemoveUnusedColumns::VisitOperator(LogicalOperator &op) {
 		LogicalOperatorVisitor::VisitOperatorExpressions(op);
 		if (!everything_referenced) {
 			auto &get = (LogicalGet &)op;
+			// for every table filter, push a column binding into the column references map to prevent the column from
+			// being projected out
+			for (auto &filter : get.tableFilters) {
+				idx_t index = INVALID_INDEX;
+				for (idx_t i = 0; i < get.column_ids.size(); i++) {
+					if (get.column_ids[i] == filter.column_index) {
+						index = i;
+						break;
+					}
+				}
+				if (index == INVALID_INDEX) {
+					throw InternalException("Could not find column index for table filter");
+				}
+				ColumnBinding filter_binding(get.table_index, index);
+				if (column_references.find(filter_binding) == column_references.end()) {
+					column_references.insert(make_pair(filter_binding, vector<BoundColumnRefExpression *>()));
+				}
+			}
 			// table scan: figure out which columns are referenced
 			ClearUnusedExpressions(get.column_ids, get.table_index);
 
@@ -151,19 +168,6 @@ void RemoveUnusedColumns::VisitOperator(LogicalOperator &op) {
 			}
 		}
 		return;
-	case LogicalOperatorType::TABLE_FUNCTION: {
-		LogicalOperatorVisitor::VisitOperatorExpressions(op);
-		auto &fun = (LogicalTableFunction &)op;
-		if (!everything_referenced && fun.function.supports_projection) {
-			// table producing function: figure out which columns are referenced
-			ClearUnusedExpressions(fun.column_ids, fun.table_index);
-			// see above for this special case
-			if (fun.column_ids.size() == 0) {
-				fun.column_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);
-			}
-		}
-		return;
-	}
 	case LogicalOperatorType::DISTINCT: {
 		// distinct, all projected columns are used for the DISTINCT computation
 		// mark all columns as used and continue to the children
diff --git a/src/parallel/pipeline.cpp b/src/parallel/pipeline.cpp
index 9f69a66ef152..6191dbbd4b35 100644
--- a/src/parallel/pipeline.cpp
+++ b/src/parallel/pipeline.cpp
@@ -31,7 +31,8 @@ class PipelineTask : public Task {
 };
 
 Pipeline::Pipeline(Executor &executor_)
-    : executor(executor_), finished_dependencies(0), finished(false), finished_tasks(0), total_tasks(0), recursive_cte(nullptr) {
+    : executor(executor_), finished_dependencies(0), finished(false), finished_tasks(0), total_tasks(0),
+      recursive_cte(nullptr) {
 }
 
 void Pipeline::Execute(TaskContext &task) {
@@ -72,7 +73,7 @@ void Pipeline::FinishTask() {
 	if (current_finished == total_tasks) {
 		try {
 			sink->Finalize(executor.context, move(sink_state));
-		} catch(std::exception &ex) {
+		} catch (std::exception &ex) {
 			executor.PushError(ex.what());
 		} catch (...) {
 			executor.PushError("Unknown exception in Finalize!");
@@ -96,7 +97,7 @@ bool Pipeline::ScheduleOperator(PhysicalOperator *op) {
 	case PhysicalOperatorType::HASH_JOIN:
 		// filter, projection or hash probe: continue in children
 		return ScheduleOperator(op->children[0].get());
-	case PhysicalOperatorType::SEQ_SCAN: {
+	case PhysicalOperatorType::TABLE_SCAN: {
 		// we reached a scan: split it up into parts and schedule the parts
 		auto &scheduler = TaskScheduler::GetScheduler(executor.context);
 
diff --git a/src/planner/bind_context.cpp b/src/planner/bind_context.cpp
index 4d0a69517f60..23b585938f13 100644
--- a/src/planner/bind_context.cpp
+++ b/src/planner/bind_context.cpp
@@ -101,8 +101,14 @@ void BindContext::AddBinding(const string &alias, unique_ptr<Binding> binding) {
 	bindings[alias] = move(binding);
 }
 
-void BindContext::AddBaseTable(idx_t index, const string &alias, TableCatalogEntry &table, LogicalGet &get) {
-	AddBinding(alias, make_unique<TableBinding>(alias, table, get, index));
+void BindContext::AddBaseTable(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types,
+                               unordered_map<string, column_t> name_map, LogicalGet &get) {
+	AddBinding(alias, make_unique<TableBinding>(alias, move(types), move(names), move(name_map), get, index));
+}
+
+void BindContext::AddTableFunction(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types,
+                                   LogicalGet &get) {
+	AddBinding(alias, make_unique<TableBinding>(alias, move(types), move(names), get, index));
 }
 
 void BindContext::AddSubquery(idx_t index, const string &alias, SubqueryRef &ref, BoundQueryNode &subquery) {
@@ -123,11 +129,11 @@ void BindContext::AddSubquery(idx_t index, const string &alias, SubqueryRef &ref
 }
 
 void BindContext::AddGenericBinding(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types) {
-	AddBinding(alias, make_unique<GenericBinding>(alias, move(types), move(names), index));
+	AddBinding(alias, make_unique<Binding>(alias, move(types), move(names), index));
 }
 
 void BindContext::AddCTEBinding(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types) {
-	auto binding = make_shared<GenericBinding>(alias, move(types), move(names), index);
+	auto binding = make_shared<Binding>(alias, move(types), move(names), index);
 
 	if (cte_bindings.find(alias) != cte_bindings.end()) {
 		throw BinderException("Duplicate alias \"%s\" in query!", alias);
diff --git a/src/planner/binder/statement/bind_call.cpp b/src/planner/binder/statement/bind_call.cpp
index 0a1ed1197887..96ee958423b1 100644
--- a/src/planner/binder/statement/bind_call.cpp
+++ b/src/planner/binder/statement/bind_call.cpp
@@ -2,6 +2,7 @@
 #include "duckdb/parser/statement/call_statement.hpp"
 #include "duckdb/parser/tableref/table_function_ref.hpp"
 #include "duckdb/planner/tableref/bound_table_function.hpp"
+#include "duckdb/planner/operator/logical_get.hpp"
 
 namespace duckdb {
 using namespace std;
@@ -14,9 +15,14 @@ BoundStatement Binder::Bind(CallStatement &stmt) {
 
 	auto bound_func = Bind(ref);
 	auto &bound_table_func = (BoundTableFunction &)*bound_func;
+	auto &get = (LogicalGet &)*bound_table_func.get;
+	assert(get.returned_types.size() > 0);
+	for (idx_t i = 0; i < get.returned_types.size(); i++) {
+		get.column_ids.push_back(i);
+	}
 
-	result.types = bound_table_func.return_types;
-	result.names = bound_table_func.names;
+	result.types = get.returned_types;
+	result.names = get.names;
 	result.plan = CreatePlan(*bound_func);
 	return result;
 }
diff --git a/src/planner/binder/statement/bind_create.cpp b/src/planner/binder/statement/bind_create.cpp
index ed1534fa9c72..2586d522fd6e 100644
--- a/src/planner/binder/statement/bind_create.cpp
+++ b/src/planner/binder/statement/bind_create.cpp
@@ -87,6 +87,8 @@ BoundStatement Binder::Bind(CreateStatement &stmt) {
 		if (bound_table->type != TableReferenceType::BASE_TABLE) {
 			throw BinderException("Can only delete from base table!");
 		}
+		auto &table_binding = (BoundBaseTableRef &)*bound_table;
+		auto table = table_binding.table;
 		// bind the index expressions
 		vector<unique_ptr<Expression>> expressions;
 		IndexBinder binder(*this, context);
@@ -107,7 +109,7 @@ BoundStatement Binder::Bind(CreateStatement &stmt) {
 		// this gives us a logical table scan
 		// we take the required columns from here
 		// create the logical operator
-		result.plan = make_unique<LogicalCreateIndex>(*get.table, get.column_ids, move(expressions),
+		result.plan = make_unique<LogicalCreateIndex>(*table, get.column_ids, move(expressions),
 		                                              unique_ptr_cast<CreateInfo, CreateIndexInfo>(move(stmt.info)));
 		break;
 	}
diff --git a/src/planner/binder/statement/bind_delete.cpp b/src/planner/binder/statement/bind_delete.cpp
index 115d98bf3a23..1da159203c6e 100644
--- a/src/planner/binder/statement/bind_delete.cpp
+++ b/src/planner/binder/statement/bind_delete.cpp
@@ -5,6 +5,7 @@
 #include "duckdb/planner/operator/logical_filter.hpp"
 #include "duckdb/planner/operator/logical_get.hpp"
 #include "duckdb/planner/bound_tableref.hpp"
+#include "duckdb/planner/tableref/bound_basetableref.hpp"
 
 namespace duckdb {
 using namespace std;
@@ -17,11 +18,14 @@ BoundStatement Binder::Bind(DeleteStatement &stmt) {
 	if (bound_table->type != TableReferenceType::BASE_TABLE) {
 		throw BinderException("Can only delete from base table!");
 	}
+	auto &table_binding = (BoundBaseTableRef &)*bound_table;
+	auto table = table_binding.table;
+
 	auto root = CreatePlan(*bound_table);
 	auto &get = (LogicalGet &)*root;
-	assert(root->type == LogicalOperatorType::GET && get.table);
+	assert(root->type == LogicalOperatorType::GET);
 
-	if (!get.table->temporary) {
+	if (!table->temporary) {
 		// delete from persistent table: not read only!
 		this->read_only = false;
 	}
@@ -37,7 +41,7 @@ BoundStatement Binder::Bind(DeleteStatement &stmt) {
 		root = move(filter);
 	}
 	// create the delete node
-	auto del = make_unique<LogicalDelete>(get.table);
+	auto del = make_unique<LogicalDelete>(table);
 	del->AddChild(move(root));
 
 	// set up the delete expression
diff --git a/src/planner/binder/statement/bind_update.cpp b/src/planner/binder/statement/bind_update.cpp
index 0689be8bacd2..4ef6a8de956a 100644
--- a/src/planner/binder/statement/bind_update.cpp
+++ b/src/planner/binder/statement/bind_update.cpp
@@ -12,6 +12,7 @@
 #include "duckdb/parser/expression/columnref_expression.hpp"
 #include "duckdb/storage/data_table.hpp"
 #include "duckdb/planner/bound_tableref.hpp"
+#include "duckdb/planner/tableref/bound_basetableref.hpp"
 
 #include <algorithm>
 
@@ -94,11 +95,13 @@ BoundStatement Binder::Bind(UpdateStatement &stmt) {
 	if (bound_table->type != TableReferenceType::BASE_TABLE) {
 		throw BinderException("Can only update base table!");
 	}
+	auto &table_binding = (BoundBaseTableRef &)*bound_table;
+	auto table = table_binding.table;
+
 	auto root = CreatePlan(*bound_table);
 	auto &get = (LogicalGet &)*root;
-	assert(root->type == LogicalOperatorType::GET && get.table);
+	assert(root->type == LogicalOperatorType::GET);
 
-	auto &table = get.table;
 	if (!table->temporary) {
 		// update of persistent table: not read only!
 		this->read_only = false;
diff --git a/src/planner/binder/tableref/bind_basetableref.cpp b/src/planner/binder/tableref/bind_basetableref.cpp
index 5fd695527984..7f3cb2c8ed11 100644
--- a/src/planner/binder/tableref/bind_basetableref.cpp
+++ b/src/planner/binder/tableref/bind_basetableref.cpp
@@ -7,6 +7,7 @@
 #include "duckdb/planner/tableref/bound_cteref.hpp"
 #include "duckdb/planner/operator/logical_get.hpp"
 #include "duckdb/parser/statement/select_statement.hpp"
+#include "duckdb/function/table/table_scan.hpp"
 
 namespace duckdb {
 using namespace std;
@@ -29,7 +30,7 @@ unique_ptr<BoundTableRef> Binder::Bind(BaseTableRef &ref) {
 			// This can only be the case if there is a recursive CTE present.
 			auto index = GenerateTableIndex();
 			auto result = make_unique<BoundCTERef>(index, ctebinding->index);
-			auto b = (GenericBinding *)ctebinding;
+			auto b = ctebinding;
 
 			bind_context.AddGenericBinding(index, ref.alias.empty() ? ref.table_name : ref.alias, b->names, b->types);
 			// Update references to CTE
@@ -51,10 +52,21 @@ unique_ptr<BoundTableRef> Binder::Bind(BaseTableRef &ref) {
 		auto table_index = GenerateTableIndex();
 		auto table = (TableCatalogEntry *)table_or_view;
 
-		auto logical_get = make_unique<LogicalGet>(table, table_index);
+		auto scan_function = TableScanFunction::GetFunction();
+		auto bind_data = make_unique<TableScanBindData>(table);
+		vector<LogicalType> table_types;
+		vector<string> table_names;
+		for (auto &col : table->columns) {
+			table_types.push_back(col.type);
+			table_names.push_back(col.name);
+		}
+
+		auto logical_get =
+		    make_unique<LogicalGet>(table_index, scan_function, move(bind_data), table_types, table_names);
 		auto alias = ref.alias.empty() ? ref.table_name : ref.alias;
-		bind_context.AddBaseTable(table_index, alias, *table, *logical_get);
-		return make_unique_base<BoundTableRef, BoundBaseTableRef>(move(logical_get));
+		bind_context.AddBaseTable(table_index, alias, move(table_names), move(table_types), table->name_map,
+		                          *logical_get);
+		return make_unique_base<BoundTableRef, BoundBaseTableRef>(table, move(logical_get));
 	}
 	case CatalogType::VIEW_ENTRY: {
 		// the node is a view: get the query that the view represents
diff --git a/src/planner/binder/tableref/bind_table_function.cpp b/src/planner/binder/tableref/bind_table_function.cpp
index b6b572f10887..18cc90a3b902 100644
--- a/src/planner/binder/tableref/bind_table_function.cpp
+++ b/src/planner/binder/tableref/bind_table_function.cpp
@@ -5,6 +5,7 @@
 #include "duckdb/parser/expression/columnref_expression.hpp"
 #include "duckdb/parser/expression/comparison_expression.hpp"
 #include "duckdb/planner/expression_binder/constant_binder.hpp"
+#include "duckdb/planner/operator/logical_get.hpp"
 #include "duckdb/planner/tableref/bound_table_function.hpp"
 #include "duckdb/execution/expression_executor.hpp"
 #include "duckdb/common/algorithm.hpp"
@@ -72,29 +73,31 @@ unique_ptr<BoundTableRef> Binder::Bind(TableFunctionRef &ref) {
 	}
 
 	// cast the parameters to the type of the function
-	auto result = make_unique<BoundTableFunction>(table_function, bind_index);
 	for (idx_t i = 0; i < arguments.size(); i++) {
-		if (table_function.arguments[i] == LogicalType::ANY) {
-			result->parameters.push_back(move(parameters[i]));
-		} else {
-			result->parameters.push_back(parameters[i].CastAs(table_function.arguments[i]));
+		if (table_function.arguments[i] != LogicalType::ANY) {
+			parameters[i] = parameters[i].CastAs(table_function.arguments[i]);
 		}
 	}
 
 	// perform the binding
-	result->bind_data =
-	    table_function.bind(context, result->parameters, named_parameters, result->return_types, result->names);
-	assert(result->return_types.size() == result->names.size());
-	assert(result->return_types.size() > 0);
-	vector<string> names = result->names;
-	for (idx_t i = 0; i < ref.column_name_alias.size() && i < result->names.size(); i++) {
-		names[i] = ref.column_name_alias[i];
+	unique_ptr<FunctionData> bind_data;
+	vector<LogicalType> return_types;
+	vector<string> return_names;
+	if (table_function.bind) {
+		bind_data = table_function.bind(context, parameters, named_parameters, return_types, return_names);
+	}
+	assert(return_types.size() == return_names.size());
+	assert(return_types.size() > 0);
+	// overwrite the names with any supplied aliases
+	for (idx_t i = 0; i < ref.column_name_alias.size() && i < return_names.size(); i++) {
+		return_names[i] = ref.column_name_alias[i];
 	}
+	auto get = make_unique<LogicalGet>(bind_index, table_function, move(bind_data), return_types, return_names);
 	// now add the table function to the bind context so its columns can be bound
-	bind_context.AddGenericBinding(bind_index, ref.alias.empty() ? fexpr->function_name : ref.alias, names,
-	                               result->return_types);
+	bind_context.AddTableFunction(bind_index, ref.alias.empty() ? fexpr->function_name : ref.alias, return_names,
+	                              return_types, *get);
 
-	return move(result);
+	return make_unique_base<BoundTableRef, BoundTableFunction>(move(get));
 }
 
 } // namespace duckdb
diff --git a/src/planner/binder/tableref/plan_dummytableref.cpp b/src/planner/binder/tableref/plan_dummytableref.cpp
index b85ae4bf9b44..e1705419f81a 100644
--- a/src/planner/binder/tableref/plan_dummytableref.cpp
+++ b/src/planner/binder/tableref/plan_dummytableref.cpp
@@ -1,12 +1,12 @@
 #include "duckdb/planner/binder.hpp"
-#include "duckdb/planner/operator/logical_get.hpp"
+#include "duckdb/planner/operator/logical_dummy_scan.hpp"
 #include "duckdb/planner/tableref/bound_dummytableref.hpp"
 
 namespace duckdb {
 using namespace std;
 
 unique_ptr<LogicalOperator> Binder::CreatePlan(BoundEmptyTableRef &ref) {
-	return make_unique<LogicalGet>(ref.bind_index);
+	return make_unique<LogicalDummyScan>(ref.bind_index);
 }
 
 } // namespace duckdb
diff --git a/src/planner/binder/tableref/plan_expressionlistref.cpp b/src/planner/binder/tableref/plan_expressionlistref.cpp
index 3a77b2e0774b..cb8f0a7a573b 100644
--- a/src/planner/binder/tableref/plan_expressionlistref.cpp
+++ b/src/planner/binder/tableref/plan_expressionlistref.cpp
@@ -1,13 +1,13 @@
 #include "duckdb/planner/binder.hpp"
 #include "duckdb/planner/tableref/bound_expressionlistref.hpp"
 #include "duckdb/planner/operator/logical_expression_get.hpp"
-#include "duckdb/planner/operator/logical_get.hpp"
+#include "duckdb/planner/operator/logical_dummy_scan.hpp"
 
 namespace duckdb {
 using namespace std;
 
 unique_ptr<LogicalOperator> Binder::CreatePlan(BoundExpressionListRef &ref) {
-	auto root = make_unique_base<LogicalOperator, LogicalGet>(0);
+	auto root = make_unique_base<LogicalOperator, LogicalDummyScan>(0);
 	// values list, first plan any subqueries in the list
 	for (auto &expr_list : ref.values) {
 		for (auto &expr : expr_list) {
diff --git a/src/planner/binder/tableref/plan_table_function.cpp b/src/planner/binder/tableref/plan_table_function.cpp
index 44027c0b9c07..16906eda787b 100644
--- a/src/planner/binder/tableref/plan_table_function.cpp
+++ b/src/planner/binder/tableref/plan_table_function.cpp
@@ -1,18 +1,11 @@
 #include "duckdb/planner/binder.hpp"
-#include "duckdb/planner/operator/logical_table_function.hpp"
 #include "duckdb/planner/tableref/bound_table_function.hpp"
 
 namespace duckdb {
 using namespace std;
 
 unique_ptr<LogicalOperator> Binder::CreatePlan(BoundTableFunction &ref) {
-
-	auto logical_fun = make_unique<LogicalTableFunction>(ref.function, ref.bind_index, move(ref.bind_data),
-	                                                     move(ref.parameters), ref.return_types, ref.names);
-	for (idx_t i = 0; i < ref.return_types.size(); i++) {
-		logical_fun->column_ids.push_back(i);
-	}
-	return move(logical_fun);
+	return move(ref.get);
 }
 
 } // namespace duckdb
diff --git a/src/planner/operator/CMakeLists.txt b/src/planner/operator/CMakeLists.txt
index 801abad051af..2e99f2126f83 100644
--- a/src/planner/operator/CMakeLists.txt
+++ b/src/planner/operator/CMakeLists.txt
@@ -1,17 +1,18 @@
-add_library_unity(duckdb_planner_operator
-                  OBJECT
-                  logical_aggregate.cpp
-                  logical_empty_result.cpp
-                  logical_any_join.cpp
-                  logical_comparison_join.cpp
-                  logical_cross_product.cpp
-                  logical_filter.cpp
-                  logical_get.cpp
-                  logical_join.cpp
-                  logical_projection.cpp
-                  logical_table_function.cpp
-                  logical_unnest.cpp
-                  logical_window.cpp
-                  logical_distinct.cpp)
-set(ALL_OBJECT_FILES ${ALL_OBJECT_FILES}
-                     $<TARGET_OBJECTS:duckdb_planner_operator> PARENT_SCOPE)
+add_library_unity(
+  duckdb_planner_operator
+  OBJECT
+  logical_aggregate.cpp
+  logical_empty_result.cpp
+  logical_any_join.cpp
+  logical_comparison_join.cpp
+  logical_cross_product.cpp
+  logical_filter.cpp
+  logical_get.cpp
+  logical_join.cpp
+  logical_projection.cpp
+  logical_unnest.cpp
+  logical_window.cpp
+  logical_distinct.cpp)
+set(ALL_OBJECT_FILES
+    ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_planner_operator>
+    PARENT_SCOPE)
diff --git a/src/planner/operator/logical_get.cpp b/src/planner/operator/logical_get.cpp
index e3218e6b33d8..8617e2844261 100644
--- a/src/planner/operator/logical_get.cpp
+++ b/src/planner/operator/logical_get.cpp
@@ -2,31 +2,23 @@
 
 #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
 #include "duckdb/storage/data_table.hpp"
+#include "duckdb/planner/operator/logical_get.hpp"
 
 namespace duckdb {
 using namespace std;
 
-LogicalGet::LogicalGet(idx_t table_index)
-    : LogicalOperator(LogicalOperatorType::GET), table(nullptr), table_index(table_index) {
-}
-LogicalGet::LogicalGet(TableCatalogEntry *table, idx_t table_index)
-    : LogicalOperator(LogicalOperatorType::GET), table(table), table_index(table_index) {
-}
-LogicalGet::LogicalGet(TableCatalogEntry *table, idx_t table_index, vector<column_t> column_ids)
-    : LogicalOperator(LogicalOperatorType::GET), table(table), table_index(table_index), column_ids(column_ids) {
+LogicalGet::LogicalGet(idx_t table_index, TableFunction function, unique_ptr<FunctionData> bind_data,
+                       vector<LogicalType> returned_types, vector<string> returned_names)
+    : LogicalOperator(LogicalOperatorType::GET), table_index(table_index), function(move(function)),
+      bind_data(move(bind_data)), returned_types(move(returned_types)), names(move(returned_names)) {
 }
 
 string LogicalGet::ParamsToString() const {
-	if (!table) {
-		return "";
-	}
-	return "(" + table->name + ")";
+	return string();
+	// return "(" + table->name + ")";
 }
 
 vector<ColumnBinding> LogicalGet::GetColumnBindings() {
-	if (!table) {
-		return {ColumnBinding(INVALID_INDEX, 0)};
-	}
 	if (column_ids.size() == 0) {
 		return {ColumnBinding(table_index, 0)};
 	}
@@ -41,12 +33,18 @@ void LogicalGet::ResolveTypes() {
 	if (column_ids.size() == 0) {
 		column_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);
 	}
-	types = table->GetTypes(column_ids);
+	for (auto &index : column_ids) {
+		if (index == COLUMN_IDENTIFIER_ROW_ID) {
+			types.push_back(LOGICAL_ROW_TYPE);
+		} else {
+			types.push_back(returned_types[index]);
+		}
+	}
 }
 
 idx_t LogicalGet::EstimateCardinality() {
-	if (table) {
-		return table->storage->info->cardinality;
+	if (function.cardinality) {
+		return function.cardinality(bind_data.get());
 	} else {
 		return 1;
 	}
diff --git a/src/planner/operator/logical_table_function.cpp b/src/planner/operator/logical_table_function.cpp
deleted file mode 100644
index de5aa9075902..000000000000
--- a/src/planner/operator/logical_table_function.cpp
+++ /dev/null
@@ -1,30 +0,0 @@
-#include "duckdb/planner/operator/logical_table_function.hpp"
-
-#include "duckdb/catalog/catalog_entry/table_function_catalog_entry.hpp"
-
-namespace duckdb {
-using namespace std;
-
-vector<ColumnBinding> LogicalTableFunction::GetColumnBindings() {
-	vector<ColumnBinding> result;
-	for (idx_t i = 0; i < column_ids.size(); i++) {
-		result.push_back(ColumnBinding(table_index, i));
-	}
-	return result;
-}
-
-void LogicalTableFunction::ResolveTypes() {
-	for (auto col_idx : column_ids) {
-		if (col_idx == COLUMN_IDENTIFIER_ROW_ID) {
-			types.push_back(LOGICAL_ROW_TYPE);
-			continue;
-		}
-		types.push_back(return_types[col_idx]);
-	}
-}
-
-string LogicalTableFunction::ParamsToString() const {
-	return "(" + function.name + ")";
-}
-
-} // namespace duckdb
diff --git a/src/planner/table_binding.cpp b/src/planner/table_binding.cpp
index 9871c4400dd6..b52f61440d2b 100644
--- a/src/planner/table_binding.cpp
+++ b/src/planner/table_binding.cpp
@@ -13,64 +13,11 @@
 namespace duckdb {
 using namespace std;
 
-TableBinding::TableBinding(const string &alias, TableCatalogEntry &table, LogicalGet &get, idx_t index)
-    : Binding(BindingType::TABLE, alias, index), table(table), get(get) {
+Binding::Binding(const string &alias, idx_t index) : alias(alias), index(index) {
 }
 
-bool TableBinding::HasMatchingBinding(const string &column_name) {
-	return table.ColumnExists(column_name);
-}
-
-BindResult TableBinding::Bind(ColumnRefExpression &colref, idx_t depth) {
-	auto entry = table.name_map.find(colref.column_name);
-	if (entry == table.name_map.end()) {
-		return BindResult(StringUtil::Format("Table \"%s\" does not have a column named \"%s\"", colref.table_name,
-		                                     colref.column_name));
-	}
-	auto col_index = entry->second;
-	// fetch the type of the column
-	LogicalType col_type;
-	if (entry->second == COLUMN_IDENTIFIER_ROW_ID) {
-		// row id: BIGINT type
-		col_type = LogicalType::BIGINT;
-	} else {
-		// normal column: fetch type from base column
-		auto &col = table.columns[col_index];
-		col_type = col.type;
-	}
-
-	auto &column_ids = get.column_ids;
-	// check if the entry already exists in the column list for the table
-	ColumnBinding binding;
-
-	binding.column_index = column_ids.size();
-	for (idx_t i = 0; i < column_ids.size(); i++) {
-		if (column_ids[i] == col_index) {
-			binding.column_index = i;
-			break;
-		}
-	}
-	if (binding.column_index == column_ids.size()) {
-		// column binding not found: add it to the list of bindings
-		column_ids.push_back(col_index);
-	}
-	binding.table_index = index;
-	return BindResult(make_unique<BoundColumnRefExpression>(colref.GetName(), col_type, binding, depth));
-}
-
-void TableBinding::GenerateAllColumnExpressions(BindContext &context,
-                                                vector<unique_ptr<ParsedExpression>> &select_list) {
-	for (auto &column : table.columns) {
-		if (context.BindingIsHidden(alias, column.name)) {
-			continue;
-		}
-		assert(!column.name.empty());
-		select_list.push_back(make_unique<ColumnRefExpression>(column.name, alias));
-	}
-}
-
-GenericBinding::GenericBinding(const string &alias, vector<LogicalType> coltypes, vector<string> colnames, idx_t index)
-    : Binding(BindingType::GENERIC, alias, index), types(move(coltypes)), names(move(colnames)) {
+Binding::Binding(const string &alias, vector<LogicalType> coltypes, vector<string> colnames, idx_t index)
+    : alias(alias), index(index), types(move(coltypes)), names(move(colnames)) {
 	assert(types.size() == names.size());
 	for (idx_t i = 0; i < names.size(); i++) {
 		auto &name = names[i];
@@ -83,12 +30,12 @@ GenericBinding::GenericBinding(const string &alias, vector<LogicalType> coltypes
 	TableCatalogEntry::AddLowerCaseAliases(name_map);
 }
 
-bool GenericBinding::HasMatchingBinding(const string &column_name) {
+bool Binding::HasMatchingBinding(const string &column_name) {
 	auto entry = name_map.find(column_name);
 	return entry != name_map.end();
 }
 
-BindResult GenericBinding::Bind(ColumnRefExpression &colref, idx_t depth) {
+BindResult Binding::Bind(ColumnRefExpression &colref, idx_t depth) {
 	auto column_entry = name_map.find(colref.column_name);
 	if (column_entry == name_map.end()) {
 		return BindResult(StringUtil::Format("Values list \"%s\" does not have a column named \"%s\"", alias.c_str(),
@@ -101,8 +48,7 @@ BindResult GenericBinding::Bind(ColumnRefExpression &colref, idx_t depth) {
 	return BindResult(make_unique<BoundColumnRefExpression>(colref.GetName(), sql_type, binding, depth));
 }
 
-void GenericBinding::GenerateAllColumnExpressions(BindContext &context,
-                                                  vector<unique_ptr<ParsedExpression>> &select_list) {
+void Binding::GenerateAllColumnExpressions(BindContext &context, vector<unique_ptr<ParsedExpression>> &select_list) {
 	for (auto &column_name : names) {
 		assert(!column_name.empty());
 		if (context.BindingIsHidden(alias, column_name)) {
@@ -112,4 +58,51 @@ void GenericBinding::GenerateAllColumnExpressions(BindContext &context,
 	}
 }
 
+TableBinding::TableBinding(const string &alias, vector<LogicalType> types_, vector<string> names_, LogicalGet &get,
+                           idx_t index)
+    : Binding(alias, move(types_), move(names_), index), get(get) {
+}
+
+TableBinding::TableBinding(const string &alias, vector<LogicalType> types, vector<string> names,
+                           unordered_map<string, column_t> name_map, LogicalGet &get, idx_t index)
+    : TableBinding(alias, move(types), move(names), get, index) {
+	this->name_map = move(name_map);
+}
+
+BindResult TableBinding::Bind(ColumnRefExpression &colref, idx_t depth) {
+	auto entry = name_map.find(colref.column_name);
+	if (entry == name_map.end()) {
+		return BindResult(StringUtil::Format("Table \"%s\" does not have a column named \"%s\"", colref.table_name,
+		                                     colref.column_name));
+	}
+	auto col_index = entry->second;
+	// fetch the type of the column
+	LogicalType col_type;
+	if (entry->second == COLUMN_IDENTIFIER_ROW_ID) {
+		// row id: BIGINT type
+		col_type = LogicalType::BIGINT;
+	} else {
+		// normal column: fetch type from base column
+		col_type = types[col_index];
+	}
+
+	auto &column_ids = get.column_ids;
+	// check if the entry already exists in the column list for the table
+	ColumnBinding binding;
+
+	binding.column_index = column_ids.size();
+	for (idx_t i = 0; i < column_ids.size(); i++) {
+		if (column_ids[i] == col_index) {
+			binding.column_index = i;
+			break;
+		}
+	}
+	if (binding.column_index == column_ids.size()) {
+		// column binding not found: add it to the list of bindings
+		column_ids.push_back(col_index);
+	}
+	binding.table_index = index;
+	return BindResult(make_unique<BoundColumnRefExpression>(colref.GetName(), col_type, binding, depth));
+}
+
 } // namespace duckdb
diff --git a/src/storage/data_table.cpp b/src/storage/data_table.cpp
index 93a3a8715347..1ca4d8a6af7f 100644
--- a/src/storage/data_table.cpp
+++ b/src/storage/data_table.cpp
@@ -514,51 +514,14 @@ bool DataTable::ScanBaseTable(Transaction &transaction, DataChunk &result, Table
 	return true;
 }
 
-//===--------------------------------------------------------------------===//
-// Index Scan
-//===--------------------------------------------------------------------===//
-void DataTable::InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index,
-                                    vector<column_t> column_ids) {
-	state.index = &index;
-	state.column_ids = move(column_ids);
-	transaction.storage.InitializeScan(this, state.local_state);
-}
-
-void DataTable::InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index, Value value,
-                                    ExpressionType expr_type, vector<column_t> column_ids) {
-	InitializeIndexScan(transaction, state, index, move(column_ids));
-	state.index_state = index.InitializeScanSinglePredicate(transaction, state.column_ids, value, expr_type);
-}
-
-void DataTable::InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index, Value low_value,
-                                    ExpressionType low_type, Value high_value, ExpressionType high_type,
-                                    vector<column_t> column_ids) {
-	InitializeIndexScan(transaction, state, index, move(column_ids));
-	state.index_state =
-	    index.InitializeScanTwoPredicates(transaction, state.column_ids, low_value, low_type, high_value, high_type);
-}
-
-void DataTable::IndexScan(Transaction &transaction, DataChunk &result, TableIndexScanState &state) {
-	// clear any previously pinned blocks
-	state.fetch_state.handles.clear();
-	// scan the index
-	state.index->Scan(transaction, *this, state, result);
-	if (result.size() > 0) {
-		return;
-	}
-	// scan the local structure
-	transaction.storage.Scan(state.local_state, state.column_ids, result);
-}
-
 //===--------------------------------------------------------------------===//
 // Fetch
 //===--------------------------------------------------------------------===//
 void DataTable::Fetch(Transaction &transaction, DataChunk &result, vector<column_t> &column_ids,
-                      Vector &row_identifiers, idx_t fetch_count, TableIndexScanState &state) {
+                      Vector &row_identifiers, idx_t fetch_count, ColumnFetchState &state) {
 	// first figure out which row identifiers we should use for this transaction by looking at the VersionManagers
 	row_t rows[STANDARD_VECTOR_SIZE];
 	idx_t count = FetchRows(transaction, row_identifiers, fetch_count, rows);
-
 	if (count == 0) {
 		// no rows to use
 		return;
@@ -579,7 +542,7 @@ void DataTable::Fetch(Transaction &transaction, DataChunk &result, vector<column
 			// regular column: fetch data from the base column
 			for (idx_t i = 0; i < count; i++) {
 				auto row_id = rows[i];
-				columns[column]->FetchRow(state.fetch_state, transaction, row_id, result.data[col_idx], i);
+				columns[column]->FetchRow(state, transaction, row_id, result.data[col_idx], i);
 			}
 		}
 	}
diff --git a/src/storage/uncompressed_segment.cpp b/src/storage/uncompressed_segment.cpp
index 3d285ee11318..4b68f12d595f 100644
--- a/src/storage/uncompressed_segment.cpp
+++ b/src/storage/uncompressed_segment.cpp
@@ -144,6 +144,19 @@ void UncompressedSegment::Fetch(ColumnScanState &state, idx_t vector_index, Vect
 //===--------------------------------------------------------------------===//
 // Filter
 //===--------------------------------------------------------------------===//
+template <class T, class OP, bool HAS_NULL>
+static idx_t filter_selection_loop(T *vec, T *predicate, SelectionVector &sel, idx_t approved_tuple_count,
+                                   nullmask_t &nullmask, SelectionVector &result_sel) {
+	idx_t result_count = 0;
+	for (idx_t i = 0; i < approved_tuple_count; i++) {
+		auto idx = sel.get_index(i);
+		if ((!HAS_NULL || !nullmask[idx]) && OP::Operation(vec[idx], *predicate)) {
+			result_sel.set_index(result_count++, idx);
+		}
+	}
+	return result_count;
+}
+
 template <class T>
 static void filterSelectionType(T *vec, T *predicate, SelectionVector &sel, idx_t &approved_tuple_count,
                                 ExpressionType comparison_type, nullmask_t &nullmask) {
@@ -152,54 +165,51 @@ static void filterSelectionType(T *vec, T *predicate, SelectionVector &sel, idx_
 	switch (comparison_type) {
 	case ExpressionType::COMPARE_EQUAL: {
 		if (!nullmask.any()) {
-			approved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, Equals, false, true, true, true, false>(
-			    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);
+			approved_tuple_count =
+			    filter_selection_loop<T, Equals, false>(vec, predicate, sel, approved_tuple_count, nullmask, new_sel);
 		} else {
-			approved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, Equals, false, true, false, true, false>(
-			    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);
+			approved_tuple_count =
+			    filter_selection_loop<T, Equals, true>(vec, predicate, sel, approved_tuple_count, nullmask, new_sel);
 		}
 		break;
 	}
 	case ExpressionType::COMPARE_LESSTHAN: {
 		if (!nullmask.any()) {
-			approved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, LessThan, false, true, true, true, false>(
-			    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);
+			approved_tuple_count =
+			    filter_selection_loop<T, LessThan, false>(vec, predicate, sel, approved_tuple_count, nullmask, new_sel);
 		} else {
-			approved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, LessThan, false, true, false, true, false>(
-			    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);
+			approved_tuple_count =
+			    filter_selection_loop<T, LessThan, true>(vec, predicate, sel, approved_tuple_count, nullmask, new_sel);
 		}
 		break;
 	}
 	case ExpressionType::COMPARE_GREATERTHAN: {
 		if (!nullmask.any()) {
-			approved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, GreaterThan, false, true, true, true, false>(
-			    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);
+			approved_tuple_count = filter_selection_loop<T, GreaterThan, false>(
+			    vec, predicate, sel, approved_tuple_count, nullmask, new_sel);
 		} else {
-			approved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, GreaterThan, false, true, false, true, false>(
-			    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);
+			approved_tuple_count = filter_selection_loop<T, GreaterThan, true>(vec, predicate, sel,
+			                                                                   approved_tuple_count, nullmask, new_sel);
 		}
 		break;
 	}
 	case ExpressionType::COMPARE_LESSTHANOREQUALTO: {
 		if (!nullmask.any()) {
-			approved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, LessThanEquals, false, true, true, true, false>(
-			    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);
+			approved_tuple_count = filter_selection_loop<T, LessThanEquals, false>(
+			    vec, predicate, sel, approved_tuple_count, nullmask, new_sel);
 		} else {
-			approved_tuple_count =
-			    BinaryExecutor::SelectFlatLoop<T, T, LessThanEquals, false, true, false, true, false>(
-			        vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);
+			approved_tuple_count = filter_selection_loop<T, LessThanEquals, true>(
+			    vec, predicate, sel, approved_tuple_count, nullmask, new_sel);
 		}
 		break;
 	}
 	case ExpressionType::COMPARE_GREATERTHANOREQUALTO: {
 		if (!nullmask.any()) {
-			approved_tuple_count =
-			    BinaryExecutor::SelectFlatLoop<T, T, GreaterThanEquals, false, true, true, true, false>(
-			        vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);
+			approved_tuple_count = filter_selection_loop<T, GreaterThanEquals, false>(
+			    vec, predicate, sel, approved_tuple_count, nullmask, new_sel);
 		} else {
-			approved_tuple_count =
-			    BinaryExecutor::SelectFlatLoop<T, T, GreaterThanEquals, false, true, false, true, false>(
-			        vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);
+			approved_tuple_count = filter_selection_loop<T, GreaterThanEquals, true>(
+			    vec, predicate, sel, approved_tuple_count, nullmask, new_sel);
 		}
 		break;
 	}
diff --git a/third_party/catch/catch.hpp b/third_party/catch/catch.hpp
index 841e53d20fcf..d8ae61b9ca69 100644
--- a/third_party/catch/catch.hpp
+++ b/third_party/catch/catch.hpp
@@ -1860,6 +1860,13 @@ namespace Catch {
         INTERNAL_CATCH_REACT( catchAssertionHandler ) \
     } while( false )
 
+#define INTERNAL_CATCH_MSG_LINENR( macroName, messageType, resultDisposition, fname, linenr, ... ) \
+    do { \
+        Catch::AssertionHandler catchAssertionHandler( macroName##_catch_sr, ::Catch::SourceLineInfo(fname.c_str(), linenr), Catch::StringRef(), resultDisposition ); \
+        catchAssertionHandler.handleMessage( messageType, ( Catch::MessageStream() << __VA_ARGS__ + ::Catch::StreamEndStop() ).m_stream.str() ); \
+        INTERNAL_CATCH_REACT( catchAssertionHandler ) \
+    } while( false )
+
 ///////////////////////////////////////////////////////////////////////////////
 #define INTERNAL_CATCH_CAPTURE( varName, macroName, ... ) \
     auto varName = Catch::Capturer( macroName, CATCH_INTERNAL_LINEINFO, Catch::ResultWas::Info, #__VA_ARGS__ ); \
@@ -13778,6 +13785,7 @@ int main (int argc, char * const argv[]) {
 #define SECTION( ... ) INTERNAL_CATCH_SECTION( __VA_ARGS__ )
 #define DYNAMIC_SECTION( ... ) INTERNAL_CATCH_DYNAMIC_SECTION( __VA_ARGS__ )
 #define FAIL( ... ) INTERNAL_CATCH_MSG( "FAIL", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::Normal, __VA_ARGS__ )
+#define FAIL_LINE(fname, linenr, ...) INTERNAL_CATCH_MSG_LINENR( "FAIL", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::Normal, fname, linenr, __VA_ARGS__ )
 #define FAIL_CHECK( ... ) INTERNAL_CATCH_MSG( "FAIL_CHECK", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )
 #define SUCCEED( ... ) INTERNAL_CATCH_MSG( "SUCCEED", Catch::ResultWas::Ok, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )
 #define ANON_TEST_CASE() INTERNAL_CATCH_TESTCASE()
@@ -13907,6 +13915,7 @@ using Catch::Detail::Approx;
 #define SECTION( ... )
 #define DYNAMIC_SECTION( ... )
 #define FAIL( ... ) (void)(0)
+#define FAIL_LINE( ... ) (void)(0)
 #define FAIL_CHECK( ... ) (void)(0)
 #define SUCCEED( ... ) (void)(0)
 #define ANON_TEST_CASE() INTERNAL_CATCH_TESTCASE_NO_REGISTRATION(INTERNAL_CATCH_UNIQUE_NAME( ____C_A_T_C_H____T_E_S_T____ ))
diff --git a/tools/pythonpkg/duckdb_python.cpp b/tools/pythonpkg/duckdb_python.cpp
index 48d4be61a82e..9b87cfbe9302 100644
--- a/tools/pythonpkg/duckdb_python.cpp
+++ b/tools/pythonpkg/duckdb_python.cpp
@@ -61,8 +61,7 @@ struct IntegralConvert {
 	}
 };
 
-template <>
-double IntegralConvert::convert_value(hugeint_t val) {
+template <> double IntegralConvert::convert_value(hugeint_t val) {
 	double result;
 	Hugeint::TryCast(val, result);
 	return result;
@@ -93,7 +92,7 @@ template <class T> static py::array fetch_column_regular(string numpy_type, Chun
 	return fetch_column<T, T, RegularConvert>(numpy_type, collection, column);
 }
 
-template<class DUCKDB_T>
+template <class DUCKDB_T>
 static void decimal_convert_internal(ChunkCollection &collection, idx_t column, double *out_ptr, double division) {
 	idx_t out_offset = 0;
 	for (auto &data_chunk : collection.chunks) {
@@ -110,13 +109,14 @@ static void decimal_convert_internal(ChunkCollection &collection, idx_t column,
 	}
 }
 
-static py::array fetch_column_decimal(string numpy_type, ChunkCollection &collection, idx_t column, LogicalType &decimal_type) {
+static py::array fetch_column_decimal(string numpy_type, ChunkCollection &collection, idx_t column,
+                                      LogicalType &decimal_type) {
 	auto out = py::array(py::dtype(numpy_type), collection.count);
 	auto out_ptr = (double *)out.mutable_data();
 
 	auto dec_scale = decimal_type.scale();
 	double division = pow(10, dec_scale);
-	switch(decimal_type.InternalType()) {
+	switch (decimal_type.InternalType()) {
 	case PhysicalType::INT16:
 		decimal_convert_internal<int16_t>(collection, column, out_ptr, division);
 		break;
@@ -155,17 +155,24 @@ std::string generate() {
 
 struct PandasScanFunctionData : public TableFunctionData {
 	PandasScanFunctionData(py::handle df, idx_t row_count, vector<LogicalType> sql_types)
-	    : df(df), row_count(row_count), sql_types(sql_types), position(0) {
+	    : df(df), row_count(row_count), sql_types(sql_types) {
 	}
 	py::handle df;
 	idx_t row_count;
 	vector<LogicalType> sql_types;
+};
+
+struct PandasScanState : public FunctionOperatorData {
+	PandasScanState() : position(0) {
+	}
+
 	idx_t position;
 };
 
 struct PandasScanFunction : public TableFunction {
 	PandasScanFunction()
-	    : TableFunction("pandas_scan", {LogicalType::VARCHAR}, pandas_scan_bind, pandas_scan_function, nullptr){};
+	    : TableFunction("pandas_scan", {LogicalType::VARCHAR}, pandas_scan_function, pandas_scan_bind, pandas_scan_init,
+	                    nullptr, nullptr, nullptr, pandas_scan_cardinality){};
 
 	static unique_ptr<FunctionData> pandas_scan_bind(ClientContext &context, vector<Value> &inputs,
 	                                                 unordered_map<string, Value> &named_parameters,
@@ -220,6 +227,12 @@ struct PandasScanFunction : public TableFunction {
 		return make_unique<PandasScanFunctionData>(df, row_count, return_types);
 	}
 
+	static unique_ptr<FunctionOperatorData> pandas_scan_init(ClientContext &context, const FunctionData *bind_data,
+	                                                         OperatorTaskInfo *task_info, vector<column_t> &column_ids,
+	                                                         unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+		return make_unique<PandasScanState>();
+	}
+
 	template <class T> static void scan_pandas_column(py::array numpy_col, idx_t count, idx_t offset, Vector &out) {
 		auto src_ptr = (T *)numpy_col.data();
 		FlatVector::SetData(out, (data_ptr_t)(src_ptr + offset));
@@ -240,14 +253,15 @@ struct PandasScanFunction : public TableFunction {
 		}
 	}
 
-	static void pandas_scan_function(ClientContext &context, vector<Value> &input, DataChunk &output,
-	                                 FunctionData *dataptr) {
-		auto &data = *((PandasScanFunctionData *)dataptr);
+	static void pandas_scan_function(ClientContext &context, const FunctionData *bind_data,
+	                                 FunctionOperatorData *operator_state, DataChunk &output) {
+		auto &data = (PandasScanFunctionData &)*bind_data;
+		auto &state = (PandasScanState &)*operator_state;
 
-		if (data.position >= data.row_count) {
+		if (state.position >= data.row_count) {
 			return;
 		}
-		idx_t this_count = std::min((idx_t)STANDARD_VECTOR_SIZE, data.row_count - data.position);
+		idx_t this_count = std::min((idx_t)STANDARD_VECTOR_SIZE, data.row_count - state.position);
 
 		auto df_names = py::list(data.df.attr("columns"));
 		auto get_fun = data.df.attr("__getitem__");
@@ -258,26 +272,26 @@ struct PandasScanFunction : public TableFunction {
 
 			switch (data.sql_types[col_idx].id()) {
 			case LogicalTypeId::BOOLEAN:
-				scan_pandas_column<bool>(numpy_col, this_count, data.position, output.data[col_idx]);
+				scan_pandas_column<bool>(numpy_col, this_count, state.position, output.data[col_idx]);
 				break;
 			case LogicalTypeId::TINYINT:
-				scan_pandas_column<int8_t>(numpy_col, this_count, data.position, output.data[col_idx]);
+				scan_pandas_column<int8_t>(numpy_col, this_count, state.position, output.data[col_idx]);
 				break;
 			case LogicalTypeId::SMALLINT:
-				scan_pandas_column<int16_t>(numpy_col, this_count, data.position, output.data[col_idx]);
+				scan_pandas_column<int16_t>(numpy_col, this_count, state.position, output.data[col_idx]);
 				break;
 			case LogicalTypeId::INTEGER:
-				scan_pandas_column<int32_t>(numpy_col, this_count, data.position, output.data[col_idx]);
+				scan_pandas_column<int32_t>(numpy_col, this_count, state.position, output.data[col_idx]);
 				break;
 			case LogicalTypeId::BIGINT:
-				scan_pandas_column<int64_t>(numpy_col, this_count, data.position, output.data[col_idx]);
+				scan_pandas_column<int64_t>(numpy_col, this_count, state.position, output.data[col_idx]);
 				break;
 			case LogicalTypeId::FLOAT:
-				scan_pandas_fp_column<float>((float *)numpy_col.data(), this_count, data.position,
+				scan_pandas_fp_column<float>((float *)numpy_col.data(), this_count, state.position,
 				                             output.data[col_idx]);
 				break;
 			case LogicalTypeId::DOUBLE:
-				scan_pandas_fp_column<double>((double *)numpy_col.data(), this_count, data.position,
+				scan_pandas_fp_column<double>((double *)numpy_col.data(), this_count, state.position,
 				                              output.data[col_idx]);
 				break;
 			case LogicalTypeId::TIMESTAMP: {
@@ -286,7 +300,7 @@ struct PandasScanFunction : public TableFunction {
 				auto &nullmask = FlatVector::Nullmask(output.data[col_idx]);
 
 				for (idx_t row = 0; row < this_count; row++) {
-					auto source_idx = data.position + row;
+					auto source_idx = state.position + row;
 					if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
 						// pandas Not a Time (NaT)
 						nullmask[row] = true;
@@ -305,7 +319,7 @@ struct PandasScanFunction : public TableFunction {
 				auto tgt_ptr = (string_t *)FlatVector::GetData(output.data[col_idx]);
 
 				for (idx_t row = 0; row < this_count; row++) {
-					auto source_idx = data.position + row;
+					auto source_idx = state.position + row;
 					auto val = src_ptr[source_idx];
 
 #if PY_MAJOR_VERSION >= 3
@@ -332,7 +346,12 @@ struct PandasScanFunction : public TableFunction {
 				throw runtime_error("Unsupported type " + data.sql_types[col_idx].ToString());
 			}
 		}
-		data.position += this_count;
+		state.position += this_count;
+	}
+
+	static idx_t pandas_scan_cardinality(const FunctionData *bind_data) {
+		auto &data = (PandasScanFunctionData &)*bind_data;
+		return data.row_count;
 	}
 };
 
@@ -504,7 +523,8 @@ struct DuckDBPyResult {
 				col_res = duckdb_py_convert::fetch_column_regular<double>("float64", mres->collection, col_idx);
 				break;
 			case LogicalTypeId::DECIMAL:
-				col_res = duckdb_py_convert::fetch_column_decimal("float64", mres->collection, col_idx, mres->types[col_idx]);
+				col_res =
+				    duckdb_py_convert::fetch_column_decimal("float64", mres->collection, col_idx, mres->types[col_idx]);
 				break;
 			case LogicalTypeId::TIMESTAMP:
 				col_res = duckdb_py_convert::fetch_column<timestamp_t, int64_t, duckdb_py_convert::TimestampConvert>(
diff --git a/tools/rpkg/src/duckdbr.cpp b/tools/rpkg/src/duckdbr.cpp
index 5dd7d9a77d72..e8df1e1f7a7e 100644
--- a/tools/rpkg/src/duckdbr.cpp
+++ b/tools/rpkg/src/duckdbr.cpp
@@ -36,14 +36,12 @@ static void vector_to_r(Vector &src_vec, size_t count, void *dest, uint64_t dest
 }
 
 struct RIntegralType {
-	template<class T>
-	static double DoubleCast(T val) {
+	template <class T> static double DoubleCast(T val) {
 		return double(val);
 	}
 };
 
-template<class T>
-static void RDecimalCastLoop(Vector &src_vec, size_t count, double *dest_ptr, uint8_t scale) {
+template <class T> static void RDecimalCastLoop(Vector &src_vec, size_t count, double *dest_ptr, uint8_t scale) {
 	auto src_ptr = FlatVector::GetData<T>(src_vec);
 	auto &nullmask = FlatVector::Nullmask(src_vec);
 	double division = pow(10, scale);
@@ -557,7 +555,7 @@ SEXP duckdb_execute_R(SEXP stmtsexp) {
 					auto &decimal_type = result->types[col_idx];
 					double *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;
 					auto dec_scale = decimal_type.scale();
-					switch(decimal_type.InternalType()) {
+					switch (decimal_type.InternalType()) {
 					case PhysicalType::INT16:
 						RDecimalCastLoop<int16_t>(src_vec, chunk->size(), dest_ptr, dec_scale);
 						break;
@@ -628,18 +626,24 @@ static SEXP duckdb_finalize_database_R(SEXP dbsexp) {
 
 struct DataFrameScanFunctionData : public TableFunctionData {
 	DataFrameScanFunctionData(SEXP df, idx_t row_count, vector<RType> rtypes)
-	    : df(df), row_count(row_count), rtypes(rtypes), position(0) {
+	    : df(df), row_count(row_count), rtypes(rtypes) {
 	}
 	SEXP df;
 	idx_t row_count;
 	vector<RType> rtypes;
+};
+
+struct DataFrameScanState : public FunctionOperatorData {
+	DataFrameScanState() : position(0) {
+	}
+
 	idx_t position;
 };
 
 struct DataFrameScanFunction : public TableFunction {
 	DataFrameScanFunction()
-	    : TableFunction("dataframe_scan", {LogicalType::VARCHAR}, dataframe_scan_bind, dataframe_scan_function,
-	                    nullptr){};
+	    : TableFunction("dataframe_scan", {LogicalType::VARCHAR}, dataframe_scan_function, dataframe_scan_bind,
+	                    dataframe_scan_init, nullptr, nullptr, nullptr, dataframe_scan_cardinality){};
 
 	static unique_ptr<FunctionData> dataframe_scan_bind(ClientContext &context, vector<Value> &inputs,
 	                                                    unordered_map<string, Value> &named_parameters,
@@ -685,14 +689,20 @@ struct DataFrameScanFunction : public TableFunction {
 		return make_unique<DataFrameScanFunctionData>(df, row_count, rtypes);
 	}
 
-	static void dataframe_scan_function(ClientContext &context, vector<Value> &input, DataChunk &output,
-	                                    FunctionData *dataptr) {
-		auto &data = *((DataFrameScanFunctionData *)dataptr);
+	static unique_ptr<FunctionOperatorData>
+	dataframe_scan_init(ClientContext &context, const FunctionData *bind_data, OperatorTaskInfo *task_info,
+	                    vector<column_t> &column_ids, unordered_map<idx_t, vector<TableFilter>> &table_filters) {
+		return make_unique<DataFrameScanState>();
+	}
 
-		if (data.position >= data.row_count) {
+	static void dataframe_scan_function(ClientContext &context, const FunctionData *bind_data,
+	                                    FunctionOperatorData *operator_state, DataChunk &output) {
+		auto &data = (DataFrameScanFunctionData &)*bind_data;
+		auto &state = (DataFrameScanState &)*operator_state;
+		if (state.position >= data.row_count) {
 			return;
 		}
-		idx_t this_count = std::min((idx_t)STANDARD_VECTOR_SIZE, data.row_count - data.position);
+		idx_t this_count = std::min((idx_t)STANDARD_VECTOR_SIZE, data.row_count - state.position);
 
 		output.SetCardinality(this_count);
 
@@ -703,33 +713,33 @@ struct DataFrameScanFunction : public TableFunction {
 
 			switch (data.rtypes[col_idx]) {
 			case RType::LOGICAL: {
-				auto data_ptr = INTEGER_POINTER(coldata) + data.position;
+				auto data_ptr = INTEGER_POINTER(coldata) + state.position;
 				AppendColumnSegment<int, bool, RBooleanType>(data_ptr, v, this_count);
 				break;
 			}
 			case RType::INTEGER: {
-				auto data_ptr = INTEGER_POINTER(coldata) + data.position;
+				auto data_ptr = INTEGER_POINTER(coldata) + state.position;
 				AppendColumnSegment<int, int, RIntegerType>(data_ptr, v, this_count);
 				break;
 			}
 			case RType::NUMERIC: {
-				auto data_ptr = NUMERIC_POINTER(coldata) + data.position;
+				auto data_ptr = NUMERIC_POINTER(coldata) + state.position;
 				AppendColumnSegment<double, double, RDoubleType>(data_ptr, v, this_count);
 				break;
 			}
 			case RType::STRING:
-				AppendStringSegment(coldata, v, data.position, this_count);
+				AppendStringSegment(coldata, v, state.position, this_count);
 				break;
 			case RType::FACTOR:
-				AppendFactor(coldata, v, data.position, this_count);
+				AppendFactor(coldata, v, state.position, this_count);
 				break;
 			case RType::TIMESTAMP: {
-				auto data_ptr = NUMERIC_POINTER(coldata) + data.position;
+				auto data_ptr = NUMERIC_POINTER(coldata) + state.position;
 				AppendColumnSegment<double, timestamp_t, RTimestampType>(data_ptr, v, this_count);
 				break;
 			}
 			case RType::DATE: {
-				auto data_ptr = NUMERIC_POINTER(coldata) + data.position;
+				auto data_ptr = NUMERIC_POINTER(coldata) + state.position;
 				AppendColumnSegment<double, date_t, RDateType>(data_ptr, v, this_count);
 				break;
 			}
@@ -738,7 +748,12 @@ struct DataFrameScanFunction : public TableFunction {
 			}
 		}
 
-		data.position += this_count;
+		state.position += this_count;
+	}
+
+	static idx_t dataframe_scan_cardinality(const FunctionData *bind_data) {
+		auto &data = (DataFrameScanFunctionData &)*bind_data;
+		return data.row_count;
 	}
 };
 
